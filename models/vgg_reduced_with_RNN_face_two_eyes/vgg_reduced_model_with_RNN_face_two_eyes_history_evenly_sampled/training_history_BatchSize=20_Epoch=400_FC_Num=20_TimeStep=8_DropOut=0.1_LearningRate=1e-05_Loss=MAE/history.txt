Epoch: 1| Step: 0
Training loss: 6.029313087463379
Validation loss: 5.232009108348559

Epoch: 5| Step: 1
Training loss: 5.183974266052246
Validation loss: 5.2216170782684

Epoch: 5| Step: 2
Training loss: 5.172536849975586
Validation loss: 5.211851325086368

Epoch: 5| Step: 3
Training loss: 4.190723896026611
Validation loss: 5.202419352787797

Epoch: 5| Step: 4
Training loss: 4.415961742401123
Validation loss: 5.193677158765896

Epoch: 5| Step: 5
Training loss: 5.962930679321289
Validation loss: 5.184967246106876

Epoch: 5| Step: 6
Training loss: 4.923110485076904
Validation loss: 5.1761431642757945

Epoch: 5| Step: 7
Training loss: 4.842325210571289
Validation loss: 5.166912171148485

Epoch: 5| Step: 8
Training loss: 4.567807197570801
Validation loss: 5.156305282346664

Epoch: 5| Step: 9
Training loss: 4.816042900085449
Validation loss: 5.144951979319255

Epoch: 5| Step: 10
Training loss: 4.6214799880981445
Validation loss: 5.132256492491691

Epoch: 2| Step: 0
Training loss: 4.264437675476074
Validation loss: 5.118845908872543

Epoch: 5| Step: 1
Training loss: 4.216276168823242
Validation loss: 5.103989144807221

Epoch: 5| Step: 2
Training loss: 6.284358501434326
Validation loss: 5.0880446228929745

Epoch: 5| Step: 3
Training loss: 6.244481086730957
Validation loss: 5.0699276821587675

Epoch: 5| Step: 4
Training loss: 5.343702793121338
Validation loss: 5.050212070506106

Epoch: 5| Step: 5
Training loss: 3.848442554473877
Validation loss: 5.0296615887713685

Epoch: 5| Step: 6
Training loss: 4.602524280548096
Validation loss: 5.006818320161553

Epoch: 5| Step: 7
Training loss: 4.53935432434082
Validation loss: 4.981707270427417

Epoch: 5| Step: 8
Training loss: 5.182417392730713
Validation loss: 4.954242460189327

Epoch: 5| Step: 9
Training loss: 5.101482391357422
Validation loss: 4.926200569316905

Epoch: 5| Step: 10
Training loss: 3.0466325283050537
Validation loss: 4.895566776234617

Epoch: 3| Step: 0
Training loss: 4.111353874206543
Validation loss: 4.861380761669528

Epoch: 5| Step: 1
Training loss: 3.746157169342041
Validation loss: 4.825843206015966

Epoch: 5| Step: 2
Training loss: 5.625574111938477
Validation loss: 4.788198183941585

Epoch: 5| Step: 3
Training loss: 4.0770134925842285
Validation loss: 4.748040117243285

Epoch: 5| Step: 4
Training loss: 5.279841423034668
Validation loss: 4.708206915086316

Epoch: 5| Step: 5
Training loss: 4.1064066886901855
Validation loss: 4.666736782238048

Epoch: 5| Step: 6
Training loss: 5.49133825302124
Validation loss: 4.623630205790202

Epoch: 5| Step: 7
Training loss: 3.4805378913879395
Validation loss: 4.581280334021455

Epoch: 5| Step: 8
Training loss: 4.508041858673096
Validation loss: 4.5393844419910065

Epoch: 5| Step: 9
Training loss: 4.527743339538574
Validation loss: 4.500941866187639

Epoch: 5| Step: 10
Training loss: 3.9241323471069336
Validation loss: 4.461632692685691

Epoch: 4| Step: 0
Training loss: 5.538203716278076
Validation loss: 4.424270004354497

Epoch: 5| Step: 1
Training loss: 3.9196460247039795
Validation loss: 4.390183625682708

Epoch: 5| Step: 2
Training loss: 3.821352005004883
Validation loss: 4.35767731102564

Epoch: 5| Step: 3
Training loss: 3.6242928504943848
Validation loss: 4.324282128323791

Epoch: 5| Step: 4
Training loss: 2.6070125102996826
Validation loss: 4.29215891386873

Epoch: 5| Step: 5
Training loss: 4.357342720031738
Validation loss: 4.263518461617091

Epoch: 5| Step: 6
Training loss: 3.277200222015381
Validation loss: 4.233831795313025

Epoch: 5| Step: 7
Training loss: 3.7910523414611816
Validation loss: 4.2018045071632635

Epoch: 5| Step: 8
Training loss: 3.785520076751709
Validation loss: 4.170183058707945

Epoch: 5| Step: 9
Training loss: 4.882599830627441
Validation loss: 4.1383053692438265

Epoch: 5| Step: 10
Training loss: 5.3874077796936035
Validation loss: 4.10912222503334

Epoch: 5| Step: 0
Training loss: 4.365634918212891
Validation loss: 4.079754444860643

Epoch: 5| Step: 1
Training loss: 4.111175537109375
Validation loss: 4.052495207837833

Epoch: 5| Step: 2
Training loss: 4.354457855224609
Validation loss: 4.02585849454326

Epoch: 5| Step: 3
Training loss: 2.7449400424957275
Validation loss: 4.000903370559857

Epoch: 5| Step: 4
Training loss: 4.99633264541626
Validation loss: 3.976994160682924

Epoch: 5| Step: 5
Training loss: 3.5773773193359375
Validation loss: 3.9538082948295017

Epoch: 5| Step: 6
Training loss: 2.1839065551757812
Validation loss: 3.930969638209189

Epoch: 5| Step: 7
Training loss: 2.924166679382324
Validation loss: 3.9114101215075423

Epoch: 5| Step: 8
Training loss: 4.094909191131592
Validation loss: 3.893635149924986

Epoch: 5| Step: 9
Training loss: 4.200217247009277
Validation loss: 3.8780619457203853

Epoch: 5| Step: 10
Training loss: 4.52788782119751
Validation loss: 3.865191467346684

Epoch: 6| Step: 0
Training loss: 3.4477226734161377
Validation loss: 3.8501614216835267

Epoch: 5| Step: 1
Training loss: 4.122990608215332
Validation loss: 3.8395236743393766

Epoch: 5| Step: 2
Training loss: 4.187029838562012
Validation loss: 3.828469796847272

Epoch: 5| Step: 3
Training loss: 4.565158843994141
Validation loss: 3.8167628780488045

Epoch: 5| Step: 4
Training loss: 4.379806041717529
Validation loss: 3.807562038462649

Epoch: 5| Step: 5
Training loss: 2.843412160873413
Validation loss: 3.798621357128184

Epoch: 5| Step: 6
Training loss: 3.4054572582244873
Validation loss: 3.7887528634840444

Epoch: 5| Step: 7
Training loss: 3.7763259410858154
Validation loss: 3.7817280010510514

Epoch: 5| Step: 8
Training loss: 4.254132270812988
Validation loss: 3.772819149878717

Epoch: 5| Step: 9
Training loss: 2.6039841175079346
Validation loss: 3.764471048949867

Epoch: 5| Step: 10
Training loss: 2.8475522994995117
Validation loss: 3.755815836691087

Epoch: 7| Step: 0
Training loss: 3.457099199295044
Validation loss: 3.7473285326393704

Epoch: 5| Step: 1
Training loss: 4.190733909606934
Validation loss: 3.735476116980276

Epoch: 5| Step: 2
Training loss: 3.0713019371032715
Validation loss: 3.7236182048756588

Epoch: 5| Step: 3
Training loss: 3.2060153484344482
Validation loss: 3.7127999541580037

Epoch: 5| Step: 4
Training loss: 4.343581199645996
Validation loss: 3.699973334548294

Epoch: 5| Step: 5
Training loss: 3.9535439014434814
Validation loss: 3.689798939612604

Epoch: 5| Step: 6
Training loss: 3.4627552032470703
Validation loss: 3.6783767566886

Epoch: 5| Step: 7
Training loss: 3.5433592796325684
Validation loss: 3.6700115870403986

Epoch: 5| Step: 8
Training loss: 2.9397435188293457
Validation loss: 3.661727125926684

Epoch: 5| Step: 9
Training loss: 3.197700023651123
Validation loss: 3.651811238258116

Epoch: 5| Step: 10
Training loss: 4.28973388671875
Validation loss: 3.647203799216978

Epoch: 8| Step: 0
Training loss: 4.279440879821777
Validation loss: 3.6407059854076755

Epoch: 5| Step: 1
Training loss: 2.6918275356292725
Validation loss: 3.633230963060933

Epoch: 5| Step: 2
Training loss: 3.7301013469696045
Validation loss: 3.624100277500768

Epoch: 5| Step: 3
Training loss: 3.7957401275634766
Validation loss: 3.6180774422102076

Epoch: 5| Step: 4
Training loss: 3.5103859901428223
Validation loss: 3.6116788746208273

Epoch: 5| Step: 5
Training loss: 3.5184237957000732
Validation loss: 3.6033652546585246

Epoch: 5| Step: 6
Training loss: 3.367161273956299
Validation loss: 3.5971591523898545

Epoch: 5| Step: 7
Training loss: 2.6658847332000732
Validation loss: 3.5894998581178728

Epoch: 5| Step: 8
Training loss: 4.0345778465271
Validation loss: 3.581078701121833

Epoch: 5| Step: 9
Training loss: 3.0037522315979004
Validation loss: 3.5748952486181773

Epoch: 5| Step: 10
Training loss: 4.282643795013428
Validation loss: 3.567671783508793

Epoch: 9| Step: 0
Training loss: 4.099507808685303
Validation loss: 3.5593533900476273

Epoch: 5| Step: 1
Training loss: 3.135958194732666
Validation loss: 3.552702416655838

Epoch: 5| Step: 2
Training loss: 3.192432403564453
Validation loss: 3.541430950164795

Epoch: 5| Step: 3
Training loss: 4.013760566711426
Validation loss: 3.5341449963149203

Epoch: 5| Step: 4
Training loss: 3.5415701866149902
Validation loss: 3.521460909997263

Epoch: 5| Step: 5
Training loss: 3.76731538772583
Validation loss: 3.5096757847775697

Epoch: 5| Step: 6
Training loss: 2.6832175254821777
Validation loss: 3.4996957855839885

Epoch: 5| Step: 7
Training loss: 3.190627336502075
Validation loss: 3.4893227802809847

Epoch: 5| Step: 8
Training loss: 3.140941858291626
Validation loss: 3.482024654265373

Epoch: 5| Step: 9
Training loss: 4.206412315368652
Validation loss: 3.4722390379956973

Epoch: 5| Step: 10
Training loss: 2.838878631591797
Validation loss: 3.459932719507525

Epoch: 10| Step: 0
Training loss: 2.8518500328063965
Validation loss: 3.4488031197619695

Epoch: 5| Step: 1
Training loss: 3.2981696128845215
Validation loss: 3.4419252693012194

Epoch: 5| Step: 2
Training loss: 3.6039795875549316
Validation loss: 3.4323258271781345

Epoch: 5| Step: 3
Training loss: 3.0565385818481445
Validation loss: 3.4226215013893704

Epoch: 5| Step: 4
Training loss: 3.0727667808532715
Validation loss: 3.414908796228388

Epoch: 5| Step: 5
Training loss: 4.021265506744385
Validation loss: 3.4087696331803516

Epoch: 5| Step: 6
Training loss: 3.8315589427948
Validation loss: 3.398410689446234

Epoch: 5| Step: 7
Training loss: 3.6969478130340576
Validation loss: 3.3899761297369517

Epoch: 5| Step: 8
Training loss: 3.1194281578063965
Validation loss: 3.381354803680092

Epoch: 5| Step: 9
Training loss: 3.380624294281006
Validation loss: 3.375267708173362

Epoch: 5| Step: 10
Training loss: 2.8921570777893066
Validation loss: 3.367231627946259

Epoch: 11| Step: 0
Training loss: 3.7128005027770996
Validation loss: 3.359421096822267

Epoch: 5| Step: 1
Training loss: 3.0777363777160645
Validation loss: 3.350503234453099

Epoch: 5| Step: 2
Training loss: 3.0378806591033936
Validation loss: 3.3421313198663856

Epoch: 5| Step: 3
Training loss: 2.7577147483825684
Validation loss: 3.3356920057727444

Epoch: 5| Step: 4
Training loss: 3.908029556274414
Validation loss: 3.328174329573108

Epoch: 5| Step: 5
Training loss: 2.7225067615509033
Validation loss: 3.3212865552594586

Epoch: 5| Step: 6
Training loss: 2.9036338329315186
Validation loss: 3.316334327061971

Epoch: 5| Step: 7
Training loss: 2.802718162536621
Validation loss: 3.3106885597270024

Epoch: 5| Step: 8
Training loss: 4.0124311447143555
Validation loss: 3.303378258982012

Epoch: 5| Step: 9
Training loss: 3.485538959503174
Validation loss: 3.2972109138324694

Epoch: 5| Step: 10
Training loss: 3.843649387359619
Validation loss: 3.2930135060382146

Epoch: 12| Step: 0
Training loss: 3.6375021934509277
Validation loss: 3.2852492409367717

Epoch: 5| Step: 1
Training loss: 3.1987249851226807
Validation loss: 3.2829390930873092

Epoch: 5| Step: 2
Training loss: 3.4342727661132812
Validation loss: 3.273216493668095

Epoch: 5| Step: 3
Training loss: 3.775373935699463
Validation loss: 3.271481983123287

Epoch: 5| Step: 4
Training loss: 2.7039785385131836
Validation loss: 3.267563327666252

Epoch: 5| Step: 5
Training loss: 3.288079023361206
Validation loss: 3.2666732136921217

Epoch: 5| Step: 6
Training loss: 3.3208835124969482
Validation loss: 3.257767485034081

Epoch: 5| Step: 7
Training loss: 3.285640239715576
Validation loss: 3.251987834130564

Epoch: 5| Step: 8
Training loss: 3.0773959159851074
Validation loss: 3.2447727700715423

Epoch: 5| Step: 9
Training loss: 3.396357774734497
Validation loss: 3.23884948607414

Epoch: 5| Step: 10
Training loss: 2.463216781616211
Validation loss: 3.2364760111736994

Epoch: 13| Step: 0
Training loss: 2.6249642372131348
Validation loss: 3.2268980215954524

Epoch: 5| Step: 1
Training loss: 2.90622878074646
Validation loss: 3.222657249819848

Epoch: 5| Step: 2
Training loss: 3.4035377502441406
Validation loss: 3.2177072007169008

Epoch: 5| Step: 3
Training loss: 2.301830768585205
Validation loss: 3.216302352566873

Epoch: 5| Step: 4
Training loss: 3.2333686351776123
Validation loss: 3.2091871538469867

Epoch: 5| Step: 5
Training loss: 4.688042640686035
Validation loss: 3.205625246929866

Epoch: 5| Step: 6
Training loss: 2.9899656772613525
Validation loss: 3.1998378948498796

Epoch: 5| Step: 7
Training loss: 3.162224054336548
Validation loss: 3.195503091299406

Epoch: 5| Step: 8
Training loss: 3.176856279373169
Validation loss: 3.1929453598555697

Epoch: 5| Step: 9
Training loss: 3.2839977741241455
Validation loss: 3.185717544248027

Epoch: 5| Step: 10
Training loss: 3.45888090133667
Validation loss: 3.1796826701010428

Epoch: 14| Step: 0
Training loss: 3.04319167137146
Validation loss: 3.1762860359684115

Epoch: 5| Step: 1
Training loss: 3.6528639793395996
Validation loss: 3.1719161823231685

Epoch: 5| Step: 2
Training loss: 4.251728057861328
Validation loss: 3.168854905712989

Epoch: 5| Step: 3
Training loss: 3.0463554859161377
Validation loss: 3.161597890238608

Epoch: 5| Step: 4
Training loss: 2.614238739013672
Validation loss: 3.157719712103567

Epoch: 5| Step: 5
Training loss: 4.211114406585693
Validation loss: 3.1858739109449488

Epoch: 5| Step: 6
Training loss: 2.916834592819214
Validation loss: 3.1507968569314606

Epoch: 5| Step: 7
Training loss: 2.690553665161133
Validation loss: 3.1605432418084916

Epoch: 5| Step: 8
Training loss: 3.361060619354248
Validation loss: 3.170232388281053

Epoch: 5| Step: 9
Training loss: 2.159276247024536
Validation loss: 3.165151919088056

Epoch: 5| Step: 10
Training loss: 2.956166982650757
Validation loss: 3.171512044886107

Epoch: 15| Step: 0
Training loss: 3.7612667083740234
Validation loss: 3.1750506483098513

Epoch: 5| Step: 1
Training loss: 3.427079677581787
Validation loss: 3.165870015339185

Epoch: 5| Step: 2
Training loss: 4.096096515655518
Validation loss: 3.151330776112054

Epoch: 5| Step: 3
Training loss: 2.982166290283203
Validation loss: 3.141442847508256

Epoch: 5| Step: 4
Training loss: 2.408550977706909
Validation loss: 3.1356865411163657

Epoch: 5| Step: 5
Training loss: 2.6641993522644043
Validation loss: 3.127732374334848

Epoch: 5| Step: 6
Training loss: 3.1179263591766357
Validation loss: 3.121209377883583

Epoch: 5| Step: 7
Training loss: 3.6407577991485596
Validation loss: 3.1156144859970256

Epoch: 5| Step: 8
Training loss: 2.8801462650299072
Validation loss: 3.1111209187456357

Epoch: 5| Step: 9
Training loss: 2.8112621307373047
Validation loss: 3.1062309126700125

Epoch: 5| Step: 10
Training loss: 2.8445334434509277
Validation loss: 3.1121335337238927

Epoch: 16| Step: 0
Training loss: 3.6618666648864746
Validation loss: 3.110135668067522

Epoch: 5| Step: 1
Training loss: 2.3609862327575684
Validation loss: 3.091434706923782

Epoch: 5| Step: 2
Training loss: 2.945552349090576
Validation loss: 3.094457200778428

Epoch: 5| Step: 3
Training loss: 2.940178871154785
Validation loss: 3.095949826701995

Epoch: 5| Step: 4
Training loss: 3.209052324295044
Validation loss: 3.0950964343163276

Epoch: 5| Step: 5
Training loss: 3.973580837249756
Validation loss: 3.091070375134868

Epoch: 5| Step: 6
Training loss: 3.807091474533081
Validation loss: 3.081794833624235

Epoch: 5| Step: 7
Training loss: 3.0384438037872314
Validation loss: 3.07235388858344

Epoch: 5| Step: 8
Training loss: 2.8585567474365234
Validation loss: 3.0663093110566497

Epoch: 5| Step: 9
Training loss: 2.808828592300415
Validation loss: 3.063766038545998

Epoch: 5| Step: 10
Training loss: 2.6567277908325195
Validation loss: 3.0623849796992477

Epoch: 17| Step: 0
Training loss: 3.133375644683838
Validation loss: 3.071852381511401

Epoch: 5| Step: 1
Training loss: 2.1714413166046143
Validation loss: 3.06571860723598

Epoch: 5| Step: 2
Training loss: 3.441676378250122
Validation loss: 3.061927103227185

Epoch: 5| Step: 3
Training loss: 2.3179924488067627
Validation loss: 3.053918694937101

Epoch: 5| Step: 4
Training loss: 3.8087692260742188
Validation loss: 3.0479264284974787

Epoch: 5| Step: 5
Training loss: 3.397066831588745
Validation loss: 3.0474027331157396

Epoch: 5| Step: 6
Training loss: 3.2106239795684814
Validation loss: 3.042159057432605

Epoch: 5| Step: 7
Training loss: 2.8190653324127197
Validation loss: 3.037805011195521

Epoch: 5| Step: 8
Training loss: 3.9552829265594482
Validation loss: 3.0354149239037627

Epoch: 5| Step: 9
Training loss: 2.9275925159454346
Validation loss: 3.0335609682144655

Epoch: 5| Step: 10
Training loss: 2.8212947845458984
Validation loss: 3.0289147028359036

Epoch: 18| Step: 0
Training loss: 3.039280652999878
Validation loss: 3.027050156747141

Epoch: 5| Step: 1
Training loss: 2.975628137588501
Validation loss: 3.022940435717183

Epoch: 5| Step: 2
Training loss: 3.174222230911255
Validation loss: 3.020579138109761

Epoch: 5| Step: 3
Training loss: 3.111215591430664
Validation loss: 3.0193609832435526

Epoch: 5| Step: 4
Training loss: 2.443688154220581
Validation loss: 3.014735283390168

Epoch: 5| Step: 5
Training loss: 3.6527607440948486
Validation loss: 3.007434883425313

Epoch: 5| Step: 6
Training loss: 4.111084938049316
Validation loss: 3.006104330862722

Epoch: 5| Step: 7
Training loss: 2.6831157207489014
Validation loss: 3.002520368945214

Epoch: 5| Step: 8
Training loss: 2.1753833293914795
Validation loss: 2.9983560833879697

Epoch: 5| Step: 9
Training loss: 2.7760732173919678
Validation loss: 2.9970503263576056

Epoch: 5| Step: 10
Training loss: 3.731605052947998
Validation loss: 2.9932759372136926

Epoch: 19| Step: 0
Training loss: 3.240903377532959
Validation loss: 2.9922410749620005

Epoch: 5| Step: 1
Training loss: 3.7615630626678467
Validation loss: 2.98808370354355

Epoch: 5| Step: 2
Training loss: 3.2555384635925293
Validation loss: 2.9871376355489097

Epoch: 5| Step: 3
Training loss: 2.7623043060302734
Validation loss: 2.9835946739360852

Epoch: 5| Step: 4
Training loss: 3.0234148502349854
Validation loss: 2.9819938675049813

Epoch: 5| Step: 5
Training loss: 2.307791233062744
Validation loss: 2.979407197685652

Epoch: 5| Step: 6
Training loss: 3.098611354827881
Validation loss: 2.973226137058709

Epoch: 5| Step: 7
Training loss: 3.2001445293426514
Validation loss: 2.972967296518305

Epoch: 5| Step: 8
Training loss: 2.928110361099243
Validation loss: 2.9710007431686565

Epoch: 5| Step: 9
Training loss: 2.720890998840332
Validation loss: 2.970637139453683

Epoch: 5| Step: 10
Training loss: 3.28749680519104
Validation loss: 2.967237457152336

Epoch: 20| Step: 0
Training loss: 3.808086395263672
Validation loss: 2.964342604401291

Epoch: 5| Step: 1
Training loss: 2.9708685874938965
Validation loss: 2.959111982776273

Epoch: 5| Step: 2
Training loss: 2.846076250076294
Validation loss: 2.9589692687475555

Epoch: 5| Step: 3
Training loss: 2.8840744495391846
Validation loss: 2.957081725520472

Epoch: 5| Step: 4
Training loss: 2.671151638031006
Validation loss: 2.9561852075720347

Epoch: 5| Step: 5
Training loss: 2.774364948272705
Validation loss: 2.953295715393559

Epoch: 5| Step: 6
Training loss: 1.907649278640747
Validation loss: 2.951281193763979

Epoch: 5| Step: 7
Training loss: 2.956976890563965
Validation loss: 2.9449438587311776

Epoch: 5| Step: 8
Training loss: 3.833815336227417
Validation loss: 2.9432181466010308

Epoch: 5| Step: 9
Training loss: 3.0751373767852783
Validation loss: 2.9404944937716246

Epoch: 5| Step: 10
Training loss: 3.711060047149658
Validation loss: 2.9406048482464207

Epoch: 21| Step: 0
Training loss: 3.0586583614349365
Validation loss: 2.935493289783437

Epoch: 5| Step: 1
Training loss: 3.5890393257141113
Validation loss: 2.933262571211784

Epoch: 5| Step: 2
Training loss: 2.739503860473633
Validation loss: 2.92743432137274

Epoch: 5| Step: 3
Training loss: 2.5310587882995605
Validation loss: 2.9277112355796238

Epoch: 5| Step: 4
Training loss: 3.120626449584961
Validation loss: 2.926086615490657

Epoch: 5| Step: 5
Training loss: 3.151420831680298
Validation loss: 2.9266976746179725

Epoch: 5| Step: 6
Training loss: 2.586967706680298
Validation loss: 2.9270205831014984

Epoch: 5| Step: 7
Training loss: 3.188760280609131
Validation loss: 2.9230424152907504

Epoch: 5| Step: 8
Training loss: 3.1520321369171143
Validation loss: 2.9188814727208947

Epoch: 5| Step: 9
Training loss: 3.173109769821167
Validation loss: 2.9141139855948825

Epoch: 5| Step: 10
Training loss: 2.816154956817627
Validation loss: 2.9140493715963056

Epoch: 22| Step: 0
Training loss: 2.8991732597351074
Validation loss: 2.908441866597822

Epoch: 5| Step: 1
Training loss: 3.062675714492798
Validation loss: 2.9053512721933346

Epoch: 5| Step: 2
Training loss: 3.439897060394287
Validation loss: 2.904529981715705

Epoch: 5| Step: 3
Training loss: 3.302924394607544
Validation loss: 2.9063323697736188

Epoch: 5| Step: 4
Training loss: 3.2698731422424316
Validation loss: 2.9055449988252375

Epoch: 5| Step: 5
Training loss: 2.895810604095459
Validation loss: 2.902365182035713

Epoch: 5| Step: 6
Training loss: 2.5434136390686035
Validation loss: 2.897438985045238

Epoch: 5| Step: 7
Training loss: 3.381115436553955
Validation loss: 2.8929011539746354

Epoch: 5| Step: 8
Training loss: 2.4417788982391357
Validation loss: 2.8945218619479927

Epoch: 5| Step: 9
Training loss: 2.4630866050720215
Validation loss: 2.8932881073285173

Epoch: 5| Step: 10
Training loss: 3.316298723220825
Validation loss: 2.8901538900149766

Epoch: 23| Step: 0
Training loss: 2.8898558616638184
Validation loss: 2.886515194369901

Epoch: 5| Step: 1
Training loss: 3.1143851280212402
Validation loss: 2.8825608017624065

Epoch: 5| Step: 2
Training loss: 2.928011655807495
Validation loss: 2.88178002449774

Epoch: 5| Step: 3
Training loss: 2.358325719833374
Validation loss: 2.880425671095489

Epoch: 5| Step: 4
Training loss: 3.2927842140197754
Validation loss: 2.883698001984627

Epoch: 5| Step: 5
Training loss: 2.3077964782714844
Validation loss: 2.879643322319113

Epoch: 5| Step: 6
Training loss: 3.171750545501709
Validation loss: 2.8741352147953485

Epoch: 5| Step: 7
Training loss: 2.2821457386016846
Validation loss: 2.8700623230267595

Epoch: 5| Step: 8
Training loss: 3.3955891132354736
Validation loss: 2.8690117430943314

Epoch: 5| Step: 9
Training loss: 3.3865833282470703
Validation loss: 2.867712156746977

Epoch: 5| Step: 10
Training loss: 3.8082144260406494
Validation loss: 2.8674802011059177

Epoch: 24| Step: 0
Training loss: 2.668546199798584
Validation loss: 2.864868499899423

Epoch: 5| Step: 1
Training loss: 2.7441067695617676
Validation loss: 2.8645364956189225

Epoch: 5| Step: 2
Training loss: 3.660100221633911
Validation loss: 2.862131231574602

Epoch: 5| Step: 3
Training loss: 3.3707268238067627
Validation loss: 2.8598883536554154

Epoch: 5| Step: 4
Training loss: 2.756298065185547
Validation loss: 2.8549634871944303

Epoch: 5| Step: 5
Training loss: 3.306182384490967
Validation loss: 2.8553620153857815

Epoch: 5| Step: 6
Training loss: 2.636401414871216
Validation loss: 2.8521556290247108

Epoch: 5| Step: 7
Training loss: 2.2073974609375
Validation loss: 2.8537975229242796

Epoch: 5| Step: 8
Training loss: 3.2145323753356934
Validation loss: 2.851094966293663

Epoch: 5| Step: 9
Training loss: 2.969006061553955
Validation loss: 2.852461168842931

Epoch: 5| Step: 10
Training loss: 3.1503992080688477
Validation loss: 2.852729602526593

Epoch: 25| Step: 0
Training loss: 2.9257895946502686
Validation loss: 2.858223725390691

Epoch: 5| Step: 1
Training loss: 2.5427517890930176
Validation loss: 2.851837665803971

Epoch: 5| Step: 2
Training loss: 3.5822463035583496
Validation loss: 2.853157179329985

Epoch: 5| Step: 3
Training loss: 2.883953094482422
Validation loss: 2.8464792697660384

Epoch: 5| Step: 4
Training loss: 3.7219901084899902
Validation loss: 2.8451689417644213

Epoch: 5| Step: 5
Training loss: 2.549611806869507
Validation loss: 2.8449364272497033

Epoch: 5| Step: 6
Training loss: 2.5819575786590576
Validation loss: 2.8444577288883988

Epoch: 5| Step: 7
Training loss: 3.0633022785186768
Validation loss: 2.8439061052055767

Epoch: 5| Step: 8
Training loss: 2.906101942062378
Validation loss: 2.8395019910668813

Epoch: 5| Step: 9
Training loss: 2.928969621658325
Validation loss: 2.8434027753850466

Epoch: 5| Step: 10
Training loss: 2.9171533584594727
Validation loss: 2.841708767798639

Epoch: 26| Step: 0
Training loss: 3.120579719543457
Validation loss: 2.836740457883445

Epoch: 5| Step: 1
Training loss: 2.985478162765503
Validation loss: 2.8336011466159614

Epoch: 5| Step: 2
Training loss: 3.0243988037109375
Validation loss: 2.8308356782441497

Epoch: 5| Step: 3
Training loss: 3.2389473915100098
Validation loss: 2.8319532384154615

Epoch: 5| Step: 4
Training loss: 3.2148406505584717
Validation loss: 2.831257845765801

Epoch: 5| Step: 5
Training loss: 2.8110268115997314
Validation loss: 2.8283690534612185

Epoch: 5| Step: 6
Training loss: 3.4467110633850098
Validation loss: 2.8293307596637356

Epoch: 5| Step: 7
Training loss: 2.7979812622070312
Validation loss: 2.826502643605714

Epoch: 5| Step: 8
Training loss: 2.9053685665130615
Validation loss: 2.825893117535499

Epoch: 5| Step: 9
Training loss: 2.8451716899871826
Validation loss: 2.8271399723586215

Epoch: 5| Step: 10
Training loss: 1.955157995223999
Validation loss: 2.83554575263813

Epoch: 27| Step: 0
Training loss: 2.224381446838379
Validation loss: 2.825467078916488

Epoch: 5| Step: 1
Training loss: 2.9684455394744873
Validation loss: 2.8285671716095298

Epoch: 5| Step: 2
Training loss: 2.7871384620666504
Validation loss: 2.830632548178396

Epoch: 5| Step: 3
Training loss: 3.0757663249969482
Validation loss: 2.8367320875967703

Epoch: 5| Step: 4
Training loss: 3.319615125656128
Validation loss: 2.8410486303349978

Epoch: 5| Step: 5
Training loss: 3.4361655712127686
Validation loss: 2.835154374440511

Epoch: 5| Step: 6
Training loss: 2.744821548461914
Validation loss: 2.830776801673315

Epoch: 5| Step: 7
Training loss: 2.063309907913208
Validation loss: 2.8265732360142533

Epoch: 5| Step: 8
Training loss: 3.3558106422424316
Validation loss: 2.8228229297104703

Epoch: 5| Step: 9
Training loss: 3.3246617317199707
Validation loss: 2.8239036606204126

Epoch: 5| Step: 10
Training loss: 3.2132086753845215
Validation loss: 2.823804604109897

Epoch: 28| Step: 0
Training loss: 2.3659849166870117
Validation loss: 2.8234019535844044

Epoch: 5| Step: 1
Training loss: 3.318533420562744
Validation loss: 2.822882285682104

Epoch: 5| Step: 2
Training loss: 2.8852787017822266
Validation loss: 2.82030394769484

Epoch: 5| Step: 3
Training loss: 2.8831210136413574
Validation loss: 2.8191099474506993

Epoch: 5| Step: 4
Training loss: 3.5425007343292236
Validation loss: 2.817127157283086

Epoch: 5| Step: 5
Training loss: 2.8048205375671387
Validation loss: 2.813247826791579

Epoch: 5| Step: 6
Training loss: 3.0106911659240723
Validation loss: 2.811727977568103

Epoch: 5| Step: 7
Training loss: 3.2686245441436768
Validation loss: 2.8117825138953423

Epoch: 5| Step: 8
Training loss: 2.3581886291503906
Validation loss: 2.8092741684247087

Epoch: 5| Step: 9
Training loss: 3.1796576976776123
Validation loss: 2.806436536132648

Epoch: 5| Step: 10
Training loss: 2.706683874130249
Validation loss: 2.8080225195935977

Epoch: 29| Step: 0
Training loss: 2.844085216522217
Validation loss: 2.805706157479235

Epoch: 5| Step: 1
Training loss: 3.184527635574341
Validation loss: 2.803348249004733

Epoch: 5| Step: 2
Training loss: 2.849884510040283
Validation loss: 2.8042101808773574

Epoch: 5| Step: 3
Training loss: 2.4979312419891357
Validation loss: 2.80406702205699

Epoch: 5| Step: 4
Training loss: 2.488635301589966
Validation loss: 2.803996865467359

Epoch: 5| Step: 5
Training loss: 3.1603481769561768
Validation loss: 2.8030272119788715

Epoch: 5| Step: 6
Training loss: 3.728822708129883
Validation loss: 2.8024763189336306

Epoch: 5| Step: 7
Training loss: 3.5112202167510986
Validation loss: 2.803664440749794

Epoch: 5| Step: 8
Training loss: 2.4575107097625732
Validation loss: 2.7997874726531324

Epoch: 5| Step: 9
Training loss: 3.2638518810272217
Validation loss: 2.796624873274116

Epoch: 5| Step: 10
Training loss: 2.192769765853882
Validation loss: 2.7956016678963937

Epoch: 30| Step: 0
Training loss: 3.6214706897735596
Validation loss: 2.797610339298043

Epoch: 5| Step: 1
Training loss: 2.786337375640869
Validation loss: 2.795488372925789

Epoch: 5| Step: 2
Training loss: 2.3841755390167236
Validation loss: 2.796080571348949

Epoch: 5| Step: 3
Training loss: 3.192472457885742
Validation loss: 2.795513447894845

Epoch: 5| Step: 4
Training loss: 2.6427969932556152
Validation loss: 2.79518307921707

Epoch: 5| Step: 5
Training loss: 3.6025664806365967
Validation loss: 2.795063195690032

Epoch: 5| Step: 6
Training loss: 2.232755184173584
Validation loss: 2.793877573423488

Epoch: 5| Step: 7
Training loss: 2.9955990314483643
Validation loss: 2.7940904607055006

Epoch: 5| Step: 8
Training loss: 3.03847074508667
Validation loss: 2.7918374512785222

Epoch: 5| Step: 9
Training loss: 3.3208656311035156
Validation loss: 2.791994861377183

Epoch: 5| Step: 10
Training loss: 2.337566614151001
Validation loss: 2.7908449660065355

Epoch: 31| Step: 0
Training loss: 2.7751975059509277
Validation loss: 2.790555474578693

Epoch: 5| Step: 1
Training loss: 2.548084259033203
Validation loss: 2.7899399521530315

Epoch: 5| Step: 2
Training loss: 2.8066792488098145
Validation loss: 2.788425709611626

Epoch: 5| Step: 3
Training loss: 3.5297958850860596
Validation loss: 2.7873379543263423

Epoch: 5| Step: 4
Training loss: 2.847437858581543
Validation loss: 2.7873031093228247

Epoch: 5| Step: 5
Training loss: 2.5575509071350098
Validation loss: 2.786996269738802

Epoch: 5| Step: 6
Training loss: 3.373145580291748
Validation loss: 2.7850027673987934

Epoch: 5| Step: 7
Training loss: 2.883496046066284
Validation loss: 2.7859494814308743

Epoch: 5| Step: 8
Training loss: 3.618344783782959
Validation loss: 2.783494313557943

Epoch: 5| Step: 9
Training loss: 2.5722527503967285
Validation loss: 2.783967674419444

Epoch: 5| Step: 10
Training loss: 2.63309383392334
Validation loss: 2.7837076546043478

Epoch: 32| Step: 0
Training loss: 2.524029493331909
Validation loss: 2.7833861433049685

Epoch: 5| Step: 1
Training loss: 3.1038756370544434
Validation loss: 2.7817040669020785

Epoch: 5| Step: 2
Training loss: 3.215501308441162
Validation loss: 2.780873344790551

Epoch: 5| Step: 3
Training loss: 2.662148952484131
Validation loss: 2.7803773110912693

Epoch: 5| Step: 4
Training loss: 2.6936683654785156
Validation loss: 2.7787037562298518

Epoch: 5| Step: 5
Training loss: 3.0287883281707764
Validation loss: 2.7796605761333177

Epoch: 5| Step: 6
Training loss: 3.196312665939331
Validation loss: 2.7789839160057808

Epoch: 5| Step: 7
Training loss: 2.7362618446350098
Validation loss: 2.7774687274809806

Epoch: 5| Step: 8
Training loss: 2.6497669219970703
Validation loss: 2.775384485080678

Epoch: 5| Step: 9
Training loss: 3.3521888256073
Validation loss: 2.7756180711971816

Epoch: 5| Step: 10
Training loss: 2.985706090927124
Validation loss: 2.7755137899870514

Epoch: 33| Step: 0
Training loss: 2.628384828567505
Validation loss: 2.7736708271887993

Epoch: 5| Step: 1
Training loss: 3.6102237701416016
Validation loss: 2.7744097402018886

Epoch: 5| Step: 2
Training loss: 3.584425449371338
Validation loss: 2.772836605707804

Epoch: 5| Step: 3
Training loss: 1.9411722421646118
Validation loss: 2.772016191995272

Epoch: 5| Step: 4
Training loss: 2.9066615104675293
Validation loss: 2.7695890395872054

Epoch: 5| Step: 5
Training loss: 2.9234352111816406
Validation loss: 2.770382240254392

Epoch: 5| Step: 6
Training loss: 2.4765937328338623
Validation loss: 2.7670380556455223

Epoch: 5| Step: 7
Training loss: 1.9065208435058594
Validation loss: 2.767131056836856

Epoch: 5| Step: 8
Training loss: 3.545060634613037
Validation loss: 2.76724152411184

Epoch: 5| Step: 9
Training loss: 3.7811012268066406
Validation loss: 2.766022777044645

Epoch: 5| Step: 10
Training loss: 2.7388927936553955
Validation loss: 2.7629642127662577

Epoch: 34| Step: 0
Training loss: 2.8341917991638184
Validation loss: 2.7635542064584713

Epoch: 5| Step: 1
Training loss: 3.4162425994873047
Validation loss: 2.7617843484365814

Epoch: 5| Step: 2
Training loss: 2.2814667224884033
Validation loss: 2.762882609521189

Epoch: 5| Step: 3
Training loss: 3.413700580596924
Validation loss: 2.7619707507471882

Epoch: 5| Step: 4
Training loss: 2.8391802310943604
Validation loss: 2.7606494221636044

Epoch: 5| Step: 5
Training loss: 2.99920392036438
Validation loss: 2.758482022952008

Epoch: 5| Step: 6
Training loss: 3.5982413291931152
Validation loss: 2.7585000735457226

Epoch: 5| Step: 7
Training loss: 3.16024112701416
Validation loss: 2.755683596416186

Epoch: 5| Step: 8
Training loss: 2.184333324432373
Validation loss: 2.756374059184905

Epoch: 5| Step: 9
Training loss: 2.4029736518859863
Validation loss: 2.7554839400834936

Epoch: 5| Step: 10
Training loss: 2.8495872020721436
Validation loss: 2.753011470199913

Epoch: 35| Step: 0
Training loss: 3.4347434043884277
Validation loss: 2.755308420427384

Epoch: 5| Step: 1
Training loss: 3.070857524871826
Validation loss: 2.7552039777078936

Epoch: 5| Step: 2
Training loss: 2.927051067352295
Validation loss: 2.753823167534285

Epoch: 5| Step: 3
Training loss: 2.8559391498565674
Validation loss: 2.7525777868045274

Epoch: 5| Step: 4
Training loss: 3.1280062198638916
Validation loss: 2.7523709215143675

Epoch: 5| Step: 5
Training loss: 2.769153118133545
Validation loss: 2.75355331103007

Epoch: 5| Step: 6
Training loss: 3.4638187885284424
Validation loss: 2.752515459573397

Epoch: 5| Step: 7
Training loss: 2.737151622772217
Validation loss: 2.751329155378444

Epoch: 5| Step: 8
Training loss: 2.682532787322998
Validation loss: 2.749533112331103

Epoch: 5| Step: 9
Training loss: 2.4955830574035645
Validation loss: 2.7494443719105055

Epoch: 5| Step: 10
Training loss: 2.2885944843292236
Validation loss: 2.750058763770647

Epoch: 36| Step: 0
Training loss: 3.797452449798584
Validation loss: 2.7565491430221067

Epoch: 5| Step: 1
Training loss: 2.6159956455230713
Validation loss: 2.760919893941572

Epoch: 5| Step: 2
Training loss: 2.510211229324341
Validation loss: 2.761886642825219

Epoch: 5| Step: 3
Training loss: 1.992588996887207
Validation loss: 2.7611306405836538

Epoch: 5| Step: 4
Training loss: 2.7885003089904785
Validation loss: 2.7590243662557294

Epoch: 5| Step: 5
Training loss: 2.851792573928833
Validation loss: 2.7516192748982418

Epoch: 5| Step: 6
Training loss: 2.8454036712646484
Validation loss: 2.752505794648201

Epoch: 5| Step: 7
Training loss: 2.5587716102600098
Validation loss: 2.7541481346212406

Epoch: 5| Step: 8
Training loss: 3.8515751361846924
Validation loss: 2.7525160876653527

Epoch: 5| Step: 9
Training loss: 3.0349700450897217
Validation loss: 2.74902331700889

Epoch: 5| Step: 10
Training loss: 3.1106739044189453
Validation loss: 2.7702482028674056

Epoch: 37| Step: 0
Training loss: 3.072195053100586
Validation loss: 2.825869514096168

Epoch: 5| Step: 1
Training loss: 3.410661220550537
Validation loss: 2.845238206207111

Epoch: 5| Step: 2
Training loss: 3.229856491088867
Validation loss: 2.8578729091152066

Epoch: 5| Step: 3
Training loss: 2.734684944152832
Validation loss: 2.8410032385139057

Epoch: 5| Step: 4
Training loss: 2.8811447620391846
Validation loss: 2.8195650987727667

Epoch: 5| Step: 5
Training loss: 3.1237785816192627
Validation loss: 2.81333169885861

Epoch: 5| Step: 6
Training loss: 3.4232401847839355
Validation loss: 2.810763548779231

Epoch: 5| Step: 7
Training loss: 2.6003832817077637
Validation loss: 2.8084438334229174

Epoch: 5| Step: 8
Training loss: 2.5047693252563477
Validation loss: 2.8083150284264677

Epoch: 5| Step: 9
Training loss: 2.28083872795105
Validation loss: 2.8099976252484065

Epoch: 5| Step: 10
Training loss: 3.144498348236084
Validation loss: 2.8098597782914356

Epoch: 38| Step: 0
Training loss: 3.0361199378967285
Validation loss: 2.8066948203630346

Epoch: 5| Step: 1
Training loss: 2.9615824222564697
Validation loss: 2.805902134987616

Epoch: 5| Step: 2
Training loss: 2.949714183807373
Validation loss: 2.8095338370210383

Epoch: 5| Step: 3
Training loss: 2.6051440238952637
Validation loss: 2.807843203185707

Epoch: 5| Step: 4
Training loss: 2.650247097015381
Validation loss: 2.809204993709441

Epoch: 5| Step: 5
Training loss: 2.73799204826355
Validation loss: 2.8044537344286518

Epoch: 5| Step: 6
Training loss: 4.041658878326416
Validation loss: 2.805771953316145

Epoch: 5| Step: 7
Training loss: 3.0668234825134277
Validation loss: 2.800551329889605

Epoch: 5| Step: 8
Training loss: 2.7223706245422363
Validation loss: 2.801211351989418

Epoch: 5| Step: 9
Training loss: 2.534473419189453
Validation loss: 2.7982928291443856

Epoch: 5| Step: 10
Training loss: 2.9375362396240234
Validation loss: 2.7954239230002127

Epoch: 39| Step: 0
Training loss: 2.79494047164917
Validation loss: 2.7973700697704027

Epoch: 5| Step: 1
Training loss: 3.1382498741149902
Validation loss: 2.7983320836097962

Epoch: 5| Step: 2
Training loss: 2.6735222339630127
Validation loss: 2.7930031053481565

Epoch: 5| Step: 3
Training loss: 2.674593210220337
Validation loss: 2.7940476530341694

Epoch: 5| Step: 4
Training loss: 3.063591241836548
Validation loss: 2.791913773423882

Epoch: 5| Step: 5
Training loss: 2.635113000869751
Validation loss: 2.7901243317511772

Epoch: 5| Step: 6
Training loss: 3.2353835105895996
Validation loss: 2.7941690798728698

Epoch: 5| Step: 7
Training loss: 3.195235013961792
Validation loss: 2.7975098086941625

Epoch: 5| Step: 8
Training loss: 2.92374587059021
Validation loss: 2.7924143652762137

Epoch: 5| Step: 9
Training loss: 3.245328426361084
Validation loss: 2.7932065379235054

Epoch: 5| Step: 10
Training loss: 2.515626907348633
Validation loss: 2.783164301226216

Epoch: 40| Step: 0
Training loss: 2.5163509845733643
Validation loss: 2.784993710056428

Epoch: 5| Step: 1
Training loss: 3.531196117401123
Validation loss: 2.780821689995386

Epoch: 5| Step: 2
Training loss: 2.2718238830566406
Validation loss: 2.7813990039210164

Epoch: 5| Step: 3
Training loss: 3.110483169555664
Validation loss: 2.7789095140272573

Epoch: 5| Step: 4
Training loss: 2.9164018630981445
Validation loss: 2.7828834620855187

Epoch: 5| Step: 5
Training loss: 3.538221836090088
Validation loss: 2.778673743688932

Epoch: 5| Step: 6
Training loss: 2.7412915229797363
Validation loss: 2.7756484426477903

Epoch: 5| Step: 7
Training loss: 3.4705066680908203
Validation loss: 2.768361832505913

Epoch: 5| Step: 8
Training loss: 2.687534809112549
Validation loss: 2.755070363321612

Epoch: 5| Step: 9
Training loss: 2.599853038787842
Validation loss: 2.7554221101986465

Epoch: 5| Step: 10
Training loss: 2.6203649044036865
Validation loss: 2.7465339501698813

Epoch: 41| Step: 0
Training loss: 3.1153130531311035
Validation loss: 2.752941231573782

Epoch: 5| Step: 1
Training loss: 3.0210604667663574
Validation loss: 2.7256454626719155

Epoch: 5| Step: 2
Training loss: 3.0864040851593018
Validation loss: 2.7277161998133503

Epoch: 5| Step: 3
Training loss: 3.2340564727783203
Validation loss: 2.737541211548672

Epoch: 5| Step: 4
Training loss: 2.962246894836426
Validation loss: 2.7540164788564048

Epoch: 5| Step: 5
Training loss: 2.248889923095703
Validation loss: 2.7734792386331866

Epoch: 5| Step: 6
Training loss: 2.4468541145324707
Validation loss: 2.7899625352633897

Epoch: 5| Step: 7
Training loss: 2.967078685760498
Validation loss: 2.745513639142436

Epoch: 5| Step: 8
Training loss: 2.7103452682495117
Validation loss: 2.736890903083227

Epoch: 5| Step: 9
Training loss: 2.6967315673828125
Validation loss: 2.763439886031612

Epoch: 5| Step: 10
Training loss: 3.553851366043091
Validation loss: 2.7861257073699788

Epoch: 42| Step: 0
Training loss: 3.4294369220733643
Validation loss: 2.790274607237949

Epoch: 5| Step: 1
Training loss: 2.844870090484619
Validation loss: 2.773825850538028

Epoch: 5| Step: 2
Training loss: 2.752141237258911
Validation loss: 2.764192658085977

Epoch: 5| Step: 3
Training loss: 2.6170597076416016
Validation loss: 2.7719722306856545

Epoch: 5| Step: 4
Training loss: 3.801046848297119
Validation loss: 2.756969851832236

Epoch: 5| Step: 5
Training loss: 2.5177125930786133
Validation loss: 2.7214782340552217

Epoch: 5| Step: 6
Training loss: 2.104642391204834
Validation loss: 2.7218652156091507

Epoch: 5| Step: 7
Training loss: 2.664313316345215
Validation loss: 2.72125147491373

Epoch: 5| Step: 8
Training loss: 3.3149871826171875
Validation loss: 2.7235289568542154

Epoch: 5| Step: 9
Training loss: 2.7787246704101562
Validation loss: 2.722043555269959

Epoch: 5| Step: 10
Training loss: 3.034921646118164
Validation loss: 2.7241949881276777

Epoch: 43| Step: 0
Training loss: 3.7393603324890137
Validation loss: 2.7223923155056533

Epoch: 5| Step: 1
Training loss: 3.107443332672119
Validation loss: 2.720510757097634

Epoch: 5| Step: 2
Training loss: 3.151205539703369
Validation loss: 2.7216272507944415

Epoch: 5| Step: 3
Training loss: 2.9506287574768066
Validation loss: 2.747480733420259

Epoch: 5| Step: 4
Training loss: 2.8518030643463135
Validation loss: 2.7818220379532024

Epoch: 5| Step: 5
Training loss: 2.9216225147247314
Validation loss: 2.7908442763872046

Epoch: 5| Step: 6
Training loss: 3.5873756408691406
Validation loss: 2.7833481629689536

Epoch: 5| Step: 7
Training loss: 2.2729005813598633
Validation loss: 2.7997916975329

Epoch: 5| Step: 8
Training loss: 3.1244399547576904
Validation loss: 2.8055971437884915

Epoch: 5| Step: 9
Training loss: 1.934645414352417
Validation loss: 2.785065914994927

Epoch: 5| Step: 10
Training loss: 2.1680562496185303
Validation loss: 2.7814187054993003

Epoch: 44| Step: 0
Training loss: 3.2971301078796387
Validation loss: 2.787822610588484

Epoch: 5| Step: 1
Training loss: 2.2372994422912598
Validation loss: 2.790665908526349

Epoch: 5| Step: 2
Training loss: 2.835294246673584
Validation loss: 2.7854167902341453

Epoch: 5| Step: 3
Training loss: 3.186851978302002
Validation loss: 2.7701817661203365

Epoch: 5| Step: 4
Training loss: 2.9996838569641113
Validation loss: 2.7570711002554944

Epoch: 5| Step: 5
Training loss: 3.035534381866455
Validation loss: 2.7565635378642748

Epoch: 5| Step: 6
Training loss: 2.7845406532287598
Validation loss: 2.7599171412888395

Epoch: 5| Step: 7
Training loss: 2.73504900932312
Validation loss: 2.767132935985442

Epoch: 5| Step: 8
Training loss: 2.3721303939819336
Validation loss: 2.7592009934045936

Epoch: 5| Step: 9
Training loss: 2.6848902702331543
Validation loss: 2.756111847457065

Epoch: 5| Step: 10
Training loss: 4.021456718444824
Validation loss: 2.7607610097495456

Epoch: 45| Step: 0
Training loss: 2.511913299560547
Validation loss: 2.760801963908698

Epoch: 5| Step: 1
Training loss: 3.3907275199890137
Validation loss: 2.757128115623228

Epoch: 5| Step: 2
Training loss: 2.3665146827697754
Validation loss: 2.7623080181819137

Epoch: 5| Step: 3
Training loss: 3.541764736175537
Validation loss: 2.756431761608329

Epoch: 5| Step: 4
Training loss: 2.267821788787842
Validation loss: 2.7582489136726625

Epoch: 5| Step: 5
Training loss: 2.4954679012298584
Validation loss: 2.7621612600100938

Epoch: 5| Step: 6
Training loss: 3.1443099975585938
Validation loss: 2.7726126768255748

Epoch: 5| Step: 7
Training loss: 3.241891860961914
Validation loss: 2.768373353506929

Epoch: 5| Step: 8
Training loss: 2.54331111907959
Validation loss: 2.7719984105838242

Epoch: 5| Step: 9
Training loss: 3.288928508758545
Validation loss: 2.786495695831955

Epoch: 5| Step: 10
Training loss: 3.1052284240722656
Validation loss: 2.7790174432980117

Epoch: 46| Step: 0
Training loss: 3.0746970176696777
Validation loss: 2.770059016443068

Epoch: 5| Step: 1
Training loss: 2.7517600059509277
Validation loss: 2.7714243550454416

Epoch: 5| Step: 2
Training loss: 3.0204710960388184
Validation loss: 2.7639896151840047

Epoch: 5| Step: 3
Training loss: 3.4887688159942627
Validation loss: 2.7577694436555267

Epoch: 5| Step: 4
Training loss: 2.9531054496765137
Validation loss: 2.7531865463461926

Epoch: 5| Step: 5
Training loss: 3.399911403656006
Validation loss: 2.7523215970685406

Epoch: 5| Step: 6
Training loss: 2.3130013942718506
Validation loss: 2.753060089644565

Epoch: 5| Step: 7
Training loss: 2.4765539169311523
Validation loss: 2.750539518171741

Epoch: 5| Step: 8
Training loss: 2.646002769470215
Validation loss: 2.7476434348731913

Epoch: 5| Step: 9
Training loss: 2.7582974433898926
Validation loss: 2.7415889001661733

Epoch: 5| Step: 10
Training loss: 2.896223545074463
Validation loss: 2.745935619518321

Epoch: 47| Step: 0
Training loss: 3.5157246589660645
Validation loss: 2.736870722104144

Epoch: 5| Step: 1
Training loss: 3.0051698684692383
Validation loss: 2.730240398837674

Epoch: 5| Step: 2
Training loss: 2.8062682151794434
Validation loss: 2.7224191952777166

Epoch: 5| Step: 3
Training loss: 2.8312995433807373
Validation loss: 2.7012067584581274

Epoch: 5| Step: 4
Training loss: 2.5218048095703125
Validation loss: 2.694968769627233

Epoch: 5| Step: 5
Training loss: 2.527940034866333
Validation loss: 2.6948486066633657

Epoch: 5| Step: 6
Training loss: 2.7692744731903076
Validation loss: 2.700069986363893

Epoch: 5| Step: 7
Training loss: 1.868117094039917
Validation loss: 2.697463107365434

Epoch: 5| Step: 8
Training loss: 3.6707603931427
Validation loss: 2.7007431368674

Epoch: 5| Step: 9
Training loss: 3.0808069705963135
Validation loss: 2.6979286388684343

Epoch: 5| Step: 10
Training loss: 2.87870192527771
Validation loss: 2.6954002508553128

Epoch: 48| Step: 0
Training loss: 2.7637898921966553
Validation loss: 2.697624450088829

Epoch: 5| Step: 1
Training loss: 2.4656331539154053
Validation loss: 2.6969414910962506

Epoch: 5| Step: 2
Training loss: 2.6981358528137207
Validation loss: 2.6961365643367974

Epoch: 5| Step: 3
Training loss: 3.275196075439453
Validation loss: 2.7014621150109077

Epoch: 5| Step: 4
Training loss: 3.1064159870147705
Validation loss: 2.7212372877264537

Epoch: 5| Step: 5
Training loss: 2.490595817565918
Validation loss: 2.7112598752462738

Epoch: 5| Step: 6
Training loss: 2.754854679107666
Validation loss: 2.7007439777415287

Epoch: 5| Step: 7
Training loss: 3.0656323432922363
Validation loss: 2.694354218821372

Epoch: 5| Step: 8
Training loss: 3.023135185241699
Validation loss: 2.691874140052385

Epoch: 5| Step: 9
Training loss: 2.9336025714874268
Validation loss: 2.6873401006062827

Epoch: 5| Step: 10
Training loss: 2.7658493518829346
Validation loss: 2.6854093151707805

Epoch: 49| Step: 0
Training loss: 2.682079792022705
Validation loss: 2.6847748730772283

Epoch: 5| Step: 1
Training loss: 2.3776190280914307
Validation loss: 2.685553220010573

Epoch: 5| Step: 2
Training loss: 2.33685040473938
Validation loss: 2.6904034999109085

Epoch: 5| Step: 3
Training loss: 2.784327268600464
Validation loss: 2.6876114619675504

Epoch: 5| Step: 4
Training loss: 2.544668674468994
Validation loss: 2.6873227960319928

Epoch: 5| Step: 5
Training loss: 2.873810291290283
Validation loss: 2.682218413199148

Epoch: 5| Step: 6
Training loss: 3.371138095855713
Validation loss: 2.6874166419429164

Epoch: 5| Step: 7
Training loss: 3.207578182220459
Validation loss: 2.691938192613663

Epoch: 5| Step: 8
Training loss: 2.35819935798645
Validation loss: 2.697246782241329

Epoch: 5| Step: 9
Training loss: 3.8915343284606934
Validation loss: 2.7034589731565086

Epoch: 5| Step: 10
Training loss: 2.838252544403076
Validation loss: 2.700721622795187

Epoch: 50| Step: 0
Training loss: 3.1375226974487305
Validation loss: 2.682337655816027

Epoch: 5| Step: 1
Training loss: 3.634526014328003
Validation loss: 2.6815107791654524

Epoch: 5| Step: 2
Training loss: 3.1556191444396973
Validation loss: 2.679907944894606

Epoch: 5| Step: 3
Training loss: 2.7807624340057373
Validation loss: 2.6804091315115652

Epoch: 5| Step: 4
Training loss: 2.3519649505615234
Validation loss: 2.682993399199619

Epoch: 5| Step: 5
Training loss: 2.1518898010253906
Validation loss: 2.6825492202594714

Epoch: 5| Step: 6
Training loss: 3.3211727142333984
Validation loss: 2.6819294575721986

Epoch: 5| Step: 7
Training loss: 2.4377942085266113
Validation loss: 2.6775806924348236

Epoch: 5| Step: 8
Training loss: 2.879927396774292
Validation loss: 2.674911134986467

Epoch: 5| Step: 9
Training loss: 3.118293523788452
Validation loss: 2.6797017358964488

Epoch: 5| Step: 10
Training loss: 2.1285600662231445
Validation loss: 2.6763852847519742

Epoch: 51| Step: 0
Training loss: 2.7549636363983154
Validation loss: 2.673127233341176

Epoch: 5| Step: 1
Training loss: 2.7592015266418457
Validation loss: 2.678466732783984

Epoch: 5| Step: 2
Training loss: 3.242628812789917
Validation loss: 2.6770967719375447

Epoch: 5| Step: 3
Training loss: 3.1166086196899414
Validation loss: 2.684618126961493

Epoch: 5| Step: 4
Training loss: 3.1563820838928223
Validation loss: 2.6805282177463656

Epoch: 5| Step: 5
Training loss: 2.9903512001037598
Validation loss: 2.6851537612176712

Epoch: 5| Step: 6
Training loss: 3.5277819633483887
Validation loss: 2.6788914870190363

Epoch: 5| Step: 7
Training loss: 2.059568405151367
Validation loss: 2.6744492028349187

Epoch: 5| Step: 8
Training loss: 2.2842869758605957
Validation loss: 2.6726570180667344

Epoch: 5| Step: 9
Training loss: 2.2055068016052246
Validation loss: 2.6684016207213044

Epoch: 5| Step: 10
Training loss: 3.0554261207580566
Validation loss: 2.6750619385832097

Epoch: 52| Step: 0
Training loss: 2.972659111022949
Validation loss: 2.6738676409567557

Epoch: 5| Step: 1
Training loss: 3.708069324493408
Validation loss: 2.6712087251806773

Epoch: 5| Step: 2
Training loss: 2.9605090618133545
Validation loss: 2.6713243581915416

Epoch: 5| Step: 3
Training loss: 3.1503448486328125
Validation loss: 2.672749642402895

Epoch: 5| Step: 4
Training loss: 2.394423246383667
Validation loss: 2.6722173818977932

Epoch: 5| Step: 5
Training loss: 2.7991254329681396
Validation loss: 2.6774278379255727

Epoch: 5| Step: 6
Training loss: 1.8326585292816162
Validation loss: 2.680464765076996

Epoch: 5| Step: 7
Training loss: 3.180112361907959
Validation loss: 2.6735116768908758

Epoch: 5| Step: 8
Training loss: 2.889751434326172
Validation loss: 2.669071187255203

Epoch: 5| Step: 9
Training loss: 2.904113292694092
Validation loss: 2.6727056016204176

Epoch: 5| Step: 10
Training loss: 2.198730707168579
Validation loss: 2.6796676625487623

Epoch: 53| Step: 0
Training loss: 3.5158374309539795
Validation loss: 2.6839874098377843

Epoch: 5| Step: 1
Training loss: 2.8873610496520996
Validation loss: 2.690054298729025

Epoch: 5| Step: 2
Training loss: 2.765465497970581
Validation loss: 2.70969303705359

Epoch: 5| Step: 3
Training loss: 3.03749418258667
Validation loss: 2.7101690717922744

Epoch: 5| Step: 4
Training loss: 2.629425048828125
Validation loss: 2.739765631255283

Epoch: 5| Step: 5
Training loss: 3.0040886402130127
Validation loss: 2.7130914349709787

Epoch: 5| Step: 6
Training loss: 2.871293544769287
Validation loss: 2.676938843983476

Epoch: 5| Step: 7
Training loss: 3.0739617347717285
Validation loss: 2.663243844944944

Epoch: 5| Step: 8
Training loss: 2.546551465988159
Validation loss: 2.67086003416328

Epoch: 5| Step: 9
Training loss: 2.5873656272888184
Validation loss: 2.6819603571327786

Epoch: 5| Step: 10
Training loss: 2.3024203777313232
Validation loss: 2.702303073739493

Epoch: 54| Step: 0
Training loss: 2.191967725753784
Validation loss: 2.720986350890129

Epoch: 5| Step: 1
Training loss: 3.0971691608428955
Validation loss: 2.7302075919284614

Epoch: 5| Step: 2
Training loss: 3.4812088012695312
Validation loss: 2.7086235682169595

Epoch: 5| Step: 3
Training loss: 2.730531692504883
Validation loss: 2.6929361410038446

Epoch: 5| Step: 4
Training loss: 3.2488396167755127
Validation loss: 2.6702206903888333

Epoch: 5| Step: 5
Training loss: 2.6863481998443604
Validation loss: 2.657740093046619

Epoch: 5| Step: 6
Training loss: 2.0326781272888184
Validation loss: 2.6617978029353644

Epoch: 5| Step: 7
Training loss: 2.9061806201934814
Validation loss: 2.6646769226238294

Epoch: 5| Step: 8
Training loss: 2.4811527729034424
Validation loss: 2.67406657690643

Epoch: 5| Step: 9
Training loss: 3.636317014694214
Validation loss: 2.690514797805458

Epoch: 5| Step: 10
Training loss: 2.7302398681640625
Validation loss: 2.688477736647411

Epoch: 55| Step: 0
Training loss: 2.5019469261169434
Validation loss: 2.697571059708954

Epoch: 5| Step: 1
Training loss: 3.1888797283172607
Validation loss: 2.6808284841557986

Epoch: 5| Step: 2
Training loss: 2.9621024131774902
Validation loss: 2.6687526651608047

Epoch: 5| Step: 3
Training loss: 2.6469359397888184
Validation loss: 2.660700915962137

Epoch: 5| Step: 4
Training loss: 2.865264654159546
Validation loss: 2.655413027732603

Epoch: 5| Step: 5
Training loss: 2.2642502784729004
Validation loss: 2.6547087700136247

Epoch: 5| Step: 6
Training loss: 2.524714946746826
Validation loss: 2.652184941435373

Epoch: 5| Step: 7
Training loss: 2.9368667602539062
Validation loss: 2.651289642498057

Epoch: 5| Step: 8
Training loss: 2.9492485523223877
Validation loss: 2.6525364998848207

Epoch: 5| Step: 9
Training loss: 3.591059923171997
Validation loss: 2.653457034018732

Epoch: 5| Step: 10
Training loss: 2.582534074783325
Validation loss: 2.651764521034815

Epoch: 56| Step: 0
Training loss: 3.233050584793091
Validation loss: 2.6484963945163194

Epoch: 5| Step: 1
Training loss: 2.3507239818573
Validation loss: 2.6484801974347842

Epoch: 5| Step: 2
Training loss: 1.9987090826034546
Validation loss: 2.6470268234129875

Epoch: 5| Step: 3
Training loss: 2.5350584983825684
Validation loss: 2.6498553855444795

Epoch: 5| Step: 4
Training loss: 3.260136365890503
Validation loss: 2.6465604625722414

Epoch: 5| Step: 5
Training loss: 3.1522791385650635
Validation loss: 2.6464147798476683

Epoch: 5| Step: 6
Training loss: 3.3386154174804688
Validation loss: 2.6452147729935183

Epoch: 5| Step: 7
Training loss: 2.9698681831359863
Validation loss: 2.6418294650252148

Epoch: 5| Step: 8
Training loss: 2.6810574531555176
Validation loss: 2.6364189065912718

Epoch: 5| Step: 9
Training loss: 2.788943290710449
Validation loss: 2.6365923548257477

Epoch: 5| Step: 10
Training loss: 2.517169713973999
Validation loss: 2.6333354237259075

Epoch: 57| Step: 0
Training loss: 2.84298038482666
Validation loss: 2.6343000140241397

Epoch: 5| Step: 1
Training loss: 3.178374767303467
Validation loss: 2.6373806384301957

Epoch: 5| Step: 2
Training loss: 2.1114888191223145
Validation loss: 2.6289252696498746

Epoch: 5| Step: 3
Training loss: 3.124795436859131
Validation loss: 2.6306147524105605

Epoch: 5| Step: 4
Training loss: 2.4466681480407715
Validation loss: 2.627822114575294

Epoch: 5| Step: 5
Training loss: 2.701234817504883
Validation loss: 2.627200318920997

Epoch: 5| Step: 6
Training loss: 2.8743820190429688
Validation loss: 2.624765150008663

Epoch: 5| Step: 7
Training loss: 3.2357382774353027
Validation loss: 2.62389305586456

Epoch: 5| Step: 8
Training loss: 3.1716086864471436
Validation loss: 2.625064003852106

Epoch: 5| Step: 9
Training loss: 1.925718903541565
Validation loss: 2.622226579214937

Epoch: 5| Step: 10
Training loss: 3.1397743225097656
Validation loss: 2.6254387414583595

Epoch: 58| Step: 0
Training loss: 2.3894248008728027
Validation loss: 2.6243692905672136

Epoch: 5| Step: 1
Training loss: 2.883281707763672
Validation loss: 2.623876097381756

Epoch: 5| Step: 2
Training loss: 2.5343477725982666
Validation loss: 2.6220031399880686

Epoch: 5| Step: 3
Training loss: 2.866344451904297
Validation loss: 2.6227353798445834

Epoch: 5| Step: 4
Training loss: 2.988999843597412
Validation loss: 2.6175498013855307

Epoch: 5| Step: 5
Training loss: 3.230060577392578
Validation loss: 2.614949744234803

Epoch: 5| Step: 6
Training loss: 2.5371804237365723
Validation loss: 2.618802801255257

Epoch: 5| Step: 7
Training loss: 2.8086977005004883
Validation loss: 2.613683731325211

Epoch: 5| Step: 8
Training loss: 2.251924753189087
Validation loss: 2.6163919792380383

Epoch: 5| Step: 9
Training loss: 2.8572468757629395
Validation loss: 2.615620215733846

Epoch: 5| Step: 10
Training loss: 3.3778135776519775
Validation loss: 2.618640302329935

Epoch: 59| Step: 0
Training loss: 2.726616859436035
Validation loss: 2.6173072348358812

Epoch: 5| Step: 1
Training loss: 2.4888577461242676
Validation loss: 2.6152359054934595

Epoch: 5| Step: 2
Training loss: 3.3035788536071777
Validation loss: 2.612679766070458

Epoch: 5| Step: 3
Training loss: 2.584321975708008
Validation loss: 2.6055514017740884

Epoch: 5| Step: 4
Training loss: 2.4098572731018066
Validation loss: 2.6059509913126626

Epoch: 5| Step: 5
Training loss: 2.864009141921997
Validation loss: 2.607881035856021

Epoch: 5| Step: 6
Training loss: 3.077111005783081
Validation loss: 2.6083424757885676

Epoch: 5| Step: 7
Training loss: 2.2906813621520996
Validation loss: 2.609449017432428

Epoch: 5| Step: 8
Training loss: 2.7807157039642334
Validation loss: 2.609337668265066

Epoch: 5| Step: 9
Training loss: 3.1080708503723145
Validation loss: 2.6082903646653697

Epoch: 5| Step: 10
Training loss: 2.9808194637298584
Validation loss: 2.6093767689120386

Epoch: 60| Step: 0
Training loss: 3.0421395301818848
Validation loss: 2.6068613503568914

Epoch: 5| Step: 1
Training loss: 2.557203769683838
Validation loss: 2.6065672392486245

Epoch: 5| Step: 2
Training loss: 2.0363690853118896
Validation loss: 2.6078248229078067

Epoch: 5| Step: 3
Training loss: 2.979518175125122
Validation loss: 2.609404904868013

Epoch: 5| Step: 4
Training loss: 3.1332249641418457
Validation loss: 2.6111231029674573

Epoch: 5| Step: 5
Training loss: 2.5490036010742188
Validation loss: 2.611896631538227

Epoch: 5| Step: 6
Training loss: 3.17883038520813
Validation loss: 2.6122515432296263

Epoch: 5| Step: 7
Training loss: 2.78665828704834
Validation loss: 2.608602739149524

Epoch: 5| Step: 8
Training loss: 3.1586337089538574
Validation loss: 2.61289644241333

Epoch: 5| Step: 9
Training loss: 2.5174124240875244
Validation loss: 2.614962790601997

Epoch: 5| Step: 10
Training loss: 2.605059862136841
Validation loss: 2.6041488826915784

Epoch: 61| Step: 0
Training loss: 3.4234631061553955
Validation loss: 2.600145291256648

Epoch: 5| Step: 1
Training loss: 2.1538186073303223
Validation loss: 2.599983589623564

Epoch: 5| Step: 2
Training loss: 3.0668022632598877
Validation loss: 2.6013342718924246

Epoch: 5| Step: 3
Training loss: 1.9657013416290283
Validation loss: 2.6025507629558606

Epoch: 5| Step: 4
Training loss: 2.8070178031921387
Validation loss: 2.600494087383311

Epoch: 5| Step: 5
Training loss: 3.472867965698242
Validation loss: 2.60044966718202

Epoch: 5| Step: 6
Training loss: 2.9751241207122803
Validation loss: 2.5926384695114626

Epoch: 5| Step: 7
Training loss: 2.7073657512664795
Validation loss: 2.5959485371907554

Epoch: 5| Step: 8
Training loss: 3.232570171356201
Validation loss: 2.598817979135821

Epoch: 5| Step: 9
Training loss: 2.4860498905181885
Validation loss: 2.5967723887453795

Epoch: 5| Step: 10
Training loss: 2.1965579986572266
Validation loss: 2.6009458752088648

Epoch: 62| Step: 0
Training loss: 3.018510341644287
Validation loss: 2.5897236857362973

Epoch: 5| Step: 1
Training loss: 3.175607442855835
Validation loss: 2.590772121183334

Epoch: 5| Step: 2
Training loss: 2.51598858833313
Validation loss: 2.5863740341637724

Epoch: 5| Step: 3
Training loss: 2.7030458450317383
Validation loss: 2.585841950549874

Epoch: 5| Step: 4
Training loss: 2.503200054168701
Validation loss: 2.583654724141603

Epoch: 5| Step: 5
Training loss: 3.4174866676330566
Validation loss: 2.5838070838682112

Epoch: 5| Step: 6
Training loss: 2.5441088676452637
Validation loss: 2.584136352744154

Epoch: 5| Step: 7
Training loss: 2.6491055488586426
Validation loss: 2.583495955313406

Epoch: 5| Step: 8
Training loss: 2.870772123336792
Validation loss: 2.580526846711354

Epoch: 5| Step: 9
Training loss: 2.825401782989502
Validation loss: 2.580424988141624

Epoch: 5| Step: 10
Training loss: 2.0406978130340576
Validation loss: 2.5783346519675305

Epoch: 63| Step: 0
Training loss: 3.1112160682678223
Validation loss: 2.575390295315814

Epoch: 5| Step: 1
Training loss: 3.6589150428771973
Validation loss: 2.578650871912638

Epoch: 5| Step: 2
Training loss: 2.535268783569336
Validation loss: 2.578575436786939

Epoch: 5| Step: 3
Training loss: 2.276545524597168
Validation loss: 2.575424999319097

Epoch: 5| Step: 4
Training loss: 2.404717206954956
Validation loss: 2.5746313141238306

Epoch: 5| Step: 5
Training loss: 3.0285561084747314
Validation loss: 2.5786488594547397

Epoch: 5| Step: 6
Training loss: 2.0322318077087402
Validation loss: 2.57837341677758

Epoch: 5| Step: 7
Training loss: 2.66447377204895
Validation loss: 2.5781341316879436

Epoch: 5| Step: 8
Training loss: 2.3919003009796143
Validation loss: 2.578074565497778

Epoch: 5| Step: 9
Training loss: 3.160881519317627
Validation loss: 2.57263732212846

Epoch: 5| Step: 10
Training loss: 3.100520372390747
Validation loss: 2.570339613063361

Epoch: 64| Step: 0
Training loss: 3.4262022972106934
Validation loss: 2.5720545412391744

Epoch: 5| Step: 1
Training loss: 2.6671175956726074
Validation loss: 2.573648193831085

Epoch: 5| Step: 2
Training loss: 2.859255075454712
Validation loss: 2.5725460334490706

Epoch: 5| Step: 3
Training loss: 2.9893970489501953
Validation loss: 2.5717036749726985

Epoch: 5| Step: 4
Training loss: 2.3139991760253906
Validation loss: 2.5678576346366637

Epoch: 5| Step: 5
Training loss: 2.409618854522705
Validation loss: 2.571355317228584

Epoch: 5| Step: 6
Training loss: 3.313457489013672
Validation loss: 2.5711137402442192

Epoch: 5| Step: 7
Training loss: 2.219174861907959
Validation loss: 2.5743544640079623

Epoch: 5| Step: 8
Training loss: 3.60369610786438
Validation loss: 2.579237291889806

Epoch: 5| Step: 9
Training loss: 2.407059669494629
Validation loss: 2.5816826743464314

Epoch: 5| Step: 10
Training loss: 1.9174975156784058
Validation loss: 2.5831131601846344

Epoch: 65| Step: 0
Training loss: 2.7988877296447754
Validation loss: 2.595206117117277

Epoch: 5| Step: 1
Training loss: 2.5614027976989746
Validation loss: 2.5866101147026144

Epoch: 5| Step: 2
Training loss: 2.987478733062744
Validation loss: 2.57981619527263

Epoch: 5| Step: 3
Training loss: 1.468907117843628
Validation loss: 2.5781214032121884

Epoch: 5| Step: 4
Training loss: 2.7947428226470947
Validation loss: 2.5745067775890393

Epoch: 5| Step: 5
Training loss: 2.5045225620269775
Validation loss: 2.5698502486751926

Epoch: 5| Step: 6
Training loss: 3.3450469970703125
Validation loss: 2.5663835028166413

Epoch: 5| Step: 7
Training loss: 2.599189281463623
Validation loss: 2.5643805560245307

Epoch: 5| Step: 8
Training loss: 3.456146240234375
Validation loss: 2.5653513836604294

Epoch: 5| Step: 9
Training loss: 2.8043324947357178
Validation loss: 2.56723928195174

Epoch: 5| Step: 10
Training loss: 2.994428873062134
Validation loss: 2.566152557249992

Epoch: 66| Step: 0
Training loss: 2.7124993801116943
Validation loss: 2.56212124388705

Epoch: 5| Step: 1
Training loss: 1.9057655334472656
Validation loss: 2.562542797416769

Epoch: 5| Step: 2
Training loss: 3.0395944118499756
Validation loss: 2.566632165703722

Epoch: 5| Step: 3
Training loss: 2.317478895187378
Validation loss: 2.5687065252693753

Epoch: 5| Step: 4
Training loss: 3.0372910499572754
Validation loss: 2.5677857283622987

Epoch: 5| Step: 5
Training loss: 2.7444770336151123
Validation loss: 2.566501207249139

Epoch: 5| Step: 6
Training loss: 3.290947675704956
Validation loss: 2.5676102561335408

Epoch: 5| Step: 7
Training loss: 2.937584638595581
Validation loss: 2.5640311215513494

Epoch: 5| Step: 8
Training loss: 3.2395331859588623
Validation loss: 2.5601918492265927

Epoch: 5| Step: 9
Training loss: 2.240996837615967
Validation loss: 2.561389797477312

Epoch: 5| Step: 10
Training loss: 2.7144622802734375
Validation loss: 2.5624597995511946

Epoch: 67| Step: 0
Training loss: 2.4227383136749268
Validation loss: 2.5586781117223922

Epoch: 5| Step: 1
Training loss: 2.79315185546875
Validation loss: 2.559378185579854

Epoch: 5| Step: 2
Training loss: 2.7770628929138184
Validation loss: 2.5573858061144428

Epoch: 5| Step: 3
Training loss: 2.6291863918304443
Validation loss: 2.558624057359593

Epoch: 5| Step: 4
Training loss: 2.501997709274292
Validation loss: 2.5615834010544645

Epoch: 5| Step: 5
Training loss: 2.6656858921051025
Validation loss: 2.5601786695500857

Epoch: 5| Step: 6
Training loss: 2.698749542236328
Validation loss: 2.558285661922988

Epoch: 5| Step: 7
Training loss: 3.551469326019287
Validation loss: 2.5627312608944472

Epoch: 5| Step: 8
Training loss: 2.572465419769287
Validation loss: 2.5612922355692875

Epoch: 5| Step: 9
Training loss: 2.9947049617767334
Validation loss: 2.5640004501547864

Epoch: 5| Step: 10
Training loss: 2.5296239852905273
Validation loss: 2.569541549169889

Epoch: 68| Step: 0
Training loss: 3.3160953521728516
Validation loss: 2.566223300913329

Epoch: 5| Step: 1
Training loss: 2.90272855758667
Validation loss: 2.562903481145059

Epoch: 5| Step: 2
Training loss: 3.297381639480591
Validation loss: 2.5580098705907024

Epoch: 5| Step: 3
Training loss: 2.5325253009796143
Validation loss: 2.5568801126172467

Epoch: 5| Step: 4
Training loss: 2.6126036643981934
Validation loss: 2.55408146560833

Epoch: 5| Step: 5
Training loss: 2.5639376640319824
Validation loss: 2.554437411728726

Epoch: 5| Step: 6
Training loss: 2.268014430999756
Validation loss: 2.552378803171137

Epoch: 5| Step: 7
Training loss: 2.8012192249298096
Validation loss: 2.553619356565578

Epoch: 5| Step: 8
Training loss: 3.3587327003479004
Validation loss: 2.5528500336472706

Epoch: 5| Step: 9
Training loss: 1.9430078268051147
Validation loss: 2.5542817449056976

Epoch: 5| Step: 10
Training loss: 2.5289371013641357
Validation loss: 2.5568630413342546

Epoch: 69| Step: 0
Training loss: 3.1794567108154297
Validation loss: 2.5597859223683677

Epoch: 5| Step: 1
Training loss: 3.5284759998321533
Validation loss: 2.5602781926431963

Epoch: 5| Step: 2
Training loss: 2.5086910724639893
Validation loss: 2.5677451882311093

Epoch: 5| Step: 3
Training loss: 2.6241023540496826
Validation loss: 2.576891529944635

Epoch: 5| Step: 4
Training loss: 2.3184268474578857
Validation loss: 2.5736390518885788

Epoch: 5| Step: 5
Training loss: 3.2302043437957764
Validation loss: 2.5753503922493226

Epoch: 5| Step: 6
Training loss: 2.4687037467956543
Validation loss: 2.570745386103148

Epoch: 5| Step: 7
Training loss: 2.5411856174468994
Validation loss: 2.5691647709056897

Epoch: 5| Step: 8
Training loss: 2.2697174549102783
Validation loss: 2.559058961047921

Epoch: 5| Step: 9
Training loss: 2.7347412109375
Validation loss: 2.5536196334387666

Epoch: 5| Step: 10
Training loss: 2.7398180961608887
Validation loss: 2.5511038021374772

Epoch: 70| Step: 0
Training loss: 2.9607810974121094
Validation loss: 2.557172765013992

Epoch: 5| Step: 1
Training loss: 3.2198894023895264
Validation loss: 2.5552248826590915

Epoch: 5| Step: 2
Training loss: 3.773560047149658
Validation loss: 2.5607678941501084

Epoch: 5| Step: 3
Training loss: 2.3738789558410645
Validation loss: 2.5549780681569088

Epoch: 5| Step: 4
Training loss: 3.0241355895996094
Validation loss: 2.551307198821857

Epoch: 5| Step: 5
Training loss: 2.4557297229766846
Validation loss: 2.550751632259738

Epoch: 5| Step: 6
Training loss: 2.1683876514434814
Validation loss: 2.552658204109438

Epoch: 5| Step: 7
Training loss: 2.398695468902588
Validation loss: 2.5525538895719793

Epoch: 5| Step: 8
Training loss: 2.9277663230895996
Validation loss: 2.5573790457940873

Epoch: 5| Step: 9
Training loss: 2.2753779888153076
Validation loss: 2.5603279157351424

Epoch: 5| Step: 10
Training loss: 2.47113299369812
Validation loss: 2.5774432202821136

Epoch: 71| Step: 0
Training loss: 2.40024995803833
Validation loss: 2.570923800109535

Epoch: 5| Step: 1
Training loss: 2.6339163780212402
Validation loss: 2.5538943108691963

Epoch: 5| Step: 2
Training loss: 2.843663454055786
Validation loss: 2.5445716406709407

Epoch: 5| Step: 3
Training loss: 3.365126371383667
Validation loss: 2.543847914664976

Epoch: 5| Step: 4
Training loss: 2.983358144760132
Validation loss: 2.5450016016601236

Epoch: 5| Step: 5
Training loss: 1.872450590133667
Validation loss: 2.5460411451196157

Epoch: 5| Step: 6
Training loss: 3.0373892784118652
Validation loss: 2.560263585018855

Epoch: 5| Step: 7
Training loss: 2.4353108406066895
Validation loss: 2.5805812522929203

Epoch: 5| Step: 8
Training loss: 3.227930784225464
Validation loss: 2.5753646435276156

Epoch: 5| Step: 9
Training loss: 2.6289374828338623
Validation loss: 2.553969544749106

Epoch: 5| Step: 10
Training loss: 2.7607014179229736
Validation loss: 2.547470418355798

Epoch: 72| Step: 0
Training loss: 3.2017712593078613
Validation loss: 2.5444137844988095

Epoch: 5| Step: 1
Training loss: 2.824615955352783
Validation loss: 2.539160354163057

Epoch: 5| Step: 2
Training loss: 3.102182626724243
Validation loss: 2.539237447964248

Epoch: 5| Step: 3
Training loss: 1.7513246536254883
Validation loss: 2.547492801502187

Epoch: 5| Step: 4
Training loss: 2.249882698059082
Validation loss: 2.5567000553172123

Epoch: 5| Step: 5
Training loss: 2.447711706161499
Validation loss: 2.5716109378363496

Epoch: 5| Step: 6
Training loss: 2.8726446628570557
Validation loss: 2.5975784588885564

Epoch: 5| Step: 7
Training loss: 2.911665439605713
Validation loss: 2.573104891725766

Epoch: 5| Step: 8
Training loss: 2.777600049972534
Validation loss: 2.559056205134238

Epoch: 5| Step: 9
Training loss: 2.820997476577759
Validation loss: 2.543689843147032

Epoch: 5| Step: 10
Training loss: 3.2603139877319336
Validation loss: 2.5498719164120254

Epoch: 73| Step: 0
Training loss: 2.570160388946533
Validation loss: 2.538066884522797

Epoch: 5| Step: 1
Training loss: 2.832594394683838
Validation loss: 2.533658566013459

Epoch: 5| Step: 2
Training loss: 2.5222814083099365
Validation loss: 2.532734235127767

Epoch: 5| Step: 3
Training loss: 2.436829090118408
Validation loss: 2.5327981248978646

Epoch: 5| Step: 4
Training loss: 2.65299391746521
Validation loss: 2.53576172039073

Epoch: 5| Step: 5
Training loss: 2.244070053100586
Validation loss: 2.5331125054308163

Epoch: 5| Step: 6
Training loss: 1.681173324584961
Validation loss: 2.5322085042153635

Epoch: 5| Step: 7
Training loss: 3.380629301071167
Validation loss: 2.5458924539627565

Epoch: 5| Step: 8
Training loss: 3.508831024169922
Validation loss: 2.55937454008287

Epoch: 5| Step: 9
Training loss: 2.996579647064209
Validation loss: 2.5593935622963855

Epoch: 5| Step: 10
Training loss: 3.281341075897217
Validation loss: 2.556167335920436

Epoch: 74| Step: 0
Training loss: 3.4024531841278076
Validation loss: 2.5468804323545067

Epoch: 5| Step: 1
Training loss: 2.6962311267852783
Validation loss: 2.5376732426304973

Epoch: 5| Step: 2
Training loss: 2.697855234146118
Validation loss: 2.529858248208159

Epoch: 5| Step: 3
Training loss: 3.20146107673645
Validation loss: 2.5310447139124714

Epoch: 5| Step: 4
Training loss: 2.3840253353118896
Validation loss: 2.5239748980409358

Epoch: 5| Step: 5
Training loss: 2.612614154815674
Validation loss: 2.5266811565686296

Epoch: 5| Step: 6
Training loss: 3.2029190063476562
Validation loss: 2.526771435173609

Epoch: 5| Step: 7
Training loss: 2.1080527305603027
Validation loss: 2.529115758916383

Epoch: 5| Step: 8
Training loss: 2.176969289779663
Validation loss: 2.526136262442476

Epoch: 5| Step: 9
Training loss: 2.754502296447754
Validation loss: 2.5267363684151762

Epoch: 5| Step: 10
Training loss: 2.6933276653289795
Validation loss: 2.5244801147009737

Epoch: 75| Step: 0
Training loss: 2.2902889251708984
Validation loss: 2.526397353859358

Epoch: 5| Step: 1
Training loss: 2.5798161029815674
Validation loss: 2.525863757697485

Epoch: 5| Step: 2
Training loss: 3.1490111351013184
Validation loss: 2.5285865286345124

Epoch: 5| Step: 3
Training loss: 2.6200919151306152
Validation loss: 2.5324425748599473

Epoch: 5| Step: 4
Training loss: 2.4999659061431885
Validation loss: 2.532283721431609

Epoch: 5| Step: 5
Training loss: 2.986070394515991
Validation loss: 2.538908609779932

Epoch: 5| Step: 6
Training loss: 2.4550509452819824
Validation loss: 2.545088101458806

Epoch: 5| Step: 7
Training loss: 2.830108880996704
Validation loss: 2.547939528701126

Epoch: 5| Step: 8
Training loss: 3.0778088569641113
Validation loss: 2.549091318602203

Epoch: 5| Step: 9
Training loss: 2.2477192878723145
Validation loss: 2.5414676948260237

Epoch: 5| Step: 10
Training loss: 3.237528085708618
Validation loss: 2.5347906004997993

Epoch: 76| Step: 0
Training loss: 2.7922310829162598
Validation loss: 2.530835795146163

Epoch: 5| Step: 1
Training loss: 2.727235794067383
Validation loss: 2.529126159606441

Epoch: 5| Step: 2
Training loss: 2.5877742767333984
Validation loss: 2.529016740860478

Epoch: 5| Step: 3
Training loss: 3.1169514656066895
Validation loss: 2.5251283901993946

Epoch: 5| Step: 4
Training loss: 3.1930034160614014
Validation loss: 2.5205269808410318

Epoch: 5| Step: 5
Training loss: 2.376094102859497
Validation loss: 2.520073349757861

Epoch: 5| Step: 6
Training loss: 2.3452067375183105
Validation loss: 2.520675120815154

Epoch: 5| Step: 7
Training loss: 2.6177010536193848
Validation loss: 2.523090990640784

Epoch: 5| Step: 8
Training loss: 1.924839735031128
Validation loss: 2.5214842801452964

Epoch: 5| Step: 9
Training loss: 2.837001323699951
Validation loss: 2.519656781227358

Epoch: 5| Step: 10
Training loss: 3.44522762298584
Validation loss: 2.5190475692031202

Epoch: 77| Step: 0
Training loss: 2.7081310749053955
Validation loss: 2.5209264037429646

Epoch: 5| Step: 1
Training loss: 3.0318965911865234
Validation loss: 2.5194063981374106

Epoch: 5| Step: 2
Training loss: 2.66398549079895
Validation loss: 2.521989050731864

Epoch: 5| Step: 3
Training loss: 2.660205602645874
Validation loss: 2.5196122533531597

Epoch: 5| Step: 4
Training loss: 2.8605730533599854
Validation loss: 2.5197186059849237

Epoch: 5| Step: 5
Training loss: 2.8261351585388184
Validation loss: 2.5273640360883487

Epoch: 5| Step: 6
Training loss: 2.883563995361328
Validation loss: 2.533601221217904

Epoch: 5| Step: 7
Training loss: 2.699723720550537
Validation loss: 2.5331054144008185

Epoch: 5| Step: 8
Training loss: 2.3938450813293457
Validation loss: 2.532123222145983

Epoch: 5| Step: 9
Training loss: 2.386794090270996
Validation loss: 2.52146101767017

Epoch: 5| Step: 10
Training loss: 2.721421718597412
Validation loss: 2.514424172780847

Epoch: 78| Step: 0
Training loss: 2.6291422843933105
Validation loss: 2.513419246160856

Epoch: 5| Step: 1
Training loss: 2.560391664505005
Validation loss: 2.5154881015900643

Epoch: 5| Step: 2
Training loss: 2.928781032562256
Validation loss: 2.519984619591826

Epoch: 5| Step: 3
Training loss: 3.120753765106201
Validation loss: 2.516743019062986

Epoch: 5| Step: 4
Training loss: 3.02070951461792
Validation loss: 2.5130959710767193

Epoch: 5| Step: 5
Training loss: 2.6767306327819824
Validation loss: 2.5135581467741277

Epoch: 5| Step: 6
Training loss: 2.6811015605926514
Validation loss: 2.5134910280986498

Epoch: 5| Step: 7
Training loss: 2.8681626319885254
Validation loss: 2.511671012447726

Epoch: 5| Step: 8
Training loss: 2.8882570266723633
Validation loss: 2.5168122194146596

Epoch: 5| Step: 9
Training loss: 2.3518292903900146
Validation loss: 2.51410493030343

Epoch: 5| Step: 10
Training loss: 1.9539850950241089
Validation loss: 2.517682106264176

Epoch: 79| Step: 0
Training loss: 2.082197904586792
Validation loss: 2.517478301960935

Epoch: 5| Step: 1
Training loss: 3.0695526599884033
Validation loss: 2.516880573764924

Epoch: 5| Step: 2
Training loss: 2.690392017364502
Validation loss: 2.5186035504905124

Epoch: 5| Step: 3
Training loss: 2.296257257461548
Validation loss: 2.522048980959

Epoch: 5| Step: 4
Training loss: 2.2275402545928955
Validation loss: 2.5210313643178632

Epoch: 5| Step: 5
Training loss: 2.842428207397461
Validation loss: 2.537048598771454

Epoch: 5| Step: 6
Training loss: 2.633810043334961
Validation loss: 2.531750568779566

Epoch: 5| Step: 7
Training loss: 3.090817928314209
Validation loss: 2.5280114399489535

Epoch: 5| Step: 8
Training loss: 3.3305327892303467
Validation loss: 2.517097919218002

Epoch: 5| Step: 9
Training loss: 2.6128525733947754
Validation loss: 2.5156802964466873

Epoch: 5| Step: 10
Training loss: 2.900522232055664
Validation loss: 2.5095006855585242

Epoch: 80| Step: 0
Training loss: 2.7930824756622314
Validation loss: 2.5064236079492876

Epoch: 5| Step: 1
Training loss: 2.545440912246704
Validation loss: 2.5114281305702786

Epoch: 5| Step: 2
Training loss: 1.7279326915740967
Validation loss: 2.511658919754849

Epoch: 5| Step: 3
Training loss: 2.788126230239868
Validation loss: 2.5093399247815533

Epoch: 5| Step: 4
Training loss: 2.8976917266845703
Validation loss: 2.506719522578742

Epoch: 5| Step: 5
Training loss: 2.978912591934204
Validation loss: 2.5098535399283133

Epoch: 5| Step: 6
Training loss: 2.952639579772949
Validation loss: 2.50722570829494

Epoch: 5| Step: 7
Training loss: 2.977004289627075
Validation loss: 2.5101479535461753

Epoch: 5| Step: 8
Training loss: 2.2542243003845215
Validation loss: 2.5118547793357604

Epoch: 5| Step: 9
Training loss: 2.788273334503174
Validation loss: 2.5085450577479538

Epoch: 5| Step: 10
Training loss: 3.135946750640869
Validation loss: 2.514286107914422

Epoch: 81| Step: 0
Training loss: 3.461228847503662
Validation loss: 2.513788510394353

Epoch: 5| Step: 1
Training loss: 2.4909567832946777
Validation loss: 2.514107924635692

Epoch: 5| Step: 2
Training loss: 3.4833984375
Validation loss: 2.5188716611554547

Epoch: 5| Step: 3
Training loss: 2.8181304931640625
Validation loss: 2.518884902359337

Epoch: 5| Step: 4
Training loss: 2.274463176727295
Validation loss: 2.526818957380069

Epoch: 5| Step: 5
Training loss: 2.2463631629943848
Validation loss: 2.519026748595699

Epoch: 5| Step: 6
Training loss: 2.7434773445129395
Validation loss: 2.517350650602771

Epoch: 5| Step: 7
Training loss: 2.598701000213623
Validation loss: 2.5072687672030542

Epoch: 5| Step: 8
Training loss: 2.738525152206421
Validation loss: 2.498121048814507

Epoch: 5| Step: 9
Training loss: 2.464714288711548
Validation loss: 2.4985454133761826

Epoch: 5| Step: 10
Training loss: 2.30861234664917
Validation loss: 2.4994344352394022

Epoch: 82| Step: 0
Training loss: 2.486201286315918
Validation loss: 2.5052209797725884

Epoch: 5| Step: 1
Training loss: 2.03767728805542
Validation loss: 2.5250970009834535

Epoch: 5| Step: 2
Training loss: 2.628732919692993
Validation loss: 2.525267272867182

Epoch: 5| Step: 3
Training loss: 3.0223069190979004
Validation loss: 2.5118207136789956

Epoch: 5| Step: 4
Training loss: 3.1096115112304688
Validation loss: 2.502740278038927

Epoch: 5| Step: 5
Training loss: 2.7842297554016113
Validation loss: 2.515395313180903

Epoch: 5| Step: 6
Training loss: 2.796954393386841
Validation loss: 2.5337634240427325

Epoch: 5| Step: 7
Training loss: 3.069589376449585
Validation loss: 2.5418383229163384

Epoch: 5| Step: 8
Training loss: 2.4719271659851074
Validation loss: 2.5391612386190765

Epoch: 5| Step: 9
Training loss: 2.6220550537109375
Validation loss: 2.536323606327016

Epoch: 5| Step: 10
Training loss: 2.7968521118164062
Validation loss: 2.5202895133726058

Epoch: 83| Step: 0
Training loss: 2.857635021209717
Validation loss: 2.513268542546098

Epoch: 5| Step: 1
Training loss: 2.464848041534424
Validation loss: 2.50651228556069

Epoch: 5| Step: 2
Training loss: 2.681946277618408
Validation loss: 2.5022994061951995

Epoch: 5| Step: 3
Training loss: 2.4158523082733154
Validation loss: 2.5010803925093783

Epoch: 5| Step: 4
Training loss: 2.81101655960083
Validation loss: 2.4987002957251763

Epoch: 5| Step: 5
Training loss: 2.8297617435455322
Validation loss: 2.497159816885507

Epoch: 5| Step: 6
Training loss: 2.498690366744995
Validation loss: 2.4998862461377214

Epoch: 5| Step: 7
Training loss: 3.26216197013855
Validation loss: 2.495427026543566

Epoch: 5| Step: 8
Training loss: 2.8334362506866455
Validation loss: 2.49862317885122

Epoch: 5| Step: 9
Training loss: 2.837031841278076
Validation loss: 2.495601310524889

Epoch: 5| Step: 10
Training loss: 2.0775513648986816
Validation loss: 2.4963438023803053

Epoch: 84| Step: 0
Training loss: 2.4800491333007812
Validation loss: 2.493013745994978

Epoch: 5| Step: 1
Training loss: 3.2645962238311768
Validation loss: 2.491102090445898

Epoch: 5| Step: 2
Training loss: 3.0005955696105957
Validation loss: 2.494602834024737

Epoch: 5| Step: 3
Training loss: 3.068249464035034
Validation loss: 2.4962832235520884

Epoch: 5| Step: 4
Training loss: 2.602677822113037
Validation loss: 2.493365249326152

Epoch: 5| Step: 5
Training loss: 3.0328967571258545
Validation loss: 2.4967679669780116

Epoch: 5| Step: 6
Training loss: 2.5250439643859863
Validation loss: 2.495060802787863

Epoch: 5| Step: 7
Training loss: 2.5461251735687256
Validation loss: 2.4964327607103574

Epoch: 5| Step: 8
Training loss: 2.656433582305908
Validation loss: 2.4975740986485637

Epoch: 5| Step: 9
Training loss: 2.282390832901001
Validation loss: 2.5035218115775817

Epoch: 5| Step: 10
Training loss: 2.062896966934204
Validation loss: 2.501641527298958

Epoch: 85| Step: 0
Training loss: 2.1688334941864014
Validation loss: 2.4968411396908503

Epoch: 5| Step: 1
Training loss: 1.8857028484344482
Validation loss: 2.4917432774779615

Epoch: 5| Step: 2
Training loss: 2.6412365436553955
Validation loss: 2.4888848694421912

Epoch: 5| Step: 3
Training loss: 2.4630532264709473
Validation loss: 2.489308811003162

Epoch: 5| Step: 4
Training loss: 3.1230132579803467
Validation loss: 2.487406446087745

Epoch: 5| Step: 5
Training loss: 3.2748687267303467
Validation loss: 2.490099776175714

Epoch: 5| Step: 6
Training loss: 1.7392832040786743
Validation loss: 2.4872670071099394

Epoch: 5| Step: 7
Training loss: 2.9917430877685547
Validation loss: 2.4881647645786242

Epoch: 5| Step: 8
Training loss: 2.8349735736846924
Validation loss: 2.4854314506694837

Epoch: 5| Step: 9
Training loss: 3.4204955101013184
Validation loss: 2.488088805188415

Epoch: 5| Step: 10
Training loss: 3.088170051574707
Validation loss: 2.4831065465045232

Epoch: 86| Step: 0
Training loss: 2.893608570098877
Validation loss: 2.487592133142615

Epoch: 5| Step: 1
Training loss: 2.225959300994873
Validation loss: 2.4884755406328427

Epoch: 5| Step: 2
Training loss: 2.4128823280334473
Validation loss: 2.4877696524384203

Epoch: 5| Step: 3
Training loss: 2.1954469680786133
Validation loss: 2.4822751014463362

Epoch: 5| Step: 4
Training loss: 3.0895698070526123
Validation loss: 2.4890187812107865

Epoch: 5| Step: 5
Training loss: 2.4395840167999268
Validation loss: 2.4886722641606487

Epoch: 5| Step: 6
Training loss: 2.9506354331970215
Validation loss: 2.4868104432218816

Epoch: 5| Step: 7
Training loss: 3.0876286029815674
Validation loss: 2.4887495399803243

Epoch: 5| Step: 8
Training loss: 2.4878687858581543
Validation loss: 2.492479137195054

Epoch: 5| Step: 9
Training loss: 2.6574273109436035
Validation loss: 2.499017982072728

Epoch: 5| Step: 10
Training loss: 3.173382043838501
Validation loss: 2.500946129522016

Epoch: 87| Step: 0
Training loss: 3.3433685302734375
Validation loss: 2.498900807032021

Epoch: 5| Step: 1
Training loss: 2.167661666870117
Validation loss: 2.494240553148331

Epoch: 5| Step: 2
Training loss: 2.568436861038208
Validation loss: 2.487171947315175

Epoch: 5| Step: 3
Training loss: 2.7839276790618896
Validation loss: 2.4826007261071155

Epoch: 5| Step: 4
Training loss: 2.3471932411193848
Validation loss: 2.4831824123218493

Epoch: 5| Step: 5
Training loss: 2.946934461593628
Validation loss: 2.4818904810054327

Epoch: 5| Step: 6
Training loss: 2.4020934104919434
Validation loss: 2.4835777051987185

Epoch: 5| Step: 7
Training loss: 3.53680419921875
Validation loss: 2.4828159962930987

Epoch: 5| Step: 8
Training loss: 3.04390287399292
Validation loss: 2.48191584310224

Epoch: 5| Step: 9
Training loss: 2.542402982711792
Validation loss: 2.4842737438858196

Epoch: 5| Step: 10
Training loss: 1.789057731628418
Validation loss: 2.485709592860232

Epoch: 88| Step: 0
Training loss: 2.4113354682922363
Validation loss: 2.481727264260733

Epoch: 5| Step: 1
Training loss: 2.6584932804107666
Validation loss: 2.4806319077809653

Epoch: 5| Step: 2
Training loss: 2.532787799835205
Validation loss: 2.478579085360291

Epoch: 5| Step: 3
Training loss: 2.783273220062256
Validation loss: 2.4858773857034664

Epoch: 5| Step: 4
Training loss: 3.178626298904419
Validation loss: 2.4905549454432663

Epoch: 5| Step: 5
Training loss: 2.7251954078674316
Validation loss: 2.4995416953999507

Epoch: 5| Step: 6
Training loss: 2.8036248683929443
Validation loss: 2.500759534938361

Epoch: 5| Step: 7
Training loss: 2.6483356952667236
Validation loss: 2.4989755128019597

Epoch: 5| Step: 8
Training loss: 2.9370970726013184
Validation loss: 2.492715084424583

Epoch: 5| Step: 9
Training loss: 2.7324957847595215
Validation loss: 2.494047826336276

Epoch: 5| Step: 10
Training loss: 2.0103962421417236
Validation loss: 2.4872486437520673

Epoch: 89| Step: 0
Training loss: 2.9024410247802734
Validation loss: 2.4864864708274923

Epoch: 5| Step: 1
Training loss: 2.693058729171753
Validation loss: 2.481897625871884

Epoch: 5| Step: 2
Training loss: 2.3351802825927734
Validation loss: 2.4816285769144693

Epoch: 5| Step: 3
Training loss: 2.78676700592041
Validation loss: 2.4761158035647486

Epoch: 5| Step: 4
Training loss: 2.632814407348633
Validation loss: 2.480614322488026

Epoch: 5| Step: 5
Training loss: 3.2156550884246826
Validation loss: 2.480023573803645

Epoch: 5| Step: 6
Training loss: 2.1327710151672363
Validation loss: 2.479369333995286

Epoch: 5| Step: 7
Training loss: 2.352139472961426
Validation loss: 2.482317219498337

Epoch: 5| Step: 8
Training loss: 2.625980854034424
Validation loss: 2.480918502294889

Epoch: 5| Step: 9
Training loss: 2.65645694732666
Validation loss: 2.4837934458127586

Epoch: 5| Step: 10
Training loss: 3.25610089302063
Validation loss: 2.485244269012123

Epoch: 90| Step: 0
Training loss: 2.711735963821411
Validation loss: 2.4951652916528846

Epoch: 5| Step: 1
Training loss: 2.3906326293945312
Validation loss: 2.487043680683259

Epoch: 5| Step: 2
Training loss: 2.5598337650299072
Validation loss: 2.487984162504955

Epoch: 5| Step: 3
Training loss: 2.3232948780059814
Validation loss: 2.4840172131856284

Epoch: 5| Step: 4
Training loss: 2.4608263969421387
Validation loss: 2.478914406991774

Epoch: 5| Step: 5
Training loss: 2.1922202110290527
Validation loss: 2.478650221260645

Epoch: 5| Step: 6
Training loss: 3.514869213104248
Validation loss: 2.4789691663557485

Epoch: 5| Step: 7
Training loss: 2.9950225353240967
Validation loss: 2.4754303424589095

Epoch: 5| Step: 8
Training loss: 2.705693244934082
Validation loss: 2.473780534600699

Epoch: 5| Step: 9
Training loss: 2.658435821533203
Validation loss: 2.4741440126972813

Epoch: 5| Step: 10
Training loss: 2.9903814792633057
Validation loss: 2.4725928729580295

Epoch: 91| Step: 0
Training loss: 2.780848979949951
Validation loss: 2.4738701492227535

Epoch: 5| Step: 1
Training loss: 2.9235782623291016
Validation loss: 2.4732291877910657

Epoch: 5| Step: 2
Training loss: 2.7678141593933105
Validation loss: 2.473849824679795

Epoch: 5| Step: 3
Training loss: 2.3008017539978027
Validation loss: 2.4750284712801696

Epoch: 5| Step: 4
Training loss: 2.7672791481018066
Validation loss: 2.4709742633245324

Epoch: 5| Step: 5
Training loss: 2.475346803665161
Validation loss: 2.470730540572956

Epoch: 5| Step: 6
Training loss: 2.8160910606384277
Validation loss: 2.480756864752821

Epoch: 5| Step: 7
Training loss: 2.727065324783325
Validation loss: 2.4826797926297752

Epoch: 5| Step: 8
Training loss: 3.5252106189727783
Validation loss: 2.4994266622809955

Epoch: 5| Step: 9
Training loss: 2.0239481925964355
Validation loss: 2.4983560962061726

Epoch: 5| Step: 10
Training loss: 2.3416874408721924
Validation loss: 2.4942032060315533

Epoch: 92| Step: 0
Training loss: 1.9999738931655884
Validation loss: 2.4954165976534606

Epoch: 5| Step: 1
Training loss: 2.963183879852295
Validation loss: 2.4835252710568008

Epoch: 5| Step: 2
Training loss: 2.346036911010742
Validation loss: 2.478527899711363

Epoch: 5| Step: 3
Training loss: 2.9319252967834473
Validation loss: 2.475809286999446

Epoch: 5| Step: 4
Training loss: 2.1298828125
Validation loss: 2.473369457388437

Epoch: 5| Step: 5
Training loss: 3.052295684814453
Validation loss: 2.471698340549264

Epoch: 5| Step: 6
Training loss: 3.0486674308776855
Validation loss: 2.46866476023069

Epoch: 5| Step: 7
Training loss: 3.2411980628967285
Validation loss: 2.4692225251146542

Epoch: 5| Step: 8
Training loss: 2.3974032402038574
Validation loss: 2.471218293712985

Epoch: 5| Step: 9
Training loss: 2.6342055797576904
Validation loss: 2.4710662159868466

Epoch: 5| Step: 10
Training loss: 2.681809902191162
Validation loss: 2.467334403786608

Epoch: 93| Step: 0
Training loss: 2.5180087089538574
Validation loss: 2.4679205930361183

Epoch: 5| Step: 1
Training loss: 2.1706249713897705
Validation loss: 2.470018374022617

Epoch: 5| Step: 2
Training loss: 3.021078586578369
Validation loss: 2.4735357530655397

Epoch: 5| Step: 3
Training loss: 2.3163750171661377
Validation loss: 2.4679644518001105

Epoch: 5| Step: 4
Training loss: 2.477839946746826
Validation loss: 2.4741051658507316

Epoch: 5| Step: 5
Training loss: 2.558257579803467
Validation loss: 2.4804965578099734

Epoch: 5| Step: 6
Training loss: 3.366377592086792
Validation loss: 2.490810304559687

Epoch: 5| Step: 7
Training loss: 2.9153876304626465
Validation loss: 2.490876054251066

Epoch: 5| Step: 8
Training loss: 2.3119633197784424
Validation loss: 2.5024849317407094

Epoch: 5| Step: 9
Training loss: 2.85089373588562
Validation loss: 2.501444060315368

Epoch: 5| Step: 10
Training loss: 2.935206890106201
Validation loss: 2.5007459066247426

Epoch: 94| Step: 0
Training loss: 2.5534253120422363
Validation loss: 2.49385097975372

Epoch: 5| Step: 1
Training loss: 2.6954574584960938
Validation loss: 2.4778507114738546

Epoch: 5| Step: 2
Training loss: 3.3570778369903564
Validation loss: 2.4654065460287113

Epoch: 5| Step: 3
Training loss: 3.388958692550659
Validation loss: 2.4656701600679787

Epoch: 5| Step: 4
Training loss: 2.9058890342712402
Validation loss: 2.467408662201256

Epoch: 5| Step: 5
Training loss: 2.790630340576172
Validation loss: 2.4713260204561296

Epoch: 5| Step: 6
Training loss: 2.568786144256592
Validation loss: 2.473846830347533

Epoch: 5| Step: 7
Training loss: 2.3054261207580566
Validation loss: 2.481719878412062

Epoch: 5| Step: 8
Training loss: 2.464594841003418
Validation loss: 2.4721595241177465

Epoch: 5| Step: 9
Training loss: 2.382814884185791
Validation loss: 2.472951496801069

Epoch: 5| Step: 10
Training loss: 1.9344722032546997
Validation loss: 2.4636051885543333

Epoch: 95| Step: 0
Training loss: 2.4182424545288086
Validation loss: 2.4633083599869923

Epoch: 5| Step: 1
Training loss: 2.6103978157043457
Validation loss: 2.464647449472899

Epoch: 5| Step: 2
Training loss: 2.7678515911102295
Validation loss: 2.474439367171257

Epoch: 5| Step: 3
Training loss: 3.0320487022399902
Validation loss: 2.492102276894354

Epoch: 5| Step: 4
Training loss: 3.0888898372650146
Validation loss: 2.5145841619019866

Epoch: 5| Step: 5
Training loss: 2.826139211654663
Validation loss: 2.53380944139214

Epoch: 5| Step: 6
Training loss: 2.7733006477355957
Validation loss: 2.526420006188013

Epoch: 5| Step: 7
Training loss: 3.0048751831054688
Validation loss: 2.52642931220352

Epoch: 5| Step: 8
Training loss: 2.3852405548095703
Validation loss: 2.492489558394237

Epoch: 5| Step: 9
Training loss: 2.7792251110076904
Validation loss: 2.463984448422668

Epoch: 5| Step: 10
Training loss: 1.735115647315979
Validation loss: 2.459240516026815

Epoch: 96| Step: 0
Training loss: 2.8385977745056152
Validation loss: 2.458980575684578

Epoch: 5| Step: 1
Training loss: 2.7918541431427
Validation loss: 2.477994029239942

Epoch: 5| Step: 2
Training loss: 3.0551376342773438
Validation loss: 2.4884316203414754

Epoch: 5| Step: 3
Training loss: 2.3547658920288086
Validation loss: 2.4965051604855444

Epoch: 5| Step: 4
Training loss: 2.585099220275879
Validation loss: 2.5092739417988765

Epoch: 5| Step: 5
Training loss: 2.8642642498016357
Validation loss: 2.5575677451267036

Epoch: 5| Step: 6
Training loss: 2.7037546634674072
Validation loss: 2.6067587278222524

Epoch: 5| Step: 7
Training loss: 2.774076223373413
Validation loss: 2.5739447096342682

Epoch: 5| Step: 8
Training loss: 2.3443052768707275
Validation loss: 2.488250776003766

Epoch: 5| Step: 9
Training loss: 3.245770215988159
Validation loss: 2.461561490130681

Epoch: 5| Step: 10
Training loss: 2.336498498916626
Validation loss: 2.4628087910272742

Epoch: 97| Step: 0
Training loss: 2.087364673614502
Validation loss: 2.470536216612785

Epoch: 5| Step: 1
Training loss: 3.1733477115631104
Validation loss: 2.4922560876415623

Epoch: 5| Step: 2
Training loss: 2.896110773086548
Validation loss: 2.5115210907433623

Epoch: 5| Step: 3
Training loss: 2.601107120513916
Validation loss: 2.5241495076046196

Epoch: 5| Step: 4
Training loss: 2.934744358062744
Validation loss: 2.501079220925608

Epoch: 5| Step: 5
Training loss: 2.727867603302002
Validation loss: 2.490367671494843

Epoch: 5| Step: 6
Training loss: 3.5103161334991455
Validation loss: 2.487654388591807

Epoch: 5| Step: 7
Training loss: 2.4924943447113037
Validation loss: 2.4763759566891577

Epoch: 5| Step: 8
Training loss: 2.151033878326416
Validation loss: 2.4754680971945486

Epoch: 5| Step: 9
Training loss: 2.4186789989471436
Validation loss: 2.4664438924481793

Epoch: 5| Step: 10
Training loss: 2.4433085918426514
Validation loss: 2.454085919164842

Epoch: 98| Step: 0
Training loss: 2.6483750343322754
Validation loss: 2.4533722246846845

Epoch: 5| Step: 1
Training loss: 3.161587715148926
Validation loss: 2.4611209823239233

Epoch: 5| Step: 2
Training loss: 2.5924525260925293
Validation loss: 2.4763558487738333

Epoch: 5| Step: 3
Training loss: 2.449155330657959
Validation loss: 2.495712387946344

Epoch: 5| Step: 4
Training loss: 2.4945621490478516
Validation loss: 2.5125412351341656

Epoch: 5| Step: 5
Training loss: 2.030026912689209
Validation loss: 2.5048686060854184

Epoch: 5| Step: 6
Training loss: 2.8759360313415527
Validation loss: 2.5003724739115727

Epoch: 5| Step: 7
Training loss: 2.217940330505371
Validation loss: 2.486226479212443

Epoch: 5| Step: 8
Training loss: 3.117845058441162
Validation loss: 2.477814746159379

Epoch: 5| Step: 9
Training loss: 3.2371737957000732
Validation loss: 2.4704940190879245

Epoch: 5| Step: 10
Training loss: 2.8989877700805664
Validation loss: 2.4699942373460337

Epoch: 99| Step: 0
Training loss: 2.964527130126953
Validation loss: 2.4726546836155716

Epoch: 5| Step: 1
Training loss: 2.5226147174835205
Validation loss: 2.4681072081288984

Epoch: 5| Step: 2
Training loss: 2.3729937076568604
Validation loss: 2.4715900767234062

Epoch: 5| Step: 3
Training loss: 2.4037516117095947
Validation loss: 2.4863451706465853

Epoch: 5| Step: 4
Training loss: 2.309601306915283
Validation loss: 2.5049459395870084

Epoch: 5| Step: 5
Training loss: 2.6137824058532715
Validation loss: 2.5378165706511466

Epoch: 5| Step: 6
Training loss: 3.2637627124786377
Validation loss: 2.5358769227099676

Epoch: 5| Step: 7
Training loss: 2.895857572555542
Validation loss: 2.5337744541065668

Epoch: 5| Step: 8
Training loss: 3.0804591178894043
Validation loss: 2.5289950165697324

Epoch: 5| Step: 9
Training loss: 2.480508804321289
Validation loss: 2.5273068848476616

Epoch: 5| Step: 10
Training loss: 2.8080694675445557
Validation loss: 2.5236880779266357

Epoch: 100| Step: 0
Training loss: 2.9837770462036133
Validation loss: 2.5025309721628823

Epoch: 5| Step: 1
Training loss: 1.9591842889785767
Validation loss: 2.494648784719488

Epoch: 5| Step: 2
Training loss: 1.9607903957366943
Validation loss: 2.476067122592721

Epoch: 5| Step: 3
Training loss: 2.6826462745666504
Validation loss: 2.4703901660057808

Epoch: 5| Step: 4
Training loss: 2.3646202087402344
Validation loss: 2.465934940563735

Epoch: 5| Step: 5
Training loss: 2.84004282951355
Validation loss: 2.470006817130632

Epoch: 5| Step: 6
Training loss: 2.2366738319396973
Validation loss: 2.4750979279959076

Epoch: 5| Step: 7
Training loss: 2.6702980995178223
Validation loss: 2.4716279378501316

Epoch: 5| Step: 8
Training loss: 2.756213426589966
Validation loss: 2.4701118597420315

Epoch: 5| Step: 9
Training loss: 3.1625685691833496
Validation loss: 2.467384828034268

Epoch: 5| Step: 10
Training loss: 3.8628575801849365
Validation loss: 2.4602729018016527

Epoch: 101| Step: 0
Training loss: 2.865734815597534
Validation loss: 2.4529227300356795

Epoch: 5| Step: 1
Training loss: 2.7632062435150146
Validation loss: 2.4471347408909954

Epoch: 5| Step: 2
Training loss: 3.007431983947754
Validation loss: 2.451206097038843

Epoch: 5| Step: 3
Training loss: 2.3481128215789795
Validation loss: 2.4548886642661145

Epoch: 5| Step: 4
Training loss: 2.716578960418701
Validation loss: 2.459549473178002

Epoch: 5| Step: 5
Training loss: 2.493661403656006
Validation loss: 2.4692352048812376

Epoch: 5| Step: 6
Training loss: 3.0783257484436035
Validation loss: 2.476238663478564

Epoch: 5| Step: 7
Training loss: 2.8196182250976562
Validation loss: 2.4717820895615445

Epoch: 5| Step: 8
Training loss: 1.8926512002944946
Validation loss: 2.4522908810646302

Epoch: 5| Step: 9
Training loss: 2.278661012649536
Validation loss: 2.4503583113352456

Epoch: 5| Step: 10
Training loss: 3.135300874710083
Validation loss: 2.445493939102337

Epoch: 102| Step: 0
Training loss: 2.9900691509246826
Validation loss: 2.4466237175849175

Epoch: 5| Step: 1
Training loss: 2.2955758571624756
Validation loss: 2.442896294337447

Epoch: 5| Step: 2
Training loss: 2.0759310722351074
Validation loss: 2.447241485759776

Epoch: 5| Step: 3
Training loss: 2.1909167766571045
Validation loss: 2.450678474159651

Epoch: 5| Step: 4
Training loss: 2.7502341270446777
Validation loss: 2.4489975193495392

Epoch: 5| Step: 5
Training loss: 2.7855916023254395
Validation loss: 2.44911455082637

Epoch: 5| Step: 6
Training loss: 2.467878818511963
Validation loss: 2.4502931717903382

Epoch: 5| Step: 7
Training loss: 3.5973618030548096
Validation loss: 2.4472964066331104

Epoch: 5| Step: 8
Training loss: 2.8723978996276855
Validation loss: 2.444755509335508

Epoch: 5| Step: 9
Training loss: 2.6105945110321045
Validation loss: 2.441812494749664

Epoch: 5| Step: 10
Training loss: 2.7908103466033936
Validation loss: 2.4403871823382635

Epoch: 103| Step: 0
Training loss: 2.7979581356048584
Validation loss: 2.448218995524991

Epoch: 5| Step: 1
Training loss: 3.0754213333129883
Validation loss: 2.454276530973373

Epoch: 5| Step: 2
Training loss: 2.0138309001922607
Validation loss: 2.4685025625331427

Epoch: 5| Step: 3
Training loss: 2.016475200653076
Validation loss: 2.4765549244419223

Epoch: 5| Step: 4
Training loss: 3.2084319591522217
Validation loss: 2.47728927417468

Epoch: 5| Step: 5
Training loss: 3.2417361736297607
Validation loss: 2.476211327378468

Epoch: 5| Step: 6
Training loss: 2.1673717498779297
Validation loss: 2.4607422749201455

Epoch: 5| Step: 7
Training loss: 2.5261614322662354
Validation loss: 2.453154358812558

Epoch: 5| Step: 8
Training loss: 2.923253059387207
Validation loss: 2.445419301268875

Epoch: 5| Step: 9
Training loss: 2.496358633041382
Validation loss: 2.4354698991262786

Epoch: 5| Step: 10
Training loss: 2.8554701805114746
Validation loss: 2.4358652022577103

Epoch: 104| Step: 0
Training loss: 2.7915241718292236
Validation loss: 2.437912471832768

Epoch: 5| Step: 1
Training loss: 2.180293560028076
Validation loss: 2.439123466450681

Epoch: 5| Step: 2
Training loss: 3.0445284843444824
Validation loss: 2.4430613056305917

Epoch: 5| Step: 3
Training loss: 2.4471538066864014
Validation loss: 2.445405585791475

Epoch: 5| Step: 4
Training loss: 3.104562282562256
Validation loss: 2.446103283154067

Epoch: 5| Step: 5
Training loss: 3.0770602226257324
Validation loss: 2.4450961492394887

Epoch: 5| Step: 6
Training loss: 2.3659467697143555
Validation loss: 2.4460473009335097

Epoch: 5| Step: 7
Training loss: 2.4943909645080566
Validation loss: 2.45341577324816

Epoch: 5| Step: 8
Training loss: 2.6349451541900635
Validation loss: 2.4546661940954064

Epoch: 5| Step: 9
Training loss: 2.686396598815918
Validation loss: 2.469718635723155

Epoch: 5| Step: 10
Training loss: 2.5380616188049316
Validation loss: 2.4639751731708484

Epoch: 105| Step: 0
Training loss: 2.4958267211914062
Validation loss: 2.4477036358207784

Epoch: 5| Step: 1
Training loss: 3.230060577392578
Validation loss: 2.4390723218200026

Epoch: 5| Step: 2
Training loss: 2.485398292541504
Validation loss: 2.4473976191654

Epoch: 5| Step: 3
Training loss: 2.7186622619628906
Validation loss: 2.4557036020422496

Epoch: 5| Step: 4
Training loss: 2.815417766571045
Validation loss: 2.4718091616066555

Epoch: 5| Step: 5
Training loss: 2.2222867012023926
Validation loss: 2.492256740088104

Epoch: 5| Step: 6
Training loss: 2.910295009613037
Validation loss: 2.5036695541874057

Epoch: 5| Step: 7
Training loss: 2.4855380058288574
Validation loss: 2.4845244397399244

Epoch: 5| Step: 8
Training loss: 2.581815719604492
Validation loss: 2.4705156357057634

Epoch: 5| Step: 9
Training loss: 2.3310468196868896
Validation loss: 2.4510969218387397

Epoch: 5| Step: 10
Training loss: 3.1327571868896484
Validation loss: 2.4442230142572874

Epoch: 106| Step: 0
Training loss: 2.8272838592529297
Validation loss: 2.436104707820441

Epoch: 5| Step: 1
Training loss: 3.02958345413208
Validation loss: 2.431452376868135

Epoch: 5| Step: 2
Training loss: 2.7174341678619385
Validation loss: 2.428685126766082

Epoch: 5| Step: 3
Training loss: 2.6911025047302246
Validation loss: 2.4379844396345076

Epoch: 5| Step: 4
Training loss: 2.640584707260132
Validation loss: 2.442307262010472

Epoch: 5| Step: 5
Training loss: 2.1606507301330566
Validation loss: 2.4427339825578915

Epoch: 5| Step: 6
Training loss: 2.369114398956299
Validation loss: 2.437838154454385

Epoch: 5| Step: 7
Training loss: 2.231264114379883
Validation loss: 2.4424375308457242

Epoch: 5| Step: 8
Training loss: 3.0395045280456543
Validation loss: 2.4368009233987458

Epoch: 5| Step: 9
Training loss: 2.9199485778808594
Validation loss: 2.435745093130296

Epoch: 5| Step: 10
Training loss: 2.658879041671753
Validation loss: 2.4317971121880317

Epoch: 107| Step: 0
Training loss: 2.873427629470825
Validation loss: 2.4296892842938824

Epoch: 5| Step: 1
Training loss: 2.9227004051208496
Validation loss: 2.4278720104566185

Epoch: 5| Step: 2
Training loss: 2.8270816802978516
Validation loss: 2.4352321881119923

Epoch: 5| Step: 3
Training loss: 2.1501240730285645
Validation loss: 2.4346647313846055

Epoch: 5| Step: 4
Training loss: 2.415100574493408
Validation loss: 2.4372522548962663

Epoch: 5| Step: 5
Training loss: 2.6785078048706055
Validation loss: 2.4380197550660823

Epoch: 5| Step: 6
Training loss: 2.7738707065582275
Validation loss: 2.445474006796396

Epoch: 5| Step: 7
Training loss: 2.549065351486206
Validation loss: 2.446618251903083

Epoch: 5| Step: 8
Training loss: 2.640418291091919
Validation loss: 2.4450460210923226

Epoch: 5| Step: 9
Training loss: 2.812138557434082
Validation loss: 2.45154373363782

Epoch: 5| Step: 10
Training loss: 2.5504496097564697
Validation loss: 2.4526953953568653

Epoch: 108| Step: 0
Training loss: 2.887773275375366
Validation loss: 2.459444171638899

Epoch: 5| Step: 1
Training loss: 2.6292433738708496
Validation loss: 2.4660961833051456

Epoch: 5| Step: 2
Training loss: 2.9432082176208496
Validation loss: 2.4668976119769517

Epoch: 5| Step: 3
Training loss: 2.867774486541748
Validation loss: 2.480053958072457

Epoch: 5| Step: 4
Training loss: 2.541062116622925
Validation loss: 2.4923786347912205

Epoch: 5| Step: 5
Training loss: 3.0637781620025635
Validation loss: 2.483845341590143

Epoch: 5| Step: 6
Training loss: 2.6905789375305176
Validation loss: 2.4729869519510577

Epoch: 5| Step: 7
Training loss: 2.627833843231201
Validation loss: 2.458122440563735

Epoch: 5| Step: 8
Training loss: 2.918738842010498
Validation loss: 2.44567302221893

Epoch: 5| Step: 9
Training loss: 1.8371795415878296
Validation loss: 2.4368081861926663

Epoch: 5| Step: 10
Training loss: 2.189669132232666
Validation loss: 2.4378216753723803

Epoch: 109| Step: 0
Training loss: 2.784904956817627
Validation loss: 2.4424155014817432

Epoch: 5| Step: 1
Training loss: 2.5807976722717285
Validation loss: 2.445985517194194

Epoch: 5| Step: 2
Training loss: 2.9655892848968506
Validation loss: 2.441092111731088

Epoch: 5| Step: 3
Training loss: 2.5785973072052
Validation loss: 2.433779543445956

Epoch: 5| Step: 4
Training loss: 2.6479289531707764
Validation loss: 2.4306029811982186

Epoch: 5| Step: 5
Training loss: 2.312072515487671
Validation loss: 2.436603005214404

Epoch: 5| Step: 6
Training loss: 2.7718758583068848
Validation loss: 2.4331750023749565

Epoch: 5| Step: 7
Training loss: 2.917762279510498
Validation loss: 2.447876512363393

Epoch: 5| Step: 8
Training loss: 2.568956136703491
Validation loss: 2.437990450089978

Epoch: 5| Step: 9
Training loss: 2.476224184036255
Validation loss: 2.4319815892045216

Epoch: 5| Step: 10
Training loss: 2.585218667984009
Validation loss: 2.4307249053832023

Epoch: 110| Step: 0
Training loss: 1.9892059564590454
Validation loss: 2.4301913297304543

Epoch: 5| Step: 1
Training loss: 2.913602113723755
Validation loss: 2.4269395105300413

Epoch: 5| Step: 2
Training loss: 2.6197218894958496
Validation loss: 2.423029758596933

Epoch: 5| Step: 3
Training loss: 2.7260193824768066
Validation loss: 2.423228238218574

Epoch: 5| Step: 4
Training loss: 2.3219680786132812
Validation loss: 2.4180031412391254

Epoch: 5| Step: 5
Training loss: 2.400653839111328
Validation loss: 2.4179675809798704

Epoch: 5| Step: 6
Training loss: 3.031188488006592
Validation loss: 2.419839282189646

Epoch: 5| Step: 7
Training loss: 2.1204140186309814
Validation loss: 2.4186777530177945

Epoch: 5| Step: 8
Training loss: 3.0753798484802246
Validation loss: 2.4183568749376523

Epoch: 5| Step: 9
Training loss: 3.2965168952941895
Validation loss: 2.425966893472979

Epoch: 5| Step: 10
Training loss: 2.701179027557373
Validation loss: 2.4278719809747513

Epoch: 111| Step: 0
Training loss: 2.6685879230499268
Validation loss: 2.429618820067375

Epoch: 5| Step: 1
Training loss: 2.4378554821014404
Validation loss: 2.4359107709700063

Epoch: 5| Step: 2
Training loss: 2.8652734756469727
Validation loss: 2.4606832150490052

Epoch: 5| Step: 3
Training loss: 3.360861301422119
Validation loss: 2.51017657403023

Epoch: 5| Step: 4
Training loss: 2.230125665664673
Validation loss: 2.4871767156867572

Epoch: 5| Step: 5
Training loss: 2.2097995281219482
Validation loss: 2.441641423010057

Epoch: 5| Step: 6
Training loss: 2.636878490447998
Validation loss: 2.450926931955481

Epoch: 5| Step: 7
Training loss: 2.6984400749206543
Validation loss: 2.4556057888974427

Epoch: 5| Step: 8
Training loss: 2.9393627643585205
Validation loss: 2.4545150879890687

Epoch: 5| Step: 9
Training loss: 2.5576438903808594
Validation loss: 2.457458867821642

Epoch: 5| Step: 10
Training loss: 2.6856729984283447
Validation loss: 2.4620682526660222

Epoch: 112| Step: 0
Training loss: 2.6766855716705322
Validation loss: 2.465088129043579

Epoch: 5| Step: 1
Training loss: 2.370271682739258
Validation loss: 2.4619347177526003

Epoch: 5| Step: 2
Training loss: 2.0846962928771973
Validation loss: 2.457728814053279

Epoch: 5| Step: 3
Training loss: 2.2456157207489014
Validation loss: 2.4433456979772097

Epoch: 5| Step: 4
Training loss: 2.434027910232544
Validation loss: 2.4324450057039977

Epoch: 5| Step: 5
Training loss: 3.1473324298858643
Validation loss: 2.427311940859723

Epoch: 5| Step: 6
Training loss: 3.343040943145752
Validation loss: 2.4308388002457155

Epoch: 5| Step: 7
Training loss: 2.680018663406372
Validation loss: 2.430545037792575

Epoch: 5| Step: 8
Training loss: 2.970158100128174
Validation loss: 2.4294747947364725

Epoch: 5| Step: 9
Training loss: 2.224302291870117
Validation loss: 2.423600391675067

Epoch: 5| Step: 10
Training loss: 3.261138916015625
Validation loss: 2.4226786141754477

Epoch: 113| Step: 0
Training loss: 2.881054162979126
Validation loss: 2.4142313670086604

Epoch: 5| Step: 1
Training loss: 3.05004620552063
Validation loss: 2.4123263564161075

Epoch: 5| Step: 2
Training loss: 2.2913572788238525
Validation loss: 2.4107604436976935

Epoch: 5| Step: 3
Training loss: 2.7705917358398438
Validation loss: 2.4070424418295584

Epoch: 5| Step: 4
Training loss: 2.0749213695526123
Validation loss: 2.4066102735457884

Epoch: 5| Step: 5
Training loss: 2.785208225250244
Validation loss: 2.406953606554257

Epoch: 5| Step: 6
Training loss: 2.731271266937256
Validation loss: 2.4158975385850474

Epoch: 5| Step: 7
Training loss: 2.83086895942688
Validation loss: 2.4149402341535016

Epoch: 5| Step: 8
Training loss: 2.544682502746582
Validation loss: 2.4180397218273533

Epoch: 5| Step: 9
Training loss: 2.9277234077453613
Validation loss: 2.4240011886883805

Epoch: 5| Step: 10
Training loss: 2.1976287364959717
Validation loss: 2.4259155129873626

Epoch: 114| Step: 0
Training loss: 3.165008068084717
Validation loss: 2.4238594270521596

Epoch: 5| Step: 1
Training loss: 3.142965793609619
Validation loss: 2.420089101278654

Epoch: 5| Step: 2
Training loss: 2.546344041824341
Validation loss: 2.414649545505483

Epoch: 5| Step: 3
Training loss: 2.7712900638580322
Validation loss: 2.4069963450072915

Epoch: 5| Step: 4
Training loss: 2.762115001678467
Validation loss: 2.40767071067646

Epoch: 5| Step: 5
Training loss: 2.288093090057373
Validation loss: 2.4046549361239196

Epoch: 5| Step: 6
Training loss: 2.6839585304260254
Validation loss: 2.404843830293225

Epoch: 5| Step: 7
Training loss: 2.2461962699890137
Validation loss: 2.404582667094405

Epoch: 5| Step: 8
Training loss: 2.569976806640625
Validation loss: 2.40871432007

Epoch: 5| Step: 9
Training loss: 2.4668936729431152
Validation loss: 2.402423104932231

Epoch: 5| Step: 10
Training loss: 2.505389451980591
Validation loss: 2.40414600218496

Epoch: 115| Step: 0
Training loss: 2.233694553375244
Validation loss: 2.4071653222524994

Epoch: 5| Step: 1
Training loss: 2.609679937362671
Validation loss: 2.4098885238811536

Epoch: 5| Step: 2
Training loss: 2.2344653606414795
Validation loss: 2.410766686162641

Epoch: 5| Step: 3
Training loss: 2.5289692878723145
Validation loss: 2.4125337318707536

Epoch: 5| Step: 4
Training loss: 2.7583491802215576
Validation loss: 2.4227232420316307

Epoch: 5| Step: 5
Training loss: 2.1707732677459717
Validation loss: 2.4233587480360463

Epoch: 5| Step: 6
Training loss: 2.5457937717437744
Validation loss: 2.41703216491207

Epoch: 5| Step: 7
Training loss: 2.563429832458496
Validation loss: 2.4139821837025304

Epoch: 5| Step: 8
Training loss: 2.9967167377471924
Validation loss: 2.414268729507282

Epoch: 5| Step: 9
Training loss: 3.168790817260742
Validation loss: 2.4045488911290325

Epoch: 5| Step: 10
Training loss: 3.3046348094940186
Validation loss: 2.406395161023704

Epoch: 116| Step: 0
Training loss: 1.9520686864852905
Validation loss: 2.403057934135519

Epoch: 5| Step: 1
Training loss: 2.5083518028259277
Validation loss: 2.401499914866622

Epoch: 5| Step: 2
Training loss: 2.895709991455078
Validation loss: 2.406304072308284

Epoch: 5| Step: 3
Training loss: 2.979586601257324
Validation loss: 2.4064626437361523

Epoch: 5| Step: 4
Training loss: 2.541220188140869
Validation loss: 2.4079467955455987

Epoch: 5| Step: 5
Training loss: 3.06266450881958
Validation loss: 2.4076714592595256

Epoch: 5| Step: 6
Training loss: 2.9241063594818115
Validation loss: 2.415131225380846

Epoch: 5| Step: 7
Training loss: 2.627589464187622
Validation loss: 2.421746748749928

Epoch: 5| Step: 8
Training loss: 2.433805465698242
Validation loss: 2.427526871363322

Epoch: 5| Step: 9
Training loss: 2.3883352279663086
Validation loss: 2.4377470670207853

Epoch: 5| Step: 10
Training loss: 2.730889320373535
Validation loss: 2.441041946411133

Epoch: 117| Step: 0
Training loss: 2.4467530250549316
Validation loss: 2.436865383578885

Epoch: 5| Step: 1
Training loss: 2.6757607460021973
Validation loss: 2.429501477108207

Epoch: 5| Step: 2
Training loss: 2.7671782970428467
Validation loss: 2.427020098573418

Epoch: 5| Step: 3
Training loss: 2.4962069988250732
Validation loss: 2.4224649090920725

Epoch: 5| Step: 4
Training loss: 2.677285671234131
Validation loss: 2.422410531710553

Epoch: 5| Step: 5
Training loss: 3.366158962249756
Validation loss: 2.4227477606906684

Epoch: 5| Step: 6
Training loss: 2.334482192993164
Validation loss: 2.4141362354319584

Epoch: 5| Step: 7
Training loss: 2.1140475273132324
Validation loss: 2.4056247818854546

Epoch: 5| Step: 8
Training loss: 2.4404187202453613
Validation loss: 2.403565768272646

Epoch: 5| Step: 9
Training loss: 2.6352763175964355
Validation loss: 2.3938587686066986

Epoch: 5| Step: 10
Training loss: 3.2631890773773193
Validation loss: 2.400527633646483

Epoch: 118| Step: 0
Training loss: 2.5309641361236572
Validation loss: 2.4155268028218257

Epoch: 5| Step: 1
Training loss: 2.589353561401367
Validation loss: 2.4328053664135676

Epoch: 5| Step: 2
Training loss: 2.462919235229492
Validation loss: 2.4414533338239117

Epoch: 5| Step: 3
Training loss: 2.6198995113372803
Validation loss: 2.4253415599946053

Epoch: 5| Step: 4
Training loss: 2.9185678958892822
Validation loss: 2.417188295754053

Epoch: 5| Step: 5
Training loss: 2.686107873916626
Validation loss: 2.411738636673138

Epoch: 5| Step: 6
Training loss: 2.8425209522247314
Validation loss: 2.4049686180647982

Epoch: 5| Step: 7
Training loss: 2.362511396408081
Validation loss: 2.3960090298806467

Epoch: 5| Step: 8
Training loss: 3.0600600242614746
Validation loss: 2.399518656474288

Epoch: 5| Step: 9
Training loss: 2.734361171722412
Validation loss: 2.3957830936677995

Epoch: 5| Step: 10
Training loss: 2.1548969745635986
Validation loss: 2.399704030765

Epoch: 119| Step: 0
Training loss: 3.227020740509033
Validation loss: 2.39809242884318

Epoch: 5| Step: 1
Training loss: 2.0634865760803223
Validation loss: 2.3990752927718626

Epoch: 5| Step: 2
Training loss: 3.0423026084899902
Validation loss: 2.4021873730485157

Epoch: 5| Step: 3
Training loss: 2.4518299102783203
Validation loss: 2.399767747489355

Epoch: 5| Step: 4
Training loss: 3.3227317333221436
Validation loss: 2.4010876353069017

Epoch: 5| Step: 5
Training loss: 2.6905629634857178
Validation loss: 2.408536180373161

Epoch: 5| Step: 6
Training loss: 2.718280076980591
Validation loss: 2.4133478903001353

Epoch: 5| Step: 7
Training loss: 2.3935341835021973
Validation loss: 2.4283274604428198

Epoch: 5| Step: 8
Training loss: 2.314131259918213
Validation loss: 2.4347503774909565

Epoch: 5| Step: 9
Training loss: 2.001901388168335
Validation loss: 2.44281760338814

Epoch: 5| Step: 10
Training loss: 2.7640702724456787
Validation loss: 2.4307888400170112

Epoch: 120| Step: 0
Training loss: 2.483694076538086
Validation loss: 2.4198576070929088

Epoch: 5| Step: 1
Training loss: 2.259474039077759
Validation loss: 2.414042680494247

Epoch: 5| Step: 2
Training loss: 2.481624126434326
Validation loss: 2.405143294283139

Epoch: 5| Step: 3
Training loss: 3.2817413806915283
Validation loss: 2.403518969012845

Epoch: 5| Step: 4
Training loss: 3.33793568611145
Validation loss: 2.3995518556205173

Epoch: 5| Step: 5
Training loss: 3.0098683834075928
Validation loss: 2.3983142939946984

Epoch: 5| Step: 6
Training loss: 2.8270440101623535
Validation loss: 2.4008049118903374

Epoch: 5| Step: 7
Training loss: 2.1442275047302246
Validation loss: 2.4086224904624363

Epoch: 5| Step: 8
Training loss: 2.331822633743286
Validation loss: 2.4048738018158944

Epoch: 5| Step: 9
Training loss: 2.5520071983337402
Validation loss: 2.4041465226040093

Epoch: 5| Step: 10
Training loss: 2.3382720947265625
Validation loss: 2.409482027894707

Epoch: 121| Step: 0
Training loss: 3.393550157546997
Validation loss: 2.4091158143935667

Epoch: 5| Step: 1
Training loss: 1.8628208637237549
Validation loss: 2.4050728633839595

Epoch: 5| Step: 2
Training loss: 2.9652373790740967
Validation loss: 2.409761082741522

Epoch: 5| Step: 3
Training loss: 2.483489990234375
Validation loss: 2.409869137630668

Epoch: 5| Step: 4
Training loss: 2.8920013904571533
Validation loss: 2.4149767429597917

Epoch: 5| Step: 5
Training loss: 2.6808013916015625
Validation loss: 2.422845364898764

Epoch: 5| Step: 6
Training loss: 2.899604320526123
Validation loss: 2.413327178647441

Epoch: 5| Step: 7
Training loss: 2.2103800773620605
Validation loss: 2.4199585837702595

Epoch: 5| Step: 8
Training loss: 2.9810688495635986
Validation loss: 2.431045091280373

Epoch: 5| Step: 9
Training loss: 2.111999034881592
Validation loss: 2.4553257291034987

Epoch: 5| Step: 10
Training loss: 2.402053117752075
Validation loss: 2.476302085384246

Epoch: 122| Step: 0
Training loss: 3.104501247406006
Validation loss: 2.491264250970656

Epoch: 5| Step: 1
Training loss: 2.5917365550994873
Validation loss: 2.492457410340668

Epoch: 5| Step: 2
Training loss: 2.5995051860809326
Validation loss: 2.4720422337132115

Epoch: 5| Step: 3
Training loss: 2.6611921787261963
Validation loss: 2.425774689643614

Epoch: 5| Step: 4
Training loss: 2.4856719970703125
Validation loss: 2.4026811481803976

Epoch: 5| Step: 5
Training loss: 2.0663342475891113
Validation loss: 2.3882979372496247

Epoch: 5| Step: 6
Training loss: 2.693209171295166
Validation loss: 2.3860049786106234

Epoch: 5| Step: 7
Training loss: 2.8262510299682617
Validation loss: 2.38045762431237

Epoch: 5| Step: 8
Training loss: 2.49770450592041
Validation loss: 2.3835854863607757

Epoch: 5| Step: 9
Training loss: 2.6619367599487305
Validation loss: 2.3859998641475553

Epoch: 5| Step: 10
Training loss: 3.018763303756714
Validation loss: 2.386630722271499

Epoch: 123| Step: 0
Training loss: 2.203242540359497
Validation loss: 2.386788275934035

Epoch: 5| Step: 1
Training loss: 2.46710467338562
Validation loss: 2.385643459135486

Epoch: 5| Step: 2
Training loss: 2.6063461303710938
Validation loss: 2.3910039368496148

Epoch: 5| Step: 3
Training loss: 3.4992918968200684
Validation loss: 2.3925277007523404

Epoch: 5| Step: 4
Training loss: 2.9796762466430664
Validation loss: 2.388898164995255

Epoch: 5| Step: 5
Training loss: 1.7225345373153687
Validation loss: 2.3882899258726384

Epoch: 5| Step: 6
Training loss: 3.3628666400909424
Validation loss: 2.3868964692597747

Epoch: 5| Step: 7
Training loss: 2.319218635559082
Validation loss: 2.383719974948514

Epoch: 5| Step: 8
Training loss: 2.612166166305542
Validation loss: 2.379083151458412

Epoch: 5| Step: 9
Training loss: 3.0890355110168457
Validation loss: 2.376387942221857

Epoch: 5| Step: 10
Training loss: 2.128857374191284
Validation loss: 2.376137161767611

Epoch: 124| Step: 0
Training loss: 2.7769463062286377
Validation loss: 2.3790446994125203

Epoch: 5| Step: 1
Training loss: 2.5303568840026855
Validation loss: 2.3836416890544276

Epoch: 5| Step: 2
Training loss: 2.3129913806915283
Validation loss: 2.3942523335897796

Epoch: 5| Step: 3
Training loss: 2.594229221343994
Validation loss: 2.3993922895000828

Epoch: 5| Step: 4
Training loss: 2.4846255779266357
Validation loss: 2.411672281962569

Epoch: 5| Step: 5
Training loss: 2.9535324573516846
Validation loss: 2.4129138710678264

Epoch: 5| Step: 6
Training loss: 2.540679931640625
Validation loss: 2.420789767337102

Epoch: 5| Step: 7
Training loss: 2.148210048675537
Validation loss: 2.4309173348129436

Epoch: 5| Step: 8
Training loss: 3.1046485900878906
Validation loss: 2.419241359156947

Epoch: 5| Step: 9
Training loss: 2.4008290767669678
Validation loss: 2.4016465551109722

Epoch: 5| Step: 10
Training loss: 3.152738571166992
Validation loss: 2.3936155175649994

Epoch: 125| Step: 0
Training loss: 2.7128288745880127
Validation loss: 2.38095199677252

Epoch: 5| Step: 1
Training loss: 1.9804487228393555
Validation loss: 2.383498945543843

Epoch: 5| Step: 2
Training loss: 2.4435300827026367
Validation loss: 2.3729915618896484

Epoch: 5| Step: 3
Training loss: 2.4960525035858154
Validation loss: 2.3765163690813127

Epoch: 5| Step: 4
Training loss: 2.4277446269989014
Validation loss: 2.374052047729492

Epoch: 5| Step: 5
Training loss: 2.5686168670654297
Validation loss: 2.379079980234946

Epoch: 5| Step: 6
Training loss: 2.699613571166992
Validation loss: 2.385279663147465

Epoch: 5| Step: 7
Training loss: 2.815474271774292
Validation loss: 2.3855869872595674

Epoch: 5| Step: 8
Training loss: 3.2151546478271484
Validation loss: 2.387175295942573

Epoch: 5| Step: 9
Training loss: 3.159827470779419
Validation loss: 2.385257790165563

Epoch: 5| Step: 10
Training loss: 2.4940454959869385
Validation loss: 2.384134372075399

Epoch: 126| Step: 0
Training loss: 3.1890640258789062
Validation loss: 2.384675043885426

Epoch: 5| Step: 1
Training loss: 2.1255645751953125
Validation loss: 2.3797061366419636

Epoch: 5| Step: 2
Training loss: 2.9408986568450928
Validation loss: 2.380462654175297

Epoch: 5| Step: 3
Training loss: 2.5294647216796875
Validation loss: 2.379460706505724

Epoch: 5| Step: 4
Training loss: 1.4938360452651978
Validation loss: 2.3810901718754924

Epoch: 5| Step: 5
Training loss: 2.3462698459625244
Validation loss: 2.392374102787305

Epoch: 5| Step: 6
Training loss: 2.309035539627075
Validation loss: 2.3988599520857616

Epoch: 5| Step: 7
Training loss: 3.3228001594543457
Validation loss: 2.4117823416186916

Epoch: 5| Step: 8
Training loss: 2.998622179031372
Validation loss: 2.4145316000907653

Epoch: 5| Step: 9
Training loss: 2.7539892196655273
Validation loss: 2.4265364959675777

Epoch: 5| Step: 10
Training loss: 2.879976272583008
Validation loss: 2.431644283315187

Epoch: 127| Step: 0
Training loss: 3.0590367317199707
Validation loss: 2.428772000856297

Epoch: 5| Step: 1
Training loss: 2.971383810043335
Validation loss: 2.428119582514609

Epoch: 5| Step: 2
Training loss: 2.4114160537719727
Validation loss: 2.429100509612791

Epoch: 5| Step: 3
Training loss: 2.7251524925231934
Validation loss: 2.4288465361441336

Epoch: 5| Step: 4
Training loss: 2.171292304992676
Validation loss: 2.4335043238055323

Epoch: 5| Step: 5
Training loss: 2.268507957458496
Validation loss: 2.4137663866883967

Epoch: 5| Step: 6
Training loss: 2.527979850769043
Validation loss: 2.4080121837636477

Epoch: 5| Step: 7
Training loss: 2.923363447189331
Validation loss: 2.390212494839904

Epoch: 5| Step: 8
Training loss: 2.5988621711730957
Validation loss: 2.3926805885889197

Epoch: 5| Step: 9
Training loss: 2.3781440258026123
Validation loss: 2.387157308158054

Epoch: 5| Step: 10
Training loss: 2.903531312942505
Validation loss: 2.3821341068513933

Epoch: 128| Step: 0
Training loss: 2.700260877609253
Validation loss: 2.385969804179284

Epoch: 5| Step: 1
Training loss: 2.5712709426879883
Validation loss: 2.3765454856298303

Epoch: 5| Step: 2
Training loss: 2.6020874977111816
Validation loss: 2.3778112421753588

Epoch: 5| Step: 3
Training loss: 2.752943992614746
Validation loss: 2.3778602077114965

Epoch: 5| Step: 4
Training loss: 2.7950291633605957
Validation loss: 2.382255957972619

Epoch: 5| Step: 5
Training loss: 2.356398820877075
Validation loss: 2.3825979617334183

Epoch: 5| Step: 6
Training loss: 2.3713042736053467
Validation loss: 2.383600850259104

Epoch: 5| Step: 7
Training loss: 2.6381912231445312
Validation loss: 2.3899533133352957

Epoch: 5| Step: 8
Training loss: 3.004972457885742
Validation loss: 2.3997995981606106

Epoch: 5| Step: 9
Training loss: 2.46028470993042
Validation loss: 2.3995614641456195

Epoch: 5| Step: 10
Training loss: 2.679856300354004
Validation loss: 2.398432634210074

Epoch: 129| Step: 0
Training loss: 2.3873817920684814
Validation loss: 2.3959848957677043

Epoch: 5| Step: 1
Training loss: 2.0880930423736572
Validation loss: 2.3962182742293163

Epoch: 5| Step: 2
Training loss: 2.8339126110076904
Validation loss: 2.3949548698240712

Epoch: 5| Step: 3
Training loss: 2.4976305961608887
Validation loss: 2.390081831203994

Epoch: 5| Step: 4
Training loss: 2.9669182300567627
Validation loss: 2.397508999352814

Epoch: 5| Step: 5
Training loss: 2.9127848148345947
Validation loss: 2.403243318680794

Epoch: 5| Step: 6
Training loss: 2.1915524005889893
Validation loss: 2.4018674204426427

Epoch: 5| Step: 7
Training loss: 2.81318998336792
Validation loss: 2.408940392155801

Epoch: 5| Step: 8
Training loss: 2.7891910076141357
Validation loss: 2.410728552008188

Epoch: 5| Step: 9
Training loss: 2.9443957805633545
Validation loss: 2.4117059758914414

Epoch: 5| Step: 10
Training loss: 2.2359888553619385
Validation loss: 2.3975173645122076

Epoch: 130| Step: 0
Training loss: 2.508047103881836
Validation loss: 2.3974788547844015

Epoch: 5| Step: 1
Training loss: 2.7009894847869873
Validation loss: 2.3980451630007837

Epoch: 5| Step: 2
Training loss: 2.7424533367156982
Validation loss: 2.3950448472012758

Epoch: 5| Step: 3
Training loss: 2.5089662075042725
Validation loss: 2.385706760550058

Epoch: 5| Step: 4
Training loss: 3.110029697418213
Validation loss: 2.379659870619415

Epoch: 5| Step: 5
Training loss: 2.4007201194763184
Validation loss: 2.380700775372085

Epoch: 5| Step: 6
Training loss: 2.392322301864624
Validation loss: 2.37543148122808

Epoch: 5| Step: 7
Training loss: 2.0832290649414062
Validation loss: 2.375704498701198

Epoch: 5| Step: 8
Training loss: 2.7686190605163574
Validation loss: 2.3762113714730866

Epoch: 5| Step: 9
Training loss: 3.0383596420288086
Validation loss: 2.3772973552826913

Epoch: 5| Step: 10
Training loss: 2.4355762004852295
Validation loss: 2.37480697067835

Epoch: 131| Step: 0
Training loss: 2.3928706645965576
Validation loss: 2.3807970554597917

Epoch: 5| Step: 1
Training loss: 2.7504372596740723
Validation loss: 2.381445607831401

Epoch: 5| Step: 2
Training loss: 2.9059088230133057
Validation loss: 2.384292056483607

Epoch: 5| Step: 3
Training loss: 2.9898922443389893
Validation loss: 2.385123457959903

Epoch: 5| Step: 4
Training loss: 2.691964864730835
Validation loss: 2.3886036052498767

Epoch: 5| Step: 5
Training loss: 2.714351177215576
Validation loss: 2.3951087305622716

Epoch: 5| Step: 6
Training loss: 3.0549004077911377
Validation loss: 2.400851203549293

Epoch: 5| Step: 7
Training loss: 2.3761894702911377
Validation loss: 2.4013244618651686

Epoch: 5| Step: 8
Training loss: 2.6158995628356934
Validation loss: 2.402287221723987

Epoch: 5| Step: 9
Training loss: 1.6744180917739868
Validation loss: 2.4154620221866074

Epoch: 5| Step: 10
Training loss: 2.5381228923797607
Validation loss: 2.405962359520697

Epoch: 132| Step: 0
Training loss: 1.938631296157837
Validation loss: 2.399621322590818

Epoch: 5| Step: 1
Training loss: 3.0127758979797363
Validation loss: 2.3995407730020504

Epoch: 5| Step: 2
Training loss: 2.512868642807007
Validation loss: 2.396015972219488

Epoch: 5| Step: 3
Training loss: 3.079371213912964
Validation loss: 2.408284283453418

Epoch: 5| Step: 4
Training loss: 2.665168285369873
Validation loss: 2.410449053651543

Epoch: 5| Step: 5
Training loss: 1.719408392906189
Validation loss: 2.425313224074661

Epoch: 5| Step: 6
Training loss: 3.1762053966522217
Validation loss: 2.414672420870873

Epoch: 5| Step: 7
Training loss: 2.5394749641418457
Validation loss: 2.4164433094762985

Epoch: 5| Step: 8
Training loss: 2.3852055072784424
Validation loss: 2.4151721795399985

Epoch: 5| Step: 9
Training loss: 2.764455795288086
Validation loss: 2.4025007294070337

Epoch: 5| Step: 10
Training loss: 3.049968957901001
Validation loss: 2.3977472320679696

Epoch: 133| Step: 0
Training loss: 1.928829550743103
Validation loss: 2.3975488908829226

Epoch: 5| Step: 1
Training loss: 2.25380277633667
Validation loss: 2.390632647340016

Epoch: 5| Step: 2
Training loss: 2.2240657806396484
Validation loss: 2.3949343055807133

Epoch: 5| Step: 3
Training loss: 3.0175259113311768
Validation loss: 2.3835840994311916

Epoch: 5| Step: 4
Training loss: 2.570312976837158
Validation loss: 2.3850363275056243

Epoch: 5| Step: 5
Training loss: 2.417346477508545
Validation loss: 2.3885953503270305

Epoch: 5| Step: 6
Training loss: 2.541688919067383
Validation loss: 2.3792892322745374

Epoch: 5| Step: 7
Training loss: 2.5767624378204346
Validation loss: 2.3785101726490963

Epoch: 5| Step: 8
Training loss: 2.8304080963134766
Validation loss: 2.3746920631777857

Epoch: 5| Step: 9
Training loss: 3.002429246902466
Validation loss: 2.375979497868528

Epoch: 5| Step: 10
Training loss: 3.244659662246704
Validation loss: 2.376626514619397

Epoch: 134| Step: 0
Training loss: 2.606278896331787
Validation loss: 2.370999604143122

Epoch: 5| Step: 1
Training loss: 2.7966926097869873
Validation loss: 2.3709309895833335

Epoch: 5| Step: 2
Training loss: 2.141295909881592
Validation loss: 2.3747661690558157

Epoch: 5| Step: 3
Training loss: 2.746382713317871
Validation loss: 2.3673864538951586

Epoch: 5| Step: 4
Training loss: 2.802480936050415
Validation loss: 2.374527851740519

Epoch: 5| Step: 5
Training loss: 2.0778183937072754
Validation loss: 2.378701533040693

Epoch: 5| Step: 6
Training loss: 2.6204030513763428
Validation loss: 2.3818377461484683

Epoch: 5| Step: 7
Training loss: 2.753995180130005
Validation loss: 2.376056008441474

Epoch: 5| Step: 8
Training loss: 2.7413716316223145
Validation loss: 2.3822530674678024

Epoch: 5| Step: 9
Training loss: 2.865480422973633
Validation loss: 2.388586082766133

Epoch: 5| Step: 10
Training loss: 2.3653903007507324
Validation loss: 2.396775411021325

Epoch: 135| Step: 0
Training loss: 3.2644011974334717
Validation loss: 2.3968290667380057

Epoch: 5| Step: 1
Training loss: 2.429898738861084
Validation loss: 2.399651288986206

Epoch: 5| Step: 2
Training loss: 2.242345094680786
Validation loss: 2.395348874471521

Epoch: 5| Step: 3
Training loss: 2.5446505546569824
Validation loss: 2.3885794890824186

Epoch: 5| Step: 4
Training loss: 2.2764573097229004
Validation loss: 2.376959871220332

Epoch: 5| Step: 5
Training loss: 2.893091917037964
Validation loss: 2.3829527080699964

Epoch: 5| Step: 6
Training loss: 2.493623733520508
Validation loss: 2.3763019551513014

Epoch: 5| Step: 7
Training loss: 2.601219892501831
Validation loss: 2.3795124971738426

Epoch: 5| Step: 8
Training loss: 2.6347103118896484
Validation loss: 2.382797074574296

Epoch: 5| Step: 9
Training loss: 2.5563712120056152
Validation loss: 2.375907333948279

Epoch: 5| Step: 10
Training loss: 2.5826425552368164
Validation loss: 2.3776791505916144

Epoch: 136| Step: 0
Training loss: 2.083437204360962
Validation loss: 2.3717577585610012

Epoch: 5| Step: 1
Training loss: 2.5913829803466797
Validation loss: 2.3791226392151206

Epoch: 5| Step: 2
Training loss: 2.6980528831481934
Validation loss: 2.3787891070048013

Epoch: 5| Step: 3
Training loss: 2.9418084621429443
Validation loss: 2.3844678094310146

Epoch: 5| Step: 4
Training loss: 3.3251609802246094
Validation loss: 2.3890698776450208

Epoch: 5| Step: 5
Training loss: 2.3814008235931396
Validation loss: 2.390445150354857

Epoch: 5| Step: 6
Training loss: 2.6628642082214355
Validation loss: 2.3833535845561693

Epoch: 5| Step: 7
Training loss: 1.9436689615249634
Validation loss: 2.3837208004407984

Epoch: 5| Step: 8
Training loss: 2.1891424655914307
Validation loss: 2.3765545916813675

Epoch: 5| Step: 9
Training loss: 2.8148183822631836
Validation loss: 2.379002389087472

Epoch: 5| Step: 10
Training loss: 3.0318777561187744
Validation loss: 2.373105336261052

Epoch: 137| Step: 0
Training loss: 2.7004871368408203
Validation loss: 2.3672901404801237

Epoch: 5| Step: 1
Training loss: 2.6508753299713135
Validation loss: 2.3709302179275022

Epoch: 5| Step: 2
Training loss: 1.6154483556747437
Validation loss: 2.3784827904034684

Epoch: 5| Step: 3
Training loss: 2.2052409648895264
Validation loss: 2.3771748312057985

Epoch: 5| Step: 4
Training loss: 2.7438957691192627
Validation loss: 2.3798915442600044

Epoch: 5| Step: 5
Training loss: 2.7066636085510254
Validation loss: 2.38050437742664

Epoch: 5| Step: 6
Training loss: 2.852189779281616
Validation loss: 2.3783446845187934

Epoch: 5| Step: 7
Training loss: 2.8641607761383057
Validation loss: 2.3902214945003553

Epoch: 5| Step: 8
Training loss: 2.521813154220581
Validation loss: 2.3873292451263755

Epoch: 5| Step: 9
Training loss: 2.636688232421875
Validation loss: 2.3876360231830227

Epoch: 5| Step: 10
Training loss: 3.0154497623443604
Validation loss: 2.391508194708055

Epoch: 138| Step: 0
Training loss: 2.7971229553222656
Validation loss: 2.3831364647034676

Epoch: 5| Step: 1
Training loss: 1.9153763055801392
Validation loss: 2.370834178822015

Epoch: 5| Step: 2
Training loss: 3.1129469871520996
Validation loss: 2.3658181441727506

Epoch: 5| Step: 3
Training loss: 2.4014506340026855
Validation loss: 2.3788522597282165

Epoch: 5| Step: 4
Training loss: 2.157480239868164
Validation loss: 2.3637964494766726

Epoch: 5| Step: 5
Training loss: 2.16304349899292
Validation loss: 2.3612997275526806

Epoch: 5| Step: 6
Training loss: 2.8849470615386963
Validation loss: 2.3697137268640662

Epoch: 5| Step: 7
Training loss: 2.9357800483703613
Validation loss: 2.3737823629892

Epoch: 5| Step: 8
Training loss: 2.7257308959960938
Validation loss: 2.369932310555571

Epoch: 5| Step: 9
Training loss: 2.960707664489746
Validation loss: 2.373852663142707

Epoch: 5| Step: 10
Training loss: 2.2612574100494385
Validation loss: 2.3730409299173663

Epoch: 139| Step: 0
Training loss: 2.2464325428009033
Validation loss: 2.3769594571923696

Epoch: 5| Step: 1
Training loss: 2.673644781112671
Validation loss: 2.3712143257100093

Epoch: 5| Step: 2
Training loss: 2.212244987487793
Validation loss: 2.368039023491644

Epoch: 5| Step: 3
Training loss: 2.91209077835083
Validation loss: 2.36471906528678

Epoch: 5| Step: 4
Training loss: 2.7764947414398193
Validation loss: 2.361972103836716

Epoch: 5| Step: 5
Training loss: 3.523937940597534
Validation loss: 2.350511884176603

Epoch: 5| Step: 6
Training loss: 1.9387471675872803
Validation loss: 2.355330410824027

Epoch: 5| Step: 7
Training loss: 2.8753719329833984
Validation loss: 2.3585114145791657

Epoch: 5| Step: 8
Training loss: 2.3547890186309814
Validation loss: 2.360773332657353

Epoch: 5| Step: 9
Training loss: 2.440037488937378
Validation loss: 2.357048790941956

Epoch: 5| Step: 10
Training loss: 2.4872426986694336
Validation loss: 2.3537376285881124

Epoch: 140| Step: 0
Training loss: 2.202357053756714
Validation loss: 2.366900351739699

Epoch: 5| Step: 1
Training loss: 2.4785428047180176
Validation loss: 2.382326285044352

Epoch: 5| Step: 2
Training loss: 2.4842355251312256
Validation loss: 2.4043140462649766

Epoch: 5| Step: 3
Training loss: 2.605804920196533
Validation loss: 2.437832388826596

Epoch: 5| Step: 4
Training loss: 2.143430709838867
Validation loss: 2.4599590711696173

Epoch: 5| Step: 5
Training loss: 2.181764602661133
Validation loss: 2.4593440127629105

Epoch: 5| Step: 6
Training loss: 2.699887752532959
Validation loss: 2.4607401791439263

Epoch: 5| Step: 7
Training loss: 2.865417242050171
Validation loss: 2.441790116730557

Epoch: 5| Step: 8
Training loss: 2.786503314971924
Validation loss: 2.430661778296194

Epoch: 5| Step: 9
Training loss: 2.9179158210754395
Validation loss: 2.417252134251338

Epoch: 5| Step: 10
Training loss: 3.2437915802001953
Validation loss: 2.3921135856259252

Epoch: 141| Step: 0
Training loss: 2.4731478691101074
Validation loss: 2.3810321028514574

Epoch: 5| Step: 1
Training loss: 2.231118679046631
Validation loss: 2.373379220244705

Epoch: 5| Step: 2
Training loss: 2.8450582027435303
Validation loss: 2.3551007368231334

Epoch: 5| Step: 3
Training loss: 2.9004197120666504
Validation loss: 2.3592500558463474

Epoch: 5| Step: 4
Training loss: 2.309905529022217
Validation loss: 2.367165239908362

Epoch: 5| Step: 5
Training loss: 2.889845609664917
Validation loss: 2.360520903782178

Epoch: 5| Step: 6
Training loss: 3.435450315475464
Validation loss: 2.356672938152026

Epoch: 5| Step: 7
Training loss: 2.159787893295288
Validation loss: 2.3470821098614763

Epoch: 5| Step: 8
Training loss: 2.236807346343994
Validation loss: 2.3487551622493292

Epoch: 5| Step: 9
Training loss: 2.58691143989563
Validation loss: 2.353263091015559

Epoch: 5| Step: 10
Training loss: 2.2484943866729736
Validation loss: 2.348234348399665

Epoch: 142| Step: 0
Training loss: 2.6023950576782227
Validation loss: 2.353555599848429

Epoch: 5| Step: 1
Training loss: 2.047516345977783
Validation loss: 2.3484765227122972

Epoch: 5| Step: 2
Training loss: 2.327467441558838
Validation loss: 2.366361077113818

Epoch: 5| Step: 3
Training loss: 2.422541856765747
Validation loss: 2.3808895311047955

Epoch: 5| Step: 4
Training loss: 3.1072120666503906
Validation loss: 2.384837786356608

Epoch: 5| Step: 5
Training loss: 2.283113718032837
Validation loss: 2.3968766427809194

Epoch: 5| Step: 6
Training loss: 2.491992235183716
Validation loss: 2.388721953156174

Epoch: 5| Step: 7
Training loss: 3.042579174041748
Validation loss: 2.388387792853899

Epoch: 5| Step: 8
Training loss: 2.891383647918701
Validation loss: 2.378544653615644

Epoch: 5| Step: 9
Training loss: 2.9020302295684814
Validation loss: 2.381398957262757

Epoch: 5| Step: 10
Training loss: 2.235166549682617
Validation loss: 2.364717314320226

Epoch: 143| Step: 0
Training loss: 2.916234254837036
Validation loss: 2.3733235918065554

Epoch: 5| Step: 1
Training loss: 2.7613956928253174
Validation loss: 2.3604625501940326

Epoch: 5| Step: 2
Training loss: 3.178443431854248
Validation loss: 2.354154107391193

Epoch: 5| Step: 3
Training loss: 2.616037130355835
Validation loss: 2.3683768087817776

Epoch: 5| Step: 4
Training loss: 2.3564822673797607
Validation loss: 2.3635780247308875

Epoch: 5| Step: 5
Training loss: 2.635866641998291
Validation loss: 2.3676215987051688

Epoch: 5| Step: 6
Training loss: 2.9770894050598145
Validation loss: 2.374359679478471

Epoch: 5| Step: 7
Training loss: 1.9053113460540771
Validation loss: 2.37577514238255

Epoch: 5| Step: 8
Training loss: 1.9956958293914795
Validation loss: 2.369514047458608

Epoch: 5| Step: 9
Training loss: 2.1300549507141113
Validation loss: 2.3718470578552573

Epoch: 5| Step: 10
Training loss: 2.8117127418518066
Validation loss: 2.368117170949136

Epoch: 144| Step: 0
Training loss: 2.306093454360962
Validation loss: 2.3693756159915718

Epoch: 5| Step: 1
Training loss: 2.540391445159912
Validation loss: 2.368364590470509

Epoch: 5| Step: 2
Training loss: 2.6582577228546143
Validation loss: 2.380813019250029

Epoch: 5| Step: 3
Training loss: 2.497537136077881
Validation loss: 2.3775447927495486

Epoch: 5| Step: 4
Training loss: 2.6781227588653564
Validation loss: 2.3668661694372854

Epoch: 5| Step: 5
Training loss: 2.1653389930725098
Validation loss: 2.3675811213831746

Epoch: 5| Step: 6
Training loss: 2.395171880722046
Validation loss: 2.3612499685697657

Epoch: 5| Step: 7
Training loss: 2.8181614875793457
Validation loss: 2.3606678337179203

Epoch: 5| Step: 8
Training loss: 2.7082066535949707
Validation loss: 2.3627451312157417

Epoch: 5| Step: 9
Training loss: 2.827565908432007
Validation loss: 2.3707390985181256

Epoch: 5| Step: 10
Training loss: 2.6229419708251953
Validation loss: 2.3581929283757366

Epoch: 145| Step: 0
Training loss: 2.1128487586975098
Validation loss: 2.368395802795246

Epoch: 5| Step: 1
Training loss: 2.436760425567627
Validation loss: 2.366858502869965

Epoch: 5| Step: 2
Training loss: 2.6995699405670166
Validation loss: 2.364010384005885

Epoch: 5| Step: 3
Training loss: 2.4614012241363525
Validation loss: 2.3679036427569646

Epoch: 5| Step: 4
Training loss: 2.5371429920196533
Validation loss: 2.360929940336494

Epoch: 5| Step: 5
Training loss: 1.7623838186264038
Validation loss: 2.3811378632822344

Epoch: 5| Step: 6
Training loss: 2.3875458240509033
Validation loss: 2.3704740462764615

Epoch: 5| Step: 7
Training loss: 2.795900344848633
Validation loss: 2.3760836560239076

Epoch: 5| Step: 8
Training loss: 2.8330771923065186
Validation loss: 2.3729519228781424

Epoch: 5| Step: 9
Training loss: 3.6033637523651123
Validation loss: 2.3792378466616393

Epoch: 5| Step: 10
Training loss: 2.5639150142669678
Validation loss: 2.374056513591479

Epoch: 146| Step: 0
Training loss: 2.4031593799591064
Validation loss: 2.357267584851993

Epoch: 5| Step: 1
Training loss: 2.0481996536254883
Validation loss: 2.3401838502576275

Epoch: 5| Step: 2
Training loss: 3.1592345237731934
Validation loss: 2.3387576380083637

Epoch: 5| Step: 3
Training loss: 2.889094114303589
Validation loss: 2.3296659223494993

Epoch: 5| Step: 4
Training loss: 2.8980464935302734
Validation loss: 2.34285980655301

Epoch: 5| Step: 5
Training loss: 2.1934475898742676
Validation loss: 2.3333275446327786

Epoch: 5| Step: 6
Training loss: 2.7184958457946777
Validation loss: 2.3427524105195077

Epoch: 5| Step: 7
Training loss: 2.5565309524536133
Validation loss: 2.3464478574773318

Epoch: 5| Step: 8
Training loss: 2.3266186714172363
Validation loss: 2.353082315896147

Epoch: 5| Step: 9
Training loss: 2.3116040229797363
Validation loss: 2.353376591077415

Epoch: 5| Step: 10
Training loss: 2.759161949157715
Validation loss: 2.3611100463457007

Epoch: 147| Step: 0
Training loss: 2.5873827934265137
Validation loss: 2.3623080099782636

Epoch: 5| Step: 1
Training loss: 2.1758995056152344
Validation loss: 2.3615826791332615

Epoch: 5| Step: 2
Training loss: 2.318044424057007
Validation loss: 2.3629036000979844

Epoch: 5| Step: 3
Training loss: 2.5260863304138184
Validation loss: 2.366602531043432

Epoch: 5| Step: 4
Training loss: 2.5941901206970215
Validation loss: 2.3516557139735066

Epoch: 5| Step: 5
Training loss: 2.49922513961792
Validation loss: 2.3497964553935553

Epoch: 5| Step: 6
Training loss: 2.6741342544555664
Validation loss: 2.36816345748081

Epoch: 5| Step: 7
Training loss: 2.1425232887268066
Validation loss: 2.399290333512009

Epoch: 5| Step: 8
Training loss: 2.357725143432617
Validation loss: 2.4158896835901404

Epoch: 5| Step: 9
Training loss: 2.9266819953918457
Validation loss: 2.4312982636113323

Epoch: 5| Step: 10
Training loss: 3.4849016666412354
Validation loss: 2.417057386008642

Epoch: 148| Step: 0
Training loss: 2.2439353466033936
Validation loss: 2.3843210179318666

Epoch: 5| Step: 1
Training loss: 3.131218671798706
Validation loss: 2.366940124060518

Epoch: 5| Step: 2
Training loss: 1.9665638208389282
Validation loss: 2.3650026398320354

Epoch: 5| Step: 3
Training loss: 3.271331787109375
Validation loss: 2.3654436731851227

Epoch: 5| Step: 4
Training loss: 3.0158143043518066
Validation loss: 2.3636708003218456

Epoch: 5| Step: 5
Training loss: 3.184985637664795
Validation loss: 2.363641426127444

Epoch: 5| Step: 6
Training loss: 2.1742401123046875
Validation loss: 2.347274693109656

Epoch: 5| Step: 7
Training loss: 2.086108684539795
Validation loss: 2.3371006083744827

Epoch: 5| Step: 8
Training loss: 2.7567625045776367
Validation loss: 2.330608816557033

Epoch: 5| Step: 9
Training loss: 2.3182265758514404
Validation loss: 2.328213163601455

Epoch: 5| Step: 10
Training loss: 1.9528014659881592
Validation loss: 2.3285014244817916

Epoch: 149| Step: 0
Training loss: 3.102316379547119
Validation loss: 2.3307623709401777

Epoch: 5| Step: 1
Training loss: 2.656481981277466
Validation loss: 2.3280905959426716

Epoch: 5| Step: 2
Training loss: 2.7640624046325684
Validation loss: 2.342176696305634

Epoch: 5| Step: 3
Training loss: 2.250251054763794
Validation loss: 2.344468116760254

Epoch: 5| Step: 4
Training loss: 3.014572858810425
Validation loss: 2.344327788199148

Epoch: 5| Step: 5
Training loss: 2.442894458770752
Validation loss: 2.359286013469901

Epoch: 5| Step: 6
Training loss: 1.756020188331604
Validation loss: 2.3793170349572295

Epoch: 5| Step: 7
Training loss: 3.017650604248047
Validation loss: 2.378129692487819

Epoch: 5| Step: 8
Training loss: 2.1455118656158447
Validation loss: 2.392452750154721

Epoch: 5| Step: 9
Training loss: 1.9613370895385742
Validation loss: 2.3940499008342786

Epoch: 5| Step: 10
Training loss: 3.205531358718872
Validation loss: 2.399097857936736

Epoch: 150| Step: 0
Training loss: 2.117682933807373
Validation loss: 2.3805502307030464

Epoch: 5| Step: 1
Training loss: 2.383118152618408
Validation loss: 2.3702725569407144

Epoch: 5| Step: 2
Training loss: 2.8383431434631348
Validation loss: 2.353924507735878

Epoch: 5| Step: 3
Training loss: 3.2651572227478027
Validation loss: 2.377474625905355

Epoch: 5| Step: 4
Training loss: 2.5179882049560547
Validation loss: 2.4014996918298865

Epoch: 5| Step: 5
Training loss: 2.6463656425476074
Validation loss: 2.4109676832793863

Epoch: 5| Step: 6
Training loss: 2.70538067817688
Validation loss: 2.416826252014406

Epoch: 5| Step: 7
Training loss: 2.341791868209839
Validation loss: 2.377648147203589

Epoch: 5| Step: 8
Training loss: 2.1541965007781982
Validation loss: 2.3469871397941344

Epoch: 5| Step: 9
Training loss: 2.9840831756591797
Validation loss: 2.33914025111865

Epoch: 5| Step: 10
Training loss: 2.091348648071289
Validation loss: 2.3504982943175943

Epoch: 151| Step: 0
Training loss: 2.7276387214660645
Validation loss: 2.340621204786403

Epoch: 5| Step: 1
Training loss: 2.3520660400390625
Validation loss: 2.345332803264741

Epoch: 5| Step: 2
Training loss: 2.0762386322021484
Validation loss: 2.3616151937874417

Epoch: 5| Step: 3
Training loss: 2.9006752967834473
Validation loss: 2.375016559836685

Epoch: 5| Step: 4
Training loss: 2.8285553455352783
Validation loss: 2.423788703897948

Epoch: 5| Step: 5
Training loss: 3.1419315338134766
Validation loss: 2.411140452149094

Epoch: 5| Step: 6
Training loss: 2.2536442279815674
Validation loss: 2.401736723479404

Epoch: 5| Step: 7
Training loss: 2.1507720947265625
Validation loss: 2.360267395614296

Epoch: 5| Step: 8
Training loss: 2.145285129547119
Validation loss: 2.3457726663158787

Epoch: 5| Step: 9
Training loss: 2.742124080657959
Validation loss: 2.3417244777884534

Epoch: 5| Step: 10
Training loss: 2.7104625701904297
Validation loss: 2.3563758480933403

Epoch: 152| Step: 0
Training loss: 2.75443959236145
Validation loss: 2.3792226673454366

Epoch: 5| Step: 1
Training loss: 2.7121009826660156
Validation loss: 2.369902863297411

Epoch: 5| Step: 2
Training loss: 2.052210569381714
Validation loss: 2.368272419898741

Epoch: 5| Step: 3
Training loss: 2.718966007232666
Validation loss: 2.347035382383613

Epoch: 5| Step: 4
Training loss: 2.6155972480773926
Validation loss: 2.349665141874744

Epoch: 5| Step: 5
Training loss: 2.3220763206481934
Validation loss: 2.341157319725201

Epoch: 5| Step: 6
Training loss: 2.953963041305542
Validation loss: 2.344693991445726

Epoch: 5| Step: 7
Training loss: 2.2863099575042725
Validation loss: 2.3505125609777306

Epoch: 5| Step: 8
Training loss: 2.697943925857544
Validation loss: 2.349275440298101

Epoch: 5| Step: 9
Training loss: 2.5327486991882324
Validation loss: 2.3465059265013664

Epoch: 5| Step: 10
Training loss: 2.5695903301239014
Validation loss: 2.3543002220892135

Epoch: 153| Step: 0
Training loss: 3.3794798851013184
Validation loss: 2.3530772783422984

Epoch: 5| Step: 1
Training loss: 1.857680082321167
Validation loss: 2.356873973723381

Epoch: 5| Step: 2
Training loss: 2.644986391067505
Validation loss: 2.3564927654881633

Epoch: 5| Step: 3
Training loss: 2.2410385608673096
Validation loss: 2.3656964532790647

Epoch: 5| Step: 4
Training loss: 3.2138569355010986
Validation loss: 2.381848504466395

Epoch: 5| Step: 5
Training loss: 2.6971077919006348
Validation loss: 2.411655003024686

Epoch: 5| Step: 6
Training loss: 2.2593462467193604
Validation loss: 2.4178626280958935

Epoch: 5| Step: 7
Training loss: 2.4063212871551514
Validation loss: 2.4204694481306177

Epoch: 5| Step: 8
Training loss: 2.699016571044922
Validation loss: 2.409542727214034

Epoch: 5| Step: 9
Training loss: 2.484184980392456
Validation loss: 2.396035930161835

Epoch: 5| Step: 10
Training loss: 2.145843029022217
Validation loss: 2.38834947411732

Epoch: 154| Step: 0
Training loss: 2.964216709136963
Validation loss: 2.378956066664829

Epoch: 5| Step: 1
Training loss: 2.6662697792053223
Validation loss: 2.3691468623376664

Epoch: 5| Step: 2
Training loss: 2.551827907562256
Validation loss: 2.3838441397554133

Epoch: 5| Step: 3
Training loss: 2.427213668823242
Validation loss: 2.3711761274645404

Epoch: 5| Step: 4
Training loss: 2.3933286666870117
Validation loss: 2.3612777340796685

Epoch: 5| Step: 5
Training loss: 2.967080593109131
Validation loss: 2.3727934898868686

Epoch: 5| Step: 6
Training loss: 2.369917392730713
Validation loss: 2.356076330266973

Epoch: 5| Step: 7
Training loss: 2.03853440284729
Validation loss: 2.348324627004644

Epoch: 5| Step: 8
Training loss: 2.6164088249206543
Validation loss: 2.3397683802471367

Epoch: 5| Step: 9
Training loss: 2.6501717567443848
Validation loss: 2.3167861046329623

Epoch: 5| Step: 10
Training loss: 1.9543851613998413
Validation loss: 2.30833879850244

Epoch: 155| Step: 0
Training loss: 2.6369597911834717
Validation loss: 2.3102515205260246

Epoch: 5| Step: 1
Training loss: 2.824228525161743
Validation loss: 2.3047260238278295

Epoch: 5| Step: 2
Training loss: 2.8911232948303223
Validation loss: 2.316433669418417

Epoch: 5| Step: 3
Training loss: 2.7934670448303223
Validation loss: 2.3189631213424025

Epoch: 5| Step: 4
Training loss: 2.451035261154175
Validation loss: 2.318804233304916

Epoch: 5| Step: 5
Training loss: 3.0936501026153564
Validation loss: 2.320514032917638

Epoch: 5| Step: 6
Training loss: 2.1978461742401123
Validation loss: 2.327149145064815

Epoch: 5| Step: 7
Training loss: 2.3758773803710938
Validation loss: 2.3209447296716834

Epoch: 5| Step: 8
Training loss: 2.162415027618408
Validation loss: 2.312895708186652

Epoch: 5| Step: 9
Training loss: 2.1422789096832275
Validation loss: 2.3211796206812703

Epoch: 5| Step: 10
Training loss: 2.486131429672241
Validation loss: 2.3191735641930693

Epoch: 156| Step: 0
Training loss: 2.9801013469696045
Validation loss: 2.3084355285090785

Epoch: 5| Step: 1
Training loss: 2.722451686859131
Validation loss: 2.296726260133969

Epoch: 5| Step: 2
Training loss: 2.889315366744995
Validation loss: 2.292511140146563

Epoch: 5| Step: 3
Training loss: 2.279242753982544
Validation loss: 2.2936109727428806

Epoch: 5| Step: 4
Training loss: 2.6130270957946777
Validation loss: 2.2950487649568947

Epoch: 5| Step: 5
Training loss: 2.52473783493042
Validation loss: 2.2897677024205527

Epoch: 5| Step: 6
Training loss: 1.959413766860962
Validation loss: 2.286428354119742

Epoch: 5| Step: 7
Training loss: 2.355416774749756
Validation loss: 2.2889307468168196

Epoch: 5| Step: 8
Training loss: 2.7064967155456543
Validation loss: 2.284713493880405

Epoch: 5| Step: 9
Training loss: 2.699873924255371
Validation loss: 2.289699173742725

Epoch: 5| Step: 10
Training loss: 2.1921045780181885
Validation loss: 2.2968577338803198

Epoch: 157| Step: 0
Training loss: 2.408417224884033
Validation loss: 2.2936705107329995

Epoch: 5| Step: 1
Training loss: 2.5529332160949707
Validation loss: 2.300265960795905

Epoch: 5| Step: 2
Training loss: 2.0513439178466797
Validation loss: 2.3081500581515733

Epoch: 5| Step: 3
Training loss: 2.171619176864624
Validation loss: 2.324720287835726

Epoch: 5| Step: 4
Training loss: 2.405264377593994
Validation loss: 2.319538862474503

Epoch: 5| Step: 5
Training loss: 2.5603058338165283
Validation loss: 2.347106623393233

Epoch: 5| Step: 6
Training loss: 3.561068058013916
Validation loss: 2.3560696391649145

Epoch: 5| Step: 7
Training loss: 2.692838668823242
Validation loss: 2.354887754686417

Epoch: 5| Step: 8
Training loss: 2.116414785385132
Validation loss: 2.347830746763496

Epoch: 5| Step: 9
Training loss: 2.7585842609405518
Validation loss: 2.344152855616744

Epoch: 5| Step: 10
Training loss: 2.697661876678467
Validation loss: 2.326170115060704

Epoch: 158| Step: 0
Training loss: 3.03764009475708
Validation loss: 2.322716397623862

Epoch: 5| Step: 1
Training loss: 2.0572190284729004
Validation loss: 2.332251651312715

Epoch: 5| Step: 2
Training loss: 2.299492359161377
Validation loss: 2.3309914373582408

Epoch: 5| Step: 3
Training loss: 2.253873109817505
Validation loss: 2.343163885096068

Epoch: 5| Step: 4
Training loss: 2.9236578941345215
Validation loss: 2.3751959211082867

Epoch: 5| Step: 5
Training loss: 1.7955242395401
Validation loss: 2.3870383770235124

Epoch: 5| Step: 6
Training loss: 2.9634993076324463
Validation loss: 2.4043707437412714

Epoch: 5| Step: 7
Training loss: 2.873473644256592
Validation loss: 2.368503537229312

Epoch: 5| Step: 8
Training loss: 1.9982696771621704
Validation loss: 2.347752465996691

Epoch: 5| Step: 9
Training loss: 2.6321849822998047
Validation loss: 2.324592472404562

Epoch: 5| Step: 10
Training loss: 3.087923049926758
Validation loss: 2.325973146705217

Epoch: 159| Step: 0
Training loss: 2.759944200515747
Validation loss: 2.323709677624446

Epoch: 5| Step: 1
Training loss: 2.9233992099761963
Validation loss: 2.3385339411356116

Epoch: 5| Step: 2
Training loss: 2.1986725330352783
Validation loss: 2.3538694125349804

Epoch: 5| Step: 3
Training loss: 2.128446578979492
Validation loss: 2.359852619068597

Epoch: 5| Step: 4
Training loss: 2.647665500640869
Validation loss: 2.3597685034557054

Epoch: 5| Step: 5
Training loss: 2.684389591217041
Validation loss: 2.3758989828889088

Epoch: 5| Step: 6
Training loss: 2.293470621109009
Validation loss: 2.3509340337527695

Epoch: 5| Step: 7
Training loss: 2.346484422683716
Validation loss: 2.3226246936346895

Epoch: 5| Step: 8
Training loss: 2.882843017578125
Validation loss: 2.313015727586644

Epoch: 5| Step: 9
Training loss: 2.6070034503936768
Validation loss: 2.3095867762001614

Epoch: 5| Step: 10
Training loss: 2.3168227672576904
Validation loss: 2.3129703152564263

Epoch: 160| Step: 0
Training loss: 2.1420986652374268
Validation loss: 2.331220252539522

Epoch: 5| Step: 1
Training loss: 2.465847969055176
Validation loss: 2.380802187868344

Epoch: 5| Step: 2
Training loss: 2.2387304306030273
Validation loss: 2.417032064930085

Epoch: 5| Step: 3
Training loss: 3.0587210655212402
Validation loss: 2.4561692796727663

Epoch: 5| Step: 4
Training loss: 2.303398370742798
Validation loss: 2.4791900111782934

Epoch: 5| Step: 5
Training loss: 2.6110174655914307
Validation loss: 2.538812506583429

Epoch: 5| Step: 6
Training loss: 2.3738789558410645
Validation loss: 2.4944977427041657

Epoch: 5| Step: 7
Training loss: 2.3192429542541504
Validation loss: 2.397194536783362

Epoch: 5| Step: 8
Training loss: 2.622162342071533
Validation loss: 2.379429401889924

Epoch: 5| Step: 9
Training loss: 2.824822425842285
Validation loss: 2.3658085459022113

Epoch: 5| Step: 10
Training loss: 3.173062801361084
Validation loss: 2.346240428186232

Epoch: 161| Step: 0
Training loss: 2.011719226837158
Validation loss: 2.364669943368563

Epoch: 5| Step: 1
Training loss: 2.8156893253326416
Validation loss: 2.360263968026766

Epoch: 5| Step: 2
Training loss: 2.839150905609131
Validation loss: 2.407330643746161

Epoch: 5| Step: 3
Training loss: 3.3323512077331543
Validation loss: 2.4182357147175777

Epoch: 5| Step: 4
Training loss: 2.1954598426818848
Validation loss: 2.414108363530969

Epoch: 5| Step: 5
Training loss: 2.313471555709839
Validation loss: 2.386256435865997

Epoch: 5| Step: 6
Training loss: 2.459165334701538
Validation loss: 2.3454311740013862

Epoch: 5| Step: 7
Training loss: 3.346874952316284
Validation loss: 2.3137936886920722

Epoch: 5| Step: 8
Training loss: 2.5615553855895996
Validation loss: 2.3025925518364034

Epoch: 5| Step: 9
Training loss: 2.7277591228485107
Validation loss: 2.2825211991545973

Epoch: 5| Step: 10
Training loss: 1.4430428743362427
Validation loss: 2.270420382099767

Epoch: 162| Step: 0
Training loss: 2.317683696746826
Validation loss: 2.2675052919695453

Epoch: 5| Step: 1
Training loss: 2.6006617546081543
Validation loss: 2.274370143490453

Epoch: 5| Step: 2
Training loss: 2.1921987533569336
Validation loss: 2.2741178210063646

Epoch: 5| Step: 3
Training loss: 3.0463578701019287
Validation loss: 2.269342108439374

Epoch: 5| Step: 4
Training loss: 1.9746534824371338
Validation loss: 2.2710636174806984

Epoch: 5| Step: 5
Training loss: 2.6094746589660645
Validation loss: 2.2768572889348513

Epoch: 5| Step: 6
Training loss: 2.3281822204589844
Validation loss: 2.269951884464551

Epoch: 5| Step: 7
Training loss: 2.724828004837036
Validation loss: 2.271320830109299

Epoch: 5| Step: 8
Training loss: 2.6092171669006348
Validation loss: 2.2799957336918

Epoch: 5| Step: 9
Training loss: 2.1927735805511475
Validation loss: 2.285960423049106

Epoch: 5| Step: 10
Training loss: 3.3885905742645264
Validation loss: 2.294985314851166

Epoch: 163| Step: 0
Training loss: 3.2971901893615723
Validation loss: 2.3001184412228164

Epoch: 5| Step: 1
Training loss: 2.8522963523864746
Validation loss: 2.306186983662267

Epoch: 5| Step: 2
Training loss: 2.8620219230651855
Validation loss: 2.309573406814247

Epoch: 5| Step: 3
Training loss: 2.434725284576416
Validation loss: 2.300497039671867

Epoch: 5| Step: 4
Training loss: 2.155963182449341
Validation loss: 2.2991820355897308

Epoch: 5| Step: 5
Training loss: 2.1436870098114014
Validation loss: 2.3043948604214575

Epoch: 5| Step: 6
Training loss: 2.3807032108306885
Validation loss: 2.3025079952773226

Epoch: 5| Step: 7
Training loss: 2.349494457244873
Validation loss: 2.2927611643268215

Epoch: 5| Step: 8
Training loss: 2.3523964881896973
Validation loss: 2.2889571471880843

Epoch: 5| Step: 9
Training loss: 2.0842700004577637
Validation loss: 2.3040390758104223

Epoch: 5| Step: 10
Training loss: 2.6195316314697266
Validation loss: 2.325316631665794

Epoch: 164| Step: 0
Training loss: 2.4946959018707275
Validation loss: 2.319421168296568

Epoch: 5| Step: 1
Training loss: 1.9354333877563477
Validation loss: 2.3565127567578386

Epoch: 5| Step: 2
Training loss: 2.294377326965332
Validation loss: 2.356841525723857

Epoch: 5| Step: 3
Training loss: 2.6102287769317627
Validation loss: 2.349742889404297

Epoch: 5| Step: 4
Training loss: 2.346876859664917
Validation loss: 2.316108488267468

Epoch: 5| Step: 5
Training loss: 2.696927547454834
Validation loss: 2.3050186300790436

Epoch: 5| Step: 6
Training loss: 2.5326688289642334
Validation loss: 2.3013936217113207

Epoch: 5| Step: 7
Training loss: 2.9395790100097656
Validation loss: 2.313843475875034

Epoch: 5| Step: 8
Training loss: 2.4142472743988037
Validation loss: 2.30841185456963

Epoch: 5| Step: 9
Training loss: 2.7031192779541016
Validation loss: 2.31330003276948

Epoch: 5| Step: 10
Training loss: 2.616215467453003
Validation loss: 2.306855788794897

Epoch: 165| Step: 0
Training loss: 2.716948986053467
Validation loss: 2.307865958059988

Epoch: 5| Step: 1
Training loss: 3.1349337100982666
Validation loss: 2.3042806169038177

Epoch: 5| Step: 2
Training loss: 2.0873165130615234
Validation loss: 2.310347790359169

Epoch: 5| Step: 3
Training loss: 2.674531936645508
Validation loss: 2.290057428421513

Epoch: 5| Step: 4
Training loss: 1.8981447219848633
Validation loss: 2.2929083583175496

Epoch: 5| Step: 5
Training loss: 2.8877999782562256
Validation loss: 2.2810668637675624

Epoch: 5| Step: 6
Training loss: 2.2543089389801025
Validation loss: 2.285388751696515

Epoch: 5| Step: 7
Training loss: 2.7677817344665527
Validation loss: 2.289314418710688

Epoch: 5| Step: 8
Training loss: 2.3403804302215576
Validation loss: 2.2929041795833136

Epoch: 5| Step: 9
Training loss: 2.217172145843506
Validation loss: 2.2885420655691497

Epoch: 5| Step: 10
Training loss: 2.4782185554504395
Validation loss: 2.2956389663039998

Epoch: 166| Step: 0
Training loss: 2.6212077140808105
Validation loss: 2.3115098168773036

Epoch: 5| Step: 1
Training loss: 3.1480133533477783
Validation loss: 2.3055656289541595

Epoch: 5| Step: 2
Training loss: 2.558500289916992
Validation loss: 2.3143513587213334

Epoch: 5| Step: 3
Training loss: 2.4896223545074463
Validation loss: 2.3345064911791074

Epoch: 5| Step: 4
Training loss: 2.642634153366089
Validation loss: 2.330766062582693

Epoch: 5| Step: 5
Training loss: 1.9235140085220337
Validation loss: 2.345092511946155

Epoch: 5| Step: 6
Training loss: 1.985716462135315
Validation loss: 2.3377225886109056

Epoch: 5| Step: 7
Training loss: 2.213181257247925
Validation loss: 2.324853676621632

Epoch: 5| Step: 8
Training loss: 3.0263631343841553
Validation loss: 2.3252995039827082

Epoch: 5| Step: 9
Training loss: 2.364816188812256
Validation loss: 2.3298333127011537

Epoch: 5| Step: 10
Training loss: 2.3398544788360596
Validation loss: 2.3342295487721763

Epoch: 167| Step: 0
Training loss: 2.3892741203308105
Validation loss: 2.319992449975783

Epoch: 5| Step: 1
Training loss: 2.8144936561584473
Validation loss: 2.316753133650749

Epoch: 5| Step: 2
Training loss: 2.4232935905456543
Validation loss: 2.3099312577196347

Epoch: 5| Step: 3
Training loss: 2.4191901683807373
Validation loss: 2.3049681878859

Epoch: 5| Step: 4
Training loss: 2.459717035293579
Validation loss: 2.3070079870121454

Epoch: 5| Step: 5
Training loss: 2.1877315044403076
Validation loss: 2.301014613079768

Epoch: 5| Step: 6
Training loss: 2.0554633140563965
Validation loss: 2.3067817790533907

Epoch: 5| Step: 7
Training loss: 2.502807140350342
Validation loss: 2.317519559655138

Epoch: 5| Step: 8
Training loss: 2.8481178283691406
Validation loss: 2.336600785614342

Epoch: 5| Step: 9
Training loss: 2.5072479248046875
Validation loss: 2.3430647465490524

Epoch: 5| Step: 10
Training loss: 2.6476612091064453
Validation loss: 2.335876246934296

Epoch: 168| Step: 0
Training loss: 2.61350679397583
Validation loss: 2.333833125329787

Epoch: 5| Step: 1
Training loss: 2.457777261734009
Validation loss: 2.322013091015559

Epoch: 5| Step: 2
Training loss: 2.2228567600250244
Validation loss: 2.3262218352287047

Epoch: 5| Step: 3
Training loss: 3.2160308361053467
Validation loss: 2.334966436509163

Epoch: 5| Step: 4
Training loss: 3.06943941116333
Validation loss: 2.375893005760767

Epoch: 5| Step: 5
Training loss: 2.6109564304351807
Validation loss: 2.3354844944451445

Epoch: 5| Step: 6
Training loss: 1.5797072649002075
Validation loss: 2.331235808710898

Epoch: 5| Step: 7
Training loss: 2.57434344291687
Validation loss: 2.3247790849337013

Epoch: 5| Step: 8
Training loss: 2.270287275314331
Validation loss: 2.3415457612724713

Epoch: 5| Step: 9
Training loss: 2.0539984703063965
Validation loss: 2.3451723360246226

Epoch: 5| Step: 10
Training loss: 2.683461904525757
Validation loss: 2.3679675543180077

Epoch: 169| Step: 0
Training loss: 2.4666056632995605
Validation loss: 2.3403197616659184

Epoch: 5| Step: 1
Training loss: 2.426462173461914
Validation loss: 2.3198005845469813

Epoch: 5| Step: 2
Training loss: 2.455557346343994
Validation loss: 2.3176348773382043

Epoch: 5| Step: 3
Training loss: 2.228461265563965
Validation loss: 2.318321625391642

Epoch: 5| Step: 4
Training loss: 2.454082489013672
Validation loss: 2.3283512194951377

Epoch: 5| Step: 5
Training loss: 2.2510788440704346
Validation loss: 2.324490790726036

Epoch: 5| Step: 6
Training loss: 2.7134127616882324
Validation loss: 2.36145201037007

Epoch: 5| Step: 7
Training loss: 3.3154003620147705
Validation loss: 2.3650360158694688

Epoch: 5| Step: 8
Training loss: 2.452728271484375
Validation loss: 2.3413559441925376

Epoch: 5| Step: 9
Training loss: 2.1518242359161377
Validation loss: 2.3094967975411365

Epoch: 5| Step: 10
Training loss: 2.4108827114105225
Validation loss: 2.303219856754426

Epoch: 170| Step: 0
Training loss: 2.9796364307403564
Validation loss: 2.2736101586331605

Epoch: 5| Step: 1
Training loss: 2.3161940574645996
Validation loss: 2.283054103133499

Epoch: 5| Step: 2
Training loss: 2.498192310333252
Validation loss: 2.289847502144434

Epoch: 5| Step: 3
Training loss: 2.6601758003234863
Validation loss: 2.2937477993708786

Epoch: 5| Step: 4
Training loss: 2.1850671768188477
Validation loss: 2.2922542736094487

Epoch: 5| Step: 5
Training loss: 2.693878650665283
Validation loss: 2.2875635059930945

Epoch: 5| Step: 6
Training loss: 2.3152661323547363
Validation loss: 2.2735762455130137

Epoch: 5| Step: 7
Training loss: 2.4619572162628174
Validation loss: 2.266234774743357

Epoch: 5| Step: 8
Training loss: 2.4428346157073975
Validation loss: 2.2612080509944628

Epoch: 5| Step: 9
Training loss: 2.490873098373413
Validation loss: 2.2671695781010452

Epoch: 5| Step: 10
Training loss: 2.3488638401031494
Validation loss: 2.2651041297502417

Epoch: 171| Step: 0
Training loss: 2.4427177906036377
Validation loss: 2.272533360347953

Epoch: 5| Step: 1
Training loss: 2.872710704803467
Validation loss: 2.281949467556451

Epoch: 5| Step: 2
Training loss: 2.0680651664733887
Validation loss: 2.294904039752099

Epoch: 5| Step: 3
Training loss: 2.0904908180236816
Validation loss: 2.3251612212068293

Epoch: 5| Step: 4
Training loss: 2.685307502746582
Validation loss: 2.3558952513561455

Epoch: 5| Step: 5
Training loss: 2.8952972888946533
Validation loss: 2.3874071951835387

Epoch: 5| Step: 6
Training loss: 1.9746582508087158
Validation loss: 2.404315892086234

Epoch: 5| Step: 7
Training loss: 1.7854816913604736
Validation loss: 2.3843942842175885

Epoch: 5| Step: 8
Training loss: 3.590447187423706
Validation loss: 2.3690569836606263

Epoch: 5| Step: 9
Training loss: 2.842529296875
Validation loss: 2.3035878699312926

Epoch: 5| Step: 10
Training loss: 2.2210333347320557
Validation loss: 2.2748795170937814

Epoch: 172| Step: 0
Training loss: 2.413422107696533
Validation loss: 2.2679966470246673

Epoch: 5| Step: 1
Training loss: 2.5395941734313965
Validation loss: 2.2746493072919947

Epoch: 5| Step: 2
Training loss: 2.086947441101074
Validation loss: 2.2952821613639913

Epoch: 5| Step: 3
Training loss: 2.617116689682007
Validation loss: 2.3188190408932265

Epoch: 5| Step: 4
Training loss: 2.7162349224090576
Validation loss: 2.323328164315993

Epoch: 5| Step: 5
Training loss: 2.5803451538085938
Validation loss: 2.328493118286133

Epoch: 5| Step: 6
Training loss: 2.4414334297180176
Validation loss: 2.305403168483447

Epoch: 5| Step: 7
Training loss: 2.3612256050109863
Validation loss: 2.277448861829696

Epoch: 5| Step: 8
Training loss: 2.6007778644561768
Validation loss: 2.2641769827053113

Epoch: 5| Step: 9
Training loss: 2.6461634635925293
Validation loss: 2.256611624071675

Epoch: 5| Step: 10
Training loss: 2.484149217605591
Validation loss: 2.2519682107433194

Epoch: 173| Step: 0
Training loss: 2.5664925575256348
Validation loss: 2.2542646572154057

Epoch: 5| Step: 1
Training loss: 2.8249738216400146
Validation loss: 2.2554852347220145

Epoch: 5| Step: 2
Training loss: 2.2587497234344482
Validation loss: 2.2646598508281093

Epoch: 5| Step: 3
Training loss: 2.4545950889587402
Validation loss: 2.287053572234287

Epoch: 5| Step: 4
Training loss: 2.7424685955047607
Validation loss: 2.319321588803363

Epoch: 5| Step: 5
Training loss: 2.4840807914733887
Validation loss: 2.3426865659734255

Epoch: 5| Step: 6
Training loss: 2.268301248550415
Validation loss: 2.339517697211235

Epoch: 5| Step: 7
Training loss: 2.9094860553741455
Validation loss: 2.3295386247737433

Epoch: 5| Step: 8
Training loss: 2.3412508964538574
Validation loss: 2.3351968924204507

Epoch: 5| Step: 9
Training loss: 1.952833890914917
Validation loss: 2.34177759257696

Epoch: 5| Step: 10
Training loss: 2.815460205078125
Validation loss: 2.3237185990938576

Epoch: 174| Step: 0
Training loss: 2.8761940002441406
Validation loss: 2.317666220408614

Epoch: 5| Step: 1
Training loss: 2.4856953620910645
Validation loss: 2.302802360186013

Epoch: 5| Step: 2
Training loss: 2.1791813373565674
Validation loss: 2.3166623448812835

Epoch: 5| Step: 3
Training loss: 2.3869941234588623
Validation loss: 2.3182736084025395

Epoch: 5| Step: 4
Training loss: 2.658750057220459
Validation loss: 2.3317927134934293

Epoch: 5| Step: 5
Training loss: 2.720268964767456
Validation loss: 2.3252039699144262

Epoch: 5| Step: 6
Training loss: 2.1231415271759033
Validation loss: 2.3329321876648934

Epoch: 5| Step: 7
Training loss: 2.0953025817871094
Validation loss: 2.3109332515347387

Epoch: 5| Step: 8
Training loss: 2.4625186920166016
Validation loss: 2.293324407710824

Epoch: 5| Step: 9
Training loss: 2.7895779609680176
Validation loss: 2.2995896544507755

Epoch: 5| Step: 10
Training loss: 2.219424247741699
Validation loss: 2.2986512773780414

Epoch: 175| Step: 0
Training loss: 2.3920469284057617
Validation loss: 2.3097140199394635

Epoch: 5| Step: 1
Training loss: 2.3823840618133545
Validation loss: 2.3256020161413375

Epoch: 5| Step: 2
Training loss: 2.360220432281494
Validation loss: 2.3328734418397308

Epoch: 5| Step: 3
Training loss: 1.9137394428253174
Validation loss: 2.345285610486102

Epoch: 5| Step: 4
Training loss: 2.57769513130188
Validation loss: 2.3739628868718303

Epoch: 5| Step: 5
Training loss: 2.50506329536438
Validation loss: 2.3678632115805023

Epoch: 5| Step: 6
Training loss: 2.145749568939209
Validation loss: 2.3525538880337953

Epoch: 5| Step: 7
Training loss: 2.277238130569458
Validation loss: 2.3336441375875987

Epoch: 5| Step: 8
Training loss: 3.049165725708008
Validation loss: 2.329810245062715

Epoch: 5| Step: 9
Training loss: 2.5625693798065186
Validation loss: 2.3156650732922297

Epoch: 5| Step: 10
Training loss: 3.0730385780334473
Validation loss: 2.3183719394027547

Epoch: 176| Step: 0
Training loss: 2.530468463897705
Validation loss: 2.2989150785630748

Epoch: 5| Step: 1
Training loss: 2.1592419147491455
Validation loss: 2.2904733150236067

Epoch: 5| Step: 2
Training loss: 3.2306041717529297
Validation loss: 2.276992892706266

Epoch: 5| Step: 3
Training loss: 2.2291359901428223
Validation loss: 2.2698123249956357

Epoch: 5| Step: 4
Training loss: 2.6413869857788086
Validation loss: 2.269720060850984

Epoch: 5| Step: 5
Training loss: 2.166421890258789
Validation loss: 2.2694004402365735

Epoch: 5| Step: 6
Training loss: 1.6943638324737549
Validation loss: 2.2707177439043598

Epoch: 5| Step: 7
Training loss: 2.111825704574585
Validation loss: 2.2828118775480535

Epoch: 5| Step: 8
Training loss: 2.7040023803710938
Validation loss: 2.2872813004319386

Epoch: 5| Step: 9
Training loss: 2.6848676204681396
Validation loss: 2.2900628505214566

Epoch: 5| Step: 10
Training loss: 2.9666218757629395
Validation loss: 2.296713585494667

Epoch: 177| Step: 0
Training loss: 2.6878931522369385
Validation loss: 2.2724790368028867

Epoch: 5| Step: 1
Training loss: 2.407510757446289
Validation loss: 2.272862898406162

Epoch: 5| Step: 2
Training loss: 2.617003917694092
Validation loss: 2.261530726186691

Epoch: 5| Step: 3
Training loss: 2.567992687225342
Validation loss: 2.2496664677896807

Epoch: 5| Step: 4
Training loss: 2.131654739379883
Validation loss: 2.255307710298928

Epoch: 5| Step: 5
Training loss: 2.5161831378936768
Validation loss: 2.262686010329954

Epoch: 5| Step: 6
Training loss: 2.3976120948791504
Validation loss: 2.267651306685581

Epoch: 5| Step: 7
Training loss: 1.986281156539917
Validation loss: 2.2785877079092045

Epoch: 5| Step: 8
Training loss: 2.2845540046691895
Validation loss: 2.307132733765469

Epoch: 5| Step: 9
Training loss: 3.44214129447937
Validation loss: 2.330335904193181

Epoch: 5| Step: 10
Training loss: 1.9615256786346436
Validation loss: 2.3376245293565976

Epoch: 178| Step: 0
Training loss: 2.4486656188964844
Validation loss: 2.330452493442002

Epoch: 5| Step: 1
Training loss: 2.4494640827178955
Validation loss: 2.3087390545875794

Epoch: 5| Step: 2
Training loss: 2.9135186672210693
Validation loss: 2.2879135890673568

Epoch: 5| Step: 3
Training loss: 2.204146385192871
Validation loss: 2.266117775312034

Epoch: 5| Step: 4
Training loss: 2.6527161598205566
Validation loss: 2.255306008041546

Epoch: 5| Step: 5
Training loss: 2.2648463249206543
Validation loss: 2.250471035639445

Epoch: 5| Step: 6
Training loss: 2.6819496154785156
Validation loss: 2.2462459174535607

Epoch: 5| Step: 7
Training loss: 2.176161527633667
Validation loss: 2.254666196402683

Epoch: 5| Step: 8
Training loss: 2.385542869567871
Validation loss: 2.265793269680392

Epoch: 5| Step: 9
Training loss: 2.044480085372925
Validation loss: 2.2760735673289143

Epoch: 5| Step: 10
Training loss: 2.702798843383789
Validation loss: 2.3029567580069266

Epoch: 179| Step: 0
Training loss: 2.5370359420776367
Validation loss: 2.3093183835347495

Epoch: 5| Step: 1
Training loss: 2.077561855316162
Validation loss: 2.2963223893155336

Epoch: 5| Step: 2
Training loss: 2.159088373184204
Validation loss: 2.315117359161377

Epoch: 5| Step: 3
Training loss: 2.625673294067383
Validation loss: 2.3083939859944005

Epoch: 5| Step: 4
Training loss: 2.689577341079712
Validation loss: 2.323589753079158

Epoch: 5| Step: 5
Training loss: 2.118079662322998
Validation loss: 2.322575206397682

Epoch: 5| Step: 6
Training loss: 2.3349435329437256
Validation loss: 2.32166467174407

Epoch: 5| Step: 7
Training loss: 2.449073076248169
Validation loss: 2.2981561153165755

Epoch: 5| Step: 8
Training loss: 2.6794846057891846
Validation loss: 2.274597083368609

Epoch: 5| Step: 9
Training loss: 2.4270904064178467
Validation loss: 2.2647719588330997

Epoch: 5| Step: 10
Training loss: 2.782022476196289
Validation loss: 2.260526644286289

Epoch: 180| Step: 0
Training loss: 2.311520576477051
Validation loss: 2.3030476595765803

Epoch: 5| Step: 1
Training loss: 2.638350248336792
Validation loss: 2.3288521510298534

Epoch: 5| Step: 2
Training loss: 2.2034049034118652
Validation loss: 2.3751741199083227

Epoch: 5| Step: 3
Training loss: 2.6118781566619873
Validation loss: 2.3895949753381873

Epoch: 5| Step: 4
Training loss: 3.20989727973938
Validation loss: 2.3948262827370757

Epoch: 5| Step: 5
Training loss: 3.021857738494873
Validation loss: 2.3615731270082536

Epoch: 5| Step: 6
Training loss: 2.2847437858581543
Validation loss: 2.336096232937228

Epoch: 5| Step: 7
Training loss: 1.962641954421997
Validation loss: 2.276642578904347

Epoch: 5| Step: 8
Training loss: 2.0492873191833496
Validation loss: 2.2457086411855554

Epoch: 5| Step: 9
Training loss: 2.654773235321045
Validation loss: 2.2314117262440343

Epoch: 5| Step: 10
Training loss: 2.4979686737060547
Validation loss: 2.243567330862886

Epoch: 181| Step: 0
Training loss: 1.6660875082015991
Validation loss: 2.251057045434111

Epoch: 5| Step: 1
Training loss: 2.610027551651001
Validation loss: 2.2660370385775

Epoch: 5| Step: 2
Training loss: 2.260526180267334
Validation loss: 2.2884483709130237

Epoch: 5| Step: 3
Training loss: 2.924022674560547
Validation loss: 2.299056678689936

Epoch: 5| Step: 4
Training loss: 2.281947612762451
Validation loss: 2.28431874193171

Epoch: 5| Step: 5
Training loss: 3.2192764282226562
Validation loss: 2.2945474193942164

Epoch: 5| Step: 6
Training loss: 2.5107388496398926
Validation loss: 2.2735780439069195

Epoch: 5| Step: 7
Training loss: 2.76469087600708
Validation loss: 2.277228650226388

Epoch: 5| Step: 8
Training loss: 2.1956300735473633
Validation loss: 2.26269059283759

Epoch: 5| Step: 9
Training loss: 3.018249273300171
Validation loss: 2.2558825567204464

Epoch: 5| Step: 10
Training loss: 1.6675916910171509
Validation loss: 2.244058362899288

Epoch: 182| Step: 0
Training loss: 2.611311435699463
Validation loss: 2.246701145684847

Epoch: 5| Step: 1
Training loss: 2.435117483139038
Validation loss: 2.2626967019932245

Epoch: 5| Step: 2
Training loss: 2.1093411445617676
Validation loss: 2.2580405947982625

Epoch: 5| Step: 3
Training loss: 3.1464407444000244
Validation loss: 2.276475111643473

Epoch: 5| Step: 4
Training loss: 2.333315372467041
Validation loss: 2.2897718888457104

Epoch: 5| Step: 5
Training loss: 2.6469764709472656
Validation loss: 2.2911930289319766

Epoch: 5| Step: 6
Training loss: 2.362215518951416
Validation loss: 2.283771689220141

Epoch: 5| Step: 7
Training loss: 2.402434825897217
Validation loss: 2.310775487653671

Epoch: 5| Step: 8
Training loss: 1.9523630142211914
Validation loss: 2.303706322946856

Epoch: 5| Step: 9
Training loss: 2.3793816566467285
Validation loss: 2.3236376316316667

Epoch: 5| Step: 10
Training loss: 2.348870277404785
Validation loss: 2.32007344307438

Epoch: 183| Step: 0
Training loss: 1.4623749256134033
Validation loss: 2.332564215506277

Epoch: 5| Step: 1
Training loss: 1.9519469738006592
Validation loss: 2.335512202273133

Epoch: 5| Step: 2
Training loss: 2.4371979236602783
Validation loss: 2.31268032263684

Epoch: 5| Step: 3
Training loss: 3.2009196281433105
Validation loss: 2.306187906572896

Epoch: 5| Step: 4
Training loss: 2.3304085731506348
Validation loss: 2.2908747657652824

Epoch: 5| Step: 5
Training loss: 1.8405754566192627
Validation loss: 2.273853705775353

Epoch: 5| Step: 6
Training loss: 2.9579570293426514
Validation loss: 2.2546566045412453

Epoch: 5| Step: 7
Training loss: 2.5965847969055176
Validation loss: 2.2447885441523727

Epoch: 5| Step: 8
Training loss: 2.089384078979492
Validation loss: 2.244485952520883

Epoch: 5| Step: 9
Training loss: 3.196739673614502
Validation loss: 2.2385453742037535

Epoch: 5| Step: 10
Training loss: 2.5452637672424316
Validation loss: 2.2418501197650866

Epoch: 184| Step: 0
Training loss: 1.839337944984436
Validation loss: 2.2485681605595413

Epoch: 5| Step: 1
Training loss: 2.0808136463165283
Validation loss: 2.2677439976763982

Epoch: 5| Step: 2
Training loss: 2.369966745376587
Validation loss: 2.314103759745116

Epoch: 5| Step: 3
Training loss: 2.7811484336853027
Validation loss: 2.312561173592844

Epoch: 5| Step: 4
Training loss: 3.554088592529297
Validation loss: 2.3172654515953472

Epoch: 5| Step: 5
Training loss: 2.264925718307495
Validation loss: 2.293932912170246

Epoch: 5| Step: 6
Training loss: 2.6068196296691895
Validation loss: 2.2934535600805797

Epoch: 5| Step: 7
Training loss: 2.473435878753662
Validation loss: 2.2580910446823284

Epoch: 5| Step: 8
Training loss: 2.614724636077881
Validation loss: 2.257323063829894

Epoch: 5| Step: 9
Training loss: 2.1108758449554443
Validation loss: 2.236033175581245

Epoch: 5| Step: 10
Training loss: 1.9935353994369507
Validation loss: 2.235286630609984

Epoch: 185| Step: 0
Training loss: 2.2116663455963135
Validation loss: 2.2429351755367812

Epoch: 5| Step: 1
Training loss: 2.5849721431732178
Validation loss: 2.2411694090853453

Epoch: 5| Step: 2
Training loss: 1.8491361141204834
Validation loss: 2.2294295680138374

Epoch: 5| Step: 3
Training loss: 2.6712493896484375
Validation loss: 2.235780962051884

Epoch: 5| Step: 4
Training loss: 2.674203395843506
Validation loss: 2.2423905762293006

Epoch: 5| Step: 5
Training loss: 2.259228229522705
Validation loss: 2.241465563415199

Epoch: 5| Step: 6
Training loss: 2.818502902984619
Validation loss: 2.231708916284705

Epoch: 5| Step: 7
Training loss: 2.635439395904541
Validation loss: 2.2261474337629092

Epoch: 5| Step: 8
Training loss: 2.649977922439575
Validation loss: 2.2313175585962113

Epoch: 5| Step: 9
Training loss: 2.151343584060669
Validation loss: 2.240037892454414

Epoch: 5| Step: 10
Training loss: 2.225147247314453
Validation loss: 2.253499605322397

Epoch: 186| Step: 0
Training loss: 1.9096477031707764
Validation loss: 2.273653035522789

Epoch: 5| Step: 1
Training loss: 2.142277479171753
Validation loss: 2.3058293275935675

Epoch: 5| Step: 2
Training loss: 2.314396381378174
Validation loss: 2.3713829286636843

Epoch: 5| Step: 3
Training loss: 2.8122611045837402
Validation loss: 2.406515057368945

Epoch: 5| Step: 4
Training loss: 2.0009727478027344
Validation loss: 2.3917573754505446

Epoch: 5| Step: 5
Training loss: 2.1551456451416016
Validation loss: 2.3537845816663516

Epoch: 5| Step: 6
Training loss: 3.5570290088653564
Validation loss: 2.325062115987142

Epoch: 5| Step: 7
Training loss: 2.3286025524139404
Validation loss: 2.3121631119840886

Epoch: 5| Step: 8
Training loss: 2.2851672172546387
Validation loss: 2.3183608285842405

Epoch: 5| Step: 9
Training loss: 2.731055498123169
Validation loss: 2.3301215146177556

Epoch: 5| Step: 10
Training loss: 2.695014476776123
Validation loss: 2.337317941009357

Epoch: 187| Step: 0
Training loss: 1.902115821838379
Validation loss: 2.322069719273557

Epoch: 5| Step: 1
Training loss: 2.2695345878601074
Validation loss: 2.3167596914434947

Epoch: 5| Step: 2
Training loss: 2.765889883041382
Validation loss: 2.3153462179245485

Epoch: 5| Step: 3
Training loss: 3.0287880897521973
Validation loss: 2.2930899025291525

Epoch: 5| Step: 4
Training loss: 2.272822856903076
Validation loss: 2.261405993533391

Epoch: 5| Step: 5
Training loss: 2.5292675495147705
Validation loss: 2.234827390281103

Epoch: 5| Step: 6
Training loss: 2.5253117084503174
Validation loss: 2.228453323405276

Epoch: 5| Step: 7
Training loss: 1.782731056213379
Validation loss: 2.2221727243033786

Epoch: 5| Step: 8
Training loss: 1.6911617517471313
Validation loss: 2.231414400121217

Epoch: 5| Step: 9
Training loss: 3.0363731384277344
Validation loss: 2.2297804535076184

Epoch: 5| Step: 10
Training loss: 2.8716542720794678
Validation loss: 2.2514472417933966

Epoch: 188| Step: 0
Training loss: 1.6890243291854858
Validation loss: 2.256319425439322

Epoch: 5| Step: 1
Training loss: 2.232726812362671
Validation loss: 2.2613411282980316

Epoch: 5| Step: 2
Training loss: 2.270758628845215
Validation loss: 2.269538506384819

Epoch: 5| Step: 3
Training loss: 2.926931381225586
Validation loss: 2.2724740274490847

Epoch: 5| Step: 4
Training loss: 2.138435125350952
Validation loss: 2.2686244621071765

Epoch: 5| Step: 5
Training loss: 2.71838116645813
Validation loss: 2.297662740112633

Epoch: 5| Step: 6
Training loss: 1.968435525894165
Validation loss: 2.3144307495445333

Epoch: 5| Step: 7
Training loss: 3.123542308807373
Validation loss: 2.3224926430691957

Epoch: 5| Step: 8
Training loss: 2.6227242946624756
Validation loss: 2.286933957889516

Epoch: 5| Step: 9
Training loss: 2.7386438846588135
Validation loss: 2.2559020826893468

Epoch: 5| Step: 10
Training loss: 2.3169267177581787
Validation loss: 2.242666108633882

Epoch: 189| Step: 0
Training loss: 2.4418349266052246
Validation loss: 2.2511942976264545

Epoch: 5| Step: 1
Training loss: 2.052680730819702
Validation loss: 2.257829248264272

Epoch: 5| Step: 2
Training loss: 2.2328662872314453
Validation loss: 2.2761061345377276

Epoch: 5| Step: 3
Training loss: 2.177057981491089
Validation loss: 2.28603877816149

Epoch: 5| Step: 4
Training loss: 2.2626781463623047
Validation loss: 2.2911681641814527

Epoch: 5| Step: 5
Training loss: 1.9082746505737305
Validation loss: 2.2917837096798803

Epoch: 5| Step: 6
Training loss: 2.806288003921509
Validation loss: 2.287991052032799

Epoch: 5| Step: 7
Training loss: 2.5911014080047607
Validation loss: 2.2860372399771087

Epoch: 5| Step: 8
Training loss: 2.1573760509490967
Validation loss: 2.2876666617649857

Epoch: 5| Step: 9
Training loss: 2.9484267234802246
Validation loss: 2.305346135170229

Epoch: 5| Step: 10
Training loss: 3.0832996368408203
Validation loss: 2.3302174665594615

Epoch: 190| Step: 0
Training loss: 2.581449031829834
Validation loss: 2.3254427704759824

Epoch: 5| Step: 1
Training loss: 2.649322509765625
Validation loss: 2.347015186022687

Epoch: 5| Step: 2
Training loss: 1.8364804983139038
Validation loss: 2.3409638481755413

Epoch: 5| Step: 3
Training loss: 1.7666717767715454
Validation loss: 2.3523123700131654

Epoch: 5| Step: 4
Training loss: 2.9447696208953857
Validation loss: 2.3440913513142574

Epoch: 5| Step: 5
Training loss: 2.2503161430358887
Validation loss: 2.3133758498776342

Epoch: 5| Step: 6
Training loss: 2.272380828857422
Validation loss: 2.268383756760628

Epoch: 5| Step: 7
Training loss: 2.2103171348571777
Validation loss: 2.2686289843692573

Epoch: 5| Step: 8
Training loss: 2.5784060955047607
Validation loss: 2.26849425736294

Epoch: 5| Step: 9
Training loss: 2.574178457260132
Validation loss: 2.268232783963603

Epoch: 5| Step: 10
Training loss: 2.970834732055664
Validation loss: 2.2575188042015157

Epoch: 191| Step: 0
Training loss: 2.074491024017334
Validation loss: 2.258581825481948

Epoch: 5| Step: 1
Training loss: 2.4155688285827637
Validation loss: 2.243174465753699

Epoch: 5| Step: 2
Training loss: 2.7729859352111816
Validation loss: 2.23755580635481

Epoch: 5| Step: 3
Training loss: 2.2118592262268066
Validation loss: 2.239379705921296

Epoch: 5| Step: 4
Training loss: 2.4523749351501465
Validation loss: 2.228812743258733

Epoch: 5| Step: 5
Training loss: 2.720550775527954
Validation loss: 2.225182117954377

Epoch: 5| Step: 6
Training loss: 1.6895755529403687
Validation loss: 2.2175891437838153

Epoch: 5| Step: 7
Training loss: 3.050297260284424
Validation loss: 2.229529506416731

Epoch: 5| Step: 8
Training loss: 2.647461414337158
Validation loss: 2.2202093921681887

Epoch: 5| Step: 9
Training loss: 2.7983365058898926
Validation loss: 2.2254194136588805

Epoch: 5| Step: 10
Training loss: 1.3577841520309448
Validation loss: 2.2306316385986986

Epoch: 192| Step: 0
Training loss: 2.7053520679473877
Validation loss: 2.227603090706692

Epoch: 5| Step: 1
Training loss: 2.128188371658325
Validation loss: 2.2247524722929923

Epoch: 5| Step: 2
Training loss: 2.1232991218566895
Validation loss: 2.2134723124965543

Epoch: 5| Step: 3
Training loss: 2.314202070236206
Validation loss: 2.2049022951433734

Epoch: 5| Step: 4
Training loss: 2.747368812561035
Validation loss: 2.221700929826306

Epoch: 5| Step: 5
Training loss: 2.166194200515747
Validation loss: 2.2397067649390108

Epoch: 5| Step: 6
Training loss: 1.8715423345565796
Validation loss: 2.248179307547949

Epoch: 5| Step: 7
Training loss: 2.4951658248901367
Validation loss: 2.2616289136230305

Epoch: 5| Step: 8
Training loss: 1.8395931720733643
Validation loss: 2.261455314133757

Epoch: 5| Step: 9
Training loss: 2.566664457321167
Validation loss: 2.270584060299781

Epoch: 5| Step: 10
Training loss: 3.467012405395508
Validation loss: 2.2601737232618433

Epoch: 193| Step: 0
Training loss: 2.5571327209472656
Validation loss: 2.2650203192105858

Epoch: 5| Step: 1
Training loss: 3.2133896350860596
Validation loss: 2.2555774975848455

Epoch: 5| Step: 2
Training loss: 2.4376626014709473
Validation loss: 2.2490392705445648

Epoch: 5| Step: 3
Training loss: 1.9208894968032837
Validation loss: 2.260392145443988

Epoch: 5| Step: 4
Training loss: 1.7730858325958252
Validation loss: 2.252501864587107

Epoch: 5| Step: 5
Training loss: 2.302164316177368
Validation loss: 2.2622376565010316

Epoch: 5| Step: 6
Training loss: 2.849184036254883
Validation loss: 2.2591323083446873

Epoch: 5| Step: 7
Training loss: 1.849277138710022
Validation loss: 2.2635992316789526

Epoch: 5| Step: 8
Training loss: 2.6637067794799805
Validation loss: 2.2492058712949037

Epoch: 5| Step: 9
Training loss: 2.0225813388824463
Validation loss: 2.254354738420056

Epoch: 5| Step: 10
Training loss: 2.3445582389831543
Validation loss: 2.2565899920719925

Epoch: 194| Step: 0
Training loss: 3.0162694454193115
Validation loss: 2.2434905831531813

Epoch: 5| Step: 1
Training loss: 2.31740140914917
Validation loss: 2.2346717926763717

Epoch: 5| Step: 2
Training loss: 2.2156124114990234
Validation loss: 2.242942422948858

Epoch: 5| Step: 3
Training loss: 2.2491846084594727
Validation loss: 2.2554524944674585

Epoch: 5| Step: 4
Training loss: 2.4000821113586426
Validation loss: 2.2577136921626266

Epoch: 5| Step: 5
Training loss: 2.7446448802948
Validation loss: 2.254631455226611

Epoch: 5| Step: 6
Training loss: 1.9618619680404663
Validation loss: 2.2568980724580827

Epoch: 5| Step: 7
Training loss: 2.3784682750701904
Validation loss: 2.245896763699029

Epoch: 5| Step: 8
Training loss: 2.4599609375
Validation loss: 2.2463504422095513

Epoch: 5| Step: 9
Training loss: 1.7898247241973877
Validation loss: 2.2452900178970827

Epoch: 5| Step: 10
Training loss: 2.4235763549804688
Validation loss: 2.235022339769589

Epoch: 195| Step: 0
Training loss: 2.390554428100586
Validation loss: 2.2499251827116935

Epoch: 5| Step: 1
Training loss: 1.9936984777450562
Validation loss: 2.257675160643875

Epoch: 5| Step: 2
Training loss: 2.333946466445923
Validation loss: 2.257678980468422

Epoch: 5| Step: 3
Training loss: 3.0686099529266357
Validation loss: 2.2677597589390253

Epoch: 5| Step: 4
Training loss: 2.485612154006958
Validation loss: 2.26941180229187

Epoch: 5| Step: 5
Training loss: 2.2214932441711426
Validation loss: 2.2702020214449976

Epoch: 5| Step: 6
Training loss: 2.9732537269592285
Validation loss: 2.2540480090725805

Epoch: 5| Step: 7
Training loss: 1.8802540302276611
Validation loss: 2.2539188938756145

Epoch: 5| Step: 8
Training loss: 1.911717176437378
Validation loss: 2.2556645408753426

Epoch: 5| Step: 9
Training loss: 2.772386074066162
Validation loss: 2.247576951980591

Epoch: 5| Step: 10
Training loss: 1.9462857246398926
Validation loss: 2.240077221265403

Epoch: 196| Step: 0
Training loss: 2.7530643939971924
Validation loss: 2.2325312245276665

Epoch: 5| Step: 1
Training loss: 2.764066457748413
Validation loss: 2.237168535109489

Epoch: 5| Step: 2
Training loss: 2.572140693664551
Validation loss: 2.2405876908251035

Epoch: 5| Step: 3
Training loss: 1.9014179706573486
Validation loss: 2.251075562610421

Epoch: 5| Step: 4
Training loss: 3.0453782081604004
Validation loss: 2.2372015394190305

Epoch: 5| Step: 5
Training loss: 2.129671573638916
Validation loss: 2.2261185594784316

Epoch: 5| Step: 6
Training loss: 2.8381237983703613
Validation loss: 2.231140890429097

Epoch: 5| Step: 7
Training loss: 1.7535810470581055
Validation loss: 2.233044405137339

Epoch: 5| Step: 8
Training loss: 2.1421895027160645
Validation loss: 2.223673279567431

Epoch: 5| Step: 9
Training loss: 1.8635761737823486
Validation loss: 2.2270445708305604

Epoch: 5| Step: 10
Training loss: 1.8634974956512451
Validation loss: 2.216472682132516

Epoch: 197| Step: 0
Training loss: 2.9241857528686523
Validation loss: 2.233249851452407

Epoch: 5| Step: 1
Training loss: 2.4693827629089355
Validation loss: 2.2455868182643766

Epoch: 5| Step: 2
Training loss: 2.204543113708496
Validation loss: 2.2519238994967554

Epoch: 5| Step: 3
Training loss: 1.7102512121200562
Validation loss: 2.251333631494994

Epoch: 5| Step: 4
Training loss: 2.5217127799987793
Validation loss: 2.2417536448406916

Epoch: 5| Step: 5
Training loss: 2.118669033050537
Validation loss: 2.254542327696277

Epoch: 5| Step: 6
Training loss: 2.599919080734253
Validation loss: 2.2401773109230945

Epoch: 5| Step: 7
Training loss: 2.783444881439209
Validation loss: 2.2403629056869017

Epoch: 5| Step: 8
Training loss: 2.1675872802734375
Validation loss: 2.240693279491958

Epoch: 5| Step: 9
Training loss: 1.8918240070343018
Validation loss: 2.2395876017949914

Epoch: 5| Step: 10
Training loss: 2.4295814037323
Validation loss: 2.237564899588144

Epoch: 198| Step: 0
Training loss: 2.2722771167755127
Validation loss: 2.2564421187164965

Epoch: 5| Step: 1
Training loss: 2.4040088653564453
Validation loss: 2.247408866882324

Epoch: 5| Step: 2
Training loss: 2.0344510078430176
Validation loss: 2.236405969947897

Epoch: 5| Step: 3
Training loss: 2.4405605792999268
Validation loss: 2.226942603306104

Epoch: 5| Step: 4
Training loss: 2.449917793273926
Validation loss: 2.231932129270287

Epoch: 5| Step: 5
Training loss: 2.6886098384857178
Validation loss: 2.260285582593692

Epoch: 5| Step: 6
Training loss: 1.938846230506897
Validation loss: 2.2546846661516415

Epoch: 5| Step: 7
Training loss: 1.6391725540161133
Validation loss: 2.2616553998762563

Epoch: 5| Step: 8
Training loss: 2.730980157852173
Validation loss: 2.2630512663113174

Epoch: 5| Step: 9
Training loss: 2.395580530166626
Validation loss: 2.3058585710422967

Epoch: 5| Step: 10
Training loss: 2.7255444526672363
Validation loss: 2.3474747288611626

Epoch: 199| Step: 0
Training loss: 2.344914197921753
Validation loss: 2.3664882054892917

Epoch: 5| Step: 1
Training loss: 1.7309890985488892
Validation loss: 2.3638518805144937

Epoch: 5| Step: 2
Training loss: 3.347628116607666
Validation loss: 2.3749493706610894

Epoch: 5| Step: 3
Training loss: 2.2198257446289062
Validation loss: 2.3613225721543833

Epoch: 5| Step: 4
Training loss: 2.561579942703247
Validation loss: 2.329741952239826

Epoch: 5| Step: 5
Training loss: 2.085881471633911
Validation loss: 2.2840292351220244

Epoch: 5| Step: 6
Training loss: 2.4006850719451904
Validation loss: 2.283768227023463

Epoch: 5| Step: 7
Training loss: 2.0508549213409424
Validation loss: 2.2758894966494654

Epoch: 5| Step: 8
Training loss: 1.9369561672210693
Validation loss: 2.2832874867223922

Epoch: 5| Step: 9
Training loss: 2.7336761951446533
Validation loss: 2.312357756399339

Epoch: 5| Step: 10
Training loss: 2.629319190979004
Validation loss: 2.302076898595338

Epoch: 200| Step: 0
Training loss: 2.157310724258423
Validation loss: 2.3015369087137203

Epoch: 5| Step: 1
Training loss: 2.198840618133545
Validation loss: 2.2625562273046023

Epoch: 5| Step: 2
Training loss: 2.6126439571380615
Validation loss: 2.2517212847227692

Epoch: 5| Step: 3
Training loss: 1.941354751586914
Validation loss: 2.228196551722865

Epoch: 5| Step: 4
Training loss: 2.6845340728759766
Validation loss: 2.208883495740993

Epoch: 5| Step: 5
Training loss: 2.266148090362549
Validation loss: 2.2145560761933685

Epoch: 5| Step: 6
Training loss: 2.409788131713867
Validation loss: 2.206301763493528

Epoch: 5| Step: 7
Training loss: 2.4773080348968506
Validation loss: 2.2322273741486254

Epoch: 5| Step: 8
Training loss: 2.5937795639038086
Validation loss: 2.2423223192973802

Epoch: 5| Step: 9
Training loss: 2.7465713024139404
Validation loss: 2.262649918115267

Epoch: 5| Step: 10
Training loss: 1.863535761833191
Validation loss: 2.2732721297971663

Epoch: 201| Step: 0
Training loss: 2.7219924926757812
Validation loss: 2.2610386033211984

Epoch: 5| Step: 1
Training loss: 2.618616819381714
Validation loss: 2.2468984357772337

Epoch: 5| Step: 2
Training loss: 2.342923164367676
Validation loss: 2.2142119189744354

Epoch: 5| Step: 3
Training loss: 1.421630620956421
Validation loss: 2.199949238889961

Epoch: 5| Step: 4
Training loss: 2.1406350135803223
Validation loss: 2.19456289404182

Epoch: 5| Step: 5
Training loss: 2.4832277297973633
Validation loss: 2.186517943618118

Epoch: 5| Step: 6
Training loss: 1.8949272632598877
Validation loss: 2.1819454187987954

Epoch: 5| Step: 7
Training loss: 2.7636327743530273
Validation loss: 2.185007567046791

Epoch: 5| Step: 8
Training loss: 2.753659725189209
Validation loss: 2.185806583332759

Epoch: 5| Step: 9
Training loss: 2.26847505569458
Validation loss: 2.19292466614836

Epoch: 5| Step: 10
Training loss: 2.558506488800049
Validation loss: 2.2037607316047914

Epoch: 202| Step: 0
Training loss: 2.5922210216522217
Validation loss: 2.212075674405662

Epoch: 5| Step: 1
Training loss: 2.5509567260742188
Validation loss: 2.2184644309423303

Epoch: 5| Step: 2
Training loss: 2.061122179031372
Validation loss: 2.212551873217347

Epoch: 5| Step: 3
Training loss: 2.241436243057251
Validation loss: 2.211521674227971

Epoch: 5| Step: 4
Training loss: 3.178281545639038
Validation loss: 2.21948560848031

Epoch: 5| Step: 5
Training loss: 2.4423470497131348
Validation loss: 2.2286959437913794

Epoch: 5| Step: 6
Training loss: 2.022761583328247
Validation loss: 2.236290495882752

Epoch: 5| Step: 7
Training loss: 2.840496063232422
Validation loss: 2.231135837493404

Epoch: 5| Step: 8
Training loss: 1.9447940587997437
Validation loss: 2.230821382614874

Epoch: 5| Step: 9
Training loss: 2.0282034873962402
Validation loss: 2.2446783306778118

Epoch: 5| Step: 10
Training loss: 1.487945318222046
Validation loss: 2.2511976175410773

Epoch: 203| Step: 0
Training loss: 2.700098991394043
Validation loss: 2.2366734832845707

Epoch: 5| Step: 1
Training loss: 2.8488190174102783
Validation loss: 2.2438160347682174

Epoch: 5| Step: 2
Training loss: 1.7541494369506836
Validation loss: 2.2386180764885357

Epoch: 5| Step: 3
Training loss: 3.0832138061523438
Validation loss: 2.2624963227138726

Epoch: 5| Step: 4
Training loss: 2.12211275100708
Validation loss: 2.2635824808510403

Epoch: 5| Step: 5
Training loss: 2.116246223449707
Validation loss: 2.270022648637013

Epoch: 5| Step: 6
Training loss: 1.925344705581665
Validation loss: 2.255265515337708

Epoch: 5| Step: 7
Training loss: 2.0435802936553955
Validation loss: 2.2313547826582387

Epoch: 5| Step: 8
Training loss: 2.0122876167297363
Validation loss: 2.2126059814166

Epoch: 5| Step: 9
Training loss: 3.0111663341522217
Validation loss: 2.2115062257295013

Epoch: 5| Step: 10
Training loss: 2.0801591873168945
Validation loss: 2.209198646647956

Epoch: 204| Step: 0
Training loss: 2.417811870574951
Validation loss: 2.2125831906513502

Epoch: 5| Step: 1
Training loss: 2.6242775917053223
Validation loss: 2.228841838016305

Epoch: 5| Step: 2
Training loss: 1.6896240711212158
Validation loss: 2.2032276686801704

Epoch: 5| Step: 3
Training loss: 2.68586802482605
Validation loss: 2.215637319831438

Epoch: 5| Step: 4
Training loss: 1.8586938381195068
Validation loss: 2.2076620414692867

Epoch: 5| Step: 5
Training loss: 2.1799163818359375
Validation loss: 2.21456136754764

Epoch: 5| Step: 6
Training loss: 2.327788829803467
Validation loss: 2.211625276073333

Epoch: 5| Step: 7
Training loss: 2.512176513671875
Validation loss: 2.221777617290456

Epoch: 5| Step: 8
Training loss: 2.539926528930664
Validation loss: 2.230253627223353

Epoch: 5| Step: 9
Training loss: 2.0795352458953857
Validation loss: 2.2360175630097747

Epoch: 5| Step: 10
Training loss: 2.471506357192993
Validation loss: 2.2436202982420563

Epoch: 205| Step: 0
Training loss: 1.9431381225585938
Validation loss: 2.2602600794966503

Epoch: 5| Step: 1
Training loss: 3.0464940071105957
Validation loss: 2.2542058370446645

Epoch: 5| Step: 2
Training loss: 2.3442602157592773
Validation loss: 2.2664353514230378

Epoch: 5| Step: 3
Training loss: 1.7781410217285156
Validation loss: 2.2662300191899782

Epoch: 5| Step: 4
Training loss: 2.0186080932617188
Validation loss: 2.27109718579118

Epoch: 5| Step: 5
Training loss: 2.1413073539733887
Validation loss: 2.2944935291044173

Epoch: 5| Step: 6
Training loss: 2.7248587608337402
Validation loss: 2.297164617046233

Epoch: 5| Step: 7
Training loss: 2.182499885559082
Validation loss: 2.268148213304499

Epoch: 5| Step: 8
Training loss: 2.4843297004699707
Validation loss: 2.2343329075844056

Epoch: 5| Step: 9
Training loss: 2.6594398021698
Validation loss: 2.210351538914506

Epoch: 5| Step: 10
Training loss: 2.026489734649658
Validation loss: 2.196051559140605

Epoch: 206| Step: 0
Training loss: 2.6634483337402344
Validation loss: 2.2040820275583575

Epoch: 5| Step: 1
Training loss: 2.648627519607544
Validation loss: 2.2081793995313745

Epoch: 5| Step: 2
Training loss: 1.5919650793075562
Validation loss: 2.1878192322228545

Epoch: 5| Step: 3
Training loss: 1.791118860244751
Validation loss: 2.194919750254641

Epoch: 5| Step: 4
Training loss: 2.591230869293213
Validation loss: 2.2046108989305395

Epoch: 5| Step: 5
Training loss: 2.1944141387939453
Validation loss: 2.203857103983561

Epoch: 5| Step: 6
Training loss: 2.537421226501465
Validation loss: 2.197015454692225

Epoch: 5| Step: 7
Training loss: 2.8083105087280273
Validation loss: 2.20437603868464

Epoch: 5| Step: 8
Training loss: 2.7685537338256836
Validation loss: 2.2169237880296606

Epoch: 5| Step: 9
Training loss: 2.201516628265381
Validation loss: 2.217840502339025

Epoch: 5| Step: 10
Training loss: 1.5157263278961182
Validation loss: 2.2135108901608374

Epoch: 207| Step: 0
Training loss: 2.4228076934814453
Validation loss: 2.2269044665880102

Epoch: 5| Step: 1
Training loss: 1.7511217594146729
Validation loss: 2.2341013928895355

Epoch: 5| Step: 2
Training loss: 2.065624713897705
Validation loss: 2.2471294736349456

Epoch: 5| Step: 3
Training loss: 1.748178482055664
Validation loss: 2.271189187162666

Epoch: 5| Step: 4
Training loss: 2.828465223312378
Validation loss: 2.2843738166234826

Epoch: 5| Step: 5
Training loss: 2.6925854682922363
Validation loss: 2.301503851849546

Epoch: 5| Step: 6
Training loss: 2.2418675422668457
Validation loss: 2.2809645847607682

Epoch: 5| Step: 7
Training loss: 1.7978572845458984
Validation loss: 2.280980495996373

Epoch: 5| Step: 8
Training loss: 2.7638726234436035
Validation loss: 2.2622954768519246

Epoch: 5| Step: 9
Training loss: 3.1558971405029297
Validation loss: 2.267247433303505

Epoch: 5| Step: 10
Training loss: 2.1967360973358154
Validation loss: 2.2682954239588913

Epoch: 208| Step: 0
Training loss: 2.7226102352142334
Validation loss: 2.243250172625306

Epoch: 5| Step: 1
Training loss: 2.3793575763702393
Validation loss: 2.237808448012157

Epoch: 5| Step: 2
Training loss: 1.909787893295288
Validation loss: 2.216500598897216

Epoch: 5| Step: 3
Training loss: 2.016876220703125
Validation loss: 2.217503975796443

Epoch: 5| Step: 4
Training loss: 2.568732261657715
Validation loss: 2.223564955496019

Epoch: 5| Step: 5
Training loss: 1.9083318710327148
Validation loss: 2.222914957231091

Epoch: 5| Step: 6
Training loss: 2.0793731212615967
Validation loss: 2.2284939596729894

Epoch: 5| Step: 7
Training loss: 2.4755425453186035
Validation loss: 2.2167313111725675

Epoch: 5| Step: 8
Training loss: 2.164963483810425
Validation loss: 2.2159786019273984

Epoch: 5| Step: 9
Training loss: 2.319077253341675
Validation loss: 2.205121132635301

Epoch: 5| Step: 10
Training loss: 2.6840860843658447
Validation loss: 2.188545929488315

Epoch: 209| Step: 0
Training loss: 1.9374744892120361
Validation loss: 2.206217283843666

Epoch: 5| Step: 1
Training loss: 2.7885570526123047
Validation loss: 2.197101254617014

Epoch: 5| Step: 2
Training loss: 1.8523569107055664
Validation loss: 2.1914496139813493

Epoch: 5| Step: 3
Training loss: 2.6259427070617676
Validation loss: 2.196203677884994

Epoch: 5| Step: 4
Training loss: 2.263721227645874
Validation loss: 2.184337995385611

Epoch: 5| Step: 5
Training loss: 2.1917483806610107
Validation loss: 2.206188909469112

Epoch: 5| Step: 6
Training loss: 2.7882609367370605
Validation loss: 2.1988751683183896

Epoch: 5| Step: 7
Training loss: 2.224773645401001
Validation loss: 2.2015745665437434

Epoch: 5| Step: 8
Training loss: 1.5479894876480103
Validation loss: 2.200747584783903

Epoch: 5| Step: 9
Training loss: 1.7468124628067017
Validation loss: 2.2109929259105394

Epoch: 5| Step: 10
Training loss: 3.107903242111206
Validation loss: 2.2057155768076577

Epoch: 210| Step: 0
Training loss: 2.1786396503448486
Validation loss: 2.203147224200669

Epoch: 5| Step: 1
Training loss: 2.4217190742492676
Validation loss: 2.2056777836174093

Epoch: 5| Step: 2
Training loss: 2.733213186264038
Validation loss: 2.2074317560401013

Epoch: 5| Step: 3
Training loss: 2.541423797607422
Validation loss: 2.191868643606863

Epoch: 5| Step: 4
Training loss: 2.267232894897461
Validation loss: 2.1965052902057605

Epoch: 5| Step: 5
Training loss: 2.319124937057495
Validation loss: 2.2066226595191547

Epoch: 5| Step: 6
Training loss: 1.8196674585342407
Validation loss: 2.2065172297980196

Epoch: 5| Step: 7
Training loss: 2.1798484325408936
Validation loss: 2.202982848690402

Epoch: 5| Step: 8
Training loss: 2.4230332374572754
Validation loss: 2.2149226178405104

Epoch: 5| Step: 9
Training loss: 1.797410249710083
Validation loss: 2.2257955766493276

Epoch: 5| Step: 10
Training loss: 2.095412492752075
Validation loss: 2.2297281936932634

Epoch: 211| Step: 0
Training loss: 2.4481358528137207
Validation loss: 2.2318412360324653

Epoch: 5| Step: 1
Training loss: 2.2161288261413574
Validation loss: 2.210170581776609

Epoch: 5| Step: 2
Training loss: 2.049510955810547
Validation loss: 2.2248542283170964

Epoch: 5| Step: 3
Training loss: 2.139094591140747
Validation loss: 2.2170846180249284

Epoch: 5| Step: 4
Training loss: 1.7833095788955688
Validation loss: 2.2056259916674708

Epoch: 5| Step: 5
Training loss: 2.092785596847534
Validation loss: 2.203901134511476

Epoch: 5| Step: 6
Training loss: 2.184584140777588
Validation loss: 2.204553557980445

Epoch: 5| Step: 7
Training loss: 2.7366654872894287
Validation loss: 2.2066296915854178

Epoch: 5| Step: 8
Training loss: 2.0880465507507324
Validation loss: 2.196563551502843

Epoch: 5| Step: 9
Training loss: 2.765139102935791
Validation loss: 2.184875485717609

Epoch: 5| Step: 10
Training loss: 2.3737850189208984
Validation loss: 2.168978257845807

Epoch: 212| Step: 0
Training loss: 2.609070301055908
Validation loss: 2.1952496279952345

Epoch: 5| Step: 1
Training loss: 2.1425042152404785
Validation loss: 2.198452252213673

Epoch: 5| Step: 2
Training loss: 2.581305503845215
Validation loss: 2.209918127265028

Epoch: 5| Step: 3
Training loss: 2.3821794986724854
Validation loss: 2.2047561266089

Epoch: 5| Step: 4
Training loss: 2.195028305053711
Validation loss: 2.1901162696141068

Epoch: 5| Step: 5
Training loss: 2.1853034496307373
Validation loss: 2.197270872772381

Epoch: 5| Step: 6
Training loss: 2.6481995582580566
Validation loss: 2.187433229979648

Epoch: 5| Step: 7
Training loss: 2.069822311401367
Validation loss: 2.2014029102940715

Epoch: 5| Step: 8
Training loss: 1.5223222970962524
Validation loss: 2.214295300104285

Epoch: 5| Step: 9
Training loss: 2.532804012298584
Validation loss: 2.2210380543944654

Epoch: 5| Step: 10
Training loss: 2.1849961280822754
Validation loss: 2.2245709767905613

Epoch: 213| Step: 0
Training loss: 2.1117305755615234
Validation loss: 2.2354834489924933

Epoch: 5| Step: 1
Training loss: 2.274887800216675
Validation loss: 2.2252875656209965

Epoch: 5| Step: 2
Training loss: 2.1192009449005127
Validation loss: 2.206377137091852

Epoch: 5| Step: 3
Training loss: 2.5008442401885986
Validation loss: 2.203454144539372

Epoch: 5| Step: 4
Training loss: 1.8225501775741577
Validation loss: 2.182844856733917

Epoch: 5| Step: 5
Training loss: 3.0463805198669434
Validation loss: 2.187181959870041

Epoch: 5| Step: 6
Training loss: 1.9295141696929932
Validation loss: 2.204685625209603

Epoch: 5| Step: 7
Training loss: 2.516169786453247
Validation loss: 2.1949590098473335

Epoch: 5| Step: 8
Training loss: 2.0187082290649414
Validation loss: 2.2009220277109454

Epoch: 5| Step: 9
Training loss: 2.3904032707214355
Validation loss: 2.193182852960402

Epoch: 5| Step: 10
Training loss: 2.1823863983154297
Validation loss: 2.187237831854051

Epoch: 214| Step: 0
Training loss: 2.9408469200134277
Validation loss: 2.1796645669526953

Epoch: 5| Step: 1
Training loss: 2.1251635551452637
Validation loss: 2.1821180159045803

Epoch: 5| Step: 2
Training loss: 2.8452939987182617
Validation loss: 2.199095738831387

Epoch: 5| Step: 3
Training loss: 2.340893268585205
Validation loss: 2.2023073806557605

Epoch: 5| Step: 4
Training loss: 1.3859745264053345
Validation loss: 2.1932917461600354

Epoch: 5| Step: 5
Training loss: 2.1985466480255127
Validation loss: 2.190921216882685

Epoch: 5| Step: 6
Training loss: 2.1141114234924316
Validation loss: 2.187657835663006

Epoch: 5| Step: 7
Training loss: 2.3823235034942627
Validation loss: 2.1863989778744277

Epoch: 5| Step: 8
Training loss: 1.6163381338119507
Validation loss: 2.1964422118279243

Epoch: 5| Step: 9
Training loss: 2.374105453491211
Validation loss: 2.2231197639178206

Epoch: 5| Step: 10
Training loss: 2.4431731700897217
Validation loss: 2.230423314597017

Epoch: 215| Step: 0
Training loss: 2.1316277980804443
Validation loss: 2.244092102973692

Epoch: 5| Step: 1
Training loss: 2.187633991241455
Validation loss: 2.2316055195305937

Epoch: 5| Step: 2
Training loss: 2.2957043647766113
Validation loss: 2.2011391219272407

Epoch: 5| Step: 3
Training loss: 1.8402957916259766
Validation loss: 2.2056227883984967

Epoch: 5| Step: 4
Training loss: 2.3455770015716553
Validation loss: 2.20917857334178

Epoch: 5| Step: 5
Training loss: 2.7310118675231934
Validation loss: 2.2273800373077393

Epoch: 5| Step: 6
Training loss: 2.441044569015503
Validation loss: 2.230263384439612

Epoch: 5| Step: 7
Training loss: 2.090837001800537
Validation loss: 2.2297546248282156

Epoch: 5| Step: 8
Training loss: 2.2481753826141357
Validation loss: 2.2349303409617436

Epoch: 5| Step: 9
Training loss: 2.4159016609191895
Validation loss: 2.2208483398601575

Epoch: 5| Step: 10
Training loss: 2.337319850921631
Validation loss: 2.2372906387493177

Epoch: 216| Step: 0
Training loss: 2.6153335571289062
Validation loss: 2.2183507565529115

Epoch: 5| Step: 1
Training loss: 2.5468831062316895
Validation loss: 2.211066130668886

Epoch: 5| Step: 2
Training loss: 2.9517393112182617
Validation loss: 2.200352132961314

Epoch: 5| Step: 3
Training loss: 2.389633893966675
Validation loss: 2.197128047225296

Epoch: 5| Step: 4
Training loss: 2.1568853855133057
Validation loss: 2.2016427696392102

Epoch: 5| Step: 5
Training loss: 2.2147295475006104
Validation loss: 2.1891520664256108

Epoch: 5| Step: 6
Training loss: 1.686824083328247
Validation loss: 2.172660658436437

Epoch: 5| Step: 7
Training loss: 1.5248922109603882
Validation loss: 2.1648913045083322

Epoch: 5| Step: 8
Training loss: 2.75490403175354
Validation loss: 2.1533437031571583

Epoch: 5| Step: 9
Training loss: 1.9502614736557007
Validation loss: 2.156961175703233

Epoch: 5| Step: 10
Training loss: 2.1000728607177734
Validation loss: 2.160192310169179

Epoch: 217| Step: 0
Training loss: 2.2911083698272705
Validation loss: 2.170284912150393

Epoch: 5| Step: 1
Training loss: 1.9605457782745361
Validation loss: 2.187747178539153

Epoch: 5| Step: 2
Training loss: 2.638789653778076
Validation loss: 2.1768272512702533

Epoch: 5| Step: 3
Training loss: 2.1070897579193115
Validation loss: 2.1880975820684947

Epoch: 5| Step: 4
Training loss: 2.1168549060821533
Validation loss: 2.1853316983869

Epoch: 5| Step: 5
Training loss: 2.4411399364471436
Validation loss: 2.186172531497094

Epoch: 5| Step: 6
Training loss: 2.9713921546936035
Validation loss: 2.1961178113055486

Epoch: 5| Step: 7
Training loss: 1.9733304977416992
Validation loss: 2.188568079343406

Epoch: 5| Step: 8
Training loss: 2.0676164627075195
Validation loss: 2.192854665940808

Epoch: 5| Step: 9
Training loss: 1.9981542825698853
Validation loss: 2.190539521555747

Epoch: 5| Step: 10
Training loss: 2.081380605697632
Validation loss: 2.189470127064695

Epoch: 218| Step: 0
Training loss: 1.9950447082519531
Validation loss: 2.1747324082159225

Epoch: 5| Step: 1
Training loss: 2.296668529510498
Validation loss: 2.1735674642747447

Epoch: 5| Step: 2
Training loss: 2.3021206855773926
Validation loss: 2.1811112921725035

Epoch: 5| Step: 3
Training loss: 2.2718327045440674
Validation loss: 2.184624574517691

Epoch: 5| Step: 4
Training loss: 2.871898651123047
Validation loss: 2.183036473489577

Epoch: 5| Step: 5
Training loss: 2.5804073810577393
Validation loss: 2.184997497066375

Epoch: 5| Step: 6
Training loss: 2.522089719772339
Validation loss: 2.2059646601318033

Epoch: 5| Step: 7
Training loss: 1.7359510660171509
Validation loss: 2.205217033304194

Epoch: 5| Step: 8
Training loss: 1.7228620052337646
Validation loss: 2.205951065145513

Epoch: 5| Step: 9
Training loss: 2.3975327014923096
Validation loss: 2.21140395697727

Epoch: 5| Step: 10
Training loss: 1.5963099002838135
Validation loss: 2.2099853125951623

Epoch: 219| Step: 0
Training loss: 2.029426097869873
Validation loss: 2.192499053093695

Epoch: 5| Step: 1
Training loss: 2.8691961765289307
Validation loss: 2.208014653575036

Epoch: 5| Step: 2
Training loss: 2.0478556156158447
Validation loss: 2.1811018913022933

Epoch: 5| Step: 3
Training loss: 2.6749556064605713
Validation loss: 2.177343286493773

Epoch: 5| Step: 4
Training loss: 1.8836767673492432
Validation loss: 2.1779324598209833

Epoch: 5| Step: 5
Training loss: 1.7297685146331787
Validation loss: 2.153532205089446

Epoch: 5| Step: 6
Training loss: 2.73321795463562
Validation loss: 2.1612254842635124

Epoch: 5| Step: 7
Training loss: 2.0682313442230225
Validation loss: 2.166192957150039

Epoch: 5| Step: 8
Training loss: 1.7575747966766357
Validation loss: 2.1675992858025337

Epoch: 5| Step: 9
Training loss: 2.35749888420105
Validation loss: 2.1739509592774096

Epoch: 5| Step: 10
Training loss: 2.16906476020813
Validation loss: 2.186773447580235

Epoch: 220| Step: 0
Training loss: 1.9243844747543335
Validation loss: 2.173763249510078

Epoch: 5| Step: 1
Training loss: 2.9626739025115967
Validation loss: 2.168194827213082

Epoch: 5| Step: 2
Training loss: 2.321418046951294
Validation loss: 2.1888032715807677

Epoch: 5| Step: 3
Training loss: 1.8220323324203491
Validation loss: 2.201664904112457

Epoch: 5| Step: 4
Training loss: 2.064253330230713
Validation loss: 2.2146848222260833

Epoch: 5| Step: 5
Training loss: 1.6131603717803955
Validation loss: 2.20425170980474

Epoch: 5| Step: 6
Training loss: 1.8253917694091797
Validation loss: 2.206530576111168

Epoch: 5| Step: 7
Training loss: 2.4569315910339355
Validation loss: 2.2079079920245754

Epoch: 5| Step: 8
Training loss: 2.2781224250793457
Validation loss: 2.213714171481389

Epoch: 5| Step: 9
Training loss: 2.5452158451080322
Validation loss: 2.2157535117159606

Epoch: 5| Step: 10
Training loss: 2.659365653991699
Validation loss: 2.210272858219762

Epoch: 221| Step: 0
Training loss: 3.1295573711395264
Validation loss: 2.190357280033891

Epoch: 5| Step: 1
Training loss: 1.6300556659698486
Validation loss: 2.179748571047219

Epoch: 5| Step: 2
Training loss: 2.6246399879455566
Validation loss: 2.174253398372281

Epoch: 5| Step: 3
Training loss: 2.4247994422912598
Validation loss: 2.162995446112848

Epoch: 5| Step: 4
Training loss: 2.756171941757202
Validation loss: 2.1623958823501424

Epoch: 5| Step: 5
Training loss: 2.195427417755127
Validation loss: 2.1610262752861105

Epoch: 5| Step: 6
Training loss: 1.6939513683319092
Validation loss: 2.16304842118294

Epoch: 5| Step: 7
Training loss: 2.047609806060791
Validation loss: 2.152876821897363

Epoch: 5| Step: 8
Training loss: 2.228257656097412
Validation loss: 2.168889411034123

Epoch: 5| Step: 9
Training loss: 2.0215654373168945
Validation loss: 2.165865648177362

Epoch: 5| Step: 10
Training loss: 1.4995697736740112
Validation loss: 2.1847624291655836

Epoch: 222| Step: 0
Training loss: 2.472132444381714
Validation loss: 2.195590939573062

Epoch: 5| Step: 1
Training loss: 2.0228419303894043
Validation loss: 2.176420803992979

Epoch: 5| Step: 2
Training loss: 2.6433024406433105
Validation loss: 2.2032592270963933

Epoch: 5| Step: 3
Training loss: 1.8018001317977905
Validation loss: 2.213563347375521

Epoch: 5| Step: 4
Training loss: 2.1583964824676514
Validation loss: 2.236937794634091

Epoch: 5| Step: 5
Training loss: 1.9662444591522217
Validation loss: 2.2597033977508545

Epoch: 5| Step: 6
Training loss: 2.9668874740600586
Validation loss: 2.234622698958202

Epoch: 5| Step: 7
Training loss: 1.9008548259735107
Validation loss: 2.2487888464363675

Epoch: 5| Step: 8
Training loss: 2.3023829460144043
Validation loss: 2.240197789284491

Epoch: 5| Step: 9
Training loss: 2.0815770626068115
Validation loss: 2.2146804332733154

Epoch: 5| Step: 10
Training loss: 2.160351514816284
Validation loss: 2.2307896050073768

Epoch: 223| Step: 0
Training loss: 2.4620518684387207
Validation loss: 2.2258227102218138

Epoch: 5| Step: 1
Training loss: 1.9814989566802979
Validation loss: 2.2237501157227384

Epoch: 5| Step: 2
Training loss: 1.8803209066390991
Validation loss: 2.226996168013542

Epoch: 5| Step: 3
Training loss: 2.318951368331909
Validation loss: 2.2003519124882196

Epoch: 5| Step: 4
Training loss: 2.7405261993408203
Validation loss: 2.189736899509225

Epoch: 5| Step: 5
Training loss: 2.4084763526916504
Validation loss: 2.1748502254486084

Epoch: 5| Step: 6
Training loss: 1.5478522777557373
Validation loss: 2.170926906729257

Epoch: 5| Step: 7
Training loss: 2.3063533306121826
Validation loss: 2.1689915759589082

Epoch: 5| Step: 8
Training loss: 1.9379692077636719
Validation loss: 2.179655280164493

Epoch: 5| Step: 9
Training loss: 2.4077141284942627
Validation loss: 2.1788583340183383

Epoch: 5| Step: 10
Training loss: 2.399660110473633
Validation loss: 2.18616218977077

Epoch: 224| Step: 0
Training loss: 1.5331207513809204
Validation loss: 2.197123642890684

Epoch: 5| Step: 1
Training loss: 3.0936973094940186
Validation loss: 2.211914511137111

Epoch: 5| Step: 2
Training loss: 2.9268531799316406
Validation loss: 2.195872219659949

Epoch: 5| Step: 3
Training loss: 2.6017823219299316
Validation loss: 2.200886477706253

Epoch: 5| Step: 4
Training loss: 1.9300485849380493
Validation loss: 2.2011699317603983

Epoch: 5| Step: 5
Training loss: 2.5201210975646973
Validation loss: 2.1747009779817317

Epoch: 5| Step: 6
Training loss: 1.6590938568115234
Validation loss: 2.170325089526433

Epoch: 5| Step: 7
Training loss: 1.8607107400894165
Validation loss: 2.1611166872004026

Epoch: 5| Step: 8
Training loss: 2.254912853240967
Validation loss: 2.1630477648909374

Epoch: 5| Step: 9
Training loss: 2.0013694763183594
Validation loss: 2.167666353205199

Epoch: 5| Step: 10
Training loss: 2.3564162254333496
Validation loss: 2.1689697542498187

Epoch: 225| Step: 0
Training loss: 2.3407859802246094
Validation loss: 2.178321171832341

Epoch: 5| Step: 1
Training loss: 1.6234159469604492
Validation loss: 2.1814617700474237

Epoch: 5| Step: 2
Training loss: 1.8594805002212524
Validation loss: 2.181456140292588

Epoch: 5| Step: 3
Training loss: 2.1989731788635254
Validation loss: 2.202649994563031

Epoch: 5| Step: 4
Training loss: 2.047071695327759
Validation loss: 2.2167080345974175

Epoch: 5| Step: 5
Training loss: 2.131434202194214
Validation loss: 2.2031073134432555

Epoch: 5| Step: 6
Training loss: 2.2222933769226074
Validation loss: 2.2119882055508193

Epoch: 5| Step: 7
Training loss: 2.2564187049865723
Validation loss: 2.2029404678652362

Epoch: 5| Step: 8
Training loss: 2.4581990242004395
Validation loss: 2.202201583052194

Epoch: 5| Step: 9
Training loss: 2.7271230220794678
Validation loss: 2.2032939900634108

Epoch: 5| Step: 10
Training loss: 2.4282984733581543
Validation loss: 2.1853740651120424

Epoch: 226| Step: 0
Training loss: 1.8386989831924438
Validation loss: 2.1979474816271054

Epoch: 5| Step: 1
Training loss: 2.8803727626800537
Validation loss: 2.1790535552527315

Epoch: 5| Step: 2
Training loss: 1.9173316955566406
Validation loss: 2.1676523788000948

Epoch: 5| Step: 3
Training loss: 2.1894423961639404
Validation loss: 2.1649092166654524

Epoch: 5| Step: 4
Training loss: 1.7438997030258179
Validation loss: 2.1796614098292526

Epoch: 5| Step: 5
Training loss: 2.4545207023620605
Validation loss: 2.186739412687158

Epoch: 5| Step: 6
Training loss: 2.0180039405822754
Validation loss: 2.187334701579104

Epoch: 5| Step: 7
Training loss: 2.54691743850708
Validation loss: 2.2086180922805623

Epoch: 5| Step: 8
Training loss: 2.134765148162842
Validation loss: 2.215227700048877

Epoch: 5| Step: 9
Training loss: 2.6240429878234863
Validation loss: 2.2043435265941005

Epoch: 5| Step: 10
Training loss: 1.7940031290054321
Validation loss: 2.1670224153867332

Epoch: 227| Step: 0
Training loss: 2.379459857940674
Validation loss: 2.158155566902571

Epoch: 5| Step: 1
Training loss: 2.352341651916504
Validation loss: 2.1607325448784778

Epoch: 5| Step: 2
Training loss: 1.8545325994491577
Validation loss: 2.160096804300944

Epoch: 5| Step: 3
Training loss: 1.9916117191314697
Validation loss: 2.146548294251965

Epoch: 5| Step: 4
Training loss: 2.2026262283325195
Validation loss: 2.1479700714029293

Epoch: 5| Step: 5
Training loss: 2.7970681190490723
Validation loss: 2.1497667733059136

Epoch: 5| Step: 6
Training loss: 2.004408121109009
Validation loss: 2.1314113832289174

Epoch: 5| Step: 7
Training loss: 1.9418697357177734
Validation loss: 2.151077646081166

Epoch: 5| Step: 8
Training loss: 2.0223281383514404
Validation loss: 2.141678515300956

Epoch: 5| Step: 9
Training loss: 2.3955798149108887
Validation loss: 2.149348989609749

Epoch: 5| Step: 10
Training loss: 2.0408196449279785
Validation loss: 2.1415600340853453

Epoch: 228| Step: 0
Training loss: 2.394404888153076
Validation loss: 2.146808164094084

Epoch: 5| Step: 1
Training loss: 2.4545788764953613
Validation loss: 2.1619368035306215

Epoch: 5| Step: 2
Training loss: 1.9265563488006592
Validation loss: 2.166410251330304

Epoch: 5| Step: 3
Training loss: 2.434298515319824
Validation loss: 2.171209860873479

Epoch: 5| Step: 4
Training loss: 1.6614353656768799
Validation loss: 2.1853987632259244

Epoch: 5| Step: 5
Training loss: 2.4061930179595947
Validation loss: 2.1879133588524273

Epoch: 5| Step: 6
Training loss: 2.713872194290161
Validation loss: 2.2104179448978876

Epoch: 5| Step: 7
Training loss: 1.7580955028533936
Validation loss: 2.1781732548949537

Epoch: 5| Step: 8
Training loss: 1.8535873889923096
Validation loss: 2.1744612801459526

Epoch: 5| Step: 9
Training loss: 2.1082615852355957
Validation loss: 2.1809814348015735

Epoch: 5| Step: 10
Training loss: 2.4980640411376953
Validation loss: 2.169296444103282

Epoch: 229| Step: 0
Training loss: 1.6471506357192993
Validation loss: 2.15269559942266

Epoch: 5| Step: 1
Training loss: 2.608654022216797
Validation loss: 2.135858630621305

Epoch: 5| Step: 2
Training loss: 2.3900961875915527
Validation loss: 2.136718502608679

Epoch: 5| Step: 3
Training loss: 2.5118746757507324
Validation loss: 2.1204338291639924

Epoch: 5| Step: 4
Training loss: 2.0801756381988525
Validation loss: 2.127075861859065

Epoch: 5| Step: 5
Training loss: 2.1368212699890137
Validation loss: 2.118902590966994

Epoch: 5| Step: 6
Training loss: 2.441577434539795
Validation loss: 2.115161818842734

Epoch: 5| Step: 7
Training loss: 2.136244058609009
Validation loss: 2.1111387732208415

Epoch: 5| Step: 8
Training loss: 2.059697389602661
Validation loss: 2.114193149792251

Epoch: 5| Step: 9
Training loss: 1.8200165033340454
Validation loss: 2.1249378547873548

Epoch: 5| Step: 10
Training loss: 2.3257575035095215
Validation loss: 2.1457043001728673

Epoch: 230| Step: 0
Training loss: 1.5104186534881592
Validation loss: 2.1754757691455144

Epoch: 5| Step: 1
Training loss: 1.851009726524353
Validation loss: 2.2100086007066952

Epoch: 5| Step: 2
Training loss: 2.067913055419922
Validation loss: 2.2359658236144693

Epoch: 5| Step: 3
Training loss: 1.950174331665039
Validation loss: 2.2184921695340063

Epoch: 5| Step: 4
Training loss: 2.5216455459594727
Validation loss: 2.1992450375710764

Epoch: 5| Step: 5
Training loss: 2.831627607345581
Validation loss: 2.178172944694437

Epoch: 5| Step: 6
Training loss: 2.052982807159424
Validation loss: 2.149630838824857

Epoch: 5| Step: 7
Training loss: 2.4980504512786865
Validation loss: 2.161141795496787

Epoch: 5| Step: 8
Training loss: 2.6461362838745117
Validation loss: 2.165347885060054

Epoch: 5| Step: 9
Training loss: 2.2318522930145264
Validation loss: 2.185860485158941

Epoch: 5| Step: 10
Training loss: 2.0470263957977295
Validation loss: 2.189717278685621

Epoch: 231| Step: 0
Training loss: 2.6632766723632812
Validation loss: 2.180922741531044

Epoch: 5| Step: 1
Training loss: 1.9549806118011475
Validation loss: 2.1750169287445726

Epoch: 5| Step: 2
Training loss: 1.9809045791625977
Validation loss: 2.1582404669894966

Epoch: 5| Step: 3
Training loss: 2.3217997550964355
Validation loss: 2.130194256382604

Epoch: 5| Step: 4
Training loss: 2.106788158416748
Validation loss: 2.1409258534831386

Epoch: 5| Step: 5
Training loss: 1.2674480676651
Validation loss: 2.128695490539715

Epoch: 5| Step: 6
Training loss: 1.5929219722747803
Validation loss: 2.126173029663742

Epoch: 5| Step: 7
Training loss: 3.0610883235931396
Validation loss: 2.1466443025937645

Epoch: 5| Step: 8
Training loss: 2.6819748878479004
Validation loss: 2.146629148913968

Epoch: 5| Step: 9
Training loss: 2.32918119430542
Validation loss: 2.156997098717638

Epoch: 5| Step: 10
Training loss: 2.3900699615478516
Validation loss: 2.1678507725397744

Epoch: 232| Step: 0
Training loss: 2.066418409347534
Validation loss: 2.167421522960868

Epoch: 5| Step: 1
Training loss: 2.2436416149139404
Validation loss: 2.164217190075946

Epoch: 5| Step: 2
Training loss: 2.3075690269470215
Validation loss: 2.1906055660657984

Epoch: 5| Step: 3
Training loss: 1.63858962059021
Validation loss: 2.1820940407373572

Epoch: 5| Step: 4
Training loss: 1.8853051662445068
Validation loss: 2.1885773853589128

Epoch: 5| Step: 5
Training loss: 1.578730583190918
Validation loss: 2.192519977528562

Epoch: 5| Step: 6
Training loss: 2.4477715492248535
Validation loss: 2.188899891350859

Epoch: 5| Step: 7
Training loss: 2.225217342376709
Validation loss: 2.2036764134642897

Epoch: 5| Step: 8
Training loss: 2.598879814147949
Validation loss: 2.210316777229309

Epoch: 5| Step: 9
Training loss: 2.4429335594177246
Validation loss: 2.1874497372617006

Epoch: 5| Step: 10
Training loss: 2.49570631980896
Validation loss: 2.1687584000249065

Epoch: 233| Step: 0
Training loss: 1.4261116981506348
Validation loss: 2.1566674773411085

Epoch: 5| Step: 1
Training loss: 1.9467697143554688
Validation loss: 2.1508796471421436

Epoch: 5| Step: 2
Training loss: 2.222548007965088
Validation loss: 2.137066948798395

Epoch: 5| Step: 3
Training loss: 2.063815116882324
Validation loss: 2.1363226418854087

Epoch: 5| Step: 4
Training loss: 2.300973415374756
Validation loss: 2.1359232574380855

Epoch: 5| Step: 5
Training loss: 2.2185091972351074
Validation loss: 2.1360796266986477

Epoch: 5| Step: 6
Training loss: 2.5871174335479736
Validation loss: 2.1233187196075276

Epoch: 5| Step: 7
Training loss: 2.331127643585205
Validation loss: 2.1199483538186676

Epoch: 5| Step: 8
Training loss: 2.079481601715088
Validation loss: 2.119641101488503

Epoch: 5| Step: 9
Training loss: 2.0895533561706543
Validation loss: 2.139584440056996

Epoch: 5| Step: 10
Training loss: 2.460099697113037
Validation loss: 2.1220098182719243

Epoch: 234| Step: 0
Training loss: 2.3799259662628174
Validation loss: 2.1508400645307315

Epoch: 5| Step: 1
Training loss: 2.5710113048553467
Validation loss: 2.1355048187317385

Epoch: 5| Step: 2
Training loss: 1.8388172388076782
Validation loss: 2.1296449707400416

Epoch: 5| Step: 3
Training loss: 2.0324859619140625
Validation loss: 2.1359679468216433

Epoch: 5| Step: 4
Training loss: 2.3188531398773193
Validation loss: 2.150159848633633

Epoch: 5| Step: 5
Training loss: 2.0529561042785645
Validation loss: 2.148360844581358

Epoch: 5| Step: 6
Training loss: 2.004873752593994
Validation loss: 2.155912609510524

Epoch: 5| Step: 7
Training loss: 2.5996975898742676
Validation loss: 2.15226419766744

Epoch: 5| Step: 8
Training loss: 2.5450332164764404
Validation loss: 2.1515253615635697

Epoch: 5| Step: 9
Training loss: 1.3518189191818237
Validation loss: 2.156410148066859

Epoch: 5| Step: 10
Training loss: 1.9143569469451904
Validation loss: 2.1405611512481526

Epoch: 235| Step: 0
Training loss: 1.999449372291565
Validation loss: 2.1509841565162904

Epoch: 5| Step: 1
Training loss: 2.151829481124878
Validation loss: 2.168766539583924

Epoch: 5| Step: 2
Training loss: 1.8158966302871704
Validation loss: 2.1968001498970935

Epoch: 5| Step: 3
Training loss: 1.5682529211044312
Validation loss: 2.2012944208678378

Epoch: 5| Step: 4
Training loss: 2.2240207195281982
Validation loss: 2.2266729570204213

Epoch: 5| Step: 5
Training loss: 2.4626691341400146
Validation loss: 2.2547048163670365

Epoch: 5| Step: 6
Training loss: 2.21860671043396
Validation loss: 2.211496373658539

Epoch: 5| Step: 7
Training loss: 2.330294132232666
Validation loss: 2.1907271723593436

Epoch: 5| Step: 8
Training loss: 2.2629475593566895
Validation loss: 2.1787010033925376

Epoch: 5| Step: 9
Training loss: 2.2265238761901855
Validation loss: 2.154333943961769

Epoch: 5| Step: 10
Training loss: 2.745737075805664
Validation loss: 2.1565228149455082

Epoch: 236| Step: 0
Training loss: 1.6854276657104492
Validation loss: 2.144658851367171

Epoch: 5| Step: 1
Training loss: 2.4103236198425293
Validation loss: 2.1558490696773736

Epoch: 5| Step: 2
Training loss: 2.406118869781494
Validation loss: 2.1495879414261028

Epoch: 5| Step: 3
Training loss: 1.6188102960586548
Validation loss: 2.1553813154979418

Epoch: 5| Step: 4
Training loss: 2.859760046005249
Validation loss: 2.145135095042567

Epoch: 5| Step: 5
Training loss: 2.429610252380371
Validation loss: 2.1494591338660127

Epoch: 5| Step: 6
Training loss: 2.135990619659424
Validation loss: 2.151406270201488

Epoch: 5| Step: 7
Training loss: 2.019562244415283
Validation loss: 2.146512991638594

Epoch: 5| Step: 8
Training loss: 2.6874942779541016
Validation loss: 2.1627229964861305

Epoch: 5| Step: 9
Training loss: 1.9766013622283936
Validation loss: 2.1587391335477113

Epoch: 5| Step: 10
Training loss: 1.548155426979065
Validation loss: 2.170006485395534

Epoch: 237| Step: 0
Training loss: 2.332475423812866
Validation loss: 2.1656139281488236

Epoch: 5| Step: 1
Training loss: 2.244729518890381
Validation loss: 2.167797193732313

Epoch: 5| Step: 2
Training loss: 1.7553164958953857
Validation loss: 2.1605860840889717

Epoch: 5| Step: 3
Training loss: 1.988247275352478
Validation loss: 2.1728737559369815

Epoch: 5| Step: 4
Training loss: 2.2016310691833496
Validation loss: 2.160861853630312

Epoch: 5| Step: 5
Training loss: 2.1828718185424805
Validation loss: 2.156485528074285

Epoch: 5| Step: 6
Training loss: 2.8514273166656494
Validation loss: 2.1658722739065848

Epoch: 5| Step: 7
Training loss: 1.7896426916122437
Validation loss: 2.15386329543206

Epoch: 5| Step: 8
Training loss: 2.5841751098632812
Validation loss: 2.152683263183922

Epoch: 5| Step: 9
Training loss: 2.175281524658203
Validation loss: 2.1467054966957337

Epoch: 5| Step: 10
Training loss: 1.336869478225708
Validation loss: 2.1533421624091362

Epoch: 238| Step: 0
Training loss: 1.8445713520050049
Validation loss: 2.1508185760949248

Epoch: 5| Step: 1
Training loss: 1.9738439321517944
Validation loss: 2.136398028301936

Epoch: 5| Step: 2
Training loss: 1.8701616525650024
Validation loss: 2.1456303365768923

Epoch: 5| Step: 3
Training loss: 2.4816501140594482
Validation loss: 2.1503608393412765

Epoch: 5| Step: 4
Training loss: 2.444852352142334
Validation loss: 2.1508869317270096

Epoch: 5| Step: 5
Training loss: 2.1536262035369873
Validation loss: 2.1502372808353876

Epoch: 5| Step: 6
Training loss: 2.056483745574951
Validation loss: 2.147655064059842

Epoch: 5| Step: 7
Training loss: 1.9142110347747803
Validation loss: 2.1467663318880144

Epoch: 5| Step: 8
Training loss: 2.5387721061706543
Validation loss: 2.152424963571692

Epoch: 5| Step: 9
Training loss: 2.3259835243225098
Validation loss: 2.1455186002997944

Epoch: 5| Step: 10
Training loss: 1.6940120458602905
Validation loss: 2.1405675090769285

Epoch: 239| Step: 0
Training loss: 2.529740810394287
Validation loss: 2.1326981257366877

Epoch: 5| Step: 1
Training loss: 2.01649808883667
Validation loss: 2.116979932272306

Epoch: 5| Step: 2
Training loss: 1.4626915454864502
Validation loss: 2.1252991358439126

Epoch: 5| Step: 3
Training loss: 1.9268596172332764
Validation loss: 2.134743546926847

Epoch: 5| Step: 4
Training loss: 2.2138843536376953
Validation loss: 2.1378912810356385

Epoch: 5| Step: 5
Training loss: 2.151787042617798
Validation loss: 2.1199608284940004

Epoch: 5| Step: 6
Training loss: 2.1659531593322754
Validation loss: 2.1290331707205823

Epoch: 5| Step: 7
Training loss: 2.4123244285583496
Validation loss: 2.1308140870063537

Epoch: 5| Step: 8
Training loss: 1.9627126455307007
Validation loss: 2.122161547342936

Epoch: 5| Step: 9
Training loss: 2.5880885124206543
Validation loss: 2.121275560830229

Epoch: 5| Step: 10
Training loss: 1.8630292415618896
Validation loss: 2.118896843284689

Epoch: 240| Step: 0
Training loss: 2.174522876739502
Validation loss: 2.1354502452317106

Epoch: 5| Step: 1
Training loss: 2.0493435859680176
Validation loss: 2.1358306061836982

Epoch: 5| Step: 2
Training loss: 1.7392069101333618
Validation loss: 2.1371173397187264

Epoch: 5| Step: 3
Training loss: 1.5645091533660889
Validation loss: 2.1449752725580686

Epoch: 5| Step: 4
Training loss: 2.518953561782837
Validation loss: 2.1566402527593795

Epoch: 5| Step: 5
Training loss: 2.0873305797576904
Validation loss: 2.1560459803509455

Epoch: 5| Step: 6
Training loss: 1.7132759094238281
Validation loss: 2.17146437270667

Epoch: 5| Step: 7
Training loss: 2.136704683303833
Validation loss: 2.187408490847516

Epoch: 5| Step: 8
Training loss: 3.0505552291870117
Validation loss: 2.1847246975027104

Epoch: 5| Step: 9
Training loss: 2.01827335357666
Validation loss: 2.1791009633771834

Epoch: 5| Step: 10
Training loss: 2.427375078201294
Validation loss: 2.2064900116253923

Epoch: 241| Step: 0
Training loss: 2.7779057025909424
Validation loss: 2.1852730345982376

Epoch: 5| Step: 1
Training loss: 2.312854290008545
Validation loss: 2.169456845970564

Epoch: 5| Step: 2
Training loss: 2.438312292098999
Validation loss: 2.1481118971301663

Epoch: 5| Step: 3
Training loss: 2.416698932647705
Validation loss: 2.117656719300055

Epoch: 5| Step: 4
Training loss: 1.3162970542907715
Validation loss: 2.111335756958172

Epoch: 5| Step: 5
Training loss: 1.8686563968658447
Validation loss: 2.0949196379671813

Epoch: 5| Step: 6
Training loss: 2.4339377880096436
Validation loss: 2.097697610496193

Epoch: 5| Step: 7
Training loss: 1.7855300903320312
Validation loss: 2.1143481321232294

Epoch: 5| Step: 8
Training loss: 1.8703880310058594
Validation loss: 2.1322466609298543

Epoch: 5| Step: 9
Training loss: 1.949267029762268
Validation loss: 2.1338962406240483

Epoch: 5| Step: 10
Training loss: 2.6190690994262695
Validation loss: 2.1521500284953783

Epoch: 242| Step: 0
Training loss: 1.8926690816879272
Validation loss: 2.136025341608191

Epoch: 5| Step: 1
Training loss: 2.364807605743408
Validation loss: 2.1556661680180538

Epoch: 5| Step: 2
Training loss: 1.5877068042755127
Validation loss: 2.138816924505336

Epoch: 5| Step: 3
Training loss: 2.0597314834594727
Validation loss: 2.142832306123549

Epoch: 5| Step: 4
Training loss: 2.3320364952087402
Validation loss: 2.1517852249965874

Epoch: 5| Step: 5
Training loss: 1.959678292274475
Validation loss: 2.1501962779670634

Epoch: 5| Step: 6
Training loss: 2.3356008529663086
Validation loss: 2.152664804971346

Epoch: 5| Step: 7
Training loss: 2.112597942352295
Validation loss: 2.1554040498630975

Epoch: 5| Step: 8
Training loss: 2.121523380279541
Validation loss: 2.1473991665788876

Epoch: 5| Step: 9
Training loss: 2.5024514198303223
Validation loss: 2.1429745535696707

Epoch: 5| Step: 10
Training loss: 2.089123010635376
Validation loss: 2.1232482489719184

Epoch: 243| Step: 0
Training loss: 2.171708345413208
Validation loss: 2.1032928997470486

Epoch: 5| Step: 1
Training loss: 1.8383891582489014
Validation loss: 2.1063090396183792

Epoch: 5| Step: 2
Training loss: 1.8908824920654297
Validation loss: 2.100098917561193

Epoch: 5| Step: 3
Training loss: 2.07100248336792
Validation loss: 2.095607065385388

Epoch: 5| Step: 4
Training loss: 2.071789264678955
Validation loss: 2.1162201691699285

Epoch: 5| Step: 5
Training loss: 2.671678304672241
Validation loss: 2.1280591334066083

Epoch: 5| Step: 6
Training loss: 2.359865665435791
Validation loss: 2.1146423739771687

Epoch: 5| Step: 7
Training loss: 2.2198781967163086
Validation loss: 2.12266275190538

Epoch: 5| Step: 8
Training loss: 1.782149076461792
Validation loss: 2.1280415058135986

Epoch: 5| Step: 9
Training loss: 2.2310714721679688
Validation loss: 2.1192797973591793

Epoch: 5| Step: 10
Training loss: 2.0093400478363037
Validation loss: 2.113988866088211

Epoch: 244| Step: 0
Training loss: 2.638881206512451
Validation loss: 2.118526730486142

Epoch: 5| Step: 1
Training loss: 1.972557783126831
Validation loss: 2.1181768166121615

Epoch: 5| Step: 2
Training loss: 2.3080406188964844
Validation loss: 2.1363099364824194

Epoch: 5| Step: 3
Training loss: 2.9709150791168213
Validation loss: 2.1520828790562128

Epoch: 5| Step: 4
Training loss: 1.3940092325210571
Validation loss: 2.141812880833944

Epoch: 5| Step: 5
Training loss: 2.268096446990967
Validation loss: 2.1449686327288227

Epoch: 5| Step: 6
Training loss: 2.153909206390381
Validation loss: 2.1393149001623994

Epoch: 5| Step: 7
Training loss: 1.759447693824768
Validation loss: 2.136843067343517

Epoch: 5| Step: 8
Training loss: 1.895782709121704
Validation loss: 2.1183283662283294

Epoch: 5| Step: 9
Training loss: 2.1438233852386475
Validation loss: 2.105006114129097

Epoch: 5| Step: 10
Training loss: 1.6646177768707275
Validation loss: 2.103025662001743

Epoch: 245| Step: 0
Training loss: 2.315765619277954
Validation loss: 2.1173917555039927

Epoch: 5| Step: 1
Training loss: 1.6236021518707275
Validation loss: 2.139698067019063

Epoch: 5| Step: 2
Training loss: 1.9361721277236938
Validation loss: 2.139452334373228

Epoch: 5| Step: 3
Training loss: 2.5880677700042725
Validation loss: 2.132779828963741

Epoch: 5| Step: 4
Training loss: 2.0209126472473145
Validation loss: 2.1508271232728036

Epoch: 5| Step: 5
Training loss: 1.468222975730896
Validation loss: 2.1527505420869395

Epoch: 5| Step: 6
Training loss: 2.1183457374572754
Validation loss: 2.143879741750738

Epoch: 5| Step: 7
Training loss: 2.705615997314453
Validation loss: 2.141796258188063

Epoch: 5| Step: 8
Training loss: 2.424792766571045
Validation loss: 2.1537094359756797

Epoch: 5| Step: 9
Training loss: 1.977220892906189
Validation loss: 2.1380424089329217

Epoch: 5| Step: 10
Training loss: 2.015129327774048
Validation loss: 2.136734721481159

Epoch: 246| Step: 0
Training loss: 1.8841482400894165
Validation loss: 2.129721313394526

Epoch: 5| Step: 1
Training loss: 2.7752082347869873
Validation loss: 2.1285811316582466

Epoch: 5| Step: 2
Training loss: 2.129512310028076
Validation loss: 2.131560197440527

Epoch: 5| Step: 3
Training loss: 2.0066606998443604
Validation loss: 2.12913707763918

Epoch: 5| Step: 4
Training loss: 2.521120548248291
Validation loss: 2.1145893002069123

Epoch: 5| Step: 5
Training loss: 1.9134525060653687
Validation loss: 2.0999129638876965

Epoch: 5| Step: 6
Training loss: 1.983525276184082
Validation loss: 2.108253748186173

Epoch: 5| Step: 7
Training loss: 2.1954269409179688
Validation loss: 2.1112185960174887

Epoch: 5| Step: 8
Training loss: 1.6819130182266235
Validation loss: 2.1258729504000757

Epoch: 5| Step: 9
Training loss: 2.3524317741394043
Validation loss: 2.1129807156901204

Epoch: 5| Step: 10
Training loss: 1.4535189867019653
Validation loss: 2.103447106576735

Epoch: 247| Step: 0
Training loss: 1.8877642154693604
Validation loss: 2.1136494234044063

Epoch: 5| Step: 1
Training loss: 2.257275342941284
Validation loss: 2.1225885370726227

Epoch: 5| Step: 2
Training loss: 1.9305871725082397
Validation loss: 2.0977125296028714

Epoch: 5| Step: 3
Training loss: 2.1163008213043213
Validation loss: 2.111990410794494

Epoch: 5| Step: 4
Training loss: 2.2815582752227783
Validation loss: 2.1149827972535165

Epoch: 5| Step: 5
Training loss: 2.672159194946289
Validation loss: 2.1062788373680523

Epoch: 5| Step: 6
Training loss: 1.5584911108016968
Validation loss: 2.096939104859547

Epoch: 5| Step: 7
Training loss: 1.9526119232177734
Validation loss: 2.0956180326400267

Epoch: 5| Step: 8
Training loss: 2.0788261890411377
Validation loss: 2.09470861188827

Epoch: 5| Step: 9
Training loss: 2.1510119438171387
Validation loss: 2.0947377668913973

Epoch: 5| Step: 10
Training loss: 1.99984610080719
Validation loss: 2.095269408277286

Epoch: 248| Step: 0
Training loss: 2.8424243927001953
Validation loss: 2.091613451639811

Epoch: 5| Step: 1
Training loss: 1.9219157695770264
Validation loss: 2.098229903046803

Epoch: 5| Step: 2
Training loss: 1.6581586599349976
Validation loss: 2.106687100984717

Epoch: 5| Step: 3
Training loss: 1.633479118347168
Validation loss: 2.1022584643415225

Epoch: 5| Step: 4
Training loss: 2.393998622894287
Validation loss: 2.1024542726496214

Epoch: 5| Step: 5
Training loss: 1.6889032125473022
Validation loss: 2.097079530838997

Epoch: 5| Step: 6
Training loss: 2.0962960720062256
Validation loss: 2.105409742683493

Epoch: 5| Step: 7
Training loss: 2.294590711593628
Validation loss: 2.087461292102773

Epoch: 5| Step: 8
Training loss: 1.8268970251083374
Validation loss: 2.0823562401597218

Epoch: 5| Step: 9
Training loss: 2.3975112438201904
Validation loss: 2.093607243671212

Epoch: 5| Step: 10
Training loss: 2.0645694732666016
Validation loss: 2.109683190622637

Epoch: 249| Step: 0
Training loss: 1.9863317012786865
Validation loss: 2.1308154136903825

Epoch: 5| Step: 1
Training loss: 2.089625597000122
Validation loss: 2.133792846433578

Epoch: 5| Step: 2
Training loss: 3.1451878547668457
Validation loss: 2.1357345042690152

Epoch: 5| Step: 3
Training loss: 1.8772056102752686
Validation loss: 2.149954236963744

Epoch: 5| Step: 4
Training loss: 2.1702141761779785
Validation loss: 2.1468921630613265

Epoch: 5| Step: 5
Training loss: 2.120607852935791
Validation loss: 2.140919716127457

Epoch: 5| Step: 6
Training loss: 1.8236099481582642
Validation loss: 2.1452650703409666

Epoch: 5| Step: 7
Training loss: 1.5402393341064453
Validation loss: 2.144161980639222

Epoch: 5| Step: 8
Training loss: 2.141569137573242
Validation loss: 2.127556006113688

Epoch: 5| Step: 9
Training loss: 1.893776297569275
Validation loss: 2.136087361202445

Epoch: 5| Step: 10
Training loss: 2.0873825550079346
Validation loss: 2.1300366360654115

Epoch: 250| Step: 0
Training loss: 2.2163138389587402
Validation loss: 2.107636974703881

Epoch: 5| Step: 1
Training loss: 1.8042325973510742
Validation loss: 2.1096230476133284

Epoch: 5| Step: 2
Training loss: 2.3540210723876953
Validation loss: 2.0907901615224858

Epoch: 5| Step: 3
Training loss: 2.335409641265869
Validation loss: 2.0879914581134753

Epoch: 5| Step: 4
Training loss: 1.8408368825912476
Validation loss: 2.104431813763034

Epoch: 5| Step: 5
Training loss: 2.419757127761841
Validation loss: 2.1015853010198122

Epoch: 5| Step: 6
Training loss: 2.2218053340911865
Validation loss: 2.100141916223752

Epoch: 5| Step: 7
Training loss: 1.3983627557754517
Validation loss: 2.1143254951764177

Epoch: 5| Step: 8
Training loss: 2.6268115043640137
Validation loss: 2.0985622124005388

Epoch: 5| Step: 9
Training loss: 1.7198727130889893
Validation loss: 2.084048944134866

Epoch: 5| Step: 10
Training loss: 1.8238245248794556
Validation loss: 2.095240100737541

Epoch: 251| Step: 0
Training loss: 2.321486711502075
Validation loss: 2.088745327406032

Epoch: 5| Step: 1
Training loss: 1.2781145572662354
Validation loss: 2.106207932195356

Epoch: 5| Step: 2
Training loss: 2.2923176288604736
Validation loss: 2.1178633820626045

Epoch: 5| Step: 3
Training loss: 2.3004965782165527
Validation loss: 2.1367086159285678

Epoch: 5| Step: 4
Training loss: 2.420130491256714
Validation loss: 2.1400357189998833

Epoch: 5| Step: 5
Training loss: 2.3417904376983643
Validation loss: 2.150657869154407

Epoch: 5| Step: 6
Training loss: 1.8940340280532837
Validation loss: 2.143279496059623

Epoch: 5| Step: 7
Training loss: 2.2750022411346436
Validation loss: 2.173776803478118

Epoch: 5| Step: 8
Training loss: 2.1486122608184814
Validation loss: 2.161012203462662

Epoch: 5| Step: 9
Training loss: 1.4651267528533936
Validation loss: 2.1563847423881612

Epoch: 5| Step: 10
Training loss: 2.0860347747802734
Validation loss: 2.1711976963986634

Epoch: 252| Step: 0
Training loss: 2.8263516426086426
Validation loss: 2.153012042404503

Epoch: 5| Step: 1
Training loss: 2.217085123062134
Validation loss: 2.1240648454235447

Epoch: 5| Step: 2
Training loss: 1.5310865640640259
Validation loss: 2.122771479750192

Epoch: 5| Step: 3
Training loss: 2.2601475715637207
Validation loss: 2.106802357140408

Epoch: 5| Step: 4
Training loss: 1.6518815755844116
Validation loss: 2.085496405119537

Epoch: 5| Step: 5
Training loss: 1.8413232564926147
Validation loss: 2.0825024240760395

Epoch: 5| Step: 6
Training loss: 1.6685482263565063
Validation loss: 2.0766650361399495

Epoch: 5| Step: 7
Training loss: 2.0472874641418457
Validation loss: 2.07105512772837

Epoch: 5| Step: 8
Training loss: 2.1450164318084717
Validation loss: 2.0853035783254974

Epoch: 5| Step: 9
Training loss: 2.2354607582092285
Validation loss: 2.09976617751583

Epoch: 5| Step: 10
Training loss: 2.252470016479492
Validation loss: 2.0939247172365905

Epoch: 253| Step: 0
Training loss: 2.4407408237457275
Validation loss: 2.0927424379574355

Epoch: 5| Step: 1
Training loss: 1.4513894319534302
Validation loss: 2.1041094103167133

Epoch: 5| Step: 2
Training loss: 1.5757993459701538
Validation loss: 2.102490844265107

Epoch: 5| Step: 3
Training loss: 1.881791353225708
Validation loss: 2.0776786394016717

Epoch: 5| Step: 4
Training loss: 2.8148550987243652
Validation loss: 2.091657092494349

Epoch: 5| Step: 5
Training loss: 2.1447060108184814
Validation loss: 2.0880831595390075

Epoch: 5| Step: 6
Training loss: 2.2201359272003174
Validation loss: 2.0925906165953605

Epoch: 5| Step: 7
Training loss: 2.0186848640441895
Validation loss: 2.096049260067683

Epoch: 5| Step: 8
Training loss: 2.497310161590576
Validation loss: 2.092981364137383

Epoch: 5| Step: 9
Training loss: 1.8113329410552979
Validation loss: 2.1106277396602016

Epoch: 5| Step: 10
Training loss: 1.8593164682388306
Validation loss: 2.106560173855033

Epoch: 254| Step: 0
Training loss: 1.7337100505828857
Validation loss: 2.0849494805899997

Epoch: 5| Step: 1
Training loss: 1.984623670578003
Validation loss: 2.1020593822643323

Epoch: 5| Step: 2
Training loss: 2.155430316925049
Validation loss: 2.0797881798077653

Epoch: 5| Step: 3
Training loss: 2.3905320167541504
Validation loss: 2.1030567666535736

Epoch: 5| Step: 4
Training loss: 2.648263454437256
Validation loss: 2.0941086584521877

Epoch: 5| Step: 5
Training loss: 1.576205849647522
Validation loss: 2.094358241686257

Epoch: 5| Step: 6
Training loss: 2.3078701496124268
Validation loss: 2.0898608687103435

Epoch: 5| Step: 7
Training loss: 2.1599044799804688
Validation loss: 2.0849861521874704

Epoch: 5| Step: 8
Training loss: 1.639794945716858
Validation loss: 2.097359052268408

Epoch: 5| Step: 9
Training loss: 1.8840458393096924
Validation loss: 2.1192610238188054

Epoch: 5| Step: 10
Training loss: 2.092543601989746
Validation loss: 2.1097660346697737

Epoch: 255| Step: 0
Training loss: 2.538362503051758
Validation loss: 2.1021173705336866

Epoch: 5| Step: 1
Training loss: 1.5202603340148926
Validation loss: 2.0820181985055246

Epoch: 5| Step: 2
Training loss: 2.401137590408325
Validation loss: 2.0743366505510066

Epoch: 5| Step: 3
Training loss: 1.6598650217056274
Validation loss: 2.0603733678017893

Epoch: 5| Step: 4
Training loss: 2.1410069465637207
Validation loss: 2.053419251595774

Epoch: 5| Step: 5
Training loss: 2.3294990062713623
Validation loss: 2.060792056463098

Epoch: 5| Step: 6
Training loss: 1.995600938796997
Validation loss: 2.0740649943710654

Epoch: 5| Step: 7
Training loss: 2.1832032203674316
Validation loss: 2.063503587117759

Epoch: 5| Step: 8
Training loss: 2.617703676223755
Validation loss: 2.075561859274423

Epoch: 5| Step: 9
Training loss: 1.4338551759719849
Validation loss: 2.0877495401649067

Epoch: 5| Step: 10
Training loss: 1.860923171043396
Validation loss: 2.110568014524316

Epoch: 256| Step: 0
Training loss: 1.9234269857406616
Validation loss: 2.131893886032925

Epoch: 5| Step: 1
Training loss: 2.168660879135132
Validation loss: 2.159551892229306

Epoch: 5| Step: 2
Training loss: 2.264949321746826
Validation loss: 2.143350680669149

Epoch: 5| Step: 3
Training loss: 1.9208282232284546
Validation loss: 2.1352203546031827

Epoch: 5| Step: 4
Training loss: 2.048809766769409
Validation loss: 2.12530840340481

Epoch: 5| Step: 5
Training loss: 1.7021434307098389
Validation loss: 2.112387611019996

Epoch: 5| Step: 6
Training loss: 1.6040525436401367
Validation loss: 2.1045140425364175

Epoch: 5| Step: 7
Training loss: 1.9222761392593384
Validation loss: 2.102789198198626

Epoch: 5| Step: 8
Training loss: 2.7269368171691895
Validation loss: 2.1144481410262403

Epoch: 5| Step: 9
Training loss: 2.516554832458496
Validation loss: 2.0860607598417547

Epoch: 5| Step: 10
Training loss: 1.8087321519851685
Validation loss: 2.0952206580869612

Epoch: 257| Step: 0
Training loss: 2.6755707263946533
Validation loss: 2.0830858240845385

Epoch: 5| Step: 1
Training loss: 1.6600462198257446
Validation loss: 2.09286593878141

Epoch: 5| Step: 2
Training loss: 2.582726001739502
Validation loss: 2.073761360619658

Epoch: 5| Step: 3
Training loss: 2.111011266708374
Validation loss: 2.0676324213704755

Epoch: 5| Step: 4
Training loss: 2.636678695678711
Validation loss: 2.067206857024982

Epoch: 5| Step: 5
Training loss: 2.0018646717071533
Validation loss: 2.070625687158236

Epoch: 5| Step: 6
Training loss: 1.5960479974746704
Validation loss: 2.060875459383893

Epoch: 5| Step: 7
Training loss: 1.456321358680725
Validation loss: 2.0694964906220794

Epoch: 5| Step: 8
Training loss: 2.013207197189331
Validation loss: 2.053601267517254

Epoch: 5| Step: 9
Training loss: 1.9902416467666626
Validation loss: 2.068125815801723

Epoch: 5| Step: 10
Training loss: 1.6482131481170654
Validation loss: 2.0649236094567085

Epoch: 258| Step: 0
Training loss: 1.5157296657562256
Validation loss: 2.0753355820973716

Epoch: 5| Step: 1
Training loss: 2.427659034729004
Validation loss: 2.0882663034623667

Epoch: 5| Step: 2
Training loss: 1.9760215282440186
Validation loss: 2.1010241739211546

Epoch: 5| Step: 3
Training loss: 1.8255548477172852
Validation loss: 2.121648137287427

Epoch: 5| Step: 4
Training loss: 2.1629128456115723
Validation loss: 2.1325747325856197

Epoch: 5| Step: 5
Training loss: 1.8340587615966797
Validation loss: 2.141806317913917

Epoch: 5| Step: 6
Training loss: 2.206613302230835
Validation loss: 2.142990994197066

Epoch: 5| Step: 7
Training loss: 2.1905369758605957
Validation loss: 2.138436908363014

Epoch: 5| Step: 8
Training loss: 2.6908199787139893
Validation loss: 2.138677325299991

Epoch: 5| Step: 9
Training loss: 1.947191596031189
Validation loss: 2.114814578845937

Epoch: 5| Step: 10
Training loss: 1.7844271659851074
Validation loss: 2.117320937495078

Epoch: 259| Step: 0
Training loss: 1.8959124088287354
Validation loss: 2.079897789544957

Epoch: 5| Step: 1
Training loss: 1.7603511810302734
Validation loss: 2.0629499150860693

Epoch: 5| Step: 2
Training loss: 2.220029354095459
Validation loss: 2.080669473576289

Epoch: 5| Step: 3
Training loss: 2.4275171756744385
Validation loss: 2.074443248010451

Epoch: 5| Step: 4
Training loss: 2.2717182636260986
Validation loss: 2.0954183147799585

Epoch: 5| Step: 5
Training loss: 1.7419599294662476
Validation loss: 2.100444896246797

Epoch: 5| Step: 6
Training loss: 1.3296136856079102
Validation loss: 2.1015613437980734

Epoch: 5| Step: 7
Training loss: 1.980584740638733
Validation loss: 2.0912397907626246

Epoch: 5| Step: 8
Training loss: 2.468064546585083
Validation loss: 2.1039712441864835

Epoch: 5| Step: 9
Training loss: 2.2579808235168457
Validation loss: 2.1010572705217587

Epoch: 5| Step: 10
Training loss: 2.0105769634246826
Validation loss: 2.085026192408736

Epoch: 260| Step: 0
Training loss: 2.1874823570251465
Validation loss: 2.0990642655280327

Epoch: 5| Step: 1
Training loss: 2.0484867095947266
Validation loss: 2.097587534176406

Epoch: 5| Step: 2
Training loss: 2.1420254707336426
Validation loss: 2.088250280708395

Epoch: 5| Step: 3
Training loss: 1.9731624126434326
Validation loss: 2.0847692412714802

Epoch: 5| Step: 4
Training loss: 1.9116458892822266
Validation loss: 2.0708504953692035

Epoch: 5| Step: 5
Training loss: 1.13357412815094
Validation loss: 2.081548918959915

Epoch: 5| Step: 6
Training loss: 1.7908369302749634
Validation loss: 2.085972321930752

Epoch: 5| Step: 7
Training loss: 2.4302330017089844
Validation loss: 2.088542902341453

Epoch: 5| Step: 8
Training loss: 2.338848829269409
Validation loss: 2.100074747557281

Epoch: 5| Step: 9
Training loss: 1.8822730779647827
Validation loss: 2.1051400425613567

Epoch: 5| Step: 10
Training loss: 2.492036819458008
Validation loss: 2.13179515254113

Epoch: 261| Step: 0
Training loss: 2.2671732902526855
Validation loss: 2.1379470504740232

Epoch: 5| Step: 1
Training loss: 1.657724142074585
Validation loss: 2.105834940428375

Epoch: 5| Step: 2
Training loss: 1.793421745300293
Validation loss: 2.098093118718875

Epoch: 5| Step: 3
Training loss: 2.912062883377075
Validation loss: 2.0933807139755576

Epoch: 5| Step: 4
Training loss: 1.7368113994598389
Validation loss: 2.0969060800408803

Epoch: 5| Step: 5
Training loss: 1.8782923221588135
Validation loss: 2.0960253131005073

Epoch: 5| Step: 6
Training loss: 2.2139060497283936
Validation loss: 2.0982501968260734

Epoch: 5| Step: 7
Training loss: 2.1015424728393555
Validation loss: 2.103044109959756

Epoch: 5| Step: 8
Training loss: 2.4470105171203613
Validation loss: 2.0930058853600615

Epoch: 5| Step: 9
Training loss: 1.4306085109710693
Validation loss: 2.0780831767666723

Epoch: 5| Step: 10
Training loss: 2.119203567504883
Validation loss: 2.0793980270303707

Epoch: 262| Step: 0
Training loss: 1.662072777748108
Validation loss: 2.1135748009527884

Epoch: 5| Step: 1
Training loss: 2.0759634971618652
Validation loss: 2.120163348413283

Epoch: 5| Step: 2
Training loss: 2.276845932006836
Validation loss: 2.1616030841745357

Epoch: 5| Step: 3
Training loss: 2.008653402328491
Validation loss: 2.2319301430897047

Epoch: 5| Step: 4
Training loss: 2.4972758293151855
Validation loss: 2.2373574831152476

Epoch: 5| Step: 5
Training loss: 1.8883230686187744
Validation loss: 2.2268926840956493

Epoch: 5| Step: 6
Training loss: 2.0773961544036865
Validation loss: 2.156626162990447

Epoch: 5| Step: 7
Training loss: 1.3795980215072632
Validation loss: 2.104477237629634

Epoch: 5| Step: 8
Training loss: 2.037019729614258
Validation loss: 2.1048895146257136

Epoch: 5| Step: 9
Training loss: 2.336696147918701
Validation loss: 2.0915408826643422

Epoch: 5| Step: 10
Training loss: 2.7100753784179688
Validation loss: 2.091255780189268

Epoch: 263| Step: 0
Training loss: 2.317878484725952
Validation loss: 2.0896127813605854

Epoch: 5| Step: 1
Training loss: 2.1756482124328613
Validation loss: 2.0750956176429667

Epoch: 5| Step: 2
Training loss: 2.3010566234588623
Validation loss: 2.058537931852443

Epoch: 5| Step: 3
Training loss: 1.8174279928207397
Validation loss: 2.0321854699042534

Epoch: 5| Step: 4
Training loss: 1.788183569908142
Validation loss: 2.0361070850844025

Epoch: 5| Step: 5
Training loss: 2.3241119384765625
Validation loss: 2.0387623617725987

Epoch: 5| Step: 6
Training loss: 2.5796406269073486
Validation loss: 2.0691023462562153

Epoch: 5| Step: 7
Training loss: 2.5188279151916504
Validation loss: 2.0850064792940692

Epoch: 5| Step: 8
Training loss: 1.5220847129821777
Validation loss: 2.0925985523449477

Epoch: 5| Step: 9
Training loss: 1.5544195175170898
Validation loss: 2.1260717363767725

Epoch: 5| Step: 10
Training loss: 2.3563408851623535
Validation loss: 2.1761172330507668

Epoch: 264| Step: 0
Training loss: 2.1240501403808594
Validation loss: 2.1625721595620595

Epoch: 5| Step: 1
Training loss: 2.247837543487549
Validation loss: 2.1571635277040544

Epoch: 5| Step: 2
Training loss: 2.1177845001220703
Validation loss: 2.135588022970384

Epoch: 5| Step: 3
Training loss: 1.9869575500488281
Validation loss: 2.12619581401989

Epoch: 5| Step: 4
Training loss: 1.862680196762085
Validation loss: 2.1145715264863867

Epoch: 5| Step: 5
Training loss: 1.9143970012664795
Validation loss: 2.1000572045644126

Epoch: 5| Step: 6
Training loss: 2.132190465927124
Validation loss: 2.1185280366610457

Epoch: 5| Step: 7
Training loss: 1.937902808189392
Validation loss: 2.112446274808658

Epoch: 5| Step: 8
Training loss: 2.1589436531066895
Validation loss: 2.115843606251542

Epoch: 5| Step: 9
Training loss: 2.1308395862579346
Validation loss: 2.1179639306119693

Epoch: 5| Step: 10
Training loss: 1.8781442642211914
Validation loss: 2.098135926390207

Epoch: 265| Step: 0
Training loss: 1.9169546365737915
Validation loss: 2.0790952072348645

Epoch: 5| Step: 1
Training loss: 2.214275360107422
Validation loss: 2.0850663992666427

Epoch: 5| Step: 2
Training loss: 1.9448661804199219
Validation loss: 2.0861585832411245

Epoch: 5| Step: 3
Training loss: 2.3009283542633057
Validation loss: 2.0703063472624748

Epoch: 5| Step: 4
Training loss: 2.4254279136657715
Validation loss: 2.0714687301266577

Epoch: 5| Step: 5
Training loss: 1.7814934253692627
Validation loss: 2.0731004092001144

Epoch: 5| Step: 6
Training loss: 2.5358760356903076
Validation loss: 2.072745107835339

Epoch: 5| Step: 7
Training loss: 1.3110840320587158
Validation loss: 2.0743391770188526

Epoch: 5| Step: 8
Training loss: 1.350993037223816
Validation loss: 2.060974182621125

Epoch: 5| Step: 9
Training loss: 2.104212999343872
Validation loss: 2.087197224299113

Epoch: 5| Step: 10
Training loss: 2.233008623123169
Validation loss: 2.0646765962723763

Epoch: 266| Step: 0
Training loss: 1.9582054615020752
Validation loss: 2.0767549494261384

Epoch: 5| Step: 1
Training loss: 2.16815447807312
Validation loss: 2.0871150237257763

Epoch: 5| Step: 2
Training loss: 2.72550892829895
Validation loss: 2.0984125919239496

Epoch: 5| Step: 3
Training loss: 1.8566821813583374
Validation loss: 2.087428100647465

Epoch: 5| Step: 4
Training loss: 1.9015697240829468
Validation loss: 2.072284044757966

Epoch: 5| Step: 5
Training loss: 2.3486411571502686
Validation loss: 2.075468319718556

Epoch: 5| Step: 6
Training loss: 1.8905357122421265
Validation loss: 2.0517640908559165

Epoch: 5| Step: 7
Training loss: 2.3560492992401123
Validation loss: 2.057279686773977

Epoch: 5| Step: 8
Training loss: 2.0060524940490723
Validation loss: 2.0455278555552163

Epoch: 5| Step: 9
Training loss: 1.80575692653656
Validation loss: 2.038171358005975

Epoch: 5| Step: 10
Training loss: 1.2002938985824585
Validation loss: 2.038362294115046

Epoch: 267| Step: 0
Training loss: 2.060685157775879
Validation loss: 2.0411764114133772

Epoch: 5| Step: 1
Training loss: 2.343578815460205
Validation loss: 2.0471342930229763

Epoch: 5| Step: 2
Training loss: 2.0282576084136963
Validation loss: 2.072464173839938

Epoch: 5| Step: 3
Training loss: 1.9634742736816406
Validation loss: 2.1100243753002537

Epoch: 5| Step: 4
Training loss: 2.132030963897705
Validation loss: 2.096680138700752

Epoch: 5| Step: 5
Training loss: 1.4782259464263916
Validation loss: 2.119484152845157

Epoch: 5| Step: 6
Training loss: 2.0036821365356445
Validation loss: 2.1571717134086033

Epoch: 5| Step: 7
Training loss: 1.8356330394744873
Validation loss: 2.1262890215842956

Epoch: 5| Step: 8
Training loss: 2.540393829345703
Validation loss: 2.088780085245768

Epoch: 5| Step: 9
Training loss: 2.252948760986328
Validation loss: 2.0831891772567586

Epoch: 5| Step: 10
Training loss: 2.081552267074585
Validation loss: 2.060881180147971

Epoch: 268| Step: 0
Training loss: 2.478123188018799
Validation loss: 2.0496298446450183

Epoch: 5| Step: 1
Training loss: 2.824153423309326
Validation loss: 2.0578030206823863

Epoch: 5| Step: 2
Training loss: 1.629241704940796
Validation loss: 2.058507619365569

Epoch: 5| Step: 3
Training loss: 1.6451616287231445
Validation loss: 2.0873922891514276

Epoch: 5| Step: 4
Training loss: 2.159193277359009
Validation loss: 2.0873388987715527

Epoch: 5| Step: 5
Training loss: 1.2343826293945312
Validation loss: 2.096851325804187

Epoch: 5| Step: 6
Training loss: 2.652742862701416
Validation loss: 2.078913314368135

Epoch: 5| Step: 7
Training loss: 2.0609335899353027
Validation loss: 2.0534811635171213

Epoch: 5| Step: 8
Training loss: 1.8823823928833008
Validation loss: 2.0393313156661166

Epoch: 5| Step: 9
Training loss: 1.9808229207992554
Validation loss: 2.055039728841474

Epoch: 5| Step: 10
Training loss: 1.7983222007751465
Validation loss: 2.0622322892629974

Epoch: 269| Step: 0
Training loss: 1.8458179235458374
Validation loss: 2.0680698681903142

Epoch: 5| Step: 1
Training loss: 1.9915695190429688
Validation loss: 2.091213375009516

Epoch: 5| Step: 2
Training loss: 2.0174880027770996
Validation loss: 2.1004991480099258

Epoch: 5| Step: 3
Training loss: 2.0008010864257812
Validation loss: 2.095691975726876

Epoch: 5| Step: 4
Training loss: 2.3758544921875
Validation loss: 2.0854109538498746

Epoch: 5| Step: 5
Training loss: 2.429810047149658
Validation loss: 2.0725595438352196

Epoch: 5| Step: 6
Training loss: 1.8550388813018799
Validation loss: 2.087163939270922

Epoch: 5| Step: 7
Training loss: 1.9400653839111328
Validation loss: 2.0863732599443003

Epoch: 5| Step: 8
Training loss: 2.054459810256958
Validation loss: 2.060472167948241

Epoch: 5| Step: 9
Training loss: 1.7393203973770142
Validation loss: 2.055420547403315

Epoch: 5| Step: 10
Training loss: 1.7377774715423584
Validation loss: 2.0509185880743046

Epoch: 270| Step: 0
Training loss: 1.4012216329574585
Validation loss: 2.050715059362432

Epoch: 5| Step: 1
Training loss: 1.7987518310546875
Validation loss: 2.073701097119239

Epoch: 5| Step: 2
Training loss: 2.3110406398773193
Validation loss: 2.064147412136037

Epoch: 5| Step: 3
Training loss: 1.7364652156829834
Validation loss: 2.0893391973228863

Epoch: 5| Step: 4
Training loss: 2.1216061115264893
Validation loss: 2.092302069869093

Epoch: 5| Step: 5
Training loss: 2.243544340133667
Validation loss: 2.096839794548609

Epoch: 5| Step: 6
Training loss: 1.6775338649749756
Validation loss: 2.0836718108064387

Epoch: 5| Step: 7
Training loss: 1.9365627765655518
Validation loss: 2.0798534590710878

Epoch: 5| Step: 8
Training loss: 2.3180160522460938
Validation loss: 2.0708455911246677

Epoch: 5| Step: 9
Training loss: 1.731644630432129
Validation loss: 2.079487551925003

Epoch: 5| Step: 10
Training loss: 2.627986431121826
Validation loss: 2.0767677830111597

Epoch: 271| Step: 0
Training loss: 2.2423927783966064
Validation loss: 2.082923566141436

Epoch: 5| Step: 1
Training loss: 2.6305482387542725
Validation loss: 2.1191015217893865

Epoch: 5| Step: 2
Training loss: 1.8331283330917358
Validation loss: 2.1302884778668805

Epoch: 5| Step: 3
Training loss: 2.302171230316162
Validation loss: 2.1302613084034254

Epoch: 5| Step: 4
Training loss: 2.1667697429656982
Validation loss: 2.1008834351775465

Epoch: 5| Step: 5
Training loss: 1.9691383838653564
Validation loss: 2.0890510594973

Epoch: 5| Step: 6
Training loss: 1.934769868850708
Validation loss: 2.0439974428505026

Epoch: 5| Step: 7
Training loss: 1.6255314350128174
Validation loss: 2.0301518901701896

Epoch: 5| Step: 8
Training loss: 1.4606579542160034
Validation loss: 2.0369543516507713

Epoch: 5| Step: 9
Training loss: 2.0606231689453125
Validation loss: 2.042167486683015

Epoch: 5| Step: 10
Training loss: 2.1002376079559326
Validation loss: 2.0599217209764706

Epoch: 272| Step: 0
Training loss: 1.8819236755371094
Validation loss: 2.057462748660836

Epoch: 5| Step: 1
Training loss: 2.4188222885131836
Validation loss: 2.047892884541583

Epoch: 5| Step: 2
Training loss: 1.6436293125152588
Validation loss: 2.0400654628712642

Epoch: 5| Step: 3
Training loss: 1.6653594970703125
Validation loss: 2.055532201643913

Epoch: 5| Step: 4
Training loss: 1.0236746072769165
Validation loss: 2.062973706952987

Epoch: 5| Step: 5
Training loss: 2.226149082183838
Validation loss: 2.0837348712387906

Epoch: 5| Step: 6
Training loss: 2.5873594284057617
Validation loss: 2.1169774506681707

Epoch: 5| Step: 7
Training loss: 2.3493309020996094
Validation loss: 2.1489560527186238

Epoch: 5| Step: 8
Training loss: 2.1606197357177734
Validation loss: 2.1838339041638117

Epoch: 5| Step: 9
Training loss: 2.494513511657715
Validation loss: 2.137187361717224

Epoch: 5| Step: 10
Training loss: 1.8493425846099854
Validation loss: 2.108974265795882

Epoch: 273| Step: 0
Training loss: 1.915399193763733
Validation loss: 2.096077944642754

Epoch: 5| Step: 1
Training loss: 1.5847938060760498
Validation loss: 2.0728310667058474

Epoch: 5| Step: 2
Training loss: 1.693377137184143
Validation loss: 2.0704502213385796

Epoch: 5| Step: 3
Training loss: 2.1921420097351074
Validation loss: 2.0637704018623597

Epoch: 5| Step: 4
Training loss: 1.2030068635940552
Validation loss: 2.072471639161469

Epoch: 5| Step: 5
Training loss: 2.659264087677002
Validation loss: 2.0717506331782185

Epoch: 5| Step: 6
Training loss: 2.0135130882263184
Validation loss: 2.055025792890979

Epoch: 5| Step: 7
Training loss: 2.6069507598876953
Validation loss: 2.0635380719297673

Epoch: 5| Step: 8
Training loss: 1.9046989679336548
Validation loss: 2.0622724743299585

Epoch: 5| Step: 9
Training loss: 2.073859691619873
Validation loss: 2.0546571336766726

Epoch: 5| Step: 10
Training loss: 1.850839614868164
Validation loss: 2.042570501245478

Epoch: 274| Step: 0
Training loss: 1.6128278970718384
Validation loss: 2.0551604301698747

Epoch: 5| Step: 1
Training loss: 1.9502700567245483
Validation loss: 2.0604518254597983

Epoch: 5| Step: 2
Training loss: 1.7917829751968384
Validation loss: 2.0646529364329513

Epoch: 5| Step: 3
Training loss: 2.1891486644744873
Validation loss: 2.0658812753615843

Epoch: 5| Step: 4
Training loss: 2.785020351409912
Validation loss: 2.057684080575102

Epoch: 5| Step: 5
Training loss: 1.3756860494613647
Validation loss: 2.0742609962340324

Epoch: 5| Step: 6
Training loss: 2.0003511905670166
Validation loss: 2.0593288893340738

Epoch: 5| Step: 7
Training loss: 1.678651213645935
Validation loss: 2.062903529854231

Epoch: 5| Step: 8
Training loss: 1.700411081314087
Validation loss: 2.0558670695110033

Epoch: 5| Step: 9
Training loss: 2.1863598823547363
Validation loss: 2.0678972608299664

Epoch: 5| Step: 10
Training loss: 2.617582082748413
Validation loss: 2.074398931636605

Epoch: 275| Step: 0
Training loss: 1.471937894821167
Validation loss: 2.0844080858333136

Epoch: 5| Step: 1
Training loss: 2.3581252098083496
Validation loss: 2.078581351105885

Epoch: 5| Step: 2
Training loss: 1.6954288482666016
Validation loss: 2.058373220505253

Epoch: 5| Step: 3
Training loss: 1.2928106784820557
Validation loss: 2.051423618870397

Epoch: 5| Step: 4
Training loss: 1.8750159740447998
Validation loss: 2.0513157998361895

Epoch: 5| Step: 5
Training loss: 1.8805043697357178
Validation loss: 2.041872775682839

Epoch: 5| Step: 6
Training loss: 2.4589285850524902
Validation loss: 2.051198628640944

Epoch: 5| Step: 7
Training loss: 2.174636125564575
Validation loss: 2.0598604922653525

Epoch: 5| Step: 8
Training loss: 2.7010245323181152
Validation loss: 2.063792772190545

Epoch: 5| Step: 9
Training loss: 1.649229645729065
Validation loss: 2.0815134740644887

Epoch: 5| Step: 10
Training loss: 2.497732162475586
Validation loss: 2.0932428824004305

Epoch: 276| Step: 0
Training loss: 2.1834816932678223
Validation loss: 2.0823727628236175

Epoch: 5| Step: 1
Training loss: 1.761325478553772
Validation loss: 2.078632907200885

Epoch: 5| Step: 2
Training loss: 1.8507006168365479
Validation loss: 2.0753497436482418

Epoch: 5| Step: 3
Training loss: 2.6428351402282715
Validation loss: 2.061591702122842

Epoch: 5| Step: 4
Training loss: 2.081712484359741
Validation loss: 2.060476332582453

Epoch: 5| Step: 5
Training loss: 1.9942067861557007
Validation loss: 2.0636398471811765

Epoch: 5| Step: 6
Training loss: 1.4806874990463257
Validation loss: 2.073399862935466

Epoch: 5| Step: 7
Training loss: 2.038156032562256
Validation loss: 2.0584731101989746

Epoch: 5| Step: 8
Training loss: 1.8361371755599976
Validation loss: 2.071544119106826

Epoch: 5| Step: 9
Training loss: 2.0579376220703125
Validation loss: 2.0675010283788047

Epoch: 5| Step: 10
Training loss: 1.7044576406478882
Validation loss: 2.0656419851446666

Epoch: 277| Step: 0
Training loss: 1.9084373712539673
Validation loss: 2.063872169422847

Epoch: 5| Step: 1
Training loss: 2.009497880935669
Validation loss: 2.066183584992604

Epoch: 5| Step: 2
Training loss: 2.1297459602355957
Validation loss: 2.056518141941358

Epoch: 5| Step: 3
Training loss: 1.6933395862579346
Validation loss: 2.0600925542974986

Epoch: 5| Step: 4
Training loss: 1.2683756351470947
Validation loss: 2.057041040030859

Epoch: 5| Step: 5
Training loss: 2.096888780593872
Validation loss: 2.046296742654616

Epoch: 5| Step: 6
Training loss: 2.4055237770080566
Validation loss: 2.075969280735139

Epoch: 5| Step: 7
Training loss: 2.1883511543273926
Validation loss: 2.0526369207648822

Epoch: 5| Step: 8
Training loss: 2.1697516441345215
Validation loss: 2.059203076106246

Epoch: 5| Step: 9
Training loss: 2.051851272583008
Validation loss: 2.0596121870061403

Epoch: 5| Step: 10
Training loss: 1.5469253063201904
Validation loss: 2.077105365773683

Epoch: 278| Step: 0
Training loss: 1.857918381690979
Validation loss: 2.06670553709871

Epoch: 5| Step: 1
Training loss: 2.324294328689575
Validation loss: 2.0729643119278776

Epoch: 5| Step: 2
Training loss: 2.72253155708313
Validation loss: 2.0665736864971858

Epoch: 5| Step: 3
Training loss: 2.1608853340148926
Validation loss: 2.065068542316396

Epoch: 5| Step: 4
Training loss: 1.4108142852783203
Validation loss: 2.0485962513954408

Epoch: 5| Step: 5
Training loss: 1.9929670095443726
Validation loss: 2.037395520876813

Epoch: 5| Step: 6
Training loss: 1.5582035779953003
Validation loss: 2.0458747263877624

Epoch: 5| Step: 7
Training loss: 1.9378106594085693
Validation loss: 2.047784182333177

Epoch: 5| Step: 8
Training loss: 2.3305211067199707
Validation loss: 2.031139204579015

Epoch: 5| Step: 9
Training loss: 2.1268038749694824
Validation loss: 2.0453210594833537

Epoch: 5| Step: 10
Training loss: 0.9403672814369202
Validation loss: 2.0509999670008177

Epoch: 279| Step: 0
Training loss: 2.2826907634735107
Validation loss: 2.0537724661570724

Epoch: 5| Step: 1
Training loss: 1.5049870014190674
Validation loss: 2.0639403712364937

Epoch: 5| Step: 2
Training loss: 2.299703598022461
Validation loss: 2.0946103552336335

Epoch: 5| Step: 3
Training loss: 2.1560757160186768
Validation loss: 2.087625644540274

Epoch: 5| Step: 4
Training loss: 1.5237380266189575
Validation loss: 2.0831022108754804

Epoch: 5| Step: 5
Training loss: 2.1711933612823486
Validation loss: 2.0828717011277393

Epoch: 5| Step: 6
Training loss: 1.4775402545928955
Validation loss: 2.079289047948776

Epoch: 5| Step: 7
Training loss: 2.208966016769409
Validation loss: 2.079170198850734

Epoch: 5| Step: 8
Training loss: 2.0020689964294434
Validation loss: 2.056069335629863

Epoch: 5| Step: 9
Training loss: 1.9929271936416626
Validation loss: 2.0564007823185255

Epoch: 5| Step: 10
Training loss: 1.6297564506530762
Validation loss: 2.0634662989647157

Epoch: 280| Step: 0
Training loss: 2.9119715690612793
Validation loss: 2.052662132888712

Epoch: 5| Step: 1
Training loss: 1.622591257095337
Validation loss: 2.048915788691531

Epoch: 5| Step: 2
Training loss: 1.8408892154693604
Validation loss: 2.0520269729757823

Epoch: 5| Step: 3
Training loss: 1.5092569589614868
Validation loss: 2.0564342814107097

Epoch: 5| Step: 4
Training loss: 1.4034181833267212
Validation loss: 2.0365017408965738

Epoch: 5| Step: 5
Training loss: 1.995038628578186
Validation loss: 2.0632017645784604

Epoch: 5| Step: 6
Training loss: 2.1594691276550293
Validation loss: 2.079679512208508

Epoch: 5| Step: 7
Training loss: 1.4669110774993896
Validation loss: 2.0733706694777294

Epoch: 5| Step: 8
Training loss: 1.8754615783691406
Validation loss: 2.0838833393589145

Epoch: 5| Step: 9
Training loss: 2.210442304611206
Validation loss: 2.0637641773428967

Epoch: 5| Step: 10
Training loss: 2.4420788288116455
Validation loss: 2.0737991461189846

Epoch: 281| Step: 0
Training loss: 2.0904910564422607
Validation loss: 2.0520478474196566

Epoch: 5| Step: 1
Training loss: 2.0027737617492676
Validation loss: 2.0569763388685

Epoch: 5| Step: 2
Training loss: 1.6737905740737915
Validation loss: 2.0480151048270603

Epoch: 5| Step: 3
Training loss: 1.7125797271728516
Validation loss: 2.0450530590549594

Epoch: 5| Step: 4
Training loss: 2.1140453815460205
Validation loss: 2.0671602731109946

Epoch: 5| Step: 5
Training loss: 2.1473240852355957
Validation loss: 2.0687051037306428

Epoch: 5| Step: 6
Training loss: 1.8520772457122803
Validation loss: 2.057999272500315

Epoch: 5| Step: 7
Training loss: 1.6711530685424805
Validation loss: 2.043078386655418

Epoch: 5| Step: 8
Training loss: 1.7561140060424805
Validation loss: 2.063582426758223

Epoch: 5| Step: 9
Training loss: 1.9910805225372314
Validation loss: 2.054393276091545

Epoch: 5| Step: 10
Training loss: 2.265223979949951
Validation loss: 2.0501796942885204

Epoch: 282| Step: 0
Training loss: 2.054823637008667
Validation loss: 2.0456164190846104

Epoch: 5| Step: 1
Training loss: 1.7995598316192627
Validation loss: 2.073166875429051

Epoch: 5| Step: 2
Training loss: 1.8143022060394287
Validation loss: 2.0315203564141386

Epoch: 5| Step: 3
Training loss: 1.3939998149871826
Validation loss: 2.062536488297165

Epoch: 5| Step: 4
Training loss: 1.9436988830566406
Validation loss: 2.0690256318738385

Epoch: 5| Step: 5
Training loss: 2.373016834259033
Validation loss: 2.045644671686234

Epoch: 5| Step: 6
Training loss: 1.920875906944275
Validation loss: 2.0401423515812045

Epoch: 5| Step: 7
Training loss: 1.4653713703155518
Validation loss: 2.032006125296316

Epoch: 5| Step: 8
Training loss: 2.9893038272857666
Validation loss: 2.047871256387362

Epoch: 5| Step: 9
Training loss: 1.5717204809188843
Validation loss: 2.0495108891558904

Epoch: 5| Step: 10
Training loss: 1.8324899673461914
Validation loss: 2.0643216820173365

Epoch: 283| Step: 0
Training loss: 2.433445692062378
Validation loss: 2.055329780424795

Epoch: 5| Step: 1
Training loss: 1.833957314491272
Validation loss: 2.049888333966655

Epoch: 5| Step: 2
Training loss: 1.8190873861312866
Validation loss: 2.036795006003431

Epoch: 5| Step: 3
Training loss: 1.8184623718261719
Validation loss: 2.0355286021386423

Epoch: 5| Step: 4
Training loss: 2.4421279430389404
Validation loss: 2.0382480928974767

Epoch: 5| Step: 5
Training loss: 1.387316107749939
Validation loss: 2.035787292706069

Epoch: 5| Step: 6
Training loss: 1.7778284549713135
Validation loss: 2.041983090421205

Epoch: 5| Step: 7
Training loss: 1.602905511856079
Validation loss: 2.0415101640967914

Epoch: 5| Step: 8
Training loss: 2.129859209060669
Validation loss: 2.0557351958367134

Epoch: 5| Step: 9
Training loss: 1.8054368495941162
Validation loss: 2.0493197159100602

Epoch: 5| Step: 10
Training loss: 1.9854031801223755
Validation loss: 2.0748439809327484

Epoch: 284| Step: 0
Training loss: 2.0344650745391846
Validation loss: 2.0751451548709663

Epoch: 5| Step: 1
Training loss: 1.4285480976104736
Validation loss: 2.07868525033356

Epoch: 5| Step: 2
Training loss: 2.683084487915039
Validation loss: 2.081177116722189

Epoch: 5| Step: 3
Training loss: 1.7224140167236328
Validation loss: 2.081921869708646

Epoch: 5| Step: 4
Training loss: 2.2239956855773926
Validation loss: 2.0614343638061197

Epoch: 5| Step: 5
Training loss: 1.9478342533111572
Validation loss: 2.0659442922120452

Epoch: 5| Step: 6
Training loss: 1.7277017831802368
Validation loss: 2.040347030085902

Epoch: 5| Step: 7
Training loss: 2.50869083404541
Validation loss: 2.02461992027939

Epoch: 5| Step: 8
Training loss: 1.654732346534729
Validation loss: 2.0153650468395603

Epoch: 5| Step: 9
Training loss: 1.8642297983169556
Validation loss: 2.0406889428374586

Epoch: 5| Step: 10
Training loss: 1.307102918624878
Validation loss: 2.0186694822003766

Epoch: 285| Step: 0
Training loss: 2.590548276901245
Validation loss: 2.033166993048883

Epoch: 5| Step: 1
Training loss: 1.9803606271743774
Validation loss: 2.040942733005811

Epoch: 5| Step: 2
Training loss: 1.4248199462890625
Validation loss: 2.0327837159556728

Epoch: 5| Step: 3
Training loss: 2.198387861251831
Validation loss: 2.0609239121919036

Epoch: 5| Step: 4
Training loss: 1.743384599685669
Validation loss: 2.0321632354490218

Epoch: 5| Step: 5
Training loss: 1.7796579599380493
Validation loss: 2.0380181074142456

Epoch: 5| Step: 6
Training loss: 2.306993007659912
Validation loss: 2.0552641345608618

Epoch: 5| Step: 7
Training loss: 2.5102908611297607
Validation loss: 2.0585106188251125

Epoch: 5| Step: 8
Training loss: 1.4233545064926147
Validation loss: 2.0687849483182355

Epoch: 5| Step: 9
Training loss: 1.0735596418380737
Validation loss: 2.0487238335353073

Epoch: 5| Step: 10
Training loss: 2.154348373413086
Validation loss: 2.068557903330813

Epoch: 286| Step: 0
Training loss: 2.5734972953796387
Validation loss: 2.0388636640323106

Epoch: 5| Step: 1
Training loss: 1.105945348739624
Validation loss: 2.023379556594356

Epoch: 5| Step: 2
Training loss: 1.639776587486267
Validation loss: 2.0232948744168846

Epoch: 5| Step: 3
Training loss: 1.7697864770889282
Validation loss: 2.035799026489258

Epoch: 5| Step: 4
Training loss: 2.1645843982696533
Validation loss: 2.035803864079137

Epoch: 5| Step: 5
Training loss: 1.8605930805206299
Validation loss: 2.0286377412016674

Epoch: 5| Step: 6
Training loss: 2.112407684326172
Validation loss: 2.043893870487008

Epoch: 5| Step: 7
Training loss: 1.919594168663025
Validation loss: 2.058097247154482

Epoch: 5| Step: 8
Training loss: 2.008314847946167
Validation loss: 2.053696370893909

Epoch: 5| Step: 9
Training loss: 1.7597061395645142
Validation loss: 2.030722439930003

Epoch: 5| Step: 10
Training loss: 2.2542741298675537
Validation loss: 2.0415677626927695

Epoch: 287| Step: 0
Training loss: 2.2086594104766846
Validation loss: 2.023798173473727

Epoch: 5| Step: 1
Training loss: 2.719156265258789
Validation loss: 2.0257297408196235

Epoch: 5| Step: 2
Training loss: 1.5920394659042358
Validation loss: 2.0267513644310737

Epoch: 5| Step: 3
Training loss: 2.189770221710205
Validation loss: 2.042199796245944

Epoch: 5| Step: 4
Training loss: 1.417731523513794
Validation loss: 2.0684685707092285

Epoch: 5| Step: 5
Training loss: 1.761936902999878
Validation loss: 2.0863405965989634

Epoch: 5| Step: 6
Training loss: 2.154851198196411
Validation loss: 2.1075797414266937

Epoch: 5| Step: 7
Training loss: 1.3681217432022095
Validation loss: 2.0759607476572834

Epoch: 5| Step: 8
Training loss: 2.6338300704956055
Validation loss: 2.0796557434143557

Epoch: 5| Step: 9
Training loss: 1.2118545770645142
Validation loss: 2.054623039819861

Epoch: 5| Step: 10
Training loss: 1.9651392698287964
Validation loss: 2.0579068071098736

Epoch: 288| Step: 0
Training loss: 2.386862277984619
Validation loss: 2.0564322522891465

Epoch: 5| Step: 1
Training loss: 1.7618274688720703
Validation loss: 2.027055519883351

Epoch: 5| Step: 2
Training loss: 2.1635241508483887
Validation loss: 2.005131385659659

Epoch: 5| Step: 3
Training loss: 1.902098298072815
Validation loss: 2.0110220191299275

Epoch: 5| Step: 4
Training loss: 2.3047537803649902
Validation loss: 1.9988254167700326

Epoch: 5| Step: 5
Training loss: 1.4156049489974976
Validation loss: 2.031282631299829

Epoch: 5| Step: 6
Training loss: 1.5033612251281738
Validation loss: 2.0408822541595786

Epoch: 5| Step: 7
Training loss: 2.302645683288574
Validation loss: 2.0489835585317304

Epoch: 5| Step: 8
Training loss: 1.9845119714736938
Validation loss: 2.0731714566548667

Epoch: 5| Step: 9
Training loss: 1.5720751285552979
Validation loss: 2.0940338411638812

Epoch: 5| Step: 10
Training loss: 1.6993985176086426
Validation loss: 2.069112972546649

Epoch: 289| Step: 0
Training loss: 2.1957945823669434
Validation loss: 2.0629832808689406

Epoch: 5| Step: 1
Training loss: 2.0504345893859863
Validation loss: 2.053350612681399

Epoch: 5| Step: 2
Training loss: 2.266392707824707
Validation loss: 2.045275044697587

Epoch: 5| Step: 3
Training loss: 1.716321587562561
Validation loss: 2.0336231159907516

Epoch: 5| Step: 4
Training loss: 1.9063104391098022
Validation loss: 2.036568631408035

Epoch: 5| Step: 5
Training loss: 1.9888184070587158
Validation loss: 2.041022462229575

Epoch: 5| Step: 6
Training loss: 1.9480273723602295
Validation loss: 2.0510977391273744

Epoch: 5| Step: 7
Training loss: 1.6339906454086304
Validation loss: 2.0381499798067155

Epoch: 5| Step: 8
Training loss: 1.561104416847229
Validation loss: 2.0333526647219093

Epoch: 5| Step: 9
Training loss: 1.99993896484375
Validation loss: 2.073222147521152

Epoch: 5| Step: 10
Training loss: 1.7880663871765137
Validation loss: 2.087351063246368

Epoch: 290| Step: 0
Training loss: 2.4738399982452393
Validation loss: 2.1036825513326995

Epoch: 5| Step: 1
Training loss: 1.3162727355957031
Validation loss: 2.062171846307734

Epoch: 5| Step: 2
Training loss: 1.419433355331421
Validation loss: 2.039183565365371

Epoch: 5| Step: 3
Training loss: 2.1222214698791504
Validation loss: 2.025541264523742

Epoch: 5| Step: 4
Training loss: 1.9375689029693604
Validation loss: 2.0203239405027

Epoch: 5| Step: 5
Training loss: 2.008331298828125
Validation loss: 2.0307313934449227

Epoch: 5| Step: 6
Training loss: 1.9703655242919922
Validation loss: 2.0191513825488347

Epoch: 5| Step: 7
Training loss: 2.0167593955993652
Validation loss: 2.0178151720313617

Epoch: 5| Step: 8
Training loss: 2.388152599334717
Validation loss: 2.0255780886578303

Epoch: 5| Step: 9
Training loss: 1.916711449623108
Validation loss: 2.0195125584961264

Epoch: 5| Step: 10
Training loss: 1.3423280715942383
Validation loss: 2.0140840520140944

Epoch: 291| Step: 0
Training loss: 1.9261757135391235
Validation loss: 2.034930121514105

Epoch: 5| Step: 1
Training loss: 1.5796563625335693
Validation loss: 2.0328100535177414

Epoch: 5| Step: 2
Training loss: 1.2250779867172241
Validation loss: 2.0380846402978383

Epoch: 5| Step: 3
Training loss: 2.6018288135528564
Validation loss: 2.0466564932177143

Epoch: 5| Step: 4
Training loss: 2.2414519786834717
Validation loss: 2.064320232278557

Epoch: 5| Step: 5
Training loss: 2.0019428730010986
Validation loss: 2.0513363653613674

Epoch: 5| Step: 6
Training loss: 2.0284953117370605
Validation loss: 2.0894353902468117

Epoch: 5| Step: 7
Training loss: 1.8078209161758423
Validation loss: 2.0885606222255255

Epoch: 5| Step: 8
Training loss: 1.9502058029174805
Validation loss: 2.0960106824034

Epoch: 5| Step: 9
Training loss: 1.6192963123321533
Validation loss: 2.0626092726184475

Epoch: 5| Step: 10
Training loss: 1.816556453704834
Validation loss: 2.0676830571184874

Epoch: 292| Step: 0
Training loss: 1.5617961883544922
Validation loss: 2.064683371974576

Epoch: 5| Step: 1
Training loss: 1.6249288320541382
Validation loss: 2.0572743749105804

Epoch: 5| Step: 2
Training loss: 2.1312146186828613
Validation loss: 2.0489515053328646

Epoch: 5| Step: 3
Training loss: 2.180246591567993
Validation loss: 2.0473616943564465

Epoch: 5| Step: 4
Training loss: 1.7419145107269287
Validation loss: 2.0318625665480092

Epoch: 5| Step: 5
Training loss: 1.761315941810608
Validation loss: 2.056348495585944

Epoch: 5| Step: 6
Training loss: 1.8331571817398071
Validation loss: 2.0419423477624052

Epoch: 5| Step: 7
Training loss: 2.1559243202209473
Validation loss: 2.0360741666568223

Epoch: 5| Step: 8
Training loss: 1.7098318338394165
Validation loss: 2.0675799462103073

Epoch: 5| Step: 9
Training loss: 2.208468198776245
Validation loss: 2.071546223855788

Epoch: 5| Step: 10
Training loss: 1.73001229763031
Validation loss: 2.0379971329883864

Epoch: 293| Step: 0
Training loss: 2.1568081378936768
Validation loss: 2.025369196809748

Epoch: 5| Step: 1
Training loss: 1.9148906469345093
Validation loss: 2.0445717303983626

Epoch: 5| Step: 2
Training loss: 1.7606580257415771
Validation loss: 2.046308678965415

Epoch: 5| Step: 3
Training loss: 1.8049428462982178
Validation loss: 2.0339877092710106

Epoch: 5| Step: 4
Training loss: 1.5396372079849243
Validation loss: 2.0482917421607563

Epoch: 5| Step: 5
Training loss: 1.4662338495254517
Validation loss: 2.0645001472965365

Epoch: 5| Step: 6
Training loss: 2.2463793754577637
Validation loss: 2.051117738087972

Epoch: 5| Step: 7
Training loss: 1.3889729976654053
Validation loss: 2.0566004553148822

Epoch: 5| Step: 8
Training loss: 2.00822377204895
Validation loss: 2.0505555675875757

Epoch: 5| Step: 9
Training loss: 2.020937442779541
Validation loss: 2.0442631885569584

Epoch: 5| Step: 10
Training loss: 2.195190191268921
Validation loss: 2.0565059390119327

Epoch: 294| Step: 0
Training loss: 1.800119400024414
Validation loss: 2.0633118370527863

Epoch: 5| Step: 1
Training loss: 1.6137117147445679
Validation loss: 2.075217044481667

Epoch: 5| Step: 2
Training loss: 2.867971897125244
Validation loss: 2.0773481015236146

Epoch: 5| Step: 3
Training loss: 1.5791157484054565
Validation loss: 2.0754039390112764

Epoch: 5| Step: 4
Training loss: 1.6615005731582642
Validation loss: 2.065792099122078

Epoch: 5| Step: 5
Training loss: 2.1421608924865723
Validation loss: 2.0865385429833525

Epoch: 5| Step: 6
Training loss: 1.860565423965454
Validation loss: 2.0811208960830525

Epoch: 5| Step: 7
Training loss: 2.1012542247772217
Validation loss: 2.0591552462629092

Epoch: 5| Step: 8
Training loss: 2.0041041374206543
Validation loss: 2.052865637245999

Epoch: 5| Step: 9
Training loss: 0.6864975094795227
Validation loss: 2.03734750388771

Epoch: 5| Step: 10
Training loss: 2.2169573307037354
Validation loss: 2.0296464094551663

Epoch: 295| Step: 0
Training loss: 2.3522660732269287
Validation loss: 2.017519481720463

Epoch: 5| Step: 1
Training loss: 2.130523204803467
Validation loss: 2.024918915123068

Epoch: 5| Step: 2
Training loss: 1.338759183883667
Validation loss: 2.013702068277585

Epoch: 5| Step: 3
Training loss: 1.4036966562271118
Validation loss: 2.029588555776945

Epoch: 5| Step: 4
Training loss: 2.4642128944396973
Validation loss: 2.0551348168362855

Epoch: 5| Step: 5
Training loss: 2.0603973865509033
Validation loss: 2.069636083418323

Epoch: 5| Step: 6
Training loss: 1.9512447118759155
Validation loss: 2.0726847879348265

Epoch: 5| Step: 7
Training loss: 2.07920503616333
Validation loss: 2.0439151435770015

Epoch: 5| Step: 8
Training loss: 1.816301941871643
Validation loss: 2.03057461912914

Epoch: 5| Step: 9
Training loss: 1.4178109169006348
Validation loss: 2.0276638487333893

Epoch: 5| Step: 10
Training loss: 1.7394611835479736
Validation loss: 2.017696101178405

Epoch: 296| Step: 0
Training loss: 2.678521156311035
Validation loss: 2.0294960993592457

Epoch: 5| Step: 1
Training loss: 1.427290916442871
Validation loss: 2.027395784213979

Epoch: 5| Step: 2
Training loss: 2.4935059547424316
Validation loss: 2.0284132931822088

Epoch: 5| Step: 3
Training loss: 1.9268414974212646
Validation loss: 2.042904128310501

Epoch: 5| Step: 4
Training loss: 1.715966820716858
Validation loss: 2.0371481526282524

Epoch: 5| Step: 5
Training loss: 1.893347978591919
Validation loss: 2.0372047167952343

Epoch: 5| Step: 6
Training loss: 1.6662347316741943
Validation loss: 2.0358659298189226

Epoch: 5| Step: 7
Training loss: 1.3895320892333984
Validation loss: 2.0241935586416595

Epoch: 5| Step: 8
Training loss: 1.5885480642318726
Validation loss: 2.038997252782186

Epoch: 5| Step: 9
Training loss: 1.6495163440704346
Validation loss: 2.0327765710892214

Epoch: 5| Step: 10
Training loss: 1.9153577089309692
Validation loss: 2.0448146776486467

Epoch: 297| Step: 0
Training loss: 1.4518846273422241
Validation loss: 2.044539923308998

Epoch: 5| Step: 1
Training loss: 1.5440517663955688
Validation loss: 2.014164742603097

Epoch: 5| Step: 2
Training loss: 1.4969600439071655
Validation loss: 2.0048397920464955

Epoch: 5| Step: 3
Training loss: 2.5821681022644043
Validation loss: 2.009454160608271

Epoch: 5| Step: 4
Training loss: 2.0101048946380615
Validation loss: 2.0178059941978863

Epoch: 5| Step: 5
Training loss: 1.8206331729888916
Validation loss: 2.031080779208932

Epoch: 5| Step: 6
Training loss: 2.0408718585968018
Validation loss: 2.032164225014307

Epoch: 5| Step: 7
Training loss: 1.9589016437530518
Validation loss: 2.06720144261596

Epoch: 5| Step: 8
Training loss: 2.182243824005127
Validation loss: 2.0499490832769744

Epoch: 5| Step: 9
Training loss: 1.6500873565673828
Validation loss: 2.051885365157999

Epoch: 5| Step: 10
Training loss: 1.5926183462142944
Validation loss: 2.0382527356506674

Epoch: 298| Step: 0
Training loss: 2.635127067565918
Validation loss: 2.04105854675334

Epoch: 5| Step: 1
Training loss: 1.5146392583847046
Validation loss: 2.0213012708130704

Epoch: 5| Step: 2
Training loss: 2.023163080215454
Validation loss: 2.021583103364514

Epoch: 5| Step: 3
Training loss: 1.5498464107513428
Validation loss: 2.024488003023209

Epoch: 5| Step: 4
Training loss: 1.5750762224197388
Validation loss: 2.01196305213436

Epoch: 5| Step: 5
Training loss: 1.7946832180023193
Validation loss: 2.0067986839561054

Epoch: 5| Step: 6
Training loss: 1.7902942895889282
Validation loss: 2.0285682678222656

Epoch: 5| Step: 7
Training loss: 2.0311217308044434
Validation loss: 2.0580576030156945

Epoch: 5| Step: 8
Training loss: 1.1643650531768799
Validation loss: 2.0997979653778898

Epoch: 5| Step: 9
Training loss: 2.2315783500671387
Validation loss: 2.06172550237307

Epoch: 5| Step: 10
Training loss: 2.2203824520111084
Validation loss: 2.078388649930236

Epoch: 299| Step: 0
Training loss: 2.268989086151123
Validation loss: 2.091418908488366

Epoch: 5| Step: 1
Training loss: 1.9043819904327393
Validation loss: 2.05367971235706

Epoch: 5| Step: 2
Training loss: 1.7905429601669312
Validation loss: 2.0343577246512137

Epoch: 5| Step: 3
Training loss: 1.6387571096420288
Validation loss: 2.0453676844155915

Epoch: 5| Step: 4
Training loss: 1.6798465251922607
Validation loss: 2.0286419135268017

Epoch: 5| Step: 5
Training loss: 2.0508580207824707
Validation loss: 2.0542047792865383

Epoch: 5| Step: 6
Training loss: 1.7152236700057983
Validation loss: 2.0573177299191876

Epoch: 5| Step: 7
Training loss: 2.3922207355499268
Validation loss: 2.054707655342676

Epoch: 5| Step: 8
Training loss: 2.036816358566284
Validation loss: 2.060943156160334

Epoch: 5| Step: 9
Training loss: 1.4420064687728882
Validation loss: 2.043004689678069

Epoch: 5| Step: 10
Training loss: 1.5425455570220947
Validation loss: 2.044511310515865

Epoch: 300| Step: 0
Training loss: 1.844356894493103
Validation loss: 2.021172352375523

Epoch: 5| Step: 1
Training loss: 1.9513174295425415
Validation loss: 2.000481149201752

Epoch: 5| Step: 2
Training loss: 1.318493127822876
Validation loss: 2.005271345056513

Epoch: 5| Step: 3
Training loss: 1.6052587032318115
Validation loss: 2.017023504421275

Epoch: 5| Step: 4
Training loss: 2.194014310836792
Validation loss: 1.997016627301452

Epoch: 5| Step: 5
Training loss: 1.8282222747802734
Validation loss: 2.028006716441083

Epoch: 5| Step: 6
Training loss: 1.4071661233901978
Validation loss: 2.0471070607503257

Epoch: 5| Step: 7
Training loss: 2.087320327758789
Validation loss: 2.0398266905097553

Epoch: 5| Step: 8
Training loss: 1.240543246269226
Validation loss: 2.0663573075366277

Epoch: 5| Step: 9
Training loss: 2.6787009239196777
Validation loss: 2.088522664962276

Epoch: 5| Step: 10
Training loss: 2.2046444416046143
Validation loss: 2.064745280050462

Epoch: 301| Step: 0
Training loss: 1.5933802127838135
Validation loss: 2.0261063909017913

Epoch: 5| Step: 1
Training loss: 1.6779648065567017
Validation loss: 1.999930408693129

Epoch: 5| Step: 2
Training loss: 1.8948217630386353
Validation loss: 2.012275686828039

Epoch: 5| Step: 3
Training loss: 1.6967880725860596
Validation loss: 2.032431620423512

Epoch: 5| Step: 4
Training loss: 2.0875301361083984
Validation loss: 2.017533245907035

Epoch: 5| Step: 5
Training loss: 2.4728922843933105
Validation loss: 2.017497547211186

Epoch: 5| Step: 6
Training loss: 2.246683359146118
Validation loss: 1.9951985215628019

Epoch: 5| Step: 7
Training loss: 1.3304804563522339
Validation loss: 2.0188615860477572

Epoch: 5| Step: 8
Training loss: 1.9937076568603516
Validation loss: 2.039298648475319

Epoch: 5| Step: 9
Training loss: 1.8250080347061157
Validation loss: 2.0707542216905983

Epoch: 5| Step: 10
Training loss: 1.9703763723373413
Validation loss: 2.0842542315042145

Epoch: 302| Step: 0
Training loss: 2.4615767002105713
Validation loss: 2.0549457214211904

Epoch: 5| Step: 1
Training loss: 2.46933913230896
Validation loss: 2.0197743523505425

Epoch: 5| Step: 2
Training loss: 1.2247753143310547
Validation loss: 2.0094794316958358

Epoch: 5| Step: 3
Training loss: 1.927098035812378
Validation loss: 2.01104704026253

Epoch: 5| Step: 4
Training loss: 1.2135694026947021
Validation loss: 2.0036739341674314

Epoch: 5| Step: 5
Training loss: 1.7934648990631104
Validation loss: 2.0158463011505785

Epoch: 5| Step: 6
Training loss: 1.6492887735366821
Validation loss: 2.0027095553695515

Epoch: 5| Step: 7
Training loss: 1.9008041620254517
Validation loss: 2.0121440528541483

Epoch: 5| Step: 8
Training loss: 2.2859654426574707
Validation loss: 2.015065659758865

Epoch: 5| Step: 9
Training loss: 1.9821817874908447
Validation loss: 2.0297974912069177

Epoch: 5| Step: 10
Training loss: 1.1587514877319336
Validation loss: 2.02213970563745

Epoch: 303| Step: 0
Training loss: 1.9681724309921265
Validation loss: 2.0393895923450427

Epoch: 5| Step: 1
Training loss: 1.799583077430725
Validation loss: 2.0555088186776764

Epoch: 5| Step: 2
Training loss: 1.6307672262191772
Validation loss: 2.040213518245246

Epoch: 5| Step: 3
Training loss: 1.2744362354278564
Validation loss: 2.0429488202576995

Epoch: 5| Step: 4
Training loss: 1.7737382650375366
Validation loss: 2.0539822962976273

Epoch: 5| Step: 5
Training loss: 1.3808330297470093
Validation loss: 2.042577297456803

Epoch: 5| Step: 6
Training loss: 2.0231144428253174
Validation loss: 2.047047140777752

Epoch: 5| Step: 7
Training loss: 1.4632939100265503
Validation loss: 2.0568308432896933

Epoch: 5| Step: 8
Training loss: 2.3314297199249268
Validation loss: 2.0244018980251846

Epoch: 5| Step: 9
Training loss: 2.386582851409912
Validation loss: 2.0050015731524398

Epoch: 5| Step: 10
Training loss: 1.876412034034729
Validation loss: 1.9926623529003513

Epoch: 304| Step: 0
Training loss: 1.9741668701171875
Validation loss: 1.9915346586576073

Epoch: 5| Step: 1
Training loss: 1.6857311725616455
Validation loss: 2.0001999614059285

Epoch: 5| Step: 2
Training loss: 2.0019359588623047
Validation loss: 1.9765705165042673

Epoch: 5| Step: 3
Training loss: 1.455664038658142
Validation loss: 2.003202340936148

Epoch: 5| Step: 4
Training loss: 1.7926712036132812
Validation loss: 1.9893684079570155

Epoch: 5| Step: 5
Training loss: 2.3066213130950928
Validation loss: 2.010976088944302

Epoch: 5| Step: 6
Training loss: 1.6814435720443726
Validation loss: 2.005612991189444

Epoch: 5| Step: 7
Training loss: 1.6654655933380127
Validation loss: 2.0154282239175614

Epoch: 5| Step: 8
Training loss: 1.8441543579101562
Validation loss: 2.018700326001772

Epoch: 5| Step: 9
Training loss: 1.764174222946167
Validation loss: 2.030763887589978

Epoch: 5| Step: 10
Training loss: 1.6991801261901855
Validation loss: 2.0390697243393108

Epoch: 305| Step: 0
Training loss: 1.7437829971313477
Validation loss: 2.066395139181486

Epoch: 5| Step: 1
Training loss: 1.8625972270965576
Validation loss: 2.069418053473196

Epoch: 5| Step: 2
Training loss: 2.2028534412384033
Validation loss: 2.0955995769910913

Epoch: 5| Step: 3
Training loss: 1.9715518951416016
Validation loss: 2.071071186373311

Epoch: 5| Step: 4
Training loss: 1.8839054107666016
Validation loss: 2.0577654274561072

Epoch: 5| Step: 5
Training loss: 1.5389254093170166
Validation loss: 2.0565447217674664

Epoch: 5| Step: 6
Training loss: 1.8257068395614624
Validation loss: 2.0201832709773893

Epoch: 5| Step: 7
Training loss: 1.0045876502990723
Validation loss: 2.027714522936011

Epoch: 5| Step: 8
Training loss: 1.816963791847229
Validation loss: 2.0088963893152054

Epoch: 5| Step: 9
Training loss: 2.0514776706695557
Validation loss: 2.0290754405401086

Epoch: 5| Step: 10
Training loss: 2.0812790393829346
Validation loss: 2.0330433307155484

Epoch: 306| Step: 0
Training loss: 1.7436225414276123
Validation loss: 2.0403371446876117

Epoch: 5| Step: 1
Training loss: 1.9492595195770264
Validation loss: 2.0482115309725524

Epoch: 5| Step: 2
Training loss: 2.1193747520446777
Validation loss: 2.0249720619570826

Epoch: 5| Step: 3
Training loss: 1.2550256252288818
Validation loss: 2.032504521390443

Epoch: 5| Step: 4
Training loss: 1.7451454401016235
Validation loss: 2.0370728174845376

Epoch: 5| Step: 5
Training loss: 1.5019114017486572
Validation loss: 2.043584539044288

Epoch: 5| Step: 6
Training loss: 1.58719801902771
Validation loss: 1.9995037330094205

Epoch: 5| Step: 7
Training loss: 2.6094460487365723
Validation loss: 2.011284678213058

Epoch: 5| Step: 8
Training loss: 1.6584373712539673
Validation loss: 2.0009763266450618

Epoch: 5| Step: 9
Training loss: 1.8021771907806396
Validation loss: 2.0134836845500494

Epoch: 5| Step: 10
Training loss: 1.917670488357544
Validation loss: 2.0123425529849146

Epoch: 307| Step: 0
Training loss: 1.6918671131134033
Validation loss: 2.0158155489993352

Epoch: 5| Step: 1
Training loss: 1.6631816625595093
Validation loss: 2.0453010810318815

Epoch: 5| Step: 2
Training loss: 1.9837754964828491
Validation loss: 2.0805564465061313

Epoch: 5| Step: 3
Training loss: 1.5509567260742188
Validation loss: 2.0939606569146596

Epoch: 5| Step: 4
Training loss: 1.947210669517517
Validation loss: 2.101976412598805

Epoch: 5| Step: 5
Training loss: 1.4585630893707275
Validation loss: 2.10038249979737

Epoch: 5| Step: 6
Training loss: 1.8102481365203857
Validation loss: 2.07620039550207

Epoch: 5| Step: 7
Training loss: 1.5362119674682617
Validation loss: 2.0456475583455895

Epoch: 5| Step: 8
Training loss: 2.295279026031494
Validation loss: 2.030914091294812

Epoch: 5| Step: 9
Training loss: 2.56842303276062
Validation loss: 2.03317085389168

Epoch: 5| Step: 10
Training loss: 1.3964850902557373
Validation loss: 2.0126855604110228

Epoch: 308| Step: 0
Training loss: 2.0068700313568115
Validation loss: 1.995914222091757

Epoch: 5| Step: 1
Training loss: 2.4932994842529297
Validation loss: 1.9799006087805635

Epoch: 5| Step: 2
Training loss: 2.046297073364258
Validation loss: 1.9977358002816477

Epoch: 5| Step: 3
Training loss: 2.3076000213623047
Validation loss: 1.9683575014914236

Epoch: 5| Step: 4
Training loss: 1.3841273784637451
Validation loss: 1.99473322591474

Epoch: 5| Step: 5
Training loss: 1.6728702783584595
Validation loss: 2.019087637624433

Epoch: 5| Step: 6
Training loss: 1.7391140460968018
Validation loss: 2.0342528025309243

Epoch: 5| Step: 7
Training loss: 2.005957841873169
Validation loss: 2.0280608207948747

Epoch: 5| Step: 8
Training loss: 1.4133728742599487
Validation loss: 2.063957388683032

Epoch: 5| Step: 9
Training loss: 1.5240274667739868
Validation loss: 2.0726277443670456

Epoch: 5| Step: 10
Training loss: 1.3732224702835083
Validation loss: 2.0584576437550206

Epoch: 309| Step: 0
Training loss: 2.0119214057922363
Validation loss: 2.0568788077241633

Epoch: 5| Step: 1
Training loss: 0.9749933481216431
Validation loss: 2.0557477743394914

Epoch: 5| Step: 2
Training loss: 1.887761116027832
Validation loss: 2.0478324749136485

Epoch: 5| Step: 3
Training loss: 2.349769115447998
Validation loss: 2.063789624039845

Epoch: 5| Step: 4
Training loss: 2.1615376472473145
Validation loss: 2.0860132748080837

Epoch: 5| Step: 5
Training loss: 1.665128469467163
Validation loss: 2.1023728988503896

Epoch: 5| Step: 6
Training loss: 1.1934112310409546
Validation loss: 2.080828284704557

Epoch: 5| Step: 7
Training loss: 1.1700772047042847
Validation loss: 2.0821743549839145

Epoch: 5| Step: 8
Training loss: 2.061434268951416
Validation loss: 2.0781368619652203

Epoch: 5| Step: 9
Training loss: 1.8453395366668701
Validation loss: 2.062039162523003

Epoch: 5| Step: 10
Training loss: 2.576817512512207
Validation loss: 2.057823210634211

Epoch: 310| Step: 0
Training loss: 1.4814473390579224
Validation loss: 2.0325552186658307

Epoch: 5| Step: 1
Training loss: 1.8804359436035156
Validation loss: 2.053542580655826

Epoch: 5| Step: 2
Training loss: 2.1023483276367188
Validation loss: 2.055754410323276

Epoch: 5| Step: 3
Training loss: 1.9830341339111328
Validation loss: 2.0190137996468493

Epoch: 5| Step: 4
Training loss: 2.3201358318328857
Validation loss: 2.051359400954298

Epoch: 5| Step: 5
Training loss: 1.7491624355316162
Validation loss: 2.0388851319589922

Epoch: 5| Step: 6
Training loss: 1.6647087335586548
Validation loss: 2.023262923763644

Epoch: 5| Step: 7
Training loss: 1.2602144479751587
Validation loss: 2.015314825119511

Epoch: 5| Step: 8
Training loss: 1.3367884159088135
Validation loss: 2.0118327102353497

Epoch: 5| Step: 9
Training loss: 1.8448846340179443
Validation loss: 2.01629666871922

Epoch: 5| Step: 10
Training loss: 1.8689069747924805
Validation loss: 1.996005017270324

Epoch: 311| Step: 0
Training loss: 1.7085809707641602
Validation loss: 2.016441919470346

Epoch: 5| Step: 1
Training loss: 2.400460958480835
Validation loss: 2.0381163333051946

Epoch: 5| Step: 2
Training loss: 1.4357397556304932
Validation loss: 2.043824995717695

Epoch: 5| Step: 3
Training loss: 1.4019083976745605
Validation loss: 2.097732966946017

Epoch: 5| Step: 4
Training loss: 1.829563856124878
Validation loss: 2.0813308146692093

Epoch: 5| Step: 5
Training loss: 2.0085084438323975
Validation loss: 2.0683516635689685

Epoch: 5| Step: 6
Training loss: 1.9852640628814697
Validation loss: 2.072793460661365

Epoch: 5| Step: 7
Training loss: 1.483622431755066
Validation loss: 2.0315908578134354

Epoch: 5| Step: 8
Training loss: 2.011435031890869
Validation loss: 2.013684544512021

Epoch: 5| Step: 9
Training loss: 1.6552760601043701
Validation loss: 2.007155401732332

Epoch: 5| Step: 10
Training loss: 1.6462774276733398
Validation loss: 2.0063126664007864

Epoch: 312| Step: 0
Training loss: 2.534644365310669
Validation loss: 1.989256489661432

Epoch: 5| Step: 1
Training loss: 2.293081283569336
Validation loss: 1.9970987458382883

Epoch: 5| Step: 2
Training loss: 1.8541228771209717
Validation loss: 2.007235288619995

Epoch: 5| Step: 3
Training loss: 1.19430673122406
Validation loss: 2.011179079291641

Epoch: 5| Step: 4
Training loss: 1.32139253616333
Validation loss: 2.01400004407411

Epoch: 5| Step: 5
Training loss: 1.6141360998153687
Validation loss: 2.035772433844946

Epoch: 5| Step: 6
Training loss: 2.2050299644470215
Validation loss: 2.039212247376801

Epoch: 5| Step: 7
Training loss: 1.628302812576294
Validation loss: 2.0446745118787213

Epoch: 5| Step: 8
Training loss: 1.646423578262329
Validation loss: 2.0409844562571537

Epoch: 5| Step: 9
Training loss: 1.5406233072280884
Validation loss: 2.035036310072868

Epoch: 5| Step: 10
Training loss: 1.5896886587142944
Validation loss: 2.0187654931058168

Epoch: 313| Step: 0
Training loss: 2.1690025329589844
Validation loss: 2.0132990985788326

Epoch: 5| Step: 1
Training loss: 2.029463291168213
Validation loss: 2.010891878476707

Epoch: 5| Step: 2
Training loss: 1.4456770420074463
Validation loss: 1.983384487449482

Epoch: 5| Step: 3
Training loss: 1.4557859897613525
Validation loss: 2.0193144377841743

Epoch: 5| Step: 4
Training loss: 1.8421529531478882
Validation loss: 2.045115975923436

Epoch: 5| Step: 5
Training loss: 1.4844224452972412
Validation loss: 2.0462607363218903

Epoch: 5| Step: 6
Training loss: 2.197054386138916
Validation loss: 2.0127564784019225

Epoch: 5| Step: 7
Training loss: 1.4378890991210938
Validation loss: 2.0041374314215874

Epoch: 5| Step: 8
Training loss: 1.5085172653198242
Validation loss: 2.0025488997018464

Epoch: 5| Step: 9
Training loss: 1.5681182146072388
Validation loss: 1.9879175668121667

Epoch: 5| Step: 10
Training loss: 2.341616153717041
Validation loss: 2.0270696942524244

Epoch: 314| Step: 0
Training loss: 1.5319305658340454
Validation loss: 2.026289327170259

Epoch: 5| Step: 1
Training loss: 1.5287106037139893
Validation loss: 2.0355137983957925

Epoch: 5| Step: 2
Training loss: 1.0130575895309448
Validation loss: 2.051577970545779

Epoch: 5| Step: 3
Training loss: 2.0019614696502686
Validation loss: 2.085398979084466

Epoch: 5| Step: 4
Training loss: 1.4073503017425537
Validation loss: 2.0599208006294827

Epoch: 5| Step: 5
Training loss: 1.8676626682281494
Validation loss: 2.04749136329979

Epoch: 5| Step: 6
Training loss: 2.0338025093078613
Validation loss: 2.0339257178768033

Epoch: 5| Step: 7
Training loss: 2.3312389850616455
Validation loss: 2.02381633686763

Epoch: 5| Step: 8
Training loss: 2.1354706287384033
Validation loss: 2.0220032879101333

Epoch: 5| Step: 9
Training loss: 1.6810493469238281
Validation loss: 2.0080810157201623

Epoch: 5| Step: 10
Training loss: 1.666527509689331
Validation loss: 2.0202927948326193

Epoch: 315| Step: 0
Training loss: 1.4736138582229614
Validation loss: 2.0241426139749508

Epoch: 5| Step: 1
Training loss: 1.494508981704712
Validation loss: 2.0367684761683145

Epoch: 5| Step: 2
Training loss: 2.2886242866516113
Validation loss: 2.0170255745610883

Epoch: 5| Step: 3
Training loss: 1.7529188394546509
Validation loss: 2.0092644089011737

Epoch: 5| Step: 4
Training loss: 2.1223907470703125
Validation loss: 2.000640846067859

Epoch: 5| Step: 5
Training loss: 1.8851673603057861
Validation loss: 2.0197997798201857

Epoch: 5| Step: 6
Training loss: 1.6288572549819946
Validation loss: 2.0199826378976145

Epoch: 5| Step: 7
Training loss: 1.6622655391693115
Validation loss: 1.9962566232168546

Epoch: 5| Step: 8
Training loss: 1.3872241973876953
Validation loss: 2.0098800607906875

Epoch: 5| Step: 9
Training loss: 2.138782262802124
Validation loss: 2.0133451518192085

Epoch: 5| Step: 10
Training loss: 1.3424526453018188
Validation loss: 2.0151402745195615

Epoch: 316| Step: 0
Training loss: 1.2625526189804077
Validation loss: 2.043238724431684

Epoch: 5| Step: 1
Training loss: 1.9138590097427368
Validation loss: 2.0202657189420474

Epoch: 5| Step: 2
Training loss: 1.5649356842041016
Validation loss: 2.0517036581552155

Epoch: 5| Step: 3
Training loss: 1.6779941320419312
Validation loss: 2.0251555365900837

Epoch: 5| Step: 4
Training loss: 2.1639418601989746
Validation loss: 2.030328676264773

Epoch: 5| Step: 5
Training loss: 1.0100599527359009
Validation loss: 2.022341805119668

Epoch: 5| Step: 6
Training loss: 1.6503578424453735
Validation loss: 2.063228561032203

Epoch: 5| Step: 7
Training loss: 1.9188165664672852
Validation loss: 2.0440054375638246

Epoch: 5| Step: 8
Training loss: 1.9539626836776733
Validation loss: 2.057056406492828

Epoch: 5| Step: 9
Training loss: 1.9774425029754639
Validation loss: 2.075994792804923

Epoch: 5| Step: 10
Training loss: 2.1654767990112305
Validation loss: 2.053484889768785

Epoch: 317| Step: 0
Training loss: 1.6208734512329102
Validation loss: 2.0482767089720695

Epoch: 5| Step: 1
Training loss: 1.3230137825012207
Validation loss: 2.0707871042272097

Epoch: 5| Step: 2
Training loss: 1.3486839532852173
Validation loss: 2.080311808534848

Epoch: 5| Step: 3
Training loss: 1.1433439254760742
Validation loss: 2.074633941855482

Epoch: 5| Step: 4
Training loss: 1.9576870203018188
Validation loss: 2.0626419205819406

Epoch: 5| Step: 5
Training loss: 1.8282499313354492
Validation loss: 2.0478084292463077

Epoch: 5| Step: 6
Training loss: 2.083378553390503
Validation loss: 2.055700607197259

Epoch: 5| Step: 7
Training loss: 1.8198490142822266
Validation loss: 2.026098079578851

Epoch: 5| Step: 8
Training loss: 1.6607919931411743
Validation loss: 2.0065907022004486

Epoch: 5| Step: 9
Training loss: 2.3388173580169678
Validation loss: 1.992741346359253

Epoch: 5| Step: 10
Training loss: 2.0715343952178955
Validation loss: 1.9945351936483895

Epoch: 318| Step: 0
Training loss: 2.0921878814697266
Validation loss: 1.997624748496599

Epoch: 5| Step: 1
Training loss: 1.9139963388442993
Validation loss: 1.9912647726715251

Epoch: 5| Step: 2
Training loss: 1.5048918724060059
Validation loss: 1.9951509942290604

Epoch: 5| Step: 3
Training loss: 2.2177774906158447
Validation loss: 2.0025423239636164

Epoch: 5| Step: 4
Training loss: 0.7259325385093689
Validation loss: 2.005166551118256

Epoch: 5| Step: 5
Training loss: 1.7824407815933228
Validation loss: 2.0342882346081477

Epoch: 5| Step: 6
Training loss: 1.7123432159423828
Validation loss: 2.032529145158747

Epoch: 5| Step: 7
Training loss: 2.2724366188049316
Validation loss: 2.048978369723084

Epoch: 5| Step: 8
Training loss: 1.500331163406372
Validation loss: 2.0245735132566063

Epoch: 5| Step: 9
Training loss: 1.904889702796936
Validation loss: 2.016356407955129

Epoch: 5| Step: 10
Training loss: 1.4714699983596802
Validation loss: 2.007588117353378

Epoch: 319| Step: 0
Training loss: 1.2662290334701538
Validation loss: 1.9905436192789385

Epoch: 5| Step: 1
Training loss: 2.00713849067688
Validation loss: 1.9964578292703117

Epoch: 5| Step: 2
Training loss: 2.0587353706359863
Validation loss: 2.0079891963671614

Epoch: 5| Step: 3
Training loss: 1.6945905685424805
Validation loss: 1.9844467665559502

Epoch: 5| Step: 4
Training loss: 1.952413558959961
Validation loss: 2.008334179078379

Epoch: 5| Step: 5
Training loss: 1.4954487085342407
Validation loss: 2.011250924679541

Epoch: 5| Step: 6
Training loss: 1.6200268268585205
Validation loss: 2.0139036819499028

Epoch: 5| Step: 7
Training loss: 1.9631925821304321
Validation loss: 2.042536912425872

Epoch: 5| Step: 8
Training loss: 1.5812082290649414
Validation loss: 2.0269507233814528

Epoch: 5| Step: 9
Training loss: 1.6723178625106812
Validation loss: 2.0400330405081473

Epoch: 5| Step: 10
Training loss: 1.569491982460022
Validation loss: 2.0372349651910926

Epoch: 320| Step: 0
Training loss: 1.7242921590805054
Validation loss: 2.0336455093917025

Epoch: 5| Step: 1
Training loss: 1.731136679649353
Validation loss: 2.017589129427428

Epoch: 5| Step: 2
Training loss: 2.369246006011963
Validation loss: 1.993023746757097

Epoch: 5| Step: 3
Training loss: 1.5053348541259766
Validation loss: 1.9932927623871834

Epoch: 5| Step: 4
Training loss: 1.5930609703063965
Validation loss: 2.00495728113318

Epoch: 5| Step: 5
Training loss: 1.1848433017730713
Validation loss: 1.9748710457996657

Epoch: 5| Step: 6
Training loss: 1.5243369340896606
Validation loss: 2.0045260216600154

Epoch: 5| Step: 7
Training loss: 1.8957840204238892
Validation loss: 1.9966635806586153

Epoch: 5| Step: 8
Training loss: 1.6605991125106812
Validation loss: 2.0076951801135974

Epoch: 5| Step: 9
Training loss: 1.861985445022583
Validation loss: 2.0139780544465586

Epoch: 5| Step: 10
Training loss: 1.8403525352478027
Validation loss: 2.0492709247014855

Epoch: 321| Step: 0
Training loss: 1.6399166584014893
Validation loss: 2.0875682164263982

Epoch: 5| Step: 1
Training loss: 1.9344758987426758
Validation loss: 2.0925330423539683

Epoch: 5| Step: 2
Training loss: 1.9348783493041992
Validation loss: 2.0684811043482956

Epoch: 5| Step: 3
Training loss: 1.4824020862579346
Validation loss: 2.0842099446122364

Epoch: 5| Step: 4
Training loss: 1.787287712097168
Validation loss: 2.0796195281449186

Epoch: 5| Step: 5
Training loss: 1.6291173696517944
Validation loss: 2.0243474232253207

Epoch: 5| Step: 6
Training loss: 1.5410101413726807
Validation loss: 2.0070007949747066

Epoch: 5| Step: 7
Training loss: 1.9309288263320923
Validation loss: 2.0149492461194276

Epoch: 5| Step: 8
Training loss: 1.8584667444229126
Validation loss: 2.0156422712469615

Epoch: 5| Step: 9
Training loss: 1.975388765335083
Validation loss: 2.0080198921183103

Epoch: 5| Step: 10
Training loss: 1.2142759561538696
Validation loss: 1.9963415040764758

Epoch: 322| Step: 0
Training loss: 1.6512842178344727
Validation loss: 2.0056195502640097

Epoch: 5| Step: 1
Training loss: 1.5246926546096802
Validation loss: 1.9823006506889098

Epoch: 5| Step: 2
Training loss: 1.8770818710327148
Validation loss: 1.992392780960247

Epoch: 5| Step: 3
Training loss: 1.634777307510376
Validation loss: 2.0090222589431272

Epoch: 5| Step: 4
Training loss: 1.6798427104949951
Validation loss: 2.051596559504027

Epoch: 5| Step: 5
Training loss: 1.9265152215957642
Validation loss: 2.053476466927477

Epoch: 5| Step: 6
Training loss: 1.7706791162490845
Validation loss: 2.066682574569538

Epoch: 5| Step: 7
Training loss: 1.1897828578948975
Validation loss: 2.0812676222093645

Epoch: 5| Step: 8
Training loss: 1.95499587059021
Validation loss: 2.0467576647317536

Epoch: 5| Step: 9
Training loss: 2.014463424682617
Validation loss: 2.0207072406686764

Epoch: 5| Step: 10
Training loss: 1.7782585620880127
Validation loss: 2.0171236709881852

Epoch: 323| Step: 0
Training loss: 1.948144555091858
Validation loss: 1.9984186785195464

Epoch: 5| Step: 1
Training loss: 1.7107582092285156
Validation loss: 2.028542354542722

Epoch: 5| Step: 2
Training loss: 1.6972852945327759
Validation loss: 2.0448883989805817

Epoch: 5| Step: 3
Training loss: 1.9953464269638062
Validation loss: 2.0531719730746363

Epoch: 5| Step: 4
Training loss: 1.4692738056182861
Validation loss: 2.0515328325251097

Epoch: 5| Step: 5
Training loss: 2.624695301055908
Validation loss: 2.0512705541426137

Epoch: 5| Step: 6
Training loss: 1.2729787826538086
Validation loss: 2.0462561550960747

Epoch: 5| Step: 7
Training loss: 1.7946655750274658
Validation loss: 2.046534699778403

Epoch: 5| Step: 8
Training loss: 1.4368387460708618
Validation loss: 2.0201663201855076

Epoch: 5| Step: 9
Training loss: 1.7231117486953735
Validation loss: 2.0243056410102436

Epoch: 5| Step: 10
Training loss: 1.0456633567810059
Validation loss: 2.0048271122799126

Epoch: 324| Step: 0
Training loss: 1.526515007019043
Validation loss: 1.9929129769725185

Epoch: 5| Step: 1
Training loss: 1.5390369892120361
Validation loss: 2.0085199404788274

Epoch: 5| Step: 2
Training loss: 1.7254717350006104
Validation loss: 2.0326242369990193

Epoch: 5| Step: 3
Training loss: 2.0308895111083984
Validation loss: 2.027920787052442

Epoch: 5| Step: 4
Training loss: 1.99666428565979
Validation loss: 2.0412903447305

Epoch: 5| Step: 5
Training loss: 2.1373982429504395
Validation loss: 2.012831477708714

Epoch: 5| Step: 6
Training loss: 1.6365963220596313
Validation loss: 2.0167733289862193

Epoch: 5| Step: 7
Training loss: 1.5974843502044678
Validation loss: 1.9812795962056806

Epoch: 5| Step: 8
Training loss: 1.6180614233016968
Validation loss: 1.9786754987573112

Epoch: 5| Step: 9
Training loss: 1.650644302368164
Validation loss: 1.9811112598706317

Epoch: 5| Step: 10
Training loss: 1.428344488143921
Validation loss: 2.011603706626482

Epoch: 325| Step: 0
Training loss: 1.6184803247451782
Validation loss: 2.0029755369309457

Epoch: 5| Step: 1
Training loss: 2.266918659210205
Validation loss: 2.0270128737213793

Epoch: 5| Step: 2
Training loss: 1.4343591928482056
Validation loss: 2.0670739194398284

Epoch: 5| Step: 3
Training loss: 1.3196651935577393
Validation loss: 2.058512213409588

Epoch: 5| Step: 4
Training loss: 1.422088384628296
Validation loss: 2.0810139051047702

Epoch: 5| Step: 5
Training loss: 1.8813937902450562
Validation loss: 2.0840397111831175

Epoch: 5| Step: 6
Training loss: 1.5248124599456787
Validation loss: 2.082975410646008

Epoch: 5| Step: 7
Training loss: 1.6638333797454834
Validation loss: 2.0481626218365085

Epoch: 5| Step: 8
Training loss: 1.4990483522415161
Validation loss: 2.0216993708764353

Epoch: 5| Step: 9
Training loss: 2.348419666290283
Validation loss: 2.0241661687051096

Epoch: 5| Step: 10
Training loss: 1.844861388206482
Validation loss: 2.0263357367566837

Epoch: 326| Step: 0
Training loss: 1.6532726287841797
Validation loss: 2.037437092873358

Epoch: 5| Step: 1
Training loss: 1.500985860824585
Validation loss: 2.0341064391597623

Epoch: 5| Step: 2
Training loss: 1.8699185848236084
Validation loss: 2.0453841429884716

Epoch: 5| Step: 3
Training loss: 1.407444715499878
Validation loss: 2.054438450003183

Epoch: 5| Step: 4
Training loss: 1.6905521154403687
Validation loss: 2.058855067017258

Epoch: 5| Step: 5
Training loss: 1.9054439067840576
Validation loss: 2.0277399939875447

Epoch: 5| Step: 6
Training loss: 1.8983275890350342
Validation loss: 2.030152569534958

Epoch: 5| Step: 7
Training loss: 1.8242499828338623
Validation loss: 2.017594809173256

Epoch: 5| Step: 8
Training loss: 2.028296709060669
Validation loss: 1.9976020795042797

Epoch: 5| Step: 9
Training loss: 1.814806342124939
Validation loss: 1.9969838383377239

Epoch: 5| Step: 10
Training loss: 1.1771008968353271
Validation loss: 1.9898060291044173

Epoch: 327| Step: 0
Training loss: 1.8156474828720093
Validation loss: 1.9970499841115807

Epoch: 5| Step: 1
Training loss: 2.110283136367798
Validation loss: 1.9981415169213408

Epoch: 5| Step: 2
Training loss: 2.148747444152832
Validation loss: 2.0013728744240216

Epoch: 5| Step: 3
Training loss: 1.523988962173462
Validation loss: 2.0001735148891324

Epoch: 5| Step: 4
Training loss: 2.0774736404418945
Validation loss: 1.9849621493329284

Epoch: 5| Step: 5
Training loss: 1.3825674057006836
Validation loss: 1.9910081535257318

Epoch: 5| Step: 6
Training loss: 1.7799361944198608
Validation loss: 1.9893467080208562

Epoch: 5| Step: 7
Training loss: 1.6359659433364868
Validation loss: 2.0141471406464935

Epoch: 5| Step: 8
Training loss: 1.4872233867645264
Validation loss: 2.038233971083036

Epoch: 5| Step: 9
Training loss: 1.2875782251358032
Validation loss: 2.0589275334471013

Epoch: 5| Step: 10
Training loss: 1.4477874040603638
Validation loss: 2.0200482799160864

Epoch: 328| Step: 0
Training loss: 1.6160857677459717
Validation loss: 2.0455226718738513

Epoch: 5| Step: 1
Training loss: 2.000300645828247
Validation loss: 2.0144225474326842

Epoch: 5| Step: 2
Training loss: 2.2717344760894775
Validation loss: 2.009018657028034

Epoch: 5| Step: 3
Training loss: 1.2177168130874634
Validation loss: 2.0135700882122083

Epoch: 5| Step: 4
Training loss: 1.213879942893982
Validation loss: 2.008725307321036

Epoch: 5| Step: 5
Training loss: 2.0243277549743652
Validation loss: 2.00186300405892

Epoch: 5| Step: 6
Training loss: 1.5141069889068604
Validation loss: 2.0163104072693856

Epoch: 5| Step: 7
Training loss: 2.020272731781006
Validation loss: 2.038742378193845

Epoch: 5| Step: 8
Training loss: 1.2437245845794678
Validation loss: 2.0607727881400817

Epoch: 5| Step: 9
Training loss: 2.2626917362213135
Validation loss: 2.0806793974291895

Epoch: 5| Step: 10
Training loss: 1.2515316009521484
Validation loss: 2.0901722292746268

Epoch: 329| Step: 0
Training loss: 1.5336315631866455
Validation loss: 2.0679055670256257

Epoch: 5| Step: 1
Training loss: 1.4828637838363647
Validation loss: 2.029377006715344

Epoch: 5| Step: 2
Training loss: 1.8699321746826172
Validation loss: 2.0063923481971986

Epoch: 5| Step: 3
Training loss: 1.748299241065979
Validation loss: 1.9832640130032775

Epoch: 5| Step: 4
Training loss: 1.4240128993988037
Validation loss: 1.9756646028129004

Epoch: 5| Step: 5
Training loss: 1.7095104455947876
Validation loss: 1.995996957184166

Epoch: 5| Step: 6
Training loss: 2.0356879234313965
Validation loss: 1.9963334503994192

Epoch: 5| Step: 7
Training loss: 1.5494489669799805
Validation loss: 2.0175472305667017

Epoch: 5| Step: 8
Training loss: 1.7938188314437866
Validation loss: 2.0470498531095442

Epoch: 5| Step: 9
Training loss: 1.4739199876785278
Validation loss: 2.0466348842907975

Epoch: 5| Step: 10
Training loss: 2.1170544624328613
Validation loss: 2.057594173698015

Epoch: 330| Step: 0
Training loss: 1.6395747661590576
Validation loss: 2.0224788368389173

Epoch: 5| Step: 1
Training loss: 1.4358303546905518
Validation loss: 2.0100436236268733

Epoch: 5| Step: 2
Training loss: 1.3996913433074951
Validation loss: 2.0175933543071953

Epoch: 5| Step: 3
Training loss: 1.7848966121673584
Validation loss: 1.9950453799257997

Epoch: 5| Step: 4
Training loss: 2.0671563148498535
Validation loss: 1.9705127926282986

Epoch: 5| Step: 5
Training loss: 1.7644373178482056
Validation loss: 2.0092196233810915

Epoch: 5| Step: 6
Training loss: 1.5172184705734253
Validation loss: 1.9743691567451722

Epoch: 5| Step: 7
Training loss: 2.061452865600586
Validation loss: 1.9871064437332975

Epoch: 5| Step: 8
Training loss: 1.867281198501587
Validation loss: 1.9974657566316667

Epoch: 5| Step: 9
Training loss: 1.1507948637008667
Validation loss: 2.000602096639654

Epoch: 5| Step: 10
Training loss: 1.6672254800796509
Validation loss: 2.0181727909272715

Epoch: 331| Step: 0
Training loss: 2.0458321571350098
Validation loss: 2.0372970283672376

Epoch: 5| Step: 1
Training loss: 1.473698616027832
Validation loss: 2.052552862833905

Epoch: 5| Step: 2
Training loss: 1.896610975265503
Validation loss: 2.0649703779528217

Epoch: 5| Step: 3
Training loss: 1.6190767288208008
Validation loss: 2.0243893323406095

Epoch: 5| Step: 4
Training loss: 1.7472339868545532
Validation loss: 2.0038485257856307

Epoch: 5| Step: 5
Training loss: 2.163849353790283
Validation loss: 2.006556858298599

Epoch: 5| Step: 6
Training loss: 1.6653053760528564
Validation loss: 2.0079095184162097

Epoch: 5| Step: 7
Training loss: 1.3375731706619263
Validation loss: 2.012955962970693

Epoch: 5| Step: 8
Training loss: 1.4649195671081543
Validation loss: 2.006099051044833

Epoch: 5| Step: 9
Training loss: 1.7227588891983032
Validation loss: 1.9903539021809895

Epoch: 5| Step: 10
Training loss: 1.3630588054656982
Validation loss: 1.9983257991011425

Epoch: 332| Step: 0
Training loss: 1.9296391010284424
Validation loss: 2.037320343396997

Epoch: 5| Step: 1
Training loss: 1.894431471824646
Validation loss: 2.0638305884535595

Epoch: 5| Step: 2
Training loss: 1.7435665130615234
Validation loss: 2.059283776949811

Epoch: 5| Step: 3
Training loss: 2.0642142295837402
Validation loss: 2.0466567111271683

Epoch: 5| Step: 4
Training loss: 1.4768587350845337
Validation loss: 2.044172380560188

Epoch: 5| Step: 5
Training loss: 1.1015733480453491
Validation loss: 2.011087135602069

Epoch: 5| Step: 6
Training loss: 1.2171592712402344
Validation loss: 1.9930891631751932

Epoch: 5| Step: 7
Training loss: 2.5273678302764893
Validation loss: 1.964970793775333

Epoch: 5| Step: 8
Training loss: 1.5373971462249756
Validation loss: 1.9790058879442112

Epoch: 5| Step: 9
Training loss: 1.9874216318130493
Validation loss: 1.9754509361841346

Epoch: 5| Step: 10
Training loss: 1.2252047061920166
Validation loss: 1.992636675475746

Epoch: 333| Step: 0
Training loss: 1.8725910186767578
Validation loss: 1.9962016228706605

Epoch: 5| Step: 1
Training loss: 2.4392080307006836
Validation loss: 1.9902056827340076

Epoch: 5| Step: 2
Training loss: 1.4447224140167236
Validation loss: 2.044375470889512

Epoch: 5| Step: 3
Training loss: 1.4624186754226685
Validation loss: 2.0234826482752317

Epoch: 5| Step: 4
Training loss: 1.903599500656128
Validation loss: 2.0523218339489353

Epoch: 5| Step: 5
Training loss: 1.0789029598236084
Validation loss: 2.028205963873094

Epoch: 5| Step: 6
Training loss: 1.17208993434906
Validation loss: 2.0493621531353203

Epoch: 5| Step: 7
Training loss: 1.862491250038147
Validation loss: 2.0244415934367845

Epoch: 5| Step: 8
Training loss: 1.866332769393921
Validation loss: 2.0029437529143466

Epoch: 5| Step: 9
Training loss: 2.134387493133545
Validation loss: 1.9774651001858454

Epoch: 5| Step: 10
Training loss: 0.9674029350280762
Validation loss: 1.9896603066434142

Epoch: 334| Step: 0
Training loss: 1.967698097229004
Validation loss: 1.9764259297360656

Epoch: 5| Step: 1
Training loss: 1.8794729709625244
Validation loss: 1.9783851126188874

Epoch: 5| Step: 2
Training loss: 1.4206435680389404
Validation loss: 1.9866324150434105

Epoch: 5| Step: 3
Training loss: 2.118385076522827
Validation loss: 1.989583856316023

Epoch: 5| Step: 4
Training loss: 1.2905675172805786
Validation loss: 1.9619497932413572

Epoch: 5| Step: 5
Training loss: 1.3288743495941162
Validation loss: 2.0005384722063617

Epoch: 5| Step: 6
Training loss: 1.9191251993179321
Validation loss: 1.9988784200401717

Epoch: 5| Step: 7
Training loss: 1.4730793237686157
Validation loss: 2.015191247386317

Epoch: 5| Step: 8
Training loss: 1.986254096031189
Validation loss: 2.0247077595803047

Epoch: 5| Step: 9
Training loss: 1.2785879373550415
Validation loss: 2.078206136662473

Epoch: 5| Step: 10
Training loss: 1.640161156654358
Validation loss: 2.0760512069989274

Epoch: 335| Step: 0
Training loss: 1.7851555347442627
Validation loss: 2.0690219043403544

Epoch: 5| Step: 1
Training loss: 1.4631274938583374
Validation loss: 2.087294570861324

Epoch: 5| Step: 2
Training loss: 1.7767788171768188
Validation loss: 2.0813421151971303

Epoch: 5| Step: 3
Training loss: 1.599722146987915
Validation loss: 2.0547496298308014

Epoch: 5| Step: 4
Training loss: 1.699293851852417
Validation loss: 2.0082728760216826

Epoch: 5| Step: 5
Training loss: 1.8830339908599854
Validation loss: 1.9929447814982424

Epoch: 5| Step: 6
Training loss: 1.425808310508728
Validation loss: 2.021280679651486

Epoch: 5| Step: 7
Training loss: 1.4343599081039429
Validation loss: 2.0044053216134348

Epoch: 5| Step: 8
Training loss: 1.955949068069458
Validation loss: 1.9830785707760883

Epoch: 5| Step: 9
Training loss: 1.9051183462142944
Validation loss: 1.9781337245818107

Epoch: 5| Step: 10
Training loss: 1.5551111698150635
Validation loss: 1.9859351445269842

Epoch: 336| Step: 0
Training loss: 1.7043483257293701
Validation loss: 2.0047632750644477

Epoch: 5| Step: 1
Training loss: 1.4217122793197632
Validation loss: 2.039281073436942

Epoch: 5| Step: 2
Training loss: 1.5282841920852661
Validation loss: 2.0437293437219437

Epoch: 5| Step: 3
Training loss: 1.6249358654022217
Validation loss: 2.040518081316384

Epoch: 5| Step: 4
Training loss: 1.0453708171844482
Validation loss: 2.033472135502805

Epoch: 5| Step: 5
Training loss: 1.8700720071792603
Validation loss: 2.0294259543059976

Epoch: 5| Step: 6
Training loss: 2.288130283355713
Validation loss: 2.029156163174619

Epoch: 5| Step: 7
Training loss: 1.580387830734253
Validation loss: 2.001816831609254

Epoch: 5| Step: 8
Training loss: 1.8613121509552002
Validation loss: 2.0025107834928777

Epoch: 5| Step: 9
Training loss: 1.108474850654602
Validation loss: 2.0058656584831978

Epoch: 5| Step: 10
Training loss: 2.08660626411438
Validation loss: 2.006078515001523

Epoch: 337| Step: 0
Training loss: 1.949171781539917
Validation loss: 1.9993778556905768

Epoch: 5| Step: 1
Training loss: 1.3327726125717163
Validation loss: 1.983497941365806

Epoch: 5| Step: 2
Training loss: 1.74823796749115
Validation loss: 2.0081555048624673

Epoch: 5| Step: 3
Training loss: 2.238502025604248
Validation loss: 2.004848316151609

Epoch: 5| Step: 4
Training loss: 1.7255375385284424
Validation loss: 2.0398744113983645

Epoch: 5| Step: 5
Training loss: 2.0315189361572266
Validation loss: 2.0588276501624816

Epoch: 5| Step: 6
Training loss: 1.3592636585235596
Validation loss: 2.0576435878712642

Epoch: 5| Step: 7
Training loss: 1.156091332435608
Validation loss: 2.0360061045615905

Epoch: 5| Step: 8
Training loss: 1.4627071619033813
Validation loss: 2.013604034659683

Epoch: 5| Step: 9
Training loss: 1.1356576681137085
Validation loss: 1.9972041037774855

Epoch: 5| Step: 10
Training loss: 1.9957194328308105
Validation loss: 1.9867170959390619

Epoch: 338| Step: 0
Training loss: 1.6213924884796143
Validation loss: 1.9991589387257893

Epoch: 5| Step: 1
Training loss: 1.4309146404266357
Validation loss: 1.9785318887361916

Epoch: 5| Step: 2
Training loss: 1.290065050125122
Validation loss: 1.987427516650128

Epoch: 5| Step: 3
Training loss: 2.1211061477661133
Validation loss: 1.9774331713235507

Epoch: 5| Step: 4
Training loss: 1.6067068576812744
Validation loss: 2.011454564268871

Epoch: 5| Step: 5
Training loss: 1.0609562397003174
Validation loss: 2.032880731808242

Epoch: 5| Step: 6
Training loss: 1.7970383167266846
Validation loss: 2.0665560435223322

Epoch: 5| Step: 7
Training loss: 1.8947627544403076
Validation loss: 2.074484791806949

Epoch: 5| Step: 8
Training loss: 2.1266427040100098
Validation loss: 2.0521927341338126

Epoch: 5| Step: 9
Training loss: 1.5790865421295166
Validation loss: 2.0220724972345496

Epoch: 5| Step: 10
Training loss: 1.8556584119796753
Validation loss: 2.018139586653761

Epoch: 339| Step: 0
Training loss: 1.3342063426971436
Validation loss: 2.0135329372139386

Epoch: 5| Step: 1
Training loss: 1.826507329940796
Validation loss: 1.9967104799004012

Epoch: 5| Step: 2
Training loss: 1.2997678518295288
Validation loss: 1.9863374976701633

Epoch: 5| Step: 3
Training loss: 1.2142530679702759
Validation loss: 1.9912158622536609

Epoch: 5| Step: 4
Training loss: 2.1955342292785645
Validation loss: 2.0027406856577885

Epoch: 5| Step: 5
Training loss: 1.7985334396362305
Validation loss: 1.996160816120845

Epoch: 5| Step: 6
Training loss: 1.498610496520996
Validation loss: 1.985032812241585

Epoch: 5| Step: 7
Training loss: 1.662043571472168
Validation loss: 1.9986090326821933

Epoch: 5| Step: 8
Training loss: 1.978721022605896
Validation loss: 1.9925236881420176

Epoch: 5| Step: 9
Training loss: 1.419908881187439
Validation loss: 2.0195256369088286

Epoch: 5| Step: 10
Training loss: 1.8032307624816895
Validation loss: 2.01589830588269

Epoch: 340| Step: 0
Training loss: 1.4820213317871094
Validation loss: 2.0207910896629415

Epoch: 5| Step: 1
Training loss: 2.4186244010925293
Validation loss: 2.038752258464854

Epoch: 5| Step: 2
Training loss: 1.6450961828231812
Validation loss: 2.0163584191312074

Epoch: 5| Step: 3
Training loss: 1.4146361351013184
Validation loss: 2.017083465412099

Epoch: 5| Step: 4
Training loss: 1.1642684936523438
Validation loss: 2.0130588957058486

Epoch: 5| Step: 5
Training loss: 1.5301235914230347
Validation loss: 2.020356671784514

Epoch: 5| Step: 6
Training loss: 1.1212948560714722
Validation loss: 2.021471431178431

Epoch: 5| Step: 7
Training loss: 2.1418323516845703
Validation loss: 2.024711916523595

Epoch: 5| Step: 8
Training loss: 1.779026746749878
Validation loss: 2.032210880710233

Epoch: 5| Step: 9
Training loss: 1.7999670505523682
Validation loss: 2.0495028380424745

Epoch: 5| Step: 10
Training loss: 1.4394556283950806
Validation loss: 2.0397025885120517

Epoch: 341| Step: 0
Training loss: 1.7718513011932373
Validation loss: 2.0402943805981706

Epoch: 5| Step: 1
Training loss: 1.540891408920288
Validation loss: 2.033602791447793

Epoch: 5| Step: 2
Training loss: 1.0426594018936157
Validation loss: 2.031390441361294

Epoch: 5| Step: 3
Training loss: 1.9410804510116577
Validation loss: 2.0251780556094263

Epoch: 5| Step: 4
Training loss: 1.8952051401138306
Validation loss: 2.0217007642151206

Epoch: 5| Step: 5
Training loss: 1.5447731018066406
Validation loss: 2.0119495520027737

Epoch: 5| Step: 6
Training loss: 1.2903759479522705
Validation loss: 2.017767790184226

Epoch: 5| Step: 7
Training loss: 1.7403831481933594
Validation loss: 2.0212913328601467

Epoch: 5| Step: 8
Training loss: 2.0131802558898926
Validation loss: 2.0102667885441936

Epoch: 5| Step: 9
Training loss: 1.6524498462677002
Validation loss: 2.0050415787645566

Epoch: 5| Step: 10
Training loss: 1.5476717948913574
Validation loss: 1.9911250747660154

Epoch: 342| Step: 0
Training loss: 1.1603915691375732
Validation loss: 2.007837321168633

Epoch: 5| Step: 1
Training loss: 1.6896581649780273
Validation loss: 2.0108093805210565

Epoch: 5| Step: 2
Training loss: 1.4502034187316895
Validation loss: 2.018566610992596

Epoch: 5| Step: 3
Training loss: 1.7533385753631592
Validation loss: 2.026011513125512

Epoch: 5| Step: 4
Training loss: 1.0271012783050537
Validation loss: 2.027705879621608

Epoch: 5| Step: 5
Training loss: 1.6705595254898071
Validation loss: 2.011192152577062

Epoch: 5| Step: 6
Training loss: 1.9727506637573242
Validation loss: 2.0103679831309984

Epoch: 5| Step: 7
Training loss: 1.137853741645813
Validation loss: 1.974996164280881

Epoch: 5| Step: 8
Training loss: 2.1510443687438965
Validation loss: 1.9907155959836897

Epoch: 5| Step: 9
Training loss: 1.909967064857483
Validation loss: 1.980380703044194

Epoch: 5| Step: 10
Training loss: 1.8508570194244385
Validation loss: 2.011441687101959

Epoch: 343| Step: 0
Training loss: 1.4967832565307617
Validation loss: 1.9807529552008516

Epoch: 5| Step: 1
Training loss: 1.9299389123916626
Validation loss: 1.993450153258539

Epoch: 5| Step: 2
Training loss: 1.3399732112884521
Validation loss: 1.9987762692154094

Epoch: 5| Step: 3
Training loss: 1.6022346019744873
Validation loss: 2.0170435520910446

Epoch: 5| Step: 4
Training loss: 1.9887745380401611
Validation loss: 2.03524378807314

Epoch: 5| Step: 5
Training loss: 1.5281003713607788
Validation loss: 2.0001520623442945

Epoch: 5| Step: 6
Training loss: 1.2198349237442017
Validation loss: 1.9745011611651349

Epoch: 5| Step: 7
Training loss: 1.0606689453125
Validation loss: 1.977869551668885

Epoch: 5| Step: 8
Training loss: 2.336019515991211
Validation loss: 1.966319763532249

Epoch: 5| Step: 9
Training loss: 2.166872501373291
Validation loss: 1.965799440619766

Epoch: 5| Step: 10
Training loss: 1.255732536315918
Validation loss: 1.9734430005473476

Epoch: 344| Step: 0
Training loss: 1.5812456607818604
Validation loss: 1.9844649017498057

Epoch: 5| Step: 1
Training loss: 1.6244808435440063
Validation loss: 1.9945375765523603

Epoch: 5| Step: 2
Training loss: 0.8802372217178345
Validation loss: 2.015936811765035

Epoch: 5| Step: 3
Training loss: 1.5607388019561768
Validation loss: 2.0651236785355436

Epoch: 5| Step: 4
Training loss: 1.5086075067520142
Validation loss: 2.0421006576989287

Epoch: 5| Step: 5
Training loss: 1.990614652633667
Validation loss: 2.0781283147873415

Epoch: 5| Step: 6
Training loss: 1.7812604904174805
Validation loss: 2.0528291322851695

Epoch: 5| Step: 7
Training loss: 1.9943088293075562
Validation loss: 2.02564214762821

Epoch: 5| Step: 8
Training loss: 1.6160056591033936
Validation loss: 1.9955648427368493

Epoch: 5| Step: 9
Training loss: 1.9200557470321655
Validation loss: 2.0025192768343034

Epoch: 5| Step: 10
Training loss: 1.365761637687683
Validation loss: 1.97561562830402

Epoch: 345| Step: 0
Training loss: 1.0075509548187256
Validation loss: 1.9665514179455337

Epoch: 5| Step: 1
Training loss: 1.73702073097229
Validation loss: 1.9680233693891955

Epoch: 5| Step: 2
Training loss: 1.778005838394165
Validation loss: 1.9802455722644765

Epoch: 5| Step: 3
Training loss: 1.607842206954956
Validation loss: 2.007104294274443

Epoch: 5| Step: 4
Training loss: 1.786018967628479
Validation loss: 1.9957307448951147

Epoch: 5| Step: 5
Training loss: 1.855013132095337
Validation loss: 2.0073153754716277

Epoch: 5| Step: 6
Training loss: 2.2225775718688965
Validation loss: 2.012204759864397

Epoch: 5| Step: 7
Training loss: 1.2794265747070312
Validation loss: 2.0104479815370295

Epoch: 5| Step: 8
Training loss: 1.5022785663604736
Validation loss: 2.012894840650661

Epoch: 5| Step: 9
Training loss: 1.4716923236846924
Validation loss: 2.015865300291328

Epoch: 5| Step: 10
Training loss: 1.2373936176300049
Validation loss: 2.0018577819229453

Epoch: 346| Step: 0
Training loss: 1.5874292850494385
Validation loss: 2.0148818454434796

Epoch: 5| Step: 1
Training loss: 1.19228994846344
Validation loss: 2.006687154052078

Epoch: 5| Step: 2
Training loss: 1.4832980632781982
Validation loss: 2.00042752809422

Epoch: 5| Step: 3
Training loss: 1.6107158660888672
Validation loss: 1.9856742351285872

Epoch: 5| Step: 4
Training loss: 1.835428237915039
Validation loss: 1.9883681458811606

Epoch: 5| Step: 5
Training loss: 1.1258317232131958
Validation loss: 2.0194554200736423

Epoch: 5| Step: 6
Training loss: 1.6236743927001953
Validation loss: 2.026447247433406

Epoch: 5| Step: 7
Training loss: 2.704246997833252
Validation loss: 2.0496584523108696

Epoch: 5| Step: 8
Training loss: 1.8868000507354736
Validation loss: 2.0804864847531883

Epoch: 5| Step: 9
Training loss: 0.8965883255004883
Validation loss: 2.0324847300847373

Epoch: 5| Step: 10
Training loss: 1.6180729866027832
Validation loss: 2.0506334817537697

Epoch: 347| Step: 0
Training loss: 1.4120376110076904
Validation loss: 2.0507514117866434

Epoch: 5| Step: 1
Training loss: 1.9515609741210938
Validation loss: 2.0228282277302077

Epoch: 5| Step: 2
Training loss: 1.358943223953247
Validation loss: 2.0262576174992386

Epoch: 5| Step: 3
Training loss: 1.4914727210998535
Validation loss: 2.007491465537779

Epoch: 5| Step: 4
Training loss: 1.6465091705322266
Validation loss: 1.9860767010719544

Epoch: 5| Step: 5
Training loss: 1.9332510232925415
Validation loss: 1.9806364197884836

Epoch: 5| Step: 6
Training loss: 1.3905351161956787
Validation loss: 1.9831123864778908

Epoch: 5| Step: 7
Training loss: 1.3948609828948975
Validation loss: 2.0075347167189403

Epoch: 5| Step: 8
Training loss: 1.1878379583358765
Validation loss: 2.0368252825993363

Epoch: 5| Step: 9
Training loss: 1.853397011756897
Validation loss: 2.051222197471126

Epoch: 5| Step: 10
Training loss: 2.001743793487549
Validation loss: 2.080297759784165

Epoch: 348| Step: 0
Training loss: 1.341544508934021
Validation loss: 2.1114373591638382

Epoch: 5| Step: 1
Training loss: 1.5261189937591553
Validation loss: 2.1099776721769765

Epoch: 5| Step: 2
Training loss: 1.6423572301864624
Validation loss: 2.0574118039941274

Epoch: 5| Step: 3
Training loss: 1.4700849056243896
Validation loss: 2.0356981215938443

Epoch: 5| Step: 4
Training loss: 0.7973636388778687
Validation loss: 2.0044103412217993

Epoch: 5| Step: 5
Training loss: 1.7736766338348389
Validation loss: 1.9800877160923456

Epoch: 5| Step: 6
Training loss: 1.9289108514785767
Validation loss: 1.9834733316975255

Epoch: 5| Step: 7
Training loss: 1.4281305074691772
Validation loss: 1.9908868241053757

Epoch: 5| Step: 8
Training loss: 2.330237865447998
Validation loss: 1.9857758219524095

Epoch: 5| Step: 9
Training loss: 1.595106840133667
Validation loss: 1.9791147785802041

Epoch: 5| Step: 10
Training loss: 1.903741717338562
Validation loss: 1.9932837627267326

Epoch: 349| Step: 0
Training loss: 1.288417100906372
Validation loss: 2.0160618520552114

Epoch: 5| Step: 1
Training loss: 1.9458612203598022
Validation loss: 2.0519482012717956

Epoch: 5| Step: 2
Training loss: 1.471735954284668
Validation loss: 2.035633417867845

Epoch: 5| Step: 3
Training loss: 1.6207221746444702
Validation loss: 2.0538157365655385

Epoch: 5| Step: 4
Training loss: 1.681176781654358
Validation loss: 2.041443572249464

Epoch: 5| Step: 5
Training loss: 1.782623291015625
Validation loss: 2.0073203861072497

Epoch: 5| Step: 6
Training loss: 1.197330355644226
Validation loss: 1.9719118149049821

Epoch: 5| Step: 7
Training loss: 2.39074969291687
Validation loss: 1.9902310704672208

Epoch: 5| Step: 8
Training loss: 1.61727774143219
Validation loss: 1.9771352173179708

Epoch: 5| Step: 9
Training loss: 1.171386957168579
Validation loss: 1.9789264625118625

Epoch: 5| Step: 10
Training loss: 1.4867336750030518
Validation loss: 1.9880831472335323

Epoch: 350| Step: 0
Training loss: 1.5435693264007568
Validation loss: 1.9998895340068366

Epoch: 5| Step: 1
Training loss: 1.6184072494506836
Validation loss: 2.030457720961622

Epoch: 5| Step: 2
Training loss: 1.524282693862915
Validation loss: 2.0555744683870705

Epoch: 5| Step: 3
Training loss: 1.3380242586135864
Validation loss: 2.032570437718463

Epoch: 5| Step: 4
Training loss: 1.4648772478103638
Validation loss: 2.0535944841241323

Epoch: 5| Step: 5
Training loss: 1.414292573928833
Validation loss: 2.0268516502072735

Epoch: 5| Step: 6
Training loss: 1.7349989414215088
Validation loss: 1.9970829691938174

Epoch: 5| Step: 7
Training loss: 1.426933765411377
Validation loss: 1.993295310645975

Epoch: 5| Step: 8
Training loss: 2.1914515495300293
Validation loss: 2.0020824465700375

Epoch: 5| Step: 9
Training loss: 1.461399793624878
Validation loss: 1.9823242772010066

Epoch: 5| Step: 10
Training loss: 1.6669378280639648
Validation loss: 1.997202242574384

Epoch: 351| Step: 0
Training loss: 1.5281120538711548
Validation loss: 2.007915868554064

Epoch: 5| Step: 1
Training loss: 1.2214548587799072
Validation loss: 2.0030670448016097

Epoch: 5| Step: 2
Training loss: 1.4269012212753296
Validation loss: 2.008974363726954

Epoch: 5| Step: 3
Training loss: 1.060437798500061
Validation loss: 2.0391313939966182

Epoch: 5| Step: 4
Training loss: 1.315966010093689
Validation loss: 2.0639459535639775

Epoch: 5| Step: 5
Training loss: 1.7526493072509766
Validation loss: 2.0535348615338727

Epoch: 5| Step: 6
Training loss: 1.6648565530776978
Validation loss: 2.069393465595861

Epoch: 5| Step: 7
Training loss: 1.342124581336975
Validation loss: 2.029423482956425

Epoch: 5| Step: 8
Training loss: 1.9023643732070923
Validation loss: 2.0240585393803094

Epoch: 5| Step: 9
Training loss: 2.5106074810028076
Validation loss: 1.9991881014198385

Epoch: 5| Step: 10
Training loss: 1.466745376586914
Validation loss: 1.9920970393765358

Epoch: 352| Step: 0
Training loss: 1.2243095636367798
Validation loss: 1.9722220077309558

Epoch: 5| Step: 1
Training loss: 0.9672718048095703
Validation loss: 1.9784620397834367

Epoch: 5| Step: 2
Training loss: 1.2685675621032715
Validation loss: 2.001987505984563

Epoch: 5| Step: 3
Training loss: 1.4550179243087769
Validation loss: 1.9966375122788131

Epoch: 5| Step: 4
Training loss: 1.4257423877716064
Validation loss: 1.998070518175761

Epoch: 5| Step: 5
Training loss: 1.7442655563354492
Validation loss: 2.024906692966338

Epoch: 5| Step: 6
Training loss: 1.530268669128418
Validation loss: 2.0597959385123303

Epoch: 5| Step: 7
Training loss: 1.7981655597686768
Validation loss: 2.073669163129663

Epoch: 5| Step: 8
Training loss: 2.1331255435943604
Validation loss: 2.050304905060799

Epoch: 5| Step: 9
Training loss: 2.3649234771728516
Validation loss: 2.0432294966072164

Epoch: 5| Step: 10
Training loss: 1.3050870895385742
Validation loss: 2.037852601338458

Epoch: 353| Step: 0
Training loss: 1.4250411987304688
Validation loss: 1.9973306937884259

Epoch: 5| Step: 1
Training loss: 1.8657233715057373
Validation loss: 1.9888418489886868

Epoch: 5| Step: 2
Training loss: 2.0906906127929688
Validation loss: 1.9805343228001748

Epoch: 5| Step: 3
Training loss: 1.0979267358779907
Validation loss: 1.9861708917925436

Epoch: 5| Step: 4
Training loss: 1.9518495798110962
Validation loss: 1.9849579385531846

Epoch: 5| Step: 5
Training loss: 1.4283323287963867
Validation loss: 2.012618854481687

Epoch: 5| Step: 6
Training loss: 0.9991051554679871
Validation loss: 2.009847894791634

Epoch: 5| Step: 7
Training loss: 1.8423058986663818
Validation loss: 2.021539795783258

Epoch: 5| Step: 8
Training loss: 1.7583720684051514
Validation loss: 2.04287963785151

Epoch: 5| Step: 9
Training loss: 1.109328031539917
Validation loss: 2.0530475006308606

Epoch: 5| Step: 10
Training loss: 1.7330609560012817
Validation loss: 2.032789550801759

Epoch: 354| Step: 0
Training loss: 1.7957077026367188
Validation loss: 2.0229505082612396

Epoch: 5| Step: 1
Training loss: 1.604074239730835
Validation loss: 1.9918032666688323

Epoch: 5| Step: 2
Training loss: 1.5633747577667236
Validation loss: 2.006214162354828

Epoch: 5| Step: 3
Training loss: 1.7561569213867188
Validation loss: 2.0039697911149714

Epoch: 5| Step: 4
Training loss: 1.4496843814849854
Validation loss: 2.002852861599256

Epoch: 5| Step: 5
Training loss: 1.5115480422973633
Validation loss: 1.9978864410872101

Epoch: 5| Step: 6
Training loss: 1.2451952695846558
Validation loss: 1.996545414770803

Epoch: 5| Step: 7
Training loss: 1.391228437423706
Validation loss: 1.9892825336866482

Epoch: 5| Step: 8
Training loss: 1.9780008792877197
Validation loss: 1.993998271162792

Epoch: 5| Step: 9
Training loss: 1.826468825340271
Validation loss: 1.9859876530144804

Epoch: 5| Step: 10
Training loss: 0.8471120595932007
Validation loss: 1.9785257872714792

Epoch: 355| Step: 0
Training loss: 1.8439760208129883
Validation loss: 1.975231961537433

Epoch: 5| Step: 1
Training loss: 1.5804831981658936
Validation loss: 2.0212715774454098

Epoch: 5| Step: 2
Training loss: 1.3515996932983398
Validation loss: 2.014229505292831

Epoch: 5| Step: 3
Training loss: 1.2287027835845947
Validation loss: 2.0174684601445354

Epoch: 5| Step: 4
Training loss: 1.604243516921997
Validation loss: 2.019133529355449

Epoch: 5| Step: 5
Training loss: 1.9801489114761353
Validation loss: 2.0222296304600214

Epoch: 5| Step: 6
Training loss: 1.2614415884017944
Validation loss: 2.0111779346260974

Epoch: 5| Step: 7
Training loss: 1.6937297582626343
Validation loss: 1.9893965464766308

Epoch: 5| Step: 8
Training loss: 1.6966091394424438
Validation loss: 1.9711366802133539

Epoch: 5| Step: 9
Training loss: 1.5716588497161865
Validation loss: 1.959498228565339

Epoch: 5| Step: 10
Training loss: 1.1433513164520264
Validation loss: 1.9786065188787316

Epoch: 356| Step: 0
Training loss: 0.9924018979072571
Validation loss: 1.977301933432138

Epoch: 5| Step: 1
Training loss: 1.8786083459854126
Validation loss: 1.981655220831594

Epoch: 5| Step: 2
Training loss: 1.521537184715271
Validation loss: 1.9782475168986986

Epoch: 5| Step: 3
Training loss: 1.869678258895874
Validation loss: 1.9898681666261406

Epoch: 5| Step: 4
Training loss: 1.3786524534225464
Validation loss: 2.004783885453337

Epoch: 5| Step: 5
Training loss: 1.8383777141571045
Validation loss: 2.0200552837823027

Epoch: 5| Step: 6
Training loss: 1.1755096912384033
Validation loss: 2.01237573418566

Epoch: 5| Step: 7
Training loss: 1.4939265251159668
Validation loss: 1.9697201175074424

Epoch: 5| Step: 8
Training loss: 1.2597748041152954
Validation loss: 2.004493063496005

Epoch: 5| Step: 9
Training loss: 1.5543493032455444
Validation loss: 1.9569824677641674

Epoch: 5| Step: 10
Training loss: 2.1417076587677
Validation loss: 1.9643320422018729

Epoch: 357| Step: 0
Training loss: 1.3626744747161865
Validation loss: 1.9470981603027673

Epoch: 5| Step: 1
Training loss: 2.0238752365112305
Validation loss: 1.9510074251441545

Epoch: 5| Step: 2
Training loss: 1.1134881973266602
Validation loss: 1.972944890299151

Epoch: 5| Step: 3
Training loss: 1.7326349020004272
Validation loss: 1.9629064682991273

Epoch: 5| Step: 4
Training loss: 1.9509292840957642
Validation loss: 1.9711944364732312

Epoch: 5| Step: 5
Training loss: 1.4357969760894775
Validation loss: 1.9847170781063777

Epoch: 5| Step: 6
Training loss: 1.220096468925476
Validation loss: 1.9873875341107767

Epoch: 5| Step: 7
Training loss: 1.3522520065307617
Validation loss: 1.9818197552875807

Epoch: 5| Step: 8
Training loss: 1.366996169090271
Validation loss: 1.978520542062739

Epoch: 5| Step: 9
Training loss: 1.7382009029388428
Validation loss: 1.983988695247199

Epoch: 5| Step: 10
Training loss: 1.6942131519317627
Validation loss: 2.000875360222273

Epoch: 358| Step: 0
Training loss: 1.9054781198501587
Validation loss: 1.9881742974763275

Epoch: 5| Step: 1
Training loss: 2.0226082801818848
Validation loss: 1.9694487510188934

Epoch: 5| Step: 2
Training loss: 1.6987882852554321
Validation loss: 1.9692070586707002

Epoch: 5| Step: 3
Training loss: 1.847998023033142
Validation loss: 1.9816551105950468

Epoch: 5| Step: 4
Training loss: 1.3093266487121582
Validation loss: 1.9870156011273783

Epoch: 5| Step: 5
Training loss: 1.6005538702011108
Validation loss: 1.9765500894156836

Epoch: 5| Step: 6
Training loss: 1.053098440170288
Validation loss: 2.013747925399452

Epoch: 5| Step: 7
Training loss: 1.5063257217407227
Validation loss: 2.030797758410054

Epoch: 5| Step: 8
Training loss: 0.9436846971511841
Validation loss: 2.0450416726450764

Epoch: 5| Step: 9
Training loss: 1.4671833515167236
Validation loss: 2.0650378414379653

Epoch: 5| Step: 10
Training loss: 1.7320480346679688
Validation loss: 2.0681870419492006

Epoch: 359| Step: 0
Training loss: 1.5659465789794922
Validation loss: 1.9995039188733665

Epoch: 5| Step: 1
Training loss: 2.0227138996124268
Validation loss: 1.9925357244348014

Epoch: 5| Step: 2
Training loss: 1.679273247718811
Validation loss: 1.9568101847043602

Epoch: 5| Step: 3
Training loss: 1.3076425790786743
Validation loss: 1.9597698693634362

Epoch: 5| Step: 4
Training loss: 1.5976123809814453
Validation loss: 1.9753208468037267

Epoch: 5| Step: 5
Training loss: 1.6971683502197266
Validation loss: 1.9590976802251672

Epoch: 5| Step: 6
Training loss: 1.7401468753814697
Validation loss: 1.9626938450721003

Epoch: 5| Step: 7
Training loss: 1.6264026165008545
Validation loss: 1.9596951674389582

Epoch: 5| Step: 8
Training loss: 1.2635695934295654
Validation loss: 1.9701090499918947

Epoch: 5| Step: 9
Training loss: 1.2790635824203491
Validation loss: 2.0091532648250623

Epoch: 5| Step: 10
Training loss: 1.1275988817214966
Validation loss: 2.0237327365465063

Epoch: 360| Step: 0
Training loss: 1.2015498876571655
Validation loss: 2.0467658478726625

Epoch: 5| Step: 1
Training loss: 1.728628158569336
Validation loss: 2.0283001597209642

Epoch: 5| Step: 2
Training loss: 1.7240070104599
Validation loss: 2.0099873542785645

Epoch: 5| Step: 3
Training loss: 1.5771653652191162
Validation loss: 1.9910920153382003

Epoch: 5| Step: 4
Training loss: 1.3402668237686157
Validation loss: 1.9701449358335106

Epoch: 5| Step: 5
Training loss: 1.1426324844360352
Validation loss: 1.9579798047260573

Epoch: 5| Step: 6
Training loss: 2.165301561355591
Validation loss: 1.9601908012103009

Epoch: 5| Step: 7
Training loss: 1.168116569519043
Validation loss: 1.9757730384026804

Epoch: 5| Step: 8
Training loss: 1.0947797298431396
Validation loss: 1.9664218412932528

Epoch: 5| Step: 9
Training loss: 2.126370906829834
Validation loss: 1.9467756158562117

Epoch: 5| Step: 10
Training loss: 1.8393852710723877
Validation loss: 1.9732288686178063

Epoch: 361| Step: 0
Training loss: 0.958676815032959
Validation loss: 1.9870836914226573

Epoch: 5| Step: 1
Training loss: 1.285134196281433
Validation loss: 1.9858391284942627

Epoch: 5| Step: 2
Training loss: 1.9167770147323608
Validation loss: 2.0180668997508224

Epoch: 5| Step: 3
Training loss: 1.5756367444992065
Validation loss: 2.003721970383839

Epoch: 5| Step: 4
Training loss: 1.3087574243545532
Validation loss: 1.994404072402626

Epoch: 5| Step: 5
Training loss: 1.1508662700653076
Validation loss: 2.0045435197891726

Epoch: 5| Step: 6
Training loss: 1.3370075225830078
Validation loss: 2.0066721900816886

Epoch: 5| Step: 7
Training loss: 1.4225842952728271
Validation loss: 1.9907721755325154

Epoch: 5| Step: 8
Training loss: 1.7067039012908936
Validation loss: 1.9824049972718762

Epoch: 5| Step: 9
Training loss: 2.3357315063476562
Validation loss: 1.9908097290223645

Epoch: 5| Step: 10
Training loss: 1.7200243473052979
Validation loss: 1.9865219528957079

Epoch: 362| Step: 0
Training loss: 1.3018382787704468
Validation loss: 1.9755533203001945

Epoch: 5| Step: 1
Training loss: 1.6000906229019165
Validation loss: 1.9770706674104095

Epoch: 5| Step: 2
Training loss: 1.170785665512085
Validation loss: 1.9553655719244352

Epoch: 5| Step: 3
Training loss: 1.0684106349945068
Validation loss: 1.9817004434524044

Epoch: 5| Step: 4
Training loss: 1.0099265575408936
Validation loss: 1.9747104016683434

Epoch: 5| Step: 5
Training loss: 1.8280823230743408
Validation loss: 1.9955728156592256

Epoch: 5| Step: 6
Training loss: 2.210749387741089
Validation loss: 1.9877957092818392

Epoch: 5| Step: 7
Training loss: 1.9395334720611572
Validation loss: 1.9998721230414607

Epoch: 5| Step: 8
Training loss: 1.6795345544815063
Validation loss: 2.001308278370929

Epoch: 5| Step: 9
Training loss: 1.6855261325836182
Validation loss: 1.9725298907167168

Epoch: 5| Step: 10
Training loss: 0.9864796996116638
Validation loss: 1.9575453176293323

Epoch: 363| Step: 0
Training loss: 1.8087351322174072
Validation loss: 1.970886465041868

Epoch: 5| Step: 1
Training loss: 1.829882264137268
Validation loss: 1.9766875979720906

Epoch: 5| Step: 2
Training loss: 1.106637716293335
Validation loss: 1.9678486585617065

Epoch: 5| Step: 3
Training loss: 1.7383201122283936
Validation loss: 1.977243887480869

Epoch: 5| Step: 4
Training loss: 1.227447271347046
Validation loss: 2.0108846567010366

Epoch: 5| Step: 5
Training loss: 1.515927791595459
Validation loss: 1.9953425661210091

Epoch: 5| Step: 6
Training loss: 2.0392696857452393
Validation loss: 2.011451013626591

Epoch: 5| Step: 7
Training loss: 1.3639382123947144
Validation loss: 2.0008876400609172

Epoch: 5| Step: 8
Training loss: 1.565377950668335
Validation loss: 1.999911517225286

Epoch: 5| Step: 9
Training loss: 1.0547387599945068
Validation loss: 1.969578701962707

Epoch: 5| Step: 10
Training loss: 1.2604143619537354
Validation loss: 1.968530652343586

Epoch: 364| Step: 0
Training loss: 1.3061492443084717
Validation loss: 1.9620845369113389

Epoch: 5| Step: 1
Training loss: 1.323049545288086
Validation loss: 1.969954131751932

Epoch: 5| Step: 2
Training loss: 0.9767107963562012
Validation loss: 1.9674640470935452

Epoch: 5| Step: 3
Training loss: 1.8845916986465454
Validation loss: 1.9807240116980769

Epoch: 5| Step: 4
Training loss: 2.4439918994903564
Validation loss: 1.9850280348972609

Epoch: 5| Step: 5
Training loss: 1.8610641956329346
Validation loss: 2.021717386861001

Epoch: 5| Step: 6
Training loss: 1.2545559406280518
Validation loss: 1.9928805366639168

Epoch: 5| Step: 7
Training loss: 1.5216234922409058
Validation loss: 1.9777182455985778

Epoch: 5| Step: 8
Training loss: 1.2879000902175903
Validation loss: 1.978339777197889

Epoch: 5| Step: 9
Training loss: 1.4018762111663818
Validation loss: 1.9743592328922723

Epoch: 5| Step: 10
Training loss: 1.3750571012496948
Validation loss: 1.9697303592517812

Epoch: 365| Step: 0
Training loss: 1.081829309463501
Validation loss: 1.9744685952381422

Epoch: 5| Step: 1
Training loss: 1.5566879510879517
Validation loss: 1.9688171417482438

Epoch: 5| Step: 2
Training loss: 1.4815163612365723
Validation loss: 1.9990839830008886

Epoch: 5| Step: 3
Training loss: 1.7663971185684204
Validation loss: 1.98800398970163

Epoch: 5| Step: 4
Training loss: 1.375659704208374
Validation loss: 1.9710280869596748

Epoch: 5| Step: 5
Training loss: 1.8616416454315186
Validation loss: 1.966161568959554

Epoch: 5| Step: 6
Training loss: 1.2528526782989502
Validation loss: 1.9728605593404462

Epoch: 5| Step: 7
Training loss: 1.9120349884033203
Validation loss: 1.9610439590228501

Epoch: 5| Step: 8
Training loss: 1.5685720443725586
Validation loss: 1.9910767783400833

Epoch: 5| Step: 9
Training loss: 1.3715416193008423
Validation loss: 2.0294731483664563

Epoch: 5| Step: 10
Training loss: 1.243972897529602
Validation loss: 1.9965770706053703

Epoch: 366| Step: 0
Training loss: 1.6000629663467407
Validation loss: 1.9811010770900275

Epoch: 5| Step: 1
Training loss: 1.7621303796768188
Validation loss: 1.9689438855776222

Epoch: 5| Step: 2
Training loss: 1.9447009563446045
Validation loss: 1.9702180483007943

Epoch: 5| Step: 3
Training loss: 1.4311301708221436
Validation loss: 1.9551741359054402

Epoch: 5| Step: 4
Training loss: 1.64628005027771
Validation loss: 1.9689605082235029

Epoch: 5| Step: 5
Training loss: 1.5737402439117432
Validation loss: 1.9841659812517063

Epoch: 5| Step: 6
Training loss: 0.8989322781562805
Validation loss: 2.0178985108611402

Epoch: 5| Step: 7
Training loss: 1.22552490234375
Validation loss: 2.0495820660744943

Epoch: 5| Step: 8
Training loss: 1.5782707929611206
Validation loss: 2.0993342271415134

Epoch: 5| Step: 9
Training loss: 1.504127860069275
Validation loss: 2.0775226546872045

Epoch: 5| Step: 10
Training loss: 1.5317649841308594
Validation loss: 2.0226026581179712

Epoch: 367| Step: 0
Training loss: 1.7270227670669556
Validation loss: 2.010004715252948

Epoch: 5| Step: 1
Training loss: 1.5644868612289429
Validation loss: 1.9789906278733285

Epoch: 5| Step: 2
Training loss: 1.7077049016952515
Validation loss: 1.9735173563803396

Epoch: 5| Step: 3
Training loss: 1.5047080516815186
Validation loss: 1.999045007972307

Epoch: 5| Step: 4
Training loss: 1.955320954322815
Validation loss: 1.992549750112718

Epoch: 5| Step: 5
Training loss: 2.111257553100586
Validation loss: 1.9640723607873405

Epoch: 5| Step: 6
Training loss: 1.5680986642837524
Validation loss: 1.9388942244232341

Epoch: 5| Step: 7
Training loss: 1.1832760572433472
Validation loss: 1.9336133374962756

Epoch: 5| Step: 8
Training loss: 1.528564214706421
Validation loss: 1.9456375363052532

Epoch: 5| Step: 9
Training loss: 1.1755177974700928
Validation loss: 1.966642742515892

Epoch: 5| Step: 10
Training loss: 1.1575329303741455
Validation loss: 1.958228265085528

Epoch: 368| Step: 0
Training loss: 1.3476121425628662
Validation loss: 1.9421862376633512

Epoch: 5| Step: 1
Training loss: 1.5814735889434814
Validation loss: 1.9379154777014127

Epoch: 5| Step: 2
Training loss: 2.196660280227661
Validation loss: 1.9513276956414665

Epoch: 5| Step: 3
Training loss: 1.3102055788040161
Validation loss: 1.9379558601687032

Epoch: 5| Step: 4
Training loss: 1.2077935934066772
Validation loss: 1.955533605749889

Epoch: 5| Step: 5
Training loss: 1.296226143836975
Validation loss: 1.9442228040387552

Epoch: 5| Step: 6
Training loss: 1.5195242166519165
Validation loss: 1.9382014377142793

Epoch: 5| Step: 7
Training loss: 1.1895606517791748
Validation loss: 1.9723122530086066

Epoch: 5| Step: 8
Training loss: 1.4898773431777954
Validation loss: 1.9515879179841729

Epoch: 5| Step: 9
Training loss: 1.4570711851119995
Validation loss: 1.9653315300582557

Epoch: 5| Step: 10
Training loss: 1.951225757598877
Validation loss: 1.9572646656344015

Epoch: 369| Step: 0
Training loss: 1.728795051574707
Validation loss: 1.9762119093248922

Epoch: 5| Step: 1
Training loss: 1.7956397533416748
Validation loss: 1.9899635584123674

Epoch: 5| Step: 2
Training loss: 1.830100655555725
Validation loss: 1.9859852201195174

Epoch: 5| Step: 3
Training loss: 0.7923566699028015
Validation loss: 2.000190137535013

Epoch: 5| Step: 4
Training loss: 1.5065382719039917
Validation loss: 2.0056611671242663

Epoch: 5| Step: 5
Training loss: 1.6254422664642334
Validation loss: 1.9883701006571453

Epoch: 5| Step: 6
Training loss: 1.1665672063827515
Validation loss: 2.013497096236034

Epoch: 5| Step: 7
Training loss: 1.5668985843658447
Validation loss: 2.012087639941964

Epoch: 5| Step: 8
Training loss: 1.9749778509140015
Validation loss: 2.0185524955872567

Epoch: 5| Step: 9
Training loss: 1.585077166557312
Validation loss: 1.9660752473338958

Epoch: 5| Step: 10
Training loss: 0.826880931854248
Validation loss: 1.9559885788989324

Epoch: 370| Step: 0
Training loss: 1.4330333471298218
Validation loss: 1.9446237984523977

Epoch: 5| Step: 1
Training loss: 1.984250783920288
Validation loss: 1.9556019242091844

Epoch: 5| Step: 2
Training loss: 1.528564453125
Validation loss: 1.947279832696402

Epoch: 5| Step: 3
Training loss: 1.6072742938995361
Validation loss: 1.9551779493208854

Epoch: 5| Step: 4
Training loss: 1.6228764057159424
Validation loss: 1.98161934139908

Epoch: 5| Step: 5
Training loss: 1.2586829662322998
Validation loss: 1.9834474594362321

Epoch: 5| Step: 6
Training loss: 0.7579809427261353
Validation loss: 1.995887762756758

Epoch: 5| Step: 7
Training loss: 2.0139284133911133
Validation loss: 2.0106081142220447

Epoch: 5| Step: 8
Training loss: 1.519579529762268
Validation loss: 2.014614890980464

Epoch: 5| Step: 9
Training loss: 1.2224535942077637
Validation loss: 2.024229936702277

Epoch: 5| Step: 10
Training loss: 1.7815933227539062
Validation loss: 1.996332622343494

Epoch: 371| Step: 0
Training loss: 1.1229783296585083
Validation loss: 1.9908239328733055

Epoch: 5| Step: 1
Training loss: 1.235667109489441
Validation loss: 1.960649799275142

Epoch: 5| Step: 2
Training loss: 1.7517194747924805
Validation loss: 1.9804992829599688

Epoch: 5| Step: 3
Training loss: 1.3926210403442383
Validation loss: 1.9920555724892566

Epoch: 5| Step: 4
Training loss: 1.8541486263275146
Validation loss: 1.983585839630455

Epoch: 5| Step: 5
Training loss: 1.5390821695327759
Validation loss: 1.962111888393279

Epoch: 5| Step: 6
Training loss: 1.9684059619903564
Validation loss: 1.9433018648496239

Epoch: 5| Step: 7
Training loss: 1.5404279232025146
Validation loss: 1.9526343576369747

Epoch: 5| Step: 8
Training loss: 1.6310904026031494
Validation loss: 1.9838745696570284

Epoch: 5| Step: 9
Training loss: 1.4672905206680298
Validation loss: 2.020833738388554

Epoch: 5| Step: 10
Training loss: 1.2213727235794067
Validation loss: 2.0189616372508388

Epoch: 372| Step: 0
Training loss: 1.040893793106079
Validation loss: 2.025291568489485

Epoch: 5| Step: 1
Training loss: 1.5602569580078125
Validation loss: 2.0313846500970985

Epoch: 5| Step: 2
Training loss: 2.103529214859009
Validation loss: 2.0069605560712915

Epoch: 5| Step: 3
Training loss: 1.6208412647247314
Validation loss: 1.9676893141961866

Epoch: 5| Step: 4
Training loss: 2.573026657104492
Validation loss: 1.953310989564465

Epoch: 5| Step: 5
Training loss: 1.5248053073883057
Validation loss: 1.9362850625027892

Epoch: 5| Step: 6
Training loss: 1.0809485912322998
Validation loss: 1.9276272814760926

Epoch: 5| Step: 7
Training loss: 1.095848798751831
Validation loss: 1.9428292910257976

Epoch: 5| Step: 8
Training loss: 1.6190112829208374
Validation loss: 1.9639000508093065

Epoch: 5| Step: 9
Training loss: 0.8481277227401733
Validation loss: 1.9696812270790018

Epoch: 5| Step: 10
Training loss: 1.4732341766357422
Validation loss: 1.9535496773258332

Epoch: 373| Step: 0
Training loss: 1.558119535446167
Validation loss: 1.972517749314667

Epoch: 5| Step: 1
Training loss: 2.4429612159729004
Validation loss: 2.0081994879630303

Epoch: 5| Step: 2
Training loss: 1.1034396886825562
Validation loss: 2.040973658202797

Epoch: 5| Step: 3
Training loss: 0.812227725982666
Validation loss: 2.036258800055391

Epoch: 5| Step: 4
Training loss: 1.13532555103302
Validation loss: 1.977745109988797

Epoch: 5| Step: 5
Training loss: 1.6965281963348389
Validation loss: 1.9473053575843893

Epoch: 5| Step: 6
Training loss: 1.3957393169403076
Validation loss: 1.9251759513731925

Epoch: 5| Step: 7
Training loss: 2.014464855194092
Validation loss: 1.9405869976166756

Epoch: 5| Step: 8
Training loss: 1.2768117189407349
Validation loss: 1.9379378416204964

Epoch: 5| Step: 9
Training loss: 1.6450424194335938
Validation loss: 1.9362709124883015

Epoch: 5| Step: 10
Training loss: 1.287879228591919
Validation loss: 1.9210761042051419

Epoch: 374| Step: 0
Training loss: 1.7519776821136475
Validation loss: 1.9208914400428854

Epoch: 5| Step: 1
Training loss: 1.6312000751495361
Validation loss: 1.9246835439435896

Epoch: 5| Step: 2
Training loss: 1.7243629693984985
Validation loss: 1.9333870244282547

Epoch: 5| Step: 3
Training loss: 1.4183087348937988
Validation loss: 1.950396494198871

Epoch: 5| Step: 4
Training loss: 2.286165714263916
Validation loss: 1.96478331986294

Epoch: 5| Step: 5
Training loss: 1.3974382877349854
Validation loss: 1.9399077046302058

Epoch: 5| Step: 6
Training loss: 1.4545156955718994
Validation loss: 1.9361792302900744

Epoch: 5| Step: 7
Training loss: 0.9595016241073608
Validation loss: 1.9209141538989158

Epoch: 5| Step: 8
Training loss: 1.0943076610565186
Validation loss: 1.9324763000652354

Epoch: 5| Step: 9
Training loss: 1.339671015739441
Validation loss: 1.933310028045408

Epoch: 5| Step: 10
Training loss: 1.3355848789215088
Validation loss: 1.9631456764795447

Epoch: 375| Step: 0
Training loss: 1.550652265548706
Validation loss: 1.9656154365949734

Epoch: 5| Step: 1
Training loss: 1.146153211593628
Validation loss: 1.9561909667907222

Epoch: 5| Step: 2
Training loss: 1.7726538181304932
Validation loss: 1.9867974378729378

Epoch: 5| Step: 3
Training loss: 1.4238381385803223
Validation loss: 1.9989130548251572

Epoch: 5| Step: 4
Training loss: 1.6705875396728516
Validation loss: 2.008780594794981

Epoch: 5| Step: 5
Training loss: 0.8866375088691711
Validation loss: 2.009741847233106

Epoch: 5| Step: 6
Training loss: 1.6800813674926758
Validation loss: 2.009755967765726

Epoch: 5| Step: 7
Training loss: 1.5727484226226807
Validation loss: 1.9827119637561101

Epoch: 5| Step: 8
Training loss: 1.5503146648406982
Validation loss: 1.9725103173204648

Epoch: 5| Step: 9
Training loss: 1.3428500890731812
Validation loss: 1.9556102624503515

Epoch: 5| Step: 10
Training loss: 1.6970341205596924
Validation loss: 1.9412342092042327

Epoch: 376| Step: 0
Training loss: 1.297906756401062
Validation loss: 1.9434596069397465

Epoch: 5| Step: 1
Training loss: 1.2914758920669556
Validation loss: 1.9611996925005348

Epoch: 5| Step: 2
Training loss: 1.3127400875091553
Validation loss: 1.9414004510448826

Epoch: 5| Step: 3
Training loss: 1.6165701150894165
Validation loss: 1.9560841860309723

Epoch: 5| Step: 4
Training loss: 1.1072436571121216
Validation loss: 1.954861182038502

Epoch: 5| Step: 5
Training loss: 2.019350528717041
Validation loss: 1.9513848045820832

Epoch: 5| Step: 6
Training loss: 1.543704628944397
Validation loss: 1.937023203860047

Epoch: 5| Step: 7
Training loss: 1.4900615215301514
Validation loss: 1.936626531744516

Epoch: 5| Step: 8
Training loss: 1.3513506650924683
Validation loss: 1.9554831622749247

Epoch: 5| Step: 9
Training loss: 1.5874643325805664
Validation loss: 1.954375946393577

Epoch: 5| Step: 10
Training loss: 1.5401781797409058
Validation loss: 1.9481481441887476

Epoch: 377| Step: 0
Training loss: 1.6632131338119507
Validation loss: 1.9550667039809688

Epoch: 5| Step: 1
Training loss: 1.5698362588882446
Validation loss: 1.9477151414399505

Epoch: 5| Step: 2
Training loss: 1.082063913345337
Validation loss: 1.912098958928098

Epoch: 5| Step: 3
Training loss: 1.471620798110962
Validation loss: 1.9527399693765948

Epoch: 5| Step: 4
Training loss: 1.6301839351654053
Validation loss: 1.9494564417869813

Epoch: 5| Step: 5
Training loss: 1.4137448072433472
Validation loss: 1.9492274433053949

Epoch: 5| Step: 6
Training loss: 1.8651645183563232
Validation loss: 1.9632832004177956

Epoch: 5| Step: 7
Training loss: 1.3706225156784058
Validation loss: 1.9463144758696198

Epoch: 5| Step: 8
Training loss: 1.622423529624939
Validation loss: 1.9382864967469247

Epoch: 5| Step: 9
Training loss: 1.5685381889343262
Validation loss: 1.9565566150091027

Epoch: 5| Step: 10
Training loss: 0.6378684043884277
Validation loss: 1.9578311340783232

Epoch: 378| Step: 0
Training loss: 1.5594542026519775
Validation loss: 1.9642823011644426

Epoch: 5| Step: 1
Training loss: 2.1048779487609863
Validation loss: 1.9394867676560597

Epoch: 5| Step: 2
Training loss: 1.3017394542694092
Validation loss: 1.9239818011560748

Epoch: 5| Step: 3
Training loss: 1.0950452089309692
Validation loss: 1.9453514378557923

Epoch: 5| Step: 4
Training loss: 0.9398424029350281
Validation loss: 1.9594886815676125

Epoch: 5| Step: 5
Training loss: 1.6251189708709717
Validation loss: 1.9636248439870856

Epoch: 5| Step: 6
Training loss: 1.241556167602539
Validation loss: 1.9538709860976025

Epoch: 5| Step: 7
Training loss: 2.1704819202423096
Validation loss: 1.9707086560546712

Epoch: 5| Step: 8
Training loss: 1.5162203311920166
Validation loss: 1.9598124463071105

Epoch: 5| Step: 9
Training loss: 1.0505726337432861
Validation loss: 1.9588142415528655

Epoch: 5| Step: 10
Training loss: 0.9761665463447571
Validation loss: 1.9610192224543581

Epoch: 379| Step: 0
Training loss: 1.2779260873794556
Validation loss: 1.945761170438541

Epoch: 5| Step: 1
Training loss: 0.9519916772842407
Validation loss: 1.9380684027107813

Epoch: 5| Step: 2
Training loss: 1.6567890644073486
Validation loss: 1.9537020332069808

Epoch: 5| Step: 3
Training loss: 1.8461719751358032
Validation loss: 1.9350567658742268

Epoch: 5| Step: 4
Training loss: 1.3062597513198853
Validation loss: 1.93398271324814

Epoch: 5| Step: 5
Training loss: 1.3289310932159424
Validation loss: 1.9341046707604521

Epoch: 5| Step: 6
Training loss: 1.4497185945510864
Validation loss: 1.9487941803470734

Epoch: 5| Step: 7
Training loss: 1.3447635173797607
Validation loss: 1.9331225784876014

Epoch: 5| Step: 8
Training loss: 2.1686789989471436
Validation loss: 1.9379407257162116

Epoch: 5| Step: 9
Training loss: 1.3592023849487305
Validation loss: 1.9468265412956156

Epoch: 5| Step: 10
Training loss: 1.098753809928894
Validation loss: 1.9625935733959239

Epoch: 380| Step: 0
Training loss: 1.0323781967163086
Validation loss: 1.962000669971589

Epoch: 5| Step: 1
Training loss: 1.6800251007080078
Validation loss: 2.010908844650433

Epoch: 5| Step: 2
Training loss: 1.1590261459350586
Validation loss: 1.9506097660269788

Epoch: 5| Step: 3
Training loss: 2.0277137756347656
Validation loss: 1.9615737597147624

Epoch: 5| Step: 4
Training loss: 1.6272979974746704
Validation loss: 1.9691324618554884

Epoch: 5| Step: 5
Training loss: 1.2687480449676514
Validation loss: 1.9653240365366782

Epoch: 5| Step: 6
Training loss: 1.0963609218597412
Validation loss: 1.9790728989467825

Epoch: 5| Step: 7
Training loss: 1.4843169450759888
Validation loss: 1.9746573163617043

Epoch: 5| Step: 8
Training loss: 1.1502975225448608
Validation loss: 1.9722985042038785

Epoch: 5| Step: 9
Training loss: 1.374802589416504
Validation loss: 1.9635531786949403

Epoch: 5| Step: 10
Training loss: 1.924739122390747
Validation loss: 1.9414290317925074

Epoch: 381| Step: 0
Training loss: 1.495619773864746
Validation loss: 1.9306853714809622

Epoch: 5| Step: 1
Training loss: 1.2868820428848267
Validation loss: 1.9483784629452614

Epoch: 5| Step: 2
Training loss: 1.2218788862228394
Validation loss: 1.9169723756851689

Epoch: 5| Step: 3
Training loss: 0.5915447473526001
Validation loss: 1.9398368225302747

Epoch: 5| Step: 4
Training loss: 1.5763390064239502
Validation loss: 1.9168607278536725

Epoch: 5| Step: 5
Training loss: 1.7256193161010742
Validation loss: 1.9308148840422272

Epoch: 5| Step: 6
Training loss: 1.2861807346343994
Validation loss: 1.9047492242628528

Epoch: 5| Step: 7
Training loss: 1.6901733875274658
Validation loss: 1.9254586850443194

Epoch: 5| Step: 8
Training loss: 1.6181681156158447
Validation loss: 1.8919338564718924

Epoch: 5| Step: 9
Training loss: 2.1614253520965576
Validation loss: 1.889980525098821

Epoch: 5| Step: 10
Training loss: 1.175976276397705
Validation loss: 1.9062243930755123

Epoch: 382| Step: 0
Training loss: 1.5041697025299072
Validation loss: 1.9125560945080173

Epoch: 5| Step: 1
Training loss: 1.5128532648086548
Validation loss: 1.9350079721020115

Epoch: 5| Step: 2
Training loss: 1.639884352684021
Validation loss: 1.9497921748827862

Epoch: 5| Step: 3
Training loss: 1.1318351030349731
Validation loss: 1.9413626450364307

Epoch: 5| Step: 4
Training loss: 1.4919129610061646
Validation loss: 1.9679346071776522

Epoch: 5| Step: 5
Training loss: 1.1350324153900146
Validation loss: 1.9913732582522976

Epoch: 5| Step: 6
Training loss: 1.9852176904678345
Validation loss: 2.0149289433674147

Epoch: 5| Step: 7
Training loss: 1.1543619632720947
Validation loss: 2.052808646232851

Epoch: 5| Step: 8
Training loss: 1.5961612462997437
Validation loss: 2.007437998248685

Epoch: 5| Step: 9
Training loss: 1.573413610458374
Validation loss: 1.961185214340046

Epoch: 5| Step: 10
Training loss: 1.1953535079956055
Validation loss: 1.9660374990073584

Epoch: 383| Step: 0
Training loss: 2.0191147327423096
Validation loss: 1.955799820602581

Epoch: 5| Step: 1
Training loss: 1.2959578037261963
Validation loss: 1.948871293375569

Epoch: 5| Step: 2
Training loss: 1.533289909362793
Validation loss: 1.9352921555119176

Epoch: 5| Step: 3
Training loss: 1.907961130142212
Validation loss: 1.9365778341088244

Epoch: 5| Step: 4
Training loss: 1.5737216472625732
Validation loss: 1.9186951780831942

Epoch: 5| Step: 5
Training loss: 1.2403528690338135
Validation loss: 1.9139396503407469

Epoch: 5| Step: 6
Training loss: 0.9186215400695801
Validation loss: 1.9229013432738602

Epoch: 5| Step: 7
Training loss: 1.100894570350647
Validation loss: 1.9594927692926059

Epoch: 5| Step: 8
Training loss: 1.9347398281097412
Validation loss: 1.9906349053946875

Epoch: 5| Step: 9
Training loss: 0.9615980982780457
Validation loss: 1.9988335960654802

Epoch: 5| Step: 10
Training loss: 1.454166293144226
Validation loss: 2.023453982927466

Epoch: 384| Step: 0
Training loss: 1.8674453496932983
Validation loss: 2.010212372708064

Epoch: 5| Step: 1
Training loss: 1.7682297229766846
Validation loss: 2.0005461733828307

Epoch: 5| Step: 2
Training loss: 1.9124456644058228
Validation loss: 1.9620136317386423

Epoch: 5| Step: 3
Training loss: 1.4225813150405884
Validation loss: 1.963305764300849

Epoch: 5| Step: 4
Training loss: 1.3419958353042603
Validation loss: 1.9411206040331113

Epoch: 5| Step: 5
Training loss: 0.944240927696228
Validation loss: 1.9586837035353466

Epoch: 5| Step: 6
Training loss: 1.5567208528518677
Validation loss: 1.934681705249253

Epoch: 5| Step: 7
Training loss: 1.3723498582839966
Validation loss: 1.9308464962949035

Epoch: 5| Step: 8
Training loss: 1.6049139499664307
Validation loss: 1.9466066078473163

Epoch: 5| Step: 9
Training loss: 1.1588634252548218
Validation loss: 1.9507266462490123

Epoch: 5| Step: 10
Training loss: 0.8990272879600525
Validation loss: 1.9876131806322324

Epoch: 385| Step: 0
Training loss: 1.328931450843811
Validation loss: 1.9690361945859847

Epoch: 5| Step: 1
Training loss: 1.684451699256897
Validation loss: 1.983359044597995

Epoch: 5| Step: 2
Training loss: 1.5797226428985596
Validation loss: 1.9480142580565585

Epoch: 5| Step: 3
Training loss: 1.6609179973602295
Validation loss: 1.9558097675282469

Epoch: 5| Step: 4
Training loss: 1.1551262140274048
Validation loss: 1.9248833399946972

Epoch: 5| Step: 5
Training loss: 1.080357551574707
Validation loss: 1.9370800500274987

Epoch: 5| Step: 6
Training loss: 1.9020344018936157
Validation loss: 1.9463595767174997

Epoch: 5| Step: 7
Training loss: 1.5376102924346924
Validation loss: 1.934340751299294

Epoch: 5| Step: 8
Training loss: 1.6329084634780884
Validation loss: 1.9509635830438266

Epoch: 5| Step: 9
Training loss: 0.9838827252388
Validation loss: 1.92830886379365

Epoch: 5| Step: 10
Training loss: 1.390153408050537
Validation loss: 1.933813330947712

Epoch: 386| Step: 0
Training loss: 1.4832185506820679
Validation loss: 1.9386639364304081

Epoch: 5| Step: 1
Training loss: 1.0612202882766724
Validation loss: 1.9488045323279597

Epoch: 5| Step: 2
Training loss: 1.3331964015960693
Validation loss: 1.9784207010781893

Epoch: 5| Step: 3
Training loss: 1.5211951732635498
Validation loss: 1.9562832386262956

Epoch: 5| Step: 4
Training loss: 1.433633804321289
Validation loss: 1.9348086733971872

Epoch: 5| Step: 5
Training loss: 0.7123042345046997
Validation loss: 1.9310999429354103

Epoch: 5| Step: 6
Training loss: 1.1589210033416748
Validation loss: 1.9090779314758957

Epoch: 5| Step: 7
Training loss: 1.9955825805664062
Validation loss: 1.9245159856734737

Epoch: 5| Step: 8
Training loss: 1.576758623123169
Validation loss: 1.931087229841499

Epoch: 5| Step: 9
Training loss: 1.3909857273101807
Validation loss: 1.9421585849536362

Epoch: 5| Step: 10
Training loss: 1.9391382932662964
Validation loss: 1.9670663674672444

Epoch: 387| Step: 0
Training loss: 1.0161136388778687
Validation loss: 1.9537406070258028

Epoch: 5| Step: 1
Training loss: 1.5289287567138672
Validation loss: 1.941614443256009

Epoch: 5| Step: 2
Training loss: 1.7127830982208252
Validation loss: 1.9403412124162078

Epoch: 5| Step: 3
Training loss: 1.3890997171401978
Validation loss: 1.9200197496721823

Epoch: 5| Step: 4
Training loss: 1.161349892616272
Validation loss: 1.905782829048813

Epoch: 5| Step: 5
Training loss: 1.2866899967193604
Validation loss: 1.919248451468765

Epoch: 5| Step: 6
Training loss: 1.1602219343185425
Validation loss: 1.9201425608768259

Epoch: 5| Step: 7
Training loss: 1.3078253269195557
Validation loss: 1.9253753654418453

Epoch: 5| Step: 8
Training loss: 2.029082775115967
Validation loss: 1.9315875743025093

Epoch: 5| Step: 9
Training loss: 1.6865688562393188
Validation loss: 1.9094834712243849

Epoch: 5| Step: 10
Training loss: 1.6977241039276123
Validation loss: 1.9283583394942745

Epoch: 388| Step: 0
Training loss: 1.563042402267456
Validation loss: 1.9682005156752884

Epoch: 5| Step: 1
Training loss: 1.0639039278030396
Validation loss: 1.974905389611439

Epoch: 5| Step: 2
Training loss: 1.5554370880126953
Validation loss: 2.0268397767056703

Epoch: 5| Step: 3
Training loss: 1.7344844341278076
Validation loss: 2.0233280735631145

Epoch: 5| Step: 4
Training loss: 1.0820269584655762
Validation loss: 1.992780117578404

Epoch: 5| Step: 5
Training loss: 1.307442307472229
Validation loss: 1.966493598876461

Epoch: 5| Step: 6
Training loss: 1.8840481042861938
Validation loss: 1.9848053070806688

Epoch: 5| Step: 7
Training loss: 0.8902952075004578
Validation loss: 1.9581407449578727

Epoch: 5| Step: 8
Training loss: 1.9239723682403564
Validation loss: 1.9643065929412842

Epoch: 5| Step: 9
Training loss: 1.6931085586547852
Validation loss: 1.920544844801708

Epoch: 5| Step: 10
Training loss: 1.1226472854614258
Validation loss: 1.897288030193698

Epoch: 389| Step: 0
Training loss: 0.9413105249404907
Validation loss: 1.8931187532281364

Epoch: 5| Step: 1
Training loss: 1.848427414894104
Validation loss: 1.9133446678038566

Epoch: 5| Step: 2
Training loss: 1.4592006206512451
Validation loss: 1.9437209124206214

Epoch: 5| Step: 3
Training loss: 0.9960079193115234
Validation loss: 1.9335138156849851

Epoch: 5| Step: 4
Training loss: 1.3291733264923096
Validation loss: 1.943372231657787

Epoch: 5| Step: 5
Training loss: 1.4103734493255615
Validation loss: 1.9479116509037633

Epoch: 5| Step: 6
Training loss: 1.8184468746185303
Validation loss: 1.9483560054532942

Epoch: 5| Step: 7
Training loss: 1.8944694995880127
Validation loss: 1.9694124665311588

Epoch: 5| Step: 8
Training loss: 1.452376127243042
Validation loss: 1.9595830914794758

Epoch: 5| Step: 9
Training loss: 1.6014314889907837
Validation loss: 1.9617962837219238

Epoch: 5| Step: 10
Training loss: 0.843045711517334
Validation loss: 1.9550225106618737

Epoch: 390| Step: 0
Training loss: 1.460909128189087
Validation loss: 1.955462686477169

Epoch: 5| Step: 1
Training loss: 1.1290159225463867
Validation loss: 1.9294954884436823

Epoch: 5| Step: 2
Training loss: 1.612370252609253
Validation loss: 1.9865776018429828

Epoch: 5| Step: 3
Training loss: 1.1072808504104614
Validation loss: 1.9875235634465371

Epoch: 5| Step: 4
Training loss: 1.894832968711853
Validation loss: 1.9903285426478232

Epoch: 5| Step: 5
Training loss: 1.077652096748352
Validation loss: 2.0048095769779657

Epoch: 5| Step: 6
Training loss: 1.5702743530273438
Validation loss: 1.9971274022133119

Epoch: 5| Step: 7
Training loss: 1.774587631225586
Validation loss: 1.9368682984382875

Epoch: 5| Step: 8
Training loss: 1.4860624074935913
Validation loss: 1.916116347876928

Epoch: 5| Step: 9
Training loss: 1.429465889930725
Validation loss: 1.8997282366598807

Epoch: 5| Step: 10
Training loss: 1.2101213932037354
Validation loss: 1.89785986433747

Epoch: 391| Step: 0
Training loss: 1.1941041946411133
Validation loss: 1.896465273313625

Epoch: 5| Step: 1
Training loss: 1.5184986591339111
Validation loss: 1.9009790971714964

Epoch: 5| Step: 2
Training loss: 1.0521266460418701
Validation loss: 1.9188716078317294

Epoch: 5| Step: 3
Training loss: 2.022822856903076
Validation loss: 1.926657256259713

Epoch: 5| Step: 4
Training loss: 1.4702810049057007
Validation loss: 1.9222506528259606

Epoch: 5| Step: 5
Training loss: 1.3456881046295166
Validation loss: 1.944326323847617

Epoch: 5| Step: 6
Training loss: 1.0595190525054932
Validation loss: 1.9613746596920876

Epoch: 5| Step: 7
Training loss: 1.6091639995574951
Validation loss: 1.9871284525881532

Epoch: 5| Step: 8
Training loss: 1.3776495456695557
Validation loss: 1.9857630614311463

Epoch: 5| Step: 9
Training loss: 1.5728788375854492
Validation loss: 1.967285817669284

Epoch: 5| Step: 10
Training loss: 1.6528066396713257
Validation loss: 1.9827873373544345

Epoch: 392| Step: 0
Training loss: 1.3093681335449219
Validation loss: 1.9762832759529032

Epoch: 5| Step: 1
Training loss: 1.480175256729126
Validation loss: 1.9708267578514673

Epoch: 5| Step: 2
Training loss: 1.3114596605300903
Validation loss: 1.9612611493756693

Epoch: 5| Step: 3
Training loss: 1.9169809818267822
Validation loss: 1.957960449239259

Epoch: 5| Step: 4
Training loss: 1.5442253351211548
Validation loss: 1.9732600206969886

Epoch: 5| Step: 5
Training loss: 1.7550519704818726
Validation loss: 1.9451346115399433

Epoch: 5| Step: 6
Training loss: 0.7908161282539368
Validation loss: 1.9410217346683625

Epoch: 5| Step: 7
Training loss: 1.6158649921417236
Validation loss: 1.9294053610935007

Epoch: 5| Step: 8
Training loss: 0.9965046048164368
Validation loss: 1.8937661852887882

Epoch: 5| Step: 9
Training loss: 1.3635956048965454
Validation loss: 1.9138683106309624

Epoch: 5| Step: 10
Training loss: 1.2890790700912476
Validation loss: 1.9533263098809026

Epoch: 393| Step: 0
Training loss: 1.5862436294555664
Validation loss: 2.001783932408979

Epoch: 5| Step: 1
Training loss: 1.208911657333374
Validation loss: 2.022290846352936

Epoch: 5| Step: 2
Training loss: 1.4852367639541626
Validation loss: 1.9839635177325177

Epoch: 5| Step: 3
Training loss: 1.643236756324768
Validation loss: 1.9457686844692434

Epoch: 5| Step: 4
Training loss: 1.2792494297027588
Validation loss: 1.919495060879697

Epoch: 5| Step: 5
Training loss: 1.5946271419525146
Validation loss: 1.916595019320006

Epoch: 5| Step: 6
Training loss: 0.9201167225837708
Validation loss: 1.9173899824901293

Epoch: 5| Step: 7
Training loss: 1.7213413715362549
Validation loss: 1.9023662164647093

Epoch: 5| Step: 8
Training loss: 1.1118396520614624
Validation loss: 1.900022029876709

Epoch: 5| Step: 9
Training loss: 1.6782630681991577
Validation loss: 1.9058066157884495

Epoch: 5| Step: 10
Training loss: 1.495650291442871
Validation loss: 1.919862308809834

Epoch: 394| Step: 0
Training loss: 1.6304309368133545
Validation loss: 1.9327841074235979

Epoch: 5| Step: 1
Training loss: 1.292742371559143
Validation loss: 1.9733632546599194

Epoch: 5| Step: 2
Training loss: 1.7056496143341064
Validation loss: 1.9881759241063108

Epoch: 5| Step: 3
Training loss: 2.06292724609375
Validation loss: 1.9976567491408317

Epoch: 5| Step: 4
Training loss: 1.519254207611084
Validation loss: 1.957975277336695

Epoch: 5| Step: 5
Training loss: 1.0577447414398193
Validation loss: 1.9542006177286948

Epoch: 5| Step: 6
Training loss: 1.3970870971679688
Validation loss: 1.924514228297818

Epoch: 5| Step: 7
Training loss: 0.7404745221138
Validation loss: 1.9265656278979393

Epoch: 5| Step: 8
Training loss: 1.8268039226531982
Validation loss: 1.9281875100187076

Epoch: 5| Step: 9
Training loss: 0.8440119624137878
Validation loss: 1.92739321595879

Epoch: 5| Step: 10
Training loss: 1.2400445938110352
Validation loss: 1.9402727324475524

Epoch: 395| Step: 0
Training loss: 1.194985032081604
Validation loss: 1.921218438815045

Epoch: 5| Step: 1
Training loss: 0.9756773114204407
Validation loss: 1.9230332566845802

Epoch: 5| Step: 2
Training loss: 1.3174545764923096
Validation loss: 1.9304365727209276

Epoch: 5| Step: 3
Training loss: 1.4970871210098267
Validation loss: 1.913635641015986

Epoch: 5| Step: 4
Training loss: 1.3106485605239868
Validation loss: 1.9459709685335878

Epoch: 5| Step: 5
Training loss: 1.5741040706634521
Validation loss: 1.9113317061496038

Epoch: 5| Step: 6
Training loss: 1.553634524345398
Validation loss: 1.9674483960674656

Epoch: 5| Step: 7
Training loss: 1.5235306024551392
Validation loss: 1.953657934742589

Epoch: 5| Step: 8
Training loss: 1.635805368423462
Validation loss: 1.9422182088257165

Epoch: 5| Step: 9
Training loss: 1.1160017251968384
Validation loss: 1.9469031390323435

Epoch: 5| Step: 10
Training loss: 1.4539995193481445
Validation loss: 1.970211890435988

Epoch: 396| Step: 0
Training loss: 0.7680246233940125
Validation loss: 1.9567752025460685

Epoch: 5| Step: 1
Training loss: 1.4070016145706177
Validation loss: 1.9347282340449672

Epoch: 5| Step: 2
Training loss: 1.037795066833496
Validation loss: 1.9535489915519633

Epoch: 5| Step: 3
Training loss: 1.427949070930481
Validation loss: 1.9385641351822884

Epoch: 5| Step: 4
Training loss: 2.0528666973114014
Validation loss: 1.9429921360426052

Epoch: 5| Step: 5
Training loss: 1.9571526050567627
Validation loss: 1.9484948445391912

Epoch: 5| Step: 6
Training loss: 1.492870569229126
Validation loss: 1.9170425502202844

Epoch: 5| Step: 7
Training loss: 1.1931006908416748
Validation loss: 1.9232333834453295

Epoch: 5| Step: 8
Training loss: 1.2962446212768555
Validation loss: 1.8917500613838114

Epoch: 5| Step: 9
Training loss: 1.3065232038497925
Validation loss: 1.8935003857458792

Epoch: 5| Step: 10
Training loss: 1.4309982061386108
Validation loss: 1.9093094154070782

Epoch: 397| Step: 0
Training loss: 1.015539526939392
Validation loss: 1.8971425153875863

Epoch: 5| Step: 1
Training loss: 1.879586935043335
Validation loss: 1.9110570159009708

Epoch: 5| Step: 2
Training loss: 0.9821785092353821
Validation loss: 1.902800037014869

Epoch: 5| Step: 3
Training loss: 1.2549241781234741
Validation loss: 1.8969770836573776

Epoch: 5| Step: 4
Training loss: 1.4519433975219727
Validation loss: 1.9224831314497097

Epoch: 5| Step: 5
Training loss: 0.7685045003890991
Validation loss: 1.9492043090123001

Epoch: 5| Step: 6
Training loss: 1.6676628589630127
Validation loss: 1.9277051302694506

Epoch: 5| Step: 7
Training loss: 0.9534002542495728
Validation loss: 1.964675147046325

Epoch: 5| Step: 8
Training loss: 1.8987843990325928
Validation loss: 1.9630916567258938

Epoch: 5| Step: 9
Training loss: 1.631148338317871
Validation loss: 1.973818386754682

Epoch: 5| Step: 10
Training loss: 1.7535076141357422
Validation loss: 1.9580565062902306

Epoch: 398| Step: 0
Training loss: 1.2788063287734985
Validation loss: 1.9358079766714444

Epoch: 5| Step: 1
Training loss: 1.5713526010513306
Validation loss: 1.9280861218770344

Epoch: 5| Step: 2
Training loss: 0.7109473943710327
Validation loss: 1.9377738891109344

Epoch: 5| Step: 3
Training loss: 1.4402352571487427
Validation loss: 1.9539656767281153

Epoch: 5| Step: 4
Training loss: 1.1109583377838135
Validation loss: 1.927344560623169

Epoch: 5| Step: 5
Training loss: 1.8370263576507568
Validation loss: 1.9393439369816934

Epoch: 5| Step: 6
Training loss: 1.3577303886413574
Validation loss: 1.9441505709002096

Epoch: 5| Step: 7
Training loss: 1.5511507987976074
Validation loss: 1.926997532126724

Epoch: 5| Step: 8
Training loss: 1.3491580486297607
Validation loss: 1.9588117394396054

Epoch: 5| Step: 9
Training loss: 1.6330022811889648
Validation loss: 1.9396786394939627

Epoch: 5| Step: 10
Training loss: 1.6881619691848755
Validation loss: 1.9051499033486972

Epoch: 399| Step: 0
Training loss: 1.5729669332504272
Validation loss: 1.9067235967164398

Epoch: 5| Step: 1
Training loss: 1.8279975652694702
Validation loss: 1.8827453787608812

Epoch: 5| Step: 2
Training loss: 1.2843403816223145
Validation loss: 1.8759097578704997

Epoch: 5| Step: 3
Training loss: 0.9840667843818665
Validation loss: 1.8897474440195228

Epoch: 5| Step: 4
Training loss: 1.64279305934906
Validation loss: 1.9049223558877104

Epoch: 5| Step: 5
Training loss: 1.1717339754104614
Validation loss: 1.9022911646032845

Epoch: 5| Step: 6
Training loss: 1.7877737283706665
Validation loss: 1.8962177627830095

Epoch: 5| Step: 7
Training loss: 1.5245953798294067
Validation loss: 1.9386101897044847

Epoch: 5| Step: 8
Training loss: 0.8329939842224121
Validation loss: 1.9425674894804597

Epoch: 5| Step: 9
Training loss: 1.1843560934066772
Validation loss: 1.9615443278384466

Epoch: 5| Step: 10
Training loss: 1.3270337581634521
Validation loss: 1.995179630094959

Epoch: 400| Step: 0
Training loss: 1.2683290243148804
Validation loss: 2.0182528316333728

Epoch: 5| Step: 1
Training loss: 1.049310564994812
Validation loss: 2.0065791042902137

Epoch: 5| Step: 2
Training loss: 1.3802235126495361
Validation loss: 2.0068747638374247

Epoch: 5| Step: 3
Training loss: 1.2991095781326294
Validation loss: 1.975435221067039

Epoch: 5| Step: 4
Training loss: 1.1159073114395142
Validation loss: 1.9658510928512902

Epoch: 5| Step: 5
Training loss: 1.4680062532424927
Validation loss: 1.9415355638791156

Epoch: 5| Step: 6
Training loss: 1.7980457544326782
Validation loss: 1.9652208743556854

Epoch: 5| Step: 7
Training loss: 1.6555382013320923
Validation loss: 1.9348483982906546

Epoch: 5| Step: 8
Training loss: 1.5834883451461792
Validation loss: 1.9182825191046602

Epoch: 5| Step: 9
Training loss: 1.3098379373550415
Validation loss: 1.909666766402542

Epoch: 5| Step: 10
Training loss: 1.3471378087997437
Validation loss: 1.9293381411542174

Testing loss: 2.282318221198188
