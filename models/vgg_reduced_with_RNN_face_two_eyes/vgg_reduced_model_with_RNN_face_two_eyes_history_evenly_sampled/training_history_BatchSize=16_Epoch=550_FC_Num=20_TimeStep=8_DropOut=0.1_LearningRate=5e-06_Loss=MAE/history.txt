Epoch: 1| Step: 0
Training loss: 4.753247261047363
Validation loss: 5.240536505176175

Epoch: 6| Step: 1
Training loss: 4.998105525970459
Validation loss: 5.234991755536807

Epoch: 6| Step: 2
Training loss: 4.711266040802002
Validation loss: 5.229616011342695

Epoch: 6| Step: 3
Training loss: 5.036812782287598
Validation loss: 5.224385117971769

Epoch: 6| Step: 4
Training loss: 4.737950325012207
Validation loss: 5.218819084987845

Epoch: 6| Step: 5
Training loss: 4.849861145019531
Validation loss: 5.213676360345656

Epoch: 6| Step: 6
Training loss: 4.93465518951416
Validation loss: 5.208355488315705

Epoch: 6| Step: 7
Training loss: 4.146527290344238
Validation loss: 5.202889416807441

Epoch: 6| Step: 8
Training loss: 5.096956253051758
Validation loss: 5.1978697315339115

Epoch: 6| Step: 9
Training loss: 5.913311004638672
Validation loss: 5.192087306771227

Epoch: 6| Step: 10
Training loss: 5.019199848175049
Validation loss: 5.186358944062264

Epoch: 6| Step: 11
Training loss: 4.866792678833008
Validation loss: 5.1804047502497195

Epoch: 6| Step: 12
Training loss: 6.212247848510742
Validation loss: 5.173955425139396

Epoch: 6| Step: 13
Training loss: 4.5257439613342285
Validation loss: 5.1675765181100495

Epoch: 2| Step: 0
Training loss: 5.534564971923828
Validation loss: 5.161051950147075

Epoch: 6| Step: 1
Training loss: 4.076791763305664
Validation loss: 5.153976573739

Epoch: 6| Step: 2
Training loss: 4.729529857635498
Validation loss: 5.1466731358599915

Epoch: 6| Step: 3
Training loss: 5.039240837097168
Validation loss: 5.138631005440989

Epoch: 6| Step: 4
Training loss: 5.01308536529541
Validation loss: 5.130613162953367

Epoch: 6| Step: 5
Training loss: 4.900034427642822
Validation loss: 5.1226700659721125

Epoch: 6| Step: 6
Training loss: 5.001126289367676
Validation loss: 5.113342854284471

Epoch: 6| Step: 7
Training loss: 5.349808692932129
Validation loss: 5.1040979867340415

Epoch: 6| Step: 8
Training loss: 5.412556171417236
Validation loss: 5.094591038201445

Epoch: 6| Step: 9
Training loss: 3.8877949714660645
Validation loss: 5.083907414508122

Epoch: 6| Step: 10
Training loss: 3.9078214168548584
Validation loss: 5.072697208773706

Epoch: 6| Step: 11
Training loss: 5.310001373291016
Validation loss: 5.062913874144195

Epoch: 6| Step: 12
Training loss: 5.256096839904785
Validation loss: 5.051029656523017

Epoch: 6| Step: 13
Training loss: 5.440194129943848
Validation loss: 5.039679065827401

Epoch: 3| Step: 0
Training loss: 6.13958740234375
Validation loss: 5.027079402759511

Epoch: 6| Step: 1
Training loss: 3.351572275161743
Validation loss: 5.013167945287561

Epoch: 6| Step: 2
Training loss: 4.786725997924805
Validation loss: 5.000495197952435

Epoch: 6| Step: 3
Training loss: 4.978966236114502
Validation loss: 4.9866385613718345

Epoch: 6| Step: 4
Training loss: 5.4556379318237305
Validation loss: 4.972249354085615

Epoch: 6| Step: 5
Training loss: 5.022556781768799
Validation loss: 4.958009689084945

Epoch: 6| Step: 6
Training loss: 4.129204750061035
Validation loss: 4.942639186818113

Epoch: 6| Step: 7
Training loss: 5.636395454406738
Validation loss: 4.927136334039831

Epoch: 6| Step: 8
Training loss: 5.52255916595459
Validation loss: 4.911593867886451

Epoch: 6| Step: 9
Training loss: 4.219080924987793
Validation loss: 4.894362664991809

Epoch: 6| Step: 10
Training loss: 3.8733181953430176
Validation loss: 4.878294842217558

Epoch: 6| Step: 11
Training loss: 4.432418346405029
Validation loss: 4.862099088648314

Epoch: 6| Step: 12
Training loss: 4.51578950881958
Validation loss: 4.845395585542084

Epoch: 6| Step: 13
Training loss: 3.6488943099975586
Validation loss: 4.828227391806982

Epoch: 4| Step: 0
Training loss: 5.197209358215332
Validation loss: 4.810153010070965

Epoch: 6| Step: 1
Training loss: 3.2334060668945312
Validation loss: 4.791703075490972

Epoch: 6| Step: 2
Training loss: 4.617709159851074
Validation loss: 4.773441258297171

Epoch: 6| Step: 3
Training loss: 4.572826862335205
Validation loss: 4.754446721846057

Epoch: 6| Step: 4
Training loss: 4.960895538330078
Validation loss: 4.735318265935426

Epoch: 6| Step: 5
Training loss: 6.517145156860352
Validation loss: 4.715505892230619

Epoch: 6| Step: 6
Training loss: 3.8423774242401123
Validation loss: 4.69635663493987

Epoch: 6| Step: 7
Training loss: 4.42695426940918
Validation loss: 4.675571651868923

Epoch: 6| Step: 8
Training loss: 3.5326948165893555
Validation loss: 4.6549598273410595

Epoch: 6| Step: 9
Training loss: 3.0588598251342773
Validation loss: 4.63332430008919

Epoch: 6| Step: 10
Training loss: 4.841200828552246
Validation loss: 4.611816103740405

Epoch: 6| Step: 11
Training loss: 5.2108659744262695
Validation loss: 4.590646774538102

Epoch: 6| Step: 12
Training loss: 3.8938159942626953
Validation loss: 4.567485491434733

Epoch: 6| Step: 13
Training loss: 4.813867568969727
Validation loss: 4.544533714171378

Epoch: 5| Step: 0
Training loss: 3.676891803741455
Validation loss: 4.522342789557673

Epoch: 6| Step: 1
Training loss: 4.039501190185547
Validation loss: 4.497049936684229

Epoch: 6| Step: 2
Training loss: 5.009922981262207
Validation loss: 4.4740991618043635

Epoch: 6| Step: 3
Training loss: 3.697892427444458
Validation loss: 4.449901826920048

Epoch: 6| Step: 4
Training loss: 5.218473434448242
Validation loss: 4.424646346799789

Epoch: 6| Step: 5
Training loss: 3.863804817199707
Validation loss: 4.402104998147616

Epoch: 6| Step: 6
Training loss: 3.5990543365478516
Validation loss: 4.37791815111714

Epoch: 6| Step: 7
Training loss: 4.67225456237793
Validation loss: 4.355252199275519

Epoch: 6| Step: 8
Training loss: 3.686363935470581
Validation loss: 4.3313643599069245

Epoch: 6| Step: 9
Training loss: 4.252816200256348
Validation loss: 4.307864853130874

Epoch: 6| Step: 10
Training loss: 4.904361724853516
Validation loss: 4.284632849436934

Epoch: 6| Step: 11
Training loss: 4.609990119934082
Validation loss: 4.261189891446021

Epoch: 6| Step: 12
Training loss: 3.3612351417541504
Validation loss: 4.238370357021209

Epoch: 6| Step: 13
Training loss: 3.481598138809204
Validation loss: 4.215517731123073

Epoch: 6| Step: 0
Training loss: 3.843773126602173
Validation loss: 4.192192031491187

Epoch: 6| Step: 1
Training loss: 3.7707784175872803
Validation loss: 4.167467394182759

Epoch: 6| Step: 2
Training loss: 4.447617530822754
Validation loss: 4.140722279907555

Epoch: 6| Step: 3
Training loss: 4.186976432800293
Validation loss: 4.116782311470278

Epoch: 6| Step: 4
Training loss: 3.0100173950195312
Validation loss: 4.091430597407843

Epoch: 6| Step: 5
Training loss: 3.201540946960449
Validation loss: 4.067048101014988

Epoch: 6| Step: 6
Training loss: 4.581557273864746
Validation loss: 4.042413911511821

Epoch: 6| Step: 7
Training loss: 4.67707633972168
Validation loss: 4.019725835451516

Epoch: 6| Step: 8
Training loss: 3.9614291191101074
Validation loss: 3.9985227149019957

Epoch: 6| Step: 9
Training loss: 5.0996503829956055
Validation loss: 3.9764838577598653

Epoch: 6| Step: 10
Training loss: 3.5827527046203613
Validation loss: 3.9561382493665143

Epoch: 6| Step: 11
Training loss: 3.3346214294433594
Validation loss: 3.9379002560851393

Epoch: 6| Step: 12
Training loss: 3.4113311767578125
Validation loss: 3.917496053121423

Epoch: 6| Step: 13
Training loss: 2.6212215423583984
Validation loss: 3.901906854362898

Epoch: 7| Step: 0
Training loss: 3.9384989738464355
Validation loss: 3.8864556845798286

Epoch: 6| Step: 1
Training loss: 2.7285356521606445
Validation loss: 3.8709063222331386

Epoch: 6| Step: 2
Training loss: 4.830265045166016
Validation loss: 3.858490159434657

Epoch: 6| Step: 3
Training loss: 4.338261604309082
Validation loss: 3.845707557534659

Epoch: 6| Step: 4
Training loss: 3.8774490356445312
Validation loss: 3.83366580676007

Epoch: 6| Step: 5
Training loss: 4.344573020935059
Validation loss: 3.821512201780914

Epoch: 6| Step: 6
Training loss: 3.388622760772705
Validation loss: 3.807499941959176

Epoch: 6| Step: 7
Training loss: 3.529390811920166
Validation loss: 3.798099753677204

Epoch: 6| Step: 8
Training loss: 3.5060558319091797
Validation loss: 3.7847893109885593

Epoch: 6| Step: 9
Training loss: 4.235527038574219
Validation loss: 3.774961256211804

Epoch: 6| Step: 10
Training loss: 3.058136224746704
Validation loss: 3.7626507820621615

Epoch: 6| Step: 11
Training loss: 3.40610671043396
Validation loss: 3.7494263084985877

Epoch: 6| Step: 12
Training loss: 3.4923484325408936
Validation loss: 3.7416870388933408

Epoch: 6| Step: 13
Training loss: 2.39032244682312
Validation loss: 3.7285805133081253

Epoch: 8| Step: 0
Training loss: 3.840247392654419
Validation loss: 3.7189585342202136

Epoch: 6| Step: 1
Training loss: 3.4718127250671387
Validation loss: 3.7100545411468833

Epoch: 6| Step: 2
Training loss: 3.5000486373901367
Validation loss: 3.6985024534245974

Epoch: 6| Step: 3
Training loss: 3.784421920776367
Validation loss: 3.688077078070692

Epoch: 6| Step: 4
Training loss: 3.1402664184570312
Validation loss: 3.6788681501983316

Epoch: 6| Step: 5
Training loss: 3.234647750854492
Validation loss: 3.670033444640457

Epoch: 6| Step: 6
Training loss: 3.4413042068481445
Validation loss: 3.6628293209178473

Epoch: 6| Step: 7
Training loss: 4.221086502075195
Validation loss: 3.6552585940207205

Epoch: 6| Step: 8
Training loss: 2.8813576698303223
Validation loss: 3.647960450059624

Epoch: 6| Step: 9
Training loss: 5.170852184295654
Validation loss: 3.64108952142859

Epoch: 6| Step: 10
Training loss: 3.2113354206085205
Validation loss: 3.6331439300249984

Epoch: 6| Step: 11
Training loss: 3.2400264739990234
Validation loss: 3.6264164422148015

Epoch: 6| Step: 12
Training loss: 3.5159189701080322
Validation loss: 3.6219677976382676

Epoch: 6| Step: 13
Training loss: 3.176968574523926
Validation loss: 3.6149806925045547

Epoch: 9| Step: 0
Training loss: 3.3681869506835938
Validation loss: 3.6095609434189333

Epoch: 6| Step: 1
Training loss: 2.666196346282959
Validation loss: 3.602677176075597

Epoch: 6| Step: 2
Training loss: 4.567478179931641
Validation loss: 3.5970605470800914

Epoch: 6| Step: 3
Training loss: 2.3599562644958496
Validation loss: 3.5918143231381654

Epoch: 6| Step: 4
Training loss: 3.4723732471466064
Validation loss: 3.5872761408487954

Epoch: 6| Step: 5
Training loss: 4.162241458892822
Validation loss: 3.580279452826387

Epoch: 6| Step: 6
Training loss: 2.947657585144043
Validation loss: 3.5741371185548845

Epoch: 6| Step: 7
Training loss: 3.470656156539917
Validation loss: 3.568743100730322

Epoch: 6| Step: 8
Training loss: 4.3716254234313965
Validation loss: 3.5629542489205637

Epoch: 6| Step: 9
Training loss: 2.551323890686035
Validation loss: 3.5569799587290776

Epoch: 6| Step: 10
Training loss: 2.9347023963928223
Validation loss: 3.54868729652897

Epoch: 6| Step: 11
Training loss: 4.332659721374512
Validation loss: 3.547010470462102

Epoch: 6| Step: 12
Training loss: 4.276394367218018
Validation loss: 3.5409892195014545

Epoch: 6| Step: 13
Training loss: 3.3898706436157227
Validation loss: 3.535031733974334

Epoch: 10| Step: 0
Training loss: 3.0898513793945312
Validation loss: 3.5299668158254316

Epoch: 6| Step: 1
Training loss: 3.2258691787719727
Validation loss: 3.525760994162611

Epoch: 6| Step: 2
Training loss: 3.719146251678467
Validation loss: 3.521104745967414

Epoch: 6| Step: 3
Training loss: 3.1750175952911377
Validation loss: 3.5165677583345802

Epoch: 6| Step: 4
Training loss: 3.6381301879882812
Validation loss: 3.5123369693756104

Epoch: 6| Step: 5
Training loss: 3.4954402446746826
Validation loss: 3.5078374134596957

Epoch: 6| Step: 6
Training loss: 3.3501534461975098
Validation loss: 3.5048506516282276

Epoch: 6| Step: 7
Training loss: 3.8488712310791016
Validation loss: 3.4998869434479745

Epoch: 6| Step: 8
Training loss: 4.545314788818359
Validation loss: 3.4946667045675297

Epoch: 6| Step: 9
Training loss: 3.0005874633789062
Validation loss: 3.4913937173863894

Epoch: 6| Step: 10
Training loss: 3.8077783584594727
Validation loss: 3.4873741467793784

Epoch: 6| Step: 11
Training loss: 3.4778661727905273
Validation loss: 3.4806368863710793

Epoch: 6| Step: 12
Training loss: 2.441030502319336
Validation loss: 3.4774103497946136

Epoch: 6| Step: 13
Training loss: 3.0690839290618896
Validation loss: 3.4717026500291723

Epoch: 11| Step: 0
Training loss: 2.3264529705047607
Validation loss: 3.4671447764160814

Epoch: 6| Step: 1
Training loss: 3.3720788955688477
Validation loss: 3.463089766040925

Epoch: 6| Step: 2
Training loss: 3.252063274383545
Validation loss: 3.455709103615053

Epoch: 6| Step: 3
Training loss: 2.6954689025878906
Validation loss: 3.450977640767251

Epoch: 6| Step: 4
Training loss: 3.129960536956787
Validation loss: 3.4465845425923667

Epoch: 6| Step: 5
Training loss: 4.81901216506958
Validation loss: 3.4401070071804907

Epoch: 6| Step: 6
Training loss: 3.611201763153076
Validation loss: 3.4367482328927643

Epoch: 6| Step: 7
Training loss: 3.886924982070923
Validation loss: 3.4315268429376746

Epoch: 6| Step: 8
Training loss: 3.860534191131592
Validation loss: 3.427401276044948

Epoch: 6| Step: 9
Training loss: 4.114240646362305
Validation loss: 3.423928222348613

Epoch: 6| Step: 10
Training loss: 2.7848119735717773
Validation loss: 3.4176585007739324

Epoch: 6| Step: 11
Training loss: 2.5999157428741455
Validation loss: 3.4146915635754986

Epoch: 6| Step: 12
Training loss: 3.0526270866394043
Validation loss: 3.412482459058044

Epoch: 6| Step: 13
Training loss: 4.209676742553711
Validation loss: 3.410662853589622

Epoch: 12| Step: 0
Training loss: 2.77364182472229
Validation loss: 3.4069104425368772

Epoch: 6| Step: 1
Training loss: 2.923656940460205
Validation loss: 3.4044319583523657

Epoch: 6| Step: 2
Training loss: 3.007744789123535
Validation loss: 3.400202646050402

Epoch: 6| Step: 3
Training loss: 3.7473762035369873
Validation loss: 3.3969603507749495

Epoch: 6| Step: 4
Training loss: 3.9004290103912354
Validation loss: 3.396492470977127

Epoch: 6| Step: 5
Training loss: 3.4749319553375244
Validation loss: 3.390611940814603

Epoch: 6| Step: 6
Training loss: 3.3579158782958984
Validation loss: 3.388856690417054

Epoch: 6| Step: 7
Training loss: 2.528472900390625
Validation loss: 3.385237532277261

Epoch: 6| Step: 8
Training loss: 4.5033087730407715
Validation loss: 3.3831647339687554

Epoch: 6| Step: 9
Training loss: 2.2692246437072754
Validation loss: 3.3787329017475085

Epoch: 6| Step: 10
Training loss: 1.912369728088379
Validation loss: 3.377370080640239

Epoch: 6| Step: 11
Training loss: 4.396402359008789
Validation loss: 3.373815426262476

Epoch: 6| Step: 12
Training loss: 3.519993305206299
Validation loss: 3.3702048870824997

Epoch: 6| Step: 13
Training loss: 5.303741931915283
Validation loss: 3.366421330359674

Epoch: 13| Step: 0
Training loss: 3.2773818969726562
Validation loss: 3.3625991908452844

Epoch: 6| Step: 1
Training loss: 2.8342347145080566
Validation loss: 3.3583858372062765

Epoch: 6| Step: 2
Training loss: 3.904670000076294
Validation loss: 3.356468895430206

Epoch: 6| Step: 3
Training loss: 2.9093120098114014
Validation loss: 3.3527960367100214

Epoch: 6| Step: 4
Training loss: 3.4467978477478027
Validation loss: 3.3506704248407835

Epoch: 6| Step: 5
Training loss: 3.7938222885131836
Validation loss: 3.3502492699571835

Epoch: 6| Step: 6
Training loss: 2.4261693954467773
Validation loss: 3.3481264550198793

Epoch: 6| Step: 7
Training loss: 2.7603211402893066
Validation loss: 3.3431761546801497

Epoch: 6| Step: 8
Training loss: 2.9899702072143555
Validation loss: 3.3414347171783447

Epoch: 6| Step: 9
Training loss: 4.099977016448975
Validation loss: 3.3378031176905476

Epoch: 6| Step: 10
Training loss: 3.3787317276000977
Validation loss: 3.333279930135255

Epoch: 6| Step: 11
Training loss: 3.069993734359741
Validation loss: 3.3332928560113393

Epoch: 6| Step: 12
Training loss: 4.059990406036377
Validation loss: 3.329724798920334

Epoch: 6| Step: 13
Training loss: 3.3469200134277344
Validation loss: 3.3272426102751043

Epoch: 14| Step: 0
Training loss: 4.065574645996094
Validation loss: 3.3232874716481855

Epoch: 6| Step: 1
Training loss: 2.9574060440063477
Validation loss: 3.3214627747894614

Epoch: 6| Step: 2
Training loss: 3.762899398803711
Validation loss: 3.3180724549037155

Epoch: 6| Step: 3
Training loss: 3.0379014015197754
Validation loss: 3.3144229894043296

Epoch: 6| Step: 4
Training loss: 2.8589816093444824
Validation loss: 3.312790137465282

Epoch: 6| Step: 5
Training loss: 3.5037386417388916
Validation loss: 3.313077726671773

Epoch: 6| Step: 6
Training loss: 2.972184181213379
Validation loss: 3.3098479932354343

Epoch: 6| Step: 7
Training loss: 2.4741499423980713
Validation loss: 3.3045043278765935

Epoch: 6| Step: 8
Training loss: 4.4458441734313965
Validation loss: 3.301509185503888

Epoch: 6| Step: 9
Training loss: 3.393824577331543
Validation loss: 3.2998999011132026

Epoch: 6| Step: 10
Training loss: 2.569335460662842
Validation loss: 3.295851256257744

Epoch: 6| Step: 11
Training loss: 3.7662577629089355
Validation loss: 3.2935084835175545

Epoch: 6| Step: 12
Training loss: 2.7194435596466064
Validation loss: 3.2902842824177077

Epoch: 6| Step: 13
Training loss: 3.3793654441833496
Validation loss: 3.287016599409042

Epoch: 15| Step: 0
Training loss: 2.8441028594970703
Validation loss: 3.285353358073901

Epoch: 6| Step: 1
Training loss: 3.702404499053955
Validation loss: 3.2826299769904024

Epoch: 6| Step: 2
Training loss: 3.7845516204833984
Validation loss: 3.2800831512738298

Epoch: 6| Step: 3
Training loss: 2.257387399673462
Validation loss: 3.2774085639625468

Epoch: 6| Step: 4
Training loss: 3.555793523788452
Validation loss: 3.2753702825115574

Epoch: 6| Step: 5
Training loss: 2.793154239654541
Validation loss: 3.2760598838970227

Epoch: 6| Step: 6
Training loss: 4.305722236633301
Validation loss: 3.2699947126450075

Epoch: 6| Step: 7
Training loss: 2.102053165435791
Validation loss: 3.266784824350829

Epoch: 6| Step: 8
Training loss: 3.906214714050293
Validation loss: 3.2663934846078195

Epoch: 6| Step: 9
Training loss: 3.2092716693878174
Validation loss: 3.2641701108665875

Epoch: 6| Step: 10
Training loss: 3.413646697998047
Validation loss: 3.258091354882845

Epoch: 6| Step: 11
Training loss: 3.2668652534484863
Validation loss: 3.2591679865314114

Epoch: 6| Step: 12
Training loss: 3.7396366596221924
Validation loss: 3.253729763851371

Epoch: 6| Step: 13
Training loss: 2.0486719608306885
Validation loss: 3.24979664433387

Epoch: 16| Step: 0
Training loss: 2.5799314975738525
Validation loss: 3.247067864223193

Epoch: 6| Step: 1
Training loss: 2.5357604026794434
Validation loss: 3.2458615918313303

Epoch: 6| Step: 2
Training loss: 4.083803176879883
Validation loss: 3.2423157999592442

Epoch: 6| Step: 3
Training loss: 3.0191497802734375
Validation loss: 3.2368280015965945

Epoch: 6| Step: 4
Training loss: 3.049990177154541
Validation loss: 3.23493363523996

Epoch: 6| Step: 5
Training loss: 4.278411865234375
Validation loss: 3.2318036069152174

Epoch: 6| Step: 6
Training loss: 3.374156951904297
Validation loss: 3.229101521994478

Epoch: 6| Step: 7
Training loss: 3.2227630615234375
Validation loss: 3.226454875802481

Epoch: 6| Step: 8
Training loss: 2.4670753479003906
Validation loss: 3.221580213116061

Epoch: 6| Step: 9
Training loss: 2.8236494064331055
Validation loss: 3.2178467781313005

Epoch: 6| Step: 10
Training loss: 3.292457103729248
Validation loss: 3.2189856190835275

Epoch: 6| Step: 11
Training loss: 3.142641067504883
Validation loss: 3.211643918868034

Epoch: 6| Step: 12
Training loss: 3.6826493740081787
Validation loss: 3.211924732372325

Epoch: 6| Step: 13
Training loss: 3.6858530044555664
Validation loss: 3.2088515553423154

Epoch: 17| Step: 0
Training loss: 2.981443166732788
Validation loss: 3.204368878436345

Epoch: 6| Step: 1
Training loss: 2.6122524738311768
Validation loss: 3.2027454145493044

Epoch: 6| Step: 2
Training loss: 2.4135053157806396
Validation loss: 3.2027701024086244

Epoch: 6| Step: 3
Training loss: 3.7091212272644043
Validation loss: 3.2039422322345037

Epoch: 6| Step: 4
Training loss: 3.4434165954589844
Validation loss: 3.20440931986737

Epoch: 6| Step: 5
Training loss: 3.8430895805358887
Validation loss: 3.200711704069568

Epoch: 6| Step: 6
Training loss: 3.3920035362243652
Validation loss: 3.200818056701332

Epoch: 6| Step: 7
Training loss: 4.335878372192383
Validation loss: 3.1948919321901057

Epoch: 6| Step: 8
Training loss: 3.5842857360839844
Validation loss: 3.190062176796698

Epoch: 6| Step: 9
Training loss: 3.3579893112182617
Validation loss: 3.186773571916806

Epoch: 6| Step: 10
Training loss: 2.8230152130126953
Validation loss: 3.182234956372169

Epoch: 6| Step: 11
Training loss: 2.871513843536377
Validation loss: 3.180191780931206

Epoch: 6| Step: 12
Training loss: 2.0031824111938477
Validation loss: 3.1765034583307084

Epoch: 6| Step: 13
Training loss: 3.3630034923553467
Validation loss: 3.1776402176067395

Epoch: 18| Step: 0
Training loss: 3.471668243408203
Validation loss: 3.173435841837237

Epoch: 6| Step: 1
Training loss: 2.9240832328796387
Validation loss: 3.1699518695954354

Epoch: 6| Step: 2
Training loss: 3.2189278602600098
Validation loss: 3.1695102260958765

Epoch: 6| Step: 3
Training loss: 3.8182356357574463
Validation loss: 3.165134399167953

Epoch: 6| Step: 4
Training loss: 3.9573285579681396
Validation loss: 3.161970207768102

Epoch: 6| Step: 5
Training loss: 2.381666660308838
Validation loss: 3.160236358642578

Epoch: 6| Step: 6
Training loss: 3.9472289085388184
Validation loss: 3.1577499835721907

Epoch: 6| Step: 7
Training loss: 2.381648063659668
Validation loss: 3.1563679633602018

Epoch: 6| Step: 8
Training loss: 2.9253997802734375
Validation loss: 3.1533942837868967

Epoch: 6| Step: 9
Training loss: 2.552091360092163
Validation loss: 3.1522025113464682

Epoch: 6| Step: 10
Training loss: 2.9130773544311523
Validation loss: 3.147553354181269

Epoch: 6| Step: 11
Training loss: 2.6370837688446045
Validation loss: 3.1475751323084675

Epoch: 6| Step: 12
Training loss: 4.13555908203125
Validation loss: 3.1469576512613604

Epoch: 6| Step: 13
Training loss: 3.015883445739746
Validation loss: 3.1442574685619724

Epoch: 19| Step: 0
Training loss: 2.514730930328369
Validation loss: 3.1406253435278453

Epoch: 6| Step: 1
Training loss: 2.6822826862335205
Validation loss: 3.1383377685341785

Epoch: 6| Step: 2
Training loss: 2.7587552070617676
Validation loss: 3.1364625013002785

Epoch: 6| Step: 3
Training loss: 3.3301801681518555
Validation loss: 3.13293779793606

Epoch: 6| Step: 4
Training loss: 3.5217957496643066
Validation loss: 3.129851646320794

Epoch: 6| Step: 5
Training loss: 3.658234119415283
Validation loss: 3.125515681441112

Epoch: 6| Step: 6
Training loss: 3.6762912273406982
Validation loss: 3.1260347597060667

Epoch: 6| Step: 7
Training loss: 2.783531665802002
Validation loss: 3.125067885204028

Epoch: 6| Step: 8
Training loss: 3.6672263145446777
Validation loss: 3.1257728530514624

Epoch: 6| Step: 9
Training loss: 3.4580700397491455
Validation loss: 3.1246923092872865

Epoch: 6| Step: 10
Training loss: 2.3543953895568848
Validation loss: 3.1187583605448403

Epoch: 6| Step: 11
Training loss: 2.9168570041656494
Validation loss: 3.118584958455896

Epoch: 6| Step: 12
Training loss: 3.5262396335601807
Validation loss: 3.112982755066246

Epoch: 6| Step: 13
Training loss: 3.178420066833496
Validation loss: 3.1110035732228267

Epoch: 20| Step: 0
Training loss: 3.292478561401367
Validation loss: 3.109485326274749

Epoch: 6| Step: 1
Training loss: 3.1950979232788086
Validation loss: 3.1046408402022494

Epoch: 6| Step: 2
Training loss: 4.127709865570068
Validation loss: 3.1022186561297347

Epoch: 6| Step: 3
Training loss: 3.486726999282837
Validation loss: 3.1016872390624015

Epoch: 6| Step: 4
Training loss: 3.0207340717315674
Validation loss: 3.099601299531998

Epoch: 6| Step: 5
Training loss: 2.726602792739868
Validation loss: 3.096742081385787

Epoch: 6| Step: 6
Training loss: 3.5193052291870117
Validation loss: 3.0916005565274145

Epoch: 6| Step: 7
Training loss: 2.622148036956787
Validation loss: 3.090206133422031

Epoch: 6| Step: 8
Training loss: 2.949697494506836
Validation loss: 3.087725362470073

Epoch: 6| Step: 9
Training loss: 3.6053130626678467
Validation loss: 3.089868824969056

Epoch: 6| Step: 10
Training loss: 2.4392364025115967
Validation loss: 3.086077377360354

Epoch: 6| Step: 11
Training loss: 3.071594715118408
Validation loss: 3.083282316884687

Epoch: 6| Step: 12
Training loss: 3.214993476867676
Validation loss: 3.084788163503011

Epoch: 6| Step: 13
Training loss: 1.9479899406433105
Validation loss: 3.07733170447811

Epoch: 21| Step: 0
Training loss: 2.870711326599121
Validation loss: 3.0767763506981636

Epoch: 6| Step: 1
Training loss: 4.427731513977051
Validation loss: 3.0748673382625786

Epoch: 6| Step: 2
Training loss: 2.8043339252471924
Validation loss: 3.0735512959059847

Epoch: 6| Step: 3
Training loss: 2.697195053100586
Validation loss: 3.072375500073997

Epoch: 6| Step: 4
Training loss: 2.9139914512634277
Validation loss: 3.0702024018892677

Epoch: 6| Step: 5
Training loss: 2.7947239875793457
Validation loss: 3.0672731014990036

Epoch: 6| Step: 6
Training loss: 2.6676130294799805
Validation loss: 3.0651745616748767

Epoch: 6| Step: 7
Training loss: 3.72623348236084
Validation loss: 3.0675415018553376

Epoch: 6| Step: 8
Training loss: 2.922375440597534
Validation loss: 3.0646719830010527

Epoch: 6| Step: 9
Training loss: 3.3121774196624756
Validation loss: 3.0607770566017396

Epoch: 6| Step: 10
Training loss: 2.727355718612671
Validation loss: 3.061050038183889

Epoch: 6| Step: 11
Training loss: 3.302076816558838
Validation loss: 3.0556175375497467

Epoch: 6| Step: 12
Training loss: 2.8758950233459473
Validation loss: 3.052499355808381

Epoch: 6| Step: 13
Training loss: 3.6722941398620605
Validation loss: 3.049557334633284

Epoch: 22| Step: 0
Training loss: 3.38336181640625
Validation loss: 3.050093586726855

Epoch: 6| Step: 1
Training loss: 2.6082677841186523
Validation loss: 3.047638488072221

Epoch: 6| Step: 2
Training loss: 3.0951905250549316
Validation loss: 3.0466038257844987

Epoch: 6| Step: 3
Training loss: 3.6007778644561768
Validation loss: 3.0445156225594143

Epoch: 6| Step: 4
Training loss: 3.287687301635742
Validation loss: 3.0462379532475627

Epoch: 6| Step: 5
Training loss: 2.8053784370422363
Validation loss: 3.0440783500671387

Epoch: 6| Step: 6
Training loss: 3.5289831161499023
Validation loss: 3.041610551136796

Epoch: 6| Step: 7
Training loss: 3.3021037578582764
Validation loss: 3.041373219541324

Epoch: 6| Step: 8
Training loss: 3.2575578689575195
Validation loss: 3.037176767985026

Epoch: 6| Step: 9
Training loss: 2.116816997528076
Validation loss: 3.0318884362456617

Epoch: 6| Step: 10
Training loss: 3.772901773452759
Validation loss: 3.03334806811425

Epoch: 6| Step: 11
Training loss: 2.658024787902832
Validation loss: 3.0275670405357116

Epoch: 6| Step: 12
Training loss: 1.7772676944732666
Validation loss: 3.0300953054940827

Epoch: 6| Step: 13
Training loss: 4.698546886444092
Validation loss: 3.0323211146939184

Epoch: 23| Step: 0
Training loss: 3.5707850456237793
Validation loss: 3.0258338989750033

Epoch: 6| Step: 1
Training loss: 3.463387966156006
Validation loss: 3.0218238574202343

Epoch: 6| Step: 2
Training loss: 2.881533145904541
Validation loss: 3.0207320554282076

Epoch: 6| Step: 3
Training loss: 3.2448432445526123
Validation loss: 3.0171318772018596

Epoch: 6| Step: 4
Training loss: 3.514890193939209
Validation loss: 3.0169050590966338

Epoch: 6| Step: 5
Training loss: 2.8571221828460693
Validation loss: 3.015636936310799

Epoch: 6| Step: 6
Training loss: 2.9688000679016113
Validation loss: 3.01378236791139

Epoch: 6| Step: 7
Training loss: 1.7342817783355713
Validation loss: 3.0140057481745237

Epoch: 6| Step: 8
Training loss: 4.300290107727051
Validation loss: 3.013343616198468

Epoch: 6| Step: 9
Training loss: 2.8499088287353516
Validation loss: 3.0120028500915854

Epoch: 6| Step: 10
Training loss: 3.2667770385742188
Validation loss: 3.011858360741728

Epoch: 6| Step: 11
Training loss: 3.534741163253784
Validation loss: 3.006919600630319

Epoch: 6| Step: 12
Training loss: 2.4148178100585938
Validation loss: 3.0075109030610774

Epoch: 6| Step: 13
Training loss: 1.8328825235366821
Validation loss: 3.002905802060199

Epoch: 24| Step: 0
Training loss: 3.0019304752349854
Validation loss: 3.001268494513727

Epoch: 6| Step: 1
Training loss: 3.8955612182617188
Validation loss: 2.9992245012714016

Epoch: 6| Step: 2
Training loss: 2.579383134841919
Validation loss: 2.9963167739170853

Epoch: 6| Step: 3
Training loss: 2.853731393814087
Validation loss: 3.0027643019153225

Epoch: 6| Step: 4
Training loss: 2.3741161823272705
Validation loss: 2.99872487847523

Epoch: 6| Step: 5
Training loss: 3.0543761253356934
Validation loss: 2.9968816977675243

Epoch: 6| Step: 6
Training loss: 3.4386491775512695
Validation loss: 2.9926043172036447

Epoch: 6| Step: 7
Training loss: 4.218782901763916
Validation loss: 2.9925117774676253

Epoch: 6| Step: 8
Training loss: 3.062373161315918
Validation loss: 2.988159715488393

Epoch: 6| Step: 9
Training loss: 2.384016275405884
Validation loss: 2.9864312346263597

Epoch: 6| Step: 10
Training loss: 3.484557867050171
Validation loss: 2.9855119951309694

Epoch: 6| Step: 11
Training loss: 2.851527214050293
Validation loss: 2.984388005348944

Epoch: 6| Step: 12
Training loss: 3.4506897926330566
Validation loss: 2.983484173333773

Epoch: 6| Step: 13
Training loss: 1.4465057849884033
Validation loss: 2.9806688370243197

Epoch: 25| Step: 0
Training loss: 3.310148000717163
Validation loss: 2.9819687335721907

Epoch: 6| Step: 1
Training loss: 3.287686347961426
Validation loss: 2.981097957139374

Epoch: 6| Step: 2
Training loss: 3.4295597076416016
Validation loss: 2.978930416927543

Epoch: 6| Step: 3
Training loss: 2.983515739440918
Validation loss: 2.9775095626872075

Epoch: 6| Step: 4
Training loss: 2.9333386421203613
Validation loss: 2.9756247407646588

Epoch: 6| Step: 5
Training loss: 3.454406976699829
Validation loss: 2.973859412695772

Epoch: 6| Step: 6
Training loss: 3.316014051437378
Validation loss: 2.974358220254221

Epoch: 6| Step: 7
Training loss: 2.7011985778808594
Validation loss: 2.970983761613087

Epoch: 6| Step: 8
Training loss: 2.6647701263427734
Validation loss: 2.971009205746394

Epoch: 6| Step: 9
Training loss: 2.3260598182678223
Validation loss: 2.971346075816821

Epoch: 6| Step: 10
Training loss: 3.1381983757019043
Validation loss: 2.971235018904491

Epoch: 6| Step: 11
Training loss: 3.492511749267578
Validation loss: 2.971343991576984

Epoch: 6| Step: 12
Training loss: 2.8412058353424072
Validation loss: 2.964120585431335

Epoch: 6| Step: 13
Training loss: 2.4665565490722656
Validation loss: 2.963773509507538

Epoch: 26| Step: 0
Training loss: 3.1612884998321533
Validation loss: 2.969241847274124

Epoch: 6| Step: 1
Training loss: 2.4628491401672363
Validation loss: 2.963491024509553

Epoch: 6| Step: 2
Training loss: 2.369292736053467
Validation loss: 2.96790285007928

Epoch: 6| Step: 3
Training loss: 3.4335596561431885
Validation loss: 2.962740180312946

Epoch: 6| Step: 4
Training loss: 3.3681142330169678
Validation loss: 2.961847169424898

Epoch: 6| Step: 5
Training loss: 3.310563564300537
Validation loss: 2.966452552426246

Epoch: 6| Step: 6
Training loss: 3.172229290008545
Validation loss: 2.9678854685957714

Epoch: 6| Step: 7
Training loss: 3.38423490524292
Validation loss: 2.964569345597298

Epoch: 6| Step: 8
Training loss: 2.8174779415130615
Validation loss: 2.9596944291104554

Epoch: 6| Step: 9
Training loss: 2.792982578277588
Validation loss: 2.957209481987902

Epoch: 6| Step: 10
Training loss: 3.425497055053711
Validation loss: 2.9534368899560746

Epoch: 6| Step: 11
Training loss: 2.8827781677246094
Validation loss: 2.9532484521148024

Epoch: 6| Step: 12
Training loss: 3.098224401473999
Validation loss: 2.953370048153785

Epoch: 6| Step: 13
Training loss: 2.5517046451568604
Validation loss: 2.952174904525921

Epoch: 27| Step: 0
Training loss: 2.407844066619873
Validation loss: 2.9481880408461376

Epoch: 6| Step: 1
Training loss: 2.8453874588012695
Validation loss: 2.9521017689858713

Epoch: 6| Step: 2
Training loss: 4.113504409790039
Validation loss: 2.947659774493146

Epoch: 6| Step: 3
Training loss: 3.0224814414978027
Validation loss: 2.9467341130779636

Epoch: 6| Step: 4
Training loss: 3.210426092147827
Validation loss: 2.9452112669585855

Epoch: 6| Step: 5
Training loss: 3.217909097671509
Validation loss: 2.9439852878611577

Epoch: 6| Step: 6
Training loss: 2.290062427520752
Validation loss: 2.941020752793999

Epoch: 6| Step: 7
Training loss: 3.030583143234253
Validation loss: 2.9437037283374416

Epoch: 6| Step: 8
Training loss: 2.589257001876831
Validation loss: 2.9426714117809007

Epoch: 6| Step: 9
Training loss: 3.1405582427978516
Validation loss: 2.9438536884964153

Epoch: 6| Step: 10
Training loss: 3.1001484394073486
Validation loss: 2.949258409520631

Epoch: 6| Step: 11
Training loss: 2.712827205657959
Validation loss: 2.9398715701154483

Epoch: 6| Step: 12
Training loss: 3.7536134719848633
Validation loss: 2.9377024660828295

Epoch: 6| Step: 13
Training loss: 2.7821381092071533
Validation loss: 2.9351098434899443

Epoch: 28| Step: 0
Training loss: 3.1168460845947266
Validation loss: 2.9380470911661782

Epoch: 6| Step: 1
Training loss: 2.4408957958221436
Validation loss: 2.936873174482776

Epoch: 6| Step: 2
Training loss: 2.99690580368042
Validation loss: 2.9396619130206365

Epoch: 6| Step: 3
Training loss: 2.911327362060547
Validation loss: 2.93424746810749

Epoch: 6| Step: 4
Training loss: 2.6508986949920654
Validation loss: 2.9325610642792075

Epoch: 6| Step: 5
Training loss: 3.0339226722717285
Validation loss: 2.9467109198211343

Epoch: 6| Step: 6
Training loss: 3.2251133918762207
Validation loss: 2.94126465500042

Epoch: 6| Step: 7
Training loss: 2.8729636669158936
Validation loss: 2.9411910733869

Epoch: 6| Step: 8
Training loss: 2.7513954639434814
Validation loss: 2.93442016519526

Epoch: 6| Step: 9
Training loss: 3.13333797454834
Validation loss: 2.930604286091302

Epoch: 6| Step: 10
Training loss: 4.243249893188477
Validation loss: 2.929065783818563

Epoch: 6| Step: 11
Training loss: 2.9949698448181152
Validation loss: 2.9248045362452024

Epoch: 6| Step: 12
Training loss: 3.024533271789551
Validation loss: 2.9277111586704048

Epoch: 6| Step: 13
Training loss: 2.626828908920288
Validation loss: 2.926096695725636

Epoch: 29| Step: 0
Training loss: 2.5767736434936523
Validation loss: 2.926859709524339

Epoch: 6| Step: 1
Training loss: 3.629471778869629
Validation loss: 2.929367188484438

Epoch: 6| Step: 2
Training loss: 3.0708773136138916
Validation loss: 2.923284843403806

Epoch: 6| Step: 3
Training loss: 2.518864393234253
Validation loss: 2.9200831869597077

Epoch: 6| Step: 4
Training loss: 1.8953430652618408
Validation loss: 2.9189525599120767

Epoch: 6| Step: 5
Training loss: 3.4569666385650635
Validation loss: 2.9142031131252164

Epoch: 6| Step: 6
Training loss: 2.8903098106384277
Validation loss: 2.919155187504266

Epoch: 6| Step: 7
Training loss: 3.064049243927002
Validation loss: 2.923203388849894

Epoch: 6| Step: 8
Training loss: 3.327068567276001
Validation loss: 2.92046949683979

Epoch: 6| Step: 9
Training loss: 3.294039249420166
Validation loss: 2.920551574358376

Epoch: 6| Step: 10
Training loss: 3.2664437294006348
Validation loss: 2.9171844836204284

Epoch: 6| Step: 11
Training loss: 3.6295621395111084
Validation loss: 2.913292428498627

Epoch: 6| Step: 12
Training loss: 2.3747403621673584
Validation loss: 2.911748509253225

Epoch: 6| Step: 13
Training loss: 3.1129703521728516
Validation loss: 2.9105459285038773

Epoch: 30| Step: 0
Training loss: 2.7582716941833496
Validation loss: 2.9124446709950766

Epoch: 6| Step: 1
Training loss: 2.739499807357788
Validation loss: 2.9167267891668502

Epoch: 6| Step: 2
Training loss: 2.5089809894561768
Validation loss: 2.9321987141845045

Epoch: 6| Step: 3
Training loss: 2.3766441345214844
Validation loss: 2.930641505026048

Epoch: 6| Step: 4
Training loss: 2.506840229034424
Validation loss: 2.917998093430714

Epoch: 6| Step: 5
Training loss: 3.3255393505096436
Validation loss: 2.908290957891813

Epoch: 6| Step: 6
Training loss: 2.80241060256958
Validation loss: 2.9129060724730134

Epoch: 6| Step: 7
Training loss: 3.1715211868286133
Validation loss: 2.9100991987412974

Epoch: 6| Step: 8
Training loss: 3.909752368927002
Validation loss: 2.910446572047408

Epoch: 6| Step: 9
Training loss: 3.0483031272888184
Validation loss: 2.910992532648066

Epoch: 6| Step: 10
Training loss: 3.713789701461792
Validation loss: 2.9073007901509604

Epoch: 6| Step: 11
Training loss: 3.5516672134399414
Validation loss: 2.907128369936379

Epoch: 6| Step: 12
Training loss: 2.525888442993164
Validation loss: 2.9049918472125964

Epoch: 6| Step: 13
Training loss: 3.1364986896514893
Validation loss: 2.908550839270315

Epoch: 31| Step: 0
Training loss: 3.069593906402588
Validation loss: 2.9224144797171316

Epoch: 6| Step: 1
Training loss: 2.4902384281158447
Validation loss: 2.919180272727884

Epoch: 6| Step: 2
Training loss: 1.701673150062561
Validation loss: 2.9170141194456365

Epoch: 6| Step: 3
Training loss: 3.1912035942077637
Validation loss: 2.9153673033560477

Epoch: 6| Step: 4
Training loss: 3.103851318359375
Validation loss: 2.915201033315351

Epoch: 6| Step: 5
Training loss: 2.467245578765869
Validation loss: 2.90468418469993

Epoch: 6| Step: 6
Training loss: 3.772555112838745
Validation loss: 2.8993869878912486

Epoch: 6| Step: 7
Training loss: 2.9039907455444336
Validation loss: 2.903092899630147

Epoch: 6| Step: 8
Training loss: 3.1901333332061768
Validation loss: 2.9062717371089484

Epoch: 6| Step: 9
Training loss: 2.685055732727051
Validation loss: 2.899640631932084

Epoch: 6| Step: 10
Training loss: 3.385835647583008
Validation loss: 2.8961474613476823

Epoch: 6| Step: 11
Training loss: 3.576176166534424
Validation loss: 2.89700791399966

Epoch: 6| Step: 12
Training loss: 3.177455425262451
Validation loss: 2.9017828946472495

Epoch: 6| Step: 13
Training loss: 3.4448649883270264
Validation loss: 2.9067395015429427

Epoch: 32| Step: 0
Training loss: 4.281345844268799
Validation loss: 2.9105818117818525

Epoch: 6| Step: 1
Training loss: 3.441598415374756
Validation loss: 2.9078109648919876

Epoch: 6| Step: 2
Training loss: 2.732698917388916
Validation loss: 2.9056057929992676

Epoch: 6| Step: 3
Training loss: 2.0043699741363525
Validation loss: 2.8951718294492332

Epoch: 6| Step: 4
Training loss: 3.193328857421875
Validation loss: 2.895173675270491

Epoch: 6| Step: 5
Training loss: 2.6139206886291504
Validation loss: 2.8930186328067573

Epoch: 6| Step: 6
Training loss: 2.6452512741088867
Validation loss: 2.8950247738950994

Epoch: 6| Step: 7
Training loss: 3.4110326766967773
Validation loss: 2.895868211664179

Epoch: 6| Step: 8
Training loss: 2.789973258972168
Validation loss: 2.8925662194528887

Epoch: 6| Step: 9
Training loss: 3.260207414627075
Validation loss: 2.8914549068738054

Epoch: 6| Step: 10
Training loss: 3.5008058547973633
Validation loss: 2.892650035119826

Epoch: 6| Step: 11
Training loss: 2.578281879425049
Validation loss: 2.8891475995381675

Epoch: 6| Step: 12
Training loss: 2.509082794189453
Validation loss: 2.8888996339613393

Epoch: 6| Step: 13
Training loss: 2.829247236251831
Validation loss: 2.889944509793353

Epoch: 33| Step: 0
Training loss: 3.4308743476867676
Validation loss: 2.8924356711808072

Epoch: 6| Step: 1
Training loss: 3.2327237129211426
Validation loss: 2.893546632541123

Epoch: 6| Step: 2
Training loss: 2.6906630992889404
Validation loss: 2.8924784634702947

Epoch: 6| Step: 3
Training loss: 3.934753656387329
Validation loss: 2.895554463068644

Epoch: 6| Step: 4
Training loss: 3.624638557434082
Validation loss: 2.8958232248983076

Epoch: 6| Step: 5
Training loss: 3.111879587173462
Validation loss: 2.8913613724452194

Epoch: 6| Step: 6
Training loss: 2.7051117420196533
Validation loss: 2.8851037281815723

Epoch: 6| Step: 7
Training loss: 2.69084095954895
Validation loss: 2.8838302909687

Epoch: 6| Step: 8
Training loss: 3.2462072372436523
Validation loss: 2.885891027348016

Epoch: 6| Step: 9
Training loss: 2.881747245788574
Validation loss: 2.8848774868954896

Epoch: 6| Step: 10
Training loss: 2.0301249027252197
Validation loss: 2.8863184067510788

Epoch: 6| Step: 11
Training loss: 2.568669557571411
Validation loss: 2.8836991812593196

Epoch: 6| Step: 12
Training loss: 2.618795394897461
Validation loss: 2.8835973995988087

Epoch: 6| Step: 13
Training loss: 2.9706668853759766
Validation loss: 2.882899486890403

Epoch: 34| Step: 0
Training loss: 3.0300800800323486
Validation loss: 2.879389088640931

Epoch: 6| Step: 1
Training loss: 3.244563102722168
Validation loss: 2.878666739309988

Epoch: 6| Step: 2
Training loss: 2.7778525352478027
Validation loss: 2.8829558587843374

Epoch: 6| Step: 3
Training loss: 2.53265380859375
Validation loss: 2.8944633955596597

Epoch: 6| Step: 4
Training loss: 2.1000938415527344
Validation loss: 2.8923427366441294

Epoch: 6| Step: 5
Training loss: 2.668142318725586
Validation loss: 2.8992465875482045

Epoch: 6| Step: 6
Training loss: 3.56735897064209
Validation loss: 2.898961018490535

Epoch: 6| Step: 7
Training loss: 3.12758731842041
Validation loss: 2.8908939194935623

Epoch: 6| Step: 8
Training loss: 3.3968710899353027
Validation loss: 2.8795476600687993

Epoch: 6| Step: 9
Training loss: 3.638786792755127
Validation loss: 2.876315729592436

Epoch: 6| Step: 10
Training loss: 3.359619140625
Validation loss: 2.872902126722438

Epoch: 6| Step: 11
Training loss: 2.386045455932617
Validation loss: 2.8827698333289034

Epoch: 6| Step: 12
Training loss: 2.641873836517334
Validation loss: 2.8785093215204056

Epoch: 6| Step: 13
Training loss: 3.47567081451416
Validation loss: 2.8775204919999644

Epoch: 35| Step: 0
Training loss: 2.299865484237671
Validation loss: 2.8739281931231098

Epoch: 6| Step: 1
Training loss: 3.880331516265869
Validation loss: 2.874883710697133

Epoch: 6| Step: 2
Training loss: 3.313312530517578
Validation loss: 2.873168278765935

Epoch: 6| Step: 3
Training loss: 3.080871105194092
Validation loss: 2.8734181619459584

Epoch: 6| Step: 4
Training loss: 3.133397102355957
Validation loss: 2.8742865644475466

Epoch: 6| Step: 5
Training loss: 2.4597678184509277
Validation loss: 2.87464314891446

Epoch: 6| Step: 6
Training loss: 3.691044807434082
Validation loss: 2.878603319967947

Epoch: 6| Step: 7
Training loss: 2.2785849571228027
Validation loss: 2.876734305453557

Epoch: 6| Step: 8
Training loss: 2.419221878051758
Validation loss: 2.873456703719272

Epoch: 6| Step: 9
Training loss: 4.019231796264648
Validation loss: 2.8771759745895222

Epoch: 6| Step: 10
Training loss: 3.2686634063720703
Validation loss: 2.875767300205846

Epoch: 6| Step: 11
Training loss: 1.7915185689926147
Validation loss: 2.873801008347542

Epoch: 6| Step: 12
Training loss: 3.1606054306030273
Validation loss: 2.8726982532009

Epoch: 6| Step: 13
Training loss: 2.601536273956299
Validation loss: 2.8746732434918805

Epoch: 36| Step: 0
Training loss: 3.345632553100586
Validation loss: 2.8723121279029438

Epoch: 6| Step: 1
Training loss: 2.473158836364746
Validation loss: 2.867832399183704

Epoch: 6| Step: 2
Training loss: 3.8047449588775635
Validation loss: 2.869224476557906

Epoch: 6| Step: 3
Training loss: 2.494438648223877
Validation loss: 2.864834434242659

Epoch: 6| Step: 4
Training loss: 3.243086338043213
Validation loss: 2.866777184189007

Epoch: 6| Step: 5
Training loss: 2.6108076572418213
Validation loss: 2.8688507874806723

Epoch: 6| Step: 6
Training loss: 2.1811647415161133
Validation loss: 2.8668341841748965

Epoch: 6| Step: 7
Training loss: 2.9141383171081543
Validation loss: 2.866240393730902

Epoch: 6| Step: 8
Training loss: 3.1412646770477295
Validation loss: 2.864054810616278

Epoch: 6| Step: 9
Training loss: 3.4773404598236084
Validation loss: 2.865023269448229

Epoch: 6| Step: 10
Training loss: 3.479020118713379
Validation loss: 2.8636509885070143

Epoch: 6| Step: 11
Training loss: 2.8425440788269043
Validation loss: 2.867922495770198

Epoch: 6| Step: 12
Training loss: 3.0627899169921875
Validation loss: 2.8683204215059996

Epoch: 6| Step: 13
Training loss: 2.053227186203003
Validation loss: 2.864741425360403

Epoch: 37| Step: 0
Training loss: 3.319683790206909
Validation loss: 2.8649080748199136

Epoch: 6| Step: 1
Training loss: 2.3828577995300293
Validation loss: 2.863853539189985

Epoch: 6| Step: 2
Training loss: 2.029120445251465
Validation loss: 2.866307561115552

Epoch: 6| Step: 3
Training loss: 3.7347049713134766
Validation loss: 2.862783052588022

Epoch: 6| Step: 4
Training loss: 3.216921091079712
Validation loss: 2.861453281935825

Epoch: 6| Step: 5
Training loss: 2.6919164657592773
Validation loss: 2.8595683702858548

Epoch: 6| Step: 6
Training loss: 3.4097495079040527
Validation loss: 2.8613655823533253

Epoch: 6| Step: 7
Training loss: 2.6839592456817627
Validation loss: 2.8606453275167816

Epoch: 6| Step: 8
Training loss: 2.5889792442321777
Validation loss: 2.857964164467268

Epoch: 6| Step: 9
Training loss: 2.517831802368164
Validation loss: 2.8603117747973372

Epoch: 6| Step: 10
Training loss: 3.414060354232788
Validation loss: 2.859377307276572

Epoch: 6| Step: 11
Training loss: 3.0070724487304688
Validation loss: 2.859494491290021

Epoch: 6| Step: 12
Training loss: 3.6524040699005127
Validation loss: 2.858519520810855

Epoch: 6| Step: 13
Training loss: 2.727550745010376
Validation loss: 2.8600732844362975

Epoch: 38| Step: 0
Training loss: 3.741856575012207
Validation loss: 2.860365388213947

Epoch: 6| Step: 1
Training loss: 2.1346020698547363
Validation loss: 2.8601048325979583

Epoch: 6| Step: 2
Training loss: 2.0174448490142822
Validation loss: 2.8607887068102436

Epoch: 6| Step: 3
Training loss: 2.0388870239257812
Validation loss: 2.858323376665833

Epoch: 6| Step: 4
Training loss: 2.8414907455444336
Validation loss: 2.8568364163880706

Epoch: 6| Step: 5
Training loss: 3.7300236225128174
Validation loss: 2.8598924811168382

Epoch: 6| Step: 6
Training loss: 3.132467746734619
Validation loss: 2.858675520907166

Epoch: 6| Step: 7
Training loss: 3.1444501876831055
Validation loss: 2.859344005584717

Epoch: 6| Step: 8
Training loss: 3.006455659866333
Validation loss: 2.859141854829686

Epoch: 6| Step: 9
Training loss: 3.4342803955078125
Validation loss: 2.8589492049268497

Epoch: 6| Step: 10
Training loss: 3.900937557220459
Validation loss: 2.85678449497428

Epoch: 6| Step: 11
Training loss: 3.2614614963531494
Validation loss: 2.855670944336922

Epoch: 6| Step: 12
Training loss: 2.5472898483276367
Validation loss: 2.857160165745725

Epoch: 6| Step: 13
Training loss: 2.151681661605835
Validation loss: 2.8537362775494977

Epoch: 39| Step: 0
Training loss: 3.2498483657836914
Validation loss: 2.854208105353899

Epoch: 6| Step: 1
Training loss: 2.8036866188049316
Validation loss: 2.8544638515800558

Epoch: 6| Step: 2
Training loss: 2.4334962368011475
Validation loss: 2.855823778337048

Epoch: 6| Step: 3
Training loss: 3.366489887237549
Validation loss: 2.8561106010149886

Epoch: 6| Step: 4
Training loss: 3.6155452728271484
Validation loss: 2.8559770379015195

Epoch: 6| Step: 5
Training loss: 2.6626322269439697
Validation loss: 2.859519761095765

Epoch: 6| Step: 6
Training loss: 2.89675235748291
Validation loss: 2.8651493954402145

Epoch: 6| Step: 7
Training loss: 2.706115484237671
Validation loss: 2.860717401709608

Epoch: 6| Step: 8
Training loss: 2.88722562789917
Validation loss: 2.8570912986673336

Epoch: 6| Step: 9
Training loss: 3.250243902206421
Validation loss: 2.8531458788020636

Epoch: 6| Step: 10
Training loss: 3.271481513977051
Validation loss: 2.852192986396051

Epoch: 6| Step: 11
Training loss: 2.3981480598449707
Validation loss: 2.8497985255333687

Epoch: 6| Step: 12
Training loss: 2.9450860023498535
Validation loss: 2.8489560619477303

Epoch: 6| Step: 13
Training loss: 2.8945302963256836
Validation loss: 2.849736982776273

Epoch: 40| Step: 0
Training loss: 2.248206615447998
Validation loss: 2.8504474701419955

Epoch: 6| Step: 1
Training loss: 3.387444019317627
Validation loss: 2.850782525154852

Epoch: 6| Step: 2
Training loss: 3.276576519012451
Validation loss: 2.8474204694071124

Epoch: 6| Step: 3
Training loss: 3.251681327819824
Validation loss: 2.8512297907183246

Epoch: 6| Step: 4
Training loss: 2.546844959259033
Validation loss: 2.8497422664396224

Epoch: 6| Step: 5
Training loss: 2.5588905811309814
Validation loss: 2.8538721607577417

Epoch: 6| Step: 6
Training loss: 3.7702796459198
Validation loss: 2.8563421157098587

Epoch: 6| Step: 7
Training loss: 2.4458365440368652
Validation loss: 2.8609967821387836

Epoch: 6| Step: 8
Training loss: 2.4482340812683105
Validation loss: 2.855501041617445

Epoch: 6| Step: 9
Training loss: 3.4453582763671875
Validation loss: 2.8560850645906184

Epoch: 6| Step: 10
Training loss: 2.9852333068847656
Validation loss: 2.8553753591352895

Epoch: 6| Step: 11
Training loss: 2.3984997272491455
Validation loss: 2.848642313352195

Epoch: 6| Step: 12
Training loss: 3.632383346557617
Validation loss: 2.8474923692723757

Epoch: 6| Step: 13
Training loss: 3.047558546066284
Validation loss: 2.847314993540446

Epoch: 41| Step: 0
Training loss: 3.133530378341675
Validation loss: 2.8470662768169115

Epoch: 6| Step: 1
Training loss: 2.849698305130005
Validation loss: 2.847073365283269

Epoch: 6| Step: 2
Training loss: 4.411378383636475
Validation loss: 2.8452573437844553

Epoch: 6| Step: 3
Training loss: 2.242069721221924
Validation loss: 2.84810290028972

Epoch: 6| Step: 4
Training loss: 2.814678430557251
Validation loss: 2.8466399741429154

Epoch: 6| Step: 5
Training loss: 3.647773265838623
Validation loss: 2.8444570623418337

Epoch: 6| Step: 6
Training loss: 3.406616687774658
Validation loss: 2.84261514038168

Epoch: 6| Step: 7
Training loss: 2.1319832801818848
Validation loss: 2.8456639500074488

Epoch: 6| Step: 8
Training loss: 2.0648789405822754
Validation loss: 2.8462943210396716

Epoch: 6| Step: 9
Training loss: 2.427248954772949
Validation loss: 2.84471397502448

Epoch: 6| Step: 10
Training loss: 2.8031997680664062
Validation loss: 2.8496945186327864

Epoch: 6| Step: 11
Training loss: 3.2271058559417725
Validation loss: 2.8462744964066373

Epoch: 6| Step: 12
Training loss: 3.0983378887176514
Validation loss: 2.8428201060141287

Epoch: 6| Step: 13
Training loss: 3.141340970993042
Validation loss: 2.8458612247179915

Epoch: 42| Step: 0
Training loss: 3.198578119277954
Validation loss: 2.8406424624945528

Epoch: 6| Step: 1
Training loss: 3.4179954528808594
Validation loss: 2.8433640285204818

Epoch: 6| Step: 2
Training loss: 2.3677940368652344
Validation loss: 2.841686120597265

Epoch: 6| Step: 3
Training loss: 3.1025941371917725
Validation loss: 2.842962752106369

Epoch: 6| Step: 4
Training loss: 2.7169485092163086
Validation loss: 2.8410640301242953

Epoch: 6| Step: 5
Training loss: 3.1363883018493652
Validation loss: 2.8422977360345985

Epoch: 6| Step: 6
Training loss: 2.3628134727478027
Validation loss: 2.8403984859425533

Epoch: 6| Step: 7
Training loss: 3.1950535774230957
Validation loss: 2.842699363667478

Epoch: 6| Step: 8
Training loss: 2.984142303466797
Validation loss: 2.838176750367688

Epoch: 6| Step: 9
Training loss: 3.6266629695892334
Validation loss: 2.8383019098671536

Epoch: 6| Step: 10
Training loss: 2.2620835304260254
Validation loss: 2.839398196948472

Epoch: 6| Step: 11
Training loss: 2.599097728729248
Validation loss: 2.838457606172049

Epoch: 6| Step: 12
Training loss: 3.530221462249756
Validation loss: 2.836622538105134

Epoch: 6| Step: 13
Training loss: 2.649420738220215
Validation loss: 2.8392886090022262

Epoch: 43| Step: 0
Training loss: 3.064469337463379
Validation loss: 2.8405841012154855

Epoch: 6| Step: 1
Training loss: 2.888965129852295
Validation loss: 2.83739350944437

Epoch: 6| Step: 2
Training loss: 3.623568058013916
Validation loss: 2.8387596094480125

Epoch: 6| Step: 3
Training loss: 2.790198802947998
Validation loss: 2.8398948484851467

Epoch: 6| Step: 4
Training loss: 2.2502057552337646
Validation loss: 2.845249447771298

Epoch: 6| Step: 5
Training loss: 2.6472928524017334
Validation loss: 2.8370863263325026

Epoch: 6| Step: 6
Training loss: 3.107241630554199
Validation loss: 2.8420135821065595

Epoch: 6| Step: 7
Training loss: 2.6271705627441406
Validation loss: 2.8383148921433317

Epoch: 6| Step: 8
Training loss: 2.5181291103363037
Validation loss: 2.8358176498002905

Epoch: 6| Step: 9
Training loss: 2.571960926055908
Validation loss: 2.8359978942460913

Epoch: 6| Step: 10
Training loss: 2.718728542327881
Validation loss: 2.835443240340038

Epoch: 6| Step: 11
Training loss: 3.3484818935394287
Validation loss: 2.8352318066422657

Epoch: 6| Step: 12
Training loss: 3.990461826324463
Validation loss: 2.8357390178147184

Epoch: 6| Step: 13
Training loss: 3.223118305206299
Validation loss: 2.8351778958433416

Epoch: 44| Step: 0
Training loss: 3.756312847137451
Validation loss: 2.8367716907173075

Epoch: 6| Step: 1
Training loss: 3.014631509780884
Validation loss: 2.8356203750897477

Epoch: 6| Step: 2
Training loss: 2.125441551208496
Validation loss: 2.836661743861373

Epoch: 6| Step: 3
Training loss: 3.4591407775878906
Validation loss: 2.836952540182298

Epoch: 6| Step: 4
Training loss: 2.425873279571533
Validation loss: 2.833810939583727

Epoch: 6| Step: 5
Training loss: 3.4604482650756836
Validation loss: 2.8349135306573685

Epoch: 6| Step: 6
Training loss: 3.290342330932617
Validation loss: 2.8309351039189163

Epoch: 6| Step: 7
Training loss: 2.1461892127990723
Validation loss: 2.833680442584458

Epoch: 6| Step: 8
Training loss: 3.529001235961914
Validation loss: 2.830444871738393

Epoch: 6| Step: 9
Training loss: 2.9150753021240234
Validation loss: 2.8346374137427217

Epoch: 6| Step: 10
Training loss: 3.016458749771118
Validation loss: 2.833566757940477

Epoch: 6| Step: 11
Training loss: 2.189011573791504
Validation loss: 2.831742686610068

Epoch: 6| Step: 12
Training loss: 2.3865225315093994
Validation loss: 2.8326525226716073

Epoch: 6| Step: 13
Training loss: 3.9007067680358887
Validation loss: 2.8318498365340696

Epoch: 45| Step: 0
Training loss: 3.1825168132781982
Validation loss: 2.8325275041723765

Epoch: 6| Step: 1
Training loss: 3.4144487380981445
Validation loss: 2.8341258110538607

Epoch: 6| Step: 2
Training loss: 3.5019912719726562
Validation loss: 2.8309213551141883

Epoch: 6| Step: 3
Training loss: 2.7692298889160156
Validation loss: 2.834123052576537

Epoch: 6| Step: 4
Training loss: 4.037115097045898
Validation loss: 2.8319888858384985

Epoch: 6| Step: 5
Training loss: 2.708411455154419
Validation loss: 2.831206626789544

Epoch: 6| Step: 6
Training loss: 2.5223379135131836
Validation loss: 2.8318957923561014

Epoch: 6| Step: 7
Training loss: 2.5209848880767822
Validation loss: 2.8269057863502094

Epoch: 6| Step: 8
Training loss: 2.4627652168273926
Validation loss: 2.833032907978181

Epoch: 6| Step: 9
Training loss: 2.3703060150146484
Validation loss: 2.8309036095937095

Epoch: 6| Step: 10
Training loss: 2.211674690246582
Validation loss: 2.8305575950171358

Epoch: 6| Step: 11
Training loss: 3.194530487060547
Validation loss: 2.8293996728876585

Epoch: 6| Step: 12
Training loss: 2.714555025100708
Validation loss: 2.827800653314078

Epoch: 6| Step: 13
Training loss: 3.9999020099639893
Validation loss: 2.8284705761940248

Epoch: 46| Step: 0
Training loss: 1.5755641460418701
Validation loss: 2.8290654279852427

Epoch: 6| Step: 1
Training loss: 2.271967887878418
Validation loss: 2.8287793615812897

Epoch: 6| Step: 2
Training loss: 4.149631500244141
Validation loss: 2.833231472199963

Epoch: 6| Step: 3
Training loss: 2.9200172424316406
Validation loss: 2.8346939753460627

Epoch: 6| Step: 4
Training loss: 2.9026038646698
Validation loss: 2.8257740313006985

Epoch: 6| Step: 5
Training loss: 3.225257158279419
Validation loss: 2.8273528827134

Epoch: 6| Step: 6
Training loss: 3.709780693054199
Validation loss: 2.82346652143745

Epoch: 6| Step: 7
Training loss: 1.981773853302002
Validation loss: 2.824619908486643

Epoch: 6| Step: 8
Training loss: 2.2192559242248535
Validation loss: 2.823556084786692

Epoch: 6| Step: 9
Training loss: 3.3573191165924072
Validation loss: 2.821305772309662

Epoch: 6| Step: 10
Training loss: 3.6171317100524902
Validation loss: 2.821975267061623

Epoch: 6| Step: 11
Training loss: 3.3700971603393555
Validation loss: 2.8262588054903093

Epoch: 6| Step: 12
Training loss: 3.1365346908569336
Validation loss: 2.8285115611168647

Epoch: 6| Step: 13
Training loss: 2.481058359146118
Validation loss: 2.8359907442523586

Epoch: 47| Step: 0
Training loss: 3.478853940963745
Validation loss: 2.829909860446889

Epoch: 6| Step: 1
Training loss: 3.153254747390747
Validation loss: 2.8240347088024182

Epoch: 6| Step: 2
Training loss: 2.544184923171997
Validation loss: 2.825258965133339

Epoch: 6| Step: 3
Training loss: 3.043645143508911
Validation loss: 2.820882684441023

Epoch: 6| Step: 4
Training loss: 1.7329692840576172
Validation loss: 2.8213128043759252

Epoch: 6| Step: 5
Training loss: 2.60550594329834
Validation loss: 2.815933712067143

Epoch: 6| Step: 6
Training loss: 3.4307730197906494
Validation loss: 2.8213812330717682

Epoch: 6| Step: 7
Training loss: 2.398193836212158
Validation loss: 2.820068695211923

Epoch: 6| Step: 8
Training loss: 3.387129545211792
Validation loss: 2.816238744284517

Epoch: 6| Step: 9
Training loss: 3.6910157203674316
Validation loss: 2.8188418649858042

Epoch: 6| Step: 10
Training loss: 3.252925157546997
Validation loss: 2.822089784888811

Epoch: 6| Step: 11
Training loss: 2.946516752243042
Validation loss: 2.8184841935352614

Epoch: 6| Step: 12
Training loss: 2.7311062812805176
Validation loss: 2.8197819596977642

Epoch: 6| Step: 13
Training loss: 2.409543037414551
Validation loss: 2.8185315978142524

Epoch: 48| Step: 0
Training loss: 2.3325915336608887
Validation loss: 2.8145683503920034

Epoch: 6| Step: 1
Training loss: 3.392049789428711
Validation loss: 2.815275740879838

Epoch: 6| Step: 2
Training loss: 2.4039711952209473
Validation loss: 2.8123915144192275

Epoch: 6| Step: 3
Training loss: 2.5925827026367188
Validation loss: 2.8121950754555325

Epoch: 6| Step: 4
Training loss: 2.204441547393799
Validation loss: 2.811599200771701

Epoch: 6| Step: 5
Training loss: 3.108628988265991
Validation loss: 2.8135183447150776

Epoch: 6| Step: 6
Training loss: 3.2063770294189453
Validation loss: 2.809229279077181

Epoch: 6| Step: 7
Training loss: 4.291715145111084
Validation loss: 2.813462908549975

Epoch: 6| Step: 8
Training loss: 2.717402219772339
Validation loss: 2.808433481442031

Epoch: 6| Step: 9
Training loss: 3.4086413383483887
Validation loss: 2.8089372906633603

Epoch: 6| Step: 10
Training loss: 1.8100945949554443
Validation loss: 2.8109009009535595

Epoch: 6| Step: 11
Training loss: 2.3568456172943115
Validation loss: 2.810530206208588

Epoch: 6| Step: 12
Training loss: 3.6639676094055176
Validation loss: 2.8107822043921358

Epoch: 6| Step: 13
Training loss: 3.9509310722351074
Validation loss: 2.8173389665542112

Epoch: 49| Step: 0
Training loss: 2.869635581970215
Validation loss: 2.8135946566058743

Epoch: 6| Step: 1
Training loss: 3.7745261192321777
Validation loss: 2.8082941552644134

Epoch: 6| Step: 2
Training loss: 2.684025287628174
Validation loss: 2.8089065013393277

Epoch: 6| Step: 3
Training loss: 2.7629101276397705
Validation loss: 2.8081822831143617

Epoch: 6| Step: 4
Training loss: 1.9799246788024902
Validation loss: 2.8076331333447526

Epoch: 6| Step: 5
Training loss: 3.5557684898376465
Validation loss: 2.814256621945289

Epoch: 6| Step: 6
Training loss: 2.780085563659668
Validation loss: 2.809058940538796

Epoch: 6| Step: 7
Training loss: 2.793194055557251
Validation loss: 2.8132021119517665

Epoch: 6| Step: 8
Training loss: 3.3683714866638184
Validation loss: 2.8165027736335673

Epoch: 6| Step: 9
Training loss: 3.1990036964416504
Validation loss: 2.8112365943129345

Epoch: 6| Step: 10
Training loss: 2.661008358001709
Validation loss: 2.813724074312436

Epoch: 6| Step: 11
Training loss: 3.554090976715088
Validation loss: 2.8104081666597756

Epoch: 6| Step: 12
Training loss: 2.651226043701172
Validation loss: 2.808726720912482

Epoch: 6| Step: 13
Training loss: 1.9629238843917847
Validation loss: 2.8094052294249177

Epoch: 50| Step: 0
Training loss: 2.529458522796631
Validation loss: 2.8080987776479414

Epoch: 6| Step: 1
Training loss: 2.5696377754211426
Validation loss: 2.8052798009687856

Epoch: 6| Step: 2
Training loss: 2.4899356365203857
Validation loss: 2.8061255408871557

Epoch: 6| Step: 3
Training loss: 3.2769198417663574
Validation loss: 2.8060033090652956

Epoch: 6| Step: 4
Training loss: 2.7800941467285156
Validation loss: 2.8023265305385796

Epoch: 6| Step: 5
Training loss: 3.479552745819092
Validation loss: 2.8021615653909664

Epoch: 6| Step: 6
Training loss: 2.925469398498535
Validation loss: 2.8012901301025064

Epoch: 6| Step: 7
Training loss: 3.5133132934570312
Validation loss: 2.8054775960983767

Epoch: 6| Step: 8
Training loss: 2.5395469665527344
Validation loss: 2.7985479395876647

Epoch: 6| Step: 9
Training loss: 3.8598573207855225
Validation loss: 2.808837645797319

Epoch: 6| Step: 10
Training loss: 2.7939910888671875
Validation loss: 2.8044694367275445

Epoch: 6| Step: 11
Training loss: 2.6471705436706543
Validation loss: 2.813857909171812

Epoch: 6| Step: 12
Training loss: 2.751636028289795
Validation loss: 2.8077267933917303

Epoch: 6| Step: 13
Training loss: 2.591087579727173
Validation loss: 2.805760866852217

Epoch: 51| Step: 0
Training loss: 3.694455862045288
Validation loss: 2.8033584676763064

Epoch: 6| Step: 1
Training loss: 3.2326879501342773
Validation loss: 2.7992347953140095

Epoch: 6| Step: 2
Training loss: 2.752821683883667
Validation loss: 2.799030557755501

Epoch: 6| Step: 3
Training loss: 2.6405367851257324
Validation loss: 2.8035497357768397

Epoch: 6| Step: 4
Training loss: 2.508312702178955
Validation loss: 2.8029712477037982

Epoch: 6| Step: 5
Training loss: 3.2483346462249756
Validation loss: 2.8013278156198482

Epoch: 6| Step: 6
Training loss: 2.6523871421813965
Validation loss: 2.8026887934695006

Epoch: 6| Step: 7
Training loss: 2.9322452545166016
Validation loss: 2.80585297717843

Epoch: 6| Step: 8
Training loss: 2.990708827972412
Validation loss: 2.8024632136027017

Epoch: 6| Step: 9
Training loss: 3.3996689319610596
Validation loss: 2.801491424601565

Epoch: 6| Step: 10
Training loss: 1.9518401622772217
Validation loss: 2.803613552483179

Epoch: 6| Step: 11
Training loss: 2.6036133766174316
Validation loss: 2.8064454524747786

Epoch: 6| Step: 12
Training loss: 3.543574333190918
Validation loss: 2.8078258191385577

Epoch: 6| Step: 13
Training loss: 2.672603130340576
Validation loss: 2.810895312216974

Epoch: 52| Step: 0
Training loss: 3.2049918174743652
Validation loss: 2.806556563223562

Epoch: 6| Step: 1
Training loss: 2.582237482070923
Validation loss: 2.8088542722886607

Epoch: 6| Step: 2
Training loss: 3.203407049179077
Validation loss: 2.8005837343072377

Epoch: 6| Step: 3
Training loss: 2.7849442958831787
Validation loss: 2.801077163347634

Epoch: 6| Step: 4
Training loss: 3.6527228355407715
Validation loss: 2.797114433780793

Epoch: 6| Step: 5
Training loss: 2.4737586975097656
Validation loss: 2.798828012199812

Epoch: 6| Step: 6
Training loss: 2.4280476570129395
Validation loss: 2.794847357657648

Epoch: 6| Step: 7
Training loss: 3.558454990386963
Validation loss: 2.795603459881198

Epoch: 6| Step: 8
Training loss: 2.585982322692871
Validation loss: 2.7955405635218464

Epoch: 6| Step: 9
Training loss: 3.18855881690979
Validation loss: 2.7976769939545663

Epoch: 6| Step: 10
Training loss: 3.1668379306793213
Validation loss: 2.799227042864728

Epoch: 6| Step: 11
Training loss: 2.1683878898620605
Validation loss: 2.7990329727049796

Epoch: 6| Step: 12
Training loss: 2.962693691253662
Validation loss: 2.7956870140567904

Epoch: 6| Step: 13
Training loss: 2.9077608585357666
Validation loss: 2.7952510310757543

Epoch: 53| Step: 0
Training loss: 3.2495319843292236
Validation loss: 2.795960444276051

Epoch: 6| Step: 1
Training loss: 3.3668875694274902
Validation loss: 2.7971137133977746

Epoch: 6| Step: 2
Training loss: 3.797828197479248
Validation loss: 2.7930845804111932

Epoch: 6| Step: 3
Training loss: 2.897007942199707
Validation loss: 2.794608780132827

Epoch: 6| Step: 4
Training loss: 2.863013505935669
Validation loss: 2.7956569502430577

Epoch: 6| Step: 5
Training loss: 2.5410094261169434
Validation loss: 2.794364995853875

Epoch: 6| Step: 6
Training loss: 3.160478115081787
Validation loss: 2.7964676605757846

Epoch: 6| Step: 7
Training loss: 2.7518649101257324
Validation loss: 2.7930433263060865

Epoch: 6| Step: 8
Training loss: 3.2655162811279297
Validation loss: 2.7901873870562484

Epoch: 6| Step: 9
Training loss: 2.2200708389282227
Validation loss: 2.792208020405103

Epoch: 6| Step: 10
Training loss: 2.1615631580352783
Validation loss: 2.795399517141363

Epoch: 6| Step: 11
Training loss: 3.294848918914795
Validation loss: 2.7917146041829097

Epoch: 6| Step: 12
Training loss: 2.2690634727478027
Validation loss: 2.7909411409849763

Epoch: 6| Step: 13
Training loss: 2.9880306720733643
Validation loss: 2.792008182053925

Epoch: 54| Step: 0
Training loss: 3.065481662750244
Validation loss: 2.791874821468066

Epoch: 6| Step: 1
Training loss: 3.45182466506958
Validation loss: 2.790672720119517

Epoch: 6| Step: 2
Training loss: 2.747004508972168
Validation loss: 2.7923320672845326

Epoch: 6| Step: 3
Training loss: 2.933781147003174
Validation loss: 2.789911416269118

Epoch: 6| Step: 4
Training loss: 3.226180076599121
Validation loss: 2.7899317818303264

Epoch: 6| Step: 5
Training loss: 3.283043384552002
Validation loss: 2.7906668391278995

Epoch: 6| Step: 6
Training loss: 2.5181732177734375
Validation loss: 2.784506674735777

Epoch: 6| Step: 7
Training loss: 2.9564266204833984
Validation loss: 2.7887920307856735

Epoch: 6| Step: 8
Training loss: 3.2398855686187744
Validation loss: 2.7858396832660963

Epoch: 6| Step: 9
Training loss: 2.5393826961517334
Validation loss: 2.7844296962984147

Epoch: 6| Step: 10
Training loss: 3.0409793853759766
Validation loss: 2.7853889721696095

Epoch: 6| Step: 11
Training loss: 2.362484931945801
Validation loss: 2.786328725917365

Epoch: 6| Step: 12
Training loss: 2.20249080657959
Validation loss: 2.782930850982666

Epoch: 6| Step: 13
Training loss: 3.382417678833008
Validation loss: 2.788554722262967

Epoch: 55| Step: 0
Training loss: 2.589738368988037
Validation loss: 2.784666162665172

Epoch: 6| Step: 1
Training loss: 3.424633741378784
Validation loss: 2.784045632167529

Epoch: 6| Step: 2
Training loss: 3.1097660064697266
Validation loss: 2.786113423685874

Epoch: 6| Step: 3
Training loss: 3.9473023414611816
Validation loss: 2.7888052899350404

Epoch: 6| Step: 4
Training loss: 3.2558064460754395
Validation loss: 2.7897749306053243

Epoch: 6| Step: 5
Training loss: 2.647599458694458
Validation loss: 2.790589173634847

Epoch: 6| Step: 6
Training loss: 2.5090131759643555
Validation loss: 2.7948874991427184

Epoch: 6| Step: 7
Training loss: 1.952972412109375
Validation loss: 2.7931573185869443

Epoch: 6| Step: 8
Training loss: 2.606308698654175
Validation loss: 2.787514773748254

Epoch: 6| Step: 9
Training loss: 2.813688039779663
Validation loss: 2.789936686074862

Epoch: 6| Step: 10
Training loss: 3.3671224117279053
Validation loss: 2.7819853469889653

Epoch: 6| Step: 11
Training loss: 2.791363477706909
Validation loss: 2.7869248800380255

Epoch: 6| Step: 12
Training loss: 2.592292308807373
Validation loss: 2.7878349340090187

Epoch: 6| Step: 13
Training loss: 3.2503466606140137
Validation loss: 2.784554568670129

Epoch: 56| Step: 0
Training loss: 2.6514086723327637
Validation loss: 2.786928105097945

Epoch: 6| Step: 1
Training loss: 2.0512619018554688
Validation loss: 2.786244461613317

Epoch: 6| Step: 2
Training loss: 2.7553796768188477
Validation loss: 2.7900392701548915

Epoch: 6| Step: 3
Training loss: 3.290647268295288
Validation loss: 2.78738336665656

Epoch: 6| Step: 4
Training loss: 3.733973741531372
Validation loss: 2.7899893765808432

Epoch: 6| Step: 5
Training loss: 2.3714728355407715
Validation loss: 2.78612793132823

Epoch: 6| Step: 6
Training loss: 2.841874599456787
Validation loss: 2.781433736124346

Epoch: 6| Step: 7
Training loss: 2.957062005996704
Validation loss: 2.7862124340508574

Epoch: 6| Step: 8
Training loss: 3.255950927734375
Validation loss: 2.7834959209606214

Epoch: 6| Step: 9
Training loss: 2.8834667205810547
Validation loss: 2.782311431823238

Epoch: 6| Step: 10
Training loss: 2.4196181297302246
Validation loss: 2.7807442449754283

Epoch: 6| Step: 11
Training loss: 3.47735857963562
Validation loss: 2.7811816635952202

Epoch: 6| Step: 12
Training loss: 3.5006651878356934
Validation loss: 2.781859523506575

Epoch: 6| Step: 13
Training loss: 2.30332612991333
Validation loss: 2.7813036672530638

Epoch: 57| Step: 0
Training loss: 3.764726400375366
Validation loss: 2.782062884299986

Epoch: 6| Step: 1
Training loss: 2.895857334136963
Validation loss: 2.7791033021865355

Epoch: 6| Step: 2
Training loss: 2.7525525093078613
Validation loss: 2.7807137350882254

Epoch: 6| Step: 3
Training loss: 1.9439924955368042
Validation loss: 2.784229042709515

Epoch: 6| Step: 4
Training loss: 3.03867244720459
Validation loss: 2.7805125405711513

Epoch: 6| Step: 5
Training loss: 2.0129966735839844
Validation loss: 2.7795138359069824

Epoch: 6| Step: 6
Training loss: 3.6281731128692627
Validation loss: 2.7819004597202426

Epoch: 6| Step: 7
Training loss: 2.674196243286133
Validation loss: 2.7834847281056065

Epoch: 6| Step: 8
Training loss: 2.906364679336548
Validation loss: 2.781726660266999

Epoch: 6| Step: 9
Training loss: 2.590768814086914
Validation loss: 2.7835361880640828

Epoch: 6| Step: 10
Training loss: 2.964709758758545
Validation loss: 2.7767175910293416

Epoch: 6| Step: 11
Training loss: 2.1576952934265137
Validation loss: 2.7786863875645462

Epoch: 6| Step: 12
Training loss: 3.999776840209961
Validation loss: 2.7763828205805954

Epoch: 6| Step: 13
Training loss: 3.5845608711242676
Validation loss: 2.7765544665757047

Epoch: 58| Step: 0
Training loss: 2.729644298553467
Validation loss: 2.7804816358832904

Epoch: 6| Step: 1
Training loss: 3.053257942199707
Validation loss: 2.774483783270723

Epoch: 6| Step: 2
Training loss: 3.235002040863037
Validation loss: 2.778711013896491

Epoch: 6| Step: 3
Training loss: 3.3759713172912598
Validation loss: 2.777004111197687

Epoch: 6| Step: 4
Training loss: 2.4245712757110596
Validation loss: 2.775005002175608

Epoch: 6| Step: 5
Training loss: 2.9745514392852783
Validation loss: 2.7781230916259108

Epoch: 6| Step: 6
Training loss: 3.264468193054199
Validation loss: 2.774542616259667

Epoch: 6| Step: 7
Training loss: 2.968391180038452
Validation loss: 2.7752497939653296

Epoch: 6| Step: 8
Training loss: 3.478646755218506
Validation loss: 2.7785445105644966

Epoch: 6| Step: 9
Training loss: 2.7612414360046387
Validation loss: 2.7732470189371417

Epoch: 6| Step: 10
Training loss: 2.574507713317871
Validation loss: 2.777752753226988

Epoch: 6| Step: 11
Training loss: 2.0308310985565186
Validation loss: 2.7738202002740677

Epoch: 6| Step: 12
Training loss: 3.178712844848633
Validation loss: 2.7734690763617076

Epoch: 6| Step: 13
Training loss: 2.2766823768615723
Validation loss: 2.777502311173306

Epoch: 59| Step: 0
Training loss: 3.3231990337371826
Validation loss: 2.775000713204825

Epoch: 6| Step: 1
Training loss: 2.288041114807129
Validation loss: 2.7750681728445072

Epoch: 6| Step: 2
Training loss: 2.9030067920684814
Validation loss: 2.775420024830808

Epoch: 6| Step: 3
Training loss: 2.683037281036377
Validation loss: 2.7801256436173634

Epoch: 6| Step: 4
Training loss: 3.51493501663208
Validation loss: 2.7888450186739684

Epoch: 6| Step: 5
Training loss: 2.5305073261260986
Validation loss: 2.7804778878406813

Epoch: 6| Step: 6
Training loss: 2.5670886039733887
Validation loss: 2.776695751374768

Epoch: 6| Step: 7
Training loss: 3.2761282920837402
Validation loss: 2.7737550735473633

Epoch: 6| Step: 8
Training loss: 2.6696505546569824
Validation loss: 2.7746194818968415

Epoch: 6| Step: 9
Training loss: 3.73996639251709
Validation loss: 2.771238588517712

Epoch: 6| Step: 10
Training loss: 3.036738395690918
Validation loss: 2.768514020468599

Epoch: 6| Step: 11
Training loss: 2.8103256225585938
Validation loss: 2.769393321006529

Epoch: 6| Step: 12
Training loss: 2.4757351875305176
Validation loss: 2.7670093531249673

Epoch: 6| Step: 13
Training loss: 2.6783294677734375
Validation loss: 2.7694303399773053

Epoch: 60| Step: 0
Training loss: 2.977526903152466
Validation loss: 2.7681311227942027

Epoch: 6| Step: 1
Training loss: 2.7530126571655273
Validation loss: 2.768832383617278

Epoch: 6| Step: 2
Training loss: 2.9798104763031006
Validation loss: 2.7654049037605204

Epoch: 6| Step: 3
Training loss: 1.8738582134246826
Validation loss: 2.767304351252894

Epoch: 6| Step: 4
Training loss: 3.0770082473754883
Validation loss: 2.770751594215311

Epoch: 6| Step: 5
Training loss: 3.131514310836792
Validation loss: 2.773002165620045

Epoch: 6| Step: 6
Training loss: 2.9831185340881348
Validation loss: 2.7767382360273793

Epoch: 6| Step: 7
Training loss: 3.2341394424438477
Validation loss: 2.779999679134738

Epoch: 6| Step: 8
Training loss: 3.0235323905944824
Validation loss: 2.7785101859800276

Epoch: 6| Step: 9
Training loss: 2.9469070434570312
Validation loss: 2.7786125572778846

Epoch: 6| Step: 10
Training loss: 2.6978139877319336
Validation loss: 2.7781948274181736

Epoch: 6| Step: 11
Training loss: 2.7783186435699463
Validation loss: 2.7753428413021948

Epoch: 6| Step: 12
Training loss: 3.1369974613189697
Validation loss: 2.7690295198912263

Epoch: 6| Step: 13
Training loss: 3.0651135444641113
Validation loss: 2.7677731334522204

Epoch: 61| Step: 0
Training loss: 3.2940213680267334
Validation loss: 2.765116976153466

Epoch: 6| Step: 1
Training loss: 2.8301234245300293
Validation loss: 2.764243882189515

Epoch: 6| Step: 2
Training loss: 2.996616840362549
Validation loss: 2.767352350296513

Epoch: 6| Step: 3
Training loss: 2.2558176517486572
Validation loss: 2.768747504039477

Epoch: 6| Step: 4
Training loss: 3.517831802368164
Validation loss: 2.7672388348528134

Epoch: 6| Step: 5
Training loss: 1.7707395553588867
Validation loss: 2.7678444436801377

Epoch: 6| Step: 6
Training loss: 3.2486796379089355
Validation loss: 2.770649112680907

Epoch: 6| Step: 7
Training loss: 3.333996057510376
Validation loss: 2.772616260795183

Epoch: 6| Step: 8
Training loss: 2.8232855796813965
Validation loss: 2.766968401529456

Epoch: 6| Step: 9
Training loss: 3.5107522010803223
Validation loss: 2.7681958521566083

Epoch: 6| Step: 10
Training loss: 2.3010470867156982
Validation loss: 2.7683694465186006

Epoch: 6| Step: 11
Training loss: 2.8654770851135254
Validation loss: 2.7688617219207106

Epoch: 6| Step: 12
Training loss: 3.2956788539886475
Validation loss: 2.7698854784811697

Epoch: 6| Step: 13
Training loss: 2.2652487754821777
Validation loss: 2.7674672193424676

Epoch: 62| Step: 0
Training loss: 2.701136589050293
Validation loss: 2.7687153534222673

Epoch: 6| Step: 1
Training loss: 3.5838561058044434
Validation loss: 2.770761800068681

Epoch: 6| Step: 2
Training loss: 1.8445138931274414
Validation loss: 2.7684118722074773

Epoch: 6| Step: 3
Training loss: 2.7803025245666504
Validation loss: 2.7719439588567263

Epoch: 6| Step: 4
Training loss: 2.580300807952881
Validation loss: 2.773318226619433

Epoch: 6| Step: 5
Training loss: 3.1245856285095215
Validation loss: 2.7815839270109772

Epoch: 6| Step: 6
Training loss: 3.228621006011963
Validation loss: 2.7843086027329966

Epoch: 6| Step: 7
Training loss: 2.82765531539917
Validation loss: 2.7786759740562847

Epoch: 6| Step: 8
Training loss: 2.834075450897217
Validation loss: 2.783070057950994

Epoch: 6| Step: 9
Training loss: 2.262336492538452
Validation loss: 2.769631572948989

Epoch: 6| Step: 10
Training loss: 3.5597004890441895
Validation loss: 2.7636941402189192

Epoch: 6| Step: 11
Training loss: 3.2909364700317383
Validation loss: 2.766565292112289

Epoch: 6| Step: 12
Training loss: 2.749574899673462
Validation loss: 2.7734780311584473

Epoch: 6| Step: 13
Training loss: 3.508847951889038
Validation loss: 2.7738453700978267

Epoch: 63| Step: 0
Training loss: 2.6339335441589355
Validation loss: 2.7723742967010825

Epoch: 6| Step: 1
Training loss: 2.4612717628479004
Validation loss: 2.772447604005055

Epoch: 6| Step: 2
Training loss: 3.044257640838623
Validation loss: 2.773206377542147

Epoch: 6| Step: 3
Training loss: 2.945056438446045
Validation loss: 2.770921963517384

Epoch: 6| Step: 4
Training loss: 3.664877414703369
Validation loss: 2.7709525631320093

Epoch: 6| Step: 5
Training loss: 2.8188722133636475
Validation loss: 2.765623002923945

Epoch: 6| Step: 6
Training loss: 3.14766263961792
Validation loss: 2.767375305134763

Epoch: 6| Step: 7
Training loss: 2.0510971546173096
Validation loss: 2.7622206518726964

Epoch: 6| Step: 8
Training loss: 3.640385150909424
Validation loss: 2.7628758261280675

Epoch: 6| Step: 9
Training loss: 2.3635315895080566
Validation loss: 2.7627279220088834

Epoch: 6| Step: 10
Training loss: 4.074933052062988
Validation loss: 2.759604097694479

Epoch: 6| Step: 11
Training loss: 1.911605954170227
Validation loss: 2.7623601805779243

Epoch: 6| Step: 12
Training loss: 2.810960054397583
Validation loss: 2.7585376949720484

Epoch: 6| Step: 13
Training loss: 3.12209415435791
Validation loss: 2.7605452178626932

Epoch: 64| Step: 0
Training loss: 2.359243869781494
Validation loss: 2.759206792359711

Epoch: 6| Step: 1
Training loss: 4.106983184814453
Validation loss: 2.7613643702640327

Epoch: 6| Step: 2
Training loss: 1.3922879695892334
Validation loss: 2.76197842115997

Epoch: 6| Step: 3
Training loss: 3.129567861557007
Validation loss: 2.76251559616417

Epoch: 6| Step: 4
Training loss: 2.575779438018799
Validation loss: 2.761211610609485

Epoch: 6| Step: 5
Training loss: 3.3270506858825684
Validation loss: 2.7603324510717906

Epoch: 6| Step: 6
Training loss: 3.475904941558838
Validation loss: 2.7654289378914783

Epoch: 6| Step: 7
Training loss: 3.6805710792541504
Validation loss: 2.762779594749533

Epoch: 6| Step: 8
Training loss: 2.069828987121582
Validation loss: 2.764658740771714

Epoch: 6| Step: 9
Training loss: 3.4545888900756836
Validation loss: 2.765498758644186

Epoch: 6| Step: 10
Training loss: 3.0812344551086426
Validation loss: 2.7671753386015534

Epoch: 6| Step: 11
Training loss: 2.6913657188415527
Validation loss: 2.765489811538368

Epoch: 6| Step: 12
Training loss: 2.366088628768921
Validation loss: 2.765142427977695

Epoch: 6| Step: 13
Training loss: 2.580338478088379
Validation loss: 2.766203929019231

Epoch: 65| Step: 0
Training loss: 2.6158552169799805
Validation loss: 2.766922866144488

Epoch: 6| Step: 1
Training loss: 2.0512938499450684
Validation loss: 2.7645417054494223

Epoch: 6| Step: 2
Training loss: 3.2555456161499023
Validation loss: 2.7592860062917075

Epoch: 6| Step: 3
Training loss: 3.0345566272735596
Validation loss: 2.7606948421847437

Epoch: 6| Step: 4
Training loss: 3.2066028118133545
Validation loss: 2.7611016227353002

Epoch: 6| Step: 5
Training loss: 2.31594181060791
Validation loss: 2.7583343957060125

Epoch: 6| Step: 6
Training loss: 3.325728416442871
Validation loss: 2.7617271946322535

Epoch: 6| Step: 7
Training loss: 2.638975143432617
Validation loss: 2.758584876214304

Epoch: 6| Step: 8
Training loss: 3.0330986976623535
Validation loss: 2.7600473447512557

Epoch: 6| Step: 9
Training loss: 3.167264461517334
Validation loss: 2.7604778582049954

Epoch: 6| Step: 10
Training loss: 3.298269271850586
Validation loss: 2.756904484123312

Epoch: 6| Step: 11
Training loss: 2.7351040840148926
Validation loss: 2.7562979780217653

Epoch: 6| Step: 12
Training loss: 2.7157974243164062
Validation loss: 2.7575242493742254

Epoch: 6| Step: 13
Training loss: 3.122637987136841
Validation loss: 2.756266393969136

Epoch: 66| Step: 0
Training loss: 3.2179486751556396
Validation loss: 2.7589113840492825

Epoch: 6| Step: 1
Training loss: 2.6629505157470703
Validation loss: 2.756304435832526

Epoch: 6| Step: 2
Training loss: 3.083939790725708
Validation loss: 2.7562893693165114

Epoch: 6| Step: 3
Training loss: 3.0099778175354004
Validation loss: 2.7533008155002388

Epoch: 6| Step: 4
Training loss: 3.277862548828125
Validation loss: 2.7518082844313754

Epoch: 6| Step: 5
Training loss: 3.003291606903076
Validation loss: 2.754012856432187

Epoch: 6| Step: 6
Training loss: 2.272005558013916
Validation loss: 2.753745304640903

Epoch: 6| Step: 7
Training loss: 3.4038197994232178
Validation loss: 2.755688726261098

Epoch: 6| Step: 8
Training loss: 2.8054542541503906
Validation loss: 2.753866257206086

Epoch: 6| Step: 9
Training loss: 1.9308007955551147
Validation loss: 2.757625449088312

Epoch: 6| Step: 10
Training loss: 3.11470890045166
Validation loss: 2.753192091500887

Epoch: 6| Step: 11
Training loss: 2.8834314346313477
Validation loss: 2.75326374782029

Epoch: 6| Step: 12
Training loss: 2.947946786880493
Validation loss: 2.751205693009079

Epoch: 6| Step: 13
Training loss: 2.675222158432007
Validation loss: 2.752179963614351

Epoch: 67| Step: 0
Training loss: 3.347296714782715
Validation loss: 2.754924830570016

Epoch: 6| Step: 1
Training loss: 2.706763744354248
Validation loss: 2.7539732174206804

Epoch: 6| Step: 2
Training loss: 2.9012551307678223
Validation loss: 2.7550159705582487

Epoch: 6| Step: 3
Training loss: 2.7970457077026367
Validation loss: 2.755799073044972

Epoch: 6| Step: 4
Training loss: 3.090304374694824
Validation loss: 2.757097008407757

Epoch: 6| Step: 5
Training loss: 2.792792797088623
Validation loss: 2.7564588285261586

Epoch: 6| Step: 6
Training loss: 3.7469842433929443
Validation loss: 2.7566687573668776

Epoch: 6| Step: 7
Training loss: 3.225125789642334
Validation loss: 2.7596314184127317

Epoch: 6| Step: 8
Training loss: 2.5954418182373047
Validation loss: 2.7583391640775945

Epoch: 6| Step: 9
Training loss: 3.2622604370117188
Validation loss: 2.7626698068393174

Epoch: 6| Step: 10
Training loss: 2.3209047317504883
Validation loss: 2.7654300248751076

Epoch: 6| Step: 11
Training loss: 2.727646827697754
Validation loss: 2.7671559344055834

Epoch: 6| Step: 12
Training loss: 2.9445834159851074
Validation loss: 2.763924293620612

Epoch: 6| Step: 13
Training loss: 1.1204079389572144
Validation loss: 2.7587794103930072

Epoch: 68| Step: 0
Training loss: 2.380626678466797
Validation loss: 2.7567347736768824

Epoch: 6| Step: 1
Training loss: 3.335315227508545
Validation loss: 2.755863969044019

Epoch: 6| Step: 2
Training loss: 3.3475182056427
Validation loss: 2.7587544815514677

Epoch: 6| Step: 3
Training loss: 3.2042927742004395
Validation loss: 2.7542428944700506

Epoch: 6| Step: 4
Training loss: 3.3883488178253174
Validation loss: 2.754541286858179

Epoch: 6| Step: 5
Training loss: 2.3074660301208496
Validation loss: 2.7531637889082714

Epoch: 6| Step: 6
Training loss: 2.85886287689209
Validation loss: 2.7506656441637265

Epoch: 6| Step: 7
Training loss: 2.4883360862731934
Validation loss: 2.7503639190427718

Epoch: 6| Step: 8
Training loss: 2.6209769248962402
Validation loss: 2.752689607681767

Epoch: 6| Step: 9
Training loss: 2.671755075454712
Validation loss: 2.7498135976893927

Epoch: 6| Step: 10
Training loss: 3.0554184913635254
Validation loss: 2.748116659861739

Epoch: 6| Step: 11
Training loss: 3.644885540008545
Validation loss: 2.7517266683681036

Epoch: 6| Step: 12
Training loss: 2.210014820098877
Validation loss: 2.7512360054959535

Epoch: 6| Step: 13
Training loss: 2.8183696269989014
Validation loss: 2.7498487375115834

Epoch: 69| Step: 0
Training loss: 2.428231954574585
Validation loss: 2.7482671404397614

Epoch: 6| Step: 1
Training loss: 3.050461530685425
Validation loss: 2.7492676524705786

Epoch: 6| Step: 2
Training loss: 2.8168327808380127
Validation loss: 2.748556452412759

Epoch: 6| Step: 3
Training loss: 2.390383243560791
Validation loss: 2.7484005292256675

Epoch: 6| Step: 4
Training loss: 3.884868621826172
Validation loss: 2.7535076782267582

Epoch: 6| Step: 5
Training loss: 2.8154191970825195
Validation loss: 2.7482709089914956

Epoch: 6| Step: 6
Training loss: 2.6696486473083496
Validation loss: 2.750803993594262

Epoch: 6| Step: 7
Training loss: 3.0516767501831055
Validation loss: 2.7603558135289017

Epoch: 6| Step: 8
Training loss: 2.522991180419922
Validation loss: 2.7600877695186163

Epoch: 6| Step: 9
Training loss: 2.6669278144836426
Validation loss: 2.7655950412955335

Epoch: 6| Step: 10
Training loss: 3.672661542892456
Validation loss: 2.7685924037810294

Epoch: 6| Step: 11
Training loss: 3.036168098449707
Validation loss: 2.7592877188036518

Epoch: 6| Step: 12
Training loss: 2.0837621688842773
Validation loss: 2.7603544906903337

Epoch: 6| Step: 13
Training loss: 3.582383394241333
Validation loss: 2.758169722813432

Epoch: 70| Step: 0
Training loss: 3.12387752532959
Validation loss: 2.752301036670644

Epoch: 6| Step: 1
Training loss: 1.5103247165679932
Validation loss: 2.7498558157233783

Epoch: 6| Step: 2
Training loss: 2.6063408851623535
Validation loss: 2.7484528762038036

Epoch: 6| Step: 3
Training loss: 3.1814420223236084
Validation loss: 2.748831936108169

Epoch: 6| Step: 4
Training loss: 2.5676255226135254
Validation loss: 2.745259218318488

Epoch: 6| Step: 5
Training loss: 3.047008991241455
Validation loss: 2.744428870498493

Epoch: 6| Step: 6
Training loss: 3.120203971862793
Validation loss: 2.7452232914586223

Epoch: 6| Step: 7
Training loss: 2.7969236373901367
Validation loss: 2.7443406658787883

Epoch: 6| Step: 8
Training loss: 2.91237473487854
Validation loss: 2.741681819321007

Epoch: 6| Step: 9
Training loss: 2.818443775177002
Validation loss: 2.745783072645946

Epoch: 6| Step: 10
Training loss: 2.584109306335449
Validation loss: 2.74417551871269

Epoch: 6| Step: 11
Training loss: 3.7758638858795166
Validation loss: 2.742632676196355

Epoch: 6| Step: 12
Training loss: 2.6246495246887207
Validation loss: 2.7453287596343667

Epoch: 6| Step: 13
Training loss: 4.163621425628662
Validation loss: 2.7429208986220823

Epoch: 71| Step: 0
Training loss: 3.269364595413208
Validation loss: 2.744086983383343

Epoch: 6| Step: 1
Training loss: 3.4662675857543945
Validation loss: 2.7445172904640116

Epoch: 6| Step: 2
Training loss: 2.362550735473633
Validation loss: 2.743043171462192

Epoch: 6| Step: 3
Training loss: 2.5423927307128906
Validation loss: 2.7443173470035678

Epoch: 6| Step: 4
Training loss: 2.4894356727600098
Validation loss: 2.7436344700474895

Epoch: 6| Step: 5
Training loss: 2.793149471282959
Validation loss: 2.7453775226428943

Epoch: 6| Step: 6
Training loss: 3.282900094985962
Validation loss: 2.7451197383224324

Epoch: 6| Step: 7
Training loss: 3.3950154781341553
Validation loss: 2.7472608499629523

Epoch: 6| Step: 8
Training loss: 3.747530460357666
Validation loss: 2.74917495635248

Epoch: 6| Step: 9
Training loss: 1.8687641620635986
Validation loss: 2.7464826132661555

Epoch: 6| Step: 10
Training loss: 2.958599805831909
Validation loss: 2.7495677368615263

Epoch: 6| Step: 11
Training loss: 2.9565043449401855
Validation loss: 2.7500691644607054

Epoch: 6| Step: 12
Training loss: 2.8814828395843506
Validation loss: 2.7469012352728073

Epoch: 6| Step: 13
Training loss: 1.7422465085983276
Validation loss: 2.748989036006312

Epoch: 72| Step: 0
Training loss: 2.422610282897949
Validation loss: 2.7457699237331266

Epoch: 6| Step: 1
Training loss: 3.694308280944824
Validation loss: 2.742701022855697

Epoch: 6| Step: 2
Training loss: 2.294858455657959
Validation loss: 2.738827105491392

Epoch: 6| Step: 3
Training loss: 2.5224223136901855
Validation loss: 2.7407588804921796

Epoch: 6| Step: 4
Training loss: 3.2725791931152344
Validation loss: 2.7375204922050558

Epoch: 6| Step: 5
Training loss: 3.713479518890381
Validation loss: 2.7405418503669

Epoch: 6| Step: 6
Training loss: 2.613982677459717
Validation loss: 2.7411281934348484

Epoch: 6| Step: 7
Training loss: 2.633324146270752
Validation loss: 2.741720902022495

Epoch: 6| Step: 8
Training loss: 3.441910982131958
Validation loss: 2.7416590208648355

Epoch: 6| Step: 9
Training loss: 2.57816743850708
Validation loss: 2.7397878759650776

Epoch: 6| Step: 10
Training loss: 2.161557197570801
Validation loss: 2.7402768442707677

Epoch: 6| Step: 11
Training loss: 2.6583399772644043
Validation loss: 2.7409985860188804

Epoch: 6| Step: 12
Training loss: 2.904736042022705
Validation loss: 2.7406324289178334

Epoch: 6| Step: 13
Training loss: 3.638173818588257
Validation loss: 2.7434713968666653

Epoch: 73| Step: 0
Training loss: 3.214045524597168
Validation loss: 2.7447683734278523

Epoch: 6| Step: 1
Training loss: 2.4080538749694824
Validation loss: 2.740623915067283

Epoch: 6| Step: 2
Training loss: 2.4286551475524902
Validation loss: 2.7388303997696086

Epoch: 6| Step: 3
Training loss: 2.9503605365753174
Validation loss: 2.7412910128152497

Epoch: 6| Step: 4
Training loss: 2.071620225906372
Validation loss: 2.7376378377278647

Epoch: 6| Step: 5
Training loss: 3.2903802394866943
Validation loss: 2.7376290316222818

Epoch: 6| Step: 6
Training loss: 2.921804428100586
Validation loss: 2.7379573622057514

Epoch: 6| Step: 7
Training loss: 2.910689115524292
Validation loss: 2.7368273504318728

Epoch: 6| Step: 8
Training loss: 3.5765740871429443
Validation loss: 2.7382098859356296

Epoch: 6| Step: 9
Training loss: 2.8323450088500977
Validation loss: 2.735719055257818

Epoch: 6| Step: 10
Training loss: 2.8584961891174316
Validation loss: 2.7337164519935526

Epoch: 6| Step: 11
Training loss: 2.650944232940674
Validation loss: 2.735442784524733

Epoch: 6| Step: 12
Training loss: 2.6606454849243164
Validation loss: 2.737105700277513

Epoch: 6| Step: 13
Training loss: 3.776064157485962
Validation loss: 2.736861313543012

Epoch: 74| Step: 0
Training loss: 2.6164627075195312
Validation loss: 2.7399842508377565

Epoch: 6| Step: 1
Training loss: 3.3566479682922363
Validation loss: 2.7426395928987892

Epoch: 6| Step: 2
Training loss: 2.3619205951690674
Validation loss: 2.7544135919181247

Epoch: 6| Step: 3
Training loss: 3.1526072025299072
Validation loss: 2.758373316898141

Epoch: 6| Step: 4
Training loss: 3.045593023300171
Validation loss: 2.75681225715145

Epoch: 6| Step: 5
Training loss: 3.1359803676605225
Validation loss: 2.7494318536532822

Epoch: 6| Step: 6
Training loss: 2.3734652996063232
Validation loss: 2.7513621263606574

Epoch: 6| Step: 7
Training loss: 3.4700698852539062
Validation loss: 2.7458800782439527

Epoch: 6| Step: 8
Training loss: 2.3702025413513184
Validation loss: 2.74392653793417

Epoch: 6| Step: 9
Training loss: 3.104466438293457
Validation loss: 2.7394903962330153

Epoch: 6| Step: 10
Training loss: 2.6738510131835938
Validation loss: 2.734328072558167

Epoch: 6| Step: 11
Training loss: 2.864434242248535
Validation loss: 2.7341473358933643

Epoch: 6| Step: 12
Training loss: 3.5544047355651855
Validation loss: 2.733729911106889

Epoch: 6| Step: 13
Training loss: 1.509468674659729
Validation loss: 2.7342611564102994

Epoch: 75| Step: 0
Training loss: 2.879392147064209
Validation loss: 2.734388910314088

Epoch: 6| Step: 1
Training loss: 2.4486207962036133
Validation loss: 2.73500810387314

Epoch: 6| Step: 2
Training loss: 2.437342643737793
Validation loss: 2.7389473786918064

Epoch: 6| Step: 3
Training loss: 3.570161819458008
Validation loss: 2.737282952954692

Epoch: 6| Step: 4
Training loss: 3.090646266937256
Validation loss: 2.7322855021363948

Epoch: 6| Step: 5
Training loss: 3.167142152786255
Validation loss: 2.7324808592437417

Epoch: 6| Step: 6
Training loss: 2.836280345916748
Validation loss: 2.7326366465578795

Epoch: 6| Step: 7
Training loss: 2.6783618927001953
Validation loss: 2.734503822941934

Epoch: 6| Step: 8
Training loss: 3.000835418701172
Validation loss: 2.7329606240795505

Epoch: 6| Step: 9
Training loss: 2.8306519985198975
Validation loss: 2.7344919020129788

Epoch: 6| Step: 10
Training loss: 2.9085121154785156
Validation loss: 2.7344256934299263

Epoch: 6| Step: 11
Training loss: 3.335174083709717
Validation loss: 2.731650285823371

Epoch: 6| Step: 12
Training loss: 2.1160988807678223
Validation loss: 2.7312915825074717

Epoch: 6| Step: 13
Training loss: 2.895843744277954
Validation loss: 2.7363704917251424

Epoch: 76| Step: 0
Training loss: 2.512620449066162
Validation loss: 2.732816373148272

Epoch: 6| Step: 1
Training loss: 3.1839194297790527
Validation loss: 2.7320635241846882

Epoch: 6| Step: 2
Training loss: 2.307889699935913
Validation loss: 2.733911656564282

Epoch: 6| Step: 3
Training loss: 2.0358855724334717
Validation loss: 2.733724517206992

Epoch: 6| Step: 4
Training loss: 3.2700068950653076
Validation loss: 2.7340680347975863

Epoch: 6| Step: 5
Training loss: 3.295886993408203
Validation loss: 2.7342573545312368

Epoch: 6| Step: 6
Training loss: 2.589655876159668
Validation loss: 2.7316591150017193

Epoch: 6| Step: 7
Training loss: 2.858710289001465
Validation loss: 2.733414508963144

Epoch: 6| Step: 8
Training loss: 3.362905263900757
Validation loss: 2.7333873907725015

Epoch: 6| Step: 9
Training loss: 3.689781665802002
Validation loss: 2.733268932629657

Epoch: 6| Step: 10
Training loss: 2.9758596420288086
Validation loss: 2.7365910084016862

Epoch: 6| Step: 11
Training loss: 1.4839460849761963
Validation loss: 2.733674305741505

Epoch: 6| Step: 12
Training loss: 3.7049851417541504
Validation loss: 2.735208175515616

Epoch: 6| Step: 13
Training loss: 2.7968406677246094
Validation loss: 2.735146317430722

Epoch: 77| Step: 0
Training loss: 3.2772693634033203
Validation loss: 2.733534441199354

Epoch: 6| Step: 1
Training loss: 2.8585996627807617
Validation loss: 2.7283006842418382

Epoch: 6| Step: 2
Training loss: 2.494755268096924
Validation loss: 2.7298955584085114

Epoch: 6| Step: 3
Training loss: 2.9030137062072754
Validation loss: 2.729469209588984

Epoch: 6| Step: 4
Training loss: 2.496303081512451
Validation loss: 2.7328419070090018

Epoch: 6| Step: 5
Training loss: 3.4693946838378906
Validation loss: 2.7283346986257904

Epoch: 6| Step: 6
Training loss: 2.4993762969970703
Validation loss: 2.7376292649135796

Epoch: 6| Step: 7
Training loss: 2.99531888961792
Validation loss: 2.731119655793713

Epoch: 6| Step: 8
Training loss: 2.61495304107666
Validation loss: 2.7344596565410657

Epoch: 6| Step: 9
Training loss: 2.7690205574035645
Validation loss: 2.731365898604034

Epoch: 6| Step: 10
Training loss: 2.69094181060791
Validation loss: 2.7363738526580152

Epoch: 6| Step: 11
Training loss: 2.7962849140167236
Validation loss: 2.730860887035247

Epoch: 6| Step: 12
Training loss: 3.0827090740203857
Validation loss: 2.7357405513845463

Epoch: 6| Step: 13
Training loss: 3.448014974594116
Validation loss: 2.73033385122976

Epoch: 78| Step: 0
Training loss: 3.0329339504241943
Validation loss: 2.7274848927733717

Epoch: 6| Step: 1
Training loss: 3.0129759311676025
Validation loss: 2.7239929860638035

Epoch: 6| Step: 2
Training loss: 3.0655035972595215
Validation loss: 2.7265403501449095

Epoch: 6| Step: 3
Training loss: 2.7989213466644287
Validation loss: 2.7295435038946008

Epoch: 6| Step: 4
Training loss: 3.019423246383667
Validation loss: 2.7254574709041144

Epoch: 6| Step: 5
Training loss: 3.0708494186401367
Validation loss: 2.730999695357456

Epoch: 6| Step: 6
Training loss: 2.5431694984436035
Validation loss: 2.7279266516367593

Epoch: 6| Step: 7
Training loss: 2.427295207977295
Validation loss: 2.726043378153155

Epoch: 6| Step: 8
Training loss: 2.7548060417175293
Validation loss: 2.725349377560359

Epoch: 6| Step: 9
Training loss: 2.6780519485473633
Validation loss: 2.726435617734027

Epoch: 6| Step: 10
Training loss: 2.809554100036621
Validation loss: 2.726280056020265

Epoch: 6| Step: 11
Training loss: 3.039567470550537
Validation loss: 2.7244003126698155

Epoch: 6| Step: 12
Training loss: 2.800990581512451
Validation loss: 2.7243319224285822

Epoch: 6| Step: 13
Training loss: 3.2160046100616455
Validation loss: 2.7276756096911687

Epoch: 79| Step: 0
Training loss: 2.8697218894958496
Validation loss: 2.7283222111322547

Epoch: 6| Step: 1
Training loss: 3.1340901851654053
Validation loss: 2.7269458822024766

Epoch: 6| Step: 2
Training loss: 2.7399048805236816
Validation loss: 2.7273180869317826

Epoch: 6| Step: 3
Training loss: 2.614215850830078
Validation loss: 2.7294501719936246

Epoch: 6| Step: 4
Training loss: 2.374490976333618
Validation loss: 2.7262789767275573

Epoch: 6| Step: 5
Training loss: 3.0006461143493652
Validation loss: 2.722268191717004

Epoch: 6| Step: 6
Training loss: 1.8061847686767578
Validation loss: 2.7257609162279355

Epoch: 6| Step: 7
Training loss: 2.584299325942993
Validation loss: 2.7271019874080533

Epoch: 6| Step: 8
Training loss: 3.221491813659668
Validation loss: 2.7217372027776574

Epoch: 6| Step: 9
Training loss: 2.4925358295440674
Validation loss: 2.722980196757983

Epoch: 6| Step: 10
Training loss: 3.393141269683838
Validation loss: 2.7265038874841507

Epoch: 6| Step: 11
Training loss: 3.506258487701416
Validation loss: 2.7260233202288227

Epoch: 6| Step: 12
Training loss: 3.6635472774505615
Validation loss: 2.7250523669745332

Epoch: 6| Step: 13
Training loss: 2.4663445949554443
Validation loss: 2.7249948619514384

Epoch: 80| Step: 0
Training loss: 2.336714744567871
Validation loss: 2.7295062234324794

Epoch: 6| Step: 1
Training loss: 2.310760974884033
Validation loss: 2.728607290534563

Epoch: 6| Step: 2
Training loss: 2.400820732116699
Validation loss: 2.726300626672724

Epoch: 6| Step: 3
Training loss: 3.6314539909362793
Validation loss: 2.72486852317728

Epoch: 6| Step: 4
Training loss: 2.3228275775909424
Validation loss: 2.7230618717849895

Epoch: 6| Step: 5
Training loss: 3.1564388275146484
Validation loss: 2.7230912562339538

Epoch: 6| Step: 6
Training loss: 2.1596693992614746
Validation loss: 2.7211662236080376

Epoch: 6| Step: 7
Training loss: 3.1510608196258545
Validation loss: 2.7182553506666616

Epoch: 6| Step: 8
Training loss: 3.6445231437683105
Validation loss: 2.718269807036205

Epoch: 6| Step: 9
Training loss: 3.1112353801727295
Validation loss: 2.7178437761081162

Epoch: 6| Step: 10
Training loss: 3.23911190032959
Validation loss: 2.716945817393641

Epoch: 6| Step: 11
Training loss: 2.990353584289551
Validation loss: 2.716329623294133

Epoch: 6| Step: 12
Training loss: 2.4227633476257324
Validation loss: 2.7162496351426646

Epoch: 6| Step: 13
Training loss: 3.304718017578125
Validation loss: 2.7163084655679683

Epoch: 81| Step: 0
Training loss: 2.589118003845215
Validation loss: 2.7190102992519254

Epoch: 6| Step: 1
Training loss: 3.409489870071411
Validation loss: 2.7182593678915374

Epoch: 6| Step: 2
Training loss: 2.7533750534057617
Validation loss: 2.717271715082148

Epoch: 6| Step: 3
Training loss: 2.9076972007751465
Validation loss: 2.7147667510535127

Epoch: 6| Step: 4
Training loss: 3.358865261077881
Validation loss: 2.7182552019755044

Epoch: 6| Step: 5
Training loss: 2.749284267425537
Validation loss: 2.7173739069251606

Epoch: 6| Step: 6
Training loss: 3.2361769676208496
Validation loss: 2.717275265724428

Epoch: 6| Step: 7
Training loss: 2.970982551574707
Validation loss: 2.7189662943604174

Epoch: 6| Step: 8
Training loss: 2.613426446914673
Validation loss: 2.7185099868364233

Epoch: 6| Step: 9
Training loss: 2.654958724975586
Validation loss: 2.7184677559842347

Epoch: 6| Step: 10
Training loss: 2.0090370178222656
Validation loss: 2.7187004473901566

Epoch: 6| Step: 11
Training loss: 3.237844467163086
Validation loss: 2.7197395986126316

Epoch: 6| Step: 12
Training loss: 2.988377094268799
Validation loss: 2.718352174246183

Epoch: 6| Step: 13
Training loss: 2.165132999420166
Validation loss: 2.7205325429157545

Epoch: 82| Step: 0
Training loss: 3.1566147804260254
Validation loss: 2.722516608494584

Epoch: 6| Step: 1
Training loss: 2.482658863067627
Validation loss: 2.719347897396293

Epoch: 6| Step: 2
Training loss: 2.8335680961608887
Validation loss: 2.718860205783639

Epoch: 6| Step: 3
Training loss: 2.528176784515381
Validation loss: 2.7168601661600094

Epoch: 6| Step: 4
Training loss: 2.7989580631256104
Validation loss: 2.7176811797644502

Epoch: 6| Step: 5
Training loss: 2.268411874771118
Validation loss: 2.715410417126071

Epoch: 6| Step: 6
Training loss: 4.029974460601807
Validation loss: 2.7157644712796776

Epoch: 6| Step: 7
Training loss: 2.8698320388793945
Validation loss: 2.713710533675327

Epoch: 6| Step: 8
Training loss: 2.007460117340088
Validation loss: 2.71367613474528

Epoch: 6| Step: 9
Training loss: 2.9307069778442383
Validation loss: 2.7123888077274447

Epoch: 6| Step: 10
Training loss: 2.86393666267395
Validation loss: 2.713222913844611

Epoch: 6| Step: 11
Training loss: 2.864272117614746
Validation loss: 2.7121249347604732

Epoch: 6| Step: 12
Training loss: 3.027696132659912
Validation loss: 2.712123986213438

Epoch: 6| Step: 13
Training loss: 3.5813212394714355
Validation loss: 2.7123971344322286

Epoch: 83| Step: 0
Training loss: 2.0549557209014893
Validation loss: 2.712006115144299

Epoch: 6| Step: 1
Training loss: 3.3364179134368896
Validation loss: 2.712275666575278

Epoch: 6| Step: 2
Training loss: 3.3836240768432617
Validation loss: 2.7134909347821305

Epoch: 6| Step: 3
Training loss: 2.738837242126465
Validation loss: 2.711669091255434

Epoch: 6| Step: 4
Training loss: 2.3733739852905273
Validation loss: 2.7158134470703783

Epoch: 6| Step: 5
Training loss: 2.915038824081421
Validation loss: 2.71200515121542

Epoch: 6| Step: 6
Training loss: 2.816568374633789
Validation loss: 2.7136500535472745

Epoch: 6| Step: 7
Training loss: 3.0768778324127197
Validation loss: 2.712382624226232

Epoch: 6| Step: 8
Training loss: 3.6798348426818848
Validation loss: 2.7112025112234135

Epoch: 6| Step: 9
Training loss: 2.931279182434082
Validation loss: 2.7118421933984243

Epoch: 6| Step: 10
Training loss: 2.7670655250549316
Validation loss: 2.7110364770376556

Epoch: 6| Step: 11
Training loss: 3.0114269256591797
Validation loss: 2.7116976015029417

Epoch: 6| Step: 12
Training loss: 2.332447052001953
Validation loss: 2.709418435250559

Epoch: 6| Step: 13
Training loss: 2.1869142055511475
Validation loss: 2.712606458253758

Epoch: 84| Step: 0
Training loss: 3.0766983032226562
Validation loss: 2.713687119945403

Epoch: 6| Step: 1
Training loss: 2.7838945388793945
Validation loss: 2.70956519598602

Epoch: 6| Step: 2
Training loss: 2.1338729858398438
Validation loss: 2.7113329005497757

Epoch: 6| Step: 3
Training loss: 2.917654037475586
Validation loss: 2.709143107937228

Epoch: 6| Step: 4
Training loss: 2.774782657623291
Validation loss: 2.7084424752061085

Epoch: 6| Step: 5
Training loss: 4.174530506134033
Validation loss: 2.7113630258908836

Epoch: 6| Step: 6
Training loss: 3.1632988452911377
Validation loss: 2.710035862461213

Epoch: 6| Step: 7
Training loss: 2.9442877769470215
Validation loss: 2.709692314106931

Epoch: 6| Step: 8
Training loss: 2.1506803035736084
Validation loss: 2.709133235357141

Epoch: 6| Step: 9
Training loss: 3.0951361656188965
Validation loss: 2.7082459542059127

Epoch: 6| Step: 10
Training loss: 2.1903834342956543
Validation loss: 2.706464590564851

Epoch: 6| Step: 11
Training loss: 2.9090707302093506
Validation loss: 2.7039313841891546

Epoch: 6| Step: 12
Training loss: 2.6523656845092773
Validation loss: 2.708446446285453

Epoch: 6| Step: 13
Training loss: 2.9363410472869873
Validation loss: 2.7105576556216002

Epoch: 85| Step: 0
Training loss: 2.6519839763641357
Validation loss: 2.715844359449161

Epoch: 6| Step: 1
Training loss: 3.2165260314941406
Validation loss: 2.7123169283713064

Epoch: 6| Step: 2
Training loss: 2.0319080352783203
Validation loss: 2.7172871148714455

Epoch: 6| Step: 3
Training loss: 3.29911208152771
Validation loss: 2.707823996902794

Epoch: 6| Step: 4
Training loss: 3.2039332389831543
Validation loss: 2.7097033864708355

Epoch: 6| Step: 5
Training loss: 3.1324918270111084
Validation loss: 2.7087728695202897

Epoch: 6| Step: 6
Training loss: 3.1276259422302246
Validation loss: 2.707440371154457

Epoch: 6| Step: 7
Training loss: 3.021852731704712
Validation loss: 2.704049471885927

Epoch: 6| Step: 8
Training loss: 3.1436100006103516
Validation loss: 2.704437066149968

Epoch: 6| Step: 9
Training loss: 2.5023727416992188
Validation loss: 2.7049081530622257

Epoch: 6| Step: 10
Training loss: 3.1213021278381348
Validation loss: 2.705922254952051

Epoch: 6| Step: 11
Training loss: 2.489942789077759
Validation loss: 2.7066658158456125

Epoch: 6| Step: 12
Training loss: 2.191545009613037
Validation loss: 2.7051335098922893

Epoch: 6| Step: 13
Training loss: 2.6512937545776367
Validation loss: 2.7036228436295704

Epoch: 86| Step: 0
Training loss: 3.066016674041748
Validation loss: 2.709697856697985

Epoch: 6| Step: 1
Training loss: 2.805914878845215
Validation loss: 2.7031453424884426

Epoch: 6| Step: 2
Training loss: 2.966350555419922
Validation loss: 2.7081684707313456

Epoch: 6| Step: 3
Training loss: 2.215894937515259
Validation loss: 2.706530055692119

Epoch: 6| Step: 4
Training loss: 2.2358217239379883
Validation loss: 2.708022784161311

Epoch: 6| Step: 5
Training loss: 3.3912246227264404
Validation loss: 2.706644299209759

Epoch: 6| Step: 6
Training loss: 3.3700966835021973
Validation loss: 2.7014291260832097

Epoch: 6| Step: 7
Training loss: 2.765204906463623
Validation loss: 2.7053661064435075

Epoch: 6| Step: 8
Training loss: 2.8397083282470703
Validation loss: 2.706510479732226

Epoch: 6| Step: 9
Training loss: 2.1414318084716797
Validation loss: 2.702421126827117

Epoch: 6| Step: 10
Training loss: 2.9524359703063965
Validation loss: 2.706412351259621

Epoch: 6| Step: 11
Training loss: 3.3764281272888184
Validation loss: 2.7051604999009

Epoch: 6| Step: 12
Training loss: 2.4239907264709473
Validation loss: 2.7037973224475818

Epoch: 6| Step: 13
Training loss: 3.5292012691497803
Validation loss: 2.703725814819336

Epoch: 87| Step: 0
Training loss: 3.006171464920044
Validation loss: 2.7124964447431665

Epoch: 6| Step: 1
Training loss: 2.3712902069091797
Validation loss: 2.7483634256547496

Epoch: 6| Step: 2
Training loss: 2.666064739227295
Validation loss: 2.765650951734153

Epoch: 6| Step: 3
Training loss: 3.471900463104248
Validation loss: 2.7740823530381724

Epoch: 6| Step: 4
Training loss: 2.8942015171051025
Validation loss: 2.779849011410949

Epoch: 6| Step: 5
Training loss: 3.4270853996276855
Validation loss: 2.7625592780369583

Epoch: 6| Step: 6
Training loss: 3.3841357231140137
Validation loss: 2.727872771601523

Epoch: 6| Step: 7
Training loss: 2.5780906677246094
Validation loss: 2.720077694103282

Epoch: 6| Step: 8
Training loss: 2.235874891281128
Validation loss: 2.7326907855208202

Epoch: 6| Step: 9
Training loss: 2.7265233993530273
Validation loss: 2.73083951909055

Epoch: 6| Step: 10
Training loss: 2.492248058319092
Validation loss: 2.7419071787147113

Epoch: 6| Step: 11
Training loss: 3.329869508743286
Validation loss: 2.7455281621666363

Epoch: 6| Step: 12
Training loss: 2.8659605979919434
Validation loss: 2.7480162087307183

Epoch: 6| Step: 13
Training loss: 2.6055498123168945
Validation loss: 2.737862028101439

Epoch: 88| Step: 0
Training loss: 2.497800588607788
Validation loss: 2.729941716758154

Epoch: 6| Step: 1
Training loss: 2.5457334518432617
Validation loss: 2.713042974472046

Epoch: 6| Step: 2
Training loss: 2.679823637008667
Validation loss: 2.69848314151969

Epoch: 6| Step: 3
Training loss: 2.9194793701171875
Validation loss: 2.6994517182791107

Epoch: 6| Step: 4
Training loss: 2.4103989601135254
Validation loss: 2.700895047956897

Epoch: 6| Step: 5
Training loss: 2.292593479156494
Validation loss: 2.6998314754937285

Epoch: 6| Step: 6
Training loss: 3.4316439628601074
Validation loss: 2.71076867657323

Epoch: 6| Step: 7
Training loss: 2.8501038551330566
Validation loss: 2.70811475476911

Epoch: 6| Step: 8
Training loss: 2.8104007244110107
Validation loss: 2.7099267231520785

Epoch: 6| Step: 9
Training loss: 3.0650806427001953
Validation loss: 2.7078028801948792

Epoch: 6| Step: 10
Training loss: 2.653824806213379
Validation loss: 2.704558931371217

Epoch: 6| Step: 11
Training loss: 3.2173874378204346
Validation loss: 2.7027845049417145

Epoch: 6| Step: 12
Training loss: 3.19594669342041
Validation loss: 2.7004553015514086

Epoch: 6| Step: 13
Training loss: 3.6029272079467773
Validation loss: 2.7000369974361953

Epoch: 89| Step: 0
Training loss: 3.712421417236328
Validation loss: 2.699884436463797

Epoch: 6| Step: 1
Training loss: 2.6694514751434326
Validation loss: 2.697514141759565

Epoch: 6| Step: 2
Training loss: 2.86525559425354
Validation loss: 2.6977129597817697

Epoch: 6| Step: 3
Training loss: 1.9254300594329834
Validation loss: 2.7004009087880454

Epoch: 6| Step: 4
Training loss: 3.665353298187256
Validation loss: 2.700581971035209

Epoch: 6| Step: 5
Training loss: 3.4349465370178223
Validation loss: 2.700420641130017

Epoch: 6| Step: 6
Training loss: 2.785536766052246
Validation loss: 2.7034180318155596

Epoch: 6| Step: 7
Training loss: 2.243835210800171
Validation loss: 2.705419573732602

Epoch: 6| Step: 8
Training loss: 2.117224931716919
Validation loss: 2.7056496297159502

Epoch: 6| Step: 9
Training loss: 2.9094462394714355
Validation loss: 2.707728639725716

Epoch: 6| Step: 10
Training loss: 2.7761659622192383
Validation loss: 2.7073168677668416

Epoch: 6| Step: 11
Training loss: 3.3310766220092773
Validation loss: 2.709201305143295

Epoch: 6| Step: 12
Training loss: 2.448031187057495
Validation loss: 2.70770457226743

Epoch: 6| Step: 13
Training loss: 2.9170374870300293
Validation loss: 2.7028897757171304

Epoch: 90| Step: 0
Training loss: 2.560711622238159
Validation loss: 2.698651054854034

Epoch: 6| Step: 1
Training loss: 2.6673483848571777
Validation loss: 2.696456301596857

Epoch: 6| Step: 2
Training loss: 2.798621416091919
Validation loss: 2.695798081736411

Epoch: 6| Step: 3
Training loss: 2.381481170654297
Validation loss: 2.697355975386917

Epoch: 6| Step: 4
Training loss: 3.606365919113159
Validation loss: 2.6940017695068033

Epoch: 6| Step: 5
Training loss: 2.5203638076782227
Validation loss: 2.697104525822465

Epoch: 6| Step: 6
Training loss: 3.779845952987671
Validation loss: 2.698050593817106

Epoch: 6| Step: 7
Training loss: 2.473377227783203
Validation loss: 2.700756880544847

Epoch: 6| Step: 8
Training loss: 2.380366325378418
Validation loss: 2.6982157871287358

Epoch: 6| Step: 9
Training loss: 3.066877603530884
Validation loss: 2.7057512806307886

Epoch: 6| Step: 10
Training loss: 2.70076060295105
Validation loss: 2.702849413758965

Epoch: 6| Step: 11
Training loss: 3.341846466064453
Validation loss: 2.7022269131034933

Epoch: 6| Step: 12
Training loss: 2.5589542388916016
Validation loss: 2.6986199527658443

Epoch: 6| Step: 13
Training loss: 2.926370859146118
Validation loss: 2.7020791217844975

Epoch: 91| Step: 0
Training loss: 2.518106460571289
Validation loss: 2.6937999058795232

Epoch: 6| Step: 1
Training loss: 1.5944228172302246
Validation loss: 2.696899994727104

Epoch: 6| Step: 2
Training loss: 3.0518102645874023
Validation loss: 2.6973470436629428

Epoch: 6| Step: 3
Training loss: 2.099031686782837
Validation loss: 2.696139210013933

Epoch: 6| Step: 4
Training loss: 2.3157589435577393
Validation loss: 2.6948055836462204

Epoch: 6| Step: 5
Training loss: 2.6968464851379395
Validation loss: 2.694606355441514

Epoch: 6| Step: 6
Training loss: 3.9551146030426025
Validation loss: 2.6926875909169516

Epoch: 6| Step: 7
Training loss: 3.447542428970337
Validation loss: 2.6933320030089347

Epoch: 6| Step: 8
Training loss: 3.470303535461426
Validation loss: 2.6904131058723695

Epoch: 6| Step: 9
Training loss: 2.370927333831787
Validation loss: 2.6926484723244943

Epoch: 6| Step: 10
Training loss: 2.6108222007751465
Validation loss: 2.6916369763753747

Epoch: 6| Step: 11
Training loss: 3.6767454147338867
Validation loss: 2.6900641687454714

Epoch: 6| Step: 12
Training loss: 3.011551856994629
Validation loss: 2.6919436147136073

Epoch: 6| Step: 13
Training loss: 2.9717695713043213
Validation loss: 2.6952574253082275

Epoch: 92| Step: 0
Training loss: 3.2478480339050293
Validation loss: 2.6969911462517193

Epoch: 6| Step: 1
Training loss: 3.6192121505737305
Validation loss: 2.6963999912302983

Epoch: 6| Step: 2
Training loss: 3.0931315422058105
Validation loss: 2.6942745177976546

Epoch: 6| Step: 3
Training loss: 1.9049103260040283
Validation loss: 2.6982067169681674

Epoch: 6| Step: 4
Training loss: 2.964902400970459
Validation loss: 2.696917677438387

Epoch: 6| Step: 5
Training loss: 2.826625347137451
Validation loss: 2.696556968073691

Epoch: 6| Step: 6
Training loss: 2.6478781700134277
Validation loss: 2.6929302702667894

Epoch: 6| Step: 7
Training loss: 2.984583854675293
Validation loss: 2.69509445980031

Epoch: 6| Step: 8
Training loss: 2.647139549255371
Validation loss: 2.6948155151900424

Epoch: 6| Step: 9
Training loss: 3.4542479515075684
Validation loss: 2.6932420474226757

Epoch: 6| Step: 10
Training loss: 2.501365900039673
Validation loss: 2.694964575511153

Epoch: 6| Step: 11
Training loss: 2.067335605621338
Validation loss: 2.6980320612589517

Epoch: 6| Step: 12
Training loss: 3.158102035522461
Validation loss: 2.6911873689261814

Epoch: 6| Step: 13
Training loss: 2.3572115898132324
Validation loss: 2.6942030255512526

Epoch: 93| Step: 0
Training loss: 2.565034866333008
Validation loss: 2.690122381333382

Epoch: 6| Step: 1
Training loss: 2.58288836479187
Validation loss: 2.6875866177261516

Epoch: 6| Step: 2
Training loss: 3.139437675476074
Validation loss: 2.688945257535545

Epoch: 6| Step: 3
Training loss: 2.87664794921875
Validation loss: 2.690301436249928

Epoch: 6| Step: 4
Training loss: 3.2162294387817383
Validation loss: 2.6891217744478615

Epoch: 6| Step: 5
Training loss: 2.212604522705078
Validation loss: 2.687272628148397

Epoch: 6| Step: 6
Training loss: 2.7918403148651123
Validation loss: 2.6881094747974026

Epoch: 6| Step: 7
Training loss: 3.0795304775238037
Validation loss: 2.6864868210208033

Epoch: 6| Step: 8
Training loss: 3.350487232208252
Validation loss: 2.6894016163323515

Epoch: 6| Step: 9
Training loss: 2.7022511959075928
Validation loss: 2.6860350485770934

Epoch: 6| Step: 10
Training loss: 2.897642135620117
Validation loss: 2.689208815174718

Epoch: 6| Step: 11
Training loss: 3.3402600288391113
Validation loss: 2.689185247626356

Epoch: 6| Step: 12
Training loss: 2.1803548336029053
Validation loss: 2.6893870702353855

Epoch: 6| Step: 13
Training loss: 2.615139961242676
Validation loss: 2.691750664864817

Epoch: 94| Step: 0
Training loss: 2.8395166397094727
Validation loss: 2.6897059012484807

Epoch: 6| Step: 1
Training loss: 2.8897531032562256
Validation loss: 2.693205646289292

Epoch: 6| Step: 2
Training loss: 3.07741641998291
Validation loss: 2.690575538143035

Epoch: 6| Step: 3
Training loss: 2.089000701904297
Validation loss: 2.6873455457789923

Epoch: 6| Step: 4
Training loss: 3.6648623943328857
Validation loss: 2.686877496780888

Epoch: 6| Step: 5
Training loss: 2.3178443908691406
Validation loss: 2.693350048475368

Epoch: 6| Step: 6
Training loss: 2.919576644897461
Validation loss: 2.6834889868254304

Epoch: 6| Step: 7
Training loss: 2.4880528450012207
Validation loss: 2.6880595273869012

Epoch: 6| Step: 8
Training loss: 2.443756580352783
Validation loss: 2.6831708620953303

Epoch: 6| Step: 9
Training loss: 3.14176869392395
Validation loss: 2.6853123172636955

Epoch: 6| Step: 10
Training loss: 3.792459011077881
Validation loss: 2.6851566709497923

Epoch: 6| Step: 11
Training loss: 2.9533004760742188
Validation loss: 2.683917942867484

Epoch: 6| Step: 12
Training loss: 2.3582446575164795
Validation loss: 2.6855524842457106

Epoch: 6| Step: 13
Training loss: 2.507223129272461
Validation loss: 2.684920408392465

Epoch: 95| Step: 0
Training loss: 3.1347806453704834
Validation loss: 2.685913788375034

Epoch: 6| Step: 1
Training loss: 3.3070003986358643
Validation loss: 2.683665995956749

Epoch: 6| Step: 2
Training loss: 2.7178289890289307
Validation loss: 2.6845311439165505

Epoch: 6| Step: 3
Training loss: 2.8466544151306152
Validation loss: 2.6824579136345976

Epoch: 6| Step: 4
Training loss: 2.7073538303375244
Validation loss: 2.682045308492517

Epoch: 6| Step: 5
Training loss: 3.0412402153015137
Validation loss: 2.6823953582394506

Epoch: 6| Step: 6
Training loss: 2.7145543098449707
Validation loss: 2.680797005212435

Epoch: 6| Step: 7
Training loss: 2.1443064212799072
Validation loss: 2.6831760150130077

Epoch: 6| Step: 8
Training loss: 2.465940475463867
Validation loss: 2.681352469228929

Epoch: 6| Step: 9
Training loss: 3.515005588531494
Validation loss: 2.6820428832884757

Epoch: 6| Step: 10
Training loss: 1.9111576080322266
Validation loss: 2.68170662336452

Epoch: 6| Step: 11
Training loss: 3.019369125366211
Validation loss: 2.685255104495633

Epoch: 6| Step: 12
Training loss: 2.8146424293518066
Validation loss: 2.6842312530804704

Epoch: 6| Step: 13
Training loss: 3.565690040588379
Validation loss: 2.6815919773553007

Epoch: 96| Step: 0
Training loss: 2.9146828651428223
Validation loss: 2.6805200781873477

Epoch: 6| Step: 1
Training loss: 2.7347512245178223
Validation loss: 2.6847293761468705

Epoch: 6| Step: 2
Training loss: 3.2274177074432373
Validation loss: 2.679935222030968

Epoch: 6| Step: 3
Training loss: 2.756812810897827
Validation loss: 2.6795650246322795

Epoch: 6| Step: 4
Training loss: 3.0832529067993164
Validation loss: 2.677432411460466

Epoch: 6| Step: 5
Training loss: 2.227296829223633
Validation loss: 2.6792197022386777

Epoch: 6| Step: 6
Training loss: 3.5244383811950684
Validation loss: 2.677861605921099

Epoch: 6| Step: 7
Training loss: 3.0068564414978027
Validation loss: 2.679854190477761

Epoch: 6| Step: 8
Training loss: 2.550017833709717
Validation loss: 2.683128933752737

Epoch: 6| Step: 9
Training loss: 2.9355902671813965
Validation loss: 2.6833741459795224

Epoch: 6| Step: 10
Training loss: 3.001904010772705
Validation loss: 2.684282345156516

Epoch: 6| Step: 11
Training loss: 2.363583564758301
Validation loss: 2.682413080687164

Epoch: 6| Step: 12
Training loss: 2.4080605506896973
Validation loss: 2.681558019371443

Epoch: 6| Step: 13
Training loss: 2.775399684906006
Validation loss: 2.678746695159584

Epoch: 97| Step: 0
Training loss: 2.4834704399108887
Validation loss: 2.683192512040497

Epoch: 6| Step: 1
Training loss: 3.629274368286133
Validation loss: 2.678219372226346

Epoch: 6| Step: 2
Training loss: 2.8325862884521484
Validation loss: 2.676700989405314

Epoch: 6| Step: 3
Training loss: 2.9708266258239746
Validation loss: 2.6755746487648255

Epoch: 6| Step: 4
Training loss: 2.555110454559326
Validation loss: 2.678451961086642

Epoch: 6| Step: 5
Training loss: 3.0505571365356445
Validation loss: 2.679254549805836

Epoch: 6| Step: 6
Training loss: 2.6339187622070312
Validation loss: 2.678223720160864

Epoch: 6| Step: 7
Training loss: 2.913242816925049
Validation loss: 2.685166517893473

Epoch: 6| Step: 8
Training loss: 3.032707691192627
Validation loss: 2.6812938695312827

Epoch: 6| Step: 9
Training loss: 2.49686861038208
Validation loss: 2.678960874516477

Epoch: 6| Step: 10
Training loss: 2.563030242919922
Validation loss: 2.6824265244186565

Epoch: 6| Step: 11
Training loss: 3.382704257965088
Validation loss: 2.679626659680438

Epoch: 6| Step: 12
Training loss: 2.7615318298339844
Validation loss: 2.677938504885602

Epoch: 6| Step: 13
Training loss: 1.71468985080719
Validation loss: 2.6830254754712506

Epoch: 98| Step: 0
Training loss: 2.6177496910095215
Validation loss: 2.6781072539667927

Epoch: 6| Step: 1
Training loss: 3.1657779216766357
Validation loss: 2.6786447442987913

Epoch: 6| Step: 2
Training loss: 2.975179672241211
Validation loss: 2.6760452152580343

Epoch: 6| Step: 3
Training loss: 3.3097753524780273
Validation loss: 2.6748929305743148

Epoch: 6| Step: 4
Training loss: 2.024369716644287
Validation loss: 2.675477494475662

Epoch: 6| Step: 5
Training loss: 2.7023963928222656
Validation loss: 2.675347005167315

Epoch: 6| Step: 6
Training loss: 2.612531900405884
Validation loss: 2.6714302698771157

Epoch: 6| Step: 7
Training loss: 3.1381852626800537
Validation loss: 2.677734754418814

Epoch: 6| Step: 8
Training loss: 2.8426513671875
Validation loss: 2.674511722339097

Epoch: 6| Step: 9
Training loss: 2.5235366821289062
Validation loss: 2.6768719175810456

Epoch: 6| Step: 10
Training loss: 2.6104583740234375
Validation loss: 2.6773202650008665

Epoch: 6| Step: 11
Training loss: 2.4895615577697754
Validation loss: 2.6752116244326354

Epoch: 6| Step: 12
Training loss: 3.7249040603637695
Validation loss: 2.6771767754708566

Epoch: 6| Step: 13
Training loss: 2.711230754852295
Validation loss: 2.6764934883322766

Epoch: 99| Step: 0
Training loss: 2.218323230743408
Validation loss: 2.675541764946394

Epoch: 6| Step: 1
Training loss: 2.310628652572632
Validation loss: 2.676976755101194

Epoch: 6| Step: 2
Training loss: 3.226783037185669
Validation loss: 2.679263489220732

Epoch: 6| Step: 3
Training loss: 2.616304636001587
Validation loss: 2.676326767090828

Epoch: 6| Step: 4
Training loss: 3.622002124786377
Validation loss: 2.6779706401209675

Epoch: 6| Step: 5
Training loss: 2.6473610401153564
Validation loss: 2.6749346692075013

Epoch: 6| Step: 6
Training loss: 2.8425004482269287
Validation loss: 2.675830364227295

Epoch: 6| Step: 7
Training loss: 2.8480331897735596
Validation loss: 2.673639428231024

Epoch: 6| Step: 8
Training loss: 3.060981035232544
Validation loss: 2.676047258479621

Epoch: 6| Step: 9
Training loss: 3.4137821197509766
Validation loss: 2.6738496083085255

Epoch: 6| Step: 10
Training loss: 2.616880416870117
Validation loss: 2.672355559564406

Epoch: 6| Step: 11
Training loss: 2.8693227767944336
Validation loss: 2.674770216788015

Epoch: 6| Step: 12
Training loss: 2.1389894485473633
Validation loss: 2.6719134084640013

Epoch: 6| Step: 13
Training loss: 3.1892404556274414
Validation loss: 2.6741698147148214

Epoch: 100| Step: 0
Training loss: 2.9166057109832764
Validation loss: 2.6748473746802217

Epoch: 6| Step: 1
Training loss: 2.5256447792053223
Validation loss: 2.6724075860874628

Epoch: 6| Step: 2
Training loss: 2.9542360305786133
Validation loss: 2.6774735912199943

Epoch: 6| Step: 3
Training loss: 3.18572998046875
Validation loss: 2.6763368729622132

Epoch: 6| Step: 4
Training loss: 3.38421368598938
Validation loss: 2.678903369493382

Epoch: 6| Step: 5
Training loss: 2.9277615547180176
Validation loss: 2.675302659311602

Epoch: 6| Step: 6
Training loss: 2.4267263412475586
Validation loss: 2.6725239779359553

Epoch: 6| Step: 7
Training loss: 2.8493261337280273
Validation loss: 2.6764500269325833

Epoch: 6| Step: 8
Training loss: 3.007582187652588
Validation loss: 2.6734675797083045

Epoch: 6| Step: 9
Training loss: 2.9558238983154297
Validation loss: 2.672237068094233

Epoch: 6| Step: 10
Training loss: 1.677494764328003
Validation loss: 2.6687425310893724

Epoch: 6| Step: 11
Training loss: 2.4264955520629883
Validation loss: 2.669092942309636

Epoch: 6| Step: 12
Training loss: 2.7937235832214355
Validation loss: 2.669577452444261

Epoch: 6| Step: 13
Training loss: 3.779550313949585
Validation loss: 2.6675151958260486

Epoch: 101| Step: 0
Training loss: 2.842881202697754
Validation loss: 2.6686639452493317

Epoch: 6| Step: 1
Training loss: 2.0912046432495117
Validation loss: 2.669694185256958

Epoch: 6| Step: 2
Training loss: 3.2583954334259033
Validation loss: 2.6709163624753236

Epoch: 6| Step: 3
Training loss: 3.607609748840332
Validation loss: 2.67091554211032

Epoch: 6| Step: 4
Training loss: 2.586010217666626
Validation loss: 2.668099316217566

Epoch: 6| Step: 5
Training loss: 3.094104290008545
Validation loss: 2.6700262792648806

Epoch: 6| Step: 6
Training loss: 2.062955379486084
Validation loss: 2.673140166908182

Epoch: 6| Step: 7
Training loss: 2.1420440673828125
Validation loss: 2.6683358851299492

Epoch: 6| Step: 8
Training loss: 2.7915430068969727
Validation loss: 2.6684428543172856

Epoch: 6| Step: 9
Training loss: 2.772517204284668
Validation loss: 2.6705501002650105

Epoch: 6| Step: 10
Training loss: 2.670036554336548
Validation loss: 2.6807005969426965

Epoch: 6| Step: 11
Training loss: 3.168917417526245
Validation loss: 2.6794457820154007

Epoch: 6| Step: 12
Training loss: 3.5921034812927246
Validation loss: 2.67114015804824

Epoch: 6| Step: 13
Training loss: 2.7118847370147705
Validation loss: 2.6670100330024638

Epoch: 102| Step: 0
Training loss: 3.8027234077453613
Validation loss: 2.666152787464921

Epoch: 6| Step: 1
Training loss: 3.0592260360717773
Validation loss: 2.6656764604712047

Epoch: 6| Step: 2
Training loss: 3.4254627227783203
Validation loss: 2.66775833406756

Epoch: 6| Step: 3
Training loss: 2.3995842933654785
Validation loss: 2.6661625549357426

Epoch: 6| Step: 4
Training loss: 3.200951099395752
Validation loss: 2.667809755571427

Epoch: 6| Step: 5
Training loss: 2.7045130729675293
Validation loss: 2.67211587198319

Epoch: 6| Step: 6
Training loss: 3.003206729888916
Validation loss: 2.667616864686371

Epoch: 6| Step: 7
Training loss: 2.783745288848877
Validation loss: 2.6711681273675736

Epoch: 6| Step: 8
Training loss: 2.0652105808258057
Validation loss: 2.6696897834859867

Epoch: 6| Step: 9
Training loss: 2.237417221069336
Validation loss: 2.6708124376112417

Epoch: 6| Step: 10
Training loss: 2.775646209716797
Validation loss: 2.6698989919436875

Epoch: 6| Step: 11
Training loss: 2.4815096855163574
Validation loss: 2.6684546598824124

Epoch: 6| Step: 12
Training loss: 3.0555577278137207
Validation loss: 2.668147535734279

Epoch: 6| Step: 13
Training loss: 2.007747173309326
Validation loss: 2.664954939196187

Epoch: 103| Step: 0
Training loss: 2.774942398071289
Validation loss: 2.6655999332345943

Epoch: 6| Step: 1
Training loss: 2.441720724105835
Validation loss: 2.662283056525774

Epoch: 6| Step: 2
Training loss: 3.05301570892334
Validation loss: 2.663436423065842

Epoch: 6| Step: 3
Training loss: 2.988417863845825
Validation loss: 2.666585829950148

Epoch: 6| Step: 4
Training loss: 2.541752815246582
Validation loss: 2.676959522308842

Epoch: 6| Step: 5
Training loss: 2.8082432746887207
Validation loss: 2.6645098578545356

Epoch: 6| Step: 6
Training loss: 2.6373131275177
Validation loss: 2.663930449434506

Epoch: 6| Step: 7
Training loss: 3.9205069541931152
Validation loss: 2.664802884542814

Epoch: 6| Step: 8
Training loss: 3.17836594581604
Validation loss: 2.670728609126101

Epoch: 6| Step: 9
Training loss: 1.659677267074585
Validation loss: 2.6724596126105196

Epoch: 6| Step: 10
Training loss: 2.8247923851013184
Validation loss: 2.670795412473781

Epoch: 6| Step: 11
Training loss: 2.8743717670440674
Validation loss: 2.678812119268602

Epoch: 6| Step: 12
Training loss: 2.945516347885132
Validation loss: 2.6798462419099707

Epoch: 6| Step: 13
Training loss: 2.6709046363830566
Validation loss: 2.671536486635926

Epoch: 104| Step: 0
Training loss: 3.0725326538085938
Validation loss: 2.6710074268361574

Epoch: 6| Step: 1
Training loss: 2.244960308074951
Validation loss: 2.6752068765701784

Epoch: 6| Step: 2
Training loss: 2.5189976692199707
Validation loss: 2.676050255375524

Epoch: 6| Step: 3
Training loss: 3.0438072681427
Validation loss: 2.6745828659303728

Epoch: 6| Step: 4
Training loss: 2.534024715423584
Validation loss: 2.667677266623384

Epoch: 6| Step: 5
Training loss: 2.918868064880371
Validation loss: 2.668306645526681

Epoch: 6| Step: 6
Training loss: 2.1093649864196777
Validation loss: 2.6675797406063286

Epoch: 6| Step: 7
Training loss: 2.6737756729125977
Validation loss: 2.6636623720968924

Epoch: 6| Step: 8
Training loss: 3.0201005935668945
Validation loss: 2.660609693937404

Epoch: 6| Step: 9
Training loss: 2.8189055919647217
Validation loss: 2.660121503696647

Epoch: 6| Step: 10
Training loss: 3.2763426303863525
Validation loss: 2.659155830260246

Epoch: 6| Step: 11
Training loss: 2.666444778442383
Validation loss: 2.657658346237675

Epoch: 6| Step: 12
Training loss: 3.298290252685547
Validation loss: 2.656903692471084

Epoch: 6| Step: 13
Training loss: 3.3338634967803955
Validation loss: 2.658756858559065

Epoch: 105| Step: 0
Training loss: 3.104381561279297
Validation loss: 2.660845592457761

Epoch: 6| Step: 1
Training loss: 3.9080710411071777
Validation loss: 2.6602294342492216

Epoch: 6| Step: 2
Training loss: 2.8839054107666016
Validation loss: 2.6617210962439097

Epoch: 6| Step: 3
Training loss: 3.5982823371887207
Validation loss: 2.660689884616483

Epoch: 6| Step: 4
Training loss: 2.4028890132904053
Validation loss: 2.6601895619464178

Epoch: 6| Step: 5
Training loss: 3.2558672428131104
Validation loss: 2.658168533796905

Epoch: 6| Step: 6
Training loss: 2.5048599243164062
Validation loss: 2.6605888720481627

Epoch: 6| Step: 7
Training loss: 2.3641557693481445
Validation loss: 2.6577474609498055

Epoch: 6| Step: 8
Training loss: 2.5362327098846436
Validation loss: 2.6576617328069543

Epoch: 6| Step: 9
Training loss: 1.8148999214172363
Validation loss: 2.656629631596227

Epoch: 6| Step: 10
Training loss: 2.295865535736084
Validation loss: 2.659668719896706

Epoch: 6| Step: 11
Training loss: 2.9155755043029785
Validation loss: 2.659253135804207

Epoch: 6| Step: 12
Training loss: 2.347275733947754
Validation loss: 2.6675174800298547

Epoch: 6| Step: 13
Training loss: 3.8245468139648438
Validation loss: 2.667489331255677

Epoch: 106| Step: 0
Training loss: 2.361222267150879
Validation loss: 2.6693811570444415

Epoch: 6| Step: 1
Training loss: 2.4292869567871094
Validation loss: 2.6673069307881017

Epoch: 6| Step: 2
Training loss: 2.2784628868103027
Validation loss: 2.6668066145271383

Epoch: 6| Step: 3
Training loss: 3.0820960998535156
Validation loss: 2.669664659807759

Epoch: 6| Step: 4
Training loss: 3.0657262802124023
Validation loss: 2.668448817345404

Epoch: 6| Step: 5
Training loss: 2.2457220554351807
Validation loss: 2.6599224511013237

Epoch: 6| Step: 6
Training loss: 4.167397499084473
Validation loss: 2.66383800455319

Epoch: 6| Step: 7
Training loss: 2.979996681213379
Validation loss: 2.6554930158840713

Epoch: 6| Step: 8
Training loss: 3.3566267490386963
Validation loss: 2.659296476712791

Epoch: 6| Step: 9
Training loss: 3.059629440307617
Validation loss: 2.6538901867405063

Epoch: 6| Step: 10
Training loss: 2.866530418395996
Validation loss: 2.6538110497177287

Epoch: 6| Step: 11
Training loss: 1.89644193649292
Validation loss: 2.6574203737320437

Epoch: 6| Step: 12
Training loss: 3.025883197784424
Validation loss: 2.65727222863064

Epoch: 6| Step: 13
Training loss: 2.2126526832580566
Validation loss: 2.6558510154806156

Epoch: 107| Step: 0
Training loss: 2.936910629272461
Validation loss: 2.6554534742909093

Epoch: 6| Step: 1
Training loss: 3.047528028488159
Validation loss: 2.6540586794576337

Epoch: 6| Step: 2
Training loss: 3.6416280269622803
Validation loss: 2.6529858932700208

Epoch: 6| Step: 3
Training loss: 2.4664804935455322
Validation loss: 2.6520031780324955

Epoch: 6| Step: 4
Training loss: 3.3667421340942383
Validation loss: 2.6546164430597776

Epoch: 6| Step: 5
Training loss: 3.439483642578125
Validation loss: 2.6550922624526487

Epoch: 6| Step: 6
Training loss: 2.49961519241333
Validation loss: 2.6567116552783596

Epoch: 6| Step: 7
Training loss: 2.3373899459838867
Validation loss: 2.653803535687026

Epoch: 6| Step: 8
Training loss: 2.296825885772705
Validation loss: 2.6574463921208538

Epoch: 6| Step: 9
Training loss: 2.09877347946167
Validation loss: 2.6540811548950853

Epoch: 6| Step: 10
Training loss: 2.489309310913086
Validation loss: 2.6537089322202947

Epoch: 6| Step: 11
Training loss: 2.7868857383728027
Validation loss: 2.6528187439005864

Epoch: 6| Step: 12
Training loss: 3.349180221557617
Validation loss: 2.653616266865884

Epoch: 6| Step: 13
Training loss: 2.2352612018585205
Validation loss: 2.648977477063415

Epoch: 108| Step: 0
Training loss: 2.35005521774292
Validation loss: 2.6497222864499657

Epoch: 6| Step: 1
Training loss: 1.5631382465362549
Validation loss: 2.653117774635233

Epoch: 6| Step: 2
Training loss: 3.3325648307800293
Validation loss: 2.64988588517712

Epoch: 6| Step: 3
Training loss: 3.6822478771209717
Validation loss: 2.6491569652352283

Epoch: 6| Step: 4
Training loss: 2.8243813514709473
Validation loss: 2.652801231671405

Epoch: 6| Step: 5
Training loss: 4.408524036407471
Validation loss: 2.64988463412049

Epoch: 6| Step: 6
Training loss: 1.872560977935791
Validation loss: 2.649979852860974

Epoch: 6| Step: 7
Training loss: 2.845165252685547
Validation loss: 2.6494710445404053

Epoch: 6| Step: 8
Training loss: 2.8382041454315186
Validation loss: 2.651585817337036

Epoch: 6| Step: 9
Training loss: 2.7431299686431885
Validation loss: 2.6522727166452715

Epoch: 6| Step: 10
Training loss: 3.0785703659057617
Validation loss: 2.6592626828019337

Epoch: 6| Step: 11
Training loss: 2.330815076828003
Validation loss: 2.654954848750945

Epoch: 6| Step: 12
Training loss: 2.4412765502929688
Validation loss: 2.657940464635049

Epoch: 6| Step: 13
Training loss: 2.8990113735198975
Validation loss: 2.6575602972379295

Epoch: 109| Step: 0
Training loss: 2.423828601837158
Validation loss: 2.6628586861395065

Epoch: 6| Step: 1
Training loss: 2.9372761249542236
Validation loss: 2.6670049287939586

Epoch: 6| Step: 2
Training loss: 2.32796573638916
Validation loss: 2.665443451173844

Epoch: 6| Step: 3
Training loss: 3.509627342224121
Validation loss: 2.670820010605679

Epoch: 6| Step: 4
Training loss: 2.7056565284729004
Validation loss: 2.6794779223780476

Epoch: 6| Step: 5
Training loss: 2.8904361724853516
Validation loss: 2.6814699172973633

Epoch: 6| Step: 6
Training loss: 2.3155176639556885
Validation loss: 2.6887242383854364

Epoch: 6| Step: 7
Training loss: 2.410153865814209
Validation loss: 2.690249676345497

Epoch: 6| Step: 8
Training loss: 3.3662514686584473
Validation loss: 2.6699887244932112

Epoch: 6| Step: 9
Training loss: 3.1137876510620117
Validation loss: 2.6586969103864444

Epoch: 6| Step: 10
Training loss: 2.7024459838867188
Validation loss: 2.6524373754378288

Epoch: 6| Step: 11
Training loss: 2.903085708618164
Validation loss: 2.652448292701475

Epoch: 6| Step: 12
Training loss: 3.6027889251708984
Validation loss: 2.6474177478462138

Epoch: 6| Step: 13
Training loss: 1.4105782508850098
Validation loss: 2.650025639482724

Epoch: 110| Step: 0
Training loss: 3.3090198040008545
Validation loss: 2.6489530173681115

Epoch: 6| Step: 1
Training loss: 2.4745724201202393
Validation loss: 2.6471965338594172

Epoch: 6| Step: 2
Training loss: 2.1310317516326904
Validation loss: 2.6504204785952004

Epoch: 6| Step: 3
Training loss: 2.9768362045288086
Validation loss: 2.647108716349448

Epoch: 6| Step: 4
Training loss: 2.9631528854370117
Validation loss: 2.6487939870485695

Epoch: 6| Step: 5
Training loss: 3.04746150970459
Validation loss: 2.6469412285794496

Epoch: 6| Step: 6
Training loss: 2.87966251373291
Validation loss: 2.6473154842212634

Epoch: 6| Step: 7
Training loss: 2.756248950958252
Validation loss: 2.6492657892165647

Epoch: 6| Step: 8
Training loss: 3.016468048095703
Validation loss: 2.6453471106867634

Epoch: 6| Step: 9
Training loss: 2.891787528991699
Validation loss: 2.6484953100963304

Epoch: 6| Step: 10
Training loss: 2.2851977348327637
Validation loss: 2.6489181159645

Epoch: 6| Step: 11
Training loss: 2.7180206775665283
Validation loss: 2.6458126114260767

Epoch: 6| Step: 12
Training loss: 2.745750904083252
Validation loss: 2.6456911640782512

Epoch: 6| Step: 13
Training loss: 3.078455924987793
Validation loss: 2.643939838614515

Epoch: 111| Step: 0
Training loss: 1.8962923288345337
Validation loss: 2.6433857640912457

Epoch: 6| Step: 1
Training loss: 2.860166072845459
Validation loss: 2.646384918561546

Epoch: 6| Step: 2
Training loss: 3.230605363845825
Validation loss: 2.6458241093543267

Epoch: 6| Step: 3
Training loss: 3.4727423191070557
Validation loss: 2.6471540774068525

Epoch: 6| Step: 4
Training loss: 3.495793342590332
Validation loss: 2.6460056484386487

Epoch: 6| Step: 5
Training loss: 2.998486280441284
Validation loss: 2.6453977707893617

Epoch: 6| Step: 6
Training loss: 2.6345372200012207
Validation loss: 2.6464899919366323

Epoch: 6| Step: 7
Training loss: 2.328660249710083
Validation loss: 2.642979009177095

Epoch: 6| Step: 8
Training loss: 2.6269471645355225
Validation loss: 2.642499969851586

Epoch: 6| Step: 9
Training loss: 2.782209873199463
Validation loss: 2.6435161200902795

Epoch: 6| Step: 10
Training loss: 3.3975718021392822
Validation loss: 2.646159951404859

Epoch: 6| Step: 11
Training loss: 1.8179839849472046
Validation loss: 2.6488118248601116

Epoch: 6| Step: 12
Training loss: 2.8874785900115967
Validation loss: 2.6473785369626937

Epoch: 6| Step: 13
Training loss: 2.6028056144714355
Validation loss: 2.6426168949373308

Epoch: 112| Step: 0
Training loss: 2.9279303550720215
Validation loss: 2.6502966573161464

Epoch: 6| Step: 1
Training loss: 2.3249170780181885
Validation loss: 2.6459849854951263

Epoch: 6| Step: 2
Training loss: 2.680816173553467
Validation loss: 2.6404116897172827

Epoch: 6| Step: 3
Training loss: 2.567507743835449
Validation loss: 2.642311267955329

Epoch: 6| Step: 4
Training loss: 2.6800308227539062
Validation loss: 2.6427461254981255

Epoch: 6| Step: 5
Training loss: 3.0712428092956543
Validation loss: 2.6438202832334783

Epoch: 6| Step: 6
Training loss: 2.8531742095947266
Validation loss: 2.647278047377063

Epoch: 6| Step: 7
Training loss: 3.8141071796417236
Validation loss: 2.658346364575048

Epoch: 6| Step: 8
Training loss: 1.7584830522537231
Validation loss: 2.6539717643491683

Epoch: 6| Step: 9
Training loss: 3.4862239360809326
Validation loss: 2.652426991411435

Epoch: 6| Step: 10
Training loss: 3.3962855339050293
Validation loss: 2.6442037948998074

Epoch: 6| Step: 11
Training loss: 2.204481601715088
Validation loss: 2.643663424317555

Epoch: 6| Step: 12
Training loss: 2.9669578075408936
Validation loss: 2.6455254324020876

Epoch: 6| Step: 13
Training loss: 2.1257829666137695
Validation loss: 2.6394051864583004

Epoch: 113| Step: 0
Training loss: 3.265634536743164
Validation loss: 2.6382668133704894

Epoch: 6| Step: 1
Training loss: 2.0308456420898438
Validation loss: 2.639558620350335

Epoch: 6| Step: 2
Training loss: 2.1363022327423096
Validation loss: 2.653097434710431

Epoch: 6| Step: 3
Training loss: 2.5483694076538086
Validation loss: 2.6487209899451143

Epoch: 6| Step: 4
Training loss: 3.009481906890869
Validation loss: 2.651916821797689

Epoch: 6| Step: 5
Training loss: 2.386544704437256
Validation loss: 2.66362008484461

Epoch: 6| Step: 6
Training loss: 3.2168052196502686
Validation loss: 2.658261222224082

Epoch: 6| Step: 7
Training loss: 3.0623624324798584
Validation loss: 2.658761524385022

Epoch: 6| Step: 8
Training loss: 2.4501359462738037
Validation loss: 2.6605692601973012

Epoch: 6| Step: 9
Training loss: 3.324237108230591
Validation loss: 2.6600732162434566

Epoch: 6| Step: 10
Training loss: 2.3768060207366943
Validation loss: 2.648555060868622

Epoch: 6| Step: 11
Training loss: 3.231825590133667
Validation loss: 2.6543675750814457

Epoch: 6| Step: 12
Training loss: 3.1870715618133545
Validation loss: 2.6424400062971216

Epoch: 6| Step: 13
Training loss: 3.022778034210205
Validation loss: 2.639837247069164

Epoch: 114| Step: 0
Training loss: 2.868380546569824
Validation loss: 2.6372209108004006

Epoch: 6| Step: 1
Training loss: 2.4044084548950195
Validation loss: 2.63912768261407

Epoch: 6| Step: 2
Training loss: 3.088423252105713
Validation loss: 2.6388259754386

Epoch: 6| Step: 3
Training loss: 2.4624862670898438
Validation loss: 2.6377799998047533

Epoch: 6| Step: 4
Training loss: 2.7403674125671387
Validation loss: 2.6376083025368313

Epoch: 6| Step: 5
Training loss: 2.4275143146514893
Validation loss: 2.639393150165517

Epoch: 6| Step: 6
Training loss: 3.212448835372925
Validation loss: 2.6440689666296846

Epoch: 6| Step: 7
Training loss: 3.0377237796783447
Validation loss: 2.641799303793138

Epoch: 6| Step: 8
Training loss: 2.6919667720794678
Validation loss: 2.640131219740837

Epoch: 6| Step: 9
Training loss: 3.143249034881592
Validation loss: 2.6399801623436714

Epoch: 6| Step: 10
Training loss: 3.0537188053131104
Validation loss: 2.635462809634465

Epoch: 6| Step: 11
Training loss: 2.3970346450805664
Validation loss: 2.638239960516653

Epoch: 6| Step: 12
Training loss: 2.879819393157959
Validation loss: 2.6347215457629134

Epoch: 6| Step: 13
Training loss: 2.573836326599121
Validation loss: 2.6376046544762066

Epoch: 115| Step: 0
Training loss: 2.1932883262634277
Validation loss: 2.649067947941442

Epoch: 6| Step: 1
Training loss: 3.48519229888916
Validation loss: 2.645227737324212

Epoch: 6| Step: 2
Training loss: 3.1301119327545166
Validation loss: 2.647967800017326

Epoch: 6| Step: 3
Training loss: 3.8184449672698975
Validation loss: 2.644465700272591

Epoch: 6| Step: 4
Training loss: 1.6745905876159668
Validation loss: 2.6463212966918945

Epoch: 6| Step: 5
Training loss: 2.768817186355591
Validation loss: 2.640339959052301

Epoch: 6| Step: 6
Training loss: 2.9828908443450928
Validation loss: 2.6388836727347424

Epoch: 6| Step: 7
Training loss: 2.742980480194092
Validation loss: 2.6379638487292874

Epoch: 6| Step: 8
Training loss: 2.515326499938965
Validation loss: 2.640450749346005

Epoch: 6| Step: 9
Training loss: 2.8339853286743164
Validation loss: 2.6393772761027017

Epoch: 6| Step: 10
Training loss: 2.6106979846954346
Validation loss: 2.638238594096194

Epoch: 6| Step: 11
Training loss: 2.656301975250244
Validation loss: 2.6424983137397358

Epoch: 6| Step: 12
Training loss: 2.8933262825012207
Validation loss: 2.6374584705598894

Epoch: 6| Step: 13
Training loss: 2.6045937538146973
Validation loss: 2.640022531632454

Epoch: 116| Step: 0
Training loss: 3.415468215942383
Validation loss: 2.635004605016401

Epoch: 6| Step: 1
Training loss: 3.3187308311462402
Validation loss: 2.6357691339267197

Epoch: 6| Step: 2
Training loss: 2.3410725593566895
Validation loss: 2.6355204300213884

Epoch: 6| Step: 3
Training loss: 2.385702610015869
Validation loss: 2.6367935519064627

Epoch: 6| Step: 4
Training loss: 2.592801809310913
Validation loss: 2.634949066305673

Epoch: 6| Step: 5
Training loss: 2.3052000999450684
Validation loss: 2.635059120834515

Epoch: 6| Step: 6
Training loss: 3.5072946548461914
Validation loss: 2.632797207883609

Epoch: 6| Step: 7
Training loss: 2.4654793739318848
Validation loss: 2.633387529721824

Epoch: 6| Step: 8
Training loss: 2.7228989601135254
Validation loss: 2.6340075257003948

Epoch: 6| Step: 9
Training loss: 2.9948551654815674
Validation loss: 2.63414486505652

Epoch: 6| Step: 10
Training loss: 2.7443909645080566
Validation loss: 2.6355259751760833

Epoch: 6| Step: 11
Training loss: 2.94686222076416
Validation loss: 2.6334419506852345

Epoch: 6| Step: 12
Training loss: 2.7678747177124023
Validation loss: 2.6314109807373374

Epoch: 6| Step: 13
Training loss: 2.2765958309173584
Validation loss: 2.633577980020995

Epoch: 117| Step: 0
Training loss: 2.3584537506103516
Validation loss: 2.6302913106897825

Epoch: 6| Step: 1
Training loss: 2.5884737968444824
Validation loss: 2.633401971991344

Epoch: 6| Step: 2
Training loss: 2.548715114593506
Validation loss: 2.631245897662255

Epoch: 6| Step: 3
Training loss: 3.0624468326568604
Validation loss: 2.6316758483968754

Epoch: 6| Step: 4
Training loss: 3.1589746475219727
Validation loss: 2.630050572015906

Epoch: 6| Step: 5
Training loss: 3.7731826305389404
Validation loss: 2.6348346279513453

Epoch: 6| Step: 6
Training loss: 2.7994000911712646
Validation loss: 2.631385786558992

Epoch: 6| Step: 7
Training loss: 3.1941702365875244
Validation loss: 2.634959820778139

Epoch: 6| Step: 8
Training loss: 2.879150390625
Validation loss: 2.628307245110953

Epoch: 6| Step: 9
Training loss: 2.156461715698242
Validation loss: 2.629694707932011

Epoch: 6| Step: 10
Training loss: 2.5122134685516357
Validation loss: 2.6315162771491596

Epoch: 6| Step: 11
Training loss: 2.9600775241851807
Validation loss: 2.632608723896806

Epoch: 6| Step: 12
Training loss: 1.7424671649932861
Validation loss: 2.6381794816704205

Epoch: 6| Step: 13
Training loss: 3.656238079071045
Validation loss: 2.6405148967619865

Epoch: 118| Step: 0
Training loss: 3.0297470092773438
Validation loss: 2.6319112085526988

Epoch: 6| Step: 1
Training loss: 3.399847984313965
Validation loss: 2.636497933377502

Epoch: 6| Step: 2
Training loss: 3.6756930351257324
Validation loss: 2.6336577938449

Epoch: 6| Step: 3
Training loss: 2.476287603378296
Validation loss: 2.6258590170132217

Epoch: 6| Step: 4
Training loss: 3.127028226852417
Validation loss: 2.6287642345633557

Epoch: 6| Step: 5
Training loss: 3.2500176429748535
Validation loss: 2.62685719613106

Epoch: 6| Step: 6
Training loss: 1.9752449989318848
Validation loss: 2.6295567661203365

Epoch: 6| Step: 7
Training loss: 2.707127571105957
Validation loss: 2.6268228561647478

Epoch: 6| Step: 8
Training loss: 2.3636231422424316
Validation loss: 2.6240662528622534

Epoch: 6| Step: 9
Training loss: 2.5089478492736816
Validation loss: 2.6304286500459075

Epoch: 6| Step: 10
Training loss: 2.1587443351745605
Validation loss: 2.6304421758139007

Epoch: 6| Step: 11
Training loss: 2.9052011966705322
Validation loss: 2.628171741321523

Epoch: 6| Step: 12
Training loss: 2.6714365482330322
Validation loss: 2.631936260448989

Epoch: 6| Step: 13
Training loss: 2.5416388511657715
Validation loss: 2.626549459272815

Epoch: 119| Step: 0
Training loss: 2.841311454772949
Validation loss: 2.630505810501755

Epoch: 6| Step: 1
Training loss: 3.112544298171997
Validation loss: 2.631142775217692

Epoch: 6| Step: 2
Training loss: 2.918186664581299
Validation loss: 2.6347626460495817

Epoch: 6| Step: 3
Training loss: 2.8765170574188232
Validation loss: 2.6425979368148313

Epoch: 6| Step: 4
Training loss: 2.924307346343994
Validation loss: 2.649001908558671

Epoch: 6| Step: 5
Training loss: 2.5777697563171387
Validation loss: 2.645504146493891

Epoch: 6| Step: 6
Training loss: 2.597625970840454
Validation loss: 2.6434089355571295

Epoch: 6| Step: 7
Training loss: 2.813661575317383
Validation loss: 2.6404966795316307

Epoch: 6| Step: 8
Training loss: 3.7534871101379395
Validation loss: 2.633942619446785

Epoch: 6| Step: 9
Training loss: 2.441037654876709
Validation loss: 2.6288720561612036

Epoch: 6| Step: 10
Training loss: 2.7163805961608887
Validation loss: 2.6275228351675053

Epoch: 6| Step: 11
Training loss: 2.3730616569519043
Validation loss: 2.6251621579611175

Epoch: 6| Step: 12
Training loss: 2.6263251304626465
Validation loss: 2.6261688637477096

Epoch: 6| Step: 13
Training loss: 2.0420889854431152
Validation loss: 2.6261635185569845

Epoch: 120| Step: 0
Training loss: 2.247964859008789
Validation loss: 2.62779624103218

Epoch: 6| Step: 1
Training loss: 2.755600929260254
Validation loss: 2.6297585938566472

Epoch: 6| Step: 2
Training loss: 1.4613516330718994
Validation loss: 2.633057983972693

Epoch: 6| Step: 3
Training loss: 2.581240653991699
Validation loss: 2.631035997021583

Epoch: 6| Step: 4
Training loss: 3.295506000518799
Validation loss: 2.6304883085271364

Epoch: 6| Step: 5
Training loss: 2.559922695159912
Validation loss: 2.628015548952164

Epoch: 6| Step: 6
Training loss: 3.426943778991699
Validation loss: 2.632278912810869

Epoch: 6| Step: 7
Training loss: 3.3357980251312256
Validation loss: 2.6317728642494447

Epoch: 6| Step: 8
Training loss: 2.5789120197296143
Validation loss: 2.62759962133182

Epoch: 6| Step: 9
Training loss: 3.142970085144043
Validation loss: 2.6265302370953303

Epoch: 6| Step: 10
Training loss: 2.322885274887085
Validation loss: 2.6287564513503865

Epoch: 6| Step: 11
Training loss: 3.2561254501342773
Validation loss: 2.6288268899404876

Epoch: 6| Step: 12
Training loss: 3.773218870162964
Validation loss: 2.629351762033278

Epoch: 6| Step: 13
Training loss: 1.779348611831665
Validation loss: 2.63025483264718

Epoch: 121| Step: 0
Training loss: 1.9024869203567505
Validation loss: 2.6270183606814315

Epoch: 6| Step: 1
Training loss: 1.8474102020263672
Validation loss: 2.633317465423256

Epoch: 6| Step: 2
Training loss: 3.1071176528930664
Validation loss: 2.6412557863420054

Epoch: 6| Step: 3
Training loss: 2.6270618438720703
Validation loss: 2.6467517319545952

Epoch: 6| Step: 4
Training loss: 3.13433575630188
Validation loss: 2.6429777273567776

Epoch: 6| Step: 5
Training loss: 2.707360029220581
Validation loss: 2.64259607561173

Epoch: 6| Step: 6
Training loss: 2.4882962703704834
Validation loss: 2.6326867970087195

Epoch: 6| Step: 7
Training loss: 2.8329668045043945
Validation loss: 2.6279013490164154

Epoch: 6| Step: 8
Training loss: 4.0788679122924805
Validation loss: 2.618371286699849

Epoch: 6| Step: 9
Training loss: 2.085667133331299
Validation loss: 2.6217867405183855

Epoch: 6| Step: 10
Training loss: 2.55985951423645
Validation loss: 2.6160924588480303

Epoch: 6| Step: 11
Training loss: 2.869925022125244
Validation loss: 2.6193517536245365

Epoch: 6| Step: 12
Training loss: 3.7203657627105713
Validation loss: 2.622694746140511

Epoch: 6| Step: 13
Training loss: 3.118791103363037
Validation loss: 2.6235103017540387

Epoch: 122| Step: 0
Training loss: 3.7834606170654297
Validation loss: 2.627490928096156

Epoch: 6| Step: 1
Training loss: 2.6962950229644775
Validation loss: 2.6277663964097218

Epoch: 6| Step: 2
Training loss: 3.6243367195129395
Validation loss: 2.635441098161923

Epoch: 6| Step: 3
Training loss: 2.587648391723633
Validation loss: 2.6317234654580393

Epoch: 6| Step: 4
Training loss: 2.534243106842041
Validation loss: 2.6306946457073255

Epoch: 6| Step: 5
Training loss: 3.2449426651000977
Validation loss: 2.6346253554026284

Epoch: 6| Step: 6
Training loss: 2.2465462684631348
Validation loss: 2.6297839021170013

Epoch: 6| Step: 7
Training loss: 1.873641014099121
Validation loss: 2.628887273932016

Epoch: 6| Step: 8
Training loss: 3.493323802947998
Validation loss: 2.621020927224108

Epoch: 6| Step: 9
Training loss: 2.6089487075805664
Validation loss: 2.6171403033759004

Epoch: 6| Step: 10
Training loss: 2.060661554336548
Validation loss: 2.6160767821855444

Epoch: 6| Step: 11
Training loss: 2.6175622940063477
Validation loss: 2.6173225987342095

Epoch: 6| Step: 12
Training loss: 2.8943028450012207
Validation loss: 2.622151723472021

Epoch: 6| Step: 13
Training loss: 2.6345040798187256
Validation loss: 2.6228491234522995

Epoch: 123| Step: 0
Training loss: 2.8022115230560303
Validation loss: 2.6226349799863753

Epoch: 6| Step: 1
Training loss: 2.5787768363952637
Validation loss: 2.6244932041373303

Epoch: 6| Step: 2
Training loss: 2.5137581825256348
Validation loss: 2.629824531975613

Epoch: 6| Step: 3
Training loss: 2.714447259902954
Validation loss: 2.6318857285284225

Epoch: 6| Step: 4
Training loss: 3.0918025970458984
Validation loss: 2.628186179745582

Epoch: 6| Step: 5
Training loss: 2.4184651374816895
Validation loss: 2.635007563457694

Epoch: 6| Step: 6
Training loss: 3.0225250720977783
Validation loss: 2.62745580878309

Epoch: 6| Step: 7
Training loss: 2.1775999069213867
Validation loss: 2.6210990772452405

Epoch: 6| Step: 8
Training loss: 3.035841464996338
Validation loss: 2.617663816739154

Epoch: 6| Step: 9
Training loss: 3.0355727672576904
Validation loss: 2.6147454220761537

Epoch: 6| Step: 10
Training loss: 2.4405717849731445
Validation loss: 2.6167967883489465

Epoch: 6| Step: 11
Training loss: 2.509655714035034
Validation loss: 2.6170440079063497

Epoch: 6| Step: 12
Training loss: 3.118420124053955
Validation loss: 2.6145713047314714

Epoch: 6| Step: 13
Training loss: 3.915884256362915
Validation loss: 2.618859685877318

Epoch: 124| Step: 0
Training loss: 2.9206109046936035
Validation loss: 2.6162662659921954

Epoch: 6| Step: 1
Training loss: 3.557142734527588
Validation loss: 2.6190168344846336

Epoch: 6| Step: 2
Training loss: 1.8102668523788452
Validation loss: 2.6237886618542414

Epoch: 6| Step: 3
Training loss: 2.6660373210906982
Validation loss: 2.621588409587901

Epoch: 6| Step: 4
Training loss: 2.9679675102233887
Validation loss: 2.6180857073876167

Epoch: 6| Step: 5
Training loss: 2.809628963470459
Validation loss: 2.617984094927388

Epoch: 6| Step: 6
Training loss: 2.8774020671844482
Validation loss: 2.619685742162889

Epoch: 6| Step: 7
Training loss: 3.377978563308716
Validation loss: 2.619807691984279

Epoch: 6| Step: 8
Training loss: 2.6263427734375
Validation loss: 2.622618059958181

Epoch: 6| Step: 9
Training loss: 1.871881365776062
Validation loss: 2.6251562000602804

Epoch: 6| Step: 10
Training loss: 2.898303985595703
Validation loss: 2.622014307206677

Epoch: 6| Step: 11
Training loss: 2.8916373252868652
Validation loss: 2.621929919847878

Epoch: 6| Step: 12
Training loss: 2.6493067741394043
Validation loss: 2.6197476669024398

Epoch: 6| Step: 13
Training loss: 2.984467029571533
Validation loss: 2.6321843567714898

Epoch: 125| Step: 0
Training loss: 2.593517303466797
Validation loss: 2.6328568356011504

Epoch: 6| Step: 1
Training loss: 2.6319708824157715
Validation loss: 2.621729753350699

Epoch: 6| Step: 2
Training loss: 2.8481810092926025
Validation loss: 2.621559691685502

Epoch: 6| Step: 3
Training loss: 3.773486852645874
Validation loss: 2.6143678952288885

Epoch: 6| Step: 4
Training loss: 2.962582588195801
Validation loss: 2.61356787015033

Epoch: 6| Step: 5
Training loss: 2.182852268218994
Validation loss: 2.6125830399092806

Epoch: 6| Step: 6
Training loss: 2.677685022354126
Validation loss: 2.6141776500209684

Epoch: 6| Step: 7
Training loss: 2.279892921447754
Validation loss: 2.6086076946668726

Epoch: 6| Step: 8
Training loss: 3.5787558555603027
Validation loss: 2.613372323333576

Epoch: 6| Step: 9
Training loss: 3.262631893157959
Validation loss: 2.6103326582139537

Epoch: 6| Step: 10
Training loss: 2.912017345428467
Validation loss: 2.6133384704589844

Epoch: 6| Step: 11
Training loss: 2.453059196472168
Validation loss: 2.6151789208894134

Epoch: 6| Step: 12
Training loss: 2.164396047592163
Validation loss: 2.611628427300402

Epoch: 6| Step: 13
Training loss: 2.321732521057129
Validation loss: 2.6089497971278366

Epoch: 126| Step: 0
Training loss: 2.9458932876586914
Validation loss: 2.612577061499319

Epoch: 6| Step: 1
Training loss: 3.314155101776123
Validation loss: 2.6112723683798187

Epoch: 6| Step: 2
Training loss: 2.5268335342407227
Validation loss: 2.6105537081277497

Epoch: 6| Step: 3
Training loss: 3.1397299766540527
Validation loss: 2.6102476914723716

Epoch: 6| Step: 4
Training loss: 2.950650215148926
Validation loss: 2.609710321631483

Epoch: 6| Step: 5
Training loss: 2.9642558097839355
Validation loss: 2.6084258300001903

Epoch: 6| Step: 6
Training loss: 2.670893907546997
Validation loss: 2.609549981291576

Epoch: 6| Step: 7
Training loss: 2.3660964965820312
Validation loss: 2.608935522776778

Epoch: 6| Step: 8
Training loss: 3.2345473766326904
Validation loss: 2.606066373086745

Epoch: 6| Step: 9
Training loss: 2.9781620502471924
Validation loss: 2.608627034771827

Epoch: 6| Step: 10
Training loss: 2.865969657897949
Validation loss: 2.6082924514688473

Epoch: 6| Step: 11
Training loss: 2.3570432662963867
Validation loss: 2.6071859534068773

Epoch: 6| Step: 12
Training loss: 2.48008394241333
Validation loss: 2.60720315030826

Epoch: 6| Step: 13
Training loss: 1.3201711177825928
Validation loss: 2.605424258016771

Epoch: 127| Step: 0
Training loss: 2.426973581314087
Validation loss: 2.6064961725665676

Epoch: 6| Step: 1
Training loss: 3.326951026916504
Validation loss: 2.6138580153065343

Epoch: 6| Step: 2
Training loss: 1.8262879848480225
Validation loss: 2.6219521927577194

Epoch: 6| Step: 3
Training loss: 3.343600273132324
Validation loss: 2.6216400054193314

Epoch: 6| Step: 4
Training loss: 2.6461689472198486
Validation loss: 2.6113514566934235

Epoch: 6| Step: 5
Training loss: 1.975304365158081
Validation loss: 2.61405364928707

Epoch: 6| Step: 6
Training loss: 2.9878311157226562
Validation loss: 2.6178232546775573

Epoch: 6| Step: 7
Training loss: 2.670596122741699
Validation loss: 2.6091526939022924

Epoch: 6| Step: 8
Training loss: 2.4099926948547363
Validation loss: 2.607658052957186

Epoch: 6| Step: 9
Training loss: 3.0047857761383057
Validation loss: 2.608125784063852

Epoch: 6| Step: 10
Training loss: 2.6766350269317627
Validation loss: 2.605684644432478

Epoch: 6| Step: 11
Training loss: 2.731508731842041
Validation loss: 2.6067531198583622

Epoch: 6| Step: 12
Training loss: 3.743384838104248
Validation loss: 2.6117603753202703

Epoch: 6| Step: 13
Training loss: 3.038771629333496
Validation loss: 2.6068849332870974

Epoch: 128| Step: 0
Training loss: 2.0975375175476074
Validation loss: 2.6126023287414224

Epoch: 6| Step: 1
Training loss: 3.443573236465454
Validation loss: 2.6137041891774824

Epoch: 6| Step: 2
Training loss: 2.9430017471313477
Validation loss: 2.6165284879745974

Epoch: 6| Step: 3
Training loss: 2.3091635704040527
Validation loss: 2.6168045100345405

Epoch: 6| Step: 4
Training loss: 2.926609516143799
Validation loss: 2.6173075501636793

Epoch: 6| Step: 5
Training loss: 2.32989501953125
Validation loss: 2.6121817609315277

Epoch: 6| Step: 6
Training loss: 2.6912965774536133
Validation loss: 2.6108314350087154

Epoch: 6| Step: 7
Training loss: 3.032329559326172
Validation loss: 2.607129584076584

Epoch: 6| Step: 8
Training loss: 2.8175525665283203
Validation loss: 2.6070922805416967

Epoch: 6| Step: 9
Training loss: 3.0777206420898438
Validation loss: 2.6057945746247486

Epoch: 6| Step: 10
Training loss: 2.242936611175537
Validation loss: 2.6036298351903118

Epoch: 6| Step: 11
Training loss: 2.5758919715881348
Validation loss: 2.603430078875634

Epoch: 6| Step: 12
Training loss: 2.8842129707336426
Validation loss: 2.607260178494197

Epoch: 6| Step: 13
Training loss: 3.9834933280944824
Validation loss: 2.604401429494222

Epoch: 129| Step: 0
Training loss: 2.706109046936035
Validation loss: 2.609745451199111

Epoch: 6| Step: 1
Training loss: 3.154965877532959
Validation loss: 2.6191655358960553

Epoch: 6| Step: 2
Training loss: 2.4634995460510254
Validation loss: 2.6296307399708736

Epoch: 6| Step: 3
Training loss: 2.389681816101074
Validation loss: 2.616019456617294

Epoch: 6| Step: 4
Training loss: 2.4680368900299072
Validation loss: 2.6149620317643687

Epoch: 6| Step: 5
Training loss: 2.3268017768859863
Validation loss: 2.6070029171564246

Epoch: 6| Step: 6
Training loss: 2.863839626312256
Validation loss: 2.603446980958344

Epoch: 6| Step: 7
Training loss: 3.518277168273926
Validation loss: 2.603105598880399

Epoch: 6| Step: 8
Training loss: 2.7086195945739746
Validation loss: 2.5988436539967856

Epoch: 6| Step: 9
Training loss: 2.755068778991699
Validation loss: 2.6021748153112267

Epoch: 6| Step: 10
Training loss: 3.305213451385498
Validation loss: 2.600922769115817

Epoch: 6| Step: 11
Training loss: 2.34615421295166
Validation loss: 2.601639586110269

Epoch: 6| Step: 12
Training loss: 2.8089451789855957
Validation loss: 2.604080823159987

Epoch: 6| Step: 13
Training loss: 3.030827522277832
Validation loss: 2.6032095109262774

Epoch: 130| Step: 0
Training loss: 2.6028547286987305
Validation loss: 2.6012464672006588

Epoch: 6| Step: 1
Training loss: 2.994541883468628
Validation loss: 2.6036516902267293

Epoch: 6| Step: 2
Training loss: 3.1024222373962402
Validation loss: 2.599948957402219

Epoch: 6| Step: 3
Training loss: 3.132143974304199
Validation loss: 2.598276871506886

Epoch: 6| Step: 4
Training loss: 2.70414137840271
Validation loss: 2.6064637245670443

Epoch: 6| Step: 5
Training loss: 2.1846580505371094
Validation loss: 2.6018957399552867

Epoch: 6| Step: 6
Training loss: 3.3152880668640137
Validation loss: 2.601787778639024

Epoch: 6| Step: 7
Training loss: 2.847109317779541
Validation loss: 2.602600236092844

Epoch: 6| Step: 8
Training loss: 2.787346124649048
Validation loss: 2.602074935872068

Epoch: 6| Step: 9
Training loss: 3.1762397289276123
Validation loss: 2.603887624638055

Epoch: 6| Step: 10
Training loss: 2.295473098754883
Validation loss: 2.5988119853440153

Epoch: 6| Step: 11
Training loss: 3.0694990158081055
Validation loss: 2.5992372061616633

Epoch: 6| Step: 12
Training loss: 2.071746826171875
Validation loss: 2.5994150689853135

Epoch: 6| Step: 13
Training loss: 2.130964756011963
Validation loss: 2.6041470086702736

Epoch: 131| Step: 0
Training loss: 2.758206367492676
Validation loss: 2.6019564392746135

Epoch: 6| Step: 1
Training loss: 2.1749629974365234
Validation loss: 2.6073146430394982

Epoch: 6| Step: 2
Training loss: 3.2286834716796875
Validation loss: 2.6141075959769626

Epoch: 6| Step: 3
Training loss: 3.3266725540161133
Validation loss: 2.6222010812451764

Epoch: 6| Step: 4
Training loss: 2.2111966609954834
Validation loss: 2.6283568105389996

Epoch: 6| Step: 5
Training loss: 2.4669013023376465
Validation loss: 2.6236941840059016

Epoch: 6| Step: 6
Training loss: 2.696503162384033
Validation loss: 2.6118760160220567

Epoch: 6| Step: 7
Training loss: 3.160215377807617
Validation loss: 2.6028848540398384

Epoch: 6| Step: 8
Training loss: 1.811549425125122
Validation loss: 2.603839848631172

Epoch: 6| Step: 9
Training loss: 2.9012036323547363
Validation loss: 2.600007369954099

Epoch: 6| Step: 10
Training loss: 3.4988620281219482
Validation loss: 2.5954536596934

Epoch: 6| Step: 11
Training loss: 2.5907318592071533
Validation loss: 2.6001948900120233

Epoch: 6| Step: 12
Training loss: 2.8449840545654297
Validation loss: 2.5974859986253964

Epoch: 6| Step: 13
Training loss: 3.3437559604644775
Validation loss: 2.597456798758558

Epoch: 132| Step: 0
Training loss: 2.5365474224090576
Validation loss: 2.5937225664815595

Epoch: 6| Step: 1
Training loss: 3.070958137512207
Validation loss: 2.5938415014615623

Epoch: 6| Step: 2
Training loss: 1.8307042121887207
Validation loss: 2.5917720845950547

Epoch: 6| Step: 3
Training loss: 3.0531516075134277
Validation loss: 2.59873366355896

Epoch: 6| Step: 4
Training loss: 2.3745105266571045
Validation loss: 2.593954896414152

Epoch: 6| Step: 5
Training loss: 2.692711114883423
Validation loss: 2.5956648139543432

Epoch: 6| Step: 6
Training loss: 2.7244577407836914
Validation loss: 2.596451054337204

Epoch: 6| Step: 7
Training loss: 2.2758357524871826
Validation loss: 2.5985768328430834

Epoch: 6| Step: 8
Training loss: 2.682874917984009
Validation loss: 2.595226667260611

Epoch: 6| Step: 9
Training loss: 2.9807374477386475
Validation loss: 2.602237573233984

Epoch: 6| Step: 10
Training loss: 2.8843588829040527
Validation loss: 2.599503150550268

Epoch: 6| Step: 11
Training loss: 3.7171547412872314
Validation loss: 2.5962978101545766

Epoch: 6| Step: 12
Training loss: 2.5332114696502686
Validation loss: 2.5969961484273276

Epoch: 6| Step: 13
Training loss: 3.638251781463623
Validation loss: 2.5934903442218737

Epoch: 133| Step: 0
Training loss: 1.7800312042236328
Validation loss: 2.5928204597965365

Epoch: 6| Step: 1
Training loss: 2.4435782432556152
Validation loss: 2.5913381576538086

Epoch: 6| Step: 2
Training loss: 2.6985464096069336
Validation loss: 2.59343324681764

Epoch: 6| Step: 3
Training loss: 3.1203701496124268
Validation loss: 2.5943477230687297

Epoch: 6| Step: 4
Training loss: 2.5780811309814453
Validation loss: 2.595937062335271

Epoch: 6| Step: 5
Training loss: 3.8539440631866455
Validation loss: 2.5932238025050007

Epoch: 6| Step: 6
Training loss: 2.937167167663574
Validation loss: 2.593841375843171

Epoch: 6| Step: 7
Training loss: 3.385444402694702
Validation loss: 2.600327653269614

Epoch: 6| Step: 8
Training loss: 3.301051378250122
Validation loss: 2.591442196599899

Epoch: 6| Step: 9
Training loss: 2.6254990100860596
Validation loss: 2.593189354865782

Epoch: 6| Step: 10
Training loss: 2.4289755821228027
Validation loss: 2.592426798676932

Epoch: 6| Step: 11
Training loss: 3.339095115661621
Validation loss: 2.593180666687668

Epoch: 6| Step: 12
Training loss: 1.877882957458496
Validation loss: 2.5912731488545737

Epoch: 6| Step: 13
Training loss: 1.7663500308990479
Validation loss: 2.5947930864108506

Epoch: 134| Step: 0
Training loss: 2.6839373111724854
Validation loss: 2.597098150560933

Epoch: 6| Step: 1
Training loss: 3.016249179840088
Validation loss: 2.602175079366212

Epoch: 6| Step: 2
Training loss: 3.0283055305480957
Validation loss: 2.6024793373641146

Epoch: 6| Step: 3
Training loss: 2.5826070308685303
Validation loss: 2.6043803922591673

Epoch: 6| Step: 4
Training loss: 2.6569180488586426
Validation loss: 2.603779100602673

Epoch: 6| Step: 5
Training loss: 2.7722256183624268
Validation loss: 2.6027777938432592

Epoch: 6| Step: 6
Training loss: 3.306089401245117
Validation loss: 2.603437413451492

Epoch: 6| Step: 7
Training loss: 2.5195975303649902
Validation loss: 2.594164543254401

Epoch: 6| Step: 8
Training loss: 3.2788028717041016
Validation loss: 2.5893994505687425

Epoch: 6| Step: 9
Training loss: 2.534359931945801
Validation loss: 2.591534924763505

Epoch: 6| Step: 10
Training loss: 3.515099048614502
Validation loss: 2.595571715344665

Epoch: 6| Step: 11
Training loss: 3.014106273651123
Validation loss: 2.593090511137439

Epoch: 6| Step: 12
Training loss: 1.5045151710510254
Validation loss: 2.594684644411969

Epoch: 6| Step: 13
Training loss: 1.70473313331604
Validation loss: 2.5887743221816195

Epoch: 135| Step: 0
Training loss: 2.9863176345825195
Validation loss: 2.588350119129304

Epoch: 6| Step: 1
Training loss: 2.6812081336975098
Validation loss: 2.5908617998964045

Epoch: 6| Step: 2
Training loss: 3.797860860824585
Validation loss: 2.5897268582415838

Epoch: 6| Step: 3
Training loss: 2.921113967895508
Validation loss: 2.5925453042471283

Epoch: 6| Step: 4
Training loss: 2.604400157928467
Validation loss: 2.5923013507678943

Epoch: 6| Step: 5
Training loss: 2.446479558944702
Validation loss: 2.5931578323405278

Epoch: 6| Step: 6
Training loss: 2.566636085510254
Validation loss: 2.590844702977006

Epoch: 6| Step: 7
Training loss: 2.5609936714172363
Validation loss: 2.591973573930802

Epoch: 6| Step: 8
Training loss: 1.7436555624008179
Validation loss: 2.592147660511796

Epoch: 6| Step: 9
Training loss: 2.7843480110168457
Validation loss: 2.5896040701097056

Epoch: 6| Step: 10
Training loss: 2.4200000762939453
Validation loss: 2.5890959885812577

Epoch: 6| Step: 11
Training loss: 2.709097385406494
Validation loss: 2.588850657145182

Epoch: 6| Step: 12
Training loss: 2.6645002365112305
Validation loss: 2.588186312747258

Epoch: 6| Step: 13
Training loss: 4.279709339141846
Validation loss: 2.58639201553919

Epoch: 136| Step: 0
Training loss: 2.1708154678344727
Validation loss: 2.58931073065727

Epoch: 6| Step: 1
Training loss: 2.287994861602783
Validation loss: 2.586288893094627

Epoch: 6| Step: 2
Training loss: 2.4274449348449707
Validation loss: 2.586434489937239

Epoch: 6| Step: 3
Training loss: 2.354008674621582
Validation loss: 2.587501266951202

Epoch: 6| Step: 4
Training loss: 3.837761402130127
Validation loss: 2.588338218709474

Epoch: 6| Step: 5
Training loss: 2.8999578952789307
Validation loss: 2.5912346814268377

Epoch: 6| Step: 6
Training loss: 2.5817813873291016
Validation loss: 2.584932957926104

Epoch: 6| Step: 7
Training loss: 3.236325263977051
Validation loss: 2.5852388207630446

Epoch: 6| Step: 8
Training loss: 2.353482246398926
Validation loss: 2.5861524689582085

Epoch: 6| Step: 9
Training loss: 3.470310688018799
Validation loss: 2.596370627803187

Epoch: 6| Step: 10
Training loss: 3.4290757179260254
Validation loss: 2.593506859194848

Epoch: 6| Step: 11
Training loss: 2.484419345855713
Validation loss: 2.585204262887278

Epoch: 6| Step: 12
Training loss: 2.704754114151001
Validation loss: 2.5923320939463954

Epoch: 6| Step: 13
Training loss: 1.935281753540039
Validation loss: 2.5869511737618396

Epoch: 137| Step: 0
Training loss: 3.5613207817077637
Validation loss: 2.5875076504163843

Epoch: 6| Step: 1
Training loss: 2.8544247150421143
Validation loss: 2.5856750472899406

Epoch: 6| Step: 2
Training loss: 3.1928327083587646
Validation loss: 2.5885597018785376

Epoch: 6| Step: 3
Training loss: 2.756701707839966
Validation loss: 2.58859339580741

Epoch: 6| Step: 4
Training loss: 2.336078405380249
Validation loss: 2.585967540740967

Epoch: 6| Step: 5
Training loss: 2.230301856994629
Validation loss: 2.5891827972986365

Epoch: 6| Step: 6
Training loss: 3.7919416427612305
Validation loss: 2.5871432827365015

Epoch: 6| Step: 7
Training loss: 3.0564050674438477
Validation loss: 2.580179883587745

Epoch: 6| Step: 8
Training loss: 2.1751742362976074
Validation loss: 2.5828346616478375

Epoch: 6| Step: 9
Training loss: 3.202333688735962
Validation loss: 2.5813961259780394

Epoch: 6| Step: 10
Training loss: 2.677023410797119
Validation loss: 2.5814706356294694

Epoch: 6| Step: 11
Training loss: 2.079888343811035
Validation loss: 2.5826867447104505

Epoch: 6| Step: 12
Training loss: 1.7897869348526
Validation loss: 2.583791204678115

Epoch: 6| Step: 13
Training loss: 2.817265748977661
Validation loss: 2.581007524203229

Epoch: 138| Step: 0
Training loss: 2.2773690223693848
Validation loss: 2.584561886325959

Epoch: 6| Step: 1
Training loss: 2.309577226638794
Validation loss: 2.588164221855902

Epoch: 6| Step: 2
Training loss: 2.954369068145752
Validation loss: 2.6039743987462853

Epoch: 6| Step: 3
Training loss: 2.6231446266174316
Validation loss: 2.610700458608648

Epoch: 6| Step: 4
Training loss: 3.4949724674224854
Validation loss: 2.610724574776106

Epoch: 6| Step: 5
Training loss: 2.5545361042022705
Validation loss: 2.6140092085766535

Epoch: 6| Step: 6
Training loss: 3.2185757160186768
Validation loss: 2.61691193426809

Epoch: 6| Step: 7
Training loss: 2.818241596221924
Validation loss: 2.5942086250551286

Epoch: 6| Step: 8
Training loss: 2.2085795402526855
Validation loss: 2.5850480089905443

Epoch: 6| Step: 9
Training loss: 3.0806121826171875
Validation loss: 2.582730706020068

Epoch: 6| Step: 10
Training loss: 3.1330008506774902
Validation loss: 2.583764026241918

Epoch: 6| Step: 11
Training loss: 2.629746913909912
Validation loss: 2.587626249559464

Epoch: 6| Step: 12
Training loss: 2.940723419189453
Validation loss: 2.592024826234387

Epoch: 6| Step: 13
Training loss: 2.1627144813537598
Validation loss: 2.5931670793923

Epoch: 139| Step: 0
Training loss: 2.2004740238189697
Validation loss: 2.5915217348324355

Epoch: 6| Step: 1
Training loss: 2.424929618835449
Validation loss: 2.59136700630188

Epoch: 6| Step: 2
Training loss: 2.5648341178894043
Validation loss: 2.590354101632231

Epoch: 6| Step: 3
Training loss: 2.571199893951416
Validation loss: 2.5851882965334

Epoch: 6| Step: 4
Training loss: 2.752070426940918
Validation loss: 2.587549612086306

Epoch: 6| Step: 5
Training loss: 2.7146944999694824
Validation loss: 2.585015030317409

Epoch: 6| Step: 6
Training loss: 3.2182140350341797
Validation loss: 2.5897284092441684

Epoch: 6| Step: 7
Training loss: 3.42582631111145
Validation loss: 2.591952513622981

Epoch: 6| Step: 8
Training loss: 3.110037326812744
Validation loss: 2.597393940853816

Epoch: 6| Step: 9
Training loss: 3.100717067718506
Validation loss: 2.5921745966839533

Epoch: 6| Step: 10
Training loss: 3.449418544769287
Validation loss: 2.588297346586822

Epoch: 6| Step: 11
Training loss: 2.201418161392212
Validation loss: 2.5863505973610827

Epoch: 6| Step: 12
Training loss: 2.4036648273468018
Validation loss: 2.584008042530347

Epoch: 6| Step: 13
Training loss: 2.164820671081543
Validation loss: 2.5828944534383793

Epoch: 140| Step: 0
Training loss: 2.2455363273620605
Validation loss: 2.58721354956268

Epoch: 6| Step: 1
Training loss: 2.9451241493225098
Validation loss: 2.5847301688245548

Epoch: 6| Step: 2
Training loss: 2.1347007751464844
Validation loss: 2.5895890369210193

Epoch: 6| Step: 3
Training loss: 2.457559108734131
Validation loss: 2.5790797561727543

Epoch: 6| Step: 4
Training loss: 3.376436233520508
Validation loss: 2.5851813695764028

Epoch: 6| Step: 5
Training loss: 2.492194175720215
Validation loss: 2.5825029547496507

Epoch: 6| Step: 6
Training loss: 2.7339119911193848
Validation loss: 2.5832419472356

Epoch: 6| Step: 7
Training loss: 3.2564918994903564
Validation loss: 2.5802340981780842

Epoch: 6| Step: 8
Training loss: 3.3081953525543213
Validation loss: 2.5841000618473178

Epoch: 6| Step: 9
Training loss: 2.3255791664123535
Validation loss: 2.5883047298718522

Epoch: 6| Step: 10
Training loss: 2.502207040786743
Validation loss: 2.585929319422732

Epoch: 6| Step: 11
Training loss: 3.371553421020508
Validation loss: 2.592457071427376

Epoch: 6| Step: 12
Training loss: 2.318330764770508
Validation loss: 2.587850747569915

Epoch: 6| Step: 13
Training loss: 3.2537684440612793
Validation loss: 2.587867434306811

Epoch: 141| Step: 0
Training loss: 2.1835312843322754
Validation loss: 2.5875826753595823

Epoch: 6| Step: 1
Training loss: 4.0393595695495605
Validation loss: 2.58758520823653

Epoch: 6| Step: 2
Training loss: 2.192021369934082
Validation loss: 2.5880679468954764

Epoch: 6| Step: 3
Training loss: 2.9346847534179688
Validation loss: 2.586193971736457

Epoch: 6| Step: 4
Training loss: 2.7775816917419434
Validation loss: 2.5845862486029185

Epoch: 6| Step: 5
Training loss: 3.061385154724121
Validation loss: 2.5844845643607517

Epoch: 6| Step: 6
Training loss: 2.9853410720825195
Validation loss: 2.5820872373478387

Epoch: 6| Step: 7
Training loss: 3.4010815620422363
Validation loss: 2.578620982426469

Epoch: 6| Step: 8
Training loss: 2.4671435356140137
Validation loss: 2.579844328664964

Epoch: 6| Step: 9
Training loss: 2.7433557510375977
Validation loss: 2.5783700917356756

Epoch: 6| Step: 10
Training loss: 2.360030174255371
Validation loss: 2.580251552725351

Epoch: 6| Step: 11
Training loss: 2.769742488861084
Validation loss: 2.5867807480596725

Epoch: 6| Step: 12
Training loss: 2.185757637023926
Validation loss: 2.591202235990955

Epoch: 6| Step: 13
Training loss: 2.0454647541046143
Validation loss: 2.598331997471471

Epoch: 142| Step: 0
Training loss: 3.1055283546447754
Validation loss: 2.6066890890880297

Epoch: 6| Step: 1
Training loss: 1.8936901092529297
Validation loss: 2.6061277299798946

Epoch: 6| Step: 2
Training loss: 2.4355108737945557
Validation loss: 2.589268789496473

Epoch: 6| Step: 3
Training loss: 2.4724934101104736
Validation loss: 2.5859225155204855

Epoch: 6| Step: 4
Training loss: 3.376394271850586
Validation loss: 2.58264398318465

Epoch: 6| Step: 5
Training loss: 2.358001232147217
Validation loss: 2.5775263770934074

Epoch: 6| Step: 6
Training loss: 2.4297428131103516
Validation loss: 2.577226769539618

Epoch: 6| Step: 7
Training loss: 3.6068778038024902
Validation loss: 2.575227173425818

Epoch: 6| Step: 8
Training loss: 3.2546157836914062
Validation loss: 2.578657670687604

Epoch: 6| Step: 9
Training loss: 3.1894991397857666
Validation loss: 2.5759979653102096

Epoch: 6| Step: 10
Training loss: 3.0051069259643555
Validation loss: 2.573658286884267

Epoch: 6| Step: 11
Training loss: 2.315171480178833
Validation loss: 2.576738196034585

Epoch: 6| Step: 12
Training loss: 2.60563325881958
Validation loss: 2.5741235620232037

Epoch: 6| Step: 13
Training loss: 2.23085880279541
Validation loss: 2.5716625772496706

Epoch: 143| Step: 0
Training loss: 2.2061927318573
Validation loss: 2.5777626422143753

Epoch: 6| Step: 1
Training loss: 2.643697738647461
Validation loss: 2.5810356678501254

Epoch: 6| Step: 2
Training loss: 3.4684925079345703
Validation loss: 2.5879459124739452

Epoch: 6| Step: 3
Training loss: 2.2140536308288574
Validation loss: 2.575330741943852

Epoch: 6| Step: 4
Training loss: 2.2974131107330322
Validation loss: 2.5781342316699285

Epoch: 6| Step: 5
Training loss: 2.782064914703369
Validation loss: 2.5744453835231003

Epoch: 6| Step: 6
Training loss: 3.003300905227661
Validation loss: 2.5762949810233167

Epoch: 6| Step: 7
Training loss: 2.810420036315918
Validation loss: 2.572306340740573

Epoch: 6| Step: 8
Training loss: 2.179384708404541
Validation loss: 2.5695312638436594

Epoch: 6| Step: 9
Training loss: 3.2718281745910645
Validation loss: 2.570549749558972

Epoch: 6| Step: 10
Training loss: 3.2023210525512695
Validation loss: 2.572459897687358

Epoch: 6| Step: 11
Training loss: 3.1735734939575195
Validation loss: 2.572733732961839

Epoch: 6| Step: 12
Training loss: 2.5530314445495605
Validation loss: 2.569270815900577

Epoch: 6| Step: 13
Training loss: 2.53300142288208
Validation loss: 2.5747730270508797

Epoch: 144| Step: 0
Training loss: 3.383549690246582
Validation loss: 2.576284190659882

Epoch: 6| Step: 1
Training loss: 2.8263888359069824
Validation loss: 2.577818465489213

Epoch: 6| Step: 2
Training loss: 3.412519931793213
Validation loss: 2.58059109410932

Epoch: 6| Step: 3
Training loss: 2.7120299339294434
Validation loss: 2.577206104032455

Epoch: 6| Step: 4
Training loss: 3.5995302200317383
Validation loss: 2.57822266445365

Epoch: 6| Step: 5
Training loss: 3.428725242614746
Validation loss: 2.5828066846375823

Epoch: 6| Step: 6
Training loss: 1.9306917190551758
Validation loss: 2.58740488431787

Epoch: 6| Step: 7
Training loss: 2.4726223945617676
Validation loss: 2.5802260675737934

Epoch: 6| Step: 8
Training loss: 2.5335397720336914
Validation loss: 2.583842118581136

Epoch: 6| Step: 9
Training loss: 2.5567092895507812
Validation loss: 2.585780889757218

Epoch: 6| Step: 10
Training loss: 2.6993088722229004
Validation loss: 2.577917109253586

Epoch: 6| Step: 11
Training loss: 1.9654877185821533
Validation loss: 2.578465579658426

Epoch: 6| Step: 12
Training loss: 2.4587411880493164
Validation loss: 2.585463262373401

Epoch: 6| Step: 13
Training loss: 2.1438255310058594
Validation loss: 2.577003973786549

Epoch: 145| Step: 0
Training loss: 3.1498656272888184
Validation loss: 2.5698898428229877

Epoch: 6| Step: 1
Training loss: 2.766496181488037
Validation loss: 2.5691719901177192

Epoch: 6| Step: 2
Training loss: 2.5029077529907227
Validation loss: 2.5698915322621665

Epoch: 6| Step: 3
Training loss: 2.8345651626586914
Validation loss: 2.5774744890069448

Epoch: 6| Step: 4
Training loss: 2.9612953662872314
Validation loss: 2.579533278301198

Epoch: 6| Step: 5
Training loss: 2.2182226181030273
Validation loss: 2.59958456664957

Epoch: 6| Step: 6
Training loss: 2.6021249294281006
Validation loss: 2.595116630677254

Epoch: 6| Step: 7
Training loss: 3.0665411949157715
Validation loss: 2.580699869381484

Epoch: 6| Step: 8
Training loss: 2.8421802520751953
Validation loss: 2.5782885820634904

Epoch: 6| Step: 9
Training loss: 3.5063862800598145
Validation loss: 2.5706844560561644

Epoch: 6| Step: 10
Training loss: 1.928983449935913
Validation loss: 2.5704735120137534

Epoch: 6| Step: 11
Training loss: 2.6803579330444336
Validation loss: 2.5656391266853578

Epoch: 6| Step: 12
Training loss: 2.981722831726074
Validation loss: 2.5727241475095033

Epoch: 6| Step: 13
Training loss: 2.195270299911499
Validation loss: 2.57858548625823

Epoch: 146| Step: 0
Training loss: 2.7675750255584717
Validation loss: 2.5775095519199165

Epoch: 6| Step: 1
Training loss: 3.348437547683716
Validation loss: 2.591968746595485

Epoch: 6| Step: 2
Training loss: 2.555678367614746
Validation loss: 2.6000857045573573

Epoch: 6| Step: 3
Training loss: 2.1706271171569824
Validation loss: 2.5917214526925036

Epoch: 6| Step: 4
Training loss: 3.086493968963623
Validation loss: 2.586655775705973

Epoch: 6| Step: 5
Training loss: 2.6424546241760254
Validation loss: 2.577310155796748

Epoch: 6| Step: 6
Training loss: 2.792752504348755
Validation loss: 2.568641995870939

Epoch: 6| Step: 7
Training loss: 3.181567668914795
Validation loss: 2.569977888496973

Epoch: 6| Step: 8
Training loss: 2.557953357696533
Validation loss: 2.564650140782838

Epoch: 6| Step: 9
Training loss: 2.915459632873535
Validation loss: 2.5670321718338998

Epoch: 6| Step: 10
Training loss: 2.5109963417053223
Validation loss: 2.5667967437415995

Epoch: 6| Step: 11
Training loss: 2.1335415840148926
Validation loss: 2.5695517396414154

Epoch: 6| Step: 12
Training loss: 3.365394115447998
Validation loss: 2.570195749241819

Epoch: 6| Step: 13
Training loss: 2.164641857147217
Validation loss: 2.5684289675886913

Epoch: 147| Step: 0
Training loss: 2.653366804122925
Validation loss: 2.568218514483462

Epoch: 6| Step: 1
Training loss: 3.6361541748046875
Validation loss: 2.5682012599001647

Epoch: 6| Step: 2
Training loss: 3.5237579345703125
Validation loss: 2.5683338257574264

Epoch: 6| Step: 3
Training loss: 2.5997838973999023
Validation loss: 2.5657707875774753

Epoch: 6| Step: 4
Training loss: 1.9903943538665771
Validation loss: 2.5703724430453394

Epoch: 6| Step: 5
Training loss: 2.6663870811462402
Validation loss: 2.5703677310738513

Epoch: 6| Step: 6
Training loss: 2.8442978858947754
Validation loss: 2.56918518517607

Epoch: 6| Step: 7
Training loss: 2.693774938583374
Validation loss: 2.5693213093665337

Epoch: 6| Step: 8
Training loss: 1.687247395515442
Validation loss: 2.5673344263466458

Epoch: 6| Step: 9
Training loss: 4.055900573730469
Validation loss: 2.5663691233563166

Epoch: 6| Step: 10
Training loss: 2.4916164875030518
Validation loss: 2.571091995444349

Epoch: 6| Step: 11
Training loss: 2.6290106773376465
Validation loss: 2.5646491819812405

Epoch: 6| Step: 12
Training loss: 2.235599994659424
Validation loss: 2.568145808353219

Epoch: 6| Step: 13
Training loss: 2.4748616218566895
Validation loss: 2.562454018541562

Epoch: 148| Step: 0
Training loss: 2.1527481079101562
Validation loss: 2.567044501663536

Epoch: 6| Step: 1
Training loss: 3.110464096069336
Validation loss: 2.5648402424268824

Epoch: 6| Step: 2
Training loss: 3.1604552268981934
Validation loss: 2.562531235397503

Epoch: 6| Step: 3
Training loss: 2.9274258613586426
Validation loss: 2.5632550895854993

Epoch: 6| Step: 4
Training loss: 3.3436481952667236
Validation loss: 2.565413813437185

Epoch: 6| Step: 5
Training loss: 2.74526047706604
Validation loss: 2.5658135619214786

Epoch: 6| Step: 6
Training loss: 1.7022262811660767
Validation loss: 2.5670245667939544

Epoch: 6| Step: 7
Training loss: 2.5085511207580566
Validation loss: 2.5667326629802747

Epoch: 6| Step: 8
Training loss: 2.264512777328491
Validation loss: 2.5668645571636897

Epoch: 6| Step: 9
Training loss: 2.7471022605895996
Validation loss: 2.5648323720501316

Epoch: 6| Step: 10
Training loss: 3.4566636085510254
Validation loss: 2.5643649870349514

Epoch: 6| Step: 11
Training loss: 2.9452595710754395
Validation loss: 2.5600830329361783

Epoch: 6| Step: 12
Training loss: 2.372434377670288
Validation loss: 2.5592638190074632

Epoch: 6| Step: 13
Training loss: 3.0171871185302734
Validation loss: 2.5658993541553454

Epoch: 149| Step: 0
Training loss: 2.609187126159668
Validation loss: 2.566736352059149

Epoch: 6| Step: 1
Training loss: 2.205211639404297
Validation loss: 2.5668094158172607

Epoch: 6| Step: 2
Training loss: 3.4526216983795166
Validation loss: 2.567359996098344

Epoch: 6| Step: 3
Training loss: 3.094026803970337
Validation loss: 2.56035812183093

Epoch: 6| Step: 4
Training loss: 2.6930761337280273
Validation loss: 2.560945685191821

Epoch: 6| Step: 5
Training loss: 3.359288454055786
Validation loss: 2.559401878746607

Epoch: 6| Step: 6
Training loss: 3.9985642433166504
Validation loss: 2.564800262451172

Epoch: 6| Step: 7
Training loss: 3.1640679836273193
Validation loss: 2.5592846716603925

Epoch: 6| Step: 8
Training loss: 2.7270889282226562
Validation loss: 2.5587098278025144

Epoch: 6| Step: 9
Training loss: 2.686072826385498
Validation loss: 2.5634069904204337

Epoch: 6| Step: 10
Training loss: 2.4677319526672363
Validation loss: 2.56064930013431

Epoch: 6| Step: 11
Training loss: 2.1765213012695312
Validation loss: 2.55561004659181

Epoch: 6| Step: 12
Training loss: 1.4606120586395264
Validation loss: 2.5643323262532554

Epoch: 6| Step: 13
Training loss: 1.696789026260376
Validation loss: 2.5623399519151255

Epoch: 150| Step: 0
Training loss: 2.382819890975952
Validation loss: 2.564256118189904

Epoch: 6| Step: 1
Training loss: 2.503826141357422
Validation loss: 2.561079937924621

Epoch: 6| Step: 2
Training loss: 3.0339152812957764
Validation loss: 2.5597990892266713

Epoch: 6| Step: 3
Training loss: 2.82175612449646
Validation loss: 2.555328461431688

Epoch: 6| Step: 4
Training loss: 3.225770950317383
Validation loss: 2.555253795398179

Epoch: 6| Step: 5
Training loss: 2.5507688522338867
Validation loss: 2.5539718084437872

Epoch: 6| Step: 6
Training loss: 2.5605502128601074
Validation loss: 2.5555068754380748

Epoch: 6| Step: 7
Training loss: 2.03348970413208
Validation loss: 2.556280110471992

Epoch: 6| Step: 8
Training loss: 3.819493293762207
Validation loss: 2.558121532522222

Epoch: 6| Step: 9
Training loss: 2.4020156860351562
Validation loss: 2.555262768140403

Epoch: 6| Step: 10
Training loss: 1.7904239892959595
Validation loss: 2.557102152096328

Epoch: 6| Step: 11
Training loss: 3.675471305847168
Validation loss: 2.5534445598561275

Epoch: 6| Step: 12
Training loss: 2.4014930725097656
Validation loss: 2.555599163937312

Epoch: 6| Step: 13
Training loss: 3.2079501152038574
Validation loss: 2.5538145495999243

Epoch: 151| Step: 0
Training loss: 3.7222068309783936
Validation loss: 2.552444391353156

Epoch: 6| Step: 1
Training loss: 3.1667604446411133
Validation loss: 2.5571332900754866

Epoch: 6| Step: 2
Training loss: 2.134011745452881
Validation loss: 2.562817927329771

Epoch: 6| Step: 3
Training loss: 2.504786491394043
Validation loss: 2.568135371772192

Epoch: 6| Step: 4
Training loss: 3.241039752960205
Validation loss: 2.5649282727190243

Epoch: 6| Step: 5
Training loss: 1.9686338901519775
Validation loss: 2.5634133226128033

Epoch: 6| Step: 6
Training loss: 2.683990478515625
Validation loss: 2.562816704473188

Epoch: 6| Step: 7
Training loss: 3.0642876625061035
Validation loss: 2.56543037455569

Epoch: 6| Step: 8
Training loss: 2.5897111892700195
Validation loss: 2.562281995691279

Epoch: 6| Step: 9
Training loss: 2.7240030765533447
Validation loss: 2.565924080469275

Epoch: 6| Step: 10
Training loss: 2.781733989715576
Validation loss: 2.560975113222676

Epoch: 6| Step: 11
Training loss: 2.59674072265625
Validation loss: 2.5591248158485658

Epoch: 6| Step: 12
Training loss: 2.359954357147217
Validation loss: 2.5617646632655973

Epoch: 6| Step: 13
Training loss: 2.5857367515563965
Validation loss: 2.5570998166197088

Epoch: 152| Step: 0
Training loss: 2.0723471641540527
Validation loss: 2.5573916153241227

Epoch: 6| Step: 1
Training loss: 2.0228545665740967
Validation loss: 2.5540821526640203

Epoch: 6| Step: 2
Training loss: 2.724383592605591
Validation loss: 2.5594305017943024

Epoch: 6| Step: 3
Training loss: 2.780693531036377
Validation loss: 2.5554829746164303

Epoch: 6| Step: 4
Training loss: 2.1155014038085938
Validation loss: 2.5618864515776276

Epoch: 6| Step: 5
Training loss: 2.9850363731384277
Validation loss: 2.56130172616692

Epoch: 6| Step: 6
Training loss: 2.7313430309295654
Validation loss: 2.5632474858273744

Epoch: 6| Step: 7
Training loss: 2.975156784057617
Validation loss: 2.5580344520589358

Epoch: 6| Step: 8
Training loss: 3.0483641624450684
Validation loss: 2.564144024284937

Epoch: 6| Step: 9
Training loss: 2.8533782958984375
Validation loss: 2.564824725991936

Epoch: 6| Step: 10
Training loss: 3.516739845275879
Validation loss: 2.565209452823926

Epoch: 6| Step: 11
Training loss: 3.0384159088134766
Validation loss: 2.5590383160498833

Epoch: 6| Step: 12
Training loss: 2.2491366863250732
Validation loss: 2.5576226403636317

Epoch: 6| Step: 13
Training loss: 3.3753464221954346
Validation loss: 2.5565146220627653

Epoch: 153| Step: 0
Training loss: 3.4515938758850098
Validation loss: 2.549520682263118

Epoch: 6| Step: 1
Training loss: 2.156984329223633
Validation loss: 2.5501953786419285

Epoch: 6| Step: 2
Training loss: 2.7442543506622314
Validation loss: 2.55497298958481

Epoch: 6| Step: 3
Training loss: 2.6597073078155518
Validation loss: 2.5511894264528827

Epoch: 6| Step: 4
Training loss: 2.6640515327453613
Validation loss: 2.5536346281728437

Epoch: 6| Step: 5
Training loss: 3.1386120319366455
Validation loss: 2.550802976854386

Epoch: 6| Step: 6
Training loss: 3.3723182678222656
Validation loss: 2.553318203136485

Epoch: 6| Step: 7
Training loss: 2.5767836570739746
Validation loss: 2.554109875873853

Epoch: 6| Step: 8
Training loss: 3.3818295001983643
Validation loss: 2.5506175384726575

Epoch: 6| Step: 9
Training loss: 1.6229779720306396
Validation loss: 2.5520590723201795

Epoch: 6| Step: 10
Training loss: 2.0176281929016113
Validation loss: 2.5502147443832888

Epoch: 6| Step: 11
Training loss: 2.8473353385925293
Validation loss: 2.55136259653235

Epoch: 6| Step: 12
Training loss: 2.420656204223633
Validation loss: 2.548689990915278

Epoch: 6| Step: 13
Training loss: 3.3563504219055176
Validation loss: 2.548561170536985

Epoch: 154| Step: 0
Training loss: 2.2011919021606445
Validation loss: 2.5496426525936333

Epoch: 6| Step: 1
Training loss: 2.812805652618408
Validation loss: 2.548108629001084

Epoch: 6| Step: 2
Training loss: 2.6397557258605957
Validation loss: 2.5480069883408083

Epoch: 6| Step: 3
Training loss: 2.229762315750122
Validation loss: 2.5500636792952016

Epoch: 6| Step: 4
Training loss: 2.5914838314056396
Validation loss: 2.552493187689012

Epoch: 6| Step: 5
Training loss: 3.0929572582244873
Validation loss: 2.5468374811192995

Epoch: 6| Step: 6
Training loss: 2.1215696334838867
Validation loss: 2.548313715124643

Epoch: 6| Step: 7
Training loss: 2.7823755741119385
Validation loss: 2.552484684093024

Epoch: 6| Step: 8
Training loss: 2.6933882236480713
Validation loss: 2.548775467821347

Epoch: 6| Step: 9
Training loss: 3.1088719367980957
Validation loss: 2.554533056033555

Epoch: 6| Step: 10
Training loss: 3.468470335006714
Validation loss: 2.547548447885821

Epoch: 6| Step: 11
Training loss: 3.223330497741699
Validation loss: 2.5491986582356114

Epoch: 6| Step: 12
Training loss: 2.328587532043457
Validation loss: 2.547418204686975

Epoch: 6| Step: 13
Training loss: 2.8406710624694824
Validation loss: 2.548097066981818

Epoch: 155| Step: 0
Training loss: 2.867961883544922
Validation loss: 2.551592021860102

Epoch: 6| Step: 1
Training loss: 3.082031488418579
Validation loss: 2.5471638402631207

Epoch: 6| Step: 2
Training loss: 3.072614908218384
Validation loss: 2.547089686957739

Epoch: 6| Step: 3
Training loss: 2.0552499294281006
Validation loss: 2.5532570449254846

Epoch: 6| Step: 4
Training loss: 2.716440200805664
Validation loss: 2.548428286788284

Epoch: 6| Step: 5
Training loss: 2.5134568214416504
Validation loss: 2.5501651840825237

Epoch: 6| Step: 6
Training loss: 2.9305787086486816
Validation loss: 2.5513628503327728

Epoch: 6| Step: 7
Training loss: 2.760577917098999
Validation loss: 2.5512093010769097

Epoch: 6| Step: 8
Training loss: 2.8938217163085938
Validation loss: 2.5473607817003803

Epoch: 6| Step: 9
Training loss: 2.5182833671569824
Validation loss: 2.552380008082236

Epoch: 6| Step: 10
Training loss: 1.7918171882629395
Validation loss: 2.5476266055978756

Epoch: 6| Step: 11
Training loss: 2.7709717750549316
Validation loss: 2.5488123265645837

Epoch: 6| Step: 12
Training loss: 2.9589285850524902
Validation loss: 2.542998121630761

Epoch: 6| Step: 13
Training loss: 3.4433465003967285
Validation loss: 2.542774003039124

Epoch: 156| Step: 0
Training loss: 2.8063125610351562
Validation loss: 2.5432818397398917

Epoch: 6| Step: 1
Training loss: 2.4624717235565186
Validation loss: 2.5424713960257908

Epoch: 6| Step: 2
Training loss: 2.307377576828003
Validation loss: 2.548310649010443

Epoch: 6| Step: 3
Training loss: 2.8324451446533203
Validation loss: 2.5431678038771435

Epoch: 6| Step: 4
Training loss: 2.5985307693481445
Validation loss: 2.5416967330440396

Epoch: 6| Step: 5
Training loss: 2.629180908203125
Validation loss: 2.541957514260405

Epoch: 6| Step: 6
Training loss: 3.527900218963623
Validation loss: 2.5384098458033737

Epoch: 6| Step: 7
Training loss: 2.8431477546691895
Validation loss: 2.5408265795758975

Epoch: 6| Step: 8
Training loss: 2.693354606628418
Validation loss: 2.5451777570991108

Epoch: 6| Step: 9
Training loss: 2.6372499465942383
Validation loss: 2.5470785889574277

Epoch: 6| Step: 10
Training loss: 2.184711217880249
Validation loss: 2.5444434945301344

Epoch: 6| Step: 11
Training loss: 2.8813865184783936
Validation loss: 2.55378968228576

Epoch: 6| Step: 12
Training loss: 2.248079299926758
Validation loss: 2.554224773119855

Epoch: 6| Step: 13
Training loss: 3.873667001724243
Validation loss: 2.560099547909152

Epoch: 157| Step: 0
Training loss: 2.612863540649414
Validation loss: 2.5528610060291905

Epoch: 6| Step: 1
Training loss: 2.571265459060669
Validation loss: 2.5489371386907433

Epoch: 6| Step: 2
Training loss: 2.853841781616211
Validation loss: 2.5502094504653767

Epoch: 6| Step: 3
Training loss: 2.4329986572265625
Validation loss: 2.544456112769342

Epoch: 6| Step: 4
Training loss: 2.037782669067383
Validation loss: 2.544528966308922

Epoch: 6| Step: 5
Training loss: 3.0529708862304688
Validation loss: 2.5414410688543834

Epoch: 6| Step: 6
Training loss: 3.2099080085754395
Validation loss: 2.540031774069673

Epoch: 6| Step: 7
Training loss: 2.5669922828674316
Validation loss: 2.5441239162157943

Epoch: 6| Step: 8
Training loss: 2.3616604804992676
Validation loss: 2.5440700182350735

Epoch: 6| Step: 9
Training loss: 2.8027610778808594
Validation loss: 2.542720866459672

Epoch: 6| Step: 10
Training loss: 2.9232325553894043
Validation loss: 2.5385638052417385

Epoch: 6| Step: 11
Training loss: 2.244331121444702
Validation loss: 2.5442796881480882

Epoch: 6| Step: 12
Training loss: 3.2634215354919434
Validation loss: 2.5403211988428587

Epoch: 6| Step: 13
Training loss: 3.4486007690429688
Validation loss: 2.546622940289077

Epoch: 158| Step: 0
Training loss: 3.2833895683288574
Validation loss: 2.5521134843108473

Epoch: 6| Step: 1
Training loss: 2.6557912826538086
Validation loss: 2.5485387412450646

Epoch: 6| Step: 2
Training loss: 2.565582752227783
Validation loss: 2.550792558218843

Epoch: 6| Step: 3
Training loss: 3.2696967124938965
Validation loss: 2.5622705413449194

Epoch: 6| Step: 4
Training loss: 2.9840269088745117
Validation loss: 2.5632018709695465

Epoch: 6| Step: 5
Training loss: 3.168694496154785
Validation loss: 2.5515278898259646

Epoch: 6| Step: 6
Training loss: 2.7904272079467773
Validation loss: 2.5504939940667923

Epoch: 6| Step: 7
Training loss: 2.9373972415924072
Validation loss: 2.5463170210520425

Epoch: 6| Step: 8
Training loss: 1.7908508777618408
Validation loss: 2.5438178995604157

Epoch: 6| Step: 9
Training loss: 2.3065009117126465
Validation loss: 2.540082621318038

Epoch: 6| Step: 10
Training loss: 2.472865581512451
Validation loss: 2.5432603487404446

Epoch: 6| Step: 11
Training loss: 2.4661197662353516
Validation loss: 2.5429271498034076

Epoch: 6| Step: 12
Training loss: 2.2842535972595215
Validation loss: 2.5417394766243557

Epoch: 6| Step: 13
Training loss: 3.221421241760254
Validation loss: 2.546143970181865

Epoch: 159| Step: 0
Training loss: 3.0173277854919434
Validation loss: 2.5471195790075485

Epoch: 6| Step: 1
Training loss: 2.214238405227661
Validation loss: 2.547170385237663

Epoch: 6| Step: 2
Training loss: 2.7367162704467773
Validation loss: 2.546625539820681

Epoch: 6| Step: 3
Training loss: 3.4543986320495605
Validation loss: 2.5543916815070697

Epoch: 6| Step: 4
Training loss: 2.8890109062194824
Validation loss: 2.547848278476346

Epoch: 6| Step: 5
Training loss: 2.9732229709625244
Validation loss: 2.546476535899665

Epoch: 6| Step: 6
Training loss: 2.223501443862915
Validation loss: 2.554727372302804

Epoch: 6| Step: 7
Training loss: 2.3386497497558594
Validation loss: 2.543638306279336

Epoch: 6| Step: 8
Training loss: 2.3041574954986572
Validation loss: 2.539856195449829

Epoch: 6| Step: 9
Training loss: 1.9940381050109863
Validation loss: 2.5429142239273235

Epoch: 6| Step: 10
Training loss: 3.649550676345825
Validation loss: 2.540449814129901

Epoch: 6| Step: 11
Training loss: 2.9409124851226807
Validation loss: 2.540803063300348

Epoch: 6| Step: 12
Training loss: 2.510171413421631
Validation loss: 2.5396591514669438

Epoch: 6| Step: 13
Training loss: 2.6568193435668945
Validation loss: 2.536955743707636

Epoch: 160| Step: 0
Training loss: 2.3321900367736816
Validation loss: 2.537336021341303

Epoch: 6| Step: 1
Training loss: 2.3981034755706787
Validation loss: 2.5407729174501155

Epoch: 6| Step: 2
Training loss: 3.3016626834869385
Validation loss: 2.5470162130171254

Epoch: 6| Step: 3
Training loss: 2.356135368347168
Validation loss: 2.5444517699621056

Epoch: 6| Step: 4
Training loss: 3.273056983947754
Validation loss: 2.5627419564031784

Epoch: 6| Step: 5
Training loss: 2.1595959663391113
Validation loss: 2.5579208814969627

Epoch: 6| Step: 6
Training loss: 1.9529013633728027
Validation loss: 2.5472190662096907

Epoch: 6| Step: 7
Training loss: 2.428926944732666
Validation loss: 2.545462623719246

Epoch: 6| Step: 8
Training loss: 2.49981689453125
Validation loss: 2.5540233478751233

Epoch: 6| Step: 9
Training loss: 2.8304967880249023
Validation loss: 2.5742686205012824

Epoch: 6| Step: 10
Training loss: 2.9421164989471436
Validation loss: 2.5793799174729215

Epoch: 6| Step: 11
Training loss: 3.3135886192321777
Validation loss: 2.5475705926136305

Epoch: 6| Step: 12
Training loss: 3.122065782546997
Validation loss: 2.5545530678123556

Epoch: 6| Step: 13
Training loss: 3.5229098796844482
Validation loss: 2.5449129253305416

Epoch: 161| Step: 0
Training loss: 2.699096202850342
Validation loss: 2.539224793834071

Epoch: 6| Step: 1
Training loss: 2.2581839561462402
Validation loss: 2.5421128631919943

Epoch: 6| Step: 2
Training loss: 2.785820722579956
Validation loss: 2.542625152936546

Epoch: 6| Step: 3
Training loss: 2.5568110942840576
Validation loss: 2.546663330447289

Epoch: 6| Step: 4
Training loss: 2.2905941009521484
Validation loss: 2.536811349212482

Epoch: 6| Step: 5
Training loss: 3.28872013092041
Validation loss: 2.5388517661761214

Epoch: 6| Step: 6
Training loss: 2.970693588256836
Validation loss: 2.5373612680742816

Epoch: 6| Step: 7
Training loss: 3.330305576324463
Validation loss: 2.535588877175444

Epoch: 6| Step: 8
Training loss: 3.074232816696167
Validation loss: 2.5346821508099957

Epoch: 6| Step: 9
Training loss: 2.0590925216674805
Validation loss: 2.5436245626018894

Epoch: 6| Step: 10
Training loss: 3.2550034523010254
Validation loss: 2.539946586854996

Epoch: 6| Step: 11
Training loss: 1.8212705850601196
Validation loss: 2.545276572627406

Epoch: 6| Step: 12
Training loss: 2.835733413696289
Validation loss: 2.5402804497749574

Epoch: 6| Step: 13
Training loss: 2.8382248878479004
Validation loss: 2.538982217029859

Epoch: 162| Step: 0
Training loss: 2.5224647521972656
Validation loss: 2.532042375174902

Epoch: 6| Step: 1
Training loss: 1.9588834047317505
Validation loss: 2.531965083973382

Epoch: 6| Step: 2
Training loss: 2.645142078399658
Validation loss: 2.535447633394631

Epoch: 6| Step: 3
Training loss: 2.9165735244750977
Validation loss: 2.5402211937853085

Epoch: 6| Step: 4
Training loss: 2.1132888793945312
Validation loss: 2.542614418973205

Epoch: 6| Step: 5
Training loss: 3.186594009399414
Validation loss: 2.549236697535361

Epoch: 6| Step: 6
Training loss: 3.590059757232666
Validation loss: 2.551220501622846

Epoch: 6| Step: 7
Training loss: 2.7184500694274902
Validation loss: 2.5649497278275026

Epoch: 6| Step: 8
Training loss: 2.7001988887786865
Validation loss: 2.5500699012510237

Epoch: 6| Step: 9
Training loss: 2.8325488567352295
Validation loss: 2.5557465014919156

Epoch: 6| Step: 10
Training loss: 2.7379050254821777
Validation loss: 2.5522611141204834

Epoch: 6| Step: 11
Training loss: 2.5933475494384766
Validation loss: 2.5367685517957135

Epoch: 6| Step: 12
Training loss: 2.7487406730651855
Validation loss: 2.5337635329974595

Epoch: 6| Step: 13
Training loss: 2.7367029190063477
Validation loss: 2.530060011853454

Epoch: 163| Step: 0
Training loss: 2.606937885284424
Validation loss: 2.5325751842991

Epoch: 6| Step: 1
Training loss: 2.7689218521118164
Validation loss: 2.5312605955267466

Epoch: 6| Step: 2
Training loss: 2.755490779876709
Validation loss: 2.5291546929267144

Epoch: 6| Step: 3
Training loss: 2.0639069080352783
Validation loss: 2.533875193647159

Epoch: 6| Step: 4
Training loss: 3.563235282897949
Validation loss: 2.5391761449075516

Epoch: 6| Step: 5
Training loss: 2.1217713356018066
Validation loss: 2.539421050779281

Epoch: 6| Step: 6
Training loss: 2.5159945487976074
Validation loss: 2.5359836445059827

Epoch: 6| Step: 7
Training loss: 2.9696273803710938
Validation loss: 2.5367182506028043

Epoch: 6| Step: 8
Training loss: 2.3266096115112305
Validation loss: 2.5364954702315794

Epoch: 6| Step: 9
Training loss: 2.709954261779785
Validation loss: 2.537432192474283

Epoch: 6| Step: 10
Training loss: 2.6588997840881348
Validation loss: 2.530914680932158

Epoch: 6| Step: 11
Training loss: 3.554290771484375
Validation loss: 2.5311854526560795

Epoch: 6| Step: 12
Training loss: 2.269141674041748
Validation loss: 2.5370740223956365

Epoch: 6| Step: 13
Training loss: 3.49503231048584
Validation loss: 2.5315701192425144

Epoch: 164| Step: 0
Training loss: 3.04323148727417
Validation loss: 2.527124584362071

Epoch: 6| Step: 1
Training loss: 3.5345988273620605
Validation loss: 2.540919437203356

Epoch: 6| Step: 2
Training loss: 2.543126106262207
Validation loss: 2.5473693801510717

Epoch: 6| Step: 3
Training loss: 2.4052131175994873
Validation loss: 2.547254454705023

Epoch: 6| Step: 4
Training loss: 2.301440715789795
Validation loss: 2.5436891817277476

Epoch: 6| Step: 5
Training loss: 2.6741528511047363
Validation loss: 2.552521817145809

Epoch: 6| Step: 6
Training loss: 3.356072425842285
Validation loss: 2.548949426220309

Epoch: 6| Step: 7
Training loss: 2.6293673515319824
Validation loss: 2.554152580999559

Epoch: 6| Step: 8
Training loss: 2.2291722297668457
Validation loss: 2.5580494480748333

Epoch: 6| Step: 9
Training loss: 2.6887896060943604
Validation loss: 2.557722307020618

Epoch: 6| Step: 10
Training loss: 2.814114570617676
Validation loss: 2.5501411191878782

Epoch: 6| Step: 11
Training loss: 2.2875800132751465
Validation loss: 2.5482152790151615

Epoch: 6| Step: 12
Training loss: 2.623730182647705
Validation loss: 2.53622531378141

Epoch: 6| Step: 13
Training loss: 3.035540819168091
Validation loss: 2.5345179650091354

Epoch: 165| Step: 0
Training loss: 2.813575267791748
Validation loss: 2.525417415044641

Epoch: 6| Step: 1
Training loss: 2.328378915786743
Validation loss: 2.524137176493163

Epoch: 6| Step: 2
Training loss: 2.4716012477874756
Validation loss: 2.525288289593112

Epoch: 6| Step: 3
Training loss: 2.9869351387023926
Validation loss: 2.5253777785967757

Epoch: 6| Step: 4
Training loss: 3.0438008308410645
Validation loss: 2.5240374226723947

Epoch: 6| Step: 5
Training loss: 3.1703805923461914
Validation loss: 2.526238103066721

Epoch: 6| Step: 6
Training loss: 2.0267481803894043
Validation loss: 2.5284503531712357

Epoch: 6| Step: 7
Training loss: 2.3975725173950195
Validation loss: 2.5293277566150953

Epoch: 6| Step: 8
Training loss: 3.7427520751953125
Validation loss: 2.527736179290279

Epoch: 6| Step: 9
Training loss: 2.8532497882843018
Validation loss: 2.5267641236705165

Epoch: 6| Step: 10
Training loss: 2.369871139526367
Validation loss: 2.527128514423165

Epoch: 6| Step: 11
Training loss: 2.8312292098999023
Validation loss: 2.5247292928798224

Epoch: 6| Step: 12
Training loss: 2.197343111038208
Validation loss: 2.5239227740995345

Epoch: 6| Step: 13
Training loss: 2.783405303955078
Validation loss: 2.5211033539105485

Epoch: 166| Step: 0
Training loss: 2.0424396991729736
Validation loss: 2.5328217680736254

Epoch: 6| Step: 1
Training loss: 2.6484053134918213
Validation loss: 2.5254615737545874

Epoch: 6| Step: 2
Training loss: 2.6391983032226562
Validation loss: 2.5257237316459737

Epoch: 6| Step: 3
Training loss: 3.143625020980835
Validation loss: 2.527222982016943

Epoch: 6| Step: 4
Training loss: 3.1287121772766113
Validation loss: 2.5299686308830016

Epoch: 6| Step: 5
Training loss: 2.2590088844299316
Validation loss: 2.5277087637173232

Epoch: 6| Step: 6
Training loss: 2.4387388229370117
Validation loss: 2.52612982514084

Epoch: 6| Step: 7
Training loss: 2.7688252925872803
Validation loss: 2.5227395847279537

Epoch: 6| Step: 8
Training loss: 2.934098243713379
Validation loss: 2.527137535874562

Epoch: 6| Step: 9
Training loss: 3.2095961570739746
Validation loss: 2.5256676802071194

Epoch: 6| Step: 10
Training loss: 2.404174327850342
Validation loss: 2.526389942374281

Epoch: 6| Step: 11
Training loss: 2.5404319763183594
Validation loss: 2.5263488395239717

Epoch: 6| Step: 12
Training loss: 2.7784738540649414
Validation loss: 2.525849465400942

Epoch: 6| Step: 13
Training loss: 3.0697429180145264
Validation loss: 2.5246486048544607

Epoch: 167| Step: 0
Training loss: 2.677894353866577
Validation loss: 2.52612280589278

Epoch: 6| Step: 1
Training loss: 2.687793254852295
Validation loss: 2.5335333372956965

Epoch: 6| Step: 2
Training loss: 3.019111156463623
Validation loss: 2.5241965273375153

Epoch: 6| Step: 3
Training loss: 2.1000585556030273
Validation loss: 2.526927953125328

Epoch: 6| Step: 4
Training loss: 3.798067569732666
Validation loss: 2.531914444379909

Epoch: 6| Step: 5
Training loss: 3.2800986766815186
Validation loss: 2.540578588362663

Epoch: 6| Step: 6
Training loss: 2.2395098209381104
Validation loss: 2.530705531438192

Epoch: 6| Step: 7
Training loss: 2.375155448913574
Validation loss: 2.526770463553808

Epoch: 6| Step: 8
Training loss: 2.3927526473999023
Validation loss: 2.53107814891364

Epoch: 6| Step: 9
Training loss: 3.049826145172119
Validation loss: 2.5300279996728383

Epoch: 6| Step: 10
Training loss: 2.2764909267425537
Validation loss: 2.5287670486716816

Epoch: 6| Step: 11
Training loss: 2.774789810180664
Validation loss: 2.531856693247313

Epoch: 6| Step: 12
Training loss: 2.393590211868286
Validation loss: 2.530525166501281

Epoch: 6| Step: 13
Training loss: 2.810326099395752
Validation loss: 2.5255406697591147

Epoch: 168| Step: 0
Training loss: 2.780864953994751
Validation loss: 2.527013007030692

Epoch: 6| Step: 1
Training loss: 3.2773544788360596
Validation loss: 2.530238092586558

Epoch: 6| Step: 2
Training loss: 2.380229949951172
Validation loss: 2.529249224611508

Epoch: 6| Step: 3
Training loss: 2.408614158630371
Validation loss: 2.5290658448332097

Epoch: 6| Step: 4
Training loss: 3.02170991897583
Validation loss: 2.5284457206726074

Epoch: 6| Step: 5
Training loss: 2.9305262565612793
Validation loss: 2.526514983946277

Epoch: 6| Step: 6
Training loss: 2.39129638671875
Validation loss: 2.5282249501956406

Epoch: 6| Step: 7
Training loss: 2.4422659873962402
Validation loss: 2.526516386257705

Epoch: 6| Step: 8
Training loss: 2.3573427200317383
Validation loss: 2.53396539790656

Epoch: 6| Step: 9
Training loss: 2.810919761657715
Validation loss: 2.5282723929292414

Epoch: 6| Step: 10
Training loss: 2.129878520965576
Validation loss: 2.527671265345748

Epoch: 6| Step: 11
Training loss: 3.038095474243164
Validation loss: 2.5300466988676336

Epoch: 6| Step: 12
Training loss: 3.106776237487793
Validation loss: 2.5273229691290084

Epoch: 6| Step: 13
Training loss: 2.722698211669922
Validation loss: 2.5222621040959514

Epoch: 169| Step: 0
Training loss: 2.4935240745544434
Validation loss: 2.5228582735984557

Epoch: 6| Step: 1
Training loss: 3.4870188236236572
Validation loss: 2.5246986830106346

Epoch: 6| Step: 2
Training loss: 2.1499223709106445
Validation loss: 2.521896864778252

Epoch: 6| Step: 3
Training loss: 4.28032112121582
Validation loss: 2.523798809256605

Epoch: 6| Step: 4
Training loss: 2.1005477905273438
Validation loss: 2.5239922410698346

Epoch: 6| Step: 5
Training loss: 2.4533329010009766
Validation loss: 2.5204232482499975

Epoch: 6| Step: 6
Training loss: 2.9104433059692383
Validation loss: 2.5218673675291

Epoch: 6| Step: 7
Training loss: 2.723447322845459
Validation loss: 2.520648612770983

Epoch: 6| Step: 8
Training loss: 2.456787109375
Validation loss: 2.529013651673512

Epoch: 6| Step: 9
Training loss: 2.270968437194824
Validation loss: 2.526330691511913

Epoch: 6| Step: 10
Training loss: 2.157148838043213
Validation loss: 2.5200940332105084

Epoch: 6| Step: 11
Training loss: 3.3759982585906982
Validation loss: 2.5222844616059334

Epoch: 6| Step: 12
Training loss: 1.9276573657989502
Validation loss: 2.517516900134343

Epoch: 6| Step: 13
Training loss: 3.4098870754241943
Validation loss: 2.5233483417059785

Epoch: 170| Step: 0
Training loss: 2.8259286880493164
Validation loss: 2.5230187139203473

Epoch: 6| Step: 1
Training loss: 3.140491008758545
Validation loss: 2.523318024091823

Epoch: 6| Step: 2
Training loss: 2.3139986991882324
Validation loss: 2.528112913972588

Epoch: 6| Step: 3
Training loss: 3.1477274894714355
Validation loss: 2.527982614373648

Epoch: 6| Step: 4
Training loss: 2.71358060836792
Validation loss: 2.534408318099155

Epoch: 6| Step: 5
Training loss: 3.229628086090088
Validation loss: 2.5378508580628263

Epoch: 6| Step: 6
Training loss: 2.25844669342041
Validation loss: 2.528314228980772

Epoch: 6| Step: 7
Training loss: 2.809088706970215
Validation loss: 2.533627317797753

Epoch: 6| Step: 8
Training loss: 2.590254306793213
Validation loss: 2.5254806292954313

Epoch: 6| Step: 9
Training loss: 2.1237454414367676
Validation loss: 2.524428836760982

Epoch: 6| Step: 10
Training loss: 2.351229429244995
Validation loss: 2.5194133609853764

Epoch: 6| Step: 11
Training loss: 2.287970781326294
Validation loss: 2.519206529022545

Epoch: 6| Step: 12
Training loss: 2.7731361389160156
Validation loss: 2.5243148675528904

Epoch: 6| Step: 13
Training loss: 3.5325088500976562
Validation loss: 2.521129790172782

Epoch: 171| Step: 0
Training loss: 2.8323216438293457
Validation loss: 2.518904424482776

Epoch: 6| Step: 1
Training loss: 2.765477180480957
Validation loss: 2.522751787657379

Epoch: 6| Step: 2
Training loss: 2.6363635063171387
Validation loss: 2.523742914199829

Epoch: 6| Step: 3
Training loss: 2.8852181434631348
Validation loss: 2.517634512275778

Epoch: 6| Step: 4
Training loss: 1.9948126077651978
Validation loss: 2.5259880045408845

Epoch: 6| Step: 5
Training loss: 2.7794859409332275
Validation loss: 2.528219033313054

Epoch: 6| Step: 6
Training loss: 2.559152126312256
Validation loss: 2.5322117549116894

Epoch: 6| Step: 7
Training loss: 2.6123437881469727
Validation loss: 2.5321534218326693

Epoch: 6| Step: 8
Training loss: 2.451364517211914
Validation loss: 2.5335540489483903

Epoch: 6| Step: 9
Training loss: 2.534727096557617
Validation loss: 2.5265761780482467

Epoch: 6| Step: 10
Training loss: 3.4439563751220703
Validation loss: 2.527051648785991

Epoch: 6| Step: 11
Training loss: 2.69290828704834
Validation loss: 2.520042465579125

Epoch: 6| Step: 12
Training loss: 2.4755032062530518
Validation loss: 2.517155211458924

Epoch: 6| Step: 13
Training loss: 3.3692433834075928
Validation loss: 2.5187956030650804

Epoch: 172| Step: 0
Training loss: 2.8456056118011475
Validation loss: 2.5164333210196546

Epoch: 6| Step: 1
Training loss: 2.902559995651245
Validation loss: 2.5152393797392487

Epoch: 6| Step: 2
Training loss: 2.6838221549987793
Validation loss: 2.521444361696961

Epoch: 6| Step: 3
Training loss: 2.520111083984375
Validation loss: 2.521849145171463

Epoch: 6| Step: 4
Training loss: 2.6824769973754883
Validation loss: 2.517307330203313

Epoch: 6| Step: 5
Training loss: 2.699800729751587
Validation loss: 2.5195799412265902

Epoch: 6| Step: 6
Training loss: 2.4821414947509766
Validation loss: 2.5171930405401413

Epoch: 6| Step: 7
Training loss: 2.258206367492676
Validation loss: 2.5171882849867626

Epoch: 6| Step: 8
Training loss: 2.570882797241211
Validation loss: 2.5160521640572497

Epoch: 6| Step: 9
Training loss: 2.6298952102661133
Validation loss: 2.5181917708407164

Epoch: 6| Step: 10
Training loss: 2.1297855377197266
Validation loss: 2.521436440047397

Epoch: 6| Step: 11
Training loss: 3.4777960777282715
Validation loss: 2.5335386953046246

Epoch: 6| Step: 12
Training loss: 2.6574769020080566
Validation loss: 2.540324831521639

Epoch: 6| Step: 13
Training loss: 3.677232503890991
Validation loss: 2.5356534270830053

Epoch: 173| Step: 0
Training loss: 2.169020175933838
Validation loss: 2.539781760143977

Epoch: 6| Step: 1
Training loss: 2.699342727661133
Validation loss: 2.5299701229218514

Epoch: 6| Step: 2
Training loss: 3.10894513130188
Validation loss: 2.5299460631544872

Epoch: 6| Step: 3
Training loss: 2.402250289916992
Validation loss: 2.5223959902281403

Epoch: 6| Step: 4
Training loss: 2.3409571647644043
Validation loss: 2.5182058426641647

Epoch: 6| Step: 5
Training loss: 3.4987359046936035
Validation loss: 2.518222269191537

Epoch: 6| Step: 6
Training loss: 3.06813383102417
Validation loss: 2.5177645760197795

Epoch: 6| Step: 7
Training loss: 2.307542562484741
Validation loss: 2.514912159212174

Epoch: 6| Step: 8
Training loss: 2.1108460426330566
Validation loss: 2.5171250784268944

Epoch: 6| Step: 9
Training loss: 3.2131237983703613
Validation loss: 2.5192290326600433

Epoch: 6| Step: 10
Training loss: 2.300875663757324
Validation loss: 2.519810914993286

Epoch: 6| Step: 11
Training loss: 2.7447004318237305
Validation loss: 2.5216675701961724

Epoch: 6| Step: 12
Training loss: 3.4821128845214844
Validation loss: 2.5206618232111775

Epoch: 6| Step: 13
Training loss: 2.1371965408325195
Validation loss: 2.5177621072338474

Epoch: 174| Step: 0
Training loss: 2.158320903778076
Validation loss: 2.518337539447251

Epoch: 6| Step: 1
Training loss: 1.8522453308105469
Validation loss: 2.516353061122279

Epoch: 6| Step: 2
Training loss: 2.6817665100097656
Validation loss: 2.5155514081319175

Epoch: 6| Step: 3
Training loss: 3.076190948486328
Validation loss: 2.519773870386103

Epoch: 6| Step: 4
Training loss: 3.0133228302001953
Validation loss: 2.514863552585725

Epoch: 6| Step: 5
Training loss: 2.2928333282470703
Validation loss: 2.512051954064318

Epoch: 6| Step: 6
Training loss: 3.402696132659912
Validation loss: 2.5133128345653577

Epoch: 6| Step: 7
Training loss: 2.7520415782928467
Validation loss: 2.5112435561354443

Epoch: 6| Step: 8
Training loss: 2.6831326484680176
Validation loss: 2.5136858109504945

Epoch: 6| Step: 9
Training loss: 3.1424307823181152
Validation loss: 2.5114786214725946

Epoch: 6| Step: 10
Training loss: 1.9140467643737793
Validation loss: 2.5134510173592517

Epoch: 6| Step: 11
Training loss: 2.6671133041381836
Validation loss: 2.51316584310224

Epoch: 6| Step: 12
Training loss: 2.643286943435669
Validation loss: 2.516256809234619

Epoch: 6| Step: 13
Training loss: 3.96081805229187
Validation loss: 2.512779648585986

Epoch: 175| Step: 0
Training loss: 1.954473614692688
Validation loss: 2.5108543160141155

Epoch: 6| Step: 1
Training loss: 2.6702709197998047
Validation loss: 2.5118054189989643

Epoch: 6| Step: 2
Training loss: 1.8730762004852295
Validation loss: 2.5173912022703435

Epoch: 6| Step: 3
Training loss: 2.5529367923736572
Validation loss: 2.5198738703163723

Epoch: 6| Step: 4
Training loss: 1.85921311378479
Validation loss: 2.5254734536652923

Epoch: 6| Step: 5
Training loss: 2.8979175090789795
Validation loss: 2.5276602109273276

Epoch: 6| Step: 6
Training loss: 2.474353075027466
Validation loss: 2.5280393554318334

Epoch: 6| Step: 7
Training loss: 3.1496291160583496
Validation loss: 2.538658595854236

Epoch: 6| Step: 8
Training loss: 3.0834920406341553
Validation loss: 2.5275470518296763

Epoch: 6| Step: 9
Training loss: 2.186552047729492
Validation loss: 2.5287572235189457

Epoch: 6| Step: 10
Training loss: 2.9558849334716797
Validation loss: 2.5188779548932145

Epoch: 6| Step: 11
Training loss: 2.94834566116333
Validation loss: 2.51549365187204

Epoch: 6| Step: 12
Training loss: 3.8823468685150146
Validation loss: 2.515305749831661

Epoch: 6| Step: 13
Training loss: 3.7364094257354736
Validation loss: 2.517200111061014

Epoch: 176| Step: 0
Training loss: 2.2482705116271973
Validation loss: 2.5187320991228987

Epoch: 6| Step: 1
Training loss: 2.800609588623047
Validation loss: 2.515591404771292

Epoch: 6| Step: 2
Training loss: 2.649082660675049
Validation loss: 2.5133390477908555

Epoch: 6| Step: 3
Training loss: 2.4196243286132812
Validation loss: 2.513185478025867

Epoch: 6| Step: 4
Training loss: 3.3351287841796875
Validation loss: 2.5145789243841685

Epoch: 6| Step: 5
Training loss: 2.706662654876709
Validation loss: 2.51071608707469

Epoch: 6| Step: 6
Training loss: 2.3963441848754883
Validation loss: 2.5107925630384877

Epoch: 6| Step: 7
Training loss: 2.684084415435791
Validation loss: 2.5145477441049393

Epoch: 6| Step: 8
Training loss: 2.8670973777770996
Validation loss: 2.5118784314842633

Epoch: 6| Step: 9
Training loss: 3.204373836517334
Validation loss: 2.5197812152165238

Epoch: 6| Step: 10
Training loss: 2.0025219917297363
Validation loss: 2.514836883032194

Epoch: 6| Step: 11
Training loss: 3.2017080783843994
Validation loss: 2.520511217014764

Epoch: 6| Step: 12
Training loss: 2.592660427093506
Validation loss: 2.517837832050939

Epoch: 6| Step: 13
Training loss: 2.537487030029297
Validation loss: 2.521456100607431

Epoch: 177| Step: 0
Training loss: 3.0901474952697754
Validation loss: 2.521018902460734

Epoch: 6| Step: 1
Training loss: 2.52805233001709
Validation loss: 2.5164165548098985

Epoch: 6| Step: 2
Training loss: 2.511296510696411
Validation loss: 2.510809249775384

Epoch: 6| Step: 3
Training loss: 3.3594183921813965
Validation loss: 2.507075430244528

Epoch: 6| Step: 4
Training loss: 1.9859541654586792
Validation loss: 2.507838769625592

Epoch: 6| Step: 5
Training loss: 2.210308074951172
Validation loss: 2.5076318940808697

Epoch: 6| Step: 6
Training loss: 2.809349298477173
Validation loss: 2.5084210134321645

Epoch: 6| Step: 7
Training loss: 2.652056932449341
Validation loss: 2.5067578695153676

Epoch: 6| Step: 8
Training loss: 2.4663381576538086
Validation loss: 2.5076985359191895

Epoch: 6| Step: 9
Training loss: 2.976745128631592
Validation loss: 2.5078857444947764

Epoch: 6| Step: 10
Training loss: 2.8470280170440674
Validation loss: 2.5091778668024207

Epoch: 6| Step: 11
Training loss: 2.29630970954895
Validation loss: 2.5062731568531325

Epoch: 6| Step: 12
Training loss: 2.747903347015381
Validation loss: 2.5124906032316145

Epoch: 6| Step: 13
Training loss: 3.6910717487335205
Validation loss: 2.5101345277601674

Epoch: 178| Step: 0
Training loss: 2.917584180831909
Validation loss: 2.5067912711892077

Epoch: 6| Step: 1
Training loss: 2.072882652282715
Validation loss: 2.511799830262379

Epoch: 6| Step: 2
Training loss: 2.394472599029541
Validation loss: 2.5107843568248134

Epoch: 6| Step: 3
Training loss: 2.5885543823242188
Validation loss: 2.5123740626919653

Epoch: 6| Step: 4
Training loss: 3.2750048637390137
Validation loss: 2.5204032877440095

Epoch: 6| Step: 5
Training loss: 2.614978790283203
Validation loss: 2.519548649428993

Epoch: 6| Step: 6
Training loss: 1.9522693157196045
Validation loss: 2.526213438280167

Epoch: 6| Step: 7
Training loss: 3.064455509185791
Validation loss: 2.5265547152488463

Epoch: 6| Step: 8
Training loss: 2.2154321670532227
Validation loss: 2.5218844054847636

Epoch: 6| Step: 9
Training loss: 2.4384989738464355
Validation loss: 2.5213794964616016

Epoch: 6| Step: 10
Training loss: 3.313742160797119
Validation loss: 2.5056135090448524

Epoch: 6| Step: 11
Training loss: 2.4628679752349854
Validation loss: 2.5071387624227874

Epoch: 6| Step: 12
Training loss: 3.782747745513916
Validation loss: 2.504188181251608

Epoch: 6| Step: 13
Training loss: 2.5160539150238037
Validation loss: 2.5080963616730063

Epoch: 179| Step: 0
Training loss: 2.5218944549560547
Validation loss: 2.5124545507533576

Epoch: 6| Step: 1
Training loss: 4.381473541259766
Validation loss: 2.516637848269555

Epoch: 6| Step: 2
Training loss: 2.8040192127227783
Validation loss: 2.5219798805893108

Epoch: 6| Step: 3
Training loss: 2.8397858142852783
Validation loss: 2.518603999127624

Epoch: 6| Step: 4
Training loss: 2.1986308097839355
Validation loss: 2.521310947274649

Epoch: 6| Step: 5
Training loss: 2.60827898979187
Validation loss: 2.5180732896251063

Epoch: 6| Step: 6
Training loss: 2.730800151824951
Validation loss: 2.514497116047849

Epoch: 6| Step: 7
Training loss: 1.6990033388137817
Validation loss: 2.5143105650460846

Epoch: 6| Step: 8
Training loss: 2.7382853031158447
Validation loss: 2.507241515703099

Epoch: 6| Step: 9
Training loss: 2.0660171508789062
Validation loss: 2.5047006889056136

Epoch: 6| Step: 10
Training loss: 2.4636950492858887
Validation loss: 2.5071522164088424

Epoch: 6| Step: 11
Training loss: 3.2719740867614746
Validation loss: 2.503715343372796

Epoch: 6| Step: 12
Training loss: 3.0949530601501465
Validation loss: 2.5144256622560563

Epoch: 6| Step: 13
Training loss: 2.0994019508361816
Validation loss: 2.5216544879380094

Epoch: 180| Step: 0
Training loss: 2.0279855728149414
Validation loss: 2.5385500179824008

Epoch: 6| Step: 1
Training loss: 2.4767987728118896
Validation loss: 2.548150472743537

Epoch: 6| Step: 2
Training loss: 2.503398895263672
Validation loss: 2.560121895164572

Epoch: 6| Step: 3
Training loss: 3.025845527648926
Validation loss: 2.5472018616173857

Epoch: 6| Step: 4
Training loss: 3.0197737216949463
Validation loss: 2.539842697881883

Epoch: 6| Step: 5
Training loss: 2.461932420730591
Validation loss: 2.535104377295381

Epoch: 6| Step: 6
Training loss: 2.774831771850586
Validation loss: 2.5205210255038355

Epoch: 6| Step: 7
Training loss: 2.913754463195801
Validation loss: 2.5140090578345844

Epoch: 6| Step: 8
Training loss: 2.783115863800049
Validation loss: 2.506205169103479

Epoch: 6| Step: 9
Training loss: 3.4196503162384033
Validation loss: 2.503561991517262

Epoch: 6| Step: 10
Training loss: 2.374894857406616
Validation loss: 2.5024151596971738

Epoch: 6| Step: 11
Training loss: 2.8167431354522705
Validation loss: 2.5017093689210954

Epoch: 6| Step: 12
Training loss: 2.6694438457489014
Validation loss: 2.508774685603316

Epoch: 6| Step: 13
Training loss: 2.3125433921813965
Validation loss: 2.510346540840723

Epoch: 181| Step: 0
Training loss: 3.297271251678467
Validation loss: 2.510610600953461

Epoch: 6| Step: 1
Training loss: 1.578776240348816
Validation loss: 2.5106811395255466

Epoch: 6| Step: 2
Training loss: 2.315181255340576
Validation loss: 2.5125558145584597

Epoch: 6| Step: 3
Training loss: 2.035745620727539
Validation loss: 2.511549126717352

Epoch: 6| Step: 4
Training loss: 2.9615654945373535
Validation loss: 2.5162400609703472

Epoch: 6| Step: 5
Training loss: 3.267704963684082
Validation loss: 2.511041828381118

Epoch: 6| Step: 6
Training loss: 2.879096031188965
Validation loss: 2.502901556671307

Epoch: 6| Step: 7
Training loss: 3.3952512741088867
Validation loss: 2.5071152692200034

Epoch: 6| Step: 8
Training loss: 2.6901941299438477
Validation loss: 2.507653723480881

Epoch: 6| Step: 9
Training loss: 2.8336029052734375
Validation loss: 2.514670446354856

Epoch: 6| Step: 10
Training loss: 2.3897130489349365
Validation loss: 2.5128506614315893

Epoch: 6| Step: 11
Training loss: 2.928213119506836
Validation loss: 2.5213473996808453

Epoch: 6| Step: 12
Training loss: 2.3772082328796387
Validation loss: 2.529003753457018

Epoch: 6| Step: 13
Training loss: 2.8467233180999756
Validation loss: 2.530398755945185

Epoch: 182| Step: 0
Training loss: 3.1327173709869385
Validation loss: 2.5221825825270785

Epoch: 6| Step: 1
Training loss: 3.1010210514068604
Validation loss: 2.5245303466755855

Epoch: 6| Step: 2
Training loss: 1.820613980293274
Validation loss: 2.5152034605703046

Epoch: 6| Step: 3
Training loss: 2.7467994689941406
Validation loss: 2.5118335447003766

Epoch: 6| Step: 4
Training loss: 2.104057788848877
Validation loss: 2.5046049984552528

Epoch: 6| Step: 5
Training loss: 3.128457546234131
Validation loss: 2.5050177189611618

Epoch: 6| Step: 6
Training loss: 2.8393282890319824
Validation loss: 2.5011808692768054

Epoch: 6| Step: 7
Training loss: 2.8586902618408203
Validation loss: 2.502386005975867

Epoch: 6| Step: 8
Training loss: 2.9037129878997803
Validation loss: 2.5012839173757904

Epoch: 6| Step: 9
Training loss: 2.8711743354797363
Validation loss: 2.5054832402096

Epoch: 6| Step: 10
Training loss: 2.004209518432617
Validation loss: 2.5035608148062103

Epoch: 6| Step: 11
Training loss: 2.6190032958984375
Validation loss: 2.5055833990855882

Epoch: 6| Step: 12
Training loss: 2.8314387798309326
Validation loss: 2.5062551729140745

Epoch: 6| Step: 13
Training loss: 2.827136993408203
Validation loss: 2.503088851128855

Epoch: 183| Step: 0
Training loss: 2.6541829109191895
Validation loss: 2.5016273683117283

Epoch: 6| Step: 1
Training loss: 2.891603946685791
Validation loss: 2.5032897200635684

Epoch: 6| Step: 2
Training loss: 2.6515896320343018
Validation loss: 2.502634427880728

Epoch: 6| Step: 3
Training loss: 2.305903434753418
Validation loss: 2.505325604510564

Epoch: 6| Step: 4
Training loss: 2.7025084495544434
Validation loss: 2.513088810828424

Epoch: 6| Step: 5
Training loss: 2.7584712505340576
Validation loss: 2.5203119913736978

Epoch: 6| Step: 6
Training loss: 3.0707790851593018
Validation loss: 2.5200110661086215

Epoch: 6| Step: 7
Training loss: 3.3881146907806396
Validation loss: 2.5443591097349763

Epoch: 6| Step: 8
Training loss: 2.4919142723083496
Validation loss: 2.5374240131788355

Epoch: 6| Step: 9
Training loss: 1.9506332874298096
Validation loss: 2.5369091597936486

Epoch: 6| Step: 10
Training loss: 1.5539608001708984
Validation loss: 2.540168785279797

Epoch: 6| Step: 11
Training loss: 3.650766611099243
Validation loss: 2.526254359111991

Epoch: 6| Step: 12
Training loss: 2.964223861694336
Validation loss: 2.5118990252094884

Epoch: 6| Step: 13
Training loss: 2.595184326171875
Validation loss: 2.5045427148060133

Epoch: 184| Step: 0
Training loss: 2.8064348697662354
Validation loss: 2.4990648531144664

Epoch: 6| Step: 1
Training loss: 2.8030617237091064
Validation loss: 2.497486581084549

Epoch: 6| Step: 2
Training loss: 2.140566825866699
Validation loss: 2.496537846903647

Epoch: 6| Step: 3
Training loss: 2.9414854049682617
Validation loss: 2.49601581276104

Epoch: 6| Step: 4
Training loss: 3.1616530418395996
Validation loss: 2.499396744594779

Epoch: 6| Step: 5
Training loss: 3.406237840652466
Validation loss: 2.5047461345631588

Epoch: 6| Step: 6
Training loss: 2.3030219078063965
Validation loss: 2.503504027602493

Epoch: 6| Step: 7
Training loss: 3.0576272010803223
Validation loss: 2.502054468277962

Epoch: 6| Step: 8
Training loss: 3.21223521232605
Validation loss: 2.497414142854752

Epoch: 6| Step: 9
Training loss: 2.966188669204712
Validation loss: 2.495412411228303

Epoch: 6| Step: 10
Training loss: 1.9677584171295166
Validation loss: 2.4944808662578626

Epoch: 6| Step: 11
Training loss: 1.999801754951477
Validation loss: 2.5002119105349303

Epoch: 6| Step: 12
Training loss: 2.7423365116119385
Validation loss: 2.4936978137621315

Epoch: 6| Step: 13
Training loss: 1.8523966073989868
Validation loss: 2.5003116489738546

Epoch: 185| Step: 0
Training loss: 2.387695789337158
Validation loss: 2.502852814171904

Epoch: 6| Step: 1
Training loss: 2.3906567096710205
Validation loss: 2.5012131685851724

Epoch: 6| Step: 2
Training loss: 3.624650716781616
Validation loss: 2.5093703782686623

Epoch: 6| Step: 3
Training loss: 1.903059482574463
Validation loss: 2.495693714387955

Epoch: 6| Step: 4
Training loss: 2.6860265731811523
Validation loss: 2.5051090473769815

Epoch: 6| Step: 5
Training loss: 2.9173336029052734
Validation loss: 2.5109992950193343

Epoch: 6| Step: 6
Training loss: 3.10056734085083
Validation loss: 2.509979530047345

Epoch: 6| Step: 7
Training loss: 2.3050339221954346
Validation loss: 2.4981051080970356

Epoch: 6| Step: 8
Training loss: 2.2025768756866455
Validation loss: 2.509508678990026

Epoch: 6| Step: 9
Training loss: 3.37925386428833
Validation loss: 2.5048815383706042

Epoch: 6| Step: 10
Training loss: 2.126819372177124
Validation loss: 2.4973428736450853

Epoch: 6| Step: 11
Training loss: 2.904918670654297
Validation loss: 2.4984381557792745

Epoch: 6| Step: 12
Training loss: 2.7280545234680176
Validation loss: 2.4917553624799176

Epoch: 6| Step: 13
Training loss: 3.146958589553833
Validation loss: 2.4889462327444427

Epoch: 186| Step: 0
Training loss: 3.501608371734619
Validation loss: 2.492018142054158

Epoch: 6| Step: 1
Training loss: 3.068852663040161
Validation loss: 2.49518483941273

Epoch: 6| Step: 2
Training loss: 2.364652156829834
Validation loss: 2.497097328145017

Epoch: 6| Step: 3
Training loss: 2.5373189449310303
Validation loss: 2.4937056713206793

Epoch: 6| Step: 4
Training loss: 2.7679898738861084
Validation loss: 2.493739994623328

Epoch: 6| Step: 5
Training loss: 2.8486902713775635
Validation loss: 2.498904617883826

Epoch: 6| Step: 6
Training loss: 2.980405330657959
Validation loss: 2.4951743361770466

Epoch: 6| Step: 7
Training loss: 2.1227684020996094
Validation loss: 2.4924196684232323

Epoch: 6| Step: 8
Training loss: 2.4282662868499756
Validation loss: 2.4917702751774944

Epoch: 6| Step: 9
Training loss: 2.0019118785858154
Validation loss: 2.4899382488701933

Epoch: 6| Step: 10
Training loss: 2.8815152645111084
Validation loss: 2.493773957734467

Epoch: 6| Step: 11
Training loss: 2.989375591278076
Validation loss: 2.4919812499835925

Epoch: 6| Step: 12
Training loss: 2.6663577556610107
Validation loss: 2.495320779021068

Epoch: 6| Step: 13
Training loss: 2.259182929992676
Validation loss: 2.496718955296342

Epoch: 187| Step: 0
Training loss: 3.01823353767395
Validation loss: 2.4941801768477245

Epoch: 6| Step: 1
Training loss: 3.2247707843780518
Validation loss: 2.4947040824479956

Epoch: 6| Step: 2
Training loss: 3.157907485961914
Validation loss: 2.5005921958595194

Epoch: 6| Step: 3
Training loss: 2.5214757919311523
Validation loss: 2.501317162667551

Epoch: 6| Step: 4
Training loss: 2.420088768005371
Validation loss: 2.5064621407498597

Epoch: 6| Step: 5
Training loss: 2.309741973876953
Validation loss: 2.5067423492349605

Epoch: 6| Step: 6
Training loss: 2.558150291442871
Validation loss: 2.505921589430942

Epoch: 6| Step: 7
Training loss: 1.504706859588623
Validation loss: 2.5039590661243727

Epoch: 6| Step: 8
Training loss: 3.867551326751709
Validation loss: 2.5089706195298063

Epoch: 6| Step: 9
Training loss: 2.4925122261047363
Validation loss: 2.5058019109951553

Epoch: 6| Step: 10
Training loss: 3.202559232711792
Validation loss: 2.508072063487063

Epoch: 6| Step: 11
Training loss: 3.1045682430267334
Validation loss: 2.509484132130941

Epoch: 6| Step: 12
Training loss: 1.829522728919983
Validation loss: 2.4989319565475627

Epoch: 6| Step: 13
Training loss: 2.0716142654418945
Validation loss: 2.5047497236600487

Epoch: 188| Step: 0
Training loss: 2.6115496158599854
Validation loss: 2.4935935774157123

Epoch: 6| Step: 1
Training loss: 2.869180202484131
Validation loss: 2.4921044482979724

Epoch: 6| Step: 2
Training loss: 2.659426689147949
Validation loss: 2.4913981601756108

Epoch: 6| Step: 3
Training loss: 2.4456427097320557
Validation loss: 2.4893684233388593

Epoch: 6| Step: 4
Training loss: 3.031827449798584
Validation loss: 2.4953242604450514

Epoch: 6| Step: 5
Training loss: 2.9398865699768066
Validation loss: 2.493566956571353

Epoch: 6| Step: 6
Training loss: 2.8836917877197266
Validation loss: 2.4906599854910247

Epoch: 6| Step: 7
Training loss: 2.5945167541503906
Validation loss: 2.4946449623313

Epoch: 6| Step: 8
Training loss: 2.1065220832824707
Validation loss: 2.497973959933045

Epoch: 6| Step: 9
Training loss: 1.975463628768921
Validation loss: 2.4907005961223314

Epoch: 6| Step: 10
Training loss: 3.31247615814209
Validation loss: 2.4913492471941057

Epoch: 6| Step: 11
Training loss: 2.649059772491455
Validation loss: 2.493150895641696

Epoch: 6| Step: 12
Training loss: 3.062986373901367
Validation loss: 2.4923715155611754

Epoch: 6| Step: 13
Training loss: 2.1534740924835205
Validation loss: 2.487178680717304

Epoch: 189| Step: 0
Training loss: 3.370546340942383
Validation loss: 2.49187348991312

Epoch: 6| Step: 1
Training loss: 3.178347587585449
Validation loss: 2.4869762569345455

Epoch: 6| Step: 2
Training loss: 2.227389335632324
Validation loss: 2.490617472638366

Epoch: 6| Step: 3
Training loss: 2.268033981323242
Validation loss: 2.4847279697336178

Epoch: 6| Step: 4
Training loss: 2.0428361892700195
Validation loss: 2.488992803840227

Epoch: 6| Step: 5
Training loss: 2.1684908866882324
Validation loss: 2.484945107531804

Epoch: 6| Step: 6
Training loss: 2.063464641571045
Validation loss: 2.4869010576637844

Epoch: 6| Step: 7
Training loss: 2.2357733249664307
Validation loss: 2.490211307361562

Epoch: 6| Step: 8
Training loss: 3.501307725906372
Validation loss: 2.4910958966901227

Epoch: 6| Step: 9
Training loss: 4.121526718139648
Validation loss: 2.4969361661582865

Epoch: 6| Step: 10
Training loss: 2.4225752353668213
Validation loss: 2.5030160693712133

Epoch: 6| Step: 11
Training loss: 2.6061081886291504
Validation loss: 2.5138208097027195

Epoch: 6| Step: 12
Training loss: 2.6906728744506836
Validation loss: 2.503946537612587

Epoch: 6| Step: 13
Training loss: 2.4744977951049805
Validation loss: 2.5028966960086616

Epoch: 190| Step: 0
Training loss: 2.756960153579712
Validation loss: 2.4999671853998655

Epoch: 6| Step: 1
Training loss: 2.2797131538391113
Validation loss: 2.4971760549852924

Epoch: 6| Step: 2
Training loss: 3.0818657875061035
Validation loss: 2.493733795740271

Epoch: 6| Step: 3
Training loss: 2.9141526222229004
Validation loss: 2.4934764728751233

Epoch: 6| Step: 4
Training loss: 2.972134590148926
Validation loss: 2.4894030324874388

Epoch: 6| Step: 5
Training loss: 3.206719398498535
Validation loss: 2.4846702826920377

Epoch: 6| Step: 6
Training loss: 2.354827404022217
Validation loss: 2.4919579926357476

Epoch: 6| Step: 7
Training loss: 3.222090005874634
Validation loss: 2.484422501697335

Epoch: 6| Step: 8
Training loss: 2.6059062480926514
Validation loss: 2.4879929481014127

Epoch: 6| Step: 9
Training loss: 1.7165019512176514
Validation loss: 2.4837338642407487

Epoch: 6| Step: 10
Training loss: 2.530090808868408
Validation loss: 2.487060231547202

Epoch: 6| Step: 11
Training loss: 2.449995517730713
Validation loss: 2.482723223265781

Epoch: 6| Step: 12
Training loss: 3.211287021636963
Validation loss: 2.487113639872561

Epoch: 6| Step: 13
Training loss: 1.712752103805542
Validation loss: 2.485352828938474

Epoch: 191| Step: 0
Training loss: 1.5450350046157837
Validation loss: 2.484755785234513

Epoch: 6| Step: 1
Training loss: 1.7529222965240479
Validation loss: 2.4846387345303773

Epoch: 6| Step: 2
Training loss: 2.648165702819824
Validation loss: 2.489866461805118

Epoch: 6| Step: 3
Training loss: 2.3164069652557373
Validation loss: 2.500871140469787

Epoch: 6| Step: 4
Training loss: 3.562340021133423
Validation loss: 2.498232813291652

Epoch: 6| Step: 5
Training loss: 2.888113021850586
Validation loss: 2.5361997491569928

Epoch: 6| Step: 6
Training loss: 2.707031726837158
Validation loss: 2.5480451788953555

Epoch: 6| Step: 7
Training loss: 2.624180316925049
Validation loss: 2.5383524817805134

Epoch: 6| Step: 8
Training loss: 3.389788866043091
Validation loss: 2.5287126905174664

Epoch: 6| Step: 9
Training loss: 2.551680088043213
Validation loss: 2.5177459716796875

Epoch: 6| Step: 10
Training loss: 2.4458937644958496
Validation loss: 2.5034736740973687

Epoch: 6| Step: 11
Training loss: 2.830382823944092
Validation loss: 2.4896380157880884

Epoch: 6| Step: 12
Training loss: 3.0633163452148438
Validation loss: 2.4852104289557344

Epoch: 6| Step: 13
Training loss: 3.7297487258911133
Validation loss: 2.483681191680252

Epoch: 192| Step: 0
Training loss: 2.1301848888397217
Validation loss: 2.483652965996855

Epoch: 6| Step: 1
Training loss: 2.591820240020752
Validation loss: 2.483227140160017

Epoch: 6| Step: 2
Training loss: 2.674246072769165
Validation loss: 2.4850903557192896

Epoch: 6| Step: 3
Training loss: 3.260875701904297
Validation loss: 2.4845649452619654

Epoch: 6| Step: 4
Training loss: 2.806565999984741
Validation loss: 2.4844776289437407

Epoch: 6| Step: 5
Training loss: 1.8789126873016357
Validation loss: 2.483313586122246

Epoch: 6| Step: 6
Training loss: 3.333439350128174
Validation loss: 2.4838094454939648

Epoch: 6| Step: 7
Training loss: 2.866093635559082
Validation loss: 2.4828554532861196

Epoch: 6| Step: 8
Training loss: 2.689378261566162
Validation loss: 2.488889125085646

Epoch: 6| Step: 9
Training loss: 2.0413074493408203
Validation loss: 2.4853862331759546

Epoch: 6| Step: 10
Training loss: 3.4414799213409424
Validation loss: 2.4943531892632924

Epoch: 6| Step: 11
Training loss: 1.6085174083709717
Validation loss: 2.4867576886248846

Epoch: 6| Step: 12
Training loss: 2.8474228382110596
Validation loss: 2.494193048887355

Epoch: 6| Step: 13
Training loss: 3.7760603427886963
Validation loss: 2.4937462088882283

Epoch: 193| Step: 0
Training loss: 2.4992218017578125
Validation loss: 2.4861422687448482

Epoch: 6| Step: 1
Training loss: 2.701846122741699
Validation loss: 2.4920142748022593

Epoch: 6| Step: 2
Training loss: 3.486959934234619
Validation loss: 2.4929029275012273

Epoch: 6| Step: 3
Training loss: 2.513047695159912
Validation loss: 2.4977122968243015

Epoch: 6| Step: 4
Training loss: 2.9428882598876953
Validation loss: 2.492940754018804

Epoch: 6| Step: 5
Training loss: 3.1649646759033203
Validation loss: 2.5006957669411936

Epoch: 6| Step: 6
Training loss: 2.858778476715088
Validation loss: 2.4916382502484065

Epoch: 6| Step: 7
Training loss: 2.534945011138916
Validation loss: 2.489726079407559

Epoch: 6| Step: 8
Training loss: 2.8269424438476562
Validation loss: 2.487766642724314

Epoch: 6| Step: 9
Training loss: 2.198620557785034
Validation loss: 2.485693311178556

Epoch: 6| Step: 10
Training loss: 1.8411078453063965
Validation loss: 2.488835532178161

Epoch: 6| Step: 11
Training loss: 2.6657209396362305
Validation loss: 2.4893272563975346

Epoch: 6| Step: 12
Training loss: 2.474208354949951
Validation loss: 2.495011032268565

Epoch: 6| Step: 13
Training loss: 2.659466028213501
Validation loss: 2.4825092797638266

Epoch: 194| Step: 0
Training loss: 2.6518678665161133
Validation loss: 2.481817255737961

Epoch: 6| Step: 1
Training loss: 2.863903760910034
Validation loss: 2.484310983329691

Epoch: 6| Step: 2
Training loss: 3.0753860473632812
Validation loss: 2.4884783914012294

Epoch: 6| Step: 3
Training loss: 2.953639507293701
Validation loss: 2.4855998126409387

Epoch: 6| Step: 4
Training loss: 3.024675130844116
Validation loss: 2.482121636790614

Epoch: 6| Step: 5
Training loss: 1.868276834487915
Validation loss: 2.4839838602209605

Epoch: 6| Step: 6
Training loss: 2.6664552688598633
Validation loss: 2.48636059863593

Epoch: 6| Step: 7
Training loss: 3.0283360481262207
Validation loss: 2.477861519782774

Epoch: 6| Step: 8
Training loss: 3.060760498046875
Validation loss: 2.4908764772517706

Epoch: 6| Step: 9
Training loss: 1.4270284175872803
Validation loss: 2.4821848356595604

Epoch: 6| Step: 10
Training loss: 1.7133874893188477
Validation loss: 2.483682576046195

Epoch: 6| Step: 11
Training loss: 3.1199493408203125
Validation loss: 2.4833881009009575

Epoch: 6| Step: 12
Training loss: 2.8215715885162354
Validation loss: 2.480136327846076

Epoch: 6| Step: 13
Training loss: 3.4291164875030518
Validation loss: 2.481241913251979

Epoch: 195| Step: 0
Training loss: 2.4156441688537598
Validation loss: 2.4794917439901702

Epoch: 6| Step: 1
Training loss: 2.265049457550049
Validation loss: 2.484656946633452

Epoch: 6| Step: 2
Training loss: 3.3079793453216553
Validation loss: 2.487751691572128

Epoch: 6| Step: 3
Training loss: 1.9839630126953125
Validation loss: 2.485875960319273

Epoch: 6| Step: 4
Training loss: 2.75703763961792
Validation loss: 2.4839162031809487

Epoch: 6| Step: 5
Training loss: 2.6122045516967773
Validation loss: 2.4843889154413694

Epoch: 6| Step: 6
Training loss: 3.5333175659179688
Validation loss: 2.483311376264018

Epoch: 6| Step: 7
Training loss: 2.0338969230651855
Validation loss: 2.4813622582343315

Epoch: 6| Step: 8
Training loss: 3.0556912422180176
Validation loss: 2.4909055976457495

Epoch: 6| Step: 9
Training loss: 2.8353981971740723
Validation loss: 2.488871612856465

Epoch: 6| Step: 10
Training loss: 2.775392532348633
Validation loss: 2.482721315917148

Epoch: 6| Step: 11
Training loss: 3.3837106227874756
Validation loss: 2.488042591720499

Epoch: 6| Step: 12
Training loss: 2.4938411712646484
Validation loss: 2.4911722983083417

Epoch: 6| Step: 13
Training loss: 1.2944623231887817
Validation loss: 2.4851651396802676

Epoch: 196| Step: 0
Training loss: 2.5741162300109863
Validation loss: 2.4925123722322526

Epoch: 6| Step: 1
Training loss: 2.0818991661071777
Validation loss: 2.5000341579478276

Epoch: 6| Step: 2
Training loss: 2.749577283859253
Validation loss: 2.507189937817153

Epoch: 6| Step: 3
Training loss: 3.220933437347412
Validation loss: 2.4955001774654595

Epoch: 6| Step: 4
Training loss: 3.0267908573150635
Validation loss: 2.48696497947939

Epoch: 6| Step: 5
Training loss: 2.266655445098877
Validation loss: 2.4890691823856805

Epoch: 6| Step: 6
Training loss: 1.9590959548950195
Validation loss: 2.4864037729078725

Epoch: 6| Step: 7
Training loss: 2.317046642303467
Validation loss: 2.4867090794347946

Epoch: 6| Step: 8
Training loss: 2.5641283988952637
Validation loss: 2.490905584827546

Epoch: 6| Step: 9
Training loss: 2.4066824913024902
Validation loss: 2.4898705431210097

Epoch: 6| Step: 10
Training loss: 4.053339958190918
Validation loss: 2.48643244466474

Epoch: 6| Step: 11
Training loss: 2.954113245010376
Validation loss: 2.485570966556508

Epoch: 6| Step: 12
Training loss: 2.573268175125122
Validation loss: 2.4879035231887654

Epoch: 6| Step: 13
Training loss: 2.6344008445739746
Validation loss: 2.4933895270029702

Epoch: 197| Step: 0
Training loss: 2.0722382068634033
Validation loss: 2.493429809488276

Epoch: 6| Step: 1
Training loss: 3.010915517807007
Validation loss: 2.488903558382424

Epoch: 6| Step: 2
Training loss: 1.9556645154953003
Validation loss: 2.4879802426984234

Epoch: 6| Step: 3
Training loss: 2.8976612091064453
Validation loss: 2.4918021335396716

Epoch: 6| Step: 4
Training loss: 1.7495601177215576
Validation loss: 2.4927678595307055

Epoch: 6| Step: 5
Training loss: 2.8637709617614746
Validation loss: 2.49501637745929

Epoch: 6| Step: 6
Training loss: 2.9390463829040527
Validation loss: 2.5033939397463234

Epoch: 6| Step: 7
Training loss: 2.726581573486328
Validation loss: 2.498814913534349

Epoch: 6| Step: 8
Training loss: 2.684523105621338
Validation loss: 2.4936275687268985

Epoch: 6| Step: 9
Training loss: 3.1053690910339355
Validation loss: 2.494569875860727

Epoch: 6| Step: 10
Training loss: 2.6949405670166016
Validation loss: 2.4987646482324086

Epoch: 6| Step: 11
Training loss: 2.800549030303955
Validation loss: 2.4905019114094396

Epoch: 6| Step: 12
Training loss: 3.0478689670562744
Validation loss: 2.495754664944064

Epoch: 6| Step: 13
Training loss: 2.892666816711426
Validation loss: 2.4915245374043784

Epoch: 198| Step: 0
Training loss: 3.069398880004883
Validation loss: 2.4911097582950386

Epoch: 6| Step: 1
Training loss: 2.530008316040039
Validation loss: 2.4846424338638142

Epoch: 6| Step: 2
Training loss: 3.172412872314453
Validation loss: 2.4804075276979836

Epoch: 6| Step: 3
Training loss: 2.4554741382598877
Validation loss: 2.4932121256346345

Epoch: 6| Step: 4
Training loss: 2.707005500793457
Validation loss: 2.487940416541151

Epoch: 6| Step: 5
Training loss: 2.7076807022094727
Validation loss: 2.491560577064432

Epoch: 6| Step: 6
Training loss: 2.5277791023254395
Validation loss: 2.4968918856754097

Epoch: 6| Step: 7
Training loss: 2.213244915008545
Validation loss: 2.4986947659523255

Epoch: 6| Step: 8
Training loss: 3.0659635066986084
Validation loss: 2.4952432904192197

Epoch: 6| Step: 9
Training loss: 2.4106202125549316
Validation loss: 2.4859717738243843

Epoch: 6| Step: 10
Training loss: 2.3735063076019287
Validation loss: 2.4855635832714778

Epoch: 6| Step: 11
Training loss: 3.421349048614502
Validation loss: 2.486042017577797

Epoch: 6| Step: 12
Training loss: 2.717588424682617
Validation loss: 2.484475753640616

Epoch: 6| Step: 13
Training loss: 1.78076171875
Validation loss: 2.48447605358657

Epoch: 199| Step: 0
Training loss: 2.313441753387451
Validation loss: 2.4933135278763308

Epoch: 6| Step: 1
Training loss: 2.376154899597168
Validation loss: 2.486875851949056

Epoch: 6| Step: 2
Training loss: 2.1865339279174805
Validation loss: 2.501769491421279

Epoch: 6| Step: 3
Training loss: 3.5980441570281982
Validation loss: 2.5011862939403904

Epoch: 6| Step: 4
Training loss: 2.4059300422668457
Validation loss: 2.501626342855474

Epoch: 6| Step: 5
Training loss: 2.5126540660858154
Validation loss: 2.4981799305126233

Epoch: 6| Step: 6
Training loss: 3.3343420028686523
Validation loss: 2.4882828574026785

Epoch: 6| Step: 7
Training loss: 1.9465826749801636
Validation loss: 2.4888725408943753

Epoch: 6| Step: 8
Training loss: 3.2497334480285645
Validation loss: 2.4946990961669595

Epoch: 6| Step: 9
Training loss: 2.959566116333008
Validation loss: 2.496670430706393

Epoch: 6| Step: 10
Training loss: 2.8853654861450195
Validation loss: 2.4926889224718978

Epoch: 6| Step: 11
Training loss: 1.7906970977783203
Validation loss: 2.4802447416449107

Epoch: 6| Step: 12
Training loss: 2.7126259803771973
Validation loss: 2.477950883168046

Epoch: 6| Step: 13
Training loss: 3.4277687072753906
Validation loss: 2.474132773696735

Epoch: 200| Step: 0
Training loss: 2.4711503982543945
Validation loss: 2.4769407190302366

Epoch: 6| Step: 1
Training loss: 2.717813014984131
Validation loss: 2.482682640834521

Epoch: 6| Step: 2
Training loss: 2.8115835189819336
Validation loss: 2.4768726428349814

Epoch: 6| Step: 3
Training loss: 2.8004021644592285
Validation loss: 2.4848471918413715

Epoch: 6| Step: 4
Training loss: 2.684190273284912
Validation loss: 2.4749508134780394

Epoch: 6| Step: 5
Training loss: 3.239574432373047
Validation loss: 2.479647672304543

Epoch: 6| Step: 6
Training loss: 2.9816231727600098
Validation loss: 2.478443045769968

Epoch: 6| Step: 7
Training loss: 3.076592206954956
Validation loss: 2.471651784835323

Epoch: 6| Step: 8
Training loss: 2.3088927268981934
Validation loss: 2.4792262649023407

Epoch: 6| Step: 9
Training loss: 2.833470344543457
Validation loss: 2.481100595125588

Epoch: 6| Step: 10
Training loss: 2.5809707641601562
Validation loss: 2.4844985956786783

Epoch: 6| Step: 11
Training loss: 1.9728949069976807
Validation loss: 2.4837699961918656

Epoch: 6| Step: 12
Training loss: 2.470425605773926
Validation loss: 2.4818900810774935

Epoch: 6| Step: 13
Training loss: 2.122161388397217
Validation loss: 2.4843790326067197

Epoch: 201| Step: 0
Training loss: 3.254810094833374
Validation loss: 2.487390746352493

Epoch: 6| Step: 1
Training loss: 3.208585262298584
Validation loss: 2.504529248001755

Epoch: 6| Step: 2
Training loss: 2.874762535095215
Validation loss: 2.5277063846588135

Epoch: 6| Step: 3
Training loss: 3.022397518157959
Validation loss: 2.5291387009364303

Epoch: 6| Step: 4
Training loss: 2.5033445358276367
Validation loss: 2.5178262546498287

Epoch: 6| Step: 5
Training loss: 2.8773016929626465
Validation loss: 2.521621440046577

Epoch: 6| Step: 6
Training loss: 2.245115280151367
Validation loss: 2.513892130185199

Epoch: 6| Step: 7
Training loss: 2.56416392326355
Validation loss: 2.503996500404932

Epoch: 6| Step: 8
Training loss: 1.7830162048339844
Validation loss: 2.4858858226447977

Epoch: 6| Step: 9
Training loss: 3.364506959915161
Validation loss: 2.4807564802067255

Epoch: 6| Step: 10
Training loss: 2.648505687713623
Validation loss: 2.4787348983108357

Epoch: 6| Step: 11
Training loss: 1.7111499309539795
Validation loss: 2.477332832992718

Epoch: 6| Step: 12
Training loss: 2.6117985248565674
Validation loss: 2.4869759826249975

Epoch: 6| Step: 13
Training loss: 2.7372376918792725
Validation loss: 2.477074597471504

Epoch: 202| Step: 0
Training loss: 3.426199197769165
Validation loss: 2.485976803687311

Epoch: 6| Step: 1
Training loss: 3.011287212371826
Validation loss: 2.4865440783962125

Epoch: 6| Step: 2
Training loss: 2.269836187362671
Validation loss: 2.488321945231448

Epoch: 6| Step: 3
Training loss: 2.1042983531951904
Validation loss: 2.485592057628016

Epoch: 6| Step: 4
Training loss: 2.1224756240844727
Validation loss: 2.4871742340826217

Epoch: 6| Step: 5
Training loss: 2.337723731994629
Validation loss: 2.4861561764952955

Epoch: 6| Step: 6
Training loss: 2.734705924987793
Validation loss: 2.4776950241417013

Epoch: 6| Step: 7
Training loss: 2.551579475402832
Validation loss: 2.473818084245087

Epoch: 6| Step: 8
Training loss: 3.0130832195281982
Validation loss: 2.471808612987559

Epoch: 6| Step: 9
Training loss: 2.7144627571105957
Validation loss: 2.4710736864356586

Epoch: 6| Step: 10
Training loss: 2.5707154273986816
Validation loss: 2.476992817335231

Epoch: 6| Step: 11
Training loss: 3.15031361579895
Validation loss: 2.4704877727775165

Epoch: 6| Step: 12
Training loss: 2.2850661277770996
Validation loss: 2.48151675603723

Epoch: 6| Step: 13
Training loss: 3.5626134872436523
Validation loss: 2.49346258050652

Epoch: 203| Step: 0
Training loss: 2.6231417655944824
Validation loss: 2.488734188900199

Epoch: 6| Step: 1
Training loss: 3.1251015663146973
Validation loss: 2.4916571776072183

Epoch: 6| Step: 2
Training loss: 2.584693431854248
Validation loss: 2.501077490468179

Epoch: 6| Step: 3
Training loss: 2.254549264907837
Validation loss: 2.4837697808460524

Epoch: 6| Step: 4
Training loss: 2.5255613327026367
Validation loss: 2.500527274224066

Epoch: 6| Step: 5
Training loss: 2.583080530166626
Validation loss: 2.4934592785373813

Epoch: 6| Step: 6
Training loss: 2.5178303718566895
Validation loss: 2.4987497688621603

Epoch: 6| Step: 7
Training loss: 2.7619924545288086
Validation loss: 2.4922750124367337

Epoch: 6| Step: 8
Training loss: 3.2423324584960938
Validation loss: 2.4983790074625323

Epoch: 6| Step: 9
Training loss: 2.449106216430664
Validation loss: 2.495174930941674

Epoch: 6| Step: 10
Training loss: 3.176112174987793
Validation loss: 2.472209261309716

Epoch: 6| Step: 11
Training loss: 2.8845179080963135
Validation loss: 2.474890319249963

Epoch: 6| Step: 12
Training loss: 2.0144777297973633
Validation loss: 2.4726547810339157

Epoch: 6| Step: 13
Training loss: 2.53238582611084
Validation loss: 2.4816826005135812

Epoch: 204| Step: 0
Training loss: 2.3310303688049316
Validation loss: 2.4793657538711384

Epoch: 6| Step: 1
Training loss: 2.9387667179107666
Validation loss: 2.4802004560347526

Epoch: 6| Step: 2
Training loss: 2.12995982170105
Validation loss: 2.4874249171185236

Epoch: 6| Step: 3
Training loss: 3.3748655319213867
Validation loss: 2.4861597784103884

Epoch: 6| Step: 4
Training loss: 3.5398824214935303
Validation loss: 2.488060684614284

Epoch: 6| Step: 5
Training loss: 2.664005756378174
Validation loss: 2.4804345510339223

Epoch: 6| Step: 6
Training loss: 2.80855393409729
Validation loss: 2.48747004232099

Epoch: 6| Step: 7
Training loss: 1.4207402467727661
Validation loss: 2.4849485838285057

Epoch: 6| Step: 8
Training loss: 1.900827407836914
Validation loss: 2.48212597703421

Epoch: 6| Step: 9
Training loss: 2.809638023376465
Validation loss: 2.4790566813561226

Epoch: 6| Step: 10
Training loss: 2.885444402694702
Validation loss: 2.4824765138728644

Epoch: 6| Step: 11
Training loss: 2.5918538570404053
Validation loss: 2.4766941583284767

Epoch: 6| Step: 12
Training loss: 2.704261541366577
Validation loss: 2.478083218297651

Epoch: 6| Step: 13
Training loss: 3.787442922592163
Validation loss: 2.4949089442529986

Epoch: 205| Step: 0
Training loss: 2.1101813316345215
Validation loss: 2.5123590782124507

Epoch: 6| Step: 1
Training loss: 2.984145164489746
Validation loss: 2.513443336691908

Epoch: 6| Step: 2
Training loss: 2.6825308799743652
Validation loss: 2.5143193326970583

Epoch: 6| Step: 3
Training loss: 3.2075552940368652
Validation loss: 2.4964735046509774

Epoch: 6| Step: 4
Training loss: 3.2076973915100098
Validation loss: 2.4938636005565686

Epoch: 6| Step: 5
Training loss: 2.8724148273468018
Validation loss: 2.49458674974339

Epoch: 6| Step: 6
Training loss: 1.8888212442398071
Validation loss: 2.477085769817393

Epoch: 6| Step: 7
Training loss: 2.3409156799316406
Validation loss: 2.4678800106048584

Epoch: 6| Step: 8
Training loss: 2.858609676361084
Validation loss: 2.472021682288057

Epoch: 6| Step: 9
Training loss: 3.052480697631836
Validation loss: 2.469166624930597

Epoch: 6| Step: 10
Training loss: 1.9915549755096436
Validation loss: 2.47030185884045

Epoch: 6| Step: 11
Training loss: 2.902744770050049
Validation loss: 2.4700661833568285

Epoch: 6| Step: 12
Training loss: 2.8821327686309814
Validation loss: 2.4704176456697526

Epoch: 6| Step: 13
Training loss: 2.078524589538574
Validation loss: 2.4713820872768277

Epoch: 206| Step: 0
Training loss: 2.8517332077026367
Validation loss: 2.470371946211784

Epoch: 6| Step: 1
Training loss: 3.0407841205596924
Validation loss: 2.472543485703007

Epoch: 6| Step: 2
Training loss: 3.0329651832580566
Validation loss: 2.465353117194227

Epoch: 6| Step: 3
Training loss: 3.4024851322174072
Validation loss: 2.466983146564935

Epoch: 6| Step: 4
Training loss: 2.205461263656616
Validation loss: 2.4711471885763188

Epoch: 6| Step: 5
Training loss: 2.9871861934661865
Validation loss: 2.469321632897982

Epoch: 6| Step: 6
Training loss: 2.619636297225952
Validation loss: 2.4684703888431674

Epoch: 6| Step: 7
Training loss: 2.169210910797119
Validation loss: 2.46814888779835

Epoch: 6| Step: 8
Training loss: 1.8771257400512695
Validation loss: 2.477063391798286

Epoch: 6| Step: 9
Training loss: 2.1830358505249023
Validation loss: 2.475599588886384

Epoch: 6| Step: 10
Training loss: 2.4342575073242188
Validation loss: 2.4836898183309906

Epoch: 6| Step: 11
Training loss: 2.641998291015625
Validation loss: 2.476945438692647

Epoch: 6| Step: 12
Training loss: 3.346282720565796
Validation loss: 2.490906940993442

Epoch: 6| Step: 13
Training loss: 2.355076789855957
Validation loss: 2.4990408241107898

Epoch: 207| Step: 0
Training loss: 2.2827200889587402
Validation loss: 2.498942464910528

Epoch: 6| Step: 1
Training loss: 3.0716991424560547
Validation loss: 2.503228847698499

Epoch: 6| Step: 2
Training loss: 2.0499837398529053
Validation loss: 2.50424648228512

Epoch: 6| Step: 3
Training loss: 2.4079596996307373
Validation loss: 2.4965902374636744

Epoch: 6| Step: 4
Training loss: 2.834057331085205
Validation loss: 2.4914955298105874

Epoch: 6| Step: 5
Training loss: 2.9437947273254395
Validation loss: 2.487957537815135

Epoch: 6| Step: 6
Training loss: 2.2690365314483643
Validation loss: 2.4854234187833724

Epoch: 6| Step: 7
Training loss: 2.485823631286621
Validation loss: 2.4839553435643515

Epoch: 6| Step: 8
Training loss: 2.2835373878479004
Validation loss: 2.4804413164815595

Epoch: 6| Step: 9
Training loss: 2.8117165565490723
Validation loss: 2.4743532083367787

Epoch: 6| Step: 10
Training loss: 3.8289051055908203
Validation loss: 2.4673408603155487

Epoch: 6| Step: 11
Training loss: 3.238868236541748
Validation loss: 2.4679159015737553

Epoch: 6| Step: 12
Training loss: 2.570192337036133
Validation loss: 2.467538587508663

Epoch: 6| Step: 13
Training loss: 1.682571291923523
Validation loss: 2.4612731805411716

Epoch: 208| Step: 0
Training loss: 3.0872762203216553
Validation loss: 2.461368155735795

Epoch: 6| Step: 1
Training loss: 2.5262808799743652
Validation loss: 2.4676101182096746

Epoch: 6| Step: 2
Training loss: 2.645587205886841
Validation loss: 2.4719330597949285

Epoch: 6| Step: 3
Training loss: 2.096181869506836
Validation loss: 2.466352473023117

Epoch: 6| Step: 4
Training loss: 3.028930902481079
Validation loss: 2.4698475535197923

Epoch: 6| Step: 5
Training loss: 2.7945094108581543
Validation loss: 2.466416299984019

Epoch: 6| Step: 6
Training loss: 3.0957045555114746
Validation loss: 2.461557783106322

Epoch: 6| Step: 7
Training loss: 2.2154219150543213
Validation loss: 2.4617882210721254

Epoch: 6| Step: 8
Training loss: 2.9618730545043945
Validation loss: 2.463297237632095

Epoch: 6| Step: 9
Training loss: 2.374526023864746
Validation loss: 2.4643134968255156

Epoch: 6| Step: 10
Training loss: 2.524057388305664
Validation loss: 2.462660689507761

Epoch: 6| Step: 11
Training loss: 3.12985897064209
Validation loss: 2.4629686494027414

Epoch: 6| Step: 12
Training loss: 2.8471336364746094
Validation loss: 2.4617398913188646

Epoch: 6| Step: 13
Training loss: 1.424745798110962
Validation loss: 2.462901573027334

Epoch: 209| Step: 0
Training loss: 2.8064544200897217
Validation loss: 2.459972640519501

Epoch: 6| Step: 1
Training loss: 3.4521965980529785
Validation loss: 2.4610881882329143

Epoch: 6| Step: 2
Training loss: 2.49229097366333
Validation loss: 2.464715316731443

Epoch: 6| Step: 3
Training loss: 2.687177896499634
Validation loss: 2.458500700612222

Epoch: 6| Step: 4
Training loss: 2.5919241905212402
Validation loss: 2.4626757047509633

Epoch: 6| Step: 5
Training loss: 2.682847023010254
Validation loss: 2.457889285138858

Epoch: 6| Step: 6
Training loss: 2.754168748855591
Validation loss: 2.460231673332953

Epoch: 6| Step: 7
Training loss: 2.4732258319854736
Validation loss: 2.4621311054434827

Epoch: 6| Step: 8
Training loss: 2.8634657859802246
Validation loss: 2.4567067930775304

Epoch: 6| Step: 9
Training loss: 2.434253215789795
Validation loss: 2.4579716010760237

Epoch: 6| Step: 10
Training loss: 2.441251754760742
Validation loss: 2.4631392289233465

Epoch: 6| Step: 11
Training loss: 2.298576831817627
Validation loss: 2.4643959486356346

Epoch: 6| Step: 12
Training loss: 2.80839467048645
Validation loss: 2.4740111879123154

Epoch: 6| Step: 13
Training loss: 2.318369150161743
Validation loss: 2.474173309982464

Epoch: 210| Step: 0
Training loss: 2.2775087356567383
Validation loss: 2.4855542464922835

Epoch: 6| Step: 1
Training loss: 2.8553552627563477
Validation loss: 2.4829136504921863

Epoch: 6| Step: 2
Training loss: 2.569206714630127
Validation loss: 2.483321614162896

Epoch: 6| Step: 3
Training loss: 2.7386269569396973
Validation loss: 2.4792991197237404

Epoch: 6| Step: 4
Training loss: 2.017507553100586
Validation loss: 2.4777271414315827

Epoch: 6| Step: 5
Training loss: 2.9580888748168945
Validation loss: 2.4806123959120883

Epoch: 6| Step: 6
Training loss: 3.3298990726470947
Validation loss: 2.467889655020929

Epoch: 6| Step: 7
Training loss: 3.321383476257324
Validation loss: 2.471830629533337

Epoch: 6| Step: 8
Training loss: 2.485466480255127
Validation loss: 2.47079441624303

Epoch: 6| Step: 9
Training loss: 2.550607442855835
Validation loss: 2.4616510611708446

Epoch: 6| Step: 10
Training loss: 2.8134946823120117
Validation loss: 2.4725482643291516

Epoch: 6| Step: 11
Training loss: 2.5196056365966797
Validation loss: 2.473507604291362

Epoch: 6| Step: 12
Training loss: 1.9671169519424438
Validation loss: 2.4775976416885213

Epoch: 6| Step: 13
Training loss: 2.847672462463379
Validation loss: 2.4812850054874214

Epoch: 211| Step: 0
Training loss: 3.610830783843994
Validation loss: 2.4854541183799825

Epoch: 6| Step: 1
Training loss: 3.154397964477539
Validation loss: 2.4803898616503646

Epoch: 6| Step: 2
Training loss: 3.270289897918701
Validation loss: 2.47863349863278

Epoch: 6| Step: 3
Training loss: 2.1804497241973877
Validation loss: 2.4715592322811

Epoch: 6| Step: 4
Training loss: 2.30273175239563
Validation loss: 2.469590094781691

Epoch: 6| Step: 5
Training loss: 2.4772040843963623
Validation loss: 2.479866381614439

Epoch: 6| Step: 6
Training loss: 2.008124351501465
Validation loss: 2.4786174528060423

Epoch: 6| Step: 7
Training loss: 2.440992832183838
Validation loss: 2.4833981298631236

Epoch: 6| Step: 8
Training loss: 2.1894540786743164
Validation loss: 2.481538926401446

Epoch: 6| Step: 9
Training loss: 2.7946572303771973
Validation loss: 2.482056071681361

Epoch: 6| Step: 10
Training loss: 2.9557037353515625
Validation loss: 2.491930728317589

Epoch: 6| Step: 11
Training loss: 2.2127885818481445
Validation loss: 2.4824737502682592

Epoch: 6| Step: 12
Training loss: 3.0156946182250977
Validation loss: 2.481707401173089

Epoch: 6| Step: 13
Training loss: 2.3759098052978516
Validation loss: 2.475064992904663

Epoch: 212| Step: 0
Training loss: 2.133833646774292
Validation loss: 2.466231482003325

Epoch: 6| Step: 1
Training loss: 2.40756893157959
Validation loss: 2.4812601920097106

Epoch: 6| Step: 2
Training loss: 2.7057266235351562
Validation loss: 2.4713548203950286

Epoch: 6| Step: 3
Training loss: 2.4161853790283203
Validation loss: 2.467092337146882

Epoch: 6| Step: 4
Training loss: 2.8381471633911133
Validation loss: 2.4720136478383052

Epoch: 6| Step: 5
Training loss: 2.513214588165283
Validation loss: 2.489860814104798

Epoch: 6| Step: 6
Training loss: 2.6596713066101074
Validation loss: 2.490902780204691

Epoch: 6| Step: 7
Training loss: 2.6575770378112793
Validation loss: 2.494443375577209

Epoch: 6| Step: 8
Training loss: 2.9522206783294678
Validation loss: 2.4881324280974684

Epoch: 6| Step: 9
Training loss: 2.526160478591919
Validation loss: 2.4881271905796503

Epoch: 6| Step: 10
Training loss: 2.785954475402832
Validation loss: 2.4858067368948333

Epoch: 6| Step: 11
Training loss: 2.7000181674957275
Validation loss: 2.4900741295147966

Epoch: 6| Step: 12
Training loss: 2.869560480117798
Validation loss: 2.491190263020095

Epoch: 6| Step: 13
Training loss: 3.154669761657715
Validation loss: 2.470264314323343

Epoch: 213| Step: 0
Training loss: 1.9295121431350708
Validation loss: 2.4709854202885784

Epoch: 6| Step: 1
Training loss: 2.7754623889923096
Validation loss: 2.4642419353608163

Epoch: 6| Step: 2
Training loss: 2.5256729125976562
Validation loss: 2.467017058403261

Epoch: 6| Step: 3
Training loss: 2.2094287872314453
Validation loss: 2.4603620113865023

Epoch: 6| Step: 4
Training loss: 2.511457681655884
Validation loss: 2.4616771282688266

Epoch: 6| Step: 5
Training loss: 2.9360861778259277
Validation loss: 2.4694997059401644

Epoch: 6| Step: 6
Training loss: 2.687455654144287
Validation loss: 2.466003461550641

Epoch: 6| Step: 7
Training loss: 2.926013946533203
Validation loss: 2.4722584857735583

Epoch: 6| Step: 8
Training loss: 2.4321165084838867
Validation loss: 2.4706887173396286

Epoch: 6| Step: 9
Training loss: 2.7956531047821045
Validation loss: 2.467410018367152

Epoch: 6| Step: 10
Training loss: 2.142733097076416
Validation loss: 2.4675398308743715

Epoch: 6| Step: 11
Training loss: 2.951902151107788
Validation loss: 2.4729223738434496

Epoch: 6| Step: 12
Training loss: 3.1866841316223145
Validation loss: 2.4885998336217736

Epoch: 6| Step: 13
Training loss: 3.44345760345459
Validation loss: 2.4863898831029094

Epoch: 214| Step: 0
Training loss: 2.7487735748291016
Validation loss: 2.4805802863131285

Epoch: 6| Step: 1
Training loss: 2.791551113128662
Validation loss: 2.4719389164319603

Epoch: 6| Step: 2
Training loss: 2.5600368976593018
Validation loss: 2.479782622347596

Epoch: 6| Step: 3
Training loss: 1.987291932106018
Validation loss: 2.4854372111699914

Epoch: 6| Step: 4
Training loss: 3.121518135070801
Validation loss: 2.4811918556049304

Epoch: 6| Step: 5
Training loss: 3.1377995014190674
Validation loss: 2.477189927972773

Epoch: 6| Step: 6
Training loss: 2.4473986625671387
Validation loss: 2.458966898661788

Epoch: 6| Step: 7
Training loss: 1.9031397104263306
Validation loss: 2.471043227821268

Epoch: 6| Step: 8
Training loss: 2.420515537261963
Validation loss: 2.4648219846910044

Epoch: 6| Step: 9
Training loss: 2.786849021911621
Validation loss: 2.463843778897357

Epoch: 6| Step: 10
Training loss: 4.162268161773682
Validation loss: 2.4699858055319837

Epoch: 6| Step: 11
Training loss: 2.2800655364990234
Validation loss: 2.467569604996712

Epoch: 6| Step: 12
Training loss: 1.653918743133545
Validation loss: 2.462428057065574

Epoch: 6| Step: 13
Training loss: 3.4865307807922363
Validation loss: 2.459424936643211

Epoch: 215| Step: 0
Training loss: 2.851019859313965
Validation loss: 2.458075346485261

Epoch: 6| Step: 1
Training loss: 2.47525691986084
Validation loss: 2.456251816083026

Epoch: 6| Step: 2
Training loss: 2.3660504817962646
Validation loss: 2.461689995181176

Epoch: 6| Step: 3
Training loss: 1.073526382446289
Validation loss: 2.46641037284687

Epoch: 6| Step: 4
Training loss: 3.498870849609375
Validation loss: 2.4754745806417158

Epoch: 6| Step: 5
Training loss: 2.364485263824463
Validation loss: 2.4747034965022916

Epoch: 6| Step: 6
Training loss: 2.93770432472229
Validation loss: 2.487580273741035

Epoch: 6| Step: 7
Training loss: 3.173224449157715
Validation loss: 2.4791670409581994

Epoch: 6| Step: 8
Training loss: 3.1641135215759277
Validation loss: 2.474219383731965

Epoch: 6| Step: 9
Training loss: 2.6664865016937256
Validation loss: 2.485996857766182

Epoch: 6| Step: 10
Training loss: 2.4518449306488037
Validation loss: 2.4910872636302823

Epoch: 6| Step: 11
Training loss: 2.547994613647461
Validation loss: 2.493460509084886

Epoch: 6| Step: 12
Training loss: 2.361255168914795
Validation loss: 2.4893236775552072

Epoch: 6| Step: 13
Training loss: 3.7189674377441406
Validation loss: 2.4711529439495457

Epoch: 216| Step: 0
Training loss: 2.6731271743774414
Validation loss: 2.4667453509505077

Epoch: 6| Step: 1
Training loss: 2.3571085929870605
Validation loss: 2.459130520461708

Epoch: 6| Step: 2
Training loss: 3.2810893058776855
Validation loss: 2.456825658839236

Epoch: 6| Step: 3
Training loss: 3.1761865615844727
Validation loss: 2.4574115968519643

Epoch: 6| Step: 4
Training loss: 2.5726964473724365
Validation loss: 2.463407608770555

Epoch: 6| Step: 5
Training loss: 2.2577860355377197
Validation loss: 2.455640328827725

Epoch: 6| Step: 6
Training loss: 2.3376235961914062
Validation loss: 2.4646736960257254

Epoch: 6| Step: 7
Training loss: 2.785390853881836
Validation loss: 2.4593074911384174

Epoch: 6| Step: 8
Training loss: 2.9283618927001953
Validation loss: 2.456170097474129

Epoch: 6| Step: 9
Training loss: 2.1779778003692627
Validation loss: 2.4624723311393493

Epoch: 6| Step: 10
Training loss: 2.5260684490203857
Validation loss: 2.471476465143183

Epoch: 6| Step: 11
Training loss: 3.1359035968780518
Validation loss: 2.4644433836783133

Epoch: 6| Step: 12
Training loss: 2.0276236534118652
Validation loss: 2.4585702419281006

Epoch: 6| Step: 13
Training loss: 2.958805561065674
Validation loss: 2.467536705796437

Epoch: 217| Step: 0
Training loss: 2.8696463108062744
Validation loss: 2.463370612872544

Epoch: 6| Step: 1
Training loss: 2.515353202819824
Validation loss: 2.468524049687129

Epoch: 6| Step: 2
Training loss: 2.5264837741851807
Validation loss: 2.4708921294058523

Epoch: 6| Step: 3
Training loss: 2.466304302215576
Validation loss: 2.465160346800281

Epoch: 6| Step: 4
Training loss: 2.4729971885681152
Validation loss: 2.464731865031745

Epoch: 6| Step: 5
Training loss: 2.3375940322875977
Validation loss: 2.4699088322219027

Epoch: 6| Step: 6
Training loss: 3.4810776710510254
Validation loss: 2.469454970411075

Epoch: 6| Step: 7
Training loss: 2.7348263263702393
Validation loss: 2.468452097267233

Epoch: 6| Step: 8
Training loss: 2.0703277587890625
Validation loss: 2.470153066419786

Epoch: 6| Step: 9
Training loss: 3.149155378341675
Validation loss: 2.464440050945487

Epoch: 6| Step: 10
Training loss: 1.8277173042297363
Validation loss: 2.4743522392806185

Epoch: 6| Step: 11
Training loss: 3.0764496326446533
Validation loss: 2.464167848710091

Epoch: 6| Step: 12
Training loss: 2.892517566680908
Validation loss: 2.4633679364317205

Epoch: 6| Step: 13
Training loss: 2.781550645828247
Validation loss: 2.464669865946616

Epoch: 218| Step: 0
Training loss: 3.399623155593872
Validation loss: 2.4792410609542683

Epoch: 6| Step: 1
Training loss: 2.6090927124023438
Validation loss: 2.47855290033484

Epoch: 6| Step: 2
Training loss: 2.598064422607422
Validation loss: 2.5212520476310485

Epoch: 6| Step: 3
Training loss: 2.501343250274658
Validation loss: 2.5374743220626668

Epoch: 6| Step: 4
Training loss: 2.9576687812805176
Validation loss: 2.5253907403638287

Epoch: 6| Step: 5
Training loss: 1.8974820375442505
Validation loss: 2.4998390084953717

Epoch: 6| Step: 6
Training loss: 2.291172981262207
Validation loss: 2.477174958875102

Epoch: 6| Step: 7
Training loss: 2.739659309387207
Validation loss: 2.4724501281656246

Epoch: 6| Step: 8
Training loss: 2.940532922744751
Validation loss: 2.454363869082543

Epoch: 6| Step: 9
Training loss: 3.1232049465179443
Validation loss: 2.4554656936276342

Epoch: 6| Step: 10
Training loss: 1.9636605978012085
Validation loss: 2.4537069823152278

Epoch: 6| Step: 11
Training loss: 2.507680892944336
Validation loss: 2.4570891216237056

Epoch: 6| Step: 12
Training loss: 2.2594823837280273
Validation loss: 2.4604750499930432

Epoch: 6| Step: 13
Training loss: 3.988664388656616
Validation loss: 2.4563969130157144

Epoch: 219| Step: 0
Training loss: 3.075777053833008
Validation loss: 2.4599688168494933

Epoch: 6| Step: 1
Training loss: 2.426107883453369
Validation loss: 2.455232684330274

Epoch: 6| Step: 2
Training loss: 1.8354158401489258
Validation loss: 2.4615928332010903

Epoch: 6| Step: 3
Training loss: 2.6941590309143066
Validation loss: 2.4546718751230547

Epoch: 6| Step: 4
Training loss: 1.5571800470352173
Validation loss: 2.463119629890688

Epoch: 6| Step: 5
Training loss: 2.961060047149658
Validation loss: 2.4636481320986183

Epoch: 6| Step: 6
Training loss: 2.681335210800171
Validation loss: 2.4601802582381875

Epoch: 6| Step: 7
Training loss: 3.1114695072174072
Validation loss: 2.4653928997696086

Epoch: 6| Step: 8
Training loss: 2.826483964920044
Validation loss: 2.462090443539363

Epoch: 6| Step: 9
Training loss: 2.7801713943481445
Validation loss: 2.4787310733590076

Epoch: 6| Step: 10
Training loss: 3.4224815368652344
Validation loss: 2.4772630148036505

Epoch: 6| Step: 11
Training loss: 3.0911145210266113
Validation loss: 2.4851152153425318

Epoch: 6| Step: 12
Training loss: 2.520490884780884
Validation loss: 2.4742906221779446

Epoch: 6| Step: 13
Training loss: 1.6157633066177368
Validation loss: 2.47768682946441

Epoch: 220| Step: 0
Training loss: 3.266225576400757
Validation loss: 2.4660922634986138

Epoch: 6| Step: 1
Training loss: 2.472268581390381
Validation loss: 2.463196328891221

Epoch: 6| Step: 2
Training loss: 2.2513513565063477
Validation loss: 2.460234421555714

Epoch: 6| Step: 3
Training loss: 2.3096587657928467
Validation loss: 2.4616657444225845

Epoch: 6| Step: 4
Training loss: 3.687532424926758
Validation loss: 2.4594516215785855

Epoch: 6| Step: 5
Training loss: 1.9979525804519653
Validation loss: 2.4588274417384977

Epoch: 6| Step: 6
Training loss: 2.4450621604919434
Validation loss: 2.462962099300918

Epoch: 6| Step: 7
Training loss: 2.7436294555664062
Validation loss: 2.4617919588601715

Epoch: 6| Step: 8
Training loss: 2.9209699630737305
Validation loss: 2.45757124757254

Epoch: 6| Step: 9
Training loss: 2.2359015941619873
Validation loss: 2.4603465833971576

Epoch: 6| Step: 10
Training loss: 3.0163516998291016
Validation loss: 2.4609359336155716

Epoch: 6| Step: 11
Training loss: 2.7824649810791016
Validation loss: 2.460664121053552

Epoch: 6| Step: 12
Training loss: 2.572237730026245
Validation loss: 2.4615994807212584

Epoch: 6| Step: 13
Training loss: 2.100952386856079
Validation loss: 2.466683997902819

Epoch: 221| Step: 0
Training loss: 3.600283145904541
Validation loss: 2.4761691734354985

Epoch: 6| Step: 1
Training loss: 2.1518707275390625
Validation loss: 2.479209694811093

Epoch: 6| Step: 2
Training loss: 2.0302295684814453
Validation loss: 2.494229539748161

Epoch: 6| Step: 3
Training loss: 2.618856430053711
Validation loss: 2.490910865927255

Epoch: 6| Step: 4
Training loss: 2.5333781242370605
Validation loss: 2.4800490166551326

Epoch: 6| Step: 5
Training loss: 2.083204746246338
Validation loss: 2.4722047211021505

Epoch: 6| Step: 6
Training loss: 2.709811210632324
Validation loss: 2.4514419314681843

Epoch: 6| Step: 7
Training loss: 3.2654852867126465
Validation loss: 2.460675339544973

Epoch: 6| Step: 8
Training loss: 2.3152475357055664
Validation loss: 2.4580177824984313

Epoch: 6| Step: 9
Training loss: 2.961850881576538
Validation loss: 2.456504516704108

Epoch: 6| Step: 10
Training loss: 2.9117584228515625
Validation loss: 2.4570042241004204

Epoch: 6| Step: 11
Training loss: 3.2173755168914795
Validation loss: 2.453253810123731

Epoch: 6| Step: 12
Training loss: 2.5099198818206787
Validation loss: 2.4562157943684566

Epoch: 6| Step: 13
Training loss: 1.7476154565811157
Validation loss: 2.4527727045038694

Epoch: 222| Step: 0
Training loss: 2.617488384246826
Validation loss: 2.4606674704500424

Epoch: 6| Step: 1
Training loss: 3.097484827041626
Validation loss: 2.4588037972809165

Epoch: 6| Step: 2
Training loss: 2.5715017318725586
Validation loss: 2.4591927528381348

Epoch: 6| Step: 3
Training loss: 1.9860186576843262
Validation loss: 2.4615036390161

Epoch: 6| Step: 4
Training loss: 2.051492691040039
Validation loss: 2.45380889215777

Epoch: 6| Step: 5
Training loss: 3.101069450378418
Validation loss: 2.466932681299025

Epoch: 6| Step: 6
Training loss: 2.6036338806152344
Validation loss: 2.468331603593724

Epoch: 6| Step: 7
Training loss: 2.7810354232788086
Validation loss: 2.467538720817976

Epoch: 6| Step: 8
Training loss: 3.348069667816162
Validation loss: 2.4699785350471415

Epoch: 6| Step: 9
Training loss: 2.9114418029785156
Validation loss: 2.4737873743939143

Epoch: 6| Step: 10
Training loss: 1.5213226079940796
Validation loss: 2.471965282194076

Epoch: 6| Step: 11
Training loss: 2.4777400493621826
Validation loss: 2.4738234755813435

Epoch: 6| Step: 12
Training loss: 2.649538278579712
Validation loss: 2.4679240616418983

Epoch: 6| Step: 13
Training loss: 3.7715160846710205
Validation loss: 2.4614820377801054

Epoch: 223| Step: 0
Training loss: 1.9891963005065918
Validation loss: 2.463124188043738

Epoch: 6| Step: 1
Training loss: 2.9845848083496094
Validation loss: 2.4681320113520466

Epoch: 6| Step: 2
Training loss: 3.10456919670105
Validation loss: 2.462019871639949

Epoch: 6| Step: 3
Training loss: 2.62764048576355
Validation loss: 2.4514906790948685

Epoch: 6| Step: 4
Training loss: 2.402130126953125
Validation loss: 2.456169879564675

Epoch: 6| Step: 5
Training loss: 2.9370975494384766
Validation loss: 2.453009900226388

Epoch: 6| Step: 6
Training loss: 1.7372111082077026
Validation loss: 2.4503598828469553

Epoch: 6| Step: 7
Training loss: 2.439607620239258
Validation loss: 2.450342342417727

Epoch: 6| Step: 8
Training loss: 2.850311756134033
Validation loss: 2.4538283937720844

Epoch: 6| Step: 9
Training loss: 3.038522243499756
Validation loss: 2.4439603692741803

Epoch: 6| Step: 10
Training loss: 3.4539787769317627
Validation loss: 2.4404235885989283

Epoch: 6| Step: 11
Training loss: 2.195533037185669
Validation loss: 2.4409245393609487

Epoch: 6| Step: 12
Training loss: 2.245053768157959
Validation loss: 2.441277693676692

Epoch: 6| Step: 13
Training loss: 3.241905689239502
Validation loss: 2.4440237245252057

Epoch: 224| Step: 0
Training loss: 2.820659637451172
Validation loss: 2.4391662792492936

Epoch: 6| Step: 1
Training loss: 2.192082405090332
Validation loss: 2.436790043307889

Epoch: 6| Step: 2
Training loss: 2.5071916580200195
Validation loss: 2.434914401782456

Epoch: 6| Step: 3
Training loss: 2.091855764389038
Validation loss: 2.4419526976923787

Epoch: 6| Step: 4
Training loss: 3.0392556190490723
Validation loss: 2.4456902832113285

Epoch: 6| Step: 5
Training loss: 2.7018494606018066
Validation loss: 2.4399095017422914

Epoch: 6| Step: 6
Training loss: 1.9374406337738037
Validation loss: 2.4501953176272813

Epoch: 6| Step: 7
Training loss: 3.764718532562256
Validation loss: 2.4556629760290987

Epoch: 6| Step: 8
Training loss: 2.8954319953918457
Validation loss: 2.4572874217905025

Epoch: 6| Step: 9
Training loss: 2.5320816040039062
Validation loss: 2.458008914865473

Epoch: 6| Step: 10
Training loss: 2.827421188354492
Validation loss: 2.4583483126855667

Epoch: 6| Step: 11
Training loss: 2.265244483947754
Validation loss: 2.462687530825215

Epoch: 6| Step: 12
Training loss: 2.191147804260254
Validation loss: 2.457379646198724

Epoch: 6| Step: 13
Training loss: 3.5766241550445557
Validation loss: 2.453093362110917

Epoch: 225| Step: 0
Training loss: 2.6334497928619385
Validation loss: 2.4496784748569613

Epoch: 6| Step: 1
Training loss: 2.2199957370758057
Validation loss: 2.4519747175196165

Epoch: 6| Step: 2
Training loss: 2.7647435665130615
Validation loss: 2.437039344541488

Epoch: 6| Step: 3
Training loss: 2.3989925384521484
Validation loss: 2.443976734274177

Epoch: 6| Step: 4
Training loss: 3.6219265460968018
Validation loss: 2.447307473869734

Epoch: 6| Step: 5
Training loss: 1.8352630138397217
Validation loss: 2.443129654853575

Epoch: 6| Step: 6
Training loss: 3.389397621154785
Validation loss: 2.4542164751278457

Epoch: 6| Step: 7
Training loss: 2.249089241027832
Validation loss: 2.4451674056309525

Epoch: 6| Step: 8
Training loss: 2.745382308959961
Validation loss: 2.4554679932132846

Epoch: 6| Step: 9
Training loss: 1.7730246782302856
Validation loss: 2.4549644711197063

Epoch: 6| Step: 10
Training loss: 3.083482027053833
Validation loss: 2.4581548706177743

Epoch: 6| Step: 11
Training loss: 3.172877311706543
Validation loss: 2.4520138848212456

Epoch: 6| Step: 12
Training loss: 2.608297348022461
Validation loss: 2.4464661511041785

Epoch: 6| Step: 13
Training loss: 2.175184726715088
Validation loss: 2.4393805175699215

Epoch: 226| Step: 0
Training loss: 3.2018818855285645
Validation loss: 2.44136708013473

Epoch: 6| Step: 1
Training loss: 2.238381862640381
Validation loss: 2.446540883792344

Epoch: 6| Step: 2
Training loss: 2.531989097595215
Validation loss: 2.439763933099726

Epoch: 6| Step: 3
Training loss: 2.733952522277832
Validation loss: 2.4354258019437074

Epoch: 6| Step: 4
Training loss: 2.4477195739746094
Validation loss: 2.439818131026401

Epoch: 6| Step: 5
Training loss: 2.9132189750671387
Validation loss: 2.4483852719747894

Epoch: 6| Step: 6
Training loss: 2.548130512237549
Validation loss: 2.456190827072308

Epoch: 6| Step: 7
Training loss: 2.4133071899414062
Validation loss: 2.459211236687117

Epoch: 6| Step: 8
Training loss: 2.254627227783203
Validation loss: 2.4682598319104923

Epoch: 6| Step: 9
Training loss: 2.7921104431152344
Validation loss: 2.455622193633869

Epoch: 6| Step: 10
Training loss: 2.549877882003784
Validation loss: 2.44946458519146

Epoch: 6| Step: 11
Training loss: 2.477987289428711
Validation loss: 2.448260417548559

Epoch: 6| Step: 12
Training loss: 2.996185779571533
Validation loss: 2.441481828689575

Epoch: 6| Step: 13
Training loss: 2.850553035736084
Validation loss: 2.4384106923175115

Epoch: 227| Step: 0
Training loss: 2.5210940837860107
Validation loss: 2.4334231474066295

Epoch: 6| Step: 1
Training loss: 2.491584062576294
Validation loss: 2.434432642434233

Epoch: 6| Step: 2
Training loss: 2.5815415382385254
Validation loss: 2.4300923142381894

Epoch: 6| Step: 3
Training loss: 3.946810245513916
Validation loss: 2.4336057606563775

Epoch: 6| Step: 4
Training loss: 2.566481113433838
Validation loss: 2.4335309984863445

Epoch: 6| Step: 5
Training loss: 2.5474698543548584
Validation loss: 2.435297881403277

Epoch: 6| Step: 6
Training loss: 2.1422877311706543
Validation loss: 2.452568724591245

Epoch: 6| Step: 7
Training loss: 3.4281649589538574
Validation loss: 2.439538594215147

Epoch: 6| Step: 8
Training loss: 2.853506088256836
Validation loss: 2.4368116009619927

Epoch: 6| Step: 9
Training loss: 2.3756263256073
Validation loss: 2.442370027624151

Epoch: 6| Step: 10
Training loss: 2.33586049079895
Validation loss: 2.433175294629989

Epoch: 6| Step: 11
Training loss: 1.98227858543396
Validation loss: 2.4295988159794963

Epoch: 6| Step: 12
Training loss: 2.53175687789917
Validation loss: 2.428442934507965

Epoch: 6| Step: 13
Training loss: 2.5940606594085693
Validation loss: 2.4252088121188584

Epoch: 228| Step: 0
Training loss: 3.556447982788086
Validation loss: 2.4349158861303843

Epoch: 6| Step: 1
Training loss: 2.2518999576568604
Validation loss: 2.4325487485495945

Epoch: 6| Step: 2
Training loss: 2.7843101024627686
Validation loss: 2.4313018552718626

Epoch: 6| Step: 3
Training loss: 1.977065086364746
Validation loss: 2.436922509183166

Epoch: 6| Step: 4
Training loss: 2.977036952972412
Validation loss: 2.441270492410147

Epoch: 6| Step: 5
Training loss: 3.0585787296295166
Validation loss: 2.4530053843734083

Epoch: 6| Step: 6
Training loss: 2.8529438972473145
Validation loss: 2.4567962487538657

Epoch: 6| Step: 7
Training loss: 2.4263625144958496
Validation loss: 2.460424792382025

Epoch: 6| Step: 8
Training loss: 2.2228281497955322
Validation loss: 2.4569427172342935

Epoch: 6| Step: 9
Training loss: 2.7649617195129395
Validation loss: 2.4774172382970012

Epoch: 6| Step: 10
Training loss: 2.6605706214904785
Validation loss: 2.475649379914807

Epoch: 6| Step: 11
Training loss: 2.6846256256103516
Validation loss: 2.4908930691339637

Epoch: 6| Step: 12
Training loss: 2.169802188873291
Validation loss: 2.4829035548753637

Epoch: 6| Step: 13
Training loss: 2.3060476779937744
Validation loss: 2.481366652314381

Epoch: 229| Step: 0
Training loss: 3.312061309814453
Validation loss: 2.4606213620913926

Epoch: 6| Step: 1
Training loss: 2.424359083175659
Validation loss: 2.459666436718356

Epoch: 6| Step: 2
Training loss: 2.1700241565704346
Validation loss: 2.4442197674064228

Epoch: 6| Step: 3
Training loss: 2.0628738403320312
Validation loss: 2.4303327965480026

Epoch: 6| Step: 4
Training loss: 2.381603956222534
Validation loss: 2.431282271621048

Epoch: 6| Step: 5
Training loss: 3.799203395843506
Validation loss: 2.426457169235394

Epoch: 6| Step: 6
Training loss: 2.5908641815185547
Validation loss: 2.4284885596203547

Epoch: 6| Step: 7
Training loss: 2.6775784492492676
Validation loss: 2.4282921565476285

Epoch: 6| Step: 8
Training loss: 2.776261568069458
Validation loss: 2.4317474390870784

Epoch: 6| Step: 9
Training loss: 2.6444621086120605
Validation loss: 2.420873060021349

Epoch: 6| Step: 10
Training loss: 2.617588996887207
Validation loss: 2.4250585238138833

Epoch: 6| Step: 11
Training loss: 2.372877597808838
Validation loss: 2.42935283466052

Epoch: 6| Step: 12
Training loss: 2.6727004051208496
Validation loss: 2.4327088889255317

Epoch: 6| Step: 13
Training loss: 2.0789928436279297
Validation loss: 2.4329307156224407

Epoch: 230| Step: 0
Training loss: 2.7941389083862305
Validation loss: 2.430415291940012

Epoch: 6| Step: 1
Training loss: 3.277012586593628
Validation loss: 2.435810292920759

Epoch: 6| Step: 2
Training loss: 3.105881690979004
Validation loss: 2.4363951170316307

Epoch: 6| Step: 3
Training loss: 2.264517307281494
Validation loss: 2.4380364776939474

Epoch: 6| Step: 4
Training loss: 3.114206314086914
Validation loss: 2.4370729564338602

Epoch: 6| Step: 5
Training loss: 2.5573980808258057
Validation loss: 2.4385921032198015

Epoch: 6| Step: 6
Training loss: 2.032827854156494
Validation loss: 2.439240253099831

Epoch: 6| Step: 7
Training loss: 2.8439292907714844
Validation loss: 2.4462411429292414

Epoch: 6| Step: 8
Training loss: 1.72169828414917
Validation loss: 2.4398687603653118

Epoch: 6| Step: 9
Training loss: 3.2349467277526855
Validation loss: 2.4455969872013217

Epoch: 6| Step: 10
Training loss: 2.3847856521606445
Validation loss: 2.457070181446691

Epoch: 6| Step: 11
Training loss: 2.6143765449523926
Validation loss: 2.451303123145975

Epoch: 6| Step: 12
Training loss: 2.24415922164917
Validation loss: 2.437716290514956

Epoch: 6| Step: 13
Training loss: 2.477680206298828
Validation loss: 2.448055928753268

Epoch: 231| Step: 0
Training loss: 1.6743117570877075
Validation loss: 2.445981974242836

Epoch: 6| Step: 1
Training loss: 2.314826726913452
Validation loss: 2.4574289347535823

Epoch: 6| Step: 2
Training loss: 2.7187862396240234
Validation loss: 2.464374380726968

Epoch: 6| Step: 3
Training loss: 2.654452085494995
Validation loss: 2.457807315293179

Epoch: 6| Step: 4
Training loss: 2.800373077392578
Validation loss: 2.4570517924524125

Epoch: 6| Step: 5
Training loss: 2.409552574157715
Validation loss: 2.4710561434427896

Epoch: 6| Step: 6
Training loss: 3.32434344291687
Validation loss: 2.458984544200282

Epoch: 6| Step: 7
Training loss: 2.4560632705688477
Validation loss: 2.4548111090096096

Epoch: 6| Step: 8
Training loss: 2.4032392501831055
Validation loss: 2.4426216258797595

Epoch: 6| Step: 9
Training loss: 3.3330202102661133
Validation loss: 2.4327069841405398

Epoch: 6| Step: 10
Training loss: 2.330942153930664
Validation loss: 2.4350180343915055

Epoch: 6| Step: 11
Training loss: 2.5524449348449707
Validation loss: 2.438729234921035

Epoch: 6| Step: 12
Training loss: 2.8641815185546875
Validation loss: 2.430934839351203

Epoch: 6| Step: 13
Training loss: 3.1234681606292725
Validation loss: 2.43471279451924

Epoch: 232| Step: 0
Training loss: 2.952314853668213
Validation loss: 2.4390274414452175

Epoch: 6| Step: 1
Training loss: 2.4312305450439453
Validation loss: 2.437914043344477

Epoch: 6| Step: 2
Training loss: 3.435490131378174
Validation loss: 2.4359263271413822

Epoch: 6| Step: 3
Training loss: 3.071847438812256
Validation loss: 2.4376820697579333

Epoch: 6| Step: 4
Training loss: 2.229903221130371
Validation loss: 2.4438772586084183

Epoch: 6| Step: 5
Training loss: 2.5506253242492676
Validation loss: 2.434484963775963

Epoch: 6| Step: 6
Training loss: 2.6835947036743164
Validation loss: 2.435964749705407

Epoch: 6| Step: 7
Training loss: 2.60709285736084
Validation loss: 2.433867149455573

Epoch: 6| Step: 8
Training loss: 2.393040418624878
Validation loss: 2.4385331215397006

Epoch: 6| Step: 9
Training loss: 2.7100648880004883
Validation loss: 2.4494771034486833

Epoch: 6| Step: 10
Training loss: 2.4301671981811523
Validation loss: 2.444221294054421

Epoch: 6| Step: 11
Training loss: 2.638432025909424
Validation loss: 2.446997719426309

Epoch: 6| Step: 12
Training loss: 2.1855783462524414
Validation loss: 2.4619076713438957

Epoch: 6| Step: 13
Training loss: 2.291249990463257
Validation loss: 2.463374614715576

Epoch: 233| Step: 0
Training loss: 3.8156232833862305
Validation loss: 2.4555034983542656

Epoch: 6| Step: 1
Training loss: 2.4458489418029785
Validation loss: 2.450767655526438

Epoch: 6| Step: 2
Training loss: 2.0105385780334473
Validation loss: 2.445402640168385

Epoch: 6| Step: 3
Training loss: 2.2183055877685547
Validation loss: 2.439798524302821

Epoch: 6| Step: 4
Training loss: 3.116236686706543
Validation loss: 2.4352220104586695

Epoch: 6| Step: 5
Training loss: 3.21733021736145
Validation loss: 2.4371997515360513

Epoch: 6| Step: 6
Training loss: 1.5378665924072266
Validation loss: 2.43470359617664

Epoch: 6| Step: 7
Training loss: 2.0830321311950684
Validation loss: 2.4340121848608858

Epoch: 6| Step: 8
Training loss: 2.1626334190368652
Validation loss: 2.442361157427552

Epoch: 6| Step: 9
Training loss: 3.380544662475586
Validation loss: 2.43190445182144

Epoch: 6| Step: 10
Training loss: 2.3450074195861816
Validation loss: 2.4339107313463764

Epoch: 6| Step: 11
Training loss: 3.468325138092041
Validation loss: 2.4419491137227705

Epoch: 6| Step: 12
Training loss: 2.1408886909484863
Validation loss: 2.4425475699927217

Epoch: 6| Step: 13
Training loss: 2.929227590560913
Validation loss: 2.4428642898477535

Epoch: 234| Step: 0
Training loss: 2.6259377002716064
Validation loss: 2.4306769396669123

Epoch: 6| Step: 1
Training loss: 2.477506637573242
Validation loss: 2.434498953562911

Epoch: 6| Step: 2
Training loss: 2.9837260246276855
Validation loss: 2.427840917341171

Epoch: 6| Step: 3
Training loss: 2.549147605895996
Validation loss: 2.4280095920767835

Epoch: 6| Step: 4
Training loss: 2.5950522422790527
Validation loss: 2.4334893072805097

Epoch: 6| Step: 5
Training loss: 2.3578810691833496
Validation loss: 2.4320863369972474

Epoch: 6| Step: 6
Training loss: 2.496523380279541
Validation loss: 2.432234864081106

Epoch: 6| Step: 7
Training loss: 2.2444496154785156
Validation loss: 2.4305461337489467

Epoch: 6| Step: 8
Training loss: 2.8703489303588867
Validation loss: 2.435462433804748

Epoch: 6| Step: 9
Training loss: 2.7333004474639893
Validation loss: 2.4361436008125223

Epoch: 6| Step: 10
Training loss: 2.298252582550049
Validation loss: 2.4333813575006302

Epoch: 6| Step: 11
Training loss: 2.44563364982605
Validation loss: 2.437353123900711

Epoch: 6| Step: 12
Training loss: 3.229712963104248
Validation loss: 2.4343664056511334

Epoch: 6| Step: 13
Training loss: 2.7605912685394287
Validation loss: 2.4314074875206075

Epoch: 235| Step: 0
Training loss: 2.3243463039398193
Validation loss: 2.43168153044998

Epoch: 6| Step: 1
Training loss: 2.2903363704681396
Validation loss: 2.439181025310229

Epoch: 6| Step: 2
Training loss: 2.5968117713928223
Validation loss: 2.428490120877502

Epoch: 6| Step: 3
Training loss: 3.2481346130371094
Validation loss: 2.435145778040732

Epoch: 6| Step: 4
Training loss: 1.8464443683624268
Validation loss: 2.4376156458290676

Epoch: 6| Step: 5
Training loss: 3.551304578781128
Validation loss: 2.434127712762484

Epoch: 6| Step: 6
Training loss: 2.7175028324127197
Validation loss: 2.4398299647915747

Epoch: 6| Step: 7
Training loss: 2.621479034423828
Validation loss: 2.4429943484644734

Epoch: 6| Step: 8
Training loss: 2.505718469619751
Validation loss: 2.437141985021612

Epoch: 6| Step: 9
Training loss: 2.0952112674713135
Validation loss: 2.4378271564360587

Epoch: 6| Step: 10
Training loss: 3.054805040359497
Validation loss: 2.438820703055269

Epoch: 6| Step: 11
Training loss: 3.0855722427368164
Validation loss: 2.4410356039642007

Epoch: 6| Step: 12
Training loss: 1.9784975051879883
Validation loss: 2.437911525849373

Epoch: 6| Step: 13
Training loss: 2.7476816177368164
Validation loss: 2.431592572119928

Epoch: 236| Step: 0
Training loss: 2.6532883644104004
Validation loss: 2.4348832791851414

Epoch: 6| Step: 1
Training loss: 2.240509033203125
Validation loss: 2.4387255432785198

Epoch: 6| Step: 2
Training loss: 2.647714138031006
Validation loss: 2.4301956340830815

Epoch: 6| Step: 3
Training loss: 2.8119187355041504
Validation loss: 2.424817100647957

Epoch: 6| Step: 4
Training loss: 2.290418863296509
Validation loss: 2.4293447002287833

Epoch: 6| Step: 5
Training loss: 2.8340487480163574
Validation loss: 2.4253626459388324

Epoch: 6| Step: 6
Training loss: 2.4539971351623535
Validation loss: 2.428370452696277

Epoch: 6| Step: 7
Training loss: 3.216747283935547
Validation loss: 2.4258098243385233

Epoch: 6| Step: 8
Training loss: 2.229121685028076
Validation loss: 2.427801809003276

Epoch: 6| Step: 9
Training loss: 2.669675350189209
Validation loss: 2.4221510630781933

Epoch: 6| Step: 10
Training loss: 2.8182003498077393
Validation loss: 2.4232590916336223

Epoch: 6| Step: 11
Training loss: 2.573906183242798
Validation loss: 2.419462473161759

Epoch: 6| Step: 12
Training loss: 2.5800886154174805
Validation loss: 2.4207931308336157

Epoch: 6| Step: 13
Training loss: 2.725576162338257
Validation loss: 2.421614485402261

Epoch: 237| Step: 0
Training loss: 3.2245278358459473
Validation loss: 2.428961512862995

Epoch: 6| Step: 1
Training loss: 2.3561689853668213
Validation loss: 2.4325484562945623

Epoch: 6| Step: 2
Training loss: 2.88893985748291
Validation loss: 2.436415841502528

Epoch: 6| Step: 3
Training loss: 1.6680541038513184
Validation loss: 2.4361204255011772

Epoch: 6| Step: 4
Training loss: 2.0861997604370117
Validation loss: 2.430939310340471

Epoch: 6| Step: 5
Training loss: 2.72381329536438
Validation loss: 2.435727068172988

Epoch: 6| Step: 6
Training loss: 2.7130463123321533
Validation loss: 2.445027600052536

Epoch: 6| Step: 7
Training loss: 2.9720282554626465
Validation loss: 2.449427640566262

Epoch: 6| Step: 8
Training loss: 2.7644267082214355
Validation loss: 2.444390622518396

Epoch: 6| Step: 9
Training loss: 2.3004777431488037
Validation loss: 2.44697182537407

Epoch: 6| Step: 10
Training loss: 2.79007625579834
Validation loss: 2.442238279568252

Epoch: 6| Step: 11
Training loss: 2.0631933212280273
Validation loss: 2.44457830408568

Epoch: 6| Step: 12
Training loss: 3.400918960571289
Validation loss: 2.4472310120059597

Epoch: 6| Step: 13
Training loss: 2.547058343887329
Validation loss: 2.454565432763869

Epoch: 238| Step: 0
Training loss: 2.8375046253204346
Validation loss: 2.452576991050474

Epoch: 6| Step: 1
Training loss: 2.3699541091918945
Validation loss: 2.439968055294406

Epoch: 6| Step: 2
Training loss: 1.8229243755340576
Validation loss: 2.4440037768374205

Epoch: 6| Step: 3
Training loss: 3.6722583770751953
Validation loss: 2.4377123463538384

Epoch: 6| Step: 4
Training loss: 2.927412748336792
Validation loss: 2.4331768456325737

Epoch: 6| Step: 5
Training loss: 2.2621021270751953
Validation loss: 2.433864249978014

Epoch: 6| Step: 6
Training loss: 2.8112916946411133
Validation loss: 2.4243583986836095

Epoch: 6| Step: 7
Training loss: 2.6826889514923096
Validation loss: 2.422763668080812

Epoch: 6| Step: 8
Training loss: 2.7183620929718018
Validation loss: 2.421585662390596

Epoch: 6| Step: 9
Training loss: 2.7904398441314697
Validation loss: 2.4244431859703472

Epoch: 6| Step: 10
Training loss: 2.0356225967407227
Validation loss: 2.4162782366557787

Epoch: 6| Step: 11
Training loss: 2.56514835357666
Validation loss: 2.42551104996794

Epoch: 6| Step: 12
Training loss: 2.4936890602111816
Validation loss: 2.421831387345509

Epoch: 6| Step: 13
Training loss: 2.6910324096679688
Validation loss: 2.4200320782199984

Epoch: 239| Step: 0
Training loss: 2.3385894298553467
Validation loss: 2.4313843788639193

Epoch: 6| Step: 1
Training loss: 2.933053970336914
Validation loss: 2.4443694904286373

Epoch: 6| Step: 2
Training loss: 2.5542383193969727
Validation loss: 2.430103971112159

Epoch: 6| Step: 3
Training loss: 2.651240348815918
Validation loss: 2.4388926157387356

Epoch: 6| Step: 4
Training loss: 3.380995750427246
Validation loss: 2.436308083995696

Epoch: 6| Step: 5
Training loss: 1.8916428089141846
Validation loss: 2.4276787593800533

Epoch: 6| Step: 6
Training loss: 2.9309470653533936
Validation loss: 2.431201934814453

Epoch: 6| Step: 7
Training loss: 2.422907829284668
Validation loss: 2.42646110955105

Epoch: 6| Step: 8
Training loss: 2.715508460998535
Validation loss: 2.4359403630738616

Epoch: 6| Step: 9
Training loss: 2.5280117988586426
Validation loss: 2.4382666721138904

Epoch: 6| Step: 10
Training loss: 2.923610210418701
Validation loss: 2.4484905581320486

Epoch: 6| Step: 11
Training loss: 2.1801202297210693
Validation loss: 2.445348556323718

Epoch: 6| Step: 12
Training loss: 2.5093142986297607
Validation loss: 2.444942343619562

Epoch: 6| Step: 13
Training loss: 2.7060041427612305
Validation loss: 2.4371939295081684

Epoch: 240| Step: 0
Training loss: 2.3792262077331543
Validation loss: 2.425489678177782

Epoch: 6| Step: 1
Training loss: 3.0179433822631836
Validation loss: 2.431700634699996

Epoch: 6| Step: 2
Training loss: 1.9573644399642944
Validation loss: 2.4178058101284887

Epoch: 6| Step: 3
Training loss: 2.640378475189209
Validation loss: 2.4322860112754245

Epoch: 6| Step: 4
Training loss: 2.90541672706604
Validation loss: 2.425388023417483

Epoch: 6| Step: 5
Training loss: 2.8318450450897217
Validation loss: 2.432631043977635

Epoch: 6| Step: 6
Training loss: 2.539592742919922
Validation loss: 2.422148410991956

Epoch: 6| Step: 7
Training loss: 2.9939124584198
Validation loss: 2.430289001875026

Epoch: 6| Step: 8
Training loss: 3.488306999206543
Validation loss: 2.4310527168294436

Epoch: 6| Step: 9
Training loss: 2.4376344680786133
Validation loss: 2.4150172613000356

Epoch: 6| Step: 10
Training loss: 2.040843963623047
Validation loss: 2.416428014796267

Epoch: 6| Step: 11
Training loss: 2.243154525756836
Validation loss: 2.4148686188523487

Epoch: 6| Step: 12
Training loss: 3.003239631652832
Validation loss: 2.4214588890793505

Epoch: 6| Step: 13
Training loss: 1.571441650390625
Validation loss: 2.420639948178363

Epoch: 241| Step: 0
Training loss: 2.955498456954956
Validation loss: 2.426197516020908

Epoch: 6| Step: 1
Training loss: 2.5131101608276367
Validation loss: 2.4349714402229554

Epoch: 6| Step: 2
Training loss: 2.156857967376709
Validation loss: 2.4290896641310824

Epoch: 6| Step: 3
Training loss: 2.3292598724365234
Validation loss: 2.438721240207713

Epoch: 6| Step: 4
Training loss: 2.612665891647339
Validation loss: 2.44938047470585

Epoch: 6| Step: 5
Training loss: 3.1225171089172363
Validation loss: 2.452025228931058

Epoch: 6| Step: 6
Training loss: 2.3228743076324463
Validation loss: 2.4604180602617163

Epoch: 6| Step: 7
Training loss: 2.5168704986572266
Validation loss: 2.462150084075107

Epoch: 6| Step: 8
Training loss: 3.0231454372406006
Validation loss: 2.4735412495110625

Epoch: 6| Step: 9
Training loss: 3.050039768218994
Validation loss: 2.4700198558069046

Epoch: 6| Step: 10
Training loss: 2.707012414932251
Validation loss: 2.4645387331644693

Epoch: 6| Step: 11
Training loss: 2.5837154388427734
Validation loss: 2.4556899250194593

Epoch: 6| Step: 12
Training loss: 2.347928524017334
Validation loss: 2.453707753971059

Epoch: 6| Step: 13
Training loss: 1.9493039846420288
Validation loss: 2.4482945267872145

Epoch: 242| Step: 0
Training loss: 2.4056005477905273
Validation loss: 2.4429654331617456

Epoch: 6| Step: 1
Training loss: 3.5401320457458496
Validation loss: 2.426800507371144

Epoch: 6| Step: 2
Training loss: 2.128819227218628
Validation loss: 2.420972378023209

Epoch: 6| Step: 3
Training loss: 2.6361398696899414
Validation loss: 2.4214464079949165

Epoch: 6| Step: 4
Training loss: 2.8311634063720703
Validation loss: 2.421395722255912

Epoch: 6| Step: 5
Training loss: 3.1397457122802734
Validation loss: 2.417101998482981

Epoch: 6| Step: 6
Training loss: 2.430525302886963
Validation loss: 2.4205129531122025

Epoch: 6| Step: 7
Training loss: 2.2232022285461426
Validation loss: 2.4208083229680217

Epoch: 6| Step: 8
Training loss: 2.3139560222625732
Validation loss: 2.4199707200450282

Epoch: 6| Step: 9
Training loss: 2.019803524017334
Validation loss: 2.4068569367931736

Epoch: 6| Step: 10
Training loss: 2.7482457160949707
Validation loss: 2.411726943908199

Epoch: 6| Step: 11
Training loss: 2.6704277992248535
Validation loss: 2.414907773335775

Epoch: 6| Step: 12
Training loss: 2.579254150390625
Validation loss: 2.4075173280572377

Epoch: 6| Step: 13
Training loss: 3.2548577785491943
Validation loss: 2.41323257518071

Epoch: 243| Step: 0
Training loss: 2.4985411167144775
Validation loss: 2.4169177829578357

Epoch: 6| Step: 1
Training loss: 2.4523935317993164
Validation loss: 2.412975070297077

Epoch: 6| Step: 2
Training loss: 2.61342191696167
Validation loss: 2.421177476964971

Epoch: 6| Step: 3
Training loss: 2.604306697845459
Validation loss: 2.4158677926627536

Epoch: 6| Step: 4
Training loss: 2.4857637882232666
Validation loss: 2.4171194914848573

Epoch: 6| Step: 5
Training loss: 2.937589406967163
Validation loss: 2.426184661926762

Epoch: 6| Step: 6
Training loss: 2.1411359310150146
Validation loss: 2.4222667755619174

Epoch: 6| Step: 7
Training loss: 2.828935146331787
Validation loss: 2.427150616081812

Epoch: 6| Step: 8
Training loss: 3.044959545135498
Validation loss: 2.4249709370315715

Epoch: 6| Step: 9
Training loss: 2.168354034423828
Validation loss: 2.4325647123398317

Epoch: 6| Step: 10
Training loss: 2.6705875396728516
Validation loss: 2.4424553814754693

Epoch: 6| Step: 11
Training loss: 2.432480812072754
Validation loss: 2.4314414826772546

Epoch: 6| Step: 12
Training loss: 3.296706199645996
Validation loss: 2.4447964288855113

Epoch: 6| Step: 13
Training loss: 2.0142338275909424
Validation loss: 2.4509680245512273

Epoch: 244| Step: 0
Training loss: 2.7667324542999268
Validation loss: 2.4635228392898396

Epoch: 6| Step: 1
Training loss: 2.4680352210998535
Validation loss: 2.483311730046426

Epoch: 6| Step: 2
Training loss: 3.637643575668335
Validation loss: 2.4936509978386665

Epoch: 6| Step: 3
Training loss: 2.4064626693725586
Validation loss: 2.4922601305028445

Epoch: 6| Step: 4
Training loss: 3.434448719024658
Validation loss: 2.4652586778004966

Epoch: 6| Step: 5
Training loss: 2.290292263031006
Validation loss: 2.4400505942683064

Epoch: 6| Step: 6
Training loss: 2.2050940990448
Validation loss: 2.4338415258674213

Epoch: 6| Step: 7
Training loss: 2.718356132507324
Validation loss: 2.420755322261523

Epoch: 6| Step: 8
Training loss: 2.4572815895080566
Validation loss: 2.4162805554687337

Epoch: 6| Step: 9
Training loss: 2.1678712368011475
Validation loss: 2.415562891191052

Epoch: 6| Step: 10
Training loss: 2.6448609828948975
Validation loss: 2.41371565224022

Epoch: 6| Step: 11
Training loss: 2.695937156677246
Validation loss: 2.4075884152484197

Epoch: 6| Step: 12
Training loss: 2.3365721702575684
Validation loss: 2.415658197095317

Epoch: 6| Step: 13
Training loss: 2.2736892700195312
Validation loss: 2.419595205655662

Epoch: 245| Step: 0
Training loss: 3.0125832557678223
Validation loss: 2.422477299167264

Epoch: 6| Step: 1
Training loss: 2.0205602645874023
Validation loss: 2.4299078705490276

Epoch: 6| Step: 2
Training loss: 2.4527883529663086
Validation loss: 2.4217058945727605

Epoch: 6| Step: 3
Training loss: 2.9148266315460205
Validation loss: 2.426630761033745

Epoch: 6| Step: 4
Training loss: 1.8301315307617188
Validation loss: 2.4230837078504663

Epoch: 6| Step: 5
Training loss: 3.5065419673919678
Validation loss: 2.421802343860749

Epoch: 6| Step: 6
Training loss: 2.826369047164917
Validation loss: 2.4138696296240694

Epoch: 6| Step: 7
Training loss: 3.0519981384277344
Validation loss: 2.4062234586285007

Epoch: 6| Step: 8
Training loss: 3.0562565326690674
Validation loss: 2.4136714166210544

Epoch: 6| Step: 9
Training loss: 2.6231207847595215
Validation loss: 2.4151916452633437

Epoch: 6| Step: 10
Training loss: 2.8188321590423584
Validation loss: 2.4159533695508073

Epoch: 6| Step: 11
Training loss: 1.9077794551849365
Validation loss: 2.412099261437693

Epoch: 6| Step: 12
Training loss: 2.000936508178711
Validation loss: 2.4147552931180565

Epoch: 6| Step: 13
Training loss: 2.5179874897003174
Validation loss: 2.427184045955699

Epoch: 246| Step: 0
Training loss: 2.724274158477783
Validation loss: 2.426584397592852

Epoch: 6| Step: 1
Training loss: 3.0107154846191406
Validation loss: 2.429599013379825

Epoch: 6| Step: 2
Training loss: 2.121610403060913
Validation loss: 2.4380014122173352

Epoch: 6| Step: 3
Training loss: 2.678891181945801
Validation loss: 2.4512483586547194

Epoch: 6| Step: 4
Training loss: 2.2655200958251953
Validation loss: 2.453486357965777

Epoch: 6| Step: 5
Training loss: 3.30460262298584
Validation loss: 2.462645382009527

Epoch: 6| Step: 6
Training loss: 2.5067925453186035
Validation loss: 2.45871913561257

Epoch: 6| Step: 7
Training loss: 2.573831558227539
Validation loss: 2.468882337693245

Epoch: 6| Step: 8
Training loss: 2.627988338470459
Validation loss: 2.4671793163463636

Epoch: 6| Step: 9
Training loss: 2.5125951766967773
Validation loss: 2.4647487389144076

Epoch: 6| Step: 10
Training loss: 3.1054272651672363
Validation loss: 2.4584947529659478

Epoch: 6| Step: 11
Training loss: 2.525660514831543
Validation loss: 2.4575016421656453

Epoch: 6| Step: 12
Training loss: 2.131308078765869
Validation loss: 2.440085344417121

Epoch: 6| Step: 13
Training loss: 2.1895575523376465
Validation loss: 2.4214053282173733

Epoch: 247| Step: 0
Training loss: 2.6576199531555176
Validation loss: 2.414284593315535

Epoch: 6| Step: 1
Training loss: 2.622413396835327
Validation loss: 2.4090536666172806

Epoch: 6| Step: 2
Training loss: 1.9465972185134888
Validation loss: 2.402876623215214

Epoch: 6| Step: 3
Training loss: 2.4489357471466064
Validation loss: 2.407716869026102

Epoch: 6| Step: 4
Training loss: 2.7778513431549072
Validation loss: 2.4133866704920286

Epoch: 6| Step: 5
Training loss: 2.4610981941223145
Validation loss: 2.41257417842906

Epoch: 6| Step: 6
Training loss: 3.127340078353882
Validation loss: 2.4153417835953417

Epoch: 6| Step: 7
Training loss: 2.8038957118988037
Validation loss: 2.4203376052200154

Epoch: 6| Step: 8
Training loss: 2.764596939086914
Validation loss: 2.425836278546241

Epoch: 6| Step: 9
Training loss: 2.581495761871338
Validation loss: 2.4415381211106495

Epoch: 6| Step: 10
Training loss: 2.5356884002685547
Validation loss: 2.444852844361336

Epoch: 6| Step: 11
Training loss: 2.946678638458252
Validation loss: 2.457946205651888

Epoch: 6| Step: 12
Training loss: 2.4601988792419434
Validation loss: 2.4469385454731603

Epoch: 6| Step: 13
Training loss: 2.137833595275879
Validation loss: 2.4422409162726453

Epoch: 248| Step: 0
Training loss: 3.028055191040039
Validation loss: 2.4404523731559835

Epoch: 6| Step: 1
Training loss: 2.467071771621704
Validation loss: 2.4190176328023276

Epoch: 6| Step: 2
Training loss: 2.289433240890503
Validation loss: 2.420691322254878

Epoch: 6| Step: 3
Training loss: 2.5328402519226074
Validation loss: 2.4182961551092004

Epoch: 6| Step: 4
Training loss: 2.751115322113037
Validation loss: 2.413632208301175

Epoch: 6| Step: 5
Training loss: 2.976503372192383
Validation loss: 2.4142610821672665

Epoch: 6| Step: 6
Training loss: 2.125870704650879
Validation loss: 2.4069001136287564

Epoch: 6| Step: 7
Training loss: 2.0680766105651855
Validation loss: 2.4129434183079708

Epoch: 6| Step: 8
Training loss: 2.1136398315429688
Validation loss: 2.403846945813907

Epoch: 6| Step: 9
Training loss: 2.6803138256073
Validation loss: 2.4094679509439776

Epoch: 6| Step: 10
Training loss: 3.3187737464904785
Validation loss: 2.416157909618911

Epoch: 6| Step: 11
Training loss: 2.8903732299804688
Validation loss: 2.4209280014038086

Epoch: 6| Step: 12
Training loss: 2.2506730556488037
Validation loss: 2.41492893362558

Epoch: 6| Step: 13
Training loss: 3.120922565460205
Validation loss: 2.4242745958348757

Epoch: 249| Step: 0
Training loss: 2.657594680786133
Validation loss: 2.4220927299991732

Epoch: 6| Step: 1
Training loss: 3.083354949951172
Validation loss: 2.4207381868875153

Epoch: 6| Step: 2
Training loss: 2.964118003845215
Validation loss: 2.4175993140025804

Epoch: 6| Step: 3
Training loss: 2.483243465423584
Validation loss: 2.4129151323790192

Epoch: 6| Step: 4
Training loss: 1.846433162689209
Validation loss: 2.4098705322511735

Epoch: 6| Step: 5
Training loss: 3.321739435195923
Validation loss: 2.4074632429307505

Epoch: 6| Step: 6
Training loss: 2.5255205631256104
Validation loss: 2.410830477232574

Epoch: 6| Step: 7
Training loss: 2.192943572998047
Validation loss: 2.4062214846252115

Epoch: 6| Step: 8
Training loss: 3.062849760055542
Validation loss: 2.409264479914019

Epoch: 6| Step: 9
Training loss: 2.511399745941162
Validation loss: 2.4146717004878546

Epoch: 6| Step: 10
Training loss: 2.184910774230957
Validation loss: 2.43227723849717

Epoch: 6| Step: 11
Training loss: 2.311112880706787
Validation loss: 2.441589222159437

Epoch: 6| Step: 12
Training loss: 2.796505928039551
Validation loss: 2.4361021518707275

Epoch: 6| Step: 13
Training loss: 2.2013769149780273
Validation loss: 2.423001491895286

Epoch: 250| Step: 0
Training loss: 2.859133243560791
Validation loss: 2.4323914384329193

Epoch: 6| Step: 1
Training loss: 2.7732455730438232
Validation loss: 2.435153989381688

Epoch: 6| Step: 2
Training loss: 2.611609935760498
Validation loss: 2.432545515798753

Epoch: 6| Step: 3
Training loss: 2.7446727752685547
Validation loss: 2.4200647979654293

Epoch: 6| Step: 4
Training loss: 2.7033517360687256
Validation loss: 2.410257649678056

Epoch: 6| Step: 5
Training loss: 1.9174396991729736
Validation loss: 2.401368228338098

Epoch: 6| Step: 6
Training loss: 2.1519711017608643
Validation loss: 2.4111319793167936

Epoch: 6| Step: 7
Training loss: 2.4931066036224365
Validation loss: 2.411284803062357

Epoch: 6| Step: 8
Training loss: 2.655073404312134
Validation loss: 2.4206647514015116

Epoch: 6| Step: 9
Training loss: 3.062769889831543
Validation loss: 2.4090732964136268

Epoch: 6| Step: 10
Training loss: 2.639914035797119
Validation loss: 2.4067288111614924

Epoch: 6| Step: 11
Training loss: 2.6210451126098633
Validation loss: 2.4164876220046834

Epoch: 6| Step: 12
Training loss: 2.631621837615967
Validation loss: 2.40463085328379

Epoch: 6| Step: 13
Training loss: 2.628413200378418
Validation loss: 2.41027513370719

Epoch: 251| Step: 0
Training loss: 2.769322395324707
Validation loss: 2.4176888055698846

Epoch: 6| Step: 1
Training loss: 1.907569408416748
Validation loss: 2.416691803163098

Epoch: 6| Step: 2
Training loss: 3.1265130043029785
Validation loss: 2.4284432857267317

Epoch: 6| Step: 3
Training loss: 2.337594509124756
Validation loss: 2.422300249017695

Epoch: 6| Step: 4
Training loss: 2.6635727882385254
Validation loss: 2.4284042389162126

Epoch: 6| Step: 5
Training loss: 2.5550765991210938
Validation loss: 2.438506349440544

Epoch: 6| Step: 6
Training loss: 2.550079107284546
Validation loss: 2.4326478332601567

Epoch: 6| Step: 7
Training loss: 3.363377332687378
Validation loss: 2.4329743205860095

Epoch: 6| Step: 8
Training loss: 2.812730312347412
Validation loss: 2.435519338935934

Epoch: 6| Step: 9
Training loss: 2.4237170219421387
Validation loss: 2.4315821406661824

Epoch: 6| Step: 10
Training loss: 2.61326265335083
Validation loss: 2.4314880037820465

Epoch: 6| Step: 11
Training loss: 2.1956582069396973
Validation loss: 2.421564463646181

Epoch: 6| Step: 12
Training loss: 2.592946767807007
Validation loss: 2.4282203951189594

Epoch: 6| Step: 13
Training loss: 2.242231607437134
Validation loss: 2.432706807249336

Epoch: 252| Step: 0
Training loss: 2.148723602294922
Validation loss: 2.4314605177089734

Epoch: 6| Step: 1
Training loss: 2.615776777267456
Validation loss: 2.423859232215471

Epoch: 6| Step: 2
Training loss: 1.737793207168579
Validation loss: 2.4177828399083947

Epoch: 6| Step: 3
Training loss: 3.0211145877838135
Validation loss: 2.4245338952669533

Epoch: 6| Step: 4
Training loss: 2.4224612712860107
Validation loss: 2.4287755925168275

Epoch: 6| Step: 5
Training loss: 3.0046427249908447
Validation loss: 2.424912414243144

Epoch: 6| Step: 6
Training loss: 3.4147276878356934
Validation loss: 2.42442040417784

Epoch: 6| Step: 7
Training loss: 2.356764793395996
Validation loss: 2.425448743245935

Epoch: 6| Step: 8
Training loss: 2.841702938079834
Validation loss: 2.410594081365934

Epoch: 6| Step: 9
Training loss: 2.5957441329956055
Validation loss: 2.4159133690659718

Epoch: 6| Step: 10
Training loss: 2.575122356414795
Validation loss: 2.4076058249319754

Epoch: 6| Step: 11
Training loss: 2.1550331115722656
Validation loss: 2.4117786345943326

Epoch: 6| Step: 12
Training loss: 3.1348230838775635
Validation loss: 2.41053629690601

Epoch: 6| Step: 13
Training loss: 2.056328535079956
Validation loss: 2.41662190293753

Epoch: 253| Step: 0
Training loss: 2.1655995845794678
Validation loss: 2.409251559165216

Epoch: 6| Step: 1
Training loss: 2.839620590209961
Validation loss: 2.4135107276260213

Epoch: 6| Step: 2
Training loss: 2.634420871734619
Validation loss: 2.4097031470268004

Epoch: 6| Step: 3
Training loss: 3.2687087059020996
Validation loss: 2.4174456083646385

Epoch: 6| Step: 4
Training loss: 3.0069985389709473
Validation loss: 2.414543072382609

Epoch: 6| Step: 5
Training loss: 2.3877017498016357
Validation loss: 2.4040556159070743

Epoch: 6| Step: 6
Training loss: 2.221846103668213
Validation loss: 2.4080253031946

Epoch: 6| Step: 7
Training loss: 2.4369277954101562
Validation loss: 2.4170577423546904

Epoch: 6| Step: 8
Training loss: 2.4321131706237793
Validation loss: 2.4248659431293444

Epoch: 6| Step: 9
Training loss: 2.559119462966919
Validation loss: 2.417714959831648

Epoch: 6| Step: 10
Training loss: 2.245626211166382
Validation loss: 2.417207730713711

Epoch: 6| Step: 11
Training loss: 2.4438209533691406
Validation loss: 2.4098786846283944

Epoch: 6| Step: 12
Training loss: 2.6454505920410156
Validation loss: 2.4232374339975338

Epoch: 6| Step: 13
Training loss: 3.097198724746704
Validation loss: 2.423324061978248

Epoch: 254| Step: 0
Training loss: 2.3397603034973145
Validation loss: 2.4234085621372348

Epoch: 6| Step: 1
Training loss: 1.827038288116455
Validation loss: 2.4312230438314457

Epoch: 6| Step: 2
Training loss: 1.9333078861236572
Validation loss: 2.422339831629107

Epoch: 6| Step: 3
Training loss: 3.0133156776428223
Validation loss: 2.4240823727782055

Epoch: 6| Step: 4
Training loss: 2.6473560333251953
Validation loss: 2.4225105777863534

Epoch: 6| Step: 5
Training loss: 2.358905792236328
Validation loss: 2.415624531366492

Epoch: 6| Step: 6
Training loss: 2.20770001411438
Validation loss: 2.42494479046073

Epoch: 6| Step: 7
Training loss: 3.0750951766967773
Validation loss: 2.4220351301213747

Epoch: 6| Step: 8
Training loss: 2.4514715671539307
Validation loss: 2.4336374959638043

Epoch: 6| Step: 9
Training loss: 2.4708657264709473
Validation loss: 2.449038403008574

Epoch: 6| Step: 10
Training loss: 3.41265869140625
Validation loss: 2.4495090617928454

Epoch: 6| Step: 11
Training loss: 2.361544609069824
Validation loss: 2.4269821028555594

Epoch: 6| Step: 12
Training loss: 3.0387253761291504
Validation loss: 2.4274910060308312

Epoch: 6| Step: 13
Training loss: 3.5239920616149902
Validation loss: 2.414032572059221

Epoch: 255| Step: 0
Training loss: 2.451401710510254
Validation loss: 2.411216264129967

Epoch: 6| Step: 1
Training loss: 3.1570873260498047
Validation loss: 2.4094469137089227

Epoch: 6| Step: 2
Training loss: 3.3726491928100586
Validation loss: 2.4050803569055375

Epoch: 6| Step: 3
Training loss: 1.9680832624435425
Validation loss: 2.406842703460365

Epoch: 6| Step: 4
Training loss: 2.9323320388793945
Validation loss: 2.404503322416736

Epoch: 6| Step: 5
Training loss: 2.640831470489502
Validation loss: 2.4023406133856824

Epoch: 6| Step: 6
Training loss: 1.7063230276107788
Validation loss: 2.399550405881738

Epoch: 6| Step: 7
Training loss: 2.8991310596466064
Validation loss: 2.4022386714976323

Epoch: 6| Step: 8
Training loss: 2.3109326362609863
Validation loss: 2.402978007511426

Epoch: 6| Step: 9
Training loss: 2.3935530185699463
Validation loss: 2.4049058216874317

Epoch: 6| Step: 10
Training loss: 2.51871919631958
Validation loss: 2.4116383649969615

Epoch: 6| Step: 11
Training loss: 2.459078311920166
Validation loss: 2.4073898433357157

Epoch: 6| Step: 12
Training loss: 2.8256211280822754
Validation loss: 2.404392485977501

Epoch: 6| Step: 13
Training loss: 2.739041566848755
Validation loss: 2.4074147619226927

Epoch: 256| Step: 0
Training loss: 2.944739818572998
Validation loss: 2.407217712812526

Epoch: 6| Step: 1
Training loss: 1.8489130735397339
Validation loss: 2.3985073233163483

Epoch: 6| Step: 2
Training loss: 2.6827175617218018
Validation loss: 2.4077228320542203

Epoch: 6| Step: 3
Training loss: 2.777831792831421
Validation loss: 2.4001804333861156

Epoch: 6| Step: 4
Training loss: 3.2284746170043945
Validation loss: 2.4042310817267305

Epoch: 6| Step: 5
Training loss: 3.4359092712402344
Validation loss: 2.4056816203619844

Epoch: 6| Step: 6
Training loss: 2.1635429859161377
Validation loss: 2.3964202147658153

Epoch: 6| Step: 7
Training loss: 2.3232405185699463
Validation loss: 2.4027357562895744

Epoch: 6| Step: 8
Training loss: 2.7347238063812256
Validation loss: 2.393005604385048

Epoch: 6| Step: 9
Training loss: 2.9501829147338867
Validation loss: 2.3970123849889284

Epoch: 6| Step: 10
Training loss: 2.144796848297119
Validation loss: 2.389554641580069

Epoch: 6| Step: 11
Training loss: 2.4946351051330566
Validation loss: 2.3901746349949993

Epoch: 6| Step: 12
Training loss: 2.411109447479248
Validation loss: 2.4050783982840915

Epoch: 6| Step: 13
Training loss: 1.7784135341644287
Validation loss: 2.426886386768792

Epoch: 257| Step: 0
Training loss: 2.497653007507324
Validation loss: 2.436071736838228

Epoch: 6| Step: 1
Training loss: 2.539783477783203
Validation loss: 2.468825058270526

Epoch: 6| Step: 2
Training loss: 3.1223878860473633
Validation loss: 2.5103210582528064

Epoch: 6| Step: 3
Training loss: 3.342043876647949
Validation loss: 2.4993100781594553

Epoch: 6| Step: 4
Training loss: 2.342796802520752
Validation loss: 2.471378352052422

Epoch: 6| Step: 5
Training loss: 2.373251438140869
Validation loss: 2.450950837904407

Epoch: 6| Step: 6
Training loss: 2.3529064655303955
Validation loss: 2.4394398299596642

Epoch: 6| Step: 7
Training loss: 2.256082534790039
Validation loss: 2.419599222880538

Epoch: 6| Step: 8
Training loss: 2.494941473007202
Validation loss: 2.420839698083939

Epoch: 6| Step: 9
Training loss: 2.39910888671875
Validation loss: 2.4080124773005003

Epoch: 6| Step: 10
Training loss: 2.7932729721069336
Validation loss: 2.4093421941162436

Epoch: 6| Step: 11
Training loss: 2.0635414123535156
Validation loss: 2.414708870713429

Epoch: 6| Step: 12
Training loss: 2.770963191986084
Validation loss: 2.414977558197514

Epoch: 6| Step: 13
Training loss: 3.3799521923065186
Validation loss: 2.4121891939511864

Epoch: 258| Step: 0
Training loss: 2.428870677947998
Validation loss: 2.417334992398498

Epoch: 6| Step: 1
Training loss: 2.3482699394226074
Validation loss: 2.412991077669205

Epoch: 6| Step: 2
Training loss: 2.7573208808898926
Validation loss: 2.418318958692653

Epoch: 6| Step: 3
Training loss: 2.544631004333496
Validation loss: 2.4258102781029156

Epoch: 6| Step: 4
Training loss: 2.178466558456421
Validation loss: 2.4240455371077343

Epoch: 6| Step: 5
Training loss: 2.969053268432617
Validation loss: 2.432016887972432

Epoch: 6| Step: 6
Training loss: 1.763758659362793
Validation loss: 2.4304240390818608

Epoch: 6| Step: 7
Training loss: 2.487293243408203
Validation loss: 2.425782370310958

Epoch: 6| Step: 8
Training loss: 3.9796385765075684
Validation loss: 2.4202362747602564

Epoch: 6| Step: 9
Training loss: 2.3171579837799072
Validation loss: 2.407811080255816

Epoch: 6| Step: 10
Training loss: 2.2959847450256348
Validation loss: 2.41633951792153

Epoch: 6| Step: 11
Training loss: 3.034128189086914
Validation loss: 2.4207235715722524

Epoch: 6| Step: 12
Training loss: 2.730332851409912
Validation loss: 2.4243068566886325

Epoch: 6| Step: 13
Training loss: 2.4318788051605225
Validation loss: 2.4231113285146733

Epoch: 259| Step: 0
Training loss: 2.2960448265075684
Validation loss: 2.4080854180038616

Epoch: 6| Step: 1
Training loss: 2.6349329948425293
Validation loss: 2.404776532162902

Epoch: 6| Step: 2
Training loss: 2.9084830284118652
Validation loss: 2.378311541772658

Epoch: 6| Step: 3
Training loss: 3.617084503173828
Validation loss: 2.374530703790726

Epoch: 6| Step: 4
Training loss: 2.425758123397827
Validation loss: 2.3708048456458637

Epoch: 6| Step: 5
Training loss: 2.202911376953125
Validation loss: 2.3645452837790213

Epoch: 6| Step: 6
Training loss: 2.5570387840270996
Validation loss: 2.370074866920389

Epoch: 6| Step: 7
Training loss: 2.5404469966888428
Validation loss: 2.3630405651625765

Epoch: 6| Step: 8
Training loss: 2.668074607849121
Validation loss: 2.3589176939379786

Epoch: 6| Step: 9
Training loss: 3.0198841094970703
Validation loss: 2.3682201382934407

Epoch: 6| Step: 10
Training loss: 2.365286350250244
Validation loss: 2.371252970028949

Epoch: 6| Step: 11
Training loss: 1.644744634628296
Validation loss: 2.3679896682821293

Epoch: 6| Step: 12
Training loss: 2.427659273147583
Validation loss: 2.3669442079400502

Epoch: 6| Step: 13
Training loss: 3.4400148391723633
Validation loss: 2.3699653379378782

Epoch: 260| Step: 0
Training loss: 1.4857650995254517
Validation loss: 2.371808890373476

Epoch: 6| Step: 1
Training loss: 2.3383524417877197
Validation loss: 2.385807993591473

Epoch: 6| Step: 2
Training loss: 2.4741148948669434
Validation loss: 2.3977131048838296

Epoch: 6| Step: 3
Training loss: 2.8754043579101562
Validation loss: 2.3940110027149157

Epoch: 6| Step: 4
Training loss: 2.815889835357666
Validation loss: 2.395620543469665

Epoch: 6| Step: 5
Training loss: 3.0527265071868896
Validation loss: 2.403838752418436

Epoch: 6| Step: 6
Training loss: 2.4228038787841797
Validation loss: 2.3960618383140972

Epoch: 6| Step: 7
Training loss: 2.615394115447998
Validation loss: 2.393115161567606

Epoch: 6| Step: 8
Training loss: 2.2010040283203125
Validation loss: 2.3909736525627876

Epoch: 6| Step: 9
Training loss: 2.930860757827759
Validation loss: 2.3935767681367937

Epoch: 6| Step: 10
Training loss: 2.5678389072418213
Validation loss: 2.390968704736361

Epoch: 6| Step: 11
Training loss: 2.4731545448303223
Validation loss: 2.3917355024686424

Epoch: 6| Step: 12
Training loss: 2.5790183544158936
Validation loss: 2.392290666539182

Epoch: 6| Step: 13
Training loss: 4.091334342956543
Validation loss: 2.3910621878921345

Epoch: 261| Step: 0
Training loss: 2.675151824951172
Validation loss: 2.3982549931413386

Epoch: 6| Step: 1
Training loss: 2.821791887283325
Validation loss: 2.4042502833950903

Epoch: 6| Step: 2
Training loss: 2.963261365890503
Validation loss: 2.4041690134233042

Epoch: 6| Step: 3
Training loss: 2.001903533935547
Validation loss: 2.402180799873926

Epoch: 6| Step: 4
Training loss: 2.262129783630371
Validation loss: 2.417190359484765

Epoch: 6| Step: 5
Training loss: 3.2882280349731445
Validation loss: 2.401554566557689

Epoch: 6| Step: 6
Training loss: 2.9378304481506348
Validation loss: 2.39787204803959

Epoch: 6| Step: 7
Training loss: 1.8753762245178223
Validation loss: 2.3991067076242096

Epoch: 6| Step: 8
Training loss: 2.1395184993743896
Validation loss: 2.388608576149069

Epoch: 6| Step: 9
Training loss: 2.529616117477417
Validation loss: 2.38767082460465

Epoch: 6| Step: 10
Training loss: 2.965031623840332
Validation loss: 2.3846398425358597

Epoch: 6| Step: 11
Training loss: 2.337174892425537
Validation loss: 2.391024266519854

Epoch: 6| Step: 12
Training loss: 2.502310276031494
Validation loss: 2.4102695359978625

Epoch: 6| Step: 13
Training loss: 2.9792935848236084
Validation loss: 2.4066092224531275

Epoch: 262| Step: 0
Training loss: 2.6597633361816406
Validation loss: 2.4507030440915014

Epoch: 6| Step: 1
Training loss: 2.646512508392334
Validation loss: 2.4370687853905464

Epoch: 6| Step: 2
Training loss: 2.3593809604644775
Validation loss: 2.422515679431218

Epoch: 6| Step: 3
Training loss: 2.099076747894287
Validation loss: 2.4125395026258243

Epoch: 6| Step: 4
Training loss: 1.915818691253662
Validation loss: 2.4154999897044194

Epoch: 6| Step: 5
Training loss: 2.901359796524048
Validation loss: 2.395506828061996

Epoch: 6| Step: 6
Training loss: 3.3064188957214355
Validation loss: 2.4006417464184504

Epoch: 6| Step: 7
Training loss: 3.2347545623779297
Validation loss: 2.3891227732422533

Epoch: 6| Step: 8
Training loss: 1.9793338775634766
Validation loss: 2.388142619081723

Epoch: 6| Step: 9
Training loss: 1.9188568592071533
Validation loss: 2.3873519436005624

Epoch: 6| Step: 10
Training loss: 3.1936216354370117
Validation loss: 2.3860306201442594

Epoch: 6| Step: 11
Training loss: 2.1508917808532715
Validation loss: 2.392023112184258

Epoch: 6| Step: 12
Training loss: 2.985764503479004
Validation loss: 2.3935345808664956

Epoch: 6| Step: 13
Training loss: 3.3226938247680664
Validation loss: 2.3863299790249077

Epoch: 263| Step: 0
Training loss: 2.674673080444336
Validation loss: 2.3922064868352746

Epoch: 6| Step: 1
Training loss: 2.3268728256225586
Validation loss: 2.393386633165421

Epoch: 6| Step: 2
Training loss: 2.315398693084717
Validation loss: 2.402436440990817

Epoch: 6| Step: 3
Training loss: 2.9149229526519775
Validation loss: 2.4180869979243123

Epoch: 6| Step: 4
Training loss: 2.1766161918640137
Validation loss: 2.4218088721716278

Epoch: 6| Step: 5
Training loss: 2.6116831302642822
Validation loss: 2.432114839553833

Epoch: 6| Step: 6
Training loss: 2.5754246711730957
Validation loss: 2.4407658243692048

Epoch: 6| Step: 7
Training loss: 2.6203694343566895
Validation loss: 2.4519267056577947

Epoch: 6| Step: 8
Training loss: 2.1846489906311035
Validation loss: 2.4496542048710648

Epoch: 6| Step: 9
Training loss: 2.3751730918884277
Validation loss: 2.441559955637942

Epoch: 6| Step: 10
Training loss: 2.9139394760131836
Validation loss: 2.4405164898082776

Epoch: 6| Step: 11
Training loss: 3.139939308166504
Validation loss: 2.431884032423778

Epoch: 6| Step: 12
Training loss: 2.313028573989868
Validation loss: 2.403153242603425

Epoch: 6| Step: 13
Training loss: 3.424821615219116
Validation loss: 2.396555157117946

Epoch: 264| Step: 0
Training loss: 3.240914821624756
Validation loss: 2.3884075251958703

Epoch: 6| Step: 1
Training loss: 3.4515576362609863
Validation loss: 2.3906115921594764

Epoch: 6| Step: 2
Training loss: 2.2469167709350586
Validation loss: 2.3924880104680217

Epoch: 6| Step: 3
Training loss: 2.574859380722046
Validation loss: 2.3939904141169723

Epoch: 6| Step: 4
Training loss: 2.5088024139404297
Validation loss: 2.4001701621599096

Epoch: 6| Step: 5
Training loss: 2.5398592948913574
Validation loss: 2.4064665507244807

Epoch: 6| Step: 6
Training loss: 2.3732242584228516
Validation loss: 2.4026995474292385

Epoch: 6| Step: 7
Training loss: 2.6624128818511963
Validation loss: 2.3927785914431334

Epoch: 6| Step: 8
Training loss: 2.1391775608062744
Validation loss: 2.3968846233942176

Epoch: 6| Step: 9
Training loss: 2.0829954147338867
Validation loss: 2.38741192125505

Epoch: 6| Step: 10
Training loss: 2.3566854000091553
Validation loss: 2.3864012636164182

Epoch: 6| Step: 11
Training loss: 3.3052167892456055
Validation loss: 2.3934007742071666

Epoch: 6| Step: 12
Training loss: 2.3120603561401367
Validation loss: 2.390665900322699

Epoch: 6| Step: 13
Training loss: 2.130268096923828
Validation loss: 2.4051690819442912

Epoch: 265| Step: 0
Training loss: 2.551266670227051
Validation loss: 2.398634397855369

Epoch: 6| Step: 1
Training loss: 2.4765968322753906
Validation loss: 2.427964351510489

Epoch: 6| Step: 2
Training loss: 3.068329095840454
Validation loss: 2.4407411031825568

Epoch: 6| Step: 3
Training loss: 2.0512843132019043
Validation loss: 2.45041198115195

Epoch: 6| Step: 4
Training loss: 1.9699944257736206
Validation loss: 2.422424139515046

Epoch: 6| Step: 5
Training loss: 2.2653937339782715
Validation loss: 2.416702724272205

Epoch: 6| Step: 6
Training loss: 2.564720630645752
Validation loss: 2.4125735503371044

Epoch: 6| Step: 7
Training loss: 3.2470602989196777
Validation loss: 2.3943469473110732

Epoch: 6| Step: 8
Training loss: 2.3460965156555176
Validation loss: 2.3911557069388767

Epoch: 6| Step: 9
Training loss: 3.9150476455688477
Validation loss: 2.406346026287284

Epoch: 6| Step: 10
Training loss: 2.7800004482269287
Validation loss: 2.395965196753061

Epoch: 6| Step: 11
Training loss: 2.6166138648986816
Validation loss: 2.3894309818103747

Epoch: 6| Step: 12
Training loss: 2.3693718910217285
Validation loss: 2.3767051184049217

Epoch: 6| Step: 13
Training loss: 1.5242170095443726
Validation loss: 2.3820779067213818

Epoch: 266| Step: 0
Training loss: 2.384719133377075
Validation loss: 2.375694123647546

Epoch: 6| Step: 1
Training loss: 2.6047723293304443
Validation loss: 2.375349449855025

Epoch: 6| Step: 2
Training loss: 2.3056468963623047
Validation loss: 2.374006868690573

Epoch: 6| Step: 3
Training loss: 3.1045429706573486
Validation loss: 2.3900308109098867

Epoch: 6| Step: 4
Training loss: 2.455252170562744
Validation loss: 2.401319080783475

Epoch: 6| Step: 5
Training loss: 2.346933126449585
Validation loss: 2.4147730527385587

Epoch: 6| Step: 6
Training loss: 2.776516914367676
Validation loss: 2.4306536977009108

Epoch: 6| Step: 7
Training loss: 1.7418084144592285
Validation loss: 2.424264315635927

Epoch: 6| Step: 8
Training loss: 3.0127267837524414
Validation loss: 2.4251523556247836

Epoch: 6| Step: 9
Training loss: 2.3182122707366943
Validation loss: 2.419986891490157

Epoch: 6| Step: 10
Training loss: 1.9645798206329346
Validation loss: 2.4090200662612915

Epoch: 6| Step: 11
Training loss: 3.403935432434082
Validation loss: 2.3892083808939946

Epoch: 6| Step: 12
Training loss: 2.9061529636383057
Validation loss: 2.38865242978578

Epoch: 6| Step: 13
Training loss: 3.098296642303467
Validation loss: 2.3804515433567826

Epoch: 267| Step: 0
Training loss: 2.551034688949585
Validation loss: 2.3926892126760175

Epoch: 6| Step: 1
Training loss: 3.123016357421875
Validation loss: 2.404031535630585

Epoch: 6| Step: 2
Training loss: 2.6134448051452637
Validation loss: 2.4146253934470554

Epoch: 6| Step: 3
Training loss: 2.904561996459961
Validation loss: 2.4165935798357894

Epoch: 6| Step: 4
Training loss: 2.046520233154297
Validation loss: 2.4288798891088015

Epoch: 6| Step: 5
Training loss: 2.5602011680603027
Validation loss: 2.4453345370549027

Epoch: 6| Step: 6
Training loss: 2.1424312591552734
Validation loss: 2.4354073437311317

Epoch: 6| Step: 7
Training loss: 3.0024566650390625
Validation loss: 2.4279172753774994

Epoch: 6| Step: 8
Training loss: 2.2966084480285645
Validation loss: 2.4195384774156796

Epoch: 6| Step: 9
Training loss: 2.217679977416992
Validation loss: 2.419539713090466

Epoch: 6| Step: 10
Training loss: 1.8848854303359985
Validation loss: 2.420392362020349

Epoch: 6| Step: 11
Training loss: 3.4373421669006348
Validation loss: 2.4152550312780563

Epoch: 6| Step: 12
Training loss: 3.098484754562378
Validation loss: 2.4239036703622467

Epoch: 6| Step: 13
Training loss: 2.2030484676361084
Validation loss: 2.4209373561284875

Epoch: 268| Step: 0
Training loss: 2.5710129737854004
Validation loss: 2.413659789228952

Epoch: 6| Step: 1
Training loss: 2.309943199157715
Validation loss: 2.395984293312155

Epoch: 6| Step: 2
Training loss: 2.666687488555908
Validation loss: 2.3819842415471233

Epoch: 6| Step: 3
Training loss: 2.929466962814331
Validation loss: 2.37300972015627

Epoch: 6| Step: 4
Training loss: 2.5130274295806885
Validation loss: 2.381744818020892

Epoch: 6| Step: 5
Training loss: 2.3932723999023438
Validation loss: 2.371276319667857

Epoch: 6| Step: 6
Training loss: 2.3073573112487793
Validation loss: 2.369726647612869

Epoch: 6| Step: 7
Training loss: 2.92592191696167
Validation loss: 2.382918055339526

Epoch: 6| Step: 8
Training loss: 2.377495765686035
Validation loss: 2.3823033250788206

Epoch: 6| Step: 9
Training loss: 2.6973042488098145
Validation loss: 2.3823567590405865

Epoch: 6| Step: 10
Training loss: 3.107128143310547
Validation loss: 2.396127244477631

Epoch: 6| Step: 11
Training loss: 1.8619388341903687
Validation loss: 2.3936802725638113

Epoch: 6| Step: 12
Training loss: 2.883288860321045
Validation loss: 2.401307905873945

Epoch: 6| Step: 13
Training loss: 2.3924288749694824
Validation loss: 2.394731116551225

Epoch: 269| Step: 0
Training loss: 3.205604076385498
Validation loss: 2.4001178074908514

Epoch: 6| Step: 1
Training loss: 1.3918616771697998
Validation loss: 2.399579273757114

Epoch: 6| Step: 2
Training loss: 2.244633197784424
Validation loss: 2.3992513700198104

Epoch: 6| Step: 3
Training loss: 2.6243929862976074
Validation loss: 2.414305889478294

Epoch: 6| Step: 4
Training loss: 2.461003303527832
Validation loss: 2.4025741033656622

Epoch: 6| Step: 5
Training loss: 2.9971535205841064
Validation loss: 2.3934104519505657

Epoch: 6| Step: 6
Training loss: 2.695392608642578
Validation loss: 2.390660680750365

Epoch: 6| Step: 7
Training loss: 1.9385623931884766
Validation loss: 2.382369795153218

Epoch: 6| Step: 8
Training loss: 2.4729621410369873
Validation loss: 2.38220912666731

Epoch: 6| Step: 9
Training loss: 2.2732958793640137
Validation loss: 2.3822570308562248

Epoch: 6| Step: 10
Training loss: 2.7986598014831543
Validation loss: 2.3898246826664096

Epoch: 6| Step: 11
Training loss: 3.3599674701690674
Validation loss: 2.4016268971145793

Epoch: 6| Step: 12
Training loss: 2.6622445583343506
Validation loss: 2.403656316059892

Epoch: 6| Step: 13
Training loss: 3.0027215480804443
Validation loss: 2.4038356170859387

Epoch: 270| Step: 0
Training loss: 2.984281063079834
Validation loss: 2.415741120615313

Epoch: 6| Step: 1
Training loss: 2.3916893005371094
Validation loss: 2.4133166267025854

Epoch: 6| Step: 2
Training loss: 3.279515027999878
Validation loss: 2.4121413000168337

Epoch: 6| Step: 3
Training loss: 2.6544995307922363
Validation loss: 2.4182851340181086

Epoch: 6| Step: 4
Training loss: 2.349663734436035
Validation loss: 2.416540197146836

Epoch: 6| Step: 5
Training loss: 2.798482894897461
Validation loss: 2.4293407317130797

Epoch: 6| Step: 6
Training loss: 2.4594788551330566
Validation loss: 2.4294379283023138

Epoch: 6| Step: 7
Training loss: 2.822416305541992
Validation loss: 2.4135032238498813

Epoch: 6| Step: 8
Training loss: 2.0660018920898438
Validation loss: 2.4111920146531958

Epoch: 6| Step: 9
Training loss: 1.6846380233764648
Validation loss: 2.410025568418605

Epoch: 6| Step: 10
Training loss: 2.7298107147216797
Validation loss: 2.403863381314021

Epoch: 6| Step: 11
Training loss: 3.1096394062042236
Validation loss: 2.407492773507231

Epoch: 6| Step: 12
Training loss: 2.1153361797332764
Validation loss: 2.4072950757959837

Epoch: 6| Step: 13
Training loss: 2.2769880294799805
Validation loss: 2.41509477297465

Epoch: 271| Step: 0
Training loss: 2.996706008911133
Validation loss: 2.41021542908043

Epoch: 6| Step: 1
Training loss: 2.723292827606201
Validation loss: 2.39697786044049

Epoch: 6| Step: 2
Training loss: 2.552161693572998
Validation loss: 2.401848634084066

Epoch: 6| Step: 3
Training loss: 2.97212553024292
Validation loss: 2.395051581885225

Epoch: 6| Step: 4
Training loss: 2.063192129135132
Validation loss: 2.3859381291174118

Epoch: 6| Step: 5
Training loss: 2.4636435508728027
Validation loss: 2.388321976507864

Epoch: 6| Step: 6
Training loss: 3.033562183380127
Validation loss: 2.3843678543644566

Epoch: 6| Step: 7
Training loss: 2.235260009765625
Validation loss: 2.3816104242878575

Epoch: 6| Step: 8
Training loss: 1.8210554122924805
Validation loss: 2.3793094670900734

Epoch: 6| Step: 9
Training loss: 2.426429271697998
Validation loss: 2.3648914983195644

Epoch: 6| Step: 10
Training loss: 2.244141101837158
Validation loss: 2.3864981371869325

Epoch: 6| Step: 11
Training loss: 2.763354778289795
Validation loss: 2.3778810052461523

Epoch: 6| Step: 12
Training loss: 3.37351655960083
Validation loss: 2.379258309641192

Epoch: 6| Step: 13
Training loss: 1.8572286367416382
Validation loss: 2.3897285435789373

Epoch: 272| Step: 0
Training loss: 2.922163486480713
Validation loss: 2.3851248628349713

Epoch: 6| Step: 1
Training loss: 3.2317075729370117
Validation loss: 2.383175101331485

Epoch: 6| Step: 2
Training loss: 2.8683879375457764
Validation loss: 2.3969944395044798

Epoch: 6| Step: 3
Training loss: 2.044330596923828
Validation loss: 2.3824994474328975

Epoch: 6| Step: 4
Training loss: 2.208418607711792
Validation loss: 2.390060196640671

Epoch: 6| Step: 5
Training loss: 2.091602087020874
Validation loss: 2.3756278407189155

Epoch: 6| Step: 6
Training loss: 3.221733331680298
Validation loss: 2.391395063810451

Epoch: 6| Step: 7
Training loss: 2.8441028594970703
Validation loss: 2.3732353282231156

Epoch: 6| Step: 8
Training loss: 2.6437153816223145
Validation loss: 2.37888995293648

Epoch: 6| Step: 9
Training loss: 2.8566417694091797
Validation loss: 2.383670499247889

Epoch: 6| Step: 10
Training loss: 2.713204860687256
Validation loss: 2.3768552375096146

Epoch: 6| Step: 11
Training loss: 2.2389349937438965
Validation loss: 2.379960270338161

Epoch: 6| Step: 12
Training loss: 2.0402822494506836
Validation loss: 2.3911567093223653

Epoch: 6| Step: 13
Training loss: 1.5369831323623657
Validation loss: 2.395510805550442

Epoch: 273| Step: 0
Training loss: 2.397477626800537
Validation loss: 2.399271180552821

Epoch: 6| Step: 1
Training loss: 2.6159884929656982
Validation loss: 2.3985773722330728

Epoch: 6| Step: 2
Training loss: 2.1008148193359375
Validation loss: 2.3986369973869732

Epoch: 6| Step: 3
Training loss: 3.321420669555664
Validation loss: 2.4043341426439184

Epoch: 6| Step: 4
Training loss: 2.405568838119507
Validation loss: 2.3990043414536344

Epoch: 6| Step: 5
Training loss: 2.41477370262146
Validation loss: 2.3835485058446086

Epoch: 6| Step: 6
Training loss: 2.492366313934326
Validation loss: 2.406364558845438

Epoch: 6| Step: 7
Training loss: 2.4866440296173096
Validation loss: 2.4019868091870378

Epoch: 6| Step: 8
Training loss: 2.423861026763916
Validation loss: 2.410196852940385

Epoch: 6| Step: 9
Training loss: 2.381495952606201
Validation loss: 2.4076234832886727

Epoch: 6| Step: 10
Training loss: 2.6078333854675293
Validation loss: 2.419531160785306

Epoch: 6| Step: 11
Training loss: 2.294283866882324
Validation loss: 2.420088334750104

Epoch: 6| Step: 12
Training loss: 2.9181511402130127
Validation loss: 2.4197670054692093

Epoch: 6| Step: 13
Training loss: 3.314610004425049
Validation loss: 2.411204586746872

Epoch: 274| Step: 0
Training loss: 1.741007685661316
Validation loss: 2.396893608954645

Epoch: 6| Step: 1
Training loss: 3.108849048614502
Validation loss: 2.383369448364422

Epoch: 6| Step: 2
Training loss: 2.647336006164551
Validation loss: 2.3911909339248494

Epoch: 6| Step: 3
Training loss: 2.147042751312256
Validation loss: 2.3929679701405187

Epoch: 6| Step: 4
Training loss: 2.7447423934936523
Validation loss: 2.4032995111198834

Epoch: 6| Step: 5
Training loss: 2.4097132682800293
Validation loss: 2.4025339567533104

Epoch: 6| Step: 6
Training loss: 2.5082168579101562
Validation loss: 2.397124890358217

Epoch: 6| Step: 7
Training loss: 2.4138951301574707
Validation loss: 2.3960661221575994

Epoch: 6| Step: 8
Training loss: 2.4858975410461426
Validation loss: 2.399472005905644

Epoch: 6| Step: 9
Training loss: 2.6908586025238037
Validation loss: 2.4015142661268993

Epoch: 6| Step: 10
Training loss: 2.564112424850464
Validation loss: 2.4001740563300347

Epoch: 6| Step: 11
Training loss: 2.373392343521118
Validation loss: 2.387750530755648

Epoch: 6| Step: 12
Training loss: 2.8001370429992676
Validation loss: 2.3946710273783696

Epoch: 6| Step: 13
Training loss: 3.5652194023132324
Validation loss: 2.390844911657354

Epoch: 275| Step: 0
Training loss: 2.3549108505249023
Validation loss: 2.380224630396853

Epoch: 6| Step: 1
Training loss: 2.1306686401367188
Validation loss: 2.371674337694722

Epoch: 6| Step: 2
Training loss: 3.169426441192627
Validation loss: 2.3609550332510345

Epoch: 6| Step: 3
Training loss: 1.9993367195129395
Validation loss: 2.3623420115440124

Epoch: 6| Step: 4
Training loss: 2.760786294937134
Validation loss: 2.363162373983732

Epoch: 6| Step: 5
Training loss: 2.2327914237976074
Validation loss: 2.3590949209787513

Epoch: 6| Step: 6
Training loss: 3.3102335929870605
Validation loss: 2.376583350602017

Epoch: 6| Step: 7
Training loss: 2.6598005294799805
Validation loss: 2.377616584941905

Epoch: 6| Step: 8
Training loss: 2.18635630607605
Validation loss: 2.3941250949777584

Epoch: 6| Step: 9
Training loss: 1.9421660900115967
Validation loss: 2.4006496501225296

Epoch: 6| Step: 10
Training loss: 2.4889883995056152
Validation loss: 2.418822137258386

Epoch: 6| Step: 11
Training loss: 2.8062376976013184
Validation loss: 2.4168266429696033

Epoch: 6| Step: 12
Training loss: 3.324094772338867
Validation loss: 2.4239902034882577

Epoch: 6| Step: 13
Training loss: 2.407740592956543
Validation loss: 2.418257050616767

Epoch: 276| Step: 0
Training loss: 2.260737895965576
Validation loss: 2.404049642624394

Epoch: 6| Step: 1
Training loss: 2.31781005859375
Validation loss: 2.392686995126868

Epoch: 6| Step: 2
Training loss: 2.227226734161377
Validation loss: 2.383562799422972

Epoch: 6| Step: 3
Training loss: 2.5358986854553223
Validation loss: 2.3869364646173294

Epoch: 6| Step: 4
Training loss: 3.100933074951172
Validation loss: 2.3768325262172247

Epoch: 6| Step: 5
Training loss: 2.6510462760925293
Validation loss: 2.3692697376333256

Epoch: 6| Step: 6
Training loss: 3.2201929092407227
Validation loss: 2.3719233082186792

Epoch: 6| Step: 7
Training loss: 2.7870593070983887
Validation loss: 2.3682837537539903

Epoch: 6| Step: 8
Training loss: 2.518660306930542
Validation loss: 2.36913630782917

Epoch: 6| Step: 9
Training loss: 3.016057014465332
Validation loss: 2.361734446658883

Epoch: 6| Step: 10
Training loss: 2.084839344024658
Validation loss: 2.3601632220770723

Epoch: 6| Step: 11
Training loss: 2.6081485748291016
Validation loss: 2.357425484606015

Epoch: 6| Step: 12
Training loss: 1.684586763381958
Validation loss: 2.3573494239520003

Epoch: 6| Step: 13
Training loss: 2.8786771297454834
Validation loss: 2.3615684560550156

Epoch: 277| Step: 0
Training loss: 2.53489351272583
Validation loss: 2.3702525272164294

Epoch: 6| Step: 1
Training loss: 2.5002408027648926
Validation loss: 2.369722048441569

Epoch: 6| Step: 2
Training loss: 2.7344326972961426
Validation loss: 2.3746695082674742

Epoch: 6| Step: 3
Training loss: 2.610243320465088
Validation loss: 2.38126959723811

Epoch: 6| Step: 4
Training loss: 3.2450718879699707
Validation loss: 2.381033028325727

Epoch: 6| Step: 5
Training loss: 2.2696352005004883
Validation loss: 2.396856577165665

Epoch: 6| Step: 6
Training loss: 2.694629192352295
Validation loss: 2.409202303937686

Epoch: 6| Step: 7
Training loss: 2.3429007530212402
Validation loss: 2.4178327206642396

Epoch: 6| Step: 8
Training loss: 2.613476276397705
Validation loss: 2.410594722276093

Epoch: 6| Step: 9
Training loss: 2.702017307281494
Validation loss: 2.401238477358254

Epoch: 6| Step: 10
Training loss: 2.5976080894470215
Validation loss: 2.3915346489157727

Epoch: 6| Step: 11
Training loss: 2.307229995727539
Validation loss: 2.3823976926906134

Epoch: 6| Step: 12
Training loss: 1.842224359512329
Validation loss: 2.380405174788608

Epoch: 6| Step: 13
Training loss: 2.808488607406616
Validation loss: 2.3780456999296784

Epoch: 278| Step: 0
Training loss: 2.876375198364258
Validation loss: 2.369904374563566

Epoch: 6| Step: 1
Training loss: 2.4243853092193604
Validation loss: 2.3742098859561387

Epoch: 6| Step: 2
Training loss: 2.32926082611084
Validation loss: 2.3795324115342993

Epoch: 6| Step: 3
Training loss: 2.279113292694092
Validation loss: 2.370645334643702

Epoch: 6| Step: 4
Training loss: 2.433471202850342
Validation loss: 2.3716248696850193

Epoch: 6| Step: 5
Training loss: 3.578927993774414
Validation loss: 2.370580551444843

Epoch: 6| Step: 6
Training loss: 3.2428886890411377
Validation loss: 2.375660491246049

Epoch: 6| Step: 7
Training loss: 2.3022313117980957
Validation loss: 2.3685391538886615

Epoch: 6| Step: 8
Training loss: 2.455625534057617
Validation loss: 2.3911284605662027

Epoch: 6| Step: 9
Training loss: 2.453706741333008
Validation loss: 2.3906362082368586

Epoch: 6| Step: 10
Training loss: 2.0256006717681885
Validation loss: 2.400028726106049

Epoch: 6| Step: 11
Training loss: 3.056044578552246
Validation loss: 2.4044973645158993

Epoch: 6| Step: 12
Training loss: 1.8774299621582031
Validation loss: 2.4046055091324674

Epoch: 6| Step: 13
Training loss: 2.2771284580230713
Validation loss: 2.40959261309716

Epoch: 279| Step: 0
Training loss: 2.9544034004211426
Validation loss: 2.393968279643725

Epoch: 6| Step: 1
Training loss: 2.1872551441192627
Validation loss: 2.388205264204292

Epoch: 6| Step: 2
Training loss: 2.6338186264038086
Validation loss: 2.3815868708395187

Epoch: 6| Step: 3
Training loss: 1.9397878646850586
Validation loss: 2.3888852416828112

Epoch: 6| Step: 4
Training loss: 2.7293827533721924
Validation loss: 2.3652430260053245

Epoch: 6| Step: 5
Training loss: 2.0731863975524902
Validation loss: 2.3684616857959377

Epoch: 6| Step: 6
Training loss: 2.243723154067993
Validation loss: 2.3663975346472954

Epoch: 6| Step: 7
Training loss: 2.9533586502075195
Validation loss: 2.35738564819418

Epoch: 6| Step: 8
Training loss: 3.0722599029541016
Validation loss: 2.354773244550151

Epoch: 6| Step: 9
Training loss: 1.9884122610092163
Validation loss: 2.3592350034303564

Epoch: 6| Step: 10
Training loss: 3.046847343444824
Validation loss: 2.3629653928100423

Epoch: 6| Step: 11
Training loss: 2.0010414123535156
Validation loss: 2.3654889406696444

Epoch: 6| Step: 12
Training loss: 3.0720298290252686
Validation loss: 2.3783948498387493

Epoch: 6| Step: 13
Training loss: 2.8694658279418945
Validation loss: 2.387920456547891

Epoch: 280| Step: 0
Training loss: 1.7696374654769897
Validation loss: 2.4009385390948226

Epoch: 6| Step: 1
Training loss: 2.549306631088257
Validation loss: 2.4254439159106185

Epoch: 6| Step: 2
Training loss: 2.586989402770996
Validation loss: 2.4297955933437554

Epoch: 6| Step: 3
Training loss: 3.2099456787109375
Validation loss: 2.4170257045376684

Epoch: 6| Step: 4
Training loss: 2.725255012512207
Validation loss: 2.4037113779334613

Epoch: 6| Step: 5
Training loss: 2.2936394214630127
Validation loss: 2.3729826545202606

Epoch: 6| Step: 6
Training loss: 1.7269957065582275
Validation loss: 2.376301351413932

Epoch: 6| Step: 7
Training loss: 3.1603899002075195
Validation loss: 2.371196549425843

Epoch: 6| Step: 8
Training loss: 2.2149105072021484
Validation loss: 2.3589056973816245

Epoch: 6| Step: 9
Training loss: 3.4938836097717285
Validation loss: 2.3683319937798286

Epoch: 6| Step: 10
Training loss: 2.0931715965270996
Validation loss: 2.370634248179774

Epoch: 6| Step: 11
Training loss: 2.2144317626953125
Validation loss: 2.3639301074448453

Epoch: 6| Step: 12
Training loss: 3.0719940662384033
Validation loss: 2.380286975573468

Epoch: 6| Step: 13
Training loss: 2.63449764251709
Validation loss: 2.3739900896626134

Epoch: 281| Step: 0
Training loss: 2.193582057952881
Validation loss: 2.3806550118231002

Epoch: 6| Step: 1
Training loss: 3.3460099697113037
Validation loss: 2.3923806733982538

Epoch: 6| Step: 2
Training loss: 2.0846047401428223
Validation loss: 2.395545892818

Epoch: 6| Step: 3
Training loss: 2.5567879676818848
Validation loss: 2.3965166691810853

Epoch: 6| Step: 4
Training loss: 2.7316436767578125
Validation loss: 2.400104145849905

Epoch: 6| Step: 5
Training loss: 2.3183083534240723
Validation loss: 2.41066558899418

Epoch: 6| Step: 6
Training loss: 2.6331558227539062
Validation loss: 2.4206739856350805

Epoch: 6| Step: 7
Training loss: 2.0003018379211426
Validation loss: 2.424183799374488

Epoch: 6| Step: 8
Training loss: 1.9888463020324707
Validation loss: 2.416612755867743

Epoch: 6| Step: 9
Training loss: 2.0915329456329346
Validation loss: 2.415359079196889

Epoch: 6| Step: 10
Training loss: 3.2756717205047607
Validation loss: 2.41394906146552

Epoch: 6| Step: 11
Training loss: 1.7324442863464355
Validation loss: 2.413414098883188

Epoch: 6| Step: 12
Training loss: 3.998021125793457
Validation loss: 2.4017744987241683

Epoch: 6| Step: 13
Training loss: 2.6102309226989746
Validation loss: 2.3870380745139173

Epoch: 282| Step: 0
Training loss: 2.5764286518096924
Validation loss: 2.382676165591004

Epoch: 6| Step: 1
Training loss: 2.283662796020508
Validation loss: 2.3710005180810088

Epoch: 6| Step: 2
Training loss: 2.046638011932373
Validation loss: 2.3612743526376705

Epoch: 6| Step: 3
Training loss: 2.771909713745117
Validation loss: 2.357697138222315

Epoch: 6| Step: 4
Training loss: 2.6966586112976074
Validation loss: 2.347960396479535

Epoch: 6| Step: 5
Training loss: 2.9828858375549316
Validation loss: 2.361609253832089

Epoch: 6| Step: 6
Training loss: 2.771415948867798
Validation loss: 2.3599097267273934

Epoch: 6| Step: 7
Training loss: 2.000980854034424
Validation loss: 2.360804493709277

Epoch: 6| Step: 8
Training loss: 2.072265386581421
Validation loss: 2.3556940299208446

Epoch: 6| Step: 9
Training loss: 2.8503572940826416
Validation loss: 2.344575757621437

Epoch: 6| Step: 10
Training loss: 2.958773136138916
Validation loss: 2.3370288982186267

Epoch: 6| Step: 11
Training loss: 2.596433639526367
Validation loss: 2.3494703487683366

Epoch: 6| Step: 12
Training loss: 2.232428789138794
Validation loss: 2.352710695676906

Epoch: 6| Step: 13
Training loss: 3.2731823921203613
Validation loss: 2.3586474490422074

Epoch: 283| Step: 0
Training loss: 2.62703537940979
Validation loss: 2.36900314464364

Epoch: 6| Step: 1
Training loss: 2.062131881713867
Validation loss: 2.3789532082055205

Epoch: 6| Step: 2
Training loss: 2.4535722732543945
Validation loss: 2.393706647298669

Epoch: 6| Step: 3
Training loss: 1.8961600065231323
Validation loss: 2.4331077657720095

Epoch: 6| Step: 4
Training loss: 3.317439317703247
Validation loss: 2.417926844730172

Epoch: 6| Step: 5
Training loss: 2.889768600463867
Validation loss: 2.43101732448865

Epoch: 6| Step: 6
Training loss: 3.5214033126831055
Validation loss: 2.4041022946757655

Epoch: 6| Step: 7
Training loss: 2.1773922443389893
Validation loss: 2.407031836048249

Epoch: 6| Step: 8
Training loss: 1.789595127105713
Validation loss: 2.385895403482581

Epoch: 6| Step: 9
Training loss: 2.3907065391540527
Validation loss: 2.3634776607636483

Epoch: 6| Step: 10
Training loss: 2.77573299407959
Validation loss: 2.3702000443653395

Epoch: 6| Step: 11
Training loss: 2.758094072341919
Validation loss: 2.3587593122195174

Epoch: 6| Step: 12
Training loss: 2.378251075744629
Validation loss: 2.356837470044372

Epoch: 6| Step: 13
Training loss: 2.469254970550537
Validation loss: 2.3688692533841698

Epoch: 284| Step: 0
Training loss: 1.8784971237182617
Validation loss: 2.3603690157654467

Epoch: 6| Step: 1
Training loss: 3.302159309387207
Validation loss: 2.3703677961903233

Epoch: 6| Step: 2
Training loss: 2.2863588333129883
Validation loss: 2.3655413914752264

Epoch: 6| Step: 3
Training loss: 2.6373438835144043
Validation loss: 2.371777288375362

Epoch: 6| Step: 4
Training loss: 2.7043304443359375
Validation loss: 2.365712296578192

Epoch: 6| Step: 5
Training loss: 3.49945068359375
Validation loss: 2.3585268143684632

Epoch: 6| Step: 6
Training loss: 2.3199734687805176
Validation loss: 2.366192143450501

Epoch: 6| Step: 7
Training loss: 2.404355525970459
Validation loss: 2.366798767479517

Epoch: 6| Step: 8
Training loss: 2.9756336212158203
Validation loss: 2.3859336991463937

Epoch: 6| Step: 9
Training loss: 2.3848867416381836
Validation loss: 2.3910439296435286

Epoch: 6| Step: 10
Training loss: 2.4881937503814697
Validation loss: 2.3764775491529897

Epoch: 6| Step: 11
Training loss: 1.781682014465332
Validation loss: 2.3765771978644916

Epoch: 6| Step: 12
Training loss: 2.4429826736450195
Validation loss: 2.3585644037492814

Epoch: 6| Step: 13
Training loss: 2.430840015411377
Validation loss: 2.3636543494398876

Epoch: 285| Step: 0
Training loss: 3.106560707092285
Validation loss: 2.377916389896024

Epoch: 6| Step: 1
Training loss: 3.0716452598571777
Validation loss: 2.3842058617581605

Epoch: 6| Step: 2
Training loss: 3.046142339706421
Validation loss: 2.374261825315414

Epoch: 6| Step: 3
Training loss: 1.5831387042999268
Validation loss: 2.3731984656344176

Epoch: 6| Step: 4
Training loss: 1.564103603363037
Validation loss: 2.373871600756081

Epoch: 6| Step: 5
Training loss: 2.4042000770568848
Validation loss: 2.363924462308166

Epoch: 6| Step: 6
Training loss: 2.461169958114624
Validation loss: 2.3686349186846005

Epoch: 6| Step: 7
Training loss: 2.9456872940063477
Validation loss: 2.3611905215888895

Epoch: 6| Step: 8
Training loss: 2.0497283935546875
Validation loss: 2.362136417819608

Epoch: 6| Step: 9
Training loss: 2.124484062194824
Validation loss: 2.3681479961641374

Epoch: 6| Step: 10
Training loss: 2.94083571434021
Validation loss: 2.3699418088441253

Epoch: 6| Step: 11
Training loss: 2.600224494934082
Validation loss: 2.378274102364817

Epoch: 6| Step: 12
Training loss: 2.9966065883636475
Validation loss: 2.383079844136392

Epoch: 6| Step: 13
Training loss: 2.731255531311035
Validation loss: 2.3953662841550765

Epoch: 286| Step: 0
Training loss: 1.7466567754745483
Validation loss: 2.4002676215223087

Epoch: 6| Step: 1
Training loss: 2.172565460205078
Validation loss: 2.4205267788261495

Epoch: 6| Step: 2
Training loss: 2.5754990577697754
Validation loss: 2.4241037343138006

Epoch: 6| Step: 3
Training loss: 2.715391159057617
Validation loss: 2.4192480220589587

Epoch: 6| Step: 4
Training loss: 2.405029058456421
Validation loss: 2.426499423160348

Epoch: 6| Step: 5
Training loss: 2.4060773849487305
Validation loss: 2.4033261114551174

Epoch: 6| Step: 6
Training loss: 3.0183029174804688
Validation loss: 2.4096527458519064

Epoch: 6| Step: 7
Training loss: 2.5357096195220947
Validation loss: 2.387090088218771

Epoch: 6| Step: 8
Training loss: 2.4376773834228516
Validation loss: 2.3863333989215154

Epoch: 6| Step: 9
Training loss: 2.0634822845458984
Validation loss: 2.3932512678125852

Epoch: 6| Step: 10
Training loss: 3.306912660598755
Validation loss: 2.3799245152422177

Epoch: 6| Step: 11
Training loss: 2.732576608657837
Validation loss: 2.380958139255483

Epoch: 6| Step: 12
Training loss: 2.600055456161499
Validation loss: 2.388014256313283

Epoch: 6| Step: 13
Training loss: 3.087022542953491
Validation loss: 2.398291854448216

Epoch: 287| Step: 0
Training loss: 2.1105268001556396
Validation loss: 2.399258462331628

Epoch: 6| Step: 1
Training loss: 2.926342487335205
Validation loss: 2.397467831129669

Epoch: 6| Step: 2
Training loss: 1.8657171726226807
Validation loss: 2.383137631159957

Epoch: 6| Step: 3
Training loss: 2.7830440998077393
Validation loss: 2.383539602320681

Epoch: 6| Step: 4
Training loss: 2.1344661712646484
Validation loss: 2.36827685499704

Epoch: 6| Step: 5
Training loss: 2.295689344406128
Validation loss: 2.3672432514929

Epoch: 6| Step: 6
Training loss: 2.5181357860565186
Validation loss: 2.3566749608644875

Epoch: 6| Step: 7
Training loss: 3.3918023109436035
Validation loss: 2.3502868875380485

Epoch: 6| Step: 8
Training loss: 2.510805130004883
Validation loss: 2.336546692796933

Epoch: 6| Step: 9
Training loss: 3.35654354095459
Validation loss: 2.3355287249370287

Epoch: 6| Step: 10
Training loss: 2.5843677520751953
Validation loss: 2.3369222815318773

Epoch: 6| Step: 11
Training loss: 2.278632640838623
Validation loss: 2.3384905656178794

Epoch: 6| Step: 12
Training loss: 2.119378089904785
Validation loss: 2.3521012336977067

Epoch: 6| Step: 13
Training loss: 2.731966733932495
Validation loss: 2.3426882964308544

Epoch: 288| Step: 0
Training loss: 2.0741496086120605
Validation loss: 2.3539679050445557

Epoch: 6| Step: 1
Training loss: 2.7885990142822266
Validation loss: 2.3602106314833446

Epoch: 6| Step: 2
Training loss: 2.5431580543518066
Validation loss: 2.366133507861886

Epoch: 6| Step: 3
Training loss: 2.8031978607177734
Validation loss: 2.3702177898858183

Epoch: 6| Step: 4
Training loss: 2.7722976207733154
Validation loss: 2.370378061007428

Epoch: 6| Step: 5
Training loss: 2.2906739711761475
Validation loss: 2.3754910858728553

Epoch: 6| Step: 6
Training loss: 2.8645687103271484
Validation loss: 2.373916405503468

Epoch: 6| Step: 7
Training loss: 2.1200428009033203
Validation loss: 2.3694221793964343

Epoch: 6| Step: 8
Training loss: 2.2928993701934814
Validation loss: 2.381767903604815

Epoch: 6| Step: 9
Training loss: 3.0189208984375
Validation loss: 2.3697431933495308

Epoch: 6| Step: 10
Training loss: 2.300143003463745
Validation loss: 2.383894958803731

Epoch: 6| Step: 11
Training loss: 2.7850332260131836
Validation loss: 2.415188463785315

Epoch: 6| Step: 12
Training loss: 2.2145867347717285
Validation loss: 2.419175365919708

Epoch: 6| Step: 13
Training loss: 2.411787986755371
Validation loss: 2.4339892838590886

Epoch: 289| Step: 0
Training loss: 2.0847861766815186
Validation loss: 2.435567996835196

Epoch: 6| Step: 1
Training loss: 2.19211483001709
Validation loss: 2.442935779530515

Epoch: 6| Step: 2
Training loss: 2.1968584060668945
Validation loss: 2.4399277625545377

Epoch: 6| Step: 3
Training loss: 2.850125789642334
Validation loss: 2.432246069754324

Epoch: 6| Step: 4
Training loss: 2.763963460922241
Validation loss: 2.416030119824153

Epoch: 6| Step: 5
Training loss: 2.8715620040893555
Validation loss: 2.426639879903486

Epoch: 6| Step: 6
Training loss: 2.852159023284912
Validation loss: 2.391602721265567

Epoch: 6| Step: 7
Training loss: 2.32308292388916
Validation loss: 2.3946874167329524

Epoch: 6| Step: 8
Training loss: 2.947728157043457
Validation loss: 2.3722550433169127

Epoch: 6| Step: 9
Training loss: 2.3450815677642822
Validation loss: 2.3769044107006443

Epoch: 6| Step: 10
Training loss: 2.127366065979004
Validation loss: 2.3785436153411865

Epoch: 6| Step: 11
Training loss: 3.1748406887054443
Validation loss: 2.368567923063873

Epoch: 6| Step: 12
Training loss: 2.543205738067627
Validation loss: 2.360533880931075

Epoch: 6| Step: 13
Training loss: 1.8369358777999878
Validation loss: 2.3557990033139466

Epoch: 290| Step: 0
Training loss: 1.954784631729126
Validation loss: 2.3579160167324926

Epoch: 6| Step: 1
Training loss: 2.1173129081726074
Validation loss: 2.3529188094600553

Epoch: 6| Step: 2
Training loss: 2.3497142791748047
Validation loss: 2.3547506845125588

Epoch: 6| Step: 3
Training loss: 2.0958168506622314
Validation loss: 2.359214109759177

Epoch: 6| Step: 4
Training loss: 2.19273042678833
Validation loss: 2.3599549057663127

Epoch: 6| Step: 5
Training loss: 2.142002582550049
Validation loss: 2.3580196057596514

Epoch: 6| Step: 6
Training loss: 2.910505771636963
Validation loss: 2.3985173574057956

Epoch: 6| Step: 7
Training loss: 2.319596767425537
Validation loss: 2.425387223561605

Epoch: 6| Step: 8
Training loss: 2.1184639930725098
Validation loss: 2.4464309369364092

Epoch: 6| Step: 9
Training loss: 3.228426218032837
Validation loss: 2.4341379852705103

Epoch: 6| Step: 10
Training loss: 2.8047003746032715
Validation loss: 2.4218587183183238

Epoch: 6| Step: 11
Training loss: 3.1423442363739014
Validation loss: 2.4095669331089145

Epoch: 6| Step: 12
Training loss: 3.216801404953003
Validation loss: 2.382995690068891

Epoch: 6| Step: 13
Training loss: 3.012941598892212
Validation loss: 2.373144075434695

Epoch: 291| Step: 0
Training loss: 2.9432976245880127
Validation loss: 2.351979955550163

Epoch: 6| Step: 1
Training loss: 3.1698293685913086
Validation loss: 2.355613395731936

Epoch: 6| Step: 2
Training loss: 2.8160572052001953
Validation loss: 2.3486722438566145

Epoch: 6| Step: 3
Training loss: 2.159655809402466
Validation loss: 2.365632821154851

Epoch: 6| Step: 4
Training loss: 2.435607671737671
Validation loss: 2.3549969734684115

Epoch: 6| Step: 5
Training loss: 2.395251750946045
Validation loss: 2.3526354451333322

Epoch: 6| Step: 6
Training loss: 2.3496620655059814
Validation loss: 2.3543481980600665

Epoch: 6| Step: 7
Training loss: 2.0457208156585693
Validation loss: 2.353766069617323

Epoch: 6| Step: 8
Training loss: 2.75736403465271
Validation loss: 2.3499013967411493

Epoch: 6| Step: 9
Training loss: 2.4286584854125977
Validation loss: 2.347819253962527

Epoch: 6| Step: 10
Training loss: 2.46321964263916
Validation loss: 2.34725417629365

Epoch: 6| Step: 11
Training loss: 1.7080914974212646
Validation loss: 2.3592137085494174

Epoch: 6| Step: 12
Training loss: 2.5144941806793213
Validation loss: 2.3661740518385366

Epoch: 6| Step: 13
Training loss: 3.4469692707061768
Validation loss: 2.362342293544482

Epoch: 292| Step: 0
Training loss: 1.9684607982635498
Validation loss: 2.3780275929358696

Epoch: 6| Step: 1
Training loss: 2.6502246856689453
Validation loss: 2.3848578365900184

Epoch: 6| Step: 2
Training loss: 2.9586501121520996
Validation loss: 2.3803454906709733

Epoch: 6| Step: 3
Training loss: 2.089216470718384
Validation loss: 2.3840967121944634

Epoch: 6| Step: 4
Training loss: 2.6752328872680664
Validation loss: 2.3938718867558304

Epoch: 6| Step: 5
Training loss: 2.552342176437378
Validation loss: 2.388206348624281

Epoch: 6| Step: 6
Training loss: 2.0695245265960693
Validation loss: 2.411346297110281

Epoch: 6| Step: 7
Training loss: 2.7109928131103516
Validation loss: 2.4208743136416198

Epoch: 6| Step: 8
Training loss: 2.6165995597839355
Validation loss: 2.4295443796342417

Epoch: 6| Step: 9
Training loss: 1.8599787950515747
Validation loss: 2.417841629315448

Epoch: 6| Step: 10
Training loss: 3.1029906272888184
Validation loss: 2.3951702220465547

Epoch: 6| Step: 11
Training loss: 2.478123188018799
Validation loss: 2.3887694292171027

Epoch: 6| Step: 12
Training loss: 2.5687499046325684
Validation loss: 2.3742856646096833

Epoch: 6| Step: 13
Training loss: 3.373009204864502
Validation loss: 2.3759820897092103

Epoch: 293| Step: 0
Training loss: 2.9336390495300293
Validation loss: 2.3784833287680023

Epoch: 6| Step: 1
Training loss: 1.9071050882339478
Validation loss: 2.375866723316972

Epoch: 6| Step: 2
Training loss: 2.639134407043457
Validation loss: 2.394951366609143

Epoch: 6| Step: 3
Training loss: 2.2077536582946777
Validation loss: 2.402526899050641

Epoch: 6| Step: 4
Training loss: 2.7238564491271973
Validation loss: 2.4208601315816245

Epoch: 6| Step: 5
Training loss: 2.6777663230895996
Validation loss: 2.416904939118252

Epoch: 6| Step: 6
Training loss: 3.8566808700561523
Validation loss: 2.4127362671718804

Epoch: 6| Step: 7
Training loss: 2.5051417350769043
Validation loss: 2.416135670036398

Epoch: 6| Step: 8
Training loss: 1.7094597816467285
Validation loss: 2.392021458636048

Epoch: 6| Step: 9
Training loss: 2.530025005340576
Validation loss: 2.409136877265028

Epoch: 6| Step: 10
Training loss: 2.1207165718078613
Validation loss: 2.3885460335721254

Epoch: 6| Step: 11
Training loss: 2.31007719039917
Validation loss: 2.3867803286480647

Epoch: 6| Step: 12
Training loss: 2.6345107555389404
Validation loss: 2.388199201194189

Epoch: 6| Step: 13
Training loss: 2.43318247795105
Validation loss: 2.366820760952529

Epoch: 294| Step: 0
Training loss: 3.299896478652954
Validation loss: 2.3631808398872294

Epoch: 6| Step: 1
Training loss: 2.5994763374328613
Validation loss: 2.3694397249529437

Epoch: 6| Step: 2
Training loss: 2.5844573974609375
Validation loss: 2.371871289386544

Epoch: 6| Step: 3
Training loss: 2.5976099967956543
Validation loss: 2.3699259668268184

Epoch: 6| Step: 4
Training loss: 2.3707704544067383
Validation loss: 2.3775414856531287

Epoch: 6| Step: 5
Training loss: 2.2824907302856445
Validation loss: 2.3781529216356176

Epoch: 6| Step: 6
Training loss: 2.689037322998047
Validation loss: 2.375501855727165

Epoch: 6| Step: 7
Training loss: 1.8334929943084717
Validation loss: 2.392870003177274

Epoch: 6| Step: 8
Training loss: 2.4974656105041504
Validation loss: 2.391292920676611

Epoch: 6| Step: 9
Training loss: 2.4683923721313477
Validation loss: 2.386355648758591

Epoch: 6| Step: 10
Training loss: 2.515596389770508
Validation loss: 2.4059879369633173

Epoch: 6| Step: 11
Training loss: 2.3878700733184814
Validation loss: 2.4045481297277633

Epoch: 6| Step: 12
Training loss: 2.3610005378723145
Validation loss: 2.392384841877927

Epoch: 6| Step: 13
Training loss: 2.685459852218628
Validation loss: 2.3703729721807663

Epoch: 295| Step: 0
Training loss: 2.509552001953125
Validation loss: 2.385167896106679

Epoch: 6| Step: 1
Training loss: 2.665191411972046
Validation loss: 2.36497430006663

Epoch: 6| Step: 2
Training loss: 2.958054542541504
Validation loss: 2.3472500744686333

Epoch: 6| Step: 3
Training loss: 2.919440269470215
Validation loss: 2.3519942017011743

Epoch: 6| Step: 4
Training loss: 2.837045669555664
Validation loss: 2.3412125277262863

Epoch: 6| Step: 5
Training loss: 2.5496292114257812
Validation loss: 2.334886440666773

Epoch: 6| Step: 6
Training loss: 1.7590296268463135
Validation loss: 2.331763372626356

Epoch: 6| Step: 7
Training loss: 1.8329174518585205
Validation loss: 2.3294155956596456

Epoch: 6| Step: 8
Training loss: 2.675827980041504
Validation loss: 2.3383503703660864

Epoch: 6| Step: 9
Training loss: 1.860323190689087
Validation loss: 2.333507991606189

Epoch: 6| Step: 10
Training loss: 2.5369820594787598
Validation loss: 2.342222200926914

Epoch: 6| Step: 11
Training loss: 2.4469799995422363
Validation loss: 2.343418308483657

Epoch: 6| Step: 12
Training loss: 2.7150535583496094
Validation loss: 2.3629932865019767

Epoch: 6| Step: 13
Training loss: 3.3777987957000732
Validation loss: 2.3792606425541702

Epoch: 296| Step: 0
Training loss: 2.8796844482421875
Validation loss: 2.408629914765717

Epoch: 6| Step: 1
Training loss: 2.330990791320801
Validation loss: 2.430345791642384

Epoch: 6| Step: 2
Training loss: 3.0427842140197754
Validation loss: 2.432683890865695

Epoch: 6| Step: 3
Training loss: 2.914790630340576
Validation loss: 2.430253162178942

Epoch: 6| Step: 4
Training loss: 2.7722792625427246
Validation loss: 2.42483357203904

Epoch: 6| Step: 5
Training loss: 2.3659253120422363
Validation loss: 2.4352523075636996

Epoch: 6| Step: 6
Training loss: 2.067824602127075
Validation loss: 2.4274740193479802

Epoch: 6| Step: 7
Training loss: 2.6874687671661377
Validation loss: 2.422483987705682

Epoch: 6| Step: 8
Training loss: 2.2530503273010254
Validation loss: 2.420730124237717

Epoch: 6| Step: 9
Training loss: 1.904984951019287
Validation loss: 2.4099235842304845

Epoch: 6| Step: 10
Training loss: 2.397481918334961
Validation loss: 2.383492944061115

Epoch: 6| Step: 11
Training loss: 2.243581533432007
Validation loss: 2.3741158234175814

Epoch: 6| Step: 12
Training loss: 2.8624908924102783
Validation loss: 2.36251591097924

Epoch: 6| Step: 13
Training loss: 2.2968764305114746
Validation loss: 2.3690521845253567

Epoch: 297| Step: 0
Training loss: 2.5623912811279297
Validation loss: 2.3637461944292952

Epoch: 6| Step: 1
Training loss: 3.036761999130249
Validation loss: 2.3684378875199186

Epoch: 6| Step: 2
Training loss: 1.8445236682891846
Validation loss: 2.358299155389109

Epoch: 6| Step: 3
Training loss: 2.344550371170044
Validation loss: 2.351984688030776

Epoch: 6| Step: 4
Training loss: 2.6058762073516846
Validation loss: 2.3482640712491927

Epoch: 6| Step: 5
Training loss: 2.767530679702759
Validation loss: 2.3539931569048154

Epoch: 6| Step: 6
Training loss: 2.4953699111938477
Validation loss: 2.3731826787353842

Epoch: 6| Step: 7
Training loss: 1.94491446018219
Validation loss: 2.3710746278044996

Epoch: 6| Step: 8
Training loss: 2.650322914123535
Validation loss: 2.3702058305022535

Epoch: 6| Step: 9
Training loss: 2.317122459411621
Validation loss: 2.3668200815877607

Epoch: 6| Step: 10
Training loss: 2.514397144317627
Validation loss: 2.377162141184653

Epoch: 6| Step: 11
Training loss: 2.1793160438537598
Validation loss: 2.3601282809370305

Epoch: 6| Step: 12
Training loss: 3.274562358856201
Validation loss: 2.3493116773584837

Epoch: 6| Step: 13
Training loss: 2.686009168624878
Validation loss: 2.343345760017313

Epoch: 298| Step: 0
Training loss: 2.661130905151367
Validation loss: 2.3598633350864535

Epoch: 6| Step: 1
Training loss: 1.9608200788497925
Validation loss: 2.3522999748106925

Epoch: 6| Step: 2
Training loss: 2.604907512664795
Validation loss: 2.3635860643079205

Epoch: 6| Step: 3
Training loss: 2.3293659687042236
Validation loss: 2.3664286892901183

Epoch: 6| Step: 4
Training loss: 1.8794364929199219
Validation loss: 2.3778243372517247

Epoch: 6| Step: 5
Training loss: 2.362056016921997
Validation loss: 2.3650918417079474

Epoch: 6| Step: 6
Training loss: 3.3451056480407715
Validation loss: 2.361189939642465

Epoch: 6| Step: 7
Training loss: 3.2559051513671875
Validation loss: 2.361545867817376

Epoch: 6| Step: 8
Training loss: 2.2485694885253906
Validation loss: 2.365446108643727

Epoch: 6| Step: 9
Training loss: 1.995652198791504
Validation loss: 2.369389428887316

Epoch: 6| Step: 10
Training loss: 2.0508923530578613
Validation loss: 2.363894477967293

Epoch: 6| Step: 11
Training loss: 2.596895694732666
Validation loss: 2.3786512433841662

Epoch: 6| Step: 12
Training loss: 2.964564800262451
Validation loss: 2.376716706060594

Epoch: 6| Step: 13
Training loss: 2.934873104095459
Validation loss: 2.373912675406343

Epoch: 299| Step: 0
Training loss: 1.9690827131271362
Validation loss: 2.3591782739085536

Epoch: 6| Step: 1
Training loss: 2.590986728668213
Validation loss: 2.3661505970903622

Epoch: 6| Step: 2
Training loss: 1.8472007513046265
Validation loss: 2.376215104133852

Epoch: 6| Step: 3
Training loss: 2.3026108741760254
Validation loss: 2.391434515676191

Epoch: 6| Step: 4
Training loss: 2.695772886276245
Validation loss: 2.4011635267606346

Epoch: 6| Step: 5
Training loss: 3.1475706100463867
Validation loss: 2.3989821428893716

Epoch: 6| Step: 6
Training loss: 3.118180751800537
Validation loss: 2.384131025242549

Epoch: 6| Step: 7
Training loss: 2.656893491744995
Validation loss: 2.357781305108019

Epoch: 6| Step: 8
Training loss: 2.5035290718078613
Validation loss: 2.3585992141436507

Epoch: 6| Step: 9
Training loss: 1.499515414237976
Validation loss: 2.3531861715419318

Epoch: 6| Step: 10
Training loss: 2.5495009422302246
Validation loss: 2.359156982873076

Epoch: 6| Step: 11
Training loss: 2.941429853439331
Validation loss: 2.346283712694722

Epoch: 6| Step: 12
Training loss: 2.6274654865264893
Validation loss: 2.3363613723426737

Epoch: 6| Step: 13
Training loss: 2.649043560028076
Validation loss: 2.342496492529428

Epoch: 300| Step: 0
Training loss: 1.5199122428894043
Validation loss: 2.3492210629165813

Epoch: 6| Step: 1
Training loss: 2.181426525115967
Validation loss: 2.354444824239259

Epoch: 6| Step: 2
Training loss: 2.821866512298584
Validation loss: 2.362134115670317

Epoch: 6| Step: 3
Training loss: 2.8209099769592285
Validation loss: 2.3511756004825717

Epoch: 6| Step: 4
Training loss: 2.915172815322876
Validation loss: 2.3663951145705355

Epoch: 6| Step: 5
Training loss: 2.708855628967285
Validation loss: 2.3776575621738227

Epoch: 6| Step: 6
Training loss: 2.5989136695861816
Validation loss: 2.4032516402582966

Epoch: 6| Step: 7
Training loss: 3.006479263305664
Validation loss: 2.4077770991991927

Epoch: 6| Step: 8
Training loss: 1.7173430919647217
Validation loss: 2.4090687254423737

Epoch: 6| Step: 9
Training loss: 2.0706779956817627
Validation loss: 2.3985352900720414

Epoch: 6| Step: 10
Training loss: 2.230740547180176
Validation loss: 2.3879095149296585

Epoch: 6| Step: 11
Training loss: 2.773186206817627
Validation loss: 2.3848982703301216

Epoch: 6| Step: 12
Training loss: 2.864353656768799
Validation loss: 2.384328538371671

Epoch: 6| Step: 13
Training loss: 2.9629571437835693
Validation loss: 2.367238195993567

Epoch: 301| Step: 0
Training loss: 2.382516622543335
Validation loss: 2.3789636858047976

Epoch: 6| Step: 1
Training loss: 2.965480327606201
Validation loss: 2.3758353007737028

Epoch: 6| Step: 2
Training loss: 2.4739766120910645
Validation loss: 2.3863973963645195

Epoch: 6| Step: 3
Training loss: 2.4949307441711426
Validation loss: 2.381382329489595

Epoch: 6| Step: 4
Training loss: 1.731046199798584
Validation loss: 2.361969801687425

Epoch: 6| Step: 5
Training loss: 2.3110718727111816
Validation loss: 2.360335603837044

Epoch: 6| Step: 6
Training loss: 2.726386070251465
Validation loss: 2.3749752724042503

Epoch: 6| Step: 7
Training loss: 2.3896729946136475
Validation loss: 2.36156105226086

Epoch: 6| Step: 8
Training loss: 2.4643259048461914
Validation loss: 2.3801693736865954

Epoch: 6| Step: 9
Training loss: 2.69071626663208
Validation loss: 2.3918511431704284

Epoch: 6| Step: 10
Training loss: 2.6180155277252197
Validation loss: 2.379391360026534

Epoch: 6| Step: 11
Training loss: 2.8166825771331787
Validation loss: 2.3948732499153382

Epoch: 6| Step: 12
Training loss: 2.096186399459839
Validation loss: 2.377069127175116

Epoch: 6| Step: 13
Training loss: 2.854686737060547
Validation loss: 2.3801155423605316

Epoch: 302| Step: 0
Training loss: 1.8909475803375244
Validation loss: 2.3721424597565846

Epoch: 6| Step: 1
Training loss: 2.845890760421753
Validation loss: 2.3629934608295398

Epoch: 6| Step: 2
Training loss: 2.5537924766540527
Validation loss: 2.381455618848083

Epoch: 6| Step: 3
Training loss: 2.9648900032043457
Validation loss: 2.389186946294641

Epoch: 6| Step: 4
Training loss: 1.8919451236724854
Validation loss: 2.404960513114929

Epoch: 6| Step: 5
Training loss: 1.911035180091858
Validation loss: 2.4124023709245908

Epoch: 6| Step: 6
Training loss: 2.449479103088379
Validation loss: 2.4092893985009964

Epoch: 6| Step: 7
Training loss: 2.995769500732422
Validation loss: 2.4148249139067945

Epoch: 6| Step: 8
Training loss: 2.426351547241211
Validation loss: 2.402034551866593

Epoch: 6| Step: 9
Training loss: 2.5677249431610107
Validation loss: 2.3987404505411782

Epoch: 6| Step: 10
Training loss: 2.201521873474121
Validation loss: 2.3700693294566166

Epoch: 6| Step: 11
Training loss: 1.8960413932800293
Validation loss: 2.378878584472082

Epoch: 6| Step: 12
Training loss: 3.5018606185913086
Validation loss: 2.3686299734218146

Epoch: 6| Step: 13
Training loss: 3.0543363094329834
Validation loss: 2.364551600589547

Epoch: 303| Step: 0
Training loss: 2.4916489124298096
Validation loss: 2.355393619947536

Epoch: 6| Step: 1
Training loss: 2.193394660949707
Validation loss: 2.3534342396643853

Epoch: 6| Step: 2
Training loss: 2.96732759475708
Validation loss: 2.334388698301008

Epoch: 6| Step: 3
Training loss: 2.454633951187134
Validation loss: 2.3312061422614643

Epoch: 6| Step: 4
Training loss: 2.617375612258911
Validation loss: 2.348679619450723

Epoch: 6| Step: 5
Training loss: 2.1651928424835205
Validation loss: 2.3579234794903825

Epoch: 6| Step: 6
Training loss: 2.1249136924743652
Validation loss: 2.356871417773667

Epoch: 6| Step: 7
Training loss: 1.840314507484436
Validation loss: 2.3799187983236005

Epoch: 6| Step: 8
Training loss: 2.233071804046631
Validation loss: 2.376152066774266

Epoch: 6| Step: 9
Training loss: 3.11950421333313
Validation loss: 2.3772972194097375

Epoch: 6| Step: 10
Training loss: 2.6395978927612305
Validation loss: 2.3917156034900295

Epoch: 6| Step: 11
Training loss: 2.2734153270721436
Validation loss: 2.3761453987449728

Epoch: 6| Step: 12
Training loss: 3.258204698562622
Validation loss: 2.400726690087267

Epoch: 6| Step: 13
Training loss: 2.6667377948760986
Validation loss: 2.3713304176125476

Epoch: 304| Step: 0
Training loss: 2.0734853744506836
Validation loss: 2.3606777703890236

Epoch: 6| Step: 1
Training loss: 2.3824691772460938
Validation loss: 2.3539947566165718

Epoch: 6| Step: 2
Training loss: 1.8594293594360352
Validation loss: 2.3514022160601873

Epoch: 6| Step: 3
Training loss: 1.862656593322754
Validation loss: 2.3327577601196947

Epoch: 6| Step: 4
Training loss: 2.9133028984069824
Validation loss: 2.3363756236209663

Epoch: 6| Step: 5
Training loss: 2.391024112701416
Validation loss: 2.322551865731516

Epoch: 6| Step: 6
Training loss: 2.346435785293579
Validation loss: 2.3314797339900846

Epoch: 6| Step: 7
Training loss: 3.388597011566162
Validation loss: 2.339068425598965

Epoch: 6| Step: 8
Training loss: 2.5256688594818115
Validation loss: 2.333031303139143

Epoch: 6| Step: 9
Training loss: 2.829366445541382
Validation loss: 2.340713947050033

Epoch: 6| Step: 10
Training loss: 2.2641918659210205
Validation loss: 2.342091093781174

Epoch: 6| Step: 11
Training loss: 2.504815101623535
Validation loss: 2.3496343243506645

Epoch: 6| Step: 12
Training loss: 2.2483034133911133
Validation loss: 2.3410541601078485

Epoch: 6| Step: 13
Training loss: 3.7738332748413086
Validation loss: 2.380741721840315

Epoch: 305| Step: 0
Training loss: 2.5353338718414307
Validation loss: 2.4024588100371824

Epoch: 6| Step: 1
Training loss: 2.791571617126465
Validation loss: 2.4250914896688154

Epoch: 6| Step: 2
Training loss: 2.836005687713623
Validation loss: 2.4404300489733295

Epoch: 6| Step: 3
Training loss: 2.5159876346588135
Validation loss: 2.4422820357866186

Epoch: 6| Step: 4
Training loss: 2.807584762573242
Validation loss: 2.426526205514067

Epoch: 6| Step: 5
Training loss: 1.6836237907409668
Validation loss: 2.436049948456467

Epoch: 6| Step: 6
Training loss: 2.339144229888916
Validation loss: 2.4402462410670456

Epoch: 6| Step: 7
Training loss: 1.851570725440979
Validation loss: 2.4027457314152874

Epoch: 6| Step: 8
Training loss: 2.5330522060394287
Validation loss: 2.3581567502790883

Epoch: 6| Step: 9
Training loss: 2.9693245887756348
Validation loss: 2.3415057607876357

Epoch: 6| Step: 10
Training loss: 1.9901456832885742
Validation loss: 2.344852311636812

Epoch: 6| Step: 11
Training loss: 2.4511022567749023
Validation loss: 2.348637624453473

Epoch: 6| Step: 12
Training loss: 2.6980926990509033
Validation loss: 2.366208243113692

Epoch: 6| Step: 13
Training loss: 3.2923622131347656
Validation loss: 2.382662296295166

Epoch: 306| Step: 0
Training loss: 2.6000609397888184
Validation loss: 2.3732330927284817

Epoch: 6| Step: 1
Training loss: 2.036019802093506
Validation loss: 2.376705446550923

Epoch: 6| Step: 2
Training loss: 3.035216808319092
Validation loss: 2.360702109593217

Epoch: 6| Step: 3
Training loss: 2.303953170776367
Validation loss: 2.3363303779273905

Epoch: 6| Step: 4
Training loss: 2.2794580459594727
Validation loss: 2.344366547881916

Epoch: 6| Step: 5
Training loss: 1.9725048542022705
Validation loss: 2.3346383751079602

Epoch: 6| Step: 6
Training loss: 2.8046083450317383
Validation loss: 2.3446505300460325

Epoch: 6| Step: 7
Training loss: 3.746680498123169
Validation loss: 2.362958503025834

Epoch: 6| Step: 8
Training loss: 2.4530158042907715
Validation loss: 2.357005714088358

Epoch: 6| Step: 9
Training loss: 2.1338589191436768
Validation loss: 2.3649037948218723

Epoch: 6| Step: 10
Training loss: 2.1371078491210938
Validation loss: 2.3744568209494314

Epoch: 6| Step: 11
Training loss: 2.304610013961792
Validation loss: 2.3840553811801377

Epoch: 6| Step: 12
Training loss: 3.076373338699341
Validation loss: 2.432564189357142

Epoch: 6| Step: 13
Training loss: 1.7551229000091553
Validation loss: 2.4192835054089947

Epoch: 307| Step: 0
Training loss: 3.368459701538086
Validation loss: 2.3861501883434992

Epoch: 6| Step: 1
Training loss: 2.0026018619537354
Validation loss: 2.3686821691451536

Epoch: 6| Step: 2
Training loss: 2.4116811752319336
Validation loss: 2.358610409562306

Epoch: 6| Step: 3
Training loss: 3.360948085784912
Validation loss: 2.3532115849115516

Epoch: 6| Step: 4
Training loss: 1.6393331289291382
Validation loss: 2.3532368906082644

Epoch: 6| Step: 5
Training loss: 2.0116429328918457
Validation loss: 2.3435926181013866

Epoch: 6| Step: 6
Training loss: 3.1403660774230957
Validation loss: 2.3534226007359003

Epoch: 6| Step: 7
Training loss: 1.816201090812683
Validation loss: 2.347500393467565

Epoch: 6| Step: 8
Training loss: 2.935955762863159
Validation loss: 2.3470906134574645

Epoch: 6| Step: 9
Training loss: 2.530215263366699
Validation loss: 2.360689681063416

Epoch: 6| Step: 10
Training loss: 2.6376380920410156
Validation loss: 2.3596176742225565

Epoch: 6| Step: 11
Training loss: 2.208217144012451
Validation loss: 2.3599918106550812

Epoch: 6| Step: 12
Training loss: 2.035628080368042
Validation loss: 2.3636431514575915

Epoch: 6| Step: 13
Training loss: 2.7506465911865234
Validation loss: 2.3823926064275924

Epoch: 308| Step: 0
Training loss: 2.4704127311706543
Validation loss: 2.3627319438483125

Epoch: 6| Step: 1
Training loss: 2.6354966163635254
Validation loss: 2.3772566164693525

Epoch: 6| Step: 2
Training loss: 2.5506625175476074
Validation loss: 2.3806604339230444

Epoch: 6| Step: 3
Training loss: 2.347031593322754
Validation loss: 2.379695741079187

Epoch: 6| Step: 4
Training loss: 2.5767250061035156
Validation loss: 2.3653442167466685

Epoch: 6| Step: 5
Training loss: 3.405643939971924
Validation loss: 2.3626615129491335

Epoch: 6| Step: 6
Training loss: 1.7625491619110107
Validation loss: 2.335340428095992

Epoch: 6| Step: 7
Training loss: 1.854071021080017
Validation loss: 2.342487782560369

Epoch: 6| Step: 8
Training loss: 2.868197441101074
Validation loss: 2.3512615080802672

Epoch: 6| Step: 9
Training loss: 2.5160491466522217
Validation loss: 2.3443002470078005

Epoch: 6| Step: 10
Training loss: 2.6189353466033936
Validation loss: 2.3376131083375666

Epoch: 6| Step: 11
Training loss: 2.2006473541259766
Validation loss: 2.3371026336505847

Epoch: 6| Step: 12
Training loss: 2.698378562927246
Validation loss: 2.334738390420073

Epoch: 6| Step: 13
Training loss: 2.133439064025879
Validation loss: 2.337981063832519

Epoch: 309| Step: 0
Training loss: 2.551264762878418
Validation loss: 2.3483536063983874

Epoch: 6| Step: 1
Training loss: 2.211928367614746
Validation loss: 2.3430956435459915

Epoch: 6| Step: 2
Training loss: 2.0317440032958984
Validation loss: 2.340822042957429

Epoch: 6| Step: 3
Training loss: 2.4080381393432617
Validation loss: 2.33988404914897

Epoch: 6| Step: 4
Training loss: 2.268244981765747
Validation loss: 2.3703628714366625

Epoch: 6| Step: 5
Training loss: 2.6334915161132812
Validation loss: 2.372222623517436

Epoch: 6| Step: 6
Training loss: 2.636460065841675
Validation loss: 2.3699676785417783

Epoch: 6| Step: 7
Training loss: 2.4538962841033936
Validation loss: 2.400134225045481

Epoch: 6| Step: 8
Training loss: 3.0858664512634277
Validation loss: 2.4118455045966694

Epoch: 6| Step: 9
Training loss: 2.9079766273498535
Validation loss: 2.414903586910617

Epoch: 6| Step: 10
Training loss: 2.0915462970733643
Validation loss: 2.391342229740594

Epoch: 6| Step: 11
Training loss: 2.380082607269287
Validation loss: 2.3935775218471402

Epoch: 6| Step: 12
Training loss: 2.602450370788574
Validation loss: 2.383773688347109

Epoch: 6| Step: 13
Training loss: 2.2288832664489746
Validation loss: 2.3668088246417303

Epoch: 310| Step: 0
Training loss: 2.513084888458252
Validation loss: 2.3449671319735947

Epoch: 6| Step: 1
Training loss: 1.6861242055892944
Validation loss: 2.3536194345002532

Epoch: 6| Step: 2
Training loss: 1.7391451597213745
Validation loss: 2.3419594892891507

Epoch: 6| Step: 3
Training loss: 3.6239213943481445
Validation loss: 2.3449503580729165

Epoch: 6| Step: 4
Training loss: 2.5033278465270996
Validation loss: 2.3408628907254947

Epoch: 6| Step: 5
Training loss: 1.953338623046875
Validation loss: 2.346389642325781

Epoch: 6| Step: 6
Training loss: 2.9077212810516357
Validation loss: 2.338978185448595

Epoch: 6| Step: 7
Training loss: 1.9575685262680054
Validation loss: 2.3471469007512575

Epoch: 6| Step: 8
Training loss: 2.051361560821533
Validation loss: 2.3571195487053163

Epoch: 6| Step: 9
Training loss: 2.831662178039551
Validation loss: 2.372836894886468

Epoch: 6| Step: 10
Training loss: 2.9250330924987793
Validation loss: 2.3855987133518344

Epoch: 6| Step: 11
Training loss: 2.993795871734619
Validation loss: 2.3732744160518853

Epoch: 6| Step: 12
Training loss: 2.7529077529907227
Validation loss: 2.3783349349934566

Epoch: 6| Step: 13
Training loss: 1.9510411024093628
Validation loss: 2.3835690354788177

Epoch: 311| Step: 0
Training loss: 2.0956807136535645
Validation loss: 2.381758423261745

Epoch: 6| Step: 1
Training loss: 3.3930275440216064
Validation loss: 2.3699735415879117

Epoch: 6| Step: 2
Training loss: 2.9294309616088867
Validation loss: 2.372787424313125

Epoch: 6| Step: 3
Training loss: 2.52591609954834
Validation loss: 2.357178485521706

Epoch: 6| Step: 4
Training loss: 2.2263693809509277
Validation loss: 2.346992920803767

Epoch: 6| Step: 5
Training loss: 2.7673990726470947
Validation loss: 2.3555847034659436

Epoch: 6| Step: 6
Training loss: 2.2646572589874268
Validation loss: 2.3319325165082048

Epoch: 6| Step: 7
Training loss: 3.338581085205078
Validation loss: 2.337738193491454

Epoch: 6| Step: 8
Training loss: 3.327208995819092
Validation loss: 2.3450093551348616

Epoch: 6| Step: 9
Training loss: 2.1509828567504883
Validation loss: 2.359925495680942

Epoch: 6| Step: 10
Training loss: 2.0940101146698
Validation loss: 2.3615166371868503

Epoch: 6| Step: 11
Training loss: 1.3812233209609985
Validation loss: 2.365539558472172

Epoch: 6| Step: 12
Training loss: 2.159410238265991
Validation loss: 2.3766301319163334

Epoch: 6| Step: 13
Training loss: 1.9628976583480835
Validation loss: 2.369964753427813

Epoch: 312| Step: 0
Training loss: 3.292762279510498
Validation loss: 2.3634997696004887

Epoch: 6| Step: 1
Training loss: 2.6657872200012207
Validation loss: 2.3722309271494546

Epoch: 6| Step: 2
Training loss: 2.962613582611084
Validation loss: 2.366484334391932

Epoch: 6| Step: 3
Training loss: 3.1064162254333496
Validation loss: 2.3570110259517545

Epoch: 6| Step: 4
Training loss: 2.535799980163574
Validation loss: 2.364867341133856

Epoch: 6| Step: 5
Training loss: 2.8179047107696533
Validation loss: 2.366358773682707

Epoch: 6| Step: 6
Training loss: 2.4217216968536377
Validation loss: 2.382450249887282

Epoch: 6| Step: 7
Training loss: 1.7832224369049072
Validation loss: 2.3670519269922727

Epoch: 6| Step: 8
Training loss: 2.3404226303100586
Validation loss: 2.379682166602022

Epoch: 6| Step: 9
Training loss: 1.500504732131958
Validation loss: 2.3673617737267607

Epoch: 6| Step: 10
Training loss: 1.8323856592178345
Validation loss: 2.3806385045410483

Epoch: 6| Step: 11
Training loss: 2.3589835166931152
Validation loss: 2.3831378593239734

Epoch: 6| Step: 12
Training loss: 2.3798341751098633
Validation loss: 2.390131852960074

Epoch: 6| Step: 13
Training loss: 2.5034008026123047
Validation loss: 2.371813074234993

Epoch: 313| Step: 0
Training loss: 1.9452258348464966
Validation loss: 2.3635857259073565

Epoch: 6| Step: 1
Training loss: 2.9577536582946777
Validation loss: 2.3579216593055317

Epoch: 6| Step: 2
Training loss: 2.357100486755371
Validation loss: 2.3556121831299155

Epoch: 6| Step: 3
Training loss: 1.3436124324798584
Validation loss: 2.3682949055907545

Epoch: 6| Step: 4
Training loss: 2.6636316776275635
Validation loss: 2.3798136147119666

Epoch: 6| Step: 5
Training loss: 3.1312074661254883
Validation loss: 2.3958505661256853

Epoch: 6| Step: 6
Training loss: 3.0455307960510254
Validation loss: 2.4096344312032065

Epoch: 6| Step: 7
Training loss: 2.739201307296753
Validation loss: 2.3981347596773537

Epoch: 6| Step: 8
Training loss: 2.5348682403564453
Validation loss: 2.3971368779418287

Epoch: 6| Step: 9
Training loss: 2.568751811981201
Validation loss: 2.361614052967359

Epoch: 6| Step: 10
Training loss: 2.033456563949585
Validation loss: 2.348458533645958

Epoch: 6| Step: 11
Training loss: 2.0891361236572266
Validation loss: 2.3433138055186116

Epoch: 6| Step: 12
Training loss: 2.4675111770629883
Validation loss: 2.3419245340490855

Epoch: 6| Step: 13
Training loss: 2.5905861854553223
Validation loss: 2.341542613121771

Epoch: 314| Step: 0
Training loss: 3.0393669605255127
Validation loss: 2.3396710170212613

Epoch: 6| Step: 1
Training loss: 2.5404820442199707
Validation loss: 2.348638347400132

Epoch: 6| Step: 2
Training loss: 2.48828125
Validation loss: 2.3535654955012824

Epoch: 6| Step: 3
Training loss: 2.838702917098999
Validation loss: 2.36027632733827

Epoch: 6| Step: 4
Training loss: 2.18098783493042
Validation loss: 2.3492457969214326

Epoch: 6| Step: 5
Training loss: 1.9449769258499146
Validation loss: 2.3503051445048344

Epoch: 6| Step: 6
Training loss: 2.3267979621887207
Validation loss: 2.3510350296574254

Epoch: 6| Step: 7
Training loss: 2.6107141971588135
Validation loss: 2.365045908958681

Epoch: 6| Step: 8
Training loss: 2.162179946899414
Validation loss: 2.373410330023817

Epoch: 6| Step: 9
Training loss: 2.6286182403564453
Validation loss: 2.387191029005153

Epoch: 6| Step: 10
Training loss: 2.161850929260254
Validation loss: 2.405711322702387

Epoch: 6| Step: 11
Training loss: 2.413773536682129
Validation loss: 2.403666188639979

Epoch: 6| Step: 12
Training loss: 2.747012138366699
Validation loss: 2.4188680700076524

Epoch: 6| Step: 13
Training loss: 2.6397461891174316
Validation loss: 2.4058597831315893

Epoch: 315| Step: 0
Training loss: 1.9345042705535889
Validation loss: 2.3862170583458355

Epoch: 6| Step: 1
Training loss: 2.103572368621826
Validation loss: 2.369364200099822

Epoch: 6| Step: 2
Training loss: 2.973454475402832
Validation loss: 2.34043030072284

Epoch: 6| Step: 3
Training loss: 1.9755918979644775
Validation loss: 2.3400937690529773

Epoch: 6| Step: 4
Training loss: 1.7176971435546875
Validation loss: 2.3354353238177556

Epoch: 6| Step: 5
Training loss: 2.708792209625244
Validation loss: 2.3308381008845505

Epoch: 6| Step: 6
Training loss: 2.9099903106689453
Validation loss: 2.325389644151093

Epoch: 6| Step: 7
Training loss: 2.285961866378784
Validation loss: 2.3214411632989043

Epoch: 6| Step: 8
Training loss: 2.2263925075531006
Validation loss: 2.3242829871434036

Epoch: 6| Step: 9
Training loss: 2.489450693130493
Validation loss: 2.335348747109854

Epoch: 6| Step: 10
Training loss: 2.9203624725341797
Validation loss: 2.3323948370513095

Epoch: 6| Step: 11
Training loss: 3.3117053508758545
Validation loss: 2.3374420853071314

Epoch: 6| Step: 12
Training loss: 2.7672340869903564
Validation loss: 2.3432400175320205

Epoch: 6| Step: 13
Training loss: 2.000819206237793
Validation loss: 2.3388694563219623

Epoch: 316| Step: 0
Training loss: 2.422616481781006
Validation loss: 2.3651432760300173

Epoch: 6| Step: 1
Training loss: 2.1074624061584473
Validation loss: 2.3921482383563952

Epoch: 6| Step: 2
Training loss: 3.2277655601501465
Validation loss: 2.4409277567299466

Epoch: 6| Step: 3
Training loss: 2.36352276802063
Validation loss: 2.440928151530604

Epoch: 6| Step: 4
Training loss: 2.031024932861328
Validation loss: 2.4588932042480796

Epoch: 6| Step: 5
Training loss: 1.7828747034072876
Validation loss: 2.4388669844596618

Epoch: 6| Step: 6
Training loss: 2.7292566299438477
Validation loss: 2.400752770003452

Epoch: 6| Step: 7
Training loss: 2.355764389038086
Validation loss: 2.385264486394903

Epoch: 6| Step: 8
Training loss: 2.24336576461792
Validation loss: 2.383255571447393

Epoch: 6| Step: 9
Training loss: 2.5218257904052734
Validation loss: 2.360093883288804

Epoch: 6| Step: 10
Training loss: 2.7890141010284424
Validation loss: 2.361339512691703

Epoch: 6| Step: 11
Training loss: 2.7870888710021973
Validation loss: 2.3528827146817277

Epoch: 6| Step: 12
Training loss: 2.7066688537597656
Validation loss: 2.3561983980158323

Epoch: 6| Step: 13
Training loss: 2.5604772567749023
Validation loss: 2.358115606410529

Epoch: 317| Step: 0
Training loss: 1.4412271976470947
Validation loss: 2.343126307251633

Epoch: 6| Step: 1
Training loss: 1.9048610925674438
Validation loss: 2.3496349396244174

Epoch: 6| Step: 2
Training loss: 2.8887269496917725
Validation loss: 2.3455437934526833

Epoch: 6| Step: 3
Training loss: 2.064159393310547
Validation loss: 2.3449221118803947

Epoch: 6| Step: 4
Training loss: 2.545945167541504
Validation loss: 2.352230638586065

Epoch: 6| Step: 5
Training loss: 2.896613597869873
Validation loss: 2.3703361095920688

Epoch: 6| Step: 6
Training loss: 2.1916770935058594
Validation loss: 2.3616105433433288

Epoch: 6| Step: 7
Training loss: 2.7590370178222656
Validation loss: 2.3644361752335743

Epoch: 6| Step: 8
Training loss: 2.4907541275024414
Validation loss: 2.3718877120684554

Epoch: 6| Step: 9
Training loss: 2.563897132873535
Validation loss: 2.3710227166452715

Epoch: 6| Step: 10
Training loss: 3.1458489894866943
Validation loss: 2.3555404140103247

Epoch: 6| Step: 11
Training loss: 3.3240628242492676
Validation loss: 2.3585006831794657

Epoch: 6| Step: 12
Training loss: 1.7943754196166992
Validation loss: 2.3702561932225383

Epoch: 6| Step: 13
Training loss: 2.379786729812622
Validation loss: 2.3626605464566137

Epoch: 318| Step: 0
Training loss: 2.3748555183410645
Validation loss: 2.3515253772017775

Epoch: 6| Step: 1
Training loss: 2.6057305335998535
Validation loss: 2.347127834955851

Epoch: 6| Step: 2
Training loss: 1.9489169120788574
Validation loss: 2.3396290822695662

Epoch: 6| Step: 3
Training loss: 2.6896238327026367
Validation loss: 2.322335425243583

Epoch: 6| Step: 4
Training loss: 2.296947479248047
Validation loss: 2.3219156598532074

Epoch: 6| Step: 5
Training loss: 2.5603251457214355
Validation loss: 2.330888266204506

Epoch: 6| Step: 6
Training loss: 2.930128335952759
Validation loss: 2.332922840631136

Epoch: 6| Step: 7
Training loss: 2.312225341796875
Validation loss: 2.349778218935895

Epoch: 6| Step: 8
Training loss: 2.3384501934051514
Validation loss: 2.3516955939672326

Epoch: 6| Step: 9
Training loss: 2.839707851409912
Validation loss: 2.3596257907088085

Epoch: 6| Step: 10
Training loss: 2.6211934089660645
Validation loss: 2.367780335487858

Epoch: 6| Step: 11
Training loss: 2.233595371246338
Validation loss: 2.3630058509047314

Epoch: 6| Step: 12
Training loss: 2.9629886150360107
Validation loss: 2.3777671424291467

Epoch: 6| Step: 13
Training loss: 0.9406607151031494
Validation loss: 2.3739023234254573

Epoch: 319| Step: 0
Training loss: 2.142134428024292
Validation loss: 2.36213263644967

Epoch: 6| Step: 1
Training loss: 2.4562277793884277
Validation loss: 2.3647623523589103

Epoch: 6| Step: 2
Training loss: 1.942158579826355
Validation loss: 2.3465687613333426

Epoch: 6| Step: 3
Training loss: 2.6078829765319824
Validation loss: 2.3350811337911956

Epoch: 6| Step: 4
Training loss: 3.4487369060516357
Validation loss: 2.345651964987478

Epoch: 6| Step: 5
Training loss: 2.877981185913086
Validation loss: 2.3358387203626734

Epoch: 6| Step: 6
Training loss: 1.624497890472412
Validation loss: 2.341917722455917

Epoch: 6| Step: 7
Training loss: 2.5719685554504395
Validation loss: 2.334756615341351

Epoch: 6| Step: 8
Training loss: 3.0938358306884766
Validation loss: 2.347683124644782

Epoch: 6| Step: 9
Training loss: 2.196197986602783
Validation loss: 2.347597840011761

Epoch: 6| Step: 10
Training loss: 2.1697776317596436
Validation loss: 2.3476141370752805

Epoch: 6| Step: 11
Training loss: 2.045772075653076
Validation loss: 2.371289130180113

Epoch: 6| Step: 12
Training loss: 2.8528616428375244
Validation loss: 2.400423167854227

Epoch: 6| Step: 13
Training loss: 2.053739309310913
Validation loss: 2.41536372195008

Epoch: 320| Step: 0
Training loss: 2.8527731895446777
Validation loss: 2.42169520162767

Epoch: 6| Step: 1
Training loss: 2.961639642715454
Validation loss: 2.393135109255391

Epoch: 6| Step: 2
Training loss: 2.1670494079589844
Validation loss: 2.3722911188679356

Epoch: 6| Step: 3
Training loss: 2.1930673122406006
Validation loss: 2.3533983538227696

Epoch: 6| Step: 4
Training loss: 2.1943929195404053
Validation loss: 2.3629746257617907

Epoch: 6| Step: 5
Training loss: 2.358058452606201
Validation loss: 2.341153106381816

Epoch: 6| Step: 6
Training loss: 2.1096293926239014
Validation loss: 2.344595960391465

Epoch: 6| Step: 7
Training loss: 2.8481876850128174
Validation loss: 2.337315925987818

Epoch: 6| Step: 8
Training loss: 2.5763258934020996
Validation loss: 2.3383264746717227

Epoch: 6| Step: 9
Training loss: 2.7249927520751953
Validation loss: 2.333378186789892

Epoch: 6| Step: 10
Training loss: 2.3644871711730957
Validation loss: 2.3460615770791167

Epoch: 6| Step: 11
Training loss: 2.2613813877105713
Validation loss: 2.35826737137251

Epoch: 6| Step: 12
Training loss: 2.278599977493286
Validation loss: 2.355615582517398

Epoch: 6| Step: 13
Training loss: 2.2795021533966064
Validation loss: 2.3579258252215642

Epoch: 321| Step: 0
Training loss: 2.1436386108398438
Validation loss: 2.3833076261704966

Epoch: 6| Step: 1
Training loss: 2.3949036598205566
Validation loss: 2.384521738175423

Epoch: 6| Step: 2
Training loss: 2.439727544784546
Validation loss: 2.370079081545594

Epoch: 6| Step: 3
Training loss: 1.422646403312683
Validation loss: 2.374157659469112

Epoch: 6| Step: 4
Training loss: 3.2863545417785645
Validation loss: 2.3555714238074517

Epoch: 6| Step: 5
Training loss: 2.8012917041778564
Validation loss: 2.3611408305424515

Epoch: 6| Step: 6
Training loss: 2.082714796066284
Validation loss: 2.345341904188997

Epoch: 6| Step: 7
Training loss: 2.420827865600586
Validation loss: 2.3577686432869203

Epoch: 6| Step: 8
Training loss: 2.7436158657073975
Validation loss: 2.3270894865835867

Epoch: 6| Step: 9
Training loss: 2.16862416267395
Validation loss: 2.3381450253148235

Epoch: 6| Step: 10
Training loss: 2.660654067993164
Validation loss: 2.3543621468287643

Epoch: 6| Step: 11
Training loss: 2.285346508026123
Validation loss: 2.3325436089628484

Epoch: 6| Step: 12
Training loss: 2.7000834941864014
Validation loss: 2.34398942096259

Epoch: 6| Step: 13
Training loss: 2.5448598861694336
Validation loss: 2.3547368511076896

Epoch: 322| Step: 0
Training loss: 2.107027530670166
Validation loss: 2.3687146120173956

Epoch: 6| Step: 1
Training loss: 3.406766414642334
Validation loss: 2.37843825996563

Epoch: 6| Step: 2
Training loss: 2.2702555656433105
Validation loss: 2.3795879886996363

Epoch: 6| Step: 3
Training loss: 2.4897732734680176
Validation loss: 2.388776594592679

Epoch: 6| Step: 4
Training loss: 2.1568288803100586
Validation loss: 2.369499624416392

Epoch: 6| Step: 5
Training loss: 2.9764115810394287
Validation loss: 2.3684862147095385

Epoch: 6| Step: 6
Training loss: 2.592655658721924
Validation loss: 2.3447804117715485

Epoch: 6| Step: 7
Training loss: 2.534956455230713
Validation loss: 2.3174267584277737

Epoch: 6| Step: 8
Training loss: 2.261859893798828
Validation loss: 2.325583742510888

Epoch: 6| Step: 9
Training loss: 2.123155117034912
Validation loss: 2.317481827992265

Epoch: 6| Step: 10
Training loss: 1.6847522258758545
Validation loss: 2.327769810153592

Epoch: 6| Step: 11
Training loss: 2.2449190616607666
Validation loss: 2.3438039415626117

Epoch: 6| Step: 12
Training loss: 2.3194522857666016
Validation loss: 2.3582222794973724

Epoch: 6| Step: 13
Training loss: 3.4948856830596924
Validation loss: 2.36381350281418

Epoch: 323| Step: 0
Training loss: 1.7213435173034668
Validation loss: 2.3717716458023235

Epoch: 6| Step: 1
Training loss: 2.5097084045410156
Validation loss: 2.373264971599784

Epoch: 6| Step: 2
Training loss: 3.551487922668457
Validation loss: 2.3732764438916276

Epoch: 6| Step: 3
Training loss: 2.490591287612915
Validation loss: 2.3639250416909494

Epoch: 6| Step: 4
Training loss: 1.759048342704773
Validation loss: 2.3610856276686474

Epoch: 6| Step: 5
Training loss: 2.2319841384887695
Validation loss: 2.3653776517478367

Epoch: 6| Step: 6
Training loss: 2.0415492057800293
Validation loss: 2.3703652671588364

Epoch: 6| Step: 7
Training loss: 2.4312243461608887
Validation loss: 2.350288362913234

Epoch: 6| Step: 8
Training loss: 2.788207530975342
Validation loss: 2.3443342126825804

Epoch: 6| Step: 9
Training loss: 2.2422423362731934
Validation loss: 2.340241765463224

Epoch: 6| Step: 10
Training loss: 3.069190740585327
Validation loss: 2.3494724663355018

Epoch: 6| Step: 11
Training loss: 2.285069465637207
Validation loss: 2.330068665166055

Epoch: 6| Step: 12
Training loss: 2.974928379058838
Validation loss: 2.3339600588685725

Epoch: 6| Step: 13
Training loss: 1.520362377166748
Validation loss: 2.3402344898511003

Epoch: 324| Step: 0
Training loss: 2.541322708129883
Validation loss: 2.356532119935559

Epoch: 6| Step: 1
Training loss: 1.8481459617614746
Validation loss: 2.3844816095085553

Epoch: 6| Step: 2
Training loss: 2.9615769386291504
Validation loss: 2.395685736851026

Epoch: 6| Step: 3
Training loss: 2.7901175022125244
Validation loss: 2.405144476121472

Epoch: 6| Step: 4
Training loss: 1.681251049041748
Validation loss: 2.4049631293101976

Epoch: 6| Step: 5
Training loss: 2.3703136444091797
Validation loss: 2.4009028660353793

Epoch: 6| Step: 6
Training loss: 1.9253497123718262
Validation loss: 2.384584685807587

Epoch: 6| Step: 7
Training loss: 2.9172585010528564
Validation loss: 2.3692991964278685

Epoch: 6| Step: 8
Training loss: 1.9736039638519287
Validation loss: 2.374292153184132

Epoch: 6| Step: 9
Training loss: 2.892547607421875
Validation loss: 2.3781755355096634

Epoch: 6| Step: 10
Training loss: 2.5255355834960938
Validation loss: 2.375114679336548

Epoch: 6| Step: 11
Training loss: 3.0218029022216797
Validation loss: 2.3656217154636177

Epoch: 6| Step: 12
Training loss: 2.672574520111084
Validation loss: 2.3628455387648715

Epoch: 6| Step: 13
Training loss: 2.273952007293701
Validation loss: 2.365134980088921

Epoch: 325| Step: 0
Training loss: 1.9539223909378052
Validation loss: 2.3573043205404796

Epoch: 6| Step: 1
Training loss: 2.2498116493225098
Validation loss: 2.379409856693719

Epoch: 6| Step: 2
Training loss: 1.870227336883545
Validation loss: 2.390953440820017

Epoch: 6| Step: 3
Training loss: 2.7035341262817383
Validation loss: 2.4184715529923797

Epoch: 6| Step: 4
Training loss: 2.851762056350708
Validation loss: 2.425335602093768

Epoch: 6| Step: 5
Training loss: 2.8491692543029785
Validation loss: 2.4057215054829917

Epoch: 6| Step: 6
Training loss: 2.2237181663513184
Validation loss: 2.4185032408724547

Epoch: 6| Step: 7
Training loss: 2.825561046600342
Validation loss: 2.3722686844487346

Epoch: 6| Step: 8
Training loss: 2.8049631118774414
Validation loss: 2.3513303546495337

Epoch: 6| Step: 9
Training loss: 2.6431453227996826
Validation loss: 2.3373133418380574

Epoch: 6| Step: 10
Training loss: 1.6576935052871704
Validation loss: 2.327504301583895

Epoch: 6| Step: 11
Training loss: 3.4874513149261475
Validation loss: 2.3279367082862445

Epoch: 6| Step: 12
Training loss: 1.9194473028182983
Validation loss: 2.3274710383466495

Epoch: 6| Step: 13
Training loss: 2.140005350112915
Validation loss: 2.3420938317493727

Epoch: 326| Step: 0
Training loss: 2.3399407863616943
Validation loss: 2.345812000254149

Epoch: 6| Step: 1
Training loss: 3.1560873985290527
Validation loss: 2.3368049590818343

Epoch: 6| Step: 2
Training loss: 2.3556535243988037
Validation loss: 2.331062527113063

Epoch: 6| Step: 3
Training loss: 2.1495771408081055
Validation loss: 2.326365417049777

Epoch: 6| Step: 4
Training loss: 1.8201181888580322
Validation loss: 2.3200253466124177

Epoch: 6| Step: 5
Training loss: 2.385164260864258
Validation loss: 2.326074779674571

Epoch: 6| Step: 6
Training loss: 2.4647274017333984
Validation loss: 2.3373466883936236

Epoch: 6| Step: 7
Training loss: 2.501372814178467
Validation loss: 2.342807715938937

Epoch: 6| Step: 8
Training loss: 3.2219347953796387
Validation loss: 2.3564773528806624

Epoch: 6| Step: 9
Training loss: 1.838925838470459
Validation loss: 2.3776821795330254

Epoch: 6| Step: 10
Training loss: 1.8982422351837158
Validation loss: 2.4035923814260833

Epoch: 6| Step: 11
Training loss: 2.6362192630767822
Validation loss: 2.451291584199475

Epoch: 6| Step: 12
Training loss: 3.086664915084839
Validation loss: 2.4311179678927184

Epoch: 6| Step: 13
Training loss: 2.650723695755005
Validation loss: 2.417456352582542

Epoch: 327| Step: 0
Training loss: 3.1786599159240723
Validation loss: 2.412722203039354

Epoch: 6| Step: 1
Training loss: 2.4167819023132324
Validation loss: 2.3974369341327297

Epoch: 6| Step: 2
Training loss: 3.333271026611328
Validation loss: 2.381892083793558

Epoch: 6| Step: 3
Training loss: 2.4513401985168457
Validation loss: 2.3673736459465435

Epoch: 6| Step: 4
Training loss: 3.124457836151123
Validation loss: 2.3594519758737214

Epoch: 6| Step: 5
Training loss: 3.136929988861084
Validation loss: 2.3602148960995417

Epoch: 6| Step: 6
Training loss: 1.9366801977157593
Validation loss: 2.347743582981889

Epoch: 6| Step: 7
Training loss: 2.3404107093811035
Validation loss: 2.3425126383381505

Epoch: 6| Step: 8
Training loss: 1.6077669858932495
Validation loss: 2.3429654977654897

Epoch: 6| Step: 9
Training loss: 1.8837779760360718
Validation loss: 2.3556900998597503

Epoch: 6| Step: 10
Training loss: 2.713273525238037
Validation loss: 2.355565232615317

Epoch: 6| Step: 11
Training loss: 1.6670923233032227
Validation loss: 2.3525970776875815

Epoch: 6| Step: 12
Training loss: 2.2284066677093506
Validation loss: 2.3558841700194986

Epoch: 6| Step: 13
Training loss: 1.6021753549575806
Validation loss: 2.3669132186520483

Epoch: 328| Step: 0
Training loss: 2.3649368286132812
Validation loss: 2.3472028368262836

Epoch: 6| Step: 1
Training loss: 1.9789305925369263
Validation loss: 2.329852029841433

Epoch: 6| Step: 2
Training loss: 2.652143955230713
Validation loss: 2.33171034115617

Epoch: 6| Step: 3
Training loss: 2.2184784412384033
Validation loss: 2.330124911441598

Epoch: 6| Step: 4
Training loss: 1.4894790649414062
Validation loss: 2.3310399863027755

Epoch: 6| Step: 5
Training loss: 3.195122718811035
Validation loss: 2.328068197414439

Epoch: 6| Step: 6
Training loss: 2.535586357116699
Validation loss: 2.317255381614931

Epoch: 6| Step: 7
Training loss: 2.109288215637207
Validation loss: 2.3171780096587313

Epoch: 6| Step: 8
Training loss: 2.4544544219970703
Validation loss: 2.335160022140831

Epoch: 6| Step: 9
Training loss: 2.4288296699523926
Validation loss: 2.3566310867186515

Epoch: 6| Step: 10
Training loss: 2.2622551918029785
Validation loss: 2.377106789619692

Epoch: 6| Step: 11
Training loss: 2.8643293380737305
Validation loss: 2.416480538665607

Epoch: 6| Step: 12
Training loss: 2.857603073120117
Validation loss: 2.408539710506316

Epoch: 6| Step: 13
Training loss: 2.681332588195801
Validation loss: 2.4298268133594143

Epoch: 329| Step: 0
Training loss: 3.519240379333496
Validation loss: 2.423743765841248

Epoch: 6| Step: 1
Training loss: 1.7891180515289307
Validation loss: 2.3875512987054806

Epoch: 6| Step: 2
Training loss: 1.933065414428711
Validation loss: 2.3904498828354703

Epoch: 6| Step: 3
Training loss: 2.7222516536712646
Validation loss: 2.344456368877042

Epoch: 6| Step: 4
Training loss: 2.185548782348633
Validation loss: 2.343902777600032

Epoch: 6| Step: 5
Training loss: 2.601595163345337
Validation loss: 2.3295786726859307

Epoch: 6| Step: 6
Training loss: 2.529388427734375
Validation loss: 2.3340043496060114

Epoch: 6| Step: 7
Training loss: 1.9840885400772095
Validation loss: 2.3478270769119263

Epoch: 6| Step: 8
Training loss: 2.062811851501465
Validation loss: 2.3368737595055693

Epoch: 6| Step: 9
Training loss: 2.815410614013672
Validation loss: 2.343675687748899

Epoch: 6| Step: 10
Training loss: 2.404353141784668
Validation loss: 2.3353329755926646

Epoch: 6| Step: 11
Training loss: 2.765061378479004
Validation loss: 2.335047250152916

Epoch: 6| Step: 12
Training loss: 2.4709270000457764
Validation loss: 2.331371658591814

Epoch: 6| Step: 13
Training loss: 2.4724485874176025
Validation loss: 2.3444343202857563

Epoch: 330| Step: 0
Training loss: 1.6369876861572266
Validation loss: 2.3491643321129585

Epoch: 6| Step: 1
Training loss: 2.9022326469421387
Validation loss: 2.3603024328908613

Epoch: 6| Step: 2
Training loss: 1.6910603046417236
Validation loss: 2.379607359568278

Epoch: 6| Step: 3
Training loss: 1.9490026235580444
Validation loss: 2.384975802513861

Epoch: 6| Step: 4
Training loss: 2.487889051437378
Validation loss: 2.3698447468460246

Epoch: 6| Step: 5
Training loss: 2.6317548751831055
Validation loss: 2.3881576753431752

Epoch: 6| Step: 6
Training loss: 2.565889358520508
Validation loss: 2.380453325087024

Epoch: 6| Step: 7
Training loss: 2.853215217590332
Validation loss: 2.3836881012044926

Epoch: 6| Step: 8
Training loss: 2.933570384979248
Validation loss: 2.394561921396563

Epoch: 6| Step: 9
Training loss: 2.7189278602600098
Validation loss: 2.3740290980185232

Epoch: 6| Step: 10
Training loss: 3.6266026496887207
Validation loss: 2.353337299439215

Epoch: 6| Step: 11
Training loss: 1.3032459020614624
Validation loss: 2.345274535558557

Epoch: 6| Step: 12
Training loss: 2.173150062561035
Validation loss: 2.326157075102611

Epoch: 6| Step: 13
Training loss: 2.4260640144348145
Validation loss: 2.337210665466965

Epoch: 331| Step: 0
Training loss: 1.5569567680358887
Validation loss: 2.3382575999024096

Epoch: 6| Step: 1
Training loss: 2.7766852378845215
Validation loss: 2.352271212044583

Epoch: 6| Step: 2
Training loss: 2.9338810443878174
Validation loss: 2.358677682056222

Epoch: 6| Step: 3
Training loss: 2.436893939971924
Validation loss: 2.3625547091166177

Epoch: 6| Step: 4
Training loss: 3.0512232780456543
Validation loss: 2.363030900237381

Epoch: 6| Step: 5
Training loss: 1.980151891708374
Validation loss: 2.356303484209122

Epoch: 6| Step: 6
Training loss: 2.1918511390686035
Validation loss: 2.3500313297394784

Epoch: 6| Step: 7
Training loss: 2.6900691986083984
Validation loss: 2.3365019418859996

Epoch: 6| Step: 8
Training loss: 2.5886073112487793
Validation loss: 2.355269939668717

Epoch: 6| Step: 9
Training loss: 2.5210089683532715
Validation loss: 2.347427906528596

Epoch: 6| Step: 10
Training loss: 2.358656883239746
Validation loss: 2.3487414236991637

Epoch: 6| Step: 11
Training loss: 2.158146858215332
Validation loss: 2.360797369351951

Epoch: 6| Step: 12
Training loss: 1.915428638458252
Validation loss: 2.3574835279936432

Epoch: 6| Step: 13
Training loss: 2.7305684089660645
Validation loss: 2.3513586726239932

Epoch: 332| Step: 0
Training loss: 1.7799177169799805
Validation loss: 2.3600276618875484

Epoch: 6| Step: 1
Training loss: 3.0718507766723633
Validation loss: 2.361904626251549

Epoch: 6| Step: 2
Training loss: 3.025514602661133
Validation loss: 2.357999583726288

Epoch: 6| Step: 3
Training loss: 2.401089668273926
Validation loss: 2.354385014503233

Epoch: 6| Step: 4
Training loss: 2.1420178413391113
Validation loss: 2.3460045501750004

Epoch: 6| Step: 5
Training loss: 2.4791343212127686
Validation loss: 2.3367547245435816

Epoch: 6| Step: 6
Training loss: 2.2697997093200684
Validation loss: 2.338684235849688

Epoch: 6| Step: 7
Training loss: 2.5933165550231934
Validation loss: 2.335437226039107

Epoch: 6| Step: 8
Training loss: 2.389890670776367
Validation loss: 2.3242948337267806

Epoch: 6| Step: 9
Training loss: 2.67992901802063
Validation loss: 2.3016171429746892

Epoch: 6| Step: 10
Training loss: 2.332481861114502
Validation loss: 2.316318949063619

Epoch: 6| Step: 11
Training loss: 2.3346071243286133
Validation loss: 2.3166164377684235

Epoch: 6| Step: 12
Training loss: 2.1898703575134277
Validation loss: 2.3244306656622116

Epoch: 6| Step: 13
Training loss: 1.866208791732788
Validation loss: 2.3374022617134997

Epoch: 333| Step: 0
Training loss: 2.496692180633545
Validation loss: 2.3426919060368694

Epoch: 6| Step: 1
Training loss: 2.783270835876465
Validation loss: 2.364012466963901

Epoch: 6| Step: 2
Training loss: 1.4736425876617432
Validation loss: 2.358300357736567

Epoch: 6| Step: 3
Training loss: 2.5789589881896973
Validation loss: 2.3577554841195383

Epoch: 6| Step: 4
Training loss: 2.1984310150146484
Validation loss: 2.3720424072716826

Epoch: 6| Step: 5
Training loss: 2.052931070327759
Validation loss: 2.377137299506895

Epoch: 6| Step: 6
Training loss: 2.712599754333496
Validation loss: 2.3860706257563766

Epoch: 6| Step: 7
Training loss: 1.647965669631958
Validation loss: 2.383632852185157

Epoch: 6| Step: 8
Training loss: 2.9929146766662598
Validation loss: 2.371829209789153

Epoch: 6| Step: 9
Training loss: 2.956974506378174
Validation loss: 2.372510597270022

Epoch: 6| Step: 10
Training loss: 2.8890881538391113
Validation loss: 2.351720843263852

Epoch: 6| Step: 11
Training loss: 2.2234725952148438
Validation loss: 2.343625626256389

Epoch: 6| Step: 12
Training loss: 2.4409642219543457
Validation loss: 2.325830982577416

Epoch: 6| Step: 13
Training loss: 2.4198334217071533
Validation loss: 2.3228738769408195

Epoch: 334| Step: 0
Training loss: 1.9149019718170166
Validation loss: 2.323182826401085

Epoch: 6| Step: 1
Training loss: 2.436614513397217
Validation loss: 2.334940961612168

Epoch: 6| Step: 2
Training loss: 2.952953338623047
Validation loss: 2.3391096361221804

Epoch: 6| Step: 3
Training loss: 2.2934327125549316
Validation loss: 2.3620626029147895

Epoch: 6| Step: 4
Training loss: 2.603959798812866
Validation loss: 2.370695919118902

Epoch: 6| Step: 5
Training loss: 2.4164557456970215
Validation loss: 2.3801955587120465

Epoch: 6| Step: 6
Training loss: 2.461627721786499
Validation loss: 2.395396678678451

Epoch: 6| Step: 7
Training loss: 2.351558208465576
Validation loss: 2.380105000670238

Epoch: 6| Step: 8
Training loss: 2.687872886657715
Validation loss: 2.3837753777862876

Epoch: 6| Step: 9
Training loss: 2.1448781490325928
Validation loss: 2.383228020001483

Epoch: 6| Step: 10
Training loss: 2.0348548889160156
Validation loss: 2.3840075487731607

Epoch: 6| Step: 11
Training loss: 2.8427023887634277
Validation loss: 2.398368057384286

Epoch: 6| Step: 12
Training loss: 2.4069840908050537
Validation loss: 2.3893464303785756

Epoch: 6| Step: 13
Training loss: 1.9185417890548706
Validation loss: 2.351088582828481

Epoch: 335| Step: 0
Training loss: 1.622476577758789
Validation loss: 2.327550704761218

Epoch: 6| Step: 1
Training loss: 2.879444122314453
Validation loss: 2.3090920653394473

Epoch: 6| Step: 2
Training loss: 2.263472080230713
Validation loss: 2.2976216577714488

Epoch: 6| Step: 3
Training loss: 2.2777011394500732
Validation loss: 2.303672634145265

Epoch: 6| Step: 4
Training loss: 1.9766261577606201
Validation loss: 2.2885988553365073

Epoch: 6| Step: 5
Training loss: 2.8295679092407227
Validation loss: 2.2942922140962336

Epoch: 6| Step: 6
Training loss: 2.5853688716888428
Validation loss: 2.309129491929085

Epoch: 6| Step: 7
Training loss: 3.403081178665161
Validation loss: 2.302419198456631

Epoch: 6| Step: 8
Training loss: 2.3265109062194824
Validation loss: 2.3264404548111783

Epoch: 6| Step: 9
Training loss: 2.2301011085510254
Validation loss: 2.328525081757576

Epoch: 6| Step: 10
Training loss: 2.8540916442871094
Validation loss: 2.336233082637992

Epoch: 6| Step: 11
Training loss: 2.695157051086426
Validation loss: 2.343124956213018

Epoch: 6| Step: 12
Training loss: 2.0488533973693848
Validation loss: 2.3719188192839264

Epoch: 6| Step: 13
Training loss: 1.7044527530670166
Validation loss: 2.3881788381966214

Epoch: 336| Step: 0
Training loss: 2.094562530517578
Validation loss: 2.3889172923180366

Epoch: 6| Step: 1
Training loss: 3.1323227882385254
Validation loss: 2.382520793586649

Epoch: 6| Step: 2
Training loss: 2.6079556941986084
Validation loss: 2.402333713346912

Epoch: 6| Step: 3
Training loss: 2.0602216720581055
Validation loss: 2.398872538279462

Epoch: 6| Step: 4
Training loss: 2.522469997406006
Validation loss: 2.375790101225658

Epoch: 6| Step: 5
Training loss: 1.9618709087371826
Validation loss: 2.375788624568652

Epoch: 6| Step: 6
Training loss: 2.9221882820129395
Validation loss: 2.3574235618755384

Epoch: 6| Step: 7
Training loss: 2.0352325439453125
Validation loss: 2.3528796754857546

Epoch: 6| Step: 8
Training loss: 2.7875118255615234
Validation loss: 2.3423514340513494

Epoch: 6| Step: 9
Training loss: 1.9953763484954834
Validation loss: 2.3167984306171374

Epoch: 6| Step: 10
Training loss: 1.9484692811965942
Validation loss: 2.3058762319626345

Epoch: 6| Step: 11
Training loss: 2.4213733673095703
Validation loss: 2.3132363980816257

Epoch: 6| Step: 12
Training loss: 2.383391857147217
Validation loss: 2.305168636383549

Epoch: 6| Step: 13
Training loss: 3.057204484939575
Validation loss: 2.3218165187425512

Epoch: 337| Step: 0
Training loss: 1.864518404006958
Validation loss: 2.3304441641735774

Epoch: 6| Step: 1
Training loss: 2.9797842502593994
Validation loss: 2.3378144643640004

Epoch: 6| Step: 2
Training loss: 2.429612159729004
Validation loss: 2.341702092078424

Epoch: 6| Step: 3
Training loss: 2.197478771209717
Validation loss: 2.3399780463146906

Epoch: 6| Step: 4
Training loss: 2.2640161514282227
Validation loss: 2.3692225922820387

Epoch: 6| Step: 5
Training loss: 2.2405662536621094
Validation loss: 2.361863156800629

Epoch: 6| Step: 6
Training loss: 2.8629066944122314
Validation loss: 2.358584462955434

Epoch: 6| Step: 7
Training loss: 2.5227503776550293
Validation loss: 2.367011990598453

Epoch: 6| Step: 8
Training loss: 2.042113780975342
Validation loss: 2.3589347793209936

Epoch: 6| Step: 9
Training loss: 3.1280603408813477
Validation loss: 2.36813864656674

Epoch: 6| Step: 10
Training loss: 2.8560070991516113
Validation loss: 2.3407410626770346

Epoch: 6| Step: 11
Training loss: 2.1577954292297363
Validation loss: 2.332241189095282

Epoch: 6| Step: 12
Training loss: 1.573371410369873
Validation loss: 2.3152729670206704

Epoch: 6| Step: 13
Training loss: 2.5753602981567383
Validation loss: 2.306026574104063

Epoch: 338| Step: 0
Training loss: 2.012056589126587
Validation loss: 2.2957399737450386

Epoch: 6| Step: 1
Training loss: 2.873804807662964
Validation loss: 2.303948720296224

Epoch: 6| Step: 2
Training loss: 2.1173179149627686
Validation loss: 2.314645085283505

Epoch: 6| Step: 3
Training loss: 2.6347880363464355
Validation loss: 2.3256062769120738

Epoch: 6| Step: 4
Training loss: 2.7460546493530273
Validation loss: 2.3388087621299167

Epoch: 6| Step: 5
Training loss: 2.1576690673828125
Validation loss: 2.329784442019719

Epoch: 6| Step: 6
Training loss: 1.6540908813476562
Validation loss: 2.3240376595527894

Epoch: 6| Step: 7
Training loss: 2.398958206176758
Validation loss: 2.3454000283313055

Epoch: 6| Step: 8
Training loss: 2.6456856727600098
Validation loss: 2.3473313136767318

Epoch: 6| Step: 9
Training loss: 2.4369516372680664
Validation loss: 2.353831439889887

Epoch: 6| Step: 10
Training loss: 2.2065317630767822
Validation loss: 2.3750402581307197

Epoch: 6| Step: 11
Training loss: 2.78960919380188
Validation loss: 2.4072989674024683

Epoch: 6| Step: 12
Training loss: 2.769024610519409
Validation loss: 2.4159694743412796

Epoch: 6| Step: 13
Training loss: 2.124458074569702
Validation loss: 2.3915129579523557

Epoch: 339| Step: 0
Training loss: 2.4738872051239014
Validation loss: 2.3519534064877416

Epoch: 6| Step: 1
Training loss: 2.9084863662719727
Validation loss: 2.3480108271362963

Epoch: 6| Step: 2
Training loss: 2.195535659790039
Validation loss: 2.327623664691884

Epoch: 6| Step: 3
Training loss: 2.1431918144226074
Validation loss: 2.3168537257820048

Epoch: 6| Step: 4
Training loss: 2.433590888977051
Validation loss: 2.302977664496309

Epoch: 6| Step: 5
Training loss: 2.855961322784424
Validation loss: 2.3003997777097966

Epoch: 6| Step: 6
Training loss: 2.0445823669433594
Validation loss: 2.2873578994504866

Epoch: 6| Step: 7
Training loss: 1.9813055992126465
Validation loss: 2.3155716849911596

Epoch: 6| Step: 8
Training loss: 2.318575143814087
Validation loss: 2.3010491735191754

Epoch: 6| Step: 9
Training loss: 1.9585957527160645
Validation loss: 2.326646266445037

Epoch: 6| Step: 10
Training loss: 1.9566878080368042
Validation loss: 2.3512194489920013

Epoch: 6| Step: 11
Training loss: 3.302074432373047
Validation loss: 2.3761976457411245

Epoch: 6| Step: 12
Training loss: 2.7045626640319824
Validation loss: 2.399941587960848

Epoch: 6| Step: 13
Training loss: 2.3840415477752686
Validation loss: 2.389213422293304

Epoch: 340| Step: 0
Training loss: 2.0888967514038086
Validation loss: 2.3983553814631637

Epoch: 6| Step: 1
Training loss: 2.7464215755462646
Validation loss: 2.3887975626094367

Epoch: 6| Step: 2
Training loss: 3.0068697929382324
Validation loss: 2.3717690437070784

Epoch: 6| Step: 3
Training loss: 2.202925205230713
Validation loss: 2.3653024960589666

Epoch: 6| Step: 4
Training loss: 1.9661892652511597
Validation loss: 2.3678252056080806

Epoch: 6| Step: 5
Training loss: 2.4854512214660645
Validation loss: 2.370319499764391

Epoch: 6| Step: 6
Training loss: 2.182042121887207
Validation loss: 2.3574543332540863

Epoch: 6| Step: 7
Training loss: 2.535271167755127
Validation loss: 2.358468383871099

Epoch: 6| Step: 8
Training loss: 3.114088773727417
Validation loss: 2.363654874986218

Epoch: 6| Step: 9
Training loss: 1.984894037246704
Validation loss: 2.332658447245116

Epoch: 6| Step: 10
Training loss: 2.2226758003234863
Validation loss: 2.3423800699172483

Epoch: 6| Step: 11
Training loss: 1.84101402759552
Validation loss: 2.3177533380446897

Epoch: 6| Step: 12
Training loss: 2.0537893772125244
Validation loss: 2.3141820276937177

Epoch: 6| Step: 13
Training loss: 3.553804397583008
Validation loss: 2.321499832214848

Epoch: 341| Step: 0
Training loss: 1.9723361730575562
Validation loss: 2.3367234430005475

Epoch: 6| Step: 1
Training loss: 2.2673110961914062
Validation loss: 2.3468684022144606

Epoch: 6| Step: 2
Training loss: 2.885164737701416
Validation loss: 2.355530410684565

Epoch: 6| Step: 3
Training loss: 2.237318754196167
Validation loss: 2.3799231744581655

Epoch: 6| Step: 4
Training loss: 2.900261163711548
Validation loss: 2.3504598230443974

Epoch: 6| Step: 5
Training loss: 2.5896291732788086
Validation loss: 2.3354110230681715

Epoch: 6| Step: 6
Training loss: 3.048476219177246
Validation loss: 2.3305119801593084

Epoch: 6| Step: 7
Training loss: 1.4256097078323364
Validation loss: 2.314613552503688

Epoch: 6| Step: 8
Training loss: 2.1133594512939453
Validation loss: 2.3184638049012873

Epoch: 6| Step: 9
Training loss: 2.543384075164795
Validation loss: 2.306716420317209

Epoch: 6| Step: 10
Training loss: 2.1028780937194824
Validation loss: 2.295147790703722

Epoch: 6| Step: 11
Training loss: 2.7883872985839844
Validation loss: 2.318749617504817

Epoch: 6| Step: 12
Training loss: 2.1488804817199707
Validation loss: 2.3318762087052867

Epoch: 6| Step: 13
Training loss: 2.4933152198791504
Validation loss: 2.3230833494535057

Epoch: 342| Step: 0
Training loss: 1.9316381216049194
Validation loss: 2.3310090803330943

Epoch: 6| Step: 1
Training loss: 2.202291488647461
Validation loss: 2.344600300635061

Epoch: 6| Step: 2
Training loss: 2.916168212890625
Validation loss: 2.3680261591429352

Epoch: 6| Step: 3
Training loss: 2.381725311279297
Validation loss: 2.3635253521703903

Epoch: 6| Step: 4
Training loss: 1.9953211545944214
Validation loss: 2.3654002707491637

Epoch: 6| Step: 5
Training loss: 2.462533473968506
Validation loss: 2.3554511070251465

Epoch: 6| Step: 6
Training loss: 2.3557868003845215
Validation loss: 2.360413625676145

Epoch: 6| Step: 7
Training loss: 2.9630684852600098
Validation loss: 2.3613291786563013

Epoch: 6| Step: 8
Training loss: 1.5361541509628296
Validation loss: 2.3659731726492605

Epoch: 6| Step: 9
Training loss: 3.03075909614563
Validation loss: 2.35172688832847

Epoch: 6| Step: 10
Training loss: 2.0852766036987305
Validation loss: 2.3423168979665285

Epoch: 6| Step: 11
Training loss: 2.1082262992858887
Validation loss: 2.3336553804336058

Epoch: 6| Step: 12
Training loss: 2.3973307609558105
Validation loss: 2.3330152701306086

Epoch: 6| Step: 13
Training loss: 3.744886636734009
Validation loss: 2.3236342758260746

Epoch: 343| Step: 0
Training loss: 2.053755521774292
Validation loss: 2.3315275920334684

Epoch: 6| Step: 1
Training loss: 2.7328543663024902
Validation loss: 2.318495017226024

Epoch: 6| Step: 2
Training loss: 2.3490657806396484
Validation loss: 2.3551623103439168

Epoch: 6| Step: 3
Training loss: 2.4694089889526367
Validation loss: 2.36899741747046

Epoch: 6| Step: 4
Training loss: 2.6607842445373535
Validation loss: 2.375174173744776

Epoch: 6| Step: 5
Training loss: 2.7452261447906494
Validation loss: 2.3963252703348794

Epoch: 6| Step: 6
Training loss: 1.8909846544265747
Validation loss: 2.3758452323175248

Epoch: 6| Step: 7
Training loss: 2.26369047164917
Validation loss: 2.3620170957298687

Epoch: 6| Step: 8
Training loss: 2.3949005603790283
Validation loss: 2.331333344982516

Epoch: 6| Step: 9
Training loss: 2.5401926040649414
Validation loss: 2.314578729291116

Epoch: 6| Step: 10
Training loss: 2.154048442840576
Validation loss: 2.297501171788862

Epoch: 6| Step: 11
Training loss: 2.4527664184570312
Validation loss: 2.295479584765691

Epoch: 6| Step: 12
Training loss: 2.2487823963165283
Validation loss: 2.287408754389773

Epoch: 6| Step: 13
Training loss: 2.5331027507781982
Validation loss: 2.290862719217936

Epoch: 344| Step: 0
Training loss: 2.013890027999878
Validation loss: 2.2828878459110054

Epoch: 6| Step: 1
Training loss: 2.5049047470092773
Validation loss: 2.2820754845937095

Epoch: 6| Step: 2
Training loss: 2.8220632076263428
Validation loss: 2.280905564626058

Epoch: 6| Step: 3
Training loss: 2.411569118499756
Validation loss: 2.28785974748673

Epoch: 6| Step: 4
Training loss: 3.129849433898926
Validation loss: 2.2965652904202862

Epoch: 6| Step: 5
Training loss: 2.3680787086486816
Validation loss: 2.302835367059195

Epoch: 6| Step: 6
Training loss: 2.694777011871338
Validation loss: 2.310054199669951

Epoch: 6| Step: 7
Training loss: 2.5033581256866455
Validation loss: 2.3431899932123

Epoch: 6| Step: 8
Training loss: 2.62758207321167
Validation loss: 2.3653719579019854

Epoch: 6| Step: 9
Training loss: 1.8971924781799316
Validation loss: 2.392642944089828

Epoch: 6| Step: 10
Training loss: 1.9537837505340576
Validation loss: 2.3849412548926567

Epoch: 6| Step: 11
Training loss: 1.910595417022705
Validation loss: 2.3780777274921374

Epoch: 6| Step: 12
Training loss: 2.616882085800171
Validation loss: 2.352923445804145

Epoch: 6| Step: 13
Training loss: 1.8320304155349731
Validation loss: 2.3205362263546196

Epoch: 345| Step: 0
Training loss: 2.75028133392334
Validation loss: 2.307891861084969

Epoch: 6| Step: 1
Training loss: 1.564880132675171
Validation loss: 2.3170254153590046

Epoch: 6| Step: 2
Training loss: 2.5487189292907715
Validation loss: 2.318504368105242

Epoch: 6| Step: 3
Training loss: 2.0919389724731445
Validation loss: 2.3123241855252172

Epoch: 6| Step: 4
Training loss: 2.8892898559570312
Validation loss: 2.3195237241765505

Epoch: 6| Step: 5
Training loss: 2.4077179431915283
Validation loss: 2.3235652036564325

Epoch: 6| Step: 6
Training loss: 2.8068413734436035
Validation loss: 2.3566801881277435

Epoch: 6| Step: 7
Training loss: 2.4445295333862305
Validation loss: 2.3338011798038276

Epoch: 6| Step: 8
Training loss: 1.9856829643249512
Validation loss: 2.3339660667604014

Epoch: 6| Step: 9
Training loss: 3.3221616744995117
Validation loss: 2.341931294369441

Epoch: 6| Step: 10
Training loss: 1.7483983039855957
Validation loss: 2.3705039049989436

Epoch: 6| Step: 11
Training loss: 2.3644070625305176
Validation loss: 2.3486114701917096

Epoch: 6| Step: 12
Training loss: 2.108360767364502
Validation loss: 2.341293245233515

Epoch: 6| Step: 13
Training loss: 1.931172251701355
Validation loss: 2.3338779839136268

Epoch: 346| Step: 0
Training loss: 3.2760934829711914
Validation loss: 2.3326095893818843

Epoch: 6| Step: 1
Training loss: 1.665405511856079
Validation loss: 2.3197289743731098

Epoch: 6| Step: 2
Training loss: 2.6604440212249756
Validation loss: 2.3142591522585962

Epoch: 6| Step: 3
Training loss: 2.496134042739868
Validation loss: 2.3096036987919963

Epoch: 6| Step: 4
Training loss: 2.86433482170105
Validation loss: 2.308676278719338

Epoch: 6| Step: 5
Training loss: 2.4117815494537354
Validation loss: 2.3020530900647564

Epoch: 6| Step: 6
Training loss: 2.5069503784179688
Validation loss: 2.3082988108358076

Epoch: 6| Step: 7
Training loss: 2.3741776943206787
Validation loss: 2.3121155282502532

Epoch: 6| Step: 8
Training loss: 2.1098461151123047
Validation loss: 2.329792732833534

Epoch: 6| Step: 9
Training loss: 2.1954407691955566
Validation loss: 2.3503168090697257

Epoch: 6| Step: 10
Training loss: 1.642669677734375
Validation loss: 2.3799193623245403

Epoch: 6| Step: 11
Training loss: 1.872128963470459
Validation loss: 2.4203310474272697

Epoch: 6| Step: 12
Training loss: 2.5623860359191895
Validation loss: 2.390754322851858

Epoch: 6| Step: 13
Training loss: 2.7962911128997803
Validation loss: 2.4244771054995957

Epoch: 347| Step: 0
Training loss: 2.9405245780944824
Validation loss: 2.419671650855772

Epoch: 6| Step: 1
Training loss: 1.7519969940185547
Validation loss: 2.4055044010121334

Epoch: 6| Step: 2
Training loss: 2.1509692668914795
Validation loss: 2.3778499070034234

Epoch: 6| Step: 3
Training loss: 2.599736452102661
Validation loss: 2.3662496741100023

Epoch: 6| Step: 4
Training loss: 1.7243233919143677
Validation loss: 2.344935911957936

Epoch: 6| Step: 5
Training loss: 2.91552734375
Validation loss: 2.3378908685458604

Epoch: 6| Step: 6
Training loss: 2.729888677597046
Validation loss: 2.3092547347468715

Epoch: 6| Step: 7
Training loss: 2.429276943206787
Validation loss: 2.318522817345076

Epoch: 6| Step: 8
Training loss: 2.5636065006256104
Validation loss: 2.3213966341428858

Epoch: 6| Step: 9
Training loss: 2.070002555847168
Validation loss: 2.3205172502866356

Epoch: 6| Step: 10
Training loss: 2.428635835647583
Validation loss: 2.299284881161105

Epoch: 6| Step: 11
Training loss: 2.08648681640625
Validation loss: 2.30698791626961

Epoch: 6| Step: 12
Training loss: 2.664811372756958
Validation loss: 2.298037285445839

Epoch: 6| Step: 13
Training loss: 2.1913576126098633
Validation loss: 2.3035553424589095

Epoch: 348| Step: 0
Training loss: 3.398700714111328
Validation loss: 2.3191428748510217

Epoch: 6| Step: 1
Training loss: 2.2799172401428223
Validation loss: 2.324764246581703

Epoch: 6| Step: 2
Training loss: 2.043760299682617
Validation loss: 2.3556742257969354

Epoch: 6| Step: 3
Training loss: 2.2857141494750977
Validation loss: 2.3816054905614545

Epoch: 6| Step: 4
Training loss: 1.906140685081482
Validation loss: 2.3693157485736314

Epoch: 6| Step: 5
Training loss: 2.823596715927124
Validation loss: 2.3652820074430077

Epoch: 6| Step: 6
Training loss: 2.5834155082702637
Validation loss: 2.378353282969485

Epoch: 6| Step: 7
Training loss: 2.12778902053833
Validation loss: 2.363675635348084

Epoch: 6| Step: 8
Training loss: 2.325167417526245
Validation loss: 2.3637683878662767

Epoch: 6| Step: 9
Training loss: 2.094515800476074
Validation loss: 2.338854259060275

Epoch: 6| Step: 10
Training loss: 1.8950759172439575
Validation loss: 2.329441783248737

Epoch: 6| Step: 11
Training loss: 2.742316246032715
Validation loss: 2.3132811477107387

Epoch: 6| Step: 12
Training loss: 2.362966537475586
Validation loss: 2.3043155413801952

Epoch: 6| Step: 13
Training loss: 2.186609983444214
Validation loss: 2.3059154274643108

Epoch: 349| Step: 0
Training loss: 2.9207229614257812
Validation loss: 2.3171099180816324

Epoch: 6| Step: 1
Training loss: 2.3205249309539795
Validation loss: 2.3179423373232604

Epoch: 6| Step: 2
Training loss: 2.4509754180908203
Validation loss: 2.3034343001663045

Epoch: 6| Step: 3
Training loss: 2.334196090698242
Validation loss: 2.3198329530736452

Epoch: 6| Step: 4
Training loss: 2.2624964714050293
Validation loss: 2.3280740284150645

Epoch: 6| Step: 5
Training loss: 1.997391700744629
Validation loss: 2.3426245309973277

Epoch: 6| Step: 6
Training loss: 2.104811668395996
Validation loss: 2.3488054865150043

Epoch: 6| Step: 7
Training loss: 1.7574790716171265
Validation loss: 2.364308936621553

Epoch: 6| Step: 8
Training loss: 2.673779249191284
Validation loss: 2.363024162989791

Epoch: 6| Step: 9
Training loss: 3.1006948947906494
Validation loss: 2.341163194307717

Epoch: 6| Step: 10
Training loss: 2.0812902450561523
Validation loss: 2.34751582402055

Epoch: 6| Step: 11
Training loss: 2.6963701248168945
Validation loss: 2.3341443436120146

Epoch: 6| Step: 12
Training loss: 2.5970330238342285
Validation loss: 2.3282171474990023

Epoch: 6| Step: 13
Training loss: 1.51578950881958
Validation loss: 2.320948088040916

Epoch: 350| Step: 0
Training loss: 2.7588062286376953
Validation loss: 2.329541439651161

Epoch: 6| Step: 1
Training loss: 1.9244489669799805
Validation loss: 2.3371858494256132

Epoch: 6| Step: 2
Training loss: 3.2750539779663086
Validation loss: 2.360360066095988

Epoch: 6| Step: 3
Training loss: 2.4519426822662354
Validation loss: 2.370060787406019

Epoch: 6| Step: 4
Training loss: 2.7699031829833984
Validation loss: 2.348854277723579

Epoch: 6| Step: 5
Training loss: 2.1118290424346924
Validation loss: 2.338935634141327

Epoch: 6| Step: 6
Training loss: 2.6984267234802246
Validation loss: 2.3393543356208393

Epoch: 6| Step: 7
Training loss: 2.310439109802246
Validation loss: 2.3369041091652325

Epoch: 6| Step: 8
Training loss: 1.5307490825653076
Validation loss: 2.3241961002349854

Epoch: 6| Step: 9
Training loss: 2.270564556121826
Validation loss: 2.323578511514971

Epoch: 6| Step: 10
Training loss: 2.2079856395721436
Validation loss: 2.3183616310037594

Epoch: 6| Step: 11
Training loss: 1.7531495094299316
Validation loss: 2.3162480464545627

Epoch: 6| Step: 12
Training loss: 2.491901397705078
Validation loss: 2.3217085048716557

Epoch: 6| Step: 13
Training loss: 2.736448049545288
Validation loss: 2.3197252058213755

Epoch: 351| Step: 0
Training loss: 2.2457971572875977
Validation loss: 2.3359436668375486

Epoch: 6| Step: 1
Training loss: 2.2668356895446777
Validation loss: 2.3318071801175355

Epoch: 6| Step: 2
Training loss: 2.3757505416870117
Validation loss: 2.345442397620088

Epoch: 6| Step: 3
Training loss: 2.602306365966797
Validation loss: 2.3683493496269308

Epoch: 6| Step: 4
Training loss: 2.914987564086914
Validation loss: 2.3641389467382945

Epoch: 6| Step: 5
Training loss: 2.116941452026367
Validation loss: 2.3899952339869674

Epoch: 6| Step: 6
Training loss: 2.9149370193481445
Validation loss: 2.3536401051346973

Epoch: 6| Step: 7
Training loss: 2.4621362686157227
Validation loss: 2.336555447629703

Epoch: 6| Step: 8
Training loss: 1.982405185699463
Validation loss: 2.308659351000222

Epoch: 6| Step: 9
Training loss: 2.952726364135742
Validation loss: 2.3017257311010875

Epoch: 6| Step: 10
Training loss: 2.0506253242492676
Validation loss: 2.2864704196171095

Epoch: 6| Step: 11
Training loss: 1.8929848670959473
Validation loss: 2.272216098282927

Epoch: 6| Step: 12
Training loss: 2.0871400833129883
Validation loss: 2.2825293874227874

Epoch: 6| Step: 13
Training loss: 2.31048321723938
Validation loss: 2.297365726963166

Epoch: 352| Step: 0
Training loss: 2.1767611503601074
Validation loss: 2.288544019063314

Epoch: 6| Step: 1
Training loss: 2.4067254066467285
Validation loss: 2.3039446107802855

Epoch: 6| Step: 2
Training loss: 2.959610939025879
Validation loss: 2.334043437434781

Epoch: 6| Step: 3
Training loss: 1.9903169870376587
Validation loss: 2.327605193661105

Epoch: 6| Step: 4
Training loss: 2.8061788082122803
Validation loss: 2.3355021399836384

Epoch: 6| Step: 5
Training loss: 2.385651111602783
Validation loss: 2.3219505074203655

Epoch: 6| Step: 6
Training loss: 2.897670269012451
Validation loss: 2.327890101299491

Epoch: 6| Step: 7
Training loss: 2.5479981899261475
Validation loss: 2.3273771065537647

Epoch: 6| Step: 8
Training loss: 2.3813958168029785
Validation loss: 2.31321894737982

Epoch: 6| Step: 9
Training loss: 1.9187698364257812
Validation loss: 2.3245572890004804

Epoch: 6| Step: 10
Training loss: 2.119955062866211
Validation loss: 2.3103899289202947

Epoch: 6| Step: 11
Training loss: 2.646435499191284
Validation loss: 2.317357163275442

Epoch: 6| Step: 12
Training loss: 1.6343697309494019
Validation loss: 2.3215879419798493

Epoch: 6| Step: 13
Training loss: 1.758169174194336
Validation loss: 2.3481835319149877

Epoch: 353| Step: 0
Training loss: 2.48478627204895
Validation loss: 2.352354418846869

Epoch: 6| Step: 1
Training loss: 2.838665008544922
Validation loss: 2.370950755252633

Epoch: 6| Step: 2
Training loss: 3.0101730823516846
Validation loss: 2.3749073872002224

Epoch: 6| Step: 3
Training loss: 2.23555850982666
Validation loss: 2.3445988996054536

Epoch: 6| Step: 4
Training loss: 2.916469097137451
Validation loss: 2.328533713535596

Epoch: 6| Step: 5
Training loss: 1.0851935148239136
Validation loss: 2.3336566109811105

Epoch: 6| Step: 6
Training loss: 2.474194049835205
Validation loss: 2.3232915273276706

Epoch: 6| Step: 7
Training loss: 1.5868217945098877
Validation loss: 2.31061613944269

Epoch: 6| Step: 8
Training loss: 2.4326534271240234
Validation loss: 2.303676748788485

Epoch: 6| Step: 9
Training loss: 2.5575900077819824
Validation loss: 2.2816808492906633

Epoch: 6| Step: 10
Training loss: 2.7265989780426025
Validation loss: 2.2909670158099105

Epoch: 6| Step: 11
Training loss: 2.1077890396118164
Validation loss: 2.2992357156609975

Epoch: 6| Step: 12
Training loss: 2.0906710624694824
Validation loss: 2.317745518940751

Epoch: 6| Step: 13
Training loss: 2.704892873764038
Validation loss: 2.3394721964354157

Epoch: 354| Step: 0
Training loss: 2.3847339153289795
Validation loss: 2.371938536244054

Epoch: 6| Step: 1
Training loss: 2.3022303581237793
Validation loss: 2.400389163724838

Epoch: 6| Step: 2
Training loss: 2.4213504791259766
Validation loss: 2.4180690062943326

Epoch: 6| Step: 3
Training loss: 1.8055933713912964
Validation loss: 2.4246790203996884

Epoch: 6| Step: 4
Training loss: 1.9108718633651733
Validation loss: 2.4098936152714554

Epoch: 6| Step: 5
Training loss: 2.543752431869507
Validation loss: 2.408636071348703

Epoch: 6| Step: 6
Training loss: 2.2637271881103516
Validation loss: 2.3615828944790747

Epoch: 6| Step: 7
Training loss: 2.869652271270752
Validation loss: 2.332819859186808

Epoch: 6| Step: 8
Training loss: 2.949021100997925
Validation loss: 2.29869754340059

Epoch: 6| Step: 9
Training loss: 2.2214012145996094
Validation loss: 2.285443772551834

Epoch: 6| Step: 10
Training loss: 2.409447431564331
Validation loss: 2.2764780162483134

Epoch: 6| Step: 11
Training loss: 2.3652184009552
Validation loss: 2.2821869952704317

Epoch: 6| Step: 12
Training loss: 2.221297025680542
Validation loss: 2.2826136465995543

Epoch: 6| Step: 13
Training loss: 2.376424789428711
Validation loss: 2.2816313646172963

Epoch: 355| Step: 0
Training loss: 1.514973759651184
Validation loss: 2.275781700688024

Epoch: 6| Step: 1
Training loss: 2.711663246154785
Validation loss: 2.2780791303162933

Epoch: 6| Step: 2
Training loss: 1.9057748317718506
Validation loss: 2.2696052738415298

Epoch: 6| Step: 3
Training loss: 2.6099038124084473
Validation loss: 2.291535328793269

Epoch: 6| Step: 4
Training loss: 3.211122751235962
Validation loss: 2.3100845506114345

Epoch: 6| Step: 5
Training loss: 2.07207989692688
Validation loss: 2.3276489857704408

Epoch: 6| Step: 6
Training loss: 2.4428467750549316
Validation loss: 2.343591450363077

Epoch: 6| Step: 7
Training loss: 2.082304000854492
Validation loss: 2.353875055108019

Epoch: 6| Step: 8
Training loss: 1.96865975856781
Validation loss: 2.351883719044347

Epoch: 6| Step: 9
Training loss: 2.6030261516571045
Validation loss: 2.378465452501851

Epoch: 6| Step: 10
Training loss: 3.0678257942199707
Validation loss: 2.374152421951294

Epoch: 6| Step: 11
Training loss: 2.2719268798828125
Validation loss: 2.3502234733232887

Epoch: 6| Step: 12
Training loss: 2.2453205585479736
Validation loss: 2.323248473546838

Epoch: 6| Step: 13
Training loss: 2.3369522094726562
Validation loss: 2.291197899849184

Epoch: 356| Step: 0
Training loss: 2.292208194732666
Validation loss: 2.28981049342822

Epoch: 6| Step: 1
Training loss: 2.6090002059936523
Validation loss: 2.278023282686869

Epoch: 6| Step: 2
Training loss: 2.4006872177124023
Validation loss: 2.2734645669178297

Epoch: 6| Step: 3
Training loss: 2.380284070968628
Validation loss: 2.2871057192484536

Epoch: 6| Step: 4
Training loss: 2.4316678047180176
Validation loss: 2.2790666908346195

Epoch: 6| Step: 5
Training loss: 2.496603488922119
Validation loss: 2.302695389716856

Epoch: 6| Step: 6
Training loss: 2.5249428749084473
Validation loss: 2.309710487242668

Epoch: 6| Step: 7
Training loss: 2.1305322647094727
Validation loss: 2.3188416804036787

Epoch: 6| Step: 8
Training loss: 2.3197975158691406
Validation loss: 2.340157319140691

Epoch: 6| Step: 9
Training loss: 2.3039679527282715
Validation loss: 2.3604345116564023

Epoch: 6| Step: 10
Training loss: 1.6068170070648193
Validation loss: 2.367255574913435

Epoch: 6| Step: 11
Training loss: 3.1973350048065186
Validation loss: 2.3628222224532918

Epoch: 6| Step: 12
Training loss: 2.557107448577881
Validation loss: 2.3684310451630624

Epoch: 6| Step: 13
Training loss: 1.3047006130218506
Validation loss: 2.3598728667023363

Epoch: 357| Step: 0
Training loss: 2.38594651222229
Validation loss: 2.3561243857106855

Epoch: 6| Step: 1
Training loss: 2.2285265922546387
Validation loss: 2.3619368768507436

Epoch: 6| Step: 2
Training loss: 2.763765811920166
Validation loss: 2.3679697975035636

Epoch: 6| Step: 3
Training loss: 2.299091339111328
Validation loss: 2.3455234394278577

Epoch: 6| Step: 4
Training loss: 1.871457815170288
Validation loss: 2.3408114987034954

Epoch: 6| Step: 5
Training loss: 1.9308784008026123
Validation loss: 2.3293622693707867

Epoch: 6| Step: 6
Training loss: 2.4852864742279053
Validation loss: 2.3007825830931306

Epoch: 6| Step: 7
Training loss: 2.234851360321045
Validation loss: 2.3030818418789933

Epoch: 6| Step: 8
Training loss: 2.350480079650879
Validation loss: 2.3060816000866633

Epoch: 6| Step: 9
Training loss: 1.8466157913208008
Validation loss: 2.3000700422512588

Epoch: 6| Step: 10
Training loss: 2.787125825881958
Validation loss: 2.3023487060300765

Epoch: 6| Step: 11
Training loss: 2.505434513092041
Validation loss: 2.2968189562520673

Epoch: 6| Step: 12
Training loss: 2.4739022254943848
Validation loss: 2.293132684564078

Epoch: 6| Step: 13
Training loss: 2.8227975368499756
Validation loss: 2.2863560209992113

Epoch: 358| Step: 0
Training loss: 2.0341649055480957
Validation loss: 2.30744049626012

Epoch: 6| Step: 1
Training loss: 1.9538710117340088
Validation loss: 2.301337775363717

Epoch: 6| Step: 2
Training loss: 2.3670473098754883
Validation loss: 2.301862229583084

Epoch: 6| Step: 3
Training loss: 1.430737853050232
Validation loss: 2.2982644573334725

Epoch: 6| Step: 4
Training loss: 2.7979369163513184
Validation loss: 2.3056170043124946

Epoch: 6| Step: 5
Training loss: 2.8757739067077637
Validation loss: 2.3162486771101594

Epoch: 6| Step: 6
Training loss: 2.9518227577209473
Validation loss: 2.327933362735215

Epoch: 6| Step: 7
Training loss: 2.371286630630493
Validation loss: 2.3123922886386996

Epoch: 6| Step: 8
Training loss: 2.3598384857177734
Validation loss: 2.3177255712529665

Epoch: 6| Step: 9
Training loss: 2.8783013820648193
Validation loss: 2.324075029742333

Epoch: 6| Step: 10
Training loss: 1.9398322105407715
Validation loss: 2.325241816941128

Epoch: 6| Step: 11
Training loss: 2.6313834190368652
Validation loss: 2.3312623859733663

Epoch: 6| Step: 12
Training loss: 1.8746042251586914
Validation loss: 2.30859975917365

Epoch: 6| Step: 13
Training loss: 2.3021719455718994
Validation loss: 2.3098346956314577

Epoch: 359| Step: 0
Training loss: 2.7121105194091797
Validation loss: 2.307722742839526

Epoch: 6| Step: 1
Training loss: 2.35813307762146
Validation loss: 2.311053260680168

Epoch: 6| Step: 2
Training loss: 1.8953858613967896
Validation loss: 2.3025399202941568

Epoch: 6| Step: 3
Training loss: 2.2802352905273438
Validation loss: 2.3025335265744116

Epoch: 6| Step: 4
Training loss: 2.2985901832580566
Validation loss: 2.3089788626599055

Epoch: 6| Step: 5
Training loss: 2.377678155899048
Validation loss: 2.325681165982318

Epoch: 6| Step: 6
Training loss: 3.6285533905029297
Validation loss: 2.3137261918796006

Epoch: 6| Step: 7
Training loss: 3.2001068592071533
Validation loss: 2.3107738366691013

Epoch: 6| Step: 8
Training loss: 1.5789921283721924
Validation loss: 2.322943256747338

Epoch: 6| Step: 9
Training loss: 1.3527247905731201
Validation loss: 2.3345417373923847

Epoch: 6| Step: 10
Training loss: 2.540992021560669
Validation loss: 2.3536772651057087

Epoch: 6| Step: 11
Training loss: 1.8438271284103394
Validation loss: 2.3499289430597776

Epoch: 6| Step: 12
Training loss: 2.2410030364990234
Validation loss: 2.3768406196307112

Epoch: 6| Step: 13
Training loss: 2.621769428253174
Validation loss: 2.3666542294204875

Epoch: 360| Step: 0
Training loss: 2.406892776489258
Validation loss: 2.3610804926964546

Epoch: 6| Step: 1
Training loss: 2.8989176750183105
Validation loss: 2.3104075334405385

Epoch: 6| Step: 2
Training loss: 2.022782325744629
Validation loss: 2.2700933051365677

Epoch: 6| Step: 3
Training loss: 2.562238931655884
Validation loss: 2.2777484693834857

Epoch: 6| Step: 4
Training loss: 2.112321138381958
Validation loss: 2.2639576773489676

Epoch: 6| Step: 5
Training loss: 2.1582632064819336
Validation loss: 2.261204614434191

Epoch: 6| Step: 6
Training loss: 2.1559770107269287
Validation loss: 2.2513462497342016

Epoch: 6| Step: 7
Training loss: 1.9628742933273315
Validation loss: 2.2682818340998825

Epoch: 6| Step: 8
Training loss: 2.0802061557769775
Validation loss: 2.243203479756591

Epoch: 6| Step: 9
Training loss: 3.060396194458008
Validation loss: 2.266405560637033

Epoch: 6| Step: 10
Training loss: 2.3687477111816406
Validation loss: 2.2500624682313655

Epoch: 6| Step: 11
Training loss: 2.6132736206054688
Validation loss: 2.273558647401871

Epoch: 6| Step: 12
Training loss: 2.1002535820007324
Validation loss: 2.2774035725542294

Epoch: 6| Step: 13
Training loss: 2.4935755729675293
Validation loss: 2.3175198147373814

Epoch: 361| Step: 0
Training loss: 2.2657997608184814
Validation loss: 2.337892657967024

Epoch: 6| Step: 1
Training loss: 3.5788254737854004
Validation loss: 2.360699963826005

Epoch: 6| Step: 2
Training loss: 2.292320966720581
Validation loss: 2.358303241832282

Epoch: 6| Step: 3
Training loss: 3.1229662895202637
Validation loss: 2.345729156207013

Epoch: 6| Step: 4
Training loss: 2.2033486366271973
Validation loss: 2.333830548870948

Epoch: 6| Step: 5
Training loss: 2.50797700881958
Validation loss: 2.323259530528899

Epoch: 6| Step: 6
Training loss: 1.9059714078903198
Validation loss: 2.3248673690262662

Epoch: 6| Step: 7
Training loss: 2.1624226570129395
Validation loss: 2.31813020090903

Epoch: 6| Step: 8
Training loss: 2.095804452896118
Validation loss: 2.340512614096365

Epoch: 6| Step: 9
Training loss: 1.8466811180114746
Validation loss: 2.310393225762152

Epoch: 6| Step: 10
Training loss: 2.6664516925811768
Validation loss: 2.318947171652189

Epoch: 6| Step: 11
Training loss: 1.572817325592041
Validation loss: 2.311204013004098

Epoch: 6| Step: 12
Training loss: 2.383553981781006
Validation loss: 2.3159432359921035

Epoch: 6| Step: 13
Training loss: 2.1632232666015625
Validation loss: 2.3349946391197944

Epoch: 362| Step: 0
Training loss: 3.0409607887268066
Validation loss: 2.3227076094637633

Epoch: 6| Step: 1
Training loss: 2.512422561645508
Validation loss: 2.3392053393907446

Epoch: 6| Step: 2
Training loss: 2.043048620223999
Validation loss: 2.341640213484405

Epoch: 6| Step: 3
Training loss: 2.1075637340545654
Validation loss: 2.327969270367776

Epoch: 6| Step: 4
Training loss: 2.728754997253418
Validation loss: 2.328435908081711

Epoch: 6| Step: 5
Training loss: 1.9925198554992676
Validation loss: 2.3220628230802474

Epoch: 6| Step: 6
Training loss: 1.8542330265045166
Validation loss: 2.320311459161902

Epoch: 6| Step: 7
Training loss: 2.5252525806427
Validation loss: 2.299422760163584

Epoch: 6| Step: 8
Training loss: 1.9087072610855103
Validation loss: 2.299282532866283

Epoch: 6| Step: 9
Training loss: 2.717176675796509
Validation loss: 2.296227103920393

Epoch: 6| Step: 10
Training loss: 2.1914072036743164
Validation loss: 2.3027901444383847

Epoch: 6| Step: 11
Training loss: 2.2985527515411377
Validation loss: 2.3093552025415565

Epoch: 6| Step: 12
Training loss: 2.2756354808807373
Validation loss: 2.315323328459135

Epoch: 6| Step: 13
Training loss: 2.440919876098633
Validation loss: 2.3233303229014077

Epoch: 363| Step: 0
Training loss: 2.285883903503418
Validation loss: 2.3092257553531277

Epoch: 6| Step: 1
Training loss: 2.2654552459716797
Validation loss: 2.3149657569905764

Epoch: 6| Step: 2
Training loss: 2.29514479637146
Validation loss: 2.313269443409417

Epoch: 6| Step: 3
Training loss: 2.7723851203918457
Validation loss: 2.3096499545599825

Epoch: 6| Step: 4
Training loss: 2.6486611366271973
Validation loss: 2.2976904761406685

Epoch: 6| Step: 5
Training loss: 2.1756725311279297
Validation loss: 2.2921072283098773

Epoch: 6| Step: 6
Training loss: 2.521787643432617
Validation loss: 2.274320912617509

Epoch: 6| Step: 7
Training loss: 1.765015959739685
Validation loss: 2.2850993192324074

Epoch: 6| Step: 8
Training loss: 2.073307514190674
Validation loss: 2.3019747990433888

Epoch: 6| Step: 9
Training loss: 1.713728666305542
Validation loss: 2.3013250250970163

Epoch: 6| Step: 10
Training loss: 3.126067638397217
Validation loss: 2.3055595428712907

Epoch: 6| Step: 11
Training loss: 2.244255781173706
Validation loss: 2.319274675461554

Epoch: 6| Step: 12
Training loss: 2.3536081314086914
Validation loss: 2.320427703601058

Epoch: 6| Step: 13
Training loss: 2.123721122741699
Validation loss: 2.3271498039204586

Epoch: 364| Step: 0
Training loss: 2.8304362297058105
Validation loss: 2.327266308569139

Epoch: 6| Step: 1
Training loss: 2.1732420921325684
Validation loss: 2.328919082559565

Epoch: 6| Step: 2
Training loss: 1.8462471961975098
Validation loss: 2.3253364255351405

Epoch: 6| Step: 3
Training loss: 3.00479793548584
Validation loss: 2.3067169907272502

Epoch: 6| Step: 4
Training loss: 2.1088125705718994
Validation loss: 2.2907560076764835

Epoch: 6| Step: 5
Training loss: 2.226125955581665
Validation loss: 2.286902314873152

Epoch: 6| Step: 6
Training loss: 2.1333446502685547
Validation loss: 2.2933212710965063

Epoch: 6| Step: 7
Training loss: 2.1750786304473877
Validation loss: 2.2884106841138614

Epoch: 6| Step: 8
Training loss: 2.512124538421631
Validation loss: 2.2820438531137284

Epoch: 6| Step: 9
Training loss: 1.770848274230957
Validation loss: 2.307107589578116

Epoch: 6| Step: 10
Training loss: 2.0174341201782227
Validation loss: 2.319686484593217

Epoch: 6| Step: 11
Training loss: 2.2721266746520996
Validation loss: 2.326659333321356

Epoch: 6| Step: 12
Training loss: 2.7104878425598145
Validation loss: 2.332040845706899

Epoch: 6| Step: 13
Training loss: 3.334137439727783
Validation loss: 2.3467196251756404

Epoch: 365| Step: 0
Training loss: 1.592420220375061
Validation loss: 2.343766684173256

Epoch: 6| Step: 1
Training loss: 1.7693638801574707
Validation loss: 2.332652363725888

Epoch: 6| Step: 2
Training loss: 1.9024139642715454
Validation loss: 2.3107805867348947

Epoch: 6| Step: 3
Training loss: 2.925837755203247
Validation loss: 2.2940919283897645

Epoch: 6| Step: 4
Training loss: 2.788447380065918
Validation loss: 2.299596366061959

Epoch: 6| Step: 5
Training loss: 2.541811943054199
Validation loss: 2.299105795480872

Epoch: 6| Step: 6
Training loss: 2.475551128387451
Validation loss: 2.290156892550889

Epoch: 6| Step: 7
Training loss: 1.9257848262786865
Validation loss: 2.281095581669961

Epoch: 6| Step: 8
Training loss: 2.584218978881836
Validation loss: 2.2858134264587076

Epoch: 6| Step: 9
Training loss: 2.6977756023406982
Validation loss: 2.285909391218616

Epoch: 6| Step: 10
Training loss: 2.0112509727478027
Validation loss: 2.287859078376524

Epoch: 6| Step: 11
Training loss: 2.265493869781494
Validation loss: 2.2840332664469236

Epoch: 6| Step: 12
Training loss: 2.7915844917297363
Validation loss: 2.284794099869267

Epoch: 6| Step: 13
Training loss: 1.937223196029663
Validation loss: 2.2794551080273044

Epoch: 366| Step: 0
Training loss: 1.9823044538497925
Validation loss: 2.2843688982789234

Epoch: 6| Step: 1
Training loss: 2.432361602783203
Validation loss: 2.293468793233236

Epoch: 6| Step: 2
Training loss: 2.8157496452331543
Validation loss: 2.2897399830561813

Epoch: 6| Step: 3
Training loss: 2.4896368980407715
Validation loss: 2.2972476020936043

Epoch: 6| Step: 4
Training loss: 2.33384370803833
Validation loss: 2.294791034472886

Epoch: 6| Step: 5
Training loss: 2.1307764053344727
Validation loss: 2.292666689042122

Epoch: 6| Step: 6
Training loss: 2.5140953063964844
Validation loss: 2.301674181415189

Epoch: 6| Step: 7
Training loss: 2.1891543865203857
Validation loss: 2.306922738270093

Epoch: 6| Step: 8
Training loss: 2.510998487472534
Validation loss: 2.2969093912391254

Epoch: 6| Step: 9
Training loss: 1.913447618484497
Validation loss: 2.29491376748649

Epoch: 6| Step: 10
Training loss: 2.151768207550049
Validation loss: 2.2838249219361173

Epoch: 6| Step: 11
Training loss: 2.767540693283081
Validation loss: 2.277472578069215

Epoch: 6| Step: 12
Training loss: 2.1727254390716553
Validation loss: 2.2908223239324426

Epoch: 6| Step: 13
Training loss: 1.8775994777679443
Validation loss: 2.29848192327766

Epoch: 367| Step: 0
Training loss: 1.6134252548217773
Validation loss: 2.311515200522638

Epoch: 6| Step: 1
Training loss: 2.7649171352386475
Validation loss: 2.3161552644545034

Epoch: 6| Step: 2
Training loss: 2.3290953636169434
Validation loss: 2.312395406025712

Epoch: 6| Step: 3
Training loss: 2.3435678482055664
Validation loss: 2.3168551357843543

Epoch: 6| Step: 4
Training loss: 2.5855369567871094
Validation loss: 2.31698094132126

Epoch: 6| Step: 5
Training loss: 2.1436538696289062
Validation loss: 2.3201109414459555

Epoch: 6| Step: 6
Training loss: 2.352389097213745
Validation loss: 2.32335058335335

Epoch: 6| Step: 7
Training loss: 2.435483932495117
Validation loss: 2.310513460507957

Epoch: 6| Step: 8
Training loss: 2.1258039474487305
Validation loss: 2.2962455877693753

Epoch: 6| Step: 9
Training loss: 2.42810320854187
Validation loss: 2.2908529261107087

Epoch: 6| Step: 10
Training loss: 2.135683059692383
Validation loss: 2.284027438009939

Epoch: 6| Step: 11
Training loss: 1.9942288398742676
Validation loss: 2.2770519564228673

Epoch: 6| Step: 12
Training loss: 2.5863561630249023
Validation loss: 2.266348554242042

Epoch: 6| Step: 13
Training loss: 2.7049736976623535
Validation loss: 2.2864578334234094

Epoch: 368| Step: 0
Training loss: 2.5766658782958984
Validation loss: 2.2722855793532504

Epoch: 6| Step: 1
Training loss: 2.35986590385437
Validation loss: 2.265538061818769

Epoch: 6| Step: 2
Training loss: 2.599154472351074
Validation loss: 2.2672171477348573

Epoch: 6| Step: 3
Training loss: 2.045130729675293
Validation loss: 2.2739906900672504

Epoch: 6| Step: 4
Training loss: 3.289952516555786
Validation loss: 2.2917218797950336

Epoch: 6| Step: 5
Training loss: 2.2495126724243164
Validation loss: 2.292543149763538

Epoch: 6| Step: 6
Training loss: 2.919034481048584
Validation loss: 2.2982461913939445

Epoch: 6| Step: 7
Training loss: 1.8395696878433228
Validation loss: 2.288878353693152

Epoch: 6| Step: 8
Training loss: 1.7634270191192627
Validation loss: 2.2928526670702043

Epoch: 6| Step: 9
Training loss: 1.847482681274414
Validation loss: 2.3002593696758313

Epoch: 6| Step: 10
Training loss: 2.96687650680542
Validation loss: 2.295841847696612

Epoch: 6| Step: 11
Training loss: 1.2999722957611084
Validation loss: 2.292581840228009

Epoch: 6| Step: 12
Training loss: 2.4157092571258545
Validation loss: 2.2853935098135345

Epoch: 6| Step: 13
Training loss: 2.1330368518829346
Validation loss: 2.310032175433251

Epoch: 369| Step: 0
Training loss: 2.407626152038574
Validation loss: 2.311106361368651

Epoch: 6| Step: 1
Training loss: 2.2905921936035156
Validation loss: 2.313572132459251

Epoch: 6| Step: 2
Training loss: 1.790177583694458
Validation loss: 2.3238664211765414

Epoch: 6| Step: 3
Training loss: 2.557427167892456
Validation loss: 2.3000841397111134

Epoch: 6| Step: 4
Training loss: 2.2670984268188477
Validation loss: 2.281283768274451

Epoch: 6| Step: 5
Training loss: 2.2924535274505615
Validation loss: 2.289378148253246

Epoch: 6| Step: 6
Training loss: 2.1969127655029297
Validation loss: 2.2830706411792385

Epoch: 6| Step: 7
Training loss: 1.9087274074554443
Validation loss: 2.2956367667003343

Epoch: 6| Step: 8
Training loss: 2.6702070236206055
Validation loss: 2.270734299895584

Epoch: 6| Step: 9
Training loss: 2.3358092308044434
Validation loss: 2.269496179396106

Epoch: 6| Step: 10
Training loss: 2.7415809631347656
Validation loss: 2.2767758420718613

Epoch: 6| Step: 11
Training loss: 2.152137041091919
Validation loss: 2.269657737465315

Epoch: 6| Step: 12
Training loss: 2.311368465423584
Validation loss: 2.275090353463286

Epoch: 6| Step: 13
Training loss: 2.490091323852539
Validation loss: 2.2874575302165043

Epoch: 370| Step: 0
Training loss: 2.0916261672973633
Validation loss: 2.290855238514562

Epoch: 6| Step: 1
Training loss: 2.5357303619384766
Validation loss: 2.310886054910639

Epoch: 6| Step: 2
Training loss: 3.0128068923950195
Validation loss: 2.327408177878267

Epoch: 6| Step: 3
Training loss: 2.0781352519989014
Validation loss: 2.3364073896920807

Epoch: 6| Step: 4
Training loss: 2.539212942123413
Validation loss: 2.3138203620910645

Epoch: 6| Step: 5
Training loss: 2.838836669921875
Validation loss: 2.3113562086577057

Epoch: 6| Step: 6
Training loss: 1.6642999649047852
Validation loss: 2.3012328788798344

Epoch: 6| Step: 7
Training loss: 2.053736448287964
Validation loss: 2.286307801482498

Epoch: 6| Step: 8
Training loss: 1.96353018283844
Validation loss: 2.281630746779903

Epoch: 6| Step: 9
Training loss: 2.0670859813690186
Validation loss: 2.27526492329054

Epoch: 6| Step: 10
Training loss: 2.522369384765625
Validation loss: 2.304717695841225

Epoch: 6| Step: 11
Training loss: 2.9680919647216797
Validation loss: 2.2907202013077272

Epoch: 6| Step: 12
Training loss: 1.5029714107513428
Validation loss: 2.284866461189844

Epoch: 6| Step: 13
Training loss: 2.627640962600708
Validation loss: 2.310113158277286

Epoch: 371| Step: 0
Training loss: 2.7973849773406982
Validation loss: 2.3217725369238083

Epoch: 6| Step: 1
Training loss: 2.7877817153930664
Validation loss: 2.3096319296026744

Epoch: 6| Step: 2
Training loss: 1.7383315563201904
Validation loss: 2.3161830773917575

Epoch: 6| Step: 3
Training loss: 3.1926088333129883
Validation loss: 2.325346141733149

Epoch: 6| Step: 4
Training loss: 2.0135741233825684
Validation loss: 2.3326147756268902

Epoch: 6| Step: 5
Training loss: 2.1506760120391846
Validation loss: 2.3360534201386156

Epoch: 6| Step: 6
Training loss: 2.308417797088623
Validation loss: 2.3143286448653027

Epoch: 6| Step: 7
Training loss: 2.2529051303863525
Validation loss: 2.3009256291133102

Epoch: 6| Step: 8
Training loss: 2.3672637939453125
Validation loss: 2.2899677522720827

Epoch: 6| Step: 9
Training loss: 2.458637237548828
Validation loss: 2.2806417249864146

Epoch: 6| Step: 10
Training loss: 2.393105983734131
Validation loss: 2.270020306751292

Epoch: 6| Step: 11
Training loss: 1.5727660655975342
Validation loss: 2.2601528975271408

Epoch: 6| Step: 12
Training loss: 2.346162796020508
Validation loss: 2.257480513664984

Epoch: 6| Step: 13
Training loss: 1.7787461280822754
Validation loss: 2.2661966149524977

Epoch: 372| Step: 0
Training loss: 2.3934311866760254
Validation loss: 2.23906220159223

Epoch: 6| Step: 1
Training loss: 1.8041499853134155
Validation loss: 2.2524448569102953

Epoch: 6| Step: 2
Training loss: 2.8613126277923584
Validation loss: 2.2678905046114357

Epoch: 6| Step: 3
Training loss: 2.4249496459960938
Validation loss: 2.2542870172890286

Epoch: 6| Step: 4
Training loss: 2.3563649654388428
Validation loss: 2.267574769194408

Epoch: 6| Step: 5
Training loss: 2.2286248207092285
Validation loss: 2.2877949976151988

Epoch: 6| Step: 6
Training loss: 2.2742722034454346
Validation loss: 2.2968407805247972

Epoch: 6| Step: 7
Training loss: 1.8642754554748535
Validation loss: 2.2761949236674974

Epoch: 6| Step: 8
Training loss: 2.320685386657715
Validation loss: 2.2856160517661803

Epoch: 6| Step: 9
Training loss: 2.2048325538635254
Validation loss: 2.2851489384969077

Epoch: 6| Step: 10
Training loss: 2.371126174926758
Validation loss: 2.293627571034175

Epoch: 6| Step: 11
Training loss: 2.389529228210449
Validation loss: 2.3036497767253588

Epoch: 6| Step: 12
Training loss: 2.320916175842285
Validation loss: 2.3049977517897084

Epoch: 6| Step: 13
Training loss: 2.3825132846832275
Validation loss: 2.318801497900358

Epoch: 373| Step: 0
Training loss: 2.9379348754882812
Validation loss: 2.307331156987016

Epoch: 6| Step: 1
Training loss: 2.310910940170288
Validation loss: 2.2841114895318144

Epoch: 6| Step: 2
Training loss: 2.118091344833374
Validation loss: 2.2790568310727357

Epoch: 6| Step: 3
Training loss: 1.593221664428711
Validation loss: 2.280334318837812

Epoch: 6| Step: 4
Training loss: 2.129851818084717
Validation loss: 2.2745055819070465

Epoch: 6| Step: 5
Training loss: 1.718117594718933
Validation loss: 2.2664250302058395

Epoch: 6| Step: 6
Training loss: 2.4446446895599365
Validation loss: 2.2655784160860124

Epoch: 6| Step: 7
Training loss: 2.7273685932159424
Validation loss: 2.287898443078482

Epoch: 6| Step: 8
Training loss: 3.436762571334839
Validation loss: 2.3049429898620932

Epoch: 6| Step: 9
Training loss: 2.115668296813965
Validation loss: 2.296747515278478

Epoch: 6| Step: 10
Training loss: 2.2538347244262695
Validation loss: 2.2954803461669595

Epoch: 6| Step: 11
Training loss: 2.1649227142333984
Validation loss: 2.3111926637670046

Epoch: 6| Step: 12
Training loss: 2.1001038551330566
Validation loss: 2.3111924215029647

Epoch: 6| Step: 13
Training loss: 2.128748893737793
Validation loss: 2.3168924547010854

Epoch: 374| Step: 0
Training loss: 2.760448932647705
Validation loss: 2.298121178021995

Epoch: 6| Step: 1
Training loss: 2.3714561462402344
Validation loss: 2.2895036692260415

Epoch: 6| Step: 2
Training loss: 3.5497188568115234
Validation loss: 2.283263357736731

Epoch: 6| Step: 3
Training loss: 2.1816627979278564
Validation loss: 2.270320344996709

Epoch: 6| Step: 4
Training loss: 2.212881088256836
Validation loss: 2.2783229530498548

Epoch: 6| Step: 5
Training loss: 1.6040356159210205
Validation loss: 2.279009267848025

Epoch: 6| Step: 6
Training loss: 2.5432753562927246
Validation loss: 2.27022893967167

Epoch: 6| Step: 7
Training loss: 2.157003164291382
Validation loss: 2.2840583285977765

Epoch: 6| Step: 8
Training loss: 2.024667739868164
Validation loss: 2.28280286635122

Epoch: 6| Step: 9
Training loss: 1.7330743074417114
Validation loss: 2.2806522436039423

Epoch: 6| Step: 10
Training loss: 2.266355514526367
Validation loss: 2.2726456708805536

Epoch: 6| Step: 11
Training loss: 2.6739554405212402
Validation loss: 2.2748558008542625

Epoch: 6| Step: 12
Training loss: 1.9059333801269531
Validation loss: 2.295277000755392

Epoch: 6| Step: 13
Training loss: 2.02402925491333
Validation loss: 2.297990015757981

Epoch: 375| Step: 0
Training loss: 2.0571160316467285
Validation loss: 2.3122372088893766

Epoch: 6| Step: 1
Training loss: 2.027585029602051
Validation loss: 2.3169396897797943

Epoch: 6| Step: 2
Training loss: 2.1269612312316895
Validation loss: 2.3149053845354306

Epoch: 6| Step: 3
Training loss: 2.05844783782959
Validation loss: 2.3141931692759194

Epoch: 6| Step: 4
Training loss: 2.1256022453308105
Validation loss: 2.2998374200636342

Epoch: 6| Step: 5
Training loss: 2.537508487701416
Validation loss: 2.30022087917533

Epoch: 6| Step: 6
Training loss: 2.7185537815093994
Validation loss: 2.3017676299618137

Epoch: 6| Step: 7
Training loss: 1.328434944152832
Validation loss: 2.2992909057165987

Epoch: 6| Step: 8
Training loss: 2.8023641109466553
Validation loss: 2.29802083200024

Epoch: 6| Step: 9
Training loss: 3.1514573097229004
Validation loss: 2.301209927887045

Epoch: 6| Step: 10
Training loss: 2.814028263092041
Validation loss: 2.2962278243034118

Epoch: 6| Step: 11
Training loss: 1.398546814918518
Validation loss: 2.2975820905418805

Epoch: 6| Step: 12
Training loss: 2.6957621574401855
Validation loss: 2.297149201875092

Epoch: 6| Step: 13
Training loss: 2.0971059799194336
Validation loss: 2.2937282182837047

Epoch: 376| Step: 0
Training loss: 2.5305182933807373
Validation loss: 2.2925724393577984

Epoch: 6| Step: 1
Training loss: 1.694604754447937
Validation loss: 2.275495557374852

Epoch: 6| Step: 2
Training loss: 1.3956890106201172
Validation loss: 2.2606968546426423

Epoch: 6| Step: 3
Training loss: 2.3052525520324707
Validation loss: 2.256854985349922

Epoch: 6| Step: 4
Training loss: 3.2889535427093506
Validation loss: 2.2466904732488815

Epoch: 6| Step: 5
Training loss: 2.1204280853271484
Validation loss: 2.2500452072389665

Epoch: 6| Step: 6
Training loss: 2.0793776512145996
Validation loss: 2.2386202530194352

Epoch: 6| Step: 7
Training loss: 2.205516815185547
Validation loss: 2.235569505281346

Epoch: 6| Step: 8
Training loss: 2.205488681793213
Validation loss: 2.2475615842368013

Epoch: 6| Step: 9
Training loss: 2.5782699584960938
Validation loss: 2.252423142874113

Epoch: 6| Step: 10
Training loss: 2.6111810207366943
Validation loss: 2.249721621954313

Epoch: 6| Step: 11
Training loss: 2.080789804458618
Validation loss: 2.2639393678275486

Epoch: 6| Step: 12
Training loss: 2.555695056915283
Validation loss: 2.2711295594451246

Epoch: 6| Step: 13
Training loss: 2.8212053775787354
Validation loss: 2.301373025422455

Epoch: 377| Step: 0
Training loss: 2.4815897941589355
Validation loss: 2.3219360100325717

Epoch: 6| Step: 1
Training loss: 2.525726318359375
Validation loss: 2.3261293454836776

Epoch: 6| Step: 2
Training loss: 2.8231863975524902
Validation loss: 2.322434872709295

Epoch: 6| Step: 3
Training loss: 2.311872959136963
Validation loss: 2.295683553141932

Epoch: 6| Step: 4
Training loss: 1.4373369216918945
Validation loss: 2.291540999566355

Epoch: 6| Step: 5
Training loss: 2.425830125808716
Validation loss: 2.2742777947456605

Epoch: 6| Step: 6
Training loss: 2.213172674179077
Validation loss: 2.2718592407882854

Epoch: 6| Step: 7
Training loss: 2.7419590950012207
Validation loss: 2.267404969020556

Epoch: 6| Step: 8
Training loss: 1.9625511169433594
Validation loss: 2.2773581499694497

Epoch: 6| Step: 9
Training loss: 2.4115211963653564
Validation loss: 2.2958016062295563

Epoch: 6| Step: 10
Training loss: 1.7701197862625122
Validation loss: 2.286275235555505

Epoch: 6| Step: 11
Training loss: 2.457214593887329
Validation loss: 2.2878041011030956

Epoch: 6| Step: 12
Training loss: 1.9763572216033936
Validation loss: 2.2916995069032073

Epoch: 6| Step: 13
Training loss: 2.847944736480713
Validation loss: 2.3021171426260345

Epoch: 378| Step: 0
Training loss: 2.347477436065674
Validation loss: 2.3065040906270347

Epoch: 6| Step: 1
Training loss: 2.36234450340271
Validation loss: 2.299076021358531

Epoch: 6| Step: 2
Training loss: 2.159552574157715
Validation loss: 2.306302488491099

Epoch: 6| Step: 3
Training loss: 2.5893375873565674
Validation loss: 2.297241276310336

Epoch: 6| Step: 4
Training loss: 3.0034260749816895
Validation loss: 2.320352787612587

Epoch: 6| Step: 5
Training loss: 2.203859806060791
Validation loss: 2.3065524895985923

Epoch: 6| Step: 6
Training loss: 2.0332536697387695
Validation loss: 2.3114951451619468

Epoch: 6| Step: 7
Training loss: 2.015659809112549
Validation loss: 2.3034988449465845

Epoch: 6| Step: 8
Training loss: 1.9811280965805054
Validation loss: 2.313263508581346

Epoch: 6| Step: 9
Training loss: 2.7811787128448486
Validation loss: 2.3127989384435836

Epoch: 6| Step: 10
Training loss: 2.1766796112060547
Validation loss: 2.301861539963753

Epoch: 6| Step: 11
Training loss: 2.110076665878296
Validation loss: 2.287747290826613

Epoch: 6| Step: 12
Training loss: 2.05972957611084
Validation loss: 2.2874405255881687

Epoch: 6| Step: 13
Training loss: 2.081491470336914
Validation loss: 2.295784781056066

Epoch: 379| Step: 0
Training loss: 2.0053741931915283
Validation loss: 2.2753742484636206

Epoch: 6| Step: 1
Training loss: 3.422140598297119
Validation loss: 2.2622062390850437

Epoch: 6| Step: 2
Training loss: 2.200291156768799
Validation loss: 2.257428438432755

Epoch: 6| Step: 3
Training loss: 1.9716752767562866
Validation loss: 2.2486415729727796

Epoch: 6| Step: 4
Training loss: 2.9829187393188477
Validation loss: 2.237332708092146

Epoch: 6| Step: 5
Training loss: 2.0392491817474365
Validation loss: 2.2670330873099704

Epoch: 6| Step: 6
Training loss: 2.432307004928589
Validation loss: 2.2604155284102245

Epoch: 6| Step: 7
Training loss: 1.715111494064331
Validation loss: 2.2517301318466023

Epoch: 6| Step: 8
Training loss: 2.317559242248535
Validation loss: 2.2633037644047893

Epoch: 6| Step: 9
Training loss: 1.998009443283081
Validation loss: 2.273234877535092

Epoch: 6| Step: 10
Training loss: 2.0955817699432373
Validation loss: 2.2834405437592538

Epoch: 6| Step: 11
Training loss: 2.1831164360046387
Validation loss: 2.3046369783339964

Epoch: 6| Step: 12
Training loss: 2.0556445121765137
Validation loss: 2.3063146798841414

Epoch: 6| Step: 13
Training loss: 2.897010326385498
Validation loss: 2.2902557401246924

Epoch: 380| Step: 0
Training loss: 2.8696088790893555
Validation loss: 2.2903389853815876

Epoch: 6| Step: 1
Training loss: 2.1362318992614746
Validation loss: 2.2736499258266982

Epoch: 6| Step: 2
Training loss: 1.8700368404388428
Validation loss: 2.2571550338499007

Epoch: 6| Step: 3
Training loss: 1.987314224243164
Validation loss: 2.23394416352754

Epoch: 6| Step: 4
Training loss: 2.155649423599243
Validation loss: 2.2519109633661087

Epoch: 6| Step: 5
Training loss: 2.1409645080566406
Validation loss: 2.270155314476259

Epoch: 6| Step: 6
Training loss: 2.5947742462158203
Validation loss: 2.2975357835010817

Epoch: 6| Step: 7
Training loss: 2.584123373031616
Validation loss: 2.319046148689844

Epoch: 6| Step: 8
Training loss: 2.225609540939331
Validation loss: 2.3263095271202827

Epoch: 6| Step: 9
Training loss: 1.7287888526916504
Validation loss: 2.3335741181527414

Epoch: 6| Step: 10
Training loss: 2.6049530506134033
Validation loss: 2.3047458946063952

Epoch: 6| Step: 11
Training loss: 2.550156831741333
Validation loss: 2.306168959986779

Epoch: 6| Step: 12
Training loss: 2.5021791458129883
Validation loss: 2.2759633935907835

Epoch: 6| Step: 13
Training loss: 1.8975194692611694
Validation loss: 2.2613844615156933

Epoch: 381| Step: 0
Training loss: 2.6622543334960938
Validation loss: 2.2577921754570416

Epoch: 6| Step: 1
Training loss: 2.5812578201293945
Validation loss: 2.2734502054029897

Epoch: 6| Step: 2
Training loss: 2.161942958831787
Validation loss: 2.273154120291433

Epoch: 6| Step: 3
Training loss: 2.6094980239868164
Validation loss: 2.264809368759073

Epoch: 6| Step: 4
Training loss: 2.509202003479004
Validation loss: 2.273325791922949

Epoch: 6| Step: 5
Training loss: 2.573479652404785
Validation loss: 2.2607270171565395

Epoch: 6| Step: 6
Training loss: 2.070042133331299
Validation loss: 2.2822677063685592

Epoch: 6| Step: 7
Training loss: 1.9747272729873657
Validation loss: 2.301699785776036

Epoch: 6| Step: 8
Training loss: 2.184821367263794
Validation loss: 2.3118132570738434

Epoch: 6| Step: 9
Training loss: 2.3974056243896484
Validation loss: 2.3190450001788396

Epoch: 6| Step: 10
Training loss: 1.965776801109314
Validation loss: 2.3303134928467455

Epoch: 6| Step: 11
Training loss: 2.5119788646698
Validation loss: 2.286736201214534

Epoch: 6| Step: 12
Training loss: 2.090951919555664
Validation loss: 2.280710845865229

Epoch: 6| Step: 13
Training loss: 1.3615885972976685
Validation loss: 2.275067158924636

Epoch: 382| Step: 0
Training loss: 1.9733916521072388
Validation loss: 2.2699521690286617

Epoch: 6| Step: 1
Training loss: 2.9551842212677
Validation loss: 2.260465189974795

Epoch: 6| Step: 2
Training loss: 2.5140366554260254
Validation loss: 2.2530047560250885

Epoch: 6| Step: 3
Training loss: 2.501953363418579
Validation loss: 2.2623925029590564

Epoch: 6| Step: 4
Training loss: 3.121243953704834
Validation loss: 2.254143594413675

Epoch: 6| Step: 5
Training loss: 2.0383358001708984
Validation loss: 2.250374350496518

Epoch: 6| Step: 6
Training loss: 1.9720842838287354
Validation loss: 2.2611590816128637

Epoch: 6| Step: 7
Training loss: 1.7738937139511108
Validation loss: 2.266901808400308

Epoch: 6| Step: 8
Training loss: 2.1156039237976074
Validation loss: 2.264855610427036

Epoch: 6| Step: 9
Training loss: 2.8039889335632324
Validation loss: 2.2849535660077165

Epoch: 6| Step: 10
Training loss: 2.2027878761291504
Validation loss: 2.2789341480501237

Epoch: 6| Step: 11
Training loss: 2.185076951980591
Validation loss: 2.261204122215189

Epoch: 6| Step: 12
Training loss: 2.040266990661621
Validation loss: 2.289309235029323

Epoch: 6| Step: 13
Training loss: 1.489036202430725
Validation loss: 2.2982160532346336

Epoch: 383| Step: 0
Training loss: 2.3217849731445312
Validation loss: 2.307623255637384

Epoch: 6| Step: 1
Training loss: 2.3849616050720215
Validation loss: 2.3198955033415105

Epoch: 6| Step: 2
Training loss: 2.4936130046844482
Validation loss: 2.324720310908492

Epoch: 6| Step: 3
Training loss: 2.675567626953125
Validation loss: 2.3265024872236353

Epoch: 6| Step: 4
Training loss: 2.023740768432617
Validation loss: 2.3366297291171167

Epoch: 6| Step: 5
Training loss: 1.9938855171203613
Validation loss: 2.3004379016096874

Epoch: 6| Step: 6
Training loss: 2.331364393234253
Validation loss: 2.290594088133945

Epoch: 6| Step: 7
Training loss: 1.863221526145935
Validation loss: 2.2647965492740756

Epoch: 6| Step: 8
Training loss: 2.9171907901763916
Validation loss: 2.2692737656254924

Epoch: 6| Step: 9
Training loss: 2.8150508403778076
Validation loss: 2.2699489490960234

Epoch: 6| Step: 10
Training loss: 2.2480645179748535
Validation loss: 2.2678792092107956

Epoch: 6| Step: 11
Training loss: 1.8457934856414795
Validation loss: 2.253290758338026

Epoch: 6| Step: 12
Training loss: 1.6267592906951904
Validation loss: 2.273683432609804

Epoch: 6| Step: 13
Training loss: 2.5371217727661133
Validation loss: 2.271746878982872

Epoch: 384| Step: 0
Training loss: 2.279799461364746
Validation loss: 2.284434098069386

Epoch: 6| Step: 1
Training loss: 2.5748612880706787
Validation loss: 2.313558186254194

Epoch: 6| Step: 2
Training loss: 1.4936679601669312
Validation loss: 2.364352999194976

Epoch: 6| Step: 3
Training loss: 2.689784526824951
Validation loss: 2.371545232752318

Epoch: 6| Step: 4
Training loss: 1.9172606468200684
Validation loss: 2.3693237996870473

Epoch: 6| Step: 5
Training loss: 2.233095169067383
Validation loss: 2.373094215187975

Epoch: 6| Step: 6
Training loss: 1.7299939393997192
Validation loss: 2.3639506755336637

Epoch: 6| Step: 7
Training loss: 2.842998743057251
Validation loss: 2.353339074760355

Epoch: 6| Step: 8
Training loss: 2.6894049644470215
Validation loss: 2.3301881795288413

Epoch: 6| Step: 9
Training loss: 2.7405948638916016
Validation loss: 2.285699869996758

Epoch: 6| Step: 10
Training loss: 1.5065670013427734
Validation loss: 2.2699966687028126

Epoch: 6| Step: 11
Training loss: 2.5620079040527344
Validation loss: 2.2530737923037623

Epoch: 6| Step: 12
Training loss: 2.596221685409546
Validation loss: 2.2591637014060892

Epoch: 6| Step: 13
Training loss: 2.3758625984191895
Validation loss: 2.238216644974165

Epoch: 385| Step: 0
Training loss: 2.35545015335083
Validation loss: 2.2545036910682597

Epoch: 6| Step: 1
Training loss: 2.4770522117614746
Validation loss: 2.2419240628519366

Epoch: 6| Step: 2
Training loss: 2.5821022987365723
Validation loss: 2.2332869960415747

Epoch: 6| Step: 3
Training loss: 2.4109203815460205
Validation loss: 2.254394321031468

Epoch: 6| Step: 4
Training loss: 2.3805108070373535
Validation loss: 2.243766123248685

Epoch: 6| Step: 5
Training loss: 2.1820740699768066
Validation loss: 2.26451882239311

Epoch: 6| Step: 6
Training loss: 1.4222564697265625
Validation loss: 2.2847477492465766

Epoch: 6| Step: 7
Training loss: 2.526015281677246
Validation loss: 2.2869024020369335

Epoch: 6| Step: 8
Training loss: 1.4713850021362305
Validation loss: 2.279083228880359

Epoch: 6| Step: 9
Training loss: 1.9072418212890625
Validation loss: 2.2918063773903796

Epoch: 6| Step: 10
Training loss: 2.4971261024475098
Validation loss: 2.2873313785881124

Epoch: 6| Step: 11
Training loss: 2.5502920150756836
Validation loss: 2.2899854260106243

Epoch: 6| Step: 12
Training loss: 2.7884092330932617
Validation loss: 2.2884534225668958

Epoch: 6| Step: 13
Training loss: 2.4400405883789062
Validation loss: 2.260884569537255

Epoch: 386| Step: 0
Training loss: 2.024665355682373
Validation loss: 2.259296659500368

Epoch: 6| Step: 1
Training loss: 2.573902130126953
Validation loss: 2.2466489063796176

Epoch: 6| Step: 2
Training loss: 2.7752108573913574
Validation loss: 2.2553839324623026

Epoch: 6| Step: 3
Training loss: 1.9026607275009155
Validation loss: 2.2555647947454966

Epoch: 6| Step: 4
Training loss: 2.5988926887512207
Validation loss: 2.2578830001174763

Epoch: 6| Step: 5
Training loss: 2.5872178077697754
Validation loss: 2.276750474847773

Epoch: 6| Step: 6
Training loss: 1.2743384838104248
Validation loss: 2.3045926606783302

Epoch: 6| Step: 7
Training loss: 2.6208996772766113
Validation loss: 2.293858317918675

Epoch: 6| Step: 8
Training loss: 2.9956352710723877
Validation loss: 2.2973371423700804

Epoch: 6| Step: 9
Training loss: 2.437018394470215
Validation loss: 2.321414250199513

Epoch: 6| Step: 10
Training loss: 1.7892870903015137
Validation loss: 2.320569722883163

Epoch: 6| Step: 11
Training loss: 1.6258010864257812
Validation loss: 2.2865296986795243

Epoch: 6| Step: 12
Training loss: 2.3294968605041504
Validation loss: 2.2901730409232517

Epoch: 6| Step: 13
Training loss: 2.3509275913238525
Validation loss: 2.2597974679803334

Epoch: 387| Step: 0
Training loss: 1.970651388168335
Validation loss: 2.260733086575744

Epoch: 6| Step: 1
Training loss: 2.3185110092163086
Validation loss: 2.280343819690007

Epoch: 6| Step: 2
Training loss: 3.4094126224517822
Validation loss: 2.265343237948674

Epoch: 6| Step: 3
Training loss: 1.342637062072754
Validation loss: 2.2630365458867883

Epoch: 6| Step: 4
Training loss: 1.5159478187561035
Validation loss: 2.266569757974276

Epoch: 6| Step: 5
Training loss: 2.912774085998535
Validation loss: 2.253865894450936

Epoch: 6| Step: 6
Training loss: 1.8767930269241333
Validation loss: 2.260855077415384

Epoch: 6| Step: 7
Training loss: 2.5998623371124268
Validation loss: 2.2891983088626655

Epoch: 6| Step: 8
Training loss: 3.3217015266418457
Validation loss: 2.317343665707496

Epoch: 6| Step: 9
Training loss: 1.2922461032867432
Validation loss: 2.303852055662422

Epoch: 6| Step: 10
Training loss: 2.061133861541748
Validation loss: 2.3156144926624913

Epoch: 6| Step: 11
Training loss: 2.4770004749298096
Validation loss: 2.324931477987638

Epoch: 6| Step: 12
Training loss: 2.6447460651397705
Validation loss: 2.317857600027515

Epoch: 6| Step: 13
Training loss: 1.9078292846679688
Validation loss: 2.317596297110281

Epoch: 388| Step: 0
Training loss: 2.0640530586242676
Validation loss: 2.3089821569381224

Epoch: 6| Step: 1
Training loss: 2.5663676261901855
Validation loss: 2.2933189510017313

Epoch: 6| Step: 2
Training loss: 2.558711528778076
Validation loss: 2.2772519101378736

Epoch: 6| Step: 3
Training loss: 1.6724774837493896
Validation loss: 2.2628801048442884

Epoch: 6| Step: 4
Training loss: 2.7915353775024414
Validation loss: 2.2685602967457106

Epoch: 6| Step: 5
Training loss: 2.8266539573669434
Validation loss: 2.2631345256682365

Epoch: 6| Step: 6
Training loss: 1.6416971683502197
Validation loss: 2.2446796650527627

Epoch: 6| Step: 7
Training loss: 2.546487808227539
Validation loss: 2.265555509956934

Epoch: 6| Step: 8
Training loss: 2.149355173110962
Validation loss: 2.2761094890614992

Epoch: 6| Step: 9
Training loss: 1.6458048820495605
Validation loss: 2.2741667532151744

Epoch: 6| Step: 10
Training loss: 2.2484865188598633
Validation loss: 2.276268348898939

Epoch: 6| Step: 11
Training loss: 2.0878658294677734
Validation loss: 2.2755870690909763

Epoch: 6| Step: 12
Training loss: 2.6696996688842773
Validation loss: 2.2597656762728127

Epoch: 6| Step: 13
Training loss: 2.0615720748901367
Validation loss: 2.2553723345520678

Epoch: 389| Step: 0
Training loss: 2.0614194869995117
Validation loss: 2.2574482323021017

Epoch: 6| Step: 1
Training loss: 3.035958766937256
Validation loss: 2.2499806342586393

Epoch: 6| Step: 2
Training loss: 2.010472536087036
Validation loss: 2.2446731854510564

Epoch: 6| Step: 3
Training loss: 1.9915544986724854
Validation loss: 2.2384963676493657

Epoch: 6| Step: 4
Training loss: 2.9687862396240234
Validation loss: 2.229201598833966

Epoch: 6| Step: 5
Training loss: 1.8761523962020874
Validation loss: 2.2315396070480347

Epoch: 6| Step: 6
Training loss: 2.016810417175293
Validation loss: 2.2323543512693016

Epoch: 6| Step: 7
Training loss: 2.1350903511047363
Validation loss: 2.2615371314428185

Epoch: 6| Step: 8
Training loss: 2.5536041259765625
Validation loss: 2.253368462285688

Epoch: 6| Step: 9
Training loss: 1.5876481533050537
Validation loss: 2.2631988679209063

Epoch: 6| Step: 10
Training loss: 2.62225341796875
Validation loss: 2.2875386925153833

Epoch: 6| Step: 11
Training loss: 2.5622143745422363
Validation loss: 2.2888658021086004

Epoch: 6| Step: 12
Training loss: 2.49535870552063
Validation loss: 2.2965930097846576

Epoch: 6| Step: 13
Training loss: 1.591814637184143
Validation loss: 2.274999313457038

Epoch: 390| Step: 0
Training loss: 1.869637131690979
Validation loss: 2.251801183146815

Epoch: 6| Step: 1
Training loss: 2.869433879852295
Validation loss: 2.246960502798839

Epoch: 6| Step: 2
Training loss: 2.3665945529937744
Validation loss: 2.239081777552123

Epoch: 6| Step: 3
Training loss: 1.7817286252975464
Validation loss: 2.221261737167194

Epoch: 6| Step: 4
Training loss: 2.362133502960205
Validation loss: 2.2299978348516647

Epoch: 6| Step: 5
Training loss: 2.2989587783813477
Validation loss: 2.2141731451916438

Epoch: 6| Step: 6
Training loss: 2.1243696212768555
Validation loss: 2.220044759012038

Epoch: 6| Step: 7
Training loss: 2.7353484630584717
Validation loss: 2.2571982414491716

Epoch: 6| Step: 8
Training loss: 1.961771011352539
Validation loss: 2.251915269000556

Epoch: 6| Step: 9
Training loss: 1.9902939796447754
Validation loss: 2.2691125792841755

Epoch: 6| Step: 10
Training loss: 2.226757526397705
Validation loss: 2.2718288616467546

Epoch: 6| Step: 11
Training loss: 3.042269229888916
Validation loss: 2.2877564071327128

Epoch: 6| Step: 12
Training loss: 1.7151908874511719
Validation loss: 2.2770626032224266

Epoch: 6| Step: 13
Training loss: 2.320101022720337
Validation loss: 2.2788949448575258

Epoch: 391| Step: 0
Training loss: 2.782259941101074
Validation loss: 2.264363509352489

Epoch: 6| Step: 1
Training loss: 2.644212007522583
Validation loss: 2.2378655838710007

Epoch: 6| Step: 2
Training loss: 2.69094181060791
Validation loss: 2.2349093601267827

Epoch: 6| Step: 3
Training loss: 2.222391128540039
Validation loss: 2.2385378576094106

Epoch: 6| Step: 4
Training loss: 2.172105312347412
Validation loss: 2.233944462191674

Epoch: 6| Step: 5
Training loss: 2.1271824836730957
Validation loss: 2.2265158314858713

Epoch: 6| Step: 6
Training loss: 2.8734962940216064
Validation loss: 2.2358491049017957

Epoch: 6| Step: 7
Training loss: 2.846165895462036
Validation loss: 2.24268764065158

Epoch: 6| Step: 8
Training loss: 1.785426139831543
Validation loss: 2.2468717508418585

Epoch: 6| Step: 9
Training loss: 1.8682135343551636
Validation loss: 2.2640437849106325

Epoch: 6| Step: 10
Training loss: 1.957565188407898
Validation loss: 2.2829824032322055

Epoch: 6| Step: 11
Training loss: 1.101089358329773
Validation loss: 2.2998798393434092

Epoch: 6| Step: 12
Training loss: 1.992264747619629
Validation loss: 2.3130748784670265

Epoch: 6| Step: 13
Training loss: 2.7522878646850586
Validation loss: 2.3107644281079693

Epoch: 392| Step: 0
Training loss: 2.0275068283081055
Validation loss: 2.317278164689259

Epoch: 6| Step: 1
Training loss: 2.813751220703125
Validation loss: 2.3269740073911604

Epoch: 6| Step: 2
Training loss: 2.8630261421203613
Validation loss: 2.357952871630269

Epoch: 6| Step: 3
Training loss: 1.6712154150009155
Validation loss: 2.327062624757008

Epoch: 6| Step: 4
Training loss: 2.45273494720459
Validation loss: 2.318124948009368

Epoch: 6| Step: 5
Training loss: 2.598034381866455
Validation loss: 2.3060561380078717

Epoch: 6| Step: 6
Training loss: 1.7923272848129272
Validation loss: 2.2649321684273342

Epoch: 6| Step: 7
Training loss: 2.1073784828186035
Validation loss: 2.2574559129694456

Epoch: 6| Step: 8
Training loss: 1.8651719093322754
Validation loss: 2.2652058575742986

Epoch: 6| Step: 9
Training loss: 2.3014168739318848
Validation loss: 2.2635040257566716

Epoch: 6| Step: 10
Training loss: 2.0715603828430176
Validation loss: 2.2627102944158737

Epoch: 6| Step: 11
Training loss: 2.4897706508636475
Validation loss: 2.2632868828312045

Epoch: 6| Step: 12
Training loss: 2.090294599533081
Validation loss: 2.265861003629623

Epoch: 6| Step: 13
Training loss: 2.59309720993042
Validation loss: 2.257124275289556

Epoch: 393| Step: 0
Training loss: 1.8856003284454346
Validation loss: 2.2884003731512252

Epoch: 6| Step: 1
Training loss: 2.119203567504883
Validation loss: 2.294352836506341

Epoch: 6| Step: 2
Training loss: 2.9628171920776367
Validation loss: 2.2920512486529607

Epoch: 6| Step: 3
Training loss: 2.2677571773529053
Validation loss: 2.291500199225641

Epoch: 6| Step: 4
Training loss: 1.7559773921966553
Validation loss: 2.2717910325655373

Epoch: 6| Step: 5
Training loss: 2.842151641845703
Validation loss: 2.2583013452509397

Epoch: 6| Step: 6
Training loss: 3.40286922454834
Validation loss: 2.250503565675469

Epoch: 6| Step: 7
Training loss: 2.743821144104004
Validation loss: 2.2404645719835834

Epoch: 6| Step: 8
Training loss: 2.2457659244537354
Validation loss: 2.2355521519978843

Epoch: 6| Step: 9
Training loss: 1.741950273513794
Validation loss: 2.2474275045497443

Epoch: 6| Step: 10
Training loss: 2.020214080810547
Validation loss: 2.2487179810001003

Epoch: 6| Step: 11
Training loss: 2.2832651138305664
Validation loss: 2.258496583148997

Epoch: 6| Step: 12
Training loss: 1.4205291271209717
Validation loss: 2.2759724663149927

Epoch: 6| Step: 13
Training loss: 1.5571893453598022
Validation loss: 2.2989473906896447

Epoch: 394| Step: 0
Training loss: 2.060213565826416
Validation loss: 2.306411204799529

Epoch: 6| Step: 1
Training loss: 1.9054388999938965
Validation loss: 2.343741064430565

Epoch: 6| Step: 2
Training loss: 2.873579740524292
Validation loss: 2.319310818949053

Epoch: 6| Step: 3
Training loss: 2.4596471786499023
Validation loss: 2.329025064745257

Epoch: 6| Step: 4
Training loss: 1.4209575653076172
Validation loss: 2.3126136282438874

Epoch: 6| Step: 5
Training loss: 2.8972420692443848
Validation loss: 2.2947968065097766

Epoch: 6| Step: 6
Training loss: 2.784660816192627
Validation loss: 2.2586201826731362

Epoch: 6| Step: 7
Training loss: 2.1783134937286377
Validation loss: 2.236064303305841

Epoch: 6| Step: 8
Training loss: 1.79593825340271
Validation loss: 2.241031849256126

Epoch: 6| Step: 9
Training loss: 2.5452420711517334
Validation loss: 2.2388208091899915

Epoch: 6| Step: 10
Training loss: 1.98819899559021
Validation loss: 2.2503339808474303

Epoch: 6| Step: 11
Training loss: 2.909575939178467
Validation loss: 2.2556047234483945

Epoch: 6| Step: 12
Training loss: 1.847557544708252
Validation loss: 2.2719831107765116

Epoch: 6| Step: 13
Training loss: 1.7318923473358154
Validation loss: 2.2757884404992543

Epoch: 395| Step: 0
Training loss: 2.2541651725769043
Validation loss: 2.289356959763394

Epoch: 6| Step: 1
Training loss: 1.380585789680481
Validation loss: 2.268885771433512

Epoch: 6| Step: 2
Training loss: 2.2893080711364746
Validation loss: 2.281741434527982

Epoch: 6| Step: 3
Training loss: 2.207585334777832
Validation loss: 2.2790706106411514

Epoch: 6| Step: 4
Training loss: 3.1542062759399414
Validation loss: 2.286599733496225

Epoch: 6| Step: 5
Training loss: 1.5347219705581665
Validation loss: 2.2846665305476033

Epoch: 6| Step: 6
Training loss: 2.0477428436279297
Validation loss: 2.2831038941619215

Epoch: 6| Step: 7
Training loss: 2.7025692462921143
Validation loss: 2.303397406813919

Epoch: 6| Step: 8
Training loss: 2.904568910598755
Validation loss: 2.2966089274293635

Epoch: 6| Step: 9
Training loss: 2.2598931789398193
Validation loss: 2.2699590011309554

Epoch: 6| Step: 10
Training loss: 2.108569622039795
Validation loss: 2.2608750302304506

Epoch: 6| Step: 11
Training loss: 1.954514741897583
Validation loss: 2.25907677091578

Epoch: 6| Step: 12
Training loss: 2.0336294174194336
Validation loss: 2.240874853185428

Epoch: 6| Step: 13
Training loss: 2.842589855194092
Validation loss: 2.235604302857512

Epoch: 396| Step: 0
Training loss: 1.8975509405136108
Validation loss: 2.2310332687952186

Epoch: 6| Step: 1
Training loss: 2.3270440101623535
Validation loss: 2.2250471166385117

Epoch: 6| Step: 2
Training loss: 2.204436779022217
Validation loss: 2.205541108244209

Epoch: 6| Step: 3
Training loss: 2.140597343444824
Validation loss: 2.2337107760931856

Epoch: 6| Step: 4
Training loss: 2.2788872718811035
Validation loss: 2.2363280583453435

Epoch: 6| Step: 5
Training loss: 2.8219351768493652
Validation loss: 2.272274678753268

Epoch: 6| Step: 6
Training loss: 2.426128387451172
Validation loss: 2.2833530710589502

Epoch: 6| Step: 7
Training loss: 2.2243692874908447
Validation loss: 2.293595670371927

Epoch: 6| Step: 8
Training loss: 2.034860372543335
Validation loss: 2.2752199378064883

Epoch: 6| Step: 9
Training loss: 2.7691311836242676
Validation loss: 2.256356818701631

Epoch: 6| Step: 10
Training loss: 2.097724437713623
Validation loss: 2.2350568156088553

Epoch: 6| Step: 11
Training loss: 1.937172770500183
Validation loss: 2.2239695390065513

Epoch: 6| Step: 12
Training loss: 2.070591449737549
Validation loss: 2.239949603234568

Epoch: 6| Step: 13
Training loss: 2.555457353591919
Validation loss: 2.2330537944711666

Epoch: 397| Step: 0
Training loss: 2.024610996246338
Validation loss: 2.2324353802588677

Epoch: 6| Step: 1
Training loss: 2.5051534175872803
Validation loss: 2.238482980317967

Epoch: 6| Step: 2
Training loss: 1.8856264352798462
Validation loss: 2.2317195656479045

Epoch: 6| Step: 3
Training loss: 2.0078964233398438
Validation loss: 2.247741057026771

Epoch: 6| Step: 4
Training loss: 2.2709522247314453
Validation loss: 2.246419611797538

Epoch: 6| Step: 5
Training loss: 2.6625781059265137
Validation loss: 2.2616289674594836

Epoch: 6| Step: 6
Training loss: 1.8640329837799072
Validation loss: 2.2906136461483535

Epoch: 6| Step: 7
Training loss: 2.273146629333496
Validation loss: 2.30451778698993

Epoch: 6| Step: 8
Training loss: 2.6844301223754883
Validation loss: 2.3475003806493615

Epoch: 6| Step: 9
Training loss: 2.2669730186462402
Validation loss: 2.350413099411995

Epoch: 6| Step: 10
Training loss: 2.5456767082214355
Validation loss: 2.337493975957235

Epoch: 6| Step: 11
Training loss: 2.782425880432129
Validation loss: 2.342512887011292

Epoch: 6| Step: 12
Training loss: 1.259223222732544
Validation loss: 2.330972176726146

Epoch: 6| Step: 13
Training loss: 2.926246166229248
Validation loss: 2.3103635670036398

Epoch: 398| Step: 0
Training loss: 2.095323324203491
Validation loss: 2.282542772190545

Epoch: 6| Step: 1
Training loss: 2.0564630031585693
Validation loss: 2.260586074603501

Epoch: 6| Step: 2
Training loss: 3.0981268882751465
Validation loss: 2.236934955402087

Epoch: 6| Step: 3
Training loss: 1.898069143295288
Validation loss: 2.234973781852312

Epoch: 6| Step: 4
Training loss: 2.110020160675049
Validation loss: 2.2428316659824823

Epoch: 6| Step: 5
Training loss: 2.4323840141296387
Validation loss: 2.2332634566932597

Epoch: 6| Step: 6
Training loss: 2.2192587852478027
Validation loss: 2.2258176162678707

Epoch: 6| Step: 7
Training loss: 2.3458354473114014
Validation loss: 2.2308034973759807

Epoch: 6| Step: 8
Training loss: 1.3704181909561157
Validation loss: 2.2289485367395545

Epoch: 6| Step: 9
Training loss: 1.9044957160949707
Validation loss: 2.2403087487784763

Epoch: 6| Step: 10
Training loss: 2.2741661071777344
Validation loss: 2.250145600688073

Epoch: 6| Step: 11
Training loss: 2.6174631118774414
Validation loss: 2.2802245386185183

Epoch: 6| Step: 12
Training loss: 2.8879613876342773
Validation loss: 2.2909263077602593

Epoch: 6| Step: 13
Training loss: 1.947693109512329
Validation loss: 2.2852412013597387

Epoch: 399| Step: 0
Training loss: 1.826545000076294
Validation loss: 2.29815738431869

Epoch: 6| Step: 1
Training loss: 2.5446152687072754
Validation loss: 2.2924531147044194

Epoch: 6| Step: 2
Training loss: 1.8341574668884277
Validation loss: 2.2992611495397424

Epoch: 6| Step: 3
Training loss: 2.4493844509124756
Validation loss: 2.278839793256534

Epoch: 6| Step: 4
Training loss: 2.3299851417541504
Validation loss: 2.2588499182014057

Epoch: 6| Step: 5
Training loss: 2.4094443321228027
Validation loss: 2.2535765786324777

Epoch: 6| Step: 6
Training loss: 2.0766987800598145
Validation loss: 2.244874697859569

Epoch: 6| Step: 7
Training loss: 2.5152108669281006
Validation loss: 2.2302123961910123

Epoch: 6| Step: 8
Training loss: 2.1142232418060303
Validation loss: 2.2439959549134776

Epoch: 6| Step: 9
Training loss: 2.4057512283325195
Validation loss: 2.2483274090674614

Epoch: 6| Step: 10
Training loss: 2.997938394546509
Validation loss: 2.2481823980167346

Epoch: 6| Step: 11
Training loss: 1.414430856704712
Validation loss: 2.258235623759608

Epoch: 6| Step: 12
Training loss: 2.029855728149414
Validation loss: 2.2751359913938787

Epoch: 6| Step: 13
Training loss: 2.5225236415863037
Validation loss: 2.294326800172047

Epoch: 400| Step: 0
Training loss: 2.1319141387939453
Validation loss: 2.3049951625126663

Epoch: 6| Step: 1
Training loss: 2.980929374694824
Validation loss: 2.302219570323985

Epoch: 6| Step: 2
Training loss: 1.8988583087921143
Validation loss: 2.308676678647277

Epoch: 6| Step: 3
Training loss: 2.4429850578308105
Validation loss: 2.2797400669385026

Epoch: 6| Step: 4
Training loss: 2.0997314453125
Validation loss: 2.2502165712336057

Epoch: 6| Step: 5
Training loss: 2.515122413635254
Validation loss: 2.2325342496236167

Epoch: 6| Step: 6
Training loss: 2.044746160507202
Validation loss: 2.2142278148281958

Epoch: 6| Step: 7
Training loss: 1.8162596225738525
Validation loss: 2.2109604689382736

Epoch: 6| Step: 8
Training loss: 2.606893539428711
Validation loss: 2.2090498349999868

Epoch: 6| Step: 9
Training loss: 2.37982177734375
Validation loss: 2.2044261168408137

Epoch: 6| Step: 10
Training loss: 2.91215181350708
Validation loss: 2.21207493992262

Epoch: 6| Step: 11
Training loss: 2.5242483615875244
Validation loss: 2.20553336604949

Epoch: 6| Step: 12
Training loss: 1.5813190937042236
Validation loss: 2.2180390691244476

Epoch: 6| Step: 13
Training loss: 1.3876944780349731
Validation loss: 2.213712807624571

Epoch: 401| Step: 0
Training loss: 2.4323768615722656
Validation loss: 2.2524271139534573

Epoch: 6| Step: 1
Training loss: 2.301579475402832
Validation loss: 2.2660132838833715

Epoch: 6| Step: 2
Training loss: 2.183478355407715
Validation loss: 2.309084753836355

Epoch: 6| Step: 3
Training loss: 2.2942287921905518
Validation loss: 2.3363343156794065

Epoch: 6| Step: 4
Training loss: 1.6549257040023804
Validation loss: 2.3603736149367465

Epoch: 6| Step: 5
Training loss: 2.0707128047943115
Validation loss: 2.3815269675306094

Epoch: 6| Step: 6
Training loss: 2.7849936485290527
Validation loss: 2.390671181422408

Epoch: 6| Step: 7
Training loss: 1.9066965579986572
Validation loss: 2.3704787377388246

Epoch: 6| Step: 8
Training loss: 2.1063578128814697
Validation loss: 2.3368412576695925

Epoch: 6| Step: 9
Training loss: 2.879730701446533
Validation loss: 2.293433872602319

Epoch: 6| Step: 10
Training loss: 2.1450486183166504
Validation loss: 2.266460544319563

Epoch: 6| Step: 11
Training loss: 1.9246914386749268
Validation loss: 2.2646239803683375

Epoch: 6| Step: 12
Training loss: 2.1897056102752686
Validation loss: 2.24190838362581

Epoch: 6| Step: 13
Training loss: 2.943441390991211
Validation loss: 2.2336646895254813

Epoch: 402| Step: 0
Training loss: 1.6996240615844727
Validation loss: 2.2233861236162085

Epoch: 6| Step: 1
Training loss: 2.585784435272217
Validation loss: 2.2166770299275718

Epoch: 6| Step: 2
Training loss: 2.522820472717285
Validation loss: 2.230862468801519

Epoch: 6| Step: 3
Training loss: 1.7459715604782104
Validation loss: 2.215256101341658

Epoch: 6| Step: 4
Training loss: 2.322294235229492
Validation loss: 2.2069921724257933

Epoch: 6| Step: 5
Training loss: 2.458866596221924
Validation loss: 2.222774895288611

Epoch: 6| Step: 6
Training loss: 2.6713063716888428
Validation loss: 2.2362599039590485

Epoch: 6| Step: 7
Training loss: 2.9958505630493164
Validation loss: 2.2565525680459957

Epoch: 6| Step: 8
Training loss: 2.429607391357422
Validation loss: 2.266124609977968

Epoch: 6| Step: 9
Training loss: 2.269960880279541
Validation loss: 2.303600649679861

Epoch: 6| Step: 10
Training loss: 2.3346920013427734
Validation loss: 2.3285533971683954

Epoch: 6| Step: 11
Training loss: 1.811375379562378
Validation loss: 2.2939119851717384

Epoch: 6| Step: 12
Training loss: 1.7913827896118164
Validation loss: 2.2957801331755934

Epoch: 6| Step: 13
Training loss: 1.5014989376068115
Validation loss: 2.284674447069886

Epoch: 403| Step: 0
Training loss: 1.74589204788208
Validation loss: 2.2583270149846233

Epoch: 6| Step: 1
Training loss: 1.9695159196853638
Validation loss: 2.2565462743082354

Epoch: 6| Step: 2
Training loss: 2.209745168685913
Validation loss: 2.2441941499710083

Epoch: 6| Step: 3
Training loss: 1.7501795291900635
Validation loss: 2.258031839965492

Epoch: 6| Step: 4
Training loss: 2.070955753326416
Validation loss: 2.2350400391445366

Epoch: 6| Step: 5
Training loss: 2.251607894897461
Validation loss: 2.245915946140084

Epoch: 6| Step: 6
Training loss: 1.94071626663208
Validation loss: 2.229452988152863

Epoch: 6| Step: 7
Training loss: 2.920543670654297
Validation loss: 2.239139013392951

Epoch: 6| Step: 8
Training loss: 3.008965015411377
Validation loss: 2.2491570416317193

Epoch: 6| Step: 9
Training loss: 2.1931073665618896
Validation loss: 2.239503752800726

Epoch: 6| Step: 10
Training loss: 2.694164752960205
Validation loss: 2.233541019501225

Epoch: 6| Step: 11
Training loss: 2.448659896850586
Validation loss: 2.2442141989225983

Epoch: 6| Step: 12
Training loss: 1.9650583267211914
Validation loss: 2.240838691752444

Epoch: 6| Step: 13
Training loss: 1.7706466913223267
Validation loss: 2.248611033603709

Epoch: 404| Step: 0
Training loss: 2.590214967727661
Validation loss: 2.2553024830356723

Epoch: 6| Step: 1
Training loss: 2.000823736190796
Validation loss: 2.265881433281847

Epoch: 6| Step: 2
Training loss: 2.4414472579956055
Validation loss: 2.2842668205179195

Epoch: 6| Step: 3
Training loss: 2.451061725616455
Validation loss: 2.2752759943726244

Epoch: 6| Step: 4
Training loss: 2.2296690940856934
Validation loss: 2.257210772524598

Epoch: 6| Step: 5
Training loss: 2.0532681941986084
Validation loss: 2.2511834995720976

Epoch: 6| Step: 6
Training loss: 2.4471521377563477
Validation loss: 2.244259213888517

Epoch: 6| Step: 7
Training loss: 1.9728578329086304
Validation loss: 2.2322080160981868

Epoch: 6| Step: 8
Training loss: 2.0412113666534424
Validation loss: 2.224797858986803

Epoch: 6| Step: 9
Training loss: 2.6770687103271484
Validation loss: 2.2174544180593183

Epoch: 6| Step: 10
Training loss: 1.833102822303772
Validation loss: 2.2130334172197568

Epoch: 6| Step: 11
Training loss: 2.1584973335266113
Validation loss: 2.202097531287901

Epoch: 6| Step: 12
Training loss: 2.232462167739868
Validation loss: 2.2068171808796544

Epoch: 6| Step: 13
Training loss: 1.8403009176254272
Validation loss: 2.2194559279308526

Epoch: 405| Step: 0
Training loss: 2.4299747943878174
Validation loss: 2.2459437334409325

Epoch: 6| Step: 1
Training loss: 1.9397825002670288
Validation loss: 2.2793599097959456

Epoch: 6| Step: 2
Training loss: 2.435032844543457
Validation loss: 2.2981268282859557

Epoch: 6| Step: 3
Training loss: 2.460167407989502
Validation loss: 2.2841380180851107

Epoch: 6| Step: 4
Training loss: 1.9227893352508545
Validation loss: 2.302862557031775

Epoch: 6| Step: 5
Training loss: 2.845198154449463
Validation loss: 2.3124527623576503

Epoch: 6| Step: 6
Training loss: 2.2268285751342773
Validation loss: 2.288358585808867

Epoch: 6| Step: 7
Training loss: 2.130801200866699
Validation loss: 2.270392844753881

Epoch: 6| Step: 8
Training loss: 1.9333808422088623
Validation loss: 2.2568300065173896

Epoch: 6| Step: 9
Training loss: 2.72243070602417
Validation loss: 2.2515761672809558

Epoch: 6| Step: 10
Training loss: 2.506511688232422
Validation loss: 2.213548732060258

Epoch: 6| Step: 11
Training loss: 1.7261906862258911
Validation loss: 2.2215596937364146

Epoch: 6| Step: 12
Training loss: 2.097318172454834
Validation loss: 2.2136783881853987

Epoch: 6| Step: 13
Training loss: 1.5878971815109253
Validation loss: 2.2084223044815885

Epoch: 406| Step: 0
Training loss: 2.245208501815796
Validation loss: 2.214910381583757

Epoch: 6| Step: 1
Training loss: 1.6867618560791016
Validation loss: 2.208394173652895

Epoch: 6| Step: 2
Training loss: 2.9707107543945312
Validation loss: 2.2402816998061312

Epoch: 6| Step: 3
Training loss: 1.995072841644287
Validation loss: 2.2447178261254424

Epoch: 6| Step: 4
Training loss: 2.1580426692962646
Validation loss: 2.258327620003813

Epoch: 6| Step: 5
Training loss: 2.617382049560547
Validation loss: 2.288520746333625

Epoch: 6| Step: 6
Training loss: 1.9289801120758057
Validation loss: 2.318348359036189

Epoch: 6| Step: 7
Training loss: 1.3272799253463745
Validation loss: 2.3263234810162614

Epoch: 6| Step: 8
Training loss: 1.9528167247772217
Validation loss: 2.350228555740849

Epoch: 6| Step: 9
Training loss: 3.3148813247680664
Validation loss: 2.3299057278581845

Epoch: 6| Step: 10
Training loss: 1.6992418766021729
Validation loss: 2.2661884138661046

Epoch: 6| Step: 11
Training loss: 2.2558770179748535
Validation loss: 2.2278445279726418

Epoch: 6| Step: 12
Training loss: 2.420731782913208
Validation loss: 2.2179845738154587

Epoch: 6| Step: 13
Training loss: 2.8943405151367188
Validation loss: 2.1969013765294063

Epoch: 407| Step: 0
Training loss: 1.8611111640930176
Validation loss: 2.1946243932170253

Epoch: 6| Step: 1
Training loss: 1.910961389541626
Validation loss: 2.1951715638560634

Epoch: 6| Step: 2
Training loss: 2.335362434387207
Validation loss: 2.1957479497437835

Epoch: 6| Step: 3
Training loss: 2.1657614707946777
Validation loss: 2.200074634244365

Epoch: 6| Step: 4
Training loss: 2.8034768104553223
Validation loss: 2.205801558750932

Epoch: 6| Step: 5
Training loss: 1.4807953834533691
Validation loss: 2.2133575152325373

Epoch: 6| Step: 6
Training loss: 2.3222076892852783
Validation loss: 2.225041079264815

Epoch: 6| Step: 7
Training loss: 2.3833181858062744
Validation loss: 2.2618865915524062

Epoch: 6| Step: 8
Training loss: 2.3901913166046143
Validation loss: 2.2802006377968738

Epoch: 6| Step: 9
Training loss: 2.801750659942627
Validation loss: 2.302297669072305

Epoch: 6| Step: 10
Training loss: 1.9838521480560303
Validation loss: 2.3295953735228507

Epoch: 6| Step: 11
Training loss: 2.1754417419433594
Validation loss: 2.3117093975825975

Epoch: 6| Step: 12
Training loss: 2.3795909881591797
Validation loss: 2.3093781368706816

Epoch: 6| Step: 13
Training loss: 2.157811164855957
Validation loss: 2.2904387571478404

Epoch: 408| Step: 0
Training loss: 2.1588168144226074
Validation loss: 2.3009352248202086

Epoch: 6| Step: 1
Training loss: 2.0587098598480225
Validation loss: 2.2836928572705997

Epoch: 6| Step: 2
Training loss: 2.304199695587158
Validation loss: 2.286068880429832

Epoch: 6| Step: 3
Training loss: 2.0636072158813477
Validation loss: 2.2741757003209924

Epoch: 6| Step: 4
Training loss: 2.1635632514953613
Validation loss: 2.2646872202555337

Epoch: 6| Step: 5
Training loss: 1.7708535194396973
Validation loss: 2.243777375067434

Epoch: 6| Step: 6
Training loss: 2.556445837020874
Validation loss: 2.2368722064520723

Epoch: 6| Step: 7
Training loss: 2.2443718910217285
Validation loss: 2.2324896422765588

Epoch: 6| Step: 8
Training loss: 1.9215984344482422
Validation loss: 2.2276831237218713

Epoch: 6| Step: 9
Training loss: 2.3989522457122803
Validation loss: 2.2247551179701284

Epoch: 6| Step: 10
Training loss: 2.1569149494171143
Validation loss: 2.2114483015511626

Epoch: 6| Step: 11
Training loss: 2.27909255027771
Validation loss: 2.2193736260937107

Epoch: 6| Step: 12
Training loss: 2.315667152404785
Validation loss: 2.220555064498737

Epoch: 6| Step: 13
Training loss: 2.8294787406921387
Validation loss: 2.223106309931765

Epoch: 409| Step: 0
Training loss: 2.3599307537078857
Validation loss: 2.230195397971779

Epoch: 6| Step: 1
Training loss: 2.0194265842437744
Validation loss: 2.2289215005854124

Epoch: 6| Step: 2
Training loss: 2.4995951652526855
Validation loss: 2.2288839317137197

Epoch: 6| Step: 3
Training loss: 2.6007723808288574
Validation loss: 2.248616485185521

Epoch: 6| Step: 4
Training loss: 1.9309864044189453
Validation loss: 2.2441495028875207

Epoch: 6| Step: 5
Training loss: 1.7663686275482178
Validation loss: 2.2384657770074825

Epoch: 6| Step: 6
Training loss: 1.9584035873413086
Validation loss: 2.263537173630089

Epoch: 6| Step: 7
Training loss: 1.8973212242126465
Validation loss: 2.2580962104182087

Epoch: 6| Step: 8
Training loss: 2.3344273567199707
Validation loss: 2.2410836335151427

Epoch: 6| Step: 9
Training loss: 2.2331461906433105
Validation loss: 2.2463113979626725

Epoch: 6| Step: 10
Training loss: 3.0078632831573486
Validation loss: 2.2173658622208463

Epoch: 6| Step: 11
Training loss: 1.8420724868774414
Validation loss: 2.2064513826882965

Epoch: 6| Step: 12
Training loss: 2.209404468536377
Validation loss: 2.206345449211777

Epoch: 6| Step: 13
Training loss: 2.340886354446411
Validation loss: 2.2068569198731454

Epoch: 410| Step: 0
Training loss: 2.1807713508605957
Validation loss: 2.2272135698667137

Epoch: 6| Step: 1
Training loss: 2.6835176944732666
Validation loss: 2.2308269200786466

Epoch: 6| Step: 2
Training loss: 2.3198301792144775
Validation loss: 2.2282532248445737

Epoch: 6| Step: 3
Training loss: 2.0931692123413086
Validation loss: 2.2396759474149315

Epoch: 6| Step: 4
Training loss: 2.0330543518066406
Validation loss: 2.2551754174693937

Epoch: 6| Step: 5
Training loss: 2.734915018081665
Validation loss: 2.2508452476993686

Epoch: 6| Step: 6
Training loss: 1.7534538507461548
Validation loss: 2.234120807340068

Epoch: 6| Step: 7
Training loss: 2.81657075881958
Validation loss: 2.23773532272667

Epoch: 6| Step: 8
Training loss: 1.8962892293930054
Validation loss: 2.23430109536776

Epoch: 6| Step: 9
Training loss: 2.565455198287964
Validation loss: 2.218226480227645

Epoch: 6| Step: 10
Training loss: 1.9188289642333984
Validation loss: 2.2300033364244687

Epoch: 6| Step: 11
Training loss: 1.5834922790527344
Validation loss: 2.2172640882512575

Epoch: 6| Step: 12
Training loss: 2.187802791595459
Validation loss: 2.237006192566246

Epoch: 6| Step: 13
Training loss: 1.9751464128494263
Validation loss: 2.253996126113399

Epoch: 411| Step: 0
Training loss: 1.8833578824996948
Validation loss: 2.2590277630795716

Epoch: 6| Step: 1
Training loss: 1.727908730506897
Validation loss: 2.2679318971531366

Epoch: 6| Step: 2
Training loss: 2.125871181488037
Validation loss: 2.2559127910162813

Epoch: 6| Step: 3
Training loss: 2.00323224067688
Validation loss: 2.2601544933934368

Epoch: 6| Step: 4
Training loss: 2.891892910003662
Validation loss: 2.2426215628142

Epoch: 6| Step: 5
Training loss: 2.0590028762817383
Validation loss: 2.247716315330998

Epoch: 6| Step: 6
Training loss: 2.473440170288086
Validation loss: 2.2502946238363943

Epoch: 6| Step: 7
Training loss: 2.478893280029297
Validation loss: 2.237601346867059

Epoch: 6| Step: 8
Training loss: 2.5294408798217773
Validation loss: 2.2272707775074947

Epoch: 6| Step: 9
Training loss: 2.0929198265075684
Validation loss: 2.218714144922072

Epoch: 6| Step: 10
Training loss: 2.6946606636047363
Validation loss: 2.221638979450349

Epoch: 6| Step: 11
Training loss: 2.3186044692993164
Validation loss: 2.2356609836701424

Epoch: 6| Step: 12
Training loss: 2.0338358879089355
Validation loss: 2.2305463232019895

Epoch: 6| Step: 13
Training loss: 1.0305266380310059
Validation loss: 2.2135669595451763

Epoch: 412| Step: 0
Training loss: 2.180748701095581
Validation loss: 2.2355678491694952

Epoch: 6| Step: 1
Training loss: 1.6509785652160645
Validation loss: 2.2336215101262575

Epoch: 6| Step: 2
Training loss: 1.8578102588653564
Validation loss: 2.227352835798776

Epoch: 6| Step: 3
Training loss: 2.2706408500671387
Validation loss: 2.2570536931355796

Epoch: 6| Step: 4
Training loss: 2.474825620651245
Validation loss: 2.2214850841029996

Epoch: 6| Step: 5
Training loss: 1.7246094942092896
Validation loss: 2.2488769459468063

Epoch: 6| Step: 6
Training loss: 2.5155086517333984
Validation loss: 2.2251575070042766

Epoch: 6| Step: 7
Training loss: 1.6297714710235596
Validation loss: 2.225405526417558

Epoch: 6| Step: 8
Training loss: 2.8381171226501465
Validation loss: 2.2074441499607538

Epoch: 6| Step: 9
Training loss: 1.852980136871338
Validation loss: 2.2197561212765273

Epoch: 6| Step: 10
Training loss: 2.5278003215789795
Validation loss: 2.2043167083494124

Epoch: 6| Step: 11
Training loss: 2.3661091327667236
Validation loss: 2.208056938263678

Epoch: 6| Step: 12
Training loss: 2.660433053970337
Validation loss: 2.20883338169385

Epoch: 6| Step: 13
Training loss: 2.2354230880737305
Validation loss: 2.214381394847747

Epoch: 413| Step: 0
Training loss: 2.710298538208008
Validation loss: 2.2254434657353226

Epoch: 6| Step: 1
Training loss: 2.4379212856292725
Validation loss: 2.2410863112377863

Epoch: 6| Step: 2
Training loss: 2.2918739318847656
Validation loss: 2.2267982882838093

Epoch: 6| Step: 3
Training loss: 2.132410764694214
Validation loss: 2.2343644685642694

Epoch: 6| Step: 4
Training loss: 1.8924176692962646
Validation loss: 2.2379961859795356

Epoch: 6| Step: 5
Training loss: 1.4556275606155396
Validation loss: 2.2247425163945844

Epoch: 6| Step: 6
Training loss: 1.7883036136627197
Validation loss: 2.251256468475506

Epoch: 6| Step: 7
Training loss: 2.4190614223480225
Validation loss: 2.2711474408385572

Epoch: 6| Step: 8
Training loss: 2.084108829498291
Validation loss: 2.266749502510153

Epoch: 6| Step: 9
Training loss: 2.602444648742676
Validation loss: 2.2595580149722356

Epoch: 6| Step: 10
Training loss: 2.8299572467803955
Validation loss: 2.24785735530238

Epoch: 6| Step: 11
Training loss: 2.0499329566955566
Validation loss: 2.2426087292291785

Epoch: 6| Step: 12
Training loss: 1.9586536884307861
Validation loss: 2.2213585069102626

Epoch: 6| Step: 13
Training loss: 1.7743878364562988
Validation loss: 2.22097449405219

Epoch: 414| Step: 0
Training loss: 2.6929569244384766
Validation loss: 2.2207524238094205

Epoch: 6| Step: 1
Training loss: 2.186169147491455
Validation loss: 2.212091153667819

Epoch: 6| Step: 2
Training loss: 1.4450777769088745
Validation loss: 2.200899592009924

Epoch: 6| Step: 3
Training loss: 1.930253028869629
Validation loss: 2.22762752861105

Epoch: 6| Step: 4
Training loss: 1.4967784881591797
Validation loss: 2.225608109146036

Epoch: 6| Step: 5
Training loss: 2.6521501541137695
Validation loss: 2.2630564628108853

Epoch: 6| Step: 6
Training loss: 1.980928897857666
Validation loss: 2.2836834000002955

Epoch: 6| Step: 7
Training loss: 2.175801992416382
Validation loss: 2.2946448633747716

Epoch: 6| Step: 8
Training loss: 2.9690041542053223
Validation loss: 2.2967382348993772

Epoch: 6| Step: 9
Training loss: 2.0186045169830322
Validation loss: 2.2846012320569766

Epoch: 6| Step: 10
Training loss: 1.7977888584136963
Validation loss: 2.271146556382538

Epoch: 6| Step: 11
Training loss: 2.3845481872558594
Validation loss: 2.274298498707433

Epoch: 6| Step: 12
Training loss: 2.7917535305023193
Validation loss: 2.246132964728981

Epoch: 6| Step: 13
Training loss: 2.614048480987549
Validation loss: 2.235214594871767

Epoch: 415| Step: 0
Training loss: 2.1391751766204834
Validation loss: 2.221902133316122

Epoch: 6| Step: 1
Training loss: 2.436483383178711
Validation loss: 2.207552825250933

Epoch: 6| Step: 2
Training loss: 2.371541976928711
Validation loss: 2.216498767175982

Epoch: 6| Step: 3
Training loss: 2.3032608032226562
Validation loss: 2.211700976535838

Epoch: 6| Step: 4
Training loss: 2.9665791988372803
Validation loss: 2.200456715399219

Epoch: 6| Step: 5
Training loss: 2.365168809890747
Validation loss: 2.1971494459336802

Epoch: 6| Step: 6
Training loss: 2.5037548542022705
Validation loss: 2.2046293315067085

Epoch: 6| Step: 7
Training loss: 1.49412202835083
Validation loss: 2.1990704754347443

Epoch: 6| Step: 8
Training loss: 2.0636889934539795
Validation loss: 2.2084155236521075

Epoch: 6| Step: 9
Training loss: 2.480698585510254
Validation loss: 2.2218675997949417

Epoch: 6| Step: 10
Training loss: 1.5364238023757935
Validation loss: 2.2314699388319448

Epoch: 6| Step: 11
Training loss: 2.038421392440796
Validation loss: 2.248995569444472

Epoch: 6| Step: 12
Training loss: 2.209394931793213
Validation loss: 2.2736060657808856

Epoch: 6| Step: 13
Training loss: 1.473278284072876
Validation loss: 2.267201356990363

Epoch: 416| Step: 0
Training loss: 2.214966297149658
Validation loss: 2.2488774432930896

Epoch: 6| Step: 1
Training loss: 2.5511622428894043
Validation loss: 2.239931025812703

Epoch: 6| Step: 2
Training loss: 1.9080122709274292
Validation loss: 2.228026169602589

Epoch: 6| Step: 3
Training loss: 2.055328607559204
Validation loss: 2.225968519846598

Epoch: 6| Step: 4
Training loss: 2.587153911590576
Validation loss: 2.2158865941468107

Epoch: 6| Step: 5
Training loss: 3.125999927520752
Validation loss: 2.2171290151534544

Epoch: 6| Step: 6
Training loss: 1.4232730865478516
Validation loss: 2.2325811847563712

Epoch: 6| Step: 7
Training loss: 2.1980881690979004
Validation loss: 2.2397954002503426

Epoch: 6| Step: 8
Training loss: 2.6363577842712402
Validation loss: 2.2238265019591137

Epoch: 6| Step: 9
Training loss: 2.1903820037841797
Validation loss: 2.2491707827455256

Epoch: 6| Step: 10
Training loss: 1.7744303941726685
Validation loss: 2.2197884923668316

Epoch: 6| Step: 11
Training loss: 2.0193514823913574
Validation loss: 2.2017463932755175

Epoch: 6| Step: 12
Training loss: 1.998551845550537
Validation loss: 2.2131033379544496

Epoch: 6| Step: 13
Training loss: 1.9443449974060059
Validation loss: 2.2139841484767135

Epoch: 417| Step: 0
Training loss: 2.6000099182128906
Validation loss: 2.2334646819740214

Epoch: 6| Step: 1
Training loss: 2.1531450748443604
Validation loss: 2.2091680560060727

Epoch: 6| Step: 2
Training loss: 1.980979084968567
Validation loss: 2.2200468919610463

Epoch: 6| Step: 3
Training loss: 1.9671075344085693
Validation loss: 2.220015738600044

Epoch: 6| Step: 4
Training loss: 2.115199089050293
Validation loss: 2.2222147090460664

Epoch: 6| Step: 5
Training loss: 2.0486154556274414
Validation loss: 2.206548842050696

Epoch: 6| Step: 6
Training loss: 1.8826651573181152
Validation loss: 2.2458352504238004

Epoch: 6| Step: 7
Training loss: 2.264660358428955
Validation loss: 2.265337395411666

Epoch: 6| Step: 8
Training loss: 1.9720003604888916
Validation loss: 2.2746178206577095

Epoch: 6| Step: 9
Training loss: 2.614863634109497
Validation loss: 2.282442292859477

Epoch: 6| Step: 10
Training loss: 2.2812581062316895
Validation loss: 2.3113728877036803

Epoch: 6| Step: 11
Training loss: 2.002537250518799
Validation loss: 2.270910257934242

Epoch: 6| Step: 12
Training loss: 2.5773279666900635
Validation loss: 2.2586632133812032

Epoch: 6| Step: 13
Training loss: 2.0816116333007812
Validation loss: 2.2627999756925847

Epoch: 418| Step: 0
Training loss: 2.1489319801330566
Validation loss: 2.2410532812918387

Epoch: 6| Step: 1
Training loss: 2.2713799476623535
Validation loss: 2.2288962666706373

Epoch: 6| Step: 2
Training loss: 1.999578833580017
Validation loss: 2.217411063050711

Epoch: 6| Step: 3
Training loss: 2.5442941188812256
Validation loss: 2.2011940453642156

Epoch: 6| Step: 4
Training loss: 2.4040470123291016
Validation loss: 2.1986820928512083

Epoch: 6| Step: 5
Training loss: 1.9728922843933105
Validation loss: 2.1974418906755346

Epoch: 6| Step: 6
Training loss: 2.2970118522644043
Validation loss: 2.2048667835932907

Epoch: 6| Step: 7
Training loss: 1.6651241779327393
Validation loss: 2.2147241946189635

Epoch: 6| Step: 8
Training loss: 2.570249080657959
Validation loss: 2.225528645259078

Epoch: 6| Step: 9
Training loss: 1.8117873668670654
Validation loss: 2.2519687144987044

Epoch: 6| Step: 10
Training loss: 2.0576188564300537
Validation loss: 2.2513055045117616

Epoch: 6| Step: 11
Training loss: 2.4984872341156006
Validation loss: 2.2431961080079437

Epoch: 6| Step: 12
Training loss: 2.104386806488037
Validation loss: 2.2255684278344594

Epoch: 6| Step: 13
Training loss: 2.580888032913208
Validation loss: 2.2161432107289634

Epoch: 419| Step: 0
Training loss: 2.0098726749420166
Validation loss: 2.2227395837024977

Epoch: 6| Step: 1
Training loss: 2.4519264698028564
Validation loss: 2.2182392471580097

Epoch: 6| Step: 2
Training loss: 2.00986909866333
Validation loss: 2.239222523986652

Epoch: 6| Step: 3
Training loss: 2.757065773010254
Validation loss: 2.2316607813681326

Epoch: 6| Step: 4
Training loss: 2.0303292274475098
Validation loss: 2.2495043867377826

Epoch: 6| Step: 5
Training loss: 2.794095039367676
Validation loss: 2.2282977001641386

Epoch: 6| Step: 6
Training loss: 2.19193959236145
Validation loss: 2.226941208685598

Epoch: 6| Step: 7
Training loss: 2.1553754806518555
Validation loss: 2.2301999907339773

Epoch: 6| Step: 8
Training loss: 2.5883736610412598
Validation loss: 2.220210749615905

Epoch: 6| Step: 9
Training loss: 2.5811171531677246
Validation loss: 2.2333871933721725

Epoch: 6| Step: 10
Training loss: 1.5926334857940674
Validation loss: 2.2241310970757597

Epoch: 6| Step: 11
Training loss: 1.3077869415283203
Validation loss: 2.2154368790247108

Epoch: 6| Step: 12
Training loss: 2.089791774749756
Validation loss: 2.2312741587238927

Epoch: 6| Step: 13
Training loss: 1.6679941415786743
Validation loss: 2.219892747940556

Epoch: 420| Step: 0
Training loss: 2.5262017250061035
Validation loss: 2.208721714635049

Epoch: 6| Step: 1
Training loss: 2.350494384765625
Validation loss: 2.202642462586844

Epoch: 6| Step: 2
Training loss: 2.1164355278015137
Validation loss: 2.19259980417067

Epoch: 6| Step: 3
Training loss: 1.704384684562683
Validation loss: 2.195419531996532

Epoch: 6| Step: 4
Training loss: 2.2619917392730713
Validation loss: 2.202846315599257

Epoch: 6| Step: 5
Training loss: 2.519926071166992
Validation loss: 2.2033861580715386

Epoch: 6| Step: 6
Training loss: 1.9535975456237793
Validation loss: 2.212997067359186

Epoch: 6| Step: 7
Training loss: 2.1266448497772217
Validation loss: 2.2134570152528825

Epoch: 6| Step: 8
Training loss: 2.345099449157715
Validation loss: 2.2168186736363236

Epoch: 6| Step: 9
Training loss: 1.707718849182129
Validation loss: 2.207373724188856

Epoch: 6| Step: 10
Training loss: 2.805422782897949
Validation loss: 2.217816819426834

Epoch: 6| Step: 11
Training loss: 1.6803512573242188
Validation loss: 2.223299332844314

Epoch: 6| Step: 12
Training loss: 1.8810195922851562
Validation loss: 2.234500881164305

Epoch: 6| Step: 13
Training loss: 2.817142963409424
Validation loss: 2.220569456777265

Epoch: 421| Step: 0
Training loss: 2.5390474796295166
Validation loss: 2.2336124579111734

Epoch: 6| Step: 1
Training loss: 1.561633586883545
Validation loss: 2.2356187066724225

Epoch: 6| Step: 2
Training loss: 1.8647406101226807
Validation loss: 2.2570109764734902

Epoch: 6| Step: 3
Training loss: 1.6275736093521118
Validation loss: 2.2669952915560816

Epoch: 6| Step: 4
Training loss: 1.8315693140029907
Validation loss: 2.24649376638474

Epoch: 6| Step: 5
Training loss: 2.331937313079834
Validation loss: 2.244918131059216

Epoch: 6| Step: 6
Training loss: 2.0535311698913574
Validation loss: 2.237728031732703

Epoch: 6| Step: 7
Training loss: 2.4319820404052734
Validation loss: 2.2286483600575435

Epoch: 6| Step: 8
Training loss: 2.5217225551605225
Validation loss: 2.2142843995043027

Epoch: 6| Step: 9
Training loss: 2.644892692565918
Validation loss: 2.1963040187794673

Epoch: 6| Step: 10
Training loss: 2.2819583415985107
Validation loss: 2.197692873657391

Epoch: 6| Step: 11
Training loss: 2.319791316986084
Validation loss: 2.1846649492940595

Epoch: 6| Step: 12
Training loss: 2.490192413330078
Validation loss: 2.211528467875655

Epoch: 6| Step: 13
Training loss: 1.9159268140792847
Validation loss: 2.2022742404732654

Epoch: 422| Step: 0
Training loss: 1.1240993738174438
Validation loss: 2.2240597791569208

Epoch: 6| Step: 1
Training loss: 1.7392501831054688
Validation loss: 2.244824310784699

Epoch: 6| Step: 2
Training loss: 2.030487537384033
Validation loss: 2.2351416362229215

Epoch: 6| Step: 3
Training loss: 3.0498838424682617
Validation loss: 2.250797058946343

Epoch: 6| Step: 4
Training loss: 1.4846826791763306
Validation loss: 2.2417842982917704

Epoch: 6| Step: 5
Training loss: 2.6409034729003906
Validation loss: 2.232677977572205

Epoch: 6| Step: 6
Training loss: 2.3883016109466553
Validation loss: 2.218858524035382

Epoch: 6| Step: 7
Training loss: 2.379284381866455
Validation loss: 2.2093975646521455

Epoch: 6| Step: 8
Training loss: 1.933919906616211
Validation loss: 2.222263474618235

Epoch: 6| Step: 9
Training loss: 2.513803482055664
Validation loss: 2.223195634862428

Epoch: 6| Step: 10
Training loss: 2.2798914909362793
Validation loss: 2.2235715927616244

Epoch: 6| Step: 11
Training loss: 2.448920488357544
Validation loss: 2.246285682083458

Epoch: 6| Step: 12
Training loss: 2.351285219192505
Validation loss: 2.2396823129346295

Epoch: 6| Step: 13
Training loss: 1.966653823852539
Validation loss: 2.2400104794450986

Epoch: 423| Step: 0
Training loss: 2.330925941467285
Validation loss: 2.2504120795957503

Epoch: 6| Step: 1
Training loss: 1.8740936517715454
Validation loss: 2.24656996932081

Epoch: 6| Step: 2
Training loss: 2.358841896057129
Validation loss: 2.2395359495634675

Epoch: 6| Step: 3
Training loss: 2.828873634338379
Validation loss: 2.2204073500889603

Epoch: 6| Step: 4
Training loss: 1.8808419704437256
Validation loss: 2.207167133208244

Epoch: 6| Step: 5
Training loss: 2.0261075496673584
Validation loss: 2.199915421906338

Epoch: 6| Step: 6
Training loss: 1.988191843032837
Validation loss: 2.225108694004756

Epoch: 6| Step: 7
Training loss: 2.049168586730957
Validation loss: 2.2118471924976637

Epoch: 6| Step: 8
Training loss: 3.1587917804718018
Validation loss: 2.2077150806303947

Epoch: 6| Step: 9
Training loss: 1.6923296451568604
Validation loss: 2.215817662977403

Epoch: 6| Step: 10
Training loss: 1.4768465757369995
Validation loss: 2.2147763031785206

Epoch: 6| Step: 11
Training loss: 1.9197640419006348
Validation loss: 2.2291405534231536

Epoch: 6| Step: 12
Training loss: 3.1455492973327637
Validation loss: 2.2282451737311577

Epoch: 6| Step: 13
Training loss: 1.3363267183303833
Validation loss: 2.249580439700875

Epoch: 424| Step: 0
Training loss: 2.2518723011016846
Validation loss: 2.2401735321167977

Epoch: 6| Step: 1
Training loss: 2.4516167640686035
Validation loss: 2.2267651352831113

Epoch: 6| Step: 2
Training loss: 2.3441529273986816
Validation loss: 2.2328097051189792

Epoch: 6| Step: 3
Training loss: 1.8740870952606201
Validation loss: 2.226487969839445

Epoch: 6| Step: 4
Training loss: 2.098914623260498
Validation loss: 2.2216302399994223

Epoch: 6| Step: 5
Training loss: 2.2763137817382812
Validation loss: 2.2307233092605427

Epoch: 6| Step: 6
Training loss: 1.942749261856079
Validation loss: 2.2251465858951693

Epoch: 6| Step: 7
Training loss: 1.543046236038208
Validation loss: 2.2348358502952

Epoch: 6| Step: 8
Training loss: 2.7488925457000732
Validation loss: 2.2353849180283083

Epoch: 6| Step: 9
Training loss: 1.7046303749084473
Validation loss: 2.236094564519903

Epoch: 6| Step: 10
Training loss: 2.4401137828826904
Validation loss: 2.238373899972567

Epoch: 6| Step: 11
Training loss: 2.014394760131836
Validation loss: 2.232552569399598

Epoch: 6| Step: 12
Training loss: 2.251544713973999
Validation loss: 2.233987233972037

Epoch: 6| Step: 13
Training loss: 2.6023764610290527
Validation loss: 2.2489430686478973

Epoch: 425| Step: 0
Training loss: 2.7325522899627686
Validation loss: 2.245518528005128

Epoch: 6| Step: 1
Training loss: 1.6539584398269653
Validation loss: 2.229673872711838

Epoch: 6| Step: 2
Training loss: 2.5199108123779297
Validation loss: 2.2310322997390584

Epoch: 6| Step: 3
Training loss: 2.296337842941284
Validation loss: 2.2212380375913394

Epoch: 6| Step: 4
Training loss: 1.9250133037567139
Validation loss: 2.217622176293404

Epoch: 6| Step: 5
Training loss: 2.3230791091918945
Validation loss: 2.230801010644564

Epoch: 6| Step: 6
Training loss: 1.8489197492599487
Validation loss: 2.211839988667478

Epoch: 6| Step: 7
Training loss: 2.0274040699005127
Validation loss: 2.2117833527185584

Epoch: 6| Step: 8
Training loss: 2.518214702606201
Validation loss: 2.1883006711159982

Epoch: 6| Step: 9
Training loss: 1.675241470336914
Validation loss: 2.2109480519448557

Epoch: 6| Step: 10
Training loss: 1.9663044214248657
Validation loss: 2.1983082256009503

Epoch: 6| Step: 11
Training loss: 1.7380006313323975
Validation loss: 2.1995433222862983

Epoch: 6| Step: 12
Training loss: 2.894296646118164
Validation loss: 2.204597783345048

Epoch: 6| Step: 13
Training loss: 2.2632036209106445
Validation loss: 2.210523274637038

Epoch: 426| Step: 0
Training loss: 2.305662155151367
Validation loss: 2.218152408958763

Epoch: 6| Step: 1
Training loss: 2.2198338508605957
Validation loss: 2.2299115734715618

Epoch: 6| Step: 2
Training loss: 1.9529201984405518
Validation loss: 2.2283907410919026

Epoch: 6| Step: 3
Training loss: 2.2222368717193604
Validation loss: 2.2307700700657342

Epoch: 6| Step: 4
Training loss: 2.617882490158081
Validation loss: 2.2449894233416487

Epoch: 6| Step: 5
Training loss: 2.371431827545166
Validation loss: 2.2212405384227796

Epoch: 6| Step: 6
Training loss: 1.6352112293243408
Validation loss: 2.233982209236391

Epoch: 6| Step: 7
Training loss: 1.7071356773376465
Validation loss: 2.224885174023208

Epoch: 6| Step: 8
Training loss: 1.1274241209030151
Validation loss: 2.244384857916063

Epoch: 6| Step: 9
Training loss: 2.7749061584472656
Validation loss: 2.2307729310886835

Epoch: 6| Step: 10
Training loss: 2.617964267730713
Validation loss: 2.2223788256286294

Epoch: 6| Step: 11
Training loss: 2.3638687133789062
Validation loss: 2.2177193703189975

Epoch: 6| Step: 12
Training loss: 1.9682095050811768
Validation loss: 2.211516959692842

Epoch: 6| Step: 13
Training loss: 2.6164095401763916
Validation loss: 2.217287517363025

Epoch: 427| Step: 0
Training loss: 2.609787940979004
Validation loss: 2.2165688724928003

Epoch: 6| Step: 1
Training loss: 2.209918975830078
Validation loss: 2.2027612565666117

Epoch: 6| Step: 2
Training loss: 2.346733570098877
Validation loss: 2.231669936128842

Epoch: 6| Step: 3
Training loss: 2.0167906284332275
Validation loss: 2.223727023729714

Epoch: 6| Step: 4
Training loss: 2.5322046279907227
Validation loss: 2.202509598065448

Epoch: 6| Step: 5
Training loss: 1.598917007446289
Validation loss: 2.2057472864786782

Epoch: 6| Step: 6
Training loss: 2.2402865886688232
Validation loss: 2.213343221654174

Epoch: 6| Step: 7
Training loss: 1.9389643669128418
Validation loss: 2.228260963193832

Epoch: 6| Step: 8
Training loss: 1.5640575885772705
Validation loss: 2.2176045089639644

Epoch: 6| Step: 9
Training loss: 2.55214262008667
Validation loss: 2.220863328185133

Epoch: 6| Step: 10
Training loss: 1.9528380632400513
Validation loss: 2.2375790406298894

Epoch: 6| Step: 11
Training loss: 2.396000862121582
Validation loss: 2.2327772558376355

Epoch: 6| Step: 12
Training loss: 2.335881471633911
Validation loss: 2.2404578783178843

Epoch: 6| Step: 13
Training loss: 1.8247857093811035
Validation loss: 2.2409754953076764

Epoch: 428| Step: 0
Training loss: 2.3487391471862793
Validation loss: 2.2413223584493003

Epoch: 6| Step: 1
Training loss: 1.9135966300964355
Validation loss: 2.2441805280664915

Epoch: 6| Step: 2
Training loss: 1.8240360021591187
Validation loss: 2.233662812940536

Epoch: 6| Step: 3
Training loss: 1.7106926441192627
Validation loss: 2.2332013601897867

Epoch: 6| Step: 4
Training loss: 2.8422837257385254
Validation loss: 2.205415956435665

Epoch: 6| Step: 5
Training loss: 1.4755473136901855
Validation loss: 2.1975610717650382

Epoch: 6| Step: 6
Training loss: 2.5349206924438477
Validation loss: 2.1912403991145473

Epoch: 6| Step: 7
Training loss: 1.985400915145874
Validation loss: 2.1891864807375017

Epoch: 6| Step: 8
Training loss: 2.9121413230895996
Validation loss: 2.1732313697056105

Epoch: 6| Step: 9
Training loss: 1.8120192289352417
Validation loss: 2.192389113928682

Epoch: 6| Step: 10
Training loss: 1.9767603874206543
Validation loss: 2.202979821030812

Epoch: 6| Step: 11
Training loss: 2.700439929962158
Validation loss: 2.211287611274309

Epoch: 6| Step: 12
Training loss: 2.1750082969665527
Validation loss: 2.23073645048244

Epoch: 6| Step: 13
Training loss: 1.9338035583496094
Validation loss: 2.2252793606891426

Epoch: 429| Step: 0
Training loss: 1.991709589958191
Validation loss: 2.226593058596375

Epoch: 6| Step: 1
Training loss: 1.3488483428955078
Validation loss: 2.2405722500175558

Epoch: 6| Step: 2
Training loss: 2.267745018005371
Validation loss: 2.2479974121175785

Epoch: 6| Step: 3
Training loss: 2.1647980213165283
Validation loss: 2.2295095446289226

Epoch: 6| Step: 4
Training loss: 1.8855007886886597
Validation loss: 2.226475167018111

Epoch: 6| Step: 5
Training loss: 1.9442120790481567
Validation loss: 2.2200545598101873

Epoch: 6| Step: 6
Training loss: 2.848721981048584
Validation loss: 2.2027257039982784

Epoch: 6| Step: 7
Training loss: 2.126067638397217
Validation loss: 2.229212395606502

Epoch: 6| Step: 8
Training loss: 2.582545280456543
Validation loss: 2.218504427581705

Epoch: 6| Step: 9
Training loss: 3.033385753631592
Validation loss: 2.218748169560586

Epoch: 6| Step: 10
Training loss: 1.6218652725219727
Validation loss: 2.2128960432544833

Epoch: 6| Step: 11
Training loss: 1.7484556436538696
Validation loss: 2.2192224328235914

Epoch: 6| Step: 12
Training loss: 2.0324580669403076
Validation loss: 2.215777909883889

Epoch: 6| Step: 13
Training loss: 3.018812894821167
Validation loss: 2.2008005188357447

Epoch: 430| Step: 0
Training loss: 2.022146701812744
Validation loss: 2.2068797362748014

Epoch: 6| Step: 1
Training loss: 2.5386710166931152
Validation loss: 2.206874132156372

Epoch: 6| Step: 2
Training loss: 2.033613443374634
Validation loss: 2.1987969965063114

Epoch: 6| Step: 3
Training loss: 2.475036144256592
Validation loss: 2.2021296178140948

Epoch: 6| Step: 4
Training loss: 1.9779984951019287
Validation loss: 2.1981350196305143

Epoch: 6| Step: 5
Training loss: 2.290252447128296
Validation loss: 2.195450134174798

Epoch: 6| Step: 6
Training loss: 1.836493730545044
Validation loss: 2.201100577590286

Epoch: 6| Step: 7
Training loss: 2.376758337020874
Validation loss: 2.210468761382564

Epoch: 6| Step: 8
Training loss: 1.8776724338531494
Validation loss: 2.192440853323988

Epoch: 6| Step: 9
Training loss: 2.3640732765197754
Validation loss: 2.2096735200574322

Epoch: 6| Step: 10
Training loss: 2.128643035888672
Validation loss: 2.2142801618063324

Epoch: 6| Step: 11
Training loss: 1.5312552452087402
Validation loss: 2.230855549535444

Epoch: 6| Step: 12
Training loss: 2.378901243209839
Validation loss: 2.221372999170775

Epoch: 6| Step: 13
Training loss: 2.345158100128174
Validation loss: 2.234786420740107

Epoch: 431| Step: 0
Training loss: 1.7285643815994263
Validation loss: 2.24836459723852

Epoch: 6| Step: 1
Training loss: 1.8211712837219238
Validation loss: 2.2703800355234454

Epoch: 6| Step: 2
Training loss: 1.750105857849121
Validation loss: 2.267669766179977

Epoch: 6| Step: 3
Training loss: 2.35811448097229
Validation loss: 2.2414209688863447

Epoch: 6| Step: 4
Training loss: 2.7508323192596436
Validation loss: 2.2323074674093597

Epoch: 6| Step: 5
Training loss: 2.7445321083068848
Validation loss: 2.2226663891987135

Epoch: 6| Step: 6
Training loss: 1.9850388765335083
Validation loss: 2.2152566858517226

Epoch: 6| Step: 7
Training loss: 2.2106900215148926
Validation loss: 2.206578277772473

Epoch: 6| Step: 8
Training loss: 2.4644649028778076
Validation loss: 2.191992646904402

Epoch: 6| Step: 9
Training loss: 2.23933744430542
Validation loss: 2.2018825225932623

Epoch: 6| Step: 10
Training loss: 1.7682769298553467
Validation loss: 2.1975627355678107

Epoch: 6| Step: 11
Training loss: 1.490619421005249
Validation loss: 2.201056324025636

Epoch: 6| Step: 12
Training loss: 2.3628666400909424
Validation loss: 2.195849564767653

Epoch: 6| Step: 13
Training loss: 2.9615397453308105
Validation loss: 2.194339129232591

Epoch: 432| Step: 0
Training loss: 2.3524560928344727
Validation loss: 2.2082941750044465

Epoch: 6| Step: 1
Training loss: 2.115154266357422
Validation loss: 2.2347879512335664

Epoch: 6| Step: 2
Training loss: 1.76068115234375
Validation loss: 2.2188354743424283

Epoch: 6| Step: 3
Training loss: 3.0831971168518066
Validation loss: 2.240561707045442

Epoch: 6| Step: 4
Training loss: 2.6391706466674805
Validation loss: 2.2380064969421714

Epoch: 6| Step: 5
Training loss: 2.1007001399993896
Validation loss: 2.2320742478934665

Epoch: 6| Step: 6
Training loss: 2.6276254653930664
Validation loss: 2.2075578371683755

Epoch: 6| Step: 7
Training loss: 2.028165340423584
Validation loss: 2.1968371432314635

Epoch: 6| Step: 8
Training loss: 1.96291184425354
Validation loss: 2.1978818754996023

Epoch: 6| Step: 9
Training loss: 1.8208823204040527
Validation loss: 2.1707775233894266

Epoch: 6| Step: 10
Training loss: 2.1727190017700195
Validation loss: 2.1674451930548555

Epoch: 6| Step: 11
Training loss: 1.490718960762024
Validation loss: 2.173933985412762

Epoch: 6| Step: 12
Training loss: 2.2850682735443115
Validation loss: 2.1803205333730227

Epoch: 6| Step: 13
Training loss: 1.580636978149414
Validation loss: 2.1999077745663222

Epoch: 433| Step: 0
Training loss: 2.67960524559021
Validation loss: 2.223433008757971

Epoch: 6| Step: 1
Training loss: 1.7286030054092407
Validation loss: 2.2430674183753228

Epoch: 6| Step: 2
Training loss: 2.088200092315674
Validation loss: 2.262593256529941

Epoch: 6| Step: 3
Training loss: 2.500150203704834
Validation loss: 2.2455029538882676

Epoch: 6| Step: 4
Training loss: 2.15606689453125
Validation loss: 2.271426329048731

Epoch: 6| Step: 5
Training loss: 2.124791145324707
Validation loss: 2.2706460337485037

Epoch: 6| Step: 6
Training loss: 1.642292857170105
Validation loss: 2.2577468720815514

Epoch: 6| Step: 7
Training loss: 2.5915822982788086
Validation loss: 2.2282979180735927

Epoch: 6| Step: 8
Training loss: 1.93282949924469
Validation loss: 2.2228045540471233

Epoch: 6| Step: 9
Training loss: 1.8959654569625854
Validation loss: 2.1801392750073503

Epoch: 6| Step: 10
Training loss: 2.409527063369751
Validation loss: 2.1803902733710503

Epoch: 6| Step: 11
Training loss: 2.411351442337036
Validation loss: 2.177356712279781

Epoch: 6| Step: 12
Training loss: 2.17893385887146
Validation loss: 2.1796739306501163

Epoch: 6| Step: 13
Training loss: 1.8459268808364868
Validation loss: 2.192207690208189

Epoch: 434| Step: 0
Training loss: 1.2340691089630127
Validation loss: 2.2190225880633117

Epoch: 6| Step: 1
Training loss: 1.8782490491867065
Validation loss: 2.244557455021848

Epoch: 6| Step: 2
Training loss: 2.559260368347168
Validation loss: 2.2590825890982025

Epoch: 6| Step: 3
Training loss: 2.199643135070801
Validation loss: 2.261671443139353

Epoch: 6| Step: 4
Training loss: 2.212006092071533
Validation loss: 2.261294860993662

Epoch: 6| Step: 5
Training loss: 2.3079206943511963
Validation loss: 2.232235162488876

Epoch: 6| Step: 6
Training loss: 2.225735664367676
Validation loss: 2.2193416472404235

Epoch: 6| Step: 7
Training loss: 1.7482436895370483
Validation loss: 2.2183382434229695

Epoch: 6| Step: 8
Training loss: 1.9804701805114746
Validation loss: 2.1961189239255843

Epoch: 6| Step: 9
Training loss: 2.5622761249542236
Validation loss: 2.195983697009343

Epoch: 6| Step: 10
Training loss: 1.715529203414917
Validation loss: 2.1942664448932936

Epoch: 6| Step: 11
Training loss: 2.382824420928955
Validation loss: 2.183275863688479

Epoch: 6| Step: 12
Training loss: 2.8308587074279785
Validation loss: 2.184498502362159

Epoch: 6| Step: 13
Training loss: 2.8139593601226807
Validation loss: 2.177135782857095

Epoch: 435| Step: 0
Training loss: 3.094127655029297
Validation loss: 2.208972695053265

Epoch: 6| Step: 1
Training loss: 2.0728986263275146
Validation loss: 2.226710363100934

Epoch: 6| Step: 2
Training loss: 1.6963386535644531
Validation loss: 2.2251790749129428

Epoch: 6| Step: 3
Training loss: 2.4875149726867676
Validation loss: 2.220188699742799

Epoch: 6| Step: 4
Training loss: 2.3120553493499756
Validation loss: 2.2167445203309417

Epoch: 6| Step: 5
Training loss: 2.07973051071167
Validation loss: 2.225898324802358

Epoch: 6| Step: 6
Training loss: 1.9268513917922974
Validation loss: 2.2118573419509397

Epoch: 6| Step: 7
Training loss: 2.410189390182495
Validation loss: 2.216397698207568

Epoch: 6| Step: 8
Training loss: 1.5847303867340088
Validation loss: 2.22049613921873

Epoch: 6| Step: 9
Training loss: 2.1533432006835938
Validation loss: 2.2220094973041165

Epoch: 6| Step: 10
Training loss: 1.4285104274749756
Validation loss: 2.213097926109068

Epoch: 6| Step: 11
Training loss: 1.9414260387420654
Validation loss: 2.224311936286188

Epoch: 6| Step: 12
Training loss: 2.857797622680664
Validation loss: 2.2292741806276384

Epoch: 6| Step: 13
Training loss: 1.6046453714370728
Validation loss: 2.2273571773241927

Epoch: 436| Step: 0
Training loss: 2.553497552871704
Validation loss: 2.232050952091012

Epoch: 6| Step: 1
Training loss: 1.9298691749572754
Validation loss: 2.2241110468423493

Epoch: 6| Step: 2
Training loss: 2.121870756149292
Validation loss: 2.2264492870658956

Epoch: 6| Step: 3
Training loss: 1.9592584371566772
Validation loss: 2.2377087147005144

Epoch: 6| Step: 4
Training loss: 1.5335288047790527
Validation loss: 2.2227271577363372

Epoch: 6| Step: 5
Training loss: 2.3939852714538574
Validation loss: 2.2238028485287904

Epoch: 6| Step: 6
Training loss: 2.1897947788238525
Validation loss: 2.2192733800539406

Epoch: 6| Step: 7
Training loss: 1.7396354675292969
Validation loss: 2.2127467483602543

Epoch: 6| Step: 8
Training loss: 1.8593552112579346
Validation loss: 2.216609085759809

Epoch: 6| Step: 9
Training loss: 2.132235050201416
Validation loss: 2.2092875870325233

Epoch: 6| Step: 10
Training loss: 2.0163919925689697
Validation loss: 2.2453190331817954

Epoch: 6| Step: 11
Training loss: 2.512019157409668
Validation loss: 2.2199948167288177

Epoch: 6| Step: 12
Training loss: 2.7864489555358887
Validation loss: 2.2331916132280902

Epoch: 6| Step: 13
Training loss: 2.3572473526000977
Validation loss: 2.225558606527185

Epoch: 437| Step: 0
Training loss: 1.5983245372772217
Validation loss: 2.223173515771025

Epoch: 6| Step: 1
Training loss: 2.6581132411956787
Validation loss: 2.244117562488843

Epoch: 6| Step: 2
Training loss: 1.7854900360107422
Validation loss: 2.245549814675444

Epoch: 6| Step: 3
Training loss: 1.8516114950180054
Validation loss: 2.2353376983314432

Epoch: 6| Step: 4
Training loss: 2.045860767364502
Validation loss: 2.226117290476317

Epoch: 6| Step: 5
Training loss: 1.833415150642395
Validation loss: 2.230851811747397

Epoch: 6| Step: 6
Training loss: 2.1215662956237793
Validation loss: 2.211860737492961

Epoch: 6| Step: 7
Training loss: 2.2595107555389404
Validation loss: 2.202849295831496

Epoch: 6| Step: 8
Training loss: 2.0649478435516357
Validation loss: 2.1928364102558424

Epoch: 6| Step: 9
Training loss: 2.402076005935669
Validation loss: 2.193389900269047

Epoch: 6| Step: 10
Training loss: 2.708068370819092
Validation loss: 2.1881799377420896

Epoch: 6| Step: 11
Training loss: 2.2096972465515137
Validation loss: 2.1916871250316663

Epoch: 6| Step: 12
Training loss: 2.1554455757141113
Validation loss: 2.172680808651832

Epoch: 6| Step: 13
Training loss: 2.448457956314087
Validation loss: 2.18625166339259

Epoch: 438| Step: 0
Training loss: 2.5821170806884766
Validation loss: 2.210429476153466

Epoch: 6| Step: 1
Training loss: 2.3641555309295654
Validation loss: 2.2002680352939072

Epoch: 6| Step: 2
Training loss: 2.22278094291687
Validation loss: 2.1993987329544558

Epoch: 6| Step: 3
Training loss: 2.222376823425293
Validation loss: 2.2213536334294144

Epoch: 6| Step: 4
Training loss: 1.8649468421936035
Validation loss: 2.203677015919839

Epoch: 6| Step: 5
Training loss: 2.0291972160339355
Validation loss: 2.1924239768776843

Epoch: 6| Step: 6
Training loss: 2.4231464862823486
Validation loss: 2.2031455757797405

Epoch: 6| Step: 7
Training loss: 1.8842320442199707
Validation loss: 2.2024266745454524

Epoch: 6| Step: 8
Training loss: 2.298069953918457
Validation loss: 2.1983970967672204

Epoch: 6| Step: 9
Training loss: 1.7763535976409912
Validation loss: 2.2161637647177583

Epoch: 6| Step: 10
Training loss: 1.6433645486831665
Validation loss: 2.2200815677642822

Epoch: 6| Step: 11
Training loss: 2.213102340698242
Validation loss: 2.220750953561516

Epoch: 6| Step: 12
Training loss: 1.832133173942566
Validation loss: 2.199242163729924

Epoch: 6| Step: 13
Training loss: 2.671276569366455
Validation loss: 2.196339299601893

Epoch: 439| Step: 0
Training loss: 3.0970094203948975
Validation loss: 2.2107281915603147

Epoch: 6| Step: 1
Training loss: 1.7228562831878662
Validation loss: 2.1989170325699674

Epoch: 6| Step: 2
Training loss: 1.8202569484710693
Validation loss: 2.191848411354967

Epoch: 6| Step: 3
Training loss: 1.8205573558807373
Validation loss: 2.1938719146995136

Epoch: 6| Step: 4
Training loss: 2.3045454025268555
Validation loss: 2.2226906771300943

Epoch: 6| Step: 5
Training loss: 2.433864116668701
Validation loss: 2.2463853333586004

Epoch: 6| Step: 6
Training loss: 2.507474660873413
Validation loss: 2.261772938953933

Epoch: 6| Step: 7
Training loss: 2.365467071533203
Validation loss: 2.273282374105146

Epoch: 6| Step: 8
Training loss: 1.761197566986084
Validation loss: 2.25430251449667

Epoch: 6| Step: 9
Training loss: 1.8208928108215332
Validation loss: 2.2462185710989018

Epoch: 6| Step: 10
Training loss: 2.67533802986145
Validation loss: 2.223319874014906

Epoch: 6| Step: 11
Training loss: 1.9303686618804932
Validation loss: 2.210678441550142

Epoch: 6| Step: 12
Training loss: 1.4186097383499146
Validation loss: 2.186389171948997

Epoch: 6| Step: 13
Training loss: 2.3543431758880615
Validation loss: 2.1965306266661613

Epoch: 440| Step: 0
Training loss: 1.7851579189300537
Validation loss: 2.1872309484789447

Epoch: 6| Step: 1
Training loss: 2.8754324913024902
Validation loss: 2.181511366239158

Epoch: 6| Step: 2
Training loss: 1.5596652030944824
Validation loss: 2.1940470049458165

Epoch: 6| Step: 3
Training loss: 1.9325755834579468
Validation loss: 2.1967098687284734

Epoch: 6| Step: 4
Training loss: 3.217139720916748
Validation loss: 2.1976073236875635

Epoch: 6| Step: 5
Training loss: 3.1295623779296875
Validation loss: 2.1928059285686863

Epoch: 6| Step: 6
Training loss: 1.9958134889602661
Validation loss: 2.2090876435720794

Epoch: 6| Step: 7
Training loss: 2.582365036010742
Validation loss: 2.2350287642530215

Epoch: 6| Step: 8
Training loss: 2.2053191661834717
Validation loss: 2.219492458528088

Epoch: 6| Step: 9
Training loss: 1.2598321437835693
Validation loss: 2.2242688414871052

Epoch: 6| Step: 10
Training loss: 1.3724465370178223
Validation loss: 2.2166610635736936

Epoch: 6| Step: 11
Training loss: 1.5245689153671265
Validation loss: 2.2126091987855974

Epoch: 6| Step: 12
Training loss: 1.9725754261016846
Validation loss: 2.224920816318963

Epoch: 6| Step: 13
Training loss: 2.710202693939209
Validation loss: 2.219114890662573

Epoch: 441| Step: 0
Training loss: 1.2631769180297852
Validation loss: 2.201995233053802

Epoch: 6| Step: 1
Training loss: 1.9811090230941772
Validation loss: 2.2092434924135924

Epoch: 6| Step: 2
Training loss: 2.027003765106201
Validation loss: 2.199982376508815

Epoch: 6| Step: 3
Training loss: 2.4786949157714844
Validation loss: 2.1921908624710573

Epoch: 6| Step: 4
Training loss: 1.8122495412826538
Validation loss: 2.1891196466261342

Epoch: 6| Step: 5
Training loss: 1.9887685775756836
Validation loss: 2.186891200721905

Epoch: 6| Step: 6
Training loss: 2.5295097827911377
Validation loss: 2.1773672103881836

Epoch: 6| Step: 7
Training loss: 2.335057258605957
Validation loss: 2.1956383156520065

Epoch: 6| Step: 8
Training loss: 2.8566317558288574
Validation loss: 2.1923582323135866

Epoch: 6| Step: 9
Training loss: 1.2728807926177979
Validation loss: 2.177828501629573

Epoch: 6| Step: 10
Training loss: 2.3705029487609863
Validation loss: 2.1847917033780004

Epoch: 6| Step: 11
Training loss: 2.138481855392456
Validation loss: 2.204148136159425

Epoch: 6| Step: 12
Training loss: 1.9549269676208496
Validation loss: 2.2000353567061888

Epoch: 6| Step: 13
Training loss: 3.263371229171753
Validation loss: 2.2025137152723087

Epoch: 442| Step: 0
Training loss: 1.9905973672866821
Validation loss: 2.1888424388823973

Epoch: 6| Step: 1
Training loss: 1.8864421844482422
Validation loss: 2.1927586473444456

Epoch: 6| Step: 2
Training loss: 2.836235523223877
Validation loss: 2.190841237703959

Epoch: 6| Step: 3
Training loss: 1.9751849174499512
Validation loss: 2.1889396816171627

Epoch: 6| Step: 4
Training loss: 1.8417490720748901
Validation loss: 2.1852499079960648

Epoch: 6| Step: 5
Training loss: 2.5386152267456055
Validation loss: 2.206111777213312

Epoch: 6| Step: 6
Training loss: 2.270505905151367
Validation loss: 2.1961349787250644

Epoch: 6| Step: 7
Training loss: 1.2708327770233154
Validation loss: 2.202611107980051

Epoch: 6| Step: 8
Training loss: 2.8366427421569824
Validation loss: 2.213953366843603

Epoch: 6| Step: 9
Training loss: 1.9546351432800293
Validation loss: 2.2238411313744

Epoch: 6| Step: 10
Training loss: 1.9933733940124512
Validation loss: 2.2223138270839566

Epoch: 6| Step: 11
Training loss: 2.009296417236328
Validation loss: 2.2170012253586964

Epoch: 6| Step: 12
Training loss: 2.1436607837677
Validation loss: 2.241097122110346

Epoch: 6| Step: 13
Training loss: 2.052554130554199
Validation loss: 2.2408262888590493

Epoch: 443| Step: 0
Training loss: 2.111964225769043
Validation loss: 2.2350301922008557

Epoch: 6| Step: 1
Training loss: 1.665816307067871
Validation loss: 2.2163979263715845

Epoch: 6| Step: 2
Training loss: 2.06272292137146
Validation loss: 2.2140870478845414

Epoch: 6| Step: 3
Training loss: 2.709580183029175
Validation loss: 2.191347106810539

Epoch: 6| Step: 4
Training loss: 1.9444280862808228
Validation loss: 2.182209348165861

Epoch: 6| Step: 5
Training loss: 1.8469839096069336
Validation loss: 2.1963328751184608

Epoch: 6| Step: 6
Training loss: 2.151984691619873
Validation loss: 2.18297403858554

Epoch: 6| Step: 7
Training loss: 2.432762622833252
Validation loss: 2.1727620452962895

Epoch: 6| Step: 8
Training loss: 2.3012397289276123
Validation loss: 2.187141808130408

Epoch: 6| Step: 9
Training loss: 2.3248090744018555
Validation loss: 2.170235267249487

Epoch: 6| Step: 10
Training loss: 2.2295284271240234
Validation loss: 2.2025838308436896

Epoch: 6| Step: 11
Training loss: 1.5078152418136597
Validation loss: 2.209468772334437

Epoch: 6| Step: 12
Training loss: 2.2893483638763428
Validation loss: 2.234806347918767

Epoch: 6| Step: 13
Training loss: 2.1000869274139404
Validation loss: 2.243964005542058

Epoch: 444| Step: 0
Training loss: 1.913011074066162
Validation loss: 2.232161286056683

Epoch: 6| Step: 1
Training loss: 1.691713571548462
Validation loss: 2.2206871612097627

Epoch: 6| Step: 2
Training loss: 2.159532070159912
Validation loss: 2.192922035853068

Epoch: 6| Step: 3
Training loss: 2.9422049522399902
Validation loss: 2.1855103687573503

Epoch: 6| Step: 4
Training loss: 1.788526177406311
Validation loss: 2.205177027692077

Epoch: 6| Step: 5
Training loss: 2.6578493118286133
Validation loss: 2.1836163433649207

Epoch: 6| Step: 6
Training loss: 2.404517650604248
Validation loss: 2.2058082985621628

Epoch: 6| Step: 7
Training loss: 2.731731653213501
Validation loss: 2.1924801936713596

Epoch: 6| Step: 8
Training loss: 0.9957287311553955
Validation loss: 2.1790641353976343

Epoch: 6| Step: 9
Training loss: 1.8673521280288696
Validation loss: 2.1915719009214834

Epoch: 6| Step: 10
Training loss: 2.287752151489258
Validation loss: 2.206960421736522

Epoch: 6| Step: 11
Training loss: 2.1833817958831787
Validation loss: 2.198382954443655

Epoch: 6| Step: 12
Training loss: 2.34700083732605
Validation loss: 2.2095093919384863

Epoch: 6| Step: 13
Training loss: 1.4618651866912842
Validation loss: 2.2089288491074757

Epoch: 445| Step: 0
Training loss: 1.0298547744750977
Validation loss: 2.2126861336410686

Epoch: 6| Step: 1
Training loss: 2.671912670135498
Validation loss: 2.2142456116214877

Epoch: 6| Step: 2
Training loss: 2.29099702835083
Validation loss: 2.210545878256521

Epoch: 6| Step: 3
Training loss: 2.0050878524780273
Validation loss: 2.207978868997225

Epoch: 6| Step: 4
Training loss: 2.435148000717163
Validation loss: 2.218934392416349

Epoch: 6| Step: 5
Training loss: 1.8580020666122437
Validation loss: 2.206170784529819

Epoch: 6| Step: 6
Training loss: 2.5033040046691895
Validation loss: 2.17310365041097

Epoch: 6| Step: 7
Training loss: 2.1639673709869385
Validation loss: 2.1887728860301356

Epoch: 6| Step: 8
Training loss: 1.998673439025879
Validation loss: 2.184538984811434

Epoch: 6| Step: 9
Training loss: 2.0307259559631348
Validation loss: 2.1820914206966275

Epoch: 6| Step: 10
Training loss: 2.5751280784606934
Validation loss: 2.180777508725402

Epoch: 6| Step: 11
Training loss: 2.1463441848754883
Validation loss: 2.1717236849569503

Epoch: 6| Step: 12
Training loss: 2.125257730484009
Validation loss: 2.1835016794102167

Epoch: 6| Step: 13
Training loss: 1.454847812652588
Validation loss: 2.202761116848197

Epoch: 446| Step: 0
Training loss: 1.9705753326416016
Validation loss: 2.2105581350223993

Epoch: 6| Step: 1
Training loss: 2.1615681648254395
Validation loss: 2.215359874950942

Epoch: 6| Step: 2
Training loss: 2.101773977279663
Validation loss: 2.2308125457456036

Epoch: 6| Step: 3
Training loss: 1.4974029064178467
Validation loss: 2.1995278045695317

Epoch: 6| Step: 4
Training loss: 2.2424824237823486
Validation loss: 2.1979362067355903

Epoch: 6| Step: 5
Training loss: 2.3315587043762207
Validation loss: 2.210042389490271

Epoch: 6| Step: 6
Training loss: 2.5427331924438477
Validation loss: 2.1796937783559165

Epoch: 6| Step: 7
Training loss: 2.0305728912353516
Validation loss: 2.156570052587858

Epoch: 6| Step: 8
Training loss: 1.9840099811553955
Validation loss: 2.18336481689125

Epoch: 6| Step: 9
Training loss: 2.214390754699707
Validation loss: 2.1716322898864746

Epoch: 6| Step: 10
Training loss: 1.7914882898330688
Validation loss: 2.179256316154234

Epoch: 6| Step: 11
Training loss: 1.8598558902740479
Validation loss: 2.163264430979247

Epoch: 6| Step: 12
Training loss: 2.607814311981201
Validation loss: 2.2016562441343903

Epoch: 6| Step: 13
Training loss: 2.480458974838257
Validation loss: 2.2136578893148773

Epoch: 447| Step: 0
Training loss: 1.9286000728607178
Validation loss: 2.226956731529646

Epoch: 6| Step: 1
Training loss: 1.9355418682098389
Validation loss: 2.251515790980349

Epoch: 6| Step: 2
Training loss: 1.733302116394043
Validation loss: 2.243058486651349

Epoch: 6| Step: 3
Training loss: 1.3854992389678955
Validation loss: 2.257553441550142

Epoch: 6| Step: 4
Training loss: 2.311128854751587
Validation loss: 2.2546306489616312

Epoch: 6| Step: 5
Training loss: 2.267747163772583
Validation loss: 2.2440243382607736

Epoch: 6| Step: 6
Training loss: 2.854233741760254
Validation loss: 2.2472007351536907

Epoch: 6| Step: 7
Training loss: 2.8779685497283936
Validation loss: 2.2007638741565008

Epoch: 6| Step: 8
Training loss: 2.2233567237854004
Validation loss: 2.1793330613002984

Epoch: 6| Step: 9
Training loss: 1.9537789821624756
Validation loss: 2.1573738513454312

Epoch: 6| Step: 10
Training loss: 2.0125513076782227
Validation loss: 2.1497456514707176

Epoch: 6| Step: 11
Training loss: 2.414649248123169
Validation loss: 2.1437164583513812

Epoch: 6| Step: 12
Training loss: 2.1020543575286865
Validation loss: 2.1605289866847377

Epoch: 6| Step: 13
Training loss: 1.6912556886672974
Validation loss: 2.1515466731081725

Epoch: 448| Step: 0
Training loss: 2.573838233947754
Validation loss: 2.17342233914201

Epoch: 6| Step: 1
Training loss: 2.3307909965515137
Validation loss: 2.182277282079061

Epoch: 6| Step: 2
Training loss: 2.187246322631836
Validation loss: 2.1945015204850065

Epoch: 6| Step: 3
Training loss: 2.251883029937744
Validation loss: 2.2496923861965055

Epoch: 6| Step: 4
Training loss: 2.1834516525268555
Validation loss: 2.2586389869771977

Epoch: 6| Step: 5
Training loss: 2.111867904663086
Validation loss: 2.2625776337039087

Epoch: 6| Step: 6
Training loss: 1.640223741531372
Validation loss: 2.24675847894402

Epoch: 6| Step: 7
Training loss: 1.7421668767929077
Validation loss: 2.235499282037058

Epoch: 6| Step: 8
Training loss: 2.3003358840942383
Validation loss: 2.2248985613546064

Epoch: 6| Step: 9
Training loss: 2.0294599533081055
Validation loss: 2.2057677084399807

Epoch: 6| Step: 10
Training loss: 1.4931931495666504
Validation loss: 2.188744973110896

Epoch: 6| Step: 11
Training loss: 2.5077993869781494
Validation loss: 2.182502010817169

Epoch: 6| Step: 12
Training loss: 2.2730417251586914
Validation loss: 2.17524383401358

Epoch: 6| Step: 13
Training loss: 1.865282654762268
Validation loss: 2.1784459237129457

Epoch: 449| Step: 0
Training loss: 1.887627124786377
Validation loss: 2.19489525979565

Epoch: 6| Step: 1
Training loss: 1.5647950172424316
Validation loss: 2.1798418644935853

Epoch: 6| Step: 2
Training loss: 2.200744390487671
Validation loss: 2.184839274293633

Epoch: 6| Step: 3
Training loss: 1.9261895418167114
Validation loss: 2.1992873914780153

Epoch: 6| Step: 4
Training loss: 2.6442553997039795
Validation loss: 2.218682312196301

Epoch: 6| Step: 5
Training loss: 2.7934749126434326
Validation loss: 2.2245855280148086

Epoch: 6| Step: 6
Training loss: 2.253621816635132
Validation loss: 2.228796975587004

Epoch: 6| Step: 7
Training loss: 1.7477624416351318
Validation loss: 2.233197776220178

Epoch: 6| Step: 8
Training loss: 2.132629632949829
Validation loss: 2.2172044682246383

Epoch: 6| Step: 9
Training loss: 2.63275146484375
Validation loss: 2.1925205569113455

Epoch: 6| Step: 10
Training loss: 1.94637131690979
Validation loss: 2.1719533115304928

Epoch: 6| Step: 11
Training loss: 1.5478780269622803
Validation loss: 2.1528641331580376

Epoch: 6| Step: 12
Training loss: 1.6608384847640991
Validation loss: 2.151773806541197

Epoch: 6| Step: 13
Training loss: 2.8405416011810303
Validation loss: 2.1593826227290656

Epoch: 450| Step: 0
Training loss: 1.9916388988494873
Validation loss: 2.1650564670562744

Epoch: 6| Step: 1
Training loss: 2.0212340354919434
Validation loss: 2.1582678210350776

Epoch: 6| Step: 2
Training loss: 2.478203773498535
Validation loss: 2.1633204311452885

Epoch: 6| Step: 3
Training loss: 1.8198024034500122
Validation loss: 2.168830158889935

Epoch: 6| Step: 4
Training loss: 2.699801206588745
Validation loss: 2.1886122816352436

Epoch: 6| Step: 5
Training loss: 2.112441301345825
Validation loss: 2.191074070110116

Epoch: 6| Step: 6
Training loss: 2.307213306427002
Validation loss: 2.2108699557601765

Epoch: 6| Step: 7
Training loss: 1.6589744091033936
Validation loss: 2.189172371741264

Epoch: 6| Step: 8
Training loss: 1.8079311847686768
Validation loss: 2.1916303480825117

Epoch: 6| Step: 9
Training loss: 3.3310937881469727
Validation loss: 2.19044828414917

Epoch: 6| Step: 10
Training loss: 1.8185603618621826
Validation loss: 2.1798631247653755

Epoch: 6| Step: 11
Training loss: 1.9567232131958008
Validation loss: 2.191743876344414

Epoch: 6| Step: 12
Training loss: 1.7210607528686523
Validation loss: 2.19795923848306

Epoch: 6| Step: 13
Training loss: 1.3803032636642456
Validation loss: 2.2049572378076534

Epoch: 451| Step: 0
Training loss: 1.9520777463912964
Validation loss: 2.2087161720439954

Epoch: 6| Step: 1
Training loss: 1.8446842432022095
Validation loss: 2.244477492506786

Epoch: 6| Step: 2
Training loss: 2.3720710277557373
Validation loss: 2.2391012176390617

Epoch: 6| Step: 3
Training loss: 1.582105040550232
Validation loss: 2.2318342372935307

Epoch: 6| Step: 4
Training loss: 1.6037851572036743
Validation loss: 2.2280681158906672

Epoch: 6| Step: 5
Training loss: 2.5860562324523926
Validation loss: 2.195915565695814

Epoch: 6| Step: 6
Training loss: 2.1927192211151123
Validation loss: 2.175575658839236

Epoch: 6| Step: 7
Training loss: 2.7960691452026367
Validation loss: 2.161905878333635

Epoch: 6| Step: 8
Training loss: 2.353736400604248
Validation loss: 2.1623206318065686

Epoch: 6| Step: 9
Training loss: 1.6525155305862427
Validation loss: 2.1412564221248833

Epoch: 6| Step: 10
Training loss: 2.619048833847046
Validation loss: 2.1503686648543163

Epoch: 6| Step: 11
Training loss: 1.7974199056625366
Validation loss: 2.1463615689226376

Epoch: 6| Step: 12
Training loss: 1.8592336177825928
Validation loss: 2.1671592830329813

Epoch: 6| Step: 13
Training loss: 2.369616746902466
Validation loss: 2.1813033857653217

Epoch: 452| Step: 0
Training loss: 1.938212513923645
Validation loss: 2.2000506949681107

Epoch: 6| Step: 1
Training loss: 2.4072465896606445
Validation loss: 2.2026254451403053

Epoch: 6| Step: 2
Training loss: 1.2772881984710693
Validation loss: 2.2156366814849195

Epoch: 6| Step: 3
Training loss: 2.0626473426818848
Validation loss: 2.2180517873456402

Epoch: 6| Step: 4
Training loss: 1.537432312965393
Validation loss: 2.2088822549389255

Epoch: 6| Step: 5
Training loss: 1.4064059257507324
Validation loss: 2.2257759289074968

Epoch: 6| Step: 6
Training loss: 2.8171567916870117
Validation loss: 2.216749647612213

Epoch: 6| Step: 7
Training loss: 2.651442527770996
Validation loss: 2.195969905904544

Epoch: 6| Step: 8
Training loss: 2.5254900455474854
Validation loss: 2.1573876642411753

Epoch: 6| Step: 9
Training loss: 2.38682222366333
Validation loss: 2.174291092862365

Epoch: 6| Step: 10
Training loss: 1.9455853700637817
Validation loss: 2.1696567548218595

Epoch: 6| Step: 11
Training loss: 2.4129791259765625
Validation loss: 2.1369774751765753

Epoch: 6| Step: 12
Training loss: 2.0204644203186035
Validation loss: 2.167983679361241

Epoch: 6| Step: 13
Training loss: 1.9476640224456787
Validation loss: 2.1673458122438

Epoch: 453| Step: 0
Training loss: 2.148805856704712
Validation loss: 2.1800294896607757

Epoch: 6| Step: 1
Training loss: 2.573611259460449
Validation loss: 2.218598376038254

Epoch: 6| Step: 2
Training loss: 1.772932767868042
Validation loss: 2.235475699106852

Epoch: 6| Step: 3
Training loss: 1.2598053216934204
Validation loss: 2.2541417191105504

Epoch: 6| Step: 4
Training loss: 2.6270360946655273
Validation loss: 2.2361100412184194

Epoch: 6| Step: 5
Training loss: 2.5491185188293457
Validation loss: 2.235673153272239

Epoch: 6| Step: 6
Training loss: 1.6439387798309326
Validation loss: 2.20825614980472

Epoch: 6| Step: 7
Training loss: 1.8489561080932617
Validation loss: 2.215930287555982

Epoch: 6| Step: 8
Training loss: 2.22598934173584
Validation loss: 2.1925997170068885

Epoch: 6| Step: 9
Training loss: 2.3932056427001953
Validation loss: 2.191589532359954

Epoch: 6| Step: 10
Training loss: 2.270078659057617
Validation loss: 2.1814174370099138

Epoch: 6| Step: 11
Training loss: 2.37656831741333
Validation loss: 2.1677655045704176

Epoch: 6| Step: 12
Training loss: 1.4466569423675537
Validation loss: 2.177088273468838

Epoch: 6| Step: 13
Training loss: 2.385807752609253
Validation loss: 2.168732097071986

Epoch: 454| Step: 0
Training loss: 1.3488643169403076
Validation loss: 2.1607716826982397

Epoch: 6| Step: 1
Training loss: 2.469627857208252
Validation loss: 2.178188943093823

Epoch: 6| Step: 2
Training loss: 2.309722900390625
Validation loss: 2.172134526314274

Epoch: 6| Step: 3
Training loss: 1.5870234966278076
Validation loss: 2.1703777928506174

Epoch: 6| Step: 4
Training loss: 2.2624855041503906
Validation loss: 2.172086259370209

Epoch: 6| Step: 5
Training loss: 1.6262067556381226
Validation loss: 2.1588668977060625

Epoch: 6| Step: 6
Training loss: 2.0380256175994873
Validation loss: 2.161896362099596

Epoch: 6| Step: 7
Training loss: 2.5333023071289062
Validation loss: 2.191270171955068

Epoch: 6| Step: 8
Training loss: 2.3003110885620117
Validation loss: 2.1855166496769076

Epoch: 6| Step: 9
Training loss: 2.9128055572509766
Validation loss: 2.189871600879136

Epoch: 6| Step: 10
Training loss: 2.1147379875183105
Validation loss: 2.1694304686720653

Epoch: 6| Step: 11
Training loss: 2.0578866004943848
Validation loss: 2.17927828655448

Epoch: 6| Step: 12
Training loss: 1.569502830505371
Validation loss: 2.1942595051180933

Epoch: 6| Step: 13
Training loss: 2.0938477516174316
Validation loss: 2.2068027629647204

Epoch: 455| Step: 0
Training loss: 2.140188694000244
Validation loss: 2.2043245377079135

Epoch: 6| Step: 1
Training loss: 2.0684921741485596
Validation loss: 2.2057352988950667

Epoch: 6| Step: 2
Training loss: 1.902557611465454
Validation loss: 2.193609619653353

Epoch: 6| Step: 3
Training loss: 1.892066478729248
Validation loss: 2.2028878811867005

Epoch: 6| Step: 4
Training loss: 2.2500693798065186
Validation loss: 2.2022555194875246

Epoch: 6| Step: 5
Training loss: 2.1823954582214355
Validation loss: 2.1718144557809316

Epoch: 6| Step: 6
Training loss: 1.8211193084716797
Validation loss: 2.149815497859832

Epoch: 6| Step: 7
Training loss: 1.8619638681411743
Validation loss: 2.148498829974923

Epoch: 6| Step: 8
Training loss: 2.2110939025878906
Validation loss: 2.1678676118132887

Epoch: 6| Step: 9
Training loss: 1.7400836944580078
Validation loss: 2.1538032844502437

Epoch: 6| Step: 10
Training loss: 2.541335344314575
Validation loss: 2.1764818776038384

Epoch: 6| Step: 11
Training loss: 2.355830669403076
Validation loss: 2.1741688712950675

Epoch: 6| Step: 12
Training loss: 2.3860726356506348
Validation loss: 2.1973499226313766

Epoch: 6| Step: 13
Training loss: 1.6022878885269165
Validation loss: 2.2089712389053835

Epoch: 456| Step: 0
Training loss: 1.5368345975875854
Validation loss: 2.20864277244896

Epoch: 6| Step: 1
Training loss: 1.893714189529419
Validation loss: 2.2031809706841745

Epoch: 6| Step: 2
Training loss: 1.8802392482757568
Validation loss: 2.2208663237992154

Epoch: 6| Step: 3
Training loss: 2.4845476150512695
Validation loss: 2.23050243367431

Epoch: 6| Step: 4
Training loss: 2.0953078269958496
Validation loss: 2.222976020587388

Epoch: 6| Step: 5
Training loss: 1.738187551498413
Validation loss: 2.2267216046651206

Epoch: 6| Step: 6
Training loss: 2.707728624343872
Validation loss: 2.220081070417999

Epoch: 6| Step: 7
Training loss: 2.4049670696258545
Validation loss: 2.219598190758818

Epoch: 6| Step: 8
Training loss: 1.708306074142456
Validation loss: 2.2117921639514226

Epoch: 6| Step: 9
Training loss: 1.6287808418273926
Validation loss: 2.193527275516141

Epoch: 6| Step: 10
Training loss: 2.232630491256714
Validation loss: 2.194063199463711

Epoch: 6| Step: 11
Training loss: 2.4309158325195312
Validation loss: 2.185318554601362

Epoch: 6| Step: 12
Training loss: 2.324428081512451
Validation loss: 2.1626469755685456

Epoch: 6| Step: 13
Training loss: 1.9042826890945435
Validation loss: 2.152737477774261

Epoch: 457| Step: 0
Training loss: 1.9922454357147217
Validation loss: 2.1631694122027327

Epoch: 6| Step: 1
Training loss: 1.372067928314209
Validation loss: 2.141340796665479

Epoch: 6| Step: 2
Training loss: 1.9110027551651
Validation loss: 2.1784563423484884

Epoch: 6| Step: 3
Training loss: 2.389063596725464
Validation loss: 2.198517786559238

Epoch: 6| Step: 4
Training loss: 2.145160675048828
Validation loss: 2.2193030875216246

Epoch: 6| Step: 5
Training loss: 2.420964241027832
Validation loss: 2.254848660961274

Epoch: 6| Step: 6
Training loss: 1.894735336303711
Validation loss: 2.226781152909802

Epoch: 6| Step: 7
Training loss: 1.8647611141204834
Validation loss: 2.2228172415046283

Epoch: 6| Step: 8
Training loss: 2.0644919872283936
Validation loss: 2.2072110945178616

Epoch: 6| Step: 9
Training loss: 1.858280897140503
Validation loss: 2.1734660261420795

Epoch: 6| Step: 10
Training loss: 2.12778639793396
Validation loss: 2.1668231666729016

Epoch: 6| Step: 11
Training loss: 2.316854476928711
Validation loss: 2.1662504493549304

Epoch: 6| Step: 12
Training loss: 2.6285204887390137
Validation loss: 2.170893499928136

Epoch: 6| Step: 13
Training loss: 2.450246810913086
Validation loss: 2.1485507770251204

Epoch: 458| Step: 0
Training loss: 1.510685920715332
Validation loss: 2.1486924258611535

Epoch: 6| Step: 1
Training loss: 2.383298397064209
Validation loss: 2.1547134935214953

Epoch: 6| Step: 2
Training loss: 2.0185928344726562
Validation loss: 2.171389989955451

Epoch: 6| Step: 3
Training loss: 2.832615852355957
Validation loss: 2.1926053339435208

Epoch: 6| Step: 4
Training loss: 1.9991765022277832
Validation loss: 2.1943774992419827

Epoch: 6| Step: 5
Training loss: 1.1066901683807373
Validation loss: 2.2100324246191208

Epoch: 6| Step: 6
Training loss: 2.1372313499450684
Validation loss: 2.202851003216159

Epoch: 6| Step: 7
Training loss: 1.8295059204101562
Validation loss: 2.2055527728091002

Epoch: 6| Step: 8
Training loss: 3.0350112915039062
Validation loss: 2.199016294171733

Epoch: 6| Step: 9
Training loss: 2.13145112991333
Validation loss: 2.191912740789434

Epoch: 6| Step: 10
Training loss: 2.3671417236328125
Validation loss: 2.176691642371557

Epoch: 6| Step: 11
Training loss: 1.4968392848968506
Validation loss: 2.172320874788428

Epoch: 6| Step: 12
Training loss: 1.995380163192749
Validation loss: 2.154495539203767

Epoch: 6| Step: 13
Training loss: 2.4601142406463623
Validation loss: 2.154040345581629

Epoch: 459| Step: 0
Training loss: 1.4326441287994385
Validation loss: 2.176838755607605

Epoch: 6| Step: 1
Training loss: 2.0052833557128906
Validation loss: 2.165051665357364

Epoch: 6| Step: 2
Training loss: 1.6593098640441895
Validation loss: 2.1794972522284395

Epoch: 6| Step: 3
Training loss: 1.9708741903305054
Validation loss: 2.174891682081325

Epoch: 6| Step: 4
Training loss: 2.1708450317382812
Validation loss: 2.1691217473758164

Epoch: 6| Step: 5
Training loss: 2.0050172805786133
Validation loss: 2.173106289679004

Epoch: 6| Step: 6
Training loss: 1.9383718967437744
Validation loss: 2.179638397309088

Epoch: 6| Step: 7
Training loss: 2.5164942741394043
Validation loss: 2.1819664329610844

Epoch: 6| Step: 8
Training loss: 2.183094024658203
Validation loss: 2.16361036351932

Epoch: 6| Step: 9
Training loss: 2.4533982276916504
Validation loss: 2.1683252088485228

Epoch: 6| Step: 10
Training loss: 1.8466942310333252
Validation loss: 2.16318610150327

Epoch: 6| Step: 11
Training loss: 1.803795337677002
Validation loss: 2.1713465695740073

Epoch: 6| Step: 12
Training loss: 2.4311635494232178
Validation loss: 2.165617066044961

Epoch: 6| Step: 13
Training loss: 3.1146414279937744
Validation loss: 2.1686062530804704

Epoch: 460| Step: 0
Training loss: 1.5277807712554932
Validation loss: 2.1815311075538717

Epoch: 6| Step: 1
Training loss: 2.044978618621826
Validation loss: 2.1852456702980945

Epoch: 6| Step: 2
Training loss: 2.172974109649658
Validation loss: 2.1701188625827914

Epoch: 6| Step: 3
Training loss: 1.4559252262115479
Validation loss: 2.1699877656916136

Epoch: 6| Step: 4
Training loss: 2.88370680809021
Validation loss: 2.146600943739696

Epoch: 6| Step: 5
Training loss: 1.9905707836151123
Validation loss: 2.144554353529407

Epoch: 6| Step: 6
Training loss: 1.9528557062149048
Validation loss: 2.13558461845562

Epoch: 6| Step: 7
Training loss: 2.1356256008148193
Validation loss: 2.140692575003511

Epoch: 6| Step: 8
Training loss: 2.501913547515869
Validation loss: 2.134394881545856

Epoch: 6| Step: 9
Training loss: 2.58425235748291
Validation loss: 2.1373516282727643

Epoch: 6| Step: 10
Training loss: 1.4640542268753052
Validation loss: 2.166323358012784

Epoch: 6| Step: 11
Training loss: 2.6455345153808594
Validation loss: 2.1803207397460938

Epoch: 6| Step: 12
Training loss: 1.9208325147628784
Validation loss: 2.1898313671030025

Epoch: 6| Step: 13
Training loss: 1.602582573890686
Validation loss: 2.197351563361383

Epoch: 461| Step: 0
Training loss: 2.5069007873535156
Validation loss: 2.211044943460854

Epoch: 6| Step: 1
Training loss: 2.3167972564697266
Validation loss: 2.19381260102795

Epoch: 6| Step: 2
Training loss: 1.8893901109695435
Validation loss: 2.164575235818022

Epoch: 6| Step: 3
Training loss: 2.659540891647339
Validation loss: 2.1659201601500153

Epoch: 6| Step: 4
Training loss: 1.162697196006775
Validation loss: 2.17205491886344

Epoch: 6| Step: 5
Training loss: 1.9577202796936035
Validation loss: 2.1779902199263215

Epoch: 6| Step: 6
Training loss: 1.650383472442627
Validation loss: 2.1751803608350855

Epoch: 6| Step: 7
Training loss: 2.247601270675659
Validation loss: 2.187718509345926

Epoch: 6| Step: 8
Training loss: 2.0297036170959473
Validation loss: 2.200711137504988

Epoch: 6| Step: 9
Training loss: 1.3097747564315796
Validation loss: 2.220612477230769

Epoch: 6| Step: 10
Training loss: 1.9711257219314575
Validation loss: 2.2198719286149546

Epoch: 6| Step: 11
Training loss: 2.6244585514068604
Validation loss: 2.211631098101216

Epoch: 6| Step: 12
Training loss: 2.5040740966796875
Validation loss: 2.2120206150957333

Epoch: 6| Step: 13
Training loss: 2.1127700805664062
Validation loss: 2.20566362719382

Epoch: 462| Step: 0
Training loss: 1.8169935941696167
Validation loss: 2.2161928556298696

Epoch: 6| Step: 1
Training loss: 1.6816505193710327
Validation loss: 2.1693991281652965

Epoch: 6| Step: 2
Training loss: 2.3390088081359863
Validation loss: 2.1676375609572216

Epoch: 6| Step: 3
Training loss: 2.1505935192108154
Validation loss: 2.137932905586817

Epoch: 6| Step: 4
Training loss: 2.2516212463378906
Validation loss: 2.138255270578528

Epoch: 6| Step: 5
Training loss: 1.9774649143218994
Validation loss: 2.114964626168692

Epoch: 6| Step: 6
Training loss: 2.2605884075164795
Validation loss: 2.1424354199440248

Epoch: 6| Step: 7
Training loss: 2.050579071044922
Validation loss: 2.14715850481423

Epoch: 6| Step: 8
Training loss: 2.0136075019836426
Validation loss: 2.1709658484305105

Epoch: 6| Step: 9
Training loss: 2.1717119216918945
Validation loss: 2.159602775368639

Epoch: 6| Step: 10
Training loss: 2.046689510345459
Validation loss: 2.1456001714993547

Epoch: 6| Step: 11
Training loss: 2.4146456718444824
Validation loss: 2.175235652154492

Epoch: 6| Step: 12
Training loss: 2.1847050189971924
Validation loss: 2.17496814650874

Epoch: 6| Step: 13
Training loss: 1.447129726409912
Validation loss: 2.169348714172199

Epoch: 463| Step: 0
Training loss: 2.2732362747192383
Validation loss: 2.157695262662826

Epoch: 6| Step: 1
Training loss: 1.8195314407348633
Validation loss: 2.178198545209823

Epoch: 6| Step: 2
Training loss: 1.6626522541046143
Validation loss: 2.1792542857508503

Epoch: 6| Step: 3
Training loss: 2.1327552795410156
Validation loss: 2.1791031463171846

Epoch: 6| Step: 4
Training loss: 2.2935290336608887
Validation loss: 2.179449176275602

Epoch: 6| Step: 5
Training loss: 2.6917262077331543
Validation loss: 2.1801794959652807

Epoch: 6| Step: 6
Training loss: 2.4287636280059814
Validation loss: 2.1694019648336593

Epoch: 6| Step: 7
Training loss: 1.5453587770462036
Validation loss: 2.1734725095892466

Epoch: 6| Step: 8
Training loss: 1.5804816484451294
Validation loss: 2.179516129596259

Epoch: 6| Step: 9
Training loss: 1.7945799827575684
Validation loss: 2.1770876069222727

Epoch: 6| Step: 10
Training loss: 2.325775146484375
Validation loss: 2.199255140878821

Epoch: 6| Step: 11
Training loss: 2.211851119995117
Validation loss: 2.2033480931353826

Epoch: 6| Step: 12
Training loss: 2.298152208328247
Validation loss: 2.1934548270317817

Epoch: 6| Step: 13
Training loss: 1.5737656354904175
Validation loss: 2.2112450650943223

Epoch: 464| Step: 0
Training loss: 1.9864773750305176
Validation loss: 2.2157082044950096

Epoch: 6| Step: 1
Training loss: 2.133815288543701
Validation loss: 2.2103794390155422

Epoch: 6| Step: 2
Training loss: 2.151366710662842
Validation loss: 2.222455047792004

Epoch: 6| Step: 3
Training loss: 1.4398285150527954
Validation loss: 2.217870330297819

Epoch: 6| Step: 4
Training loss: 1.8904054164886475
Validation loss: 2.198127528672577

Epoch: 6| Step: 5
Training loss: 2.338033437728882
Validation loss: 2.1699970024888233

Epoch: 6| Step: 6
Training loss: 1.4789835214614868
Validation loss: 2.1567506149250972

Epoch: 6| Step: 7
Training loss: 2.855639696121216
Validation loss: 2.1506158344207273

Epoch: 6| Step: 8
Training loss: 2.0008344650268555
Validation loss: 2.1430796397629606

Epoch: 6| Step: 9
Training loss: 2.3445305824279785
Validation loss: 2.1464686368101384

Epoch: 6| Step: 10
Training loss: 1.323777437210083
Validation loss: 2.1381808480908795

Epoch: 6| Step: 11
Training loss: 1.9601647853851318
Validation loss: 2.14015793800354

Epoch: 6| Step: 12
Training loss: 2.899256706237793
Validation loss: 2.160110604378485

Epoch: 6| Step: 13
Training loss: 2.0675580501556396
Validation loss: 2.169839520608225

Epoch: 465| Step: 0
Training loss: 1.8630644083023071
Validation loss: 2.1625930801514657

Epoch: 6| Step: 1
Training loss: 2.41709566116333
Validation loss: 2.184108905894782

Epoch: 6| Step: 2
Training loss: 1.8835248947143555
Validation loss: 2.177049345867608

Epoch: 6| Step: 3
Training loss: 1.9427474737167358
Validation loss: 2.1807190872007802

Epoch: 6| Step: 4
Training loss: 2.040701389312744
Validation loss: 2.173088542876705

Epoch: 6| Step: 5
Training loss: 1.6032536029815674
Validation loss: 2.1734093158475813

Epoch: 6| Step: 6
Training loss: 1.9057120084762573
Validation loss: 2.172949534590526

Epoch: 6| Step: 7
Training loss: 1.8798530101776123
Validation loss: 2.16341354257317

Epoch: 6| Step: 8
Training loss: 2.635737419128418
Validation loss: 2.1561619299714283

Epoch: 6| Step: 9
Training loss: 2.0608749389648438
Validation loss: 2.178310501960016

Epoch: 6| Step: 10
Training loss: 2.729219675064087
Validation loss: 2.201920811847974

Epoch: 6| Step: 11
Training loss: 1.384695291519165
Validation loss: 2.1989675875632995

Epoch: 6| Step: 12
Training loss: 2.209825038909912
Validation loss: 2.2117082098478913

Epoch: 6| Step: 13
Training loss: 2.2336981296539307
Validation loss: 2.2074095215848697

Epoch: 466| Step: 0
Training loss: 2.091169834136963
Validation loss: 2.2170894863784953

Epoch: 6| Step: 1
Training loss: 1.7370555400848389
Validation loss: 2.235367259671611

Epoch: 6| Step: 2
Training loss: 1.975792407989502
Validation loss: 2.202482229919844

Epoch: 6| Step: 3
Training loss: 1.8142540454864502
Validation loss: 2.1906663640852897

Epoch: 6| Step: 4
Training loss: 1.912607192993164
Validation loss: 2.141861577187815

Epoch: 6| Step: 5
Training loss: 2.7644147872924805
Validation loss: 2.1351937119678785

Epoch: 6| Step: 6
Training loss: 2.294046640396118
Validation loss: 2.119194020507156

Epoch: 6| Step: 7
Training loss: 2.2288079261779785
Validation loss: 2.1279485097495456

Epoch: 6| Step: 8
Training loss: 1.913966178894043
Validation loss: 2.117030500083841

Epoch: 6| Step: 9
Training loss: 1.9120123386383057
Validation loss: 2.1563631155157603

Epoch: 6| Step: 10
Training loss: 1.7750167846679688
Validation loss: 2.162142821537551

Epoch: 6| Step: 11
Training loss: 2.8256964683532715
Validation loss: 2.1981147489240094

Epoch: 6| Step: 12
Training loss: 2.137572765350342
Validation loss: 2.1948510549401723

Epoch: 6| Step: 13
Training loss: 1.3026171922683716
Validation loss: 2.1901261037395847

Epoch: 467| Step: 0
Training loss: 2.0142993927001953
Validation loss: 2.171647523039131

Epoch: 6| Step: 1
Training loss: 2.1584696769714355
Validation loss: 2.1628583028752315

Epoch: 6| Step: 2
Training loss: 3.003734588623047
Validation loss: 2.160297985999815

Epoch: 6| Step: 3
Training loss: 2.555420398712158
Validation loss: 2.1586409589295745

Epoch: 6| Step: 4
Training loss: 2.15281343460083
Validation loss: 2.158592750949244

Epoch: 6| Step: 5
Training loss: 1.22416353225708
Validation loss: 2.139954883565185

Epoch: 6| Step: 6
Training loss: 1.8451521396636963
Validation loss: 2.15224983743442

Epoch: 6| Step: 7
Training loss: 1.8063349723815918
Validation loss: 2.159012771421863

Epoch: 6| Step: 8
Training loss: 1.2152900695800781
Validation loss: 2.1631523614288657

Epoch: 6| Step: 9
Training loss: 2.4813785552978516
Validation loss: 2.1462272738897674

Epoch: 6| Step: 10
Training loss: 1.63563871383667
Validation loss: 2.1451839605967202

Epoch: 6| Step: 11
Training loss: 2.1710476875305176
Validation loss: 2.1690182865306897

Epoch: 6| Step: 12
Training loss: 2.042792558670044
Validation loss: 2.157975245547551

Epoch: 6| Step: 13
Training loss: 2.5772054195404053
Validation loss: 2.1472428716639036

Epoch: 468| Step: 0
Training loss: 2.340257406234741
Validation loss: 2.162556553399691

Epoch: 6| Step: 1
Training loss: 1.813249945640564
Validation loss: 2.1628588835398355

Epoch: 6| Step: 2
Training loss: 2.3122565746307373
Validation loss: 2.1756390961267615

Epoch: 6| Step: 3
Training loss: 2.1695499420166016
Validation loss: 2.1828887821525655

Epoch: 6| Step: 4
Training loss: 1.9042387008666992
Validation loss: 2.1744385457807973

Epoch: 6| Step: 5
Training loss: 1.622213363647461
Validation loss: 2.1933614592398367

Epoch: 6| Step: 6
Training loss: 1.8526561260223389
Validation loss: 2.192951556174986

Epoch: 6| Step: 7
Training loss: 2.3034451007843018
Validation loss: 2.198672309998543

Epoch: 6| Step: 8
Training loss: 1.975731611251831
Validation loss: 2.205711110945671

Epoch: 6| Step: 9
Training loss: 2.175673007965088
Validation loss: 2.177672231069175

Epoch: 6| Step: 10
Training loss: 2.712127208709717
Validation loss: 2.155868919946814

Epoch: 6| Step: 11
Training loss: 2.1056008338928223
Validation loss: 2.147045373916626

Epoch: 6| Step: 12
Training loss: 1.6046940088272095
Validation loss: 2.1588826999869397

Epoch: 6| Step: 13
Training loss: 1.6671221256256104
Validation loss: 2.1497652556306575

Epoch: 469| Step: 0
Training loss: 1.7763376235961914
Validation loss: 2.1529045886890863

Epoch: 6| Step: 1
Training loss: 2.4227523803710938
Validation loss: 2.1573473638103855

Epoch: 6| Step: 2
Training loss: 1.7773793935775757
Validation loss: 2.1638664225096345

Epoch: 6| Step: 3
Training loss: 2.0271029472351074
Validation loss: 2.1585033811548704

Epoch: 6| Step: 4
Training loss: 2.220731496810913
Validation loss: 2.1588149045103338

Epoch: 6| Step: 5
Training loss: 2.0511443614959717
Validation loss: 2.166678400449855

Epoch: 6| Step: 6
Training loss: 1.984476089477539
Validation loss: 2.1812140633982997

Epoch: 6| Step: 7
Training loss: 2.1596059799194336
Validation loss: 2.2023878687171528

Epoch: 6| Step: 8
Training loss: 1.376681923866272
Validation loss: 2.1883845893285607

Epoch: 6| Step: 9
Training loss: 1.462453842163086
Validation loss: 2.1867840482342626

Epoch: 6| Step: 10
Training loss: 2.435232639312744
Validation loss: 2.1932611426999493

Epoch: 6| Step: 11
Training loss: 2.6177027225494385
Validation loss: 2.155515815622063

Epoch: 6| Step: 12
Training loss: 2.5367226600646973
Validation loss: 2.1703427824922787

Epoch: 6| Step: 13
Training loss: 1.5177054405212402
Validation loss: 2.163686196009318

Epoch: 470| Step: 0
Training loss: 2.782891273498535
Validation loss: 2.1398769834990143

Epoch: 6| Step: 1
Training loss: 2.4786930084228516
Validation loss: 2.156720494711271

Epoch: 6| Step: 2
Training loss: 2.3552560806274414
Validation loss: 2.1428632761842463

Epoch: 6| Step: 3
Training loss: 1.5245857238769531
Validation loss: 2.15461983988362

Epoch: 6| Step: 4
Training loss: 1.5985260009765625
Validation loss: 2.181652994566066

Epoch: 6| Step: 5
Training loss: 2.2379989624023438
Validation loss: 2.2116533069200415

Epoch: 6| Step: 6
Training loss: 1.9887272119522095
Validation loss: 2.23930440666855

Epoch: 6| Step: 7
Training loss: 2.3298637866973877
Validation loss: 2.2200358221607823

Epoch: 6| Step: 8
Training loss: 1.1159719228744507
Validation loss: 2.202446696578815

Epoch: 6| Step: 9
Training loss: 2.4406380653381348
Validation loss: 2.179491641700909

Epoch: 6| Step: 10
Training loss: 1.2570016384124756
Validation loss: 2.156399614067488

Epoch: 6| Step: 11
Training loss: 2.0021848678588867
Validation loss: 2.159500765544112

Epoch: 6| Step: 12
Training loss: 2.407675266265869
Validation loss: 2.149810858952102

Epoch: 6| Step: 13
Training loss: 2.24723219871521
Validation loss: 2.1513142585754395

Epoch: 471| Step: 0
Training loss: 1.5603406429290771
Validation loss: 2.150563511797177

Epoch: 6| Step: 1
Training loss: 2.313703775405884
Validation loss: 2.15730220015331

Epoch: 6| Step: 2
Training loss: 1.852286696434021
Validation loss: 2.1681525681608464

Epoch: 6| Step: 3
Training loss: 1.9399030208587646
Validation loss: 2.1836689774708082

Epoch: 6| Step: 4
Training loss: 2.1096670627593994
Validation loss: 2.226466750585905

Epoch: 6| Step: 5
Training loss: 2.3512659072875977
Validation loss: 2.2274783477988294

Epoch: 6| Step: 6
Training loss: 2.199664831161499
Validation loss: 2.2400507593667633

Epoch: 6| Step: 7
Training loss: 2.146737813949585
Validation loss: 2.2167177482317855

Epoch: 6| Step: 8
Training loss: 1.944568395614624
Validation loss: 2.2157016249113184

Epoch: 6| Step: 9
Training loss: 1.8867716789245605
Validation loss: 2.175795487178269

Epoch: 6| Step: 10
Training loss: 2.2644762992858887
Validation loss: 2.1564109966319096

Epoch: 6| Step: 11
Training loss: 1.6542621850967407
Validation loss: 2.1445179421414613

Epoch: 6| Step: 12
Training loss: 2.0404672622680664
Validation loss: 2.1379414732738207

Epoch: 6| Step: 13
Training loss: 2.5787484645843506
Validation loss: 2.1463190509426977

Epoch: 472| Step: 0
Training loss: 2.227933645248413
Validation loss: 2.139541418321671

Epoch: 6| Step: 1
Training loss: 1.8198293447494507
Validation loss: 2.1366383491023893

Epoch: 6| Step: 2
Training loss: 2.113403797149658
Validation loss: 2.169695487586401

Epoch: 6| Step: 3
Training loss: 2.45892071723938
Validation loss: 2.1541117622006323

Epoch: 6| Step: 4
Training loss: 2.211935043334961
Validation loss: 2.158952377175772

Epoch: 6| Step: 5
Training loss: 1.7921398878097534
Validation loss: 2.1544810136159263

Epoch: 6| Step: 6
Training loss: 1.3676199913024902
Validation loss: 2.1651152949179373

Epoch: 6| Step: 7
Training loss: 1.7065623998641968
Validation loss: 2.1669775298846665

Epoch: 6| Step: 8
Training loss: 2.3621435165405273
Validation loss: 2.163151971755489

Epoch: 6| Step: 9
Training loss: 2.1714518070220947
Validation loss: 2.155705057164674

Epoch: 6| Step: 10
Training loss: 2.379697799682617
Validation loss: 2.165479770270727

Epoch: 6| Step: 11
Training loss: 1.8986244201660156
Validation loss: 2.184302355653496

Epoch: 6| Step: 12
Training loss: 1.8279426097869873
Validation loss: 2.1954091133609897

Epoch: 6| Step: 13
Training loss: 2.383491039276123
Validation loss: 2.1656789100298317

Epoch: 473| Step: 0
Training loss: 1.9241427183151245
Validation loss: 2.189343229416878

Epoch: 6| Step: 1
Training loss: 2.40771746635437
Validation loss: 2.150202335849885

Epoch: 6| Step: 2
Training loss: 2.3093323707580566
Validation loss: 2.1371523898134948

Epoch: 6| Step: 3
Training loss: 2.4094367027282715
Validation loss: 2.1229708194732666

Epoch: 6| Step: 4
Training loss: 2.3571653366088867
Validation loss: 2.148283432888728

Epoch: 6| Step: 5
Training loss: 1.445241928100586
Validation loss: 2.1475310710168656

Epoch: 6| Step: 6
Training loss: 1.8402211666107178
Validation loss: 2.153087241675264

Epoch: 6| Step: 7
Training loss: 1.9059474468231201
Validation loss: 2.1666762059734714

Epoch: 6| Step: 8
Training loss: 2.6558053493499756
Validation loss: 2.1751073919316775

Epoch: 6| Step: 9
Training loss: 2.0124449729919434
Validation loss: 2.196400947468255

Epoch: 6| Step: 10
Training loss: 2.215170383453369
Validation loss: 2.168704384116716

Epoch: 6| Step: 11
Training loss: 1.7490723133087158
Validation loss: 2.179706132540139

Epoch: 6| Step: 12
Training loss: 1.2991836071014404
Validation loss: 2.179852110083385

Epoch: 6| Step: 13
Training loss: 1.9389063119888306
Validation loss: 2.1464903508463213

Epoch: 474| Step: 0
Training loss: 1.6216598749160767
Validation loss: 2.1525192645288285

Epoch: 6| Step: 1
Training loss: 2.352501630783081
Validation loss: 2.1357406980247906

Epoch: 6| Step: 2
Training loss: 2.830354690551758
Validation loss: 2.1188336277520783

Epoch: 6| Step: 3
Training loss: 1.6614960432052612
Validation loss: 2.142388661702474

Epoch: 6| Step: 4
Training loss: 1.443948745727539
Validation loss: 2.1473430202853296

Epoch: 6| Step: 5
Training loss: 2.4328994750976562
Validation loss: 2.14290359199688

Epoch: 6| Step: 6
Training loss: 2.238539218902588
Validation loss: 2.1509580150727303

Epoch: 6| Step: 7
Training loss: 1.9904285669326782
Validation loss: 2.164431421987472

Epoch: 6| Step: 8
Training loss: 2.0924620628356934
Validation loss: 2.189286365303942

Epoch: 6| Step: 9
Training loss: 2.3092498779296875
Validation loss: 2.2007321862764258

Epoch: 6| Step: 10
Training loss: 2.2067558765411377
Validation loss: 2.227364011990127

Epoch: 6| Step: 11
Training loss: 2.18595027923584
Validation loss: 2.225119995814498

Epoch: 6| Step: 12
Training loss: 1.681625485420227
Validation loss: 2.232280251800373

Epoch: 6| Step: 13
Training loss: 1.0137832164764404
Validation loss: 2.193338191637429

Epoch: 475| Step: 0
Training loss: 1.5204441547393799
Validation loss: 2.1906087372892644

Epoch: 6| Step: 1
Training loss: 1.7857171297073364
Validation loss: 2.17395535848474

Epoch: 6| Step: 2
Training loss: 1.3974592685699463
Validation loss: 2.1495465950299333

Epoch: 6| Step: 3
Training loss: 2.344635009765625
Validation loss: 2.126417124143211

Epoch: 6| Step: 4
Training loss: 2.113614797592163
Validation loss: 2.1582773321418354

Epoch: 6| Step: 5
Training loss: 2.1097285747528076
Validation loss: 2.148033736854471

Epoch: 6| Step: 6
Training loss: 1.9731942415237427
Validation loss: 2.1617666162470335

Epoch: 6| Step: 7
Training loss: 2.06177020072937
Validation loss: 2.1753852008491434

Epoch: 6| Step: 8
Training loss: 2.17134952545166
Validation loss: 2.148855681060463

Epoch: 6| Step: 9
Training loss: 2.1538643836975098
Validation loss: 2.1528551937431417

Epoch: 6| Step: 10
Training loss: 2.6923627853393555
Validation loss: 2.152392223317136

Epoch: 6| Step: 11
Training loss: 2.0766711235046387
Validation loss: 2.15010319986651

Epoch: 6| Step: 12
Training loss: 1.81753671169281
Validation loss: 2.148856051506535

Epoch: 6| Step: 13
Training loss: 2.4580721855163574
Validation loss: 2.1473498293148574

Epoch: 476| Step: 0
Training loss: 2.3800015449523926
Validation loss: 2.140465604361667

Epoch: 6| Step: 1
Training loss: 1.5041730403900146
Validation loss: 2.1546838155356784

Epoch: 6| Step: 2
Training loss: 2.230163812637329
Validation loss: 2.143832278508012

Epoch: 6| Step: 3
Training loss: 2.432342290878296
Validation loss: 2.161081575578259

Epoch: 6| Step: 4
Training loss: 1.4558005332946777
Validation loss: 2.176665739346576

Epoch: 6| Step: 5
Training loss: 2.3386573791503906
Validation loss: 2.1688425207650788

Epoch: 6| Step: 6
Training loss: 1.808288812637329
Validation loss: 2.1814233487652195

Epoch: 6| Step: 7
Training loss: 2.3351149559020996
Validation loss: 2.1606475999278407

Epoch: 6| Step: 8
Training loss: 2.272427797317505
Validation loss: 2.1571015465644097

Epoch: 6| Step: 9
Training loss: 1.7218416929244995
Validation loss: 2.144695935710784

Epoch: 6| Step: 10
Training loss: 2.3675551414489746
Validation loss: 2.1450846220857356

Epoch: 6| Step: 11
Training loss: 1.3064109086990356
Validation loss: 2.120033689724502

Epoch: 6| Step: 12
Training loss: 2.194304943084717
Validation loss: 2.1371698687153478

Epoch: 6| Step: 13
Training loss: 2.199373722076416
Validation loss: 2.136781633541148

Epoch: 477| Step: 0
Training loss: 1.5404865741729736
Validation loss: 2.1429145502787765

Epoch: 6| Step: 1
Training loss: 1.546238899230957
Validation loss: 2.1433539236745527

Epoch: 6| Step: 2
Training loss: 1.3329262733459473
Validation loss: 2.1452421834391933

Epoch: 6| Step: 3
Training loss: 1.710662603378296
Validation loss: 2.148135123714324

Epoch: 6| Step: 4
Training loss: 1.95182466506958
Validation loss: 2.1582158406575522

Epoch: 6| Step: 5
Training loss: 2.077512502670288
Validation loss: 2.159628927066762

Epoch: 6| Step: 6
Training loss: 2.7620582580566406
Validation loss: 2.176357653833205

Epoch: 6| Step: 7
Training loss: 2.1952035427093506
Validation loss: 2.1599154562078495

Epoch: 6| Step: 8
Training loss: 2.63893461227417
Validation loss: 2.1539753201187297

Epoch: 6| Step: 9
Training loss: 2.4081828594207764
Validation loss: 2.127645887354369

Epoch: 6| Step: 10
Training loss: 1.914189100265503
Validation loss: 2.169006504038329

Epoch: 6| Step: 11
Training loss: 2.2722630500793457
Validation loss: 2.1416863113321285

Epoch: 6| Step: 12
Training loss: 1.9542696475982666
Validation loss: 2.1272090788810485

Epoch: 6| Step: 13
Training loss: 1.902020812034607
Validation loss: 2.152387503654726

Epoch: 478| Step: 0
Training loss: 2.172494649887085
Validation loss: 2.1329151738074517

Epoch: 6| Step: 1
Training loss: 1.9454731941223145
Validation loss: 2.1429063786742506

Epoch: 6| Step: 2
Training loss: 1.935163974761963
Validation loss: 2.126054774048508

Epoch: 6| Step: 3
Training loss: 1.9250571727752686
Validation loss: 2.140956977362274

Epoch: 6| Step: 4
Training loss: 2.0340416431427
Validation loss: 2.163108297573623

Epoch: 6| Step: 5
Training loss: 1.5832031965255737
Validation loss: 2.156511870763635

Epoch: 6| Step: 6
Training loss: 1.7652009725570679
Validation loss: 2.1648558339764996

Epoch: 6| Step: 7
Training loss: 2.4467506408691406
Validation loss: 2.191741666486186

Epoch: 6| Step: 8
Training loss: 2.288142681121826
Validation loss: 2.2150345066542267

Epoch: 6| Step: 9
Training loss: 2.5716402530670166
Validation loss: 2.201228477621591

Epoch: 6| Step: 10
Training loss: 1.6734049320220947
Validation loss: 2.1855564399432112

Epoch: 6| Step: 11
Training loss: 1.7084277868270874
Validation loss: 2.193886846624395

Epoch: 6| Step: 12
Training loss: 2.2483670711517334
Validation loss: 2.1810606269426245

Epoch: 6| Step: 13
Training loss: 1.9617960453033447
Validation loss: 2.1534738361194568

Epoch: 479| Step: 0
Training loss: 1.9592828750610352
Validation loss: 2.1739039856900453

Epoch: 6| Step: 1
Training loss: 2.5648748874664307
Validation loss: 2.148242627420733

Epoch: 6| Step: 2
Training loss: 1.8677234649658203
Validation loss: 2.1686181586275817

Epoch: 6| Step: 3
Training loss: 1.620729684829712
Validation loss: 2.1510756848960795

Epoch: 6| Step: 4
Training loss: 1.4400098323822021
Validation loss: 2.1693924447541595

Epoch: 6| Step: 5
Training loss: 2.8917908668518066
Validation loss: 2.1838042210507136

Epoch: 6| Step: 6
Training loss: 2.6351511478424072
Validation loss: 2.1937434596400105

Epoch: 6| Step: 7
Training loss: 2.2624552249908447
Validation loss: 2.193926577926964

Epoch: 6| Step: 8
Training loss: 1.839539885520935
Validation loss: 2.1686063043532835

Epoch: 6| Step: 9
Training loss: 1.4467308521270752
Validation loss: 2.1777257355310584

Epoch: 6| Step: 10
Training loss: 1.7684478759765625
Validation loss: 2.1492423677957184

Epoch: 6| Step: 11
Training loss: 2.463775634765625
Validation loss: 2.1583055065524195

Epoch: 6| Step: 12
Training loss: 1.8873149156570435
Validation loss: 2.135277766053395

Epoch: 6| Step: 13
Training loss: 1.4087698459625244
Validation loss: 2.146891156832377

Epoch: 480| Step: 0
Training loss: 1.4010875225067139
Validation loss: 2.1313951989655853

Epoch: 6| Step: 1
Training loss: 2.0882492065429688
Validation loss: 2.1203659042235343

Epoch: 6| Step: 2
Training loss: 2.4041788578033447
Validation loss: 2.1186688407774894

Epoch: 6| Step: 3
Training loss: 1.898065209388733
Validation loss: 2.105669544589135

Epoch: 6| Step: 4
Training loss: 2.368363380432129
Validation loss: 2.11237346869643

Epoch: 6| Step: 5
Training loss: 2.194272994995117
Validation loss: 2.117872588096126

Epoch: 6| Step: 6
Training loss: 1.9992003440856934
Validation loss: 2.1291560895981325

Epoch: 6| Step: 7
Training loss: 1.7983629703521729
Validation loss: 2.158381344169699

Epoch: 6| Step: 8
Training loss: 1.7368483543395996
Validation loss: 2.165479031942224

Epoch: 6| Step: 9
Training loss: 2.7198121547698975
Validation loss: 2.1891610007132254

Epoch: 6| Step: 10
Training loss: 1.8199046850204468
Validation loss: 2.2071687495836647

Epoch: 6| Step: 11
Training loss: 1.4212672710418701
Validation loss: 2.221764544005035

Epoch: 6| Step: 12
Training loss: 2.555417060852051
Validation loss: 2.206118655461137

Epoch: 6| Step: 13
Training loss: 1.9606729745864868
Validation loss: 2.1674206897776616

Epoch: 481| Step: 0
Training loss: 2.1495580673217773
Validation loss: 2.1535315334155993

Epoch: 6| Step: 1
Training loss: 1.7524566650390625
Validation loss: 2.143355638750138

Epoch: 6| Step: 2
Training loss: 1.7375414371490479
Validation loss: 2.1322075077282485

Epoch: 6| Step: 3
Training loss: 1.2044041156768799
Validation loss: 2.138091960260945

Epoch: 6| Step: 4
Training loss: 2.1651551723480225
Validation loss: 2.146151186317526

Epoch: 6| Step: 5
Training loss: 2.142864942550659
Validation loss: 2.1746330568867345

Epoch: 6| Step: 6
Training loss: 2.1234350204467773
Validation loss: 2.185011899599465

Epoch: 6| Step: 7
Training loss: 2.7095890045166016
Validation loss: 2.197692640366093

Epoch: 6| Step: 8
Training loss: 2.3126492500305176
Validation loss: 2.1935994996819446

Epoch: 6| Step: 9
Training loss: 2.475216865539551
Validation loss: 2.179899446425899

Epoch: 6| Step: 10
Training loss: 1.9882711172103882
Validation loss: 2.172736499899177

Epoch: 6| Step: 11
Training loss: 1.2584943771362305
Validation loss: 2.1468550492358465

Epoch: 6| Step: 12
Training loss: 2.1536788940429688
Validation loss: 2.1277911996328704

Epoch: 6| Step: 13
Training loss: 2.0256974697113037
Validation loss: 2.1261627956103255

Epoch: 482| Step: 0
Training loss: 2.0863637924194336
Validation loss: 2.131359028559859

Epoch: 6| Step: 1
Training loss: 1.864728569984436
Validation loss: 2.1474174453366186

Epoch: 6| Step: 2
Training loss: 2.066173553466797
Validation loss: 2.152146439398489

Epoch: 6| Step: 3
Training loss: 1.496541976928711
Validation loss: 2.1857132245135564

Epoch: 6| Step: 4
Training loss: 2.210146903991699
Validation loss: 2.1859944699912943

Epoch: 6| Step: 5
Training loss: 1.6064491271972656
Validation loss: 2.2023290895646617

Epoch: 6| Step: 6
Training loss: 2.0003888607025146
Validation loss: 2.206196472208987

Epoch: 6| Step: 7
Training loss: 1.7165995836257935
Validation loss: 2.1946611994056293

Epoch: 6| Step: 8
Training loss: 1.917069673538208
Validation loss: 2.1680193178115355

Epoch: 6| Step: 9
Training loss: 2.5296359062194824
Validation loss: 2.181693225778559

Epoch: 6| Step: 10
Training loss: 2.2137928009033203
Validation loss: 2.1572152978630474

Epoch: 6| Step: 11
Training loss: 2.141652822494507
Validation loss: 2.1460561701046523

Epoch: 6| Step: 12
Training loss: 1.8846265077590942
Validation loss: 2.1409516860080022

Epoch: 6| Step: 13
Training loss: 2.7713441848754883
Validation loss: 2.132689873377482

Epoch: 483| Step: 0
Training loss: 1.1038808822631836
Validation loss: 2.132524550602

Epoch: 6| Step: 1
Training loss: 2.7175769805908203
Validation loss: 2.1354251702626548

Epoch: 6| Step: 2
Training loss: 2.5825753211975098
Validation loss: 2.131116391510092

Epoch: 6| Step: 3
Training loss: 2.4067702293395996
Validation loss: 2.1340623107007755

Epoch: 6| Step: 4
Training loss: 1.9232462644577026
Validation loss: 2.121357710130753

Epoch: 6| Step: 5
Training loss: 2.0371973514556885
Validation loss: 2.1429442077554683

Epoch: 6| Step: 6
Training loss: 2.793057680130005
Validation loss: 2.1207077144294657

Epoch: 6| Step: 7
Training loss: 1.8160581588745117
Validation loss: 2.1528126693541005

Epoch: 6| Step: 8
Training loss: 1.371396780014038
Validation loss: 2.132681646654683

Epoch: 6| Step: 9
Training loss: 1.3090728521347046
Validation loss: 2.12924240737833

Epoch: 6| Step: 10
Training loss: 1.8239431381225586
Validation loss: 2.13076852983044

Epoch: 6| Step: 11
Training loss: 1.8471200466156006
Validation loss: 2.1346146086210847

Epoch: 6| Step: 12
Training loss: 1.858842134475708
Validation loss: 2.1537391139614965

Epoch: 6| Step: 13
Training loss: 2.6925973892211914
Validation loss: 2.1812032986712713

Epoch: 484| Step: 0
Training loss: 1.8935081958770752
Validation loss: 2.1475531337081746

Epoch: 6| Step: 1
Training loss: 1.9889655113220215
Validation loss: 2.1637525609744492

Epoch: 6| Step: 2
Training loss: 1.6218066215515137
Validation loss: 2.17128130953799

Epoch: 6| Step: 3
Training loss: 1.9268907308578491
Validation loss: 2.1828142878829793

Epoch: 6| Step: 4
Training loss: 1.9713490009307861
Validation loss: 2.173531477169324

Epoch: 6| Step: 5
Training loss: 2.864448070526123
Validation loss: 2.1688835928517003

Epoch: 6| Step: 6
Training loss: 2.0616605281829834
Validation loss: 2.1500775044964207

Epoch: 6| Step: 7
Training loss: 1.4068812131881714
Validation loss: 2.148204354829686

Epoch: 6| Step: 8
Training loss: 1.8776826858520508
Validation loss: 2.1603359688994703

Epoch: 6| Step: 9
Training loss: 2.387744426727295
Validation loss: 2.1722015206531813

Epoch: 6| Step: 10
Training loss: 1.7196072340011597
Validation loss: 2.1548546206566597

Epoch: 6| Step: 11
Training loss: 2.0168304443359375
Validation loss: 2.1459111628993863

Epoch: 6| Step: 12
Training loss: 2.0403823852539062
Validation loss: 2.1367238311357397

Epoch: 6| Step: 13
Training loss: 2.4617435932159424
Validation loss: 2.145099634765297

Epoch: 485| Step: 0
Training loss: 1.5664591789245605
Validation loss: 2.1267579319656535

Epoch: 6| Step: 1
Training loss: 1.5462801456451416
Validation loss: 2.127978851718287

Epoch: 6| Step: 2
Training loss: 2.045348644256592
Validation loss: 2.110728112600183

Epoch: 6| Step: 3
Training loss: 2.3188586235046387
Validation loss: 2.1020584875537502

Epoch: 6| Step: 4
Training loss: 3.014983654022217
Validation loss: 2.124950942172799

Epoch: 6| Step: 5
Training loss: 1.689058542251587
Validation loss: 2.1470668008250575

Epoch: 6| Step: 6
Training loss: 1.960758090019226
Validation loss: 2.1432223576371388

Epoch: 6| Step: 7
Training loss: 1.8890310525894165
Validation loss: 2.1550123191648916

Epoch: 6| Step: 8
Training loss: 1.805484414100647
Validation loss: 2.1419388094256

Epoch: 6| Step: 9
Training loss: 2.7242636680603027
Validation loss: 2.148019108721005

Epoch: 6| Step: 10
Training loss: 2.0983128547668457
Validation loss: 2.1539815395109114

Epoch: 6| Step: 11
Training loss: 2.1256089210510254
Validation loss: 2.155455643130887

Epoch: 6| Step: 12
Training loss: 1.3180136680603027
Validation loss: 2.1593632313512985

Epoch: 6| Step: 13
Training loss: 1.9510273933410645
Validation loss: 2.1735699510061615

Epoch: 486| Step: 0
Training loss: 2.4717254638671875
Validation loss: 2.1431120582806167

Epoch: 6| Step: 1
Training loss: 2.276409149169922
Validation loss: 2.152105187857023

Epoch: 6| Step: 2
Training loss: 2.3056640625
Validation loss: 2.135148009946269

Epoch: 6| Step: 3
Training loss: 2.0300962924957275
Validation loss: 2.1358551741928182

Epoch: 6| Step: 4
Training loss: 1.6065771579742432
Validation loss: 2.128181408810359

Epoch: 6| Step: 5
Training loss: 1.6245322227478027
Validation loss: 2.1306764618042977

Epoch: 6| Step: 6
Training loss: 2.7552356719970703
Validation loss: 2.1297880423966276

Epoch: 6| Step: 7
Training loss: 1.33061945438385
Validation loss: 2.145284278418428

Epoch: 6| Step: 8
Training loss: 1.6449406147003174
Validation loss: 2.190216866872644

Epoch: 6| Step: 9
Training loss: 1.5140318870544434
Validation loss: 2.173728055851434

Epoch: 6| Step: 10
Training loss: 2.533721923828125
Validation loss: 2.1645903177158807

Epoch: 6| Step: 11
Training loss: 1.7992854118347168
Validation loss: 2.1399449981668943

Epoch: 6| Step: 12
Training loss: 2.3725686073303223
Validation loss: 2.144844053893961

Epoch: 6| Step: 13
Training loss: 1.5432798862457275
Validation loss: 2.1333945669153684

Epoch: 487| Step: 0
Training loss: 1.5292783975601196
Validation loss: 2.1481645786634056

Epoch: 6| Step: 1
Training loss: 0.9923461675643921
Validation loss: 2.150873561059275

Epoch: 6| Step: 2
Training loss: 2.375718832015991
Validation loss: 2.1649468304008566

Epoch: 6| Step: 3
Training loss: 1.9523959159851074
Validation loss: 2.165196736653646

Epoch: 6| Step: 4
Training loss: 2.233933925628662
Validation loss: 2.180318691397226

Epoch: 6| Step: 5
Training loss: 1.6563901901245117
Validation loss: 2.1988753041913434

Epoch: 6| Step: 6
Training loss: 2.7943310737609863
Validation loss: 2.187482136552052

Epoch: 6| Step: 7
Training loss: 1.815821647644043
Validation loss: 2.1814377384801067

Epoch: 6| Step: 8
Training loss: 1.8452494144439697
Validation loss: 2.1527271322024766

Epoch: 6| Step: 9
Training loss: 2.6191506385803223
Validation loss: 2.1437569010642266

Epoch: 6| Step: 10
Training loss: 2.204840660095215
Validation loss: 2.1186197342411166

Epoch: 6| Step: 11
Training loss: 1.6728500127792358
Validation loss: 2.1052575649753695

Epoch: 6| Step: 12
Training loss: 2.1024136543273926
Validation loss: 2.1152428939778316

Epoch: 6| Step: 13
Training loss: 2.3091325759887695
Validation loss: 2.118118086168843

Epoch: 488| Step: 0
Training loss: 1.1980671882629395
Validation loss: 2.1049570088745444

Epoch: 6| Step: 1
Training loss: 1.5116995573043823
Validation loss: 2.105409945211103

Epoch: 6| Step: 2
Training loss: 2.7900476455688477
Validation loss: 2.1128518876209053

Epoch: 6| Step: 3
Training loss: 2.4719536304473877
Validation loss: 2.119439096860988

Epoch: 6| Step: 4
Training loss: 2.3868513107299805
Validation loss: 2.124463518460592

Epoch: 6| Step: 5
Training loss: 2.205059051513672
Validation loss: 2.1116378999525502

Epoch: 6| Step: 6
Training loss: 2.406888723373413
Validation loss: 2.1438117437465216

Epoch: 6| Step: 7
Training loss: 1.7207584381103516
Validation loss: 2.1379141705010527

Epoch: 6| Step: 8
Training loss: 1.5243771076202393
Validation loss: 2.1722218990325928

Epoch: 6| Step: 9
Training loss: 1.5889477729797363
Validation loss: 2.189630926296275

Epoch: 6| Step: 10
Training loss: 1.5080926418304443
Validation loss: 2.195723387502855

Epoch: 6| Step: 11
Training loss: 2.7539892196655273
Validation loss: 2.1644276188265894

Epoch: 6| Step: 12
Training loss: 2.2496237754821777
Validation loss: 2.1325062705624487

Epoch: 6| Step: 13
Training loss: 1.4282286167144775
Validation loss: 2.1351927224025933

Epoch: 489| Step: 0
Training loss: 1.5079834461212158
Validation loss: 2.113299113447948

Epoch: 6| Step: 1
Training loss: 2.4838674068450928
Validation loss: 2.134112226065769

Epoch: 6| Step: 2
Training loss: 1.8680884838104248
Validation loss: 2.1279748127024662

Epoch: 6| Step: 3
Training loss: 2.059084177017212
Validation loss: 2.142027606246292

Epoch: 6| Step: 4
Training loss: 1.7003700733184814
Validation loss: 2.1600667289508286

Epoch: 6| Step: 5
Training loss: 1.8692444562911987
Validation loss: 2.186764822211317

Epoch: 6| Step: 6
Training loss: 1.7041139602661133
Validation loss: 2.199705080319476

Epoch: 6| Step: 7
Training loss: 2.105025053024292
Validation loss: 2.2310982288852816

Epoch: 6| Step: 8
Training loss: 2.8304829597473145
Validation loss: 2.2143254331363145

Epoch: 6| Step: 9
Training loss: 2.7965006828308105
Validation loss: 2.1940743077185845

Epoch: 6| Step: 10
Training loss: 1.915234923362732
Validation loss: 2.1797749034820066

Epoch: 6| Step: 11
Training loss: 1.446530818939209
Validation loss: 2.1562494385627007

Epoch: 6| Step: 12
Training loss: 2.0643692016601562
Validation loss: 2.1357232652684695

Epoch: 6| Step: 13
Training loss: 1.2826615571975708
Validation loss: 2.113902723917397

Epoch: 490| Step: 0
Training loss: 2.010057210922241
Validation loss: 2.123541191060056

Epoch: 6| Step: 1
Training loss: 2.0922975540161133
Validation loss: 2.1123863586815457

Epoch: 6| Step: 2
Training loss: 2.204601764678955
Validation loss: 2.124249965913834

Epoch: 6| Step: 3
Training loss: 1.8400421142578125
Validation loss: 2.142360064291185

Epoch: 6| Step: 4
Training loss: 1.806063175201416
Validation loss: 2.1377291564018495

Epoch: 6| Step: 5
Training loss: 2.009763479232788
Validation loss: 2.146953805800407

Epoch: 6| Step: 6
Training loss: 1.9318125247955322
Validation loss: 2.157858681935136

Epoch: 6| Step: 7
Training loss: 2.697636604309082
Validation loss: 2.144180605488439

Epoch: 6| Step: 8
Training loss: 2.315058708190918
Validation loss: 2.1575571913872995

Epoch: 6| Step: 9
Training loss: 1.2670644521713257
Validation loss: 2.1319170639079106

Epoch: 6| Step: 10
Training loss: 2.1763358116149902
Validation loss: 2.1366431020921275

Epoch: 6| Step: 11
Training loss: 1.722437858581543
Validation loss: 2.150322555213846

Epoch: 6| Step: 12
Training loss: 2.000983953475952
Validation loss: 2.1394928104134014

Epoch: 6| Step: 13
Training loss: 1.5443774461746216
Validation loss: 2.150310008756576

Epoch: 491| Step: 0
Training loss: 2.0566816329956055
Validation loss: 2.1604451005176832

Epoch: 6| Step: 1
Training loss: 1.8689261674880981
Validation loss: 2.1781355463048464

Epoch: 6| Step: 2
Training loss: 1.8983850479125977
Validation loss: 2.1698010685623332

Epoch: 6| Step: 3
Training loss: 1.7964024543762207
Validation loss: 2.181183417638143

Epoch: 6| Step: 4
Training loss: 2.132626533508301
Validation loss: 2.186149243385561

Epoch: 6| Step: 5
Training loss: 1.7361016273498535
Validation loss: 2.176130981855495

Epoch: 6| Step: 6
Training loss: 1.9224128723144531
Validation loss: 2.1644779328377015

Epoch: 6| Step: 7
Training loss: 2.0619254112243652
Validation loss: 2.13747469071419

Epoch: 6| Step: 8
Training loss: 2.0485963821411133
Validation loss: 2.1386120319366455

Epoch: 6| Step: 9
Training loss: 2.7604174613952637
Validation loss: 2.1323163778551164

Epoch: 6| Step: 10
Training loss: 1.1678783893585205
Validation loss: 2.1499676089132986

Epoch: 6| Step: 11
Training loss: 2.2445030212402344
Validation loss: 2.136822308263471

Epoch: 6| Step: 12
Training loss: 2.423849105834961
Validation loss: 2.1377318700154624

Epoch: 6| Step: 13
Training loss: 1.470549464225769
Validation loss: 2.168766542147565

Epoch: 492| Step: 0
Training loss: 2.4181604385375977
Validation loss: 2.165305636262381

Epoch: 6| Step: 1
Training loss: 1.8411611318588257
Validation loss: 2.1798350913550264

Epoch: 6| Step: 2
Training loss: 1.717092514038086
Validation loss: 2.190748413403829

Epoch: 6| Step: 3
Training loss: 2.134549140930176
Validation loss: 2.2152847628439627

Epoch: 6| Step: 4
Training loss: 2.075678586959839
Validation loss: 2.1808363673507527

Epoch: 6| Step: 5
Training loss: 1.7960011959075928
Validation loss: 2.2018698312902965

Epoch: 6| Step: 6
Training loss: 1.710373878479004
Validation loss: 2.1645122753676547

Epoch: 6| Step: 7
Training loss: 1.6083120107650757
Validation loss: 2.133726824996292

Epoch: 6| Step: 8
Training loss: 2.1560893058776855
Validation loss: 2.1240655299155944

Epoch: 6| Step: 9
Training loss: 1.408095121383667
Validation loss: 2.112249849944986

Epoch: 6| Step: 10
Training loss: 2.464277744293213
Validation loss: 2.1294292429442048

Epoch: 6| Step: 11
Training loss: 2.258152961730957
Validation loss: 2.114711420510405

Epoch: 6| Step: 12
Training loss: 2.524522066116333
Validation loss: 2.144837648637833

Epoch: 6| Step: 13
Training loss: 1.5775198936462402
Validation loss: 2.1369065648765972

Epoch: 493| Step: 0
Training loss: 2.2121825218200684
Validation loss: 2.132518288909748

Epoch: 6| Step: 1
Training loss: 1.6401705741882324
Validation loss: 2.1472440496567757

Epoch: 6| Step: 2
Training loss: 1.4305462837219238
Validation loss: 2.1324313417557748

Epoch: 6| Step: 3
Training loss: 2.6476681232452393
Validation loss: 2.1353273891633555

Epoch: 6| Step: 4
Training loss: 2.1560988426208496
Validation loss: 2.147033060750654

Epoch: 6| Step: 5
Training loss: 1.4597108364105225
Validation loss: 2.134902064518262

Epoch: 6| Step: 6
Training loss: 1.2807958126068115
Validation loss: 2.13307293768852

Epoch: 6| Step: 7
Training loss: 1.9868940114974976
Validation loss: 2.121631060877154

Epoch: 6| Step: 8
Training loss: 2.2131385803222656
Validation loss: 2.1232082869416926

Epoch: 6| Step: 9
Training loss: 1.8342844247817993
Validation loss: 2.1258660811249928

Epoch: 6| Step: 10
Training loss: 2.3264479637145996
Validation loss: 2.1309243017627346

Epoch: 6| Step: 11
Training loss: 2.02144193649292
Validation loss: 2.1167548420608684

Epoch: 6| Step: 12
Training loss: 2.711143732070923
Validation loss: 2.1361082151371944

Epoch: 6| Step: 13
Training loss: 1.694818377494812
Validation loss: 2.13669708723663

Epoch: 494| Step: 0
Training loss: 2.161162853240967
Validation loss: 2.1414856705614316

Epoch: 6| Step: 1
Training loss: 2.0461277961730957
Validation loss: 2.1553005403087986

Epoch: 6| Step: 2
Training loss: 2.12691068649292
Validation loss: 2.1883347111363567

Epoch: 6| Step: 3
Training loss: 2.152850389480591
Validation loss: 2.1895127783539476

Epoch: 6| Step: 4
Training loss: 1.576888084411621
Validation loss: 2.166008477569908

Epoch: 6| Step: 5
Training loss: 2.048496961593628
Validation loss: 2.152860379988147

Epoch: 6| Step: 6
Training loss: 2.24114990234375
Validation loss: 2.1141484680996148

Epoch: 6| Step: 7
Training loss: 2.0267107486724854
Validation loss: 2.1154072233425674

Epoch: 6| Step: 8
Training loss: 2.0704126358032227
Validation loss: 2.10363495221702

Epoch: 6| Step: 9
Training loss: 2.122317314147949
Validation loss: 2.0885894067825808

Epoch: 6| Step: 10
Training loss: 1.4826483726501465
Validation loss: 2.0940374392335133

Epoch: 6| Step: 11
Training loss: 1.7027926445007324
Validation loss: 2.110187058807701

Epoch: 6| Step: 12
Training loss: 2.4133968353271484
Validation loss: 2.132152429191015

Epoch: 6| Step: 13
Training loss: 1.43373441696167
Validation loss: 2.1236618398338236

Epoch: 495| Step: 0
Training loss: 2.184579372406006
Validation loss: 2.173892746689499

Epoch: 6| Step: 1
Training loss: 1.5060904026031494
Validation loss: 2.1656648305154618

Epoch: 6| Step: 2
Training loss: 1.4551843404769897
Validation loss: 2.183057245387826

Epoch: 6| Step: 3
Training loss: 1.8951258659362793
Validation loss: 2.1725024613001014

Epoch: 6| Step: 4
Training loss: 2.5403099060058594
Validation loss: 2.1610699366497736

Epoch: 6| Step: 5
Training loss: 2.1244492530822754
Validation loss: 2.158366369944747

Epoch: 6| Step: 6
Training loss: 1.8288706541061401
Validation loss: 2.1376361270104685

Epoch: 6| Step: 7
Training loss: 2.1462807655334473
Validation loss: 2.129882181844404

Epoch: 6| Step: 8
Training loss: 1.5599671602249146
Validation loss: 2.1245103613022835

Epoch: 6| Step: 9
Training loss: 1.9777109622955322
Validation loss: 2.122725837974138

Epoch: 6| Step: 10
Training loss: 2.020714282989502
Validation loss: 2.1070746273122807

Epoch: 6| Step: 11
Training loss: 3.160064935684204
Validation loss: 2.1196847795158305

Epoch: 6| Step: 12
Training loss: 1.383899450302124
Validation loss: 2.1204447451458184

Epoch: 6| Step: 13
Training loss: 1.7773672342300415
Validation loss: 2.143486721541292

Epoch: 496| Step: 0
Training loss: 1.4562098979949951
Validation loss: 2.162484117733535

Epoch: 6| Step: 1
Training loss: 2.410680055618286
Validation loss: 2.1534553458613734

Epoch: 6| Step: 2
Training loss: 1.6202545166015625
Validation loss: 2.152661238947222

Epoch: 6| Step: 3
Training loss: 1.3909910917282104
Validation loss: 2.133780042330424

Epoch: 6| Step: 4
Training loss: 2.2481179237365723
Validation loss: 2.1249269541873725

Epoch: 6| Step: 5
Training loss: 2.344029664993286
Validation loss: 2.1230642718653523

Epoch: 6| Step: 6
Training loss: 1.780845046043396
Validation loss: 2.1163254219998597

Epoch: 6| Step: 7
Training loss: 1.2923264503479004
Validation loss: 2.1271894285755772

Epoch: 6| Step: 8
Training loss: 2.7814316749572754
Validation loss: 2.1311212201272287

Epoch: 6| Step: 9
Training loss: 1.5743436813354492
Validation loss: 2.1390583104984735

Epoch: 6| Step: 10
Training loss: 2.3860435485839844
Validation loss: 2.145875907713367

Epoch: 6| Step: 11
Training loss: 2.2716405391693115
Validation loss: 2.1556754804426626

Epoch: 6| Step: 12
Training loss: 2.1901967525482178
Validation loss: 2.138688310500114

Epoch: 6| Step: 13
Training loss: 1.9455119371414185
Validation loss: 2.1186869695622432

Epoch: 497| Step: 0
Training loss: 1.055031418800354
Validation loss: 2.1312201253829466

Epoch: 6| Step: 1
Training loss: 2.377805709838867
Validation loss: 2.1213962288313013

Epoch: 6| Step: 2
Training loss: 2.22711181640625
Validation loss: 2.1240885180811726

Epoch: 6| Step: 3
Training loss: 2.804692506790161
Validation loss: 2.1279801348204255

Epoch: 6| Step: 4
Training loss: 1.814152717590332
Validation loss: 2.12497890123757

Epoch: 6| Step: 5
Training loss: 2.3251733779907227
Validation loss: 2.139496144428048

Epoch: 6| Step: 6
Training loss: 1.788630485534668
Validation loss: 2.14133882522583

Epoch: 6| Step: 7
Training loss: 2.415219783782959
Validation loss: 2.1293485446642806

Epoch: 6| Step: 8
Training loss: 2.0743956565856934
Validation loss: 2.158434050057524

Epoch: 6| Step: 9
Training loss: 1.1015102863311768
Validation loss: 2.1588862890838296

Epoch: 6| Step: 10
Training loss: 1.6062442064285278
Validation loss: 2.1227180829612156

Epoch: 6| Step: 11
Training loss: 2.226757287979126
Validation loss: 2.12668784715796

Epoch: 6| Step: 12
Training loss: 1.9372735023498535
Validation loss: 2.127023866099696

Epoch: 6| Step: 13
Training loss: 1.674898624420166
Validation loss: 2.1281623660877185

Epoch: 498| Step: 0
Training loss: 0.9074780941009521
Validation loss: 2.144592833775346

Epoch: 6| Step: 1
Training loss: 1.553078055381775
Validation loss: 2.1482561172977572

Epoch: 6| Step: 2
Training loss: 1.4139914512634277
Validation loss: 2.157425352322158

Epoch: 6| Step: 3
Training loss: 1.5815088748931885
Validation loss: 2.1646448822431665

Epoch: 6| Step: 4
Training loss: 2.932788372039795
Validation loss: 2.178063738730646

Epoch: 6| Step: 5
Training loss: 1.9638135433197021
Validation loss: 2.1901990828975553

Epoch: 6| Step: 6
Training loss: 1.9452030658721924
Validation loss: 2.1668633953217538

Epoch: 6| Step: 7
Training loss: 2.0516602993011475
Validation loss: 2.15923067831224

Epoch: 6| Step: 8
Training loss: 2.217954635620117
Validation loss: 2.1388627149725474

Epoch: 6| Step: 9
Training loss: 1.4143134355545044
Validation loss: 2.1347166953548307

Epoch: 6| Step: 10
Training loss: 2.9157872200012207
Validation loss: 2.14374218961244

Epoch: 6| Step: 11
Training loss: 2.47353458404541
Validation loss: 2.1356694108696392

Epoch: 6| Step: 12
Training loss: 1.9491076469421387
Validation loss: 2.131685649195025

Epoch: 6| Step: 13
Training loss: 2.310185670852661
Validation loss: 2.120599091693919

Epoch: 499| Step: 0
Training loss: 1.9276961088180542
Validation loss: 2.1039269111489736

Epoch: 6| Step: 1
Training loss: 2.3407702445983887
Validation loss: 2.1104727765565277

Epoch: 6| Step: 2
Training loss: 1.8231580257415771
Validation loss: 2.1262523128140356

Epoch: 6| Step: 3
Training loss: 1.8085968494415283
Validation loss: 2.1274072854749617

Epoch: 6| Step: 4
Training loss: 1.6083353757858276
Validation loss: 2.119185301565355

Epoch: 6| Step: 5
Training loss: 1.644916296005249
Validation loss: 2.10224627038484

Epoch: 6| Step: 6
Training loss: 2.670013904571533
Validation loss: 2.1313612114998604

Epoch: 6| Step: 7
Training loss: 1.9076768159866333
Validation loss: 2.1385245861545688

Epoch: 6| Step: 8
Training loss: 1.803182601928711
Validation loss: 2.154783894938807

Epoch: 6| Step: 9
Training loss: 2.0809669494628906
Validation loss: 2.1382208613939184

Epoch: 6| Step: 10
Training loss: 1.7320846319198608
Validation loss: 2.135276250941779

Epoch: 6| Step: 11
Training loss: 1.8678061962127686
Validation loss: 2.1165386810097644

Epoch: 6| Step: 12
Training loss: 2.4722635746002197
Validation loss: 2.1457986780392226

Epoch: 6| Step: 13
Training loss: 1.8747308254241943
Validation loss: 2.1402210573996268

Epoch: 500| Step: 0
Training loss: 1.9901269674301147
Validation loss: 2.1511154482441563

Epoch: 6| Step: 1
Training loss: 2.316711902618408
Validation loss: 2.1562489053254486

Epoch: 6| Step: 2
Training loss: 2.23712158203125
Validation loss: 2.1525300651468258

Epoch: 6| Step: 3
Training loss: 2.125535011291504
Validation loss: 2.1390871706829278

Epoch: 6| Step: 4
Training loss: 1.5303454399108887
Validation loss: 2.139109524347449

Epoch: 6| Step: 5
Training loss: 1.29763662815094
Validation loss: 2.1391854593830724

Epoch: 6| Step: 6
Training loss: 2.367619037628174
Validation loss: 2.110962208881173

Epoch: 6| Step: 7
Training loss: 2.211613178253174
Validation loss: 2.1251831182869534

Epoch: 6| Step: 8
Training loss: 1.8195542097091675
Validation loss: 2.1157357461990847

Epoch: 6| Step: 9
Training loss: 2.591393232345581
Validation loss: 2.1365205831425165

Epoch: 6| Step: 10
Training loss: 1.7762017250061035
Validation loss: 2.1518386922856814

Epoch: 6| Step: 11
Training loss: 1.6093764305114746
Validation loss: 2.151993264434158

Epoch: 6| Step: 12
Training loss: 1.873966932296753
Validation loss: 2.1719741898198284

Epoch: 6| Step: 13
Training loss: 1.5210028886795044
Validation loss: 2.151472222420477

Epoch: 501| Step: 0
Training loss: 2.163175582885742
Validation loss: 2.1509318415836622

Epoch: 6| Step: 1
Training loss: 1.925986409187317
Validation loss: 2.1905540394526657

Epoch: 6| Step: 2
Training loss: 1.7146966457366943
Validation loss: 2.1509307392181887

Epoch: 6| Step: 3
Training loss: 2.066469669342041
Validation loss: 2.139297777606595

Epoch: 6| Step: 4
Training loss: 1.8389949798583984
Validation loss: 2.146741702992429

Epoch: 6| Step: 5
Training loss: 1.5107133388519287
Validation loss: 2.140889367749614

Epoch: 6| Step: 6
Training loss: 1.928107500076294
Validation loss: 2.123526096343994

Epoch: 6| Step: 7
Training loss: 2.136932373046875
Validation loss: 2.129732313976493

Epoch: 6| Step: 8
Training loss: 2.039785385131836
Validation loss: 2.135145733433385

Epoch: 6| Step: 9
Training loss: 2.0726397037506104
Validation loss: 2.148842029674079

Epoch: 6| Step: 10
Training loss: 1.5142935514450073
Validation loss: 2.1264797077384046

Epoch: 6| Step: 11
Training loss: 2.481069564819336
Validation loss: 2.1493129602042575

Epoch: 6| Step: 12
Training loss: 2.462787628173828
Validation loss: 2.135170590492987

Epoch: 6| Step: 13
Training loss: 1.2830458879470825
Validation loss: 2.1369822576481807

Epoch: 502| Step: 0
Training loss: 1.7924962043762207
Validation loss: 2.1274939275556997

Epoch: 6| Step: 1
Training loss: 1.8613803386688232
Validation loss: 2.1131691714768768

Epoch: 6| Step: 2
Training loss: 1.629616379737854
Validation loss: 2.1309887029791392

Epoch: 6| Step: 3
Training loss: 2.251166820526123
Validation loss: 2.1320790680505897

Epoch: 6| Step: 4
Training loss: 2.4866726398468018
Validation loss: 2.1506165894128944

Epoch: 6| Step: 5
Training loss: 2.236387014389038
Validation loss: 2.1823151957604194

Epoch: 6| Step: 6
Training loss: 2.654379367828369
Validation loss: 2.1714149008515062

Epoch: 6| Step: 7
Training loss: 1.5616124868392944
Validation loss: 2.1631805063575826

Epoch: 6| Step: 8
Training loss: 1.2438137531280518
Validation loss: 2.166171076477215

Epoch: 6| Step: 9
Training loss: 1.8728454113006592
Validation loss: 2.148306994027989

Epoch: 6| Step: 10
Training loss: 2.2641279697418213
Validation loss: 2.153532922908824

Epoch: 6| Step: 11
Training loss: 1.6138403415679932
Validation loss: 2.1325292356552614

Epoch: 6| Step: 12
Training loss: 1.8353745937347412
Validation loss: 2.1046153165960826

Epoch: 6| Step: 13
Training loss: 2.3460869789123535
Validation loss: 2.1079880640070927

Epoch: 503| Step: 0
Training loss: 1.6697797775268555
Validation loss: 2.1088523505836405

Epoch: 6| Step: 1
Training loss: 2.0660109519958496
Validation loss: 2.1067672442364436

Epoch: 6| Step: 2
Training loss: 2.6194968223571777
Validation loss: 2.125007926776845

Epoch: 6| Step: 3
Training loss: 2.413031816482544
Validation loss: 2.127937788604408

Epoch: 6| Step: 4
Training loss: 2.0130467414855957
Validation loss: 2.168051714538246

Epoch: 6| Step: 5
Training loss: 1.4945461750030518
Validation loss: 2.1597019485248032

Epoch: 6| Step: 6
Training loss: 1.0080347061157227
Validation loss: 2.155323366965017

Epoch: 6| Step: 7
Training loss: 1.9572800397872925
Validation loss: 2.129138938842281

Epoch: 6| Step: 8
Training loss: 1.3905541896820068
Validation loss: 2.123003162363524

Epoch: 6| Step: 9
Training loss: 2.784451484680176
Validation loss: 2.1035966232258785

Epoch: 6| Step: 10
Training loss: 2.1199865341186523
Validation loss: 2.095209526759322

Epoch: 6| Step: 11
Training loss: 2.6349682807922363
Validation loss: 2.1161282805986303

Epoch: 6| Step: 12
Training loss: 1.366005301475525
Validation loss: 2.0925458695298884

Epoch: 6| Step: 13
Training loss: 1.9653897285461426
Validation loss: 2.0955661906990954

Epoch: 504| Step: 0
Training loss: 1.9607402086257935
Validation loss: 2.112994777259006

Epoch: 6| Step: 1
Training loss: 2.519669532775879
Validation loss: 2.115607325748731

Epoch: 6| Step: 2
Training loss: 2.0135722160339355
Validation loss: 2.1476350356173772

Epoch: 6| Step: 3
Training loss: 1.9510610103607178
Validation loss: 2.151957429865355

Epoch: 6| Step: 4
Training loss: 1.1923351287841797
Validation loss: 2.1502122097117926

Epoch: 6| Step: 5
Training loss: 1.8920563459396362
Validation loss: 2.1485514615171697

Epoch: 6| Step: 6
Training loss: 2.1226162910461426
Validation loss: 2.168455334119899

Epoch: 6| Step: 7
Training loss: 2.343454122543335
Validation loss: 2.1327305506634455

Epoch: 6| Step: 8
Training loss: 2.195319890975952
Validation loss: 2.1257017966239684

Epoch: 6| Step: 9
Training loss: 1.450142741203308
Validation loss: 2.103407262473978

Epoch: 6| Step: 10
Training loss: 1.3638887405395508
Validation loss: 2.1079121507624143

Epoch: 6| Step: 11
Training loss: 2.2851650714874268
Validation loss: 2.106617819878363

Epoch: 6| Step: 12
Training loss: 2.0717036724090576
Validation loss: 2.1014673914960635

Epoch: 6| Step: 13
Training loss: 2.1181421279907227
Validation loss: 2.1107969642967306

Epoch: 505| Step: 0
Training loss: 2.2876672744750977
Validation loss: 2.12012057663292

Epoch: 6| Step: 1
Training loss: 1.5777448415756226
Validation loss: 2.14346408331266

Epoch: 6| Step: 2
Training loss: 1.9476203918457031
Validation loss: 2.144186568516557

Epoch: 6| Step: 3
Training loss: 1.4786499738693237
Validation loss: 2.1914928625988703

Epoch: 6| Step: 4
Training loss: 2.0185394287109375
Validation loss: 2.2066605757641535

Epoch: 6| Step: 5
Training loss: 1.38950514793396
Validation loss: 2.1796069452839513

Epoch: 6| Step: 6
Training loss: 1.7898259162902832
Validation loss: 2.188835210697625

Epoch: 6| Step: 7
Training loss: 1.9836041927337646
Validation loss: 2.16297334753057

Epoch: 6| Step: 8
Training loss: 2.352107048034668
Validation loss: 2.1356122442471084

Epoch: 6| Step: 9
Training loss: 2.3845791816711426
Validation loss: 2.1099547186205463

Epoch: 6| Step: 10
Training loss: 1.941429853439331
Validation loss: 2.1127222866140385

Epoch: 6| Step: 11
Training loss: 1.9553297758102417
Validation loss: 2.106511304455419

Epoch: 6| Step: 12
Training loss: 2.167093515396118
Validation loss: 2.085091442190191

Epoch: 6| Step: 13
Training loss: 2.2384305000305176
Validation loss: 2.086246457151187

Epoch: 506| Step: 0
Training loss: 1.9179315567016602
Validation loss: 2.101200303723735

Epoch: 6| Step: 1
Training loss: 1.413366675376892
Validation loss: 2.109175069357759

Epoch: 6| Step: 2
Training loss: 1.5697388648986816
Validation loss: 2.1229592933449695

Epoch: 6| Step: 3
Training loss: 2.567749261856079
Validation loss: 2.140331688747611

Epoch: 6| Step: 4
Training loss: 1.6427854299545288
Validation loss: 2.152336723061018

Epoch: 6| Step: 5
Training loss: 2.0502490997314453
Validation loss: 2.174669914348151

Epoch: 6| Step: 6
Training loss: 1.9663324356079102
Validation loss: 2.164742200605331

Epoch: 6| Step: 7
Training loss: 1.9068570137023926
Validation loss: 2.1439180758691605

Epoch: 6| Step: 8
Training loss: 2.4281516075134277
Validation loss: 2.1263946576785018

Epoch: 6| Step: 9
Training loss: 2.245828628540039
Validation loss: 2.109438588542323

Epoch: 6| Step: 10
Training loss: 1.330507516860962
Validation loss: 2.0979011186989407

Epoch: 6| Step: 11
Training loss: 1.5421440601348877
Validation loss: 2.101370744807746

Epoch: 6| Step: 12
Training loss: 2.4116477966308594
Validation loss: 2.1089733544216362

Epoch: 6| Step: 13
Training loss: 2.608208656311035
Validation loss: 2.0985420237305346

Epoch: 507| Step: 0
Training loss: 1.7800016403198242
Validation loss: 2.1205743987073182

Epoch: 6| Step: 1
Training loss: 2.79373836517334
Validation loss: 2.10974697912893

Epoch: 6| Step: 2
Training loss: 2.002103328704834
Validation loss: 2.094633197271696

Epoch: 6| Step: 3
Training loss: 1.2529222965240479
Validation loss: 2.11338101279351

Epoch: 6| Step: 4
Training loss: 2.130463123321533
Validation loss: 2.126751699755269

Epoch: 6| Step: 5
Training loss: 1.6583616733551025
Validation loss: 2.1296834227859334

Epoch: 6| Step: 6
Training loss: 0.9457398653030396
Validation loss: 2.1300671818435832

Epoch: 6| Step: 7
Training loss: 2.1201837062835693
Validation loss: 2.1562974940064135

Epoch: 6| Step: 8
Training loss: 1.8167237043380737
Validation loss: 2.1530849164532078

Epoch: 6| Step: 9
Training loss: 1.5987564325332642
Validation loss: 2.1776820587855514

Epoch: 6| Step: 10
Training loss: 1.8914744853973389
Validation loss: 2.170751351182179

Epoch: 6| Step: 11
Training loss: 2.3288066387176514
Validation loss: 2.1538879897004817

Epoch: 6| Step: 12
Training loss: 2.4798309803009033
Validation loss: 2.1493106913822952

Epoch: 6| Step: 13
Training loss: 2.8611576557159424
Validation loss: 2.1307523660762335

Epoch: 508| Step: 0
Training loss: 2.4755868911743164
Validation loss: 2.112489988726954

Epoch: 6| Step: 1
Training loss: 1.5027536153793335
Validation loss: 2.1079573323649745

Epoch: 6| Step: 2
Training loss: 1.595841646194458
Validation loss: 2.1201073918291318

Epoch: 6| Step: 3
Training loss: 1.6019971370697021
Validation loss: 2.104816667495235

Epoch: 6| Step: 4
Training loss: 1.6584787368774414
Validation loss: 2.1133668140698503

Epoch: 6| Step: 5
Training loss: 2.499980926513672
Validation loss: 2.109886900071175

Epoch: 6| Step: 6
Training loss: 1.9665157794952393
Validation loss: 2.148419633988411

Epoch: 6| Step: 7
Training loss: 1.7235989570617676
Validation loss: 2.204620697165048

Epoch: 6| Step: 8
Training loss: 1.8572527170181274
Validation loss: 2.2022428153663554

Epoch: 6| Step: 9
Training loss: 2.0939645767211914
Validation loss: 2.1774344777548187

Epoch: 6| Step: 10
Training loss: 2.499189853668213
Validation loss: 2.1861424676833616

Epoch: 6| Step: 11
Training loss: 1.761410117149353
Validation loss: 2.135047067878067

Epoch: 6| Step: 12
Training loss: 2.224576234817505
Validation loss: 2.120443131334038

Epoch: 6| Step: 13
Training loss: 1.8350884914398193
Validation loss: 2.1027115852602067

Epoch: 509| Step: 0
Training loss: 1.135304570198059
Validation loss: 2.106643945940079

Epoch: 6| Step: 1
Training loss: 1.7705609798431396
Validation loss: 2.1074418739605973

Epoch: 6| Step: 2
Training loss: 2.7192485332489014
Validation loss: 2.1062194429418093

Epoch: 6| Step: 3
Training loss: 1.892643690109253
Validation loss: 2.123844785075034

Epoch: 6| Step: 4
Training loss: 1.9998207092285156
Validation loss: 2.1379297010360228

Epoch: 6| Step: 5
Training loss: 1.544391393661499
Validation loss: 2.117112300729239

Epoch: 6| Step: 6
Training loss: 1.2622451782226562
Validation loss: 2.1250032096780758

Epoch: 6| Step: 7
Training loss: 2.3442800045013428
Validation loss: 2.116751383709651

Epoch: 6| Step: 8
Training loss: 1.8905901908874512
Validation loss: 2.106417648253902

Epoch: 6| Step: 9
Training loss: 2.674861431121826
Validation loss: 2.1138915067077964

Epoch: 6| Step: 10
Training loss: 2.4962244033813477
Validation loss: 2.127063871711813

Epoch: 6| Step: 11
Training loss: 1.6348271369934082
Validation loss: 2.115722406295038

Epoch: 6| Step: 12
Training loss: 1.6653823852539062
Validation loss: 2.098134312578427

Epoch: 6| Step: 13
Training loss: 2.4373719692230225
Validation loss: 2.121607113909978

Epoch: 510| Step: 0
Training loss: 1.76055109500885
Validation loss: 2.1359472005598006

Epoch: 6| Step: 1
Training loss: 1.704827070236206
Validation loss: 2.1484598882736696

Epoch: 6| Step: 2
Training loss: 1.7216835021972656
Validation loss: 2.1525290371269308

Epoch: 6| Step: 3
Training loss: 2.227267265319824
Validation loss: 2.176224623956988

Epoch: 6| Step: 4
Training loss: 1.6515980958938599
Validation loss: 2.187907623988326

Epoch: 6| Step: 5
Training loss: 1.8690427541732788
Validation loss: 2.188983973636422

Epoch: 6| Step: 6
Training loss: 1.9572489261627197
Validation loss: 2.1357701132374425

Epoch: 6| Step: 7
Training loss: 2.445979118347168
Validation loss: 2.1156915362163256

Epoch: 6| Step: 8
Training loss: 1.950892686843872
Validation loss: 2.1118518357635825

Epoch: 6| Step: 9
Training loss: 1.7614517211914062
Validation loss: 2.1043991452904156

Epoch: 6| Step: 10
Training loss: 2.6072797775268555
Validation loss: 2.09712113359923

Epoch: 6| Step: 11
Training loss: 1.987786054611206
Validation loss: 2.0897822854339436

Epoch: 6| Step: 12
Training loss: 1.275606632232666
Validation loss: 2.1196632769800003

Epoch: 6| Step: 13
Training loss: 2.5319886207580566
Validation loss: 2.130613312926344

Epoch: 511| Step: 0
Training loss: 1.7281708717346191
Validation loss: 2.146968772334437

Epoch: 6| Step: 1
Training loss: 1.5243325233459473
Validation loss: 2.1431399045451993

Epoch: 6| Step: 2
Training loss: 2.09466814994812
Validation loss: 2.128948626979705

Epoch: 6| Step: 3
Training loss: 2.1820216178894043
Validation loss: 2.1187241154332317

Epoch: 6| Step: 4
Training loss: 2.0831875801086426
Validation loss: 2.0982727107181343

Epoch: 6| Step: 5
Training loss: 1.8014219999313354
Validation loss: 2.092052741717267

Epoch: 6| Step: 6
Training loss: 1.628596305847168
Validation loss: 2.097857867517779

Epoch: 6| Step: 7
Training loss: 2.3969814777374268
Validation loss: 2.101360059553577

Epoch: 6| Step: 8
Training loss: 1.6399428844451904
Validation loss: 2.0909404729002263

Epoch: 6| Step: 9
Training loss: 1.7246067523956299
Validation loss: 2.1153490684365712

Epoch: 6| Step: 10
Training loss: 1.4051164388656616
Validation loss: 2.103630281263782

Epoch: 6| Step: 11
Training loss: 2.2573184967041016
Validation loss: 2.128724686561092

Epoch: 6| Step: 12
Training loss: 2.545504093170166
Validation loss: 2.1411217592095815

Epoch: 6| Step: 13
Training loss: 2.460921049118042
Validation loss: 2.1767001382766233

Epoch: 512| Step: 0
Training loss: 2.494957685470581
Validation loss: 2.157734340237033

Epoch: 6| Step: 1
Training loss: 2.3164188861846924
Validation loss: 2.1504022536739225

Epoch: 6| Step: 2
Training loss: 1.6274282932281494
Validation loss: 2.139397108426658

Epoch: 6| Step: 3
Training loss: 1.8022873401641846
Validation loss: 2.1142138870813514

Epoch: 6| Step: 4
Training loss: 1.742509126663208
Validation loss: 2.109697493173743

Epoch: 6| Step: 5
Training loss: 1.190718650817871
Validation loss: 2.108946701531769

Epoch: 6| Step: 6
Training loss: 1.949737787246704
Validation loss: 2.101966337491107

Epoch: 6| Step: 7
Training loss: 2.437426805496216
Validation loss: 2.100896244407982

Epoch: 6| Step: 8
Training loss: 2.066223382949829
Validation loss: 2.1203013799523793

Epoch: 6| Step: 9
Training loss: 2.049222230911255
Validation loss: 2.124027198360812

Epoch: 6| Step: 10
Training loss: 1.5944647789001465
Validation loss: 2.1237843818562006

Epoch: 6| Step: 11
Training loss: 2.199939727783203
Validation loss: 2.1332240181584514

Epoch: 6| Step: 12
Training loss: 1.701322078704834
Validation loss: 2.1350467358866045

Epoch: 6| Step: 13
Training loss: 2.121873378753662
Validation loss: 2.163423199807444

Epoch: 513| Step: 0
Training loss: 2.0683741569519043
Validation loss: 2.157836341088818

Epoch: 6| Step: 1
Training loss: 1.7050907611846924
Validation loss: 2.151501250523393

Epoch: 6| Step: 2
Training loss: 1.9825356006622314
Validation loss: 2.16676466567542

Epoch: 6| Step: 3
Training loss: 1.5997426509857178
Validation loss: 2.151379108428955

Epoch: 6| Step: 4
Training loss: 1.6801965236663818
Validation loss: 2.117980541721467

Epoch: 6| Step: 5
Training loss: 1.8816710710525513
Validation loss: 2.102291637851346

Epoch: 6| Step: 6
Training loss: 2.1000452041625977
Validation loss: 2.12039755493082

Epoch: 6| Step: 7
Training loss: 2.3517370223999023
Validation loss: 2.094926393160256

Epoch: 6| Step: 8
Training loss: 2.0864500999450684
Validation loss: 2.1031045939332698

Epoch: 6| Step: 9
Training loss: 2.2087597846984863
Validation loss: 2.111450138912406

Epoch: 6| Step: 10
Training loss: 1.7130157947540283
Validation loss: 2.0939890441074165

Epoch: 6| Step: 11
Training loss: 2.554713726043701
Validation loss: 2.11972334308009

Epoch: 6| Step: 12
Training loss: 1.7320688962936401
Validation loss: 2.125504139930971

Epoch: 6| Step: 13
Training loss: 1.232531189918518
Validation loss: 2.133241025350427

Epoch: 514| Step: 0
Training loss: 1.38743257522583
Validation loss: 2.137977143769623

Epoch: 6| Step: 1
Training loss: 1.882660150527954
Validation loss: 2.153234279283913

Epoch: 6| Step: 2
Training loss: 2.0709238052368164
Validation loss: 2.1348627639073197

Epoch: 6| Step: 3
Training loss: 1.728444218635559
Validation loss: 2.160957885044877

Epoch: 6| Step: 4
Training loss: 2.228963851928711
Validation loss: 2.1556111163990472

Epoch: 6| Step: 5
Training loss: 1.734344720840454
Validation loss: 2.1428500503622074

Epoch: 6| Step: 6
Training loss: 2.910508394241333
Validation loss: 2.122705985141057

Epoch: 6| Step: 7
Training loss: 1.6279958486557007
Validation loss: 2.0988673420362574

Epoch: 6| Step: 8
Training loss: 1.2383034229278564
Validation loss: 2.074659019388178

Epoch: 6| Step: 9
Training loss: 2.2722911834716797
Validation loss: 2.1107010431187128

Epoch: 6| Step: 10
Training loss: 1.5143851041793823
Validation loss: 2.0779677667925434

Epoch: 6| Step: 11
Training loss: 1.8943029642105103
Validation loss: 2.0916190967764905

Epoch: 6| Step: 12
Training loss: 2.3812665939331055
Validation loss: 2.104411232856012

Epoch: 6| Step: 13
Training loss: 2.449453830718994
Validation loss: 2.1203528014562463

Epoch: 515| Step: 0
Training loss: 1.884401559829712
Validation loss: 2.113201064448203

Epoch: 6| Step: 1
Training loss: 1.245908498764038
Validation loss: 2.1248627478076565

Epoch: 6| Step: 2
Training loss: 1.3189127445220947
Validation loss: 2.1279971163759948

Epoch: 6| Step: 3
Training loss: 1.6968497037887573
Validation loss: 2.112315326608637

Epoch: 6| Step: 4
Training loss: 1.9186830520629883
Validation loss: 2.1088426369492725

Epoch: 6| Step: 5
Training loss: 2.1686794757843018
Validation loss: 2.1013443316182783

Epoch: 6| Step: 6
Training loss: 2.335904598236084
Validation loss: 2.0927278559695006

Epoch: 6| Step: 7
Training loss: 2.0708794593811035
Validation loss: 2.0897175188987487

Epoch: 6| Step: 8
Training loss: 1.495898962020874
Validation loss: 2.101715371172915

Epoch: 6| Step: 9
Training loss: 2.575439214706421
Validation loss: 2.097724897887117

Epoch: 6| Step: 10
Training loss: 2.3672122955322266
Validation loss: 2.1041529998984387

Epoch: 6| Step: 11
Training loss: 1.3512054681777954
Validation loss: 2.1371594129070157

Epoch: 6| Step: 12
Training loss: 2.509589672088623
Validation loss: 2.123829686513511

Epoch: 6| Step: 13
Training loss: 2.030299425125122
Validation loss: 2.1211453971042427

Epoch: 516| Step: 0
Training loss: 2.3763747215270996
Validation loss: 2.1411095280801096

Epoch: 6| Step: 1
Training loss: 2.1185312271118164
Validation loss: 2.1406297094078472

Epoch: 6| Step: 2
Training loss: 1.130595088005066
Validation loss: 2.133819854387673

Epoch: 6| Step: 3
Training loss: 1.6282813549041748
Validation loss: 2.139030155315194

Epoch: 6| Step: 4
Training loss: 1.7518216371536255
Validation loss: 2.1308214254276727

Epoch: 6| Step: 5
Training loss: 1.7225549221038818
Validation loss: 2.1328889144364225

Epoch: 6| Step: 6
Training loss: 3.1079916954040527
Validation loss: 2.124187610482657

Epoch: 6| Step: 7
Training loss: 2.6383609771728516
Validation loss: 2.1166796632992324

Epoch: 6| Step: 8
Training loss: 1.8729708194732666
Validation loss: 2.1202385323022

Epoch: 6| Step: 9
Training loss: 2.241319179534912
Validation loss: 2.1187376412012244

Epoch: 6| Step: 10
Training loss: 1.560486078262329
Validation loss: 2.125338080108807

Epoch: 6| Step: 11
Training loss: 1.3080759048461914
Validation loss: 2.117313790064986

Epoch: 6| Step: 12
Training loss: 1.6934864521026611
Validation loss: 2.083351025017359

Epoch: 6| Step: 13
Training loss: 1.7911720275878906
Validation loss: 2.1019127330472394

Epoch: 517| Step: 0
Training loss: 1.800432562828064
Validation loss: 2.0914948114784817

Epoch: 6| Step: 1
Training loss: 1.711681604385376
Validation loss: 2.0958099801053285

Epoch: 6| Step: 2
Training loss: 1.7436082363128662
Validation loss: 2.089636488627362

Epoch: 6| Step: 3
Training loss: 1.6191480159759521
Validation loss: 2.0760590773756786

Epoch: 6| Step: 4
Training loss: 2.2584025859832764
Validation loss: 2.085246744976249

Epoch: 6| Step: 5
Training loss: 2.015181064605713
Validation loss: 2.0889936454834475

Epoch: 6| Step: 6
Training loss: 1.8679654598236084
Validation loss: 2.1127759859126103

Epoch: 6| Step: 7
Training loss: 2.1457560062408447
Validation loss: 2.1169181741693968

Epoch: 6| Step: 8
Training loss: 2.0749778747558594
Validation loss: 2.1447313242061163

Epoch: 6| Step: 9
Training loss: 1.6767323017120361
Validation loss: 2.1316183100464525

Epoch: 6| Step: 10
Training loss: 1.7215214967727661
Validation loss: 2.141974062047979

Epoch: 6| Step: 11
Training loss: 2.461007595062256
Validation loss: 2.142887043696578

Epoch: 6| Step: 12
Training loss: 1.8052297830581665
Validation loss: 2.1489021765288485

Epoch: 6| Step: 13
Training loss: 2.145311117172241
Validation loss: 2.143152818884901

Epoch: 518| Step: 0
Training loss: 2.3740851879119873
Validation loss: 2.141997111740933

Epoch: 6| Step: 1
Training loss: 1.9696099758148193
Validation loss: 2.1217903449971187

Epoch: 6| Step: 2
Training loss: 2.480565309524536
Validation loss: 2.1288432921132734

Epoch: 6| Step: 3
Training loss: 1.6501902341842651
Validation loss: 2.10771006666204

Epoch: 6| Step: 4
Training loss: 2.2243752479553223
Validation loss: 2.121385120576428

Epoch: 6| Step: 5
Training loss: 1.9019155502319336
Validation loss: 2.1109595683313187

Epoch: 6| Step: 6
Training loss: 1.186028242111206
Validation loss: 2.1158829965899066

Epoch: 6| Step: 7
Training loss: 1.605881929397583
Validation loss: 2.113771273243812

Epoch: 6| Step: 8
Training loss: 1.5582033395767212
Validation loss: 2.1257974011923677

Epoch: 6| Step: 9
Training loss: 2.6206233501434326
Validation loss: 2.1189242165575743

Epoch: 6| Step: 10
Training loss: 2.521763801574707
Validation loss: 2.1388824370599564

Epoch: 6| Step: 11
Training loss: 1.5660080909729004
Validation loss: 2.1402153174082437

Epoch: 6| Step: 12
Training loss: 1.3732142448425293
Validation loss: 2.1461953860457226

Epoch: 6| Step: 13
Training loss: 1.881784200668335
Validation loss: 2.1275417714990597

Epoch: 519| Step: 0
Training loss: 1.6636378765106201
Validation loss: 2.1276328538053777

Epoch: 6| Step: 1
Training loss: 1.3972938060760498
Validation loss: 2.1234196565484487

Epoch: 6| Step: 2
Training loss: 2.3545918464660645
Validation loss: 2.1195944381016556

Epoch: 6| Step: 3
Training loss: 2.318134307861328
Validation loss: 2.1227630774180093

Epoch: 6| Step: 4
Training loss: 2.0166611671447754
Validation loss: 2.12321779804845

Epoch: 6| Step: 5
Training loss: 2.3408684730529785
Validation loss: 2.166952052424031

Epoch: 6| Step: 6
Training loss: 1.7343710660934448
Validation loss: 2.1431559439628356

Epoch: 6| Step: 7
Training loss: 0.7813278436660767
Validation loss: 2.1421287854512534

Epoch: 6| Step: 8
Training loss: 2.4879863262176514
Validation loss: 2.13612465448277

Epoch: 6| Step: 9
Training loss: 2.126946449279785
Validation loss: 2.1483635133312595

Epoch: 6| Step: 10
Training loss: 1.525325059890747
Validation loss: 2.1358206977126417

Epoch: 6| Step: 11
Training loss: 2.197699546813965
Validation loss: 2.1273096838305072

Epoch: 6| Step: 12
Training loss: 1.7356717586517334
Validation loss: 2.111332513952768

Epoch: 6| Step: 13
Training loss: 2.271794319152832
Validation loss: 2.14035322589259

Epoch: 520| Step: 0
Training loss: 1.9638841152191162
Validation loss: 2.114266513496317

Epoch: 6| Step: 1
Training loss: 2.005014657974243
Validation loss: 2.120489429402095

Epoch: 6| Step: 2
Training loss: 2.070916175842285
Validation loss: 2.1128694934229695

Epoch: 6| Step: 3
Training loss: 1.988896369934082
Validation loss: 2.100040085854069

Epoch: 6| Step: 4
Training loss: 1.843315601348877
Validation loss: 2.086269527353266

Epoch: 6| Step: 5
Training loss: 1.9744157791137695
Validation loss: 2.0766387024233417

Epoch: 6| Step: 6
Training loss: 1.8694498538970947
Validation loss: 2.0696515960078083

Epoch: 6| Step: 7
Training loss: 1.6375079154968262
Validation loss: 2.0923286868679907

Epoch: 6| Step: 8
Training loss: 1.3782848119735718
Validation loss: 2.0900431192049416

Epoch: 6| Step: 9
Training loss: 1.6567866802215576
Validation loss: 2.078927678446616

Epoch: 6| Step: 10
Training loss: 2.2021448612213135
Validation loss: 2.0994379981871574

Epoch: 6| Step: 11
Training loss: 2.182143449783325
Validation loss: 2.101911598636258

Epoch: 6| Step: 12
Training loss: 2.232541084289551
Validation loss: 2.094865791259273

Epoch: 6| Step: 13
Training loss: 1.7350972890853882
Validation loss: 2.1419501304626465

Epoch: 521| Step: 0
Training loss: 2.42587947845459
Validation loss: 2.129033068174957

Epoch: 6| Step: 1
Training loss: 2.3095669746398926
Validation loss: 2.133019067907846

Epoch: 6| Step: 2
Training loss: 1.7507569789886475
Validation loss: 2.1333093668824885

Epoch: 6| Step: 3
Training loss: 1.8327929973602295
Validation loss: 2.1084367870002665

Epoch: 6| Step: 4
Training loss: 1.567687749862671
Validation loss: 2.1139614094970045

Epoch: 6| Step: 5
Training loss: 2.3668839931488037
Validation loss: 2.098656277502737

Epoch: 6| Step: 6
Training loss: 1.317212462425232
Validation loss: 2.092094165022655

Epoch: 6| Step: 7
Training loss: 1.437866449356079
Validation loss: 2.117057869511266

Epoch: 6| Step: 8
Training loss: 2.582515001296997
Validation loss: 2.1179669031532864

Epoch: 6| Step: 9
Training loss: 1.6163403987884521
Validation loss: 2.112404495157221

Epoch: 6| Step: 10
Training loss: 1.8393853902816772
Validation loss: 2.103676333222338

Epoch: 6| Step: 11
Training loss: 1.8418384790420532
Validation loss: 2.116951198988063

Epoch: 6| Step: 12
Training loss: 2.0348377227783203
Validation loss: 2.107660687097939

Epoch: 6| Step: 13
Training loss: 1.7139832973480225
Validation loss: 2.1198745184047247

Epoch: 522| Step: 0
Training loss: 2.349952220916748
Validation loss: 2.1322441254892657

Epoch: 6| Step: 1
Training loss: 2.0079522132873535
Validation loss: 2.139798161804035

Epoch: 6| Step: 2
Training loss: 2.731809616088867
Validation loss: 2.146108629882977

Epoch: 6| Step: 3
Training loss: 1.7590843439102173
Validation loss: 2.165606637154856

Epoch: 6| Step: 4
Training loss: 1.9877147674560547
Validation loss: 2.1641809671155867

Epoch: 6| Step: 5
Training loss: 1.9795844554901123
Validation loss: 2.1817622210389827

Epoch: 6| Step: 6
Training loss: 1.6012120246887207
Validation loss: 2.1613947781183387

Epoch: 6| Step: 7
Training loss: 2.05350923538208
Validation loss: 2.14795123505336

Epoch: 6| Step: 8
Training loss: 2.534266233444214
Validation loss: 2.1505737702051797

Epoch: 6| Step: 9
Training loss: 1.5168116092681885
Validation loss: 2.1376706220770396

Epoch: 6| Step: 10
Training loss: 1.755110740661621
Validation loss: 2.139187115494923

Epoch: 6| Step: 11
Training loss: 1.5918612480163574
Validation loss: 2.120435933912954

Epoch: 6| Step: 12
Training loss: 1.7258734703063965
Validation loss: 2.1439241978429977

Epoch: 6| Step: 13
Training loss: 0.7564599514007568
Validation loss: 2.127270378092284

Epoch: 523| Step: 0
Training loss: 1.9729456901550293
Validation loss: 2.1202738079973447

Epoch: 6| Step: 1
Training loss: 1.6882866621017456
Validation loss: 2.118675688261627

Epoch: 6| Step: 2
Training loss: 1.9110628366470337
Validation loss: 2.1197707704318467

Epoch: 6| Step: 3
Training loss: 1.3914439678192139
Validation loss: 2.1059466049235356

Epoch: 6| Step: 4
Training loss: 1.4024605751037598
Validation loss: 2.1136050480668263

Epoch: 6| Step: 5
Training loss: 1.9472064971923828
Validation loss: 2.1177525827961583

Epoch: 6| Step: 6
Training loss: 2.155276298522949
Validation loss: 2.0993089932267384

Epoch: 6| Step: 7
Training loss: 2.1618337631225586
Validation loss: 2.096767303764179

Epoch: 6| Step: 8
Training loss: 2.388059616088867
Validation loss: 2.094946365202627

Epoch: 6| Step: 9
Training loss: 1.9497959613800049
Validation loss: 2.0876549700255036

Epoch: 6| Step: 10
Training loss: 1.2991509437561035
Validation loss: 2.0937820314079203

Epoch: 6| Step: 11
Training loss: 2.8576555252075195
Validation loss: 2.1028368806326263

Epoch: 6| Step: 12
Training loss: 1.8961920738220215
Validation loss: 2.1160211934838244

Epoch: 6| Step: 13
Training loss: 1.6008641719818115
Validation loss: 2.135470578747411

Epoch: 524| Step: 0
Training loss: 2.3291497230529785
Validation loss: 2.138699403373144

Epoch: 6| Step: 1
Training loss: 1.689835548400879
Validation loss: 2.1676557910057808

Epoch: 6| Step: 2
Training loss: 1.7846095561981201
Validation loss: 2.1377197773225847

Epoch: 6| Step: 3
Training loss: 2.226766586303711
Validation loss: 2.119315770364577

Epoch: 6| Step: 4
Training loss: 1.5711669921875
Validation loss: 2.110004291739515

Epoch: 6| Step: 5
Training loss: 2.0566694736480713
Validation loss: 2.106484429810637

Epoch: 6| Step: 6
Training loss: 1.6120054721832275
Validation loss: 2.077269228555823

Epoch: 6| Step: 7
Training loss: 1.9671865701675415
Validation loss: 2.0881332505133843

Epoch: 6| Step: 8
Training loss: 1.5650075674057007
Validation loss: 2.086078216952662

Epoch: 6| Step: 9
Training loss: 2.025744915008545
Validation loss: 2.091950862638412

Epoch: 6| Step: 10
Training loss: 2.31082820892334
Validation loss: 2.098842627258711

Epoch: 6| Step: 11
Training loss: 1.8891398906707764
Validation loss: 2.121945887483576

Epoch: 6| Step: 12
Training loss: 1.4023786783218384
Validation loss: 2.1150420647795483

Epoch: 6| Step: 13
Training loss: 2.784740924835205
Validation loss: 2.1303116301054597

Epoch: 525| Step: 0
Training loss: 2.6715192794799805
Validation loss: 2.126511166172643

Epoch: 6| Step: 1
Training loss: 2.0581045150756836
Validation loss: 2.1297948283533894

Epoch: 6| Step: 2
Training loss: 1.7168247699737549
Validation loss: 2.1300532766567764

Epoch: 6| Step: 3
Training loss: 1.8075937032699585
Validation loss: 2.10055560194036

Epoch: 6| Step: 4
Training loss: 2.252758026123047
Validation loss: 2.08843405272371

Epoch: 6| Step: 5
Training loss: 1.9265594482421875
Validation loss: 2.1020668142585346

Epoch: 6| Step: 6
Training loss: 1.8247822523117065
Validation loss: 2.1267647333042596

Epoch: 6| Step: 7
Training loss: 1.7738714218139648
Validation loss: 2.107919664793117

Epoch: 6| Step: 8
Training loss: 1.638728380203247
Validation loss: 2.1332770188649497

Epoch: 6| Step: 9
Training loss: 1.40812087059021
Validation loss: 2.125037972645093

Epoch: 6| Step: 10
Training loss: 1.814473032951355
Validation loss: 2.153133664079892

Epoch: 6| Step: 11
Training loss: 1.5788710117340088
Validation loss: 2.1133331893592753

Epoch: 6| Step: 12
Training loss: 2.2904629707336426
Validation loss: 2.094101030339477

Epoch: 6| Step: 13
Training loss: 1.8505223989486694
Validation loss: 2.099896564278551

Epoch: 526| Step: 0
Training loss: 2.502948045730591
Validation loss: 2.093980573838757

Epoch: 6| Step: 1
Training loss: 1.0990885496139526
Validation loss: 2.074014207368256

Epoch: 6| Step: 2
Training loss: 1.650120735168457
Validation loss: 2.0658432873346473

Epoch: 6| Step: 3
Training loss: 1.5225913524627686
Validation loss: 2.08318079158824

Epoch: 6| Step: 4
Training loss: 1.6287062168121338
Validation loss: 2.0869095786925285

Epoch: 6| Step: 5
Training loss: 2.2888824939727783
Validation loss: 2.1063102112021497

Epoch: 6| Step: 6
Training loss: 1.827344536781311
Validation loss: 2.1105825106302896

Epoch: 6| Step: 7
Training loss: 1.7292530536651611
Validation loss: 2.1225548226346254

Epoch: 6| Step: 8
Training loss: 2.2998595237731934
Validation loss: 2.1363097121638637

Epoch: 6| Step: 9
Training loss: 1.8114118576049805
Validation loss: 2.1060936732958724

Epoch: 6| Step: 10
Training loss: 2.3978142738342285
Validation loss: 2.122583376464023

Epoch: 6| Step: 11
Training loss: 1.8215649127960205
Validation loss: 2.1078669589052916

Epoch: 6| Step: 12
Training loss: 1.85476553440094
Validation loss: 2.104331301104638

Epoch: 6| Step: 13
Training loss: 2.5002026557922363
Validation loss: 2.106329156506446

Epoch: 527| Step: 0
Training loss: 1.8594228029251099
Validation loss: 2.091609395960326

Epoch: 6| Step: 1
Training loss: 1.5431993007659912
Validation loss: 2.106590937542659

Epoch: 6| Step: 2
Training loss: 2.3680009841918945
Validation loss: 2.087707575931344

Epoch: 6| Step: 3
Training loss: 2.5688483715057373
Validation loss: 2.0953965469073226

Epoch: 6| Step: 4
Training loss: 2.032292604446411
Validation loss: 2.1091978908866964

Epoch: 6| Step: 5
Training loss: 1.4216969013214111
Validation loss: 2.112777874033938

Epoch: 6| Step: 6
Training loss: 1.9389963150024414
Validation loss: 2.121325695386497

Epoch: 6| Step: 7
Training loss: 1.8035938739776611
Validation loss: 2.1097534113032843

Epoch: 6| Step: 8
Training loss: 2.0305228233337402
Validation loss: 2.1066018714699695

Epoch: 6| Step: 9
Training loss: 1.4957976341247559
Validation loss: 2.0917668675863617

Epoch: 6| Step: 10
Training loss: 2.6132094860076904
Validation loss: 2.0967518309111237

Epoch: 6| Step: 11
Training loss: 1.2897523641586304
Validation loss: 2.0925892809385895

Epoch: 6| Step: 12
Training loss: 1.6292519569396973
Validation loss: 2.1106017789533063

Epoch: 6| Step: 13
Training loss: 1.8952223062515259
Validation loss: 2.1283247906674623

Epoch: 528| Step: 0
Training loss: 1.4908421039581299
Validation loss: 2.1168011439743863

Epoch: 6| Step: 1
Training loss: 1.8969857692718506
Validation loss: 2.1348906537537933

Epoch: 6| Step: 2
Training loss: 1.8610639572143555
Validation loss: 2.1127962681554977

Epoch: 6| Step: 3
Training loss: 2.158519983291626
Validation loss: 2.0909837471541537

Epoch: 6| Step: 4
Training loss: 1.7797186374664307
Validation loss: 2.0595413061880294

Epoch: 6| Step: 5
Training loss: 1.6183080673217773
Validation loss: 2.0731863052614274

Epoch: 6| Step: 6
Training loss: 1.3353761434555054
Validation loss: 2.0865236251584944

Epoch: 6| Step: 7
Training loss: 1.678964614868164
Validation loss: 2.0954118108236663

Epoch: 6| Step: 8
Training loss: 1.835615634918213
Validation loss: 2.097740186158047

Epoch: 6| Step: 9
Training loss: 2.326878547668457
Validation loss: 2.1117606060479277

Epoch: 6| Step: 10
Training loss: 2.1784284114837646
Validation loss: 2.0967763982793337

Epoch: 6| Step: 11
Training loss: 2.030749797821045
Validation loss: 2.1069306776087773

Epoch: 6| Step: 12
Training loss: 2.6486387252807617
Validation loss: 2.083441580495527

Epoch: 6| Step: 13
Training loss: 1.7492578029632568
Validation loss: 2.084231997048983

Epoch: 529| Step: 0
Training loss: 2.020325183868408
Validation loss: 2.0904338359832764

Epoch: 6| Step: 1
Training loss: 1.8605272769927979
Validation loss: 2.0873367504407

Epoch: 6| Step: 2
Training loss: 1.8828907012939453
Validation loss: 2.1027287321705974

Epoch: 6| Step: 3
Training loss: 1.6304525136947632
Validation loss: 2.1172148040545884

Epoch: 6| Step: 4
Training loss: 1.614068865776062
Validation loss: 2.1401186040652695

Epoch: 6| Step: 5
Training loss: 1.8709213733673096
Validation loss: 2.14642830305202

Epoch: 6| Step: 6
Training loss: 1.1848055124282837
Validation loss: 2.1640145496655534

Epoch: 6| Step: 7
Training loss: 2.3523170948028564
Validation loss: 2.1501735871837986

Epoch: 6| Step: 8
Training loss: 2.2409088611602783
Validation loss: 2.129516419544015

Epoch: 6| Step: 9
Training loss: 2.229236125946045
Validation loss: 2.11448315394822

Epoch: 6| Step: 10
Training loss: 1.371415615081787
Validation loss: 2.0949794259122623

Epoch: 6| Step: 11
Training loss: 2.1784586906433105
Validation loss: 2.0711165397397933

Epoch: 6| Step: 12
Training loss: 1.8406744003295898
Validation loss: 2.0893179703784246

Epoch: 6| Step: 13
Training loss: 2.792872428894043
Validation loss: 2.066768438585343

Epoch: 530| Step: 0
Training loss: 1.6862995624542236
Validation loss: 2.0957701360025713

Epoch: 6| Step: 1
Training loss: 2.0871453285217285
Validation loss: 2.097377037489286

Epoch: 6| Step: 2
Training loss: 1.7892868518829346
Validation loss: 2.105336122615363

Epoch: 6| Step: 3
Training loss: 1.2817353010177612
Validation loss: 2.102925560807669

Epoch: 6| Step: 4
Training loss: 2.138740062713623
Validation loss: 2.120443176197749

Epoch: 6| Step: 5
Training loss: 1.9636842012405396
Validation loss: 2.0995450096745647

Epoch: 6| Step: 6
Training loss: 2.074624538421631
Validation loss: 2.1137095266772854

Epoch: 6| Step: 7
Training loss: 1.6858036518096924
Validation loss: 2.0810592430894093

Epoch: 6| Step: 8
Training loss: 2.1364431381225586
Validation loss: 2.095888788982104

Epoch: 6| Step: 9
Training loss: 2.1411919593811035
Validation loss: 2.1084857730455298

Epoch: 6| Step: 10
Training loss: 1.8490135669708252
Validation loss: 2.066418881057411

Epoch: 6| Step: 11
Training loss: 1.7787227630615234
Validation loss: 2.0877155411627983

Epoch: 6| Step: 12
Training loss: 2.146862745285034
Validation loss: 2.0825874677268406

Epoch: 6| Step: 13
Training loss: 1.695873737335205
Validation loss: 2.118565382496003

Epoch: 531| Step: 0
Training loss: 1.8294198513031006
Validation loss: 2.1447115508458947

Epoch: 6| Step: 1
Training loss: 1.976383090019226
Validation loss: 2.1563280808028353

Epoch: 6| Step: 2
Training loss: 1.674020767211914
Validation loss: 2.1705606240098194

Epoch: 6| Step: 3
Training loss: 2.4800524711608887
Validation loss: 2.17942242340375

Epoch: 6| Step: 4
Training loss: 1.7828508615493774
Validation loss: 2.163643898502473

Epoch: 6| Step: 5
Training loss: 2.224123954772949
Validation loss: 2.1543396621622066

Epoch: 6| Step: 6
Training loss: 1.2879910469055176
Validation loss: 2.12725769576206

Epoch: 6| Step: 7
Training loss: 1.6862338781356812
Validation loss: 2.109924216424265

Epoch: 6| Step: 8
Training loss: 2.1511974334716797
Validation loss: 2.109771059405419

Epoch: 6| Step: 9
Training loss: 1.859257698059082
Validation loss: 2.0818744885024203

Epoch: 6| Step: 10
Training loss: 1.9344063997268677
Validation loss: 2.0856850224156536

Epoch: 6| Step: 11
Training loss: 1.9577707052230835
Validation loss: 2.0872718108597623

Epoch: 6| Step: 12
Training loss: 1.5319422483444214
Validation loss: 2.090279850908505

Epoch: 6| Step: 13
Training loss: 2.2678728103637695
Validation loss: 2.075993214884112

Epoch: 532| Step: 0
Training loss: 1.6968847513198853
Validation loss: 2.1083907799054216

Epoch: 6| Step: 1
Training loss: 1.673378586769104
Validation loss: 2.095143457894684

Epoch: 6| Step: 2
Training loss: 1.8308440446853638
Validation loss: 2.109268585840861

Epoch: 6| Step: 3
Training loss: 2.120802879333496
Validation loss: 2.1030029045638217

Epoch: 6| Step: 4
Training loss: 2.027099847793579
Validation loss: 2.1055142879486084

Epoch: 6| Step: 5
Training loss: 2.1225879192352295
Validation loss: 2.0906521645925378

Epoch: 6| Step: 6
Training loss: 1.8833396434783936
Validation loss: 2.1025390201999294

Epoch: 6| Step: 7
Training loss: 1.6132190227508545
Validation loss: 2.0818971767220447

Epoch: 6| Step: 8
Training loss: 1.880922794342041
Validation loss: 2.091431966391943

Epoch: 6| Step: 9
Training loss: 1.3813227415084839
Validation loss: 2.1143960260575816

Epoch: 6| Step: 10
Training loss: 2.5813450813293457
Validation loss: 2.0929271969743954

Epoch: 6| Step: 11
Training loss: 1.62148118019104
Validation loss: 2.1345423959916636

Epoch: 6| Step: 12
Training loss: 2.3890342712402344
Validation loss: 2.136222388154717

Epoch: 6| Step: 13
Training loss: 1.3944644927978516
Validation loss: 2.1243372732593166

Epoch: 533| Step: 0
Training loss: 2.465679168701172
Validation loss: 2.1157681506167174

Epoch: 6| Step: 1
Training loss: 1.978463888168335
Validation loss: 2.098821178559334

Epoch: 6| Step: 2
Training loss: 1.2103514671325684
Validation loss: 2.1154362668273268

Epoch: 6| Step: 3
Training loss: 1.6077053546905518
Validation loss: 2.141246621326734

Epoch: 6| Step: 4
Training loss: 2.1371657848358154
Validation loss: 2.134984608619444

Epoch: 6| Step: 5
Training loss: 2.253939151763916
Validation loss: 2.1225276390711465

Epoch: 6| Step: 6
Training loss: 1.443080186843872
Validation loss: 2.0999535258098314

Epoch: 6| Step: 7
Training loss: 1.7045905590057373
Validation loss: 2.097998583188621

Epoch: 6| Step: 8
Training loss: 2.4252185821533203
Validation loss: 2.0894335739074217

Epoch: 6| Step: 9
Training loss: 2.0539679527282715
Validation loss: 2.089587302618129

Epoch: 6| Step: 10
Training loss: 1.721132755279541
Validation loss: 2.0864295523653746

Epoch: 6| Step: 11
Training loss: 1.752875566482544
Validation loss: 2.079019263226499

Epoch: 6| Step: 12
Training loss: 1.5480222702026367
Validation loss: 2.0888863391773675

Epoch: 6| Step: 13
Training loss: 1.9560928344726562
Validation loss: 2.0928549484540055

Epoch: 534| Step: 0
Training loss: 2.2279326915740967
Validation loss: 2.109885641323623

Epoch: 6| Step: 1
Training loss: 1.2682535648345947
Validation loss: 2.147809159371161

Epoch: 6| Step: 2
Training loss: 2.815047025680542
Validation loss: 2.1543249622468026

Epoch: 6| Step: 3
Training loss: 2.2048380374908447
Validation loss: 2.1379161906498734

Epoch: 6| Step: 4
Training loss: 2.36238431930542
Validation loss: 2.116211568155596

Epoch: 6| Step: 5
Training loss: 2.782902717590332
Validation loss: 2.095638373846649

Epoch: 6| Step: 6
Training loss: 1.3580410480499268
Validation loss: 2.10221803316506

Epoch: 6| Step: 7
Training loss: 1.2806414365768433
Validation loss: 2.081882776752595

Epoch: 6| Step: 8
Training loss: 1.435246229171753
Validation loss: 2.097174875197872

Epoch: 6| Step: 9
Training loss: 1.5488853454589844
Validation loss: 2.1025343492466915

Epoch: 6| Step: 10
Training loss: 2.552687406539917
Validation loss: 2.11134902123482

Epoch: 6| Step: 11
Training loss: 1.544264316558838
Validation loss: 2.1270749286938737

Epoch: 6| Step: 12
Training loss: 1.4610189199447632
Validation loss: 2.143071907822804

Epoch: 6| Step: 13
Training loss: 1.2326579093933105
Validation loss: 2.1394668779065533

Epoch: 535| Step: 0
Training loss: 2.7964062690734863
Validation loss: 2.133138482288648

Epoch: 6| Step: 1
Training loss: 1.574454665184021
Validation loss: 2.110324026435934

Epoch: 6| Step: 2
Training loss: 1.6788251399993896
Validation loss: 2.104406782375869

Epoch: 6| Step: 3
Training loss: 1.4685266017913818
Validation loss: 2.073146025339762

Epoch: 6| Step: 4
Training loss: 1.1089726686477661
Validation loss: 2.077382354326146

Epoch: 6| Step: 5
Training loss: 2.376816749572754
Validation loss: 2.064937404406968

Epoch: 6| Step: 6
Training loss: 1.7502446174621582
Validation loss: 2.0554044015945925

Epoch: 6| Step: 7
Training loss: 1.8031706809997559
Validation loss: 2.067635980985498

Epoch: 6| Step: 8
Training loss: 1.7574915885925293
Validation loss: 2.079681534920969

Epoch: 6| Step: 9
Training loss: 2.686763286590576
Validation loss: 2.0880760838908534

Epoch: 6| Step: 10
Training loss: 1.6171138286590576
Validation loss: 2.1136884958513322

Epoch: 6| Step: 11
Training loss: 1.8844696283340454
Validation loss: 2.1331072417638635

Epoch: 6| Step: 12
Training loss: 1.4538235664367676
Validation loss: 2.151342994423323

Epoch: 6| Step: 13
Training loss: 2.763920783996582
Validation loss: 2.164753681869917

Epoch: 536| Step: 0
Training loss: 1.795055866241455
Validation loss: 2.1577395021274524

Epoch: 6| Step: 1
Training loss: 2.568019390106201
Validation loss: 2.1432310547879947

Epoch: 6| Step: 2
Training loss: 1.403085470199585
Validation loss: 2.1524422707096225

Epoch: 6| Step: 3
Training loss: 1.2074295282363892
Validation loss: 2.1120660715205695

Epoch: 6| Step: 4
Training loss: 1.7845349311828613
Validation loss: 2.0825228511646228

Epoch: 6| Step: 5
Training loss: 1.4323313236236572
Validation loss: 2.0682510278558217

Epoch: 6| Step: 6
Training loss: 2.6985208988189697
Validation loss: 2.0859668818853234

Epoch: 6| Step: 7
Training loss: 2.127087116241455
Validation loss: 2.0738605478758454

Epoch: 6| Step: 8
Training loss: 2.048236131668091
Validation loss: 2.0718386839794856

Epoch: 6| Step: 9
Training loss: 1.2158328294754028
Validation loss: 2.1178116824037287

Epoch: 6| Step: 10
Training loss: 1.2276288270950317
Validation loss: 2.126580851052397

Epoch: 6| Step: 11
Training loss: 2.28019118309021
Validation loss: 2.131685967086464

Epoch: 6| Step: 12
Training loss: 2.8940348625183105
Validation loss: 2.142426429256316

Epoch: 6| Step: 13
Training loss: 1.7560862302780151
Validation loss: 2.1393237908681235

Epoch: 537| Step: 0
Training loss: 1.9692485332489014
Validation loss: 2.1426814345903296

Epoch: 6| Step: 1
Training loss: 1.4412994384765625
Validation loss: 2.105533633180844

Epoch: 6| Step: 2
Training loss: 1.3000102043151855
Validation loss: 2.087568680445353

Epoch: 6| Step: 3
Training loss: 1.5262287855148315
Validation loss: 2.069066265577911

Epoch: 6| Step: 4
Training loss: 2.3506393432617188
Validation loss: 2.096673914181289

Epoch: 6| Step: 5
Training loss: 2.1272292137145996
Validation loss: 2.0554089366748767

Epoch: 6| Step: 6
Training loss: 1.2180638313293457
Validation loss: 2.0896617161330355

Epoch: 6| Step: 7
Training loss: 2.103158712387085
Validation loss: 2.089071314821961

Epoch: 6| Step: 8
Training loss: 1.9078710079193115
Validation loss: 2.0800751204131753

Epoch: 6| Step: 9
Training loss: 2.1885733604431152
Validation loss: 2.0727285902987242

Epoch: 6| Step: 10
Training loss: 2.3264822959899902
Validation loss: 2.065556578738715

Epoch: 6| Step: 11
Training loss: 1.9672460556030273
Validation loss: 2.0957757273027973

Epoch: 6| Step: 12
Training loss: 1.7505282163619995
Validation loss: 2.101962794539749

Epoch: 6| Step: 13
Training loss: 2.2046897411346436
Validation loss: 2.1272574957980903

Epoch: 538| Step: 0
Training loss: 1.8157193660736084
Validation loss: 2.138569631884175

Epoch: 6| Step: 1
Training loss: 2.653208017349243
Validation loss: 2.128763355234618

Epoch: 6| Step: 2
Training loss: 2.169611930847168
Validation loss: 2.1099766326206986

Epoch: 6| Step: 3
Training loss: 2.3515093326568604
Validation loss: 2.0980749950614026

Epoch: 6| Step: 4
Training loss: 1.2828235626220703
Validation loss: 2.087521022365939

Epoch: 6| Step: 5
Training loss: 2.006620407104492
Validation loss: 2.071012514893727

Epoch: 6| Step: 6
Training loss: 2.099310874938965
Validation loss: 2.0735849641984507

Epoch: 6| Step: 7
Training loss: 2.0414280891418457
Validation loss: 2.085956536313539

Epoch: 6| Step: 8
Training loss: 1.5641186237335205
Validation loss: 2.096846775342059

Epoch: 6| Step: 9
Training loss: 1.647869348526001
Validation loss: 2.0998756680437314

Epoch: 6| Step: 10
Training loss: 1.7518281936645508
Validation loss: 2.105684039413288

Epoch: 6| Step: 11
Training loss: 1.4241840839385986
Validation loss: 2.142405747085489

Epoch: 6| Step: 12
Training loss: 1.7467247247695923
Validation loss: 2.1325424819864254

Epoch: 6| Step: 13
Training loss: 1.6991852521896362
Validation loss: 2.14707943700975

Epoch: 539| Step: 0
Training loss: 2.0659992694854736
Validation loss: 2.1535930966818206

Epoch: 6| Step: 1
Training loss: 1.8884036540985107
Validation loss: 2.1444312346878873

Epoch: 6| Step: 2
Training loss: 2.090999126434326
Validation loss: 2.1442074519331737

Epoch: 6| Step: 3
Training loss: 1.814581036567688
Validation loss: 2.1203868414766047

Epoch: 6| Step: 4
Training loss: 1.6726223230361938
Validation loss: 2.106910946548626

Epoch: 6| Step: 5
Training loss: 2.093745708465576
Validation loss: 2.1307857805682766

Epoch: 6| Step: 6
Training loss: 1.5959184169769287
Validation loss: 2.1124514405445387

Epoch: 6| Step: 7
Training loss: 1.8444037437438965
Validation loss: 2.1095931709453626

Epoch: 6| Step: 8
Training loss: 1.9737138748168945
Validation loss: 2.091490335361932

Epoch: 6| Step: 9
Training loss: 1.9896868467330933
Validation loss: 2.109659451310353

Epoch: 6| Step: 10
Training loss: 1.8941938877105713
Validation loss: 2.0895240640127533

Epoch: 6| Step: 11
Training loss: 1.6929426193237305
Validation loss: 2.104351338519845

Epoch: 6| Step: 12
Training loss: 2.1581757068634033
Validation loss: 2.1096009080128004

Epoch: 6| Step: 13
Training loss: 0.936992883682251
Validation loss: 2.131077358799596

Epoch: 540| Step: 0
Training loss: 1.7819743156433105
Validation loss: 2.109715897549865

Epoch: 6| Step: 1
Training loss: 2.4085841178894043
Validation loss: 2.10964887116545

Epoch: 6| Step: 2
Training loss: 2.354811906814575
Validation loss: 2.1158599648424374

Epoch: 6| Step: 3
Training loss: 2.279867172241211
Validation loss: 2.1180253977416665

Epoch: 6| Step: 4
Training loss: 1.8151155710220337
Validation loss: 2.0965301605962936

Epoch: 6| Step: 5
Training loss: 1.2392033338546753
Validation loss: 2.0861173598997054

Epoch: 6| Step: 6
Training loss: 1.5379120111465454
Validation loss: 2.0828853602050454

Epoch: 6| Step: 7
Training loss: 2.079533338546753
Validation loss: 2.076748025032782

Epoch: 6| Step: 8
Training loss: 1.4934401512145996
Validation loss: 2.0855268765521306

Epoch: 6| Step: 9
Training loss: 1.7363882064819336
Validation loss: 2.0897671663632957

Epoch: 6| Step: 10
Training loss: 2.1775035858154297
Validation loss: 2.0987680547980854

Epoch: 6| Step: 11
Training loss: 1.8114409446716309
Validation loss: 2.126745787999963

Epoch: 6| Step: 12
Training loss: 1.7225029468536377
Validation loss: 2.1253268693083074

Epoch: 6| Step: 13
Training loss: 1.4930784702301025
Validation loss: 2.147856863596106

Epoch: 541| Step: 0
Training loss: 1.4676647186279297
Validation loss: 2.1492389658445954

Epoch: 6| Step: 1
Training loss: 1.9391852617263794
Validation loss: 2.1482315730023127

Epoch: 6| Step: 2
Training loss: 1.5924521684646606
Validation loss: 2.1248374498018654

Epoch: 6| Step: 3
Training loss: 1.4962830543518066
Validation loss: 2.1130784147529194

Epoch: 6| Step: 4
Training loss: 2.153041362762451
Validation loss: 2.1048321313755487

Epoch: 6| Step: 5
Training loss: 1.8485107421875
Validation loss: 2.1018743899560746

Epoch: 6| Step: 6
Training loss: 2.2906417846679688
Validation loss: 2.075855255126953

Epoch: 6| Step: 7
Training loss: 2.248544216156006
Validation loss: 2.0792315467711417

Epoch: 6| Step: 8
Training loss: 1.4196133613586426
Validation loss: 2.099861334728938

Epoch: 6| Step: 9
Training loss: 1.9034748077392578
Validation loss: 2.0880531841708767

Epoch: 6| Step: 10
Training loss: 1.658313512802124
Validation loss: 2.0811316326100338

Epoch: 6| Step: 11
Training loss: 1.8956148624420166
Validation loss: 2.1107441814996863

Epoch: 6| Step: 12
Training loss: 1.9936879873275757
Validation loss: 2.109175907668247

Epoch: 6| Step: 13
Training loss: 2.1840927600860596
Validation loss: 2.130290549288514

Epoch: 542| Step: 0
Training loss: 2.2348403930664062
Validation loss: 2.138517097760272

Epoch: 6| Step: 1
Training loss: 1.5631945133209229
Validation loss: 2.147565512246983

Epoch: 6| Step: 2
Training loss: 1.1052613258361816
Validation loss: 2.1336169806859826

Epoch: 6| Step: 3
Training loss: 1.9177801609039307
Validation loss: 2.1031148933595225

Epoch: 6| Step: 4
Training loss: 1.7894114255905151
Validation loss: 2.1285239317083873

Epoch: 6| Step: 5
Training loss: 1.3316841125488281
Validation loss: 2.10733473941844

Epoch: 6| Step: 6
Training loss: 2.350874423980713
Validation loss: 2.1103478170210317

Epoch: 6| Step: 7
Training loss: 1.75816011428833
Validation loss: 2.1125184002742974

Epoch: 6| Step: 8
Training loss: 2.2644875049591064
Validation loss: 2.0923686745346233

Epoch: 6| Step: 9
Training loss: 1.709085464477539
Validation loss: 2.0846722843826457

Epoch: 6| Step: 10
Training loss: 2.2210845947265625
Validation loss: 2.1086508535569712

Epoch: 6| Step: 11
Training loss: 1.5560176372528076
Validation loss: 2.100573785843388

Epoch: 6| Step: 12
Training loss: 2.528019428253174
Validation loss: 2.095841061684393

Epoch: 6| Step: 13
Training loss: 1.56374990940094
Validation loss: 2.08044929786395

Epoch: 543| Step: 0
Training loss: 2.151461601257324
Validation loss: 2.127838867966847

Epoch: 6| Step: 1
Training loss: 1.270242691040039
Validation loss: 2.1533125523597962

Epoch: 6| Step: 2
Training loss: 2.412334442138672
Validation loss: 2.1593759136815227

Epoch: 6| Step: 3
Training loss: 1.4016648530960083
Validation loss: 2.1654572973969164

Epoch: 6| Step: 4
Training loss: 2.0140390396118164
Validation loss: 2.169949852010255

Epoch: 6| Step: 5
Training loss: 2.594208002090454
Validation loss: 2.1251115568222536

Epoch: 6| Step: 6
Training loss: 1.649972677230835
Validation loss: 2.0778524824368056

Epoch: 6| Step: 7
Training loss: 0.9915580749511719
Validation loss: 2.064690512995566

Epoch: 6| Step: 8
Training loss: 1.7899441719055176
Validation loss: 2.087184521459764

Epoch: 6| Step: 9
Training loss: 2.1248669624328613
Validation loss: 2.0737587482698503

Epoch: 6| Step: 10
Training loss: 2.6673810482025146
Validation loss: 2.0685667389182636

Epoch: 6| Step: 11
Training loss: 1.6781365871429443
Validation loss: 2.0746798284592165

Epoch: 6| Step: 12
Training loss: 1.76986825466156
Validation loss: 2.068982824202507

Epoch: 6| Step: 13
Training loss: 1.2750157117843628
Validation loss: 2.097098840180264

Epoch: 544| Step: 0
Training loss: 1.598518967628479
Validation loss: 2.0909900191009685

Epoch: 6| Step: 1
Training loss: 1.4617211818695068
Validation loss: 2.084763132115846

Epoch: 6| Step: 2
Training loss: 1.376764178276062
Validation loss: 2.1171791784224974

Epoch: 6| Step: 3
Training loss: 2.1792664527893066
Validation loss: 2.1155441640525736

Epoch: 6| Step: 4
Training loss: 1.7023966312408447
Validation loss: 2.12501367445915

Epoch: 6| Step: 5
Training loss: 1.8603832721710205
Validation loss: 2.137389736790811

Epoch: 6| Step: 6
Training loss: 2.4586539268493652
Validation loss: 2.1236181054064023

Epoch: 6| Step: 7
Training loss: 2.1230831146240234
Validation loss: 2.1420683771051388

Epoch: 6| Step: 8
Training loss: 1.5746887922286987
Validation loss: 2.126814526896323

Epoch: 6| Step: 9
Training loss: 2.5933163166046143
Validation loss: 2.1116629710761448

Epoch: 6| Step: 10
Training loss: 1.8240103721618652
Validation loss: 2.1111071058498916

Epoch: 6| Step: 11
Training loss: 1.3256242275238037
Validation loss: 2.1218009930784985

Epoch: 6| Step: 12
Training loss: 2.214524507522583
Validation loss: 2.099883146183465

Epoch: 6| Step: 13
Training loss: 1.1971583366394043
Validation loss: 2.098106817532611

Epoch: 545| Step: 0
Training loss: 2.01399564743042
Validation loss: 2.096744288680374

Epoch: 6| Step: 1
Training loss: 2.4609692096710205
Validation loss: 2.090987383037485

Epoch: 6| Step: 2
Training loss: 1.8494755029678345
Validation loss: 2.0966991865506737

Epoch: 6| Step: 3
Training loss: 2.12180757522583
Validation loss: 2.1030152805389895

Epoch: 6| Step: 4
Training loss: 1.8140909671783447
Validation loss: 2.094120094853063

Epoch: 6| Step: 5
Training loss: 1.4051151275634766
Validation loss: 2.1202351688056864

Epoch: 6| Step: 6
Training loss: 1.8655123710632324
Validation loss: 2.1176532494124545

Epoch: 6| Step: 7
Training loss: 1.6480247974395752
Validation loss: 2.1062786271495204

Epoch: 6| Step: 8
Training loss: 1.8924593925476074
Validation loss: 2.1116868539523055

Epoch: 6| Step: 9
Training loss: 1.9129387140274048
Validation loss: 2.12499402928096

Epoch: 6| Step: 10
Training loss: 1.2968696355819702
Validation loss: 2.1011172315125823

Epoch: 6| Step: 11
Training loss: 1.4651856422424316
Validation loss: 2.096108962130803

Epoch: 6| Step: 12
Training loss: 2.1531639099121094
Validation loss: 2.109166047906363

Epoch: 6| Step: 13
Training loss: 1.7708871364593506
Validation loss: 2.1060904636177966

Epoch: 546| Step: 0
Training loss: 2.227987289428711
Validation loss: 2.101272788099063

Epoch: 6| Step: 1
Training loss: 1.973844289779663
Validation loss: 2.1019701791065994

Epoch: 6| Step: 2
Training loss: 2.2221274375915527
Validation loss: 2.0906556011528097

Epoch: 6| Step: 3
Training loss: 2.095271110534668
Validation loss: 2.0999615359049972

Epoch: 6| Step: 4
Training loss: 1.7559680938720703
Validation loss: 2.1108763371744463

Epoch: 6| Step: 5
Training loss: 1.5498945713043213
Validation loss: 2.0950966265893753

Epoch: 6| Step: 6
Training loss: 1.5489213466644287
Validation loss: 2.1141561564578804

Epoch: 6| Step: 7
Training loss: 2.111968517303467
Validation loss: 2.1314159490728892

Epoch: 6| Step: 8
Training loss: 2.040886402130127
Validation loss: 2.135519112310102

Epoch: 6| Step: 9
Training loss: 2.1921215057373047
Validation loss: 2.123862594686529

Epoch: 6| Step: 10
Training loss: 1.9931353330612183
Validation loss: 2.117321575841596

Epoch: 6| Step: 11
Training loss: 1.4690264463424683
Validation loss: 2.1117040931537585

Epoch: 6| Step: 12
Training loss: 1.366300106048584
Validation loss: 2.1149632879482803

Epoch: 6| Step: 13
Training loss: 0.5793440937995911
Validation loss: 2.128723382949829

Epoch: 547| Step: 0
Training loss: 1.5769156217575073
Validation loss: 2.16000469141109

Epoch: 6| Step: 1
Training loss: 1.0475552082061768
Validation loss: 2.1534742578383415

Epoch: 6| Step: 2
Training loss: 1.2733919620513916
Validation loss: 2.1569362455798733

Epoch: 6| Step: 3
Training loss: 1.3969967365264893
Validation loss: 2.1288217831683416

Epoch: 6| Step: 4
Training loss: 2.80450701713562
Validation loss: 2.1166123267143004

Epoch: 6| Step: 5
Training loss: 2.4353384971618652
Validation loss: 2.0931394856463195

Epoch: 6| Step: 6
Training loss: 1.778071403503418
Validation loss: 2.106696859482796

Epoch: 6| Step: 7
Training loss: 2.407017469406128
Validation loss: 2.0980689551240657

Epoch: 6| Step: 8
Training loss: 1.3288167715072632
Validation loss: 2.0884316223923878

Epoch: 6| Step: 9
Training loss: 1.6739422082901
Validation loss: 2.0961680399474276

Epoch: 6| Step: 10
Training loss: 2.1846790313720703
Validation loss: 2.1103386558512205

Epoch: 6| Step: 11
Training loss: 2.2125372886657715
Validation loss: 2.1074891398029942

Epoch: 6| Step: 12
Training loss: 1.7975937128067017
Validation loss: 2.1403966155103458

Epoch: 6| Step: 13
Training loss: 1.8556580543518066
Validation loss: 2.1273854624840522

Epoch: 548| Step: 0
Training loss: 1.265386700630188
Validation loss: 2.1292985716173725

Epoch: 6| Step: 1
Training loss: 1.698805570602417
Validation loss: 2.115812563127087

Epoch: 6| Step: 2
Training loss: 2.280534267425537
Validation loss: 2.0928255434959167

Epoch: 6| Step: 3
Training loss: 2.2201595306396484
Validation loss: 2.08577254767059

Epoch: 6| Step: 4
Training loss: 2.108252763748169
Validation loss: 2.073614925466558

Epoch: 6| Step: 5
Training loss: 1.7344104051589966
Validation loss: 2.073215789692376

Epoch: 6| Step: 6
Training loss: 1.780950903892517
Validation loss: 2.076893678275488

Epoch: 6| Step: 7
Training loss: 2.004775047302246
Validation loss: 2.0672526744104203

Epoch: 6| Step: 8
Training loss: 1.8256686925888062
Validation loss: 2.073102815176851

Epoch: 6| Step: 9
Training loss: 1.5050857067108154
Validation loss: 2.0635706660568074

Epoch: 6| Step: 10
Training loss: 1.725926160812378
Validation loss: 2.0941743722525974

Epoch: 6| Step: 11
Training loss: 1.9888546466827393
Validation loss: 2.127607378908383

Epoch: 6| Step: 12
Training loss: 1.5959641933441162
Validation loss: 2.12054689468876

Epoch: 6| Step: 13
Training loss: 1.9875719547271729
Validation loss: 2.1324378469938874

Epoch: 549| Step: 0
Training loss: 1.3602538108825684
Validation loss: 2.174196921369081

Epoch: 6| Step: 1
Training loss: 1.4743783473968506
Validation loss: 2.146130202918924

Epoch: 6| Step: 2
Training loss: 1.224578619003296
Validation loss: 2.143064579656047

Epoch: 6| Step: 3
Training loss: 1.2380905151367188
Validation loss: 2.1054827423505884

Epoch: 6| Step: 4
Training loss: 2.2204394340515137
Validation loss: 2.073217233022054

Epoch: 6| Step: 5
Training loss: 1.51336669921875
Validation loss: 2.0911236181054065

Epoch: 6| Step: 6
Training loss: 1.9607983827590942
Validation loss: 2.075701893016856

Epoch: 6| Step: 7
Training loss: 2.264444351196289
Validation loss: 2.0769148283107306

Epoch: 6| Step: 8
Training loss: 1.620102882385254
Validation loss: 2.0793049514934583

Epoch: 6| Step: 9
Training loss: 2.784653425216675
Validation loss: 2.080386975760101

Epoch: 6| Step: 10
Training loss: 1.943644642829895
Validation loss: 2.0947125214402393

Epoch: 6| Step: 11
Training loss: 2.096273183822632
Validation loss: 2.099962075551351

Epoch: 6| Step: 12
Training loss: 1.7404747009277344
Validation loss: 2.112359636573381

Epoch: 6| Step: 13
Training loss: 2.3172714710235596
Validation loss: 2.1105006946030485

Epoch: 550| Step: 0
Training loss: 2.3488762378692627
Validation loss: 2.1035979627281107

Epoch: 6| Step: 1
Training loss: 1.7704541683197021
Validation loss: 2.104990282366353

Epoch: 6| Step: 2
Training loss: 1.6021010875701904
Validation loss: 2.071282086833831

Epoch: 6| Step: 3
Training loss: 2.497286558151245
Validation loss: 2.1053370173259447

Epoch: 6| Step: 4
Training loss: 1.6391713619232178
Validation loss: 2.1034723366460493

Epoch: 6| Step: 5
Training loss: 2.0651021003723145
Validation loss: 2.089287022108673

Epoch: 6| Step: 6
Training loss: 1.5618343353271484
Validation loss: 2.097087945989383

Epoch: 6| Step: 7
Training loss: 1.9786365032196045
Validation loss: 2.09032339947198

Epoch: 6| Step: 8
Training loss: 2.1341612339019775
Validation loss: 2.0807032277507167

Epoch: 6| Step: 9
Training loss: 1.0665173530578613
Validation loss: 2.100817964922997

Epoch: 6| Step: 10
Training loss: 1.9183502197265625
Validation loss: 2.1010077435483216

Epoch: 6| Step: 11
Training loss: 1.6384376287460327
Validation loss: 2.1028098752421718

Epoch: 6| Step: 12
Training loss: 1.4930355548858643
Validation loss: 2.084200777033324

Epoch: 6| Step: 13
Training loss: 1.8518660068511963
Validation loss: 2.1153387741375993

Testing loss: 2.3120257589552136
