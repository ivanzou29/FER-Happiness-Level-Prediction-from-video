Epoch: 1| Step: 0
Training loss: 6.6336613304030205
Validation loss: 5.796573633846383

Epoch: 6| Step: 1
Training loss: 5.448628755302599
Validation loss: 5.791239407173909

Epoch: 6| Step: 2
Training loss: 6.601603238132439
Validation loss: 5.78530020526149

Epoch: 6| Step: 3
Training loss: 5.8207483320462785
Validation loss: 5.779710348568406

Epoch: 6| Step: 4
Training loss: 6.111668929255746
Validation loss: 5.774053559250794

Epoch: 6| Step: 5
Training loss: 5.426628381717484
Validation loss: 5.768580990672448

Epoch: 6| Step: 6
Training loss: 5.275614965669046
Validation loss: 5.762604086188594

Epoch: 6| Step: 7
Training loss: 5.3638630306270985
Validation loss: 5.756359072345933

Epoch: 6| Step: 8
Training loss: 6.343692271904825
Validation loss: 5.750983572750802

Epoch: 6| Step: 9
Training loss: 6.444742517410813
Validation loss: 5.745286651353902

Epoch: 6| Step: 10
Training loss: 5.817945657077004
Validation loss: 5.738830114393622

Epoch: 6| Step: 11
Training loss: 4.365369606056897
Validation loss: 5.732616740547933

Epoch: 6| Step: 12
Training loss: 5.179871062511418
Validation loss: 5.726009579974833

Epoch: 6| Step: 13
Training loss: 5.9235399467285
Validation loss: 5.719243834823513

Epoch: 2| Step: 0
Training loss: 6.030362553111766
Validation loss: 5.712068009541281

Epoch: 6| Step: 1
Training loss: 5.732197943347626
Validation loss: 5.705261438049395

Epoch: 6| Step: 2
Training loss: 3.4913533897948
Validation loss: 5.697415015530167

Epoch: 6| Step: 3
Training loss: 5.802987467132871
Validation loss: 5.689895426538249

Epoch: 6| Step: 4
Training loss: 6.006791403798704
Validation loss: 5.681307113289807

Epoch: 6| Step: 5
Training loss: 5.382482953219566
Validation loss: 5.6722665505429415

Epoch: 6| Step: 6
Training loss: 6.140184537121205
Validation loss: 5.663607786354077

Epoch: 6| Step: 7
Training loss: 6.213297077831752
Validation loss: 5.653277920571155

Epoch: 6| Step: 8
Training loss: 6.560119487790737
Validation loss: 5.643308519595312

Epoch: 6| Step: 9
Training loss: 5.400368020974394
Validation loss: 5.632281510165529

Epoch: 6| Step: 10
Training loss: 4.589544953705114
Validation loss: 5.6210291073744525

Epoch: 6| Step: 11
Training loss: 6.2095775338918235
Validation loss: 5.609570156640644

Epoch: 6| Step: 12
Training loss: 5.846124013832363
Validation loss: 5.596750548723175

Epoch: 6| Step: 13
Training loss: 5.521295760839307
Validation loss: 5.585056040390131

Epoch: 3| Step: 0
Training loss: 5.813234016258352
Validation loss: 5.572237569768965

Epoch: 6| Step: 1
Training loss: 6.003403016483261
Validation loss: 5.558233108843157

Epoch: 6| Step: 2
Training loss: 6.5214580525075245
Validation loss: 5.543843958909405

Epoch: 6| Step: 3
Training loss: 5.3840056095065725
Validation loss: 5.529626050698991

Epoch: 6| Step: 4
Training loss: 4.6297133888862305
Validation loss: 5.513598628327314

Epoch: 6| Step: 5
Training loss: 5.17737851238424
Validation loss: 5.49793178046132

Epoch: 6| Step: 6
Training loss: 4.056753466473424
Validation loss: 5.482248126713116

Epoch: 6| Step: 7
Training loss: 5.704304445143234
Validation loss: 5.466992688955742

Epoch: 6| Step: 8
Training loss: 5.158828368131269
Validation loss: 5.450093400841068

Epoch: 6| Step: 9
Training loss: 5.920685419664099
Validation loss: 5.432509747555389

Epoch: 6| Step: 10
Training loss: 5.720730798093703
Validation loss: 5.415385070840454

Epoch: 6| Step: 11
Training loss: 5.509607420296046
Validation loss: 5.396005134668073

Epoch: 6| Step: 12
Training loss: 5.90197599263804
Validation loss: 5.377976925062446

Epoch: 6| Step: 13
Training loss: 5.141017168385529
Validation loss: 5.3587537788321855

Epoch: 4| Step: 0
Training loss: 5.68504028789165
Validation loss: 5.338434916663784

Epoch: 6| Step: 1
Training loss: 4.537742015595163
Validation loss: 5.3188459680736635

Epoch: 6| Step: 2
Training loss: 4.978878039476607
Validation loss: 5.297630752476541

Epoch: 6| Step: 3
Training loss: 5.270329668710918
Validation loss: 5.276673813567725

Epoch: 6| Step: 4
Training loss: 4.617334766911692
Validation loss: 5.255564464073109

Epoch: 6| Step: 5
Training loss: 5.847840534942718
Validation loss: 5.233861652609117

Epoch: 6| Step: 6
Training loss: 5.5590034382139235
Validation loss: 5.209665557130068

Epoch: 6| Step: 7
Training loss: 5.563633492526279
Validation loss: 5.1857471749114445

Epoch: 6| Step: 8
Training loss: 4.871811043819299
Validation loss: 5.160693709759198

Epoch: 6| Step: 9
Training loss: 5.208528845614249
Validation loss: 5.137666092765061

Epoch: 6| Step: 10
Training loss: 5.1042660242907125
Validation loss: 5.1112604178874195

Epoch: 6| Step: 11
Training loss: 5.484837873874263
Validation loss: 5.086832726494545

Epoch: 6| Step: 12
Training loss: 5.003860890334028
Validation loss: 5.060475015201492

Epoch: 6| Step: 13
Training loss: 5.769567614771993
Validation loss: 5.034989328094169

Epoch: 5| Step: 0
Training loss: 5.807553719622302
Validation loss: 5.008012754132418

Epoch: 6| Step: 1
Training loss: 4.652991671730391
Validation loss: 4.9829584711976

Epoch: 6| Step: 2
Training loss: 5.2966016850807645
Validation loss: 4.957691910493558

Epoch: 6| Step: 3
Training loss: 5.903467885484868
Validation loss: 4.931718707795037

Epoch: 6| Step: 4
Training loss: 4.860331254195819
Validation loss: 4.906282659823888

Epoch: 6| Step: 5
Training loss: 5.0938484790854215
Validation loss: 4.881132234626446

Epoch: 6| Step: 6
Training loss: 4.781939687414749
Validation loss: 4.855979553793061

Epoch: 6| Step: 7
Training loss: 5.5495325733647975
Validation loss: 4.832732880790753

Epoch: 6| Step: 8
Training loss: 4.848989495471945
Validation loss: 4.810397671907115

Epoch: 6| Step: 9
Training loss: 4.2755759849465615
Validation loss: 4.785802156319606

Epoch: 6| Step: 10
Training loss: 4.557969443646891
Validation loss: 4.763195825052723

Epoch: 6| Step: 11
Training loss: 3.9576615549874505
Validation loss: 4.742516408738564

Epoch: 6| Step: 12
Training loss: 4.638603617918858
Validation loss: 4.721788842190149

Epoch: 6| Step: 13
Training loss: 3.99281094156584
Validation loss: 4.701057373963554

Epoch: 6| Step: 0
Training loss: 5.104534691239007
Validation loss: 4.678798458719882

Epoch: 6| Step: 1
Training loss: 3.493664866384353
Validation loss: 4.662131654231878

Epoch: 6| Step: 2
Training loss: 4.994627545802496
Validation loss: 4.642561859311235

Epoch: 6| Step: 3
Training loss: 4.256292509295222
Validation loss: 4.621456441672357

Epoch: 6| Step: 4
Training loss: 4.449964184563341
Validation loss: 4.601999339089305

Epoch: 6| Step: 5
Training loss: 4.039194484893243
Validation loss: 4.584697152806514

Epoch: 6| Step: 6
Training loss: 4.30543447891686
Validation loss: 4.565463117698963

Epoch: 6| Step: 7
Training loss: 4.546675739969129
Validation loss: 4.5488061091538565

Epoch: 6| Step: 8
Training loss: 6.048204064009608
Validation loss: 4.5308485035005965

Epoch: 6| Step: 9
Training loss: 3.9960108176954625
Validation loss: 4.51300361746989

Epoch: 6| Step: 10
Training loss: 4.915309632522588
Validation loss: 4.492965930693745

Epoch: 6| Step: 11
Training loss: 4.676776470944457
Validation loss: 4.4746986332597

Epoch: 6| Step: 12
Training loss: 5.042373775780384
Validation loss: 4.457384317662022

Epoch: 6| Step: 13
Training loss: 4.781925926550578
Validation loss: 4.441146761762833

Epoch: 7| Step: 0
Training loss: 5.0715749899837155
Validation loss: 4.424933830439936

Epoch: 6| Step: 1
Training loss: 5.086347759710778
Validation loss: 4.40922013757769

Epoch: 6| Step: 2
Training loss: 4.929933569036929
Validation loss: 4.394562404216779

Epoch: 6| Step: 3
Training loss: 4.5608718266190795
Validation loss: 4.3758980434363055

Epoch: 6| Step: 4
Training loss: 4.61533851845047
Validation loss: 4.362889377310514

Epoch: 6| Step: 5
Training loss: 3.709184156102503
Validation loss: 4.343991612610929

Epoch: 6| Step: 6
Training loss: 2.8609449735467822
Validation loss: 4.328676053551728

Epoch: 6| Step: 7
Training loss: 4.069883708370327
Validation loss: 4.314683204324047

Epoch: 6| Step: 8
Training loss: 4.0508919004595745
Validation loss: 4.299792015366655

Epoch: 6| Step: 9
Training loss: 4.4096731321684555
Validation loss: 4.283668724056086

Epoch: 6| Step: 10
Training loss: 4.685548096211805
Validation loss: 4.268680365793574

Epoch: 6| Step: 11
Training loss: 5.395005014044241
Validation loss: 4.251275092661145

Epoch: 6| Step: 12
Training loss: 3.92710060230509
Validation loss: 4.227562960011797

Epoch: 6| Step: 13
Training loss: 4.023758662470168
Validation loss: 4.207179153802065

Epoch: 8| Step: 0
Training loss: 3.1977340364443183
Validation loss: 4.187193843281977

Epoch: 6| Step: 1
Training loss: 4.86903662174576
Validation loss: 4.172982619789245

Epoch: 6| Step: 2
Training loss: 4.7167224696512395
Validation loss: 4.162375675054343

Epoch: 6| Step: 3
Training loss: 3.892112478224628
Validation loss: 4.150172580847389

Epoch: 6| Step: 4
Training loss: 3.6502417079375973
Validation loss: 4.131282495659379

Epoch: 6| Step: 5
Training loss: 4.667683740318509
Validation loss: 4.11477816603186

Epoch: 6| Step: 6
Training loss: 3.9645407875706153
Validation loss: 4.099157393455646

Epoch: 6| Step: 7
Training loss: 4.073459572799925
Validation loss: 4.08295317021346

Epoch: 6| Step: 8
Training loss: 3.2355164803368335
Validation loss: 4.0699909823202045

Epoch: 6| Step: 9
Training loss: 5.038229703469451
Validation loss: 4.057891367084352

Epoch: 6| Step: 10
Training loss: 3.8820360355267094
Validation loss: 4.042384360583997

Epoch: 6| Step: 11
Training loss: 3.767732529074288
Validation loss: 4.029829508399189

Epoch: 6| Step: 12
Training loss: 4.7779437832245675
Validation loss: 4.015723937992657

Epoch: 6| Step: 13
Training loss: 5.358398348511253
Validation loss: 4.004658680508942

Epoch: 9| Step: 0
Training loss: 4.714973201412609
Validation loss: 3.9904301977058867

Epoch: 6| Step: 1
Training loss: 2.1385350849875953
Validation loss: 3.9785770691796354

Epoch: 6| Step: 2
Training loss: 4.365424003151919
Validation loss: 3.965268869935193

Epoch: 6| Step: 3
Training loss: 4.249192329404555
Validation loss: 3.9572580950720924

Epoch: 6| Step: 4
Training loss: 4.684526034128608
Validation loss: 3.94546512392615

Epoch: 6| Step: 5
Training loss: 4.898006049081191
Validation loss: 3.936153178269656

Epoch: 6| Step: 6
Training loss: 4.71100187494884
Validation loss: 3.925910771824543

Epoch: 6| Step: 7
Training loss: 2.5785324237139315
Validation loss: 3.915388545884402

Epoch: 6| Step: 8
Training loss: 3.8931260247320276
Validation loss: 3.9049276168610674

Epoch: 6| Step: 9
Training loss: 4.540568274335961
Validation loss: 3.8951103132210565

Epoch: 6| Step: 10
Training loss: 3.8060706285828094
Validation loss: 3.88423700769383

Epoch: 6| Step: 11
Training loss: 3.744828281922148
Validation loss: 3.8760565919280054

Epoch: 6| Step: 12
Training loss: 3.712889854435086
Validation loss: 3.8701420930637855

Epoch: 6| Step: 13
Training loss: 4.04787995221498
Validation loss: 3.86400371150002

Epoch: 10| Step: 0
Training loss: 3.797718346893827
Validation loss: 3.8585092750062824

Epoch: 6| Step: 1
Training loss: 3.4824941716415805
Validation loss: 3.844222306470939

Epoch: 6| Step: 2
Training loss: 2.5715590587689827
Validation loss: 3.8337087799586427

Epoch: 6| Step: 3
Training loss: 3.7683126268544833
Validation loss: 3.8286250511313367

Epoch: 6| Step: 4
Training loss: 3.5729435214413434
Validation loss: 3.8189870192145063

Epoch: 6| Step: 5
Training loss: 4.060195503977312
Validation loss: 3.8159832466976926

Epoch: 6| Step: 6
Training loss: 5.1961957367171365
Validation loss: 3.8080635543577896

Epoch: 6| Step: 7
Training loss: 3.6185316056150403
Validation loss: 3.7979548222048196

Epoch: 6| Step: 8
Training loss: 4.483687185246812
Validation loss: 3.78983241873838

Epoch: 6| Step: 9
Training loss: 4.582108466887196
Validation loss: 3.7821745373176383

Epoch: 6| Step: 10
Training loss: 3.235859258526429
Validation loss: 3.779331562332133

Epoch: 6| Step: 11
Training loss: 4.285885716597262
Validation loss: 3.7795742942014123

Epoch: 6| Step: 12
Training loss: 4.7500662548062245
Validation loss: 3.7693352618310167

Epoch: 6| Step: 13
Training loss: 2.928264791272329
Validation loss: 3.7569962296915635

Epoch: 11| Step: 0
Training loss: 4.049068843091427
Validation loss: 3.7510351345234345

Epoch: 6| Step: 1
Training loss: 3.778660667945912
Validation loss: 3.74371845720252

Epoch: 6| Step: 2
Training loss: 3.6387558751794318
Validation loss: 3.7453172151689533

Epoch: 6| Step: 3
Training loss: 3.949694928327436
Validation loss: 3.740813919217409

Epoch: 6| Step: 4
Training loss: 4.228000473816411
Validation loss: 3.7339375406544018

Epoch: 6| Step: 5
Training loss: 3.699009922662953
Validation loss: 3.7266823931267234

Epoch: 6| Step: 6
Training loss: 4.385475478453749
Validation loss: 3.7197084212973537

Epoch: 6| Step: 7
Training loss: 3.1364271662614285
Validation loss: 3.7118411924802106

Epoch: 6| Step: 8
Training loss: 3.543376255678564
Validation loss: 3.7097202600392514

Epoch: 6| Step: 9
Training loss: 4.265906467862805
Validation loss: 3.7051380605467013

Epoch: 6| Step: 10
Training loss: 3.5814824905958056
Validation loss: 3.7003250249810615

Epoch: 6| Step: 11
Training loss: 4.812490289851709
Validation loss: 3.6920948048538462

Epoch: 6| Step: 12
Training loss: 3.745040029355116
Validation loss: 3.685911383881454

Epoch: 6| Step: 13
Training loss: 3.0677959816052662
Validation loss: 3.6840001191825547

Epoch: 12| Step: 0
Training loss: 3.5661214524669678
Validation loss: 3.6835413423097063

Epoch: 6| Step: 1
Training loss: 3.760344415676803
Validation loss: 3.684355717377988

Epoch: 6| Step: 2
Training loss: 3.633601802274861
Validation loss: 3.674055774861344

Epoch: 6| Step: 3
Training loss: 3.504610022863245
Validation loss: 3.665283338378941

Epoch: 6| Step: 4
Training loss: 4.313995544289811
Validation loss: 3.655853639849095

Epoch: 6| Step: 5
Training loss: 3.4438459601074265
Validation loss: 3.651231163490187

Epoch: 6| Step: 6
Training loss: 3.7351206270524666
Validation loss: 3.647727159883521

Epoch: 6| Step: 7
Training loss: 4.397941602054648
Validation loss: 3.635694200832582

Epoch: 6| Step: 8
Training loss: 4.162304133025454
Validation loss: 3.632335122761912

Epoch: 6| Step: 9
Training loss: 3.491399825528325
Validation loss: 3.6243554370743185

Epoch: 6| Step: 10
Training loss: 3.9719823455110874
Validation loss: 3.622478267105954

Epoch: 6| Step: 11
Training loss: 3.6560616730010325
Validation loss: 3.6169628086901473

Epoch: 6| Step: 12
Training loss: 4.059497604104416
Validation loss: 3.611972598062582

Epoch: 6| Step: 13
Training loss: 3.8401124691387314
Validation loss: 3.600725083668025

Epoch: 13| Step: 0
Training loss: 4.0933148101818295
Validation loss: 3.599465217201076

Epoch: 6| Step: 1
Training loss: 3.1627004446806533
Validation loss: 3.5908025952495044

Epoch: 6| Step: 2
Training loss: 3.98535335721137
Validation loss: 3.5899386161482854

Epoch: 6| Step: 3
Training loss: 3.940023431078954
Validation loss: 3.5820418794813107

Epoch: 6| Step: 4
Training loss: 3.1960436443838875
Validation loss: 3.574574743785675

Epoch: 6| Step: 5
Training loss: 3.3712210515143957
Validation loss: 3.5694686248870227

Epoch: 6| Step: 6
Training loss: 4.727312819771046
Validation loss: 3.5611422689090326

Epoch: 6| Step: 7
Training loss: 4.060372367657687
Validation loss: 3.5587906926654247

Epoch: 6| Step: 8
Training loss: 4.029236046484015
Validation loss: 3.548826840589002

Epoch: 6| Step: 9
Training loss: 3.405868088896698
Validation loss: 3.542070414761029

Epoch: 6| Step: 10
Training loss: 3.409157308452042
Validation loss: 3.5378490557985867

Epoch: 6| Step: 11
Training loss: 3.0814500848211286
Validation loss: 3.53464067871948

Epoch: 6| Step: 12
Training loss: 4.223587766197645
Validation loss: 3.5307190300144713

Epoch: 6| Step: 13
Training loss: 3.571674646346992
Validation loss: 3.530402233227661

Epoch: 14| Step: 0
Training loss: 3.782756032604994
Validation loss: 3.5253297976598867

Epoch: 6| Step: 1
Training loss: 3.2982235722127458
Validation loss: 3.5212154065830923

Epoch: 6| Step: 2
Training loss: 3.9310700731691384
Validation loss: 3.512302926857489

Epoch: 6| Step: 3
Training loss: 2.860419577652426
Validation loss: 3.515680943343629

Epoch: 6| Step: 4
Training loss: 3.794056163921113
Validation loss: 3.5102541585787006

Epoch: 6| Step: 5
Training loss: 4.581937588956423
Validation loss: 3.506463041470971

Epoch: 6| Step: 6
Training loss: 3.1298918011278887
Validation loss: 3.5020505345086486

Epoch: 6| Step: 7
Training loss: 3.4654448287814548
Validation loss: 3.49733037993266

Epoch: 6| Step: 8
Training loss: 3.747371769824074
Validation loss: 3.49542318258326

Epoch: 6| Step: 9
Training loss: 3.476678259133177
Validation loss: 3.492574381058012

Epoch: 6| Step: 10
Training loss: 4.72157294104387
Validation loss: 3.4875012350754657

Epoch: 6| Step: 11
Training loss: 3.964278458008084
Validation loss: 3.4879682177410594

Epoch: 6| Step: 12
Training loss: 3.2722964244029233
Validation loss: 3.4853704159952255

Epoch: 6| Step: 13
Training loss: 3.2259482475618335
Validation loss: 3.4852646712243605

Epoch: 15| Step: 0
Training loss: 3.1378246367392384
Validation loss: 3.4814156998898005

Epoch: 6| Step: 1
Training loss: 3.185374130720147
Validation loss: 3.4745117465961566

Epoch: 6| Step: 2
Training loss: 3.202908838933381
Validation loss: 3.4686243488465447

Epoch: 6| Step: 3
Training loss: 4.098492619750631
Validation loss: 3.4653010110724747

Epoch: 6| Step: 4
Training loss: 3.0155350271450945
Validation loss: 3.4622628375641247

Epoch: 6| Step: 5
Training loss: 4.464465241228418
Validation loss: 3.4619059877848035

Epoch: 6| Step: 6
Training loss: 3.690973488604206
Validation loss: 3.457797969136648

Epoch: 6| Step: 7
Training loss: 3.384679688663114
Validation loss: 3.4558371218001853

Epoch: 6| Step: 8
Training loss: 3.068709947748109
Validation loss: 3.45574747948949

Epoch: 6| Step: 9
Training loss: 4.320025967413953
Validation loss: 3.452714935693472

Epoch: 6| Step: 10
Training loss: 4.410208797226253
Validation loss: 3.450814634582107

Epoch: 6| Step: 11
Training loss: 4.1418883501640416
Validation loss: 3.444062839235241

Epoch: 6| Step: 12
Training loss: 3.2465571727997222
Validation loss: 3.4424485148013853

Epoch: 6| Step: 13
Training loss: 3.47027444419279
Validation loss: 3.439600210272078

Epoch: 16| Step: 0
Training loss: 3.669146883811068
Validation loss: 3.439208987636194

Epoch: 6| Step: 1
Training loss: 3.1828103066887694
Validation loss: 3.4351671732368723

Epoch: 6| Step: 2
Training loss: 3.6186444044765995
Validation loss: 3.431488052580912

Epoch: 6| Step: 3
Training loss: 2.779182866024025
Validation loss: 3.4309067007469776

Epoch: 6| Step: 4
Training loss: 4.229951131191189
Validation loss: 3.4235470198142552

Epoch: 6| Step: 5
Training loss: 3.845437772555637
Validation loss: 3.4251640808668653

Epoch: 6| Step: 6
Training loss: 3.843303127208717
Validation loss: 3.421663298824117

Epoch: 6| Step: 7
Training loss: 3.9358567941712046
Validation loss: 3.4206924601521447

Epoch: 6| Step: 8
Training loss: 3.5101693780357666
Validation loss: 3.4196958092284038

Epoch: 6| Step: 9
Training loss: 3.540818475620421
Validation loss: 3.41630282041662

Epoch: 6| Step: 10
Training loss: 3.7853594431158615
Validation loss: 3.4110067765543324

Epoch: 6| Step: 11
Training loss: 4.071769585346443
Validation loss: 3.417269557241468

Epoch: 6| Step: 12
Training loss: 3.536259971003197
Validation loss: 3.409767355643602

Epoch: 6| Step: 13
Training loss: 2.8659853376930564
Validation loss: 3.4037834239030538

Epoch: 17| Step: 0
Training loss: 3.853336939122538
Validation loss: 3.404426703122717

Epoch: 6| Step: 1
Training loss: 3.469414587191883
Validation loss: 3.4004362974899687

Epoch: 6| Step: 2
Training loss: 4.161965935614893
Validation loss: 3.3990659569006687

Epoch: 6| Step: 3
Training loss: 3.1347271402914147
Validation loss: 3.398008484258545

Epoch: 6| Step: 4
Training loss: 3.0949394944890827
Validation loss: 3.394769926476399

Epoch: 6| Step: 5
Training loss: 3.040925932966003
Validation loss: 3.391879951918477

Epoch: 6| Step: 6
Training loss: 3.7611655267197115
Validation loss: 3.3913105154053986

Epoch: 6| Step: 7
Training loss: 3.4692485554145014
Validation loss: 3.385844692436614

Epoch: 6| Step: 8
Training loss: 3.3877886321915436
Validation loss: 3.3857861116443573

Epoch: 6| Step: 9
Training loss: 3.7995145437446927
Validation loss: 3.384712568317819

Epoch: 6| Step: 10
Training loss: 3.2571509990972802
Validation loss: 3.383244519442266

Epoch: 6| Step: 11
Training loss: 4.490262834973966
Validation loss: 3.386552536754498

Epoch: 6| Step: 12
Training loss: 3.4847392759940123
Validation loss: 3.3825595195293854

Epoch: 6| Step: 13
Training loss: 4.148607613331795
Validation loss: 3.3798381699374933

Epoch: 18| Step: 0
Training loss: 3.3650521501918425
Validation loss: 3.37520188427002

Epoch: 6| Step: 1
Training loss: 4.125559450994666
Validation loss: 3.373391052384431

Epoch: 6| Step: 2
Training loss: 4.327491686376104
Validation loss: 3.3741503078510573

Epoch: 6| Step: 3
Training loss: 3.9865901997312516
Validation loss: 3.371351357962837

Epoch: 6| Step: 4
Training loss: 3.555291361397644
Validation loss: 3.3678405827303703

Epoch: 6| Step: 5
Training loss: 3.6159528763325195
Validation loss: 3.367127230232151

Epoch: 6| Step: 6
Training loss: 3.8781356430215057
Validation loss: 3.3637927789015327

Epoch: 6| Step: 7
Training loss: 3.7354012200539146
Validation loss: 3.361896859728335

Epoch: 6| Step: 8
Training loss: 2.6839578928423107
Validation loss: 3.3597546617848284

Epoch: 6| Step: 9
Training loss: 2.4767319293384755
Validation loss: 3.357401595935839

Epoch: 6| Step: 10
Training loss: 3.4836208741970762
Validation loss: 3.356188421157489

Epoch: 6| Step: 11
Training loss: 3.420683213415912
Validation loss: 3.3559939717020315

Epoch: 6| Step: 12
Training loss: 3.070208288079156
Validation loss: 3.353782797444176

Epoch: 6| Step: 13
Training loss: 4.522022190611498
Validation loss: 3.353472537261169

Epoch: 19| Step: 0
Training loss: 3.1304880399135837
Validation loss: 3.3508368072510937

Epoch: 6| Step: 1
Training loss: 2.931752690073703
Validation loss: 3.3496771281408133

Epoch: 6| Step: 2
Training loss: 3.9153569378623323
Validation loss: 3.3471649690490164

Epoch: 6| Step: 3
Training loss: 3.702314843513513
Validation loss: 3.344773436558368

Epoch: 6| Step: 4
Training loss: 3.2039807176807447
Validation loss: 3.3452200868014876

Epoch: 6| Step: 5
Training loss: 2.6660323481332187
Validation loss: 3.3416785270777694

Epoch: 6| Step: 6
Training loss: 3.576332942850153
Validation loss: 3.3411289784026756

Epoch: 6| Step: 7
Training loss: 4.464407351335362
Validation loss: 3.3428300403366387

Epoch: 6| Step: 8
Training loss: 3.5054563497889797
Validation loss: 3.3427769699327983

Epoch: 6| Step: 9
Training loss: 3.268082127803306
Validation loss: 3.336152876708966

Epoch: 6| Step: 10
Training loss: 3.506362717392542
Validation loss: 3.333475078112158

Epoch: 6| Step: 11
Training loss: 4.504292877621589
Validation loss: 3.3304345159828417

Epoch: 6| Step: 12
Training loss: 3.482244687111043
Validation loss: 3.3305843051446806

Epoch: 6| Step: 13
Training loss: 3.849073120112447
Validation loss: 3.3293098583293785

Epoch: 20| Step: 0
Training loss: 3.2662776313135624
Validation loss: 3.338141857487824

Epoch: 6| Step: 1
Training loss: 4.042853636646242
Validation loss: 3.3473276988488223

Epoch: 6| Step: 2
Training loss: 2.86096380733143
Validation loss: 3.329906205160789

Epoch: 6| Step: 3
Training loss: 3.7584164584173405
Validation loss: 3.325192857716437

Epoch: 6| Step: 4
Training loss: 3.528642890431583
Validation loss: 3.3215720437106215

Epoch: 6| Step: 5
Training loss: 3.5757825088415416
Validation loss: 3.319615795335149

Epoch: 6| Step: 6
Training loss: 3.3928479760985484
Validation loss: 3.319849200417363

Epoch: 6| Step: 7
Training loss: 3.796398242798024
Validation loss: 3.316518085218928

Epoch: 6| Step: 8
Training loss: 3.228613988689863
Validation loss: 3.317617236280011

Epoch: 6| Step: 9
Training loss: 4.060670411330268
Validation loss: 3.3148718244536353

Epoch: 6| Step: 10
Training loss: 3.501729810224992
Validation loss: 3.315064064559676

Epoch: 6| Step: 11
Training loss: 3.8287013028815675
Validation loss: 3.310946505218406

Epoch: 6| Step: 12
Training loss: 2.9319561528652196
Validation loss: 3.312703544877973

Epoch: 6| Step: 13
Training loss: 3.9946823536200275
Validation loss: 3.3097751932015096

Epoch: 21| Step: 0
Training loss: 3.698011771398432
Validation loss: 3.306130022961679

Epoch: 6| Step: 1
Training loss: 3.1520820518502815
Validation loss: 3.306848892107395

Epoch: 6| Step: 2
Training loss: 2.6524678848724146
Validation loss: 3.3056902815038818

Epoch: 6| Step: 3
Training loss: 3.1955369343551836
Validation loss: 3.3101258796965487

Epoch: 6| Step: 4
Training loss: 3.6740138540821796
Validation loss: 3.3050184190617355

Epoch: 6| Step: 5
Training loss: 3.2934561263550464
Validation loss: 3.3005693331113375

Epoch: 6| Step: 6
Training loss: 4.844126828209931
Validation loss: 3.2993726617572006

Epoch: 6| Step: 7
Training loss: 3.479109133551171
Validation loss: 3.2946628220447014

Epoch: 6| Step: 8
Training loss: 3.383068189582677
Validation loss: 3.2940015356006955

Epoch: 6| Step: 9
Training loss: 3.383012232709571
Validation loss: 3.2911093608586337

Epoch: 6| Step: 10
Training loss: 3.8599722087432844
Validation loss: 3.291714055904163

Epoch: 6| Step: 11
Training loss: 3.8515980314585088
Validation loss: 3.2874996158944776

Epoch: 6| Step: 12
Training loss: 2.6928335095546965
Validation loss: 3.2893327206393006

Epoch: 6| Step: 13
Training loss: 4.064464622235661
Validation loss: 3.28661265973855

Epoch: 22| Step: 0
Training loss: 3.910670350506679
Validation loss: 3.2827895131749876

Epoch: 6| Step: 1
Training loss: 3.555202304325679
Validation loss: 3.285098017420232

Epoch: 6| Step: 2
Training loss: 3.6650823869591584
Validation loss: 3.2816609490059276

Epoch: 6| Step: 3
Training loss: 3.1596116397124114
Validation loss: 3.282373306189557

Epoch: 6| Step: 4
Training loss: 3.0723880808895685
Validation loss: 3.2819248722314747

Epoch: 6| Step: 5
Training loss: 3.878154578084602
Validation loss: 3.2798872782683883

Epoch: 6| Step: 6
Training loss: 4.1978740579542535
Validation loss: 3.284706443021377

Epoch: 6| Step: 7
Training loss: 3.0507762483953877
Validation loss: 3.2821915454931365

Epoch: 6| Step: 8
Training loss: 3.3988083209596436
Validation loss: 3.279996632763845

Epoch: 6| Step: 9
Training loss: 3.5640513739773865
Validation loss: 3.2787360996083366

Epoch: 6| Step: 10
Training loss: 3.553056346864161
Validation loss: 3.273785925520296

Epoch: 6| Step: 11
Training loss: 3.5796344355192984
Validation loss: 3.273467706522377

Epoch: 6| Step: 12
Training loss: 3.5005299303235247
Validation loss: 3.271375089389422

Epoch: 6| Step: 13
Training loss: 2.6252540283811574
Validation loss: 3.26897064231658

Epoch: 23| Step: 0
Training loss: 3.816890252462182
Validation loss: 3.2677516576490766

Epoch: 6| Step: 1
Training loss: 2.7728153874229515
Validation loss: 3.268298477688379

Epoch: 6| Step: 2
Training loss: 4.165521362572265
Validation loss: 3.2669640368893362

Epoch: 6| Step: 3
Training loss: 4.156922938429343
Validation loss: 3.263063753395727

Epoch: 6| Step: 4
Training loss: 2.967479072374885
Validation loss: 3.2619166046412285

Epoch: 6| Step: 5
Training loss: 3.733993063831885
Validation loss: 3.260950169021115

Epoch: 6| Step: 6
Training loss: 3.7296851168921745
Validation loss: 3.2582010658271296

Epoch: 6| Step: 7
Training loss: 3.518410625997182
Validation loss: 3.2587210623082066

Epoch: 6| Step: 8
Training loss: 3.645689098593169
Validation loss: 3.2569589410256

Epoch: 6| Step: 9
Training loss: 3.9342284159361878
Validation loss: 3.2550770455085565

Epoch: 6| Step: 10
Training loss: 2.394399020105143
Validation loss: 3.2541535579007763

Epoch: 6| Step: 11
Training loss: 2.722308406200826
Validation loss: 3.258202959325803

Epoch: 6| Step: 12
Training loss: 4.111717803682439
Validation loss: 3.2579151160125575

Epoch: 6| Step: 13
Training loss: 2.008294429903493
Validation loss: 3.2565531784939363

Epoch: 24| Step: 0
Training loss: 3.2364411319946327
Validation loss: 3.258036353983433

Epoch: 6| Step: 1
Training loss: 4.087693021457323
Validation loss: 3.2513376438098227

Epoch: 6| Step: 2
Training loss: 3.09978166857317
Validation loss: 3.250300053580379

Epoch: 6| Step: 3
Training loss: 3.3758492990639013
Validation loss: 3.2476854246613307

Epoch: 6| Step: 4
Training loss: 3.3650478991065267
Validation loss: 3.2501618539848995

Epoch: 6| Step: 5
Training loss: 2.973176567267152
Validation loss: 3.2494045371514066

Epoch: 6| Step: 6
Training loss: 3.1538064392337626
Validation loss: 3.249684868325435

Epoch: 6| Step: 7
Training loss: 3.56048152024496
Validation loss: 3.2484586608813375

Epoch: 6| Step: 8
Training loss: 3.1583085098566
Validation loss: 3.247089453668621

Epoch: 6| Step: 9
Training loss: 4.191279740926299
Validation loss: 3.2449826335924197

Epoch: 6| Step: 10
Training loss: 3.776872354973967
Validation loss: 3.2431911187709623

Epoch: 6| Step: 11
Training loss: 3.1949668641379447
Validation loss: 3.2422464265792152

Epoch: 6| Step: 12
Training loss: 2.998819118782881
Validation loss: 3.239970318860731

Epoch: 6| Step: 13
Training loss: 5.011331687484119
Validation loss: 3.2428191076704236

Epoch: 25| Step: 0
Training loss: 3.1044966417768456
Validation loss: 3.2395150545050506

Epoch: 6| Step: 1
Training loss: 3.567261174527663
Validation loss: 3.2379348941543045

Epoch: 6| Step: 2
Training loss: 3.194405350008219
Validation loss: 3.237367382081882

Epoch: 6| Step: 3
Training loss: 3.8442815397608174
Validation loss: 3.2407193918952455

Epoch: 6| Step: 4
Training loss: 2.9494363666608314
Validation loss: 3.239483771673539

Epoch: 6| Step: 5
Training loss: 4.367926628879922
Validation loss: 3.24087483212806

Epoch: 6| Step: 6
Training loss: 4.034854667154518
Validation loss: 3.241525996133514

Epoch: 6| Step: 7
Training loss: 2.9193745894402174
Validation loss: 3.230637030948901

Epoch: 6| Step: 8
Training loss: 3.2583303062899707
Validation loss: 3.2326911298858776

Epoch: 6| Step: 9
Training loss: 3.9125756887116525
Validation loss: 3.232918251400003

Epoch: 6| Step: 10
Training loss: 4.165609047495008
Validation loss: 3.2302833925839667

Epoch: 6| Step: 11
Training loss: 3.189983671858085
Validation loss: 3.228149562444795

Epoch: 6| Step: 12
Training loss: 2.2621647159563603
Validation loss: 3.2276123773277448

Epoch: 6| Step: 13
Training loss: 3.3820078115164374
Validation loss: 3.226112992888209

Epoch: 26| Step: 0
Training loss: 3.6045935199790424
Validation loss: 3.227468932817164

Epoch: 6| Step: 1
Training loss: 3.298167477049193
Validation loss: 3.227886928952953

Epoch: 6| Step: 2
Training loss: 3.645478512891231
Validation loss: 3.2253994068856198

Epoch: 6| Step: 3
Training loss: 3.201747840144904
Validation loss: 3.222364996722094

Epoch: 6| Step: 4
Training loss: 4.110875309089874
Validation loss: 3.222864275918122

Epoch: 6| Step: 5
Training loss: 3.8117306042373698
Validation loss: 3.22031248538389

Epoch: 6| Step: 6
Training loss: 4.218544283902226
Validation loss: 3.2186209993987775

Epoch: 6| Step: 7
Training loss: 3.3000218708585147
Validation loss: 3.217602981105084

Epoch: 6| Step: 8
Training loss: 3.0158079417975348
Validation loss: 3.2187285318523866

Epoch: 6| Step: 9
Training loss: 3.9175834123973443
Validation loss: 3.2175690622775037

Epoch: 6| Step: 10
Training loss: 3.402753803056264
Validation loss: 3.2161212927014993

Epoch: 6| Step: 11
Training loss: 2.4756306239803143
Validation loss: 3.2151483411833364

Epoch: 6| Step: 12
Training loss: 3.543353513036368
Validation loss: 3.214627818692197

Epoch: 6| Step: 13
Training loss: 1.7978512972738805
Validation loss: 3.2150427558179033

Epoch: 27| Step: 0
Training loss: 3.644330934046488
Validation loss: 3.2190622412625536

Epoch: 6| Step: 1
Training loss: 3.23465686988867
Validation loss: 3.2191819481475825

Epoch: 6| Step: 2
Training loss: 3.7571814120136335
Validation loss: 3.213434667350435

Epoch: 6| Step: 3
Training loss: 4.0039572214743355
Validation loss: 3.213057300493123

Epoch: 6| Step: 4
Training loss: 3.638901462161123
Validation loss: 3.2103170556892615

Epoch: 6| Step: 5
Training loss: 3.139650260011135
Validation loss: 3.2099962824333317

Epoch: 6| Step: 6
Training loss: 2.748205639903386
Validation loss: 3.210418048371849

Epoch: 6| Step: 7
Training loss: 2.9997332772260052
Validation loss: 3.21846373882328

Epoch: 6| Step: 8
Training loss: 3.252645589515349
Validation loss: 3.209043815411349

Epoch: 6| Step: 9
Training loss: 2.876791851757336
Validation loss: 3.208710914471975

Epoch: 6| Step: 10
Training loss: 3.534130440774945
Validation loss: 3.2066649254124804

Epoch: 6| Step: 11
Training loss: 3.8171453472843972
Validation loss: 3.206390808131257

Epoch: 6| Step: 12
Training loss: 3.5674115505361077
Validation loss: 3.205819774734117

Epoch: 6| Step: 13
Training loss: 4.438641898220081
Validation loss: 3.2038652470585904

Epoch: 28| Step: 0
Training loss: 3.67989664637513
Validation loss: 3.2042283249630996

Epoch: 6| Step: 1
Training loss: 2.964334517059153
Validation loss: 3.2028831904889272

Epoch: 6| Step: 2
Training loss: 3.085040848274535
Validation loss: 3.202339327719227

Epoch: 6| Step: 3
Training loss: 3.435781847111359
Validation loss: 3.2025032534519577

Epoch: 6| Step: 4
Training loss: 3.217238284169207
Validation loss: 3.201324545941427

Epoch: 6| Step: 5
Training loss: 4.072412692188507
Validation loss: 3.2010621654428553

Epoch: 6| Step: 6
Training loss: 3.706150669870393
Validation loss: 3.2014118982946704

Epoch: 6| Step: 7
Training loss: 2.747233473091843
Validation loss: 3.1989402633259583

Epoch: 6| Step: 8
Training loss: 3.8393021567363275
Validation loss: 3.1977098809694695

Epoch: 6| Step: 9
Training loss: 3.3380951882898704
Validation loss: 3.1976530711912625

Epoch: 6| Step: 10
Training loss: 4.181454065928352
Validation loss: 3.1981616599584677

Epoch: 6| Step: 11
Training loss: 3.7288859739457645
Validation loss: 3.199441017722483

Epoch: 6| Step: 12
Training loss: 3.0658428087543435
Validation loss: 3.196835431730656

Epoch: 6| Step: 13
Training loss: 2.598347369733787
Validation loss: 3.1955886361665695

Epoch: 29| Step: 0
Training loss: 3.0064741848094725
Validation loss: 3.1934289227304653

Epoch: 6| Step: 1
Training loss: 3.9739948369354052
Validation loss: 3.1912459757732554

Epoch: 6| Step: 2
Training loss: 2.9988879685904806
Validation loss: 3.1917431060236154

Epoch: 6| Step: 3
Training loss: 3.4632615666913305
Validation loss: 3.191448469298557

Epoch: 6| Step: 4
Training loss: 3.3852147125259786
Validation loss: 3.1895851651633857

Epoch: 6| Step: 5
Training loss: 2.3993623919701017
Validation loss: 3.1883875097684355

Epoch: 6| Step: 6
Training loss: 3.782840110681195
Validation loss: 3.1892175295738077

Epoch: 6| Step: 7
Training loss: 3.404293653406752
Validation loss: 3.1894586839853463

Epoch: 6| Step: 8
Training loss: 3.628444744940984
Validation loss: 3.190480430702187

Epoch: 6| Step: 9
Training loss: 3.0743076258297353
Validation loss: 3.192285907075749

Epoch: 6| Step: 10
Training loss: 3.782493449909517
Validation loss: 3.187403077226957

Epoch: 6| Step: 11
Training loss: 4.069459089846653
Validation loss: 3.182155067994043

Epoch: 6| Step: 12
Training loss: 3.787235283492339
Validation loss: 3.1828054368468224

Epoch: 6| Step: 13
Training loss: 2.9150671978332334
Validation loss: 3.180326888263881

Epoch: 30| Step: 0
Training loss: 3.1982879588804884
Validation loss: 3.1804757009162614

Epoch: 6| Step: 1
Training loss: 3.150438453798435
Validation loss: 3.177566087109314

Epoch: 6| Step: 2
Training loss: 3.316365990995335
Validation loss: 3.1785984525043838

Epoch: 6| Step: 3
Training loss: 3.1304618406969236
Validation loss: 3.1758552785521887

Epoch: 6| Step: 4
Training loss: 3.447660653712064
Validation loss: 3.1772168044537246

Epoch: 6| Step: 5
Training loss: 3.3471878774594828
Validation loss: 3.1766122523549356

Epoch: 6| Step: 6
Training loss: 3.9752655612359575
Validation loss: 3.1752002549235594

Epoch: 6| Step: 7
Training loss: 3.6699997029317375
Validation loss: 3.171626831090423

Epoch: 6| Step: 8
Training loss: 3.8657282995115594
Validation loss: 3.172230701636221

Epoch: 6| Step: 9
Training loss: 2.9911479688013847
Validation loss: 3.1744302426550677

Epoch: 6| Step: 10
Training loss: 3.8153465775517614
Validation loss: 3.1775214081678462

Epoch: 6| Step: 11
Training loss: 3.154792978111434
Validation loss: 3.172332303954607

Epoch: 6| Step: 12
Training loss: 3.904404104877538
Validation loss: 3.170913580487199

Epoch: 6| Step: 13
Training loss: 2.5265130825553315
Validation loss: 3.166463569082295

Epoch: 31| Step: 0
Training loss: 3.6473647180247144
Validation loss: 3.162941669110984

Epoch: 6| Step: 1
Training loss: 3.534362771361333
Validation loss: 3.1624077771775605

Epoch: 6| Step: 2
Training loss: 3.1001859055427277
Validation loss: 3.159466240603231

Epoch: 6| Step: 3
Training loss: 2.874224019026327
Validation loss: 3.155758722328275

Epoch: 6| Step: 4
Training loss: 3.4466530750038644
Validation loss: 3.1547153039043323

Epoch: 6| Step: 5
Training loss: 3.0158703956178328
Validation loss: 3.154692969290316

Epoch: 6| Step: 6
Training loss: 3.3073935825934995
Validation loss: 3.1560654303469935

Epoch: 6| Step: 7
Training loss: 2.864500361310204
Validation loss: 3.1568227350033546

Epoch: 6| Step: 8
Training loss: 4.1224889337079995
Validation loss: 3.1533883222357093

Epoch: 6| Step: 9
Training loss: 4.276688644895821
Validation loss: 3.159898403526243

Epoch: 6| Step: 10
Training loss: 3.2509629216914933
Validation loss: 3.147707749002745

Epoch: 6| Step: 11
Training loss: 3.482522240955891
Validation loss: 3.146243466281703

Epoch: 6| Step: 12
Training loss: 3.4910056484660794
Validation loss: 3.1498103150269587

Epoch: 6| Step: 13
Training loss: 3.0075624832676837
Validation loss: 3.148260358873883

Epoch: 32| Step: 0
Training loss: 3.5174424284539176
Validation loss: 3.1541318996012797

Epoch: 6| Step: 1
Training loss: 3.379342570275377
Validation loss: 3.151043571540069

Epoch: 6| Step: 2
Training loss: 4.183010598508726
Validation loss: 3.1579934163049392

Epoch: 6| Step: 3
Training loss: 3.3038608969161936
Validation loss: 3.156141547507763

Epoch: 6| Step: 4
Training loss: 2.8219840466962864
Validation loss: 3.151234543356052

Epoch: 6| Step: 5
Training loss: 3.0786313642534946
Validation loss: 3.159448869767331

Epoch: 6| Step: 6
Training loss: 2.9760440565150175
Validation loss: 3.1593883323718788

Epoch: 6| Step: 7
Training loss: 3.3009246975579063
Validation loss: 3.150476655447303

Epoch: 6| Step: 8
Training loss: 2.977290667679028
Validation loss: 3.143101751000156

Epoch: 6| Step: 9
Training loss: 3.6061690984209616
Validation loss: 3.1421644780015585

Epoch: 6| Step: 10
Training loss: 3.7712341573279393
Validation loss: 3.1386732488430704

Epoch: 6| Step: 11
Training loss: 3.408189134104521
Validation loss: 3.137539870597082

Epoch: 6| Step: 12
Training loss: 3.580720318407628
Validation loss: 3.1347363644627353

Epoch: 6| Step: 13
Training loss: 3.829299186154051
Validation loss: 3.1357724434168626

Epoch: 33| Step: 0
Training loss: 2.6955331905517257
Validation loss: 3.1332113103030945

Epoch: 6| Step: 1
Training loss: 3.143293471206653
Validation loss: 3.1311237754087164

Epoch: 6| Step: 2
Training loss: 3.1290629105990067
Validation loss: 3.1310176622429027

Epoch: 6| Step: 3
Training loss: 3.779078845455069
Validation loss: 3.130533977276862

Epoch: 6| Step: 4
Training loss: 3.232474390623251
Validation loss: 3.128044222393109

Epoch: 6| Step: 5
Training loss: 2.7393939360117074
Validation loss: 3.1274192322112744

Epoch: 6| Step: 6
Training loss: 3.54666419390064
Validation loss: 3.128041824340255

Epoch: 6| Step: 7
Training loss: 3.293041441127548
Validation loss: 3.1274016604209365

Epoch: 6| Step: 8
Training loss: 3.8728124535082804
Validation loss: 3.129072337448374

Epoch: 6| Step: 9
Training loss: 4.119186466227851
Validation loss: 3.1263697520192966

Epoch: 6| Step: 10
Training loss: 2.6484508232749318
Validation loss: 3.1243823370103896

Epoch: 6| Step: 11
Training loss: 3.6289142653722704
Validation loss: 3.1255265085643336

Epoch: 6| Step: 12
Training loss: 4.09996132250895
Validation loss: 3.122685981380368

Epoch: 6| Step: 13
Training loss: 3.1229824419752577
Validation loss: 3.1208785494437294

Epoch: 34| Step: 0
Training loss: 3.7932898152765318
Validation loss: 3.121413052992553

Epoch: 6| Step: 1
Training loss: 3.115059262319687
Validation loss: 3.119258323839147

Epoch: 6| Step: 2
Training loss: 3.344038193306628
Validation loss: 3.124007670039716

Epoch: 6| Step: 3
Training loss: 3.529251883662797
Validation loss: 3.121504111693811

Epoch: 6| Step: 4
Training loss: 3.894490600496234
Validation loss: 3.1224839383337692

Epoch: 6| Step: 5
Training loss: 2.6233028193261956
Validation loss: 3.1177513074672745

Epoch: 6| Step: 6
Training loss: 4.03871823288028
Validation loss: 3.1166795642694054

Epoch: 6| Step: 7
Training loss: 3.309709921397032
Validation loss: 3.1177513962726846

Epoch: 6| Step: 8
Training loss: 2.6121398531523456
Validation loss: 3.115979402407296

Epoch: 6| Step: 9
Training loss: 3.7360339450233453
Validation loss: 3.1170558522816365

Epoch: 6| Step: 10
Training loss: 2.998031606231477
Validation loss: 3.1149064767275756

Epoch: 6| Step: 11
Training loss: 2.9579017395969798
Validation loss: 3.1145890039983684

Epoch: 6| Step: 12
Training loss: 3.4729853711181233
Validation loss: 3.11482872968345

Epoch: 6| Step: 13
Training loss: 3.8871926483628054
Validation loss: 3.115455382441757

Epoch: 35| Step: 0
Training loss: 3.927256141051194
Validation loss: 3.1141196625417185

Epoch: 6| Step: 1
Training loss: 3.516363312230907
Validation loss: 3.1125077570191633

Epoch: 6| Step: 2
Training loss: 3.488914099141239
Validation loss: 3.11004520225668

Epoch: 6| Step: 3
Training loss: 3.447638801065492
Validation loss: 3.111809057171421

Epoch: 6| Step: 4
Training loss: 4.028562137627831
Validation loss: 3.109528101899461

Epoch: 6| Step: 5
Training loss: 3.0095171965123435
Validation loss: 3.1104957497048185

Epoch: 6| Step: 6
Training loss: 3.801749785263167
Validation loss: 3.1082776394859524

Epoch: 6| Step: 7
Training loss: 3.4409912413375054
Validation loss: 3.108229006864762

Epoch: 6| Step: 8
Training loss: 3.367225735263628
Validation loss: 3.107447120070655

Epoch: 6| Step: 9
Training loss: 2.384007688855567
Validation loss: 3.1060284200598303

Epoch: 6| Step: 10
Training loss: 3.0159058118931594
Validation loss: 3.106453178916157

Epoch: 6| Step: 11
Training loss: 3.4858957572841813
Validation loss: 3.1087852244779195

Epoch: 6| Step: 12
Training loss: 2.813226563595637
Validation loss: 3.1080233647132673

Epoch: 6| Step: 13
Training loss: 3.281341260821663
Validation loss: 3.1071539626626983

Epoch: 36| Step: 0
Training loss: 3.740049257005076
Validation loss: 3.106611796177558

Epoch: 6| Step: 1
Training loss: 3.537860051356039
Validation loss: 3.102586018525702

Epoch: 6| Step: 2
Training loss: 2.739229438077196
Validation loss: 3.1033999386779434

Epoch: 6| Step: 3
Training loss: 3.5209592236165017
Validation loss: 3.1059188395872908

Epoch: 6| Step: 4
Training loss: 3.8371534110253727
Validation loss: 3.113914974181533

Epoch: 6| Step: 5
Training loss: 3.8563262387843333
Validation loss: 3.104172635504553

Epoch: 6| Step: 6
Training loss: 3.0914211563009335
Validation loss: 3.1034403714741083

Epoch: 6| Step: 7
Training loss: 2.8167428967545542
Validation loss: 3.1056873403773024

Epoch: 6| Step: 8
Training loss: 3.1421884469401236
Validation loss: 3.106878475459623

Epoch: 6| Step: 9
Training loss: 3.4740738437251553
Validation loss: 3.1093132221913455

Epoch: 6| Step: 10
Training loss: 3.331626232436816
Validation loss: 3.1068244276674304

Epoch: 6| Step: 11
Training loss: 3.397477218181026
Validation loss: 3.1045338397762468

Epoch: 6| Step: 12
Training loss: 3.3113477610250786
Validation loss: 3.104699942901509

Epoch: 6| Step: 13
Training loss: 3.360125080913984
Validation loss: 3.1039797064591736

Epoch: 37| Step: 0
Training loss: 4.048840608775376
Validation loss: 3.103949279396871

Epoch: 6| Step: 1
Training loss: 2.9560642046943757
Validation loss: 3.1025533459591683

Epoch: 6| Step: 2
Training loss: 3.152051796327814
Validation loss: 3.102736665171535

Epoch: 6| Step: 3
Training loss: 3.7726294242646135
Validation loss: 3.103124430486535

Epoch: 6| Step: 4
Training loss: 3.4173174602702012
Validation loss: 3.1028248414722057

Epoch: 6| Step: 5
Training loss: 3.043887821030302
Validation loss: 3.1028719113219974

Epoch: 6| Step: 6
Training loss: 2.940035111613385
Validation loss: 3.1016992884051335

Epoch: 6| Step: 7
Training loss: 3.528736536565833
Validation loss: 3.1024352108671405

Epoch: 6| Step: 8
Training loss: 3.5434739531793302
Validation loss: 3.100082970738411

Epoch: 6| Step: 9
Training loss: 3.3660014247517283
Validation loss: 3.0997296209116882

Epoch: 6| Step: 10
Training loss: 4.123963659324332
Validation loss: 3.100130265800575

Epoch: 6| Step: 11
Training loss: 3.2944717687710563
Validation loss: 3.0983223404236693

Epoch: 6| Step: 12
Training loss: 2.9931677265984913
Validation loss: 3.097944738558222

Epoch: 6| Step: 13
Training loss: 2.2936112447653936
Validation loss: 3.0972966142100535

Epoch: 38| Step: 0
Training loss: 3.569998896408979
Validation loss: 3.0966301706900223

Epoch: 6| Step: 1
Training loss: 3.035546158694903
Validation loss: 3.0946502038784014

Epoch: 6| Step: 2
Training loss: 2.981575016882659
Validation loss: 3.0948513238078643

Epoch: 6| Step: 3
Training loss: 3.53958240589102
Validation loss: 3.0949505063289067

Epoch: 6| Step: 4
Training loss: 3.3477153617064537
Validation loss: 3.093621702197038

Epoch: 6| Step: 5
Training loss: 2.85329336649394
Validation loss: 3.0936532128173044

Epoch: 6| Step: 6
Training loss: 4.1796254376233435
Validation loss: 3.093456492625179

Epoch: 6| Step: 7
Training loss: 3.4311275717428837
Validation loss: 3.0927973316587503

Epoch: 6| Step: 8
Training loss: 3.445120946701631
Validation loss: 3.0927461910040708

Epoch: 6| Step: 9
Training loss: 3.9769581895778576
Validation loss: 3.09261205715793

Epoch: 6| Step: 10
Training loss: 3.4673877137368194
Validation loss: 3.090672324130682

Epoch: 6| Step: 11
Training loss: 2.546382552204765
Validation loss: 3.091114158097293

Epoch: 6| Step: 12
Training loss: 3.199458261171417
Validation loss: 3.088906225319251

Epoch: 6| Step: 13
Training loss: 3.2972654861686976
Validation loss: 3.0905132230894026

Epoch: 39| Step: 0
Training loss: 3.2168856656594578
Validation loss: 3.0879120679487553

Epoch: 6| Step: 1
Training loss: 3.692355305413608
Validation loss: 3.0888090315549617

Epoch: 6| Step: 2
Training loss: 3.465367910826389
Validation loss: 3.089081109291242

Epoch: 6| Step: 3
Training loss: 3.941670343721273
Validation loss: 3.0846059983551033

Epoch: 6| Step: 4
Training loss: 3.9016726110500812
Validation loss: 3.083818235129698

Epoch: 6| Step: 5
Training loss: 2.9756324095895166
Validation loss: 3.0860699867271175

Epoch: 6| Step: 6
Training loss: 2.7544792282642483
Validation loss: 3.084625876731524

Epoch: 6| Step: 7
Training loss: 3.2219394325895374
Validation loss: 3.0864085504479712

Epoch: 6| Step: 8
Training loss: 2.987085679185879
Validation loss: 3.0845187540552748

Epoch: 6| Step: 9
Training loss: 3.6403109042517587
Validation loss: 3.0829559390097985

Epoch: 6| Step: 10
Training loss: 3.157620274177761
Validation loss: 3.0816821577464695

Epoch: 6| Step: 11
Training loss: 3.2048375459582794
Validation loss: 3.080351661353352

Epoch: 6| Step: 12
Training loss: 3.3178444699193945
Validation loss: 3.0788191104413625

Epoch: 6| Step: 13
Training loss: 3.4656763979348444
Validation loss: 3.0755073740385948

Epoch: 40| Step: 0
Training loss: 4.105636927157188
Validation loss: 3.0724415696365783

Epoch: 6| Step: 1
Training loss: 3.106790820193637
Validation loss: 3.0748959437426384

Epoch: 6| Step: 2
Training loss: 3.419970953745498
Validation loss: 3.0748153516033176

Epoch: 6| Step: 3
Training loss: 3.755042437073599
Validation loss: 3.0728374979212063

Epoch: 6| Step: 4
Training loss: 2.9803172381726286
Validation loss: 3.0762740231749452

Epoch: 6| Step: 5
Training loss: 3.0780326713231005
Validation loss: 3.0723497785896874

Epoch: 6| Step: 6
Training loss: 3.7389806972024786
Validation loss: 3.067160854495819

Epoch: 6| Step: 7
Training loss: 3.0903215002807807
Validation loss: 3.0691334696463555

Epoch: 6| Step: 8
Training loss: 2.946183053228343
Validation loss: 3.0708865381845767

Epoch: 6| Step: 9
Training loss: 4.041481459526359
Validation loss: 3.068282316745532

Epoch: 6| Step: 10
Training loss: 3.391931097671369
Validation loss: 3.0715362907892647

Epoch: 6| Step: 11
Training loss: 2.8430044014192553
Validation loss: 3.0668796884196925

Epoch: 6| Step: 12
Training loss: 3.0478767508871867
Validation loss: 3.0664219909351735

Epoch: 6| Step: 13
Training loss: 2.834838654301661
Validation loss: 3.067970914108328

Epoch: 41| Step: 0
Training loss: 2.519071315214735
Validation loss: 3.0641786044566146

Epoch: 6| Step: 1
Training loss: 3.7526495156690522
Validation loss: 3.065775470950952

Epoch: 6| Step: 2
Training loss: 4.211026503944014
Validation loss: 3.0650239914926702

Epoch: 6| Step: 3
Training loss: 3.330939164251185
Validation loss: 3.0652293920945284

Epoch: 6| Step: 4
Training loss: 3.497738925279659
Validation loss: 3.0708322993838455

Epoch: 6| Step: 5
Training loss: 2.528562744116475
Validation loss: 3.0617100741390115

Epoch: 6| Step: 6
Training loss: 3.3696322671176726
Validation loss: 3.0629725607511338

Epoch: 6| Step: 7
Training loss: 3.137625101338637
Validation loss: 3.0638168999331916

Epoch: 6| Step: 8
Training loss: 3.2241456075496404
Validation loss: 3.063326022947623

Epoch: 6| Step: 9
Training loss: 2.989169279305988
Validation loss: 3.0602182607057666

Epoch: 6| Step: 10
Training loss: 3.403159883458726
Validation loss: 3.0634476796578443

Epoch: 6| Step: 11
Training loss: 3.14027455970059
Validation loss: 3.0604045547492182

Epoch: 6| Step: 12
Training loss: 3.545662155830842
Validation loss: 3.0650862839120205

Epoch: 6| Step: 13
Training loss: 4.109699657074992
Validation loss: 3.0613712644099027

Epoch: 42| Step: 0
Training loss: 3.095736395720267
Validation loss: 3.062696059285794

Epoch: 6| Step: 1
Training loss: 3.152254956589066
Validation loss: 3.0611227796619134

Epoch: 6| Step: 2
Training loss: 3.18995093568003
Validation loss: 3.0616798951903412

Epoch: 6| Step: 3
Training loss: 2.3254983921541683
Validation loss: 3.060200174033455

Epoch: 6| Step: 4
Training loss: 2.948818881987683
Validation loss: 3.060210156482396

Epoch: 6| Step: 5
Training loss: 3.621866911121252
Validation loss: 3.059661719434435

Epoch: 6| Step: 6
Training loss: 3.3163110654221812
Validation loss: 3.058155873823844

Epoch: 6| Step: 7
Training loss: 3.4788653001446166
Validation loss: 3.060249857254261

Epoch: 6| Step: 8
Training loss: 4.095075552852394
Validation loss: 3.064655557417164

Epoch: 6| Step: 9
Training loss: 3.513168765441691
Validation loss: 3.060684456175708

Epoch: 6| Step: 10
Training loss: 3.2347217318677024
Validation loss: 3.093372168184027

Epoch: 6| Step: 11
Training loss: 3.5533208546470068
Validation loss: 3.083758648010376

Epoch: 6| Step: 12
Training loss: 3.7424563508428346
Validation loss: 3.0635528303384247

Epoch: 6| Step: 13
Training loss: 3.1665928647994717
Validation loss: 3.060248470822953

Epoch: 43| Step: 0
Training loss: 3.3416046675894453
Validation loss: 3.061343941923001

Epoch: 6| Step: 1
Training loss: 2.909187718969696
Validation loss: 3.0548482151375005

Epoch: 6| Step: 2
Training loss: 3.0781135365229115
Validation loss: 3.0548048934449152

Epoch: 6| Step: 3
Training loss: 3.2323574094308083
Validation loss: 3.0531907539736287

Epoch: 6| Step: 4
Training loss: 3.165238677512348
Validation loss: 3.054649765494523

Epoch: 6| Step: 5
Training loss: 3.2608771603260873
Validation loss: 3.0559082713915315

Epoch: 6| Step: 6
Training loss: 3.605074082881849
Validation loss: 3.0566078160947687

Epoch: 6| Step: 7
Training loss: 2.670720436538891
Validation loss: 3.055887400847047

Epoch: 6| Step: 8
Training loss: 3.139110902419733
Validation loss: 3.0567245386436306

Epoch: 6| Step: 9
Training loss: 3.439806909686608
Validation loss: 3.060208735686011

Epoch: 6| Step: 10
Training loss: 3.2139978976287327
Validation loss: 3.0579288195589642

Epoch: 6| Step: 11
Training loss: 3.790144492542867
Validation loss: 3.0570437378376707

Epoch: 6| Step: 12
Training loss: 3.9937213257907933
Validation loss: 3.052350989058504

Epoch: 6| Step: 13
Training loss: 3.9638848709648054
Validation loss: 3.049611299876011

Epoch: 44| Step: 0
Training loss: 3.2584096237838462
Validation loss: 3.0506879828422075

Epoch: 6| Step: 1
Training loss: 3.441756647394649
Validation loss: 3.0485280473065846

Epoch: 6| Step: 2
Training loss: 3.184138002270769
Validation loss: 3.04926584160586

Epoch: 6| Step: 3
Training loss: 3.8630604309600844
Validation loss: 3.049764453992062

Epoch: 6| Step: 4
Training loss: 3.7127723414138227
Validation loss: 3.050126986967514

Epoch: 6| Step: 5
Training loss: 4.100057852732319
Validation loss: 3.046230294861796

Epoch: 6| Step: 6
Training loss: 2.7622799229019206
Validation loss: 3.047481471248351

Epoch: 6| Step: 7
Training loss: 3.0498237621481628
Validation loss: 3.046752318885446

Epoch: 6| Step: 8
Training loss: 3.029049418688869
Validation loss: 3.0463102546702605

Epoch: 6| Step: 9
Training loss: 2.7213558117923906
Validation loss: 3.0456418470297195

Epoch: 6| Step: 10
Training loss: 3.2775324515941016
Validation loss: 3.04405209104147

Epoch: 6| Step: 11
Training loss: 2.9589813131687954
Validation loss: 3.047020378672695

Epoch: 6| Step: 12
Training loss: 3.428154744077464
Validation loss: 3.046764158678615

Epoch: 6| Step: 13
Training loss: 3.785156879877721
Validation loss: 3.048519015557234

Epoch: 45| Step: 0
Training loss: 3.346389156806773
Validation loss: 3.043434991635972

Epoch: 6| Step: 1
Training loss: 2.9559499963394806
Validation loss: 3.0447281806094155

Epoch: 6| Step: 2
Training loss: 3.2060210742983606
Validation loss: 3.0415015996919696

Epoch: 6| Step: 3
Training loss: 3.5042539358139386
Validation loss: 3.040457185146305

Epoch: 6| Step: 4
Training loss: 3.1150154826114718
Validation loss: 3.0391631640781385

Epoch: 6| Step: 5
Training loss: 2.985749731942045
Validation loss: 3.038948676758401

Epoch: 6| Step: 6
Training loss: 1.8211628642605309
Validation loss: 3.037858043948481

Epoch: 6| Step: 7
Training loss: 3.8878599092260373
Validation loss: 3.0396155671757894

Epoch: 6| Step: 8
Training loss: 3.383191376011524
Validation loss: 3.037365658242458

Epoch: 6| Step: 9
Training loss: 3.7491594008215436
Validation loss: 3.0362062808515744

Epoch: 6| Step: 10
Training loss: 3.933501377934163
Validation loss: 3.0352597903335967

Epoch: 6| Step: 11
Training loss: 3.4327899916496523
Validation loss: 3.0365648410157027

Epoch: 6| Step: 12
Training loss: 3.108048659337726
Validation loss: 3.030944275987101

Epoch: 6| Step: 13
Training loss: 3.8264400588758636
Validation loss: 3.0333381727730613

Epoch: 46| Step: 0
Training loss: 2.7080363379763375
Validation loss: 3.031478900256997

Epoch: 6| Step: 1
Training loss: 3.343148863759487
Validation loss: 3.031893510576226

Epoch: 6| Step: 2
Training loss: 3.1435144901223815
Validation loss: 3.0285363135421983

Epoch: 6| Step: 3
Training loss: 3.3616589256529097
Validation loss: 3.03074725047437

Epoch: 6| Step: 4
Training loss: 2.919648979983861
Validation loss: 3.025657250837323

Epoch: 6| Step: 5
Training loss: 3.1727556781833712
Validation loss: 3.0264453451715285

Epoch: 6| Step: 6
Training loss: 3.7125004418369634
Validation loss: 3.034323750630416

Epoch: 6| Step: 7
Training loss: 2.919784532461842
Validation loss: 3.024090737594891

Epoch: 6| Step: 8
Training loss: 3.3009385652692975
Validation loss: 3.024116026400906

Epoch: 6| Step: 9
Training loss: 3.7497491116838377
Validation loss: 3.0231610731128296

Epoch: 6| Step: 10
Training loss: 3.556481749051364
Validation loss: 3.018468844729234

Epoch: 6| Step: 11
Training loss: 3.2412463924977817
Validation loss: 3.021873867471903

Epoch: 6| Step: 12
Training loss: 3.7488321393138477
Validation loss: 3.0272868493720413

Epoch: 6| Step: 13
Training loss: 3.3380691900196435
Validation loss: 3.020325944755141

Epoch: 47| Step: 0
Training loss: 3.343454223100381
Validation loss: 3.0186155048366197

Epoch: 6| Step: 1
Training loss: 3.458293929890514
Validation loss: 3.021458306477084

Epoch: 6| Step: 2
Training loss: 3.74204656857211
Validation loss: 3.0173500343066353

Epoch: 6| Step: 3
Training loss: 3.3684534228959198
Validation loss: 3.02055912208907

Epoch: 6| Step: 4
Training loss: 3.665067164910245
Validation loss: 3.023663852913276

Epoch: 6| Step: 5
Training loss: 2.491451908242257
Validation loss: 3.0189720510178804

Epoch: 6| Step: 6
Training loss: 2.408680765595162
Validation loss: 3.0214570235782086

Epoch: 6| Step: 7
Training loss: 3.5900638417382424
Validation loss: 3.019769730983286

Epoch: 6| Step: 8
Training loss: 3.317765998439002
Validation loss: 3.020551049802556

Epoch: 6| Step: 9
Training loss: 3.217841158951629
Validation loss: 3.0212387412639203

Epoch: 6| Step: 10
Training loss: 3.628984563370536
Validation loss: 3.0205530205593867

Epoch: 6| Step: 11
Training loss: 3.254146571632564
Validation loss: 3.018480724969344

Epoch: 6| Step: 12
Training loss: 3.2949940888926346
Validation loss: 3.015076959981053

Epoch: 6| Step: 13
Training loss: 3.2052733125361774
Validation loss: 3.017266417350521

Epoch: 48| Step: 0
Training loss: 3.0289083658426965
Validation loss: 3.0147020765101553

Epoch: 6| Step: 1
Training loss: 2.6558246945241764
Validation loss: 3.0178193623504628

Epoch: 6| Step: 2
Training loss: 3.1931984023839335
Validation loss: 3.0211984574276047

Epoch: 6| Step: 3
Training loss: 2.5031722922745034
Validation loss: 3.018874874770755

Epoch: 6| Step: 4
Training loss: 3.545036208986089
Validation loss: 3.0181213151254127

Epoch: 6| Step: 5
Training loss: 3.084161870485947
Validation loss: 3.0214729935940468

Epoch: 6| Step: 6
Training loss: 3.7466019811736704
Validation loss: 3.0177903534501054

Epoch: 6| Step: 7
Training loss: 3.7282822197684684
Validation loss: 3.0121493472158503

Epoch: 6| Step: 8
Training loss: 3.0359490536221068
Validation loss: 3.02217644071779

Epoch: 6| Step: 9
Training loss: 2.1708705418107637
Validation loss: 3.017100234367168

Epoch: 6| Step: 10
Training loss: 3.5337777332125775
Validation loss: 3.020003132075898

Epoch: 6| Step: 11
Training loss: 3.479168067672965
Validation loss: 3.0146621594354115

Epoch: 6| Step: 12
Training loss: 3.8298990926572105
Validation loss: 3.0198729287176063

Epoch: 6| Step: 13
Training loss: 4.70764733552429
Validation loss: 3.010938144848544

Epoch: 49| Step: 0
Training loss: 2.8415064083190216
Validation loss: 3.012233768354758

Epoch: 6| Step: 1
Training loss: 3.0410035512264333
Validation loss: 3.0150885985049634

Epoch: 6| Step: 2
Training loss: 3.2224923017008877
Validation loss: 3.0146746780107754

Epoch: 6| Step: 3
Training loss: 2.8263172252004196
Validation loss: 3.024913072807464

Epoch: 6| Step: 4
Training loss: 3.7985128002164483
Validation loss: 3.0275352338608297

Epoch: 6| Step: 5
Training loss: 2.737695214962187
Validation loss: 3.02804119204472

Epoch: 6| Step: 6
Training loss: 2.683450353531014
Validation loss: 3.0230570123920373

Epoch: 6| Step: 7
Training loss: 3.3962277298450925
Validation loss: 3.0279147938216657

Epoch: 6| Step: 8
Training loss: 2.7830721426141425
Validation loss: 3.0266481919551707

Epoch: 6| Step: 9
Training loss: 4.249222852673718
Validation loss: 3.0215450128877803

Epoch: 6| Step: 10
Training loss: 3.4324859116522832
Validation loss: 3.018824621856269

Epoch: 6| Step: 11
Training loss: 3.576395874675031
Validation loss: 3.025939947886169

Epoch: 6| Step: 12
Training loss: 3.894612180429485
Validation loss: 3.0229202501726604

Epoch: 6| Step: 13
Training loss: 3.4265049656022497
Validation loss: 3.017660958533447

Epoch: 50| Step: 0
Training loss: 2.88784441854858
Validation loss: 3.010541319257835

Epoch: 6| Step: 1
Training loss: 3.6650235800615563
Validation loss: 3.009474404652106

Epoch: 6| Step: 2
Training loss: 3.621251239664473
Validation loss: 3.013754232353652

Epoch: 6| Step: 3
Training loss: 3.0954468052402815
Validation loss: 3.01433762947843

Epoch: 6| Step: 4
Training loss: 2.7472857171480194
Validation loss: 3.0097496967807595

Epoch: 6| Step: 5
Training loss: 3.335386851691937
Validation loss: 3.0085873429744554

Epoch: 6| Step: 6
Training loss: 4.029782996760069
Validation loss: 3.0078543702860165

Epoch: 6| Step: 7
Training loss: 2.8952988238765642
Validation loss: 3.0066440553835614

Epoch: 6| Step: 8
Training loss: 3.481044392018594
Validation loss: 3.0120724425305228

Epoch: 6| Step: 9
Training loss: 3.1509988745103557
Validation loss: 3.007262552030347

Epoch: 6| Step: 10
Training loss: 3.5361723224715544
Validation loss: 3.004827155351355

Epoch: 6| Step: 11
Training loss: 3.2870409046641855
Validation loss: 3.00494051786529

Epoch: 6| Step: 12
Training loss: 2.7176948341355063
Validation loss: 3.0034516134761673

Epoch: 6| Step: 13
Training loss: 3.617661644857402
Validation loss: 3.0052397970811455

Epoch: 51| Step: 0
Training loss: 3.473636793424413
Validation loss: 3.0050837467376086

Epoch: 6| Step: 1
Training loss: 2.6595845553430038
Validation loss: 3.000934732082589

Epoch: 6| Step: 2
Training loss: 3.540628318414707
Validation loss: 2.999785263484169

Epoch: 6| Step: 3
Training loss: 3.2381160312006356
Validation loss: 3.0018194263321645

Epoch: 6| Step: 4
Training loss: 2.900132991766771
Validation loss: 3.004269037235824

Epoch: 6| Step: 5
Training loss: 3.859641370963262
Validation loss: 3.0077957031394673

Epoch: 6| Step: 6
Training loss: 3.4662481685046185
Validation loss: 3.0031801684507204

Epoch: 6| Step: 7
Training loss: 3.574110686122532
Validation loss: 2.9999326994056887

Epoch: 6| Step: 8
Training loss: 2.704371346915775
Validation loss: 2.994721631501429

Epoch: 6| Step: 9
Training loss: 2.9169338285612647
Validation loss: 3.000097707298968

Epoch: 6| Step: 10
Training loss: 3.5895780811651457
Validation loss: 2.997592845603909

Epoch: 6| Step: 11
Training loss: 3.4767100785039156
Validation loss: 2.99606465396138

Epoch: 6| Step: 12
Training loss: 3.5861934661929955
Validation loss: 2.994641426815621

Epoch: 6| Step: 13
Training loss: 2.448731296345199
Validation loss: 2.9951784790251086

Epoch: 52| Step: 0
Training loss: 4.197247902329964
Validation loss: 2.995650345307983

Epoch: 6| Step: 1
Training loss: 2.6826352291382305
Validation loss: 2.9939497385481477

Epoch: 6| Step: 2
Training loss: 2.3959088742053805
Validation loss: 2.9934833943705987

Epoch: 6| Step: 3
Training loss: 3.133629138321586
Validation loss: 2.9960095740203014

Epoch: 6| Step: 4
Training loss: 3.6577215901206808
Validation loss: 2.9945010887017736

Epoch: 6| Step: 5
Training loss: 3.120570285713984
Validation loss: 2.9947063012638786

Epoch: 6| Step: 6
Training loss: 2.544715105909768
Validation loss: 2.9964065667614044

Epoch: 6| Step: 7
Training loss: 3.7861692098698656
Validation loss: 2.993364803608201

Epoch: 6| Step: 8
Training loss: 2.9355012302568286
Validation loss: 2.9926255813974083

Epoch: 6| Step: 9
Training loss: 3.777000877180293
Validation loss: 2.9950866730832013

Epoch: 6| Step: 10
Training loss: 3.942315200025556
Validation loss: 2.9908905589972328

Epoch: 6| Step: 11
Training loss: 2.9931071887439225
Validation loss: 2.9931222016978634

Epoch: 6| Step: 12
Training loss: 3.271727777792269
Validation loss: 2.993468993849435

Epoch: 6| Step: 13
Training loss: 2.8210432210246115
Validation loss: 2.9904033600574635

Epoch: 53| Step: 0
Training loss: 3.6440787898233524
Validation loss: 2.991645108607828

Epoch: 6| Step: 1
Training loss: 3.3395199267356457
Validation loss: 2.993497265565357

Epoch: 6| Step: 2
Training loss: 2.8131618992458307
Validation loss: 2.9965608155226513

Epoch: 6| Step: 3
Training loss: 2.572941510985319
Validation loss: 2.9895615189765348

Epoch: 6| Step: 4
Training loss: 3.5963487599760606
Validation loss: 2.9902986917819083

Epoch: 6| Step: 5
Training loss: 3.319963360549792
Validation loss: 2.9951833492201434

Epoch: 6| Step: 6
Training loss: 4.0762855795413255
Validation loss: 2.991454863342414

Epoch: 6| Step: 7
Training loss: 3.6708868766860387
Validation loss: 2.992713930964345

Epoch: 6| Step: 8
Training loss: 2.8804005196014515
Validation loss: 2.989256110985849

Epoch: 6| Step: 9
Training loss: 2.977379714240116
Validation loss: 2.9909450046440362

Epoch: 6| Step: 10
Training loss: 3.508385558355042
Validation loss: 2.9894458692984887

Epoch: 6| Step: 11
Training loss: 2.9902426671586526
Validation loss: 2.9891712055719415

Epoch: 6| Step: 12
Training loss: 3.0976427037061938
Validation loss: 2.9896371024877038

Epoch: 6| Step: 13
Training loss: 3.1404277682646975
Validation loss: 2.9876964074267094

Epoch: 54| Step: 0
Training loss: 3.887925525203173
Validation loss: 2.98845799493317

Epoch: 6| Step: 1
Training loss: 2.9583748469775584
Validation loss: 2.987931557160196

Epoch: 6| Step: 2
Training loss: 3.1870820014489682
Validation loss: 2.98943248355477

Epoch: 6| Step: 3
Training loss: 3.365394203256217
Validation loss: 2.9867459129836105

Epoch: 6| Step: 4
Training loss: 2.5622578948486736
Validation loss: 2.9892627609504685

Epoch: 6| Step: 5
Training loss: 2.560271620049837
Validation loss: 2.99281672705203

Epoch: 6| Step: 6
Training loss: 2.929195271149303
Validation loss: 2.9952479431774184

Epoch: 6| Step: 7
Training loss: 2.7808382393855906
Validation loss: 3.0068610465857804

Epoch: 6| Step: 8
Training loss: 3.45865392156511
Validation loss: 3.0173993721006935

Epoch: 6| Step: 9
Training loss: 4.084037616223977
Validation loss: 3.0107058198052497

Epoch: 6| Step: 10
Training loss: 3.595859737601349
Validation loss: 2.996635372118867

Epoch: 6| Step: 11
Training loss: 2.9983143839326556
Validation loss: 2.990369676973372

Epoch: 6| Step: 12
Training loss: 3.632026045794091
Validation loss: 2.99081619691672

Epoch: 6| Step: 13
Training loss: 3.66222525858316
Validation loss: 2.984947982406029

Epoch: 55| Step: 0
Training loss: 3.6326389722500583
Validation loss: 2.988054232975774

Epoch: 6| Step: 1
Training loss: 2.738004618778053
Validation loss: 2.988813259856022

Epoch: 6| Step: 2
Training loss: 3.5910408755265024
Validation loss: 2.9895030674008836

Epoch: 6| Step: 3
Training loss: 3.35200465560262
Validation loss: 2.9891983738515107

Epoch: 6| Step: 4
Training loss: 3.3015852270684576
Validation loss: 2.992061273364949

Epoch: 6| Step: 5
Training loss: 3.867456538542437
Validation loss: 2.989258687270003

Epoch: 6| Step: 6
Training loss: 2.566398539306577
Validation loss: 2.987555553434465

Epoch: 6| Step: 7
Training loss: 3.9542474773953886
Validation loss: 2.9859436925602325

Epoch: 6| Step: 8
Training loss: 3.3617694217055334
Validation loss: 2.9857812184290196

Epoch: 6| Step: 9
Training loss: 2.8362367750576563
Validation loss: 2.983800983079389

Epoch: 6| Step: 10
Training loss: 2.581769090233366
Validation loss: 2.9809372643788463

Epoch: 6| Step: 11
Training loss: 2.494982834873514
Validation loss: 2.983469227688315

Epoch: 6| Step: 12
Training loss: 3.603732103084354
Validation loss: 2.9801886678834677

Epoch: 6| Step: 13
Training loss: 3.7249656470846078
Validation loss: 2.9799223501551655

Epoch: 56| Step: 0
Training loss: 3.0418183450025644
Validation loss: 2.9821804718340417

Epoch: 6| Step: 1
Training loss: 3.7019329486299917
Validation loss: 2.9792635464694097

Epoch: 6| Step: 2
Training loss: 3.6963518870569154
Validation loss: 2.984180458916834

Epoch: 6| Step: 3
Training loss: 3.235017132249421
Validation loss: 2.9812899531933934

Epoch: 6| Step: 4
Training loss: 2.6899587340185453
Validation loss: 2.982061375696829

Epoch: 6| Step: 5
Training loss: 2.9098311479483328
Validation loss: 2.9843043343823172

Epoch: 6| Step: 6
Training loss: 3.203207173107549
Validation loss: 2.9801527966055157

Epoch: 6| Step: 7
Training loss: 3.5222683000676045
Validation loss: 2.9866914028067755

Epoch: 6| Step: 8
Training loss: 3.0562989650306562
Validation loss: 2.9832897097386946

Epoch: 6| Step: 9
Training loss: 3.082977033768995
Validation loss: 2.9817850241095236

Epoch: 6| Step: 10
Training loss: 2.7671894023938264
Validation loss: 2.9793641469329395

Epoch: 6| Step: 11
Training loss: 3.8229613063329895
Validation loss: 2.978720362132593

Epoch: 6| Step: 12
Training loss: 3.150104545190506
Validation loss: 2.9786083505157754

Epoch: 6| Step: 13
Training loss: 3.9928765047629007
Validation loss: 2.977840731457142

Epoch: 57| Step: 0
Training loss: 3.235042189922885
Validation loss: 2.9783547520812608

Epoch: 6| Step: 1
Training loss: 3.271469799407829
Validation loss: 2.9781679481138603

Epoch: 6| Step: 2
Training loss: 3.6396766049436615
Validation loss: 2.977262720823895

Epoch: 6| Step: 3
Training loss: 3.1547385647605264
Validation loss: 2.98048741340667

Epoch: 6| Step: 4
Training loss: 3.808889962439409
Validation loss: 2.975924126421877

Epoch: 6| Step: 5
Training loss: 3.676416453692237
Validation loss: 2.9734251178168107

Epoch: 6| Step: 6
Training loss: 3.2558608395505106
Validation loss: 2.978952212667691

Epoch: 6| Step: 7
Training loss: 2.908967910951546
Validation loss: 2.974729613193726

Epoch: 6| Step: 8
Training loss: 3.106667878501339
Validation loss: 2.977205346975014

Epoch: 6| Step: 9
Training loss: 2.083790792467531
Validation loss: 2.9791115680340625

Epoch: 6| Step: 10
Training loss: 2.6526698500518346
Validation loss: 2.9787427906305113

Epoch: 6| Step: 11
Training loss: 4.003290253681914
Validation loss: 2.9794851526265176

Epoch: 6| Step: 12
Training loss: 3.3715223126160345
Validation loss: 2.975895247546486

Epoch: 6| Step: 13
Training loss: 3.0600323758874666
Validation loss: 2.974830937478608

Epoch: 58| Step: 0
Training loss: 2.7419814333965333
Validation loss: 2.9766325742800404

Epoch: 6| Step: 1
Training loss: 2.915331689405672
Validation loss: 2.9745902472369807

Epoch: 6| Step: 2
Training loss: 3.0468123991966487
Validation loss: 2.973495700563975

Epoch: 6| Step: 3
Training loss: 3.6314250962921526
Validation loss: 2.9756342412332017

Epoch: 6| Step: 4
Training loss: 3.1599757799596566
Validation loss: 2.977898415897824

Epoch: 6| Step: 5
Training loss: 4.07980627721998
Validation loss: 2.978342167782749

Epoch: 6| Step: 6
Training loss: 2.8859386499853894
Validation loss: 2.9730042179040317

Epoch: 6| Step: 7
Training loss: 4.01371345591296
Validation loss: 2.977372846583568

Epoch: 6| Step: 8
Training loss: 2.908190827763205
Validation loss: 2.9753155527261055

Epoch: 6| Step: 9
Training loss: 2.91476472876839
Validation loss: 2.9785697442834707

Epoch: 6| Step: 10
Training loss: 2.6513687161885557
Validation loss: 2.983198598377806

Epoch: 6| Step: 11
Training loss: 3.9302631055201993
Validation loss: 2.979708925052047

Epoch: 6| Step: 12
Training loss: 3.100200363575155
Validation loss: 2.9814406915816174

Epoch: 6| Step: 13
Training loss: 3.3252047769689095
Validation loss: 2.974600240332085

Epoch: 59| Step: 0
Training loss: 3.3057242135867817
Validation loss: 2.974505627343867

Epoch: 6| Step: 1
Training loss: 3.1889639092045217
Validation loss: 2.972162837872592

Epoch: 6| Step: 2
Training loss: 3.117158435504383
Validation loss: 2.975658234282897

Epoch: 6| Step: 3
Training loss: 2.8773952954926854
Validation loss: 2.972659637534189

Epoch: 6| Step: 4
Training loss: 3.6152756584031978
Validation loss: 2.972995263700641

Epoch: 6| Step: 5
Training loss: 3.369143455614753
Validation loss: 2.9733213021099205

Epoch: 6| Step: 6
Training loss: 2.87586232397264
Validation loss: 2.9707406762290764

Epoch: 6| Step: 7
Training loss: 3.099367840207279
Validation loss: 2.971107673643133

Epoch: 6| Step: 8
Training loss: 3.821677246966372
Validation loss: 2.9704968384869077

Epoch: 6| Step: 9
Training loss: 3.2187128157458504
Validation loss: 2.971648514868246

Epoch: 6| Step: 10
Training loss: 3.584490315744964
Validation loss: 2.9729559662942138

Epoch: 6| Step: 11
Training loss: 3.1934909245171097
Validation loss: 2.9709946501876825

Epoch: 6| Step: 12
Training loss: 3.579254105506094
Validation loss: 2.9729774673137994

Epoch: 6| Step: 13
Training loss: 2.0658133508911725
Validation loss: 2.9746607299445538

Epoch: 60| Step: 0
Training loss: 2.0924469038449116
Validation loss: 2.9692624403816748

Epoch: 6| Step: 1
Training loss: 3.4707767648349783
Validation loss: 2.969265298211385

Epoch: 6| Step: 2
Training loss: 2.685580166697057
Validation loss: 2.970857027313122

Epoch: 6| Step: 3
Training loss: 3.423441071292994
Validation loss: 2.971267605034656

Epoch: 6| Step: 4
Training loss: 3.6955274716970217
Validation loss: 2.9678112434793884

Epoch: 6| Step: 5
Training loss: 3.1935427365170703
Validation loss: 2.9690867744102105

Epoch: 6| Step: 6
Training loss: 3.672955812507791
Validation loss: 2.9725698596743837

Epoch: 6| Step: 7
Training loss: 3.6191249462103046
Validation loss: 2.9710977507726826

Epoch: 6| Step: 8
Training loss: 3.2489139502892774
Validation loss: 2.9682569732335775

Epoch: 6| Step: 9
Training loss: 3.3211436230009097
Validation loss: 2.9711278540708204

Epoch: 6| Step: 10
Training loss: 2.72675443044813
Validation loss: 2.968325131059356

Epoch: 6| Step: 11
Training loss: 3.451950356764124
Validation loss: 2.9717239035237375

Epoch: 6| Step: 12
Training loss: 3.6663545706890783
Validation loss: 2.9781420341376164

Epoch: 6| Step: 13
Training loss: 2.611124331754217
Validation loss: 2.9799552643636167

Epoch: 61| Step: 0
Training loss: 2.892234890063696
Validation loss: 2.977473616833017

Epoch: 6| Step: 1
Training loss: 3.4405581655775936
Validation loss: 2.9773219887517817

Epoch: 6| Step: 2
Training loss: 3.2773929269440685
Validation loss: 2.973354907590995

Epoch: 6| Step: 3
Training loss: 3.729838277056801
Validation loss: 2.9701277691506833

Epoch: 6| Step: 4
Training loss: 3.238182296437453
Validation loss: 2.9665377022200157

Epoch: 6| Step: 5
Training loss: 3.1889843943786134
Validation loss: 2.966883395404826

Epoch: 6| Step: 6
Training loss: 3.2143874742657887
Validation loss: 2.96319543510888

Epoch: 6| Step: 7
Training loss: 2.7422386229876627
Validation loss: 2.966465876251492

Epoch: 6| Step: 8
Training loss: 4.079077364626276
Validation loss: 2.9645777556301085

Epoch: 6| Step: 9
Training loss: 3.2135088572174557
Validation loss: 2.96554720292779

Epoch: 6| Step: 10
Training loss: 3.2860113566429328
Validation loss: 2.9615194629898487

Epoch: 6| Step: 11
Training loss: 2.7513776276244744
Validation loss: 2.966303100121716

Epoch: 6| Step: 12
Training loss: 3.0634290881821165
Validation loss: 2.970059241827568

Epoch: 6| Step: 13
Training loss: 3.2505431088234062
Validation loss: 2.9677552029354137

Epoch: 62| Step: 0
Training loss: 3.7768915452078704
Validation loss: 2.9629240546041804

Epoch: 6| Step: 1
Training loss: 3.4794943801740215
Validation loss: 2.965595164462782

Epoch: 6| Step: 2
Training loss: 3.2631883793849576
Validation loss: 2.9682588267021743

Epoch: 6| Step: 3
Training loss: 3.657432951661375
Validation loss: 2.9721233215823992

Epoch: 6| Step: 4
Training loss: 3.622719014183283
Validation loss: 2.9771677498424167

Epoch: 6| Step: 5
Training loss: 2.3766820873742875
Validation loss: 2.972717287116839

Epoch: 6| Step: 6
Training loss: 3.092513791102109
Validation loss: 2.9703479173238483

Epoch: 6| Step: 7
Training loss: 3.0496209706413016
Validation loss: 2.9686923804571728

Epoch: 6| Step: 8
Training loss: 2.2079214275726553
Validation loss: 2.9675114533459697

Epoch: 6| Step: 9
Training loss: 3.5511469049470676
Validation loss: 2.9691858132573206

Epoch: 6| Step: 10
Training loss: 3.5950283264826846
Validation loss: 2.9642219903724465

Epoch: 6| Step: 11
Training loss: 2.879132493548234
Validation loss: 2.963116481209585

Epoch: 6| Step: 12
Training loss: 3.791247432014861
Validation loss: 2.961560806166435

Epoch: 6| Step: 13
Training loss: 2.1138223741481834
Validation loss: 2.962581543366773

Epoch: 63| Step: 0
Training loss: 3.9273932188829193
Validation loss: 2.9626148051231613

Epoch: 6| Step: 1
Training loss: 2.4623126350807727
Validation loss: 2.9635231156904585

Epoch: 6| Step: 2
Training loss: 2.920326189608095
Validation loss: 2.9595325719307

Epoch: 6| Step: 3
Training loss: 2.6467385933596823
Validation loss: 2.9626641198918553

Epoch: 6| Step: 4
Training loss: 3.4238392665962474
Validation loss: 2.9608202967428268

Epoch: 6| Step: 5
Training loss: 3.803330949208089
Validation loss: 2.9611121100836186

Epoch: 6| Step: 6
Training loss: 3.550631915520351
Validation loss: 2.962861448631784

Epoch: 6| Step: 7
Training loss: 2.6950743639139843
Validation loss: 2.9562306578458966

Epoch: 6| Step: 8
Training loss: 3.1864079119228523
Validation loss: 2.9592648613412953

Epoch: 6| Step: 9
Training loss: 3.3313258006792124
Validation loss: 2.9588836023544807

Epoch: 6| Step: 10
Training loss: 3.267751485053049
Validation loss: 2.959446022001049

Epoch: 6| Step: 11
Training loss: 2.5795477438211116
Validation loss: 2.961705175544339

Epoch: 6| Step: 12
Training loss: 3.573851586332708
Validation loss: 2.9728373276083673

Epoch: 6| Step: 13
Training loss: 4.027282181573515
Validation loss: 2.97866146027166

Epoch: 64| Step: 0
Training loss: 3.163079605967729
Validation loss: 2.982409672327662

Epoch: 6| Step: 1
Training loss: 3.2067200373796783
Validation loss: 2.999530611951596

Epoch: 6| Step: 2
Training loss: 3.903860108761493
Validation loss: 3.0039723939471696

Epoch: 6| Step: 3
Training loss: 3.1898337403980532
Validation loss: 2.9712016156985195

Epoch: 6| Step: 4
Training loss: 3.003856246790015
Validation loss: 2.9654033715911385

Epoch: 6| Step: 5
Training loss: 3.690892873114264
Validation loss: 2.9733856157157286

Epoch: 6| Step: 6
Training loss: 3.4165959854878594
Validation loss: 2.9634970745191533

Epoch: 6| Step: 7
Training loss: 2.963660766854265
Validation loss: 2.9620497562563597

Epoch: 6| Step: 8
Training loss: 3.072498581888292
Validation loss: 2.9609340886649336

Epoch: 6| Step: 9
Training loss: 3.126444063321636
Validation loss: 2.957861206797053

Epoch: 6| Step: 10
Training loss: 3.1607193227116657
Validation loss: 2.9602808078948373

Epoch: 6| Step: 11
Training loss: 3.1405340532637873
Validation loss: 2.957336084957184

Epoch: 6| Step: 12
Training loss: 3.0323009438844006
Validation loss: 2.954254525561089

Epoch: 6| Step: 13
Training loss: 3.3268622210047756
Validation loss: 2.955426559508598

Epoch: 65| Step: 0
Training loss: 2.6696064559707566
Validation loss: 2.953769271306055

Epoch: 6| Step: 1
Training loss: 4.502255192550469
Validation loss: 2.95480984685105

Epoch: 6| Step: 2
Training loss: 3.4463908957928733
Validation loss: 2.9524563971516815

Epoch: 6| Step: 3
Training loss: 2.9706349060933577
Validation loss: 2.9549653881064177

Epoch: 6| Step: 4
Training loss: 3.479772016357916
Validation loss: 2.956289860937245

Epoch: 6| Step: 5
Training loss: 2.8596848283516985
Validation loss: 2.955798490527267

Epoch: 6| Step: 6
Training loss: 2.6954869310631477
Validation loss: 2.954667478896062

Epoch: 6| Step: 7
Training loss: 3.1260087483211043
Validation loss: 2.9527929809208975

Epoch: 6| Step: 8
Training loss: 3.083775016148183
Validation loss: 2.9543006893184094

Epoch: 6| Step: 9
Training loss: 2.9292263634478424
Validation loss: 2.955000508884444

Epoch: 6| Step: 10
Training loss: 3.4421474598180475
Validation loss: 2.954721901370154

Epoch: 6| Step: 11
Training loss: 3.4996431713769525
Validation loss: 2.9558544221117984

Epoch: 6| Step: 12
Training loss: 3.249012870530607
Validation loss: 2.95472076996485

Epoch: 6| Step: 13
Training loss: 2.9414064121119643
Validation loss: 2.957530411136307

Epoch: 66| Step: 0
Training loss: 2.6699430385328466
Validation loss: 2.952723077135996

Epoch: 6| Step: 1
Training loss: 2.8097286557634984
Validation loss: 2.956851008690037

Epoch: 6| Step: 2
Training loss: 3.47773184666418
Validation loss: 2.958320959661229

Epoch: 6| Step: 3
Training loss: 3.636071759127481
Validation loss: 2.9638233992011225

Epoch: 6| Step: 4
Training loss: 3.460561073102717
Validation loss: 2.955781492625076

Epoch: 6| Step: 5
Training loss: 3.0170185249222654
Validation loss: 2.9525412816925933

Epoch: 6| Step: 6
Training loss: 3.7133531919412928
Validation loss: 2.9490594979671054

Epoch: 6| Step: 7
Training loss: 2.8834803358174472
Validation loss: 2.9505628913298976

Epoch: 6| Step: 8
Training loss: 3.566234705665222
Validation loss: 2.9527354545866893

Epoch: 6| Step: 9
Training loss: 3.2313775810274774
Validation loss: 2.950637023692621

Epoch: 6| Step: 10
Training loss: 3.4725468106612887
Validation loss: 2.9506535056003034

Epoch: 6| Step: 11
Training loss: 3.142960472389982
Validation loss: 2.948908044129936

Epoch: 6| Step: 12
Training loss: 3.23063731186215
Validation loss: 2.9504130882613153

Epoch: 6| Step: 13
Training loss: 2.650901795740076
Validation loss: 2.951048948209345

Epoch: 67| Step: 0
Training loss: 3.4366845290727754
Validation loss: 2.951418303878552

Epoch: 6| Step: 1
Training loss: 2.7880963701096406
Validation loss: 2.948521920271512

Epoch: 6| Step: 2
Training loss: 3.4103044650279326
Validation loss: 2.9507267790333676

Epoch: 6| Step: 3
Training loss: 3.08590396911174
Validation loss: 2.9503363904003295

Epoch: 6| Step: 4
Training loss: 3.3591035955046147
Validation loss: 2.9539534507130516

Epoch: 6| Step: 5
Training loss: 2.501481952121004
Validation loss: 2.9541225169072645

Epoch: 6| Step: 6
Training loss: 2.9433412304517046
Validation loss: 2.9573675809578193

Epoch: 6| Step: 7
Training loss: 3.9033350940660196
Validation loss: 2.9578315942566804

Epoch: 6| Step: 8
Training loss: 3.3775793038862205
Validation loss: 2.956663407097596

Epoch: 6| Step: 9
Training loss: 2.9738298823758433
Validation loss: 2.957951767362065

Epoch: 6| Step: 10
Training loss: 3.0987326831033695
Validation loss: 2.9592722613517553

Epoch: 6| Step: 11
Training loss: 2.8885947856198615
Validation loss: 2.9649665977086355

Epoch: 6| Step: 12
Training loss: 3.823821221517928
Validation loss: 2.9633482246292844

Epoch: 6| Step: 13
Training loss: 3.5271384009388465
Validation loss: 2.975729631609092

Epoch: 68| Step: 0
Training loss: 3.1136451422372047
Validation loss: 2.9877703297541536

Epoch: 6| Step: 1
Training loss: 3.3763504152360793
Validation loss: 2.9792880042112495

Epoch: 6| Step: 2
Training loss: 3.476624906172683
Validation loss: 2.970476221389162

Epoch: 6| Step: 3
Training loss: 3.6757573807009276
Validation loss: 2.9546832233747082

Epoch: 6| Step: 4
Training loss: 3.034082721183517
Validation loss: 2.951742310054446

Epoch: 6| Step: 5
Training loss: 3.1297089765005133
Validation loss: 2.948895807098493

Epoch: 6| Step: 6
Training loss: 3.0442180297205366
Validation loss: 2.9478740549191054

Epoch: 6| Step: 7
Training loss: 3.130291692773717
Validation loss: 2.9479774084166825

Epoch: 6| Step: 8
Training loss: 2.7182606223754973
Validation loss: 2.957704099896482

Epoch: 6| Step: 9
Training loss: 3.2219708077868225
Validation loss: 2.9731618605849777

Epoch: 6| Step: 10
Training loss: 3.4946013094153643
Validation loss: 2.972830002757397

Epoch: 6| Step: 11
Training loss: 3.4489242756340155
Validation loss: 2.970883496699503

Epoch: 6| Step: 12
Training loss: 3.0230853050580153
Validation loss: 2.9643059083980985

Epoch: 6| Step: 13
Training loss: 3.633340776651673
Validation loss: 2.973970354601605

Epoch: 69| Step: 0
Training loss: 2.97421211901267
Validation loss: 2.97275266989142

Epoch: 6| Step: 1
Training loss: 2.820704044626633
Validation loss: 2.9529128364395962

Epoch: 6| Step: 2
Training loss: 3.7740606895139837
Validation loss: 2.949564174065155

Epoch: 6| Step: 3
Training loss: 3.7045307308059736
Validation loss: 2.9487285295417953

Epoch: 6| Step: 4
Training loss: 3.9879294902571556
Validation loss: 2.9472651831227803

Epoch: 6| Step: 5
Training loss: 3.1209351615098693
Validation loss: 2.9479776397374455

Epoch: 6| Step: 6
Training loss: 3.5354842734555563
Validation loss: 2.947909619346018

Epoch: 6| Step: 7
Training loss: 2.6098889969646315
Validation loss: 2.9497904022963755

Epoch: 6| Step: 8
Training loss: 2.6990297198869464
Validation loss: 2.948068365645492

Epoch: 6| Step: 9
Training loss: 3.3033796748180455
Validation loss: 2.959358677758044

Epoch: 6| Step: 10
Training loss: 3.420554825243998
Validation loss: 2.9704462064225954

Epoch: 6| Step: 11
Training loss: 2.470558180345718
Validation loss: 2.9668939337716895

Epoch: 6| Step: 12
Training loss: 2.939747376779547
Validation loss: 2.960329073850552

Epoch: 6| Step: 13
Training loss: 3.8994997828591496
Validation loss: 2.954491641918989

Epoch: 70| Step: 0
Training loss: 2.504941538815731
Validation loss: 2.945690978603504

Epoch: 6| Step: 1
Training loss: 3.624632981235097
Validation loss: 2.9434377544704367

Epoch: 6| Step: 2
Training loss: 2.76591757395985
Validation loss: 2.9452766509192005

Epoch: 6| Step: 3
Training loss: 3.539576343681405
Validation loss: 2.9463602587718034

Epoch: 6| Step: 4
Training loss: 2.989033523315424
Validation loss: 2.9456239245554183

Epoch: 6| Step: 5
Training loss: 3.4669517461006056
Validation loss: 2.9475689311169524

Epoch: 6| Step: 6
Training loss: 4.075582947019019
Validation loss: 2.9436187744153384

Epoch: 6| Step: 7
Training loss: 3.0376566403034895
Validation loss: 2.9446872763383514

Epoch: 6| Step: 8
Training loss: 2.941029964051826
Validation loss: 2.9441781863622953

Epoch: 6| Step: 9
Training loss: 3.075640300052992
Validation loss: 2.9430142261720924

Epoch: 6| Step: 10
Training loss: 3.618611065926781
Validation loss: 2.9416350455857585

Epoch: 6| Step: 11
Training loss: 3.3430075133042685
Validation loss: 2.942493811536285

Epoch: 6| Step: 12
Training loss: 2.4757136385332474
Validation loss: 2.9427424150185386

Epoch: 6| Step: 13
Training loss: 3.6607682440100655
Validation loss: 2.942286827194363

Epoch: 71| Step: 0
Training loss: 2.606469369707964
Validation loss: 2.943570986942071

Epoch: 6| Step: 1
Training loss: 3.2864395519914926
Validation loss: 2.949645202919665

Epoch: 6| Step: 2
Training loss: 3.2831225183907105
Validation loss: 2.947744537468375

Epoch: 6| Step: 3
Training loss: 3.8126853522598627
Validation loss: 2.9521752917263764

Epoch: 6| Step: 4
Training loss: 2.566077363701068
Validation loss: 2.946690212548325

Epoch: 6| Step: 5
Training loss: 3.333949048079168
Validation loss: 2.9510022853161755

Epoch: 6| Step: 6
Training loss: 3.2005116292119147
Validation loss: 2.9380660060497594

Epoch: 6| Step: 7
Training loss: 2.611090273356878
Validation loss: 2.9394952686741718

Epoch: 6| Step: 8
Training loss: 2.994970237826057
Validation loss: 2.94185542971173

Epoch: 6| Step: 9
Training loss: 3.6124582044038176
Validation loss: 2.9426768950361017

Epoch: 6| Step: 10
Training loss: 3.5898947561664762
Validation loss: 2.94122216871399

Epoch: 6| Step: 11
Training loss: 3.1158347959294797
Validation loss: 2.9433461498372173

Epoch: 6| Step: 12
Training loss: 3.167960320965975
Validation loss: 2.945592657209466

Epoch: 6| Step: 13
Training loss: 4.12978109079769
Validation loss: 2.94459998273412

Epoch: 72| Step: 0
Training loss: 3.4438935902424577
Validation loss: 2.944160294154518

Epoch: 6| Step: 1
Training loss: 2.6974589328980767
Validation loss: 2.940155427915067

Epoch: 6| Step: 2
Training loss: 2.6942216075326106
Validation loss: 2.9406513040100273

Epoch: 6| Step: 3
Training loss: 3.3385359852822334
Validation loss: 2.9392517232342876

Epoch: 6| Step: 4
Training loss: 3.4454915871645486
Validation loss: 2.937638439441209

Epoch: 6| Step: 5
Training loss: 3.190288744925916
Validation loss: 2.9399744763793083

Epoch: 6| Step: 6
Training loss: 3.143743380772806
Validation loss: 2.9427317152402073

Epoch: 6| Step: 7
Training loss: 3.1520602679033782
Validation loss: 2.9401627190726054

Epoch: 6| Step: 8
Training loss: 3.1751344967687274
Validation loss: 2.9370135391277854

Epoch: 6| Step: 9
Training loss: 3.185056310661933
Validation loss: 2.9396155678266984

Epoch: 6| Step: 10
Training loss: 3.403418807981106
Validation loss: 2.9368400050477184

Epoch: 6| Step: 11
Training loss: 3.119705139556602
Validation loss: 2.9373338661524975

Epoch: 6| Step: 12
Training loss: 3.463065223143522
Validation loss: 2.939294082612003

Epoch: 6| Step: 13
Training loss: 3.951343723091877
Validation loss: 2.9393456725545426

Epoch: 73| Step: 0
Training loss: 2.6150712752247527
Validation loss: 2.9368078323530393

Epoch: 6| Step: 1
Training loss: 3.617524034569229
Validation loss: 2.9398070600657475

Epoch: 6| Step: 2
Training loss: 3.149152272307531
Validation loss: 2.9369699021226996

Epoch: 6| Step: 3
Training loss: 3.257695696815735
Validation loss: 2.941474633437261

Epoch: 6| Step: 4
Training loss: 3.5449124590956216
Validation loss: 2.9412458175287

Epoch: 6| Step: 5
Training loss: 3.0648225035309
Validation loss: 2.951009159612689

Epoch: 6| Step: 6
Training loss: 4.041692412513976
Validation loss: 2.956859183783765

Epoch: 6| Step: 7
Training loss: 2.514982153220588
Validation loss: 2.9447424865725256

Epoch: 6| Step: 8
Training loss: 3.31092163485389
Validation loss: 2.937787127682103

Epoch: 6| Step: 9
Training loss: 3.379754849634501
Validation loss: 2.9331086987493484

Epoch: 6| Step: 10
Training loss: 2.9453523263844152
Validation loss: 2.9327863822591946

Epoch: 6| Step: 11
Training loss: 2.792135047526661
Validation loss: 2.9324067836196717

Epoch: 6| Step: 12
Training loss: 3.623863305080125
Validation loss: 2.937863955950364

Epoch: 6| Step: 13
Training loss: 2.8183964272837283
Validation loss: 2.9323591893603815

Epoch: 74| Step: 0
Training loss: 3.3936810059673657
Validation loss: 2.933166228938775

Epoch: 6| Step: 1
Training loss: 2.98471179280077
Validation loss: 2.9333126268280596

Epoch: 6| Step: 2
Training loss: 2.6887106719038165
Validation loss: 2.9330735631925906

Epoch: 6| Step: 3
Training loss: 3.0970887942766168
Validation loss: 2.933923150766757

Epoch: 6| Step: 4
Training loss: 2.682741965609165
Validation loss: 2.933615993932494

Epoch: 6| Step: 5
Training loss: 3.039337224237264
Validation loss: 2.9307282598825504

Epoch: 6| Step: 6
Training loss: 3.5763038765063375
Validation loss: 2.9321972092222297

Epoch: 6| Step: 7
Training loss: 3.2456533268647894
Validation loss: 2.9334740987988703

Epoch: 6| Step: 8
Training loss: 3.3895270332173384
Validation loss: 2.9322170699134786

Epoch: 6| Step: 9
Training loss: 3.393610751560271
Validation loss: 2.931598184768122

Epoch: 6| Step: 10
Training loss: 2.5668259368955706
Validation loss: 2.93419611178283

Epoch: 6| Step: 11
Training loss: 3.5687166817040072
Validation loss: 2.9346927921589456

Epoch: 6| Step: 12
Training loss: 3.246423954700363
Validation loss: 2.935499420731089

Epoch: 6| Step: 13
Training loss: 4.445055050761113
Validation loss: 2.93913427014947

Epoch: 75| Step: 0
Training loss: 2.5399590889947596
Validation loss: 2.93198411012331

Epoch: 6| Step: 1
Training loss: 3.3394302558361284
Validation loss: 2.934321254294943

Epoch: 6| Step: 2
Training loss: 2.212798612454325
Validation loss: 2.931217245423606

Epoch: 6| Step: 3
Training loss: 3.8370774822430063
Validation loss: 2.9351466222486575

Epoch: 6| Step: 4
Training loss: 4.0304593042690735
Validation loss: 2.9313779600141907

Epoch: 6| Step: 5
Training loss: 3.3312520841266346
Validation loss: 2.92961394011874

Epoch: 6| Step: 6
Training loss: 3.2577112122668725
Validation loss: 2.9315155044789885

Epoch: 6| Step: 7
Training loss: 3.237664507953913
Validation loss: 2.9295072294168003

Epoch: 6| Step: 8
Training loss: 4.079344585358505
Validation loss: 2.9336205958030273

Epoch: 6| Step: 9
Training loss: 3.009699400532781
Validation loss: 2.929474609515488

Epoch: 6| Step: 10
Training loss: 3.2063272983684454
Validation loss: 2.9288896771883346

Epoch: 6| Step: 11
Training loss: 2.5424235941791387
Validation loss: 2.929965262860356

Epoch: 6| Step: 12
Training loss: 2.4139084257567545
Validation loss: 2.9278403202406285

Epoch: 6| Step: 13
Training loss: 3.476229053751071
Validation loss: 2.9319692003183366

Epoch: 76| Step: 0
Training loss: 3.247204972536688
Validation loss: 2.9306094277044052

Epoch: 6| Step: 1
Training loss: 3.2910292446862095
Validation loss: 2.928028533152332

Epoch: 6| Step: 2
Training loss: 2.3392513588781836
Validation loss: 2.929154097807646

Epoch: 6| Step: 3
Training loss: 3.5541439101879613
Validation loss: 2.9300666827308897

Epoch: 6| Step: 4
Training loss: 3.457065043311173
Validation loss: 2.930967792958376

Epoch: 6| Step: 5
Training loss: 3.216806954864292
Validation loss: 2.9286796331451677

Epoch: 6| Step: 6
Training loss: 3.1564040949001972
Validation loss: 2.928528047127215

Epoch: 6| Step: 7
Training loss: 2.6887811667650166
Validation loss: 2.928944318680075

Epoch: 6| Step: 8
Training loss: 3.647470480869376
Validation loss: 2.9266685939687824

Epoch: 6| Step: 9
Training loss: 2.665693840756835
Validation loss: 2.9293851516742957

Epoch: 6| Step: 10
Training loss: 2.9714344937663744
Validation loss: 2.92793600687901

Epoch: 6| Step: 11
Training loss: 3.7891257998498022
Validation loss: 2.925898819414729

Epoch: 6| Step: 12
Training loss: 3.037693372308983
Validation loss: 2.9274375233247008

Epoch: 6| Step: 13
Training loss: 4.024210379726419
Validation loss: 2.9267911047316537

Epoch: 77| Step: 0
Training loss: 3.5235414341655256
Validation loss: 2.924191225267915

Epoch: 6| Step: 1
Training loss: 2.704269784177014
Validation loss: 2.925977603524988

Epoch: 6| Step: 2
Training loss: 3.570917458064464
Validation loss: 2.926352220902853

Epoch: 6| Step: 3
Training loss: 3.863349134814971
Validation loss: 2.9264795840220597

Epoch: 6| Step: 4
Training loss: 2.726695759749399
Validation loss: 2.9262150540167857

Epoch: 6| Step: 5
Training loss: 3.149844780382508
Validation loss: 2.9255955914566227

Epoch: 6| Step: 6
Training loss: 2.772092939236242
Validation loss: 2.9263050284049807

Epoch: 6| Step: 7
Training loss: 3.6804610490161687
Validation loss: 2.9272247818622583

Epoch: 6| Step: 8
Training loss: 3.4613301418252505
Validation loss: 2.926898487291801

Epoch: 6| Step: 9
Training loss: 2.7873082561147973
Validation loss: 2.925759116490395

Epoch: 6| Step: 10
Training loss: 2.834567829541822
Validation loss: 2.9275397978762134

Epoch: 6| Step: 11
Training loss: 2.6510139468879146
Validation loss: 2.9279601517587173

Epoch: 6| Step: 12
Training loss: 3.1252496238191343
Validation loss: 2.9296590552914608

Epoch: 6| Step: 13
Training loss: 4.128614518208962
Validation loss: 2.9312612453110036

Epoch: 78| Step: 0
Training loss: 3.831061284207614
Validation loss: 2.935313061553372

Epoch: 6| Step: 1
Training loss: 3.0278615988542814
Validation loss: 2.9394525267058342

Epoch: 6| Step: 2
Training loss: 3.262461905421452
Validation loss: 2.9306882583838494

Epoch: 6| Step: 3
Training loss: 3.4061060883805037
Validation loss: 2.9273812519697717

Epoch: 6| Step: 4
Training loss: 3.887114262225598
Validation loss: 2.933095462328413

Epoch: 6| Step: 5
Training loss: 3.069350385495346
Validation loss: 2.9265540426158885

Epoch: 6| Step: 6
Training loss: 2.913495456045865
Validation loss: 2.920832926053093

Epoch: 6| Step: 7
Training loss: 2.7485764893937543
Validation loss: 2.924087764859044

Epoch: 6| Step: 8
Training loss: 3.2241899759438124
Validation loss: 2.923385704246701

Epoch: 6| Step: 9
Training loss: 2.648522389719678
Validation loss: 2.922603840692771

Epoch: 6| Step: 10
Training loss: 2.7413931454127596
Validation loss: 2.9169734008337453

Epoch: 6| Step: 11
Training loss: 3.8882648709109136
Validation loss: 2.9199710310767326

Epoch: 6| Step: 12
Training loss: 2.2871295983440865
Validation loss: 2.923676767958896

Epoch: 6| Step: 13
Training loss: 3.8288785231761087
Validation loss: 2.9197703347806767

Epoch: 79| Step: 0
Training loss: 3.110477424602204
Validation loss: 2.9213345268898836

Epoch: 6| Step: 1
Training loss: 2.782447985551098
Validation loss: 2.9192377471885744

Epoch: 6| Step: 2
Training loss: 3.120465307261993
Validation loss: 2.9213386636956096

Epoch: 6| Step: 3
Training loss: 3.390578027918443
Validation loss: 2.9203144455592613

Epoch: 6| Step: 4
Training loss: 3.5255423811693003
Validation loss: 2.9194598229199804

Epoch: 6| Step: 5
Training loss: 4.05941091614091
Validation loss: 2.9183586132408683

Epoch: 6| Step: 6
Training loss: 2.351042325604681
Validation loss: 2.919383909201626

Epoch: 6| Step: 7
Training loss: 3.186810886466066
Validation loss: 2.9199973928198566

Epoch: 6| Step: 8
Training loss: 3.6165428163854254
Validation loss: 2.9186459138160608

Epoch: 6| Step: 9
Training loss: 2.6902035266785322
Validation loss: 2.921051461214161

Epoch: 6| Step: 10
Training loss: 3.080188659735866
Validation loss: 2.9169161840728783

Epoch: 6| Step: 11
Training loss: 2.628246842507173
Validation loss: 2.919136918006083

Epoch: 6| Step: 12
Training loss: 3.6631029902045755
Validation loss: 2.923327968425189

Epoch: 6| Step: 13
Training loss: 3.4011878799547337
Validation loss: 2.920600118570709

Epoch: 80| Step: 0
Training loss: 3.662595801028143
Validation loss: 2.9207510416999836

Epoch: 6| Step: 1
Training loss: 2.9998873053682646
Validation loss: 2.915738283822649

Epoch: 6| Step: 2
Training loss: 2.47477123089462
Validation loss: 2.9227983289056727

Epoch: 6| Step: 3
Training loss: 2.796454882902525
Validation loss: 2.921090409877262

Epoch: 6| Step: 4
Training loss: 2.705506086408558
Validation loss: 2.921126956852591

Epoch: 6| Step: 5
Training loss: 3.581678466730101
Validation loss: 2.9253738211422844

Epoch: 6| Step: 6
Training loss: 3.8157329922076917
Validation loss: 2.918164782317079

Epoch: 6| Step: 7
Training loss: 2.805478635264365
Validation loss: 2.9139297746762156

Epoch: 6| Step: 8
Training loss: 3.681478465427477
Validation loss: 2.9125953215439013

Epoch: 6| Step: 9
Training loss: 3.5950620163620624
Validation loss: 2.9134899195889017

Epoch: 6| Step: 10
Training loss: 3.1805400783230726
Validation loss: 2.912992571371052

Epoch: 6| Step: 11
Training loss: 3.599197902333398
Validation loss: 2.9139337865070267

Epoch: 6| Step: 12
Training loss: 2.6480495652633755
Validation loss: 2.914697716146947

Epoch: 6| Step: 13
Training loss: 2.7259830416559816
Validation loss: 2.912540916420585

Epoch: 81| Step: 0
Training loss: 3.033677535038403
Validation loss: 2.9117983464080237

Epoch: 6| Step: 1
Training loss: 3.5535061728242843
Validation loss: 2.913945126937493

Epoch: 6| Step: 2
Training loss: 2.876376941835586
Validation loss: 2.913326399301588

Epoch: 6| Step: 3
Training loss: 3.5715439423591233
Validation loss: 2.9164216819105184

Epoch: 6| Step: 4
Training loss: 2.6916439134169514
Validation loss: 2.9198536373940276

Epoch: 6| Step: 5
Training loss: 2.5004488542067125
Validation loss: 2.9212623977480545

Epoch: 6| Step: 6
Training loss: 4.360324769829499
Validation loss: 2.9264989736785454

Epoch: 6| Step: 7
Training loss: 2.5107826398797806
Validation loss: 2.9185319365174034

Epoch: 6| Step: 8
Training loss: 3.205041972345234
Validation loss: 2.915038628929506

Epoch: 6| Step: 9
Training loss: 2.856687856956892
Validation loss: 2.9149864795147313

Epoch: 6| Step: 10
Training loss: 2.9994533358640334
Validation loss: 2.9114374728000967

Epoch: 6| Step: 11
Training loss: 3.7402421517951137
Validation loss: 2.9104004173809694

Epoch: 6| Step: 12
Training loss: 3.435395029777524
Validation loss: 2.9084194738149094

Epoch: 6| Step: 13
Training loss: 2.9023986236190478
Validation loss: 2.9123317152494956

Epoch: 82| Step: 0
Training loss: 2.7873624006445334
Validation loss: 2.9118298577816106

Epoch: 6| Step: 1
Training loss: 3.2905954154949772
Validation loss: 2.911321718075461

Epoch: 6| Step: 2
Training loss: 3.67430131978838
Validation loss: 2.910269870867593

Epoch: 6| Step: 3
Training loss: 2.613437984310964
Validation loss: 2.908218220117646

Epoch: 6| Step: 4
Training loss: 2.1544489318361983
Validation loss: 2.910874720888949

Epoch: 6| Step: 5
Training loss: 3.5870681343254365
Validation loss: 2.9140982932070156

Epoch: 6| Step: 6
Training loss: 2.9364976187237932
Validation loss: 2.91313604495246

Epoch: 6| Step: 7
Training loss: 2.852903954591022
Validation loss: 2.9113348263033667

Epoch: 6| Step: 8
Training loss: 3.0646018775639927
Validation loss: 2.9178793997912016

Epoch: 6| Step: 9
Training loss: 3.9124243195743076
Validation loss: 2.9131014737361642

Epoch: 6| Step: 10
Training loss: 3.250285356171887
Validation loss: 2.9111695610976698

Epoch: 6| Step: 11
Training loss: 3.5991863761822067
Validation loss: 2.913614191685161

Epoch: 6| Step: 12
Training loss: 3.3219830069293907
Validation loss: 2.9114436524316547

Epoch: 6| Step: 13
Training loss: 3.4468668158564584
Validation loss: 2.9093620582594877

Epoch: 83| Step: 0
Training loss: 2.87100090862859
Validation loss: 2.9071621080467644

Epoch: 6| Step: 1
Training loss: 2.73903159229099
Validation loss: 2.907622656350943

Epoch: 6| Step: 2
Training loss: 2.99467981986568
Validation loss: 2.9072962710299413

Epoch: 6| Step: 3
Training loss: 3.6371188983335743
Validation loss: 2.9080754709796435

Epoch: 6| Step: 4
Training loss: 3.7035797741253726
Validation loss: 2.910852877402126

Epoch: 6| Step: 5
Training loss: 2.8556657924063735
Validation loss: 2.91155442041084

Epoch: 6| Step: 6
Training loss: 2.925873167990372
Validation loss: 2.916149123957776

Epoch: 6| Step: 7
Training loss: 3.5656689386226534
Validation loss: 2.9229514855800756

Epoch: 6| Step: 8
Training loss: 2.755780300679427
Validation loss: 2.9129769491867066

Epoch: 6| Step: 9
Training loss: 3.8338905979839293
Validation loss: 2.9074487541554763

Epoch: 6| Step: 10
Training loss: 3.279277099404339
Validation loss: 2.905608419628136

Epoch: 6| Step: 11
Training loss: 2.7113881025232964
Validation loss: 2.9077576726869845

Epoch: 6| Step: 12
Training loss: 3.5588705748701734
Validation loss: 2.9071765295593615

Epoch: 6| Step: 13
Training loss: 2.9279820882635015
Validation loss: 2.909306760833412

Epoch: 84| Step: 0
Training loss: 3.7951896286380444
Validation loss: 2.9131385882316234

Epoch: 6| Step: 1
Training loss: 3.067600285041886
Validation loss: 2.913594524465991

Epoch: 6| Step: 2
Training loss: 3.126910426785307
Validation loss: 2.9152963017847813

Epoch: 6| Step: 3
Training loss: 2.976847637466428
Validation loss: 2.914253772050285

Epoch: 6| Step: 4
Training loss: 3.3831435959955187
Validation loss: 2.9196398884880512

Epoch: 6| Step: 5
Training loss: 3.2145675596162095
Validation loss: 2.915409972943908

Epoch: 6| Step: 6
Training loss: 4.231020566503983
Validation loss: 2.9153247512076077

Epoch: 6| Step: 7
Training loss: 2.691583414433866
Validation loss: 2.9128802906136837

Epoch: 6| Step: 8
Training loss: 2.5100936259707356
Validation loss: 2.911520645772396

Epoch: 6| Step: 9
Training loss: 3.8378289991871646
Validation loss: 2.9092305495754367

Epoch: 6| Step: 10
Training loss: 2.735518211074033
Validation loss: 2.9093169984353384

Epoch: 6| Step: 11
Training loss: 2.9878277203838803
Validation loss: 2.9079790779379313

Epoch: 6| Step: 12
Training loss: 2.6678701804231526
Validation loss: 2.9089983646054876

Epoch: 6| Step: 13
Training loss: 3.1953475689071142
Validation loss: 2.908273721592869

Epoch: 85| Step: 0
Training loss: 2.286228130688571
Validation loss: 2.908184775211649

Epoch: 6| Step: 1
Training loss: 3.430760939023228
Validation loss: 2.9078789983001108

Epoch: 6| Step: 2
Training loss: 2.4613563786616357
Validation loss: 2.905652067061435

Epoch: 6| Step: 3
Training loss: 3.2891342626431155
Validation loss: 2.90786308591983

Epoch: 6| Step: 4
Training loss: 3.8211908559368135
Validation loss: 2.9071583972778843

Epoch: 6| Step: 5
Training loss: 3.9163796881112276
Validation loss: 2.9086881782214036

Epoch: 6| Step: 6
Training loss: 3.1781228454642556
Validation loss: 2.91106589768663

Epoch: 6| Step: 7
Training loss: 3.8301906695601393
Validation loss: 2.9119381222089262

Epoch: 6| Step: 8
Training loss: 3.0578551588167557
Validation loss: 2.911485166042818

Epoch: 6| Step: 9
Training loss: 3.537663939219013
Validation loss: 2.9159814475035213

Epoch: 6| Step: 10
Training loss: 2.9087228406712753
Validation loss: 2.918449154856916

Epoch: 6| Step: 11
Training loss: 2.858261642075999
Validation loss: 2.907167066607197

Epoch: 6| Step: 12
Training loss: 2.3684490606536963
Validation loss: 2.9079783603248814

Epoch: 6| Step: 13
Training loss: 3.282568530422691
Validation loss: 2.9083457682654856

Epoch: 86| Step: 0
Training loss: 3.041127893118717
Validation loss: 2.9037164642088458

Epoch: 6| Step: 1
Training loss: 3.837610940230479
Validation loss: 2.9040507405045894

Epoch: 6| Step: 2
Training loss: 2.608051809732417
Validation loss: 2.9044124171678125

Epoch: 6| Step: 3
Training loss: 3.390070575440831
Validation loss: 2.9054495416689945

Epoch: 6| Step: 4
Training loss: 3.597404943380736
Validation loss: 2.9024466084784524

Epoch: 6| Step: 5
Training loss: 3.6095094862154196
Validation loss: 2.9033577816088307

Epoch: 6| Step: 6
Training loss: 2.701381142895818
Validation loss: 2.902275355264426

Epoch: 6| Step: 7
Training loss: 3.0606995564580237
Validation loss: 2.9013207770565774

Epoch: 6| Step: 8
Training loss: 2.9557717386056295
Validation loss: 2.9016308056576867

Epoch: 6| Step: 9
Training loss: 3.1219137592219828
Validation loss: 2.8982783156298964

Epoch: 6| Step: 10
Training loss: 3.1011100073833346
Validation loss: 2.8969819759575457

Epoch: 6| Step: 11
Training loss: 3.5149608747711367
Validation loss: 2.900987919152891

Epoch: 6| Step: 12
Training loss: 2.8441929734186364
Validation loss: 2.896775642483454

Epoch: 6| Step: 13
Training loss: 2.9559540291955293
Validation loss: 2.897644527104157

Epoch: 87| Step: 0
Training loss: 2.7200577320255093
Validation loss: 2.8969710328311344

Epoch: 6| Step: 1
Training loss: 2.976033802086614
Validation loss: 2.8974012065701804

Epoch: 6| Step: 2
Training loss: 3.173493221513124
Validation loss: 2.897400089943633

Epoch: 6| Step: 3
Training loss: 3.5800821207526803
Validation loss: 2.899834218093917

Epoch: 6| Step: 4
Training loss: 2.965620941706012
Validation loss: 2.897563707421656

Epoch: 6| Step: 5
Training loss: 3.166593768301331
Validation loss: 2.897361352822828

Epoch: 6| Step: 6
Training loss: 2.9481346310394945
Validation loss: 2.8954498439602023

Epoch: 6| Step: 7
Training loss: 3.699226741923125
Validation loss: 2.896830271124583

Epoch: 6| Step: 8
Training loss: 3.7957214361308345
Validation loss: 2.896897228921311

Epoch: 6| Step: 9
Training loss: 3.1789828932722766
Validation loss: 2.8988674596619664

Epoch: 6| Step: 10
Training loss: 3.180826868722443
Validation loss: 2.8961911299509873

Epoch: 6| Step: 11
Training loss: 2.690298619340308
Validation loss: 2.897440164356927

Epoch: 6| Step: 12
Training loss: 2.912743482112754
Validation loss: 2.8977219702544703

Epoch: 6| Step: 13
Training loss: 3.6564011501793283
Validation loss: 2.8984346537079495

Epoch: 88| Step: 0
Training loss: 2.1539038457846686
Validation loss: 2.9020072373038412

Epoch: 6| Step: 1
Training loss: 3.0758054097190595
Validation loss: 2.8995251379596114

Epoch: 6| Step: 2
Training loss: 2.9967630725440855
Validation loss: 2.8972829567908476

Epoch: 6| Step: 3
Training loss: 2.956907080760728
Validation loss: 2.902480163667541

Epoch: 6| Step: 4
Training loss: 2.976257468786565
Validation loss: 2.9004670738347613

Epoch: 6| Step: 5
Training loss: 3.8253875286783523
Validation loss: 2.9034891121653885

Epoch: 6| Step: 6
Training loss: 3.668583600041461
Validation loss: 2.899662881322248

Epoch: 6| Step: 7
Training loss: 3.7087138691509245
Validation loss: 2.9000775996919597

Epoch: 6| Step: 8
Training loss: 3.4662919141489277
Validation loss: 2.8998603579967397

Epoch: 6| Step: 9
Training loss: 3.383753691869609
Validation loss: 2.8951854301191435

Epoch: 6| Step: 10
Training loss: 2.803864424705247
Validation loss: 2.8942930868022057

Epoch: 6| Step: 11
Training loss: 3.3045553266638494
Validation loss: 2.8964970901317817

Epoch: 6| Step: 12
Training loss: 3.1408694347703174
Validation loss: 2.896499368334796

Epoch: 6| Step: 13
Training loss: 2.360061545620154
Validation loss: 2.8916995529267493

Epoch: 89| Step: 0
Training loss: 3.290642945330341
Validation loss: 2.893380065588011

Epoch: 6| Step: 1
Training loss: 3.119724398202467
Validation loss: 2.894519558501919

Epoch: 6| Step: 2
Training loss: 3.1469507990537506
Validation loss: 2.8950219173226226

Epoch: 6| Step: 3
Training loss: 3.0798798027364964
Validation loss: 2.8952110629991044

Epoch: 6| Step: 4
Training loss: 2.9287965767739075
Validation loss: 2.893546629472223

Epoch: 6| Step: 5
Training loss: 3.3542078777806426
Validation loss: 2.8940743177900345

Epoch: 6| Step: 6
Training loss: 3.21909278599859
Validation loss: 2.893388674306809

Epoch: 6| Step: 7
Training loss: 2.309669515080108
Validation loss: 2.8925808157516455

Epoch: 6| Step: 8
Training loss: 3.3791436084441955
Validation loss: 2.8955873827724354

Epoch: 6| Step: 9
Training loss: 3.3662456425448437
Validation loss: 2.8935799591724085

Epoch: 6| Step: 10
Training loss: 3.2894784116209093
Validation loss: 2.8925911125508668

Epoch: 6| Step: 11
Training loss: 3.6239227799026383
Validation loss: 2.8948714106908753

Epoch: 6| Step: 12
Training loss: 3.238562779906317
Validation loss: 2.8955585455301445

Epoch: 6| Step: 13
Training loss: 2.9954940016572964
Validation loss: 2.90614886399549

Epoch: 90| Step: 0
Training loss: 2.853363388146854
Validation loss: 2.9093107103067655

Epoch: 6| Step: 1
Training loss: 3.558586514211222
Validation loss: 2.913505812676622

Epoch: 6| Step: 2
Training loss: 3.003348071718058
Validation loss: 2.9101228890327517

Epoch: 6| Step: 3
Training loss: 2.767538497091909
Validation loss: 2.9034013604509457

Epoch: 6| Step: 4
Training loss: 3.3724098156181346
Validation loss: 2.899670161130749

Epoch: 6| Step: 5
Training loss: 3.272817184195749
Validation loss: 2.8940661079610868

Epoch: 6| Step: 6
Training loss: 3.509866431756971
Validation loss: 2.891275855759131

Epoch: 6| Step: 7
Training loss: 3.1577694700726724
Validation loss: 2.897065666587799

Epoch: 6| Step: 8
Training loss: 2.3169897672898934
Validation loss: 2.8927302548920473

Epoch: 6| Step: 9
Training loss: 3.474167176488551
Validation loss: 2.8932889583262633

Epoch: 6| Step: 10
Training loss: 3.448095741500475
Validation loss: 2.8951491985399307

Epoch: 6| Step: 11
Training loss: 3.642584015787797
Validation loss: 2.894037332627937

Epoch: 6| Step: 12
Training loss: 2.3413022292829293
Validation loss: 2.8954100749157434

Epoch: 6| Step: 13
Training loss: 3.7721981437962095
Validation loss: 2.8969430084693415

Epoch: 91| Step: 0
Training loss: 3.1440282194215503
Validation loss: 2.8956128243992714

Epoch: 6| Step: 1
Training loss: 3.26104093350125
Validation loss: 2.8956967706203423

Epoch: 6| Step: 2
Training loss: 3.7584966405559435
Validation loss: 2.894705880402783

Epoch: 6| Step: 3
Training loss: 2.851443437154763
Validation loss: 2.8910408197637336

Epoch: 6| Step: 4
Training loss: 2.4750303709690593
Validation loss: 2.8881447112660803

Epoch: 6| Step: 5
Training loss: 3.3322537740302094
Validation loss: 2.892569636176198

Epoch: 6| Step: 6
Training loss: 3.311791686136566
Validation loss: 2.8893951753167473

Epoch: 6| Step: 7
Training loss: 3.19617657531973
Validation loss: 2.8887147311267327

Epoch: 6| Step: 8
Training loss: 2.995267791493981
Validation loss: 2.8887108262667964

Epoch: 6| Step: 9
Training loss: 2.5914569508213336
Validation loss: 2.8865029062293672

Epoch: 6| Step: 10
Training loss: 3.3761274079511927
Validation loss: 2.888013806739489

Epoch: 6| Step: 11
Training loss: 2.982141907547407
Validation loss: 2.8869397849470144

Epoch: 6| Step: 12
Training loss: 4.042931951825289
Validation loss: 2.8879070244948233

Epoch: 6| Step: 13
Training loss: 2.678315637273275
Validation loss: 2.888298643940202

Epoch: 92| Step: 0
Training loss: 3.4300787144295417
Validation loss: 2.8880954262586647

Epoch: 6| Step: 1
Training loss: 3.17926877425688
Validation loss: 2.8863461110575157

Epoch: 6| Step: 2
Training loss: 2.8226881509514956
Validation loss: 2.884561346103766

Epoch: 6| Step: 3
Training loss: 2.589461676721152
Validation loss: 2.8869243938612117

Epoch: 6| Step: 4
Training loss: 3.0505342859787103
Validation loss: 2.8862985930766287

Epoch: 6| Step: 5
Training loss: 3.0478728396605925
Validation loss: 2.885111760274322

Epoch: 6| Step: 6
Training loss: 3.0778455268512426
Validation loss: 2.888613444452493

Epoch: 6| Step: 7
Training loss: 3.2273054768442884
Validation loss: 2.8849413939279245

Epoch: 6| Step: 8
Training loss: 3.0210699229932194
Validation loss: 2.8888342465740746

Epoch: 6| Step: 9
Training loss: 3.224780313269054
Validation loss: 2.886183500021812

Epoch: 6| Step: 10
Training loss: 3.635831501345567
Validation loss: 2.8850190643296565

Epoch: 6| Step: 11
Training loss: 3.3554772764370715
Validation loss: 2.8850707770878716

Epoch: 6| Step: 12
Training loss: 3.43847642382313
Validation loss: 2.889564964113672

Epoch: 6| Step: 13
Training loss: 3.315513679440507
Validation loss: 2.8996901340941963

Epoch: 93| Step: 0
Training loss: 3.515364438043826
Validation loss: 2.9096141965830147

Epoch: 6| Step: 1
Training loss: 2.174839219914154
Validation loss: 2.893628028253949

Epoch: 6| Step: 2
Training loss: 2.738724393807602
Validation loss: 2.914516277392564

Epoch: 6| Step: 3
Training loss: 3.5984128473309487
Validation loss: 2.9055465586132745

Epoch: 6| Step: 4
Training loss: 3.5328685460797145
Validation loss: 2.892795504141049

Epoch: 6| Step: 5
Training loss: 3.253832098401047
Validation loss: 2.8886853664506105

Epoch: 6| Step: 6
Training loss: 3.2029478442816512
Validation loss: 2.8834635819717973

Epoch: 6| Step: 7
Training loss: 2.430561656641493
Validation loss: 2.882785427383127

Epoch: 6| Step: 8
Training loss: 2.908144425721407
Validation loss: 2.8819489714060667

Epoch: 6| Step: 9
Training loss: 3.342721370878835
Validation loss: 2.883925623120145

Epoch: 6| Step: 10
Training loss: 3.255251529661311
Validation loss: 2.8837613900916326

Epoch: 6| Step: 11
Training loss: 3.5569891887132643
Validation loss: 2.880902982715106

Epoch: 6| Step: 12
Training loss: 3.245565176298056
Validation loss: 2.8847630886991213

Epoch: 6| Step: 13
Training loss: 3.5767747755205113
Validation loss: 2.882375470663931

Epoch: 94| Step: 0
Training loss: 2.857768290048963
Validation loss: 2.8817401506351903

Epoch: 6| Step: 1
Training loss: 2.898366428542389
Validation loss: 2.88277467136534

Epoch: 6| Step: 2
Training loss: 3.286513112977409
Validation loss: 2.8840835694435545

Epoch: 6| Step: 3
Training loss: 2.809635823228249
Validation loss: 2.882639078959542

Epoch: 6| Step: 4
Training loss: 3.138835036304367
Validation loss: 2.881908614862564

Epoch: 6| Step: 5
Training loss: 3.3809758722165917
Validation loss: 2.879615794095914

Epoch: 6| Step: 6
Training loss: 2.726281006718492
Validation loss: 2.882979407654492

Epoch: 6| Step: 7
Training loss: 2.794672775630729
Validation loss: 2.8847817385455086

Epoch: 6| Step: 8
Training loss: 2.6908227650692895
Validation loss: 2.887124382781188

Epoch: 6| Step: 9
Training loss: 3.8299342025802154
Validation loss: 2.887667144851412

Epoch: 6| Step: 10
Training loss: 3.475045891328398
Validation loss: 2.882573875513176

Epoch: 6| Step: 11
Training loss: 3.317571967579724
Validation loss: 2.882711529752504

Epoch: 6| Step: 12
Training loss: 3.398226746787655
Validation loss: 2.8818338736599576

Epoch: 6| Step: 13
Training loss: 3.9536863388353853
Validation loss: 2.879492431836661

Epoch: 95| Step: 0
Training loss: 3.0821932325838755
Validation loss: 2.876947054849506

Epoch: 6| Step: 1
Training loss: 2.7493101468494485
Validation loss: 2.8798082991375313

Epoch: 6| Step: 2
Training loss: 3.507624903634881
Validation loss: 2.8800896992866023

Epoch: 6| Step: 3
Training loss: 3.753472691168429
Validation loss: 2.8793894442869075

Epoch: 6| Step: 4
Training loss: 3.4606514633845156
Validation loss: 2.882938190517732

Epoch: 6| Step: 5
Training loss: 2.5881876303624005
Validation loss: 2.8790192991981733

Epoch: 6| Step: 6
Training loss: 2.861172637360215
Validation loss: 2.8804902865500703

Epoch: 6| Step: 7
Training loss: 2.367766155359791
Validation loss: 2.879069187465982

Epoch: 6| Step: 8
Training loss: 3.395088597800367
Validation loss: 2.8815247426580646

Epoch: 6| Step: 9
Training loss: 3.0593446318976865
Validation loss: 2.8765428272501987

Epoch: 6| Step: 10
Training loss: 3.5627808041915547
Validation loss: 2.8783314482355933

Epoch: 6| Step: 11
Training loss: 3.398149289592844
Validation loss: 2.878166989519692

Epoch: 6| Step: 12
Training loss: 3.4380765951521934
Validation loss: 2.878623875645189

Epoch: 6| Step: 13
Training loss: 2.731062272034094
Validation loss: 2.87725121226619

Epoch: 96| Step: 0
Training loss: 2.747076214222242
Validation loss: 2.8743844044235427

Epoch: 6| Step: 1
Training loss: 2.3475411842316674
Validation loss: 2.8801129011985624

Epoch: 6| Step: 2
Training loss: 2.700826913868558
Validation loss: 2.885910146280606

Epoch: 6| Step: 3
Training loss: 3.8733785374728953
Validation loss: 2.880023063737658

Epoch: 6| Step: 4
Training loss: 3.4113294892574277
Validation loss: 2.8831040389787375

Epoch: 6| Step: 5
Training loss: 3.058787372642963
Validation loss: 2.8833008394882738

Epoch: 6| Step: 6
Training loss: 2.847573361544429
Validation loss: 2.884083471665363

Epoch: 6| Step: 7
Training loss: 3.427936915312376
Validation loss: 2.885402253084102

Epoch: 6| Step: 8
Training loss: 3.516452132516631
Validation loss: 2.8814454219694863

Epoch: 6| Step: 9
Training loss: 2.955015515901524
Validation loss: 2.8724486206215354

Epoch: 6| Step: 10
Training loss: 3.438393216692596
Validation loss: 2.8739728854001263

Epoch: 6| Step: 11
Training loss: 2.723943200929426
Validation loss: 2.874667914901442

Epoch: 6| Step: 12
Training loss: 3.658657487716875
Validation loss: 2.869925014123238

Epoch: 6| Step: 13
Training loss: 3.4570880777462007
Validation loss: 2.8720696287601375

Epoch: 97| Step: 0
Training loss: 3.000531467409409
Validation loss: 2.872278962486241

Epoch: 6| Step: 1
Training loss: 3.59755154104206
Validation loss: 2.874028029533341

Epoch: 6| Step: 2
Training loss: 2.7278974265562135
Validation loss: 2.8716046318890927

Epoch: 6| Step: 3
Training loss: 3.402577511523261
Validation loss: 2.8716454412354517

Epoch: 6| Step: 4
Training loss: 3.5721724525677354
Validation loss: 2.8733179737144297

Epoch: 6| Step: 5
Training loss: 2.9677504613601395
Validation loss: 2.8717324823340133

Epoch: 6| Step: 6
Training loss: 2.694882565914029
Validation loss: 2.872465346786426

Epoch: 6| Step: 7
Training loss: 3.353111638222955
Validation loss: 2.8731639397606425

Epoch: 6| Step: 8
Training loss: 3.302144977623949
Validation loss: 2.8716867981380756

Epoch: 6| Step: 9
Training loss: 3.0619923696391727
Validation loss: 2.872863220692387

Epoch: 6| Step: 10
Training loss: 3.50646226209837
Validation loss: 2.8744327811338195

Epoch: 6| Step: 11
Training loss: 2.798775820832365
Validation loss: 2.871798232769797

Epoch: 6| Step: 12
Training loss: 3.327295764183875
Validation loss: 2.872391936039105

Epoch: 6| Step: 13
Training loss: 2.6471695917303055
Validation loss: 2.8748498924699577

Epoch: 98| Step: 0
Training loss: 3.6607177043194374
Validation loss: 2.8742497068362827

Epoch: 6| Step: 1
Training loss: 3.716670504740514
Validation loss: 2.8772271613106795

Epoch: 6| Step: 2
Training loss: 2.8479763944697702
Validation loss: 2.8751050048028635

Epoch: 6| Step: 3
Training loss: 2.7299061906507736
Validation loss: 2.8772082771646295

Epoch: 6| Step: 4
Training loss: 2.4356316472942434
Validation loss: 2.8709377036298207

Epoch: 6| Step: 5
Training loss: 3.1391962701711167
Validation loss: 2.8761420369210673

Epoch: 6| Step: 6
Training loss: 3.1784674625936633
Validation loss: 2.877302673489814

Epoch: 6| Step: 7
Training loss: 3.2377086910899466
Validation loss: 2.88277162463486

Epoch: 6| Step: 8
Training loss: 3.436976444948362
Validation loss: 2.8865012329587993

Epoch: 6| Step: 9
Training loss: 2.97363457640547
Validation loss: 2.8770755152858114

Epoch: 6| Step: 10
Training loss: 3.4559296830317683
Validation loss: 2.8767459912527267

Epoch: 6| Step: 11
Training loss: 3.2437346294531366
Validation loss: 2.873256242812517

Epoch: 6| Step: 12
Training loss: 3.0089644963156164
Validation loss: 2.871540763455181

Epoch: 6| Step: 13
Training loss: 2.9082341138061025
Validation loss: 2.8704887546850943

Epoch: 99| Step: 0
Training loss: 3.4536085523812705
Validation loss: 2.8697423204685832

Epoch: 6| Step: 1
Training loss: 2.9886852514894744
Validation loss: 2.872658420242781

Epoch: 6| Step: 2
Training loss: 3.1893024210415244
Validation loss: 2.871318130593067

Epoch: 6| Step: 3
Training loss: 2.5191145678033373
Validation loss: 2.8714146704615366

Epoch: 6| Step: 4
Training loss: 3.462710509803993
Validation loss: 2.872625440378954

Epoch: 6| Step: 5
Training loss: 3.7316946202455434
Validation loss: 2.87258759807332

Epoch: 6| Step: 6
Training loss: 2.784772806403149
Validation loss: 2.8740759162969813

Epoch: 6| Step: 7
Training loss: 3.2394128163754403
Validation loss: 2.8776121368914027

Epoch: 6| Step: 8
Training loss: 3.030767972708325
Validation loss: 2.8820648971420275

Epoch: 6| Step: 9
Training loss: 3.2219780595578196
Validation loss: 2.8834872190556866

Epoch: 6| Step: 10
Training loss: 3.1877550509268233
Validation loss: 2.8805293386605517

Epoch: 6| Step: 11
Training loss: 3.07792639696783
Validation loss: 2.8835594360547834

Epoch: 6| Step: 12
Training loss: 3.3861173559987834
Validation loss: 2.8921015459567805

Epoch: 6| Step: 13
Training loss: 2.7024848488692625
Validation loss: 2.8954661645518893

Epoch: 100| Step: 0
Training loss: 2.9030458568876214
Validation loss: 2.8960261424949816

Epoch: 6| Step: 1
Training loss: 3.2662025926480287
Validation loss: 2.9074429134428583

Epoch: 6| Step: 2
Training loss: 2.9656905622239584
Validation loss: 2.9267781217873923

Epoch: 6| Step: 3
Training loss: 2.6155191598349776
Validation loss: 2.9215074007110315

Epoch: 6| Step: 4
Training loss: 3.9127428948321623
Validation loss: 2.920870219660072

Epoch: 6| Step: 5
Training loss: 2.866931373735511
Validation loss: 2.914481115609549

Epoch: 6| Step: 6
Training loss: 3.1728835733899983
Validation loss: 2.905612779989439

Epoch: 6| Step: 7
Training loss: 3.497325556605956
Validation loss: 2.885389839125537

Epoch: 6| Step: 8
Training loss: 3.4727909503983185
Validation loss: 2.876647335487979

Epoch: 6| Step: 9
Training loss: 3.376622128081496
Validation loss: 2.867194291809466

Epoch: 6| Step: 10
Training loss: 3.0357783206629287
Validation loss: 2.8684198588338803

Epoch: 6| Step: 11
Training loss: 3.248360733952703
Validation loss: 2.867451642681478

Epoch: 6| Step: 12
Training loss: 3.2881957155623773
Validation loss: 2.8665061253491917

Epoch: 6| Step: 13
Training loss: 2.158108338911193
Validation loss: 2.868778810609552

Epoch: 101| Step: 0
Training loss: 2.7519311193340363
Validation loss: 2.865313368741802

Epoch: 6| Step: 1
Training loss: 3.1056232150067506
Validation loss: 2.869635100424837

Epoch: 6| Step: 2
Training loss: 2.442358798549978
Validation loss: 2.8675078357567623

Epoch: 6| Step: 3
Training loss: 2.551803781158853
Validation loss: 2.868965586717612

Epoch: 6| Step: 4
Training loss: 3.319835673482316
Validation loss: 2.872915613600981

Epoch: 6| Step: 5
Training loss: 3.2341298180865925
Validation loss: 2.8748613959916267

Epoch: 6| Step: 6
Training loss: 3.3477069579371346
Validation loss: 2.8786564082952584

Epoch: 6| Step: 7
Training loss: 3.185940080298351
Validation loss: 2.88582053815137

Epoch: 6| Step: 8
Training loss: 2.9581636908519786
Validation loss: 2.895998523279787

Epoch: 6| Step: 9
Training loss: 3.551448075364025
Validation loss: 2.885763590313258

Epoch: 6| Step: 10
Training loss: 3.8839584900654214
Validation loss: 2.8945462481376256

Epoch: 6| Step: 11
Training loss: 3.6029248753576173
Validation loss: 2.87932342557968

Epoch: 6| Step: 12
Training loss: 3.051812968251573
Validation loss: 2.8697659490763403

Epoch: 6| Step: 13
Training loss: 3.0449444254296463
Validation loss: 2.861213929704695

Epoch: 102| Step: 0
Training loss: 3.4798730068493633
Validation loss: 2.8616933154274697

Epoch: 6| Step: 1
Training loss: 3.028692995700791
Validation loss: 2.868297414717137

Epoch: 6| Step: 2
Training loss: 3.029066892412331
Validation loss: 2.867731437579455

Epoch: 6| Step: 3
Training loss: 3.269814172533416
Validation loss: 2.8697510688827865

Epoch: 6| Step: 4
Training loss: 3.249273072155759
Validation loss: 2.86419383215373

Epoch: 6| Step: 5
Training loss: 2.613243114153261
Validation loss: 2.8628144011987113

Epoch: 6| Step: 6
Training loss: 3.004193553901239
Validation loss: 2.859836436461609

Epoch: 6| Step: 7
Training loss: 2.3721366486710376
Validation loss: 2.8615629863655845

Epoch: 6| Step: 8
Training loss: 3.801117963470326
Validation loss: 2.8659543661553397

Epoch: 6| Step: 9
Training loss: 3.745617658256873
Validation loss: 2.866697877772193

Epoch: 6| Step: 10
Training loss: 3.0344413396495926
Validation loss: 2.8670517069289465

Epoch: 6| Step: 11
Training loss: 3.1037216550260176
Validation loss: 2.8716373101230133

Epoch: 6| Step: 12
Training loss: 2.5778328469942027
Validation loss: 2.8725267626863853

Epoch: 6| Step: 13
Training loss: 4.013771668467427
Validation loss: 2.8722547645740795

Epoch: 103| Step: 0
Training loss: 2.464893177340938
Validation loss: 2.871531500003839

Epoch: 6| Step: 1
Training loss: 3.143000828567187
Validation loss: 2.8682181223962617

Epoch: 6| Step: 2
Training loss: 3.175041234507091
Validation loss: 2.8781448969090286

Epoch: 6| Step: 3
Training loss: 3.394500486456184
Validation loss: 2.868273995672162

Epoch: 6| Step: 4
Training loss: 3.11969230039331
Validation loss: 2.8645263582680904

Epoch: 6| Step: 5
Training loss: 3.237694552552016
Validation loss: 2.8594693332467287

Epoch: 6| Step: 6
Training loss: 3.276336333219101
Validation loss: 2.8629587919107884

Epoch: 6| Step: 7
Training loss: 3.509281250269584
Validation loss: 2.8622848486487715

Epoch: 6| Step: 8
Training loss: 3.0901631842427064
Validation loss: 2.8606344930408705

Epoch: 6| Step: 9
Training loss: 2.2982868863567734
Validation loss: 2.8597935231816494

Epoch: 6| Step: 10
Training loss: 2.7179225670996425
Validation loss: 2.8581345291143707

Epoch: 6| Step: 11
Training loss: 3.3736066414506944
Validation loss: 2.8588463079148387

Epoch: 6| Step: 12
Training loss: 3.5891248047419126
Validation loss: 2.8585453946993646

Epoch: 6| Step: 13
Training loss: 3.828986744325477
Validation loss: 2.8590421796181067

Epoch: 104| Step: 0
Training loss: 3.035043289655119
Validation loss: 2.857569951812605

Epoch: 6| Step: 1
Training loss: 3.128181516458812
Validation loss: 2.8598437226281446

Epoch: 6| Step: 2
Training loss: 2.849275021615799
Validation loss: 2.859200302642862

Epoch: 6| Step: 3
Training loss: 2.6741121975764313
Validation loss: 2.860926383373985

Epoch: 6| Step: 4
Training loss: 2.4634684793086685
Validation loss: 2.864153929862781

Epoch: 6| Step: 5
Training loss: 2.6416423575870276
Validation loss: 2.86580158777899

Epoch: 6| Step: 6
Training loss: 3.589324083373955
Validation loss: 2.8660277226445885

Epoch: 6| Step: 7
Training loss: 3.6256281867471127
Validation loss: 2.8654451197459534

Epoch: 6| Step: 8
Training loss: 3.6901845696662825
Validation loss: 2.864626843671098

Epoch: 6| Step: 9
Training loss: 3.5197440875833057
Validation loss: 2.869342923787096

Epoch: 6| Step: 10
Training loss: 3.0861844120959243
Validation loss: 2.8571570015738827

Epoch: 6| Step: 11
Training loss: 3.543227012835862
Validation loss: 2.8625063696077193

Epoch: 6| Step: 12
Training loss: 3.1080758145780547
Validation loss: 2.8630528476919013

Epoch: 6| Step: 13
Training loss: 2.6684828077294607
Validation loss: 2.861143554504617

Epoch: 105| Step: 0
Training loss: 2.8320191271292257
Validation loss: 2.8608380331496774

Epoch: 6| Step: 1
Training loss: 2.863205475474577
Validation loss: 2.862549569105163

Epoch: 6| Step: 2
Training loss: 3.189630880734395
Validation loss: 2.8578099374817882

Epoch: 6| Step: 3
Training loss: 3.0124749843461
Validation loss: 2.861316065329049

Epoch: 6| Step: 4
Training loss: 2.9939468032402186
Validation loss: 2.8597969162147376

Epoch: 6| Step: 5
Training loss: 3.349019114811391
Validation loss: 2.8603582307237057

Epoch: 6| Step: 6
Training loss: 3.092543549782251
Validation loss: 2.8519004092262685

Epoch: 6| Step: 7
Training loss: 2.9701979469070805
Validation loss: 2.8552584540884527

Epoch: 6| Step: 8
Training loss: 3.4441848951057787
Validation loss: 2.8537847315620337

Epoch: 6| Step: 9
Training loss: 2.230744941032784
Validation loss: 2.857519324850296

Epoch: 6| Step: 10
Training loss: 3.5693623887528783
Validation loss: 2.854903205512441

Epoch: 6| Step: 11
Training loss: 2.750259733938956
Validation loss: 2.8560174920577714

Epoch: 6| Step: 12
Training loss: 4.426894287860133
Validation loss: 2.8545479845729234

Epoch: 6| Step: 13
Training loss: 2.7297033893579115
Validation loss: 2.85247088910081

Epoch: 106| Step: 0
Training loss: 3.648941299321763
Validation loss: 2.851448533964885

Epoch: 6| Step: 1
Training loss: 2.9071101074677097
Validation loss: 2.8567825966103935

Epoch: 6| Step: 2
Training loss: 2.7763280285446315
Validation loss: 2.8511948736664623

Epoch: 6| Step: 3
Training loss: 3.3441147649865974
Validation loss: 2.8575396247272247

Epoch: 6| Step: 4
Training loss: 3.367967130323926
Validation loss: 2.8545565846685874

Epoch: 6| Step: 5
Training loss: 2.702064614879407
Validation loss: 2.851587116238031

Epoch: 6| Step: 6
Training loss: 3.5558409443867625
Validation loss: 2.8531658560770747

Epoch: 6| Step: 7
Training loss: 3.315359213168508
Validation loss: 2.8519526451993578

Epoch: 6| Step: 8
Training loss: 2.775383409011555
Validation loss: 2.8571665655564655

Epoch: 6| Step: 9
Training loss: 3.2633171139847534
Validation loss: 2.860842820193424

Epoch: 6| Step: 10
Training loss: 2.8012315289740792
Validation loss: 2.8615737029606776

Epoch: 6| Step: 11
Training loss: 2.704701223178826
Validation loss: 2.871438146029873

Epoch: 6| Step: 12
Training loss: 3.305025412595987
Validation loss: 2.8695570288125087

Epoch: 6| Step: 13
Training loss: 3.6540390241738727
Validation loss: 2.8707048300191467

Epoch: 107| Step: 0
Training loss: 3.9480563149962586
Validation loss: 2.862157840916551

Epoch: 6| Step: 1
Training loss: 3.0495004150970773
Validation loss: 2.8466613535917795

Epoch: 6| Step: 2
Training loss: 2.4935928256952633
Validation loss: 2.8482845312190657

Epoch: 6| Step: 3
Training loss: 3.222294901616455
Validation loss: 2.850184871029369

Epoch: 6| Step: 4
Training loss: 2.921871083302856
Validation loss: 2.8512956382856327

Epoch: 6| Step: 5
Training loss: 3.197901639789147
Validation loss: 2.8504725808691433

Epoch: 6| Step: 6
Training loss: 2.5248709466266073
Validation loss: 2.8526728413759295

Epoch: 6| Step: 7
Training loss: 3.529353890224993
Validation loss: 2.85389675920777

Epoch: 6| Step: 8
Training loss: 2.752545998835988
Validation loss: 2.8531331639589244

Epoch: 6| Step: 9
Training loss: 3.8410257749598933
Validation loss: 2.8530261958284497

Epoch: 6| Step: 10
Training loss: 2.6327083578369095
Validation loss: 2.8524995292269253

Epoch: 6| Step: 11
Training loss: 2.8032774714718784
Validation loss: 2.848680523201618

Epoch: 6| Step: 12
Training loss: 3.527007398484563
Validation loss: 2.849449895629096

Epoch: 6| Step: 13
Training loss: 3.530096760361139
Validation loss: 2.848977364538044

Epoch: 108| Step: 0
Training loss: 3.461481675880439
Validation loss: 2.848718547199162

Epoch: 6| Step: 1
Training loss: 3.451600303460149
Validation loss: 2.8474733610233383

Epoch: 6| Step: 2
Training loss: 3.5106305397754687
Validation loss: 2.849379486295738

Epoch: 6| Step: 3
Training loss: 3.9160342551380407
Validation loss: 2.847615429065061

Epoch: 6| Step: 4
Training loss: 2.508276875600872
Validation loss: 2.8466731043094864

Epoch: 6| Step: 5
Training loss: 2.9489821989674097
Validation loss: 2.8459106948876847

Epoch: 6| Step: 6
Training loss: 2.658228686992497
Validation loss: 2.846169827908655

Epoch: 6| Step: 7
Training loss: 3.5937472136113517
Validation loss: 2.845595171251059

Epoch: 6| Step: 8
Training loss: 3.249668397859222
Validation loss: 2.84457969889799

Epoch: 6| Step: 9
Training loss: 2.8719413077220084
Validation loss: 2.8462166260359205

Epoch: 6| Step: 10
Training loss: 2.355840802265747
Validation loss: 2.844639118639013

Epoch: 6| Step: 11
Training loss: 3.188673813050679
Validation loss: 2.843424440698263

Epoch: 6| Step: 12
Training loss: 3.1786366818803793
Validation loss: 2.845407939546709

Epoch: 6| Step: 13
Training loss: 2.4841820024104218
Validation loss: 2.8449161738776656

Epoch: 109| Step: 0
Training loss: 2.886043072036081
Validation loss: 2.850124719593335

Epoch: 6| Step: 1
Training loss: 2.9913944159468193
Validation loss: 2.8543587130421653

Epoch: 6| Step: 2
Training loss: 3.240226133955765
Validation loss: 2.8531618657250943

Epoch: 6| Step: 3
Training loss: 3.0252205571248005
Validation loss: 2.8553417326763726

Epoch: 6| Step: 4
Training loss: 3.010486870357391
Validation loss: 2.857390252585887

Epoch: 6| Step: 5
Training loss: 3.379756683756102
Validation loss: 2.857930545296115

Epoch: 6| Step: 6
Training loss: 3.1335641620373726
Validation loss: 2.8549608667996598

Epoch: 6| Step: 7
Training loss: 3.2012380112524434
Validation loss: 2.8514094405059174

Epoch: 6| Step: 8
Training loss: 2.878561053549789
Validation loss: 2.8434486179874594

Epoch: 6| Step: 9
Training loss: 2.7803807989896163
Validation loss: 2.8431353548796094

Epoch: 6| Step: 10
Training loss: 4.134189196136075
Validation loss: 2.840528417445048

Epoch: 6| Step: 11
Training loss: 3.0798146214369773
Validation loss: 2.8397292486598182

Epoch: 6| Step: 12
Training loss: 2.709570636307917
Validation loss: 2.8390255050085957

Epoch: 6| Step: 13
Training loss: 3.542252136906126
Validation loss: 2.8379059242861624

Epoch: 110| Step: 0
Training loss: 3.598357191361571
Validation loss: 2.842069324609384

Epoch: 6| Step: 1
Training loss: 3.0051149632556178
Validation loss: 2.8378442469539653

Epoch: 6| Step: 2
Training loss: 2.5179536833802065
Validation loss: 2.8390585221163906

Epoch: 6| Step: 3
Training loss: 3.1190287188363275
Validation loss: 2.8396186238923407

Epoch: 6| Step: 4
Training loss: 2.8079252548377016
Validation loss: 2.84032111491666

Epoch: 6| Step: 5
Training loss: 2.7813340935155915
Validation loss: 2.8399218377445825

Epoch: 6| Step: 6
Training loss: 3.290543102900848
Validation loss: 2.835924940025788

Epoch: 6| Step: 7
Training loss: 3.020714452750162
Validation loss: 2.8379771494354196

Epoch: 6| Step: 8
Training loss: 3.3135898164866195
Validation loss: 2.8377453589742596

Epoch: 6| Step: 9
Training loss: 2.944367679658914
Validation loss: 2.839181027184505

Epoch: 6| Step: 10
Training loss: 2.8886963054663335
Validation loss: 2.839364656146002

Epoch: 6| Step: 11
Training loss: 3.5318941862212654
Validation loss: 2.8349161528470668

Epoch: 6| Step: 12
Training loss: 3.3816293669314157
Validation loss: 2.838026518003948

Epoch: 6| Step: 13
Training loss: 3.9064927903063293
Validation loss: 2.84418887403223

Epoch: 111| Step: 0
Training loss: 2.7580739186473333
Validation loss: 2.846370023309788

Epoch: 6| Step: 1
Training loss: 3.500181738358465
Validation loss: 2.8520142933834927

Epoch: 6| Step: 2
Training loss: 2.660881582177711
Validation loss: 2.856791554317127

Epoch: 6| Step: 3
Training loss: 3.058650809154073
Validation loss: 2.862743541464783

Epoch: 6| Step: 4
Training loss: 3.1930625100926813
Validation loss: 2.851930009728487

Epoch: 6| Step: 5
Training loss: 3.8930651507919243
Validation loss: 2.848637364467497

Epoch: 6| Step: 6
Training loss: 3.54552282698888
Validation loss: 2.839159554934494

Epoch: 6| Step: 7
Training loss: 3.483520129243511
Validation loss: 2.8369289658243075

Epoch: 6| Step: 8
Training loss: 3.3525254082339186
Validation loss: 2.8358353462195343

Epoch: 6| Step: 9
Training loss: 2.856404580371979
Validation loss: 2.835015182013176

Epoch: 6| Step: 10
Training loss: 2.411957251813642
Validation loss: 2.836378815706151

Epoch: 6| Step: 11
Training loss: 2.869462693057811
Validation loss: 2.8357443627778562

Epoch: 6| Step: 12
Training loss: 3.047220533291876
Validation loss: 2.837600972703389

Epoch: 6| Step: 13
Training loss: 3.0241245800070526
Validation loss: 2.8359649014147084

Epoch: 112| Step: 0
Training loss: 2.831493921277761
Validation loss: 2.836094946951111

Epoch: 6| Step: 1
Training loss: 3.0554313827098527
Validation loss: 2.840284787310037

Epoch: 6| Step: 2
Training loss: 3.3031443787496233
Validation loss: 2.836002172048347

Epoch: 6| Step: 3
Training loss: 3.408950854805765
Validation loss: 2.838334514686632

Epoch: 6| Step: 4
Training loss: 3.2256404861702284
Validation loss: 2.8386482823107753

Epoch: 6| Step: 5
Training loss: 3.354052776669819
Validation loss: 2.846819879727146

Epoch: 6| Step: 6
Training loss: 2.7364560300896956
Validation loss: 2.8466838526434537

Epoch: 6| Step: 7
Training loss: 2.427268832953358
Validation loss: 2.848015922117045

Epoch: 6| Step: 8
Training loss: 3.9024779150641553
Validation loss: 2.8484959107933716

Epoch: 6| Step: 9
Training loss: 3.2414388136884122
Validation loss: 2.848459681143301

Epoch: 6| Step: 10
Training loss: 3.4234687890799718
Validation loss: 2.8406361278459156

Epoch: 6| Step: 11
Training loss: 2.998496314540912
Validation loss: 2.8400108982306325

Epoch: 6| Step: 12
Training loss: 2.7885868297325813
Validation loss: 2.83531430306134

Epoch: 6| Step: 13
Training loss: 3.0067227061336386
Validation loss: 2.835988701161808

Epoch: 113| Step: 0
Training loss: 3.5921298148097756
Validation loss: 2.838442526910495

Epoch: 6| Step: 1
Training loss: 2.629405820179457
Validation loss: 2.8367203871688202

Epoch: 6| Step: 2
Training loss: 3.458141428820347
Validation loss: 2.8418953333329373

Epoch: 6| Step: 3
Training loss: 1.9747861335945975
Validation loss: 2.8377585062341524

Epoch: 6| Step: 4
Training loss: 3.428807730138327
Validation loss: 2.835764434314876

Epoch: 6| Step: 5
Training loss: 2.5353593788999187
Validation loss: 2.833291785160538

Epoch: 6| Step: 6
Training loss: 3.1520918848325543
Validation loss: 2.8340855063910255

Epoch: 6| Step: 7
Training loss: 2.3062966112011463
Validation loss: 2.836356738355439

Epoch: 6| Step: 8
Training loss: 2.8601898533155588
Validation loss: 2.8385452606157346

Epoch: 6| Step: 9
Training loss: 4.047731758065733
Validation loss: 2.8350027174237704

Epoch: 6| Step: 10
Training loss: 3.106043118316975
Validation loss: 2.8369162502897773

Epoch: 6| Step: 11
Training loss: 3.472947339107641
Validation loss: 2.837912842181463

Epoch: 6| Step: 12
Training loss: 3.243503974301717
Validation loss: 2.8385216701616445

Epoch: 6| Step: 13
Training loss: 3.704773226244482
Validation loss: 2.839124800787559

Epoch: 114| Step: 0
Training loss: 3.5311454824998503
Validation loss: 2.838564130128408

Epoch: 6| Step: 1
Training loss: 2.3628350963806146
Validation loss: 2.8364085230564804

Epoch: 6| Step: 2
Training loss: 2.7017315045561396
Validation loss: 2.8359956978589507

Epoch: 6| Step: 3
Training loss: 2.5747447655855438
Validation loss: 2.8363941032624584

Epoch: 6| Step: 4
Training loss: 3.1280527081743985
Validation loss: 2.8317491209089227

Epoch: 6| Step: 5
Training loss: 3.461771638466652
Validation loss: 2.8315385056439792

Epoch: 6| Step: 6
Training loss: 3.5787960572631716
Validation loss: 2.8294527459557806

Epoch: 6| Step: 7
Training loss: 3.392197486022842
Validation loss: 2.8318665838124097

Epoch: 6| Step: 8
Training loss: 3.1864951550710092
Validation loss: 2.8320840968546754

Epoch: 6| Step: 9
Training loss: 3.181452230984251
Validation loss: 2.8322870311993227

Epoch: 6| Step: 10
Training loss: 3.126096609349482
Validation loss: 2.830880021054261

Epoch: 6| Step: 11
Training loss: 2.9564709957821957
Validation loss: 2.8294308084599935

Epoch: 6| Step: 12
Training loss: 3.2062550208217875
Validation loss: 2.8288683651137516

Epoch: 6| Step: 13
Training loss: 3.3507180028075143
Validation loss: 2.832314265179405

Epoch: 115| Step: 0
Training loss: 3.3702030707055277
Validation loss: 2.828559452331636

Epoch: 6| Step: 1
Training loss: 3.587446306737307
Validation loss: 2.825655166761771

Epoch: 6| Step: 2
Training loss: 3.437625119793227
Validation loss: 2.8265420266628287

Epoch: 6| Step: 3
Training loss: 2.7094689164829346
Validation loss: 2.831982979085515

Epoch: 6| Step: 4
Training loss: 2.7984738175566424
Validation loss: 2.8277576076233237

Epoch: 6| Step: 5
Training loss: 2.8727115977466524
Validation loss: 2.8306022024107085

Epoch: 6| Step: 6
Training loss: 3.080200115490038
Validation loss: 2.8282019691325093

Epoch: 6| Step: 7
Training loss: 3.419267889265123
Validation loss: 2.8276721766552315

Epoch: 6| Step: 8
Training loss: 3.6692872364046654
Validation loss: 2.829489222600679

Epoch: 6| Step: 9
Training loss: 3.017880243775668
Validation loss: 2.8420501608513242

Epoch: 6| Step: 10
Training loss: 3.094050537308173
Validation loss: 2.82920002769417

Epoch: 6| Step: 11
Training loss: 2.6663368339008495
Validation loss: 2.838092245375533

Epoch: 6| Step: 12
Training loss: 2.276925154831745
Validation loss: 2.8338494153546483

Epoch: 6| Step: 13
Training loss: 3.7102069336382684
Validation loss: 2.844163233804574

Epoch: 116| Step: 0
Training loss: 2.967915307206719
Validation loss: 2.8447256991593424

Epoch: 6| Step: 1
Training loss: 2.9704806453303525
Validation loss: 2.842827761996729

Epoch: 6| Step: 2
Training loss: 3.039916558375372
Validation loss: 2.8470880073776526

Epoch: 6| Step: 3
Training loss: 3.1475174461166056
Validation loss: 2.838825748915998

Epoch: 6| Step: 4
Training loss: 2.5005139776219436
Validation loss: 2.8327690596522106

Epoch: 6| Step: 5
Training loss: 3.1948576139383493
Validation loss: 2.828941626618312

Epoch: 6| Step: 6
Training loss: 3.3000840031884926
Validation loss: 2.828799509785899

Epoch: 6| Step: 7
Training loss: 3.1176115048801907
Validation loss: 2.8265231839174443

Epoch: 6| Step: 8
Training loss: 3.5378569513862033
Validation loss: 2.824824045974004

Epoch: 6| Step: 9
Training loss: 3.094478945156454
Validation loss: 2.8236392219193225

Epoch: 6| Step: 10
Training loss: 2.6824611178208353
Validation loss: 2.82043914515119

Epoch: 6| Step: 11
Training loss: 3.9710033357673953
Validation loss: 2.8224181985474317

Epoch: 6| Step: 12
Training loss: 3.0570377762157213
Validation loss: 2.8203486794553254

Epoch: 6| Step: 13
Training loss: 2.9166096454677723
Validation loss: 2.821118594986637

Epoch: 117| Step: 0
Training loss: 2.937273057328117
Validation loss: 2.822524498294645

Epoch: 6| Step: 1
Training loss: 3.3900455384023096
Validation loss: 2.8216750130362374

Epoch: 6| Step: 2
Training loss: 3.2933851818168107
Validation loss: 2.8234881979749202

Epoch: 6| Step: 3
Training loss: 2.578816454091691
Validation loss: 2.817731455097193

Epoch: 6| Step: 4
Training loss: 3.7588641624252586
Validation loss: 2.820123394300129

Epoch: 6| Step: 5
Training loss: 3.238175522719913
Validation loss: 2.823305317953209

Epoch: 6| Step: 6
Training loss: 3.389174753302469
Validation loss: 2.8206142527377187

Epoch: 6| Step: 7
Training loss: 3.2412780221477315
Validation loss: 2.822420456613963

Epoch: 6| Step: 8
Training loss: 3.1062251867151383
Validation loss: 2.8199815403393673

Epoch: 6| Step: 9
Training loss: 3.667571967523322
Validation loss: 2.822660478965936

Epoch: 6| Step: 10
Training loss: 2.951264294755724
Validation loss: 2.8215565225480375

Epoch: 6| Step: 11
Training loss: 2.313595074331018
Validation loss: 2.8223687377174302

Epoch: 6| Step: 12
Training loss: 1.9634594752532872
Validation loss: 2.820439839589575

Epoch: 6| Step: 13
Training loss: 3.6862279993372824
Validation loss: 2.8270413902805194

Epoch: 118| Step: 0
Training loss: 3.2410885338630258
Validation loss: 2.8200097731571683

Epoch: 6| Step: 1
Training loss: 2.5607946350205912
Validation loss: 2.824511455588762

Epoch: 6| Step: 2
Training loss: 3.144684706077028
Validation loss: 2.8235851392861675

Epoch: 6| Step: 3
Training loss: 3.6219822391304146
Validation loss: 2.8257285396983414

Epoch: 6| Step: 4
Training loss: 2.674320640929754
Validation loss: 2.8222090025556033

Epoch: 6| Step: 5
Training loss: 3.1364750559620846
Validation loss: 2.823467436272308

Epoch: 6| Step: 6
Training loss: 3.60128975123003
Validation loss: 2.825813013338311

Epoch: 6| Step: 7
Training loss: 3.219860588988973
Validation loss: 2.8246905582159756

Epoch: 6| Step: 8
Training loss: 3.316420340536174
Validation loss: 2.8261079821876396

Epoch: 6| Step: 9
Training loss: 2.488683359661197
Validation loss: 2.8274579872568704

Epoch: 6| Step: 10
Training loss: 2.8314604085248916
Validation loss: 2.823227621457561

Epoch: 6| Step: 11
Training loss: 3.396290629357638
Validation loss: 2.8302595836949034

Epoch: 6| Step: 12
Training loss: 3.301196840747286
Validation loss: 2.8221098728451226

Epoch: 6| Step: 13
Training loss: 2.8264336349440295
Validation loss: 2.8199036931710193

Epoch: 119| Step: 0
Training loss: 3.5890210426204745
Validation loss: 2.8192753115618387

Epoch: 6| Step: 1
Training loss: 2.582919385005749
Validation loss: 2.821805966975917

Epoch: 6| Step: 2
Training loss: 3.458870780884626
Validation loss: 2.8216569545836907

Epoch: 6| Step: 3
Training loss: 3.238484448728788
Validation loss: 2.81973752050495

Epoch: 6| Step: 4
Training loss: 3.5750532666486246
Validation loss: 2.8228985565213693

Epoch: 6| Step: 5
Training loss: 3.503290264713018
Validation loss: 2.8236493860738068

Epoch: 6| Step: 6
Training loss: 3.2405013146335246
Validation loss: 2.820883786141729

Epoch: 6| Step: 7
Training loss: 3.040610578606682
Validation loss: 2.819150256443802

Epoch: 6| Step: 8
Training loss: 3.1475335046804407
Validation loss: 2.814582761773865

Epoch: 6| Step: 9
Training loss: 2.6605949320224354
Validation loss: 2.821408309304495

Epoch: 6| Step: 10
Training loss: 2.983790475213631
Validation loss: 2.8148956268637595

Epoch: 6| Step: 11
Training loss: 2.5081564408933166
Validation loss: 2.8185778676509505

Epoch: 6| Step: 12
Training loss: 2.8036998826954647
Validation loss: 2.8140968101245405

Epoch: 6| Step: 13
Training loss: 3.1040262962879157
Validation loss: 2.8162781891355713

Epoch: 120| Step: 0
Training loss: 3.4073075918729097
Validation loss: 2.8142173109073356

Epoch: 6| Step: 1
Training loss: 2.7042927066562017
Validation loss: 2.815432370032527

Epoch: 6| Step: 2
Training loss: 3.171834109188395
Validation loss: 2.8161694779286255

Epoch: 6| Step: 3
Training loss: 2.9125851729222214
Validation loss: 2.8157660317436704

Epoch: 6| Step: 4
Training loss: 2.5550487391233174
Validation loss: 2.8166188824027394

Epoch: 6| Step: 5
Training loss: 2.6685347173189675
Validation loss: 2.8154917474996535

Epoch: 6| Step: 6
Training loss: 2.870959718650842
Validation loss: 2.8168463417812655

Epoch: 6| Step: 7
Training loss: 2.815808871718885
Validation loss: 2.815486000114238

Epoch: 6| Step: 8
Training loss: 3.0606166731830395
Validation loss: 2.813451440596083

Epoch: 6| Step: 9
Training loss: 3.4478990875134063
Validation loss: 2.819349660721058

Epoch: 6| Step: 10
Training loss: 3.4869822510906743
Validation loss: 2.8215843580021476

Epoch: 6| Step: 11
Training loss: 3.226878153067775
Validation loss: 2.8270418192101885

Epoch: 6| Step: 12
Training loss: 3.431765402629749
Validation loss: 2.8325251404424283

Epoch: 6| Step: 13
Training loss: 4.119082975458958
Validation loss: 2.8326421856213124

Epoch: 121| Step: 0
Training loss: 3.255645836484993
Validation loss: 2.8341799197507447

Epoch: 6| Step: 1
Training loss: 3.7277510245194305
Validation loss: 2.830233492997904

Epoch: 6| Step: 2
Training loss: 2.4109350396055373
Validation loss: 2.8343723830072967

Epoch: 6| Step: 3
Training loss: 2.9730541950396847
Validation loss: 2.8420030740153486

Epoch: 6| Step: 4
Training loss: 2.620590138839199
Validation loss: 2.830961025679065

Epoch: 6| Step: 5
Training loss: 2.799696197377034
Validation loss: 2.8201527438211564

Epoch: 6| Step: 6
Training loss: 2.6270730143704135
Validation loss: 2.8161235032098215

Epoch: 6| Step: 7
Training loss: 3.3626519831801436
Validation loss: 2.814097086157359

Epoch: 6| Step: 8
Training loss: 2.8029296806951605
Validation loss: 2.8094338497226214

Epoch: 6| Step: 9
Training loss: 3.0463381563312577
Validation loss: 2.815914572462443

Epoch: 6| Step: 10
Training loss: 3.542910473395787
Validation loss: 2.812228274692595

Epoch: 6| Step: 11
Training loss: 3.0211422115569424
Validation loss: 2.8132646767647005

Epoch: 6| Step: 12
Training loss: 3.4480868909291513
Validation loss: 2.812599891337993

Epoch: 6| Step: 13
Training loss: 4.02672518133969
Validation loss: 2.8145818755243064

Epoch: 122| Step: 0
Training loss: 3.108320661285451
Validation loss: 2.8118139571922875

Epoch: 6| Step: 1
Training loss: 3.737149281456668
Validation loss: 2.8146954124775556

Epoch: 6| Step: 2
Training loss: 2.796108972082194
Validation loss: 2.8115374322823383

Epoch: 6| Step: 3
Training loss: 2.544484426590555
Validation loss: 2.8136306622938148

Epoch: 6| Step: 4
Training loss: 3.5792535726160786
Validation loss: 2.8173354389658467

Epoch: 6| Step: 5
Training loss: 2.800755456781728
Validation loss: 2.8152960548085706

Epoch: 6| Step: 6
Training loss: 3.1434920400424984
Validation loss: 2.812884248215057

Epoch: 6| Step: 7
Training loss: 3.2033676427723283
Validation loss: 2.8111388345665884

Epoch: 6| Step: 8
Training loss: 2.9983312416034025
Validation loss: 2.812380600631457

Epoch: 6| Step: 9
Training loss: 2.9150258126269226
Validation loss: 2.81378572852554

Epoch: 6| Step: 10
Training loss: 3.581165204866754
Validation loss: 2.814613660102778

Epoch: 6| Step: 11
Training loss: 3.272281560987667
Validation loss: 2.812995070406569

Epoch: 6| Step: 12
Training loss: 2.9008071959897066
Validation loss: 2.813872121361105

Epoch: 6| Step: 13
Training loss: 2.6579412125285637
Validation loss: 2.80931856430712

Epoch: 123| Step: 0
Training loss: 3.331019329508547
Validation loss: 2.8114907097894593

Epoch: 6| Step: 1
Training loss: 2.9357508869561246
Validation loss: 2.80981077380444

Epoch: 6| Step: 2
Training loss: 2.7372485075788116
Validation loss: 2.8096193681310355

Epoch: 6| Step: 3
Training loss: 3.127255350693701
Validation loss: 2.81114638374503

Epoch: 6| Step: 4
Training loss: 2.9165720424743276
Validation loss: 2.806581633913638

Epoch: 6| Step: 5
Training loss: 3.2622112336379345
Validation loss: 2.8083553388445526

Epoch: 6| Step: 6
Training loss: 2.605687259507624
Validation loss: 2.80755930172036

Epoch: 6| Step: 7
Training loss: 3.139029785714922
Validation loss: 2.809612833147759

Epoch: 6| Step: 8
Training loss: 3.098070306993564
Validation loss: 2.805116574290282

Epoch: 6| Step: 9
Training loss: 3.601405738182748
Validation loss: 2.8074500684396426

Epoch: 6| Step: 10
Training loss: 3.3578875420138794
Validation loss: 2.8094320903999406

Epoch: 6| Step: 11
Training loss: 3.4416132506381034
Validation loss: 2.808542978645726

Epoch: 6| Step: 12
Training loss: 2.8735128785908954
Validation loss: 2.8078088259858527

Epoch: 6| Step: 13
Training loss: 3.1046904734274263
Validation loss: 2.807068083795367

Epoch: 124| Step: 0
Training loss: 2.962761229252621
Validation loss: 2.8099676008972883

Epoch: 6| Step: 1
Training loss: 3.3202704213785874
Validation loss: 2.820253934875107

Epoch: 6| Step: 2
Training loss: 3.072350056452677
Validation loss: 2.821416363465987

Epoch: 6| Step: 3
Training loss: 2.650269721358048
Validation loss: 2.826405563346291

Epoch: 6| Step: 4
Training loss: 3.382685352781552
Validation loss: 2.8239249056128504

Epoch: 6| Step: 5
Training loss: 3.3629208326229234
Validation loss: 2.833142949776987

Epoch: 6| Step: 6
Training loss: 3.2791369219105078
Validation loss: 2.81736170370428

Epoch: 6| Step: 7
Training loss: 3.1163142231100833
Validation loss: 2.8138911645275786

Epoch: 6| Step: 8
Training loss: 2.91159288417336
Validation loss: 2.809915395511198

Epoch: 6| Step: 9
Training loss: 2.3945525574475117
Validation loss: 2.8095782345286886

Epoch: 6| Step: 10
Training loss: 3.2606774044084945
Validation loss: 2.809084600746664

Epoch: 6| Step: 11
Training loss: 3.273023774943845
Validation loss: 2.809494826727916

Epoch: 6| Step: 12
Training loss: 3.219111746302179
Validation loss: 2.806872870143129

Epoch: 6| Step: 13
Training loss: 3.355949465119963
Validation loss: 2.806959933771112

Epoch: 125| Step: 0
Training loss: 2.8062755795950602
Validation loss: 2.8074614216886036

Epoch: 6| Step: 1
Training loss: 3.1306660973853266
Validation loss: 2.8139518026066486

Epoch: 6| Step: 2
Training loss: 2.637417532549087
Validation loss: 2.8130182953133396

Epoch: 6| Step: 3
Training loss: 3.6095028809191
Validation loss: 2.815328380416491

Epoch: 6| Step: 4
Training loss: 3.0786792236816587
Validation loss: 2.812361691263318

Epoch: 6| Step: 5
Training loss: 3.5840438463645468
Validation loss: 2.811978651649402

Epoch: 6| Step: 6
Training loss: 3.387341856696188
Validation loss: 2.8059265249928096

Epoch: 6| Step: 7
Training loss: 3.28699694943845
Validation loss: 2.8032006419737763

Epoch: 6| Step: 8
Training loss: 2.6280195035863927
Validation loss: 2.8069909653278313

Epoch: 6| Step: 9
Training loss: 2.631752955556351
Validation loss: 2.8044088307871764

Epoch: 6| Step: 10
Training loss: 3.1748554527239374
Validation loss: 2.8046832889421642

Epoch: 6| Step: 11
Training loss: 2.93755973592852
Validation loss: 2.8045589497427192

Epoch: 6| Step: 12
Training loss: 3.0593717518556396
Validation loss: 2.80272661336446

Epoch: 6| Step: 13
Training loss: 3.5613888798015063
Validation loss: 2.803010799792317

Epoch: 126| Step: 0
Training loss: 2.1569473686888943
Validation loss: 2.8043445088705323

Epoch: 6| Step: 1
Training loss: 3.4893057793459925
Validation loss: 2.809965826399031

Epoch: 6| Step: 2
Training loss: 3.642048046006723
Validation loss: 2.810296100977427

Epoch: 6| Step: 3
Training loss: 3.5397986179119134
Validation loss: 2.822497195286194

Epoch: 6| Step: 4
Training loss: 3.5882166183302027
Validation loss: 2.825529588315573

Epoch: 6| Step: 5
Training loss: 3.7462785693133505
Validation loss: 2.827048335668576

Epoch: 6| Step: 6
Training loss: 3.1965875669789274
Validation loss: 2.819302098362959

Epoch: 6| Step: 7
Training loss: 3.113434714791142
Validation loss: 2.813340498783862

Epoch: 6| Step: 8
Training loss: 2.8328309081163834
Validation loss: 2.8155790340182487

Epoch: 6| Step: 9
Training loss: 2.6186980941107674
Validation loss: 2.8067473706682984

Epoch: 6| Step: 10
Training loss: 2.908057522379294
Validation loss: 2.803929528392357

Epoch: 6| Step: 11
Training loss: 2.7723967842722943
Validation loss: 2.797153256717304

Epoch: 6| Step: 12
Training loss: 2.5711912374870574
Validation loss: 2.803951571232062

Epoch: 6| Step: 13
Training loss: 2.780011190487959
Validation loss: 2.7994846532624327

Epoch: 127| Step: 0
Training loss: 3.538135937793606
Validation loss: 2.797819048711884

Epoch: 6| Step: 1
Training loss: 2.986234714601469
Validation loss: 2.8009520070309875

Epoch: 6| Step: 2
Training loss: 3.669651088499849
Validation loss: 2.8053073276422285

Epoch: 6| Step: 3
Training loss: 2.7882579850594094
Validation loss: 2.8003992272181786

Epoch: 6| Step: 4
Training loss: 3.729284160333018
Validation loss: 2.8007416232296007

Epoch: 6| Step: 5
Training loss: 3.077016563095725
Validation loss: 2.802066090366789

Epoch: 6| Step: 6
Training loss: 3.150291332517729
Validation loss: 2.806764553212235

Epoch: 6| Step: 7
Training loss: 3.2957925330207503
Validation loss: 2.8113276673737593

Epoch: 6| Step: 8
Training loss: 3.2786437810518216
Validation loss: 2.8081716704982025

Epoch: 6| Step: 9
Training loss: 2.897191193575907
Validation loss: 2.8048830837362724

Epoch: 6| Step: 10
Training loss: 2.849831418857221
Validation loss: 2.8148743855731175

Epoch: 6| Step: 11
Training loss: 2.6466548175050066
Validation loss: 2.817947827580735

Epoch: 6| Step: 12
Training loss: 2.356432361780616
Validation loss: 2.8119615839302132

Epoch: 6| Step: 13
Training loss: 2.700736782424054
Validation loss: 2.819383488375746

Epoch: 128| Step: 0
Training loss: 2.8619463256025406
Validation loss: 2.82379894880681

Epoch: 6| Step: 1
Training loss: 3.0286766219057006
Validation loss: 2.821967670870125

Epoch: 6| Step: 2
Training loss: 3.043320524084983
Validation loss: 2.806966200023279

Epoch: 6| Step: 3
Training loss: 3.4055331814563194
Validation loss: 2.809641330746192

Epoch: 6| Step: 4
Training loss: 2.5333794008215746
Validation loss: 2.8009419728559792

Epoch: 6| Step: 5
Training loss: 2.9477292777488
Validation loss: 2.799681588495739

Epoch: 6| Step: 6
Training loss: 3.566930057628092
Validation loss: 2.7967201593814957

Epoch: 6| Step: 7
Training loss: 4.205927145188652
Validation loss: 2.7952712921889424

Epoch: 6| Step: 8
Training loss: 2.9561834089912646
Validation loss: 2.795518153805052

Epoch: 6| Step: 9
Training loss: 2.930814724551178
Validation loss: 2.7924216628066842

Epoch: 6| Step: 10
Training loss: 2.622786360562342
Validation loss: 2.79874236148053

Epoch: 6| Step: 11
Training loss: 3.129586478025092
Validation loss: 2.7956253700148537

Epoch: 6| Step: 12
Training loss: 2.7667713268047835
Validation loss: 2.7921199849894447

Epoch: 6| Step: 13
Training loss: 3.2022368897893294
Validation loss: 2.794339784734558

Epoch: 129| Step: 0
Training loss: 2.5574350310395535
Validation loss: 2.7970724122670023

Epoch: 6| Step: 1
Training loss: 2.728227342082076
Validation loss: 2.797091116122971

Epoch: 6| Step: 2
Training loss: 3.162747333489605
Validation loss: 2.7994666595446693

Epoch: 6| Step: 3
Training loss: 3.2773959822919863
Validation loss: 2.7952369755447077

Epoch: 6| Step: 4
Training loss: 2.587414829492544
Validation loss: 2.794074580453304

Epoch: 6| Step: 5
Training loss: 3.9042218856136355
Validation loss: 2.7948392149235524

Epoch: 6| Step: 6
Training loss: 2.967942137974188
Validation loss: 2.795873418060657

Epoch: 6| Step: 7
Training loss: 3.4776255835996825
Validation loss: 2.801816475103541

Epoch: 6| Step: 8
Training loss: 2.74736087047634
Validation loss: 2.798446932157068

Epoch: 6| Step: 9
Training loss: 2.0105575617566793
Validation loss: 2.810139066883613

Epoch: 6| Step: 10
Training loss: 3.8625618445127254
Validation loss: 2.809350370107302

Epoch: 6| Step: 11
Training loss: 3.125709148053071
Validation loss: 2.8051837709797303

Epoch: 6| Step: 12
Training loss: 3.5388446260801873
Validation loss: 2.8193086890882375

Epoch: 6| Step: 13
Training loss: 2.761898482758724
Validation loss: 2.8123101483692303

Epoch: 130| Step: 0
Training loss: 3.4830822107303963
Validation loss: 2.7996124988273157

Epoch: 6| Step: 1
Training loss: 2.9676135648675253
Validation loss: 2.794071643445808

Epoch: 6| Step: 2
Training loss: 2.8317862569138565
Validation loss: 2.791230026305984

Epoch: 6| Step: 3
Training loss: 2.9820921789975046
Validation loss: 2.795510577096024

Epoch: 6| Step: 4
Training loss: 3.813364399959044
Validation loss: 2.7968612169173728

Epoch: 6| Step: 5
Training loss: 2.2223181174038533
Validation loss: 2.801855088429548

Epoch: 6| Step: 6
Training loss: 2.6511171901015342
Validation loss: 2.803834903769708

Epoch: 6| Step: 7
Training loss: 2.9685231975454114
Validation loss: 2.808128976481092

Epoch: 6| Step: 8
Training loss: 3.2788824350048
Validation loss: 2.8102039914531107

Epoch: 6| Step: 9
Training loss: 3.77118231632034
Validation loss: 2.8124680657436723

Epoch: 6| Step: 10
Training loss: 2.909888993862825
Validation loss: 2.804176828167022

Epoch: 6| Step: 11
Training loss: 3.470618492215164
Validation loss: 2.799944772922807

Epoch: 6| Step: 12
Training loss: 2.9590075803545526
Validation loss: 2.7966747651085635

Epoch: 6| Step: 13
Training loss: 2.824120146532506
Validation loss: 2.7955491005323765

Epoch: 131| Step: 0
Training loss: 3.470531109447173
Validation loss: 2.7938725427392432

Epoch: 6| Step: 1
Training loss: 3.398961379789966
Validation loss: 2.7911262307445415

Epoch: 6| Step: 2
Training loss: 3.2030862945451117
Validation loss: 2.8001406174316927

Epoch: 6| Step: 3
Training loss: 2.719145647396956
Validation loss: 2.7996777371006467

Epoch: 6| Step: 4
Training loss: 2.464369738866079
Validation loss: 2.806965389000612

Epoch: 6| Step: 5
Training loss: 2.9617834971119428
Validation loss: 2.8148161526676034

Epoch: 6| Step: 6
Training loss: 3.208321278206772
Validation loss: 2.8197637901442114

Epoch: 6| Step: 7
Training loss: 3.318848051357653
Validation loss: 2.8186913309589356

Epoch: 6| Step: 8
Training loss: 3.3247211941728185
Validation loss: 2.8188435268254084

Epoch: 6| Step: 9
Training loss: 3.5264118099849138
Validation loss: 2.825455387257854

Epoch: 6| Step: 10
Training loss: 2.1140351986584784
Validation loss: 2.825701458172781

Epoch: 6| Step: 11
Training loss: 2.7548813412516013
Validation loss: 2.8212020916785954

Epoch: 6| Step: 12
Training loss: 3.201906744795695
Validation loss: 2.813345124256383

Epoch: 6| Step: 13
Training loss: 3.7856393354250586
Validation loss: 2.8036248570017848

Epoch: 132| Step: 0
Training loss: 3.59506957664595
Validation loss: 2.7993726652376627

Epoch: 6| Step: 1
Training loss: 2.589224210487866
Validation loss: 2.7985303760895146

Epoch: 6| Step: 2
Training loss: 3.1461288279682464
Validation loss: 2.7913054990386255

Epoch: 6| Step: 3
Training loss: 2.849529722798708
Validation loss: 2.790413547860861

Epoch: 6| Step: 4
Training loss: 2.9569602967874533
Validation loss: 2.7915340787587613

Epoch: 6| Step: 5
Training loss: 3.485060004397762
Validation loss: 2.792777550449899

Epoch: 6| Step: 6
Training loss: 2.5292154306385366
Validation loss: 2.789736856859549

Epoch: 6| Step: 7
Training loss: 3.378044168385673
Validation loss: 2.793010258554415

Epoch: 6| Step: 8
Training loss: 3.3219337723737223
Validation loss: 2.7915424037037746

Epoch: 6| Step: 9
Training loss: 3.3223767135858537
Validation loss: 2.794441306861861

Epoch: 6| Step: 10
Training loss: 3.2311302531796353
Validation loss: 2.7935501660330875

Epoch: 6| Step: 11
Training loss: 2.2685192694918657
Validation loss: 2.797625251952896

Epoch: 6| Step: 12
Training loss: 3.2597255441476887
Validation loss: 2.7977598624583946

Epoch: 6| Step: 13
Training loss: 3.364198707980452
Validation loss: 2.8020415889474206

Epoch: 133| Step: 0
Training loss: 2.872396866264169
Validation loss: 2.7936930390729353

Epoch: 6| Step: 1
Training loss: 3.163932741118215
Validation loss: 2.793918462435182

Epoch: 6| Step: 2
Training loss: 3.3967401584789543
Validation loss: 2.7889602075701987

Epoch: 6| Step: 3
Training loss: 3.44753271694579
Validation loss: 2.7880181402176314

Epoch: 6| Step: 4
Training loss: 2.322142011402008
Validation loss: 2.788016100719779

Epoch: 6| Step: 5
Training loss: 3.7200289538497504
Validation loss: 2.7882851158128186

Epoch: 6| Step: 6
Training loss: 2.424084055850098
Validation loss: 2.787988270344367

Epoch: 6| Step: 7
Training loss: 3.315405956514849
Validation loss: 2.7873739966658797

Epoch: 6| Step: 8
Training loss: 2.9317190222070906
Validation loss: 2.7896001710077005

Epoch: 6| Step: 9
Training loss: 3.421110024144539
Validation loss: 2.784588272148704

Epoch: 6| Step: 10
Training loss: 3.0386253375927645
Validation loss: 2.7895876578850154

Epoch: 6| Step: 11
Training loss: 2.8872395253461725
Validation loss: 2.7951844601839837

Epoch: 6| Step: 12
Training loss: 2.913735542670623
Validation loss: 2.792163415926106

Epoch: 6| Step: 13
Training loss: 3.3312941671739336
Validation loss: 2.794793522250355

Epoch: 134| Step: 0
Training loss: 2.8913609573045016
Validation loss: 2.798769137787489

Epoch: 6| Step: 1
Training loss: 3.4627465886746505
Validation loss: 2.793788410950556

Epoch: 6| Step: 2
Training loss: 3.1643343584983317
Validation loss: 2.7966153465484545

Epoch: 6| Step: 3
Training loss: 3.361835802696859
Validation loss: 2.795037301125554

Epoch: 6| Step: 4
Training loss: 2.3406252566898953
Validation loss: 2.793421956747818

Epoch: 6| Step: 5
Training loss: 3.130564503815379
Validation loss: 2.7878299980773527

Epoch: 6| Step: 6
Training loss: 3.4367645864168135
Validation loss: 2.7875571895592826

Epoch: 6| Step: 7
Training loss: 2.8286444255497805
Validation loss: 2.7880868183793543

Epoch: 6| Step: 8
Training loss: 3.113945596953507
Validation loss: 2.7875051530646635

Epoch: 6| Step: 9
Training loss: 3.0825652806902237
Validation loss: 2.784601238600875

Epoch: 6| Step: 10
Training loss: 3.011505792314867
Validation loss: 2.7844918633392575

Epoch: 6| Step: 11
Training loss: 3.278661088046985
Validation loss: 2.790549443305215

Epoch: 6| Step: 12
Training loss: 2.9353819982910423
Validation loss: 2.787826913794791

Epoch: 6| Step: 13
Training loss: 3.25769467220787
Validation loss: 2.7833007758524757

Epoch: 135| Step: 0
Training loss: 4.11732647713731
Validation loss: 2.789042228408365

Epoch: 6| Step: 1
Training loss: 3.08081773430161
Validation loss: 2.7859781993402315

Epoch: 6| Step: 2
Training loss: 2.5584073763227497
Validation loss: 2.7885764320539668

Epoch: 6| Step: 3
Training loss: 3.0860425713916206
Validation loss: 2.7920441504680262

Epoch: 6| Step: 4
Training loss: 3.209858882571087
Validation loss: 2.791321474300962

Epoch: 6| Step: 5
Training loss: 3.1762658907189936
Validation loss: 2.7944540450321016

Epoch: 6| Step: 6
Training loss: 2.7910831088215775
Validation loss: 2.787711200156189

Epoch: 6| Step: 7
Training loss: 3.4646096478394006
Validation loss: 2.791382637568203

Epoch: 6| Step: 8
Training loss: 2.9856344231897425
Validation loss: 2.784616926417417

Epoch: 6| Step: 9
Training loss: 2.8496500369250217
Validation loss: 2.791507774891799

Epoch: 6| Step: 10
Training loss: 2.8977352638610427
Validation loss: 2.7858429845818016

Epoch: 6| Step: 11
Training loss: 3.3745174769453294
Validation loss: 2.782193289287046

Epoch: 6| Step: 12
Training loss: 2.334295301596118
Validation loss: 2.783249589164831

Epoch: 6| Step: 13
Training loss: 3.0116850261061776
Validation loss: 2.7798264222199105

Epoch: 136| Step: 0
Training loss: 3.1746975972499136
Validation loss: 2.7837632104149734

Epoch: 6| Step: 1
Training loss: 3.015496285809592
Validation loss: 2.7824798801416555

Epoch: 6| Step: 2
Training loss: 3.0303788653912664
Validation loss: 2.7812647425652686

Epoch: 6| Step: 3
Training loss: 4.041343413859446
Validation loss: 2.7804767362821763

Epoch: 6| Step: 4
Training loss: 3.0013060905556674
Validation loss: 2.782357507295537

Epoch: 6| Step: 5
Training loss: 2.6029780205565487
Validation loss: 2.7817030608292845

Epoch: 6| Step: 6
Training loss: 3.343000381437754
Validation loss: 2.7865819054705327

Epoch: 6| Step: 7
Training loss: 2.6277114851289074
Validation loss: 2.787386633772535

Epoch: 6| Step: 8
Training loss: 3.3218925755521207
Validation loss: 2.784284110323869

Epoch: 6| Step: 9
Training loss: 3.2778849467486033
Validation loss: 2.7849042298324305

Epoch: 6| Step: 10
Training loss: 3.4235295167132183
Validation loss: 2.7842569055943

Epoch: 6| Step: 11
Training loss: 2.5862791636663185
Validation loss: 2.7986609208016553

Epoch: 6| Step: 12
Training loss: 2.4984111505375024
Validation loss: 2.7990887281162355

Epoch: 6| Step: 13
Training loss: 2.9466062583024706
Validation loss: 2.7997908364310335

Epoch: 137| Step: 0
Training loss: 2.461990663939933
Validation loss: 2.789914657820049

Epoch: 6| Step: 1
Training loss: 3.5682155870387002
Validation loss: 2.789049023921153

Epoch: 6| Step: 2
Training loss: 2.809928905633008
Validation loss: 2.7934115027292075

Epoch: 6| Step: 3
Training loss: 2.990319209075842
Validation loss: 2.7901602035175705

Epoch: 6| Step: 4
Training loss: 3.6421751725009903
Validation loss: 2.790015264060568

Epoch: 6| Step: 5
Training loss: 3.192051947092116
Validation loss: 2.7802798219897915

Epoch: 6| Step: 6
Training loss: 3.0749495339323
Validation loss: 2.775923276083372

Epoch: 6| Step: 7
Training loss: 3.220363471799873
Validation loss: 2.777989413666109

Epoch: 6| Step: 8
Training loss: 2.3864335359516913
Validation loss: 2.7767205248189324

Epoch: 6| Step: 9
Training loss: 3.3249228389649588
Validation loss: 2.7784726262015513

Epoch: 6| Step: 10
Training loss: 3.416022185662296
Validation loss: 2.7797960474711103

Epoch: 6| Step: 11
Training loss: 3.0271260632419636
Validation loss: 2.777884011305218

Epoch: 6| Step: 12
Training loss: 3.0762332583161363
Validation loss: 2.77959547781618

Epoch: 6| Step: 13
Training loss: 2.520655370898674
Validation loss: 2.7761046121133925

Epoch: 138| Step: 0
Training loss: 3.224323669013177
Validation loss: 2.778884816678875

Epoch: 6| Step: 1
Training loss: 3.1014193638748173
Validation loss: 2.78100919493346

Epoch: 6| Step: 2
Training loss: 3.2411257556504083
Validation loss: 2.779746497811475

Epoch: 6| Step: 3
Training loss: 2.9350686257964678
Validation loss: 2.7809039282319907

Epoch: 6| Step: 4
Training loss: 2.9680094548200766
Validation loss: 2.7807940129690905

Epoch: 6| Step: 5
Training loss: 2.9664484036625005
Validation loss: 2.7782149697540754

Epoch: 6| Step: 6
Training loss: 2.7210853456054713
Validation loss: 2.779013049959805

Epoch: 6| Step: 7
Training loss: 3.300338733512124
Validation loss: 2.7769570480152175

Epoch: 6| Step: 8
Training loss: 2.8786809825367503
Validation loss: 2.774645306047662

Epoch: 6| Step: 9
Training loss: 2.7405175669719015
Validation loss: 2.777300387313514

Epoch: 6| Step: 10
Training loss: 3.484320806928619
Validation loss: 2.781120158998429

Epoch: 6| Step: 11
Training loss: 3.2411909295292367
Validation loss: 2.776936828378887

Epoch: 6| Step: 12
Training loss: 3.479362132050538
Validation loss: 2.7808058530285966

Epoch: 6| Step: 13
Training loss: 2.8291202711777848
Validation loss: 2.7803603682062032

Epoch: 139| Step: 0
Training loss: 3.224786671524686
Validation loss: 2.785656495640336

Epoch: 6| Step: 1
Training loss: 3.068267995735109
Validation loss: 2.783080671574606

Epoch: 6| Step: 2
Training loss: 3.80035341526714
Validation loss: 2.7844465947180597

Epoch: 6| Step: 3
Training loss: 2.046355785881548
Validation loss: 2.7816215940704554

Epoch: 6| Step: 4
Training loss: 3.503230375258497
Validation loss: 2.794892686134641

Epoch: 6| Step: 5
Training loss: 2.6624766353244644
Validation loss: 2.7911611407542884

Epoch: 6| Step: 6
Training loss: 2.9479961766460163
Validation loss: 2.791611654529034

Epoch: 6| Step: 7
Training loss: 2.6046921975425827
Validation loss: 2.786691437889009

Epoch: 6| Step: 8
Training loss: 3.3565306931513947
Validation loss: 2.7823422001759734

Epoch: 6| Step: 9
Training loss: 2.85375808427278
Validation loss: 2.776587587599477

Epoch: 6| Step: 10
Training loss: 3.3741876542888036
Validation loss: 2.7769255137377624

Epoch: 6| Step: 11
Training loss: 2.81896018790353
Validation loss: 2.778967432863388

Epoch: 6| Step: 12
Training loss: 3.2373329679194605
Validation loss: 2.774316946216393

Epoch: 6| Step: 13
Training loss: 3.6067347261937406
Validation loss: 2.777768825769527

Epoch: 140| Step: 0
Training loss: 3.305657859807696
Validation loss: 2.7739145851007136

Epoch: 6| Step: 1
Training loss: 2.8645170076957003
Validation loss: 2.775741621575799

Epoch: 6| Step: 2
Training loss: 2.986358143447885
Validation loss: 2.7731238218261804

Epoch: 6| Step: 3
Training loss: 3.5358430142659336
Validation loss: 2.776514591895523

Epoch: 6| Step: 4
Training loss: 2.5377169286147407
Validation loss: 2.772247677625882

Epoch: 6| Step: 5
Training loss: 3.1935089916211963
Validation loss: 2.7755873855445876

Epoch: 6| Step: 6
Training loss: 3.0819374911475443
Validation loss: 2.7740592189210127

Epoch: 6| Step: 7
Training loss: 3.1645869067743018
Validation loss: 2.77193751336503

Epoch: 6| Step: 8
Training loss: 3.219998756313676
Validation loss: 2.774828274036349

Epoch: 6| Step: 9
Training loss: 3.0024851995733846
Validation loss: 2.7766624556462003

Epoch: 6| Step: 10
Training loss: 3.244989788115763
Validation loss: 2.774624966081438

Epoch: 6| Step: 11
Training loss: 3.4588958711679956
Validation loss: 2.778521781534393

Epoch: 6| Step: 12
Training loss: 2.4676617505395027
Validation loss: 2.7771701973417433

Epoch: 6| Step: 13
Training loss: 2.6938461959196016
Validation loss: 2.7763803086921506

Epoch: 141| Step: 0
Training loss: 3.184666440016518
Validation loss: 2.7901551941344986

Epoch: 6| Step: 1
Training loss: 3.6657489726378576
Validation loss: 2.795998192104841

Epoch: 6| Step: 2
Training loss: 2.8858371983618927
Validation loss: 2.802541181587361

Epoch: 6| Step: 3
Training loss: 2.6995080994288267
Validation loss: 2.782709686918431

Epoch: 6| Step: 4
Training loss: 3.268977584355923
Validation loss: 2.7733652163509626

Epoch: 6| Step: 5
Training loss: 2.9511038509181287
Validation loss: 2.7749659951449157

Epoch: 6| Step: 6
Training loss: 2.8746845238130385
Validation loss: 2.7751314990293476

Epoch: 6| Step: 7
Training loss: 2.9442875138534617
Validation loss: 2.7713269103964446

Epoch: 6| Step: 8
Training loss: 3.0896059275079857
Validation loss: 2.7690272255666684

Epoch: 6| Step: 9
Training loss: 2.8026789111454584
Validation loss: 2.7745128127068486

Epoch: 6| Step: 10
Training loss: 3.3761645533155598
Validation loss: 2.7741325241258603

Epoch: 6| Step: 11
Training loss: 2.7491323662921396
Validation loss: 2.769098944765315

Epoch: 6| Step: 12
Training loss: 3.518779373723909
Validation loss: 2.772096501576178

Epoch: 6| Step: 13
Training loss: 2.9049650243337766
Validation loss: 2.7768804762823716

Epoch: 142| Step: 0
Training loss: 2.3910959814535246
Validation loss: 2.7831653619322547

Epoch: 6| Step: 1
Training loss: 3.0894025060751567
Validation loss: 2.78647118558652

Epoch: 6| Step: 2
Training loss: 2.8812198529766038
Validation loss: 2.789778766373822

Epoch: 6| Step: 3
Training loss: 3.016554931201171
Validation loss: 2.8007041909224335

Epoch: 6| Step: 4
Training loss: 3.225319685357392
Validation loss: 2.807018008177095

Epoch: 6| Step: 5
Training loss: 3.319429024235348
Validation loss: 2.8083630296956645

Epoch: 6| Step: 6
Training loss: 3.693803733267032
Validation loss: 2.785340393189389

Epoch: 6| Step: 7
Training loss: 3.0933355188636074
Validation loss: 2.7756467046990307

Epoch: 6| Step: 8
Training loss: 2.974770634889385
Validation loss: 2.7694061407012263

Epoch: 6| Step: 9
Training loss: 2.454188608310024
Validation loss: 2.7656350167775963

Epoch: 6| Step: 10
Training loss: 3.666919497240588
Validation loss: 2.7681653759542426

Epoch: 6| Step: 11
Training loss: 3.1126662428248215
Validation loss: 2.7702690146315874

Epoch: 6| Step: 12
Training loss: 3.0009986486841838
Validation loss: 2.7725320223287535

Epoch: 6| Step: 13
Training loss: 2.9684815937979616
Validation loss: 2.775396435094829

Epoch: 143| Step: 0
Training loss: 3.6762308459932473
Validation loss: 2.776163850034112

Epoch: 6| Step: 1
Training loss: 3.106709320064792
Validation loss: 2.78206120609459

Epoch: 6| Step: 2
Training loss: 2.758451566054196
Validation loss: 2.7889396916425637

Epoch: 6| Step: 3
Training loss: 2.8169911447859124
Validation loss: 2.7821881863148996

Epoch: 6| Step: 4
Training loss: 3.638075037857122
Validation loss: 2.7772124077265343

Epoch: 6| Step: 5
Training loss: 3.135753592366756
Validation loss: 2.772694592573441

Epoch: 6| Step: 6
Training loss: 2.331582797843706
Validation loss: 2.7721252461256776

Epoch: 6| Step: 7
Training loss: 3.062545776025074
Validation loss: 2.767973204038884

Epoch: 6| Step: 8
Training loss: 3.161755585037623
Validation loss: 2.7675574301877894

Epoch: 6| Step: 9
Training loss: 2.735681886349504
Validation loss: 2.767614470462558

Epoch: 6| Step: 10
Training loss: 3.1191678365477085
Validation loss: 2.765080151664861

Epoch: 6| Step: 11
Training loss: 3.0075348961280937
Validation loss: 2.7667686841915278

Epoch: 6| Step: 12
Training loss: 3.0577307174108306
Validation loss: 2.7695813795176836

Epoch: 6| Step: 13
Training loss: 3.7273194126157354
Validation loss: 2.7841218844019404

Epoch: 144| Step: 0
Training loss: 3.3899965890512775
Validation loss: 2.7900865797497265

Epoch: 6| Step: 1
Training loss: 3.173504640966796
Validation loss: 2.801201470528743

Epoch: 6| Step: 2
Training loss: 3.2321362694821443
Validation loss: 2.8138570521867354

Epoch: 6| Step: 3
Training loss: 2.541963862152501
Validation loss: 2.818598910946938

Epoch: 6| Step: 4
Training loss: 2.484350240332104
Validation loss: 2.813117760888678

Epoch: 6| Step: 5
Training loss: 3.2180008988743696
Validation loss: 2.8099353176264907

Epoch: 6| Step: 6
Training loss: 2.3420872194124116
Validation loss: 2.7955147313580557

Epoch: 6| Step: 7
Training loss: 3.4753440521951102
Validation loss: 2.77936240196313

Epoch: 6| Step: 8
Training loss: 2.950098171863576
Validation loss: 2.78146460289247

Epoch: 6| Step: 9
Training loss: 3.1819046875725077
Validation loss: 2.7704417716650362

Epoch: 6| Step: 10
Training loss: 3.0954238524956676
Validation loss: 2.7665676380417867

Epoch: 6| Step: 11
Training loss: 3.0506734010826597
Validation loss: 2.765273704810183

Epoch: 6| Step: 12
Training loss: 3.3450340586298304
Validation loss: 2.7628223291092047

Epoch: 6| Step: 13
Training loss: 3.55837090775412
Validation loss: 2.7633148179538027

Epoch: 145| Step: 0
Training loss: 2.830156302836705
Validation loss: 2.765576011724869

Epoch: 6| Step: 1
Training loss: 3.231300846489299
Validation loss: 2.764667289313387

Epoch: 6| Step: 2
Training loss: 3.375855231539339
Validation loss: 2.765030087960017

Epoch: 6| Step: 3
Training loss: 2.7974631261227736
Validation loss: 2.7640835968321555

Epoch: 6| Step: 4
Training loss: 2.5104937614115728
Validation loss: 2.7684072722891706

Epoch: 6| Step: 5
Training loss: 3.195421137746728
Validation loss: 2.7657747250742566

Epoch: 6| Step: 6
Training loss: 3.4852258302044667
Validation loss: 2.7708226759695838

Epoch: 6| Step: 7
Training loss: 2.914242654503673
Validation loss: 2.7688031468829544

Epoch: 6| Step: 8
Training loss: 3.384313378164909
Validation loss: 2.762340287912181

Epoch: 6| Step: 9
Training loss: 2.388947540371486
Validation loss: 2.769394802698354

Epoch: 6| Step: 10
Training loss: 3.606049562169691
Validation loss: 2.76660276157048

Epoch: 6| Step: 11
Training loss: 3.2615781102725685
Validation loss: 2.7632138593266986

Epoch: 6| Step: 12
Training loss: 3.083720895964644
Validation loss: 2.7651027610221006

Epoch: 6| Step: 13
Training loss: 2.8302402068191843
Validation loss: 2.763267339469117

Epoch: 146| Step: 0
Training loss: 2.991210140436149
Validation loss: 2.7621896527408794

Epoch: 6| Step: 1
Training loss: 3.113568722269264
Validation loss: 2.7632330595628467

Epoch: 6| Step: 2
Training loss: 3.036963515136945
Validation loss: 2.7621966331148875

Epoch: 6| Step: 3
Training loss: 2.7372249029578404
Validation loss: 2.765049630686366

Epoch: 6| Step: 4
Training loss: 2.887247782999757
Validation loss: 2.765786350429346

Epoch: 6| Step: 5
Training loss: 2.691899003984018
Validation loss: 2.777486696134723

Epoch: 6| Step: 6
Training loss: 3.2428704335328664
Validation loss: 2.780934419940793

Epoch: 6| Step: 7
Training loss: 3.7306622679681958
Validation loss: 2.8049962217793794

Epoch: 6| Step: 8
Training loss: 3.447506852395576
Validation loss: 2.79448138809593

Epoch: 6| Step: 9
Training loss: 2.334734756957513
Validation loss: 2.7687343672433253

Epoch: 6| Step: 10
Training loss: 3.1456145322046827
Validation loss: 2.762609358949337

Epoch: 6| Step: 11
Training loss: 3.4196980837240125
Validation loss: 2.7590346316239382

Epoch: 6| Step: 12
Training loss: 2.8515327347547546
Validation loss: 2.762220625753735

Epoch: 6| Step: 13
Training loss: 3.5561686689197747
Validation loss: 2.760999805958622

Epoch: 147| Step: 0
Training loss: 3.12025900743809
Validation loss: 2.760508772616892

Epoch: 6| Step: 1
Training loss: 3.129174457917925
Validation loss: 2.7634449305751176

Epoch: 6| Step: 2
Training loss: 3.49315628166068
Validation loss: 2.7639837366401534

Epoch: 6| Step: 3
Training loss: 3.0439536149930886
Validation loss: 2.765430319142161

Epoch: 6| Step: 4
Training loss: 3.4700200960308445
Validation loss: 2.762947183522999

Epoch: 6| Step: 5
Training loss: 2.9486224045259943
Validation loss: 2.764841137218521

Epoch: 6| Step: 6
Training loss: 3.884305793471001
Validation loss: 2.7645730716176002

Epoch: 6| Step: 7
Training loss: 2.7432951252510316
Validation loss: 2.7618103564475733

Epoch: 6| Step: 8
Training loss: 2.994793028900279
Validation loss: 2.763803944696298

Epoch: 6| Step: 9
Training loss: 1.76102922906398
Validation loss: 2.762670379323057

Epoch: 6| Step: 10
Training loss: 3.3671767374030432
Validation loss: 2.7594775790604036

Epoch: 6| Step: 11
Training loss: 2.9095471455159445
Validation loss: 2.76105032992639

Epoch: 6| Step: 12
Training loss: 2.924112208038569
Validation loss: 2.7610887250723666

Epoch: 6| Step: 13
Training loss: 2.938774481719674
Validation loss: 2.7602656379815618

Epoch: 148| Step: 0
Training loss: 3.1789879931582834
Validation loss: 2.7581787163690823

Epoch: 6| Step: 1
Training loss: 3.4021204843417916
Validation loss: 2.759322714512024

Epoch: 6| Step: 2
Training loss: 2.7683287082597503
Validation loss: 2.7586213179923704

Epoch: 6| Step: 3
Training loss: 3.4629177516298624
Validation loss: 2.760511544737571

Epoch: 6| Step: 4
Training loss: 3.1826508980552046
Validation loss: 2.759743586877369

Epoch: 6| Step: 5
Training loss: 2.4436306273044206
Validation loss: 2.7575090653843146

Epoch: 6| Step: 6
Training loss: 3.6410480302609294
Validation loss: 2.7602777462762127

Epoch: 6| Step: 7
Training loss: 3.2582858174039164
Validation loss: 2.7621143998291107

Epoch: 6| Step: 8
Training loss: 2.757890305758848
Validation loss: 2.7707825513490527

Epoch: 6| Step: 9
Training loss: 3.0304526627328223
Validation loss: 2.7636544727714014

Epoch: 6| Step: 10
Training loss: 2.6215227802108276
Validation loss: 2.7705602635451014

Epoch: 6| Step: 11
Training loss: 2.9511977269714817
Validation loss: 2.7768819718803086

Epoch: 6| Step: 12
Training loss: 2.7038267250126853
Validation loss: 2.778242632277386

Epoch: 6| Step: 13
Training loss: 3.6620039047312063
Validation loss: 2.7823746958014017

Epoch: 149| Step: 0
Training loss: 2.458720731653147
Validation loss: 2.7780073047137535

Epoch: 6| Step: 1
Training loss: 3.638669647199734
Validation loss: 2.7688640696446805

Epoch: 6| Step: 2
Training loss: 2.7343275665528695
Validation loss: 2.7699328419684295

Epoch: 6| Step: 3
Training loss: 3.020128751119701
Validation loss: 2.764497131509202

Epoch: 6| Step: 4
Training loss: 2.488515797913456
Validation loss: 2.75989670286127

Epoch: 6| Step: 5
Training loss: 3.7057619645183495
Validation loss: 2.757921090948718

Epoch: 6| Step: 6
Training loss: 2.8585779298572382
Validation loss: 2.7517237085445245

Epoch: 6| Step: 7
Training loss: 2.833632696455709
Validation loss: 2.7598860735517556

Epoch: 6| Step: 8
Training loss: 3.2095365043497956
Validation loss: 2.758295936604833

Epoch: 6| Step: 9
Training loss: 3.038778178979986
Validation loss: 2.7594384953720703

Epoch: 6| Step: 10
Training loss: 3.056855274012783
Validation loss: 2.759774082003875

Epoch: 6| Step: 11
Training loss: 3.8273773085989222
Validation loss: 2.761289988164486

Epoch: 6| Step: 12
Training loss: 2.519901218900284
Validation loss: 2.758502264017099

Epoch: 6| Step: 13
Training loss: 3.2727310765851194
Validation loss: 2.759899390138928

Epoch: 150| Step: 0
Training loss: 3.0836231679699475
Validation loss: 2.7607962299593383

Epoch: 6| Step: 1
Training loss: 3.224071363071048
Validation loss: 2.762676092751336

Epoch: 6| Step: 2
Training loss: 2.982713006879591
Validation loss: 2.7560163373441626

Epoch: 6| Step: 3
Training loss: 2.972304294518626
Validation loss: 2.7570735351887485

Epoch: 6| Step: 4
Training loss: 3.38757918712219
Validation loss: 2.761993556515107

Epoch: 6| Step: 5
Training loss: 3.131959870482069
Validation loss: 2.7568000497411296

Epoch: 6| Step: 6
Training loss: 2.9403494143289715
Validation loss: 2.752057358405388

Epoch: 6| Step: 7
Training loss: 3.164841845569965
Validation loss: 2.7526206564971303

Epoch: 6| Step: 8
Training loss: 2.711538374651602
Validation loss: 2.7492308673728503

Epoch: 6| Step: 9
Training loss: 3.5458305266235097
Validation loss: 2.7550841474332985

Epoch: 6| Step: 10
Training loss: 2.409145545176343
Validation loss: 2.7532165226819254

Epoch: 6| Step: 11
Training loss: 2.9185991334010324
Validation loss: 2.7500964079781793

Epoch: 6| Step: 12
Training loss: 3.1187125469397547
Validation loss: 2.7536420765400713

Epoch: 6| Step: 13
Training loss: 3.3470914313026334
Validation loss: 2.7515596793964003

Testing loss: 2.963578627210067
