Epoch: 1| Step: 0
Training loss: 5.797791606483199
Validation loss: 5.781654449745021

Epoch: 6| Step: 1
Training loss: 4.997914642337815
Validation loss: 5.776496175676108

Epoch: 6| Step: 2
Training loss: 6.4885087774299235
Validation loss: 5.771271330022101

Epoch: 6| Step: 3
Training loss: 6.528624084298469
Validation loss: 5.766335624403265

Epoch: 6| Step: 4
Training loss: 6.7240973905627985
Validation loss: 5.761148206001149

Epoch: 6| Step: 5
Training loss: 5.4520362269876514
Validation loss: 5.75610158374286

Epoch: 6| Step: 6
Training loss: 6.755866997773237
Validation loss: 5.75081661715611

Epoch: 6| Step: 7
Training loss: 5.794503192028773
Validation loss: 5.745577552038286

Epoch: 6| Step: 8
Training loss: 5.998090122157668
Validation loss: 5.7398567742773325

Epoch: 6| Step: 9
Training loss: 4.62020398535963
Validation loss: 5.733824795256002

Epoch: 6| Step: 10
Training loss: 4.7791266619541455
Validation loss: 5.727921484566916

Epoch: 6| Step: 11
Training loss: 5.003470551508668
Validation loss: 5.721766558887789

Epoch: 6| Step: 12
Training loss: 5.241659351014256
Validation loss: 5.715520992451937

Epoch: 6| Step: 13
Training loss: 6.504063436538995
Validation loss: 5.708648230437005

Epoch: 2| Step: 0
Training loss: 5.621112751878932
Validation loss: 5.701733478607284

Epoch: 6| Step: 1
Training loss: 5.386637133117641
Validation loss: 5.693679308699818

Epoch: 6| Step: 2
Training loss: 4.937779092747509
Validation loss: 5.686044423119341

Epoch: 6| Step: 3
Training loss: 5.861184616391287
Validation loss: 5.6780568957695285

Epoch: 6| Step: 4
Training loss: 6.369150806876252
Validation loss: 5.669675543343316

Epoch: 6| Step: 5
Training loss: 6.070546267216969
Validation loss: 5.659321776388989

Epoch: 6| Step: 6
Training loss: 6.131411874794348
Validation loss: 5.650088079217716

Epoch: 6| Step: 7
Training loss: 5.256302456588349
Validation loss: 5.639505251063941

Epoch: 6| Step: 8
Training loss: 5.105979421069837
Validation loss: 5.628876919455178

Epoch: 6| Step: 9
Training loss: 6.819669258398482
Validation loss: 5.6179174902485745

Epoch: 6| Step: 10
Training loss: 5.66994575918583
Validation loss: 5.606995520899634

Epoch: 6| Step: 11
Training loss: 5.354305973046641
Validation loss: 5.593209823601337

Epoch: 6| Step: 12
Training loss: 5.380056974258233
Validation loss: 5.580735185072398

Epoch: 6| Step: 13
Training loss: 4.841535492705184
Validation loss: 5.567057704890384

Epoch: 3| Step: 0
Training loss: 5.90841328396886
Validation loss: 5.553655801773959

Epoch: 6| Step: 1
Training loss: 4.658353394457772
Validation loss: 5.538091023037388

Epoch: 6| Step: 2
Training loss: 5.265643111291182
Validation loss: 5.524107242979215

Epoch: 6| Step: 3
Training loss: 5.604634356452814
Validation loss: 5.506653869149427

Epoch: 6| Step: 4
Training loss: 4.348850028084719
Validation loss: 5.490614758099907

Epoch: 6| Step: 5
Training loss: 5.5006366708027254
Validation loss: 5.474078874300997

Epoch: 6| Step: 6
Training loss: 5.295205722519081
Validation loss: 5.456179276072037

Epoch: 6| Step: 7
Training loss: 5.998990291831149
Validation loss: 5.4366567691244025

Epoch: 6| Step: 8
Training loss: 5.347516433526496
Validation loss: 5.417856981420062

Epoch: 6| Step: 9
Training loss: 6.03890268526409
Validation loss: 5.398350908651576

Epoch: 6| Step: 10
Training loss: 6.095113278995647
Validation loss: 5.376168164400128

Epoch: 6| Step: 11
Training loss: 4.2293676068655826
Validation loss: 5.353917753839311

Epoch: 6| Step: 12
Training loss: 6.564337772807537
Validation loss: 5.333092702672138

Epoch: 6| Step: 13
Training loss: 5.281108244850056
Validation loss: 5.310187766135666

Epoch: 4| Step: 0
Training loss: 6.315484578318941
Validation loss: 5.2880380966871705

Epoch: 6| Step: 1
Training loss: 4.591975901045349
Validation loss: 5.264000705255029

Epoch: 6| Step: 2
Training loss: 5.793790505606115
Validation loss: 5.241629207362526

Epoch: 6| Step: 3
Training loss: 5.655571491158216
Validation loss: 5.216053218339932

Epoch: 6| Step: 4
Training loss: 5.349977311416004
Validation loss: 5.1926590545883595

Epoch: 6| Step: 5
Training loss: 3.7113972268689257
Validation loss: 5.1697127082512315

Epoch: 6| Step: 6
Training loss: 6.084942992295197
Validation loss: 5.146024530625183

Epoch: 6| Step: 7
Training loss: 5.011846241923783
Validation loss: 5.121640869063695

Epoch: 6| Step: 8
Training loss: 5.616795469141019
Validation loss: 5.099267997222285

Epoch: 6| Step: 9
Training loss: 5.192397965083918
Validation loss: 5.075850654975593

Epoch: 6| Step: 10
Training loss: 3.8194212078582153
Validation loss: 5.052013840327965

Epoch: 6| Step: 11
Training loss: 4.3805254240470575
Validation loss: 5.030619117082782

Epoch: 6| Step: 12
Training loss: 4.890815901762867
Validation loss: 5.009407999874482

Epoch: 6| Step: 13
Training loss: 5.810530790418914
Validation loss: 4.989682666729101

Epoch: 5| Step: 0
Training loss: 5.053123173097034
Validation loss: 4.9663539399585686

Epoch: 6| Step: 1
Training loss: 5.06322784843001
Validation loss: 4.946037447351667

Epoch: 6| Step: 2
Training loss: 5.217207080933418
Validation loss: 4.92496384933827

Epoch: 6| Step: 3
Training loss: 4.685845451811936
Validation loss: 4.904136708908354

Epoch: 6| Step: 4
Training loss: 4.652233055200733
Validation loss: 4.8845944979957565

Epoch: 6| Step: 5
Training loss: 5.073684770005498
Validation loss: 4.863200756832953

Epoch: 6| Step: 6
Training loss: 4.892449669284242
Validation loss: 4.844651678223243

Epoch: 6| Step: 7
Training loss: 5.265497856982259
Validation loss: 4.822948817780246

Epoch: 6| Step: 8
Training loss: 5.238386296777157
Validation loss: 4.804451165038073

Epoch: 6| Step: 9
Training loss: 3.7158575269161433
Validation loss: 4.785373506115623

Epoch: 6| Step: 10
Training loss: 5.471545044663459
Validation loss: 4.763432041190512

Epoch: 6| Step: 11
Training loss: 4.628296579378268
Validation loss: 4.742017970366312

Epoch: 6| Step: 12
Training loss: 4.094156026724799
Validation loss: 4.723472723926674

Epoch: 6| Step: 13
Training loss: 5.790262980706679
Validation loss: 4.704013345782046

Epoch: 6| Step: 0
Training loss: 4.856268868231725
Validation loss: 4.683298062234878

Epoch: 6| Step: 1
Training loss: 4.9123897161553325
Validation loss: 4.663120692945621

Epoch: 6| Step: 2
Training loss: 4.069195672866109
Validation loss: 4.63964875687425

Epoch: 6| Step: 3
Training loss: 5.297271443612688
Validation loss: 4.6191261282777925

Epoch: 6| Step: 4
Training loss: 4.659600812325516
Validation loss: 4.597126856734269

Epoch: 6| Step: 5
Training loss: 4.51275712651751
Validation loss: 4.576012905598886

Epoch: 6| Step: 6
Training loss: 4.843980156137281
Validation loss: 4.551609254065224

Epoch: 6| Step: 7
Training loss: 5.145114225522769
Validation loss: 4.529307623572956

Epoch: 6| Step: 8
Training loss: 4.898772159807604
Validation loss: 4.503727860267298

Epoch: 6| Step: 9
Training loss: 4.3722820013457495
Validation loss: 4.478863826891716

Epoch: 6| Step: 10
Training loss: 4.763079254086886
Validation loss: 4.45197531124224

Epoch: 6| Step: 11
Training loss: 4.486730295970474
Validation loss: 4.427844582049249

Epoch: 6| Step: 12
Training loss: 3.8413224657040264
Validation loss: 4.404903674254428

Epoch: 6| Step: 13
Training loss: 3.6551907300955535
Validation loss: 4.382175986240971

Epoch: 7| Step: 0
Training loss: 3.972281739352947
Validation loss: 4.3638051311089345

Epoch: 6| Step: 1
Training loss: 4.588931300593568
Validation loss: 4.3453061861878775

Epoch: 6| Step: 2
Training loss: 4.589906498906179
Validation loss: 4.3273445688305365

Epoch: 6| Step: 3
Training loss: 4.507330962961115
Validation loss: 4.309252564441448

Epoch: 6| Step: 4
Training loss: 3.834880613336285
Validation loss: 4.2897711531396725

Epoch: 6| Step: 5
Training loss: 4.087039018587066
Validation loss: 4.271098540700845

Epoch: 6| Step: 6
Training loss: 4.112760244558833
Validation loss: 4.256287640155541

Epoch: 6| Step: 7
Training loss: 4.830700233832101
Validation loss: 4.239655214435886

Epoch: 6| Step: 8
Training loss: 5.162311112686829
Validation loss: 4.223715997640567

Epoch: 6| Step: 9
Training loss: 4.324004377308199
Validation loss: 4.20865284037738

Epoch: 6| Step: 10
Training loss: 4.5051966437333295
Validation loss: 4.191911568051223

Epoch: 6| Step: 11
Training loss: 3.70285445243075
Validation loss: 4.1766966812990285

Epoch: 6| Step: 12
Training loss: 4.650014914211844
Validation loss: 4.159525259654377

Epoch: 6| Step: 13
Training loss: 3.9177904478293666
Validation loss: 4.1423206685923

Epoch: 8| Step: 0
Training loss: 3.5502010664615447
Validation loss: 4.130119454467061

Epoch: 6| Step: 1
Training loss: 3.8493446634555513
Validation loss: 4.113757270372849

Epoch: 6| Step: 2
Training loss: 4.56272971215121
Validation loss: 4.098578536150875

Epoch: 6| Step: 3
Training loss: 4.350255471981938
Validation loss: 4.078726539036109

Epoch: 6| Step: 4
Training loss: 3.0952912161883406
Validation loss: 4.057084815256851

Epoch: 6| Step: 5
Training loss: 5.005415844328841
Validation loss: 4.032073908220429

Epoch: 6| Step: 6
Training loss: 4.124632847947935
Validation loss: 4.017437440587129

Epoch: 6| Step: 7
Training loss: 3.594885870510644
Validation loss: 4.006336503829681

Epoch: 6| Step: 8
Training loss: 2.8921008492240583
Validation loss: 3.998917870376042

Epoch: 6| Step: 9
Training loss: 4.908604536783867
Validation loss: 3.98937960943949

Epoch: 6| Step: 10
Training loss: 4.326596206969074
Validation loss: 3.9813985356847925

Epoch: 6| Step: 11
Training loss: 4.146087613127289
Validation loss: 3.972119091919225

Epoch: 6| Step: 12
Training loss: 4.837491231116891
Validation loss: 3.9597858961034134

Epoch: 6| Step: 13
Training loss: 4.665082299261902
Validation loss: 3.947864138714027

Epoch: 9| Step: 0
Training loss: 3.935515130532643
Validation loss: 3.941241750781805

Epoch: 6| Step: 1
Training loss: 3.5853785658915287
Validation loss: 3.9322899776923155

Epoch: 6| Step: 2
Training loss: 2.5457641425670365
Validation loss: 3.9248306412399496

Epoch: 6| Step: 3
Training loss: 4.182259084052849
Validation loss: 3.919127489561421

Epoch: 6| Step: 4
Training loss: 4.140648032070376
Validation loss: 3.911776773175328

Epoch: 6| Step: 5
Training loss: 3.966049837723628
Validation loss: 3.904393735800571

Epoch: 6| Step: 6
Training loss: 3.706738089575452
Validation loss: 3.8991412406049797

Epoch: 6| Step: 7
Training loss: 3.809073737783001
Validation loss: 3.888874329384906

Epoch: 6| Step: 8
Training loss: 3.665229009782722
Validation loss: 3.881801129267165

Epoch: 6| Step: 9
Training loss: 4.401093841183276
Validation loss: 3.8752108598249135

Epoch: 6| Step: 10
Training loss: 4.168096195406847
Validation loss: 3.8670948954267343

Epoch: 6| Step: 11
Training loss: 4.89626564660298
Validation loss: 3.858158188942512

Epoch: 6| Step: 12
Training loss: 4.6065048333617495
Validation loss: 3.8532025187495993

Epoch: 6| Step: 13
Training loss: 4.935274419295244
Validation loss: 3.8490755245198236

Epoch: 10| Step: 0
Training loss: 4.604275018904391
Validation loss: 3.8432044532399017

Epoch: 6| Step: 1
Training loss: 3.684011846218882
Validation loss: 3.838414360381158

Epoch: 6| Step: 2
Training loss: 5.32791522108107
Validation loss: 3.8307702554118257

Epoch: 6| Step: 3
Training loss: 4.322463536547217
Validation loss: 3.8255790020751186

Epoch: 6| Step: 4
Training loss: 4.132804423506404
Validation loss: 3.8187782536421406

Epoch: 6| Step: 5
Training loss: 3.767530030635228
Validation loss: 3.810343283812624

Epoch: 6| Step: 6
Training loss: 4.000115869751219
Validation loss: 3.805488127042782

Epoch: 6| Step: 7
Training loss: 3.254874462044869
Validation loss: 3.803626909628034

Epoch: 6| Step: 8
Training loss: 2.6501728325390177
Validation loss: 3.7967005317008327

Epoch: 6| Step: 9
Training loss: 4.130605876530289
Validation loss: 3.7923782446751666

Epoch: 6| Step: 10
Training loss: 3.594499858079887
Validation loss: 3.7879979950427343

Epoch: 6| Step: 11
Training loss: 3.8249725440542126
Validation loss: 3.7844500748874803

Epoch: 6| Step: 12
Training loss: 4.040104095326533
Validation loss: 3.780713412027427

Epoch: 6| Step: 13
Training loss: 3.6811305494633553
Validation loss: 3.77563843245586

Epoch: 11| Step: 0
Training loss: 3.319456892287264
Validation loss: 3.7730003787726574

Epoch: 6| Step: 1
Training loss: 3.782982169391379
Validation loss: 3.7677440567325995

Epoch: 6| Step: 2
Training loss: 4.871522103008223
Validation loss: 3.765266116440152

Epoch: 6| Step: 3
Training loss: 2.9109452579740958
Validation loss: 3.7605687669886625

Epoch: 6| Step: 4
Training loss: 4.159850432568206
Validation loss: 3.756980405626831

Epoch: 6| Step: 5
Training loss: 4.455003629912023
Validation loss: 3.7486743128760907

Epoch: 6| Step: 6
Training loss: 3.8856519912486664
Validation loss: 3.7482830547043577

Epoch: 6| Step: 7
Training loss: 3.8209702251265596
Validation loss: 3.7480312306623107

Epoch: 6| Step: 8
Training loss: 4.160070054858227
Validation loss: 3.744072393290057

Epoch: 6| Step: 9
Training loss: 3.9021069337396264
Validation loss: 3.740683541007867

Epoch: 6| Step: 10
Training loss: 4.171693947967397
Validation loss: 3.7366363177175237

Epoch: 6| Step: 11
Training loss: 4.006423084727559
Validation loss: 3.730418931950226

Epoch: 6| Step: 12
Training loss: 3.055790928724222
Validation loss: 3.727911667803689

Epoch: 6| Step: 13
Training loss: 4.129089178185215
Validation loss: 3.7211081491537135

Epoch: 12| Step: 0
Training loss: 3.7717833753580603
Validation loss: 3.7145445792172436

Epoch: 6| Step: 1
Training loss: 4.512116967004045
Validation loss: 3.7120376042625174

Epoch: 6| Step: 2
Training loss: 2.782739219150457
Validation loss: 3.7091037124714195

Epoch: 6| Step: 3
Training loss: 4.077082826006505
Validation loss: 3.7091511350835833

Epoch: 6| Step: 4
Training loss: 3.5726659184468317
Validation loss: 3.7089488334555365

Epoch: 6| Step: 5
Training loss: 3.5389886642063235
Validation loss: 3.700836578064104

Epoch: 6| Step: 6
Training loss: 4.2294199199047045
Validation loss: 3.6943259253468455

Epoch: 6| Step: 7
Training loss: 3.6717409799345146
Validation loss: 3.6914383046901116

Epoch: 6| Step: 8
Training loss: 3.113311269656084
Validation loss: 3.6882297509171975

Epoch: 6| Step: 9
Training loss: 3.9268400216385175
Validation loss: 3.6843722945061987

Epoch: 6| Step: 10
Training loss: 4.203473044808035
Validation loss: 3.6816288695206603

Epoch: 6| Step: 11
Training loss: 4.250522805763363
Validation loss: 3.677853170647242

Epoch: 6| Step: 12
Training loss: 3.9594998431075052
Validation loss: 3.676320314249662

Epoch: 6| Step: 13
Training loss: 4.63185251206053
Validation loss: 3.6748726705604144

Epoch: 13| Step: 0
Training loss: 4.038530502848347
Validation loss: 3.6694844364221817

Epoch: 6| Step: 1
Training loss: 3.5325155775370605
Validation loss: 3.6645441698782037

Epoch: 6| Step: 2
Training loss: 3.46942324591592
Validation loss: 3.66362314423549

Epoch: 6| Step: 3
Training loss: 3.961709573652728
Validation loss: 3.656126556121612

Epoch: 6| Step: 4
Training loss: 4.101533668053425
Validation loss: 3.653926647223478

Epoch: 6| Step: 5
Training loss: 4.011407084184294
Validation loss: 3.6500169274621306

Epoch: 6| Step: 6
Training loss: 3.4405143699218392
Validation loss: 3.652225214019703

Epoch: 6| Step: 7
Training loss: 3.820315994853974
Validation loss: 3.648262576421244

Epoch: 6| Step: 8
Training loss: 4.1570218165533825
Validation loss: 3.6467641619001596

Epoch: 6| Step: 9
Training loss: 4.732429935764905
Validation loss: 3.6400612578567015

Epoch: 6| Step: 10
Training loss: 3.420661885421446
Validation loss: 3.6360017095534456

Epoch: 6| Step: 11
Training loss: 2.717331000778475
Validation loss: 3.6317602000131854

Epoch: 6| Step: 12
Training loss: 3.766093751215487
Validation loss: 3.6281077974209164

Epoch: 6| Step: 13
Training loss: 4.441927138677791
Validation loss: 3.624694466223695

Epoch: 14| Step: 0
Training loss: 3.919765436978674
Validation loss: 3.6229826278657455

Epoch: 6| Step: 1
Training loss: 3.367207042522321
Validation loss: 3.6229274186874982

Epoch: 6| Step: 2
Training loss: 4.158885607742898
Validation loss: 3.616495884964505

Epoch: 6| Step: 3
Training loss: 2.3903738650388235
Validation loss: 3.6119412008974696

Epoch: 6| Step: 4
Training loss: 3.43142663052893
Validation loss: 3.609450281021601

Epoch: 6| Step: 5
Training loss: 3.824002284157043
Validation loss: 3.6122035032081325

Epoch: 6| Step: 6
Training loss: 4.696678635685987
Validation loss: 3.604508493234404

Epoch: 6| Step: 7
Training loss: 3.8101491715672666
Validation loss: 3.6045466235856147

Epoch: 6| Step: 8
Training loss: 3.670850115653626
Validation loss: 3.600138615830203

Epoch: 6| Step: 9
Training loss: 3.5268865312235347
Validation loss: 3.5949401254480122

Epoch: 6| Step: 10
Training loss: 4.387673033864261
Validation loss: 3.594165768321036

Epoch: 6| Step: 11
Training loss: 4.2122211941332885
Validation loss: 3.5896937295111995

Epoch: 6| Step: 12
Training loss: 2.7810512000195406
Validation loss: 3.5877400112198017

Epoch: 6| Step: 13
Training loss: 4.7668067342457245
Validation loss: 3.583876671393385

Epoch: 15| Step: 0
Training loss: 3.6710544399796015
Validation loss: 3.588669073638603

Epoch: 6| Step: 1
Training loss: 2.9107999563355813
Validation loss: 3.5861847469860875

Epoch: 6| Step: 2
Training loss: 3.7621187847068494
Validation loss: 3.5796665944461585

Epoch: 6| Step: 3
Training loss: 3.0359275358294733
Validation loss: 3.5782357081566043

Epoch: 6| Step: 4
Training loss: 3.6683754984887518
Validation loss: 3.5720549738152094

Epoch: 6| Step: 5
Training loss: 4.316537266464674
Validation loss: 3.5692811166758376

Epoch: 6| Step: 6
Training loss: 3.923857655088918
Validation loss: 3.563273793617161

Epoch: 6| Step: 7
Training loss: 3.62486056355615
Validation loss: 3.563494419928636

Epoch: 6| Step: 8
Training loss: 3.812311636852304
Validation loss: 3.5604384825678044

Epoch: 6| Step: 9
Training loss: 4.734919652045653
Validation loss: 3.5568643338885546

Epoch: 6| Step: 10
Training loss: 4.206938081097519
Validation loss: 3.554819813217249

Epoch: 6| Step: 11
Training loss: 3.7409296330796336
Validation loss: 3.551561110728017

Epoch: 6| Step: 12
Training loss: 3.5517617058594966
Validation loss: 3.556158971364889

Epoch: 6| Step: 13
Training loss: 3.1019869497136585
Validation loss: 3.5467019124939383

Epoch: 16| Step: 0
Training loss: 3.2778663264093906
Validation loss: 3.54685488040088

Epoch: 6| Step: 1
Training loss: 3.6346147558190776
Validation loss: 3.5432989399393695

Epoch: 6| Step: 2
Training loss: 4.20046606656828
Validation loss: 3.5400760319143942

Epoch: 6| Step: 3
Training loss: 3.817567677875363
Validation loss: 3.5392256927333405

Epoch: 6| Step: 4
Training loss: 3.267713691010652
Validation loss: 3.5385061495571826

Epoch: 6| Step: 5
Training loss: 3.474911827231196
Validation loss: 3.539707926786584

Epoch: 6| Step: 6
Training loss: 4.281394788980728
Validation loss: 3.5382952172689666

Epoch: 6| Step: 7
Training loss: 2.607012472979606
Validation loss: 3.537209344507781

Epoch: 6| Step: 8
Training loss: 2.472483841367865
Validation loss: 3.535089702089743

Epoch: 6| Step: 9
Training loss: 4.243323748253852
Validation loss: 3.532824932546254

Epoch: 6| Step: 10
Training loss: 4.431053744813835
Validation loss: 3.5294691672393346

Epoch: 6| Step: 11
Training loss: 4.5212510907691525
Validation loss: 3.5240415279063733

Epoch: 6| Step: 12
Training loss: 3.8602702843707712
Validation loss: 3.5198023136529986

Epoch: 6| Step: 13
Training loss: 3.477428816965631
Validation loss: 3.5192136981488362

Epoch: 17| Step: 0
Training loss: 3.53103704569961
Validation loss: 3.511938306757565

Epoch: 6| Step: 1
Training loss: 3.6168083503031045
Validation loss: 3.5141930292401438

Epoch: 6| Step: 2
Training loss: 4.395884340300684
Validation loss: 3.507326823450747

Epoch: 6| Step: 3
Training loss: 3.624174747582294
Validation loss: 3.5102529929733204

Epoch: 6| Step: 4
Training loss: 2.519067529394829
Validation loss: 3.5081494700256406

Epoch: 6| Step: 5
Training loss: 4.494502205956262
Validation loss: 3.5114639578350073

Epoch: 6| Step: 6
Training loss: 3.4144225465360822
Validation loss: 3.5045675660412865

Epoch: 6| Step: 7
Training loss: 3.3930070657518807
Validation loss: 3.4993459761412025

Epoch: 6| Step: 8
Training loss: 2.9891156795574787
Validation loss: 3.4988500871270958

Epoch: 6| Step: 9
Training loss: 3.597121539644119
Validation loss: 3.4959604138541898

Epoch: 6| Step: 10
Training loss: 4.754555174421284
Validation loss: 3.4948127310334622

Epoch: 6| Step: 11
Training loss: 3.525818825708949
Validation loss: 3.4919415580243682

Epoch: 6| Step: 12
Training loss: 4.261222160071609
Validation loss: 3.489241270889955

Epoch: 6| Step: 13
Training loss: 2.7935282540272586
Validation loss: 3.486592963508742

Epoch: 18| Step: 0
Training loss: 3.958725772611285
Validation loss: 3.484944008737155

Epoch: 6| Step: 1
Training loss: 3.5723104750465002
Validation loss: 3.48208835226646

Epoch: 6| Step: 2
Training loss: 3.3424731517275545
Validation loss: 3.477511808121547

Epoch: 6| Step: 3
Training loss: 4.00905252350608
Validation loss: 3.4743848457875246

Epoch: 6| Step: 4
Training loss: 3.606755350495123
Validation loss: 3.471932915779838

Epoch: 6| Step: 5
Training loss: 3.7023623683161055
Validation loss: 3.4677765631562507

Epoch: 6| Step: 6
Training loss: 3.7997874953430784
Validation loss: 3.4680092983481465

Epoch: 6| Step: 7
Training loss: 2.928063840441108
Validation loss: 3.465661726237272

Epoch: 6| Step: 8
Training loss: 4.292998073432609
Validation loss: 3.463300890914841

Epoch: 6| Step: 9
Training loss: 3.6423286086625195
Validation loss: 3.4603212891736703

Epoch: 6| Step: 10
Training loss: 4.2500767420403625
Validation loss: 3.4579447204112896

Epoch: 6| Step: 11
Training loss: 3.239081013650057
Validation loss: 3.455459289054847

Epoch: 6| Step: 12
Training loss: 3.0807553588751238
Validation loss: 3.4503859733406164

Epoch: 6| Step: 13
Training loss: 4.0304862784921225
Validation loss: 3.4485006486887744

Epoch: 19| Step: 0
Training loss: 2.9000961616620935
Validation loss: 3.4573726666451208

Epoch: 6| Step: 1
Training loss: 3.6651039839457167
Validation loss: 3.4745105247296184

Epoch: 6| Step: 2
Training loss: 3.803647128195527
Validation loss: 3.445561441462991

Epoch: 6| Step: 3
Training loss: 4.295487391358668
Validation loss: 3.4444500079811866

Epoch: 6| Step: 4
Training loss: 3.9700485868387494
Validation loss: 3.4395301186314677

Epoch: 6| Step: 5
Training loss: 3.093264454973632
Validation loss: 3.4402049007976636

Epoch: 6| Step: 6
Training loss: 3.2823609424198374
Validation loss: 3.4414891183453555

Epoch: 6| Step: 7
Training loss: 3.7018110946196354
Validation loss: 3.438146893888766

Epoch: 6| Step: 8
Training loss: 3.5807031397018116
Validation loss: 3.4370737820246435

Epoch: 6| Step: 9
Training loss: 3.7895359018862154
Validation loss: 3.436622786625254

Epoch: 6| Step: 10
Training loss: 3.579011632354157
Validation loss: 3.433254707297112

Epoch: 6| Step: 11
Training loss: 3.1886250623439576
Validation loss: 3.4322947927663

Epoch: 6| Step: 12
Training loss: 4.193573148952482
Validation loss: 3.4303909250519853

Epoch: 6| Step: 13
Training loss: 4.1153305469748425
Validation loss: 3.426029536397513

Epoch: 20| Step: 0
Training loss: 3.2217451067547147
Validation loss: 3.424359186900554

Epoch: 6| Step: 1
Training loss: 3.9813459064423937
Validation loss: 3.4199120249836272

Epoch: 6| Step: 2
Training loss: 3.7433208748215803
Validation loss: 3.4160589032246613

Epoch: 6| Step: 3
Training loss: 4.2087396608094805
Validation loss: 3.413041406247926

Epoch: 6| Step: 4
Training loss: 4.060668062765879
Validation loss: 3.412998040184893

Epoch: 6| Step: 5
Training loss: 3.9675531459967357
Validation loss: 3.4104786943966268

Epoch: 6| Step: 6
Training loss: 3.3386296792810035
Validation loss: 3.408176254155721

Epoch: 6| Step: 7
Training loss: 3.0778582307267093
Validation loss: 3.4064283336518746

Epoch: 6| Step: 8
Training loss: 3.786723313467567
Validation loss: 3.40544720608918

Epoch: 6| Step: 9
Training loss: 3.065892734171613
Validation loss: 3.4052482020661667

Epoch: 6| Step: 10
Training loss: 3.20322399451637
Validation loss: 3.406735532667507

Epoch: 6| Step: 11
Training loss: 3.3113709450937
Validation loss: 3.4035719592593714

Epoch: 6| Step: 12
Training loss: 4.003564676741168
Validation loss: 3.4042680748422027

Epoch: 6| Step: 13
Training loss: 3.7254654971112022
Validation loss: 3.395642068654067

Epoch: 21| Step: 0
Training loss: 2.7650356203513047
Validation loss: 3.3893830953104334

Epoch: 6| Step: 1
Training loss: 4.263046882874494
Validation loss: 3.38868091857825

Epoch: 6| Step: 2
Training loss: 3.1927602410051037
Validation loss: 3.3882732178964163

Epoch: 6| Step: 3
Training loss: 3.281928873224746
Validation loss: 3.3871452357374854

Epoch: 6| Step: 4
Training loss: 3.313844515885419
Validation loss: 3.38791823936665

Epoch: 6| Step: 5
Training loss: 3.449987997504102
Validation loss: 3.3845231859144382

Epoch: 6| Step: 6
Training loss: 3.604553304819158
Validation loss: 3.3842621854634256

Epoch: 6| Step: 7
Training loss: 3.7530315860808585
Validation loss: 3.3802387076851286

Epoch: 6| Step: 8
Training loss: 4.044174176805305
Validation loss: 3.3793655852444537

Epoch: 6| Step: 9
Training loss: 3.7687200592521815
Validation loss: 3.3753211515422876

Epoch: 6| Step: 10
Training loss: 3.1296454424419946
Validation loss: 3.3720412386199374

Epoch: 6| Step: 11
Training loss: 3.898627572786858
Validation loss: 3.3689996162856803

Epoch: 6| Step: 12
Training loss: 3.411104435315332
Validation loss: 3.366588150038046

Epoch: 6| Step: 13
Training loss: 4.733574827955661
Validation loss: 3.368588162175664

Epoch: 22| Step: 0
Training loss: 4.405791563169518
Validation loss: 3.3610993233719255

Epoch: 6| Step: 1
Training loss: 2.4786356723291503
Validation loss: 3.361268320669594

Epoch: 6| Step: 2
Training loss: 4.227557898902654
Validation loss: 3.357329053640291

Epoch: 6| Step: 3
Training loss: 3.937789906319721
Validation loss: 3.353057095904411

Epoch: 6| Step: 4
Training loss: 3.4910886943196453
Validation loss: 3.351911401242024

Epoch: 6| Step: 5
Training loss: 2.3372513256291616
Validation loss: 3.349208934110724

Epoch: 6| Step: 6
Training loss: 3.518304913898607
Validation loss: 3.3495986584806743

Epoch: 6| Step: 7
Training loss: 3.9495430500964828
Validation loss: 3.3495484797328796

Epoch: 6| Step: 8
Training loss: 2.915473984776438
Validation loss: 3.347500346004086

Epoch: 6| Step: 9
Training loss: 3.7371486434875063
Validation loss: 3.345001187488555

Epoch: 6| Step: 10
Training loss: 3.6053388743705983
Validation loss: 3.3434311602905336

Epoch: 6| Step: 11
Training loss: 3.322671496555661
Validation loss: 3.344144642814007

Epoch: 6| Step: 12
Training loss: 3.590729879070984
Validation loss: 3.3413552652514635

Epoch: 6| Step: 13
Training loss: 4.27920416518697
Validation loss: 3.3418769501035483

Epoch: 23| Step: 0
Training loss: 3.2848220999983693
Validation loss: 3.337671378636537

Epoch: 6| Step: 1
Training loss: 3.801913211447996
Validation loss: 3.331101700071531

Epoch: 6| Step: 2
Training loss: 2.1667642082363825
Validation loss: 3.331948520788576

Epoch: 6| Step: 3
Training loss: 4.161582566158703
Validation loss: 3.3330324734508885

Epoch: 6| Step: 4
Training loss: 4.17508005762151
Validation loss: 3.330095832904409

Epoch: 6| Step: 5
Training loss: 3.8042643662295688
Validation loss: 3.327177689463679

Epoch: 6| Step: 6
Training loss: 3.419472883326418
Validation loss: 3.3227223234577465

Epoch: 6| Step: 7
Training loss: 3.5383631539462
Validation loss: 3.324549768439031

Epoch: 6| Step: 8
Training loss: 3.275757470512009
Validation loss: 3.317133652519825

Epoch: 6| Step: 9
Training loss: 3.577294132432574
Validation loss: 3.320804015520262

Epoch: 6| Step: 10
Training loss: 3.338068618626815
Validation loss: 3.321594733463846

Epoch: 6| Step: 11
Training loss: 4.292876335447518
Validation loss: 3.3231710966035948

Epoch: 6| Step: 12
Training loss: 2.454399992424817
Validation loss: 3.3173366943839153

Epoch: 6| Step: 13
Training loss: 4.105413696036075
Validation loss: 3.311410525480905

Epoch: 24| Step: 0
Training loss: 3.2522164636243898
Validation loss: 3.309636705578672

Epoch: 6| Step: 1
Training loss: 3.6864396203219965
Validation loss: 3.308936349231026

Epoch: 6| Step: 2
Training loss: 3.89692490460853
Validation loss: 3.308752358880471

Epoch: 6| Step: 3
Training loss: 3.902279476213055
Validation loss: 3.304119285354778

Epoch: 6| Step: 4
Training loss: 3.121129652826588
Validation loss: 3.302512075091253

Epoch: 6| Step: 5
Training loss: 3.516977821312706
Validation loss: 3.3003968859374293

Epoch: 6| Step: 6
Training loss: 3.2695790860449216
Validation loss: 3.3008960905592617

Epoch: 6| Step: 7
Training loss: 3.5347424006724064
Validation loss: 3.3034026672452743

Epoch: 6| Step: 8
Training loss: 3.230865343466785
Validation loss: 3.300611799598861

Epoch: 6| Step: 9
Training loss: 4.275683494494508
Validation loss: 3.2929521924040275

Epoch: 6| Step: 10
Training loss: 3.3866662326071553
Validation loss: 3.296071779591427

Epoch: 6| Step: 11
Training loss: 3.50973546392508
Validation loss: 3.2917422660681126

Epoch: 6| Step: 12
Training loss: 2.9852031737021267
Validation loss: 3.292086971755293

Epoch: 6| Step: 13
Training loss: 3.9534468086343555
Validation loss: 3.2905481825863343

Epoch: 25| Step: 0
Training loss: 2.6683306469527506
Validation loss: 3.2891512650236256

Epoch: 6| Step: 1
Training loss: 3.99091786241229
Validation loss: 3.2887758890036927

Epoch: 6| Step: 2
Training loss: 3.398945667376911
Validation loss: 3.288963880125581

Epoch: 6| Step: 3
Training loss: 3.2447893480483456
Validation loss: 3.285538587685888

Epoch: 6| Step: 4
Training loss: 4.056186406323284
Validation loss: 3.285319368459131

Epoch: 6| Step: 5
Training loss: 3.1060853358015215
Validation loss: 3.283956491456785

Epoch: 6| Step: 6
Training loss: 4.101109535999926
Validation loss: 3.2828645373896648

Epoch: 6| Step: 7
Training loss: 2.2213305658038522
Validation loss: 3.280518313003944

Epoch: 6| Step: 8
Training loss: 4.069644221471389
Validation loss: 3.2782731435922776

Epoch: 6| Step: 9
Training loss: 3.585161777607623
Validation loss: 3.2750787740071456

Epoch: 6| Step: 10
Training loss: 3.5952954493735465
Validation loss: 3.272088455803316

Epoch: 6| Step: 11
Training loss: 3.5367161128272557
Validation loss: 3.2722315880170725

Epoch: 6| Step: 12
Training loss: 3.5175792094667955
Validation loss: 3.2693807149471223

Epoch: 6| Step: 13
Training loss: 3.780101507125808
Validation loss: 3.2673417477661313

Epoch: 26| Step: 0
Training loss: 3.8083890419745376
Validation loss: 3.2700329345926655

Epoch: 6| Step: 1
Training loss: 3.1990673136472285
Validation loss: 3.267387911683628

Epoch: 6| Step: 2
Training loss: 3.3494799708513376
Validation loss: 3.2634772234345664

Epoch: 6| Step: 3
Training loss: 3.3861946659629445
Validation loss: 3.2611448676542327

Epoch: 6| Step: 4
Training loss: 4.044827329819131
Validation loss: 3.2607210335618113

Epoch: 6| Step: 5
Training loss: 4.104933278218774
Validation loss: 3.2607885627797666

Epoch: 6| Step: 6
Training loss: 3.9654548963252676
Validation loss: 3.260666115706364

Epoch: 6| Step: 7
Training loss: 2.820569732009592
Validation loss: 3.2574902525582905

Epoch: 6| Step: 8
Training loss: 2.8658538959900977
Validation loss: 3.2582907333675566

Epoch: 6| Step: 9
Training loss: 2.972526637696693
Validation loss: 3.2552874381349395

Epoch: 6| Step: 10
Training loss: 3.6196120110074634
Validation loss: 3.2599253804111883

Epoch: 6| Step: 11
Training loss: 4.177341951020629
Validation loss: 3.2523420192047667

Epoch: 6| Step: 12
Training loss: 3.6357280229881215
Validation loss: 3.2500367253250255

Epoch: 6| Step: 13
Training loss: 1.8453037374806838
Validation loss: 3.250116592284755

Epoch: 27| Step: 0
Training loss: 3.7426677228488754
Validation loss: 3.2512984746452283

Epoch: 6| Step: 1
Training loss: 3.5640172571691364
Validation loss: 3.25144597079116

Epoch: 6| Step: 2
Training loss: 4.142606671283068
Validation loss: 3.2514346342689953

Epoch: 6| Step: 3
Training loss: 4.108875781003341
Validation loss: 3.2488744157535603

Epoch: 6| Step: 4
Training loss: 2.9042499181854637
Validation loss: 3.2476797356330454

Epoch: 6| Step: 5
Training loss: 3.9938681810351917
Validation loss: 3.2409979509931484

Epoch: 6| Step: 6
Training loss: 3.780254895128575
Validation loss: 3.241906493633883

Epoch: 6| Step: 7
Training loss: 3.6066210260047735
Validation loss: 3.239513895945668

Epoch: 6| Step: 8
Training loss: 2.92545038651987
Validation loss: 3.240734885783912

Epoch: 6| Step: 9
Training loss: 2.9069959442036892
Validation loss: 3.2418420126450798

Epoch: 6| Step: 10
Training loss: 3.3558359355993783
Validation loss: 3.241745548146353

Epoch: 6| Step: 11
Training loss: 3.1095699076690897
Validation loss: 3.2371286879679717

Epoch: 6| Step: 12
Training loss: 3.1172973307523026
Validation loss: 3.2375720397254777

Epoch: 6| Step: 13
Training loss: 3.137587107630829
Validation loss: 3.2356385924367657

Epoch: 28| Step: 0
Training loss: 3.4141444844543383
Validation loss: 3.233534791131901

Epoch: 6| Step: 1
Training loss: 4.2871285057944455
Validation loss: 3.232467087849343

Epoch: 6| Step: 2
Training loss: 2.968957672886414
Validation loss: 3.2291312277625925

Epoch: 6| Step: 3
Training loss: 3.3059136030258545
Validation loss: 3.227042417165503

Epoch: 6| Step: 4
Training loss: 3.6611195276832857
Validation loss: 3.227522007203038

Epoch: 6| Step: 5
Training loss: 3.233662992235133
Validation loss: 3.2232140944689207

Epoch: 6| Step: 6
Training loss: 4.169663889853198
Validation loss: 3.223826111638964

Epoch: 6| Step: 7
Training loss: 3.3417084067410183
Validation loss: 3.220725944299552

Epoch: 6| Step: 8
Training loss: 3.128523709156586
Validation loss: 3.22170552528827

Epoch: 6| Step: 9
Training loss: 3.3097015651994357
Validation loss: 3.2216328383744397

Epoch: 6| Step: 10
Training loss: 3.1100239292217724
Validation loss: 3.2211664441759957

Epoch: 6| Step: 11
Training loss: 3.101951593932612
Validation loss: 3.219382244585981

Epoch: 6| Step: 12
Training loss: 2.955196562295266
Validation loss: 3.2143471019382552

Epoch: 6| Step: 13
Training loss: 4.819961708201661
Validation loss: 3.2156928318783984

Epoch: 29| Step: 0
Training loss: 2.6659087554415826
Validation loss: 3.2121206100481734

Epoch: 6| Step: 1
Training loss: 3.7401369724588838
Validation loss: 3.212904454578735

Epoch: 6| Step: 2
Training loss: 2.601711326214185
Validation loss: 3.2112630602175063

Epoch: 6| Step: 3
Training loss: 3.760283801548558
Validation loss: 3.2146820341477627

Epoch: 6| Step: 4
Training loss: 3.08863361258234
Validation loss: 3.211365043380355

Epoch: 6| Step: 5
Training loss: 3.6712887559766725
Validation loss: 3.206279788354343

Epoch: 6| Step: 6
Training loss: 3.7247983327462046
Validation loss: 3.205107275270542

Epoch: 6| Step: 7
Training loss: 3.2288691886142766
Validation loss: 3.2049302211253865

Epoch: 6| Step: 8
Training loss: 4.264463385289823
Validation loss: 3.204370992143712

Epoch: 6| Step: 9
Training loss: 3.0322800292186316
Validation loss: 3.202788653498725

Epoch: 6| Step: 10
Training loss: 4.564712197129952
Validation loss: 3.2039186516383946

Epoch: 6| Step: 11
Training loss: 3.057742101358918
Validation loss: 3.199362929055735

Epoch: 6| Step: 12
Training loss: 3.448416006265849
Validation loss: 3.2079994231393267

Epoch: 6| Step: 13
Training loss: 2.647960068421784
Validation loss: 3.209747635312489

Epoch: 30| Step: 0
Training loss: 3.047642850711941
Validation loss: 3.2041481606935975

Epoch: 6| Step: 1
Training loss: 3.6381455520445205
Validation loss: 3.2049059983018804

Epoch: 6| Step: 2
Training loss: 4.151758046797813
Validation loss: 3.2039799815497054

Epoch: 6| Step: 3
Training loss: 2.828819906101699
Validation loss: 3.196427679273322

Epoch: 6| Step: 4
Training loss: 2.8681761988485994
Validation loss: 3.192304347199211

Epoch: 6| Step: 5
Training loss: 4.38442979643791
Validation loss: 3.192195980033111

Epoch: 6| Step: 6
Training loss: 3.4286610103439124
Validation loss: 3.189224907266398

Epoch: 6| Step: 7
Training loss: 3.223980847569223
Validation loss: 3.1887107301441686

Epoch: 6| Step: 8
Training loss: 3.3936245215386567
Validation loss: 3.18828175058946

Epoch: 6| Step: 9
Training loss: 3.7442081228429447
Validation loss: 3.191144631805663

Epoch: 6| Step: 10
Training loss: 2.786811753911538
Validation loss: 3.1913544659719655

Epoch: 6| Step: 11
Training loss: 3.6703794639717975
Validation loss: 3.1881043426038507

Epoch: 6| Step: 12
Training loss: 3.2664180686972264
Validation loss: 3.185523924414158

Epoch: 6| Step: 13
Training loss: 3.4138601142726657
Validation loss: 3.1856372625497555

Epoch: 31| Step: 0
Training loss: 3.4514139346351023
Validation loss: 3.184084009082607

Epoch: 6| Step: 1
Training loss: 3.8280253494682968
Validation loss: 3.1844821544187747

Epoch: 6| Step: 2
Training loss: 3.8741822148896765
Validation loss: 3.1800556439890664

Epoch: 6| Step: 3
Training loss: 3.5656280169862895
Validation loss: 3.18135721348466

Epoch: 6| Step: 4
Training loss: 3.1714490783057863
Validation loss: 3.183029710871641

Epoch: 6| Step: 5
Training loss: 3.227272971491493
Validation loss: 3.17808572632754

Epoch: 6| Step: 6
Training loss: 2.9941611690525622
Validation loss: 3.1799968145649524

Epoch: 6| Step: 7
Training loss: 3.8759183718310757
Validation loss: 3.1764159040978304

Epoch: 6| Step: 8
Training loss: 3.192942890223991
Validation loss: 3.1793249102451115

Epoch: 6| Step: 9
Training loss: 2.9097792003538707
Validation loss: 3.1772665572459586

Epoch: 6| Step: 10
Training loss: 3.9718879849561546
Validation loss: 3.175782007197817

Epoch: 6| Step: 11
Training loss: 3.3613712500865183
Validation loss: 3.177702424269646

Epoch: 6| Step: 12
Training loss: 3.4620494563174975
Validation loss: 3.1771798385307477

Epoch: 6| Step: 13
Training loss: 2.5253120758279097
Validation loss: 3.174930594553436

Epoch: 32| Step: 0
Training loss: 3.427688050568382
Validation loss: 3.1729192150005194

Epoch: 6| Step: 1
Training loss: 4.242525146985311
Validation loss: 3.1768819103947883

Epoch: 6| Step: 2
Training loss: 3.3991286002575523
Validation loss: 3.172505706650356

Epoch: 6| Step: 3
Training loss: 3.79778049801731
Validation loss: 3.173161692884988

Epoch: 6| Step: 4
Training loss: 3.1552681481598346
Validation loss: 3.1706415195964217

Epoch: 6| Step: 5
Training loss: 2.9568525736556404
Validation loss: 3.1677440150228433

Epoch: 6| Step: 6
Training loss: 2.5971078853180045
Validation loss: 3.168760055167149

Epoch: 6| Step: 7
Training loss: 3.285118801343481
Validation loss: 3.1727585127058635

Epoch: 6| Step: 8
Training loss: 3.997485324052563
Validation loss: 3.1693037939043336

Epoch: 6| Step: 9
Training loss: 3.3756221621635105
Validation loss: 3.170455237418584

Epoch: 6| Step: 10
Training loss: 3.330660574979482
Validation loss: 3.1674875963948517

Epoch: 6| Step: 11
Training loss: 3.526447101914001
Validation loss: 3.165955279569612

Epoch: 6| Step: 12
Training loss: 3.41578543548865
Validation loss: 3.1632858297445923

Epoch: 6| Step: 13
Training loss: 2.918455683309146
Validation loss: 3.1613042588143365

Epoch: 33| Step: 0
Training loss: 3.2258690188092993
Validation loss: 3.1621827183276987

Epoch: 6| Step: 1
Training loss: 2.9524047619142313
Validation loss: 3.1625876107208226

Epoch: 6| Step: 2
Training loss: 3.700841787308988
Validation loss: 3.162659976727348

Epoch: 6| Step: 3
Training loss: 2.1657469215586955
Validation loss: 3.1601040090492805

Epoch: 6| Step: 4
Training loss: 3.492835341064276
Validation loss: 3.158374285537281

Epoch: 6| Step: 5
Training loss: 4.378600029017417
Validation loss: 3.1575140284520216

Epoch: 6| Step: 6
Training loss: 3.7477914028357984
Validation loss: 3.1559898409762663

Epoch: 6| Step: 7
Training loss: 3.5709030364157743
Validation loss: 3.156720004911402

Epoch: 6| Step: 8
Training loss: 3.1749512736268546
Validation loss: 3.1557269455415167

Epoch: 6| Step: 9
Training loss: 3.3672478265513868
Validation loss: 3.1554718601628555

Epoch: 6| Step: 10
Training loss: 3.51647694755428
Validation loss: 3.154000722639837

Epoch: 6| Step: 11
Training loss: 3.6374938335563067
Validation loss: 3.154101400395993

Epoch: 6| Step: 12
Training loss: 3.3044303631676692
Validation loss: 3.1548777037463194

Epoch: 6| Step: 13
Training loss: 2.9031460501541066
Validation loss: 3.152736227221207

Epoch: 34| Step: 0
Training loss: 2.705601258080098
Validation loss: 3.1514357453719497

Epoch: 6| Step: 1
Training loss: 3.369878768777857
Validation loss: 3.1492751493834032

Epoch: 6| Step: 2
Training loss: 3.129139714097438
Validation loss: 3.1502271035490015

Epoch: 6| Step: 3
Training loss: 3.658164150928599
Validation loss: 3.149928568055983

Epoch: 6| Step: 4
Training loss: 3.146324944556471
Validation loss: 3.1522120618930853

Epoch: 6| Step: 5
Training loss: 3.2867791955756247
Validation loss: 3.149874139039993

Epoch: 6| Step: 6
Training loss: 3.9814533367361498
Validation loss: 3.145250633323336

Epoch: 6| Step: 7
Training loss: 4.33438681976973
Validation loss: 3.1454138763755153

Epoch: 6| Step: 8
Training loss: 3.3156247066170494
Validation loss: 3.142423508753043

Epoch: 6| Step: 9
Training loss: 2.8950227842603793
Validation loss: 3.1419014848491487

Epoch: 6| Step: 10
Training loss: 3.1431765084437147
Validation loss: 3.1411274949947696

Epoch: 6| Step: 11
Training loss: 3.422593829454985
Validation loss: 3.138309262319383

Epoch: 6| Step: 12
Training loss: 3.8014798595572787
Validation loss: 3.1396273136042296

Epoch: 6| Step: 13
Training loss: 2.9225226515780536
Validation loss: 3.13768105992148

Epoch: 35| Step: 0
Training loss: 4.174334426182374
Validation loss: 3.1353588993560413

Epoch: 6| Step: 1
Training loss: 3.3699582907249144
Validation loss: 3.1375943681413894

Epoch: 6| Step: 2
Training loss: 3.5299180481126755
Validation loss: 3.135894680627556

Epoch: 6| Step: 3
Training loss: 3.216739656348277
Validation loss: 3.1370019006569434

Epoch: 6| Step: 4
Training loss: 3.9902171668131143
Validation loss: 3.145166800909313

Epoch: 6| Step: 5
Training loss: 3.3594943712893905
Validation loss: 3.1371666132083478

Epoch: 6| Step: 6
Training loss: 3.1330949841470654
Validation loss: 3.139128986869908

Epoch: 6| Step: 7
Training loss: 2.910201964563343
Validation loss: 3.132609596092177

Epoch: 6| Step: 8
Training loss: 3.5428126257635375
Validation loss: 3.1302694156686086

Epoch: 6| Step: 9
Training loss: 2.6678974371074156
Validation loss: 3.135412198535953

Epoch: 6| Step: 10
Training loss: 3.7685549405610175
Validation loss: 3.137530372772327

Epoch: 6| Step: 11
Training loss: 3.2253261903912644
Validation loss: 3.1487493893617877

Epoch: 6| Step: 12
Training loss: 3.294246258348718
Validation loss: 3.1347714592464677

Epoch: 6| Step: 13
Training loss: 2.8056363596678793
Validation loss: 3.130477013863376

Epoch: 36| Step: 0
Training loss: 2.7953209848632317
Validation loss: 3.132533908842445

Epoch: 6| Step: 1
Training loss: 3.4346676341681373
Validation loss: 3.135294655575719

Epoch: 6| Step: 2
Training loss: 2.712604285138447
Validation loss: 3.136759475800989

Epoch: 6| Step: 3
Training loss: 3.7824969797065613
Validation loss: 3.1373676224567406

Epoch: 6| Step: 4
Training loss: 3.7376157353576183
Validation loss: 3.137608112080096

Epoch: 6| Step: 5
Training loss: 3.702499014824035
Validation loss: 3.1356352707842716

Epoch: 6| Step: 6
Training loss: 3.4530385554613967
Validation loss: 3.132880563778844

Epoch: 6| Step: 7
Training loss: 3.457547079277435
Validation loss: 3.1320791314150744

Epoch: 6| Step: 8
Training loss: 3.499062548841207
Validation loss: 3.1312119202916957

Epoch: 6| Step: 9
Training loss: 3.268690796529312
Validation loss: 3.1273791422191066

Epoch: 6| Step: 10
Training loss: 3.089824459435279
Validation loss: 3.1293207385415127

Epoch: 6| Step: 11
Training loss: 3.372940565420821
Validation loss: 3.129430349903966

Epoch: 6| Step: 12
Training loss: 2.8500788761400493
Validation loss: 3.1269716380366557

Epoch: 6| Step: 13
Training loss: 4.60076348146987
Validation loss: 3.126961589966591

Epoch: 37| Step: 0
Training loss: 2.554444374391255
Validation loss: 3.1239292549980076

Epoch: 6| Step: 1
Training loss: 3.540894562576481
Validation loss: 3.1214014232535825

Epoch: 6| Step: 2
Training loss: 2.462924119084798
Validation loss: 3.121157285647415

Epoch: 6| Step: 3
Training loss: 3.292446253402319
Validation loss: 3.1192963139607746

Epoch: 6| Step: 4
Training loss: 4.029402671826636
Validation loss: 3.120147368158843

Epoch: 6| Step: 5
Training loss: 3.21031550487941
Validation loss: 3.1261339242807114

Epoch: 6| Step: 6
Training loss: 3.493129526361634
Validation loss: 3.1303115201729868

Epoch: 6| Step: 7
Training loss: 3.83971509591822
Validation loss: 3.119214165001242

Epoch: 6| Step: 8
Training loss: 3.2453264231559933
Validation loss: 3.118613407419446

Epoch: 6| Step: 9
Training loss: 3.847240940665113
Validation loss: 3.1188066338030214

Epoch: 6| Step: 10
Training loss: 3.476333713504284
Validation loss: 3.119326846919985

Epoch: 6| Step: 11
Training loss: 3.587209039778468
Validation loss: 3.11980885018466

Epoch: 6| Step: 12
Training loss: 3.391150086699564
Validation loss: 3.1201362891335207

Epoch: 6| Step: 13
Training loss: 2.843961938359221
Validation loss: 3.11992396257813

Epoch: 38| Step: 0
Training loss: 4.10685136127882
Validation loss: 3.118468262950232

Epoch: 6| Step: 1
Training loss: 3.254692504703155
Validation loss: 3.11564673526867

Epoch: 6| Step: 2
Training loss: 3.4747542918767675
Validation loss: 3.1135719021493187

Epoch: 6| Step: 3
Training loss: 3.5433485338585395
Validation loss: 3.116022056243624

Epoch: 6| Step: 4
Training loss: 3.114250922352444
Validation loss: 3.1142477703312337

Epoch: 6| Step: 5
Training loss: 3.2821834144831996
Validation loss: 3.123260949375447

Epoch: 6| Step: 6
Training loss: 3.4634989264965528
Validation loss: 3.116244318335692

Epoch: 6| Step: 7
Training loss: 3.239052748492919
Validation loss: 3.113908797888577

Epoch: 6| Step: 8
Training loss: 3.8486663886587267
Validation loss: 3.112052961021941

Epoch: 6| Step: 9
Training loss: 3.832073184220415
Validation loss: 3.1100457866922495

Epoch: 6| Step: 10
Training loss: 3.0439901143639108
Validation loss: 3.1113970443726156

Epoch: 6| Step: 11
Training loss: 3.057133546517102
Validation loss: 3.111015010581018

Epoch: 6| Step: 12
Training loss: 3.1335522926876935
Validation loss: 3.114664098455406

Epoch: 6| Step: 13
Training loss: 2.1572480034442627
Validation loss: 3.1173097488479744

Epoch: 39| Step: 0
Training loss: 3.5866955057802277
Validation loss: 3.123963234489278

Epoch: 6| Step: 1
Training loss: 3.6822939831817694
Validation loss: 3.123573560124894

Epoch: 6| Step: 2
Training loss: 2.8984644803747623
Validation loss: 3.12395457018905

Epoch: 6| Step: 3
Training loss: 3.479383237269501
Validation loss: 3.1214058977515013

Epoch: 6| Step: 4
Training loss: 3.878163676718399
Validation loss: 3.116869024204888

Epoch: 6| Step: 5
Training loss: 3.8528671685773404
Validation loss: 3.114007391532386

Epoch: 6| Step: 6
Training loss: 3.830637080341099
Validation loss: 3.108479000990053

Epoch: 6| Step: 7
Training loss: 3.1234383304932614
Validation loss: 3.1076396556627284

Epoch: 6| Step: 8
Training loss: 3.3106765046523394
Validation loss: 3.10602921242048

Epoch: 6| Step: 9
Training loss: 3.141742867946232
Validation loss: 3.1070158681408024

Epoch: 6| Step: 10
Training loss: 2.29878539480784
Validation loss: 3.1065218136248527

Epoch: 6| Step: 11
Training loss: 3.6796786881197567
Validation loss: 3.105912208277229

Epoch: 6| Step: 12
Training loss: 2.701064719324762
Validation loss: 3.10633106401156

Epoch: 6| Step: 13
Training loss: 3.628707042601454
Validation loss: 3.1143771224131065

Epoch: 40| Step: 0
Training loss: 3.3905701522961595
Validation loss: 3.113856581296022

Epoch: 6| Step: 1
Training loss: 2.7470144190901085
Validation loss: 3.123896008802719

Epoch: 6| Step: 2
Training loss: 3.0624651225692556
Validation loss: 3.1187826051790815

Epoch: 6| Step: 3
Training loss: 3.1389877074974066
Validation loss: 3.1094727900930845

Epoch: 6| Step: 4
Training loss: 3.4226168172445988
Validation loss: 3.103682590445906

Epoch: 6| Step: 5
Training loss: 3.37757746858224
Validation loss: 3.104789194661244

Epoch: 6| Step: 6
Training loss: 3.731929345323779
Validation loss: 3.1040612452207093

Epoch: 6| Step: 7
Training loss: 3.599359264574532
Validation loss: 3.1039250729856325

Epoch: 6| Step: 8
Training loss: 3.3896246634231817
Validation loss: 3.1021557114034546

Epoch: 6| Step: 9
Training loss: 3.8609405925125464
Validation loss: 3.1007211980884386

Epoch: 6| Step: 10
Training loss: 2.7707096923165153
Validation loss: 3.099580335080087

Epoch: 6| Step: 11
Training loss: 3.4961708102977225
Validation loss: 3.0990687243698116

Epoch: 6| Step: 12
Training loss: 3.4306490512587895
Validation loss: 3.0979829710123608

Epoch: 6| Step: 13
Training loss: 3.762256936367986
Validation loss: 3.0972047510961365

Epoch: 41| Step: 0
Training loss: 2.86336967883359
Validation loss: 3.096713721775946

Epoch: 6| Step: 1
Training loss: 2.956617439774829
Validation loss: 3.0946024804399626

Epoch: 6| Step: 2
Training loss: 3.2800311049870574
Validation loss: 3.094069213242787

Epoch: 6| Step: 3
Training loss: 3.5614285112538036
Validation loss: 3.094586077616198

Epoch: 6| Step: 4
Training loss: 3.7111322934072186
Validation loss: 3.0940562817857797

Epoch: 6| Step: 5
Training loss: 3.418339963100879
Validation loss: 3.0923600300431446

Epoch: 6| Step: 6
Training loss: 3.9044783580100613
Validation loss: 3.0936204061320436

Epoch: 6| Step: 7
Training loss: 3.300507049909002
Validation loss: 3.092588658945358

Epoch: 6| Step: 8
Training loss: 4.00633310597792
Validation loss: 3.092360694091285

Epoch: 6| Step: 9
Training loss: 3.4003808088779914
Validation loss: 3.089840792950927

Epoch: 6| Step: 10
Training loss: 3.386214943694133
Validation loss: 3.0913293342077854

Epoch: 6| Step: 11
Training loss: 2.761003846870127
Validation loss: 3.087205056257407

Epoch: 6| Step: 12
Training loss: 3.1776575455524845
Validation loss: 3.0881921393021687

Epoch: 6| Step: 13
Training loss: 2.9461022894064617
Validation loss: 3.0857776476350547

Epoch: 42| Step: 0
Training loss: 2.4483524232262543
Validation loss: 3.0868383527559433

Epoch: 6| Step: 1
Training loss: 4.080279369513363
Validation loss: 3.0826435636808283

Epoch: 6| Step: 2
Training loss: 3.624155669702573
Validation loss: 3.0877518632388425

Epoch: 6| Step: 3
Training loss: 3.765688947079244
Validation loss: 3.0844677271471577

Epoch: 6| Step: 4
Training loss: 3.087730948887828
Validation loss: 3.0891906198164545

Epoch: 6| Step: 5
Training loss: 3.1909277941341654
Validation loss: 3.086674094878119

Epoch: 6| Step: 6
Training loss: 3.3315301945494693
Validation loss: 3.086578540984057

Epoch: 6| Step: 7
Training loss: 3.8512365114247595
Validation loss: 3.086756799220395

Epoch: 6| Step: 8
Training loss: 3.4131989598150043
Validation loss: 3.0838843260463014

Epoch: 6| Step: 9
Training loss: 3.653109775116638
Validation loss: 3.081517017704792

Epoch: 6| Step: 10
Training loss: 3.086126625929262
Validation loss: 3.0809467866290103

Epoch: 6| Step: 11
Training loss: 2.8759861788888466
Validation loss: 3.079832994136079

Epoch: 6| Step: 12
Training loss: 2.764298287831631
Validation loss: 3.079654598184676

Epoch: 6| Step: 13
Training loss: 3.4956089813176408
Validation loss: 3.079260020990524

Epoch: 43| Step: 0
Training loss: 3.0971035746917095
Validation loss: 3.081801301325433

Epoch: 6| Step: 1
Training loss: 4.104842903207109
Validation loss: 3.0798492124968537

Epoch: 6| Step: 2
Training loss: 3.171768863198833
Validation loss: 3.079221984836172

Epoch: 6| Step: 3
Training loss: 3.3314693643511646
Validation loss: 3.0904011148289143

Epoch: 6| Step: 4
Training loss: 3.4040744378348005
Validation loss: 3.0875497179037588

Epoch: 6| Step: 5
Training loss: 3.4338645437693165
Validation loss: 3.088993963167113

Epoch: 6| Step: 6
Training loss: 2.843227799645802
Validation loss: 3.0831926147978415

Epoch: 6| Step: 7
Training loss: 3.408774044454255
Validation loss: 3.088444034217688

Epoch: 6| Step: 8
Training loss: 3.6429277594851697
Validation loss: 3.081704003271423

Epoch: 6| Step: 9
Training loss: 3.129346495099122
Validation loss: 3.0827583540704637

Epoch: 6| Step: 10
Training loss: 3.2328425660908553
Validation loss: 3.0793021194704675

Epoch: 6| Step: 11
Training loss: 2.3736965216407437
Validation loss: 3.078228995539927

Epoch: 6| Step: 12
Training loss: 3.9839029668305295
Validation loss: 3.0781817762303327

Epoch: 6| Step: 13
Training loss: 3.500479937753779
Validation loss: 3.077776400924135

Epoch: 44| Step: 0
Training loss: 2.8266704043177717
Validation loss: 3.079231640865396

Epoch: 6| Step: 1
Training loss: 3.764025589891416
Validation loss: 3.0777922919452525

Epoch: 6| Step: 2
Training loss: 3.5269754920932144
Validation loss: 3.0791812556747353

Epoch: 6| Step: 3
Training loss: 3.776256953273762
Validation loss: 3.0764325656387745

Epoch: 6| Step: 4
Training loss: 2.947644188535487
Validation loss: 3.0754121650733

Epoch: 6| Step: 5
Training loss: 3.3794792968278395
Validation loss: 3.0755828192382677

Epoch: 6| Step: 6
Training loss: 3.577580173108568
Validation loss: 3.0758906141419926

Epoch: 6| Step: 7
Training loss: 3.3354085820084394
Validation loss: 3.075056991629269

Epoch: 6| Step: 8
Training loss: 2.9643377342190025
Validation loss: 3.0829624051575704

Epoch: 6| Step: 9
Training loss: 2.83252571787863
Validation loss: 3.0753992385266296

Epoch: 6| Step: 10
Training loss: 3.47290120585722
Validation loss: 3.0764286690504545

Epoch: 6| Step: 11
Training loss: 3.7058374956944116
Validation loss: 3.0748781251603465

Epoch: 6| Step: 12
Training loss: 3.2156520119469514
Validation loss: 3.07225234976538

Epoch: 6| Step: 13
Training loss: 3.332027386107446
Validation loss: 3.071959970479313

Epoch: 45| Step: 0
Training loss: 2.8461483075014655
Validation loss: 3.0710423201840173

Epoch: 6| Step: 1
Training loss: 3.8075454286406236
Validation loss: 3.071218172963768

Epoch: 6| Step: 2
Training loss: 3.0791845676450667
Validation loss: 3.0708636923875328

Epoch: 6| Step: 3
Training loss: 3.943005300782888
Validation loss: 3.070452255286734

Epoch: 6| Step: 4
Training loss: 3.777908235678446
Validation loss: 3.073064978127971

Epoch: 6| Step: 5
Training loss: 3.615585730495205
Validation loss: 3.0707270414864993

Epoch: 6| Step: 6
Training loss: 3.4031419485631673
Validation loss: 3.0732912911798325

Epoch: 6| Step: 7
Training loss: 3.1685840089197623
Validation loss: 3.068851889513236

Epoch: 6| Step: 8
Training loss: 3.4103195658201337
Validation loss: 3.0702448410598886

Epoch: 6| Step: 9
Training loss: 3.791637182994415
Validation loss: 3.0677561662291972

Epoch: 6| Step: 10
Training loss: 2.6962316742523176
Validation loss: 3.0676385087522675

Epoch: 6| Step: 11
Training loss: 3.046898787968037
Validation loss: 3.0689738175188124

Epoch: 6| Step: 12
Training loss: 3.027572131002472
Validation loss: 3.0699041439915176

Epoch: 6| Step: 13
Training loss: 2.5391846612739832
Validation loss: 3.067215239294755

Epoch: 46| Step: 0
Training loss: 2.7969321133200564
Validation loss: 3.0663146804316375

Epoch: 6| Step: 1
Training loss: 3.1581140433671937
Validation loss: 3.0666604828025386

Epoch: 6| Step: 2
Training loss: 3.0461000679696117
Validation loss: 3.0683173369324956

Epoch: 6| Step: 3
Training loss: 3.5862045022465736
Validation loss: 3.065782799511014

Epoch: 6| Step: 4
Training loss: 2.8859452590879386
Validation loss: 3.0718870100534073

Epoch: 6| Step: 5
Training loss: 3.4481199421654525
Validation loss: 3.075623692742338

Epoch: 6| Step: 6
Training loss: 3.8732447186530483
Validation loss: 3.0795305964637616

Epoch: 6| Step: 7
Training loss: 3.611671806886891
Validation loss: 3.081083560052506

Epoch: 6| Step: 8
Training loss: 3.0098128367687464
Validation loss: 3.0668043902405873

Epoch: 6| Step: 9
Training loss: 3.5004424769134097
Validation loss: 3.065119194434215

Epoch: 6| Step: 10
Training loss: 3.3130589139601194
Validation loss: 3.0646935058375364

Epoch: 6| Step: 11
Training loss: 3.9191581160684392
Validation loss: 3.062229484412102

Epoch: 6| Step: 12
Training loss: 3.455046244420822
Validation loss: 3.063566896404493

Epoch: 6| Step: 13
Training loss: 2.580618375112355
Validation loss: 3.064104918258118

Epoch: 47| Step: 0
Training loss: 3.306450267704436
Validation loss: 3.061564008009533

Epoch: 6| Step: 1
Training loss: 3.882784131443462
Validation loss: 3.062687065969156

Epoch: 6| Step: 2
Training loss: 3.7427129515950206
Validation loss: 3.0633499794215098

Epoch: 6| Step: 3
Training loss: 3.2579184681881355
Validation loss: 3.0630461386030228

Epoch: 6| Step: 4
Training loss: 3.2130028238387984
Validation loss: 3.063535448712042

Epoch: 6| Step: 5
Training loss: 3.3198121176262205
Validation loss: 3.061682435652678

Epoch: 6| Step: 6
Training loss: 2.96696305955314
Validation loss: 3.0611316092405305

Epoch: 6| Step: 7
Training loss: 3.715330715733191
Validation loss: 3.063298447580683

Epoch: 6| Step: 8
Training loss: 3.2792116645979643
Validation loss: 3.0617874887068015

Epoch: 6| Step: 9
Training loss: 3.2979497378135605
Validation loss: 3.062074594457513

Epoch: 6| Step: 10
Training loss: 3.2064370500460795
Validation loss: 3.0612124569475507

Epoch: 6| Step: 11
Training loss: 2.9338542959677225
Validation loss: 3.061378876509969

Epoch: 6| Step: 12
Training loss: 3.146423907560279
Validation loss: 3.060300729215099

Epoch: 6| Step: 13
Training loss: 3.3315661196272606
Validation loss: 3.0596332036061096

Epoch: 48| Step: 0
Training loss: 3.2573607792530166
Validation loss: 3.0568985364567487

Epoch: 6| Step: 1
Training loss: 3.1017898745273214
Validation loss: 3.058782226562237

Epoch: 6| Step: 2
Training loss: 2.9580861556974316
Validation loss: 3.0587160609380493

Epoch: 6| Step: 3
Training loss: 2.865969198973166
Validation loss: 3.056471730611198

Epoch: 6| Step: 4
Training loss: 2.413285707597453
Validation loss: 3.056924233988163

Epoch: 6| Step: 5
Training loss: 4.061346271720543
Validation loss: 3.055369130062949

Epoch: 6| Step: 6
Training loss: 3.1941279894959203
Validation loss: 3.0553013164120655

Epoch: 6| Step: 7
Training loss: 3.515878625834043
Validation loss: 3.0586962622663587

Epoch: 6| Step: 8
Training loss: 4.028987279065677
Validation loss: 3.0569196474953095

Epoch: 6| Step: 9
Training loss: 3.1293109913003914
Validation loss: 3.0559418444982955

Epoch: 6| Step: 10
Training loss: 3.105565176372453
Validation loss: 3.0557610369663326

Epoch: 6| Step: 11
Training loss: 3.0721796391137923
Validation loss: 3.056843422146585

Epoch: 6| Step: 12
Training loss: 3.9487061663130136
Validation loss: 3.0537879092767763

Epoch: 6| Step: 13
Training loss: 3.7847203494814905
Validation loss: 3.0553702409793195

Epoch: 49| Step: 0
Training loss: 3.3096998363283334
Validation loss: 3.053920670056147

Epoch: 6| Step: 1
Training loss: 3.737618924803702
Validation loss: 3.053557855809602

Epoch: 6| Step: 2
Training loss: 3.2835325022541464
Validation loss: 3.0527357346116646

Epoch: 6| Step: 3
Training loss: 2.6835248069291806
Validation loss: 3.053880090347286

Epoch: 6| Step: 4
Training loss: 3.798276791611343
Validation loss: 3.0541027675890384

Epoch: 6| Step: 5
Training loss: 3.696332536691167
Validation loss: 3.0534101675907146

Epoch: 6| Step: 6
Training loss: 3.4115492170424178
Validation loss: 3.0531922754362717

Epoch: 6| Step: 7
Training loss: 2.508981972743284
Validation loss: 3.052616587838161

Epoch: 6| Step: 8
Training loss: 3.443954788460635
Validation loss: 3.0521401541404263

Epoch: 6| Step: 9
Training loss: 4.269752824762847
Validation loss: 3.0506448020766084

Epoch: 6| Step: 10
Training loss: 3.00835178049055
Validation loss: 3.051208417449248

Epoch: 6| Step: 11
Training loss: 2.8180922965264896
Validation loss: 3.049585430596248

Epoch: 6| Step: 12
Training loss: 2.870312725933068
Validation loss: 3.0489163401319685

Epoch: 6| Step: 13
Training loss: 3.3048974369542274
Validation loss: 3.0493420411495804

Epoch: 50| Step: 0
Training loss: 3.1021525016402105
Validation loss: 3.0491686118046055

Epoch: 6| Step: 1
Training loss: 3.12914535237523
Validation loss: 3.0511290708160868

Epoch: 6| Step: 2
Training loss: 2.677039258621305
Validation loss: 3.0506440028939035

Epoch: 6| Step: 3
Training loss: 3.4982030887962847
Validation loss: 3.050499893635944

Epoch: 6| Step: 4
Training loss: 3.793866507989486
Validation loss: 3.048899292121002

Epoch: 6| Step: 5
Training loss: 3.0687674403423393
Validation loss: 3.046469413154954

Epoch: 6| Step: 6
Training loss: 3.6966609631681573
Validation loss: 3.048028502603863

Epoch: 6| Step: 7
Training loss: 2.6673262396351594
Validation loss: 3.050615651520902

Epoch: 6| Step: 8
Training loss: 3.9092982491232546
Validation loss: 3.0552494172273605

Epoch: 6| Step: 9
Training loss: 3.766209094068807
Validation loss: 3.0437089725116344

Epoch: 6| Step: 10
Training loss: 3.588443055295178
Validation loss: 3.0466586885742513

Epoch: 6| Step: 11
Training loss: 2.7665909626572884
Validation loss: 3.0440248531250664

Epoch: 6| Step: 12
Training loss: 3.162671195360944
Validation loss: 3.046068492129773

Epoch: 6| Step: 13
Training loss: 3.351111321658671
Validation loss: 3.0495140777265584

Epoch: 51| Step: 0
Training loss: 3.155888300651106
Validation loss: 3.054145099519144

Epoch: 6| Step: 1
Training loss: 3.01916233192643
Validation loss: 3.0567821426024024

Epoch: 6| Step: 2
Training loss: 3.4350982598655952
Validation loss: 3.059410892861633

Epoch: 6| Step: 3
Training loss: 3.858403257281538
Validation loss: 3.0550509500099126

Epoch: 6| Step: 4
Training loss: 3.441727552883698
Validation loss: 3.056567377741317

Epoch: 6| Step: 5
Training loss: 2.9646560549221923
Validation loss: 3.0488624302536693

Epoch: 6| Step: 6
Training loss: 3.2631977314452274
Validation loss: 3.044374349426062

Epoch: 6| Step: 7
Training loss: 3.2055125200749757
Validation loss: 3.042531955059201

Epoch: 6| Step: 8
Training loss: 3.662125651005498
Validation loss: 3.040908063709151

Epoch: 6| Step: 9
Training loss: 3.02034931032155
Validation loss: 3.0439103386940727

Epoch: 6| Step: 10
Training loss: 3.379488185978747
Validation loss: 3.0427551384113296

Epoch: 6| Step: 11
Training loss: 3.5558523428419013
Validation loss: 3.045192627404898

Epoch: 6| Step: 12
Training loss: 3.0113824441364994
Validation loss: 3.049360380544736

Epoch: 6| Step: 13
Training loss: 3.662759056954437
Validation loss: 3.05092552746932

Epoch: 52| Step: 0
Training loss: 3.8728282133811884
Validation loss: 3.05407092613033

Epoch: 6| Step: 1
Training loss: 3.5725420578442346
Validation loss: 3.051986516967863

Epoch: 6| Step: 2
Training loss: 2.9340098323436243
Validation loss: 3.042104490367352

Epoch: 6| Step: 3
Training loss: 3.12792892527504
Validation loss: 3.0402355271662223

Epoch: 6| Step: 4
Training loss: 3.314475711887167
Validation loss: 3.041003122969934

Epoch: 6| Step: 5
Training loss: 2.9837013003494555
Validation loss: 3.0417173844673155

Epoch: 6| Step: 6
Training loss: 3.32056926856435
Validation loss: 3.042721737444475

Epoch: 6| Step: 7
Training loss: 3.7250409168837995
Validation loss: 3.0421265847057666

Epoch: 6| Step: 8
Training loss: 2.8149013863834513
Validation loss: 3.041727772288696

Epoch: 6| Step: 9
Training loss: 3.6823681828356003
Validation loss: 3.0418173302727256

Epoch: 6| Step: 10
Training loss: 3.395543201120591
Validation loss: 3.041475168342282

Epoch: 6| Step: 11
Training loss: 3.264158951067934
Validation loss: 3.041662664294226

Epoch: 6| Step: 12
Training loss: 3.258543376217721
Validation loss: 3.0425282273898495

Epoch: 6| Step: 13
Training loss: 2.945728545818405
Validation loss: 3.0415013164820928

Epoch: 53| Step: 0
Training loss: 3.1608413689213926
Validation loss: 3.0411633507606113

Epoch: 6| Step: 1
Training loss: 3.146901553514537
Validation loss: 3.038227784395283

Epoch: 6| Step: 2
Training loss: 3.186988789572508
Validation loss: 3.0381907069841985

Epoch: 6| Step: 3
Training loss: 3.0029973315551977
Validation loss: 3.0382061983614603

Epoch: 6| Step: 4
Training loss: 3.7571427031873914
Validation loss: 3.037395179040814

Epoch: 6| Step: 5
Training loss: 3.697174828850793
Validation loss: 3.0379459430344835

Epoch: 6| Step: 6
Training loss: 3.173182326124533
Validation loss: 3.0405200736237004

Epoch: 6| Step: 7
Training loss: 3.0194052291174946
Validation loss: 3.0406842077205223

Epoch: 6| Step: 8
Training loss: 3.243001445034763
Validation loss: 3.0424636201888373

Epoch: 6| Step: 9
Training loss: 3.5516285236899545
Validation loss: 3.0413514054098147

Epoch: 6| Step: 10
Training loss: 3.3312784218783436
Validation loss: 3.035709672467463

Epoch: 6| Step: 11
Training loss: 3.397009819324261
Validation loss: 3.0344111192986607

Epoch: 6| Step: 12
Training loss: 3.7283332504342934
Validation loss: 3.0361577671145223

Epoch: 6| Step: 13
Training loss: 2.469338552118613
Validation loss: 3.035108368179524

Epoch: 54| Step: 0
Training loss: 3.1083737395441204
Validation loss: 3.042833926606795

Epoch: 6| Step: 1
Training loss: 3.9841404266121
Validation loss: 3.044018186359034

Epoch: 6| Step: 2
Training loss: 2.727757058342245
Validation loss: 3.0575974001587283

Epoch: 6| Step: 3
Training loss: 3.358826632432928
Validation loss: 3.062702713854356

Epoch: 6| Step: 4
Training loss: 3.2042329686270206
Validation loss: 3.0382096056269337

Epoch: 6| Step: 5
Training loss: 2.7059911626148483
Validation loss: 3.0394689807575035

Epoch: 6| Step: 6
Training loss: 2.9879048029328446
Validation loss: 3.0380901836704273

Epoch: 6| Step: 7
Training loss: 3.3769308147940005
Validation loss: 3.0369428081647127

Epoch: 6| Step: 8
Training loss: 3.7719013254278866
Validation loss: 3.0357855932778484

Epoch: 6| Step: 9
Training loss: 3.25660313542016
Validation loss: 3.0335144627377235

Epoch: 6| Step: 10
Training loss: 3.3322135633923082
Validation loss: 3.0321142674851016

Epoch: 6| Step: 11
Training loss: 3.2091986409941033
Validation loss: 3.0322560665394143

Epoch: 6| Step: 12
Training loss: 3.67914034588141
Validation loss: 3.0326290336510677

Epoch: 6| Step: 13
Training loss: 3.575674358868059
Validation loss: 3.034344609810681

Epoch: 55| Step: 0
Training loss: 2.4685084550730902
Validation loss: 3.0353712781048254

Epoch: 6| Step: 1
Training loss: 3.883266368719726
Validation loss: 3.0372996059362034

Epoch: 6| Step: 2
Training loss: 3.719356455358454
Validation loss: 3.0363086100739016

Epoch: 6| Step: 3
Training loss: 3.7975419326084383
Validation loss: 3.03533339974924

Epoch: 6| Step: 4
Training loss: 4.1824665848513884
Validation loss: 3.0348114904508363

Epoch: 6| Step: 5
Training loss: 3.1531866334122047
Validation loss: 3.031906239573791

Epoch: 6| Step: 6
Training loss: 3.403735291235247
Validation loss: 3.0336086770485338

Epoch: 6| Step: 7
Training loss: 3.284540179860072
Validation loss: 3.0313705337489356

Epoch: 6| Step: 8
Training loss: 2.850778466701848
Validation loss: 3.0308352695078056

Epoch: 6| Step: 9
Training loss: 3.834171922151285
Validation loss: 3.029859712219546

Epoch: 6| Step: 10
Training loss: 3.4683773081122853
Validation loss: 3.031061513165964

Epoch: 6| Step: 11
Training loss: 2.9547691007145716
Validation loss: 3.0291502107093504

Epoch: 6| Step: 12
Training loss: 1.765208574998343
Validation loss: 3.0275532980544044

Epoch: 6| Step: 13
Training loss: 2.424776369775244
Validation loss: 3.027107883861926

Epoch: 56| Step: 0
Training loss: 2.7077089812692376
Validation loss: 3.0322342224008487

Epoch: 6| Step: 1
Training loss: 2.4137891102273916
Validation loss: 3.0320589148899706

Epoch: 6| Step: 2
Training loss: 4.050827393963312
Validation loss: 3.04415731122686

Epoch: 6| Step: 3
Training loss: 3.352851388652233
Validation loss: 3.035963194381831

Epoch: 6| Step: 4
Training loss: 3.0569282762014294
Validation loss: 3.0252152827611885

Epoch: 6| Step: 5
Training loss: 3.506124315372139
Validation loss: 3.0230657106150813

Epoch: 6| Step: 6
Training loss: 3.761052818416338
Validation loss: 3.019730270570885

Epoch: 6| Step: 7
Training loss: 2.699721558659932
Validation loss: 3.019951053273801

Epoch: 6| Step: 8
Training loss: 4.023593462541493
Validation loss: 3.021080158632165

Epoch: 6| Step: 9
Training loss: 3.28015060172101
Validation loss: 3.022428278367465

Epoch: 6| Step: 10
Training loss: 3.402146693938284
Validation loss: 3.021379645611352

Epoch: 6| Step: 11
Training loss: 3.816642137029412
Validation loss: 3.0214507753777506

Epoch: 6| Step: 12
Training loss: 3.00546878807756
Validation loss: 3.0241363761447198

Epoch: 6| Step: 13
Training loss: 2.047758770660891
Validation loss: 3.021568794947592

Epoch: 57| Step: 0
Training loss: 2.8982838386870817
Validation loss: 3.026262658433915

Epoch: 6| Step: 1
Training loss: 2.766884468498427
Validation loss: 3.02966609735879

Epoch: 6| Step: 2
Training loss: 2.9334035677159847
Validation loss: 3.040099439921385

Epoch: 6| Step: 3
Training loss: 4.077438355148862
Validation loss: 3.022707392983314

Epoch: 6| Step: 4
Training loss: 3.601345626689554
Validation loss: 3.0182442545499315

Epoch: 6| Step: 5
Training loss: 3.6028040403024733
Validation loss: 3.020356116756495

Epoch: 6| Step: 6
Training loss: 2.8325019813523933
Validation loss: 3.0204909343115367

Epoch: 6| Step: 7
Training loss: 3.68580549714452
Validation loss: 3.0224341403107835

Epoch: 6| Step: 8
Training loss: 3.4769842342077424
Validation loss: 3.0189359285245523

Epoch: 6| Step: 9
Training loss: 3.0065315987077734
Validation loss: 3.0209326897824513

Epoch: 6| Step: 10
Training loss: 3.6334384173907766
Validation loss: 3.0190492232073685

Epoch: 6| Step: 11
Training loss: 2.6997623586272
Validation loss: 3.0181567500060584

Epoch: 6| Step: 12
Training loss: 3.629765764986357
Validation loss: 3.017819313079403

Epoch: 6| Step: 13
Training loss: 2.9269964854613884
Validation loss: 3.016330929447004

Epoch: 58| Step: 0
Training loss: 3.731259886250905
Validation loss: 3.016060882407344

Epoch: 6| Step: 1
Training loss: 3.657536207060298
Validation loss: 3.015695421349929

Epoch: 6| Step: 2
Training loss: 3.5462914881734973
Validation loss: 3.0133788151003404

Epoch: 6| Step: 3
Training loss: 3.2229432874063875
Validation loss: 3.0148964856879217

Epoch: 6| Step: 4
Training loss: 2.388913807504888
Validation loss: 3.014420645608218

Epoch: 6| Step: 5
Training loss: 3.1764736570289434
Validation loss: 3.0152237731660403

Epoch: 6| Step: 6
Training loss: 3.178619580340409
Validation loss: 3.015271464018904

Epoch: 6| Step: 7
Training loss: 2.6815773219494807
Validation loss: 3.018319357620763

Epoch: 6| Step: 8
Training loss: 3.707868796980956
Validation loss: 3.0216694411316896

Epoch: 6| Step: 9
Training loss: 2.2837975269168274
Validation loss: 3.0195304960706713

Epoch: 6| Step: 10
Training loss: 4.133405732987171
Validation loss: 3.015617831786601

Epoch: 6| Step: 11
Training loss: 2.7739587428319106
Validation loss: 3.0124851879160293

Epoch: 6| Step: 12
Training loss: 3.5658220562656635
Validation loss: 3.0113831728636398

Epoch: 6| Step: 13
Training loss: 3.7399053125073896
Validation loss: 3.0114243252293296

Epoch: 59| Step: 0
Training loss: 3.584982884152041
Validation loss: 3.0103648344808605

Epoch: 6| Step: 1
Training loss: 3.7263403612382175
Validation loss: 3.010809950642915

Epoch: 6| Step: 2
Training loss: 3.659566956004625
Validation loss: 3.0134212316377442

Epoch: 6| Step: 3
Training loss: 3.37744532407473
Validation loss: 3.010843219436079

Epoch: 6| Step: 4
Training loss: 3.4182252972916274
Validation loss: 3.010444935346822

Epoch: 6| Step: 5
Training loss: 2.9949734220774307
Validation loss: 3.0115193327757157

Epoch: 6| Step: 6
Training loss: 4.0636217182602286
Validation loss: 3.0103306755736847

Epoch: 6| Step: 7
Training loss: 3.035281616920999
Validation loss: 3.010284831975509

Epoch: 6| Step: 8
Training loss: 3.7444848512782953
Validation loss: 3.0119758105647607

Epoch: 6| Step: 9
Training loss: 2.738694098636385
Validation loss: 3.0114268893589484

Epoch: 6| Step: 10
Training loss: 2.7728778113191983
Validation loss: 3.0106847397949283

Epoch: 6| Step: 11
Training loss: 2.222235078244639
Validation loss: 3.0085850908527907

Epoch: 6| Step: 12
Training loss: 3.2303545007948684
Validation loss: 3.0085557279060624

Epoch: 6| Step: 13
Training loss: 2.9571900822703676
Validation loss: 3.0093183524029556

Epoch: 60| Step: 0
Training loss: 3.2526482283104867
Validation loss: 3.0093480657033824

Epoch: 6| Step: 1
Training loss: 3.2591152010815603
Validation loss: 3.0082477716486085

Epoch: 6| Step: 2
Training loss: 3.82679744200152
Validation loss: 3.007675108523794

Epoch: 6| Step: 3
Training loss: 3.933277833406955
Validation loss: 3.007254920591558

Epoch: 6| Step: 4
Training loss: 3.8227158302265356
Validation loss: 3.0061815250418094

Epoch: 6| Step: 5
Training loss: 3.184084689427755
Validation loss: 3.007492863697061

Epoch: 6| Step: 6
Training loss: 3.2432635991858128
Validation loss: 3.0056516554551176

Epoch: 6| Step: 7
Training loss: 2.96460957161468
Validation loss: 3.004460835529801

Epoch: 6| Step: 8
Training loss: 3.293053025222751
Validation loss: 3.005240881316308

Epoch: 6| Step: 9
Training loss: 2.6218218865090046
Validation loss: 3.0056574093831023

Epoch: 6| Step: 10
Training loss: 2.9779720623378827
Validation loss: 3.0051299315770015

Epoch: 6| Step: 11
Training loss: 2.508662284834407
Validation loss: 3.0046042195202767

Epoch: 6| Step: 12
Training loss: 3.505138167897209
Validation loss: 3.003627337700006

Epoch: 6| Step: 13
Training loss: 3.3877776535377246
Validation loss: 3.0022725808722064

Epoch: 61| Step: 0
Training loss: 3.166867065781117
Validation loss: 3.00414342234791

Epoch: 6| Step: 1
Training loss: 3.303918915961327
Validation loss: 3.0036953193911096

Epoch: 6| Step: 2
Training loss: 2.603072452816209
Validation loss: 3.0048458739323056

Epoch: 6| Step: 3
Training loss: 3.421815636524886
Validation loss: 3.00782656336718

Epoch: 6| Step: 4
Training loss: 2.54607739275032
Validation loss: 3.00681192125192

Epoch: 6| Step: 5
Training loss: 3.064799632606494
Validation loss: 3.003017225119279

Epoch: 6| Step: 6
Training loss: 4.144473493427087
Validation loss: 3.002429607272789

Epoch: 6| Step: 7
Training loss: 3.511514252510027
Validation loss: 3.0012029659443655

Epoch: 6| Step: 8
Training loss: 3.7064225206540238
Validation loss: 3.001175325472654

Epoch: 6| Step: 9
Training loss: 3.036954565487754
Validation loss: 3.0029500860533025

Epoch: 6| Step: 10
Training loss: 3.5993407175584555
Validation loss: 3.0047997512750313

Epoch: 6| Step: 11
Training loss: 2.615763991661098
Validation loss: 3.004254900895117

Epoch: 6| Step: 12
Training loss: 2.9995520575206505
Validation loss: 3.0021078163410153

Epoch: 6| Step: 13
Training loss: 4.226202817268185
Validation loss: 3.0025045492230964

Epoch: 62| Step: 0
Training loss: 3.9923382336850612
Validation loss: 3.005370688992143

Epoch: 6| Step: 1
Training loss: 2.845017706039923
Validation loss: 3.0043659827855635

Epoch: 6| Step: 2
Training loss: 3.5315135756167817
Validation loss: 3.003654293286084

Epoch: 6| Step: 3
Training loss: 3.286081299512664
Validation loss: 3.002604400894029

Epoch: 6| Step: 4
Training loss: 2.428086025951339
Validation loss: 3.0037605650044914

Epoch: 6| Step: 5
Training loss: 2.9532273693607816
Validation loss: 3.0046939454767756

Epoch: 6| Step: 6
Training loss: 3.5959951270794974
Validation loss: 3.002240459543087

Epoch: 6| Step: 7
Training loss: 3.4766618007236954
Validation loss: 3.0040050181890705

Epoch: 6| Step: 8
Training loss: 3.56232170863477
Validation loss: 3.0018020843706

Epoch: 6| Step: 9
Training loss: 3.4841272924668387
Validation loss: 3.002098619318914

Epoch: 6| Step: 10
Training loss: 3.369329987884942
Validation loss: 3.001436186276438

Epoch: 6| Step: 11
Training loss: 3.003034011145183
Validation loss: 3.0001443534221064

Epoch: 6| Step: 12
Training loss: 2.954964685374274
Validation loss: 3.0008874532531573

Epoch: 6| Step: 13
Training loss: 3.1767879828243784
Validation loss: 3.0007822373938042

Epoch: 63| Step: 0
Training loss: 3.475784454721494
Validation loss: 3.002538630669821

Epoch: 6| Step: 1
Training loss: 3.157934362597893
Validation loss: 3.001800354951525

Epoch: 6| Step: 2
Training loss: 3.4846107847896253
Validation loss: 3.0012447499135937

Epoch: 6| Step: 3
Training loss: 3.580235820654017
Validation loss: 3.000523926505097

Epoch: 6| Step: 4
Training loss: 3.7413951058738553
Validation loss: 2.9992637192217018

Epoch: 6| Step: 5
Training loss: 2.800968094768989
Validation loss: 3.0003422119793695

Epoch: 6| Step: 6
Training loss: 2.7959117402757228
Validation loss: 3.0014240566385015

Epoch: 6| Step: 7
Training loss: 2.92600647654048
Validation loss: 3.000012230249995

Epoch: 6| Step: 8
Training loss: 3.6660218683351204
Validation loss: 3.001819393879065

Epoch: 6| Step: 9
Training loss: 2.925192841261809
Validation loss: 2.999257267511502

Epoch: 6| Step: 10
Training loss: 3.248769086874902
Validation loss: 3.000913041817128

Epoch: 6| Step: 11
Training loss: 3.6730612279377657
Validation loss: 2.9970248408920073

Epoch: 6| Step: 12
Training loss: 3.1045350404501497
Validation loss: 2.9973705982009

Epoch: 6| Step: 13
Training loss: 3.0740791492684107
Validation loss: 2.9978054763797988

Epoch: 64| Step: 0
Training loss: 2.830522901126014
Validation loss: 2.9933757300637716

Epoch: 6| Step: 1
Training loss: 3.371703339203017
Validation loss: 2.9940530050966645

Epoch: 6| Step: 2
Training loss: 2.9218963785460375
Validation loss: 2.9935599998679656

Epoch: 6| Step: 3
Training loss: 3.7563428007268276
Validation loss: 2.9944901732014255

Epoch: 6| Step: 4
Training loss: 3.2474629696797033
Validation loss: 2.9950796851096135

Epoch: 6| Step: 5
Training loss: 2.197707420862669
Validation loss: 2.9935605256884643

Epoch: 6| Step: 6
Training loss: 3.3465439006685034
Validation loss: 2.9933023272910817

Epoch: 6| Step: 7
Training loss: 3.0845721737374077
Validation loss: 2.9957242014410084

Epoch: 6| Step: 8
Training loss: 3.7716108051051007
Validation loss: 2.992829386686172

Epoch: 6| Step: 9
Training loss: 3.7004449216003543
Validation loss: 2.9934950723159597

Epoch: 6| Step: 10
Training loss: 2.50226766736824
Validation loss: 2.9929869256528883

Epoch: 6| Step: 11
Training loss: 3.4685700515947238
Validation loss: 2.9916715517420363

Epoch: 6| Step: 12
Training loss: 3.9608549150814896
Validation loss: 2.9920409136762687

Epoch: 6| Step: 13
Training loss: 3.1699578264962986
Validation loss: 2.9917344631474894

Epoch: 65| Step: 0
Training loss: 3.3161580742131314
Validation loss: 2.993141745490966

Epoch: 6| Step: 1
Training loss: 3.162015125361537
Validation loss: 2.990984893679823

Epoch: 6| Step: 2
Training loss: 3.555427625129526
Validation loss: 2.989785897171626

Epoch: 6| Step: 3
Training loss: 3.305354923460406
Validation loss: 2.9876542752321225

Epoch: 6| Step: 4
Training loss: 3.5270617468425525
Validation loss: 2.9900514169688677

Epoch: 6| Step: 5
Training loss: 3.8135947234814846
Validation loss: 2.9916257075725845

Epoch: 6| Step: 6
Training loss: 3.2320493731268387
Validation loss: 2.9890905517715067

Epoch: 6| Step: 7
Training loss: 2.258082390200282
Validation loss: 2.9865665267528527

Epoch: 6| Step: 8
Training loss: 3.848453776007249
Validation loss: 2.988664877380191

Epoch: 6| Step: 9
Training loss: 2.971330184015059
Validation loss: 2.9892105814007364

Epoch: 6| Step: 10
Training loss: 2.6793371922481883
Validation loss: 2.9864192747990645

Epoch: 6| Step: 11
Training loss: 3.001023435862782
Validation loss: 2.985555638507574

Epoch: 6| Step: 12
Training loss: 3.5519163627572174
Validation loss: 2.9864795215893936

Epoch: 6| Step: 13
Training loss: 3.2284652604491884
Validation loss: 2.98748604085617

Epoch: 66| Step: 0
Training loss: 3.4247973082772654
Validation loss: 2.984781833796653

Epoch: 6| Step: 1
Training loss: 4.077166799172725
Validation loss: 2.988711005427521

Epoch: 6| Step: 2
Training loss: 3.2316561711104677
Validation loss: 2.9863079065021947

Epoch: 6| Step: 3
Training loss: 3.524755531653559
Validation loss: 2.9847682871342465

Epoch: 6| Step: 4
Training loss: 3.4132207535516343
Validation loss: 2.984305525013303

Epoch: 6| Step: 5
Training loss: 2.5117054608172937
Validation loss: 2.984745239114501

Epoch: 6| Step: 6
Training loss: 3.037274224324356
Validation loss: 2.9862482314326333

Epoch: 6| Step: 7
Training loss: 3.2354212741037065
Validation loss: 2.9864677037583305

Epoch: 6| Step: 8
Training loss: 2.970839397607921
Validation loss: 2.9839784925421915

Epoch: 6| Step: 9
Training loss: 3.2277114706693695
Validation loss: 2.9843697238886864

Epoch: 6| Step: 10
Training loss: 2.931721624568056
Validation loss: 2.9847472077456327

Epoch: 6| Step: 11
Training loss: 3.1188565711884713
Validation loss: 2.9861023451484154

Epoch: 6| Step: 12
Training loss: 3.3386962347011178
Validation loss: 2.984294489752933

Epoch: 6| Step: 13
Training loss: 3.6917856172868904
Validation loss: 2.9840093748523877

Epoch: 67| Step: 0
Training loss: 3.7529600540747126
Validation loss: 2.982275290061683

Epoch: 6| Step: 1
Training loss: 3.7159821283343906
Validation loss: 2.9840689460684833

Epoch: 6| Step: 2
Training loss: 3.139230598897086
Validation loss: 2.9854901358662125

Epoch: 6| Step: 3
Training loss: 2.5428672102243617
Validation loss: 2.9858233710436055

Epoch: 6| Step: 4
Training loss: 2.8053877017563056
Validation loss: 2.9840896505247456

Epoch: 6| Step: 5
Training loss: 3.748985026014476
Validation loss: 2.9822595038526134

Epoch: 6| Step: 6
Training loss: 3.185430715233457
Validation loss: 2.9820405092908873

Epoch: 6| Step: 7
Training loss: 3.4503489939768146
Validation loss: 2.9805045060876854

Epoch: 6| Step: 8
Training loss: 3.4822411268292233
Validation loss: 2.9799727308819586

Epoch: 6| Step: 9
Training loss: 3.2193217834446632
Validation loss: 2.98139809349649

Epoch: 6| Step: 10
Training loss: 3.4729014804617138
Validation loss: 2.9824735613080193

Epoch: 6| Step: 11
Training loss: 3.1124609580904314
Validation loss: 2.9839844300189022

Epoch: 6| Step: 12
Training loss: 2.9326797869921335
Validation loss: 2.97908985226218

Epoch: 6| Step: 13
Training loss: 2.5917109552097055
Validation loss: 2.981848046090806

Epoch: 68| Step: 0
Training loss: 3.5934710850495115
Validation loss: 2.9818057323877634

Epoch: 6| Step: 1
Training loss: 3.608227568053507
Validation loss: 2.98119114361314

Epoch: 6| Step: 2
Training loss: 4.224731725719028
Validation loss: 2.981239113168979

Epoch: 6| Step: 3
Training loss: 2.7051686406054225
Validation loss: 2.9830118210135255

Epoch: 6| Step: 4
Training loss: 2.8819295880242444
Validation loss: 2.9834719533287557

Epoch: 6| Step: 5
Training loss: 2.753725476114628
Validation loss: 2.986031821717267

Epoch: 6| Step: 6
Training loss: 2.7603205442187213
Validation loss: 2.986587088570525

Epoch: 6| Step: 7
Training loss: 3.9469219286523094
Validation loss: 2.9907784863020463

Epoch: 6| Step: 8
Training loss: 3.8208908548188703
Validation loss: 2.9837167249355976

Epoch: 6| Step: 9
Training loss: 2.9009041790711296
Validation loss: 2.9816918273395023

Epoch: 6| Step: 10
Training loss: 2.1734435640164103
Validation loss: 2.9789135601166286

Epoch: 6| Step: 11
Training loss: 3.195870572254078
Validation loss: 2.979179482690971

Epoch: 6| Step: 12
Training loss: 3.412666087597709
Validation loss: 2.980793518573671

Epoch: 6| Step: 13
Training loss: 2.8917379350335515
Validation loss: 2.9800688443679952

Epoch: 69| Step: 0
Training loss: 3.5056318203918737
Validation loss: 2.978582184745687

Epoch: 6| Step: 1
Training loss: 3.928201383031661
Validation loss: 2.9797248744766733

Epoch: 6| Step: 2
Training loss: 2.9825165239565443
Validation loss: 2.9808458643844844

Epoch: 6| Step: 3
Training loss: 3.4167940224582956
Validation loss: 2.977846500381946

Epoch: 6| Step: 4
Training loss: 2.708084760164885
Validation loss: 2.9807676214029923

Epoch: 6| Step: 5
Training loss: 3.0594565391389974
Validation loss: 2.9809107879440524

Epoch: 6| Step: 6
Training loss: 3.51541747434368
Validation loss: 2.9788392897692617

Epoch: 6| Step: 7
Training loss: 2.9495724901680007
Validation loss: 2.9775849530794454

Epoch: 6| Step: 8
Training loss: 2.853688740684754
Validation loss: 2.978567747469973

Epoch: 6| Step: 9
Training loss: 3.326054318423192
Validation loss: 2.978405720528721

Epoch: 6| Step: 10
Training loss: 3.2623268519965642
Validation loss: 2.9767771927599904

Epoch: 6| Step: 11
Training loss: 3.145446113518996
Validation loss: 2.977148376740354

Epoch: 6| Step: 12
Training loss: 3.523220960640987
Validation loss: 2.978275432238581

Epoch: 6| Step: 13
Training loss: 3.3719492652216765
Validation loss: 2.9767094317124143

Epoch: 70| Step: 0
Training loss: 3.5144358340375748
Validation loss: 2.9772693502177807

Epoch: 6| Step: 1
Training loss: 3.5863405221422124
Validation loss: 2.9770414633313798

Epoch: 6| Step: 2
Training loss: 3.472213528092414
Validation loss: 2.9774756376275913

Epoch: 6| Step: 3
Training loss: 2.9862473291678158
Validation loss: 2.977901818130066

Epoch: 6| Step: 4
Training loss: 2.550250291695497
Validation loss: 2.975016911742007

Epoch: 6| Step: 5
Training loss: 2.795874901664822
Validation loss: 2.975805182214508

Epoch: 6| Step: 6
Training loss: 3.2988888343658846
Validation loss: 2.974840231728144

Epoch: 6| Step: 7
Training loss: 3.4042346837047357
Validation loss: 2.9746452394396043

Epoch: 6| Step: 8
Training loss: 2.6361931623153274
Validation loss: 2.9740660724606522

Epoch: 6| Step: 9
Training loss: 3.0514337327922685
Validation loss: 2.9726823894522245

Epoch: 6| Step: 10
Training loss: 3.638548688702488
Validation loss: 2.9714124138803655

Epoch: 6| Step: 11
Training loss: 4.421890097009343
Validation loss: 2.9736945123604515

Epoch: 6| Step: 12
Training loss: 3.0127685933652404
Validation loss: 2.9732113211720073

Epoch: 6| Step: 13
Training loss: 2.412435928047332
Validation loss: 2.971383935485643

Epoch: 71| Step: 0
Training loss: 3.184226655359225
Validation loss: 2.972466754089713

Epoch: 6| Step: 1
Training loss: 3.327691994737617
Validation loss: 2.971931182274031

Epoch: 6| Step: 2
Training loss: 2.174113375721124
Validation loss: 2.972712250756988

Epoch: 6| Step: 3
Training loss: 3.6938545948071813
Validation loss: 2.971292281310058

Epoch: 6| Step: 4
Training loss: 3.1274611890109094
Validation loss: 2.972527943438085

Epoch: 6| Step: 5
Training loss: 3.182314975151614
Validation loss: 2.971099543794683

Epoch: 6| Step: 6
Training loss: 2.9941968421112666
Validation loss: 2.9709609058320585

Epoch: 6| Step: 7
Training loss: 3.483998641827359
Validation loss: 2.9717944731914847

Epoch: 6| Step: 8
Training loss: 3.062828513450862
Validation loss: 2.9695439173582803

Epoch: 6| Step: 9
Training loss: 2.9359617060728787
Validation loss: 2.972222313586859

Epoch: 6| Step: 10
Training loss: 3.4646048307564286
Validation loss: 2.9705304051530037

Epoch: 6| Step: 11
Training loss: 4.030152400616183
Validation loss: 2.9708858731856544

Epoch: 6| Step: 12
Training loss: 3.2010562822327078
Validation loss: 2.9706847781083985

Epoch: 6| Step: 13
Training loss: 3.45446295730976
Validation loss: 2.971653256262668

Epoch: 72| Step: 0
Training loss: 3.2114536585213367
Validation loss: 2.9695948263855985

Epoch: 6| Step: 1
Training loss: 3.4049002396678003
Validation loss: 2.9691145305564364

Epoch: 6| Step: 2
Training loss: 3.338813346167598
Validation loss: 2.9705077981391623

Epoch: 6| Step: 3
Training loss: 2.9061984806211445
Validation loss: 2.9695553501669965

Epoch: 6| Step: 4
Training loss: 3.3782149649611264
Validation loss: 2.968688781141623

Epoch: 6| Step: 5
Training loss: 2.8200964171247556
Validation loss: 2.9678987950472937

Epoch: 6| Step: 6
Training loss: 3.6761017841032912
Validation loss: 2.967808328965276

Epoch: 6| Step: 7
Training loss: 3.04759043583609
Validation loss: 2.9676562847976777

Epoch: 6| Step: 8
Training loss: 3.3728164390923387
Validation loss: 2.9676338571701866

Epoch: 6| Step: 9
Training loss: 3.031518668626737
Validation loss: 2.9667675936036204

Epoch: 6| Step: 10
Training loss: 3.262088010067295
Validation loss: 2.968357523528777

Epoch: 6| Step: 11
Training loss: 3.8496924884403687
Validation loss: 2.9645670464547758

Epoch: 6| Step: 12
Training loss: 2.542023889004686
Validation loss: 2.9667206249005673

Epoch: 6| Step: 13
Training loss: 3.615834454772686
Validation loss: 2.9664592106152563

Epoch: 73| Step: 0
Training loss: 3.6008946260831207
Validation loss: 2.966976739354391

Epoch: 6| Step: 1
Training loss: 3.9803249943373813
Validation loss: 2.9652700013349507

Epoch: 6| Step: 2
Training loss: 2.5272386579169415
Validation loss: 2.968216382326576

Epoch: 6| Step: 3
Training loss: 3.3166683529285637
Validation loss: 2.9674396639056457

Epoch: 6| Step: 4
Training loss: 3.7463798851227494
Validation loss: 2.96486869763794

Epoch: 6| Step: 5
Training loss: 2.9154468347016174
Validation loss: 2.965453112004859

Epoch: 6| Step: 6
Training loss: 3.7215817993391416
Validation loss: 2.9649296538334693

Epoch: 6| Step: 7
Training loss: 3.00125159540416
Validation loss: 2.964720300547107

Epoch: 6| Step: 8
Training loss: 2.8072406337159515
Validation loss: 2.964997365041775

Epoch: 6| Step: 9
Training loss: 3.0390739538766325
Validation loss: 2.9657020314981346

Epoch: 6| Step: 10
Training loss: 2.968602869503796
Validation loss: 2.9633056995360185

Epoch: 6| Step: 11
Training loss: 3.0221758435312185
Validation loss: 2.963851280755596

Epoch: 6| Step: 12
Training loss: 3.3794893147581417
Validation loss: 2.967822243282501

Epoch: 6| Step: 13
Training loss: 3.0970904878694245
Validation loss: 2.9750709119883303

Epoch: 74| Step: 0
Training loss: 2.5624151448412333
Validation loss: 2.9748098428284284

Epoch: 6| Step: 1
Training loss: 3.2047933560078277
Validation loss: 2.984193881104856

Epoch: 6| Step: 2
Training loss: 3.0578169536606876
Validation loss: 2.9882288508439396

Epoch: 6| Step: 3
Training loss: 3.47615237442207
Validation loss: 3.000507899670901

Epoch: 6| Step: 4
Training loss: 2.8662939524285562
Validation loss: 2.9851507909371753

Epoch: 6| Step: 5
Training loss: 3.6813310649864377
Validation loss: 2.9699808173956592

Epoch: 6| Step: 6
Training loss: 3.1564527389828947
Validation loss: 2.961528433711804

Epoch: 6| Step: 7
Training loss: 3.0936473482614777
Validation loss: 2.9606718144970694

Epoch: 6| Step: 8
Training loss: 3.9444629925454424
Validation loss: 2.962289279366274

Epoch: 6| Step: 9
Training loss: 3.2709365796034757
Validation loss: 2.9614181412004816

Epoch: 6| Step: 10
Training loss: 3.2336287812471096
Validation loss: 2.961745631501491

Epoch: 6| Step: 11
Training loss: 3.0205419114830834
Validation loss: 2.9626104144334904

Epoch: 6| Step: 12
Training loss: 2.921776591393019
Validation loss: 2.961587291119232

Epoch: 6| Step: 13
Training loss: 4.085995850593152
Validation loss: 2.9618119258640836

Epoch: 75| Step: 0
Training loss: 3.0387761390531565
Validation loss: 2.9616292444755863

Epoch: 6| Step: 1
Training loss: 3.1407331002073833
Validation loss: 2.9603985087986344

Epoch: 6| Step: 2
Training loss: 3.1911069619934866
Validation loss: 2.96140471966641

Epoch: 6| Step: 3
Training loss: 3.1772217433776633
Validation loss: 2.9629592869706176

Epoch: 6| Step: 4
Training loss: 2.9991151776407126
Validation loss: 2.962937387923758

Epoch: 6| Step: 5
Training loss: 3.232762916299005
Validation loss: 2.9615032371934924

Epoch: 6| Step: 6
Training loss: 3.045898750601138
Validation loss: 2.960726921482631

Epoch: 6| Step: 7
Training loss: 3.0998185873786555
Validation loss: 2.9610345560309574

Epoch: 6| Step: 8
Training loss: 3.30067781365298
Validation loss: 2.959221907648924

Epoch: 6| Step: 9
Training loss: 3.0722113020666235
Validation loss: 2.960711051551786

Epoch: 6| Step: 10
Training loss: 3.848588085132447
Validation loss: 2.9599917715876183

Epoch: 6| Step: 11
Training loss: 3.471350442589119
Validation loss: 2.9606113144319104

Epoch: 6| Step: 12
Training loss: 3.470115599012202
Validation loss: 2.9595406053516564

Epoch: 6| Step: 13
Training loss: 3.3153369199558385
Validation loss: 2.961628825516273

Epoch: 76| Step: 0
Training loss: 4.045064278034125
Validation loss: 2.964510449930688

Epoch: 6| Step: 1
Training loss: 3.2216931562786812
Validation loss: 2.9687254174450115

Epoch: 6| Step: 2
Training loss: 2.9943287013357547
Validation loss: 2.963714416948806

Epoch: 6| Step: 3
Training loss: 2.9649685518034747
Validation loss: 2.959724207340612

Epoch: 6| Step: 4
Training loss: 4.161375399046809
Validation loss: 2.9610031423257714

Epoch: 6| Step: 5
Training loss: 3.557541190128093
Validation loss: 2.958523824042254

Epoch: 6| Step: 6
Training loss: 2.6940553248727728
Validation loss: 2.9571579766633422

Epoch: 6| Step: 7
Training loss: 3.224439314962219
Validation loss: 2.958561195380663

Epoch: 6| Step: 8
Training loss: 2.2931093241087424
Validation loss: 2.959681611987045

Epoch: 6| Step: 9
Training loss: 3.0119519570155213
Validation loss: 2.9597532760481013

Epoch: 6| Step: 10
Training loss: 3.075261211930857
Validation loss: 2.9593411077642098

Epoch: 6| Step: 11
Training loss: 3.0969508403341326
Validation loss: 2.959750265250055

Epoch: 6| Step: 12
Training loss: 3.2972625938485653
Validation loss: 2.95832421109152

Epoch: 6| Step: 13
Training loss: 3.39233678685169
Validation loss: 2.9583125502950973

Epoch: 77| Step: 0
Training loss: 3.1459960558576165
Validation loss: 2.9570610422123784

Epoch: 6| Step: 1
Training loss: 3.181379238418862
Validation loss: 2.9581148453107775

Epoch: 6| Step: 2
Training loss: 3.2226205904750573
Validation loss: 2.959821108273763

Epoch: 6| Step: 3
Training loss: 3.411539153483652
Validation loss: 2.956416177136429

Epoch: 6| Step: 4
Training loss: 2.676147257700417
Validation loss: 2.9573398125172137

Epoch: 6| Step: 5
Training loss: 3.5318202005677164
Validation loss: 2.9562571393869237

Epoch: 6| Step: 6
Training loss: 2.951255893079342
Validation loss: 2.956343398519777

Epoch: 6| Step: 7
Training loss: 3.2826606261442848
Validation loss: 2.9568900164028684

Epoch: 6| Step: 8
Training loss: 2.9200698253696227
Validation loss: 2.955131851967

Epoch: 6| Step: 9
Training loss: 3.227161859813293
Validation loss: 2.954941351535705

Epoch: 6| Step: 10
Training loss: 3.6301284555032747
Validation loss: 2.953571067778024

Epoch: 6| Step: 11
Training loss: 3.2469027506107766
Validation loss: 2.954804543108988

Epoch: 6| Step: 12
Training loss: 3.533369120530566
Validation loss: 2.9540034160346123

Epoch: 6| Step: 13
Training loss: 3.288001679988534
Validation loss: 2.9534579513254395

Epoch: 78| Step: 0
Training loss: 3.118162533275541
Validation loss: 2.95527434328779

Epoch: 6| Step: 1
Training loss: 4.118260744989406
Validation loss: 2.9545814606408554

Epoch: 6| Step: 2
Training loss: 4.2083385706702146
Validation loss: 2.954420219882024

Epoch: 6| Step: 3
Training loss: 3.543151379707608
Validation loss: 2.965250394879379

Epoch: 6| Step: 4
Training loss: 2.767423745253158
Validation loss: 2.957091712341652

Epoch: 6| Step: 5
Training loss: 2.5894121411657136
Validation loss: 2.9539423654187758

Epoch: 6| Step: 6
Training loss: 2.8694759871439763
Validation loss: 2.9534909425887883

Epoch: 6| Step: 7
Training loss: 3.116249038812433
Validation loss: 2.954255824626269

Epoch: 6| Step: 8
Training loss: 2.9772887457814425
Validation loss: 2.9526808669995463

Epoch: 6| Step: 9
Training loss: 3.0589728772051186
Validation loss: 2.95459231967589

Epoch: 6| Step: 10
Training loss: 2.8546385177811406
Validation loss: 2.953640911567405

Epoch: 6| Step: 11
Training loss: 3.158819229339504
Validation loss: 2.9538131322746555

Epoch: 6| Step: 12
Training loss: 3.472665449887631
Validation loss: 2.9540973292508323

Epoch: 6| Step: 13
Training loss: 2.8973151241958552
Validation loss: 2.954536997617136

Epoch: 79| Step: 0
Training loss: 2.841291433788296
Validation loss: 2.9542763943838235

Epoch: 6| Step: 1
Training loss: 3.217430659141968
Validation loss: 2.95425420014387

Epoch: 6| Step: 2
Training loss: 3.1021691024602105
Validation loss: 2.954945567525567

Epoch: 6| Step: 3
Training loss: 3.0092681136911223
Validation loss: 2.9548119247909117

Epoch: 6| Step: 4
Training loss: 3.3551562411316684
Validation loss: 2.9546686294102384

Epoch: 6| Step: 5
Training loss: 3.548988418444119
Validation loss: 2.954427396004826

Epoch: 6| Step: 6
Training loss: 3.138992112824593
Validation loss: 2.9558745314815753

Epoch: 6| Step: 7
Training loss: 3.412006518555616
Validation loss: 2.958787584822381

Epoch: 6| Step: 8
Training loss: 3.345222505430669
Validation loss: 2.9573735718608782

Epoch: 6| Step: 9
Training loss: 3.6380745135829526
Validation loss: 2.9546411870088285

Epoch: 6| Step: 10
Training loss: 3.5950206334738244
Validation loss: 2.955068306195999

Epoch: 6| Step: 11
Training loss: 2.582731628074952
Validation loss: 2.953000518055537

Epoch: 6| Step: 12
Training loss: 2.7359091678287446
Validation loss: 2.9520173463949546

Epoch: 6| Step: 13
Training loss: 3.851299903692408
Validation loss: 2.94951453770783

Epoch: 80| Step: 0
Training loss: 3.4370319394582944
Validation loss: 2.9507714793128295

Epoch: 6| Step: 1
Training loss: 2.7905630141120232
Validation loss: 2.9494710752230064

Epoch: 6| Step: 2
Training loss: 3.7613490983681537
Validation loss: 2.9528233593879927

Epoch: 6| Step: 3
Training loss: 2.962933272857615
Validation loss: 2.9509254820116966

Epoch: 6| Step: 4
Training loss: 3.0101415559047173
Validation loss: 2.9504996685644014

Epoch: 6| Step: 5
Training loss: 3.7151365275087516
Validation loss: 2.9495493305281593

Epoch: 6| Step: 6
Training loss: 3.598146088395731
Validation loss: 2.9484707030409942

Epoch: 6| Step: 7
Training loss: 2.8739953981069357
Validation loss: 2.947452728824258

Epoch: 6| Step: 8
Training loss: 2.768658025518512
Validation loss: 2.947562661100736

Epoch: 6| Step: 9
Training loss: 4.027522529903692
Validation loss: 2.947121268538265

Epoch: 6| Step: 10
Training loss: 3.4794675198220464
Validation loss: 2.946095716055959

Epoch: 6| Step: 11
Training loss: 2.301244200160951
Validation loss: 2.9468881054888265

Epoch: 6| Step: 12
Training loss: 3.0121382880007417
Validation loss: 2.944440989364276

Epoch: 6| Step: 13
Training loss: 3.06160271403539
Validation loss: 2.944355712828569

Epoch: 81| Step: 0
Training loss: 2.8545683603632295
Validation loss: 2.944760210703876

Epoch: 6| Step: 1
Training loss: 3.436550355997159
Validation loss: 2.9456184867799635

Epoch: 6| Step: 2
Training loss: 3.683013514332106
Validation loss: 2.9456020245672434

Epoch: 6| Step: 3
Training loss: 3.205329248236382
Validation loss: 2.945445814782442

Epoch: 6| Step: 4
Training loss: 2.323730109644199
Validation loss: 2.9489890788422124

Epoch: 6| Step: 5
Training loss: 3.5395884680902525
Validation loss: 2.950465860111651

Epoch: 6| Step: 6
Training loss: 3.558541759190736
Validation loss: 2.952428828253365

Epoch: 6| Step: 7
Training loss: 2.6226194577424677
Validation loss: 2.949032266772302

Epoch: 6| Step: 8
Training loss: 2.6713251808593634
Validation loss: 2.954068196209193

Epoch: 6| Step: 9
Training loss: 3.010822801132497
Validation loss: 2.9498862260069405

Epoch: 6| Step: 10
Training loss: 2.9571338066346944
Validation loss: 2.948208913155523

Epoch: 6| Step: 11
Training loss: 3.1707197819820108
Validation loss: 2.9417609365755077

Epoch: 6| Step: 12
Training loss: 4.162743336206291
Validation loss: 2.941397389608834

Epoch: 6| Step: 13
Training loss: 3.825288804065554
Validation loss: 2.9416692901834818

Epoch: 82| Step: 0
Training loss: 3.406755042475698
Validation loss: 2.9426729189068213

Epoch: 6| Step: 1
Training loss: 3.3313651632188277
Validation loss: 2.942599751593364

Epoch: 6| Step: 2
Training loss: 2.7367505027329373
Validation loss: 2.9431908002434644

Epoch: 6| Step: 3
Training loss: 3.4736351461458987
Validation loss: 2.943076792670536

Epoch: 6| Step: 4
Training loss: 3.518974370222968
Validation loss: 2.943197350466482

Epoch: 6| Step: 5
Training loss: 2.8392188894628596
Validation loss: 2.9430957785601324

Epoch: 6| Step: 6
Training loss: 3.4873968457789157
Validation loss: 2.9453333376325808

Epoch: 6| Step: 7
Training loss: 2.633063963701714
Validation loss: 2.9453805272750864

Epoch: 6| Step: 8
Training loss: 3.320350987828402
Validation loss: 2.944777975645423

Epoch: 6| Step: 9
Training loss: 2.5317517007087695
Validation loss: 2.9445775875771463

Epoch: 6| Step: 10
Training loss: 3.2521496046125016
Validation loss: 2.9426229676716376

Epoch: 6| Step: 11
Training loss: 4.224286099223833
Validation loss: 2.9402973955859526

Epoch: 6| Step: 12
Training loss: 2.7980339163959838
Validation loss: 2.941202164868892

Epoch: 6| Step: 13
Training loss: 3.3718662548216933
Validation loss: 2.942062981171123

Epoch: 83| Step: 0
Training loss: 3.548572957297646
Validation loss: 2.939643803693705

Epoch: 6| Step: 1
Training loss: 2.6753917549833814
Validation loss: 2.940707116570796

Epoch: 6| Step: 2
Training loss: 3.635638706600484
Validation loss: 2.9393583069373506

Epoch: 6| Step: 3
Training loss: 3.325666495617936
Validation loss: 2.938261585743625

Epoch: 6| Step: 4
Training loss: 3.772679602289434
Validation loss: 2.9381838569560847

Epoch: 6| Step: 5
Training loss: 2.709309113613268
Validation loss: 2.9375451590008566

Epoch: 6| Step: 6
Training loss: 2.9831284720838007
Validation loss: 2.9374890070883857

Epoch: 6| Step: 7
Training loss: 3.221640760932988
Validation loss: 2.936778139338708

Epoch: 6| Step: 8
Training loss: 2.8636019788607077
Validation loss: 2.936910730313712

Epoch: 6| Step: 9
Training loss: 3.0202136927909704
Validation loss: 2.937543088046695

Epoch: 6| Step: 10
Training loss: 3.052757648713665
Validation loss: 2.9387514044757164

Epoch: 6| Step: 11
Training loss: 3.2871291034761505
Validation loss: 2.9359327615609314

Epoch: 6| Step: 12
Training loss: 3.497567285050017
Validation loss: 2.9370298731600166

Epoch: 6| Step: 13
Training loss: 3.3921366191827658
Validation loss: 2.9356498092991945

Epoch: 84| Step: 0
Training loss: 2.9189631186204137
Validation loss: 2.9387007323046843

Epoch: 6| Step: 1
Training loss: 3.2268258419130844
Validation loss: 2.946855289112009

Epoch: 6| Step: 2
Training loss: 3.19410619373105
Validation loss: 2.941038056729291

Epoch: 6| Step: 3
Training loss: 2.292382862422254
Validation loss: 2.9400377449803208

Epoch: 6| Step: 4
Training loss: 3.218465848065058
Validation loss: 2.9389521636246934

Epoch: 6| Step: 5
Training loss: 3.0440361687394977
Validation loss: 2.9344954580026057

Epoch: 6| Step: 6
Training loss: 3.5951162643626238
Validation loss: 2.936864301937626

Epoch: 6| Step: 7
Training loss: 3.160453188305239
Validation loss: 2.9351982082278756

Epoch: 6| Step: 8
Training loss: 3.435215416251896
Validation loss: 2.934273004369494

Epoch: 6| Step: 9
Training loss: 3.3296694328573357
Validation loss: 2.93519605613715

Epoch: 6| Step: 10
Training loss: 2.8910650794648625
Validation loss: 2.9333797962483987

Epoch: 6| Step: 11
Training loss: 3.2869733033147837
Validation loss: 2.9332533052044214

Epoch: 6| Step: 12
Training loss: 3.2558889587925606
Validation loss: 2.9343156068597858

Epoch: 6| Step: 13
Training loss: 4.537293711615313
Validation loss: 2.934888764355325

Epoch: 85| Step: 0
Training loss: 3.3077260290347956
Validation loss: 2.932843102348315

Epoch: 6| Step: 1
Training loss: 3.5959357207666742
Validation loss: 2.9325888463883927

Epoch: 6| Step: 2
Training loss: 3.389765617347571
Validation loss: 2.9316886314268786

Epoch: 6| Step: 3
Training loss: 3.3167139276814592
Validation loss: 2.9332720243105523

Epoch: 6| Step: 4
Training loss: 3.0438237488759414
Validation loss: 2.9315297799511035

Epoch: 6| Step: 5
Training loss: 3.0086308938870943
Validation loss: 2.932504902814677

Epoch: 6| Step: 6
Training loss: 2.872618808663143
Validation loss: 2.9318883807211122

Epoch: 6| Step: 7
Training loss: 4.038369685655039
Validation loss: 2.9332881309665897

Epoch: 6| Step: 8
Training loss: 2.6211023003656178
Validation loss: 2.933101237100227

Epoch: 6| Step: 9
Training loss: 3.210010255458528
Validation loss: 2.931878069788496

Epoch: 6| Step: 10
Training loss: 3.166656259887728
Validation loss: 2.9336534020544933

Epoch: 6| Step: 11
Training loss: 2.5891521099930843
Validation loss: 2.934747653183839

Epoch: 6| Step: 12
Training loss: 3.6213825197105236
Validation loss: 2.934118172194668

Epoch: 6| Step: 13
Training loss: 2.7526677803092117
Validation loss: 2.933002505030262

Epoch: 86| Step: 0
Training loss: 2.554229881993706
Validation loss: 2.929447147258738

Epoch: 6| Step: 1
Training loss: 3.7588023826975596
Validation loss: 2.9295515936498906

Epoch: 6| Step: 2
Training loss: 3.5897236701217032
Validation loss: 2.9327299565351956

Epoch: 6| Step: 3
Training loss: 3.6367051137633712
Validation loss: 2.9279784730505662

Epoch: 6| Step: 4
Training loss: 3.305832973204865
Validation loss: 2.928320918706613

Epoch: 6| Step: 5
Training loss: 3.490129175719433
Validation loss: 2.9285529347131964

Epoch: 6| Step: 6
Training loss: 3.3817778452092537
Validation loss: 2.9269589002938563

Epoch: 6| Step: 7
Training loss: 3.5894412540443326
Validation loss: 2.9271566619522242

Epoch: 6| Step: 8
Training loss: 2.9060043723381317
Validation loss: 2.926815220516028

Epoch: 6| Step: 9
Training loss: 3.3072574803945907
Validation loss: 2.927146541044524

Epoch: 6| Step: 10
Training loss: 2.3958513563279866
Validation loss: 2.9287806948850195

Epoch: 6| Step: 11
Training loss: 2.9361806300881566
Validation loss: 2.9282304476962664

Epoch: 6| Step: 12
Training loss: 2.808445360192454
Validation loss: 2.927938072370234

Epoch: 6| Step: 13
Training loss: 2.860229531260836
Validation loss: 2.9269537536668855

Epoch: 87| Step: 0
Training loss: 3.3748878177789514
Validation loss: 2.9269232363303668

Epoch: 6| Step: 1
Training loss: 2.708414536261378
Validation loss: 2.926752167989165

Epoch: 6| Step: 2
Training loss: 2.8017603653809386
Validation loss: 2.92831200909214

Epoch: 6| Step: 3
Training loss: 2.692113243668594
Validation loss: 2.926730435995249

Epoch: 6| Step: 4
Training loss: 3.3762492940620215
Validation loss: 2.926722789903876

Epoch: 6| Step: 5
Training loss: 4.080424511834197
Validation loss: 2.9263028180859254

Epoch: 6| Step: 6
Training loss: 2.9809768263700858
Validation loss: 2.92681769847782

Epoch: 6| Step: 7
Training loss: 3.5397447345316486
Validation loss: 2.925946294459434

Epoch: 6| Step: 8
Training loss: 3.1680962364048475
Validation loss: 2.926252965880459

Epoch: 6| Step: 9
Training loss: 3.8097296483196983
Validation loss: 2.9283413510983185

Epoch: 6| Step: 10
Training loss: 2.716450036271705
Validation loss: 2.931638487787156

Epoch: 6| Step: 11
Training loss: 2.99524677743779
Validation loss: 2.9357060208417547

Epoch: 6| Step: 12
Training loss: 3.0993255312203205
Validation loss: 2.9368636629618488

Epoch: 6| Step: 13
Training loss: 3.401429291036906
Validation loss: 2.947449255783626

Epoch: 88| Step: 0
Training loss: 3.0013138754965376
Validation loss: 2.9376542455164736

Epoch: 6| Step: 1
Training loss: 3.049575000606834
Validation loss: 2.9282500796500797

Epoch: 6| Step: 2
Training loss: 3.900355415777486
Validation loss: 2.92288858301109

Epoch: 6| Step: 3
Training loss: 3.471149061725212
Validation loss: 2.9227075939687692

Epoch: 6| Step: 4
Training loss: 2.8725306645575155
Validation loss: 2.9217501491852147

Epoch: 6| Step: 5
Training loss: 3.76639710421066
Validation loss: 2.923587246706186

Epoch: 6| Step: 6
Training loss: 2.5131467375897896
Validation loss: 2.9233531256580627

Epoch: 6| Step: 7
Training loss: 3.481055076525044
Validation loss: 2.921191068952794

Epoch: 6| Step: 8
Training loss: 3.569619142748955
Validation loss: 2.9216628336235626

Epoch: 6| Step: 9
Training loss: 2.613063557998942
Validation loss: 2.923362710728701

Epoch: 6| Step: 10
Training loss: 2.650690521387463
Validation loss: 2.923237855048737

Epoch: 6| Step: 11
Training loss: 3.2566223165979604
Validation loss: 2.9220543780499457

Epoch: 6| Step: 12
Training loss: 3.2865926208305543
Validation loss: 2.921933830545925

Epoch: 6| Step: 13
Training loss: 3.1758237415957304
Validation loss: 2.9220688330987477

Epoch: 89| Step: 0
Training loss: 3.1444445106437446
Validation loss: 2.9224897028347243

Epoch: 6| Step: 1
Training loss: 3.275456572877012
Validation loss: 2.920532060960204

Epoch: 6| Step: 2
Training loss: 2.9218746736087717
Validation loss: 2.92033683102044

Epoch: 6| Step: 3
Training loss: 3.347572922086831
Validation loss: 2.921023716151337

Epoch: 6| Step: 4
Training loss: 2.350798422540561
Validation loss: 2.9207664687008372

Epoch: 6| Step: 5
Training loss: 3.4352678854706933
Validation loss: 2.921691440416195

Epoch: 6| Step: 6
Training loss: 2.5157650736793418
Validation loss: 2.919028656222685

Epoch: 6| Step: 7
Training loss: 3.400779601082905
Validation loss: 2.9185403463140465

Epoch: 6| Step: 8
Training loss: 3.1767507577061997
Validation loss: 2.919821647174708

Epoch: 6| Step: 9
Training loss: 3.647926180377074
Validation loss: 2.9204363152012722

Epoch: 6| Step: 10
Training loss: 3.975800506791029
Validation loss: 2.9202649195307453

Epoch: 6| Step: 11
Training loss: 2.6009331019157083
Validation loss: 2.918009076975975

Epoch: 6| Step: 12
Training loss: 3.7317117427700564
Validation loss: 2.918970025335328

Epoch: 6| Step: 13
Training loss: 2.8346147631393785
Validation loss: 2.9183564724503253

Epoch: 90| Step: 0
Training loss: 2.970467321704443
Validation loss: 2.918532906271668

Epoch: 6| Step: 1
Training loss: 2.865713130215574
Validation loss: 2.9188672669418696

Epoch: 6| Step: 2
Training loss: 2.955246098012295
Validation loss: 2.9180156002628945

Epoch: 6| Step: 3
Training loss: 3.176418864487702
Validation loss: 2.9189939879260325

Epoch: 6| Step: 4
Training loss: 3.455048452608948
Validation loss: 2.919282749604662

Epoch: 6| Step: 5
Training loss: 3.6924584882155176
Validation loss: 2.9161433164952006

Epoch: 6| Step: 6
Training loss: 2.9846654620798336
Validation loss: 2.9181054980176704

Epoch: 6| Step: 7
Training loss: 3.4552241370539587
Validation loss: 2.917338998420941

Epoch: 6| Step: 8
Training loss: 3.856858888900604
Validation loss: 2.916495271267201

Epoch: 6| Step: 9
Training loss: 2.8876307470271816
Validation loss: 2.9170355942905477

Epoch: 6| Step: 10
Training loss: 3.4363481846031254
Validation loss: 2.9170330464994056

Epoch: 6| Step: 11
Training loss: 3.201560033571067
Validation loss: 2.918417108834342

Epoch: 6| Step: 12
Training loss: 2.937706148746303
Validation loss: 2.9151224651371845

Epoch: 6| Step: 13
Training loss: 2.5247066365151944
Validation loss: 2.91613277142876

Epoch: 91| Step: 0
Training loss: 3.3056607447823083
Validation loss: 2.91528680890898

Epoch: 6| Step: 1
Training loss: 2.984194765090927
Validation loss: 2.9178745631096734

Epoch: 6| Step: 2
Training loss: 3.2504678536166174
Validation loss: 2.9198383161991956

Epoch: 6| Step: 3
Training loss: 2.7632306612801916
Validation loss: 2.9153328211482004

Epoch: 6| Step: 4
Training loss: 3.634439477323987
Validation loss: 2.914112397119469

Epoch: 6| Step: 5
Training loss: 3.530959936061065
Validation loss: 2.9173155872835146

Epoch: 6| Step: 6
Training loss: 2.7932345603953865
Validation loss: 2.9171757343163347

Epoch: 6| Step: 7
Training loss: 3.9035674382694077
Validation loss: 2.9169140290403837

Epoch: 6| Step: 8
Training loss: 3.607563703771566
Validation loss: 2.91712238484216

Epoch: 6| Step: 9
Training loss: 2.74867832328045
Validation loss: 2.91423955270236

Epoch: 6| Step: 10
Training loss: 3.063810574116785
Validation loss: 2.9122459421579743

Epoch: 6| Step: 11
Training loss: 2.7987283714177695
Validation loss: 2.9145256865764564

Epoch: 6| Step: 12
Training loss: 3.0986874416571903
Validation loss: 2.912924666932172

Epoch: 6| Step: 13
Training loss: 3.067613186788276
Validation loss: 2.913586922212554

Epoch: 92| Step: 0
Training loss: 3.1509245711498983
Validation loss: 2.9125375012131136

Epoch: 6| Step: 1
Training loss: 3.138845670359405
Validation loss: 2.9124840491735347

Epoch: 6| Step: 2
Training loss: 3.2057740213255306
Validation loss: 2.9124825827186793

Epoch: 6| Step: 3
Training loss: 3.264638359289335
Validation loss: 2.9126501006053926

Epoch: 6| Step: 4
Training loss: 3.263847195694937
Validation loss: 2.911909874765026

Epoch: 6| Step: 5
Training loss: 3.8730707595865903
Validation loss: 2.9108084395535934

Epoch: 6| Step: 6
Training loss: 3.7855316385386284
Validation loss: 2.9096174857012405

Epoch: 6| Step: 7
Training loss: 2.540794462626258
Validation loss: 2.9097649045148146

Epoch: 6| Step: 8
Training loss: 2.61793530157357
Validation loss: 2.908619253116893

Epoch: 6| Step: 9
Training loss: 2.692301342506047
Validation loss: 2.907039269203459

Epoch: 6| Step: 10
Training loss: 3.104571595545852
Validation loss: 2.9076790420569387

Epoch: 6| Step: 11
Training loss: 3.3238614133458384
Validation loss: 2.9088460420305995

Epoch: 6| Step: 12
Training loss: 3.1644606351557285
Validation loss: 2.907499830793188

Epoch: 6| Step: 13
Training loss: 3.5988886707297074
Validation loss: 2.909475984174809

Epoch: 93| Step: 0
Training loss: 3.693592276005459
Validation loss: 2.9076562840598936

Epoch: 6| Step: 1
Training loss: 3.2504753352063998
Validation loss: 2.9153197933317534

Epoch: 6| Step: 2
Training loss: 3.1124707630423547
Validation loss: 2.907686557482204

Epoch: 6| Step: 3
Training loss: 2.944941408775911
Validation loss: 2.90524208002979

Epoch: 6| Step: 4
Training loss: 3.117263372353576
Validation loss: 2.90501427288424

Epoch: 6| Step: 5
Training loss: 3.0482185727043887
Validation loss: 2.9050433330732615

Epoch: 6| Step: 6
Training loss: 2.2102032308213655
Validation loss: 2.905211768781092

Epoch: 6| Step: 7
Training loss: 3.57828091610695
Validation loss: 2.9073705296039507

Epoch: 6| Step: 8
Training loss: 3.674839592371766
Validation loss: 2.9085849446386813

Epoch: 6| Step: 9
Training loss: 2.387399529545039
Validation loss: 2.904666740622505

Epoch: 6| Step: 10
Training loss: 3.6587315150798476
Validation loss: 2.9033996227489696

Epoch: 6| Step: 11
Training loss: 2.9956601859942613
Validation loss: 2.9031717822928815

Epoch: 6| Step: 12
Training loss: 3.4892516628566717
Validation loss: 2.9009348163547983

Epoch: 6| Step: 13
Training loss: 3.1716654290179993
Validation loss: 2.90367313554089

Epoch: 94| Step: 0
Training loss: 3.59108150757442
Validation loss: 2.901385410756488

Epoch: 6| Step: 1
Training loss: 3.5903119434638815
Validation loss: 2.901899612140501

Epoch: 6| Step: 2
Training loss: 3.430108185777483
Validation loss: 2.90098785640927

Epoch: 6| Step: 3
Training loss: 3.3627804550573943
Validation loss: 2.901380585457132

Epoch: 6| Step: 4
Training loss: 2.7369174145750366
Validation loss: 2.899647941478262

Epoch: 6| Step: 5
Training loss: 3.7348568657306154
Validation loss: 2.9011627653310494

Epoch: 6| Step: 6
Training loss: 3.018102231235058
Validation loss: 2.903888448170528

Epoch: 6| Step: 7
Training loss: 2.8446566635014365
Validation loss: 2.8999087702991524

Epoch: 6| Step: 8
Training loss: 2.8721856979648357
Validation loss: 2.8981052194174994

Epoch: 6| Step: 9
Training loss: 3.0947516775270745
Validation loss: 2.897798276283626

Epoch: 6| Step: 10
Training loss: 3.584987672494632
Validation loss: 2.9008650610075204

Epoch: 6| Step: 11
Training loss: 2.878798587602717
Validation loss: 2.8993705758104262

Epoch: 6| Step: 12
Training loss: 2.9184561734695285
Validation loss: 2.9067019436351225

Epoch: 6| Step: 13
Training loss: 2.49215631256201
Validation loss: 2.9053095931184107

Epoch: 95| Step: 0
Training loss: 2.7142698710560014
Validation loss: 2.9059109877655716

Epoch: 6| Step: 1
Training loss: 2.925018740862939
Validation loss: 2.9077592173470648

Epoch: 6| Step: 2
Training loss: 2.7078921227654464
Validation loss: 2.9113475840060574

Epoch: 6| Step: 3
Training loss: 3.0133906966913138
Validation loss: 2.906634115380423

Epoch: 6| Step: 4
Training loss: 3.7823361184672
Validation loss: 2.897695122751529

Epoch: 6| Step: 5
Training loss: 3.7679795624326515
Validation loss: 2.8954618353939763

Epoch: 6| Step: 6
Training loss: 2.625661675756164
Validation loss: 2.8970728122223774

Epoch: 6| Step: 7
Training loss: 3.368626687477038
Validation loss: 2.9006759985438335

Epoch: 6| Step: 8
Training loss: 3.5257547206375057
Validation loss: 2.9036896615362835

Epoch: 6| Step: 9
Training loss: 2.3019897188740877
Validation loss: 2.9074289799805

Epoch: 6| Step: 10
Training loss: 3.3377197650462613
Validation loss: 2.912636383932137

Epoch: 6| Step: 11
Training loss: 3.7469761418809044
Validation loss: 2.9197476596148584

Epoch: 6| Step: 12
Training loss: 2.8970605093312365
Validation loss: 2.9098073839023417

Epoch: 6| Step: 13
Training loss: 3.965790373447998
Validation loss: 2.9059244847540073

Epoch: 96| Step: 0
Training loss: 3.813947309093046
Validation loss: 2.899317648529213

Epoch: 6| Step: 1
Training loss: 3.70601261401513
Validation loss: 2.8979299967947187

Epoch: 6| Step: 2
Training loss: 3.1620164825762664
Validation loss: 2.8992880799926146

Epoch: 6| Step: 3
Training loss: 3.112994210712994
Validation loss: 2.8983060864879775

Epoch: 6| Step: 4
Training loss: 3.3085620432733998
Validation loss: 2.898385098767007

Epoch: 6| Step: 5
Training loss: 3.0464931150903607
Validation loss: 2.8996694503025484

Epoch: 6| Step: 6
Training loss: 2.734847720019668
Validation loss: 2.89907806219869

Epoch: 6| Step: 7
Training loss: 2.7058952997707677
Validation loss: 2.906475508708205

Epoch: 6| Step: 8
Training loss: 3.6178405040465407
Validation loss: 2.9107806734804114

Epoch: 6| Step: 9
Training loss: 2.8502381476236236
Validation loss: 2.907205146623234

Epoch: 6| Step: 10
Training loss: 2.913606255126473
Validation loss: 2.910814011936356

Epoch: 6| Step: 11
Training loss: 3.211746448053151
Validation loss: 2.9111740099977843

Epoch: 6| Step: 12
Training loss: 2.0825754567336814
Validation loss: 2.9110384246875776

Epoch: 6| Step: 13
Training loss: 4.437388029163362
Validation loss: 2.9053470948098234

Epoch: 97| Step: 0
Training loss: 3.381269636114786
Validation loss: 2.9004418215116243

Epoch: 6| Step: 1
Training loss: 3.567726718084854
Validation loss: 2.8965882673028585

Epoch: 6| Step: 2
Training loss: 3.2069319269409515
Validation loss: 2.895713090705643

Epoch: 6| Step: 3
Training loss: 3.4751822828606973
Validation loss: 2.8935218611958837

Epoch: 6| Step: 4
Training loss: 3.261632203193096
Validation loss: 2.8937163394662457

Epoch: 6| Step: 5
Training loss: 3.407512605773939
Validation loss: 2.8943620120555797

Epoch: 6| Step: 6
Training loss: 2.7407414027758343
Validation loss: 2.893545560087411

Epoch: 6| Step: 7
Training loss: 2.9455682860996744
Validation loss: 2.8939026081054298

Epoch: 6| Step: 8
Training loss: 3.057636057461335
Validation loss: 2.8937693576789414

Epoch: 6| Step: 9
Training loss: 3.5409095104411823
Validation loss: 2.894212733346196

Epoch: 6| Step: 10
Training loss: 2.7721537453096423
Validation loss: 2.894116720105071

Epoch: 6| Step: 11
Training loss: 3.2569234902024817
Validation loss: 2.8934783696788027

Epoch: 6| Step: 12
Training loss: 2.7367904022097567
Validation loss: 2.8932768263056876

Epoch: 6| Step: 13
Training loss: 3.1426388181677956
Validation loss: 2.8932511107196457

Epoch: 98| Step: 0
Training loss: 3.1931153743745906
Validation loss: 2.8925328032729034

Epoch: 6| Step: 1
Training loss: 2.5218529228747295
Validation loss: 2.8936459370075753

Epoch: 6| Step: 2
Training loss: 3.17450458536254
Validation loss: 2.9002625687756334

Epoch: 6| Step: 3
Training loss: 4.028007918758242
Validation loss: 2.9004620914459576

Epoch: 6| Step: 4
Training loss: 2.420471769329402
Validation loss: 2.9114436383430253

Epoch: 6| Step: 5
Training loss: 3.1380398107353202
Validation loss: 2.917703258582055

Epoch: 6| Step: 6
Training loss: 3.223205297689281
Validation loss: 2.9163974432618085

Epoch: 6| Step: 7
Training loss: 3.601529930116424
Validation loss: 2.9092491553663384

Epoch: 6| Step: 8
Training loss: 3.4495915765468395
Validation loss: 2.8934411323581206

Epoch: 6| Step: 9
Training loss: 3.2298813716019947
Validation loss: 2.8888021542339306

Epoch: 6| Step: 10
Training loss: 3.352705896072831
Validation loss: 2.8904074948734584

Epoch: 6| Step: 11
Training loss: 3.044125925775335
Validation loss: 2.889395017384717

Epoch: 6| Step: 12
Training loss: 3.3165228545736976
Validation loss: 2.889966121258846

Epoch: 6| Step: 13
Training loss: 2.0733793755025927
Validation loss: 2.887873429583458

Epoch: 99| Step: 0
Training loss: 3.5240978628679303
Validation loss: 2.8904073245794715

Epoch: 6| Step: 1
Training loss: 3.4787614019099466
Validation loss: 2.8896486912337

Epoch: 6| Step: 2
Training loss: 2.9381498875930223
Validation loss: 2.88938201635491

Epoch: 6| Step: 3
Training loss: 3.105201258625177
Validation loss: 2.890974164393183

Epoch: 6| Step: 4
Training loss: 2.6592270268692983
Validation loss: 2.892606113657899

Epoch: 6| Step: 5
Training loss: 3.3122725498636245
Validation loss: 2.891953480275978

Epoch: 6| Step: 6
Training loss: 2.2125570343769883
Validation loss: 2.89162120376126

Epoch: 6| Step: 7
Training loss: 3.434047699345394
Validation loss: 2.8864917333109052

Epoch: 6| Step: 8
Training loss: 3.336303119143645
Validation loss: 2.8857264853102103

Epoch: 6| Step: 9
Training loss: 3.2390127057647473
Validation loss: 2.8838312960146006

Epoch: 6| Step: 10
Training loss: 2.842605863695049
Validation loss: 2.888101224434054

Epoch: 6| Step: 11
Training loss: 3.2242429214285075
Validation loss: 2.886102219048759

Epoch: 6| Step: 12
Training loss: 3.3359596555452065
Validation loss: 2.8857857551878965

Epoch: 6| Step: 13
Training loss: 4.008327399002938
Validation loss: 2.8852657383630937

Epoch: 100| Step: 0
Training loss: 2.6258501765095237
Validation loss: 2.884029856717193

Epoch: 6| Step: 1
Training loss: 3.1552572672036128
Validation loss: 2.8816178766212563

Epoch: 6| Step: 2
Training loss: 3.1953787575266777
Validation loss: 2.8826319740290542

Epoch: 6| Step: 3
Training loss: 3.1699534642025835
Validation loss: 2.88475798587539

Epoch: 6| Step: 4
Training loss: 2.6593225099648246
Validation loss: 2.8846829656820283

Epoch: 6| Step: 5
Training loss: 3.784545975216233
Validation loss: 2.8846016450938112

Epoch: 6| Step: 6
Training loss: 2.2858084505984197
Validation loss: 2.8824733451590814

Epoch: 6| Step: 7
Training loss: 3.4036023410313407
Validation loss: 2.8817895612343527

Epoch: 6| Step: 8
Training loss: 3.3511308156397406
Validation loss: 2.8838659034242786

Epoch: 6| Step: 9
Training loss: 3.135512712767057
Validation loss: 2.8823619567940257

Epoch: 6| Step: 10
Training loss: 3.36666278335297
Validation loss: 2.8842875741986935

Epoch: 6| Step: 11
Training loss: 3.6265771000217746
Validation loss: 2.8842296250270367

Epoch: 6| Step: 12
Training loss: 3.1800461925294568
Validation loss: 2.8840405556083244

Epoch: 6| Step: 13
Training loss: 3.3340244212591985
Validation loss: 2.886472431947967

Epoch: 101| Step: 0
Training loss: 3.1488960632634937
Validation loss: 2.8846507320652117

Epoch: 6| Step: 1
Training loss: 3.205898665722735
Validation loss: 2.891647352302062

Epoch: 6| Step: 2
Training loss: 2.906737091920322
Validation loss: 2.8981851447391893

Epoch: 6| Step: 3
Training loss: 2.9669592023769615
Validation loss: 2.893555936735942

Epoch: 6| Step: 4
Training loss: 3.0133905384519024
Validation loss: 2.8893234821602163

Epoch: 6| Step: 5
Training loss: 2.9861007414250866
Validation loss: 2.882375018838845

Epoch: 6| Step: 6
Training loss: 3.4863337327073247
Validation loss: 2.879472495057924

Epoch: 6| Step: 7
Training loss: 2.8479897888514882
Validation loss: 2.8796653203785727

Epoch: 6| Step: 8
Training loss: 3.197032363016643
Validation loss: 2.8812474679360762

Epoch: 6| Step: 9
Training loss: 3.291341612656768
Validation loss: 2.879898994314185

Epoch: 6| Step: 10
Training loss: 3.0994553795138216
Validation loss: 2.8790307353046627

Epoch: 6| Step: 11
Training loss: 3.656112016209739
Validation loss: 2.879442138681187

Epoch: 6| Step: 12
Training loss: 3.062493616214249
Validation loss: 2.879932185531688

Epoch: 6| Step: 13
Training loss: 3.806331208964725
Validation loss: 2.879123176165628

Epoch: 102| Step: 0
Training loss: 3.703926740041339
Validation loss: 2.8799927505506746

Epoch: 6| Step: 1
Training loss: 2.7833871238520858
Validation loss: 2.878924347395453

Epoch: 6| Step: 2
Training loss: 2.9106135271504447
Validation loss: 2.8779367461378715

Epoch: 6| Step: 3
Training loss: 2.638411909352265
Validation loss: 2.8770939093335826

Epoch: 6| Step: 4
Training loss: 3.33530722030898
Validation loss: 2.877273245805099

Epoch: 6| Step: 5
Training loss: 2.768362813015979
Validation loss: 2.8787158851867134

Epoch: 6| Step: 6
Training loss: 3.0599815757047204
Validation loss: 2.876975156366389

Epoch: 6| Step: 7
Training loss: 3.494735982634149
Validation loss: 2.8759646480455645

Epoch: 6| Step: 8
Training loss: 2.923605666428603
Validation loss: 2.8764946197122176

Epoch: 6| Step: 9
Training loss: 3.1941096273203167
Validation loss: 2.8769103770382096

Epoch: 6| Step: 10
Training loss: 3.4228806781482786
Validation loss: 2.8757543229672398

Epoch: 6| Step: 11
Training loss: 3.487288962921353
Validation loss: 2.877977332078887

Epoch: 6| Step: 12
Training loss: 3.1359348481475458
Validation loss: 2.8750366914823435

Epoch: 6| Step: 13
Training loss: 3.5877917446908043
Validation loss: 2.8756035433850826

Epoch: 103| Step: 0
Training loss: 3.9834028666238552
Validation loss: 2.873823577036445

Epoch: 6| Step: 1
Training loss: 3.125086058385345
Validation loss: 2.872598703698931

Epoch: 6| Step: 2
Training loss: 3.4571515250969935
Validation loss: 2.873436024895019

Epoch: 6| Step: 3
Training loss: 2.5077851195935206
Validation loss: 2.871846115651015

Epoch: 6| Step: 4
Training loss: 3.472090204060349
Validation loss: 2.8736462609367908

Epoch: 6| Step: 5
Training loss: 3.498224080345425
Validation loss: 2.8731157870645982

Epoch: 6| Step: 6
Training loss: 3.261207622751334
Validation loss: 2.872128543152643

Epoch: 6| Step: 7
Training loss: 3.3978807015136288
Validation loss: 2.872024637248297

Epoch: 6| Step: 8
Training loss: 2.0903690426638994
Validation loss: 2.8715018042628255

Epoch: 6| Step: 9
Training loss: 3.465158613793891
Validation loss: 2.870912093341838

Epoch: 6| Step: 10
Training loss: 2.4101315192587545
Validation loss: 2.8713374177554405

Epoch: 6| Step: 11
Training loss: 2.6995437801772635
Validation loss: 2.868247129943427

Epoch: 6| Step: 12
Training loss: 3.112822648449192
Validation loss: 2.8705094299331275

Epoch: 6| Step: 13
Training loss: 3.5195414112211116
Validation loss: 2.8714059369368767

Epoch: 104| Step: 0
Training loss: 3.32121655890614
Validation loss: 2.8688138703702024

Epoch: 6| Step: 1
Training loss: 3.1887252547060245
Validation loss: 2.8704248149799763

Epoch: 6| Step: 2
Training loss: 2.8593573230968286
Validation loss: 2.8689089468030473

Epoch: 6| Step: 3
Training loss: 2.6049855483344335
Validation loss: 2.8687720127214233

Epoch: 6| Step: 4
Training loss: 2.914156423901069
Validation loss: 2.8681020874861303

Epoch: 6| Step: 5
Training loss: 2.68786086387662
Validation loss: 2.8689288435043747

Epoch: 6| Step: 6
Training loss: 3.2801290868153155
Validation loss: 2.8674730979754015

Epoch: 6| Step: 7
Training loss: 3.6354720030383247
Validation loss: 2.8672264954611317

Epoch: 6| Step: 8
Training loss: 3.0324154216044628
Validation loss: 2.866910518878324

Epoch: 6| Step: 9
Training loss: 3.4622889650669704
Validation loss: 2.8700435300034632

Epoch: 6| Step: 10
Training loss: 3.872865150332019
Validation loss: 2.8719942682042054

Epoch: 6| Step: 11
Training loss: 3.550014366873025
Validation loss: 2.8708870998736473

Epoch: 6| Step: 12
Training loss: 2.59624241952244
Validation loss: 2.875178229472916

Epoch: 6| Step: 13
Training loss: 2.991979845774696
Validation loss: 2.8729314331035947

Epoch: 105| Step: 0
Training loss: 2.9524882603992535
Validation loss: 2.874269506807841

Epoch: 6| Step: 1
Training loss: 3.5598749226660837
Validation loss: 2.871901090845034

Epoch: 6| Step: 2
Training loss: 3.1317558504337586
Validation loss: 2.8699110396494985

Epoch: 6| Step: 3
Training loss: 3.3450349139343003
Validation loss: 2.8769084059044983

Epoch: 6| Step: 4
Training loss: 3.4145147168144954
Validation loss: 2.86851651769283

Epoch: 6| Step: 5
Training loss: 2.983077800896036
Validation loss: 2.8702046277544278

Epoch: 6| Step: 6
Training loss: 2.9824341859294865
Validation loss: 2.8667476773053697

Epoch: 6| Step: 7
Training loss: 3.457337446715172
Validation loss: 2.864633066112956

Epoch: 6| Step: 8
Training loss: 3.153472282407614
Validation loss: 2.8674060082984534

Epoch: 6| Step: 9
Training loss: 3.446380933973089
Validation loss: 2.869087399180206

Epoch: 6| Step: 10
Training loss: 2.3630296305228597
Validation loss: 2.8685928034279473

Epoch: 6| Step: 11
Training loss: 2.1516652777342546
Validation loss: 2.870316630813931

Epoch: 6| Step: 12
Training loss: 3.4634551455750304
Validation loss: 2.872066872376378

Epoch: 6| Step: 13
Training loss: 3.8800757605244858
Validation loss: 2.8738037499065623

Epoch: 106| Step: 0
Training loss: 3.0149435745956517
Validation loss: 2.8764901742148115

Epoch: 6| Step: 1
Training loss: 3.419856203190492
Validation loss: 2.8743402402649876

Epoch: 6| Step: 2
Training loss: 3.502683564412404
Validation loss: 2.8763732947391367

Epoch: 6| Step: 3
Training loss: 2.6954438550702893
Validation loss: 2.8737506532745267

Epoch: 6| Step: 4
Training loss: 2.3798732953043698
Validation loss: 2.872325937682145

Epoch: 6| Step: 5
Training loss: 3.418574304616485
Validation loss: 2.8705330772329556

Epoch: 6| Step: 6
Training loss: 3.3739304437257034
Validation loss: 2.8685910133607795

Epoch: 6| Step: 7
Training loss: 3.6545240452923045
Validation loss: 2.8677553688209096

Epoch: 6| Step: 8
Training loss: 2.9348463693471114
Validation loss: 2.8674220834999726

Epoch: 6| Step: 9
Training loss: 2.9707994313777917
Validation loss: 2.867036769727684

Epoch: 6| Step: 10
Training loss: 3.158400303542442
Validation loss: 2.870179564708534

Epoch: 6| Step: 11
Training loss: 2.7810041340368903
Validation loss: 2.8715967577753814

Epoch: 6| Step: 12
Training loss: 3.694484238820563
Validation loss: 2.872392143101588

Epoch: 6| Step: 13
Training loss: 3.0585783157836155
Validation loss: 2.8759485189725718

Epoch: 107| Step: 0
Training loss: 3.367348085189747
Validation loss: 2.877676035385823

Epoch: 6| Step: 1
Training loss: 3.0001242929777807
Validation loss: 2.8772948203155173

Epoch: 6| Step: 2
Training loss: 2.976291594104517
Validation loss: 2.879530685528282

Epoch: 6| Step: 3
Training loss: 3.5229093912877794
Validation loss: 2.8823170583429794

Epoch: 6| Step: 4
Training loss: 3.5578175607946
Validation loss: 2.886517584607471

Epoch: 6| Step: 5
Training loss: 2.2908101879998366
Validation loss: 2.8734695673403525

Epoch: 6| Step: 6
Training loss: 2.7114366407158053
Validation loss: 2.8661482351010683

Epoch: 6| Step: 7
Training loss: 2.654276035836149
Validation loss: 2.8666200338072994

Epoch: 6| Step: 8
Training loss: 2.987284096294267
Validation loss: 2.8637232522748457

Epoch: 6| Step: 9
Training loss: 2.988667063023018
Validation loss: 2.8617197759510216

Epoch: 6| Step: 10
Training loss: 3.5939415922094353
Validation loss: 2.863869761678117

Epoch: 6| Step: 11
Training loss: 2.7339707429962687
Validation loss: 2.862437130476354

Epoch: 6| Step: 12
Training loss: 4.061534825625715
Validation loss: 2.862327559778281

Epoch: 6| Step: 13
Training loss: 3.649687265036329
Validation loss: 2.863169370173135

Epoch: 108| Step: 0
Training loss: 3.0691422035084077
Validation loss: 2.8620518478436847

Epoch: 6| Step: 1
Training loss: 3.2217502869556824
Validation loss: 2.861943421520419

Epoch: 6| Step: 2
Training loss: 3.3379217674271318
Validation loss: 2.8624503497180984

Epoch: 6| Step: 3
Training loss: 3.0887816637701784
Validation loss: 2.862372409047421

Epoch: 6| Step: 4
Training loss: 2.5671079190271935
Validation loss: 2.862072137965918

Epoch: 6| Step: 5
Training loss: 2.2262387759800166
Validation loss: 2.8617237167447658

Epoch: 6| Step: 6
Training loss: 2.257606470548088
Validation loss: 2.8600561894081005

Epoch: 6| Step: 7
Training loss: 3.8004931882745288
Validation loss: 2.8594129535091226

Epoch: 6| Step: 8
Training loss: 3.105950391354815
Validation loss: 2.858596198099057

Epoch: 6| Step: 9
Training loss: 3.7922327366642885
Validation loss: 2.8617143149103015

Epoch: 6| Step: 10
Training loss: 3.532445654535409
Validation loss: 2.8609896374978834

Epoch: 6| Step: 11
Training loss: 3.477047729919406
Validation loss: 2.8640749497928475

Epoch: 6| Step: 12
Training loss: 3.47277268857096
Validation loss: 2.858964611423007

Epoch: 6| Step: 13
Training loss: 2.574229308412053
Validation loss: 2.859477241652149

Epoch: 109| Step: 0
Training loss: 3.2751364293692324
Validation loss: 2.861671548043545

Epoch: 6| Step: 1
Training loss: 3.098397203607575
Validation loss: 2.8597631165847073

Epoch: 6| Step: 2
Training loss: 3.610763216785397
Validation loss: 2.8608807416844715

Epoch: 6| Step: 3
Training loss: 2.919609456269148
Validation loss: 2.8605393136601167

Epoch: 6| Step: 4
Training loss: 3.5100051382086983
Validation loss: 2.859438300994071

Epoch: 6| Step: 5
Training loss: 3.257497795145221
Validation loss: 2.858805670078494

Epoch: 6| Step: 6
Training loss: 3.374220016207218
Validation loss: 2.8580784271222246

Epoch: 6| Step: 7
Training loss: 2.6935091481879305
Validation loss: 2.860905812713255

Epoch: 6| Step: 8
Training loss: 2.995439878331272
Validation loss: 2.8567493607782373

Epoch: 6| Step: 9
Training loss: 2.881609409779081
Validation loss: 2.8600469568827873

Epoch: 6| Step: 10
Training loss: 2.989783055526974
Validation loss: 2.8559876709120395

Epoch: 6| Step: 11
Training loss: 3.144431620849893
Validation loss: 2.857745166876734

Epoch: 6| Step: 12
Training loss: 3.0709917321797224
Validation loss: 2.8586783454510596

Epoch: 6| Step: 13
Training loss: 3.351788706581806
Validation loss: 2.8574730070015906

Epoch: 110| Step: 0
Training loss: 3.553982910080813
Validation loss: 2.855591714567376

Epoch: 6| Step: 1
Training loss: 2.8797435603943646
Validation loss: 2.8556887169603167

Epoch: 6| Step: 2
Training loss: 2.769441546667435
Validation loss: 2.855855684681419

Epoch: 6| Step: 3
Training loss: 3.1155536547788203
Validation loss: 2.857511303367153

Epoch: 6| Step: 4
Training loss: 3.755616623070361
Validation loss: 2.8587325080521424

Epoch: 6| Step: 5
Training loss: 2.3395119560769406
Validation loss: 2.8558502519251467

Epoch: 6| Step: 6
Training loss: 4.122716560667203
Validation loss: 2.854965798391673

Epoch: 6| Step: 7
Training loss: 3.239717650414421
Validation loss: 2.8545227373587774

Epoch: 6| Step: 8
Training loss: 2.959645172966807
Validation loss: 2.8540881883936726

Epoch: 6| Step: 9
Training loss: 3.313549379357567
Validation loss: 2.8517588755840713

Epoch: 6| Step: 10
Training loss: 2.8393191518125627
Validation loss: 2.8532904374320847

Epoch: 6| Step: 11
Training loss: 2.8435365366204133
Validation loss: 2.853864043123415

Epoch: 6| Step: 12
Training loss: 2.5310343897791814
Validation loss: 2.851779620998512

Epoch: 6| Step: 13
Training loss: 3.6702430507411457
Validation loss: 2.8532596704206252

Epoch: 111| Step: 0
Training loss: 3.061840531325892
Validation loss: 2.8520110807569594

Epoch: 6| Step: 1
Training loss: 3.423675760033194
Validation loss: 2.8517681852838894

Epoch: 6| Step: 2
Training loss: 3.414888399906134
Validation loss: 2.8518501355808645

Epoch: 6| Step: 3
Training loss: 2.407673798464404
Validation loss: 2.8508755249582185

Epoch: 6| Step: 4
Training loss: 3.50163094803902
Validation loss: 2.8475081546238887

Epoch: 6| Step: 5
Training loss: 3.563207589533739
Validation loss: 2.849319912584083

Epoch: 6| Step: 6
Training loss: 3.456538795698233
Validation loss: 2.8511168572920953

Epoch: 6| Step: 7
Training loss: 3.25734057770448
Validation loss: 2.851002948077

Epoch: 6| Step: 8
Training loss: 2.9679789294705663
Validation loss: 2.8523012560435754

Epoch: 6| Step: 9
Training loss: 2.8894340742451936
Validation loss: 2.851831884354502

Epoch: 6| Step: 10
Training loss: 2.8099657296911245
Validation loss: 2.850834797780649

Epoch: 6| Step: 11
Training loss: 3.1973288593319262
Validation loss: 2.852766701587931

Epoch: 6| Step: 12
Training loss: 2.7374860231922375
Validation loss: 2.8500479638194807

Epoch: 6| Step: 13
Training loss: 3.332607206092566
Validation loss: 2.8486499250882034

Epoch: 112| Step: 0
Training loss: 3.8762067330955547
Validation loss: 2.8481040589096907

Epoch: 6| Step: 1
Training loss: 3.558245745495855
Validation loss: 2.8502268703238993

Epoch: 6| Step: 2
Training loss: 2.4483193140773287
Validation loss: 2.845590218914557

Epoch: 6| Step: 3
Training loss: 2.9800311526007897
Validation loss: 2.8474790447454064

Epoch: 6| Step: 4
Training loss: 3.274238870714096
Validation loss: 2.849922892598389

Epoch: 6| Step: 5
Training loss: 3.359128011450956
Validation loss: 2.8467846238428223

Epoch: 6| Step: 6
Training loss: 2.9672711353055488
Validation loss: 2.845601345217895

Epoch: 6| Step: 7
Training loss: 4.036169554522154
Validation loss: 2.8500900928597286

Epoch: 6| Step: 8
Training loss: 3.1653679309337157
Validation loss: 2.846014362457417

Epoch: 6| Step: 9
Training loss: 2.0386417583310306
Validation loss: 2.8487123475907197

Epoch: 6| Step: 10
Training loss: 2.7561837809040695
Validation loss: 2.8481859967212872

Epoch: 6| Step: 11
Training loss: 3.297847658561133
Validation loss: 2.849100941296431

Epoch: 6| Step: 12
Training loss: 2.9084426648012225
Validation loss: 2.848119804697325

Epoch: 6| Step: 13
Training loss: 2.6615421309346186
Validation loss: 2.8441637944560507

Epoch: 113| Step: 0
Training loss: 2.702746326184689
Validation loss: 2.8505291293414263

Epoch: 6| Step: 1
Training loss: 3.339364714595056
Validation loss: 2.846132506670306

Epoch: 6| Step: 2
Training loss: 2.7603398918175595
Validation loss: 2.846050861940278

Epoch: 6| Step: 3
Training loss: 3.641005467520498
Validation loss: 2.8451880986270504

Epoch: 6| Step: 4
Training loss: 2.3533260791475845
Validation loss: 2.8468909512008764

Epoch: 6| Step: 5
Training loss: 3.521057136841275
Validation loss: 2.846219850607161

Epoch: 6| Step: 6
Training loss: 3.2851158983290225
Validation loss: 2.8472137442708614

Epoch: 6| Step: 7
Training loss: 3.2654919756941303
Validation loss: 2.8464241782919193

Epoch: 6| Step: 8
Training loss: 3.6565992400479623
Validation loss: 2.850741356879296

Epoch: 6| Step: 9
Training loss: 3.1236105309438686
Validation loss: 2.8490855149654775

Epoch: 6| Step: 10
Training loss: 3.4835726921914842
Validation loss: 2.8490758617686236

Epoch: 6| Step: 11
Training loss: 3.0457899460178917
Validation loss: 2.8472423823540214

Epoch: 6| Step: 12
Training loss: 2.890662775566091
Validation loss: 2.845543318590281

Epoch: 6| Step: 13
Training loss: 2.2762125912755056
Validation loss: 2.853469646455966

Epoch: 114| Step: 0
Training loss: 3.6132487857494295
Validation loss: 2.8467863150546

Epoch: 6| Step: 1
Training loss: 2.875277132692206
Validation loss: 2.8468057648183582

Epoch: 6| Step: 2
Training loss: 3.3176491501029326
Validation loss: 2.8442034084395615

Epoch: 6| Step: 3
Training loss: 2.4001126978163416
Validation loss: 2.844302698312799

Epoch: 6| Step: 4
Training loss: 3.1706982764723617
Validation loss: 2.842706854307135

Epoch: 6| Step: 5
Training loss: 3.2300817034045664
Validation loss: 2.8435892868560293

Epoch: 6| Step: 6
Training loss: 3.3692580935137646
Validation loss: 2.844378766406981

Epoch: 6| Step: 7
Training loss: 2.841056638180608
Validation loss: 2.8437499621369993

Epoch: 6| Step: 8
Training loss: 2.877766480622114
Validation loss: 2.840806406024214

Epoch: 6| Step: 9
Training loss: 2.9408316690626344
Validation loss: 2.8404559547991903

Epoch: 6| Step: 10
Training loss: 3.2010839891268605
Validation loss: 2.842746081873211

Epoch: 6| Step: 11
Training loss: 3.987039191427274
Validation loss: 2.8399662004343202

Epoch: 6| Step: 12
Training loss: 3.0292754673647186
Validation loss: 2.83990423474345

Epoch: 6| Step: 13
Training loss: 2.7140338375706134
Validation loss: 2.838977782852254

Epoch: 115| Step: 0
Training loss: 2.888533541840715
Validation loss: 2.841463125280068

Epoch: 6| Step: 1
Training loss: 3.8425921425229737
Validation loss: 2.842190918777768

Epoch: 6| Step: 2
Training loss: 2.7423266079388458
Validation loss: 2.8402194626995634

Epoch: 6| Step: 3
Training loss: 3.5779872018191785
Validation loss: 2.8406124969961386

Epoch: 6| Step: 4
Training loss: 3.193589023183638
Validation loss: 2.841275613165492

Epoch: 6| Step: 5
Training loss: 2.3697060258642493
Validation loss: 2.8402892344160384

Epoch: 6| Step: 6
Training loss: 2.6499619499209897
Validation loss: 2.8389989449390938

Epoch: 6| Step: 7
Training loss: 2.724445472080617
Validation loss: 2.841853047627542

Epoch: 6| Step: 8
Training loss: 2.8684026237717304
Validation loss: 2.841050971387827

Epoch: 6| Step: 9
Training loss: 3.1184079642024343
Validation loss: 2.8409376295489053

Epoch: 6| Step: 10
Training loss: 3.4956807324123558
Validation loss: 2.841774310193076

Epoch: 6| Step: 11
Training loss: 3.392076735267334
Validation loss: 2.8389505432622744

Epoch: 6| Step: 12
Training loss: 3.5647590568625933
Validation loss: 2.8401722760097483

Epoch: 6| Step: 13
Training loss: 3.2779683005642983
Validation loss: 2.8392708097697126

Epoch: 116| Step: 0
Training loss: 3.5286966730751015
Validation loss: 2.8391108291195484

Epoch: 6| Step: 1
Training loss: 2.4513422811782504
Validation loss: 2.8388881905724928

Epoch: 6| Step: 2
Training loss: 2.762856169649872
Validation loss: 2.8383685261369673

Epoch: 6| Step: 3
Training loss: 3.1879469614247697
Validation loss: 2.84497132432984

Epoch: 6| Step: 4
Training loss: 3.0731210069550907
Validation loss: 2.8477559884330113

Epoch: 6| Step: 5
Training loss: 3.4285875785538096
Validation loss: 2.839633709834117

Epoch: 6| Step: 6
Training loss: 2.448368101225864
Validation loss: 2.838361009619848

Epoch: 6| Step: 7
Training loss: 3.2727026649474737
Validation loss: 2.838439470528518

Epoch: 6| Step: 8
Training loss: 2.953778552846813
Validation loss: 2.8381706152574915

Epoch: 6| Step: 9
Training loss: 3.3569081320057115
Validation loss: 2.8444281446397293

Epoch: 6| Step: 10
Training loss: 3.921126457605417
Validation loss: 2.838371704528449

Epoch: 6| Step: 11
Training loss: 3.2245583579303894
Validation loss: 2.836379423088463

Epoch: 6| Step: 12
Training loss: 3.1565772160790453
Validation loss: 2.841416995015386

Epoch: 6| Step: 13
Training loss: 2.679510349835258
Validation loss: 2.8401715909092378

Epoch: 117| Step: 0
Training loss: 3.4670961578563504
Validation loss: 2.844815815009848

Epoch: 6| Step: 1
Training loss: 3.082873404626774
Validation loss: 2.845080990371207

Epoch: 6| Step: 2
Training loss: 2.792962006247322
Validation loss: 2.83793349730129

Epoch: 6| Step: 3
Training loss: 2.9917358376273055
Validation loss: 2.8380225813410704

Epoch: 6| Step: 4
Training loss: 3.1113268989325897
Validation loss: 2.8341129184750757

Epoch: 6| Step: 5
Training loss: 3.2260534887166
Validation loss: 2.8350483859867706

Epoch: 6| Step: 6
Training loss: 2.868344772407675
Validation loss: 2.8358168156382337

Epoch: 6| Step: 7
Training loss: 2.9518907985389675
Validation loss: 2.8357400956820404

Epoch: 6| Step: 8
Training loss: 3.6066679608195225
Validation loss: 2.8362348027731628

Epoch: 6| Step: 9
Training loss: 3.403717779650766
Validation loss: 2.8377943729286144

Epoch: 6| Step: 10
Training loss: 2.3236440252524284
Validation loss: 2.838965838642538

Epoch: 6| Step: 11
Training loss: 3.815944179022669
Validation loss: 2.8370065789607852

Epoch: 6| Step: 12
Training loss: 2.6452426601503123
Validation loss: 2.839419970404324

Epoch: 6| Step: 13
Training loss: 3.5964081594662054
Validation loss: 2.8363592673262144

Epoch: 118| Step: 0
Training loss: 2.9966045874196894
Validation loss: 2.8357507941470015

Epoch: 6| Step: 1
Training loss: 2.5591957374179515
Validation loss: 2.83670663049666

Epoch: 6| Step: 2
Training loss: 3.3990020633791134
Validation loss: 2.837693663715494

Epoch: 6| Step: 3
Training loss: 3.0370856673612474
Validation loss: 2.837444942891227

Epoch: 6| Step: 4
Training loss: 3.519823475009372
Validation loss: 2.834535034168262

Epoch: 6| Step: 5
Training loss: 3.121822114635888
Validation loss: 2.8374522242143145

Epoch: 6| Step: 6
Training loss: 3.0020916322959184
Validation loss: 2.8348412334607094

Epoch: 6| Step: 7
Training loss: 2.1950275059673228
Validation loss: 2.834870744407715

Epoch: 6| Step: 8
Training loss: 3.3835483658080325
Validation loss: 2.835935831246015

Epoch: 6| Step: 9
Training loss: 3.362427074676792
Validation loss: 2.8343792027982504

Epoch: 6| Step: 10
Training loss: 2.4702909465044964
Validation loss: 2.837462496097443

Epoch: 6| Step: 11
Training loss: 3.586675430863839
Validation loss: 2.8450975782725845

Epoch: 6| Step: 12
Training loss: 3.222291794022192
Validation loss: 2.844880852948685

Epoch: 6| Step: 13
Training loss: 4.045325965903138
Validation loss: 2.845557104616212

Epoch: 119| Step: 0
Training loss: 3.0783517821756856
Validation loss: 2.8540464255706954

Epoch: 6| Step: 1
Training loss: 2.9595849161109378
Validation loss: 2.855444683464348

Epoch: 6| Step: 2
Training loss: 3.3321337130714173
Validation loss: 2.8734745760121507

Epoch: 6| Step: 3
Training loss: 2.570365650126048
Validation loss: 2.8428722119012773

Epoch: 6| Step: 4
Training loss: 3.6526089005942977
Validation loss: 2.8365818983027964

Epoch: 6| Step: 5
Training loss: 2.085030462101949
Validation loss: 2.8321320066820674

Epoch: 6| Step: 6
Training loss: 3.4418931112233735
Validation loss: 2.8319964663102466

Epoch: 6| Step: 7
Training loss: 3.008594599515428
Validation loss: 2.829642444017537

Epoch: 6| Step: 8
Training loss: 3.695056478974645
Validation loss: 2.828714037781301

Epoch: 6| Step: 9
Training loss: 3.0795792760466574
Validation loss: 2.8295056319089547

Epoch: 6| Step: 10
Training loss: 3.3439972688034074
Validation loss: 2.8314322102067075

Epoch: 6| Step: 11
Training loss: 2.7478796847739546
Validation loss: 2.829579582699365

Epoch: 6| Step: 12
Training loss: 3.7143379773665486
Validation loss: 2.8317800301940137

Epoch: 6| Step: 13
Training loss: 2.5176339036016926
Validation loss: 2.831572894782872

Epoch: 120| Step: 0
Training loss: 3.3737592889093246
Validation loss: 2.8318480218292414

Epoch: 6| Step: 1
Training loss: 2.859245589199268
Validation loss: 2.8284466554377206

Epoch: 6| Step: 2
Training loss: 3.7095232708164154
Validation loss: 2.8299515742164134

Epoch: 6| Step: 3
Training loss: 3.8321066566070816
Validation loss: 2.8298046975537887

Epoch: 6| Step: 4
Training loss: 2.527850375920373
Validation loss: 2.831152046144618

Epoch: 6| Step: 5
Training loss: 2.177446751781095
Validation loss: 2.8347609564873673

Epoch: 6| Step: 6
Training loss: 2.6828016864112114
Validation loss: 2.8412186134397497

Epoch: 6| Step: 7
Training loss: 2.976019381736892
Validation loss: 2.8446459895185114

Epoch: 6| Step: 8
Training loss: 3.4584825475896825
Validation loss: 2.8494738814418623

Epoch: 6| Step: 9
Training loss: 3.1647842902608443
Validation loss: 2.8580266906123004

Epoch: 6| Step: 10
Training loss: 3.231801654054955
Validation loss: 2.862212088149065

Epoch: 6| Step: 11
Training loss: 3.2368255030443334
Validation loss: 2.8412834215299716

Epoch: 6| Step: 12
Training loss: 3.1996274135166347
Validation loss: 2.835231663223513

Epoch: 6| Step: 13
Training loss: 3.1518348557251015
Validation loss: 2.830707222157385

Epoch: 121| Step: 0
Training loss: 3.6547350230884397
Validation loss: 2.8315713610740207

Epoch: 6| Step: 1
Training loss: 2.5799262025909635
Validation loss: 2.8312670166008425

Epoch: 6| Step: 2
Training loss: 3.4746859511481674
Validation loss: 2.8337491838383904

Epoch: 6| Step: 3
Training loss: 2.8027302918088726
Validation loss: 2.835025769275179

Epoch: 6| Step: 4
Training loss: 2.881191221618202
Validation loss: 2.83471543070658

Epoch: 6| Step: 5
Training loss: 3.275864168259905
Validation loss: 2.8357627491863417

Epoch: 6| Step: 6
Training loss: 2.7855511956454886
Validation loss: 2.836780605036659

Epoch: 6| Step: 7
Training loss: 3.511042477812802
Validation loss: 2.836275669999273

Epoch: 6| Step: 8
Training loss: 2.9830936257442633
Validation loss: 2.8353374337552286

Epoch: 6| Step: 9
Training loss: 2.5000053405704676
Validation loss: 2.834139025922927

Epoch: 6| Step: 10
Training loss: 3.1862817567998944
Validation loss: 2.8332815895446797

Epoch: 6| Step: 11
Training loss: 3.678949302280476
Validation loss: 2.832901133291828

Epoch: 6| Step: 12
Training loss: 3.808398056871487
Validation loss: 2.83185719601229

Epoch: 6| Step: 13
Training loss: 1.802955291536487
Validation loss: 2.831325294163318

Epoch: 122| Step: 0
Training loss: 2.937668004202905
Validation loss: 2.8305214320595784

Epoch: 6| Step: 1
Training loss: 2.5593472135756516
Validation loss: 2.8306832856273387

Epoch: 6| Step: 2
Training loss: 2.3060807494213127
Validation loss: 2.8291638517863382

Epoch: 6| Step: 3
Training loss: 3.672192369097008
Validation loss: 2.8294251908680486

Epoch: 6| Step: 4
Training loss: 2.929702148400879
Validation loss: 2.8291852839132208

Epoch: 6| Step: 5
Training loss: 3.223120971464133
Validation loss: 2.829545267185343

Epoch: 6| Step: 6
Training loss: 3.272616700028834
Validation loss: 2.82931397656056

Epoch: 6| Step: 7
Training loss: 2.7878635939145098
Validation loss: 2.829376790321105

Epoch: 6| Step: 8
Training loss: 3.508590102294711
Validation loss: 2.8271730894883893

Epoch: 6| Step: 9
Training loss: 3.273709306380251
Validation loss: 2.828157972135565

Epoch: 6| Step: 10
Training loss: 2.9997587106945276
Validation loss: 2.8275291936136204

Epoch: 6| Step: 11
Training loss: 3.002278416419314
Validation loss: 2.828265154754865

Epoch: 6| Step: 12
Training loss: 3.6976964893968454
Validation loss: 2.8274033783325443

Epoch: 6| Step: 13
Training loss: 3.6515360382779702
Validation loss: 2.827573466951661

Epoch: 123| Step: 0
Training loss: 3.4647742504215593
Validation loss: 2.8265129874682615

Epoch: 6| Step: 1
Training loss: 3.4214452186222717
Validation loss: 2.829830187946021

Epoch: 6| Step: 2
Training loss: 2.7198203599736774
Validation loss: 2.8301837131213916

Epoch: 6| Step: 3
Training loss: 3.1977091337743078
Validation loss: 2.8301460216469225

Epoch: 6| Step: 4
Training loss: 3.221177010173701
Validation loss: 2.82939433378024

Epoch: 6| Step: 5
Training loss: 2.390302449326313
Validation loss: 2.8274603428482274

Epoch: 6| Step: 6
Training loss: 3.205967976620206
Validation loss: 2.829058218351504

Epoch: 6| Step: 7
Training loss: 2.7759364086090144
Validation loss: 2.8315305771512422

Epoch: 6| Step: 8
Training loss: 3.5701201739774286
Validation loss: 2.825968242071355

Epoch: 6| Step: 9
Training loss: 2.813353514968054
Validation loss: 2.8305339385727275

Epoch: 6| Step: 10
Training loss: 2.615352704858943
Validation loss: 2.8259283225713308

Epoch: 6| Step: 11
Training loss: 2.985062924333664
Validation loss: 2.8252396196892526

Epoch: 6| Step: 12
Training loss: 3.343815027478087
Validation loss: 2.8232122744101544

Epoch: 6| Step: 13
Training loss: 4.19726312565363
Validation loss: 2.825267434282049

Epoch: 124| Step: 0
Training loss: 2.9398223138170114
Validation loss: 2.8232034535204664

Epoch: 6| Step: 1
Training loss: 3.6777660107176264
Validation loss: 2.8213638038324294

Epoch: 6| Step: 2
Training loss: 3.4310334851268958
Validation loss: 2.824249480274664

Epoch: 6| Step: 3
Training loss: 3.135938801596485
Validation loss: 2.821666485347097

Epoch: 6| Step: 4
Training loss: 3.168325458204451
Validation loss: 2.822387835279447

Epoch: 6| Step: 5
Training loss: 2.9415508503218666
Validation loss: 2.82158149142462

Epoch: 6| Step: 6
Training loss: 3.2612630377289906
Validation loss: 2.822692466841291

Epoch: 6| Step: 7
Training loss: 3.1505174605396236
Validation loss: 2.824048223305629

Epoch: 6| Step: 8
Training loss: 2.5531964631742365
Validation loss: 2.8222010678376535

Epoch: 6| Step: 9
Training loss: 3.1348094331051075
Validation loss: 2.8235978349566175

Epoch: 6| Step: 10
Training loss: 3.4323614380632916
Validation loss: 2.8225801334878717

Epoch: 6| Step: 11
Training loss: 2.4900128194946225
Validation loss: 2.824367086251769

Epoch: 6| Step: 12
Training loss: 3.0683194357581276
Validation loss: 2.821495938872283

Epoch: 6| Step: 13
Training loss: 3.2389660376958522
Validation loss: 2.824661671522129

Epoch: 125| Step: 0
Training loss: 2.546146124704627
Validation loss: 2.8269199488773156

Epoch: 6| Step: 1
Training loss: 3.4868965091647044
Validation loss: 2.823768336192838

Epoch: 6| Step: 2
Training loss: 3.463651604688276
Validation loss: 2.82548168721005

Epoch: 6| Step: 3
Training loss: 3.203116068013461
Validation loss: 2.826133299099263

Epoch: 6| Step: 4
Training loss: 3.5922383985526536
Validation loss: 2.824090852313453

Epoch: 6| Step: 5
Training loss: 3.191654415123701
Validation loss: 2.8190172239070446

Epoch: 6| Step: 6
Training loss: 3.0286649712668305
Validation loss: 2.820014687689498

Epoch: 6| Step: 7
Training loss: 3.093721331839238
Validation loss: 2.8211338125710275

Epoch: 6| Step: 8
Training loss: 2.311954124563131
Validation loss: 2.819903566802854

Epoch: 6| Step: 9
Training loss: 2.8936942636877205
Validation loss: 2.8189374402953105

Epoch: 6| Step: 10
Training loss: 2.8878913118827807
Validation loss: 2.820702891276058

Epoch: 6| Step: 11
Training loss: 2.7765063003751584
Validation loss: 2.8180412678230264

Epoch: 6| Step: 12
Training loss: 3.7254972394831385
Validation loss: 2.821505023144728

Epoch: 6| Step: 13
Training loss: 3.442555957525007
Validation loss: 2.8190695508356858

Epoch: 126| Step: 0
Training loss: 2.8654310786901913
Validation loss: 2.8184115540518953

Epoch: 6| Step: 1
Training loss: 3.0931431338876494
Validation loss: 2.818127173599267

Epoch: 6| Step: 2
Training loss: 3.0394955206447554
Validation loss: 2.821278312829965

Epoch: 6| Step: 3
Training loss: 2.8351975833994465
Validation loss: 2.8189015792225876

Epoch: 6| Step: 4
Training loss: 3.458993059833465
Validation loss: 2.820969124611343

Epoch: 6| Step: 5
Training loss: 3.5250870930619396
Validation loss: 2.823430149084168

Epoch: 6| Step: 6
Training loss: 3.8687882626417776
Validation loss: 2.8227489651536284

Epoch: 6| Step: 7
Training loss: 3.2847270163531777
Validation loss: 2.818596808989226

Epoch: 6| Step: 8
Training loss: 3.0238114157814886
Validation loss: 2.826182129827408

Epoch: 6| Step: 9
Training loss: 3.5977534012822487
Validation loss: 2.818344227030365

Epoch: 6| Step: 10
Training loss: 2.857750770064834
Validation loss: 2.8184362315216753

Epoch: 6| Step: 11
Training loss: 3.157083533481167
Validation loss: 2.816581293384895

Epoch: 6| Step: 12
Training loss: 2.2233104849141294
Validation loss: 2.820048463731224

Epoch: 6| Step: 13
Training loss: 1.8009262192104913
Validation loss: 2.8180490059273455

Epoch: 127| Step: 0
Training loss: 3.3758863062403526
Validation loss: 2.822420596494131

Epoch: 6| Step: 1
Training loss: 3.65289282929829
Validation loss: 2.8207779189749407

Epoch: 6| Step: 2
Training loss: 3.1771081308533202
Validation loss: 2.8260458133259885

Epoch: 6| Step: 3
Training loss: 3.2867574339037082
Validation loss: 2.8280322709464727

Epoch: 6| Step: 4
Training loss: 3.601559322463349
Validation loss: 2.8242027538583354

Epoch: 6| Step: 5
Training loss: 2.533477556573787
Validation loss: 2.8261218294569845

Epoch: 6| Step: 6
Training loss: 3.128808714147697
Validation loss: 2.824004776177627

Epoch: 6| Step: 7
Training loss: 3.1524090955123114
Validation loss: 2.828007556645734

Epoch: 6| Step: 8
Training loss: 2.967445167092755
Validation loss: 2.832434818196394

Epoch: 6| Step: 9
Training loss: 2.851299116956674
Validation loss: 2.8360487564877936

Epoch: 6| Step: 10
Training loss: 3.2340232178674992
Validation loss: 2.8381403157328453

Epoch: 6| Step: 11
Training loss: 2.8540969246095895
Validation loss: 2.82520044668151

Epoch: 6| Step: 12
Training loss: 2.183090779855107
Validation loss: 2.815005069383417

Epoch: 6| Step: 13
Training loss: 3.6311914908706733
Validation loss: 2.811092150135398

Epoch: 128| Step: 0
Training loss: 2.9127591979641414
Validation loss: 2.8119116857163333

Epoch: 6| Step: 1
Training loss: 3.2267265370491907
Validation loss: 2.8108637891604715

Epoch: 6| Step: 2
Training loss: 3.5539423905717618
Validation loss: 2.8125118542493164

Epoch: 6| Step: 3
Training loss: 3.0836698674930445
Validation loss: 2.813750691950644

Epoch: 6| Step: 4
Training loss: 3.4385876408765936
Validation loss: 2.8121632674069716

Epoch: 6| Step: 5
Training loss: 3.4068209668306055
Validation loss: 2.815461753885779

Epoch: 6| Step: 6
Training loss: 2.7149324471234726
Validation loss: 2.8158999621429217

Epoch: 6| Step: 7
Training loss: 3.060548744614936
Validation loss: 2.8140906699815744

Epoch: 6| Step: 8
Training loss: 2.850742337104249
Validation loss: 2.815911515299413

Epoch: 6| Step: 9
Training loss: 2.9031774214332517
Validation loss: 2.8143973163989044

Epoch: 6| Step: 10
Training loss: 2.9269454941700377
Validation loss: 2.812437376284514

Epoch: 6| Step: 11
Training loss: 3.4289251014537188
Validation loss: 2.8134280060403976

Epoch: 6| Step: 12
Training loss: 3.298015379176419
Validation loss: 2.81336997556169

Epoch: 6| Step: 13
Training loss: 2.5699242759562333
Validation loss: 2.813848170993452

Epoch: 129| Step: 0
Training loss: 3.1765542678989034
Validation loss: 2.8125542219579853

Epoch: 6| Step: 1
Training loss: 2.592764058069193
Validation loss: 2.811233310007106

Epoch: 6| Step: 2
Training loss: 3.580419612566491
Validation loss: 2.8116304117452087

Epoch: 6| Step: 3
Training loss: 3.1650230927551446
Validation loss: 2.8120895906665733

Epoch: 6| Step: 4
Training loss: 3.052961481375534
Validation loss: 2.810661217987297

Epoch: 6| Step: 5
Training loss: 3.3954830964192486
Validation loss: 2.810050106986387

Epoch: 6| Step: 6
Training loss: 2.526348690500512
Validation loss: 2.8088585654868385

Epoch: 6| Step: 7
Training loss: 3.48951294481637
Validation loss: 2.8104128742182546

Epoch: 6| Step: 8
Training loss: 3.261028797021339
Validation loss: 2.8102985457567913

Epoch: 6| Step: 9
Training loss: 3.1716155148054885
Validation loss: 2.8160874360669417

Epoch: 6| Step: 10
Training loss: 2.9724730586827404
Validation loss: 2.8182141683593

Epoch: 6| Step: 11
Training loss: 2.4824493430694132
Validation loss: 2.827505528477148

Epoch: 6| Step: 12
Training loss: 3.2271686566481383
Validation loss: 2.840704199009088

Epoch: 6| Step: 13
Training loss: 3.6122608620449084
Validation loss: 2.8218117323783023

Epoch: 130| Step: 0
Training loss: 2.9805525821680043
Validation loss: 2.813673203583258

Epoch: 6| Step: 1
Training loss: 3.285800067895434
Validation loss: 2.810270968887149

Epoch: 6| Step: 2
Training loss: 3.5370624608636447
Validation loss: 2.808944767612483

Epoch: 6| Step: 3
Training loss: 3.4206847467960113
Validation loss: 2.8083408124353135

Epoch: 6| Step: 4
Training loss: 2.3187030386474903
Validation loss: 2.809056604924823

Epoch: 6| Step: 5
Training loss: 3.4263329578197443
Validation loss: 2.8090775479723558

Epoch: 6| Step: 6
Training loss: 2.8566384483317635
Validation loss: 2.8067552001926463

Epoch: 6| Step: 7
Training loss: 3.4675151929680648
Validation loss: 2.809830599036576

Epoch: 6| Step: 8
Training loss: 2.603803156595348
Validation loss: 2.806754392762541

Epoch: 6| Step: 9
Training loss: 4.076227323907119
Validation loss: 2.8073852847336904

Epoch: 6| Step: 10
Training loss: 2.2703821159763318
Validation loss: 2.8068373175441454

Epoch: 6| Step: 11
Training loss: 2.7432089096102645
Validation loss: 2.8118718037058787

Epoch: 6| Step: 12
Training loss: 3.268865264552495
Validation loss: 2.8105876095043305

Epoch: 6| Step: 13
Training loss: 2.6186775179280115
Validation loss: 2.8097950733694788

Epoch: 131| Step: 0
Training loss: 2.9956519088316518
Validation loss: 2.8137291240363704

Epoch: 6| Step: 1
Training loss: 3.843512799147029
Validation loss: 2.8096200415199593

Epoch: 6| Step: 2
Training loss: 3.4605919383424424
Validation loss: 2.8078529496471845

Epoch: 6| Step: 3
Training loss: 2.8777421230658726
Validation loss: 2.8077734477612335

Epoch: 6| Step: 4
Training loss: 2.78895923412644
Validation loss: 2.806650442416991

Epoch: 6| Step: 5
Training loss: 2.991322683749687
Validation loss: 2.8068056403658184

Epoch: 6| Step: 6
Training loss: 3.535028242459711
Validation loss: 2.805513284441198

Epoch: 6| Step: 7
Training loss: 3.604272712220541
Validation loss: 2.807243269280325

Epoch: 6| Step: 8
Training loss: 3.2790176790766568
Validation loss: 2.804009938342553

Epoch: 6| Step: 9
Training loss: 1.646830132179069
Validation loss: 2.8065801614498627

Epoch: 6| Step: 10
Training loss: 3.180337375522219
Validation loss: 2.803688774813225

Epoch: 6| Step: 11
Training loss: 3.2850884647157224
Validation loss: 2.8028698578355478

Epoch: 6| Step: 12
Training loss: 2.7794965724549945
Validation loss: 2.8025327841170764

Epoch: 6| Step: 13
Training loss: 2.5347480621646525
Validation loss: 2.802528916515546

Epoch: 132| Step: 0
Training loss: 3.5818802896386357
Validation loss: 2.803131612518245

Epoch: 6| Step: 1
Training loss: 2.8191487032454927
Validation loss: 2.806902932244883

Epoch: 6| Step: 2
Training loss: 3.2937846230817085
Validation loss: 2.801313698426982

Epoch: 6| Step: 3
Training loss: 3.3942977772306153
Validation loss: 2.8008686590420155

Epoch: 6| Step: 4
Training loss: 2.5610734643971194
Validation loss: 2.800192861316732

Epoch: 6| Step: 5
Training loss: 2.369741340074875
Validation loss: 2.8000461559183067

Epoch: 6| Step: 6
Training loss: 3.781605475244337
Validation loss: 2.7991830808976936

Epoch: 6| Step: 7
Training loss: 3.3694072584710653
Validation loss: 2.8007868811078684

Epoch: 6| Step: 8
Training loss: 3.4258330285781975
Validation loss: 2.802830926467568

Epoch: 6| Step: 9
Training loss: 3.537120699008654
Validation loss: 2.8002264077051913

Epoch: 6| Step: 10
Training loss: 2.315016743082424
Validation loss: 2.80193475915754

Epoch: 6| Step: 11
Training loss: 2.856206253351135
Validation loss: 2.8022330712579713

Epoch: 6| Step: 12
Training loss: 2.9929405440094508
Validation loss: 2.8003787117871917

Epoch: 6| Step: 13
Training loss: 2.689632988748885
Validation loss: 2.7985702274577373

Epoch: 133| Step: 0
Training loss: 3.0365948305590633
Validation loss: 2.7983389125045885

Epoch: 6| Step: 1
Training loss: 3.685088063899734
Validation loss: 2.800732075265294

Epoch: 6| Step: 2
Training loss: 3.4508203609185566
Validation loss: 2.7982775000104336

Epoch: 6| Step: 3
Training loss: 3.288707288104409
Validation loss: 2.8051483856945123

Epoch: 6| Step: 4
Training loss: 3.1237155563452195
Validation loss: 2.8063996783085643

Epoch: 6| Step: 5
Training loss: 2.6277796242805787
Validation loss: 2.8150062869964243

Epoch: 6| Step: 6
Training loss: 3.574430465681449
Validation loss: 2.8107610561030905

Epoch: 6| Step: 7
Training loss: 2.9653972767423817
Validation loss: 2.8063004396067113

Epoch: 6| Step: 8
Training loss: 2.763133505424381
Validation loss: 2.8017541341513312

Epoch: 6| Step: 9
Training loss: 2.848319940448105
Validation loss: 2.799827771852243

Epoch: 6| Step: 10
Training loss: 3.001217436131209
Validation loss: 2.796503796408807

Epoch: 6| Step: 11
Training loss: 3.412539773227181
Validation loss: 2.798989896990437

Epoch: 6| Step: 12
Training loss: 2.5195004010344966
Validation loss: 2.798044720550941

Epoch: 6| Step: 13
Training loss: 2.932826768599581
Validation loss: 2.795994698727431

Epoch: 134| Step: 0
Training loss: 2.091606523274769
Validation loss: 2.7991413616442182

Epoch: 6| Step: 1
Training loss: 3.18025731035377
Validation loss: 2.801170893755882

Epoch: 6| Step: 2
Training loss: 3.4953808958125756
Validation loss: 2.797187702908675

Epoch: 6| Step: 3
Training loss: 3.1518791830173916
Validation loss: 2.7947776539778326

Epoch: 6| Step: 4
Training loss: 2.5851955674825353
Validation loss: 2.792597761584265

Epoch: 6| Step: 5
Training loss: 3.052589730358413
Validation loss: 2.794304741955492

Epoch: 6| Step: 6
Training loss: 2.853213148646004
Validation loss: 2.79591405000818

Epoch: 6| Step: 7
Training loss: 3.220080054573384
Validation loss: 2.796978134478347

Epoch: 6| Step: 8
Training loss: 2.891430386904034
Validation loss: 2.795288289396898

Epoch: 6| Step: 9
Training loss: 3.188240414063251
Validation loss: 2.7948513009340092

Epoch: 6| Step: 10
Training loss: 3.453421049243688
Validation loss: 2.794496602117661

Epoch: 6| Step: 11
Training loss: 3.069294146678987
Validation loss: 2.7946309229969626

Epoch: 6| Step: 12
Training loss: 3.1682623975245283
Validation loss: 2.798029025559746

Epoch: 6| Step: 13
Training loss: 4.252425679628817
Validation loss: 2.7933311584680145

Epoch: 135| Step: 0
Training loss: 2.668262203046039
Validation loss: 2.7942669160685827

Epoch: 6| Step: 1
Training loss: 3.4014214405395444
Validation loss: 2.79370240278786

Epoch: 6| Step: 2
Training loss: 2.9540571729619467
Validation loss: 2.7980464467197304

Epoch: 6| Step: 3
Training loss: 3.4217409429897843
Validation loss: 2.797685063251463

Epoch: 6| Step: 4
Training loss: 2.959682712045574
Validation loss: 2.796380768454522

Epoch: 6| Step: 5
Training loss: 2.770320118195999
Validation loss: 2.796100492030655

Epoch: 6| Step: 6
Training loss: 3.1173401606375943
Validation loss: 2.7966907115339064

Epoch: 6| Step: 7
Training loss: 3.1169823600556277
Validation loss: 2.7945250584643

Epoch: 6| Step: 8
Training loss: 3.3791176437666444
Validation loss: 2.793371091352462

Epoch: 6| Step: 9
Training loss: 2.767726638459669
Validation loss: 2.795819221039046

Epoch: 6| Step: 10
Training loss: 3.264929446382564
Validation loss: 2.7939779741338056

Epoch: 6| Step: 11
Training loss: 3.435709261458609
Validation loss: 2.796928538615894

Epoch: 6| Step: 12
Training loss: 3.3747547201814116
Validation loss: 2.797290127963811

Epoch: 6| Step: 13
Training loss: 2.2933900306405803
Validation loss: 2.7925351932584097

Epoch: 136| Step: 0
Training loss: 2.768498969484523
Validation loss: 2.7941084553681574

Epoch: 6| Step: 1
Training loss: 2.9637383170603506
Validation loss: 2.798676745987933

Epoch: 6| Step: 2
Training loss: 2.9400477622168335
Validation loss: 2.7975601270998873

Epoch: 6| Step: 3
Training loss: 3.5447580346951937
Validation loss: 2.796007546266116

Epoch: 6| Step: 4
Training loss: 2.8993000895942944
Validation loss: 2.794385354552659

Epoch: 6| Step: 5
Training loss: 3.2769721346785907
Validation loss: 2.7969604990586974

Epoch: 6| Step: 6
Training loss: 3.1669001911457064
Validation loss: 2.7935789981789427

Epoch: 6| Step: 7
Training loss: 3.2332056852752036
Validation loss: 2.7908265311778613

Epoch: 6| Step: 8
Training loss: 2.9547000297712414
Validation loss: 2.7900793833926327

Epoch: 6| Step: 9
Training loss: 3.445372289022035
Validation loss: 2.7937677552116287

Epoch: 6| Step: 10
Training loss: 2.639355506689491
Validation loss: 2.789353417050349

Epoch: 6| Step: 11
Training loss: 3.327626222298651
Validation loss: 2.794156497954569

Epoch: 6| Step: 12
Training loss: 3.172867342556558
Validation loss: 2.789248804414714

Epoch: 6| Step: 13
Training loss: 2.9159928951412346
Validation loss: 2.7930381178264176

Epoch: 137| Step: 0
Training loss: 2.6384917902960616
Validation loss: 2.78989119280029

Epoch: 6| Step: 1
Training loss: 3.18152372310558
Validation loss: 2.792283446589644

Epoch: 6| Step: 2
Training loss: 3.1481706302646213
Validation loss: 2.788772687903123

Epoch: 6| Step: 3
Training loss: 2.646201751370038
Validation loss: 2.7906122265661324

Epoch: 6| Step: 4
Training loss: 2.3284365042363198
Validation loss: 2.795228465333274

Epoch: 6| Step: 5
Training loss: 3.111657919589639
Validation loss: 2.7920888212096404

Epoch: 6| Step: 6
Training loss: 3.0183355769614764
Validation loss: 2.7936003619298257

Epoch: 6| Step: 7
Training loss: 3.0885970232389415
Validation loss: 2.793625617380094

Epoch: 6| Step: 8
Training loss: 2.351875664525644
Validation loss: 2.7891003514303656

Epoch: 6| Step: 9
Training loss: 3.7658444415848265
Validation loss: 2.7885000667655895

Epoch: 6| Step: 10
Training loss: 3.6838749022807895
Validation loss: 2.7868556364544563

Epoch: 6| Step: 11
Training loss: 3.2555740679958474
Validation loss: 2.7851088400931334

Epoch: 6| Step: 12
Training loss: 3.4563190308449476
Validation loss: 2.7858682901119556

Epoch: 6| Step: 13
Training loss: 3.5201225842458492
Validation loss: 2.783652691544632

Epoch: 138| Step: 0
Training loss: 2.784924769044629
Validation loss: 2.785216112760158

Epoch: 6| Step: 1
Training loss: 2.8209063890050987
Validation loss: 2.787558670232161

Epoch: 6| Step: 2
Training loss: 3.0116145688652405
Validation loss: 2.784348798063015

Epoch: 6| Step: 3
Training loss: 3.558343436757618
Validation loss: 2.7849821035017377

Epoch: 6| Step: 4
Training loss: 2.623134676897488
Validation loss: 2.7853269414409225

Epoch: 6| Step: 5
Training loss: 3.0962024562790713
Validation loss: 2.786744237490262

Epoch: 6| Step: 6
Training loss: 3.3187467585833392
Validation loss: 2.7848163887467345

Epoch: 6| Step: 7
Training loss: 3.131054163612644
Validation loss: 2.7859526813214384

Epoch: 6| Step: 8
Training loss: 3.360299484439158
Validation loss: 2.785776287640298

Epoch: 6| Step: 9
Training loss: 3.309642494925074
Validation loss: 2.784518305294586

Epoch: 6| Step: 10
Training loss: 3.8829247441176924
Validation loss: 2.784883740178759

Epoch: 6| Step: 11
Training loss: 2.7921786811403297
Validation loss: 2.786435580608746

Epoch: 6| Step: 12
Training loss: 2.8607344600645788
Validation loss: 2.7869956313421165

Epoch: 6| Step: 13
Training loss: 2.1227682399305308
Validation loss: 2.792567837877021

Epoch: 139| Step: 0
Training loss: 3.152703133556955
Validation loss: 2.7915818671869586

Epoch: 6| Step: 1
Training loss: 3.5220581873560906
Validation loss: 2.7929281541435667

Epoch: 6| Step: 2
Training loss: 3.7274669133540175
Validation loss: 2.794081245366079

Epoch: 6| Step: 3
Training loss: 3.4313799390526274
Validation loss: 2.8026865215288823

Epoch: 6| Step: 4
Training loss: 3.2486689849768005
Validation loss: 2.7882402682811875

Epoch: 6| Step: 5
Training loss: 2.6552856489926997
Validation loss: 2.7845721689536784

Epoch: 6| Step: 6
Training loss: 2.611083607720432
Validation loss: 2.785132494521404

Epoch: 6| Step: 7
Training loss: 3.078929815272353
Validation loss: 2.7863968755097055

Epoch: 6| Step: 8
Training loss: 2.1402364781998244
Validation loss: 2.7812613634147203

Epoch: 6| Step: 9
Training loss: 3.102636040987088
Validation loss: 2.7835740834950573

Epoch: 6| Step: 10
Training loss: 2.964050749824331
Validation loss: 2.7798789519713165

Epoch: 6| Step: 11
Training loss: 3.67544849280057
Validation loss: 2.779232302127095

Epoch: 6| Step: 12
Training loss: 3.041365273231699
Validation loss: 2.7812713589043434

Epoch: 6| Step: 13
Training loss: 2.3041746441758786
Validation loss: 2.7801457022074794

Epoch: 140| Step: 0
Training loss: 2.8977095931494703
Validation loss: 2.782722384821639

Epoch: 6| Step: 1
Training loss: 3.442210212871545
Validation loss: 2.7834668488581653

Epoch: 6| Step: 2
Training loss: 2.381389255406726
Validation loss: 2.781687185159366

Epoch: 6| Step: 3
Training loss: 2.8976225414151324
Validation loss: 2.7798328114252833

Epoch: 6| Step: 4
Training loss: 2.9045096488131743
Validation loss: 2.7807186458397464

Epoch: 6| Step: 5
Training loss: 2.847839768177775
Validation loss: 2.7826671356685133

Epoch: 6| Step: 6
Training loss: 3.4541184045037516
Validation loss: 2.780787266426613

Epoch: 6| Step: 7
Training loss: 3.3583503047492202
Validation loss: 2.78027537018361

Epoch: 6| Step: 8
Training loss: 3.232235998243297
Validation loss: 2.7806541760521233

Epoch: 6| Step: 9
Training loss: 3.7074479892861234
Validation loss: 2.7793631444825055

Epoch: 6| Step: 10
Training loss: 2.803843931885753
Validation loss: 2.780678285095446

Epoch: 6| Step: 11
Training loss: 2.9380564061223606
Validation loss: 2.7805238895620272

Epoch: 6| Step: 12
Training loss: 3.1575192458290355
Validation loss: 2.780715629268213

Epoch: 6| Step: 13
Training loss: 3.071281454928972
Validation loss: 2.7836089859898925

Epoch: 141| Step: 0
Training loss: 3.350320368009355
Validation loss: 2.7836841155396783

Epoch: 6| Step: 1
Training loss: 3.492522562837456
Validation loss: 2.7856042616639027

Epoch: 6| Step: 2
Training loss: 2.988856281479237
Validation loss: 2.782859443496657

Epoch: 6| Step: 3
Training loss: 3.302944580463216
Validation loss: 2.783284986666914

Epoch: 6| Step: 4
Training loss: 3.1815168287571636
Validation loss: 2.7822364421073837

Epoch: 6| Step: 5
Training loss: 1.963408657058231
Validation loss: 2.7828950062524296

Epoch: 6| Step: 6
Training loss: 2.902333235176108
Validation loss: 2.7834645628748875

Epoch: 6| Step: 7
Training loss: 2.852063445938432
Validation loss: 2.7834537058102238

Epoch: 6| Step: 8
Training loss: 3.504886893979234
Validation loss: 2.7794440207191378

Epoch: 6| Step: 9
Training loss: 3.40959828849259
Validation loss: 2.7838032289778516

Epoch: 6| Step: 10
Training loss: 2.904735868070768
Validation loss: 2.7817856191190993

Epoch: 6| Step: 11
Training loss: 2.996782484804406
Validation loss: 2.778075663751872

Epoch: 6| Step: 12
Training loss: 3.2251990441694787
Validation loss: 2.779541882956395

Epoch: 6| Step: 13
Training loss: 2.955658809591909
Validation loss: 2.7782261342701635

Epoch: 142| Step: 0
Training loss: 3.6520982955623222
Validation loss: 2.7789665583185204

Epoch: 6| Step: 1
Training loss: 3.1622695175438342
Validation loss: 2.7808619089368287

Epoch: 6| Step: 2
Training loss: 3.0258249718471664
Validation loss: 2.7814681882538057

Epoch: 6| Step: 3
Training loss: 3.693633070900678
Validation loss: 2.7849657485180357

Epoch: 6| Step: 4
Training loss: 2.456320072950846
Validation loss: 2.7925654969181832

Epoch: 6| Step: 5
Training loss: 2.6810926306721266
Validation loss: 2.7934368447776348

Epoch: 6| Step: 6
Training loss: 3.4237664277545057
Validation loss: 2.798163079755486

Epoch: 6| Step: 7
Training loss: 2.8260431372393446
Validation loss: 2.7856187492659266

Epoch: 6| Step: 8
Training loss: 2.581319598351868
Validation loss: 2.7862114136878513

Epoch: 6| Step: 9
Training loss: 2.939368607329373
Validation loss: 2.7865511783975214

Epoch: 6| Step: 10
Training loss: 3.302359841178711
Validation loss: 2.779638951343528

Epoch: 6| Step: 11
Training loss: 2.4449015994251346
Validation loss: 2.7809833529218726

Epoch: 6| Step: 12
Training loss: 3.489562137975898
Validation loss: 2.77722180439192

Epoch: 6| Step: 13
Training loss: 3.4709943779031893
Validation loss: 2.7785067485372985

Epoch: 143| Step: 0
Training loss: 3.431718298912844
Validation loss: 2.7787564298665814

Epoch: 6| Step: 1
Training loss: 2.9286798397294462
Validation loss: 2.7779080594865855

Epoch: 6| Step: 2
Training loss: 3.7737943429227543
Validation loss: 2.78127573261107

Epoch: 6| Step: 3
Training loss: 2.8176077344685355
Validation loss: 2.7773799768976706

Epoch: 6| Step: 4
Training loss: 2.917374025581766
Validation loss: 2.7786832687888987

Epoch: 6| Step: 5
Training loss: 2.793647566246636
Validation loss: 2.7764330107530677

Epoch: 6| Step: 6
Training loss: 2.7026933093809875
Validation loss: 2.777932544895072

Epoch: 6| Step: 7
Training loss: 3.3381960368066115
Validation loss: 2.7793443988053026

Epoch: 6| Step: 8
Training loss: 3.0186616304151133
Validation loss: 2.7812122998246673

Epoch: 6| Step: 9
Training loss: 3.142496946055674
Validation loss: 2.785509924751297

Epoch: 6| Step: 10
Training loss: 2.8882291195297185
Validation loss: 2.782111196459523

Epoch: 6| Step: 11
Training loss: 3.163979008832859
Validation loss: 2.783663773468198

Epoch: 6| Step: 12
Training loss: 2.918015486050589
Validation loss: 2.7812669289638174

Epoch: 6| Step: 13
Training loss: 3.411724206401636
Validation loss: 2.783041936858788

Epoch: 144| Step: 0
Training loss: 3.0932866529801086
Validation loss: 2.793876114930337

Epoch: 6| Step: 1
Training loss: 2.9181009489903764
Validation loss: 2.792247649009984

Epoch: 6| Step: 2
Training loss: 2.952889246335366
Validation loss: 2.780422266803735

Epoch: 6| Step: 3
Training loss: 2.432119054339738
Validation loss: 2.793162047465759

Epoch: 6| Step: 4
Training loss: 3.5848917714146333
Validation loss: 2.7977943121769835

Epoch: 6| Step: 5
Training loss: 2.4504412895911036
Validation loss: 2.783473918631795

Epoch: 6| Step: 6
Training loss: 2.7433842930129915
Validation loss: 2.7812080274131463

Epoch: 6| Step: 7
Training loss: 3.15366113828583
Validation loss: 2.778960211402376

Epoch: 6| Step: 8
Training loss: 3.309179405073248
Validation loss: 2.7750223824232965

Epoch: 6| Step: 9
Training loss: 3.2684153631700568
Validation loss: 2.778936602223097

Epoch: 6| Step: 10
Training loss: 3.524917866717188
Validation loss: 2.7773976881867553

Epoch: 6| Step: 11
Training loss: 3.0229633757971883
Validation loss: 2.773740903835601

Epoch: 6| Step: 12
Training loss: 3.2671624903768395
Validation loss: 2.774395639137247

Epoch: 6| Step: 13
Training loss: 3.499977656701841
Validation loss: 2.7748623303208677

Epoch: 145| Step: 0
Training loss: 3.385692753415795
Validation loss: 2.774238531986145

Epoch: 6| Step: 1
Training loss: 2.826905382740772
Validation loss: 2.7766479656310272

Epoch: 6| Step: 2
Training loss: 3.0220357321564983
Validation loss: 2.774551751501815

Epoch: 6| Step: 3
Training loss: 2.649338830483654
Validation loss: 2.7718532392843045

Epoch: 6| Step: 4
Training loss: 3.0675786783812216
Validation loss: 2.7724674768329614

Epoch: 6| Step: 5
Training loss: 3.5793947856949715
Validation loss: 2.774491785234655

Epoch: 6| Step: 6
Training loss: 2.7821149017004
Validation loss: 2.7733244879120473

Epoch: 6| Step: 7
Training loss: 3.2779432800953057
Validation loss: 2.7805922623336277

Epoch: 6| Step: 8
Training loss: 3.3678540059158704
Validation loss: 2.772809813231104

Epoch: 6| Step: 9
Training loss: 3.227732300852913
Validation loss: 2.7722677539116765

Epoch: 6| Step: 10
Training loss: 3.0732698054447
Validation loss: 2.7760561102862487

Epoch: 6| Step: 11
Training loss: 2.9476801010125357
Validation loss: 2.7769341529726392

Epoch: 6| Step: 12
Training loss: 2.701921669254516
Validation loss: 2.7730506156862402

Epoch: 6| Step: 13
Training loss: 3.2100649202621065
Validation loss: 2.774805029749306

Epoch: 146| Step: 0
Training loss: 2.461314532749924
Validation loss: 2.7788577011637834

Epoch: 6| Step: 1
Training loss: 3.4598422760928647
Validation loss: 2.778604238747981

Epoch: 6| Step: 2
Training loss: 3.4588909082692414
Validation loss: 2.7734353582687925

Epoch: 6| Step: 3
Training loss: 2.35147571086729
Validation loss: 2.7762058166967494

Epoch: 6| Step: 4
Training loss: 2.8670085466548225
Validation loss: 2.7782132737107603

Epoch: 6| Step: 5
Training loss: 2.9098272150398756
Validation loss: 2.778705478687764

Epoch: 6| Step: 6
Training loss: 2.9476773509734566
Validation loss: 2.787010297521814

Epoch: 6| Step: 7
Training loss: 3.8343379459596
Validation loss: 2.7929647039339254

Epoch: 6| Step: 8
Training loss: 2.9296720377196133
Validation loss: 2.7953232895811144

Epoch: 6| Step: 9
Training loss: 3.2582337178046124
Validation loss: 2.7825054769975552

Epoch: 6| Step: 10
Training loss: 2.610382433821846
Validation loss: 2.7776853515944637

Epoch: 6| Step: 11
Training loss: 3.725287709230057
Validation loss: 2.7686057671497717

Epoch: 6| Step: 12
Training loss: 3.355274341355967
Validation loss: 2.769176563016909

Epoch: 6| Step: 13
Training loss: 2.257436648437826
Validation loss: 2.7656870383647214

Epoch: 147| Step: 0
Training loss: 2.8742406090965127
Validation loss: 2.766481802949468

Epoch: 6| Step: 1
Training loss: 2.466442913354458
Validation loss: 2.767988851800953

Epoch: 6| Step: 2
Training loss: 3.027826007455002
Validation loss: 2.7699651111167616

Epoch: 6| Step: 3
Training loss: 3.5496084292807146
Validation loss: 2.7662586033045464

Epoch: 6| Step: 4
Training loss: 2.8711980476379133
Validation loss: 2.768076371127181

Epoch: 6| Step: 5
Training loss: 3.0208975598753334
Validation loss: 2.768036704970342

Epoch: 6| Step: 6
Training loss: 3.5987609426392337
Validation loss: 2.7697242782826335

Epoch: 6| Step: 7
Training loss: 3.446031421901138
Validation loss: 2.76701233882925

Epoch: 6| Step: 8
Training loss: 3.7124703865283033
Validation loss: 2.7655408802544903

Epoch: 6| Step: 9
Training loss: 2.9413281109931537
Validation loss: 2.7686920891806412

Epoch: 6| Step: 10
Training loss: 2.8570011478431114
Validation loss: 2.765565406560953

Epoch: 6| Step: 11
Training loss: 3.429194734318672
Validation loss: 2.776628462065703

Epoch: 6| Step: 12
Training loss: 2.8167302848658875
Validation loss: 2.7716343496211504

Epoch: 6| Step: 13
Training loss: 1.3676968306992054
Validation loss: 2.7693463564665612

Epoch: 148| Step: 0
Training loss: 3.086395461469589
Validation loss: 2.7780540781802996

Epoch: 6| Step: 1
Training loss: 3.595608703268681
Validation loss: 2.773345144312172

Epoch: 6| Step: 2
Training loss: 2.956296479261005
Validation loss: 2.7670121072039056

Epoch: 6| Step: 3
Training loss: 2.765748102066946
Validation loss: 2.762909578774217

Epoch: 6| Step: 4
Training loss: 2.445116321628471
Validation loss: 2.765629208422917

Epoch: 6| Step: 5
Training loss: 2.55333428896628
Validation loss: 2.7635700156764718

Epoch: 6| Step: 6
Training loss: 2.630586220565782
Validation loss: 2.7659985643582616

Epoch: 6| Step: 7
Training loss: 3.906337889636253
Validation loss: 2.766360826065489

Epoch: 6| Step: 8
Training loss: 3.159291529849858
Validation loss: 2.7704271149370547

Epoch: 6| Step: 9
Training loss: 3.406692616114415
Validation loss: 2.7653269884419975

Epoch: 6| Step: 10
Training loss: 2.9178940688129793
Validation loss: 2.7671278841046987

Epoch: 6| Step: 11
Training loss: 2.794211968580785
Validation loss: 2.7630790122955116

Epoch: 6| Step: 12
Training loss: 3.7390972590155944
Validation loss: 2.766427778888689

Epoch: 6| Step: 13
Training loss: 2.5841663207154677
Validation loss: 2.764519414575392

Epoch: 149| Step: 0
Training loss: 2.656370092930892
Validation loss: 2.7631589131637786

Epoch: 6| Step: 1
Training loss: 2.2839875191382606
Validation loss: 2.7625411517262592

Epoch: 6| Step: 2
Training loss: 3.3964109495100354
Validation loss: 2.761754322282695

Epoch: 6| Step: 3
Training loss: 2.4582918993373046
Validation loss: 2.766389146469704

Epoch: 6| Step: 4
Training loss: 3.482586457219237
Validation loss: 2.7650407327271784

Epoch: 6| Step: 5
Training loss: 3.693834973179234
Validation loss: 2.7642569732177265

Epoch: 6| Step: 6
Training loss: 3.277041397424599
Validation loss: 2.765821202102021

Epoch: 6| Step: 7
Training loss: 3.7820756499472385
Validation loss: 2.7653372844178485

Epoch: 6| Step: 8
Training loss: 3.51026229443505
Validation loss: 2.764824893047518

Epoch: 6| Step: 9
Training loss: 2.638940578646005
Validation loss: 2.7639343292474443

Epoch: 6| Step: 10
Training loss: 2.939632210076216
Validation loss: 2.7634587049915598

Epoch: 6| Step: 11
Training loss: 3.288055918289979
Validation loss: 2.7623013273274504

Epoch: 6| Step: 12
Training loss: 2.5044604564430566
Validation loss: 2.7612001916462807

Epoch: 6| Step: 13
Training loss: 2.3330104695333342
Validation loss: 2.76443169082999

Epoch: 150| Step: 0
Training loss: 3.018199079010858
Validation loss: 2.7612711977804323

Epoch: 6| Step: 1
Training loss: 3.448923999120448
Validation loss: 2.7650149556497077

Epoch: 6| Step: 2
Training loss: 2.7208734747908276
Validation loss: 2.7616632932331107

Epoch: 6| Step: 3
Training loss: 3.012864821254406
Validation loss: 2.761932843275345

Epoch: 6| Step: 4
Training loss: 3.464551980034833
Validation loss: 2.761795079325386

Epoch: 6| Step: 5
Training loss: 3.815755486034085
Validation loss: 2.762784277259817

Epoch: 6| Step: 6
Training loss: 3.05433344435519
Validation loss: 2.7620843092281815

Epoch: 6| Step: 7
Training loss: 3.205649074583786
Validation loss: 2.763928622130257

Epoch: 6| Step: 8
Training loss: 3.193003074063889
Validation loss: 2.7652426630868834

Epoch: 6| Step: 9
Training loss: 2.964362827946
Validation loss: 2.769207455105318

Epoch: 6| Step: 10
Training loss: 2.7820647685713356
Validation loss: 2.7736348723346067

Epoch: 6| Step: 11
Training loss: 2.3972451293526653
Validation loss: 2.7733945162381546

Epoch: 6| Step: 12
Training loss: 3.0449688548733036
Validation loss: 2.7773939508077112

Epoch: 6| Step: 13
Training loss: 2.3890953406003437
Validation loss: 2.782468210285347

Epoch: 151| Step: 0
Training loss: 3.3587220023052713
Validation loss: 2.785804962818353

Epoch: 6| Step: 1
Training loss: 2.554695339365839
Validation loss: 2.7796501175184796

Epoch: 6| Step: 2
Training loss: 2.8896997569053076
Validation loss: 2.774846141119187

Epoch: 6| Step: 3
Training loss: 3.2327230906671574
Validation loss: 2.7666988523142897

Epoch: 6| Step: 4
Training loss: 3.051659529667385
Validation loss: 2.772899763545889

Epoch: 6| Step: 5
Training loss: 2.0863521320995195
Validation loss: 2.767432670752093

Epoch: 6| Step: 6
Training loss: 3.0247555405382913
Validation loss: 2.7593228947541766

Epoch: 6| Step: 7
Training loss: 3.0556607854428735
Validation loss: 2.763881210770226

Epoch: 6| Step: 8
Training loss: 3.469044853256973
Validation loss: 2.760020190459809

Epoch: 6| Step: 9
Training loss: 3.250011590790254
Validation loss: 2.765043623616715

Epoch: 6| Step: 10
Training loss: 3.354447694619414
Validation loss: 2.7588981298023616

Epoch: 6| Step: 11
Training loss: 3.634281247111383
Validation loss: 2.7608960215881595

Epoch: 6| Step: 12
Training loss: 2.82102150075806
Validation loss: 2.760233683605363

Epoch: 6| Step: 13
Training loss: 2.9075681916864204
Validation loss: 2.7611968362202908

Epoch: 152| Step: 0
Training loss: 2.08458537308342
Validation loss: 2.760409979290716

Epoch: 6| Step: 1
Training loss: 3.4432056585265394
Validation loss: 2.759077492520047

Epoch: 6| Step: 2
Training loss: 3.2325602429788227
Validation loss: 2.757575783163503

Epoch: 6| Step: 3
Training loss: 3.092151575713503
Validation loss: 2.7608741865579893

Epoch: 6| Step: 4
Training loss: 2.7033132145795844
Validation loss: 2.758924574526216

Epoch: 6| Step: 5
Training loss: 3.653895997854176
Validation loss: 2.757862381459461

Epoch: 6| Step: 6
Training loss: 3.491258467770861
Validation loss: 2.7599555019051025

Epoch: 6| Step: 7
Training loss: 3.226632844836992
Validation loss: 2.759547065070594

Epoch: 6| Step: 8
Training loss: 3.116326617153252
Validation loss: 2.7571298067458017

Epoch: 6| Step: 9
Training loss: 3.00586572042865
Validation loss: 2.7559850629828024

Epoch: 6| Step: 10
Training loss: 2.992433861533019
Validation loss: 2.758673693943232

Epoch: 6| Step: 11
Training loss: 3.002433584528456
Validation loss: 2.7576465888531203

Epoch: 6| Step: 12
Training loss: 2.3645812943459568
Validation loss: 2.7574079574092574

Epoch: 6| Step: 13
Training loss: 3.421822882825858
Validation loss: 2.7574235814516515

Epoch: 153| Step: 0
Training loss: 2.5366702033714605
Validation loss: 2.7582348603511946

Epoch: 6| Step: 1
Training loss: 3.499673555681714
Validation loss: 2.7628590767436156

Epoch: 6| Step: 2
Training loss: 3.5403107384976917
Validation loss: 2.761143351256513

Epoch: 6| Step: 3
Training loss: 2.856694199894169
Validation loss: 2.758651502125204

Epoch: 6| Step: 4
Training loss: 3.3869944177564104
Validation loss: 2.7617773997892785

Epoch: 6| Step: 5
Training loss: 3.425788209531842
Validation loss: 2.7640923504031525

Epoch: 6| Step: 6
Training loss: 3.082316841073391
Validation loss: 2.768514195723548

Epoch: 6| Step: 7
Training loss: 2.6019939259627547
Validation loss: 2.766950751746888

Epoch: 6| Step: 8
Training loss: 3.0133220200059005
Validation loss: 2.764129348264007

Epoch: 6| Step: 9
Training loss: 2.871156528331513
Validation loss: 2.769295076631577

Epoch: 6| Step: 10
Training loss: 2.6435047225260595
Validation loss: 2.7712050201045524

Epoch: 6| Step: 11
Training loss: 3.0052782355805916
Validation loss: 2.7655968988797466

Epoch: 6| Step: 12
Training loss: 3.1847492391182786
Validation loss: 2.762501469195377

Epoch: 6| Step: 13
Training loss: 3.257530877178524
Validation loss: 2.7659361242348495

Epoch: 154| Step: 0
Training loss: 2.9136191841390504
Validation loss: 2.757331495481123

Epoch: 6| Step: 1
Training loss: 3.43737348843902
Validation loss: 2.7554505003327616

Epoch: 6| Step: 2
Training loss: 3.2824332873849564
Validation loss: 2.7533645202946984

Epoch: 6| Step: 3
Training loss: 2.8574043528918502
Validation loss: 2.7532300894144086

Epoch: 6| Step: 4
Training loss: 3.117131512361396
Validation loss: 2.75447514892863

Epoch: 6| Step: 5
Training loss: 3.136997842308229
Validation loss: 2.753444319463582

Epoch: 6| Step: 6
Training loss: 2.1357517878870875
Validation loss: 2.7551613267930444

Epoch: 6| Step: 7
Training loss: 2.7878711196796466
Validation loss: 2.752805023187117

Epoch: 6| Step: 8
Training loss: 2.8574255462852354
Validation loss: 2.753963161564956

Epoch: 6| Step: 9
Training loss: 3.4117072948825182
Validation loss: 2.7515355602553564

Epoch: 6| Step: 10
Training loss: 3.2986153443069512
Validation loss: 2.751300151107123

Epoch: 6| Step: 11
Training loss: 3.6613164506158564
Validation loss: 2.752912288140612

Epoch: 6| Step: 12
Training loss: 2.78069908600722
Validation loss: 2.752312667552087

Epoch: 6| Step: 13
Training loss: 3.0341999604548833
Validation loss: 2.749526875312238

Epoch: 155| Step: 0
Training loss: 3.0101117746377772
Validation loss: 2.751886703162513

Epoch: 6| Step: 1
Training loss: 3.4034444471622325
Validation loss: 2.7516717108593705

Epoch: 6| Step: 2
Training loss: 2.709210112063096
Validation loss: 2.7573141694565164

Epoch: 6| Step: 3
Training loss: 2.866210272039957
Validation loss: 2.759987787389405

Epoch: 6| Step: 4
Training loss: 2.4734130472599913
Validation loss: 2.7615766419521064

Epoch: 6| Step: 5
Training loss: 2.9577653545606286
Validation loss: 2.7688189964296597

Epoch: 6| Step: 6
Training loss: 2.8277156807610493
Validation loss: 2.7711821441474043

Epoch: 6| Step: 7
Training loss: 2.6805240670980726
Validation loss: 2.771048456452318

Epoch: 6| Step: 8
Training loss: 3.4770737861394045
Validation loss: 2.764181017933032

Epoch: 6| Step: 9
Training loss: 3.352047900638329
Validation loss: 2.756477851742551

Epoch: 6| Step: 10
Training loss: 3.526759169963257
Validation loss: 2.7578692287023134

Epoch: 6| Step: 11
Training loss: 3.604556876578487
Validation loss: 2.7509701118666046

Epoch: 6| Step: 12
Training loss: 3.1993764388984176
Validation loss: 2.752724101882952

Epoch: 6| Step: 13
Training loss: 2.2263352662967324
Validation loss: 2.749758411471581

Epoch: 156| Step: 0
Training loss: 3.547153814843279
Validation loss: 2.7508077758863703

Epoch: 6| Step: 1
Training loss: 3.3327707451674127
Validation loss: 2.7542505760442952

Epoch: 6| Step: 2
Training loss: 2.7662013256205245
Validation loss: 2.7520906568915118

Epoch: 6| Step: 3
Training loss: 3.3689005802167515
Validation loss: 2.7540103405990006

Epoch: 6| Step: 4
Training loss: 3.1596950953696665
Validation loss: 2.7514123878741943

Epoch: 6| Step: 5
Training loss: 3.2950045084017994
Validation loss: 2.7520636798017493

Epoch: 6| Step: 6
Training loss: 3.160051832136161
Validation loss: 2.75385744378437

Epoch: 6| Step: 7
Training loss: 2.601410182583538
Validation loss: 2.750328398605069

Epoch: 6| Step: 8
Training loss: 3.630158667131144
Validation loss: 2.749277987743848

Epoch: 6| Step: 9
Training loss: 2.191164598383858
Validation loss: 2.7508239649021307

Epoch: 6| Step: 10
Training loss: 3.387921076993676
Validation loss: 2.750631720362249

Epoch: 6| Step: 11
Training loss: 3.0021184752871837
Validation loss: 2.750270631623607

Epoch: 6| Step: 12
Training loss: 2.5946593930958297
Validation loss: 2.751834428142195

Epoch: 6| Step: 13
Training loss: 2.0782565885485504
Validation loss: 2.752617273848494

Epoch: 157| Step: 0
Training loss: 3.577277337161973
Validation loss: 2.756094318452474

Epoch: 6| Step: 1
Training loss: 2.371124317657165
Validation loss: 2.7700621560059493

Epoch: 6| Step: 2
Training loss: 3.3076362170068183
Validation loss: 2.7898949455994457

Epoch: 6| Step: 3
Training loss: 2.2328268169480636
Validation loss: 2.782231694887621

Epoch: 6| Step: 4
Training loss: 3.4836590634383096
Validation loss: 2.791811555589992

Epoch: 6| Step: 5
Training loss: 3.4066066730190916
Validation loss: 2.789364623377696

Epoch: 6| Step: 6
Training loss: 3.0410556092325614
Validation loss: 2.7720342709451047

Epoch: 6| Step: 7
Training loss: 2.3159698023696857
Validation loss: 2.7534889432723393

Epoch: 6| Step: 8
Training loss: 2.896774596415635
Validation loss: 2.7482119057934877

Epoch: 6| Step: 9
Training loss: 3.242292802318569
Validation loss: 2.7472101614297437

Epoch: 6| Step: 10
Training loss: 3.27505868174854
Validation loss: 2.7494739577495593

Epoch: 6| Step: 11
Training loss: 3.1030145508317135
Validation loss: 2.748844599456045

Epoch: 6| Step: 12
Training loss: 3.054678446178239
Validation loss: 2.7479742817086996

Epoch: 6| Step: 13
Training loss: 3.486938628268994
Validation loss: 2.749751289509123

Epoch: 158| Step: 0
Training loss: 2.773075391743957
Validation loss: 2.748885435994683

Epoch: 6| Step: 1
Training loss: 3.515830614646939
Validation loss: 2.7484555573356952

Epoch: 6| Step: 2
Training loss: 2.6785525929833236
Validation loss: 2.7477584150938816

Epoch: 6| Step: 3
Training loss: 3.2012344363548113
Validation loss: 2.7487045678718385

Epoch: 6| Step: 4
Training loss: 3.5188759925198303
Validation loss: 2.7470955235161343

Epoch: 6| Step: 5
Training loss: 3.604574999895356
Validation loss: 2.7467754286189425

Epoch: 6| Step: 6
Training loss: 3.1760391937643258
Validation loss: 2.746446097386628

Epoch: 6| Step: 7
Training loss: 1.9978189496861565
Validation loss: 2.7486248959832222

Epoch: 6| Step: 8
Training loss: 3.0351188588631515
Validation loss: 2.7532619379175434

Epoch: 6| Step: 9
Training loss: 2.8110603038517104
Validation loss: 2.759583946432177

Epoch: 6| Step: 10
Training loss: 2.725522255503811
Validation loss: 2.7687320098370267

Epoch: 6| Step: 11
Training loss: 3.454303799166842
Validation loss: 2.7677131242608066

Epoch: 6| Step: 12
Training loss: 3.27807274441303
Validation loss: 2.7776331430811383

Epoch: 6| Step: 13
Training loss: 2.567816917078593
Validation loss: 2.7755141843447584

Epoch: 159| Step: 0
Training loss: 1.9951179642566097
Validation loss: 2.764722182317079

Epoch: 6| Step: 1
Training loss: 3.109639065518352
Validation loss: 2.7579535917346623

Epoch: 6| Step: 2
Training loss: 3.521827211368877
Validation loss: 2.751461004526456

Epoch: 6| Step: 3
Training loss: 2.9921471814658784
Validation loss: 2.7495178888902307

Epoch: 6| Step: 4
Training loss: 3.247748989224579
Validation loss: 2.7518762897871327

Epoch: 6| Step: 5
Training loss: 3.4285017670638953
Validation loss: 2.746384106985225

Epoch: 6| Step: 6
Training loss: 2.968101992908535
Validation loss: 2.7461629538593813

Epoch: 6| Step: 7
Training loss: 2.9023619865573598
Validation loss: 2.750450272674325

Epoch: 6| Step: 8
Training loss: 2.787805952721476
Validation loss: 2.75715625169354

Epoch: 6| Step: 9
Training loss: 3.547632481021385
Validation loss: 2.7574528703656083

Epoch: 6| Step: 10
Training loss: 2.738402446943433
Validation loss: 2.757353412490602

Epoch: 6| Step: 11
Training loss: 3.402207802159819
Validation loss: 2.7553946243288014

Epoch: 6| Step: 12
Training loss: 2.809029366317654
Validation loss: 2.751123278174736

Epoch: 6| Step: 13
Training loss: 3.369363670153171
Validation loss: 2.748047796700625

Epoch: 160| Step: 0
Training loss: 2.8282284375237645
Validation loss: 2.746637971260528

Epoch: 6| Step: 1
Training loss: 3.0857865308700667
Validation loss: 2.747532036363962

Epoch: 6| Step: 2
Training loss: 3.1339348283331843
Validation loss: 2.746854066855905

Epoch: 6| Step: 3
Training loss: 3.4852551088590524
Validation loss: 2.7450511848836925

Epoch: 6| Step: 4
Training loss: 2.864441265860406
Validation loss: 2.748298013926423

Epoch: 6| Step: 5
Training loss: 2.7224367948118844
Validation loss: 2.747071398776203

Epoch: 6| Step: 6
Training loss: 2.4020358748984822
Validation loss: 2.7498364572380942

Epoch: 6| Step: 7
Training loss: 2.569376580885779
Validation loss: 2.7486941704212753

Epoch: 6| Step: 8
Training loss: 2.8813747552768416
Validation loss: 2.748980291149617

Epoch: 6| Step: 9
Training loss: 2.873500266953126
Validation loss: 2.7493130225757807

Epoch: 6| Step: 10
Training loss: 2.898192690975436
Validation loss: 2.7520421780520823

Epoch: 6| Step: 11
Training loss: 3.7390398712684982
Validation loss: 2.7537167659291257

Epoch: 6| Step: 12
Training loss: 3.5480573254827927
Validation loss: 2.7519896022968537

Epoch: 6| Step: 13
Training loss: 4.026399755242104
Validation loss: 2.7504199547298898

Epoch: 161| Step: 0
Training loss: 3.745141251348701
Validation loss: 2.747889263378388

Epoch: 6| Step: 1
Training loss: 2.2237803427398912
Validation loss: 2.7452492047812465

Epoch: 6| Step: 2
Training loss: 3.2263807194745433
Validation loss: 2.744238561637846

Epoch: 6| Step: 3
Training loss: 3.8254833838506195
Validation loss: 2.745194338898948

Epoch: 6| Step: 4
Training loss: 2.8301908419258925
Validation loss: 2.7442597770141623

Epoch: 6| Step: 5
Training loss: 2.659399431880693
Validation loss: 2.744408399625222

Epoch: 6| Step: 6
Training loss: 3.0477531537000617
Validation loss: 2.7424807832690963

Epoch: 6| Step: 7
Training loss: 3.1832227244975058
Validation loss: 2.743562268500802

Epoch: 6| Step: 8
Training loss: 3.4390173597549345
Validation loss: 2.7420951893867787

Epoch: 6| Step: 9
Training loss: 2.5055542282116012
Validation loss: 2.7418188279590807

Epoch: 6| Step: 10
Training loss: 2.742561945115667
Validation loss: 2.7447835439514456

Epoch: 6| Step: 11
Training loss: 3.5161368442503935
Validation loss: 2.7433051581473396

Epoch: 6| Step: 12
Training loss: 2.8940445752088717
Validation loss: 2.7436481263786088

Epoch: 6| Step: 13
Training loss: 2.2014769754793426
Validation loss: 2.744868757478342

Epoch: 162| Step: 0
Training loss: 2.6671937679849553
Validation loss: 2.7535681504277085

Epoch: 6| Step: 1
Training loss: 3.4478340868938386
Validation loss: 2.7526404847696604

Epoch: 6| Step: 2
Training loss: 3.439291469884362
Validation loss: 2.7631897927393583

Epoch: 6| Step: 3
Training loss: 3.1088765573912194
Validation loss: 2.747559067278577

Epoch: 6| Step: 4
Training loss: 3.0765919232063386
Validation loss: 2.7433604271976386

Epoch: 6| Step: 5
Training loss: 3.083660434864914
Validation loss: 2.7418437515949856

Epoch: 6| Step: 6
Training loss: 3.3407400969615666
Validation loss: 2.7423867044990504

Epoch: 6| Step: 7
Training loss: 3.6909287885660467
Validation loss: 2.7412096281889586

Epoch: 6| Step: 8
Training loss: 3.6961132254658904
Validation loss: 2.740802849212417

Epoch: 6| Step: 9
Training loss: 2.6549259251607795
Validation loss: 2.740962323657078

Epoch: 6| Step: 10
Training loss: 3.0437693883133456
Validation loss: 2.7370615278882378

Epoch: 6| Step: 11
Training loss: 2.016091581058289
Validation loss: 2.740784744301278

Epoch: 6| Step: 12
Training loss: 2.2517957938454756
Validation loss: 2.740307851588099

Epoch: 6| Step: 13
Training loss: 2.8425283637598584
Validation loss: 2.741896762188432

Epoch: 163| Step: 0
Training loss: 3.272873422461236
Validation loss: 2.740318725233544

Epoch: 6| Step: 1
Training loss: 3.049805938300256
Validation loss: 2.7386016468675387

Epoch: 6| Step: 2
Training loss: 2.802713958984875
Validation loss: 2.742121635351617

Epoch: 6| Step: 3
Training loss: 1.9713638150891557
Validation loss: 2.7517961917452167

Epoch: 6| Step: 4
Training loss: 3.703999862662657
Validation loss: 2.7506816146072857

Epoch: 6| Step: 5
Training loss: 2.436154409835968
Validation loss: 2.7470941344198985

Epoch: 6| Step: 6
Training loss: 3.868414050477298
Validation loss: 2.740968989580369

Epoch: 6| Step: 7
Training loss: 3.3504696644882865
Validation loss: 2.743550569532071

Epoch: 6| Step: 8
Training loss: 3.4573815809424673
Validation loss: 2.7393227277838377

Epoch: 6| Step: 9
Training loss: 3.2056501158267565
Validation loss: 2.7420730746912874

Epoch: 6| Step: 10
Training loss: 2.9867078042035566
Validation loss: 2.740007234290908

Epoch: 6| Step: 11
Training loss: 2.875079278267513
Validation loss: 2.7377231183511177

Epoch: 6| Step: 12
Training loss: 2.073425486112284
Validation loss: 2.7405404640955884

Epoch: 6| Step: 13
Training loss: 3.215573122664473
Validation loss: 2.7390836923467794

Epoch: 164| Step: 0
Training loss: 2.6463886989739676
Validation loss: 2.737641437536703

Epoch: 6| Step: 1
Training loss: 2.9954215716908497
Validation loss: 2.7411408155318275

Epoch: 6| Step: 2
Training loss: 3.658143686116154
Validation loss: 2.7404651293402633

Epoch: 6| Step: 3
Training loss: 3.002559206058837
Validation loss: 2.7421235874458176

Epoch: 6| Step: 4
Training loss: 3.145381684544387
Validation loss: 2.7411546272080862

Epoch: 6| Step: 5
Training loss: 2.5012356565446434
Validation loss: 2.7433385320287815

Epoch: 6| Step: 6
Training loss: 3.2913155348324024
Validation loss: 2.7394984881864555

Epoch: 6| Step: 7
Training loss: 2.717879144913585
Validation loss: 2.743278031114795

Epoch: 6| Step: 8
Training loss: 3.279904044073558
Validation loss: 2.7437097534573662

Epoch: 6| Step: 9
Training loss: 3.3759138494862144
Validation loss: 2.7464760270202455

Epoch: 6| Step: 10
Training loss: 3.3881866547421864
Validation loss: 2.746094875871967

Epoch: 6| Step: 11
Training loss: 2.7278528521277186
Validation loss: 2.748444794233801

Epoch: 6| Step: 12
Training loss: 3.056499597385604
Validation loss: 2.746843023087331

Epoch: 6| Step: 13
Training loss: 2.544405061323544
Validation loss: 2.7469710022695315

Epoch: 165| Step: 0
Training loss: 3.0080458513377084
Validation loss: 2.7495980943252203

Epoch: 6| Step: 1
Training loss: 2.054210999212269
Validation loss: 2.759386194326942

Epoch: 6| Step: 2
Training loss: 3.408854197751544
Validation loss: 2.7553093818393335

Epoch: 6| Step: 3
Training loss: 2.5127420906608116
Validation loss: 2.7594652387120124

Epoch: 6| Step: 4
Training loss: 3.694455327629051
Validation loss: 2.7581000468799504

Epoch: 6| Step: 5
Training loss: 3.1117043516154927
Validation loss: 2.751502106907375

Epoch: 6| Step: 6
Training loss: 2.6890627730799994
Validation loss: 2.7387509930735603

Epoch: 6| Step: 7
Training loss: 3.6326633873967475
Validation loss: 2.7365974865838516

Epoch: 6| Step: 8
Training loss: 2.9312583679209916
Validation loss: 2.7350739047907773

Epoch: 6| Step: 9
Training loss: 2.642843905529909
Validation loss: 2.735112330908999

Epoch: 6| Step: 10
Training loss: 3.1919228778786612
Validation loss: 2.732839243899582

Epoch: 6| Step: 11
Training loss: 3.6121677971916477
Validation loss: 2.7340256690798097

Epoch: 6| Step: 12
Training loss: 2.5896929528708466
Validation loss: 2.733414037462459

Epoch: 6| Step: 13
Training loss: 3.435716756032946
Validation loss: 2.7326925879046957

Epoch: 166| Step: 0
Training loss: 3.034028657580467
Validation loss: 2.735238050916574

Epoch: 6| Step: 1
Training loss: 3.031753655503879
Validation loss: 2.7345105546907016

Epoch: 6| Step: 2
Training loss: 2.649877736132174
Validation loss: 2.7356134032132644

Epoch: 6| Step: 3
Training loss: 3.0640662722878043
Validation loss: 2.734906819509409

Epoch: 6| Step: 4
Training loss: 2.950446958141701
Validation loss: 2.7364845400692284

Epoch: 6| Step: 5
Training loss: 2.8850337209334054
Validation loss: 2.73725378705135

Epoch: 6| Step: 6
Training loss: 3.056888811559523
Validation loss: 2.733413580710179

Epoch: 6| Step: 7
Training loss: 2.6964860655574703
Validation loss: 2.7333512506590543

Epoch: 6| Step: 8
Training loss: 3.5025630830343037
Validation loss: 2.735863871217414

Epoch: 6| Step: 9
Training loss: 3.349152380906582
Validation loss: 2.7343519546779924

Epoch: 6| Step: 10
Training loss: 3.5723143460062596
Validation loss: 2.73203824515921

Epoch: 6| Step: 11
Training loss: 3.5936287237519133
Validation loss: 2.731040710073219

Epoch: 6| Step: 12
Training loss: 2.1007609487327925
Validation loss: 2.732344771564267

Epoch: 6| Step: 13
Training loss: 3.0359192113870304
Validation loss: 2.7295724131460335

Epoch: 167| Step: 0
Training loss: 2.626281243945942
Validation loss: 2.7325337679153128

Epoch: 6| Step: 1
Training loss: 2.3600185097760558
Validation loss: 2.7358325754499027

Epoch: 6| Step: 2
Training loss: 3.0406831867104076
Validation loss: 2.742479790523089

Epoch: 6| Step: 3
Training loss: 3.0323089637555674
Validation loss: 2.744088332743166

Epoch: 6| Step: 4
Training loss: 3.6081920187914354
Validation loss: 2.7450872579934025

Epoch: 6| Step: 5
Training loss: 3.5543828477365365
Validation loss: 2.7488265475112073

Epoch: 6| Step: 6
Training loss: 2.8121378347549317
Validation loss: 2.739847169977223

Epoch: 6| Step: 7
Training loss: 3.295060078560888
Validation loss: 2.7389643844227787

Epoch: 6| Step: 8
Training loss: 2.6808229937802146
Validation loss: 2.736747540739848

Epoch: 6| Step: 9
Training loss: 2.6822317962384314
Validation loss: 2.737138406199551

Epoch: 6| Step: 10
Training loss: 3.163610506151373
Validation loss: 2.73412992583331

Epoch: 6| Step: 11
Training loss: 2.612640712909254
Validation loss: 2.7383563143584126

Epoch: 6| Step: 12
Training loss: 3.6872337374490542
Validation loss: 2.7398369503797406

Epoch: 6| Step: 13
Training loss: 3.399149221674944
Validation loss: 2.7388129840116626

Epoch: 168| Step: 0
Training loss: 3.5214461897368126
Validation loss: 2.7365996196733837

Epoch: 6| Step: 1
Training loss: 2.6725414850282077
Validation loss: 2.74284400510132

Epoch: 6| Step: 2
Training loss: 3.339255047942208
Validation loss: 2.7506319086300515

Epoch: 6| Step: 3
Training loss: 3.107591587229966
Validation loss: 2.7431322537650575

Epoch: 6| Step: 4
Training loss: 3.085265267465649
Validation loss: 2.743831480506969

Epoch: 6| Step: 5
Training loss: 3.7024563857760997
Validation loss: 2.7393935532521927

Epoch: 6| Step: 6
Training loss: 2.9077248061463465
Validation loss: 2.7394763469139503

Epoch: 6| Step: 7
Training loss: 2.5987656597713342
Validation loss: 2.7381885586545365

Epoch: 6| Step: 8
Training loss: 2.8776049215508532
Validation loss: 2.738640737731802

Epoch: 6| Step: 9
Training loss: 2.7052607395490202
Validation loss: 2.7412719862385853

Epoch: 6| Step: 10
Training loss: 3.292656826029555
Validation loss: 2.735980710396493

Epoch: 6| Step: 11
Training loss: 3.573431142943966
Validation loss: 2.7338946326894034

Epoch: 6| Step: 12
Training loss: 2.1734593602170564
Validation loss: 2.735707340070327

Epoch: 6| Step: 13
Training loss: 2.4891293695714443
Validation loss: 2.7347144337821714

Epoch: 169| Step: 0
Training loss: 3.2601678690370774
Validation loss: 2.7336579688530103

Epoch: 6| Step: 1
Training loss: 2.952425434873221
Validation loss: 2.734307195757412

Epoch: 6| Step: 2
Training loss: 3.3147532159191413
Validation loss: 2.736267449405548

Epoch: 6| Step: 3
Training loss: 3.41932199773498
Validation loss: 2.7364830514344427

Epoch: 6| Step: 4
Training loss: 3.3259740334952066
Validation loss: 2.7314121828101885

Epoch: 6| Step: 5
Training loss: 2.96508434259321
Validation loss: 2.7304912722712906

Epoch: 6| Step: 6
Training loss: 2.7486249780607634
Validation loss: 2.730990637230321

Epoch: 6| Step: 7
Training loss: 2.927523126290937
Validation loss: 2.729562075246304

Epoch: 6| Step: 8
Training loss: 2.774785791325907
Validation loss: 2.7296864618037073

Epoch: 6| Step: 9
Training loss: 3.255863475739769
Validation loss: 2.728521514239561

Epoch: 6| Step: 10
Training loss: 3.01365969167782
Validation loss: 2.727938613319771

Epoch: 6| Step: 11
Training loss: 2.9333908884586433
Validation loss: 2.727397546952497

Epoch: 6| Step: 12
Training loss: 2.76513831387635
Validation loss: 2.7274349645656693

Epoch: 6| Step: 13
Training loss: 2.794071348001584
Validation loss: 2.728247594771681

Epoch: 170| Step: 0
Training loss: 3.2965333589832895
Validation loss: 2.7279624214025957

Epoch: 6| Step: 1
Training loss: 2.9423213918145468
Validation loss: 2.7256199374933288

Epoch: 6| Step: 2
Training loss: 2.5808049000631454
Validation loss: 2.7274332830023797

Epoch: 6| Step: 3
Training loss: 2.4933753934498375
Validation loss: 2.7261970412136436

Epoch: 6| Step: 4
Training loss: 3.6084136343133983
Validation loss: 2.7265050917100755

Epoch: 6| Step: 5
Training loss: 2.9541601556689163
Validation loss: 2.7273406478482514

Epoch: 6| Step: 6
Training loss: 3.2706237207457964
Validation loss: 2.7246603799374753

Epoch: 6| Step: 7
Training loss: 2.649930819921968
Validation loss: 2.726186914323744

Epoch: 6| Step: 8
Training loss: 2.883724740276982
Validation loss: 2.724825334026653

Epoch: 6| Step: 9
Training loss: 3.13175478462249
Validation loss: 2.7259004889711784

Epoch: 6| Step: 10
Training loss: 3.0704820891856324
Validation loss: 2.724465829101843

Epoch: 6| Step: 11
Training loss: 3.183428389110355
Validation loss: 2.7283339815684426

Epoch: 6| Step: 12
Training loss: 3.478363736331576
Validation loss: 2.7272332005885302

Epoch: 6| Step: 13
Training loss: 2.6916229205124607
Validation loss: 2.7251449845937272

Epoch: 171| Step: 0
Training loss: 3.1696328943967154
Validation loss: 2.725278716271389

Epoch: 6| Step: 1
Training loss: 2.870587819475532
Validation loss: 2.7269250038943254

Epoch: 6| Step: 2
Training loss: 2.4842861327585646
Validation loss: 2.7256159250120393

Epoch: 6| Step: 3
Training loss: 2.7862454246870207
Validation loss: 2.7282119868479757

Epoch: 6| Step: 4
Training loss: 3.2140794960355192
Validation loss: 2.723905165946796

Epoch: 6| Step: 5
Training loss: 3.1702341430065344
Validation loss: 2.7253381370877925

Epoch: 6| Step: 6
Training loss: 3.6460301954616696
Validation loss: 2.731222409089538

Epoch: 6| Step: 7
Training loss: 3.0400698053978785
Validation loss: 2.7265794713951017

Epoch: 6| Step: 8
Training loss: 3.003132615094647
Validation loss: 2.728976634709213

Epoch: 6| Step: 9
Training loss: 2.7104558599298256
Validation loss: 2.7307849339312185

Epoch: 6| Step: 10
Training loss: 2.895877499323628
Validation loss: 2.7335589872726542

Epoch: 6| Step: 11
Training loss: 3.2318674585906924
Validation loss: 2.733065496398467

Epoch: 6| Step: 12
Training loss: 3.2380803946681103
Validation loss: 2.731295916926307

Epoch: 6| Step: 13
Training loss: 2.9406941680394794
Validation loss: 2.723622303336362

Epoch: 172| Step: 0
Training loss: 2.837848954442858
Validation loss: 2.7263093795554063

Epoch: 6| Step: 1
Training loss: 3.282274068246287
Validation loss: 2.722865957820521

Epoch: 6| Step: 2
Training loss: 3.2680096110525945
Validation loss: 2.7249557678931797

Epoch: 6| Step: 3
Training loss: 3.340875834226959
Validation loss: 2.722157983675603

Epoch: 6| Step: 4
Training loss: 2.854857164006613
Validation loss: 2.7231427317125028

Epoch: 6| Step: 5
Training loss: 3.123317876130908
Validation loss: 2.7219241976828896

Epoch: 6| Step: 6
Training loss: 3.1006894360186568
Validation loss: 2.722252481838046

Epoch: 6| Step: 7
Training loss: 2.7005882046326457
Validation loss: 2.7206681891227316

Epoch: 6| Step: 8
Training loss: 2.7646262741682706
Validation loss: 2.723125864109131

Epoch: 6| Step: 9
Training loss: 3.6199647857470696
Validation loss: 2.7208606455970004

Epoch: 6| Step: 10
Training loss: 3.1743944807181523
Validation loss: 2.7199330182366586

Epoch: 6| Step: 11
Training loss: 2.106130633947813
Validation loss: 2.721904192744015

Epoch: 6| Step: 12
Training loss: 3.3235100641834254
Validation loss: 2.72224931195595

Epoch: 6| Step: 13
Training loss: 2.5813970897967597
Validation loss: 2.7229753361042848

Epoch: 173| Step: 0
Training loss: 3.3427807124975613
Validation loss: 2.7210096304932083

Epoch: 6| Step: 1
Training loss: 2.94335710693758
Validation loss: 2.722258437364123

Epoch: 6| Step: 2
Training loss: 3.209455533303346
Validation loss: 2.723445710377547

Epoch: 6| Step: 3
Training loss: 3.20773653366881
Validation loss: 2.728469764038133

Epoch: 6| Step: 4
Training loss: 3.631801538389124
Validation loss: 2.7296508313257912

Epoch: 6| Step: 5
Training loss: 2.365654678864045
Validation loss: 2.736686293648131

Epoch: 6| Step: 6
Training loss: 3.370225566933062
Validation loss: 2.7461552820538384

Epoch: 6| Step: 7
Training loss: 2.895557710626125
Validation loss: 2.7457891986859098

Epoch: 6| Step: 8
Training loss: 2.663697964514913
Validation loss: 2.7308251993869406

Epoch: 6| Step: 9
Training loss: 2.893113503374557
Validation loss: 2.7431132885331824

Epoch: 6| Step: 10
Training loss: 2.796526924509767
Validation loss: 2.735838214674167

Epoch: 6| Step: 11
Training loss: 3.006425968976052
Validation loss: 2.73326228646215

Epoch: 6| Step: 12
Training loss: 2.996174598607664
Validation loss: 2.7275927364596866

Epoch: 6| Step: 13
Training loss: 3.1009382489307393
Validation loss: 2.726115025395292

Epoch: 174| Step: 0
Training loss: 3.20601304277324
Validation loss: 2.723369753067112

Epoch: 6| Step: 1
Training loss: 2.5476416621628406
Validation loss: 2.7206463685771385

Epoch: 6| Step: 2
Training loss: 3.36161069773915
Validation loss: 2.7216095182187865

Epoch: 6| Step: 3
Training loss: 2.7701886987966935
Validation loss: 2.720869289480277

Epoch: 6| Step: 4
Training loss: 2.731664916761985
Validation loss: 2.7236093355467115

Epoch: 6| Step: 5
Training loss: 2.7676987281855663
Validation loss: 2.7239451971090065

Epoch: 6| Step: 6
Training loss: 2.7597078288965307
Validation loss: 2.7229636899090153

Epoch: 6| Step: 7
Training loss: 3.4097655466870482
Validation loss: 2.7260057759097727

Epoch: 6| Step: 8
Training loss: 2.6553839674206845
Validation loss: 2.7272806145425643

Epoch: 6| Step: 9
Training loss: 2.114230297165066
Validation loss: 2.7247354911743074

Epoch: 6| Step: 10
Training loss: 3.111832304272997
Validation loss: 2.7288354934020234

Epoch: 6| Step: 11
Training loss: 3.9216713415513316
Validation loss: 2.727565539629943

Epoch: 6| Step: 12
Training loss: 3.3022275746768353
Validation loss: 2.728893405059519

Epoch: 6| Step: 13
Training loss: 4.104763678231182
Validation loss: 2.7238490221306293

Epoch: 175| Step: 0
Training loss: 2.913582524511058
Validation loss: 2.7249467079661707

Epoch: 6| Step: 1
Training loss: 3.206615500038614
Validation loss: 2.7228304810067727

Epoch: 6| Step: 2
Training loss: 3.1440223045043276
Validation loss: 2.7240306917027284

Epoch: 6| Step: 3
Training loss: 3.2112932959429847
Validation loss: 2.724127560435992

Epoch: 6| Step: 4
Training loss: 3.404119962996772
Validation loss: 2.7237020392490767

Epoch: 6| Step: 5
Training loss: 2.6692282969489347
Validation loss: 2.7243405765277315

Epoch: 6| Step: 6
Training loss: 3.3703776601294124
Validation loss: 2.7251145459858273

Epoch: 6| Step: 7
Training loss: 2.418546296445308
Validation loss: 2.7238671511389514

Epoch: 6| Step: 8
Training loss: 2.4144952380018263
Validation loss: 2.7252233373273116

Epoch: 6| Step: 9
Training loss: 3.0583973087060468
Validation loss: 2.723199084020159

Epoch: 6| Step: 10
Training loss: 3.1971871768972506
Validation loss: 2.722181936491511

Epoch: 6| Step: 11
Training loss: 3.2253780823507943
Validation loss: 2.7248425796766975

Epoch: 6| Step: 12
Training loss: 3.0237032357077296
Validation loss: 2.724452774052661

Epoch: 6| Step: 13
Training loss: 3.384535705188714
Validation loss: 2.7242290575856267

Epoch: 176| Step: 0
Training loss: 3.1299762015611026
Validation loss: 2.719227214416672

Epoch: 6| Step: 1
Training loss: 2.909482901075026
Validation loss: 2.718914594183514

Epoch: 6| Step: 2
Training loss: 2.7105491865769165
Validation loss: 2.71655453721626

Epoch: 6| Step: 3
Training loss: 2.9103191150945236
Validation loss: 2.7163111811649467

Epoch: 6| Step: 4
Training loss: 3.275019370451273
Validation loss: 2.7155343032732326

Epoch: 6| Step: 5
Training loss: 3.2794480962006136
Validation loss: 2.7186796183723474

Epoch: 6| Step: 6
Training loss: 3.6703675117770955
Validation loss: 2.7159626040173954

Epoch: 6| Step: 7
Training loss: 3.0676164510769546
Validation loss: 2.7173228154747164

Epoch: 6| Step: 8
Training loss: 1.6681071096742268
Validation loss: 2.718685287518255

Epoch: 6| Step: 9
Training loss: 3.25130788456047
Validation loss: 2.717344141932076

Epoch: 6| Step: 10
Training loss: 3.1574379979658405
Validation loss: 2.716923625572455

Epoch: 6| Step: 11
Training loss: 3.5441967771680067
Validation loss: 2.7259898015755253

Epoch: 6| Step: 12
Training loss: 2.582723135305087
Validation loss: 2.716710639410008

Epoch: 6| Step: 13
Training loss: 2.670583580190472
Validation loss: 2.7182839587881538

Epoch: 177| Step: 0
Training loss: 2.3535028607667354
Validation loss: 2.7176411495835286

Epoch: 6| Step: 1
Training loss: 3.215173011502878
Validation loss: 2.713404317398325

Epoch: 6| Step: 2
Training loss: 2.7803985492518666
Validation loss: 2.7158787858124174

Epoch: 6| Step: 3
Training loss: 2.9347162245338954
Validation loss: 2.714083818033659

Epoch: 6| Step: 4
Training loss: 3.154734634871066
Validation loss: 2.7169513054138195

Epoch: 6| Step: 5
Training loss: 3.276734360247555
Validation loss: 2.7134262594837746

Epoch: 6| Step: 6
Training loss: 3.118067719894353
Validation loss: 2.718913722009017

Epoch: 6| Step: 7
Training loss: 3.3830760826691333
Validation loss: 2.7212547830877862

Epoch: 6| Step: 8
Training loss: 2.691268053645394
Validation loss: 2.7228104996742686

Epoch: 6| Step: 9
Training loss: 3.3867660571955476
Validation loss: 2.7208051249050587

Epoch: 6| Step: 10
Training loss: 2.76410508282057
Validation loss: 2.716008389222368

Epoch: 6| Step: 11
Training loss: 2.55481218039597
Validation loss: 2.712735805598626

Epoch: 6| Step: 12
Training loss: 2.9982429763328713
Validation loss: 2.7166553774015987

Epoch: 6| Step: 13
Training loss: 4.04604823088172
Validation loss: 2.7176569531956782

Epoch: 178| Step: 0
Training loss: 2.5352661861335197
Validation loss: 2.716583975157443

Epoch: 6| Step: 1
Training loss: 3.733483627109738
Validation loss: 2.711221757883335

Epoch: 6| Step: 2
Training loss: 2.910898736029135
Validation loss: 2.7190306625552876

Epoch: 6| Step: 3
Training loss: 3.0447593190452813
Validation loss: 2.7106844781685746

Epoch: 6| Step: 4
Training loss: 3.2602459717614436
Validation loss: 2.7103875840605127

Epoch: 6| Step: 5
Training loss: 3.352026847203793
Validation loss: 2.718042626988755

Epoch: 6| Step: 6
Training loss: 2.9151444050270725
Validation loss: 2.713975026012409

Epoch: 6| Step: 7
Training loss: 3.1576861145307635
Validation loss: 2.7098227924351437

Epoch: 6| Step: 8
Training loss: 3.1737794467420857
Validation loss: 2.711031447423412

Epoch: 6| Step: 9
Training loss: 2.8310427288791065
Validation loss: 2.710540054851083

Epoch: 6| Step: 10
Training loss: 3.181740437833532
Validation loss: 2.709044224194866

Epoch: 6| Step: 11
Training loss: 2.2827622091509734
Validation loss: 2.707913564204253

Epoch: 6| Step: 12
Training loss: 3.306454017272123
Validation loss: 2.709601740572565

Epoch: 6| Step: 13
Training loss: 1.924500943182429
Validation loss: 2.7085086724733705

Epoch: 179| Step: 0
Training loss: 3.533483423488066
Validation loss: 2.7071838691020225

Epoch: 6| Step: 1
Training loss: 3.026152266791789
Validation loss: 2.7064730686642773

Epoch: 6| Step: 2
Training loss: 2.62908472416094
Validation loss: 2.710033551039352

Epoch: 6| Step: 3
Training loss: 2.687517033012884
Validation loss: 2.7084441630086666

Epoch: 6| Step: 4
Training loss: 2.5028894892280174
Validation loss: 2.705983340916105

Epoch: 6| Step: 5
Training loss: 2.3048512546100857
Validation loss: 2.705298760899518

Epoch: 6| Step: 6
Training loss: 3.378480458856683
Validation loss: 2.7065351870076957

Epoch: 6| Step: 7
Training loss: 3.0594718130689453
Validation loss: 2.7069366125542045

Epoch: 6| Step: 8
Training loss: 3.177752081523349
Validation loss: 2.7085940646491213

Epoch: 6| Step: 9
Training loss: 2.604995982044365
Validation loss: 2.7077587868710453

Epoch: 6| Step: 10
Training loss: 3.4725312938886717
Validation loss: 2.709920833150105

Epoch: 6| Step: 11
Training loss: 3.5913051083960825
Validation loss: 2.708905626385869

Epoch: 6| Step: 12
Training loss: 2.9535675524569047
Validation loss: 2.7102920365731427

Epoch: 6| Step: 13
Training loss: 3.2637060632747024
Validation loss: 2.710929528026344

Epoch: 180| Step: 0
Training loss: 3.0003501369871888
Validation loss: 2.7117193033953435

Epoch: 6| Step: 1
Training loss: 3.195118196357732
Validation loss: 2.7070222342564647

Epoch: 6| Step: 2
Training loss: 3.4245402786352384
Validation loss: 2.707652682462645

Epoch: 6| Step: 3
Training loss: 2.9324849924937677
Validation loss: 2.7064714110189314

Epoch: 6| Step: 4
Training loss: 3.355989249274729
Validation loss: 2.7070156021730134

Epoch: 6| Step: 5
Training loss: 2.744718682165091
Validation loss: 2.7112416232184513

Epoch: 6| Step: 6
Training loss: 3.119466383613334
Validation loss: 2.7066327690340932

Epoch: 6| Step: 7
Training loss: 3.263391926765123
Validation loss: 2.706570707867379

Epoch: 6| Step: 8
Training loss: 3.230275084884171
Validation loss: 2.707557425722972

Epoch: 6| Step: 9
Training loss: 2.4218395599725526
Validation loss: 2.709275601579584

Epoch: 6| Step: 10
Training loss: 3.172200003073115
Validation loss: 2.7083934584791387

Epoch: 6| Step: 11
Training loss: 2.252465910150829
Validation loss: 2.7094357054218126

Epoch: 6| Step: 12
Training loss: 3.0528829176012535
Validation loss: 2.7095995247307556

Epoch: 6| Step: 13
Training loss: 2.924072255432939
Validation loss: 2.7097763085839817

Epoch: 181| Step: 0
Training loss: 2.3463413408940057
Validation loss: 2.7133403986310536

Epoch: 6| Step: 1
Training loss: 2.9477347777275043
Validation loss: 2.7124335341582246

Epoch: 6| Step: 2
Training loss: 3.1006872830385954
Validation loss: 2.709387352795293

Epoch: 6| Step: 3
Training loss: 3.263555281523744
Validation loss: 2.713532829699356

Epoch: 6| Step: 4
Training loss: 3.0082249742543423
Validation loss: 2.7084401515849836

Epoch: 6| Step: 5
Training loss: 2.77085734956893
Validation loss: 2.707352478773347

Epoch: 6| Step: 6
Training loss: 2.457071228187279
Validation loss: 2.7062422369866206

Epoch: 6| Step: 7
Training loss: 3.132963181674737
Validation loss: 2.706834010494537

Epoch: 6| Step: 8
Training loss: 2.3365135885896975
Validation loss: 2.704592654702046

Epoch: 6| Step: 9
Training loss: 3.9655648012755047
Validation loss: 2.7063597790560476

Epoch: 6| Step: 10
Training loss: 3.251851801396341
Validation loss: 2.70559651473655

Epoch: 6| Step: 11
Training loss: 3.1097148153665404
Validation loss: 2.7040132325440798

Epoch: 6| Step: 12
Training loss: 2.8881285738762954
Validation loss: 2.7059188972539716

Epoch: 6| Step: 13
Training loss: 3.6404236831996193
Validation loss: 2.7052616246540775

Epoch: 182| Step: 0
Training loss: 3.2572605022179424
Validation loss: 2.7072461567391835

Epoch: 6| Step: 1
Training loss: 3.0400611785956695
Validation loss: 2.7061424676776964

Epoch: 6| Step: 2
Training loss: 3.0005851810660213
Validation loss: 2.705626371320958

Epoch: 6| Step: 3
Training loss: 2.8793883625214787
Validation loss: 2.7024635559823023

Epoch: 6| Step: 4
Training loss: 3.0189612715499767
Validation loss: 2.703727130165949

Epoch: 6| Step: 5
Training loss: 3.099987946763756
Validation loss: 2.7013150567519015

Epoch: 6| Step: 6
Training loss: 3.252483885928208
Validation loss: 2.7040977095962817

Epoch: 6| Step: 7
Training loss: 3.4499270445255545
Validation loss: 2.703198733211211

Epoch: 6| Step: 8
Training loss: 2.819420839992824
Validation loss: 2.7041776031339224

Epoch: 6| Step: 9
Training loss: 2.939204756170255
Validation loss: 2.7046831126218454

Epoch: 6| Step: 10
Training loss: 2.9365175917592294
Validation loss: 2.703761211607527

Epoch: 6| Step: 11
Training loss: 3.040419876064178
Validation loss: 2.7036795288312243

Epoch: 6| Step: 12
Training loss: 2.4083469716074206
Validation loss: 2.702890176677993

Epoch: 6| Step: 13
Training loss: 3.1916372339337418
Validation loss: 2.707515111779598

Epoch: 183| Step: 0
Training loss: 3.23595533600906
Validation loss: 2.706457640209373

Epoch: 6| Step: 1
Training loss: 3.0871068356646045
Validation loss: 2.705494459771181

Epoch: 6| Step: 2
Training loss: 2.4270159885302656
Validation loss: 2.709595162109498

Epoch: 6| Step: 3
Training loss: 2.6098040382220122
Validation loss: 2.723981321024476

Epoch: 6| Step: 4
Training loss: 2.442229060565622
Validation loss: 2.730526990364879

Epoch: 6| Step: 5
Training loss: 3.6301859887346235
Validation loss: 2.747005181804167

Epoch: 6| Step: 6
Training loss: 3.5699974271620767
Validation loss: 2.7288271425005006

Epoch: 6| Step: 7
Training loss: 3.6532388661229995
Validation loss: 2.7194572342623013

Epoch: 6| Step: 8
Training loss: 3.2593530904704657
Validation loss: 2.7074380068385144

Epoch: 6| Step: 9
Training loss: 2.732561131078865
Validation loss: 2.7071782213257953

Epoch: 6| Step: 10
Training loss: 3.037162755760789
Validation loss: 2.7021879693758706

Epoch: 6| Step: 11
Training loss: 2.778260585364157
Validation loss: 2.7018915421149297

Epoch: 6| Step: 12
Training loss: 3.1544627048611407
Validation loss: 2.7033417450218247

Epoch: 6| Step: 13
Training loss: 1.5691910720172535
Validation loss: 2.701719184166104

Epoch: 184| Step: 0
Training loss: 2.3486489531345067
Validation loss: 2.7010125683499218

Epoch: 6| Step: 1
Training loss: 2.4296609073667823
Validation loss: 2.702816229223264

Epoch: 6| Step: 2
Training loss: 2.528074934078192
Validation loss: 2.7008208199602945

Epoch: 6| Step: 3
Training loss: 3.126037120381479
Validation loss: 2.7025383004290053

Epoch: 6| Step: 4
Training loss: 2.4775646600840635
Validation loss: 2.698444235212023

Epoch: 6| Step: 5
Training loss: 2.4307756838949657
Validation loss: 2.7018104100842892

Epoch: 6| Step: 6
Training loss: 3.1330962016960204
Validation loss: 2.7033055349695254

Epoch: 6| Step: 7
Training loss: 3.4941373497748764
Validation loss: 2.7015686239679892

Epoch: 6| Step: 8
Training loss: 3.1561593524266414
Validation loss: 2.7003548610356987

Epoch: 6| Step: 9
Training loss: 2.596419190434641
Validation loss: 2.701732210528728

Epoch: 6| Step: 10
Training loss: 3.3866922802094197
Validation loss: 2.701887650004052

Epoch: 6| Step: 11
Training loss: 3.753009859807525
Validation loss: 2.7022971676276737

Epoch: 6| Step: 12
Training loss: 3.6820239770575847
Validation loss: 2.704955712636107

Epoch: 6| Step: 13
Training loss: 3.349718702661895
Validation loss: 2.7032548601865414

Epoch: 185| Step: 0
Training loss: 3.451419737226211
Validation loss: 2.705205773388973

Epoch: 6| Step: 1
Training loss: 2.5740120186810422
Validation loss: 2.708402791485403

Epoch: 6| Step: 2
Training loss: 3.2194546418956027
Validation loss: 2.7109850987199735

Epoch: 6| Step: 3
Training loss: 2.6717130377686265
Validation loss: 2.7076907194591

Epoch: 6| Step: 4
Training loss: 3.2877757257791265
Validation loss: 2.700732468136164

Epoch: 6| Step: 5
Training loss: 3.2127530425044473
Validation loss: 2.6992211795140193

Epoch: 6| Step: 6
Training loss: 3.027253337863623
Validation loss: 2.701553689426818

Epoch: 6| Step: 7
Training loss: 2.4197165438261194
Validation loss: 2.6994674418699813

Epoch: 6| Step: 8
Training loss: 2.680279991554965
Validation loss: 2.6993683633343157

Epoch: 6| Step: 9
Training loss: 2.841723883566475
Validation loss: 2.6992460994772305

Epoch: 6| Step: 10
Training loss: 3.0621412417416347
Validation loss: 2.700511327208573

Epoch: 6| Step: 11
Training loss: 3.4972329782312643
Validation loss: 2.70125188164713

Epoch: 6| Step: 12
Training loss: 3.132723914056919
Validation loss: 2.6989192153868746

Epoch: 6| Step: 13
Training loss: 3.1765024790274565
Validation loss: 2.6994657590296733

Epoch: 186| Step: 0
Training loss: 3.159160669378614
Validation loss: 2.697406975473265

Epoch: 6| Step: 1
Training loss: 3.7618154669793387
Validation loss: 2.698187130618811

Epoch: 6| Step: 2
Training loss: 3.07220943954902
Validation loss: 2.6965906490088223

Epoch: 6| Step: 3
Training loss: 2.933873636885528
Validation loss: 2.6965659545412213

Epoch: 6| Step: 4
Training loss: 2.881187084115135
Validation loss: 2.698527111973856

Epoch: 6| Step: 5
Training loss: 3.4108444166216985
Validation loss: 2.699714242974301

Epoch: 6| Step: 6
Training loss: 2.414351263954116
Validation loss: 2.698442608736281

Epoch: 6| Step: 7
Training loss: 2.8924375058135
Validation loss: 2.700998987063219

Epoch: 6| Step: 8
Training loss: 2.462927797598143
Validation loss: 2.696897038393127

Epoch: 6| Step: 9
Training loss: 3.5454163093550277
Validation loss: 2.7058135061386115

Epoch: 6| Step: 10
Training loss: 2.9845937279241475
Validation loss: 2.7038687610362993

Epoch: 6| Step: 11
Training loss: 2.67180486218935
Validation loss: 2.702502899216936

Epoch: 6| Step: 12
Training loss: 2.7015554468825114
Validation loss: 2.70895553395956

Epoch: 6| Step: 13
Training loss: 3.2063502007902103
Validation loss: 2.7051256600253355

Epoch: 187| Step: 0
Training loss: 2.934362968444533
Validation loss: 2.7065802024978285

Epoch: 6| Step: 1
Training loss: 3.392759714663759
Validation loss: 2.719485253138083

Epoch: 6| Step: 2
Training loss: 3.1012519277361377
Validation loss: 2.716248696505009

Epoch: 6| Step: 3
Training loss: 2.680191926773764
Validation loss: 2.7044148144052245

Epoch: 6| Step: 4
Training loss: 3.2321097139677977
Validation loss: 2.7118305332264825

Epoch: 6| Step: 5
Training loss: 2.9626945978948807
Validation loss: 2.7065610862795197

Epoch: 6| Step: 6
Training loss: 2.6216865699175846
Validation loss: 2.6993318881911668

Epoch: 6| Step: 7
Training loss: 3.2342838882660656
Validation loss: 2.7055805563470847

Epoch: 6| Step: 8
Training loss: 3.46831929050177
Validation loss: 2.7030001223875906

Epoch: 6| Step: 9
Training loss: 2.882599448004651
Validation loss: 2.7011489478659545

Epoch: 6| Step: 10
Training loss: 2.862708144970215
Validation loss: 2.7011280573066685

Epoch: 6| Step: 11
Training loss: 2.547983875984185
Validation loss: 2.700200008366073

Epoch: 6| Step: 12
Training loss: 3.1951411791251125
Validation loss: 2.6981462735765533

Epoch: 6| Step: 13
Training loss: 3.0098136289062003
Validation loss: 2.699029089194528

Epoch: 188| Step: 0
Training loss: 3.0665619051357473
Validation loss: 2.6973286872235227

Epoch: 6| Step: 1
Training loss: 3.2192281719681444
Validation loss: 2.6969842116982923

Epoch: 6| Step: 2
Training loss: 2.301760505606719
Validation loss: 2.6967031112664843

Epoch: 6| Step: 3
Training loss: 3.045048092617346
Validation loss: 2.697246803943405

Epoch: 6| Step: 4
Training loss: 3.387822130940991
Validation loss: 2.6970064423128366

Epoch: 6| Step: 5
Training loss: 3.136103017380028
Validation loss: 2.6977126905598174

Epoch: 6| Step: 6
Training loss: 2.797056906128405
Validation loss: 2.6937787467306418

Epoch: 6| Step: 7
Training loss: 2.9796680659844084
Validation loss: 2.6955106339311783

Epoch: 6| Step: 8
Training loss: 3.1969027490986996
Validation loss: 2.6942922379461867

Epoch: 6| Step: 9
Training loss: 2.925160891028615
Validation loss: 2.6967548350862396

Epoch: 6| Step: 10
Training loss: 2.5238490285806288
Validation loss: 2.696802282017821

Epoch: 6| Step: 11
Training loss: 3.161142013955947
Validation loss: 2.698584706955165

Epoch: 6| Step: 12
Training loss: 3.2283146051964193
Validation loss: 2.6996619073257326

Epoch: 6| Step: 13
Training loss: 3.260329045264977
Validation loss: 2.699866543596938

Epoch: 189| Step: 0
Training loss: 3.7993856535767057
Validation loss: 2.6995657029199887

Epoch: 6| Step: 1
Training loss: 2.7712493431217857
Validation loss: 2.7055643666628235

Epoch: 6| Step: 2
Training loss: 2.517987107823389
Validation loss: 2.707158702126482

Epoch: 6| Step: 3
Training loss: 3.4255888829435284
Validation loss: 2.7163870602711637

Epoch: 6| Step: 4
Training loss: 3.189643288880864
Validation loss: 2.710468762963157

Epoch: 6| Step: 5
Training loss: 3.340179961832775
Validation loss: 2.716207301336902

Epoch: 6| Step: 6
Training loss: 2.379638158395637
Validation loss: 2.7098977198789154

Epoch: 6| Step: 7
Training loss: 2.6546682697248514
Validation loss: 2.7115966396518383

Epoch: 6| Step: 8
Training loss: 3.178768840678457
Validation loss: 2.7239678109639263

Epoch: 6| Step: 9
Training loss: 2.9393168573065553
Validation loss: 2.713772177237442

Epoch: 6| Step: 10
Training loss: 3.0432670946492686
Validation loss: 2.710201344925888

Epoch: 6| Step: 11
Training loss: 3.204412136588126
Validation loss: 2.711860751308086

Epoch: 6| Step: 12
Training loss: 3.1487152507177494
Validation loss: 2.7033000801381637

Epoch: 6| Step: 13
Training loss: 1.3347132912843231
Validation loss: 2.6943700520987637

Epoch: 190| Step: 0
Training loss: 2.4616500549513516
Validation loss: 2.692542944890998

Epoch: 6| Step: 1
Training loss: 2.8882802990598924
Validation loss: 2.692915587957173

Epoch: 6| Step: 2
Training loss: 3.1380376833810226
Validation loss: 2.6922202985548727

Epoch: 6| Step: 3
Training loss: 3.054881370226547
Validation loss: 2.6946077775842974

Epoch: 6| Step: 4
Training loss: 3.226072703725333
Validation loss: 2.692556549787649

Epoch: 6| Step: 5
Training loss: 2.836771356404253
Validation loss: 2.692587095572231

Epoch: 6| Step: 6
Training loss: 2.8420545952725407
Validation loss: 2.692383269547711

Epoch: 6| Step: 7
Training loss: 3.0112820517741135
Validation loss: 2.690383480334719

Epoch: 6| Step: 8
Training loss: 3.609825733659809
Validation loss: 2.688848061518445

Epoch: 6| Step: 9
Training loss: 3.2710946013142252
Validation loss: 2.688647474290155

Epoch: 6| Step: 10
Training loss: 2.564722725380086
Validation loss: 2.6872295950453005

Epoch: 6| Step: 11
Training loss: 2.8824307155305546
Validation loss: 2.688725075183469

Epoch: 6| Step: 12
Training loss: 3.255756561907735
Validation loss: 2.6885740457221394

Epoch: 6| Step: 13
Training loss: 2.854769974776728
Validation loss: 2.6895854687216194

Epoch: 191| Step: 0
Training loss: 2.758969331776205
Validation loss: 2.690762414355884

Epoch: 6| Step: 1
Training loss: 3.5692895805385714
Validation loss: 2.6890212606739117

Epoch: 6| Step: 2
Training loss: 3.006299398734115
Validation loss: 2.6923255304770835

Epoch: 6| Step: 3
Training loss: 2.189449858173856
Validation loss: 2.696482541184707

Epoch: 6| Step: 4
Training loss: 2.9595924885639673
Validation loss: 2.7064323130278103

Epoch: 6| Step: 5
Training loss: 2.86174171765541
Validation loss: 2.7196519218693966

Epoch: 6| Step: 6
Training loss: 3.0240761725505023
Validation loss: 2.746601340751269

Epoch: 6| Step: 7
Training loss: 2.8861547597946564
Validation loss: 2.717103051229428

Epoch: 6| Step: 8
Training loss: 3.0585695852832937
Validation loss: 2.7038658322365268

Epoch: 6| Step: 9
Training loss: 3.3154689511205993
Validation loss: 2.694867858782492

Epoch: 6| Step: 10
Training loss: 3.244978914118884
Validation loss: 2.6944193440480304

Epoch: 6| Step: 11
Training loss: 3.3128195554515827
Validation loss: 2.6915983547679407

Epoch: 6| Step: 12
Training loss: 2.909457989583602
Validation loss: 2.69020264043102

Epoch: 6| Step: 13
Training loss: 2.728583780801414
Validation loss: 2.6868371453693647

Epoch: 192| Step: 0
Training loss: 3.1228954094758588
Validation loss: 2.686625485986184

Epoch: 6| Step: 1
Training loss: 3.2119629050995204
Validation loss: 2.689505489633529

Epoch: 6| Step: 2
Training loss: 3.191972623922793
Validation loss: 2.6865066978268937

Epoch: 6| Step: 3
Training loss: 3.1735258269496414
Validation loss: 2.68620268313024

Epoch: 6| Step: 4
Training loss: 3.258143126910942
Validation loss: 2.6868940663813636

Epoch: 6| Step: 5
Training loss: 2.5581558435194416
Validation loss: 2.684751965306659

Epoch: 6| Step: 6
Training loss: 2.4772481360340413
Validation loss: 2.6848223845963926

Epoch: 6| Step: 7
Training loss: 3.4003306059823757
Validation loss: 2.6843927444268245

Epoch: 6| Step: 8
Training loss: 2.9375982065220265
Validation loss: 2.686062857093804

Epoch: 6| Step: 9
Training loss: 3.26941457378434
Validation loss: 2.6884634499778977

Epoch: 6| Step: 10
Training loss: 3.324941626014846
Validation loss: 2.686916147672985

Epoch: 6| Step: 11
Training loss: 3.1180599206007944
Validation loss: 2.6894613779665084

Epoch: 6| Step: 12
Training loss: 2.167140493178809
Validation loss: 2.695752246349342

Epoch: 6| Step: 13
Training loss: 2.3902280390655934
Validation loss: 2.699930041670434

Epoch: 193| Step: 0
Training loss: 3.0944031305330806
Validation loss: 2.711428751522209

Epoch: 6| Step: 1
Training loss: 3.139435803938858
Validation loss: 2.7338809418739087

Epoch: 6| Step: 2
Training loss: 2.9781789320458465
Validation loss: 2.756680200100173

Epoch: 6| Step: 3
Training loss: 2.4607241583493034
Validation loss: 2.774983028961202

Epoch: 6| Step: 4
Training loss: 3.1009739238057206
Validation loss: 2.811672024101171

Epoch: 6| Step: 5
Training loss: 3.3692619147098894
Validation loss: 2.7906809088674636

Epoch: 6| Step: 6
Training loss: 3.293233731831919
Validation loss: 2.700713487086063

Epoch: 6| Step: 7
Training loss: 3.1473014050187826
Validation loss: 2.686177738554454

Epoch: 6| Step: 8
Training loss: 3.0294545942380133
Validation loss: 2.6876729703025095

Epoch: 6| Step: 9
Training loss: 2.9293583799508855
Validation loss: 2.6897408543315873

Epoch: 6| Step: 10
Training loss: 3.1156436471945423
Validation loss: 2.694463303188504

Epoch: 6| Step: 11
Training loss: 3.105043547688894
Validation loss: 2.7006430597316085

Epoch: 6| Step: 12
Training loss: 2.899714843936807
Validation loss: 2.7112019519737918

Epoch: 6| Step: 13
Training loss: 2.1887372468917774
Validation loss: 2.711747342663424

Epoch: 194| Step: 0
Training loss: 2.411533944995382
Validation loss: 2.7134872039613116

Epoch: 6| Step: 1
Training loss: 2.342191457713259
Validation loss: 2.714650609141462

Epoch: 6| Step: 2
Training loss: 2.9897320186489895
Validation loss: 2.7218562132563546

Epoch: 6| Step: 3
Training loss: 3.580877719456393
Validation loss: 2.7162850228195863

Epoch: 6| Step: 4
Training loss: 3.1553645638825727
Validation loss: 2.7050101569352014

Epoch: 6| Step: 5
Training loss: 2.9083923319285687
Validation loss: 2.7038377074432156

Epoch: 6| Step: 6
Training loss: 3.1576234454188934
Validation loss: 2.6964892010759542

Epoch: 6| Step: 7
Training loss: 2.730675510769668
Validation loss: 2.6949737331178705

Epoch: 6| Step: 8
Training loss: 3.289572778112684
Validation loss: 2.6938048914145183

Epoch: 6| Step: 9
Training loss: 3.0605532628463172
Validation loss: 2.6941004204251136

Epoch: 6| Step: 10
Training loss: 3.9495174547798055
Validation loss: 2.6942464310098666

Epoch: 6| Step: 11
Training loss: 3.0716958072278437
Validation loss: 2.6939434239314313

Epoch: 6| Step: 12
Training loss: 2.374536368641975
Validation loss: 2.6954907477696834

Epoch: 6| Step: 13
Training loss: 3.1160989261246215
Validation loss: 2.697286043635377

Epoch: 195| Step: 0
Training loss: 2.6423213408244406
Validation loss: 2.6967951599454576

Epoch: 6| Step: 1
Training loss: 2.774884601289948
Validation loss: 2.701188128024922

Epoch: 6| Step: 2
Training loss: 2.9733483289617038
Validation loss: 2.6997243723068505

Epoch: 6| Step: 3
Training loss: 3.3593491664159316
Validation loss: 2.70195762933975

Epoch: 6| Step: 4
Training loss: 3.2839239941442626
Validation loss: 2.7020220014412155

Epoch: 6| Step: 5
Training loss: 3.0605434473696507
Validation loss: 2.697822515628346

Epoch: 6| Step: 6
Training loss: 2.3667276773065913
Validation loss: 2.706529483887114

Epoch: 6| Step: 7
Training loss: 2.7702436943137347
Validation loss: 2.7047477904591926

Epoch: 6| Step: 8
Training loss: 3.0032367729163107
Validation loss: 2.7000425034599163

Epoch: 6| Step: 9
Training loss: 3.2195698703151807
Validation loss: 2.7007408888223634

Epoch: 6| Step: 10
Training loss: 2.9411381045812397
Validation loss: 2.6941729628259705

Epoch: 6| Step: 11
Training loss: 3.316699119549674
Validation loss: 2.6975171465685484

Epoch: 6| Step: 12
Training loss: 3.253796487447559
Validation loss: 2.7021948324634932

Epoch: 6| Step: 13
Training loss: 3.1676779353648414
Validation loss: 2.705667815617839

Epoch: 196| Step: 0
Training loss: 3.3619509734437467
Validation loss: 2.694520135408467

Epoch: 6| Step: 1
Training loss: 3.289307501359667
Validation loss: 2.702371695637962

Epoch: 6| Step: 2
Training loss: 2.8998500127481672
Validation loss: 2.6928305773208883

Epoch: 6| Step: 3
Training loss: 3.378615526690965
Validation loss: 2.691455087588197

Epoch: 6| Step: 4
Training loss: 3.013392437324293
Validation loss: 2.6893090323976048

Epoch: 6| Step: 5
Training loss: 2.839337289346896
Validation loss: 2.694155722585538

Epoch: 6| Step: 6
Training loss: 2.7093392093674824
Validation loss: 2.686753783016559

Epoch: 6| Step: 7
Training loss: 2.6083854580709454
Validation loss: 2.688809960097096

Epoch: 6| Step: 8
Training loss: 3.267592280163975
Validation loss: 2.6835747356152844

Epoch: 6| Step: 9
Training loss: 3.100599778512414
Validation loss: 2.6831978993474697

Epoch: 6| Step: 10
Training loss: 3.033001580453946
Validation loss: 2.6867093561339703

Epoch: 6| Step: 11
Training loss: 2.7551975550497816
Validation loss: 2.6840679617070733

Epoch: 6| Step: 12
Training loss: 2.4956325528789804
Validation loss: 2.680181854664246

Epoch: 6| Step: 13
Training loss: 3.277888147108753
Validation loss: 2.6803732058392

Epoch: 197| Step: 0
Training loss: 2.8575255035570555
Validation loss: 2.6814657712555365

Epoch: 6| Step: 1
Training loss: 2.7740053267204337
Validation loss: 2.6823781441689425

Epoch: 6| Step: 2
Training loss: 3.0849589281114853
Validation loss: 2.67841407321492

Epoch: 6| Step: 3
Training loss: 2.971522753003694
Validation loss: 2.679825716697345

Epoch: 6| Step: 4
Training loss: 2.889107630672718
Validation loss: 2.679396892302316

Epoch: 6| Step: 5
Training loss: 3.6773166024166564
Validation loss: 2.679334551426547

Epoch: 6| Step: 6
Training loss: 3.5800530848483283
Validation loss: 2.6874265381716613

Epoch: 6| Step: 7
Training loss: 2.6399892007722476
Validation loss: 2.6794490697970246

Epoch: 6| Step: 8
Training loss: 2.9262274489741706
Validation loss: 2.679945157802692

Epoch: 6| Step: 9
Training loss: 2.9541001097620394
Validation loss: 2.6809235035722265

Epoch: 6| Step: 10
Training loss: 3.0381586059394183
Validation loss: 2.6803967735987353

Epoch: 6| Step: 11
Training loss: 2.7724296350381543
Validation loss: 2.680542370528949

Epoch: 6| Step: 12
Training loss: 2.550870043857949
Validation loss: 2.681182494048623

Epoch: 6| Step: 13
Training loss: 3.3881371155863325
Validation loss: 2.679236920528606

Epoch: 198| Step: 0
Training loss: 2.6308071751502933
Validation loss: 2.6826637826329676

Epoch: 6| Step: 1
Training loss: 3.6114654432383926
Validation loss: 2.6820855779631954

Epoch: 6| Step: 2
Training loss: 3.234655395737667
Validation loss: 2.6782428568057655

Epoch: 6| Step: 3
Training loss: 3.4241604075247354
Validation loss: 2.6773304200193753

Epoch: 6| Step: 4
Training loss: 3.1766585936415392
Validation loss: 2.6779211077379688

Epoch: 6| Step: 5
Training loss: 2.9851442314331305
Validation loss: 2.6788725350207363

Epoch: 6| Step: 6
Training loss: 2.795990702885136
Validation loss: 2.679398892008647

Epoch: 6| Step: 7
Training loss: 2.312353387257457
Validation loss: 2.675180807664735

Epoch: 6| Step: 8
Training loss: 3.137883294390323
Validation loss: 2.677123098715295

Epoch: 6| Step: 9
Training loss: 2.735811216009532
Validation loss: 2.6781923797792877

Epoch: 6| Step: 10
Training loss: 3.1490305301837416
Validation loss: 2.67899105115428

Epoch: 6| Step: 11
Training loss: 2.75433857006671
Validation loss: 2.6779400828081688

Epoch: 6| Step: 12
Training loss: 3.00758008182798
Validation loss: 2.67605222260072

Epoch: 6| Step: 13
Training loss: 2.7493933095146743
Validation loss: 2.675223688619847

Epoch: 199| Step: 0
Training loss: 2.6795433606232164
Validation loss: 2.673846622878466

Epoch: 6| Step: 1
Training loss: 3.079844657646612
Validation loss: 2.67635692765783

Epoch: 6| Step: 2
Training loss: 3.2232455367946
Validation loss: 2.6749851653061767

Epoch: 6| Step: 3
Training loss: 2.955641224542954
Validation loss: 2.6738066019873323

Epoch: 6| Step: 4
Training loss: 2.4811120828498607
Validation loss: 2.6767278915469905

Epoch: 6| Step: 5
Training loss: 3.10273101856406
Validation loss: 2.6724352093099144

Epoch: 6| Step: 6
Training loss: 3.1734415329457235
Validation loss: 2.677968756247774

Epoch: 6| Step: 7
Training loss: 3.036115065332901
Validation loss: 2.6740793354498

Epoch: 6| Step: 8
Training loss: 2.61925440917318
Validation loss: 2.6729447298825306

Epoch: 6| Step: 9
Training loss: 2.749501443232997
Validation loss: 2.672757780875854

Epoch: 6| Step: 10
Training loss: 2.885258161871227
Validation loss: 2.6746068772743525

Epoch: 6| Step: 11
Training loss: 3.2576673004213266
Validation loss: 2.675739440519472

Epoch: 6| Step: 12
Training loss: 3.2973178367245453
Validation loss: 2.6807022490982013

Epoch: 6| Step: 13
Training loss: 3.59281325363572
Validation loss: 2.6809118439563515

Epoch: 200| Step: 0
Training loss: 3.1244607078607696
Validation loss: 2.6801428447303706

Epoch: 6| Step: 1
Training loss: 3.2317140109558578
Validation loss: 2.6867172520736773

Epoch: 6| Step: 2
Training loss: 2.832770647012253
Validation loss: 2.702595878226022

Epoch: 6| Step: 3
Training loss: 3.42691129273881
Validation loss: 2.7158907502909684

Epoch: 6| Step: 4
Training loss: 3.0719070758871827
Validation loss: 2.6948066834839044

Epoch: 6| Step: 5
Training loss: 2.932991951526585
Validation loss: 2.711289968305922

Epoch: 6| Step: 6
Training loss: 3.5495216477170985
Validation loss: 2.6791666529769054

Epoch: 6| Step: 7
Training loss: 2.3502081839691575
Validation loss: 2.673962937114225

Epoch: 6| Step: 8
Training loss: 2.5913970569888
Validation loss: 2.670660364944323

Epoch: 6| Step: 9
Training loss: 3.0185494745284167
Validation loss: 2.6694545935709324

Epoch: 6| Step: 10
Training loss: 2.8576211188438374
Validation loss: 2.6706099740286873

Epoch: 6| Step: 11
Training loss: 3.0871903978556787
Validation loss: 2.6722034136652217

Epoch: 6| Step: 12
Training loss: 2.7073187957457274
Validation loss: 2.6718734513807028

Epoch: 6| Step: 13
Training loss: 3.1076069314593346
Validation loss: 2.6731152441194834

Epoch: 201| Step: 0
Training loss: 2.4016385167537244
Validation loss: 2.6719803155200132

Epoch: 6| Step: 1
Training loss: 3.2542778618082795
Validation loss: 2.6704964522739068

Epoch: 6| Step: 2
Training loss: 3.2545767616482695
Validation loss: 2.6735127084713466

Epoch: 6| Step: 3
Training loss: 2.8900847058933703
Validation loss: 2.672485667492752

Epoch: 6| Step: 4
Training loss: 2.9791818542804704
Validation loss: 2.6741552917157043

Epoch: 6| Step: 5
Training loss: 3.0313055288990074
Validation loss: 2.6739556238200732

Epoch: 6| Step: 6
Training loss: 3.0131731096504732
Validation loss: 2.6717997863426683

Epoch: 6| Step: 7
Training loss: 3.2648486807138526
Validation loss: 2.672914201324827

Epoch: 6| Step: 8
Training loss: 2.320299039345689
Validation loss: 2.672824600919814

Epoch: 6| Step: 9
Training loss: 3.687936142813381
Validation loss: 2.6736139092290676

Epoch: 6| Step: 10
Training loss: 3.020500708496738
Validation loss: 2.6713161492135797

Epoch: 6| Step: 11
Training loss: 3.453978558162894
Validation loss: 2.672351094552443

Epoch: 6| Step: 12
Training loss: 2.350735642563464
Validation loss: 2.6761422284084206

Epoch: 6| Step: 13
Training loss: 2.543311217608942
Validation loss: 2.6730267898381306

Epoch: 202| Step: 0
Training loss: 2.919052801006847
Validation loss: 2.6764987042089343

Epoch: 6| Step: 1
Training loss: 2.7756206677511894
Validation loss: 2.6856511670815717

Epoch: 6| Step: 2
Training loss: 2.9457298408109227
Validation loss: 2.683180803564846

Epoch: 6| Step: 3
Training loss: 2.747398186030292
Validation loss: 2.6811611744545116

Epoch: 6| Step: 4
Training loss: 2.6657818478661373
Validation loss: 2.679359882157017

Epoch: 6| Step: 5
Training loss: 2.5750588419589135
Validation loss: 2.675654931406797

Epoch: 6| Step: 6
Training loss: 3.1984400284705443
Validation loss: 2.676435086054703

Epoch: 6| Step: 7
Training loss: 3.365499617739089
Validation loss: 2.6864838926933743

Epoch: 6| Step: 8
Training loss: 2.804526916837206
Validation loss: 2.674828362787775

Epoch: 6| Step: 9
Training loss: 3.313798182197278
Validation loss: 2.675035860980706

Epoch: 6| Step: 10
Training loss: 3.1571818571881334
Validation loss: 2.6819201783938604

Epoch: 6| Step: 11
Training loss: 3.33318392100849
Validation loss: 2.676068079262157

Epoch: 6| Step: 12
Training loss: 3.0492625736466175
Validation loss: 2.680049370857485

Epoch: 6| Step: 13
Training loss: 3.130979539227466
Validation loss: 2.676927695991814

Epoch: 203| Step: 0
Training loss: 3.763309510805761
Validation loss: 2.6794523687690295

Epoch: 6| Step: 1
Training loss: 3.174110864809938
Validation loss: 2.6785561553043045

Epoch: 6| Step: 2
Training loss: 2.2291796912647635
Validation loss: 2.678572186647182

Epoch: 6| Step: 3
Training loss: 3.1652109581425845
Validation loss: 2.67192479617142

Epoch: 6| Step: 4
Training loss: 3.4010502034771943
Validation loss: 2.6683856252443605

Epoch: 6| Step: 5
Training loss: 2.626836588377003
Validation loss: 2.671919757972108

Epoch: 6| Step: 6
Training loss: 1.6691527977054745
Validation loss: 2.6795747091577957

Epoch: 6| Step: 7
Training loss: 3.312086259446551
Validation loss: 2.6679186080510924

Epoch: 6| Step: 8
Training loss: 3.1613114064664343
Validation loss: 2.670059046586883

Epoch: 6| Step: 9
Training loss: 3.2328812102828346
Validation loss: 2.6684933726467905

Epoch: 6| Step: 10
Training loss: 3.221167536114092
Validation loss: 2.6692605772304114

Epoch: 6| Step: 11
Training loss: 2.8629568210214424
Validation loss: 2.671865291850078

Epoch: 6| Step: 12
Training loss: 2.4496318462681237
Validation loss: 2.6671659523893676

Epoch: 6| Step: 13
Training loss: 3.100109615233765
Validation loss: 2.6665962470149815

Epoch: 204| Step: 0
Training loss: 2.388887559412308
Validation loss: 2.669318200548246

Epoch: 6| Step: 1
Training loss: 3.53466348322386
Validation loss: 2.66646272766488

Epoch: 6| Step: 2
Training loss: 3.2109851694397182
Validation loss: 2.6701805087357307

Epoch: 6| Step: 3
Training loss: 3.3228309325316214
Validation loss: 2.6668598338377207

Epoch: 6| Step: 4
Training loss: 1.4443211635326627
Validation loss: 2.6692901775500544

Epoch: 6| Step: 5
Training loss: 3.0658746926816147
Validation loss: 2.6733797762129345

Epoch: 6| Step: 6
Training loss: 3.364198707980452
Validation loss: 2.676759789276641

Epoch: 6| Step: 7
Training loss: 3.024089417664477
Validation loss: 2.6775057257417596

Epoch: 6| Step: 8
Training loss: 2.9087144800500164
Validation loss: 2.6778930196772346

Epoch: 6| Step: 9
Training loss: 3.2641276892200777
Validation loss: 2.6752076659597717

Epoch: 6| Step: 10
Training loss: 3.5535479049835104
Validation loss: 2.6742093004138083

Epoch: 6| Step: 11
Training loss: 2.5958960054607334
Validation loss: 2.674124533951709

Epoch: 6| Step: 12
Training loss: 2.784388282478753
Validation loss: 2.668938399452564

Epoch: 6| Step: 13
Training loss: 2.71254917574839
Validation loss: 2.669371987303768

Epoch: 205| Step: 0
Training loss: 3.222588185834255
Validation loss: 2.6656258080930666

Epoch: 6| Step: 1
Training loss: 3.410636387394089
Validation loss: 2.665090766457224

Epoch: 6| Step: 2
Training loss: 2.8900393330890424
Validation loss: 2.6680059306527153

Epoch: 6| Step: 3
Training loss: 2.4740688152071217
Validation loss: 2.667276207673228

Epoch: 6| Step: 4
Training loss: 3.32204788633738
Validation loss: 2.6677571945814456

Epoch: 6| Step: 5
Training loss: 3.2547555023575816
Validation loss: 2.6648997854729735

Epoch: 6| Step: 6
Training loss: 3.65340032135558
Validation loss: 2.6662773404431284

Epoch: 6| Step: 7
Training loss: 2.7794447622943523
Validation loss: 2.666447430168787

Epoch: 6| Step: 8
Training loss: 2.5635209259554093
Validation loss: 2.6661994285047568

Epoch: 6| Step: 9
Training loss: 1.9522283097873456
Validation loss: 2.667917945020274

Epoch: 6| Step: 10
Training loss: 3.3888667597508517
Validation loss: 2.6689342652552956

Epoch: 6| Step: 11
Training loss: 2.8939641687881164
Validation loss: 2.6709356637546993

Epoch: 6| Step: 12
Training loss: 3.1088326906159147
Validation loss: 2.667808273611457

Epoch: 6| Step: 13
Training loss: 2.1846888326281517
Validation loss: 2.6711589259302584

Epoch: 206| Step: 0
Training loss: 2.3469808054310994
Validation loss: 2.6764948996908053

Epoch: 6| Step: 1
Training loss: 3.440145272359015
Validation loss: 2.6803157781050047

Epoch: 6| Step: 2
Training loss: 3.143328513677414
Validation loss: 2.6835764226888283

Epoch: 6| Step: 3
Training loss: 2.3738639523763974
Validation loss: 2.6847975207737442

Epoch: 6| Step: 4
Training loss: 2.4879217202484454
Validation loss: 2.6893968806162007

Epoch: 6| Step: 5
Training loss: 3.008628516539905
Validation loss: 2.6895487122077046

Epoch: 6| Step: 6
Training loss: 3.03929000042198
Validation loss: 2.680614179061938

Epoch: 6| Step: 7
Training loss: 3.6640947743114833
Validation loss: 2.6939192409706245

Epoch: 6| Step: 8
Training loss: 2.636084269726522
Validation loss: 2.6952481807140027

Epoch: 6| Step: 9
Training loss: 2.937555190846221
Validation loss: 2.6863012700116045

Epoch: 6| Step: 10
Training loss: 2.9645629267326434
Validation loss: 2.6786431062427942

Epoch: 6| Step: 11
Training loss: 2.7983478951392415
Validation loss: 2.6844056075196274

Epoch: 6| Step: 12
Training loss: 3.642743325258564
Validation loss: 2.676419335974598

Epoch: 6| Step: 13
Training loss: 3.1789102940077805
Validation loss: 2.666154822582689

Epoch: 207| Step: 0
Training loss: 3.024242993678658
Validation loss: 2.663028601942727

Epoch: 6| Step: 1
Training loss: 3.1988619091855286
Validation loss: 2.667056196229444

Epoch: 6| Step: 2
Training loss: 3.018565271384308
Validation loss: 2.663928901773086

Epoch: 6| Step: 3
Training loss: 2.659644616845461
Validation loss: 2.660374652314526

Epoch: 6| Step: 4
Training loss: 2.4633599846739855
Validation loss: 2.6631701812456754

Epoch: 6| Step: 5
Training loss: 2.83785601159638
Validation loss: 2.667392904528645

Epoch: 6| Step: 6
Training loss: 2.634333411778787
Validation loss: 2.665050523175863

Epoch: 6| Step: 7
Training loss: 3.409365847511489
Validation loss: 2.662845962553904

Epoch: 6| Step: 8
Training loss: 3.132747050146276
Validation loss: 2.663842175011196

Epoch: 6| Step: 9
Training loss: 3.326176175771588
Validation loss: 2.663040336006281

Epoch: 6| Step: 10
Training loss: 3.260355370933572
Validation loss: 2.664669511533495

Epoch: 6| Step: 11
Training loss: 2.84942931769213
Validation loss: 2.6631210916080605

Epoch: 6| Step: 12
Training loss: 3.2079826923008112
Validation loss: 2.663911190565002

Epoch: 6| Step: 13
Training loss: 2.5383030151673895
Validation loss: 2.670329063775682

Epoch: 208| Step: 0
Training loss: 2.9307398825996906
Validation loss: 2.667552458314034

Epoch: 6| Step: 1
Training loss: 3.1193055722568754
Validation loss: 2.6719370869967665

Epoch: 6| Step: 2
Training loss: 2.5406804490460897
Validation loss: 2.680842466615529

Epoch: 6| Step: 3
Training loss: 2.8405680198536065
Validation loss: 2.6804833052202026

Epoch: 6| Step: 4
Training loss: 2.9492161630783356
Validation loss: 2.6993767455386215

Epoch: 6| Step: 5
Training loss: 3.84172476161189
Validation loss: 2.6927952112831925

Epoch: 6| Step: 6
Training loss: 2.7206084816183873
Validation loss: 2.673861947074892

Epoch: 6| Step: 7
Training loss: 2.2167233089390193
Validation loss: 2.66619037949563

Epoch: 6| Step: 8
Training loss: 2.835009882941672
Validation loss: 2.6597408994188134

Epoch: 6| Step: 9
Training loss: 2.904779205598313
Validation loss: 2.6623284654342076

Epoch: 6| Step: 10
Training loss: 3.3069620443772347
Validation loss: 2.6597430430616313

Epoch: 6| Step: 11
Training loss: 3.4556490273898604
Validation loss: 2.662456490874022

Epoch: 6| Step: 12
Training loss: 3.166064723844301
Validation loss: 2.660464912916486

Epoch: 6| Step: 13
Training loss: 2.5167236772189283
Validation loss: 2.6593411453741442

Epoch: 209| Step: 0
Training loss: 2.266750187831024
Validation loss: 2.6587609407138393

Epoch: 6| Step: 1
Training loss: 3.35060244594811
Validation loss: 2.6585680330262424

Epoch: 6| Step: 2
Training loss: 3.134272741625477
Validation loss: 2.659224628299822

Epoch: 6| Step: 3
Training loss: 2.6292865812479564
Validation loss: 2.6566476079145716

Epoch: 6| Step: 4
Training loss: 2.880204672693245
Validation loss: 2.6553128311412735

Epoch: 6| Step: 5
Training loss: 3.8397267693428407
Validation loss: 2.6578961863687454

Epoch: 6| Step: 6
Training loss: 2.1117410458916512
Validation loss: 2.6566699328841024

Epoch: 6| Step: 7
Training loss: 3.251428730241799
Validation loss: 2.660593828746961

Epoch: 6| Step: 8
Training loss: 2.830420305562433
Validation loss: 2.6580764021683883

Epoch: 6| Step: 9
Training loss: 2.950816710614801
Validation loss: 2.6562682969719638

Epoch: 6| Step: 10
Training loss: 2.8014384287451417
Validation loss: 2.659398222070053

Epoch: 6| Step: 11
Training loss: 3.425280404968494
Validation loss: 2.6583719983720426

Epoch: 6| Step: 12
Training loss: 2.7856564707922264
Validation loss: 2.6595980251999594

Epoch: 6| Step: 13
Training loss: 3.3381708963849768
Validation loss: 2.6597936822652546

Epoch: 210| Step: 0
Training loss: 2.7901716831667205
Validation loss: 2.6599841118556338

Epoch: 6| Step: 1
Training loss: 3.370406946124297
Validation loss: 2.663467169899106

Epoch: 6| Step: 2
Training loss: 2.8707222003954445
Validation loss: 2.666794193843464

Epoch: 6| Step: 3
Training loss: 2.9845347736190653
Validation loss: 2.6718087060093625

Epoch: 6| Step: 4
Training loss: 2.3317676695551626
Validation loss: 2.68228515152698

Epoch: 6| Step: 5
Training loss: 3.5591771205592866
Validation loss: 2.7063478112801245

Epoch: 6| Step: 6
Training loss: 1.9156551041345689
Validation loss: 2.6918442906938593

Epoch: 6| Step: 7
Training loss: 3.2376583222667525
Validation loss: 2.673397594425045

Epoch: 6| Step: 8
Training loss: 3.136011483346584
Validation loss: 2.6634437603453467

Epoch: 6| Step: 9
Training loss: 2.755869497041342
Validation loss: 2.657582504110327

Epoch: 6| Step: 10
Training loss: 3.2037131165023376
Validation loss: 2.6564530451246533

Epoch: 6| Step: 11
Training loss: 3.3632652291194356
Validation loss: 2.6558893295463837

Epoch: 6| Step: 12
Training loss: 3.094396196176031
Validation loss: 2.6562136315227254

Epoch: 6| Step: 13
Training loss: 2.8118933129291905
Validation loss: 2.6598106710211247

Epoch: 211| Step: 0
Training loss: 3.312844888258747
Validation loss: 2.6587620341434284

Epoch: 6| Step: 1
Training loss: 3.354718338674044
Validation loss: 2.6563921915079143

Epoch: 6| Step: 2
Training loss: 2.298389584205892
Validation loss: 2.6602162349909633

Epoch: 6| Step: 3
Training loss: 3.132573220873035
Validation loss: 2.6578977508481665

Epoch: 6| Step: 4
Training loss: 3.0993692248552738
Validation loss: 2.658049084319122

Epoch: 6| Step: 5
Training loss: 2.9286303431203993
Validation loss: 2.662819947622964

Epoch: 6| Step: 6
Training loss: 2.695197680695222
Validation loss: 2.6608034987554476

Epoch: 6| Step: 7
Training loss: 3.157372605509133
Validation loss: 2.6613951969084995

Epoch: 6| Step: 8
Training loss: 3.3222484016308402
Validation loss: 2.6590804508268513

Epoch: 6| Step: 9
Training loss: 3.227475090373956
Validation loss: 2.6564253699110454

Epoch: 6| Step: 10
Training loss: 2.8349954180537473
Validation loss: 2.6554878159576054

Epoch: 6| Step: 11
Training loss: 2.9982469523018453
Validation loss: 2.660005757312279

Epoch: 6| Step: 12
Training loss: 2.7601810474723285
Validation loss: 2.6557351836180385

Epoch: 6| Step: 13
Training loss: 2.316195241957108
Validation loss: 2.663710615715077

Epoch: 212| Step: 0
Training loss: 3.726698770970525
Validation loss: 2.6740150384831276

Epoch: 6| Step: 1
Training loss: 2.8433648152488655
Validation loss: 2.667280567425842

Epoch: 6| Step: 2
Training loss: 2.9687082388098927
Validation loss: 2.663100208864679

Epoch: 6| Step: 3
Training loss: 2.8667938211614237
Validation loss: 2.667984126214296

Epoch: 6| Step: 4
Training loss: 3.0464655674425867
Validation loss: 2.6671188788863756

Epoch: 6| Step: 5
Training loss: 2.389725858855144
Validation loss: 2.6643623373614735

Epoch: 6| Step: 6
Training loss: 2.476850330461911
Validation loss: 2.674209797955031

Epoch: 6| Step: 7
Training loss: 3.243023794392149
Validation loss: 2.671597383655163

Epoch: 6| Step: 8
Training loss: 3.2512169540233558
Validation loss: 2.68026290585542

Epoch: 6| Step: 9
Training loss: 3.1153862129924623
Validation loss: 2.6784405171895633

Epoch: 6| Step: 10
Training loss: 2.6239877293055587
Validation loss: 2.6748087062372035

Epoch: 6| Step: 11
Training loss: 2.819035798531927
Validation loss: 2.6784455766230333

Epoch: 6| Step: 12
Training loss: 3.0625594775593936
Validation loss: 2.6782580993731853

Epoch: 6| Step: 13
Training loss: 3.2437208111870133
Validation loss: 2.672149185497977

Epoch: 213| Step: 0
Training loss: 2.328584766433323
Validation loss: 2.6682821278423874

Epoch: 6| Step: 1
Training loss: 2.4452756446279116
Validation loss: 2.6663655850067247

Epoch: 6| Step: 2
Training loss: 2.970216409010869
Validation loss: 2.6714324037681427

Epoch: 6| Step: 3
Training loss: 3.2790392012746805
Validation loss: 2.6598637146431607

Epoch: 6| Step: 4
Training loss: 3.4298115145218233
Validation loss: 2.6601645220611547

Epoch: 6| Step: 5
Training loss: 2.9889312635566916
Validation loss: 2.663623766350245

Epoch: 6| Step: 6
Training loss: 2.741470025691311
Validation loss: 2.6611818906471822

Epoch: 6| Step: 7
Training loss: 3.539063847354186
Validation loss: 2.655259594264599

Epoch: 6| Step: 8
Training loss: 2.6259594934830153
Validation loss: 2.6569362238955256

Epoch: 6| Step: 9
Training loss: 2.7313671025851636
Validation loss: 2.654080211562789

Epoch: 6| Step: 10
Training loss: 3.33456156672585
Validation loss: 2.65645858457205

Epoch: 6| Step: 11
Training loss: 3.0893026425490824
Validation loss: 2.6524329607170274

Epoch: 6| Step: 12
Training loss: 3.3942186850396894
Validation loss: 2.656294951761283

Epoch: 6| Step: 13
Training loss: 2.1048657857916475
Validation loss: 2.660020296745821

Epoch: 214| Step: 0
Training loss: 3.2794206151739713
Validation loss: 2.656852235993666

Epoch: 6| Step: 1
Training loss: 2.669123431842218
Validation loss: 2.6574515726115364

Epoch: 6| Step: 2
Training loss: 2.7784328980923148
Validation loss: 2.660049041914625

Epoch: 6| Step: 3
Training loss: 3.264700726847174
Validation loss: 2.6771627530638504

Epoch: 6| Step: 4
Training loss: 2.51770682113238
Validation loss: 2.6762626778332583

Epoch: 6| Step: 5
Training loss: 3.2089704070945246
Validation loss: 2.675501073377497

Epoch: 6| Step: 6
Training loss: 3.155040395874064
Validation loss: 2.668692953052332

Epoch: 6| Step: 7
Training loss: 2.7066870356327315
Validation loss: 2.662647535900664

Epoch: 6| Step: 8
Training loss: 2.7427420639550535
Validation loss: 2.656558678659285

Epoch: 6| Step: 9
Training loss: 2.94822552863586
Validation loss: 2.6495976572736923

Epoch: 6| Step: 10
Training loss: 2.6739591088545867
Validation loss: 2.650887802987001

Epoch: 6| Step: 11
Training loss: 3.608626118704958
Validation loss: 2.648655867805591

Epoch: 6| Step: 12
Training loss: 2.674890344814345
Validation loss: 2.653282526043759

Epoch: 6| Step: 13
Training loss: 3.647915331050353
Validation loss: 2.6501404271344913

Epoch: 215| Step: 0
Training loss: 3.060950841090838
Validation loss: 2.6536291522574795

Epoch: 6| Step: 1
Training loss: 2.7336070699004753
Validation loss: 2.6487570736290276

Epoch: 6| Step: 2
Training loss: 3.0948259428564233
Validation loss: 2.65131458112515

Epoch: 6| Step: 3
Training loss: 2.6825240445014864
Validation loss: 2.649537174503877

Epoch: 6| Step: 4
Training loss: 2.9262056132082526
Validation loss: 2.6520722438570514

Epoch: 6| Step: 5
Training loss: 3.0945883491639483
Validation loss: 2.648810578630158

Epoch: 6| Step: 6
Training loss: 3.1954957494443326
Validation loss: 2.649761883622492

Epoch: 6| Step: 7
Training loss: 3.376408883359928
Validation loss: 2.65082907594399

Epoch: 6| Step: 8
Training loss: 2.95069421907993
Validation loss: 2.6491293243603726

Epoch: 6| Step: 9
Training loss: 3.5234189593383443
Validation loss: 2.6482941902143735

Epoch: 6| Step: 10
Training loss: 2.248311999054574
Validation loss: 2.648109663790058

Epoch: 6| Step: 11
Training loss: 3.1241534803154107
Validation loss: 2.6490613153280242

Epoch: 6| Step: 12
Training loss: 2.861936328811474
Validation loss: 2.656607709103244

Epoch: 6| Step: 13
Training loss: 2.518381350211193
Validation loss: 2.651190609822243

Epoch: 216| Step: 0
Training loss: 3.8710686214181886
Validation loss: 2.669306512329571

Epoch: 6| Step: 1
Training loss: 2.859030614240012
Validation loss: 2.669680887335559

Epoch: 6| Step: 2
Training loss: 2.933548399959473
Validation loss: 2.671315735586312

Epoch: 6| Step: 3
Training loss: 2.8351826149121155
Validation loss: 2.680532148626226

Epoch: 6| Step: 4
Training loss: 2.88928719570547
Validation loss: 2.684957339793342

Epoch: 6| Step: 5
Training loss: 3.1582473629110295
Validation loss: 2.6625699279189474

Epoch: 6| Step: 6
Training loss: 2.50038716179361
Validation loss: 2.6665902498535123

Epoch: 6| Step: 7
Training loss: 3.1847119573298412
Validation loss: 2.662967859118596

Epoch: 6| Step: 8
Training loss: 3.016804360747543
Validation loss: 2.6558210495871806

Epoch: 6| Step: 9
Training loss: 2.7308062998279787
Validation loss: 2.6577083186826447

Epoch: 6| Step: 10
Training loss: 3.0226707570547937
Validation loss: 2.6538195740298396

Epoch: 6| Step: 11
Training loss: 2.6283318400776876
Validation loss: 2.650303730901323

Epoch: 6| Step: 12
Training loss: 2.7007352816791474
Validation loss: 2.649323031566212

Epoch: 6| Step: 13
Training loss: 3.344036054407714
Validation loss: 2.6527863448156306

Epoch: 217| Step: 0
Training loss: 3.071775907856623
Validation loss: 2.653553415633985

Epoch: 6| Step: 1
Training loss: 2.8269687206749494
Validation loss: 2.6532716464436956

Epoch: 6| Step: 2
Training loss: 3.1733434125061675
Validation loss: 2.650692929613633

Epoch: 6| Step: 3
Training loss: 2.8968108103203036
Validation loss: 2.648964351340927

Epoch: 6| Step: 4
Training loss: 3.304476828206592
Validation loss: 2.6513452123837467

Epoch: 6| Step: 5
Training loss: 3.0835037871662734
Validation loss: 2.6487346761583948

Epoch: 6| Step: 6
Training loss: 2.450828886921972
Validation loss: 2.65033145069232

Epoch: 6| Step: 7
Training loss: 3.4478531723092174
Validation loss: 2.650232464064583

Epoch: 6| Step: 8
Training loss: 2.3833217389373815
Validation loss: 2.650148709660427

Epoch: 6| Step: 9
Training loss: 3.029403910907214
Validation loss: 2.6523012868909266

Epoch: 6| Step: 10
Training loss: 3.0862486863471474
Validation loss: 2.652344628599899

Epoch: 6| Step: 11
Training loss: 2.4907947822242926
Validation loss: 2.653340813272789

Epoch: 6| Step: 12
Training loss: 2.9126581893987296
Validation loss: 2.651996704441643

Epoch: 6| Step: 13
Training loss: 3.6334535094751903
Validation loss: 2.6472865493308375

Epoch: 218| Step: 0
Training loss: 2.5086794866774476
Validation loss: 2.647545882739447

Epoch: 6| Step: 1
Training loss: 3.020253320894704
Validation loss: 2.661827488679428

Epoch: 6| Step: 2
Training loss: 2.7259884642638905
Validation loss: 2.6702425324035404

Epoch: 6| Step: 3
Training loss: 3.3121185083057525
Validation loss: 2.6739440191497077

Epoch: 6| Step: 4
Training loss: 2.614706292370393
Validation loss: 2.6704737484958474

Epoch: 6| Step: 5
Training loss: 3.5645414158585806
Validation loss: 2.6674090683182015

Epoch: 6| Step: 6
Training loss: 3.3296208848022366
Validation loss: 2.6643450177646693

Epoch: 6| Step: 7
Training loss: 2.582443781459611
Validation loss: 2.6623032461319607

Epoch: 6| Step: 8
Training loss: 3.4575285990229383
Validation loss: 2.6590940572477137

Epoch: 6| Step: 9
Training loss: 2.977051542062085
Validation loss: 2.6508292268129883

Epoch: 6| Step: 10
Training loss: 3.334985959139296
Validation loss: 2.646281320635901

Epoch: 6| Step: 11
Training loss: 2.9594938840421037
Validation loss: 2.6427276990760897

Epoch: 6| Step: 12
Training loss: 2.572120285852234
Validation loss: 2.6442726796370843

Epoch: 6| Step: 13
Training loss: 2.0241656668566197
Validation loss: 2.6383917249714877

Epoch: 219| Step: 0
Training loss: 2.965437476577484
Validation loss: 2.6415041994838417

Epoch: 6| Step: 1
Training loss: 3.6378900954562456
Validation loss: 2.643114761179343

Epoch: 6| Step: 2
Training loss: 2.3393602078556412
Validation loss: 2.649523614795357

Epoch: 6| Step: 3
Training loss: 2.946910960684947
Validation loss: 2.6459258488635826

Epoch: 6| Step: 4
Training loss: 2.74433071794883
Validation loss: 2.649885087821612

Epoch: 6| Step: 5
Training loss: 2.878429192156342
Validation loss: 2.6488640699687855

Epoch: 6| Step: 6
Training loss: 2.7314110959378133
Validation loss: 2.6499885781727506

Epoch: 6| Step: 7
Training loss: 3.0462364114451232
Validation loss: 2.6503827378770044

Epoch: 6| Step: 8
Training loss: 3.2420110079974376
Validation loss: 2.6484797153078294

Epoch: 6| Step: 9
Training loss: 2.816587571908946
Validation loss: 2.652499266347708

Epoch: 6| Step: 10
Training loss: 2.1882346963067296
Validation loss: 2.650976485367677

Epoch: 6| Step: 11
Training loss: 3.7169803287456644
Validation loss: 2.6607403272008145

Epoch: 6| Step: 12
Training loss: 2.9649045432872985
Validation loss: 2.647123456500736

Epoch: 6| Step: 13
Training loss: 3.178972993470201
Validation loss: 2.6403215096426464

Epoch: 220| Step: 0
Training loss: 3.68768620424998
Validation loss: 2.6395993600959606

Epoch: 6| Step: 1
Training loss: 1.9650435905377832
Validation loss: 2.6394674918601058

Epoch: 6| Step: 2
Training loss: 2.8814758675640517
Validation loss: 2.6388774209528036

Epoch: 6| Step: 3
Training loss: 3.5014814238926406
Validation loss: 2.637406436839344

Epoch: 6| Step: 4
Training loss: 3.0518098433064518
Validation loss: 2.6403861212356428

Epoch: 6| Step: 5
Training loss: 3.0364162819482234
Validation loss: 2.637677075246078

Epoch: 6| Step: 6
Training loss: 2.979511712284437
Validation loss: 2.640154545265339

Epoch: 6| Step: 7
Training loss: 3.0879178030903898
Validation loss: 2.639318015679361

Epoch: 6| Step: 8
Training loss: 3.2595339099040608
Validation loss: 2.640080773967439

Epoch: 6| Step: 9
Training loss: 2.930284932574267
Validation loss: 2.638483600404953

Epoch: 6| Step: 10
Training loss: 2.148021976862885
Validation loss: 2.641889040118271

Epoch: 6| Step: 11
Training loss: 3.0296324513919743
Validation loss: 2.644136143362428

Epoch: 6| Step: 12
Training loss: 2.7506724315767195
Validation loss: 2.63887281074728

Epoch: 6| Step: 13
Training loss: 2.9263182123146008
Validation loss: 2.638673422702226

Epoch: 221| Step: 0
Training loss: 3.2154970490233437
Validation loss: 2.6404917072251415

Epoch: 6| Step: 1
Training loss: 1.9649506496221323
Validation loss: 2.6433799776199884

Epoch: 6| Step: 2
Training loss: 3.38224297854515
Validation loss: 2.64717838617325

Epoch: 6| Step: 3
Training loss: 3.211312153809801
Validation loss: 2.650026910776402

Epoch: 6| Step: 4
Training loss: 3.0084647920439855
Validation loss: 2.6480381239478956

Epoch: 6| Step: 5
Training loss: 3.4356601299552976
Validation loss: 2.651697083394899

Epoch: 6| Step: 6
Training loss: 2.817038371221898
Validation loss: 2.6505298616468016

Epoch: 6| Step: 7
Training loss: 2.458826134205498
Validation loss: 2.6498272789413213

Epoch: 6| Step: 8
Training loss: 2.311391203772092
Validation loss: 2.6505326085449736

Epoch: 6| Step: 9
Training loss: 3.3046040986631615
Validation loss: 2.645271474802889

Epoch: 6| Step: 10
Training loss: 3.221070721470176
Validation loss: 2.6437289775880544

Epoch: 6| Step: 11
Training loss: 3.1849561525976657
Validation loss: 2.6443573957328668

Epoch: 6| Step: 12
Training loss: 2.9046319538651626
Validation loss: 2.641939777005822

Epoch: 6| Step: 13
Training loss: 2.7956466108374225
Validation loss: 2.638900954199689

Epoch: 222| Step: 0
Training loss: 1.6339634393549574
Validation loss: 2.642881916893085

Epoch: 6| Step: 1
Training loss: 3.4178177980059457
Validation loss: 2.6381487122614606

Epoch: 6| Step: 2
Training loss: 3.010178782074053
Validation loss: 2.6411185825407015

Epoch: 6| Step: 3
Training loss: 2.8062615613125743
Validation loss: 2.636635530860793

Epoch: 6| Step: 4
Training loss: 2.7674025518254655
Validation loss: 2.6384015922409025

Epoch: 6| Step: 5
Training loss: 2.9047664013961065
Validation loss: 2.637052910768507

Epoch: 6| Step: 6
Training loss: 2.7317054141890313
Validation loss: 2.6352090357784106

Epoch: 6| Step: 7
Training loss: 3.030286812883388
Validation loss: 2.6388693051204304

Epoch: 6| Step: 8
Training loss: 3.5138047316721766
Validation loss: 2.637511423810651

Epoch: 6| Step: 9
Training loss: 3.3927779855313913
Validation loss: 2.6360871833902415

Epoch: 6| Step: 10
Training loss: 3.0110156949336413
Validation loss: 2.641330592444025

Epoch: 6| Step: 11
Training loss: 3.1512608139294382
Validation loss: 2.6403531354891117

Epoch: 6| Step: 12
Training loss: 3.1813766903935154
Validation loss: 2.636585022494946

Epoch: 6| Step: 13
Training loss: 2.3014584436868675
Validation loss: 2.6382668121583293

Epoch: 223| Step: 0
Training loss: 2.3258473564699265
Validation loss: 2.6385630181518827

Epoch: 6| Step: 1
Training loss: 2.643564067101018
Validation loss: 2.6389397927300204

Epoch: 6| Step: 2
Training loss: 2.8689953667918062
Validation loss: 2.6385495968541

Epoch: 6| Step: 3
Training loss: 3.2065322246113017
Validation loss: 2.6365752505225224

Epoch: 6| Step: 4
Training loss: 3.494357192448352
Validation loss: 2.6353058930138196

Epoch: 6| Step: 5
Training loss: 2.632507849932466
Validation loss: 2.6365994236909747

Epoch: 6| Step: 6
Training loss: 3.214296092667552
Validation loss: 2.6409732778000206

Epoch: 6| Step: 7
Training loss: 2.7690614374466755
Validation loss: 2.6455539177621854

Epoch: 6| Step: 8
Training loss: 2.6931848061401977
Validation loss: 2.6444245485334212

Epoch: 6| Step: 9
Training loss: 3.297086012898759
Validation loss: 2.6494976137101807

Epoch: 6| Step: 10
Training loss: 2.9139314269177317
Validation loss: 2.6406646840093564

Epoch: 6| Step: 11
Training loss: 3.0079705531221057
Validation loss: 2.6502530308015073

Epoch: 6| Step: 12
Training loss: 2.98093203722374
Validation loss: 2.6553952506116727

Epoch: 6| Step: 13
Training loss: 3.5143297310087385
Validation loss: 2.6637208559730725

Epoch: 224| Step: 0
Training loss: 2.7265925801976123
Validation loss: 2.6501996221521504

Epoch: 6| Step: 1
Training loss: 3.4229127190060797
Validation loss: 2.6429519628392053

Epoch: 6| Step: 2
Training loss: 2.9783150227017092
Validation loss: 2.6381381191123534

Epoch: 6| Step: 3
Training loss: 2.465530807571858
Validation loss: 2.632074716626

Epoch: 6| Step: 4
Training loss: 2.7617484472855205
Validation loss: 2.638721296093945

Epoch: 6| Step: 5
Training loss: 2.6804111938167683
Validation loss: 2.634405949513613

Epoch: 6| Step: 6
Training loss: 2.994849552203254
Validation loss: 2.6360770691899504

Epoch: 6| Step: 7
Training loss: 3.082261148249892
Validation loss: 2.6376136404218244

Epoch: 6| Step: 8
Training loss: 2.8529143173128615
Validation loss: 2.6341491151613288

Epoch: 6| Step: 9
Training loss: 3.0568262598382843
Validation loss: 2.6356428027374226

Epoch: 6| Step: 10
Training loss: 3.1694368660074965
Validation loss: 2.637970253661227

Epoch: 6| Step: 11
Training loss: 3.1844253670824294
Validation loss: 2.637066057272226

Epoch: 6| Step: 12
Training loss: 3.006985320258075
Validation loss: 2.6364788439409264

Epoch: 6| Step: 13
Training loss: 3.2247318126740208
Validation loss: 2.6339645993089444

Epoch: 225| Step: 0
Training loss: 3.0953720926616897
Validation loss: 2.6339271872956616

Epoch: 6| Step: 1
Training loss: 1.9526811629491263
Validation loss: 2.635403333269721

Epoch: 6| Step: 2
Training loss: 3.24845673526502
Validation loss: 2.6395509247411804

Epoch: 6| Step: 3
Training loss: 3.0967999461728573
Validation loss: 2.6457068419763803

Epoch: 6| Step: 4
Training loss: 3.110203771508416
Validation loss: 2.6450423502924436

Epoch: 6| Step: 5
Training loss: 3.376952560186477
Validation loss: 2.652138861544902

Epoch: 6| Step: 6
Training loss: 2.823779482204202
Validation loss: 2.6590844885079323

Epoch: 6| Step: 7
Training loss: 2.634317754483254
Validation loss: 2.686758594930561

Epoch: 6| Step: 8
Training loss: 2.8818620805320467
Validation loss: 2.6829271286389744

Epoch: 6| Step: 9
Training loss: 3.116186913541444
Validation loss: 2.6738493486992176

Epoch: 6| Step: 10
Training loss: 2.622340171751063
Validation loss: 2.6631404156769394

Epoch: 6| Step: 11
Training loss: 3.66215182267066
Validation loss: 2.6555275732698758

Epoch: 6| Step: 12
Training loss: 2.3675325349950853
Validation loss: 2.6489982498967675

Epoch: 6| Step: 13
Training loss: 3.3981064909290066
Validation loss: 2.638210170344809

Epoch: 226| Step: 0
Training loss: 2.6886730738887525
Validation loss: 2.6348420631791747

Epoch: 6| Step: 1
Training loss: 3.402145572676258
Validation loss: 2.6332011733946232

Epoch: 6| Step: 2
Training loss: 2.412428812350367
Validation loss: 2.627677647578189

Epoch: 6| Step: 3
Training loss: 3.5710918485761183
Validation loss: 2.6315098402597235

Epoch: 6| Step: 4
Training loss: 2.5153716534343635
Validation loss: 2.630754841734381

Epoch: 6| Step: 5
Training loss: 3.1052967719675664
Validation loss: 2.6282987527925528

Epoch: 6| Step: 6
Training loss: 2.725954004281707
Validation loss: 2.6302033919697467

Epoch: 6| Step: 7
Training loss: 2.7395062937377888
Validation loss: 2.6301971588011104

Epoch: 6| Step: 8
Training loss: 3.415998874315706
Validation loss: 2.6300191666058974

Epoch: 6| Step: 9
Training loss: 3.7289473541954608
Validation loss: 2.629170241661509

Epoch: 6| Step: 10
Training loss: 2.5859269893928203
Validation loss: 2.631440841975175

Epoch: 6| Step: 11
Training loss: 3.368505516452018
Validation loss: 2.630626274310132

Epoch: 6| Step: 12
Training loss: 2.3204651856197582
Validation loss: 2.629362571280535

Epoch: 6| Step: 13
Training loss: 2.1688989241859478
Validation loss: 2.63005159086254

Epoch: 227| Step: 0
Training loss: 2.868088583233938
Validation loss: 2.6300325997556713

Epoch: 6| Step: 1
Training loss: 3.160184013706841
Validation loss: 2.631009555854315

Epoch: 6| Step: 2
Training loss: 3.0287888750894676
Validation loss: 2.6315854251298263

Epoch: 6| Step: 3
Training loss: 2.515241226397865
Validation loss: 2.633173089261562

Epoch: 6| Step: 4
Training loss: 3.2142658293578243
Validation loss: 2.630527187446436

Epoch: 6| Step: 5
Training loss: 2.8547258780603064
Validation loss: 2.632192112169626

Epoch: 6| Step: 6
Training loss: 3.2097973806540367
Validation loss: 2.636395700369474

Epoch: 6| Step: 7
Training loss: 3.090743945294721
Validation loss: 2.641077743448096

Epoch: 6| Step: 8
Training loss: 2.9333086345095167
Validation loss: 2.63093850401354

Epoch: 6| Step: 9
Training loss: 2.726862062978297
Validation loss: 2.641340169692015

Epoch: 6| Step: 10
Training loss: 2.433984617925983
Validation loss: 2.6391228319738373

Epoch: 6| Step: 11
Training loss: 3.016635231430349
Validation loss: 2.6401505320401215

Epoch: 6| Step: 12
Training loss: 3.4696315985368575
Validation loss: 2.638752805104315

Epoch: 6| Step: 13
Training loss: 2.7123847198600486
Validation loss: 2.6345957055699927

Epoch: 228| Step: 0
Training loss: 3.276263125908911
Validation loss: 2.6395037054848904

Epoch: 6| Step: 1
Training loss: 2.4988780365086276
Validation loss: 2.634150313210781

Epoch: 6| Step: 2
Training loss: 2.48205112236792
Validation loss: 2.629204269641336

Epoch: 6| Step: 3
Training loss: 2.9108957874301034
Validation loss: 2.629323905238307

Epoch: 6| Step: 4
Training loss: 3.2812511625741987
Validation loss: 2.630195965773873

Epoch: 6| Step: 5
Training loss: 3.0877559663870757
Validation loss: 2.6355825454108093

Epoch: 6| Step: 6
Training loss: 2.9898962904891633
Validation loss: 2.6287137309550292

Epoch: 6| Step: 7
Training loss: 2.7568606714374866
Validation loss: 2.6297385929474277

Epoch: 6| Step: 8
Training loss: 2.685813019482659
Validation loss: 2.627865546185261

Epoch: 6| Step: 9
Training loss: 2.8329648918995365
Validation loss: 2.637046293258623

Epoch: 6| Step: 10
Training loss: 2.9902165148878774
Validation loss: 2.6353309212404246

Epoch: 6| Step: 11
Training loss: 3.0125338667236154
Validation loss: 2.6411966160369476

Epoch: 6| Step: 12
Training loss: 3.469626650994317
Validation loss: 2.6328602462708446

Epoch: 6| Step: 13
Training loss: 3.0729830632337345
Validation loss: 2.6315330808875945

Epoch: 229| Step: 0
Training loss: 2.7214052235074155
Validation loss: 2.634135288404943

Epoch: 6| Step: 1
Training loss: 3.2001149991352547
Validation loss: 2.6487877063955194

Epoch: 6| Step: 2
Training loss: 3.4205287566987113
Validation loss: 2.647823280786784

Epoch: 6| Step: 3
Training loss: 2.8972976787718077
Validation loss: 2.6436686660170046

Epoch: 6| Step: 4
Training loss: 3.4130740622558076
Validation loss: 2.6458144810200093

Epoch: 6| Step: 5
Training loss: 2.5988396035839245
Validation loss: 2.6381944398549497

Epoch: 6| Step: 6
Training loss: 2.3340464819142586
Validation loss: 2.6379627492319715

Epoch: 6| Step: 7
Training loss: 3.0745013445201246
Validation loss: 2.6314898348013536

Epoch: 6| Step: 8
Training loss: 2.62523677303047
Validation loss: 2.6305207825452253

Epoch: 6| Step: 9
Training loss: 2.609975323176745
Validation loss: 2.6310545291246674

Epoch: 6| Step: 10
Training loss: 2.728296815895404
Validation loss: 2.628854058177334

Epoch: 6| Step: 11
Training loss: 3.475097210299694
Validation loss: 2.6326501299096763

Epoch: 6| Step: 12
Training loss: 3.1182874684415873
Validation loss: 2.6296316485480107

Epoch: 6| Step: 13
Training loss: 3.0582035054464733
Validation loss: 2.630976865697865

Epoch: 230| Step: 0
Training loss: 3.007952956846331
Validation loss: 2.6317370091795236

Epoch: 6| Step: 1
Training loss: 3.7511169041859556
Validation loss: 2.6251350403255502

Epoch: 6| Step: 2
Training loss: 3.01145480690249
Validation loss: 2.6253884121398428

Epoch: 6| Step: 3
Training loss: 3.0368605140706393
Validation loss: 2.627359044154653

Epoch: 6| Step: 4
Training loss: 3.089409605986557
Validation loss: 2.6275398528407328

Epoch: 6| Step: 5
Training loss: 2.157010151760952
Validation loss: 2.622111464252148

Epoch: 6| Step: 6
Training loss: 3.1585385929399092
Validation loss: 2.631233133787086

Epoch: 6| Step: 7
Training loss: 2.64037795858096
Validation loss: 2.625304034078876

Epoch: 6| Step: 8
Training loss: 2.1622035446266374
Validation loss: 2.625666646496394

Epoch: 6| Step: 9
Training loss: 2.9472253390946976
Validation loss: 2.630792679880602

Epoch: 6| Step: 10
Training loss: 3.0209816907209794
Validation loss: 2.6355992923955194

Epoch: 6| Step: 11
Training loss: 3.0683116654171974
Validation loss: 2.646530010875958

Epoch: 6| Step: 12
Training loss: 2.7285241882583056
Validation loss: 2.639491370472032

Epoch: 6| Step: 13
Training loss: 3.5522433754822074
Validation loss: 2.6455994737552317

Epoch: 231| Step: 0
Training loss: 2.9183839556190256
Validation loss: 2.640138668083396

Epoch: 6| Step: 1
Training loss: 2.925626417068826
Validation loss: 2.636059564724113

Epoch: 6| Step: 2
Training loss: 3.498914822876393
Validation loss: 2.627971350371303

Epoch: 6| Step: 3
Training loss: 2.9490394386197463
Validation loss: 2.6254407294917366

Epoch: 6| Step: 4
Training loss: 2.986194315694956
Validation loss: 2.6263994392099286

Epoch: 6| Step: 5
Training loss: 3.4162913015460266
Validation loss: 2.6277716614870563

Epoch: 6| Step: 6
Training loss: 2.637210783084375
Validation loss: 2.627474730207289

Epoch: 6| Step: 7
Training loss: 2.783214860857932
Validation loss: 2.6238962637374588

Epoch: 6| Step: 8
Training loss: 2.5926508585372003
Validation loss: 2.625290078710194

Epoch: 6| Step: 9
Training loss: 2.563882501340959
Validation loss: 2.6239044063413415

Epoch: 6| Step: 10
Training loss: 3.043927297578629
Validation loss: 2.624123315084147

Epoch: 6| Step: 11
Training loss: 3.0605552882582194
Validation loss: 2.6234503438258554

Epoch: 6| Step: 12
Training loss: 2.9355584079010812
Validation loss: 2.6236826373952367

Epoch: 6| Step: 13
Training loss: 3.0759875626827244
Validation loss: 2.62320546026092

Epoch: 232| Step: 0
Training loss: 3.0855273783051267
Validation loss: 2.6253164870173706

Epoch: 6| Step: 1
Training loss: 3.0373395335821023
Validation loss: 2.6236560826849553

Epoch: 6| Step: 2
Training loss: 2.656028289517873
Validation loss: 2.6311858246938042

Epoch: 6| Step: 3
Training loss: 2.3094813259151885
Validation loss: 2.6356044914581087

Epoch: 6| Step: 4
Training loss: 3.097694117734335
Validation loss: 2.6435237555278

Epoch: 6| Step: 5
Training loss: 3.34743147354696
Validation loss: 2.6488725819884915

Epoch: 6| Step: 6
Training loss: 3.4083130914387048
Validation loss: 2.63968038899082

Epoch: 6| Step: 7
Training loss: 2.426438198111411
Validation loss: 2.6434440227632634

Epoch: 6| Step: 8
Training loss: 2.6252216972101943
Validation loss: 2.645063238942791

Epoch: 6| Step: 9
Training loss: 3.0220212157418014
Validation loss: 2.6477371690057923

Epoch: 6| Step: 10
Training loss: 3.700622227904008
Validation loss: 2.6471772162941867

Epoch: 6| Step: 11
Training loss: 2.5873916087276125
Validation loss: 2.6501814061346414

Epoch: 6| Step: 12
Training loss: 2.687898207150556
Validation loss: 2.6430270371661773

Epoch: 6| Step: 13
Training loss: 3.130256199695549
Validation loss: 2.64539362637139

Epoch: 233| Step: 0
Training loss: 2.902326334802226
Validation loss: 2.658820558968545

Epoch: 6| Step: 1
Training loss: 3.0816413429695575
Validation loss: 2.6349974128586067

Epoch: 6| Step: 2
Training loss: 2.780191798832134
Validation loss: 2.6348527756337896

Epoch: 6| Step: 3
Training loss: 2.8130380751565154
Validation loss: 2.6317036373960123

Epoch: 6| Step: 4
Training loss: 3.33741802443509
Validation loss: 2.6309321147300073

Epoch: 6| Step: 5
Training loss: 1.9307122231758682
Validation loss: 2.6253146790135378

Epoch: 6| Step: 6
Training loss: 3.274434595586903
Validation loss: 2.627169308937243

Epoch: 6| Step: 7
Training loss: 2.7944902024041895
Validation loss: 2.6293494291605164

Epoch: 6| Step: 8
Training loss: 3.450429287061923
Validation loss: 2.636637967481399

Epoch: 6| Step: 9
Training loss: 2.5462147611671235
Validation loss: 2.633217714522598

Epoch: 6| Step: 10
Training loss: 3.0730412517228007
Validation loss: 2.634269495483472

Epoch: 6| Step: 11
Training loss: 2.7966916327864437
Validation loss: 2.6366373267262384

Epoch: 6| Step: 12
Training loss: 2.9937019997334415
Validation loss: 2.636385118652405

Epoch: 6| Step: 13
Training loss: 3.533223233816809
Validation loss: 2.6313048070602596

Epoch: 234| Step: 0
Training loss: 2.505633682232128
Validation loss: 2.6268696404029908

Epoch: 6| Step: 1
Training loss: 3.035728214135794
Validation loss: 2.6217199782682465

Epoch: 6| Step: 2
Training loss: 2.922903604040959
Validation loss: 2.6285934073159165

Epoch: 6| Step: 3
Training loss: 2.5566519087854984
Validation loss: 2.6287573250324203

Epoch: 6| Step: 4
Training loss: 2.7588743591625873
Validation loss: 2.6246472916229577

Epoch: 6| Step: 5
Training loss: 2.534301801910922
Validation loss: 2.6329623270063216

Epoch: 6| Step: 6
Training loss: 2.538139574600378
Validation loss: 2.6296390982728335

Epoch: 6| Step: 7
Training loss: 2.828592335567301
Validation loss: 2.6287238656843512

Epoch: 6| Step: 8
Training loss: 3.3223339434847983
Validation loss: 2.6297865168839083

Epoch: 6| Step: 9
Training loss: 3.3014662172979996
Validation loss: 2.641707852977624

Epoch: 6| Step: 10
Training loss: 3.712747297174396
Validation loss: 2.635509741431458

Epoch: 6| Step: 11
Training loss: 3.1497857399384377
Validation loss: 2.636930989208565

Epoch: 6| Step: 12
Training loss: 2.818634379314158
Validation loss: 2.6374124400955448

Epoch: 6| Step: 13
Training loss: 3.261975745395696
Validation loss: 2.642569098908025

Epoch: 235| Step: 0
Training loss: 3.3185066608076452
Validation loss: 2.6353229034396657

Epoch: 6| Step: 1
Training loss: 3.513411846791631
Validation loss: 2.630924256971595

Epoch: 6| Step: 2
Training loss: 2.4174932403627745
Validation loss: 2.624921757498355

Epoch: 6| Step: 3
Training loss: 3.080468849067967
Validation loss: 2.6289659982229776

Epoch: 6| Step: 4
Training loss: 3.151943781743495
Validation loss: 2.631375108573535

Epoch: 6| Step: 5
Training loss: 2.9660506977010708
Validation loss: 2.630352568390179

Epoch: 6| Step: 6
Training loss: 2.4650118569481605
Validation loss: 2.6204768352952494

Epoch: 6| Step: 7
Training loss: 2.5893718122627956
Validation loss: 2.620194017790941

Epoch: 6| Step: 8
Training loss: 2.671424515431868
Validation loss: 2.6200966048495413

Epoch: 6| Step: 9
Training loss: 3.215500311477639
Validation loss: 2.6288320538255845

Epoch: 6| Step: 10
Training loss: 2.9976796077467456
Validation loss: 2.627063994533149

Epoch: 6| Step: 11
Training loss: 2.731369633967922
Validation loss: 2.624560136169579

Epoch: 6| Step: 12
Training loss: 2.705748767555377
Validation loss: 2.629904666713553

Epoch: 6| Step: 13
Training loss: 3.5871324729736576
Validation loss: 2.6332221720418723

Epoch: 236| Step: 0
Training loss: 3.3830325295161088
Validation loss: 2.6277246100749045

Epoch: 6| Step: 1
Training loss: 3.680243772020623
Validation loss: 2.6276219541360915

Epoch: 6| Step: 2
Training loss: 3.0512712112058304
Validation loss: 2.6249553121893108

Epoch: 6| Step: 3
Training loss: 2.2659396249079604
Validation loss: 2.6222712978282496

Epoch: 6| Step: 4
Training loss: 2.6885152274281046
Validation loss: 2.632703463686833

Epoch: 6| Step: 5
Training loss: 2.51323344594584
Validation loss: 2.6232658279393064

Epoch: 6| Step: 6
Training loss: 3.207729101049179
Validation loss: 2.627182231670971

Epoch: 6| Step: 7
Training loss: 2.859680159497566
Validation loss: 2.619273818057354

Epoch: 6| Step: 8
Training loss: 3.4822026481665236
Validation loss: 2.623030448590131

Epoch: 6| Step: 9
Training loss: 2.329327266481415
Validation loss: 2.622457181905795

Epoch: 6| Step: 10
Training loss: 2.685654649826058
Validation loss: 2.626557282297708

Epoch: 6| Step: 11
Training loss: 2.2448586957679195
Validation loss: 2.630688026048665

Epoch: 6| Step: 12
Training loss: 3.1920644952095105
Validation loss: 2.6292536220079192

Epoch: 6| Step: 13
Training loss: 3.5224193785235514
Validation loss: 2.6279472724573525

Epoch: 237| Step: 0
Training loss: 3.048239378012177
Validation loss: 2.6319800908301647

Epoch: 6| Step: 1
Training loss: 2.785080575650588
Validation loss: 2.6233272838599655

Epoch: 6| Step: 2
Training loss: 2.566374292276292
Validation loss: 2.62284757554138

Epoch: 6| Step: 3
Training loss: 2.387923964959261
Validation loss: 2.624834142348807

Epoch: 6| Step: 4
Training loss: 3.2072004489661436
Validation loss: 2.623440173088864

Epoch: 6| Step: 5
Training loss: 3.094100469909713
Validation loss: 2.6216498148618355

Epoch: 6| Step: 6
Training loss: 3.041629599428107
Validation loss: 2.619284255533985

Epoch: 6| Step: 7
Training loss: 3.3539222644038817
Validation loss: 2.6222865294349615

Epoch: 6| Step: 8
Training loss: 3.099266605377946
Validation loss: 2.622869564612402

Epoch: 6| Step: 9
Training loss: 3.1866664918662733
Validation loss: 2.6200836652696657

Epoch: 6| Step: 10
Training loss: 2.7803289195542
Validation loss: 2.622498481063648

Epoch: 6| Step: 11
Training loss: 3.1232398607508842
Validation loss: 2.619644511885412

Epoch: 6| Step: 12
Training loss: 2.2162874552342067
Validation loss: 2.620006410504336

Epoch: 6| Step: 13
Training loss: 3.377804615167892
Validation loss: 2.623153125692559

Epoch: 238| Step: 0
Training loss: 2.5921447566430564
Validation loss: 2.6178391667843166

Epoch: 6| Step: 1
Training loss: 3.0100780327399477
Validation loss: 2.629241608450852

Epoch: 6| Step: 2
Training loss: 3.10357569929861
Validation loss: 2.6266803070822093

Epoch: 6| Step: 3
Training loss: 3.089248927910898
Validation loss: 2.640267030583094

Epoch: 6| Step: 4
Training loss: 2.7552167655560997
Validation loss: 2.6243657460695125

Epoch: 6| Step: 5
Training loss: 2.972643577759208
Validation loss: 2.6242931271692695

Epoch: 6| Step: 6
Training loss: 3.156845640877867
Validation loss: 2.620969799820287

Epoch: 6| Step: 7
Training loss: 3.1886621488389886
Validation loss: 2.615360267303148

Epoch: 6| Step: 8
Training loss: 2.550598044483192
Validation loss: 2.612830453289971

Epoch: 6| Step: 9
Training loss: 2.580711870234961
Validation loss: 2.6166361233326594

Epoch: 6| Step: 10
Training loss: 2.4716471802176345
Validation loss: 2.6159841401988335

Epoch: 6| Step: 11
Training loss: 2.886682739859125
Validation loss: 2.6144547721129645

Epoch: 6| Step: 12
Training loss: 3.1602860130573895
Validation loss: 2.617600903884483

Epoch: 6| Step: 13
Training loss: 4.06983426555636
Validation loss: 2.617011549056357

Epoch: 239| Step: 0
Training loss: 2.5759106923728092
Validation loss: 2.6232221743631707

Epoch: 6| Step: 1
Training loss: 2.3105417156403725
Validation loss: 2.623563841415921

Epoch: 6| Step: 2
Training loss: 3.510504082894026
Validation loss: 2.624594739657303

Epoch: 6| Step: 3
Training loss: 3.1696128859148742
Validation loss: 2.6214739072047823

Epoch: 6| Step: 4
Training loss: 2.7352818320503336
Validation loss: 2.6244367189482265

Epoch: 6| Step: 5
Training loss: 3.652675609505499
Validation loss: 2.6295937951576813

Epoch: 6| Step: 6
Training loss: 2.6702741322180064
Validation loss: 2.628613363622362

Epoch: 6| Step: 7
Training loss: 1.8892724109071053
Validation loss: 2.6284060191609258

Epoch: 6| Step: 8
Training loss: 2.820979581015926
Validation loss: 2.6312663955962954

Epoch: 6| Step: 9
Training loss: 3.037699808212934
Validation loss: 2.6393436381877766

Epoch: 6| Step: 10
Training loss: 2.9695250453146502
Validation loss: 2.6315654523942795

Epoch: 6| Step: 11
Training loss: 3.178020368295916
Validation loss: 2.6249156065235337

Epoch: 6| Step: 12
Training loss: 3.4301206971222125
Validation loss: 2.620620085421677

Epoch: 6| Step: 13
Training loss: 2.751402237322891
Validation loss: 2.618222140638149

Epoch: 240| Step: 0
Training loss: 3.0472103619023514
Validation loss: 2.6150399975137404

Epoch: 6| Step: 1
Training loss: 2.7528323413083164
Validation loss: 2.6148526371237373

Epoch: 6| Step: 2
Training loss: 3.0553045015561056
Validation loss: 2.6144018799473994

Epoch: 6| Step: 3
Training loss: 2.4632974601717956
Validation loss: 2.612289855994664

Epoch: 6| Step: 4
Training loss: 3.3964967294197392
Validation loss: 2.612608765339226

Epoch: 6| Step: 5
Training loss: 2.6393620105941378
Validation loss: 2.6165135423909027

Epoch: 6| Step: 6
Training loss: 3.407118240432032
Validation loss: 2.6171452226990755

Epoch: 6| Step: 7
Training loss: 3.295677220585347
Validation loss: 2.6211652232347395

Epoch: 6| Step: 8
Training loss: 3.0914476863772773
Validation loss: 2.6162586996393036

Epoch: 6| Step: 9
Training loss: 3.057404931400285
Validation loss: 2.615066898034301

Epoch: 6| Step: 10
Training loss: 3.0403820791564766
Validation loss: 2.614761954030685

Epoch: 6| Step: 11
Training loss: 2.435560090274642
Validation loss: 2.6079340038336656

Epoch: 6| Step: 12
Training loss: 2.5449793963544485
Validation loss: 2.6108865371521692

Epoch: 6| Step: 13
Training loss: 2.901647060561036
Validation loss: 2.614592576967601

Epoch: 241| Step: 0
Training loss: 3.0708047797343383
Validation loss: 2.620016670892615

Epoch: 6| Step: 1
Training loss: 2.469276565215748
Validation loss: 2.628725922467894

Epoch: 6| Step: 2
Training loss: 2.9607371561921267
Validation loss: 2.6267150534372807

Epoch: 6| Step: 3
Training loss: 3.0131223107044853
Validation loss: 2.6491435489783193

Epoch: 6| Step: 4
Training loss: 2.9294617426038174
Validation loss: 2.660456561327952

Epoch: 6| Step: 5
Training loss: 3.243058347371815
Validation loss: 2.684459369404195

Epoch: 6| Step: 6
Training loss: 2.915734678047465
Validation loss: 2.6943762947552656

Epoch: 6| Step: 7
Training loss: 2.7832999229329447
Validation loss: 2.6716375172850433

Epoch: 6| Step: 8
Training loss: 3.033113516363905
Validation loss: 2.6762702961455873

Epoch: 6| Step: 9
Training loss: 3.060022870395937
Validation loss: 2.6718990130791562

Epoch: 6| Step: 10
Training loss: 2.6968393617399213
Validation loss: 2.6635895871273725

Epoch: 6| Step: 11
Training loss: 3.256877518006682
Validation loss: 2.6508722521733126

Epoch: 6| Step: 12
Training loss: 2.8652605030868163
Validation loss: 2.6286481478181667

Epoch: 6| Step: 13
Training loss: 2.9769517538910697
Validation loss: 2.6170374888989283

Epoch: 242| Step: 0
Training loss: 2.884822155315272
Validation loss: 2.616900155669113

Epoch: 6| Step: 1
Training loss: 2.8883088601453686
Validation loss: 2.612048106189138

Epoch: 6| Step: 2
Training loss: 2.985662532104932
Validation loss: 2.615947650963411

Epoch: 6| Step: 3
Training loss: 3.3207042507864815
Validation loss: 2.6126213901612663

Epoch: 6| Step: 4
Training loss: 3.167039464455943
Validation loss: 2.61114590606453

Epoch: 6| Step: 5
Training loss: 2.844870210445852
Validation loss: 2.6145118167909427

Epoch: 6| Step: 6
Training loss: 2.9917785524434044
Validation loss: 2.61591767049201

Epoch: 6| Step: 7
Training loss: 3.069712029286953
Validation loss: 2.607014001125873

Epoch: 6| Step: 8
Training loss: 3.0338619030156635
Validation loss: 2.60793962471262

Epoch: 6| Step: 9
Training loss: 2.563065257181963
Validation loss: 2.61077835360806

Epoch: 6| Step: 10
Training loss: 3.0868471760489293
Validation loss: 2.6100850408159824

Epoch: 6| Step: 11
Training loss: 3.1112113399103754
Validation loss: 2.6117707247861466

Epoch: 6| Step: 12
Training loss: 2.4956868157874132
Validation loss: 2.618030895238399

Epoch: 6| Step: 13
Training loss: 2.5135840435437045
Validation loss: 2.6098965693468332

Epoch: 243| Step: 0
Training loss: 3.1644946898115824
Validation loss: 2.614221928746872

Epoch: 6| Step: 1
Training loss: 2.901107997352854
Validation loss: 2.614821091101796

Epoch: 6| Step: 2
Training loss: 2.736747018034852
Validation loss: 2.6244236029570582

Epoch: 6| Step: 3
Training loss: 2.535831684718336
Validation loss: 2.62132414727087

Epoch: 6| Step: 4
Training loss: 2.589258004026168
Validation loss: 2.6323496712158465

Epoch: 6| Step: 5
Training loss: 2.9694802440185892
Validation loss: 2.6335411442538197

Epoch: 6| Step: 6
Training loss: 3.04021614360379
Validation loss: 2.635731362915049

Epoch: 6| Step: 7
Training loss: 2.7834330360083
Validation loss: 2.6253757774280237

Epoch: 6| Step: 8
Training loss: 3.413103680434926
Validation loss: 2.6245395131491174

Epoch: 6| Step: 9
Training loss: 2.5320563268317184
Validation loss: 2.611815496839424

Epoch: 6| Step: 10
Training loss: 3.564366303523099
Validation loss: 2.6111440327766084

Epoch: 6| Step: 11
Training loss: 2.586344983590841
Validation loss: 2.6098772036894973

Epoch: 6| Step: 12
Training loss: 3.1272404078291416
Validation loss: 2.607704860620901

Epoch: 6| Step: 13
Training loss: 3.1890951914702685
Validation loss: 2.609948829874086

Epoch: 244| Step: 0
Training loss: 2.816654104471879
Validation loss: 2.610395472067751

Epoch: 6| Step: 1
Training loss: 3.2366543169764883
Validation loss: 2.6064022757167034

Epoch: 6| Step: 2
Training loss: 3.0143798471214494
Validation loss: 2.611364744560726

Epoch: 6| Step: 3
Training loss: 2.89832825981809
Validation loss: 2.6100158012649524

Epoch: 6| Step: 4
Training loss: 3.5124500094620172
Validation loss: 2.6128458301996225

Epoch: 6| Step: 5
Training loss: 3.0096582075453546
Validation loss: 2.613491219689466

Epoch: 6| Step: 6
Training loss: 2.937812626212468
Validation loss: 2.6107665535488573

Epoch: 6| Step: 7
Training loss: 3.094466617701876
Validation loss: 2.610442301578785

Epoch: 6| Step: 8
Training loss: 2.602203931576784
Validation loss: 2.608058256051638

Epoch: 6| Step: 9
Training loss: 2.9922952259083897
Validation loss: 2.607265738703526

Epoch: 6| Step: 10
Training loss: 2.908948732282984
Validation loss: 2.612049528335331

Epoch: 6| Step: 11
Training loss: 2.597087505289692
Validation loss: 2.6127536203691824

Epoch: 6| Step: 12
Training loss: 3.1399296992019066
Validation loss: 2.616067776184689

Epoch: 6| Step: 13
Training loss: 1.9363317967099734
Validation loss: 2.6178861569240386

Epoch: 245| Step: 0
Training loss: 3.3364497557518007
Validation loss: 2.620944916157999

Epoch: 6| Step: 1
Training loss: 3.3009820459450196
Validation loss: 2.6198829049971586

Epoch: 6| Step: 2
Training loss: 3.542758384440014
Validation loss: 2.6234524018122296

Epoch: 6| Step: 3
Training loss: 3.684884647132241
Validation loss: 2.614511331422231

Epoch: 6| Step: 4
Training loss: 2.3882201821178772
Validation loss: 2.617956741415191

Epoch: 6| Step: 5
Training loss: 2.6225960032270654
Validation loss: 2.620956872865465

Epoch: 6| Step: 6
Training loss: 2.5891449274583493
Validation loss: 2.6315280452408003

Epoch: 6| Step: 7
Training loss: 2.177708318580105
Validation loss: 2.632751635516181

Epoch: 6| Step: 8
Training loss: 3.034243806149844
Validation loss: 2.6342372477137572

Epoch: 6| Step: 9
Training loss: 2.5127919041748212
Validation loss: 2.621494768508909

Epoch: 6| Step: 10
Training loss: 2.6440064939341243
Validation loss: 2.61342694717762

Epoch: 6| Step: 11
Training loss: 3.1782260694908886
Validation loss: 2.608927060927362

Epoch: 6| Step: 12
Training loss: 2.868346767301721
Validation loss: 2.609173639289826

Epoch: 6| Step: 13
Training loss: 2.8728570000139753
Validation loss: 2.605110828822101

Epoch: 246| Step: 0
Training loss: 3.2137121385134226
Validation loss: 2.6069720515139005

Epoch: 6| Step: 1
Training loss: 3.5765479997880076
Validation loss: 2.6060309672687003

Epoch: 6| Step: 2
Training loss: 2.7877508760467484
Validation loss: 2.607712731326004

Epoch: 6| Step: 3
Training loss: 3.8927336956964256
Validation loss: 2.606095785663617

Epoch: 6| Step: 4
Training loss: 2.663609351495498
Validation loss: 2.605420650338235

Epoch: 6| Step: 5
Training loss: 2.4914534393559347
Validation loss: 2.6092040853543175

Epoch: 6| Step: 6
Training loss: 2.9764759922222437
Validation loss: 2.606387333903275

Epoch: 6| Step: 7
Training loss: 2.5580865954310696
Validation loss: 2.6096091324751116

Epoch: 6| Step: 8
Training loss: 3.202437164142835
Validation loss: 2.6071339145469548

Epoch: 6| Step: 9
Training loss: 2.299226037706393
Validation loss: 2.609828860134388

Epoch: 6| Step: 10
Training loss: 3.1013071257724056
Validation loss: 2.6097442078869624

Epoch: 6| Step: 11
Training loss: 2.455891015607572
Validation loss: 2.6121384418510996

Epoch: 6| Step: 12
Training loss: 3.010872213529836
Validation loss: 2.6124508557096235

Epoch: 6| Step: 13
Training loss: 2.052592903292796
Validation loss: 2.6127178935571878

Epoch: 247| Step: 0
Training loss: 2.668862948383798
Validation loss: 2.6201463626114188

Epoch: 6| Step: 1
Training loss: 3.395346452566952
Validation loss: 2.6145393895079905

Epoch: 6| Step: 2
Training loss: 2.8428346607006634
Validation loss: 2.6185733452174693

Epoch: 6| Step: 3
Training loss: 2.9708735851612382
Validation loss: 2.6206759755979703

Epoch: 6| Step: 4
Training loss: 2.860709624119133
Validation loss: 2.6214836112719757

Epoch: 6| Step: 5
Training loss: 2.688412976993934
Validation loss: 2.6237527703793613

Epoch: 6| Step: 6
Training loss: 3.4232480155567435
Validation loss: 2.640932933961126

Epoch: 6| Step: 7
Training loss: 3.034581506775629
Validation loss: 2.635130891128577

Epoch: 6| Step: 8
Training loss: 3.1314773568399574
Validation loss: 2.6428360453566624

Epoch: 6| Step: 9
Training loss: 2.7603838552768165
Validation loss: 2.662404617803346

Epoch: 6| Step: 10
Training loss: 3.02218089246851
Validation loss: 2.621572336837188

Epoch: 6| Step: 11
Training loss: 2.720236536287698
Validation loss: 2.6230066996527746

Epoch: 6| Step: 12
Training loss: 2.721613286046381
Validation loss: 2.614996625723627

Epoch: 6| Step: 13
Training loss: 2.750430160171133
Validation loss: 2.609916971154517

Epoch: 248| Step: 0
Training loss: 2.8483755200161625
Validation loss: 2.6093248933929596

Epoch: 6| Step: 1
Training loss: 2.8409446880537916
Validation loss: 2.60615240342051

Epoch: 6| Step: 2
Training loss: 2.8550893215764175
Validation loss: 2.6024571796112244

Epoch: 6| Step: 3
Training loss: 3.0048161630364376
Validation loss: 2.607169993202983

Epoch: 6| Step: 4
Training loss: 3.120381719273238
Validation loss: 2.605594505107387

Epoch: 6| Step: 5
Training loss: 2.851648449582256
Validation loss: 2.605676273664417

Epoch: 6| Step: 6
Training loss: 2.970309199412126
Validation loss: 2.6064488720640853

Epoch: 6| Step: 7
Training loss: 3.2399916969004545
Validation loss: 2.6058689899798355

Epoch: 6| Step: 8
Training loss: 3.27507484292277
Validation loss: 2.6059440667146108

Epoch: 6| Step: 9
Training loss: 3.0108145656540994
Validation loss: 2.611591085069344

Epoch: 6| Step: 10
Training loss: 3.322617392780299
Validation loss: 2.604597847630964

Epoch: 6| Step: 11
Training loss: 2.805949657654735
Validation loss: 2.606110770464154

Epoch: 6| Step: 12
Training loss: 2.3279898175413423
Validation loss: 2.6114764712493344

Epoch: 6| Step: 13
Training loss: 2.423857634162633
Validation loss: 2.609998461868599

Epoch: 249| Step: 0
Training loss: 2.5008504374740235
Validation loss: 2.6148977593523957

Epoch: 6| Step: 1
Training loss: 2.9877118534324265
Validation loss: 2.626248640381903

Epoch: 6| Step: 2
Training loss: 3.1902609442768353
Validation loss: 2.6335945144992765

Epoch: 6| Step: 3
Training loss: 2.880737550390267
Validation loss: 2.6413596633001974

Epoch: 6| Step: 4
Training loss: 2.894242780676586
Validation loss: 2.6569559036380372

Epoch: 6| Step: 5
Training loss: 3.0689565367643024
Validation loss: 2.6539635234074113

Epoch: 6| Step: 6
Training loss: 2.143443570048481
Validation loss: 2.6310066321826837

Epoch: 6| Step: 7
Training loss: 2.8878473906839126
Validation loss: 2.6301529589249437

Epoch: 6| Step: 8
Training loss: 2.8025021340517737
Validation loss: 2.6231105878161753

Epoch: 6| Step: 9
Training loss: 3.3499628264229333
Validation loss: 2.6181440069620905

Epoch: 6| Step: 10
Training loss: 3.335118785155364
Validation loss: 2.6172015612632693

Epoch: 6| Step: 11
Training loss: 2.634825075919572
Validation loss: 2.607192051567892

Epoch: 6| Step: 12
Training loss: 3.0603391848304162
Validation loss: 2.6056410293185035

Epoch: 6| Step: 13
Training loss: 3.3393682844125516
Validation loss: 2.5997240810691373

Epoch: 250| Step: 0
Training loss: 2.3211641643144834
Validation loss: 2.6050665034588203

Epoch: 6| Step: 1
Training loss: 2.571744479347282
Validation loss: 2.6028618662370606

Epoch: 6| Step: 2
Training loss: 2.801434769194572
Validation loss: 2.606633369643948

Epoch: 6| Step: 3
Training loss: 3.119561307338604
Validation loss: 2.6057352115904293

Epoch: 6| Step: 4
Training loss: 3.110175408326135
Validation loss: 2.6007803405356573

Epoch: 6| Step: 5
Training loss: 2.815355419670597
Validation loss: 2.601889605523912

Epoch: 6| Step: 6
Training loss: 3.3013285707933444
Validation loss: 2.6050373700598652

Epoch: 6| Step: 7
Training loss: 2.5193876950079694
Validation loss: 2.604123602398256

Epoch: 6| Step: 8
Training loss: 3.172670311651229
Validation loss: 2.6070474293472032

Epoch: 6| Step: 9
Training loss: 3.3441775039762147
Validation loss: 2.6059398670117733

Epoch: 6| Step: 10
Training loss: 3.177125990951245
Validation loss: 2.5977365532403556

Epoch: 6| Step: 11
Training loss: 2.787189271312347
Validation loss: 2.606614366263764

Epoch: 6| Step: 12
Training loss: 2.7756661071001045
Validation loss: 2.607833539637942

Epoch: 6| Step: 13
Training loss: 3.2495549704226177
Validation loss: 2.605078470062547

Epoch: 251| Step: 0
Training loss: 2.9617406716990744
Validation loss: 2.6062013453697044

Epoch: 6| Step: 1
Training loss: 2.9025468100651093
Validation loss: 2.61039806478138

Epoch: 6| Step: 2
Training loss: 2.346303134127557
Validation loss: 2.6070234856430035

Epoch: 6| Step: 3
Training loss: 2.2617870577444017
Validation loss: 2.6045405169163605

Epoch: 6| Step: 4
Training loss: 2.9765727526070145
Validation loss: 2.606428402782937

Epoch: 6| Step: 5
Training loss: 3.0829467187385924
Validation loss: 2.608469978489965

Epoch: 6| Step: 6
Training loss: 2.642095754373933
Validation loss: 2.6102977514027152

Epoch: 6| Step: 7
Training loss: 3.253075831442038
Validation loss: 2.601843972946086

Epoch: 6| Step: 8
Training loss: 2.4621014461301907
Validation loss: 2.6109216547221603

Epoch: 6| Step: 9
Training loss: 3.146361620335916
Validation loss: 2.605240822707581

Epoch: 6| Step: 10
Training loss: 3.0296768353546506
Validation loss: 2.611810033498419

Epoch: 6| Step: 11
Training loss: 2.931871256438634
Validation loss: 2.6134701601113273

Epoch: 6| Step: 12
Training loss: 3.6040340391831514
Validation loss: 2.6237502592587783

Epoch: 6| Step: 13
Training loss: 3.3304312152434217
Validation loss: 2.6193590588426785

Epoch: 252| Step: 0
Training loss: 3.6048408862592787
Validation loss: 2.6411368790220093

Epoch: 6| Step: 1
Training loss: 2.8816767577183464
Validation loss: 2.6561245767417523

Epoch: 6| Step: 2
Training loss: 2.945744409437523
Validation loss: 2.6612874809776987

Epoch: 6| Step: 3
Training loss: 2.5401530110085764
Validation loss: 2.651749160123928

Epoch: 6| Step: 4
Training loss: 3.0543729420142345
Validation loss: 2.6397720195143073

Epoch: 6| Step: 5
Training loss: 3.1472824666279404
Validation loss: 2.637665094223009

Epoch: 6| Step: 6
Training loss: 2.576124490182106
Validation loss: 2.6350390403543646

Epoch: 6| Step: 7
Training loss: 2.3832541134701852
Validation loss: 2.622760337801107

Epoch: 6| Step: 8
Training loss: 2.558932169889944
Validation loss: 2.6286719852497202

Epoch: 6| Step: 9
Training loss: 2.8924584425147417
Validation loss: 2.6249175632539083

Epoch: 6| Step: 10
Training loss: 3.032803953179369
Validation loss: 2.628554755317197

Epoch: 6| Step: 11
Training loss: 3.191315256266665
Validation loss: 2.6185636685471914

Epoch: 6| Step: 12
Training loss: 3.2301596478669605
Validation loss: 2.627033354374306

Epoch: 6| Step: 13
Training loss: 2.723376667264695
Validation loss: 2.6140044200231642

Epoch: 253| Step: 0
Training loss: 3.3445211216560025
Validation loss: 2.6107652092597906

Epoch: 6| Step: 1
Training loss: 3.402263303171353
Validation loss: 2.621074986436893

Epoch: 6| Step: 2
Training loss: 2.332071939749185
Validation loss: 2.6123218104089108

Epoch: 6| Step: 3
Training loss: 2.982567684304093
Validation loss: 2.6031798299800295

Epoch: 6| Step: 4
Training loss: 3.1788136924155945
Validation loss: 2.6044486459635774

Epoch: 6| Step: 5
Training loss: 2.755190718846301
Validation loss: 2.6010391421884465

Epoch: 6| Step: 6
Training loss: 2.851631728076619
Validation loss: 2.60235362052631

Epoch: 6| Step: 7
Training loss: 2.7950844600793463
Validation loss: 2.597921375478574

Epoch: 6| Step: 8
Training loss: 3.2681855744675383
Validation loss: 2.599371001379703

Epoch: 6| Step: 9
Training loss: 2.7827564403064264
Validation loss: 2.600874900886942

Epoch: 6| Step: 10
Training loss: 2.761020858188472
Validation loss: 2.6004085122820078

Epoch: 6| Step: 11
Training loss: 2.8584032752670883
Validation loss: 2.598201033664513

Epoch: 6| Step: 12
Training loss: 2.675822949606644
Validation loss: 2.613404509326098

Epoch: 6| Step: 13
Training loss: 2.748354939949723
Validation loss: 2.624216332874855

Epoch: 254| Step: 0
Training loss: 3.2376642133976494
Validation loss: 2.662844868394414

Epoch: 6| Step: 1
Training loss: 3.4770071366823565
Validation loss: 2.6897151209734798

Epoch: 6| Step: 2
Training loss: 2.891779158838242
Validation loss: 2.7432637254874654

Epoch: 6| Step: 3
Training loss: 2.694751537384492
Validation loss: 2.7267412143024647

Epoch: 6| Step: 4
Training loss: 3.1158204104439586
Validation loss: 2.7011412174951905

Epoch: 6| Step: 5
Training loss: 3.4437134507138425
Validation loss: 2.6897814139656226

Epoch: 6| Step: 6
Training loss: 2.8750623613311364
Validation loss: 2.6465405849654853

Epoch: 6| Step: 7
Training loss: 2.4500257996738286
Validation loss: 2.6182848517133075

Epoch: 6| Step: 8
Training loss: 2.8351837922117356
Validation loss: 2.602875314456985

Epoch: 6| Step: 9
Training loss: 2.7209398942987018
Validation loss: 2.6031149773854776

Epoch: 6| Step: 10
Training loss: 2.2328917375176545
Validation loss: 2.6034919683475586

Epoch: 6| Step: 11
Training loss: 3.1385925700738624
Validation loss: 2.606251648756078

Epoch: 6| Step: 12
Training loss: 3.0397691076835662
Validation loss: 2.6035981638579333

Epoch: 6| Step: 13
Training loss: 2.97135682346895
Validation loss: 2.605846971081142

Epoch: 255| Step: 0
Training loss: 3.059806573526343
Validation loss: 2.6050698060894857

Epoch: 6| Step: 1
Training loss: 2.685764018209945
Validation loss: 2.610677601165675

Epoch: 6| Step: 2
Training loss: 2.865982010129382
Validation loss: 2.611302098989989

Epoch: 6| Step: 3
Training loss: 2.56179316006314
Validation loss: 2.6138351841462617

Epoch: 6| Step: 4
Training loss: 3.2753438929190817
Validation loss: 2.6100755192957017

Epoch: 6| Step: 5
Training loss: 2.4064883820003447
Validation loss: 2.607227862949973

Epoch: 6| Step: 6
Training loss: 3.0241122811175765
Validation loss: 2.6099343032341626

Epoch: 6| Step: 7
Training loss: 3.187432082705505
Validation loss: 2.6102742067959377

Epoch: 6| Step: 8
Training loss: 2.7457196996983364
Validation loss: 2.6097042020255454

Epoch: 6| Step: 9
Training loss: 3.106093625712904
Validation loss: 2.606271460384711

Epoch: 6| Step: 10
Training loss: 2.8205737893755334
Validation loss: 2.6067112916923625

Epoch: 6| Step: 11
Training loss: 3.3842966114663064
Validation loss: 2.6053960206140285

Epoch: 6| Step: 12
Training loss: 2.786054597405902
Validation loss: 2.6059931778461536

Epoch: 6| Step: 13
Training loss: 3.5493421670396312
Validation loss: 2.6074246004539035

Epoch: 256| Step: 0
Training loss: 2.963283605798398
Validation loss: 2.60765002751385

Epoch: 6| Step: 1
Training loss: 2.703928128043487
Validation loss: 2.6100801651418943

Epoch: 6| Step: 2
Training loss: 2.386479791894149
Validation loss: 2.6073481293498313

Epoch: 6| Step: 3
Training loss: 2.956892244606797
Validation loss: 2.6115895340786737

Epoch: 6| Step: 4
Training loss: 2.720419535538741
Validation loss: 2.6192644317314278

Epoch: 6| Step: 5
Training loss: 2.7326359913762293
Validation loss: 2.616103138766484

Epoch: 6| Step: 6
Training loss: 3.2384950500516414
Validation loss: 2.623588516534504

Epoch: 6| Step: 7
Training loss: 3.3120309749573824
Validation loss: 2.6249590478408886

Epoch: 6| Step: 8
Training loss: 3.1609315805195903
Validation loss: 2.6298831146916215

Epoch: 6| Step: 9
Training loss: 3.091106942673204
Validation loss: 2.6299464240454653

Epoch: 6| Step: 10
Training loss: 2.5140292396028583
Validation loss: 2.6337308876671868

Epoch: 6| Step: 11
Training loss: 3.257946569670853
Validation loss: 2.638177595649698

Epoch: 6| Step: 12
Training loss: 2.739056225871219
Validation loss: 2.651793914588733

Epoch: 6| Step: 13
Training loss: 3.2997574341374714
Validation loss: 2.6358434135520197

Epoch: 257| Step: 0
Training loss: 2.529718006084397
Validation loss: 2.6262059095770534

Epoch: 6| Step: 1
Training loss: 2.4320045535898243
Validation loss: 2.619902386528776

Epoch: 6| Step: 2
Training loss: 2.784729484829796
Validation loss: 2.613505788356967

Epoch: 6| Step: 3
Training loss: 2.705009024388178
Validation loss: 2.6185133951045696

Epoch: 6| Step: 4
Training loss: 2.994027232034156
Validation loss: 2.6264594338192753

Epoch: 6| Step: 5
Training loss: 3.257583427151341
Validation loss: 2.6178616699410098

Epoch: 6| Step: 6
Training loss: 3.3801360433614
Validation loss: 2.621042865847146

Epoch: 6| Step: 7
Training loss: 3.1766660989585387
Validation loss: 2.6251697856491814

Epoch: 6| Step: 8
Training loss: 3.021666646439443
Validation loss: 2.626226860194693

Epoch: 6| Step: 9
Training loss: 2.755113009923319
Validation loss: 2.6199222446449224

Epoch: 6| Step: 10
Training loss: 3.3424664467016956
Validation loss: 2.6167679880388244

Epoch: 6| Step: 11
Training loss: 3.0062978126070505
Validation loss: 2.616659367230263

Epoch: 6| Step: 12
Training loss: 2.6190168222045145
Validation loss: 2.6189941870378646

Epoch: 6| Step: 13
Training loss: 2.7350188450974757
Validation loss: 2.6088767531156263

Epoch: 258| Step: 0
Training loss: 3.223100999140297
Validation loss: 2.6085071158156397

Epoch: 6| Step: 1
Training loss: 3.118889136259079
Validation loss: 2.6015561459819803

Epoch: 6| Step: 2
Training loss: 3.4709752823530113
Validation loss: 2.6030776848362303

Epoch: 6| Step: 3
Training loss: 2.4109126902482387
Validation loss: 2.5998903957815642

Epoch: 6| Step: 4
Training loss: 3.287939899442907
Validation loss: 2.60596091267877

Epoch: 6| Step: 5
Training loss: 2.6853645179564203
Validation loss: 2.6141896572683763

Epoch: 6| Step: 6
Training loss: 2.710248612264787
Validation loss: 2.6047092543552024

Epoch: 6| Step: 7
Training loss: 3.3766766374848127
Validation loss: 2.6205509755259726

Epoch: 6| Step: 8
Training loss: 2.847200249894708
Validation loss: 2.62128663015484

Epoch: 6| Step: 9
Training loss: 2.2042793874876723
Validation loss: 2.634501720125893

Epoch: 6| Step: 10
Training loss: 3.3623765887334645
Validation loss: 2.633032641709193

Epoch: 6| Step: 11
Training loss: 2.058624556888202
Validation loss: 2.663949914673418

Epoch: 6| Step: 12
Training loss: 2.7226140417168585
Validation loss: 2.6447948597618454

Epoch: 6| Step: 13
Training loss: 3.285242757667482
Validation loss: 2.6359969166703987

Epoch: 259| Step: 0
Training loss: 3.136241681789954
Validation loss: 2.6196604574968085

Epoch: 6| Step: 1
Training loss: 2.830411713646974
Validation loss: 2.622487844248974

Epoch: 6| Step: 2
Training loss: 2.7495194795580624
Validation loss: 2.6103914509013113

Epoch: 6| Step: 3
Training loss: 2.7463340599866886
Validation loss: 2.6054028582368924

Epoch: 6| Step: 4
Training loss: 3.2216505296213875
Validation loss: 2.6057934044129665

Epoch: 6| Step: 5
Training loss: 2.989528978941361
Validation loss: 2.610040949225723

Epoch: 6| Step: 6
Training loss: 2.7003023260891945
Validation loss: 2.6070587919341115

Epoch: 6| Step: 7
Training loss: 2.9987163976557265
Validation loss: 2.605029548350052

Epoch: 6| Step: 8
Training loss: 2.69581311870309
Validation loss: 2.60396272578557

Epoch: 6| Step: 9
Training loss: 3.5771949592166647
Validation loss: 2.6141337382512773

Epoch: 6| Step: 10
Training loss: 3.188807649349258
Validation loss: 2.623116318864014

Epoch: 6| Step: 11
Training loss: 2.8058832961247995
Validation loss: 2.611992001953101

Epoch: 6| Step: 12
Training loss: 2.5079188814505704
Validation loss: 2.6215689004875706

Epoch: 6| Step: 13
Training loss: 2.4934941516698252
Validation loss: 2.6323077922857427

Epoch: 260| Step: 0
Training loss: 2.344452612783817
Validation loss: 2.626565477166841

Epoch: 6| Step: 1
Training loss: 2.740377323176969
Validation loss: 2.6245839990085913

Epoch: 6| Step: 2
Training loss: 2.905401947000245
Validation loss: 2.634821136307494

Epoch: 6| Step: 3
Training loss: 3.5564188670741603
Validation loss: 2.6212843347678585

Epoch: 6| Step: 4
Training loss: 3.0189982310211265
Validation loss: 2.6337797804657908

Epoch: 6| Step: 5
Training loss: 3.184702674246381
Validation loss: 2.635841169745945

Epoch: 6| Step: 6
Training loss: 2.7846633025479273
Validation loss: 2.63544428072137

Epoch: 6| Step: 7
Training loss: 3.2960471609963666
Validation loss: 2.6301943643483896

Epoch: 6| Step: 8
Training loss: 3.0044979708165265
Validation loss: 2.6402436202048905

Epoch: 6| Step: 9
Training loss: 3.064946968155002
Validation loss: 2.6272681701853737

Epoch: 6| Step: 10
Training loss: 2.79057651319597
Validation loss: 2.6450212947691445

Epoch: 6| Step: 11
Training loss: 2.386997237869921
Validation loss: 2.647707617238568

Epoch: 6| Step: 12
Training loss: 2.8345775864110316
Validation loss: 2.6262748940919303

Epoch: 6| Step: 13
Training loss: 2.6585536167950465
Validation loss: 2.6226950700982283

Epoch: 261| Step: 0
Training loss: 2.604939969006285
Validation loss: 2.624519706574647

Epoch: 6| Step: 1
Training loss: 2.3555508373121277
Validation loss: 2.6334153899989134

Epoch: 6| Step: 2
Training loss: 3.3773422590645565
Validation loss: 2.6357299243672556

Epoch: 6| Step: 3
Training loss: 2.999196580753733
Validation loss: 2.622827388674902

Epoch: 6| Step: 4
Training loss: 2.842007952319945
Validation loss: 2.6185355214124524

Epoch: 6| Step: 5
Training loss: 3.220833113564652
Validation loss: 2.624083359426448

Epoch: 6| Step: 6
Training loss: 2.766779426973168
Validation loss: 2.6245907378037856

Epoch: 6| Step: 7
Training loss: 2.8785007558731857
Validation loss: 2.610139260958957

Epoch: 6| Step: 8
Training loss: 2.611905087719663
Validation loss: 2.607875741795518

Epoch: 6| Step: 9
Training loss: 2.994166742996001
Validation loss: 2.6014595842832984

Epoch: 6| Step: 10
Training loss: 3.00586572042865
Validation loss: 2.5985285130046982

Epoch: 6| Step: 11
Training loss: 3.1145182488997385
Validation loss: 2.5977798352329757

Epoch: 6| Step: 12
Training loss: 2.997290977590548
Validation loss: 2.5957588939125866

Epoch: 6| Step: 13
Training loss: 2.9943377783875857
Validation loss: 2.5983785405517197

Epoch: 262| Step: 0
Training loss: 2.7973948586949398
Validation loss: 2.595992833357028

Epoch: 6| Step: 1
Training loss: 3.384114144963579
Validation loss: 2.5966435657662443

Epoch: 6| Step: 2
Training loss: 2.8907777488146666
Validation loss: 2.5870486868091445

Epoch: 6| Step: 3
Training loss: 3.506912489809468
Validation loss: 2.60290933753248

Epoch: 6| Step: 4
Training loss: 3.0382045917644285
Validation loss: 2.605118066729399

Epoch: 6| Step: 5
Training loss: 2.4821823328687915
Validation loss: 2.5982862020955455

Epoch: 6| Step: 6
Training loss: 2.9228047406352484
Validation loss: 2.607963977782747

Epoch: 6| Step: 7
Training loss: 2.673648357269534
Validation loss: 2.6274283789251207

Epoch: 6| Step: 8
Training loss: 3.04833260907609
Validation loss: 2.6545531516574665

Epoch: 6| Step: 9
Training loss: 2.8202240737198117
Validation loss: 2.6887103286498184

Epoch: 6| Step: 10
Training loss: 2.5629735369557083
Validation loss: 2.7519991041820777

Epoch: 6| Step: 11
Training loss: 2.886052985325537
Validation loss: 2.725465453640018

Epoch: 6| Step: 12
Training loss: 3.215703318599518
Validation loss: 2.71437449088026

Epoch: 6| Step: 13
Training loss: 2.744530700978898
Validation loss: 2.6552518461535817

Epoch: 263| Step: 0
Training loss: 2.8062040431416215
Validation loss: 2.6105460298238206

Epoch: 6| Step: 1
Training loss: 3.1593540149448347
Validation loss: 2.595631112620346

Epoch: 6| Step: 2
Training loss: 3.3032924873092706
Validation loss: 2.5928445998349385

Epoch: 6| Step: 3
Training loss: 2.9373090966059237
Validation loss: 2.5937042271824944

Epoch: 6| Step: 4
Training loss: 3.07601453590679
Validation loss: 2.6006870148549512

Epoch: 6| Step: 5
Training loss: 3.285057692347765
Validation loss: 2.6144452782735743

Epoch: 6| Step: 6
Training loss: 2.922407785075188
Validation loss: 2.6170042720418762

Epoch: 6| Step: 7
Training loss: 3.032221687546403
Validation loss: 2.608985837963784

Epoch: 6| Step: 8
Training loss: 2.9428211471853483
Validation loss: 2.6091252198143273

Epoch: 6| Step: 9
Training loss: 2.7946269628158973
Validation loss: 2.6149940346282925

Epoch: 6| Step: 10
Training loss: 2.7619425940545512
Validation loss: 2.605062458813059

Epoch: 6| Step: 11
Training loss: 2.336086612905092
Validation loss: 2.5979805564338143

Epoch: 6| Step: 12
Training loss: 2.5843118127111913
Validation loss: 2.5949491587023106

Epoch: 6| Step: 13
Training loss: 3.795754098466521
Validation loss: 2.5983526255744853

Epoch: 264| Step: 0
Training loss: 2.9674622001265134
Validation loss: 2.597678624032957

Epoch: 6| Step: 1
Training loss: 3.22936239982437
Validation loss: 2.59788497101683

Epoch: 6| Step: 2
Training loss: 2.644617797697512
Validation loss: 2.607335692357865

Epoch: 6| Step: 3
Training loss: 2.7831059810349235
Validation loss: 2.6366750308673255

Epoch: 6| Step: 4
Training loss: 3.5464859131474524
Validation loss: 2.672214614325149

Epoch: 6| Step: 5
Training loss: 2.6929225774911942
Validation loss: 2.7280529426594975

Epoch: 6| Step: 6
Training loss: 3.4511265560125777
Validation loss: 2.834387952728818

Epoch: 6| Step: 7
Training loss: 3.3651031627967436
Validation loss: 2.829955118983616

Epoch: 6| Step: 8
Training loss: 2.5235315075066254
Validation loss: 2.784958357584059

Epoch: 6| Step: 9
Training loss: 3.057738826528879
Validation loss: 2.740134079771431

Epoch: 6| Step: 10
Training loss: 2.8434052310751396
Validation loss: 2.65748131025375

Epoch: 6| Step: 11
Training loss: 2.972898135075133
Validation loss: 2.626386451129695

Epoch: 6| Step: 12
Training loss: 2.685433591360695
Validation loss: 2.5999915406031913

Epoch: 6| Step: 13
Training loss: 2.2922934166400233
Validation loss: 2.590193073742894

Epoch: 265| Step: 0
Training loss: 2.077771838015919
Validation loss: 2.5954595092356945

Epoch: 6| Step: 1
Training loss: 3.19074697233345
Validation loss: 2.5938953794302178

Epoch: 6| Step: 2
Training loss: 3.015752760004151
Validation loss: 2.599637685635946

Epoch: 6| Step: 3
Training loss: 3.0910916707993565
Validation loss: 2.606847674749824

Epoch: 6| Step: 4
Training loss: 2.547459260354619
Validation loss: 2.60459503653995

Epoch: 6| Step: 5
Training loss: 2.86758411792939
Validation loss: 2.607952177768609

Epoch: 6| Step: 6
Training loss: 3.1712730099539064
Validation loss: 2.6128204973010334

Epoch: 6| Step: 7
Training loss: 2.710920262350636
Validation loss: 2.6115049948589966

Epoch: 6| Step: 8
Training loss: 3.677182002630377
Validation loss: 2.6110642935770128

Epoch: 6| Step: 9
Training loss: 3.552761755151503
Validation loss: 2.607507192547719

Epoch: 6| Step: 10
Training loss: 2.4952850703366285
Validation loss: 2.60148529289966

Epoch: 6| Step: 11
Training loss: 3.239233376264477
Validation loss: 2.5979795775458148

Epoch: 6| Step: 12
Training loss: 2.9342579908675743
Validation loss: 2.5953628520831566

Epoch: 6| Step: 13
Training loss: 2.450793865586055
Validation loss: 2.595171358453069

Epoch: 266| Step: 0
Training loss: 2.941272018226991
Validation loss: 2.590500485352275

Epoch: 6| Step: 1
Training loss: 3.2310259152892904
Validation loss: 2.59097553612239

Epoch: 6| Step: 2
Training loss: 2.871592285054916
Validation loss: 2.589266005062733

Epoch: 6| Step: 3
Training loss: 2.6580452630384848
Validation loss: 2.591668343428883

Epoch: 6| Step: 4
Training loss: 2.8496945468444403
Validation loss: 2.592773473095498

Epoch: 6| Step: 5
Training loss: 2.723527853643868
Validation loss: 2.5890552460818643

Epoch: 6| Step: 6
Training loss: 3.7031298931105594
Validation loss: 2.5889316275913643

Epoch: 6| Step: 7
Training loss: 2.570564234502537
Validation loss: 2.5857407129717176

Epoch: 6| Step: 8
Training loss: 3.001215370674333
Validation loss: 2.586569712476507

Epoch: 6| Step: 9
Training loss: 2.945772089629564
Validation loss: 2.585886069294646

Epoch: 6| Step: 10
Training loss: 2.638080160685816
Validation loss: 2.5904986268238295

Epoch: 6| Step: 11
Training loss: 2.8370144063041254
Validation loss: 2.5908540397028776

Epoch: 6| Step: 12
Training loss: 2.917267619393048
Validation loss: 2.5892658139728026

Epoch: 6| Step: 13
Training loss: 3.152549160264712
Validation loss: 2.592580910121004

Epoch: 267| Step: 0
Training loss: 2.2728184647037994
Validation loss: 2.599554057525936

Epoch: 6| Step: 1
Training loss: 2.692319053584011
Validation loss: 2.608143710051976

Epoch: 6| Step: 2
Training loss: 3.08188426703145
Validation loss: 2.6203741693549083

Epoch: 6| Step: 3
Training loss: 3.391540403773012
Validation loss: 2.640281479663989

Epoch: 6| Step: 4
Training loss: 3.2131354983621465
Validation loss: 2.6443136981868056

Epoch: 6| Step: 5
Training loss: 3.638690221538557
Validation loss: 2.6421665740990234

Epoch: 6| Step: 6
Training loss: 2.9736680904106074
Validation loss: 2.6457530881459537

Epoch: 6| Step: 7
Training loss: 2.9744511522779455
Validation loss: 2.6607333860908393

Epoch: 6| Step: 8
Training loss: 2.434373268450022
Validation loss: 2.6470764333395382

Epoch: 6| Step: 9
Training loss: 2.583527793538392
Validation loss: 2.658015919432376

Epoch: 6| Step: 10
Training loss: 3.15145176932704
Validation loss: 2.6598147307259126

Epoch: 6| Step: 11
Training loss: 3.1089641357100515
Validation loss: 2.6765513481465883

Epoch: 6| Step: 12
Training loss: 2.7419036979208213
Validation loss: 2.6614662024040885

Epoch: 6| Step: 13
Training loss: 2.0685917450916524
Validation loss: 2.650996170670549

Epoch: 268| Step: 0
Training loss: 2.7482539616079693
Validation loss: 2.620372126072076

Epoch: 6| Step: 1
Training loss: 2.7334946441346726
Validation loss: 2.598097902894381

Epoch: 6| Step: 2
Training loss: 3.2031747209365085
Validation loss: 2.598214300776461

Epoch: 6| Step: 3
Training loss: 2.6986729998997996
Validation loss: 2.587695435902113

Epoch: 6| Step: 4
Training loss: 3.1438883817335683
Validation loss: 2.5831182388988876

Epoch: 6| Step: 5
Training loss: 3.088240833437784
Validation loss: 2.5865391466733465

Epoch: 6| Step: 6
Training loss: 3.387345798262533
Validation loss: 2.585061799703826

Epoch: 6| Step: 7
Training loss: 2.8974571523715587
Validation loss: 2.5848489117054623

Epoch: 6| Step: 8
Training loss: 2.1980547628062888
Validation loss: 2.585805896721092

Epoch: 6| Step: 9
Training loss: 3.2916343944915134
Validation loss: 2.584569750924665

Epoch: 6| Step: 10
Training loss: 2.451491474122003
Validation loss: 2.5882354436022257

Epoch: 6| Step: 11
Training loss: 2.8392251034802474
Validation loss: 2.5842307143417784

Epoch: 6| Step: 12
Training loss: 3.2649309068645116
Validation loss: 2.584707974763026

Epoch: 6| Step: 13
Training loss: 2.6009116518532207
Validation loss: 2.5810168512313645

Epoch: 269| Step: 0
Training loss: 3.220860354239033
Validation loss: 2.587126770653211

Epoch: 6| Step: 1
Training loss: 2.761706145822988
Validation loss: 2.588319084313621

Epoch: 6| Step: 2
Training loss: 2.644630419000089
Validation loss: 2.5920333350747367

Epoch: 6| Step: 3
Training loss: 3.2307934672805465
Validation loss: 2.5890871674313396

Epoch: 6| Step: 4
Training loss: 2.664770753744762
Validation loss: 2.591743625283917

Epoch: 6| Step: 5
Training loss: 2.9956420398771115
Validation loss: 2.5905814210924007

Epoch: 6| Step: 6
Training loss: 3.3937443741950233
Validation loss: 2.5950017291454937

Epoch: 6| Step: 7
Training loss: 2.85919705863891
Validation loss: 2.5984040645685123

Epoch: 6| Step: 8
Training loss: 2.8634909101594714
Validation loss: 2.5949650821869175

Epoch: 6| Step: 9
Training loss: 2.8395240320369934
Validation loss: 2.5989559850169

Epoch: 6| Step: 10
Training loss: 2.7250543921405517
Validation loss: 2.600231503836158

Epoch: 6| Step: 11
Training loss: 2.8308747975574264
Validation loss: 2.6033368228617277

Epoch: 6| Step: 12
Training loss: 3.3408738360317125
Validation loss: 2.6051128324106885

Epoch: 6| Step: 13
Training loss: 1.7399900117127067
Validation loss: 2.6116120400409715

Epoch: 270| Step: 0
Training loss: 2.9243920240499817
Validation loss: 2.6187779351785414

Epoch: 6| Step: 1
Training loss: 2.33028081634251
Validation loss: 2.604088856836973

Epoch: 6| Step: 2
Training loss: 3.1767746238603745
Validation loss: 2.6277205885976365

Epoch: 6| Step: 3
Training loss: 2.965871921626617
Validation loss: 2.6421187844799348

Epoch: 6| Step: 4
Training loss: 3.0923221260052203
Validation loss: 2.623465150347116

Epoch: 6| Step: 5
Training loss: 3.185920174230262
Validation loss: 2.6423316794992813

Epoch: 6| Step: 6
Training loss: 2.8214483536342363
Validation loss: 2.635347243741961

Epoch: 6| Step: 7
Training loss: 3.0465216016005128
Validation loss: 2.62260836687373

Epoch: 6| Step: 8
Training loss: 2.804899499898135
Validation loss: 2.6374005890947774

Epoch: 6| Step: 9
Training loss: 2.6799127689797704
Validation loss: 2.632472413615224

Epoch: 6| Step: 10
Training loss: 2.7120519100948854
Validation loss: 2.6280307530617075

Epoch: 6| Step: 11
Training loss: 3.183602137642325
Validation loss: 2.6150496989870233

Epoch: 6| Step: 12
Training loss: 2.957658144414048
Validation loss: 2.6105630601731717

Epoch: 6| Step: 13
Training loss: 2.8981634046401035
Validation loss: 2.604446760968225

Epoch: 271| Step: 0
Training loss: 3.4930810659870364
Validation loss: 2.6118200453614673

Epoch: 6| Step: 1
Training loss: 2.7139105860262442
Validation loss: 2.588934351715711

Epoch: 6| Step: 2
Training loss: 3.2850003562706416
Validation loss: 2.5777502046667626

Epoch: 6| Step: 3
Training loss: 3.0076076685531064
Validation loss: 2.577281892851182

Epoch: 6| Step: 4
Training loss: 3.1958161122746285
Validation loss: 2.5780671670989412

Epoch: 6| Step: 5
Training loss: 2.716146077161847
Validation loss: 2.5799158707036196

Epoch: 6| Step: 6
Training loss: 2.887858123369368
Validation loss: 2.5793818875757974

Epoch: 6| Step: 7
Training loss: 2.21081499494972
Validation loss: 2.5788335766750548

Epoch: 6| Step: 8
Training loss: 2.735052580667976
Validation loss: 2.580070933599562

Epoch: 6| Step: 9
Training loss: 3.0992784521777486
Validation loss: 2.5774801159330605

Epoch: 6| Step: 10
Training loss: 3.099624758744118
Validation loss: 2.577051157223294

Epoch: 6| Step: 11
Training loss: 2.6672473116371394
Validation loss: 2.5748348756997497

Epoch: 6| Step: 12
Training loss: 2.8675812910774647
Validation loss: 2.577332839256643

Epoch: 6| Step: 13
Training loss: 2.788838353486527
Validation loss: 2.573678294065278

Epoch: 272| Step: 0
Training loss: 3.1095369383081986
Validation loss: 2.5760735417732286

Epoch: 6| Step: 1
Training loss: 3.119102253256852
Validation loss: 2.5718422593931334

Epoch: 6| Step: 2
Training loss: 2.814217869326029
Validation loss: 2.586874526117173

Epoch: 6| Step: 3
Training loss: 3.086432385901512
Validation loss: 2.579492296267465

Epoch: 6| Step: 4
Training loss: 3.263597653068356
Validation loss: 2.594361226422783

Epoch: 6| Step: 5
Training loss: 2.9031158282871132
Validation loss: 2.591418991411955

Epoch: 6| Step: 6
Training loss: 3.077986041190438
Validation loss: 2.605511858286891

Epoch: 6| Step: 7
Training loss: 2.8161644692942267
Validation loss: 2.5892860803180047

Epoch: 6| Step: 8
Training loss: 3.209398778067724
Validation loss: 2.591669243587493

Epoch: 6| Step: 9
Training loss: 3.179986213318311
Validation loss: 2.596981551440806

Epoch: 6| Step: 10
Training loss: 2.4847513549567637
Validation loss: 2.590400663267691

Epoch: 6| Step: 11
Training loss: 2.7474200544449707
Validation loss: 2.5798861685949603

Epoch: 6| Step: 12
Training loss: 2.2035206108124767
Validation loss: 2.588217864688839

Epoch: 6| Step: 13
Training loss: 2.4155073564117733
Validation loss: 2.5847165006850155

Epoch: 273| Step: 0
Training loss: 2.805983220186859
Validation loss: 2.601577096050862

Epoch: 6| Step: 1
Training loss: 2.7651502126276566
Validation loss: 2.598226712361803

Epoch: 6| Step: 2
Training loss: 2.6379847221250237
Validation loss: 2.621124064451123

Epoch: 6| Step: 3
Training loss: 2.930517623278222
Validation loss: 2.6378069687082886

Epoch: 6| Step: 4
Training loss: 2.7828766427205958
Validation loss: 2.6748409115062546

Epoch: 6| Step: 5
Training loss: 2.8297802206906653
Validation loss: 2.705595282944017

Epoch: 6| Step: 6
Training loss: 2.765023979786643
Validation loss: 2.70238728402704

Epoch: 6| Step: 7
Training loss: 3.246818892991902
Validation loss: 2.660656646307748

Epoch: 6| Step: 8
Training loss: 3.317667547161893
Validation loss: 2.614703321545119

Epoch: 6| Step: 9
Training loss: 2.69241894188218
Validation loss: 2.592730918328462

Epoch: 6| Step: 10
Training loss: 2.964404328643723
Validation loss: 2.58188232600041

Epoch: 6| Step: 11
Training loss: 3.1864067147446855
Validation loss: 2.5826790927581658

Epoch: 6| Step: 12
Training loss: 3.3387046611511013
Validation loss: 2.579492768348421

Epoch: 6| Step: 13
Training loss: 2.412225215462334
Validation loss: 2.576352605208661

Epoch: 274| Step: 0
Training loss: 2.7901014428513826
Validation loss: 2.577038099495612

Epoch: 6| Step: 1
Training loss: 2.809491561830812
Validation loss: 2.5781326348523264

Epoch: 6| Step: 2
Training loss: 3.699951614888315
Validation loss: 2.578988048572137

Epoch: 6| Step: 3
Training loss: 2.942254783764562
Validation loss: 2.578826555276457

Epoch: 6| Step: 4
Training loss: 3.196720326132059
Validation loss: 2.5800129510523138

Epoch: 6| Step: 5
Training loss: 2.9618638333401717
Validation loss: 2.5822851282003954

Epoch: 6| Step: 6
Training loss: 2.3754892347280974
Validation loss: 2.5827093627840707

Epoch: 6| Step: 7
Training loss: 2.862500426446475
Validation loss: 2.581805853999522

Epoch: 6| Step: 8
Training loss: 2.998918656332613
Validation loss: 2.581215339206852

Epoch: 6| Step: 9
Training loss: 3.2865209477782957
Validation loss: 2.5798289684285396

Epoch: 6| Step: 10
Training loss: 2.610517788384925
Validation loss: 2.5843442876531704

Epoch: 6| Step: 11
Training loss: 2.5004520007650384
Validation loss: 2.581319399721622

Epoch: 6| Step: 12
Training loss: 2.9843195565550964
Validation loss: 2.5798853835694677

Epoch: 6| Step: 13
Training loss: 2.7136913021562417
Validation loss: 2.581006768551389

Epoch: 275| Step: 0
Training loss: 3.294339185566001
Validation loss: 2.580957630939262

Epoch: 6| Step: 1
Training loss: 2.9815100854309327
Validation loss: 2.5892025129245377

Epoch: 6| Step: 2
Training loss: 2.767660652604664
Validation loss: 2.589357747392851

Epoch: 6| Step: 3
Training loss: 3.3225187982238387
Validation loss: 2.593219699409871

Epoch: 6| Step: 4
Training loss: 2.433235546220027
Validation loss: 2.6046913461753793

Epoch: 6| Step: 5
Training loss: 2.6792396638298364
Validation loss: 2.5976039819842955

Epoch: 6| Step: 6
Training loss: 2.791829763933706
Validation loss: 2.6321426249743034

Epoch: 6| Step: 7
Training loss: 3.074990472546216
Validation loss: 2.6371217476355113

Epoch: 6| Step: 8
Training loss: 2.8535682626369407
Validation loss: 2.627609063810258

Epoch: 6| Step: 9
Training loss: 2.8441738609255016
Validation loss: 2.635917806264585

Epoch: 6| Step: 10
Training loss: 2.9989561808133303
Validation loss: 2.6312389601632553

Epoch: 6| Step: 11
Training loss: 2.9455384994941
Validation loss: 2.629544940543897

Epoch: 6| Step: 12
Training loss: 2.382018110089517
Validation loss: 2.6370626702771656

Epoch: 6| Step: 13
Training loss: 3.620921635986827
Validation loss: 2.644250423542791

Epoch: 276| Step: 0
Training loss: 2.7799673658966646
Validation loss: 2.6121415264953245

Epoch: 6| Step: 1
Training loss: 2.7151424106460995
Validation loss: 2.5899237886708315

Epoch: 6| Step: 2
Training loss: 2.903875385784409
Validation loss: 2.5801854903491988

Epoch: 6| Step: 3
Training loss: 2.9565451863766454
Validation loss: 2.5668747228152893

Epoch: 6| Step: 4
Training loss: 2.9306329854546047
Validation loss: 2.5682757854954352

Epoch: 6| Step: 5
Training loss: 3.207047010561913
Validation loss: 2.5659498327465524

Epoch: 6| Step: 6
Training loss: 3.06907943542239
Validation loss: 2.569578206834722

Epoch: 6| Step: 7
Training loss: 2.5745710441550003
Validation loss: 2.5684263797926605

Epoch: 6| Step: 8
Training loss: 3.2110910494953915
Validation loss: 2.567672273628563

Epoch: 6| Step: 9
Training loss: 2.9547636138295124
Validation loss: 2.5708864879419804

Epoch: 6| Step: 10
Training loss: 2.95150793296734
Validation loss: 2.5645683618882265

Epoch: 6| Step: 11
Training loss: 3.3783230846107175
Validation loss: 2.5681852945091665

Epoch: 6| Step: 12
Training loss: 2.2727130377930562
Validation loss: 2.562232814198338

Epoch: 6| Step: 13
Training loss: 2.874099756355869
Validation loss: 2.563052590307742

Epoch: 277| Step: 0
Training loss: 2.949312524378364
Validation loss: 2.5637941471541716

Epoch: 6| Step: 1
Training loss: 2.519700628693763
Validation loss: 2.56070500395068

Epoch: 6| Step: 2
Training loss: 2.424636841156407
Validation loss: 2.5654876853697886

Epoch: 6| Step: 3
Training loss: 3.0071346955953957
Validation loss: 2.5693557863276406

Epoch: 6| Step: 4
Training loss: 2.876872075137604
Validation loss: 2.570529318561902

Epoch: 6| Step: 5
Training loss: 2.9865720959858786
Validation loss: 2.574788913981438

Epoch: 6| Step: 6
Training loss: 3.0992781444692357
Validation loss: 2.58012655303289

Epoch: 6| Step: 7
Training loss: 3.093006853956293
Validation loss: 2.6090432783257635

Epoch: 6| Step: 8
Training loss: 2.5127100197235244
Validation loss: 2.620245280435087

Epoch: 6| Step: 9
Training loss: 3.1924848286410876
Validation loss: 2.6144409343549833

Epoch: 6| Step: 10
Training loss: 3.093559182187451
Validation loss: 2.614239921678532

Epoch: 6| Step: 11
Training loss: 3.2657543686060246
Validation loss: 2.594182218261764

Epoch: 6| Step: 12
Training loss: 2.860696122608657
Validation loss: 2.592061638454378

Epoch: 6| Step: 13
Training loss: 2.829394145316842
Validation loss: 2.576579707051227

Epoch: 278| Step: 0
Training loss: 2.6215934447652693
Validation loss: 2.568499782714957

Epoch: 6| Step: 1
Training loss: 3.5497787621560173
Validation loss: 2.563324184219242

Epoch: 6| Step: 2
Training loss: 3.078802663497496
Validation loss: 2.5693937723635503

Epoch: 6| Step: 3
Training loss: 2.8613567884656463
Validation loss: 2.5640824086865868

Epoch: 6| Step: 4
Training loss: 3.075749754023796
Validation loss: 2.563801676692243

Epoch: 6| Step: 5
Training loss: 3.230352139011566
Validation loss: 2.5607841443530153

Epoch: 6| Step: 6
Training loss: 2.7043618255710453
Validation loss: 2.566675438471064

Epoch: 6| Step: 7
Training loss: 2.95253881055888
Validation loss: 2.560469997072247

Epoch: 6| Step: 8
Training loss: 2.346322440816022
Validation loss: 2.5641467747868245

Epoch: 6| Step: 9
Training loss: 2.6878192623263146
Validation loss: 2.563613148602981

Epoch: 6| Step: 10
Training loss: 2.565805396778361
Validation loss: 2.563421506385223

Epoch: 6| Step: 11
Training loss: 3.3862355029365068
Validation loss: 2.5639577171413537

Epoch: 6| Step: 12
Training loss: 2.783016886586898
Validation loss: 2.563875650978102

Epoch: 6| Step: 13
Training loss: 2.4177892861762444
Validation loss: 2.566658093944606

Epoch: 279| Step: 0
Training loss: 2.7603713313764437
Validation loss: 2.5646552289811804

Epoch: 6| Step: 1
Training loss: 2.864308421497146
Validation loss: 2.5656357704006374

Epoch: 6| Step: 2
Training loss: 2.741217460665333
Validation loss: 2.5690770525589706

Epoch: 6| Step: 3
Training loss: 2.7534193974853314
Validation loss: 2.5780891075382795

Epoch: 6| Step: 4
Training loss: 3.0151012539032687
Validation loss: 2.5807656877999228

Epoch: 6| Step: 5
Training loss: 2.971536232365547
Validation loss: 2.591767735866932

Epoch: 6| Step: 6
Training loss: 3.1876092031883356
Validation loss: 2.5927688990699753

Epoch: 6| Step: 7
Training loss: 2.665399836592985
Validation loss: 2.59332983431712

Epoch: 6| Step: 8
Training loss: 3.325340718186455
Validation loss: 2.5889963017479425

Epoch: 6| Step: 9
Training loss: 3.146204911743621
Validation loss: 2.578404282861645

Epoch: 6| Step: 10
Training loss: 2.381863664666667
Validation loss: 2.5895269266917325

Epoch: 6| Step: 11
Training loss: 2.692983577588957
Validation loss: 2.587804742937083

Epoch: 6| Step: 12
Training loss: 2.817815124029905
Validation loss: 2.5883757422793017

Epoch: 6| Step: 13
Training loss: 3.4925005812975565
Validation loss: 2.5893898273823353

Epoch: 280| Step: 0
Training loss: 2.5279891120217446
Validation loss: 2.5942594094924605

Epoch: 6| Step: 1
Training loss: 3.256040388451972
Validation loss: 2.6257616462640487

Epoch: 6| Step: 2
Training loss: 2.965198199127239
Validation loss: 2.6254747062108996

Epoch: 6| Step: 3
Training loss: 3.5142563253762207
Validation loss: 2.644635785458879

Epoch: 6| Step: 4
Training loss: 3.2014256877719607
Validation loss: 2.6479324031957425

Epoch: 6| Step: 5
Training loss: 2.5503996816326215
Validation loss: 2.6060651006390803

Epoch: 6| Step: 6
Training loss: 2.70815158136327
Validation loss: 2.5921279474824557

Epoch: 6| Step: 7
Training loss: 3.2561098035625955
Validation loss: 2.5662579037415076

Epoch: 6| Step: 8
Training loss: 2.8966941011605356
Validation loss: 2.5631574032070086

Epoch: 6| Step: 9
Training loss: 2.7997176572953366
Validation loss: 2.5624969136249276

Epoch: 6| Step: 10
Training loss: 2.6649713392308967
Validation loss: 2.5614208006822063

Epoch: 6| Step: 11
Training loss: 2.955996454507769
Validation loss: 2.5606746820496733

Epoch: 6| Step: 12
Training loss: 2.8824793511980284
Validation loss: 2.563902238402896

Epoch: 6| Step: 13
Training loss: 2.0770337674403963
Validation loss: 2.5598352754924054

Epoch: 281| Step: 0
Training loss: 3.055231304496373
Validation loss: 2.561319230721562

Epoch: 6| Step: 1
Training loss: 2.796796914827404
Validation loss: 2.5606116623657154

Epoch: 6| Step: 2
Training loss: 2.9460796298202294
Validation loss: 2.560214891872706

Epoch: 6| Step: 3
Training loss: 2.7305562410540243
Validation loss: 2.5580122753418575

Epoch: 6| Step: 4
Training loss: 2.8184350017465056
Validation loss: 2.5607286529221005

Epoch: 6| Step: 5
Training loss: 3.586905953273232
Validation loss: 2.5600328872026936

Epoch: 6| Step: 6
Training loss: 2.8429908158257615
Validation loss: 2.5703379007687643

Epoch: 6| Step: 7
Training loss: 3.057891960066758
Validation loss: 2.5666048890158173

Epoch: 6| Step: 8
Training loss: 2.5324486614118693
Validation loss: 2.571485296540281

Epoch: 6| Step: 9
Training loss: 2.6094447143744413
Validation loss: 2.5639617836351682

Epoch: 6| Step: 10
Training loss: 2.5324120385577515
Validation loss: 2.574512638509607

Epoch: 6| Step: 11
Training loss: 3.4049138239459946
Validation loss: 2.599503216245018

Epoch: 6| Step: 12
Training loss: 2.567493690252676
Validation loss: 2.593906546616611

Epoch: 6| Step: 13
Training loss: 3.0926557975633417
Validation loss: 2.595062026813186

Epoch: 282| Step: 0
Training loss: 2.2419921577241593
Validation loss: 2.5858870264886247

Epoch: 6| Step: 1
Training loss: 2.429512434659682
Validation loss: 2.596603461730344

Epoch: 6| Step: 2
Training loss: 2.446387301545403
Validation loss: 2.5869657187798154

Epoch: 6| Step: 3
Training loss: 2.580101688805861
Validation loss: 2.5760267234011125

Epoch: 6| Step: 4
Training loss: 2.86055560310571
Validation loss: 2.5697191116171156

Epoch: 6| Step: 5
Training loss: 2.9306730113263075
Validation loss: 2.5680607592525404

Epoch: 6| Step: 6
Training loss: 2.9655903917711117
Validation loss: 2.560897704370103

Epoch: 6| Step: 7
Training loss: 3.1501702398891402
Validation loss: 2.559491888786208

Epoch: 6| Step: 8
Training loss: 3.8180723897107147
Validation loss: 2.5584394145233795

Epoch: 6| Step: 9
Training loss: 2.667876882912315
Validation loss: 2.565369181010786

Epoch: 6| Step: 10
Training loss: 2.8063605373846383
Validation loss: 2.559823247610509

Epoch: 6| Step: 11
Training loss: 3.1970607013780485
Validation loss: 2.563339708088479

Epoch: 6| Step: 12
Training loss: 3.245415314839674
Validation loss: 2.5656634087423136

Epoch: 6| Step: 13
Training loss: 3.0497901469093813
Validation loss: 2.5712533129069324

Epoch: 283| Step: 0
Training loss: 2.704121929517692
Validation loss: 2.5625983948903985

Epoch: 6| Step: 1
Training loss: 2.590458815597186
Validation loss: 2.570596995815051

Epoch: 6| Step: 2
Training loss: 2.734162327806479
Validation loss: 2.572781796453747

Epoch: 6| Step: 3
Training loss: 3.123953224339918
Validation loss: 2.578845790264387

Epoch: 6| Step: 4
Training loss: 2.641309389890048
Validation loss: 2.567225960660161

Epoch: 6| Step: 5
Training loss: 2.992669686690747
Validation loss: 2.5697502705489095

Epoch: 6| Step: 6
Training loss: 2.327322597606021
Validation loss: 2.5738969794988087

Epoch: 6| Step: 7
Training loss: 3.3503159559054323
Validation loss: 2.5638670457525223

Epoch: 6| Step: 8
Training loss: 2.6993897490154777
Validation loss: 2.5644119137297636

Epoch: 6| Step: 9
Training loss: 2.9085538203070196
Validation loss: 2.5670128808032837

Epoch: 6| Step: 10
Training loss: 3.6214868029752
Validation loss: 2.574173356899498

Epoch: 6| Step: 11
Training loss: 2.9047191238528662
Validation loss: 2.569221857897377

Epoch: 6| Step: 12
Training loss: 3.0372751662947852
Validation loss: 2.575964215641848

Epoch: 6| Step: 13
Training loss: 2.6633581757451155
Validation loss: 2.5766641713560277

Epoch: 284| Step: 0
Training loss: 2.8909067377481104
Validation loss: 2.5764120816013856

Epoch: 6| Step: 1
Training loss: 3.4168818026164964
Validation loss: 2.5745272684246583

Epoch: 6| Step: 2
Training loss: 3.3042393012960627
Validation loss: 2.5750320999258554

Epoch: 6| Step: 3
Training loss: 3.0737769695276262
Validation loss: 2.5691380734328177

Epoch: 6| Step: 4
Training loss: 2.500908877146865
Validation loss: 2.5723005432847947

Epoch: 6| Step: 5
Training loss: 2.808732115582925
Validation loss: 2.5835206092595717

Epoch: 6| Step: 6
Training loss: 3.094669089922709
Validation loss: 2.5750754698459946

Epoch: 6| Step: 7
Training loss: 2.594421667434218
Validation loss: 2.5927941816825015

Epoch: 6| Step: 8
Training loss: 2.517444971083595
Validation loss: 2.5956663881902484

Epoch: 6| Step: 9
Training loss: 2.707877419073791
Validation loss: 2.5924762613380867

Epoch: 6| Step: 10
Training loss: 3.1820226244454815
Validation loss: 2.59736461693972

Epoch: 6| Step: 11
Training loss: 3.0864113745634536
Validation loss: 2.5980510630296565

Epoch: 6| Step: 12
Training loss: 1.9391503227319977
Validation loss: 2.59296613843504

Epoch: 6| Step: 13
Training loss: 3.322226872293825
Validation loss: 2.581569888126141

Epoch: 285| Step: 0
Training loss: 2.7985994787318886
Validation loss: 2.581658761037997

Epoch: 6| Step: 1
Training loss: 3.3004177638249805
Validation loss: 2.574361375529984

Epoch: 6| Step: 2
Training loss: 2.4680803573794305
Validation loss: 2.5644747660500036

Epoch: 6| Step: 3
Training loss: 3.2731965552173787
Validation loss: 2.5713657635209324

Epoch: 6| Step: 4
Training loss: 2.3117293027254706
Validation loss: 2.5637018820187327

Epoch: 6| Step: 5
Training loss: 2.806319842924362
Validation loss: 2.5631358100458774

Epoch: 6| Step: 6
Training loss: 2.5329388294567106
Validation loss: 2.56896430716593

Epoch: 6| Step: 7
Training loss: 3.506356325764331
Validation loss: 2.5668762099388203

Epoch: 6| Step: 8
Training loss: 3.186718714088165
Validation loss: 2.5664182170621936

Epoch: 6| Step: 9
Training loss: 2.6205657563630895
Validation loss: 2.5638155897805057

Epoch: 6| Step: 10
Training loss: 2.650097442131007
Validation loss: 2.5661541915253894

Epoch: 6| Step: 11
Training loss: 2.9104922926262855
Validation loss: 2.5707270127212087

Epoch: 6| Step: 12
Training loss: 2.8629444959925068
Validation loss: 2.5714134902596495

Epoch: 6| Step: 13
Training loss: 3.2091377207730853
Validation loss: 2.580223137113512

Epoch: 286| Step: 0
Training loss: 2.804074786316706
Validation loss: 2.5865564847505182

Epoch: 6| Step: 1
Training loss: 3.1869705358842335
Validation loss: 2.581900234509128

Epoch: 6| Step: 2
Training loss: 3.1191198339945774
Validation loss: 2.579504790978946

Epoch: 6| Step: 3
Training loss: 2.7618823400927774
Validation loss: 2.588388962689018

Epoch: 6| Step: 4
Training loss: 2.519893176675688
Validation loss: 2.5884407294316247

Epoch: 6| Step: 5
Training loss: 2.977492940463546
Validation loss: 2.6196537074868926

Epoch: 6| Step: 6
Training loss: 2.5522421236009154
Validation loss: 2.6252408305382415

Epoch: 6| Step: 7
Training loss: 2.817878243241125
Validation loss: 2.6270767431072484

Epoch: 6| Step: 8
Training loss: 2.4924469337438855
Validation loss: 2.6228085544317556

Epoch: 6| Step: 9
Training loss: 2.740854836094744
Validation loss: 2.606625081622229

Epoch: 6| Step: 10
Training loss: 3.3584002832849684
Validation loss: 2.6153426133973925

Epoch: 6| Step: 11
Training loss: 2.8540212403905802
Validation loss: 2.5973771717538803

Epoch: 6| Step: 12
Training loss: 3.238152698132585
Validation loss: 2.5694785497106047

Epoch: 6| Step: 13
Training loss: 3.051811562026664
Validation loss: 2.5741749443768533

Epoch: 287| Step: 0
Training loss: 2.749325582862731
Validation loss: 2.565103314486351

Epoch: 6| Step: 1
Training loss: 2.6652908849225483
Validation loss: 2.562901201112298

Epoch: 6| Step: 2
Training loss: 2.621478579791454
Validation loss: 2.5635253881598894

Epoch: 6| Step: 3
Training loss: 3.012159500823029
Validation loss: 2.5718538054289435

Epoch: 6| Step: 4
Training loss: 2.738507793377117
Validation loss: 2.5604347642551857

Epoch: 6| Step: 5
Training loss: 3.5286419444983568
Validation loss: 2.5628799038810457

Epoch: 6| Step: 6
Training loss: 2.785668538664625
Validation loss: 2.574031585447681

Epoch: 6| Step: 7
Training loss: 3.064731641163486
Validation loss: 2.5855813230509

Epoch: 6| Step: 8
Training loss: 2.142734574036866
Validation loss: 2.582567880247422

Epoch: 6| Step: 9
Training loss: 3.053412520146676
Validation loss: 2.5848884265061254

Epoch: 6| Step: 10
Training loss: 3.0445126496476815
Validation loss: 2.594613692640928

Epoch: 6| Step: 11
Training loss: 2.6834432457000217
Validation loss: 2.587752288817252

Epoch: 6| Step: 12
Training loss: 2.981821455657667
Validation loss: 2.5987791548368486

Epoch: 6| Step: 13
Training loss: 3.5135449847241427
Validation loss: 2.5885036529511627

Epoch: 288| Step: 0
Training loss: 3.1705247231749625
Validation loss: 2.580482956348078

Epoch: 6| Step: 1
Training loss: 3.038299072401684
Validation loss: 2.5751018132090007

Epoch: 6| Step: 2
Training loss: 2.403757464019883
Validation loss: 2.576765052883479

Epoch: 6| Step: 3
Training loss: 2.5731096903151163
Validation loss: 2.573688225161904

Epoch: 6| Step: 4
Training loss: 2.74163969388021
Validation loss: 2.5674096172326784

Epoch: 6| Step: 5
Training loss: 3.2230685993295096
Validation loss: 2.566223879251954

Epoch: 6| Step: 6
Training loss: 3.356561946756978
Validation loss: 2.568267013340783

Epoch: 6| Step: 7
Training loss: 2.7100258649316675
Validation loss: 2.5637624068583036

Epoch: 6| Step: 8
Training loss: 3.104572056321622
Validation loss: 2.572467632417144

Epoch: 6| Step: 9
Training loss: 2.810081119927631
Validation loss: 2.565695382315021

Epoch: 6| Step: 10
Training loss: 2.8691662189336675
Validation loss: 2.578796877900866

Epoch: 6| Step: 11
Training loss: 2.8665155356142704
Validation loss: 2.577789142567619

Epoch: 6| Step: 12
Training loss: 2.6501183141531643
Validation loss: 2.5953363656861934

Epoch: 6| Step: 13
Training loss: 2.9692852943084773
Validation loss: 2.586813138726912

Epoch: 289| Step: 0
Training loss: 3.619444174061867
Validation loss: 2.5898044949277503

Epoch: 6| Step: 1
Training loss: 2.7460274179622086
Validation loss: 2.6110173515078867

Epoch: 6| Step: 2
Training loss: 2.5036921893190907
Validation loss: 2.6139917351905844

Epoch: 6| Step: 3
Training loss: 3.327958796832973
Validation loss: 2.6165316763297084

Epoch: 6| Step: 4
Training loss: 2.855801042460103
Validation loss: 2.616514698545928

Epoch: 6| Step: 5
Training loss: 3.484845732636301
Validation loss: 2.6335042207482995

Epoch: 6| Step: 6
Training loss: 2.692546630568928
Validation loss: 2.6003627107608347

Epoch: 6| Step: 7
Training loss: 2.4570626892116163
Validation loss: 2.5937494198140834

Epoch: 6| Step: 8
Training loss: 2.4396419406261063
Validation loss: 2.5763922105173744

Epoch: 6| Step: 9
Training loss: 2.9743051053961076
Validation loss: 2.5752344517951027

Epoch: 6| Step: 10
Training loss: 2.4982098846100733
Validation loss: 2.5671280547149173

Epoch: 6| Step: 11
Training loss: 2.4726050493625253
Validation loss: 2.5653458346458664

Epoch: 6| Step: 12
Training loss: 2.951073312281145
Validation loss: 2.5553144318092667

Epoch: 6| Step: 13
Training loss: 3.2844116963841814
Validation loss: 2.560574446124132

Epoch: 290| Step: 0
Training loss: 2.8217124106373292
Validation loss: 2.5573254033283455

Epoch: 6| Step: 1
Training loss: 3.1843090166587507
Validation loss: 2.558646348006966

Epoch: 6| Step: 2
Training loss: 2.6100083912973964
Validation loss: 2.565056826588414

Epoch: 6| Step: 3
Training loss: 2.8952728021723657
Validation loss: 2.554927130675192

Epoch: 6| Step: 4
Training loss: 2.8464163552087225
Validation loss: 2.555485964174273

Epoch: 6| Step: 5
Training loss: 2.9813680629424804
Validation loss: 2.553898048404649

Epoch: 6| Step: 6
Training loss: 3.006540163117966
Validation loss: 2.5552969369296226

Epoch: 6| Step: 7
Training loss: 2.8389525136600815
Validation loss: 2.555228351793034

Epoch: 6| Step: 8
Training loss: 1.7443155198871882
Validation loss: 2.552222263220353

Epoch: 6| Step: 9
Training loss: 3.3951814333901518
Validation loss: 2.5553880478427966

Epoch: 6| Step: 10
Training loss: 2.5584369174560093
Validation loss: 2.5522881046303634

Epoch: 6| Step: 11
Training loss: 3.4072311808061992
Validation loss: 2.5525155226149585

Epoch: 6| Step: 12
Training loss: 3.0597252244935094
Validation loss: 2.557540055111866

Epoch: 6| Step: 13
Training loss: 2.9603141994223785
Validation loss: 2.557205823969576

Epoch: 291| Step: 0
Training loss: 2.4187773552661156
Validation loss: 2.5606491403724974

Epoch: 6| Step: 1
Training loss: 2.3856105697871
Validation loss: 2.5619777884664323

Epoch: 6| Step: 2
Training loss: 2.334198473443879
Validation loss: 2.566064552845716

Epoch: 6| Step: 3
Training loss: 3.2740147338889862
Validation loss: 2.5756870589694434

Epoch: 6| Step: 4
Training loss: 3.5009331140522213
Validation loss: 2.5771249133406777

Epoch: 6| Step: 5
Training loss: 2.780128081273399
Validation loss: 2.58694505594572

Epoch: 6| Step: 6
Training loss: 3.459981471987823
Validation loss: 2.5905333013218184

Epoch: 6| Step: 7
Training loss: 3.1843018288483633
Validation loss: 2.596482503140396

Epoch: 6| Step: 8
Training loss: 2.817279907674428
Validation loss: 2.602443555854772

Epoch: 6| Step: 9
Training loss: 3.0365907477705654
Validation loss: 2.5955191256081442

Epoch: 6| Step: 10
Training loss: 3.186714524371279
Validation loss: 2.6305016223246387

Epoch: 6| Step: 11
Training loss: 2.5638972869033827
Validation loss: 2.621917728602585

Epoch: 6| Step: 12
Training loss: 2.467570735454742
Validation loss: 2.6299435523179784

Epoch: 6| Step: 13
Training loss: 2.7915920038819597
Validation loss: 2.6137139470297006

Epoch: 292| Step: 0
Training loss: 2.891299937040039
Validation loss: 2.6052016638393227

Epoch: 6| Step: 1
Training loss: 2.8462208504036473
Validation loss: 2.578884069441783

Epoch: 6| Step: 2
Training loss: 3.3581952529678296
Validation loss: 2.5778980681031265

Epoch: 6| Step: 3
Training loss: 3.1044434972294526
Validation loss: 2.5625689997713743

Epoch: 6| Step: 4
Training loss: 2.766517624421603
Validation loss: 2.5576680344641534

Epoch: 6| Step: 5
Training loss: 2.5248031463937046
Validation loss: 2.561149863763304

Epoch: 6| Step: 6
Training loss: 2.7006213109088995
Validation loss: 2.5602320988082568

Epoch: 6| Step: 7
Training loss: 3.012382226438342
Validation loss: 2.5703955674714556

Epoch: 6| Step: 8
Training loss: 2.6831745558808993
Validation loss: 2.558727022902217

Epoch: 6| Step: 9
Training loss: 2.9246356182874917
Validation loss: 2.5647020260335305

Epoch: 6| Step: 10
Training loss: 2.897423579711561
Validation loss: 2.5740110167342904

Epoch: 6| Step: 11
Training loss: 2.945267977997798
Validation loss: 2.565396881184177

Epoch: 6| Step: 12
Training loss: 2.445551656417284
Validation loss: 2.562736225219795

Epoch: 6| Step: 13
Training loss: 3.5467924536959767
Validation loss: 2.572339048924624

Epoch: 293| Step: 0
Training loss: 2.2561195652843593
Validation loss: 2.5640631919260457

Epoch: 6| Step: 1
Training loss: 3.0407305457055736
Validation loss: 2.5598282410411115

Epoch: 6| Step: 2
Training loss: 2.9101849240932154
Validation loss: 2.570173663561864

Epoch: 6| Step: 3
Training loss: 3.0980572242549527
Validation loss: 2.5855814807016553

Epoch: 6| Step: 4
Training loss: 3.1562623882994814
Validation loss: 2.5835441734209406

Epoch: 6| Step: 5
Training loss: 3.074810896850667
Validation loss: 2.579909031612368

Epoch: 6| Step: 6
Training loss: 3.1468665508319726
Validation loss: 2.596841637248863

Epoch: 6| Step: 7
Training loss: 2.821081843809253
Validation loss: 2.6088264374550123

Epoch: 6| Step: 8
Training loss: 1.848013974293804
Validation loss: 2.609684142379348

Epoch: 6| Step: 9
Training loss: 3.175725694759308
Validation loss: 2.6223698187538727

Epoch: 6| Step: 10
Training loss: 3.232795366451093
Validation loss: 2.6106051543755897

Epoch: 6| Step: 11
Training loss: 2.8399555756224055
Validation loss: 2.617727982937254

Epoch: 6| Step: 12
Training loss: 2.9056589489498426
Validation loss: 2.610163829228557

Epoch: 6| Step: 13
Training loss: 2.2407835708754043
Validation loss: 2.6038387881366805

Epoch: 294| Step: 0
Training loss: 3.0222130792454567
Validation loss: 2.59783664212401

Epoch: 6| Step: 1
Training loss: 3.0284513157934945
Validation loss: 2.5869954404373554

Epoch: 6| Step: 2
Training loss: 2.972551341467651
Validation loss: 2.5860893726130976

Epoch: 6| Step: 3
Training loss: 3.102718416528581
Validation loss: 2.591075059024464

Epoch: 6| Step: 4
Training loss: 2.1884743836446092
Validation loss: 2.5774954734813345

Epoch: 6| Step: 5
Training loss: 3.0220928504156195
Validation loss: 2.589526965301867

Epoch: 6| Step: 6
Training loss: 3.156725554945828
Validation loss: 2.6133094301829916

Epoch: 6| Step: 7
Training loss: 2.871442667201947
Validation loss: 2.612666596061645

Epoch: 6| Step: 8
Training loss: 2.715511805169271
Validation loss: 2.5982270961836336

Epoch: 6| Step: 9
Training loss: 2.5898291125682227
Validation loss: 2.610255149386431

Epoch: 6| Step: 10
Training loss: 3.4641200603267777
Validation loss: 2.601156053022097

Epoch: 6| Step: 11
Training loss: 2.8585881052016213
Validation loss: 2.5889873304626674

Epoch: 6| Step: 12
Training loss: 2.2902964107798267
Validation loss: 2.5828979302571216

Epoch: 6| Step: 13
Training loss: 2.889365091771014
Validation loss: 2.5787586317269393

Epoch: 295| Step: 0
Training loss: 3.040415955244973
Validation loss: 2.5740927448269213

Epoch: 6| Step: 1
Training loss: 3.3400593292083656
Validation loss: 2.5779910920718416

Epoch: 6| Step: 2
Training loss: 2.8676102246066417
Validation loss: 2.567700466137381

Epoch: 6| Step: 3
Training loss: 2.8301561343523103
Validation loss: 2.566054474355099

Epoch: 6| Step: 4
Training loss: 2.7518522786925024
Validation loss: 2.582419700966058

Epoch: 6| Step: 5
Training loss: 3.0555184641426725
Validation loss: 2.5795627605996705

Epoch: 6| Step: 6
Training loss: 2.7444587713151622
Validation loss: 2.5842737047009123

Epoch: 6| Step: 7
Training loss: 3.5236469891645
Validation loss: 2.589949681083893

Epoch: 6| Step: 8
Training loss: 3.0356246999136087
Validation loss: 2.5784161485016264

Epoch: 6| Step: 9
Training loss: 2.9871528838820036
Validation loss: 2.579015615393231

Epoch: 6| Step: 10
Training loss: 2.4326127770872805
Validation loss: 2.5776619006468646

Epoch: 6| Step: 11
Training loss: 2.6989593160360754
Validation loss: 2.578589035241346

Epoch: 6| Step: 12
Training loss: 1.9288144009037118
Validation loss: 2.5688729522464

Epoch: 6| Step: 13
Training loss: 2.8654686871643076
Validation loss: 2.572966268047282

Epoch: 296| Step: 0
Training loss: 2.8558489628558825
Validation loss: 2.5657696377242356

Epoch: 6| Step: 1
Training loss: 2.4213071095787257
Validation loss: 2.572179741503738

Epoch: 6| Step: 2
Training loss: 2.721877393053582
Validation loss: 2.574096167868699

Epoch: 6| Step: 3
Training loss: 2.889767741337866
Validation loss: 2.567082391425776

Epoch: 6| Step: 4
Training loss: 2.4919643959943167
Validation loss: 2.5834782161501053

Epoch: 6| Step: 5
Training loss: 2.8566506336464044
Validation loss: 2.5915518691699297

Epoch: 6| Step: 6
Training loss: 3.0416106301637136
Validation loss: 2.6048739201784423

Epoch: 6| Step: 7
Training loss: 2.261950018198161
Validation loss: 2.6039197533157004

Epoch: 6| Step: 8
Training loss: 2.907309554366316
Validation loss: 2.5882838086461137

Epoch: 6| Step: 9
Training loss: 2.975389785235621
Validation loss: 2.5946151846149577

Epoch: 6| Step: 10
Training loss: 3.507956860806625
Validation loss: 2.60179185753944

Epoch: 6| Step: 11
Training loss: 2.722661328960919
Validation loss: 2.5972387199878844

Epoch: 6| Step: 12
Training loss: 3.5828550300452853
Validation loss: 2.601395852663019

Epoch: 6| Step: 13
Training loss: 2.741512900294819
Validation loss: 2.582186199764727

Epoch: 297| Step: 0
Training loss: 3.4271453264343745
Validation loss: 2.589189725396176

Epoch: 6| Step: 1
Training loss: 3.721125765447907
Validation loss: 2.576672530377782

Epoch: 6| Step: 2
Training loss: 2.8932107443556343
Validation loss: 2.5685482144595175

Epoch: 6| Step: 3
Training loss: 3.518457246733961
Validation loss: 2.5608852395031914

Epoch: 6| Step: 4
Training loss: 2.506874360583996
Validation loss: 2.569142594733412

Epoch: 6| Step: 5
Training loss: 2.5923899566338124
Validation loss: 2.5723450605202767

Epoch: 6| Step: 6
Training loss: 2.508787541966258
Validation loss: 2.570401679359966

Epoch: 6| Step: 7
Training loss: 2.630217317370692
Validation loss: 2.574061397440354

Epoch: 6| Step: 8
Training loss: 2.682504135654813
Validation loss: 2.590139890031781

Epoch: 6| Step: 9
Training loss: 2.7222534056799943
Validation loss: 2.6006709607969207

Epoch: 6| Step: 10
Training loss: 2.9046524743425164
Validation loss: 2.595042399303616

Epoch: 6| Step: 11
Training loss: 2.83645936141951
Validation loss: 2.6039417830960465

Epoch: 6| Step: 12
Training loss: 2.5907141142129193
Validation loss: 2.6001628172799145

Epoch: 6| Step: 13
Training loss: 2.0890018656910865
Validation loss: 2.5836190261878724

Epoch: 298| Step: 0
Training loss: 2.8798737058498776
Validation loss: 2.595777433573671

Epoch: 6| Step: 1
Training loss: 2.491181747642347
Validation loss: 2.5815245329241803

Epoch: 6| Step: 2
Training loss: 2.5661540146987556
Validation loss: 2.5863243918743803

Epoch: 6| Step: 3
Training loss: 3.0749506194328853
Validation loss: 2.5774234616478426

Epoch: 6| Step: 4
Training loss: 2.87659658798252
Validation loss: 2.566533935075632

Epoch: 6| Step: 5
Training loss: 2.3321945158837445
Validation loss: 2.567053220422661

Epoch: 6| Step: 6
Training loss: 2.9643234178308697
Validation loss: 2.5636503007321165

Epoch: 6| Step: 7
Training loss: 3.369939896135308
Validation loss: 2.573903800202182

Epoch: 6| Step: 8
Training loss: 2.331563164588579
Validation loss: 2.5806572737108304

Epoch: 6| Step: 9
Training loss: 3.009591346957855
Validation loss: 2.5773706112411725

Epoch: 6| Step: 10
Training loss: 2.714091727846634
Validation loss: 2.600100134506019

Epoch: 6| Step: 11
Training loss: 3.7172631889805574
Validation loss: 2.604931115615949

Epoch: 6| Step: 12
Training loss: 2.7121827181701312
Validation loss: 2.6038159343840404

Epoch: 6| Step: 13
Training loss: 2.97082495204462
Validation loss: 2.6155944962009916

Epoch: 299| Step: 0
Training loss: 2.472174382074315
Validation loss: 2.6242134177539445

Epoch: 6| Step: 1
Training loss: 3.0005444986215433
Validation loss: 2.601598088323666

Epoch: 6| Step: 2
Training loss: 2.362635298795552
Validation loss: 2.598939835434094

Epoch: 6| Step: 3
Training loss: 3.034544894238496
Validation loss: 2.5966508707158455

Epoch: 6| Step: 4
Training loss: 2.7325679366451894
Validation loss: 2.584980673292969

Epoch: 6| Step: 5
Training loss: 2.8194298036526124
Validation loss: 2.5797242097956974

Epoch: 6| Step: 6
Training loss: 2.2348224752016668
Validation loss: 2.580194346181408

Epoch: 6| Step: 7
Training loss: 2.53480769554729
Validation loss: 2.586010833147539

Epoch: 6| Step: 8
Training loss: 3.1902555634780634
Validation loss: 2.593981878158279

Epoch: 6| Step: 9
Training loss: 3.3492936143990275
Validation loss: 2.5749822683666665

Epoch: 6| Step: 10
Training loss: 3.1418154154269247
Validation loss: 2.5885771094934342

Epoch: 6| Step: 11
Training loss: 2.8250949708621955
Validation loss: 2.5837553938510065

Epoch: 6| Step: 12
Training loss: 3.03975624462446
Validation loss: 2.59010509347275

Epoch: 6| Step: 13
Training loss: 3.531919702811684
Validation loss: 2.6202665869042

Epoch: 300| Step: 0
Training loss: 3.1196835880738396
Validation loss: 2.6474458400779577

Epoch: 6| Step: 1
Training loss: 3.133383986557402
Validation loss: 2.627447434713835

Epoch: 6| Step: 2
Training loss: 3.4828446795353334
Validation loss: 2.618380141825574

Epoch: 6| Step: 3
Training loss: 3.254517276907357
Validation loss: 2.626536329435418

Epoch: 6| Step: 4
Training loss: 2.88752687780248
Validation loss: 2.6453537429209093

Epoch: 6| Step: 5
Training loss: 2.363532842689968
Validation loss: 2.6379390637837647

Epoch: 6| Step: 6
Training loss: 3.0740723241812113
Validation loss: 2.6572604106469653

Epoch: 6| Step: 7
Training loss: 2.3777149142613747
Validation loss: 2.6316598729404643

Epoch: 6| Step: 8
Training loss: 3.338777213433808
Validation loss: 2.62078930476936

Epoch: 6| Step: 9
Training loss: 2.582155625757027
Validation loss: 2.6117129743491443

Epoch: 6| Step: 10
Training loss: 2.389470638244018
Validation loss: 2.5983656610396415

Epoch: 6| Step: 11
Training loss: 2.6949567034752073
Validation loss: 2.5872842213738156

Epoch: 6| Step: 12
Training loss: 2.4100758247002196
Validation loss: 2.564464439389186

Epoch: 6| Step: 13
Training loss: 2.7777157734202604
Validation loss: 2.564114104028832

Epoch: 301| Step: 0
Training loss: 2.5582839894791185
Validation loss: 2.558013357717938

Epoch: 6| Step: 1
Training loss: 3.0895980563662877
Validation loss: 2.5588244537921163

Epoch: 6| Step: 2
Training loss: 2.9623364689112384
Validation loss: 2.554446476932604

Epoch: 6| Step: 3
Training loss: 2.8629874668093507
Validation loss: 2.5570307796272775

Epoch: 6| Step: 4
Training loss: 2.636576963780405
Validation loss: 2.558703239206773

Epoch: 6| Step: 5
Training loss: 3.2038635891034764
Validation loss: 2.5704895431327213

Epoch: 6| Step: 6
Training loss: 3.006553961283072
Validation loss: 2.5858621343729884

Epoch: 6| Step: 7
Training loss: 3.174940309939651
Validation loss: 2.6024108427866617

Epoch: 6| Step: 8
Training loss: 2.81461551364561
Validation loss: 2.6159732348374374

Epoch: 6| Step: 9
Training loss: 2.3165117468137777
Validation loss: 2.638133709255704

Epoch: 6| Step: 10
Training loss: 3.0026170124309632
Validation loss: 2.6534586224951022

Epoch: 6| Step: 11
Training loss: 2.6677324628849637
Validation loss: 2.6736039427449994

Epoch: 6| Step: 12
Training loss: 3.2471650303384534
Validation loss: 2.7000220667409396

Epoch: 6| Step: 13
Training loss: 2.5286080029869744
Validation loss: 2.662844424568923

Epoch: 302| Step: 0
Training loss: 3.3977090690684193
Validation loss: 2.6422469071869497

Epoch: 6| Step: 1
Training loss: 2.1957742334431676
Validation loss: 2.627551854664949

Epoch: 6| Step: 2
Training loss: 3.1766784076400314
Validation loss: 2.6107200853260912

Epoch: 6| Step: 3
Training loss: 2.752382893301568
Validation loss: 2.598930634112134

Epoch: 6| Step: 4
Training loss: 3.147461543495908
Validation loss: 2.575493084109497

Epoch: 6| Step: 5
Training loss: 3.352558263717589
Validation loss: 2.5859632231478833

Epoch: 6| Step: 6
Training loss: 2.597167922850277
Validation loss: 2.569573065736711

Epoch: 6| Step: 7
Training loss: 2.9196713547421993
Validation loss: 2.575349500915065

Epoch: 6| Step: 8
Training loss: 2.6468615498927286
Validation loss: 2.5840765637794876

Epoch: 6| Step: 9
Training loss: 2.760545969879663
Validation loss: 2.579695003859325

Epoch: 6| Step: 10
Training loss: 2.870599281134363
Validation loss: 2.5790324106118714

Epoch: 6| Step: 11
Training loss: 2.469306786439101
Validation loss: 2.5898236968855763

Epoch: 6| Step: 12
Training loss: 2.908409710803902
Validation loss: 2.584953558853277

Epoch: 6| Step: 13
Training loss: 2.6352297046872524
Validation loss: 2.5809507196148718

Epoch: 303| Step: 0
Training loss: 2.671769703357368
Validation loss: 2.608142168806496

Epoch: 6| Step: 1
Training loss: 2.1691744913885045
Validation loss: 2.6071430593844958

Epoch: 6| Step: 2
Training loss: 3.0569641527065077
Validation loss: 2.6423999995038665

Epoch: 6| Step: 3
Training loss: 3.391566413941107
Validation loss: 2.644348168245621

Epoch: 6| Step: 4
Training loss: 2.5430654105993162
Validation loss: 2.657200484352434

Epoch: 6| Step: 5
Training loss: 2.5397924694374696
Validation loss: 2.665520511764339

Epoch: 6| Step: 6
Training loss: 3.1596797022677556
Validation loss: 2.644497388217989

Epoch: 6| Step: 7
Training loss: 2.553822315478676
Validation loss: 2.6348729141521856

Epoch: 6| Step: 8
Training loss: 3.4609501754494185
Validation loss: 2.658478342548235

Epoch: 6| Step: 9
Training loss: 2.0216662338939853
Validation loss: 2.6411148415962122

Epoch: 6| Step: 10
Training loss: 3.045452079099073
Validation loss: 2.630264033740339

Epoch: 6| Step: 11
Training loss: 3.3826814057847647
Validation loss: 2.618015061126391

Epoch: 6| Step: 12
Training loss: 2.5857868438813254
Validation loss: 2.5903013777166133

Epoch: 6| Step: 13
Training loss: 3.5776596099841735
Validation loss: 2.588445891489816

Epoch: 304| Step: 0
Training loss: 3.3345149489030645
Validation loss: 2.5646486815640435

Epoch: 6| Step: 1
Training loss: 2.843058239984687
Validation loss: 2.555347988575464

Epoch: 6| Step: 2
Training loss: 2.693467014255932
Validation loss: 2.556744268904187

Epoch: 6| Step: 3
Training loss: 3.095438640860693
Validation loss: 2.5520638778845672

Epoch: 6| Step: 4
Training loss: 2.8002736843412923
Validation loss: 2.5532678871578205

Epoch: 6| Step: 5
Training loss: 2.6904067355248302
Validation loss: 2.5550932699792046

Epoch: 6| Step: 6
Training loss: 3.079858746695564
Validation loss: 2.553874302051557

Epoch: 6| Step: 7
Training loss: 2.5389463427456582
Validation loss: 2.5618505437742094

Epoch: 6| Step: 8
Training loss: 3.2428929308338335
Validation loss: 2.574565182141739

Epoch: 6| Step: 9
Training loss: 3.0596271975939873
Validation loss: 2.5875931595275747

Epoch: 6| Step: 10
Training loss: 2.7172365031723618
Validation loss: 2.6033349222900504

Epoch: 6| Step: 11
Training loss: 2.5421862357804073
Validation loss: 2.61802851963809

Epoch: 6| Step: 12
Training loss: 2.5547227769568366
Validation loss: 2.601974555678299

Epoch: 6| Step: 13
Training loss: 3.1809674810182216
Validation loss: 2.6062392507961802

Epoch: 305| Step: 0
Training loss: 2.810600995993419
Validation loss: 2.600185780044538

Epoch: 6| Step: 1
Training loss: 2.9713101240276845
Validation loss: 2.5810898404752334

Epoch: 6| Step: 2
Training loss: 2.892255828231649
Validation loss: 2.567139144604926

Epoch: 6| Step: 3
Training loss: 2.9351836466481585
Validation loss: 2.562866193776066

Epoch: 6| Step: 4
Training loss: 3.203055627583379
Validation loss: 2.566767410945508

Epoch: 6| Step: 5
Training loss: 2.9028139208460497
Validation loss: 2.5584650814690613

Epoch: 6| Step: 6
Training loss: 2.8710826224805626
Validation loss: 2.5551684304680027

Epoch: 6| Step: 7
Training loss: 2.81681704336079
Validation loss: 2.554623698388395

Epoch: 6| Step: 8
Training loss: 2.9452972816458627
Validation loss: 2.560603080211429

Epoch: 6| Step: 9
Training loss: 2.9604722112876103
Validation loss: 2.5682058350139787

Epoch: 6| Step: 10
Training loss: 3.0943177598109797
Validation loss: 2.5723347405393224

Epoch: 6| Step: 11
Training loss: 2.4882890111302136
Validation loss: 2.578031078926116

Epoch: 6| Step: 12
Training loss: 2.715434804561864
Validation loss: 2.5892820357745086

Epoch: 6| Step: 13
Training loss: 2.261445498389802
Validation loss: 2.5901274723578798

Epoch: 306| Step: 0
Training loss: 2.221521500206313
Validation loss: 2.594994698146279

Epoch: 6| Step: 1
Training loss: 2.5132138087574347
Validation loss: 2.586200017355338

Epoch: 6| Step: 2
Training loss: 2.2436089346487598
Validation loss: 2.600998346986134

Epoch: 6| Step: 3
Training loss: 2.955044722888305
Validation loss: 2.6276031552352888

Epoch: 6| Step: 4
Training loss: 2.676043732848854
Validation loss: 2.6107115736233704

Epoch: 6| Step: 5
Training loss: 3.2363245888634875
Validation loss: 2.6042288364659854

Epoch: 6| Step: 6
Training loss: 2.7082086289868617
Validation loss: 2.609196674064075

Epoch: 6| Step: 7
Training loss: 3.5654537604466703
Validation loss: 2.6137366730419926

Epoch: 6| Step: 8
Training loss: 3.17331065493048
Validation loss: 2.630133387617631

Epoch: 6| Step: 9
Training loss: 2.5794976481696668
Validation loss: 2.5860832492257466

Epoch: 6| Step: 10
Training loss: 3.1957840326743128
Validation loss: 2.5815311269161656

Epoch: 6| Step: 11
Training loss: 3.198917062622155
Validation loss: 2.585489565210021

Epoch: 6| Step: 12
Training loss: 2.985510644988614
Validation loss: 2.5696939760910507

Epoch: 6| Step: 13
Training loss: 2.3094401349082103
Validation loss: 2.5641693282348936

Epoch: 307| Step: 0
Training loss: 2.5819715992187757
Validation loss: 2.5720741141567016

Epoch: 6| Step: 1
Training loss: 2.7446742071876353
Validation loss: 2.552180866506502

Epoch: 6| Step: 2
Training loss: 3.173737078021
Validation loss: 2.549623142273768

Epoch: 6| Step: 3
Training loss: 3.1833617330619135
Validation loss: 2.5467836036592186

Epoch: 6| Step: 4
Training loss: 2.327643632728482
Validation loss: 2.56998434152817

Epoch: 6| Step: 5
Training loss: 2.9256277209593
Validation loss: 2.5808017263103107

Epoch: 6| Step: 6
Training loss: 3.0005603902670663
Validation loss: 2.5856365096473914

Epoch: 6| Step: 7
Training loss: 3.098606036167006
Validation loss: 2.6094677452821493

Epoch: 6| Step: 8
Training loss: 2.4126278462901865
Validation loss: 2.6003426135582073

Epoch: 6| Step: 9
Training loss: 2.7348451046781483
Validation loss: 2.6152253741283964

Epoch: 6| Step: 10
Training loss: 3.1250424191456925
Validation loss: 2.625795144334701

Epoch: 6| Step: 11
Training loss: 3.2387116333703467
Validation loss: 2.6255042943842772

Epoch: 6| Step: 12
Training loss: 2.777860740906196
Validation loss: 2.6246185318544835

Epoch: 6| Step: 13
Training loss: 2.5356832229891477
Validation loss: 2.6004907978177063

Epoch: 308| Step: 0
Training loss: 3.1936474031515654
Validation loss: 2.59281896473157

Epoch: 6| Step: 1
Training loss: 2.5737277360039323
Validation loss: 2.5717060624977344

Epoch: 6| Step: 2
Training loss: 2.1476979595420636
Validation loss: 2.5756955311451

Epoch: 6| Step: 3
Training loss: 2.8380189933544533
Validation loss: 2.5698121323742344

Epoch: 6| Step: 4
Training loss: 3.2809453913670694
Validation loss: 2.5803680337777193

Epoch: 6| Step: 5
Training loss: 3.1090293193721767
Validation loss: 2.562513550993402

Epoch: 6| Step: 6
Training loss: 3.1514599399020793
Validation loss: 2.577252206641081

Epoch: 6| Step: 7
Training loss: 3.126703484677002
Validation loss: 2.5845479875050525

Epoch: 6| Step: 8
Training loss: 2.7309400509177317
Validation loss: 2.570803776382964

Epoch: 6| Step: 9
Training loss: 3.0221386073582
Validation loss: 2.58721962431667

Epoch: 6| Step: 10
Training loss: 2.52932496515531
Validation loss: 2.583056738419342

Epoch: 6| Step: 11
Training loss: 2.4600617318820293
Validation loss: 2.5778361149011184

Epoch: 6| Step: 12
Training loss: 2.941945060834209
Validation loss: 2.573468754929837

Epoch: 6| Step: 13
Training loss: 2.6144186831807095
Validation loss: 2.5602632069799736

Epoch: 309| Step: 0
Training loss: 2.972950423293391
Validation loss: 2.5601311055414686

Epoch: 6| Step: 1
Training loss: 2.428133157645211
Validation loss: 2.552081415017876

Epoch: 6| Step: 2
Training loss: 2.7288893250542015
Validation loss: 2.55095533430742

Epoch: 6| Step: 3
Training loss: 3.0183605377246367
Validation loss: 2.55581788850291

Epoch: 6| Step: 4
Training loss: 3.128487129095938
Validation loss: 2.553536952704319

Epoch: 6| Step: 5
Training loss: 2.8645046893797392
Validation loss: 2.561658676620921

Epoch: 6| Step: 6
Training loss: 3.3019555164393033
Validation loss: 2.5708873754334283

Epoch: 6| Step: 7
Training loss: 2.876756711886204
Validation loss: 2.577067509630947

Epoch: 6| Step: 8
Training loss: 2.1545416657444134
Validation loss: 2.59191953786996

Epoch: 6| Step: 9
Training loss: 2.5757287188730764
Validation loss: 2.6134757376937006

Epoch: 6| Step: 10
Training loss: 3.543954058226671
Validation loss: 2.6264167659859448

Epoch: 6| Step: 11
Training loss: 2.7665705384555963
Validation loss: 2.6324160142737543

Epoch: 6| Step: 12
Training loss: 2.8833978156962683
Validation loss: 2.621013542261031

Epoch: 6| Step: 13
Training loss: 2.3925682597054267
Validation loss: 2.60448614183047

Epoch: 310| Step: 0
Training loss: 2.994031372864075
Validation loss: 2.598258143136534

Epoch: 6| Step: 1
Training loss: 1.909750179509987
Validation loss: 2.6010517433314275

Epoch: 6| Step: 2
Training loss: 2.6844492607813835
Validation loss: 2.6003509225897337

Epoch: 6| Step: 3
Training loss: 3.2489487341595997
Validation loss: 2.595840942661882

Epoch: 6| Step: 4
Training loss: 2.4866927749279086
Validation loss: 2.590188714885258

Epoch: 6| Step: 5
Training loss: 3.0051605026872727
Validation loss: 2.579245845292262

Epoch: 6| Step: 6
Training loss: 3.148800660952832
Validation loss: 2.557524195321979

Epoch: 6| Step: 7
Training loss: 3.507436345583873
Validation loss: 2.545147792612919

Epoch: 6| Step: 8
Training loss: 2.5769491577580497
Validation loss: 2.547480703612066

Epoch: 6| Step: 9
Training loss: 2.500137706778658
Validation loss: 2.5532931853922034

Epoch: 6| Step: 10
Training loss: 3.2030070957720973
Validation loss: 2.5471972028871948

Epoch: 6| Step: 11
Training loss: 2.27070416657683
Validation loss: 2.5445415417339596

Epoch: 6| Step: 12
Training loss: 3.1874637975693827
Validation loss: 2.536673909357099

Epoch: 6| Step: 13
Training loss: 3.2316214962170324
Validation loss: 2.557076104087045

Epoch: 311| Step: 0
Training loss: 2.9737612541534166
Validation loss: 2.563779658980789

Epoch: 6| Step: 1
Training loss: 2.5405670872618047
Validation loss: 2.556285849739378

Epoch: 6| Step: 2
Training loss: 2.4951718438240684
Validation loss: 2.5758360774079545

Epoch: 6| Step: 3
Training loss: 2.844896357949721
Validation loss: 2.570418354329136

Epoch: 6| Step: 4
Training loss: 3.1563071066345243
Validation loss: 2.5795301419781853

Epoch: 6| Step: 5
Training loss: 2.783107094697475
Validation loss: 2.5777568615206374

Epoch: 6| Step: 6
Training loss: 2.545452165138073
Validation loss: 2.587015624480957

Epoch: 6| Step: 7
Training loss: 3.3201055484677453
Validation loss: 2.643552082695881

Epoch: 6| Step: 8
Training loss: 3.1405597129602465
Validation loss: 2.6267455255372303

Epoch: 6| Step: 9
Training loss: 3.1007669423052686
Validation loss: 2.653292193004432

Epoch: 6| Step: 10
Training loss: 2.776587102863661
Validation loss: 2.618700591475453

Epoch: 6| Step: 11
Training loss: 2.3905077138814996
Validation loss: 2.6241421320753138

Epoch: 6| Step: 12
Training loss: 2.996822104519261
Validation loss: 2.617297083777163

Epoch: 6| Step: 13
Training loss: 2.7624765351968925
Validation loss: 2.5850038155497237

Epoch: 312| Step: 0
Training loss: 2.6612438157754683
Validation loss: 2.579376490707935

Epoch: 6| Step: 1
Training loss: 3.2964947377247804
Validation loss: 2.5612999386798174

Epoch: 6| Step: 2
Training loss: 2.8976488711380672
Validation loss: 2.565103358461261

Epoch: 6| Step: 3
Training loss: 2.904963547023214
Validation loss: 2.561819190689833

Epoch: 6| Step: 4
Training loss: 2.791921053631039
Validation loss: 2.556458065020547

Epoch: 6| Step: 5
Training loss: 2.8969856183475606
Validation loss: 2.565896122563323

Epoch: 6| Step: 6
Training loss: 2.6042982958270087
Validation loss: 2.561068403324081

Epoch: 6| Step: 7
Training loss: 2.5818059364155443
Validation loss: 2.586403839668666

Epoch: 6| Step: 8
Training loss: 3.250646966949095
Validation loss: 2.5855817682407443

Epoch: 6| Step: 9
Training loss: 2.385038942862814
Validation loss: 2.6029197933535615

Epoch: 6| Step: 10
Training loss: 2.8394509821773624
Validation loss: 2.62484817925274

Epoch: 6| Step: 11
Training loss: 2.688767245284799
Validation loss: 2.642090827156869

Epoch: 6| Step: 12
Training loss: 2.979645981721923
Validation loss: 2.6762643944220605

Epoch: 6| Step: 13
Training loss: 3.457861642190972
Validation loss: 2.660982060967506

Epoch: 313| Step: 0
Training loss: 2.9080968751578298
Validation loss: 2.614711477579951

Epoch: 6| Step: 1
Training loss: 2.1861474351505508
Validation loss: 2.5678773898525913

Epoch: 6| Step: 2
Training loss: 3.4976180009111704
Validation loss: 2.552848971958004

Epoch: 6| Step: 3
Training loss: 2.6362755523065506
Validation loss: 2.550199451644904

Epoch: 6| Step: 4
Training loss: 2.4679971826744382
Validation loss: 2.5422750464742427

Epoch: 6| Step: 5
Training loss: 2.7586991827173
Validation loss: 2.5490595336163513

Epoch: 6| Step: 6
Training loss: 2.605214256657137
Validation loss: 2.542603973678792

Epoch: 6| Step: 7
Training loss: 2.8538210768668613
Validation loss: 2.544677998705201

Epoch: 6| Step: 8
Training loss: 3.0173606818905725
Validation loss: 2.5440352700257955

Epoch: 6| Step: 9
Training loss: 3.0999456462401973
Validation loss: 2.5471651007802634

Epoch: 6| Step: 10
Training loss: 3.0535451016291058
Validation loss: 2.543017716372117

Epoch: 6| Step: 11
Training loss: 2.725731665700665
Validation loss: 2.5441280362745324

Epoch: 6| Step: 12
Training loss: 3.1213696564336133
Validation loss: 2.546775515463117

Epoch: 6| Step: 13
Training loss: 3.6404582628043154
Validation loss: 2.5514779500236227

Epoch: 314| Step: 0
Training loss: 3.2188784379240425
Validation loss: 2.5503603823544636

Epoch: 6| Step: 1
Training loss: 2.2257977159345637
Validation loss: 2.558414972818517

Epoch: 6| Step: 2
Training loss: 2.844301778060003
Validation loss: 2.5546934126422096

Epoch: 6| Step: 3
Training loss: 2.2872713652203007
Validation loss: 2.5694896733557426

Epoch: 6| Step: 4
Training loss: 2.685180905461707
Validation loss: 2.5750348327810344

Epoch: 6| Step: 5
Training loss: 3.0844016587053185
Validation loss: 2.6033421011260525

Epoch: 6| Step: 6
Training loss: 3.5399082680578955
Validation loss: 2.61059713035871

Epoch: 6| Step: 7
Training loss: 3.313530239903785
Validation loss: 2.622437631371077

Epoch: 6| Step: 8
Training loss: 2.6436331504448303
Validation loss: 2.6103320479907026

Epoch: 6| Step: 9
Training loss: 3.1912523510360575
Validation loss: 2.5967812041884373

Epoch: 6| Step: 10
Training loss: 2.7497825536589664
Validation loss: 2.623904298867733

Epoch: 6| Step: 11
Training loss: 1.9893146819505085
Validation loss: 2.6325747236286032

Epoch: 6| Step: 12
Training loss: 3.0935480841819007
Validation loss: 2.6405186601082953

Epoch: 6| Step: 13
Training loss: 3.023531811251117
Validation loss: 2.6323291920046032

Epoch: 315| Step: 0
Training loss: 3.081735110832039
Validation loss: 2.65855932543909

Epoch: 6| Step: 1
Training loss: 2.717289323966368
Validation loss: 2.655558153036407

Epoch: 6| Step: 2
Training loss: 2.5084729617301926
Validation loss: 2.655144383073971

Epoch: 6| Step: 3
Training loss: 3.0260359763498474
Validation loss: 2.6160296466601696

Epoch: 6| Step: 4
Training loss: 3.0244850098636853
Validation loss: 2.606711738190888

Epoch: 6| Step: 5
Training loss: 2.5219648569730566
Validation loss: 2.5805976016010073

Epoch: 6| Step: 6
Training loss: 2.921113756534189
Validation loss: 2.556434666357563

Epoch: 6| Step: 7
Training loss: 2.857826689220345
Validation loss: 2.5443832999506926

Epoch: 6| Step: 8
Training loss: 3.4545122354908875
Validation loss: 2.5476133503201153

Epoch: 6| Step: 9
Training loss: 2.4592929734313276
Validation loss: 2.5426501330366023

Epoch: 6| Step: 10
Training loss: 2.7094202550432667
Validation loss: 2.5412428452271936

Epoch: 6| Step: 11
Training loss: 3.1820163305931697
Validation loss: 2.536366230444528

Epoch: 6| Step: 12
Training loss: 2.8098949659815813
Validation loss: 2.5422781725250982

Epoch: 6| Step: 13
Training loss: 2.848956362057038
Validation loss: 2.5369037375996277

Epoch: 316| Step: 0
Training loss: 3.423762806662667
Validation loss: 2.5495449555716587

Epoch: 6| Step: 1
Training loss: 2.8775868595114904
Validation loss: 2.5438659556076764

Epoch: 6| Step: 2
Training loss: 3.659019529830052
Validation loss: 2.545123736974511

Epoch: 6| Step: 3
Training loss: 2.603839965672525
Validation loss: 2.5452832209492335

Epoch: 6| Step: 4
Training loss: 3.2685819681132964
Validation loss: 2.543895709945532

Epoch: 6| Step: 5
Training loss: 2.1925837707174995
Validation loss: 2.551209747560756

Epoch: 6| Step: 6
Training loss: 2.283274549112738
Validation loss: 2.552287935883097

Epoch: 6| Step: 7
Training loss: 2.6954014860197364
Validation loss: 2.5592988330945925

Epoch: 6| Step: 8
Training loss: 2.5390991208296594
Validation loss: 2.5695801423512

Epoch: 6| Step: 9
Training loss: 2.780611972276724
Validation loss: 2.580150876501391

Epoch: 6| Step: 10
Training loss: 2.4822074983653977
Validation loss: 2.5805490741222776

Epoch: 6| Step: 11
Training loss: 3.2406820088065027
Validation loss: 2.5775312021418064

Epoch: 6| Step: 12
Training loss: 2.364798772691039
Validation loss: 2.5813915839259676

Epoch: 6| Step: 13
Training loss: 3.412773674690879
Validation loss: 2.572595264782754

Epoch: 317| Step: 0
Training loss: 1.9367509439923285
Validation loss: 2.5547155297364736

Epoch: 6| Step: 1
Training loss: 2.510077573633767
Validation loss: 2.5619435480284922

Epoch: 6| Step: 2
Training loss: 3.392146599732557
Validation loss: 2.5541480844217155

Epoch: 6| Step: 3
Training loss: 3.334430863574766
Validation loss: 2.5623655146362294

Epoch: 6| Step: 4
Training loss: 3.39598482570246
Validation loss: 2.550101028220939

Epoch: 6| Step: 5
Training loss: 2.786010268839405
Validation loss: 2.5521942553210835

Epoch: 6| Step: 6
Training loss: 2.6203194624388066
Validation loss: 2.5690952788437995

Epoch: 6| Step: 7
Training loss: 2.710855004542267
Validation loss: 2.5725716152798404

Epoch: 6| Step: 8
Training loss: 3.284353768291864
Validation loss: 2.584697775557188

Epoch: 6| Step: 9
Training loss: 2.4409927384183736
Validation loss: 2.596195875005918

Epoch: 6| Step: 10
Training loss: 3.0462126183045677
Validation loss: 2.604029754649257

Epoch: 6| Step: 11
Training loss: 2.3883089302912195
Validation loss: 2.5957112612303157

Epoch: 6| Step: 12
Training loss: 2.7723246316165118
Validation loss: 2.5974440034036554

Epoch: 6| Step: 13
Training loss: 3.0974924590209105
Validation loss: 2.583951044278866

Epoch: 318| Step: 0
Training loss: 3.2604311291716144
Validation loss: 2.594936103110794

Epoch: 6| Step: 1
Training loss: 2.7384788888086544
Validation loss: 2.598203042581548

Epoch: 6| Step: 2
Training loss: 2.733228432185298
Validation loss: 2.622998145721353

Epoch: 6| Step: 3
Training loss: 2.9876984470488392
Validation loss: 2.5768454749059244

Epoch: 6| Step: 4
Training loss: 2.849822216177416
Validation loss: 2.572062241187114

Epoch: 6| Step: 5
Training loss: 2.964121211570938
Validation loss: 2.580772775941524

Epoch: 6| Step: 6
Training loss: 2.812231517268799
Validation loss: 2.564466916591961

Epoch: 6| Step: 7
Training loss: 2.454000523312986
Validation loss: 2.5613560467945655

Epoch: 6| Step: 8
Training loss: 2.924354847241184
Validation loss: 2.562417912162595

Epoch: 6| Step: 9
Training loss: 2.607429007188279
Validation loss: 2.5662434644421923

Epoch: 6| Step: 10
Training loss: 3.1539701782732523
Validation loss: 2.574214333220745

Epoch: 6| Step: 11
Training loss: 2.49151841512539
Validation loss: 2.59762712724922

Epoch: 6| Step: 12
Training loss: 2.789067885449764
Validation loss: 2.60317693463351

Epoch: 6| Step: 13
Training loss: 2.9494612638287303
Validation loss: 2.619740274127841

Epoch: 319| Step: 0
Training loss: 2.926636106234499
Validation loss: 2.6144223505387014

Epoch: 6| Step: 1
Training loss: 2.916633841920249
Validation loss: 2.630736106149602

Epoch: 6| Step: 2
Training loss: 2.655561829226579
Validation loss: 2.605689883470307

Epoch: 6| Step: 3
Training loss: 3.0122511574946134
Validation loss: 2.6505949633349273

Epoch: 6| Step: 4
Training loss: 2.469704069409978
Validation loss: 2.6194498078876207

Epoch: 6| Step: 5
Training loss: 2.7040458389662994
Validation loss: 2.601500861034405

Epoch: 6| Step: 6
Training loss: 2.48105817384797
Validation loss: 2.594569554523088

Epoch: 6| Step: 7
Training loss: 3.0731914505165996
Validation loss: 2.5823625539399493

Epoch: 6| Step: 8
Training loss: 3.2380335659009725
Validation loss: 2.5757893204083224

Epoch: 6| Step: 9
Training loss: 2.4350606988316796
Validation loss: 2.5629224561548067

Epoch: 6| Step: 10
Training loss: 3.019673056683901
Validation loss: 2.546082627608459

Epoch: 6| Step: 11
Training loss: 3.028451158341014
Validation loss: 2.5476068919356623

Epoch: 6| Step: 12
Training loss: 2.9584770346828946
Validation loss: 2.5485377507962683

Epoch: 6| Step: 13
Training loss: 2.6771059641394848
Validation loss: 2.533306366685733

Epoch: 320| Step: 0
Training loss: 3.301869302225188
Validation loss: 2.544590971508693

Epoch: 6| Step: 1
Training loss: 3.059903503841228
Validation loss: 2.5467716047330757

Epoch: 6| Step: 2
Training loss: 2.8112207682418306
Validation loss: 2.541655092769464

Epoch: 6| Step: 3
Training loss: 2.928417856396624
Validation loss: 2.5420533270588184

Epoch: 6| Step: 4
Training loss: 3.1456889609919543
Validation loss: 2.550248166594844

Epoch: 6| Step: 5
Training loss: 2.998019677451961
Validation loss: 2.5411575839057647

Epoch: 6| Step: 6
Training loss: 3.501973821745868
Validation loss: 2.547068751771616

Epoch: 6| Step: 7
Training loss: 2.504494822534292
Validation loss: 2.553706998239113

Epoch: 6| Step: 8
Training loss: 2.734441789083868
Validation loss: 2.563849473244229

Epoch: 6| Step: 9
Training loss: 2.3784746552119995
Validation loss: 2.56114310418695

Epoch: 6| Step: 10
Training loss: 2.100511025512206
Validation loss: 2.5656186326806627

Epoch: 6| Step: 11
Training loss: 2.8135062219128266
Validation loss: 2.5724394881675043

Epoch: 6| Step: 12
Training loss: 2.565264257608706
Validation loss: 2.5947736273736273

Epoch: 6| Step: 13
Training loss: 2.5492054393255965
Validation loss: 2.6102063443408956

Epoch: 321| Step: 0
Training loss: 2.4687408253945917
Validation loss: 2.6420606271325773

Epoch: 6| Step: 1
Training loss: 3.390266364331594
Validation loss: 2.665250460463565

Epoch: 6| Step: 2
Training loss: 2.432362350536836
Validation loss: 2.741093217650353

Epoch: 6| Step: 3
Training loss: 2.810931213270094
Validation loss: 2.8631577059611137

Epoch: 6| Step: 4
Training loss: 3.162216740765277
Validation loss: 2.8257614635887167

Epoch: 6| Step: 5
Training loss: 2.8953390088337185
Validation loss: 2.737489150145625

Epoch: 6| Step: 6
Training loss: 2.7313270365939077
Validation loss: 2.627343254551206

Epoch: 6| Step: 7
Training loss: 2.706993554143203
Validation loss: 2.5810561863185315

Epoch: 6| Step: 8
Training loss: 3.0497967136363098
Validation loss: 2.5493504638189433

Epoch: 6| Step: 9
Training loss: 2.497311004269328
Validation loss: 2.529257447507194

Epoch: 6| Step: 10
Training loss: 2.9277733004312787
Validation loss: 2.5360840548677275

Epoch: 6| Step: 11
Training loss: 2.98789921730772
Validation loss: 2.5310264558575195

Epoch: 6| Step: 12
Training loss: 3.151423323456093
Validation loss: 2.534572642156003

Epoch: 6| Step: 13
Training loss: 2.7209738044248892
Validation loss: 2.5373885621210492

Epoch: 322| Step: 0
Training loss: 2.9228951208435743
Validation loss: 2.537100324318009

Epoch: 6| Step: 1
Training loss: 2.5051091439536357
Validation loss: 2.5397014874668242

Epoch: 6| Step: 2
Training loss: 3.5109080226392457
Validation loss: 2.546913278044067

Epoch: 6| Step: 3
Training loss: 3.159506751085721
Validation loss: 2.5405151058865636

Epoch: 6| Step: 4
Training loss: 3.373051964204325
Validation loss: 2.544032694326921

Epoch: 6| Step: 5
Training loss: 2.7241560582790405
Validation loss: 2.541537108230113

Epoch: 6| Step: 6
Training loss: 3.0121572845650024
Validation loss: 2.5409759041420483

Epoch: 6| Step: 7
Training loss: 2.3463895049205425
Validation loss: 2.538283743625588

Epoch: 6| Step: 8
Training loss: 2.7498063105950887
Validation loss: 2.538975827084281

Epoch: 6| Step: 9
Training loss: 2.874608386361343
Validation loss: 2.541531128667778

Epoch: 6| Step: 10
Training loss: 2.9708928455814014
Validation loss: 2.5357652663887826

Epoch: 6| Step: 11
Training loss: 3.0524277389683667
Validation loss: 2.5337629384125027

Epoch: 6| Step: 12
Training loss: 2.7368454590479576
Validation loss: 2.535837622117067

Epoch: 6| Step: 13
Training loss: 2.7395594684059366
Validation loss: 2.5306380319724644

Epoch: 323| Step: 0
Training loss: 2.722197177884211
Validation loss: 2.532148713378524

Epoch: 6| Step: 1
Training loss: 3.2223212420569927
Validation loss: 2.5311696880304835

Epoch: 6| Step: 2
Training loss: 3.078962802633777
Validation loss: 2.5325207606337075

Epoch: 6| Step: 3
Training loss: 2.606687246551966
Validation loss: 2.532640687614813

Epoch: 6| Step: 4
Training loss: 3.0507087259305417
Validation loss: 2.539948338666413

Epoch: 6| Step: 5
Training loss: 2.462621687772485
Validation loss: 2.556030652907708

Epoch: 6| Step: 6
Training loss: 2.6207907397797117
Validation loss: 2.574152342152486

Epoch: 6| Step: 7
Training loss: 2.9697723234615547
Validation loss: 2.5929025549781435

Epoch: 6| Step: 8
Training loss: 3.0509187909136486
Validation loss: 2.6284160156008656

Epoch: 6| Step: 9
Training loss: 2.958172072909122
Validation loss: 2.644510925227467

Epoch: 6| Step: 10
Training loss: 2.991359028277878
Validation loss: 2.651504184855771

Epoch: 6| Step: 11
Training loss: 2.8578213499170992
Validation loss: 2.648647414131667

Epoch: 6| Step: 12
Training loss: 2.9864066832783656
Validation loss: 2.6081990173578093

Epoch: 6| Step: 13
Training loss: 2.428759235044504
Validation loss: 2.578596512630337

Epoch: 324| Step: 0
Training loss: 2.7946453050944804
Validation loss: 2.566418849377033

Epoch: 6| Step: 1
Training loss: 2.4176726275470957
Validation loss: 2.54610344409307

Epoch: 6| Step: 2
Training loss: 2.5289205499479848
Validation loss: 2.528013853978838

Epoch: 6| Step: 3
Training loss: 3.17395011784778
Validation loss: 2.5272144181133926

Epoch: 6| Step: 4
Training loss: 2.967540293727696
Validation loss: 2.530166464961552

Epoch: 6| Step: 5
Training loss: 2.8904999577050963
Validation loss: 2.533419373345946

Epoch: 6| Step: 6
Training loss: 2.7528330341759366
Validation loss: 2.529930272044336

Epoch: 6| Step: 7
Training loss: 3.0412987961247033
Validation loss: 2.5379291074004717

Epoch: 6| Step: 8
Training loss: 2.1926722821845828
Validation loss: 2.545535249255417

Epoch: 6| Step: 9
Training loss: 2.6860394612166694
Validation loss: 2.530580758026017

Epoch: 6| Step: 10
Training loss: 3.005959313945338
Validation loss: 2.5439671159133135

Epoch: 6| Step: 11
Training loss: 3.2921451430092143
Validation loss: 2.5399708435501327

Epoch: 6| Step: 12
Training loss: 2.7758226051760753
Validation loss: 2.5471940526795303

Epoch: 6| Step: 13
Training loss: 3.4757072168183925
Validation loss: 2.5492657341209233

Epoch: 325| Step: 0
Training loss: 1.732931550238641
Validation loss: 2.554332282847284

Epoch: 6| Step: 1
Training loss: 3.1802306215163507
Validation loss: 2.5696458023875395

Epoch: 6| Step: 2
Training loss: 2.1687200670622673
Validation loss: 2.593686328021915

Epoch: 6| Step: 3
Training loss: 2.6618265294187156
Validation loss: 2.6076576250770818

Epoch: 6| Step: 4
Training loss: 3.198506072128803
Validation loss: 2.6222414209409117

Epoch: 6| Step: 5
Training loss: 2.8070886900683973
Validation loss: 2.6438326963086762

Epoch: 6| Step: 6
Training loss: 3.1179637277094825
Validation loss: 2.621361937684483

Epoch: 6| Step: 7
Training loss: 2.9216817700143825
Validation loss: 2.595042251118713

Epoch: 6| Step: 8
Training loss: 3.1103891223693716
Validation loss: 2.5808477349144234

Epoch: 6| Step: 9
Training loss: 2.5947976811504043
Validation loss: 2.554248188127513

Epoch: 6| Step: 10
Training loss: 2.735972782345406
Validation loss: 2.547220667282656

Epoch: 6| Step: 11
Training loss: 3.4161968063193955
Validation loss: 2.5260272840203117

Epoch: 6| Step: 12
Training loss: 3.035067327465896
Validation loss: 2.531362994148434

Epoch: 6| Step: 13
Training loss: 2.8399352592825955
Validation loss: 2.529002993173481

Epoch: 326| Step: 0
Training loss: 3.14093532262728
Validation loss: 2.5213411030462898

Epoch: 6| Step: 1
Training loss: 2.86914760518637
Validation loss: 2.5246430500390895

Epoch: 6| Step: 2
Training loss: 2.905032651524058
Validation loss: 2.525020826869712

Epoch: 6| Step: 3
Training loss: 2.9160519269969085
Validation loss: 2.530716165622415

Epoch: 6| Step: 4
Training loss: 3.070093511095406
Validation loss: 2.531952906598065

Epoch: 6| Step: 5
Training loss: 2.8658716992066267
Validation loss: 2.5426376850854076

Epoch: 6| Step: 6
Training loss: 2.824591858674598
Validation loss: 2.5523214400322844

Epoch: 6| Step: 7
Training loss: 2.5867338769413384
Validation loss: 2.5513700257264587

Epoch: 6| Step: 8
Training loss: 2.327161243834098
Validation loss: 2.5574858705988

Epoch: 6| Step: 9
Training loss: 2.7657025859747435
Validation loss: 2.5808097575364513

Epoch: 6| Step: 10
Training loss: 2.638014727802247
Validation loss: 2.5739212184117255

Epoch: 6| Step: 11
Training loss: 2.8887877528101873
Validation loss: 2.5789337172546274

Epoch: 6| Step: 12
Training loss: 3.366728926230879
Validation loss: 2.5962209514418495

Epoch: 6| Step: 13
Training loss: 2.2171810136610106
Validation loss: 2.5851298015944995

Epoch: 327| Step: 0
Training loss: 3.052854646643085
Validation loss: 2.5949936242797507

Epoch: 6| Step: 1
Training loss: 2.7239155422567083
Validation loss: 2.6241958732296435

Epoch: 6| Step: 2
Training loss: 2.4592009699708495
Validation loss: 2.6345832960052333

Epoch: 6| Step: 3
Training loss: 2.6661443993624863
Validation loss: 2.6705388055839814

Epoch: 6| Step: 4
Training loss: 2.6734037431718254
Validation loss: 2.6757596363487828

Epoch: 6| Step: 5
Training loss: 2.845049718278241
Validation loss: 2.67287257910771

Epoch: 6| Step: 6
Training loss: 2.9425829475269123
Validation loss: 2.6596468878010318

Epoch: 6| Step: 7
Training loss: 3.2720661796088772
Validation loss: 2.598362338048074

Epoch: 6| Step: 8
Training loss: 2.879395152262206
Validation loss: 2.566677448091315

Epoch: 6| Step: 9
Training loss: 2.7310730970692902
Validation loss: 2.541029995786859

Epoch: 6| Step: 10
Training loss: 2.967389085941667
Validation loss: 2.5324507133774397

Epoch: 6| Step: 11
Training loss: 2.32625120397636
Validation loss: 2.528258248670033

Epoch: 6| Step: 12
Training loss: 3.3884160453682175
Validation loss: 2.534012673764646

Epoch: 6| Step: 13
Training loss: 2.799902188772514
Validation loss: 2.526116004173946

Epoch: 328| Step: 0
Training loss: 2.392041752696442
Validation loss: 2.5302266197131624

Epoch: 6| Step: 1
Training loss: 3.1055341605729203
Validation loss: 2.5287744364288383

Epoch: 6| Step: 2
Training loss: 2.788011710920873
Validation loss: 2.530180796046467

Epoch: 6| Step: 3
Training loss: 2.6299388382330644
Validation loss: 2.5311514135010498

Epoch: 6| Step: 4
Training loss: 3.110095990039655
Validation loss: 2.5350109312575793

Epoch: 6| Step: 5
Training loss: 2.9094496310748736
Validation loss: 2.5330504821627193

Epoch: 6| Step: 6
Training loss: 2.4007932544113926
Validation loss: 2.533880231712467

Epoch: 6| Step: 7
Training loss: 2.6852097622220445
Validation loss: 2.5388814609501176

Epoch: 6| Step: 8
Training loss: 2.2441408374809515
Validation loss: 2.530191203864947

Epoch: 6| Step: 9
Training loss: 3.6217212976816775
Validation loss: 2.5381015329096033

Epoch: 6| Step: 10
Training loss: 2.7618458245163575
Validation loss: 2.5359639389271984

Epoch: 6| Step: 11
Training loss: 3.4638538344206253
Validation loss: 2.5442201210038213

Epoch: 6| Step: 12
Training loss: 2.4130659793412814
Validation loss: 2.5418498314337206

Epoch: 6| Step: 13
Training loss: 3.357404405904597
Validation loss: 2.553737913845006

Epoch: 329| Step: 0
Training loss: 2.9133221296826806
Validation loss: 2.5668984987112378

Epoch: 6| Step: 1
Training loss: 2.3921540799288747
Validation loss: 2.584241381644316

Epoch: 6| Step: 2
Training loss: 2.399517499582873
Validation loss: 2.6156828599291595

Epoch: 6| Step: 3
Training loss: 2.570783670482587
Validation loss: 2.638585105066779

Epoch: 6| Step: 4
Training loss: 3.0507121646107014
Validation loss: 2.640600416119155

Epoch: 6| Step: 5
Training loss: 2.91646658801516
Validation loss: 2.637542894787624

Epoch: 6| Step: 6
Training loss: 3.050264478379133
Validation loss: 2.6163840252990735

Epoch: 6| Step: 7
Training loss: 3.0550224725424293
Validation loss: 2.603061752379222

Epoch: 6| Step: 8
Training loss: 1.9500614401112444
Validation loss: 2.5952317539257983

Epoch: 6| Step: 9
Training loss: 3.5332522496930414
Validation loss: 2.573603289639819

Epoch: 6| Step: 10
Training loss: 2.807872355931767
Validation loss: 2.5971058676569267

Epoch: 6| Step: 11
Training loss: 3.225586972307206
Validation loss: 2.5794571592878106

Epoch: 6| Step: 12
Training loss: 2.6964710344130736
Validation loss: 2.576442824264442

Epoch: 6| Step: 13
Training loss: 3.229291080826346
Validation loss: 2.5741887197352327

Epoch: 330| Step: 0
Training loss: 2.455861988433326
Validation loss: 2.566340627952145

Epoch: 6| Step: 1
Training loss: 2.836799259456359
Validation loss: 2.5450220706336553

Epoch: 6| Step: 2
Training loss: 2.898765853831902
Validation loss: 2.544593393504693

Epoch: 6| Step: 3
Training loss: 3.264843714947505
Validation loss: 2.5443091720513977

Epoch: 6| Step: 4
Training loss: 2.574029246925116
Validation loss: 2.5474131368137543

Epoch: 6| Step: 5
Training loss: 3.3207392878280295
Validation loss: 2.562374999336248

Epoch: 6| Step: 6
Training loss: 2.4362564827454514
Validation loss: 2.561911208416229

Epoch: 6| Step: 7
Training loss: 3.212249413598828
Validation loss: 2.5610178370896897

Epoch: 6| Step: 8
Training loss: 2.56303753681059
Validation loss: 2.5540665401859406

Epoch: 6| Step: 9
Training loss: 2.8755653488913495
Validation loss: 2.5619383585879167

Epoch: 6| Step: 10
Training loss: 2.8638242698439726
Validation loss: 2.5741840469570922

Epoch: 6| Step: 11
Training loss: 3.0653021312860655
Validation loss: 2.577060183987982

Epoch: 6| Step: 12
Training loss: 2.3345091672689975
Validation loss: 2.5830537371481466

Epoch: 6| Step: 13
Training loss: 3.626653359987119
Validation loss: 2.589156951806332

Epoch: 331| Step: 0
Training loss: 3.0867245213776404
Validation loss: 2.603329967995388

Epoch: 6| Step: 1
Training loss: 2.9369895978619365
Validation loss: 2.6211007422880312

Epoch: 6| Step: 2
Training loss: 2.580872152905121
Validation loss: 2.613799881115395

Epoch: 6| Step: 3
Training loss: 2.2947843210105945
Validation loss: 2.605584906175527

Epoch: 6| Step: 4
Training loss: 3.1091475667156376
Validation loss: 2.631918097644733

Epoch: 6| Step: 5
Training loss: 3.124518395506325
Validation loss: 2.6104710584341135

Epoch: 6| Step: 6
Training loss: 2.634632602102062
Validation loss: 2.615227675813606

Epoch: 6| Step: 7
Training loss: 2.3031709498217414
Validation loss: 2.6180923310780533

Epoch: 6| Step: 8
Training loss: 3.0019261216864543
Validation loss: 2.6269685587955878

Epoch: 6| Step: 9
Training loss: 3.060357570575346
Validation loss: 2.6141926276967276

Epoch: 6| Step: 10
Training loss: 2.791227979970363
Validation loss: 2.638704190989519

Epoch: 6| Step: 11
Training loss: 3.308647938974776
Validation loss: 2.663074110259149

Epoch: 6| Step: 12
Training loss: 2.6919107836241873
Validation loss: 2.6337171998570676

Epoch: 6| Step: 13
Training loss: 3.2997850348075617
Validation loss: 2.6070981340784813

Epoch: 332| Step: 0
Training loss: 3.19233785266788
Validation loss: 2.587034559761257

Epoch: 6| Step: 1
Training loss: 2.4497246957362173
Validation loss: 2.572818580030836

Epoch: 6| Step: 2
Training loss: 2.352318524973208
Validation loss: 2.561035323920401

Epoch: 6| Step: 3
Training loss: 2.952535580542615
Validation loss: 2.5595322838393835

Epoch: 6| Step: 4
Training loss: 3.013228022189575
Validation loss: 2.5568012916650926

Epoch: 6| Step: 5
Training loss: 2.9253776893324632
Validation loss: 2.5559181003327742

Epoch: 6| Step: 6
Training loss: 2.352291969887386
Validation loss: 2.5529848392921806

Epoch: 6| Step: 7
Training loss: 2.871203362065789
Validation loss: 2.551619455462823

Epoch: 6| Step: 8
Training loss: 3.118436711234117
Validation loss: 2.54908782537398

Epoch: 6| Step: 9
Training loss: 3.553595540772053
Validation loss: 2.5523998118680793

Epoch: 6| Step: 10
Training loss: 2.8530697536237994
Validation loss: 2.5585597287987603

Epoch: 6| Step: 11
Training loss: 2.3115954305302306
Validation loss: 2.5590003271637864

Epoch: 6| Step: 12
Training loss: 3.305420562025037
Validation loss: 2.5580918838828657

Epoch: 6| Step: 13
Training loss: 2.915149475766972
Validation loss: 2.5600570330688663

Epoch: 333| Step: 0
Training loss: 2.927842680879055
Validation loss: 2.5670533762152727

Epoch: 6| Step: 1
Training loss: 2.811326099822765
Validation loss: 2.569350016184587

Epoch: 6| Step: 2
Training loss: 2.76825110976146
Validation loss: 2.5788047702292753

Epoch: 6| Step: 3
Training loss: 2.740952259737687
Validation loss: 2.5808628265751086

Epoch: 6| Step: 4
Training loss: 2.7250946378460483
Validation loss: 2.5922034454334932

Epoch: 6| Step: 5
Training loss: 3.5180769444346853
Validation loss: 2.592565020446181

Epoch: 6| Step: 6
Training loss: 2.39246691386944
Validation loss: 2.609162402836646

Epoch: 6| Step: 7
Training loss: 2.3769587420332154
Validation loss: 2.6001752846369213

Epoch: 6| Step: 8
Training loss: 3.5904140745781272
Validation loss: 2.6023956741388448

Epoch: 6| Step: 9
Training loss: 3.0246663122324757
Validation loss: 2.6016180359007586

Epoch: 6| Step: 10
Training loss: 3.039055282466526
Validation loss: 2.6008271322328795

Epoch: 6| Step: 11
Training loss: 2.716316976059442
Validation loss: 2.616670803197169

Epoch: 6| Step: 12
Training loss: 2.836729837499418
Validation loss: 2.607521385649697

Epoch: 6| Step: 13
Training loss: 1.5984036439235494
Validation loss: 2.6543942999771404

Epoch: 334| Step: 0
Training loss: 2.8677994493410144
Validation loss: 2.6686046019619845

Epoch: 6| Step: 1
Training loss: 2.506348369694156
Validation loss: 2.66823257979284

Epoch: 6| Step: 2
Training loss: 2.8432400424346533
Validation loss: 2.6445856150420846

Epoch: 6| Step: 3
Training loss: 2.426522993858018
Validation loss: 2.640077096612585

Epoch: 6| Step: 4
Training loss: 3.314689632288133
Validation loss: 2.617831884725693

Epoch: 6| Step: 5
Training loss: 2.950449543984218
Validation loss: 2.59862814816122

Epoch: 6| Step: 6
Training loss: 3.048699561370869
Validation loss: 2.57554959322877

Epoch: 6| Step: 7
Training loss: 2.998449560700731
Validation loss: 2.550835065376533

Epoch: 6| Step: 8
Training loss: 3.3749239877688764
Validation loss: 2.54594520674952

Epoch: 6| Step: 9
Training loss: 2.789373300369364
Validation loss: 2.551976967947942

Epoch: 6| Step: 10
Training loss: 2.2817386469645813
Validation loss: 2.5476151374924783

Epoch: 6| Step: 11
Training loss: 2.7867321034403747
Validation loss: 2.5495492119711107

Epoch: 6| Step: 12
Training loss: 3.2075373335083115
Validation loss: 2.5524998646180768

Epoch: 6| Step: 13
Training loss: 2.455859755559558
Validation loss: 2.550342006095318

Epoch: 335| Step: 0
Training loss: 3.1578140160633885
Validation loss: 2.554959820575795

Epoch: 6| Step: 1
Training loss: 2.06974732943926
Validation loss: 2.5588881196073134

Epoch: 6| Step: 2
Training loss: 2.7238756292465918
Validation loss: 2.5673273927977847

Epoch: 6| Step: 3
Training loss: 3.0758852483033206
Validation loss: 2.56026676967111

Epoch: 6| Step: 4
Training loss: 2.9571207453741497
Validation loss: 2.559828475389601

Epoch: 6| Step: 5
Training loss: 3.359698896540438
Validation loss: 2.56467912141411

Epoch: 6| Step: 6
Training loss: 3.147282315120354
Validation loss: 2.565196054896079

Epoch: 6| Step: 7
Training loss: 2.691025661361746
Validation loss: 2.5729184176637623

Epoch: 6| Step: 8
Training loss: 2.852918997239419
Validation loss: 2.5807391355308806

Epoch: 6| Step: 9
Training loss: 2.3685213366129863
Validation loss: 2.5759941227023004

Epoch: 6| Step: 10
Training loss: 2.9107314802191846
Validation loss: 2.5937482386856234

Epoch: 6| Step: 11
Training loss: 2.620744252674657
Validation loss: 2.589277996175188

Epoch: 6| Step: 12
Training loss: 2.9894474720848487
Validation loss: 2.6106832966600018

Epoch: 6| Step: 13
Training loss: 2.992540781863419
Validation loss: 2.6294135606023663

Epoch: 336| Step: 0
Training loss: 3.6049734252712073
Validation loss: 2.6399695790574422

Epoch: 6| Step: 1
Training loss: 3.22962374169801
Validation loss: 2.6146424100586674

Epoch: 6| Step: 2
Training loss: 2.2103312709275027
Validation loss: 2.606088578015681

Epoch: 6| Step: 3
Training loss: 2.3307803583472686
Validation loss: 2.594596291812915

Epoch: 6| Step: 4
Training loss: 2.9023749656590168
Validation loss: 2.5952579934482767

Epoch: 6| Step: 5
Training loss: 3.0698415768780163
Validation loss: 2.585367888823851

Epoch: 6| Step: 6
Training loss: 2.7593355376898447
Validation loss: 2.5988542090087985

Epoch: 6| Step: 7
Training loss: 2.687334898379542
Validation loss: 2.5997551712833813

Epoch: 6| Step: 8
Training loss: 3.246714324940813
Validation loss: 2.5918873794005908

Epoch: 6| Step: 9
Training loss: 2.3375012321264927
Validation loss: 2.6174602250739594

Epoch: 6| Step: 10
Training loss: 2.8502133875150677
Validation loss: 2.62975170485166

Epoch: 6| Step: 11
Training loss: 2.448004267863374
Validation loss: 2.6265156721526064

Epoch: 6| Step: 12
Training loss: 3.173845552836766
Validation loss: 2.6222646527921345

Epoch: 6| Step: 13
Training loss: 2.6170863801010933
Validation loss: 2.60240513509828

Epoch: 337| Step: 0
Training loss: 3.3527696120752575
Validation loss: 2.5825678881887915

Epoch: 6| Step: 1
Training loss: 2.936659022944444
Validation loss: 2.578060892401252

Epoch: 6| Step: 2
Training loss: 3.5663484900853946
Validation loss: 2.5700105360761687

Epoch: 6| Step: 3
Training loss: 2.693353444093588
Validation loss: 2.556315271979515

Epoch: 6| Step: 4
Training loss: 2.947716013052057
Validation loss: 2.5543864419220212

Epoch: 6| Step: 5
Training loss: 2.918838636861776
Validation loss: 2.551358564844474

Epoch: 6| Step: 6
Training loss: 2.158325302325101
Validation loss: 2.54205160455377

Epoch: 6| Step: 7
Training loss: 2.447817558284322
Validation loss: 2.5417357562630385

Epoch: 6| Step: 8
Training loss: 3.156551535526633
Validation loss: 2.5570019441182765

Epoch: 6| Step: 9
Training loss: 2.9492522180944545
Validation loss: 2.5625757996047764

Epoch: 6| Step: 10
Training loss: 2.1850811254948628
Validation loss: 2.58596092813044

Epoch: 6| Step: 11
Training loss: 2.893519915997203
Validation loss: 2.6010905428381332

Epoch: 6| Step: 12
Training loss: 2.632892913043129
Validation loss: 2.6277424159159484

Epoch: 6| Step: 13
Training loss: 2.7848553381285317
Validation loss: 2.6446608872742483

Epoch: 338| Step: 0
Training loss: 2.6903200656830126
Validation loss: 2.627598690622932

Epoch: 6| Step: 1
Training loss: 2.5091994778825195
Validation loss: 2.6178385605997363

Epoch: 6| Step: 2
Training loss: 2.731620927497175
Validation loss: 2.5883218675200483

Epoch: 6| Step: 3
Training loss: 3.3726719491613997
Validation loss: 2.563909422659723

Epoch: 6| Step: 4
Training loss: 3.187957730806386
Validation loss: 2.558022331399767

Epoch: 6| Step: 5
Training loss: 2.715593807976339
Validation loss: 2.5550871315057355

Epoch: 6| Step: 6
Training loss: 2.573410810414403
Validation loss: 2.5683061803602967

Epoch: 6| Step: 7
Training loss: 2.6996275044382934
Validation loss: 2.5800894205505753

Epoch: 6| Step: 8
Training loss: 2.1516207330451222
Validation loss: 2.575660748466215

Epoch: 6| Step: 9
Training loss: 3.434420506711277
Validation loss: 2.6115689706039165

Epoch: 6| Step: 10
Training loss: 3.061232168162052
Validation loss: 2.6182365165262347

Epoch: 6| Step: 11
Training loss: 2.6838234882216407
Validation loss: 2.5962225155635554

Epoch: 6| Step: 12
Training loss: 2.8318888029908384
Validation loss: 2.586370894981076

Epoch: 6| Step: 13
Training loss: 2.372389312188028
Validation loss: 2.5627605866983743

Epoch: 339| Step: 0
Training loss: 2.5936349130858662
Validation loss: 2.5453233006337963

Epoch: 6| Step: 1
Training loss: 3.1625189136045098
Validation loss: 2.547130556544981

Epoch: 6| Step: 2
Training loss: 3.0621452904634077
Validation loss: 2.531483906651771

Epoch: 6| Step: 3
Training loss: 2.923826167960267
Validation loss: 2.5424354664078406

Epoch: 6| Step: 4
Training loss: 2.159519977919672
Validation loss: 2.5439030454322853

Epoch: 6| Step: 5
Training loss: 3.1849112376445916
Validation loss: 2.5467375957245664

Epoch: 6| Step: 6
Training loss: 2.8682214187638415
Validation loss: 2.5561847336550043

Epoch: 6| Step: 7
Training loss: 2.7070492169993576
Validation loss: 2.557615852362656

Epoch: 6| Step: 8
Training loss: 2.427132296307075
Validation loss: 2.565260387057108

Epoch: 6| Step: 9
Training loss: 3.2977470220975
Validation loss: 2.5770973621070494

Epoch: 6| Step: 10
Training loss: 2.5854143149349595
Validation loss: 2.557340887424865

Epoch: 6| Step: 11
Training loss: 2.8308508787452706
Validation loss: 2.574347093216578

Epoch: 6| Step: 12
Training loss: 2.596437831029349
Validation loss: 2.566112504059487

Epoch: 6| Step: 13
Training loss: 2.962196585654056
Validation loss: 2.5839363278275163

Epoch: 340| Step: 0
Training loss: 2.859967113119058
Validation loss: 2.581132646760465

Epoch: 6| Step: 1
Training loss: 2.9421800707512085
Validation loss: 2.5874340987248523

Epoch: 6| Step: 2
Training loss: 2.338423716764346
Validation loss: 2.6202645988165094

Epoch: 6| Step: 3
Training loss: 2.824659975231973
Validation loss: 2.6120126680974214

Epoch: 6| Step: 4
Training loss: 3.268066515681027
Validation loss: 2.6047171085221863

Epoch: 6| Step: 5
Training loss: 2.937221432727374
Validation loss: 2.578340430781655

Epoch: 6| Step: 6
Training loss: 2.525980043478909
Validation loss: 2.5465242048779992

Epoch: 6| Step: 7
Training loss: 2.8437067384887578
Validation loss: 2.5464992531636885

Epoch: 6| Step: 8
Training loss: 3.04300103029653
Validation loss: 2.5342120694233707

Epoch: 6| Step: 9
Training loss: 3.053837260288947
Validation loss: 2.5252717546760675

Epoch: 6| Step: 10
Training loss: 3.4603633361295727
Validation loss: 2.5268622333043123

Epoch: 6| Step: 11
Training loss: 2.4927553110017326
Validation loss: 2.520147209046105

Epoch: 6| Step: 12
Training loss: 2.208605935407555
Validation loss: 2.523840365095507

Epoch: 6| Step: 13
Training loss: 2.1927759034776706
Validation loss: 2.5317856507864565

Epoch: 341| Step: 0
Training loss: 2.7073364085812712
Validation loss: 2.5243735604533857

Epoch: 6| Step: 1
Training loss: 3.14935259145436
Validation loss: 2.527338918590732

Epoch: 6| Step: 2
Training loss: 2.65346461841894
Validation loss: 2.5169516756594557

Epoch: 6| Step: 3
Training loss: 2.4359210842673202
Validation loss: 2.52820032659742

Epoch: 6| Step: 4
Training loss: 2.6008921266425395
Validation loss: 2.5468923957049943

Epoch: 6| Step: 5
Training loss: 3.2989895805386293
Validation loss: 2.5686758649201296

Epoch: 6| Step: 6
Training loss: 2.5969435553103137
Validation loss: 2.5758938011616155

Epoch: 6| Step: 7
Training loss: 3.0262907694954237
Validation loss: 2.618152509189407

Epoch: 6| Step: 8
Training loss: 3.2732321007866396
Validation loss: 2.632090891793425

Epoch: 6| Step: 9
Training loss: 2.614651946323839
Validation loss: 2.6335727269227394

Epoch: 6| Step: 10
Training loss: 2.5857294926726855
Validation loss: 2.6237129468504383

Epoch: 6| Step: 11
Training loss: 3.069389534560279
Validation loss: 2.6490925968352346

Epoch: 6| Step: 12
Training loss: 2.940168751135936
Validation loss: 2.620622757040904

Epoch: 6| Step: 13
Training loss: 1.9880551432593037
Validation loss: 2.597660375260741

Epoch: 342| Step: 0
Training loss: 2.8528252301040222
Validation loss: 2.5392004528700434

Epoch: 6| Step: 1
Training loss: 2.7390060880328035
Validation loss: 2.529443858852654

Epoch: 6| Step: 2
Training loss: 2.5142569287157133
Validation loss: 2.517540419240099

Epoch: 6| Step: 3
Training loss: 2.676966940480821
Validation loss: 2.5221595363835956

Epoch: 6| Step: 4
Training loss: 2.636647857843275
Validation loss: 2.5195405326990867

Epoch: 6| Step: 5
Training loss: 2.761582259240967
Validation loss: 2.5147096505755546

Epoch: 6| Step: 6
Training loss: 2.094559470317046
Validation loss: 2.5169432277932056

Epoch: 6| Step: 7
Training loss: 3.1093679456774566
Validation loss: 2.512059806799682

Epoch: 6| Step: 8
Training loss: 2.6952895011473474
Validation loss: 2.514177457623067

Epoch: 6| Step: 9
Training loss: 3.4287835322349083
Validation loss: 2.5103542259013643

Epoch: 6| Step: 10
Training loss: 3.1375023040155106
Validation loss: 2.5242032928236773

Epoch: 6| Step: 11
Training loss: 2.598182292248733
Validation loss: 2.525243771714681

Epoch: 6| Step: 12
Training loss: 2.982792619546029
Validation loss: 2.5445045921940297

Epoch: 6| Step: 13
Training loss: 3.0109189328391746
Validation loss: 2.5793613267408717

Epoch: 343| Step: 0
Training loss: 3.5014883691446657
Validation loss: 2.5946371916262705

Epoch: 6| Step: 1
Training loss: 3.1421392785179765
Validation loss: 2.5802483628209285

Epoch: 6| Step: 2
Training loss: 2.281747110628514
Validation loss: 2.5946852175034643

Epoch: 6| Step: 3
Training loss: 2.996357295693728
Validation loss: 2.5688391480169877

Epoch: 6| Step: 4
Training loss: 1.964309103937972
Validation loss: 2.6091413712025444

Epoch: 6| Step: 5
Training loss: 2.1903050557708177
Validation loss: 2.5686834579953763

Epoch: 6| Step: 6
Training loss: 2.6877386297695627
Validation loss: 2.5574402897635418

Epoch: 6| Step: 7
Training loss: 2.72085875362499
Validation loss: 2.551110708414825

Epoch: 6| Step: 8
Training loss: 2.43583465809307
Validation loss: 2.546332727306082

Epoch: 6| Step: 9
Training loss: 2.751624061290061
Validation loss: 2.544579438786466

Epoch: 6| Step: 10
Training loss: 2.603620385411077
Validation loss: 2.5384444400324226

Epoch: 6| Step: 11
Training loss: 3.747491887893702
Validation loss: 2.534056118486619

Epoch: 6| Step: 12
Training loss: 2.7137993649315764
Validation loss: 2.5409533213921525

Epoch: 6| Step: 13
Training loss: 3.0440487004217838
Validation loss: 2.53776774395931

Epoch: 344| Step: 0
Training loss: 2.5374312104921657
Validation loss: 2.5480529569472172

Epoch: 6| Step: 1
Training loss: 2.6930352805086324
Validation loss: 2.5569742006248237

Epoch: 6| Step: 2
Training loss: 2.9985592879489187
Validation loss: 2.6094741198242284

Epoch: 6| Step: 3
Training loss: 2.7664483348076745
Validation loss: 2.6285438240843852

Epoch: 6| Step: 4
Training loss: 3.321435931266447
Validation loss: 2.631965963389118

Epoch: 6| Step: 5
Training loss: 2.533954070821377
Validation loss: 2.6388186238348097

Epoch: 6| Step: 6
Training loss: 2.3661427222356064
Validation loss: 2.6263931247815293

Epoch: 6| Step: 7
Training loss: 3.4995595109863555
Validation loss: 2.624238409144511

Epoch: 6| Step: 8
Training loss: 3.048953711729171
Validation loss: 2.567638923858232

Epoch: 6| Step: 9
Training loss: 3.218547036892039
Validation loss: 2.516464667012085

Epoch: 6| Step: 10
Training loss: 2.388454973255983
Validation loss: 2.5104112750586824

Epoch: 6| Step: 11
Training loss: 2.5705200853555508
Validation loss: 2.5143093683297484

Epoch: 6| Step: 12
Training loss: 2.438907705865372
Validation loss: 2.5121258089225265

Epoch: 6| Step: 13
Training loss: 2.422751483441667
Validation loss: 2.506039102534301

Epoch: 345| Step: 0
Training loss: 2.0226705268482714
Validation loss: 2.506916435905679

Epoch: 6| Step: 1
Training loss: 2.8629573206836585
Validation loss: 2.5083628038462957

Epoch: 6| Step: 2
Training loss: 3.2892888007157657
Validation loss: 2.5150685159501625

Epoch: 6| Step: 3
Training loss: 2.3280674460036783
Validation loss: 2.519091791109817

Epoch: 6| Step: 4
Training loss: 3.024855958646071
Validation loss: 2.5373222431467743

Epoch: 6| Step: 5
Training loss: 2.7438233107242223
Validation loss: 2.5384607664410628

Epoch: 6| Step: 6
Training loss: 2.712296906352479
Validation loss: 2.5634904313500924

Epoch: 6| Step: 7
Training loss: 2.131810438464085
Validation loss: 2.555748106619276

Epoch: 6| Step: 8
Training loss: 3.0075017595167077
Validation loss: 2.5608667320446057

Epoch: 6| Step: 9
Training loss: 2.437308279469366
Validation loss: 2.5570887033180356

Epoch: 6| Step: 10
Training loss: 3.3573537024056077
Validation loss: 2.5578783347823104

Epoch: 6| Step: 11
Training loss: 2.9154981906540485
Validation loss: 2.5694244992244113

Epoch: 6| Step: 12
Training loss: 3.289381867984514
Validation loss: 2.571947823498

Epoch: 6| Step: 13
Training loss: 2.664137763696971
Validation loss: 2.5705128866629114

Epoch: 346| Step: 0
Training loss: 2.4393515768057896
Validation loss: 2.5943907830695094

Epoch: 6| Step: 1
Training loss: 3.3188303792239173
Validation loss: 2.598160323158943

Epoch: 6| Step: 2
Training loss: 2.4207420406319042
Validation loss: 2.561654930722218

Epoch: 6| Step: 3
Training loss: 3.068859115494218
Validation loss: 2.5311174113637662

Epoch: 6| Step: 4
Training loss: 2.892634172946191
Validation loss: 2.526174297768709

Epoch: 6| Step: 5
Training loss: 2.3507050126284423
Validation loss: 2.515572045645999

Epoch: 6| Step: 6
Training loss: 3.3762135619732714
Validation loss: 2.5225756556481485

Epoch: 6| Step: 7
Training loss: 2.765822926136132
Validation loss: 2.5165363277065342

Epoch: 6| Step: 8
Training loss: 2.7019199044464557
Validation loss: 2.5166527318728273

Epoch: 6| Step: 9
Training loss: 3.055754414262246
Validation loss: 2.518142724332175

Epoch: 6| Step: 10
Training loss: 2.569957210021274
Validation loss: 2.5321012245833496

Epoch: 6| Step: 11
Training loss: 3.3132617002709615
Validation loss: 2.55175797927301

Epoch: 6| Step: 12
Training loss: 2.2933619615335226
Validation loss: 2.5750461444808033

Epoch: 6| Step: 13
Training loss: 2.34209923148436
Validation loss: 2.578168148849332

Epoch: 347| Step: 0
Training loss: 3.095789073629423
Validation loss: 2.591553874338192

Epoch: 6| Step: 1
Training loss: 2.648783523325827
Validation loss: 2.593777883364714

Epoch: 6| Step: 2
Training loss: 2.9078922348938345
Validation loss: 2.573494658493585

Epoch: 6| Step: 3
Training loss: 3.1186123987700376
Validation loss: 2.579815003572807

Epoch: 6| Step: 4
Training loss: 3.1518418149999574
Validation loss: 2.6000353382050276

Epoch: 6| Step: 5
Training loss: 2.1981972851228093
Validation loss: 2.6195879949012357

Epoch: 6| Step: 6
Training loss: 2.1913313963374454
Validation loss: 2.605688550336241

Epoch: 6| Step: 7
Training loss: 2.7801093001799884
Validation loss: 2.5586477697763534

Epoch: 6| Step: 8
Training loss: 2.397878674941664
Validation loss: 2.5620422334571944

Epoch: 6| Step: 9
Training loss: 2.413731030666698
Validation loss: 2.5533736268104468

Epoch: 6| Step: 10
Training loss: 3.240957150777194
Validation loss: 2.523151915544085

Epoch: 6| Step: 11
Training loss: 2.465568713958699
Validation loss: 2.522157332726275

Epoch: 6| Step: 12
Training loss: 3.110301737483577
Validation loss: 2.534652227301645

Epoch: 6| Step: 13
Training loss: 2.9989921148335794
Validation loss: 2.5248500170248334

Epoch: 348| Step: 0
Training loss: 2.7867168746270323
Validation loss: 2.5109857281776837

Epoch: 6| Step: 1
Training loss: 3.2188328111976974
Validation loss: 2.532494677884142

Epoch: 6| Step: 2
Training loss: 3.022291335861459
Validation loss: 2.547058003268619

Epoch: 6| Step: 3
Training loss: 2.0176177117894545
Validation loss: 2.5371098974063595

Epoch: 6| Step: 4
Training loss: 2.462035016149415
Validation loss: 2.552267220062481

Epoch: 6| Step: 5
Training loss: 2.852169776945867
Validation loss: 2.5449425065610476

Epoch: 6| Step: 6
Training loss: 3.2683682395657097
Validation loss: 2.5570808672793865

Epoch: 6| Step: 7
Training loss: 3.0269619214851535
Validation loss: 2.562411194950034

Epoch: 6| Step: 8
Training loss: 2.8727106018153354
Validation loss: 2.5752584869856134

Epoch: 6| Step: 9
Training loss: 2.5866959027312793
Validation loss: 2.58950931348015

Epoch: 6| Step: 10
Training loss: 2.563468284956874
Validation loss: 2.5958053524416203

Epoch: 6| Step: 11
Training loss: 2.2378637646824178
Validation loss: 2.6018243039773346

Epoch: 6| Step: 12
Training loss: 3.147334736309885
Validation loss: 2.5997085555451096

Epoch: 6| Step: 13
Training loss: 2.4210637856691353
Validation loss: 2.5864833563867182

Epoch: 349| Step: 0
Training loss: 2.491902206498178
Validation loss: 2.548027879345471

Epoch: 6| Step: 1
Training loss: 3.116649150969165
Validation loss: 2.555157750149917

Epoch: 6| Step: 2
Training loss: 3.4561254661709024
Validation loss: 2.55452226461488

Epoch: 6| Step: 3
Training loss: 2.1586942226181867
Validation loss: 2.5408025819698477

Epoch: 6| Step: 4
Training loss: 2.704838733202376
Validation loss: 2.561716972026489

Epoch: 6| Step: 5
Training loss: 2.8903249223994623
Validation loss: 2.577155966817032

Epoch: 6| Step: 6
Training loss: 2.8064757360391197
Validation loss: 2.5426414055631925

Epoch: 6| Step: 7
Training loss: 2.635585965434455
Validation loss: 2.5271656552891733

Epoch: 6| Step: 8
Training loss: 2.547085431538691
Validation loss: 2.5364448678567473

Epoch: 6| Step: 9
Training loss: 2.8967444726863745
Validation loss: 2.5311714918772847

Epoch: 6| Step: 10
Training loss: 2.649310572930403
Validation loss: 2.535632389123788

Epoch: 6| Step: 11
Training loss: 2.6749469430955943
Validation loss: 2.513644181058724

Epoch: 6| Step: 12
Training loss: 3.1829547264146365
Validation loss: 2.5088546060293955

Epoch: 6| Step: 13
Training loss: 2.0017936531377134
Validation loss: 2.4967542374619356

Epoch: 350| Step: 0
Training loss: 3.2511516877958964
Validation loss: 2.5252169600027288

Epoch: 6| Step: 1
Training loss: 2.4616171246577325
Validation loss: 2.5410607851561506

Epoch: 6| Step: 2
Training loss: 2.6216608335119282
Validation loss: 2.5852155464229893

Epoch: 6| Step: 3
Training loss: 2.6632839642637056
Validation loss: 2.628895179803119

Epoch: 6| Step: 4
Training loss: 2.9200169168269667
Validation loss: 2.6905090626433106

Epoch: 6| Step: 5
Training loss: 2.442753241694869
Validation loss: 2.644718784849151

Epoch: 6| Step: 6
Training loss: 2.7970571618456566
Validation loss: 2.627053326435078

Epoch: 6| Step: 7
Training loss: 2.6526871965886887
Validation loss: 2.599764738490307

Epoch: 6| Step: 8
Training loss: 2.3379226465669403
Validation loss: 2.5905273240169544

Epoch: 6| Step: 9
Training loss: 3.547873469903805
Validation loss: 2.5805859446781536

Epoch: 6| Step: 10
Training loss: 3.2161106287873746
Validation loss: 2.570165073438029

Epoch: 6| Step: 11
Training loss: 2.5895073443491117
Validation loss: 2.5210030682570292

Epoch: 6| Step: 12
Training loss: 3.113845142333602
Validation loss: 2.521277425590806

Epoch: 6| Step: 13
Training loss: 1.4730676536743434
Validation loss: 2.5093129408574653

Epoch: 351| Step: 0
Training loss: 3.0026101837142027
Validation loss: 2.520571466680641

Epoch: 6| Step: 1
Training loss: 3.1810776579514637
Validation loss: 2.5336559280372417

Epoch: 6| Step: 2
Training loss: 2.344607997249562
Validation loss: 2.551046293775674

Epoch: 6| Step: 3
Training loss: 3.0579320355005004
Validation loss: 2.5916613380080062

Epoch: 6| Step: 4
Training loss: 2.5825467193897595
Validation loss: 2.616635424773161

Epoch: 6| Step: 5
Training loss: 3.0224374304921904
Validation loss: 2.6151463960822787

Epoch: 6| Step: 6
Training loss: 2.826273106341788
Validation loss: 2.604314323587135

Epoch: 6| Step: 7
Training loss: 2.507141023386004
Validation loss: 2.5941843755601766

Epoch: 6| Step: 8
Training loss: 2.9588880063721454
Validation loss: 2.594066314940145

Epoch: 6| Step: 9
Training loss: 2.5483113550602683
Validation loss: 2.5707644240364367

Epoch: 6| Step: 10
Training loss: 2.779126674778048
Validation loss: 2.544105425578372

Epoch: 6| Step: 11
Training loss: 1.9995880298701103
Validation loss: 2.511869458905323

Epoch: 6| Step: 12
Training loss: 3.077580592620955
Validation loss: 2.5115886272986687

Epoch: 6| Step: 13
Training loss: 2.691110359392692
Validation loss: 2.504063048710179

Epoch: 352| Step: 0
Training loss: 2.695179015461593
Validation loss: 2.495523399953967

Epoch: 6| Step: 1
Training loss: 2.790023424467244
Validation loss: 2.4972950915055465

Epoch: 6| Step: 2
Training loss: 2.9526137459443045
Validation loss: 2.523303465561653

Epoch: 6| Step: 3
Training loss: 2.593634361538839
Validation loss: 2.5310279326445153

Epoch: 6| Step: 4
Training loss: 2.92356880582242
Validation loss: 2.5665408412720647

Epoch: 6| Step: 5
Training loss: 2.7980092055828494
Validation loss: 2.59882999548579

Epoch: 6| Step: 6
Training loss: 2.436415210835346
Validation loss: 2.6222815073161323

Epoch: 6| Step: 7
Training loss: 2.707105583282279
Validation loss: 2.602558436463323

Epoch: 6| Step: 8
Training loss: 2.8303660581292758
Validation loss: 2.573086525770947

Epoch: 6| Step: 9
Training loss: 3.2286101487221464
Validation loss: 2.5294040343180493

Epoch: 6| Step: 10
Training loss: 2.763133677995537
Validation loss: 2.5242645423134213

Epoch: 6| Step: 11
Training loss: 2.7527164567451097
Validation loss: 2.506602748943602

Epoch: 6| Step: 12
Training loss: 2.5299749106267595
Validation loss: 2.503612983948707

Epoch: 6| Step: 13
Training loss: 3.129619693259626
Validation loss: 2.4965790600283455

Epoch: 353| Step: 0
Training loss: 3.1345573760169843
Validation loss: 2.496257802203708

Epoch: 6| Step: 1
Training loss: 2.682200240765271
Validation loss: 2.4905821772374486

Epoch: 6| Step: 2
Training loss: 3.3056238169171226
Validation loss: 2.490628442277996

Epoch: 6| Step: 3
Training loss: 2.912040274687383
Validation loss: 2.4992674738824663

Epoch: 6| Step: 4
Training loss: 2.3094435417110923
Validation loss: 2.5056020298448702

Epoch: 6| Step: 5
Training loss: 2.2309397719532376
Validation loss: 2.510024389895213

Epoch: 6| Step: 6
Training loss: 2.6852487405536603
Validation loss: 2.5144425221047157

Epoch: 6| Step: 7
Training loss: 2.2970932837324436
Validation loss: 2.5497458271554843

Epoch: 6| Step: 8
Training loss: 2.8989997585753136
Validation loss: 2.5622827381279207

Epoch: 6| Step: 9
Training loss: 2.9912393128347237
Validation loss: 2.599501361194512

Epoch: 6| Step: 10
Training loss: 2.9298375612610297
Validation loss: 2.603805912420543

Epoch: 6| Step: 11
Training loss: 3.123141384543633
Validation loss: 2.5457828056383507

Epoch: 6| Step: 12
Training loss: 2.038587609892395
Validation loss: 2.527454064496265

Epoch: 6| Step: 13
Training loss: 3.3327515730227106
Validation loss: 2.4928574902479492

Epoch: 354| Step: 0
Training loss: 2.601287460680669
Validation loss: 2.499724397542166

Epoch: 6| Step: 1
Training loss: 3.0800013366299988
Validation loss: 2.4988075755582946

Epoch: 6| Step: 2
Training loss: 2.520954812225559
Validation loss: 2.4988106841715267

Epoch: 6| Step: 3
Training loss: 2.94066076469766
Validation loss: 2.506223063282878

Epoch: 6| Step: 4
Training loss: 2.8746135286056758
Validation loss: 2.503863481101917

Epoch: 6| Step: 5
Training loss: 3.112859106221409
Validation loss: 2.5055472081428105

Epoch: 6| Step: 6
Training loss: 2.9062683761179793
Validation loss: 2.5081148371366604

Epoch: 6| Step: 7
Training loss: 2.950573015326754
Validation loss: 2.520712677127409

Epoch: 6| Step: 8
Training loss: 1.986446710908279
Validation loss: 2.5276150781974964

Epoch: 6| Step: 9
Training loss: 2.457438570110492
Validation loss: 2.5360806816063115

Epoch: 6| Step: 10
Training loss: 2.6326178866488146
Validation loss: 2.548112877581783

Epoch: 6| Step: 11
Training loss: 2.981711432297016
Validation loss: 2.562511857248201

Epoch: 6| Step: 12
Training loss: 2.9371612028796887
Validation loss: 2.574618933525273

Epoch: 6| Step: 13
Training loss: 3.1276426204421206
Validation loss: 2.5831971164030336

Epoch: 355| Step: 0
Training loss: 2.3735083865139495
Validation loss: 2.583066831954624

Epoch: 6| Step: 1
Training loss: 2.9852878312934825
Validation loss: 2.5635044151312663

Epoch: 6| Step: 2
Training loss: 2.4105960191246134
Validation loss: 2.5666865702692245

Epoch: 6| Step: 3
Training loss: 2.646800027301172
Validation loss: 2.5484185839927824

Epoch: 6| Step: 4
Training loss: 3.123390088239147
Validation loss: 2.5555917223986357

Epoch: 6| Step: 5
Training loss: 2.5733734734357854
Validation loss: 2.560742634765639

Epoch: 6| Step: 6
Training loss: 3.038724198916394
Validation loss: 2.580830012803585

Epoch: 6| Step: 7
Training loss: 3.2996473181715054
Validation loss: 2.599690031099047

Epoch: 6| Step: 8
Training loss: 2.887334486936546
Validation loss: 2.562255179382605

Epoch: 6| Step: 9
Training loss: 2.4583987749947633
Validation loss: 2.5498408468969673

Epoch: 6| Step: 10
Training loss: 2.6360066674456406
Validation loss: 2.529952620820153

Epoch: 6| Step: 11
Training loss: 3.1088961898733736
Validation loss: 2.5405887198706165

Epoch: 6| Step: 12
Training loss: 2.582302708286091
Validation loss: 2.5192540577103557

Epoch: 6| Step: 13
Training loss: 2.1631809463474445
Validation loss: 2.534430277998567

Epoch: 356| Step: 0
Training loss: 2.9179399889814177
Validation loss: 2.5231652501081228

Epoch: 6| Step: 1
Training loss: 1.953697791985354
Validation loss: 2.5081275473961964

Epoch: 6| Step: 2
Training loss: 2.029317435343089
Validation loss: 2.5217378607635723

Epoch: 6| Step: 3
Training loss: 2.853267128821037
Validation loss: 2.5320669112104723

Epoch: 6| Step: 4
Training loss: 3.3755775240105903
Validation loss: 2.5382396369887585

Epoch: 6| Step: 5
Training loss: 3.4259317119270776
Validation loss: 2.531231001895702

Epoch: 6| Step: 6
Training loss: 2.513208591121189
Validation loss: 2.558774084671389

Epoch: 6| Step: 7
Training loss: 3.072178397422718
Validation loss: 2.583081466022014

Epoch: 6| Step: 8
Training loss: 2.677178189468625
Validation loss: 2.621815647103329

Epoch: 6| Step: 9
Training loss: 3.2302591424214353
Validation loss: 2.6083356204339516

Epoch: 6| Step: 10
Training loss: 2.1532541001016328
Validation loss: 2.580287721545865

Epoch: 6| Step: 11
Training loss: 2.671246460272765
Validation loss: 2.5727971865312274

Epoch: 6| Step: 12
Training loss: 2.7221710779830897
Validation loss: 2.5318863065267183

Epoch: 6| Step: 13
Training loss: 2.4576980826100043
Validation loss: 2.532243904950457

Epoch: 357| Step: 0
Training loss: 2.3056247680366133
Validation loss: 2.5080834184479084

Epoch: 6| Step: 1
Training loss: 2.8115368359462787
Validation loss: 2.506933394073195

Epoch: 6| Step: 2
Training loss: 2.7937102927302666
Validation loss: 2.5132841830543597

Epoch: 6| Step: 3
Training loss: 3.1096182109852037
Validation loss: 2.506390144947555

Epoch: 6| Step: 4
Training loss: 2.664455888179369
Validation loss: 2.505101137134278

Epoch: 6| Step: 5
Training loss: 2.807047751357226
Validation loss: 2.5134854301627754

Epoch: 6| Step: 6
Training loss: 2.398737885492773
Validation loss: 2.520297290865027

Epoch: 6| Step: 7
Training loss: 3.1162254742002684
Validation loss: 2.536955486783489

Epoch: 6| Step: 8
Training loss: 3.036925047159615
Validation loss: 2.555533968421295

Epoch: 6| Step: 9
Training loss: 1.797321496305247
Validation loss: 2.5621082057413362

Epoch: 6| Step: 10
Training loss: 3.131592320291748
Validation loss: 2.618649254537789

Epoch: 6| Step: 11
Training loss: 2.4194806476409525
Validation loss: 2.648671933002561

Epoch: 6| Step: 12
Training loss: 3.2506682369185618
Validation loss: 2.6631586965945004

Epoch: 6| Step: 13
Training loss: 2.8394783551035503
Validation loss: 2.636838019380341

Epoch: 358| Step: 0
Training loss: 2.712447040234231
Validation loss: 2.5857689791449903

Epoch: 6| Step: 1
Training loss: 1.9256155318015349
Validation loss: 2.5518173115959493

Epoch: 6| Step: 2
Training loss: 2.7442947507317874
Validation loss: 2.5172704462837414

Epoch: 6| Step: 3
Training loss: 2.530849566398698
Validation loss: 2.5044126125476285

Epoch: 6| Step: 4
Training loss: 2.7360953014797014
Validation loss: 2.5051157927462224

Epoch: 6| Step: 5
Training loss: 3.10701765863651
Validation loss: 2.4959953792366623

Epoch: 6| Step: 6
Training loss: 2.706643433197102
Validation loss: 2.5008030001727843

Epoch: 6| Step: 7
Training loss: 2.815471181785363
Validation loss: 2.498953718261276

Epoch: 6| Step: 8
Training loss: 2.8148909684200945
Validation loss: 2.505762635793791

Epoch: 6| Step: 9
Training loss: 2.8534781932007585
Validation loss: 2.4990606758309117

Epoch: 6| Step: 10
Training loss: 2.9137044487219277
Validation loss: 2.5015794061642365

Epoch: 6| Step: 11
Training loss: 2.7045079921520396
Validation loss: 2.5009446400072464

Epoch: 6| Step: 12
Training loss: 3.130524596593665
Validation loss: 2.515682577754358

Epoch: 6| Step: 13
Training loss: 3.273538883796933
Validation loss: 2.497431888072199

Epoch: 359| Step: 0
Training loss: 2.5627066366106694
Validation loss: 2.532044750180076

Epoch: 6| Step: 1
Training loss: 3.1483755555223776
Validation loss: 2.5154616748027046

Epoch: 6| Step: 2
Training loss: 2.358402380140338
Validation loss: 2.528592239527871

Epoch: 6| Step: 3
Training loss: 2.5638247531387806
Validation loss: 2.5270114354405004

Epoch: 6| Step: 4
Training loss: 2.902341778473422
Validation loss: 2.5526858420714325

Epoch: 6| Step: 5
Training loss: 2.7771220058334536
Validation loss: 2.5471034286956327

Epoch: 6| Step: 6
Training loss: 2.7997991523914156
Validation loss: 2.547000071891222

Epoch: 6| Step: 7
Training loss: 2.7332312235329024
Validation loss: 2.5566404194387076

Epoch: 6| Step: 8
Training loss: 2.6688077397767134
Validation loss: 2.562217191571583

Epoch: 6| Step: 9
Training loss: 2.561944854893282
Validation loss: 2.553262633897216

Epoch: 6| Step: 10
Training loss: 2.479003377286604
Validation loss: 2.5388466919213926

Epoch: 6| Step: 11
Training loss: 2.8506357855782003
Validation loss: 2.5355617878193653

Epoch: 6| Step: 12
Training loss: 2.9795821284769706
Validation loss: 2.520648759027086

Epoch: 6| Step: 13
Training loss: 3.2112731015691156
Validation loss: 2.5245453662316173

Epoch: 360| Step: 0
Training loss: 2.4018014187129713
Validation loss: 2.563233623441046

Epoch: 6| Step: 1
Training loss: 2.9792343523210465
Validation loss: 2.592109761501545

Epoch: 6| Step: 2
Training loss: 3.4149844672769984
Validation loss: 2.6274317071120046

Epoch: 6| Step: 3
Training loss: 2.0741352991246034
Validation loss: 2.6222812345552664

Epoch: 6| Step: 4
Training loss: 2.6646192757511513
Validation loss: 2.639392019068482

Epoch: 6| Step: 5
Training loss: 3.0658330102125246
Validation loss: 2.598369793067172

Epoch: 6| Step: 6
Training loss: 1.9784260284231039
Validation loss: 2.61637660201227

Epoch: 6| Step: 7
Training loss: 3.159882372103396
Validation loss: 2.589442870073116

Epoch: 6| Step: 8
Training loss: 2.3973677545218512
Validation loss: 2.577935423084957

Epoch: 6| Step: 9
Training loss: 2.713378247241575
Validation loss: 2.5879412753874993

Epoch: 6| Step: 10
Training loss: 3.2129743292667845
Validation loss: 2.5294465740698953

Epoch: 6| Step: 11
Training loss: 2.6154728525043995
Validation loss: 2.521707743316181

Epoch: 6| Step: 12
Training loss: 2.852969305965069
Validation loss: 2.50308828031602

Epoch: 6| Step: 13
Training loss: 2.660748252030085
Validation loss: 2.481905336493457

Epoch: 361| Step: 0
Training loss: 2.824576918392172
Validation loss: 2.488979602265458

Epoch: 6| Step: 1
Training loss: 3.1479066159794584
Validation loss: 2.4874979488393

Epoch: 6| Step: 2
Training loss: 2.823774669551275
Validation loss: 2.491708502763096

Epoch: 6| Step: 3
Training loss: 2.1717314089504876
Validation loss: 2.508036054577584

Epoch: 6| Step: 4
Training loss: 3.4333262681116783
Validation loss: 2.5144185846152673

Epoch: 6| Step: 5
Training loss: 2.746208524950756
Validation loss: 2.5132324870923513

Epoch: 6| Step: 6
Training loss: 2.2760890952841963
Validation loss: 2.589427358148813

Epoch: 6| Step: 7
Training loss: 3.1947295536205202
Validation loss: 2.5888338275491347

Epoch: 6| Step: 8
Training loss: 2.4016630371334577
Validation loss: 2.600572822470604

Epoch: 6| Step: 9
Training loss: 2.6520102379717785
Validation loss: 2.6110759862526947

Epoch: 6| Step: 10
Training loss: 2.854692136930929
Validation loss: 2.5764828590281117

Epoch: 6| Step: 11
Training loss: 2.5944076991105507
Validation loss: 2.5554141557535472

Epoch: 6| Step: 12
Training loss: 2.573698740926259
Validation loss: 2.5234595395302346

Epoch: 6| Step: 13
Training loss: 3.311611704211074
Validation loss: 2.511862940256861

Epoch: 362| Step: 0
Training loss: 2.9650869156705117
Validation loss: 2.511997598402773

Epoch: 6| Step: 1
Training loss: 2.625283543849675
Validation loss: 2.5039262140978846

Epoch: 6| Step: 2
Training loss: 2.592474934264561
Validation loss: 2.482468756835899

Epoch: 6| Step: 3
Training loss: 2.7055601055551746
Validation loss: 2.5105476985151105

Epoch: 6| Step: 4
Training loss: 2.5181799761843977
Validation loss: 2.5099650971550367

Epoch: 6| Step: 5
Training loss: 3.1964613660879087
Validation loss: 2.508409878447897

Epoch: 6| Step: 6
Training loss: 2.3508216476645813
Validation loss: 2.5062321917151005

Epoch: 6| Step: 7
Training loss: 2.8343573757914884
Validation loss: 2.5021007089862906

Epoch: 6| Step: 8
Training loss: 3.0125629909150375
Validation loss: 2.522035950721548

Epoch: 6| Step: 9
Training loss: 3.070044741226871
Validation loss: 2.5595600381667296

Epoch: 6| Step: 10
Training loss: 2.963634380014397
Validation loss: 2.575462803924682

Epoch: 6| Step: 11
Training loss: 2.5402339169781802
Validation loss: 2.609787152231935

Epoch: 6| Step: 12
Training loss: 2.420056651059214
Validation loss: 2.6202596687047484

Epoch: 6| Step: 13
Training loss: 2.7117988910883506
Validation loss: 2.6292539637611747

Epoch: 363| Step: 0
Training loss: 2.8089326062535944
Validation loss: 2.597503803204634

Epoch: 6| Step: 1
Training loss: 3.0391633867713823
Validation loss: 2.5617613769617815

Epoch: 6| Step: 2
Training loss: 2.5650731635116144
Validation loss: 2.570679637238069

Epoch: 6| Step: 3
Training loss: 2.497836416534003
Validation loss: 2.541767441802489

Epoch: 6| Step: 4
Training loss: 2.9021580920388406
Validation loss: 2.531706011982987

Epoch: 6| Step: 5
Training loss: 3.034061032993356
Validation loss: 2.5432396349662567

Epoch: 6| Step: 6
Training loss: 2.464603660243854
Validation loss: 2.528961098791371

Epoch: 6| Step: 7
Training loss: 2.9482556115647514
Validation loss: 2.5308013765581396

Epoch: 6| Step: 8
Training loss: 2.218421159472632
Validation loss: 2.506360674656033

Epoch: 6| Step: 9
Training loss: 2.7890033448514853
Validation loss: 2.5165294106023994

Epoch: 6| Step: 10
Training loss: 2.867100020485128
Validation loss: 2.521634787963851

Epoch: 6| Step: 11
Training loss: 2.5524960138811004
Validation loss: 2.5270032261330835

Epoch: 6| Step: 12
Training loss: 3.4488081379850395
Validation loss: 2.5378647996318247

Epoch: 6| Step: 13
Training loss: 1.4180687062576038
Validation loss: 2.517728961739224

Epoch: 364| Step: 0
Training loss: 2.980184278998866
Validation loss: 2.5170649572379302

Epoch: 6| Step: 1
Training loss: 2.282415223067065
Validation loss: 2.49634438960827

Epoch: 6| Step: 2
Training loss: 2.5989103344681257
Validation loss: 2.5218552752171717

Epoch: 6| Step: 3
Training loss: 2.597871745643253
Validation loss: 2.5267661784869064

Epoch: 6| Step: 4
Training loss: 2.8047355286462636
Validation loss: 2.5288078993146517

Epoch: 6| Step: 5
Training loss: 2.625935705625354
Validation loss: 2.52668442527547

Epoch: 6| Step: 6
Training loss: 3.3040603511554005
Validation loss: 2.5285834118261845

Epoch: 6| Step: 7
Training loss: 3.413464945649898
Validation loss: 2.514463728992479

Epoch: 6| Step: 8
Training loss: 2.77349887833711
Validation loss: 2.509712449973207

Epoch: 6| Step: 9
Training loss: 2.332564658753979
Validation loss: 2.5328025295242527

Epoch: 6| Step: 10
Training loss: 2.459859945140583
Validation loss: 2.5254809439856034

Epoch: 6| Step: 11
Training loss: 3.0399634587450834
Validation loss: 2.543158206681116

Epoch: 6| Step: 12
Training loss: 2.311703106465319
Validation loss: 2.5362174229727756

Epoch: 6| Step: 13
Training loss: 2.629882268554994
Validation loss: 2.5601660070828225

Epoch: 365| Step: 0
Training loss: 2.1721752151363587
Validation loss: 2.5602914960929444

Epoch: 6| Step: 1
Training loss: 2.222265762326415
Validation loss: 2.568388934421333

Epoch: 6| Step: 2
Training loss: 3.2230569116465957
Validation loss: 2.54058633088809

Epoch: 6| Step: 3
Training loss: 2.7771484478020168
Validation loss: 2.5348813589721346

Epoch: 6| Step: 4
Training loss: 2.798027099641744
Validation loss: 2.5355321884548276

Epoch: 6| Step: 5
Training loss: 2.06569378113609
Validation loss: 2.5134255928030784

Epoch: 6| Step: 6
Training loss: 2.974592703498915
Validation loss: 2.5000127976612965

Epoch: 6| Step: 7
Training loss: 3.1589093477356887
Validation loss: 2.5081584391400624

Epoch: 6| Step: 8
Training loss: 3.121852968613609
Validation loss: 2.5302216965407203

Epoch: 6| Step: 9
Training loss: 3.049163115705153
Validation loss: 2.5300830524643345

Epoch: 6| Step: 10
Training loss: 2.783421900666842
Validation loss: 2.558734491205494

Epoch: 6| Step: 11
Training loss: 2.527590614301905
Validation loss: 2.555350694326369

Epoch: 6| Step: 12
Training loss: 2.24645037929633
Validation loss: 2.5772341792933458

Epoch: 6| Step: 13
Training loss: 3.1112988525086402
Validation loss: 2.56917038194727

Epoch: 366| Step: 0
Training loss: 3.151466900004849
Validation loss: 2.544846207386239

Epoch: 6| Step: 1
Training loss: 3.000577235319429
Validation loss: 2.5285459614266377

Epoch: 6| Step: 2
Training loss: 2.726100937215138
Validation loss: 2.531804676118599

Epoch: 6| Step: 3
Training loss: 2.684412935319753
Validation loss: 2.5220683254180054

Epoch: 6| Step: 4
Training loss: 2.789358940719336
Validation loss: 2.5093490263127034

Epoch: 6| Step: 5
Training loss: 2.4925221185649775
Validation loss: 2.516933777638666

Epoch: 6| Step: 6
Training loss: 2.5282439289953715
Validation loss: 2.5014764809600036

Epoch: 6| Step: 7
Training loss: 3.2822904844452427
Validation loss: 2.5272581343958964

Epoch: 6| Step: 8
Training loss: 2.303311832877845
Validation loss: 2.5251186861978727

Epoch: 6| Step: 9
Training loss: 2.5823658597956043
Validation loss: 2.5628751484655194

Epoch: 6| Step: 10
Training loss: 2.3023641998967204
Validation loss: 2.6113561524941447

Epoch: 6| Step: 11
Training loss: 2.8398707833243053
Validation loss: 2.5878401945358274

Epoch: 6| Step: 12
Training loss: 2.6984052964295095
Validation loss: 2.5792648187283094

Epoch: 6| Step: 13
Training loss: 3.2167701928538217
Validation loss: 2.564143644402945

Epoch: 367| Step: 0
Training loss: 2.7462857045008717
Validation loss: 2.5207143776011423

Epoch: 6| Step: 1
Training loss: 2.683122307513699
Validation loss: 2.4958417889402513

Epoch: 6| Step: 2
Training loss: 2.716553337760139
Validation loss: 2.4827017587249496

Epoch: 6| Step: 3
Training loss: 2.8162902723498378
Validation loss: 2.4794660494152776

Epoch: 6| Step: 4
Training loss: 2.78080917465268
Validation loss: 2.4867858065920836

Epoch: 6| Step: 5
Training loss: 2.8449370872366355
Validation loss: 2.487407397783333

Epoch: 6| Step: 6
Training loss: 2.484449085594457
Validation loss: 2.4892450821019

Epoch: 6| Step: 7
Training loss: 3.1423172827673866
Validation loss: 2.4943451741440468

Epoch: 6| Step: 8
Training loss: 2.600918526892512
Validation loss: 2.492949062972078

Epoch: 6| Step: 9
Training loss: 2.332942101058942
Validation loss: 2.488742328139034

Epoch: 6| Step: 10
Training loss: 2.806126217565324
Validation loss: 2.486386131668965

Epoch: 6| Step: 11
Training loss: 3.261886281719239
Validation loss: 2.4826339190018123

Epoch: 6| Step: 12
Training loss: 3.2098045113714795
Validation loss: 2.4867597523862806

Epoch: 6| Step: 13
Training loss: 2.830066667721805
Validation loss: 2.48367086606526

Epoch: 368| Step: 0
Training loss: 2.913092321324299
Validation loss: 2.485587749350852

Epoch: 6| Step: 1
Training loss: 3.1915039645192347
Validation loss: 2.4956714689463695

Epoch: 6| Step: 2
Training loss: 2.993616783666328
Validation loss: 2.520084154519561

Epoch: 6| Step: 3
Training loss: 2.593172307772442
Validation loss: 2.5447875426350604

Epoch: 6| Step: 4
Training loss: 2.185331959593463
Validation loss: 2.5723167604523542

Epoch: 6| Step: 5
Training loss: 2.5568107157896836
Validation loss: 2.5577527804991607

Epoch: 6| Step: 6
Training loss: 2.6343994791108565
Validation loss: 2.5963189619902285

Epoch: 6| Step: 7
Training loss: 3.116539909382664
Validation loss: 2.652542364167171

Epoch: 6| Step: 8
Training loss: 2.6546406975853376
Validation loss: 2.6813890827199507

Epoch: 6| Step: 9
Training loss: 2.975438503998471
Validation loss: 2.6658807360318457

Epoch: 6| Step: 10
Training loss: 2.6673821939698246
Validation loss: 2.585480907481911

Epoch: 6| Step: 11
Training loss: 3.210427051076034
Validation loss: 2.5478813517946635

Epoch: 6| Step: 12
Training loss: 2.220962281148572
Validation loss: 2.5167072974010165

Epoch: 6| Step: 13
Training loss: 2.6570497991670963
Validation loss: 2.505841508243343

Epoch: 369| Step: 0
Training loss: 2.928542093801285
Validation loss: 2.493437029040735

Epoch: 6| Step: 1
Training loss: 2.328683056608865
Validation loss: 2.484679934175694

Epoch: 6| Step: 2
Training loss: 2.8666020349121535
Validation loss: 2.485132549369248

Epoch: 6| Step: 3
Training loss: 3.0829847671473973
Validation loss: 2.475857085419367

Epoch: 6| Step: 4
Training loss: 2.8826452687457684
Validation loss: 2.4790240352140716

Epoch: 6| Step: 5
Training loss: 3.1528734331749058
Validation loss: 2.478241662509376

Epoch: 6| Step: 6
Training loss: 3.1178302150107196
Validation loss: 2.485916404557012

Epoch: 6| Step: 7
Training loss: 2.528488065209037
Validation loss: 2.497302165568463

Epoch: 6| Step: 8
Training loss: 2.336322561313859
Validation loss: 2.506025819037709

Epoch: 6| Step: 9
Training loss: 2.6114442581225528
Validation loss: 2.514700211397084

Epoch: 6| Step: 10
Training loss: 3.1468918558406096
Validation loss: 2.5289466898343416

Epoch: 6| Step: 11
Training loss: 2.9898468503993265
Validation loss: 2.5606488069834463

Epoch: 6| Step: 12
Training loss: 2.0764344875583784
Validation loss: 2.5904558550655237

Epoch: 6| Step: 13
Training loss: 2.2652642324564876
Validation loss: 2.62245211612295

Epoch: 370| Step: 0
Training loss: 2.588239768605776
Validation loss: 2.6230204189198645

Epoch: 6| Step: 1
Training loss: 3.022644412090737
Validation loss: 2.612390084046292

Epoch: 6| Step: 2
Training loss: 2.6395489006737214
Validation loss: 2.609645954948944

Epoch: 6| Step: 3
Training loss: 2.2994639020667313
Validation loss: 2.6247376527180677

Epoch: 6| Step: 4
Training loss: 2.9533545995194905
Validation loss: 2.5518563212086476

Epoch: 6| Step: 5
Training loss: 2.4751585822885787
Validation loss: 2.5459925682227422

Epoch: 6| Step: 6
Training loss: 2.659492219343026
Validation loss: 2.508597019358074

Epoch: 6| Step: 7
Training loss: 2.7113236473847824
Validation loss: 2.494268418276264

Epoch: 6| Step: 8
Training loss: 2.8981540263690406
Validation loss: 2.4864831762397968

Epoch: 6| Step: 9
Training loss: 3.106552453158658
Validation loss: 2.479751424539707

Epoch: 6| Step: 10
Training loss: 2.7306208534060805
Validation loss: 2.479286826029231

Epoch: 6| Step: 11
Training loss: 2.9404986071610066
Validation loss: 2.478205436507314

Epoch: 6| Step: 12
Training loss: 2.669515181111555
Validation loss: 2.481734132359235

Epoch: 6| Step: 13
Training loss: 2.9624839106255636
Validation loss: 2.4723213120713847

Epoch: 371| Step: 0
Training loss: 2.9353217307000143
Validation loss: 2.484481735965292

Epoch: 6| Step: 1
Training loss: 2.744969535338956
Validation loss: 2.4876502487755854

Epoch: 6| Step: 2
Training loss: 2.4935536242728014
Validation loss: 2.484774734287411

Epoch: 6| Step: 3
Training loss: 2.9620050201888626
Validation loss: 2.477770557977357

Epoch: 6| Step: 4
Training loss: 2.9659093818943436
Validation loss: 2.4997070448491434

Epoch: 6| Step: 5
Training loss: 2.4790661788791954
Validation loss: 2.5078998538065074

Epoch: 6| Step: 6
Training loss: 2.9025758878921915
Validation loss: 2.524061298545763

Epoch: 6| Step: 7
Training loss: 2.6352220144245186
Validation loss: 2.582162215158927

Epoch: 6| Step: 8
Training loss: 2.774396445820302
Validation loss: 2.6466461796945446

Epoch: 6| Step: 9
Training loss: 2.502417825727315
Validation loss: 2.659780622073358

Epoch: 6| Step: 10
Training loss: 3.278167875607731
Validation loss: 2.6963743700781997

Epoch: 6| Step: 11
Training loss: 2.9566126014327905
Validation loss: 2.650009274984061

Epoch: 6| Step: 12
Training loss: 2.4521217967613973
Validation loss: 2.5879502552520206

Epoch: 6| Step: 13
Training loss: 1.9368363751341953
Validation loss: 2.5531796164861307

Epoch: 372| Step: 0
Training loss: 2.157471131344906
Validation loss: 2.527713808706726

Epoch: 6| Step: 1
Training loss: 3.1117406692518226
Validation loss: 2.5032924813451007

Epoch: 6| Step: 2
Training loss: 2.9180932688667895
Validation loss: 2.504133960684402

Epoch: 6| Step: 3
Training loss: 3.151881906175432
Validation loss: 2.5025586248116847

Epoch: 6| Step: 4
Training loss: 2.449507846836059
Validation loss: 2.5106701092153396

Epoch: 6| Step: 5
Training loss: 2.6972901980574173
Validation loss: 2.512818599526886

Epoch: 6| Step: 6
Training loss: 2.8145134394560825
Validation loss: 2.5187136054141805

Epoch: 6| Step: 7
Training loss: 2.8009900556590046
Validation loss: 2.5148483154557995

Epoch: 6| Step: 8
Training loss: 3.018788314165501
Validation loss: 2.5284289935393502

Epoch: 6| Step: 9
Training loss: 2.757654115273056
Validation loss: 2.4985513181418053

Epoch: 6| Step: 10
Training loss: 2.5588198962259967
Validation loss: 2.514703687759191

Epoch: 6| Step: 11
Training loss: 2.561052983806516
Validation loss: 2.519605854542316

Epoch: 6| Step: 12
Training loss: 2.7783040936202785
Validation loss: 2.5142455811001647

Epoch: 6| Step: 13
Training loss: 2.241748727007892
Validation loss: 2.515060162670813

Epoch: 373| Step: 0
Training loss: 2.889314096490922
Validation loss: 2.512524546302979

Epoch: 6| Step: 1
Training loss: 2.3225526624279107
Validation loss: 2.5218557631703855

Epoch: 6| Step: 2
Training loss: 2.7066809577595934
Validation loss: 2.5310699852612886

Epoch: 6| Step: 3
Training loss: 2.3128755625340793
Validation loss: 2.5274042265337613

Epoch: 6| Step: 4
Training loss: 3.0101317344556295
Validation loss: 2.5307427022917195

Epoch: 6| Step: 5
Training loss: 2.507168030447491
Validation loss: 2.518848046427308

Epoch: 6| Step: 6
Training loss: 2.6122393391359067
Validation loss: 2.521880390453076

Epoch: 6| Step: 7
Training loss: 2.855711210422718
Validation loss: 2.4989065178449272

Epoch: 6| Step: 8
Training loss: 2.8509157884484604
Validation loss: 2.4875844155281164

Epoch: 6| Step: 9
Training loss: 2.7362746261387723
Validation loss: 2.4850978314438574

Epoch: 6| Step: 10
Training loss: 2.9409912140788625
Validation loss: 2.497690809929427

Epoch: 6| Step: 11
Training loss: 2.8152176336852195
Validation loss: 2.4951317558556005

Epoch: 6| Step: 12
Training loss: 2.9005596278623815
Validation loss: 2.5034717633791006

Epoch: 6| Step: 13
Training loss: 2.7910057158457753
Validation loss: 2.49727906263756

Epoch: 374| Step: 0
Training loss: 2.74183969927555
Validation loss: 2.5130823567250293

Epoch: 6| Step: 1
Training loss: 2.605156326435797
Validation loss: 2.523148942081134

Epoch: 6| Step: 2
Training loss: 2.689456670976239
Validation loss: 2.513155987766133

Epoch: 6| Step: 3
Training loss: 2.6662686964936326
Validation loss: 2.52951838690998

Epoch: 6| Step: 4
Training loss: 2.791832582088753
Validation loss: 2.520803236944844

Epoch: 6| Step: 5
Training loss: 3.047002701650786
Validation loss: 2.523260252265142

Epoch: 6| Step: 6
Training loss: 2.566541322727357
Validation loss: 2.5136260575475813

Epoch: 6| Step: 7
Training loss: 2.601934366311771
Validation loss: 2.5254610898811483

Epoch: 6| Step: 8
Training loss: 2.6858619310933927
Validation loss: 2.515880106313825

Epoch: 6| Step: 9
Training loss: 2.868201468889118
Validation loss: 2.515488486030748

Epoch: 6| Step: 10
Training loss: 2.8403086537551148
Validation loss: 2.502015404850154

Epoch: 6| Step: 11
Training loss: 2.6487696616580347
Validation loss: 2.5112773073744723

Epoch: 6| Step: 12
Training loss: 2.434562967704775
Validation loss: 2.5166733109760595

Epoch: 6| Step: 13
Training loss: 3.199782250863626
Validation loss: 2.5012360665244735

Epoch: 375| Step: 0
Training loss: 3.150799870737501
Validation loss: 2.516548479963176

Epoch: 6| Step: 1
Training loss: 2.8267452183041404
Validation loss: 2.531208505395462

Epoch: 6| Step: 2
Training loss: 2.1491899871842843
Validation loss: 2.5672169202874424

Epoch: 6| Step: 3
Training loss: 2.949006129804665
Validation loss: 2.5915416217169795

Epoch: 6| Step: 4
Training loss: 2.733915017811541
Validation loss: 2.561874136139295

Epoch: 6| Step: 5
Training loss: 2.725935462182099
Validation loss: 2.5340870411489025

Epoch: 6| Step: 6
Training loss: 2.5966090794920285
Validation loss: 2.5109015763934464

Epoch: 6| Step: 7
Training loss: 2.6681355861258114
Validation loss: 2.47660453856201

Epoch: 6| Step: 8
Training loss: 2.5614999820218523
Validation loss: 2.4753432958793984

Epoch: 6| Step: 9
Training loss: 3.2547716178407597
Validation loss: 2.4977991999793057

Epoch: 6| Step: 10
Training loss: 2.1493391884462922
Validation loss: 2.4786528850078

Epoch: 6| Step: 11
Training loss: 2.5759273525798516
Validation loss: 2.5095825644391354

Epoch: 6| Step: 12
Training loss: 2.5661556870586377
Validation loss: 2.5110594589828414

Epoch: 6| Step: 13
Training loss: 3.558669456907712
Validation loss: 2.519090490508708

Epoch: 376| Step: 0
Training loss: 2.885079668290429
Validation loss: 2.5349348464440418

Epoch: 6| Step: 1
Training loss: 2.4612345198361942
Validation loss: 2.5039679780581325

Epoch: 6| Step: 2
Training loss: 2.2232467859095464
Validation loss: 2.507814109039378

Epoch: 6| Step: 3
Training loss: 2.4057651378064553
Validation loss: 2.531051098235024

Epoch: 6| Step: 4
Training loss: 2.70172012072268
Validation loss: 2.502322206440984

Epoch: 6| Step: 5
Training loss: 3.1323861381375058
Validation loss: 2.497440890555093

Epoch: 6| Step: 6
Training loss: 2.959206429889971
Validation loss: 2.491676998607442

Epoch: 6| Step: 7
Training loss: 2.6488262780130616
Validation loss: 2.4754287123860363

Epoch: 6| Step: 8
Training loss: 3.1904686959564312
Validation loss: 2.4789742081156994

Epoch: 6| Step: 9
Training loss: 2.756428919929734
Validation loss: 2.4956197142649623

Epoch: 6| Step: 10
Training loss: 2.466124865165172
Validation loss: 2.4720814621692377

Epoch: 6| Step: 11
Training loss: 2.403909511024661
Validation loss: 2.4794430692825182

Epoch: 6| Step: 12
Training loss: 2.6641045620190296
Validation loss: 2.5037205298811687

Epoch: 6| Step: 13
Training loss: 3.3076683650915992
Validation loss: 2.535179611460692

Epoch: 377| Step: 0
Training loss: 2.1249656674472623
Validation loss: 2.552362270987295

Epoch: 6| Step: 1
Training loss: 2.2917813243504184
Validation loss: 2.5698301399610113

Epoch: 6| Step: 2
Training loss: 2.8196149898702614
Validation loss: 2.5951884857439205

Epoch: 6| Step: 3
Training loss: 2.6122376962788727
Validation loss: 2.6121605927152673

Epoch: 6| Step: 4
Training loss: 3.101306664511549
Validation loss: 2.5905061123903335

Epoch: 6| Step: 5
Training loss: 2.99718120390933
Validation loss: 2.5974646224444795

Epoch: 6| Step: 6
Training loss: 2.446064793705617
Validation loss: 2.57290755395636

Epoch: 6| Step: 7
Training loss: 2.9239786500477494
Validation loss: 2.5235480258897645

Epoch: 6| Step: 8
Training loss: 2.671638165958693
Validation loss: 2.49670311309728

Epoch: 6| Step: 9
Training loss: 2.8127958354068516
Validation loss: 2.4767944272885933

Epoch: 6| Step: 10
Training loss: 3.001799361709404
Validation loss: 2.480632301876878

Epoch: 6| Step: 11
Training loss: 2.935884559076885
Validation loss: 2.4760933744818385

Epoch: 6| Step: 12
Training loss: 2.891941080255599
Validation loss: 2.4767595081248546

Epoch: 6| Step: 13
Training loss: 2.278733838516319
Validation loss: 2.473622272422799

Epoch: 378| Step: 0
Training loss: 2.1948429569382264
Validation loss: 2.4802873856012764

Epoch: 6| Step: 1
Training loss: 2.8146801446001373
Validation loss: 2.479802014479322

Epoch: 6| Step: 2
Training loss: 2.3653368876486778
Validation loss: 2.464265809335115

Epoch: 6| Step: 3
Training loss: 2.377978013818484
Validation loss: 2.493227073962135

Epoch: 6| Step: 4
Training loss: 3.1458935931836267
Validation loss: 2.4774978231162192

Epoch: 6| Step: 5
Training loss: 3.107923005730016
Validation loss: 2.503513734091874

Epoch: 6| Step: 6
Training loss: 2.610343616272277
Validation loss: 2.5211432061508514

Epoch: 6| Step: 7
Training loss: 2.5291633953678736
Validation loss: 2.5719444195259276

Epoch: 6| Step: 8
Training loss: 2.8055236760039386
Validation loss: 2.604588274554389

Epoch: 6| Step: 9
Training loss: 2.2088241991275286
Validation loss: 2.627032491705893

Epoch: 6| Step: 10
Training loss: 3.292644950902705
Validation loss: 2.593260189914178

Epoch: 6| Step: 11
Training loss: 2.2361121194125073
Validation loss: 2.5449641745064637

Epoch: 6| Step: 12
Training loss: 3.47994330107879
Validation loss: 2.4939180123302154

Epoch: 6| Step: 13
Training loss: 2.92235181865181
Validation loss: 2.472829488431283

Epoch: 379| Step: 0
Training loss: 3.2434570768246807
Validation loss: 2.4803938540661763

Epoch: 6| Step: 1
Training loss: 3.2557753086964976
Validation loss: 2.4758731256135587

Epoch: 6| Step: 2
Training loss: 2.331438510012747
Validation loss: 2.4674687963612

Epoch: 6| Step: 3
Training loss: 2.301961029624346
Validation loss: 2.4777191608982414

Epoch: 6| Step: 4
Training loss: 2.5483903180028418
Validation loss: 2.4821911469152256

Epoch: 6| Step: 5
Training loss: 2.689573508278423
Validation loss: 2.4816561677599736

Epoch: 6| Step: 6
Training loss: 2.716237277243846
Validation loss: 2.4803406901719214

Epoch: 6| Step: 7
Training loss: 2.3249505437697686
Validation loss: 2.4823298251127444

Epoch: 6| Step: 8
Training loss: 2.6884564316865736
Validation loss: 2.488082385576524

Epoch: 6| Step: 9
Training loss: 2.632229250817151
Validation loss: 2.5053594239786867

Epoch: 6| Step: 10
Training loss: 2.736921334615999
Validation loss: 2.5118491211152456

Epoch: 6| Step: 11
Training loss: 3.055010610209269
Validation loss: 2.5305448081763635

Epoch: 6| Step: 12
Training loss: 3.3709356065346783
Validation loss: 2.5480925453505234

Epoch: 6| Step: 13
Training loss: 2.717454009452147
Validation loss: 2.5614284743152558

Epoch: 380| Step: 0
Training loss: 2.334487516048319
Validation loss: 2.5641446672020582

Epoch: 6| Step: 1
Training loss: 2.6522763318129976
Validation loss: 2.6139955865452857

Epoch: 6| Step: 2
Training loss: 2.9235727202451325
Validation loss: 2.6401058724815414

Epoch: 6| Step: 3
Training loss: 2.7326798770539007
Validation loss: 2.640359146609705

Epoch: 6| Step: 4
Training loss: 3.2108175065018245
Validation loss: 2.593986489576991

Epoch: 6| Step: 5
Training loss: 3.2385303875438503
Validation loss: 2.558002514894645

Epoch: 6| Step: 6
Training loss: 2.1223915022043296
Validation loss: 2.51316171147421

Epoch: 6| Step: 7
Training loss: 2.817889919294138
Validation loss: 2.5087731540744773

Epoch: 6| Step: 8
Training loss: 3.080175346238298
Validation loss: 2.4849849877438728

Epoch: 6| Step: 9
Training loss: 2.227035632810654
Validation loss: 2.5014467739405295

Epoch: 6| Step: 10
Training loss: 2.8735400929890687
Validation loss: 2.495573154474059

Epoch: 6| Step: 11
Training loss: 2.883690346314551
Validation loss: 2.5134585593193033

Epoch: 6| Step: 12
Training loss: 2.725718370293467
Validation loss: 2.518201627024104

Epoch: 6| Step: 13
Training loss: 2.0681834663895207
Validation loss: 2.5378715696916894

Epoch: 381| Step: 0
Training loss: 2.889252867959079
Validation loss: 2.5372775850467484

Epoch: 6| Step: 1
Training loss: 3.137773272403344
Validation loss: 2.5356160475368554

Epoch: 6| Step: 2
Training loss: 2.7120592945897415
Validation loss: 2.5321807547768342

Epoch: 6| Step: 3
Training loss: 3.2059532518982454
Validation loss: 2.5290860976607474

Epoch: 6| Step: 4
Training loss: 3.0999118054057515
Validation loss: 2.5709654156463895

Epoch: 6| Step: 5
Training loss: 2.746587369786478
Validation loss: 2.6310730573369554

Epoch: 6| Step: 6
Training loss: 2.2162785264366898
Validation loss: 2.628338917476029

Epoch: 6| Step: 7
Training loss: 2.604251972072866
Validation loss: 2.625985787181653

Epoch: 6| Step: 8
Training loss: 2.4981256134055356
Validation loss: 2.586870850426769

Epoch: 6| Step: 9
Training loss: 2.774456685808633
Validation loss: 2.5258614526031153

Epoch: 6| Step: 10
Training loss: 2.275292442724815
Validation loss: 2.4986180064510943

Epoch: 6| Step: 11
Training loss: 3.217978968445478
Validation loss: 2.4727536177624625

Epoch: 6| Step: 12
Training loss: 2.3678110642194077
Validation loss: 2.4685676946653894

Epoch: 6| Step: 13
Training loss: 2.1609679864703697
Validation loss: 2.4616077495454474

Epoch: 382| Step: 0
Training loss: 2.9483879081141726
Validation loss: 2.4807436983730793

Epoch: 6| Step: 1
Training loss: 3.1064981158079052
Validation loss: 2.4698128002028943

Epoch: 6| Step: 2
Training loss: 2.8051957968851844
Validation loss: 2.480868655908457

Epoch: 6| Step: 3
Training loss: 3.1417037098232834
Validation loss: 2.482031050488876

Epoch: 6| Step: 4
Training loss: 2.805942605223527
Validation loss: 2.4805094294352905

Epoch: 6| Step: 5
Training loss: 2.9709339340604255
Validation loss: 2.480929712509045

Epoch: 6| Step: 6
Training loss: 2.657690398177236
Validation loss: 2.4975450357340523

Epoch: 6| Step: 7
Training loss: 2.51405598299973
Validation loss: 2.5234499481827775

Epoch: 6| Step: 8
Training loss: 2.1910492577354344
Validation loss: 2.52066100740126

Epoch: 6| Step: 9
Training loss: 2.387920270748566
Validation loss: 2.5395445168776933

Epoch: 6| Step: 10
Training loss: 2.633441612174351
Validation loss: 2.5525910753685572

Epoch: 6| Step: 11
Training loss: 2.530566653094598
Validation loss: 2.5614397229970463

Epoch: 6| Step: 12
Training loss: 2.705563718542813
Validation loss: 2.5751181849640963

Epoch: 6| Step: 13
Training loss: 2.286372456136294
Validation loss: 2.575457176867548

Epoch: 383| Step: 0
Training loss: 2.7006136302889643
Validation loss: 2.5704721146346743

Epoch: 6| Step: 1
Training loss: 3.3519941287660733
Validation loss: 2.540756793658253

Epoch: 6| Step: 2
Training loss: 2.640542565136862
Validation loss: 2.5158712793526727

Epoch: 6| Step: 3
Training loss: 2.9508559779329184
Validation loss: 2.4896858696389885

Epoch: 6| Step: 4
Training loss: 2.4916700824556783
Validation loss: 2.477175173210946

Epoch: 6| Step: 5
Training loss: 2.5029093026749876
Validation loss: 2.4719886497385395

Epoch: 6| Step: 6
Training loss: 2.8984595449591235
Validation loss: 2.476521247459896

Epoch: 6| Step: 7
Training loss: 2.9372240302132404
Validation loss: 2.47370721566916

Epoch: 6| Step: 8
Training loss: 3.451458144607089
Validation loss: 2.473650086936486

Epoch: 6| Step: 9
Training loss: 2.895618970515995
Validation loss: 2.48378378391877

Epoch: 6| Step: 10
Training loss: 2.4514467366435064
Validation loss: 2.508973664594104

Epoch: 6| Step: 11
Training loss: 2.1793652368036396
Validation loss: 2.5099909452114795

Epoch: 6| Step: 12
Training loss: 2.413388747725933
Validation loss: 2.5533969385646498

Epoch: 6| Step: 13
Training loss: 2.1590059884267907
Validation loss: 2.5481579129617633

Epoch: 384| Step: 0
Training loss: 2.998574872073021
Validation loss: 2.6181247307056266

Epoch: 6| Step: 1
Training loss: 2.602953015126531
Validation loss: 2.625926821489616

Epoch: 6| Step: 2
Training loss: 2.7947420479579193
Validation loss: 2.6435411009841734

Epoch: 6| Step: 3
Training loss: 2.7584783598545575
Validation loss: 2.6203155166716527

Epoch: 6| Step: 4
Training loss: 2.0435636102918555
Validation loss: 2.5968245415929787

Epoch: 6| Step: 5
Training loss: 2.7686807593649783
Validation loss: 2.5487846765903845

Epoch: 6| Step: 6
Training loss: 3.187285172946036
Validation loss: 2.5378936252941395

Epoch: 6| Step: 7
Training loss: 2.4743605009089222
Validation loss: 2.5114977015348736

Epoch: 6| Step: 8
Training loss: 2.97848264582152
Validation loss: 2.4968642842646047

Epoch: 6| Step: 9
Training loss: 2.659801128955558
Validation loss: 2.4895742914529313

Epoch: 6| Step: 10
Training loss: 2.898532259232679
Validation loss: 2.5018014170439766

Epoch: 6| Step: 11
Training loss: 2.9264739862794964
Validation loss: 2.501913484853946

Epoch: 6| Step: 12
Training loss: 2.123861905675287
Validation loss: 2.5038538054742334

Epoch: 6| Step: 13
Training loss: 3.0388043840720913
Validation loss: 2.4813417561910542

Epoch: 385| Step: 0
Training loss: 3.152211390934499
Validation loss: 2.5157341846456944

Epoch: 6| Step: 1
Training loss: 2.5734519453170206
Validation loss: 2.4911276315302393

Epoch: 6| Step: 2
Training loss: 2.897843868201435
Validation loss: 2.500506569187182

Epoch: 6| Step: 3
Training loss: 2.2439128338480985
Validation loss: 2.5151884708745245

Epoch: 6| Step: 4
Training loss: 2.742961980669561
Validation loss: 2.5494960165226916

Epoch: 6| Step: 5
Training loss: 2.999908127967441
Validation loss: 2.552300338777459

Epoch: 6| Step: 6
Training loss: 2.250579335544751
Validation loss: 2.5492299240759575

Epoch: 6| Step: 7
Training loss: 2.93618355329543
Validation loss: 2.528753070254105

Epoch: 6| Step: 8
Training loss: 2.496082192455393
Validation loss: 2.5184247866838083

Epoch: 6| Step: 9
Training loss: 2.3248178431207522
Validation loss: 2.5199643756681245

Epoch: 6| Step: 10
Training loss: 2.8428366734958326
Validation loss: 2.486207494263124

Epoch: 6| Step: 11
Training loss: 2.9154383298068964
Validation loss: 2.4750573451696223

Epoch: 6| Step: 12
Training loss: 2.801727518135278
Validation loss: 2.47965738767614

Epoch: 6| Step: 13
Training loss: 2.5472802149906597
Validation loss: 2.477714258073352

Epoch: 386| Step: 0
Training loss: 3.322066402573174
Validation loss: 2.468995164811516

Epoch: 6| Step: 1
Training loss: 2.1089022636503083
Validation loss: 2.4755065650235584

Epoch: 6| Step: 2
Training loss: 2.584915835192805
Validation loss: 2.4646442062722453

Epoch: 6| Step: 3
Training loss: 2.9938869182200847
Validation loss: 2.496515284960499

Epoch: 6| Step: 4
Training loss: 2.483368675782635
Validation loss: 2.495004745578513

Epoch: 6| Step: 5
Training loss: 2.421735599566762
Validation loss: 2.4995582385096666

Epoch: 6| Step: 6
Training loss: 2.8546281613184035
Validation loss: 2.509556949176296

Epoch: 6| Step: 7
Training loss: 2.5616204217605434
Validation loss: 2.5217047544258326

Epoch: 6| Step: 8
Training loss: 2.8518407398500973
Validation loss: 2.5394829131126824

Epoch: 6| Step: 9
Training loss: 2.7591895104832402
Validation loss: 2.527100213358854

Epoch: 6| Step: 10
Training loss: 2.6658890802442032
Validation loss: 2.551290571194016

Epoch: 6| Step: 11
Training loss: 2.776590623428723
Validation loss: 2.529890441993228

Epoch: 6| Step: 12
Training loss: 2.7451668663238675
Validation loss: 2.5234834491652323

Epoch: 6| Step: 13
Training loss: 2.255804944723483
Validation loss: 2.5589136698454102

Epoch: 387| Step: 0
Training loss: 2.858920368677392
Validation loss: 2.568613105417453

Epoch: 6| Step: 1
Training loss: 1.9891597703042547
Validation loss: 2.5987580470634755

Epoch: 6| Step: 2
Training loss: 2.6643239002128403
Validation loss: 2.571525680648082

Epoch: 6| Step: 3
Training loss: 2.512755753894367
Validation loss: 2.536161634598639

Epoch: 6| Step: 4
Training loss: 3.358575486255296
Validation loss: 2.483818375196214

Epoch: 6| Step: 5
Training loss: 2.1520754444412247
Validation loss: 2.502223600027477

Epoch: 6| Step: 6
Training loss: 3.044052616561918
Validation loss: 2.4949246180873894

Epoch: 6| Step: 7
Training loss: 2.5521431014140283
Validation loss: 2.4929583140509344

Epoch: 6| Step: 8
Training loss: 3.1818718682751204
Validation loss: 2.5001163763215994

Epoch: 6| Step: 9
Training loss: 2.4355770252995472
Validation loss: 2.5029560814125205

Epoch: 6| Step: 10
Training loss: 2.5309466898476125
Validation loss: 2.5046645885899124

Epoch: 6| Step: 11
Training loss: 3.3409499093359503
Validation loss: 2.492746345075893

Epoch: 6| Step: 12
Training loss: 2.4757072825289925
Validation loss: 2.501660297115669

Epoch: 6| Step: 13
Training loss: 2.3747141816670476
Validation loss: 2.5100175733236676

Epoch: 388| Step: 0
Training loss: 2.734263739365889
Validation loss: 2.4886938050484693

Epoch: 6| Step: 1
Training loss: 2.445743218169314
Validation loss: 2.4968191892571583

Epoch: 6| Step: 2
Training loss: 3.1456738025222832
Validation loss: 2.512561777378078

Epoch: 6| Step: 3
Training loss: 2.1776124107522903
Validation loss: 2.5175855646621987

Epoch: 6| Step: 4
Training loss: 2.26863140710511
Validation loss: 2.5115014977447254

Epoch: 6| Step: 5
Training loss: 2.852051408216097
Validation loss: 2.514631208182964

Epoch: 6| Step: 6
Training loss: 2.865323908472455
Validation loss: 2.5215730282730515

Epoch: 6| Step: 7
Training loss: 2.519878984452023
Validation loss: 2.5259120913426054

Epoch: 6| Step: 8
Training loss: 3.044439819623245
Validation loss: 2.521703913672705

Epoch: 6| Step: 9
Training loss: 2.8140507978993483
Validation loss: 2.4895713834355213

Epoch: 6| Step: 10
Training loss: 2.3725715066888515
Validation loss: 2.494935641537068

Epoch: 6| Step: 11
Training loss: 2.730214905297322
Validation loss: 2.5122094135441944

Epoch: 6| Step: 12
Training loss: 3.3578862639677305
Validation loss: 2.5070937368096

Epoch: 6| Step: 13
Training loss: 2.204420966590346
Validation loss: 2.540734470295888

Epoch: 389| Step: 0
Training loss: 3.2249777090795617
Validation loss: 2.588286761262187

Epoch: 6| Step: 1
Training loss: 2.637255443064372
Validation loss: 2.59111162347462

Epoch: 6| Step: 2
Training loss: 2.9940597214689384
Validation loss: 2.5774894002958244

Epoch: 6| Step: 3
Training loss: 2.5418706301371836
Validation loss: 2.5812638710438054

Epoch: 6| Step: 4
Training loss: 2.5822831346976924
Validation loss: 2.5553206058539226

Epoch: 6| Step: 5
Training loss: 2.2431622556248163
Validation loss: 2.536897851202046

Epoch: 6| Step: 6
Training loss: 2.544068738758463
Validation loss: 2.537674622463007

Epoch: 6| Step: 7
Training loss: 3.3183026143339323
Validation loss: 2.5373714356865253

Epoch: 6| Step: 8
Training loss: 3.0222097659165983
Validation loss: 2.511992632359943

Epoch: 6| Step: 9
Training loss: 2.2997825022151805
Validation loss: 2.5063883386082653

Epoch: 6| Step: 10
Training loss: 2.6119915298569936
Validation loss: 2.4844792006807035

Epoch: 6| Step: 11
Training loss: 2.7001806551930394
Validation loss: 2.4691903067080765

Epoch: 6| Step: 12
Training loss: 2.544899484414405
Validation loss: 2.478844057475618

Epoch: 6| Step: 13
Training loss: 2.292669689425315
Validation loss: 2.488641225366966

Epoch: 390| Step: 0
Training loss: 3.019925702425301
Validation loss: 2.5026040194960832

Epoch: 6| Step: 1
Training loss: 2.7289458517962815
Validation loss: 2.4939933244672914

Epoch: 6| Step: 2
Training loss: 2.5980623544459265
Validation loss: 2.4858780525163486

Epoch: 6| Step: 3
Training loss: 2.9696841727696457
Validation loss: 2.518581366557439

Epoch: 6| Step: 4
Training loss: 2.0345508458423023
Validation loss: 2.538525462564772

Epoch: 6| Step: 5
Training loss: 2.9354419397620295
Validation loss: 2.5826021976538476

Epoch: 6| Step: 6
Training loss: 2.661295866564274
Validation loss: 2.56161453611575

Epoch: 6| Step: 7
Training loss: 2.674389642977137
Validation loss: 2.559172109342174

Epoch: 6| Step: 8
Training loss: 2.542879680239761
Validation loss: 2.5517762107121973

Epoch: 6| Step: 9
Training loss: 2.6895998358620363
Validation loss: 2.5068710840296964

Epoch: 6| Step: 10
Training loss: 2.7871253715542603
Validation loss: 2.50397020335434

Epoch: 6| Step: 11
Training loss: 2.7729999895615136
Validation loss: 2.4813168422748304

Epoch: 6| Step: 12
Training loss: 2.601740284020133
Validation loss: 2.4753601583541167

Epoch: 6| Step: 13
Training loss: 2.1603474040931636
Validation loss: 2.4677526261772806

Epoch: 391| Step: 0
Training loss: 3.2575054069702523
Validation loss: 2.4758050444159623

Epoch: 6| Step: 1
Training loss: 2.2548612425884738
Validation loss: 2.494345182366295

Epoch: 6| Step: 2
Training loss: 2.6468402018055497
Validation loss: 2.505696869170903

Epoch: 6| Step: 3
Training loss: 1.9976387390156938
Validation loss: 2.523673989735578

Epoch: 6| Step: 4
Training loss: 2.701923522301738
Validation loss: 2.571590479525835

Epoch: 6| Step: 5
Training loss: 2.7180766883288032
Validation loss: 2.5867161783092922

Epoch: 6| Step: 6
Training loss: 2.5526434043780086
Validation loss: 2.529131605645212

Epoch: 6| Step: 7
Training loss: 2.74570424341322
Validation loss: 2.4820303078479276

Epoch: 6| Step: 8
Training loss: 2.5474489653532024
Validation loss: 2.477776057168883

Epoch: 6| Step: 9
Training loss: 3.032653169215197
Validation loss: 2.467990169001048

Epoch: 6| Step: 10
Training loss: 2.8032397940955183
Validation loss: 2.4663781501064013

Epoch: 6| Step: 11
Training loss: 2.411270156230302
Validation loss: 2.4657910715938303

Epoch: 6| Step: 12
Training loss: 3.336727004240844
Validation loss: 2.461013059925924

Epoch: 6| Step: 13
Training loss: 3.147442757568501
Validation loss: 2.4638663936024514

Epoch: 392| Step: 0
Training loss: 2.634398212081715
Validation loss: 2.4819745068860586

Epoch: 6| Step: 1
Training loss: 2.905869817990628
Validation loss: 2.4757922427734464

Epoch: 6| Step: 2
Training loss: 2.297178702484833
Validation loss: 2.494390450570545

Epoch: 6| Step: 3
Training loss: 2.979776404524251
Validation loss: 2.499946335247324

Epoch: 6| Step: 4
Training loss: 3.0603541427329732
Validation loss: 2.546587751365579

Epoch: 6| Step: 5
Training loss: 3.45824001753202
Validation loss: 2.56664350607333

Epoch: 6| Step: 6
Training loss: 2.6893382328400484
Validation loss: 2.545878420892843

Epoch: 6| Step: 7
Training loss: 1.8683116513552993
Validation loss: 2.527209613338884

Epoch: 6| Step: 8
Training loss: 2.4947643769642505
Validation loss: 2.4946714938293706

Epoch: 6| Step: 9
Training loss: 2.3458894247482664
Validation loss: 2.4869238327322725

Epoch: 6| Step: 10
Training loss: 2.6457293232175885
Validation loss: 2.4959523381765742

Epoch: 6| Step: 11
Training loss: 2.955525709143337
Validation loss: 2.502522463978648

Epoch: 6| Step: 12
Training loss: 2.5379249254550644
Validation loss: 2.4959969383762752

Epoch: 6| Step: 13
Training loss: 2.6572331123874164
Validation loss: 2.4679116045249136

Epoch: 393| Step: 0
Training loss: 2.5877802526581277
Validation loss: 2.4995624261840264

Epoch: 6| Step: 1
Training loss: 3.32772710149861
Validation loss: 2.495908972826102

Epoch: 6| Step: 2
Training loss: 2.352679117419334
Validation loss: 2.4941511945166237

Epoch: 6| Step: 3
Training loss: 3.1660927369542007
Validation loss: 2.484201057955761

Epoch: 6| Step: 4
Training loss: 2.4636573898738794
Validation loss: 2.499573502000176

Epoch: 6| Step: 5
Training loss: 2.559804941286125
Validation loss: 2.4952034903322957

Epoch: 6| Step: 6
Training loss: 1.7824723583715862
Validation loss: 2.510994587117145

Epoch: 6| Step: 7
Training loss: 2.9966179539586464
Validation loss: 2.5353910298678044

Epoch: 6| Step: 8
Training loss: 3.1241350121232934
Validation loss: 2.515175306028435

Epoch: 6| Step: 9
Training loss: 2.067799320349013
Validation loss: 2.5067809137018733

Epoch: 6| Step: 10
Training loss: 3.0241796090409805
Validation loss: 2.4917767754902305

Epoch: 6| Step: 11
Training loss: 3.0644884466077027
Validation loss: 2.49952683534376

Epoch: 6| Step: 12
Training loss: 2.4000658105728196
Validation loss: 2.4932156316596057

Epoch: 6| Step: 13
Training loss: 1.894502494043202
Validation loss: 2.4887845699098308

Epoch: 394| Step: 0
Training loss: 2.101095949025584
Validation loss: 2.491244016867092

Epoch: 6| Step: 1
Training loss: 2.33964963180979
Validation loss: 2.48968146352972

Epoch: 6| Step: 2
Training loss: 2.9583742022489696
Validation loss: 2.488223550239918

Epoch: 6| Step: 3
Training loss: 2.7930092121741295
Validation loss: 2.4599802338160957

Epoch: 6| Step: 4
Training loss: 2.890064081979709
Validation loss: 2.4780465205927755

Epoch: 6| Step: 5
Training loss: 2.9861422593811096
Validation loss: 2.46411674374728

Epoch: 6| Step: 6
Training loss: 3.0768346260268795
Validation loss: 2.471631947565219

Epoch: 6| Step: 7
Training loss: 2.6658403387888896
Validation loss: 2.486578093181857

Epoch: 6| Step: 8
Training loss: 2.754677349381291
Validation loss: 2.494239363899024

Epoch: 6| Step: 9
Training loss: 2.94972202478446
Validation loss: 2.5180539543606297

Epoch: 6| Step: 10
Training loss: 2.5526327566805445
Validation loss: 2.5106450227503485

Epoch: 6| Step: 11
Training loss: 2.373038837434948
Validation loss: 2.4962180859936045

Epoch: 6| Step: 12
Training loss: 2.7602333919694746
Validation loss: 2.518495552835078

Epoch: 6| Step: 13
Training loss: 1.9960858667744283
Validation loss: 2.515061943414936

Epoch: 395| Step: 0
Training loss: 2.5862246812011622
Validation loss: 2.548261920992818

Epoch: 6| Step: 1
Training loss: 3.1706866965221336
Validation loss: 2.5417063014186123

Epoch: 6| Step: 2
Training loss: 2.5628769760105614
Validation loss: 2.5505799242318856

Epoch: 6| Step: 3
Training loss: 2.710109265366363
Validation loss: 2.5608217689995167

Epoch: 6| Step: 4
Training loss: 2.777569939997178
Validation loss: 2.58034848128048

Epoch: 6| Step: 5
Training loss: 3.0528699536032127
Validation loss: 2.546624450217175

Epoch: 6| Step: 6
Training loss: 3.131789651688682
Validation loss: 2.527132975113698

Epoch: 6| Step: 7
Training loss: 2.5886148382292573
Validation loss: 2.5186808837683667

Epoch: 6| Step: 8
Training loss: 2.334718928604884
Validation loss: 2.51862228543254

Epoch: 6| Step: 9
Training loss: 3.131074875371572
Validation loss: 2.5002644778401155

Epoch: 6| Step: 10
Training loss: 2.5867200514439586
Validation loss: 2.5104526676671597

Epoch: 6| Step: 11
Training loss: 2.2529222796665165
Validation loss: 2.479209999484083

Epoch: 6| Step: 12
Training loss: 2.1247592116422265
Validation loss: 2.50410252685644

Epoch: 6| Step: 13
Training loss: 2.4755759214540967
Validation loss: 2.514066484084951

Epoch: 396| Step: 0
Training loss: 2.7067179532978374
Validation loss: 2.5193328435893374

Epoch: 6| Step: 1
Training loss: 2.6661979640885103
Validation loss: 2.585206961655711

Epoch: 6| Step: 2
Training loss: 2.833464413770966
Validation loss: 2.6185518321020034

Epoch: 6| Step: 3
Training loss: 2.2337222979962013
Validation loss: 2.6262619629889516

Epoch: 6| Step: 4
Training loss: 2.630375671099484
Validation loss: 2.606945665364649

Epoch: 6| Step: 5
Training loss: 3.0205824824568515
Validation loss: 2.6012734888181024

Epoch: 6| Step: 6
Training loss: 2.8643953203865973
Validation loss: 2.543988064589015

Epoch: 6| Step: 7
Training loss: 2.8520433830396468
Validation loss: 2.479975826762213

Epoch: 6| Step: 8
Training loss: 2.275544543647364
Validation loss: 2.457792516348807

Epoch: 6| Step: 9
Training loss: 2.647897400824698
Validation loss: 2.442349851776477

Epoch: 6| Step: 10
Training loss: 2.578087823773155
Validation loss: 2.445300305099663

Epoch: 6| Step: 11
Training loss: 2.6700267980423726
Validation loss: 2.4408243925038495

Epoch: 6| Step: 12
Training loss: 3.4101927450527842
Validation loss: 2.454329347148312

Epoch: 6| Step: 13
Training loss: 2.256167541856923
Validation loss: 2.4572743805936823

Epoch: 397| Step: 0
Training loss: 2.5566122754348766
Validation loss: 2.4534000096009225

Epoch: 6| Step: 1
Training loss: 1.5203383785605415
Validation loss: 2.4656118497530715

Epoch: 6| Step: 2
Training loss: 2.5898898711779856
Validation loss: 2.489125064440801

Epoch: 6| Step: 3
Training loss: 2.831143786056989
Validation loss: 2.4860180290863045

Epoch: 6| Step: 4
Training loss: 2.789869859456286
Validation loss: 2.5129440289929668

Epoch: 6| Step: 5
Training loss: 2.8596069575378924
Validation loss: 2.5935333216798004

Epoch: 6| Step: 6
Training loss: 2.163999260484495
Validation loss: 2.6296645021486142

Epoch: 6| Step: 7
Training loss: 3.121697473681186
Validation loss: 2.6737451020536267

Epoch: 6| Step: 8
Training loss: 3.634211576400507
Validation loss: 2.6622840796876575

Epoch: 6| Step: 9
Training loss: 2.5725849159098035
Validation loss: 2.5780823893924056

Epoch: 6| Step: 10
Training loss: 2.0832653288868395
Validation loss: 2.5003837060260934

Epoch: 6| Step: 11
Training loss: 2.630331800729233
Validation loss: 2.4722088303993868

Epoch: 6| Step: 12
Training loss: 2.8895499214893827
Validation loss: 2.4623710060304145

Epoch: 6| Step: 13
Training loss: 3.275260326725909
Validation loss: 2.4341823674742638

Epoch: 398| Step: 0
Training loss: 2.953107399862814
Validation loss: 2.453726165057102

Epoch: 6| Step: 1
Training loss: 2.273865439916988
Validation loss: 2.4434026342801536

Epoch: 6| Step: 2
Training loss: 2.44630309689088
Validation loss: 2.441576776008642

Epoch: 6| Step: 3
Training loss: 2.5587027723075146
Validation loss: 2.4392794300080096

Epoch: 6| Step: 4
Training loss: 2.6409644636647127
Validation loss: 2.436446450995954

Epoch: 6| Step: 5
Training loss: 2.706896757938135
Validation loss: 2.4467507718342776

Epoch: 6| Step: 6
Training loss: 2.8020568241344983
Validation loss: 2.4584215487974044

Epoch: 6| Step: 7
Training loss: 2.595194035443979
Validation loss: 2.4519654352379967

Epoch: 6| Step: 8
Training loss: 2.5025774067464552
Validation loss: 2.4894139324942652

Epoch: 6| Step: 9
Training loss: 2.1128572331232025
Validation loss: 2.5170129905922565

Epoch: 6| Step: 10
Training loss: 2.8699827782516287
Validation loss: 2.5495323130279153

Epoch: 6| Step: 11
Training loss: 3.3105885010749536
Validation loss: 2.595067284368304

Epoch: 6| Step: 12
Training loss: 3.234688711386354
Validation loss: 2.6208607550052374

Epoch: 6| Step: 13
Training loss: 2.516311267574961
Validation loss: 2.5576411687333738

Epoch: 399| Step: 0
Training loss: 2.516752949766077
Validation loss: 2.508408044946514

Epoch: 6| Step: 1
Training loss: 2.8490269924075475
Validation loss: 2.5086441314634658

Epoch: 6| Step: 2
Training loss: 2.3534911095066526
Validation loss: 2.476472387087724

Epoch: 6| Step: 3
Training loss: 2.8628901986116477
Validation loss: 2.469084198235668

Epoch: 6| Step: 4
Training loss: 2.3691108368386993
Validation loss: 2.463528941090242

Epoch: 6| Step: 5
Training loss: 2.941925610896514
Validation loss: 2.455448204027835

Epoch: 6| Step: 6
Training loss: 1.6848492466078875
Validation loss: 2.4660005473494655

Epoch: 6| Step: 7
Training loss: 1.9425650808854107
Validation loss: 2.459412183872832

Epoch: 6| Step: 8
Training loss: 3.128814505423833
Validation loss: 2.476403382378696

Epoch: 6| Step: 9
Training loss: 2.9155132374496504
Validation loss: 2.489638825087008

Epoch: 6| Step: 10
Training loss: 2.9134592858620794
Validation loss: 2.5263589659515535

Epoch: 6| Step: 11
Training loss: 3.2459828418647216
Validation loss: 2.492617463270365

Epoch: 6| Step: 12
Training loss: 2.7193876373761894
Validation loss: 2.4847274306372844

Epoch: 6| Step: 13
Training loss: 2.7227793683492787
Validation loss: 2.4651446857159347

Epoch: 400| Step: 0
Training loss: 2.6849402724003792
Validation loss: 2.4583955266422435

Epoch: 6| Step: 1
Training loss: 2.8068852646511964
Validation loss: 2.4762222295919414

Epoch: 6| Step: 2
Training loss: 3.0702283231344145
Validation loss: 2.457457017239857

Epoch: 6| Step: 3
Training loss: 2.064947121522742
Validation loss: 2.450026023597622

Epoch: 6| Step: 4
Training loss: 2.9942183412940677
Validation loss: 2.4542219809016332

Epoch: 6| Step: 5
Training loss: 2.9540734761061525
Validation loss: 2.474339412403897

Epoch: 6| Step: 6
Training loss: 3.2527292969179467
Validation loss: 2.487148207825516

Epoch: 6| Step: 7
Training loss: 2.7627552035417953
Validation loss: 2.477006200600662

Epoch: 6| Step: 8
Training loss: 2.802594777528501
Validation loss: 2.4811799218200004

Epoch: 6| Step: 9
Training loss: 2.467565517927764
Validation loss: 2.51269017949038

Epoch: 6| Step: 10
Training loss: 2.2904196612032193
Validation loss: 2.4776295624019147

Epoch: 6| Step: 11
Training loss: 2.161570742951113
Validation loss: 2.501433571618513

Epoch: 6| Step: 12
Training loss: 2.3883766122833414
Validation loss: 2.479254249424471

Epoch: 6| Step: 13
Training loss: 2.3059436542942207
Validation loss: 2.4869557465529306

Testing loss: 2.6472222154618867
