Epoch: 1| Step: 0
Training loss: 6.193754483711167
Validation loss: 5.734619403655898

Epoch: 6| Step: 1
Training loss: 4.04224664256296
Validation loss: 5.724108647309512

Epoch: 6| Step: 2
Training loss: 4.684061035058293
Validation loss: 5.715895751607338

Epoch: 6| Step: 3
Training loss: 5.979897838727774
Validation loss: 5.70822266442279

Epoch: 6| Step: 4
Training loss: 5.339261852781559
Validation loss: 5.701189795183478

Epoch: 6| Step: 5
Training loss: 6.027663988171278
Validation loss: 5.693519861911599

Epoch: 6| Step: 6
Training loss: 6.324126763054766
Validation loss: 5.685367184775901

Epoch: 6| Step: 7
Training loss: 6.030423913228836
Validation loss: 5.676948381234705

Epoch: 6| Step: 8
Training loss: 5.92916960333052
Validation loss: 5.668311444378142

Epoch: 6| Step: 9
Training loss: 4.58420011242707
Validation loss: 5.659409116644415

Epoch: 6| Step: 10
Training loss: 6.187709612137646
Validation loss: 5.649625940669811

Epoch: 6| Step: 11
Training loss: 6.249932555788446
Validation loss: 5.6387962594897205

Epoch: 6| Step: 12
Training loss: 6.181046328067506
Validation loss: 5.627672345912166

Epoch: 6| Step: 13
Training loss: 5.640133823132806
Validation loss: 5.615998068903572

Epoch: 2| Step: 0
Training loss: 6.529654129939857
Validation loss: 5.602668245633704

Epoch: 6| Step: 1
Training loss: 5.314502293851011
Validation loss: 5.589027246605211

Epoch: 6| Step: 2
Training loss: 5.18395102562553
Validation loss: 5.574499192568994

Epoch: 6| Step: 3
Training loss: 5.022634201725308
Validation loss: 5.558027470755028

Epoch: 6| Step: 4
Training loss: 6.124251650811771
Validation loss: 5.541091312971825

Epoch: 6| Step: 5
Training loss: 6.232152557053202
Validation loss: 5.522633876497032

Epoch: 6| Step: 6
Training loss: 6.925464534671742
Validation loss: 5.502888604282544

Epoch: 6| Step: 7
Training loss: 4.691999386812578
Validation loss: 5.480631238567972

Epoch: 6| Step: 8
Training loss: 4.867132244745544
Validation loss: 5.457204493305575

Epoch: 6| Step: 9
Training loss: 4.857379466793162
Validation loss: 5.432107103271531

Epoch: 6| Step: 10
Training loss: 5.009335576388361
Validation loss: 5.406009622968103

Epoch: 6| Step: 11
Training loss: 5.114831093603079
Validation loss: 5.377247765098285

Epoch: 6| Step: 12
Training loss: 5.829369787895038
Validation loss: 5.347881852448542

Epoch: 6| Step: 13
Training loss: 4.839777541920025
Validation loss: 5.316118605973644

Epoch: 3| Step: 0
Training loss: 5.676102505103083
Validation loss: 5.282495976782511

Epoch: 6| Step: 1
Training loss: 5.534036570216902
Validation loss: 5.24669250433969

Epoch: 6| Step: 2
Training loss: 6.952974124943146
Validation loss: 5.211677732995259

Epoch: 6| Step: 3
Training loss: 4.8843392144452435
Validation loss: 5.172792478288698

Epoch: 6| Step: 4
Training loss: 3.489187705923539
Validation loss: 5.136038498971831

Epoch: 6| Step: 5
Training loss: 4.909324703043891
Validation loss: 5.098117787956462

Epoch: 6| Step: 6
Training loss: 4.402084654365386
Validation loss: 5.062323484757869

Epoch: 6| Step: 7
Training loss: 4.982546097101482
Validation loss: 5.029246938449368

Epoch: 6| Step: 8
Training loss: 5.688319555907279
Validation loss: 4.995741211775137

Epoch: 6| Step: 9
Training loss: 4.730538302350472
Validation loss: 4.961966963409227

Epoch: 6| Step: 10
Training loss: 4.967923653462857
Validation loss: 4.930460293465949

Epoch: 6| Step: 11
Training loss: 4.627662098753985
Validation loss: 4.90259076476545

Epoch: 6| Step: 12
Training loss: 5.529794275137349
Validation loss: 4.8754528593625945

Epoch: 6| Step: 13
Training loss: 4.240129115459986
Validation loss: 4.8479973406122925

Epoch: 4| Step: 0
Training loss: 4.8444803979299715
Validation loss: 4.824589192684824

Epoch: 6| Step: 1
Training loss: 5.448886218572491
Validation loss: 4.802755442487556

Epoch: 6| Step: 2
Training loss: 5.202106547988141
Validation loss: 4.779142825469881

Epoch: 6| Step: 3
Training loss: 2.773661171933568
Validation loss: 4.757344753107743

Epoch: 6| Step: 4
Training loss: 5.070531808021927
Validation loss: 4.735374272395577

Epoch: 6| Step: 5
Training loss: 4.328030030899076
Validation loss: 4.717032855939236

Epoch: 6| Step: 6
Training loss: 4.081778924617687
Validation loss: 4.697376550955907

Epoch: 6| Step: 7
Training loss: 5.441157021055651
Validation loss: 4.678246209819525

Epoch: 6| Step: 8
Training loss: 4.526241507323398
Validation loss: 4.658841566136654

Epoch: 6| Step: 9
Training loss: 4.685639686190012
Validation loss: 4.641195399811231

Epoch: 6| Step: 10
Training loss: 4.666568051159078
Validation loss: 4.621620821723535

Epoch: 6| Step: 11
Training loss: 4.380515627187532
Validation loss: 4.599224985293763

Epoch: 6| Step: 12
Training loss: 5.672723375665886
Validation loss: 4.577517784353244

Epoch: 6| Step: 13
Training loss: 5.298693319504823
Validation loss: 4.557691655713764

Epoch: 5| Step: 0
Training loss: 5.715069362856904
Validation loss: 4.537457041055547

Epoch: 6| Step: 1
Training loss: 4.077948906264581
Validation loss: 4.522401308209664

Epoch: 6| Step: 2
Training loss: 4.210581012420756
Validation loss: 4.505993549014797

Epoch: 6| Step: 3
Training loss: 4.617405197252591
Validation loss: 4.488456303481799

Epoch: 6| Step: 4
Training loss: 5.038752867182808
Validation loss: 4.4702568471010755

Epoch: 6| Step: 5
Training loss: 4.815667435287661
Validation loss: 4.452610679160526

Epoch: 6| Step: 6
Training loss: 3.691572623565544
Validation loss: 4.435265491065407

Epoch: 6| Step: 7
Training loss: 3.9315106085680607
Validation loss: 4.417985851857177

Epoch: 6| Step: 8
Training loss: 5.344527873927727
Validation loss: 4.402882710355186

Epoch: 6| Step: 9
Training loss: 4.859025850662582
Validation loss: 4.3842139004150535

Epoch: 6| Step: 10
Training loss: 4.10344171979497
Validation loss: 4.370643755679643

Epoch: 6| Step: 11
Training loss: 4.93571826318719
Validation loss: 4.351585791823319

Epoch: 6| Step: 12
Training loss: 3.871151890014961
Validation loss: 4.3353387997438695

Epoch: 6| Step: 13
Training loss: 3.1860991747040464
Validation loss: 4.3215968137805225

Epoch: 6| Step: 0
Training loss: 4.324293733823677
Validation loss: 4.308210863061957

Epoch: 6| Step: 1
Training loss: 5.414807200993012
Validation loss: 4.295228661304344

Epoch: 6| Step: 2
Training loss: 4.533040922682462
Validation loss: 4.2829133316025345

Epoch: 6| Step: 3
Training loss: 4.1210583436719554
Validation loss: 4.268193587002875

Epoch: 6| Step: 4
Training loss: 4.597792112146715
Validation loss: 4.257733161385026

Epoch: 6| Step: 5
Training loss: 4.833035339289411
Validation loss: 4.2464951136646825

Epoch: 6| Step: 6
Training loss: 4.646397965450735
Validation loss: 4.234943163030389

Epoch: 6| Step: 7
Training loss: 4.18603695035429
Validation loss: 4.2217309626770465

Epoch: 6| Step: 8
Training loss: 5.150321928165765
Validation loss: 4.213815480802872

Epoch: 6| Step: 9
Training loss: 3.568974016577574
Validation loss: 4.204163142819433

Epoch: 6| Step: 10
Training loss: 3.008987633164697
Validation loss: 4.193622177017521

Epoch: 6| Step: 11
Training loss: 3.834126777355755
Validation loss: 4.1848943602495305

Epoch: 6| Step: 12
Training loss: 4.775765258822197
Validation loss: 4.175620841540836

Epoch: 6| Step: 13
Training loss: 2.6687720054416055
Validation loss: 4.162897809140365

Epoch: 7| Step: 0
Training loss: 3.718466483456107
Validation loss: 4.155416250355221

Epoch: 6| Step: 1
Training loss: 4.222921611906574
Validation loss: 4.139504932020919

Epoch: 6| Step: 2
Training loss: 3.9908734153911447
Validation loss: 4.128045010693583

Epoch: 6| Step: 3
Training loss: 3.8015675373412474
Validation loss: 4.112545922828952

Epoch: 6| Step: 4
Training loss: 3.2610549708192713
Validation loss: 4.097137764033063

Epoch: 6| Step: 5
Training loss: 4.414399962902173
Validation loss: 4.08370341335169

Epoch: 6| Step: 6
Training loss: 4.964549082153517
Validation loss: 4.067184604649434

Epoch: 6| Step: 7
Training loss: 4.3999346121351
Validation loss: 4.052790106617383

Epoch: 6| Step: 8
Training loss: 4.39568040530541
Validation loss: 4.038654938606356

Epoch: 6| Step: 9
Training loss: 4.308791625527602
Validation loss: 4.025896963990427

Epoch: 6| Step: 10
Training loss: 3.837308246406834
Validation loss: 4.018089761532133

Epoch: 6| Step: 11
Training loss: 4.771676445747896
Validation loss: 4.007548984340831

Epoch: 6| Step: 12
Training loss: 4.408468350876934
Validation loss: 3.9983919638985115

Epoch: 6| Step: 13
Training loss: 4.105734253055581
Validation loss: 3.991005292970772

Epoch: 8| Step: 0
Training loss: 4.82443501223261
Validation loss: 3.9785075162253527

Epoch: 6| Step: 1
Training loss: 4.025725845379107
Validation loss: 3.9736485247672237

Epoch: 6| Step: 2
Training loss: 5.19323891008273
Validation loss: 3.959732472021764

Epoch: 6| Step: 3
Training loss: 2.900626700198812
Validation loss: 3.9480415021680666

Epoch: 6| Step: 4
Training loss: 3.907129051480992
Validation loss: 3.9375104121109428

Epoch: 6| Step: 5
Training loss: 4.617108391150232
Validation loss: 3.9282424263748017

Epoch: 6| Step: 6
Training loss: 3.4695037847581562
Validation loss: 3.918188357601522

Epoch: 6| Step: 7
Training loss: 3.5527877929429685
Validation loss: 3.9100670719470663

Epoch: 6| Step: 8
Training loss: 3.698658498938833
Validation loss: 3.904033238296353

Epoch: 6| Step: 9
Training loss: 3.7024879390460868
Validation loss: 3.8980023659548495

Epoch: 6| Step: 10
Training loss: 3.380020927951286
Validation loss: 3.891112104223181

Epoch: 6| Step: 11
Training loss: 4.8869144879238755
Validation loss: 3.8843956421502037

Epoch: 6| Step: 12
Training loss: 3.581258276485446
Validation loss: 3.872387256951142

Epoch: 6| Step: 13
Training loss: 5.092534768646459
Validation loss: 3.8649628456220126

Epoch: 9| Step: 0
Training loss: 4.428001230861696
Validation loss: 3.8523322921973406

Epoch: 6| Step: 1
Training loss: 2.3864877841907752
Validation loss: 3.8347399664573083

Epoch: 6| Step: 2
Training loss: 3.5036336565247943
Validation loss: 3.828153645029688

Epoch: 6| Step: 3
Training loss: 3.5909759429661214
Validation loss: 3.8136599433870257

Epoch: 6| Step: 4
Training loss: 4.154089803695626
Validation loss: 3.805273101885938

Epoch: 6| Step: 5
Training loss: 4.534201035951519
Validation loss: 3.797499487457082

Epoch: 6| Step: 6
Training loss: 4.119341118727776
Validation loss: 3.7833929834456

Epoch: 6| Step: 7
Training loss: 3.7936354894811366
Validation loss: 3.7741128346949058

Epoch: 6| Step: 8
Training loss: 4.263517984224605
Validation loss: 3.7679868369995013

Epoch: 6| Step: 9
Training loss: 3.9101983219592866
Validation loss: 3.7587888783494727

Epoch: 6| Step: 10
Training loss: 4.5648833020305375
Validation loss: 3.756585743219382

Epoch: 6| Step: 11
Training loss: 3.7865087338765817
Validation loss: 3.7479076988397795

Epoch: 6| Step: 12
Training loss: 3.9883221391604984
Validation loss: 3.735418038712013

Epoch: 6| Step: 13
Training loss: 3.918050291633398
Validation loss: 3.723152877725639

Epoch: 10| Step: 0
Training loss: 3.0852975688840796
Validation loss: 3.7170604281098143

Epoch: 6| Step: 1
Training loss: 3.6832927690116377
Validation loss: 3.7084734204554093

Epoch: 6| Step: 2
Training loss: 3.016090633831619
Validation loss: 3.6988097583707646

Epoch: 6| Step: 3
Training loss: 3.4339709112749373
Validation loss: 3.696893972393364

Epoch: 6| Step: 4
Training loss: 3.185615431225053
Validation loss: 3.6853214848441596

Epoch: 6| Step: 5
Training loss: 4.1632807643759095
Validation loss: 3.677417984729951

Epoch: 6| Step: 6
Training loss: 4.1627905300349
Validation loss: 3.683507097557589

Epoch: 6| Step: 7
Training loss: 4.117951816212099
Validation loss: 3.676391489532841

Epoch: 6| Step: 8
Training loss: 3.791018643739138
Validation loss: 3.669601231438225

Epoch: 6| Step: 9
Training loss: 3.962915291669474
Validation loss: 3.668726099880517

Epoch: 6| Step: 10
Training loss: 4.878068007454546
Validation loss: 3.662384403875007

Epoch: 6| Step: 11
Training loss: 4.1990772596075585
Validation loss: 3.6565412698607305

Epoch: 6| Step: 12
Training loss: 4.265475874868701
Validation loss: 3.649683265412055

Epoch: 6| Step: 13
Training loss: 3.681093243044688
Validation loss: 3.6492028585662037

Epoch: 11| Step: 0
Training loss: 2.6254053257044063
Validation loss: 3.6434689361623716

Epoch: 6| Step: 1
Training loss: 3.465662363881162
Validation loss: 3.6526813099495623

Epoch: 6| Step: 2
Training loss: 5.119716991709143
Validation loss: 3.642547962891136

Epoch: 6| Step: 3
Training loss: 4.052035896134739
Validation loss: 3.631723223643602

Epoch: 6| Step: 4
Training loss: 4.257218009673074
Validation loss: 3.6379340152477457

Epoch: 6| Step: 5
Training loss: 4.022274701131476
Validation loss: 3.6427252665660097

Epoch: 6| Step: 6
Training loss: 4.108735821696284
Validation loss: 3.6386628355616173

Epoch: 6| Step: 7
Training loss: 4.329720874273663
Validation loss: 3.629242182485732

Epoch: 6| Step: 8
Training loss: 3.3126888581186016
Validation loss: 3.621658870309461

Epoch: 6| Step: 9
Training loss: 4.2426746292455135
Validation loss: 3.624993393226857

Epoch: 6| Step: 10
Training loss: 3.3015959146291802
Validation loss: 3.622702405447302

Epoch: 6| Step: 11
Training loss: 3.021092335789687
Validation loss: 3.6309825835249807

Epoch: 6| Step: 12
Training loss: 3.6742491493532983
Validation loss: 3.6224265774871798

Epoch: 6| Step: 13
Training loss: 2.9662561482632235
Validation loss: 3.610495345279553

Epoch: 12| Step: 0
Training loss: 4.141770229669431
Validation loss: 3.601069655048252

Epoch: 6| Step: 1
Training loss: 3.844911477368345
Validation loss: 3.5871129365133303

Epoch: 6| Step: 2
Training loss: 3.5579454185240516
Validation loss: 3.586041551514165

Epoch: 6| Step: 3
Training loss: 4.435158340053123
Validation loss: 3.58478030336932

Epoch: 6| Step: 4
Training loss: 3.526627477369242
Validation loss: 3.5781747259537693

Epoch: 6| Step: 5
Training loss: 3.544521542477615
Validation loss: 3.576659724396397

Epoch: 6| Step: 6
Training loss: 4.690352728945215
Validation loss: 3.5752846258959528

Epoch: 6| Step: 7
Training loss: 3.4639650626237737
Validation loss: 3.574496123383397

Epoch: 6| Step: 8
Training loss: 3.465453635021593
Validation loss: 3.5700844061115022

Epoch: 6| Step: 9
Training loss: 2.664088453239143
Validation loss: 3.5728635448872996

Epoch: 6| Step: 10
Training loss: 4.185707505740027
Validation loss: 3.5666608750192124

Epoch: 6| Step: 11
Training loss: 3.0792451166286274
Validation loss: 3.5638630951877346

Epoch: 6| Step: 12
Training loss: 4.07960197040575
Validation loss: 3.5598044064104646

Epoch: 6| Step: 13
Training loss: 3.7107000335205664
Validation loss: 3.5556849729363575

Epoch: 13| Step: 0
Training loss: 4.047149059780843
Validation loss: 3.552960604170174

Epoch: 6| Step: 1
Training loss: 2.8459155881135985
Validation loss: 3.55363827608874

Epoch: 6| Step: 2
Training loss: 3.3143440727677067
Validation loss: 3.5523569571050686

Epoch: 6| Step: 3
Training loss: 3.672185357146506
Validation loss: 3.5494289327679334

Epoch: 6| Step: 4
Training loss: 2.9137154134680263
Validation loss: 3.5495739844271914

Epoch: 6| Step: 5
Training loss: 3.3988429737457224
Validation loss: 3.5492654160850985

Epoch: 6| Step: 6
Training loss: 4.282170329056375
Validation loss: 3.5443943360779757

Epoch: 6| Step: 7
Training loss: 4.295468075773609
Validation loss: 3.5427727006756564

Epoch: 6| Step: 8
Training loss: 3.3806531679062855
Validation loss: 3.53871697799105

Epoch: 6| Step: 9
Training loss: 4.6344495585971845
Validation loss: 3.5374936433540274

Epoch: 6| Step: 10
Training loss: 4.404273922473452
Validation loss: 3.5379666283771383

Epoch: 6| Step: 11
Training loss: 3.8782812193115204
Validation loss: 3.5358452299987295

Epoch: 6| Step: 12
Training loss: 3.036163909055934
Validation loss: 3.5332869595947596

Epoch: 6| Step: 13
Training loss: 3.8912596893434994
Validation loss: 3.533801017738364

Epoch: 14| Step: 0
Training loss: 3.5142309519081993
Validation loss: 3.5358402039955084

Epoch: 6| Step: 1
Training loss: 3.479149154040334
Validation loss: 3.531762470241188

Epoch: 6| Step: 2
Training loss: 4.082626255603657
Validation loss: 3.5287177069891333

Epoch: 6| Step: 3
Training loss: 3.125514484016179
Validation loss: 3.529065820690684

Epoch: 6| Step: 4
Training loss: 3.866072430385559
Validation loss: 3.5236618086644262

Epoch: 6| Step: 5
Training loss: 3.6286481718308874
Validation loss: 3.5246300616007105

Epoch: 6| Step: 6
Training loss: 3.209068478337168
Validation loss: 3.5227360941420067

Epoch: 6| Step: 7
Training loss: 3.8712115072591353
Validation loss: 3.5218225642662135

Epoch: 6| Step: 8
Training loss: 3.9235663547420065
Validation loss: 3.5211245236843918

Epoch: 6| Step: 9
Training loss: 3.7704988334764233
Validation loss: 3.518561922551775

Epoch: 6| Step: 10
Training loss: 4.360806356636135
Validation loss: 3.5161094734601486

Epoch: 6| Step: 11
Training loss: 3.8724647349949226
Validation loss: 3.5161978510357157

Epoch: 6| Step: 12
Training loss: 3.23691713248625
Validation loss: 3.513094722570636

Epoch: 6| Step: 13
Training loss: 4.378789949531622
Validation loss: 3.5144872460077816

Epoch: 15| Step: 0
Training loss: 3.3382540304662
Validation loss: 3.51338087934665

Epoch: 6| Step: 1
Training loss: 3.8326390646670876
Validation loss: 3.5131389473671266

Epoch: 6| Step: 2
Training loss: 3.504609886803266
Validation loss: 3.5147427351292593

Epoch: 6| Step: 3
Training loss: 3.6276905992466206
Validation loss: 3.510973188843362

Epoch: 6| Step: 4
Training loss: 4.189758375024611
Validation loss: 3.506399443804601

Epoch: 6| Step: 5
Training loss: 4.189176764631928
Validation loss: 3.5065827323297665

Epoch: 6| Step: 6
Training loss: 2.419456209294528
Validation loss: 3.5059564068868467

Epoch: 6| Step: 7
Training loss: 4.378518569758801
Validation loss: 3.5054974253528908

Epoch: 6| Step: 8
Training loss: 3.057854846939863
Validation loss: 3.504861620915286

Epoch: 6| Step: 9
Training loss: 4.322925956746732
Validation loss: 3.5074941642015167

Epoch: 6| Step: 10
Training loss: 4.085117702772812
Validation loss: 3.508081246396139

Epoch: 6| Step: 11
Training loss: 4.233779245956408
Validation loss: 3.5071502476248484

Epoch: 6| Step: 12
Training loss: 2.75847326040938
Validation loss: 3.5055894498064775

Epoch: 6| Step: 13
Training loss: 3.286641804470197
Validation loss: 3.50313283023982

Epoch: 16| Step: 0
Training loss: 3.583081007360852
Validation loss: 3.5003166260604486

Epoch: 6| Step: 1
Training loss: 4.6543312983934735
Validation loss: 3.5027770789950052

Epoch: 6| Step: 2
Training loss: 3.586149720538064
Validation loss: 3.497097165204565

Epoch: 6| Step: 3
Training loss: 3.8907283171758125
Validation loss: 3.498345633038344

Epoch: 6| Step: 4
Training loss: 2.788542370421461
Validation loss: 3.4939281413437615

Epoch: 6| Step: 5
Training loss: 4.020762678457843
Validation loss: 3.4933417004678646

Epoch: 6| Step: 6
Training loss: 3.8892488918490447
Validation loss: 3.4919909269375258

Epoch: 6| Step: 7
Training loss: 3.678292886926178
Validation loss: 3.487744842542866

Epoch: 6| Step: 8
Training loss: 3.416912364654243
Validation loss: 3.492135558579764

Epoch: 6| Step: 9
Training loss: 3.982063849848777
Validation loss: 3.490866745219414

Epoch: 6| Step: 10
Training loss: 4.02795038547663
Validation loss: 3.492561056991434

Epoch: 6| Step: 11
Training loss: 3.3399228449150367
Validation loss: 3.4829337480872438

Epoch: 6| Step: 12
Training loss: 3.3049542835669126
Validation loss: 3.4836641794431444

Epoch: 6| Step: 13
Training loss: 3.1229682421014653
Validation loss: 3.484560066487003

Epoch: 17| Step: 0
Training loss: 2.9838590325712984
Validation loss: 3.481285726609475

Epoch: 6| Step: 1
Training loss: 3.9698715427476956
Validation loss: 3.484803352824084

Epoch: 6| Step: 2
Training loss: 4.444651683638122
Validation loss: 3.4823773307818566

Epoch: 6| Step: 3
Training loss: 3.790442020940477
Validation loss: 3.4839381381820855

Epoch: 6| Step: 4
Training loss: 2.8107620803694195
Validation loss: 3.4809732716083532

Epoch: 6| Step: 5
Training loss: 4.634184712923214
Validation loss: 3.478888946309111

Epoch: 6| Step: 6
Training loss: 3.7210396521858846
Validation loss: 3.4768320854534993

Epoch: 6| Step: 7
Training loss: 3.5683073928462647
Validation loss: 3.4762597393160184

Epoch: 6| Step: 8
Training loss: 3.9441785334710753
Validation loss: 3.4750468562772334

Epoch: 6| Step: 9
Training loss: 3.207081802471546
Validation loss: 3.4726773221508305

Epoch: 6| Step: 10
Training loss: 2.981510725156566
Validation loss: 3.4689333681645245

Epoch: 6| Step: 11
Training loss: 3.557078201047756
Validation loss: 3.467521438828682

Epoch: 6| Step: 12
Training loss: 3.68243771937393
Validation loss: 3.46442218363534

Epoch: 6| Step: 13
Training loss: 4.050548638752822
Validation loss: 3.464782959217624

Epoch: 18| Step: 0
Training loss: 4.079753682050078
Validation loss: 3.4574322174524594

Epoch: 6| Step: 1
Training loss: 3.061957642155743
Validation loss: 3.4549041368302142

Epoch: 6| Step: 2
Training loss: 4.121585704493166
Validation loss: 3.4498333651007957

Epoch: 6| Step: 3
Training loss: 3.3100548122512143
Validation loss: 3.447345870915692

Epoch: 6| Step: 4
Training loss: 3.470583869117432
Validation loss: 3.4448762391032735

Epoch: 6| Step: 5
Training loss: 3.5771112463515045
Validation loss: 3.444691255424275

Epoch: 6| Step: 6
Training loss: 4.097414662355178
Validation loss: 3.4395155187595043

Epoch: 6| Step: 7
Training loss: 3.9113865154528775
Validation loss: 3.436259587168958

Epoch: 6| Step: 8
Training loss: 3.9020899479136673
Validation loss: 3.4312985576736232

Epoch: 6| Step: 9
Training loss: 4.077870561986059
Validation loss: 3.426901296735644

Epoch: 6| Step: 10
Training loss: 3.4262575277352263
Validation loss: 3.4324854769705446

Epoch: 6| Step: 11
Training loss: 2.9482527003269836
Validation loss: 3.432256538432563

Epoch: 6| Step: 12
Training loss: 3.916678705940952
Validation loss: 3.428691246066431

Epoch: 6| Step: 13
Training loss: 2.5591719811186726
Validation loss: 3.4226588914656837

Epoch: 19| Step: 0
Training loss: 4.028367068857439
Validation loss: 3.4277403852084443

Epoch: 6| Step: 1
Training loss: 4.0518125363486295
Validation loss: 3.4284234803944957

Epoch: 6| Step: 2
Training loss: 4.223762303831452
Validation loss: 3.424978647808467

Epoch: 6| Step: 3
Training loss: 4.800377179267523
Validation loss: 3.4203901183457144

Epoch: 6| Step: 4
Training loss: 3.0585689616751743
Validation loss: 3.41908281125159

Epoch: 6| Step: 5
Training loss: 3.1546641983297734
Validation loss: 3.4190959552836118

Epoch: 6| Step: 6
Training loss: 3.89028328616707
Validation loss: 3.4212279457888712

Epoch: 6| Step: 7
Training loss: 3.351040032484901
Validation loss: 3.418622832780722

Epoch: 6| Step: 8
Training loss: 2.8685931260510174
Validation loss: 3.4147116987932207

Epoch: 6| Step: 9
Training loss: 3.444233074334098
Validation loss: 3.4140143500542863

Epoch: 6| Step: 10
Training loss: 2.525452556278512
Validation loss: 3.412452485390316

Epoch: 6| Step: 11
Training loss: 3.796642657419796
Validation loss: 3.4121390105687874

Epoch: 6| Step: 12
Training loss: 3.2747794157099523
Validation loss: 3.4114028025621685

Epoch: 6| Step: 13
Training loss: 4.098490990927022
Validation loss: 3.4098387643015204

Epoch: 20| Step: 0
Training loss: 3.2537991253093312
Validation loss: 3.407712356252881

Epoch: 6| Step: 1
Training loss: 3.804177878712527
Validation loss: 3.409380069686525

Epoch: 6| Step: 2
Training loss: 4.159176821325908
Validation loss: 3.4060288088660546

Epoch: 6| Step: 3
Training loss: 4.272050538324886
Validation loss: 3.4043765086832876

Epoch: 6| Step: 4
Training loss: 3.9322104877235633
Validation loss: 3.404772399332649

Epoch: 6| Step: 5
Training loss: 3.1190008945494383
Validation loss: 3.403607941925385

Epoch: 6| Step: 6
Training loss: 2.9391377530155287
Validation loss: 3.402037947886592

Epoch: 6| Step: 7
Training loss: 4.196765271624944
Validation loss: 3.4009449772990976

Epoch: 6| Step: 8
Training loss: 4.079775187712602
Validation loss: 3.4005978953748306

Epoch: 6| Step: 9
Training loss: 3.0276647385271866
Validation loss: 3.400061068266912

Epoch: 6| Step: 10
Training loss: 2.4585212592586143
Validation loss: 3.4014561676984685

Epoch: 6| Step: 11
Training loss: 3.070923256732847
Validation loss: 3.399854683590622

Epoch: 6| Step: 12
Training loss: 4.412322493054519
Validation loss: 3.4008981100630193

Epoch: 6| Step: 13
Training loss: 3.2957715542706314
Validation loss: 3.3987028564081916

Epoch: 21| Step: 0
Training loss: 3.3628012993694005
Validation loss: 3.3974141489721106

Epoch: 6| Step: 1
Training loss: 4.0923054017236495
Validation loss: 3.39700310421358

Epoch: 6| Step: 2
Training loss: 3.9935689726920254
Validation loss: 3.3948341458321436

Epoch: 6| Step: 3
Training loss: 3.848934244055551
Validation loss: 3.3978734305605234

Epoch: 6| Step: 4
Training loss: 3.5395685301514748
Validation loss: 3.394340049913301

Epoch: 6| Step: 5
Training loss: 4.024729815590232
Validation loss: 3.3953934991183248

Epoch: 6| Step: 6
Training loss: 3.622733624429792
Validation loss: 3.3971485470092317

Epoch: 6| Step: 7
Training loss: 3.38406370075052
Validation loss: 3.395815060282834

Epoch: 6| Step: 8
Training loss: 2.581898834480487
Validation loss: 3.394484723185035

Epoch: 6| Step: 9
Training loss: 4.235876513935291
Validation loss: 3.3939876380962275

Epoch: 6| Step: 10
Training loss: 4.09671867997683
Validation loss: 3.3940853733893475

Epoch: 6| Step: 11
Training loss: 2.5702882898923924
Validation loss: 3.3920510464395273

Epoch: 6| Step: 12
Training loss: 3.3151577058450816
Validation loss: 3.3929777798889464

Epoch: 6| Step: 13
Training loss: 3.551112127047974
Validation loss: 3.392923456815061

Epoch: 22| Step: 0
Training loss: 4.019396958549925
Validation loss: 3.3895600246816953

Epoch: 6| Step: 1
Training loss: 3.7977614133360866
Validation loss: 3.392064381376368

Epoch: 6| Step: 2
Training loss: 3.463925967969331
Validation loss: 3.388477098579572

Epoch: 6| Step: 3
Training loss: 3.009247831230526
Validation loss: 3.389412843362184

Epoch: 6| Step: 4
Training loss: 2.1927979753765348
Validation loss: 3.3877744026143817

Epoch: 6| Step: 5
Training loss: 4.20239977624625
Validation loss: 3.387381276694175

Epoch: 6| Step: 6
Training loss: 3.3735811995360776
Validation loss: 3.386305710490948

Epoch: 6| Step: 7
Training loss: 4.084412153289559
Validation loss: 3.3852655227783743

Epoch: 6| Step: 8
Training loss: 3.573509737993473
Validation loss: 3.384793115684126

Epoch: 6| Step: 9
Training loss: 3.6068500092373874
Validation loss: 3.3859139964875786

Epoch: 6| Step: 10
Training loss: 3.711473157269408
Validation loss: 3.3886048833789206

Epoch: 6| Step: 11
Training loss: 3.230893827837401
Validation loss: 3.3874146205412314

Epoch: 6| Step: 12
Training loss: 3.6495061775486586
Validation loss: 3.386757446027119

Epoch: 6| Step: 13
Training loss: 4.630053465763132
Validation loss: 3.389786772182503

Epoch: 23| Step: 0
Training loss: 3.482075706644909
Validation loss: 3.3851704189708625

Epoch: 6| Step: 1
Training loss: 4.159132108754336
Validation loss: 3.379476400528356

Epoch: 6| Step: 2
Training loss: 3.9852795340832383
Validation loss: 3.3802451618331535

Epoch: 6| Step: 3
Training loss: 3.5516083848223787
Validation loss: 3.3812739911482232

Epoch: 6| Step: 4
Training loss: 3.946817182901197
Validation loss: 3.3829364383985157

Epoch: 6| Step: 5
Training loss: 3.1711397869248485
Validation loss: 3.381824084424935

Epoch: 6| Step: 6
Training loss: 3.4565851473292692
Validation loss: 3.3798435341150888

Epoch: 6| Step: 7
Training loss: 2.594538924870085
Validation loss: 3.379565096867262

Epoch: 6| Step: 8
Training loss: 3.445580712083443
Validation loss: 3.3762310096794756

Epoch: 6| Step: 9
Training loss: 4.271336794075463
Validation loss: 3.3758826337905923

Epoch: 6| Step: 10
Training loss: 2.9771865631066805
Validation loss: 3.3753065443268038

Epoch: 6| Step: 11
Training loss: 3.950066268944451
Validation loss: 3.3759869477306896

Epoch: 6| Step: 12
Training loss: 3.5524670047825015
Validation loss: 3.375318493203909

Epoch: 6| Step: 13
Training loss: 3.6434946170252527
Validation loss: 3.374379576881778

Epoch: 24| Step: 0
Training loss: 2.8425840565676053
Validation loss: 3.3755910668037226

Epoch: 6| Step: 1
Training loss: 3.883450553554699
Validation loss: 3.375040583516552

Epoch: 6| Step: 2
Training loss: 3.782592535103549
Validation loss: 3.3721356955033284

Epoch: 6| Step: 3
Training loss: 3.00090299367804
Validation loss: 3.3717521344244186

Epoch: 6| Step: 4
Training loss: 3.8199553839589555
Validation loss: 3.371292380847002

Epoch: 6| Step: 5
Training loss: 3.4234735247598227
Validation loss: 3.368934317001837

Epoch: 6| Step: 6
Training loss: 3.812234337727936
Validation loss: 3.372601086845426

Epoch: 6| Step: 7
Training loss: 4.606000072060177
Validation loss: 3.3700044304257575

Epoch: 6| Step: 8
Training loss: 3.6005015765561335
Validation loss: 3.3700757429091563

Epoch: 6| Step: 9
Training loss: 2.986146730511175
Validation loss: 3.3681251513332113

Epoch: 6| Step: 10
Training loss: 3.032141485571772
Validation loss: 3.367796922372408

Epoch: 6| Step: 11
Training loss: 4.299809677880082
Validation loss: 3.3667728776076786

Epoch: 6| Step: 12
Training loss: 2.761739123753527
Validation loss: 3.370551898240003

Epoch: 6| Step: 13
Training loss: 4.294491748513642
Validation loss: 3.368174730605703

Epoch: 25| Step: 0
Training loss: 4.083068423857999
Validation loss: 3.366468061629981

Epoch: 6| Step: 1
Training loss: 3.1738883708224357
Validation loss: 3.3645015990959015

Epoch: 6| Step: 2
Training loss: 3.4071150215065225
Validation loss: 3.3645596787999583

Epoch: 6| Step: 3
Training loss: 3.4422406885554615
Validation loss: 3.365464905001155

Epoch: 6| Step: 4
Training loss: 2.517556059439522
Validation loss: 3.3632821768884615

Epoch: 6| Step: 5
Training loss: 3.2612871626889177
Validation loss: 3.363536067631479

Epoch: 6| Step: 6
Training loss: 3.961456084303009
Validation loss: 3.3621873435683844

Epoch: 6| Step: 7
Training loss: 3.089646363253144
Validation loss: 3.36320879183831

Epoch: 6| Step: 8
Training loss: 3.4418299367630922
Validation loss: 3.361421177604694

Epoch: 6| Step: 9
Training loss: 2.2726423308364896
Validation loss: 3.3592251606153356

Epoch: 6| Step: 10
Training loss: 4.543055237515089
Validation loss: 3.3595962928484098

Epoch: 6| Step: 11
Training loss: 4.046598800601234
Validation loss: 3.359529351754284

Epoch: 6| Step: 12
Training loss: 4.407985480753669
Validation loss: 3.3589585660709225

Epoch: 6| Step: 13
Training loss: 4.134573721633119
Validation loss: 3.356781897614176

Epoch: 26| Step: 0
Training loss: 3.3133228647487547
Validation loss: 3.357579836454933

Epoch: 6| Step: 1
Training loss: 3.0469056739241234
Validation loss: 3.3528639069064785

Epoch: 6| Step: 2
Training loss: 4.162710804226498
Validation loss: 3.349618794977389

Epoch: 6| Step: 3
Training loss: 3.5195792107060995
Validation loss: 3.3463850720038493

Epoch: 6| Step: 4
Training loss: 2.9805201054819492
Validation loss: 3.345286802314337

Epoch: 6| Step: 5
Training loss: 3.9866716534977815
Validation loss: 3.338507241362804

Epoch: 6| Step: 6
Training loss: 3.563489809897615
Validation loss: 3.334897501614272

Epoch: 6| Step: 7
Training loss: 4.018690312299752
Validation loss: 3.3327957494045064

Epoch: 6| Step: 8
Training loss: 3.1809883174927553
Validation loss: 3.3290346427601936

Epoch: 6| Step: 9
Training loss: 2.488083285087683
Validation loss: 3.329587237829892

Epoch: 6| Step: 10
Training loss: 4.312358466880392
Validation loss: 3.3253822407954945

Epoch: 6| Step: 11
Training loss: 3.9428457876993632
Validation loss: 3.324663292941301

Epoch: 6| Step: 12
Training loss: 3.4311778799235633
Validation loss: 3.3253443369803217

Epoch: 6| Step: 13
Training loss: 3.6185105213256374
Validation loss: 3.323317683172744

Epoch: 27| Step: 0
Training loss: 4.3342818664798095
Validation loss: 3.323545333907355

Epoch: 6| Step: 1
Training loss: 3.136646388681222
Validation loss: 3.320552408525664

Epoch: 6| Step: 2
Training loss: 4.3256974556461065
Validation loss: 3.3210411635964325

Epoch: 6| Step: 3
Training loss: 3.6198997133810935
Validation loss: 3.321207859603554

Epoch: 6| Step: 4
Training loss: 4.014683000679788
Validation loss: 3.32070465377941

Epoch: 6| Step: 5
Training loss: 3.9967728948487986
Validation loss: 3.3204922156825747

Epoch: 6| Step: 6
Training loss: 3.6047125753879
Validation loss: 3.3161985027242102

Epoch: 6| Step: 7
Training loss: 2.878957098378543
Validation loss: 3.3285526422818106

Epoch: 6| Step: 8
Training loss: 3.8341400845545905
Validation loss: 3.3173065781978712

Epoch: 6| Step: 9
Training loss: 2.3317954808451247
Validation loss: 3.3214513805217343

Epoch: 6| Step: 10
Training loss: 2.6059494833276724
Validation loss: 3.331396034206002

Epoch: 6| Step: 11
Training loss: 3.8738662537828104
Validation loss: 3.3433878697446553

Epoch: 6| Step: 12
Training loss: 3.1389346911784255
Validation loss: 3.340204336508143

Epoch: 6| Step: 13
Training loss: 3.465699099960186
Validation loss: 3.3336466554825672

Epoch: 28| Step: 0
Training loss: 3.5186895280591393
Validation loss: 3.3340002474631185

Epoch: 6| Step: 1
Training loss: 2.704802593424698
Validation loss: 3.3351495829643976

Epoch: 6| Step: 2
Training loss: 3.5772821358187623
Validation loss: 3.331658045925182

Epoch: 6| Step: 3
Training loss: 3.9960512697827615
Validation loss: 3.3311903084146754

Epoch: 6| Step: 4
Training loss: 3.650239356566839
Validation loss: 3.326159065912749

Epoch: 6| Step: 5
Training loss: 4.01523692114911
Validation loss: 3.3185340700020243

Epoch: 6| Step: 6
Training loss: 3.5518828006345253
Validation loss: 3.31522339159064

Epoch: 6| Step: 7
Training loss: 3.4107973035867705
Validation loss: 3.31292006680475

Epoch: 6| Step: 8
Training loss: 3.47522111367614
Validation loss: 3.3123860802993055

Epoch: 6| Step: 9
Training loss: 3.1745732298452953
Validation loss: 3.308516170261776

Epoch: 6| Step: 10
Training loss: 3.609711998734269
Validation loss: 3.3070044985429314

Epoch: 6| Step: 11
Training loss: 4.142808561556998
Validation loss: 3.3074118522192277

Epoch: 6| Step: 12
Training loss: 3.423571161875746
Validation loss: 3.3067590066387944

Epoch: 6| Step: 13
Training loss: 3.1148516859379716
Validation loss: 3.31117067075854

Epoch: 29| Step: 0
Training loss: 2.838356688652186
Validation loss: 3.3096529984498226

Epoch: 6| Step: 1
Training loss: 3.3430906697448775
Validation loss: 3.310444776847204

Epoch: 6| Step: 2
Training loss: 2.998099996984581
Validation loss: 3.3111448482068266

Epoch: 6| Step: 3
Training loss: 3.408946938220086
Validation loss: 3.3033236904948704

Epoch: 6| Step: 4
Training loss: 3.1528394042353196
Validation loss: 3.3022597606654553

Epoch: 6| Step: 5
Training loss: 3.6311036387376645
Validation loss: 3.3019708347899477

Epoch: 6| Step: 6
Training loss: 4.054611763954286
Validation loss: 3.2964547729325715

Epoch: 6| Step: 7
Training loss: 3.7646847892619113
Validation loss: 3.3028828993506996

Epoch: 6| Step: 8
Training loss: 4.008531294049726
Validation loss: 3.29823690407893

Epoch: 6| Step: 9
Training loss: 4.0733895706148875
Validation loss: 3.2974589315308136

Epoch: 6| Step: 10
Training loss: 3.817741418185995
Validation loss: 3.2983764563822433

Epoch: 6| Step: 11
Training loss: 2.887417720266431
Validation loss: 3.3027671141447574

Epoch: 6| Step: 12
Training loss: 4.069754827739646
Validation loss: 3.302528450463666

Epoch: 6| Step: 13
Training loss: 2.85888751100811
Validation loss: 3.296128703749394

Epoch: 30| Step: 0
Training loss: 3.423953048072189
Validation loss: 3.2959909136767678

Epoch: 6| Step: 1
Training loss: 3.2408173756898493
Validation loss: 3.2974887842839706

Epoch: 6| Step: 2
Training loss: 3.1035355986810065
Validation loss: 3.303518662985691

Epoch: 6| Step: 3
Training loss: 3.702050805722668
Validation loss: 3.3009344273292553

Epoch: 6| Step: 4
Training loss: 3.5733853728742004
Validation loss: 3.3017409612232393

Epoch: 6| Step: 5
Training loss: 3.714225517036661
Validation loss: 3.2995999755363434

Epoch: 6| Step: 6
Training loss: 3.2245860107610556
Validation loss: 3.2949724872903254

Epoch: 6| Step: 7
Training loss: 2.9266276338562403
Validation loss: 3.296229660278355

Epoch: 6| Step: 8
Training loss: 4.477072268981658
Validation loss: 3.291948567836758

Epoch: 6| Step: 9
Training loss: 4.133507019413541
Validation loss: 3.2920716237673755

Epoch: 6| Step: 10
Training loss: 3.861235506049678
Validation loss: 3.2981981457569933

Epoch: 6| Step: 11
Training loss: 3.5165023048162265
Validation loss: 3.305409153123167

Epoch: 6| Step: 12
Training loss: 3.342250737416368
Validation loss: 3.3013152110317243

Epoch: 6| Step: 13
Training loss: 2.35919582873985
Validation loss: 3.3006197811310485

Epoch: 31| Step: 0
Training loss: 3.834567134057092
Validation loss: 3.3043639647871896

Epoch: 6| Step: 1
Training loss: 3.147312010467877
Validation loss: 3.29031678093092

Epoch: 6| Step: 2
Training loss: 4.119146181539637
Validation loss: 3.2885439167267525

Epoch: 6| Step: 3
Training loss: 3.5252811996088935
Validation loss: 3.2975915323499234

Epoch: 6| Step: 4
Training loss: 3.9851273368679507
Validation loss: 3.3114087812441726

Epoch: 6| Step: 5
Training loss: 2.9146366320834094
Validation loss: 3.3004330007623084

Epoch: 6| Step: 6
Training loss: 3.216273419813455
Validation loss: 3.2874767578855555

Epoch: 6| Step: 7
Training loss: 3.2418867224471617
Validation loss: 3.2857988335901926

Epoch: 6| Step: 8
Training loss: 2.8655056295211465
Validation loss: 3.2867269813609266

Epoch: 6| Step: 9
Training loss: 3.688322072610215
Validation loss: 3.2901409274157905

Epoch: 6| Step: 10
Training loss: 3.921777731612524
Validation loss: 3.2962309132323977

Epoch: 6| Step: 11
Training loss: 4.42461835864167
Validation loss: 3.3013750763821403

Epoch: 6| Step: 12
Training loss: 2.6440353492070496
Validation loss: 3.2941531137158404

Epoch: 6| Step: 13
Training loss: 3.544190453770115
Validation loss: 3.2913935823093263

Epoch: 32| Step: 0
Training loss: 3.59638813876552
Validation loss: 3.2935112353664455

Epoch: 6| Step: 1
Training loss: 3.24056547104723
Validation loss: 3.288163034045979

Epoch: 6| Step: 2
Training loss: 4.101377646504058
Validation loss: 3.287218508738089

Epoch: 6| Step: 3
Training loss: 3.863885876559715
Validation loss: 3.2819328742131395

Epoch: 6| Step: 4
Training loss: 3.9078548949213485
Validation loss: 3.278012777276848

Epoch: 6| Step: 5
Training loss: 3.7295259412749853
Validation loss: 3.2804584710663405

Epoch: 6| Step: 6
Training loss: 3.661768734157193
Validation loss: 3.2765843407742348

Epoch: 6| Step: 7
Training loss: 2.8375572434083405
Validation loss: 3.2825134438817183

Epoch: 6| Step: 8
Training loss: 4.1757168457089024
Validation loss: 3.2773826266615913

Epoch: 6| Step: 9
Training loss: 3.6045637555124075
Validation loss: 3.275753643546752

Epoch: 6| Step: 10
Training loss: 3.6425896447539023
Validation loss: 3.276577576028539

Epoch: 6| Step: 11
Training loss: 2.163062129524735
Validation loss: 3.2761965526131753

Epoch: 6| Step: 12
Training loss: 2.713557843082606
Validation loss: 3.275107759150885

Epoch: 6| Step: 13
Training loss: 3.5584710075909336
Validation loss: 3.2736608384174803

Epoch: 33| Step: 0
Training loss: 3.658119701731651
Validation loss: 3.2722653162912585

Epoch: 6| Step: 1
Training loss: 3.6471632502768396
Validation loss: 3.273809203313144

Epoch: 6| Step: 2
Training loss: 3.772895221168294
Validation loss: 3.274515214071146

Epoch: 6| Step: 3
Training loss: 3.905429601349095
Validation loss: 3.275126510239441

Epoch: 6| Step: 4
Training loss: 3.549583845864301
Validation loss: 3.2760466931917818

Epoch: 6| Step: 5
Training loss: 2.657066578729726
Validation loss: 3.2748315370328043

Epoch: 6| Step: 6
Training loss: 4.24754733952304
Validation loss: 3.2752062444146275

Epoch: 6| Step: 7
Training loss: 3.6375735350841407
Validation loss: 3.274481210681051

Epoch: 6| Step: 8
Training loss: 3.8571104749702836
Validation loss: 3.2733172835803304

Epoch: 6| Step: 9
Training loss: 3.3132920667763632
Validation loss: 3.2727632119102137

Epoch: 6| Step: 10
Training loss: 3.6290442170523756
Validation loss: 3.267007654280968

Epoch: 6| Step: 11
Training loss: 3.084906683550707
Validation loss: 3.267973222635567

Epoch: 6| Step: 12
Training loss: 2.695830983588852
Validation loss: 3.265247418720578

Epoch: 6| Step: 13
Training loss: 2.945992874364788
Validation loss: 3.2697803758530823

Epoch: 34| Step: 0
Training loss: 3.240348864482003
Validation loss: 3.2702907464660305

Epoch: 6| Step: 1
Training loss: 3.1279199310064825
Validation loss: 3.266843780008865

Epoch: 6| Step: 2
Training loss: 3.6396522368423287
Validation loss: 3.2651530974489495

Epoch: 6| Step: 3
Training loss: 3.232993895289247
Validation loss: 3.2675580901835515

Epoch: 6| Step: 4
Training loss: 2.8917666268637867
Validation loss: 3.268852815183785

Epoch: 6| Step: 5
Training loss: 3.4645175715796537
Validation loss: 3.268842825225178

Epoch: 6| Step: 6
Training loss: 2.279722878362659
Validation loss: 3.2700184693444756

Epoch: 6| Step: 7
Training loss: 3.6446050409531368
Validation loss: 3.272704720432375

Epoch: 6| Step: 8
Training loss: 4.221359237237984
Validation loss: 3.273391903834714

Epoch: 6| Step: 9
Training loss: 4.174168559905542
Validation loss: 3.2708025062748542

Epoch: 6| Step: 10
Training loss: 3.664905833326537
Validation loss: 3.26578632687706

Epoch: 6| Step: 11
Training loss: 3.6456259241598348
Validation loss: 3.265729680821829

Epoch: 6| Step: 12
Training loss: 2.6886347659364316
Validation loss: 3.2645328055571134

Epoch: 6| Step: 13
Training loss: 5.182292484558143
Validation loss: 3.263320773277114

Epoch: 35| Step: 0
Training loss: 3.1413635600124854
Validation loss: 3.2625652332641844

Epoch: 6| Step: 1
Training loss: 4.766734710065432
Validation loss: 3.26181101313295

Epoch: 6| Step: 2
Training loss: 3.293826605758304
Validation loss: 3.2631702518356254

Epoch: 6| Step: 3
Training loss: 2.9755476375427317
Validation loss: 3.2613264791522454

Epoch: 6| Step: 4
Training loss: 3.4931783955796942
Validation loss: 3.2605633378157037

Epoch: 6| Step: 5
Training loss: 3.8180863773092835
Validation loss: 3.26020124795037

Epoch: 6| Step: 6
Training loss: 3.0741160665228797
Validation loss: 3.2620296902597694

Epoch: 6| Step: 7
Training loss: 3.849195267435538
Validation loss: 3.2585838555373003

Epoch: 6| Step: 8
Training loss: 3.1333634422424796
Validation loss: 3.260745453430655

Epoch: 6| Step: 9
Training loss: 4.065683379402869
Validation loss: 3.2586737890742534

Epoch: 6| Step: 10
Training loss: 2.9198095191593967
Validation loss: 3.257789288899434

Epoch: 6| Step: 11
Training loss: 3.2098778974180635
Validation loss: 3.258909314531363

Epoch: 6| Step: 12
Training loss: 3.3209394513784316
Validation loss: 3.2582009954061104

Epoch: 6| Step: 13
Training loss: 3.564366303523099
Validation loss: 3.2568887946518608

Epoch: 36| Step: 0
Training loss: 3.3967417026675895
Validation loss: 3.256862285106665

Epoch: 6| Step: 1
Training loss: 4.11071175419764
Validation loss: 3.256976056272222

Epoch: 6| Step: 2
Training loss: 3.5474740081329568
Validation loss: 3.2579319964635447

Epoch: 6| Step: 3
Training loss: 3.233083568508849
Validation loss: 3.257397586076809

Epoch: 6| Step: 4
Training loss: 3.479699800192955
Validation loss: 3.2669061211582653

Epoch: 6| Step: 5
Training loss: 3.6520010231492948
Validation loss: 3.2700451560350743

Epoch: 6| Step: 6
Training loss: 3.4306397386965064
Validation loss: 3.2616828761744743

Epoch: 6| Step: 7
Training loss: 3.8409149134993474
Validation loss: 3.254674425931289

Epoch: 6| Step: 8
Training loss: 3.0020806726624354
Validation loss: 3.2545053524160314

Epoch: 6| Step: 9
Training loss: 4.145835735889039
Validation loss: 3.2530394099489612

Epoch: 6| Step: 10
Training loss: 3.4520078206863305
Validation loss: 3.2536999676546414

Epoch: 6| Step: 11
Training loss: 3.079213526003142
Validation loss: 3.252303409184593

Epoch: 6| Step: 12
Training loss: 3.032286791118833
Validation loss: 3.252604547620769

Epoch: 6| Step: 13
Training loss: 3.2649634754422108
Validation loss: 3.2534525212619085

Epoch: 37| Step: 0
Training loss: 3.2822405092124103
Validation loss: 3.2525379062467272

Epoch: 6| Step: 1
Training loss: 3.969382048011833
Validation loss: 3.252072102059825

Epoch: 6| Step: 2
Training loss: 3.6943068960743926
Validation loss: 3.2531502603352376

Epoch: 6| Step: 3
Training loss: 3.9048386122095167
Validation loss: 3.249873554051201

Epoch: 6| Step: 4
Training loss: 3.3294460200115723
Validation loss: 3.2498423867071407

Epoch: 6| Step: 5
Training loss: 3.532500594153223
Validation loss: 3.247096502491598

Epoch: 6| Step: 6
Training loss: 3.426853268832916
Validation loss: 3.2500361211014197

Epoch: 6| Step: 7
Training loss: 2.7488161486567653
Validation loss: 3.2537749668908327

Epoch: 6| Step: 8
Training loss: 3.900033627878609
Validation loss: 3.2579777696498287

Epoch: 6| Step: 9
Training loss: 3.822442020952056
Validation loss: 3.264218007214715

Epoch: 6| Step: 10
Training loss: 2.603406281403701
Validation loss: 3.253411075066472

Epoch: 6| Step: 11
Training loss: 3.656461530255885
Validation loss: 3.2468423704378493

Epoch: 6| Step: 12
Training loss: 3.436337361090805
Validation loss: 3.2486833456363153

Epoch: 6| Step: 13
Training loss: 3.252771369702631
Validation loss: 3.2454988564260994

Epoch: 38| Step: 0
Training loss: 2.890813048148514
Validation loss: 3.246342433285832

Epoch: 6| Step: 1
Training loss: 3.651142171581996
Validation loss: 3.2475427578422336

Epoch: 6| Step: 2
Training loss: 3.957556129582855
Validation loss: 3.2476872970575266

Epoch: 6| Step: 3
Training loss: 3.14163146332328
Validation loss: 3.247985930434614

Epoch: 6| Step: 4
Training loss: 1.7807483970702354
Validation loss: 3.2480283140777724

Epoch: 6| Step: 5
Training loss: 3.8888744414530434
Validation loss: 3.246323671509626

Epoch: 6| Step: 6
Training loss: 3.4473298064138644
Validation loss: 3.244777546613583

Epoch: 6| Step: 7
Training loss: 3.69178380902321
Validation loss: 3.2439437472299586

Epoch: 6| Step: 8
Training loss: 2.5008615916442722
Validation loss: 3.2430884336976047

Epoch: 6| Step: 9
Training loss: 4.398462217542671
Validation loss: 3.2447834113876595

Epoch: 6| Step: 10
Training loss: 3.623026343439129
Validation loss: 3.242284889898344

Epoch: 6| Step: 11
Training loss: 3.9146122651031727
Validation loss: 3.2443587357816472

Epoch: 6| Step: 12
Training loss: 3.443169790361961
Validation loss: 3.2425040418555238

Epoch: 6| Step: 13
Training loss: 3.8797010393094653
Validation loss: 3.2401637004023156

Epoch: 39| Step: 0
Training loss: 3.0553901820272826
Validation loss: 3.240588974811541

Epoch: 6| Step: 1
Training loss: 2.8567419383912642
Validation loss: 3.239265103130238

Epoch: 6| Step: 2
Training loss: 4.276157887126569
Validation loss: 3.238802801017081

Epoch: 6| Step: 3
Training loss: 3.789053942483893
Validation loss: 3.2402476084148537

Epoch: 6| Step: 4
Training loss: 3.427059200553606
Validation loss: 3.241068062409644

Epoch: 6| Step: 5
Training loss: 3.349285926438801
Validation loss: 3.237885423939104

Epoch: 6| Step: 6
Training loss: 3.398280909646691
Validation loss: 3.2383244145677534

Epoch: 6| Step: 7
Training loss: 3.0627176635619446
Validation loss: 3.2474302098001635

Epoch: 6| Step: 8
Training loss: 3.186148263377834
Validation loss: 3.2466868874294414

Epoch: 6| Step: 9
Training loss: 4.010661698159056
Validation loss: 3.272135190503159

Epoch: 6| Step: 10
Training loss: 3.5945075522033165
Validation loss: 3.2609848543788913

Epoch: 6| Step: 11
Training loss: 3.5806207074009606
Validation loss: 3.2440520113304823

Epoch: 6| Step: 12
Training loss: 3.5139873844326277
Validation loss: 3.236434895650035

Epoch: 6| Step: 13
Training loss: 3.394090419718025
Validation loss: 3.236177929268178

Epoch: 40| Step: 0
Training loss: 3.7528864877652865
Validation loss: 3.2328162368337834

Epoch: 6| Step: 1
Training loss: 3.5934700234859873
Validation loss: 3.236092291718905

Epoch: 6| Step: 2
Training loss: 4.033100028948682
Validation loss: 3.237442539541533

Epoch: 6| Step: 3
Training loss: 3.766294554387662
Validation loss: 3.2356811726769745

Epoch: 6| Step: 4
Training loss: 3.227881801488004
Validation loss: 3.236287856858516

Epoch: 6| Step: 5
Training loss: 3.552282035095236
Validation loss: 3.234104966577567

Epoch: 6| Step: 6
Training loss: 3.5595195416046574
Validation loss: 3.2343183110925398

Epoch: 6| Step: 7
Training loss: 3.745164933080593
Validation loss: 3.233630970976827

Epoch: 6| Step: 8
Training loss: 3.665085769628109
Validation loss: 3.2319222899209747

Epoch: 6| Step: 9
Training loss: 2.7960913215535
Validation loss: 3.2305626356904416

Epoch: 6| Step: 10
Training loss: 4.17689469340384
Validation loss: 3.2282145313459734

Epoch: 6| Step: 11
Training loss: 2.8606321145807447
Validation loss: 3.228620358452542

Epoch: 6| Step: 12
Training loss: 2.461616156113016
Validation loss: 3.2286974695390054

Epoch: 6| Step: 13
Training loss: 2.803034047976405
Validation loss: 3.2313199509574204

Epoch: 41| Step: 0
Training loss: 2.675683413756541
Validation loss: 3.229898431902344

Epoch: 6| Step: 1
Training loss: 3.3479244520899596
Validation loss: 3.2302080590282376

Epoch: 6| Step: 2
Training loss: 3.3951481476990395
Validation loss: 3.2306956587603843

Epoch: 6| Step: 3
Training loss: 2.8722325149177905
Validation loss: 3.2331895828218684

Epoch: 6| Step: 4
Training loss: 3.5064449915665064
Validation loss: 3.230198981296322

Epoch: 6| Step: 5
Training loss: 3.1359746865204556
Validation loss: 3.22880914450882

Epoch: 6| Step: 6
Training loss: 3.5135653417615043
Validation loss: 3.227106000664332

Epoch: 6| Step: 7
Training loss: 4.088204158126817
Validation loss: 3.2258011718419666

Epoch: 6| Step: 8
Training loss: 3.817920146372838
Validation loss: 3.2243249753524723

Epoch: 6| Step: 9
Training loss: 3.624109619234297
Validation loss: 3.2266026765796556

Epoch: 6| Step: 10
Training loss: 3.084040809776944
Validation loss: 3.2268366181883525

Epoch: 6| Step: 11
Training loss: 3.927117115688305
Validation loss: 3.227720191627363

Epoch: 6| Step: 12
Training loss: 4.071436047845922
Validation loss: 3.2245360825290943

Epoch: 6| Step: 13
Training loss: 3.1004330670976024
Validation loss: 3.226087007627748

Epoch: 42| Step: 0
Training loss: 3.0279630162992697
Validation loss: 3.224120694985245

Epoch: 6| Step: 1
Training loss: 3.32028090518056
Validation loss: 3.2253600713587445

Epoch: 6| Step: 2
Training loss: 4.0420366622568284
Validation loss: 3.222775560881988

Epoch: 6| Step: 3
Training loss: 3.915877174726805
Validation loss: 3.221853356104535

Epoch: 6| Step: 4
Training loss: 3.89467829481211
Validation loss: 3.223902387930614

Epoch: 6| Step: 5
Training loss: 3.262782854117785
Validation loss: 3.224056010156775

Epoch: 6| Step: 6
Training loss: 2.6684235705959085
Validation loss: 3.2207418145542532

Epoch: 6| Step: 7
Training loss: 3.503901895203537
Validation loss: 3.223207252708024

Epoch: 6| Step: 8
Training loss: 2.9794744230357835
Validation loss: 3.228566798695349

Epoch: 6| Step: 9
Training loss: 3.5601870071927517
Validation loss: 3.2377259746085616

Epoch: 6| Step: 10
Training loss: 3.0655219291135363
Validation loss: 3.2478084416387687

Epoch: 6| Step: 11
Training loss: 3.3566790031299854
Validation loss: 3.2254226754174895

Epoch: 6| Step: 12
Training loss: 3.247762643531806
Validation loss: 3.218083058581349

Epoch: 6| Step: 13
Training loss: 4.932063912836858
Validation loss: 3.219750707266842

Epoch: 43| Step: 0
Training loss: 3.3244306091144233
Validation loss: 3.2250930660778683

Epoch: 6| Step: 1
Training loss: 3.86264751856303
Validation loss: 3.240805772583658

Epoch: 6| Step: 2
Training loss: 3.181701172497854
Validation loss: 3.239350072743564

Epoch: 6| Step: 3
Training loss: 3.2383940415934456
Validation loss: 3.2268142425202493

Epoch: 6| Step: 4
Training loss: 3.3545031329424777
Validation loss: 3.2217029343571

Epoch: 6| Step: 5
Training loss: 3.651668318854451
Validation loss: 3.21744169556491

Epoch: 6| Step: 6
Training loss: 3.047791797916128
Validation loss: 3.215501134266176

Epoch: 6| Step: 7
Training loss: 3.437697248868482
Validation loss: 3.220661168205835

Epoch: 6| Step: 8
Training loss: 2.705880056560742
Validation loss: 3.225441431599828

Epoch: 6| Step: 9
Training loss: 3.989781918409793
Validation loss: 3.230361640099755

Epoch: 6| Step: 10
Training loss: 3.4295987962795857
Validation loss: 3.2356470987049715

Epoch: 6| Step: 11
Training loss: 3.9744168171645082
Validation loss: 3.2291596464516776

Epoch: 6| Step: 12
Training loss: 3.1445940283911935
Validation loss: 3.2213221052898797

Epoch: 6| Step: 13
Training loss: 4.4337180771389635
Validation loss: 3.2146770267747424

Epoch: 44| Step: 0
Training loss: 4.120842890765322
Validation loss: 3.2143931065719284

Epoch: 6| Step: 1
Training loss: 3.5463554909324033
Validation loss: 3.2147430032130733

Epoch: 6| Step: 2
Training loss: 3.5732827550477966
Validation loss: 3.215435479543783

Epoch: 6| Step: 3
Training loss: 3.760595738311529
Validation loss: 3.216601076455741

Epoch: 6| Step: 4
Training loss: 3.435785039179433
Validation loss: 3.2151400964383523

Epoch: 6| Step: 5
Training loss: 3.167277795815242
Validation loss: 3.216389927496652

Epoch: 6| Step: 6
Training loss: 3.1298936293202324
Validation loss: 3.2153245041649234

Epoch: 6| Step: 7
Training loss: 2.819642555363117
Validation loss: 3.215401151160856

Epoch: 6| Step: 8
Training loss: 3.6099629769579806
Validation loss: 3.212483300772577

Epoch: 6| Step: 9
Training loss: 2.7967736422964045
Validation loss: 3.2097271668409735

Epoch: 6| Step: 10
Training loss: 3.1318409619054646
Validation loss: 3.2095632082919567

Epoch: 6| Step: 11
Training loss: 3.476293934939151
Validation loss: 3.2088047432905675

Epoch: 6| Step: 12
Training loss: 4.046908934461971
Validation loss: 3.206231639570977

Epoch: 6| Step: 13
Training loss: 3.7296034203757924
Validation loss: 3.208250967363373

Epoch: 45| Step: 0
Training loss: 3.6778052956767184
Validation loss: 3.208918184292999

Epoch: 6| Step: 1
Training loss: 3.4789092983298455
Validation loss: 3.211155726441765

Epoch: 6| Step: 2
Training loss: 3.9268928434411894
Validation loss: 3.2130192444871306

Epoch: 6| Step: 3
Training loss: 4.3447964731886595
Validation loss: 3.2077685608695723

Epoch: 6| Step: 4
Training loss: 3.421243408999577
Validation loss: 3.2091638097237136

Epoch: 6| Step: 5
Training loss: 2.3391862305232
Validation loss: 3.204876153471012

Epoch: 6| Step: 6
Training loss: 3.686447251903173
Validation loss: 3.2013203288930505

Epoch: 6| Step: 7
Training loss: 3.034225733628318
Validation loss: 3.202736724522907

Epoch: 6| Step: 8
Training loss: 4.076441625672401
Validation loss: 3.20122639041805

Epoch: 6| Step: 9
Training loss: 2.63243095734888
Validation loss: 3.2029439047086137

Epoch: 6| Step: 10
Training loss: 3.2030154325772653
Validation loss: 3.202949307413191

Epoch: 6| Step: 11
Training loss: 3.769123146221391
Validation loss: 3.201060262570732

Epoch: 6| Step: 12
Training loss: 3.476295032284984
Validation loss: 3.199731469295568

Epoch: 6| Step: 13
Training loss: 2.005740985886717
Validation loss: 3.1992961642743536

Epoch: 46| Step: 0
Training loss: 3.6766866122339117
Validation loss: 3.2007368836162677

Epoch: 6| Step: 1
Training loss: 3.3490034528494093
Validation loss: 3.2007012409978253

Epoch: 6| Step: 2
Training loss: 3.496572723823756
Validation loss: 3.1983918185763374

Epoch: 6| Step: 3
Training loss: 3.2947256304555115
Validation loss: 3.200147330125281

Epoch: 6| Step: 4
Training loss: 4.171430814148959
Validation loss: 3.1974554028181026

Epoch: 6| Step: 5
Training loss: 3.164511114271238
Validation loss: 3.1997625783294557

Epoch: 6| Step: 6
Training loss: 4.055875100795382
Validation loss: 3.2005999801556233

Epoch: 6| Step: 7
Training loss: 3.781205358320544
Validation loss: 3.199338494204859

Epoch: 6| Step: 8
Training loss: 2.776026417378428
Validation loss: 3.199165505764713

Epoch: 6| Step: 9
Training loss: 2.573699482018574
Validation loss: 3.1951689068227953

Epoch: 6| Step: 10
Training loss: 2.893787530445576
Validation loss: 3.1981006673728944

Epoch: 6| Step: 11
Training loss: 3.441079512812945
Validation loss: 3.1966889733667507

Epoch: 6| Step: 12
Training loss: 4.025273587424
Validation loss: 3.1954859665861433

Epoch: 6| Step: 13
Training loss: 2.9691751276096072
Validation loss: 3.195499204003961

Epoch: 47| Step: 0
Training loss: 3.1301251917168287
Validation loss: 3.195412388007071

Epoch: 6| Step: 1
Training loss: 2.9452814156184632
Validation loss: 3.197656136988856

Epoch: 6| Step: 2
Training loss: 3.9927335541118767
Validation loss: 3.196723495474928

Epoch: 6| Step: 3
Training loss: 2.2720223443316065
Validation loss: 3.1944994056031395

Epoch: 6| Step: 4
Training loss: 4.098838846419314
Validation loss: 3.194318573302673

Epoch: 6| Step: 5
Training loss: 3.5095846546624556
Validation loss: 3.205733337396965

Epoch: 6| Step: 6
Training loss: 3.712262047742373
Validation loss: 3.203400173017702

Epoch: 6| Step: 7
Training loss: 3.117993855214013
Validation loss: 3.194067260198376

Epoch: 6| Step: 8
Training loss: 3.8575572316046047
Validation loss: 3.1928192126377333

Epoch: 6| Step: 9
Training loss: 4.058658603006875
Validation loss: 3.190948893360511

Epoch: 6| Step: 10
Training loss: 2.7512582154695107
Validation loss: 3.1929142182366483

Epoch: 6| Step: 11
Training loss: 2.4558133501582384
Validation loss: 3.194947993244729

Epoch: 6| Step: 12
Training loss: 3.8983325523668158
Validation loss: 3.197999506158648

Epoch: 6| Step: 13
Training loss: 4.000216716617642
Validation loss: 3.1957658998165437

Epoch: 48| Step: 0
Training loss: 2.847015853060556
Validation loss: 3.191117736778088

Epoch: 6| Step: 1
Training loss: 3.201729819531978
Validation loss: 3.192279260831458

Epoch: 6| Step: 2
Training loss: 3.3428429059481175
Validation loss: 3.1900056597342843

Epoch: 6| Step: 3
Training loss: 3.5242698346077965
Validation loss: 3.187273619476913

Epoch: 6| Step: 4
Training loss: 3.2849719055925313
Validation loss: 3.1882364096794142

Epoch: 6| Step: 5
Training loss: 3.9079971678615215
Validation loss: 3.190591011928149

Epoch: 6| Step: 6
Training loss: 2.7086618859958294
Validation loss: 3.1923042620738973

Epoch: 6| Step: 7
Training loss: 4.0584553464581
Validation loss: 3.19292496283513

Epoch: 6| Step: 8
Training loss: 4.014221658665892
Validation loss: 3.1944756181030183

Epoch: 6| Step: 9
Training loss: 2.9985742359879084
Validation loss: 3.189614817104252

Epoch: 6| Step: 10
Training loss: 3.288225733496146
Validation loss: 3.1897230220058206

Epoch: 6| Step: 11
Training loss: 3.87914571186201
Validation loss: 3.196577179549594

Epoch: 6| Step: 12
Training loss: 3.732446148452598
Validation loss: 3.1965298726907254

Epoch: 6| Step: 13
Training loss: 2.7152949335630026
Validation loss: 3.19143190392553

Epoch: 49| Step: 0
Training loss: 4.411322089038862
Validation loss: 3.1897907659476656

Epoch: 6| Step: 1
Training loss: 3.4907138796071826
Validation loss: 3.1893364242603277

Epoch: 6| Step: 2
Training loss: 3.501097643260125
Validation loss: 3.1887318376086515

Epoch: 6| Step: 3
Training loss: 3.6034097630114195
Validation loss: 3.1884000875844123

Epoch: 6| Step: 4
Training loss: 2.389764568592132
Validation loss: 3.1871043761407933

Epoch: 6| Step: 5
Training loss: 2.7650257905443647
Validation loss: 3.1889849506808545

Epoch: 6| Step: 6
Training loss: 2.856381710029084
Validation loss: 3.1859053391477077

Epoch: 6| Step: 7
Training loss: 3.578800853883576
Validation loss: 3.1873525432184153

Epoch: 6| Step: 8
Training loss: 2.972291460349835
Validation loss: 3.18719596305528

Epoch: 6| Step: 9
Training loss: 4.339523784334485
Validation loss: 3.187430536847156

Epoch: 6| Step: 10
Training loss: 3.3584231425378035
Validation loss: 3.183811483330258

Epoch: 6| Step: 11
Training loss: 4.009183593367501
Validation loss: 3.1855449242307765

Epoch: 6| Step: 12
Training loss: 3.2330433043610065
Validation loss: 3.183179308848084

Epoch: 6| Step: 13
Training loss: 2.4884486359209714
Validation loss: 3.181392207368867

Epoch: 50| Step: 0
Training loss: 3.196083479486905
Validation loss: 3.1843486958495832

Epoch: 6| Step: 1
Training loss: 3.015686983252246
Validation loss: 3.1838537534163245

Epoch: 6| Step: 2
Training loss: 4.320796339317485
Validation loss: 3.1823002666581877

Epoch: 6| Step: 3
Training loss: 3.707745080359843
Validation loss: 3.182844959192813

Epoch: 6| Step: 4
Training loss: 2.473752229370531
Validation loss: 3.184163593181117

Epoch: 6| Step: 5
Training loss: 2.844408231577565
Validation loss: 3.1869602715574006

Epoch: 6| Step: 6
Training loss: 3.4559684542169897
Validation loss: 3.186333185580984

Epoch: 6| Step: 7
Training loss: 3.7413363514120155
Validation loss: 3.1886909185544274

Epoch: 6| Step: 8
Training loss: 2.955957094162447
Validation loss: 3.179795349360916

Epoch: 6| Step: 9
Training loss: 3.329884238765531
Validation loss: 3.179197410443768

Epoch: 6| Step: 10
Training loss: 4.071328532392928
Validation loss: 3.180890805420684

Epoch: 6| Step: 11
Training loss: 3.360601440823857
Validation loss: 3.179448123397245

Epoch: 6| Step: 12
Training loss: 3.598187567859482
Validation loss: 3.179287615648987

Epoch: 6| Step: 13
Training loss: 3.598184652385641
Validation loss: 3.1777652976184

Epoch: 51| Step: 0
Training loss: 4.067306726666808
Validation loss: 3.178241622820545

Epoch: 6| Step: 1
Training loss: 3.320993869655227
Validation loss: 3.176828479009549

Epoch: 6| Step: 2
Training loss: 2.8250079602154683
Validation loss: 3.1763093927939177

Epoch: 6| Step: 3
Training loss: 2.976461734217531
Validation loss: 3.1779045126344077

Epoch: 6| Step: 4
Training loss: 3.6004589318104046
Validation loss: 3.176373247704983

Epoch: 6| Step: 5
Training loss: 3.3658149913550317
Validation loss: 3.175910364148997

Epoch: 6| Step: 6
Training loss: 3.611384109219922
Validation loss: 3.1736913790717973

Epoch: 6| Step: 7
Training loss: 3.5887934463087388
Validation loss: 3.176106892984225

Epoch: 6| Step: 8
Training loss: 2.6010347581394058
Validation loss: 3.1743148406787207

Epoch: 6| Step: 9
Training loss: 2.5364571218207024
Validation loss: 3.1739214826788515

Epoch: 6| Step: 10
Training loss: 4.119987679250127
Validation loss: 3.175336065537598

Epoch: 6| Step: 11
Training loss: 3.9063740214686904
Validation loss: 3.1776038851742903

Epoch: 6| Step: 12
Training loss: 3.206353026402338
Validation loss: 3.182862099244098

Epoch: 6| Step: 13
Training loss: 3.947048900454998
Validation loss: 3.176339698128654

Epoch: 52| Step: 0
Training loss: 4.139264959421766
Validation loss: 3.1846880524495713

Epoch: 6| Step: 1
Training loss: 3.2044107973298983
Validation loss: 3.1745907860297873

Epoch: 6| Step: 2
Training loss: 3.3970903905611736
Validation loss: 3.168791189951674

Epoch: 6| Step: 3
Training loss: 2.865188608668656
Validation loss: 3.1711974209049405

Epoch: 6| Step: 4
Training loss: 3.193552591153905
Validation loss: 3.171025135101026

Epoch: 6| Step: 5
Training loss: 2.9133260578731006
Validation loss: 3.1712538024351047

Epoch: 6| Step: 6
Training loss: 3.024155957716433
Validation loss: 3.1668620014230915

Epoch: 6| Step: 7
Training loss: 3.4232563731733805
Validation loss: 3.1698821082267616

Epoch: 6| Step: 8
Training loss: 4.040260594716357
Validation loss: 3.17160675193168

Epoch: 6| Step: 9
Training loss: 3.4094420708790723
Validation loss: 3.169404411016951

Epoch: 6| Step: 10
Training loss: 3.8650229204887414
Validation loss: 3.169869539425543

Epoch: 6| Step: 11
Training loss: 3.8742271390940632
Validation loss: 3.1670376658010246

Epoch: 6| Step: 12
Training loss: 2.538311280847521
Validation loss: 3.1712299666802526

Epoch: 6| Step: 13
Training loss: 3.7238575457114296
Validation loss: 3.168192515820771

Epoch: 53| Step: 0
Training loss: 3.1582001053247777
Validation loss: 3.1650912608746538

Epoch: 6| Step: 1
Training loss: 3.2937310582001746
Validation loss: 3.1657071875532434

Epoch: 6| Step: 2
Training loss: 3.9497726761315306
Validation loss: 3.1665829699799803

Epoch: 6| Step: 3
Training loss: 3.5648013261004983
Validation loss: 3.165677960345606

Epoch: 6| Step: 4
Training loss: 3.5389803104246345
Validation loss: 3.165410068280816

Epoch: 6| Step: 5
Training loss: 3.437083409815338
Validation loss: 3.162125164884041

Epoch: 6| Step: 6
Training loss: 2.858676512407077
Validation loss: 3.163046638352964

Epoch: 6| Step: 7
Training loss: 3.5156125216792438
Validation loss: 3.161178057194227

Epoch: 6| Step: 8
Training loss: 3.4554311378979734
Validation loss: 3.1638665818589833

Epoch: 6| Step: 9
Training loss: 3.48062876666388
Validation loss: 3.1625250403590637

Epoch: 6| Step: 10
Training loss: 3.2228583625068405
Validation loss: 3.1600320891203144

Epoch: 6| Step: 11
Training loss: 4.034515477696239
Validation loss: 3.1624114559550165

Epoch: 6| Step: 12
Training loss: 2.9108972617299926
Validation loss: 3.162829852084699

Epoch: 6| Step: 13
Training loss: 2.9530055107687927
Validation loss: 3.1620151853578995

Epoch: 54| Step: 0
Training loss: 2.6987420860552604
Validation loss: 3.163730252959928

Epoch: 6| Step: 1
Training loss: 3.5347696503907073
Validation loss: 3.159897647390111

Epoch: 6| Step: 2
Training loss: 3.7218590570295738
Validation loss: 3.161622774262512

Epoch: 6| Step: 3
Training loss: 3.004253550916327
Validation loss: 3.1616615227006

Epoch: 6| Step: 4
Training loss: 4.0311310033460455
Validation loss: 3.165327490604277

Epoch: 6| Step: 5
Training loss: 2.43816092896165
Validation loss: 3.1673351018448055

Epoch: 6| Step: 6
Training loss: 3.922996573394905
Validation loss: 3.1608265799689432

Epoch: 6| Step: 7
Training loss: 3.4937462112324327
Validation loss: 3.1629125549492074

Epoch: 6| Step: 8
Training loss: 3.2906329467329702
Validation loss: 3.160468939416502

Epoch: 6| Step: 9
Training loss: 4.007105238825096
Validation loss: 3.1599366222400436

Epoch: 6| Step: 10
Training loss: 3.32686308098105
Validation loss: 3.160859389061801

Epoch: 6| Step: 11
Training loss: 3.356016387481145
Validation loss: 3.1556794731100997

Epoch: 6| Step: 12
Training loss: 3.157314007884671
Validation loss: 3.157572302474998

Epoch: 6| Step: 13
Training loss: 3.2505197842965097
Validation loss: 3.1565426975348765

Epoch: 55| Step: 0
Training loss: 3.6101357455105734
Validation loss: 3.153622542739396

Epoch: 6| Step: 1
Training loss: 4.532675472845885
Validation loss: 3.156875723771367

Epoch: 6| Step: 2
Training loss: 2.8154062302558622
Validation loss: 3.156196919501212

Epoch: 6| Step: 3
Training loss: 3.4340103469541674
Validation loss: 3.155285420138288

Epoch: 6| Step: 4
Training loss: 3.6728114455815617
Validation loss: 3.154044824418292

Epoch: 6| Step: 5
Training loss: 3.5236848799313254
Validation loss: 3.156067374968842

Epoch: 6| Step: 6
Training loss: 3.5479686244192297
Validation loss: 3.1556235932210757

Epoch: 6| Step: 7
Training loss: 3.7468515530601083
Validation loss: 3.156139303203606

Epoch: 6| Step: 8
Training loss: 3.419056188620957
Validation loss: 3.154883809585881

Epoch: 6| Step: 9
Training loss: 2.788816125924459
Validation loss: 3.154808229283692

Epoch: 6| Step: 10
Training loss: 2.8212266956697003
Validation loss: 3.157144201955864

Epoch: 6| Step: 11
Training loss: 3.2432821241402325
Validation loss: 3.1594872545781647

Epoch: 6| Step: 12
Training loss: 3.090065968621008
Validation loss: 3.159044797239376

Epoch: 6| Step: 13
Training loss: 2.6482580793702777
Validation loss: 3.156162552752688

Epoch: 56| Step: 0
Training loss: 3.320036609631652
Validation loss: 3.1545546380863025

Epoch: 6| Step: 1
Training loss: 3.434876429127258
Validation loss: 3.1535790228042884

Epoch: 6| Step: 2
Training loss: 3.046749797107054
Validation loss: 3.1506039676055004

Epoch: 6| Step: 3
Training loss: 4.037480234387087
Validation loss: 3.154180224355867

Epoch: 6| Step: 4
Training loss: 4.203500270044439
Validation loss: 3.150979595476386

Epoch: 6| Step: 5
Training loss: 3.339518213301532
Validation loss: 3.148482938529332

Epoch: 6| Step: 6
Training loss: 3.785751059834248
Validation loss: 3.148819409469222

Epoch: 6| Step: 7
Training loss: 3.2864591393971048
Validation loss: 3.149459462520253

Epoch: 6| Step: 8
Training loss: 2.497140393338542
Validation loss: 3.152212745864055

Epoch: 6| Step: 9
Training loss: 2.625005631213733
Validation loss: 3.148637252338119

Epoch: 6| Step: 10
Training loss: 2.856549978050377
Validation loss: 3.149672607737507

Epoch: 6| Step: 11
Training loss: 4.108236292891686
Validation loss: 3.1524219819636725

Epoch: 6| Step: 12
Training loss: 3.550380772331334
Validation loss: 3.1453393815794755

Epoch: 6| Step: 13
Training loss: 2.7058426971163874
Validation loss: 3.146881276673998

Epoch: 57| Step: 0
Training loss: 1.9199778799928569
Validation loss: 3.145993431910815

Epoch: 6| Step: 1
Training loss: 3.925257345133552
Validation loss: 3.146907264244359

Epoch: 6| Step: 2
Training loss: 2.7033308535124307
Validation loss: 3.1561527665678053

Epoch: 6| Step: 3
Training loss: 3.6115280269341747
Validation loss: 3.1642535286817965

Epoch: 6| Step: 4
Training loss: 3.9762389645367877
Validation loss: 3.1607191118272056

Epoch: 6| Step: 5
Training loss: 3.796389701817558
Validation loss: 3.1434241342623173

Epoch: 6| Step: 6
Training loss: 3.8748749743565316
Validation loss: 3.1437949117763564

Epoch: 6| Step: 7
Training loss: 3.6356725447852525
Validation loss: 3.141897380608172

Epoch: 6| Step: 8
Training loss: 3.072787386658634
Validation loss: 3.143966453895036

Epoch: 6| Step: 9
Training loss: 3.379215010278772
Validation loss: 3.1443619873293676

Epoch: 6| Step: 10
Training loss: 2.8895624630776444
Validation loss: 3.146953893065373

Epoch: 6| Step: 11
Training loss: 4.04690068652864
Validation loss: 3.1481091227241573

Epoch: 6| Step: 12
Training loss: 2.901629641181824
Validation loss: 3.146140583052904

Epoch: 6| Step: 13
Training loss: 2.983420653814581
Validation loss: 3.144197098904795

Epoch: 58| Step: 0
Training loss: 2.9691786607158703
Validation loss: 3.143106099991533

Epoch: 6| Step: 1
Training loss: 3.27904734477223
Validation loss: 3.144115762809223

Epoch: 6| Step: 2
Training loss: 2.916158050513334
Validation loss: 3.141884708016364

Epoch: 6| Step: 3
Training loss: 4.149939773306392
Validation loss: 3.141084174926997

Epoch: 6| Step: 4
Training loss: 4.023983342449074
Validation loss: 3.141396190452369

Epoch: 6| Step: 5
Training loss: 3.190691528224515
Validation loss: 3.1385059426795636

Epoch: 6| Step: 6
Training loss: 3.1920517977094693
Validation loss: 3.1395904072778067

Epoch: 6| Step: 7
Training loss: 3.2570621349016897
Validation loss: 3.1384118468098166

Epoch: 6| Step: 8
Training loss: 3.8766210303295017
Validation loss: 3.1388700452417964

Epoch: 6| Step: 9
Training loss: 3.979361817266342
Validation loss: 3.1371160160698484

Epoch: 6| Step: 10
Training loss: 3.3400970184489203
Validation loss: 3.138680415360727

Epoch: 6| Step: 11
Training loss: 2.8107652188358743
Validation loss: 3.137731114423683

Epoch: 6| Step: 12
Training loss: 2.925221693978653
Validation loss: 3.1364595047631174

Epoch: 6| Step: 13
Training loss: 3.0441097916341566
Validation loss: 3.136693258305428

Epoch: 59| Step: 0
Training loss: 3.44749800031243
Validation loss: 3.1350980893963953

Epoch: 6| Step: 1
Training loss: 3.1544516699633816
Validation loss: 3.1362528428835508

Epoch: 6| Step: 2
Training loss: 3.612195782903169
Validation loss: 3.1359436248628416

Epoch: 6| Step: 3
Training loss: 2.5454900989898146
Validation loss: 3.136216372591975

Epoch: 6| Step: 4
Training loss: 3.7280440674252433
Validation loss: 3.136501723971851

Epoch: 6| Step: 5
Training loss: 2.8338097190537885
Validation loss: 3.133960249210657

Epoch: 6| Step: 6
Training loss: 3.6591331656119923
Validation loss: 3.134250153369527

Epoch: 6| Step: 7
Training loss: 3.9712456493455917
Validation loss: 3.1342799738245275

Epoch: 6| Step: 8
Training loss: 3.3576635925022384
Validation loss: 3.1342800229006915

Epoch: 6| Step: 9
Training loss: 3.1235164935765156
Validation loss: 3.133415229039549

Epoch: 6| Step: 10
Training loss: 3.7543373455803017
Validation loss: 3.1315015696742416

Epoch: 6| Step: 11
Training loss: 3.613217244998992
Validation loss: 3.1319460485516855

Epoch: 6| Step: 12
Training loss: 3.632844001879545
Validation loss: 3.1318641765513697

Epoch: 6| Step: 13
Training loss: 1.8510129732803595
Validation loss: 3.133151595581803

Epoch: 60| Step: 0
Training loss: 3.581629606835967
Validation loss: 3.129846261429381

Epoch: 6| Step: 1
Training loss: 3.215405254066115
Validation loss: 3.134149498854964

Epoch: 6| Step: 2
Training loss: 2.623986275526534
Validation loss: 3.1306891848099556

Epoch: 6| Step: 3
Training loss: 4.1223334739275606
Validation loss: 3.133718063540127

Epoch: 6| Step: 4
Training loss: 3.973236071678427
Validation loss: 3.134501462267706

Epoch: 6| Step: 5
Training loss: 3.209636043937988
Validation loss: 3.133349205959579

Epoch: 6| Step: 6
Training loss: 3.665563475213642
Validation loss: 3.1334157722989353

Epoch: 6| Step: 7
Training loss: 3.607630188219293
Validation loss: 3.128536679242045

Epoch: 6| Step: 8
Training loss: 3.047384679175495
Validation loss: 3.127692044625259

Epoch: 6| Step: 9
Training loss: 3.8088135954176954
Validation loss: 3.1267239530442974

Epoch: 6| Step: 10
Training loss: 3.3554917713303696
Validation loss: 3.1280499823020222

Epoch: 6| Step: 11
Training loss: 2.313257351139583
Validation loss: 3.1272142223936332

Epoch: 6| Step: 12
Training loss: 3.1008650526437025
Validation loss: 3.1283590299565462

Epoch: 6| Step: 13
Training loss: 3.1467324460422588
Validation loss: 3.1262147720437676

Epoch: 61| Step: 0
Training loss: 2.994029143187138
Validation loss: 3.125147140484411

Epoch: 6| Step: 1
Training loss: 3.573202019836067
Validation loss: 3.1241218932892054

Epoch: 6| Step: 2
Training loss: 2.79978101418968
Validation loss: 3.1227176280842146

Epoch: 6| Step: 3
Training loss: 3.4893336572099107
Validation loss: 3.1236191953776657

Epoch: 6| Step: 4
Training loss: 2.9650632754388155
Validation loss: 3.1257050791429877

Epoch: 6| Step: 5
Training loss: 3.6496546020122587
Validation loss: 3.1266058965073347

Epoch: 6| Step: 6
Training loss: 2.3805603390317573
Validation loss: 3.1243568513321622

Epoch: 6| Step: 7
Training loss: 2.954618691823821
Validation loss: 3.1241285950861672

Epoch: 6| Step: 8
Training loss: 4.136686474437357
Validation loss: 3.1198455139199246

Epoch: 6| Step: 9
Training loss: 3.4728995582297992
Validation loss: 3.1235313147285275

Epoch: 6| Step: 10
Training loss: 3.712891652419637
Validation loss: 3.1196362377287565

Epoch: 6| Step: 11
Training loss: 4.074105455939166
Validation loss: 3.1216329635287203

Epoch: 6| Step: 12
Training loss: 3.006980087229564
Validation loss: 3.1204249126777834

Epoch: 6| Step: 13
Training loss: 3.7530566156082616
Validation loss: 3.120905593050197

Epoch: 62| Step: 0
Training loss: 4.195958490913691
Validation loss: 3.1207045002144476

Epoch: 6| Step: 1
Training loss: 3.323710921661432
Validation loss: 3.118980017129945

Epoch: 6| Step: 2
Training loss: 3.469628712471233
Validation loss: 3.1191446523371784

Epoch: 6| Step: 3
Training loss: 3.3336305167917684
Validation loss: 3.1191436611195718

Epoch: 6| Step: 4
Training loss: 3.3298189392354085
Validation loss: 3.117047979724867

Epoch: 6| Step: 5
Training loss: 3.8913876195897004
Validation loss: 3.118695514661782

Epoch: 6| Step: 6
Training loss: 4.024617734965354
Validation loss: 3.1179001154734256

Epoch: 6| Step: 7
Training loss: 3.1686362281855303
Validation loss: 3.1174630005240798

Epoch: 6| Step: 8
Training loss: 3.68085398073964
Validation loss: 3.1182586690614555

Epoch: 6| Step: 9
Training loss: 2.9324934479493088
Validation loss: 3.1181793612806166

Epoch: 6| Step: 10
Training loss: 3.1281673401854837
Validation loss: 3.115392261276396

Epoch: 6| Step: 11
Training loss: 2.2203999147113116
Validation loss: 3.115223382192427

Epoch: 6| Step: 12
Training loss: 3.2301826765527313
Validation loss: 3.115947416583367

Epoch: 6| Step: 13
Training loss: 2.324557239663853
Validation loss: 3.1158658013451603

Epoch: 63| Step: 0
Training loss: 2.6929146093067224
Validation loss: 3.1153555895689173

Epoch: 6| Step: 1
Training loss: 3.559614920630982
Validation loss: 3.1145673018783135

Epoch: 6| Step: 2
Training loss: 2.6567315057893524
Validation loss: 3.1147288303108933

Epoch: 6| Step: 3
Training loss: 3.2469375560267273
Validation loss: 3.1141627888588115

Epoch: 6| Step: 4
Training loss: 2.6668533518135837
Validation loss: 3.1189581154159742

Epoch: 6| Step: 5
Training loss: 3.549185920108385
Validation loss: 3.120252007300389

Epoch: 6| Step: 6
Training loss: 3.400230478440918
Validation loss: 3.132798804579844

Epoch: 6| Step: 7
Training loss: 4.548693945262312
Validation loss: 3.1248698193086497

Epoch: 6| Step: 8
Training loss: 3.264467755292093
Validation loss: 3.1124715817676214

Epoch: 6| Step: 9
Training loss: 3.1953695054320583
Validation loss: 3.111530055335373

Epoch: 6| Step: 10
Training loss: 3.4298675420336564
Validation loss: 3.108146766648456

Epoch: 6| Step: 11
Training loss: 3.3697522655858396
Validation loss: 3.1076054300380846

Epoch: 6| Step: 12
Training loss: 3.6893661432226166
Validation loss: 3.108026926396248

Epoch: 6| Step: 13
Training loss: 3.500994404809834
Validation loss: 3.1047075016151497

Epoch: 64| Step: 0
Training loss: 4.045473069488541
Validation loss: 3.106138463812691

Epoch: 6| Step: 1
Training loss: 2.997958124195318
Validation loss: 3.121530420586928

Epoch: 6| Step: 2
Training loss: 2.623218476795624
Validation loss: 3.125640810001552

Epoch: 6| Step: 3
Training loss: 3.7913563500042153
Validation loss: 3.1254120151081106

Epoch: 6| Step: 4
Training loss: 3.151199984185712
Validation loss: 3.1052001027910587

Epoch: 6| Step: 5
Training loss: 2.858614794457417
Validation loss: 3.0964534793306453

Epoch: 6| Step: 6
Training loss: 3.816958337713848
Validation loss: 3.0984055802813857

Epoch: 6| Step: 7
Training loss: 3.2001248335331094
Validation loss: 3.1091723046988666

Epoch: 6| Step: 8
Training loss: 3.641953778387855
Validation loss: 3.119812810920914

Epoch: 6| Step: 9
Training loss: 3.3111411132420434
Validation loss: 3.1168042890920784

Epoch: 6| Step: 10
Training loss: 3.405583587691529
Validation loss: 3.1056180326171874

Epoch: 6| Step: 11
Training loss: 3.4630294229798033
Validation loss: 3.097561881552073

Epoch: 6| Step: 12
Training loss: 3.3130439455645164
Validation loss: 3.0949178981147534

Epoch: 6| Step: 13
Training loss: 3.3145995773662267
Validation loss: 3.095951782190042

Epoch: 65| Step: 0
Training loss: 3.5384239311197296
Validation loss: 3.0945048989271706

Epoch: 6| Step: 1
Training loss: 3.6981859709055778
Validation loss: 3.0974961759962825

Epoch: 6| Step: 2
Training loss: 3.0312278196172233
Validation loss: 3.08898518252306

Epoch: 6| Step: 3
Training loss: 3.3983171112835797
Validation loss: 3.0854313344035496

Epoch: 6| Step: 4
Training loss: 2.8187511909296266
Validation loss: 3.0824387945290033

Epoch: 6| Step: 5
Training loss: 2.9268757666212726
Validation loss: 3.086675001009261

Epoch: 6| Step: 6
Training loss: 3.187032179067635
Validation loss: 3.084895706496009

Epoch: 6| Step: 7
Training loss: 3.535498165224549
Validation loss: 3.0845674779222994

Epoch: 6| Step: 8
Training loss: 3.7020164150243007
Validation loss: 3.085462002240666

Epoch: 6| Step: 9
Training loss: 3.5502760121676795
Validation loss: 3.0818915872319654

Epoch: 6| Step: 10
Training loss: 2.63598776397991
Validation loss: 3.084273578809757

Epoch: 6| Step: 11
Training loss: 3.563523797945021
Validation loss: 3.090610459481362

Epoch: 6| Step: 12
Training loss: 3.3364057368621696
Validation loss: 3.0905381218430357

Epoch: 6| Step: 13
Training loss: 4.03974315582249
Validation loss: 3.0891580337910174

Epoch: 66| Step: 0
Training loss: 3.6973566768536172
Validation loss: 3.0845388723582574

Epoch: 6| Step: 1
Training loss: 2.597719762498938
Validation loss: 3.0799533604061926

Epoch: 6| Step: 2
Training loss: 3.5009329778493425
Validation loss: 3.081111294089383

Epoch: 6| Step: 3
Training loss: 3.7908841817356405
Validation loss: 3.0813735136761795

Epoch: 6| Step: 4
Training loss: 2.8771162122817717
Validation loss: 3.0838326252501522

Epoch: 6| Step: 5
Training loss: 3.926681187661679
Validation loss: 3.081486674167915

Epoch: 6| Step: 6
Training loss: 3.205674510565286
Validation loss: 3.0839660436583203

Epoch: 6| Step: 7
Training loss: 3.442006434432936
Validation loss: 3.0813131629317145

Epoch: 6| Step: 8
Training loss: 3.2615009166594016
Validation loss: 3.0787195797747833

Epoch: 6| Step: 9
Training loss: 3.809838914044051
Validation loss: 3.0809393809739767

Epoch: 6| Step: 10
Training loss: 2.1860171060198224
Validation loss: 3.0805890307128463

Epoch: 6| Step: 11
Training loss: 3.4530384173693482
Validation loss: 3.0752802754016666

Epoch: 6| Step: 12
Training loss: 3.6699743668079403
Validation loss: 3.0780020743865086

Epoch: 6| Step: 13
Training loss: 2.5861137767996083
Validation loss: 3.0772455513546344

Epoch: 67| Step: 0
Training loss: 3.3877759645109022
Validation loss: 3.0792230330304977

Epoch: 6| Step: 1
Training loss: 3.800886632981487
Validation loss: 3.0766860941004883

Epoch: 6| Step: 2
Training loss: 2.15165353220923
Validation loss: 3.074855746735611

Epoch: 6| Step: 3
Training loss: 3.7588330824016944
Validation loss: 3.0769089055484367

Epoch: 6| Step: 4
Training loss: 3.0868017604038367
Validation loss: 3.0721757955442293

Epoch: 6| Step: 5
Training loss: 3.6723853223332212
Validation loss: 3.0747084482650884

Epoch: 6| Step: 6
Training loss: 4.01821780084703
Validation loss: 3.071576922680321

Epoch: 6| Step: 7
Training loss: 3.258431574778677
Validation loss: 3.0738742549508387

Epoch: 6| Step: 8
Training loss: 2.798389301918
Validation loss: 3.0720479102502676

Epoch: 6| Step: 9
Training loss: 2.8927175834671788
Validation loss: 3.072347656650176

Epoch: 6| Step: 10
Training loss: 3.6592361124135735
Validation loss: 3.069603784826877

Epoch: 6| Step: 11
Training loss: 3.5361669286448016
Validation loss: 3.069679047743765

Epoch: 6| Step: 12
Training loss: 3.150597373388752
Validation loss: 3.0709820602594546

Epoch: 6| Step: 13
Training loss: 2.8084072427805924
Validation loss: 3.071834930407952

Epoch: 68| Step: 0
Training loss: 2.4384997347279556
Validation loss: 3.076575516019435

Epoch: 6| Step: 1
Training loss: 3.588333958048278
Validation loss: 3.07409889223226

Epoch: 6| Step: 2
Training loss: 3.287397166917414
Validation loss: 3.0773312157469213

Epoch: 6| Step: 3
Training loss: 2.9823587207315514
Validation loss: 3.0878620219932986

Epoch: 6| Step: 4
Training loss: 3.8856286748703366
Validation loss: 3.069534915945717

Epoch: 6| Step: 5
Training loss: 3.799944857147061
Validation loss: 3.070302847649521

Epoch: 6| Step: 6
Training loss: 2.9734296356594303
Validation loss: 3.0669511764275166

Epoch: 6| Step: 7
Training loss: 3.229188012493503
Validation loss: 3.0661749581230637

Epoch: 6| Step: 8
Training loss: 3.725020563465682
Validation loss: 3.068468394402497

Epoch: 6| Step: 9
Training loss: 3.946818149426025
Validation loss: 3.0658504916990066

Epoch: 6| Step: 10
Training loss: 2.7935042714853915
Validation loss: 3.064076709006851

Epoch: 6| Step: 11
Training loss: 3.7255470283846326
Validation loss: 3.066359323090652

Epoch: 6| Step: 12
Training loss: 2.7323839186349157
Validation loss: 3.0641396816448165

Epoch: 6| Step: 13
Training loss: 2.8247929117373647
Validation loss: 3.063853756758253

Epoch: 69| Step: 0
Training loss: 3.1180008900208636
Validation loss: 3.068426455580951

Epoch: 6| Step: 1
Training loss: 3.2556888968190885
Validation loss: 3.064144860560849

Epoch: 6| Step: 2
Training loss: 2.785218568508625
Validation loss: 3.0642098581410586

Epoch: 6| Step: 3
Training loss: 3.728184377064746
Validation loss: 3.0627644692350158

Epoch: 6| Step: 4
Training loss: 3.7857564759281255
Validation loss: 3.0641564649822786

Epoch: 6| Step: 5
Training loss: 2.8634121436870132
Validation loss: 3.065787393649614

Epoch: 6| Step: 6
Training loss: 3.173831881007393
Validation loss: 3.0704108487078074

Epoch: 6| Step: 7
Training loss: 3.1424488446450387
Validation loss: 3.0736236048307686

Epoch: 6| Step: 8
Training loss: 3.6822972205451547
Validation loss: 3.08292661582405

Epoch: 6| Step: 9
Training loss: 3.1600667707414716
Validation loss: 3.0634231448444607

Epoch: 6| Step: 10
Training loss: 3.622199588216055
Validation loss: 3.05880854020905

Epoch: 6| Step: 11
Training loss: 3.3202985695939393
Validation loss: 3.060184741217238

Epoch: 6| Step: 12
Training loss: 3.6380694019058373
Validation loss: 3.063421640179001

Epoch: 6| Step: 13
Training loss: 2.926204635483579
Validation loss: 3.060611689326572

Epoch: 70| Step: 0
Training loss: 3.3788654655685275
Validation loss: 3.063831799020068

Epoch: 6| Step: 1
Training loss: 3.6683202540574515
Validation loss: 3.064721860818044

Epoch: 6| Step: 2
Training loss: 3.217180480504727
Validation loss: 3.0618083902040425

Epoch: 6| Step: 3
Training loss: 3.0207326061073494
Validation loss: 3.059904426278132

Epoch: 6| Step: 4
Training loss: 3.184809428072526
Validation loss: 3.062104010999117

Epoch: 6| Step: 5
Training loss: 3.1206648702612894
Validation loss: 3.0676228960729723

Epoch: 6| Step: 6
Training loss: 3.1000770067064085
Validation loss: 3.070768695092628

Epoch: 6| Step: 7
Training loss: 3.1932945688187098
Validation loss: 3.0704156467462873

Epoch: 6| Step: 8
Training loss: 4.074776045373081
Validation loss: 3.0665279149272178

Epoch: 6| Step: 9
Training loss: 2.8537963478445167
Validation loss: 3.07084722287174

Epoch: 6| Step: 10
Training loss: 4.012204386912312
Validation loss: 3.068839672972124

Epoch: 6| Step: 11
Training loss: 3.3121108780236743
Validation loss: 3.060079827502982

Epoch: 6| Step: 12
Training loss: 3.571646476637511
Validation loss: 3.052067718639509

Epoch: 6| Step: 13
Training loss: 1.9916203308567888
Validation loss: 3.05293219675047

Epoch: 71| Step: 0
Training loss: 3.3852152759609853
Validation loss: 3.055106092460724

Epoch: 6| Step: 1
Training loss: 3.3402032312933856
Validation loss: 3.0614806582670946

Epoch: 6| Step: 2
Training loss: 3.116701934397317
Validation loss: 3.0650843685535785

Epoch: 6| Step: 3
Training loss: 3.873768518483008
Validation loss: 3.0597478233397433

Epoch: 6| Step: 4
Training loss: 3.142367358871815
Validation loss: 3.0590610160060283

Epoch: 6| Step: 5
Training loss: 3.276039127577307
Validation loss: 3.0579132864131204

Epoch: 6| Step: 6
Training loss: 3.93518240402888
Validation loss: 3.0567573941007993

Epoch: 6| Step: 7
Training loss: 3.018083430083135
Validation loss: 3.0538326649624117

Epoch: 6| Step: 8
Training loss: 3.499845637595966
Validation loss: 3.0572170114218227

Epoch: 6| Step: 9
Training loss: 3.7246685213414725
Validation loss: 3.0617138672104005

Epoch: 6| Step: 10
Training loss: 3.3672200708075235
Validation loss: 3.050373763770557

Epoch: 6| Step: 11
Training loss: 2.3852910393252134
Validation loss: 3.051315293857261

Epoch: 6| Step: 12
Training loss: 2.721433170516394
Validation loss: 3.0496721367512665

Epoch: 6| Step: 13
Training loss: 3.5147572442521473
Validation loss: 3.050849134711358

Epoch: 72| Step: 0
Training loss: 3.104693852318772
Validation loss: 3.052128472113916

Epoch: 6| Step: 1
Training loss: 2.788960259965179
Validation loss: 3.0559942830739413

Epoch: 6| Step: 2
Training loss: 3.1938183562546296
Validation loss: 3.057149546516638

Epoch: 6| Step: 3
Training loss: 3.0954378706350925
Validation loss: 3.054327384275606

Epoch: 6| Step: 4
Training loss: 3.4945156179786743
Validation loss: 3.0512268674555445

Epoch: 6| Step: 5
Training loss: 3.9514718802164848
Validation loss: 3.0523265481467483

Epoch: 6| Step: 6
Training loss: 3.5532953575447705
Validation loss: 3.0551892317975464

Epoch: 6| Step: 7
Training loss: 3.300109144775615
Validation loss: 3.0554378408228473

Epoch: 6| Step: 8
Training loss: 2.2293205445795854
Validation loss: 3.0588600236509245

Epoch: 6| Step: 9
Training loss: 3.7415694520777882
Validation loss: 3.0622755030739794

Epoch: 6| Step: 10
Training loss: 3.051662967276158
Validation loss: 3.0574414060266255

Epoch: 6| Step: 11
Training loss: 3.9792397111243334
Validation loss: 3.0572778017678934

Epoch: 6| Step: 12
Training loss: 3.1851169429371895
Validation loss: 3.055946136326134

Epoch: 6| Step: 13
Training loss: 3.500505410896242
Validation loss: 3.0504974766440918

Epoch: 73| Step: 0
Training loss: 3.3635962645556345
Validation loss: 3.0505535090149514

Epoch: 6| Step: 1
Training loss: 3.0835919314703593
Validation loss: 3.047611311045362

Epoch: 6| Step: 2
Training loss: 3.3977760109634523
Validation loss: 3.0462581274048297

Epoch: 6| Step: 3
Training loss: 3.1216705896855634
Validation loss: 3.045633643414016

Epoch: 6| Step: 4
Training loss: 3.6641312127085888
Validation loss: 3.043946991865919

Epoch: 6| Step: 5
Training loss: 3.217149651459007
Validation loss: 3.044057142434585

Epoch: 6| Step: 6
Training loss: 4.077715272161644
Validation loss: 3.0441396697930734

Epoch: 6| Step: 7
Training loss: 3.309889718607075
Validation loss: 3.045288260066519

Epoch: 6| Step: 8
Training loss: 3.143527535365419
Validation loss: 3.0448726531229267

Epoch: 6| Step: 9
Training loss: 2.9310400523660913
Validation loss: 3.044940651881481

Epoch: 6| Step: 10
Training loss: 3.4239732414519115
Validation loss: 3.0442747924164757

Epoch: 6| Step: 11
Training loss: 3.0171264705481318
Validation loss: 3.041498067995488

Epoch: 6| Step: 12
Training loss: 3.2236998191971895
Validation loss: 3.04346401554507

Epoch: 6| Step: 13
Training loss: 3.2605764981582315
Validation loss: 3.0413770050292115

Epoch: 74| Step: 0
Training loss: 3.5689996688812693
Validation loss: 3.0432024534319027

Epoch: 6| Step: 1
Training loss: 3.9889284929477724
Validation loss: 3.0399280292738204

Epoch: 6| Step: 2
Training loss: 2.7807762514024335
Validation loss: 3.0393631242306314

Epoch: 6| Step: 3
Training loss: 3.55951980952685
Validation loss: 3.03949845245054

Epoch: 6| Step: 4
Training loss: 2.5012110637816027
Validation loss: 3.0404271713040045

Epoch: 6| Step: 5
Training loss: 3.1912383055183176
Validation loss: 3.0378346873091617

Epoch: 6| Step: 6
Training loss: 2.8264579285466964
Validation loss: 3.037156639473898

Epoch: 6| Step: 7
Training loss: 3.0365059501530607
Validation loss: 3.0368422595833295

Epoch: 6| Step: 8
Training loss: 2.7132911688537926
Validation loss: 3.036395736727646

Epoch: 6| Step: 9
Training loss: 3.143875337987832
Validation loss: 3.036898080454006

Epoch: 6| Step: 10
Training loss: 2.9857328032351544
Validation loss: 3.034688167059146

Epoch: 6| Step: 11
Training loss: 3.708654211213228
Validation loss: 3.035729972362447

Epoch: 6| Step: 12
Training loss: 4.195061986963112
Validation loss: 3.035028431695988

Epoch: 6| Step: 13
Training loss: 3.831048215247528
Validation loss: 3.03905285046769

Epoch: 75| Step: 0
Training loss: 3.575187310066843
Validation loss: 3.0326182604592504

Epoch: 6| Step: 1
Training loss: 3.206718104287655
Validation loss: 3.0344715495614887

Epoch: 6| Step: 2
Training loss: 2.8436493908198592
Validation loss: 3.0344077280445236

Epoch: 6| Step: 3
Training loss: 3.5252220895483517
Validation loss: 3.0360542067412237

Epoch: 6| Step: 4
Training loss: 2.8927228583599778
Validation loss: 3.033107848330028

Epoch: 6| Step: 5
Training loss: 3.5351167286723864
Validation loss: 3.0374200684228345

Epoch: 6| Step: 6
Training loss: 3.7137015559305513
Validation loss: 3.041469278194536

Epoch: 6| Step: 7
Training loss: 3.128554497042811
Validation loss: 3.040794620648279

Epoch: 6| Step: 8
Training loss: 2.984152740670437
Validation loss: 3.048570967092025

Epoch: 6| Step: 9
Training loss: 3.1770050205939095
Validation loss: 3.0379796631695846

Epoch: 6| Step: 10
Training loss: 3.1568486618486986
Validation loss: 3.032656168500631

Epoch: 6| Step: 11
Training loss: 3.0713205793792286
Validation loss: 3.0343147585550954

Epoch: 6| Step: 12
Training loss: 4.02952408623801
Validation loss: 3.034164649567577

Epoch: 6| Step: 13
Training loss: 3.0914968898115287
Validation loss: 3.030670272114809

Epoch: 76| Step: 0
Training loss: 3.173990530700596
Validation loss: 3.029605342770663

Epoch: 6| Step: 1
Training loss: 3.1803052897229604
Validation loss: 3.028174242631199

Epoch: 6| Step: 2
Training loss: 3.2609124014984796
Validation loss: 3.029548283221187

Epoch: 6| Step: 3
Training loss: 3.9103718487639343
Validation loss: 3.030228180720679

Epoch: 6| Step: 4
Training loss: 3.348053916360289
Validation loss: 3.0331450943706897

Epoch: 6| Step: 5
Training loss: 3.383460848304842
Validation loss: 3.039604506683527

Epoch: 6| Step: 6
Training loss: 3.9235306242992998
Validation loss: 3.0368287611196747

Epoch: 6| Step: 7
Training loss: 3.0486008671207316
Validation loss: 3.0363151164591566

Epoch: 6| Step: 8
Training loss: 2.967704829897586
Validation loss: 3.032777167075005

Epoch: 6| Step: 9
Training loss: 2.7394924559707774
Validation loss: 3.0308979956139974

Epoch: 6| Step: 10
Training loss: 3.283938804864774
Validation loss: 3.0284040288903906

Epoch: 6| Step: 11
Training loss: 3.3751675599500626
Validation loss: 3.0273013100508983

Epoch: 6| Step: 12
Training loss: 3.1681398846443503
Validation loss: 3.0253371924448462

Epoch: 6| Step: 13
Training loss: 3.3500506496870686
Validation loss: 3.023812906244519

Epoch: 77| Step: 0
Training loss: 2.664056503870864
Validation loss: 3.0256142898595293

Epoch: 6| Step: 1
Training loss: 2.9849496657634136
Validation loss: 3.028836181376596

Epoch: 6| Step: 2
Training loss: 2.7648465197771075
Validation loss: 3.027895064683703

Epoch: 6| Step: 3
Training loss: 3.0479965884372313
Validation loss: 3.037128070190403

Epoch: 6| Step: 4
Training loss: 2.1297534062017665
Validation loss: 3.0406959042058204

Epoch: 6| Step: 5
Training loss: 3.3863953256666264
Validation loss: 3.0375967527802126

Epoch: 6| Step: 6
Training loss: 3.316408981843324
Validation loss: 3.036219055939176

Epoch: 6| Step: 7
Training loss: 3.669333759505595
Validation loss: 3.0257118063244133

Epoch: 6| Step: 8
Training loss: 3.6344024788366283
Validation loss: 3.026570517255197

Epoch: 6| Step: 9
Training loss: 2.991347869917075
Validation loss: 3.021170359231371

Epoch: 6| Step: 10
Training loss: 3.290646133282536
Validation loss: 3.020447924465352

Epoch: 6| Step: 11
Training loss: 4.275856351689472
Validation loss: 3.0222418455055458

Epoch: 6| Step: 12
Training loss: 3.659737122272334
Validation loss: 3.0221961817392637

Epoch: 6| Step: 13
Training loss: 4.104007595226257
Validation loss: 3.023759413592029

Epoch: 78| Step: 0
Training loss: 3.066184182842778
Validation loss: 3.0262613419921967

Epoch: 6| Step: 1
Training loss: 3.2553924427102006
Validation loss: 3.0258735055243524

Epoch: 6| Step: 2
Training loss: 3.540299424692704
Validation loss: 3.0243368102018398

Epoch: 6| Step: 3
Training loss: 3.1511119151626277
Validation loss: 3.024510833612824

Epoch: 6| Step: 4
Training loss: 3.2079800167650463
Validation loss: 3.0230282343839825

Epoch: 6| Step: 5
Training loss: 2.9301531205511235
Validation loss: 3.0207659879708673

Epoch: 6| Step: 6
Training loss: 3.4847599381416576
Validation loss: 3.0201062216696335

Epoch: 6| Step: 7
Training loss: 3.8122182022760893
Validation loss: 3.0173548517227897

Epoch: 6| Step: 8
Training loss: 2.8188537037247836
Validation loss: 3.017969714339651

Epoch: 6| Step: 9
Training loss: 2.6016710046817146
Validation loss: 3.016438581820213

Epoch: 6| Step: 10
Training loss: 3.1395972548802438
Validation loss: 3.01579596432119

Epoch: 6| Step: 11
Training loss: 3.6427598186923724
Validation loss: 3.0148771101294227

Epoch: 6| Step: 12
Training loss: 3.1499422703857123
Validation loss: 3.015428917038

Epoch: 6| Step: 13
Training loss: 4.582272678528704
Validation loss: 3.0142961443699927

Epoch: 79| Step: 0
Training loss: 2.6209835933272223
Validation loss: 3.012568398057736

Epoch: 6| Step: 1
Training loss: 2.608637539935033
Validation loss: 3.011224604152156

Epoch: 6| Step: 2
Training loss: 3.2525047040666344
Validation loss: 3.0122305121352455

Epoch: 6| Step: 3
Training loss: 3.66647708287107
Validation loss: 3.0104651356550134

Epoch: 6| Step: 4
Training loss: 3.2038001860796843
Validation loss: 3.010893447192443

Epoch: 6| Step: 5
Training loss: 3.485886592313734
Validation loss: 3.012030471717999

Epoch: 6| Step: 6
Training loss: 3.466715310440149
Validation loss: 3.0118024477734884

Epoch: 6| Step: 7
Training loss: 3.676452380864554
Validation loss: 3.0113725722500524

Epoch: 6| Step: 8
Training loss: 3.684428859637341
Validation loss: 3.0078969695609414

Epoch: 6| Step: 9
Training loss: 3.183893294956958
Validation loss: 3.0099163026353946

Epoch: 6| Step: 10
Training loss: 3.54068030291444
Validation loss: 3.008764838602893

Epoch: 6| Step: 11
Training loss: 2.9550900657599133
Validation loss: 3.0104937186764267

Epoch: 6| Step: 12
Training loss: 3.0817699249061654
Validation loss: 3.0072442014221985

Epoch: 6| Step: 13
Training loss: 3.3420519929285213
Validation loss: 3.007845149923762

Epoch: 80| Step: 0
Training loss: 3.2161997349143725
Validation loss: 3.006269847173393

Epoch: 6| Step: 1
Training loss: 3.564995811641849
Validation loss: 3.0064766235496023

Epoch: 6| Step: 2
Training loss: 3.1242387988932223
Validation loss: 3.005949818267939

Epoch: 6| Step: 3
Training loss: 3.26918412602495
Validation loss: 3.0157051175672174

Epoch: 6| Step: 4
Training loss: 3.18660080138043
Validation loss: 3.0207246777120327

Epoch: 6| Step: 5
Training loss: 3.100630074735063
Validation loss: 3.023255213216757

Epoch: 6| Step: 6
Training loss: 3.144825266485576
Validation loss: 3.004176616482974

Epoch: 6| Step: 7
Training loss: 3.5463732393920653
Validation loss: 3.0045544685431653

Epoch: 6| Step: 8
Training loss: 3.461299007643301
Validation loss: 3.003814133012407

Epoch: 6| Step: 9
Training loss: 3.543749806237594
Validation loss: 3.0047537268803923

Epoch: 6| Step: 10
Training loss: 3.965751055554464
Validation loss: 3.004096491847423

Epoch: 6| Step: 11
Training loss: 2.727444044425552
Validation loss: 3.0109483110545705

Epoch: 6| Step: 12
Training loss: 2.645518717245198
Validation loss: 3.004927278780263

Epoch: 6| Step: 13
Training loss: 3.282316343423971
Validation loss: 3.0052658552982146

Epoch: 81| Step: 0
Training loss: 3.2200652463000945
Validation loss: 3.00318598174691

Epoch: 6| Step: 1
Training loss: 3.8254577063676978
Validation loss: 3.0036479756189736

Epoch: 6| Step: 2
Training loss: 3.236329451050196
Validation loss: 3.002519161703562

Epoch: 6| Step: 3
Training loss: 2.5421062360364504
Validation loss: 3.0002118107665674

Epoch: 6| Step: 4
Training loss: 4.057896749733061
Validation loss: 3.001961746879693

Epoch: 6| Step: 5
Training loss: 2.5808730766956938
Validation loss: 3.000210158189127

Epoch: 6| Step: 6
Training loss: 2.5052037440606245
Validation loss: 3.0032692497909697

Epoch: 6| Step: 7
Training loss: 3.719825140422246
Validation loss: 2.999408625181856

Epoch: 6| Step: 8
Training loss: 3.5902359740928467
Validation loss: 3.0050910919302076

Epoch: 6| Step: 9
Training loss: 2.2232314506914266
Validation loss: 3.0067874137041697

Epoch: 6| Step: 10
Training loss: 3.761875676162793
Validation loss: 3.031179435948066

Epoch: 6| Step: 11
Training loss: 3.408777261813141
Validation loss: 3.0248853896513266

Epoch: 6| Step: 12
Training loss: 2.9855469005544286
Validation loss: 3.00360597329299

Epoch: 6| Step: 13
Training loss: 3.79779380701456
Validation loss: 3.0015639258717606

Epoch: 82| Step: 0
Training loss: 4.015955098756037
Validation loss: 2.9954312137155945

Epoch: 6| Step: 1
Training loss: 3.943899131893313
Validation loss: 2.9975275546871876

Epoch: 6| Step: 2
Training loss: 2.597673137868037
Validation loss: 2.9986009275079852

Epoch: 6| Step: 3
Training loss: 1.8870259858178247
Validation loss: 2.9991099838775304

Epoch: 6| Step: 4
Training loss: 3.300608324566068
Validation loss: 3.0017184493771847

Epoch: 6| Step: 5
Training loss: 3.3752206800863003
Validation loss: 3.0010225457284676

Epoch: 6| Step: 6
Training loss: 3.531435936277719
Validation loss: 3.004966558202396

Epoch: 6| Step: 7
Training loss: 3.2388872746034076
Validation loss: 3.0048989832184243

Epoch: 6| Step: 8
Training loss: 3.209245890515561
Validation loss: 3.001980602885275

Epoch: 6| Step: 9
Training loss: 3.0038597391047333
Validation loss: 3.0036941296180557

Epoch: 6| Step: 10
Training loss: 3.0539182977446067
Validation loss: 2.999313691298698

Epoch: 6| Step: 11
Training loss: 3.672960486162376
Validation loss: 2.999751145627564

Epoch: 6| Step: 12
Training loss: 2.8362808229899152
Validation loss: 2.9964881033454067

Epoch: 6| Step: 13
Training loss: 3.890891927731498
Validation loss: 2.995629489689815

Epoch: 83| Step: 0
Training loss: 3.2677586352281147
Validation loss: 2.9954373176335545

Epoch: 6| Step: 1
Training loss: 2.5851664243505397
Validation loss: 2.994746979981497

Epoch: 6| Step: 2
Training loss: 3.0727786965296864
Validation loss: 2.993301364631042

Epoch: 6| Step: 3
Training loss: 3.729653665862979
Validation loss: 2.9929775181579514

Epoch: 6| Step: 4
Training loss: 2.9629891164826323
Validation loss: 2.988673687706955

Epoch: 6| Step: 5
Training loss: 3.5757020967810385
Validation loss: 2.990966611199696

Epoch: 6| Step: 6
Training loss: 2.8773976155484435
Validation loss: 2.9930343155767543

Epoch: 6| Step: 7
Training loss: 3.440783233191609
Validation loss: 2.997753744841972

Epoch: 6| Step: 8
Training loss: 4.0377820935037025
Validation loss: 3.0044808985907956

Epoch: 6| Step: 9
Training loss: 3.4116449591376696
Validation loss: 3.009047185280478

Epoch: 6| Step: 10
Training loss: 3.004247202082529
Validation loss: 2.994549032532586

Epoch: 6| Step: 11
Training loss: 2.621047268269159
Validation loss: 2.987485931015989

Epoch: 6| Step: 12
Training loss: 3.44299930760634
Validation loss: 2.9890860335848406

Epoch: 6| Step: 13
Training loss: 3.5297940383780384
Validation loss: 2.9912506310111184

Epoch: 84| Step: 0
Training loss: 3.5204819423026588
Validation loss: 2.988754523451464

Epoch: 6| Step: 1
Training loss: 3.605784822870435
Validation loss: 2.9884324112434997

Epoch: 6| Step: 2
Training loss: 3.8515176828496727
Validation loss: 2.9893048679017435

Epoch: 6| Step: 3
Training loss: 3.66583443358008
Validation loss: 2.986169596012917

Epoch: 6| Step: 4
Training loss: 3.1936488962313785
Validation loss: 2.988736878373297

Epoch: 6| Step: 5
Training loss: 2.538875256016489
Validation loss: 2.989885944664954

Epoch: 6| Step: 6
Training loss: 2.7090771362880917
Validation loss: 2.9881224574322776

Epoch: 6| Step: 7
Training loss: 2.6334825336665806
Validation loss: 2.9875616288218243

Epoch: 6| Step: 8
Training loss: 3.3656670839588316
Validation loss: 2.9914272887725026

Epoch: 6| Step: 9
Training loss: 3.5088881306898756
Validation loss: 2.9882667103086

Epoch: 6| Step: 10
Training loss: 4.015400802350324
Validation loss: 2.9862099454612507

Epoch: 6| Step: 11
Training loss: 2.995534275144735
Validation loss: 2.987647597661064

Epoch: 6| Step: 12
Training loss: 2.4543751246503542
Validation loss: 2.986275713893454

Epoch: 6| Step: 13
Training loss: 3.201735478908946
Validation loss: 2.9850932466426037

Epoch: 85| Step: 0
Training loss: 3.7046147822431488
Validation loss: 2.983079982038463

Epoch: 6| Step: 1
Training loss: 2.6682194917289843
Validation loss: 2.9842316139332974

Epoch: 6| Step: 2
Training loss: 3.0303664345321444
Validation loss: 2.984577369024357

Epoch: 6| Step: 3
Training loss: 3.332832266976513
Validation loss: 2.9816772555157947

Epoch: 6| Step: 4
Training loss: 3.0297939303483954
Validation loss: 2.9799887941728858

Epoch: 6| Step: 5
Training loss: 3.9747658138746345
Validation loss: 2.984778619776682

Epoch: 6| Step: 6
Training loss: 3.3220201835593333
Validation loss: 2.9826627583907346

Epoch: 6| Step: 7
Training loss: 3.0623221832345897
Validation loss: 2.983018228793714

Epoch: 6| Step: 8
Training loss: 3.1377778314020706
Validation loss: 2.9832229954997653

Epoch: 6| Step: 9
Training loss: 3.2848235516357436
Validation loss: 2.9797151110780984

Epoch: 6| Step: 10
Training loss: 3.2063222419675688
Validation loss: 2.979975045061065

Epoch: 6| Step: 11
Training loss: 3.0037554441379672
Validation loss: 2.9807483774860994

Epoch: 6| Step: 12
Training loss: 3.152453263471029
Validation loss: 2.976583022404108

Epoch: 6| Step: 13
Training loss: 3.7582244964426517
Validation loss: 2.981098900897434

Epoch: 86| Step: 0
Training loss: 3.3570997473085167
Validation loss: 2.981306257039817

Epoch: 6| Step: 1
Training loss: 2.97079975239383
Validation loss: 2.983637249486721

Epoch: 6| Step: 2
Training loss: 2.4553790579474257
Validation loss: 2.980860899530413

Epoch: 6| Step: 3
Training loss: 3.316190571056563
Validation loss: 2.987001067399538

Epoch: 6| Step: 4
Training loss: 3.2170841387559266
Validation loss: 2.9881628680200047

Epoch: 6| Step: 5
Training loss: 2.943840812691602
Validation loss: 2.9777310784373334

Epoch: 6| Step: 6
Training loss: 3.1928962955043207
Validation loss: 2.975947590786348

Epoch: 6| Step: 7
Training loss: 3.409323888967256
Validation loss: 2.976094796636536

Epoch: 6| Step: 8
Training loss: 3.55708543990473
Validation loss: 2.9810279133835853

Epoch: 6| Step: 9
Training loss: 3.4065599213042654
Validation loss: 2.9741623906187016

Epoch: 6| Step: 10
Training loss: 3.373485366601841
Validation loss: 2.978388451400198

Epoch: 6| Step: 11
Training loss: 3.1556211543838906
Validation loss: 2.9729454149228385

Epoch: 6| Step: 12
Training loss: 4.240046570360194
Validation loss: 2.992879741159314

Epoch: 6| Step: 13
Training loss: 2.321788793429313
Validation loss: 3.021848119598836

Epoch: 87| Step: 0
Training loss: 3.4484342588021413
Validation loss: 3.0059405579493776

Epoch: 6| Step: 1
Training loss: 3.7632789743268886
Validation loss: 2.9955230929688734

Epoch: 6| Step: 2
Training loss: 2.8418087883663516
Validation loss: 2.998926789412142

Epoch: 6| Step: 3
Training loss: 3.24991607557657
Validation loss: 2.9907540085207915

Epoch: 6| Step: 4
Training loss: 3.4860652364994382
Validation loss: 2.981294518451361

Epoch: 6| Step: 5
Training loss: 2.581229635162931
Validation loss: 2.982229022065986

Epoch: 6| Step: 6
Training loss: 3.527874844301201
Validation loss: 2.983879205802669

Epoch: 6| Step: 7
Training loss: 3.5035822111435744
Validation loss: 2.9947145031390616

Epoch: 6| Step: 8
Training loss: 3.4705250640170724
Validation loss: 2.9878178290176667

Epoch: 6| Step: 9
Training loss: 3.3333565870109716
Validation loss: 2.980847084778118

Epoch: 6| Step: 10
Training loss: 3.2728029059330757
Validation loss: 2.9768807191542286

Epoch: 6| Step: 11
Training loss: 3.595144780709491
Validation loss: 2.975815807872174

Epoch: 6| Step: 12
Training loss: 2.095189524888533
Validation loss: 2.974595704444954

Epoch: 6| Step: 13
Training loss: 3.0118047204716594
Validation loss: 2.9731206821776928

Epoch: 88| Step: 0
Training loss: 2.5245811303819523
Validation loss: 2.972927663078684

Epoch: 6| Step: 1
Training loss: 3.4006870585357856
Validation loss: 2.971393263811987

Epoch: 6| Step: 2
Training loss: 3.3330823485933982
Validation loss: 2.972981402913125

Epoch: 6| Step: 3
Training loss: 3.392804267299193
Validation loss: 2.979032387099889

Epoch: 6| Step: 4
Training loss: 3.4260369339180805
Validation loss: 2.97812807162404

Epoch: 6| Step: 5
Training loss: 3.3258513085027617
Validation loss: 2.978648403899127

Epoch: 6| Step: 6
Training loss: 3.709750915350365
Validation loss: 2.9713546388977723

Epoch: 6| Step: 7
Training loss: 2.1887869182895665
Validation loss: 2.9686286128582777

Epoch: 6| Step: 8
Training loss: 3.3872811841498494
Validation loss: 2.970187698188992

Epoch: 6| Step: 9
Training loss: 3.0946658541694614
Validation loss: 2.9685064124112066

Epoch: 6| Step: 10
Training loss: 3.732249401185747
Validation loss: 2.9694565230756447

Epoch: 6| Step: 11
Training loss: 3.346514405843499
Validation loss: 2.974527507586702

Epoch: 6| Step: 12
Training loss: 2.9517491279110315
Validation loss: 2.9652074915807365

Epoch: 6| Step: 13
Training loss: 3.414863125919135
Validation loss: 2.9747278930279117

Epoch: 89| Step: 0
Training loss: 2.652544646035698
Validation loss: 2.9667178899189572

Epoch: 6| Step: 1
Training loss: 3.1446637806892968
Validation loss: 2.9718170617909063

Epoch: 6| Step: 2
Training loss: 2.5069376052194885
Validation loss: 2.975604056876547

Epoch: 6| Step: 3
Training loss: 3.110314308793776
Validation loss: 2.974600267911085

Epoch: 6| Step: 4
Training loss: 3.0865028346382544
Validation loss: 2.984683096011488

Epoch: 6| Step: 5
Training loss: 3.6387337286744903
Validation loss: 2.9843107651584613

Epoch: 6| Step: 6
Training loss: 3.12652703169303
Validation loss: 2.988661037918985

Epoch: 6| Step: 7
Training loss: 3.7850789002190943
Validation loss: 2.99554195270358

Epoch: 6| Step: 8
Training loss: 2.610246432863591
Validation loss: 2.972366008156359

Epoch: 6| Step: 9
Training loss: 3.4234907960072976
Validation loss: 2.9752394175462156

Epoch: 6| Step: 10
Training loss: 3.1504572218627427
Validation loss: 2.9627267473399987

Epoch: 6| Step: 11
Training loss: 3.418978645447693
Validation loss: 2.961452227156697

Epoch: 6| Step: 12
Training loss: 4.05419189717099
Validation loss: 2.963754115421327

Epoch: 6| Step: 13
Training loss: 3.4260749299539817
Validation loss: 2.9638726506123145

Epoch: 90| Step: 0
Training loss: 3.5518570247089913
Validation loss: 2.9672213216894554

Epoch: 6| Step: 1
Training loss: 3.357030005717785
Validation loss: 2.964924604245179

Epoch: 6| Step: 2
Training loss: 2.8134914769866746
Validation loss: 2.9666109799749925

Epoch: 6| Step: 3
Training loss: 3.2636685145946944
Validation loss: 2.9685644086371927

Epoch: 6| Step: 4
Training loss: 3.779615443009208
Validation loss: 2.9727533589324735

Epoch: 6| Step: 5
Training loss: 3.498416678744497
Validation loss: 2.964924918980043

Epoch: 6| Step: 6
Training loss: 3.342700544003289
Validation loss: 2.963582410124463

Epoch: 6| Step: 7
Training loss: 3.047386869813868
Validation loss: 2.962590944406801

Epoch: 6| Step: 8
Training loss: 3.082784621068663
Validation loss: 2.963008335576092

Epoch: 6| Step: 9
Training loss: 2.6605926021353503
Validation loss: 2.9583968092610604

Epoch: 6| Step: 10
Training loss: 3.0966336461316333
Validation loss: 2.962537917789316

Epoch: 6| Step: 11
Training loss: 3.539736382534286
Validation loss: 2.9567418136625894

Epoch: 6| Step: 12
Training loss: 3.2434885379029494
Validation loss: 2.961698311358813

Epoch: 6| Step: 13
Training loss: 2.9377864941429044
Validation loss: 2.956442123726451

Epoch: 91| Step: 0
Training loss: 3.308301460118982
Validation loss: 2.961418480547046

Epoch: 6| Step: 1
Training loss: 3.0856060381224233
Validation loss: 2.962576450835855

Epoch: 6| Step: 2
Training loss: 3.3451939967626036
Validation loss: 2.9569696168630153

Epoch: 6| Step: 3
Training loss: 2.722202695616498
Validation loss: 2.9597223294715027

Epoch: 6| Step: 4
Training loss: 3.4720727625574974
Validation loss: 2.9547508145286177

Epoch: 6| Step: 5
Training loss: 3.1309207522348603
Validation loss: 2.9577777715830256

Epoch: 6| Step: 6
Training loss: 3.863133010103012
Validation loss: 2.9562022690790792

Epoch: 6| Step: 7
Training loss: 3.1233097846067266
Validation loss: 2.959842382503755

Epoch: 6| Step: 8
Training loss: 2.9099959975801712
Validation loss: 2.9554438335600386

Epoch: 6| Step: 9
Training loss: 3.6232483676703264
Validation loss: 2.9599314542306776

Epoch: 6| Step: 10
Training loss: 2.885470026030103
Validation loss: 2.9675005059529886

Epoch: 6| Step: 11
Training loss: 3.539244792361267
Validation loss: 3.0030049575935154

Epoch: 6| Step: 12
Training loss: 3.3697961318837946
Validation loss: 3.0242343073186753

Epoch: 6| Step: 13
Training loss: 2.4322640351407996
Validation loss: 3.0358310914828013

Epoch: 92| Step: 0
Training loss: 3.1393343422786084
Validation loss: 3.041890141336195

Epoch: 6| Step: 1
Training loss: 3.159867130817976
Validation loss: 3.000748732323531

Epoch: 6| Step: 2
Training loss: 3.833471682719453
Validation loss: 3.0035317220268745

Epoch: 6| Step: 3
Training loss: 3.2404574638768695
Validation loss: 3.0033183357616657

Epoch: 6| Step: 4
Training loss: 2.8403264492085643
Validation loss: 2.959906015461627

Epoch: 6| Step: 5
Training loss: 3.2201498006248648
Validation loss: 2.9513396377523753

Epoch: 6| Step: 6
Training loss: 2.5912582194174485
Validation loss: 2.954850025012489

Epoch: 6| Step: 7
Training loss: 3.5967408049976246
Validation loss: 2.9528968151225956

Epoch: 6| Step: 8
Training loss: 3.1563220629633038
Validation loss: 2.9553982202690894

Epoch: 6| Step: 9
Training loss: 2.8079901246878056
Validation loss: 2.9562840421419296

Epoch: 6| Step: 10
Training loss: 3.3255916499297564
Validation loss: 2.9569129416799407

Epoch: 6| Step: 11
Training loss: 3.649137442060099
Validation loss: 2.959410538171818

Epoch: 6| Step: 12
Training loss: 3.578235474592652
Validation loss: 2.954448529455068

Epoch: 6| Step: 13
Training loss: 3.047388278080562
Validation loss: 2.9586156406800055

Epoch: 93| Step: 0
Training loss: 3.5729908986438788
Validation loss: 2.956951850606161

Epoch: 6| Step: 1
Training loss: 2.8620897757087054
Validation loss: 2.9549222053395803

Epoch: 6| Step: 2
Training loss: 3.62014590206443
Validation loss: 2.9532839503398325

Epoch: 6| Step: 3
Training loss: 3.538773076431238
Validation loss: 2.9520610128135183

Epoch: 6| Step: 4
Training loss: 3.693128525142695
Validation loss: 2.9499950490930504

Epoch: 6| Step: 5
Training loss: 3.976631568653614
Validation loss: 2.9479826957438657

Epoch: 6| Step: 6
Training loss: 3.237565535541146
Validation loss: 2.9483637201002644

Epoch: 6| Step: 7
Training loss: 2.7527055435976835
Validation loss: 2.946501306258344

Epoch: 6| Step: 8
Training loss: 2.4612136928036716
Validation loss: 2.9451017757265903

Epoch: 6| Step: 9
Training loss: 2.754645152423717
Validation loss: 2.943840106433031

Epoch: 6| Step: 10
Training loss: 2.5604941728581854
Validation loss: 2.9432650346700626

Epoch: 6| Step: 11
Training loss: 3.163872607148963
Validation loss: 2.948250173425922

Epoch: 6| Step: 12
Training loss: 3.30133131511341
Validation loss: 2.9479789946158332

Epoch: 6| Step: 13
Training loss: 3.490985159876021
Validation loss: 2.9624239918958475

Epoch: 94| Step: 0
Training loss: 2.347351562226982
Validation loss: 2.9637373110624363

Epoch: 6| Step: 1
Training loss: 3.9605936657347964
Validation loss: 2.9745435640850912

Epoch: 6| Step: 2
Training loss: 3.7716688351042666
Validation loss: 2.97725999466543

Epoch: 6| Step: 3
Training loss: 3.2543256290178797
Validation loss: 2.9706322515220736

Epoch: 6| Step: 4
Training loss: 3.3985407671091905
Validation loss: 2.9669061242202157

Epoch: 6| Step: 5
Training loss: 3.196681244796697
Validation loss: 2.9511609382274995

Epoch: 6| Step: 6
Training loss: 3.4026728053779993
Validation loss: 2.9422192363743793

Epoch: 6| Step: 7
Training loss: 3.0362589243368614
Validation loss: 2.9447283831057747

Epoch: 6| Step: 8
Training loss: 3.3789521142570065
Validation loss: 2.9449678185987445

Epoch: 6| Step: 9
Training loss: 2.298472569014626
Validation loss: 2.9404665599375317

Epoch: 6| Step: 10
Training loss: 3.2715339315276433
Validation loss: 2.938928955185676

Epoch: 6| Step: 11
Training loss: 3.1015926330793775
Validation loss: 2.942572093833233

Epoch: 6| Step: 12
Training loss: 2.778056679605385
Validation loss: 2.941266868753553

Epoch: 6| Step: 13
Training loss: 3.9128735348752017
Validation loss: 2.9416202213004836

Epoch: 95| Step: 0
Training loss: 3.048309770857687
Validation loss: 2.9408281847157407

Epoch: 6| Step: 1
Training loss: 3.6791307550551893
Validation loss: 2.941145711453851

Epoch: 6| Step: 2
Training loss: 3.161259971231865
Validation loss: 2.9423255322227844

Epoch: 6| Step: 3
Training loss: 3.140411217848309
Validation loss: 2.941036816330043

Epoch: 6| Step: 4
Training loss: 2.836583087674544
Validation loss: 2.9396095136977802

Epoch: 6| Step: 5
Training loss: 3.4448056356360035
Validation loss: 2.9410068757402894

Epoch: 6| Step: 6
Training loss: 2.191216499694897
Validation loss: 2.9401135674968697

Epoch: 6| Step: 7
Training loss: 3.806877492911049
Validation loss: 2.9416670696215625

Epoch: 6| Step: 8
Training loss: 3.2454157556188155
Validation loss: 2.9405646638975926

Epoch: 6| Step: 9
Training loss: 2.625563334008977
Validation loss: 2.9414112989990815

Epoch: 6| Step: 10
Training loss: 3.5980307915278082
Validation loss: 2.9401501962673273

Epoch: 6| Step: 11
Training loss: 3.2711908100561633
Validation loss: 2.9392796302882234

Epoch: 6| Step: 12
Training loss: 3.326108796377803
Validation loss: 2.93738117208949

Epoch: 6| Step: 13
Training loss: 3.6830359124518006
Validation loss: 2.9364825781824027

Epoch: 96| Step: 0
Training loss: 3.0140797505297883
Validation loss: 2.9380224736789495

Epoch: 6| Step: 1
Training loss: 3.443889298018924
Validation loss: 2.932466735200778

Epoch: 6| Step: 2
Training loss: 3.8525560192513395
Validation loss: 2.932268768630888

Epoch: 6| Step: 3
Training loss: 3.197717186155886
Validation loss: 2.93063978943648

Epoch: 6| Step: 4
Training loss: 3.346391151708714
Validation loss: 2.9308697998689643

Epoch: 6| Step: 5
Training loss: 3.995727880291019
Validation loss: 2.9306627188615497

Epoch: 6| Step: 6
Training loss: 2.9398902745434192
Validation loss: 2.9347616281588906

Epoch: 6| Step: 7
Training loss: 2.7892637206934485
Validation loss: 2.9446761082782658

Epoch: 6| Step: 8
Training loss: 2.55014259089305
Validation loss: 2.95016338451424

Epoch: 6| Step: 9
Training loss: 3.295812932918667
Validation loss: 2.955771814931

Epoch: 6| Step: 10
Training loss: 3.0920954431802925
Validation loss: 2.979509339236645

Epoch: 6| Step: 11
Training loss: 2.4509356989058073
Validation loss: 2.979614541392795

Epoch: 6| Step: 12
Training loss: 3.1113239870205533
Validation loss: 3.0013577104696454

Epoch: 6| Step: 13
Training loss: 3.9264084348194705
Validation loss: 2.948168683618518

Epoch: 97| Step: 0
Training loss: 3.0534657720581
Validation loss: 2.9325126160060715

Epoch: 6| Step: 1
Training loss: 2.9532152596056847
Validation loss: 2.9313954894696064

Epoch: 6| Step: 2
Training loss: 3.414050767821661
Validation loss: 2.9330987854238595

Epoch: 6| Step: 3
Training loss: 3.5343661442248555
Validation loss: 2.936608346096434

Epoch: 6| Step: 4
Training loss: 3.3631641398564254
Validation loss: 2.9439979610250466

Epoch: 6| Step: 5
Training loss: 3.3789065322434855
Validation loss: 2.95820657758096

Epoch: 6| Step: 6
Training loss: 2.986763682265668
Validation loss: 2.9462890155132335

Epoch: 6| Step: 7
Training loss: 2.93000144802227
Validation loss: 2.941191272957727

Epoch: 6| Step: 8
Training loss: 3.478035809657761
Validation loss: 2.9345846910472333

Epoch: 6| Step: 9
Training loss: 3.269395905203427
Validation loss: 2.9334394482839983

Epoch: 6| Step: 10
Training loss: 2.787657653729556
Validation loss: 2.9305818623593867

Epoch: 6| Step: 11
Training loss: 2.877224932000655
Validation loss: 2.929457787043201

Epoch: 6| Step: 12
Training loss: 3.8806366071805467
Validation loss: 2.928136777370943

Epoch: 6| Step: 13
Training loss: 3.048724273535559
Validation loss: 2.9291917449540916

Epoch: 98| Step: 0
Training loss: 3.601397661586724
Validation loss: 2.9276882932191524

Epoch: 6| Step: 1
Training loss: 3.21418097189134
Validation loss: 2.9297843355972164

Epoch: 6| Step: 2
Training loss: 2.728401503910399
Validation loss: 2.9317325464139863

Epoch: 6| Step: 3
Training loss: 2.5244933007087753
Validation loss: 2.935018929468696

Epoch: 6| Step: 4
Training loss: 3.4076449836230918
Validation loss: 2.9479522413049977

Epoch: 6| Step: 5
Training loss: 3.5458942687509922
Validation loss: 2.9521451332426825

Epoch: 6| Step: 6
Training loss: 3.0191774938313602
Validation loss: 2.943693346406274

Epoch: 6| Step: 7
Training loss: 3.5205236595950544
Validation loss: 2.936465633472761

Epoch: 6| Step: 8
Training loss: 3.6872769304466675
Validation loss: 2.9279654419614265

Epoch: 6| Step: 9
Training loss: 3.3672614211179703
Validation loss: 2.9339549138333085

Epoch: 6| Step: 10
Training loss: 2.5596768714703684
Validation loss: 2.9246646430476955

Epoch: 6| Step: 11
Training loss: 2.270948797900998
Validation loss: 2.932768013204649

Epoch: 6| Step: 12
Training loss: 3.124072585773128
Validation loss: 2.9205240264532977

Epoch: 6| Step: 13
Training loss: 4.416299600762644
Validation loss: 2.9224952231194554

Epoch: 99| Step: 0
Training loss: 3.3499026156262643
Validation loss: 2.921923166873526

Epoch: 6| Step: 1
Training loss: 3.2596395295601166
Validation loss: 2.920055003980535

Epoch: 6| Step: 2
Training loss: 4.073847489526322
Validation loss: 2.9271321066918543

Epoch: 6| Step: 3
Training loss: 3.3728560242945615
Validation loss: 2.928881744384745

Epoch: 6| Step: 4
Training loss: 3.294847488694262
Validation loss: 2.941977836999668

Epoch: 6| Step: 5
Training loss: 3.8227114644010833
Validation loss: 2.955255515447416

Epoch: 6| Step: 6
Training loss: 2.643670847905047
Validation loss: 2.9577606810454675

Epoch: 6| Step: 7
Training loss: 2.6299141798050463
Validation loss: 2.944091186788416

Epoch: 6| Step: 8
Training loss: 3.1006629850171192
Validation loss: 2.9346948904578274

Epoch: 6| Step: 9
Training loss: 3.1163033591551605
Validation loss: 2.9283101198336667

Epoch: 6| Step: 10
Training loss: 3.335266188674662
Validation loss: 2.9303287172461636

Epoch: 6| Step: 11
Training loss: 3.0684041311980916
Validation loss: 2.920511970701371

Epoch: 6| Step: 12
Training loss: 2.117260921092013
Validation loss: 2.917566601547616

Epoch: 6| Step: 13
Training loss: 3.3443494598092127
Validation loss: 2.9227415717673892

Epoch: 100| Step: 0
Training loss: 3.434717474011762
Validation loss: 2.919986358598914

Epoch: 6| Step: 1
Training loss: 3.6281745427549805
Validation loss: 2.9202997184658104

Epoch: 6| Step: 2
Training loss: 3.1984278035354667
Validation loss: 2.9201598530250696

Epoch: 6| Step: 3
Training loss: 3.1285599839610216
Validation loss: 2.920379991460953

Epoch: 6| Step: 4
Training loss: 3.2916422171026727
Validation loss: 2.9196970940193996

Epoch: 6| Step: 5
Training loss: 2.5120605426040696
Validation loss: 2.91922777885538

Epoch: 6| Step: 6
Training loss: 3.5309823533975475
Validation loss: 2.9175630999603492

Epoch: 6| Step: 7
Training loss: 3.360580015301764
Validation loss: 2.9177296267562705

Epoch: 6| Step: 8
Training loss: 3.833377395597788
Validation loss: 2.917792159057828

Epoch: 6| Step: 9
Training loss: 2.905093875753573
Validation loss: 2.9157219738310904

Epoch: 6| Step: 10
Training loss: 3.107167135810895
Validation loss: 2.91331797621393

Epoch: 6| Step: 11
Training loss: 2.1978833767025603
Validation loss: 2.911544399356767

Epoch: 6| Step: 12
Training loss: 2.9524029853250635
Validation loss: 2.9156539922760794

Epoch: 6| Step: 13
Training loss: 3.6987930906930693
Validation loss: 2.914463941826206

Epoch: 101| Step: 0
Training loss: 3.2447417343649234
Validation loss: 2.926307608422535

Epoch: 6| Step: 1
Training loss: 3.601960464302928
Validation loss: 2.918249764745423

Epoch: 6| Step: 2
Training loss: 3.148331633271673
Validation loss: 2.9158391918439603

Epoch: 6| Step: 3
Training loss: 2.452849160011683
Validation loss: 2.936447653238315

Epoch: 6| Step: 4
Training loss: 2.842365640569908
Validation loss: 2.9499722073627375

Epoch: 6| Step: 5
Training loss: 3.0562527834015634
Validation loss: 2.9349253744774773

Epoch: 6| Step: 6
Training loss: 2.82794812740034
Validation loss: 2.920125291217882

Epoch: 6| Step: 7
Training loss: 2.8982591599867784
Validation loss: 2.9153330788020324

Epoch: 6| Step: 8
Training loss: 3.538827244095112
Validation loss: 2.9073320293792904

Epoch: 6| Step: 9
Training loss: 3.5150957175363495
Validation loss: 2.9103583862023235

Epoch: 6| Step: 10
Training loss: 3.353549323915205
Validation loss: 2.90979145739846

Epoch: 6| Step: 11
Training loss: 3.0285656241338175
Validation loss: 2.913680500700157

Epoch: 6| Step: 12
Training loss: 3.6474342682257936
Validation loss: 2.912636193813522

Epoch: 6| Step: 13
Training loss: 3.828040670906305
Validation loss: 2.9120944215397997

Epoch: 102| Step: 0
Training loss: 3.866568467658098
Validation loss: 2.912707847408235

Epoch: 6| Step: 1
Training loss: 3.5321602787446116
Validation loss: 2.9144445846942255

Epoch: 6| Step: 2
Training loss: 3.271689009458169
Validation loss: 2.912879798634923

Epoch: 6| Step: 3
Training loss: 2.818191280097403
Validation loss: 2.912684436014136

Epoch: 6| Step: 4
Training loss: 3.073351882029047
Validation loss: 2.9122123982571657

Epoch: 6| Step: 5
Training loss: 3.4761451042011213
Validation loss: 2.9136679239065373

Epoch: 6| Step: 6
Training loss: 2.870196102234689
Validation loss: 2.912301382719521

Epoch: 6| Step: 7
Training loss: 2.76181491970331
Validation loss: 2.91316329752516

Epoch: 6| Step: 8
Training loss: 2.956742911346678
Validation loss: 2.9116431951770414

Epoch: 6| Step: 9
Training loss: 2.7960691516494482
Validation loss: 2.9105206286978107

Epoch: 6| Step: 10
Training loss: 3.3499122949762734
Validation loss: 2.9086109627096297

Epoch: 6| Step: 11
Training loss: 2.5743006228681633
Validation loss: 2.908215298772448

Epoch: 6| Step: 12
Training loss: 3.3215157516452836
Validation loss: 2.9082226488502143

Epoch: 6| Step: 13
Training loss: 4.411833127557088
Validation loss: 2.9073926620202957

Epoch: 103| Step: 0
Training loss: 3.377877315789083
Validation loss: 2.906080742303622

Epoch: 6| Step: 1
Training loss: 3.0323627435200713
Validation loss: 2.9057551445737064

Epoch: 6| Step: 2
Training loss: 3.3756896833110557
Validation loss: 2.905129444128063

Epoch: 6| Step: 3
Training loss: 3.2050964243364715
Validation loss: 2.904459902714512

Epoch: 6| Step: 4
Training loss: 2.670956102268276
Validation loss: 2.902250855371037

Epoch: 6| Step: 5
Training loss: 2.754602222561547
Validation loss: 2.90629067129521

Epoch: 6| Step: 6
Training loss: 3.545848546666024
Validation loss: 2.8997220157548087

Epoch: 6| Step: 7
Training loss: 3.6223163536597975
Validation loss: 2.8993623403047653

Epoch: 6| Step: 8
Training loss: 3.5081829053896914
Validation loss: 2.911420652653576

Epoch: 6| Step: 9
Training loss: 3.244948643070795
Validation loss: 2.9221046457970252

Epoch: 6| Step: 10
Training loss: 3.1014364298606534
Validation loss: 2.934128805525764

Epoch: 6| Step: 11
Training loss: 2.5385561394125635
Validation loss: 2.952989958756069

Epoch: 6| Step: 12
Training loss: 2.895001207262489
Validation loss: 2.9575591720181467

Epoch: 6| Step: 13
Training loss: 4.19765346008015
Validation loss: 2.9709270929233256

Epoch: 104| Step: 0
Training loss: 3.6403327791872404
Validation loss: 2.9442778453981147

Epoch: 6| Step: 1
Training loss: 3.35933028790194
Validation loss: 2.9220542525900566

Epoch: 6| Step: 2
Training loss: 2.9807227990105045
Validation loss: 2.9094206342826494

Epoch: 6| Step: 3
Training loss: 2.8147072501943917
Validation loss: 2.902067806285191

Epoch: 6| Step: 4
Training loss: 3.223678667123128
Validation loss: 2.9032032133406007

Epoch: 6| Step: 5
Training loss: 3.4362527144980923
Validation loss: 2.90618532981905

Epoch: 6| Step: 6
Training loss: 3.5355395704646395
Validation loss: 2.911276980938118

Epoch: 6| Step: 7
Training loss: 2.868646151921509
Validation loss: 2.9141663831900773

Epoch: 6| Step: 8
Training loss: 3.3386219667645647
Validation loss: 2.9090825185306333

Epoch: 6| Step: 9
Training loss: 3.4167095894947397
Validation loss: 2.90814793600472

Epoch: 6| Step: 10
Training loss: 2.8785045659285964
Validation loss: 2.9088510409054043

Epoch: 6| Step: 11
Training loss: 2.8875339786792718
Validation loss: 2.9065769755682496

Epoch: 6| Step: 12
Training loss: 2.595774859835753
Validation loss: 2.902800820064519

Epoch: 6| Step: 13
Training loss: 3.983040739563182
Validation loss: 2.904585411120025

Epoch: 105| Step: 0
Training loss: 3.29423988940918
Validation loss: 2.898617781875058

Epoch: 6| Step: 1
Training loss: 2.4810826780849453
Validation loss: 2.9005863781449612

Epoch: 6| Step: 2
Training loss: 3.5484827909682544
Validation loss: 2.898392467581797

Epoch: 6| Step: 3
Training loss: 3.396288523366022
Validation loss: 2.9114205857320576

Epoch: 6| Step: 4
Training loss: 3.3345915962665655
Validation loss: 2.9126332223283713

Epoch: 6| Step: 5
Training loss: 2.7653427411026366
Validation loss: 2.9147220604035726

Epoch: 6| Step: 6
Training loss: 3.0730938531687086
Validation loss: 2.922380685382218

Epoch: 6| Step: 7
Training loss: 3.3728444315334456
Validation loss: 2.9286280452683253

Epoch: 6| Step: 8
Training loss: 2.6281869706366994
Validation loss: 2.9236202628757164

Epoch: 6| Step: 9
Training loss: 3.4712985187638457
Validation loss: 2.935774873253333

Epoch: 6| Step: 10
Training loss: 3.3737919376080443
Validation loss: 2.940702891064958

Epoch: 6| Step: 11
Training loss: 3.296870516371729
Validation loss: 2.9188362179993055

Epoch: 6| Step: 12
Training loss: 2.8782580615172373
Validation loss: 2.8985551826191753

Epoch: 6| Step: 13
Training loss: 3.982952866413533
Validation loss: 2.903324995944298

Epoch: 106| Step: 0
Training loss: 3.6244561675341003
Validation loss: 2.8956676033515323

Epoch: 6| Step: 1
Training loss: 2.982272221196174
Validation loss: 2.89249600934126

Epoch: 6| Step: 2
Training loss: 3.70740786087463
Validation loss: 2.89978210555665

Epoch: 6| Step: 3
Training loss: 3.14903749565607
Validation loss: 2.891396245971726

Epoch: 6| Step: 4
Training loss: 3.058033859045522
Validation loss: 2.8919658323738147

Epoch: 6| Step: 5
Training loss: 3.331782806901326
Validation loss: 2.8943684407203394

Epoch: 6| Step: 6
Training loss: 3.1657601782357925
Validation loss: 2.8916184908388294

Epoch: 6| Step: 7
Training loss: 3.0455679413014263
Validation loss: 2.8932590127354376

Epoch: 6| Step: 8
Training loss: 2.245140125344982
Validation loss: 2.8956025525110003

Epoch: 6| Step: 9
Training loss: 3.0662378349949297
Validation loss: 2.892626325944594

Epoch: 6| Step: 10
Training loss: 3.37877161716965
Validation loss: 2.8929891800869982

Epoch: 6| Step: 11
Training loss: 2.7748669016768144
Validation loss: 2.890501220678119

Epoch: 6| Step: 12
Training loss: 3.3230764575832943
Validation loss: 2.892985182633093

Epoch: 6| Step: 13
Training loss: 3.845343530832738
Validation loss: 2.8905933754212887

Epoch: 107| Step: 0
Training loss: 3.2130105410752305
Validation loss: 2.89083217331854

Epoch: 6| Step: 1
Training loss: 3.3733645114538438
Validation loss: 2.888389786125031

Epoch: 6| Step: 2
Training loss: 3.4777679068114162
Validation loss: 2.8909994249261186

Epoch: 6| Step: 3
Training loss: 3.5017878189686407
Validation loss: 2.8896083881064327

Epoch: 6| Step: 4
Training loss: 2.850046920390135
Validation loss: 2.8937154933995006

Epoch: 6| Step: 5
Training loss: 3.25511485868396
Validation loss: 2.8958400414324905

Epoch: 6| Step: 6
Training loss: 3.3825790641887856
Validation loss: 2.889483417157777

Epoch: 6| Step: 7
Training loss: 2.7939635739201356
Validation loss: 2.890590202124309

Epoch: 6| Step: 8
Training loss: 3.1042376687209776
Validation loss: 2.8903474762650276

Epoch: 6| Step: 9
Training loss: 3.14346246030056
Validation loss: 2.8883635024717935

Epoch: 6| Step: 10
Training loss: 3.032277984920253
Validation loss: 2.8814705880968043

Epoch: 6| Step: 11
Training loss: 3.277872145276757
Validation loss: 2.8855449271438687

Epoch: 6| Step: 12
Training loss: 3.0614830975711538
Validation loss: 2.883818469921273

Epoch: 6| Step: 13
Training loss: 2.980032112665414
Validation loss: 2.885894447669687

Epoch: 108| Step: 0
Training loss: 2.8802525181798635
Validation loss: 2.8838715794265264

Epoch: 6| Step: 1
Training loss: 3.55730983716458
Validation loss: 2.8885072958843505

Epoch: 6| Step: 2
Training loss: 2.9537966332808443
Validation loss: 2.8853702176409364

Epoch: 6| Step: 3
Training loss: 2.9531075613324393
Validation loss: 2.8861306116003687

Epoch: 6| Step: 4
Training loss: 3.684526828941002
Validation loss: 2.8869272266370314

Epoch: 6| Step: 5
Training loss: 3.204803027261189
Validation loss: 2.888728034234937

Epoch: 6| Step: 6
Training loss: 2.9187907704154474
Validation loss: 2.8872351301338273

Epoch: 6| Step: 7
Training loss: 3.6815844139442286
Validation loss: 2.8859730438026867

Epoch: 6| Step: 8
Training loss: 2.752173778386679
Validation loss: 2.8876286340607122

Epoch: 6| Step: 9
Training loss: 2.6505706208742024
Validation loss: 2.8859276561006313

Epoch: 6| Step: 10
Training loss: 3.192645538525686
Validation loss: 2.8847086385625533

Epoch: 6| Step: 11
Training loss: 3.6012905456739186
Validation loss: 2.8851844555259443

Epoch: 6| Step: 12
Training loss: 3.393864222618852
Validation loss: 2.8827618103346317

Epoch: 6| Step: 13
Training loss: 2.8352778064173867
Validation loss: 2.882576463544298

Epoch: 109| Step: 0
Training loss: 2.8516742005091693
Validation loss: 2.8834523892746535

Epoch: 6| Step: 1
Training loss: 3.3134316627705025
Validation loss: 2.881631873501443

Epoch: 6| Step: 2
Training loss: 3.6757498566506115
Validation loss: 2.8802154890434863

Epoch: 6| Step: 3
Training loss: 2.239321375467517
Validation loss: 2.8800988337376885

Epoch: 6| Step: 4
Training loss: 3.0405080147455514
Validation loss: 2.8778875758269367

Epoch: 6| Step: 5
Training loss: 2.786321067400024
Validation loss: 2.8811178187621236

Epoch: 6| Step: 6
Training loss: 2.799000364063017
Validation loss: 2.8787288088203318

Epoch: 6| Step: 7
Training loss: 3.7503717873967073
Validation loss: 2.887055524491383

Epoch: 6| Step: 8
Training loss: 3.6411474286923817
Validation loss: 2.890514327538322

Epoch: 6| Step: 9
Training loss: 3.1418718738134377
Validation loss: 2.900558063459049

Epoch: 6| Step: 10
Training loss: 2.8716070637538613
Validation loss: 2.905659067177014

Epoch: 6| Step: 11
Training loss: 4.005088906890784
Validation loss: 2.9003071964910623

Epoch: 6| Step: 12
Training loss: 2.7924539585125836
Validation loss: 2.878900376314158

Epoch: 6| Step: 13
Training loss: 3.1813201836599085
Validation loss: 2.876392771713573

Epoch: 110| Step: 0
Training loss: 3.109025945192619
Validation loss: 2.8768716331416377

Epoch: 6| Step: 1
Training loss: 3.40382480904768
Validation loss: 2.8799838169388394

Epoch: 6| Step: 2
Training loss: 2.257058621640341
Validation loss: 2.881798542624206

Epoch: 6| Step: 3
Training loss: 3.0460329114772766
Validation loss: 2.888352122844088

Epoch: 6| Step: 4
Training loss: 2.6355864177410044
Validation loss: 2.8964231741284587

Epoch: 6| Step: 5
Training loss: 3.342787274246487
Validation loss: 2.891595716375258

Epoch: 6| Step: 6
Training loss: 3.5976403450381325
Validation loss: 2.8999401668745306

Epoch: 6| Step: 7
Training loss: 3.5539731156722874
Validation loss: 2.8860720709767165

Epoch: 6| Step: 8
Training loss: 3.0899908173063553
Validation loss: 2.881163136308624

Epoch: 6| Step: 9
Training loss: 3.145363037794901
Validation loss: 2.883610373965422

Epoch: 6| Step: 10
Training loss: 3.6741584333254154
Validation loss: 2.8778137377198427

Epoch: 6| Step: 11
Training loss: 3.649219371980987
Validation loss: 2.8763404457070014

Epoch: 6| Step: 12
Training loss: 3.098069999165055
Validation loss: 2.8743710764036035

Epoch: 6| Step: 13
Training loss: 2.4573799698506424
Validation loss: 2.872006916804592

Epoch: 111| Step: 0
Training loss: 3.5734131285549817
Validation loss: 2.87024763010785

Epoch: 6| Step: 1
Training loss: 3.086817362452496
Validation loss: 2.881089011985702

Epoch: 6| Step: 2
Training loss: 3.67924830575458
Validation loss: 2.8946086152535626

Epoch: 6| Step: 3
Training loss: 3.4106383447174564
Validation loss: 2.8907655087028226

Epoch: 6| Step: 4
Training loss: 3.3024256836631714
Validation loss: 2.8869767047477257

Epoch: 6| Step: 5
Training loss: 3.3314623509157126
Validation loss: 2.8816206977102503

Epoch: 6| Step: 6
Training loss: 3.3287407390538712
Validation loss: 2.871180601566368

Epoch: 6| Step: 7
Training loss: 3.2085314272541785
Validation loss: 2.87204070623636

Epoch: 6| Step: 8
Training loss: 3.031932321422193
Validation loss: 2.8679998610041353

Epoch: 6| Step: 9
Training loss: 2.943009910771607
Validation loss: 2.8730713722995604

Epoch: 6| Step: 10
Training loss: 2.9729266851978577
Validation loss: 2.873093561922049

Epoch: 6| Step: 11
Training loss: 2.8183754479682883
Validation loss: 2.868624872519887

Epoch: 6| Step: 12
Training loss: 2.689961393001283
Validation loss: 2.8669109176991583

Epoch: 6| Step: 13
Training loss: 2.6403971918018043
Validation loss: 2.8686885833510805

Epoch: 112| Step: 0
Training loss: 4.136583882583715
Validation loss: 2.8692595717741036

Epoch: 6| Step: 1
Training loss: 3.5029633102738886
Validation loss: 2.9245848531912375

Epoch: 6| Step: 2
Training loss: 3.2550722302276216
Validation loss: 2.9212963081091767

Epoch: 6| Step: 3
Training loss: 2.889565433445839
Validation loss: 2.9492294192893644

Epoch: 6| Step: 4
Training loss: 2.5399913790699196
Validation loss: 2.926413838341826

Epoch: 6| Step: 5
Training loss: 2.7432019566179373
Validation loss: 2.9269992812068026

Epoch: 6| Step: 6
Training loss: 3.7162605736636913
Validation loss: 2.919790346730394

Epoch: 6| Step: 7
Training loss: 2.8485630093543164
Validation loss: 2.9157611106236745

Epoch: 6| Step: 8
Training loss: 2.8817455932975324
Validation loss: 2.875914725534738

Epoch: 6| Step: 9
Training loss: 2.9932959672199955
Validation loss: 2.866595436660235

Epoch: 6| Step: 10
Training loss: 3.058605286636129
Validation loss: 2.8644328789153315

Epoch: 6| Step: 11
Training loss: 3.4179899552913633
Validation loss: 2.8640888032606693

Epoch: 6| Step: 12
Training loss: 2.673662268299188
Validation loss: 2.8630560327063437

Epoch: 6| Step: 13
Training loss: 3.5541570582079207
Validation loss: 2.862361785902121

Epoch: 113| Step: 0
Training loss: 3.3306539893396465
Validation loss: 2.862101665515727

Epoch: 6| Step: 1
Training loss: 3.6254831189462404
Validation loss: 2.8653473015255897

Epoch: 6| Step: 2
Training loss: 2.8710125347250472
Validation loss: 2.8681132319323073

Epoch: 6| Step: 3
Training loss: 3.142880365360221
Validation loss: 2.867066845240289

Epoch: 6| Step: 4
Training loss: 3.499437559440356
Validation loss: 2.8628436354322795

Epoch: 6| Step: 5
Training loss: 2.829754776052217
Validation loss: 2.8671233114200665

Epoch: 6| Step: 6
Training loss: 3.0884415522920015
Validation loss: 2.8685039269866883

Epoch: 6| Step: 7
Training loss: 2.1485997364170792
Validation loss: 2.8697513886956463

Epoch: 6| Step: 8
Training loss: 3.7325120692431657
Validation loss: 2.878474910953246

Epoch: 6| Step: 9
Training loss: 2.918470061312827
Validation loss: 2.8816900052433687

Epoch: 6| Step: 10
Training loss: 3.2092561426783695
Validation loss: 2.8749838022040595

Epoch: 6| Step: 11
Training loss: 3.4287536322907872
Validation loss: 2.8752079657070717

Epoch: 6| Step: 12
Training loss: 2.5218171861112406
Validation loss: 2.875858355307002

Epoch: 6| Step: 13
Training loss: 3.802215964037632
Validation loss: 2.8670431469966715

Epoch: 114| Step: 0
Training loss: 3.5158604521849672
Validation loss: 2.8677690319773137

Epoch: 6| Step: 1
Training loss: 3.32507815161621
Validation loss: 2.8598523946481262

Epoch: 6| Step: 2
Training loss: 3.978362090304228
Validation loss: 2.8595365499612875

Epoch: 6| Step: 3
Training loss: 2.7310505739639512
Validation loss: 2.8608821808237423

Epoch: 6| Step: 4
Training loss: 3.6127609950626804
Validation loss: 2.8614058772986533

Epoch: 6| Step: 5
Training loss: 2.925872842045153
Validation loss: 2.859404627126878

Epoch: 6| Step: 6
Training loss: 2.549257439598278
Validation loss: 2.8618498927348544

Epoch: 6| Step: 7
Training loss: 3.415056516031679
Validation loss: 2.8594763666272995

Epoch: 6| Step: 8
Training loss: 2.93844005071409
Validation loss: 2.8609965676777067

Epoch: 6| Step: 9
Training loss: 2.69482886356673
Validation loss: 2.8618073384099425

Epoch: 6| Step: 10
Training loss: 3.3314637822302693
Validation loss: 2.862761178653043

Epoch: 6| Step: 11
Training loss: 3.185680393622766
Validation loss: 2.8620770098310833

Epoch: 6| Step: 12
Training loss: 2.737322107396408
Validation loss: 2.861165947738236

Epoch: 6| Step: 13
Training loss: 3.030108049940055
Validation loss: 2.862311533886993

Epoch: 115| Step: 0
Training loss: 3.7446515406820984
Validation loss: 2.863339348712136

Epoch: 6| Step: 1
Training loss: 2.92759756184672
Validation loss: 2.862946808954248

Epoch: 6| Step: 2
Training loss: 2.6806303539831906
Validation loss: 2.8628729687654157

Epoch: 6| Step: 3
Training loss: 3.5671273679673616
Validation loss: 2.862665311456374

Epoch: 6| Step: 4
Training loss: 3.6490998085612563
Validation loss: 2.8626625334798224

Epoch: 6| Step: 5
Training loss: 2.856973775901516
Validation loss: 2.8618859421239495

Epoch: 6| Step: 6
Training loss: 3.261453108335095
Validation loss: 2.860628841730346

Epoch: 6| Step: 7
Training loss: 3.048006913645355
Validation loss: 2.8604508170449754

Epoch: 6| Step: 8
Training loss: 3.064046819433758
Validation loss: 2.858603135874985

Epoch: 6| Step: 9
Training loss: 2.981145899332656
Validation loss: 2.8607707780122906

Epoch: 6| Step: 10
Training loss: 3.4871972120094923
Validation loss: 2.8577531643792935

Epoch: 6| Step: 11
Training loss: 3.113523236949017
Validation loss: 2.8582243029271996

Epoch: 6| Step: 12
Training loss: 2.792481792120796
Validation loss: 2.856995854555032

Epoch: 6| Step: 13
Training loss: 2.766106773698766
Validation loss: 2.8521203493762926

Epoch: 116| Step: 0
Training loss: 3.7892150218980363
Validation loss: 2.8503818991541054

Epoch: 6| Step: 1
Training loss: 3.097072782080667
Validation loss: 2.8527315084143043

Epoch: 6| Step: 2
Training loss: 2.653464438715329
Validation loss: 2.8560698636703057

Epoch: 6| Step: 3
Training loss: 3.041946415686944
Validation loss: 2.8514382747034714

Epoch: 6| Step: 4
Training loss: 2.7696601181286473
Validation loss: 2.851752745513106

Epoch: 6| Step: 5
Training loss: 2.9376100560126295
Validation loss: 2.847857172695101

Epoch: 6| Step: 6
Training loss: 3.1198593582341387
Validation loss: 2.8506388846415294

Epoch: 6| Step: 7
Training loss: 3.153286439602058
Validation loss: 2.8587140411476133

Epoch: 6| Step: 8
Training loss: 3.070246960277744
Validation loss: 2.86297859296049

Epoch: 6| Step: 9
Training loss: 3.291750717699563
Validation loss: 2.8597128269729355

Epoch: 6| Step: 10
Training loss: 3.4457773599994908
Validation loss: 2.8915706507819667

Epoch: 6| Step: 11
Training loss: 3.4392712277994506
Validation loss: 2.934658458290142

Epoch: 6| Step: 12
Training loss: 3.2875784744933694
Validation loss: 2.929130617436065

Epoch: 6| Step: 13
Training loss: 2.995373018754822
Validation loss: 2.913379793648696

Epoch: 117| Step: 0
Training loss: 3.3453100255238106
Validation loss: 2.882707814189095

Epoch: 6| Step: 1
Training loss: 2.950515158979723
Validation loss: 2.853348279557727

Epoch: 6| Step: 2
Training loss: 2.904009211544003
Validation loss: 2.8469525387995844

Epoch: 6| Step: 3
Training loss: 3.798594772114659
Validation loss: 2.845933989882719

Epoch: 6| Step: 4
Training loss: 3.0039094247788816
Validation loss: 2.8459595078626148

Epoch: 6| Step: 5
Training loss: 2.655207709971719
Validation loss: 2.850243788955092

Epoch: 6| Step: 6
Training loss: 3.188284683880012
Validation loss: 2.8444111733911255

Epoch: 6| Step: 7
Training loss: 2.9168599382579314
Validation loss: 2.8505332160124155

Epoch: 6| Step: 8
Training loss: 3.3815808597944432
Validation loss: 2.847288253469366

Epoch: 6| Step: 9
Training loss: 3.2912703327807007
Validation loss: 2.845233458639687

Epoch: 6| Step: 10
Training loss: 3.4117791333193335
Validation loss: 2.848588642378341

Epoch: 6| Step: 11
Training loss: 3.0328399578347134
Validation loss: 2.8436790177083218

Epoch: 6| Step: 12
Training loss: 3.209996292017046
Validation loss: 2.842948724060014

Epoch: 6| Step: 13
Training loss: 2.6237906440396497
Validation loss: 2.8444144793225865

Epoch: 118| Step: 0
Training loss: 3.1252578628962326
Validation loss: 2.8435551124601965

Epoch: 6| Step: 1
Training loss: 3.395077361853298
Validation loss: 2.846578397440209

Epoch: 6| Step: 2
Training loss: 2.767353702941024
Validation loss: 2.845195746681138

Epoch: 6| Step: 3
Training loss: 3.3670090630287257
Validation loss: 2.8447700500177655

Epoch: 6| Step: 4
Training loss: 3.1664327903179292
Validation loss: 2.8460240548632707

Epoch: 6| Step: 5
Training loss: 3.1487261542810168
Validation loss: 2.8450332697672933

Epoch: 6| Step: 6
Training loss: 3.184228901604742
Validation loss: 2.842962414457623

Epoch: 6| Step: 7
Training loss: 3.448947640950365
Validation loss: 2.8457104725781246

Epoch: 6| Step: 8
Training loss: 3.2728493829064176
Validation loss: 2.8448464399430877

Epoch: 6| Step: 9
Training loss: 3.0663739050841876
Validation loss: 2.846947757215409

Epoch: 6| Step: 10
Training loss: 2.772109710492945
Validation loss: 2.852531541981386

Epoch: 6| Step: 11
Training loss: 3.2685524992056463
Validation loss: 2.870044887729506

Epoch: 6| Step: 12
Training loss: 2.814903927344275
Validation loss: 2.850920765704747

Epoch: 6| Step: 13
Training loss: 3.1948619422277105
Validation loss: 2.8531851203864216

Epoch: 119| Step: 0
Training loss: 2.8166014541510624
Validation loss: 2.852296794410345

Epoch: 6| Step: 1
Training loss: 3.0545441967065705
Validation loss: 2.845952002386208

Epoch: 6| Step: 2
Training loss: 2.6117603112695753
Validation loss: 2.842452871170917

Epoch: 6| Step: 3
Training loss: 2.9033106224085685
Validation loss: 2.8425253352202136

Epoch: 6| Step: 4
Training loss: 3.4072646283521375
Validation loss: 2.8359238769363144

Epoch: 6| Step: 5
Training loss: 3.9667334051421586
Validation loss: 2.83812411081019

Epoch: 6| Step: 6
Training loss: 3.14795433104372
Validation loss: 2.839094825682637

Epoch: 6| Step: 7
Training loss: 3.0976205369158207
Validation loss: 2.8350465638882247

Epoch: 6| Step: 8
Training loss: 2.625457632954717
Validation loss: 2.8415257625008246

Epoch: 6| Step: 9
Training loss: 2.5773582474276826
Validation loss: 2.836536810261952

Epoch: 6| Step: 10
Training loss: 3.4855030098523017
Validation loss: 2.8354497535482546

Epoch: 6| Step: 11
Training loss: 2.7975879804669894
Validation loss: 2.8356107363477885

Epoch: 6| Step: 12
Training loss: 3.299016031319391
Validation loss: 2.836794599929631

Epoch: 6| Step: 13
Training loss: 4.260957840527174
Validation loss: 2.8384936142453885

Epoch: 120| Step: 0
Training loss: 3.4242935343084193
Validation loss: 2.8400833722317818

Epoch: 6| Step: 1
Training loss: 4.025659277334273
Validation loss: 2.8341047149591114

Epoch: 6| Step: 2
Training loss: 2.416414664272652
Validation loss: 2.8380463629292345

Epoch: 6| Step: 3
Training loss: 3.5277361646252103
Validation loss: 2.8343907059575346

Epoch: 6| Step: 4
Training loss: 2.470095786735444
Validation loss: 2.838030828634502

Epoch: 6| Step: 5
Training loss: 3.0878986549152394
Validation loss: 2.835265967783147

Epoch: 6| Step: 6
Training loss: 3.026466606799142
Validation loss: 2.8367225263063696

Epoch: 6| Step: 7
Training loss: 2.8860225844633
Validation loss: 2.833706719577106

Epoch: 6| Step: 8
Training loss: 2.309089517046837
Validation loss: 2.838635854446347

Epoch: 6| Step: 9
Training loss: 2.905121122582919
Validation loss: 2.833726353202544

Epoch: 6| Step: 10
Training loss: 2.859887582663632
Validation loss: 2.837123713050965

Epoch: 6| Step: 11
Training loss: 4.003442951472925
Validation loss: 2.837854869733508

Epoch: 6| Step: 12
Training loss: 3.0924752431632556
Validation loss: 2.836963504691316

Epoch: 6| Step: 13
Training loss: 3.549386231998621
Validation loss: 2.8478688869718205

Epoch: 121| Step: 0
Training loss: 3.017420101040309
Validation loss: 2.8658223871924466

Epoch: 6| Step: 1
Training loss: 3.028734874427802
Validation loss: 2.8714799505296407

Epoch: 6| Step: 2
Training loss: 3.1334100091629344
Validation loss: 2.8795582240967543

Epoch: 6| Step: 3
Training loss: 3.09110416597448
Validation loss: 2.8888081657510467

Epoch: 6| Step: 4
Training loss: 2.8776533073728814
Validation loss: 2.8601391051132943

Epoch: 6| Step: 5
Training loss: 3.0893146819088244
Validation loss: 2.8391012350144162

Epoch: 6| Step: 6
Training loss: 3.756864622486018
Validation loss: 2.8339680685166426

Epoch: 6| Step: 7
Training loss: 2.7153225044367355
Validation loss: 2.835350938477766

Epoch: 6| Step: 8
Training loss: 2.7781131499545144
Validation loss: 2.831445489092658

Epoch: 6| Step: 9
Training loss: 3.765013585769033
Validation loss: 2.832452748197791

Epoch: 6| Step: 10
Training loss: 2.671404077623069
Validation loss: 2.8349819939278755

Epoch: 6| Step: 11
Training loss: 2.8457088221674267
Validation loss: 2.837972746583144

Epoch: 6| Step: 12
Training loss: 3.23057384389211
Validation loss: 2.8369604223171705

Epoch: 6| Step: 13
Training loss: 4.092776816204463
Validation loss: 2.840018547589127

Epoch: 122| Step: 0
Training loss: 3.098693904761371
Validation loss: 2.839767998268177

Epoch: 6| Step: 1
Training loss: 3.117519580868285
Validation loss: 2.843540325005277

Epoch: 6| Step: 2
Training loss: 3.8474834887452074
Validation loss: 2.840384443416862

Epoch: 6| Step: 3
Training loss: 2.9818934164156157
Validation loss: 2.837696419157437

Epoch: 6| Step: 4
Training loss: 3.5036659115769426
Validation loss: 2.8413849716235418

Epoch: 6| Step: 5
Training loss: 3.297586807137964
Validation loss: 2.8400711212513747

Epoch: 6| Step: 6
Training loss: 2.394982051264457
Validation loss: 2.841114130222332

Epoch: 6| Step: 7
Training loss: 2.880320063396174
Validation loss: 2.8385547229338255

Epoch: 6| Step: 8
Training loss: 3.216235910407768
Validation loss: 2.8336999705434875

Epoch: 6| Step: 9
Training loss: 3.197398654265194
Validation loss: 2.8356600394348543

Epoch: 6| Step: 10
Training loss: 2.7033484923301856
Validation loss: 2.833189564941429

Epoch: 6| Step: 11
Training loss: 3.7764242605429907
Validation loss: 2.8319512953060446

Epoch: 6| Step: 12
Training loss: 2.8599429374284164
Validation loss: 2.8241369710199713

Epoch: 6| Step: 13
Training loss: 2.708754570309771
Validation loss: 2.827814339264811

Epoch: 123| Step: 0
Training loss: 2.9577306930586382
Validation loss: 2.8289864967897445

Epoch: 6| Step: 1
Training loss: 3.1213245903271822
Validation loss: 2.826007087837391

Epoch: 6| Step: 2
Training loss: 3.8166430115834324
Validation loss: 2.8271077656925505

Epoch: 6| Step: 3
Training loss: 3.2376913124617115
Validation loss: 2.8248297852507327

Epoch: 6| Step: 4
Training loss: 3.2316467277720995
Validation loss: 2.827511343911976

Epoch: 6| Step: 5
Training loss: 3.146772147716767
Validation loss: 2.8296031335469065

Epoch: 6| Step: 6
Training loss: 3.213382727321178
Validation loss: 2.825999372430921

Epoch: 6| Step: 7
Training loss: 2.921721918512474
Validation loss: 2.8333571962030892

Epoch: 6| Step: 8
Training loss: 3.1665294684420227
Validation loss: 2.824612526797246

Epoch: 6| Step: 9
Training loss: 3.132047564567995
Validation loss: 2.8237851500662026

Epoch: 6| Step: 10
Training loss: 2.577522531109372
Validation loss: 2.826122138785974

Epoch: 6| Step: 11
Training loss: 3.0202474793343974
Validation loss: 2.826340861283359

Epoch: 6| Step: 12
Training loss: 2.961251516474621
Validation loss: 2.8287450935155514

Epoch: 6| Step: 13
Training loss: 3.3421159120430355
Validation loss: 2.8264135724285797

Epoch: 124| Step: 0
Training loss: 3.0631241454329716
Validation loss: 2.8372633464859667

Epoch: 6| Step: 1
Training loss: 2.7302268689246945
Validation loss: 2.8280133393201314

Epoch: 6| Step: 2
Training loss: 2.9685468102237746
Validation loss: 2.820224039177044

Epoch: 6| Step: 3
Training loss: 3.340107297258899
Validation loss: 2.824004382191001

Epoch: 6| Step: 4
Training loss: 3.1613830523925883
Validation loss: 2.828357568901525

Epoch: 6| Step: 5
Training loss: 3.224585567134628
Validation loss: 2.8226276406098227

Epoch: 6| Step: 6
Training loss: 2.446448698945528
Validation loss: 2.823596952444577

Epoch: 6| Step: 7
Training loss: 2.8433503928647283
Validation loss: 2.827353273888944

Epoch: 6| Step: 8
Training loss: 2.9868866103226623
Validation loss: 2.8269632623309047

Epoch: 6| Step: 9
Training loss: 3.282886206168494
Validation loss: 2.822947801011799

Epoch: 6| Step: 10
Training loss: 3.3468483803596065
Validation loss: 2.822737839594798

Epoch: 6| Step: 11
Training loss: 3.7249351803049064
Validation loss: 2.826996915452254

Epoch: 6| Step: 12
Training loss: 3.6592179991989573
Validation loss: 2.822845765655189

Epoch: 6| Step: 13
Training loss: 2.7223902042832586
Validation loss: 2.8191437999346767

Epoch: 125| Step: 0
Training loss: 3.155646540295708
Validation loss: 2.822516810608001

Epoch: 6| Step: 1
Training loss: 2.8605822740047344
Validation loss: 2.826661637753134

Epoch: 6| Step: 2
Training loss: 3.813027767485471
Validation loss: 2.8616155691469882

Epoch: 6| Step: 3
Training loss: 3.2193416310978438
Validation loss: 2.8661886641821783

Epoch: 6| Step: 4
Training loss: 3.4468174283709145
Validation loss: 2.8466006846066203

Epoch: 6| Step: 5
Training loss: 3.234976155165182
Validation loss: 2.8214971873027364

Epoch: 6| Step: 6
Training loss: 2.5427534771112454
Validation loss: 2.8237121978302175

Epoch: 6| Step: 7
Training loss: 2.606333164562287
Validation loss: 2.817567446300002

Epoch: 6| Step: 8
Training loss: 3.1956483995493747
Validation loss: 2.820139904465969

Epoch: 6| Step: 9
Training loss: 3.3119061495526747
Validation loss: 2.817079773559483

Epoch: 6| Step: 10
Training loss: 2.7369048704062258
Validation loss: 2.815579555746082

Epoch: 6| Step: 11
Training loss: 3.1309087205640322
Validation loss: 2.81850169808292

Epoch: 6| Step: 12
Training loss: 3.4169479502441553
Validation loss: 2.8193989990226127

Epoch: 6| Step: 13
Training loss: 2.9101944274446314
Validation loss: 2.820484414177394

Epoch: 126| Step: 0
Training loss: 2.340804627150723
Validation loss: 2.8193365958378656

Epoch: 6| Step: 1
Training loss: 2.854004866940065
Validation loss: 2.8153363135605973

Epoch: 6| Step: 2
Training loss: 3.7213164377224204
Validation loss: 2.818923679599319

Epoch: 6| Step: 3
Training loss: 3.9107511908076957
Validation loss: 2.815975458295613

Epoch: 6| Step: 4
Training loss: 2.9810216148434856
Validation loss: 2.8170184738582766

Epoch: 6| Step: 5
Training loss: 2.9129993452705882
Validation loss: 2.816851430202893

Epoch: 6| Step: 6
Training loss: 3.4131794012149332
Validation loss: 2.8148821587948016

Epoch: 6| Step: 7
Training loss: 3.0667128877335443
Validation loss: 2.8193118971509272

Epoch: 6| Step: 8
Training loss: 3.1379767492635215
Validation loss: 2.817515590096232

Epoch: 6| Step: 9
Training loss: 3.240645223350289
Validation loss: 2.8178614805512123

Epoch: 6| Step: 10
Training loss: 3.283862427295981
Validation loss: 2.8264365727903673

Epoch: 6| Step: 11
Training loss: 2.93945198946199
Validation loss: 2.8222171752463505

Epoch: 6| Step: 12
Training loss: 2.6329056811044413
Validation loss: 2.841579260988632

Epoch: 6| Step: 13
Training loss: 3.1043857437417897
Validation loss: 2.8328059089817046

Epoch: 127| Step: 0
Training loss: 2.8475589604758373
Validation loss: 2.8140458893497935

Epoch: 6| Step: 1
Training loss: 3.2883134654998596
Validation loss: 2.812666704166389

Epoch: 6| Step: 2
Training loss: 3.4215618669601806
Validation loss: 2.8124232109643756

Epoch: 6| Step: 3
Training loss: 3.0599027246708745
Validation loss: 2.8113896820538025

Epoch: 6| Step: 4
Training loss: 3.173428310153714
Validation loss: 2.8105343456781893

Epoch: 6| Step: 5
Training loss: 3.183400528549761
Validation loss: 2.8104836723205278

Epoch: 6| Step: 6
Training loss: 3.4431468013032362
Validation loss: 2.81358769940328

Epoch: 6| Step: 7
Training loss: 3.2325363461604026
Validation loss: 2.808707161175224

Epoch: 6| Step: 8
Training loss: 3.035290571502931
Validation loss: 2.8136321228674883

Epoch: 6| Step: 9
Training loss: 2.765412058418101
Validation loss: 2.822789032241643

Epoch: 6| Step: 10
Training loss: 2.9742605364233627
Validation loss: 2.8290818079737874

Epoch: 6| Step: 11
Training loss: 3.0019512188917177
Validation loss: 2.83671161460941

Epoch: 6| Step: 12
Training loss: 3.2604201604237386
Validation loss: 2.8440797279496546

Epoch: 6| Step: 13
Training loss: 2.8276195601356227
Validation loss: 2.845151652952117

Epoch: 128| Step: 0
Training loss: 3.5596079548335458
Validation loss: 2.835153341407839

Epoch: 6| Step: 1
Training loss: 2.465140976192076
Validation loss: 2.818326200904082

Epoch: 6| Step: 2
Training loss: 3.318830953928934
Validation loss: 2.8156971487299582

Epoch: 6| Step: 3
Training loss: 3.7537192656344605
Validation loss: 2.8102637567111355

Epoch: 6| Step: 4
Training loss: 2.8914843132573753
Validation loss: 2.8093552841233307

Epoch: 6| Step: 5
Training loss: 3.3404821666874724
Validation loss: 2.8100026280774717

Epoch: 6| Step: 6
Training loss: 2.905876545855976
Validation loss: 2.814866370070375

Epoch: 6| Step: 7
Training loss: 3.256414099601882
Validation loss: 2.8137462019895514

Epoch: 6| Step: 8
Training loss: 2.571235746011276
Validation loss: 2.815249687005695

Epoch: 6| Step: 9
Training loss: 2.8258192241754827
Validation loss: 2.818452465958975

Epoch: 6| Step: 10
Training loss: 3.2453970959161014
Validation loss: 2.8162946308145833

Epoch: 6| Step: 11
Training loss: 3.3563181609153263
Validation loss: 2.8112302805827074

Epoch: 6| Step: 12
Training loss: 3.0819060828413622
Validation loss: 2.8100311901466593

Epoch: 6| Step: 13
Training loss: 2.994115143808729
Validation loss: 2.8114056462331773

Epoch: 129| Step: 0
Training loss: 3.905583927587485
Validation loss: 2.8116457062131013

Epoch: 6| Step: 1
Training loss: 2.9440617422595485
Validation loss: 2.8053281844489475

Epoch: 6| Step: 2
Training loss: 3.3638074864153658
Validation loss: 2.806466419509529

Epoch: 6| Step: 3
Training loss: 3.066828102202579
Validation loss: 2.8082077297578234

Epoch: 6| Step: 4
Training loss: 2.9981739526712046
Validation loss: 2.8066490010454896

Epoch: 6| Step: 5
Training loss: 2.7281189768791347
Validation loss: 2.8193409168582724

Epoch: 6| Step: 6
Training loss: 3.0781578410763926
Validation loss: 2.8219940496575155

Epoch: 6| Step: 7
Training loss: 3.069502007667244
Validation loss: 2.8251148794013092

Epoch: 6| Step: 8
Training loss: 3.436874887674888
Validation loss: 2.8551590962593827

Epoch: 6| Step: 9
Training loss: 2.7467147971383645
Validation loss: 2.88140399693846

Epoch: 6| Step: 10
Training loss: 3.532190653328668
Validation loss: 2.8777091845372356

Epoch: 6| Step: 11
Training loss: 3.1797768770070687
Validation loss: 2.8388340751515924

Epoch: 6| Step: 12
Training loss: 2.41569004933564
Validation loss: 2.8238637844629997

Epoch: 6| Step: 13
Training loss: 2.7382338842194436
Validation loss: 2.8210854951394793

Epoch: 130| Step: 0
Training loss: 3.140039949345213
Validation loss: 2.8044003785755103

Epoch: 6| Step: 1
Training loss: 2.2571617165341524
Validation loss: 2.8100598157871106

Epoch: 6| Step: 2
Training loss: 2.6293169582191047
Validation loss: 2.8074926741616437

Epoch: 6| Step: 3
Training loss: 2.5103014422258263
Validation loss: 2.804916809837468

Epoch: 6| Step: 4
Training loss: 2.920678694509216
Validation loss: 2.8066832576239222

Epoch: 6| Step: 5
Training loss: 3.5368691357019495
Validation loss: 2.803590398458887

Epoch: 6| Step: 6
Training loss: 2.738019857296991
Validation loss: 2.8032369755195163

Epoch: 6| Step: 7
Training loss: 3.4987439217741225
Validation loss: 2.8054952864412597

Epoch: 6| Step: 8
Training loss: 3.7452223542926344
Validation loss: 2.8079283298258684

Epoch: 6| Step: 9
Training loss: 2.6894836202428687
Validation loss: 2.8004613694731466

Epoch: 6| Step: 10
Training loss: 3.704680940838642
Validation loss: 2.804061866943281

Epoch: 6| Step: 11
Training loss: 3.310217880960949
Validation loss: 2.803676112432148

Epoch: 6| Step: 12
Training loss: 3.5168444065778806
Validation loss: 2.8126384796724904

Epoch: 6| Step: 13
Training loss: 2.7080425008484204
Validation loss: 2.8212942056074413

Epoch: 131| Step: 0
Training loss: 3.058020916884086
Validation loss: 2.8405881349220636

Epoch: 6| Step: 1
Training loss: 3.1917527196320847
Validation loss: 2.834073427585966

Epoch: 6| Step: 2
Training loss: 3.2791758930184756
Validation loss: 2.8313052020221336

Epoch: 6| Step: 3
Training loss: 2.5455679318638587
Validation loss: 2.8633533355615146

Epoch: 6| Step: 4
Training loss: 2.7391585877750733
Validation loss: 2.8579158142820646

Epoch: 6| Step: 5
Training loss: 3.186695670577126
Validation loss: 2.8622595621989766

Epoch: 6| Step: 6
Training loss: 2.957747137170689
Validation loss: 2.86259599109075

Epoch: 6| Step: 7
Training loss: 2.844895519892427
Validation loss: 2.805682735578643

Epoch: 6| Step: 8
Training loss: 3.3859868122166223
Validation loss: 2.800050155128918

Epoch: 6| Step: 9
Training loss: 2.9661339728051574
Validation loss: 2.7959505552642354

Epoch: 6| Step: 10
Training loss: 2.46166932865413
Validation loss: 2.799040780261257

Epoch: 6| Step: 11
Training loss: 3.8278302760431244
Validation loss: 2.8044898687072792

Epoch: 6| Step: 12
Training loss: 3.605426693027324
Validation loss: 2.807069046392884

Epoch: 6| Step: 13
Training loss: 3.268237515422396
Validation loss: 2.8113719842958655

Epoch: 132| Step: 0
Training loss: 2.848190027348029
Validation loss: 2.8116889887234158

Epoch: 6| Step: 1
Training loss: 3.521910342806664
Validation loss: 2.819586782194675

Epoch: 6| Step: 2
Training loss: 3.311806948153956
Validation loss: 2.8140094056583056

Epoch: 6| Step: 3
Training loss: 3.1141547649245602
Validation loss: 2.80795506875115

Epoch: 6| Step: 4
Training loss: 3.324335797733699
Validation loss: 2.803834975087733

Epoch: 6| Step: 5
Training loss: 2.899153381942951
Validation loss: 2.8023775745770454

Epoch: 6| Step: 6
Training loss: 3.1477917939081377
Validation loss: 2.800329843992783

Epoch: 6| Step: 7
Training loss: 3.4513691714615002
Validation loss: 2.8012122414172174

Epoch: 6| Step: 8
Training loss: 2.9222891610927277
Validation loss: 2.8007871319079234

Epoch: 6| Step: 9
Training loss: 3.027742539258119
Validation loss: 2.7998058064238465

Epoch: 6| Step: 10
Training loss: 2.7643253699549484
Validation loss: 2.7986856698292772

Epoch: 6| Step: 11
Training loss: 3.060870612963207
Validation loss: 2.7956579239878057

Epoch: 6| Step: 12
Training loss: 3.043634344327954
Validation loss: 2.7953384540821524

Epoch: 6| Step: 13
Training loss: 3.170192779792321
Validation loss: 2.7944679702581467

Epoch: 133| Step: 0
Training loss: 3.4905647074547566
Validation loss: 2.8027652173530013

Epoch: 6| Step: 1
Training loss: 2.709448677653965
Validation loss: 2.807924966329138

Epoch: 6| Step: 2
Training loss: 3.111285212353156
Validation loss: 2.8087255182943576

Epoch: 6| Step: 3
Training loss: 2.904723884473658
Validation loss: 2.8091784608273294

Epoch: 6| Step: 4
Training loss: 3.561508442266897
Validation loss: 2.816494912652701

Epoch: 6| Step: 5
Training loss: 2.8999476855590847
Validation loss: 2.80982738288596

Epoch: 6| Step: 6
Training loss: 3.6645797657185692
Validation loss: 2.813100025702341

Epoch: 6| Step: 7
Training loss: 2.4334166142395413
Validation loss: 2.7910449026343187

Epoch: 6| Step: 8
Training loss: 3.0062978126070505
Validation loss: 2.788261572718578

Epoch: 6| Step: 9
Training loss: 3.1890534747985195
Validation loss: 2.7912671411364887

Epoch: 6| Step: 10
Training loss: 3.0084104265671154
Validation loss: 2.7905515746575253

Epoch: 6| Step: 11
Training loss: 2.860082986868119
Validation loss: 2.788836527854732

Epoch: 6| Step: 12
Training loss: 3.313062799974843
Validation loss: 2.7977268436232112

Epoch: 6| Step: 13
Training loss: 3.1348244919998454
Validation loss: 2.7885008155857323

Epoch: 134| Step: 0
Training loss: 2.8628782064132348
Validation loss: 2.7912965148650684

Epoch: 6| Step: 1
Training loss: 2.841137031427322
Validation loss: 2.7907783541035136

Epoch: 6| Step: 2
Training loss: 3.336733292083741
Validation loss: 2.7901797889062245

Epoch: 6| Step: 3
Training loss: 2.67691679756902
Validation loss: 2.7945351312755498

Epoch: 6| Step: 4
Training loss: 3.492301375817404
Validation loss: 2.7898371956733565

Epoch: 6| Step: 5
Training loss: 3.3789872529127245
Validation loss: 2.802208089165081

Epoch: 6| Step: 6
Training loss: 2.830032969575923
Validation loss: 2.793839667906186

Epoch: 6| Step: 7
Training loss: 2.689361105281708
Validation loss: 2.8011834384183962

Epoch: 6| Step: 8
Training loss: 3.255925279120787
Validation loss: 2.7999694877125174

Epoch: 6| Step: 9
Training loss: 2.67620267125079
Validation loss: 2.8099575669844272

Epoch: 6| Step: 10
Training loss: 3.430659197753098
Validation loss: 2.80821587198941

Epoch: 6| Step: 11
Training loss: 2.899014397555467
Validation loss: 2.821883723509938

Epoch: 6| Step: 12
Training loss: 3.8879851305327984
Validation loss: 2.8198810922709416

Epoch: 6| Step: 13
Training loss: 2.781368295961238
Validation loss: 2.7954364073483036

Epoch: 135| Step: 0
Training loss: 3.278967944808405
Validation loss: 2.7866018122451455

Epoch: 6| Step: 1
Training loss: 3.5245516552786595
Validation loss: 2.7998847278842174

Epoch: 6| Step: 2
Training loss: 3.251501763439683
Validation loss: 2.7888520861337107

Epoch: 6| Step: 3
Training loss: 3.097579127694972
Validation loss: 2.788103481474801

Epoch: 6| Step: 4
Training loss: 2.669584843223466
Validation loss: 2.7919853440578306

Epoch: 6| Step: 5
Training loss: 3.608246730149867
Validation loss: 2.7912903658970643

Epoch: 6| Step: 6
Training loss: 3.790075673980924
Validation loss: 2.79113331050924

Epoch: 6| Step: 7
Training loss: 2.673789426023365
Validation loss: 2.7879148522124084

Epoch: 6| Step: 8
Training loss: 2.6171557979656455
Validation loss: 2.793285466824002

Epoch: 6| Step: 9
Training loss: 2.274101868131818
Validation loss: 2.787190356669338

Epoch: 6| Step: 10
Training loss: 2.876306983088195
Validation loss: 2.7847108590526495

Epoch: 6| Step: 11
Training loss: 3.3980510623501328
Validation loss: 2.7878786307113996

Epoch: 6| Step: 12
Training loss: 3.127919473670102
Validation loss: 2.7904254582697305

Epoch: 6| Step: 13
Training loss: 2.7827949947468436
Validation loss: 2.789569328301316

Epoch: 136| Step: 0
Training loss: 3.1235415297755242
Validation loss: 2.790662732529695

Epoch: 6| Step: 1
Training loss: 2.871220301738995
Validation loss: 2.804231239400251

Epoch: 6| Step: 2
Training loss: 2.9898607256038368
Validation loss: 2.8049505026302293

Epoch: 6| Step: 3
Training loss: 3.63378604436686
Validation loss: 2.7904501976544758

Epoch: 6| Step: 4
Training loss: 3.150579665602678
Validation loss: 2.8080460661066153

Epoch: 6| Step: 5
Training loss: 3.4535791435048453
Validation loss: 2.800739244250838

Epoch: 6| Step: 6
Training loss: 3.223526752695221
Validation loss: 2.805718652305726

Epoch: 6| Step: 7
Training loss: 3.5363594831641536
Validation loss: 2.8024803322896332

Epoch: 6| Step: 8
Training loss: 2.241078172129699
Validation loss: 2.799784924044706

Epoch: 6| Step: 9
Training loss: 3.6726935590266208
Validation loss: 2.8139716296394157

Epoch: 6| Step: 10
Training loss: 2.768537894707669
Validation loss: 2.7985298172887396

Epoch: 6| Step: 11
Training loss: 3.2669759629891715
Validation loss: 2.7933478187302727

Epoch: 6| Step: 12
Training loss: 2.2765161178356776
Validation loss: 2.7880720217760695

Epoch: 6| Step: 13
Training loss: 2.534970786624194
Validation loss: 2.7878329536150432

Epoch: 137| Step: 0
Training loss: 3.204133410006308
Validation loss: 2.7875377577241305

Epoch: 6| Step: 1
Training loss: 3.264686413086785
Validation loss: 2.779673927228478

Epoch: 6| Step: 2
Training loss: 2.8246139735238636
Validation loss: 2.783835461667819

Epoch: 6| Step: 3
Training loss: 3.334887587269856
Validation loss: 2.783851447565919

Epoch: 6| Step: 4
Training loss: 3.2886356611395478
Validation loss: 2.784914652268021

Epoch: 6| Step: 5
Training loss: 3.1872265268332605
Validation loss: 2.7793370436543956

Epoch: 6| Step: 6
Training loss: 2.8424085869764366
Validation loss: 2.7783046897075376

Epoch: 6| Step: 7
Training loss: 3.378953666574813
Validation loss: 2.7812475997400106

Epoch: 6| Step: 8
Training loss: 3.4751670522810505
Validation loss: 2.79276567852877

Epoch: 6| Step: 9
Training loss: 3.380213913327604
Validation loss: 2.7889379800600786

Epoch: 6| Step: 10
Training loss: 2.3830666328363725
Validation loss: 2.7802406849474957

Epoch: 6| Step: 11
Training loss: 2.8719534281086623
Validation loss: 2.784193582163779

Epoch: 6| Step: 12
Training loss: 2.1933139378502706
Validation loss: 2.7833044684568033

Epoch: 6| Step: 13
Training loss: 3.5871338022724037
Validation loss: 2.7816853658935994

Epoch: 138| Step: 0
Training loss: 2.9240274100212647
Validation loss: 2.7779611090865024

Epoch: 6| Step: 1
Training loss: 3.4109979139247253
Validation loss: 2.780286971789524

Epoch: 6| Step: 2
Training loss: 3.8440229117418245
Validation loss: 2.775954222383638

Epoch: 6| Step: 3
Training loss: 3.1118589667991134
Validation loss: 2.782093295865447

Epoch: 6| Step: 4
Training loss: 2.4565298178284194
Validation loss: 2.784767549815678

Epoch: 6| Step: 5
Training loss: 3.336215362769218
Validation loss: 2.7827130928697144

Epoch: 6| Step: 6
Training loss: 2.6018110276842354
Validation loss: 2.7787523095962894

Epoch: 6| Step: 7
Training loss: 3.554575354515323
Validation loss: 2.7753047117679595

Epoch: 6| Step: 8
Training loss: 2.9878435200745805
Validation loss: 2.7752116237817246

Epoch: 6| Step: 9
Training loss: 2.741562557466133
Validation loss: 2.785370366010059

Epoch: 6| Step: 10
Training loss: 2.6634301472694086
Validation loss: 2.7770604297065278

Epoch: 6| Step: 11
Training loss: 2.947272581947969
Validation loss: 2.7886091473776213

Epoch: 6| Step: 12
Training loss: 2.540311629334736
Validation loss: 2.7891687299596244

Epoch: 6| Step: 13
Training loss: 4.125950328134052
Validation loss: 2.802827223916676

Epoch: 139| Step: 0
Training loss: 2.9879758192562336
Validation loss: 2.790977685645036

Epoch: 6| Step: 1
Training loss: 3.590545286882387
Validation loss: 2.8102019753546874

Epoch: 6| Step: 2
Training loss: 2.876679137443425
Validation loss: 2.822112124799471

Epoch: 6| Step: 3
Training loss: 2.7978375872251315
Validation loss: 2.808629707086744

Epoch: 6| Step: 4
Training loss: 2.7460960073448226
Validation loss: 2.8008875416582577

Epoch: 6| Step: 5
Training loss: 3.236195222546473
Validation loss: 2.7871299430326877

Epoch: 6| Step: 6
Training loss: 2.8078197956786477
Validation loss: 2.7859123273887376

Epoch: 6| Step: 7
Training loss: 3.282219153284928
Validation loss: 2.7793228627504387

Epoch: 6| Step: 8
Training loss: 2.6319531586255898
Validation loss: 2.7775975581810624

Epoch: 6| Step: 9
Training loss: 3.5850376836905697
Validation loss: 2.7738946371835236

Epoch: 6| Step: 10
Training loss: 3.4486047494185823
Validation loss: 2.7739795516187016

Epoch: 6| Step: 11
Training loss: 2.6951292113856904
Validation loss: 2.7733148279925484

Epoch: 6| Step: 12
Training loss: 3.0648195474346287
Validation loss: 2.7754861039142367

Epoch: 6| Step: 13
Training loss: 3.3918173666676283
Validation loss: 2.7758163323447933

Epoch: 140| Step: 0
Training loss: 3.369839148602077
Validation loss: 2.7775793276077168

Epoch: 6| Step: 1
Training loss: 3.429366042381116
Validation loss: 2.7747181180977942

Epoch: 6| Step: 2
Training loss: 2.164309931632615
Validation loss: 2.7728589358155094

Epoch: 6| Step: 3
Training loss: 2.830095984782328
Validation loss: 2.771324249925758

Epoch: 6| Step: 4
Training loss: 3.214762319319168
Validation loss: 2.7743987346551378

Epoch: 6| Step: 5
Training loss: 3.148909237641164
Validation loss: 2.778289508820027

Epoch: 6| Step: 6
Training loss: 2.8554251650551064
Validation loss: 2.775917335950101

Epoch: 6| Step: 7
Training loss: 3.069447014425438
Validation loss: 2.7769636192268483

Epoch: 6| Step: 8
Training loss: 3.271457993130566
Validation loss: 2.766734411529821

Epoch: 6| Step: 9
Training loss: 3.393070868163799
Validation loss: 2.7690870759429878

Epoch: 6| Step: 10
Training loss: 3.373725367848725
Validation loss: 2.7709027495298577

Epoch: 6| Step: 11
Training loss: 3.1455058417895874
Validation loss: 2.7697551207597337

Epoch: 6| Step: 12
Training loss: 3.1298055701759644
Validation loss: 2.7691303830115657

Epoch: 6| Step: 13
Training loss: 2.10546082334141
Validation loss: 2.792997411914578

Epoch: 141| Step: 0
Training loss: 2.2452249720960005
Validation loss: 2.8020081649330706

Epoch: 6| Step: 1
Training loss: 3.5051996572008304
Validation loss: 2.843932980583823

Epoch: 6| Step: 2
Training loss: 3.713870012160377
Validation loss: 2.877437801931711

Epoch: 6| Step: 3
Training loss: 3.643542909053597
Validation loss: 2.834411402120111

Epoch: 6| Step: 4
Training loss: 3.032816374047629
Validation loss: 2.7874800435749836

Epoch: 6| Step: 5
Training loss: 3.5892795787723593
Validation loss: 2.7732489427466316

Epoch: 6| Step: 6
Training loss: 2.7320291974586586
Validation loss: 2.7669714242276493

Epoch: 6| Step: 7
Training loss: 3.5041128244394995
Validation loss: 2.7647480196143457

Epoch: 6| Step: 8
Training loss: 3.187582875090668
Validation loss: 2.774511200332168

Epoch: 6| Step: 9
Training loss: 2.4800661736550516
Validation loss: 2.773282674546338

Epoch: 6| Step: 10
Training loss: 2.439924159512915
Validation loss: 2.772281377220966

Epoch: 6| Step: 11
Training loss: 3.0853579979023062
Validation loss: 2.771334740083951

Epoch: 6| Step: 12
Training loss: 2.9239315200697873
Validation loss: 2.771212089706623

Epoch: 6| Step: 13
Training loss: 2.8015098315775693
Validation loss: 2.770191894335688

Epoch: 142| Step: 0
Training loss: 2.994417081985853
Validation loss: 2.772281168229624

Epoch: 6| Step: 1
Training loss: 3.4238729697041768
Validation loss: 2.7747337758667703

Epoch: 6| Step: 2
Training loss: 3.120065837312187
Validation loss: 2.767616359187136

Epoch: 6| Step: 3
Training loss: 3.425272469924852
Validation loss: 2.7708219718715594

Epoch: 6| Step: 4
Training loss: 3.5135447132961812
Validation loss: 2.7675017384114406

Epoch: 6| Step: 5
Training loss: 2.54187982217797
Validation loss: 2.764067842560475

Epoch: 6| Step: 6
Training loss: 2.9512003121561747
Validation loss: 2.761225469552847

Epoch: 6| Step: 7
Training loss: 2.6830050115549184
Validation loss: 2.766574519338098

Epoch: 6| Step: 8
Training loss: 2.6797917737775196
Validation loss: 2.766402898812723

Epoch: 6| Step: 9
Training loss: 3.3571121046286843
Validation loss: 2.7618453650402315

Epoch: 6| Step: 10
Training loss: 3.447256772297415
Validation loss: 2.7672599954515067

Epoch: 6| Step: 11
Training loss: 2.7790504930760807
Validation loss: 2.7662579666246216

Epoch: 6| Step: 12
Training loss: 3.0910347476957294
Validation loss: 2.764891997110933

Epoch: 6| Step: 13
Training loss: 2.819435131097287
Validation loss: 2.768116547014262

Epoch: 143| Step: 0
Training loss: 2.7588635567929054
Validation loss: 2.7659040676056104

Epoch: 6| Step: 1
Training loss: 3.656169270985432
Validation loss: 2.7794994390859755

Epoch: 6| Step: 2
Training loss: 3.2531403261789253
Validation loss: 2.787182550367737

Epoch: 6| Step: 3
Training loss: 3.154752923930393
Validation loss: 2.7709091778155406

Epoch: 6| Step: 4
Training loss: 3.1508195446741447
Validation loss: 2.770744345123678

Epoch: 6| Step: 5
Training loss: 2.831630494274194
Validation loss: 2.7691221628861693

Epoch: 6| Step: 6
Training loss: 3.0652156389309666
Validation loss: 2.764922234251374

Epoch: 6| Step: 7
Training loss: 2.733937168490465
Validation loss: 2.763495357889469

Epoch: 6| Step: 8
Training loss: 3.1657485802225596
Validation loss: 2.762923370705589

Epoch: 6| Step: 9
Training loss: 3.3527952119138185
Validation loss: 2.758690395305968

Epoch: 6| Step: 10
Training loss: 3.0144613125739204
Validation loss: 2.7644485911007712

Epoch: 6| Step: 11
Training loss: 2.7762960826719594
Validation loss: 2.76230780718457

Epoch: 6| Step: 12
Training loss: 2.9582233318956956
Validation loss: 2.7575956362348255

Epoch: 6| Step: 13
Training loss: 3.1137437656360083
Validation loss: 2.758270362313905

Epoch: 144| Step: 0
Training loss: 3.014576625926358
Validation loss: 2.757966777292097

Epoch: 6| Step: 1
Training loss: 3.074355242363836
Validation loss: 2.758408395238915

Epoch: 6| Step: 2
Training loss: 2.9682493088781747
Validation loss: 2.7611389280186667

Epoch: 6| Step: 3
Training loss: 3.207376775121359
Validation loss: 2.7553618114417335

Epoch: 6| Step: 4
Training loss: 3.4449656478431443
Validation loss: 2.7600015372610427

Epoch: 6| Step: 5
Training loss: 3.7037007974683873
Validation loss: 2.7575607456800024

Epoch: 6| Step: 6
Training loss: 2.870449611522564
Validation loss: 2.759053800547003

Epoch: 6| Step: 7
Training loss: 3.653200752771639
Validation loss: 2.7579810977492603

Epoch: 6| Step: 8
Training loss: 2.3790591837515267
Validation loss: 2.7547901651244535

Epoch: 6| Step: 9
Training loss: 3.198480131892923
Validation loss: 2.755844210008271

Epoch: 6| Step: 10
Training loss: 2.9082162419952677
Validation loss: 2.7585328174749937

Epoch: 6| Step: 11
Training loss: 2.4753321530727725
Validation loss: 2.7560426134494507

Epoch: 6| Step: 12
Training loss: 2.546767343691423
Validation loss: 2.766006420250686

Epoch: 6| Step: 13
Training loss: 3.4132141875046043
Validation loss: 2.7692377492731723

Epoch: 145| Step: 0
Training loss: 2.6529631081153844
Validation loss: 2.7871056699601344

Epoch: 6| Step: 1
Training loss: 3.1832456433532954
Validation loss: 2.782969571964435

Epoch: 6| Step: 2
Training loss: 3.6274420306505215
Validation loss: 2.7754129476135128

Epoch: 6| Step: 3
Training loss: 3.0226349467781213
Validation loss: 2.759286519047677

Epoch: 6| Step: 4
Training loss: 3.52904367303889
Validation loss: 2.7572471924461257

Epoch: 6| Step: 5
Training loss: 2.621470303498406
Validation loss: 2.755826725791123

Epoch: 6| Step: 6
Training loss: 2.8991122629957173
Validation loss: 2.7568281112706914

Epoch: 6| Step: 7
Training loss: 3.509003366985646
Validation loss: 2.7583974599997534

Epoch: 6| Step: 8
Training loss: 3.010417177052878
Validation loss: 2.7593315835268903

Epoch: 6| Step: 9
Training loss: 3.060410078408196
Validation loss: 2.7600776567898877

Epoch: 6| Step: 10
Training loss: 3.0115361931437494
Validation loss: 2.7590015553944216

Epoch: 6| Step: 11
Training loss: 2.98093987537293
Validation loss: 2.7633234181001036

Epoch: 6| Step: 12
Training loss: 2.991500895236565
Validation loss: 2.7608438995113476

Epoch: 6| Step: 13
Training loss: 2.8773646374373376
Validation loss: 2.762840837069092

Epoch: 146| Step: 0
Training loss: 3.5475359733537264
Validation loss: 2.761245846946026

Epoch: 6| Step: 1
Training loss: 3.1789174940088993
Validation loss: 2.757298439730661

Epoch: 6| Step: 2
Training loss: 3.320784806711045
Validation loss: 2.7582321602984186

Epoch: 6| Step: 3
Training loss: 2.729565559724922
Validation loss: 2.7605275115412824

Epoch: 6| Step: 4
Training loss: 2.663458613081843
Validation loss: 2.7550277940807084

Epoch: 6| Step: 5
Training loss: 3.2037034419587833
Validation loss: 2.757112468295822

Epoch: 6| Step: 6
Training loss: 3.0961248357282183
Validation loss: 2.7565222199771116

Epoch: 6| Step: 7
Training loss: 3.169976027725986
Validation loss: 2.752967050492614

Epoch: 6| Step: 8
Training loss: 2.1116928364317125
Validation loss: 2.757162956569309

Epoch: 6| Step: 9
Training loss: 2.93802638106061
Validation loss: 2.758093945666993

Epoch: 6| Step: 10
Training loss: 3.325745784327578
Validation loss: 2.772292427846919

Epoch: 6| Step: 11
Training loss: 3.3735588670306744
Validation loss: 2.7633247419821676

Epoch: 6| Step: 12
Training loss: 2.8649742460840897
Validation loss: 2.765620589491753

Epoch: 6| Step: 13
Training loss: 3.441510444648541
Validation loss: 2.7819039909089684

Epoch: 147| Step: 0
Training loss: 3.076297585477
Validation loss: 2.7657597015801536

Epoch: 6| Step: 1
Training loss: 3.413162636611382
Validation loss: 2.765001411508093

Epoch: 6| Step: 2
Training loss: 2.748356067693759
Validation loss: 2.7668171171839733

Epoch: 6| Step: 3
Training loss: 2.90429621826657
Validation loss: 2.766284532827218

Epoch: 6| Step: 4
Training loss: 2.9010720014555647
Validation loss: 2.757145108788077

Epoch: 6| Step: 5
Training loss: 3.0971282085601155
Validation loss: 2.7694901050917924

Epoch: 6| Step: 6
Training loss: 2.927992999542706
Validation loss: 2.75983706747462

Epoch: 6| Step: 7
Training loss: 3.4087624339599785
Validation loss: 2.759381594537543

Epoch: 6| Step: 8
Training loss: 3.1506267347976156
Validation loss: 2.760616414293543

Epoch: 6| Step: 9
Training loss: 3.3233404736328964
Validation loss: 2.7561571192020784

Epoch: 6| Step: 10
Training loss: 3.2845181129990957
Validation loss: 2.7553776247955475

Epoch: 6| Step: 11
Training loss: 2.2120529973267318
Validation loss: 2.758551519637584

Epoch: 6| Step: 12
Training loss: 2.91478730461211
Validation loss: 2.754843914884846

Epoch: 6| Step: 13
Training loss: 3.623484985514164
Validation loss: 2.7524769535988534

Epoch: 148| Step: 0
Training loss: 3.400911820383171
Validation loss: 2.7539695223385774

Epoch: 6| Step: 1
Training loss: 2.7668046752182067
Validation loss: 2.767815008949023

Epoch: 6| Step: 2
Training loss: 3.3758340440791907
Validation loss: 2.7957494563922776

Epoch: 6| Step: 3
Training loss: 3.064234184190086
Validation loss: 2.773589654816219

Epoch: 6| Step: 4
Training loss: 2.614308062851709
Validation loss: 2.76797367361196

Epoch: 6| Step: 5
Training loss: 2.9494913341539117
Validation loss: 2.776491746758048

Epoch: 6| Step: 6
Training loss: 3.178758790202406
Validation loss: 2.791861765298996

Epoch: 6| Step: 7
Training loss: 2.9040899966247764
Validation loss: 2.7621800569021056

Epoch: 6| Step: 8
Training loss: 2.9116593748138544
Validation loss: 2.7607831962756104

Epoch: 6| Step: 9
Training loss: 3.2857502911650354
Validation loss: 2.7518857529366563

Epoch: 6| Step: 10
Training loss: 3.0148085047195607
Validation loss: 2.7499937381840893

Epoch: 6| Step: 11
Training loss: 3.644309344798536
Validation loss: 2.753012663535934

Epoch: 6| Step: 12
Training loss: 3.0951815289089932
Validation loss: 2.7524170698988897

Epoch: 6| Step: 13
Training loss: 2.367434246435125
Validation loss: 2.7537965474430974

Epoch: 149| Step: 0
Training loss: 3.0852442481792024
Validation loss: 2.7527150411489782

Epoch: 6| Step: 1
Training loss: 3.212109576891791
Validation loss: 2.752045075143647

Epoch: 6| Step: 2
Training loss: 2.6608226238369332
Validation loss: 2.754612192869492

Epoch: 6| Step: 3
Training loss: 2.1634537153836173
Validation loss: 2.7554909291566205

Epoch: 6| Step: 4
Training loss: 2.8244293683080977
Validation loss: 2.752070520046737

Epoch: 6| Step: 5
Training loss: 3.9510347773422065
Validation loss: 2.75391739670147

Epoch: 6| Step: 6
Training loss: 3.869430723680967
Validation loss: 2.7487980359034467

Epoch: 6| Step: 7
Training loss: 2.7751534325049656
Validation loss: 2.749820522518564

Epoch: 6| Step: 8
Training loss: 3.013401615190646
Validation loss: 2.7488906073174912

Epoch: 6| Step: 9
Training loss: 2.8714434975112106
Validation loss: 2.7447327653841054

Epoch: 6| Step: 10
Training loss: 2.948589737868044
Validation loss: 2.74444332847934

Epoch: 6| Step: 11
Training loss: 3.45447358599652
Validation loss: 2.749953417789009

Epoch: 6| Step: 12
Training loss: 2.807188486292077
Validation loss: 2.7473438538929296

Epoch: 6| Step: 13
Training loss: 3.05239383997165
Validation loss: 2.745178729302773

Epoch: 150| Step: 0
Training loss: 3.2537280488418685
Validation loss: 2.7457975680245483

Epoch: 6| Step: 1
Training loss: 3.0875059367134376
Validation loss: 2.74535783229544

Epoch: 6| Step: 2
Training loss: 2.4592638894639265
Validation loss: 2.75754285027052

Epoch: 6| Step: 3
Training loss: 2.613859058587823
Validation loss: 2.794091171138703

Epoch: 6| Step: 4
Training loss: 3.537134988777359
Validation loss: 2.811601176595133

Epoch: 6| Step: 5
Training loss: 3.3368964860434818
Validation loss: 2.824724845579409

Epoch: 6| Step: 6
Training loss: 2.7863439994005774
Validation loss: 2.840514033005993

Epoch: 6| Step: 7
Training loss: 2.69818828693223
Validation loss: 2.836631554149035

Epoch: 6| Step: 8
Training loss: 2.703442946241019
Validation loss: 2.8306724031788333

Epoch: 6| Step: 9
Training loss: 3.566072245706287
Validation loss: 2.785275035398955

Epoch: 6| Step: 10
Training loss: 3.0283508594476762
Validation loss: 2.7576391888451135

Epoch: 6| Step: 11
Training loss: 3.427624196947216
Validation loss: 2.7425383123798905

Epoch: 6| Step: 12
Training loss: 3.4315597533334956
Validation loss: 2.7435634533456517

Epoch: 6| Step: 13
Training loss: 2.7011308315245395
Validation loss: 2.7460433392164427

Epoch: 151| Step: 0
Training loss: 3.4356128020518493
Validation loss: 2.7416772967562397

Epoch: 6| Step: 1
Training loss: 2.734269581533747
Validation loss: 2.7394716771975323

Epoch: 6| Step: 2
Training loss: 3.3976266880288737
Validation loss: 2.7418929736143416

Epoch: 6| Step: 3
Training loss: 2.437219163415305
Validation loss: 2.7415017050280186

Epoch: 6| Step: 4
Training loss: 3.664605919857081
Validation loss: 2.7487680485468284

Epoch: 6| Step: 5
Training loss: 2.681957206737414
Validation loss: 2.745817217757066

Epoch: 6| Step: 6
Training loss: 3.3693781053079097
Validation loss: 2.757020970763177

Epoch: 6| Step: 7
Training loss: 3.3643628373936934
Validation loss: 2.746378601430636

Epoch: 6| Step: 8
Training loss: 2.8756814232049615
Validation loss: 2.7545459365972293

Epoch: 6| Step: 9
Training loss: 3.244566557021806
Validation loss: 2.752271266167227

Epoch: 6| Step: 10
Training loss: 2.930720846407148
Validation loss: 2.7524274644629187

Epoch: 6| Step: 11
Training loss: 2.6851130686560083
Validation loss: 2.736101970827729

Epoch: 6| Step: 12
Training loss: 2.875195040513964
Validation loss: 2.7331241438577187

Epoch: 6| Step: 13
Training loss: 2.7810603730782355
Validation loss: 2.735576003751147

Epoch: 152| Step: 0
Training loss: 2.4003797985605626
Validation loss: 2.7315181742536243

Epoch: 6| Step: 1
Training loss: 3.5149699639329883
Validation loss: 2.7361139995994943

Epoch: 6| Step: 2
Training loss: 3.1572569194623936
Validation loss: 2.7396430646121916

Epoch: 6| Step: 3
Training loss: 3.2005099903457923
Validation loss: 2.744136995539336

Epoch: 6| Step: 4
Training loss: 3.223819629025216
Validation loss: 2.7378313890104935

Epoch: 6| Step: 5
Training loss: 2.5967842646239006
Validation loss: 2.745312319921238

Epoch: 6| Step: 6
Training loss: 2.6092712016218784
Validation loss: 2.757067360106253

Epoch: 6| Step: 7
Training loss: 3.4631899700531528
Validation loss: 2.76217806422302

Epoch: 6| Step: 8
Training loss: 3.2480575919189554
Validation loss: 2.7717126719635505

Epoch: 6| Step: 9
Training loss: 2.9233693264260956
Validation loss: 2.7846209882954183

Epoch: 6| Step: 10
Training loss: 3.036858629872255
Validation loss: 2.7520875996254954

Epoch: 6| Step: 11
Training loss: 3.3132320530824946
Validation loss: 2.738954582728049

Epoch: 6| Step: 12
Training loss: 2.698163722054001
Validation loss: 2.7318500577030154

Epoch: 6| Step: 13
Training loss: 3.3381907516200537
Validation loss: 2.7313898783754387

Epoch: 153| Step: 0
Training loss: 2.889954195286578
Validation loss: 2.737056248981495

Epoch: 6| Step: 1
Training loss: 2.656437586724116
Validation loss: 2.7340645581351466

Epoch: 6| Step: 2
Training loss: 3.13877426958443
Validation loss: 2.7418066016809077

Epoch: 6| Step: 3
Training loss: 3.6137299130230174
Validation loss: 2.7383859129989796

Epoch: 6| Step: 4
Training loss: 3.3453867106288837
Validation loss: 2.7357952951810485

Epoch: 6| Step: 5
Training loss: 3.561409498922941
Validation loss: 2.7379251196177075

Epoch: 6| Step: 6
Training loss: 2.8362525785929567
Validation loss: 2.733966182026301

Epoch: 6| Step: 7
Training loss: 3.097355138856565
Validation loss: 2.7261130721822187

Epoch: 6| Step: 8
Training loss: 3.275659357919559
Validation loss: 2.7312475045123468

Epoch: 6| Step: 9
Training loss: 2.5005753808698903
Validation loss: 2.7425793400326275

Epoch: 6| Step: 10
Training loss: 2.798543847734763
Validation loss: 2.7433375713660695

Epoch: 6| Step: 11
Training loss: 2.9652091342704545
Validation loss: 2.760324461672638

Epoch: 6| Step: 12
Training loss: 2.7796647772629526
Validation loss: 2.7394886472270747

Epoch: 6| Step: 13
Training loss: 3.3947655494873765
Validation loss: 2.739556637184771

Epoch: 154| Step: 0
Training loss: 3.054512038399032
Validation loss: 2.7284002495271897

Epoch: 6| Step: 1
Training loss: 2.75829572469498
Validation loss: 2.7337874692811877

Epoch: 6| Step: 2
Training loss: 2.7994505888197354
Validation loss: 2.7329764375380345

Epoch: 6| Step: 3
Training loss: 2.8726143268247326
Validation loss: 2.73084703904818

Epoch: 6| Step: 4
Training loss: 3.8985558990662854
Validation loss: 2.731750510415727

Epoch: 6| Step: 5
Training loss: 3.2119275722294933
Validation loss: 2.7381038609777004

Epoch: 6| Step: 6
Training loss: 3.2977212841179604
Validation loss: 2.7310910110377904

Epoch: 6| Step: 7
Training loss: 2.8543234640522024
Validation loss: 2.7291691778591476

Epoch: 6| Step: 8
Training loss: 2.8130016303411995
Validation loss: 2.729102594155325

Epoch: 6| Step: 9
Training loss: 2.6774314525388756
Validation loss: 2.73428133802661

Epoch: 6| Step: 10
Training loss: 2.9345344020785347
Validation loss: 2.7551112531332906

Epoch: 6| Step: 11
Training loss: 3.2975581758470467
Validation loss: 2.7741015861519074

Epoch: 6| Step: 12
Training loss: 2.895931342865423
Validation loss: 2.776169702836071

Epoch: 6| Step: 13
Training loss: 3.4212533046384497
Validation loss: 2.7936776729321675

Epoch: 155| Step: 0
Training loss: 3.4711632109669535
Validation loss: 2.813521402308531

Epoch: 6| Step: 1
Training loss: 2.9662066356577252
Validation loss: 2.7803379751279853

Epoch: 6| Step: 2
Training loss: 2.161319909010342
Validation loss: 2.7525836557576877

Epoch: 6| Step: 3
Training loss: 2.957008835419093
Validation loss: 2.7391778583551862

Epoch: 6| Step: 4
Training loss: 2.951016758415185
Validation loss: 2.7306453985638086

Epoch: 6| Step: 5
Training loss: 3.1143948467126754
Validation loss: 2.728802782974866

Epoch: 6| Step: 6
Training loss: 3.1227582901962263
Validation loss: 2.729220564428296

Epoch: 6| Step: 7
Training loss: 2.184636667102458
Validation loss: 2.731879867598285

Epoch: 6| Step: 8
Training loss: 3.2698881075319393
Validation loss: 2.733686031613418

Epoch: 6| Step: 9
Training loss: 3.430514920123144
Validation loss: 2.7351684656645516

Epoch: 6| Step: 10
Training loss: 2.9049213612823284
Validation loss: 2.728939179050582

Epoch: 6| Step: 11
Training loss: 3.219512849054883
Validation loss: 2.7256520898023844

Epoch: 6| Step: 12
Training loss: 3.8801855031137644
Validation loss: 2.732516490121436

Epoch: 6| Step: 13
Training loss: 2.8643640237723194
Validation loss: 2.728007760875492

Epoch: 156| Step: 0
Training loss: 2.513902631362624
Validation loss: 2.7383399842275575

Epoch: 6| Step: 1
Training loss: 2.689530160281298
Validation loss: 2.747063294622767

Epoch: 6| Step: 2
Training loss: 3.43557074767857
Validation loss: 2.753400055260289

Epoch: 6| Step: 3
Training loss: 2.961962197978877
Validation loss: 2.764386392327273

Epoch: 6| Step: 4
Training loss: 2.5360386140212143
Validation loss: 2.7762482739840006

Epoch: 6| Step: 5
Training loss: 3.180910367391835
Validation loss: 2.790412425170825

Epoch: 6| Step: 6
Training loss: 3.7528855983537595
Validation loss: 2.7686008234016453

Epoch: 6| Step: 7
Training loss: 2.8461674067358596
Validation loss: 2.737491014703432

Epoch: 6| Step: 8
Training loss: 3.150272563465119
Validation loss: 2.727709958121472

Epoch: 6| Step: 9
Training loss: 3.340804897563823
Validation loss: 2.724750543281103

Epoch: 6| Step: 10
Training loss: 3.306258457223499
Validation loss: 2.721348721007672

Epoch: 6| Step: 11
Training loss: 2.721259876911426
Validation loss: 2.723498720436387

Epoch: 6| Step: 12
Training loss: 2.7284405642693126
Validation loss: 2.72360424988222

Epoch: 6| Step: 13
Training loss: 3.5660676993952207
Validation loss: 2.725764453425077

Epoch: 157| Step: 0
Training loss: 3.4194826446418523
Validation loss: 2.7227423989677524

Epoch: 6| Step: 1
Training loss: 2.914773235628583
Validation loss: 2.7268884395063897

Epoch: 6| Step: 2
Training loss: 2.580875386170679
Validation loss: 2.7232840466241313

Epoch: 6| Step: 3
Training loss: 2.5191766533720448
Validation loss: 2.7269478948149586

Epoch: 6| Step: 4
Training loss: 2.91330772627249
Validation loss: 2.730570490265163

Epoch: 6| Step: 5
Training loss: 4.043590022464616
Validation loss: 2.7302718919199243

Epoch: 6| Step: 6
Training loss: 3.4200671571975323
Validation loss: 2.7374046106407803

Epoch: 6| Step: 7
Training loss: 3.0921734732935713
Validation loss: 2.730426959183708

Epoch: 6| Step: 8
Training loss: 2.66001230710273
Validation loss: 2.7335150997652713

Epoch: 6| Step: 9
Training loss: 3.282623439539325
Validation loss: 2.7328382645367055

Epoch: 6| Step: 10
Training loss: 2.476292544311889
Validation loss: 2.726434838814382

Epoch: 6| Step: 11
Training loss: 2.497808354065403
Validation loss: 2.720725464277706

Epoch: 6| Step: 12
Training loss: 2.9620869602108364
Validation loss: 2.7305645237632556

Epoch: 6| Step: 13
Training loss: 3.6842119460712652
Validation loss: 2.722697706247218

Epoch: 158| Step: 0
Training loss: 3.1160410826084144
Validation loss: 2.7308870003695422

Epoch: 6| Step: 1
Training loss: 2.0463444844909526
Validation loss: 2.7316219889464293

Epoch: 6| Step: 2
Training loss: 3.3642157165816986
Validation loss: 2.745147394042917

Epoch: 6| Step: 3
Training loss: 3.3520426372920915
Validation loss: 2.733461245728499

Epoch: 6| Step: 4
Training loss: 2.2103432439701645
Validation loss: 2.7261250002078805

Epoch: 6| Step: 5
Training loss: 3.3109299879722474
Validation loss: 2.7203400153459882

Epoch: 6| Step: 6
Training loss: 2.797300423601582
Validation loss: 2.730107603084953

Epoch: 6| Step: 7
Training loss: 3.1328899725945214
Validation loss: 2.7267057719258245

Epoch: 6| Step: 8
Training loss: 3.3530392538947678
Validation loss: 2.7169652966713698

Epoch: 6| Step: 9
Training loss: 2.941894490728734
Validation loss: 2.721416722822126

Epoch: 6| Step: 10
Training loss: 3.4835032925065263
Validation loss: 2.721040396724512

Epoch: 6| Step: 11
Training loss: 2.73751415440632
Validation loss: 2.7182664159434546

Epoch: 6| Step: 12
Training loss: 3.054439134574275
Validation loss: 2.7156320518823978

Epoch: 6| Step: 13
Training loss: 3.474585358835284
Validation loss: 2.722117638987422

Epoch: 159| Step: 0
Training loss: 3.141957318312917
Validation loss: 2.7255469190033748

Epoch: 6| Step: 1
Training loss: 3.0261615635312253
Validation loss: 2.715195207029495

Epoch: 6| Step: 2
Training loss: 2.674389999572241
Validation loss: 2.712141063386946

Epoch: 6| Step: 3
Training loss: 3.252402517982215
Validation loss: 2.7135345255452488

Epoch: 6| Step: 4
Training loss: 2.618586926173962
Validation loss: 2.711802992080022

Epoch: 6| Step: 5
Training loss: 2.470086906695722
Validation loss: 2.7158127692613423

Epoch: 6| Step: 6
Training loss: 3.250188968740053
Validation loss: 2.720159801369421

Epoch: 6| Step: 7
Training loss: 2.9302684970776687
Validation loss: 2.719557999810114

Epoch: 6| Step: 8
Training loss: 2.988579948306867
Validation loss: 2.71972166752343

Epoch: 6| Step: 9
Training loss: 3.1123109691162685
Validation loss: 2.719853900433641

Epoch: 6| Step: 10
Training loss: 3.0440822224183206
Validation loss: 2.717278599690395

Epoch: 6| Step: 11
Training loss: 3.1835739790413693
Validation loss: 2.718144690890482

Epoch: 6| Step: 12
Training loss: 3.282953601185094
Validation loss: 2.729194007541826

Epoch: 6| Step: 13
Training loss: 3.5608386800594767
Validation loss: 2.726822230233156

Epoch: 160| Step: 0
Training loss: 2.4945690291949143
Validation loss: 2.7282141913315456

Epoch: 6| Step: 1
Training loss: 3.2490294547866583
Validation loss: 2.7257779367109145

Epoch: 6| Step: 2
Training loss: 3.205606532081782
Validation loss: 2.730888372832653

Epoch: 6| Step: 3
Training loss: 2.677982243724756
Validation loss: 2.7399550891076143

Epoch: 6| Step: 4
Training loss: 3.1254858020831637
Validation loss: 2.7311666963516346

Epoch: 6| Step: 5
Training loss: 2.853095825982073
Validation loss: 2.742352430008339

Epoch: 6| Step: 6
Training loss: 2.2982538975890376
Validation loss: 2.746967865577849

Epoch: 6| Step: 7
Training loss: 2.5726997397297775
Validation loss: 2.760950257885927

Epoch: 6| Step: 8
Training loss: 3.569153311632673
Validation loss: 2.7495916404578926

Epoch: 6| Step: 9
Training loss: 3.7724978459720515
Validation loss: 2.7286318327187096

Epoch: 6| Step: 10
Training loss: 3.459343881303408
Validation loss: 2.709434868989833

Epoch: 6| Step: 11
Training loss: 2.7079341202953255
Validation loss: 2.71098909124756

Epoch: 6| Step: 12
Training loss: 3.397638196232789
Validation loss: 2.7102791705342724

Epoch: 6| Step: 13
Training loss: 2.6330036580675724
Validation loss: 2.7148781243744424

Epoch: 161| Step: 0
Training loss: 3.1316437860058732
Validation loss: 2.7145775798549994

Epoch: 6| Step: 1
Training loss: 3.0369297575503653
Validation loss: 2.7182428200210436

Epoch: 6| Step: 2
Training loss: 3.511710874487137
Validation loss: 2.7199088712446042

Epoch: 6| Step: 3
Training loss: 3.487395341731598
Validation loss: 2.715809076455602

Epoch: 6| Step: 4
Training loss: 3.0834901786983053
Validation loss: 2.7182343120841534

Epoch: 6| Step: 5
Training loss: 3.1342733501712563
Validation loss: 2.716394323504096

Epoch: 6| Step: 6
Training loss: 2.638770722091461
Validation loss: 2.7100509050078516

Epoch: 6| Step: 7
Training loss: 2.452158743693495
Validation loss: 2.709221205147943

Epoch: 6| Step: 8
Training loss: 3.2478542580439385
Validation loss: 2.7111570368619606

Epoch: 6| Step: 9
Training loss: 2.9310301285454092
Validation loss: 2.7052755669158213

Epoch: 6| Step: 10
Training loss: 2.66318074509801
Validation loss: 2.7060856029162195

Epoch: 6| Step: 11
Training loss: 2.9755141447074327
Validation loss: 2.711469120995058

Epoch: 6| Step: 12
Training loss: 3.0751914360189128
Validation loss: 2.7256114855040576

Epoch: 6| Step: 13
Training loss: 3.036550861778777
Validation loss: 2.7545505937883568

Epoch: 162| Step: 0
Training loss: 2.4766959265738535
Validation loss: 2.753711917408628

Epoch: 6| Step: 1
Training loss: 3.2136323113334373
Validation loss: 2.7758187474604004

Epoch: 6| Step: 2
Training loss: 2.6466288734767667
Validation loss: 2.7737964860551347

Epoch: 6| Step: 3
Training loss: 3.597720664376521
Validation loss: 2.7450097580316077

Epoch: 6| Step: 4
Training loss: 2.8989073174653077
Validation loss: 2.706442436161539

Epoch: 6| Step: 5
Training loss: 2.8230810551562158
Validation loss: 2.713663756276952

Epoch: 6| Step: 6
Training loss: 3.447373238847921
Validation loss: 2.715960287646473

Epoch: 6| Step: 7
Training loss: 2.7804389371074847
Validation loss: 2.7202567608243466

Epoch: 6| Step: 8
Training loss: 2.862866547283284
Validation loss: 2.7308661720776057

Epoch: 6| Step: 9
Training loss: 3.7529999495358135
Validation loss: 2.7524990983345163

Epoch: 6| Step: 10
Training loss: 3.46602489204075
Validation loss: 2.7511108453728625

Epoch: 6| Step: 11
Training loss: 2.68471107377537
Validation loss: 2.732859967098241

Epoch: 6| Step: 12
Training loss: 3.0974284180874596
Validation loss: 2.7227967738393684

Epoch: 6| Step: 13
Training loss: 2.5750095848719896
Validation loss: 2.7206840646681516

Epoch: 163| Step: 0
Training loss: 3.326997951175574
Validation loss: 2.71865257095211

Epoch: 6| Step: 1
Training loss: 3.308050369986257
Validation loss: 2.71817597432701

Epoch: 6| Step: 2
Training loss: 3.343208625676077
Validation loss: 2.7169178574486503

Epoch: 6| Step: 3
Training loss: 2.827912886447346
Validation loss: 2.7140603066538604

Epoch: 6| Step: 4
Training loss: 3.269001944115715
Validation loss: 2.7119518393215256

Epoch: 6| Step: 5
Training loss: 2.706461000035721
Validation loss: 2.7117088057303818

Epoch: 6| Step: 6
Training loss: 3.267761991427342
Validation loss: 2.7148099049520997

Epoch: 6| Step: 7
Training loss: 2.7731728870795815
Validation loss: 2.708002486423638

Epoch: 6| Step: 8
Training loss: 3.6295189150390805
Validation loss: 2.7090198949748165

Epoch: 6| Step: 9
Training loss: 3.032249050087709
Validation loss: 2.7084541754508233

Epoch: 6| Step: 10
Training loss: 2.321652523179343
Validation loss: 2.706816337563637

Epoch: 6| Step: 11
Training loss: 2.747763764873183
Validation loss: 2.714082097027591

Epoch: 6| Step: 12
Training loss: 2.8895986023499245
Validation loss: 2.706934920151351

Epoch: 6| Step: 13
Training loss: 2.8353402005287434
Validation loss: 2.70780698869425

Epoch: 164| Step: 0
Training loss: 2.7949409830758416
Validation loss: 2.7011351280924036

Epoch: 6| Step: 1
Training loss: 3.307521461653623
Validation loss: 2.708187699168947

Epoch: 6| Step: 2
Training loss: 2.800559914327889
Validation loss: 2.710148783282384

Epoch: 6| Step: 3
Training loss: 2.974813272722905
Validation loss: 2.7229193943695216

Epoch: 6| Step: 4
Training loss: 3.038246496329904
Validation loss: 2.7345016211097075

Epoch: 6| Step: 5
Training loss: 3.4388577640777203
Validation loss: 2.764408845068154

Epoch: 6| Step: 6
Training loss: 2.9269186134192524
Validation loss: 2.7707928446321106

Epoch: 6| Step: 7
Training loss: 3.34094177399964
Validation loss: 2.775703678489307

Epoch: 6| Step: 8
Training loss: 2.976181846969447
Validation loss: 2.7326140046484575

Epoch: 6| Step: 9
Training loss: 2.8150413052118486
Validation loss: 2.7168686405970295

Epoch: 6| Step: 10
Training loss: 2.833192784432391
Validation loss: 2.7009231730141847

Epoch: 6| Step: 11
Training loss: 2.774907026365814
Validation loss: 2.7067827511000933

Epoch: 6| Step: 12
Training loss: 3.372949754545996
Validation loss: 2.702939395767021

Epoch: 6| Step: 13
Training loss: 3.046681559364208
Validation loss: 2.70587967758743

Epoch: 165| Step: 0
Training loss: 3.136371674106436
Validation loss: 2.6983265887044166

Epoch: 6| Step: 1
Training loss: 2.8844242707546095
Validation loss: 2.6974195370035385

Epoch: 6| Step: 2
Training loss: 2.8585634174181562
Validation loss: 2.701553432261229

Epoch: 6| Step: 3
Training loss: 3.085424916636075
Validation loss: 2.701635850206807

Epoch: 6| Step: 4
Training loss: 2.9610373447463343
Validation loss: 2.7017786382592037

Epoch: 6| Step: 5
Training loss: 3.1782193180218488
Validation loss: 2.6989661388908326

Epoch: 6| Step: 6
Training loss: 3.2064385371703863
Validation loss: 2.6982745197230096

Epoch: 6| Step: 7
Training loss: 3.002019202672243
Validation loss: 2.698637531832434

Epoch: 6| Step: 8
Training loss: 2.5568713265492624
Validation loss: 2.7248979061465004

Epoch: 6| Step: 9
Training loss: 2.3955100021010174
Validation loss: 2.7193039030590094

Epoch: 6| Step: 10
Training loss: 3.324002143446028
Validation loss: 2.7470650201636584

Epoch: 6| Step: 11
Training loss: 3.5094884594234204
Validation loss: 2.7708051937456064

Epoch: 6| Step: 12
Training loss: 2.824621401373322
Validation loss: 2.7647382676022554

Epoch: 6| Step: 13
Training loss: 3.471470221572926
Validation loss: 2.783473122868698

Epoch: 166| Step: 0
Training loss: 3.271221712869823
Validation loss: 2.7765603185391865

Epoch: 6| Step: 1
Training loss: 3.0540364930296486
Validation loss: 2.7356682550827345

Epoch: 6| Step: 2
Training loss: 3.275220289902298
Validation loss: 2.715072517143435

Epoch: 6| Step: 3
Training loss: 2.7533231943173186
Validation loss: 2.6994840926255868

Epoch: 6| Step: 4
Training loss: 3.2414997152634046
Validation loss: 2.6982240307394223

Epoch: 6| Step: 5
Training loss: 3.021791468415527
Validation loss: 2.6925772078858023

Epoch: 6| Step: 6
Training loss: 3.0351122603794196
Validation loss: 2.70109155277585

Epoch: 6| Step: 7
Training loss: 2.659150368945289
Validation loss: 2.696947941953215

Epoch: 6| Step: 8
Training loss: 3.3516518463105553
Validation loss: 2.6964030442963196

Epoch: 6| Step: 9
Training loss: 3.109025178333118
Validation loss: 2.694944692670451

Epoch: 6| Step: 10
Training loss: 3.3336925948771388
Validation loss: 2.695397231672593

Epoch: 6| Step: 11
Training loss: 2.6196117503661207
Validation loss: 2.7015546924672758

Epoch: 6| Step: 12
Training loss: 2.4491938296180362
Validation loss: 2.705684728574432

Epoch: 6| Step: 13
Training loss: 3.2704134791094566
Validation loss: 2.7008246443164796

Epoch: 167| Step: 0
Training loss: 3.010594733404633
Validation loss: 2.712866023151951

Epoch: 6| Step: 1
Training loss: 2.6585166684572137
Validation loss: 2.715181472911631

Epoch: 6| Step: 2
Training loss: 2.7714302643755317
Validation loss: 2.7154589252528054

Epoch: 6| Step: 3
Training loss: 2.987724302163321
Validation loss: 2.7144150281010644

Epoch: 6| Step: 4
Training loss: 2.9677168805280587
Validation loss: 2.7118212469953664

Epoch: 6| Step: 5
Training loss: 3.7558760064878127
Validation loss: 2.6980393436040484

Epoch: 6| Step: 6
Training loss: 2.9708633128860944
Validation loss: 2.694267327351426

Epoch: 6| Step: 7
Training loss: 3.4227516758339083
Validation loss: 2.692896038680629

Epoch: 6| Step: 8
Training loss: 2.6192683360164435
Validation loss: 2.694066103530182

Epoch: 6| Step: 9
Training loss: 3.199829490410418
Validation loss: 2.693664902289219

Epoch: 6| Step: 10
Training loss: 2.8278382719756006
Validation loss: 2.6941255590360655

Epoch: 6| Step: 11
Training loss: 3.1345194972495696
Validation loss: 2.695120819300211

Epoch: 6| Step: 12
Training loss: 2.658498911549057
Validation loss: 2.6920939018774854

Epoch: 6| Step: 13
Training loss: 3.3966194288308964
Validation loss: 2.6905238926966413

Epoch: 168| Step: 0
Training loss: 3.2620140444548524
Validation loss: 2.6943772243494255

Epoch: 6| Step: 1
Training loss: 3.515864792169404
Validation loss: 2.6926636279885594

Epoch: 6| Step: 2
Training loss: 2.8254191062416787
Validation loss: 2.694216529196468

Epoch: 6| Step: 3
Training loss: 3.14450638091874
Validation loss: 2.6986475664092775

Epoch: 6| Step: 4
Training loss: 2.8429617994642298
Validation loss: 2.7024424564498095

Epoch: 6| Step: 5
Training loss: 3.367493369953338
Validation loss: 2.7123337458955983

Epoch: 6| Step: 6
Training loss: 3.1615062795875613
Validation loss: 2.7106527810385894

Epoch: 6| Step: 7
Training loss: 2.7174126854760274
Validation loss: 2.694969781550226

Epoch: 6| Step: 8
Training loss: 2.9764881675429917
Validation loss: 2.6985454585968833

Epoch: 6| Step: 9
Training loss: 2.8465356283231356
Validation loss: 2.6908365453909386

Epoch: 6| Step: 10
Training loss: 2.601900554149382
Validation loss: 2.6991017812243534

Epoch: 6| Step: 11
Training loss: 2.817260612601178
Validation loss: 2.6945351669700774

Epoch: 6| Step: 12
Training loss: 2.7624772256456147
Validation loss: 2.6990207268070274

Epoch: 6| Step: 13
Training loss: 3.575907190633301
Validation loss: 2.6942290722982665

Epoch: 169| Step: 0
Training loss: 2.789220725307713
Validation loss: 2.692787352206409

Epoch: 6| Step: 1
Training loss: 3.4028617035426962
Validation loss: 2.6892952404356634

Epoch: 6| Step: 2
Training loss: 3.0884088205690565
Validation loss: 2.6876844632335004

Epoch: 6| Step: 3
Training loss: 2.713208832832951
Validation loss: 2.688089854019693

Epoch: 6| Step: 4
Training loss: 3.2900652953744167
Validation loss: 2.691957255035148

Epoch: 6| Step: 5
Training loss: 2.7959905323419463
Validation loss: 2.6904522667087676

Epoch: 6| Step: 6
Training loss: 2.4192874991366784
Validation loss: 2.6900405541927457

Epoch: 6| Step: 7
Training loss: 2.9979492171594555
Validation loss: 2.689717100617941

Epoch: 6| Step: 8
Training loss: 2.9239872931792688
Validation loss: 2.6876362916042047

Epoch: 6| Step: 9
Training loss: 3.681751878914192
Validation loss: 2.688640515596705

Epoch: 6| Step: 10
Training loss: 2.476952362662022
Validation loss: 2.695758746376428

Epoch: 6| Step: 11
Training loss: 2.672507406426097
Validation loss: 2.6892833273189845

Epoch: 6| Step: 12
Training loss: 3.464404984725856
Validation loss: 2.690191692867776

Epoch: 6| Step: 13
Training loss: 3.431209148448685
Validation loss: 2.697203025136886

Epoch: 170| Step: 0
Training loss: 2.550348546012141
Validation loss: 2.7110862415703285

Epoch: 6| Step: 1
Training loss: 3.226762003422843
Validation loss: 2.7328260023021698

Epoch: 6| Step: 2
Training loss: 3.070719374082437
Validation loss: 2.7343192464884085

Epoch: 6| Step: 3
Training loss: 3.4062638588719643
Validation loss: 2.729545315875139

Epoch: 6| Step: 4
Training loss: 2.9843505538817974
Validation loss: 2.717219722500865

Epoch: 6| Step: 5
Training loss: 2.5270577081658407
Validation loss: 2.7113207190736075

Epoch: 6| Step: 6
Training loss: 3.1470123170139486
Validation loss: 2.714154350006505

Epoch: 6| Step: 7
Training loss: 3.2264516594347024
Validation loss: 2.7079581563243935

Epoch: 6| Step: 8
Training loss: 3.235053392114124
Validation loss: 2.7050842007881646

Epoch: 6| Step: 9
Training loss: 3.4383505029167987
Validation loss: 2.7116425609724146

Epoch: 6| Step: 10
Training loss: 2.4912572577524386
Validation loss: 2.7172532837402277

Epoch: 6| Step: 11
Training loss: 3.061097427248346
Validation loss: 2.702830740395859

Epoch: 6| Step: 12
Training loss: 3.032303459924697
Validation loss: 2.713355390179335

Epoch: 6| Step: 13
Training loss: 2.157849257789348
Validation loss: 2.690397098057199

Epoch: 171| Step: 0
Training loss: 2.810671232970194
Validation loss: 2.6992572610539622

Epoch: 6| Step: 1
Training loss: 2.8523244179556633
Validation loss: 2.6862406984205585

Epoch: 6| Step: 2
Training loss: 3.1200253373119824
Validation loss: 2.683600837371089

Epoch: 6| Step: 3
Training loss: 3.2623806401776987
Validation loss: 2.6926907384300005

Epoch: 6| Step: 4
Training loss: 2.5689755008965234
Validation loss: 2.6837269921194933

Epoch: 6| Step: 5
Training loss: 3.0685320246521655
Validation loss: 2.6903706381999237

Epoch: 6| Step: 6
Training loss: 3.074120099473397
Validation loss: 2.692093019109148

Epoch: 6| Step: 7
Training loss: 3.5334482018374573
Validation loss: 2.678904347881745

Epoch: 6| Step: 8
Training loss: 2.8731401481502927
Validation loss: 2.6798800860815017

Epoch: 6| Step: 9
Training loss: 3.766205549006284
Validation loss: 2.68181558014434

Epoch: 6| Step: 10
Training loss: 3.1366330107755847
Validation loss: 2.682617495218985

Epoch: 6| Step: 11
Training loss: 2.6415234002415042
Validation loss: 2.6807426614600858

Epoch: 6| Step: 12
Training loss: 2.1601371557347218
Validation loss: 2.688727525621222

Epoch: 6| Step: 13
Training loss: 2.8185884484391837
Validation loss: 2.698082458923433

Epoch: 172| Step: 0
Training loss: 3.052374000292017
Validation loss: 2.6936521271924274

Epoch: 6| Step: 1
Training loss: 3.257871192751047
Validation loss: 2.6933427320687144

Epoch: 6| Step: 2
Training loss: 2.9724283018199866
Validation loss: 2.709550253477811

Epoch: 6| Step: 3
Training loss: 3.2936608434550427
Validation loss: 2.731602103832122

Epoch: 6| Step: 4
Training loss: 2.542651553668013
Validation loss: 2.735378773763446

Epoch: 6| Step: 5
Training loss: 3.1372700701959286
Validation loss: 2.726848015323462

Epoch: 6| Step: 6
Training loss: 3.0265041048307895
Validation loss: 2.731104639805695

Epoch: 6| Step: 7
Training loss: 3.0551129993574335
Validation loss: 2.70525823301332

Epoch: 6| Step: 8
Training loss: 2.874638907934905
Validation loss: 2.719958926601936

Epoch: 6| Step: 9
Training loss: 2.203893865518753
Validation loss: 2.7191975184820207

Epoch: 6| Step: 10
Training loss: 2.8781863260932155
Validation loss: 2.7244190436712925

Epoch: 6| Step: 11
Training loss: 3.264764115603114
Validation loss: 2.7113669013021724

Epoch: 6| Step: 12
Training loss: 2.928614712438482
Validation loss: 2.6847558306953263

Epoch: 6| Step: 13
Training loss: 3.743360745631662
Validation loss: 2.682523818960464

Epoch: 173| Step: 0
Training loss: 2.3477284552059134
Validation loss: 2.6756055304297868

Epoch: 6| Step: 1
Training loss: 2.925445170638331
Validation loss: 2.6755614300962485

Epoch: 6| Step: 2
Training loss: 3.0485489379598665
Validation loss: 2.6788400671963872

Epoch: 6| Step: 3
Training loss: 3.2840494475457858
Validation loss: 2.6777109896484936

Epoch: 6| Step: 4
Training loss: 2.8102658192895453
Validation loss: 2.6863845815135323

Epoch: 6| Step: 5
Training loss: 3.203056520800008
Validation loss: 2.6820249637361036

Epoch: 6| Step: 6
Training loss: 3.548502544443552
Validation loss: 2.684154965229821

Epoch: 6| Step: 7
Training loss: 2.5934817623558417
Validation loss: 2.6851530031379975

Epoch: 6| Step: 8
Training loss: 3.270468300700037
Validation loss: 2.688368394438419

Epoch: 6| Step: 9
Training loss: 2.94651628173804
Validation loss: 2.6829772800954017

Epoch: 6| Step: 10
Training loss: 3.456339311049404
Validation loss: 2.6825089762170067

Epoch: 6| Step: 11
Training loss: 2.659757385375602
Validation loss: 2.6770212558810758

Epoch: 6| Step: 12
Training loss: 2.7724327309017776
Validation loss: 2.67482123971295

Epoch: 6| Step: 13
Training loss: 3.2143843590268033
Validation loss: 2.6783169514864618

Epoch: 174| Step: 0
Training loss: 2.64322980808695
Validation loss: 2.6801688507783608

Epoch: 6| Step: 1
Training loss: 2.6920532866159497
Validation loss: 2.677797407012144

Epoch: 6| Step: 2
Training loss: 2.921386188275587
Validation loss: 2.6789885171691026

Epoch: 6| Step: 3
Training loss: 2.002872549922463
Validation loss: 2.6953011347106175

Epoch: 6| Step: 4
Training loss: 3.2346197210785435
Validation loss: 2.701748019901505

Epoch: 6| Step: 5
Training loss: 2.8127239561983277
Validation loss: 2.6944134069116212

Epoch: 6| Step: 6
Training loss: 3.2433763645319353
Validation loss: 2.6929936922553908

Epoch: 6| Step: 7
Training loss: 2.793811676232129
Validation loss: 2.69505890540048

Epoch: 6| Step: 8
Training loss: 3.371380171647776
Validation loss: 2.685449726752754

Epoch: 6| Step: 9
Training loss: 3.6365265267908757
Validation loss: 2.6789870205090582

Epoch: 6| Step: 10
Training loss: 3.3480742826709675
Validation loss: 2.675260203060317

Epoch: 6| Step: 11
Training loss: 2.8504981157784757
Validation loss: 2.6841516319232537

Epoch: 6| Step: 12
Training loss: 2.9250066773428056
Validation loss: 2.6784027903218957

Epoch: 6| Step: 13
Training loss: 3.3914411415145365
Validation loss: 2.6713205234859596

Epoch: 175| Step: 0
Training loss: 3.0075536046756604
Validation loss: 2.6869635717927793

Epoch: 6| Step: 1
Training loss: 2.8523657098665076
Validation loss: 2.691881925366548

Epoch: 6| Step: 2
Training loss: 2.8832201992470488
Validation loss: 2.7036887358795894

Epoch: 6| Step: 3
Training loss: 3.1773039861047585
Validation loss: 2.7018426274948193

Epoch: 6| Step: 4
Training loss: 2.867551193245943
Validation loss: 2.703417202014587

Epoch: 6| Step: 5
Training loss: 3.3737250851717873
Validation loss: 2.6920556416512493

Epoch: 6| Step: 6
Training loss: 3.0859730392534255
Validation loss: 2.695160848528252

Epoch: 6| Step: 7
Training loss: 2.9901128603453313
Validation loss: 2.6921468836365556

Epoch: 6| Step: 8
Training loss: 2.873316064356387
Validation loss: 2.692657611766145

Epoch: 6| Step: 9
Training loss: 3.0638308066423896
Validation loss: 2.6909984788904873

Epoch: 6| Step: 10
Training loss: 3.008650229574461
Validation loss: 2.7046964820482393

Epoch: 6| Step: 11
Training loss: 2.824079623561426
Validation loss: 2.6858957438507836

Epoch: 6| Step: 12
Training loss: 3.226925291489257
Validation loss: 2.6693160223368464

Epoch: 6| Step: 13
Training loss: 2.5338560276214155
Validation loss: 2.6885013474808996

Epoch: 176| Step: 0
Training loss: 3.066620526450423
Validation loss: 2.665596944177103

Epoch: 6| Step: 1
Training loss: 2.8503281521521644
Validation loss: 2.667456178026592

Epoch: 6| Step: 2
Training loss: 2.9714335309238757
Validation loss: 2.6736444106201493

Epoch: 6| Step: 3
Training loss: 2.9744410526695035
Validation loss: 2.6777801436759296

Epoch: 6| Step: 4
Training loss: 3.216319527613968
Validation loss: 2.6699427437558767

Epoch: 6| Step: 5
Training loss: 3.1859278073988935
Validation loss: 2.671361830160371

Epoch: 6| Step: 6
Training loss: 3.096945297413388
Validation loss: 2.670570399012883

Epoch: 6| Step: 7
Training loss: 3.1158924902413094
Validation loss: 2.670824025668237

Epoch: 6| Step: 8
Training loss: 2.5381461499987865
Validation loss: 2.670431301032997

Epoch: 6| Step: 9
Training loss: 3.3427410564364304
Validation loss: 2.6697971622039076

Epoch: 6| Step: 10
Training loss: 2.5447334694086075
Validation loss: 2.667997220237184

Epoch: 6| Step: 11
Training loss: 2.827149365149891
Validation loss: 2.6720459413276125

Epoch: 6| Step: 12
Training loss: 2.8443227337917976
Validation loss: 2.669167029610667

Epoch: 6| Step: 13
Training loss: 3.723652405165803
Validation loss: 2.6730396155546923

Epoch: 177| Step: 0
Training loss: 3.198705536569469
Validation loss: 2.6694317474404166

Epoch: 6| Step: 1
Training loss: 2.527462044118655
Validation loss: 2.6668085770635255

Epoch: 6| Step: 2
Training loss: 2.864674810625088
Validation loss: 2.67155943732168

Epoch: 6| Step: 3
Training loss: 2.9561029183895693
Validation loss: 2.665920050824086

Epoch: 6| Step: 4
Training loss: 3.0289111995582787
Validation loss: 2.665130444484296

Epoch: 6| Step: 5
Training loss: 3.140203646962562
Validation loss: 2.6688616218306307

Epoch: 6| Step: 6
Training loss: 3.670215247803589
Validation loss: 2.6805715813521593

Epoch: 6| Step: 7
Training loss: 3.5051708172192897
Validation loss: 2.6926432028635734

Epoch: 6| Step: 8
Training loss: 3.3226423638630154
Validation loss: 2.6801258471145

Epoch: 6| Step: 9
Training loss: 2.316710891118558
Validation loss: 2.68501258011356

Epoch: 6| Step: 10
Training loss: 2.680562046243016
Validation loss: 2.685553845527977

Epoch: 6| Step: 11
Training loss: 3.0007231158738468
Validation loss: 2.68830120738236

Epoch: 6| Step: 12
Training loss: 2.904289815107845
Validation loss: 2.699066801302596

Epoch: 6| Step: 13
Training loss: 2.2922179050418254
Validation loss: 2.6927649867953916

Epoch: 178| Step: 0
Training loss: 2.801096623114366
Validation loss: 2.684553040194959

Epoch: 6| Step: 1
Training loss: 3.2021015299915185
Validation loss: 2.678971333279646

Epoch: 6| Step: 2
Training loss: 3.563134387903404
Validation loss: 2.688957883494374

Epoch: 6| Step: 3
Training loss: 2.6542643586469485
Validation loss: 2.6620733908874334

Epoch: 6| Step: 4
Training loss: 2.7701924856904583
Validation loss: 2.6621302491447936

Epoch: 6| Step: 5
Training loss: 3.195114316133941
Validation loss: 2.668155434040555

Epoch: 6| Step: 6
Training loss: 3.0717568142916947
Validation loss: 2.66518379584701

Epoch: 6| Step: 7
Training loss: 3.017128683156
Validation loss: 2.6720418330458386

Epoch: 6| Step: 8
Training loss: 2.1231034735440946
Validation loss: 2.669263697668943

Epoch: 6| Step: 9
Training loss: 3.4789251978486924
Validation loss: 2.6778390733082595

Epoch: 6| Step: 10
Training loss: 3.2442014758554043
Validation loss: 2.674978014855926

Epoch: 6| Step: 11
Training loss: 2.8418285879351637
Validation loss: 2.675584769080561

Epoch: 6| Step: 12
Training loss: 3.027771359669205
Validation loss: 2.6748262599875194

Epoch: 6| Step: 13
Training loss: 2.8623345073186517
Validation loss: 2.6771381135237817

Epoch: 179| Step: 0
Training loss: 3.3974481655318285
Validation loss: 2.6749545373619448

Epoch: 6| Step: 1
Training loss: 2.8900856958375245
Validation loss: 2.6685984248654027

Epoch: 6| Step: 2
Training loss: 2.8383610565868516
Validation loss: 2.6684855649684436

Epoch: 6| Step: 3
Training loss: 3.199191325050339
Validation loss: 2.6666087546776938

Epoch: 6| Step: 4
Training loss: 2.78017842083863
Validation loss: 2.6625899184200446

Epoch: 6| Step: 5
Training loss: 3.1959976916633073
Validation loss: 2.6590605669898904

Epoch: 6| Step: 6
Training loss: 2.632793483042874
Validation loss: 2.6640262535736947

Epoch: 6| Step: 7
Training loss: 3.178976443404727
Validation loss: 2.665995111108193

Epoch: 6| Step: 8
Training loss: 2.90687554303043
Validation loss: 2.6617348760492607

Epoch: 6| Step: 9
Training loss: 2.5583840786584617
Validation loss: 2.6691820742868893

Epoch: 6| Step: 10
Training loss: 2.8598520683497317
Validation loss: 2.6782642025019587

Epoch: 6| Step: 11
Training loss: 3.2892405264691114
Validation loss: 2.684459495463304

Epoch: 6| Step: 12
Training loss: 3.2046261131027864
Validation loss: 2.6788300407250305

Epoch: 6| Step: 13
Training loss: 3.032032501841648
Validation loss: 2.6963521627758418

Epoch: 180| Step: 0
Training loss: 3.1124102476117246
Validation loss: 2.720065369051247

Epoch: 6| Step: 1
Training loss: 3.0786659036566295
Validation loss: 2.7029900480108444

Epoch: 6| Step: 2
Training loss: 2.826379395348437
Validation loss: 2.7190613220095305

Epoch: 6| Step: 3
Training loss: 3.200202613615031
Validation loss: 2.72100740509805

Epoch: 6| Step: 4
Training loss: 2.368727482107422
Validation loss: 2.7068923701251695

Epoch: 6| Step: 5
Training loss: 3.024784389409763
Validation loss: 2.7057100362240676

Epoch: 6| Step: 6
Training loss: 2.8585240499710154
Validation loss: 2.6932596358055956

Epoch: 6| Step: 7
Training loss: 3.290296889246435
Validation loss: 2.681710344961492

Epoch: 6| Step: 8
Training loss: 2.8253339620694224
Validation loss: 2.6665065650665225

Epoch: 6| Step: 9
Training loss: 2.7904307538100785
Validation loss: 2.661651255319582

Epoch: 6| Step: 10
Training loss: 3.135397740979703
Validation loss: 2.657821078698773

Epoch: 6| Step: 11
Training loss: 3.1730326527172648
Validation loss: 2.6588640769145555

Epoch: 6| Step: 12
Training loss: 2.8679537463854348
Validation loss: 2.6649432407020366

Epoch: 6| Step: 13
Training loss: 3.671478769553985
Validation loss: 2.665704841323537

Epoch: 181| Step: 0
Training loss: 2.664091585509527
Validation loss: 2.66709153254251

Epoch: 6| Step: 1
Training loss: 3.211027492180967
Validation loss: 2.665709455133406

Epoch: 6| Step: 2
Training loss: 3.255171402785302
Validation loss: 2.673467199483838

Epoch: 6| Step: 3
Training loss: 3.111445518716724
Validation loss: 2.6725289341462006

Epoch: 6| Step: 4
Training loss: 2.4934987412459657
Validation loss: 2.677816995670736

Epoch: 6| Step: 5
Training loss: 3.196952119346418
Validation loss: 2.6674143774164367

Epoch: 6| Step: 6
Training loss: 3.19851397342322
Validation loss: 2.666840236793529

Epoch: 6| Step: 7
Training loss: 2.76246730042864
Validation loss: 2.663792182512644

Epoch: 6| Step: 8
Training loss: 3.6645884837854803
Validation loss: 2.6567729514792244

Epoch: 6| Step: 9
Training loss: 2.754049527384337
Validation loss: 2.6617856979155556

Epoch: 6| Step: 10
Training loss: 3.1039092364658107
Validation loss: 2.662823748573161

Epoch: 6| Step: 11
Training loss: 2.448230111906797
Validation loss: 2.671185495474172

Epoch: 6| Step: 12
Training loss: 2.8785322300927287
Validation loss: 2.6792040246164146

Epoch: 6| Step: 13
Training loss: 3.164609207204923
Validation loss: 2.694662555588645

Epoch: 182| Step: 0
Training loss: 3.0807810521317993
Validation loss: 2.7152842608915595

Epoch: 6| Step: 1
Training loss: 2.778772772499634
Validation loss: 2.717161705450701

Epoch: 6| Step: 2
Training loss: 2.8751466133217805
Validation loss: 2.7389102013534936

Epoch: 6| Step: 3
Training loss: 2.6833161011926414
Validation loss: 2.720966055002892

Epoch: 6| Step: 4
Training loss: 2.875886034228853
Validation loss: 2.716440682782503

Epoch: 6| Step: 5
Training loss: 3.6312643710720356
Validation loss: 2.698333220292202

Epoch: 6| Step: 6
Training loss: 2.9422844415496865
Validation loss: 2.6818301810515623

Epoch: 6| Step: 7
Training loss: 2.9240859535306507
Validation loss: 2.6617669091460217

Epoch: 6| Step: 8
Training loss: 2.653515474051869
Validation loss: 2.6613312119306918

Epoch: 6| Step: 9
Training loss: 3.5352199148272807
Validation loss: 2.651116213427426

Epoch: 6| Step: 10
Training loss: 2.3878523761288775
Validation loss: 2.6554256812941857

Epoch: 6| Step: 11
Training loss: 3.1609154391685674
Validation loss: 2.660729804725376

Epoch: 6| Step: 12
Training loss: 3.0312295500075326
Validation loss: 2.6658953934404153

Epoch: 6| Step: 13
Training loss: 3.3649424704725406
Validation loss: 2.6671429679474796

Epoch: 183| Step: 0
Training loss: 3.497963176430963
Validation loss: 2.6676630416637215

Epoch: 6| Step: 1
Training loss: 3.6377598043779833
Validation loss: 2.674213350722616

Epoch: 6| Step: 2
Training loss: 2.3370047590332153
Validation loss: 2.6718831422301887

Epoch: 6| Step: 3
Training loss: 2.7090354205041134
Validation loss: 2.677984883965334

Epoch: 6| Step: 4
Training loss: 3.1535047924319244
Validation loss: 2.67480331117936

Epoch: 6| Step: 5
Training loss: 3.2572673826386978
Validation loss: 2.6650339016205518

Epoch: 6| Step: 6
Training loss: 2.8093057931558874
Validation loss: 2.6637960638796736

Epoch: 6| Step: 7
Training loss: 3.111314638231912
Validation loss: 2.6621030350094723

Epoch: 6| Step: 8
Training loss: 2.3389786026764066
Validation loss: 2.657673801007552

Epoch: 6| Step: 9
Training loss: 2.815057058348952
Validation loss: 2.6584707494319515

Epoch: 6| Step: 10
Training loss: 3.1748745270213594
Validation loss: 2.652392438880568

Epoch: 6| Step: 11
Training loss: 3.2251535068616914
Validation loss: 2.655320651484822

Epoch: 6| Step: 12
Training loss: 2.760506672861318
Validation loss: 2.65204201829575

Epoch: 6| Step: 13
Training loss: 3.140693777669248
Validation loss: 2.655010987864236

Epoch: 184| Step: 0
Training loss: 3.1813564560021383
Validation loss: 2.65266103225793

Epoch: 6| Step: 1
Training loss: 3.313185710829286
Validation loss: 2.6546605102308134

Epoch: 6| Step: 2
Training loss: 3.054520936605386
Validation loss: 2.6558927832671873

Epoch: 6| Step: 3
Training loss: 3.124681075034492
Validation loss: 2.659767583986087

Epoch: 6| Step: 4
Training loss: 3.357989074125799
Validation loss: 2.6620888570083703

Epoch: 6| Step: 5
Training loss: 2.7402947569412004
Validation loss: 2.6583783110971564

Epoch: 6| Step: 6
Training loss: 3.4281765818301273
Validation loss: 2.678272220016363

Epoch: 6| Step: 7
Training loss: 3.023871496628949
Validation loss: 2.6562687949783004

Epoch: 6| Step: 8
Training loss: 2.963321742438128
Validation loss: 2.6526896194315124

Epoch: 6| Step: 9
Training loss: 2.968900014199118
Validation loss: 2.6499269395300575

Epoch: 6| Step: 10
Training loss: 2.180084520503856
Validation loss: 2.660401306434349

Epoch: 6| Step: 11
Training loss: 2.5851750935443865
Validation loss: 2.6502267674714983

Epoch: 6| Step: 12
Training loss: 2.3645326942253404
Validation loss: 2.645333045542576

Epoch: 6| Step: 13
Training loss: 3.3909717857111783
Validation loss: 2.6487971816724056

Epoch: 185| Step: 0
Training loss: 2.9884787899373277
Validation loss: 2.646170915250616

Epoch: 6| Step: 1
Training loss: 3.094516543589613
Validation loss: 2.6447919421206

Epoch: 6| Step: 2
Training loss: 2.910952956956664
Validation loss: 2.6447703505060214

Epoch: 6| Step: 3
Training loss: 2.737590533984711
Validation loss: 2.643295978934514

Epoch: 6| Step: 4
Training loss: 2.7104342210588714
Validation loss: 2.6435665613400214

Epoch: 6| Step: 5
Training loss: 2.902561595437316
Validation loss: 2.6503362523183895

Epoch: 6| Step: 6
Training loss: 2.456700919890339
Validation loss: 2.643527637560601

Epoch: 6| Step: 7
Training loss: 2.8482924850805627
Validation loss: 2.6501131793568784

Epoch: 6| Step: 8
Training loss: 3.4195183429295763
Validation loss: 2.6589424573659084

Epoch: 6| Step: 9
Training loss: 3.463094689154457
Validation loss: 2.6695132873215655

Epoch: 6| Step: 10
Training loss: 3.167886867005897
Validation loss: 2.6630751711126215

Epoch: 6| Step: 11
Training loss: 3.1319767700542065
Validation loss: 2.67359895469467

Epoch: 6| Step: 12
Training loss: 3.1866612546334805
Validation loss: 2.6671590433806727

Epoch: 6| Step: 13
Training loss: 2.1588294039703038
Validation loss: 2.6603814960695433

Epoch: 186| Step: 0
Training loss: 3.0749154180043488
Validation loss: 2.652444202336132

Epoch: 6| Step: 1
Training loss: 3.0123178007499214
Validation loss: 2.639808390171818

Epoch: 6| Step: 2
Training loss: 3.1035955189527633
Validation loss: 2.644451249993888

Epoch: 6| Step: 3
Training loss: 3.204391154811576
Validation loss: 2.6424493411698387

Epoch: 6| Step: 4
Training loss: 3.4670088238467676
Validation loss: 2.640296801565142

Epoch: 6| Step: 5
Training loss: 2.4553025415467893
Validation loss: 2.6416514586602275

Epoch: 6| Step: 6
Training loss: 2.7156710674561917
Validation loss: 2.647195709619935

Epoch: 6| Step: 7
Training loss: 2.4077520265108268
Validation loss: 2.6397947047400967

Epoch: 6| Step: 8
Training loss: 3.045121691046394
Validation loss: 2.6443037521509933

Epoch: 6| Step: 9
Training loss: 2.549033718659827
Validation loss: 2.6421995886304077

Epoch: 6| Step: 10
Training loss: 2.7197553157142567
Validation loss: 2.6368010234264387

Epoch: 6| Step: 11
Training loss: 3.0844466459075273
Validation loss: 2.63790456780074

Epoch: 6| Step: 12
Training loss: 3.7021201013654434
Validation loss: 2.64214102165912

Epoch: 6| Step: 13
Training loss: 2.851961792463887
Validation loss: 2.6399648702514673

Epoch: 187| Step: 0
Training loss: 2.610818977336781
Validation loss: 2.644422520440667

Epoch: 6| Step: 1
Training loss: 2.777991454065304
Validation loss: 2.6469507981615026

Epoch: 6| Step: 2
Training loss: 2.9740068973956393
Validation loss: 2.6356473519642343

Epoch: 6| Step: 3
Training loss: 3.0030103520670024
Validation loss: 2.6463692458011083

Epoch: 6| Step: 4
Training loss: 3.329345479339863
Validation loss: 2.6446315114863506

Epoch: 6| Step: 5
Training loss: 3.0488188973775316
Validation loss: 2.652524108181797

Epoch: 6| Step: 6
Training loss: 2.8263350243920096
Validation loss: 2.6557329624102897

Epoch: 6| Step: 7
Training loss: 3.338291168733802
Validation loss: 2.6488211349050834

Epoch: 6| Step: 8
Training loss: 3.178188411113804
Validation loss: 2.6466350718211515

Epoch: 6| Step: 9
Training loss: 3.206445080509144
Validation loss: 2.6518342193533337

Epoch: 6| Step: 10
Training loss: 2.4251649230247474
Validation loss: 2.644448897158459

Epoch: 6| Step: 11
Training loss: 3.149881717943728
Validation loss: 2.648293500973587

Epoch: 6| Step: 12
Training loss: 2.704564852167775
Validation loss: 2.646069333422127

Epoch: 6| Step: 13
Training loss: 2.8618400246023565
Validation loss: 2.6401574476399983

Epoch: 188| Step: 0
Training loss: 2.8622978572184796
Validation loss: 2.656032771976555

Epoch: 6| Step: 1
Training loss: 2.958622412370239
Validation loss: 2.638631260365314

Epoch: 6| Step: 2
Training loss: 2.7136345455116535
Validation loss: 2.6504118255167044

Epoch: 6| Step: 3
Training loss: 3.0707951523069137
Validation loss: 2.64920257176244

Epoch: 6| Step: 4
Training loss: 2.8352054880743536
Validation loss: 2.6451622600663693

Epoch: 6| Step: 5
Training loss: 2.8103787369898576
Validation loss: 2.639775803150426

Epoch: 6| Step: 6
Training loss: 2.4631119098523606
Validation loss: 2.6401567038400384

Epoch: 6| Step: 7
Training loss: 3.143935096099913
Validation loss: 2.6411855730875864

Epoch: 6| Step: 8
Training loss: 2.8537318508725678
Validation loss: 2.6394324155988724

Epoch: 6| Step: 9
Training loss: 2.8779527179791935
Validation loss: 2.6300828849988327

Epoch: 6| Step: 10
Training loss: 2.201680568888933
Validation loss: 2.640870059324434

Epoch: 6| Step: 11
Training loss: 3.278855385521014
Validation loss: 2.6384879474923304

Epoch: 6| Step: 12
Training loss: 3.8043178872298733
Validation loss: 2.6331562849813035

Epoch: 6| Step: 13
Training loss: 3.7997145846744584
Validation loss: 2.6333826362503356

Epoch: 189| Step: 0
Training loss: 3.1067125432743348
Validation loss: 2.6358052121769324

Epoch: 6| Step: 1
Training loss: 3.1938034262173027
Validation loss: 2.635828494685902

Epoch: 6| Step: 2
Training loss: 3.4393632867313153
Validation loss: 2.6346842085055604

Epoch: 6| Step: 3
Training loss: 2.635650192187384
Validation loss: 2.637971948520305

Epoch: 6| Step: 4
Training loss: 2.9074569984988803
Validation loss: 2.6310402890444853

Epoch: 6| Step: 5
Training loss: 3.225485855291501
Validation loss: 2.6390730308039387

Epoch: 6| Step: 6
Training loss: 3.262925195573625
Validation loss: 2.6363120742795045

Epoch: 6| Step: 7
Training loss: 3.0739989535367793
Validation loss: 2.6427183203869222

Epoch: 6| Step: 8
Training loss: 2.6159464612376
Validation loss: 2.6418654315977177

Epoch: 6| Step: 9
Training loss: 2.883108232417573
Validation loss: 2.651981308033775

Epoch: 6| Step: 10
Training loss: 2.826837404630701
Validation loss: 2.64858798696554

Epoch: 6| Step: 11
Training loss: 2.6697045149155456
Validation loss: 2.7057260639639087

Epoch: 6| Step: 12
Training loss: 2.8194735222263394
Validation loss: 2.672774635433918

Epoch: 6| Step: 13
Training loss: 2.662516215100409
Validation loss: 2.6789743026927133

Epoch: 190| Step: 0
Training loss: 3.0561906867327298
Validation loss: 2.6914447890193265

Epoch: 6| Step: 1
Training loss: 3.185843691864323
Validation loss: 2.723755916825899

Epoch: 6| Step: 2
Training loss: 3.1576707116354163
Validation loss: 2.7183283675865

Epoch: 6| Step: 3
Training loss: 2.961939820713088
Validation loss: 2.6996146834863834

Epoch: 6| Step: 4
Training loss: 3.432558287634786
Validation loss: 2.692469566858689

Epoch: 6| Step: 5
Training loss: 2.7807078315262688
Validation loss: 2.6436117869544424

Epoch: 6| Step: 6
Training loss: 2.7668375062093187
Validation loss: 2.6378962482881487

Epoch: 6| Step: 7
Training loss: 3.158824210825519
Validation loss: 2.6330729337766035

Epoch: 6| Step: 8
Training loss: 2.484233636253033
Validation loss: 2.6369547449598594

Epoch: 6| Step: 9
Training loss: 2.3384375828701294
Validation loss: 2.6398001742597814

Epoch: 6| Step: 10
Training loss: 3.750577500698408
Validation loss: 2.637736306012017

Epoch: 6| Step: 11
Training loss: 3.0919736135721414
Validation loss: 2.6429490654733496

Epoch: 6| Step: 12
Training loss: 2.465952579992166
Validation loss: 2.6407799279392123

Epoch: 6| Step: 13
Training loss: 2.847447265994085
Validation loss: 2.6452027065819936

Epoch: 191| Step: 0
Training loss: 3.1889645073136594
Validation loss: 2.647243157735243

Epoch: 6| Step: 1
Training loss: 3.6854183981233493
Validation loss: 2.6503787652885062

Epoch: 6| Step: 2
Training loss: 2.450131478966219
Validation loss: 2.6493216197517073

Epoch: 6| Step: 3
Training loss: 3.0938119593109072
Validation loss: 2.6491739392185027

Epoch: 6| Step: 4
Training loss: 2.7499296005948115
Validation loss: 2.6496688773273758

Epoch: 6| Step: 5
Training loss: 3.034090893504812
Validation loss: 2.6457228427173276

Epoch: 6| Step: 6
Training loss: 3.0126590670935562
Validation loss: 2.6429541608387703

Epoch: 6| Step: 7
Training loss: 3.3369436421812324
Validation loss: 2.6432597755604887

Epoch: 6| Step: 8
Training loss: 3.078607047042161
Validation loss: 2.6419271535232607

Epoch: 6| Step: 9
Training loss: 3.0978060249592656
Validation loss: 2.6416607887319388

Epoch: 6| Step: 10
Training loss: 2.892578289848493
Validation loss: 2.633412400366176

Epoch: 6| Step: 11
Training loss: 2.6419793442316464
Validation loss: 2.6308949928513696

Epoch: 6| Step: 12
Training loss: 2.6799272702440278
Validation loss: 2.628539106513855

Epoch: 6| Step: 13
Training loss: 2.7023857737634827
Validation loss: 2.6302846849768122

Epoch: 192| Step: 0
Training loss: 2.8706054272224226
Validation loss: 2.6314574760036384

Epoch: 6| Step: 1
Training loss: 2.845980764864206
Validation loss: 2.6528688746691

Epoch: 6| Step: 2
Training loss: 2.6359627098953777
Validation loss: 2.6522812550901467

Epoch: 6| Step: 3
Training loss: 2.65727609001528
Validation loss: 2.7018906492640515

Epoch: 6| Step: 4
Training loss: 2.858127509474096
Validation loss: 2.7032051906751122

Epoch: 6| Step: 5
Training loss: 3.3813440954967713
Validation loss: 2.7378314686024843

Epoch: 6| Step: 6
Training loss: 3.1782415227993757
Validation loss: 2.707017842858744

Epoch: 6| Step: 7
Training loss: 3.564180212154935
Validation loss: 2.66640288704459

Epoch: 6| Step: 8
Training loss: 3.226339484905888
Validation loss: 2.6415237632144506

Epoch: 6| Step: 9
Training loss: 2.583971457474326
Validation loss: 2.628449735383051

Epoch: 6| Step: 10
Training loss: 2.9839451665058907
Validation loss: 2.629732999164969

Epoch: 6| Step: 11
Training loss: 3.0317426458159313
Validation loss: 2.629253859918892

Epoch: 6| Step: 12
Training loss: 2.854683283994304
Validation loss: 2.6280254921918456

Epoch: 6| Step: 13
Training loss: 3.087694503279276
Validation loss: 2.635011641769375

Epoch: 193| Step: 0
Training loss: 2.565245297546508
Validation loss: 2.6361328329614118

Epoch: 6| Step: 1
Training loss: 2.659767604227124
Validation loss: 2.629397198341347

Epoch: 6| Step: 2
Training loss: 2.457742900311581
Validation loss: 2.6332981852871034

Epoch: 6| Step: 3
Training loss: 2.93038891343111
Validation loss: 2.631756253921319

Epoch: 6| Step: 4
Training loss: 3.3690450903574765
Validation loss: 2.6297615070540883

Epoch: 6| Step: 5
Training loss: 3.6946685423482015
Validation loss: 2.6300892680601518

Epoch: 6| Step: 6
Training loss: 3.0838190847389058
Validation loss: 2.628866670320904

Epoch: 6| Step: 7
Training loss: 3.105897118155934
Validation loss: 2.6276582051554724

Epoch: 6| Step: 8
Training loss: 2.783661215042491
Validation loss: 2.628273528846878

Epoch: 6| Step: 9
Training loss: 2.4135759474408385
Validation loss: 2.6272701676100927

Epoch: 6| Step: 10
Training loss: 3.031727546750303
Validation loss: 2.6324762486447644

Epoch: 6| Step: 11
Training loss: 2.4912792691407732
Validation loss: 2.6459039109124753

Epoch: 6| Step: 12
Training loss: 3.2038433478988915
Validation loss: 2.6594687304579017

Epoch: 6| Step: 13
Training loss: 3.8283348804471307
Validation loss: 2.6913268641676833

Epoch: 194| Step: 0
Training loss: 2.775871562696421
Validation loss: 2.7051011335046633

Epoch: 6| Step: 1
Training loss: 3.046316555393425
Validation loss: 2.73489443297257

Epoch: 6| Step: 2
Training loss: 3.012251790691625
Validation loss: 2.7762309556667915

Epoch: 6| Step: 3
Training loss: 2.966245538488763
Validation loss: 2.7588571626993623

Epoch: 6| Step: 4
Training loss: 3.1879641625030555
Validation loss: 2.7131487769181475

Epoch: 6| Step: 5
Training loss: 3.2682221958445745
Validation loss: 2.6478894259161123

Epoch: 6| Step: 6
Training loss: 3.235084345335612
Validation loss: 2.625684752858033

Epoch: 6| Step: 7
Training loss: 2.6638921867812497
Validation loss: 2.624135087320683

Epoch: 6| Step: 8
Training loss: 2.3352000625803755
Validation loss: 2.6243624589300754

Epoch: 6| Step: 9
Training loss: 2.6664697951918854
Validation loss: 2.632942421188933

Epoch: 6| Step: 10
Training loss: 3.299984012911825
Validation loss: 2.6344858925635597

Epoch: 6| Step: 11
Training loss: 3.031006321501802
Validation loss: 2.64973739418741

Epoch: 6| Step: 12
Training loss: 3.2306759824325924
Validation loss: 2.6564091286717346

Epoch: 6| Step: 13
Training loss: 2.9893115692140415
Validation loss: 2.6422781248032723

Epoch: 195| Step: 0
Training loss: 2.8050125486259807
Validation loss: 2.6487715799576788

Epoch: 6| Step: 1
Training loss: 2.8268305729932637
Validation loss: 2.634080877997761

Epoch: 6| Step: 2
Training loss: 2.566559994532738
Validation loss: 2.6251874193670974

Epoch: 6| Step: 3
Training loss: 2.7082095973775067
Validation loss: 2.623568247424929

Epoch: 6| Step: 4
Training loss: 2.97032782135794
Validation loss: 2.6256213558802766

Epoch: 6| Step: 5
Training loss: 3.125278918216803
Validation loss: 2.6345556391925973

Epoch: 6| Step: 6
Training loss: 3.070636450685798
Validation loss: 2.6640043886548193

Epoch: 6| Step: 7
Training loss: 3.419722485353315
Validation loss: 2.6894619994640006

Epoch: 6| Step: 8
Training loss: 2.683719193415445
Validation loss: 2.6882657607774965

Epoch: 6| Step: 9
Training loss: 3.3383785848713647
Validation loss: 2.7385466955463267

Epoch: 6| Step: 10
Training loss: 2.893508545130743
Validation loss: 2.802922231947081

Epoch: 6| Step: 11
Training loss: 3.4047491284237728
Validation loss: 2.7872464856059707

Epoch: 6| Step: 12
Training loss: 2.8376548758432505
Validation loss: 2.74347324855988

Epoch: 6| Step: 13
Training loss: 3.639255249631806
Validation loss: 2.661206058014628

Epoch: 196| Step: 0
Training loss: 3.112401208497036
Validation loss: 2.6202334144070245

Epoch: 6| Step: 1
Training loss: 3.0894474204571813
Validation loss: 2.618131166911277

Epoch: 6| Step: 2
Training loss: 2.9127472473765397
Validation loss: 2.626828147439497

Epoch: 6| Step: 3
Training loss: 2.5697874327151693
Validation loss: 2.6360846937445395

Epoch: 6| Step: 4
Training loss: 3.630526834724714
Validation loss: 2.6400875610867445

Epoch: 6| Step: 5
Training loss: 2.660441603179025
Validation loss: 2.656073967000563

Epoch: 6| Step: 6
Training loss: 3.117043704585938
Validation loss: 2.6574501337627225

Epoch: 6| Step: 7
Training loss: 2.7764151049439523
Validation loss: 2.663581766037183

Epoch: 6| Step: 8
Training loss: 3.0190700953642424
Validation loss: 2.668146619382406

Epoch: 6| Step: 9
Training loss: 3.1433394359261047
Validation loss: 2.6505214671470334

Epoch: 6| Step: 10
Training loss: 3.274264356386101
Validation loss: 2.653290067338939

Epoch: 6| Step: 11
Training loss: 2.61246494835515
Validation loss: 2.6431812530366483

Epoch: 6| Step: 12
Training loss: 2.968042871684838
Validation loss: 2.6361829396036542

Epoch: 6| Step: 13
Training loss: 2.91936560598049
Validation loss: 2.6349601351803504

Epoch: 197| Step: 0
Training loss: 2.6871887736534297
Validation loss: 2.6294192301381316

Epoch: 6| Step: 1
Training loss: 2.903831706348766
Validation loss: 2.628117422742837

Epoch: 6| Step: 2
Training loss: 3.657682350186484
Validation loss: 2.6268517408116403

Epoch: 6| Step: 3
Training loss: 3.6889061267353003
Validation loss: 2.623302339493041

Epoch: 6| Step: 4
Training loss: 2.0792703555542786
Validation loss: 2.6247281110974554

Epoch: 6| Step: 5
Training loss: 3.246447014894902
Validation loss: 2.620341272160878

Epoch: 6| Step: 6
Training loss: 2.7172883588115675
Validation loss: 2.61954949187902

Epoch: 6| Step: 7
Training loss: 2.7985812475621543
Validation loss: 2.614906088800869

Epoch: 6| Step: 8
Training loss: 3.096084176567807
Validation loss: 2.6194355326134433

Epoch: 6| Step: 9
Training loss: 2.9896757175823048
Validation loss: 2.6254238854844334

Epoch: 6| Step: 10
Training loss: 2.9690859955834763
Validation loss: 2.6146010152443333

Epoch: 6| Step: 11
Training loss: 2.7776311411830275
Validation loss: 2.6259346258627687

Epoch: 6| Step: 12
Training loss: 2.663441873788739
Validation loss: 2.619467851033871

Epoch: 6| Step: 13
Training loss: 2.892299023028366
Validation loss: 2.6513741821373262

Epoch: 198| Step: 0
Training loss: 2.7758273291849758
Validation loss: 2.661163959815745

Epoch: 6| Step: 1
Training loss: 2.8948284207692447
Validation loss: 2.69985226147589

Epoch: 6| Step: 2
Training loss: 3.1321159216230128
Validation loss: 2.70722917399262

Epoch: 6| Step: 3
Training loss: 2.7079896757754534
Validation loss: 2.6980867907511112

Epoch: 6| Step: 4
Training loss: 3.4501560618167857
Validation loss: 2.7001969986833387

Epoch: 6| Step: 5
Training loss: 2.6042190139595514
Validation loss: 2.6810179366553855

Epoch: 6| Step: 6
Training loss: 3.217605387303695
Validation loss: 2.649704411653601

Epoch: 6| Step: 7
Training loss: 3.3948144300754404
Validation loss: 2.6520162362035826

Epoch: 6| Step: 8
Training loss: 3.0582569857707553
Validation loss: 2.6408432032212508

Epoch: 6| Step: 9
Training loss: 3.22065545134137
Validation loss: 2.628833370347112

Epoch: 6| Step: 10
Training loss: 3.0342018463042653
Validation loss: 2.620576129997648

Epoch: 6| Step: 11
Training loss: 2.642773538541126
Validation loss: 2.61503615259895

Epoch: 6| Step: 12
Training loss: 2.2641219842756213
Validation loss: 2.613107117863813

Epoch: 6| Step: 13
Training loss: 2.909933073971825
Validation loss: 2.618444996217775

Epoch: 199| Step: 0
Training loss: 3.03752305135889
Validation loss: 2.6113861048340974

Epoch: 6| Step: 1
Training loss: 3.241528253288889
Validation loss: 2.6058599100289404

Epoch: 6| Step: 2
Training loss: 2.758410942699164
Validation loss: 2.611342697881533

Epoch: 6| Step: 3
Training loss: 2.9506045287815366
Validation loss: 2.6152753559238184

Epoch: 6| Step: 4
Training loss: 3.3926395461211003
Validation loss: 2.6171289022635738

Epoch: 6| Step: 5
Training loss: 2.8119738616488226
Validation loss: 2.606530406291027

Epoch: 6| Step: 6
Training loss: 2.5194616027195424
Validation loss: 2.614962480508385

Epoch: 6| Step: 7
Training loss: 3.092104079020958
Validation loss: 2.6156459705232873

Epoch: 6| Step: 8
Training loss: 3.1765080332366997
Validation loss: 2.608900327039119

Epoch: 6| Step: 9
Training loss: 2.957126227885601
Validation loss: 2.6140319196343946

Epoch: 6| Step: 10
Training loss: 2.5877816346447657
Validation loss: 2.617644881846095

Epoch: 6| Step: 11
Training loss: 2.9166667029971167
Validation loss: 2.6259056234298144

Epoch: 6| Step: 12
Training loss: 2.796476367694396
Validation loss: 2.623691599970676

Epoch: 6| Step: 13
Training loss: 3.1291461143038823
Validation loss: 2.614537389221088

Epoch: 200| Step: 0
Training loss: 2.777541441930148
Validation loss: 2.6159712140870104

Epoch: 6| Step: 1
Training loss: 3.3035284945374985
Validation loss: 2.618709054694789

Epoch: 6| Step: 2
Training loss: 2.989668540316306
Validation loss: 2.6233856815798733

Epoch: 6| Step: 3
Training loss: 2.4285805686009336
Validation loss: 2.633074344567105

Epoch: 6| Step: 4
Training loss: 3.167810701879823
Validation loss: 2.6474493425790873

Epoch: 6| Step: 5
Training loss: 2.1834788829637515
Validation loss: 2.654144622478861

Epoch: 6| Step: 6
Training loss: 2.9017975859346787
Validation loss: 2.635335423338674

Epoch: 6| Step: 7
Training loss: 3.2075734580377886
Validation loss: 2.631186444366971

Epoch: 6| Step: 8
Training loss: 3.36669578413757
Validation loss: 2.627281402729924

Epoch: 6| Step: 9
Training loss: 3.1515257576506106
Validation loss: 2.6142889505139792

Epoch: 6| Step: 10
Training loss: 3.0240588276706672
Validation loss: 2.6083508429957987

Epoch: 6| Step: 11
Training loss: 3.230873903563105
Validation loss: 2.6146614551006033

Epoch: 6| Step: 12
Training loss: 2.7394295324128013
Validation loss: 2.615358969485373

Epoch: 6| Step: 13
Training loss: 2.328596029059728
Validation loss: 2.6133541258452944

Epoch: 201| Step: 0
Training loss: 3.324288462749485
Validation loss: 2.6153537282162493

Epoch: 6| Step: 1
Training loss: 2.6020483531285583
Validation loss: 2.6140142812757965

Epoch: 6| Step: 2
Training loss: 2.446831666993871
Validation loss: 2.6100396566207493

Epoch: 6| Step: 3
Training loss: 3.9451151279142107
Validation loss: 2.6101128881659434

Epoch: 6| Step: 4
Training loss: 3.043123880332479
Validation loss: 2.6135439566643806

Epoch: 6| Step: 5
Training loss: 3.0223732191431054
Validation loss: 2.6105018595993963

Epoch: 6| Step: 6
Training loss: 3.2080220818746574
Validation loss: 2.6126042181903375

Epoch: 6| Step: 7
Training loss: 2.64095092206692
Validation loss: 2.616130048933889

Epoch: 6| Step: 8
Training loss: 2.85265390072889
Validation loss: 2.6213860076279474

Epoch: 6| Step: 9
Training loss: 3.100759868399133
Validation loss: 2.6278807434157283

Epoch: 6| Step: 10
Training loss: 2.8894302786016315
Validation loss: 2.6153119907929527

Epoch: 6| Step: 11
Training loss: 3.125922715337925
Validation loss: 2.610843852442791

Epoch: 6| Step: 12
Training loss: 2.1079214103279895
Validation loss: 2.6220933503257347

Epoch: 6| Step: 13
Training loss: 2.2993741096065587
Validation loss: 2.6433423303230845

Epoch: 202| Step: 0
Training loss: 2.888307209223263
Validation loss: 2.6658503968056566

Epoch: 6| Step: 1
Training loss: 3.1045794287246467
Validation loss: 2.689005535691407

Epoch: 6| Step: 2
Training loss: 3.602262284154608
Validation loss: 2.6961755475034095

Epoch: 6| Step: 3
Training loss: 3.264936894833665
Validation loss: 2.7229056728495826

Epoch: 6| Step: 4
Training loss: 2.5793067766710402
Validation loss: 2.6744596382338224

Epoch: 6| Step: 5
Training loss: 2.692153361896106
Validation loss: 2.6264424411470775

Epoch: 6| Step: 6
Training loss: 2.2212430889685457
Validation loss: 2.609178466548005

Epoch: 6| Step: 7
Training loss: 2.6065460219923997
Validation loss: 2.6103494647218017

Epoch: 6| Step: 8
Training loss: 3.137299708322249
Validation loss: 2.60582416347133

Epoch: 6| Step: 9
Training loss: 3.026721363693715
Validation loss: 2.608246458351678

Epoch: 6| Step: 10
Training loss: 3.039468537102681
Validation loss: 2.6124766249488474

Epoch: 6| Step: 11
Training loss: 2.926819233954682
Validation loss: 2.610690162660093

Epoch: 6| Step: 12
Training loss: 2.922034274569313
Validation loss: 2.6060187433643613

Epoch: 6| Step: 13
Training loss: 3.5783390164400504
Validation loss: 2.610322587280517

Epoch: 203| Step: 0
Training loss: 2.6401156323569572
Validation loss: 2.6076644331749144

Epoch: 6| Step: 1
Training loss: 3.2820512065902725
Validation loss: 2.6065715486482453

Epoch: 6| Step: 2
Training loss: 3.3374823180455357
Validation loss: 2.6056894702480125

Epoch: 6| Step: 3
Training loss: 2.5906692040955033
Validation loss: 2.6071825214489137

Epoch: 6| Step: 4
Training loss: 2.5218197387539987
Validation loss: 2.616184579857278

Epoch: 6| Step: 5
Training loss: 2.4559455741170044
Validation loss: 2.614611634138589

Epoch: 6| Step: 6
Training loss: 3.50886557219848
Validation loss: 2.6339213512929223

Epoch: 6| Step: 7
Training loss: 2.882028033615886
Validation loss: 2.6569922416930325

Epoch: 6| Step: 8
Training loss: 3.5984845362515596
Validation loss: 2.6664270474721006

Epoch: 6| Step: 9
Training loss: 2.379228141066176
Validation loss: 2.662681005112971

Epoch: 6| Step: 10
Training loss: 3.3763439187153743
Validation loss: 2.671255516147014

Epoch: 6| Step: 11
Training loss: 3.168822826022649
Validation loss: 2.655388090854729

Epoch: 6| Step: 12
Training loss: 2.3331250256697547
Validation loss: 2.6402740021943925

Epoch: 6| Step: 13
Training loss: 2.781980011534306
Validation loss: 2.624372453188799

Epoch: 204| Step: 0
Training loss: 2.7226974943914675
Validation loss: 2.6143206451461616

Epoch: 6| Step: 1
Training loss: 2.4686495603579437
Validation loss: 2.6088446965615852

Epoch: 6| Step: 2
Training loss: 3.490735052793504
Validation loss: 2.6137917747095214

Epoch: 6| Step: 3
Training loss: 2.4646729230250157
Validation loss: 2.5975995003534353

Epoch: 6| Step: 4
Training loss: 3.3389323100734525
Validation loss: 2.602008126476939

Epoch: 6| Step: 5
Training loss: 3.039011192378992
Validation loss: 2.602218635354578

Epoch: 6| Step: 6
Training loss: 3.3811893930133197
Validation loss: 2.6102979822022565

Epoch: 6| Step: 7
Training loss: 2.9576196122992435
Validation loss: 2.605580639972238

Epoch: 6| Step: 8
Training loss: 3.1569513731369185
Validation loss: 2.605059247694446

Epoch: 6| Step: 9
Training loss: 3.077124728417469
Validation loss: 2.6118149324452213

Epoch: 6| Step: 10
Training loss: 3.069684068657892
Validation loss: 2.607430648159083

Epoch: 6| Step: 11
Training loss: 1.9313728293459211
Validation loss: 2.6213723189260314

Epoch: 6| Step: 12
Training loss: 3.3169031209060904
Validation loss: 2.6208939567320924

Epoch: 6| Step: 13
Training loss: 1.9259059161521555
Validation loss: 2.620657267738257

Epoch: 205| Step: 0
Training loss: 2.4100676138482737
Validation loss: 2.6314691637959293

Epoch: 6| Step: 1
Training loss: 2.953164075158976
Validation loss: 2.6089064037508516

Epoch: 6| Step: 2
Training loss: 2.870802593389591
Validation loss: 2.6174215732173187

Epoch: 6| Step: 3
Training loss: 2.855617701954657
Validation loss: 2.6155444156275336

Epoch: 6| Step: 4
Training loss: 2.9812957696180336
Validation loss: 2.6244995735957732

Epoch: 6| Step: 5
Training loss: 3.140459654142118
Validation loss: 2.610367468632272

Epoch: 6| Step: 6
Training loss: 3.3246078891009048
Validation loss: 2.602861627883627

Epoch: 6| Step: 7
Training loss: 3.011129398298236
Validation loss: 2.612715268803034

Epoch: 6| Step: 8
Training loss: 2.8638374236011304
Validation loss: 2.6074782860057413

Epoch: 6| Step: 9
Training loss: 2.486076875684162
Validation loss: 2.6145275387663016

Epoch: 6| Step: 10
Training loss: 2.945705235855728
Validation loss: 2.610683441993143

Epoch: 6| Step: 11
Training loss: 2.540974621804792
Validation loss: 2.616683654332894

Epoch: 6| Step: 12
Training loss: 3.784283390716134
Validation loss: 2.626788198765967

Epoch: 6| Step: 13
Training loss: 2.6784287768933908
Validation loss: 2.623079745103258

Epoch: 206| Step: 0
Training loss: 3.1458472110534816
Validation loss: 2.626342607831672

Epoch: 6| Step: 1
Training loss: 2.826773304667179
Validation loss: 2.623440669509302

Epoch: 6| Step: 2
Training loss: 3.4535639557241233
Validation loss: 2.6466767531064543

Epoch: 6| Step: 3
Training loss: 2.0932510692484816
Validation loss: 2.6292300287378523

Epoch: 6| Step: 4
Training loss: 3.036083340050054
Validation loss: 2.6153153402803073

Epoch: 6| Step: 5
Training loss: 3.1042978826520953
Validation loss: 2.6312467166283

Epoch: 6| Step: 6
Training loss: 3.4240988555256564
Validation loss: 2.664290292872083

Epoch: 6| Step: 7
Training loss: 2.3931183621585235
Validation loss: 2.6453328836998167

Epoch: 6| Step: 8
Training loss: 3.184015800724408
Validation loss: 2.6503414747056024

Epoch: 6| Step: 9
Training loss: 2.949512350865844
Validation loss: 2.6335948649368865

Epoch: 6| Step: 10
Training loss: 2.098823322153622
Validation loss: 2.6187405333231744

Epoch: 6| Step: 11
Training loss: 3.1242000318855063
Validation loss: 2.6219004253837572

Epoch: 6| Step: 12
Training loss: 2.909442583686111
Validation loss: 2.6187053669078404

Epoch: 6| Step: 13
Training loss: 3.1709346786791737
Validation loss: 2.6071047855672846

Epoch: 207| Step: 0
Training loss: 3.206417419940585
Validation loss: 2.6059678796592123

Epoch: 6| Step: 1
Training loss: 2.320431690173138
Validation loss: 2.6101870674125935

Epoch: 6| Step: 2
Training loss: 2.9996048349156617
Validation loss: 2.6022208677600758

Epoch: 6| Step: 3
Training loss: 3.266012798445434
Validation loss: 2.616032526801719

Epoch: 6| Step: 4
Training loss: 3.4716607330706197
Validation loss: 2.612163046277501

Epoch: 6| Step: 5
Training loss: 3.2741031379649947
Validation loss: 2.611201346138663

Epoch: 6| Step: 6
Training loss: 2.907296597294241
Validation loss: 2.603287863495861

Epoch: 6| Step: 7
Training loss: 2.843329765374232
Validation loss: 2.6061367789666052

Epoch: 6| Step: 8
Training loss: 3.1036857044629054
Validation loss: 2.598231254085385

Epoch: 6| Step: 9
Training loss: 3.013729784663154
Validation loss: 2.608053925086257

Epoch: 6| Step: 10
Training loss: 1.6384540544947195
Validation loss: 2.6028230990446213

Epoch: 6| Step: 11
Training loss: 2.9720950906566355
Validation loss: 2.5994653501710987

Epoch: 6| Step: 12
Training loss: 3.2609923873105955
Validation loss: 2.614301200469663

Epoch: 6| Step: 13
Training loss: 2.076185425564317
Validation loss: 2.603624971881374

Epoch: 208| Step: 0
Training loss: 2.7947567211861633
Validation loss: 2.606417650223148

Epoch: 6| Step: 1
Training loss: 3.099316761648942
Validation loss: 2.6048317097385336

Epoch: 6| Step: 2
Training loss: 3.8621943133723353
Validation loss: 2.6096469510729983

Epoch: 6| Step: 3
Training loss: 2.577103846064112
Validation loss: 2.6099833422295724

Epoch: 6| Step: 4
Training loss: 3.1500612525434155
Validation loss: 2.605784632628396

Epoch: 6| Step: 5
Training loss: 2.522087751866059
Validation loss: 2.601545130868686

Epoch: 6| Step: 6
Training loss: 3.0114356475647672
Validation loss: 2.6146980642546285

Epoch: 6| Step: 7
Training loss: 2.9283955484669844
Validation loss: 2.6127864600324933

Epoch: 6| Step: 8
Training loss: 2.895680723125525
Validation loss: 2.6312162109166577

Epoch: 6| Step: 9
Training loss: 2.8220907506916144
Validation loss: 2.601901861636043

Epoch: 6| Step: 10
Training loss: 2.590563919948675
Validation loss: 2.611343003200399

Epoch: 6| Step: 11
Training loss: 3.077061968199558
Validation loss: 2.614825332424628

Epoch: 6| Step: 12
Training loss: 3.108994810544821
Validation loss: 2.608177252557245

Epoch: 6| Step: 13
Training loss: 2.1534488561760115
Validation loss: 2.6181469542995743

Epoch: 209| Step: 0
Training loss: 2.408189264583998
Validation loss: 2.6046897881234643

Epoch: 6| Step: 1
Training loss: 2.637222897404712
Validation loss: 2.6043307509053

Epoch: 6| Step: 2
Training loss: 3.141820575644162
Validation loss: 2.601709661928691

Epoch: 6| Step: 3
Training loss: 3.5500089940776527
Validation loss: 2.600127263539689

Epoch: 6| Step: 4
Training loss: 2.6987821940860144
Validation loss: 2.6033368691450622

Epoch: 6| Step: 5
Training loss: 3.0594252117583745
Validation loss: 2.6139128767934876

Epoch: 6| Step: 6
Training loss: 3.019223137023041
Validation loss: 2.5997490652924666

Epoch: 6| Step: 7
Training loss: 3.0023365458417666
Validation loss: 2.5963126074822727

Epoch: 6| Step: 8
Training loss: 3.617486599447215
Validation loss: 2.6034465366722253

Epoch: 6| Step: 9
Training loss: 2.713487464719785
Validation loss: 2.599357285505993

Epoch: 6| Step: 10
Training loss: 3.2017814982081565
Validation loss: 2.6075375194436172

Epoch: 6| Step: 11
Training loss: 3.052884167140325
Validation loss: 2.6155946098968674

Epoch: 6| Step: 12
Training loss: 2.182257774168744
Validation loss: 2.6197611815300585

Epoch: 6| Step: 13
Training loss: 2.138567192964594
Validation loss: 2.6285943611492786

Epoch: 210| Step: 0
Training loss: 2.9000808704544396
Validation loss: 2.6228868433556864

Epoch: 6| Step: 1
Training loss: 2.6082989878317853
Validation loss: 2.6281170384089885

Epoch: 6| Step: 2
Training loss: 3.383131333758706
Validation loss: 2.6858631022579775

Epoch: 6| Step: 3
Training loss: 2.9872952698343704
Validation loss: 2.6923991823771267

Epoch: 6| Step: 4
Training loss: 3.3328448573462954
Validation loss: 2.6452791717082915

Epoch: 6| Step: 5
Training loss: 2.838676370113494
Validation loss: 2.6403455426795266

Epoch: 6| Step: 6
Training loss: 3.020488394851504
Validation loss: 2.636613954127318

Epoch: 6| Step: 7
Training loss: 2.9782460175110304
Validation loss: 2.6036502061852893

Epoch: 6| Step: 8
Training loss: 2.7113239111879266
Validation loss: 2.6023190040288706

Epoch: 6| Step: 9
Training loss: 2.9001489403723344
Validation loss: 2.594127741682253

Epoch: 6| Step: 10
Training loss: 2.923915864268882
Validation loss: 2.5929687564858024

Epoch: 6| Step: 11
Training loss: 3.0150863878010727
Validation loss: 2.59016546158209

Epoch: 6| Step: 12
Training loss: 2.948608173551178
Validation loss: 2.590685966315925

Epoch: 6| Step: 13
Training loss: 2.2812999563103538
Validation loss: 2.59593803332746

Epoch: 211| Step: 0
Training loss: 3.0966823052160963
Validation loss: 2.5939141972827153

Epoch: 6| Step: 1
Training loss: 2.3199836677765644
Validation loss: 2.5849613113905434

Epoch: 6| Step: 2
Training loss: 3.5057475717722895
Validation loss: 2.5900938891108747

Epoch: 6| Step: 3
Training loss: 2.997416337399099
Validation loss: 2.5927175628417807

Epoch: 6| Step: 4
Training loss: 3.039644239589805
Validation loss: 2.5855758459205758

Epoch: 6| Step: 5
Training loss: 1.5925964219682245
Validation loss: 2.5899618927342543

Epoch: 6| Step: 6
Training loss: 3.343618515138991
Validation loss: 2.591758804838561

Epoch: 6| Step: 7
Training loss: 3.448403423021691
Validation loss: 2.5922980733894025

Epoch: 6| Step: 8
Training loss: 3.1379177894399484
Validation loss: 2.5871227197612168

Epoch: 6| Step: 9
Training loss: 2.859510241369246
Validation loss: 2.5844728293434454

Epoch: 6| Step: 10
Training loss: 2.527970249640776
Validation loss: 2.5883329814970897

Epoch: 6| Step: 11
Training loss: 2.868696683500413
Validation loss: 2.5850306835143804

Epoch: 6| Step: 12
Training loss: 2.5524911567616995
Validation loss: 2.586808149816344

Epoch: 6| Step: 13
Training loss: 3.6215190617103006
Validation loss: 2.596753614199913

Epoch: 212| Step: 0
Training loss: 3.285537244043146
Validation loss: 2.594656621627697

Epoch: 6| Step: 1
Training loss: 2.528093795678098
Validation loss: 2.6021767680375727

Epoch: 6| Step: 2
Training loss: 2.9306193179585764
Validation loss: 2.602552769485619

Epoch: 6| Step: 3
Training loss: 3.315894061504985
Validation loss: 2.6122207386756715

Epoch: 6| Step: 4
Training loss: 2.567706703252578
Validation loss: 2.623609399133141

Epoch: 6| Step: 5
Training loss: 2.7584664323239565
Validation loss: 2.619258260619778

Epoch: 6| Step: 6
Training loss: 3.3728910850856995
Validation loss: 2.6280487577799057

Epoch: 6| Step: 7
Training loss: 3.27223755322506
Validation loss: 2.6245954234002764

Epoch: 6| Step: 8
Training loss: 3.4720349952234986
Validation loss: 2.631352201698423

Epoch: 6| Step: 9
Training loss: 3.0708634753324446
Validation loss: 2.61158019964765

Epoch: 6| Step: 10
Training loss: 2.5765812731464353
Validation loss: 2.5974912628200904

Epoch: 6| Step: 11
Training loss: 2.3480506603747977
Validation loss: 2.598824256257863

Epoch: 6| Step: 12
Training loss: 2.525099640948117
Validation loss: 2.5938491733141946

Epoch: 6| Step: 13
Training loss: 2.7689845483086346
Validation loss: 2.5905991982145506

Epoch: 213| Step: 0
Training loss: 3.3674591025720146
Validation loss: 2.5903517909453857

Epoch: 6| Step: 1
Training loss: 3.222155648855539
Validation loss: 2.5872152346863726

Epoch: 6| Step: 2
Training loss: 2.852795645181067
Validation loss: 2.5874886201252885

Epoch: 6| Step: 3
Training loss: 2.867561336749317
Validation loss: 2.5860625989194146

Epoch: 6| Step: 4
Training loss: 2.6043614632547882
Validation loss: 2.589849360647122

Epoch: 6| Step: 5
Training loss: 2.939743483894238
Validation loss: 2.5838291560392337

Epoch: 6| Step: 6
Training loss: 2.7799907791204324
Validation loss: 2.5910326673225432

Epoch: 6| Step: 7
Training loss: 2.8979319005511384
Validation loss: 2.5855449312485663

Epoch: 6| Step: 8
Training loss: 2.164895458560663
Validation loss: 2.585303865630931

Epoch: 6| Step: 9
Training loss: 2.9681448871896565
Validation loss: 2.5883721489468

Epoch: 6| Step: 10
Training loss: 3.2489764729285233
Validation loss: 2.58607782272466

Epoch: 6| Step: 11
Training loss: 2.947521726934258
Validation loss: 2.5949002594196258

Epoch: 6| Step: 12
Training loss: 2.8436069662152863
Validation loss: 2.5905623722025948

Epoch: 6| Step: 13
Training loss: 3.5238613372783605
Validation loss: 2.5914752650408173

Epoch: 214| Step: 0
Training loss: 3.1412419714257727
Validation loss: 2.5945149892425956

Epoch: 6| Step: 1
Training loss: 2.823856821256054
Validation loss: 2.610076474985245

Epoch: 6| Step: 2
Training loss: 3.287518716621061
Validation loss: 2.6050283910341747

Epoch: 6| Step: 3
Training loss: 2.687479507013301
Validation loss: 2.597369319080056

Epoch: 6| Step: 4
Training loss: 2.6357344082763117
Validation loss: 2.599150799947913

Epoch: 6| Step: 5
Training loss: 3.288883304018428
Validation loss: 2.596684546870011

Epoch: 6| Step: 6
Training loss: 3.0316174471234203
Validation loss: 2.589417235944379

Epoch: 6| Step: 7
Training loss: 3.422483067940848
Validation loss: 2.5960901948422594

Epoch: 6| Step: 8
Training loss: 2.9769371778108327
Validation loss: 2.594522826841103

Epoch: 6| Step: 9
Training loss: 3.1029824338434806
Validation loss: 2.59430304693839

Epoch: 6| Step: 10
Training loss: 2.9745664136342786
Validation loss: 2.5946898494089035

Epoch: 6| Step: 11
Training loss: 2.575368436361643
Validation loss: 2.589924409307814

Epoch: 6| Step: 12
Training loss: 2.4568622088238836
Validation loss: 2.6010420231590965

Epoch: 6| Step: 13
Training loss: 2.216870115977592
Validation loss: 2.598654072229132

Epoch: 215| Step: 0
Training loss: 3.336608247528191
Validation loss: 2.610293963340951

Epoch: 6| Step: 1
Training loss: 3.3396608536818144
Validation loss: 2.6326312247397734

Epoch: 6| Step: 2
Training loss: 3.3860583513958553
Validation loss: 2.6428560347702623

Epoch: 6| Step: 3
Training loss: 2.567010120432824
Validation loss: 2.6240650041220914

Epoch: 6| Step: 4
Training loss: 3.060465078228496
Validation loss: 2.6278549701175105

Epoch: 6| Step: 5
Training loss: 2.850145965318374
Validation loss: 2.626157608893158

Epoch: 6| Step: 6
Training loss: 2.841075268133391
Validation loss: 2.617619500392224

Epoch: 6| Step: 7
Training loss: 2.579587579336622
Validation loss: 2.59411307209271

Epoch: 6| Step: 8
Training loss: 3.013522032537406
Validation loss: 2.5828937456869347

Epoch: 6| Step: 9
Training loss: 2.0903206824725507
Validation loss: 2.5841034780921612

Epoch: 6| Step: 10
Training loss: 2.5261490841603256
Validation loss: 2.5802199606579417

Epoch: 6| Step: 11
Training loss: 3.3867982989233845
Validation loss: 2.5866744882262176

Epoch: 6| Step: 12
Training loss: 3.093665073654816
Validation loss: 2.585293562672106

Epoch: 6| Step: 13
Training loss: 2.5822250593570715
Validation loss: 2.580851332763217

Epoch: 216| Step: 0
Training loss: 2.7236370142715884
Validation loss: 2.584440787515724

Epoch: 6| Step: 1
Training loss: 2.6267088822620868
Validation loss: 2.5849573756196045

Epoch: 6| Step: 2
Training loss: 3.06243180179566
Validation loss: 2.5794864861861337

Epoch: 6| Step: 3
Training loss: 2.586963369404347
Validation loss: 2.583324321872688

Epoch: 6| Step: 4
Training loss: 2.6966398205106517
Validation loss: 2.579032827111228

Epoch: 6| Step: 5
Training loss: 3.152311379267656
Validation loss: 2.5905231646359117

Epoch: 6| Step: 6
Training loss: 3.1657220703184707
Validation loss: 2.5786489412339866

Epoch: 6| Step: 7
Training loss: 3.192802655982488
Validation loss: 2.588834822768803

Epoch: 6| Step: 8
Training loss: 2.3327927871555962
Validation loss: 2.594846515183929

Epoch: 6| Step: 9
Training loss: 2.983013381708037
Validation loss: 2.590494234832779

Epoch: 6| Step: 10
Training loss: 3.0985061614815708
Validation loss: 2.592625714939494

Epoch: 6| Step: 11
Training loss: 2.9356433601284424
Validation loss: 2.6039731202752985

Epoch: 6| Step: 12
Training loss: 3.615941799201813
Validation loss: 2.603665441371415

Epoch: 6| Step: 13
Training loss: 2.445639981409908
Validation loss: 2.6240952695938398

Epoch: 217| Step: 0
Training loss: 3.0827410017288566
Validation loss: 2.651752968725127

Epoch: 6| Step: 1
Training loss: 2.9965651239568043
Validation loss: 2.648394577864819

Epoch: 6| Step: 2
Training loss: 2.4214164053590803
Validation loss: 2.629158900528831

Epoch: 6| Step: 3
Training loss: 3.4440940726587654
Validation loss: 2.6492745417420775

Epoch: 6| Step: 4
Training loss: 3.431977986583047
Validation loss: 2.619599236545666

Epoch: 6| Step: 5
Training loss: 2.738983020837084
Validation loss: 2.6243277175708046

Epoch: 6| Step: 6
Training loss: 2.7130183168574
Validation loss: 2.602080779126627

Epoch: 6| Step: 7
Training loss: 2.4841444760261018
Validation loss: 2.611784149709906

Epoch: 6| Step: 8
Training loss: 2.9278687388384874
Validation loss: 2.595380539164085

Epoch: 6| Step: 9
Training loss: 2.7028684990522467
Validation loss: 2.6014202482682838

Epoch: 6| Step: 10
Training loss: 2.4138088648615046
Validation loss: 2.5732006088863772

Epoch: 6| Step: 11
Training loss: 3.095986530797082
Validation loss: 2.5827949338659453

Epoch: 6| Step: 12
Training loss: 3.2612560195253204
Validation loss: 2.5813672661894924

Epoch: 6| Step: 13
Training loss: 3.212095771026844
Validation loss: 2.58304068892229

Epoch: 218| Step: 0
Training loss: 2.750777654799864
Validation loss: 2.586887238871863

Epoch: 6| Step: 1
Training loss: 2.769834601356563
Validation loss: 2.577421928887917

Epoch: 6| Step: 2
Training loss: 3.225622746866493
Validation loss: 2.5843102106286215

Epoch: 6| Step: 3
Training loss: 3.2179241417193714
Validation loss: 2.575789606054674

Epoch: 6| Step: 4
Training loss: 2.511955475515862
Validation loss: 2.5778028667881183

Epoch: 6| Step: 5
Training loss: 2.7099123728756527
Validation loss: 2.5831828362976434

Epoch: 6| Step: 6
Training loss: 2.6554869509480317
Validation loss: 2.574418690208371

Epoch: 6| Step: 7
Training loss: 2.9648128703925503
Validation loss: 2.5769814519073555

Epoch: 6| Step: 8
Training loss: 3.202387580655383
Validation loss: 2.5855608581165153

Epoch: 6| Step: 9
Training loss: 3.027130946401658
Validation loss: 2.5786784204843007

Epoch: 6| Step: 10
Training loss: 2.3734804612893003
Validation loss: 2.578045016651813

Epoch: 6| Step: 11
Training loss: 3.4897472893454125
Validation loss: 2.574604917507858

Epoch: 6| Step: 12
Training loss: 3.081922328556937
Validation loss: 2.5799158771626147

Epoch: 6| Step: 13
Training loss: 2.8776521474483094
Validation loss: 2.583254413676115

Epoch: 219| Step: 0
Training loss: 2.328444798158219
Validation loss: 2.5902403239223846

Epoch: 6| Step: 1
Training loss: 3.1026925975643267
Validation loss: 2.5986501073768324

Epoch: 6| Step: 2
Training loss: 3.1585025114647602
Validation loss: 2.6117336417197707

Epoch: 6| Step: 3
Training loss: 2.3313526079848086
Validation loss: 2.6067515647649495

Epoch: 6| Step: 4
Training loss: 3.5040504995739505
Validation loss: 2.6138012228629077

Epoch: 6| Step: 5
Training loss: 2.583282490711933
Validation loss: 2.6256471930881298

Epoch: 6| Step: 6
Training loss: 2.441265425626008
Validation loss: 2.617525511653933

Epoch: 6| Step: 7
Training loss: 3.346578952151495
Validation loss: 2.637877319489171

Epoch: 6| Step: 8
Training loss: 2.751458474856759
Validation loss: 2.625427467164134

Epoch: 6| Step: 9
Training loss: 3.345199983603051
Validation loss: 2.6170248726458296

Epoch: 6| Step: 10
Training loss: 3.3279484805007407
Validation loss: 2.6181863053434253

Epoch: 6| Step: 11
Training loss: 3.009534308315771
Validation loss: 2.6034487640859845

Epoch: 6| Step: 12
Training loss: 2.677362885085363
Validation loss: 2.595271531448491

Epoch: 6| Step: 13
Training loss: 2.4485613900532237
Validation loss: 2.5824979515739814

Epoch: 220| Step: 0
Training loss: 2.57575574728617
Validation loss: 2.5848535458641853

Epoch: 6| Step: 1
Training loss: 2.7916976490484053
Validation loss: 2.589621339621255

Epoch: 6| Step: 2
Training loss: 2.8971227249839044
Validation loss: 2.576991331476465

Epoch: 6| Step: 3
Training loss: 2.7656595691309223
Validation loss: 2.5801195490635127

Epoch: 6| Step: 4
Training loss: 3.17755580369883
Validation loss: 2.578655817966351

Epoch: 6| Step: 5
Training loss: 3.5645406132242616
Validation loss: 2.577556675990365

Epoch: 6| Step: 6
Training loss: 2.678081242349642
Validation loss: 2.5796626025622427

Epoch: 6| Step: 7
Training loss: 2.1570163415423314
Validation loss: 2.585654693566033

Epoch: 6| Step: 8
Training loss: 3.207128488458093
Validation loss: 2.5783995859064492

Epoch: 6| Step: 9
Training loss: 3.1015289842923077
Validation loss: 2.580303361936755

Epoch: 6| Step: 10
Training loss: 3.411825114715483
Validation loss: 2.59306567589302

Epoch: 6| Step: 11
Training loss: 2.5081193682723577
Validation loss: 2.610201088796681

Epoch: 6| Step: 12
Training loss: 2.910528008186485
Validation loss: 2.6129512025711876

Epoch: 6| Step: 13
Training loss: 2.8588024462520627
Validation loss: 2.628927598419296

Epoch: 221| Step: 0
Training loss: 2.92431538712883
Validation loss: 2.612763011442353

Epoch: 6| Step: 1
Training loss: 3.382939501486146
Validation loss: 2.6122911818343724

Epoch: 6| Step: 2
Training loss: 3.0909983410418924
Validation loss: 2.606690467466905

Epoch: 6| Step: 3
Training loss: 2.578810352205373
Validation loss: 2.592355801431455

Epoch: 6| Step: 4
Training loss: 2.2680638308146035
Validation loss: 2.584735863429446

Epoch: 6| Step: 5
Training loss: 3.1101608433482313
Validation loss: 2.5733897954175737

Epoch: 6| Step: 6
Training loss: 2.841913657394254
Validation loss: 2.577418027855622

Epoch: 6| Step: 7
Training loss: 3.3217748675322425
Validation loss: 2.573241998208941

Epoch: 6| Step: 8
Training loss: 2.742777008421579
Validation loss: 2.5778778116771988

Epoch: 6| Step: 9
Training loss: 2.7391960150671877
Validation loss: 2.5795898849934114

Epoch: 6| Step: 10
Training loss: 3.0991329026406693
Validation loss: 2.575787002391985

Epoch: 6| Step: 11
Training loss: 2.462555659095954
Validation loss: 2.5775488882521986

Epoch: 6| Step: 12
Training loss: 3.2351038014946774
Validation loss: 2.5834843114769126

Epoch: 6| Step: 13
Training loss: 2.8406913992965865
Validation loss: 2.5776781039751406

Epoch: 222| Step: 0
Training loss: 2.9763853165563603
Validation loss: 2.569711752056312

Epoch: 6| Step: 1
Training loss: 3.5484482557166497
Validation loss: 2.573664595663297

Epoch: 6| Step: 2
Training loss: 2.8165545589851857
Validation loss: 2.5679143215520677

Epoch: 6| Step: 3
Training loss: 2.7412212006064554
Validation loss: 2.573894015355727

Epoch: 6| Step: 4
Training loss: 3.4897940197252133
Validation loss: 2.5739108131173976

Epoch: 6| Step: 5
Training loss: 1.9756791625039896
Validation loss: 2.570246564748322

Epoch: 6| Step: 6
Training loss: 2.7585066227103066
Validation loss: 2.566309940088524

Epoch: 6| Step: 7
Training loss: 3.4972542482956084
Validation loss: 2.570211044031195

Epoch: 6| Step: 8
Training loss: 2.9768618936228153
Validation loss: 2.570916647521792

Epoch: 6| Step: 9
Training loss: 2.640060093513646
Validation loss: 2.5722193682068197

Epoch: 6| Step: 10
Training loss: 2.6388198731973262
Validation loss: 2.564386269316693

Epoch: 6| Step: 11
Training loss: 2.792023612209477
Validation loss: 2.575491757243636

Epoch: 6| Step: 12
Training loss: 2.631459417640145
Validation loss: 2.575147376107669

Epoch: 6| Step: 13
Training loss: 3.208523847860196
Validation loss: 2.5830758118926815

Epoch: 223| Step: 0
Training loss: 2.673952689101104
Validation loss: 2.603622245403977

Epoch: 6| Step: 1
Training loss: 2.867823392529984
Validation loss: 2.6011551472763035

Epoch: 6| Step: 2
Training loss: 3.0021017977172963
Validation loss: 2.592309888290316

Epoch: 6| Step: 3
Training loss: 3.1068337949185576
Validation loss: 2.631868793293802

Epoch: 6| Step: 4
Training loss: 3.1365410361297177
Validation loss: 2.625713413563868

Epoch: 6| Step: 5
Training loss: 2.67262471706474
Validation loss: 2.598891234172368

Epoch: 6| Step: 6
Training loss: 2.9791463215451137
Validation loss: 2.620292025879351

Epoch: 6| Step: 7
Training loss: 2.5974546884911485
Validation loss: 2.604860444878121

Epoch: 6| Step: 8
Training loss: 3.0635526755268203
Validation loss: 2.598422197616978

Epoch: 6| Step: 9
Training loss: 3.4026115653689764
Validation loss: 2.5950674325517777

Epoch: 6| Step: 10
Training loss: 2.7392112469582637
Validation loss: 2.594949396794592

Epoch: 6| Step: 11
Training loss: 3.066378570237332
Validation loss: 2.6046540196014494

Epoch: 6| Step: 12
Training loss: 3.034547565554428
Validation loss: 2.5891463304998545

Epoch: 6| Step: 13
Training loss: 2.1883617338655577
Validation loss: 2.578169566813689

Epoch: 224| Step: 0
Training loss: 2.2862782910715076
Validation loss: 2.5749858231377747

Epoch: 6| Step: 1
Training loss: 2.8257973718750167
Validation loss: 2.573186106924068

Epoch: 6| Step: 2
Training loss: 2.304272009687421
Validation loss: 2.581749873053156

Epoch: 6| Step: 3
Training loss: 2.5910263468478694
Validation loss: 2.583336137127686

Epoch: 6| Step: 4
Training loss: 3.207308684045079
Validation loss: 2.5797445173115126

Epoch: 6| Step: 5
Training loss: 2.2396325630868916
Validation loss: 2.572983853018963

Epoch: 6| Step: 6
Training loss: 2.5202749175020647
Validation loss: 2.577029629246737

Epoch: 6| Step: 7
Training loss: 3.3525867097637274
Validation loss: 2.5778442160304658

Epoch: 6| Step: 8
Training loss: 2.747653306705134
Validation loss: 2.5852294186406

Epoch: 6| Step: 9
Training loss: 3.1892749108201865
Validation loss: 2.588588103531107

Epoch: 6| Step: 10
Training loss: 3.2052408812842232
Validation loss: 2.5926341960363373

Epoch: 6| Step: 11
Training loss: 3.571140051495463
Validation loss: 2.5994329808013736

Epoch: 6| Step: 12
Training loss: 3.508426332185007
Validation loss: 2.602385777725686

Epoch: 6| Step: 13
Training loss: 3.043044749181323
Validation loss: 2.582993061891918

Epoch: 225| Step: 0
Training loss: 3.1067407845863655
Validation loss: 2.565111713680452

Epoch: 6| Step: 1
Training loss: 2.2846940053983644
Validation loss: 2.56783711809068

Epoch: 6| Step: 2
Training loss: 2.8099274632061633
Validation loss: 2.562138114444957

Epoch: 6| Step: 3
Training loss: 2.9629471131624925
Validation loss: 2.5672437656974743

Epoch: 6| Step: 4
Training loss: 2.9998187964074257
Validation loss: 2.57675610467771

Epoch: 6| Step: 5
Training loss: 3.0819865369756436
Validation loss: 2.571719848090048

Epoch: 6| Step: 6
Training loss: 3.253588822395929
Validation loss: 2.5778832842792667

Epoch: 6| Step: 7
Training loss: 3.184021491586814
Validation loss: 2.5672564059008356

Epoch: 6| Step: 8
Training loss: 2.9276322543585036
Validation loss: 2.5691495842233847

Epoch: 6| Step: 9
Training loss: 2.4310676604395463
Validation loss: 2.5676793385084413

Epoch: 6| Step: 10
Training loss: 2.7684228398113273
Validation loss: 2.5632655623128136

Epoch: 6| Step: 11
Training loss: 3.243559985760335
Validation loss: 2.563717595595171

Epoch: 6| Step: 12
Training loss: 2.857276521689654
Validation loss: 2.5594756504562466

Epoch: 6| Step: 13
Training loss: 2.9319810358347524
Validation loss: 2.5627102369198247

Epoch: 226| Step: 0
Training loss: 2.7906887751999245
Validation loss: 2.565795903776761

Epoch: 6| Step: 1
Training loss: 2.892001097703992
Validation loss: 2.571560278501255

Epoch: 6| Step: 2
Training loss: 2.908854968083111
Validation loss: 2.573581598841432

Epoch: 6| Step: 3
Training loss: 2.1959943153780266
Validation loss: 2.5892193252350646

Epoch: 6| Step: 4
Training loss: 2.9357370808617684
Validation loss: 2.5883554480068387

Epoch: 6| Step: 5
Training loss: 2.5091690720067636
Validation loss: 2.6243314013645573

Epoch: 6| Step: 6
Training loss: 3.3650403888426776
Validation loss: 2.640879221304313

Epoch: 6| Step: 7
Training loss: 2.8053302506561653
Validation loss: 2.671215968929977

Epoch: 6| Step: 8
Training loss: 2.8978150719925666
Validation loss: 2.686191676318204

Epoch: 6| Step: 9
Training loss: 3.0288948269427687
Validation loss: 2.6346366208133394

Epoch: 6| Step: 10
Training loss: 3.26735863914671
Validation loss: 2.601359784590574

Epoch: 6| Step: 11
Training loss: 3.012307669803766
Validation loss: 2.5867239671891045

Epoch: 6| Step: 12
Training loss: 2.8842630846127344
Validation loss: 2.567375872620832

Epoch: 6| Step: 13
Training loss: 3.501715375975155
Validation loss: 2.5615590536664206

Epoch: 227| Step: 0
Training loss: 2.698128729970765
Validation loss: 2.5633155491388

Epoch: 6| Step: 1
Training loss: 2.9396550815692972
Validation loss: 2.5608120893379125

Epoch: 6| Step: 2
Training loss: 2.9394651292321328
Validation loss: 2.56392173133966

Epoch: 6| Step: 3
Training loss: 3.328495202048306
Validation loss: 2.5687096184029365

Epoch: 6| Step: 4
Training loss: 2.92060669488148
Validation loss: 2.5804126572275567

Epoch: 6| Step: 5
Training loss: 2.21295666911733
Validation loss: 2.5838743080719886

Epoch: 6| Step: 6
Training loss: 3.485527498011182
Validation loss: 2.574983714468655

Epoch: 6| Step: 7
Training loss: 3.195955319088696
Validation loss: 2.574697287790802

Epoch: 6| Step: 8
Training loss: 2.9037177426225163
Validation loss: 2.56902630766559

Epoch: 6| Step: 9
Training loss: 2.519967448009176
Validation loss: 2.564748683791849

Epoch: 6| Step: 10
Training loss: 2.8763744551794175
Validation loss: 2.5640245989967028

Epoch: 6| Step: 11
Training loss: 3.24325374857172
Validation loss: 2.5659930124887933

Epoch: 6| Step: 12
Training loss: 2.6144878071106534
Validation loss: 2.560195888408309

Epoch: 6| Step: 13
Training loss: 3.122699348432879
Validation loss: 2.5677269041333384

Epoch: 228| Step: 0
Training loss: 3.3313432633905498
Validation loss: 2.5747009280880833

Epoch: 6| Step: 1
Training loss: 3.0551011373757704
Validation loss: 2.5766358898726294

Epoch: 6| Step: 2
Training loss: 3.156828572338358
Validation loss: 2.585545546987487

Epoch: 6| Step: 3
Training loss: 2.6519496439530106
Validation loss: 2.580763281373658

Epoch: 6| Step: 4
Training loss: 2.735991953553531
Validation loss: 2.5745372828782016

Epoch: 6| Step: 5
Training loss: 3.088118542940654
Validation loss: 2.591428037378329

Epoch: 6| Step: 6
Training loss: 2.4399128244805084
Validation loss: 2.596234343216001

Epoch: 6| Step: 7
Training loss: 2.780256629734935
Validation loss: 2.6064224491436683

Epoch: 6| Step: 8
Training loss: 3.3974981303206375
Validation loss: 2.649078955011875

Epoch: 6| Step: 9
Training loss: 2.341162715818462
Validation loss: 2.631377281169999

Epoch: 6| Step: 10
Training loss: 2.1936576280410076
Validation loss: 2.6025899153985046

Epoch: 6| Step: 11
Training loss: 3.3529409850467906
Validation loss: 2.585421328358501

Epoch: 6| Step: 12
Training loss: 3.0729459771951353
Validation loss: 2.5788678950637802

Epoch: 6| Step: 13
Training loss: 2.8100682236069794
Validation loss: 2.5627447722207886

Epoch: 229| Step: 0
Training loss: 3.0238683428083757
Validation loss: 2.556534919191445

Epoch: 6| Step: 1
Training loss: 3.103449403645687
Validation loss: 2.5619225060126727

Epoch: 6| Step: 2
Training loss: 3.143993488081772
Validation loss: 2.561308371865751

Epoch: 6| Step: 3
Training loss: 2.7404555369477888
Validation loss: 2.5725511230867912

Epoch: 6| Step: 4
Training loss: 2.459620047434253
Validation loss: 2.582100007834542

Epoch: 6| Step: 5
Training loss: 3.1683633843096626
Validation loss: 2.6025770724881103

Epoch: 6| Step: 6
Training loss: 2.9275503272495764
Validation loss: 2.6079425049414575

Epoch: 6| Step: 7
Training loss: 2.8195435381817378
Validation loss: 2.6300124202749884

Epoch: 6| Step: 8
Training loss: 3.136318613566036
Validation loss: 2.681710511300656

Epoch: 6| Step: 9
Training loss: 2.998488840336505
Validation loss: 2.6882967634698987

Epoch: 6| Step: 10
Training loss: 2.7109130506484838
Validation loss: 2.6129017846285687

Epoch: 6| Step: 11
Training loss: 2.5231145409987854
Validation loss: 2.580031929777216

Epoch: 6| Step: 12
Training loss: 2.740552713795797
Validation loss: 2.560396822527716

Epoch: 6| Step: 13
Training loss: 3.594724042166666
Validation loss: 2.5643694141635986

Epoch: 230| Step: 0
Training loss: 3.056466835614598
Validation loss: 2.562710706090053

Epoch: 6| Step: 1
Training loss: 2.527563636801225
Validation loss: 2.5613449518833256

Epoch: 6| Step: 2
Training loss: 2.7039336830561735
Validation loss: 2.567459774003163

Epoch: 6| Step: 3
Training loss: 2.223924325389651
Validation loss: 2.5660557101911787

Epoch: 6| Step: 4
Training loss: 3.1006536040844637
Validation loss: 2.5630996486700366

Epoch: 6| Step: 5
Training loss: 3.0295221182278143
Validation loss: 2.564164070313829

Epoch: 6| Step: 6
Training loss: 3.200260574937228
Validation loss: 2.559435798401377

Epoch: 6| Step: 7
Training loss: 3.1067677977750434
Validation loss: 2.5588066693196425

Epoch: 6| Step: 8
Training loss: 3.0083311748408836
Validation loss: 2.564684762122952

Epoch: 6| Step: 9
Training loss: 3.619956355385045
Validation loss: 2.560695538594402

Epoch: 6| Step: 10
Training loss: 2.9943565693898977
Validation loss: 2.5635455039852673

Epoch: 6| Step: 11
Training loss: 2.7246268760638643
Validation loss: 2.5679683888496934

Epoch: 6| Step: 12
Training loss: 2.8094438690807877
Validation loss: 2.5700171715802855

Epoch: 6| Step: 13
Training loss: 2.5040971561205967
Validation loss: 2.5791268558349674

Epoch: 231| Step: 0
Training loss: 3.274546724357434
Validation loss: 2.576964778618528

Epoch: 6| Step: 1
Training loss: 2.8951701953252944
Validation loss: 2.576573126257017

Epoch: 6| Step: 2
Training loss: 2.5294337408674052
Validation loss: 2.588093711916156

Epoch: 6| Step: 3
Training loss: 3.31006273538657
Validation loss: 2.577841767594597

Epoch: 6| Step: 4
Training loss: 2.8452523423632625
Validation loss: 2.5763519892627924

Epoch: 6| Step: 5
Training loss: 3.2328061339295857
Validation loss: 2.5732385889749585

Epoch: 6| Step: 6
Training loss: 2.718911703277568
Validation loss: 2.5772366491956538

Epoch: 6| Step: 7
Training loss: 2.107231124433147
Validation loss: 2.5687787607581574

Epoch: 6| Step: 8
Training loss: 3.1853929923362676
Validation loss: 2.5667508700664303

Epoch: 6| Step: 9
Training loss: 2.5941973380891774
Validation loss: 2.5552706542545462

Epoch: 6| Step: 10
Training loss: 2.691930268630113
Validation loss: 2.5646500010448725

Epoch: 6| Step: 11
Training loss: 2.8105577332139107
Validation loss: 2.563526590213645

Epoch: 6| Step: 12
Training loss: 3.228171771616335
Validation loss: 2.5688920911130833

Epoch: 6| Step: 13
Training loss: 3.0877266248550677
Validation loss: 2.5614058076560293

Epoch: 232| Step: 0
Training loss: 2.697097054862125
Validation loss: 2.57131618344327

Epoch: 6| Step: 1
Training loss: 2.357094173836917
Validation loss: 2.5783258274747403

Epoch: 6| Step: 2
Training loss: 2.6103223348765887
Validation loss: 2.595834086765397

Epoch: 6| Step: 3
Training loss: 3.165976917705627
Validation loss: 2.5999183888086224

Epoch: 6| Step: 4
Training loss: 3.234335783937227
Validation loss: 2.58735385720051

Epoch: 6| Step: 5
Training loss: 2.3369091653991734
Validation loss: 2.598966106567819

Epoch: 6| Step: 6
Training loss: 3.3801225005754576
Validation loss: 2.5796253302319183

Epoch: 6| Step: 7
Training loss: 3.434231678243131
Validation loss: 2.583578323063234

Epoch: 6| Step: 8
Training loss: 3.022216234793373
Validation loss: 2.5946140572359853

Epoch: 6| Step: 9
Training loss: 2.5391199662968016
Validation loss: 2.5788275523699045

Epoch: 6| Step: 10
Training loss: 2.5902184032718067
Validation loss: 2.574397505186879

Epoch: 6| Step: 11
Training loss: 3.182875925592269
Validation loss: 2.5771554923185107

Epoch: 6| Step: 12
Training loss: 3.118400624492303
Validation loss: 2.5821664108428624

Epoch: 6| Step: 13
Training loss: 2.314380087685923
Validation loss: 2.5999380643076293

Epoch: 233| Step: 0
Training loss: 2.49906388876503
Validation loss: 2.605084762348409

Epoch: 6| Step: 1
Training loss: 2.379797657291148
Validation loss: 2.6013691271158668

Epoch: 6| Step: 2
Training loss: 3.2552774569483796
Validation loss: 2.6229603974517812

Epoch: 6| Step: 3
Training loss: 2.871458443036899
Validation loss: 2.6312840878352377

Epoch: 6| Step: 4
Training loss: 3.1249461360103967
Validation loss: 2.6397122672562565

Epoch: 6| Step: 5
Training loss: 2.642280195291962
Validation loss: 2.63052937828551

Epoch: 6| Step: 6
Training loss: 3.2077273172179046
Validation loss: 2.606908734927765

Epoch: 6| Step: 7
Training loss: 3.461766955178429
Validation loss: 2.5794862377218784

Epoch: 6| Step: 8
Training loss: 3.051098053683447
Validation loss: 2.555414473774025

Epoch: 6| Step: 9
Training loss: 3.048980298542593
Validation loss: 2.557399398539114

Epoch: 6| Step: 10
Training loss: 2.259286683019788
Validation loss: 2.5479374208508

Epoch: 6| Step: 11
Training loss: 2.3887193851315645
Validation loss: 2.5479912077505316

Epoch: 6| Step: 12
Training loss: 2.667061915511043
Validation loss: 2.5482484310340396

Epoch: 6| Step: 13
Training loss: 3.938072163018984
Validation loss: 2.5436880310094017

Epoch: 234| Step: 0
Training loss: 3.310635599843506
Validation loss: 2.5506469151482105

Epoch: 6| Step: 1
Training loss: 2.351194840899113
Validation loss: 2.546127258893242

Epoch: 6| Step: 2
Training loss: 3.1647424038019074
Validation loss: 2.5469910855451974

Epoch: 6| Step: 3
Training loss: 2.917724435733014
Validation loss: 2.5409520521595788

Epoch: 6| Step: 4
Training loss: 3.165563910027602
Validation loss: 2.5501479279882933

Epoch: 6| Step: 5
Training loss: 2.8346943297927867
Validation loss: 2.5545578368917523

Epoch: 6| Step: 6
Training loss: 2.9577751886802455
Validation loss: 2.54643284678777

Epoch: 6| Step: 7
Training loss: 2.4225295628179753
Validation loss: 2.5414429627861215

Epoch: 6| Step: 8
Training loss: 3.2478218115331106
Validation loss: 2.5649702899319395

Epoch: 6| Step: 9
Training loss: 2.538619533926068
Validation loss: 2.5555733145384627

Epoch: 6| Step: 10
Training loss: 2.7394694799013615
Validation loss: 2.551856245862301

Epoch: 6| Step: 11
Training loss: 2.2231021159026216
Validation loss: 2.5741605743846123

Epoch: 6| Step: 12
Training loss: 3.649312406598617
Validation loss: 2.596489523693037

Epoch: 6| Step: 13
Training loss: 2.5909501556172057
Validation loss: 2.65150498155056

Epoch: 235| Step: 0
Training loss: 2.8609513070457213
Validation loss: 2.7010370589132755

Epoch: 6| Step: 1
Training loss: 2.0967067508878654
Validation loss: 2.7872199830727915

Epoch: 6| Step: 2
Training loss: 3.196158075722683
Validation loss: 2.839494193414253

Epoch: 6| Step: 3
Training loss: 3.078107030206113
Validation loss: 2.8262274601635906

Epoch: 6| Step: 4
Training loss: 3.000687997129279
Validation loss: 2.757476416184371

Epoch: 6| Step: 5
Training loss: 2.800626316866217
Validation loss: 2.685245663513393

Epoch: 6| Step: 6
Training loss: 3.2092108248995332
Validation loss: 2.5898033704041037

Epoch: 6| Step: 7
Training loss: 3.1459383073348928
Validation loss: 2.5442217362393116

Epoch: 6| Step: 8
Training loss: 2.7011927054285394
Validation loss: 2.5402779566941907

Epoch: 6| Step: 9
Training loss: 3.390714301414367
Validation loss: 2.5487845910949485

Epoch: 6| Step: 10
Training loss: 3.0001549680738986
Validation loss: 2.560247087693193

Epoch: 6| Step: 11
Training loss: 2.9804018745569034
Validation loss: 2.561299546822007

Epoch: 6| Step: 12
Training loss: 2.8342628263338234
Validation loss: 2.5691858066299855

Epoch: 6| Step: 13
Training loss: 2.727169286326791
Validation loss: 2.566081495770226

Epoch: 236| Step: 0
Training loss: 3.4382448256456524
Validation loss: 2.57298074235393

Epoch: 6| Step: 1
Training loss: 2.7790059669927483
Validation loss: 2.570735869224895

Epoch: 6| Step: 2
Training loss: 3.5995875175255407
Validation loss: 2.565354398935046

Epoch: 6| Step: 3
Training loss: 2.6544036731469216
Validation loss: 2.5599426315994367

Epoch: 6| Step: 4
Training loss: 2.9416079103763426
Validation loss: 2.5564873358617715

Epoch: 6| Step: 5
Training loss: 2.9304858938156553
Validation loss: 2.56026684577126

Epoch: 6| Step: 6
Training loss: 3.095561720449506
Validation loss: 2.5612555812961717

Epoch: 6| Step: 7
Training loss: 2.4851621904155268
Validation loss: 2.5553670250824605

Epoch: 6| Step: 8
Training loss: 2.776515746058421
Validation loss: 2.5465247374336104

Epoch: 6| Step: 9
Training loss: 3.286557219761227
Validation loss: 2.541235937870299

Epoch: 6| Step: 10
Training loss: 2.5430830359963497
Validation loss: 2.5463477345807775

Epoch: 6| Step: 11
Training loss: 2.601786285947903
Validation loss: 2.5434254630181905

Epoch: 6| Step: 12
Training loss: 3.0255874756911396
Validation loss: 2.5403744159207826

Epoch: 6| Step: 13
Training loss: 2.4631818921309736
Validation loss: 2.5441841532828815

Epoch: 237| Step: 0
Training loss: 2.6634544058897305
Validation loss: 2.5592153523517283

Epoch: 6| Step: 1
Training loss: 2.297125977797808
Validation loss: 2.5637126847378906

Epoch: 6| Step: 2
Training loss: 2.9180380367443326
Validation loss: 2.5642872582020657

Epoch: 6| Step: 3
Training loss: 3.494717289701203
Validation loss: 2.589240540472537

Epoch: 6| Step: 4
Training loss: 3.26388342746431
Validation loss: 2.6090322152317356

Epoch: 6| Step: 5
Training loss: 3.4204221105809123
Validation loss: 2.611525502882658

Epoch: 6| Step: 6
Training loss: 3.071728251338852
Validation loss: 2.621708896306417

Epoch: 6| Step: 7
Training loss: 2.4278027255563313
Validation loss: 2.6038948169862137

Epoch: 6| Step: 8
Training loss: 2.2178017107607193
Validation loss: 2.5698985149685636

Epoch: 6| Step: 9
Training loss: 2.2004698858438982
Validation loss: 2.5654193656823634

Epoch: 6| Step: 10
Training loss: 2.9237323916044855
Validation loss: 2.5593215164108876

Epoch: 6| Step: 11
Training loss: 3.0904509554188238
Validation loss: 2.5714249983417803

Epoch: 6| Step: 12
Training loss: 3.2585050363658308
Validation loss: 2.596093600729609

Epoch: 6| Step: 13
Training loss: 3.030069180192982
Validation loss: 2.6075223078643734

Epoch: 238| Step: 0
Training loss: 2.257370638261765
Validation loss: 2.635794433564203

Epoch: 6| Step: 1
Training loss: 2.6759649728783406
Validation loss: 2.61293952711713

Epoch: 6| Step: 2
Training loss: 2.7925946605351295
Validation loss: 2.6666828697876217

Epoch: 6| Step: 3
Training loss: 3.5489802225593183
Validation loss: 2.652817415213572

Epoch: 6| Step: 4
Training loss: 3.1118776610777372
Validation loss: 2.582503574209517

Epoch: 6| Step: 5
Training loss: 3.233683489162329
Validation loss: 2.5560866344737274

Epoch: 6| Step: 6
Training loss: 2.608871319979003
Validation loss: 2.5444750092040254

Epoch: 6| Step: 7
Training loss: 3.041142004739858
Validation loss: 2.536823299426342

Epoch: 6| Step: 8
Training loss: 2.546877808364537
Validation loss: 2.539125169054779

Epoch: 6| Step: 9
Training loss: 3.2498347900654467
Validation loss: 2.545636513420743

Epoch: 6| Step: 10
Training loss: 2.464408533814819
Validation loss: 2.5572899357126317

Epoch: 6| Step: 11
Training loss: 2.786662460883707
Validation loss: 2.5527864941961056

Epoch: 6| Step: 12
Training loss: 3.361559632135118
Validation loss: 2.5571749041735408

Epoch: 6| Step: 13
Training loss: 3.087753958817456
Validation loss: 2.5608596313517

Epoch: 239| Step: 0
Training loss: 2.5925829916226264
Validation loss: 2.5587292662008636

Epoch: 6| Step: 1
Training loss: 2.8604760890122027
Validation loss: 2.5511827625706798

Epoch: 6| Step: 2
Training loss: 3.131782800112434
Validation loss: 2.5502116696749972

Epoch: 6| Step: 3
Training loss: 2.5998395650222306
Validation loss: 2.5464766408704

Epoch: 6| Step: 4
Training loss: 2.8145383442055674
Validation loss: 2.5454945625881367

Epoch: 6| Step: 5
Training loss: 2.4132074613395433
Validation loss: 2.5435843923029937

Epoch: 6| Step: 6
Training loss: 3.5862554272105016
Validation loss: 2.53745904793764

Epoch: 6| Step: 7
Training loss: 2.6626192809415503
Validation loss: 2.538704350835008

Epoch: 6| Step: 8
Training loss: 3.029105617602386
Validation loss: 2.5428069250187573

Epoch: 6| Step: 9
Training loss: 3.325171938014394
Validation loss: 2.5384161316532587

Epoch: 6| Step: 10
Training loss: 3.1754944543971773
Validation loss: 2.5435459653880153

Epoch: 6| Step: 11
Training loss: 2.897565438006413
Validation loss: 2.551654837127003

Epoch: 6| Step: 12
Training loss: 2.839707572012206
Validation loss: 2.541110990862769

Epoch: 6| Step: 13
Training loss: 2.5928214375853478
Validation loss: 2.560546778884007

Epoch: 240| Step: 0
Training loss: 2.7487287183825075
Validation loss: 2.5705988487864007

Epoch: 6| Step: 1
Training loss: 2.8630938917533957
Validation loss: 2.586273789121233

Epoch: 6| Step: 2
Training loss: 2.3812336678332837
Validation loss: 2.596244238391264

Epoch: 6| Step: 3
Training loss: 3.291635263671449
Validation loss: 2.6033987029449763

Epoch: 6| Step: 4
Training loss: 2.9225941145388976
Validation loss: 2.616671478233619

Epoch: 6| Step: 5
Training loss: 3.3762478817336756
Validation loss: 2.6195759614831116

Epoch: 6| Step: 6
Training loss: 2.9051127515962794
Validation loss: 2.627095723378901

Epoch: 6| Step: 7
Training loss: 2.723809806513764
Validation loss: 2.620019616123484

Epoch: 6| Step: 8
Training loss: 3.00123364197429
Validation loss: 2.5863490545341494

Epoch: 6| Step: 9
Training loss: 2.731219230845169
Validation loss: 2.5868985601873398

Epoch: 6| Step: 10
Training loss: 2.8169974078355047
Validation loss: 2.5882051401455035

Epoch: 6| Step: 11
Training loss: 3.029229660813399
Validation loss: 2.572668617517034

Epoch: 6| Step: 12
Training loss: 3.3423100873910365
Validation loss: 2.5597566265428022

Epoch: 6| Step: 13
Training loss: 1.7770802061434292
Validation loss: 2.5471712663969015

Epoch: 241| Step: 0
Training loss: 3.2567204170385673
Validation loss: 2.5402405152133247

Epoch: 6| Step: 1
Training loss: 3.034038087348034
Validation loss: 2.5413547837580794

Epoch: 6| Step: 2
Training loss: 2.9091528065013543
Validation loss: 2.5397387097766706

Epoch: 6| Step: 3
Training loss: 2.3108603360780777
Validation loss: 2.5428613406559686

Epoch: 6| Step: 4
Training loss: 2.7830569794414686
Validation loss: 2.5357439788332994

Epoch: 6| Step: 5
Training loss: 3.2494145379556514
Validation loss: 2.5376492180265267

Epoch: 6| Step: 6
Training loss: 3.042908889514718
Validation loss: 2.5449787838961724

Epoch: 6| Step: 7
Training loss: 3.130311647932773
Validation loss: 2.5385254994258886

Epoch: 6| Step: 8
Training loss: 2.5120689895413566
Validation loss: 2.549076706230731

Epoch: 6| Step: 9
Training loss: 2.9932430785859077
Validation loss: 2.5375005070097685

Epoch: 6| Step: 10
Training loss: 3.325847580803622
Validation loss: 2.5437897809012453

Epoch: 6| Step: 11
Training loss: 2.3943438557765306
Validation loss: 2.538527106166085

Epoch: 6| Step: 12
Training loss: 2.8392758227893213
Validation loss: 2.5514762379002205

Epoch: 6| Step: 13
Training loss: 2.485291030236573
Validation loss: 2.5586907521271014

Epoch: 242| Step: 0
Training loss: 2.99573070012532
Validation loss: 2.558825122047447

Epoch: 6| Step: 1
Training loss: 3.057189697090146
Validation loss: 2.5825485771883767

Epoch: 6| Step: 2
Training loss: 2.741733524315095
Validation loss: 2.577262840160682

Epoch: 6| Step: 3
Training loss: 2.6923109065026183
Validation loss: 2.575667827266152

Epoch: 6| Step: 4
Training loss: 2.7101572986291753
Validation loss: 2.571263887484137

Epoch: 6| Step: 5
Training loss: 2.784008843764147
Validation loss: 2.580779647014729

Epoch: 6| Step: 6
Training loss: 2.9552335124690594
Validation loss: 2.5773639727858564

Epoch: 6| Step: 7
Training loss: 2.838098800595377
Validation loss: 2.558016975656883

Epoch: 6| Step: 8
Training loss: 2.6433509435303595
Validation loss: 2.5442183415229866

Epoch: 6| Step: 9
Training loss: 3.452814010494115
Validation loss: 2.538165005440038

Epoch: 6| Step: 10
Training loss: 2.580452071068704
Validation loss: 2.540381879646668

Epoch: 6| Step: 11
Training loss: 2.740622310136891
Validation loss: 2.5433696069658582

Epoch: 6| Step: 12
Training loss: 3.0632041588723897
Validation loss: 2.539034444876409

Epoch: 6| Step: 13
Training loss: 3.4094672451949335
Validation loss: 2.5381067468457665

Epoch: 243| Step: 0
Training loss: 2.0482580739228484
Validation loss: 2.554819265786264

Epoch: 6| Step: 1
Training loss: 2.5679816254704124
Validation loss: 2.5416790148110477

Epoch: 6| Step: 2
Training loss: 2.502249468630032
Validation loss: 2.5543040702546143

Epoch: 6| Step: 3
Training loss: 2.8643876627359783
Validation loss: 2.561299083398772

Epoch: 6| Step: 4
Training loss: 3.1307143798302923
Validation loss: 2.5857447719775073

Epoch: 6| Step: 5
Training loss: 2.022710721198563
Validation loss: 2.605422427376967

Epoch: 6| Step: 6
Training loss: 3.2787212982259457
Validation loss: 2.6165946287709483

Epoch: 6| Step: 7
Training loss: 3.077011604135952
Validation loss: 2.6434111430622926

Epoch: 6| Step: 8
Training loss: 3.190677629684996
Validation loss: 2.633905788880174

Epoch: 6| Step: 9
Training loss: 2.9691383509356837
Validation loss: 2.6213623210527772

Epoch: 6| Step: 10
Training loss: 3.054199179718725
Validation loss: 2.5909521889559897

Epoch: 6| Step: 11
Training loss: 2.706054070760711
Validation loss: 2.5933123151445865

Epoch: 6| Step: 12
Training loss: 3.3762820599137897
Validation loss: 2.591076388793788

Epoch: 6| Step: 13
Training loss: 3.4951946786079926
Validation loss: 2.571022462019989

Epoch: 244| Step: 0
Training loss: 3.284856939118298
Validation loss: 2.550170429316377

Epoch: 6| Step: 1
Training loss: 3.388328935051456
Validation loss: 2.5461218811498294

Epoch: 6| Step: 2
Training loss: 2.8185806663383346
Validation loss: 2.538942945014731

Epoch: 6| Step: 3
Training loss: 3.29327948609886
Validation loss: 2.5360623777688827

Epoch: 6| Step: 4
Training loss: 2.857743928899015
Validation loss: 2.5402880395603944

Epoch: 6| Step: 5
Training loss: 2.8609679740811957
Validation loss: 2.5389497798513068

Epoch: 6| Step: 6
Training loss: 2.317828868917716
Validation loss: 2.531171149541494

Epoch: 6| Step: 7
Training loss: 2.9322771757500696
Validation loss: 2.5320926257814236

Epoch: 6| Step: 8
Training loss: 2.5431528801185497
Validation loss: 2.5439237830079833

Epoch: 6| Step: 9
Training loss: 2.8328184520156032
Validation loss: 2.5431669727030197

Epoch: 6| Step: 10
Training loss: 3.173693807253962
Validation loss: 2.536889786057276

Epoch: 6| Step: 11
Training loss: 2.8311276171509343
Validation loss: 2.543890688264083

Epoch: 6| Step: 12
Training loss: 2.828442971916836
Validation loss: 2.5602847302451144

Epoch: 6| Step: 13
Training loss: 1.565495937608963
Validation loss: 2.5424003799498904

Epoch: 245| Step: 0
Training loss: 2.8001508229370553
Validation loss: 2.557184787080067

Epoch: 6| Step: 1
Training loss: 3.376505056984412
Validation loss: 2.5654991380927576

Epoch: 6| Step: 2
Training loss: 2.384026290172549
Validation loss: 2.5619681111712103

Epoch: 6| Step: 3
Training loss: 2.6726198998471213
Validation loss: 2.569612004334562

Epoch: 6| Step: 4
Training loss: 1.9312291338635923
Validation loss: 2.6010288029962063

Epoch: 6| Step: 5
Training loss: 3.3142934298777855
Validation loss: 2.6193960319977916

Epoch: 6| Step: 6
Training loss: 2.9539348158001206
Validation loss: 2.6600770283042072

Epoch: 6| Step: 7
Training loss: 2.5901902371211154
Validation loss: 2.6539947558279793

Epoch: 6| Step: 8
Training loss: 3.1502209479938386
Validation loss: 2.627998758459935

Epoch: 6| Step: 9
Training loss: 2.7749928586025967
Validation loss: 2.6191673111357288

Epoch: 6| Step: 10
Training loss: 3.4672598172416773
Validation loss: 2.6153807867556265

Epoch: 6| Step: 11
Training loss: 2.2231740767344035
Validation loss: 2.594427315611654

Epoch: 6| Step: 12
Training loss: 3.0871307770041376
Validation loss: 2.572874577944295

Epoch: 6| Step: 13
Training loss: 3.5415647305049283
Validation loss: 2.556404630756515

Epoch: 246| Step: 0
Training loss: 2.487136361844615
Validation loss: 2.5462687687045156

Epoch: 6| Step: 1
Training loss: 3.055067268043057
Validation loss: 2.5371194249881914

Epoch: 6| Step: 2
Training loss: 2.8178235851322366
Validation loss: 2.5398136503849

Epoch: 6| Step: 3
Training loss: 2.2459307006036635
Validation loss: 2.5432583548675867

Epoch: 6| Step: 4
Training loss: 3.3898199153993254
Validation loss: 2.5374472534575054

Epoch: 6| Step: 5
Training loss: 3.5128284775895144
Validation loss: 2.545103641750124

Epoch: 6| Step: 6
Training loss: 3.2438716329066364
Validation loss: 2.5403020138159462

Epoch: 6| Step: 7
Training loss: 2.364167758088459
Validation loss: 2.5428715614793043

Epoch: 6| Step: 8
Training loss: 3.0330383688351477
Validation loss: 2.550433956429485

Epoch: 6| Step: 9
Training loss: 3.229224780800575
Validation loss: 2.5555760601770285

Epoch: 6| Step: 10
Training loss: 2.327434872741454
Validation loss: 2.568777127032

Epoch: 6| Step: 11
Training loss: 2.7653698129972994
Validation loss: 2.5829877142546183

Epoch: 6| Step: 12
Training loss: 3.229969507315584
Validation loss: 2.5825778486319027

Epoch: 6| Step: 13
Training loss: 1.896722717708388
Validation loss: 2.597686452086317

Epoch: 247| Step: 0
Training loss: 2.9009536556314686
Validation loss: 2.649713825601422

Epoch: 6| Step: 1
Training loss: 2.8696778835071948
Validation loss: 2.647118189026242

Epoch: 6| Step: 2
Training loss: 2.525184805877187
Validation loss: 2.6608313866432085

Epoch: 6| Step: 3
Training loss: 2.8309945570213952
Validation loss: 2.656013540013329

Epoch: 6| Step: 4
Training loss: 2.7634387669468183
Validation loss: 2.62722981094444

Epoch: 6| Step: 5
Training loss: 3.3420148964532213
Validation loss: 2.596754430160519

Epoch: 6| Step: 6
Training loss: 2.6419925195904277
Validation loss: 2.6000616810930945

Epoch: 6| Step: 7
Training loss: 3.2341517864364313
Validation loss: 2.5676923220216232

Epoch: 6| Step: 8
Training loss: 2.723089766503177
Validation loss: 2.553184942212398

Epoch: 6| Step: 9
Training loss: 3.1957249456839674
Validation loss: 2.563259653441507

Epoch: 6| Step: 10
Training loss: 2.8815538093113986
Validation loss: 2.5466834108911085

Epoch: 6| Step: 11
Training loss: 2.275348292927036
Validation loss: 2.547867039775467

Epoch: 6| Step: 12
Training loss: 2.8086580950882896
Validation loss: 2.5560506662377187

Epoch: 6| Step: 13
Training loss: 3.6296190233212586
Validation loss: 2.557428200496292

Epoch: 248| Step: 0
Training loss: 3.180066735149192
Validation loss: 2.5461416692966568

Epoch: 6| Step: 1
Training loss: 2.925158934880552
Validation loss: 2.5454565099599535

Epoch: 6| Step: 2
Training loss: 2.7029417119150487
Validation loss: 2.5429527297710206

Epoch: 6| Step: 3
Training loss: 3.315019189425202
Validation loss: 2.545942899825026

Epoch: 6| Step: 4
Training loss: 2.5836293963524515
Validation loss: 2.537052576560574

Epoch: 6| Step: 5
Training loss: 2.863622293809287
Validation loss: 2.5447655850643702

Epoch: 6| Step: 6
Training loss: 3.0899730708359274
Validation loss: 2.5491814038755325

Epoch: 6| Step: 7
Training loss: 2.897439872374555
Validation loss: 2.5382744850324044

Epoch: 6| Step: 8
Training loss: 2.687109009445616
Validation loss: 2.5385403953126695

Epoch: 6| Step: 9
Training loss: 3.276785147055476
Validation loss: 2.540648830674246

Epoch: 6| Step: 10
Training loss: 2.5862443171457623
Validation loss: 2.53528292231544

Epoch: 6| Step: 11
Training loss: 2.4497245010869255
Validation loss: 2.5464254667404482

Epoch: 6| Step: 12
Training loss: 3.1372989483737896
Validation loss: 2.541549382024514

Epoch: 6| Step: 13
Training loss: 2.4543921241328017
Validation loss: 2.5531689248362106

Epoch: 249| Step: 0
Training loss: 3.07857947697787
Validation loss: 2.550949499428874

Epoch: 6| Step: 1
Training loss: 2.846382683101854
Validation loss: 2.561288190426317

Epoch: 6| Step: 2
Training loss: 2.3671063198358326
Validation loss: 2.559608072173407

Epoch: 6| Step: 3
Training loss: 2.9544540724594066
Validation loss: 2.5627432156763823

Epoch: 6| Step: 4
Training loss: 2.9639781949969675
Validation loss: 2.5568983176774163

Epoch: 6| Step: 5
Training loss: 3.0528955691607225
Validation loss: 2.5661381132391434

Epoch: 6| Step: 6
Training loss: 3.144501073467395
Validation loss: 2.5710083974792846

Epoch: 6| Step: 7
Training loss: 2.903814792706621
Validation loss: 2.556209771350512

Epoch: 6| Step: 8
Training loss: 3.1602820900663198
Validation loss: 2.5695872748166035

Epoch: 6| Step: 9
Training loss: 2.6884994422723305
Validation loss: 2.557526869701229

Epoch: 6| Step: 10
Training loss: 2.6816496046656373
Validation loss: 2.555882809783042

Epoch: 6| Step: 11
Training loss: 2.5154382861488256
Validation loss: 2.553715665809707

Epoch: 6| Step: 12
Training loss: 3.0630755759445036
Validation loss: 2.55576239857925

Epoch: 6| Step: 13
Training loss: 2.7178811625254773
Validation loss: 2.554237950599693

Epoch: 250| Step: 0
Training loss: 3.1921182722967916
Validation loss: 2.579664259705073

Epoch: 6| Step: 1
Training loss: 3.1713087957733497
Validation loss: 2.583235561837539

Epoch: 6| Step: 2
Training loss: 2.7874318546467314
Validation loss: 2.5764220066380084

Epoch: 6| Step: 3
Training loss: 2.798974469252767
Validation loss: 2.599800134483187

Epoch: 6| Step: 4
Training loss: 3.0591992087119766
Validation loss: 2.626052165078886

Epoch: 6| Step: 5
Training loss: 3.068581595529578
Validation loss: 2.6369973453350934

Epoch: 6| Step: 6
Training loss: 2.9896356841675296
Validation loss: 2.622044775406082

Epoch: 6| Step: 7
Training loss: 2.470150900181106
Validation loss: 2.610213307847018

Epoch: 6| Step: 8
Training loss: 3.0796554556020914
Validation loss: 2.614878840542998

Epoch: 6| Step: 9
Training loss: 2.5963284648412595
Validation loss: 2.5931432641735537

Epoch: 6| Step: 10
Training loss: 2.362403593165129
Validation loss: 2.596776529613115

Epoch: 6| Step: 11
Training loss: 2.6163749686119906
Validation loss: 2.590310104942424

Epoch: 6| Step: 12
Training loss: 3.0429530798296778
Validation loss: 2.606405933698789

Epoch: 6| Step: 13
Training loss: 3.1736072639499517
Validation loss: 2.5698825548776685

Epoch: 251| Step: 0
Training loss: 2.7617342893171384
Validation loss: 2.566587391188266

Epoch: 6| Step: 1
Training loss: 2.7323007618128226
Validation loss: 2.548906386996979

Epoch: 6| Step: 2
Training loss: 2.104610912399328
Validation loss: 2.536599297434641

Epoch: 6| Step: 3
Training loss: 2.7853313888547886
Validation loss: 2.5384422575817425

Epoch: 6| Step: 4
Training loss: 3.2518154355704385
Validation loss: 2.5348119979320534

Epoch: 6| Step: 5
Training loss: 3.0595195046451655
Validation loss: 2.5300383549930263

Epoch: 6| Step: 6
Training loss: 2.7535980268561095
Validation loss: 2.546746482301685

Epoch: 6| Step: 7
Training loss: 2.8383308169013484
Validation loss: 2.5516638673300402

Epoch: 6| Step: 8
Training loss: 2.9782412143059904
Validation loss: 2.5499739212674695

Epoch: 6| Step: 9
Training loss: 3.027475898073431
Validation loss: 2.573442764436731

Epoch: 6| Step: 10
Training loss: 2.9063476217958275
Validation loss: 2.5799559027482113

Epoch: 6| Step: 11
Training loss: 3.01479379533957
Validation loss: 2.5744532895125416

Epoch: 6| Step: 12
Training loss: 3.09079423986831
Validation loss: 2.5836095708556157

Epoch: 6| Step: 13
Training loss: 2.728217729213859
Validation loss: 2.617915661451286

Epoch: 252| Step: 0
Training loss: 2.8064946804978264
Validation loss: 2.629814003538485

Epoch: 6| Step: 1
Training loss: 2.208943036921176
Validation loss: 2.648094516820638

Epoch: 6| Step: 2
Training loss: 2.848757516500375
Validation loss: 2.700174268349656

Epoch: 6| Step: 3
Training loss: 3.5421850984394427
Validation loss: 2.73415330307463

Epoch: 6| Step: 4
Training loss: 2.9497326939916806
Validation loss: 2.746096515200474

Epoch: 6| Step: 5
Training loss: 2.3925517178070765
Validation loss: 2.706147750047861

Epoch: 6| Step: 6
Training loss: 2.3908072009497205
Validation loss: 2.626388526337567

Epoch: 6| Step: 7
Training loss: 3.7181511404786094
Validation loss: 2.5913136467111992

Epoch: 6| Step: 8
Training loss: 2.1121538860582847
Validation loss: 2.5749098392722805

Epoch: 6| Step: 9
Training loss: 2.3084761174887363
Validation loss: 2.5468976449931695

Epoch: 6| Step: 10
Training loss: 3.0196181034363576
Validation loss: 2.540314472203125

Epoch: 6| Step: 11
Training loss: 3.002676723339163
Validation loss: 2.5182064031740783

Epoch: 6| Step: 12
Training loss: 3.475024073675184
Validation loss: 2.517702360200122

Epoch: 6| Step: 13
Training loss: 3.209485693399753
Validation loss: 2.533976385120418

Epoch: 253| Step: 0
Training loss: 3.2911260297690275
Validation loss: 2.5245382090756983

Epoch: 6| Step: 1
Training loss: 2.390385335240709
Validation loss: 2.5178489833705853

Epoch: 6| Step: 2
Training loss: 3.0604628969513294
Validation loss: 2.527519471907477

Epoch: 6| Step: 3
Training loss: 2.5677483937902204
Validation loss: 2.531283199245012

Epoch: 6| Step: 4
Training loss: 2.438554193485441
Validation loss: 2.53453465212224

Epoch: 6| Step: 5
Training loss: 2.7433424036456215
Validation loss: 2.536796974919854

Epoch: 6| Step: 6
Training loss: 2.5801785700014026
Validation loss: 2.561938183471632

Epoch: 6| Step: 7
Training loss: 3.0883838083582638
Validation loss: 2.5401041912658417

Epoch: 6| Step: 8
Training loss: 3.064911807410946
Validation loss: 2.540525381558507

Epoch: 6| Step: 9
Training loss: 3.2138238635601626
Validation loss: 2.5548476051440563

Epoch: 6| Step: 10
Training loss: 3.0467516751884576
Validation loss: 2.5575125254529607

Epoch: 6| Step: 11
Training loss: 2.9509711913690446
Validation loss: 2.5569536927144765

Epoch: 6| Step: 12
Training loss: 2.49454092996967
Validation loss: 2.6057896481723586

Epoch: 6| Step: 13
Training loss: 3.7178996420167008
Validation loss: 2.621546861390352

Epoch: 254| Step: 0
Training loss: 2.094825354605101
Validation loss: 2.642716870121197

Epoch: 6| Step: 1
Training loss: 3.129751941247919
Validation loss: 2.635453586075766

Epoch: 6| Step: 2
Training loss: 2.900239040125514
Validation loss: 2.6364872709973812

Epoch: 6| Step: 3
Training loss: 3.2080775237383885
Validation loss: 2.623515024998829

Epoch: 6| Step: 4
Training loss: 2.8681426159502053
Validation loss: 2.5833096484932097

Epoch: 6| Step: 5
Training loss: 2.783719798533618
Validation loss: 2.5423801583301304

Epoch: 6| Step: 6
Training loss: 3.274024200666931
Validation loss: 2.53990087760809

Epoch: 6| Step: 7
Training loss: 2.7284368068094307
Validation loss: 2.53230912790177

Epoch: 6| Step: 8
Training loss: 3.0918816984376662
Validation loss: 2.5220656332602323

Epoch: 6| Step: 9
Training loss: 2.5259005687410787
Validation loss: 2.515543154775693

Epoch: 6| Step: 10
Training loss: 2.5767211791173894
Validation loss: 2.5354779117761246

Epoch: 6| Step: 11
Training loss: 3.3501535579730537
Validation loss: 2.527163786702606

Epoch: 6| Step: 12
Training loss: 2.7354507510019674
Validation loss: 2.519950275405851

Epoch: 6| Step: 13
Training loss: 3.131275589585198
Validation loss: 2.5329136163844574

Epoch: 255| Step: 0
Training loss: 3.112244015626856
Validation loss: 2.531666584542134

Epoch: 6| Step: 1
Training loss: 2.8228202512447376
Validation loss: 2.536867769223434

Epoch: 6| Step: 2
Training loss: 3.2098376392885144
Validation loss: 2.5347421727837762

Epoch: 6| Step: 3
Training loss: 2.705950544673669
Validation loss: 2.5612620603156673

Epoch: 6| Step: 4
Training loss: 2.8017857238719515
Validation loss: 2.560671808723826

Epoch: 6| Step: 5
Training loss: 3.3540135382218117
Validation loss: 2.584095837070997

Epoch: 6| Step: 6
Training loss: 2.702434738316924
Validation loss: 2.6054350889888394

Epoch: 6| Step: 7
Training loss: 2.405722225818145
Validation loss: 2.5951737450981387

Epoch: 6| Step: 8
Training loss: 2.3603046934992915
Validation loss: 2.5530842259673223

Epoch: 6| Step: 9
Training loss: 2.7745580854029535
Validation loss: 2.5631978205068484

Epoch: 6| Step: 10
Training loss: 2.726589432285502
Validation loss: 2.584229849289368

Epoch: 6| Step: 11
Training loss: 3.158656798400321
Validation loss: 2.583451971597443

Epoch: 6| Step: 12
Training loss: 3.2303206976068504
Validation loss: 2.576346039755457

Epoch: 6| Step: 13
Training loss: 2.4577175813208667
Validation loss: 2.575066598400741

Epoch: 256| Step: 0
Training loss: 2.62268182027861
Validation loss: 2.562567228030151

Epoch: 6| Step: 1
Training loss: 2.797206922899885
Validation loss: 2.555421564516861

Epoch: 6| Step: 2
Training loss: 2.3997068742719345
Validation loss: 2.546903625544835

Epoch: 6| Step: 3
Training loss: 2.8622920264774567
Validation loss: 2.5511241269635634

Epoch: 6| Step: 4
Training loss: 2.779588352984726
Validation loss: 2.5357366546233

Epoch: 6| Step: 5
Training loss: 3.1528725257412833
Validation loss: 2.545621485336371

Epoch: 6| Step: 6
Training loss: 3.172690300851501
Validation loss: 2.5223439618542858

Epoch: 6| Step: 7
Training loss: 2.889935880431497
Validation loss: 2.517937861365327

Epoch: 6| Step: 8
Training loss: 3.136052537147149
Validation loss: 2.5259493250323692

Epoch: 6| Step: 9
Training loss: 3.0003194638864668
Validation loss: 2.5242749735095664

Epoch: 6| Step: 10
Training loss: 2.3614864375177085
Validation loss: 2.520808359536156

Epoch: 6| Step: 11
Training loss: 2.5553609444512926
Validation loss: 2.5386282378615976

Epoch: 6| Step: 12
Training loss: 3.279677095801074
Validation loss: 2.5509409159224146

Epoch: 6| Step: 13
Training loss: 2.8963755550508288
Validation loss: 2.5567307855977237

Epoch: 257| Step: 0
Training loss: 2.678371629075222
Validation loss: 2.563381905694467

Epoch: 6| Step: 1
Training loss: 3.304176814162718
Validation loss: 2.5926981242415623

Epoch: 6| Step: 2
Training loss: 3.1429468179269886
Validation loss: 2.598610643991173

Epoch: 6| Step: 3
Training loss: 2.9283810563632406
Validation loss: 2.5884055168287476

Epoch: 6| Step: 4
Training loss: 3.039457241595336
Validation loss: 2.5620740911221587

Epoch: 6| Step: 5
Training loss: 3.201661161556671
Validation loss: 2.5585559933927984

Epoch: 6| Step: 6
Training loss: 2.7070602261312198
Validation loss: 2.5554639039079703

Epoch: 6| Step: 7
Training loss: 2.783055351751356
Validation loss: 2.535114845625283

Epoch: 6| Step: 8
Training loss: 2.1235766412257573
Validation loss: 2.5319270245539345

Epoch: 6| Step: 9
Training loss: 3.281717031030087
Validation loss: 2.531204395397363

Epoch: 6| Step: 10
Training loss: 2.512085883330722
Validation loss: 2.521125070451509

Epoch: 6| Step: 11
Training loss: 2.5425356541537076
Validation loss: 2.529406974582657

Epoch: 6| Step: 12
Training loss: 3.038904965590826
Validation loss: 2.5340214461317707

Epoch: 6| Step: 13
Training loss: 2.352057623462256
Validation loss: 2.5300510645488563

Epoch: 258| Step: 0
Training loss: 2.6942484206461996
Validation loss: 2.53294683936981

Epoch: 6| Step: 1
Training loss: 3.2039723833872698
Validation loss: 2.542701640248431

Epoch: 6| Step: 2
Training loss: 2.512999022921195
Validation loss: 2.5488946143076836

Epoch: 6| Step: 3
Training loss: 3.184058781459837
Validation loss: 2.54056513670546

Epoch: 6| Step: 4
Training loss: 2.555200367814183
Validation loss: 2.5331460153138354

Epoch: 6| Step: 5
Training loss: 3.448010830395322
Validation loss: 2.535910207285013

Epoch: 6| Step: 6
Training loss: 2.9758346348523497
Validation loss: 2.5241831519101403

Epoch: 6| Step: 7
Training loss: 2.772321965630205
Validation loss: 2.529491081325187

Epoch: 6| Step: 8
Training loss: 2.408866648598714
Validation loss: 2.529805733409719

Epoch: 6| Step: 9
Training loss: 2.665855989812043
Validation loss: 2.536101930955523

Epoch: 6| Step: 10
Training loss: 3.015582306712846
Validation loss: 2.5327453814514977

Epoch: 6| Step: 11
Training loss: 3.1882570153165712
Validation loss: 2.559137973614999

Epoch: 6| Step: 12
Training loss: 2.47068440426455
Validation loss: 2.577074390583245

Epoch: 6| Step: 13
Training loss: 2.609572443087924
Validation loss: 2.600749882601704

Epoch: 259| Step: 0
Training loss: 2.836691511817126
Validation loss: 2.6428473539880244

Epoch: 6| Step: 1
Training loss: 2.665774782361987
Validation loss: 2.645607547623326

Epoch: 6| Step: 2
Training loss: 3.109396316225222
Validation loss: 2.6257388915453848

Epoch: 6| Step: 3
Training loss: 2.6794464625729466
Validation loss: 2.5880871990305097

Epoch: 6| Step: 4
Training loss: 2.75525397471439
Validation loss: 2.586036195709655

Epoch: 6| Step: 5
Training loss: 3.205223624154009
Validation loss: 2.5794611973714483

Epoch: 6| Step: 6
Training loss: 2.847280469675941
Validation loss: 2.559010246098329

Epoch: 6| Step: 7
Training loss: 3.1262076523942985
Validation loss: 2.563591711283504

Epoch: 6| Step: 8
Training loss: 2.247287811005338
Validation loss: 2.5455542866337977

Epoch: 6| Step: 9
Training loss: 2.956280833561373
Validation loss: 2.528596107403992

Epoch: 6| Step: 10
Training loss: 2.5565004594467826
Validation loss: 2.5330436587343805

Epoch: 6| Step: 11
Training loss: 3.0149608137579653
Validation loss: 2.5354088562405344

Epoch: 6| Step: 12
Training loss: 2.485952008754703
Validation loss: 2.5383578768027375

Epoch: 6| Step: 13
Training loss: 3.711103126443686
Validation loss: 2.5256058653923086

Epoch: 260| Step: 0
Training loss: 2.2340246606146987
Validation loss: 2.5315261127111537

Epoch: 6| Step: 1
Training loss: 2.9590504453225983
Validation loss: 2.531144451258542

Epoch: 6| Step: 2
Training loss: 2.954980015307911
Validation loss: 2.545003212606959

Epoch: 6| Step: 3
Training loss: 2.8282170570523326
Validation loss: 2.5568811845604484

Epoch: 6| Step: 4
Training loss: 3.2360422748308135
Validation loss: 2.549001197154989

Epoch: 6| Step: 5
Training loss: 3.019135956347875
Validation loss: 2.5906492949214366

Epoch: 6| Step: 6
Training loss: 3.4167478288144135
Validation loss: 2.6125307934946074

Epoch: 6| Step: 7
Training loss: 2.360072557012863
Validation loss: 2.630015639917516

Epoch: 6| Step: 8
Training loss: 2.467575180006059
Validation loss: 2.6282657967714345

Epoch: 6| Step: 9
Training loss: 3.0433701922499004
Validation loss: 2.621594520448505

Epoch: 6| Step: 10
Training loss: 2.9342402775624437
Validation loss: 2.5763850451479824

Epoch: 6| Step: 11
Training loss: 2.7850830582127704
Validation loss: 2.5681245394918872

Epoch: 6| Step: 12
Training loss: 2.680002978024323
Validation loss: 2.5691691216653756

Epoch: 6| Step: 13
Training loss: 2.7629604111277946
Validation loss: 2.5792548673579145

Epoch: 261| Step: 0
Training loss: 2.8112430730847158
Validation loss: 2.535318300406114

Epoch: 6| Step: 1
Training loss: 2.8412387365343656
Validation loss: 2.5285262464650518

Epoch: 6| Step: 2
Training loss: 3.1744393942607365
Validation loss: 2.5256881650887713

Epoch: 6| Step: 3
Training loss: 2.761266172196781
Validation loss: 2.515271636331837

Epoch: 6| Step: 4
Training loss: 2.398368710205496
Validation loss: 2.5148931116449154

Epoch: 6| Step: 5
Training loss: 3.0710911042622477
Validation loss: 2.5211026190173107

Epoch: 6| Step: 6
Training loss: 2.6559354708082905
Validation loss: 2.5206309879470936

Epoch: 6| Step: 7
Training loss: 2.606053962927558
Validation loss: 2.526575245061138

Epoch: 6| Step: 8
Training loss: 2.7833433524158933
Validation loss: 2.550547762177494

Epoch: 6| Step: 9
Training loss: 2.377660566136645
Validation loss: 2.5537246827021685

Epoch: 6| Step: 10
Training loss: 3.7751743907941795
Validation loss: 2.558866180843027

Epoch: 6| Step: 11
Training loss: 3.0562842993186545
Validation loss: 2.5765092347666063

Epoch: 6| Step: 12
Training loss: 2.23059028254304
Validation loss: 2.5712181311370585

Epoch: 6| Step: 13
Training loss: 3.3127353512629596
Validation loss: 2.5881877105941755

Epoch: 262| Step: 0
Training loss: 3.2750528578824234
Validation loss: 2.5736913200304232

Epoch: 6| Step: 1
Training loss: 3.0676686792234067
Validation loss: 2.5817564565397744

Epoch: 6| Step: 2
Training loss: 3.0078641812727183
Validation loss: 2.5431880156693043

Epoch: 6| Step: 3
Training loss: 3.0546654898004193
Validation loss: 2.5507919305520845

Epoch: 6| Step: 4
Training loss: 3.495144064011989
Validation loss: 2.5530687788133966

Epoch: 6| Step: 5
Training loss: 2.2423204123416447
Validation loss: 2.545631638177897

Epoch: 6| Step: 6
Training loss: 2.5645413525200564
Validation loss: 2.575129030385652

Epoch: 6| Step: 7
Training loss: 2.50964003668026
Validation loss: 2.557546695906064

Epoch: 6| Step: 8
Training loss: 2.7582049644387365
Validation loss: 2.5541994209948222

Epoch: 6| Step: 9
Training loss: 2.8912052706215996
Validation loss: 2.5467801026361063

Epoch: 6| Step: 10
Training loss: 3.1434659492076773
Validation loss: 2.5229193449029457

Epoch: 6| Step: 11
Training loss: 2.7525268563078624
Validation loss: 2.536304319025415

Epoch: 6| Step: 12
Training loss: 2.243810617802227
Validation loss: 2.5343271053639973

Epoch: 6| Step: 13
Training loss: 2.3647469507373784
Validation loss: 2.5465121674807225

Epoch: 263| Step: 0
Training loss: 3.1723464089347573
Validation loss: 2.5422574658959967

Epoch: 6| Step: 1
Training loss: 2.435563712226284
Validation loss: 2.563566848688468

Epoch: 6| Step: 2
Training loss: 2.4248394942502847
Validation loss: 2.5599165218035824

Epoch: 6| Step: 3
Training loss: 3.0392987863036365
Validation loss: 2.564784248673421

Epoch: 6| Step: 4
Training loss: 2.8068156124772945
Validation loss: 2.557111328040521

Epoch: 6| Step: 5
Training loss: 2.7001848051615185
Validation loss: 2.56838545686001

Epoch: 6| Step: 6
Training loss: 2.480749976368329
Validation loss: 2.5801516962221323

Epoch: 6| Step: 7
Training loss: 2.821181736611665
Validation loss: 2.6006470106315116

Epoch: 6| Step: 8
Training loss: 2.8327607155899264
Validation loss: 2.5772927913366415

Epoch: 6| Step: 9
Training loss: 2.8201577944605756
Validation loss: 2.5859254497766173

Epoch: 6| Step: 10
Training loss: 2.673708192017826
Validation loss: 2.577366838444197

Epoch: 6| Step: 11
Training loss: 3.2070006207619266
Validation loss: 2.5779496248569416

Epoch: 6| Step: 12
Training loss: 3.453419392322279
Validation loss: 2.5595866523909683

Epoch: 6| Step: 13
Training loss: 2.72621366788852
Validation loss: 2.536365918121727

Epoch: 264| Step: 0
Training loss: 3.2965466665780356
Validation loss: 2.5313278382756677

Epoch: 6| Step: 1
Training loss: 2.4567872913341193
Validation loss: 2.5258277598674947

Epoch: 6| Step: 2
Training loss: 2.635395537481433
Validation loss: 2.5242407589031566

Epoch: 6| Step: 3
Training loss: 3.1185614825131864
Validation loss: 2.5117218206893983

Epoch: 6| Step: 4
Training loss: 3.4219848057795828
Validation loss: 2.5030825530330687

Epoch: 6| Step: 5
Training loss: 2.6033696493561886
Validation loss: 2.5298554774484088

Epoch: 6| Step: 6
Training loss: 3.3675020075440174
Validation loss: 2.543496912425245

Epoch: 6| Step: 7
Training loss: 2.450997176916955
Validation loss: 2.589983333509158

Epoch: 6| Step: 8
Training loss: 2.95284467708881
Validation loss: 2.6295007345792123

Epoch: 6| Step: 9
Training loss: 2.723240005764788
Validation loss: 2.6353324426936755

Epoch: 6| Step: 10
Training loss: 2.9666732752294194
Validation loss: 2.623470802444862

Epoch: 6| Step: 11
Training loss: 2.6952298801309116
Validation loss: 2.630186372801534

Epoch: 6| Step: 12
Training loss: 2.3018893567232337
Validation loss: 2.5842022339262476

Epoch: 6| Step: 13
Training loss: 2.7713578284677394
Validation loss: 2.5609893017370533

Epoch: 265| Step: 0
Training loss: 3.348682366485924
Validation loss: 2.52536818204862

Epoch: 6| Step: 1
Training loss: 3.1736126729755934
Validation loss: 2.5061231342356125

Epoch: 6| Step: 2
Training loss: 2.5393851207293934
Validation loss: 2.5122419357924453

Epoch: 6| Step: 3
Training loss: 2.974377568631186
Validation loss: 2.509473891612061

Epoch: 6| Step: 4
Training loss: 2.6492787153274033
Validation loss: 2.504975342590203

Epoch: 6| Step: 5
Training loss: 2.9138651517667498
Validation loss: 2.5093898587175234

Epoch: 6| Step: 6
Training loss: 2.6263446088886875
Validation loss: 2.507406034214236

Epoch: 6| Step: 7
Training loss: 2.617402662855665
Validation loss: 2.504034067028142

Epoch: 6| Step: 8
Training loss: 2.8351472956961965
Validation loss: 2.507654443139832

Epoch: 6| Step: 9
Training loss: 2.9775421052481175
Validation loss: 2.4974594327960276

Epoch: 6| Step: 10
Training loss: 3.372612426557927
Validation loss: 2.5020504572050024

Epoch: 6| Step: 11
Training loss: 2.623521842759468
Validation loss: 2.5093079551984325

Epoch: 6| Step: 12
Training loss: 2.435385642875211
Validation loss: 2.5071542835909684

Epoch: 6| Step: 13
Training loss: 2.791392915503284
Validation loss: 2.547430913274718

Epoch: 266| Step: 0
Training loss: 2.695983979989742
Validation loss: 2.6009758960459077

Epoch: 6| Step: 1
Training loss: 2.790894406291046
Validation loss: 2.623927034323124

Epoch: 6| Step: 2
Training loss: 3.035936802634779
Validation loss: 2.6187513390546293

Epoch: 6| Step: 3
Training loss: 3.290583532928866
Validation loss: 2.635703951587363

Epoch: 6| Step: 4
Training loss: 2.5832802756818802
Validation loss: 2.6194972526009543

Epoch: 6| Step: 5
Training loss: 3.0606054557252613
Validation loss: 2.6299441254939797

Epoch: 6| Step: 6
Training loss: 2.6414455967127295
Validation loss: 2.626697345063309

Epoch: 6| Step: 7
Training loss: 2.7907220941037023
Validation loss: 2.6854735850367186

Epoch: 6| Step: 8
Training loss: 3.5497132091462684
Validation loss: 2.672611178570037

Epoch: 6| Step: 9
Training loss: 2.6366655810611515
Validation loss: 2.6536847500688348

Epoch: 6| Step: 10
Training loss: 3.0702438540950454
Validation loss: 2.6614139950450464

Epoch: 6| Step: 11
Training loss: 3.0859979164873015
Validation loss: 2.592443731030013

Epoch: 6| Step: 12
Training loss: 1.9139826543853113
Validation loss: 2.5455259364681244

Epoch: 6| Step: 13
Training loss: 2.187005668371152
Validation loss: 2.5128007700095862

Epoch: 267| Step: 0
Training loss: 2.6802079387673894
Validation loss: 2.5152562561021607

Epoch: 6| Step: 1
Training loss: 3.528944495067552
Validation loss: 2.5129931845852997

Epoch: 6| Step: 2
Training loss: 2.249438533664754
Validation loss: 2.518369089731671

Epoch: 6| Step: 3
Training loss: 2.3666024570978133
Validation loss: 2.516011042302674

Epoch: 6| Step: 4
Training loss: 3.196068261640988
Validation loss: 2.5217255423898295

Epoch: 6| Step: 5
Training loss: 3.081641652439143
Validation loss: 2.5181369223557133

Epoch: 6| Step: 6
Training loss: 3.409870708173546
Validation loss: 2.5187130751208957

Epoch: 6| Step: 7
Training loss: 3.168235457137811
Validation loss: 2.5085763361888294

Epoch: 6| Step: 8
Training loss: 2.518297375317742
Validation loss: 2.511638029889961

Epoch: 6| Step: 9
Training loss: 2.6360697986119974
Validation loss: 2.511171759343309

Epoch: 6| Step: 10
Training loss: 2.4316222898718887
Validation loss: 2.519601302346764

Epoch: 6| Step: 11
Training loss: 3.0956935750049857
Validation loss: 2.5372176351040183

Epoch: 6| Step: 12
Training loss: 2.7799645357134
Validation loss: 2.5637368569445904

Epoch: 6| Step: 13
Training loss: 2.814001996259923
Validation loss: 2.5796276527496103

Epoch: 268| Step: 0
Training loss: 3.0769677479875805
Validation loss: 2.6303523607923527

Epoch: 6| Step: 1
Training loss: 2.7485935776262487
Validation loss: 2.6389824203196457

Epoch: 6| Step: 2
Training loss: 2.647645184765901
Validation loss: 2.645058252315889

Epoch: 6| Step: 3
Training loss: 3.1314769000231215
Validation loss: 2.691326440280051

Epoch: 6| Step: 4
Training loss: 3.1774606616138485
Validation loss: 2.679322485900357

Epoch: 6| Step: 5
Training loss: 2.8553022552670506
Validation loss: 2.6883123495546095

Epoch: 6| Step: 6
Training loss: 2.8719094292005884
Validation loss: 2.7095926425529675

Epoch: 6| Step: 7
Training loss: 2.2929841387100733
Validation loss: 2.7324450557544386

Epoch: 6| Step: 8
Training loss: 3.293764500160801
Validation loss: 2.741436642154953

Epoch: 6| Step: 9
Training loss: 2.355912655427285
Validation loss: 2.7338758312437026

Epoch: 6| Step: 10
Training loss: 3.286559396067473
Validation loss: 2.6517430298065117

Epoch: 6| Step: 11
Training loss: 3.0031099094801657
Validation loss: 2.6063013452545025

Epoch: 6| Step: 12
Training loss: 2.4379332719766635
Validation loss: 2.540480216930483

Epoch: 6| Step: 13
Training loss: 2.7017112077653294
Validation loss: 2.529428591149064

Epoch: 269| Step: 0
Training loss: 2.6175992271757966
Validation loss: 2.51006870635112

Epoch: 6| Step: 1
Training loss: 1.9586995641353335
Validation loss: 2.506457107460743

Epoch: 6| Step: 2
Training loss: 2.960010071299147
Validation loss: 2.515139936120424

Epoch: 6| Step: 3
Training loss: 3.1994736119294087
Validation loss: 2.5260403567886804

Epoch: 6| Step: 4
Training loss: 3.3233367431174194
Validation loss: 2.5360980229728773

Epoch: 6| Step: 5
Training loss: 3.150390625
Validation loss: 2.5449766906577276

Epoch: 6| Step: 6
Training loss: 2.513592580212982
Validation loss: 2.5407484753933764

Epoch: 6| Step: 7
Training loss: 2.5097098615218005
Validation loss: 2.530464095935125

Epoch: 6| Step: 8
Training loss: 3.4433093832782684
Validation loss: 2.5345187940302667

Epoch: 6| Step: 9
Training loss: 3.060821851928126
Validation loss: 2.527890068753473

Epoch: 6| Step: 10
Training loss: 3.011491541820684
Validation loss: 2.532937132129189

Epoch: 6| Step: 11
Training loss: 2.8739539192131702
Validation loss: 2.515712766314387

Epoch: 6| Step: 12
Training loss: 2.5171851775562977
Validation loss: 2.512166031862933

Epoch: 6| Step: 13
Training loss: 3.4184733165521424
Validation loss: 2.5051778814039953

Epoch: 270| Step: 0
Training loss: 3.117547418375983
Validation loss: 2.511829112823043

Epoch: 6| Step: 1
Training loss: 2.431531690738911
Validation loss: 2.515958865382529

Epoch: 6| Step: 2
Training loss: 2.6251291515731117
Validation loss: 2.523629908133206

Epoch: 6| Step: 3
Training loss: 3.097453049372404
Validation loss: 2.52934173963562

Epoch: 6| Step: 4
Training loss: 3.0975140109603543
Validation loss: 2.5242507260663265

Epoch: 6| Step: 5
Training loss: 3.0375900820337374
Validation loss: 2.5426866074210386

Epoch: 6| Step: 6
Training loss: 2.790862370868962
Validation loss: 2.541727722607344

Epoch: 6| Step: 7
Training loss: 2.7888024473366695
Validation loss: 2.535004220303569

Epoch: 6| Step: 8
Training loss: 2.4333443062243116
Validation loss: 2.558107478588663

Epoch: 6| Step: 9
Training loss: 3.2419701193127306
Validation loss: 2.569359724545106

Epoch: 6| Step: 10
Training loss: 2.8508666143079515
Validation loss: 2.589755533151543

Epoch: 6| Step: 11
Training loss: 2.9679307309110716
Validation loss: 2.613336543733012

Epoch: 6| Step: 12
Training loss: 2.5227447598200383
Validation loss: 2.6224173181729893

Epoch: 6| Step: 13
Training loss: 2.6736111716618605
Validation loss: 2.614705813901072

Epoch: 271| Step: 0
Training loss: 2.8558928752651482
Validation loss: 2.646009200180085

Epoch: 6| Step: 1
Training loss: 2.5093162520243117
Validation loss: 2.647583786896262

Epoch: 6| Step: 2
Training loss: 2.9767622592808465
Validation loss: 2.657627623366412

Epoch: 6| Step: 3
Training loss: 2.5651006759903807
Validation loss: 2.656820694614967

Epoch: 6| Step: 4
Training loss: 2.786403553266776
Validation loss: 2.6705449186742864

Epoch: 6| Step: 5
Training loss: 2.5876364298802503
Validation loss: 2.6189457053843888

Epoch: 6| Step: 6
Training loss: 2.9743528800281314
Validation loss: 2.573688903503214

Epoch: 6| Step: 7
Training loss: 3.0553776968622715
Validation loss: 2.567035917397155

Epoch: 6| Step: 8
Training loss: 3.192601329178185
Validation loss: 2.5391008231250236

Epoch: 6| Step: 9
Training loss: 3.37381299655778
Validation loss: 2.5324034023424673

Epoch: 6| Step: 10
Training loss: 2.2892889229820215
Validation loss: 2.5213096102279615

Epoch: 6| Step: 11
Training loss: 2.7123271447581043
Validation loss: 2.5123898510946763

Epoch: 6| Step: 12
Training loss: 3.063820379126648
Validation loss: 2.4991748514548715

Epoch: 6| Step: 13
Training loss: 2.4691658152710647
Validation loss: 2.4892118649415242

Epoch: 272| Step: 0
Training loss: 3.0554075051092338
Validation loss: 2.4899591330567987

Epoch: 6| Step: 1
Training loss: 2.825594618342233
Validation loss: 2.5021208473259398

Epoch: 6| Step: 2
Training loss: 2.7000900606747167
Validation loss: 2.496183298872573

Epoch: 6| Step: 3
Training loss: 2.8913253348200825
Validation loss: 2.500268944251062

Epoch: 6| Step: 4
Training loss: 2.9468633884108124
Validation loss: 2.501208980037588

Epoch: 6| Step: 5
Training loss: 2.368602568937566
Validation loss: 2.512170309753907

Epoch: 6| Step: 6
Training loss: 2.7555575999727493
Validation loss: 2.519407799976201

Epoch: 6| Step: 7
Training loss: 2.895997205163861
Validation loss: 2.5421162304694973

Epoch: 6| Step: 8
Training loss: 3.0424451659126825
Validation loss: 2.5506153735869073

Epoch: 6| Step: 9
Training loss: 2.9245296393523175
Validation loss: 2.550174977208455

Epoch: 6| Step: 10
Training loss: 2.8427034904762096
Validation loss: 2.552596951689382

Epoch: 6| Step: 11
Training loss: 2.484021815500583
Validation loss: 2.519139253431772

Epoch: 6| Step: 12
Training loss: 3.137016234774498
Validation loss: 2.5242675322352124

Epoch: 6| Step: 13
Training loss: 2.946860475797651
Validation loss: 2.5268445231707055

Epoch: 273| Step: 0
Training loss: 3.178654983426498
Validation loss: 2.5198290902668115

Epoch: 6| Step: 1
Training loss: 2.7104491747686223
Validation loss: 2.5262507296433263

Epoch: 6| Step: 2
Training loss: 2.5616892951093297
Validation loss: 2.5281540605888777

Epoch: 6| Step: 3
Training loss: 3.0039764118309775
Validation loss: 2.5422461010775512

Epoch: 6| Step: 4
Training loss: 2.6640545349896967
Validation loss: 2.5505087838131852

Epoch: 6| Step: 5
Training loss: 2.587776475224218
Validation loss: 2.568335181417516

Epoch: 6| Step: 6
Training loss: 2.891800430091611
Validation loss: 2.583713027911277

Epoch: 6| Step: 7
Training loss: 2.459302861901892
Validation loss: 2.6057016632297256

Epoch: 6| Step: 8
Training loss: 3.020242427165021
Validation loss: 2.6228906484171897

Epoch: 6| Step: 9
Training loss: 3.2626983816114716
Validation loss: 2.6111552764111914

Epoch: 6| Step: 10
Training loss: 2.6303465753364663
Validation loss: 2.595593288332974

Epoch: 6| Step: 11
Training loss: 2.988494745743568
Validation loss: 2.5737328503754258

Epoch: 6| Step: 12
Training loss: 2.0672677160775583
Validation loss: 2.599404856308057

Epoch: 6| Step: 13
Training loss: 3.6436245721654945
Validation loss: 2.6213402577249925

Epoch: 274| Step: 0
Training loss: 2.6705347458622257
Validation loss: 2.5468252400984737

Epoch: 6| Step: 1
Training loss: 2.0350150793393222
Validation loss: 2.5062249198638415

Epoch: 6| Step: 2
Training loss: 2.754636930022077
Validation loss: 2.5048815516002714

Epoch: 6| Step: 3
Training loss: 3.2057496273442463
Validation loss: 2.503645329106608

Epoch: 6| Step: 4
Training loss: 3.047093779705399
Validation loss: 2.5087892832225633

Epoch: 6| Step: 5
Training loss: 3.0884542125823677
Validation loss: 2.535965905153542

Epoch: 6| Step: 6
Training loss: 2.837714697155726
Validation loss: 2.539315652524825

Epoch: 6| Step: 7
Training loss: 2.974800769962869
Validation loss: 2.5558912944444114

Epoch: 6| Step: 8
Training loss: 2.7413772298821106
Validation loss: 2.546318181058728

Epoch: 6| Step: 9
Training loss: 2.886383904431669
Validation loss: 2.547500167227254

Epoch: 6| Step: 10
Training loss: 3.183128350999687
Validation loss: 2.5582357111484866

Epoch: 6| Step: 11
Training loss: 2.8327472491989534
Validation loss: 2.5389581555049587

Epoch: 6| Step: 12
Training loss: 3.1933895377971515
Validation loss: 2.5297071433230514

Epoch: 6| Step: 13
Training loss: 3.13601026692948
Validation loss: 2.5221021898440132

Epoch: 275| Step: 0
Training loss: 3.1471486825890933
Validation loss: 2.507478338215141

Epoch: 6| Step: 1
Training loss: 2.8647482159874746
Validation loss: 2.50620975416552

Epoch: 6| Step: 2
Training loss: 2.8545516559619615
Validation loss: 2.517110934123945

Epoch: 6| Step: 3
Training loss: 3.050645265955432
Validation loss: 2.510286761741135

Epoch: 6| Step: 4
Training loss: 3.3191264828002085
Validation loss: 2.5149778189515115

Epoch: 6| Step: 5
Training loss: 2.2711042773327885
Validation loss: 2.536581339955865

Epoch: 6| Step: 6
Training loss: 3.2291338190848666
Validation loss: 2.556131157277617

Epoch: 6| Step: 7
Training loss: 2.932084631287811
Validation loss: 2.577872252543814

Epoch: 6| Step: 8
Training loss: 2.75191101951687
Validation loss: 2.629372591383847

Epoch: 6| Step: 9
Training loss: 2.6229092582454596
Validation loss: 2.7113253843247245

Epoch: 6| Step: 10
Training loss: 3.227734221359521
Validation loss: 2.7985844748048003

Epoch: 6| Step: 11
Training loss: 2.2192538052090423
Validation loss: 2.8047813865753035

Epoch: 6| Step: 12
Training loss: 2.3738754019173216
Validation loss: 2.8061883307493467

Epoch: 6| Step: 13
Training loss: 2.41558098796116
Validation loss: 2.7678508900431464

Epoch: 276| Step: 0
Training loss: 3.3499312265652983
Validation loss: 2.688722268142303

Epoch: 6| Step: 1
Training loss: 2.3686698074656407
Validation loss: 2.650041447882425

Epoch: 6| Step: 2
Training loss: 2.674015191878858
Validation loss: 2.5865338261905295

Epoch: 6| Step: 3
Training loss: 3.2385978221881513
Validation loss: 2.542575787232163

Epoch: 6| Step: 4
Training loss: 2.100677303808252
Validation loss: 2.524819696056926

Epoch: 6| Step: 5
Training loss: 3.3037360514859815
Validation loss: 2.506546795435475

Epoch: 6| Step: 6
Training loss: 2.235898332232774
Validation loss: 2.507114861679397

Epoch: 6| Step: 7
Training loss: 3.312645243213534
Validation loss: 2.50155929318551

Epoch: 6| Step: 8
Training loss: 2.920475099138409
Validation loss: 2.498709774354173

Epoch: 6| Step: 9
Training loss: 2.6501795797860086
Validation loss: 2.5072197164811136

Epoch: 6| Step: 10
Training loss: 3.0973281975269913
Validation loss: 2.5141235224237573

Epoch: 6| Step: 11
Training loss: 3.107412514471681
Validation loss: 2.5179639381104946

Epoch: 6| Step: 12
Training loss: 2.463502255877915
Validation loss: 2.5148620916125735

Epoch: 6| Step: 13
Training loss: 3.402206120296851
Validation loss: 2.518383878851322

Epoch: 277| Step: 0
Training loss: 3.1212498860937794
Validation loss: 2.5109791878365284

Epoch: 6| Step: 1
Training loss: 2.6577811820704085
Validation loss: 2.5154328682745843

Epoch: 6| Step: 2
Training loss: 2.4916386971663442
Validation loss: 2.5026358808718707

Epoch: 6| Step: 3
Training loss: 2.8554325127552747
Validation loss: 2.5046473438193693

Epoch: 6| Step: 4
Training loss: 3.14348627580693
Validation loss: 2.5069473671161577

Epoch: 6| Step: 5
Training loss: 2.7865881963873163
Validation loss: 2.5064650833554065

Epoch: 6| Step: 6
Training loss: 2.6358311042048577
Validation loss: 2.5192343494073186

Epoch: 6| Step: 7
Training loss: 3.178682885580907
Validation loss: 2.511745780307287

Epoch: 6| Step: 8
Training loss: 2.685496892290549
Validation loss: 2.512220888731315

Epoch: 6| Step: 9
Training loss: 2.587841704284071
Validation loss: 2.5019805835738946

Epoch: 6| Step: 10
Training loss: 2.8850727266503218
Validation loss: 2.5125255758303817

Epoch: 6| Step: 11
Training loss: 2.814672351693478
Validation loss: 2.513705451225346

Epoch: 6| Step: 12
Training loss: 2.9948387252869755
Validation loss: 2.5290520109901986

Epoch: 6| Step: 13
Training loss: 2.8199755184653026
Validation loss: 2.5418385081615242

Epoch: 278| Step: 0
Training loss: 2.8169209807515183
Validation loss: 2.5855596355695223

Epoch: 6| Step: 1
Training loss: 2.998825638116479
Validation loss: 2.6368146349488635

Epoch: 6| Step: 2
Training loss: 3.545630417309783
Validation loss: 2.739327363127164

Epoch: 6| Step: 3
Training loss: 3.1407953472342016
Validation loss: 2.735418532049838

Epoch: 6| Step: 4
Training loss: 2.438898712269728
Validation loss: 2.6305905241798198

Epoch: 6| Step: 5
Training loss: 2.536857328163054
Validation loss: 2.613568712649741

Epoch: 6| Step: 6
Training loss: 2.984657953240095
Validation loss: 2.58496088295363

Epoch: 6| Step: 7
Training loss: 2.936553153168987
Validation loss: 2.577943113193595

Epoch: 6| Step: 8
Training loss: 2.1172359221717065
Validation loss: 2.570976958640004

Epoch: 6| Step: 9
Training loss: 3.1058062292058763
Validation loss: 2.5499776813094166

Epoch: 6| Step: 10
Training loss: 2.423716183643411
Validation loss: 2.556877552982637

Epoch: 6| Step: 11
Training loss: 2.369200904626527
Validation loss: 2.5472986998893488

Epoch: 6| Step: 12
Training loss: 2.9713950169680894
Validation loss: 2.5570238432337327

Epoch: 6| Step: 13
Training loss: 3.364083897672746
Validation loss: 2.543354549863239

Epoch: 279| Step: 0
Training loss: 2.9400876599173107
Validation loss: 2.532450209243971

Epoch: 6| Step: 1
Training loss: 2.66885901771167
Validation loss: 2.5335011369049245

Epoch: 6| Step: 2
Training loss: 2.1677138170071824
Validation loss: 2.5398231456178966

Epoch: 6| Step: 3
Training loss: 2.6523293675972353
Validation loss: 2.5445709546914315

Epoch: 6| Step: 4
Training loss: 2.40093714775491
Validation loss: 2.53970069910502

Epoch: 6| Step: 5
Training loss: 2.580446250233048
Validation loss: 2.5352162651202392

Epoch: 6| Step: 6
Training loss: 2.793880713901716
Validation loss: 2.5414676978390154

Epoch: 6| Step: 7
Training loss: 3.427427203116941
Validation loss: 2.5702135356441773

Epoch: 6| Step: 8
Training loss: 3.2665493035804873
Validation loss: 2.556130345900784

Epoch: 6| Step: 9
Training loss: 3.288700328467747
Validation loss: 2.561757622206635

Epoch: 6| Step: 10
Training loss: 2.6072644132580973
Validation loss: 2.5485417805330313

Epoch: 6| Step: 11
Training loss: 2.91179038641083
Validation loss: 2.5527889746970436

Epoch: 6| Step: 12
Training loss: 2.8094045771144063
Validation loss: 2.5471371993164276

Epoch: 6| Step: 13
Training loss: 2.6476179897395102
Validation loss: 2.5459711295495664

Epoch: 280| Step: 0
Training loss: 2.611901436457649
Validation loss: 2.5447091257555816

Epoch: 6| Step: 1
Training loss: 3.2828196812823047
Validation loss: 2.5570851351964543

Epoch: 6| Step: 2
Training loss: 2.3148515446892475
Validation loss: 2.561523999964453

Epoch: 6| Step: 3
Training loss: 2.975504369215529
Validation loss: 2.565010965512511

Epoch: 6| Step: 4
Training loss: 3.1258455277031083
Validation loss: 2.573305800462413

Epoch: 6| Step: 5
Training loss: 2.94960029609747
Validation loss: 2.584721153430256

Epoch: 6| Step: 6
Training loss: 2.2488088633799257
Validation loss: 2.5614251424380194

Epoch: 6| Step: 7
Training loss: 2.766779082285635
Validation loss: 2.580249029501962

Epoch: 6| Step: 8
Training loss: 2.541561270441114
Validation loss: 2.5567199533784657

Epoch: 6| Step: 9
Training loss: 2.9185035552512457
Validation loss: 2.551436866783135

Epoch: 6| Step: 10
Training loss: 2.7089769821231133
Validation loss: 2.5456000228927054

Epoch: 6| Step: 11
Training loss: 3.333329550423065
Validation loss: 2.5363454320878045

Epoch: 6| Step: 12
Training loss: 2.9240394775814975
Validation loss: 2.526842597531144

Epoch: 6| Step: 13
Training loss: 2.1614119068966042
Validation loss: 2.5253604648270174

Epoch: 281| Step: 0
Training loss: 3.1996828518109184
Validation loss: 2.5328983058310897

Epoch: 6| Step: 1
Training loss: 2.6491031316638396
Validation loss: 2.524338332629637

Epoch: 6| Step: 2
Training loss: 2.0012491616718506
Validation loss: 2.5356422953317965

Epoch: 6| Step: 3
Training loss: 3.3417286690329187
Validation loss: 2.5348457795908024

Epoch: 6| Step: 4
Training loss: 2.9795144329409644
Validation loss: 2.547713997567625

Epoch: 6| Step: 5
Training loss: 2.93280433161822
Validation loss: 2.5532550461697294

Epoch: 6| Step: 6
Training loss: 1.5584366415666657
Validation loss: 2.5626570290574238

Epoch: 6| Step: 7
Training loss: 2.850246177882909
Validation loss: 2.5637541972351108

Epoch: 6| Step: 8
Training loss: 2.4857322775999227
Validation loss: 2.5876157820616332

Epoch: 6| Step: 9
Training loss: 3.207828994017355
Validation loss: 2.6102582372383574

Epoch: 6| Step: 10
Training loss: 2.880353669862222
Validation loss: 2.6234454519486308

Epoch: 6| Step: 11
Training loss: 3.1346118354507237
Validation loss: 2.600499901937531

Epoch: 6| Step: 12
Training loss: 3.0360484732677193
Validation loss: 2.5837535116186294

Epoch: 6| Step: 13
Training loss: 2.1380224069147364
Validation loss: 2.56261016864995

Epoch: 282| Step: 0
Training loss: 3.4437648212093155
Validation loss: 2.557859427214003

Epoch: 6| Step: 1
Training loss: 3.1621957806002765
Validation loss: 2.537938664231006

Epoch: 6| Step: 2
Training loss: 3.2993793828739655
Validation loss: 2.521509159433034

Epoch: 6| Step: 3
Training loss: 2.4865198053997606
Validation loss: 2.5177944415667546

Epoch: 6| Step: 4
Training loss: 2.850793186036262
Validation loss: 2.512949176786649

Epoch: 6| Step: 5
Training loss: 2.2189043018253805
Validation loss: 2.5076770752933317

Epoch: 6| Step: 6
Training loss: 1.7052804448891787
Validation loss: 2.5214107416223506

Epoch: 6| Step: 7
Training loss: 2.718264130772349
Validation loss: 2.5195831117970577

Epoch: 6| Step: 8
Training loss: 2.7242154838207675
Validation loss: 2.527041166058041

Epoch: 6| Step: 9
Training loss: 3.0387251404373474
Validation loss: 2.544038855442657

Epoch: 6| Step: 10
Training loss: 2.95288553225718
Validation loss: 2.5899861436321894

Epoch: 6| Step: 11
Training loss: 3.0877255438459312
Validation loss: 2.5971693087254297

Epoch: 6| Step: 12
Training loss: 2.427026204977193
Validation loss: 2.6245300313697513

Epoch: 6| Step: 13
Training loss: 2.6850355514644817
Validation loss: 2.615541823114556

Epoch: 283| Step: 0
Training loss: 2.4615204620161735
Validation loss: 2.6558576319403797

Epoch: 6| Step: 1
Training loss: 2.923691129055057
Validation loss: 2.647708173013519

Epoch: 6| Step: 2
Training loss: 3.031596527742279
Validation loss: 2.657650203446683

Epoch: 6| Step: 3
Training loss: 3.0430765585844615
Validation loss: 2.6596307790114615

Epoch: 6| Step: 4
Training loss: 2.9640095659274075
Validation loss: 2.667158263857283

Epoch: 6| Step: 5
Training loss: 3.2385701417616928
Validation loss: 2.6294089411160355

Epoch: 6| Step: 6
Training loss: 2.6318207183001516
Validation loss: 2.6217001034555842

Epoch: 6| Step: 7
Training loss: 2.3830874425138058
Validation loss: 2.575789881748161

Epoch: 6| Step: 8
Training loss: 3.0459422713461817
Validation loss: 2.563027298381546

Epoch: 6| Step: 9
Training loss: 2.762791275617721
Validation loss: 2.5302046300091363

Epoch: 6| Step: 10
Training loss: 2.7255894364676574
Validation loss: 2.5264061172138064

Epoch: 6| Step: 11
Training loss: 2.680931225302553
Validation loss: 2.501994334265252

Epoch: 6| Step: 12
Training loss: 2.8294883518926337
Validation loss: 2.506004506985752

Epoch: 6| Step: 13
Training loss: 2.435091736336391
Validation loss: 2.5050860301285724

Epoch: 284| Step: 0
Training loss: 2.690476742867768
Validation loss: 2.4903671709877955

Epoch: 6| Step: 1
Training loss: 3.0056755103874195
Validation loss: 2.502969126164801

Epoch: 6| Step: 2
Training loss: 3.122509536178846
Validation loss: 2.5140836571091167

Epoch: 6| Step: 3
Training loss: 2.6569816927955734
Validation loss: 2.5186108353396746

Epoch: 6| Step: 4
Training loss: 3.0492015856710086
Validation loss: 2.5182263409445507

Epoch: 6| Step: 5
Training loss: 2.3405835951439404
Validation loss: 2.517384829656376

Epoch: 6| Step: 6
Training loss: 2.494377489425652
Validation loss: 2.5120397103779366

Epoch: 6| Step: 7
Training loss: 2.496689893905642
Validation loss: 2.5285230861763797

Epoch: 6| Step: 8
Training loss: 3.1196530183393767
Validation loss: 2.527588888026365

Epoch: 6| Step: 9
Training loss: 2.3677301068248147
Validation loss: 2.5300823239278225

Epoch: 6| Step: 10
Training loss: 3.0045366952616552
Validation loss: 2.5386740201317664

Epoch: 6| Step: 11
Training loss: 2.5462583953913778
Validation loss: 2.5444332083626118

Epoch: 6| Step: 12
Training loss: 3.026281000456763
Validation loss: 2.555773174672247

Epoch: 6| Step: 13
Training loss: 3.3576439944340994
Validation loss: 2.6019326666987457

Epoch: 285| Step: 0
Training loss: 2.8078891682121525
Validation loss: 2.6462623999859924

Epoch: 6| Step: 1
Training loss: 2.796751818794688
Validation loss: 2.685134786511537

Epoch: 6| Step: 2
Training loss: 2.7065609830352826
Validation loss: 2.6628184900129637

Epoch: 6| Step: 3
Training loss: 3.1357913041641474
Validation loss: 2.6412391247004288

Epoch: 6| Step: 4
Training loss: 3.057647597710879
Validation loss: 2.6239066535157898

Epoch: 6| Step: 5
Training loss: 2.8151082130894736
Validation loss: 2.549288375978855

Epoch: 6| Step: 6
Training loss: 2.920127305168998
Validation loss: 2.520289110547759

Epoch: 6| Step: 7
Training loss: 2.8184959077181095
Validation loss: 2.497049377801018

Epoch: 6| Step: 8
Training loss: 2.9388645330556398
Validation loss: 2.4877443843762355

Epoch: 6| Step: 9
Training loss: 2.3519034407835044
Validation loss: 2.49079027000562

Epoch: 6| Step: 10
Training loss: 1.9552810365481392
Validation loss: 2.4941463502032253

Epoch: 6| Step: 11
Training loss: 3.585909841260435
Validation loss: 2.4937480225289077

Epoch: 6| Step: 12
Training loss: 2.983282878029953
Validation loss: 2.5011752565568637

Epoch: 6| Step: 13
Training loss: 3.191526525091679
Validation loss: 2.4988180299220817

Epoch: 286| Step: 0
Training loss: 3.1205076352432353
Validation loss: 2.4873669754533214

Epoch: 6| Step: 1
Training loss: 2.700450036725062
Validation loss: 2.490011776025967

Epoch: 6| Step: 2
Training loss: 2.438839177740425
Validation loss: 2.4940387141835823

Epoch: 6| Step: 3
Training loss: 3.0618282281994564
Validation loss: 2.490198485091494

Epoch: 6| Step: 4
Training loss: 2.7065242496223725
Validation loss: 2.504915385864146

Epoch: 6| Step: 5
Training loss: 2.598961523712789
Validation loss: 2.5154104220888867

Epoch: 6| Step: 6
Training loss: 2.9712144761455432
Validation loss: 2.527053074032982

Epoch: 6| Step: 7
Training loss: 2.808338816908134
Validation loss: 2.5297149050489716

Epoch: 6| Step: 8
Training loss: 2.939835776329125
Validation loss: 2.4980714537586204

Epoch: 6| Step: 9
Training loss: 2.9615138154809726
Validation loss: 2.5041615990717183

Epoch: 6| Step: 10
Training loss: 3.509952563538575
Validation loss: 2.490277298700736

Epoch: 6| Step: 11
Training loss: 2.783419416623055
Validation loss: 2.485317924019312

Epoch: 6| Step: 12
Training loss: 2.565209979409942
Validation loss: 2.48268505531292

Epoch: 6| Step: 13
Training loss: 1.9817522393121696
Validation loss: 2.4877973364692725

Epoch: 287| Step: 0
Training loss: 3.0227797628187925
Validation loss: 2.490987172783319

Epoch: 6| Step: 1
Training loss: 2.340256999974091
Validation loss: 2.482723099400734

Epoch: 6| Step: 2
Training loss: 2.979051565512163
Validation loss: 2.512047760395955

Epoch: 6| Step: 3
Training loss: 2.9891778934616395
Validation loss: 2.5189112331635375

Epoch: 6| Step: 4
Training loss: 2.784896517462736
Validation loss: 2.510456836658011

Epoch: 6| Step: 5
Training loss: 2.619911620855278
Validation loss: 2.526827444989498

Epoch: 6| Step: 6
Training loss: 2.8019430605203586
Validation loss: 2.5102039897746042

Epoch: 6| Step: 7
Training loss: 2.7776182658702395
Validation loss: 2.5273140290282137

Epoch: 6| Step: 8
Training loss: 2.701210887789945
Validation loss: 2.5254219471410133

Epoch: 6| Step: 9
Training loss: 3.342323355390275
Validation loss: 2.5290036885689546

Epoch: 6| Step: 10
Training loss: 2.6491175315822577
Validation loss: 2.5258881143665146

Epoch: 6| Step: 11
Training loss: 2.978232248302523
Validation loss: 2.533205072116928

Epoch: 6| Step: 12
Training loss: 2.6787430681004554
Validation loss: 2.5376101314501147

Epoch: 6| Step: 13
Training loss: 1.7217347325068642
Validation loss: 2.5638411179112506

Epoch: 288| Step: 0
Training loss: 2.7215125419612245
Validation loss: 2.5453518544934717

Epoch: 6| Step: 1
Training loss: 2.717866688320039
Validation loss: 2.5678756537211895

Epoch: 6| Step: 2
Training loss: 2.828577837861081
Validation loss: 2.5823185280768004

Epoch: 6| Step: 3
Training loss: 2.687003599941737
Validation loss: 2.5728104132552385

Epoch: 6| Step: 4
Training loss: 3.4982409825402008
Validation loss: 2.5554833819592178

Epoch: 6| Step: 5
Training loss: 2.4253617321670498
Validation loss: 2.567593381482209

Epoch: 6| Step: 6
Training loss: 3.053087678991606
Validation loss: 2.5514792290915884

Epoch: 6| Step: 7
Training loss: 2.0248485932438314
Validation loss: 2.5355121799986398

Epoch: 6| Step: 8
Training loss: 2.8625732212613393
Validation loss: 2.5295740522150125

Epoch: 6| Step: 9
Training loss: 2.526677180832834
Validation loss: 2.527706863365394

Epoch: 6| Step: 10
Training loss: 2.052399844886716
Validation loss: 2.50752938500125

Epoch: 6| Step: 11
Training loss: 2.9604778486601155
Validation loss: 2.506578700788606

Epoch: 6| Step: 12
Training loss: 3.4945448187998083
Validation loss: 2.5037821852130375

Epoch: 6| Step: 13
Training loss: 2.8731574083300746
Validation loss: 2.5128603202662414

Epoch: 289| Step: 0
Training loss: 2.5388452055456567
Validation loss: 2.512971986711081

Epoch: 6| Step: 1
Training loss: 3.244413563031223
Validation loss: 2.5336072087465213

Epoch: 6| Step: 2
Training loss: 3.112923136065169
Validation loss: 2.560642344433354

Epoch: 6| Step: 3
Training loss: 2.1428969084365135
Validation loss: 2.5620703428289775

Epoch: 6| Step: 4
Training loss: 3.145783548192736
Validation loss: 2.569076140492921

Epoch: 6| Step: 5
Training loss: 3.0424497110290294
Validation loss: 2.6041623285729156

Epoch: 6| Step: 6
Training loss: 2.520189965066517
Validation loss: 2.6195665713465606

Epoch: 6| Step: 7
Training loss: 2.6859047169263066
Validation loss: 2.625358664468824

Epoch: 6| Step: 8
Training loss: 2.1094736711948103
Validation loss: 2.5920214269315287

Epoch: 6| Step: 9
Training loss: 3.0577792158542376
Validation loss: 2.5897564438741734

Epoch: 6| Step: 10
Training loss: 2.5609310278074675
Validation loss: 2.5708942739239227

Epoch: 6| Step: 11
Training loss: 3.1110162285308203
Validation loss: 2.5313189299776715

Epoch: 6| Step: 12
Training loss: 2.862871877177153
Validation loss: 2.523812664903075

Epoch: 6| Step: 13
Training loss: 2.581194166267739
Validation loss: 2.5008795831617143

Epoch: 290| Step: 0
Training loss: 2.6174687020981975
Validation loss: 2.49689827234273

Epoch: 6| Step: 1
Training loss: 1.9954353933941849
Validation loss: 2.4916073227996822

Epoch: 6| Step: 2
Training loss: 2.9307374420690953
Validation loss: 2.5015813235808007

Epoch: 6| Step: 3
Training loss: 3.204758241673347
Validation loss: 2.5121973545916503

Epoch: 6| Step: 4
Training loss: 2.9711201091101636
Validation loss: 2.505653440215697

Epoch: 6| Step: 5
Training loss: 2.117010242882457
Validation loss: 2.500096522282985

Epoch: 6| Step: 6
Training loss: 3.3007110407658815
Validation loss: 2.507450544173666

Epoch: 6| Step: 7
Training loss: 2.969472054461291
Validation loss: 2.5113007715313582

Epoch: 6| Step: 8
Training loss: 2.8682859224091364
Validation loss: 2.5220554653452374

Epoch: 6| Step: 9
Training loss: 2.3890786748604267
Validation loss: 2.526883232475811

Epoch: 6| Step: 10
Training loss: 2.903494728615694
Validation loss: 2.5530269529922607

Epoch: 6| Step: 11
Training loss: 2.494403105376478
Validation loss: 2.548492278507261

Epoch: 6| Step: 12
Training loss: 2.646895508309533
Validation loss: 2.558416863672089

Epoch: 6| Step: 13
Training loss: 3.566653858292538
Validation loss: 2.547522598353628

Epoch: 291| Step: 0
Training loss: 2.9814150846506466
Validation loss: 2.549588353821171

Epoch: 6| Step: 1
Training loss: 2.7067670156483645
Validation loss: 2.559461348681163

Epoch: 6| Step: 2
Training loss: 2.7238742287794757
Validation loss: 2.552835718131667

Epoch: 6| Step: 3
Training loss: 2.753453427144113
Validation loss: 2.54356938384271

Epoch: 6| Step: 4
Training loss: 2.416804265895287
Validation loss: 2.5842428736544782

Epoch: 6| Step: 5
Training loss: 2.553408988183738
Validation loss: 2.5772227578294995

Epoch: 6| Step: 6
Training loss: 2.3650977853636994
Validation loss: 2.59255341238831

Epoch: 6| Step: 7
Training loss: 2.853569098147159
Validation loss: 2.621877521286491

Epoch: 6| Step: 8
Training loss: 3.498621260334791
Validation loss: 2.581587720351451

Epoch: 6| Step: 9
Training loss: 2.9877274941372467
Validation loss: 2.5557952412967158

Epoch: 6| Step: 10
Training loss: 2.7395779182951077
Validation loss: 2.5235381006503768

Epoch: 6| Step: 11
Training loss: 3.0935403772101777
Validation loss: 2.5183445696115436

Epoch: 6| Step: 12
Training loss: 2.781101951516302
Validation loss: 2.506393146986473

Epoch: 6| Step: 13
Training loss: 1.9560377450667286
Validation loss: 2.501330852057513

Epoch: 292| Step: 0
Training loss: 2.907532111767131
Validation loss: 2.49207899137913

Epoch: 6| Step: 1
Training loss: 2.779177718781586
Validation loss: 2.490924032616221

Epoch: 6| Step: 2
Training loss: 3.1688952049678702
Validation loss: 2.4999969892586247

Epoch: 6| Step: 3
Training loss: 2.860670452894474
Validation loss: 2.5030064430400523

Epoch: 6| Step: 4
Training loss: 3.004014190599675
Validation loss: 2.4885133146425678

Epoch: 6| Step: 5
Training loss: 2.4682371355260706
Validation loss: 2.487933320854185

Epoch: 6| Step: 6
Training loss: 2.8025217859542666
Validation loss: 2.497620313433101

Epoch: 6| Step: 7
Training loss: 2.35612597556496
Validation loss: 2.5112535969708794

Epoch: 6| Step: 8
Training loss: 2.2838912723068674
Validation loss: 2.5122211499710696

Epoch: 6| Step: 9
Training loss: 2.413635018532327
Validation loss: 2.517988289873158

Epoch: 6| Step: 10
Training loss: 2.863455773586377
Validation loss: 2.5490219546044948

Epoch: 6| Step: 11
Training loss: 3.1297041010309212
Validation loss: 2.565064719216266

Epoch: 6| Step: 12
Training loss: 2.973684446390797
Validation loss: 2.5601505651070453

Epoch: 6| Step: 13
Training loss: 2.7084223708164528
Validation loss: 2.5935506120119287

Epoch: 293| Step: 0
Training loss: 2.5303975306373148
Validation loss: 2.591372647156741

Epoch: 6| Step: 1
Training loss: 2.8437966143801425
Validation loss: 2.5916935012605133

Epoch: 6| Step: 2
Training loss: 3.094717625815434
Validation loss: 2.6103502454961878

Epoch: 6| Step: 3
Training loss: 2.63524354710362
Validation loss: 2.5906933355628765

Epoch: 6| Step: 4
Training loss: 2.3851094166030835
Validation loss: 2.588003811844356

Epoch: 6| Step: 5
Training loss: 2.6599007146275264
Validation loss: 2.582840130777797

Epoch: 6| Step: 6
Training loss: 3.0919637436215384
Validation loss: 2.557690013575421

Epoch: 6| Step: 7
Training loss: 2.5316886992643686
Validation loss: 2.552145608657403

Epoch: 6| Step: 8
Training loss: 3.3090344420387394
Validation loss: 2.5642957160548043

Epoch: 6| Step: 9
Training loss: 2.4358489484761736
Validation loss: 2.5634080251974622

Epoch: 6| Step: 10
Training loss: 3.0751100287872544
Validation loss: 2.5806770588072525

Epoch: 6| Step: 11
Training loss: 2.612506380940361
Validation loss: 2.566507804433246

Epoch: 6| Step: 12
Training loss: 2.683678504904786
Validation loss: 2.5487535832198494

Epoch: 6| Step: 13
Training loss: 2.59172033845169
Validation loss: 2.552367570295354

Epoch: 294| Step: 0
Training loss: 2.9452914533191987
Validation loss: 2.5357821236280707

Epoch: 6| Step: 1
Training loss: 2.6921685057073526
Validation loss: 2.5088616015162124

Epoch: 6| Step: 2
Training loss: 2.944711962928921
Validation loss: 2.4998093399029644

Epoch: 6| Step: 3
Training loss: 2.8550679438267643
Validation loss: 2.4995881100230424

Epoch: 6| Step: 4
Training loss: 3.2410938302699246
Validation loss: 2.49680374567269

Epoch: 6| Step: 5
Training loss: 2.301588244012557
Validation loss: 2.526305231963458

Epoch: 6| Step: 6
Training loss: 2.8348613620344056
Validation loss: 2.518204335020299

Epoch: 6| Step: 7
Training loss: 2.6904333208063034
Validation loss: 2.5472547624333766

Epoch: 6| Step: 8
Training loss: 2.255737301384553
Validation loss: 2.536282247580726

Epoch: 6| Step: 9
Training loss: 2.7125802023848284
Validation loss: 2.5672122557901838

Epoch: 6| Step: 10
Training loss: 2.9239491327456073
Validation loss: 2.554783253617107

Epoch: 6| Step: 11
Training loss: 3.174698348246012
Validation loss: 2.5681779874522386

Epoch: 6| Step: 12
Training loss: 2.377015312842
Validation loss: 2.5594393532294775

Epoch: 6| Step: 13
Training loss: 2.1424943321624887
Validation loss: 2.624836068374302

Epoch: 295| Step: 0
Training loss: 2.586103266908864
Validation loss: 2.673763209310533

Epoch: 6| Step: 1
Training loss: 2.2685779138460695
Validation loss: 2.7319658289338777

Epoch: 6| Step: 2
Training loss: 1.8547915859308803
Validation loss: 2.750125237052864

Epoch: 6| Step: 3
Training loss: 2.6430429978728567
Validation loss: 2.727665077052626

Epoch: 6| Step: 4
Training loss: 2.365974543559479
Validation loss: 2.7105418849819256

Epoch: 6| Step: 5
Training loss: 3.267661303951018
Validation loss: 2.6744885541180783

Epoch: 6| Step: 6
Training loss: 2.8893890212847424
Validation loss: 2.619887135189851

Epoch: 6| Step: 7
Training loss: 2.9622213755736206
Validation loss: 2.561811595282109

Epoch: 6| Step: 8
Training loss: 3.1440907045340474
Validation loss: 2.51922743157017

Epoch: 6| Step: 9
Training loss: 2.9459940073816036
Validation loss: 2.4916017445558167

Epoch: 6| Step: 10
Training loss: 3.53384614557955
Validation loss: 2.502118710036426

Epoch: 6| Step: 11
Training loss: 2.51270764759652
Validation loss: 2.5031133257588665

Epoch: 6| Step: 12
Training loss: 3.2349959067741807
Validation loss: 2.5025834691391164

Epoch: 6| Step: 13
Training loss: 2.4182616812854607
Validation loss: 2.5207936187099853

Epoch: 296| Step: 0
Training loss: 2.285360734707792
Validation loss: 2.5086599231867934

Epoch: 6| Step: 1
Training loss: 2.2997509863024352
Validation loss: 2.512813994226513

Epoch: 6| Step: 2
Training loss: 2.679123710734888
Validation loss: 2.514849841499674

Epoch: 6| Step: 3
Training loss: 3.066975184829964
Validation loss: 2.4986428791874626

Epoch: 6| Step: 4
Training loss: 2.614324569562297
Validation loss: 2.4978578803840397

Epoch: 6| Step: 5
Training loss: 3.4316117226301373
Validation loss: 2.4993992032294625

Epoch: 6| Step: 6
Training loss: 2.8899665701229527
Validation loss: 2.5021541861420844

Epoch: 6| Step: 7
Training loss: 2.9239882716453782
Validation loss: 2.507007370346919

Epoch: 6| Step: 8
Training loss: 2.563555616340572
Validation loss: 2.5054202490399504

Epoch: 6| Step: 9
Training loss: 3.124067854140718
Validation loss: 2.5291495318867185

Epoch: 6| Step: 10
Training loss: 3.272401194993311
Validation loss: 2.530648471340689

Epoch: 6| Step: 11
Training loss: 2.9161348312142223
Validation loss: 2.561869350837474

Epoch: 6| Step: 12
Training loss: 2.866310921115989
Validation loss: 2.5637906373619366

Epoch: 6| Step: 13
Training loss: 2.6417037295399965
Validation loss: 2.580259266163916

Epoch: 297| Step: 0
Training loss: 3.279755751657026
Validation loss: 2.588589211746529

Epoch: 6| Step: 1
Training loss: 2.686196476832251
Validation loss: 2.547052369823096

Epoch: 6| Step: 2
Training loss: 3.0605641688945826
Validation loss: 2.5407130740306694

Epoch: 6| Step: 3
Training loss: 2.738244855042995
Validation loss: 2.5271518051953197

Epoch: 6| Step: 4
Training loss: 2.503384206926255
Validation loss: 2.5217426510565644

Epoch: 6| Step: 5
Training loss: 3.031903697837216
Validation loss: 2.509576717133571

Epoch: 6| Step: 6
Training loss: 3.0350550729194845
Validation loss: 2.510841379316089

Epoch: 6| Step: 7
Training loss: 2.7507880555588473
Validation loss: 2.51946824721504

Epoch: 6| Step: 8
Training loss: 2.5680748379399883
Validation loss: 2.5249802096726532

Epoch: 6| Step: 9
Training loss: 2.446453084415147
Validation loss: 2.556626806230662

Epoch: 6| Step: 10
Training loss: 2.764736657872506
Validation loss: 2.57936134363726

Epoch: 6| Step: 11
Training loss: 2.5264948697259824
Validation loss: 2.559164927814431

Epoch: 6| Step: 12
Training loss: 2.228746166557571
Validation loss: 2.5194007513501213

Epoch: 6| Step: 13
Training loss: 3.228180781987565
Validation loss: 2.517608481249713

Epoch: 298| Step: 0
Training loss: 2.35161856651004
Validation loss: 2.5265079096340313

Epoch: 6| Step: 1
Training loss: 2.8647225825825946
Validation loss: 2.5442754329150667

Epoch: 6| Step: 2
Training loss: 3.159510976881883
Validation loss: 2.5454185806434353

Epoch: 6| Step: 3
Training loss: 3.0674184112766336
Validation loss: 2.551291343916407

Epoch: 6| Step: 4
Training loss: 2.1968769187430497
Validation loss: 2.545176419956663

Epoch: 6| Step: 5
Training loss: 2.6689549601911247
Validation loss: 2.543178323325864

Epoch: 6| Step: 6
Training loss: 2.970279339841533
Validation loss: 2.561598204156235

Epoch: 6| Step: 7
Training loss: 2.9601070477485876
Validation loss: 2.569969402950025

Epoch: 6| Step: 8
Training loss: 2.8811195592253336
Validation loss: 2.6007059649430406

Epoch: 6| Step: 9
Training loss: 2.5579703699980265
Validation loss: 2.6063155754155285

Epoch: 6| Step: 10
Training loss: 2.2969764116177958
Validation loss: 2.5979636310925893

Epoch: 6| Step: 11
Training loss: 2.54409254237464
Validation loss: 2.567580955111676

Epoch: 6| Step: 12
Training loss: 2.8292878010304237
Validation loss: 2.5637285582426346

Epoch: 6| Step: 13
Training loss: 3.2288146944908225
Validation loss: 2.565671209575403

Epoch: 299| Step: 0
Training loss: 2.858043089459726
Validation loss: 2.5426550492850044

Epoch: 6| Step: 1
Training loss: 2.946246497403419
Validation loss: 2.5306986121252675

Epoch: 6| Step: 2
Training loss: 2.8266731033911685
Validation loss: 2.512596604550072

Epoch: 6| Step: 3
Training loss: 2.334344122706704
Validation loss: 2.5003277799601022

Epoch: 6| Step: 4
Training loss: 2.909515679028252
Validation loss: 2.4842283298865

Epoch: 6| Step: 5
Training loss: 2.8313391530398
Validation loss: 2.496770892956266

Epoch: 6| Step: 6
Training loss: 3.084444481589799
Validation loss: 2.512426509689482

Epoch: 6| Step: 7
Training loss: 2.5629285128443757
Validation loss: 2.5096181822446586

Epoch: 6| Step: 8
Training loss: 2.8138250832218596
Validation loss: 2.524525911474656

Epoch: 6| Step: 9
Training loss: 2.9606023513220765
Validation loss: 2.534308981060543

Epoch: 6| Step: 10
Training loss: 2.8268106683752428
Validation loss: 2.572304816845263

Epoch: 6| Step: 11
Training loss: 2.5127541408776066
Validation loss: 2.5769741658127874

Epoch: 6| Step: 12
Training loss: 2.6967612975232145
Validation loss: 2.5928246579275753

Epoch: 6| Step: 13
Training loss: 1.911704654742971
Validation loss: 2.6175531221630433

Epoch: 300| Step: 0
Training loss: 2.3345013034054634
Validation loss: 2.6362419968056177

Epoch: 6| Step: 1
Training loss: 3.1050808646319212
Validation loss: 2.613825343795551

Epoch: 6| Step: 2
Training loss: 3.0319486776351403
Validation loss: 2.6113878326544366

Epoch: 6| Step: 3
Training loss: 3.0564194084287135
Validation loss: 2.636621914524466

Epoch: 6| Step: 4
Training loss: 2.9589021879056383
Validation loss: 2.6076969259901994

Epoch: 6| Step: 5
Training loss: 2.775441565908514
Validation loss: 2.5977332447406187

Epoch: 6| Step: 6
Training loss: 2.295232172340103
Validation loss: 2.581451522205607

Epoch: 6| Step: 7
Training loss: 2.601105795973498
Validation loss: 2.5689432807432993

Epoch: 6| Step: 8
Training loss: 2.774098492150708
Validation loss: 2.539967760078952

Epoch: 6| Step: 9
Training loss: 2.8828303638928223
Validation loss: 2.499769308870113

Epoch: 6| Step: 10
Training loss: 2.8625210823715315
Validation loss: 2.4993817236549307

Epoch: 6| Step: 11
Training loss: 2.9844964287305604
Validation loss: 2.498996302409713

Epoch: 6| Step: 12
Training loss: 2.690582282140387
Validation loss: 2.5009710620443046

Epoch: 6| Step: 13
Training loss: 1.7399539743014405
Validation loss: 2.5057724319375887

Epoch: 301| Step: 0
Training loss: 2.551058930826292
Validation loss: 2.5038777896997235

Epoch: 6| Step: 1
Training loss: 2.8475504202728517
Validation loss: 2.510162615023475

Epoch: 6| Step: 2
Training loss: 2.75270346489803
Validation loss: 2.499316126080254

Epoch: 6| Step: 3
Training loss: 2.689485127266254
Validation loss: 2.499944391965253

Epoch: 6| Step: 4
Training loss: 2.5355615512280347
Validation loss: 2.504379164577941

Epoch: 6| Step: 5
Training loss: 2.0765620499288215
Validation loss: 2.5036101700599507

Epoch: 6| Step: 6
Training loss: 2.6759882269117083
Validation loss: 2.513539992033575

Epoch: 6| Step: 7
Training loss: 2.773179592981969
Validation loss: 2.525437048223078

Epoch: 6| Step: 8
Training loss: 2.443749559017054
Validation loss: 2.5263571708456496

Epoch: 6| Step: 9
Training loss: 3.20742761948015
Validation loss: 2.5532674473783907

Epoch: 6| Step: 10
Training loss: 3.203902880488505
Validation loss: 2.550091149528597

Epoch: 6| Step: 11
Training loss: 2.966658005719633
Validation loss: 2.5960130985378354

Epoch: 6| Step: 12
Training loss: 2.8006821618847457
Validation loss: 2.6247587508185752

Epoch: 6| Step: 13
Training loss: 2.8935090395171703
Validation loss: 2.6311235584884094

Epoch: 302| Step: 0
Training loss: 2.9876197631325274
Validation loss: 2.630140842256961

Epoch: 6| Step: 1
Training loss: 2.751856090819445
Validation loss: 2.6147520152006996

Epoch: 6| Step: 2
Training loss: 2.7493678146584064
Validation loss: 2.639036637383261

Epoch: 6| Step: 3
Training loss: 2.844189788012033
Validation loss: 2.5972910792528827

Epoch: 6| Step: 4
Training loss: 2.9283164109370894
Validation loss: 2.5520664324189304

Epoch: 6| Step: 5
Training loss: 2.871611381112232
Validation loss: 2.533596187608581

Epoch: 6| Step: 6
Training loss: 2.8783231685645223
Validation loss: 2.5283689207346596

Epoch: 6| Step: 7
Training loss: 2.8248958804767774
Validation loss: 2.5185174595126987

Epoch: 6| Step: 8
Training loss: 2.7432617517760356
Validation loss: 2.520628117793538

Epoch: 6| Step: 9
Training loss: 3.082143880625774
Validation loss: 2.5116233888596784

Epoch: 6| Step: 10
Training loss: 2.683986052111614
Validation loss: 2.4919838930334137

Epoch: 6| Step: 11
Training loss: 2.6830556627116375
Validation loss: 2.4908085504103528

Epoch: 6| Step: 12
Training loss: 2.339836311646931
Validation loss: 2.4805228728291384

Epoch: 6| Step: 13
Training loss: 2.9647889063088737
Validation loss: 2.477662923460462

Epoch: 303| Step: 0
Training loss: 2.435807936809303
Validation loss: 2.4926742483159656

Epoch: 6| Step: 1
Training loss: 2.714050352676607
Validation loss: 2.4749237484257183

Epoch: 6| Step: 2
Training loss: 2.6977870031199425
Validation loss: 2.5003370057888374

Epoch: 6| Step: 3
Training loss: 2.6887365645707404
Validation loss: 2.5236210498669824

Epoch: 6| Step: 4
Training loss: 2.7992723302799685
Validation loss: 2.541899737143754

Epoch: 6| Step: 5
Training loss: 2.722657125683593
Validation loss: 2.571134877861599

Epoch: 6| Step: 6
Training loss: 2.490449400949348
Validation loss: 2.5799741555207496

Epoch: 6| Step: 7
Training loss: 2.9487343093435205
Validation loss: 2.5963967601290525

Epoch: 6| Step: 8
Training loss: 2.912427346301595
Validation loss: 2.6100638791064834

Epoch: 6| Step: 9
Training loss: 2.7730164114201292
Validation loss: 2.62633119201627

Epoch: 6| Step: 10
Training loss: 3.0135370645884607
Validation loss: 2.5993126904170523

Epoch: 6| Step: 11
Training loss: 2.4153148772822353
Validation loss: 2.5881975612543493

Epoch: 6| Step: 12
Training loss: 3.02084799576632
Validation loss: 2.5679526962927084

Epoch: 6| Step: 13
Training loss: 2.8831674414156487
Validation loss: 2.5446670386125883

Epoch: 304| Step: 0
Training loss: 2.898432070991799
Validation loss: 2.5331824828372866

Epoch: 6| Step: 1
Training loss: 3.255666048549472
Validation loss: 2.5158754210227463

Epoch: 6| Step: 2
Training loss: 2.266593988973775
Validation loss: 2.504745069780535

Epoch: 6| Step: 3
Training loss: 3.003356962742574
Validation loss: 2.512726542928852

Epoch: 6| Step: 4
Training loss: 2.7383029300196053
Validation loss: 2.5003611365324416

Epoch: 6| Step: 5
Training loss: 2.94411810579984
Validation loss: 2.5125560625066434

Epoch: 6| Step: 6
Training loss: 2.8051483710720237
Validation loss: 2.5111771476170133

Epoch: 6| Step: 7
Training loss: 3.1089069263346127
Validation loss: 2.539352033465518

Epoch: 6| Step: 8
Training loss: 2.8361224489881067
Validation loss: 2.5410943334206424

Epoch: 6| Step: 9
Training loss: 2.454697609048348
Validation loss: 2.5374092074492474

Epoch: 6| Step: 10
Training loss: 2.8535966698471245
Validation loss: 2.5605202947856287

Epoch: 6| Step: 11
Training loss: 1.9583582233984527
Validation loss: 2.5703293620610994

Epoch: 6| Step: 12
Training loss: 2.3700560258126226
Validation loss: 2.5885037173268257

Epoch: 6| Step: 13
Training loss: 2.1591845460144343
Validation loss: 2.582089396220998

Epoch: 305| Step: 0
Training loss: 2.475521602960894
Validation loss: 2.58999866294565

Epoch: 6| Step: 1
Training loss: 2.3017926154825377
Validation loss: 2.58472546298963

Epoch: 6| Step: 2
Training loss: 2.548436347404514
Validation loss: 2.5602884431027007

Epoch: 6| Step: 3
Training loss: 2.5476942558460096
Validation loss: 2.5403738184988334

Epoch: 6| Step: 4
Training loss: 2.826411028209542
Validation loss: 2.532963182995654

Epoch: 6| Step: 5
Training loss: 3.4042786659546
Validation loss: 2.5205573799854264

Epoch: 6| Step: 6
Training loss: 2.7325705541661853
Validation loss: 2.5267788121740518

Epoch: 6| Step: 7
Training loss: 2.721505358327496
Validation loss: 2.522170953086636

Epoch: 6| Step: 8
Training loss: 2.9319818490001284
Validation loss: 2.525594395192084

Epoch: 6| Step: 9
Training loss: 2.7670723958472543
Validation loss: 2.522670526556565

Epoch: 6| Step: 10
Training loss: 3.329695496712887
Validation loss: 2.5434661525459554

Epoch: 6| Step: 11
Training loss: 2.2506873882177465
Validation loss: 2.5572239173205573

Epoch: 6| Step: 12
Training loss: 3.0194567119681017
Validation loss: 2.5682827948127676

Epoch: 6| Step: 13
Training loss: 1.4817691617485858
Validation loss: 2.565528550601535

Epoch: 306| Step: 0
Training loss: 2.631738822999522
Validation loss: 2.5710800226319788

Epoch: 6| Step: 1
Training loss: 2.920199806484145
Validation loss: 2.5786929591622023

Epoch: 6| Step: 2
Training loss: 3.171971361923341
Validation loss: 2.579364180241123

Epoch: 6| Step: 3
Training loss: 2.219699280449918
Validation loss: 2.5947642561610174

Epoch: 6| Step: 4
Training loss: 2.8502542081195705
Validation loss: 2.5849198667326

Epoch: 6| Step: 5
Training loss: 2.6115415795449044
Validation loss: 2.5932611221433057

Epoch: 6| Step: 6
Training loss: 2.0825164973783585
Validation loss: 2.6081349009567996

Epoch: 6| Step: 7
Training loss: 2.3213214157860524
Validation loss: 2.597120453218545

Epoch: 6| Step: 8
Training loss: 2.961623945155274
Validation loss: 2.5907636189373697

Epoch: 6| Step: 9
Training loss: 2.6246860861408265
Validation loss: 2.563973787103388

Epoch: 6| Step: 10
Training loss: 2.9827590481988007
Validation loss: 2.5491094550662474

Epoch: 6| Step: 11
Training loss: 2.8843025967157794
Validation loss: 2.539443522625255

Epoch: 6| Step: 12
Training loss: 2.759972437016062
Validation loss: 2.5398667180571293

Epoch: 6| Step: 13
Training loss: 2.740608304015296
Validation loss: 2.525455946781317

Epoch: 307| Step: 0
Training loss: 2.1436051834171903
Validation loss: 2.5179658603587045

Epoch: 6| Step: 1
Training loss: 2.5581133442419093
Validation loss: 2.511771442652468

Epoch: 6| Step: 2
Training loss: 2.222353413471056
Validation loss: 2.49281439912256

Epoch: 6| Step: 3
Training loss: 2.8990106144553196
Validation loss: 2.5028919024126393

Epoch: 6| Step: 4
Training loss: 2.871240562785495
Validation loss: 2.5072095036965503

Epoch: 6| Step: 5
Training loss: 2.862161414765485
Validation loss: 2.5145549084156804

Epoch: 6| Step: 6
Training loss: 2.307424801213863
Validation loss: 2.522608185512544

Epoch: 6| Step: 7
Training loss: 2.5938502832352524
Validation loss: 2.527551642989477

Epoch: 6| Step: 8
Training loss: 3.3663721358632794
Validation loss: 2.5350480667022808

Epoch: 6| Step: 9
Training loss: 2.6460216385121664
Validation loss: 2.5374373977401374

Epoch: 6| Step: 10
Training loss: 3.0864578774063816
Validation loss: 2.5595644311553722

Epoch: 6| Step: 11
Training loss: 3.0302825642385924
Validation loss: 2.554724210442948

Epoch: 6| Step: 12
Training loss: 2.520357029161416
Validation loss: 2.5586531472436995

Epoch: 6| Step: 13
Training loss: 2.732489584355864
Validation loss: 2.5921118423924905

Epoch: 308| Step: 0
Training loss: 3.081707568752532
Validation loss: 2.5993728644132688

Epoch: 6| Step: 1
Training loss: 2.697844711777753
Validation loss: 2.6060195116639164

Epoch: 6| Step: 2
Training loss: 2.4870631232079337
Validation loss: 2.6370351940425016

Epoch: 6| Step: 3
Training loss: 2.2894509672640617
Validation loss: 2.626904430121828

Epoch: 6| Step: 4
Training loss: 1.986334966687148
Validation loss: 2.6518663256415462

Epoch: 6| Step: 5
Training loss: 2.937994408089943
Validation loss: 2.657246925081309

Epoch: 6| Step: 6
Training loss: 3.0017423338586866
Validation loss: 2.6353149790035415

Epoch: 6| Step: 7
Training loss: 2.8969418350295597
Validation loss: 2.5754252677470832

Epoch: 6| Step: 8
Training loss: 2.233740016101626
Validation loss: 2.5556749924845166

Epoch: 6| Step: 9
Training loss: 3.153561192748784
Validation loss: 2.523058195671259

Epoch: 6| Step: 10
Training loss: 3.056951985938925
Validation loss: 2.5083872508621257

Epoch: 6| Step: 11
Training loss: 3.113333018409773
Validation loss: 2.4949519032970104

Epoch: 6| Step: 12
Training loss: 2.503374587818374
Validation loss: 2.4946037566128947

Epoch: 6| Step: 13
Training loss: 2.0411049855213634
Validation loss: 2.4977313833626225

Epoch: 309| Step: 0
Training loss: 2.5910130043424857
Validation loss: 2.483752223628279

Epoch: 6| Step: 1
Training loss: 2.7495087271477465
Validation loss: 2.500804069379999

Epoch: 6| Step: 2
Training loss: 2.8442727750724885
Validation loss: 2.511571560723118

Epoch: 6| Step: 3
Training loss: 2.3172809563977754
Validation loss: 2.5316186583526434

Epoch: 6| Step: 4
Training loss: 2.412208709524714
Validation loss: 2.561741230114114

Epoch: 6| Step: 5
Training loss: 2.884610739484128
Validation loss: 2.613118237285953

Epoch: 6| Step: 6
Training loss: 3.0413414419830658
Validation loss: 2.5957488329405036

Epoch: 6| Step: 7
Training loss: 2.525952482451623
Validation loss: 2.623914674935842

Epoch: 6| Step: 8
Training loss: 2.758721134396023
Validation loss: 2.673054388118243

Epoch: 6| Step: 9
Training loss: 3.332930699508991
Validation loss: 2.678768403467035

Epoch: 6| Step: 10
Training loss: 2.6803028523432832
Validation loss: 2.642495935396404

Epoch: 6| Step: 11
Training loss: 2.2845097075481724
Validation loss: 2.574508829659521

Epoch: 6| Step: 12
Training loss: 2.759654869670268
Validation loss: 2.5606641738709075

Epoch: 6| Step: 13
Training loss: 2.902525781850463
Validation loss: 2.539819725844226

Epoch: 310| Step: 0
Training loss: 2.177047936062012
Validation loss: 2.5118380422728763

Epoch: 6| Step: 1
Training loss: 2.9302569433565644
Validation loss: 2.5155945148479435

Epoch: 6| Step: 2
Training loss: 2.512392419438191
Validation loss: 2.5033997051534835

Epoch: 6| Step: 3
Training loss: 2.586598015182254
Validation loss: 2.5216525174035347

Epoch: 6| Step: 4
Training loss: 2.5660568301358917
Validation loss: 2.518916172335527

Epoch: 6| Step: 5
Training loss: 2.955482147694653
Validation loss: 2.5300512357925355

Epoch: 6| Step: 6
Training loss: 2.4862025994125916
Validation loss: 2.5407466632107587

Epoch: 6| Step: 7
Training loss: 2.596787110825644
Validation loss: 2.553144964854836

Epoch: 6| Step: 8
Training loss: 2.4758299697892503
Validation loss: 2.562147196751907

Epoch: 6| Step: 9
Training loss: 2.5965974184269203
Validation loss: 2.5610959668317848

Epoch: 6| Step: 10
Training loss: 2.5233815662338097
Validation loss: 2.570930401449106

Epoch: 6| Step: 11
Training loss: 3.5584673895735914
Validation loss: 2.5843891965807457

Epoch: 6| Step: 12
Training loss: 3.080356466794779
Validation loss: 2.588934724042189

Epoch: 6| Step: 13
Training loss: 2.9901681963712896
Validation loss: 2.60147876623842

Epoch: 311| Step: 0
Training loss: 2.5210859839405777
Validation loss: 2.6046514733356054

Epoch: 6| Step: 1
Training loss: 2.9268498627395556
Validation loss: 2.6167872096300253

Epoch: 6| Step: 2
Training loss: 2.9152489259150456
Validation loss: 2.639457757755062

Epoch: 6| Step: 3
Training loss: 2.541947542106983
Validation loss: 2.6680470013441346

Epoch: 6| Step: 4
Training loss: 2.390280006797274
Validation loss: 2.6390800988251977

Epoch: 6| Step: 5
Training loss: 2.504328413916301
Validation loss: 2.6420232414617586

Epoch: 6| Step: 6
Training loss: 2.6332119149170437
Validation loss: 2.645816523548846

Epoch: 6| Step: 7
Training loss: 2.69679975526232
Validation loss: 2.6246199735621043

Epoch: 6| Step: 8
Training loss: 2.7451144950905064
Validation loss: 2.596131545113241

Epoch: 6| Step: 9
Training loss: 2.233023494844564
Validation loss: 2.5601680738832258

Epoch: 6| Step: 10
Training loss: 2.7262580067597026
Validation loss: 2.5410116418441855

Epoch: 6| Step: 11
Training loss: 3.1953014569453124
Validation loss: 2.521957332642874

Epoch: 6| Step: 12
Training loss: 3.0139633107018464
Validation loss: 2.5165953556050003

Epoch: 6| Step: 13
Training loss: 2.813503510208069
Validation loss: 2.5117492495311913

Epoch: 312| Step: 0
Training loss: 2.8370500384258692
Validation loss: 2.498506327460265

Epoch: 6| Step: 1
Training loss: 2.4819053034396172
Validation loss: 2.4970528633363704

Epoch: 6| Step: 2
Training loss: 3.228701863626019
Validation loss: 2.5038176244386343

Epoch: 6| Step: 3
Training loss: 2.5161698977383598
Validation loss: 2.5019428005474422

Epoch: 6| Step: 4
Training loss: 2.7510816007636083
Validation loss: 2.5166144499332432

Epoch: 6| Step: 5
Training loss: 2.845206757392083
Validation loss: 2.5264672970647633

Epoch: 6| Step: 6
Training loss: 2.237612745971438
Validation loss: 2.559477430347305

Epoch: 6| Step: 7
Training loss: 2.853533338090985
Validation loss: 2.5753522105380258

Epoch: 6| Step: 8
Training loss: 2.039403192697622
Validation loss: 2.585324230463502

Epoch: 6| Step: 9
Training loss: 3.3037252265154335
Validation loss: 2.601333242963294

Epoch: 6| Step: 10
Training loss: 2.7610769861604076
Validation loss: 2.6004199344393455

Epoch: 6| Step: 11
Training loss: 2.3622142558393646
Validation loss: 2.5863542415826526

Epoch: 6| Step: 12
Training loss: 2.8055037051992064
Validation loss: 2.6035554443388484

Epoch: 6| Step: 13
Training loss: 2.3566364285131187
Validation loss: 2.6005644086672945

Epoch: 313| Step: 0
Training loss: 2.7461845632543604
Validation loss: 2.587587695572401

Epoch: 6| Step: 1
Training loss: 3.198400968148265
Validation loss: 2.5967404368695663

Epoch: 6| Step: 2
Training loss: 2.6909297969850954
Validation loss: 2.6023601804578047

Epoch: 6| Step: 3
Training loss: 3.143314557415524
Validation loss: 2.6531082074520844

Epoch: 6| Step: 4
Training loss: 2.4509423137025594
Validation loss: 2.6525586725736594

Epoch: 6| Step: 5
Training loss: 2.3919514485410724
Validation loss: 2.6327060986999227

Epoch: 6| Step: 6
Training loss: 3.007538225623885
Validation loss: 2.6428526842962863

Epoch: 6| Step: 7
Training loss: 2.3519132739056583
Validation loss: 2.599271160946979

Epoch: 6| Step: 8
Training loss: 2.8161389862949973
Validation loss: 2.584857602791823

Epoch: 6| Step: 9
Training loss: 2.469539178185678
Validation loss: 2.5785993053366054

Epoch: 6| Step: 10
Training loss: 2.3201429517047467
Validation loss: 2.547930327391011

Epoch: 6| Step: 11
Training loss: 2.619339789570559
Validation loss: 2.5160298690128924

Epoch: 6| Step: 12
Training loss: 2.420814922041705
Validation loss: 2.4917719440509885

Epoch: 6| Step: 13
Training loss: 3.178946593847277
Validation loss: 2.4914122656529045

Epoch: 314| Step: 0
Training loss: 2.8556684640743897
Validation loss: 2.4820826702039946

Epoch: 6| Step: 1
Training loss: 2.5454427050030266
Validation loss: 2.4773060955655595

Epoch: 6| Step: 2
Training loss: 2.433156667680139
Validation loss: 2.473210135738527

Epoch: 6| Step: 3
Training loss: 3.078995944509533
Validation loss: 2.479264457416756

Epoch: 6| Step: 4
Training loss: 2.672384202409314
Validation loss: 2.486773926411179

Epoch: 6| Step: 5
Training loss: 2.7622972716085137
Validation loss: 2.4753069187128536

Epoch: 6| Step: 6
Training loss: 2.7314640790549007
Validation loss: 2.49614585637079

Epoch: 6| Step: 7
Training loss: 2.4267814896040623
Validation loss: 2.496660478540083

Epoch: 6| Step: 8
Training loss: 2.6297017632571906
Validation loss: 2.527860658451248

Epoch: 6| Step: 9
Training loss: 2.3397017039390997
Validation loss: 2.5607092037564483

Epoch: 6| Step: 10
Training loss: 2.347342319413182
Validation loss: 2.6046938235055324

Epoch: 6| Step: 11
Training loss: 2.938700978313616
Validation loss: 2.6515231865413673

Epoch: 6| Step: 12
Training loss: 2.891357823862829
Validation loss: 2.664233355621283

Epoch: 6| Step: 13
Training loss: 3.1972472808442145
Validation loss: 2.682991541683412

Epoch: 315| Step: 0
Training loss: 2.9728485726941143
Validation loss: 2.655323551764402

Epoch: 6| Step: 1
Training loss: 2.754792632175617
Validation loss: 2.6484036891302534

Epoch: 6| Step: 2
Training loss: 2.523395171858616
Validation loss: 2.620666012241283

Epoch: 6| Step: 3
Training loss: 3.1835745781631317
Validation loss: 2.599199333231697

Epoch: 6| Step: 4
Training loss: 2.4746170826636082
Validation loss: 2.597119510529403

Epoch: 6| Step: 5
Training loss: 2.6463240120925366
Validation loss: 2.564893052828137

Epoch: 6| Step: 6
Training loss: 2.295396082156784
Validation loss: 2.54158618489589

Epoch: 6| Step: 7
Training loss: 2.786901325889408
Validation loss: 2.5086716516935246

Epoch: 6| Step: 8
Training loss: 2.382753165084759
Validation loss: 2.5053940703880038

Epoch: 6| Step: 9
Training loss: 2.5974798386409077
Validation loss: 2.496738985486495

Epoch: 6| Step: 10
Training loss: 2.973490734495792
Validation loss: 2.4930426118455875

Epoch: 6| Step: 11
Training loss: 2.6795212051796806
Validation loss: 2.495208547838943

Epoch: 6| Step: 12
Training loss: 2.861322292282878
Validation loss: 2.4855007830914286

Epoch: 6| Step: 13
Training loss: 2.121859754639636
Validation loss: 2.491871905402686

Epoch: 316| Step: 0
Training loss: 2.995315072581381
Validation loss: 2.490216522764059

Epoch: 6| Step: 1
Training loss: 2.7710044827103193
Validation loss: 2.515045633301014

Epoch: 6| Step: 2
Training loss: 2.899406003956888
Validation loss: 2.518036972329756

Epoch: 6| Step: 3
Training loss: 2.0607669369308037
Validation loss: 2.5263902365120576

Epoch: 6| Step: 4
Training loss: 2.237540610173977
Validation loss: 2.5580188267167414

Epoch: 6| Step: 5
Training loss: 2.5742911761316507
Validation loss: 2.5769729660524767

Epoch: 6| Step: 6
Training loss: 3.0845509951391255
Validation loss: 2.6227179851391544

Epoch: 6| Step: 7
Training loss: 3.0330542474430175
Validation loss: 2.6222809510403575

Epoch: 6| Step: 8
Training loss: 3.060747540486114
Validation loss: 2.6336008282097354

Epoch: 6| Step: 9
Training loss: 3.0726483416461603
Validation loss: 2.6127705862881885

Epoch: 6| Step: 10
Training loss: 2.1592788431975767
Validation loss: 2.590827962384632

Epoch: 6| Step: 11
Training loss: 2.5981354006223465
Validation loss: 2.5684039685315185

Epoch: 6| Step: 12
Training loss: 2.183565470558437
Validation loss: 2.5480446806113353

Epoch: 6| Step: 13
Training loss: 3.1468083636929047
Validation loss: 2.5318429136774343

Epoch: 317| Step: 0
Training loss: 2.6822701067505537
Validation loss: 2.51087662293089

Epoch: 6| Step: 1
Training loss: 2.6505851027695613
Validation loss: 2.5047557470516195

Epoch: 6| Step: 2
Training loss: 2.3858914853638336
Validation loss: 2.5031726046422724

Epoch: 6| Step: 3
Training loss: 2.4042400536225816
Validation loss: 2.4987528941114485

Epoch: 6| Step: 4
Training loss: 2.7184319145653064
Validation loss: 2.4980417313895167

Epoch: 6| Step: 5
Training loss: 2.8563176053182833
Validation loss: 2.4929497437440578

Epoch: 6| Step: 6
Training loss: 2.313193861506611
Validation loss: 2.5028451194027146

Epoch: 6| Step: 7
Training loss: 2.506851344846984
Validation loss: 2.5250271724545357

Epoch: 6| Step: 8
Training loss: 2.8064310503967675
Validation loss: 2.523045070872047

Epoch: 6| Step: 9
Training loss: 2.640725037976557
Validation loss: 2.546350444861398

Epoch: 6| Step: 10
Training loss: 2.668747705820424
Validation loss: 2.5123759154639282

Epoch: 6| Step: 11
Training loss: 2.6861765952041496
Validation loss: 2.5584331588239233

Epoch: 6| Step: 12
Training loss: 3.0635953228992623
Validation loss: 2.5766329627089335

Epoch: 6| Step: 13
Training loss: 3.4329836219776944
Validation loss: 2.6067468402100897

Epoch: 318| Step: 0
Training loss: 2.677855285096168
Validation loss: 2.6369189668793886

Epoch: 6| Step: 1
Training loss: 2.8726385618676264
Validation loss: 2.676118502476217

Epoch: 6| Step: 2
Training loss: 3.0261937079695174
Validation loss: 2.710885025447557

Epoch: 6| Step: 3
Training loss: 2.643257048260943
Validation loss: 2.6836297550649877

Epoch: 6| Step: 4
Training loss: 2.828404786828271
Validation loss: 2.6937351532939924

Epoch: 6| Step: 5
Training loss: 2.250899347069075
Validation loss: 2.709051528880116

Epoch: 6| Step: 6
Training loss: 3.177368518140954
Validation loss: 2.72069668268308

Epoch: 6| Step: 7
Training loss: 2.913848132719301
Validation loss: 2.688927452841176

Epoch: 6| Step: 8
Training loss: 2.2468917357944935
Validation loss: 2.6306856716233264

Epoch: 6| Step: 9
Training loss: 2.279445195541033
Validation loss: 2.5591451101393328

Epoch: 6| Step: 10
Training loss: 2.518777329365245
Validation loss: 2.5063336548034045

Epoch: 6| Step: 11
Training loss: 2.7044949450340714
Validation loss: 2.492533982662043

Epoch: 6| Step: 12
Training loss: 2.698026048561396
Validation loss: 2.4758123647139483

Epoch: 6| Step: 13
Training loss: 3.0177443572740508
Validation loss: 2.4649462147094243

Epoch: 319| Step: 0
Training loss: 2.462483722613606
Validation loss: 2.462036506204843

Epoch: 6| Step: 1
Training loss: 3.011004292688062
Validation loss: 2.462597983612604

Epoch: 6| Step: 2
Training loss: 2.217362735804909
Validation loss: 2.471737964298172

Epoch: 6| Step: 3
Training loss: 2.8180052388713106
Validation loss: 2.4691255033879087

Epoch: 6| Step: 4
Training loss: 3.1319828599677613
Validation loss: 2.4789280616746394

Epoch: 6| Step: 5
Training loss: 2.849364387172808
Validation loss: 2.4746595551889747

Epoch: 6| Step: 6
Training loss: 2.428401594474569
Validation loss: 2.4748783240764203

Epoch: 6| Step: 7
Training loss: 2.996626546702206
Validation loss: 2.474773357617243

Epoch: 6| Step: 8
Training loss: 2.704581513248251
Validation loss: 2.495922409797114

Epoch: 6| Step: 9
Training loss: 2.5005849154004784
Validation loss: 2.5046867881912425

Epoch: 6| Step: 10
Training loss: 2.6145930397694475
Validation loss: 2.5213606464335863

Epoch: 6| Step: 11
Training loss: 2.482495826802199
Validation loss: 2.545529404974262

Epoch: 6| Step: 12
Training loss: 2.697793984784305
Validation loss: 2.558275968707423

Epoch: 6| Step: 13
Training loss: 2.8590421222307048
Validation loss: 2.557550876841008

Epoch: 320| Step: 0
Training loss: 2.3010947980455487
Validation loss: 2.6122027848319314

Epoch: 6| Step: 1
Training loss: 2.9284895011527388
Validation loss: 2.667378684964577

Epoch: 6| Step: 2
Training loss: 2.905803358971619
Validation loss: 2.6936559798093875

Epoch: 6| Step: 3
Training loss: 2.6242266832863765
Validation loss: 2.7213364771845865

Epoch: 6| Step: 4
Training loss: 3.1289141746544464
Validation loss: 2.7290992669001732

Epoch: 6| Step: 5
Training loss: 2.6731296738875145
Validation loss: 2.7492967426054733

Epoch: 6| Step: 6
Training loss: 2.2604281048697734
Validation loss: 2.701658145976911

Epoch: 6| Step: 7
Training loss: 2.460398587756123
Validation loss: 2.6517255784815283

Epoch: 6| Step: 8
Training loss: 2.013959803008681
Validation loss: 2.610454370225897

Epoch: 6| Step: 9
Training loss: 2.778087060452588
Validation loss: 2.590821020988518

Epoch: 6| Step: 10
Training loss: 2.6185749077359457
Validation loss: 2.5908022301450666

Epoch: 6| Step: 11
Training loss: 2.9847774533837574
Validation loss: 2.5781543261419095

Epoch: 6| Step: 12
Training loss: 3.0644976270470106
Validation loss: 2.572765986777484

Epoch: 6| Step: 13
Training loss: 3.22326861487833
Validation loss: 2.5760346202358297

Epoch: 321| Step: 0
Training loss: 2.4050819237093397
Validation loss: 2.5782113526600443

Epoch: 6| Step: 1
Training loss: 2.3504595530392844
Validation loss: 2.573234385708024

Epoch: 6| Step: 2
Training loss: 2.881186256613809
Validation loss: 2.5826181044523815

Epoch: 6| Step: 3
Training loss: 3.100703891703211
Validation loss: 2.5788532321153808

Epoch: 6| Step: 4
Training loss: 2.484548886529638
Validation loss: 2.5626414160195385

Epoch: 6| Step: 5
Training loss: 2.8187599875533285
Validation loss: 2.5806809807414224

Epoch: 6| Step: 6
Training loss: 2.5651188006040107
Validation loss: 2.5558047062443974

Epoch: 6| Step: 7
Training loss: 2.3233342386989206
Validation loss: 2.5717289105141568

Epoch: 6| Step: 8
Training loss: 2.8975628049690716
Validation loss: 2.580925374622756

Epoch: 6| Step: 9
Training loss: 2.3680215002192204
Validation loss: 2.5741120241515203

Epoch: 6| Step: 10
Training loss: 3.3899102226680022
Validation loss: 2.593301480522048

Epoch: 6| Step: 11
Training loss: 2.205604078280636
Validation loss: 2.598530481219057

Epoch: 6| Step: 12
Training loss: 2.5114559908243774
Validation loss: 2.6071423710645067

Epoch: 6| Step: 13
Training loss: 3.0094230798542716
Validation loss: 2.5466900457689836

Epoch: 322| Step: 0
Training loss: 2.8743041481796383
Validation loss: 2.522510949351349

Epoch: 6| Step: 1
Training loss: 2.5445994877764435
Validation loss: 2.521128821659007

Epoch: 6| Step: 2
Training loss: 2.5789173180297276
Validation loss: 2.49544518556474

Epoch: 6| Step: 3
Training loss: 2.7562374123352904
Validation loss: 2.4954979876090877

Epoch: 6| Step: 4
Training loss: 2.2601148225090895
Validation loss: 2.483204895304976

Epoch: 6| Step: 5
Training loss: 2.8555871440593252
Validation loss: 2.4803535520587907

Epoch: 6| Step: 6
Training loss: 3.050119716608601
Validation loss: 2.495651149131646

Epoch: 6| Step: 7
Training loss: 2.931452430616316
Validation loss: 2.5197451575172938

Epoch: 6| Step: 8
Training loss: 2.881991799411053
Validation loss: 2.530763158717303

Epoch: 6| Step: 9
Training loss: 2.0905840266707294
Validation loss: 2.559787967834422

Epoch: 6| Step: 10
Training loss: 2.5166602995667744
Validation loss: 2.5673870962433893

Epoch: 6| Step: 11
Training loss: 2.3246739558827745
Validation loss: 2.550294880201312

Epoch: 6| Step: 12
Training loss: 2.6062030815457
Validation loss: 2.533799235172565

Epoch: 6| Step: 13
Training loss: 3.2521213064149657
Validation loss: 2.536434652468899

Epoch: 323| Step: 0
Training loss: 2.754714912022839
Validation loss: 2.5411489400851446

Epoch: 6| Step: 1
Training loss: 1.6198014957174736
Validation loss: 2.526655127769307

Epoch: 6| Step: 2
Training loss: 2.1764820004574883
Validation loss: 2.526642848588813

Epoch: 6| Step: 3
Training loss: 2.9820384520437986
Validation loss: 2.55055668975635

Epoch: 6| Step: 4
Training loss: 2.443954529459464
Validation loss: 2.544358125725508

Epoch: 6| Step: 5
Training loss: 2.3519155040925925
Validation loss: 2.559348933956258

Epoch: 6| Step: 6
Training loss: 2.430205556707408
Validation loss: 2.5607091747232498

Epoch: 6| Step: 7
Training loss: 3.0443041788477068
Validation loss: 2.5982692136249415

Epoch: 6| Step: 8
Training loss: 3.2738048556736286
Validation loss: 2.615165964854021

Epoch: 6| Step: 9
Training loss: 2.5184911665906373
Validation loss: 2.6307370338692047

Epoch: 6| Step: 10
Training loss: 3.04108822343296
Validation loss: 2.6389273200468644

Epoch: 6| Step: 11
Training loss: 2.495267585058749
Validation loss: 2.649137882946375

Epoch: 6| Step: 12
Training loss: 2.7567852581796783
Validation loss: 2.6260751318526068

Epoch: 6| Step: 13
Training loss: 3.0564932010674237
Validation loss: 2.6171190742972215

Epoch: 324| Step: 0
Training loss: 2.5212848563709205
Validation loss: 2.64390634643509

Epoch: 6| Step: 1
Training loss: 2.757939581604138
Validation loss: 2.6355658673820783

Epoch: 6| Step: 2
Training loss: 3.3390034293276805
Validation loss: 2.6635997537403084

Epoch: 6| Step: 3
Training loss: 2.890979312111493
Validation loss: 2.6198895756448923

Epoch: 6| Step: 4
Training loss: 2.2361490102943127
Validation loss: 2.5902759718011437

Epoch: 6| Step: 5
Training loss: 2.33216691381331
Validation loss: 2.549965584812449

Epoch: 6| Step: 6
Training loss: 2.3603058046286134
Validation loss: 2.544467071852566

Epoch: 6| Step: 7
Training loss: 2.6564714227277673
Validation loss: 2.5563929557767127

Epoch: 6| Step: 8
Training loss: 1.9406302607122548
Validation loss: 2.5732397645733935

Epoch: 6| Step: 9
Training loss: 3.0478729961097524
Validation loss: 2.5523577832401756

Epoch: 6| Step: 10
Training loss: 2.515703662092638
Validation loss: 2.6131231406476507

Epoch: 6| Step: 11
Training loss: 2.784034877772381
Validation loss: 2.608747971270756

Epoch: 6| Step: 12
Training loss: 2.9007480182793812
Validation loss: 2.5918006713027304

Epoch: 6| Step: 13
Training loss: 2.718155806931084
Validation loss: 2.5918571512822886

Epoch: 325| Step: 0
Training loss: 2.8627942596177585
Validation loss: 2.5565751042585982

Epoch: 6| Step: 1
Training loss: 2.546861894257883
Validation loss: 2.5139815788318898

Epoch: 6| Step: 2
Training loss: 2.934056800432893
Validation loss: 2.5025983331049386

Epoch: 6| Step: 3
Training loss: 2.1629994118910583
Validation loss: 2.5041785973934942

Epoch: 6| Step: 4
Training loss: 2.767342589053258
Validation loss: 2.4902063679030024

Epoch: 6| Step: 5
Training loss: 2.36687474970266
Validation loss: 2.493071245196346

Epoch: 6| Step: 6
Training loss: 2.3258443837283176
Validation loss: 2.5084862056964625

Epoch: 6| Step: 7
Training loss: 2.579723440621171
Validation loss: 2.523543532615807

Epoch: 6| Step: 8
Training loss: 2.3044903169752557
Validation loss: 2.5698154174638757

Epoch: 6| Step: 9
Training loss: 2.909788541156908
Validation loss: 2.5824199382280657

Epoch: 6| Step: 10
Training loss: 2.732231040763853
Validation loss: 2.6036298045038513

Epoch: 6| Step: 11
Training loss: 3.0192221894205393
Validation loss: 2.624432918081982

Epoch: 6| Step: 12
Training loss: 2.873534782882835
Validation loss: 2.6723177627609855

Epoch: 6| Step: 13
Training loss: 2.4121192592155785
Validation loss: 2.713568756841877

Epoch: 326| Step: 0
Training loss: 2.4089730448214377
Validation loss: 2.709741125869245

Epoch: 6| Step: 1
Training loss: 2.5458543288576876
Validation loss: 2.7142119127956335

Epoch: 6| Step: 2
Training loss: 2.8378227420046978
Validation loss: 2.706328612901841

Epoch: 6| Step: 3
Training loss: 3.1048626386202187
Validation loss: 2.7176030141352547

Epoch: 6| Step: 4
Training loss: 3.170294607534065
Validation loss: 2.6925738697718153

Epoch: 6| Step: 5
Training loss: 2.3108018362010587
Validation loss: 2.6736435227191206

Epoch: 6| Step: 6
Training loss: 2.336937629654202
Validation loss: 2.6460027145520515

Epoch: 6| Step: 7
Training loss: 2.427824821229766
Validation loss: 2.594920242676894

Epoch: 6| Step: 8
Training loss: 2.9650788747965287
Validation loss: 2.5624293415883597

Epoch: 6| Step: 9
Training loss: 2.4630932282163034
Validation loss: 2.541142657962236

Epoch: 6| Step: 10
Training loss: 2.5321101858140036
Validation loss: 2.534865555639446

Epoch: 6| Step: 11
Training loss: 2.6289920424453026
Validation loss: 2.5207086171400284

Epoch: 6| Step: 12
Training loss: 2.5254502905267953
Validation loss: 2.4992315721361953

Epoch: 6| Step: 13
Training loss: 2.8439173387192134
Validation loss: 2.5104221191946143

Epoch: 327| Step: 0
Training loss: 2.737203214399721
Validation loss: 2.5153514611689123

Epoch: 6| Step: 1
Training loss: 2.609818380913461
Validation loss: 2.536420871181456

Epoch: 6| Step: 2
Training loss: 2.4792178386461288
Validation loss: 2.5493687738166173

Epoch: 6| Step: 3
Training loss: 3.0108098144063153
Validation loss: 2.563300313161504

Epoch: 6| Step: 4
Training loss: 2.571647598762883
Validation loss: 2.5708778583181524

Epoch: 6| Step: 5
Training loss: 2.807120795112977
Validation loss: 2.583324812108599

Epoch: 6| Step: 6
Training loss: 2.4956046566992662
Validation loss: 2.5993748339608005

Epoch: 6| Step: 7
Training loss: 2.1654482374397133
Validation loss: 2.6035418056512123

Epoch: 6| Step: 8
Training loss: 2.846079616213104
Validation loss: 2.6503432245270586

Epoch: 6| Step: 9
Training loss: 2.524140345714414
Validation loss: 2.628181428176588

Epoch: 6| Step: 10
Training loss: 2.731089509137587
Validation loss: 2.5992163703634086

Epoch: 6| Step: 11
Training loss: 2.3437293496811624
Validation loss: 2.5758415762436595

Epoch: 6| Step: 12
Training loss: 2.6403783197694963
Validation loss: 2.575844317197381

Epoch: 6| Step: 13
Training loss: 2.7086037916465506
Validation loss: 2.573554450968299

Epoch: 328| Step: 0
Training loss: 2.8183794238989335
Validation loss: 2.5844726656734256

Epoch: 6| Step: 1
Training loss: 2.375750975085073
Validation loss: 2.5841506054906134

Epoch: 6| Step: 2
Training loss: 2.5822259826636422
Validation loss: 2.5751619476627434

Epoch: 6| Step: 3
Training loss: 2.6029692274656844
Validation loss: 2.576390183598489

Epoch: 6| Step: 4
Training loss: 2.068080634767865
Validation loss: 2.584134495326616

Epoch: 6| Step: 5
Training loss: 2.5883581351004676
Validation loss: 2.6218069729260565

Epoch: 6| Step: 6
Training loss: 2.467903668160454
Validation loss: 2.660173103448144

Epoch: 6| Step: 7
Training loss: 2.6617722497237466
Validation loss: 2.696900042252667

Epoch: 6| Step: 8
Training loss: 2.681662140584208
Validation loss: 2.6859807849912922

Epoch: 6| Step: 9
Training loss: 2.4715242853223662
Validation loss: 2.6710378489998963

Epoch: 6| Step: 10
Training loss: 2.23919158584742
Validation loss: 2.6221956351236893

Epoch: 6| Step: 11
Training loss: 2.7362383787588875
Validation loss: 2.5989862144145737

Epoch: 6| Step: 12
Training loss: 3.051196979716846
Validation loss: 2.5772607960216396

Epoch: 6| Step: 13
Training loss: 3.016837869356003
Validation loss: 2.5795669023728167

Epoch: 329| Step: 0
Training loss: 2.4440704213687
Validation loss: 2.5536604072843425

Epoch: 6| Step: 1
Training loss: 2.3446848721434193
Validation loss: 2.534927070361312

Epoch: 6| Step: 2
Training loss: 2.763688783627604
Validation loss: 2.518610143181979

Epoch: 6| Step: 3
Training loss: 2.4647365734176896
Validation loss: 2.530585745335895

Epoch: 6| Step: 4
Training loss: 2.9954316005598947
Validation loss: 2.5294838287047594

Epoch: 6| Step: 5
Training loss: 2.307908732707136
Validation loss: 2.557154274059538

Epoch: 6| Step: 6
Training loss: 2.6071477281558524
Validation loss: 2.5684520856766406

Epoch: 6| Step: 7
Training loss: 3.20181173059165
Validation loss: 2.5761970309128657

Epoch: 6| Step: 8
Training loss: 2.851592264934552
Validation loss: 2.572679838975577

Epoch: 6| Step: 9
Training loss: 2.3693154216290386
Validation loss: 2.546820279556558

Epoch: 6| Step: 10
Training loss: 2.5357504502448083
Validation loss: 2.526578952663366

Epoch: 6| Step: 11
Training loss: 2.5000879272257333
Validation loss: 2.5164298327574612

Epoch: 6| Step: 12
Training loss: 2.2325704263170683
Validation loss: 2.520865684660341

Epoch: 6| Step: 13
Training loss: 2.8407026458636597
Validation loss: 2.517895125137846

Epoch: 330| Step: 0
Training loss: 2.179517951305067
Validation loss: 2.5320292288385216

Epoch: 6| Step: 1
Training loss: 2.3660001389284973
Validation loss: 2.5570499710368138

Epoch: 6| Step: 2
Training loss: 1.9626789035769816
Validation loss: 2.618617471320478

Epoch: 6| Step: 3
Training loss: 2.75198708615489
Validation loss: 2.6311485651149633

Epoch: 6| Step: 4
Training loss: 2.385125110471679
Validation loss: 2.67641529666709

Epoch: 6| Step: 5
Training loss: 3.106801103485489
Validation loss: 2.7181063927360944

Epoch: 6| Step: 6
Training loss: 2.6775197862024047
Validation loss: 2.6678810014514247

Epoch: 6| Step: 7
Training loss: 2.623390703539362
Validation loss: 2.59197861848515

Epoch: 6| Step: 8
Training loss: 2.6784140894864485
Validation loss: 2.5662444084835463

Epoch: 6| Step: 9
Training loss: 2.4634118613844933
Validation loss: 2.5042693896553962

Epoch: 6| Step: 10
Training loss: 2.6346160416385405
Validation loss: 2.5081384770435404

Epoch: 6| Step: 11
Training loss: 2.1441260894877594
Validation loss: 2.484818609660754

Epoch: 6| Step: 12
Training loss: 3.1421911784965726
Validation loss: 2.468523289509947

Epoch: 6| Step: 13
Training loss: 3.0226901606838763
Validation loss: 2.47633059550573

Epoch: 331| Step: 0
Training loss: 2.7586117199636844
Validation loss: 2.4818433132876825

Epoch: 6| Step: 1
Training loss: 2.7768445216808795
Validation loss: 2.49528063096368

Epoch: 6| Step: 2
Training loss: 2.7606045257175302
Validation loss: 2.5276726516012085

Epoch: 6| Step: 3
Training loss: 2.579582865653419
Validation loss: 2.5894044841281665

Epoch: 6| Step: 4
Training loss: 1.6555623480353803
Validation loss: 2.655753238946651

Epoch: 6| Step: 5
Training loss: 2.4022222720810875
Validation loss: 2.731399647147093

Epoch: 6| Step: 6
Training loss: 2.020175971118523
Validation loss: 2.7674788994661927

Epoch: 6| Step: 7
Training loss: 3.3284020823441582
Validation loss: 2.76650749037254

Epoch: 6| Step: 8
Training loss: 2.607928851842157
Validation loss: 2.7629221292118955

Epoch: 6| Step: 9
Training loss: 2.548185046688236
Validation loss: 2.7000736690635927

Epoch: 6| Step: 10
Training loss: 3.01173379105153
Validation loss: 2.6553279929320532

Epoch: 6| Step: 11
Training loss: 2.5141345045211345
Validation loss: 2.6195644153782007

Epoch: 6| Step: 12
Training loss: 2.966243127171093
Validation loss: 2.565545239756992

Epoch: 6| Step: 13
Training loss: 2.170778066135401
Validation loss: 2.5339716827037733

Epoch: 332| Step: 0
Training loss: 2.9710421096041393
Validation loss: 2.5030928113331625

Epoch: 6| Step: 1
Training loss: 3.157779587352836
Validation loss: 2.4823653599215088

Epoch: 6| Step: 2
Training loss: 2.091778182543699
Validation loss: 2.481044760736824

Epoch: 6| Step: 3
Training loss: 2.6270241880199996
Validation loss: 2.4845361918503395

Epoch: 6| Step: 4
Training loss: 2.8362900696063784
Validation loss: 2.4911907243446665

Epoch: 6| Step: 5
Training loss: 2.9819009322168406
Validation loss: 2.500926431641634

Epoch: 6| Step: 6
Training loss: 2.289818960971246
Validation loss: 2.5227271904892072

Epoch: 6| Step: 7
Training loss: 2.36075677893232
Validation loss: 2.5586266515601994

Epoch: 6| Step: 8
Training loss: 2.7751315248954866
Validation loss: 2.5852633943015793

Epoch: 6| Step: 9
Training loss: 2.402978134131989
Validation loss: 2.6071657581092937

Epoch: 6| Step: 10
Training loss: 2.080835854505
Validation loss: 2.6163473084352535

Epoch: 6| Step: 11
Training loss: 2.795894514874562
Validation loss: 2.6115848163127837

Epoch: 6| Step: 12
Training loss: 2.33230860097603
Validation loss: 2.5847883569427714

Epoch: 6| Step: 13
Training loss: 2.43263806334504
Validation loss: 2.5736909016705574

Epoch: 333| Step: 0
Training loss: 1.7406575280374168
Validation loss: 2.53250752796906

Epoch: 6| Step: 1
Training loss: 2.931056971589451
Validation loss: 2.50724047423631

Epoch: 6| Step: 2
Training loss: 2.297613012379801
Validation loss: 2.4998538333453255

Epoch: 6| Step: 3
Training loss: 2.582385617406848
Validation loss: 2.485760685758931

Epoch: 6| Step: 4
Training loss: 2.566000617499214
Validation loss: 2.4702325919806607

Epoch: 6| Step: 5
Training loss: 2.3017977944528165
Validation loss: 2.466270835426753

Epoch: 6| Step: 6
Training loss: 3.0706883168928027
Validation loss: 2.474146253684062

Epoch: 6| Step: 7
Training loss: 3.372503416881145
Validation loss: 2.4740029003401434

Epoch: 6| Step: 8
Training loss: 2.1447951635622773
Validation loss: 2.489271209162846

Epoch: 6| Step: 9
Training loss: 2.8508470447711964
Validation loss: 2.481691715830267

Epoch: 6| Step: 10
Training loss: 2.4404697422558246
Validation loss: 2.5138051155732475

Epoch: 6| Step: 11
Training loss: 2.004466077152608
Validation loss: 2.569467228466308

Epoch: 6| Step: 12
Training loss: 2.943655342151398
Validation loss: 2.619634002447248

Epoch: 6| Step: 13
Training loss: 2.7054689861741434
Validation loss: 2.632016262344069

Epoch: 334| Step: 0
Training loss: 2.7105359046583195
Validation loss: 2.672220657385469

Epoch: 6| Step: 1
Training loss: 2.351425724550923
Validation loss: 2.6769850134954796

Epoch: 6| Step: 2
Training loss: 2.5289209270552235
Validation loss: 2.6884473317198787

Epoch: 6| Step: 3
Training loss: 3.0504048563424586
Validation loss: 2.7077793138405113

Epoch: 6| Step: 4
Training loss: 3.0347747759387067
Validation loss: 2.6234180871703474

Epoch: 6| Step: 5
Training loss: 2.7210452158408525
Validation loss: 2.582609499635497

Epoch: 6| Step: 6
Training loss: 2.7948973072819605
Validation loss: 2.534004625741109

Epoch: 6| Step: 7
Training loss: 1.9716454059403652
Validation loss: 2.496901123570615

Epoch: 6| Step: 8
Training loss: 2.399407007550933
Validation loss: 2.474462625414483

Epoch: 6| Step: 9
Training loss: 2.4239081923595607
Validation loss: 2.4639474478693417

Epoch: 6| Step: 10
Training loss: 2.410241816406791
Validation loss: 2.4714619746265574

Epoch: 6| Step: 11
Training loss: 2.8264968147469074
Validation loss: 2.4598853515092642

Epoch: 6| Step: 12
Training loss: 2.3329021418748908
Validation loss: 2.479298269022968

Epoch: 6| Step: 13
Training loss: 2.8163949910651773
Validation loss: 2.512091043088128

Epoch: 335| Step: 0
Training loss: 2.621915549145431
Validation loss: 2.528897661866269

Epoch: 6| Step: 1
Training loss: 2.5896467361197177
Validation loss: 2.5460204822304218

Epoch: 6| Step: 2
Training loss: 2.662291175640644
Validation loss: 2.5705132786121987

Epoch: 6| Step: 3
Training loss: 1.400028240395866
Validation loss: 2.567014353865176

Epoch: 6| Step: 4
Training loss: 2.758914543606478
Validation loss: 2.5998958752956325

Epoch: 6| Step: 5
Training loss: 2.787741211859619
Validation loss: 2.5906357911518

Epoch: 6| Step: 6
Training loss: 3.1326622677214915
Validation loss: 2.609531972858719

Epoch: 6| Step: 7
Training loss: 2.713238973203062
Validation loss: 2.6124611281085675

Epoch: 6| Step: 8
Training loss: 2.4251352331463605
Validation loss: 2.626026133678112

Epoch: 6| Step: 9
Training loss: 2.4394147150636547
Validation loss: 2.6169135101946557

Epoch: 6| Step: 10
Training loss: 1.8549134397232574
Validation loss: 2.6120755115656964

Epoch: 6| Step: 11
Training loss: 2.6477570236267054
Validation loss: 2.639609991085766

Epoch: 6| Step: 12
Training loss: 2.6045457386051187
Validation loss: 2.625626676245164

Epoch: 6| Step: 13
Training loss: 2.6585610602087275
Validation loss: 2.5901810670716756

Epoch: 336| Step: 0
Training loss: 2.8293085308959305
Validation loss: 2.5579163419293223

Epoch: 6| Step: 1
Training loss: 2.3109985838703753
Validation loss: 2.5466836655757095

Epoch: 6| Step: 2
Training loss: 2.4931097446834634
Validation loss: 2.542386107661509

Epoch: 6| Step: 3
Training loss: 2.114683352455479
Validation loss: 2.5409844668290766

Epoch: 6| Step: 4
Training loss: 1.870534920911754
Validation loss: 2.5390452243163577

Epoch: 6| Step: 5
Training loss: 2.8585130403337
Validation loss: 2.5382608389740535

Epoch: 6| Step: 6
Training loss: 2.474901864003944
Validation loss: 2.5387064426813413

Epoch: 6| Step: 7
Training loss: 3.05651317001643
Validation loss: 2.556364620513374

Epoch: 6| Step: 8
Training loss: 2.5937265601879966
Validation loss: 2.573868043101201

Epoch: 6| Step: 9
Training loss: 2.7467350217807156
Validation loss: 2.574404466966252

Epoch: 6| Step: 10
Training loss: 2.1030987084659793
Validation loss: 2.5636232016910574

Epoch: 6| Step: 11
Training loss: 2.2545572329168766
Validation loss: 2.562374046865849

Epoch: 6| Step: 12
Training loss: 2.9250650382350942
Validation loss: 2.5964285438256827

Epoch: 6| Step: 13
Training loss: 2.842012985768942
Validation loss: 2.568113637536637

Epoch: 337| Step: 0
Training loss: 2.356090760858095
Validation loss: 2.5310326567364987

Epoch: 6| Step: 1
Training loss: 2.178326800725005
Validation loss: 2.4916945749299497

Epoch: 6| Step: 2
Training loss: 2.4882580622815786
Validation loss: 2.50028496420486

Epoch: 6| Step: 3
Training loss: 2.1596402039921982
Validation loss: 2.475357327106885

Epoch: 6| Step: 4
Training loss: 2.910074486319925
Validation loss: 2.477158297994756

Epoch: 6| Step: 5
Training loss: 3.0340358870715565
Validation loss: 2.4656795287780717

Epoch: 6| Step: 6
Training loss: 2.293903530709852
Validation loss: 2.4843156389174634

Epoch: 6| Step: 7
Training loss: 1.9017519803960203
Validation loss: 2.5361085935162926

Epoch: 6| Step: 8
Training loss: 2.6953849451031697
Validation loss: 2.591315013952262

Epoch: 6| Step: 9
Training loss: 2.750830438245074
Validation loss: 2.6212093017932663

Epoch: 6| Step: 10
Training loss: 2.420504372898337
Validation loss: 2.662170287638476

Epoch: 6| Step: 11
Training loss: 2.6220007519579056
Validation loss: 2.664902184706484

Epoch: 6| Step: 12
Training loss: 3.0077681104679024
Validation loss: 2.60998059685598

Epoch: 6| Step: 13
Training loss: 2.86544439148083
Validation loss: 2.600819760156801

Epoch: 338| Step: 0
Training loss: 2.7772658883084227
Validation loss: 2.6267321292562618

Epoch: 6| Step: 1
Training loss: 2.866510212495299
Validation loss: 2.5805674270104912

Epoch: 6| Step: 2
Training loss: 2.699134836396891
Validation loss: 2.5539080127527325

Epoch: 6| Step: 3
Training loss: 2.428958893969544
Validation loss: 2.5253610840735043

Epoch: 6| Step: 4
Training loss: 2.5472540076086965
Validation loss: 2.497810564835287

Epoch: 6| Step: 5
Training loss: 2.7450087073627496
Validation loss: 2.488867967695773

Epoch: 6| Step: 6
Training loss: 2.222235078244639
Validation loss: 2.493794043795016

Epoch: 6| Step: 7
Training loss: 2.7515114185415888
Validation loss: 2.499006149698383

Epoch: 6| Step: 8
Training loss: 2.528185178137154
Validation loss: 2.5507606053620506

Epoch: 6| Step: 9
Training loss: 2.1917704723224842
Validation loss: 2.615059021033699

Epoch: 6| Step: 10
Training loss: 2.791796287450092
Validation loss: 2.642474540398194

Epoch: 6| Step: 11
Training loss: 2.5184838772034825
Validation loss: 2.647359360625636

Epoch: 6| Step: 12
Training loss: 2.567148690560128
Validation loss: 2.6227965563159477

Epoch: 6| Step: 13
Training loss: 2.5714700521423426
Validation loss: 2.6024429490393763

Epoch: 339| Step: 0
Training loss: 2.6062343679274904
Validation loss: 2.5530306156533618

Epoch: 6| Step: 1
Training loss: 2.7983164562498732
Validation loss: 2.541306270571588

Epoch: 6| Step: 2
Training loss: 2.6677909110407696
Validation loss: 2.5105166702323367

Epoch: 6| Step: 3
Training loss: 2.28468711797716
Validation loss: 2.487958264343327

Epoch: 6| Step: 4
Training loss: 2.790883727857876
Validation loss: 2.4798504510403636

Epoch: 6| Step: 5
Training loss: 2.66470731835004
Validation loss: 2.4748602636986097

Epoch: 6| Step: 6
Training loss: 2.1698300181671506
Validation loss: 2.4659008305465555

Epoch: 6| Step: 7
Training loss: 2.4752469103406387
Validation loss: 2.4852956390874477

Epoch: 6| Step: 8
Training loss: 2.5015870778712874
Validation loss: 2.4833862933584396

Epoch: 6| Step: 9
Training loss: 2.213870418295503
Validation loss: 2.502425924113693

Epoch: 6| Step: 10
Training loss: 2.9323368554616853
Validation loss: 2.503214376567213

Epoch: 6| Step: 11
Training loss: 2.479300444597241
Validation loss: 2.5144500240617065

Epoch: 6| Step: 12
Training loss: 2.32469282684762
Validation loss: 2.539875535813414

Epoch: 6| Step: 13
Training loss: 2.8153399222595934
Validation loss: 2.600649025545265

Epoch: 340| Step: 0
Training loss: 1.6842526166685212
Validation loss: 2.6125689024508048

Epoch: 6| Step: 1
Training loss: 2.3529555544694407
Validation loss: 2.5749042448579984

Epoch: 6| Step: 2
Training loss: 2.5795006983017204
Validation loss: 2.5754420286452144

Epoch: 6| Step: 3
Training loss: 2.38717941608401
Validation loss: 2.5527787574278995

Epoch: 6| Step: 4
Training loss: 2.2479626650577744
Validation loss: 2.5492937389975143

Epoch: 6| Step: 5
Training loss: 2.6928133227738966
Validation loss: 2.533757184345842

Epoch: 6| Step: 6
Training loss: 2.6851690962980546
Validation loss: 2.5239215471536443

Epoch: 6| Step: 7
Training loss: 2.4001313729887745
Validation loss: 2.5173305914620845

Epoch: 6| Step: 8
Training loss: 2.795197308695283
Validation loss: 2.5303336910248126

Epoch: 6| Step: 9
Training loss: 2.810031570583032
Validation loss: 2.534984360387122

Epoch: 6| Step: 10
Training loss: 3.1971370645541457
Validation loss: 2.5458852451658167

Epoch: 6| Step: 11
Training loss: 2.591884815647294
Validation loss: 2.5597924105070704

Epoch: 6| Step: 12
Training loss: 2.5145232826864743
Validation loss: 2.5378043228616245

Epoch: 6| Step: 13
Training loss: 2.153625549688307
Validation loss: 2.5239201474675963

Epoch: 341| Step: 0
Training loss: 2.160335485048326
Validation loss: 2.492312687127001

Epoch: 6| Step: 1
Training loss: 2.7138642005313716
Validation loss: 2.5306075605221996

Epoch: 6| Step: 2
Training loss: 2.687400816040869
Validation loss: 2.5225384646444096

Epoch: 6| Step: 3
Training loss: 2.667520108348273
Validation loss: 2.528459841044702

Epoch: 6| Step: 4
Training loss: 2.7960167958706057
Validation loss: 2.524971905428859

Epoch: 6| Step: 5
Training loss: 2.3963513574471134
Validation loss: 2.5423474438173206

Epoch: 6| Step: 6
Training loss: 2.3925292963767437
Validation loss: 2.5333839373669793

Epoch: 6| Step: 7
Training loss: 2.0813570058080426
Validation loss: 2.5552279414464976

Epoch: 6| Step: 8
Training loss: 2.393775210733348
Validation loss: 2.5868945079469734

Epoch: 6| Step: 9
Training loss: 2.6575169851454703
Validation loss: 2.596103065893226

Epoch: 6| Step: 10
Training loss: 2.5579678534306427
Validation loss: 2.6068951899978825

Epoch: 6| Step: 11
Training loss: 2.645533226795148
Validation loss: 2.616024911422257

Epoch: 6| Step: 12
Training loss: 2.1919771426603227
Validation loss: 2.6201276460780334

Epoch: 6| Step: 13
Training loss: 2.8389211045254017
Validation loss: 2.609247483670991

Epoch: 342| Step: 0
Training loss: 2.0977339916634503
Validation loss: 2.599312381712536

Epoch: 6| Step: 1
Training loss: 2.7185249673953797
Validation loss: 2.605989525187186

Epoch: 6| Step: 2
Training loss: 2.4473203757966693
Validation loss: 2.608996181979868

Epoch: 6| Step: 3
Training loss: 2.7836486245698433
Validation loss: 2.607533840436142

Epoch: 6| Step: 4
Training loss: 1.7885550899664708
Validation loss: 2.5738899197330567

Epoch: 6| Step: 5
Training loss: 2.6528862691888953
Validation loss: 2.5713605183211516

Epoch: 6| Step: 6
Training loss: 2.1417799013040257
Validation loss: 2.532553189075453

Epoch: 6| Step: 7
Training loss: 2.353299636743662
Validation loss: 2.534001198115027

Epoch: 6| Step: 8
Training loss: 2.6037157100593404
Validation loss: 2.5301975800511287

Epoch: 6| Step: 9
Training loss: 2.717952479757595
Validation loss: 2.5128497937362675

Epoch: 6| Step: 10
Training loss: 2.596991937347928
Validation loss: 2.5232139993089304

Epoch: 6| Step: 11
Training loss: 2.6653505494842027
Validation loss: 2.536816591245665

Epoch: 6| Step: 12
Training loss: 2.791110785258869
Validation loss: 2.5632231957643064

Epoch: 6| Step: 13
Training loss: 2.543764332723893
Validation loss: 2.5820075399773352

Epoch: 343| Step: 0
Training loss: 2.6661506590688058
Validation loss: 2.592721535777487

Epoch: 6| Step: 1
Training loss: 2.224610018039306
Validation loss: 2.5957557285672745

Epoch: 6| Step: 2
Training loss: 2.062702400217737
Validation loss: 2.6127096817474675

Epoch: 6| Step: 3
Training loss: 2.8068674270639846
Validation loss: 2.6213994527447553

Epoch: 6| Step: 4
Training loss: 2.2964823899809628
Validation loss: 2.6084884327218827

Epoch: 6| Step: 5
Training loss: 2.724377475290209
Validation loss: 2.6114339522726717

Epoch: 6| Step: 6
Training loss: 2.6050043106775624
Validation loss: 2.5731847420058473

Epoch: 6| Step: 7
Training loss: 2.625666397520236
Validation loss: 2.5577625839958835

Epoch: 6| Step: 8
Training loss: 2.2933652882604525
Validation loss: 2.5565251851929625

Epoch: 6| Step: 9
Training loss: 2.2642807754593393
Validation loss: 2.557579083689334

Epoch: 6| Step: 10
Training loss: 2.6397327969894895
Validation loss: 2.5804422484630103

Epoch: 6| Step: 11
Training loss: 1.6828391382062444
Validation loss: 2.570569168173473

Epoch: 6| Step: 12
Training loss: 3.204295470216381
Validation loss: 2.6011923190610924

Epoch: 6| Step: 13
Training loss: 2.9606400393232284
Validation loss: 2.595490280135032

Epoch: 344| Step: 0
Training loss: 2.0953917258672097
Validation loss: 2.5997458791665133

Epoch: 6| Step: 1
Training loss: 2.4722004209645374
Validation loss: 2.5632602865355127

Epoch: 6| Step: 2
Training loss: 2.0394875971217568
Validation loss: 2.5835987927864443

Epoch: 6| Step: 3
Training loss: 2.157972670458955
Validation loss: 2.526900607540085

Epoch: 6| Step: 4
Training loss: 2.601454907274489
Validation loss: 2.5094960364102374

Epoch: 6| Step: 5
Training loss: 2.5594976561130016
Validation loss: 2.49155988855077

Epoch: 6| Step: 6
Training loss: 2.566936560060502
Validation loss: 2.481393899586088

Epoch: 6| Step: 7
Training loss: 2.6760801719151344
Validation loss: 2.4631051612070447

Epoch: 6| Step: 8
Training loss: 2.9241767833408248
Validation loss: 2.452008013127343

Epoch: 6| Step: 9
Training loss: 2.565802702052396
Validation loss: 2.4552066285188974

Epoch: 6| Step: 10
Training loss: 2.003647458504108
Validation loss: 2.44164210470293

Epoch: 6| Step: 11
Training loss: 2.574915141957352
Validation loss: 2.465036766137321

Epoch: 6| Step: 12
Training loss: 2.7198681340790336
Validation loss: 2.4825564819522365

Epoch: 6| Step: 13
Training loss: 3.211124758121247
Validation loss: 2.5071737044292965

Epoch: 345| Step: 0
Training loss: 2.34558664202614
Validation loss: 2.545633337111963

Epoch: 6| Step: 1
Training loss: 2.6811994285527114
Validation loss: 2.5480529916582704

Epoch: 6| Step: 2
Training loss: 2.6523279293526696
Validation loss: 2.5328103961399266

Epoch: 6| Step: 3
Training loss: 2.1594515266604373
Validation loss: 2.534368126080495

Epoch: 6| Step: 4
Training loss: 2.137070203257231
Validation loss: 2.544713814374963

Epoch: 6| Step: 5
Training loss: 2.19283689966173
Validation loss: 2.5597207995132045

Epoch: 6| Step: 6
Training loss: 2.6190823655899296
Validation loss: 2.5898314130668005

Epoch: 6| Step: 7
Training loss: 2.7166926174055503
Validation loss: 2.6077005094065093

Epoch: 6| Step: 8
Training loss: 2.840549218706059
Validation loss: 2.6233870008346103

Epoch: 6| Step: 9
Training loss: 2.9798136899939225
Validation loss: 2.574790970039614

Epoch: 6| Step: 10
Training loss: 1.6945295503571756
Validation loss: 2.6058615037817523

Epoch: 6| Step: 11
Training loss: 2.503349730348623
Validation loss: 2.5954681158988153

Epoch: 6| Step: 12
Training loss: 2.6233079088749047
Validation loss: 2.5692409228208346

Epoch: 6| Step: 13
Training loss: 2.1739530433209016
Validation loss: 2.5670122506321413

Epoch: 346| Step: 0
Training loss: 2.695293924018868
Validation loss: 2.5402288224588063

Epoch: 6| Step: 1
Training loss: 1.9149946161896645
Validation loss: 2.5165424715867672

Epoch: 6| Step: 2
Training loss: 2.585740557313577
Validation loss: 2.5256988401008167

Epoch: 6| Step: 3
Training loss: 2.3791895605300772
Validation loss: 2.506815535351604

Epoch: 6| Step: 4
Training loss: 3.232313300668987
Validation loss: 2.509367334979909

Epoch: 6| Step: 5
Training loss: 2.549380328113686
Validation loss: 2.498621761694053

Epoch: 6| Step: 6
Training loss: 2.317134028799775
Validation loss: 2.506748576276889

Epoch: 6| Step: 7
Training loss: 2.220319595701408
Validation loss: 2.5383572465874438

Epoch: 6| Step: 8
Training loss: 2.3337138637693395
Validation loss: 2.6108006151872467

Epoch: 6| Step: 9
Training loss: 2.7745866141123483
Validation loss: 2.626801136062013

Epoch: 6| Step: 10
Training loss: 2.525727074818205
Validation loss: 2.663360012307952

Epoch: 6| Step: 11
Training loss: 2.3764351975594584
Validation loss: 2.633850535683561

Epoch: 6| Step: 12
Training loss: 1.845026382629825
Validation loss: 2.527579148037171

Epoch: 6| Step: 13
Training loss: 2.927770694560829
Validation loss: 2.4971977464226685

Epoch: 347| Step: 0
Training loss: 2.316960131859094
Validation loss: 2.460810078129734

Epoch: 6| Step: 1
Training loss: 2.822454341927973
Validation loss: 2.465608019280145

Epoch: 6| Step: 2
Training loss: 2.799355371384686
Validation loss: 2.4580469779842136

Epoch: 6| Step: 3
Training loss: 2.8115227590959586
Validation loss: 2.49192458049267

Epoch: 6| Step: 4
Training loss: 2.3257309041646295
Validation loss: 2.476180585208486

Epoch: 6| Step: 5
Training loss: 2.955289985641165
Validation loss: 2.4966923130824994

Epoch: 6| Step: 6
Training loss: 1.690833860459613
Validation loss: 2.51582119512368

Epoch: 6| Step: 7
Training loss: 2.2887256361426593
Validation loss: 2.5572937260994486

Epoch: 6| Step: 8
Training loss: 2.3557315002965127
Validation loss: 2.5581579460167765

Epoch: 6| Step: 9
Training loss: 2.907094033026436
Validation loss: 2.5893014633869273

Epoch: 6| Step: 10
Training loss: 2.0777888205377044
Validation loss: 2.572277277769498

Epoch: 6| Step: 11
Training loss: 2.1974344553193856
Validation loss: 2.5141432024713652

Epoch: 6| Step: 12
Training loss: 2.354813365951611
Validation loss: 2.494668370809451

Epoch: 6| Step: 13
Training loss: 2.4338141719623994
Validation loss: 2.5000113599785743

Epoch: 348| Step: 0
Training loss: 2.5507947094782724
Validation loss: 2.5169739522636343

Epoch: 6| Step: 1
Training loss: 2.5834331083000843
Validation loss: 2.5139129546267567

Epoch: 6| Step: 2
Training loss: 3.071451611606702
Validation loss: 2.5444891589476257

Epoch: 6| Step: 3
Training loss: 2.5765269557520725
Validation loss: 2.5266851547917217

Epoch: 6| Step: 4
Training loss: 2.6453663171024453
Validation loss: 2.5774906823697514

Epoch: 6| Step: 5
Training loss: 1.9490025463488851
Validation loss: 2.574469844634634

Epoch: 6| Step: 6
Training loss: 2.3380862148629857
Validation loss: 2.5878915403414386

Epoch: 6| Step: 7
Training loss: 2.291565239713626
Validation loss: 2.5940160613647234

Epoch: 6| Step: 8
Training loss: 2.6057845214559707
Validation loss: 2.560729837267098

Epoch: 6| Step: 9
Training loss: 1.8757822312396564
Validation loss: 2.547376225906985

Epoch: 6| Step: 10
Training loss: 1.9341350992112036
Validation loss: 2.5409473475185207

Epoch: 6| Step: 11
Training loss: 2.490380950802678
Validation loss: 2.5424967031969428

Epoch: 6| Step: 12
Training loss: 2.341045192186155
Validation loss: 2.5550136001161055

Epoch: 6| Step: 13
Training loss: 2.915696573145572
Validation loss: 2.5400434973243637

Epoch: 349| Step: 0
Training loss: 1.9645009282110657
Validation loss: 2.509441069917743

Epoch: 6| Step: 1
Training loss: 2.1505976134698597
Validation loss: 2.537293267518575

Epoch: 6| Step: 2
Training loss: 2.256711803738044
Validation loss: 2.5260621290241834

Epoch: 6| Step: 3
Training loss: 2.013683714956705
Validation loss: 2.5391560723895257

Epoch: 6| Step: 4
Training loss: 3.027538426200259
Validation loss: 2.5491174584182064

Epoch: 6| Step: 5
Training loss: 2.9664651209344606
Validation loss: 2.5732474517783985

Epoch: 6| Step: 6
Training loss: 1.9146540759123343
Validation loss: 2.5766052002565143

Epoch: 6| Step: 7
Training loss: 2.7670353456148398
Validation loss: 2.5817857404395075

Epoch: 6| Step: 8
Training loss: 2.5243325550490026
Validation loss: 2.5721205250610018

Epoch: 6| Step: 9
Training loss: 2.538235479795189
Validation loss: 2.5340081798242964

Epoch: 6| Step: 10
Training loss: 2.378128099878123
Validation loss: 2.5324324470798127

Epoch: 6| Step: 11
Training loss: 2.7248303176826174
Validation loss: 2.501572736699555

Epoch: 6| Step: 12
Training loss: 1.9725987189939969
Validation loss: 2.503261657567426

Epoch: 6| Step: 13
Training loss: 2.5111579802967507
Validation loss: 2.4809269379931362

Epoch: 350| Step: 0
Training loss: 2.412065686281981
Validation loss: 2.4978673401019766

Epoch: 6| Step: 1
Training loss: 2.236538992855913
Validation loss: 2.5321018512934277

Epoch: 6| Step: 2
Training loss: 1.7991685907525286
Validation loss: 2.5574040789293497

Epoch: 6| Step: 3
Training loss: 2.280169191775325
Validation loss: 2.6293254369926324

Epoch: 6| Step: 4
Training loss: 2.8103444634266443
Validation loss: 2.6485684057237524

Epoch: 6| Step: 5
Training loss: 2.7153796648149546
Validation loss: 2.5989207738257267

Epoch: 6| Step: 6
Training loss: 2.1429898084717687
Validation loss: 2.540574277970291

Epoch: 6| Step: 7
Training loss: 2.117769843948694
Validation loss: 2.5066969250169153

Epoch: 6| Step: 8
Training loss: 2.484071821031396
Validation loss: 2.4901743418313593

Epoch: 6| Step: 9
Training loss: 2.2383335500202466
Validation loss: 2.4625974277020317

Epoch: 6| Step: 10
Training loss: 2.8889273942516818
Validation loss: 2.4608228733278303

Epoch: 6| Step: 11
Training loss: 2.633710849436578
Validation loss: 2.4348566495778226

Epoch: 6| Step: 12
Training loss: 2.6300669314204193
Validation loss: 2.4461530802574663

Epoch: 6| Step: 13
Training loss: 2.587897995272524
Validation loss: 2.4544392154790127

Epoch: 351| Step: 0
Training loss: 2.7422483605915406
Validation loss: 2.4867042956988

Epoch: 6| Step: 1
Training loss: 2.8440595185910027
Validation loss: 2.500230485279389

Epoch: 6| Step: 2
Training loss: 2.541205901191593
Validation loss: 2.5171264914397393

Epoch: 6| Step: 3
Training loss: 2.58889103968053
Validation loss: 2.5170143717117663

Epoch: 6| Step: 4
Training loss: 1.6710872041878138
Validation loss: 2.53455415749998

Epoch: 6| Step: 5
Training loss: 2.6468666842171245
Validation loss: 2.558498492702935

Epoch: 6| Step: 6
Training loss: 1.9354295435197524
Validation loss: 2.570030117347629

Epoch: 6| Step: 7
Training loss: 2.243349418903665
Validation loss: 2.5309334378109822

Epoch: 6| Step: 8
Training loss: 2.3023622323735373
Validation loss: 2.5421504913963506

Epoch: 6| Step: 9
Training loss: 2.536493498279699
Validation loss: 2.5391468210157355

Epoch: 6| Step: 10
Training loss: 2.4530820417591164
Validation loss: 2.525440216434066

Epoch: 6| Step: 11
Training loss: 2.287566024577865
Validation loss: 2.5296882623363524

Epoch: 6| Step: 12
Training loss: 2.3893548920005077
Validation loss: 2.5159895183206586

Epoch: 6| Step: 13
Training loss: 2.153633409777183
Validation loss: 2.513275755501843

Epoch: 352| Step: 0
Training loss: 2.1002801435805067
Validation loss: 2.551748497305885

Epoch: 6| Step: 1
Training loss: 2.456072840234855
Validation loss: 2.5902105229564776

Epoch: 6| Step: 2
Training loss: 2.5945968164775977
Validation loss: 2.644660838806018

Epoch: 6| Step: 3
Training loss: 2.62375211572948
Validation loss: 2.620312035625427

Epoch: 6| Step: 4
Training loss: 2.8747336222766537
Validation loss: 2.568039749889932

Epoch: 6| Step: 5
Training loss: 2.7498904119677263
Validation loss: 2.4911140400571217

Epoch: 6| Step: 6
Training loss: 2.3187013934611276
Validation loss: 2.472985082267874

Epoch: 6| Step: 7
Training loss: 2.6083253131129713
Validation loss: 2.442531777057411

Epoch: 6| Step: 8
Training loss: 2.4365968253602133
Validation loss: 2.4141231616457133

Epoch: 6| Step: 9
Training loss: 2.121586245410803
Validation loss: 2.4228863274743477

Epoch: 6| Step: 10
Training loss: 2.6847381594832207
Validation loss: 2.4111518100717486

Epoch: 6| Step: 11
Training loss: 1.5703471165727405
Validation loss: 2.4168160837536434

Epoch: 6| Step: 12
Training loss: 2.238834865203305
Validation loss: 2.4589282314192125

Epoch: 6| Step: 13
Training loss: 2.35981817062266
Validation loss: 2.4845382968004297

Epoch: 353| Step: 0
Training loss: 2.1504391864833527
Validation loss: 2.5116202573175817

Epoch: 6| Step: 1
Training loss: 2.6476323977353045
Validation loss: 2.571147068196839

Epoch: 6| Step: 2
Training loss: 1.954951904368692
Validation loss: 2.586592229982143

Epoch: 6| Step: 3
Training loss: 3.1376881698778805
Validation loss: 2.614739912464739

Epoch: 6| Step: 4
Training loss: 1.5488018019220415
Validation loss: 2.581326943687632

Epoch: 6| Step: 5
Training loss: 2.466493855256647
Validation loss: 2.555291237373347

Epoch: 6| Step: 6
Training loss: 2.6291554575185936
Validation loss: 2.534094929068536

Epoch: 6| Step: 7
Training loss: 1.9350848989072815
Validation loss: 2.4734593276864834

Epoch: 6| Step: 8
Training loss: 2.5329747858129115
Validation loss: 2.467985740778452

Epoch: 6| Step: 9
Training loss: 2.4534748581133923
Validation loss: 2.428343720828531

Epoch: 6| Step: 10
Training loss: 2.335643532924197
Validation loss: 2.435756634153938

Epoch: 6| Step: 11
Training loss: 2.616951547491184
Validation loss: 2.41819845825367

Epoch: 6| Step: 12
Training loss: 2.426135837359145
Validation loss: 2.4141508705432013

Epoch: 6| Step: 13
Training loss: 2.9263229377974156
Validation loss: 2.426481604809294

Epoch: 354| Step: 0
Training loss: 2.3898977532322467
Validation loss: 2.4479709309410915

Epoch: 6| Step: 1
Training loss: 2.337434729006507
Validation loss: 2.4458891407442436

Epoch: 6| Step: 2
Training loss: 2.2562586311323183
Validation loss: 2.484445619524272

Epoch: 6| Step: 3
Training loss: 2.587857642773314
Validation loss: 2.527507321684569

Epoch: 6| Step: 4
Training loss: 2.6894931942594265
Validation loss: 2.5488640623914858

Epoch: 6| Step: 5
Training loss: 2.099400993474707
Validation loss: 2.6035799713463073

Epoch: 6| Step: 6
Training loss: 2.7536223569595224
Validation loss: 2.666077476317981

Epoch: 6| Step: 7
Training loss: 1.5657906785358853
Validation loss: 2.6867119257758687

Epoch: 6| Step: 8
Training loss: 2.2607122365726595
Validation loss: 2.677329332258099

Epoch: 6| Step: 9
Training loss: 2.6645125291457825
Validation loss: 2.655124450449489

Epoch: 6| Step: 10
Training loss: 2.6895671257951
Validation loss: 2.6123576608906065

Epoch: 6| Step: 11
Training loss: 2.3826800200108256
Validation loss: 2.5612205474634595

Epoch: 6| Step: 12
Training loss: 2.069233854475331
Validation loss: 2.5064593515147187

Epoch: 6| Step: 13
Training loss: 2.853952905674019
Validation loss: 2.468939136733132

Epoch: 355| Step: 0
Training loss: 3.048408943797247
Validation loss: 2.4557056541797486

Epoch: 6| Step: 1
Training loss: 2.223408389085222
Validation loss: 2.4352457230853086

Epoch: 6| Step: 2
Training loss: 2.634905879965517
Validation loss: 2.413767756454367

Epoch: 6| Step: 3
Training loss: 2.2669370863925864
Validation loss: 2.421189763849125

Epoch: 6| Step: 4
Training loss: 2.642455239832653
Validation loss: 2.433326438015237

Epoch: 6| Step: 5
Training loss: 2.0736001451830752
Validation loss: 2.4439028638800253

Epoch: 6| Step: 6
Training loss: 2.3387259996203165
Validation loss: 2.4568687471436923

Epoch: 6| Step: 7
Training loss: 2.246880488064023
Validation loss: 2.483174795736527

Epoch: 6| Step: 8
Training loss: 2.3179562096791724
Validation loss: 2.52515330312739

Epoch: 6| Step: 9
Training loss: 2.4081913436514837
Validation loss: 2.6014753979505527

Epoch: 6| Step: 10
Training loss: 2.378566473387438
Validation loss: 2.5969493056047854

Epoch: 6| Step: 11
Training loss: 2.3794355633550346
Validation loss: 2.5551279714415602

Epoch: 6| Step: 12
Training loss: 2.3580573236099807
Validation loss: 2.5605379882602217

Epoch: 6| Step: 13
Training loss: 2.002795173521266
Validation loss: 2.537762816222644

Epoch: 356| Step: 0
Training loss: 2.2948348138406263
Validation loss: 2.5170271276794405

Epoch: 6| Step: 1
Training loss: 2.328213376409587
Validation loss: 2.5156444063981387

Epoch: 6| Step: 2
Training loss: 2.0343883039329533
Validation loss: 2.5080343117761617

Epoch: 6| Step: 3
Training loss: 2.377798539761289
Validation loss: 2.500156651993072

Epoch: 6| Step: 4
Training loss: 2.328347317110456
Validation loss: 2.512644795107717

Epoch: 6| Step: 5
Training loss: 1.9607489141840362
Validation loss: 2.4994829996880057

Epoch: 6| Step: 6
Training loss: 2.6612624502540294
Validation loss: 2.503289155041691

Epoch: 6| Step: 7
Training loss: 2.958179810171559
Validation loss: 2.4966677915976745

Epoch: 6| Step: 8
Training loss: 2.3639749312838587
Validation loss: 2.490750773333851

Epoch: 6| Step: 9
Training loss: 2.5070000874504497
Validation loss: 2.495136534553619

Epoch: 6| Step: 10
Training loss: 2.4725978175486185
Validation loss: 2.5035654904483557

Epoch: 6| Step: 11
Training loss: 2.6136229880371404
Validation loss: 2.4999712932128038

Epoch: 6| Step: 12
Training loss: 1.8865698840565646
Validation loss: 2.5179737168203085

Epoch: 6| Step: 13
Training loss: 1.9453102326284164
Validation loss: 2.5761863860280974

Epoch: 357| Step: 0
Training loss: 2.2486093250016497
Validation loss: 2.5674182754889685

Epoch: 6| Step: 1
Training loss: 2.099873711557956
Validation loss: 2.596385424935915

Epoch: 6| Step: 2
Training loss: 1.9726071795412872
Validation loss: 2.598713130942625

Epoch: 6| Step: 3
Training loss: 2.571509178351441
Validation loss: 2.58245930058685

Epoch: 6| Step: 4
Training loss: 2.0706361913450557
Validation loss: 2.5450780747545885

Epoch: 6| Step: 5
Training loss: 2.2588852178720265
Validation loss: 2.5364222882267136

Epoch: 6| Step: 6
Training loss: 2.522828681182285
Validation loss: 2.532661914202187

Epoch: 6| Step: 7
Training loss: 2.0882055403731727
Validation loss: 2.5232526728694586

Epoch: 6| Step: 8
Training loss: 2.8176318503181004
Validation loss: 2.5416889236769444

Epoch: 6| Step: 9
Training loss: 1.862514186011444
Validation loss: 2.5028010796425155

Epoch: 6| Step: 10
Training loss: 2.3962470872171813
Validation loss: 2.5399066783171014

Epoch: 6| Step: 11
Training loss: 2.2948995386213538
Validation loss: 2.5375770634736803

Epoch: 6| Step: 12
Training loss: 2.981975449561433
Validation loss: 2.5284375358539353

Epoch: 6| Step: 13
Training loss: 2.9333403334389594
Validation loss: 2.5247015218334434

Epoch: 358| Step: 0
Training loss: 2.270076824014172
Validation loss: 2.511124195432985

Epoch: 6| Step: 1
Training loss: 1.676018971474643
Validation loss: 2.5176868481910897

Epoch: 6| Step: 2
Training loss: 2.5786748126446026
Validation loss: 2.492670177628459

Epoch: 6| Step: 3
Training loss: 2.3783273979207404
Validation loss: 2.5025821128362544

Epoch: 6| Step: 4
Training loss: 2.083842736590812
Validation loss: 2.529220825070639

Epoch: 6| Step: 5
Training loss: 1.8522856382652966
Validation loss: 2.562807545388319

Epoch: 6| Step: 6
Training loss: 2.736508828403835
Validation loss: 2.567567346492026

Epoch: 6| Step: 7
Training loss: 2.3182365815601083
Validation loss: 2.59161490707959

Epoch: 6| Step: 8
Training loss: 2.395858123208762
Validation loss: 2.576301994664587

Epoch: 6| Step: 9
Training loss: 2.0369113375994576
Validation loss: 2.5346832367539887

Epoch: 6| Step: 10
Training loss: 2.6054350752134168
Validation loss: 2.5123715042497747

Epoch: 6| Step: 11
Training loss: 2.638516820365665
Validation loss: 2.47763488290107

Epoch: 6| Step: 12
Training loss: 2.345767970780934
Validation loss: 2.4848040252036694

Epoch: 6| Step: 13
Training loss: 2.7842562426448882
Validation loss: 2.4664974047592954

Epoch: 359| Step: 0
Training loss: 2.0893362409469605
Validation loss: 2.421507730201274

Epoch: 6| Step: 1
Training loss: 1.6533498744496065
Validation loss: 2.4258654103273867

Epoch: 6| Step: 2
Training loss: 2.711102043676934
Validation loss: 2.433160229991912

Epoch: 6| Step: 3
Training loss: 2.8154318045701805
Validation loss: 2.4250089873779657

Epoch: 6| Step: 4
Training loss: 2.353053029290837
Validation loss: 2.4222354902460577

Epoch: 6| Step: 5
Training loss: 2.398905854362714
Validation loss: 2.414425777016148

Epoch: 6| Step: 6
Training loss: 2.2362001873884574
Validation loss: 2.426086627437192

Epoch: 6| Step: 7
Training loss: 2.0008170128023908
Validation loss: 2.4435614689053375

Epoch: 6| Step: 8
Training loss: 2.577660166132819
Validation loss: 2.480473971391666

Epoch: 6| Step: 9
Training loss: 2.0803224805122893
Validation loss: 2.4906660577874598

Epoch: 6| Step: 10
Training loss: 2.7853785529105224
Validation loss: 2.531069174966493

Epoch: 6| Step: 11
Training loss: 1.972194262501899
Validation loss: 2.5570089693007554

Epoch: 6| Step: 12
Training loss: 2.6085023620080006
Validation loss: 2.5593065521560363

Epoch: 6| Step: 13
Training loss: 2.4491986969000643
Validation loss: 2.5518808287455625

Epoch: 360| Step: 0
Training loss: 2.6204563963475316
Validation loss: 2.5608937201040978

Epoch: 6| Step: 1
Training loss: 2.8115421783469263
Validation loss: 2.5396342012686626

Epoch: 6| Step: 2
Training loss: 2.2265702096905997
Validation loss: 2.539852513289889

Epoch: 6| Step: 3
Training loss: 2.547192887202353
Validation loss: 2.5286474477030016

Epoch: 6| Step: 4
Training loss: 2.1138885809950647
Validation loss: 2.495331030379042

Epoch: 6| Step: 5
Training loss: 2.474217408652344
Validation loss: 2.4890020818406837

Epoch: 6| Step: 6
Training loss: 2.3003443252897116
Validation loss: 2.478573876566071

Epoch: 6| Step: 7
Training loss: 1.7118575178732087
Validation loss: 2.5022438142183394

Epoch: 6| Step: 8
Training loss: 2.713308303570722
Validation loss: 2.4868644232174875

Epoch: 6| Step: 9
Training loss: 2.4551080354432964
Validation loss: 2.4661930373942123

Epoch: 6| Step: 10
Training loss: 2.2613916242879424
Validation loss: 2.4639722450458676

Epoch: 6| Step: 11
Training loss: 2.4730164565338235
Validation loss: 2.4873744013793666

Epoch: 6| Step: 12
Training loss: 1.56927304002379
Validation loss: 2.495507609340711

Epoch: 6| Step: 13
Training loss: 1.9087232585600105
Validation loss: 2.55369478588941

Epoch: 361| Step: 0
Training loss: 2.3435949655755146
Validation loss: 2.5738534761732295

Epoch: 6| Step: 1
Training loss: 2.628830612477556
Validation loss: 2.6043006052008133

Epoch: 6| Step: 2
Training loss: 2.4619349804496107
Validation loss: 2.5446141284767654

Epoch: 6| Step: 3
Training loss: 1.9030581157187445
Validation loss: 2.509306030404467

Epoch: 6| Step: 4
Training loss: 2.3375311171148554
Validation loss: 2.443336903584401

Epoch: 6| Step: 5
Training loss: 2.2405374549777566
Validation loss: 2.4142323621467168

Epoch: 6| Step: 6
Training loss: 1.896598898889869
Validation loss: 2.399465051332661

Epoch: 6| Step: 7
Training loss: 2.570025303341283
Validation loss: 2.384248700054199

Epoch: 6| Step: 8
Training loss: 2.2134070740714002
Validation loss: 2.3982643342036063

Epoch: 6| Step: 9
Training loss: 2.5081317258735627
Validation loss: 2.3958463678277386

Epoch: 6| Step: 10
Training loss: 2.2112103081607826
Validation loss: 2.4162336112822986

Epoch: 6| Step: 11
Training loss: 2.2967639299383213
Validation loss: 2.4300546718527167

Epoch: 6| Step: 12
Training loss: 2.8047656205117457
Validation loss: 2.478082906165882

Epoch: 6| Step: 13
Training loss: 2.585526724744197
Validation loss: 2.4942540607200185

Epoch: 362| Step: 0
Training loss: 2.27026061322332
Validation loss: 2.563198178568671

Epoch: 6| Step: 1
Training loss: 2.0931705413174204
Validation loss: 2.601165712648318

Epoch: 6| Step: 2
Training loss: 1.840414942621908
Validation loss: 2.680219485708445

Epoch: 6| Step: 3
Training loss: 2.463165824453088
Validation loss: 2.7162351611972873

Epoch: 6| Step: 4
Training loss: 2.4995374251614466
Validation loss: 2.7206033733828487

Epoch: 6| Step: 5
Training loss: 2.548725789672153
Validation loss: 2.698611524216721

Epoch: 6| Step: 6
Training loss: 2.2684817489216065
Validation loss: 2.611227275957038

Epoch: 6| Step: 7
Training loss: 2.220778062238816
Validation loss: 2.5085359882398954

Epoch: 6| Step: 8
Training loss: 2.397760948164908
Validation loss: 2.4946055437381873

Epoch: 6| Step: 9
Training loss: 2.044363329955251
Validation loss: 2.4688619326326786

Epoch: 6| Step: 10
Training loss: 2.430112550114827
Validation loss: 2.460560305287882

Epoch: 6| Step: 11
Training loss: 2.519483367701504
Validation loss: 2.438439740482135

Epoch: 6| Step: 12
Training loss: 2.4153363962233887
Validation loss: 2.4321361703810296

Epoch: 6| Step: 13
Training loss: 2.918946456015584
Validation loss: 2.4345105510224547

Epoch: 363| Step: 0
Training loss: 2.0780802557007516
Validation loss: 2.4156994593827807

Epoch: 6| Step: 1
Training loss: 2.434458081611398
Validation loss: 2.4208484497185743

Epoch: 6| Step: 2
Training loss: 2.3490319307446024
Validation loss: 2.4233522417261444

Epoch: 6| Step: 3
Training loss: 2.233437081199896
Validation loss: 2.423123358483986

Epoch: 6| Step: 4
Training loss: 1.9945157676182537
Validation loss: 2.430994375631166

Epoch: 6| Step: 5
Training loss: 1.795526280303493
Validation loss: 2.476848483948804

Epoch: 6| Step: 6
Training loss: 1.9771175283751599
Validation loss: 2.4889288342431475

Epoch: 6| Step: 7
Training loss: 2.5467329863289567
Validation loss: 2.517573846115068

Epoch: 6| Step: 8
Training loss: 2.427369216868839
Validation loss: 2.550547424452663

Epoch: 6| Step: 9
Training loss: 2.617601777496294
Validation loss: 2.617418483042216

Epoch: 6| Step: 10
Training loss: 2.42943157062463
Validation loss: 2.6719003937742736

Epoch: 6| Step: 11
Training loss: 2.7497111082055268
Validation loss: 2.603969717802456

Epoch: 6| Step: 12
Training loss: 2.3362204083752007
Validation loss: 2.5111542693233

Epoch: 6| Step: 13
Training loss: 2.4434370460026837
Validation loss: 2.43000514461321

Epoch: 364| Step: 0
Training loss: 2.3172231330626922
Validation loss: 2.4127145214789465

Epoch: 6| Step: 1
Training loss: 2.946403807168573
Validation loss: 2.3974669299330538

Epoch: 6| Step: 2
Training loss: 2.084222324161509
Validation loss: 2.402024099588731

Epoch: 6| Step: 3
Training loss: 1.9094655166872547
Validation loss: 2.4033640076563105

Epoch: 6| Step: 4
Training loss: 2.4532950761479664
Validation loss: 2.40762360745087

Epoch: 6| Step: 5
Training loss: 1.6130963605180721
Validation loss: 2.435258837880557

Epoch: 6| Step: 6
Training loss: 2.0122664511557056
Validation loss: 2.453002661194002

Epoch: 6| Step: 7
Training loss: 2.4458665311554344
Validation loss: 2.4538590196722416

Epoch: 6| Step: 8
Training loss: 2.8759654538728587
Validation loss: 2.4572127565522024

Epoch: 6| Step: 9
Training loss: 1.9680549969160492
Validation loss: 2.482958229657796

Epoch: 6| Step: 10
Training loss: 2.4694626178032215
Validation loss: 2.5442121274371714

Epoch: 6| Step: 11
Training loss: 2.8248683662466636
Validation loss: 2.567540426583729

Epoch: 6| Step: 12
Training loss: 2.212041895795575
Validation loss: 2.6079708607720042

Epoch: 6| Step: 13
Training loss: 2.08543269874998
Validation loss: 2.5894334013552887

Epoch: 365| Step: 0
Training loss: 1.786006799990363
Validation loss: 2.617718751680456

Epoch: 6| Step: 1
Training loss: 2.8107036363943863
Validation loss: 2.5964118927322377

Epoch: 6| Step: 2
Training loss: 1.6659832109381558
Validation loss: 2.596565589406078

Epoch: 6| Step: 3
Training loss: 1.9809432505259204
Validation loss: 2.604389866933846

Epoch: 6| Step: 4
Training loss: 2.628493028561478
Validation loss: 2.5650445773258146

Epoch: 6| Step: 5
Training loss: 3.078412967127575
Validation loss: 2.5181252959650338

Epoch: 6| Step: 6
Training loss: 2.0280033868614673
Validation loss: 2.511681484994138

Epoch: 6| Step: 7
Training loss: 2.2953290862126225
Validation loss: 2.472834076965583

Epoch: 6| Step: 8
Training loss: 2.4638650586470194
Validation loss: 2.4179431194879495

Epoch: 6| Step: 9
Training loss: 1.833687950285827
Validation loss: 2.3832677913565568

Epoch: 6| Step: 10
Training loss: 2.5858505557100675
Validation loss: 2.38142994256859

Epoch: 6| Step: 11
Training loss: 1.7273894526087297
Validation loss: 2.396172862629925

Epoch: 6| Step: 12
Training loss: 2.225852130204495
Validation loss: 2.370260332172008

Epoch: 6| Step: 13
Training loss: 2.60687849119104
Validation loss: 2.388708581993636

Epoch: 366| Step: 0
Training loss: 2.6217915136346743
Validation loss: 2.405079666075884

Epoch: 6| Step: 1
Training loss: 1.8883781007385352
Validation loss: 2.423214835875228

Epoch: 6| Step: 2
Training loss: 3.1653894726574863
Validation loss: 2.4673149898857827

Epoch: 6| Step: 3
Training loss: 2.1705957391306043
Validation loss: 2.498012199553413

Epoch: 6| Step: 4
Training loss: 2.0174226063912144
Validation loss: 2.5302985421276674

Epoch: 6| Step: 5
Training loss: 2.4962842029870154
Validation loss: 2.5086908145064646

Epoch: 6| Step: 6
Training loss: 2.0482081374336123
Validation loss: 2.535452787653439

Epoch: 6| Step: 7
Training loss: 2.7309617892161975
Validation loss: 2.5219133653838366

Epoch: 6| Step: 8
Training loss: 2.081776673174593
Validation loss: 2.5042462844590037

Epoch: 6| Step: 9
Training loss: 1.8986370468445608
Validation loss: 2.4752255518147246

Epoch: 6| Step: 10
Training loss: 1.8910248388780255
Validation loss: 2.461801570283168

Epoch: 6| Step: 11
Training loss: 2.2052559793544964
Validation loss: 2.4594166567188385

Epoch: 6| Step: 12
Training loss: 2.108215691622844
Validation loss: 2.4595246446591554

Epoch: 6| Step: 13
Training loss: 2.0020329157117427
Validation loss: 2.48443182639504

Epoch: 367| Step: 0
Training loss: 2.0802427128252834
Validation loss: 2.481472952544788

Epoch: 6| Step: 1
Training loss: 2.7399687308594687
Validation loss: 2.4751600426928757

Epoch: 6| Step: 2
Training loss: 2.0413391732934443
Validation loss: 2.4763190575303495

Epoch: 6| Step: 3
Training loss: 2.620602148035091
Validation loss: 2.4768076926327165

Epoch: 6| Step: 4
Training loss: 2.56831871551704
Validation loss: 2.474746106838236

Epoch: 6| Step: 5
Training loss: 2.50780451407899
Validation loss: 2.485628195458459

Epoch: 6| Step: 6
Training loss: 2.207418168172321
Validation loss: 2.4981553573533297

Epoch: 6| Step: 7
Training loss: 1.9413940920535429
Validation loss: 2.4917702464604443

Epoch: 6| Step: 8
Training loss: 2.1480743656178687
Validation loss: 2.47701229349371

Epoch: 6| Step: 9
Training loss: 2.7020654972363234
Validation loss: 2.467606095285614

Epoch: 6| Step: 10
Training loss: 1.7382064974709828
Validation loss: 2.5139752364691694

Epoch: 6| Step: 11
Training loss: 1.7687873539838759
Validation loss: 2.512736876126088

Epoch: 6| Step: 12
Training loss: 2.1826964907992283
Validation loss: 2.5023016578676565

Epoch: 6| Step: 13
Training loss: 1.8574829733313358
Validation loss: 2.4908121805383816

Epoch: 368| Step: 0
Training loss: 1.9592221725218582
Validation loss: 2.4982278469937134

Epoch: 6| Step: 1
Training loss: 2.5500330156171125
Validation loss: 2.4889414704676334

Epoch: 6| Step: 2
Training loss: 2.171875
Validation loss: 2.488454285106277

Epoch: 6| Step: 3
Training loss: 2.6817830514002865
Validation loss: 2.4551092968448507

Epoch: 6| Step: 4
Training loss: 2.3566292455023206
Validation loss: 2.42601647647643

Epoch: 6| Step: 5
Training loss: 2.700162465894251
Validation loss: 2.442231385679755

Epoch: 6| Step: 6
Training loss: 2.4291114246854955
Validation loss: 2.443935345778514

Epoch: 6| Step: 7
Training loss: 1.9105891885792374
Validation loss: 2.4487740869806323

Epoch: 6| Step: 8
Training loss: 2.5360376738990014
Validation loss: 2.440078620874544

Epoch: 6| Step: 9
Training loss: 2.0621795405341072
Validation loss: 2.4548212669630045

Epoch: 6| Step: 10
Training loss: 1.880688113836172
Validation loss: 2.4735029042095396

Epoch: 6| Step: 11
Training loss: 1.9466117595197083
Validation loss: 2.484421395077378

Epoch: 6| Step: 12
Training loss: 2.2294021434537843
Validation loss: 2.5021446330014148

Epoch: 6| Step: 13
Training loss: 1.5018237471199243
Validation loss: 2.5037710348386755

Epoch: 369| Step: 0
Training loss: 1.8613792964790163
Validation loss: 2.5161964431401023

Epoch: 6| Step: 1
Training loss: 2.053519145228935
Validation loss: 2.49533307999126

Epoch: 6| Step: 2
Training loss: 2.459967721866885
Validation loss: 2.4680963992952396

Epoch: 6| Step: 3
Training loss: 2.565604585480406
Validation loss: 2.462207225079079

Epoch: 6| Step: 4
Training loss: 1.6489685794064577
Validation loss: 2.4703597291603994

Epoch: 6| Step: 5
Training loss: 2.2707873231852145
Validation loss: 2.477944915207167

Epoch: 6| Step: 6
Training loss: 2.494601333355278
Validation loss: 2.4798402258181964

Epoch: 6| Step: 7
Training loss: 2.791045523096947
Validation loss: 2.4790962704220263

Epoch: 6| Step: 8
Training loss: 1.6824798793638251
Validation loss: 2.461338992946592

Epoch: 6| Step: 9
Training loss: 2.323895702831859
Validation loss: 2.4844774207174503

Epoch: 6| Step: 10
Training loss: 2.089623555499586
Validation loss: 2.5134731865998043

Epoch: 6| Step: 11
Training loss: 2.240654930010612
Validation loss: 2.525849995743083

Epoch: 6| Step: 12
Training loss: 2.687284771484816
Validation loss: 2.578842209499684

Epoch: 6| Step: 13
Training loss: 1.5290145126162995
Validation loss: 2.559624199490677

Epoch: 370| Step: 0
Training loss: 2.29074857412292
Validation loss: 2.548433395898196

Epoch: 6| Step: 1
Training loss: 2.1352613315064985
Validation loss: 2.5749539260971566

Epoch: 6| Step: 2
Training loss: 2.1850324609994556
Validation loss: 2.5432237374069895

Epoch: 6| Step: 3
Training loss: 2.133473946983768
Validation loss: 2.5252802589415597

Epoch: 6| Step: 4
Training loss: 2.6970204125163355
Validation loss: 2.523414937575694

Epoch: 6| Step: 5
Training loss: 2.1747756359967454
Validation loss: 2.511848335238586

Epoch: 6| Step: 6
Training loss: 1.527187329646086
Validation loss: 2.501959315962333

Epoch: 6| Step: 7
Training loss: 2.187026272295431
Validation loss: 2.4688532423345473

Epoch: 6| Step: 8
Training loss: 2.2012110844583455
Validation loss: 2.4395745286432096

Epoch: 6| Step: 9
Training loss: 2.444789647763988
Validation loss: 2.4251738761124644

Epoch: 6| Step: 10
Training loss: 2.388091097054212
Validation loss: 2.4207443577904164

Epoch: 6| Step: 11
Training loss: 1.9536049825258006
Validation loss: 2.4290415405013057

Epoch: 6| Step: 12
Training loss: 2.037513349056395
Validation loss: 2.413167793333523

Epoch: 6| Step: 13
Training loss: 2.7968603378849273
Validation loss: 2.415309732619934

Epoch: 371| Step: 0
Training loss: 1.9222153152986088
Validation loss: 2.432716779551135

Epoch: 6| Step: 1
Training loss: 1.946294329952418
Validation loss: 2.4363550684525106

Epoch: 6| Step: 2
Training loss: 2.0430768132121364
Validation loss: 2.450689775623199

Epoch: 6| Step: 3
Training loss: 2.2932582068151417
Validation loss: 2.4657401234898475

Epoch: 6| Step: 4
Training loss: 2.002776245608062
Validation loss: 2.480664397916295

Epoch: 6| Step: 5
Training loss: 2.240287800079503
Validation loss: 2.533123672447072

Epoch: 6| Step: 6
Training loss: 1.9800904042383796
Validation loss: 2.5039328537454053

Epoch: 6| Step: 7
Training loss: 2.425907445011597
Validation loss: 2.537308358569796

Epoch: 6| Step: 8
Training loss: 2.0193827295937594
Validation loss: 2.550444272552576

Epoch: 6| Step: 9
Training loss: 2.362818144514175
Validation loss: 2.55583151705313

Epoch: 6| Step: 10
Training loss: 2.141111443930939
Validation loss: 2.535483706426366

Epoch: 6| Step: 11
Training loss: 2.7452003903368274
Validation loss: 2.5092928592163326

Epoch: 6| Step: 12
Training loss: 2.3347865302388287
Validation loss: 2.499806272527496

Epoch: 6| Step: 13
Training loss: 2.63605180005246
Validation loss: 2.4826981632052196

Epoch: 372| Step: 0
Training loss: 2.256527861923753
Validation loss: 2.4406696742532867

Epoch: 6| Step: 1
Training loss: 2.3498618227328816
Validation loss: 2.4366161899173333

Epoch: 6| Step: 2
Training loss: 2.05873735712335
Validation loss: 2.439566959843772

Epoch: 6| Step: 3
Training loss: 2.4603141842999503
Validation loss: 2.4583493641170224

Epoch: 6| Step: 4
Training loss: 2.8213916520916036
Validation loss: 2.4741764050642354

Epoch: 6| Step: 5
Training loss: 2.072433824391489
Validation loss: 2.4622302317618927

Epoch: 6| Step: 6
Training loss: 2.353457071042873
Validation loss: 2.5133861386962932

Epoch: 6| Step: 7
Training loss: 1.9158661110313946
Validation loss: 2.5041298441284874

Epoch: 6| Step: 8
Training loss: 2.363360846574087
Validation loss: 2.5198850916961333

Epoch: 6| Step: 9
Training loss: 2.322855265765252
Validation loss: 2.5003596990500108

Epoch: 6| Step: 10
Training loss: 1.2334080059196846
Validation loss: 2.5233944525666683

Epoch: 6| Step: 11
Training loss: 2.240253531549525
Validation loss: 2.5158035427950423

Epoch: 6| Step: 12
Training loss: 2.159855468117707
Validation loss: 2.4902300182467685

Epoch: 6| Step: 13
Training loss: 2.252359107180508
Validation loss: 2.470403038658673

Epoch: 373| Step: 0
Training loss: 1.8545853931372998
Validation loss: 2.4467206219658713

Epoch: 6| Step: 1
Training loss: 2.326667790435403
Validation loss: 2.4511539124050996

Epoch: 6| Step: 2
Training loss: 2.4772503496293568
Validation loss: 2.4494594769622555

Epoch: 6| Step: 3
Training loss: 2.510749594322505
Validation loss: 2.434099279358971

Epoch: 6| Step: 4
Training loss: 2.3042186195444376
Validation loss: 2.448896705077872

Epoch: 6| Step: 5
Training loss: 2.008135342896341
Validation loss: 2.471001253466014

Epoch: 6| Step: 6
Training loss: 2.38609033481058
Validation loss: 2.4810254587902763

Epoch: 6| Step: 7
Training loss: 1.2846223133634778
Validation loss: 2.4848577394517317

Epoch: 6| Step: 8
Training loss: 2.3680056929970945
Validation loss: 2.5231712437298826

Epoch: 6| Step: 9
Training loss: 2.1518744703076695
Validation loss: 2.507249930251452

Epoch: 6| Step: 10
Training loss: 1.9953861662096952
Validation loss: 2.4945432356143833

Epoch: 6| Step: 11
Training loss: 2.6048994228694093
Validation loss: 2.5049869783312873

Epoch: 6| Step: 12
Training loss: 2.349937003894302
Validation loss: 2.5154243674066254

Epoch: 6| Step: 13
Training loss: 1.2271845995443993
Validation loss: 2.552240910205605

Epoch: 374| Step: 0
Training loss: 1.8677373100567574
Validation loss: 2.5378769426941172

Epoch: 6| Step: 1
Training loss: 2.3683424546211302
Validation loss: 2.551090425199314

Epoch: 6| Step: 2
Training loss: 2.5956718953868143
Validation loss: 2.498020458978939

Epoch: 6| Step: 3
Training loss: 2.225793217057433
Validation loss: 2.529830899427029

Epoch: 6| Step: 4
Training loss: 2.15260781331603
Validation loss: 2.4913792502600156

Epoch: 6| Step: 5
Training loss: 2.2813420734375582
Validation loss: 2.484212409686922

Epoch: 6| Step: 6
Training loss: 1.9512596683397072
Validation loss: 2.490895258282708

Epoch: 6| Step: 7
Training loss: 2.394355804836409
Validation loss: 2.4826674967831246

Epoch: 6| Step: 8
Training loss: 1.9665425959206768
Validation loss: 2.4883785678556105

Epoch: 6| Step: 9
Training loss: 1.9881823202226814
Validation loss: 2.5034763541200866

Epoch: 6| Step: 10
Training loss: 2.2978521850429456
Validation loss: 2.5024806062322784

Epoch: 6| Step: 11
Training loss: 1.9068122409831758
Validation loss: 2.484713773717773

Epoch: 6| Step: 12
Training loss: 2.184958152806731
Validation loss: 2.488610521953508

Epoch: 6| Step: 13
Training loss: 2.435626557124274
Validation loss: 2.504479314705917

Epoch: 375| Step: 0
Training loss: 2.450424165403424
Validation loss: 2.4779223725672765

Epoch: 6| Step: 1
Training loss: 2.104756590481612
Validation loss: 2.5016157005300608

Epoch: 6| Step: 2
Training loss: 2.3084751879718017
Validation loss: 2.476955626008431

Epoch: 6| Step: 3
Training loss: 1.9998035334410431
Validation loss: 2.4845933808530183

Epoch: 6| Step: 4
Training loss: 2.0860388799026675
Validation loss: 2.468210350091111

Epoch: 6| Step: 5
Training loss: 1.8698906265749298
Validation loss: 2.4702768584793944

Epoch: 6| Step: 6
Training loss: 1.8961631432131392
Validation loss: 2.4841794090286675

Epoch: 6| Step: 7
Training loss: 1.9567766766380106
Validation loss: 2.493517868501443

Epoch: 6| Step: 8
Training loss: 2.570958018769918
Validation loss: 2.523715422326592

Epoch: 6| Step: 9
Training loss: 2.035521022447252
Validation loss: 2.5391052696847547

Epoch: 6| Step: 10
Training loss: 2.28403438841524
Validation loss: 2.514136753958745

Epoch: 6| Step: 11
Training loss: 2.107745523145082
Validation loss: 2.5101370291701386

Epoch: 6| Step: 12
Training loss: 2.6296839024410925
Validation loss: 2.470901961543277

Epoch: 6| Step: 13
Training loss: 2.2261346774081816
Validation loss: 2.44773688684905

Epoch: 376| Step: 0
Training loss: 2.704420099201958
Validation loss: 2.418340055535042

Epoch: 6| Step: 1
Training loss: 1.7768209841391236
Validation loss: 2.4231079689104535

Epoch: 6| Step: 2
Training loss: 1.9665894536308488
Validation loss: 2.426961276147774

Epoch: 6| Step: 3
Training loss: 2.022095459794851
Validation loss: 2.4167029625950227

Epoch: 6| Step: 4
Training loss: 2.5472228391926928
Validation loss: 2.4453157374254997

Epoch: 6| Step: 5
Training loss: 1.9630293308423994
Validation loss: 2.4699673831947155

Epoch: 6| Step: 6
Training loss: 2.1766890270648296
Validation loss: 2.5040159292469566

Epoch: 6| Step: 7
Training loss: 2.7528222080994476
Validation loss: 2.547083147789926

Epoch: 6| Step: 8
Training loss: 1.9826230703399448
Validation loss: 2.5918000580389866

Epoch: 6| Step: 9
Training loss: 1.8629235138152629
Validation loss: 2.6434457723014178

Epoch: 6| Step: 10
Training loss: 2.397590810828026
Validation loss: 2.622580850642282

Epoch: 6| Step: 11
Training loss: 2.338353773242075
Validation loss: 2.5828734917155867

Epoch: 6| Step: 12
Training loss: 2.2181592342844456
Validation loss: 2.561423937396342

Epoch: 6| Step: 13
Training loss: 1.6650729984169983
Validation loss: 2.5043439257501423

Epoch: 377| Step: 0
Training loss: 2.4558145151581234
Validation loss: 2.48819562148058

Epoch: 6| Step: 1
Training loss: 2.283409559643546
Validation loss: 2.460718613757567

Epoch: 6| Step: 2
Training loss: 2.185677014005501
Validation loss: 2.4584633594857563

Epoch: 6| Step: 3
Training loss: 1.9356819975617934
Validation loss: 2.4439191547101404

Epoch: 6| Step: 4
Training loss: 2.2308744739628676
Validation loss: 2.446346308308339

Epoch: 6| Step: 5
Training loss: 2.3780062872672802
Validation loss: 2.4274299589189927

Epoch: 6| Step: 6
Training loss: 1.8653652604601707
Validation loss: 2.433793612730786

Epoch: 6| Step: 7
Training loss: 1.907395440831895
Validation loss: 2.4569131406855007

Epoch: 6| Step: 8
Training loss: 2.5689209298764957
Validation loss: 2.4958051897657207

Epoch: 6| Step: 9
Training loss: 2.067244534559887
Validation loss: 2.4831109665128865

Epoch: 6| Step: 10
Training loss: 1.9926918737672605
Validation loss: 2.4945390595542962

Epoch: 6| Step: 11
Training loss: 2.0594867311306295
Validation loss: 2.475042387275269

Epoch: 6| Step: 12
Training loss: 2.2639312727171443
Validation loss: 2.4911929451035877

Epoch: 6| Step: 13
Training loss: 2.034717710256366
Validation loss: 2.530090474608083

Epoch: 378| Step: 0
Training loss: 2.284840514712863
Validation loss: 2.5232685865260986

Epoch: 6| Step: 1
Training loss: 2.7340926542285904
Validation loss: 2.5110021769685047

Epoch: 6| Step: 2
Training loss: 1.2174937792076652
Validation loss: 2.5180762670275776

Epoch: 6| Step: 3
Training loss: 2.266678558580207
Validation loss: 2.506392994583221

Epoch: 6| Step: 4
Training loss: 1.8593841680733467
Validation loss: 2.4825782204154416

Epoch: 6| Step: 5
Training loss: 2.447286278469313
Validation loss: 2.4782299524001496

Epoch: 6| Step: 6
Training loss: 2.5890937283001825
Validation loss: 2.490188064546721

Epoch: 6| Step: 7
Training loss: 2.125032761265152
Validation loss: 2.4857982362162434

Epoch: 6| Step: 8
Training loss: 1.771420108592566
Validation loss: 2.459793156550782

Epoch: 6| Step: 9
Training loss: 1.7651625171005454
Validation loss: 2.4585630546956625

Epoch: 6| Step: 10
Training loss: 2.25438157594894
Validation loss: 2.4738393630397546

Epoch: 6| Step: 11
Training loss: 1.961676591293306
Validation loss: 2.4777874600631637

Epoch: 6| Step: 12
Training loss: 1.790700903543679
Validation loss: 2.5052572133074604

Epoch: 6| Step: 13
Training loss: 2.946356388545478
Validation loss: 2.5122471105362023

Epoch: 379| Step: 0
Training loss: 2.1042631020180553
Validation loss: 2.5502938960779913

Epoch: 6| Step: 1
Training loss: 2.4165626591191915
Validation loss: 2.5751000998682003

Epoch: 6| Step: 2
Training loss: 2.5082416107879997
Validation loss: 2.5660796645131247

Epoch: 6| Step: 3
Training loss: 2.2560108216546957
Validation loss: 2.553805776082168

Epoch: 6| Step: 4
Training loss: 2.0025770750226446
Validation loss: 2.533030882215156

Epoch: 6| Step: 5
Training loss: 2.3084490580648342
Validation loss: 2.5159883338034263

Epoch: 6| Step: 6
Training loss: 2.4751347900061385
Validation loss: 2.497675142844761

Epoch: 6| Step: 7
Training loss: 1.7065903292784401
Validation loss: 2.4459397131025002

Epoch: 6| Step: 8
Training loss: 1.7988991656031788
Validation loss: 2.4268756749276945

Epoch: 6| Step: 9
Training loss: 1.9841044083779278
Validation loss: 2.428936334711938

Epoch: 6| Step: 10
Training loss: 1.9373232853194173
Validation loss: 2.424864576643506

Epoch: 6| Step: 11
Training loss: 2.438202096619298
Validation loss: 2.4033968017023732

Epoch: 6| Step: 12
Training loss: 2.0078837460000445
Validation loss: 2.4064543282658675

Epoch: 6| Step: 13
Training loss: 2.2198147435258986
Validation loss: 2.4158000714763213

Epoch: 380| Step: 0
Training loss: 2.18279315827961
Validation loss: 2.417208931805476

Epoch: 6| Step: 1
Training loss: 1.659941607792614
Validation loss: 2.4702295522231634

Epoch: 6| Step: 2
Training loss: 1.8484949381941898
Validation loss: 2.533106161946473

Epoch: 6| Step: 3
Training loss: 1.860128170027389
Validation loss: 2.520605481910929

Epoch: 6| Step: 4
Training loss: 1.8779511433137934
Validation loss: 2.5609424128154283

Epoch: 6| Step: 5
Training loss: 2.166244893714623
Validation loss: 2.5439794888339304

Epoch: 6| Step: 6
Training loss: 2.9385043111538773
Validation loss: 2.54817416204416

Epoch: 6| Step: 7
Training loss: 2.3541430131742316
Validation loss: 2.4887991670932696

Epoch: 6| Step: 8
Training loss: 2.230997159934705
Validation loss: 2.445450971595147

Epoch: 6| Step: 9
Training loss: 1.9889750591035786
Validation loss: 2.422654783300157

Epoch: 6| Step: 10
Training loss: 2.4309235890602587
Validation loss: 2.4013114167113065

Epoch: 6| Step: 11
Training loss: 1.8219837162826928
Validation loss: 2.396619293498541

Epoch: 6| Step: 12
Training loss: 2.847118520528094
Validation loss: 2.4038290697599765

Epoch: 6| Step: 13
Training loss: 1.4603276739428048
Validation loss: 2.424339064542893

Epoch: 381| Step: 0
Training loss: 2.0761649848486328
Validation loss: 2.455918799199253

Epoch: 6| Step: 1
Training loss: 2.0306921559715096
Validation loss: 2.4957535888558504

Epoch: 6| Step: 2
Training loss: 2.491402720714712
Validation loss: 2.5416870395429587

Epoch: 6| Step: 3
Training loss: 2.6874436660894943
Validation loss: 2.6002593196695876

Epoch: 6| Step: 4
Training loss: 1.5633419057506657
Validation loss: 2.5906158668771413

Epoch: 6| Step: 5
Training loss: 2.4779077961465017
Validation loss: 2.618990857917324

Epoch: 6| Step: 6
Training loss: 1.9456680769521755
Validation loss: 2.6590772229914337

Epoch: 6| Step: 7
Training loss: 2.218652320108582
Validation loss: 2.6839785750955425

Epoch: 6| Step: 8
Training loss: 2.620379787029255
Validation loss: 2.7172039602177684

Epoch: 6| Step: 9
Training loss: 2.2833956726177553
Validation loss: 2.689381567725527

Epoch: 6| Step: 10
Training loss: 1.886417973081533
Validation loss: 2.6162497258091517

Epoch: 6| Step: 11
Training loss: 2.016768966265957
Validation loss: 2.5650924326718494

Epoch: 6| Step: 12
Training loss: 2.1330290184926435
Validation loss: 2.5215866680563765

Epoch: 6| Step: 13
Training loss: 2.043432121170602
Validation loss: 2.505694270432536

Epoch: 382| Step: 0
Training loss: 2.0141493252549694
Validation loss: 2.4413872699615045

Epoch: 6| Step: 1
Training loss: 1.8468202792611903
Validation loss: 2.435491080593648

Epoch: 6| Step: 2
Training loss: 2.2189025826440982
Validation loss: 2.410061398515782

Epoch: 6| Step: 3
Training loss: 2.0294799134697654
Validation loss: 2.418091499994894

Epoch: 6| Step: 4
Training loss: 1.6132433427324235
Validation loss: 2.399373078757816

Epoch: 6| Step: 5
Training loss: 2.4887800210840587
Validation loss: 2.415124861402443

Epoch: 6| Step: 6
Training loss: 2.1095821702735322
Validation loss: 2.4367708588595094

Epoch: 6| Step: 7
Training loss: 2.433405248894372
Validation loss: 2.476506772521793

Epoch: 6| Step: 8
Training loss: 2.433739916482265
Validation loss: 2.5275137147843445

Epoch: 6| Step: 9
Training loss: 2.5283840579546144
Validation loss: 2.5588773796749673

Epoch: 6| Step: 10
Training loss: 1.878464803565468
Validation loss: 2.530753427905787

Epoch: 6| Step: 11
Training loss: 2.270500672031783
Validation loss: 2.4680306334257147

Epoch: 6| Step: 12
Training loss: 2.069667384565248
Validation loss: 2.460503067186565

Epoch: 6| Step: 13
Training loss: 2.0428160980552392
Validation loss: 2.412439465697107

Epoch: 383| Step: 0
Training loss: 1.5444495712548902
Validation loss: 2.416598634819543

Epoch: 6| Step: 1
Training loss: 2.263542533648472
Validation loss: 2.4177782821060334

Epoch: 6| Step: 2
Training loss: 2.2401402926789626
Validation loss: 2.4362787227263016

Epoch: 6| Step: 3
Training loss: 1.331545744089746
Validation loss: 2.452752989038731

Epoch: 6| Step: 4
Training loss: 2.589267027839168
Validation loss: 2.441850049968697

Epoch: 6| Step: 5
Training loss: 2.756922937710203
Validation loss: 2.4507253591424316

Epoch: 6| Step: 6
Training loss: 2.2224987758637393
Validation loss: 2.4956115301020003

Epoch: 6| Step: 7
Training loss: 1.856027105544559
Validation loss: 2.5151094777064693

Epoch: 6| Step: 8
Training loss: 2.0627205470683254
Validation loss: 2.590788163145359

Epoch: 6| Step: 9
Training loss: 2.4579487408165552
Validation loss: 2.6286132231816772

Epoch: 6| Step: 10
Training loss: 2.0535953070158586
Validation loss: 2.6544639011301716

Epoch: 6| Step: 11
Training loss: 2.113041382889418
Validation loss: 2.6445500390788896

Epoch: 6| Step: 12
Training loss: 2.109469037255732
Validation loss: 2.6167415066857487

Epoch: 6| Step: 13
Training loss: 2.2227282252666916
Validation loss: 2.5575568630538714

Epoch: 384| Step: 0
Training loss: 1.9424970237483294
Validation loss: 2.5362203320898926

Epoch: 6| Step: 1
Training loss: 2.2190451627160686
Validation loss: 2.4969683035946457

Epoch: 6| Step: 2
Training loss: 2.363594072303692
Validation loss: 2.445754598506144

Epoch: 6| Step: 3
Training loss: 1.987651492888992
Validation loss: 2.44566231426134

Epoch: 6| Step: 4
Training loss: 2.6776559318777804
Validation loss: 2.4319936623296425

Epoch: 6| Step: 5
Training loss: 2.2139082182526075
Validation loss: 2.4239387327987014

Epoch: 6| Step: 6
Training loss: 1.9396502960260706
Validation loss: 2.4277415493222496

Epoch: 6| Step: 7
Training loss: 2.1644044461341583
Validation loss: 2.410927591969475

Epoch: 6| Step: 8
Training loss: 2.0714529674953788
Validation loss: 2.4325049792664775

Epoch: 6| Step: 9
Training loss: 1.2419995819557947
Validation loss: 2.43342348525395

Epoch: 6| Step: 10
Training loss: 2.1039142142455667
Validation loss: 2.4702313486798215

Epoch: 6| Step: 11
Training loss: 2.384441281818537
Validation loss: 2.4735685204397098

Epoch: 6| Step: 12
Training loss: 1.8492821924683023
Validation loss: 2.4820106814920453

Epoch: 6| Step: 13
Training loss: 2.304359335084359
Validation loss: 2.5252949507363502

Epoch: 385| Step: 0
Training loss: 2.331008661372697
Validation loss: 2.5600258863409944

Epoch: 6| Step: 1
Training loss: 1.9160097765663162
Validation loss: 2.5406822915470246

Epoch: 6| Step: 2
Training loss: 2.1677822273365583
Validation loss: 2.539622420928175

Epoch: 6| Step: 3
Training loss: 2.0122192945247823
Validation loss: 2.531891193048572

Epoch: 6| Step: 4
Training loss: 1.790680732325749
Validation loss: 2.5023366242528207

Epoch: 6| Step: 5
Training loss: 2.0198188149049274
Validation loss: 2.4850583608716823

Epoch: 6| Step: 6
Training loss: 1.8251596511614492
Validation loss: 2.4699945777151684

Epoch: 6| Step: 7
Training loss: 2.0341798047062496
Validation loss: 2.4637230550053273

Epoch: 6| Step: 8
Training loss: 2.8616320764328074
Validation loss: 2.468036058755587

Epoch: 6| Step: 9
Training loss: 2.5188121627065674
Validation loss: 2.4457488218676233

Epoch: 6| Step: 10
Training loss: 1.6732284914028146
Validation loss: 2.4427756009380537

Epoch: 6| Step: 11
Training loss: 2.1263697080648924
Validation loss: 2.4654645635763504

Epoch: 6| Step: 12
Training loss: 1.8529060736215353
Validation loss: 2.4471042147940834

Epoch: 6| Step: 13
Training loss: 1.700168388105307
Validation loss: 2.4936979529926666

Epoch: 386| Step: 0
Training loss: 2.272801995349506
Validation loss: 2.5007979755078273

Epoch: 6| Step: 1
Training loss: 2.1623751124664197
Validation loss: 2.485880453339073

Epoch: 6| Step: 2
Training loss: 1.8926506225431734
Validation loss: 2.471619896008274

Epoch: 6| Step: 3
Training loss: 2.12516267939172
Validation loss: 2.5253197322869063

Epoch: 6| Step: 4
Training loss: 1.670431208875117
Validation loss: 2.536390023466522

Epoch: 6| Step: 5
Training loss: 2.3749142681509356
Validation loss: 2.522209945535476

Epoch: 6| Step: 6
Training loss: 2.0112043297076907
Validation loss: 2.550791499391113

Epoch: 6| Step: 7
Training loss: 2.319644099593577
Validation loss: 2.5481684324711775

Epoch: 6| Step: 8
Training loss: 2.214927819757253
Validation loss: 2.5294309688790086

Epoch: 6| Step: 9
Training loss: 2.457321659264628
Validation loss: 2.510126427897905

Epoch: 6| Step: 10
Training loss: 1.5631697173130343
Validation loss: 2.476305961423168

Epoch: 6| Step: 11
Training loss: 2.2876859829032634
Validation loss: 2.4392931694669784

Epoch: 6| Step: 12
Training loss: 1.9851044643212579
Validation loss: 2.3958847668135164

Epoch: 6| Step: 13
Training loss: 1.5597531397219748
Validation loss: 2.375415962031591

Epoch: 387| Step: 0
Training loss: 1.706389072884699
Validation loss: 2.3942049660653613

Epoch: 6| Step: 1
Training loss: 2.0527973256136094
Validation loss: 2.3917458587766594

Epoch: 6| Step: 2
Training loss: 1.759178952936625
Validation loss: 2.4111107105892877

Epoch: 6| Step: 3
Training loss: 2.3260792186101487
Validation loss: 2.454524206361146

Epoch: 6| Step: 4
Training loss: 1.5691504282760267
Validation loss: 2.4720020119109334

Epoch: 6| Step: 5
Training loss: 2.037088659223228
Validation loss: 2.5054086178691892

Epoch: 6| Step: 6
Training loss: 2.2331599419692303
Validation loss: 2.572426692054017

Epoch: 6| Step: 7
Training loss: 2.6049074772312553
Validation loss: 2.568879039814621

Epoch: 6| Step: 8
Training loss: 1.97267214324894
Validation loss: 2.549831934406544

Epoch: 6| Step: 9
Training loss: 2.265419365331256
Validation loss: 2.5113989026196006

Epoch: 6| Step: 10
Training loss: 1.9680940049832913
Validation loss: 2.5033718494432056

Epoch: 6| Step: 11
Training loss: 2.19010497708179
Validation loss: 2.5078884733377422

Epoch: 6| Step: 12
Training loss: 2.4376370318114717
Validation loss: 2.4923394969131434

Epoch: 6| Step: 13
Training loss: 1.6784351026837165
Validation loss: 2.475263564518679

Epoch: 388| Step: 0
Training loss: 2.5640280284807653
Validation loss: 2.4533097392426115

Epoch: 6| Step: 1
Training loss: 1.7461125929667005
Validation loss: 2.4697635419030193

Epoch: 6| Step: 2
Training loss: 2.2419484506171434
Validation loss: 2.469615364564643

Epoch: 6| Step: 3
Training loss: 2.1518556349451092
Validation loss: 2.4769274967112858

Epoch: 6| Step: 4
Training loss: 2.168112040415278
Validation loss: 2.4813565004747553

Epoch: 6| Step: 5
Training loss: 1.9338124777645103
Validation loss: 2.4998127200622777

Epoch: 6| Step: 6
Training loss: 1.9638581429856063
Validation loss: 2.5412421723483565

Epoch: 6| Step: 7
Training loss: 1.9823042510517384
Validation loss: 2.5798822235910186

Epoch: 6| Step: 8
Training loss: 1.9379632457558722
Validation loss: 2.5728157700890097

Epoch: 6| Step: 9
Training loss: 2.0998900611801012
Validation loss: 2.5623611384558402

Epoch: 6| Step: 10
Training loss: 2.0214441562650682
Validation loss: 2.530861603332711

Epoch: 6| Step: 11
Training loss: 1.8562823308832799
Validation loss: 2.505398300493585

Epoch: 6| Step: 12
Training loss: 2.083578197076491
Validation loss: 2.5049094427177567

Epoch: 6| Step: 13
Training loss: 2.23476561219766
Validation loss: 2.4786807961433577

Epoch: 389| Step: 0
Training loss: 2.2161565317925946
Validation loss: 2.451138584819675

Epoch: 6| Step: 1
Training loss: 2.2388435975513956
Validation loss: 2.4447354993592523

Epoch: 6| Step: 2
Training loss: 1.9839147800016719
Validation loss: 2.4329499930407232

Epoch: 6| Step: 3
Training loss: 1.7027797524027795
Validation loss: 2.436059631911773

Epoch: 6| Step: 4
Training loss: 2.164339564245669
Validation loss: 2.472619867516433

Epoch: 6| Step: 5
Training loss: 2.310577934101528
Validation loss: 2.4952290572204507

Epoch: 6| Step: 6
Training loss: 1.8610698764971396
Validation loss: 2.5288339699088564

Epoch: 6| Step: 7
Training loss: 2.0156413232896453
Validation loss: 2.5746164710690858

Epoch: 6| Step: 8
Training loss: 2.236318849769248
Validation loss: 2.5839403152569482

Epoch: 6| Step: 9
Training loss: 2.4471457924696787
Validation loss: 2.5958863114115833

Epoch: 6| Step: 10
Training loss: 2.353128615094127
Validation loss: 2.5992766555745117

Epoch: 6| Step: 11
Training loss: 1.9417762327046668
Validation loss: 2.5540461138208754

Epoch: 6| Step: 12
Training loss: 1.7714689647336548
Validation loss: 2.51674255360448

Epoch: 6| Step: 13
Training loss: 1.5627727270528777
Validation loss: 2.4630738865525634

Epoch: 390| Step: 0
Training loss: 2.548550107562501
Validation loss: 2.429201165331088

Epoch: 6| Step: 1
Training loss: 2.175504108632863
Validation loss: 2.4463298418658157

Epoch: 6| Step: 2
Training loss: 1.9656913855278575
Validation loss: 2.451439219663078

Epoch: 6| Step: 3
Training loss: 2.080493008067129
Validation loss: 2.43989883108552

Epoch: 6| Step: 4
Training loss: 2.22833470538755
Validation loss: 2.452659753537326

Epoch: 6| Step: 5
Training loss: 2.1415578104499695
Validation loss: 2.462408934510996

Epoch: 6| Step: 6
Training loss: 2.337654630880877
Validation loss: 2.485257665326003

Epoch: 6| Step: 7
Training loss: 1.6986906787656322
Validation loss: 2.478829038659901

Epoch: 6| Step: 8
Training loss: 1.5682788794966034
Validation loss: 2.515507547485898

Epoch: 6| Step: 9
Training loss: 1.748782960855133
Validation loss: 2.545884913871299

Epoch: 6| Step: 10
Training loss: 1.7945622695148418
Validation loss: 2.542744833674624

Epoch: 6| Step: 11
Training loss: 1.7238195388410686
Validation loss: 2.5254502418009297

Epoch: 6| Step: 12
Training loss: 2.3912810379143683
Validation loss: 2.5309825023115438

Epoch: 6| Step: 13
Training loss: 2.1596041037534475
Validation loss: 2.5104246813816755

Epoch: 391| Step: 0
Training loss: 1.7694171253985207
Validation loss: 2.540802493178856

Epoch: 6| Step: 1
Training loss: 1.9193959568460865
Validation loss: 2.5179996603287274

Epoch: 6| Step: 2
Training loss: 1.693929503666287
Validation loss: 2.5163887162453515

Epoch: 6| Step: 3
Training loss: 1.8466113888331805
Validation loss: 2.51040560737318

Epoch: 6| Step: 4
Training loss: 1.7592297075626444
Validation loss: 2.5338884076105592

Epoch: 6| Step: 5
Training loss: 2.014361318079602
Validation loss: 2.542638952468289

Epoch: 6| Step: 6
Training loss: 1.9212682743233405
Validation loss: 2.513032349021286

Epoch: 6| Step: 7
Training loss: 1.9448733772503
Validation loss: 2.4886145889800155

Epoch: 6| Step: 8
Training loss: 2.410310564093528
Validation loss: 2.496943354628102

Epoch: 6| Step: 9
Training loss: 2.1850207857238817
Validation loss: 2.4744709012829245

Epoch: 6| Step: 10
Training loss: 2.1351430826238245
Validation loss: 2.4843567919578247

Epoch: 6| Step: 11
Training loss: 2.47262192351272
Validation loss: 2.5004110767427723

Epoch: 6| Step: 12
Training loss: 2.1089922522397573
Validation loss: 2.4909356820202646

Epoch: 6| Step: 13
Training loss: 2.1862852811065854
Validation loss: 2.5546648397623257

Epoch: 392| Step: 0
Training loss: 1.8690486554486285
Validation loss: 2.5384579315958775

Epoch: 6| Step: 1
Training loss: 1.6595646062023086
Validation loss: 2.560294702780154

Epoch: 6| Step: 2
Training loss: 2.04945641730809
Validation loss: 2.5293208439880184

Epoch: 6| Step: 3
Training loss: 1.8373911196051342
Validation loss: 2.5494522712897174

Epoch: 6| Step: 4
Training loss: 2.3103316167295667
Validation loss: 2.536750651452291

Epoch: 6| Step: 5
Training loss: 2.4815356265540363
Validation loss: 2.509802933773898

Epoch: 6| Step: 6
Training loss: 1.591473468153084
Validation loss: 2.5076394598834644

Epoch: 6| Step: 7
Training loss: 1.980666291807677
Validation loss: 2.5137948724327415

Epoch: 6| Step: 8
Training loss: 1.856466631338006
Validation loss: 2.4848006163736835

Epoch: 6| Step: 9
Training loss: 1.7774553536389281
Validation loss: 2.466512813595174

Epoch: 6| Step: 10
Training loss: 2.3295831402354557
Validation loss: 2.4804918906447204

Epoch: 6| Step: 11
Training loss: 1.9598956741088294
Validation loss: 2.461623678466967

Epoch: 6| Step: 12
Training loss: 2.027646433555238
Validation loss: 2.4811485422905464

Epoch: 6| Step: 13
Training loss: 2.465212351568111
Validation loss: 2.458015390744482

Epoch: 393| Step: 0
Training loss: 2.071843570798807
Validation loss: 2.4781924000238216

Epoch: 6| Step: 1
Training loss: 2.393671824321636
Validation loss: 2.4841710592085353

Epoch: 6| Step: 2
Training loss: 1.7468026789399
Validation loss: 2.496576390187313

Epoch: 6| Step: 3
Training loss: 1.9949603362191863
Validation loss: 2.531021838107163

Epoch: 6| Step: 4
Training loss: 1.9429445370284006
Validation loss: 2.534415741325158

Epoch: 6| Step: 5
Training loss: 1.516496388165367
Validation loss: 2.5250783974924413

Epoch: 6| Step: 6
Training loss: 1.96529915539273
Validation loss: 2.5357211988481176

Epoch: 6| Step: 7
Training loss: 1.9971272579365869
Validation loss: 2.5294726284531257

Epoch: 6| Step: 8
Training loss: 2.0670458086951387
Validation loss: 2.5168188593720626

Epoch: 6| Step: 9
Training loss: 2.041889905078246
Validation loss: 2.5403608628849144

Epoch: 6| Step: 10
Training loss: 2.272849095287395
Validation loss: 2.529360833014445

Epoch: 6| Step: 11
Training loss: 1.6162895621453326
Validation loss: 2.4943170795915566

Epoch: 6| Step: 12
Training loss: 2.2170917600535973
Validation loss: 2.508735592908731

Epoch: 6| Step: 13
Training loss: 1.9878307499172994
Validation loss: 2.47421183627426

Epoch: 394| Step: 0
Training loss: 2.4935116493835703
Validation loss: 2.4893662484238575

Epoch: 6| Step: 1
Training loss: 1.840312404026904
Validation loss: 2.4546235999303376

Epoch: 6| Step: 2
Training loss: 2.0023540709397367
Validation loss: 2.486795302242552

Epoch: 6| Step: 3
Training loss: 1.9872214260045808
Validation loss: 2.4530196231583394

Epoch: 6| Step: 4
Training loss: 2.178694194488277
Validation loss: 2.485341799331424

Epoch: 6| Step: 5
Training loss: 1.5910063670502725
Validation loss: 2.5220040122002993

Epoch: 6| Step: 6
Training loss: 1.9373024870579927
Validation loss: 2.4833611945206497

Epoch: 6| Step: 7
Training loss: 1.5401908494921974
Validation loss: 2.54735895326663

Epoch: 6| Step: 8
Training loss: 1.5100399029745668
Validation loss: 2.571163653580585

Epoch: 6| Step: 9
Training loss: 2.5082490249946714
Validation loss: 2.6160029245968426

Epoch: 6| Step: 10
Training loss: 1.4363792030645453
Validation loss: 2.5842626248514415

Epoch: 6| Step: 11
Training loss: 2.065964765205781
Validation loss: 2.5725257247384326

Epoch: 6| Step: 12
Training loss: 2.2614316873431695
Validation loss: 2.509173472503589

Epoch: 6| Step: 13
Training loss: 2.4294317668998184
Validation loss: 2.5119616969374254

Epoch: 395| Step: 0
Training loss: 2.0543513149918966
Validation loss: 2.462320735226568

Epoch: 6| Step: 1
Training loss: 1.573779780899186
Validation loss: 2.463791705740142

Epoch: 6| Step: 2
Training loss: 1.4925420849104665
Validation loss: 2.454760814199664

Epoch: 6| Step: 3
Training loss: 1.6266944560559113
Validation loss: 2.475191993223161

Epoch: 6| Step: 4
Training loss: 1.9923874698581117
Validation loss: 2.4781816352008827

Epoch: 6| Step: 5
Training loss: 2.6624012351186805
Validation loss: 2.5423598982314526

Epoch: 6| Step: 6
Training loss: 2.890778738521489
Validation loss: 2.56791614351414

Epoch: 6| Step: 7
Training loss: 1.8796381486484937
Validation loss: 2.5754415065485667

Epoch: 6| Step: 8
Training loss: 2.096734496183375
Validation loss: 2.6185856206547125

Epoch: 6| Step: 9
Training loss: 1.8818010327952897
Validation loss: 2.5968021098525287

Epoch: 6| Step: 10
Training loss: 1.7154954093531463
Validation loss: 2.5960776476292637

Epoch: 6| Step: 11
Training loss: 1.6818970098228372
Validation loss: 2.5739261217439395

Epoch: 6| Step: 12
Training loss: 2.091784109438172
Validation loss: 2.555623757778092

Epoch: 6| Step: 13
Training loss: 1.7191827402674777
Validation loss: 2.5308877778700234

Epoch: 396| Step: 0
Training loss: 2.051115114192746
Validation loss: 2.5011669481004883

Epoch: 6| Step: 1
Training loss: 1.9749259959009295
Validation loss: 2.5039695337692156

Epoch: 6| Step: 2
Training loss: 1.2567589179732417
Validation loss: 2.496487759086139

Epoch: 6| Step: 3
Training loss: 2.3056283872915047
Validation loss: 2.473484970600225

Epoch: 6| Step: 4
Training loss: 2.206067872567393
Validation loss: 2.4567370424525525

Epoch: 6| Step: 5
Training loss: 1.799783757254181
Validation loss: 2.435100388150613

Epoch: 6| Step: 6
Training loss: 2.4298671643719376
Validation loss: 2.429787692198325

Epoch: 6| Step: 7
Training loss: 1.7780698529693861
Validation loss: 2.4587463228752378

Epoch: 6| Step: 8
Training loss: 1.8579609727363888
Validation loss: 2.4327620511494845

Epoch: 6| Step: 9
Training loss: 2.085261431800012
Validation loss: 2.4770194503210825

Epoch: 6| Step: 10
Training loss: 0.9804767745096175
Validation loss: 2.5060093549743274

Epoch: 6| Step: 11
Training loss: 2.014791863532542
Validation loss: 2.538543120998017

Epoch: 6| Step: 12
Training loss: 2.4116196602451954
Validation loss: 2.537027150737908

Epoch: 6| Step: 13
Training loss: 1.976113852746064
Validation loss: 2.553533124614398

Epoch: 397| Step: 0
Training loss: 2.067380506021387
Validation loss: 2.5402772553022492

Epoch: 6| Step: 1
Training loss: 1.7475336951853333
Validation loss: 2.5488281079012043

Epoch: 6| Step: 2
Training loss: 2.488461953492947
Validation loss: 2.5097449882344867

Epoch: 6| Step: 3
Training loss: 1.4561146161585719
Validation loss: 2.509176346564333

Epoch: 6| Step: 4
Training loss: 1.8854378405764243
Validation loss: 2.488607988814845

Epoch: 6| Step: 5
Training loss: 2.1708268305216776
Validation loss: 2.478679623273832

Epoch: 6| Step: 6
Training loss: 2.0001287418890965
Validation loss: 2.502982336775076

Epoch: 6| Step: 7
Training loss: 1.8814158977980016
Validation loss: 2.504918825657086

Epoch: 6| Step: 8
Training loss: 2.190679473852673
Validation loss: 2.5031113429440315

Epoch: 6| Step: 9
Training loss: 1.7985798584699266
Validation loss: 2.512942668080231

Epoch: 6| Step: 10
Training loss: 1.7761253120958493
Validation loss: 2.5279778737104173

Epoch: 6| Step: 11
Training loss: 2.0786008361773614
Validation loss: 2.5376373340131586

Epoch: 6| Step: 12
Training loss: 1.5689999233121834
Validation loss: 2.574882574477375

Epoch: 6| Step: 13
Training loss: 2.187687457090731
Validation loss: 2.589984940001141

Epoch: 398| Step: 0
Training loss: 1.6411306419464438
Validation loss: 2.5934204789703283

Epoch: 6| Step: 1
Training loss: 2.0083185292987045
Validation loss: 2.5842718387183083

Epoch: 6| Step: 2
Training loss: 2.1981536833860575
Validation loss: 2.5914419010717236

Epoch: 6| Step: 3
Training loss: 2.0958680783899926
Validation loss: 2.5899507223973313

Epoch: 6| Step: 4
Training loss: 2.0719616349693033
Validation loss: 2.5712357589728754

Epoch: 6| Step: 5
Training loss: 1.6612925511544439
Validation loss: 2.573440354649466

Epoch: 6| Step: 6
Training loss: 1.7876846138112958
Validation loss: 2.546177079757766

Epoch: 6| Step: 7
Training loss: 1.5188545348058815
Validation loss: 2.5656244951507245

Epoch: 6| Step: 8
Training loss: 1.9386366924573044
Validation loss: 2.518612970848542

Epoch: 6| Step: 9
Training loss: 2.0299812462602844
Validation loss: 2.52331353700936

Epoch: 6| Step: 10
Training loss: 2.3264294280763345
Validation loss: 2.5095202936124013

Epoch: 6| Step: 11
Training loss: 2.100755728115819
Validation loss: 2.5099922658483034

Epoch: 6| Step: 12
Training loss: 1.8483349317790838
Validation loss: 2.5089558026443726

Epoch: 6| Step: 13
Training loss: 1.7912735248945537
Validation loss: 2.5065159012162233

Epoch: 399| Step: 0
Training loss: 1.589542594710941
Validation loss: 2.490810263065687

Epoch: 6| Step: 1
Training loss: 1.6285398514872396
Validation loss: 2.4739626206434804

Epoch: 6| Step: 2
Training loss: 1.590473921820157
Validation loss: 2.495391718735111

Epoch: 6| Step: 3
Training loss: 1.3209875062962448
Validation loss: 2.5143797894523177

Epoch: 6| Step: 4
Training loss: 2.0924935057982523
Validation loss: 2.5033112224424214

Epoch: 6| Step: 5
Training loss: 1.6956423249644412
Validation loss: 2.521314718572233

Epoch: 6| Step: 6
Training loss: 1.5952935317627697
Validation loss: 2.5329198531285946

Epoch: 6| Step: 7
Training loss: 2.189500166756013
Validation loss: 2.5546379926247917

Epoch: 6| Step: 8
Training loss: 2.414788491916706
Validation loss: 2.5455855338911118

Epoch: 6| Step: 9
Training loss: 2.073437444806188
Validation loss: 2.576404384932799

Epoch: 6| Step: 10
Training loss: 1.746558483840603
Validation loss: 2.5545086351011212

Epoch: 6| Step: 11
Training loss: 2.4452741821016875
Validation loss: 2.527360023351935

Epoch: 6| Step: 12
Training loss: 2.4837899148898632
Validation loss: 2.535309974409473

Epoch: 6| Step: 13
Training loss: 1.7702124086721955
Validation loss: 2.5123554919773143

Epoch: 400| Step: 0
Training loss: 1.3147151056777624
Validation loss: 2.483244424244054

Epoch: 6| Step: 1
Training loss: 1.964193915414276
Validation loss: 2.4886268245294367

Epoch: 6| Step: 2
Training loss: 1.4361602510808702
Validation loss: 2.487764288559759

Epoch: 6| Step: 3
Training loss: 1.936163164214709
Validation loss: 2.5330764478619816

Epoch: 6| Step: 4
Training loss: 2.1030361298465468
Validation loss: 2.5089036516856043

Epoch: 6| Step: 5
Training loss: 1.8077546185431965
Validation loss: 2.557568711143179

Epoch: 6| Step: 6
Training loss: 1.8023834713583922
Validation loss: 2.5622964713652947

Epoch: 6| Step: 7
Training loss: 2.2122170348175523
Validation loss: 2.602132901061857

Epoch: 6| Step: 8
Training loss: 1.8819284223349177
Validation loss: 2.6442884059619107

Epoch: 6| Step: 9
Training loss: 2.0190084286079735
Validation loss: 2.619412130821609

Epoch: 6| Step: 10
Training loss: 2.1875418522782026
Validation loss: 2.5971839274916495

Epoch: 6| Step: 11
Training loss: 2.167733614430593
Validation loss: 2.586116439457092

Epoch: 6| Step: 12
Training loss: 1.864051771492793
Validation loss: 2.5508122342316506

Epoch: 6| Step: 13
Training loss: 2.4798676490845875
Validation loss: 2.5368684442730904

Epoch: 401| Step: 0
Training loss: 1.9988792378605689
Validation loss: 2.4990935405051435

Epoch: 6| Step: 1
Training loss: 1.9156238649249797
Validation loss: 2.4981833430636518

Epoch: 6| Step: 2
Training loss: 1.9490119044574974
Validation loss: 2.5026510518374208

Epoch: 6| Step: 3
Training loss: 1.839653313048435
Validation loss: 2.5174049964467518

Epoch: 6| Step: 4
Training loss: 2.0647861641551466
Validation loss: 2.5118550279400655

Epoch: 6| Step: 5
Training loss: 1.8451198079977025
Validation loss: 2.502264502602522

Epoch: 6| Step: 6
Training loss: 2.4307203642660773
Validation loss: 2.4374929806103642

Epoch: 6| Step: 7
Training loss: 1.8966947491895985
Validation loss: 2.4825712727196194

Epoch: 6| Step: 8
Training loss: 1.2752914974368619
Validation loss: 2.474827832377905

Epoch: 6| Step: 9
Training loss: 1.7692000392809455
Validation loss: 2.4853477345998076

Epoch: 6| Step: 10
Training loss: 1.731381832019815
Validation loss: 2.4554903931745287

Epoch: 6| Step: 11
Training loss: 1.8793407421586243
Validation loss: 2.4917345504932595

Epoch: 6| Step: 12
Training loss: 2.3594475539211697
Validation loss: 2.4960149238748706

Epoch: 6| Step: 13
Training loss: 1.6419751379335557
Validation loss: 2.4944676425520593

Epoch: 402| Step: 0
Training loss: 1.682597420920061
Validation loss: 2.518863729905096

Epoch: 6| Step: 1
Training loss: 1.6280916587652
Validation loss: 2.538145751031166

Epoch: 6| Step: 2
Training loss: 2.071942533425193
Validation loss: 2.5362487529171234

Epoch: 6| Step: 3
Training loss: 1.9935191771247671
Validation loss: 2.5331531602937347

Epoch: 6| Step: 4
Training loss: 2.0719158369962094
Validation loss: 2.5543378099096006

Epoch: 6| Step: 5
Training loss: 2.0577649179807005
Validation loss: 2.5607589161187696

Epoch: 6| Step: 6
Training loss: 1.4288428474488328
Validation loss: 2.530922923648629

Epoch: 6| Step: 7
Training loss: 1.8776766427523002
Validation loss: 2.551855527560353

Epoch: 6| Step: 8
Training loss: 2.2239505907649058
Validation loss: 2.560732808639119

Epoch: 6| Step: 9
Training loss: 1.7751075174784199
Validation loss: 2.5242206802411817

Epoch: 6| Step: 10
Training loss: 1.774378388318639
Validation loss: 2.54988245100963

Epoch: 6| Step: 11
Training loss: 1.9623979699892165
Validation loss: 2.553095136370325

Epoch: 6| Step: 12
Training loss: 2.2549672926668616
Validation loss: 2.5371057242152246

Epoch: 6| Step: 13
Training loss: 1.4975565240856257
Validation loss: 2.5678360837835523

Epoch: 403| Step: 0
Training loss: 1.9655766419009888
Validation loss: 2.552918414335681

Epoch: 6| Step: 1
Training loss: 1.5778041551217805
Validation loss: 2.517954517240395

Epoch: 6| Step: 2
Training loss: 2.1612790933463306
Validation loss: 2.534177304109348

Epoch: 6| Step: 3
Training loss: 1.886914418817409
Validation loss: 2.5062555312589008

Epoch: 6| Step: 4
Training loss: 1.4515078169887825
Validation loss: 2.508335613415541

Epoch: 6| Step: 5
Training loss: 1.4556435529706624
Validation loss: 2.4910273336252393

Epoch: 6| Step: 6
Training loss: 1.9707656714321864
Validation loss: 2.5110674340417165

Epoch: 6| Step: 7
Training loss: 2.377267056675047
Validation loss: 2.544990731842612

Epoch: 6| Step: 8
Training loss: 2.16000746478451
Validation loss: 2.5024712920086327

Epoch: 6| Step: 9
Training loss: 2.096416540382902
Validation loss: 2.4971857320122868

Epoch: 6| Step: 10
Training loss: 1.3854505730784554
Validation loss: 2.517937635335823

Epoch: 6| Step: 11
Training loss: 1.8131018330022
Validation loss: 2.51368643168785

Epoch: 6| Step: 12
Training loss: 2.035151563994125
Validation loss: 2.4935955871464763

Epoch: 6| Step: 13
Training loss: 1.8505516673113107
Validation loss: 2.4988369184560955

Epoch: 404| Step: 0
Training loss: 1.7776951704436155
Validation loss: 2.5179887073066216

Epoch: 6| Step: 1
Training loss: 2.516282653141918
Validation loss: 2.5384524951881486

Epoch: 6| Step: 2
Training loss: 1.927848773874128
Validation loss: 2.5837376311585616

Epoch: 6| Step: 3
Training loss: 1.7592188655759382
Validation loss: 2.612920158503034

Epoch: 6| Step: 4
Training loss: 1.4994984424019484
Validation loss: 2.637623374528896

Epoch: 6| Step: 5
Training loss: 2.026533196324917
Validation loss: 2.6834701684212114

Epoch: 6| Step: 6
Training loss: 1.7456664516227163
Validation loss: 2.6596926322987535

Epoch: 6| Step: 7
Training loss: 1.9939579296207972
Validation loss: 2.6236420462430283

Epoch: 6| Step: 8
Training loss: 0.9291566888133768
Validation loss: 2.5885388770940256

Epoch: 6| Step: 9
Training loss: 2.0466068470731784
Validation loss: 2.580523927850663

Epoch: 6| Step: 10
Training loss: 1.6461097227678565
Validation loss: 2.5032636484561523

Epoch: 6| Step: 11
Training loss: 2.2163322062557156
Validation loss: 2.5083976387276583

Epoch: 6| Step: 12
Training loss: 1.927560228329556
Validation loss: 2.489350094353515

Epoch: 6| Step: 13
Training loss: 2.215871205928591
Validation loss: 2.477745545037806

Epoch: 405| Step: 0
Training loss: 1.6906244528270689
Validation loss: 2.451510930173659

Epoch: 6| Step: 1
Training loss: 1.9247654214586312
Validation loss: 2.496148214452592

Epoch: 6| Step: 2
Training loss: 2.2266808193960053
Validation loss: 2.5049427111583245

Epoch: 6| Step: 3
Training loss: 2.0487188522829243
Validation loss: 2.531999435290995

Epoch: 6| Step: 4
Training loss: 2.0535228605035885
Validation loss: 2.497747926623919

Epoch: 6| Step: 5
Training loss: 1.8215670866883142
Validation loss: 2.513479155395201

Epoch: 6| Step: 6
Training loss: 1.9525285954646547
Validation loss: 2.5607278189747023

Epoch: 6| Step: 7
Training loss: 1.653486140993335
Validation loss: 2.5392870721822844

Epoch: 6| Step: 8
Training loss: 1.9341506310219652
Validation loss: 2.50136705983898

Epoch: 6| Step: 9
Training loss: 1.95163456315703
Validation loss: 2.486561819960312

Epoch: 6| Step: 10
Training loss: 1.8405530983525644
Validation loss: 2.5204355456030276

Epoch: 6| Step: 11
Training loss: 1.8236507863072826
Validation loss: 2.504704593584791

Epoch: 6| Step: 12
Training loss: 1.9878829826977165
Validation loss: 2.4848022052356993

Epoch: 6| Step: 13
Training loss: 1.4309773281175442
Validation loss: 2.4855989379765715

Epoch: 406| Step: 0
Training loss: 1.5135041174679802
Validation loss: 2.5055272641234017

Epoch: 6| Step: 1
Training loss: 1.8879082446674158
Validation loss: 2.5189289003528934

Epoch: 6| Step: 2
Training loss: 2.2971262891676223
Validation loss: 2.5253318052228555

Epoch: 6| Step: 3
Training loss: 1.8480239728058026
Validation loss: 2.5504347163440975

Epoch: 6| Step: 4
Training loss: 2.2414709135708804
Validation loss: 2.5614089103589017

Epoch: 6| Step: 5
Training loss: 2.122564603184068
Validation loss: 2.574858609953308

Epoch: 6| Step: 6
Training loss: 1.5886756298507616
Validation loss: 2.6191805581797305

Epoch: 6| Step: 7
Training loss: 1.6694729385581921
Validation loss: 2.6024867930576665

Epoch: 6| Step: 8
Training loss: 1.7993773575582162
Validation loss: 2.6137170974925765

Epoch: 6| Step: 9
Training loss: 2.0025211179765106
Validation loss: 2.6011740382692135

Epoch: 6| Step: 10
Training loss: 1.7644813682283735
Validation loss: 2.607433868155712

Epoch: 6| Step: 11
Training loss: 1.5307507382231769
Validation loss: 2.6217163846785914

Epoch: 6| Step: 12
Training loss: 1.791875767888948
Validation loss: 2.582847037046397

Epoch: 6| Step: 13
Training loss: 2.052490916818646
Validation loss: 2.5892958634336893

Epoch: 407| Step: 0
Training loss: 1.889328693474829
Validation loss: 2.570476593695154

Epoch: 6| Step: 1
Training loss: 1.3901509109056678
Validation loss: 2.5283770698407553

Epoch: 6| Step: 2
Training loss: 1.8994472628243984
Validation loss: 2.525559760961657

Epoch: 6| Step: 3
Training loss: 2.016845215493866
Validation loss: 2.5240001274117825

Epoch: 6| Step: 4
Training loss: 1.8202133479148783
Validation loss: 2.51912844580297

Epoch: 6| Step: 5
Training loss: 1.7904899932402736
Validation loss: 2.4911450594218283

Epoch: 6| Step: 6
Training loss: 2.0579404427647554
Validation loss: 2.5084800921619594

Epoch: 6| Step: 7
Training loss: 1.7062327177968055
Validation loss: 2.4686014855832017

Epoch: 6| Step: 8
Training loss: 2.2265345521477897
Validation loss: 2.4902523537328016

Epoch: 6| Step: 9
Training loss: 1.5821557266809225
Validation loss: 2.499996700079596

Epoch: 6| Step: 10
Training loss: 1.865829037446561
Validation loss: 2.5259247100178612

Epoch: 6| Step: 11
Training loss: 2.1517359711438018
Validation loss: 2.5200653621669518

Epoch: 6| Step: 12
Training loss: 1.7544584700593062
Validation loss: 2.524710261566266

Epoch: 6| Step: 13
Training loss: 1.6289301808746834
Validation loss: 2.547333565905792

Epoch: 408| Step: 0
Training loss: 1.9192319233718727
Validation loss: 2.5484921034729906

Epoch: 6| Step: 1
Training loss: 1.9606926753798537
Validation loss: 2.561967753938126

Epoch: 6| Step: 2
Training loss: 1.6847944116112097
Validation loss: 2.572310196657791

Epoch: 6| Step: 3
Training loss: 1.6407686443115264
Validation loss: 2.5633657530134064

Epoch: 6| Step: 4
Training loss: 2.4454179929945363
Validation loss: 2.55358911274404

Epoch: 6| Step: 5
Training loss: 1.8673495936563642
Validation loss: 2.544379896381797

Epoch: 6| Step: 6
Training loss: 1.8955625263790044
Validation loss: 2.5711716201901456

Epoch: 6| Step: 7
Training loss: 1.806278864751995
Validation loss: 2.51822604469657

Epoch: 6| Step: 8
Training loss: 2.187066716471206
Validation loss: 2.522809898095561

Epoch: 6| Step: 9
Training loss: 1.2622578416997436
Validation loss: 2.4929011164126393

Epoch: 6| Step: 10
Training loss: 1.8729706272361832
Validation loss: 2.484455620449563

Epoch: 6| Step: 11
Training loss: 1.8622856119156106
Validation loss: 2.479854658555591

Epoch: 6| Step: 12
Training loss: 1.8688693592138728
Validation loss: 2.5287667909366975

Epoch: 6| Step: 13
Training loss: 0.9063711414268177
Validation loss: 2.5092418830425776

Epoch: 409| Step: 0
Training loss: 1.1602190302550177
Validation loss: 2.498027712636786

Epoch: 6| Step: 1
Training loss: 2.0604560434289967
Validation loss: 2.527525620532958

Epoch: 6| Step: 2
Training loss: 1.8086912981590122
Validation loss: 2.5303500201212277

Epoch: 6| Step: 3
Training loss: 1.642306020653722
Validation loss: 2.554526249786262

Epoch: 6| Step: 4
Training loss: 1.8079594268044146
Validation loss: 2.5396044010402714

Epoch: 6| Step: 5
Training loss: 1.86308636235941
Validation loss: 2.5053669060637547

Epoch: 6| Step: 6
Training loss: 1.8048548765304355
Validation loss: 2.5413954267473775

Epoch: 6| Step: 7
Training loss: 2.0074700089396087
Validation loss: 2.519103575868604

Epoch: 6| Step: 8
Training loss: 2.1501863886748236
Validation loss: 2.5242807095827002

Epoch: 6| Step: 9
Training loss: 1.6858822167412424
Validation loss: 2.494123938578682

Epoch: 6| Step: 10
Training loss: 1.6582985930262417
Validation loss: 2.519498580691562

Epoch: 6| Step: 11
Training loss: 2.203177160633083
Validation loss: 2.494303718251975

Epoch: 6| Step: 12
Training loss: 1.5958543983576465
Validation loss: 2.460843927649197

Epoch: 6| Step: 13
Training loss: 2.0385549797931986
Validation loss: 2.4757345372252946

Epoch: 410| Step: 0
Training loss: 1.5943785531226105
Validation loss: 2.5362658828895213

Epoch: 6| Step: 1
Training loss: 1.58314124832821
Validation loss: 2.5461121395617377

Epoch: 6| Step: 2
Training loss: 1.6859261272849375
Validation loss: 2.5208479618904707

Epoch: 6| Step: 3
Training loss: 2.08994379962759
Validation loss: 2.5542614838046003

Epoch: 6| Step: 4
Training loss: 1.6971514172863367
Validation loss: 2.5931704313866453

Epoch: 6| Step: 5
Training loss: 1.7347858389123625
Validation loss: 2.5864024034210638

Epoch: 6| Step: 6
Training loss: 2.4417217569570075
Validation loss: 2.5717144201901143

Epoch: 6| Step: 7
Training loss: 1.8455261468556947
Validation loss: 2.5780469617222677

Epoch: 6| Step: 8
Training loss: 1.9830666381442659
Validation loss: 2.561503145661556

Epoch: 6| Step: 9
Training loss: 1.7986753649467118
Validation loss: 2.53749549590925

Epoch: 6| Step: 10
Training loss: 2.2060684129373267
Validation loss: 2.56328188264861

Epoch: 6| Step: 11
Training loss: 1.8724247095023947
Validation loss: 2.5425209268701363

Epoch: 6| Step: 12
Training loss: 1.1205174895678738
Validation loss: 2.521129322972029

Epoch: 6| Step: 13
Training loss: 1.617539888034584
Validation loss: 2.5600311692845343

Epoch: 411| Step: 0
Training loss: 1.6288364313105843
Validation loss: 2.54501020039801

Epoch: 6| Step: 1
Training loss: 2.081917306956295
Validation loss: 2.56613293627727

Epoch: 6| Step: 2
Training loss: 1.6852490989774325
Validation loss: 2.5700323996583028

Epoch: 6| Step: 3
Training loss: 1.6584926752314544
Validation loss: 2.559032283807617

Epoch: 6| Step: 4
Training loss: 2.1602875874828156
Validation loss: 2.5818204197494383

Epoch: 6| Step: 5
Training loss: 1.9854218132323267
Validation loss: 2.591548152630474

Epoch: 6| Step: 6
Training loss: 1.6560054094622436
Validation loss: 2.5827936196845442

Epoch: 6| Step: 7
Training loss: 1.125501944568637
Validation loss: 2.5919981218248536

Epoch: 6| Step: 8
Training loss: 2.0203410725590354
Validation loss: 2.579096856874593

Epoch: 6| Step: 9
Training loss: 2.1573969789664384
Validation loss: 2.5799398558222424

Epoch: 6| Step: 10
Training loss: 1.6283038372438532
Validation loss: 2.546709227525484

Epoch: 6| Step: 11
Training loss: 2.0076830632980416
Validation loss: 2.5555274427777968

Epoch: 6| Step: 12
Training loss: 2.0483009089155715
Validation loss: 2.520376417432854

Epoch: 6| Step: 13
Training loss: 0.7015071694149788
Validation loss: 2.50084386447585

Epoch: 412| Step: 0
Training loss: 1.7671183794368048
Validation loss: 2.462890365814088

Epoch: 6| Step: 1
Training loss: 1.6707242766801333
Validation loss: 2.4890303290832185

Epoch: 6| Step: 2
Training loss: 1.4786275319893558
Validation loss: 2.4407918109115982

Epoch: 6| Step: 3
Training loss: 1.6629322493946228
Validation loss: 2.473771655428831

Epoch: 6| Step: 4
Training loss: 1.778510077803197
Validation loss: 2.476043512221489

Epoch: 6| Step: 5
Training loss: 2.168788555583076
Validation loss: 2.516341849998505

Epoch: 6| Step: 6
Training loss: 1.4783777452325495
Validation loss: 2.528269948114593

Epoch: 6| Step: 7
Training loss: 1.9741219995398924
Validation loss: 2.5544288978271936

Epoch: 6| Step: 8
Training loss: 1.8619201935363365
Validation loss: 2.5653227039268565

Epoch: 6| Step: 9
Training loss: 1.9500352758493589
Validation loss: 2.5550736464779105

Epoch: 6| Step: 10
Training loss: 1.9565463198163529
Validation loss: 2.5529004220211324

Epoch: 6| Step: 11
Training loss: 1.9714364387817256
Validation loss: 2.5528471974877447

Epoch: 6| Step: 12
Training loss: 1.7069395551343352
Validation loss: 2.558548058642992

Epoch: 6| Step: 13
Training loss: 2.0482546983011045
Validation loss: 2.549431106064274

Epoch: 413| Step: 0
Training loss: 1.0014784136391706
Validation loss: 2.54999837451057

Epoch: 6| Step: 1
Training loss: 1.3368204779294364
Validation loss: 2.5573863096405023

Epoch: 6| Step: 2
Training loss: 1.706037358598312
Validation loss: 2.5388730022435144

Epoch: 6| Step: 3
Training loss: 1.859287099603784
Validation loss: 2.528093641540863

Epoch: 6| Step: 4
Training loss: 2.0057006892029503
Validation loss: 2.5472926714539796

Epoch: 6| Step: 5
Training loss: 2.0195800067026064
Validation loss: 2.569916359348102

Epoch: 6| Step: 6
Training loss: 2.1054937753977154
Validation loss: 2.5713583029912104

Epoch: 6| Step: 7
Training loss: 2.1229022274206364
Validation loss: 2.5913736206261158

Epoch: 6| Step: 8
Training loss: 2.2201991117384403
Validation loss: 2.6186263724224137

Epoch: 6| Step: 9
Training loss: 1.8061751802253256
Validation loss: 2.591956786716301

Epoch: 6| Step: 10
Training loss: 2.1533814298299374
Validation loss: 2.569142431583551

Epoch: 6| Step: 11
Training loss: 1.4062426248992803
Validation loss: 2.563854405837668

Epoch: 6| Step: 12
Training loss: 1.6094462554860587
Validation loss: 2.547610825534499

Epoch: 6| Step: 13
Training loss: 1.1683818380070643
Validation loss: 2.514932107859786

Epoch: 414| Step: 0
Training loss: 2.050210230212411
Validation loss: 2.5276802491843555

Epoch: 6| Step: 1
Training loss: 2.057161647374001
Validation loss: 2.4987963065464225

Epoch: 6| Step: 2
Training loss: 1.413176875691265
Validation loss: 2.502154746583674

Epoch: 6| Step: 3
Training loss: 1.886916630005499
Validation loss: 2.516461650500639

Epoch: 6| Step: 4
Training loss: 1.9609224235289455
Validation loss: 2.528543269575426

Epoch: 6| Step: 5
Training loss: 1.6729020146179199
Validation loss: 2.5171762344842463

Epoch: 6| Step: 6
Training loss: 2.175594082080881
Validation loss: 2.537738684519603

Epoch: 6| Step: 7
Training loss: 1.2366323473419134
Validation loss: 2.5509078730221084

Epoch: 6| Step: 8
Training loss: 1.621738167872634
Validation loss: 2.5643552361548454

Epoch: 6| Step: 9
Training loss: 1.6714902773844504
Validation loss: 2.571489850600951

Epoch: 6| Step: 10
Training loss: 1.5021523292698415
Validation loss: 2.5797978507350807

Epoch: 6| Step: 11
Training loss: 2.0815154218539953
Validation loss: 2.571786943762661

Epoch: 6| Step: 12
Training loss: 1.8527601529410578
Validation loss: 2.5665493741048064

Epoch: 6| Step: 13
Training loss: 1.617578063095228
Validation loss: 2.528875880589495

Epoch: 415| Step: 0
Training loss: 1.5230836114906998
Validation loss: 2.557315302426042

Epoch: 6| Step: 1
Training loss: 1.6009345335433078
Validation loss: 2.533908383360494

Epoch: 6| Step: 2
Training loss: 1.9472163432321699
Validation loss: 2.5084927464056124

Epoch: 6| Step: 3
Training loss: 1.723132493670762
Validation loss: 2.5391874710766924

Epoch: 6| Step: 4
Training loss: 1.84076669144384
Validation loss: 2.5335551402274032

Epoch: 6| Step: 5
Training loss: 1.7654408046550898
Validation loss: 2.550176236824345

Epoch: 6| Step: 6
Training loss: 1.7079974829054427
Validation loss: 2.56249292084051

Epoch: 6| Step: 7
Training loss: 2.0724093201313383
Validation loss: 2.5513644269222278

Epoch: 6| Step: 8
Training loss: 1.655488468933041
Validation loss: 2.5869802170771967

Epoch: 6| Step: 9
Training loss: 1.8145150131987828
Validation loss: 2.5709160322679048

Epoch: 6| Step: 10
Training loss: 2.094200313594832
Validation loss: 2.5417670766872695

Epoch: 6| Step: 11
Training loss: 1.502171375306358
Validation loss: 2.499375267315481

Epoch: 6| Step: 12
Training loss: 1.9092893915292357
Validation loss: 2.493483332615401

Epoch: 6| Step: 13
Training loss: 1.6198913527189556
Validation loss: 2.4718134616534377

Epoch: 416| Step: 0
Training loss: 1.745542230060808
Validation loss: 2.4877663073080747

Epoch: 6| Step: 1
Training loss: 1.6076306268943394
Validation loss: 2.4648260082103444

Epoch: 6| Step: 2
Training loss: 1.5196698672263773
Validation loss: 2.5045289383951137

Epoch: 6| Step: 3
Training loss: 1.6771438145443303
Validation loss: 2.5276587789295175

Epoch: 6| Step: 4
Training loss: 1.9860623612308235
Validation loss: 2.5152219626417494

Epoch: 6| Step: 5
Training loss: 2.387454754465592
Validation loss: 2.540524634825425

Epoch: 6| Step: 6
Training loss: 1.4235034043834458
Validation loss: 2.5772234700560372

Epoch: 6| Step: 7
Training loss: 1.817322661866454
Validation loss: 2.6019167493993947

Epoch: 6| Step: 8
Training loss: 1.824098244062446
Validation loss: 2.604546888753253

Epoch: 6| Step: 9
Training loss: 1.4741128451864287
Validation loss: 2.605248917343179

Epoch: 6| Step: 10
Training loss: 1.6557118243228912
Validation loss: 2.596781520104523

Epoch: 6| Step: 11
Training loss: 1.580074503626876
Validation loss: 2.6026414282484907

Epoch: 6| Step: 12
Training loss: 2.0295865803943656
Validation loss: 2.5791178556864933

Epoch: 6| Step: 13
Training loss: 1.9382097728485619
Validation loss: 2.585212370151668

Epoch: 417| Step: 0
Training loss: 1.6075034509031474
Validation loss: 2.589366145137284

Epoch: 6| Step: 1
Training loss: 1.810670455451582
Validation loss: 2.5601725589545246

Epoch: 6| Step: 2
Training loss: 1.5446186756789604
Validation loss: 2.5749203540301404

Epoch: 6| Step: 3
Training loss: 1.7753982124124517
Validation loss: 2.5761004571004835

Epoch: 6| Step: 4
Training loss: 1.974221150827401
Validation loss: 2.5398208644234566

Epoch: 6| Step: 5
Training loss: 2.1700833841643217
Validation loss: 2.5622232239139024

Epoch: 6| Step: 6
Training loss: 1.2737902755284654
Validation loss: 2.5655117788976844

Epoch: 6| Step: 7
Training loss: 1.8849269027095852
Validation loss: 2.5675223180663154

Epoch: 6| Step: 8
Training loss: 2.0735059759910754
Validation loss: 2.5490943785655733

Epoch: 6| Step: 9
Training loss: 1.321636416500756
Validation loss: 2.519774764282879

Epoch: 6| Step: 10
Training loss: 1.7954165967172695
Validation loss: 2.536658873148354

Epoch: 6| Step: 11
Training loss: 1.2710524615033791
Validation loss: 2.527618112840011

Epoch: 6| Step: 12
Training loss: 2.134187695172357
Validation loss: 2.5551186820790566

Epoch: 6| Step: 13
Training loss: 1.887802602498568
Validation loss: 2.574451994972191

Epoch: 418| Step: 0
Training loss: 1.6154191673691727
Validation loss: 2.546678147068099

Epoch: 6| Step: 1
Training loss: 1.889835602710031
Validation loss: 2.5863898012805757

Epoch: 6| Step: 2
Training loss: 2.1423693601290434
Validation loss: 2.5752571480530095

Epoch: 6| Step: 3
Training loss: 1.0838729113757855
Validation loss: 2.5514275745321373

Epoch: 6| Step: 4
Training loss: 1.958705041657897
Validation loss: 2.543703384458056

Epoch: 6| Step: 5
Training loss: 1.3495059380868848
Validation loss: 2.579865315653147

Epoch: 6| Step: 6
Training loss: 1.5640082137436078
Validation loss: 2.527426329863424

Epoch: 6| Step: 7
Training loss: 1.6182603456333562
Validation loss: 2.535089981843858

Epoch: 6| Step: 8
Training loss: 1.9405671115663066
Validation loss: 2.567346859728589

Epoch: 6| Step: 9
Training loss: 1.7938153298207706
Validation loss: 2.572579340356277

Epoch: 6| Step: 10
Training loss: 1.942569622034226
Validation loss: 2.549003043698846

Epoch: 6| Step: 11
Training loss: 1.8818457563111448
Validation loss: 2.563575297917731

Epoch: 6| Step: 12
Training loss: 2.0220169324156476
Validation loss: 2.5567285084590794

Epoch: 6| Step: 13
Training loss: 1.4086770200738548
Validation loss: 2.5433024833321074

Epoch: 419| Step: 0
Training loss: 1.3378423306178564
Validation loss: 2.563262727896557

Epoch: 6| Step: 1
Training loss: 1.344935448738979
Validation loss: 2.572155020725787

Epoch: 6| Step: 2
Training loss: 1.7516419337396083
Validation loss: 2.5483017858231887

Epoch: 6| Step: 3
Training loss: 1.10548115106643
Validation loss: 2.569322383575136

Epoch: 6| Step: 4
Training loss: 2.143439676940231
Validation loss: 2.575633752897898

Epoch: 6| Step: 5
Training loss: 2.1032414306335463
Validation loss: 2.571702010243262

Epoch: 6| Step: 6
Training loss: 1.6564703740753135
Validation loss: 2.5518609625393003

Epoch: 6| Step: 7
Training loss: 1.5215544972157378
Validation loss: 2.542740609238478

Epoch: 6| Step: 8
Training loss: 1.9410547440997858
Validation loss: 2.548890979397158

Epoch: 6| Step: 9
Training loss: 1.9778830598759654
Validation loss: 2.5302156476822706

Epoch: 6| Step: 10
Training loss: 1.6449159004720741
Validation loss: 2.4928359422073556

Epoch: 6| Step: 11
Training loss: 1.8437696552845333
Validation loss: 2.4830817805505947

Epoch: 6| Step: 12
Training loss: 1.8465472193531314
Validation loss: 2.467030867595675

Epoch: 6| Step: 13
Training loss: 1.8827101810242652
Validation loss: 2.473722157800878

Epoch: 420| Step: 0
Training loss: 1.543464445816183
Validation loss: 2.4980660669774757

Epoch: 6| Step: 1
Training loss: 1.5050914503428898
Validation loss: 2.5586549637770686

Epoch: 6| Step: 2
Training loss: 2.114686171062103
Validation loss: 2.5553188912889064

Epoch: 6| Step: 3
Training loss: 1.9977468076968523
Validation loss: 2.5592584153241225

Epoch: 6| Step: 4
Training loss: 1.5024947242834612
Validation loss: 2.5697457134053847

Epoch: 6| Step: 5
Training loss: 1.7997186467369615
Validation loss: 2.565506915942433

Epoch: 6| Step: 6
Training loss: 1.3515884749722438
Validation loss: 2.56429735763481

Epoch: 6| Step: 7
Training loss: 1.9994882286471238
Validation loss: 2.597439194310353

Epoch: 6| Step: 8
Training loss: 0.8792087288748608
Validation loss: 2.584901181757194

Epoch: 6| Step: 9
Training loss: 1.8366845092437547
Validation loss: 2.5778739282409178

Epoch: 6| Step: 10
Training loss: 1.8921715582153205
Validation loss: 2.5595335528727534

Epoch: 6| Step: 11
Training loss: 1.9753922326487057
Validation loss: 2.5724687117007825

Epoch: 6| Step: 12
Training loss: 1.6964878631211622
Validation loss: 2.544168981090217

Epoch: 6| Step: 13
Training loss: 1.9101458278129846
Validation loss: 2.538211679831933

Epoch: 421| Step: 0
Training loss: 1.296500416168252
Validation loss: 2.5121804391012477

Epoch: 6| Step: 1
Training loss: 1.7236823315301741
Validation loss: 2.4920373949150583

Epoch: 6| Step: 2
Training loss: 1.406151577366275
Validation loss: 2.49756487823521

Epoch: 6| Step: 3
Training loss: 2.010418340125565
Validation loss: 2.4919009930417038

Epoch: 6| Step: 4
Training loss: 1.7747601521662821
Validation loss: 2.5444002995907664

Epoch: 6| Step: 5
Training loss: 1.5313994665572648
Validation loss: 2.4945924151714762

Epoch: 6| Step: 6
Training loss: 1.2691020533511355
Validation loss: 2.5535628416055465

Epoch: 6| Step: 7
Training loss: 1.9641060932817513
Validation loss: 2.571072191345501

Epoch: 6| Step: 8
Training loss: 2.0571964161387153
Validation loss: 2.5577612178631783

Epoch: 6| Step: 9
Training loss: 1.7984515364403235
Validation loss: 2.5865625386290123

Epoch: 6| Step: 10
Training loss: 1.8848969883180446
Validation loss: 2.534616259846755

Epoch: 6| Step: 11
Training loss: 1.632708021407856
Validation loss: 2.580337969764936

Epoch: 6| Step: 12
Training loss: 1.9474288887292148
Validation loss: 2.6050871221977117

Epoch: 6| Step: 13
Training loss: 1.7306256018651685
Validation loss: 2.566895139977302

Epoch: 422| Step: 0
Training loss: 1.8409871235759263
Validation loss: 2.5877322828996316

Epoch: 6| Step: 1
Training loss: 1.7777190430528427
Validation loss: 2.601875651181735

Epoch: 6| Step: 2
Training loss: 1.7299364360531932
Validation loss: 2.6264651429185997

Epoch: 6| Step: 3
Training loss: 1.8648782280242553
Validation loss: 2.6661394512032808

Epoch: 6| Step: 4
Training loss: 1.783615081432305
Validation loss: 2.6720374033477405

Epoch: 6| Step: 5
Training loss: 2.1133852666897783
Validation loss: 2.646116616687966

Epoch: 6| Step: 6
Training loss: 1.4610437364761673
Validation loss: 2.604673447714895

Epoch: 6| Step: 7
Training loss: 1.525249245083667
Validation loss: 2.5652107359467133

Epoch: 6| Step: 8
Training loss: 1.1023572395088717
Validation loss: 2.5845795449492464

Epoch: 6| Step: 9
Training loss: 1.6367229015507088
Validation loss: 2.5184751626885116

Epoch: 6| Step: 10
Training loss: 1.9287173654956176
Validation loss: 2.4752244498083877

Epoch: 6| Step: 11
Training loss: 1.240608411240833
Validation loss: 2.4884926504978804

Epoch: 6| Step: 12
Training loss: 2.11067261519872
Validation loss: 2.493539201942162

Epoch: 6| Step: 13
Training loss: 1.963121998373832
Validation loss: 2.4659667197516244

Epoch: 423| Step: 0
Training loss: 1.5252809765978894
Validation loss: 2.48017638517191

Epoch: 6| Step: 1
Training loss: 2.0704711853247932
Validation loss: 2.469762603541295

Epoch: 6| Step: 2
Training loss: 1.507067797876675
Validation loss: 2.510354741620769

Epoch: 6| Step: 3
Training loss: 1.8307976382073006
Validation loss: 2.4959005656950044

Epoch: 6| Step: 4
Training loss: 1.63066405080324
Validation loss: 2.5394430754040855

Epoch: 6| Step: 5
Training loss: 1.9401572064482384
Validation loss: 2.5254756339402853

Epoch: 6| Step: 6
Training loss: 1.8003655406870527
Validation loss: 2.5175837205322686

Epoch: 6| Step: 7
Training loss: 1.4140755247074752
Validation loss: 2.4822072639182564

Epoch: 6| Step: 8
Training loss: 1.6123852770308011
Validation loss: 2.512722365970752

Epoch: 6| Step: 9
Training loss: 2.02407308486496
Validation loss: 2.5296402986658637

Epoch: 6| Step: 10
Training loss: 1.510506077016446
Validation loss: 2.5552637256240303

Epoch: 6| Step: 11
Training loss: 1.6610883183157714
Validation loss: 2.5728137283953108

Epoch: 6| Step: 12
Training loss: 1.799627700026762
Validation loss: 2.5766713488834645

Epoch: 6| Step: 13
Training loss: 1.4617905191879974
Validation loss: 2.596660892650702

Epoch: 424| Step: 0
Training loss: 1.3874833698822588
Validation loss: 2.6146566173750263

Epoch: 6| Step: 1
Training loss: 1.5439053167752057
Validation loss: 2.6125337618839315

Epoch: 6| Step: 2
Training loss: 1.663287129891226
Validation loss: 2.59893395637708

Epoch: 6| Step: 3
Training loss: 1.4152328116365918
Validation loss: 2.5833734898881415

Epoch: 6| Step: 4
Training loss: 1.779561497327984
Validation loss: 2.5815678722239004

Epoch: 6| Step: 5
Training loss: 1.6219521329615902
Validation loss: 2.5803857203145193

Epoch: 6| Step: 6
Training loss: 1.8900133514941881
Validation loss: 2.5609212264292878

Epoch: 6| Step: 7
Training loss: 2.043778968162439
Validation loss: 2.6006983184847665

Epoch: 6| Step: 8
Training loss: 1.9440879797787232
Validation loss: 2.56970939862853

Epoch: 6| Step: 9
Training loss: 1.7279268285659348
Validation loss: 2.557434838573659

Epoch: 6| Step: 10
Training loss: 1.5844948506968288
Validation loss: 2.5645110120004446

Epoch: 6| Step: 11
Training loss: 1.8861349715139217
Validation loss: 2.5537555699855923

Epoch: 6| Step: 12
Training loss: 1.6485471282229598
Validation loss: 2.537873319277485

Epoch: 6| Step: 13
Training loss: 1.6540883911343507
Validation loss: 2.5081819324741033

Epoch: 425| Step: 0
Training loss: 1.2709811338349566
Validation loss: 2.521154313248976

Epoch: 6| Step: 1
Training loss: 1.279905590807625
Validation loss: 2.53551717277489

Epoch: 6| Step: 2
Training loss: 1.870174301510366
Validation loss: 2.5463140430952746

Epoch: 6| Step: 3
Training loss: 1.762773625121522
Validation loss: 2.536933816120159

Epoch: 6| Step: 4
Training loss: 1.8378480101619994
Validation loss: 2.53494124508338

Epoch: 6| Step: 5
Training loss: 1.7459302992131998
Validation loss: 2.546370003699205

Epoch: 6| Step: 6
Training loss: 2.000226246434705
Validation loss: 2.542452472013408

Epoch: 6| Step: 7
Training loss: 1.698748854636058
Validation loss: 2.545840750617126

Epoch: 6| Step: 8
Training loss: 1.0247133761411005
Validation loss: 2.5397445971605257

Epoch: 6| Step: 9
Training loss: 1.6917424033112656
Validation loss: 2.5515148287220515

Epoch: 6| Step: 10
Training loss: 1.870944023114581
Validation loss: 2.526258865286253

Epoch: 6| Step: 11
Training loss: 2.007205143957438
Validation loss: 2.5717879904365017

Epoch: 6| Step: 12
Training loss: 1.5957489940909673
Validation loss: 2.584388318685748

Epoch: 6| Step: 13
Training loss: 1.6287926650296216
Validation loss: 2.590269746472588

Epoch: 426| Step: 0
Training loss: 1.326773415772351
Validation loss: 2.5785679689905487

Epoch: 6| Step: 1
Training loss: 1.3694667454972045
Validation loss: 2.5968764304160623

Epoch: 6| Step: 2
Training loss: 1.3517105374270306
Validation loss: 2.561115930570052

Epoch: 6| Step: 3
Training loss: 1.7885015016229013
Validation loss: 2.583526996719502

Epoch: 6| Step: 4
Training loss: 2.0281747867721465
Validation loss: 2.6100153366692482

Epoch: 6| Step: 5
Training loss: 1.75089738180649
Validation loss: 2.615699502038254

Epoch: 6| Step: 6
Training loss: 1.446847379021209
Validation loss: 2.6360967801744075

Epoch: 6| Step: 7
Training loss: 1.5411472820323733
Validation loss: 2.628830845550802

Epoch: 6| Step: 8
Training loss: 1.7424462643715621
Validation loss: 2.609573898020027

Epoch: 6| Step: 9
Training loss: 1.6281153819556062
Validation loss: 2.5972412764821824

Epoch: 6| Step: 10
Training loss: 2.1327731509648564
Validation loss: 2.5626383718312105

Epoch: 6| Step: 11
Training loss: 1.7894197465456205
Validation loss: 2.529928504805579

Epoch: 6| Step: 12
Training loss: 1.6837428617715504
Validation loss: 2.51928339040544

Epoch: 6| Step: 13
Training loss: 1.8278914734450833
Validation loss: 2.5227219854155347

Epoch: 427| Step: 0
Training loss: 1.93422280299835
Validation loss: 2.570777776398413

Epoch: 6| Step: 1
Training loss: 2.1333887907608275
Validation loss: 2.520058409988436

Epoch: 6| Step: 2
Training loss: 1.6336898271939662
Validation loss: 2.571057323402013

Epoch: 6| Step: 3
Training loss: 1.9324492795538246
Validation loss: 2.540084908157665

Epoch: 6| Step: 4
Training loss: 2.0704137237562716
Validation loss: 2.5859547856028904

Epoch: 6| Step: 5
Training loss: 1.6398168844245902
Validation loss: 2.5735110643807744

Epoch: 6| Step: 6
Training loss: 1.0550119536748628
Validation loss: 2.585162015367088

Epoch: 6| Step: 7
Training loss: 1.3602727797370566
Validation loss: 2.566311198777647

Epoch: 6| Step: 8
Training loss: 2.1742854292826235
Validation loss: 2.558407511097868

Epoch: 6| Step: 9
Training loss: 1.3827340917394628
Validation loss: 2.538105162060801

Epoch: 6| Step: 10
Training loss: 1.385638608818348
Validation loss: 2.5599802545938357

Epoch: 6| Step: 11
Training loss: 1.491130034744649
Validation loss: 2.55284504843892

Epoch: 6| Step: 12
Training loss: 1.3915390696631507
Validation loss: 2.5288192946197854

Epoch: 6| Step: 13
Training loss: 0.6714369654493095
Validation loss: 2.5698732355513063

Epoch: 428| Step: 0
Training loss: 2.1571505227940686
Validation loss: 2.572913868124449

Epoch: 6| Step: 1
Training loss: 1.0938908077610852
Validation loss: 2.5688415192076257

Epoch: 6| Step: 2
Training loss: 1.2940471105298408
Validation loss: 2.55904782068934

Epoch: 6| Step: 3
Training loss: 1.660674249954602
Validation loss: 2.5949023528921185

Epoch: 6| Step: 4
Training loss: 1.672771320545227
Validation loss: 2.584036095054417

Epoch: 6| Step: 5
Training loss: 1.8340758929508658
Validation loss: 2.5589087056874478

Epoch: 6| Step: 6
Training loss: 1.9363904667850327
Validation loss: 2.5782873207618895

Epoch: 6| Step: 7
Training loss: 1.3190885208769818
Validation loss: 2.5878223301053858

Epoch: 6| Step: 8
Training loss: 1.6308010433523974
Validation loss: 2.588768069913654

Epoch: 6| Step: 9
Training loss: 1.81462301684615
Validation loss: 2.5552919486899013

Epoch: 6| Step: 10
Training loss: 1.6305634555628883
Validation loss: 2.5846012823139874

Epoch: 6| Step: 11
Training loss: 1.5123067495929858
Validation loss: 2.5967288089738476

Epoch: 6| Step: 12
Training loss: 1.6107647274989405
Validation loss: 2.543762190614895

Epoch: 6| Step: 13
Training loss: 1.9371316621194075
Validation loss: 2.5773662177673393

Epoch: 429| Step: 0
Training loss: 1.270642777002873
Validation loss: 2.577699777209583

Epoch: 6| Step: 1
Training loss: 1.7682116305830518
Validation loss: 2.5777888153733546

Epoch: 6| Step: 2
Training loss: 1.725606800551227
Validation loss: 2.5464706880080987

Epoch: 6| Step: 3
Training loss: 1.9726655563286049
Validation loss: 2.555675896292634

Epoch: 6| Step: 4
Training loss: 1.3225375956507965
Validation loss: 2.527872968225588

Epoch: 6| Step: 5
Training loss: 2.13488758014524
Validation loss: 2.5215069663911267

Epoch: 6| Step: 6
Training loss: 1.3676971793415995
Validation loss: 2.508407040301654

Epoch: 6| Step: 7
Training loss: 1.5818319312856342
Validation loss: 2.549884092820141

Epoch: 6| Step: 8
Training loss: 1.7671727511248343
Validation loss: 2.486809155456314

Epoch: 6| Step: 9
Training loss: 1.0945970797295754
Validation loss: 2.482563206635171

Epoch: 6| Step: 10
Training loss: 1.4490381010007485
Validation loss: 2.4822572347413097

Epoch: 6| Step: 11
Training loss: 2.0866013517100606
Validation loss: 2.498141576294857

Epoch: 6| Step: 12
Training loss: 1.558401377955186
Validation loss: 2.530201650142821

Epoch: 6| Step: 13
Training loss: 1.685371610827491
Validation loss: 2.583176597844729

Epoch: 430| Step: 0
Training loss: 1.110555477424336
Validation loss: 2.5876183619333952

Epoch: 6| Step: 1
Training loss: 1.989758435544546
Validation loss: 2.6046027414418367

Epoch: 6| Step: 2
Training loss: 1.367486670322763
Validation loss: 2.6292718348106616

Epoch: 6| Step: 3
Training loss: 2.0189112406960437
Validation loss: 2.66429459304192

Epoch: 6| Step: 4
Training loss: 1.1975268628127735
Validation loss: 2.6555848275035263

Epoch: 6| Step: 5
Training loss: 1.3847767300826312
Validation loss: 2.6317513541041793

Epoch: 6| Step: 6
Training loss: 1.600733025840499
Validation loss: 2.6238612416547937

Epoch: 6| Step: 7
Training loss: 2.089643978660013
Validation loss: 2.587742751500259

Epoch: 6| Step: 8
Training loss: 1.8183368882244453
Validation loss: 2.5423615620421773

Epoch: 6| Step: 9
Training loss: 1.9844351331355432
Validation loss: 2.573432806491784

Epoch: 6| Step: 10
Training loss: 2.067891097619449
Validation loss: 2.5338438147015214

Epoch: 6| Step: 11
Training loss: 0.9233845135611943
Validation loss: 2.4858896595651987

Epoch: 6| Step: 12
Training loss: 1.4092795058418814
Validation loss: 2.4478560992419043

Epoch: 6| Step: 13
Training loss: 1.3311647969949956
Validation loss: 2.482775176612173

Epoch: 431| Step: 0
Training loss: 1.3610539646002793
Validation loss: 2.4822430060071685

Epoch: 6| Step: 1
Training loss: 1.8808829522957606
Validation loss: 2.5054205232676585

Epoch: 6| Step: 2
Training loss: 1.37623722593666
Validation loss: 2.535412801686237

Epoch: 6| Step: 3
Training loss: 1.5403453302241623
Validation loss: 2.5579475434085066

Epoch: 6| Step: 4
Training loss: 1.446221225752315
Validation loss: 2.570108092819853

Epoch: 6| Step: 5
Training loss: 1.6630360477690191
Validation loss: 2.562418464425937

Epoch: 6| Step: 6
Training loss: 1.8161571044688818
Validation loss: 2.605382019617509

Epoch: 6| Step: 7
Training loss: 1.6926637692576296
Validation loss: 2.5941871178860767

Epoch: 6| Step: 8
Training loss: 1.4142279765218289
Validation loss: 2.5519438128896383

Epoch: 6| Step: 9
Training loss: 1.6876555477084718
Validation loss: 2.56111734246011

Epoch: 6| Step: 10
Training loss: 1.518434889014512
Validation loss: 2.587158259978454

Epoch: 6| Step: 11
Training loss: 1.440755557683485
Validation loss: 2.5799710542775784

Epoch: 6| Step: 12
Training loss: 1.8378040970349285
Validation loss: 2.5666624178516306

Epoch: 6| Step: 13
Training loss: 2.3579835135778993
Validation loss: 2.5858657906777287

Epoch: 432| Step: 0
Training loss: 1.6163200226357155
Validation loss: 2.5584996229697716

Epoch: 6| Step: 1
Training loss: 1.6725883031778892
Validation loss: 2.572540392859561

Epoch: 6| Step: 2
Training loss: 1.4175868505281373
Validation loss: 2.542325534750475

Epoch: 6| Step: 3
Training loss: 1.391572864972741
Validation loss: 2.5338083381168888

Epoch: 6| Step: 4
Training loss: 1.6315555388677125
Validation loss: 2.543834060384995

Epoch: 6| Step: 5
Training loss: 1.4774418387285373
Validation loss: 2.525972111950284

Epoch: 6| Step: 6
Training loss: 1.4819969804709867
Validation loss: 2.5809752697312733

Epoch: 6| Step: 7
Training loss: 1.7203065932724222
Validation loss: 2.5782037349448004

Epoch: 6| Step: 8
Training loss: 1.7753575220158877
Validation loss: 2.5457295581737247

Epoch: 6| Step: 9
Training loss: 2.1946810971655117
Validation loss: 2.547880965419498

Epoch: 6| Step: 10
Training loss: 1.5724065681925876
Validation loss: 2.5885608852548945

Epoch: 6| Step: 11
Training loss: 1.7784976776511126
Validation loss: 2.5723595263630457

Epoch: 6| Step: 12
Training loss: 1.2380200901866454
Validation loss: 2.5249276231131237

Epoch: 6| Step: 13
Training loss: 1.652198947486593
Validation loss: 2.546029910011147

Epoch: 433| Step: 0
Training loss: 1.4783561348402074
Validation loss: 2.5489248983219936

Epoch: 6| Step: 1
Training loss: 1.826042750072285
Validation loss: 2.50716238610612

Epoch: 6| Step: 2
Training loss: 1.5626013913636536
Validation loss: 2.524409866289851

Epoch: 6| Step: 3
Training loss: 2.3265060838119287
Validation loss: 2.5296786439340018

Epoch: 6| Step: 4
Training loss: 0.6993593255775991
Validation loss: 2.5490173262077507

Epoch: 6| Step: 5
Training loss: 1.4679168610794209
Validation loss: 2.5312433864315182

Epoch: 6| Step: 6
Training loss: 1.9179093299254115
Validation loss: 2.5020152849684134

Epoch: 6| Step: 7
Training loss: 2.232738188781012
Validation loss: 2.554177814332112

Epoch: 6| Step: 8
Training loss: 1.1444275063636742
Validation loss: 2.5693666550747896

Epoch: 6| Step: 9
Training loss: 1.6741005888311067
Validation loss: 2.587224778902379

Epoch: 6| Step: 10
Training loss: 1.2607857765327348
Validation loss: 2.5642659434896315

Epoch: 6| Step: 11
Training loss: 1.4749042544566928
Validation loss: 2.5776150305639574

Epoch: 6| Step: 12
Training loss: 1.29181995815328
Validation loss: 2.576984558240563

Epoch: 6| Step: 13
Training loss: 1.6114189723442978
Validation loss: 2.5587411138710063

Epoch: 434| Step: 0
Training loss: 1.7942662416647601
Validation loss: 2.53349901192163

Epoch: 6| Step: 1
Training loss: 1.7313193820312431
Validation loss: 2.5481984383886838

Epoch: 6| Step: 2
Training loss: 1.6447238401601758
Validation loss: 2.537963167776028

Epoch: 6| Step: 3
Training loss: 1.7205337978015547
Validation loss: 2.549003911654456

Epoch: 6| Step: 4
Training loss: 1.2811249462599998
Validation loss: 2.502142067458497

Epoch: 6| Step: 5
Training loss: 1.6584995036361636
Validation loss: 2.5407553416971926

Epoch: 6| Step: 6
Training loss: 1.469906047621282
Validation loss: 2.512973556741199

Epoch: 6| Step: 7
Training loss: 1.6779006324963759
Validation loss: 2.538579339312021

Epoch: 6| Step: 8
Training loss: 1.8221854859748063
Validation loss: 2.5286508724478036

Epoch: 6| Step: 9
Training loss: 2.0916345641976957
Validation loss: 2.53109043093887

Epoch: 6| Step: 10
Training loss: 1.2889054173792762
Validation loss: 2.558061110592364

Epoch: 6| Step: 11
Training loss: 1.2190208134176923
Validation loss: 2.5907361118115997

Epoch: 6| Step: 12
Training loss: 1.207936561598714
Validation loss: 2.5833208068586297

Epoch: 6| Step: 13
Training loss: 1.6247740368360049
Validation loss: 2.6052116892899053

Epoch: 435| Step: 0
Training loss: 1.9711580838270601
Validation loss: 2.6030511828846135

Epoch: 6| Step: 1
Training loss: 0.8892762864018534
Validation loss: 2.588682069402175

Epoch: 6| Step: 2
Training loss: 1.1790426651868335
Validation loss: 2.590992785146092

Epoch: 6| Step: 3
Training loss: 1.3376345201386486
Validation loss: 2.5657992789370216

Epoch: 6| Step: 4
Training loss: 1.4276269958444734
Validation loss: 2.5694957015950117

Epoch: 6| Step: 5
Training loss: 1.6999242260819056
Validation loss: 2.533851932035255

Epoch: 6| Step: 6
Training loss: 1.780047362051083
Validation loss: 2.5351589024699885

Epoch: 6| Step: 7
Training loss: 1.9424455343929858
Validation loss: 2.561580600070763

Epoch: 6| Step: 8
Training loss: 1.6631431368154628
Validation loss: 2.532323686791754

Epoch: 6| Step: 9
Training loss: 1.6533793637702696
Validation loss: 2.5526569956443406

Epoch: 6| Step: 10
Training loss: 1.5658097118215366
Validation loss: 2.5573546171267068

Epoch: 6| Step: 11
Training loss: 1.5191529104531034
Validation loss: 2.5651073721680393

Epoch: 6| Step: 12
Training loss: 1.8032533966840567
Validation loss: 2.5285028630742525

Epoch: 6| Step: 13
Training loss: 1.7856880581155843
Validation loss: 2.542205907834916

Epoch: 436| Step: 0
Training loss: 1.4572598275484616
Validation loss: 2.5596919226975876

Epoch: 6| Step: 1
Training loss: 1.7561971065932267
Validation loss: 2.581776494861796

Epoch: 6| Step: 2
Training loss: 1.6915905435782659
Validation loss: 2.584497985798176

Epoch: 6| Step: 3
Training loss: 1.7039067985047547
Validation loss: 2.581336126321088

Epoch: 6| Step: 4
Training loss: 1.965215325533327
Validation loss: 2.596395016408312

Epoch: 6| Step: 5
Training loss: 0.9085289811512205
Validation loss: 2.561265107140736

Epoch: 6| Step: 6
Training loss: 1.4162949280039097
Validation loss: 2.5783108363041842

Epoch: 6| Step: 7
Training loss: 1.8573647539439084
Validation loss: 2.5512586622776467

Epoch: 6| Step: 8
Training loss: 1.6452343812603132
Validation loss: 2.5383110576421917

Epoch: 6| Step: 9
Training loss: 1.484489677416437
Validation loss: 2.535822803362938

Epoch: 6| Step: 10
Training loss: 1.6324590273004769
Validation loss: 2.498395926634037

Epoch: 6| Step: 11
Training loss: 1.7126247499790264
Validation loss: 2.498396710072442

Epoch: 6| Step: 12
Training loss: 1.590742377426443
Validation loss: 2.484332359228193

Epoch: 6| Step: 13
Training loss: 1.3975278570438887
Validation loss: 2.5164839813608713

Epoch: 437| Step: 0
Training loss: 1.0520176756864235
Validation loss: 2.493606120934155

Epoch: 6| Step: 1
Training loss: 1.9776893389081813
Validation loss: 2.5387752651307074

Epoch: 6| Step: 2
Training loss: 1.2584283399189327
Validation loss: 2.568913500168594

Epoch: 6| Step: 3
Training loss: 1.3214793269156555
Validation loss: 2.5651570702525386

Epoch: 6| Step: 4
Training loss: 1.7234604530500661
Validation loss: 2.578067360013335

Epoch: 6| Step: 5
Training loss: 1.6681804299319247
Validation loss: 2.6107149054457035

Epoch: 6| Step: 6
Training loss: 1.820034153167206
Validation loss: 2.5595487742129266

Epoch: 6| Step: 7
Training loss: 1.4663662335438872
Validation loss: 2.5784447475120427

Epoch: 6| Step: 8
Training loss: 1.7810352932208395
Validation loss: 2.5695366996322955

Epoch: 6| Step: 9
Training loss: 1.4718141450065652
Validation loss: 2.550963238405971

Epoch: 6| Step: 10
Training loss: 1.402491314703012
Validation loss: 2.525561075995112

Epoch: 6| Step: 11
Training loss: 1.7882768663425137
Validation loss: 2.5075435489736715

Epoch: 6| Step: 12
Training loss: 1.711588557144074
Validation loss: 2.535792645950208

Epoch: 6| Step: 13
Training loss: 1.8075364649723087
Validation loss: 2.514014866413604

Epoch: 438| Step: 0
Training loss: 1.4633845270944354
Validation loss: 2.4796781838616933

Epoch: 6| Step: 1
Training loss: 1.321009886260655
Validation loss: 2.5231007286150735

Epoch: 6| Step: 2
Training loss: 1.2835634326663021
Validation loss: 2.54135077591457

Epoch: 6| Step: 3
Training loss: 1.8553944783654825
Validation loss: 2.5431634062179933

Epoch: 6| Step: 4
Training loss: 1.4128103877311025
Validation loss: 2.5480466405338107

Epoch: 6| Step: 5
Training loss: 1.4209918119287253
Validation loss: 2.5173442715449474

Epoch: 6| Step: 6
Training loss: 1.4405606898850412
Validation loss: 2.5736798888206893

Epoch: 6| Step: 7
Training loss: 2.066097820606562
Validation loss: 2.5548531371121834

Epoch: 6| Step: 8
Training loss: 1.5369452615495165
Validation loss: 2.529960692879904

Epoch: 6| Step: 9
Training loss: 1.7560114471131953
Validation loss: 2.5343922069306277

Epoch: 6| Step: 10
Training loss: 1.4318030708858736
Validation loss: 2.5579196914061026

Epoch: 6| Step: 11
Training loss: 1.5873026867892983
Validation loss: 2.54365934861624

Epoch: 6| Step: 12
Training loss: 2.0960341562734937
Validation loss: 2.5450968002721135

Epoch: 6| Step: 13
Training loss: 0.8940040334060109
Validation loss: 2.5615104447369244

Epoch: 439| Step: 0
Training loss: 1.5664864612314515
Validation loss: 2.6157843486858927

Epoch: 6| Step: 1
Training loss: 1.4481597074351038
Validation loss: 2.587045730798141

Epoch: 6| Step: 2
Training loss: 2.3750333281738434
Validation loss: 2.619904911122702

Epoch: 6| Step: 3
Training loss: 1.5630249667428147
Validation loss: 2.6204827012398892

Epoch: 6| Step: 4
Training loss: 1.8730933349702599
Validation loss: 2.6453416125343803

Epoch: 6| Step: 5
Training loss: 1.6061278241073549
Validation loss: 2.619901701561012

Epoch: 6| Step: 6
Training loss: 1.2828548893679648
Validation loss: 2.6215896368430665

Epoch: 6| Step: 7
Training loss: 1.7441213506336317
Validation loss: 2.622719212847167

Epoch: 6| Step: 8
Training loss: 1.7282820894056337
Validation loss: 2.587692233944284

Epoch: 6| Step: 9
Training loss: 0.9834198935174854
Validation loss: 2.5630044528140754

Epoch: 6| Step: 10
Training loss: 0.8393829145931812
Validation loss: 2.528836729372738

Epoch: 6| Step: 11
Training loss: 1.793810412090739
Validation loss: 2.5177309371150316

Epoch: 6| Step: 12
Training loss: 1.2976654585225083
Validation loss: 2.4339169128505995

Epoch: 6| Step: 13
Training loss: 1.23744125034094
Validation loss: 2.4744924590235904

Epoch: 440| Step: 0
Training loss: 1.7514061727871768
Validation loss: 2.468653063145001

Epoch: 6| Step: 1
Training loss: 1.3264993928921571
Validation loss: 2.468369348291826

Epoch: 6| Step: 2
Training loss: 1.8673825980055572
Validation loss: 2.502664182177521

Epoch: 6| Step: 3
Training loss: 1.5882755577784742
Validation loss: 2.5218904238721205

Epoch: 6| Step: 4
Training loss: 1.7305543073252012
Validation loss: 2.512082352319743

Epoch: 6| Step: 5
Training loss: 1.2188703037453554
Validation loss: 2.50703313130153

Epoch: 6| Step: 6
Training loss: 1.837267779254003
Validation loss: 2.524736800437088

Epoch: 6| Step: 7
Training loss: 1.3480637086421337
Validation loss: 2.539444873374042

Epoch: 6| Step: 8
Training loss: 1.458290925998809
Validation loss: 2.5163780883342453

Epoch: 6| Step: 9
Training loss: 1.1394313680711776
Validation loss: 2.5525584575749423

Epoch: 6| Step: 10
Training loss: 1.437032872471086
Validation loss: 2.5523314592503756

Epoch: 6| Step: 11
Training loss: 1.957283171316743
Validation loss: 2.571827684978314

Epoch: 6| Step: 12
Training loss: 1.4329698748673056
Validation loss: 2.5873268062740693

Epoch: 6| Step: 13
Training loss: 1.5669600347353354
Validation loss: 2.599494557358917

Epoch: 441| Step: 0
Training loss: 1.3761339280383484
Validation loss: 2.607386823363807

Epoch: 6| Step: 1
Training loss: 1.5154337811528433
Validation loss: 2.600921533176384

Epoch: 6| Step: 2
Training loss: 1.7787307860461952
Validation loss: 2.6065454839963085

Epoch: 6| Step: 3
Training loss: 1.2988987953635664
Validation loss: 2.6231090123622223

Epoch: 6| Step: 4
Training loss: 1.6515646827127546
Validation loss: 2.609113484497618

Epoch: 6| Step: 5
Training loss: 2.0861629978550056
Validation loss: 2.5730432289351635

Epoch: 6| Step: 6
Training loss: 1.5610909020973782
Validation loss: 2.5667664361342633

Epoch: 6| Step: 7
Training loss: 1.300706374387562
Validation loss: 2.564990362442577

Epoch: 6| Step: 8
Training loss: 1.1262019941660169
Validation loss: 2.5261696193922867

Epoch: 6| Step: 9
Training loss: 1.137368924061081
Validation loss: 2.51300005633482

Epoch: 6| Step: 10
Training loss: 1.7638803149771713
Validation loss: 2.5319737187611002

Epoch: 6| Step: 11
Training loss: 2.0021358053084084
Validation loss: 2.529629898715209

Epoch: 6| Step: 12
Training loss: 1.4293752026943503
Validation loss: 2.503449343074534

Epoch: 6| Step: 13
Training loss: 1.1007891706800343
Validation loss: 2.528079814784179

Epoch: 442| Step: 0
Training loss: 1.9343056341253588
Validation loss: 2.494008575759039

Epoch: 6| Step: 1
Training loss: 1.290514596276429
Validation loss: 2.517953054166841

Epoch: 6| Step: 2
Training loss: 1.6125111069407627
Validation loss: 2.546866047436609

Epoch: 6| Step: 3
Training loss: 1.5405251770487933
Validation loss: 2.533684633621145

Epoch: 6| Step: 4
Training loss: 1.7874684791186595
Validation loss: 2.507773107347655

Epoch: 6| Step: 5
Training loss: 1.506903260581886
Validation loss: 2.529512099212546

Epoch: 6| Step: 6
Training loss: 1.1728749904150801
Validation loss: 2.5334368361452118

Epoch: 6| Step: 7
Training loss: 1.1097648902576436
Validation loss: 2.523483568027096

Epoch: 6| Step: 8
Training loss: 1.3956994898759687
Validation loss: 2.5197924671311633

Epoch: 6| Step: 9
Training loss: 1.7402571859694995
Validation loss: 2.5313839924424735

Epoch: 6| Step: 10
Training loss: 1.2981982546667514
Validation loss: 2.5019928382920615

Epoch: 6| Step: 11
Training loss: 1.6819834077359164
Validation loss: 2.5423700474599356

Epoch: 6| Step: 12
Training loss: 1.4743927044874776
Validation loss: 2.527377233857031

Epoch: 6| Step: 13
Training loss: 1.9356941298007022
Validation loss: 2.5718725134256233

Epoch: 443| Step: 0
Training loss: 1.642923253073838
Validation loss: 2.5544864539933547

Epoch: 6| Step: 1
Training loss: 1.2523980027201445
Validation loss: 2.5905535310317487

Epoch: 6| Step: 2
Training loss: 1.7776085960168326
Validation loss: 2.559176038187295

Epoch: 6| Step: 3
Training loss: 1.5176029473315844
Validation loss: 2.524243129332527

Epoch: 6| Step: 4
Training loss: 1.5088973021955463
Validation loss: 2.550336788021773

Epoch: 6| Step: 5
Training loss: 1.2696946728499292
Validation loss: 2.5482665054901066

Epoch: 6| Step: 6
Training loss: 1.9898813101103332
Validation loss: 2.514740665352182

Epoch: 6| Step: 7
Training loss: 1.8263024268174257
Validation loss: 2.5248307595666124

Epoch: 6| Step: 8
Training loss: 1.4223497038486885
Validation loss: 2.581676776356999

Epoch: 6| Step: 9
Training loss: 0.9182311312084132
Validation loss: 2.5716617275956715

Epoch: 6| Step: 10
Training loss: 1.5820529512400474
Validation loss: 2.5437958700436334

Epoch: 6| Step: 11
Training loss: 1.3900218898778536
Validation loss: 2.56843688815436

Epoch: 6| Step: 12
Training loss: 1.4635638940102977
Validation loss: 2.577218277561962

Epoch: 6| Step: 13
Training loss: 1.70957272238634
Validation loss: 2.561443196977141

Epoch: 444| Step: 0
Training loss: 1.8692679207404372
Validation loss: 2.5291763556318254

Epoch: 6| Step: 1
Training loss: 1.4228670620777701
Validation loss: 2.547367661558201

Epoch: 6| Step: 2
Training loss: 1.431403209365332
Validation loss: 2.517379467908676

Epoch: 6| Step: 3
Training loss: 1.567818858495132
Validation loss: 2.478376396162516

Epoch: 6| Step: 4
Training loss: 1.546725795755621
Validation loss: 2.4901405579638864

Epoch: 6| Step: 5
Training loss: 1.9099304440201148
Validation loss: 2.4680364680179734

Epoch: 6| Step: 6
Training loss: 1.2852045763199624
Validation loss: 2.48920105508202

Epoch: 6| Step: 7
Training loss: 1.6008273786877214
Validation loss: 2.4930958925459814

Epoch: 6| Step: 8
Training loss: 2.2423780406844314
Validation loss: 2.4740963096980715

Epoch: 6| Step: 9
Training loss: 1.0052343111519213
Validation loss: 2.5023738563078366

Epoch: 6| Step: 10
Training loss: 1.5218452153042643
Validation loss: 2.481853758539974

Epoch: 6| Step: 11
Training loss: 0.9271373875893494
Validation loss: 2.5349700261191592

Epoch: 6| Step: 12
Training loss: 1.2539361967984972
Validation loss: 2.5474057107973187

Epoch: 6| Step: 13
Training loss: 0.6672917554817375
Validation loss: 2.5858711958129015

Epoch: 445| Step: 0
Training loss: 1.1223218617621062
Validation loss: 2.611420330189598

Epoch: 6| Step: 1
Training loss: 1.5794244835924691
Validation loss: 2.5863281010519334

Epoch: 6| Step: 2
Training loss: 1.2192949397221509
Validation loss: 2.6100636895392224

Epoch: 6| Step: 3
Training loss: 1.6427826272165238
Validation loss: 2.609481367242611

Epoch: 6| Step: 4
Training loss: 1.7098701666459617
Validation loss: 2.5830910235268667

Epoch: 6| Step: 5
Training loss: 1.5330126990372734
Validation loss: 2.561257700266656

Epoch: 6| Step: 6
Training loss: 1.6589703801128202
Validation loss: 2.53653492158852

Epoch: 6| Step: 7
Training loss: 1.1963532348859471
Validation loss: 2.540498228587959

Epoch: 6| Step: 8
Training loss: 1.763524451700343
Validation loss: 2.515758605886224

Epoch: 6| Step: 9
Training loss: 1.5114816090294332
Validation loss: 2.494757856780926

Epoch: 6| Step: 10
Training loss: 1.4213920024431597
Validation loss: 2.5144782403140997

Epoch: 6| Step: 11
Training loss: 1.6306226729891438
Validation loss: 2.5007574748942036

Epoch: 6| Step: 12
Training loss: 1.3544619996241694
Validation loss: 2.505265950264872

Epoch: 6| Step: 13
Training loss: 1.9438951836730862
Validation loss: 2.550968926527854

Epoch: 446| Step: 0
Training loss: 1.6352247461661786
Validation loss: 2.5538543549844794

Epoch: 6| Step: 1
Training loss: 1.4666235119077227
Validation loss: 2.574013241732811

Epoch: 6| Step: 2
Training loss: 0.7423427218697248
Validation loss: 2.5638809454872735

Epoch: 6| Step: 3
Training loss: 2.076560212902592
Validation loss: 2.5736128136106897

Epoch: 6| Step: 4
Training loss: 1.6452911143710838
Validation loss: 2.5345700699900546

Epoch: 6| Step: 5
Training loss: 1.2703792615475766
Validation loss: 2.5268423844729355

Epoch: 6| Step: 6
Training loss: 1.0113182895457669
Validation loss: 2.5168201703144955

Epoch: 6| Step: 7
Training loss: 1.5469240123035484
Validation loss: 2.531257561525885

Epoch: 6| Step: 8
Training loss: 1.7496727228673357
Validation loss: 2.542101145269313

Epoch: 6| Step: 9
Training loss: 1.4898865220041784
Validation loss: 2.5334802259798828

Epoch: 6| Step: 10
Training loss: 1.7505312521965988
Validation loss: 2.527107921209829

Epoch: 6| Step: 11
Training loss: 1.6236319285068792
Validation loss: 2.548384991310437

Epoch: 6| Step: 12
Training loss: 1.3360067427687754
Validation loss: 2.506102861314895

Epoch: 6| Step: 13
Training loss: 1.390843577833866
Validation loss: 2.5095083208301934

Epoch: 447| Step: 0
Training loss: 1.3061994369430858
Validation loss: 2.5567164609480884

Epoch: 6| Step: 1
Training loss: 1.4093843920747893
Validation loss: 2.5524644213478327

Epoch: 6| Step: 2
Training loss: 1.5822823030932656
Validation loss: 2.5526325216714407

Epoch: 6| Step: 3
Training loss: 1.2035801014379528
Validation loss: 2.5202056457882094

Epoch: 6| Step: 4
Training loss: 1.522701379020128
Validation loss: 2.5279418077436673

Epoch: 6| Step: 5
Training loss: 1.8627324285706224
Validation loss: 2.527541949513736

Epoch: 6| Step: 6
Training loss: 1.3980760160416383
Validation loss: 2.5220530278043904

Epoch: 6| Step: 7
Training loss: 1.9951815975209328
Validation loss: 2.5304571601687287

Epoch: 6| Step: 8
Training loss: 1.6450884457264585
Validation loss: 2.4926806628749802

Epoch: 6| Step: 9
Training loss: 1.4149175766841737
Validation loss: 2.5134929308965677

Epoch: 6| Step: 10
Training loss: 1.8065218499807878
Validation loss: 2.496585237618805

Epoch: 6| Step: 11
Training loss: 1.0585014049609
Validation loss: 2.5277504489203713

Epoch: 6| Step: 12
Training loss: 1.4786975098658934
Validation loss: 2.506332722973339

Epoch: 6| Step: 13
Training loss: 0.49605866555934053
Validation loss: 2.5240909267969087

Epoch: 448| Step: 0
Training loss: 1.4797657930794874
Validation loss: 2.573445378440704

Epoch: 6| Step: 1
Training loss: 1.4663764767680407
Validation loss: 2.567284641921128

Epoch: 6| Step: 2
Training loss: 1.134909116828609
Validation loss: 2.5725394670732893

Epoch: 6| Step: 3
Training loss: 1.4998949331997984
Validation loss: 2.56960435863194

Epoch: 6| Step: 4
Training loss: 1.3569278394337552
Validation loss: 2.5748444239889783

Epoch: 6| Step: 5
Training loss: 1.457338684210649
Validation loss: 2.5988234251637343

Epoch: 6| Step: 6
Training loss: 1.607311370128904
Validation loss: 2.6097068838372746

Epoch: 6| Step: 7
Training loss: 1.4190756940700833
Validation loss: 2.6167051308822877

Epoch: 6| Step: 8
Training loss: 1.5637863204970512
Validation loss: 2.6101422517117414

Epoch: 6| Step: 9
Training loss: 1.1062605216177894
Validation loss: 2.607869206551516

Epoch: 6| Step: 10
Training loss: 1.2851551368963645
Validation loss: 2.566230729340334

Epoch: 6| Step: 11
Training loss: 1.6878682900248572
Validation loss: 2.5521168867110857

Epoch: 6| Step: 12
Training loss: 1.6563885468889148
Validation loss: 2.5288642528833205

Epoch: 6| Step: 13
Training loss: 2.114299535890272
Validation loss: 2.531126503696088

Epoch: 449| Step: 0
Training loss: 1.6682134444343164
Validation loss: 2.4971741004721597

Epoch: 6| Step: 1
Training loss: 1.418519640803043
Validation loss: 2.4900504540846433

Epoch: 6| Step: 2
Training loss: 1.5409118075869839
Validation loss: 2.5049090517611883

Epoch: 6| Step: 3
Training loss: 1.1856875391157777
Validation loss: 2.505010879557164

Epoch: 6| Step: 4
Training loss: 1.681899348791155
Validation loss: 2.5188445966495827

Epoch: 6| Step: 5
Training loss: 1.677597804167497
Validation loss: 2.5179394771702466

Epoch: 6| Step: 6
Training loss: 2.05275551361321
Validation loss: 2.5732860279304584

Epoch: 6| Step: 7
Training loss: 1.196046990016902
Validation loss: 2.5516126967616546

Epoch: 6| Step: 8
Training loss: 1.2876068219063708
Validation loss: 2.5906648272371644

Epoch: 6| Step: 9
Training loss: 1.5326517656610505
Validation loss: 2.5867050980199537

Epoch: 6| Step: 10
Training loss: 1.5778550020909055
Validation loss: 2.60075436471819

Epoch: 6| Step: 11
Training loss: 0.877076410068422
Validation loss: 2.5932390362303823

Epoch: 6| Step: 12
Training loss: 1.4856654932058686
Validation loss: 2.567738870032584

Epoch: 6| Step: 13
Training loss: 1.0829700570022254
Validation loss: 2.595364944194737

Epoch: 450| Step: 0
Training loss: 1.6502565589038203
Validation loss: 2.5776191371755446

Epoch: 6| Step: 1
Training loss: 1.2756449283760847
Validation loss: 2.527572372723167

Epoch: 6| Step: 2
Training loss: 1.582358470090011
Validation loss: 2.5474157231838226

Epoch: 6| Step: 3
Training loss: 1.245105602734097
Validation loss: 2.529564226630262

Epoch: 6| Step: 4
Training loss: 1.2110378100779324
Validation loss: 2.5481951505823357

Epoch: 6| Step: 5
Training loss: 1.474680594435988
Validation loss: 2.5344941226554774

Epoch: 6| Step: 6
Training loss: 1.3298933038004996
Validation loss: 2.572486156568803

Epoch: 6| Step: 7
Training loss: 1.3185007429269109
Validation loss: 2.572276493411799

Epoch: 6| Step: 8
Training loss: 1.727565560318263
Validation loss: 2.5714674122034165

Epoch: 6| Step: 9
Training loss: 1.511090761792539
Validation loss: 2.582642005909316

Epoch: 6| Step: 10
Training loss: 1.959710820332585
Validation loss: 2.5827065308468624

Epoch: 6| Step: 11
Training loss: 1.4487060297957628
Validation loss: 2.580863313305275

Epoch: 6| Step: 12
Training loss: 1.2885528481732522
Validation loss: 2.5858415764852247

Epoch: 6| Step: 13
Training loss: 1.5272595316504696
Validation loss: 2.5636739135343487

Epoch: 451| Step: 0
Training loss: 1.4309908236589919
Validation loss: 2.542406212265109

Epoch: 6| Step: 1
Training loss: 1.4925134113162883
Validation loss: 2.5266784521629955

Epoch: 6| Step: 2
Training loss: 1.225396543664231
Validation loss: 2.562872312617184

Epoch: 6| Step: 3
Training loss: 1.190139747716565
Validation loss: 2.536858391269502

Epoch: 6| Step: 4
Training loss: 1.4637906370703444
Validation loss: 2.533555797945947

Epoch: 6| Step: 5
Training loss: 1.5125564501608182
Validation loss: 2.5383087104501194

Epoch: 6| Step: 6
Training loss: 1.6712222384741304
Validation loss: 2.51228057314563

Epoch: 6| Step: 7
Training loss: 1.246129146061246
Validation loss: 2.555098698071114

Epoch: 6| Step: 8
Training loss: 1.7750137650936606
Validation loss: 2.5749071411312983

Epoch: 6| Step: 9
Training loss: 1.6525868627021199
Validation loss: 2.582105377167294

Epoch: 6| Step: 10
Training loss: 1.6428403883132983
Validation loss: 2.582552892854866

Epoch: 6| Step: 11
Training loss: 1.6697432573059259
Validation loss: 2.5879215552381054

Epoch: 6| Step: 12
Training loss: 1.2644160583738668
Validation loss: 2.5873759834412198

Epoch: 6| Step: 13
Training loss: 1.1129674636595603
Validation loss: 2.57339544393086

Epoch: 452| Step: 0
Training loss: 1.3510642483877235
Validation loss: 2.601970680618835

Epoch: 6| Step: 1
Training loss: 1.691455021038337
Validation loss: 2.590806612708367

Epoch: 6| Step: 2
Training loss: 1.3756657635872453
Validation loss: 2.5102582134418254

Epoch: 6| Step: 3
Training loss: 1.8921915295256369
Validation loss: 2.5291043121030072

Epoch: 6| Step: 4
Training loss: 1.326398018388913
Validation loss: 2.508598652420846

Epoch: 6| Step: 5
Training loss: 0.8933901108899185
Validation loss: 2.4830518684291167

Epoch: 6| Step: 6
Training loss: 1.1199044222581167
Validation loss: 2.493216762730671

Epoch: 6| Step: 7
Training loss: 1.6017192484745377
Validation loss: 2.468185752852784

Epoch: 6| Step: 8
Training loss: 1.56901922157529
Validation loss: 2.512208936983489

Epoch: 6| Step: 9
Training loss: 1.1538202686340673
Validation loss: 2.543316809949553

Epoch: 6| Step: 10
Training loss: 1.5156525284931521
Validation loss: 2.5443518736930106

Epoch: 6| Step: 11
Training loss: 1.5331608274420314
Validation loss: 2.565748533663459

Epoch: 6| Step: 12
Training loss: 1.039643490923061
Validation loss: 2.593968018156933

Epoch: 6| Step: 13
Training loss: 2.4182690755911445
Validation loss: 2.5792508269633503

Epoch: 453| Step: 0
Training loss: 1.113793185132153
Validation loss: 2.580828998603661

Epoch: 6| Step: 1
Training loss: 1.1451983281744593
Validation loss: 2.5510961492146347

Epoch: 6| Step: 2
Training loss: 1.0734608699025951
Validation loss: 2.517320431918211

Epoch: 6| Step: 3
Training loss: 1.7642836074860648
Validation loss: 2.5132337999054926

Epoch: 6| Step: 4
Training loss: 1.9339295991472927
Validation loss: 2.4972494642935303

Epoch: 6| Step: 5
Training loss: 1.3982538710072878
Validation loss: 2.5031934010789234

Epoch: 6| Step: 6
Training loss: 1.2623226739970443
Validation loss: 2.5286688639409616

Epoch: 6| Step: 7
Training loss: 1.1609364464653646
Validation loss: 2.5267374551806014

Epoch: 6| Step: 8
Training loss: 1.6299984424092158
Validation loss: 2.546503579084633

Epoch: 6| Step: 9
Training loss: 1.3501660403821663
Validation loss: 2.5759174380777465

Epoch: 6| Step: 10
Training loss: 1.5846814222300132
Validation loss: 2.573745645473379

Epoch: 6| Step: 11
Training loss: 1.630705135155797
Validation loss: 2.547006896178514

Epoch: 6| Step: 12
Training loss: 1.5105010261216478
Validation loss: 2.5549524245211397

Epoch: 6| Step: 13
Training loss: 1.6863493351842878
Validation loss: 2.570795936277237

Epoch: 454| Step: 0
Training loss: 1.385439215263874
Validation loss: 2.5965407680675034

Epoch: 6| Step: 1
Training loss: 1.1857700797658335
Validation loss: 2.5475857657192

Epoch: 6| Step: 2
Training loss: 1.3935250464256335
Validation loss: 2.5775596727216556

Epoch: 6| Step: 3
Training loss: 1.6776998425305991
Validation loss: 2.5733610914141143

Epoch: 6| Step: 4
Training loss: 1.4408555051216636
Validation loss: 2.555083827479831

Epoch: 6| Step: 5
Training loss: 1.7050189065863806
Validation loss: 2.5711405482791037

Epoch: 6| Step: 6
Training loss: 1.3701691294780487
Validation loss: 2.5292296150713924

Epoch: 6| Step: 7
Training loss: 1.2469982344455044
Validation loss: 2.5370487609856

Epoch: 6| Step: 8
Training loss: 1.7459907928084206
Validation loss: 2.4980245045275518

Epoch: 6| Step: 9
Training loss: 1.7346833788301048
Validation loss: 2.4808377839635267

Epoch: 6| Step: 10
Training loss: 1.7516895040565341
Validation loss: 2.5152100934444843

Epoch: 6| Step: 11
Training loss: 1.032911984360087
Validation loss: 2.4997871892859047

Epoch: 6| Step: 12
Training loss: 1.1707412321490214
Validation loss: 2.511722160062352

Epoch: 6| Step: 13
Training loss: 1.183997006853934
Validation loss: 2.5249246644329935

Epoch: 455| Step: 0
Training loss: 1.0940271298951665
Validation loss: 2.5514060443730844

Epoch: 6| Step: 1
Training loss: 1.4398944649170915
Validation loss: 2.598322848585422

Epoch: 6| Step: 2
Training loss: 1.644166013340821
Validation loss: 2.5883303617287057

Epoch: 6| Step: 3
Training loss: 1.430345561016525
Validation loss: 2.549206070881647

Epoch: 6| Step: 4
Training loss: 1.0670734037339225
Validation loss: 2.548609193684158

Epoch: 6| Step: 5
Training loss: 1.22345656261964
Validation loss: 2.5288047348159752

Epoch: 6| Step: 6
Training loss: 1.9347129588176557
Validation loss: 2.552961145700054

Epoch: 6| Step: 7
Training loss: 0.7766307839166418
Validation loss: 2.5489575857450224

Epoch: 6| Step: 8
Training loss: 1.5480676542278926
Validation loss: 2.5435087473907845

Epoch: 6| Step: 9
Training loss: 1.4707960932756774
Validation loss: 2.54360456403403

Epoch: 6| Step: 10
Training loss: 1.4627116645166893
Validation loss: 2.554860223392329

Epoch: 6| Step: 11
Training loss: 1.7274788888615693
Validation loss: 2.4972880595119555

Epoch: 6| Step: 12
Training loss: 1.7768518458846
Validation loss: 2.5020797415801455

Epoch: 6| Step: 13
Training loss: 1.1227791906693234
Validation loss: 2.509656707786712

Epoch: 456| Step: 0
Training loss: 1.4002268760636574
Validation loss: 2.539348875544604

Epoch: 6| Step: 1
Training loss: 0.9759208402210274
Validation loss: 2.5531543613071532

Epoch: 6| Step: 2
Training loss: 1.240858602751129
Validation loss: 2.561587377507872

Epoch: 6| Step: 3
Training loss: 1.3327148115485543
Validation loss: 2.583138051294995

Epoch: 6| Step: 4
Training loss: 1.1238781315587323
Validation loss: 2.594153939006835

Epoch: 6| Step: 5
Training loss: 1.7130644654605052
Validation loss: 2.6022199692811294

Epoch: 6| Step: 6
Training loss: 2.0562292776252082
Validation loss: 2.597823272425492

Epoch: 6| Step: 7
Training loss: 1.3368412106645755
Validation loss: 2.5868653205295056

Epoch: 6| Step: 8
Training loss: 1.5974979088997923
Validation loss: 2.5405224511344486

Epoch: 6| Step: 9
Training loss: 1.6992376918394672
Validation loss: 2.5602062553172953

Epoch: 6| Step: 10
Training loss: 1.2688418820188931
Validation loss: 2.504214400575865

Epoch: 6| Step: 11
Training loss: 1.0627058615123244
Validation loss: 2.482660664990384

Epoch: 6| Step: 12
Training loss: 1.5774915575868584
Validation loss: 2.534315600791023

Epoch: 6| Step: 13
Training loss: 1.4238920053560489
Validation loss: 2.4964645880309084

Epoch: 457| Step: 0
Training loss: 1.0137677744519564
Validation loss: 2.523543871922779

Epoch: 6| Step: 1
Training loss: 1.5177084377116854
Validation loss: 2.5062929076274143

Epoch: 6| Step: 2
Training loss: 1.532898152142708
Validation loss: 2.515013137114711

Epoch: 6| Step: 3
Training loss: 1.8649944370790208
Validation loss: 2.5178611700190743

Epoch: 6| Step: 4
Training loss: 1.4564305107650615
Validation loss: 2.5124806313116856

Epoch: 6| Step: 5
Training loss: 1.5086476281302525
Validation loss: 2.5153824354180596

Epoch: 6| Step: 6
Training loss: 1.4347527000453686
Validation loss: 2.5370696647286257

Epoch: 6| Step: 7
Training loss: 1.4414233695153331
Validation loss: 2.5716087308635087

Epoch: 6| Step: 8
Training loss: 1.580068543432205
Validation loss: 2.5767276878991665

Epoch: 6| Step: 9
Training loss: 1.4657736306378257
Validation loss: 2.593761957533655

Epoch: 6| Step: 10
Training loss: 1.7198273490039866
Validation loss: 2.5677231501142406

Epoch: 6| Step: 11
Training loss: 0.9031568884582153
Validation loss: 2.570524745346375

Epoch: 6| Step: 12
Training loss: 1.0239200764698615
Validation loss: 2.5919627844624467

Epoch: 6| Step: 13
Training loss: 1.2592045443829714
Validation loss: 2.5877820110997796

Epoch: 458| Step: 0
Training loss: 0.9988858453560208
Validation loss: 2.5674432480691167

Epoch: 6| Step: 1
Training loss: 1.570963862061155
Validation loss: 2.5803581035518284

Epoch: 6| Step: 2
Training loss: 1.2487003245511141
Validation loss: 2.560278728381416

Epoch: 6| Step: 3
Training loss: 1.326747583927983
Validation loss: 2.5868775279106115

Epoch: 6| Step: 4
Training loss: 1.3109432252161
Validation loss: 2.5706110456527473

Epoch: 6| Step: 5
Training loss: 0.950938170624295
Validation loss: 2.550451442449659

Epoch: 6| Step: 6
Training loss: 1.6820116154454487
Validation loss: 2.5670943513413724

Epoch: 6| Step: 7
Training loss: 1.5892186541056115
Validation loss: 2.5548334746388974

Epoch: 6| Step: 8
Training loss: 1.561100447419574
Validation loss: 2.5289612457797457

Epoch: 6| Step: 9
Training loss: 1.4565553271402043
Validation loss: 2.548826292410791

Epoch: 6| Step: 10
Training loss: 1.7990293110722704
Validation loss: 2.529880968254453

Epoch: 6| Step: 11
Training loss: 1.4328657167425658
Validation loss: 2.513886341261454

Epoch: 6| Step: 12
Training loss: 1.447967564994086
Validation loss: 2.5151810648926283

Epoch: 6| Step: 13
Training loss: 1.132151075172596
Validation loss: 2.502130684366938

Epoch: 459| Step: 0
Training loss: 1.4949527702398504
Validation loss: 2.5231892702311716

Epoch: 6| Step: 1
Training loss: 1.6399473698242444
Validation loss: 2.5236613079984607

Epoch: 6| Step: 2
Training loss: 1.107552118732671
Validation loss: 2.5417040501559747

Epoch: 6| Step: 3
Training loss: 1.5582697251881614
Validation loss: 2.566349572516244

Epoch: 6| Step: 4
Training loss: 1.836224602510008
Validation loss: 2.559529627581232

Epoch: 6| Step: 5
Training loss: 0.9525113240767833
Validation loss: 2.5702405322855335

Epoch: 6| Step: 6
Training loss: 1.2239724773915415
Validation loss: 2.591026010936174

Epoch: 6| Step: 7
Training loss: 1.162473067104948
Validation loss: 2.582354274390998

Epoch: 6| Step: 8
Training loss: 1.4987054642907887
Validation loss: 2.5415753970678208

Epoch: 6| Step: 9
Training loss: 1.2713425142576489
Validation loss: 2.5392822155415344

Epoch: 6| Step: 10
Training loss: 1.1460177302095775
Validation loss: 2.5505007013995336

Epoch: 6| Step: 11
Training loss: 1.5577603743698545
Validation loss: 2.5127164504720474

Epoch: 6| Step: 12
Training loss: 1.544335641085402
Validation loss: 2.5025872624807555

Epoch: 6| Step: 13
Training loss: 1.7439329017234295
Validation loss: 2.513100554544768

Epoch: 460| Step: 0
Training loss: 1.3436998313587443
Validation loss: 2.5291501953123303

Epoch: 6| Step: 1
Training loss: 0.9884803782451421
Validation loss: 2.5036680425548608

Epoch: 6| Step: 2
Training loss: 1.7030540241536058
Validation loss: 2.5542725562896886

Epoch: 6| Step: 3
Training loss: 1.1612446107934373
Validation loss: 2.5286366310348

Epoch: 6| Step: 4
Training loss: 1.3405074986180863
Validation loss: 2.5398001216100834

Epoch: 6| Step: 5
Training loss: 1.227635685555607
Validation loss: 2.566588323116899

Epoch: 6| Step: 6
Training loss: 1.1004004334813953
Validation loss: 2.54111841005295

Epoch: 6| Step: 7
Training loss: 1.0696676497494024
Validation loss: 2.555577236878368

Epoch: 6| Step: 8
Training loss: 1.6890844041954978
Validation loss: 2.5786973304923677

Epoch: 6| Step: 9
Training loss: 1.5842613043987517
Validation loss: 2.5503836105768123

Epoch: 6| Step: 10
Training loss: 1.4512085120606533
Validation loss: 2.556650178066812

Epoch: 6| Step: 11
Training loss: 1.8069024963292415
Validation loss: 2.5610716265560884

Epoch: 6| Step: 12
Training loss: 1.2898790951928223
Validation loss: 2.5796949800086857

Epoch: 6| Step: 13
Training loss: 1.8186004839393193
Validation loss: 2.578909151679834

Epoch: 461| Step: 0
Training loss: 1.3065428191160036
Validation loss: 2.5577958380268178

Epoch: 6| Step: 1
Training loss: 1.0485437671911426
Validation loss: 2.5951751409288613

Epoch: 6| Step: 2
Training loss: 1.4427340214871873
Validation loss: 2.5880258780465293

Epoch: 6| Step: 3
Training loss: 1.1640241475795836
Validation loss: 2.5706214014748707

Epoch: 6| Step: 4
Training loss: 1.4998406484519953
Validation loss: 2.560265109485694

Epoch: 6| Step: 5
Training loss: 1.52967590078256
Validation loss: 2.579114866232691

Epoch: 6| Step: 6
Training loss: 1.2080907523347615
Validation loss: 2.5584118193887027

Epoch: 6| Step: 7
Training loss: 1.3674780836563325
Validation loss: 2.6065368317843136

Epoch: 6| Step: 8
Training loss: 1.6020597104768683
Validation loss: 2.5507328065468364

Epoch: 6| Step: 9
Training loss: 1.5611849782459026
Validation loss: 2.597191393789931

Epoch: 6| Step: 10
Training loss: 1.4516610595618196
Validation loss: 2.5744768599910994

Epoch: 6| Step: 11
Training loss: 1.6519671071728856
Validation loss: 2.558526261250616

Epoch: 6| Step: 12
Training loss: 1.2623633754567822
Validation loss: 2.55324448034464

Epoch: 6| Step: 13
Training loss: 1.3524009881999555
Validation loss: 2.529866577710129

Epoch: 462| Step: 0
Training loss: 1.290077965472506
Validation loss: 2.540473028983118

Epoch: 6| Step: 1
Training loss: 1.683828952583616
Validation loss: 2.525862878617227

Epoch: 6| Step: 2
Training loss: 0.8644959202587968
Validation loss: 2.5463224672669442

Epoch: 6| Step: 3
Training loss: 1.6658620640597435
Validation loss: 2.54766217107124

Epoch: 6| Step: 4
Training loss: 1.5262788538349394
Validation loss: 2.5300056187012303

Epoch: 6| Step: 5
Training loss: 1.0933487837463471
Validation loss: 2.5585567318573386

Epoch: 6| Step: 6
Training loss: 1.3397370676881788
Validation loss: 2.5924639438545705

Epoch: 6| Step: 7
Training loss: 1.343597847064679
Validation loss: 2.5648286424854305

Epoch: 6| Step: 8
Training loss: 1.3209681491260696
Validation loss: 2.5781017741191588

Epoch: 6| Step: 9
Training loss: 1.1129418642159121
Validation loss: 2.541240017520777

Epoch: 6| Step: 10
Training loss: 1.310851287735004
Validation loss: 2.6042979985417407

Epoch: 6| Step: 11
Training loss: 2.020829925009878
Validation loss: 2.5527165932912443

Epoch: 6| Step: 12
Training loss: 1.4616072644320957
Validation loss: 2.544476289777195

Epoch: 6| Step: 13
Training loss: 0.690254890728528
Validation loss: 2.5888600596292513

Epoch: 463| Step: 0
Training loss: 1.3630236188223332
Validation loss: 2.566582916327952

Epoch: 6| Step: 1
Training loss: 1.180506693383597
Validation loss: 2.5563676601385055

Epoch: 6| Step: 2
Training loss: 1.541934668813236
Validation loss: 2.5585778015536427

Epoch: 6| Step: 3
Training loss: 1.080154057570464
Validation loss: 2.592392905562081

Epoch: 6| Step: 4
Training loss: 1.1673729949584304
Validation loss: 2.578670356771687

Epoch: 6| Step: 5
Training loss: 2.0050570212077954
Validation loss: 2.6001118478941856

Epoch: 6| Step: 6
Training loss: 1.378862418107571
Validation loss: 2.5874508214645124

Epoch: 6| Step: 7
Training loss: 1.0220576878370642
Validation loss: 2.5672119701880636

Epoch: 6| Step: 8
Training loss: 1.2583025812766035
Validation loss: 2.5825754682145687

Epoch: 6| Step: 9
Training loss: 1.5859662133234322
Validation loss: 2.566023297021062

Epoch: 6| Step: 10
Training loss: 1.3997344923296469
Validation loss: 2.5589306671294847

Epoch: 6| Step: 11
Training loss: 1.3133371045127853
Validation loss: 2.535858929105562

Epoch: 6| Step: 12
Training loss: 1.6272109469663496
Validation loss: 2.5324406377752298

Epoch: 6| Step: 13
Training loss: 1.062744000410986
Validation loss: 2.5557247074749276

Epoch: 464| Step: 0
Training loss: 1.1100904817045798
Validation loss: 2.5235909020690044

Epoch: 6| Step: 1
Training loss: 1.440601982545157
Validation loss: 2.5424553366879783

Epoch: 6| Step: 2
Training loss: 1.4199982718336308
Validation loss: 2.560729562955626

Epoch: 6| Step: 3
Training loss: 1.752769662677393
Validation loss: 2.5931110398121486

Epoch: 6| Step: 4
Training loss: 1.6768392144307862
Validation loss: 2.55288704695222

Epoch: 6| Step: 5
Training loss: 1.3045226581165812
Validation loss: 2.551215499444728

Epoch: 6| Step: 6
Training loss: 1.3251475449950734
Validation loss: 2.5212490444458213

Epoch: 6| Step: 7
Training loss: 1.0894067359805708
Validation loss: 2.5682776381451116

Epoch: 6| Step: 8
Training loss: 1.1679077132488935
Validation loss: 2.546253542482631

Epoch: 6| Step: 9
Training loss: 1.5172676544545152
Validation loss: 2.568270645783059

Epoch: 6| Step: 10
Training loss: 1.5923264821856575
Validation loss: 2.5801788193925788

Epoch: 6| Step: 11
Training loss: 0.9262882566595314
Validation loss: 2.5534551520107693

Epoch: 6| Step: 12
Training loss: 1.3653870853265344
Validation loss: 2.563670305578644

Epoch: 6| Step: 13
Training loss: 1.4857910629623974
Validation loss: 2.5408749793961376

Epoch: 465| Step: 0
Training loss: 1.3698662808865947
Validation loss: 2.554099803193176

Epoch: 6| Step: 1
Training loss: 1.4163480381647064
Validation loss: 2.554032687537345

Epoch: 6| Step: 2
Training loss: 0.7159041996991078
Validation loss: 2.5637743582627612

Epoch: 6| Step: 3
Training loss: 1.8508569846029739
Validation loss: 2.6040595485847504

Epoch: 6| Step: 4
Training loss: 1.0468775051713262
Validation loss: 2.5849957318991827

Epoch: 6| Step: 5
Training loss: 0.9482292072260234
Validation loss: 2.5948247885589018

Epoch: 6| Step: 6
Training loss: 1.0726428870850313
Validation loss: 2.5843471416034243

Epoch: 6| Step: 7
Training loss: 1.501242282158343
Validation loss: 2.5873650962169625

Epoch: 6| Step: 8
Training loss: 1.5735791897358165
Validation loss: 2.5615280813309296

Epoch: 6| Step: 9
Training loss: 1.456255340566379
Validation loss: 2.533761512797416

Epoch: 6| Step: 10
Training loss: 1.4157334039878384
Validation loss: 2.556497274574392

Epoch: 6| Step: 11
Training loss: 1.208942763886595
Validation loss: 2.5452050630943117

Epoch: 6| Step: 12
Training loss: 1.427613301499024
Validation loss: 2.499666634759883

Epoch: 6| Step: 13
Training loss: 1.9777300857777715
Validation loss: 2.5316893129124987

Epoch: 466| Step: 0
Training loss: 1.6717092841900376
Validation loss: 2.4954312816692665

Epoch: 6| Step: 1
Training loss: 1.7437152407883696
Validation loss: 2.4976291571666707

Epoch: 6| Step: 2
Training loss: 1.2417755883508241
Validation loss: 2.5126705298939216

Epoch: 6| Step: 3
Training loss: 1.2820845886330114
Validation loss: 2.503528128657528

Epoch: 6| Step: 4
Training loss: 1.5907395297264497
Validation loss: 2.5468434071954693

Epoch: 6| Step: 5
Training loss: 1.1708799079147891
Validation loss: 2.5496428620217086

Epoch: 6| Step: 6
Training loss: 1.1451448221530405
Validation loss: 2.550338233522699

Epoch: 6| Step: 7
Training loss: 1.226831394534157
Validation loss: 2.5770170006702475

Epoch: 6| Step: 8
Training loss: 1.4663217641141786
Validation loss: 2.561899153255497

Epoch: 6| Step: 9
Training loss: 1.501174387556242
Validation loss: 2.502550064333061

Epoch: 6| Step: 10
Training loss: 1.0474644609854733
Validation loss: 2.5229850558239026

Epoch: 6| Step: 11
Training loss: 0.7602659015039969
Validation loss: 2.5159766378758115

Epoch: 6| Step: 12
Training loss: 1.4015865566268688
Validation loss: 2.505021776238101

Epoch: 6| Step: 13
Training loss: 1.7705295601386002
Validation loss: 2.5159067057218083

Epoch: 467| Step: 0
Training loss: 1.2521312188223226
Validation loss: 2.5426634278570748

Epoch: 6| Step: 1
Training loss: 1.5612477434323742
Validation loss: 2.5289959753451936

Epoch: 6| Step: 2
Training loss: 1.1431308550551746
Validation loss: 2.5403276107147104

Epoch: 6| Step: 3
Training loss: 2.098619179661397
Validation loss: 2.567318124110277

Epoch: 6| Step: 4
Training loss: 0.7780674771414691
Validation loss: 2.5686022045377617

Epoch: 6| Step: 5
Training loss: 1.1357196730188608
Validation loss: 2.5916072525933935

Epoch: 6| Step: 6
Training loss: 0.8773408300363078
Validation loss: 2.591625614221628

Epoch: 6| Step: 7
Training loss: 1.9200257499279412
Validation loss: 2.6160196744273003

Epoch: 6| Step: 8
Training loss: 1.1004072042508792
Validation loss: 2.603083101997126

Epoch: 6| Step: 9
Training loss: 1.4150848907779032
Validation loss: 2.5942611630483126

Epoch: 6| Step: 10
Training loss: 1.6662170359963049
Validation loss: 2.6022669784259054

Epoch: 6| Step: 11
Training loss: 0.9190335530350111
Validation loss: 2.5384295092448816

Epoch: 6| Step: 12
Training loss: 1.0938220409101227
Validation loss: 2.530593953152122

Epoch: 6| Step: 13
Training loss: 1.5136840819820285
Validation loss: 2.594379072507655

Epoch: 468| Step: 0
Training loss: 1.2365829422123618
Validation loss: 2.53029088452327

Epoch: 6| Step: 1
Training loss: 1.3919207932913256
Validation loss: 2.535515194067455

Epoch: 6| Step: 2
Training loss: 1.0400212962464366
Validation loss: 2.535588720665919

Epoch: 6| Step: 3
Training loss: 1.1731355118521907
Validation loss: 2.549317649697406

Epoch: 6| Step: 4
Training loss: 1.7637444668148419
Validation loss: 2.5539723938612044

Epoch: 6| Step: 5
Training loss: 1.4976284830447533
Validation loss: 2.5639567422617455

Epoch: 6| Step: 6
Training loss: 1.7267479430159216
Validation loss: 2.581517631062119

Epoch: 6| Step: 7
Training loss: 1.4448640694751371
Validation loss: 2.588919507134224

Epoch: 6| Step: 8
Training loss: 1.1587103365104487
Validation loss: 2.557378107617508

Epoch: 6| Step: 9
Training loss: 1.3811558859682003
Validation loss: 2.5423485963901484

Epoch: 6| Step: 10
Training loss: 1.0195340562102184
Validation loss: 2.565414357152538

Epoch: 6| Step: 11
Training loss: 1.3304932964432752
Validation loss: 2.5550995519159447

Epoch: 6| Step: 12
Training loss: 1.0749387235698282
Validation loss: 2.52916623049464

Epoch: 6| Step: 13
Training loss: 1.6516520899037346
Validation loss: 2.5504980779517155

Epoch: 469| Step: 0
Training loss: 1.3777514585079917
Validation loss: 2.535845392374738

Epoch: 6| Step: 1
Training loss: 1.571011515797951
Validation loss: 2.5381401270961073

Epoch: 6| Step: 2
Training loss: 1.326129760972397
Validation loss: 2.5721168412435125

Epoch: 6| Step: 3
Training loss: 1.4518016408778323
Validation loss: 2.5459972615270896

Epoch: 6| Step: 4
Training loss: 1.0709244586650322
Validation loss: 2.562782144508118

Epoch: 6| Step: 5
Training loss: 1.0910664471112765
Validation loss: 2.5683476495555073

Epoch: 6| Step: 6
Training loss: 1.5007675114667565
Validation loss: 2.5756078300380842

Epoch: 6| Step: 7
Training loss: 1.5610062134427853
Validation loss: 2.575939556063377

Epoch: 6| Step: 8
Training loss: 1.0293892922072236
Validation loss: 2.611678615403765

Epoch: 6| Step: 9
Training loss: 1.4856922127713659
Validation loss: 2.6443687899579906

Epoch: 6| Step: 10
Training loss: 1.3385928350779217
Validation loss: 2.5946159671599336

Epoch: 6| Step: 11
Training loss: 1.2475411072343476
Validation loss: 2.587884946705832

Epoch: 6| Step: 12
Training loss: 0.9829693400742472
Validation loss: 2.5632611256598703

Epoch: 6| Step: 13
Training loss: 1.9281714039663929
Validation loss: 2.5104592088694333

Epoch: 470| Step: 0
Training loss: 1.0725288554402408
Validation loss: 2.518725982285242

Epoch: 6| Step: 1
Training loss: 1.796179661763988
Validation loss: 2.5090905187237316

Epoch: 6| Step: 2
Training loss: 1.5949765142068963
Validation loss: 2.5314253677069614

Epoch: 6| Step: 3
Training loss: 1.3843883436261726
Validation loss: 2.4970434467330653

Epoch: 6| Step: 4
Training loss: 0.9472224589472152
Validation loss: 2.5402504498745966

Epoch: 6| Step: 5
Training loss: 1.3229481500598907
Validation loss: 2.4884432272789088

Epoch: 6| Step: 6
Training loss: 0.99451458985188
Validation loss: 2.519808900146605

Epoch: 6| Step: 7
Training loss: 1.5051956000223965
Validation loss: 2.529552271695069

Epoch: 6| Step: 8
Training loss: 1.389276772483267
Validation loss: 2.5598891744311203

Epoch: 6| Step: 9
Training loss: 1.0560275007120468
Validation loss: 2.588377434947156

Epoch: 6| Step: 10
Training loss: 1.0420476725284211
Validation loss: 2.6042917831062193

Epoch: 6| Step: 11
Training loss: 1.0858731696744774
Validation loss: 2.658843431674779

Epoch: 6| Step: 12
Training loss: 1.6070063669283916
Validation loss: 2.6497526691508004

Epoch: 6| Step: 13
Training loss: 2.0357718973444885
Validation loss: 2.5932404004791447

Epoch: 471| Step: 0
Training loss: 1.1945787558829923
Validation loss: 2.5997464777364345

Epoch: 6| Step: 1
Training loss: 1.0994412173334707
Validation loss: 2.598570969869383

Epoch: 6| Step: 2
Training loss: 0.9186745061154646
Validation loss: 2.5929001800845652

Epoch: 6| Step: 3
Training loss: 1.227153514200092
Validation loss: 2.5589044388081543

Epoch: 6| Step: 4
Training loss: 1.37367210424196
Validation loss: 2.5814599148837596

Epoch: 6| Step: 5
Training loss: 1.1605416117073408
Validation loss: 2.5688191859181173

Epoch: 6| Step: 6
Training loss: 1.3435856031057063
Validation loss: 2.575692872644672

Epoch: 6| Step: 7
Training loss: 1.646649154436116
Validation loss: 2.5250516165135375

Epoch: 6| Step: 8
Training loss: 1.2066666629608604
Validation loss: 2.5602783578955415

Epoch: 6| Step: 9
Training loss: 1.98277554669226
Validation loss: 2.551330379657954

Epoch: 6| Step: 10
Training loss: 1.2136623120675514
Validation loss: 2.563358771255291

Epoch: 6| Step: 11
Training loss: 1.4759777061515518
Validation loss: 2.5813582758386926

Epoch: 6| Step: 12
Training loss: 1.2140687390023541
Validation loss: 2.585304955421768

Epoch: 6| Step: 13
Training loss: 1.4747834968080147
Validation loss: 2.595659440473751

Epoch: 472| Step: 0
Training loss: 1.3207323659499117
Validation loss: 2.5451974322079636

Epoch: 6| Step: 1
Training loss: 0.8339788360769117
Validation loss: 2.5349275021979794

Epoch: 6| Step: 2
Training loss: 1.357290050225553
Validation loss: 2.527179119824605

Epoch: 6| Step: 3
Training loss: 1.5225422894347025
Validation loss: 2.5398780238766996

Epoch: 6| Step: 4
Training loss: 1.1663782012898791
Validation loss: 2.5288069316668302

Epoch: 6| Step: 5
Training loss: 0.7024349217120188
Validation loss: 2.545090821014788

Epoch: 6| Step: 6
Training loss: 1.2420123474625322
Validation loss: 2.561071676606243

Epoch: 6| Step: 7
Training loss: 1.5998180285924317
Validation loss: 2.5390943223901132

Epoch: 6| Step: 8
Training loss: 1.6009037058485998
Validation loss: 2.5716352024500475

Epoch: 6| Step: 9
Training loss: 1.1302873024255713
Validation loss: 2.5658160267802534

Epoch: 6| Step: 10
Training loss: 1.8384208603488008
Validation loss: 2.5469510985379458

Epoch: 6| Step: 11
Training loss: 0.8021206331043526
Validation loss: 2.542371418837925

Epoch: 6| Step: 12
Training loss: 1.8632483649400862
Validation loss: 2.532856538632434

Epoch: 6| Step: 13
Training loss: 1.1135915223473096
Validation loss: 2.518925036460929

Epoch: 473| Step: 0
Training loss: 1.8550130505372662
Validation loss: 2.5694982238332633

Epoch: 6| Step: 1
Training loss: 1.117235622836752
Validation loss: 2.5572131824289595

Epoch: 6| Step: 2
Training loss: 1.901160904441393
Validation loss: 2.5971421675486885

Epoch: 6| Step: 3
Training loss: 1.1868389699086286
Validation loss: 2.5762974043313065

Epoch: 6| Step: 4
Training loss: 1.2165498681812639
Validation loss: 2.5417867413955655

Epoch: 6| Step: 5
Training loss: 1.5007760106898314
Validation loss: 2.567126712540378

Epoch: 6| Step: 6
Training loss: 1.0244949352535764
Validation loss: 2.5993545535659357

Epoch: 6| Step: 7
Training loss: 1.255787421697013
Validation loss: 2.5946126057718897

Epoch: 6| Step: 8
Training loss: 1.4989610888906693
Validation loss: 2.6120274609361838

Epoch: 6| Step: 9
Training loss: 0.982939445411696
Validation loss: 2.5807108003590216

Epoch: 6| Step: 10
Training loss: 1.2838617083448571
Validation loss: 2.6038970587846055

Epoch: 6| Step: 11
Training loss: 1.2008062535042425
Validation loss: 2.616284617549849

Epoch: 6| Step: 12
Training loss: 1.2057180822973843
Validation loss: 2.629671380982264

Epoch: 6| Step: 13
Training loss: 1.2278050246075465
Validation loss: 2.5882081498055265

Epoch: 474| Step: 0
Training loss: 1.7030018753202711
Validation loss: 2.5499659869575524

Epoch: 6| Step: 1
Training loss: 1.3806416341212142
Validation loss: 2.5334793172892685

Epoch: 6| Step: 2
Training loss: 1.0437770383153753
Validation loss: 2.5069014973247805

Epoch: 6| Step: 3
Training loss: 1.3223992284445985
Validation loss: 2.492208413819312

Epoch: 6| Step: 4
Training loss: 1.4533170347583064
Validation loss: 2.5191208061451094

Epoch: 6| Step: 5
Training loss: 1.515486012801084
Validation loss: 2.488150892775716

Epoch: 6| Step: 6
Training loss: 0.8289071833598988
Validation loss: 2.5382587967554717

Epoch: 6| Step: 7
Training loss: 1.141156843379834
Validation loss: 2.530629924590606

Epoch: 6| Step: 8
Training loss: 0.9739344214837679
Validation loss: 2.573672084371146

Epoch: 6| Step: 9
Training loss: 1.4635567262718672
Validation loss: 2.5802960564096002

Epoch: 6| Step: 10
Training loss: 1.2347879805407151
Validation loss: 2.642949043163523

Epoch: 6| Step: 11
Training loss: 1.2091911274709704
Validation loss: 2.6266670968856114

Epoch: 6| Step: 12
Training loss: 1.97088120169168
Validation loss: 2.64744782615257

Epoch: 6| Step: 13
Training loss: 0.7959453545532161
Validation loss: 2.6507289937477614

Epoch: 475| Step: 0
Training loss: 0.7271731282032429
Validation loss: 2.6557467095423677

Epoch: 6| Step: 1
Training loss: 1.4805508794625215
Validation loss: 2.6628339585455008

Epoch: 6| Step: 2
Training loss: 1.3328988390524616
Validation loss: 2.641269361294762

Epoch: 6| Step: 3
Training loss: 1.2131690352327187
Validation loss: 2.6042231170114425

Epoch: 6| Step: 4
Training loss: 1.4637173403542139
Validation loss: 2.551397782430889

Epoch: 6| Step: 5
Training loss: 1.4616579125699336
Validation loss: 2.4853690133591297

Epoch: 6| Step: 6
Training loss: 1.2625206917304066
Validation loss: 2.4765304553522505

Epoch: 6| Step: 7
Training loss: 0.839880867071335
Validation loss: 2.4803128607646054

Epoch: 6| Step: 8
Training loss: 1.85642219541104
Validation loss: 2.4705314252639035

Epoch: 6| Step: 9
Training loss: 1.0926142654197122
Validation loss: 2.4945018266918275

Epoch: 6| Step: 10
Training loss: 1.4981052034205566
Validation loss: 2.514114308437641

Epoch: 6| Step: 11
Training loss: 1.5225904408419269
Validation loss: 2.5566193307677465

Epoch: 6| Step: 12
Training loss: 1.4728450907033999
Validation loss: 2.557848103653489

Epoch: 6| Step: 13
Training loss: 0.8998477648092222
Validation loss: 2.577874759624952

Epoch: 476| Step: 0
Training loss: 1.1786949580135782
Validation loss: 2.597064969210516

Epoch: 6| Step: 1
Training loss: 1.0023818260804351
Validation loss: 2.650446568345561

Epoch: 6| Step: 2
Training loss: 1.3455342268458683
Validation loss: 2.6239659782251765

Epoch: 6| Step: 3
Training loss: 2.0770903571599
Validation loss: 2.603549741129087

Epoch: 6| Step: 4
Training loss: 1.5123602715886555
Validation loss: 2.605794037995186

Epoch: 6| Step: 5
Training loss: 1.3710427560045015
Validation loss: 2.563955552408183

Epoch: 6| Step: 6
Training loss: 1.4516999835553621
Validation loss: 2.562329708576721

Epoch: 6| Step: 7
Training loss: 0.9697743814131908
Validation loss: 2.544501809420782

Epoch: 6| Step: 8
Training loss: 1.3844584351620695
Validation loss: 2.5581245974795515

Epoch: 6| Step: 9
Training loss: 0.9669424236439288
Validation loss: 2.535060960475542

Epoch: 6| Step: 10
Training loss: 1.2681882356883405
Validation loss: 2.5612177187916205

Epoch: 6| Step: 11
Training loss: 1.1376358475104555
Validation loss: 2.5198606188838015

Epoch: 6| Step: 12
Training loss: 1.0926647797017992
Validation loss: 2.5833861246050653

Epoch: 6| Step: 13
Training loss: 1.3178250508641345
Validation loss: 2.5813188554746698

Epoch: 477| Step: 0
Training loss: 1.1321869800302151
Validation loss: 2.5929462572786357

Epoch: 6| Step: 1
Training loss: 1.3397979728508007
Validation loss: 2.631578875702521

Epoch: 6| Step: 2
Training loss: 1.4854296501344846
Validation loss: 2.6018730435712065

Epoch: 6| Step: 3
Training loss: 0.6638453184534062
Validation loss: 2.6497769223764274

Epoch: 6| Step: 4
Training loss: 1.5325753840314864
Validation loss: 2.5704391333097356

Epoch: 6| Step: 5
Training loss: 1.6906993348989736
Validation loss: 2.597032054140595

Epoch: 6| Step: 6
Training loss: 1.3066609698936944
Validation loss: 2.5967921891605137

Epoch: 6| Step: 7
Training loss: 1.0993241097630282
Validation loss: 2.5714687800270957

Epoch: 6| Step: 8
Training loss: 1.2331098519432622
Validation loss: 2.536934877173501

Epoch: 6| Step: 9
Training loss: 1.251164751988339
Validation loss: 2.547600612655554

Epoch: 6| Step: 10
Training loss: 0.9253864009659326
Validation loss: 2.523287190431713

Epoch: 6| Step: 11
Training loss: 1.5706475503003225
Validation loss: 2.530395100119278

Epoch: 6| Step: 12
Training loss: 1.5126398321410768
Validation loss: 2.5288518708887775

Epoch: 6| Step: 13
Training loss: 1.0748810547073564
Validation loss: 2.5265503520342367

Epoch: 478| Step: 0
Training loss: 1.7231781530086276
Validation loss: 2.52825535472731

Epoch: 6| Step: 1
Training loss: 1.192371415217336
Validation loss: 2.526571290888233

Epoch: 6| Step: 2
Training loss: 0.9820475234790202
Validation loss: 2.5615960484378855

Epoch: 6| Step: 3
Training loss: 1.0481395770010675
Validation loss: 2.5430179522697585

Epoch: 6| Step: 4
Training loss: 1.2065183667121968
Validation loss: 2.522497573725025

Epoch: 6| Step: 5
Training loss: 1.180741250013197
Validation loss: 2.5140709239363

Epoch: 6| Step: 6
Training loss: 1.2664055948414599
Validation loss: 2.549400450968533

Epoch: 6| Step: 7
Training loss: 0.7798925432132658
Validation loss: 2.5798924786013187

Epoch: 6| Step: 8
Training loss: 1.308941649693347
Validation loss: 2.583113040389985

Epoch: 6| Step: 9
Training loss: 1.5003537714533064
Validation loss: 2.604111981873965

Epoch: 6| Step: 10
Training loss: 1.7909068633058194
Validation loss: 2.586435617310117

Epoch: 6| Step: 11
Training loss: 1.1248245102383785
Validation loss: 2.5529200481685352

Epoch: 6| Step: 12
Training loss: 1.5913581103018228
Validation loss: 2.5510091349570514

Epoch: 6| Step: 13
Training loss: 0.9851245751004271
Validation loss: 2.5352301773341885

Epoch: 479| Step: 0
Training loss: 0.6748083531325683
Validation loss: 2.5497035753043127

Epoch: 6| Step: 1
Training loss: 1.230849627931694
Validation loss: 2.5494301346799837

Epoch: 6| Step: 2
Training loss: 1.0026878949498468
Validation loss: 2.5550968980729674

Epoch: 6| Step: 3
Training loss: 1.7461245403945955
Validation loss: 2.5835327252762386

Epoch: 6| Step: 4
Training loss: 1.262573991627947
Validation loss: 2.564438517587882

Epoch: 6| Step: 5
Training loss: 0.9993375729917748
Validation loss: 2.58593029663998

Epoch: 6| Step: 6
Training loss: 1.3265775304511194
Validation loss: 2.5963522070056544

Epoch: 6| Step: 7
Training loss: 1.1489539509767783
Validation loss: 2.6011741097230807

Epoch: 6| Step: 8
Training loss: 0.9552917865557818
Validation loss: 2.6466177645620914

Epoch: 6| Step: 9
Training loss: 1.336095120238912
Validation loss: 2.6138607882062392

Epoch: 6| Step: 10
Training loss: 1.4178681981608718
Validation loss: 2.594874073581597

Epoch: 6| Step: 11
Training loss: 1.5653218537407378
Validation loss: 2.574045111587838

Epoch: 6| Step: 12
Training loss: 1.4342759507497747
Validation loss: 2.5333278558663226

Epoch: 6| Step: 13
Training loss: 1.9093885380691098
Validation loss: 2.5547993622217486

Epoch: 480| Step: 0
Training loss: 1.2141293697524005
Validation loss: 2.524903361630642

Epoch: 6| Step: 1
Training loss: 1.7921383332988894
Validation loss: 2.5013633558627566

Epoch: 6| Step: 2
Training loss: 1.0681915430330937
Validation loss: 2.521019757776915

Epoch: 6| Step: 3
Training loss: 1.2204670670194575
Validation loss: 2.5336059459523916

Epoch: 6| Step: 4
Training loss: 1.2950840268803423
Validation loss: 2.533783961335893

Epoch: 6| Step: 5
Training loss: 1.5313870894120134
Validation loss: 2.549294398689261

Epoch: 6| Step: 6
Training loss: 1.112138502987634
Validation loss: 2.5120539346443227

Epoch: 6| Step: 7
Training loss: 1.083177255733595
Validation loss: 2.5524447706049314

Epoch: 6| Step: 8
Training loss: 1.5652616890222701
Validation loss: 2.5509332368705566

Epoch: 6| Step: 9
Training loss: 1.1597599161739283
Validation loss: 2.542842825516773

Epoch: 6| Step: 10
Training loss: 1.2843360486586421
Validation loss: 2.560074571525124

Epoch: 6| Step: 11
Training loss: 1.0905182094811443
Validation loss: 2.552094925901609

Epoch: 6| Step: 12
Training loss: 1.1236134567728748
Validation loss: 2.5503745316118525

Epoch: 6| Step: 13
Training loss: 1.2253751900320695
Validation loss: 2.5461796643628287

Epoch: 481| Step: 0
Training loss: 1.4854401631612495
Validation loss: 2.5416866169238483

Epoch: 6| Step: 1
Training loss: 1.1818424777554632
Validation loss: 2.55815931293976

Epoch: 6| Step: 2
Training loss: 1.0945555853742088
Validation loss: 2.5757409332507213

Epoch: 6| Step: 3
Training loss: 1.0447582651556695
Validation loss: 2.5507836319468917

Epoch: 6| Step: 4
Training loss: 1.6188229017890028
Validation loss: 2.5312179113714195

Epoch: 6| Step: 5
Training loss: 1.6748961487644893
Validation loss: 2.5307212164849444

Epoch: 6| Step: 6
Training loss: 1.1355611143475877
Validation loss: 2.5308549178424733

Epoch: 6| Step: 7
Training loss: 0.6204034580065475
Validation loss: 2.5071879828878787

Epoch: 6| Step: 8
Training loss: 1.1946350870851152
Validation loss: 2.521636181293503

Epoch: 6| Step: 9
Training loss: 1.2351270388696507
Validation loss: 2.543536091977922

Epoch: 6| Step: 10
Training loss: 1.303639979342359
Validation loss: 2.5557805412687356

Epoch: 6| Step: 11
Training loss: 1.3853431433574181
Validation loss: 2.589079837180458

Epoch: 6| Step: 12
Training loss: 0.8111331519923705
Validation loss: 2.5974926376660856

Epoch: 6| Step: 13
Training loss: 1.8087215502016722
Validation loss: 2.6019703165619728

Epoch: 482| Step: 0
Training loss: 0.8448566314578784
Validation loss: 2.605317431433426

Epoch: 6| Step: 1
Training loss: 1.2930971756048542
Validation loss: 2.606078737925859

Epoch: 6| Step: 2
Training loss: 0.945111686878157
Validation loss: 2.617656487344762

Epoch: 6| Step: 3
Training loss: 1.278963887215599
Validation loss: 2.582152124044519

Epoch: 6| Step: 4
Training loss: 1.3117990892900602
Validation loss: 2.5778244942212107

Epoch: 6| Step: 5
Training loss: 1.5818995291421933
Validation loss: 2.588657122955667

Epoch: 6| Step: 6
Training loss: 1.2755083435784609
Validation loss: 2.5600487574874315

Epoch: 6| Step: 7
Training loss: 1.557012305405243
Validation loss: 2.5861221672344508

Epoch: 6| Step: 8
Training loss: 1.1568259274025328
Validation loss: 2.554925837278768

Epoch: 6| Step: 9
Training loss: 1.405558522078475
Validation loss: 2.558844998305733

Epoch: 6| Step: 10
Training loss: 1.306842782614527
Validation loss: 2.546000021520307

Epoch: 6| Step: 11
Training loss: 1.4712905825039024
Validation loss: 2.5382945919026145

Epoch: 6| Step: 12
Training loss: 0.948461819483062
Validation loss: 2.5543135055999913

Epoch: 6| Step: 13
Training loss: 1.2899266438733645
Validation loss: 2.5173213785213897

Epoch: 483| Step: 0
Training loss: 0.9585773668700152
Validation loss: 2.52104765034292

Epoch: 6| Step: 1
Training loss: 1.4431810488251675
Validation loss: 2.549323044834202

Epoch: 6| Step: 2
Training loss: 0.9692998986632486
Validation loss: 2.565560279039752

Epoch: 6| Step: 3
Training loss: 0.833284893217479
Validation loss: 2.544481941016475

Epoch: 6| Step: 4
Training loss: 1.3153067505163183
Validation loss: 2.5352758126621455

Epoch: 6| Step: 5
Training loss: 1.2552596064604349
Validation loss: 2.5364183514264136

Epoch: 6| Step: 6
Training loss: 0.9198633973148926
Validation loss: 2.5487325841925683

Epoch: 6| Step: 7
Training loss: 1.0309297468964065
Validation loss: 2.5804220368464263

Epoch: 6| Step: 8
Training loss: 1.6509729926651633
Validation loss: 2.5871216713639678

Epoch: 6| Step: 9
Training loss: 1.9927941688865762
Validation loss: 2.5766677412183054

Epoch: 6| Step: 10
Training loss: 1.270982869006544
Validation loss: 2.575074283138895

Epoch: 6| Step: 11
Training loss: 1.1752924616027676
Validation loss: 2.604329630685194

Epoch: 6| Step: 12
Training loss: 1.3916073875974575
Validation loss: 2.550059306029925

Epoch: 6| Step: 13
Training loss: 0.5785120364431371
Validation loss: 2.5651221816523084

Epoch: 484| Step: 0
Training loss: 1.4425676004050143
Validation loss: 2.5892345423612317

Epoch: 6| Step: 1
Training loss: 1.244951639576672
Validation loss: 2.551041693170251

Epoch: 6| Step: 2
Training loss: 1.2577617469167763
Validation loss: 2.541430551289242

Epoch: 6| Step: 3
Training loss: 0.636623562677672
Validation loss: 2.5833120217835224

Epoch: 6| Step: 4
Training loss: 1.5368787114989402
Validation loss: 2.5606934557007386

Epoch: 6| Step: 5
Training loss: 1.5560634026248035
Validation loss: 2.600813506837754

Epoch: 6| Step: 6
Training loss: 1.1102489736063077
Validation loss: 2.5591567304901046

Epoch: 6| Step: 7
Training loss: 1.4540521268722602
Validation loss: 2.5803288729972613

Epoch: 6| Step: 8
Training loss: 1.3887759570726936
Validation loss: 2.5895960735506964

Epoch: 6| Step: 9
Training loss: 1.0492508531830096
Validation loss: 2.5518464709107542

Epoch: 6| Step: 10
Training loss: 1.3864101012696741
Validation loss: 2.570502181836571

Epoch: 6| Step: 11
Training loss: 0.8917367254049331
Validation loss: 2.589296484716227

Epoch: 6| Step: 12
Training loss: 1.093296120337903
Validation loss: 2.546703888760377

Epoch: 6| Step: 13
Training loss: 1.1015742416297154
Validation loss: 2.546164702413243

Epoch: 485| Step: 0
Training loss: 1.256148760307899
Validation loss: 2.52390845630055

Epoch: 6| Step: 1
Training loss: 1.4660390630932658
Validation loss: 2.513804416993207

Epoch: 6| Step: 2
Training loss: 0.8841850953034694
Validation loss: 2.537398539269162

Epoch: 6| Step: 3
Training loss: 1.5243113041419114
Validation loss: 2.5639800042879104

Epoch: 6| Step: 4
Training loss: 0.7824424798073999
Validation loss: 2.5683165374905337

Epoch: 6| Step: 5
Training loss: 0.9655837337231554
Validation loss: 2.57741322168023

Epoch: 6| Step: 6
Training loss: 1.871422915881731
Validation loss: 2.580846147568165

Epoch: 6| Step: 7
Training loss: 1.273213840806318
Validation loss: 2.596738481119989

Epoch: 6| Step: 8
Training loss: 0.9917937871788008
Validation loss: 2.5811775499873977

Epoch: 6| Step: 9
Training loss: 0.9792039167474658
Validation loss: 2.5955968533963296

Epoch: 6| Step: 10
Training loss: 1.1103132336928405
Validation loss: 2.6189376237163726

Epoch: 6| Step: 11
Training loss: 0.8704014237893605
Validation loss: 2.550910732221219

Epoch: 6| Step: 12
Training loss: 1.4495883686226394
Validation loss: 2.5882081973499056

Epoch: 6| Step: 13
Training loss: 1.7181265653989564
Validation loss: 2.5733902905346664

Epoch: 486| Step: 0
Training loss: 1.2093188388608451
Validation loss: 2.5809433414229077

Epoch: 6| Step: 1
Training loss: 1.4753193137882792
Validation loss: 2.558485443495663

Epoch: 6| Step: 2
Training loss: 1.4421593990873889
Validation loss: 2.555607089098513

Epoch: 6| Step: 3
Training loss: 0.9726294701501331
Validation loss: 2.5930987629122075

Epoch: 6| Step: 4
Training loss: 1.1029693601784651
Validation loss: 2.5767409660813847

Epoch: 6| Step: 5
Training loss: 0.8560198397966535
Validation loss: 2.5578357056101995

Epoch: 6| Step: 6
Training loss: 0.9449844737013681
Validation loss: 2.559168413898207

Epoch: 6| Step: 7
Training loss: 1.1435566681438334
Validation loss: 2.5796603665357467

Epoch: 6| Step: 8
Training loss: 1.4758167300949827
Validation loss: 2.58954691478459

Epoch: 6| Step: 9
Training loss: 1.6256587820565207
Validation loss: 2.5822633306340674

Epoch: 6| Step: 10
Training loss: 0.9421534758287228
Validation loss: 2.5765455492232525

Epoch: 6| Step: 11
Training loss: 1.2223953114874038
Validation loss: 2.584815925379817

Epoch: 6| Step: 12
Training loss: 1.3081921772628333
Validation loss: 2.587835064456227

Epoch: 6| Step: 13
Training loss: 1.1576307146322444
Validation loss: 2.6075812994307905

Epoch: 487| Step: 0
Training loss: 0.6026255639798987
Validation loss: 2.5599979878521517

Epoch: 6| Step: 1
Training loss: 1.817556234589058
Validation loss: 2.597183974871717

Epoch: 6| Step: 2
Training loss: 1.211090668866428
Validation loss: 2.5832647247677762

Epoch: 6| Step: 3
Training loss: 1.0425740613175711
Validation loss: 2.5830057173272523

Epoch: 6| Step: 4
Training loss: 0.9433291728553641
Validation loss: 2.593736579584539

Epoch: 6| Step: 5
Training loss: 1.1337711355811155
Validation loss: 2.590718008088459

Epoch: 6| Step: 6
Training loss: 1.3302591567560438
Validation loss: 2.582392359103639

Epoch: 6| Step: 7
Training loss: 1.058894266075081
Validation loss: 2.618557217740149

Epoch: 6| Step: 8
Training loss: 1.17862562678344
Validation loss: 2.5781273039816526

Epoch: 6| Step: 9
Training loss: 1.2294133579958881
Validation loss: 2.5806298689683946

Epoch: 6| Step: 10
Training loss: 0.8884637945351679
Validation loss: 2.5980355926341274

Epoch: 6| Step: 11
Training loss: 1.405980063067802
Validation loss: 2.5828171597087186

Epoch: 6| Step: 12
Training loss: 1.4338935725622397
Validation loss: 2.6075745972962587

Epoch: 6| Step: 13
Training loss: 1.7440754877210753
Validation loss: 2.581873565322406

Epoch: 488| Step: 0
Training loss: 1.137620181766857
Validation loss: 2.5653712356246308

Epoch: 6| Step: 1
Training loss: 1.1538157226755539
Validation loss: 2.5738079431599

Epoch: 6| Step: 2
Training loss: 1.0267685124632695
Validation loss: 2.5676247758845623

Epoch: 6| Step: 3
Training loss: 1.1049196746594958
Validation loss: 2.5547459414319285

Epoch: 6| Step: 4
Training loss: 1.563839300275505
Validation loss: 2.5758918803416386

Epoch: 6| Step: 5
Training loss: 1.292189487146697
Validation loss: 2.5588111958508124

Epoch: 6| Step: 6
Training loss: 1.3897740192729162
Validation loss: 2.5742982328052753

Epoch: 6| Step: 7
Training loss: 1.0440151380376834
Validation loss: 2.576191613441249

Epoch: 6| Step: 8
Training loss: 0.7471281141471837
Validation loss: 2.5598401987956216

Epoch: 6| Step: 9
Training loss: 1.9299300191970181
Validation loss: 2.591202466426933

Epoch: 6| Step: 10
Training loss: 1.1771853354940218
Validation loss: 2.6024925227310627

Epoch: 6| Step: 11
Training loss: 0.9083281400222939
Validation loss: 2.619247755504443

Epoch: 6| Step: 12
Training loss: 1.2168183301867985
Validation loss: 2.5899269185802236

Epoch: 6| Step: 13
Training loss: 0.7931834714722749
Validation loss: 2.5922712688811793

Epoch: 489| Step: 0
Training loss: 1.3042998051960337
Validation loss: 2.6103007154565443

Epoch: 6| Step: 1
Training loss: 1.772394688736954
Validation loss: 2.623798941348699

Epoch: 6| Step: 2
Training loss: 1.3112086801046114
Validation loss: 2.610565549607735

Epoch: 6| Step: 3
Training loss: 1.076170379582247
Validation loss: 2.5962090397946866

Epoch: 6| Step: 4
Training loss: 1.069495453106603
Validation loss: 2.56173136378515

Epoch: 6| Step: 5
Training loss: 1.1199737164274353
Validation loss: 2.580002031763499

Epoch: 6| Step: 6
Training loss: 1.1210755669052983
Validation loss: 2.5812165330225265

Epoch: 6| Step: 7
Training loss: 1.2418754713559612
Validation loss: 2.5978795790356126

Epoch: 6| Step: 8
Training loss: 1.2943056691609474
Validation loss: 2.585875710658529

Epoch: 6| Step: 9
Training loss: 1.3067025710220366
Validation loss: 2.56626541406308

Epoch: 6| Step: 10
Training loss: 0.8510448037085424
Validation loss: 2.6102834928621412

Epoch: 6| Step: 11
Training loss: 0.8639290566900074
Validation loss: 2.6142222307875143

Epoch: 6| Step: 12
Training loss: 1.2772676871048194
Validation loss: 2.5888198152116955

Epoch: 6| Step: 13
Training loss: 1.476602462954368
Validation loss: 2.625771764073774

Epoch: 490| Step: 0
Training loss: 1.1562337100969258
Validation loss: 2.606553314926635

Epoch: 6| Step: 1
Training loss: 1.2712775793244102
Validation loss: 2.6192826474370983

Epoch: 6| Step: 2
Training loss: 1.0797747277274343
Validation loss: 2.6307601093273023

Epoch: 6| Step: 3
Training loss: 1.4068794537155582
Validation loss: 2.6373296102836807

Epoch: 6| Step: 4
Training loss: 1.2185009432895846
Validation loss: 2.6084727804909797

Epoch: 6| Step: 5
Training loss: 0.9298123828774786
Validation loss: 2.585886142162351

Epoch: 6| Step: 6
Training loss: 0.8212792648837784
Validation loss: 2.5668905517978233

Epoch: 6| Step: 7
Training loss: 1.127135316610108
Validation loss: 2.5277511720437764

Epoch: 6| Step: 8
Training loss: 0.9067511323953841
Validation loss: 2.5158332316113317

Epoch: 6| Step: 9
Training loss: 1.8376424461736969
Validation loss: 2.549863190573088

Epoch: 6| Step: 10
Training loss: 1.3484965924766976
Validation loss: 2.506122653448696

Epoch: 6| Step: 11
Training loss: 0.8623336147757141
Validation loss: 2.5207853367777973

Epoch: 6| Step: 12
Training loss: 1.1789762866714883
Validation loss: 2.5376808833693887

Epoch: 6| Step: 13
Training loss: 1.606439079110247
Validation loss: 2.5647821326164983

Epoch: 491| Step: 0
Training loss: 1.5388495593242049
Validation loss: 2.5983138660893856

Epoch: 6| Step: 1
Training loss: 0.8011255780052925
Validation loss: 2.610697961518727

Epoch: 6| Step: 2
Training loss: 0.9137307567631452
Validation loss: 2.569124306916595

Epoch: 6| Step: 3
Training loss: 1.2438935853514426
Validation loss: 2.581270592330849

Epoch: 6| Step: 4
Training loss: 1.2170582792077371
Validation loss: 2.591889972824378

Epoch: 6| Step: 5
Training loss: 1.3228819634799385
Validation loss: 2.6084080732542643

Epoch: 6| Step: 6
Training loss: 1.277302032629403
Validation loss: 2.6035323133739134

Epoch: 6| Step: 7
Training loss: 1.3969234176539669
Validation loss: 2.61684926540694

Epoch: 6| Step: 8
Training loss: 1.0324338417932908
Validation loss: 2.6110285863604026

Epoch: 6| Step: 9
Training loss: 1.2646884514211474
Validation loss: 2.620785820439659

Epoch: 6| Step: 10
Training loss: 0.7959491362543006
Validation loss: 2.614093477897372

Epoch: 6| Step: 11
Training loss: 1.3082660321624322
Validation loss: 2.6013513851586536

Epoch: 6| Step: 12
Training loss: 1.3020097584600443
Validation loss: 2.5861917020147227

Epoch: 6| Step: 13
Training loss: 1.3589434760930348
Validation loss: 2.567985647656525

Epoch: 492| Step: 0
Training loss: 1.3598896674673009
Validation loss: 2.5998621490336618

Epoch: 6| Step: 1
Training loss: 0.7348942645565585
Validation loss: 2.567687075308383

Epoch: 6| Step: 2
Training loss: 1.1300279792765107
Validation loss: 2.539908016707451

Epoch: 6| Step: 3
Training loss: 1.1452306491804993
Validation loss: 2.5241423942776295

Epoch: 6| Step: 4
Training loss: 0.7256935009095924
Validation loss: 2.515815731199598

Epoch: 6| Step: 5
Training loss: 1.5909782691876542
Validation loss: 2.5754356340738345

Epoch: 6| Step: 6
Training loss: 0.7666859574240608
Validation loss: 2.57645071385364

Epoch: 6| Step: 7
Training loss: 1.158589239233886
Validation loss: 2.591281211623938

Epoch: 6| Step: 8
Training loss: 1.4213492291249301
Validation loss: 2.6167301175641375

Epoch: 6| Step: 9
Training loss: 1.4059818012069047
Validation loss: 2.628017991556469

Epoch: 6| Step: 10
Training loss: 1.4253789464796738
Validation loss: 2.6503909770858853

Epoch: 6| Step: 11
Training loss: 1.4860326245142148
Validation loss: 2.6571636792860325

Epoch: 6| Step: 12
Training loss: 0.7627201637976735
Validation loss: 2.6264365738716977

Epoch: 6| Step: 13
Training loss: 1.1095273625153037
Validation loss: 2.601927574750004

Epoch: 493| Step: 0
Training loss: 0.8715587452574749
Validation loss: 2.626500483616822

Epoch: 6| Step: 1
Training loss: 1.4700362883519764
Validation loss: 2.611028261367751

Epoch: 6| Step: 2
Training loss: 1.7999740413277452
Validation loss: 2.5741941115449936

Epoch: 6| Step: 3
Training loss: 1.0504777321069048
Validation loss: 2.579433040973644

Epoch: 6| Step: 4
Training loss: 1.0943171529333824
Validation loss: 2.5727791279673666

Epoch: 6| Step: 5
Training loss: 1.1284090947157557
Validation loss: 2.5506331005924108

Epoch: 6| Step: 6
Training loss: 1.181781350575578
Validation loss: 2.592187465425002

Epoch: 6| Step: 7
Training loss: 1.3506752144633125
Validation loss: 2.570078464394134

Epoch: 6| Step: 8
Training loss: 0.6694533820256962
Validation loss: 2.6107929953482416

Epoch: 6| Step: 9
Training loss: 1.046738003549284
Validation loss: 2.58871542635713

Epoch: 6| Step: 10
Training loss: 0.7694195119220629
Validation loss: 2.539192153737756

Epoch: 6| Step: 11
Training loss: 0.9744811193438807
Validation loss: 2.5883502719019233

Epoch: 6| Step: 12
Training loss: 1.460168809668345
Validation loss: 2.5762090898214587

Epoch: 6| Step: 13
Training loss: 1.1040710671743281
Validation loss: 2.587281654050084

Epoch: 494| Step: 0
Training loss: 1.2231061308842401
Validation loss: 2.5619868503281866

Epoch: 6| Step: 1
Training loss: 1.1161257093036188
Validation loss: 2.535871328444958

Epoch: 6| Step: 2
Training loss: 0.9893558374550505
Validation loss: 2.544965169756801

Epoch: 6| Step: 3
Training loss: 1.6598898999343827
Validation loss: 2.518845814937167

Epoch: 6| Step: 4
Training loss: 1.18319690459648
Validation loss: 2.549108972329965

Epoch: 6| Step: 5
Training loss: 1.2428996605796145
Validation loss: 2.5519285547276045

Epoch: 6| Step: 6
Training loss: 1.0376249421963746
Validation loss: 2.568057950094436

Epoch: 6| Step: 7
Training loss: 1.0320008174501183
Validation loss: 2.5464279343092953

Epoch: 6| Step: 8
Training loss: 1.2433965784679581
Validation loss: 2.559604123459105

Epoch: 6| Step: 9
Training loss: 1.1896868195868737
Validation loss: 2.5417056316883584

Epoch: 6| Step: 10
Training loss: 1.0449652261743327
Validation loss: 2.58204394986439

Epoch: 6| Step: 11
Training loss: 1.1510455043722994
Validation loss: 2.576892915111248

Epoch: 6| Step: 12
Training loss: 1.0744628074141498
Validation loss: 2.566898413819117

Epoch: 6| Step: 13
Training loss: 0.859274286090636
Validation loss: 2.5722162027973026

Epoch: 495| Step: 0
Training loss: 1.0621216044084922
Validation loss: 2.590312406003528

Epoch: 6| Step: 1
Training loss: 0.818069042334989
Validation loss: 2.6070280523593174

Epoch: 6| Step: 2
Training loss: 1.1086183573469746
Validation loss: 2.598284719136135

Epoch: 6| Step: 3
Training loss: 1.241144762293516
Validation loss: 2.623624883866987

Epoch: 6| Step: 4
Training loss: 1.0546617858012608
Validation loss: 2.6181258107515863

Epoch: 6| Step: 5
Training loss: 1.4982151697910635
Validation loss: 2.617841241912698

Epoch: 6| Step: 6
Training loss: 1.3370483420169896
Validation loss: 2.5926165910796057

Epoch: 6| Step: 7
Training loss: 0.9195833332411492
Validation loss: 2.56633076731827

Epoch: 6| Step: 8
Training loss: 1.2599749250793102
Validation loss: 2.565003123692166

Epoch: 6| Step: 9
Training loss: 1.2445483056268878
Validation loss: 2.547441247597093

Epoch: 6| Step: 10
Training loss: 1.0332170856881127
Validation loss: 2.5125006629854405

Epoch: 6| Step: 11
Training loss: 1.1998970027272886
Validation loss: 2.5178468075044225

Epoch: 6| Step: 12
Training loss: 0.8888107694299587
Validation loss: 2.528023252573393

Epoch: 6| Step: 13
Training loss: 1.4434470019757626
Validation loss: 2.5462969334007934

Epoch: 496| Step: 0
Training loss: 1.3210355144638821
Validation loss: 2.554352146894929

Epoch: 6| Step: 1
Training loss: 0.9836784199092536
Validation loss: 2.564420069263177

Epoch: 6| Step: 2
Training loss: 0.9980071595533342
Validation loss: 2.5160785659273075

Epoch: 6| Step: 3
Training loss: 0.8865492738605142
Validation loss: 2.515222177703545

Epoch: 6| Step: 4
Training loss: 0.95592007648892
Validation loss: 2.555737923248108

Epoch: 6| Step: 5
Training loss: 1.1642732877427577
Validation loss: 2.567750647677793

Epoch: 6| Step: 6
Training loss: 1.3691253008236568
Validation loss: 2.5641440743185555

Epoch: 6| Step: 7
Training loss: 0.64862721896495
Validation loss: 2.5939361089383546

Epoch: 6| Step: 8
Training loss: 0.9315260010907696
Validation loss: 2.609457626640918

Epoch: 6| Step: 9
Training loss: 1.648816684302733
Validation loss: 2.583103529612465

Epoch: 6| Step: 10
Training loss: 1.043555048478964
Validation loss: 2.6126829728271197

Epoch: 6| Step: 11
Training loss: 1.4981239030473534
Validation loss: 2.609371573622961

Epoch: 6| Step: 12
Training loss: 1.2361760580786105
Validation loss: 2.5972112538019805

Epoch: 6| Step: 13
Training loss: 0.9166593912587296
Validation loss: 2.5734998176577975

Epoch: 497| Step: 0
Training loss: 0.9402933467538329
Validation loss: 2.594102376205897

Epoch: 6| Step: 1
Training loss: 1.1787172584395813
Validation loss: 2.5960848317209395

Epoch: 6| Step: 2
Training loss: 1.3516212406513637
Validation loss: 2.601970327892566

Epoch: 6| Step: 3
Training loss: 1.1795285856818447
Validation loss: 2.595696902811027

Epoch: 6| Step: 4
Training loss: 0.9319477334859095
Validation loss: 2.587517774751808

Epoch: 6| Step: 5
Training loss: 0.8767315896969948
Validation loss: 2.5937986560838544

Epoch: 6| Step: 6
Training loss: 1.0202180149791875
Validation loss: 2.6000312561526004

Epoch: 6| Step: 7
Training loss: 0.9282910092554665
Validation loss: 2.6279551137534476

Epoch: 6| Step: 8
Training loss: 1.2566064300485524
Validation loss: 2.6175912706299815

Epoch: 6| Step: 9
Training loss: 1.0036184291664885
Validation loss: 2.6121307307153185

Epoch: 6| Step: 10
Training loss: 1.183466939144467
Validation loss: 2.6244227736201933

Epoch: 6| Step: 11
Training loss: 1.694242289041098
Validation loss: 2.597611151985436

Epoch: 6| Step: 12
Training loss: 1.2252245366366084
Validation loss: 2.534794686958341

Epoch: 6| Step: 13
Training loss: 1.1295025052755874
Validation loss: 2.516423677395821

Epoch: 498| Step: 0
Training loss: 1.0253215076221773
Validation loss: 2.558243033575905

Epoch: 6| Step: 1
Training loss: 1.5100992680439667
Validation loss: 2.555878268035249

Epoch: 6| Step: 2
Training loss: 1.1340935139792077
Validation loss: 2.5401174065596375

Epoch: 6| Step: 3
Training loss: 0.7827477784346102
Validation loss: 2.5135635085027013

Epoch: 6| Step: 4
Training loss: 1.2252573735533439
Validation loss: 2.5217041007326757

Epoch: 6| Step: 5
Training loss: 1.0939612048451712
Validation loss: 2.5303001368679805

Epoch: 6| Step: 6
Training loss: 0.8847728333169044
Validation loss: 2.545419709668161

Epoch: 6| Step: 7
Training loss: 0.93537107978192
Validation loss: 2.5711825959241885

Epoch: 6| Step: 8
Training loss: 1.0377318387502061
Validation loss: 2.5846421161264224

Epoch: 6| Step: 9
Training loss: 1.098127270838952
Validation loss: 2.597022738953975

Epoch: 6| Step: 10
Training loss: 1.2904127043352316
Validation loss: 2.621039100161485

Epoch: 6| Step: 11
Training loss: 1.5207585181380712
Validation loss: 2.6434901620805356

Epoch: 6| Step: 12
Training loss: 1.0240466801873926
Validation loss: 2.6367804718389447

Epoch: 6| Step: 13
Training loss: 1.0605832369421104
Validation loss: 2.6154569676190857

Epoch: 499| Step: 0
Training loss: 1.6224478707660446
Validation loss: 2.641004918167858

Epoch: 6| Step: 1
Training loss: 1.2016065849878068
Validation loss: 2.6136563650800158

Epoch: 6| Step: 2
Training loss: 0.8099248130658946
Validation loss: 2.633117517896019

Epoch: 6| Step: 3
Training loss: 1.3361570835906305
Validation loss: 2.57586502454072

Epoch: 6| Step: 4
Training loss: 0.5986285808469675
Validation loss: 2.6174728392286544

Epoch: 6| Step: 5
Training loss: 0.9364377679713057
Validation loss: 2.587929073024139

Epoch: 6| Step: 6
Training loss: 0.9574611398963516
Validation loss: 2.568382753861332

Epoch: 6| Step: 7
Training loss: 1.1881943730504718
Validation loss: 2.612936458131976

Epoch: 6| Step: 8
Training loss: 1.0867193686883236
Validation loss: 2.5603168931458473

Epoch: 6| Step: 9
Training loss: 1.0141589808009557
Validation loss: 2.588492752642712

Epoch: 6| Step: 10
Training loss: 0.9859009072454852
Validation loss: 2.554105029638562

Epoch: 6| Step: 11
Training loss: 1.3972856690267794
Validation loss: 2.590834959174353

Epoch: 6| Step: 12
Training loss: 1.2155148532262765
Validation loss: 2.557547915304363

Epoch: 6| Step: 13
Training loss: 1.2506103932653878
Validation loss: 2.5548482523638736

Epoch: 500| Step: 0
Training loss: 0.9818271482524624
Validation loss: 2.5394054610961367

Epoch: 6| Step: 1
Training loss: 1.070843530054688
Validation loss: 2.582094111285581

Epoch: 6| Step: 2
Training loss: 1.434934649026118
Validation loss: 2.5755430655437133

Epoch: 6| Step: 3
Training loss: 0.9683347242633156
Validation loss: 2.582068276120854

Epoch: 6| Step: 4
Training loss: 1.2089708663358285
Validation loss: 2.5895311599430975

Epoch: 6| Step: 5
Training loss: 0.7766535009105956
Validation loss: 2.607991181310685

Epoch: 6| Step: 6
Training loss: 1.6434701862700671
Validation loss: 2.5435752507693303

Epoch: 6| Step: 7
Training loss: 0.9561892172251124
Validation loss: 2.5731140083623547

Epoch: 6| Step: 8
Training loss: 0.8143242384108229
Validation loss: 2.5740274900439033

Epoch: 6| Step: 9
Training loss: 1.0377596955274935
Validation loss: 2.5454303638701394

Epoch: 6| Step: 10
Training loss: 1.0231142188676898
Validation loss: 2.587299217030119

Epoch: 6| Step: 11
Training loss: 0.8341380922401065
Validation loss: 2.5679479902040616

Epoch: 6| Step: 12
Training loss: 1.2799972829938902
Validation loss: 2.6197780590103146

Epoch: 6| Step: 13
Training loss: 1.5117352309794843
Validation loss: 2.5810229752160176

Epoch: 501| Step: 0
Training loss: 0.838263653146541
Validation loss: 2.609576249880199

Epoch: 6| Step: 1
Training loss: 0.9485576823727327
Validation loss: 2.6069022798655914

Epoch: 6| Step: 2
Training loss: 1.021794930217125
Validation loss: 2.660658367183946

Epoch: 6| Step: 3
Training loss: 0.8324251630441573
Validation loss: 2.6093906979073003

Epoch: 6| Step: 4
Training loss: 1.1735927453695119
Validation loss: 2.656022824460039

Epoch: 6| Step: 5
Training loss: 1.0114789406078066
Validation loss: 2.6641199273370373

Epoch: 6| Step: 6
Training loss: 1.681865681509388
Validation loss: 2.64399895136984

Epoch: 6| Step: 7
Training loss: 1.2922612124248314
Validation loss: 2.597970282038568

Epoch: 6| Step: 8
Training loss: 1.135366415375843
Validation loss: 2.5954476894113396

Epoch: 6| Step: 9
Training loss: 0.7136445122177939
Validation loss: 2.5804087967310494

Epoch: 6| Step: 10
Training loss: 1.2671562162740455
Validation loss: 2.590547250951836

Epoch: 6| Step: 11
Training loss: 0.8512819510469931
Validation loss: 2.590273942880126

Epoch: 6| Step: 12
Training loss: 1.5467823655876478
Validation loss: 2.6076476955451264

Epoch: 6| Step: 13
Training loss: 1.0380799660282154
Validation loss: 2.5976497897100876

Epoch: 502| Step: 0
Training loss: 1.0359977324913867
Validation loss: 2.587282804441311

Epoch: 6| Step: 1
Training loss: 0.8693499023851671
Validation loss: 2.5744772702569185

Epoch: 6| Step: 2
Training loss: 1.2917402718194118
Validation loss: 2.603485007050223

Epoch: 6| Step: 3
Training loss: 0.9367899430990146
Validation loss: 2.6042406385847174

Epoch: 6| Step: 4
Training loss: 0.8886258962285696
Validation loss: 2.5529525187477997

Epoch: 6| Step: 5
Training loss: 1.2290348477990736
Validation loss: 2.5140179914038137

Epoch: 6| Step: 6
Training loss: 1.1906204884361036
Validation loss: 2.5421220831016953

Epoch: 6| Step: 7
Training loss: 1.4805142438435892
Validation loss: 2.535972958283004

Epoch: 6| Step: 8
Training loss: 1.171120158909932
Validation loss: 2.5308068547255216

Epoch: 6| Step: 9
Training loss: 1.2381711122648074
Validation loss: 2.5123304111167806

Epoch: 6| Step: 10
Training loss: 0.7908063070009074
Validation loss: 2.4776893071641917

Epoch: 6| Step: 11
Training loss: 0.8851273830787396
Validation loss: 2.5256308580676405

Epoch: 6| Step: 12
Training loss: 1.357435487088899
Validation loss: 2.5057503350568524

Epoch: 6| Step: 13
Training loss: 1.1643567321458224
Validation loss: 2.5610100200803796

Epoch: 503| Step: 0
Training loss: 0.8787333000408645
Validation loss: 2.5219062060951942

Epoch: 6| Step: 1
Training loss: 1.1649404709468696
Validation loss: 2.5702736104150183

Epoch: 6| Step: 2
Training loss: 1.1410733217189135
Validation loss: 2.600102664523453

Epoch: 6| Step: 3
Training loss: 0.846599993095515
Validation loss: 2.616505025039872

Epoch: 6| Step: 4
Training loss: 1.2272896039007894
Validation loss: 2.5993804210767495

Epoch: 6| Step: 5
Training loss: 0.6864175511364852
Validation loss: 2.634739092960808

Epoch: 6| Step: 6
Training loss: 1.2609684369571172
Validation loss: 2.610177164199951

Epoch: 6| Step: 7
Training loss: 0.9701181410586465
Validation loss: 2.5993165388645254

Epoch: 6| Step: 8
Training loss: 1.8014185640349474
Validation loss: 2.643815988871863

Epoch: 6| Step: 9
Training loss: 0.7920887767063574
Validation loss: 2.6266986997425192

Epoch: 6| Step: 10
Training loss: 0.9539543670840653
Validation loss: 2.612864338886627

Epoch: 6| Step: 11
Training loss: 0.8595596115184706
Validation loss: 2.610232776100826

Epoch: 6| Step: 12
Training loss: 1.431455009470285
Validation loss: 2.6038064381832178

Epoch: 6| Step: 13
Training loss: 1.0858739381479556
Validation loss: 2.6095497741389315

Epoch: 504| Step: 0
Training loss: 1.7237564690947773
Validation loss: 2.6007169905107568

Epoch: 6| Step: 1
Training loss: 0.5647277427988726
Validation loss: 2.605991054917056

Epoch: 6| Step: 2
Training loss: 1.1914343658631767
Validation loss: 2.6359801459528502

Epoch: 6| Step: 3
Training loss: 0.7017842755741471
Validation loss: 2.6385385816908506

Epoch: 6| Step: 4
Training loss: 1.0809116010383728
Validation loss: 2.591035465918529

Epoch: 6| Step: 5
Training loss: 1.2262912134366688
Validation loss: 2.6154517510511064

Epoch: 6| Step: 6
Training loss: 1.0382702323839936
Validation loss: 2.6268354562838265

Epoch: 6| Step: 7
Training loss: 1.3898114600030371
Validation loss: 2.6052353308185614

Epoch: 6| Step: 8
Training loss: 1.0148870868548068
Validation loss: 2.587094042276912

Epoch: 6| Step: 9
Training loss: 0.9554693750736566
Validation loss: 2.640950258090016

Epoch: 6| Step: 10
Training loss: 1.0978807104449306
Validation loss: 2.5983024938733443

Epoch: 6| Step: 11
Training loss: 1.0067453574904088
Validation loss: 2.611423121171329

Epoch: 6| Step: 12
Training loss: 0.753082299505905
Validation loss: 2.6260404707492913

Epoch: 6| Step: 13
Training loss: 1.2747333696608114
Validation loss: 2.6136342008995905

Epoch: 505| Step: 0
Training loss: 1.0656689341149794
Validation loss: 2.633908429503687

Epoch: 6| Step: 1
Training loss: 1.094825052804266
Validation loss: 2.6233276043972014

Epoch: 6| Step: 2
Training loss: 0.6330608069138959
Validation loss: 2.6102597772343903

Epoch: 6| Step: 3
Training loss: 1.2366644475682202
Validation loss: 2.6043006485138576

Epoch: 6| Step: 4
Training loss: 1.7188648532293027
Validation loss: 2.614310224135494

Epoch: 6| Step: 5
Training loss: 0.9355332407425734
Validation loss: 2.5942485333680927

Epoch: 6| Step: 6
Training loss: 0.6653574042981188
Validation loss: 2.597085856796443

Epoch: 6| Step: 7
Training loss: 0.6895268214446829
Validation loss: 2.6153478095982416

Epoch: 6| Step: 8
Training loss: 1.4472232869039188
Validation loss: 2.5857361225398083

Epoch: 6| Step: 9
Training loss: 1.2868592825360963
Validation loss: 2.614541313311891

Epoch: 6| Step: 10
Training loss: 0.930037680959791
Validation loss: 2.5645641454106114

Epoch: 6| Step: 11
Training loss: 0.8876510290130992
Validation loss: 2.608044169083648

Epoch: 6| Step: 12
Training loss: 1.1347679886653792
Validation loss: 2.5930970169737373

Epoch: 6| Step: 13
Training loss: 1.21825741325642
Validation loss: 2.5788734331631424

Epoch: 506| Step: 0
Training loss: 0.8756665688122464
Validation loss: 2.569639523088712

Epoch: 6| Step: 1
Training loss: 1.1162866014415485
Validation loss: 2.5626833910363325

Epoch: 6| Step: 2
Training loss: 1.0968161520971322
Validation loss: 2.5770945249976625

Epoch: 6| Step: 3
Training loss: 1.2464696143892326
Validation loss: 2.5433602429059583

Epoch: 6| Step: 4
Training loss: 0.9894934295505545
Validation loss: 2.5554446624651814

Epoch: 6| Step: 5
Training loss: 1.0668991123685971
Validation loss: 2.5676224734617117

Epoch: 6| Step: 6
Training loss: 0.8439442799444223
Validation loss: 2.5472238252573542

Epoch: 6| Step: 7
Training loss: 1.5234684085155803
Validation loss: 2.5280966827073432

Epoch: 6| Step: 8
Training loss: 1.0139890553073747
Validation loss: 2.5672368773695857

Epoch: 6| Step: 9
Training loss: 0.9843648274213964
Validation loss: 2.559438133229858

Epoch: 6| Step: 10
Training loss: 1.414970148802855
Validation loss: 2.5273932219633357

Epoch: 6| Step: 11
Training loss: 0.4718325823230262
Validation loss: 2.540302082440684

Epoch: 6| Step: 12
Training loss: 1.409933225795602
Validation loss: 2.5789802567068394

Epoch: 6| Step: 13
Training loss: 0.8708116219900199
Validation loss: 2.6084218280254077

Epoch: 507| Step: 0
Training loss: 0.7088074686746224
Validation loss: 2.635648696207216

Epoch: 6| Step: 1
Training loss: 1.7168746427209993
Validation loss: 2.6323598182417496

Epoch: 6| Step: 2
Training loss: 0.9530835689857803
Validation loss: 2.6659128125915466

Epoch: 6| Step: 3
Training loss: 1.196456660772624
Validation loss: 2.6094309109602523

Epoch: 6| Step: 4
Training loss: 1.122712140162098
Validation loss: 2.684813342972562

Epoch: 6| Step: 5
Training loss: 1.050184910250754
Validation loss: 2.6523482976453985

Epoch: 6| Step: 6
Training loss: 0.7162791365044786
Validation loss: 2.65640540250496

Epoch: 6| Step: 7
Training loss: 1.3766432826124386
Validation loss: 2.639991976117345

Epoch: 6| Step: 8
Training loss: 0.8974876690392036
Validation loss: 2.62470041783426

Epoch: 6| Step: 9
Training loss: 1.0994908758516064
Validation loss: 2.6249482422710284

Epoch: 6| Step: 10
Training loss: 0.9176954146539271
Validation loss: 2.584505430220793

Epoch: 6| Step: 11
Training loss: 1.1403855895571322
Validation loss: 2.584243311138678

Epoch: 6| Step: 12
Training loss: 1.036844108263925
Validation loss: 2.558603638447723

Epoch: 6| Step: 13
Training loss: 1.0567506179392632
Validation loss: 2.5536198109216643

Epoch: 508| Step: 0
Training loss: 1.0643956720088572
Validation loss: 2.520156872981312

Epoch: 6| Step: 1
Training loss: 0.9750579841195726
Validation loss: 2.5707543928911387

Epoch: 6| Step: 2
Training loss: 0.8459638585696811
Validation loss: 2.5878099131985364

Epoch: 6| Step: 3
Training loss: 0.6154582509416173
Validation loss: 2.610525009336878

Epoch: 6| Step: 4
Training loss: 0.9763820023623174
Validation loss: 2.58788248845232

Epoch: 6| Step: 5
Training loss: 1.06287209222318
Validation loss: 2.6209094046891277

Epoch: 6| Step: 6
Training loss: 1.2940754835762067
Validation loss: 2.605070428038535

Epoch: 6| Step: 7
Training loss: 0.9525361039735811
Validation loss: 2.675814396852236

Epoch: 6| Step: 8
Training loss: 0.9168869461914334
Validation loss: 2.6715508056646606

Epoch: 6| Step: 9
Training loss: 1.1390499056733383
Validation loss: 2.6566418169981643

Epoch: 6| Step: 10
Training loss: 1.2978924356630606
Validation loss: 2.6443860523142604

Epoch: 6| Step: 11
Training loss: 1.5582623045674355
Validation loss: 2.6176481970085588

Epoch: 6| Step: 12
Training loss: 1.2526627789251454
Validation loss: 2.6156962255701406

Epoch: 6| Step: 13
Training loss: 1.1639148695349137
Validation loss: 2.5971787038339245

Epoch: 509| Step: 0
Training loss: 0.8256478958940259
Validation loss: 2.5677888995672333

Epoch: 6| Step: 1
Training loss: 1.1320844217874806
Validation loss: 2.5919951101366108

Epoch: 6| Step: 2
Training loss: 1.6712276595911448
Validation loss: 2.572548834540109

Epoch: 6| Step: 3
Training loss: 0.7103880970674041
Validation loss: 2.586076836357236

Epoch: 6| Step: 4
Training loss: 1.2512666007206863
Validation loss: 2.611308969744388

Epoch: 6| Step: 5
Training loss: 0.904543882048849
Validation loss: 2.616215174609849

Epoch: 6| Step: 6
Training loss: 1.0641387195148608
Validation loss: 2.631587028631335

Epoch: 6| Step: 7
Training loss: 1.3073245141916732
Validation loss: 2.638864321361343

Epoch: 6| Step: 8
Training loss: 1.1688174733151533
Validation loss: 2.630059055481179

Epoch: 6| Step: 9
Training loss: 0.7808557660094345
Validation loss: 2.6380253695510816

Epoch: 6| Step: 10
Training loss: 0.953987325586141
Validation loss: 2.6037067067835946

Epoch: 6| Step: 11
Training loss: 1.189214272155471
Validation loss: 2.603981732764812

Epoch: 6| Step: 12
Training loss: 0.6409351714495055
Validation loss: 2.6195073437158243

Epoch: 6| Step: 13
Training loss: 1.3551631440064602
Validation loss: 2.5836727836932813

Epoch: 510| Step: 0
Training loss: 1.180967028597703
Validation loss: 2.5287385810351446

Epoch: 6| Step: 1
Training loss: 0.9445490315595968
Validation loss: 2.541245291599275

Epoch: 6| Step: 2
Training loss: 1.2620346571430112
Validation loss: 2.5591030274990465

Epoch: 6| Step: 3
Training loss: 0.9118292825702192
Validation loss: 2.568917860197233

Epoch: 6| Step: 4
Training loss: 1.0731279418229587
Validation loss: 2.567663655167659

Epoch: 6| Step: 5
Training loss: 0.6119184477424009
Validation loss: 2.5555459462693033

Epoch: 6| Step: 6
Training loss: 0.8884281033700971
Validation loss: 2.56105379562581

Epoch: 6| Step: 7
Training loss: 0.9228548564549349
Validation loss: 2.5588365795434744

Epoch: 6| Step: 8
Training loss: 1.1008836534787425
Validation loss: 2.5557383666147975

Epoch: 6| Step: 9
Training loss: 1.0296182148941289
Validation loss: 2.5235880830278

Epoch: 6| Step: 10
Training loss: 1.2295308731937546
Validation loss: 2.582033975447196

Epoch: 6| Step: 11
Training loss: 1.6418382790550086
Validation loss: 2.572583940313374

Epoch: 6| Step: 12
Training loss: 1.0872343265002813
Validation loss: 2.6096663361215193

Epoch: 6| Step: 13
Training loss: 0.5653684909099228
Validation loss: 2.615597371430956

Epoch: 511| Step: 0
Training loss: 1.3266933129540388
Validation loss: 2.542957946866299

Epoch: 6| Step: 1
Training loss: 0.9996634155310458
Validation loss: 2.6037476348098227

Epoch: 6| Step: 2
Training loss: 0.9946548540928389
Validation loss: 2.5959259574341984

Epoch: 6| Step: 3
Training loss: 1.060825599308594
Validation loss: 2.559505652022346

Epoch: 6| Step: 4
Training loss: 0.7465445070585458
Validation loss: 2.5918328278805722

Epoch: 6| Step: 5
Training loss: 1.195187830189202
Validation loss: 2.58224015091049

Epoch: 6| Step: 6
Training loss: 1.1533440854741879
Validation loss: 2.584406943387371

Epoch: 6| Step: 7
Training loss: 1.539511987721874
Validation loss: 2.584300742945159

Epoch: 6| Step: 8
Training loss: 1.1525966043593379
Validation loss: 2.549646981511287

Epoch: 6| Step: 9
Training loss: 0.9584335951947899
Validation loss: 2.614170495031438

Epoch: 6| Step: 10
Training loss: 1.0773373919680442
Validation loss: 2.6253215174897524

Epoch: 6| Step: 11
Training loss: 0.8481964640071663
Validation loss: 2.6108072157566156

Epoch: 6| Step: 12
Training loss: 0.634337271897976
Validation loss: 2.604657057499054

Epoch: 6| Step: 13
Training loss: 0.9931450075855346
Validation loss: 2.594132479337144

Epoch: 512| Step: 0
Training loss: 1.0778291821647359
Validation loss: 2.5882671675557374

Epoch: 6| Step: 1
Training loss: 1.0149779385955005
Validation loss: 2.5598345103565556

Epoch: 6| Step: 2
Training loss: 0.6679177515739376
Validation loss: 2.5630100932075677

Epoch: 6| Step: 3
Training loss: 0.7534368368024846
Validation loss: 2.542085927364607

Epoch: 6| Step: 4
Training loss: 1.0199638413583727
Validation loss: 2.5445463969002966

Epoch: 6| Step: 5
Training loss: 1.2075336484781827
Validation loss: 2.535251854470192

Epoch: 6| Step: 6
Training loss: 0.7907434065740183
Validation loss: 2.52837338109846

Epoch: 6| Step: 7
Training loss: 0.3414226663339477
Validation loss: 2.5232147366867035

Epoch: 6| Step: 8
Training loss: 1.3592850227832431
Validation loss: 2.5521701586186474

Epoch: 6| Step: 9
Training loss: 1.0352167651643691
Validation loss: 2.5654213113316757

Epoch: 6| Step: 10
Training loss: 1.2531566340004328
Validation loss: 2.582993727864533

Epoch: 6| Step: 11
Training loss: 1.0216409187640272
Validation loss: 2.5966393095548863

Epoch: 6| Step: 12
Training loss: 1.812359640014144
Validation loss: 2.6082343647447233

Epoch: 6| Step: 13
Training loss: 0.8768768277356546
Validation loss: 2.6443581950655846

Epoch: 513| Step: 0
Training loss: 1.2560068284201424
Validation loss: 2.6432074151850795

Epoch: 6| Step: 1
Training loss: 1.1310403576909658
Validation loss: 2.635968839954834

Epoch: 6| Step: 2
Training loss: 0.7781562967402659
Validation loss: 2.6453350060681484

Epoch: 6| Step: 3
Training loss: 0.7565551236851519
Validation loss: 2.6035035448665145

Epoch: 6| Step: 4
Training loss: 1.0246385704706467
Validation loss: 2.5848449246858514

Epoch: 6| Step: 5
Training loss: 0.9400357285770761
Validation loss: 2.603274387863856

Epoch: 6| Step: 6
Training loss: 1.8297058182735142
Validation loss: 2.5881717265925093

Epoch: 6| Step: 7
Training loss: 1.0756216979433275
Validation loss: 2.6107657738809222

Epoch: 6| Step: 8
Training loss: 0.7121284486493946
Validation loss: 2.5557006189820752

Epoch: 6| Step: 9
Training loss: 1.0265203156651141
Validation loss: 2.586525428170698

Epoch: 6| Step: 10
Training loss: 0.5159699990880806
Validation loss: 2.5598559741330345

Epoch: 6| Step: 11
Training loss: 1.2567332121299002
Validation loss: 2.5666526962920733

Epoch: 6| Step: 12
Training loss: 1.2984112292775452
Validation loss: 2.5771420561155214

Epoch: 6| Step: 13
Training loss: 0.49375058789761467
Validation loss: 2.5238646672691925

Epoch: 514| Step: 0
Training loss: 1.015465826619359
Validation loss: 2.5312668959178923

Epoch: 6| Step: 1
Training loss: 1.0328655881410191
Validation loss: 2.5407978609081785

Epoch: 6| Step: 2
Training loss: 0.9676482796213711
Validation loss: 2.5115033728804135

Epoch: 6| Step: 3
Training loss: 1.1839407232853159
Validation loss: 2.536687478049153

Epoch: 6| Step: 4
Training loss: 0.9185961588039439
Validation loss: 2.543923260993136

Epoch: 6| Step: 5
Training loss: 1.2495882309761157
Validation loss: 2.5525059309733593

Epoch: 6| Step: 6
Training loss: 0.8358905814720762
Validation loss: 2.595497455975224

Epoch: 6| Step: 7
Training loss: 0.887332888437824
Validation loss: 2.576051882721791

Epoch: 6| Step: 8
Training loss: 1.4187816465100023
Validation loss: 2.6023912268652603

Epoch: 6| Step: 9
Training loss: 1.7866347719780789
Validation loss: 2.5978943793262177

Epoch: 6| Step: 10
Training loss: 0.9086079341342167
Validation loss: 2.5934110425683916

Epoch: 6| Step: 11
Training loss: 0.7831041078452213
Validation loss: 2.6156476357425493

Epoch: 6| Step: 12
Training loss: 0.5457117242483727
Validation loss: 2.6103585472249957

Epoch: 6| Step: 13
Training loss: 0.2506337180488256
Validation loss: 2.6437448545415703

Epoch: 515| Step: 0
Training loss: 0.9688680638387499
Validation loss: 2.6138924796934955

Epoch: 6| Step: 1
Training loss: 1.7236975465889308
Validation loss: 2.6055377551892547

Epoch: 6| Step: 2
Training loss: 0.8044515467503501
Validation loss: 2.632010653921842

Epoch: 6| Step: 3
Training loss: 0.9029516179059774
Validation loss: 2.5843004850237077

Epoch: 6| Step: 4
Training loss: 0.5054602502877666
Validation loss: 2.6178308848610325

Epoch: 6| Step: 5
Training loss: 1.1465430171597375
Validation loss: 2.5815282177165066

Epoch: 6| Step: 6
Training loss: 0.9025736594322863
Validation loss: 2.597504187133286

Epoch: 6| Step: 7
Training loss: 0.6930585826632693
Validation loss: 2.549052840791138

Epoch: 6| Step: 8
Training loss: 0.8743465572200176
Validation loss: 2.5791916655189846

Epoch: 6| Step: 9
Training loss: 1.1837545354931478
Validation loss: 2.592864540600198

Epoch: 6| Step: 10
Training loss: 1.4462677968874647
Validation loss: 2.614475256017927

Epoch: 6| Step: 11
Training loss: 1.0022856103056925
Validation loss: 2.6076803871575045

Epoch: 6| Step: 12
Training loss: 0.8641221796710136
Validation loss: 2.5997595101570985

Epoch: 6| Step: 13
Training loss: 1.1881133051762738
Validation loss: 2.600710698500503

Epoch: 516| Step: 0
Training loss: 1.0276571745750163
Validation loss: 2.6070286207399014

Epoch: 6| Step: 1
Training loss: 1.80972432666395
Validation loss: 2.6352283728773878

Epoch: 6| Step: 2
Training loss: 0.9742028988402907
Validation loss: 2.6199341815567645

Epoch: 6| Step: 3
Training loss: 0.8038146831535304
Validation loss: 2.6309924386144923

Epoch: 6| Step: 4
Training loss: 1.0670994891267258
Validation loss: 2.597900657434422

Epoch: 6| Step: 5
Training loss: 0.7954414038377636
Validation loss: 2.5710591880069775

Epoch: 6| Step: 6
Training loss: 1.0950605987084687
Validation loss: 2.5753167990650088

Epoch: 6| Step: 7
Training loss: 1.1953535384569496
Validation loss: 2.623558375179335

Epoch: 6| Step: 8
Training loss: 0.5212013247973716
Validation loss: 2.5751086814940005

Epoch: 6| Step: 9
Training loss: 0.8517393575977013
Validation loss: 2.591094675031599

Epoch: 6| Step: 10
Training loss: 0.8277672408718392
Validation loss: 2.5597499353967397

Epoch: 6| Step: 11
Training loss: 0.9240682342320418
Validation loss: 2.5919020141104383

Epoch: 6| Step: 12
Training loss: 1.3568195571009494
Validation loss: 2.584947267151854

Epoch: 6| Step: 13
Training loss: 0.8712796410617959
Validation loss: 2.5596870401725043

Epoch: 517| Step: 0
Training loss: 0.9975970125945941
Validation loss: 2.544133282701212

Epoch: 6| Step: 1
Training loss: 0.8245409295152065
Validation loss: 2.554379318197002

Epoch: 6| Step: 2
Training loss: 1.043966723116357
Validation loss: 2.567028220579255

Epoch: 6| Step: 3
Training loss: 0.9975761602482316
Validation loss: 2.5757633692553568

Epoch: 6| Step: 4
Training loss: 0.9970557859074319
Validation loss: 2.5879249193732825

Epoch: 6| Step: 5
Training loss: 1.6405417284949961
Validation loss: 2.5644804901811553

Epoch: 6| Step: 6
Training loss: 0.927094795213346
Validation loss: 2.5811499824186868

Epoch: 6| Step: 7
Training loss: 1.2528922951783448
Validation loss: 2.5827839975535216

Epoch: 6| Step: 8
Training loss: 0.7796684278093431
Validation loss: 2.5875717712724065

Epoch: 6| Step: 9
Training loss: 0.9946193479248169
Validation loss: 2.5983132050301245

Epoch: 6| Step: 10
Training loss: 0.9104802615012609
Validation loss: 2.597485207764639

Epoch: 6| Step: 11
Training loss: 1.2754321244923275
Validation loss: 2.608327595332494

Epoch: 6| Step: 12
Training loss: 0.7817830365418978
Validation loss: 2.61533617621066

Epoch: 6| Step: 13
Training loss: 0.4773843432708512
Validation loss: 2.6321813392146556

Epoch: 518| Step: 0
Training loss: 0.7696810349050792
Validation loss: 2.624740364098659

Epoch: 6| Step: 1
Training loss: 0.8523251329551407
Validation loss: 2.580430233180728

Epoch: 6| Step: 2
Training loss: 0.6032748930466983
Validation loss: 2.570376766940004

Epoch: 6| Step: 3
Training loss: 1.054632566928789
Validation loss: 2.570302470083198

Epoch: 6| Step: 4
Training loss: 0.9131510502247593
Validation loss: 2.5636742545298996

Epoch: 6| Step: 5
Training loss: 1.0416643079095202
Validation loss: 2.5647915629001874

Epoch: 6| Step: 6
Training loss: 1.3692869796565146
Validation loss: 2.5924765026241094

Epoch: 6| Step: 7
Training loss: 1.2889179495480363
Validation loss: 2.5430132625398953

Epoch: 6| Step: 8
Training loss: 0.956422012416091
Validation loss: 2.565575523579378

Epoch: 6| Step: 9
Training loss: 1.4420496220668177
Validation loss: 2.569508241923644

Epoch: 6| Step: 10
Training loss: 1.141642860990457
Validation loss: 2.5772594064040506

Epoch: 6| Step: 11
Training loss: 1.018321170536543
Validation loss: 2.5930981865351415

Epoch: 6| Step: 12
Training loss: 0.7659145897466464
Validation loss: 2.61659957068706

Epoch: 6| Step: 13
Training loss: 0.8290377211507449
Validation loss: 2.567739474566106

Epoch: 519| Step: 0
Training loss: 0.943729967574168
Validation loss: 2.6383176575719345

Epoch: 6| Step: 1
Training loss: 1.0321398277257114
Validation loss: 2.577771927518162

Epoch: 6| Step: 2
Training loss: 1.5187593279265614
Validation loss: 2.59877893386558

Epoch: 6| Step: 3
Training loss: 0.8694477353086203
Validation loss: 2.5901203370678236

Epoch: 6| Step: 4
Training loss: 1.0435520212780895
Validation loss: 2.5737966608801943

Epoch: 6| Step: 5
Training loss: 1.2565820018030056
Validation loss: 2.603689955527272

Epoch: 6| Step: 6
Training loss: 0.8728994633353405
Validation loss: 2.6153426457450246

Epoch: 6| Step: 7
Training loss: 1.1254093167289663
Validation loss: 2.5798962486985397

Epoch: 6| Step: 8
Training loss: 0.5609753396705107
Validation loss: 2.5936686427313074

Epoch: 6| Step: 9
Training loss: 0.716664023911978
Validation loss: 2.597022041535225

Epoch: 6| Step: 10
Training loss: 1.1498776184145107
Validation loss: 2.6234127330098937

Epoch: 6| Step: 11
Training loss: 1.0931983646574606
Validation loss: 2.556341809169708

Epoch: 6| Step: 12
Training loss: 0.9356606559610184
Validation loss: 2.5838260008839558

Epoch: 6| Step: 13
Training loss: 1.183105619889461
Validation loss: 2.5783266547358425

Epoch: 520| Step: 0
Training loss: 0.7477709707101773
Validation loss: 2.557622371675331

Epoch: 6| Step: 1
Training loss: 1.0141231289506256
Validation loss: 2.5482979136521773

Epoch: 6| Step: 2
Training loss: 0.9889840503212658
Validation loss: 2.580371175277943

Epoch: 6| Step: 3
Training loss: 1.1346419196401782
Validation loss: 2.6091736294643373

Epoch: 6| Step: 4
Training loss: 0.5166513747085214
Validation loss: 2.568266316598039

Epoch: 6| Step: 5
Training loss: 1.0618033649784298
Validation loss: 2.571899598312681

Epoch: 6| Step: 6
Training loss: 1.1405417006920247
Validation loss: 2.5725352138334783

Epoch: 6| Step: 7
Training loss: 1.5249963072435038
Validation loss: 2.560710313024617

Epoch: 6| Step: 8
Training loss: 0.4956625468642555
Validation loss: 2.5936627294865184

Epoch: 6| Step: 9
Training loss: 0.8144557961985011
Validation loss: 2.56514914193001

Epoch: 6| Step: 10
Training loss: 0.9517437666700659
Validation loss: 2.583343760548433

Epoch: 6| Step: 11
Training loss: 1.2815818356904312
Validation loss: 2.5738101663418753

Epoch: 6| Step: 12
Training loss: 1.2252252177075222
Validation loss: 2.568207643792361

Epoch: 6| Step: 13
Training loss: 1.1466369007557198
Validation loss: 2.6062340236475237

Epoch: 521| Step: 0
Training loss: 1.195280884966657
Validation loss: 2.5715135070617423

Epoch: 6| Step: 1
Training loss: 1.1508632136081431
Validation loss: 2.6160147980543065

Epoch: 6| Step: 2
Training loss: 1.0265265285744871
Validation loss: 2.6151209050916253

Epoch: 6| Step: 3
Training loss: 0.7586938118279657
Validation loss: 2.569711992486922

Epoch: 6| Step: 4
Training loss: 1.0817862002524532
Validation loss: 2.613391031906362

Epoch: 6| Step: 5
Training loss: 0.6562029730886131
Validation loss: 2.5797257809383005

Epoch: 6| Step: 6
Training loss: 0.8042827810615362
Validation loss: 2.6021877065881354

Epoch: 6| Step: 7
Training loss: 1.0590512458966477
Validation loss: 2.6178492143467404

Epoch: 6| Step: 8
Training loss: 0.3959551882989076
Validation loss: 2.6067077019987925

Epoch: 6| Step: 9
Training loss: 1.1059845708319234
Validation loss: 2.5815147769629756

Epoch: 6| Step: 10
Training loss: 0.6731989037367111
Validation loss: 2.5619055786121927

Epoch: 6| Step: 11
Training loss: 1.843622752825623
Validation loss: 2.589045506615409

Epoch: 6| Step: 12
Training loss: 1.0004356150730622
Validation loss: 2.550683589267344

Epoch: 6| Step: 13
Training loss: 0.538551447673152
Validation loss: 2.572277429259141

Epoch: 522| Step: 0
Training loss: 0.5661801643338518
Validation loss: 2.5701535467474197

Epoch: 6| Step: 1
Training loss: 0.6380278580467011
Validation loss: 2.5509165229689654

Epoch: 6| Step: 2
Training loss: 1.0385226804986765
Validation loss: 2.5230997191518156

Epoch: 6| Step: 3
Training loss: 1.0520016981626084
Validation loss: 2.544282881670579

Epoch: 6| Step: 4
Training loss: 1.4955186659892499
Validation loss: 2.53027749632463

Epoch: 6| Step: 5
Training loss: 1.1343168070345286
Validation loss: 2.5467184735737716

Epoch: 6| Step: 6
Training loss: 1.194834994013019
Validation loss: 2.5717276106150035

Epoch: 6| Step: 7
Training loss: 0.8656251597490404
Validation loss: 2.5976460769605856

Epoch: 6| Step: 8
Training loss: 0.7859247346906909
Validation loss: 2.6076246102203138

Epoch: 6| Step: 9
Training loss: 1.003913315328828
Validation loss: 2.5769226760944477

Epoch: 6| Step: 10
Training loss: 1.0358088901139
Validation loss: 2.5587918282926445

Epoch: 6| Step: 11
Training loss: 1.1310274463733265
Validation loss: 2.5582577217088702

Epoch: 6| Step: 12
Training loss: 0.9977762710201901
Validation loss: 2.593074593522444

Epoch: 6| Step: 13
Training loss: 1.0822443562882804
Validation loss: 2.5782276360599408

Epoch: 523| Step: 0
Training loss: 0.6047327798455148
Validation loss: 2.595804214715844

Epoch: 6| Step: 1
Training loss: 0.9669265197757744
Validation loss: 2.5787245375563104

Epoch: 6| Step: 2
Training loss: 0.8160739569223868
Validation loss: 2.616077798211946

Epoch: 6| Step: 3
Training loss: 0.9853843479354276
Validation loss: 2.596002341352012

Epoch: 6| Step: 4
Training loss: 0.9744223375058909
Validation loss: 2.5899726245269736

Epoch: 6| Step: 5
Training loss: 1.6586746605765315
Validation loss: 2.5780021392096257

Epoch: 6| Step: 6
Training loss: 0.9105199979254502
Validation loss: 2.583960524157129

Epoch: 6| Step: 7
Training loss: 0.939631835689346
Validation loss: 2.5797767993241

Epoch: 6| Step: 8
Training loss: 0.9971522672113933
Validation loss: 2.575371086237973

Epoch: 6| Step: 9
Training loss: 1.372226562291505
Validation loss: 2.5837688869463875

Epoch: 6| Step: 10
Training loss: 0.7700026564118774
Validation loss: 2.5715566841026134

Epoch: 6| Step: 11
Training loss: 0.7518605361016565
Validation loss: 2.567892226290489

Epoch: 6| Step: 12
Training loss: 1.0472725070839648
Validation loss: 2.6004630031912424

Epoch: 6| Step: 13
Training loss: 1.1647613271083468
Validation loss: 2.614104852027508

Epoch: 524| Step: 0
Training loss: 1.0267284566896182
Validation loss: 2.5762296678534136

Epoch: 6| Step: 1
Training loss: 1.5851554257694844
Validation loss: 2.6334200238742738

Epoch: 6| Step: 2
Training loss: 1.0370789719200357
Validation loss: 2.6211466215633052

Epoch: 6| Step: 3
Training loss: 1.3525132379924059
Validation loss: 2.6146083749368505

Epoch: 6| Step: 4
Training loss: 1.1023938444070909
Validation loss: 2.601287009308981

Epoch: 6| Step: 5
Training loss: 1.0931344071033091
Validation loss: 2.617949861178215

Epoch: 6| Step: 6
Training loss: 1.0720662138296413
Validation loss: 2.614666253597836

Epoch: 6| Step: 7
Training loss: 0.8028897323076349
Validation loss: 2.580605364243964

Epoch: 6| Step: 8
Training loss: 0.9271773744241735
Validation loss: 2.5588746135339724

Epoch: 6| Step: 9
Training loss: 0.7231853301022566
Validation loss: 2.559175512271355

Epoch: 6| Step: 10
Training loss: 0.6574491716181666
Validation loss: 2.586855876071898

Epoch: 6| Step: 11
Training loss: 0.8727994905424861
Validation loss: 2.574408559778695

Epoch: 6| Step: 12
Training loss: 0.7325470677509326
Validation loss: 2.5994960396281397

Epoch: 6| Step: 13
Training loss: 0.6132261895410469
Validation loss: 2.597581750413788

Epoch: 525| Step: 0
Training loss: 0.8757296653344719
Validation loss: 2.59351382494246

Epoch: 6| Step: 1
Training loss: 0.7053846923835523
Validation loss: 2.62918912686442

Epoch: 6| Step: 2
Training loss: 0.9106858640397816
Validation loss: 2.639072634465738

Epoch: 6| Step: 3
Training loss: 1.3034987830656435
Validation loss: 2.5897735020458192

Epoch: 6| Step: 4
Training loss: 0.6431631422456192
Validation loss: 2.6167083590605733

Epoch: 6| Step: 5
Training loss: 1.3070049604746428
Validation loss: 2.6077659813405525

Epoch: 6| Step: 6
Training loss: 0.8573491580515172
Validation loss: 2.594369700858015

Epoch: 6| Step: 7
Training loss: 0.9017875245115249
Validation loss: 2.588325936344558

Epoch: 6| Step: 8
Training loss: 1.3147524624627558
Validation loss: 2.5956381083147892

Epoch: 6| Step: 9
Training loss: 0.9128684697790588
Validation loss: 2.5758401888462195

Epoch: 6| Step: 10
Training loss: 1.3740495084174866
Validation loss: 2.603533435414097

Epoch: 6| Step: 11
Training loss: 1.1038521852637793
Validation loss: 2.549233470005851

Epoch: 6| Step: 12
Training loss: 0.7099190428072718
Validation loss: 2.5780423287529577

Epoch: 6| Step: 13
Training loss: 0.8421873174040814
Validation loss: 2.5855013155395232

Epoch: 526| Step: 0
Training loss: 0.9125438366119204
Validation loss: 2.5867372733443346

Epoch: 6| Step: 1
Training loss: 1.2127070142071121
Validation loss: 2.6202510373178645

Epoch: 6| Step: 2
Training loss: 1.1104254249289383
Validation loss: 2.619750070731981

Epoch: 6| Step: 3
Training loss: 1.1557197385898796
Validation loss: 2.589529804630212

Epoch: 6| Step: 4
Training loss: 1.0799807182109589
Validation loss: 2.610814373064465

Epoch: 6| Step: 5
Training loss: 0.6694580563361263
Validation loss: 2.582381318833809

Epoch: 6| Step: 6
Training loss: 0.9517380049891283
Validation loss: 2.6462333980062787

Epoch: 6| Step: 7
Training loss: 0.7383821610206337
Validation loss: 2.634363515487735

Epoch: 6| Step: 8
Training loss: 0.6831444271776954
Validation loss: 2.652616192877865

Epoch: 6| Step: 9
Training loss: 0.9029371944101402
Validation loss: 2.62619466204671

Epoch: 6| Step: 10
Training loss: 1.4547693116878984
Validation loss: 2.6275664292803027

Epoch: 6| Step: 11
Training loss: 1.1813987295181059
Validation loss: 2.5863960755960447

Epoch: 6| Step: 12
Training loss: 0.7330715705674021
Validation loss: 2.5667648840262505

Epoch: 6| Step: 13
Training loss: 0.8915058264250463
Validation loss: 2.606946441258135

Epoch: 527| Step: 0
Training loss: 1.4943621701814978
Validation loss: 2.6169531873889817

Epoch: 6| Step: 1
Training loss: 0.7859665214989601
Validation loss: 2.5906165536506562

Epoch: 6| Step: 2
Training loss: 1.3217676935312204
Validation loss: 2.5794825768467615

Epoch: 6| Step: 3
Training loss: 0.8237610038520184
Validation loss: 2.5970379335544886

Epoch: 6| Step: 4
Training loss: 1.1836776955424748
Validation loss: 2.594399388831375

Epoch: 6| Step: 5
Training loss: 0.425399556692356
Validation loss: 2.6046215921736566

Epoch: 6| Step: 6
Training loss: 0.592414156332621
Validation loss: 2.5933834468762447

Epoch: 6| Step: 7
Training loss: 0.9029752494972835
Validation loss: 2.6129447727383

Epoch: 6| Step: 8
Training loss: 1.067359637875279
Validation loss: 2.61145608162513

Epoch: 6| Step: 9
Training loss: 0.9773259954875284
Validation loss: 2.593434768934962

Epoch: 6| Step: 10
Training loss: 0.9016727082642982
Validation loss: 2.5779246183093107

Epoch: 6| Step: 11
Training loss: 0.8759200844477704
Validation loss: 2.568854194461874

Epoch: 6| Step: 12
Training loss: 0.9223174633562866
Validation loss: 2.598416518658556

Epoch: 6| Step: 13
Training loss: 1.3016286386673284
Validation loss: 2.5811304264092123

Epoch: 528| Step: 0
Training loss: 0.8314233986258702
Validation loss: 2.6085301083188903

Epoch: 6| Step: 1
Training loss: 0.7709178921139256
Validation loss: 2.594362888505196

Epoch: 6| Step: 2
Training loss: 1.489445908971915
Validation loss: 2.557421890196864

Epoch: 6| Step: 3
Training loss: 0.7243825552334893
Validation loss: 2.5457579946899744

Epoch: 6| Step: 4
Training loss: 0.9606290492789625
Validation loss: 2.572815062620903

Epoch: 6| Step: 5
Training loss: 1.2611013974830023
Validation loss: 2.568514474825301

Epoch: 6| Step: 6
Training loss: 1.0530104124853135
Validation loss: 2.578379502448807

Epoch: 6| Step: 7
Training loss: 0.6526431692838649
Validation loss: 2.563583293109031

Epoch: 6| Step: 8
Training loss: 1.07402275378172
Validation loss: 2.5770174010809845

Epoch: 6| Step: 9
Training loss: 1.0918344890413867
Validation loss: 2.5840952075934993

Epoch: 6| Step: 10
Training loss: 0.9007595737889725
Validation loss: 2.6158572287896136

Epoch: 6| Step: 11
Training loss: 0.7938578464803355
Validation loss: 2.5632887355984444

Epoch: 6| Step: 12
Training loss: 0.877799732065149
Validation loss: 2.599342398863524

Epoch: 6| Step: 13
Training loss: 1.2018206077324816
Validation loss: 2.6291927677692937

Epoch: 529| Step: 0
Training loss: 1.6142055274540728
Validation loss: 2.5556073273450832

Epoch: 6| Step: 1
Training loss: 0.9218402791354429
Validation loss: 2.618850951740749

Epoch: 6| Step: 2
Training loss: 0.3462364802320418
Validation loss: 2.5880575867386786

Epoch: 6| Step: 3
Training loss: 1.1282636139900146
Validation loss: 2.5955787035727296

Epoch: 6| Step: 4
Training loss: 1.067219518401797
Validation loss: 2.5765895254773836

Epoch: 6| Step: 5
Training loss: 1.3254618703422367
Validation loss: 2.556288478279004

Epoch: 6| Step: 6
Training loss: 0.6255921896182323
Validation loss: 2.6025741193386853

Epoch: 6| Step: 7
Training loss: 0.8618445200022261
Validation loss: 2.5692914609219306

Epoch: 6| Step: 8
Training loss: 0.6238655284544009
Validation loss: 2.58320098191246

Epoch: 6| Step: 9
Training loss: 1.0080761823286755
Validation loss: 2.602786732608179

Epoch: 6| Step: 10
Training loss: 0.995713733662974
Validation loss: 2.6231692806203055

Epoch: 6| Step: 11
Training loss: 0.8764171024166788
Validation loss: 2.622297827945122

Epoch: 6| Step: 12
Training loss: 1.0064251243836277
Validation loss: 2.6627772857246406

Epoch: 6| Step: 13
Training loss: 0.9965190204024378
Validation loss: 2.652519616894392

Epoch: 530| Step: 0
Training loss: 0.6541050871842087
Validation loss: 2.6258065009721183

Epoch: 6| Step: 1
Training loss: 0.9844826836194053
Validation loss: 2.665151132404194

Epoch: 6| Step: 2
Training loss: 0.8812146538213413
Validation loss: 2.6391289488647143

Epoch: 6| Step: 3
Training loss: 1.7233378128175543
Validation loss: 2.6221427935113666

Epoch: 6| Step: 4
Training loss: 0.7641122626265333
Validation loss: 2.6074737367921847

Epoch: 6| Step: 5
Training loss: 0.8507831051528644
Validation loss: 2.596984258236684

Epoch: 6| Step: 6
Training loss: 0.7519135303724325
Validation loss: 2.6017426331079934

Epoch: 6| Step: 7
Training loss: 0.8973109604605157
Validation loss: 2.5922061354611308

Epoch: 6| Step: 8
Training loss: 0.9817102482700956
Validation loss: 2.5808812432879713

Epoch: 6| Step: 9
Training loss: 0.6749284247137864
Validation loss: 2.5914078144951933

Epoch: 6| Step: 10
Training loss: 0.9927032812149419
Validation loss: 2.606790462356601

Epoch: 6| Step: 11
Training loss: 0.8660771590255352
Validation loss: 2.5750010865453414

Epoch: 6| Step: 12
Training loss: 1.4135954702094253
Validation loss: 2.6049649839032023

Epoch: 6| Step: 13
Training loss: 0.9234047820980583
Validation loss: 2.5864914819727054

Epoch: 531| Step: 0
Training loss: 1.0378604906077105
Validation loss: 2.545663927801876

Epoch: 6| Step: 1
Training loss: 0.9021190677345758
Validation loss: 2.568966608386169

Epoch: 6| Step: 2
Training loss: 0.7745463581777993
Validation loss: 2.5313940681994502

Epoch: 6| Step: 3
Training loss: 1.1503472052833645
Validation loss: 2.526982153899733

Epoch: 6| Step: 4
Training loss: 1.077359743393768
Validation loss: 2.553680565681533

Epoch: 6| Step: 5
Training loss: 0.9730860361911794
Validation loss: 2.53988452058705

Epoch: 6| Step: 6
Training loss: 1.1453901069441674
Validation loss: 2.5133389573768583

Epoch: 6| Step: 7
Training loss: 0.5940398964151039
Validation loss: 2.547031662752519

Epoch: 6| Step: 8
Training loss: 1.001339611181939
Validation loss: 2.511946063239137

Epoch: 6| Step: 9
Training loss: 1.568221640803703
Validation loss: 2.553487074642367

Epoch: 6| Step: 10
Training loss: 0.8144752993412382
Validation loss: 2.4845046596909066

Epoch: 6| Step: 11
Training loss: 0.6766279131694318
Validation loss: 2.5829768283841257

Epoch: 6| Step: 12
Training loss: 0.8366289933019724
Validation loss: 2.5935218405271807

Epoch: 6| Step: 13
Training loss: 0.7372106226860003
Validation loss: 2.644277207230479

Epoch: 532| Step: 0
Training loss: 1.081450158263875
Validation loss: 2.590239409410961

Epoch: 6| Step: 1
Training loss: 0.653232448810728
Validation loss: 2.6321070814712675

Epoch: 6| Step: 2
Training loss: 0.5509324373563308
Validation loss: 2.6693290800537057

Epoch: 6| Step: 3
Training loss: 0.8207952622881083
Validation loss: 2.635925983703569

Epoch: 6| Step: 4
Training loss: 1.2209304475836917
Validation loss: 2.631674594306748

Epoch: 6| Step: 5
Training loss: 1.0521042447167954
Validation loss: 2.635588738607367

Epoch: 6| Step: 6
Training loss: 0.9539028808134348
Validation loss: 2.6206702264963337

Epoch: 6| Step: 7
Training loss: 0.5648176342848057
Validation loss: 2.621599668075627

Epoch: 6| Step: 8
Training loss: 1.0168605038594956
Validation loss: 2.6206262034354664

Epoch: 6| Step: 9
Training loss: 0.5532189391803358
Validation loss: 2.6211067349643007

Epoch: 6| Step: 10
Training loss: 1.0183439393331462
Validation loss: 2.6264820866402276

Epoch: 6| Step: 11
Training loss: 1.1385417360036445
Validation loss: 2.621033953389631

Epoch: 6| Step: 12
Training loss: 1.6405521921623647
Validation loss: 2.6334549860063197

Epoch: 6| Step: 13
Training loss: 1.10474250580973
Validation loss: 2.626407253891917

Epoch: 533| Step: 0
Training loss: 1.0448867364126853
Validation loss: 2.6196262047476586

Epoch: 6| Step: 1
Training loss: 1.0420642602622303
Validation loss: 2.611290611531273

Epoch: 6| Step: 2
Training loss: 0.9401294708368817
Validation loss: 2.5954787513382636

Epoch: 6| Step: 3
Training loss: 0.9969531671377412
Validation loss: 2.55458739393991

Epoch: 6| Step: 4
Training loss: 0.8194958936484832
Validation loss: 2.553376490276614

Epoch: 6| Step: 5
Training loss: 0.9015650836768723
Validation loss: 2.590429043865649

Epoch: 6| Step: 6
Training loss: 0.8083143258236025
Validation loss: 2.57532985457015

Epoch: 6| Step: 7
Training loss: 0.9972758142090498
Validation loss: 2.5983013986807286

Epoch: 6| Step: 8
Training loss: 1.5604254874713093
Validation loss: 2.5807986955962146

Epoch: 6| Step: 9
Training loss: 0.5762257696258226
Validation loss: 2.5963285665444853

Epoch: 6| Step: 10
Training loss: 0.7834978952093524
Validation loss: 2.609425137083419

Epoch: 6| Step: 11
Training loss: 0.8834153876490732
Validation loss: 2.5977897689297995

Epoch: 6| Step: 12
Training loss: 1.0778522422853913
Validation loss: 2.593706073529874

Epoch: 6| Step: 13
Training loss: 1.0703865081371602
Validation loss: 2.59171786108523

Epoch: 534| Step: 0
Training loss: 0.6632381483615882
Validation loss: 2.5851529375578672

Epoch: 6| Step: 1
Training loss: 1.0818514347429913
Validation loss: 2.613408308574522

Epoch: 6| Step: 2
Training loss: 1.1632330070416952
Validation loss: 2.5995311227116167

Epoch: 6| Step: 3
Training loss: 0.7958141071600247
Validation loss: 2.6090356592499595

Epoch: 6| Step: 4
Training loss: 0.9066587052685277
Validation loss: 2.629623334058893

Epoch: 6| Step: 5
Training loss: 0.7804629748553653
Validation loss: 2.6366520193293184

Epoch: 6| Step: 6
Training loss: 0.9722716402179646
Validation loss: 2.652096136577283

Epoch: 6| Step: 7
Training loss: 0.9293338519737552
Validation loss: 2.6722034769838596

Epoch: 6| Step: 8
Training loss: 0.962557535805059
Validation loss: 2.648407924103516

Epoch: 6| Step: 9
Training loss: 0.6542478172927614
Validation loss: 2.6698059070768747

Epoch: 6| Step: 10
Training loss: 1.1608060821452733
Validation loss: 2.625517776997534

Epoch: 6| Step: 11
Training loss: 1.5596301617302688
Validation loss: 2.632713974023583

Epoch: 6| Step: 12
Training loss: 0.648050836386596
Validation loss: 2.5826081069399383

Epoch: 6| Step: 13
Training loss: 1.0610699285856204
Validation loss: 2.584733421521816

Epoch: 535| Step: 0
Training loss: 1.0510124320938223
Validation loss: 2.560773273717555

Epoch: 6| Step: 1
Training loss: 1.2766191953211286
Validation loss: 2.5833488970660503

Epoch: 6| Step: 2
Training loss: 0.9492343854205139
Validation loss: 2.5646636216459386

Epoch: 6| Step: 3
Training loss: 0.5244696106430018
Validation loss: 2.577891943159077

Epoch: 6| Step: 4
Training loss: 0.9466832209088885
Validation loss: 2.5159923438377914

Epoch: 6| Step: 5
Training loss: 0.672542617362164
Validation loss: 2.5507065079998057

Epoch: 6| Step: 6
Training loss: 1.0207771493411004
Validation loss: 2.5155253578181256

Epoch: 6| Step: 7
Training loss: 0.7412369915751934
Validation loss: 2.536604399243558

Epoch: 6| Step: 8
Training loss: 1.3228833151790915
Validation loss: 2.5741394539655778

Epoch: 6| Step: 9
Training loss: 0.8821256886042107
Validation loss: 2.5700601523141313

Epoch: 6| Step: 10
Training loss: 0.9717020156825312
Validation loss: 2.518249312782366

Epoch: 6| Step: 11
Training loss: 0.9756661841273269
Validation loss: 2.5793633026236527

Epoch: 6| Step: 12
Training loss: 1.4395340336456266
Validation loss: 2.566210661037166

Epoch: 6| Step: 13
Training loss: 0.7382519024864147
Validation loss: 2.531490003114799

Epoch: 536| Step: 0
Training loss: 1.0594329323021183
Validation loss: 2.5679113764599557

Epoch: 6| Step: 1
Training loss: 0.8258763499432953
Validation loss: 2.5667379287343204

Epoch: 6| Step: 2
Training loss: 0.8281368758591637
Validation loss: 2.5541980017677894

Epoch: 6| Step: 3
Training loss: 1.0682610670534625
Validation loss: 2.5637105277976024

Epoch: 6| Step: 4
Training loss: 0.6377108281396342
Validation loss: 2.548014740294031

Epoch: 6| Step: 5
Training loss: 0.7960465556672379
Validation loss: 2.5335824101068725

Epoch: 6| Step: 6
Training loss: 1.274254799899468
Validation loss: 2.558846100867988

Epoch: 6| Step: 7
Training loss: 0.852574368474447
Validation loss: 2.547499793876643

Epoch: 6| Step: 8
Training loss: 0.6940689968747996
Validation loss: 2.53089374206109

Epoch: 6| Step: 9
Training loss: 0.8676364870463752
Validation loss: 2.5474997717372516

Epoch: 6| Step: 10
Training loss: 1.1646395283597695
Validation loss: 2.519099437979442

Epoch: 6| Step: 11
Training loss: 1.632281130245684
Validation loss: 2.5701145136136723

Epoch: 6| Step: 12
Training loss: 0.7184806816726729
Validation loss: 2.561104652438401

Epoch: 6| Step: 13
Training loss: 0.30841934732357684
Validation loss: 2.5785438006021204

Epoch: 537| Step: 0
Training loss: 1.0092836628029989
Validation loss: 2.5807619025822834

Epoch: 6| Step: 1
Training loss: 1.019575446913794
Validation loss: 2.6171180790580646

Epoch: 6| Step: 2
Training loss: 1.0874192810795036
Validation loss: 2.5649392148609564

Epoch: 6| Step: 3
Training loss: 1.5168217132601658
Validation loss: 2.5909001132121134

Epoch: 6| Step: 4
Training loss: 0.8203919871738257
Validation loss: 2.620561154541476

Epoch: 6| Step: 5
Training loss: 0.7141090327821017
Validation loss: 2.5681102314772164

Epoch: 6| Step: 6
Training loss: 0.6013941838993357
Validation loss: 2.5618233166179496

Epoch: 6| Step: 7
Training loss: 0.7742946383548164
Validation loss: 2.5491520662399867

Epoch: 6| Step: 8
Training loss: 0.643291205272867
Validation loss: 2.5746876105094065

Epoch: 6| Step: 9
Training loss: 0.9728479464574216
Validation loss: 2.6002598737550486

Epoch: 6| Step: 10
Training loss: 0.73572031529875
Validation loss: 2.5884085118945306

Epoch: 6| Step: 11
Training loss: 0.9595755873740308
Validation loss: 2.5604325164432775

Epoch: 6| Step: 12
Training loss: 1.1070317518062167
Validation loss: 2.575891495182227

Epoch: 6| Step: 13
Training loss: 1.0934477797267874
Validation loss: 2.514518239049364

Epoch: 538| Step: 0
Training loss: 0.9470440792290383
Validation loss: 2.5690230874286106

Epoch: 6| Step: 1
Training loss: 0.8178352735276262
Validation loss: 2.5658384256756968

Epoch: 6| Step: 2
Training loss: 1.2984463926669525
Validation loss: 2.535235270775023

Epoch: 6| Step: 3
Training loss: 0.8422140694073764
Validation loss: 2.5877511921316083

Epoch: 6| Step: 4
Training loss: 0.7055191816213654
Validation loss: 2.5656237327405984

Epoch: 6| Step: 5
Training loss: 1.3657258422072465
Validation loss: 2.598105245197761

Epoch: 6| Step: 6
Training loss: 0.8551079324447373
Validation loss: 2.5721920295446505

Epoch: 6| Step: 7
Training loss: 1.111746281961821
Validation loss: 2.5921606261471073

Epoch: 6| Step: 8
Training loss: 0.9215483652546289
Validation loss: 2.577107167618491

Epoch: 6| Step: 9
Training loss: 0.6439042249211266
Validation loss: 2.551541520834565

Epoch: 6| Step: 10
Training loss: 1.07257742595629
Validation loss: 2.5940238807049503

Epoch: 6| Step: 11
Training loss: 0.8382939432823865
Validation loss: 2.593606707927565

Epoch: 6| Step: 12
Training loss: 0.900534992684016
Validation loss: 2.5408724665805873

Epoch: 6| Step: 13
Training loss: 0.6845545964198793
Validation loss: 2.5634228254976357

Epoch: 539| Step: 0
Training loss: 0.6236098804074693
Validation loss: 2.560619570447014

Epoch: 6| Step: 1
Training loss: 1.0432783945892095
Validation loss: 2.5321424220882

Epoch: 6| Step: 2
Training loss: 0.9679885763704095
Validation loss: 2.572482935680053

Epoch: 6| Step: 3
Training loss: 0.9025497531649828
Validation loss: 2.5506653480082315

Epoch: 6| Step: 4
Training loss: 0.7956468430222924
Validation loss: 2.579479002432258

Epoch: 6| Step: 5
Training loss: 1.4048615276750689
Validation loss: 2.554540964056959

Epoch: 6| Step: 6
Training loss: 1.088567389712084
Validation loss: 2.5415966206512146

Epoch: 6| Step: 7
Training loss: 0.5862232528717752
Validation loss: 2.569061973491064

Epoch: 6| Step: 8
Training loss: 0.7204774332609081
Validation loss: 2.536059825309638

Epoch: 6| Step: 9
Training loss: 1.2564317695104823
Validation loss: 2.5679822214611576

Epoch: 6| Step: 10
Training loss: 1.02020837506624
Validation loss: 2.567544571275504

Epoch: 6| Step: 11
Training loss: 0.9400383282517293
Validation loss: 2.554242630259045

Epoch: 6| Step: 12
Training loss: 0.970945638837979
Validation loss: 2.593716916346365

Epoch: 6| Step: 13
Training loss: 1.2378758871080513
Validation loss: 2.5487141479158684

Epoch: 540| Step: 0
Training loss: 0.6565980442453725
Validation loss: 2.569889418157855

Epoch: 6| Step: 1
Training loss: 0.44107520931679794
Validation loss: 2.552670772633335

Epoch: 6| Step: 2
Training loss: 0.709406115147809
Validation loss: 2.5745311350021205

Epoch: 6| Step: 3
Training loss: 1.064890024658847
Validation loss: 2.5759243673852055

Epoch: 6| Step: 4
Training loss: 0.9217244688077483
Validation loss: 2.5641663778416475

Epoch: 6| Step: 5
Training loss: 1.0354248849912322
Validation loss: 2.5565590349202765

Epoch: 6| Step: 6
Training loss: 1.0364018845002545
Validation loss: 2.5525670748112916

Epoch: 6| Step: 7
Training loss: 0.8867436208051886
Validation loss: 2.553123706985941

Epoch: 6| Step: 8
Training loss: 1.0022727649793302
Validation loss: 2.5931566955685534

Epoch: 6| Step: 9
Training loss: 1.77466275409656
Validation loss: 2.595086538270093

Epoch: 6| Step: 10
Training loss: 1.1415924776758384
Validation loss: 2.5802159972864054

Epoch: 6| Step: 11
Training loss: 1.1571241631250897
Validation loss: 2.569056050010621

Epoch: 6| Step: 12
Training loss: 0.6598912220597827
Validation loss: 2.5786265909815067

Epoch: 6| Step: 13
Training loss: 0.7894324389148919
Validation loss: 2.5727238753285064

Epoch: 541| Step: 0
Training loss: 0.9978357976480866
Validation loss: 2.6323136503701616

Epoch: 6| Step: 1
Training loss: 0.6028532572287237
Validation loss: 2.601486934663295

Epoch: 6| Step: 2
Training loss: 0.8456251359532058
Validation loss: 2.605235676214539

Epoch: 6| Step: 3
Training loss: 1.2743154202575167
Validation loss: 2.6243549859231674

Epoch: 6| Step: 4
Training loss: 0.8719540440541128
Validation loss: 2.5890389664183595

Epoch: 6| Step: 5
Training loss: 0.7347072499037053
Validation loss: 2.5927463195209492

Epoch: 6| Step: 6
Training loss: 1.327348953605093
Validation loss: 2.5849422989382784

Epoch: 6| Step: 7
Training loss: 1.1805113890121528
Validation loss: 2.569625462950706

Epoch: 6| Step: 8
Training loss: 1.0002920201215237
Validation loss: 2.550962118869534

Epoch: 6| Step: 9
Training loss: 0.7369548043222097
Validation loss: 2.5781059038207625

Epoch: 6| Step: 10
Training loss: 0.8654858845772329
Validation loss: 2.5542792095936195

Epoch: 6| Step: 11
Training loss: 0.5224618501744365
Validation loss: 2.5668435209871836

Epoch: 6| Step: 12
Training loss: 1.0302210211414506
Validation loss: 2.598959123777088

Epoch: 6| Step: 13
Training loss: 0.9841457281595855
Validation loss: 2.5764556253072333

Epoch: 542| Step: 0
Training loss: 1.2642548291003053
Validation loss: 2.597950415000588

Epoch: 6| Step: 1
Training loss: 1.0149416458568585
Validation loss: 2.632746089033085

Epoch: 6| Step: 2
Training loss: 1.2392974438353672
Validation loss: 2.610320091721539

Epoch: 6| Step: 3
Training loss: 0.49305272120196886
Validation loss: 2.5974885906029823

Epoch: 6| Step: 4
Training loss: 0.9228288597261218
Validation loss: 2.564782399497652

Epoch: 6| Step: 5
Training loss: 0.7496681273844616
Validation loss: 2.5678845664822187

Epoch: 6| Step: 6
Training loss: 0.5757438751057244
Validation loss: 2.5519962978192168

Epoch: 6| Step: 7
Training loss: 1.0243788604942878
Validation loss: 2.5239072754998246

Epoch: 6| Step: 8
Training loss: 0.5561642398516452
Validation loss: 2.5041881873076064

Epoch: 6| Step: 9
Training loss: 1.0462141085977825
Validation loss: 2.5872605040013674

Epoch: 6| Step: 10
Training loss: 0.962569363063988
Validation loss: 2.5916299686841455

Epoch: 6| Step: 11
Training loss: 0.9717084564090698
Validation loss: 2.6025326552105645

Epoch: 6| Step: 12
Training loss: 1.0034168995204158
Validation loss: 2.616875875963934

Epoch: 6| Step: 13
Training loss: 1.0631278931557626
Validation loss: 2.6488576213334856

Epoch: 543| Step: 0
Training loss: 1.0613131907131552
Validation loss: 2.6253912888498716

Epoch: 6| Step: 1
Training loss: 0.7516618040467477
Validation loss: 2.6546872004774293

Epoch: 6| Step: 2
Training loss: 0.9278715975818643
Validation loss: 2.643829922086345

Epoch: 6| Step: 3
Training loss: 1.1406392135779648
Validation loss: 2.6794068305410192

Epoch: 6| Step: 4
Training loss: 0.7947499232164642
Validation loss: 2.650738161304165

Epoch: 6| Step: 5
Training loss: 1.1235475170611064
Validation loss: 2.608913806039214

Epoch: 6| Step: 6
Training loss: 0.922221716643837
Validation loss: 2.5983597318449143

Epoch: 6| Step: 7
Training loss: 1.473755201309512
Validation loss: 2.581422631759122

Epoch: 6| Step: 8
Training loss: 0.7358569755154628
Validation loss: 2.5640676721836644

Epoch: 6| Step: 9
Training loss: 0.8161877426426359
Validation loss: 2.5517659542250746

Epoch: 6| Step: 10
Training loss: 0.9833782538698022
Validation loss: 2.573542958385331

Epoch: 6| Step: 11
Training loss: 0.7221958240143211
Validation loss: 2.547556131965734

Epoch: 6| Step: 12
Training loss: 0.36579782199920347
Validation loss: 2.5346112182632776

Epoch: 6| Step: 13
Training loss: 0.7985263618245281
Validation loss: 2.551990979658028

Epoch: 544| Step: 0
Training loss: 0.8197476213216517
Validation loss: 2.5368594301221408

Epoch: 6| Step: 1
Training loss: 0.845943249449341
Validation loss: 2.5314667716637738

Epoch: 6| Step: 2
Training loss: 1.0422077617362826
Validation loss: 2.5222338639668087

Epoch: 6| Step: 3
Training loss: 1.0040369802176876
Validation loss: 2.5561881385553025

Epoch: 6| Step: 4
Training loss: 0.8767464103135761
Validation loss: 2.568027136003871

Epoch: 6| Step: 5
Training loss: 0.7446887783306898
Validation loss: 2.5827854993388653

Epoch: 6| Step: 6
Training loss: 0.867291865211725
Validation loss: 2.581167512629589

Epoch: 6| Step: 7
Training loss: 0.8944328953673303
Validation loss: 2.540146899004182

Epoch: 6| Step: 8
Training loss: 0.9439997740397749
Validation loss: 2.5743341791168297

Epoch: 6| Step: 9
Training loss: 0.7115635473405303
Validation loss: 2.583552001632489

Epoch: 6| Step: 10
Training loss: 1.391652274295296
Validation loss: 2.6023147226201155

Epoch: 6| Step: 11
Training loss: 0.9537515925722837
Validation loss: 2.5976511516423866

Epoch: 6| Step: 12
Training loss: 0.798301467206434
Validation loss: 2.6051266026121773

Epoch: 6| Step: 13
Training loss: 1.1007061057504255
Validation loss: 2.6106392151738014

Epoch: 545| Step: 0
Training loss: 0.9074272533295129
Validation loss: 2.6377259191961127

Epoch: 6| Step: 1
Training loss: 0.6481381840040883
Validation loss: 2.661093905780619

Epoch: 6| Step: 2
Training loss: 0.9168648758363742
Validation loss: 2.6506271126821916

Epoch: 6| Step: 3
Training loss: 0.8242272109912654
Validation loss: 2.6523235140916297

Epoch: 6| Step: 4
Training loss: 0.9457360571918265
Validation loss: 2.6637804123023225

Epoch: 6| Step: 5
Training loss: 1.020021576466206
Validation loss: 2.640169229947181

Epoch: 6| Step: 6
Training loss: 0.918753949630448
Validation loss: 2.6033997462645053

Epoch: 6| Step: 7
Training loss: 1.0052572577764032
Validation loss: 2.616229933887568

Epoch: 6| Step: 8
Training loss: 1.1876159410595928
Validation loss: 2.585681967717008

Epoch: 6| Step: 9
Training loss: 0.8550202051641901
Validation loss: 2.55665872535906

Epoch: 6| Step: 10
Training loss: 1.0700217638743592
Validation loss: 2.5675344666430187

Epoch: 6| Step: 11
Training loss: 0.8056693891869366
Validation loss: 2.5100902954026756

Epoch: 6| Step: 12
Training loss: 0.8834625146682306
Validation loss: 2.53060104050201

Epoch: 6| Step: 13
Training loss: 1.6405410745135696
Validation loss: 2.509386235031922

Epoch: 546| Step: 0
Training loss: 0.8057216184460203
Validation loss: 2.4809634218544687

Epoch: 6| Step: 1
Training loss: 1.2273911513724576
Validation loss: 2.5210434688673997

Epoch: 6| Step: 2
Training loss: 1.1264701879512642
Validation loss: 2.5262034252874948

Epoch: 6| Step: 3
Training loss: 0.8401152770665039
Validation loss: 2.5490003925602975

Epoch: 6| Step: 4
Training loss: 0.8948828659980096
Validation loss: 2.542896521569429

Epoch: 6| Step: 5
Training loss: 0.8024514620948091
Validation loss: 2.5595128626424613

Epoch: 6| Step: 6
Training loss: 1.0622332743034721
Validation loss: 2.563574674901777

Epoch: 6| Step: 7
Training loss: 1.0987497767599006
Validation loss: 2.5834548563033515

Epoch: 6| Step: 8
Training loss: 0.7801102144062345
Validation loss: 2.5723354421598126

Epoch: 6| Step: 9
Training loss: 1.1803727338761667
Validation loss: 2.56206720690623

Epoch: 6| Step: 10
Training loss: 0.3724097158160777
Validation loss: 2.5911746186683535

Epoch: 6| Step: 11
Training loss: 0.6434715576199548
Validation loss: 2.6566383227563786

Epoch: 6| Step: 12
Training loss: 1.1895693266534464
Validation loss: 2.609801960632269

Epoch: 6| Step: 13
Training loss: 0.9567867355949449
Validation loss: 2.644802624936867

Epoch: 547| Step: 0
Training loss: 0.704305949816473
Validation loss: 2.637239351093961

Epoch: 6| Step: 1
Training loss: 0.8306986565004678
Validation loss: 2.6272964999075272

Epoch: 6| Step: 2
Training loss: 0.6088448688285536
Validation loss: 2.6056948598422207

Epoch: 6| Step: 3
Training loss: 0.9105391126880331
Validation loss: 2.6421346051295065

Epoch: 6| Step: 4
Training loss: 0.6344578627790068
Validation loss: 2.65470652992767

Epoch: 6| Step: 5
Training loss: 1.5598336930759418
Validation loss: 2.629349793814039

Epoch: 6| Step: 6
Training loss: 0.6248764869716509
Validation loss: 2.636727214694821

Epoch: 6| Step: 7
Training loss: 0.8564729066272497
Validation loss: 2.6388917600928767

Epoch: 6| Step: 8
Training loss: 0.9702563725699375
Validation loss: 2.5872105765174984

Epoch: 6| Step: 9
Training loss: 1.3575483743468266
Validation loss: 2.609020786561225

Epoch: 6| Step: 10
Training loss: 0.7440667703979427
Validation loss: 2.577948325111158

Epoch: 6| Step: 11
Training loss: 0.766950744022133
Validation loss: 2.561609075794528

Epoch: 6| Step: 12
Training loss: 0.851440770959273
Validation loss: 2.531814429216566

Epoch: 6| Step: 13
Training loss: 0.8329089196592122
Validation loss: 2.5474015051605745

Epoch: 548| Step: 0
Training loss: 0.9295969365992767
Validation loss: 2.5416498129850895

Epoch: 6| Step: 1
Training loss: 0.8850040746045469
Validation loss: 2.547633602854253

Epoch: 6| Step: 2
Training loss: 0.8007313782583791
Validation loss: 2.5406878493128353

Epoch: 6| Step: 3
Training loss: 0.915179100435217
Validation loss: 2.5364509726102944

Epoch: 6| Step: 4
Training loss: 1.028009583276394
Validation loss: 2.5836909655567166

Epoch: 6| Step: 5
Training loss: 0.5971904260712406
Validation loss: 2.568853178527732

Epoch: 6| Step: 6
Training loss: 1.0733209360682239
Validation loss: 2.5773724354705796

Epoch: 6| Step: 7
Training loss: 0.719218516029653
Validation loss: 2.5705978036229618

Epoch: 6| Step: 8
Training loss: 0.8775026770222142
Validation loss: 2.5522448959257846

Epoch: 6| Step: 9
Training loss: 0.6414112987621623
Validation loss: 2.554840481701466

Epoch: 6| Step: 10
Training loss: 1.375748170696514
Validation loss: 2.5948334422803327

Epoch: 6| Step: 11
Training loss: 0.8271115417538565
Validation loss: 2.6186074541181026

Epoch: 6| Step: 12
Training loss: 0.7873714190672823
Validation loss: 2.5852395354257487

Epoch: 6| Step: 13
Training loss: 0.9771556426230026
Validation loss: 2.6136039511221445

Epoch: 549| Step: 0
Training loss: 0.9372376392736869
Validation loss: 2.5990202953059427

Epoch: 6| Step: 1
Training loss: 1.2223296780503414
Validation loss: 2.57758303079486

Epoch: 6| Step: 2
Training loss: 0.8009066599825823
Validation loss: 2.5756949090701804

Epoch: 6| Step: 3
Training loss: 1.0938484147618117
Validation loss: 2.596545303854092

Epoch: 6| Step: 4
Training loss: 0.5189876437195518
Validation loss: 2.5729312631439543

Epoch: 6| Step: 5
Training loss: 0.4375900959161172
Validation loss: 2.5816507041518326

Epoch: 6| Step: 6
Training loss: 0.8637708423490261
Validation loss: 2.5829264190992443

Epoch: 6| Step: 7
Training loss: 1.1738963178734663
Validation loss: 2.6084216403044747

Epoch: 6| Step: 8
Training loss: 0.8738627195438022
Validation loss: 2.508020215483551

Epoch: 6| Step: 9
Training loss: 0.7121056820788861
Validation loss: 2.5524336088352415

Epoch: 6| Step: 10
Training loss: 1.1793930494648668
Validation loss: 2.5555758665679753

Epoch: 6| Step: 11
Training loss: 0.4952204820375526
Validation loss: 2.5333609580566914

Epoch: 6| Step: 12
Training loss: 1.035433001680424
Validation loss: 2.5494994680638854

Epoch: 6| Step: 13
Training loss: 0.6793153116489323
Validation loss: 2.5673390639869456

Epoch: 550| Step: 0
Training loss: 0.5177500888966218
Validation loss: 2.5748906356154326

Epoch: 6| Step: 1
Training loss: 0.767422492869642
Validation loss: 2.5318019239398466

Epoch: 6| Step: 2
Training loss: 0.8870616703485138
Validation loss: 2.556548197962205

Epoch: 6| Step: 3
Training loss: 1.2718465028611785
Validation loss: 2.5864571685931783

Epoch: 6| Step: 4
Training loss: 0.8149460140438564
Validation loss: 2.560221964313717

Epoch: 6| Step: 5
Training loss: 0.33585265662889063
Validation loss: 2.6199142090441607

Epoch: 6| Step: 6
Training loss: 0.6958611927242142
Validation loss: 2.5855959627168374

Epoch: 6| Step: 7
Training loss: 1.2198457438238988
Validation loss: 2.589122592559045

Epoch: 6| Step: 8
Training loss: 0.964907254125349
Validation loss: 2.6168114382347856

Epoch: 6| Step: 9
Training loss: 0.41446874590890037
Validation loss: 2.5764051361923483

Epoch: 6| Step: 10
Training loss: 0.8391314657556878
Validation loss: 2.629669547213318

Epoch: 6| Step: 11
Training loss: 1.0739030963790903
Validation loss: 2.5957397032683995

Epoch: 6| Step: 12
Training loss: 1.151279695274923
Validation loss: 2.582996165461792

Epoch: 6| Step: 13
Training loss: 1.0929809046104226
Validation loss: 2.6150535027076316

Testing loss: 2.179403540414634
