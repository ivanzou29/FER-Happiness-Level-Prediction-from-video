Epoch: 1| Step: 0
Training loss: 6.3883562088012695
Validation loss: 5.181246824161981

Epoch: 5| Step: 1
Training loss: 5.7766265869140625
Validation loss: 5.170141420056743

Epoch: 5| Step: 2
Training loss: 4.196529865264893
Validation loss: 5.159823745809575

Epoch: 5| Step: 3
Training loss: 4.44036340713501
Validation loss: 5.14956122572704

Epoch: 5| Step: 4
Training loss: 4.174209117889404
Validation loss: 5.138848350894067

Epoch: 5| Step: 5
Training loss: 4.6160078048706055
Validation loss: 5.126650415441041

Epoch: 5| Step: 6
Training loss: 5.778157711029053
Validation loss: 5.114741309996574

Epoch: 5| Step: 7
Training loss: 5.306074142456055
Validation loss: 5.101785054770849

Epoch: 5| Step: 8
Training loss: 5.226849555969238
Validation loss: 5.087052242730254

Epoch: 5| Step: 9
Training loss: 3.9379489421844482
Validation loss: 5.071178482424829

Epoch: 5| Step: 10
Training loss: 4.18450403213501
Validation loss: 5.055113064345493

Epoch: 2| Step: 0
Training loss: 4.360294818878174
Validation loss: 5.0370963901601815

Epoch: 5| Step: 1
Training loss: 5.018624305725098
Validation loss: 5.01826342716012

Epoch: 5| Step: 2
Training loss: 5.859368324279785
Validation loss: 4.99791802642166

Epoch: 5| Step: 3
Training loss: 3.904315948486328
Validation loss: 4.974595387776692

Epoch: 5| Step: 4
Training loss: 5.072558879852295
Validation loss: 4.95169727263912

Epoch: 5| Step: 5
Training loss: 5.052493095397949
Validation loss: 4.926417960915514

Epoch: 5| Step: 6
Training loss: 4.818152904510498
Validation loss: 4.900784195110362

Epoch: 5| Step: 7
Training loss: 3.8839805126190186
Validation loss: 4.8723950129683296

Epoch: 5| Step: 8
Training loss: 4.231201171875
Validation loss: 4.843207918187623

Epoch: 5| Step: 9
Training loss: 5.499973297119141
Validation loss: 4.812601489405478

Epoch: 5| Step: 10
Training loss: 4.043623447418213
Validation loss: 4.782264073689778

Epoch: 3| Step: 0
Training loss: 4.911856651306152
Validation loss: 4.748602010870493

Epoch: 5| Step: 1
Training loss: 4.551281452178955
Validation loss: 4.716033894528625

Epoch: 5| Step: 2
Training loss: 4.930924415588379
Validation loss: 4.682680606842041

Epoch: 5| Step: 3
Training loss: 4.541101932525635
Validation loss: 4.65053193799911

Epoch: 5| Step: 4
Training loss: 3.583035707473755
Validation loss: 4.615735366780271

Epoch: 5| Step: 5
Training loss: 4.218127250671387
Validation loss: 4.58266552032963

Epoch: 5| Step: 6
Training loss: 3.1383986473083496
Validation loss: 4.547144992377168

Epoch: 5| Step: 7
Training loss: 2.976510524749756
Validation loss: 4.51252217446604

Epoch: 5| Step: 8
Training loss: 4.325137138366699
Validation loss: 4.477135924882786

Epoch: 5| Step: 9
Training loss: 5.067509651184082
Validation loss: 4.441575850209882

Epoch: 5| Step: 10
Training loss: 6.085143566131592
Validation loss: 4.40571936227942

Epoch: 4| Step: 0
Training loss: 4.053297996520996
Validation loss: 4.36975569878855

Epoch: 5| Step: 1
Training loss: 3.9766151905059814
Validation loss: 4.332389277796591

Epoch: 5| Step: 2
Training loss: 3.5817198753356934
Validation loss: 4.295301365595992

Epoch: 5| Step: 3
Training loss: 5.046271800994873
Validation loss: 4.258670924812235

Epoch: 5| Step: 4
Training loss: 3.751055955886841
Validation loss: 4.222615559895833

Epoch: 5| Step: 5
Training loss: 4.596197605133057
Validation loss: 4.188517673041231

Epoch: 5| Step: 6
Training loss: 4.64377498626709
Validation loss: 4.154878554805633

Epoch: 5| Step: 7
Training loss: 2.9526920318603516
Validation loss: 4.124868295525991

Epoch: 5| Step: 8
Training loss: 4.32100772857666
Validation loss: 4.093151928276144

Epoch: 5| Step: 9
Training loss: 3.6724624633789062
Validation loss: 4.064906627901139

Epoch: 5| Step: 10
Training loss: 3.4934473037719727
Validation loss: 4.0352695372796825

Epoch: 5| Step: 0
Training loss: 3.676692485809326
Validation loss: 4.009312552790488

Epoch: 5| Step: 1
Training loss: 5.048514366149902
Validation loss: 3.982799119846795

Epoch: 5| Step: 2
Training loss: 3.267341136932373
Validation loss: 3.958310793804866

Epoch: 5| Step: 3
Training loss: 3.2750186920166016
Validation loss: 3.9333474687350694

Epoch: 5| Step: 4
Training loss: 3.783421277999878
Validation loss: 3.9090784877859135

Epoch: 5| Step: 5
Training loss: 3.250072479248047
Validation loss: 3.883346152561967

Epoch: 5| Step: 6
Training loss: 3.2876739501953125
Validation loss: 3.860609454493369

Epoch: 5| Step: 7
Training loss: 3.9076075553894043
Validation loss: 3.840298919267552

Epoch: 5| Step: 8
Training loss: 3.5711047649383545
Validation loss: 3.82398295915255

Epoch: 5| Step: 9
Training loss: 4.565669059753418
Validation loss: 3.806613581154936

Epoch: 5| Step: 10
Training loss: 3.694904088973999
Validation loss: 3.790735685697166

Epoch: 6| Step: 0
Training loss: 3.9115920066833496
Validation loss: 3.7759513162797496

Epoch: 5| Step: 1
Training loss: 2.364717960357666
Validation loss: 3.759663848466771

Epoch: 5| Step: 2
Training loss: 3.459426164627075
Validation loss: 3.7442201901507635

Epoch: 5| Step: 3
Training loss: 3.562539577484131
Validation loss: 3.7276941627584477

Epoch: 5| Step: 4
Training loss: 3.5265097618103027
Validation loss: 3.7068598654962357

Epoch: 5| Step: 5
Training loss: 3.8117051124572754
Validation loss: 3.688202396515877

Epoch: 5| Step: 6
Training loss: 3.6591732501983643
Validation loss: 3.6733078546421503

Epoch: 5| Step: 7
Training loss: 3.6413493156433105
Validation loss: 3.6585192423994823

Epoch: 5| Step: 8
Training loss: 3.499743938446045
Validation loss: 3.6438129486576205

Epoch: 5| Step: 9
Training loss: 4.0674214363098145
Validation loss: 3.6302772286117717

Epoch: 5| Step: 10
Training loss: 4.088286399841309
Validation loss: 3.614738077245733

Epoch: 7| Step: 0
Training loss: 3.872640609741211
Validation loss: 3.5987486249657086

Epoch: 5| Step: 1
Training loss: 3.8957786560058594
Validation loss: 3.583046523473596

Epoch: 5| Step: 2
Training loss: 3.1835062503814697
Validation loss: 3.57217421326586

Epoch: 5| Step: 3
Training loss: 2.841259479522705
Validation loss: 3.555335106388215

Epoch: 5| Step: 4
Training loss: 3.549393892288208
Validation loss: 3.5448775983625844

Epoch: 5| Step: 5
Training loss: 3.8162238597869873
Validation loss: 3.5361917300890853

Epoch: 5| Step: 6
Training loss: 2.716309070587158
Validation loss: 3.5247835395156697

Epoch: 5| Step: 7
Training loss: 4.872020721435547
Validation loss: 3.512980297047605

Epoch: 5| Step: 8
Training loss: 3.211394786834717
Validation loss: 3.5006728172302246

Epoch: 5| Step: 9
Training loss: 3.0885066986083984
Validation loss: 3.4915019440394577

Epoch: 5| Step: 10
Training loss: 2.968606472015381
Validation loss: 3.4831253815722722

Epoch: 8| Step: 0
Training loss: 3.016964912414551
Validation loss: 3.4718183932765836

Epoch: 5| Step: 1
Training loss: 3.8575820922851562
Validation loss: 3.4644114099523073

Epoch: 5| Step: 2
Training loss: 3.3327784538269043
Validation loss: 3.455446017685757

Epoch: 5| Step: 3
Training loss: 3.2605297565460205
Validation loss: 3.448137193597773

Epoch: 5| Step: 4
Training loss: 3.7309868335723877
Validation loss: 3.4394753825279976

Epoch: 5| Step: 5
Training loss: 2.585538387298584
Validation loss: 3.432555716524842

Epoch: 5| Step: 6
Training loss: 3.8130855560302734
Validation loss: 3.4250901591393257

Epoch: 5| Step: 7
Training loss: 3.816185474395752
Validation loss: 3.4145974446368474

Epoch: 5| Step: 8
Training loss: 3.2524540424346924
Validation loss: 3.409657919278709

Epoch: 5| Step: 9
Training loss: 3.5157980918884277
Validation loss: 3.402790505398986

Epoch: 5| Step: 10
Training loss: 2.931588649749756
Validation loss: 3.3958253117017847

Epoch: 9| Step: 0
Training loss: 2.937648296356201
Validation loss: 3.3899930395105833

Epoch: 5| Step: 1
Training loss: 4.478970527648926
Validation loss: 3.3820027279597458

Epoch: 5| Step: 2
Training loss: 2.801143169403076
Validation loss: 3.3757620088515745

Epoch: 5| Step: 3
Training loss: 2.7051429748535156
Validation loss: 3.3698300494942615

Epoch: 5| Step: 4
Training loss: 2.4921863079071045
Validation loss: 3.366538478482154

Epoch: 5| Step: 5
Training loss: 3.1713414192199707
Validation loss: 3.365642988553611

Epoch: 5| Step: 6
Training loss: 3.6734108924865723
Validation loss: 3.3532179658130934

Epoch: 5| Step: 7
Training loss: 2.9939353466033936
Validation loss: 3.3521657733507055

Epoch: 5| Step: 8
Training loss: 4.082755088806152
Validation loss: 3.3486547675184024

Epoch: 5| Step: 9
Training loss: 3.3927536010742188
Validation loss: 3.346294254385015

Epoch: 5| Step: 10
Training loss: 3.8756651878356934
Validation loss: 3.334306650264289

Epoch: 10| Step: 0
Training loss: 2.989013910293579
Validation loss: 3.3248321702403407

Epoch: 5| Step: 1
Training loss: 3.3567168712615967
Validation loss: 3.3203379210605415

Epoch: 5| Step: 2
Training loss: 3.651512622833252
Validation loss: 3.319318602162023

Epoch: 5| Step: 3
Training loss: 3.257124662399292
Validation loss: 3.3057742426472325

Epoch: 5| Step: 4
Training loss: 3.9050076007843018
Validation loss: 3.302328412250806

Epoch: 5| Step: 5
Training loss: 2.6518046855926514
Validation loss: 3.302135493165703

Epoch: 5| Step: 6
Training loss: 3.963282823562622
Validation loss: 3.302443173623854

Epoch: 5| Step: 7
Training loss: 2.1708052158355713
Validation loss: 3.2985416381589827

Epoch: 5| Step: 8
Training loss: 3.071624279022217
Validation loss: 3.292773192928683

Epoch: 5| Step: 9
Training loss: 3.0177528858184814
Validation loss: 3.2814948610080186

Epoch: 5| Step: 10
Training loss: 4.095148086547852
Validation loss: 3.274570736833798

Epoch: 11| Step: 0
Training loss: 2.897299289703369
Validation loss: 3.2682160433902534

Epoch: 5| Step: 1
Training loss: 3.518521547317505
Validation loss: 3.2619947182234896

Epoch: 5| Step: 2
Training loss: 2.9725499153137207
Validation loss: 3.2618131304299958

Epoch: 5| Step: 3
Training loss: 3.5301475524902344
Validation loss: 3.25456303422169

Epoch: 5| Step: 4
Training loss: 2.1441540718078613
Validation loss: 3.2511238641636346

Epoch: 5| Step: 5
Training loss: 2.8117849826812744
Validation loss: 3.2462537955212336

Epoch: 5| Step: 6
Training loss: 3.489231824874878
Validation loss: 3.242277076167445

Epoch: 5| Step: 7
Training loss: 3.6165592670440674
Validation loss: 3.236517713915917

Epoch: 5| Step: 8
Training loss: 4.926808834075928
Validation loss: 3.2297973171357186

Epoch: 5| Step: 9
Training loss: 2.5530171394348145
Validation loss: 3.2252889499869397

Epoch: 5| Step: 10
Training loss: 3.017763137817383
Validation loss: 3.2223738316566712

Epoch: 12| Step: 0
Training loss: 3.2798049449920654
Validation loss: 3.217574409259263

Epoch: 5| Step: 1
Training loss: 3.9167227745056152
Validation loss: 3.215360249242475

Epoch: 5| Step: 2
Training loss: 3.6276862621307373
Validation loss: 3.210968571324502

Epoch: 5| Step: 3
Training loss: 2.997572422027588
Validation loss: 3.205028795426892

Epoch: 5| Step: 4
Training loss: 2.784001588821411
Validation loss: 3.202909146585772

Epoch: 5| Step: 5
Training loss: 4.248838901519775
Validation loss: 3.2001386201509865

Epoch: 5| Step: 6
Training loss: 2.5162951946258545
Validation loss: 3.1956876964979273

Epoch: 5| Step: 7
Training loss: 2.956993818283081
Validation loss: 3.192053576951386

Epoch: 5| Step: 8
Training loss: 2.5984058380126953
Validation loss: 3.1939668373395036

Epoch: 5| Step: 9
Training loss: 2.5682787895202637
Validation loss: 3.180351521379204

Epoch: 5| Step: 10
Training loss: 3.7292094230651855
Validation loss: 3.1756901433390956

Epoch: 13| Step: 0
Training loss: 3.901686906814575
Validation loss: 3.1753413754124797

Epoch: 5| Step: 1
Training loss: 3.3925132751464844
Validation loss: 3.175851862917664

Epoch: 5| Step: 2
Training loss: 3.1931159496307373
Validation loss: 3.1712744492356495

Epoch: 5| Step: 3
Training loss: 2.904550075531006
Validation loss: 3.162391903579876

Epoch: 5| Step: 4
Training loss: 3.408836841583252
Validation loss: 3.1598342464816187

Epoch: 5| Step: 5
Training loss: 2.4945590496063232
Validation loss: 3.1573169077596357

Epoch: 5| Step: 6
Training loss: 3.0276360511779785
Validation loss: 3.1545211474100747

Epoch: 5| Step: 7
Training loss: 3.026735305786133
Validation loss: 3.1468428796337498

Epoch: 5| Step: 8
Training loss: 2.79777193069458
Validation loss: 3.1477908037042104

Epoch: 5| Step: 9
Training loss: 3.3292903900146484
Validation loss: 3.1379421039294173

Epoch: 5| Step: 10
Training loss: 3.411264419555664
Validation loss: 3.1393990260298534

Epoch: 14| Step: 0
Training loss: 2.5263566970825195
Validation loss: 3.139748934776552

Epoch: 5| Step: 1
Training loss: 2.999441146850586
Validation loss: 3.134678384309174

Epoch: 5| Step: 2
Training loss: 3.1784346103668213
Validation loss: 3.1311772126023487

Epoch: 5| Step: 3
Training loss: 2.1947245597839355
Validation loss: 3.124934806618639

Epoch: 5| Step: 4
Training loss: 3.375593662261963
Validation loss: 3.1218005739232546

Epoch: 5| Step: 5
Training loss: 4.018584728240967
Validation loss: 3.1181635164445445

Epoch: 5| Step: 6
Training loss: 3.30560564994812
Validation loss: 3.113459610169934

Epoch: 5| Step: 7
Training loss: 3.1010851860046387
Validation loss: 3.114821385311824

Epoch: 5| Step: 8
Training loss: 3.365875244140625
Validation loss: 3.1092720980285318

Epoch: 5| Step: 9
Training loss: 3.3453898429870605
Validation loss: 3.1068312685976744

Epoch: 5| Step: 10
Training loss: 3.1680259704589844
Validation loss: 3.10889434301725

Epoch: 15| Step: 0
Training loss: 3.139171600341797
Validation loss: 3.1106492806506414

Epoch: 5| Step: 1
Training loss: 2.89992094039917
Validation loss: 3.108115832010905

Epoch: 5| Step: 2
Training loss: 2.8626856803894043
Validation loss: 3.10668041629176

Epoch: 5| Step: 3
Training loss: 3.0025885105133057
Validation loss: 3.100401396392494

Epoch: 5| Step: 4
Training loss: 3.1692399978637695
Validation loss: 3.096144676208496

Epoch: 5| Step: 5
Training loss: 2.792937755584717
Validation loss: 3.092111538815242

Epoch: 5| Step: 6
Training loss: 3.2279326915740967
Validation loss: 3.086258162734329

Epoch: 5| Step: 7
Training loss: 4.214389324188232
Validation loss: 3.082297222588652

Epoch: 5| Step: 8
Training loss: 3.216137409210205
Validation loss: 3.081733144739623

Epoch: 5| Step: 9
Training loss: 3.3107597827911377
Validation loss: 3.0819974227618148

Epoch: 5| Step: 10
Training loss: 2.437544584274292
Validation loss: 3.0927512235538934

Epoch: 16| Step: 0
Training loss: 2.9694056510925293
Validation loss: 3.0791667071721887

Epoch: 5| Step: 1
Training loss: 2.4586691856384277
Validation loss: 3.081412725551154

Epoch: 5| Step: 2
Training loss: 2.3058531284332275
Validation loss: 3.068818043637019

Epoch: 5| Step: 3
Training loss: 3.200392961502075
Validation loss: 3.0698749737073014

Epoch: 5| Step: 4
Training loss: 2.665858507156372
Validation loss: 3.0745773905067035

Epoch: 5| Step: 5
Training loss: 2.684551954269409
Validation loss: 3.0832806095000236

Epoch: 5| Step: 6
Training loss: 3.620112895965576
Validation loss: 3.0824388073336695

Epoch: 5| Step: 7
Training loss: 3.4426753520965576
Validation loss: 3.0755469542677685

Epoch: 5| Step: 8
Training loss: 3.331564426422119
Validation loss: 3.0705761345483924

Epoch: 5| Step: 9
Training loss: 4.601998329162598
Validation loss: 3.062772520126835

Epoch: 5| Step: 10
Training loss: 2.907043933868408
Validation loss: 3.0562342213046167

Epoch: 17| Step: 0
Training loss: 3.2649903297424316
Validation loss: 3.053005656888408

Epoch: 5| Step: 1
Training loss: 3.7340660095214844
Validation loss: 3.051037432045065

Epoch: 5| Step: 2
Training loss: 3.2839653491973877
Validation loss: 3.0503107527250886

Epoch: 5| Step: 3
Training loss: 2.806180000305176
Validation loss: 3.048622167238625

Epoch: 5| Step: 4
Training loss: 3.3249106407165527
Validation loss: 3.043815976829939

Epoch: 5| Step: 5
Training loss: 3.146994113922119
Validation loss: 3.041537474560481

Epoch: 5| Step: 6
Training loss: 2.274761199951172
Validation loss: 3.0402484042670137

Epoch: 5| Step: 7
Training loss: 3.073408842086792
Validation loss: 3.0392972551366335

Epoch: 5| Step: 8
Training loss: 3.690713405609131
Validation loss: 3.0368625630614576

Epoch: 5| Step: 9
Training loss: 2.942277669906616
Validation loss: 3.0356177258235153

Epoch: 5| Step: 10
Training loss: 2.3832709789276123
Validation loss: 3.0332895119984946

Epoch: 18| Step: 0
Training loss: 2.550710439682007
Validation loss: 3.0317611489244687

Epoch: 5| Step: 1
Training loss: 3.82953143119812
Validation loss: 3.0302290378078336

Epoch: 5| Step: 2
Training loss: 2.9387524127960205
Validation loss: 3.028181832323792

Epoch: 5| Step: 3
Training loss: 2.4587669372558594
Validation loss: 3.0262107490211405

Epoch: 5| Step: 4
Training loss: 2.4162497520446777
Validation loss: 3.024249046079574

Epoch: 5| Step: 5
Training loss: 3.5893959999084473
Validation loss: 3.0219569283147014

Epoch: 5| Step: 6
Training loss: 2.687072277069092
Validation loss: 3.0186543080114547

Epoch: 5| Step: 7
Training loss: 4.049398422241211
Validation loss: 3.0142630659123903

Epoch: 5| Step: 8
Training loss: 3.011046886444092
Validation loss: 3.013797180626982

Epoch: 5| Step: 9
Training loss: 2.8752923011779785
Validation loss: 3.0125856014990036

Epoch: 5| Step: 10
Training loss: 3.5389773845672607
Validation loss: 3.0116118615673435

Epoch: 19| Step: 0
Training loss: 3.6638855934143066
Validation loss: 3.0123333956605647

Epoch: 5| Step: 1
Training loss: 2.9065494537353516
Validation loss: 3.0044207470391386

Epoch: 5| Step: 2
Training loss: 3.3690974712371826
Validation loss: 3.0035469019284813

Epoch: 5| Step: 3
Training loss: 2.183180332183838
Validation loss: 3.0060091582677697

Epoch: 5| Step: 4
Training loss: 2.621997833251953
Validation loss: 3.006822378404679

Epoch: 5| Step: 5
Training loss: 1.8734735250473022
Validation loss: 3.0071931372406664

Epoch: 5| Step: 6
Training loss: 2.645350694656372
Validation loss: 3.004233819182201

Epoch: 5| Step: 7
Training loss: 3.921128511428833
Validation loss: 3.0004513750794115

Epoch: 5| Step: 8
Training loss: 3.4291698932647705
Validation loss: 2.9962731792080786

Epoch: 5| Step: 9
Training loss: 3.962015151977539
Validation loss: 2.987227229661839

Epoch: 5| Step: 10
Training loss: 3.1578991413116455
Validation loss: 2.979746075086696

Epoch: 20| Step: 0
Training loss: 2.3829703330993652
Validation loss: 2.9793562760917087

Epoch: 5| Step: 1
Training loss: 3.1248726844787598
Validation loss: 2.973955944020261

Epoch: 5| Step: 2
Training loss: 3.199754476547241
Validation loss: 2.973121117520076

Epoch: 5| Step: 3
Training loss: 2.8500893115997314
Validation loss: 2.9712401923312934

Epoch: 5| Step: 4
Training loss: 3.38067364692688
Validation loss: 2.9698842674173336

Epoch: 5| Step: 5
Training loss: 3.1294562816619873
Validation loss: 2.975990031355171

Epoch: 5| Step: 6
Training loss: 2.9974303245544434
Validation loss: 2.967729324935585

Epoch: 5| Step: 7
Training loss: 3.162484884262085
Validation loss: 2.965350607390045

Epoch: 5| Step: 8
Training loss: 2.982475757598877
Validation loss: 2.9650923923779557

Epoch: 5| Step: 9
Training loss: 2.4842448234558105
Validation loss: 2.9662285722712034

Epoch: 5| Step: 10
Training loss: 3.950134754180908
Validation loss: 2.9679792081156084

Epoch: 21| Step: 0
Training loss: 2.7540204524993896
Validation loss: 2.9656799865025345

Epoch: 5| Step: 1
Training loss: 3.3597779273986816
Validation loss: 2.964125058984244

Epoch: 5| Step: 2
Training loss: 2.5377604961395264
Validation loss: 2.9625910866645073

Epoch: 5| Step: 3
Training loss: 3.428208827972412
Validation loss: 2.95945970730115

Epoch: 5| Step: 4
Training loss: 2.9404237270355225
Validation loss: 2.958027183368642

Epoch: 5| Step: 5
Training loss: 2.5162858963012695
Validation loss: 2.9554041559978197

Epoch: 5| Step: 6
Training loss: 3.254106044769287
Validation loss: 2.9524399926585536

Epoch: 5| Step: 7
Training loss: 3.1134181022644043
Validation loss: 2.95137978881918

Epoch: 5| Step: 8
Training loss: 2.9024524688720703
Validation loss: 2.9501168676601943

Epoch: 5| Step: 9
Training loss: 3.0902812480926514
Validation loss: 2.947092230601977

Epoch: 5| Step: 10
Training loss: 3.5800058841705322
Validation loss: 2.9472637791787424

Epoch: 22| Step: 0
Training loss: 3.726198673248291
Validation loss: 2.943963222606208

Epoch: 5| Step: 1
Training loss: 3.2058768272399902
Validation loss: 2.9429715807719896

Epoch: 5| Step: 2
Training loss: 2.5793185234069824
Validation loss: 2.9413681209728284

Epoch: 5| Step: 3
Training loss: 2.554100751876831
Validation loss: 2.939667558157316

Epoch: 5| Step: 4
Training loss: 3.96952486038208
Validation loss: 2.937569151642502

Epoch: 5| Step: 5
Training loss: 2.957829713821411
Validation loss: 2.934863454552107

Epoch: 5| Step: 6
Training loss: 3.1437020301818848
Validation loss: 2.9339484578819683

Epoch: 5| Step: 7
Training loss: 2.5238256454467773
Validation loss: 2.932732851274552

Epoch: 5| Step: 8
Training loss: 3.061824083328247
Validation loss: 2.9294376116926952

Epoch: 5| Step: 9
Training loss: 2.6344785690307617
Validation loss: 2.928959849060223

Epoch: 5| Step: 10
Training loss: 2.882890462875366
Validation loss: 2.9260750278349845

Epoch: 23| Step: 0
Training loss: 2.4312541484832764
Validation loss: 2.9252174285150345

Epoch: 5| Step: 1
Training loss: 3.0780837535858154
Validation loss: 2.9243218898773193

Epoch: 5| Step: 2
Training loss: 2.8565449714660645
Validation loss: 2.922803783929476

Epoch: 5| Step: 3
Training loss: 2.939380168914795
Validation loss: 2.9212380378477034

Epoch: 5| Step: 4
Training loss: 3.289105176925659
Validation loss: 2.920781276559317

Epoch: 5| Step: 5
Training loss: 2.7563817501068115
Validation loss: 2.9181973216354207

Epoch: 5| Step: 6
Training loss: 2.4542243480682373
Validation loss: 2.9165656361528622

Epoch: 5| Step: 7
Training loss: 2.6287951469421387
Validation loss: 2.9158726481981176

Epoch: 5| Step: 8
Training loss: 3.4364571571350098
Validation loss: 2.9137779615258657

Epoch: 5| Step: 9
Training loss: 4.095975875854492
Validation loss: 2.914569503517561

Epoch: 5| Step: 10
Training loss: 3.1744329929351807
Validation loss: 2.9091373848658737

Epoch: 24| Step: 0
Training loss: 2.477766513824463
Validation loss: 2.909441691572948

Epoch: 5| Step: 1
Training loss: 2.769629955291748
Validation loss: 2.9070207431752193

Epoch: 5| Step: 2
Training loss: 3.1646358966827393
Validation loss: 2.9044942830198552

Epoch: 5| Step: 3
Training loss: 3.5328621864318848
Validation loss: 2.9030696576641453

Epoch: 5| Step: 4
Training loss: 3.690634250640869
Validation loss: 2.899040396495532

Epoch: 5| Step: 5
Training loss: 3.0450541973114014
Validation loss: 2.8960632842074157

Epoch: 5| Step: 6
Training loss: 2.6959476470947266
Validation loss: 2.8877343695650817

Epoch: 5| Step: 7
Training loss: 3.2314352989196777
Validation loss: 2.8905748628800914

Epoch: 5| Step: 8
Training loss: 2.8455119132995605
Validation loss: 2.889246771412511

Epoch: 5| Step: 9
Training loss: 2.572796583175659
Validation loss: 2.8844644331162974

Epoch: 5| Step: 10
Training loss: 2.9308834075927734
Validation loss: 2.8820121134481123

Epoch: 25| Step: 0
Training loss: 3.263474225997925
Validation loss: 2.8811914766988447

Epoch: 5| Step: 1
Training loss: 3.026761054992676
Validation loss: 2.879058281580607

Epoch: 5| Step: 2
Training loss: 2.95027232170105
Validation loss: 2.877131031405541

Epoch: 5| Step: 3
Training loss: 3.192955493927002
Validation loss: 2.8715541183307605

Epoch: 5| Step: 4
Training loss: 3.606579542160034
Validation loss: 2.869297081424344

Epoch: 5| Step: 5
Training loss: 2.5263943672180176
Validation loss: 2.8699042284360496

Epoch: 5| Step: 6
Training loss: 2.717566728591919
Validation loss: 2.8682439583604054

Epoch: 5| Step: 7
Training loss: 2.6522374153137207
Validation loss: 2.865760328949139

Epoch: 5| Step: 8
Training loss: 3.4172146320343018
Validation loss: 2.864003481403474

Epoch: 5| Step: 9
Training loss: 2.463266611099243
Validation loss: 2.8624194463094077

Epoch: 5| Step: 10
Training loss: 2.959413528442383
Validation loss: 2.8608383132565405

Epoch: 26| Step: 0
Training loss: 3.630478620529175
Validation loss: 2.8588461465733026

Epoch: 5| Step: 1
Training loss: 3.0165228843688965
Validation loss: 2.858964084297098

Epoch: 5| Step: 2
Training loss: 3.1925816535949707
Validation loss: 2.861803506010322

Epoch: 5| Step: 3
Training loss: 2.444962978363037
Validation loss: 2.865014373615224

Epoch: 5| Step: 4
Training loss: 2.345832347869873
Validation loss: 2.85970571220562

Epoch: 5| Step: 5
Training loss: 2.5986132621765137
Validation loss: 2.858365943354945

Epoch: 5| Step: 6
Training loss: 3.0268287658691406
Validation loss: 2.8579602677335023

Epoch: 5| Step: 7
Training loss: 2.993583917617798
Validation loss: 2.85929169706119

Epoch: 5| Step: 8
Training loss: 3.7108561992645264
Validation loss: 2.8620594598913707

Epoch: 5| Step: 9
Training loss: 2.4617011547088623
Validation loss: 2.86865492533612

Epoch: 5| Step: 10
Training loss: 3.303579330444336
Validation loss: 2.855851291328348

Epoch: 27| Step: 0
Training loss: 2.945300579071045
Validation loss: 2.8517670477590253

Epoch: 5| Step: 1
Training loss: 3.1046876907348633
Validation loss: 2.8525138106397403

Epoch: 5| Step: 2
Training loss: 2.5351455211639404
Validation loss: 2.8546974043692313

Epoch: 5| Step: 3
Training loss: 2.8572463989257812
Validation loss: 2.857248403692758

Epoch: 5| Step: 4
Training loss: 3.146644353866577
Validation loss: 2.8574128638031664

Epoch: 5| Step: 5
Training loss: 3.610046863555908
Validation loss: 2.8519155004973054

Epoch: 5| Step: 6
Training loss: 3.1734156608581543
Validation loss: 2.848432610111852

Epoch: 5| Step: 7
Training loss: 3.105656862258911
Validation loss: 2.849003961009364

Epoch: 5| Step: 8
Training loss: 3.135607957839966
Validation loss: 2.8502080107247956

Epoch: 5| Step: 9
Training loss: 2.879563570022583
Validation loss: 2.847843295784407

Epoch: 5| Step: 10
Training loss: 1.9905637502670288
Validation loss: 2.847252002326391

Epoch: 28| Step: 0
Training loss: 3.258787155151367
Validation loss: 2.8475482848382767

Epoch: 5| Step: 1
Training loss: 3.5188400745391846
Validation loss: 2.85079288482666

Epoch: 5| Step: 2
Training loss: 3.3659768104553223
Validation loss: 2.8535125614494405

Epoch: 5| Step: 3
Training loss: 3.531400203704834
Validation loss: 2.8522622072568504

Epoch: 5| Step: 4
Training loss: 2.5004613399505615
Validation loss: 2.8484799605543896

Epoch: 5| Step: 5
Training loss: 2.660895586013794
Validation loss: 2.842966433494322

Epoch: 5| Step: 6
Training loss: 3.0852177143096924
Validation loss: 2.841951024147772

Epoch: 5| Step: 7
Training loss: 2.596975803375244
Validation loss: 2.83962679934758

Epoch: 5| Step: 8
Training loss: 2.581693172454834
Validation loss: 2.8403531043760237

Epoch: 5| Step: 9
Training loss: 2.983031749725342
Validation loss: 2.8403277807338263

Epoch: 5| Step: 10
Training loss: 2.4021780490875244
Validation loss: 2.8403599774965675

Epoch: 29| Step: 0
Training loss: 2.0234642028808594
Validation loss: 2.841953541642876

Epoch: 5| Step: 1
Training loss: 2.9972400665283203
Validation loss: 2.8384482706746748

Epoch: 5| Step: 2
Training loss: 3.1985278129577637
Validation loss: 2.8369797506640033

Epoch: 5| Step: 3
Training loss: 2.4041481018066406
Validation loss: 2.835587796344552

Epoch: 5| Step: 4
Training loss: 4.3603835105896
Validation loss: 2.834032997008293

Epoch: 5| Step: 5
Training loss: 3.3664474487304688
Validation loss: 2.8322227770282375

Epoch: 5| Step: 6
Training loss: 2.997387647628784
Validation loss: 2.8336256088749057

Epoch: 5| Step: 7
Training loss: 2.562992572784424
Validation loss: 2.834455654185305

Epoch: 5| Step: 8
Training loss: 2.72312593460083
Validation loss: 2.8355733681750555

Epoch: 5| Step: 9
Training loss: 2.8759326934814453
Validation loss: 2.8430426043848835

Epoch: 5| Step: 10
Training loss: 3.035159111022949
Validation loss: 2.839934397769231

Epoch: 30| Step: 0
Training loss: 3.02685546875
Validation loss: 2.830750834557318

Epoch: 5| Step: 1
Training loss: 2.3854947090148926
Validation loss: 2.8311073831332627

Epoch: 5| Step: 2
Training loss: 2.5671470165252686
Validation loss: 2.828965797219225

Epoch: 5| Step: 3
Training loss: 2.569685459136963
Validation loss: 2.8301234578573577

Epoch: 5| Step: 4
Training loss: 3.1162924766540527
Validation loss: 2.8290946611794094

Epoch: 5| Step: 5
Training loss: 2.6837565898895264
Validation loss: 2.8264966857048774

Epoch: 5| Step: 6
Training loss: 3.285073757171631
Validation loss: 2.8288825147895404

Epoch: 5| Step: 7
Training loss: 3.321742296218872
Validation loss: 2.832570042661441

Epoch: 5| Step: 8
Training loss: 3.093163251876831
Validation loss: 2.825489928645472

Epoch: 5| Step: 9
Training loss: 3.4039623737335205
Validation loss: 2.8263452719616633

Epoch: 5| Step: 10
Training loss: 3.019763469696045
Validation loss: 2.824082592482208

Epoch: 31| Step: 0
Training loss: 2.5889716148376465
Validation loss: 2.826263104715655

Epoch: 5| Step: 1
Training loss: 2.7683000564575195
Validation loss: 2.8273301483482443

Epoch: 5| Step: 2
Training loss: 2.9136486053466797
Validation loss: 2.830245020569012

Epoch: 5| Step: 3
Training loss: 3.1614811420440674
Validation loss: 2.829214608797463

Epoch: 5| Step: 4
Training loss: 3.4545235633850098
Validation loss: 2.829522407183083

Epoch: 5| Step: 5
Training loss: 2.6619741916656494
Validation loss: 2.827896938529066

Epoch: 5| Step: 6
Training loss: 3.0495097637176514
Validation loss: 2.8306844362648587

Epoch: 5| Step: 7
Training loss: 3.852017641067505
Validation loss: 2.831389396421371

Epoch: 5| Step: 8
Training loss: 2.705104112625122
Validation loss: 2.827287822641352

Epoch: 5| Step: 9
Training loss: 2.9323508739471436
Validation loss: 2.828507402891754

Epoch: 5| Step: 10
Training loss: 2.251213312149048
Validation loss: 2.828422177222467

Epoch: 32| Step: 0
Training loss: 2.4547553062438965
Validation loss: 2.823377355452507

Epoch: 5| Step: 1
Training loss: 3.485930919647217
Validation loss: 2.823182790510116

Epoch: 5| Step: 2
Training loss: 2.4055583477020264
Validation loss: 2.8235685107528523

Epoch: 5| Step: 3
Training loss: 2.8887994289398193
Validation loss: 2.8247236410776773

Epoch: 5| Step: 4
Training loss: 3.0300936698913574
Validation loss: 2.8279164324524584

Epoch: 5| Step: 5
Training loss: 3.104914903640747
Validation loss: 2.827329079310099

Epoch: 5| Step: 6
Training loss: 3.0260376930236816
Validation loss: 2.8242392129795526

Epoch: 5| Step: 7
Training loss: 2.583106517791748
Validation loss: 2.8203987383073374

Epoch: 5| Step: 8
Training loss: 3.2282795906066895
Validation loss: 2.821362546695176

Epoch: 5| Step: 9
Training loss: 2.9473772048950195
Validation loss: 2.8168723737039874

Epoch: 5| Step: 10
Training loss: 3.3346996307373047
Validation loss: 2.8161562078742572

Epoch: 33| Step: 0
Training loss: 2.5252041816711426
Validation loss: 2.8207376285265853

Epoch: 5| Step: 1
Training loss: 2.39489483833313
Validation loss: 2.8154101756311234

Epoch: 5| Step: 2
Training loss: 2.9944186210632324
Validation loss: 2.8234157023891324

Epoch: 5| Step: 3
Training loss: 2.9871432781219482
Validation loss: 2.8223236735149095

Epoch: 5| Step: 4
Training loss: 3.0451416969299316
Validation loss: 2.8141588523823726

Epoch: 5| Step: 5
Training loss: 3.6022849082946777
Validation loss: 2.8065004989665043

Epoch: 5| Step: 6
Training loss: 2.589007616043091
Validation loss: 2.8052827107009066

Epoch: 5| Step: 7
Training loss: 2.8963773250579834
Validation loss: 2.803380286821755

Epoch: 5| Step: 8
Training loss: 3.0062060356140137
Validation loss: 2.8047569208247687

Epoch: 5| Step: 9
Training loss: 3.4844162464141846
Validation loss: 2.805682905258671

Epoch: 5| Step: 10
Training loss: 2.7880795001983643
Validation loss: 2.810113706896382

Epoch: 34| Step: 0
Training loss: 2.8129382133483887
Validation loss: 2.804330864260274

Epoch: 5| Step: 1
Training loss: 2.6808440685272217
Validation loss: 2.801211336607574

Epoch: 5| Step: 2
Training loss: 2.7280147075653076
Validation loss: 2.79844069480896

Epoch: 5| Step: 3
Training loss: 3.346219301223755
Validation loss: 2.797943979181269

Epoch: 5| Step: 4
Training loss: 2.304595470428467
Validation loss: 2.797670066997569

Epoch: 5| Step: 5
Training loss: 3.0737204551696777
Validation loss: 2.7994213258066485

Epoch: 5| Step: 6
Training loss: 2.888437509536743
Validation loss: 2.801889637465118

Epoch: 5| Step: 7
Training loss: 2.527421474456787
Validation loss: 2.795109805240426

Epoch: 5| Step: 8
Training loss: 3.6006171703338623
Validation loss: 2.795265325935938

Epoch: 5| Step: 9
Training loss: 3.2618465423583984
Validation loss: 2.792328752497191

Epoch: 5| Step: 10
Training loss: 3.0411484241485596
Validation loss: 2.794762767771239

Epoch: 35| Step: 0
Training loss: 3.464951276779175
Validation loss: 2.7935240678889777

Epoch: 5| Step: 1
Training loss: 3.4449970722198486
Validation loss: 2.7962902515165267

Epoch: 5| Step: 2
Training loss: 2.6518139839172363
Validation loss: 2.7970494429270425

Epoch: 5| Step: 3
Training loss: 3.365676164627075
Validation loss: 2.7938841337798745

Epoch: 5| Step: 4
Training loss: 3.1784021854400635
Validation loss: 2.794615295625502

Epoch: 5| Step: 5
Training loss: 2.1708788871765137
Validation loss: 2.7912608987541607

Epoch: 5| Step: 6
Training loss: 3.1892364025115967
Validation loss: 2.7888487180074057

Epoch: 5| Step: 7
Training loss: 2.3965320587158203
Validation loss: 2.7843104972634265

Epoch: 5| Step: 8
Training loss: 2.839257001876831
Validation loss: 2.7835150636652464

Epoch: 5| Step: 9
Training loss: 2.6180050373077393
Validation loss: 2.7824569773930374

Epoch: 5| Step: 10
Training loss: 2.8671369552612305
Validation loss: 2.78016480066443

Epoch: 36| Step: 0
Training loss: 2.328842878341675
Validation loss: 2.778101110971102

Epoch: 5| Step: 1
Training loss: 2.7131400108337402
Validation loss: 2.777172286023376

Epoch: 5| Step: 2
Training loss: 3.4599032402038574
Validation loss: 2.7841098436745266

Epoch: 5| Step: 3
Training loss: 2.4951770305633545
Validation loss: 2.79357680197685

Epoch: 5| Step: 4
Training loss: 2.4965829849243164
Validation loss: 2.77490577133753

Epoch: 5| Step: 5
Training loss: 3.3090522289276123
Validation loss: 2.771370441682877

Epoch: 5| Step: 6
Training loss: 3.1571898460388184
Validation loss: 2.770632251616447

Epoch: 5| Step: 7
Training loss: 2.693235397338867
Validation loss: 2.7791263852068173

Epoch: 5| Step: 8
Training loss: 3.0707192420959473
Validation loss: 2.785723555472589

Epoch: 5| Step: 9
Training loss: 3.210707902908325
Validation loss: 2.779594034276983

Epoch: 5| Step: 10
Training loss: 3.205289363861084
Validation loss: 2.7788294694756948

Epoch: 37| Step: 0
Training loss: 2.450218677520752
Validation loss: 2.775667985280355

Epoch: 5| Step: 1
Training loss: 2.7059133052825928
Validation loss: 2.7770890574301443

Epoch: 5| Step: 2
Training loss: 3.549747943878174
Validation loss: 2.7770863989348054

Epoch: 5| Step: 3
Training loss: 2.664433002471924
Validation loss: 2.7807411275884157

Epoch: 5| Step: 4
Training loss: 3.0769970417022705
Validation loss: 2.783108636897097

Epoch: 5| Step: 5
Training loss: 3.0898900032043457
Validation loss: 2.7729640083928264

Epoch: 5| Step: 6
Training loss: 2.710542678833008
Validation loss: 2.7734897546870734

Epoch: 5| Step: 7
Training loss: 2.832568407058716
Validation loss: 2.773061652337351

Epoch: 5| Step: 8
Training loss: 3.0894758701324463
Validation loss: 2.7688068548838296

Epoch: 5| Step: 9
Training loss: 2.6330952644348145
Validation loss: 2.7721222369901595

Epoch: 5| Step: 10
Training loss: 3.272704839706421
Validation loss: 2.7656756498480357

Epoch: 38| Step: 0
Training loss: 1.9360014200210571
Validation loss: 2.7647661855143886

Epoch: 5| Step: 1
Training loss: 3.3747570514678955
Validation loss: 2.766604615795997

Epoch: 5| Step: 2
Training loss: 2.4692440032958984
Validation loss: 2.769969278766263

Epoch: 5| Step: 3
Training loss: 2.276563882827759
Validation loss: 2.7900785989658807

Epoch: 5| Step: 4
Training loss: 3.411186695098877
Validation loss: 2.789219799862113

Epoch: 5| Step: 5
Training loss: 2.32383394241333
Validation loss: 2.7712860748332035

Epoch: 5| Step: 6
Training loss: 3.8695144653320312
Validation loss: 2.7624501823097147

Epoch: 5| Step: 7
Training loss: 2.8199756145477295
Validation loss: 2.764980895544893

Epoch: 5| Step: 8
Training loss: 2.7159743309020996
Validation loss: 2.7600859262609996

Epoch: 5| Step: 9
Training loss: 3.42297101020813
Validation loss: 2.763932035815331

Epoch: 5| Step: 10
Training loss: 3.465322732925415
Validation loss: 2.764082065192602

Epoch: 39| Step: 0
Training loss: 2.913512706756592
Validation loss: 2.7575187836923907

Epoch: 5| Step: 1
Training loss: 2.683781147003174
Validation loss: 2.75730985723516

Epoch: 5| Step: 2
Training loss: 2.614563226699829
Validation loss: 2.7517425783218874

Epoch: 5| Step: 3
Training loss: 2.888842821121216
Validation loss: 2.7528122958316597

Epoch: 5| Step: 4
Training loss: 3.0373125076293945
Validation loss: 2.7540189835333053

Epoch: 5| Step: 5
Training loss: 2.9042534828186035
Validation loss: 2.748123586818736

Epoch: 5| Step: 6
Training loss: 3.9820480346679688
Validation loss: 2.7498637271183792

Epoch: 5| Step: 7
Training loss: 3.0574772357940674
Validation loss: 2.7487331077616703

Epoch: 5| Step: 8
Training loss: 3.0798230171203613
Validation loss: 2.747441581500474

Epoch: 5| Step: 9
Training loss: 2.496495485305786
Validation loss: 2.747705703140587

Epoch: 5| Step: 10
Training loss: 2.1299705505371094
Validation loss: 2.7472251589580248

Epoch: 40| Step: 0
Training loss: 2.6484994888305664
Validation loss: 2.751268556041102

Epoch: 5| Step: 1
Training loss: 3.2135281562805176
Validation loss: 2.7480686326180734

Epoch: 5| Step: 2
Training loss: 2.761530637741089
Validation loss: 2.7505422792127057

Epoch: 5| Step: 3
Training loss: 3.5434138774871826
Validation loss: 2.7501083676533034

Epoch: 5| Step: 4
Training loss: 3.4114437103271484
Validation loss: 2.74386259817308

Epoch: 5| Step: 5
Training loss: 2.3769612312316895
Validation loss: 2.7437726297686176

Epoch: 5| Step: 6
Training loss: 2.9986982345581055
Validation loss: 2.73887276393111

Epoch: 5| Step: 7
Training loss: 2.2730062007904053
Validation loss: 2.7394312581708355

Epoch: 5| Step: 8
Training loss: 3.2664694786071777
Validation loss: 2.7398791082443728

Epoch: 5| Step: 9
Training loss: 2.78712797164917
Validation loss: 2.738518230376705

Epoch: 5| Step: 10
Training loss: 2.442671775817871
Validation loss: 2.7416051177568335

Epoch: 41| Step: 0
Training loss: 2.88600492477417
Validation loss: 2.7426039890576432

Epoch: 5| Step: 1
Training loss: 2.2663028240203857
Validation loss: 2.74183254344489

Epoch: 5| Step: 2
Training loss: 3.464778184890747
Validation loss: 2.741936852855067

Epoch: 5| Step: 3
Training loss: 3.0698909759521484
Validation loss: 2.7388872356824976

Epoch: 5| Step: 4
Training loss: 3.4500699043273926
Validation loss: 2.7401643542833227

Epoch: 5| Step: 5
Training loss: 2.5076563358306885
Validation loss: 2.735941917665543

Epoch: 5| Step: 6
Training loss: 3.5913498401641846
Validation loss: 2.7350134516275055

Epoch: 5| Step: 7
Training loss: 2.248988389968872
Validation loss: 2.7349157538465274

Epoch: 5| Step: 8
Training loss: 3.0481741428375244
Validation loss: 2.7353558207070954

Epoch: 5| Step: 9
Training loss: 2.6485724449157715
Validation loss: 2.7412996958660822

Epoch: 5| Step: 10
Training loss: 2.522421360015869
Validation loss: 2.742296670072822

Epoch: 42| Step: 0
Training loss: 3.7170238494873047
Validation loss: 2.7753457561615975

Epoch: 5| Step: 1
Training loss: 3.5110504627227783
Validation loss: 2.7351555798643377

Epoch: 5| Step: 2
Training loss: 3.1328842639923096
Validation loss: 2.73739307413819

Epoch: 5| Step: 3
Training loss: 2.513476610183716
Validation loss: 2.734489551154516

Epoch: 5| Step: 4
Training loss: 2.8381247520446777
Validation loss: 2.738952972555673

Epoch: 5| Step: 5
Training loss: 2.1798691749572754
Validation loss: 2.7389370113290767

Epoch: 5| Step: 6
Training loss: 2.8225250244140625
Validation loss: 2.738447255985711

Epoch: 5| Step: 7
Training loss: 2.086573839187622
Validation loss: 2.734847189277731

Epoch: 5| Step: 8
Training loss: 2.88216495513916
Validation loss: 2.7335230150530414

Epoch: 5| Step: 9
Training loss: 3.156940460205078
Validation loss: 2.7353029071643786

Epoch: 5| Step: 10
Training loss: 2.9045097827911377
Validation loss: 2.7338253349386235

Epoch: 43| Step: 0
Training loss: 2.186126232147217
Validation loss: 2.737069514489943

Epoch: 5| Step: 1
Training loss: 3.13568377494812
Validation loss: 2.73705388910027

Epoch: 5| Step: 2
Training loss: 2.0577378273010254
Validation loss: 2.7334088638264644

Epoch: 5| Step: 3
Training loss: 2.5137953758239746
Validation loss: 2.72973386702999

Epoch: 5| Step: 4
Training loss: 2.876042604446411
Validation loss: 2.730570980297622

Epoch: 5| Step: 5
Training loss: 3.0068936347961426
Validation loss: 2.729204834148448

Epoch: 5| Step: 6
Training loss: 3.310948610305786
Validation loss: 2.7268305696466917

Epoch: 5| Step: 7
Training loss: 2.489102602005005
Validation loss: 2.726434994769353

Epoch: 5| Step: 8
Training loss: 3.2126336097717285
Validation loss: 2.7312001336005425

Epoch: 5| Step: 9
Training loss: 3.7086544036865234
Validation loss: 2.748663530554823

Epoch: 5| Step: 10
Training loss: 3.2264301776885986
Validation loss: 2.7447615079982306

Epoch: 44| Step: 0
Training loss: 3.188965320587158
Validation loss: 2.7309958088782524

Epoch: 5| Step: 1
Training loss: 2.3343896865844727
Validation loss: 2.7228203127461095

Epoch: 5| Step: 2
Training loss: 2.447897434234619
Validation loss: 2.7221504385753343

Epoch: 5| Step: 3
Training loss: 3.040773868560791
Validation loss: 2.7288165579559984

Epoch: 5| Step: 4
Training loss: 3.059990644454956
Validation loss: 2.731071856714064

Epoch: 5| Step: 5
Training loss: 2.642784595489502
Validation loss: 2.7233183204486804

Epoch: 5| Step: 6
Training loss: 2.87416934967041
Validation loss: 2.722748982009067

Epoch: 5| Step: 7
Training loss: 3.2530694007873535
Validation loss: 2.721262070440477

Epoch: 5| Step: 8
Training loss: 2.5045437812805176
Validation loss: 2.729972449682092

Epoch: 5| Step: 9
Training loss: 3.1698009967803955
Validation loss: 2.7319028326260146

Epoch: 5| Step: 10
Training loss: 3.1000919342041016
Validation loss: 2.7396757500146025

Epoch: 45| Step: 0
Training loss: 2.8184962272644043
Validation loss: 2.7486362149638515

Epoch: 5| Step: 1
Training loss: 2.128964900970459
Validation loss: 2.7461966417169057

Epoch: 5| Step: 2
Training loss: 2.8195972442626953
Validation loss: 2.7462411439546974

Epoch: 5| Step: 3
Training loss: 3.8078887462615967
Validation loss: 2.737658464780418

Epoch: 5| Step: 4
Training loss: 2.700998544692993
Validation loss: 2.7254234283201155

Epoch: 5| Step: 5
Training loss: 2.5416603088378906
Validation loss: 2.720620491171396

Epoch: 5| Step: 6
Training loss: 2.340059280395508
Validation loss: 2.718691154192853

Epoch: 5| Step: 7
Training loss: 3.455578327178955
Validation loss: 2.716367144738474

Epoch: 5| Step: 8
Training loss: 3.212261199951172
Validation loss: 2.7157039693606797

Epoch: 5| Step: 9
Training loss: 3.4290390014648438
Validation loss: 2.716772369159165

Epoch: 5| Step: 10
Training loss: 2.1582515239715576
Validation loss: 2.717142223030008

Epoch: 46| Step: 0
Training loss: 1.9533627033233643
Validation loss: 2.715726731925882

Epoch: 5| Step: 1
Training loss: 2.6972689628601074
Validation loss: 2.714306475013815

Epoch: 5| Step: 2
Training loss: 2.7937636375427246
Validation loss: 2.717429148253574

Epoch: 5| Step: 3
Training loss: 2.8054683208465576
Validation loss: 2.7157470308324343

Epoch: 5| Step: 4
Training loss: 4.394022464752197
Validation loss: 2.715315993114184

Epoch: 5| Step: 5
Training loss: 2.7573699951171875
Validation loss: 2.7143655079667286

Epoch: 5| Step: 6
Training loss: 2.9100852012634277
Validation loss: 2.7139419765882593

Epoch: 5| Step: 7
Training loss: 2.5621602535247803
Validation loss: 2.7121030848513366

Epoch: 5| Step: 8
Training loss: 3.5332489013671875
Validation loss: 2.713664775253624

Epoch: 5| Step: 9
Training loss: 2.3838047981262207
Validation loss: 2.7138274049246185

Epoch: 5| Step: 10
Training loss: 2.695437431335449
Validation loss: 2.7132516214924474

Epoch: 47| Step: 0
Training loss: 2.2903599739074707
Validation loss: 2.7120146443766933

Epoch: 5| Step: 1
Training loss: 3.301102876663208
Validation loss: 2.7138276382159163

Epoch: 5| Step: 2
Training loss: 2.356581449508667
Validation loss: 2.7114181082735778

Epoch: 5| Step: 3
Training loss: 2.8553802967071533
Validation loss: 2.7130716385379916

Epoch: 5| Step: 4
Training loss: 3.289541721343994
Validation loss: 2.711901662170246

Epoch: 5| Step: 5
Training loss: 2.475493907928467
Validation loss: 2.71606352508709

Epoch: 5| Step: 6
Training loss: 3.0718963146209717
Validation loss: 2.7132018996823217

Epoch: 5| Step: 7
Training loss: 2.8969569206237793
Validation loss: 2.715634457526668

Epoch: 5| Step: 8
Training loss: 3.2764110565185547
Validation loss: 2.713961339765979

Epoch: 5| Step: 9
Training loss: 2.4119772911071777
Validation loss: 2.714070407293176

Epoch: 5| Step: 10
Training loss: 3.2460079193115234
Validation loss: 2.717203394059212

Epoch: 48| Step: 0
Training loss: 3.0986762046813965
Validation loss: 2.7170882122490996

Epoch: 5| Step: 1
Training loss: 2.5708885192871094
Validation loss: 2.716469052017376

Epoch: 5| Step: 2
Training loss: 2.779155731201172
Validation loss: 2.7142957666868806

Epoch: 5| Step: 3
Training loss: 2.892944574356079
Validation loss: 2.7138529541671916

Epoch: 5| Step: 4
Training loss: 2.791846752166748
Validation loss: 2.706217796571793

Epoch: 5| Step: 5
Training loss: 2.5858120918273926
Validation loss: 2.7064746528543453

Epoch: 5| Step: 6
Training loss: 3.1450586318969727
Validation loss: 2.7058366037184194

Epoch: 5| Step: 7
Training loss: 2.927128314971924
Validation loss: 2.704319828300066

Epoch: 5| Step: 8
Training loss: 3.0607306957244873
Validation loss: 2.7042928382914555

Epoch: 5| Step: 9
Training loss: 2.9645791053771973
Validation loss: 2.7021258492623605

Epoch: 5| Step: 10
Training loss: 2.549525022506714
Validation loss: 2.701840005895143

Epoch: 49| Step: 0
Training loss: 3.1004226207733154
Validation loss: 2.7046453183697117

Epoch: 5| Step: 1
Training loss: 3.2690367698669434
Validation loss: 2.7122626381535686

Epoch: 5| Step: 2
Training loss: 3.700202226638794
Validation loss: 2.7188777641583513

Epoch: 5| Step: 3
Training loss: 2.601442813873291
Validation loss: 2.712340895847608

Epoch: 5| Step: 4
Training loss: 3.250288486480713
Validation loss: 2.722395189346806

Epoch: 5| Step: 5
Training loss: 3.0451865196228027
Validation loss: 2.7183359797282884

Epoch: 5| Step: 6
Training loss: 1.7728157043457031
Validation loss: 2.7382663629388295

Epoch: 5| Step: 7
Training loss: 2.748434543609619
Validation loss: 2.733305233781056

Epoch: 5| Step: 8
Training loss: 2.80083966255188
Validation loss: 2.7224053798183316

Epoch: 5| Step: 9
Training loss: 2.5686187744140625
Validation loss: 2.7143068364871445

Epoch: 5| Step: 10
Training loss: 2.447819948196411
Validation loss: 2.7061606760947936

Epoch: 50| Step: 0
Training loss: 2.68778395652771
Validation loss: 2.7061252773448987

Epoch: 5| Step: 1
Training loss: 2.4435667991638184
Validation loss: 2.7063907141326577

Epoch: 5| Step: 2
Training loss: 3.203784227371216
Validation loss: 2.708495816876811

Epoch: 5| Step: 3
Training loss: 2.6912357807159424
Validation loss: 2.7159272368236254

Epoch: 5| Step: 4
Training loss: 2.745678424835205
Validation loss: 2.70479307892502

Epoch: 5| Step: 5
Training loss: 2.5317463874816895
Validation loss: 2.7031603551680043

Epoch: 5| Step: 6
Training loss: 3.143678665161133
Validation loss: 2.7012209841000137

Epoch: 5| Step: 7
Training loss: 2.572624444961548
Validation loss: 2.7046547141126407

Epoch: 5| Step: 8
Training loss: 3.5806705951690674
Validation loss: 2.7020080063932683

Epoch: 5| Step: 9
Training loss: 3.039483070373535
Validation loss: 2.705485828461186

Epoch: 5| Step: 10
Training loss: 2.599153995513916
Validation loss: 2.7089241935360815

Epoch: 51| Step: 0
Training loss: 2.005648374557495
Validation loss: 2.707229006674982

Epoch: 5| Step: 1
Training loss: 3.110164165496826
Validation loss: 2.7044794687660794

Epoch: 5| Step: 2
Training loss: 2.829108715057373
Validation loss: 2.700809165995608

Epoch: 5| Step: 3
Training loss: 2.74955677986145
Validation loss: 2.699927576126591

Epoch: 5| Step: 4
Training loss: 2.7612955570220947
Validation loss: 2.6993898243032475

Epoch: 5| Step: 5
Training loss: 3.2481727600097656
Validation loss: 2.698982923261581

Epoch: 5| Step: 6
Training loss: 2.3336234092712402
Validation loss: 2.703892446333362

Epoch: 5| Step: 7
Training loss: 2.949934720993042
Validation loss: 2.7072226591007684

Epoch: 5| Step: 8
Training loss: 2.970163106918335
Validation loss: 2.7011486971250145

Epoch: 5| Step: 9
Training loss: 2.8729729652404785
Validation loss: 2.69680267764676

Epoch: 5| Step: 10
Training loss: 3.499253034591675
Validation loss: 2.69739447357834

Epoch: 52| Step: 0
Training loss: 2.56803560256958
Validation loss: 2.694366631969329

Epoch: 5| Step: 1
Training loss: 2.7344515323638916
Validation loss: 2.692791110725813

Epoch: 5| Step: 2
Training loss: 2.4255452156066895
Validation loss: 2.698700681809456

Epoch: 5| Step: 3
Training loss: 2.6416168212890625
Validation loss: 2.6963080052406556

Epoch: 5| Step: 4
Training loss: 2.287914752960205
Validation loss: 2.694371931014522

Epoch: 5| Step: 5
Training loss: 3.3987624645233154
Validation loss: 2.6968786972825245

Epoch: 5| Step: 6
Training loss: 2.973897933959961
Validation loss: 2.694433271244008

Epoch: 5| Step: 7
Training loss: 3.418888568878174
Validation loss: 2.6956708636335147

Epoch: 5| Step: 8
Training loss: 2.9434945583343506
Validation loss: 2.690659564028504

Epoch: 5| Step: 9
Training loss: 2.8377647399902344
Validation loss: 2.6934496177140104

Epoch: 5| Step: 10
Training loss: 2.9246714115142822
Validation loss: 2.6904987571060017

Epoch: 53| Step: 0
Training loss: 3.4653992652893066
Validation loss: 2.692554412349578

Epoch: 5| Step: 1
Training loss: 3.6650123596191406
Validation loss: 2.692192631383096

Epoch: 5| Step: 2
Training loss: 2.9936931133270264
Validation loss: 2.692627445344002

Epoch: 5| Step: 3
Training loss: 3.091859817504883
Validation loss: 2.6916693487474994

Epoch: 5| Step: 4
Training loss: 1.6286296844482422
Validation loss: 2.706217327425557

Epoch: 5| Step: 5
Training loss: 2.5272645950317383
Validation loss: 2.770024363712598

Epoch: 5| Step: 6
Training loss: 2.820693254470825
Validation loss: 2.75084602191884

Epoch: 5| Step: 7
Training loss: 3.2283775806427
Validation loss: 2.7227924895542923

Epoch: 5| Step: 8
Training loss: 2.7433536052703857
Validation loss: 2.7151634795691377

Epoch: 5| Step: 9
Training loss: 2.700049638748169
Validation loss: 2.7484665275901876

Epoch: 5| Step: 10
Training loss: 2.322999954223633
Validation loss: 2.796472285383491

Epoch: 54| Step: 0
Training loss: 3.113598346710205
Validation loss: 2.8212050827600623

Epoch: 5| Step: 1
Training loss: 2.669377565383911
Validation loss: 2.7404602394309094

Epoch: 5| Step: 2
Training loss: 2.9406940937042236
Validation loss: 2.7156149520668933

Epoch: 5| Step: 3
Training loss: 2.674121856689453
Validation loss: 2.713422090776505

Epoch: 5| Step: 4
Training loss: 3.469794750213623
Validation loss: 2.716185615908715

Epoch: 5| Step: 5
Training loss: 2.8912744522094727
Validation loss: 2.709820342320268

Epoch: 5| Step: 6
Training loss: 2.810793399810791
Validation loss: 2.735541489816481

Epoch: 5| Step: 7
Training loss: 2.7023415565490723
Validation loss: 2.7479924309638237

Epoch: 5| Step: 8
Training loss: 2.444524049758911
Validation loss: 2.7451709419168453

Epoch: 5| Step: 9
Training loss: 3.125779628753662
Validation loss: 2.7139054190727974

Epoch: 5| Step: 10
Training loss: 2.709444046020508
Validation loss: 2.699367200174639

Epoch: 55| Step: 0
Training loss: 2.2299835681915283
Validation loss: 2.7012943990768923

Epoch: 5| Step: 1
Training loss: 2.4508004188537598
Validation loss: 2.7153128731635308

Epoch: 5| Step: 2
Training loss: 2.983323574066162
Validation loss: 2.71537596179593

Epoch: 5| Step: 3
Training loss: 2.846327304840088
Validation loss: 2.709497872219291

Epoch: 5| Step: 4
Training loss: 2.4612629413604736
Validation loss: 2.7121959347878732

Epoch: 5| Step: 5
Training loss: 3.2834460735321045
Validation loss: 2.7175470654682448

Epoch: 5| Step: 6
Training loss: 2.898266553878784
Validation loss: 2.69842864108342

Epoch: 5| Step: 7
Training loss: 3.119539976119995
Validation loss: 2.708034787126767

Epoch: 5| Step: 8
Training loss: 3.294443130493164
Validation loss: 2.706410136274112

Epoch: 5| Step: 9
Training loss: 2.92641544342041
Validation loss: 2.7022891147162325

Epoch: 5| Step: 10
Training loss: 2.736417770385742
Validation loss: 2.6999381767806185

Epoch: 56| Step: 0
Training loss: 2.059091329574585
Validation loss: 2.6956618780730874

Epoch: 5| Step: 1
Training loss: 3.410350799560547
Validation loss: 2.6927483594545754

Epoch: 5| Step: 2
Training loss: 2.082564115524292
Validation loss: 2.6881719276469243

Epoch: 5| Step: 3
Training loss: 3.370354175567627
Validation loss: 2.6883373004133984

Epoch: 5| Step: 4
Training loss: 2.7766289710998535
Validation loss: 2.6884054445451304

Epoch: 5| Step: 5
Training loss: 3.436986207962036
Validation loss: 2.6889866244408394

Epoch: 5| Step: 6
Training loss: 2.35685396194458
Validation loss: 2.6863888643121205

Epoch: 5| Step: 7
Training loss: 3.2204489707946777
Validation loss: 2.6871636272758566

Epoch: 5| Step: 8
Training loss: 2.826122283935547
Validation loss: 2.6831502222245738

Epoch: 5| Step: 9
Training loss: 2.5665040016174316
Validation loss: 2.6821536197457263

Epoch: 5| Step: 10
Training loss: 3.00632643699646
Validation loss: 2.678616387869722

Epoch: 57| Step: 0
Training loss: 2.5749080181121826
Validation loss: 2.6793219274090183

Epoch: 5| Step: 1
Training loss: 3.152163028717041
Validation loss: 2.677414381375877

Epoch: 5| Step: 2
Training loss: 2.6341075897216797
Validation loss: 2.676148996558241

Epoch: 5| Step: 3
Training loss: 2.684776782989502
Validation loss: 2.6782860576465564

Epoch: 5| Step: 4
Training loss: 2.785266160964966
Validation loss: 2.6800744430993193

Epoch: 5| Step: 5
Training loss: 2.5911004543304443
Validation loss: 2.6788782124878256

Epoch: 5| Step: 6
Training loss: 2.456218957901001
Validation loss: 2.676117830379035

Epoch: 5| Step: 7
Training loss: 3.08471941947937
Validation loss: 2.6784445419106433

Epoch: 5| Step: 8
Training loss: 3.8039791584014893
Validation loss: 2.676130779327885

Epoch: 5| Step: 9
Training loss: 2.4317774772644043
Validation loss: 2.6751145393617692

Epoch: 5| Step: 10
Training loss: 2.768914222717285
Validation loss: 2.6728471927745368

Epoch: 58| Step: 0
Training loss: 2.6704094409942627
Validation loss: 2.6740728270622993

Epoch: 5| Step: 1
Training loss: 2.513362169265747
Validation loss: 2.6720790581036638

Epoch: 5| Step: 2
Training loss: 2.6336898803710938
Validation loss: 2.6722056455509637

Epoch: 5| Step: 3
Training loss: 2.960759401321411
Validation loss: 2.669968456350347

Epoch: 5| Step: 4
Training loss: 3.1389260292053223
Validation loss: 2.670434744127335

Epoch: 5| Step: 5
Training loss: 3.1748769283294678
Validation loss: 2.671691994513235

Epoch: 5| Step: 6
Training loss: 2.648754596710205
Validation loss: 2.6686115418711016

Epoch: 5| Step: 7
Training loss: 2.9070487022399902
Validation loss: 2.6703653873935824

Epoch: 5| Step: 8
Training loss: 2.060692310333252
Validation loss: 2.669392516536097

Epoch: 5| Step: 9
Training loss: 3.2609753608703613
Validation loss: 2.6692625143194713

Epoch: 5| Step: 10
Training loss: 2.9816911220550537
Validation loss: 2.6681271086456957

Epoch: 59| Step: 0
Training loss: 3.1973936557769775
Validation loss: 2.6688853771455827

Epoch: 5| Step: 1
Training loss: 2.1506283283233643
Validation loss: 2.6665892037012244

Epoch: 5| Step: 2
Training loss: 3.2608954906463623
Validation loss: 2.6673009805781867

Epoch: 5| Step: 3
Training loss: 2.018643379211426
Validation loss: 2.6653005871721493

Epoch: 5| Step: 4
Training loss: 3.110037326812744
Validation loss: 2.6663824178839244

Epoch: 5| Step: 5
Training loss: 2.5761971473693848
Validation loss: 2.6650619455563125

Epoch: 5| Step: 6
Training loss: 3.4555282592773438
Validation loss: 2.668463087851001

Epoch: 5| Step: 7
Training loss: 2.8080861568450928
Validation loss: 2.6707579705022995

Epoch: 5| Step: 8
Training loss: 2.50278902053833
Validation loss: 2.67297262530173

Epoch: 5| Step: 9
Training loss: 2.656219720840454
Validation loss: 2.6714403757485012

Epoch: 5| Step: 10
Training loss: 3.2422256469726562
Validation loss: 2.669850418644567

Epoch: 60| Step: 0
Training loss: 2.8712291717529297
Validation loss: 2.668167773113456

Epoch: 5| Step: 1
Training loss: 2.483426809310913
Validation loss: 2.6625579070019465

Epoch: 5| Step: 2
Training loss: 2.5886054039001465
Validation loss: 2.6626018452387985

Epoch: 5| Step: 3
Training loss: 2.703601360321045
Validation loss: 2.662638928300591

Epoch: 5| Step: 4
Training loss: 2.6932220458984375
Validation loss: 2.6606494842037076

Epoch: 5| Step: 5
Training loss: 2.259352684020996
Validation loss: 2.6625322500864663

Epoch: 5| Step: 6
Training loss: 3.0986337661743164
Validation loss: 2.661628714171789

Epoch: 5| Step: 7
Training loss: 3.095883846282959
Validation loss: 2.6585640779105564

Epoch: 5| Step: 8
Training loss: 3.2782504558563232
Validation loss: 2.659543796252179

Epoch: 5| Step: 9
Training loss: 2.4769787788391113
Validation loss: 2.662159830011347

Epoch: 5| Step: 10
Training loss: 3.3409600257873535
Validation loss: 2.66431107828694

Epoch: 61| Step: 0
Training loss: 2.875925302505493
Validation loss: 2.6688654371487197

Epoch: 5| Step: 1
Training loss: 2.561912775039673
Validation loss: 2.670883942675847

Epoch: 5| Step: 2
Training loss: 2.4150607585906982
Validation loss: 2.669352367360105

Epoch: 5| Step: 3
Training loss: 2.757081985473633
Validation loss: 2.6599436652275825

Epoch: 5| Step: 4
Training loss: 2.4316654205322266
Validation loss: 2.6567453466435915

Epoch: 5| Step: 5
Training loss: 2.341693878173828
Validation loss: 2.6552948054446968

Epoch: 5| Step: 6
Training loss: 2.8173224925994873
Validation loss: 2.657009547756564

Epoch: 5| Step: 7
Training loss: 3.351987361907959
Validation loss: 2.6573768559322564

Epoch: 5| Step: 8
Training loss: 2.7716715335845947
Validation loss: 2.656514888168663

Epoch: 5| Step: 9
Training loss: 3.0430614948272705
Validation loss: 2.6587681488324235

Epoch: 5| Step: 10
Training loss: 3.6183395385742188
Validation loss: 2.6584144869158344

Epoch: 62| Step: 0
Training loss: 2.29164457321167
Validation loss: 2.6549232108618623

Epoch: 5| Step: 1
Training loss: 1.9806249141693115
Validation loss: 2.654782302917973

Epoch: 5| Step: 2
Training loss: 3.0486044883728027
Validation loss: 2.6539323522198583

Epoch: 5| Step: 3
Training loss: 2.9247195720672607
Validation loss: 2.652433215930898

Epoch: 5| Step: 4
Training loss: 3.2691967487335205
Validation loss: 2.6545016381048385

Epoch: 5| Step: 5
Training loss: 2.973667621612549
Validation loss: 2.6552788852363505

Epoch: 5| Step: 6
Training loss: 3.2643039226531982
Validation loss: 2.6515871106937365

Epoch: 5| Step: 7
Training loss: 3.444549560546875
Validation loss: 2.659025881880073

Epoch: 5| Step: 8
Training loss: 2.5882468223571777
Validation loss: 2.662953917698194

Epoch: 5| Step: 9
Training loss: 2.6705117225646973
Validation loss: 2.6743321777671896

Epoch: 5| Step: 10
Training loss: 2.2712321281433105
Validation loss: 2.674610435321767

Epoch: 63| Step: 0
Training loss: 2.4788119792938232
Validation loss: 2.6728572076366794

Epoch: 5| Step: 1
Training loss: 2.9680590629577637
Validation loss: 2.662637408061694

Epoch: 5| Step: 2
Training loss: 2.7068569660186768
Validation loss: 2.6585811107389388

Epoch: 5| Step: 3
Training loss: 3.2395236492156982
Validation loss: 2.6529135498949277

Epoch: 5| Step: 4
Training loss: 2.782808542251587
Validation loss: 2.652364812871461

Epoch: 5| Step: 5
Training loss: 2.632695436477661
Validation loss: 2.6513064240896576

Epoch: 5| Step: 6
Training loss: 3.186532974243164
Validation loss: 2.651236717418958

Epoch: 5| Step: 7
Training loss: 2.1387906074523926
Validation loss: 2.647272297131118

Epoch: 5| Step: 8
Training loss: 2.65956449508667
Validation loss: 2.649611557683637

Epoch: 5| Step: 9
Training loss: 3.009807586669922
Validation loss: 2.652087826882639

Epoch: 5| Step: 10
Training loss: 2.9889304637908936
Validation loss: 2.647272543240619

Epoch: 64| Step: 0
Training loss: 3.6052823066711426
Validation loss: 2.646722193687193

Epoch: 5| Step: 1
Training loss: 3.1791937351226807
Validation loss: 2.6467870204679427

Epoch: 5| Step: 2
Training loss: 3.309035062789917
Validation loss: 2.6450788180033364

Epoch: 5| Step: 3
Training loss: 2.636758327484131
Validation loss: 2.64318246738885

Epoch: 5| Step: 4
Training loss: 2.424923896789551
Validation loss: 2.644345570636052

Epoch: 5| Step: 5
Training loss: 2.3674328327178955
Validation loss: 2.645244442006593

Epoch: 5| Step: 6
Training loss: 2.3549387454986572
Validation loss: 2.642988451065556

Epoch: 5| Step: 7
Training loss: 3.1200928688049316
Validation loss: 2.6492626692659114

Epoch: 5| Step: 8
Training loss: 2.318542003631592
Validation loss: 2.6512714124494985

Epoch: 5| Step: 9
Training loss: 2.716722011566162
Validation loss: 2.652640965677077

Epoch: 5| Step: 10
Training loss: 2.61173415184021
Validation loss: 2.656172376807018

Epoch: 65| Step: 0
Training loss: 2.506970167160034
Validation loss: 2.6524440396216606

Epoch: 5| Step: 1
Training loss: 3.5487427711486816
Validation loss: 2.651436164814939

Epoch: 5| Step: 2
Training loss: 3.0728304386138916
Validation loss: 2.6491773538692023

Epoch: 5| Step: 3
Training loss: 2.3007240295410156
Validation loss: 2.646466291078957

Epoch: 5| Step: 4
Training loss: 3.0769639015197754
Validation loss: 2.6408577657515004

Epoch: 5| Step: 5
Training loss: 2.430607318878174
Validation loss: 2.6392310332226496

Epoch: 5| Step: 6
Training loss: 2.3712172508239746
Validation loss: 2.6371556969099146

Epoch: 5| Step: 7
Training loss: 2.749237537384033
Validation loss: 2.6326015867212766

Epoch: 5| Step: 8
Training loss: 2.8794949054718018
Validation loss: 2.633094254360404

Epoch: 5| Step: 9
Training loss: 3.1378397941589355
Validation loss: 2.631389989647814

Epoch: 5| Step: 10
Training loss: 2.5065510272979736
Validation loss: 2.62975150282665

Epoch: 66| Step: 0
Training loss: 2.2731008529663086
Validation loss: 2.628764239690637

Epoch: 5| Step: 1
Training loss: 3.203995943069458
Validation loss: 2.628502368927002

Epoch: 5| Step: 2
Training loss: 2.065476179122925
Validation loss: 2.6286798010590258

Epoch: 5| Step: 3
Training loss: 3.1756248474121094
Validation loss: 2.632512900137132

Epoch: 5| Step: 4
Training loss: 2.5043578147888184
Validation loss: 2.6353725207749235

Epoch: 5| Step: 5
Training loss: 3.080280303955078
Validation loss: 2.6311015608490154

Epoch: 5| Step: 6
Training loss: 3.3147170543670654
Validation loss: 2.626496991803569

Epoch: 5| Step: 7
Training loss: 2.705958604812622
Validation loss: 2.626212094419746

Epoch: 5| Step: 8
Training loss: 2.4357516765594482
Validation loss: 2.626644290903563

Epoch: 5| Step: 9
Training loss: 3.048365831375122
Validation loss: 2.6265629542771207

Epoch: 5| Step: 10
Training loss: 2.7647039890289307
Validation loss: 2.628034294292491

Epoch: 67| Step: 0
Training loss: 2.8809239864349365
Validation loss: 2.6288098007120113

Epoch: 5| Step: 1
Training loss: 3.0301122665405273
Validation loss: 2.6295804105779177

Epoch: 5| Step: 2
Training loss: 2.32473087310791
Validation loss: 2.6284464713065856

Epoch: 5| Step: 3
Training loss: 3.0260465145111084
Validation loss: 2.625648280625702

Epoch: 5| Step: 4
Training loss: 2.5879733562469482
Validation loss: 2.625289519627889

Epoch: 5| Step: 5
Training loss: 3.1363182067871094
Validation loss: 2.6256080007040374

Epoch: 5| Step: 6
Training loss: 2.849069595336914
Validation loss: 2.6256737529590564

Epoch: 5| Step: 7
Training loss: 2.681692123413086
Validation loss: 2.622845434373425

Epoch: 5| Step: 8
Training loss: 2.694765329360962
Validation loss: 2.6230989963777605

Epoch: 5| Step: 9
Training loss: 2.8028597831726074
Validation loss: 2.624216943658808

Epoch: 5| Step: 10
Training loss: 2.5094494819641113
Validation loss: 2.6349547960424937

Epoch: 68| Step: 0
Training loss: 1.986819863319397
Validation loss: 2.6354373449920327

Epoch: 5| Step: 1
Training loss: 3.5016300678253174
Validation loss: 2.633826490371458

Epoch: 5| Step: 2
Training loss: 3.1079554557800293
Validation loss: 2.6319077784015286

Epoch: 5| Step: 3
Training loss: 2.5923123359680176
Validation loss: 2.6282098857305383

Epoch: 5| Step: 4
Training loss: 2.5533652305603027
Validation loss: 2.6228648770240044

Epoch: 5| Step: 5
Training loss: 2.1003665924072266
Validation loss: 2.62237762635754

Epoch: 5| Step: 6
Training loss: 2.9425783157348633
Validation loss: 2.6220263229903353

Epoch: 5| Step: 7
Training loss: 3.6748046875
Validation loss: 2.6176934652431036

Epoch: 5| Step: 8
Training loss: 3.2105350494384766
Validation loss: 2.617998451314947

Epoch: 5| Step: 9
Training loss: 2.4333412647247314
Validation loss: 2.6204487892889206

Epoch: 5| Step: 10
Training loss: 2.322317600250244
Validation loss: 2.622915701199603

Epoch: 69| Step: 0
Training loss: 3.1581053733825684
Validation loss: 2.6265756084072973

Epoch: 5| Step: 1
Training loss: 3.389719009399414
Validation loss: 2.637816398374496

Epoch: 5| Step: 2
Training loss: 3.0908520221710205
Validation loss: 2.6462949578480055

Epoch: 5| Step: 3
Training loss: 3.301612138748169
Validation loss: 2.650041805800571

Epoch: 5| Step: 4
Training loss: 2.9323599338531494
Validation loss: 2.640551608095887

Epoch: 5| Step: 5
Training loss: 2.462825298309326
Validation loss: 2.6314311053163264

Epoch: 5| Step: 6
Training loss: 2.1155998706817627
Validation loss: 2.619171573269752

Epoch: 5| Step: 7
Training loss: 2.610504388809204
Validation loss: 2.616282142618651

Epoch: 5| Step: 8
Training loss: 3.0388944149017334
Validation loss: 2.6144156737994124

Epoch: 5| Step: 9
Training loss: 2.397693157196045
Validation loss: 2.619068912280503

Epoch: 5| Step: 10
Training loss: 1.9715659618377686
Validation loss: 2.6192388124363397

Epoch: 70| Step: 0
Training loss: 2.2930524349212646
Validation loss: 2.626920994891915

Epoch: 5| Step: 1
Training loss: 2.535304307937622
Validation loss: 2.6381138037609797

Epoch: 5| Step: 2
Training loss: 3.264516830444336
Validation loss: 2.6424319103199947

Epoch: 5| Step: 3
Training loss: 2.9449400901794434
Validation loss: 2.651376091023927

Epoch: 5| Step: 4
Training loss: 2.6493682861328125
Validation loss: 2.655792869547362

Epoch: 5| Step: 5
Training loss: 2.7325382232666016
Validation loss: 2.6444221927273657

Epoch: 5| Step: 6
Training loss: 2.8869805335998535
Validation loss: 2.629189145180487

Epoch: 5| Step: 7
Training loss: 2.489531993865967
Validation loss: 2.622473418071706

Epoch: 5| Step: 8
Training loss: 3.179743766784668
Validation loss: 2.615686926790463

Epoch: 5| Step: 9
Training loss: 2.8662705421447754
Validation loss: 2.607351505628196

Epoch: 5| Step: 10
Training loss: 2.712578296661377
Validation loss: 2.6111105744556715

Epoch: 71| Step: 0
Training loss: 2.3101487159729004
Validation loss: 2.611728806649485

Epoch: 5| Step: 1
Training loss: 2.6502914428710938
Validation loss: 2.6124640792928715

Epoch: 5| Step: 2
Training loss: 2.5983502864837646
Validation loss: 2.610158001222918

Epoch: 5| Step: 3
Training loss: 2.215395212173462
Validation loss: 2.6097889587443364

Epoch: 5| Step: 4
Training loss: 2.4022233486175537
Validation loss: 2.608022500109929

Epoch: 5| Step: 5
Training loss: 3.5107429027557373
Validation loss: 2.6079054801694808

Epoch: 5| Step: 6
Training loss: 3.239943265914917
Validation loss: 2.607953748395366

Epoch: 5| Step: 7
Training loss: 2.671363115310669
Validation loss: 2.6068796073236773

Epoch: 5| Step: 8
Training loss: 2.8451874256134033
Validation loss: 2.605655682984219

Epoch: 5| Step: 9
Training loss: 2.5321695804595947
Validation loss: 2.6033968489657164

Epoch: 5| Step: 10
Training loss: 3.6098155975341797
Validation loss: 2.6035276689837055

Epoch: 72| Step: 0
Training loss: 2.821709156036377
Validation loss: 2.6041891959405716

Epoch: 5| Step: 1
Training loss: 2.6723504066467285
Validation loss: 2.6028632169128745

Epoch: 5| Step: 2
Training loss: 2.7172417640686035
Validation loss: 2.604206649206018

Epoch: 5| Step: 3
Training loss: 3.349902391433716
Validation loss: 2.599353144245763

Epoch: 5| Step: 4
Training loss: 3.0812978744506836
Validation loss: 2.5998586044516614

Epoch: 5| Step: 5
Training loss: 2.785402297973633
Validation loss: 2.601190108124928

Epoch: 5| Step: 6
Training loss: 2.9350521564483643
Validation loss: 2.6012243737456617

Epoch: 5| Step: 7
Training loss: 2.482788562774658
Validation loss: 2.602753919939841

Epoch: 5| Step: 8
Training loss: 2.863290309906006
Validation loss: 2.60518055833796

Epoch: 5| Step: 9
Training loss: 2.254298686981201
Validation loss: 2.604270763294671

Epoch: 5| Step: 10
Training loss: 2.3305392265319824
Validation loss: 2.601985862178187

Epoch: 73| Step: 0
Training loss: 2.8857650756835938
Validation loss: 2.603509262043943

Epoch: 5| Step: 1
Training loss: 2.780186891555786
Validation loss: 2.60079433584726

Epoch: 5| Step: 2
Training loss: 3.060520648956299
Validation loss: 2.6005921761194863

Epoch: 5| Step: 3
Training loss: 2.1435742378234863
Validation loss: 2.5998848535681285

Epoch: 5| Step: 4
Training loss: 2.21773362159729
Validation loss: 2.6005505438773864

Epoch: 5| Step: 5
Training loss: 2.8109779357910156
Validation loss: 2.6005955614069456

Epoch: 5| Step: 6
Training loss: 3.045685291290283
Validation loss: 2.601858654329854

Epoch: 5| Step: 7
Training loss: 2.530485153198242
Validation loss: 2.596045814534669

Epoch: 5| Step: 8
Training loss: 2.9981367588043213
Validation loss: 2.5967089283850884

Epoch: 5| Step: 9
Training loss: 2.844210147857666
Validation loss: 2.5981953374801146

Epoch: 5| Step: 10
Training loss: 3.0847339630126953
Validation loss: 2.5957516521535893

Epoch: 74| Step: 0
Training loss: 2.6114113330841064
Validation loss: 2.593433472418016

Epoch: 5| Step: 1
Training loss: 2.602344274520874
Validation loss: 2.595840520756219

Epoch: 5| Step: 2
Training loss: 3.147291660308838
Validation loss: 2.5916638015418925

Epoch: 5| Step: 3
Training loss: 2.4550673961639404
Validation loss: 2.59491761525472

Epoch: 5| Step: 4
Training loss: 2.657728433609009
Validation loss: 2.5938515560601347

Epoch: 5| Step: 5
Training loss: 2.387403964996338
Validation loss: 2.59650908747027

Epoch: 5| Step: 6
Training loss: 2.4758238792419434
Validation loss: 2.596692708230788

Epoch: 5| Step: 7
Training loss: 2.558251142501831
Validation loss: 2.5963730094253377

Epoch: 5| Step: 8
Training loss: 3.052128314971924
Validation loss: 2.591350414419687

Epoch: 5| Step: 9
Training loss: 2.7269463539123535
Validation loss: 2.5919969927880073

Epoch: 5| Step: 10
Training loss: 3.768251419067383
Validation loss: 2.593550287267213

Epoch: 75| Step: 0
Training loss: 2.536652088165283
Validation loss: 2.5938012343581005

Epoch: 5| Step: 1
Training loss: 2.7338860034942627
Validation loss: 2.5897359463476364

Epoch: 5| Step: 2
Training loss: 2.60210919380188
Validation loss: 2.5905631921624623

Epoch: 5| Step: 3
Training loss: 2.6951775550842285
Validation loss: 2.5907125088476364

Epoch: 5| Step: 4
Training loss: 2.9899590015411377
Validation loss: 2.5906832512988838

Epoch: 5| Step: 5
Training loss: 3.0171589851379395
Validation loss: 2.589710917524112

Epoch: 5| Step: 6
Training loss: 3.3970913887023926
Validation loss: 2.5900062745617283

Epoch: 5| Step: 7
Training loss: 1.8266178369522095
Validation loss: 2.589710117668234

Epoch: 5| Step: 8
Training loss: 3.1334328651428223
Validation loss: 2.5898224358917563

Epoch: 5| Step: 9
Training loss: 2.74550724029541
Validation loss: 2.589923797115203

Epoch: 5| Step: 10
Training loss: 2.547942876815796
Validation loss: 2.5881177558693835

Epoch: 76| Step: 0
Training loss: 2.9290452003479004
Validation loss: 2.587529774635069

Epoch: 5| Step: 1
Training loss: 2.8961596488952637
Validation loss: 2.5914310075903453

Epoch: 5| Step: 2
Training loss: 2.5825181007385254
Validation loss: 2.589882222555017

Epoch: 5| Step: 3
Training loss: 2.6841201782226562
Validation loss: 2.5888283175806843

Epoch: 5| Step: 4
Training loss: 3.0589659214019775
Validation loss: 2.5956912912348264

Epoch: 5| Step: 5
Training loss: 2.0683581829071045
Validation loss: 2.5956839643498903

Epoch: 5| Step: 6
Training loss: 2.6601738929748535
Validation loss: 2.591510679132195

Epoch: 5| Step: 7
Training loss: 2.451096773147583
Validation loss: 2.586482604344686

Epoch: 5| Step: 8
Training loss: 3.377741575241089
Validation loss: 2.5862335261478218

Epoch: 5| Step: 9
Training loss: 3.113828182220459
Validation loss: 2.5839046509035173

Epoch: 5| Step: 10
Training loss: 2.336761713027954
Validation loss: 2.5843744944500666

Epoch: 77| Step: 0
Training loss: 2.723479986190796
Validation loss: 2.5824188673368065

Epoch: 5| Step: 1
Training loss: 2.4985382556915283
Validation loss: 2.582970990929552

Epoch: 5| Step: 2
Training loss: 3.209077835083008
Validation loss: 2.5823697736186366

Epoch: 5| Step: 3
Training loss: 2.611393451690674
Validation loss: 2.587218394843481

Epoch: 5| Step: 4
Training loss: 2.7543978691101074
Validation loss: 2.5930277891056512

Epoch: 5| Step: 5
Training loss: 2.987206220626831
Validation loss: 2.5912622482545915

Epoch: 5| Step: 6
Training loss: 2.4831175804138184
Validation loss: 2.5897180470087195

Epoch: 5| Step: 7
Training loss: 3.479283094406128
Validation loss: 2.5950470893613753

Epoch: 5| Step: 8
Training loss: 2.7486350536346436
Validation loss: 2.593950187006304

Epoch: 5| Step: 9
Training loss: 2.476804733276367
Validation loss: 2.584894303352602

Epoch: 5| Step: 10
Training loss: 2.1754281520843506
Validation loss: 2.582066846150224

Epoch: 78| Step: 0
Training loss: 2.3241145610809326
Validation loss: 2.577245884044196

Epoch: 5| Step: 1
Training loss: 2.9694743156433105
Validation loss: 2.5804880998467885

Epoch: 5| Step: 2
Training loss: 3.543217182159424
Validation loss: 2.578727117148779

Epoch: 5| Step: 3
Training loss: 2.769559860229492
Validation loss: 2.5811112542306223

Epoch: 5| Step: 4
Training loss: 2.9115891456604004
Validation loss: 2.5825458111301547

Epoch: 5| Step: 5
Training loss: 2.291651487350464
Validation loss: 2.5828536787340717

Epoch: 5| Step: 6
Training loss: 2.7774300575256348
Validation loss: 2.5805327430848153

Epoch: 5| Step: 7
Training loss: 1.928727388381958
Validation loss: 2.5775541233760055

Epoch: 5| Step: 8
Training loss: 3.2759697437286377
Validation loss: 2.5773842129656064

Epoch: 5| Step: 9
Training loss: 2.8099682331085205
Validation loss: 2.57719870152012

Epoch: 5| Step: 10
Training loss: 2.5832879543304443
Validation loss: 2.5776647380603257

Epoch: 79| Step: 0
Training loss: 3.4859230518341064
Validation loss: 2.5848167942416285

Epoch: 5| Step: 1
Training loss: 3.91227388381958
Validation loss: 2.587087574825492

Epoch: 5| Step: 2
Training loss: 2.888838291168213
Validation loss: 2.5954736535267164

Epoch: 5| Step: 3
Training loss: 3.202332019805908
Validation loss: 2.6053965091705322

Epoch: 5| Step: 4
Training loss: 1.9332252740859985
Validation loss: 2.6033623577446066

Epoch: 5| Step: 5
Training loss: 2.9624691009521484
Validation loss: 2.5934535047059417

Epoch: 5| Step: 6
Training loss: 3.0820765495300293
Validation loss: 2.586316380449521

Epoch: 5| Step: 7
Training loss: 2.129002809524536
Validation loss: 2.576248748328096

Epoch: 5| Step: 8
Training loss: 2.056443452835083
Validation loss: 2.5732590588190223

Epoch: 5| Step: 9
Training loss: 1.9675438404083252
Validation loss: 2.573842438318396

Epoch: 5| Step: 10
Training loss: 2.542426347732544
Validation loss: 2.5738528313175326

Epoch: 80| Step: 0
Training loss: 1.8874400854110718
Validation loss: 2.5763581234921693

Epoch: 5| Step: 1
Training loss: 2.481337547302246
Validation loss: 2.5831052564805552

Epoch: 5| Step: 2
Training loss: 2.888399839401245
Validation loss: 2.579426473186862

Epoch: 5| Step: 3
Training loss: 2.452529191970825
Validation loss: 2.5795181284668627

Epoch: 5| Step: 4
Training loss: 3.1234560012817383
Validation loss: 2.575504408087782

Epoch: 5| Step: 5
Training loss: 2.948378801345825
Validation loss: 2.5746797900046072

Epoch: 5| Step: 6
Training loss: 2.6954410076141357
Validation loss: 2.5716296677948325

Epoch: 5| Step: 7
Training loss: 2.6296322345733643
Validation loss: 2.5686991009660947

Epoch: 5| Step: 8
Training loss: 2.7186310291290283
Validation loss: 2.5747900137337307

Epoch: 5| Step: 9
Training loss: 3.1700425148010254
Validation loss: 2.5736049554681264

Epoch: 5| Step: 10
Training loss: 3.235459327697754
Validation loss: 2.575518754220778

Epoch: 81| Step: 0
Training loss: 2.33974289894104
Validation loss: 2.576738429325883

Epoch: 5| Step: 1
Training loss: 2.8201231956481934
Validation loss: 2.5739695769484325

Epoch: 5| Step: 2
Training loss: 2.2197937965393066
Validation loss: 2.5736535569672943

Epoch: 5| Step: 3
Training loss: 2.2648253440856934
Validation loss: 2.5712960343207083

Epoch: 5| Step: 4
Training loss: 3.058800458908081
Validation loss: 2.5684932470321655

Epoch: 5| Step: 5
Training loss: 3.0090956687927246
Validation loss: 2.567530116727275

Epoch: 5| Step: 6
Training loss: 2.4018683433532715
Validation loss: 2.565695778016121

Epoch: 5| Step: 7
Training loss: 2.569664478302002
Validation loss: 2.568324030086558

Epoch: 5| Step: 8
Training loss: 3.734118700027466
Validation loss: 2.565556723584411

Epoch: 5| Step: 9
Training loss: 2.7740254402160645
Validation loss: 2.5640202927333053

Epoch: 5| Step: 10
Training loss: 2.9042065143585205
Validation loss: 2.5650021081329673

Epoch: 82| Step: 0
Training loss: 2.6466097831726074
Validation loss: 2.562988591450517

Epoch: 5| Step: 1
Training loss: 3.103006362915039
Validation loss: 2.565658284771827

Epoch: 5| Step: 2
Training loss: 3.108976125717163
Validation loss: 2.564905967763675

Epoch: 5| Step: 3
Training loss: 3.035417318344116
Validation loss: 2.567693325781053

Epoch: 5| Step: 4
Training loss: 2.8952324390411377
Validation loss: 2.5654283902978383

Epoch: 5| Step: 5
Training loss: 2.4110324382781982
Validation loss: 2.567031113050317

Epoch: 5| Step: 6
Training loss: 3.0961718559265137
Validation loss: 2.5651970063486407

Epoch: 5| Step: 7
Training loss: 2.508812665939331
Validation loss: 2.5609952326743834

Epoch: 5| Step: 8
Training loss: 2.3905909061431885
Validation loss: 2.5615517016380065

Epoch: 5| Step: 9
Training loss: 2.3820810317993164
Validation loss: 2.5641691966723372

Epoch: 5| Step: 10
Training loss: 2.4134652614593506
Validation loss: 2.56604645200955

Epoch: 83| Step: 0
Training loss: 3.408548355102539
Validation loss: 2.560744459911059

Epoch: 5| Step: 1
Training loss: 2.6985435485839844
Validation loss: 2.5581583284562632

Epoch: 5| Step: 2
Training loss: 2.4633827209472656
Validation loss: 2.5593990895055954

Epoch: 5| Step: 3
Training loss: 2.9474148750305176
Validation loss: 2.557583870426301

Epoch: 5| Step: 4
Training loss: 3.45043683052063
Validation loss: 2.55737748453694

Epoch: 5| Step: 5
Training loss: 2.278817653656006
Validation loss: 2.5570143345863587

Epoch: 5| Step: 6
Training loss: 2.0894083976745605
Validation loss: 2.55777931469743

Epoch: 5| Step: 7
Training loss: 2.8766353130340576
Validation loss: 2.5564233410742974

Epoch: 5| Step: 8
Training loss: 1.9850050210952759
Validation loss: 2.557380668578609

Epoch: 5| Step: 9
Training loss: 3.3272476196289062
Validation loss: 2.557268135009273

Epoch: 5| Step: 10
Training loss: 2.424907684326172
Validation loss: 2.557790602407148

Epoch: 84| Step: 0
Training loss: 2.9045140743255615
Validation loss: 2.5581507734073106

Epoch: 5| Step: 1
Training loss: 2.3783411979675293
Validation loss: 2.562474855812647

Epoch: 5| Step: 2
Training loss: 2.2394087314605713
Validation loss: 2.5653009747946136

Epoch: 5| Step: 3
Training loss: 2.873898983001709
Validation loss: 2.5639736190918954

Epoch: 5| Step: 4
Training loss: 2.8339991569519043
Validation loss: 2.5675965380925003

Epoch: 5| Step: 5
Training loss: 2.7088780403137207
Validation loss: 2.57476221746014

Epoch: 5| Step: 6
Training loss: 2.6963772773742676
Validation loss: 2.570543912149245

Epoch: 5| Step: 7
Training loss: 3.082289695739746
Validation loss: 2.5601302731421685

Epoch: 5| Step: 8
Training loss: 2.8302009105682373
Validation loss: 2.5556930008754937

Epoch: 5| Step: 9
Training loss: 2.331167221069336
Validation loss: 2.554429033751129

Epoch: 5| Step: 10
Training loss: 3.2264416217803955
Validation loss: 2.5596238490073913

Epoch: 85| Step: 0
Training loss: 3.2150440216064453
Validation loss: 2.553962770328727

Epoch: 5| Step: 1
Training loss: 1.9837137460708618
Validation loss: 2.5540930609549246

Epoch: 5| Step: 2
Training loss: 3.2295849323272705
Validation loss: 2.556562513433477

Epoch: 5| Step: 3
Training loss: 2.3582921028137207
Validation loss: 2.5566098638760146

Epoch: 5| Step: 4
Training loss: 3.2084178924560547
Validation loss: 2.5493892931169078

Epoch: 5| Step: 5
Training loss: 3.182626485824585
Validation loss: 2.5529836403426303

Epoch: 5| Step: 6
Training loss: 2.704982280731201
Validation loss: 2.553925191202471

Epoch: 5| Step: 7
Training loss: 2.436047077178955
Validation loss: 2.552461003744474

Epoch: 5| Step: 8
Training loss: 2.568189859390259
Validation loss: 2.5536275909792994

Epoch: 5| Step: 9
Training loss: 2.2223258018493652
Validation loss: 2.5534213768538607

Epoch: 5| Step: 10
Training loss: 2.877732276916504
Validation loss: 2.553463658978862

Epoch: 86| Step: 0
Training loss: 2.3232216835021973
Validation loss: 2.551354036536268

Epoch: 5| Step: 1
Training loss: 2.555809736251831
Validation loss: 2.5586371626905215

Epoch: 5| Step: 2
Training loss: 3.2099838256835938
Validation loss: 2.559369771711288

Epoch: 5| Step: 3
Training loss: 2.2942748069763184
Validation loss: 2.5662646293640137

Epoch: 5| Step: 4
Training loss: 2.160335063934326
Validation loss: 2.5681746262376026

Epoch: 5| Step: 5
Training loss: 2.6104283332824707
Validation loss: 2.575361769686463

Epoch: 5| Step: 6
Training loss: 3.5384278297424316
Validation loss: 2.562060950904764

Epoch: 5| Step: 7
Training loss: 3.2408173084259033
Validation loss: 2.5539442364887526

Epoch: 5| Step: 8
Training loss: 2.6280829906463623
Validation loss: 2.545105275287423

Epoch: 5| Step: 9
Training loss: 2.38995361328125
Validation loss: 2.5431440440557336

Epoch: 5| Step: 10
Training loss: 3.0967907905578613
Validation loss: 2.5456038777546217

Epoch: 87| Step: 0
Training loss: 2.9769415855407715
Validation loss: 2.5445304942387406

Epoch: 5| Step: 1
Training loss: 2.380265951156616
Validation loss: 2.5455031138594433

Epoch: 5| Step: 2
Training loss: 3.706529140472412
Validation loss: 2.5448965872487714

Epoch: 5| Step: 3
Training loss: 2.635911226272583
Validation loss: 2.5447379901844966

Epoch: 5| Step: 4
Training loss: 2.6380362510681152
Validation loss: 2.5439901403201524

Epoch: 5| Step: 5
Training loss: 2.3902406692504883
Validation loss: 2.548625256425591

Epoch: 5| Step: 6
Training loss: 2.24385404586792
Validation loss: 2.545966050958121

Epoch: 5| Step: 7
Training loss: 2.629049062728882
Validation loss: 2.5535776102414696

Epoch: 5| Step: 8
Training loss: 2.8727478981018066
Validation loss: 2.5534470465875443

Epoch: 5| Step: 9
Training loss: 2.309521436691284
Validation loss: 2.5462888863778885

Epoch: 5| Step: 10
Training loss: 3.2134602069854736
Validation loss: 2.545949234757372

Epoch: 88| Step: 0
Training loss: 3.2593491077423096
Validation loss: 2.5470707698534896

Epoch: 5| Step: 1
Training loss: 2.5305206775665283
Validation loss: 2.559572635158416

Epoch: 5| Step: 2
Training loss: 2.25567364692688
Validation loss: 2.5688543627339024

Epoch: 5| Step: 3
Training loss: 3.4203219413757324
Validation loss: 2.5834219019900084

Epoch: 5| Step: 4
Training loss: 2.399341344833374
Validation loss: 2.580799384783673

Epoch: 5| Step: 5
Training loss: 2.5456857681274414
Validation loss: 2.5803830290353424

Epoch: 5| Step: 6
Training loss: 2.3885836601257324
Validation loss: 2.5509992235450336

Epoch: 5| Step: 7
Training loss: 2.2669079303741455
Validation loss: 2.5401221090747463

Epoch: 5| Step: 8
Training loss: 2.6437339782714844
Validation loss: 2.5349907593060563

Epoch: 5| Step: 9
Training loss: 3.1803677082061768
Validation loss: 2.5407461350963962

Epoch: 5| Step: 10
Training loss: 3.1493842601776123
Validation loss: 2.5479788472575526

Epoch: 89| Step: 0
Training loss: 2.954862594604492
Validation loss: 2.5536144856483705

Epoch: 5| Step: 1
Training loss: 3.126059055328369
Validation loss: 2.5579043331966607

Epoch: 5| Step: 2
Training loss: 2.328827381134033
Validation loss: 2.562415515222857

Epoch: 5| Step: 3
Training loss: 2.520580768585205
Validation loss: 2.5605829608055855

Epoch: 5| Step: 4
Training loss: 3.2653822898864746
Validation loss: 2.566033045450846

Epoch: 5| Step: 5
Training loss: 2.9569709300994873
Validation loss: 2.5514205604471187

Epoch: 5| Step: 6
Training loss: 2.379490375518799
Validation loss: 2.5431195330876175

Epoch: 5| Step: 7
Training loss: 2.6645145416259766
Validation loss: 2.5351865394141084

Epoch: 5| Step: 8
Training loss: 2.845604658126831
Validation loss: 2.533980195240308

Epoch: 5| Step: 9
Training loss: 2.515657901763916
Validation loss: 2.5328483684088594

Epoch: 5| Step: 10
Training loss: 2.272942543029785
Validation loss: 2.536897997702322

Epoch: 90| Step: 0
Training loss: 3.3991189002990723
Validation loss: 2.5322045228814565

Epoch: 5| Step: 1
Training loss: 2.9125709533691406
Validation loss: 2.5315168852447183

Epoch: 5| Step: 2
Training loss: 2.3575565814971924
Validation loss: 2.533566923551662

Epoch: 5| Step: 3
Training loss: 1.8116328716278076
Validation loss: 2.5325988236294

Epoch: 5| Step: 4
Training loss: 3.2685253620147705
Validation loss: 2.5345122685996433

Epoch: 5| Step: 5
Training loss: 2.9751574993133545
Validation loss: 2.5316576752611386

Epoch: 5| Step: 6
Training loss: 3.17488431930542
Validation loss: 2.531956245822291

Epoch: 5| Step: 7
Training loss: 2.355252504348755
Validation loss: 2.5306285094189387

Epoch: 5| Step: 8
Training loss: 1.856022834777832
Validation loss: 2.530110487373926

Epoch: 5| Step: 9
Training loss: 2.883026599884033
Validation loss: 2.5307064697306645

Epoch: 5| Step: 10
Training loss: 2.8910536766052246
Validation loss: 2.5349810238807433

Epoch: 91| Step: 0
Training loss: 3.36077618598938
Validation loss: 2.5378729297268774

Epoch: 5| Step: 1
Training loss: 1.7696815729141235
Validation loss: 2.5413411612151773

Epoch: 5| Step: 2
Training loss: 2.7776687145233154
Validation loss: 2.539679111972932

Epoch: 5| Step: 3
Training loss: 2.5269241333007812
Validation loss: 2.537768615189419

Epoch: 5| Step: 4
Training loss: 2.4541568756103516
Validation loss: 2.532845389458441

Epoch: 5| Step: 5
Training loss: 2.461296558380127
Validation loss: 2.539502097714332

Epoch: 5| Step: 6
Training loss: 3.3135833740234375
Validation loss: 2.540085146504064

Epoch: 5| Step: 7
Training loss: 2.6948342323303223
Validation loss: 2.5361511245850594

Epoch: 5| Step: 8
Training loss: 2.535562515258789
Validation loss: 2.5341718222505305

Epoch: 5| Step: 9
Training loss: 2.860077142715454
Validation loss: 2.529780928806592

Epoch: 5| Step: 10
Training loss: 3.1319925785064697
Validation loss: 2.529082957134452

Epoch: 92| Step: 0
Training loss: 2.636383533477783
Validation loss: 2.526485994297971

Epoch: 5| Step: 1
Training loss: 2.3625998497009277
Validation loss: 2.52900694775325

Epoch: 5| Step: 2
Training loss: 3.3781940937042236
Validation loss: 2.5262681591895317

Epoch: 5| Step: 3
Training loss: 2.8904261589050293
Validation loss: 2.527475892856557

Epoch: 5| Step: 4
Training loss: 2.4747567176818848
Validation loss: 2.526835733844388

Epoch: 5| Step: 5
Training loss: 2.918320655822754
Validation loss: 2.526581629630058

Epoch: 5| Step: 6
Training loss: 2.8803212642669678
Validation loss: 2.525900133194462

Epoch: 5| Step: 7
Training loss: 2.8468246459960938
Validation loss: 2.5259410360808014

Epoch: 5| Step: 8
Training loss: 2.1115880012512207
Validation loss: 2.5237359692973476

Epoch: 5| Step: 9
Training loss: 2.12349271774292
Validation loss: 2.526615147949547

Epoch: 5| Step: 10
Training loss: 3.231768846511841
Validation loss: 2.5258072960761284

Epoch: 93| Step: 0
Training loss: 3.2868618965148926
Validation loss: 2.527627985964539

Epoch: 5| Step: 1
Training loss: 2.264791965484619
Validation loss: 2.5332046760025846

Epoch: 5| Step: 2
Training loss: 3.0547709465026855
Validation loss: 2.538853781197661

Epoch: 5| Step: 3
Training loss: 2.4736337661743164
Validation loss: 2.537278631682037

Epoch: 5| Step: 4
Training loss: 2.371108293533325
Validation loss: 2.5362934348403767

Epoch: 5| Step: 5
Training loss: 2.4234580993652344
Validation loss: 2.5296701718402166

Epoch: 5| Step: 6
Training loss: 2.588557720184326
Validation loss: 2.5225111797291744

Epoch: 5| Step: 7
Training loss: 2.374689817428589
Validation loss: 2.5195072466327297

Epoch: 5| Step: 8
Training loss: 3.1892619132995605
Validation loss: 2.521903884026312

Epoch: 5| Step: 9
Training loss: 2.98209547996521
Validation loss: 2.519096223256921

Epoch: 5| Step: 10
Training loss: 2.8163390159606934
Validation loss: 2.5210116063394854

Epoch: 94| Step: 0
Training loss: 2.74485182762146
Validation loss: 2.520522597015545

Epoch: 5| Step: 1
Training loss: 2.623291492462158
Validation loss: 2.5225069112675165

Epoch: 5| Step: 2
Training loss: 2.2386841773986816
Validation loss: 2.5241346256707304

Epoch: 5| Step: 3
Training loss: 2.945457935333252
Validation loss: 2.529467898030435

Epoch: 5| Step: 4
Training loss: 2.283590078353882
Validation loss: 2.53302957934718

Epoch: 5| Step: 5
Training loss: 3.245743989944458
Validation loss: 2.5287095641577118

Epoch: 5| Step: 6
Training loss: 3.4105563163757324
Validation loss: 2.5262392772141324

Epoch: 5| Step: 7
Training loss: 2.9227302074432373
Validation loss: 2.524622796684183

Epoch: 5| Step: 8
Training loss: 2.320730447769165
Validation loss: 2.5184701386318413

Epoch: 5| Step: 9
Training loss: 2.7597837448120117
Validation loss: 2.5087162051149594

Epoch: 5| Step: 10
Training loss: 2.1579177379608154
Validation loss: 2.505773667366274

Epoch: 95| Step: 0
Training loss: 2.353440761566162
Validation loss: 2.503095572994601

Epoch: 5| Step: 1
Training loss: 2.827195167541504
Validation loss: 2.5060282996905747

Epoch: 5| Step: 2
Training loss: 2.5765318870544434
Validation loss: 2.51085986116881

Epoch: 5| Step: 3
Training loss: 2.760756015777588
Validation loss: 2.509260868513456

Epoch: 5| Step: 4
Training loss: 2.787281036376953
Validation loss: 2.5091907593511764

Epoch: 5| Step: 5
Training loss: 2.576857089996338
Validation loss: 2.506329590274442

Epoch: 5| Step: 6
Training loss: 3.0252583026885986
Validation loss: 2.502465560872068

Epoch: 5| Step: 7
Training loss: 2.8241264820098877
Validation loss: 2.5071029611813125

Epoch: 5| Step: 8
Training loss: 2.5657050609588623
Validation loss: 2.5081185499827066

Epoch: 5| Step: 9
Training loss: 2.8906750679016113
Validation loss: 2.509537363565096

Epoch: 5| Step: 10
Training loss: 2.4357738494873047
Validation loss: 2.509635045964231

Epoch: 96| Step: 0
Training loss: 3.286205768585205
Validation loss: 2.512181935771819

Epoch: 5| Step: 1
Training loss: 2.375492572784424
Validation loss: 2.5103965574695217

Epoch: 5| Step: 2
Training loss: 2.8621537685394287
Validation loss: 2.510394109192715

Epoch: 5| Step: 3
Training loss: 2.023465156555176
Validation loss: 2.5184811007591987

Epoch: 5| Step: 4
Training loss: 2.722533702850342
Validation loss: 2.525176030333324

Epoch: 5| Step: 5
Training loss: 2.648040771484375
Validation loss: 2.521252562922816

Epoch: 5| Step: 6
Training loss: 2.5827410221099854
Validation loss: 2.5097821297184115

Epoch: 5| Step: 7
Training loss: 2.497246265411377
Validation loss: 2.505354542886057

Epoch: 5| Step: 8
Training loss: 3.065887928009033
Validation loss: 2.50474149950089

Epoch: 5| Step: 9
Training loss: 2.804823160171509
Validation loss: 2.503134609550558

Epoch: 5| Step: 10
Training loss: 2.7421348094940186
Validation loss: 2.5057124040460073

Epoch: 97| Step: 0
Training loss: 2.6919448375701904
Validation loss: 2.504533916391352

Epoch: 5| Step: 1
Training loss: 2.3030285835266113
Validation loss: 2.5043607168300177

Epoch: 5| Step: 2
Training loss: 2.7979578971862793
Validation loss: 2.4985233045393422

Epoch: 5| Step: 3
Training loss: 2.517324447631836
Validation loss: 2.499758143578806

Epoch: 5| Step: 4
Training loss: 2.2958431243896484
Validation loss: 2.498698034594136

Epoch: 5| Step: 5
Training loss: 2.843965530395508
Validation loss: 2.495486961897983

Epoch: 5| Step: 6
Training loss: 2.4972386360168457
Validation loss: 2.497495848645446

Epoch: 5| Step: 7
Training loss: 3.0560593605041504
Validation loss: 2.4992362478727936

Epoch: 5| Step: 8
Training loss: 3.0116095542907715
Validation loss: 2.5009339599199194

Epoch: 5| Step: 9
Training loss: 2.4715824127197266
Validation loss: 2.5062904383546565

Epoch: 5| Step: 10
Training loss: 3.1606926918029785
Validation loss: 2.505001908989363

Epoch: 98| Step: 0
Training loss: 1.699467420578003
Validation loss: 2.5076279486379316

Epoch: 5| Step: 1
Training loss: 2.1116480827331543
Validation loss: 2.507165506321897

Epoch: 5| Step: 2
Training loss: 2.8350179195404053
Validation loss: 2.516325686567573

Epoch: 5| Step: 3
Training loss: 2.928992748260498
Validation loss: 2.516851555916571

Epoch: 5| Step: 4
Training loss: 2.5054144859313965
Validation loss: 2.5142343018644597

Epoch: 5| Step: 5
Training loss: 2.556774616241455
Validation loss: 2.5050954818725586

Epoch: 5| Step: 6
Training loss: 2.857834815979004
Validation loss: 2.4942134734122985

Epoch: 5| Step: 7
Training loss: 2.9996116161346436
Validation loss: 2.491296399024225

Epoch: 5| Step: 8
Training loss: 3.282325029373169
Validation loss: 2.493617962765437

Epoch: 5| Step: 9
Training loss: 2.816922664642334
Validation loss: 2.496755487175398

Epoch: 5| Step: 10
Training loss: 3.129922866821289
Validation loss: 2.4999148345762685

Epoch: 99| Step: 0
Training loss: 2.7868218421936035
Validation loss: 2.496521919004379

Epoch: 5| Step: 1
Training loss: 3.291527509689331
Validation loss: 2.493637986080621

Epoch: 5| Step: 2
Training loss: 2.9840545654296875
Validation loss: 2.4964119952212096

Epoch: 5| Step: 3
Training loss: 2.18753981590271
Validation loss: 2.495009711993638

Epoch: 5| Step: 4
Training loss: 2.7824645042419434
Validation loss: 2.4935960397925427

Epoch: 5| Step: 5
Training loss: 2.193854808807373
Validation loss: 2.490997609271798

Epoch: 5| Step: 6
Training loss: 2.790159225463867
Validation loss: 2.492717425028483

Epoch: 5| Step: 7
Training loss: 2.4389896392822266
Validation loss: 2.4964763220920356

Epoch: 5| Step: 8
Training loss: 2.5104446411132812
Validation loss: 2.5147886224972305

Epoch: 5| Step: 9
Training loss: 2.8174664974212646
Validation loss: 2.523760793029621

Epoch: 5| Step: 10
Training loss: 2.839367151260376
Validation loss: 2.5171079430528867

Epoch: 100| Step: 0
Training loss: 2.965120792388916
Validation loss: 2.5104539214923816

Epoch: 5| Step: 1
Training loss: 2.0444226264953613
Validation loss: 2.5063935325991724

Epoch: 5| Step: 2
Training loss: 2.6079931259155273
Validation loss: 2.5034818469837146

Epoch: 5| Step: 3
Training loss: 2.3664824962615967
Validation loss: 2.492857627971198

Epoch: 5| Step: 4
Training loss: 3.1107239723205566
Validation loss: 2.494519067066972

Epoch: 5| Step: 5
Training loss: 3.0214173793792725
Validation loss: 2.489577272886871

Epoch: 5| Step: 6
Training loss: 2.1009905338287354
Validation loss: 2.492582126330304

Epoch: 5| Step: 7
Training loss: 2.0103187561035156
Validation loss: 2.490270588987617

Epoch: 5| Step: 8
Training loss: 3.340832233428955
Validation loss: 2.492710913381269

Epoch: 5| Step: 9
Training loss: 2.6615872383117676
Validation loss: 2.487873882375738

Epoch: 5| Step: 10
Training loss: 3.3600194454193115
Validation loss: 2.488989835144371

Epoch: 101| Step: 0
Training loss: 3.2351577281951904
Validation loss: 2.4860887463374803

Epoch: 5| Step: 1
Training loss: 2.700223445892334
Validation loss: 2.4869160241978143

Epoch: 5| Step: 2
Training loss: 2.8311901092529297
Validation loss: 2.49413731790358

Epoch: 5| Step: 3
Training loss: 1.6135072708129883
Validation loss: 2.4956450411068496

Epoch: 5| Step: 4
Training loss: 2.276258945465088
Validation loss: 2.5023147752208095

Epoch: 5| Step: 5
Training loss: 3.6893794536590576
Validation loss: 2.50616717338562

Epoch: 5| Step: 6
Training loss: 2.617239236831665
Validation loss: 2.5053856193378405

Epoch: 5| Step: 7
Training loss: 2.533661365509033
Validation loss: 2.4947073305806806

Epoch: 5| Step: 8
Training loss: 2.2655391693115234
Validation loss: 2.484199418816515

Epoch: 5| Step: 9
Training loss: 3.1911232471466064
Validation loss: 2.4805372786778275

Epoch: 5| Step: 10
Training loss: 2.518561840057373
Validation loss: 2.4847037535841747

Epoch: 102| Step: 0
Training loss: 2.8748364448547363
Validation loss: 2.4875933867628857

Epoch: 5| Step: 1
Training loss: 2.6650664806365967
Validation loss: 2.4874104556216987

Epoch: 5| Step: 2
Training loss: 2.145543098449707
Validation loss: 2.4896922829330608

Epoch: 5| Step: 3
Training loss: 3.0371780395507812
Validation loss: 2.49757186571757

Epoch: 5| Step: 4
Training loss: 2.105043888092041
Validation loss: 2.4961127773407967

Epoch: 5| Step: 5
Training loss: 2.8437652587890625
Validation loss: 2.4943011653038765

Epoch: 5| Step: 6
Training loss: 2.6775295734405518
Validation loss: 2.496528797252204

Epoch: 5| Step: 7
Training loss: 3.351341724395752
Validation loss: 2.4880472460100727

Epoch: 5| Step: 8
Training loss: 2.321800708770752
Validation loss: 2.4878764921619045

Epoch: 5| Step: 9
Training loss: 2.433997392654419
Validation loss: 2.48776731183452

Epoch: 5| Step: 10
Training loss: 3.219341516494751
Validation loss: 2.4874866060031358

Epoch: 103| Step: 0
Training loss: 2.1107757091522217
Validation loss: 2.484258718388055

Epoch: 5| Step: 1
Training loss: 2.149752140045166
Validation loss: 2.4832895045639365

Epoch: 5| Step: 2
Training loss: 3.775820255279541
Validation loss: 2.488276602119528

Epoch: 5| Step: 3
Training loss: 2.082972288131714
Validation loss: 2.4838709036509194

Epoch: 5| Step: 4
Training loss: 2.575542449951172
Validation loss: 2.4821571919225875

Epoch: 5| Step: 5
Training loss: 2.492587089538574
Validation loss: 2.492664337158203

Epoch: 5| Step: 6
Training loss: 3.027871608734131
Validation loss: 2.493804793204031

Epoch: 5| Step: 7
Training loss: 2.215125322341919
Validation loss: 2.4957719925911195

Epoch: 5| Step: 8
Training loss: 3.404271364212036
Validation loss: 2.493574209110711

Epoch: 5| Step: 9
Training loss: 2.571199417114258
Validation loss: 2.492531099627095

Epoch: 5| Step: 10
Training loss: 3.15456485748291
Validation loss: 2.4935905600106842

Epoch: 104| Step: 0
Training loss: 3.0345005989074707
Validation loss: 2.495725590695617

Epoch: 5| Step: 1
Training loss: 2.371044635772705
Validation loss: 2.4883061608960553

Epoch: 5| Step: 2
Training loss: 2.6528613567352295
Validation loss: 2.489364790660079

Epoch: 5| Step: 3
Training loss: 2.29030704498291
Validation loss: 2.487865430052562

Epoch: 5| Step: 4
Training loss: 2.6961164474487305
Validation loss: 2.4852729074416624

Epoch: 5| Step: 5
Training loss: 2.4665138721466064
Validation loss: 2.4839011674286215

Epoch: 5| Step: 6
Training loss: 3.3261847496032715
Validation loss: 2.481890037495603

Epoch: 5| Step: 7
Training loss: 2.5925753116607666
Validation loss: 2.4789770495507026

Epoch: 5| Step: 8
Training loss: 2.626086711883545
Validation loss: 2.473608342550134

Epoch: 5| Step: 9
Training loss: 3.238651990890503
Validation loss: 2.4751887475290606

Epoch: 5| Step: 10
Training loss: 2.0469465255737305
Validation loss: 2.4754062903824674

Epoch: 105| Step: 0
Training loss: 2.137427806854248
Validation loss: 2.482533831750193

Epoch: 5| Step: 1
Training loss: 2.0313515663146973
Validation loss: 2.488459746042887

Epoch: 5| Step: 2
Training loss: 2.78503680229187
Validation loss: 2.4911245017923336

Epoch: 5| Step: 3
Training loss: 3.1445670127868652
Validation loss: 2.4921548264001006

Epoch: 5| Step: 4
Training loss: 2.9216179847717285
Validation loss: 2.4827375437623713

Epoch: 5| Step: 5
Training loss: 2.786907196044922
Validation loss: 2.4866133915480746

Epoch: 5| Step: 6
Training loss: 3.1105120182037354
Validation loss: 2.4867499233573995

Epoch: 5| Step: 7
Training loss: 2.8674230575561523
Validation loss: 2.4853934293152182

Epoch: 5| Step: 8
Training loss: 2.699810743331909
Validation loss: 2.4778640449688

Epoch: 5| Step: 9
Training loss: 2.7781119346618652
Validation loss: 2.4828720118409846

Epoch: 5| Step: 10
Training loss: 2.1002755165100098
Validation loss: 2.476400629166634

Epoch: 106| Step: 0
Training loss: 2.5338804721832275
Validation loss: 2.4732003160702285

Epoch: 5| Step: 1
Training loss: 2.8871541023254395
Validation loss: 2.475139525628859

Epoch: 5| Step: 2
Training loss: 2.6388869285583496
Validation loss: 2.472080061512609

Epoch: 5| Step: 3
Training loss: 2.4079105854034424
Validation loss: 2.4748890041023173

Epoch: 5| Step: 4
Training loss: 2.6522886753082275
Validation loss: 2.4769478715876097

Epoch: 5| Step: 5
Training loss: 2.984825611114502
Validation loss: 2.4766295161298526

Epoch: 5| Step: 6
Training loss: 2.9665110111236572
Validation loss: 2.4742163637632966

Epoch: 5| Step: 7
Training loss: 2.517329692840576
Validation loss: 2.4725071896788893

Epoch: 5| Step: 8
Training loss: 2.7809393405914307
Validation loss: 2.46750622154564

Epoch: 5| Step: 9
Training loss: 2.489224910736084
Validation loss: 2.4682680893969793

Epoch: 5| Step: 10
Training loss: 2.532294750213623
Validation loss: 2.467713696982271

Epoch: 107| Step: 0
Training loss: 3.2770943641662598
Validation loss: 2.47463531391595

Epoch: 5| Step: 1
Training loss: 3.3490262031555176
Validation loss: 2.4777078782358477

Epoch: 5| Step: 2
Training loss: 2.790196657180786
Validation loss: 2.483500793416013

Epoch: 5| Step: 3
Training loss: 3.1298108100891113
Validation loss: 2.490684360586187

Epoch: 5| Step: 4
Training loss: 2.4404993057250977
Validation loss: 2.4853307534289617

Epoch: 5| Step: 5
Training loss: 2.631511688232422
Validation loss: 2.477906286075551

Epoch: 5| Step: 6
Training loss: 2.3524250984191895
Validation loss: 2.4805800735309558

Epoch: 5| Step: 7
Training loss: 2.0555007457733154
Validation loss: 2.4842108449628277

Epoch: 5| Step: 8
Training loss: 2.463191509246826
Validation loss: 2.5004573880985217

Epoch: 5| Step: 9
Training loss: 1.9857242107391357
Validation loss: 2.526575034664523

Epoch: 5| Step: 10
Training loss: 2.982013702392578
Validation loss: 2.537114812481788

Epoch: 108| Step: 0
Training loss: 2.7542777061462402
Validation loss: 2.536527295266428

Epoch: 5| Step: 1
Training loss: 2.727158546447754
Validation loss: 2.52939421643493

Epoch: 5| Step: 2
Training loss: 2.7177114486694336
Validation loss: 2.496857827709567

Epoch: 5| Step: 3
Training loss: 2.5945894718170166
Validation loss: 2.4778648294428343

Epoch: 5| Step: 4
Training loss: 2.1047420501708984
Validation loss: 2.467931911509524

Epoch: 5| Step: 5
Training loss: 2.4194583892822266
Validation loss: 2.4664314639183784

Epoch: 5| Step: 6
Training loss: 2.4443886280059814
Validation loss: 2.4737043380737305

Epoch: 5| Step: 7
Training loss: 2.9633851051330566
Validation loss: 2.4831838607788086

Epoch: 5| Step: 8
Training loss: 3.0363609790802
Validation loss: 2.4901332598860546

Epoch: 5| Step: 9
Training loss: 3.1932263374328613
Validation loss: 2.495193014862717

Epoch: 5| Step: 10
Training loss: 2.514237642288208
Validation loss: 2.487900451947284

Epoch: 109| Step: 0
Training loss: 2.4567298889160156
Validation loss: 2.479640023682707

Epoch: 5| Step: 1
Training loss: 2.881896495819092
Validation loss: 2.472579566381311

Epoch: 5| Step: 2
Training loss: 2.4269211292266846
Validation loss: 2.468187424444383

Epoch: 5| Step: 3
Training loss: 2.72100830078125
Validation loss: 2.4632256338673253

Epoch: 5| Step: 4
Training loss: 2.825366497039795
Validation loss: 2.458564217372607

Epoch: 5| Step: 5
Training loss: 3.6280677318573
Validation loss: 2.46020031744434

Epoch: 5| Step: 6
Training loss: 2.548255443572998
Validation loss: 2.466889178881081

Epoch: 5| Step: 7
Training loss: 2.382254123687744
Validation loss: 2.4746931188849994

Epoch: 5| Step: 8
Training loss: 2.164050579071045
Validation loss: 2.4952798556256037

Epoch: 5| Step: 9
Training loss: 2.649261474609375
Validation loss: 2.4851238176386845

Epoch: 5| Step: 10
Training loss: 2.8697988986968994
Validation loss: 2.470523429173295

Epoch: 110| Step: 0
Training loss: 2.8625266551971436
Validation loss: 2.4625674152886994

Epoch: 5| Step: 1
Training loss: 2.7527599334716797
Validation loss: 2.458158313587148

Epoch: 5| Step: 2
Training loss: 2.5091776847839355
Validation loss: 2.4586780891623548

Epoch: 5| Step: 3
Training loss: 2.2898242473602295
Validation loss: 2.454688120913762

Epoch: 5| Step: 4
Training loss: 3.301274061203003
Validation loss: 2.456269043748097

Epoch: 5| Step: 5
Training loss: 2.6264548301696777
Validation loss: 2.455970259122951

Epoch: 5| Step: 6
Training loss: 2.95180082321167
Validation loss: 2.4571279351429274

Epoch: 5| Step: 7
Training loss: 3.144339084625244
Validation loss: 2.45879360424575

Epoch: 5| Step: 8
Training loss: 2.057394504547119
Validation loss: 2.4596198348588842

Epoch: 5| Step: 9
Training loss: 2.6628236770629883
Validation loss: 2.459623336791992

Epoch: 5| Step: 10
Training loss: 2.121537923812866
Validation loss: 2.474304414564563

Epoch: 111| Step: 0
Training loss: 1.9712865352630615
Validation loss: 2.4770762869106826

Epoch: 5| Step: 1
Training loss: 2.436494827270508
Validation loss: 2.480970149399132

Epoch: 5| Step: 2
Training loss: 2.588254451751709
Validation loss: 2.475694730717649

Epoch: 5| Step: 3
Training loss: 2.453232765197754
Validation loss: 2.471932670121552

Epoch: 5| Step: 4
Training loss: 3.073976755142212
Validation loss: 2.4687148858142156

Epoch: 5| Step: 5
Training loss: 3.0986416339874268
Validation loss: 2.4602678360477572

Epoch: 5| Step: 6
Training loss: 2.8899142742156982
Validation loss: 2.457157470846689

Epoch: 5| Step: 7
Training loss: 2.7282357215881348
Validation loss: 2.4586017823988393

Epoch: 5| Step: 8
Training loss: 2.9045603275299072
Validation loss: 2.456639210383097

Epoch: 5| Step: 9
Training loss: 2.7894697189331055
Validation loss: 2.4599216471436205

Epoch: 5| Step: 10
Training loss: 2.4025731086730957
Validation loss: 2.4608621904926915

Epoch: 112| Step: 0
Training loss: 2.9075770378112793
Validation loss: 2.4614655484435377

Epoch: 5| Step: 1
Training loss: 2.025555372238159
Validation loss: 2.4612874677104335

Epoch: 5| Step: 2
Training loss: 2.859982967376709
Validation loss: 2.465421556144632

Epoch: 5| Step: 3
Training loss: 2.958979845046997
Validation loss: 2.462878268252137

Epoch: 5| Step: 4
Training loss: 2.1141438484191895
Validation loss: 2.462566298823203

Epoch: 5| Step: 5
Training loss: 3.296678066253662
Validation loss: 2.459438080428749

Epoch: 5| Step: 6
Training loss: 2.4160244464874268
Validation loss: 2.455758810043335

Epoch: 5| Step: 7
Training loss: 2.839836359024048
Validation loss: 2.45709999017818

Epoch: 5| Step: 8
Training loss: 2.3579776287078857
Validation loss: 2.458170493443807

Epoch: 5| Step: 9
Training loss: 2.8244102001190186
Validation loss: 2.46686573695111

Epoch: 5| Step: 10
Training loss: 2.748286247253418
Validation loss: 2.471766374444449

Epoch: 113| Step: 0
Training loss: 3.0362727642059326
Validation loss: 2.4806458104041313

Epoch: 5| Step: 1
Training loss: 2.5347657203674316
Validation loss: 2.482699960790655

Epoch: 5| Step: 2
Training loss: 3.2021193504333496
Validation loss: 2.484614949072561

Epoch: 5| Step: 3
Training loss: 2.6839890480041504
Validation loss: 2.478216189210133

Epoch: 5| Step: 4
Training loss: 2.225809335708618
Validation loss: 2.4656662120614

Epoch: 5| Step: 5
Training loss: 2.9307518005371094
Validation loss: 2.460084012759629

Epoch: 5| Step: 6
Training loss: 2.8532638549804688
Validation loss: 2.457597532579976

Epoch: 5| Step: 7
Training loss: 1.6300557851791382
Validation loss: 2.452597889848935

Epoch: 5| Step: 8
Training loss: 2.3916234970092773
Validation loss: 2.454883985621955

Epoch: 5| Step: 9
Training loss: 2.7439873218536377
Validation loss: 2.4509496509387927

Epoch: 5| Step: 10
Training loss: 3.160933494567871
Validation loss: 2.454235940851191

Epoch: 114| Step: 0
Training loss: 2.9141197204589844
Validation loss: 2.451465360579952

Epoch: 5| Step: 1
Training loss: 1.9255717992782593
Validation loss: 2.4530676129043743

Epoch: 5| Step: 2
Training loss: 2.5348384380340576
Validation loss: 2.450301262640184

Epoch: 5| Step: 3
Training loss: 2.833064079284668
Validation loss: 2.44927821236272

Epoch: 5| Step: 4
Training loss: 2.758596897125244
Validation loss: 2.449302505421382

Epoch: 5| Step: 5
Training loss: 3.0297083854675293
Validation loss: 2.447851711703885

Epoch: 5| Step: 6
Training loss: 2.268333911895752
Validation loss: 2.4504043184300905

Epoch: 5| Step: 7
Training loss: 2.1806981563568115
Validation loss: 2.449145645223638

Epoch: 5| Step: 8
Training loss: 3.162644863128662
Validation loss: 2.4464169368948987

Epoch: 5| Step: 9
Training loss: 2.7006962299346924
Validation loss: 2.4470440905581237

Epoch: 5| Step: 10
Training loss: 3.0533337593078613
Validation loss: 2.4538455676007014

Epoch: 115| Step: 0
Training loss: 2.0931315422058105
Validation loss: 2.4576708706476356

Epoch: 5| Step: 1
Training loss: 3.2030856609344482
Validation loss: 2.469316569707727

Epoch: 5| Step: 2
Training loss: 2.865586042404175
Validation loss: 2.490075154971051

Epoch: 5| Step: 3
Training loss: 2.616853952407837
Validation loss: 2.4889201284736715

Epoch: 5| Step: 4
Training loss: 2.3578789234161377
Validation loss: 2.4750696254032913

Epoch: 5| Step: 5
Training loss: 2.8853366374969482
Validation loss: 2.458470026652018

Epoch: 5| Step: 6
Training loss: 2.6842193603515625
Validation loss: 2.448216917694256

Epoch: 5| Step: 7
Training loss: 2.7555911540985107
Validation loss: 2.44259306692308

Epoch: 5| Step: 8
Training loss: 2.817185163497925
Validation loss: 2.4438726414916334

Epoch: 5| Step: 9
Training loss: 2.4085686206817627
Validation loss: 2.4474004442973802

Epoch: 5| Step: 10
Training loss: 2.632852792739868
Validation loss: 2.4499567734297885

Epoch: 116| Step: 0
Training loss: 2.9913485050201416
Validation loss: 2.4487203116058023

Epoch: 5| Step: 1
Training loss: 2.7508137226104736
Validation loss: 2.447191728058682

Epoch: 5| Step: 2
Training loss: 2.4191040992736816
Validation loss: 2.4484791448039394

Epoch: 5| Step: 3
Training loss: 2.224747896194458
Validation loss: 2.450371071856509

Epoch: 5| Step: 4
Training loss: 3.227165937423706
Validation loss: 2.443079645915698

Epoch: 5| Step: 5
Training loss: 2.7944350242614746
Validation loss: 2.4499229026097122

Epoch: 5| Step: 6
Training loss: 2.5865516662597656
Validation loss: 2.4528088056912987

Epoch: 5| Step: 7
Training loss: 2.4579720497131348
Validation loss: 2.4578478233788603

Epoch: 5| Step: 8
Training loss: 2.847133159637451
Validation loss: 2.4612483709089217

Epoch: 5| Step: 9
Training loss: 2.410834789276123
Validation loss: 2.4632158253782537

Epoch: 5| Step: 10
Training loss: 2.6262154579162598
Validation loss: 2.464346860044746

Epoch: 117| Step: 0
Training loss: 2.5743134021759033
Validation loss: 2.4546079738165743

Epoch: 5| Step: 1
Training loss: 2.55804443359375
Validation loss: 2.4503999243500414

Epoch: 5| Step: 2
Training loss: 2.7027904987335205
Validation loss: 2.4474788660644204

Epoch: 5| Step: 3
Training loss: 2.123084306716919
Validation loss: 2.443405005239671

Epoch: 5| Step: 4
Training loss: 1.9281730651855469
Validation loss: 2.4477103730683685

Epoch: 5| Step: 5
Training loss: 2.8181941509246826
Validation loss: 2.455605399224066

Epoch: 5| Step: 6
Training loss: 2.296459674835205
Validation loss: 2.451004596166713

Epoch: 5| Step: 7
Training loss: 2.7606441974639893
Validation loss: 2.4516350505172566

Epoch: 5| Step: 8
Training loss: 3.248042345046997
Validation loss: 2.451080652975267

Epoch: 5| Step: 9
Training loss: 2.9935808181762695
Validation loss: 2.4582348664601645

Epoch: 5| Step: 10
Training loss: 3.2484707832336426
Validation loss: 2.445049778107674

Epoch: 118| Step: 0
Training loss: 3.022660493850708
Validation loss: 2.4464179649147937

Epoch: 5| Step: 1
Training loss: 2.5270469188690186
Validation loss: 2.4441969830502748

Epoch: 5| Step: 2
Training loss: 2.8585917949676514
Validation loss: 2.4459214620692755

Epoch: 5| Step: 3
Training loss: 2.4682605266571045
Validation loss: 2.4452147176188808

Epoch: 5| Step: 4
Training loss: 2.34306263923645
Validation loss: 2.4474014953900407

Epoch: 5| Step: 5
Training loss: 2.1084046363830566
Validation loss: 2.4544706113876833

Epoch: 5| Step: 6
Training loss: 3.025404214859009
Validation loss: 2.4538175521358365

Epoch: 5| Step: 7
Training loss: 2.6367435455322266
Validation loss: 2.45945171899693

Epoch: 5| Step: 8
Training loss: 2.453463315963745
Validation loss: 2.4711877812621412

Epoch: 5| Step: 9
Training loss: 2.8729491233825684
Validation loss: 2.46683180973094

Epoch: 5| Step: 10
Training loss: 2.878547191619873
Validation loss: 2.4710338705329487

Epoch: 119| Step: 0
Training loss: 2.2412631511688232
Validation loss: 2.4665678572911087

Epoch: 5| Step: 1
Training loss: 3.0789284706115723
Validation loss: 2.4702490529706402

Epoch: 5| Step: 2
Training loss: 2.5415430068969727
Validation loss: 2.458960166541479

Epoch: 5| Step: 3
Training loss: 2.6236965656280518
Validation loss: 2.446663469396612

Epoch: 5| Step: 4
Training loss: 2.4567666053771973
Validation loss: 2.4427685353063766

Epoch: 5| Step: 5
Training loss: 2.8917391300201416
Validation loss: 2.435707563995033

Epoch: 5| Step: 6
Training loss: 2.7814176082611084
Validation loss: 2.4347924545247066

Epoch: 5| Step: 7
Training loss: 2.498565196990967
Validation loss: 2.4361280959139586

Epoch: 5| Step: 8
Training loss: 2.5078985691070557
Validation loss: 2.432569824239259

Epoch: 5| Step: 9
Training loss: 3.164639711380005
Validation loss: 2.4366859236071186

Epoch: 5| Step: 10
Training loss: 2.2992115020751953
Validation loss: 2.434140036183019

Epoch: 120| Step: 0
Training loss: 3.238255739212036
Validation loss: 2.4341126206100627

Epoch: 5| Step: 1
Training loss: 2.782186985015869
Validation loss: 2.428413919223252

Epoch: 5| Step: 2
Training loss: 2.370751142501831
Validation loss: 2.4348181780948432

Epoch: 5| Step: 3
Training loss: 2.967592477798462
Validation loss: 2.4331064916426137

Epoch: 5| Step: 4
Training loss: 2.371021270751953
Validation loss: 2.432813177826584

Epoch: 5| Step: 5
Training loss: 2.4226126670837402
Validation loss: 2.449280726012363

Epoch: 5| Step: 6
Training loss: 2.5462849140167236
Validation loss: 2.452586302193262

Epoch: 5| Step: 7
Training loss: 2.4141039848327637
Validation loss: 2.4586265471673783

Epoch: 5| Step: 8
Training loss: 2.230145215988159
Validation loss: 2.4616081073719966

Epoch: 5| Step: 9
Training loss: 2.623675584793091
Validation loss: 2.472831331273561

Epoch: 5| Step: 10
Training loss: 3.289125442504883
Validation loss: 2.4768943760984685

Epoch: 121| Step: 0
Training loss: 2.603891372680664
Validation loss: 2.4741502705440728

Epoch: 5| Step: 1
Training loss: 3.046959161758423
Validation loss: 2.4671364599658596

Epoch: 5| Step: 2
Training loss: 2.1351380348205566
Validation loss: 2.4455782200700495

Epoch: 5| Step: 3
Training loss: 2.4030919075012207
Validation loss: 2.4371626787288214

Epoch: 5| Step: 4
Training loss: 2.287200450897217
Validation loss: 2.434489557819982

Epoch: 5| Step: 5
Training loss: 2.7429912090301514
Validation loss: 2.436046508050734

Epoch: 5| Step: 6
Training loss: 2.674870252609253
Validation loss: 2.4343073470618135

Epoch: 5| Step: 7
Training loss: 2.5913424491882324
Validation loss: 2.442113199541646

Epoch: 5| Step: 8
Training loss: 2.808581829071045
Validation loss: 2.4470183592970653

Epoch: 5| Step: 9
Training loss: 2.7291259765625
Validation loss: 2.4410845720639793

Epoch: 5| Step: 10
Training loss: 3.2622904777526855
Validation loss: 2.447503676978491

Epoch: 122| Step: 0
Training loss: 2.598412036895752
Validation loss: 2.4336157088638632

Epoch: 5| Step: 1
Training loss: 2.468430995941162
Validation loss: 2.431722325663413

Epoch: 5| Step: 2
Training loss: 2.3744730949401855
Validation loss: 2.44206206516553

Epoch: 5| Step: 3
Training loss: 3.100785970687866
Validation loss: 2.444272910394976

Epoch: 5| Step: 4
Training loss: 3.1356639862060547
Validation loss: 2.4528261205201507

Epoch: 5| Step: 5
Training loss: 2.17657208442688
Validation loss: 2.4594639783264487

Epoch: 5| Step: 6
Training loss: 2.3859684467315674
Validation loss: 2.472555260504446

Epoch: 5| Step: 7
Training loss: 2.656916379928589
Validation loss: 2.465684413909912

Epoch: 5| Step: 8
Training loss: 2.20597243309021
Validation loss: 2.4518908890344764

Epoch: 5| Step: 9
Training loss: 3.05022931098938
Validation loss: 2.4512356942699802

Epoch: 5| Step: 10
Training loss: 3.0475502014160156
Validation loss: 2.4371182264820224

Epoch: 123| Step: 0
Training loss: 3.675100803375244
Validation loss: 2.429478435106175

Epoch: 5| Step: 1
Training loss: 2.7169227600097656
Validation loss: 2.4281238202125794

Epoch: 5| Step: 2
Training loss: 2.468388557434082
Validation loss: 2.4284738212503414

Epoch: 5| Step: 3
Training loss: 2.8628039360046387
Validation loss: 2.431041953384235

Epoch: 5| Step: 4
Training loss: 2.903956651687622
Validation loss: 2.431646490609774

Epoch: 5| Step: 5
Training loss: 2.3121800422668457
Validation loss: 2.4326486946434103

Epoch: 5| Step: 6
Training loss: 2.0712807178497314
Validation loss: 2.4326131343841553

Epoch: 5| Step: 7
Training loss: 2.2840476036071777
Validation loss: 2.4329475895051034

Epoch: 5| Step: 8
Training loss: 2.893416166305542
Validation loss: 2.4404366964934976

Epoch: 5| Step: 9
Training loss: 2.276279926300049
Validation loss: 2.4458432941026587

Epoch: 5| Step: 10
Training loss: 2.7139511108398438
Validation loss: 2.4614417142765497

Epoch: 124| Step: 0
Training loss: 2.9511756896972656
Validation loss: 2.4634335092318955

Epoch: 5| Step: 1
Training loss: 2.69216251373291
Validation loss: 2.4617243684748167

Epoch: 5| Step: 2
Training loss: 2.767037868499756
Validation loss: 2.4455463194078013

Epoch: 5| Step: 3
Training loss: 2.438372850418091
Validation loss: 2.4465839785914265

Epoch: 5| Step: 4
Training loss: 2.54483962059021
Validation loss: 2.4301441331063547

Epoch: 5| Step: 5
Training loss: 2.361595630645752
Validation loss: 2.436767162815217

Epoch: 5| Step: 6
Training loss: 2.8082022666931152
Validation loss: 2.4328997391526417

Epoch: 5| Step: 7
Training loss: 2.7446911334991455
Validation loss: 2.4276852710272676

Epoch: 5| Step: 8
Training loss: 2.769641876220703
Validation loss: 2.4297794936805643

Epoch: 5| Step: 9
Training loss: 2.8826990127563477
Validation loss: 2.4318314495907036

Epoch: 5| Step: 10
Training loss: 1.9494657516479492
Validation loss: 2.437237995927052

Epoch: 125| Step: 0
Training loss: 2.5865516662597656
Validation loss: 2.441040982482254

Epoch: 5| Step: 1
Training loss: 2.821758270263672
Validation loss: 2.437784758947229

Epoch: 5| Step: 2
Training loss: 2.076855182647705
Validation loss: 2.4411639500689764

Epoch: 5| Step: 3
Training loss: 2.5076122283935547
Validation loss: 2.4398548449239423

Epoch: 5| Step: 4
Training loss: 2.601727247238159
Validation loss: 2.4396312621331986

Epoch: 5| Step: 5
Training loss: 2.889838695526123
Validation loss: 2.4367312000643824

Epoch: 5| Step: 6
Training loss: 3.013631820678711
Validation loss: 2.4339096187263407

Epoch: 5| Step: 7
Training loss: 2.6549911499023438
Validation loss: 2.4298970981310775

Epoch: 5| Step: 8
Training loss: 2.340257167816162
Validation loss: 2.4286514456554125

Epoch: 5| Step: 9
Training loss: 3.3228557109832764
Validation loss: 2.4295596512415076

Epoch: 5| Step: 10
Training loss: 2.122511386871338
Validation loss: 2.4288241324886197

Epoch: 126| Step: 0
Training loss: 2.8256492614746094
Validation loss: 2.4296797398597962

Epoch: 5| Step: 1
Training loss: 3.365678310394287
Validation loss: 2.4279777567873717

Epoch: 5| Step: 2
Training loss: 2.398952007293701
Validation loss: 2.426917350420388

Epoch: 5| Step: 3
Training loss: 2.579005002975464
Validation loss: 2.422499865613958

Epoch: 5| Step: 4
Training loss: 2.802788734436035
Validation loss: 2.4261260750473186

Epoch: 5| Step: 5
Training loss: 2.853017807006836
Validation loss: 2.4256203084863643

Epoch: 5| Step: 6
Training loss: 2.405636787414551
Validation loss: 2.426594147118189

Epoch: 5| Step: 7
Training loss: 2.7510392665863037
Validation loss: 2.43454985977501

Epoch: 5| Step: 8
Training loss: 2.6532654762268066
Validation loss: 2.437614448608891

Epoch: 5| Step: 9
Training loss: 2.1975953578948975
Validation loss: 2.4366967472978818

Epoch: 5| Step: 10
Training loss: 2.0456387996673584
Validation loss: 2.4376133154797297

Epoch: 127| Step: 0
Training loss: 2.6601920127868652
Validation loss: 2.436921965691351

Epoch: 5| Step: 1
Training loss: 2.352247714996338
Validation loss: 2.4482998232687674

Epoch: 5| Step: 2
Training loss: 2.760465621948242
Validation loss: 2.4552941809418383

Epoch: 5| Step: 3
Training loss: 3.072174549102783
Validation loss: 2.4680746575837493

Epoch: 5| Step: 4
Training loss: 2.2570905685424805
Validation loss: 2.4541692118490896

Epoch: 5| Step: 5
Training loss: 2.8899030685424805
Validation loss: 2.4516913660110964

Epoch: 5| Step: 6
Training loss: 3.0547680854797363
Validation loss: 2.4474191024739254

Epoch: 5| Step: 7
Training loss: 2.0738298892974854
Validation loss: 2.4319570602909213

Epoch: 5| Step: 8
Training loss: 2.6530373096466064
Validation loss: 2.4317885675737934

Epoch: 5| Step: 9
Training loss: 2.6174378395080566
Validation loss: 2.430550790602161

Epoch: 5| Step: 10
Training loss: 2.697922468185425
Validation loss: 2.4292193382017073

Epoch: 128| Step: 0
Training loss: 2.741442918777466
Validation loss: 2.425593078777354

Epoch: 5| Step: 1
Training loss: 2.630709409713745
Validation loss: 2.4270579712365263

Epoch: 5| Step: 2
Training loss: 3.310654401779175
Validation loss: 2.4233491818110147

Epoch: 5| Step: 3
Training loss: 2.367551326751709
Validation loss: 2.4269775857207594

Epoch: 5| Step: 4
Training loss: 2.454740047454834
Validation loss: 2.4317449933739117

Epoch: 5| Step: 5
Training loss: 2.5507607460021973
Validation loss: 2.4339440125291065

Epoch: 5| Step: 6
Training loss: 2.514042854309082
Validation loss: 2.434360688732516

Epoch: 5| Step: 7
Training loss: 2.7183949947357178
Validation loss: 2.446295763856621

Epoch: 5| Step: 8
Training loss: 3.006787061691284
Validation loss: 2.4391338107406453

Epoch: 5| Step: 9
Training loss: 2.622784376144409
Validation loss: 2.4335998873556814

Epoch: 5| Step: 10
Training loss: 1.9665132761001587
Validation loss: 2.4306370724913893

Epoch: 129| Step: 0
Training loss: 2.559244155883789
Validation loss: 2.4278074259399087

Epoch: 5| Step: 1
Training loss: 2.7733631134033203
Validation loss: 2.435493864038939

Epoch: 5| Step: 2
Training loss: 2.4090709686279297
Validation loss: 2.4323858855873026

Epoch: 5| Step: 3
Training loss: 2.15910267829895
Validation loss: 2.4358251889546714

Epoch: 5| Step: 4
Training loss: 2.891378879547119
Validation loss: 2.427128666190691

Epoch: 5| Step: 5
Training loss: 2.4661216735839844
Validation loss: 2.418380573231687

Epoch: 5| Step: 6
Training loss: 1.6203911304473877
Validation loss: 2.4151748175262124

Epoch: 5| Step: 7
Training loss: 2.3571743965148926
Validation loss: 2.4143697510483446

Epoch: 5| Step: 8
Training loss: 3.122803211212158
Validation loss: 2.4195374673412693

Epoch: 5| Step: 9
Training loss: 2.8507072925567627
Validation loss: 2.417575910527219

Epoch: 5| Step: 10
Training loss: 3.9039859771728516
Validation loss: 2.4165844673751504

Epoch: 130| Step: 0
Training loss: 2.7733263969421387
Validation loss: 2.412988772956274

Epoch: 5| Step: 1
Training loss: 2.168745517730713
Validation loss: 2.4160945364224014

Epoch: 5| Step: 2
Training loss: 2.5876526832580566
Validation loss: 2.4113249445474274

Epoch: 5| Step: 3
Training loss: 2.7499923706054688
Validation loss: 2.4095472469124743

Epoch: 5| Step: 4
Training loss: 2.7960522174835205
Validation loss: 2.420775475040559

Epoch: 5| Step: 5
Training loss: 2.9275221824645996
Validation loss: 2.4141404526208037

Epoch: 5| Step: 6
Training loss: 2.7750704288482666
Validation loss: 2.4175479847897767

Epoch: 5| Step: 7
Training loss: 2.4590628147125244
Validation loss: 2.426605515582587

Epoch: 5| Step: 8
Training loss: 2.8625378608703613
Validation loss: 2.4254123062215824

Epoch: 5| Step: 9
Training loss: 2.7762184143066406
Validation loss: 2.4325995983616

Epoch: 5| Step: 10
Training loss: 2.007342576980591
Validation loss: 2.4434779946522047

Epoch: 131| Step: 0
Training loss: 2.4149229526519775
Validation loss: 2.446505351733136

Epoch: 5| Step: 1
Training loss: 1.8653411865234375
Validation loss: 2.438288660459621

Epoch: 5| Step: 2
Training loss: 2.8023877143859863
Validation loss: 2.433429774417672

Epoch: 5| Step: 3
Training loss: 2.6803276538848877
Validation loss: 2.4190103956448135

Epoch: 5| Step: 4
Training loss: 3.0902342796325684
Validation loss: 2.4088672694339546

Epoch: 5| Step: 5
Training loss: 2.6504032611846924
Validation loss: 2.4071626201752694

Epoch: 5| Step: 6
Training loss: 1.8016557693481445
Validation loss: 2.4017901471866074

Epoch: 5| Step: 7
Training loss: 3.029721736907959
Validation loss: 2.404728187027798

Epoch: 5| Step: 8
Training loss: 2.6483941078186035
Validation loss: 2.4030399155873123

Epoch: 5| Step: 9
Training loss: 3.179718494415283
Validation loss: 2.403821442716865

Epoch: 5| Step: 10
Training loss: 2.8305835723876953
Validation loss: 2.405938592008365

Epoch: 132| Step: 0
Training loss: 2.0888562202453613
Validation loss: 2.4128330869059407

Epoch: 5| Step: 1
Training loss: 2.392810344696045
Validation loss: 2.4101172877896215

Epoch: 5| Step: 2
Training loss: 2.6893601417541504
Validation loss: 2.4271261192137197

Epoch: 5| Step: 3
Training loss: 2.508894443511963
Validation loss: 2.449394864420737

Epoch: 5| Step: 4
Training loss: 3.164151430130005
Validation loss: 2.4806479689895466

Epoch: 5| Step: 5
Training loss: 2.4664180278778076
Validation loss: 2.4607729604167323

Epoch: 5| Step: 6
Training loss: 2.76119327545166
Validation loss: 2.4324294982417936

Epoch: 5| Step: 7
Training loss: 3.0995898246765137
Validation loss: 2.4129637390054683

Epoch: 5| Step: 8
Training loss: 2.4587156772613525
Validation loss: 2.401914219702444

Epoch: 5| Step: 9
Training loss: 2.4352314472198486
Validation loss: 2.400905737312891

Epoch: 5| Step: 10
Training loss: 2.973437547683716
Validation loss: 2.399508818503349

Epoch: 133| Step: 0
Training loss: 2.739680051803589
Validation loss: 2.406385196152554

Epoch: 5| Step: 1
Training loss: 2.4680352210998535
Validation loss: 2.414450660828621

Epoch: 5| Step: 2
Training loss: 2.1988422870635986
Validation loss: 2.412234330690035

Epoch: 5| Step: 3
Training loss: 2.6972031593322754
Validation loss: 2.4150784810384116

Epoch: 5| Step: 4
Training loss: 2.675757646560669
Validation loss: 2.420370855639058

Epoch: 5| Step: 5
Training loss: 2.264322280883789
Validation loss: 2.428482594028596

Epoch: 5| Step: 6
Training loss: 2.6511406898498535
Validation loss: 2.428267825034357

Epoch: 5| Step: 7
Training loss: 3.131080389022827
Validation loss: 2.4398588647124586

Epoch: 5| Step: 8
Training loss: 2.7729532718658447
Validation loss: 2.4490659365089993

Epoch: 5| Step: 9
Training loss: 3.0311665534973145
Validation loss: 2.4427116609388784

Epoch: 5| Step: 10
Training loss: 2.269939661026001
Validation loss: 2.4350882089266213

Epoch: 134| Step: 0
Training loss: 2.743969440460205
Validation loss: 2.427793946317447

Epoch: 5| Step: 1
Training loss: 2.8045506477355957
Validation loss: 2.414401312028208

Epoch: 5| Step: 2
Training loss: 2.2444939613342285
Validation loss: 2.4004825597168296

Epoch: 5| Step: 3
Training loss: 3.0423569679260254
Validation loss: 2.403465529923798

Epoch: 5| Step: 4
Training loss: 2.524808406829834
Validation loss: 2.400112872482628

Epoch: 5| Step: 5
Training loss: 2.9929864406585693
Validation loss: 2.4062811892519713

Epoch: 5| Step: 6
Training loss: 2.32243275642395
Validation loss: 2.3911593678177043

Epoch: 5| Step: 7
Training loss: 2.639467716217041
Validation loss: 2.3886495277445805

Epoch: 5| Step: 8
Training loss: 2.426443099975586
Validation loss: 2.389818045400804

Epoch: 5| Step: 9
Training loss: 2.282132387161255
Validation loss: 2.388991278986777

Epoch: 5| Step: 10
Training loss: 2.86991810798645
Validation loss: 2.3888041665477138

Epoch: 135| Step: 0
Training loss: 2.6567471027374268
Validation loss: 2.3956522351952008

Epoch: 5| Step: 1
Training loss: 2.6854658126831055
Validation loss: 2.4036796656988

Epoch: 5| Step: 2
Training loss: 2.7938661575317383
Validation loss: 2.4091098795654955

Epoch: 5| Step: 3
Training loss: 2.460932970046997
Validation loss: 2.4043400518355833

Epoch: 5| Step: 4
Training loss: 2.6899914741516113
Validation loss: 2.3917058129464426

Epoch: 5| Step: 5
Training loss: 2.1947739124298096
Validation loss: 2.38743931247342

Epoch: 5| Step: 6
Training loss: 2.28436279296875
Validation loss: 2.382243364087997

Epoch: 5| Step: 7
Training loss: 2.6022748947143555
Validation loss: 2.3848668734232583

Epoch: 5| Step: 8
Training loss: 2.4794392585754395
Validation loss: 2.4055277224509948

Epoch: 5| Step: 9
Training loss: 3.0922818183898926
Validation loss: 2.4134185955088627

Epoch: 5| Step: 10
Training loss: 3.062415838241577
Validation loss: 2.4367442746316232

Epoch: 136| Step: 0
Training loss: 2.9891536235809326
Validation loss: 2.4286285600354596

Epoch: 5| Step: 1
Training loss: 2.2353975772857666
Validation loss: 2.414601631062005

Epoch: 5| Step: 2
Training loss: 2.1101999282836914
Validation loss: 2.3920053192364272

Epoch: 5| Step: 3
Training loss: 2.69126558303833
Validation loss: 2.3906439863225466

Epoch: 5| Step: 4
Training loss: 2.6593778133392334
Validation loss: 2.3857674701239473

Epoch: 5| Step: 5
Training loss: 2.7239019870758057
Validation loss: 2.384027463133617

Epoch: 5| Step: 6
Training loss: 3.4022300243377686
Validation loss: 2.38439211153215

Epoch: 5| Step: 7
Training loss: 2.489405870437622
Validation loss: 2.384397824605306

Epoch: 5| Step: 8
Training loss: 2.6914494037628174
Validation loss: 2.3835427504713818

Epoch: 5| Step: 9
Training loss: 2.0807862281799316
Validation loss: 2.3863091058628534

Epoch: 5| Step: 10
Training loss: 2.757535457611084
Validation loss: 2.3841057503095238

Epoch: 137| Step: 0
Training loss: 2.6263561248779297
Validation loss: 2.3838658653279787

Epoch: 5| Step: 1
Training loss: 2.356382369995117
Validation loss: 2.396702794618504

Epoch: 5| Step: 2
Training loss: 1.9361677169799805
Validation loss: 2.4010752247225855

Epoch: 5| Step: 3
Training loss: 2.708904981613159
Validation loss: 2.4134179289622972

Epoch: 5| Step: 4
Training loss: 2.6130530834198
Validation loss: 2.4136930434934554

Epoch: 5| Step: 5
Training loss: 2.5160951614379883
Validation loss: 2.4115259160277662

Epoch: 5| Step: 6
Training loss: 2.3839192390441895
Validation loss: 2.4051190448063675

Epoch: 5| Step: 7
Training loss: 2.7702155113220215
Validation loss: 2.40105434643325

Epoch: 5| Step: 8
Training loss: 3.7540836334228516
Validation loss: 2.4016752448133243

Epoch: 5| Step: 9
Training loss: 2.577178955078125
Validation loss: 2.3844583085788194

Epoch: 5| Step: 10
Training loss: 2.5285909175872803
Validation loss: 2.384329742000949

Epoch: 138| Step: 0
Training loss: 1.7912870645523071
Validation loss: 2.382410595493932

Epoch: 5| Step: 1
Training loss: 2.898193120956421
Validation loss: 2.386249621709188

Epoch: 5| Step: 2
Training loss: 2.0232651233673096
Validation loss: 2.3847113809277936

Epoch: 5| Step: 3
Training loss: 2.665748119354248
Validation loss: 2.39049264436127

Epoch: 5| Step: 4
Training loss: 2.4890055656433105
Validation loss: 2.3875061850393973

Epoch: 5| Step: 5
Training loss: 2.88165283203125
Validation loss: 2.394546757462204

Epoch: 5| Step: 6
Training loss: 2.95689058303833
Validation loss: 2.3968496886632775

Epoch: 5| Step: 7
Training loss: 2.904796838760376
Validation loss: 2.4057135633243028

Epoch: 5| Step: 8
Training loss: 2.5787510871887207
Validation loss: 2.407567726668491

Epoch: 5| Step: 9
Training loss: 3.051832437515259
Validation loss: 2.4157677260778283

Epoch: 5| Step: 10
Training loss: 2.44401216506958
Validation loss: 2.406491202692832

Epoch: 139| Step: 0
Training loss: 2.61018443107605
Validation loss: 2.396515300196986

Epoch: 5| Step: 1
Training loss: 2.161316394805908
Validation loss: 2.3984309678436606

Epoch: 5| Step: 2
Training loss: 2.580744504928589
Validation loss: 2.389832173624346

Epoch: 5| Step: 3
Training loss: 2.4190375804901123
Validation loss: 2.388189777251213

Epoch: 5| Step: 4
Training loss: 2.573695659637451
Validation loss: 2.3966389368939143

Epoch: 5| Step: 5
Training loss: 3.12807035446167
Validation loss: 2.393318053214781

Epoch: 5| Step: 6
Training loss: 2.961879253387451
Validation loss: 2.3945117586402485

Epoch: 5| Step: 7
Training loss: 2.337465286254883
Validation loss: 2.3869268612195085

Epoch: 5| Step: 8
Training loss: 2.3567404747009277
Validation loss: 2.402745812169967

Epoch: 5| Step: 9
Training loss: 3.55224347114563
Validation loss: 2.3965238422475834

Epoch: 5| Step: 10
Training loss: 1.8533495664596558
Validation loss: 2.394647539302867

Epoch: 140| Step: 0
Training loss: 2.4303030967712402
Validation loss: 2.3900257105468423

Epoch: 5| Step: 1
Training loss: 3.1276049613952637
Validation loss: 2.398933636244907

Epoch: 5| Step: 2
Training loss: 2.5052103996276855
Validation loss: 2.3935537261347615

Epoch: 5| Step: 3
Training loss: 2.9779505729675293
Validation loss: 2.401967348590974

Epoch: 5| Step: 4
Training loss: 2.163306951522827
Validation loss: 2.4089567994558685

Epoch: 5| Step: 5
Training loss: 2.1985955238342285
Validation loss: 2.3851203969729844

Epoch: 5| Step: 6
Training loss: 2.955103635787964
Validation loss: 2.3879006934422318

Epoch: 5| Step: 7
Training loss: 2.8087024688720703
Validation loss: 2.387212704586726

Epoch: 5| Step: 8
Training loss: 2.6554176807403564
Validation loss: 2.3746628761291504

Epoch: 5| Step: 9
Training loss: 2.416795492172241
Validation loss: 2.385830456210721

Epoch: 5| Step: 10
Training loss: 2.309356451034546
Validation loss: 2.3833350314888904

Epoch: 141| Step: 0
Training loss: 2.869384765625
Validation loss: 2.3925871977242092

Epoch: 5| Step: 1
Training loss: 2.55888032913208
Validation loss: 2.3939550845853743

Epoch: 5| Step: 2
Training loss: 2.2233855724334717
Validation loss: 2.400002964081303

Epoch: 5| Step: 3
Training loss: 2.056983709335327
Validation loss: 2.3975029709518596

Epoch: 5| Step: 4
Training loss: 2.833786725997925
Validation loss: 2.390921192784463

Epoch: 5| Step: 5
Training loss: 2.938040256500244
Validation loss: 2.3986196159034647

Epoch: 5| Step: 6
Training loss: 2.908975124359131
Validation loss: 2.389857610066732

Epoch: 5| Step: 7
Training loss: 2.6871187686920166
Validation loss: 2.3853828625012468

Epoch: 5| Step: 8
Training loss: 2.423184633255005
Validation loss: 2.3837568221553678

Epoch: 5| Step: 9
Training loss: 2.3390917778015137
Validation loss: 2.3845436419210126

Epoch: 5| Step: 10
Training loss: 2.7738170623779297
Validation loss: 2.3772191027159333

Epoch: 142| Step: 0
Training loss: 2.283684015274048
Validation loss: 2.3809520762453795

Epoch: 5| Step: 1
Training loss: 3.2311387062072754
Validation loss: 2.391669814304639

Epoch: 5| Step: 2
Training loss: 2.6182663440704346
Validation loss: 2.3818729154525267

Epoch: 5| Step: 3
Training loss: 3.038522958755493
Validation loss: 2.3788286614161667

Epoch: 5| Step: 4
Training loss: 2.244504451751709
Validation loss: 2.388265332868022

Epoch: 5| Step: 5
Training loss: 2.4861693382263184
Validation loss: 2.378827069395332

Epoch: 5| Step: 6
Training loss: 2.139085054397583
Validation loss: 2.3763404559063654

Epoch: 5| Step: 7
Training loss: 2.769188642501831
Validation loss: 2.3765063849828576

Epoch: 5| Step: 8
Training loss: 2.550137996673584
Validation loss: 2.3784395661405338

Epoch: 5| Step: 9
Training loss: 2.9985642433166504
Validation loss: 2.376495163927796

Epoch: 5| Step: 10
Training loss: 2.1356773376464844
Validation loss: 2.3751882019863335

Epoch: 143| Step: 0
Training loss: 2.7057976722717285
Validation loss: 2.3804112788169616

Epoch: 5| Step: 1
Training loss: 2.4606823921203613
Validation loss: 2.379649325083661

Epoch: 5| Step: 2
Training loss: 2.872093915939331
Validation loss: 2.3843757772958405

Epoch: 5| Step: 3
Training loss: 2.2552027702331543
Validation loss: 2.3807234430825837

Epoch: 5| Step: 4
Training loss: 3.2362122535705566
Validation loss: 2.39297124390961

Epoch: 5| Step: 5
Training loss: 2.446506977081299
Validation loss: 2.406650197121405

Epoch: 5| Step: 6
Training loss: 2.907392740249634
Validation loss: 2.4173847885542017

Epoch: 5| Step: 7
Training loss: 2.555222749710083
Validation loss: 2.410805630427535

Epoch: 5| Step: 8
Training loss: 2.286632776260376
Validation loss: 2.405714181161696

Epoch: 5| Step: 9
Training loss: 2.5562174320220947
Validation loss: 2.395328214091639

Epoch: 5| Step: 10
Training loss: 2.211440086364746
Validation loss: 2.3877375254067044

Epoch: 144| Step: 0
Training loss: 1.9007232189178467
Validation loss: 2.3847758693079792

Epoch: 5| Step: 1
Training loss: 2.645918369293213
Validation loss: 2.3916076947284

Epoch: 5| Step: 2
Training loss: 2.790512800216675
Validation loss: 2.390779960540033

Epoch: 5| Step: 3
Training loss: 2.087728261947632
Validation loss: 2.4151128953503025

Epoch: 5| Step: 4
Training loss: 3.1107068061828613
Validation loss: 2.4255208815297773

Epoch: 5| Step: 5
Training loss: 2.3604979515075684
Validation loss: 2.4008622502767913

Epoch: 5| Step: 6
Training loss: 2.8803048133850098
Validation loss: 2.375743075083661

Epoch: 5| Step: 7
Training loss: 3.2354907989501953
Validation loss: 2.3772677631788355

Epoch: 5| Step: 8
Training loss: 2.996588945388794
Validation loss: 2.373618513025263

Epoch: 5| Step: 9
Training loss: 2.6944642066955566
Validation loss: 2.3742068916238765

Epoch: 5| Step: 10
Training loss: 1.7037872076034546
Validation loss: 2.3676289819901988

Epoch: 145| Step: 0
Training loss: 2.7326741218566895
Validation loss: 2.370256144513366

Epoch: 5| Step: 1
Training loss: 2.6369848251342773
Validation loss: 2.3733300598718787

Epoch: 5| Step: 2
Training loss: 2.414128541946411
Validation loss: 2.3666477946824926

Epoch: 5| Step: 3
Training loss: 2.1626334190368652
Validation loss: 2.372042409835323

Epoch: 5| Step: 4
Training loss: 2.3378617763519287
Validation loss: 2.375260006996893

Epoch: 5| Step: 5
Training loss: 3.0101099014282227
Validation loss: 2.3627759718125865

Epoch: 5| Step: 6
Training loss: 2.998765468597412
Validation loss: 2.370353880748954

Epoch: 5| Step: 7
Training loss: 2.3253021240234375
Validation loss: 2.3684375901376047

Epoch: 5| Step: 8
Training loss: 3.023144245147705
Validation loss: 2.372686775781775

Epoch: 5| Step: 9
Training loss: 2.370095729827881
Validation loss: 2.37094392571398

Epoch: 5| Step: 10
Training loss: 2.6532106399536133
Validation loss: 2.3692637874234106

Epoch: 146| Step: 0
Training loss: 2.9499473571777344
Validation loss: 2.3784955624611146

Epoch: 5| Step: 1
Training loss: 1.8883777856826782
Validation loss: 2.3785953598637737

Epoch: 5| Step: 2
Training loss: 2.9741063117980957
Validation loss: 2.3682950312091458

Epoch: 5| Step: 3
Training loss: 2.5195131301879883
Validation loss: 2.3718673541981685

Epoch: 5| Step: 4
Training loss: 1.6268218755722046
Validation loss: 2.369458234438332

Epoch: 5| Step: 5
Training loss: 3.112926721572876
Validation loss: 2.3662555884289485

Epoch: 5| Step: 6
Training loss: 2.67273211479187
Validation loss: 2.369699908841041

Epoch: 5| Step: 7
Training loss: 2.3934409618377686
Validation loss: 2.37488047025537

Epoch: 5| Step: 8
Training loss: 2.635505199432373
Validation loss: 2.3741502890022854

Epoch: 5| Step: 9
Training loss: 2.6906070709228516
Validation loss: 2.3785388418423232

Epoch: 5| Step: 10
Training loss: 3.026148557662964
Validation loss: 2.3856530061332126

Epoch: 147| Step: 0
Training loss: 2.211487293243408
Validation loss: 2.384598634576285

Epoch: 5| Step: 1
Training loss: 2.4302213191986084
Validation loss: 2.3969327531835085

Epoch: 5| Step: 2
Training loss: 3.055633544921875
Validation loss: 2.4206787360611783

Epoch: 5| Step: 3
Training loss: 1.7973778247833252
Validation loss: 2.4130603549300984

Epoch: 5| Step: 4
Training loss: 3.4089183807373047
Validation loss: 2.400054572730936

Epoch: 5| Step: 5
Training loss: 2.6061079502105713
Validation loss: 2.387471737400178

Epoch: 5| Step: 6
Training loss: 3.0981929302215576
Validation loss: 2.3617811715731056

Epoch: 5| Step: 7
Training loss: 2.5652577877044678
Validation loss: 2.359193380160998

Epoch: 5| Step: 8
Training loss: 2.3685460090637207
Validation loss: 2.3574168784644014

Epoch: 5| Step: 9
Training loss: 2.707569122314453
Validation loss: 2.36900814630652

Epoch: 5| Step: 10
Training loss: 2.3750534057617188
Validation loss: 2.3705596154735935

Epoch: 148| Step: 0
Training loss: 2.577533721923828
Validation loss: 2.357200822522563

Epoch: 5| Step: 1
Training loss: 2.4418787956237793
Validation loss: 2.3537485727699856

Epoch: 5| Step: 2
Training loss: 2.3362927436828613
Validation loss: 2.3504044317430064

Epoch: 5| Step: 3
Training loss: 2.3932628631591797
Validation loss: 2.3573480703497447

Epoch: 5| Step: 4
Training loss: 2.5942392349243164
Validation loss: 2.375942378915766

Epoch: 5| Step: 5
Training loss: 2.3769805431365967
Validation loss: 2.396811140480862

Epoch: 5| Step: 6
Training loss: 2.5340323448181152
Validation loss: 2.4247816019160773

Epoch: 5| Step: 7
Training loss: 2.7114434242248535
Validation loss: 2.421987127232295

Epoch: 5| Step: 8
Training loss: 2.749924421310425
Validation loss: 2.4447004923256497

Epoch: 5| Step: 9
Training loss: 3.091012716293335
Validation loss: 2.4287900873409805

Epoch: 5| Step: 10
Training loss: 3.0233774185180664
Validation loss: 2.3942691869633173

Epoch: 149| Step: 0
Training loss: 2.8061466217041016
Validation loss: 2.367053029357746

Epoch: 5| Step: 1
Training loss: 2.641913890838623
Validation loss: 2.347444434319773

Epoch: 5| Step: 2
Training loss: 2.1543071269989014
Validation loss: 2.345632509518695

Epoch: 5| Step: 3
Training loss: 2.576378107070923
Validation loss: 2.34813714796497

Epoch: 5| Step: 4
Training loss: 2.449490547180176
Validation loss: 2.3548241020530782

Epoch: 5| Step: 5
Training loss: 3.4807281494140625
Validation loss: 2.377920986503683

Epoch: 5| Step: 6
Training loss: 2.3811440467834473
Validation loss: 2.375689744949341

Epoch: 5| Step: 7
Training loss: 2.7958641052246094
Validation loss: 2.400542861671858

Epoch: 5| Step: 8
Training loss: 2.2506983280181885
Validation loss: 2.4071690677314677

Epoch: 5| Step: 9
Training loss: 2.168252468109131
Validation loss: 2.3842953405072613

Epoch: 5| Step: 10
Training loss: 3.009639263153076
Validation loss: 2.368576411278017

Epoch: 150| Step: 0
Training loss: 2.515298843383789
Validation loss: 2.357828570950416

Epoch: 5| Step: 1
Training loss: 2.526094675064087
Validation loss: 2.3465569737137004

Epoch: 5| Step: 2
Training loss: 2.205596446990967
Validation loss: 2.350629534772647

Epoch: 5| Step: 3
Training loss: 2.393347978591919
Validation loss: 2.355427477949409

Epoch: 5| Step: 4
Training loss: 2.590864658355713
Validation loss: 2.3646370480137486

Epoch: 5| Step: 5
Training loss: 2.725475788116455
Validation loss: 2.3628993008726384

Epoch: 5| Step: 6
Training loss: 2.8500237464904785
Validation loss: 2.3801189622571393

Epoch: 5| Step: 7
Training loss: 2.5152313709259033
Validation loss: 2.386568054076164

Epoch: 5| Step: 8
Training loss: 2.2711658477783203
Validation loss: 2.392064961053992

Epoch: 5| Step: 9
Training loss: 3.2802886962890625
Validation loss: 2.3883657096534647

Epoch: 5| Step: 10
Training loss: 2.6637017726898193
Validation loss: 2.399165899522843

Epoch: 151| Step: 0
Training loss: 2.7322914600372314
Validation loss: 2.36776045573655

Epoch: 5| Step: 1
Training loss: 2.4436073303222656
Validation loss: 2.3580549352912494

Epoch: 5| Step: 2
Training loss: 2.3211309909820557
Validation loss: 2.3557808117199968

Epoch: 5| Step: 3
Training loss: 2.810393810272217
Validation loss: 2.3416823212818434

Epoch: 5| Step: 4
Training loss: 2.718829393386841
Validation loss: 2.3433218925229964

Epoch: 5| Step: 5
Training loss: 2.5793232917785645
Validation loss: 2.34872248864943

Epoch: 5| Step: 6
Training loss: 2.104004383087158
Validation loss: 2.349505542426981

Epoch: 5| Step: 7
Training loss: 2.6993672847747803
Validation loss: 2.3437129297564105

Epoch: 5| Step: 8
Training loss: 2.4351608753204346
Validation loss: 2.349840551294306

Epoch: 5| Step: 9
Training loss: 2.847212076187134
Validation loss: 2.348250453190137

Epoch: 5| Step: 10
Training loss: 2.700438976287842
Validation loss: 2.3598514526121077

Epoch: 152| Step: 0
Training loss: 2.983707904815674
Validation loss: 2.3745014411146923

Epoch: 5| Step: 1
Training loss: 2.5175719261169434
Validation loss: 2.381046477184501

Epoch: 5| Step: 2
Training loss: 2.3903143405914307
Validation loss: 2.394032411677863

Epoch: 5| Step: 3
Training loss: 1.83599853515625
Validation loss: 2.3885132574266

Epoch: 5| Step: 4
Training loss: 2.6213467121124268
Validation loss: 2.400948550111504

Epoch: 5| Step: 5
Training loss: 3.6331417560577393
Validation loss: 2.3738128369854343

Epoch: 5| Step: 6
Training loss: 3.3427391052246094
Validation loss: 2.3564554670805573

Epoch: 5| Step: 7
Training loss: 2.3221402168273926
Validation loss: 2.3455469608306885

Epoch: 5| Step: 8
Training loss: 2.1815810203552246
Validation loss: 2.3454562002612698

Epoch: 5| Step: 9
Training loss: 1.9402862787246704
Validation loss: 2.3443072303648917

Epoch: 5| Step: 10
Training loss: 2.68878436088562
Validation loss: 2.343901285561182

Epoch: 153| Step: 0
Training loss: 2.4079675674438477
Validation loss: 2.342595569549068

Epoch: 5| Step: 1
Training loss: 2.9211926460266113
Validation loss: 2.3443365661046838

Epoch: 5| Step: 2
Training loss: 2.7238221168518066
Validation loss: 2.3444763460466937

Epoch: 5| Step: 3
Training loss: 1.9812320470809937
Validation loss: 2.342168387546334

Epoch: 5| Step: 4
Training loss: 2.5402991771698
Validation loss: 2.3518998802349134

Epoch: 5| Step: 5
Training loss: 2.7555339336395264
Validation loss: 2.3594887333531536

Epoch: 5| Step: 6
Training loss: 2.8836023807525635
Validation loss: 2.3620105558826077

Epoch: 5| Step: 7
Training loss: 2.81136155128479
Validation loss: 2.36859292368735

Epoch: 5| Step: 8
Training loss: 2.424158811569214
Validation loss: 2.3753259105067097

Epoch: 5| Step: 9
Training loss: 2.307121515274048
Validation loss: 2.3720638751983643

Epoch: 5| Step: 10
Training loss: 2.6164636611938477
Validation loss: 2.372189462825816

Epoch: 154| Step: 0
Training loss: 2.0054869651794434
Validation loss: 2.3710045917059785

Epoch: 5| Step: 1
Training loss: 2.8996646404266357
Validation loss: 2.368407501969286

Epoch: 5| Step: 2
Training loss: 2.3368821144104004
Validation loss: 2.373296135215349

Epoch: 5| Step: 3
Training loss: 2.8008389472961426
Validation loss: 2.3773318311219573

Epoch: 5| Step: 4
Training loss: 3.0077946186065674
Validation loss: 2.3874283708551878

Epoch: 5| Step: 5
Training loss: 2.647440195083618
Validation loss: 2.38856823982731

Epoch: 5| Step: 6
Training loss: 2.882415533065796
Validation loss: 2.414608916928691

Epoch: 5| Step: 7
Training loss: 2.2233898639678955
Validation loss: 2.429254344714585

Epoch: 5| Step: 8
Training loss: 2.954754114151001
Validation loss: 2.4095515884378904

Epoch: 5| Step: 9
Training loss: 2.243368625640869
Validation loss: 2.378113700497535

Epoch: 5| Step: 10
Training loss: 2.5896642208099365
Validation loss: 2.371662664157088

Epoch: 155| Step: 0
Training loss: 2.143381118774414
Validation loss: 2.3754472809453167

Epoch: 5| Step: 1
Training loss: 2.7942910194396973
Validation loss: 2.3808393273302304

Epoch: 5| Step: 2
Training loss: 2.5026092529296875
Validation loss: 2.391487649692002

Epoch: 5| Step: 3
Training loss: 2.9860587120056152
Validation loss: 2.42607271030385

Epoch: 5| Step: 4
Training loss: 2.4788379669189453
Validation loss: 2.417281860946327

Epoch: 5| Step: 5
Training loss: 2.410928249359131
Validation loss: 2.381425283288443

Epoch: 5| Step: 6
Training loss: 2.5801050662994385
Validation loss: 2.365696671188519

Epoch: 5| Step: 7
Training loss: 3.082615613937378
Validation loss: 2.360234623314232

Epoch: 5| Step: 8
Training loss: 2.238295793533325
Validation loss: 2.352644455048346

Epoch: 5| Step: 9
Training loss: 2.7814784049987793
Validation loss: 2.3529175904489334

Epoch: 5| Step: 10
Training loss: 2.341226816177368
Validation loss: 2.350973149781586

Epoch: 156| Step: 0
Training loss: 2.913350820541382
Validation loss: 2.3484702866564513

Epoch: 5| Step: 1
Training loss: 2.9030673503875732
Validation loss: 2.3474655741004535

Epoch: 5| Step: 2
Training loss: 3.116556167602539
Validation loss: 2.3496398182325464

Epoch: 5| Step: 3
Training loss: 2.329667329788208
Validation loss: 2.3415182892994215

Epoch: 5| Step: 4
Training loss: 1.686920166015625
Validation loss: 2.3430149145023798

Epoch: 5| Step: 5
Training loss: 2.902196168899536
Validation loss: 2.3331654815263647

Epoch: 5| Step: 6
Training loss: 2.690124988555908
Validation loss: 2.342120132138652

Epoch: 5| Step: 7
Training loss: 2.754822254180908
Validation loss: 2.339527832564487

Epoch: 5| Step: 8
Training loss: 2.790976047515869
Validation loss: 2.340858482545422

Epoch: 5| Step: 9
Training loss: 2.2452971935272217
Validation loss: 2.3466995249512377

Epoch: 5| Step: 10
Training loss: 1.8976104259490967
Validation loss: 2.3413985057543685

Epoch: 157| Step: 0
Training loss: 3.0561139583587646
Validation loss: 2.3631024283747517

Epoch: 5| Step: 1
Training loss: 1.9460655450820923
Validation loss: 2.3753873020090084

Epoch: 5| Step: 2
Training loss: 2.3771755695343018
Validation loss: 2.3923618126940984

Epoch: 5| Step: 3
Training loss: 2.944375991821289
Validation loss: 2.36945701542721

Epoch: 5| Step: 4
Training loss: 2.958059787750244
Validation loss: 2.3686491212537213

Epoch: 5| Step: 5
Training loss: 2.4337329864501953
Validation loss: 2.3672081680708033

Epoch: 5| Step: 6
Training loss: 2.4880645275115967
Validation loss: 2.3583755313709216

Epoch: 5| Step: 7
Training loss: 2.618826389312744
Validation loss: 2.3506711785511305

Epoch: 5| Step: 8
Training loss: 2.6460447311401367
Validation loss: 2.3524726078074467

Epoch: 5| Step: 9
Training loss: 2.0483169555664062
Validation loss: 2.3355341034550823

Epoch: 5| Step: 10
Training loss: 2.6344451904296875
Validation loss: 2.3278903371544293

Epoch: 158| Step: 0
Training loss: 2.3136134147644043
Validation loss: 2.3243167784906205

Epoch: 5| Step: 1
Training loss: 2.2365152835845947
Validation loss: 2.3212726295635266

Epoch: 5| Step: 2
Training loss: 2.4142086505889893
Validation loss: 2.3253044928273847

Epoch: 5| Step: 3
Training loss: 2.1628668308258057
Validation loss: 2.328030929770521

Epoch: 5| Step: 4
Training loss: 2.638274669647217
Validation loss: 2.3300031744023806

Epoch: 5| Step: 5
Training loss: 2.9360899925231934
Validation loss: 2.3424635856382308

Epoch: 5| Step: 6
Training loss: 2.3377254009246826
Validation loss: 2.3446441875991

Epoch: 5| Step: 7
Training loss: 2.8571696281433105
Validation loss: 2.3560411314810477

Epoch: 5| Step: 8
Training loss: 2.363229513168335
Validation loss: 2.3695022188207155

Epoch: 5| Step: 9
Training loss: 2.552577018737793
Validation loss: 2.375775005227776

Epoch: 5| Step: 10
Training loss: 3.6091506481170654
Validation loss: 2.3838195467507965

Epoch: 159| Step: 0
Training loss: 2.906430244445801
Validation loss: 2.4020009143378145

Epoch: 5| Step: 1
Training loss: 2.4143528938293457
Validation loss: 2.393693483004006

Epoch: 5| Step: 2
Training loss: 2.8297526836395264
Validation loss: 2.417424560875021

Epoch: 5| Step: 3
Training loss: 2.9216504096984863
Validation loss: 2.424308310272873

Epoch: 5| Step: 4
Training loss: 2.4945294857025146
Validation loss: 2.4198367518763386

Epoch: 5| Step: 5
Training loss: 1.9725673198699951
Validation loss: 2.4106873389213317

Epoch: 5| Step: 6
Training loss: 2.0087530612945557
Validation loss: 2.3776822179876347

Epoch: 5| Step: 7
Training loss: 2.7873432636260986
Validation loss: 2.3526401801775862

Epoch: 5| Step: 8
Training loss: 2.7216365337371826
Validation loss: 2.3356500492301038

Epoch: 5| Step: 9
Training loss: 2.5103745460510254
Validation loss: 2.3262120036668676

Epoch: 5| Step: 10
Training loss: 2.771902084350586
Validation loss: 2.334142738772977

Epoch: 160| Step: 0
Training loss: 2.068366527557373
Validation loss: 2.341573974137665

Epoch: 5| Step: 1
Training loss: 2.257720947265625
Validation loss: 2.3425143559773765

Epoch: 5| Step: 2
Training loss: 2.392540693283081
Validation loss: 2.354776559337493

Epoch: 5| Step: 3
Training loss: 2.480045795440674
Validation loss: 2.3501855609237507

Epoch: 5| Step: 4
Training loss: 2.889009475708008
Validation loss: 2.3469794104176183

Epoch: 5| Step: 5
Training loss: 2.4793128967285156
Validation loss: 2.336504408108291

Epoch: 5| Step: 6
Training loss: 2.92964506149292
Validation loss: 2.34162732349929

Epoch: 5| Step: 7
Training loss: 2.9727704524993896
Validation loss: 2.3358243101386615

Epoch: 5| Step: 8
Training loss: 3.292731761932373
Validation loss: 2.357211353958294

Epoch: 5| Step: 9
Training loss: 2.630037784576416
Validation loss: 2.363560352274167

Epoch: 5| Step: 10
Training loss: 1.837896466255188
Validation loss: 2.3724799002370527

Epoch: 161| Step: 0
Training loss: 2.4445464611053467
Validation loss: 2.3735030030691497

Epoch: 5| Step: 1
Training loss: 2.407733917236328
Validation loss: 2.380178395137992

Epoch: 5| Step: 2
Training loss: 2.5313363075256348
Validation loss: 2.386078408969346

Epoch: 5| Step: 3
Training loss: 1.770700454711914
Validation loss: 2.3803512024623092

Epoch: 5| Step: 4
Training loss: 2.3373355865478516
Validation loss: 2.3637822315257084

Epoch: 5| Step: 5
Training loss: 2.9659712314605713
Validation loss: 2.3598601113083544

Epoch: 5| Step: 6
Training loss: 2.5656485557556152
Validation loss: 2.348748476274552

Epoch: 5| Step: 7
Training loss: 3.382012128829956
Validation loss: 2.347473754677721

Epoch: 5| Step: 8
Training loss: 2.641420841217041
Validation loss: 2.3368840832864084

Epoch: 5| Step: 9
Training loss: 2.1404502391815186
Validation loss: 2.3418465147736254

Epoch: 5| Step: 10
Training loss: 3.0226869583129883
Validation loss: 2.3374814730818554

Epoch: 162| Step: 0
Training loss: 2.450862407684326
Validation loss: 2.345803021102823

Epoch: 5| Step: 1
Training loss: 2.328549861907959
Validation loss: 2.3452088448309127

Epoch: 5| Step: 2
Training loss: 2.988219738006592
Validation loss: 2.353413253702143

Epoch: 5| Step: 3
Training loss: 2.486356019973755
Validation loss: 2.34577420450026

Epoch: 5| Step: 4
Training loss: 3.1971817016601562
Validation loss: 2.346068746300154

Epoch: 5| Step: 5
Training loss: 1.8535118103027344
Validation loss: 2.346143312351678

Epoch: 5| Step: 6
Training loss: 2.8852651119232178
Validation loss: 2.345998703792531

Epoch: 5| Step: 7
Training loss: 2.6220650672912598
Validation loss: 2.3571944928938344

Epoch: 5| Step: 8
Training loss: 1.674279808998108
Validation loss: 2.355820814768473

Epoch: 5| Step: 9
Training loss: 2.59248423576355
Validation loss: 2.366520115124282

Epoch: 5| Step: 10
Training loss: 2.961812973022461
Validation loss: 2.3700019646716375

Epoch: 163| Step: 0
Training loss: 3.0239248275756836
Validation loss: 2.3810522863941808

Epoch: 5| Step: 1
Training loss: 2.426772356033325
Validation loss: 2.3665388925101167

Epoch: 5| Step: 2
Training loss: 2.395616054534912
Validation loss: 2.3706148580838273

Epoch: 5| Step: 3
Training loss: 2.8420708179473877
Validation loss: 2.357721902990854

Epoch: 5| Step: 4
Training loss: 2.0621089935302734
Validation loss: 2.347791802498602

Epoch: 5| Step: 5
Training loss: 2.7626290321350098
Validation loss: 2.357167056811753

Epoch: 5| Step: 6
Training loss: 2.1212525367736816
Validation loss: 2.3737927431701333

Epoch: 5| Step: 7
Training loss: 2.4535558223724365
Validation loss: 2.3727669715881348

Epoch: 5| Step: 8
Training loss: 2.5221946239471436
Validation loss: 2.3751393389958206

Epoch: 5| Step: 9
Training loss: 2.401517868041992
Validation loss: 2.374227113621209

Epoch: 5| Step: 10
Training loss: 3.2190017700195312
Validation loss: 2.361720164616903

Epoch: 164| Step: 0
Training loss: 1.8372414112091064
Validation loss: 2.362145129070487

Epoch: 5| Step: 1
Training loss: 2.0678954124450684
Validation loss: 2.3544293680498676

Epoch: 5| Step: 2
Training loss: 2.2997193336486816
Validation loss: 2.3421404207906416

Epoch: 5| Step: 3
Training loss: 2.2745730876922607
Validation loss: 2.3413214760441936

Epoch: 5| Step: 4
Training loss: 3.045391321182251
Validation loss: 2.344297509039602

Epoch: 5| Step: 5
Training loss: 3.001939296722412
Validation loss: 2.3511448649949926

Epoch: 5| Step: 6
Training loss: 2.8246397972106934
Validation loss: 2.3548110249221965

Epoch: 5| Step: 7
Training loss: 2.2321343421936035
Validation loss: 2.3431285094189387

Epoch: 5| Step: 8
Training loss: 3.1123299598693848
Validation loss: 2.3455175686908025

Epoch: 5| Step: 9
Training loss: 2.6454455852508545
Validation loss: 2.328477474950975

Epoch: 5| Step: 10
Training loss: 2.695676803588867
Validation loss: 2.3128414641144457

Epoch: 165| Step: 0
Training loss: 3.045348644256592
Validation loss: 2.3199665315689577

Epoch: 5| Step: 1
Training loss: 2.582873821258545
Validation loss: 2.3228137134223856

Epoch: 5| Step: 2
Training loss: 2.183544635772705
Validation loss: 2.31554251845165

Epoch: 5| Step: 3
Training loss: 2.31640625
Validation loss: 2.313944075697212

Epoch: 5| Step: 4
Training loss: 2.487025499343872
Validation loss: 2.315400687597131

Epoch: 5| Step: 5
Training loss: 2.1345038414001465
Validation loss: 2.312899176792432

Epoch: 5| Step: 6
Training loss: 2.7871956825256348
Validation loss: 2.3183341667216313

Epoch: 5| Step: 7
Training loss: 3.187398910522461
Validation loss: 2.3364762439522693

Epoch: 5| Step: 8
Training loss: 2.3274006843566895
Validation loss: 2.338349752528693

Epoch: 5| Step: 9
Training loss: 2.948312759399414
Validation loss: 2.347259913721392

Epoch: 5| Step: 10
Training loss: 2.082554817199707
Validation loss: 2.3417891251143588

Epoch: 166| Step: 0
Training loss: 2.7193431854248047
Validation loss: 2.3511697810183287

Epoch: 5| Step: 1
Training loss: 2.16009521484375
Validation loss: 2.347352079165879

Epoch: 5| Step: 2
Training loss: 2.9152727127075195
Validation loss: 2.343358835866374

Epoch: 5| Step: 3
Training loss: 2.102766990661621
Validation loss: 2.335592431406821

Epoch: 5| Step: 4
Training loss: 2.4304680824279785
Validation loss: 2.3362195132881083

Epoch: 5| Step: 5
Training loss: 2.9111599922180176
Validation loss: 2.331672578729609

Epoch: 5| Step: 6
Training loss: 2.617384433746338
Validation loss: 2.3373194535573325

Epoch: 5| Step: 7
Training loss: 2.4733169078826904
Validation loss: 2.3346274360533683

Epoch: 5| Step: 8
Training loss: 2.2589504718780518
Validation loss: 2.336989571971278

Epoch: 5| Step: 9
Training loss: 2.7188515663146973
Validation loss: 2.3407330102817987

Epoch: 5| Step: 10
Training loss: 2.570009231567383
Validation loss: 2.3398129068395144

Epoch: 167| Step: 0
Training loss: 2.1337673664093018
Validation loss: 2.3503620803997083

Epoch: 5| Step: 1
Training loss: 2.1501641273498535
Validation loss: 2.3514851780347925

Epoch: 5| Step: 2
Training loss: 2.6334261894226074
Validation loss: 2.363539372721026

Epoch: 5| Step: 3
Training loss: 2.263430595397949
Validation loss: 2.3647174194294918

Epoch: 5| Step: 4
Training loss: 2.9369044303894043
Validation loss: 2.3835163347182737

Epoch: 5| Step: 5
Training loss: 2.5821781158447266
Validation loss: 2.37518302599589

Epoch: 5| Step: 6
Training loss: 2.864260196685791
Validation loss: 2.369746179990871

Epoch: 5| Step: 7
Training loss: 2.563213348388672
Validation loss: 2.3498819745996946

Epoch: 5| Step: 8
Training loss: 2.566148281097412
Validation loss: 2.331947265132781

Epoch: 5| Step: 9
Training loss: 2.8667075634002686
Validation loss: 2.337379406857234

Epoch: 5| Step: 10
Training loss: 2.319051504135132
Validation loss: 2.3301133289132068

Epoch: 168| Step: 0
Training loss: 3.078807830810547
Validation loss: 2.342232770817254

Epoch: 5| Step: 1
Training loss: 2.9889330863952637
Validation loss: 2.3362041083715295

Epoch: 5| Step: 2
Training loss: 2.3055176734924316
Validation loss: 2.341092889026929

Epoch: 5| Step: 3
Training loss: 2.425403356552124
Validation loss: 2.3349030838217786

Epoch: 5| Step: 4
Training loss: 3.1322009563446045
Validation loss: 2.337332299960557

Epoch: 5| Step: 5
Training loss: 2.670647144317627
Validation loss: 2.3416526984143

Epoch: 5| Step: 6
Training loss: 2.5898566246032715
Validation loss: 2.3355161143887426

Epoch: 5| Step: 7
Training loss: 1.7813886404037476
Validation loss: 2.3489798550964682

Epoch: 5| Step: 8
Training loss: 2.4170212745666504
Validation loss: 2.335919851897865

Epoch: 5| Step: 9
Training loss: 2.4091603755950928
Validation loss: 2.341881231595111

Epoch: 5| Step: 10
Training loss: 2.110326051712036
Validation loss: 2.3389870761543192

Epoch: 169| Step: 0
Training loss: 2.158165454864502
Validation loss: 2.327027032452245

Epoch: 5| Step: 1
Training loss: 2.3198819160461426
Validation loss: 2.329534476803195

Epoch: 5| Step: 2
Training loss: 2.0513100624084473
Validation loss: 2.328956896258939

Epoch: 5| Step: 3
Training loss: 2.6482295989990234
Validation loss: 2.3319167911365466

Epoch: 5| Step: 4
Training loss: 3.351513385772705
Validation loss: 2.3318814641685894

Epoch: 5| Step: 5
Training loss: 2.3757710456848145
Validation loss: 2.3283691739523285

Epoch: 5| Step: 6
Training loss: 2.7958786487579346
Validation loss: 2.3368916280807985

Epoch: 5| Step: 7
Training loss: 2.6306402683258057
Validation loss: 2.341871348760461

Epoch: 5| Step: 8
Training loss: 2.404998302459717
Validation loss: 2.344703692261891

Epoch: 5| Step: 9
Training loss: 2.2508065700531006
Validation loss: 2.341029444048482

Epoch: 5| Step: 10
Training loss: 2.8010501861572266
Validation loss: 2.349320298881941

Epoch: 170| Step: 0
Training loss: 2.199575662612915
Validation loss: 2.3487572541800876

Epoch: 5| Step: 1
Training loss: 2.3358445167541504
Validation loss: 2.334092955435476

Epoch: 5| Step: 2
Training loss: 2.728519916534424
Validation loss: 2.337047538449687

Epoch: 5| Step: 3
Training loss: 2.3288521766662598
Validation loss: 2.32319466785718

Epoch: 5| Step: 4
Training loss: 2.47320294380188
Validation loss: 2.344018477265553

Epoch: 5| Step: 5
Training loss: 2.976041555404663
Validation loss: 2.337148094689974

Epoch: 5| Step: 6
Training loss: 2.8871867656707764
Validation loss: 2.329955682959608

Epoch: 5| Step: 7
Training loss: 2.4367475509643555
Validation loss: 2.3200502651993946

Epoch: 5| Step: 8
Training loss: 2.99479079246521
Validation loss: 2.314747602708878

Epoch: 5| Step: 9
Training loss: 2.367448329925537
Validation loss: 2.314741711462698

Epoch: 5| Step: 10
Training loss: 2.0472769737243652
Validation loss: 2.321039504902337

Epoch: 171| Step: 0
Training loss: 2.537055253982544
Validation loss: 2.3222013724747526

Epoch: 5| Step: 1
Training loss: 2.060485601425171
Validation loss: 2.324277288170271

Epoch: 5| Step: 2
Training loss: 2.554197311401367
Validation loss: 2.3365933267019128

Epoch: 5| Step: 3
Training loss: 2.4242019653320312
Validation loss: 2.336396558310396

Epoch: 5| Step: 4
Training loss: 2.298396587371826
Validation loss: 2.338776506403441

Epoch: 5| Step: 5
Training loss: 2.5970237255096436
Validation loss: 2.348795719044183

Epoch: 5| Step: 6
Training loss: 2.1386451721191406
Validation loss: 2.3359941128761537

Epoch: 5| Step: 7
Training loss: 2.7146074771881104
Validation loss: 2.333134135892314

Epoch: 5| Step: 8
Training loss: 2.8893744945526123
Validation loss: 2.3200821030524468

Epoch: 5| Step: 9
Training loss: 3.1534829139709473
Validation loss: 2.319296504861565

Epoch: 5| Step: 10
Training loss: 2.3210442066192627
Validation loss: 2.3297445645896335

Epoch: 172| Step: 0
Training loss: 1.8792078495025635
Validation loss: 2.3216641820887083

Epoch: 5| Step: 1
Training loss: 2.566061019897461
Validation loss: 2.3273006792991393

Epoch: 5| Step: 2
Training loss: 2.822483777999878
Validation loss: 2.330377963281447

Epoch: 5| Step: 3
Training loss: 2.597569704055786
Validation loss: 2.331447711554907

Epoch: 5| Step: 4
Training loss: 2.4868462085723877
Validation loss: 2.3345114261873308

Epoch: 5| Step: 5
Training loss: 2.9803309440612793
Validation loss: 2.330644110197662

Epoch: 5| Step: 6
Training loss: 2.8101401329040527
Validation loss: 2.3308324865115586

Epoch: 5| Step: 7
Training loss: 2.7704834938049316
Validation loss: 2.3362144270250873

Epoch: 5| Step: 8
Training loss: 2.185126781463623
Validation loss: 2.331599691862701

Epoch: 5| Step: 9
Training loss: 2.5791916847229004
Validation loss: 2.322405307523666

Epoch: 5| Step: 10
Training loss: 1.9714584350585938
Validation loss: 2.3200833848727647

Epoch: 173| Step: 0
Training loss: 3.11090350151062
Validation loss: 2.3281438812132804

Epoch: 5| Step: 1
Training loss: 1.9834305047988892
Validation loss: 2.303001193590062

Epoch: 5| Step: 2
Training loss: 2.643298864364624
Validation loss: 2.309219947425268

Epoch: 5| Step: 3
Training loss: 1.6790657043457031
Validation loss: 2.3152235246473745

Epoch: 5| Step: 4
Training loss: 2.132737398147583
Validation loss: 2.3085964597681516

Epoch: 5| Step: 5
Training loss: 2.9529175758361816
Validation loss: 2.334558474120273

Epoch: 5| Step: 6
Training loss: 3.2237708568573
Validation loss: 2.322722101724276

Epoch: 5| Step: 7
Training loss: 2.3808276653289795
Validation loss: 2.324260687315336

Epoch: 5| Step: 8
Training loss: 2.8102498054504395
Validation loss: 2.3171014760130193

Epoch: 5| Step: 9
Training loss: 2.7129065990448
Validation loss: 2.305028151440364

Epoch: 5| Step: 10
Training loss: 2.003469467163086
Validation loss: 2.3123532905373523

Epoch: 174| Step: 0
Training loss: 2.7469756603240967
Validation loss: 2.322613784061965

Epoch: 5| Step: 1
Training loss: 2.5393810272216797
Validation loss: 2.335322808193904

Epoch: 5| Step: 2
Training loss: 2.6196494102478027
Validation loss: 2.332939470967939

Epoch: 5| Step: 3
Training loss: 2.1749653816223145
Validation loss: 2.3391515824102584

Epoch: 5| Step: 4
Training loss: 2.5597989559173584
Validation loss: 2.3275274512588338

Epoch: 5| Step: 5
Training loss: 2.1645748615264893
Validation loss: 2.307095278975784

Epoch: 5| Step: 6
Training loss: 3.4793810844421387
Validation loss: 2.2924660969805974

Epoch: 5| Step: 7
Training loss: 2.1103336811065674
Validation loss: 2.293750753966711

Epoch: 5| Step: 8
Training loss: 2.6650280952453613
Validation loss: 2.2838486676575034

Epoch: 5| Step: 9
Training loss: 2.0592222213745117
Validation loss: 2.286418855831187

Epoch: 5| Step: 10
Training loss: 2.6645853519439697
Validation loss: 2.3005079197627243

Epoch: 175| Step: 0
Training loss: 2.674147367477417
Validation loss: 2.30795039925524

Epoch: 5| Step: 1
Training loss: 1.9575660228729248
Validation loss: 2.304775132927843

Epoch: 5| Step: 2
Training loss: 2.761413097381592
Validation loss: 2.31218352881811

Epoch: 5| Step: 3
Training loss: 2.7566580772399902
Validation loss: 2.3188093452043432

Epoch: 5| Step: 4
Training loss: 2.550816774368286
Validation loss: 2.320609623386014

Epoch: 5| Step: 5
Training loss: 1.926148772239685
Validation loss: 2.336844322501972

Epoch: 5| Step: 6
Training loss: 2.6368322372436523
Validation loss: 2.351007492311539

Epoch: 5| Step: 7
Training loss: 2.250185966491699
Validation loss: 2.361759021718015

Epoch: 5| Step: 8
Training loss: 2.7340283393859863
Validation loss: 2.371759278799898

Epoch: 5| Step: 9
Training loss: 2.617305040359497
Validation loss: 2.380346667382025

Epoch: 5| Step: 10
Training loss: 2.889557361602783
Validation loss: 2.36353995210381

Epoch: 176| Step: 0
Training loss: 2.552666664123535
Validation loss: 2.3428433043982393

Epoch: 5| Step: 1
Training loss: 2.328098773956299
Validation loss: 2.3426381362381803

Epoch: 5| Step: 2
Training loss: 2.284029722213745
Validation loss: 2.3288514255195536

Epoch: 5| Step: 3
Training loss: 2.361370325088501
Validation loss: 2.3150568136604885

Epoch: 5| Step: 4
Training loss: 3.2616710662841797
Validation loss: 2.304917147082667

Epoch: 5| Step: 5
Training loss: 2.938275098800659
Validation loss: 2.298579574913107

Epoch: 5| Step: 6
Training loss: 2.6446914672851562
Validation loss: 2.302271125137165

Epoch: 5| Step: 7
Training loss: 2.8437938690185547
Validation loss: 2.296753829525363

Epoch: 5| Step: 8
Training loss: 1.5875484943389893
Validation loss: 2.2936016282727643

Epoch: 5| Step: 9
Training loss: 2.5441789627075195
Validation loss: 2.296521120173957

Epoch: 5| Step: 10
Training loss: 2.118335723876953
Validation loss: 2.2903930935808408

Epoch: 177| Step: 0
Training loss: 2.2923789024353027
Validation loss: 2.2859638762730423

Epoch: 5| Step: 1
Training loss: 2.2479453086853027
Validation loss: 2.2916581169251473

Epoch: 5| Step: 2
Training loss: 3.143454074859619
Validation loss: 2.2921431679879465

Epoch: 5| Step: 3
Training loss: 2.507678985595703
Validation loss: 2.2974115904941352

Epoch: 5| Step: 4
Training loss: 2.5821690559387207
Validation loss: 2.302948587684221

Epoch: 5| Step: 5
Training loss: 1.788268804550171
Validation loss: 2.3205956412899877

Epoch: 5| Step: 6
Training loss: 2.8474509716033936
Validation loss: 2.3051833183534685

Epoch: 5| Step: 7
Training loss: 2.6270499229431152
Validation loss: 2.3036416499845442

Epoch: 5| Step: 8
Training loss: 2.469383955001831
Validation loss: 2.2951164399423907

Epoch: 5| Step: 9
Training loss: 2.4019715785980225
Validation loss: 2.285355649968629

Epoch: 5| Step: 10
Training loss: 2.663541555404663
Validation loss: 2.294451185452041

Epoch: 178| Step: 0
Training loss: 2.0856521129608154
Validation loss: 2.294837967042

Epoch: 5| Step: 1
Training loss: 2.749736785888672
Validation loss: 2.311140670571276

Epoch: 5| Step: 2
Training loss: 2.4996769428253174
Validation loss: 2.3212827277439896

Epoch: 5| Step: 3
Training loss: 2.0110652446746826
Validation loss: 2.337349917299004

Epoch: 5| Step: 4
Training loss: 2.459834337234497
Validation loss: 2.343616798359861

Epoch: 5| Step: 5
Training loss: 2.281376838684082
Validation loss: 2.349242905134796

Epoch: 5| Step: 6
Training loss: 3.2957568168640137
Validation loss: 2.3702807195724978

Epoch: 5| Step: 7
Training loss: 1.7927532196044922
Validation loss: 2.3755450325627483

Epoch: 5| Step: 8
Training loss: 2.4921154975891113
Validation loss: 2.3942319731558523

Epoch: 5| Step: 9
Training loss: 2.7355868816375732
Validation loss: 2.380271447602139

Epoch: 5| Step: 10
Training loss: 3.355059862136841
Validation loss: 2.3423446404036654

Epoch: 179| Step: 0
Training loss: 2.4319159984588623
Validation loss: 2.325636648362683

Epoch: 5| Step: 1
Training loss: 2.220235824584961
Validation loss: 2.3083577386794554

Epoch: 5| Step: 2
Training loss: 2.4324047565460205
Validation loss: 2.309254938556302

Epoch: 5| Step: 3
Training loss: 2.8127543926239014
Validation loss: 2.305082300657867

Epoch: 5| Step: 4
Training loss: 2.7689032554626465
Validation loss: 2.309816852692635

Epoch: 5| Step: 5
Training loss: 2.6569740772247314
Validation loss: 2.306107738966583

Epoch: 5| Step: 6
Training loss: 2.5376198291778564
Validation loss: 2.299333095550537

Epoch: 5| Step: 7
Training loss: 2.2577998638153076
Validation loss: 2.3046559800383863

Epoch: 5| Step: 8
Training loss: 2.5212249755859375
Validation loss: 2.3003216840887584

Epoch: 5| Step: 9
Training loss: 2.804065704345703
Validation loss: 2.301165642276887

Epoch: 5| Step: 10
Training loss: 2.1056180000305176
Validation loss: 2.2906690848770963

Epoch: 180| Step: 0
Training loss: 2.25201416015625
Validation loss: 2.291749087713098

Epoch: 5| Step: 1
Training loss: 1.6983850002288818
Validation loss: 2.301955649929662

Epoch: 5| Step: 2
Training loss: 2.933849573135376
Validation loss: 2.317274772992698

Epoch: 5| Step: 3
Training loss: 2.763296127319336
Validation loss: 2.341684966958979

Epoch: 5| Step: 4
Training loss: 1.8939192295074463
Validation loss: 2.3323101894829863

Epoch: 5| Step: 5
Training loss: 2.674222707748413
Validation loss: 2.3173247844942155

Epoch: 5| Step: 6
Training loss: 2.857189893722534
Validation loss: 2.312246604632306

Epoch: 5| Step: 7
Training loss: 2.436260223388672
Validation loss: 2.293227590540404

Epoch: 5| Step: 8
Training loss: 2.0236971378326416
Validation loss: 2.291484599472374

Epoch: 5| Step: 9
Training loss: 3.3717384338378906
Validation loss: 2.2830638552224762

Epoch: 5| Step: 10
Training loss: 2.655158519744873
Validation loss: 2.2840888192576747

Epoch: 181| Step: 0
Training loss: 3.0793943405151367
Validation loss: 2.290179516679497

Epoch: 5| Step: 1
Training loss: 2.5219297409057617
Validation loss: 2.3059110205660582

Epoch: 5| Step: 2
Training loss: 2.248922824859619
Validation loss: 2.305734999718205

Epoch: 5| Step: 3
Training loss: 3.0171070098876953
Validation loss: 2.307122745821553

Epoch: 5| Step: 4
Training loss: 2.337907552719116
Validation loss: 2.3130990894891883

Epoch: 5| Step: 5
Training loss: 2.2723937034606934
Validation loss: 2.322818863776422

Epoch: 5| Step: 6
Training loss: 2.8898873329162598
Validation loss: 2.315728937425921

Epoch: 5| Step: 7
Training loss: 1.8260997533798218
Validation loss: 2.3069236022169872

Epoch: 5| Step: 8
Training loss: 1.9413530826568604
Validation loss: 2.30897879856889

Epoch: 5| Step: 9
Training loss: 2.5680019855499268
Validation loss: 2.305444117515318

Epoch: 5| Step: 10
Training loss: 2.7899794578552246
Validation loss: 2.3163871918955157

Epoch: 182| Step: 0
Training loss: 2.507800340652466
Validation loss: 2.330509167845531

Epoch: 5| Step: 1
Training loss: 2.4242746829986572
Validation loss: 2.3448756715302825

Epoch: 5| Step: 2
Training loss: 2.6993656158447266
Validation loss: 2.3280922059089906

Epoch: 5| Step: 3
Training loss: 2.8501129150390625
Validation loss: 2.3010131441136843

Epoch: 5| Step: 4
Training loss: 2.8166663646698
Validation loss: 2.2866161971963863

Epoch: 5| Step: 5
Training loss: 2.0700628757476807
Validation loss: 2.284816954725532

Epoch: 5| Step: 6
Training loss: 2.0010979175567627
Validation loss: 2.2782839139302573

Epoch: 5| Step: 7
Training loss: 2.1876676082611084
Validation loss: 2.2961470952597995

Epoch: 5| Step: 8
Training loss: 3.081920862197876
Validation loss: 2.300356029182352

Epoch: 5| Step: 9
Training loss: 2.6216580867767334
Validation loss: 2.3118265892869685

Epoch: 5| Step: 10
Training loss: 2.3723230361938477
Validation loss: 2.3205777291328675

Epoch: 183| Step: 0
Training loss: 2.775440216064453
Validation loss: 2.3170207264602825

Epoch: 5| Step: 1
Training loss: 2.478905439376831
Validation loss: 2.317978069346438

Epoch: 5| Step: 2
Training loss: 2.239126205444336
Validation loss: 2.3089951161415345

Epoch: 5| Step: 3
Training loss: 2.4716572761535645
Validation loss: 2.319704496732322

Epoch: 5| Step: 4
Training loss: 2.2696373462677
Validation loss: 2.3224420880758636

Epoch: 5| Step: 5
Training loss: 2.880779504776001
Validation loss: 2.322758282384565

Epoch: 5| Step: 6
Training loss: 2.1345362663269043
Validation loss: 2.3460544514399704

Epoch: 5| Step: 7
Training loss: 2.585094451904297
Validation loss: 2.3397636285392185

Epoch: 5| Step: 8
Training loss: 2.0447511672973633
Validation loss: 2.3403547194696244

Epoch: 5| Step: 9
Training loss: 2.963359832763672
Validation loss: 2.3318679768552064

Epoch: 5| Step: 10
Training loss: 2.737744092941284
Validation loss: 2.3073967938782065

Epoch: 184| Step: 0
Training loss: 2.7952141761779785
Validation loss: 2.299463777131932

Epoch: 5| Step: 1
Training loss: 1.945455551147461
Validation loss: 2.2865386163034747

Epoch: 5| Step: 2
Training loss: 2.5868980884552
Validation loss: 2.301453344283565

Epoch: 5| Step: 3
Training loss: 2.9695675373077393
Validation loss: 2.3079852929679294

Epoch: 5| Step: 4
Training loss: 2.7467987537384033
Validation loss: 2.315338134765625

Epoch: 5| Step: 5
Training loss: 2.264409303665161
Validation loss: 2.318436109891502

Epoch: 5| Step: 6
Training loss: 2.3067257404327393
Validation loss: 2.3183347486680552

Epoch: 5| Step: 7
Training loss: 1.949235200881958
Validation loss: 2.3101416249429025

Epoch: 5| Step: 8
Training loss: 3.1300578117370605
Validation loss: 2.305307868988283

Epoch: 5| Step: 9
Training loss: 2.3421080112457275
Validation loss: 2.3144693630997852

Epoch: 5| Step: 10
Training loss: 2.3625564575195312
Validation loss: 2.3194530599860737

Epoch: 185| Step: 0
Training loss: 2.953280210494995
Validation loss: 2.338138245767163

Epoch: 5| Step: 1
Training loss: 2.0998756885528564
Validation loss: 2.3514614233406643

Epoch: 5| Step: 2
Training loss: 2.2344651222229004
Validation loss: 2.365938542991556

Epoch: 5| Step: 3
Training loss: 2.7248244285583496
Validation loss: 2.377404728243428

Epoch: 5| Step: 4
Training loss: 2.293508768081665
Validation loss: 2.358368364713525

Epoch: 5| Step: 5
Training loss: 2.8301031589508057
Validation loss: 2.3215315136858212

Epoch: 5| Step: 6
Training loss: 2.2810418605804443
Validation loss: 2.294229899683306

Epoch: 5| Step: 7
Training loss: 2.04738187789917
Validation loss: 2.2823349147714596

Epoch: 5| Step: 8
Training loss: 2.6529433727264404
Validation loss: 2.276921659387568

Epoch: 5| Step: 9
Training loss: 3.042414426803589
Validation loss: 2.2926049360664944

Epoch: 5| Step: 10
Training loss: 2.3362812995910645
Validation loss: 2.3090163635951217

Epoch: 186| Step: 0
Training loss: 2.441601276397705
Validation loss: 2.3073853318409254

Epoch: 5| Step: 1
Training loss: 2.6563758850097656
Validation loss: 2.2851319338685725

Epoch: 5| Step: 2
Training loss: 2.90582537651062
Validation loss: 2.2894784404385473

Epoch: 5| Step: 3
Training loss: 2.168604612350464
Validation loss: 2.2951852531843286

Epoch: 5| Step: 4
Training loss: 2.0014615058898926
Validation loss: 2.2823784043712

Epoch: 5| Step: 5
Training loss: 1.7795438766479492
Validation loss: 2.2848275041067474

Epoch: 5| Step: 6
Training loss: 2.7703096866607666
Validation loss: 2.2987892602079656

Epoch: 5| Step: 7
Training loss: 2.14768123626709
Validation loss: 2.324214184156028

Epoch: 5| Step: 8
Training loss: 3.081392765045166
Validation loss: 2.367806144939956

Epoch: 5| Step: 9
Training loss: 3.101735830307007
Validation loss: 2.3480440698644167

Epoch: 5| Step: 10
Training loss: 2.2487666606903076
Validation loss: 2.337119604951592

Epoch: 187| Step: 0
Training loss: 3.184506893157959
Validation loss: 2.318837240178098

Epoch: 5| Step: 1
Training loss: 2.622203826904297
Validation loss: 2.3313300045587684

Epoch: 5| Step: 2
Training loss: 2.6939215660095215
Validation loss: 2.3141761287566154

Epoch: 5| Step: 3
Training loss: 2.867339611053467
Validation loss: 2.304863683639034

Epoch: 5| Step: 4
Training loss: 1.6368341445922852
Validation loss: 2.298113183308673

Epoch: 5| Step: 5
Training loss: 2.152059555053711
Validation loss: 2.2656040730014926

Epoch: 5| Step: 6
Training loss: 1.9736915826797485
Validation loss: 2.2518903670772428

Epoch: 5| Step: 7
Training loss: 2.6716437339782715
Validation loss: 2.2505931008246636

Epoch: 5| Step: 8
Training loss: 2.4363484382629395
Validation loss: 2.2582972408622823

Epoch: 5| Step: 9
Training loss: 2.670306921005249
Validation loss: 2.2514267711229223

Epoch: 5| Step: 10
Training loss: 2.253490924835205
Validation loss: 2.2580375056112967

Epoch: 188| Step: 0
Training loss: 2.070920467376709
Validation loss: 2.262092154513123

Epoch: 5| Step: 1
Training loss: 1.794190764427185
Validation loss: 2.258693077230966

Epoch: 5| Step: 2
Training loss: 2.6426608562469482
Validation loss: 2.2735896674535607

Epoch: 5| Step: 3
Training loss: 2.159618854522705
Validation loss: 2.286049319851783

Epoch: 5| Step: 4
Training loss: 2.9047956466674805
Validation loss: 2.292811652665497

Epoch: 5| Step: 5
Training loss: 2.8635573387145996
Validation loss: 2.3065768006027385

Epoch: 5| Step: 6
Training loss: 2.0687646865844727
Validation loss: 2.306269138090072

Epoch: 5| Step: 7
Training loss: 2.493678569793701
Validation loss: 2.3112475026038384

Epoch: 5| Step: 8
Training loss: 3.1339266300201416
Validation loss: 2.312673266215991

Epoch: 5| Step: 9
Training loss: 2.5692267417907715
Validation loss: 2.3048397956355924

Epoch: 5| Step: 10
Training loss: 2.4411799907684326
Validation loss: 2.298050929141301

Epoch: 189| Step: 0
Training loss: 2.613847017288208
Validation loss: 2.2831693900528776

Epoch: 5| Step: 1
Training loss: 2.850435256958008
Validation loss: 2.301103430409585

Epoch: 5| Step: 2
Training loss: 2.894319534301758
Validation loss: 2.2772108508694555

Epoch: 5| Step: 3
Training loss: 1.866223931312561
Validation loss: 2.278667622996915

Epoch: 5| Step: 4
Training loss: 2.3481838703155518
Validation loss: 2.2815886441097466

Epoch: 5| Step: 5
Training loss: 2.2761614322662354
Validation loss: 2.2898430183369625

Epoch: 5| Step: 6
Training loss: 2.391328811645508
Validation loss: 2.2930102937964985

Epoch: 5| Step: 7
Training loss: 3.0653536319732666
Validation loss: 2.295855547792168

Epoch: 5| Step: 8
Training loss: 2.007477283477783
Validation loss: 2.2885470031410136

Epoch: 5| Step: 9
Training loss: 2.6350433826446533
Validation loss: 2.2877042267912175

Epoch: 5| Step: 10
Training loss: 1.9112889766693115
Validation loss: 2.2922603930196455

Epoch: 190| Step: 0
Training loss: 3.1862311363220215
Validation loss: 2.281734025606545

Epoch: 5| Step: 1
Training loss: 2.1769838333129883
Validation loss: 2.2770575310594294

Epoch: 5| Step: 2
Training loss: 2.2387824058532715
Validation loss: 2.2684939958715953

Epoch: 5| Step: 3
Training loss: 1.7225786447525024
Validation loss: 2.2716845696972263

Epoch: 5| Step: 4
Training loss: 2.4462170600891113
Validation loss: 2.2647526469281924

Epoch: 5| Step: 5
Training loss: 1.9039411544799805
Validation loss: 2.2677977008204304

Epoch: 5| Step: 6
Training loss: 2.4695451259613037
Validation loss: 2.2622096384725263

Epoch: 5| Step: 7
Training loss: 2.9080066680908203
Validation loss: 2.27382904483426

Epoch: 5| Step: 8
Training loss: 2.329345226287842
Validation loss: 2.2795728047688804

Epoch: 5| Step: 9
Training loss: 2.6923999786376953
Validation loss: 2.2911226980147825

Epoch: 5| Step: 10
Training loss: 2.8737809658050537
Validation loss: 2.3136028987105175

Epoch: 191| Step: 0
Training loss: 2.9744577407836914
Validation loss: 2.317714697571211

Epoch: 5| Step: 1
Training loss: 2.510530948638916
Validation loss: 2.3074263590638355

Epoch: 5| Step: 2
Training loss: 2.5446557998657227
Validation loss: 2.2977009742490706

Epoch: 5| Step: 3
Training loss: 2.9247634410858154
Validation loss: 2.2807885267401256

Epoch: 5| Step: 4
Training loss: 2.3034932613372803
Validation loss: 2.274531341368152

Epoch: 5| Step: 5
Training loss: 1.9199726581573486
Validation loss: 2.264282038134913

Epoch: 5| Step: 6
Training loss: 2.6633949279785156
Validation loss: 2.269688288370768

Epoch: 5| Step: 7
Training loss: 2.564150333404541
Validation loss: 2.270890801183639

Epoch: 5| Step: 8
Training loss: 2.4088377952575684
Validation loss: 2.25786026318868

Epoch: 5| Step: 9
Training loss: 1.9908654689788818
Validation loss: 2.2576958748602096

Epoch: 5| Step: 10
Training loss: 2.078218698501587
Validation loss: 2.258904985202256

Epoch: 192| Step: 0
Training loss: 2.4413459300994873
Validation loss: 2.28234080729946

Epoch: 5| Step: 1
Training loss: 1.967543601989746
Validation loss: 2.304337760453583

Epoch: 5| Step: 2
Training loss: 2.7747626304626465
Validation loss: 2.3347416359891175

Epoch: 5| Step: 3
Training loss: 2.8207504749298096
Validation loss: 2.3658287294449343

Epoch: 5| Step: 4
Training loss: 2.2531282901763916
Validation loss: 2.360450267791748

Epoch: 5| Step: 5
Training loss: 2.3650753498077393
Validation loss: 2.3345272156500045

Epoch: 5| Step: 6
Training loss: 2.645505905151367
Validation loss: 2.31101575205403

Epoch: 5| Step: 7
Training loss: 2.4950804710388184
Validation loss: 2.2896723055070445

Epoch: 5| Step: 8
Training loss: 2.822913646697998
Validation loss: 2.2752814087816464

Epoch: 5| Step: 9
Training loss: 2.301600217819214
Validation loss: 2.259610160704582

Epoch: 5| Step: 10
Training loss: 1.9920077323913574
Validation loss: 2.2643451357400544

Epoch: 193| Step: 0
Training loss: 2.5286552906036377
Validation loss: 2.2881467496195147

Epoch: 5| Step: 1
Training loss: 2.90157413482666
Validation loss: 2.275451180755451

Epoch: 5| Step: 2
Training loss: 2.8642959594726562
Validation loss: 2.263689641029604

Epoch: 5| Step: 3
Training loss: 2.1851656436920166
Validation loss: 2.2590381086513562

Epoch: 5| Step: 4
Training loss: 2.6446526050567627
Validation loss: 2.2692647800650647

Epoch: 5| Step: 5
Training loss: 2.5127570629119873
Validation loss: 2.254388504130866

Epoch: 5| Step: 6
Training loss: 2.2067012786865234
Validation loss: 2.255370631012865

Epoch: 5| Step: 7
Training loss: 2.0128867626190186
Validation loss: 2.264721849913238

Epoch: 5| Step: 8
Training loss: 3.0042102336883545
Validation loss: 2.2783943786416003

Epoch: 5| Step: 9
Training loss: 2.1001639366149902
Validation loss: 2.299371316868772

Epoch: 5| Step: 10
Training loss: 1.8389194011688232
Validation loss: 2.2993000066408547

Epoch: 194| Step: 0
Training loss: 2.647050380706787
Validation loss: 2.300470294490937

Epoch: 5| Step: 1
Training loss: 2.1975722312927246
Validation loss: 2.3080746384077173

Epoch: 5| Step: 2
Training loss: 2.6860058307647705
Validation loss: 2.310941337257303

Epoch: 5| Step: 3
Training loss: 2.7164418697357178
Validation loss: 2.3593921020466793

Epoch: 5| Step: 4
Training loss: 2.4545645713806152
Validation loss: 2.378444363993983

Epoch: 5| Step: 5
Training loss: 2.1721463203430176
Validation loss: 2.414701336173601

Epoch: 5| Step: 6
Training loss: 2.2054126262664795
Validation loss: 2.4020049110535653

Epoch: 5| Step: 7
Training loss: 2.453749895095825
Validation loss: 2.366888648720198

Epoch: 5| Step: 8
Training loss: 3.084014654159546
Validation loss: 2.320663159893405

Epoch: 5| Step: 9
Training loss: 2.732635974884033
Validation loss: 2.303943560969445

Epoch: 5| Step: 10
Training loss: 1.5853480100631714
Validation loss: 2.288955678222

Epoch: 195| Step: 0
Training loss: 2.3467483520507812
Validation loss: 2.2885292973569644

Epoch: 5| Step: 1
Training loss: 2.986057996749878
Validation loss: 2.2690292840362876

Epoch: 5| Step: 2
Training loss: 2.126483201980591
Validation loss: 2.2498829826231925

Epoch: 5| Step: 3
Training loss: 2.1441493034362793
Validation loss: 2.2358329347384873

Epoch: 5| Step: 4
Training loss: 1.8586742877960205
Validation loss: 2.235201411349799

Epoch: 5| Step: 5
Training loss: 2.0427846908569336
Validation loss: 2.2216008606777398

Epoch: 5| Step: 6
Training loss: 3.2051010131835938
Validation loss: 2.2330922644625426

Epoch: 5| Step: 7
Training loss: 2.6075243949890137
Validation loss: 2.226928359718733

Epoch: 5| Step: 8
Training loss: 2.381502151489258
Validation loss: 2.2368055159045803

Epoch: 5| Step: 9
Training loss: 2.537400484085083
Validation loss: 2.238225483125256

Epoch: 5| Step: 10
Training loss: 2.7998602390289307
Validation loss: 2.2468298160901634

Epoch: 196| Step: 0
Training loss: 1.9184386730194092
Validation loss: 2.2627057106264177

Epoch: 5| Step: 1
Training loss: 2.4373116493225098
Validation loss: 2.291458219610235

Epoch: 5| Step: 2
Training loss: 2.8495006561279297
Validation loss: 2.325397951628572

Epoch: 5| Step: 3
Training loss: 2.7178077697753906
Validation loss: 2.3214494541127193

Epoch: 5| Step: 4
Training loss: 2.3176751136779785
Validation loss: 2.3124113057249334

Epoch: 5| Step: 5
Training loss: 2.4813132286071777
Validation loss: 2.311483152451054

Epoch: 5| Step: 6
Training loss: 1.9573131799697876
Validation loss: 2.3052690413690384

Epoch: 5| Step: 7
Training loss: 1.998853087425232
Validation loss: 2.294439302977695

Epoch: 5| Step: 8
Training loss: 2.6939797401428223
Validation loss: 2.2936631787207817

Epoch: 5| Step: 9
Training loss: 2.8967933654785156
Validation loss: 2.2751959152119134

Epoch: 5| Step: 10
Training loss: 2.4971988201141357
Validation loss: 2.268535050012732

Epoch: 197| Step: 0
Training loss: 2.6560566425323486
Validation loss: 2.251982847849528

Epoch: 5| Step: 1
Training loss: 2.6752288341522217
Validation loss: 2.2715726411470802

Epoch: 5| Step: 2
Training loss: 3.450251817703247
Validation loss: 2.283235998563869

Epoch: 5| Step: 3
Training loss: 2.358372211456299
Validation loss: 2.277802090491018

Epoch: 5| Step: 4
Training loss: 2.756479501724243
Validation loss: 2.2858846597774054

Epoch: 5| Step: 5
Training loss: 2.220485210418701
Validation loss: 2.27918138042573

Epoch: 5| Step: 6
Training loss: 1.99799382686615
Validation loss: 2.2725317016724618

Epoch: 5| Step: 7
Training loss: 2.4040284156799316
Validation loss: 2.266542109110022

Epoch: 5| Step: 8
Training loss: 2.2934536933898926
Validation loss: 2.2645564643285607

Epoch: 5| Step: 9
Training loss: 1.916825532913208
Validation loss: 2.2597437545817387

Epoch: 5| Step: 10
Training loss: 2.195219039916992
Validation loss: 2.2657539972694973

Epoch: 198| Step: 0
Training loss: 2.359764337539673
Validation loss: 2.2715772903093727

Epoch: 5| Step: 1
Training loss: 2.022996425628662
Validation loss: 2.2837495111650035

Epoch: 5| Step: 2
Training loss: 1.9318441152572632
Validation loss: 2.2900038585867932

Epoch: 5| Step: 3
Training loss: 2.4593029022216797
Validation loss: 2.2893206124664633

Epoch: 5| Step: 4
Training loss: 2.5078530311584473
Validation loss: 2.2994417580225135

Epoch: 5| Step: 5
Training loss: 2.9239583015441895
Validation loss: 2.295553312506727

Epoch: 5| Step: 6
Training loss: 2.132676124572754
Validation loss: 2.2737252096976004

Epoch: 5| Step: 7
Training loss: 2.4402389526367188
Validation loss: 2.2564109410009077

Epoch: 5| Step: 8
Training loss: 2.0072455406188965
Validation loss: 2.257535978030133

Epoch: 5| Step: 9
Training loss: 2.9472298622131348
Validation loss: 2.2565653772764307

Epoch: 5| Step: 10
Training loss: 2.8539154529571533
Validation loss: 2.2607811856013473

Epoch: 199| Step: 0
Training loss: 2.5412356853485107
Validation loss: 2.257572850873393

Epoch: 5| Step: 1
Training loss: 2.163872241973877
Validation loss: 2.275592742427703

Epoch: 5| Step: 2
Training loss: 2.7244069576263428
Validation loss: 2.2624762622258996

Epoch: 5| Step: 3
Training loss: 2.3410696983337402
Validation loss: 2.2576144715791107

Epoch: 5| Step: 4
Training loss: 1.8868824243545532
Validation loss: 2.2406612480840375

Epoch: 5| Step: 5
Training loss: 2.3117001056671143
Validation loss: 2.2537186248328096

Epoch: 5| Step: 6
Training loss: 2.317160129547119
Validation loss: 2.271625453425992

Epoch: 5| Step: 7
Training loss: 2.6593117713928223
Validation loss: 2.2893641494935557

Epoch: 5| Step: 8
Training loss: 2.6115405559539795
Validation loss: 2.3026506106058755

Epoch: 5| Step: 9
Training loss: 2.323176622390747
Validation loss: 2.3136772455707675

Epoch: 5| Step: 10
Training loss: 2.6146674156188965
Validation loss: 2.302631493537657

Epoch: 200| Step: 0
Training loss: 2.0942161083221436
Validation loss: 2.284666215219805

Epoch: 5| Step: 1
Training loss: 2.8999457359313965
Validation loss: 2.263778435286655

Epoch: 5| Step: 2
Training loss: 2.5251429080963135
Validation loss: 2.2437827382036435

Epoch: 5| Step: 3
Training loss: 2.5163047313690186
Validation loss: 2.2345102192253194

Epoch: 5| Step: 4
Training loss: 2.144578218460083
Validation loss: 2.2424459303579023

Epoch: 5| Step: 5
Training loss: 2.3520619869232178
Validation loss: 2.248785730331175

Epoch: 5| Step: 6
Training loss: 1.851555585861206
Validation loss: 2.2623366771205777

Epoch: 5| Step: 7
Training loss: 1.939711332321167
Validation loss: 2.329085134690808

Epoch: 5| Step: 8
Training loss: 3.1650753021240234
Validation loss: 2.364599843179026

Epoch: 5| Step: 9
Training loss: 2.4293625354766846
Validation loss: 2.384536320163358

Epoch: 5| Step: 10
Training loss: 3.166870594024658
Validation loss: 2.3871589194061937

Epoch: 201| Step: 0
Training loss: 2.8128647804260254
Validation loss: 2.340840939552553

Epoch: 5| Step: 1
Training loss: 2.4130239486694336
Validation loss: 2.3161513484934324

Epoch: 5| Step: 2
Training loss: 2.5920016765594482
Validation loss: 2.313464818462249

Epoch: 5| Step: 3
Training loss: 3.2241387367248535
Validation loss: 2.337828705387731

Epoch: 5| Step: 4
Training loss: 2.4698286056518555
Validation loss: 2.343503975099133

Epoch: 5| Step: 5
Training loss: 1.6595432758331299
Validation loss: 2.355002354550105

Epoch: 5| Step: 6
Training loss: 2.3866569995880127
Validation loss: 2.3434405339661466

Epoch: 5| Step: 7
Training loss: 2.216294288635254
Validation loss: 2.344856103261312

Epoch: 5| Step: 8
Training loss: 2.3953347206115723
Validation loss: 2.30995495857731

Epoch: 5| Step: 9
Training loss: 1.9373832941055298
Validation loss: 2.289978458035377

Epoch: 5| Step: 10
Training loss: 2.8299951553344727
Validation loss: 2.2614536144400157

Epoch: 202| Step: 0
Training loss: 2.41314959526062
Validation loss: 2.244993168820617

Epoch: 5| Step: 1
Training loss: 2.9131174087524414
Validation loss: 2.2375699807238836

Epoch: 5| Step: 2
Training loss: 3.0328986644744873
Validation loss: 2.23183278370929

Epoch: 5| Step: 3
Training loss: 2.339263439178467
Validation loss: 2.2388051735457553

Epoch: 5| Step: 4
Training loss: 2.4960360527038574
Validation loss: 2.2336274552088913

Epoch: 5| Step: 5
Training loss: 2.3962817192077637
Validation loss: 2.240540632637598

Epoch: 5| Step: 6
Training loss: 1.5163354873657227
Validation loss: 2.247421064684468

Epoch: 5| Step: 7
Training loss: 2.5374112129211426
Validation loss: 2.2509743539235925

Epoch: 5| Step: 8
Training loss: 2.426225185394287
Validation loss: 2.2546516105692875

Epoch: 5| Step: 9
Training loss: 2.381714344024658
Validation loss: 2.2630802123777327

Epoch: 5| Step: 10
Training loss: 1.8885546922683716
Validation loss: 2.260072636347945

Epoch: 203| Step: 0
Training loss: 2.124103307723999
Validation loss: 2.2826714310594785

Epoch: 5| Step: 1
Training loss: 1.9019304513931274
Validation loss: 2.2847111276400986

Epoch: 5| Step: 2
Training loss: 2.4815096855163574
Validation loss: 2.297592152831375

Epoch: 5| Step: 3
Training loss: 3.104722261428833
Validation loss: 2.29906698196165

Epoch: 5| Step: 4
Training loss: 1.8664785623550415
Validation loss: 2.28215213488507

Epoch: 5| Step: 5
Training loss: 2.6201014518737793
Validation loss: 2.2776081651769657

Epoch: 5| Step: 6
Training loss: 2.335744857788086
Validation loss: 2.254472517198132

Epoch: 5| Step: 7
Training loss: 2.711153268814087
Validation loss: 2.246469377189554

Epoch: 5| Step: 8
Training loss: 2.8727753162384033
Validation loss: 2.2357464900580784

Epoch: 5| Step: 9
Training loss: 2.0955135822296143
Validation loss: 2.2313919503201722

Epoch: 5| Step: 10
Training loss: 2.2631945610046387
Validation loss: 2.2302989511079687

Epoch: 204| Step: 0
Training loss: 2.7804741859436035
Validation loss: 2.230121438221265

Epoch: 5| Step: 1
Training loss: 2.357255458831787
Validation loss: 2.2294890803675496

Epoch: 5| Step: 2
Training loss: 2.821683645248413
Validation loss: 2.241680047845328

Epoch: 5| Step: 3
Training loss: 1.8152389526367188
Validation loss: 2.2508584991578133

Epoch: 5| Step: 4
Training loss: 2.170673131942749
Validation loss: 2.2537351680058304

Epoch: 5| Step: 5
Training loss: 2.1424131393432617
Validation loss: 2.2380742770369335

Epoch: 5| Step: 6
Training loss: 2.247391939163208
Validation loss: 2.2302489537064747

Epoch: 5| Step: 7
Training loss: 2.336613893508911
Validation loss: 2.222873298070764

Epoch: 5| Step: 8
Training loss: 2.300798177719116
Validation loss: 2.2185041750631025

Epoch: 5| Step: 9
Training loss: 2.7547261714935303
Validation loss: 2.224177178516183

Epoch: 5| Step: 10
Training loss: 2.493302822113037
Validation loss: 2.233437858602052

Epoch: 205| Step: 0
Training loss: 3.191420316696167
Validation loss: 2.2658147760616836

Epoch: 5| Step: 1
Training loss: 1.2077229022979736
Validation loss: 2.291908028305218

Epoch: 5| Step: 2
Training loss: 2.6521048545837402
Validation loss: 2.3035363125544723

Epoch: 5| Step: 3
Training loss: 3.236804962158203
Validation loss: 2.3039760012780466

Epoch: 5| Step: 4
Training loss: 2.4167745113372803
Validation loss: 2.312783092580816

Epoch: 5| Step: 5
Training loss: 2.235687732696533
Validation loss: 2.3131852534509476

Epoch: 5| Step: 6
Training loss: 1.9968605041503906
Validation loss: 2.327603192739589

Epoch: 5| Step: 7
Training loss: 2.768085479736328
Validation loss: 2.319907807534741

Epoch: 5| Step: 8
Training loss: 2.1778931617736816
Validation loss: 2.3092165249650196

Epoch: 5| Step: 9
Training loss: 2.473513603210449
Validation loss: 2.295900034648116

Epoch: 5| Step: 10
Training loss: 1.9408212900161743
Validation loss: 2.280274483465379

Epoch: 206| Step: 0
Training loss: 1.8538200855255127
Validation loss: 2.2543189974241358

Epoch: 5| Step: 1
Training loss: 1.6680757999420166
Validation loss: 2.245081078621649

Epoch: 5| Step: 2
Training loss: 2.420522928237915
Validation loss: 2.2528954577702347

Epoch: 5| Step: 3
Training loss: 2.1916604042053223
Validation loss: 2.2452001853655745

Epoch: 5| Step: 4
Training loss: 2.1963164806365967
Validation loss: 2.243379609559172

Epoch: 5| Step: 5
Training loss: 2.8454737663269043
Validation loss: 2.24044132232666

Epoch: 5| Step: 6
Training loss: 2.739833354949951
Validation loss: 2.2474023808715162

Epoch: 5| Step: 7
Training loss: 2.457972288131714
Validation loss: 2.2410270937027468

Epoch: 5| Step: 8
Training loss: 3.030534505844116
Validation loss: 2.254813914657921

Epoch: 5| Step: 9
Training loss: 2.5724122524261475
Validation loss: 2.243741032897785

Epoch: 5| Step: 10
Training loss: 2.208627700805664
Validation loss: 2.233616905827676

Epoch: 207| Step: 0
Training loss: 2.3607754707336426
Validation loss: 2.2429238903907036

Epoch: 5| Step: 1
Training loss: 1.6741069555282593
Validation loss: 2.2400340341752574

Epoch: 5| Step: 2
Training loss: 1.8808780908584595
Validation loss: 2.26168349353216

Epoch: 5| Step: 3
Training loss: 2.728513717651367
Validation loss: 2.2727484267245055

Epoch: 5| Step: 4
Training loss: 2.3978781700134277
Validation loss: 2.2796730251722437

Epoch: 5| Step: 5
Training loss: 2.538019895553589
Validation loss: 2.2768983302577848

Epoch: 5| Step: 6
Training loss: 2.8465096950531006
Validation loss: 2.289016257050217

Epoch: 5| Step: 7
Training loss: 1.9893176555633545
Validation loss: 2.2612142819230274

Epoch: 5| Step: 8
Training loss: 2.467336654663086
Validation loss: 2.2484367227041595

Epoch: 5| Step: 9
Training loss: 2.605534076690674
Validation loss: 2.241237186616467

Epoch: 5| Step: 10
Training loss: 2.6982550621032715
Validation loss: 2.2320191911471787

Epoch: 208| Step: 0
Training loss: 1.8092597723007202
Validation loss: 2.234339238494955

Epoch: 5| Step: 1
Training loss: 2.9488043785095215
Validation loss: 2.2153501023528395

Epoch: 5| Step: 2
Training loss: 2.415602445602417
Validation loss: 2.2078308008050405

Epoch: 5| Step: 3
Training loss: 2.0972256660461426
Validation loss: 2.192256699326218

Epoch: 5| Step: 4
Training loss: 2.4261837005615234
Validation loss: 2.199629186302103

Epoch: 5| Step: 5
Training loss: 2.1729471683502197
Validation loss: 2.2104530411381877

Epoch: 5| Step: 6
Training loss: 2.8532752990722656
Validation loss: 2.2179977047827935

Epoch: 5| Step: 7
Training loss: 2.7088189125061035
Validation loss: 2.2344242013910764

Epoch: 5| Step: 8
Training loss: 2.5572099685668945
Validation loss: 2.2593769386250484

Epoch: 5| Step: 9
Training loss: 1.7548599243164062
Validation loss: 2.279171028444844

Epoch: 5| Step: 10
Training loss: 2.331378221511841
Validation loss: 2.274584872748262

Epoch: 209| Step: 0
Training loss: 2.175135850906372
Validation loss: 2.281916682438184

Epoch: 5| Step: 1
Training loss: 2.1727538108825684
Validation loss: 2.290993704590746

Epoch: 5| Step: 2
Training loss: 3.2039668560028076
Validation loss: 2.3268899866329726

Epoch: 5| Step: 3
Training loss: 2.5481045246124268
Validation loss: 2.341814153937883

Epoch: 5| Step: 4
Training loss: 2.7177367210388184
Validation loss: 2.3441763962468793

Epoch: 5| Step: 5
Training loss: 2.1819427013397217
Validation loss: 2.3116829702931065

Epoch: 5| Step: 6
Training loss: 2.465574026107788
Validation loss: 2.2736573296208538

Epoch: 5| Step: 7
Training loss: 2.1804754734039307
Validation loss: 2.251241817269274

Epoch: 5| Step: 8
Training loss: 1.8730497360229492
Validation loss: 2.2427954866040136

Epoch: 5| Step: 9
Training loss: 2.1082417964935303
Validation loss: 2.2488140316419702

Epoch: 5| Step: 10
Training loss: 3.0111448764801025
Validation loss: 2.2836260282865135

Epoch: 210| Step: 0
Training loss: 2.865299701690674
Validation loss: 2.2926605747592066

Epoch: 5| Step: 1
Training loss: 2.306317090988159
Validation loss: 2.268510457008116

Epoch: 5| Step: 2
Training loss: 3.229806423187256
Validation loss: 2.250230130328927

Epoch: 5| Step: 3
Training loss: 2.4163763523101807
Validation loss: 2.244784068035823

Epoch: 5| Step: 4
Training loss: 1.5651792287826538
Validation loss: 2.221382165467867

Epoch: 5| Step: 5
Training loss: 2.374218463897705
Validation loss: 2.210044942876344

Epoch: 5| Step: 6
Training loss: 2.5501458644866943
Validation loss: 2.2047334024983067

Epoch: 5| Step: 7
Training loss: 2.2405812740325928
Validation loss: 2.209155754376483

Epoch: 5| Step: 8
Training loss: 1.9841129779815674
Validation loss: 2.217836918369416

Epoch: 5| Step: 9
Training loss: 2.4554457664489746
Validation loss: 2.2240632836536696

Epoch: 5| Step: 10
Training loss: 1.9132603406906128
Validation loss: 2.2356829412521853

Epoch: 211| Step: 0
Training loss: 1.6894460916519165
Validation loss: 2.2406508717485654

Epoch: 5| Step: 1
Training loss: 2.046790361404419
Validation loss: 2.251577683674392

Epoch: 5| Step: 2
Training loss: 2.3310017585754395
Validation loss: 2.243880010420276

Epoch: 5| Step: 3
Training loss: 2.8122153282165527
Validation loss: 2.2504924907479236

Epoch: 5| Step: 4
Training loss: 2.469679832458496
Validation loss: 2.270383337492584

Epoch: 5| Step: 5
Training loss: 1.8789007663726807
Validation loss: 2.2997186619748353

Epoch: 5| Step: 6
Training loss: 2.3299789428710938
Validation loss: 2.3031881675925305

Epoch: 5| Step: 7
Training loss: 2.4597387313842773
Validation loss: 2.323144192336708

Epoch: 5| Step: 8
Training loss: 2.570681571960449
Validation loss: 2.295449069751206

Epoch: 5| Step: 9
Training loss: 3.126159191131592
Validation loss: 2.282875981382144

Epoch: 5| Step: 10
Training loss: 2.3532536029815674
Validation loss: 2.2560138240937264

Epoch: 212| Step: 0
Training loss: 2.0839686393737793
Validation loss: 2.232955273761544

Epoch: 5| Step: 1
Training loss: 2.553615093231201
Validation loss: 2.214439674090314

Epoch: 5| Step: 2
Training loss: 1.8961784839630127
Validation loss: 2.220879127902369

Epoch: 5| Step: 3
Training loss: 2.3891348838806152
Validation loss: 2.218595326587718

Epoch: 5| Step: 4
Training loss: 2.4071805477142334
Validation loss: 2.2215471293336604

Epoch: 5| Step: 5
Training loss: 2.9473540782928467
Validation loss: 2.224043092420024

Epoch: 5| Step: 6
Training loss: 2.76650071144104
Validation loss: 2.2227210972898748

Epoch: 5| Step: 7
Training loss: 2.3153700828552246
Validation loss: 2.224403694111814

Epoch: 5| Step: 8
Training loss: 1.8923494815826416
Validation loss: 2.230976725137362

Epoch: 5| Step: 9
Training loss: 2.039109230041504
Validation loss: 2.2353699130396687

Epoch: 5| Step: 10
Training loss: 2.759688138961792
Validation loss: 2.2492063148047334

Epoch: 213| Step: 0
Training loss: 2.084343194961548
Validation loss: 2.2507321296199674

Epoch: 5| Step: 1
Training loss: 2.557314395904541
Validation loss: 2.258986723038458

Epoch: 5| Step: 2
Training loss: 2.0271220207214355
Validation loss: 2.2758355499595724

Epoch: 5| Step: 3
Training loss: 2.5723443031311035
Validation loss: 2.26762383214889

Epoch: 5| Step: 4
Training loss: 2.1257805824279785
Validation loss: 2.2593508663997857

Epoch: 5| Step: 5
Training loss: 2.228315591812134
Validation loss: 2.253482985240157

Epoch: 5| Step: 6
Training loss: 1.5818710327148438
Validation loss: 2.2608080807552544

Epoch: 5| Step: 7
Training loss: 2.5412039756774902
Validation loss: 2.264853339041433

Epoch: 5| Step: 8
Training loss: 2.827399492263794
Validation loss: 2.2643955856241207

Epoch: 5| Step: 9
Training loss: 2.274503469467163
Validation loss: 2.2461362782345025

Epoch: 5| Step: 10
Training loss: 3.166383743286133
Validation loss: 2.215236435654343

Epoch: 214| Step: 0
Training loss: 2.820019245147705
Validation loss: 2.2141974203048216

Epoch: 5| Step: 1
Training loss: 2.5135960578918457
Validation loss: 2.2143347724791496

Epoch: 5| Step: 2
Training loss: 1.8074710369110107
Validation loss: 2.233820289693853

Epoch: 5| Step: 3
Training loss: 1.5987281799316406
Validation loss: 2.2481736213930192

Epoch: 5| Step: 4
Training loss: 1.8194105625152588
Validation loss: 2.2381885051727295

Epoch: 5| Step: 5
Training loss: 2.632672071456909
Validation loss: 2.21327043092379

Epoch: 5| Step: 6
Training loss: 2.4083590507507324
Validation loss: 2.2081188412122827

Epoch: 5| Step: 7
Training loss: 1.664608359336853
Validation loss: 2.2005487334343696

Epoch: 5| Step: 8
Training loss: 2.784181594848633
Validation loss: 2.1949525084546817

Epoch: 5| Step: 9
Training loss: 2.865246295928955
Validation loss: 2.21040843379113

Epoch: 5| Step: 10
Training loss: 2.7746942043304443
Validation loss: 2.2014981751800864

Epoch: 215| Step: 0
Training loss: 1.895382285118103
Validation loss: 2.211001160324261

Epoch: 5| Step: 1
Training loss: 2.4670166969299316
Validation loss: 2.2245699974798385

Epoch: 5| Step: 2
Training loss: 1.6815074682235718
Validation loss: 2.234809414032967

Epoch: 5| Step: 3
Training loss: 2.7978358268737793
Validation loss: 2.250570845860307

Epoch: 5| Step: 4
Training loss: 3.083894968032837
Validation loss: 2.2487278356347034

Epoch: 5| Step: 5
Training loss: 2.240013837814331
Validation loss: 2.2488948299038793

Epoch: 5| Step: 6
Training loss: 2.3908119201660156
Validation loss: 2.256036937877696

Epoch: 5| Step: 7
Training loss: 1.9353697299957275
Validation loss: 2.253564775630992

Epoch: 5| Step: 8
Training loss: 2.464836597442627
Validation loss: 2.249576417348718

Epoch: 5| Step: 9
Training loss: 2.298293352127075
Validation loss: 2.240908856032997

Epoch: 5| Step: 10
Training loss: 2.5479907989501953
Validation loss: 2.231565172954272

Epoch: 216| Step: 0
Training loss: 2.581686019897461
Validation loss: 2.216111342112223

Epoch: 5| Step: 1
Training loss: 3.2517573833465576
Validation loss: 2.2084221839904785

Epoch: 5| Step: 2
Training loss: 2.505977153778076
Validation loss: 2.2038614608908214

Epoch: 5| Step: 3
Training loss: 2.1525559425354004
Validation loss: 2.2049412881174395

Epoch: 5| Step: 4
Training loss: 1.8604780435562134
Validation loss: 2.2105264330423005

Epoch: 5| Step: 5
Training loss: 1.8062900304794312
Validation loss: 2.1905709620445006

Epoch: 5| Step: 6
Training loss: 2.1204326152801514
Validation loss: 2.188252002962174

Epoch: 5| Step: 7
Training loss: 2.0943329334259033
Validation loss: 2.178321232077896

Epoch: 5| Step: 8
Training loss: 2.3547866344451904
Validation loss: 2.191334714171707

Epoch: 5| Step: 9
Training loss: 2.7377495765686035
Validation loss: 2.203096133406444

Epoch: 5| Step: 10
Training loss: 1.9485478401184082
Validation loss: 2.2090687213405484

Epoch: 217| Step: 0
Training loss: 1.7674964666366577
Validation loss: 2.208442564933531

Epoch: 5| Step: 1
Training loss: 2.4075767993927
Validation loss: 2.2282971053995113

Epoch: 5| Step: 2
Training loss: 2.22385835647583
Validation loss: 2.23297179642544

Epoch: 5| Step: 3
Training loss: 2.4564483165740967
Validation loss: 2.230191897320491

Epoch: 5| Step: 4
Training loss: 1.9588228464126587
Validation loss: 2.222634815400647

Epoch: 5| Step: 5
Training loss: 2.5455431938171387
Validation loss: 2.217865054325391

Epoch: 5| Step: 6
Training loss: 2.380110263824463
Validation loss: 2.2228816042664232

Epoch: 5| Step: 7
Training loss: 2.0787863731384277
Validation loss: 2.231761068426153

Epoch: 5| Step: 8
Training loss: 2.236738443374634
Validation loss: 2.2414707047964937

Epoch: 5| Step: 9
Training loss: 2.711273670196533
Validation loss: 2.2284575764850905

Epoch: 5| Step: 10
Training loss: 2.608346700668335
Validation loss: 2.2206475965438353

Epoch: 218| Step: 0
Training loss: 2.8356881141662598
Validation loss: 2.211845185167046

Epoch: 5| Step: 1
Training loss: 2.25522518157959
Validation loss: 2.210640340723017

Epoch: 5| Step: 2
Training loss: 2.0526680946350098
Validation loss: 2.2070402112058414

Epoch: 5| Step: 3
Training loss: 1.6339391469955444
Validation loss: 2.2155266910470943

Epoch: 5| Step: 4
Training loss: 2.547565460205078
Validation loss: 2.2102366903776764

Epoch: 5| Step: 5
Training loss: 2.427508592605591
Validation loss: 2.208896903581517

Epoch: 5| Step: 6
Training loss: 1.3046783208847046
Validation loss: 2.1970200974454164

Epoch: 5| Step: 7
Training loss: 2.4699089527130127
Validation loss: 2.1955976845115743

Epoch: 5| Step: 8
Training loss: 2.1742665767669678
Validation loss: 2.2040307265456005

Epoch: 5| Step: 9
Training loss: 2.7632198333740234
Validation loss: 2.1897056871844875

Epoch: 5| Step: 10
Training loss: 2.909916639328003
Validation loss: 2.1977773404890493

Epoch: 219| Step: 0
Training loss: 2.3895082473754883
Validation loss: 2.2206701899087555

Epoch: 5| Step: 1
Training loss: 2.83986234664917
Validation loss: 2.238030127299729

Epoch: 5| Step: 2
Training loss: 2.237431764602661
Validation loss: 2.2499911336488623

Epoch: 5| Step: 3
Training loss: 3.0943286418914795
Validation loss: 2.265787604034588

Epoch: 5| Step: 4
Training loss: 1.3374850749969482
Validation loss: 2.2737933563929733

Epoch: 5| Step: 5
Training loss: 2.1084656715393066
Validation loss: 2.2452866313278035

Epoch: 5| Step: 6
Training loss: 2.222489833831787
Validation loss: 2.2396926495336715

Epoch: 5| Step: 7
Training loss: 2.6334807872772217
Validation loss: 2.238210542227632

Epoch: 5| Step: 8
Training loss: 2.302823781967163
Validation loss: 2.2227631550963207

Epoch: 5| Step: 9
Training loss: 2.129807710647583
Validation loss: 2.2063608092646443

Epoch: 5| Step: 10
Training loss: 1.901361107826233
Validation loss: 2.1900483433918287

Epoch: 220| Step: 0
Training loss: 2.122478485107422
Validation loss: 2.167635547217502

Epoch: 5| Step: 1
Training loss: 2.3574745655059814
Validation loss: 2.1745749263353247

Epoch: 5| Step: 2
Training loss: 2.311617136001587
Validation loss: 2.1613746150847404

Epoch: 5| Step: 3
Training loss: 2.6054115295410156
Validation loss: 2.168737979345424

Epoch: 5| Step: 4
Training loss: 2.2071452140808105
Validation loss: 2.1683027103383052

Epoch: 5| Step: 5
Training loss: 2.178933620452881
Validation loss: 2.1630211876284693

Epoch: 5| Step: 6
Training loss: 1.6696637868881226
Validation loss: 2.1738719888912734

Epoch: 5| Step: 7
Training loss: 2.200127363204956
Validation loss: 2.1924159655006985

Epoch: 5| Step: 8
Training loss: 2.345370054244995
Validation loss: 2.1971109451786166

Epoch: 5| Step: 9
Training loss: 2.620697498321533
Validation loss: 2.21376871806319

Epoch: 5| Step: 10
Training loss: 2.7608084678649902
Validation loss: 2.2179310667899346

Epoch: 221| Step: 0
Training loss: 2.383653402328491
Validation loss: 2.203862523519865

Epoch: 5| Step: 1
Training loss: 2.6074600219726562
Validation loss: 2.209143643738121

Epoch: 5| Step: 2
Training loss: 2.737769842147827
Validation loss: 2.213851821038031

Epoch: 5| Step: 3
Training loss: 2.662041187286377
Validation loss: 2.2109180214584514

Epoch: 5| Step: 4
Training loss: 2.2261552810668945
Validation loss: 2.214732050895691

Epoch: 5| Step: 5
Training loss: 1.6048071384429932
Validation loss: 2.2467867020637757

Epoch: 5| Step: 6
Training loss: 2.3270201683044434
Validation loss: 2.2504724046235443

Epoch: 5| Step: 7
Training loss: 2.019535541534424
Validation loss: 2.263548529276284

Epoch: 5| Step: 8
Training loss: 2.6238503456115723
Validation loss: 2.2503603325095227

Epoch: 5| Step: 9
Training loss: 1.6729110479354858
Validation loss: 2.2611915296123875

Epoch: 5| Step: 10
Training loss: 2.3663740158081055
Validation loss: 2.2590058824067474

Epoch: 222| Step: 0
Training loss: 2.255798578262329
Validation loss: 2.2425909708904963

Epoch: 5| Step: 1
Training loss: 2.1477413177490234
Validation loss: 2.2389208616748935

Epoch: 5| Step: 2
Training loss: 2.388516664505005
Validation loss: 2.221772942491757

Epoch: 5| Step: 3
Training loss: 1.8372700214385986
Validation loss: 2.1985766836391982

Epoch: 5| Step: 4
Training loss: 2.4680874347686768
Validation loss: 2.1867781416062386

Epoch: 5| Step: 5
Training loss: 2.0859265327453613
Validation loss: 2.176897286086954

Epoch: 5| Step: 6
Training loss: 2.201637029647827
Validation loss: 2.178870931748421

Epoch: 5| Step: 7
Training loss: 2.649913787841797
Validation loss: 2.170398235321045

Epoch: 5| Step: 8
Training loss: 1.9609107971191406
Validation loss: 2.1846388975779214

Epoch: 5| Step: 9
Training loss: 3.098418712615967
Validation loss: 2.1729091418686735

Epoch: 5| Step: 10
Training loss: 2.158144235610962
Validation loss: 2.1883421738942466

Epoch: 223| Step: 0
Training loss: 2.087303400039673
Validation loss: 2.2060307430964645

Epoch: 5| Step: 1
Training loss: 2.5236895084381104
Validation loss: 2.236438625602312

Epoch: 5| Step: 2
Training loss: 2.924161911010742
Validation loss: 2.244664058890394

Epoch: 5| Step: 3
Training loss: 1.9077953100204468
Validation loss: 2.2310282389322915

Epoch: 5| Step: 4
Training loss: 1.451411485671997
Validation loss: 2.228949939050982

Epoch: 5| Step: 5
Training loss: 2.5268502235412598
Validation loss: 2.2089089296197377

Epoch: 5| Step: 6
Training loss: 2.8315231800079346
Validation loss: 2.21444881603282

Epoch: 5| Step: 7
Training loss: 1.7924339771270752
Validation loss: 2.2116075536256194

Epoch: 5| Step: 8
Training loss: 2.237773895263672
Validation loss: 2.199129989070277

Epoch: 5| Step: 9
Training loss: 2.4221179485321045
Validation loss: 2.200741979383653

Epoch: 5| Step: 10
Training loss: 2.4447879791259766
Validation loss: 2.1949531275738954

Epoch: 224| Step: 0
Training loss: 2.045957088470459
Validation loss: 2.1930714653384302

Epoch: 5| Step: 1
Training loss: 1.9381345510482788
Validation loss: 2.1900520901526175

Epoch: 5| Step: 2
Training loss: 2.5278849601745605
Validation loss: 2.193920732826315

Epoch: 5| Step: 3
Training loss: 1.8594748973846436
Validation loss: 2.216406329985588

Epoch: 5| Step: 4
Training loss: 2.2603931427001953
Validation loss: 2.2155306134172665

Epoch: 5| Step: 5
Training loss: 2.1095807552337646
Validation loss: 2.2113412541727864

Epoch: 5| Step: 6
Training loss: 2.107301712036133
Validation loss: 2.220869623204713

Epoch: 5| Step: 7
Training loss: 3.342517852783203
Validation loss: 2.214227384136569

Epoch: 5| Step: 8
Training loss: 2.3631701469421387
Validation loss: 2.2155318952375844

Epoch: 5| Step: 9
Training loss: 2.3907439708709717
Validation loss: 2.2087165681264733

Epoch: 5| Step: 10
Training loss: 2.11844801902771
Validation loss: 2.2055109162484445

Epoch: 225| Step: 0
Training loss: 2.384316921234131
Validation loss: 2.1970095352459977

Epoch: 5| Step: 1
Training loss: 2.2758007049560547
Validation loss: 2.1916801852564656

Epoch: 5| Step: 2
Training loss: 2.307661533355713
Validation loss: 2.196579279438142

Epoch: 5| Step: 3
Training loss: 2.7492048740386963
Validation loss: 2.1896981552083004

Epoch: 5| Step: 4
Training loss: 2.0192089080810547
Validation loss: 2.1900495444574664

Epoch: 5| Step: 5
Training loss: 2.3053927421569824
Validation loss: 2.194319204617572

Epoch: 5| Step: 6
Training loss: 2.1516385078430176
Validation loss: 2.202512279633553

Epoch: 5| Step: 7
Training loss: 1.8710577487945557
Validation loss: 2.2058284795412453

Epoch: 5| Step: 8
Training loss: 2.2385048866271973
Validation loss: 2.2000189955516527

Epoch: 5| Step: 9
Training loss: 1.9443334341049194
Validation loss: 2.201642741439163

Epoch: 5| Step: 10
Training loss: 2.6939454078674316
Validation loss: 2.1865748487493044

Epoch: 226| Step: 0
Training loss: 2.2778518199920654
Validation loss: 2.187420996286536

Epoch: 5| Step: 1
Training loss: 2.3735127449035645
Validation loss: 2.1706715963220082

Epoch: 5| Step: 2
Training loss: 2.628802537918091
Validation loss: 2.1628284736346175

Epoch: 5| Step: 3
Training loss: 2.1639037132263184
Validation loss: 2.1661421304107993

Epoch: 5| Step: 4
Training loss: 2.5977814197540283
Validation loss: 2.1546314813757457

Epoch: 5| Step: 5
Training loss: 1.974082589149475
Validation loss: 2.1578601483375794

Epoch: 5| Step: 6
Training loss: 2.5210258960723877
Validation loss: 2.160781147659466

Epoch: 5| Step: 7
Training loss: 1.8729515075683594
Validation loss: 2.165383977274741

Epoch: 5| Step: 8
Training loss: 1.655042290687561
Validation loss: 2.1729482245701615

Epoch: 5| Step: 9
Training loss: 2.242177963256836
Validation loss: 2.204670347193236

Epoch: 5| Step: 10
Training loss: 2.676447868347168
Validation loss: 2.2015068556672786

Epoch: 227| Step: 0
Training loss: 2.256556987762451
Validation loss: 2.2077936075067006

Epoch: 5| Step: 1
Training loss: 2.235978364944458
Validation loss: 2.1991186987969185

Epoch: 5| Step: 2
Training loss: 2.396366834640503
Validation loss: 2.207998755157635

Epoch: 5| Step: 3
Training loss: 2.7683913707733154
Validation loss: 2.2138602900248703

Epoch: 5| Step: 4
Training loss: 2.1208019256591797
Validation loss: 2.210321118754725

Epoch: 5| Step: 5
Training loss: 1.9769089221954346
Validation loss: 2.2181961280043407

Epoch: 5| Step: 6
Training loss: 1.9832820892333984
Validation loss: 2.185241024981263

Epoch: 5| Step: 7
Training loss: 2.295544147491455
Validation loss: 2.1814786849483365

Epoch: 5| Step: 8
Training loss: 1.9951972961425781
Validation loss: 2.201715011750498

Epoch: 5| Step: 9
Training loss: 2.4399142265319824
Validation loss: 2.199241053673529

Epoch: 5| Step: 10
Training loss: 2.38574481010437
Validation loss: 2.191163644995741

Epoch: 228| Step: 0
Training loss: 2.9258525371551514
Validation loss: 2.1930828504664923

Epoch: 5| Step: 1
Training loss: 2.3369662761688232
Validation loss: 2.1867335047773135

Epoch: 5| Step: 2
Training loss: 2.3096797466278076
Validation loss: 2.2011163209074285

Epoch: 5| Step: 3
Training loss: 1.3953667879104614
Validation loss: 2.1797334301856255

Epoch: 5| Step: 4
Training loss: 2.0507285594940186
Validation loss: 2.188992110631799

Epoch: 5| Step: 5
Training loss: 2.490739345550537
Validation loss: 2.1935126986554874

Epoch: 5| Step: 6
Training loss: 2.050220489501953
Validation loss: 2.193031910927065

Epoch: 5| Step: 7
Training loss: 2.163020133972168
Validation loss: 2.194853967235934

Epoch: 5| Step: 8
Training loss: 2.404994487762451
Validation loss: 2.197523501611525

Epoch: 5| Step: 9
Training loss: 2.0311596393585205
Validation loss: 2.2059279154705744

Epoch: 5| Step: 10
Training loss: 2.5721323490142822
Validation loss: 2.213078342458253

Epoch: 229| Step: 0
Training loss: 2.305617570877075
Validation loss: 2.1972023851128033

Epoch: 5| Step: 1
Training loss: 2.3289990425109863
Validation loss: 2.1819906568014495

Epoch: 5| Step: 2
Training loss: 2.5509066581726074
Validation loss: 2.2002993527279107

Epoch: 5| Step: 3
Training loss: 1.9794132709503174
Validation loss: 2.1944133697017545

Epoch: 5| Step: 4
Training loss: 1.9916460514068604
Validation loss: 2.183922339511174

Epoch: 5| Step: 5
Training loss: 1.8299850225448608
Validation loss: 2.1660564766135266

Epoch: 5| Step: 6
Training loss: 2.4099280834198
Validation loss: 2.1720363606688795

Epoch: 5| Step: 7
Training loss: 2.626842975616455
Validation loss: 2.163386324400543

Epoch: 5| Step: 8
Training loss: 2.4430606365203857
Validation loss: 2.16986539927862

Epoch: 5| Step: 9
Training loss: 1.6305389404296875
Validation loss: 2.169569698713159

Epoch: 5| Step: 10
Training loss: 2.5906944274902344
Validation loss: 2.1783390198984454

Epoch: 230| Step: 0
Training loss: 2.114489793777466
Validation loss: 2.1799000309359644

Epoch: 5| Step: 1
Training loss: 2.353457450866699
Validation loss: 2.1910771067424486

Epoch: 5| Step: 2
Training loss: 2.491204023361206
Validation loss: 2.1958230797962477

Epoch: 5| Step: 3
Training loss: 1.857917070388794
Validation loss: 2.199659824371338

Epoch: 5| Step: 4
Training loss: 1.8972705602645874
Validation loss: 2.192480492335494

Epoch: 5| Step: 5
Training loss: 2.023071050643921
Validation loss: 2.2009917766817155

Epoch: 5| Step: 6
Training loss: 1.8351285457611084
Validation loss: 2.2118236582766295

Epoch: 5| Step: 7
Training loss: 2.450763702392578
Validation loss: 2.224327628330518

Epoch: 5| Step: 8
Training loss: 3.2923965454101562
Validation loss: 2.2235823113431215

Epoch: 5| Step: 9
Training loss: 2.0527091026306152
Validation loss: 2.224374741636297

Epoch: 5| Step: 10
Training loss: 2.076160192489624
Validation loss: 2.2139546717366865

Epoch: 231| Step: 0
Training loss: 2.256683349609375
Validation loss: 2.2160133315670874

Epoch: 5| Step: 1
Training loss: 2.622633934020996
Validation loss: 2.22218426709534

Epoch: 5| Step: 2
Training loss: 1.7203041315078735
Validation loss: 2.21668259046411

Epoch: 5| Step: 3
Training loss: 2.0601115226745605
Validation loss: 2.1914795188493628

Epoch: 5| Step: 4
Training loss: 2.6863224506378174
Validation loss: 2.1751039105076946

Epoch: 5| Step: 5
Training loss: 1.7417428493499756
Validation loss: 2.176809868504924

Epoch: 5| Step: 6
Training loss: 2.6879703998565674
Validation loss: 2.189202444527739

Epoch: 5| Step: 7
Training loss: 2.20607328414917
Validation loss: 2.2061724239780056

Epoch: 5| Step: 8
Training loss: 2.4645028114318848
Validation loss: 2.1964044904196136

Epoch: 5| Step: 9
Training loss: 2.246734142303467
Validation loss: 2.1840077702717116

Epoch: 5| Step: 10
Training loss: 1.9912244081497192
Validation loss: 2.1692601326973207

Epoch: 232| Step: 0
Training loss: 1.754945158958435
Validation loss: 2.1688556260960077

Epoch: 5| Step: 1
Training loss: 2.8507323265075684
Validation loss: 2.1805236237023466

Epoch: 5| Step: 2
Training loss: 2.3899760246276855
Validation loss: 2.178323035599083

Epoch: 5| Step: 3
Training loss: 2.125840902328491
Validation loss: 2.188222292930849

Epoch: 5| Step: 4
Training loss: 2.1208815574645996
Validation loss: 2.178705833291495

Epoch: 5| Step: 5
Training loss: 2.5485191345214844
Validation loss: 2.1991424919456564

Epoch: 5| Step: 6
Training loss: 2.640664577484131
Validation loss: 2.2126397048273394

Epoch: 5| Step: 7
Training loss: 2.029341697692871
Validation loss: 2.2217224310803156

Epoch: 5| Step: 8
Training loss: 1.8128650188446045
Validation loss: 2.234566498828191

Epoch: 5| Step: 9
Training loss: 2.188413619995117
Validation loss: 2.235220532263479

Epoch: 5| Step: 10
Training loss: 2.0557425022125244
Validation loss: 2.2156557549712477

Epoch: 233| Step: 0
Training loss: 2.1031672954559326
Validation loss: 2.191789065637896

Epoch: 5| Step: 1
Training loss: 1.8138129711151123
Validation loss: 2.189782965567804

Epoch: 5| Step: 2
Training loss: 1.840051293373108
Validation loss: 2.195570709884808

Epoch: 5| Step: 3
Training loss: 2.3978805541992188
Validation loss: 2.2038607828078733

Epoch: 5| Step: 4
Training loss: 1.4196531772613525
Validation loss: 2.210328327712192

Epoch: 5| Step: 5
Training loss: 2.674424648284912
Validation loss: 2.1924245536968274

Epoch: 5| Step: 6
Training loss: 2.6552627086639404
Validation loss: 2.1634143347381265

Epoch: 5| Step: 7
Training loss: 2.6484293937683105
Validation loss: 2.1567277472506285

Epoch: 5| Step: 8
Training loss: 2.0820188522338867
Validation loss: 2.160000503704112

Epoch: 5| Step: 9
Training loss: 2.348013401031494
Validation loss: 2.162149426757648

Epoch: 5| Step: 10
Training loss: 2.6016433238983154
Validation loss: 2.1813443476153958

Epoch: 234| Step: 0
Training loss: 1.9610207080841064
Validation loss: 2.1973753731737853

Epoch: 5| Step: 1
Training loss: 2.4514269828796387
Validation loss: 2.1880565176727953

Epoch: 5| Step: 2
Training loss: 2.114750385284424
Validation loss: 2.1754915342536023

Epoch: 5| Step: 3
Training loss: 2.0876502990722656
Validation loss: 2.1627199265264694

Epoch: 5| Step: 4
Training loss: 2.5682272911071777
Validation loss: 2.1560362872257026

Epoch: 5| Step: 5
Training loss: 2.141146183013916
Validation loss: 2.166729739917222

Epoch: 5| Step: 6
Training loss: 2.3838953971862793
Validation loss: 2.1649520256186046

Epoch: 5| Step: 7
Training loss: 2.7374892234802246
Validation loss: 2.1957364005427205

Epoch: 5| Step: 8
Training loss: 2.1663248538970947
Validation loss: 2.198076319950883

Epoch: 5| Step: 9
Training loss: 1.8157379627227783
Validation loss: 2.205785571887929

Epoch: 5| Step: 10
Training loss: 1.957811713218689
Validation loss: 2.2002004449085524

Epoch: 235| Step: 0
Training loss: 1.5740277767181396
Validation loss: 2.203700005367238

Epoch: 5| Step: 1
Training loss: 1.8960869312286377
Validation loss: 2.192175385772541

Epoch: 5| Step: 2
Training loss: 1.757718801498413
Validation loss: 2.197728295480051

Epoch: 5| Step: 3
Training loss: 1.9429785013198853
Validation loss: 2.2114146986315326

Epoch: 5| Step: 4
Training loss: 2.5322444438934326
Validation loss: 2.1943074554525395

Epoch: 5| Step: 5
Training loss: 2.342270612716675
Validation loss: 2.1735373568791214

Epoch: 5| Step: 6
Training loss: 2.3644161224365234
Validation loss: 2.1627193625255297

Epoch: 5| Step: 7
Training loss: 2.8409831523895264
Validation loss: 2.168796600834016

Epoch: 5| Step: 8
Training loss: 2.3850913047790527
Validation loss: 2.1534208725857478

Epoch: 5| Step: 9
Training loss: 2.3365347385406494
Validation loss: 2.156248318251743

Epoch: 5| Step: 10
Training loss: 2.2594122886657715
Validation loss: 2.1770542078120734

Epoch: 236| Step: 0
Training loss: 1.7312662601470947
Validation loss: 2.1709689965812107

Epoch: 5| Step: 1
Training loss: 2.281442403793335
Validation loss: 2.1804502676892024

Epoch: 5| Step: 2
Training loss: 2.020585775375366
Validation loss: 2.1939668963032384

Epoch: 5| Step: 3
Training loss: 2.2439820766448975
Validation loss: 2.196428096422585

Epoch: 5| Step: 4
Training loss: 2.7624588012695312
Validation loss: 2.1997715042483423

Epoch: 5| Step: 5
Training loss: 1.3653090000152588
Validation loss: 2.195532978221934

Epoch: 5| Step: 6
Training loss: 2.1259360313415527
Validation loss: 2.18384971029015

Epoch: 5| Step: 7
Training loss: 2.1534900665283203
Validation loss: 2.172599025951919

Epoch: 5| Step: 8
Training loss: 2.3842616081237793
Validation loss: 2.1777057442613827

Epoch: 5| Step: 9
Training loss: 2.4461307525634766
Validation loss: 2.1880996637446906

Epoch: 5| Step: 10
Training loss: 2.9005072116851807
Validation loss: 2.2073124172866985

Epoch: 237| Step: 0
Training loss: 2.63643217086792
Validation loss: 2.1780853835485314

Epoch: 5| Step: 1
Training loss: 2.6426749229431152
Validation loss: 2.175285698265158

Epoch: 5| Step: 2
Training loss: 1.7897498607635498
Validation loss: 2.1712109324752644

Epoch: 5| Step: 3
Training loss: 2.536271572113037
Validation loss: 2.180635808616556

Epoch: 5| Step: 4
Training loss: 1.7649065256118774
Validation loss: 2.182906699436967

Epoch: 5| Step: 5
Training loss: 2.2567453384399414
Validation loss: 2.1887001427271033

Epoch: 5| Step: 6
Training loss: 1.980445146560669
Validation loss: 2.1683275404796807

Epoch: 5| Step: 7
Training loss: 2.0870938301086426
Validation loss: 2.171211705412916

Epoch: 5| Step: 8
Training loss: 2.1606037616729736
Validation loss: 2.1543261838215653

Epoch: 5| Step: 9
Training loss: 2.5912423133850098
Validation loss: 2.153680419409147

Epoch: 5| Step: 10
Training loss: 1.8454219102859497
Validation loss: 2.1583871879885272

Epoch: 238| Step: 0
Training loss: 1.6337372064590454
Validation loss: 2.1564879007236932

Epoch: 5| Step: 1
Training loss: 1.6945743560791016
Validation loss: 2.1440805722308416

Epoch: 5| Step: 2
Training loss: 2.25809383392334
Validation loss: 2.1641484691250708

Epoch: 5| Step: 3
Training loss: 2.3358206748962402
Validation loss: 2.171164253706573

Epoch: 5| Step: 4
Training loss: 2.9730048179626465
Validation loss: 2.1948197016152005

Epoch: 5| Step: 5
Training loss: 2.4859824180603027
Validation loss: 2.2037594779845207

Epoch: 5| Step: 6
Training loss: 2.128406286239624
Validation loss: 2.208978755499727

Epoch: 5| Step: 7
Training loss: 2.1951823234558105
Validation loss: 2.1925868654763825

Epoch: 5| Step: 8
Training loss: 1.7928359508514404
Validation loss: 2.1786914102492796

Epoch: 5| Step: 9
Training loss: 2.5291335582733154
Validation loss: 2.167745000572615

Epoch: 5| Step: 10
Training loss: 2.050853729248047
Validation loss: 2.162096537569518

Epoch: 239| Step: 0
Training loss: 2.285304546356201
Validation loss: 2.154561129949426

Epoch: 5| Step: 1
Training loss: 1.7361453771591187
Validation loss: 2.1570943170978176

Epoch: 5| Step: 2
Training loss: 2.3374924659729004
Validation loss: 2.1657627692786594

Epoch: 5| Step: 3
Training loss: 2.5890002250671387
Validation loss: 2.149120048810077

Epoch: 5| Step: 4
Training loss: 2.520934820175171
Validation loss: 2.134955770225935

Epoch: 5| Step: 5
Training loss: 2.1751456260681152
Validation loss: 2.129274978432604

Epoch: 5| Step: 6
Training loss: 2.509045362472534
Validation loss: 2.1402522748516453

Epoch: 5| Step: 7
Training loss: 1.8703193664550781
Validation loss: 2.152728121767762

Epoch: 5| Step: 8
Training loss: 2.0581822395324707
Validation loss: 2.164559560437356

Epoch: 5| Step: 9
Training loss: 2.09893536567688
Validation loss: 2.1608236118029525

Epoch: 5| Step: 10
Training loss: 1.8841850757598877
Validation loss: 2.1722396355803295

Epoch: 240| Step: 0
Training loss: 1.8797858953475952
Validation loss: 2.1903256139447613

Epoch: 5| Step: 1
Training loss: 2.7504518032073975
Validation loss: 2.1862269934787544

Epoch: 5| Step: 2
Training loss: 2.567196846008301
Validation loss: 2.1783711525701706

Epoch: 5| Step: 3
Training loss: 1.873530387878418
Validation loss: 2.1822308904381207

Epoch: 5| Step: 4
Training loss: 1.5128625631332397
Validation loss: 2.1828846880184707

Epoch: 5| Step: 5
Training loss: 2.4607131481170654
Validation loss: 2.180364698492071

Epoch: 5| Step: 6
Training loss: 2.010032892227173
Validation loss: 2.176036368134201

Epoch: 5| Step: 7
Training loss: 1.7333848476409912
Validation loss: 2.1744002885715936

Epoch: 5| Step: 8
Training loss: 2.3100597858428955
Validation loss: 2.183334183949296

Epoch: 5| Step: 9
Training loss: 2.2884068489074707
Validation loss: 2.180229248539094

Epoch: 5| Step: 10
Training loss: 2.6292591094970703
Validation loss: 2.184417147790232

Epoch: 241| Step: 0
Training loss: 2.373617649078369
Validation loss: 2.172376642944992

Epoch: 5| Step: 1
Training loss: 1.8302805423736572
Validation loss: 2.161549739940192

Epoch: 5| Step: 2
Training loss: 2.63429594039917
Validation loss: 2.1623719892194195

Epoch: 5| Step: 3
Training loss: 1.9918220043182373
Validation loss: 2.1520719348743396

Epoch: 5| Step: 4
Training loss: 2.073361873626709
Validation loss: 2.1589029142933507

Epoch: 5| Step: 5
Training loss: 2.007002592086792
Validation loss: 2.1503220360766173

Epoch: 5| Step: 6
Training loss: 2.5446321964263916
Validation loss: 2.16628614805078

Epoch: 5| Step: 7
Training loss: 2.3362936973571777
Validation loss: 2.1661234260887228

Epoch: 5| Step: 8
Training loss: 1.6642316579818726
Validation loss: 2.1749996715976345

Epoch: 5| Step: 9
Training loss: 2.4826483726501465
Validation loss: 2.1710606082793205

Epoch: 5| Step: 10
Training loss: 1.7548729181289673
Validation loss: 2.176515661260133

Epoch: 242| Step: 0
Training loss: 2.1689486503601074
Validation loss: 2.1800178174049623

Epoch: 5| Step: 1
Training loss: 1.720855951309204
Validation loss: 2.1696867186536073

Epoch: 5| Step: 2
Training loss: 2.0390448570251465
Validation loss: 2.1748809199179373

Epoch: 5| Step: 3
Training loss: 2.230762481689453
Validation loss: 2.179236101847823

Epoch: 5| Step: 4
Training loss: 2.2866199016571045
Validation loss: 2.190155662516112

Epoch: 5| Step: 5
Training loss: 1.8559215068817139
Validation loss: 2.1968035313390915

Epoch: 5| Step: 6
Training loss: 1.9594001770019531
Validation loss: 2.1869782734942693

Epoch: 5| Step: 7
Training loss: 2.707935094833374
Validation loss: 2.205981498123497

Epoch: 5| Step: 8
Training loss: 2.6509339809417725
Validation loss: 2.209845696726153

Epoch: 5| Step: 9
Training loss: 2.056222438812256
Validation loss: 2.1974831986170944

Epoch: 5| Step: 10
Training loss: 2.1148314476013184
Validation loss: 2.1834586307566655

Epoch: 243| Step: 0
Training loss: 2.87233304977417
Validation loss: 2.165121773237823

Epoch: 5| Step: 1
Training loss: 1.5750954151153564
Validation loss: 2.1649211401580484

Epoch: 5| Step: 2
Training loss: 2.074173927307129
Validation loss: 2.158141971916281

Epoch: 5| Step: 3
Training loss: 2.386134624481201
Validation loss: 2.14373371934378

Epoch: 5| Step: 4
Training loss: 2.351292371749878
Validation loss: 2.149324086404616

Epoch: 5| Step: 5
Training loss: 2.592101812362671
Validation loss: 2.1447055237267607

Epoch: 5| Step: 6
Training loss: 1.381422996520996
Validation loss: 2.134928903272075

Epoch: 5| Step: 7
Training loss: 2.271432876586914
Validation loss: 2.154063058155839

Epoch: 5| Step: 8
Training loss: 1.9750382900238037
Validation loss: 2.1605477256159626

Epoch: 5| Step: 9
Training loss: 2.167276382446289
Validation loss: 2.1599293011491016

Epoch: 5| Step: 10
Training loss: 1.9209015369415283
Validation loss: 2.175773210422967

Epoch: 244| Step: 0
Training loss: 2.195643663406372
Validation loss: 2.158349588353147

Epoch: 5| Step: 1
Training loss: 1.6902141571044922
Validation loss: 2.152126484019782

Epoch: 5| Step: 2
Training loss: 2.675769329071045
Validation loss: 2.1555717093970186

Epoch: 5| Step: 3
Training loss: 2.2384719848632812
Validation loss: 2.1485405122080157

Epoch: 5| Step: 4
Training loss: 2.56945538520813
Validation loss: 2.1333283737141597

Epoch: 5| Step: 5
Training loss: 2.665590286254883
Validation loss: 2.1384938173396613

Epoch: 5| Step: 6
Training loss: 2.039595127105713
Validation loss: 2.1361905938835553

Epoch: 5| Step: 7
Training loss: 1.8233999013900757
Validation loss: 2.1255483601682927

Epoch: 5| Step: 8
Training loss: 1.5087581872940063
Validation loss: 2.1351573364709013

Epoch: 5| Step: 9
Training loss: 2.2195420265197754
Validation loss: 2.1483099050419305

Epoch: 5| Step: 10
Training loss: 1.9071741104125977
Validation loss: 2.1663031193517868

Epoch: 245| Step: 0
Training loss: 2.092583179473877
Validation loss: 2.1736235131499586

Epoch: 5| Step: 1
Training loss: 2.6929244995117188
Validation loss: 2.1990892335932744

Epoch: 5| Step: 2
Training loss: 1.8948348760604858
Validation loss: 2.201998092794931

Epoch: 5| Step: 3
Training loss: 2.2957088947296143
Validation loss: 2.2190523070673787

Epoch: 5| Step: 4
Training loss: 2.1156773567199707
Validation loss: 2.2075611904103267

Epoch: 5| Step: 5
Training loss: 1.752912163734436
Validation loss: 2.186823098890243

Epoch: 5| Step: 6
Training loss: 1.5427087545394897
Validation loss: 2.172355851819438

Epoch: 5| Step: 7
Training loss: 2.0233778953552246
Validation loss: 2.1726589459244923

Epoch: 5| Step: 8
Training loss: 2.3938794136047363
Validation loss: 2.1668442077534174

Epoch: 5| Step: 9
Training loss: 2.274388551712036
Validation loss: 2.16092985804363

Epoch: 5| Step: 10
Training loss: 2.5516531467437744
Validation loss: 2.1581987386108725

Epoch: 246| Step: 0
Training loss: 2.1737618446350098
Validation loss: 2.1658552321054603

Epoch: 5| Step: 1
Training loss: 2.5524778366088867
Validation loss: 2.163040537987986

Epoch: 5| Step: 2
Training loss: 2.0836236476898193
Validation loss: 2.14995506758331

Epoch: 5| Step: 3
Training loss: 2.2569515705108643
Validation loss: 2.155908053921115

Epoch: 5| Step: 4
Training loss: 1.7213436365127563
Validation loss: 2.154079815392853

Epoch: 5| Step: 5
Training loss: 2.046720504760742
Validation loss: 2.16078003503943

Epoch: 5| Step: 6
Training loss: 2.26750111579895
Validation loss: 2.1662952156477076

Epoch: 5| Step: 7
Training loss: 1.844906210899353
Validation loss: 2.166490308700069

Epoch: 5| Step: 8
Training loss: 2.1339869499206543
Validation loss: 2.189042798934444

Epoch: 5| Step: 9
Training loss: 2.0589423179626465
Validation loss: 2.1857682530597975

Epoch: 5| Step: 10
Training loss: 2.302530288696289
Validation loss: 2.179690235404558

Epoch: 247| Step: 0
Training loss: 1.5801018476486206
Validation loss: 2.1822822939965034

Epoch: 5| Step: 1
Training loss: 2.5074830055236816
Validation loss: 2.1989327182051954

Epoch: 5| Step: 2
Training loss: 2.0654454231262207
Validation loss: 2.1916881991970922

Epoch: 5| Step: 3
Training loss: 1.6216310262680054
Validation loss: 2.1810763600052043

Epoch: 5| Step: 4
Training loss: 2.3713607788085938
Validation loss: 2.1711088406142367

Epoch: 5| Step: 5
Training loss: 2.768582582473755
Validation loss: 2.1635484759525587

Epoch: 5| Step: 6
Training loss: 2.0508198738098145
Validation loss: 2.1665221221985353

Epoch: 5| Step: 7
Training loss: 2.2956783771514893
Validation loss: 2.1582565230707966

Epoch: 5| Step: 8
Training loss: 2.373627185821533
Validation loss: 2.147282720893942

Epoch: 5| Step: 9
Training loss: 2.128894805908203
Validation loss: 2.1596786950224187

Epoch: 5| Step: 10
Training loss: 1.3836784362792969
Validation loss: 2.1513358982660438

Epoch: 248| Step: 0
Training loss: 1.9144976139068604
Validation loss: 2.159749592504194

Epoch: 5| Step: 1
Training loss: 2.1314806938171387
Validation loss: 2.1661769113233014

Epoch: 5| Step: 2
Training loss: 2.0389747619628906
Validation loss: 2.156060275211129

Epoch: 5| Step: 3
Training loss: 1.9462149143218994
Validation loss: 2.1448368641637985

Epoch: 5| Step: 4
Training loss: 1.40096116065979
Validation loss: 2.152951604576521

Epoch: 5| Step: 5
Training loss: 2.411050319671631
Validation loss: 2.1397145935284194

Epoch: 5| Step: 6
Training loss: 2.292867422103882
Validation loss: 2.154097928795763

Epoch: 5| Step: 7
Training loss: 2.5825304985046387
Validation loss: 2.1422365121943976

Epoch: 5| Step: 8
Training loss: 2.0424113273620605
Validation loss: 2.1429383959821475

Epoch: 5| Step: 9
Training loss: 2.0140321254730225
Validation loss: 2.1376369871119016

Epoch: 5| Step: 10
Training loss: 2.378234386444092
Validation loss: 2.145574164646928

Epoch: 249| Step: 0
Training loss: 1.9491350650787354
Validation loss: 2.1735866941431516

Epoch: 5| Step: 1
Training loss: 2.17573618888855
Validation loss: 2.1821076536691315

Epoch: 5| Step: 2
Training loss: 1.687593698501587
Validation loss: 2.2214015376183296

Epoch: 5| Step: 3
Training loss: 2.2064571380615234
Validation loss: 2.2169368036331667

Epoch: 5| Step: 4
Training loss: 2.2878692150115967
Validation loss: 2.2205731381652174

Epoch: 5| Step: 5
Training loss: 1.7848968505859375
Validation loss: 2.203829549974011

Epoch: 5| Step: 6
Training loss: 2.137848377227783
Validation loss: 2.1611481969074537

Epoch: 5| Step: 7
Training loss: 2.4053421020507812
Validation loss: 2.1475624038327124

Epoch: 5| Step: 8
Training loss: 2.234956741333008
Validation loss: 2.1299960023613385

Epoch: 5| Step: 9
Training loss: 1.9804408550262451
Validation loss: 2.1269911950634373

Epoch: 5| Step: 10
Training loss: 2.4284660816192627
Validation loss: 2.1217558512123684

Epoch: 250| Step: 0
Training loss: 1.5473203659057617
Validation loss: 2.1316310821040982

Epoch: 5| Step: 1
Training loss: 2.653376817703247
Validation loss: 2.1308279011839177

Epoch: 5| Step: 2
Training loss: 1.5827856063842773
Validation loss: 2.146456633844683

Epoch: 5| Step: 3
Training loss: 2.405705690383911
Validation loss: 2.161129779713128

Epoch: 5| Step: 4
Training loss: 2.281630277633667
Validation loss: 2.1576302794999975

Epoch: 5| Step: 5
Training loss: 2.5123934745788574
Validation loss: 2.149483001360329

Epoch: 5| Step: 6
Training loss: 1.7716751098632812
Validation loss: 2.155376963717963

Epoch: 5| Step: 7
Training loss: 2.4439165592193604
Validation loss: 2.1604667004718574

Epoch: 5| Step: 8
Training loss: 2.3967983722686768
Validation loss: 2.16089698319794

Epoch: 5| Step: 9
Training loss: 1.9662284851074219
Validation loss: 2.167105454270558

Epoch: 5| Step: 10
Training loss: 1.457074761390686
Validation loss: 2.184139459363876

Epoch: 251| Step: 0
Training loss: 2.035799980163574
Validation loss: 2.1713255887390464

Epoch: 5| Step: 1
Training loss: 2.0354442596435547
Validation loss: 2.1668634824855353

Epoch: 5| Step: 2
Training loss: 2.092280149459839
Validation loss: 2.164128242000457

Epoch: 5| Step: 3
Training loss: 1.7232978343963623
Validation loss: 2.1618506446961434

Epoch: 5| Step: 4
Training loss: 2.202265739440918
Validation loss: 2.1592942822364067

Epoch: 5| Step: 5
Training loss: 2.3872597217559814
Validation loss: 2.1498661400169454

Epoch: 5| Step: 6
Training loss: 2.107187032699585
Validation loss: 2.1486800011768135

Epoch: 5| Step: 7
Training loss: 2.233356475830078
Validation loss: 2.1560091613441386

Epoch: 5| Step: 8
Training loss: 2.149419069290161
Validation loss: 2.1510565729551416

Epoch: 5| Step: 9
Training loss: 2.037153720855713
Validation loss: 2.145916035098414

Epoch: 5| Step: 10
Training loss: 1.9710901975631714
Validation loss: 2.154808223888438

Epoch: 252| Step: 0
Training loss: 1.6748348474502563
Validation loss: 2.137174165377053

Epoch: 5| Step: 1
Training loss: 2.5984139442443848
Validation loss: 2.1629441912456224

Epoch: 5| Step: 2
Training loss: 2.049039840698242
Validation loss: 2.1549642534666162

Epoch: 5| Step: 3
Training loss: 1.7835766077041626
Validation loss: 2.1760969572169806

Epoch: 5| Step: 4
Training loss: 2.50262713432312
Validation loss: 2.1652865332941853

Epoch: 5| Step: 5
Training loss: 2.124605894088745
Validation loss: 2.1662626727934806

Epoch: 5| Step: 6
Training loss: 2.1011013984680176
Validation loss: 2.159120739147227

Epoch: 5| Step: 7
Training loss: 1.7972404956817627
Validation loss: 2.1571861326053576

Epoch: 5| Step: 8
Training loss: 1.7363173961639404
Validation loss: 2.141997495005208

Epoch: 5| Step: 9
Training loss: 2.105311870574951
Validation loss: 2.1292426919424408

Epoch: 5| Step: 10
Training loss: 2.4583382606506348
Validation loss: 2.13216858653612

Epoch: 253| Step: 0
Training loss: 2.0306830406188965
Validation loss: 2.11857928640099

Epoch: 5| Step: 1
Training loss: 2.2533302307128906
Validation loss: 2.12835112438407

Epoch: 5| Step: 2
Training loss: 2.575679063796997
Validation loss: 2.123561188738833

Epoch: 5| Step: 3
Training loss: 1.878369688987732
Validation loss: 2.146167080889466

Epoch: 5| Step: 4
Training loss: 2.6108779907226562
Validation loss: 2.1473283178062847

Epoch: 5| Step: 5
Training loss: 2.263758420944214
Validation loss: 2.14415814030555

Epoch: 5| Step: 6
Training loss: 1.7509901523590088
Validation loss: 2.164990791710474

Epoch: 5| Step: 7
Training loss: 1.7688877582550049
Validation loss: 2.166376256173657

Epoch: 5| Step: 8
Training loss: 1.7798149585723877
Validation loss: 2.1885919917014336

Epoch: 5| Step: 9
Training loss: 1.5012177228927612
Validation loss: 2.1740309512743385

Epoch: 5| Step: 10
Training loss: 2.50144362449646
Validation loss: 2.178973990101968

Epoch: 254| Step: 0
Training loss: 2.043454647064209
Validation loss: 2.175290447409435

Epoch: 5| Step: 1
Training loss: 2.241137981414795
Validation loss: 2.13879136372638

Epoch: 5| Step: 2
Training loss: 2.6217939853668213
Validation loss: 2.1390039318351337

Epoch: 5| Step: 3
Training loss: 2.1784873008728027
Validation loss: 2.13552616488549

Epoch: 5| Step: 4
Training loss: 1.4117237329483032
Validation loss: 2.13785078576816

Epoch: 5| Step: 5
Training loss: 1.9846420288085938
Validation loss: 2.1340974441138645

Epoch: 5| Step: 6
Training loss: 2.0206284523010254
Validation loss: 2.135263419920398

Epoch: 5| Step: 7
Training loss: 2.502685070037842
Validation loss: 2.127723213165037

Epoch: 5| Step: 8
Training loss: 2.205645799636841
Validation loss: 2.1234057462343605

Epoch: 5| Step: 9
Training loss: 2.1854312419891357
Validation loss: 2.1300449114973827

Epoch: 5| Step: 10
Training loss: 1.3284342288970947
Validation loss: 2.1153680496318366

Epoch: 255| Step: 0
Training loss: 1.962720513343811
Validation loss: 2.1165348611852175

Epoch: 5| Step: 1
Training loss: 2.3558945655822754
Validation loss: 2.1174815034353607

Epoch: 5| Step: 2
Training loss: 2.451852560043335
Validation loss: 2.1321438307403238

Epoch: 5| Step: 3
Training loss: 1.907575011253357
Validation loss: 2.1737797055193173

Epoch: 5| Step: 4
Training loss: 2.403472423553467
Validation loss: 2.183004661272931

Epoch: 5| Step: 5
Training loss: 2.51063871383667
Validation loss: 2.1815157705737698

Epoch: 5| Step: 6
Training loss: 1.780739188194275
Validation loss: 2.1603599671394593

Epoch: 5| Step: 7
Training loss: 2.046679735183716
Validation loss: 2.159695984214865

Epoch: 5| Step: 8
Training loss: 1.9949499368667603
Validation loss: 2.124147950962026

Epoch: 5| Step: 9
Training loss: 1.418277621269226
Validation loss: 2.1038854839981243

Epoch: 5| Step: 10
Training loss: 1.909502625465393
Validation loss: 2.096744465571578

Epoch: 256| Step: 0
Training loss: 2.160647392272949
Validation loss: 2.0845811854126635

Epoch: 5| Step: 1
Training loss: 2.0943000316619873
Validation loss: 2.0979206203132548

Epoch: 5| Step: 2
Training loss: 2.163748264312744
Validation loss: 2.1120283424213366

Epoch: 5| Step: 3
Training loss: 1.6111218929290771
Validation loss: 2.1181694461453344

Epoch: 5| Step: 4
Training loss: 1.9851871728897095
Validation loss: 2.1453226099732103

Epoch: 5| Step: 5
Training loss: 1.964686632156372
Validation loss: 2.1708931846003376

Epoch: 5| Step: 6
Training loss: 1.8825874328613281
Validation loss: 2.2072168434819868

Epoch: 5| Step: 7
Training loss: 2.655844211578369
Validation loss: 2.2236913352884273

Epoch: 5| Step: 8
Training loss: 2.3501455783843994
Validation loss: 2.201556879986999

Epoch: 5| Step: 9
Training loss: 2.029205322265625
Validation loss: 2.1881287251749346

Epoch: 5| Step: 10
Training loss: 2.3224546909332275
Validation loss: 2.158095872530373

Epoch: 257| Step: 0
Training loss: 2.3521218299865723
Validation loss: 2.140763093066472

Epoch: 5| Step: 1
Training loss: 1.9906055927276611
Validation loss: 2.1264835916539675

Epoch: 5| Step: 2
Training loss: 2.4577910900115967
Validation loss: 2.119999962468301

Epoch: 5| Step: 3
Training loss: 2.5102152824401855
Validation loss: 2.11623429482983

Epoch: 5| Step: 4
Training loss: 1.8622815608978271
Validation loss: 2.1063659716677923

Epoch: 5| Step: 5
Training loss: 2.0829672813415527
Validation loss: 2.108845039080548

Epoch: 5| Step: 6
Training loss: 1.5968437194824219
Validation loss: 2.1125079457477858

Epoch: 5| Step: 7
Training loss: 2.0011579990386963
Validation loss: 2.114989329409856

Epoch: 5| Step: 8
Training loss: 1.505824327468872
Validation loss: 2.118298662606106

Epoch: 5| Step: 9
Training loss: 1.9751617908477783
Validation loss: 2.133062744653353

Epoch: 5| Step: 10
Training loss: 2.6447668075561523
Validation loss: 2.1731051527043825

Epoch: 258| Step: 0
Training loss: 1.9158605337142944
Validation loss: 2.186897244504703

Epoch: 5| Step: 1
Training loss: 1.8879024982452393
Validation loss: 2.20650896205697

Epoch: 5| Step: 2
Training loss: 2.6650168895721436
Validation loss: 2.2141119626260575

Epoch: 5| Step: 3
Training loss: 2.1611695289611816
Validation loss: 2.1950650650967836

Epoch: 5| Step: 4
Training loss: 2.068260431289673
Validation loss: 2.2012158952733523

Epoch: 5| Step: 5
Training loss: 1.853915810585022
Validation loss: 2.1916289457710842

Epoch: 5| Step: 6
Training loss: 1.6127694845199585
Validation loss: 2.1785180196967175

Epoch: 5| Step: 7
Training loss: 1.8259977102279663
Validation loss: 2.194908260017313

Epoch: 5| Step: 8
Training loss: 2.527144193649292
Validation loss: 2.1904461447910597

Epoch: 5| Step: 9
Training loss: 2.1804792881011963
Validation loss: 2.1753532245594966

Epoch: 5| Step: 10
Training loss: 2.27955961227417
Validation loss: 2.14233329731931

Epoch: 259| Step: 0
Training loss: 2.1241955757141113
Validation loss: 2.1023496427843646

Epoch: 5| Step: 1
Training loss: 1.7835712432861328
Validation loss: 2.106680195818665

Epoch: 5| Step: 2
Training loss: 2.535212278366089
Validation loss: 2.132931096579439

Epoch: 5| Step: 3
Training loss: 1.5980451107025146
Validation loss: 2.1607323538872505

Epoch: 5| Step: 4
Training loss: 2.679016590118408
Validation loss: 2.1529408552313365

Epoch: 5| Step: 5
Training loss: 1.8319507837295532
Validation loss: 2.149260392753027

Epoch: 5| Step: 6
Training loss: 2.211280584335327
Validation loss: 2.135374508878236

Epoch: 5| Step: 7
Training loss: 1.59689462184906
Validation loss: 2.1299834033494354

Epoch: 5| Step: 8
Training loss: 2.0147249698638916
Validation loss: 2.137982653033349

Epoch: 5| Step: 9
Training loss: 2.361708402633667
Validation loss: 2.1312304978729575

Epoch: 5| Step: 10
Training loss: 2.158622980117798
Validation loss: 2.1301694172684864

Epoch: 260| Step: 0
Training loss: 2.1310529708862305
Validation loss: 2.1345379455115205

Epoch: 5| Step: 1
Training loss: 2.052635669708252
Validation loss: 2.144870494001655

Epoch: 5| Step: 2
Training loss: 2.1884803771972656
Validation loss: 2.1355846799829954

Epoch: 5| Step: 3
Training loss: 2.502382755279541
Validation loss: 2.122599991418982

Epoch: 5| Step: 4
Training loss: 1.6709620952606201
Validation loss: 2.1377853539682206

Epoch: 5| Step: 5
Training loss: 1.972907304763794
Validation loss: 2.1385280880876767

Epoch: 5| Step: 6
Training loss: 2.1805672645568848
Validation loss: 2.129178111271192

Epoch: 5| Step: 7
Training loss: 2.2174770832061768
Validation loss: 2.141733133664695

Epoch: 5| Step: 8
Training loss: 1.7754360437393188
Validation loss: 2.1698048371140675

Epoch: 5| Step: 9
Training loss: 2.2218024730682373
Validation loss: 2.178929526318786

Epoch: 5| Step: 10
Training loss: 1.7528399229049683
Validation loss: 2.1734298480454313

Epoch: 261| Step: 0
Training loss: 2.5165603160858154
Validation loss: 2.1580560438094603

Epoch: 5| Step: 1
Training loss: 1.9634277820587158
Validation loss: 2.157791401750298

Epoch: 5| Step: 2
Training loss: 2.745093584060669
Validation loss: 2.1349132009731826

Epoch: 5| Step: 3
Training loss: 2.1014702320098877
Validation loss: 2.13003283931363

Epoch: 5| Step: 4
Training loss: 2.488431453704834
Validation loss: 2.127147105432326

Epoch: 5| Step: 5
Training loss: 1.652514100074768
Validation loss: 2.129406564979143

Epoch: 5| Step: 6
Training loss: 2.088627576828003
Validation loss: 2.1241666642568444

Epoch: 5| Step: 7
Training loss: 2.381056547164917
Validation loss: 2.1420985216735513

Epoch: 5| Step: 8
Training loss: 1.6385393142700195
Validation loss: 2.137283102158577

Epoch: 5| Step: 9
Training loss: 1.440802812576294
Validation loss: 2.13243692921054

Epoch: 5| Step: 10
Training loss: 1.6632378101348877
Validation loss: 2.1382017135620117

Epoch: 262| Step: 0
Training loss: 2.5044236183166504
Validation loss: 2.1330361443181194

Epoch: 5| Step: 1
Training loss: 1.7135798931121826
Validation loss: 2.126930808508268

Epoch: 5| Step: 2
Training loss: 2.275697946548462
Validation loss: 2.1415263247746292

Epoch: 5| Step: 3
Training loss: 2.53853702545166
Validation loss: 2.162259535122943

Epoch: 5| Step: 4
Training loss: 2.436305284500122
Validation loss: 2.191636536711006

Epoch: 5| Step: 5
Training loss: 1.9481639862060547
Validation loss: 2.207943324119814

Epoch: 5| Step: 6
Training loss: 2.035421371459961
Validation loss: 2.2129078962469615

Epoch: 5| Step: 7
Training loss: 1.6932865381240845
Validation loss: 2.215675800077377

Epoch: 5| Step: 8
Training loss: 2.0695056915283203
Validation loss: 2.1952491191125687

Epoch: 5| Step: 9
Training loss: 1.7398399114608765
Validation loss: 2.174953652966407

Epoch: 5| Step: 10
Training loss: 1.621228814125061
Validation loss: 2.1336655462941816

Epoch: 263| Step: 0
Training loss: 2.103787899017334
Validation loss: 2.108526083730882

Epoch: 5| Step: 1
Training loss: 2.20800518989563
Validation loss: 2.1003971330581175

Epoch: 5| Step: 2
Training loss: 1.8298168182373047
Validation loss: 2.075145700926422

Epoch: 5| Step: 3
Training loss: 1.8696072101593018
Validation loss: 2.091618981412662

Epoch: 5| Step: 4
Training loss: 2.4006142616271973
Validation loss: 2.0978785650704497

Epoch: 5| Step: 5
Training loss: 2.1875128746032715
Validation loss: 2.0963897910169376

Epoch: 5| Step: 6
Training loss: 1.8076837062835693
Validation loss: 2.1171996285838466

Epoch: 5| Step: 7
Training loss: 2.052385091781616
Validation loss: 2.1241668296116654

Epoch: 5| Step: 8
Training loss: 2.1476662158966064
Validation loss: 2.1460918008640246

Epoch: 5| Step: 9
Training loss: 2.0615017414093018
Validation loss: 2.1269153830825642

Epoch: 5| Step: 10
Training loss: 1.6958743333816528
Validation loss: 2.1276023387908936

Epoch: 264| Step: 0
Training loss: 2.0200881958007812
Validation loss: 2.1222550824124324

Epoch: 5| Step: 1
Training loss: 1.7128101587295532
Validation loss: 2.1303924065764233

Epoch: 5| Step: 2
Training loss: 1.99138605594635
Validation loss: 2.1391912378290647

Epoch: 5| Step: 3
Training loss: 2.6640167236328125
Validation loss: 2.145597460449383

Epoch: 5| Step: 4
Training loss: 1.8389513492584229
Validation loss: 2.1483222335897465

Epoch: 5| Step: 5
Training loss: 2.2795724868774414
Validation loss: 2.1520353850497993

Epoch: 5| Step: 6
Training loss: 1.780267357826233
Validation loss: 2.139573762493749

Epoch: 5| Step: 7
Training loss: 2.031953811645508
Validation loss: 2.1422226864804506

Epoch: 5| Step: 8
Training loss: 1.775240182876587
Validation loss: 2.138478731596342

Epoch: 5| Step: 9
Training loss: 2.3400847911834717
Validation loss: 2.1434749608398764

Epoch: 5| Step: 10
Training loss: 1.774708867073059
Validation loss: 2.148356209519089

Epoch: 265| Step: 0
Training loss: 2.230313301086426
Validation loss: 2.1579842067533925

Epoch: 5| Step: 1
Training loss: 2.5117266178131104
Validation loss: 2.157921052748157

Epoch: 5| Step: 2
Training loss: 1.8267028331756592
Validation loss: 2.1528022943004483

Epoch: 5| Step: 3
Training loss: 2.016071319580078
Validation loss: 2.140398230603946

Epoch: 5| Step: 4
Training loss: 1.596444845199585
Validation loss: 2.129199433070357

Epoch: 5| Step: 5
Training loss: 1.9936720132827759
Validation loss: 2.1294823820872972

Epoch: 5| Step: 6
Training loss: 1.9863433837890625
Validation loss: 2.1372410815249205

Epoch: 5| Step: 7
Training loss: 2.1240859031677246
Validation loss: 2.14801517609627

Epoch: 5| Step: 8
Training loss: 2.129344940185547
Validation loss: 2.147174217367685

Epoch: 5| Step: 9
Training loss: 1.7117283344268799
Validation loss: 2.176904809090399

Epoch: 5| Step: 10
Training loss: 2.1062023639678955
Validation loss: 2.1733355163246073

Epoch: 266| Step: 0
Training loss: 2.3211398124694824
Validation loss: 2.176089785432303

Epoch: 5| Step: 1
Training loss: 1.8544842004776
Validation loss: 2.177957938563439

Epoch: 5| Step: 2
Training loss: 1.9214948415756226
Validation loss: 2.153288923284059

Epoch: 5| Step: 3
Training loss: 2.5007543563842773
Validation loss: 2.1261018527451383

Epoch: 5| Step: 4
Training loss: 1.7482799291610718
Validation loss: 2.1225322779788764

Epoch: 5| Step: 5
Training loss: 1.9612255096435547
Validation loss: 2.1082285245259604

Epoch: 5| Step: 6
Training loss: 1.7876732349395752
Validation loss: 2.1240712417069303

Epoch: 5| Step: 7
Training loss: 1.576968789100647
Validation loss: 2.125706870068786

Epoch: 5| Step: 8
Training loss: 2.4805922508239746
Validation loss: 2.147975003847512

Epoch: 5| Step: 9
Training loss: 1.5511136054992676
Validation loss: 2.154532637647403

Epoch: 5| Step: 10
Training loss: 2.454083204269409
Validation loss: 2.161994598245108

Epoch: 267| Step: 0
Training loss: 1.4297822713851929
Validation loss: 2.1720882000461703

Epoch: 5| Step: 1
Training loss: 2.2089524269104004
Validation loss: 2.1658824131052983

Epoch: 5| Step: 2
Training loss: 1.6475932598114014
Validation loss: 2.145853777085581

Epoch: 5| Step: 3
Training loss: 2.1034042835235596
Validation loss: 2.121789232377083

Epoch: 5| Step: 4
Training loss: 2.0531680583953857
Validation loss: 2.1069090776546027

Epoch: 5| Step: 5
Training loss: 2.1503612995147705
Validation loss: 2.109943461674516

Epoch: 5| Step: 6
Training loss: 2.0976409912109375
Validation loss: 2.106147332858014

Epoch: 5| Step: 7
Training loss: 1.3740413188934326
Validation loss: 2.0889206240254063

Epoch: 5| Step: 8
Training loss: 2.3972861766815186
Validation loss: 2.093170272406711

Epoch: 5| Step: 9
Training loss: 2.3668673038482666
Validation loss: 2.102479532200803

Epoch: 5| Step: 10
Training loss: 2.5392062664031982
Validation loss: 2.10925288866925

Epoch: 268| Step: 0
Training loss: 1.492165207862854
Validation loss: 2.1221496981959187

Epoch: 5| Step: 1
Training loss: 1.8210151195526123
Validation loss: 2.1550768062632573

Epoch: 5| Step: 2
Training loss: 2.6159870624542236
Validation loss: 2.1595072707822247

Epoch: 5| Step: 3
Training loss: 1.9397004842758179
Validation loss: 2.167470375696818

Epoch: 5| Step: 4
Training loss: 2.130396604537964
Validation loss: 2.1645494199568227

Epoch: 5| Step: 5
Training loss: 1.5803391933441162
Validation loss: 2.158118324895059

Epoch: 5| Step: 6
Training loss: 1.566872239112854
Validation loss: 2.1576555941694524

Epoch: 5| Step: 7
Training loss: 2.036774158477783
Validation loss: 2.137757101366597

Epoch: 5| Step: 8
Training loss: 2.610991954803467
Validation loss: 2.1342182402969687

Epoch: 5| Step: 9
Training loss: 1.9585168361663818
Validation loss: 2.118904439351892

Epoch: 5| Step: 10
Training loss: 2.34676194190979
Validation loss: 2.130481320042764

Epoch: 269| Step: 0
Training loss: 2.6664352416992188
Validation loss: 2.1287570614968576

Epoch: 5| Step: 1
Training loss: 1.378631353378296
Validation loss: 2.1198496126359507

Epoch: 5| Step: 2
Training loss: 2.410806179046631
Validation loss: 2.114897874093825

Epoch: 5| Step: 3
Training loss: 1.5155210494995117
Validation loss: 2.102749147722798

Epoch: 5| Step: 4
Training loss: 1.666069746017456
Validation loss: 2.1086712729546333

Epoch: 5| Step: 5
Training loss: 1.7847322225570679
Validation loss: 2.1216922524154826

Epoch: 5| Step: 6
Training loss: 2.6999707221984863
Validation loss: 2.1294513081991546

Epoch: 5| Step: 7
Training loss: 2.0590453147888184
Validation loss: 2.1371861042514926

Epoch: 5| Step: 8
Training loss: 2.354611396789551
Validation loss: 2.1532952785491943

Epoch: 5| Step: 9
Training loss: 1.4148995876312256
Validation loss: 2.1887119713649956

Epoch: 5| Step: 10
Training loss: 2.1396124362945557
Validation loss: 2.1664770136597338

Epoch: 270| Step: 0
Training loss: 1.7389700412750244
Validation loss: 2.154191360678724

Epoch: 5| Step: 1
Training loss: 1.994998574256897
Validation loss: 2.147437382769841

Epoch: 5| Step: 2
Training loss: 1.7632057666778564
Validation loss: 2.1597987195496917

Epoch: 5| Step: 3
Training loss: 1.90433669090271
Validation loss: 2.164400359635712

Epoch: 5| Step: 4
Training loss: 1.720653772354126
Validation loss: 2.1481136557876424

Epoch: 5| Step: 5
Training loss: 2.3620445728302
Validation loss: 2.146575063787481

Epoch: 5| Step: 6
Training loss: 2.1250216960906982
Validation loss: 2.1244258290977887

Epoch: 5| Step: 7
Training loss: 2.1849112510681152
Validation loss: 2.146831004850326

Epoch: 5| Step: 8
Training loss: 2.2742531299591064
Validation loss: 2.1388506863706853

Epoch: 5| Step: 9
Training loss: 2.083029270172119
Validation loss: 2.131766095597257

Epoch: 5| Step: 10
Training loss: 1.672149896621704
Validation loss: 2.1321294499981787

Epoch: 271| Step: 0
Training loss: 1.980051040649414
Validation loss: 2.098703517708727

Epoch: 5| Step: 1
Training loss: 2.3604040145874023
Validation loss: 2.1027933013054634

Epoch: 5| Step: 2
Training loss: 2.1969540119171143
Validation loss: 2.093246606088454

Epoch: 5| Step: 3
Training loss: 1.6695516109466553
Validation loss: 2.0962550922106673

Epoch: 5| Step: 4
Training loss: 1.7984956502914429
Validation loss: 2.091159825683922

Epoch: 5| Step: 5
Training loss: 2.178819179534912
Validation loss: 2.102760786651283

Epoch: 5| Step: 6
Training loss: 2.2996444702148438
Validation loss: 2.123166558563068

Epoch: 5| Step: 7
Training loss: 1.0932384729385376
Validation loss: 2.124163547510742

Epoch: 5| Step: 8
Training loss: 1.5849149227142334
Validation loss: 2.144209067026774

Epoch: 5| Step: 9
Training loss: 2.5128931999206543
Validation loss: 2.145284893692181

Epoch: 5| Step: 10
Training loss: 2.1474101543426514
Validation loss: 2.15943040386323

Epoch: 272| Step: 0
Training loss: 1.7919962406158447
Validation loss: 2.1672253454885175

Epoch: 5| Step: 1
Training loss: 1.9916528463363647
Validation loss: 2.141757308795888

Epoch: 5| Step: 2
Training loss: 1.8622655868530273
Validation loss: 2.1371417327593734

Epoch: 5| Step: 3
Training loss: 1.8670101165771484
Validation loss: 2.115905164390482

Epoch: 5| Step: 4
Training loss: 2.0725040435791016
Validation loss: 2.1016214855255617

Epoch: 5| Step: 5
Training loss: 1.6418403387069702
Validation loss: 2.1093197125260548

Epoch: 5| Step: 6
Training loss: 1.6654548645019531
Validation loss: 2.1236781381791636

Epoch: 5| Step: 7
Training loss: 2.807612180709839
Validation loss: 2.1288258978115615

Epoch: 5| Step: 8
Training loss: 1.7312383651733398
Validation loss: 2.1437367623852146

Epoch: 5| Step: 9
Training loss: 2.077894687652588
Validation loss: 2.1395404825928392

Epoch: 5| Step: 10
Training loss: 2.5178909301757812
Validation loss: 2.1501609279263403

Epoch: 273| Step: 0
Training loss: 1.4142457246780396
Validation loss: 2.149253081249934

Epoch: 5| Step: 1
Training loss: 2.181459426879883
Validation loss: 2.146887146016603

Epoch: 5| Step: 2
Training loss: 2.351372480392456
Validation loss: 2.1568453747739076

Epoch: 5| Step: 3
Training loss: 2.0373353958129883
Validation loss: 2.1581209398085073

Epoch: 5| Step: 4
Training loss: 2.0189430713653564
Validation loss: 2.1451699631188506

Epoch: 5| Step: 5
Training loss: 2.2065248489379883
Validation loss: 2.1153554557472147

Epoch: 5| Step: 6
Training loss: 1.9624611139297485
Validation loss: 2.1071260513797885

Epoch: 5| Step: 7
Training loss: 1.1417495012283325
Validation loss: 2.094219156490859

Epoch: 5| Step: 8
Training loss: 1.9696686267852783
Validation loss: 2.115103126854025

Epoch: 5| Step: 9
Training loss: 2.1008992195129395
Validation loss: 2.125631465706774

Epoch: 5| Step: 10
Training loss: 2.522200345993042
Validation loss: 2.117811974658761

Epoch: 274| Step: 0
Training loss: 2.2471096515655518
Validation loss: 2.11879587429826

Epoch: 5| Step: 1
Training loss: 2.231781005859375
Validation loss: 2.114208011217015

Epoch: 5| Step: 2
Training loss: 1.8340561389923096
Validation loss: 2.1070827181621263

Epoch: 5| Step: 3
Training loss: 1.9109957218170166
Validation loss: 2.0979883901534544

Epoch: 5| Step: 4
Training loss: 1.8910694122314453
Validation loss: 2.1113338701186644

Epoch: 5| Step: 5
Training loss: 1.9346157312393188
Validation loss: 2.114756207312307

Epoch: 5| Step: 6
Training loss: 2.3595707416534424
Validation loss: 2.1177110415633007

Epoch: 5| Step: 7
Training loss: 1.6854721307754517
Validation loss: 2.141590235053852

Epoch: 5| Step: 8
Training loss: 1.9570674896240234
Validation loss: 2.1558756033579507

Epoch: 5| Step: 9
Training loss: 1.8270666599273682
Validation loss: 2.1715764127751833

Epoch: 5| Step: 10
Training loss: 1.748844027519226
Validation loss: 2.171012686144921

Epoch: 275| Step: 0
Training loss: 1.9359290599822998
Validation loss: 2.171497601334767

Epoch: 5| Step: 1
Training loss: 2.058856964111328
Validation loss: 2.1629924543442263

Epoch: 5| Step: 2
Training loss: 2.260874032974243
Validation loss: 2.1962763981152604

Epoch: 5| Step: 3
Training loss: 2.181349515914917
Validation loss: 2.169905677918465

Epoch: 5| Step: 4
Training loss: 1.4844733476638794
Validation loss: 2.1581106596095587

Epoch: 5| Step: 5
Training loss: 1.4494540691375732
Validation loss: 2.130105726180538

Epoch: 5| Step: 6
Training loss: 2.6301097869873047
Validation loss: 2.1147908369700112

Epoch: 5| Step: 7
Training loss: 1.5120465755462646
Validation loss: 2.105866138653089

Epoch: 5| Step: 8
Training loss: 1.8382909297943115
Validation loss: 2.099096352054227

Epoch: 5| Step: 9
Training loss: 2.025299549102783
Validation loss: 2.1007626056671143

Epoch: 5| Step: 10
Training loss: 2.3140406608581543
Validation loss: 2.10773298048204

Epoch: 276| Step: 0
Training loss: 2.378619432449341
Validation loss: 2.10301536385731

Epoch: 5| Step: 1
Training loss: 1.827873945236206
Validation loss: 2.1037112576987154

Epoch: 5| Step: 2
Training loss: 2.152353286743164
Validation loss: 2.120857575888275

Epoch: 5| Step: 3
Training loss: 2.331967830657959
Validation loss: 2.1273529170661845

Epoch: 5| Step: 4
Training loss: 1.6728721857070923
Validation loss: 2.150817437838483

Epoch: 5| Step: 5
Training loss: 1.8265933990478516
Validation loss: 2.1463370989727717

Epoch: 5| Step: 6
Training loss: 1.9558912515640259
Validation loss: 2.1402099337629092

Epoch: 5| Step: 7
Training loss: 1.9366477727890015
Validation loss: 2.132544094516385

Epoch: 5| Step: 8
Training loss: 1.4227278232574463
Validation loss: 2.1369790812974334

Epoch: 5| Step: 9
Training loss: 2.1929640769958496
Validation loss: 2.1261352082734466

Epoch: 5| Step: 10
Training loss: 1.8461694717407227
Validation loss: 2.11520674151759

Epoch: 277| Step: 0
Training loss: 2.0827574729919434
Validation loss: 2.1064301947111725

Epoch: 5| Step: 1
Training loss: 2.425652503967285
Validation loss: 2.106087924331747

Epoch: 5| Step: 2
Training loss: 1.8945623636245728
Validation loss: 2.0978444878773024

Epoch: 5| Step: 3
Training loss: 2.2011845111846924
Validation loss: 2.1074216237632175

Epoch: 5| Step: 4
Training loss: 1.2700307369232178
Validation loss: 2.1263025729886946

Epoch: 5| Step: 5
Training loss: 2.396528482437134
Validation loss: 2.1234968016224522

Epoch: 5| Step: 6
Training loss: 1.3102589845657349
Validation loss: 2.128432055955292

Epoch: 5| Step: 7
Training loss: 2.046633243560791
Validation loss: 2.1409471586186397

Epoch: 5| Step: 8
Training loss: 2.2149925231933594
Validation loss: 2.130334033760973

Epoch: 5| Step: 9
Training loss: 2.115234136581421
Validation loss: 2.1338003220096713

Epoch: 5| Step: 10
Training loss: 1.5398294925689697
Validation loss: 2.1377874651262836

Epoch: 278| Step: 0
Training loss: 2.0125489234924316
Validation loss: 2.1457709907203593

Epoch: 5| Step: 1
Training loss: 1.91657292842865
Validation loss: 2.1423721954386723

Epoch: 5| Step: 2
Training loss: 1.9353969097137451
Validation loss: 2.146211847182243

Epoch: 5| Step: 3
Training loss: 2.1876425743103027
Validation loss: 2.157391973721084

Epoch: 5| Step: 4
Training loss: 2.0474770069122314
Validation loss: 2.1594419351188083

Epoch: 5| Step: 5
Training loss: 2.3381173610687256
Validation loss: 2.1563331081021215

Epoch: 5| Step: 6
Training loss: 1.496057152748108
Validation loss: 2.14180854828127

Epoch: 5| Step: 7
Training loss: 1.1025440692901611
Validation loss: 2.149023171394102

Epoch: 5| Step: 8
Training loss: 1.8802196979522705
Validation loss: 2.1409626788990472

Epoch: 5| Step: 9
Training loss: 2.6824190616607666
Validation loss: 2.1304059746444866

Epoch: 5| Step: 10
Training loss: 1.7726116180419922
Validation loss: 2.1007610726100143

Epoch: 279| Step: 0
Training loss: 1.7031446695327759
Validation loss: 2.1000912715029973

Epoch: 5| Step: 1
Training loss: 2.0533883571624756
Validation loss: 2.092856494329309

Epoch: 5| Step: 2
Training loss: 1.3776670694351196
Validation loss: 2.1173989106250066

Epoch: 5| Step: 3
Training loss: 1.8038089275360107
Validation loss: 2.1153214029086533

Epoch: 5| Step: 4
Training loss: 1.8990951776504517
Validation loss: 2.110537995574295

Epoch: 5| Step: 5
Training loss: 2.2225723266601562
Validation loss: 2.114090524693971

Epoch: 5| Step: 6
Training loss: 1.7644481658935547
Validation loss: 2.11228576655029

Epoch: 5| Step: 7
Training loss: 2.333198070526123
Validation loss: 2.1225120226542153

Epoch: 5| Step: 8
Training loss: 1.6984965801239014
Validation loss: 2.11736770086391

Epoch: 5| Step: 9
Training loss: 2.6468727588653564
Validation loss: 2.1383808556423394

Epoch: 5| Step: 10
Training loss: 1.7647444009780884
Validation loss: 2.161379027110274

Epoch: 280| Step: 0
Training loss: 1.3104830980300903
Validation loss: 2.1798812086864183

Epoch: 5| Step: 1
Training loss: 1.6340440511703491
Validation loss: 2.196100160639773

Epoch: 5| Step: 2
Training loss: 1.733299970626831
Validation loss: 2.1714761128989597

Epoch: 5| Step: 3
Training loss: 1.7327808141708374
Validation loss: 2.1587540154816

Epoch: 5| Step: 4
Training loss: 2.214832305908203
Validation loss: 2.1403879042594665

Epoch: 5| Step: 5
Training loss: 2.2037882804870605
Validation loss: 2.1236979282030495

Epoch: 5| Step: 6
Training loss: 2.682767152786255
Validation loss: 2.1293868659645

Epoch: 5| Step: 7
Training loss: 2.0469038486480713
Validation loss: 2.130116729326146

Epoch: 5| Step: 8
Training loss: 1.9664065837860107
Validation loss: 2.1171477353701027

Epoch: 5| Step: 9
Training loss: 2.1626102924346924
Validation loss: 2.1003392614344114

Epoch: 5| Step: 10
Training loss: 1.7223472595214844
Validation loss: 2.1023177754494453

Epoch: 281| Step: 0
Training loss: 2.7875304222106934
Validation loss: 2.111759508809736

Epoch: 5| Step: 1
Training loss: 2.046849250793457
Validation loss: 2.121306206590386

Epoch: 5| Step: 2
Training loss: 1.5847504138946533
Validation loss: 2.1387559137036725

Epoch: 5| Step: 3
Training loss: 1.8678483963012695
Validation loss: 2.1369006992668234

Epoch: 5| Step: 4
Training loss: 2.3654770851135254
Validation loss: 2.138289789999685

Epoch: 5| Step: 5
Training loss: 2.032874584197998
Validation loss: 2.1542925937201387

Epoch: 5| Step: 6
Training loss: 1.4568620920181274
Validation loss: 2.152541119565246

Epoch: 5| Step: 7
Training loss: 2.068621873855591
Validation loss: 2.164053378566619

Epoch: 5| Step: 8
Training loss: 1.8997974395751953
Validation loss: 2.180755293497475

Epoch: 5| Step: 9
Training loss: 1.3265717029571533
Validation loss: 2.157419849467534

Epoch: 5| Step: 10
Training loss: 1.797780990600586
Validation loss: 2.154051960155528

Epoch: 282| Step: 0
Training loss: 2.6465983390808105
Validation loss: 2.125613148494433

Epoch: 5| Step: 1
Training loss: 1.941286325454712
Validation loss: 2.1305445804390857

Epoch: 5| Step: 2
Training loss: 1.8991851806640625
Validation loss: 2.1237493535523773

Epoch: 5| Step: 3
Training loss: 2.1059181690216064
Validation loss: 2.1125942814734673

Epoch: 5| Step: 4
Training loss: 2.0567405223846436
Validation loss: 2.0943784431744645

Epoch: 5| Step: 5
Training loss: 1.9408620595932007
Validation loss: 2.0948274827772573

Epoch: 5| Step: 6
Training loss: 1.8934249877929688
Validation loss: 2.0625012331111456

Epoch: 5| Step: 7
Training loss: 1.9490966796875
Validation loss: 2.0761381400528776

Epoch: 5| Step: 8
Training loss: 1.8933000564575195
Validation loss: 2.0889311862248245

Epoch: 5| Step: 9
Training loss: 2.0121498107910156
Validation loss: 2.1020370273179907

Epoch: 5| Step: 10
Training loss: 0.8693431615829468
Validation loss: 2.1189454883657475

Epoch: 283| Step: 0
Training loss: 1.5624278783798218
Validation loss: 2.138219512918944

Epoch: 5| Step: 1
Training loss: 1.9148889780044556
Validation loss: 2.167865204554732

Epoch: 5| Step: 2
Training loss: 2.2108895778656006
Validation loss: 2.160786956869146

Epoch: 5| Step: 3
Training loss: 1.5228525400161743
Validation loss: 2.145789166932465

Epoch: 5| Step: 4
Training loss: 1.5266183614730835
Validation loss: 2.1396026380600466

Epoch: 5| Step: 5
Training loss: 1.7197744846343994
Validation loss: 2.135784682407174

Epoch: 5| Step: 6
Training loss: 1.5950013399124146
Validation loss: 2.141140091803766

Epoch: 5| Step: 7
Training loss: 2.4132273197174072
Validation loss: 2.134667545236567

Epoch: 5| Step: 8
Training loss: 2.3668715953826904
Validation loss: 2.140349098431167

Epoch: 5| Step: 9
Training loss: 2.7349026203155518
Validation loss: 2.1582493115496892

Epoch: 5| Step: 10
Training loss: 1.5321905612945557
Validation loss: 2.142536178711922

Epoch: 284| Step: 0
Training loss: 1.7663863897323608
Validation loss: 2.1383195256674163

Epoch: 5| Step: 1
Training loss: 2.542576551437378
Validation loss: 2.1334778108904437

Epoch: 5| Step: 2
Training loss: 1.664107084274292
Validation loss: 2.140845439767325

Epoch: 5| Step: 3
Training loss: 1.6710494756698608
Validation loss: 2.1254669748326784

Epoch: 5| Step: 4
Training loss: 1.6847350597381592
Validation loss: 2.1359773297463693

Epoch: 5| Step: 5
Training loss: 2.2289414405822754
Validation loss: 2.1215406515265025

Epoch: 5| Step: 6
Training loss: 1.8616702556610107
Validation loss: 2.1249657728338756

Epoch: 5| Step: 7
Training loss: 2.119400978088379
Validation loss: 2.101196074998507

Epoch: 5| Step: 8
Training loss: 1.7906761169433594
Validation loss: 2.129423310679774

Epoch: 5| Step: 9
Training loss: 1.6764004230499268
Validation loss: 2.1325494461162116

Epoch: 5| Step: 10
Training loss: 2.0478978157043457
Validation loss: 2.1455199692838933

Epoch: 285| Step: 0
Training loss: 1.3239753246307373
Validation loss: 2.1689061490438317

Epoch: 5| Step: 1
Training loss: 1.7300955057144165
Validation loss: 2.1543078781456075

Epoch: 5| Step: 2
Training loss: 2.1462719440460205
Validation loss: 2.1670792935996928

Epoch: 5| Step: 3
Training loss: 2.55146861076355
Validation loss: 2.1841376904518373

Epoch: 5| Step: 4
Training loss: 1.9324976205825806
Validation loss: 2.171811537076068

Epoch: 5| Step: 5
Training loss: 2.1490023136138916
Validation loss: 2.1508407131318124

Epoch: 5| Step: 6
Training loss: 1.8049728870391846
Validation loss: 2.1654833798767417

Epoch: 5| Step: 7
Training loss: 1.8393714427947998
Validation loss: 2.168374664040022

Epoch: 5| Step: 8
Training loss: 1.6764882802963257
Validation loss: 2.1270558782803115

Epoch: 5| Step: 9
Training loss: 2.364349126815796
Validation loss: 2.1110195293221423

Epoch: 5| Step: 10
Training loss: 1.3937830924987793
Validation loss: 2.081459128728477

Epoch: 286| Step: 0
Training loss: 2.350770950317383
Validation loss: 2.0838293926690215

Epoch: 5| Step: 1
Training loss: 1.377148151397705
Validation loss: 2.106383207023785

Epoch: 5| Step: 2
Training loss: 2.189375638961792
Validation loss: 2.1230563976431407

Epoch: 5| Step: 3
Training loss: 1.4089055061340332
Validation loss: 2.131660630626063

Epoch: 5| Step: 4
Training loss: 1.9452121257781982
Validation loss: 2.1222104257152927

Epoch: 5| Step: 5
Training loss: 2.252454996109009
Validation loss: 2.1232287935031358

Epoch: 5| Step: 6
Training loss: 2.3131752014160156
Validation loss: 2.129869848169306

Epoch: 5| Step: 7
Training loss: 1.5451266765594482
Validation loss: 2.1377389507908977

Epoch: 5| Step: 8
Training loss: 2.1393544673919678
Validation loss: 2.1451426936734106

Epoch: 5| Step: 9
Training loss: 1.575340986251831
Validation loss: 2.1340051440782446

Epoch: 5| Step: 10
Training loss: 2.288065195083618
Validation loss: 2.139897237541855

Epoch: 287| Step: 0
Training loss: 2.1368978023529053
Validation loss: 2.1411378832273584

Epoch: 5| Step: 1
Training loss: 2.468097448348999
Validation loss: 2.1338171894832323

Epoch: 5| Step: 2
Training loss: 1.4521043300628662
Validation loss: 2.1586868429696686

Epoch: 5| Step: 3
Training loss: 1.9126899242401123
Validation loss: 2.1737786685266802

Epoch: 5| Step: 4
Training loss: 1.7014286518096924
Validation loss: 2.184927737841042

Epoch: 5| Step: 5
Training loss: 1.940940499305725
Validation loss: 2.203789936598911

Epoch: 5| Step: 6
Training loss: 1.4402110576629639
Validation loss: 2.1889781387903358

Epoch: 5| Step: 7
Training loss: 1.7637851238250732
Validation loss: 2.1917267050794376

Epoch: 5| Step: 8
Training loss: 2.182971954345703
Validation loss: 2.1748417667163316

Epoch: 5| Step: 9
Training loss: 1.9942388534545898
Validation loss: 2.128479301288564

Epoch: 5| Step: 10
Training loss: 2.1137547492980957
Validation loss: 2.1269362485536965

Epoch: 288| Step: 0
Training loss: 1.9242099523544312
Validation loss: 2.1027589228845414

Epoch: 5| Step: 1
Training loss: 1.747881293296814
Validation loss: 2.1103986617057555

Epoch: 5| Step: 2
Training loss: 1.5774316787719727
Validation loss: 2.0909010748709402

Epoch: 5| Step: 3
Training loss: 1.8582121133804321
Validation loss: 2.11281015283318

Epoch: 5| Step: 4
Training loss: 2.117149829864502
Validation loss: 2.1061535766047816

Epoch: 5| Step: 5
Training loss: 1.7910035848617554
Validation loss: 2.133789393209642

Epoch: 5| Step: 6
Training loss: 1.9752349853515625
Validation loss: 2.150722962553783

Epoch: 5| Step: 7
Training loss: 2.1768622398376465
Validation loss: 2.1682408240533646

Epoch: 5| Step: 8
Training loss: 2.0281758308410645
Validation loss: 2.2017416902767715

Epoch: 5| Step: 9
Training loss: 2.2163584232330322
Validation loss: 2.212160474510603

Epoch: 5| Step: 10
Training loss: 1.4400657415390015
Validation loss: 2.20968137761598

Epoch: 289| Step: 0
Training loss: 1.9260791540145874
Validation loss: 2.168631387013261

Epoch: 5| Step: 1
Training loss: 1.9933106899261475
Validation loss: 2.119529042192685

Epoch: 5| Step: 2
Training loss: 2.09494686126709
Validation loss: 2.1197603902509137

Epoch: 5| Step: 3
Training loss: 2.1324944496154785
Validation loss: 2.1099955061430573

Epoch: 5| Step: 4
Training loss: 1.414817214012146
Validation loss: 2.112861439745913

Epoch: 5| Step: 5
Training loss: 1.9567877054214478
Validation loss: 2.1130296773807977

Epoch: 5| Step: 6
Training loss: 1.6507501602172852
Validation loss: 2.0939776179611043

Epoch: 5| Step: 7
Training loss: 1.6519346237182617
Validation loss: 2.105092538300381

Epoch: 5| Step: 8
Training loss: 1.6494251489639282
Validation loss: 2.1043019435739003

Epoch: 5| Step: 9
Training loss: 2.1126487255096436
Validation loss: 2.1280307821048203

Epoch: 5| Step: 10
Training loss: 2.4332358837127686
Validation loss: 2.162463447099091

Epoch: 290| Step: 0
Training loss: 1.4377329349517822
Validation loss: 2.2047339177900747

Epoch: 5| Step: 1
Training loss: 2.3526062965393066
Validation loss: 2.2280717408785256

Epoch: 5| Step: 2
Training loss: 2.097649335861206
Validation loss: 2.2012033231796755

Epoch: 5| Step: 3
Training loss: 2.4084620475769043
Validation loss: 2.164213567651728

Epoch: 5| Step: 4
Training loss: 0.9833563566207886
Validation loss: 2.150542986008429

Epoch: 5| Step: 5
Training loss: 2.0563724040985107
Validation loss: 2.1495699113415134

Epoch: 5| Step: 6
Training loss: 1.8430973291397095
Validation loss: 2.1404959053121586

Epoch: 5| Step: 7
Training loss: 1.7428436279296875
Validation loss: 2.1403205394744873

Epoch: 5| Step: 8
Training loss: 2.1067099571228027
Validation loss: 2.114622780071792

Epoch: 5| Step: 9
Training loss: 2.3247931003570557
Validation loss: 2.1023046842185398

Epoch: 5| Step: 10
Training loss: 1.5778721570968628
Validation loss: 2.083720176450668

Epoch: 291| Step: 0
Training loss: 2.034151315689087
Validation loss: 2.0827533314304967

Epoch: 5| Step: 1
Training loss: 2.0216593742370605
Validation loss: 2.1116564196925007

Epoch: 5| Step: 2
Training loss: 2.27173113822937
Validation loss: 2.1485252021461405

Epoch: 5| Step: 3
Training loss: 1.8053357601165771
Validation loss: 2.17414153006769

Epoch: 5| Step: 4
Training loss: 1.4024099111557007
Validation loss: 2.192730962589223

Epoch: 5| Step: 5
Training loss: 2.3893022537231445
Validation loss: 2.2039140142420286

Epoch: 5| Step: 6
Training loss: 1.6120355129241943
Validation loss: 2.1856545286793865

Epoch: 5| Step: 7
Training loss: 2.1711392402648926
Validation loss: 2.158111587647469

Epoch: 5| Step: 8
Training loss: 2.11995005607605
Validation loss: 2.1381752567906536

Epoch: 5| Step: 9
Training loss: 1.4233824014663696
Validation loss: 2.109491553357852

Epoch: 5| Step: 10
Training loss: 1.6886489391326904
Validation loss: 2.097261826197306

Epoch: 292| Step: 0
Training loss: 1.4306085109710693
Validation loss: 2.0885295303918983

Epoch: 5| Step: 1
Training loss: 1.590885877609253
Validation loss: 2.1016349061842887

Epoch: 5| Step: 2
Training loss: 1.6873947381973267
Validation loss: 2.0883126797214633

Epoch: 5| Step: 3
Training loss: 1.4901561737060547
Validation loss: 2.1148260383195776

Epoch: 5| Step: 4
Training loss: 1.944217324256897
Validation loss: 2.1352242141641598

Epoch: 5| Step: 5
Training loss: 2.0867257118225098
Validation loss: 2.1315749934924546

Epoch: 5| Step: 6
Training loss: 1.7540918588638306
Validation loss: 2.145434679523591

Epoch: 5| Step: 7
Training loss: 1.4159715175628662
Validation loss: 2.1655759760128555

Epoch: 5| Step: 8
Training loss: 2.9299933910369873
Validation loss: 2.155378028910647

Epoch: 5| Step: 9
Training loss: 1.9297294616699219
Validation loss: 2.1291192500822005

Epoch: 5| Step: 10
Training loss: 2.5798587799072266
Validation loss: 2.118249644515335

Epoch: 293| Step: 0
Training loss: 1.1125773191452026
Validation loss: 2.101334161655877

Epoch: 5| Step: 1
Training loss: 2.2555503845214844
Validation loss: 2.10191709251814

Epoch: 5| Step: 2
Training loss: 2.245171070098877
Validation loss: 2.0900343220721007

Epoch: 5| Step: 3
Training loss: 1.357978343963623
Validation loss: 2.105295376111102

Epoch: 5| Step: 4
Training loss: 1.6962255239486694
Validation loss: 2.1221553740962857

Epoch: 5| Step: 5
Training loss: 2.305952548980713
Validation loss: 2.1555204237661054

Epoch: 5| Step: 6
Training loss: 2.0711982250213623
Validation loss: 2.1765201642949092

Epoch: 5| Step: 7
Training loss: 2.401127576828003
Validation loss: 2.1997291375232

Epoch: 5| Step: 8
Training loss: 1.2010414600372314
Validation loss: 2.2064507571599816

Epoch: 5| Step: 9
Training loss: 2.018871545791626
Validation loss: 2.206042358952184

Epoch: 5| Step: 10
Training loss: 1.925147533416748
Validation loss: 2.1971605080430225

Epoch: 294| Step: 0
Training loss: 1.291326880455017
Validation loss: 2.1863314669619323

Epoch: 5| Step: 1
Training loss: 2.205519914627075
Validation loss: 2.1495643713141

Epoch: 5| Step: 2
Training loss: 1.6184799671173096
Validation loss: 2.1181988869943926

Epoch: 5| Step: 3
Training loss: 2.5988173484802246
Validation loss: 2.1051460107167563

Epoch: 5| Step: 4
Training loss: 2.4695334434509277
Validation loss: 2.098580147630425

Epoch: 5| Step: 5
Training loss: 1.1903926134109497
Validation loss: 2.077463629425213

Epoch: 5| Step: 6
Training loss: 1.7477508783340454
Validation loss: 2.0727794708744174

Epoch: 5| Step: 7
Training loss: 2.8091537952423096
Validation loss: 2.070000768989645

Epoch: 5| Step: 8
Training loss: 1.288285732269287
Validation loss: 2.096610041074855

Epoch: 5| Step: 9
Training loss: 1.820685625076294
Validation loss: 2.105645909104296

Epoch: 5| Step: 10
Training loss: 1.5637580156326294
Validation loss: 2.1298272225164596

Epoch: 295| Step: 0
Training loss: 1.7935136556625366
Validation loss: 2.1509430408477783

Epoch: 5| Step: 1
Training loss: 1.8182157278060913
Validation loss: 2.1829980060618412

Epoch: 5| Step: 2
Training loss: 2.329402446746826
Validation loss: 2.1955710918672624

Epoch: 5| Step: 3
Training loss: 1.975520133972168
Validation loss: 2.200356703932567

Epoch: 5| Step: 4
Training loss: 1.7724933624267578
Validation loss: 2.222814785536899

Epoch: 5| Step: 5
Training loss: 2.207365036010742
Validation loss: 2.1972349407852336

Epoch: 5| Step: 6
Training loss: 1.660767912864685
Validation loss: 2.179091990634959

Epoch: 5| Step: 7
Training loss: 1.810233473777771
Validation loss: 2.1501036767036683

Epoch: 5| Step: 8
Training loss: 1.7852073907852173
Validation loss: 2.107188565756685

Epoch: 5| Step: 9
Training loss: 1.5445445775985718
Validation loss: 2.086300285913611

Epoch: 5| Step: 10
Training loss: 1.7483596801757812
Validation loss: 2.091411272684733

Epoch: 296| Step: 0
Training loss: 1.564601182937622
Validation loss: 2.0874036076248332

Epoch: 5| Step: 1
Training loss: 1.9211280345916748
Validation loss: 2.0892370593163276

Epoch: 5| Step: 2
Training loss: 1.7905572652816772
Validation loss: 2.1011391275672504

Epoch: 5| Step: 3
Training loss: 1.9292175769805908
Validation loss: 2.108145349769182

Epoch: 5| Step: 4
Training loss: 1.3795145750045776
Validation loss: 2.1005284555496706

Epoch: 5| Step: 5
Training loss: 1.865088701248169
Validation loss: 2.114033552908128

Epoch: 5| Step: 6
Training loss: 2.3016271591186523
Validation loss: 2.126573088348553

Epoch: 5| Step: 7
Training loss: 2.2066256999969482
Validation loss: 2.1232877828741588

Epoch: 5| Step: 8
Training loss: 2.0717854499816895
Validation loss: 2.127598762512207

Epoch: 5| Step: 9
Training loss: 1.5568125247955322
Validation loss: 2.15047655054318

Epoch: 5| Step: 10
Training loss: 1.8737226724624634
Validation loss: 2.178293792150354

Epoch: 297| Step: 0
Training loss: 1.9158122539520264
Validation loss: 2.1843569586353917

Epoch: 5| Step: 1
Training loss: 1.5703747272491455
Validation loss: 2.1650170510815037

Epoch: 5| Step: 2
Training loss: 2.198056697845459
Validation loss: 2.1671480722324823

Epoch: 5| Step: 3
Training loss: 1.7040417194366455
Validation loss: 2.1741623365750877

Epoch: 5| Step: 4
Training loss: 2.011284351348877
Validation loss: 2.1732694436145086

Epoch: 5| Step: 5
Training loss: 1.2429955005645752
Validation loss: 2.1745183365319365

Epoch: 5| Step: 6
Training loss: 2.019131898880005
Validation loss: 2.1509381596760084

Epoch: 5| Step: 7
Training loss: 2.030362606048584
Validation loss: 2.1559689711498957

Epoch: 5| Step: 8
Training loss: 2.115856170654297
Validation loss: 2.1314851263517975

Epoch: 5| Step: 9
Training loss: 1.799637794494629
Validation loss: 2.1279944912079842

Epoch: 5| Step: 10
Training loss: 1.7415611743927002
Validation loss: 2.109993830803902

Epoch: 298| Step: 0
Training loss: 1.617881417274475
Validation loss: 2.1201089787226852

Epoch: 5| Step: 1
Training loss: 2.0543200969696045
Validation loss: 2.1427061327042116

Epoch: 5| Step: 2
Training loss: 2.008483409881592
Validation loss: 2.157196183358469

Epoch: 5| Step: 3
Training loss: 1.9068838357925415
Validation loss: 2.1654462660512617

Epoch: 5| Step: 4
Training loss: 2.1208724975585938
Validation loss: 2.149691004906931

Epoch: 5| Step: 5
Training loss: 2.5017964839935303
Validation loss: 2.1401233724368516

Epoch: 5| Step: 6
Training loss: 1.7010345458984375
Validation loss: 2.1233984167857836

Epoch: 5| Step: 7
Training loss: 1.58711576461792
Validation loss: 2.1122112889443674

Epoch: 5| Step: 8
Training loss: 1.59127938747406
Validation loss: 2.1186537716978338

Epoch: 5| Step: 9
Training loss: 1.1991820335388184
Validation loss: 2.123418790037914

Epoch: 5| Step: 10
Training loss: 1.8828551769256592
Validation loss: 2.1271918460886967

Epoch: 299| Step: 0
Training loss: 1.1079764366149902
Validation loss: 2.1327796571998188

Epoch: 5| Step: 1
Training loss: 1.474671483039856
Validation loss: 2.1449624441003285

Epoch: 5| Step: 2
Training loss: 1.94772469997406
Validation loss: 2.1420523248692995

Epoch: 5| Step: 3
Training loss: 1.9376516342163086
Validation loss: 2.119747818157237

Epoch: 5| Step: 4
Training loss: 2.1354384422302246
Validation loss: 2.1158684492111206

Epoch: 5| Step: 5
Training loss: 1.882612943649292
Validation loss: 2.114393085561773

Epoch: 5| Step: 6
Training loss: 1.6329028606414795
Validation loss: 2.1239542038209978

Epoch: 5| Step: 7
Training loss: 1.8964630365371704
Validation loss: 2.1258687614112772

Epoch: 5| Step: 8
Training loss: 1.8131396770477295
Validation loss: 2.085237290269585

Epoch: 5| Step: 9
Training loss: 2.158834218978882
Validation loss: 2.1040756497331845

Epoch: 5| Step: 10
Training loss: 2.181954860687256
Validation loss: 2.0917517164702057

Epoch: 300| Step: 0
Training loss: 2.0458385944366455
Validation loss: 2.1004367156695296

Epoch: 5| Step: 1
Training loss: 1.6870486736297607
Validation loss: 2.1048606031684467

Epoch: 5| Step: 2
Training loss: 1.9608891010284424
Validation loss: 2.1275670156683972

Epoch: 5| Step: 3
Training loss: 1.6293213367462158
Validation loss: 2.141690263184168

Epoch: 5| Step: 4
Training loss: 1.6099611520767212
Validation loss: 2.1796731615579255

Epoch: 5| Step: 5
Training loss: 2.6030097007751465
Validation loss: 2.22139480293438

Epoch: 5| Step: 6
Training loss: 1.7758935689926147
Validation loss: 2.2490481202320387

Epoch: 5| Step: 7
Training loss: 1.415427803993225
Validation loss: 2.2009598952467724

Epoch: 5| Step: 8
Training loss: 1.7764434814453125
Validation loss: 2.176101307715139

Epoch: 5| Step: 9
Training loss: 1.8380380868911743
Validation loss: 2.1446353235552387

Epoch: 5| Step: 10
Training loss: 1.9963215589523315
Validation loss: 2.130913894663575

Epoch: 301| Step: 0
Training loss: 2.4293665885925293
Validation loss: 2.1117490183922554

Epoch: 5| Step: 1
Training loss: 1.3537347316741943
Validation loss: 2.080351116836712

Epoch: 5| Step: 2
Training loss: 1.6281731128692627
Validation loss: 2.078378649168117

Epoch: 5| Step: 3
Training loss: 1.3150885105133057
Validation loss: 2.083244069930046

Epoch: 5| Step: 4
Training loss: 2.1464037895202637
Validation loss: 2.0983865889169837

Epoch: 5| Step: 5
Training loss: 1.6442569494247437
Validation loss: 2.1049924178790023

Epoch: 5| Step: 6
Training loss: 2.417884588241577
Validation loss: 2.1093665912587154

Epoch: 5| Step: 7
Training loss: 1.7745825052261353
Validation loss: 2.109697345764406

Epoch: 5| Step: 8
Training loss: 1.689226508140564
Validation loss: 2.125400197121405

Epoch: 5| Step: 9
Training loss: 1.8610776662826538
Validation loss: 2.151880038681851

Epoch: 5| Step: 10
Training loss: 1.9072387218475342
Validation loss: 2.215341216774397

Epoch: 302| Step: 0
Training loss: 2.046729564666748
Validation loss: 2.2427289434658584

Epoch: 5| Step: 1
Training loss: 1.6709072589874268
Validation loss: 2.2415258858793523

Epoch: 5| Step: 2
Training loss: 1.5408380031585693
Validation loss: 2.2677823356402818

Epoch: 5| Step: 3
Training loss: 2.0525779724121094
Validation loss: 2.2532275312690326

Epoch: 5| Step: 4
Training loss: 1.5695445537567139
Validation loss: 2.1993297453849547

Epoch: 5| Step: 5
Training loss: 2.6634840965270996
Validation loss: 2.1798779861901396

Epoch: 5| Step: 6
Training loss: 2.325491428375244
Validation loss: 2.123662861444617

Epoch: 5| Step: 7
Training loss: 1.1317975521087646
Validation loss: 2.0827320762859878

Epoch: 5| Step: 8
Training loss: 1.7645295858383179
Validation loss: 2.061245769582769

Epoch: 5| Step: 9
Training loss: 1.6392920017242432
Validation loss: 2.0538953286345287

Epoch: 5| Step: 10
Training loss: 1.9398999214172363
Validation loss: 2.0533622887826737

Epoch: 303| Step: 0
Training loss: 2.0476975440979004
Validation loss: 2.0592031889064337

Epoch: 5| Step: 1
Training loss: 1.6481298208236694
Validation loss: 2.092089622251449

Epoch: 5| Step: 2
Training loss: 2.168137311935425
Validation loss: 2.1069631896993166

Epoch: 5| Step: 3
Training loss: 1.8591943979263306
Validation loss: 2.136634736932734

Epoch: 5| Step: 4
Training loss: 1.8749746084213257
Validation loss: 2.1643425469757407

Epoch: 5| Step: 5
Training loss: 1.8702335357666016
Validation loss: 2.1710294497910367

Epoch: 5| Step: 6
Training loss: 1.6765705347061157
Validation loss: 2.159531508722613

Epoch: 5| Step: 7
Training loss: 1.7422521114349365
Validation loss: 2.154324121372674

Epoch: 5| Step: 8
Training loss: 1.904794692993164
Validation loss: 2.1628306450382357

Epoch: 5| Step: 9
Training loss: 1.9859377145767212
Validation loss: 2.1201631587038756

Epoch: 5| Step: 10
Training loss: 1.3462512493133545
Validation loss: 2.1069737172895864

Epoch: 304| Step: 0
Training loss: 1.772810697555542
Validation loss: 2.068986097971598

Epoch: 5| Step: 1
Training loss: 1.5797228813171387
Validation loss: 2.064329731848932

Epoch: 5| Step: 2
Training loss: 2.214337110519409
Validation loss: 2.049684868063978

Epoch: 5| Step: 3
Training loss: 1.8621189594268799
Validation loss: 2.0696544442125546

Epoch: 5| Step: 4
Training loss: 1.3300927877426147
Validation loss: 2.073700563881987

Epoch: 5| Step: 5
Training loss: 2.019077777862549
Validation loss: 2.0667748848597207

Epoch: 5| Step: 6
Training loss: 1.544492483139038
Validation loss: 2.0911933991216842

Epoch: 5| Step: 7
Training loss: 1.8044259548187256
Validation loss: 2.090840708824896

Epoch: 5| Step: 8
Training loss: 2.222407102584839
Validation loss: 2.134254765766923

Epoch: 5| Step: 9
Training loss: 1.524757981300354
Validation loss: 2.1278839906056723

Epoch: 5| Step: 10
Training loss: 2.347710609436035
Validation loss: 2.138642793060631

Epoch: 305| Step: 0
Training loss: 1.0370773077011108
Validation loss: 2.1141560795486614

Epoch: 5| Step: 1
Training loss: 1.9884048700332642
Validation loss: 2.1069630576718237

Epoch: 5| Step: 2
Training loss: 1.2508032321929932
Validation loss: 2.093567132949829

Epoch: 5| Step: 3
Training loss: 1.8946831226348877
Validation loss: 2.0920923140741166

Epoch: 5| Step: 4
Training loss: 1.8481714725494385
Validation loss: 2.1332845226410897

Epoch: 5| Step: 5
Training loss: 1.9343913793563843
Validation loss: 2.1277409189490863

Epoch: 5| Step: 6
Training loss: 2.411282777786255
Validation loss: 2.161464342506983

Epoch: 5| Step: 7
Training loss: 1.601991057395935
Validation loss: 2.1514066739748885

Epoch: 5| Step: 8
Training loss: 1.884670615196228
Validation loss: 2.1441145238055976

Epoch: 5| Step: 9
Training loss: 1.9301235675811768
Validation loss: 2.122367242331146

Epoch: 5| Step: 10
Training loss: 2.1484792232513428
Validation loss: 2.118833339342507

Epoch: 306| Step: 0
Training loss: 2.0319454669952393
Validation loss: 2.134226038891782

Epoch: 5| Step: 1
Training loss: 1.641899824142456
Validation loss: 2.1101327660263225

Epoch: 5| Step: 2
Training loss: 1.5518051385879517
Validation loss: 2.1021888999528784

Epoch: 5| Step: 3
Training loss: 1.940740942955017
Validation loss: 2.1063371742925336

Epoch: 5| Step: 4
Training loss: 2.2967541217803955
Validation loss: 2.111163026543074

Epoch: 5| Step: 5
Training loss: 1.9615589380264282
Validation loss: 2.0868956888875654

Epoch: 5| Step: 6
Training loss: 2.2466022968292236
Validation loss: 2.091503597074939

Epoch: 5| Step: 7
Training loss: 1.6752456426620483
Validation loss: 2.0959638921163415

Epoch: 5| Step: 8
Training loss: 1.2874717712402344
Validation loss: 2.0972096509830926

Epoch: 5| Step: 9
Training loss: 1.5772265195846558
Validation loss: 2.0793652380666425

Epoch: 5| Step: 10
Training loss: 1.4719338417053223
Validation loss: 2.0903943148992394

Epoch: 307| Step: 0
Training loss: 1.9957935810089111
Validation loss: 2.126030621990081

Epoch: 5| Step: 1
Training loss: 2.1479721069335938
Validation loss: 2.1265889021658126

Epoch: 5| Step: 2
Training loss: 1.583962321281433
Validation loss: 2.1597022728253434

Epoch: 5| Step: 3
Training loss: 1.3627206087112427
Validation loss: 2.191141382340462

Epoch: 5| Step: 4
Training loss: 1.9085534811019897
Validation loss: 2.177898686419251

Epoch: 5| Step: 5
Training loss: 1.489682912826538
Validation loss: 2.182142516618134

Epoch: 5| Step: 6
Training loss: 1.8651167154312134
Validation loss: 2.1992872466323194

Epoch: 5| Step: 7
Training loss: 2.257275342941284
Validation loss: 2.1796598075538554

Epoch: 5| Step: 8
Training loss: 1.4345176219940186
Validation loss: 2.153165800597078

Epoch: 5| Step: 9
Training loss: 1.7502069473266602
Validation loss: 2.133727963252734

Epoch: 5| Step: 10
Training loss: 1.9680200815200806
Validation loss: 2.107129030330207

Epoch: 308| Step: 0
Training loss: 1.919248342514038
Validation loss: 2.0946227209542387

Epoch: 5| Step: 1
Training loss: 2.045732021331787
Validation loss: 2.088839820636216

Epoch: 5| Step: 2
Training loss: 1.623705267906189
Validation loss: 2.090443621399582

Epoch: 5| Step: 3
Training loss: 1.5592637062072754
Validation loss: 2.108387199781274

Epoch: 5| Step: 4
Training loss: 2.2405052185058594
Validation loss: 2.1258738015287664

Epoch: 5| Step: 5
Training loss: 1.7328380346298218
Validation loss: 2.1580161458702496

Epoch: 5| Step: 6
Training loss: 1.3748258352279663
Validation loss: 2.177978402824812

Epoch: 5| Step: 7
Training loss: 1.883136510848999
Validation loss: 2.165550847207346

Epoch: 5| Step: 8
Training loss: 1.4556663036346436
Validation loss: 2.1950063782353557

Epoch: 5| Step: 9
Training loss: 1.8759253025054932
Validation loss: 2.1945772735021447

Epoch: 5| Step: 10
Training loss: 1.8688344955444336
Validation loss: 2.165066801091676

Epoch: 309| Step: 0
Training loss: 1.6602386236190796
Validation loss: 2.122113238098801

Epoch: 5| Step: 1
Training loss: 1.7818971872329712
Validation loss: 2.0989145207148727

Epoch: 5| Step: 2
Training loss: 1.992041826248169
Validation loss: 2.082735297500446

Epoch: 5| Step: 3
Training loss: 1.8649685382843018
Validation loss: 2.054211744698145

Epoch: 5| Step: 4
Training loss: 1.2823669910430908
Validation loss: 2.06250326735999

Epoch: 5| Step: 5
Training loss: 1.2029390335083008
Validation loss: 2.0651783225356892

Epoch: 5| Step: 6
Training loss: 1.7857624292373657
Validation loss: 2.109942956637311

Epoch: 5| Step: 7
Training loss: 2.3269922733306885
Validation loss: 2.129673832206316

Epoch: 5| Step: 8
Training loss: 1.9504766464233398
Validation loss: 2.1541834031381915

Epoch: 5| Step: 9
Training loss: 2.085592746734619
Validation loss: 2.168171569865237

Epoch: 5| Step: 10
Training loss: 1.7442649602890015
Validation loss: 2.169105286239296

Epoch: 310| Step: 0
Training loss: 1.8297981023788452
Validation loss: 2.167182050725465

Epoch: 5| Step: 1
Training loss: 1.4571202993392944
Validation loss: 2.1336080207619617

Epoch: 5| Step: 2
Training loss: 1.747596025466919
Validation loss: 2.1270942290623984

Epoch: 5| Step: 3
Training loss: 2.1461682319641113
Validation loss: 2.1172019397058794

Epoch: 5| Step: 4
Training loss: 1.6163657903671265
Validation loss: 2.136750259707051

Epoch: 5| Step: 5
Training loss: 1.5035721063613892
Validation loss: 2.168783865949159

Epoch: 5| Step: 6
Training loss: 1.7151046991348267
Validation loss: 2.1595379408969673

Epoch: 5| Step: 7
Training loss: 2.7527108192443848
Validation loss: 2.181575086808974

Epoch: 5| Step: 8
Training loss: 1.7365694046020508
Validation loss: 2.160899075128699

Epoch: 5| Step: 9
Training loss: 1.4313948154449463
Validation loss: 2.1226844108232887

Epoch: 5| Step: 10
Training loss: 1.5171796083450317
Validation loss: 2.110538444211406

Epoch: 311| Step: 0
Training loss: 2.107715368270874
Validation loss: 2.111194710577688

Epoch: 5| Step: 1
Training loss: 1.8840477466583252
Validation loss: 2.0800913418492963

Epoch: 5| Step: 2
Training loss: 1.7402451038360596
Validation loss: 2.0737383686086184

Epoch: 5| Step: 3
Training loss: 2.3104405403137207
Validation loss: 2.077627422989056

Epoch: 5| Step: 4
Training loss: 1.603985071182251
Validation loss: 2.0871448978301017

Epoch: 5| Step: 5
Training loss: 1.3383824825286865
Validation loss: 2.0865727880949616

Epoch: 5| Step: 6
Training loss: 1.8658416271209717
Validation loss: 2.0993437074845835

Epoch: 5| Step: 7
Training loss: 1.6615331172943115
Validation loss: 2.1296510375956053

Epoch: 5| Step: 8
Training loss: 1.7986255884170532
Validation loss: 2.136316704493697

Epoch: 5| Step: 9
Training loss: 1.6075408458709717
Validation loss: 2.1402091569797967

Epoch: 5| Step: 10
Training loss: 1.5615301132202148
Validation loss: 2.136515471243089

Epoch: 312| Step: 0
Training loss: 1.6870940923690796
Validation loss: 2.1154015115512315

Epoch: 5| Step: 1
Training loss: 1.4405629634857178
Validation loss: 2.1276921405587146

Epoch: 5| Step: 2
Training loss: 1.8735904693603516
Validation loss: 2.114530274944921

Epoch: 5| Step: 3
Training loss: 2.20133376121521
Validation loss: 2.1178400901056107

Epoch: 5| Step: 4
Training loss: 1.324527382850647
Validation loss: 2.115121913212602

Epoch: 5| Step: 5
Training loss: 1.3630679845809937
Validation loss: 2.116231620952647

Epoch: 5| Step: 6
Training loss: 1.7174545526504517
Validation loss: 2.1093453566233316

Epoch: 5| Step: 7
Training loss: 1.6821368932724
Validation loss: 2.097643406160416

Epoch: 5| Step: 8
Training loss: 1.954697847366333
Validation loss: 2.119444718924902

Epoch: 5| Step: 9
Training loss: 1.8794491291046143
Validation loss: 2.1180780139020694

Epoch: 5| Step: 10
Training loss: 2.2184319496154785
Validation loss: 2.1103188299363658

Epoch: 313| Step: 0
Training loss: 1.4365031719207764
Validation loss: 2.1180600594448786

Epoch: 5| Step: 1
Training loss: 1.4386550188064575
Validation loss: 2.105205579470563

Epoch: 5| Step: 2
Training loss: 2.386857509613037
Validation loss: 2.0874651965274604

Epoch: 5| Step: 3
Training loss: 1.5343029499053955
Validation loss: 2.086064628375474

Epoch: 5| Step: 4
Training loss: 1.8219044208526611
Validation loss: 2.07916396920399

Epoch: 5| Step: 5
Training loss: 1.547792673110962
Validation loss: 2.0968108279730684

Epoch: 5| Step: 6
Training loss: 1.333216905593872
Validation loss: 2.1259105948991674

Epoch: 5| Step: 7
Training loss: 2.017878770828247
Validation loss: 2.142941831260599

Epoch: 5| Step: 8
Training loss: 2.143348217010498
Validation loss: 2.1768129871737574

Epoch: 5| Step: 9
Training loss: 2.120699644088745
Validation loss: 2.16828255755927

Epoch: 5| Step: 10
Training loss: 1.4678828716278076
Validation loss: 2.1507510664642497

Epoch: 314| Step: 0
Training loss: 2.0251247882843018
Validation loss: 2.147302286599272

Epoch: 5| Step: 1
Training loss: 1.7726986408233643
Validation loss: 2.112795465735979

Epoch: 5| Step: 2
Training loss: 1.4999104738235474
Validation loss: 2.094027673044512

Epoch: 5| Step: 3
Training loss: 1.6280105113983154
Validation loss: 2.072186549504598

Epoch: 5| Step: 4
Training loss: 1.780340552330017
Validation loss: 2.0588802893956504

Epoch: 5| Step: 5
Training loss: 2.3274307250976562
Validation loss: 2.0627857767125612

Epoch: 5| Step: 6
Training loss: 1.9492378234863281
Validation loss: 2.05793252811637

Epoch: 5| Step: 7
Training loss: 1.3393816947937012
Validation loss: 2.0795494138553576

Epoch: 5| Step: 8
Training loss: 1.6553875207901
Validation loss: 2.096499207199261

Epoch: 5| Step: 9
Training loss: 1.859763741493225
Validation loss: 2.109190023073586

Epoch: 5| Step: 10
Training loss: 1.4933429956436157
Validation loss: 2.1268291806661956

Epoch: 315| Step: 0
Training loss: 0.9120489954948425
Validation loss: 2.132724832463008

Epoch: 5| Step: 1
Training loss: 1.299599289894104
Validation loss: 2.169153936447636

Epoch: 5| Step: 2
Training loss: 1.4579330682754517
Validation loss: 2.1959767482614003

Epoch: 5| Step: 3
Training loss: 1.7947876453399658
Validation loss: 2.203146134653399

Epoch: 5| Step: 4
Training loss: 1.9788095951080322
Validation loss: 2.203922930584159

Epoch: 5| Step: 5
Training loss: 2.1485724449157715
Validation loss: 2.1468307177225747

Epoch: 5| Step: 6
Training loss: 2.2474093437194824
Validation loss: 2.1435845846770913

Epoch: 5| Step: 7
Training loss: 2.026087999343872
Validation loss: 2.126579133413171

Epoch: 5| Step: 8
Training loss: 1.8064590692520142
Validation loss: 2.107159209507768

Epoch: 5| Step: 9
Training loss: 1.4251075983047485
Validation loss: 2.097976182096748

Epoch: 5| Step: 10
Training loss: 2.193899393081665
Validation loss: 2.0736600814327115

Epoch: 316| Step: 0
Training loss: 1.9775480031967163
Validation loss: 2.077610323506017

Epoch: 5| Step: 1
Training loss: 1.8293952941894531
Validation loss: 2.082712491353353

Epoch: 5| Step: 2
Training loss: 1.5359671115875244
Validation loss: 2.074057525204074

Epoch: 5| Step: 3
Training loss: 1.497271180152893
Validation loss: 2.089361634305728

Epoch: 5| Step: 4
Training loss: 1.6783740520477295
Validation loss: 2.0965428339537753

Epoch: 5| Step: 5
Training loss: 2.28873610496521
Validation loss: 2.088164237237746

Epoch: 5| Step: 6
Training loss: 1.8444995880126953
Validation loss: 2.0964634956852084

Epoch: 5| Step: 7
Training loss: 1.6481117010116577
Validation loss: 2.0976502100626626

Epoch: 5| Step: 8
Training loss: 1.733258843421936
Validation loss: 2.163923353277227

Epoch: 5| Step: 9
Training loss: 1.296035647392273
Validation loss: 2.1875688850238757

Epoch: 5| Step: 10
Training loss: 1.721118688583374
Validation loss: 2.2559124859430457

Epoch: 317| Step: 0
Training loss: 2.2281336784362793
Validation loss: 2.272313258981192

Epoch: 5| Step: 1
Training loss: 2.275841236114502
Validation loss: 2.294144356122581

Epoch: 5| Step: 2
Training loss: 1.5249372720718384
Validation loss: 2.2775179596357447

Epoch: 5| Step: 3
Training loss: 1.5905473232269287
Validation loss: 2.238584318468648

Epoch: 5| Step: 4
Training loss: 1.6984790563583374
Validation loss: 2.2173528619991836

Epoch: 5| Step: 5
Training loss: 1.1288807392120361
Validation loss: 2.172083899539004

Epoch: 5| Step: 6
Training loss: 1.3222253322601318
Validation loss: 2.154987883824174

Epoch: 5| Step: 7
Training loss: 1.7010339498519897
Validation loss: 2.1176062835160123

Epoch: 5| Step: 8
Training loss: 1.537855625152588
Validation loss: 2.1064083665929814

Epoch: 5| Step: 9
Training loss: 2.1608173847198486
Validation loss: 2.0880482094262236

Epoch: 5| Step: 10
Training loss: 2.3693997859954834
Validation loss: 2.071339561093238

Epoch: 318| Step: 0
Training loss: 1.3894418478012085
Validation loss: 2.0947193907153223

Epoch: 5| Step: 1
Training loss: 1.8823572397232056
Validation loss: 2.1018702855674167

Epoch: 5| Step: 2
Training loss: 1.742028832435608
Validation loss: 2.1245441821313675

Epoch: 5| Step: 3
Training loss: 1.368491768836975
Validation loss: 2.175158936490295

Epoch: 5| Step: 4
Training loss: 1.8248050212860107
Validation loss: 2.1526820762183076

Epoch: 5| Step: 5
Training loss: 2.1633923053741455
Validation loss: 2.125124418607322

Epoch: 5| Step: 6
Training loss: 2.20601224899292
Validation loss: 2.105086827790865

Epoch: 5| Step: 7
Training loss: 1.4942553043365479
Validation loss: 2.0974714038192586

Epoch: 5| Step: 8
Training loss: 1.9497337341308594
Validation loss: 2.0902289549509683

Epoch: 5| Step: 9
Training loss: 1.807604193687439
Validation loss: 2.104088860173379

Epoch: 5| Step: 10
Training loss: 1.4371755123138428
Validation loss: 2.0983053074088147

Epoch: 319| Step: 0
Training loss: 1.359283685684204
Validation loss: 2.1280098294699066

Epoch: 5| Step: 1
Training loss: 2.0428738594055176
Validation loss: 2.140456989247312

Epoch: 5| Step: 2
Training loss: 2.162808895111084
Validation loss: 2.156222742090943

Epoch: 5| Step: 3
Training loss: 1.5410507917404175
Validation loss: 2.1526335747011247

Epoch: 5| Step: 4
Training loss: 1.1478583812713623
Validation loss: 2.1160142037176315

Epoch: 5| Step: 5
Training loss: 1.2910020351409912
Validation loss: 2.122817647072577

Epoch: 5| Step: 6
Training loss: 2.0953526496887207
Validation loss: 2.1320362180791874

Epoch: 5| Step: 7
Training loss: 1.8910362720489502
Validation loss: 2.1247211246080298

Epoch: 5| Step: 8
Training loss: 1.9477096796035767
Validation loss: 2.126170059686066

Epoch: 5| Step: 9
Training loss: 1.8338301181793213
Validation loss: 2.0872773842145036

Epoch: 5| Step: 10
Training loss: 1.603647232055664
Validation loss: 2.082455301797518

Epoch: 320| Step: 0
Training loss: 1.0675140619277954
Validation loss: 2.0804917466255928

Epoch: 5| Step: 1
Training loss: 1.5693501234054565
Validation loss: 2.0876664666719336

Epoch: 5| Step: 2
Training loss: 2.010404109954834
Validation loss: 2.100461383019724

Epoch: 5| Step: 3
Training loss: 1.505798101425171
Validation loss: 2.1137350092652025

Epoch: 5| Step: 4
Training loss: 1.8604800701141357
Validation loss: 2.1210826468724076

Epoch: 5| Step: 5
Training loss: 1.8016357421875
Validation loss: 2.1556922799797467

Epoch: 5| Step: 6
Training loss: 1.0861068964004517
Validation loss: 2.107722323427918

Epoch: 5| Step: 7
Training loss: 2.278564453125
Validation loss: 2.1329233851484073

Epoch: 5| Step: 8
Training loss: 2.5637619495391846
Validation loss: 2.1422971551136305

Epoch: 5| Step: 9
Training loss: 1.1670891046524048
Validation loss: 2.1556690546774093

Epoch: 5| Step: 10
Training loss: 1.8003430366516113
Validation loss: 2.1553299939760597

Epoch: 321| Step: 0
Training loss: 1.9153066873550415
Validation loss: 2.135917730228875

Epoch: 5| Step: 1
Training loss: 1.0477030277252197
Validation loss: 2.118725263944236

Epoch: 5| Step: 2
Training loss: 1.4080865383148193
Validation loss: 2.1124323414218042

Epoch: 5| Step: 3
Training loss: 1.9384276866912842
Validation loss: 2.0928773008367068

Epoch: 5| Step: 4
Training loss: 1.6640182733535767
Validation loss: 2.0992178801567323

Epoch: 5| Step: 5
Training loss: 1.7400619983673096
Validation loss: 2.0738961440260693

Epoch: 5| Step: 6
Training loss: 1.5196491479873657
Validation loss: 2.08034522046325

Epoch: 5| Step: 7
Training loss: 2.175095319747925
Validation loss: 2.0866372431478193

Epoch: 5| Step: 8
Training loss: 1.331443190574646
Validation loss: 2.0903742249293993

Epoch: 5| Step: 9
Training loss: 2.143035888671875
Validation loss: 2.1181764500115507

Epoch: 5| Step: 10
Training loss: 1.5455846786499023
Validation loss: 2.133806050464671

Epoch: 322| Step: 0
Training loss: 1.8959131240844727
Validation loss: 2.14716564583522

Epoch: 5| Step: 1
Training loss: 0.730111300945282
Validation loss: 2.1554323857830417

Epoch: 5| Step: 2
Training loss: 1.7115226984024048
Validation loss: 2.153494788754371

Epoch: 5| Step: 3
Training loss: 2.287008762359619
Validation loss: 2.1571943734281804

Epoch: 5| Step: 4
Training loss: 1.2998406887054443
Validation loss: 2.1481355697877946

Epoch: 5| Step: 5
Training loss: 1.8376424312591553
Validation loss: 2.127183493747506

Epoch: 5| Step: 6
Training loss: 1.7769492864608765
Validation loss: 2.111184316296731

Epoch: 5| Step: 7
Training loss: 1.9332414865493774
Validation loss: 2.087079281448036

Epoch: 5| Step: 8
Training loss: 1.9774110317230225
Validation loss: 2.0772641038381927

Epoch: 5| Step: 9
Training loss: 1.5599992275238037
Validation loss: 2.074987162825882

Epoch: 5| Step: 10
Training loss: 1.4301539659500122
Validation loss: 2.086470991052607

Epoch: 323| Step: 0
Training loss: 1.430485725402832
Validation loss: 2.1117881241665093

Epoch: 5| Step: 1
Training loss: 1.9266481399536133
Validation loss: 2.1207920171881236

Epoch: 5| Step: 2
Training loss: 1.9425194263458252
Validation loss: 2.1388419494833997

Epoch: 5| Step: 3
Training loss: 1.815410852432251
Validation loss: 2.1157304240811254

Epoch: 5| Step: 4
Training loss: 1.5962547063827515
Validation loss: 2.09656298160553

Epoch: 5| Step: 5
Training loss: 1.3131784200668335
Validation loss: 2.1088703793864094

Epoch: 5| Step: 6
Training loss: 1.419203758239746
Validation loss: 2.1276846496007775

Epoch: 5| Step: 7
Training loss: 1.780856728553772
Validation loss: 2.121202189435241

Epoch: 5| Step: 8
Training loss: 1.7612202167510986
Validation loss: 2.11639025006243

Epoch: 5| Step: 9
Training loss: 2.3768649101257324
Validation loss: 2.1035263717815442

Epoch: 5| Step: 10
Training loss: 0.9285649657249451
Validation loss: 2.0964033283213133

Epoch: 324| Step: 0
Training loss: 1.4709696769714355
Validation loss: 2.0847796419615388

Epoch: 5| Step: 1
Training loss: 1.8049904108047485
Validation loss: 2.089186153104228

Epoch: 5| Step: 2
Training loss: 2.038182258605957
Validation loss: 2.1011913630270187

Epoch: 5| Step: 3
Training loss: 1.2551546096801758
Validation loss: 2.1018061099513883

Epoch: 5| Step: 4
Training loss: 1.098515510559082
Validation loss: 2.108665709854454

Epoch: 5| Step: 5
Training loss: 2.070528507232666
Validation loss: 2.1127833268975698

Epoch: 5| Step: 6
Training loss: 1.6866071224212646
Validation loss: 2.117466160046157

Epoch: 5| Step: 7
Training loss: 1.8464616537094116
Validation loss: 2.1015085712555917

Epoch: 5| Step: 8
Training loss: 1.2885435819625854
Validation loss: 2.093237947392207

Epoch: 5| Step: 9
Training loss: 1.361868143081665
Validation loss: 2.1261628673922632

Epoch: 5| Step: 10
Training loss: 2.3248867988586426
Validation loss: 2.150283100784466

Epoch: 325| Step: 0
Training loss: 1.2796876430511475
Validation loss: 2.173723607934931

Epoch: 5| Step: 1
Training loss: 1.8575830459594727
Validation loss: 2.156740544944681

Epoch: 5| Step: 2
Training loss: 2.1383042335510254
Validation loss: 2.155396387141238

Epoch: 5| Step: 3
Training loss: 1.305403470993042
Validation loss: 2.131294014633343

Epoch: 5| Step: 4
Training loss: 2.049715995788574
Validation loss: 2.129976687892791

Epoch: 5| Step: 5
Training loss: 1.4151266813278198
Validation loss: 2.1037349316381637

Epoch: 5| Step: 6
Training loss: 1.282636284828186
Validation loss: 2.0707032321601786

Epoch: 5| Step: 7
Training loss: 1.775694489479065
Validation loss: 2.0789999679852555

Epoch: 5| Step: 8
Training loss: 1.8287413120269775
Validation loss: 2.068418200298022

Epoch: 5| Step: 9
Training loss: 1.6540412902832031
Validation loss: 2.095984051304479

Epoch: 5| Step: 10
Training loss: 1.8367087841033936
Validation loss: 2.1077038293243735

Epoch: 326| Step: 0
Training loss: 1.299994707107544
Validation loss: 2.1060626558078233

Epoch: 5| Step: 1
Training loss: 1.7303688526153564
Validation loss: 2.1489116966083484

Epoch: 5| Step: 2
Training loss: 1.8909473419189453
Validation loss: 2.13124829722989

Epoch: 5| Step: 3
Training loss: 1.8013279438018799
Validation loss: 2.137608310227753

Epoch: 5| Step: 4
Training loss: 2.0741260051727295
Validation loss: 2.10389389786669

Epoch: 5| Step: 5
Training loss: 1.529896855354309
Validation loss: 2.084696226222541

Epoch: 5| Step: 6
Training loss: 1.9935004711151123
Validation loss: 2.080394624381937

Epoch: 5| Step: 7
Training loss: 1.5093662738800049
Validation loss: 2.077101553640058

Epoch: 5| Step: 8
Training loss: 1.2978146076202393
Validation loss: 2.061324945060156

Epoch: 5| Step: 9
Training loss: 1.5419073104858398
Validation loss: 2.0797987086798555

Epoch: 5| Step: 10
Training loss: 1.373465895652771
Validation loss: 2.1099637182809974

Epoch: 327| Step: 0
Training loss: 1.356507658958435
Validation loss: 2.170301419432445

Epoch: 5| Step: 1
Training loss: 1.9070050716400146
Validation loss: 2.19259617405553

Epoch: 5| Step: 2
Training loss: 1.6986370086669922
Validation loss: 2.2006298752241236

Epoch: 5| Step: 3
Training loss: 1.314500093460083
Validation loss: 2.1997313576359905

Epoch: 5| Step: 4
Training loss: 1.7045421600341797
Validation loss: 2.1696954363135883

Epoch: 5| Step: 5
Training loss: 1.5624034404754639
Validation loss: 2.1378919745004303

Epoch: 5| Step: 6
Training loss: 1.656251311302185
Validation loss: 2.0899671867329586

Epoch: 5| Step: 7
Training loss: 1.8104702234268188
Validation loss: 2.0961393399905135

Epoch: 5| Step: 8
Training loss: 1.5633927583694458
Validation loss: 2.076735823385177

Epoch: 5| Step: 9
Training loss: 1.8992935419082642
Validation loss: 2.066908492836901

Epoch: 5| Step: 10
Training loss: 1.580165982246399
Validation loss: 2.0496563180800407

Epoch: 328| Step: 0
Training loss: 1.8253955841064453
Validation loss: 2.0368022585427887

Epoch: 5| Step: 1
Training loss: 2.283979892730713
Validation loss: 2.0484836473259875

Epoch: 5| Step: 2
Training loss: 1.6548888683319092
Validation loss: 2.0463705344866683

Epoch: 5| Step: 3
Training loss: 2.068188428878784
Validation loss: 2.058656273349639

Epoch: 5| Step: 4
Training loss: 1.6170341968536377
Validation loss: 2.0656398701411423

Epoch: 5| Step: 5
Training loss: 1.4682273864746094
Validation loss: 2.087251597835172

Epoch: 5| Step: 6
Training loss: 1.9716670513153076
Validation loss: 2.1066321916477655

Epoch: 5| Step: 7
Training loss: 0.7293485403060913
Validation loss: 2.152995636386256

Epoch: 5| Step: 8
Training loss: 1.3087255954742432
Validation loss: 2.15581859824478

Epoch: 5| Step: 9
Training loss: 1.3201892375946045
Validation loss: 2.163880084150581

Epoch: 5| Step: 10
Training loss: 1.6192848682403564
Validation loss: 2.1663695061078636

Epoch: 329| Step: 0
Training loss: 1.2304489612579346
Validation loss: 2.1334464729473157

Epoch: 5| Step: 1
Training loss: 2.675027370452881
Validation loss: 2.1076945515089136

Epoch: 5| Step: 2
Training loss: 1.603603720664978
Validation loss: 2.0725269779082267

Epoch: 5| Step: 3
Training loss: 1.4131052494049072
Validation loss: 2.0872745757461875

Epoch: 5| Step: 4
Training loss: 1.2829792499542236
Validation loss: 2.072358509545685

Epoch: 5| Step: 5
Training loss: 1.6393238306045532
Validation loss: 2.067403126788396

Epoch: 5| Step: 6
Training loss: 1.743312120437622
Validation loss: 2.089191829004595

Epoch: 5| Step: 7
Training loss: 1.0911002159118652
Validation loss: 2.0739098415579846

Epoch: 5| Step: 8
Training loss: 1.8658287525177002
Validation loss: 2.0888991330259588

Epoch: 5| Step: 9
Training loss: 1.5654748678207397
Validation loss: 2.108975592479911

Epoch: 5| Step: 10
Training loss: 1.740024209022522
Validation loss: 2.102878233437897

Epoch: 330| Step: 0
Training loss: 2.1078295707702637
Validation loss: 2.106842715253112

Epoch: 5| Step: 1
Training loss: 1.491033911705017
Validation loss: 2.085345520768114

Epoch: 5| Step: 2
Training loss: 1.407603144645691
Validation loss: 2.0921312057843773

Epoch: 5| Step: 3
Training loss: 1.8488689661026
Validation loss: 2.1248096907010643

Epoch: 5| Step: 4
Training loss: 1.3689638376235962
Validation loss: 2.1005468163439023

Epoch: 5| Step: 5
Training loss: 1.7729324102401733
Validation loss: 2.085079682770596

Epoch: 5| Step: 6
Training loss: 1.5243065357208252
Validation loss: 2.054311457500663

Epoch: 5| Step: 7
Training loss: 0.9788029789924622
Validation loss: 2.070452144069056

Epoch: 5| Step: 8
Training loss: 2.081148386001587
Validation loss: 2.084550516579741

Epoch: 5| Step: 9
Training loss: 1.6119998693466187
Validation loss: 2.073144566628241

Epoch: 5| Step: 10
Training loss: 1.4692901372909546
Validation loss: 2.086759408315023

Epoch: 331| Step: 0
Training loss: 2.4712886810302734
Validation loss: 2.0909239886909403

Epoch: 5| Step: 1
Training loss: 2.1413910388946533
Validation loss: 2.0914319920283493

Epoch: 5| Step: 2
Training loss: 2.06124210357666
Validation loss: 2.0928767111993607

Epoch: 5| Step: 3
Training loss: 1.689281702041626
Validation loss: 2.059153082550213

Epoch: 5| Step: 4
Training loss: 1.8332951068878174
Validation loss: 2.070302927365867

Epoch: 5| Step: 5
Training loss: 1.2202560901641846
Validation loss: 2.051335093795612

Epoch: 5| Step: 6
Training loss: 1.181267261505127
Validation loss: 2.0524096001860914

Epoch: 5| Step: 7
Training loss: 1.4806196689605713
Validation loss: 2.051869450076934

Epoch: 5| Step: 8
Training loss: 1.2413320541381836
Validation loss: 2.0687680859719553

Epoch: 5| Step: 9
Training loss: 1.0081613063812256
Validation loss: 2.084770989674394

Epoch: 5| Step: 10
Training loss: 1.2071995735168457
Validation loss: 2.152552348311229

Epoch: 332| Step: 0
Training loss: 0.8811004757881165
Validation loss: 2.203306846721198

Epoch: 5| Step: 1
Training loss: 1.6600128412246704
Validation loss: 2.2681697850586264

Epoch: 5| Step: 2
Training loss: 1.966949462890625
Validation loss: 2.2941229548505557

Epoch: 5| Step: 3
Training loss: 1.4098739624023438
Validation loss: 2.235151324220883

Epoch: 5| Step: 4
Training loss: 1.056251883506775
Validation loss: 2.1792424571129585

Epoch: 5| Step: 5
Training loss: 1.4961931705474854
Validation loss: 2.111065694080886

Epoch: 5| Step: 6
Training loss: 2.4402763843536377
Validation loss: 2.090239638923317

Epoch: 5| Step: 7
Training loss: 2.1438026428222656
Validation loss: 2.084635051347876

Epoch: 5| Step: 8
Training loss: 1.6442553997039795
Validation loss: 2.0493492182864936

Epoch: 5| Step: 9
Training loss: 1.6892812252044678
Validation loss: 2.040164165599372

Epoch: 5| Step: 10
Training loss: 1.6376008987426758
Validation loss: 2.036833087603251

Epoch: 333| Step: 0
Training loss: 2.197143793106079
Validation loss: 2.0449651992449196

Epoch: 5| Step: 1
Training loss: 1.5098116397857666
Validation loss: 2.0709034986393426

Epoch: 5| Step: 2
Training loss: 1.7741895914077759
Validation loss: 2.0900527328573246

Epoch: 5| Step: 3
Training loss: 1.4208450317382812
Validation loss: 2.153868349649573

Epoch: 5| Step: 4
Training loss: 1.9115352630615234
Validation loss: 2.169724766926099

Epoch: 5| Step: 5
Training loss: 1.2932478189468384
Validation loss: 2.1805252516141502

Epoch: 5| Step: 6
Training loss: 1.8368568420410156
Validation loss: 2.1430436936757897

Epoch: 5| Step: 7
Training loss: 1.7645409107208252
Validation loss: 2.103633142286731

Epoch: 5| Step: 8
Training loss: 1.642533540725708
Validation loss: 2.093733267117572

Epoch: 5| Step: 9
Training loss: 1.2610297203063965
Validation loss: 2.0788504769725185

Epoch: 5| Step: 10
Training loss: 0.8350378274917603
Validation loss: 2.0714352617981615

Epoch: 334| Step: 0
Training loss: 1.3359047174453735
Validation loss: 2.0545497504613732

Epoch: 5| Step: 1
Training loss: 1.8738908767700195
Validation loss: 2.0704178117936656

Epoch: 5| Step: 2
Training loss: 1.7599598169326782
Validation loss: 2.0708455731791835

Epoch: 5| Step: 3
Training loss: 1.8214702606201172
Validation loss: 2.1001056419905795

Epoch: 5| Step: 4
Training loss: 1.6350033283233643
Validation loss: 2.1091634688838834

Epoch: 5| Step: 5
Training loss: 1.354958415031433
Validation loss: 2.151916200114835

Epoch: 5| Step: 6
Training loss: 1.5109424591064453
Validation loss: 2.143628207586145

Epoch: 5| Step: 7
Training loss: 1.3911359310150146
Validation loss: 2.1399652573370163

Epoch: 5| Step: 8
Training loss: 2.073908567428589
Validation loss: 2.131293809542092

Epoch: 5| Step: 9
Training loss: 1.0943094491958618
Validation loss: 2.089639453477757

Epoch: 5| Step: 10
Training loss: 1.6859242916107178
Validation loss: 2.0938016445406022

Epoch: 335| Step: 0
Training loss: 1.4010169506072998
Validation loss: 2.0639335775888092

Epoch: 5| Step: 1
Training loss: 2.1013400554656982
Validation loss: 2.0425103505452475

Epoch: 5| Step: 2
Training loss: 1.4749287366867065
Validation loss: 2.042412104145173

Epoch: 5| Step: 3
Training loss: 1.3820720911026
Validation loss: 2.05136800068681

Epoch: 5| Step: 4
Training loss: 1.56210458278656
Validation loss: 2.032912059496808

Epoch: 5| Step: 5
Training loss: 2.05722975730896
Validation loss: 2.050524204008041

Epoch: 5| Step: 6
Training loss: 1.2652862071990967
Validation loss: 2.073800157475215

Epoch: 5| Step: 7
Training loss: 1.191941499710083
Validation loss: 2.1015929214416014

Epoch: 5| Step: 8
Training loss: 2.1857285499572754
Validation loss: 2.135990463277345

Epoch: 5| Step: 9
Training loss: 1.5864145755767822
Validation loss: 2.1595465983113935

Epoch: 5| Step: 10
Training loss: 1.1495317220687866
Validation loss: 2.1637480976761028

Epoch: 336| Step: 0
Training loss: 1.5431925058364868
Validation loss: 2.157468826540055

Epoch: 5| Step: 1
Training loss: 1.286571741104126
Validation loss: 2.125921962081745

Epoch: 5| Step: 2
Training loss: 1.9068189859390259
Validation loss: 2.117998251350977

Epoch: 5| Step: 3
Training loss: 1.3143106698989868
Validation loss: 2.0939606774237847

Epoch: 5| Step: 4
Training loss: 2.2753138542175293
Validation loss: 2.096818995732133

Epoch: 5| Step: 5
Training loss: 1.5714744329452515
Validation loss: 2.0897844273556947

Epoch: 5| Step: 6
Training loss: 1.4072754383087158
Validation loss: 2.0697893147827475

Epoch: 5| Step: 7
Training loss: 0.9774521589279175
Validation loss: 2.0586374241818666

Epoch: 5| Step: 8
Training loss: 2.0374767780303955
Validation loss: 2.06656369855327

Epoch: 5| Step: 9
Training loss: 1.6666145324707031
Validation loss: 2.0494129760290987

Epoch: 5| Step: 10
Training loss: 1.4835848808288574
Validation loss: 2.08985383536226

Epoch: 337| Step: 0
Training loss: 1.523439884185791
Validation loss: 2.1044646693814184

Epoch: 5| Step: 1
Training loss: 1.809120774269104
Validation loss: 2.1406723260879517

Epoch: 5| Step: 2
Training loss: 1.9895389080047607
Validation loss: 2.166428232705721

Epoch: 5| Step: 3
Training loss: 2.3907907009124756
Validation loss: 2.143111026415261

Epoch: 5| Step: 4
Training loss: 0.7842162251472473
Validation loss: 2.1283138157219015

Epoch: 5| Step: 5
Training loss: 1.18917977809906
Validation loss: 2.112677465202988

Epoch: 5| Step: 6
Training loss: 1.126451015472412
Validation loss: 2.1095690650324666

Epoch: 5| Step: 7
Training loss: 1.4789140224456787
Validation loss: 2.081977157182591

Epoch: 5| Step: 8
Training loss: 1.2718918323516846
Validation loss: 2.098534109771893

Epoch: 5| Step: 9
Training loss: 1.6394898891448975
Validation loss: 2.0783614766213203

Epoch: 5| Step: 10
Training loss: 1.9715240001678467
Validation loss: 2.0852765652441208

Epoch: 338| Step: 0
Training loss: 1.6702232360839844
Validation loss: 2.08728951151653

Epoch: 5| Step: 1
Training loss: 2.006516456604004
Validation loss: 2.0657714464331187

Epoch: 5| Step: 2
Training loss: 1.4086687564849854
Validation loss: 2.0883231496298187

Epoch: 5| Step: 3
Training loss: 1.2584476470947266
Validation loss: 2.0886035119333575

Epoch: 5| Step: 4
Training loss: 1.6539722681045532
Validation loss: 2.0924364802657918

Epoch: 5| Step: 5
Training loss: 1.972460150718689
Validation loss: 2.117603696802611

Epoch: 5| Step: 6
Training loss: 1.373669147491455
Validation loss: 2.085296937214431

Epoch: 5| Step: 7
Training loss: 1.1193923950195312
Validation loss: 2.0934971814514487

Epoch: 5| Step: 8
Training loss: 1.4809380769729614
Validation loss: 2.075812816619873

Epoch: 5| Step: 9
Training loss: 1.3091247081756592
Validation loss: 2.066867128495247

Epoch: 5| Step: 10
Training loss: 1.8798742294311523
Validation loss: 2.070366323635142

Epoch: 339| Step: 0
Training loss: 1.3194849491119385
Validation loss: 2.057425565617059

Epoch: 5| Step: 1
Training loss: 1.1523714065551758
Validation loss: 2.0731211477710354

Epoch: 5| Step: 2
Training loss: 1.4953973293304443
Validation loss: 2.085235636721375

Epoch: 5| Step: 3
Training loss: 1.5166127681732178
Validation loss: 2.1004260893790954

Epoch: 5| Step: 4
Training loss: 1.9358972311019897
Validation loss: 2.1247025741043912

Epoch: 5| Step: 5
Training loss: 2.134918689727783
Validation loss: 2.110669502647974

Epoch: 5| Step: 6
Training loss: 1.6706291437149048
Validation loss: 2.107253146427934

Epoch: 5| Step: 7
Training loss: 1.531768798828125
Validation loss: 2.1045564836071384

Epoch: 5| Step: 8
Training loss: 1.3799002170562744
Validation loss: 2.0957148818559546

Epoch: 5| Step: 9
Training loss: 1.4478682279586792
Validation loss: 2.085492777568038

Epoch: 5| Step: 10
Training loss: 1.373304843902588
Validation loss: 2.082064997765326

Epoch: 340| Step: 0
Training loss: 1.2430431842803955
Validation loss: 2.0652641480968845

Epoch: 5| Step: 1
Training loss: 1.547217845916748
Validation loss: 2.069318494489116

Epoch: 5| Step: 2
Training loss: 1.162184715270996
Validation loss: 2.0609842756743073

Epoch: 5| Step: 3
Training loss: 1.6311767101287842
Validation loss: 2.080439265056323

Epoch: 5| Step: 4
Training loss: 1.1675083637237549
Validation loss: 2.104238233258647

Epoch: 5| Step: 5
Training loss: 1.9622631072998047
Validation loss: 2.0968537638264317

Epoch: 5| Step: 6
Training loss: 1.8385000228881836
Validation loss: 2.082653545564221

Epoch: 5| Step: 7
Training loss: 1.4624922275543213
Validation loss: 2.087788020410845

Epoch: 5| Step: 8
Training loss: 1.1974378824234009
Validation loss: 2.0645228470525434

Epoch: 5| Step: 9
Training loss: 1.9179919958114624
Validation loss: 2.0898718295558805

Epoch: 5| Step: 10
Training loss: 1.7091562747955322
Validation loss: 2.0961474423767417

Epoch: 341| Step: 0
Training loss: 1.7439525127410889
Validation loss: 2.1015212330766904

Epoch: 5| Step: 1
Training loss: 1.5799500942230225
Validation loss: 2.082303444544474

Epoch: 5| Step: 2
Training loss: 1.298185110092163
Validation loss: 2.111444947540119

Epoch: 5| Step: 3
Training loss: 1.7793048620224
Validation loss: 2.092838297608078

Epoch: 5| Step: 4
Training loss: 1.684685468673706
Validation loss: 2.089512866030457

Epoch: 5| Step: 5
Training loss: 1.5752441883087158
Validation loss: 2.1048681466810164

Epoch: 5| Step: 6
Training loss: 1.5324605703353882
Validation loss: 2.117625141656527

Epoch: 5| Step: 7
Training loss: 1.6619364023208618
Validation loss: 2.110250196149272

Epoch: 5| Step: 8
Training loss: 1.6831830739974976
Validation loss: 2.1259554355375228

Epoch: 5| Step: 9
Training loss: 0.8450872302055359
Validation loss: 2.124660203533788

Epoch: 5| Step: 10
Training loss: 1.5393041372299194
Validation loss: 2.1211568437596804

Epoch: 342| Step: 0
Training loss: 1.2314971685409546
Validation loss: 2.111861498125138

Epoch: 5| Step: 1
Training loss: 1.3928219079971313
Validation loss: 2.1285762786865234

Epoch: 5| Step: 2
Training loss: 1.2474534511566162
Validation loss: 2.128321493825605

Epoch: 5| Step: 3
Training loss: 1.539876103401184
Validation loss: 2.086358827929343

Epoch: 5| Step: 4
Training loss: 2.4300873279571533
Validation loss: 2.0697738509024344

Epoch: 5| Step: 5
Training loss: 1.330522894859314
Validation loss: 2.0601406046139297

Epoch: 5| Step: 6
Training loss: 1.733001470565796
Validation loss: 2.0645849192014305

Epoch: 5| Step: 7
Training loss: 2.0504708290100098
Validation loss: 2.0630303467473676

Epoch: 5| Step: 8
Training loss: 1.6177304983139038
Validation loss: 2.052353346219627

Epoch: 5| Step: 9
Training loss: 1.1745131015777588
Validation loss: 2.046986399158355

Epoch: 5| Step: 10
Training loss: 1.2788517475128174
Validation loss: 2.04927223344003

Epoch: 343| Step: 0
Training loss: 1.124098539352417
Validation loss: 2.0728072017751713

Epoch: 5| Step: 1
Training loss: 1.7614901065826416
Validation loss: 2.1432005359280493

Epoch: 5| Step: 2
Training loss: 1.2670265436172485
Validation loss: 2.2037132722075268

Epoch: 5| Step: 3
Training loss: 1.5964946746826172
Validation loss: 2.238283500876478

Epoch: 5| Step: 4
Training loss: 1.5283701419830322
Validation loss: 2.229282312495734

Epoch: 5| Step: 5
Training loss: 2.2449920177459717
Validation loss: 2.1853410595206806

Epoch: 5| Step: 6
Training loss: 1.7811038494110107
Validation loss: 2.1890648052256596

Epoch: 5| Step: 7
Training loss: 1.4795033931732178
Validation loss: 2.156469057965022

Epoch: 5| Step: 8
Training loss: 1.4463021755218506
Validation loss: 2.1250641602341847

Epoch: 5| Step: 9
Training loss: 1.6418908834457397
Validation loss: 2.100484355803459

Epoch: 5| Step: 10
Training loss: 1.2676986455917358
Validation loss: 2.071408635826521

Epoch: 344| Step: 0
Training loss: 1.6663434505462646
Validation loss: 2.0458902223135835

Epoch: 5| Step: 1
Training loss: 1.376159429550171
Validation loss: 2.064338832773188

Epoch: 5| Step: 2
Training loss: 1.7771676778793335
Validation loss: 2.0533502076261785

Epoch: 5| Step: 3
Training loss: 1.427865982055664
Validation loss: 2.0493489234678206

Epoch: 5| Step: 4
Training loss: 1.5094112157821655
Validation loss: 2.074680669333345

Epoch: 5| Step: 5
Training loss: 1.4675028324127197
Validation loss: 2.0609939303449405

Epoch: 5| Step: 6
Training loss: 1.2814022302627563
Validation loss: 2.0840843698029876

Epoch: 5| Step: 7
Training loss: 1.7384240627288818
Validation loss: 2.0924976641131985

Epoch: 5| Step: 8
Training loss: 1.809862494468689
Validation loss: 2.1514908805970223

Epoch: 5| Step: 9
Training loss: 1.0617907047271729
Validation loss: 2.1680343253638155

Epoch: 5| Step: 10
Training loss: 1.8887827396392822
Validation loss: 2.1331591631776545

Epoch: 345| Step: 0
Training loss: 1.1492162942886353
Validation loss: 2.097820064072968

Epoch: 5| Step: 1
Training loss: 1.5786218643188477
Validation loss: 2.06404750193319

Epoch: 5| Step: 2
Training loss: 2.1612579822540283
Validation loss: 2.0604424630441973

Epoch: 5| Step: 3
Training loss: 1.1958062648773193
Validation loss: 2.0456439987305672

Epoch: 5| Step: 4
Training loss: 1.2450106143951416
Validation loss: 2.055635931671307

Epoch: 5| Step: 5
Training loss: 2.0192322731018066
Validation loss: 2.0487891422804965

Epoch: 5| Step: 6
Training loss: 1.513343334197998
Validation loss: 2.0346527150882188

Epoch: 5| Step: 7
Training loss: 2.2403225898742676
Validation loss: 2.019540621388343

Epoch: 5| Step: 8
Training loss: 1.5344091653823853
Validation loss: 2.04724379252362

Epoch: 5| Step: 9
Training loss: 1.2452126741409302
Validation loss: 2.06319454280279

Epoch: 5| Step: 10
Training loss: 0.8348531126976013
Validation loss: 2.108249456651749

Epoch: 346| Step: 0
Training loss: 1.3288453817367554
Validation loss: 2.1460830857676845

Epoch: 5| Step: 1
Training loss: 1.9599370956420898
Validation loss: 2.208522319793701

Epoch: 5| Step: 2
Training loss: 1.361156940460205
Validation loss: 2.2351892866114134

Epoch: 5| Step: 3
Training loss: 1.3182363510131836
Validation loss: 2.2090953947395406

Epoch: 5| Step: 4
Training loss: 1.8345801830291748
Validation loss: 2.192835082289993

Epoch: 5| Step: 5
Training loss: 1.2583657503128052
Validation loss: 2.150134112245293

Epoch: 5| Step: 6
Training loss: 0.9834022521972656
Validation loss: 2.1011470825441423

Epoch: 5| Step: 7
Training loss: 2.14461612701416
Validation loss: 2.041371959511952

Epoch: 5| Step: 8
Training loss: 1.4472061395645142
Validation loss: 2.0289415492806384

Epoch: 5| Step: 9
Training loss: 1.6297622919082642
Validation loss: 2.009297711874849

Epoch: 5| Step: 10
Training loss: 1.6314622163772583
Validation loss: 2.0146317187175957

Epoch: 347| Step: 0
Training loss: 1.1562902927398682
Validation loss: 2.0072641808499574

Epoch: 5| Step: 1
Training loss: 0.9718055725097656
Validation loss: 2.0291019703752253

Epoch: 5| Step: 2
Training loss: 1.6016829013824463
Validation loss: 2.063757429840744

Epoch: 5| Step: 3
Training loss: 0.9981247782707214
Validation loss: 2.104226461020849

Epoch: 5| Step: 4
Training loss: 1.6285165548324585
Validation loss: 2.1118188160721973

Epoch: 5| Step: 5
Training loss: 1.6131311655044556
Validation loss: 2.150214436233685

Epoch: 5| Step: 6
Training loss: 1.5914841890335083
Validation loss: 2.1390822087564776

Epoch: 5| Step: 7
Training loss: 2.0085604190826416
Validation loss: 2.1585276537044074

Epoch: 5| Step: 8
Training loss: 2.0814919471740723
Validation loss: 2.1530604157396542

Epoch: 5| Step: 9
Training loss: 1.7942349910736084
Validation loss: 2.1450549043634886

Epoch: 5| Step: 10
Training loss: 1.3716598749160767
Validation loss: 2.105532856397731

Epoch: 348| Step: 0
Training loss: 1.9490363597869873
Validation loss: 2.0839405675088205

Epoch: 5| Step: 1
Training loss: 1.3876407146453857
Validation loss: 2.0970320393962245

Epoch: 5| Step: 2
Training loss: 1.567050576210022
Validation loss: 2.082178859300511

Epoch: 5| Step: 3
Training loss: 1.3979356288909912
Validation loss: 2.080797992726808

Epoch: 5| Step: 4
Training loss: 1.373720407485962
Validation loss: 2.0762232952220465

Epoch: 5| Step: 5
Training loss: 1.6708202362060547
Validation loss: 2.069862101667671

Epoch: 5| Step: 6
Training loss: 1.39064621925354
Validation loss: 2.05803354196651

Epoch: 5| Step: 7
Training loss: 1.7736269235610962
Validation loss: 2.063987931897563

Epoch: 5| Step: 8
Training loss: 1.4767165184020996
Validation loss: 2.0398757714097218

Epoch: 5| Step: 9
Training loss: 1.0053772926330566
Validation loss: 2.0188255963786954

Epoch: 5| Step: 10
Training loss: 1.7003586292266846
Validation loss: 2.047913770521841

Epoch: 349| Step: 0
Training loss: 1.5760241746902466
Validation loss: 2.0416876667289325

Epoch: 5| Step: 1
Training loss: 2.041673183441162
Validation loss: 2.034655196692354

Epoch: 5| Step: 2
Training loss: 1.0302568674087524
Validation loss: 2.0556491626206266

Epoch: 5| Step: 3
Training loss: 1.6821645498275757
Validation loss: 2.058668182742211

Epoch: 5| Step: 4
Training loss: 1.6981923580169678
Validation loss: 2.1134775607816634

Epoch: 5| Step: 5
Training loss: 1.205963134765625
Validation loss: 2.1382003676506782

Epoch: 5| Step: 6
Training loss: 1.205710530281067
Validation loss: 2.159430898645873

Epoch: 5| Step: 7
Training loss: 1.9011567831039429
Validation loss: 2.177519814942473

Epoch: 5| Step: 8
Training loss: 1.6632165908813477
Validation loss: 2.1339343760603215

Epoch: 5| Step: 9
Training loss: 1.598389983177185
Validation loss: 2.099023708733179

Epoch: 5| Step: 10
Training loss: 1.0637779235839844
Validation loss: 2.0899993399138093

Epoch: 350| Step: 0
Training loss: 1.616434097290039
Validation loss: 2.1254992792683263

Epoch: 5| Step: 1
Training loss: 1.799193024635315
Validation loss: 2.144952899666243

Epoch: 5| Step: 2
Training loss: 1.8239471912384033
Validation loss: 2.165668382439562

Epoch: 5| Step: 3
Training loss: 2.1148908138275146
Validation loss: 2.123155504144648

Epoch: 5| Step: 4
Training loss: 1.2777488231658936
Validation loss: 2.089848212016526

Epoch: 5| Step: 5
Training loss: 1.143216848373413
Validation loss: 2.0886611220657185

Epoch: 5| Step: 6
Training loss: 1.6039692163467407
Validation loss: 2.1197912513568835

Epoch: 5| Step: 7
Training loss: 1.230299949645996
Validation loss: 2.1827086505069526

Epoch: 5| Step: 8
Training loss: 1.5724365711212158
Validation loss: 2.1599022124403264

Epoch: 5| Step: 9
Training loss: 1.2957284450531006
Validation loss: 2.1290933470572195

Epoch: 5| Step: 10
Training loss: 1.6336084604263306
Validation loss: 2.100291431591075

Epoch: 351| Step: 0
Training loss: 1.976874589920044
Validation loss: 2.0558670810473862

Epoch: 5| Step: 1
Training loss: 1.4652352333068848
Validation loss: 2.031265579244142

Epoch: 5| Step: 2
Training loss: 1.3433870077133179
Validation loss: 2.023529847462972

Epoch: 5| Step: 3
Training loss: 1.5810840129852295
Validation loss: 2.016528332105247

Epoch: 5| Step: 4
Training loss: 1.2777408361434937
Validation loss: 2.0427235980187692

Epoch: 5| Step: 5
Training loss: 1.5579495429992676
Validation loss: 2.042737886469851

Epoch: 5| Step: 6
Training loss: 1.9616553783416748
Validation loss: 2.0317424625478764

Epoch: 5| Step: 7
Training loss: 1.0500282049179077
Validation loss: 2.0738018699871597

Epoch: 5| Step: 8
Training loss: 1.7561674118041992
Validation loss: 2.1106597492771764

Epoch: 5| Step: 9
Training loss: 1.2475980520248413
Validation loss: 2.130879230396722

Epoch: 5| Step: 10
Training loss: 1.4615929126739502
Validation loss: 2.1798095164760465

Epoch: 352| Step: 0
Training loss: 1.527536153793335
Validation loss: 2.200738888914867

Epoch: 5| Step: 1
Training loss: 1.4189257621765137
Validation loss: 2.1891307830810547

Epoch: 5| Step: 2
Training loss: 1.4240500926971436
Validation loss: 2.106724496810667

Epoch: 5| Step: 3
Training loss: 1.5823659896850586
Validation loss: 2.062541941160797

Epoch: 5| Step: 4
Training loss: 1.4411762952804565
Validation loss: 2.011831820652049

Epoch: 5| Step: 5
Training loss: 1.7497940063476562
Validation loss: 2.0033602560720136

Epoch: 5| Step: 6
Training loss: 1.8836593627929688
Validation loss: 2.020508825138051

Epoch: 5| Step: 7
Training loss: 1.5600529909133911
Validation loss: 2.0099437980241674

Epoch: 5| Step: 8
Training loss: 1.6898565292358398
Validation loss: 2.034923009974982

Epoch: 5| Step: 9
Training loss: 1.5307440757751465
Validation loss: 2.0348219025519585

Epoch: 5| Step: 10
Training loss: 1.0312280654907227
Validation loss: 2.0646987986821

Epoch: 353| Step: 0
Training loss: 1.5609019994735718
Validation loss: 2.0800543344149025

Epoch: 5| Step: 1
Training loss: 2.0816733837127686
Validation loss: 2.1155546711337183

Epoch: 5| Step: 2
Training loss: 1.0399147272109985
Validation loss: 2.1486040853684947

Epoch: 5| Step: 3
Training loss: 1.2806928157806396
Validation loss: 2.150478861665213

Epoch: 5| Step: 4
Training loss: 1.784442663192749
Validation loss: 2.132395795596543

Epoch: 5| Step: 5
Training loss: 0.900962233543396
Validation loss: 2.1526006678099274

Epoch: 5| Step: 6
Training loss: 1.9532825946807861
Validation loss: 2.141393046225271

Epoch: 5| Step: 7
Training loss: 0.8873114585876465
Validation loss: 2.1148640724920456

Epoch: 5| Step: 8
Training loss: 1.7479660511016846
Validation loss: 2.075491791130394

Epoch: 5| Step: 9
Training loss: 1.5765321254730225
Validation loss: 2.0689741898608465

Epoch: 5| Step: 10
Training loss: 1.3962485790252686
Validation loss: 2.0524554867898264

Epoch: 354| Step: 0
Training loss: 1.4861749410629272
Validation loss: 2.046499747101979

Epoch: 5| Step: 1
Training loss: 1.49098801612854
Validation loss: 2.0448358071747648

Epoch: 5| Step: 2
Training loss: 1.3815876245498657
Validation loss: 2.0455808178071053

Epoch: 5| Step: 3
Training loss: 1.6819111108779907
Validation loss: 2.0812919485953545

Epoch: 5| Step: 4
Training loss: 1.8499892950057983
Validation loss: 2.0626884878322644

Epoch: 5| Step: 5
Training loss: 1.2134517431259155
Validation loss: 2.1026998207133305

Epoch: 5| Step: 6
Training loss: 1.6840054988861084
Validation loss: 2.0896193468442528

Epoch: 5| Step: 7
Training loss: 1.775657296180725
Validation loss: 2.0925618871565788

Epoch: 5| Step: 8
Training loss: 1.3459389209747314
Validation loss: 2.0894819459607525

Epoch: 5| Step: 9
Training loss: 1.2717912197113037
Validation loss: 2.0590378315218034

Epoch: 5| Step: 10
Training loss: 0.8371328115463257
Validation loss: 2.073683979690716

Epoch: 355| Step: 0
Training loss: 1.3012542724609375
Validation loss: 2.0117235440079884

Epoch: 5| Step: 1
Training loss: 1.38778817653656
Validation loss: 2.0056471940009826

Epoch: 5| Step: 2
Training loss: 1.5782445669174194
Validation loss: 2.044731322155204

Epoch: 5| Step: 3
Training loss: 1.408259391784668
Validation loss: 2.0260757912871656

Epoch: 5| Step: 4
Training loss: 1.90389084815979
Validation loss: 2.020719160315811

Epoch: 5| Step: 5
Training loss: 1.4164831638336182
Validation loss: 2.06406387975139

Epoch: 5| Step: 6
Training loss: 0.9894087910652161
Validation loss: 2.0764087682129233

Epoch: 5| Step: 7
Training loss: 1.5337215662002563
Validation loss: 2.0518332604439027

Epoch: 5| Step: 8
Training loss: 1.2158677577972412
Validation loss: 2.104080251468125

Epoch: 5| Step: 9
Training loss: 1.3529388904571533
Validation loss: 2.104956942219888

Epoch: 5| Step: 10
Training loss: 1.9602017402648926
Validation loss: 2.1071318695622105

Epoch: 356| Step: 0
Training loss: 1.6497293710708618
Validation loss: 2.144474098759313

Epoch: 5| Step: 1
Training loss: 1.269173502922058
Validation loss: 2.1358134336369012

Epoch: 5| Step: 2
Training loss: 1.5713322162628174
Validation loss: 2.1078441450672765

Epoch: 5| Step: 3
Training loss: 1.204031229019165
Validation loss: 2.0918871715504634

Epoch: 5| Step: 4
Training loss: 1.264573574066162
Validation loss: 2.0840966932235228

Epoch: 5| Step: 5
Training loss: 1.3825823068618774
Validation loss: 2.092095728843443

Epoch: 5| Step: 6
Training loss: 1.9246553182601929
Validation loss: 2.0848628872184345

Epoch: 5| Step: 7
Training loss: 1.5563565492630005
Validation loss: 2.071852332802229

Epoch: 5| Step: 8
Training loss: 1.5909278392791748
Validation loss: 2.0515900517022736

Epoch: 5| Step: 9
Training loss: 1.0938169956207275
Validation loss: 2.0195522897986957

Epoch: 5| Step: 10
Training loss: 1.586972713470459
Validation loss: 2.0288803603059504

Epoch: 357| Step: 0
Training loss: 1.7083714008331299
Validation loss: 2.0310225563664592

Epoch: 5| Step: 1
Training loss: 1.5604398250579834
Validation loss: 2.0415182164920274

Epoch: 5| Step: 2
Training loss: 1.3985373973846436
Validation loss: 2.031324512215071

Epoch: 5| Step: 3
Training loss: 1.6252374649047852
Validation loss: 2.0093049592869257

Epoch: 5| Step: 4
Training loss: 1.2770768404006958
Validation loss: 2.0609092071492183

Epoch: 5| Step: 5
Training loss: 2.0294809341430664
Validation loss: 2.0487197573466966

Epoch: 5| Step: 6
Training loss: 1.3206123113632202
Validation loss: 2.047672592183595

Epoch: 5| Step: 7
Training loss: 1.2989219427108765
Validation loss: 2.0548898699463054

Epoch: 5| Step: 8
Training loss: 1.5071500539779663
Validation loss: 2.0445168992524505

Epoch: 5| Step: 9
Training loss: 1.1958855390548706
Validation loss: 2.0633218339694444

Epoch: 5| Step: 10
Training loss: 0.9669909477233887
Validation loss: 2.0967786440285305

Epoch: 358| Step: 0
Training loss: 1.6267350912094116
Validation loss: 2.102325616344329

Epoch: 5| Step: 1
Training loss: 1.5461900234222412
Validation loss: 2.078324076949909

Epoch: 5| Step: 2
Training loss: 0.7099431753158569
Validation loss: 2.0724238900728125

Epoch: 5| Step: 3
Training loss: 1.1300227642059326
Validation loss: 2.0443276871917067

Epoch: 5| Step: 4
Training loss: 1.6056690216064453
Validation loss: 2.0727842046368505

Epoch: 5| Step: 5
Training loss: 1.1161279678344727
Validation loss: 2.052796653521958

Epoch: 5| Step: 6
Training loss: 1.604346513748169
Validation loss: 2.0497862190328617

Epoch: 5| Step: 7
Training loss: 1.1958256959915161
Validation loss: 2.0270276390096194

Epoch: 5| Step: 8
Training loss: 2.090485095977783
Validation loss: 2.043572520696989

Epoch: 5| Step: 9
Training loss: 1.6552438735961914
Validation loss: 2.0471101294281664

Epoch: 5| Step: 10
Training loss: 1.4612913131713867
Validation loss: 2.05640644924615

Epoch: 359| Step: 0
Training loss: 1.054212212562561
Validation loss: 2.0408550141960062

Epoch: 5| Step: 1
Training loss: 0.9751407504081726
Validation loss: 2.0641602841756677

Epoch: 5| Step: 2
Training loss: 1.287308692932129
Validation loss: 2.034177017468278

Epoch: 5| Step: 3
Training loss: 1.4094918966293335
Validation loss: 2.0575235556530695

Epoch: 5| Step: 4
Training loss: 1.9922088384628296
Validation loss: 2.068837747778944

Epoch: 5| Step: 5
Training loss: 0.8620420694351196
Validation loss: 2.0725812758168867

Epoch: 5| Step: 6
Training loss: 1.625741958618164
Validation loss: 2.069297859745641

Epoch: 5| Step: 7
Training loss: 1.98372483253479
Validation loss: 2.0622627158318796

Epoch: 5| Step: 8
Training loss: 1.9056918621063232
Validation loss: 2.05565764827113

Epoch: 5| Step: 9
Training loss: 1.2424871921539307
Validation loss: 2.0554739557286745

Epoch: 5| Step: 10
Training loss: 1.2975459098815918
Validation loss: 2.0641163241478706

Epoch: 360| Step: 0
Training loss: 1.4507108926773071
Validation loss: 2.058234473710419

Epoch: 5| Step: 1
Training loss: 1.5020097494125366
Validation loss: 2.0545875423698017

Epoch: 5| Step: 2
Training loss: 1.3045741319656372
Validation loss: 2.0539035643300703

Epoch: 5| Step: 3
Training loss: 1.1383655071258545
Validation loss: 2.025760131497537

Epoch: 5| Step: 4
Training loss: 1.253605604171753
Validation loss: 2.0325026717237247

Epoch: 5| Step: 5
Training loss: 1.3546421527862549
Validation loss: 2.065912513322728

Epoch: 5| Step: 6
Training loss: 1.1479829549789429
Validation loss: 2.067844965124643

Epoch: 5| Step: 7
Training loss: 1.6528838872909546
Validation loss: 2.067216093822192

Epoch: 5| Step: 8
Training loss: 1.853104591369629
Validation loss: 2.065345098895411

Epoch: 5| Step: 9
Training loss: 1.7477807998657227
Validation loss: 2.0601506130669707

Epoch: 5| Step: 10
Training loss: 1.1779789924621582
Validation loss: 2.0583387267205024

Epoch: 361| Step: 0
Training loss: 1.4228037595748901
Validation loss: 2.0654183779993365

Epoch: 5| Step: 1
Training loss: 1.9095180034637451
Validation loss: 2.060457588523947

Epoch: 5| Step: 2
Training loss: 1.2855958938598633
Validation loss: 2.0405266002942155

Epoch: 5| Step: 3
Training loss: 1.3162401914596558
Validation loss: 2.0409003047532934

Epoch: 5| Step: 4
Training loss: 1.0090993642807007
Validation loss: 2.0532366473187684

Epoch: 5| Step: 5
Training loss: 1.6388959884643555
Validation loss: 2.027722349730871

Epoch: 5| Step: 6
Training loss: 1.4821679592132568
Validation loss: 2.0446553871195805

Epoch: 5| Step: 7
Training loss: 0.9913825988769531
Validation loss: 2.0482572432487243

Epoch: 5| Step: 8
Training loss: 1.0542209148406982
Validation loss: 2.0413708097191265

Epoch: 5| Step: 9
Training loss: 2.022550106048584
Validation loss: 2.061933522583336

Epoch: 5| Step: 10
Training loss: 1.4870980978012085
Validation loss: 2.0856909892892324

Epoch: 362| Step: 0
Training loss: 1.597233533859253
Validation loss: 2.076914994947372

Epoch: 5| Step: 1
Training loss: 1.2312082052230835
Validation loss: 2.089071463513118

Epoch: 5| Step: 2
Training loss: 1.6107110977172852
Validation loss: 2.0687151339746292

Epoch: 5| Step: 3
Training loss: 1.5577765703201294
Validation loss: 2.0690571672172955

Epoch: 5| Step: 4
Training loss: 1.743561029434204
Validation loss: 2.0646660353547786

Epoch: 5| Step: 5
Training loss: 1.3696434497833252
Validation loss: 2.0521753500866633

Epoch: 5| Step: 6
Training loss: 0.8113589286804199
Validation loss: 2.0561703174344954

Epoch: 5| Step: 7
Training loss: 1.2616167068481445
Validation loss: 2.056581829183845

Epoch: 5| Step: 8
Training loss: 1.3847246170043945
Validation loss: 2.0829783306326917

Epoch: 5| Step: 9
Training loss: 1.7789056301116943
Validation loss: 2.0601276966833297

Epoch: 5| Step: 10
Training loss: 1.1357355117797852
Validation loss: 2.079044122849741

Epoch: 363| Step: 0
Training loss: 1.403075933456421
Validation loss: 2.092882607572822

Epoch: 5| Step: 1
Training loss: 1.3414440155029297
Validation loss: 2.0813690206056

Epoch: 5| Step: 2
Training loss: 1.7219884395599365
Validation loss: 2.091250095316159

Epoch: 5| Step: 3
Training loss: 1.5556395053863525
Validation loss: 2.074775938064821

Epoch: 5| Step: 4
Training loss: 0.9138540029525757
Validation loss: 2.0427489370428105

Epoch: 5| Step: 5
Training loss: 1.5916192531585693
Validation loss: 2.0447287867146153

Epoch: 5| Step: 6
Training loss: 1.4831275939941406
Validation loss: 2.0404530866171724

Epoch: 5| Step: 7
Training loss: 1.180773138999939
Validation loss: 2.0707135943956274

Epoch: 5| Step: 8
Training loss: 1.1926497220993042
Validation loss: 2.0286472305174796

Epoch: 5| Step: 9
Training loss: 1.2543388605117798
Validation loss: 2.055706101079141

Epoch: 5| Step: 10
Training loss: 1.8600139617919922
Validation loss: 2.065181791141469

Epoch: 364| Step: 0
Training loss: 1.4883158206939697
Validation loss: 2.037640804885536

Epoch: 5| Step: 1
Training loss: 1.001469373703003
Validation loss: 2.0609317851322952

Epoch: 5| Step: 2
Training loss: 1.414571762084961
Validation loss: 2.028232438589937

Epoch: 5| Step: 3
Training loss: 1.7088525295257568
Validation loss: 2.038473211308961

Epoch: 5| Step: 4
Training loss: 1.327967643737793
Validation loss: 2.0448368159673547

Epoch: 5| Step: 5
Training loss: 1.3411712646484375
Validation loss: 2.004766748797509

Epoch: 5| Step: 6
Training loss: 1.3250234127044678
Validation loss: 2.024400420086358

Epoch: 5| Step: 7
Training loss: 1.6764272451400757
Validation loss: 2.0072606891714115

Epoch: 5| Step: 8
Training loss: 1.3800010681152344
Validation loss: 2.002286240618716

Epoch: 5| Step: 9
Training loss: 0.9812795519828796
Validation loss: 2.013376807653776

Epoch: 5| Step: 10
Training loss: 1.8664990663528442
Validation loss: 2.056224528179374

Epoch: 365| Step: 0
Training loss: 2.1085801124572754
Validation loss: 2.076067614298995

Epoch: 5| Step: 1
Training loss: 1.14621102809906
Validation loss: 2.0714624799707884

Epoch: 5| Step: 2
Training loss: 1.292283296585083
Validation loss: 2.0697411285933627

Epoch: 5| Step: 3
Training loss: 1.03415846824646
Validation loss: 2.033624428574757

Epoch: 5| Step: 4
Training loss: 1.7463620901107788
Validation loss: 2.012040081844535

Epoch: 5| Step: 5
Training loss: 1.7371639013290405
Validation loss: 2.002865807984465

Epoch: 5| Step: 6
Training loss: 0.8573325276374817
Validation loss: 2.0068207146019064

Epoch: 5| Step: 7
Training loss: 1.3863859176635742
Validation loss: 2.0397460954163664

Epoch: 5| Step: 8
Training loss: 1.0314637422561646
Validation loss: 2.022874052806567

Epoch: 5| Step: 9
Training loss: 1.5377646684646606
Validation loss: 2.0337568342044787

Epoch: 5| Step: 10
Training loss: 1.498417615890503
Validation loss: 2.027015205352537

Epoch: 366| Step: 0
Training loss: 1.4362258911132812
Validation loss: 2.025574811043278

Epoch: 5| Step: 1
Training loss: 1.3381001949310303
Validation loss: 2.0027589413427536

Epoch: 5| Step: 2
Training loss: 1.3658798933029175
Validation loss: 2.0153729864346084

Epoch: 5| Step: 3
Training loss: 1.7667255401611328
Validation loss: 2.0081993456809752

Epoch: 5| Step: 4
Training loss: 1.166487455368042
Validation loss: 1.9884066017725135

Epoch: 5| Step: 5
Training loss: 1.1643402576446533
Validation loss: 2.0020391377069617

Epoch: 5| Step: 6
Training loss: 1.9157450199127197
Validation loss: 1.9837420114906885

Epoch: 5| Step: 7
Training loss: 1.665140151977539
Validation loss: 1.9898118383140975

Epoch: 5| Step: 8
Training loss: 1.1312438249588013
Validation loss: 1.969560428332257

Epoch: 5| Step: 9
Training loss: 1.0588703155517578
Validation loss: 2.010448301992109

Epoch: 5| Step: 10
Training loss: 1.137853980064392
Validation loss: 2.015454284606441

Epoch: 367| Step: 0
Training loss: 0.7868813872337341
Validation loss: 2.009875000164073

Epoch: 5| Step: 1
Training loss: 1.079109787940979
Validation loss: 2.05414084465273

Epoch: 5| Step: 2
Training loss: 1.2055284976959229
Validation loss: 2.0618389550075737

Epoch: 5| Step: 3
Training loss: 1.9329988956451416
Validation loss: 2.0694500066900767

Epoch: 5| Step: 4
Training loss: 1.2337367534637451
Validation loss: 2.0696735971717426

Epoch: 5| Step: 5
Training loss: 1.0856082439422607
Validation loss: 2.0982121870081913

Epoch: 5| Step: 6
Training loss: 1.4741545915603638
Validation loss: 2.0721695730763097

Epoch: 5| Step: 7
Training loss: 1.6555887460708618
Validation loss: 2.0551735483190066

Epoch: 5| Step: 8
Training loss: 2.216665267944336
Validation loss: 1.9908990539530271

Epoch: 5| Step: 9
Training loss: 1.4022245407104492
Validation loss: 2.000641740778441

Epoch: 5| Step: 10
Training loss: 1.0925014019012451
Validation loss: 2.001344052694177

Epoch: 368| Step: 0
Training loss: 1.5216701030731201
Validation loss: 1.9907868754479192

Epoch: 5| Step: 1
Training loss: 1.6240217685699463
Validation loss: 2.0123776928071053

Epoch: 5| Step: 2
Training loss: 1.5579181909561157
Validation loss: 2.0045517195937452

Epoch: 5| Step: 3
Training loss: 1.216312050819397
Validation loss: 2.019484345630933

Epoch: 5| Step: 4
Training loss: 0.8870220184326172
Validation loss: 2.0283095221365652

Epoch: 5| Step: 5
Training loss: 0.8134851455688477
Validation loss: 2.047084136675763

Epoch: 5| Step: 6
Training loss: 1.1671937704086304
Validation loss: 2.0661497346816526

Epoch: 5| Step: 7
Training loss: 1.5946195125579834
Validation loss: 2.0901593572349957

Epoch: 5| Step: 8
Training loss: 1.726991057395935
Validation loss: 2.093658839502642

Epoch: 5| Step: 9
Training loss: 1.8504059314727783
Validation loss: 2.0948465383181007

Epoch: 5| Step: 10
Training loss: 1.1749745607376099
Validation loss: 2.078791756783762

Epoch: 369| Step: 0
Training loss: 1.6560561656951904
Validation loss: 2.0672139249822146

Epoch: 5| Step: 1
Training loss: 1.2723923921585083
Validation loss: 2.05752537327428

Epoch: 5| Step: 2
Training loss: 1.0477573871612549
Validation loss: 2.0414024886264595

Epoch: 5| Step: 3
Training loss: 1.5288797616958618
Validation loss: 2.011096548008662

Epoch: 5| Step: 4
Training loss: 1.723415732383728
Validation loss: 2.028241413895802

Epoch: 5| Step: 5
Training loss: 1.2022403478622437
Validation loss: 2.0123565068808933

Epoch: 5| Step: 6
Training loss: 1.2522214651107788
Validation loss: 1.987383395112971

Epoch: 5| Step: 7
Training loss: 2.037208080291748
Validation loss: 1.993112592286961

Epoch: 5| Step: 8
Training loss: 0.9443479776382446
Validation loss: 2.001953057063523

Epoch: 5| Step: 9
Training loss: 1.388735055923462
Validation loss: 2.000620331815494

Epoch: 5| Step: 10
Training loss: 1.113124132156372
Validation loss: 2.0036287179557224

Epoch: 370| Step: 0
Training loss: 1.3217986822128296
Validation loss: 2.051397608172509

Epoch: 5| Step: 1
Training loss: 1.3458442687988281
Validation loss: 2.1233295471437517

Epoch: 5| Step: 2
Training loss: 1.0069442987442017
Validation loss: 2.1144648533995434

Epoch: 5| Step: 3
Training loss: 2.3009707927703857
Validation loss: 2.133469425221925

Epoch: 5| Step: 4
Training loss: 1.4033489227294922
Validation loss: 2.112027846356874

Epoch: 5| Step: 5
Training loss: 1.0876872539520264
Validation loss: 2.076336717092863

Epoch: 5| Step: 6
Training loss: 1.447213888168335
Validation loss: 2.014586430723949

Epoch: 5| Step: 7
Training loss: 1.1475210189819336
Validation loss: 1.9955566416504562

Epoch: 5| Step: 8
Training loss: 1.1835384368896484
Validation loss: 1.9950786200902795

Epoch: 5| Step: 9
Training loss: 1.5288718938827515
Validation loss: 1.9966340513639553

Epoch: 5| Step: 10
Training loss: 1.4072625637054443
Validation loss: 1.9931124359048822

Epoch: 371| Step: 0
Training loss: 1.2670042514801025
Validation loss: 1.977879278121456

Epoch: 5| Step: 1
Training loss: 1.882305383682251
Validation loss: 1.9986535464563677

Epoch: 5| Step: 2
Training loss: 0.9508379697799683
Validation loss: 1.9922473148633075

Epoch: 5| Step: 3
Training loss: 1.7350451946258545
Validation loss: 2.014131194801741

Epoch: 5| Step: 4
Training loss: 1.4199936389923096
Validation loss: 2.0297057359449324

Epoch: 5| Step: 5
Training loss: 1.0014829635620117
Validation loss: 2.084907679147618

Epoch: 5| Step: 6
Training loss: 1.5039849281311035
Validation loss: 2.119426973404423

Epoch: 5| Step: 7
Training loss: 0.9291160702705383
Validation loss: 2.111048017778704

Epoch: 5| Step: 8
Training loss: 1.6240379810333252
Validation loss: 2.0953637835800007

Epoch: 5| Step: 9
Training loss: 1.0243422985076904
Validation loss: 2.072269924225346

Epoch: 5| Step: 10
Training loss: 1.8411178588867188
Validation loss: 2.0409693000137166

Epoch: 372| Step: 0
Training loss: 1.4013445377349854
Validation loss: 2.0476391815370127

Epoch: 5| Step: 1
Training loss: 1.7180153131484985
Validation loss: 2.006525990783527

Epoch: 5| Step: 2
Training loss: 1.3550536632537842
Validation loss: 1.9856293175810127

Epoch: 5| Step: 3
Training loss: 0.9699563980102539
Validation loss: 1.981492397605732

Epoch: 5| Step: 4
Training loss: 1.209612250328064
Validation loss: 1.9910978655661307

Epoch: 5| Step: 5
Training loss: 1.5122606754302979
Validation loss: 2.0063522079939484

Epoch: 5| Step: 6
Training loss: 1.6452217102050781
Validation loss: 2.0256010909234323

Epoch: 5| Step: 7
Training loss: 1.1510545015335083
Validation loss: 2.0738136652977235

Epoch: 5| Step: 8
Training loss: 0.9420294761657715
Validation loss: 2.078968050659344

Epoch: 5| Step: 9
Training loss: 1.5519912242889404
Validation loss: 2.068036827989804

Epoch: 5| Step: 10
Training loss: 1.5311225652694702
Validation loss: 2.0989347068212365

Epoch: 373| Step: 0
Training loss: 1.6169830560684204
Validation loss: 2.0912821036513134

Epoch: 5| Step: 1
Training loss: 1.671505331993103
Validation loss: 2.087746294595862

Epoch: 5| Step: 2
Training loss: 0.9848507642745972
Validation loss: 2.0731317061249928

Epoch: 5| Step: 3
Training loss: 1.2438430786132812
Validation loss: 2.0541163644483014

Epoch: 5| Step: 4
Training loss: 1.3998769521713257
Validation loss: 2.0389993498402257

Epoch: 5| Step: 5
Training loss: 1.3894832134246826
Validation loss: 2.0304550150389313

Epoch: 5| Step: 6
Training loss: 1.5755037069320679
Validation loss: 1.9901120534507177

Epoch: 5| Step: 7
Training loss: 1.380361795425415
Validation loss: 1.9884073759919854

Epoch: 5| Step: 8
Training loss: 1.0069482326507568
Validation loss: 2.0073046556083103

Epoch: 5| Step: 9
Training loss: 1.4841234683990479
Validation loss: 2.0082662605470225

Epoch: 5| Step: 10
Training loss: 1.1895227432250977
Validation loss: 2.033750662239649

Epoch: 374| Step: 0
Training loss: 1.238791823387146
Validation loss: 1.9850506487713064

Epoch: 5| Step: 1
Training loss: 1.1464931964874268
Validation loss: 2.008649205648771

Epoch: 5| Step: 2
Training loss: 1.5902340412139893
Validation loss: 2.0126215962953466

Epoch: 5| Step: 3
Training loss: 1.038339376449585
Validation loss: 2.0099836703269713

Epoch: 5| Step: 4
Training loss: 1.3659067153930664
Validation loss: 2.0264714661464898

Epoch: 5| Step: 5
Training loss: 1.346954107284546
Validation loss: 2.0236771452811455

Epoch: 5| Step: 6
Training loss: 1.7590084075927734
Validation loss: 2.0536786753644227

Epoch: 5| Step: 7
Training loss: 1.1794488430023193
Validation loss: 2.05743985022268

Epoch: 5| Step: 8
Training loss: 1.223223328590393
Validation loss: 2.0610226764473865

Epoch: 5| Step: 9
Training loss: 1.0799238681793213
Validation loss: 2.0823832096592074

Epoch: 5| Step: 10
Training loss: 2.094010829925537
Validation loss: 2.0629846806167276

Epoch: 375| Step: 0
Training loss: 1.2611331939697266
Validation loss: 2.002344867234589

Epoch: 5| Step: 1
Training loss: 1.3954277038574219
Validation loss: 2.022994018370105

Epoch: 5| Step: 2
Training loss: 1.468644380569458
Validation loss: 1.996344982936818

Epoch: 5| Step: 3
Training loss: 1.2745883464813232
Validation loss: 1.9878397180188088

Epoch: 5| Step: 4
Training loss: 1.2113664150238037
Validation loss: 1.9993699853138258

Epoch: 5| Step: 5
Training loss: 1.1578978300094604
Validation loss: 1.9857059806905768

Epoch: 5| Step: 6
Training loss: 1.1719036102294922
Validation loss: 2.038090007279509

Epoch: 5| Step: 7
Training loss: 1.6148964166641235
Validation loss: 2.0573588494331605

Epoch: 5| Step: 8
Training loss: 1.3178770542144775
Validation loss: 2.0764571056571057

Epoch: 5| Step: 9
Training loss: 1.0769493579864502
Validation loss: 2.06717485638075

Epoch: 5| Step: 10
Training loss: 2.0017197132110596
Validation loss: 2.054951539603613

Epoch: 376| Step: 0
Training loss: 1.2884280681610107
Validation loss: 2.0316377429551977

Epoch: 5| Step: 1
Training loss: 1.5124069452285767
Validation loss: 2.0377034987172773

Epoch: 5| Step: 2
Training loss: 1.3339236974716187
Validation loss: 1.987031070134973

Epoch: 5| Step: 3
Training loss: 1.6011912822723389
Validation loss: 1.9929731328000304

Epoch: 5| Step: 4
Training loss: 1.914520025253296
Validation loss: 1.962946771293558

Epoch: 5| Step: 5
Training loss: 1.3239825963974
Validation loss: 1.9732630688657042

Epoch: 5| Step: 6
Training loss: 1.049605131149292
Validation loss: 1.9877685564820484

Epoch: 5| Step: 7
Training loss: 1.0405175685882568
Validation loss: 1.9715369004075245

Epoch: 5| Step: 8
Training loss: 1.519794225692749
Validation loss: 2.0031543085652013

Epoch: 5| Step: 9
Training loss: 1.2572053670883179
Validation loss: 2.037994974402971

Epoch: 5| Step: 10
Training loss: 1.2087857723236084
Validation loss: 2.070678651973765

Epoch: 377| Step: 0
Training loss: 1.1914771795272827
Validation loss: 2.1200226147969565

Epoch: 5| Step: 1
Training loss: 1.4373515844345093
Validation loss: 2.1222995609365483

Epoch: 5| Step: 2
Training loss: 1.5146286487579346
Validation loss: 2.16173231217169

Epoch: 5| Step: 3
Training loss: 1.219199776649475
Validation loss: 2.1322432564150904

Epoch: 5| Step: 4
Training loss: 0.695067286491394
Validation loss: 2.0977561884028937

Epoch: 5| Step: 5
Training loss: 1.1889816522598267
Validation loss: 2.0368202886273785

Epoch: 5| Step: 6
Training loss: 1.5078375339508057
Validation loss: 2.0238056772498676

Epoch: 5| Step: 7
Training loss: 1.7228775024414062
Validation loss: 1.982854312466037

Epoch: 5| Step: 8
Training loss: 1.5003637075424194
Validation loss: 1.9583415472379295

Epoch: 5| Step: 9
Training loss: 1.488333821296692
Validation loss: 1.9417145867501535

Epoch: 5| Step: 10
Training loss: 1.4473026990890503
Validation loss: 1.9531116280504452

Epoch: 378| Step: 0
Training loss: 0.6859873533248901
Validation loss: 1.9573227205584127

Epoch: 5| Step: 1
Training loss: 1.308518886566162
Validation loss: 2.0063100771237443

Epoch: 5| Step: 2
Training loss: 1.693007469177246
Validation loss: 2.0242930099528325

Epoch: 5| Step: 3
Training loss: 1.4436900615692139
Validation loss: 1.9982522072330597

Epoch: 5| Step: 4
Training loss: 1.4183999300003052
Validation loss: 2.044990381886882

Epoch: 5| Step: 5
Training loss: 1.9009125232696533
Validation loss: 2.0559988047486994

Epoch: 5| Step: 6
Training loss: 1.2217721939086914
Validation loss: 2.0517356113720964

Epoch: 5| Step: 7
Training loss: 0.9633415937423706
Validation loss: 2.051214820595198

Epoch: 5| Step: 8
Training loss: 1.4155313968658447
Validation loss: 2.0425139409239574

Epoch: 5| Step: 9
Training loss: 1.354641079902649
Validation loss: 2.0826478030091975

Epoch: 5| Step: 10
Training loss: 1.6802579164505005
Validation loss: 2.0536409449833695

Epoch: 379| Step: 0
Training loss: 1.3137174844741821
Validation loss: 2.072955516076857

Epoch: 5| Step: 1
Training loss: 1.1112828254699707
Validation loss: 2.0526255510186635

Epoch: 5| Step: 2
Training loss: 1.4505555629730225
Validation loss: 2.0333049733151674

Epoch: 5| Step: 3
Training loss: 1.6041297912597656
Validation loss: 2.0367780564933695

Epoch: 5| Step: 4
Training loss: 1.692832350730896
Validation loss: 2.03086858154625

Epoch: 5| Step: 5
Training loss: 1.093287467956543
Validation loss: 2.0118499955823346

Epoch: 5| Step: 6
Training loss: 1.063795566558838
Validation loss: 2.0449330281185847

Epoch: 5| Step: 7
Training loss: 1.3598675727844238
Validation loss: 1.9963607544540076

Epoch: 5| Step: 8
Training loss: 1.337167501449585
Validation loss: 1.9940812049373504

Epoch: 5| Step: 9
Training loss: 1.3903224468231201
Validation loss: 2.0098311029454714

Epoch: 5| Step: 10
Training loss: 1.0097228288650513
Validation loss: 2.02043128654521

Epoch: 380| Step: 0
Training loss: 1.1653202772140503
Validation loss: 2.026938388424535

Epoch: 5| Step: 1
Training loss: 1.5867735147476196
Validation loss: 2.030935843785604

Epoch: 5| Step: 2
Training loss: 0.9422906637191772
Validation loss: 2.0461573421314196

Epoch: 5| Step: 3
Training loss: 1.9905331134796143
Validation loss: 2.0626184555792038

Epoch: 5| Step: 4
Training loss: 1.2966821193695068
Validation loss: 2.0564521307586343

Epoch: 5| Step: 5
Training loss: 1.4203232526779175
Validation loss: 2.0344718348595405

Epoch: 5| Step: 6
Training loss: 1.1013145446777344
Validation loss: 2.0024983690631006

Epoch: 5| Step: 7
Training loss: 1.4098085165023804
Validation loss: 2.0170616437030096

Epoch: 5| Step: 8
Training loss: 1.0544270277023315
Validation loss: 2.0053337697059876

Epoch: 5| Step: 9
Training loss: 0.9319256544113159
Validation loss: 1.9767929661658503

Epoch: 5| Step: 10
Training loss: 1.5609323978424072
Validation loss: 1.9613732907079882

Epoch: 381| Step: 0
Training loss: 1.042623519897461
Validation loss: 1.978533141074642

Epoch: 5| Step: 1
Training loss: 1.8865501880645752
Validation loss: 1.9968042450566446

Epoch: 5| Step: 2
Training loss: 1.423413872718811
Validation loss: 2.0149796970428957

Epoch: 5| Step: 3
Training loss: 1.5675216913223267
Validation loss: 2.0122697391817645

Epoch: 5| Step: 4
Training loss: 1.2819805145263672
Validation loss: 2.0329121992152226

Epoch: 5| Step: 5
Training loss: 1.5129287242889404
Validation loss: 2.0448222160339355

Epoch: 5| Step: 6
Training loss: 1.2095714807510376
Validation loss: 2.0506109601707867

Epoch: 5| Step: 7
Training loss: 1.3303210735321045
Validation loss: 2.0139802566138645

Epoch: 5| Step: 8
Training loss: 1.1563966274261475
Validation loss: 2.0137158978369927

Epoch: 5| Step: 9
Training loss: 1.0244783163070679
Validation loss: 1.9936456334206365

Epoch: 5| Step: 10
Training loss: 0.863402783870697
Validation loss: 2.005310643103815

Epoch: 382| Step: 0
Training loss: 1.1244547367095947
Validation loss: 1.9886906326458018

Epoch: 5| Step: 1
Training loss: 0.8863106966018677
Validation loss: 1.9746137588254866

Epoch: 5| Step: 2
Training loss: 1.2884329557418823
Validation loss: 1.997480474492555

Epoch: 5| Step: 3
Training loss: 1.7004032135009766
Validation loss: 1.9943969557362218

Epoch: 5| Step: 4
Training loss: 1.1786977052688599
Validation loss: 2.031067575177839

Epoch: 5| Step: 5
Training loss: 1.4278576374053955
Validation loss: 2.0291868768712527

Epoch: 5| Step: 6
Training loss: 1.1451752185821533
Validation loss: 2.013290910310643

Epoch: 5| Step: 7
Training loss: 1.055137276649475
Validation loss: 2.031189485262799

Epoch: 5| Step: 8
Training loss: 1.5627355575561523
Validation loss: 2.0507496762019333

Epoch: 5| Step: 9
Training loss: 1.461717963218689
Validation loss: 2.031226873397827

Epoch: 5| Step: 10
Training loss: 1.5601177215576172
Validation loss: 2.011790147391699

Epoch: 383| Step: 0
Training loss: 1.5047684907913208
Validation loss: 1.9826265355592132

Epoch: 5| Step: 1
Training loss: 1.1184602975845337
Validation loss: 1.9919726694783857

Epoch: 5| Step: 2
Training loss: 1.2526118755340576
Validation loss: 1.9930185041119974

Epoch: 5| Step: 3
Training loss: 1.9439716339111328
Validation loss: 1.9679453142227665

Epoch: 5| Step: 4
Training loss: 1.5405601263046265
Validation loss: 1.9830892829484836

Epoch: 5| Step: 5
Training loss: 0.8977888226509094
Validation loss: 1.9810162052031486

Epoch: 5| Step: 6
Training loss: 1.446882963180542
Validation loss: 2.0028418161535777

Epoch: 5| Step: 7
Training loss: 1.3861701488494873
Validation loss: 1.9826224542433215

Epoch: 5| Step: 8
Training loss: 1.4098303318023682
Validation loss: 1.9791816819098689

Epoch: 5| Step: 9
Training loss: 0.894821047782898
Validation loss: 2.004123777471563

Epoch: 5| Step: 10
Training loss: 0.6985502243041992
Validation loss: 2.014053101180702

Epoch: 384| Step: 0
Training loss: 1.5606136322021484
Validation loss: 2.019827973458075

Epoch: 5| Step: 1
Training loss: 1.2437078952789307
Validation loss: 2.021009196517288

Epoch: 5| Step: 2
Training loss: 1.1532847881317139
Validation loss: 1.9770658452023742

Epoch: 5| Step: 3
Training loss: 1.2958158254623413
Validation loss: 1.9914743925935479

Epoch: 5| Step: 4
Training loss: 1.2841062545776367
Validation loss: 1.997227627743957

Epoch: 5| Step: 5
Training loss: 1.5141685009002686
Validation loss: 1.9948413974495345

Epoch: 5| Step: 6
Training loss: 1.283254623413086
Validation loss: 1.984941573553188

Epoch: 5| Step: 7
Training loss: 1.356321096420288
Validation loss: 1.991480520976487

Epoch: 5| Step: 8
Training loss: 0.6662470102310181
Validation loss: 1.9998475659278132

Epoch: 5| Step: 9
Training loss: 1.2072107791900635
Validation loss: 2.011569446133029

Epoch: 5| Step: 10
Training loss: 1.6008496284484863
Validation loss: 2.0228362544890373

Epoch: 385| Step: 0
Training loss: 1.4173139333724976
Validation loss: 2.010279627256496

Epoch: 5| Step: 1
Training loss: 1.2414696216583252
Validation loss: 2.0214150541572162

Epoch: 5| Step: 2
Training loss: 0.9561125040054321
Validation loss: 2.028107596341

Epoch: 5| Step: 3
Training loss: 1.0079796314239502
Validation loss: 2.0235239933895808

Epoch: 5| Step: 4
Training loss: 1.275802731513977
Validation loss: 2.0584022588627313

Epoch: 5| Step: 5
Training loss: 1.4577572345733643
Validation loss: 2.0429766742132043

Epoch: 5| Step: 6
Training loss: 1.5472813844680786
Validation loss: 2.0340089349336523

Epoch: 5| Step: 7
Training loss: 1.7187139987945557
Validation loss: 2.0078143137757496

Epoch: 5| Step: 8
Training loss: 1.2066314220428467
Validation loss: 1.9552763841485465

Epoch: 5| Step: 9
Training loss: 1.01564621925354
Validation loss: 1.9551632814509894

Epoch: 5| Step: 10
Training loss: 1.5736987590789795
Validation loss: 1.931985919193555

Epoch: 386| Step: 0
Training loss: 1.495894193649292
Validation loss: 1.941620534466159

Epoch: 5| Step: 1
Training loss: 1.2060747146606445
Validation loss: 1.9654324272627473

Epoch: 5| Step: 2
Training loss: 1.3474764823913574
Validation loss: 1.9730633894602458

Epoch: 5| Step: 3
Training loss: 1.5375059843063354
Validation loss: 1.9653916512766192

Epoch: 5| Step: 4
Training loss: 1.2991364002227783
Validation loss: 2.0177928042668167

Epoch: 5| Step: 5
Training loss: 1.1098542213439941
Validation loss: 2.035388986269633

Epoch: 5| Step: 6
Training loss: 1.3334412574768066
Validation loss: 2.0816076006940616

Epoch: 5| Step: 7
Training loss: 1.1057496070861816
Validation loss: 2.101878512290216

Epoch: 5| Step: 8
Training loss: 1.4492316246032715
Validation loss: 2.0676682854211457

Epoch: 5| Step: 9
Training loss: 1.1686421632766724
Validation loss: 2.040460358383835

Epoch: 5| Step: 10
Training loss: 1.2945921421051025
Validation loss: 2.0314551220145276

Epoch: 387| Step: 0
Training loss: 1.5382778644561768
Validation loss: 2.0132125064890873

Epoch: 5| Step: 1
Training loss: 1.117221474647522
Validation loss: 2.0218240804569696

Epoch: 5| Step: 2
Training loss: 1.1673170328140259
Validation loss: 2.021136232601699

Epoch: 5| Step: 3
Training loss: 1.9195845127105713
Validation loss: 2.000469230836438

Epoch: 5| Step: 4
Training loss: 1.4265801906585693
Validation loss: 2.0133092172684206

Epoch: 5| Step: 5
Training loss: 1.1330690383911133
Validation loss: 2.020408102261123

Epoch: 5| Step: 6
Training loss: 0.954292893409729
Validation loss: 2.0254518678111415

Epoch: 5| Step: 7
Training loss: 1.5463237762451172
Validation loss: 2.0148127232828448

Epoch: 5| Step: 8
Training loss: 1.050180435180664
Validation loss: 2.0164926487912416

Epoch: 5| Step: 9
Training loss: 1.022885799407959
Validation loss: 2.0299443865335114

Epoch: 5| Step: 10
Training loss: 1.0636053085327148
Validation loss: 2.0358755434713056

Epoch: 388| Step: 0
Training loss: 1.012248158454895
Validation loss: 2.033905698407081

Epoch: 5| Step: 1
Training loss: 1.4753433465957642
Validation loss: 2.043387165633581

Epoch: 5| Step: 2
Training loss: 0.9233320951461792
Validation loss: 1.9919169500309934

Epoch: 5| Step: 3
Training loss: 1.383978009223938
Validation loss: 2.00067001517101

Epoch: 5| Step: 4
Training loss: 1.837421178817749
Validation loss: 1.9853978169861661

Epoch: 5| Step: 5
Training loss: 1.2069964408874512
Validation loss: 1.9981773578992454

Epoch: 5| Step: 6
Training loss: 1.5261842012405396
Validation loss: 1.9770948220324773

Epoch: 5| Step: 7
Training loss: 1.1069146394729614
Validation loss: 2.005868983525102

Epoch: 5| Step: 8
Training loss: 1.598146677017212
Validation loss: 1.9971976075121152

Epoch: 5| Step: 9
Training loss: 0.8174377679824829
Validation loss: 2.0146587035989247

Epoch: 5| Step: 10
Training loss: 1.1919972896575928
Validation loss: 2.0541578544083463

Epoch: 389| Step: 0
Training loss: 1.314021348953247
Validation loss: 2.070564058519179

Epoch: 5| Step: 1
Training loss: 1.6569944620132446
Validation loss: 2.069049394258889

Epoch: 5| Step: 2
Training loss: 1.0503761768341064
Validation loss: 2.0486582171532417

Epoch: 5| Step: 3
Training loss: 1.3195728063583374
Validation loss: 2.058443425804056

Epoch: 5| Step: 4
Training loss: 1.4683570861816406
Validation loss: 2.0180411800261466

Epoch: 5| Step: 5
Training loss: 1.1302320957183838
Validation loss: 1.9993750587586434

Epoch: 5| Step: 6
Training loss: 0.9191393852233887
Validation loss: 1.9750285276802637

Epoch: 5| Step: 7
Training loss: 1.1322309970855713
Validation loss: 1.9643914943100305

Epoch: 5| Step: 8
Training loss: 1.0847448110580444
Validation loss: 1.9635307827303488

Epoch: 5| Step: 9
Training loss: 1.5926538705825806
Validation loss: 1.9489014956258959

Epoch: 5| Step: 10
Training loss: 1.336753249168396
Validation loss: 1.9564764461209696

Epoch: 390| Step: 0
Training loss: 1.4413111209869385
Validation loss: 1.9638853355120587

Epoch: 5| Step: 1
Training loss: 1.2584235668182373
Validation loss: 1.9868006590873963

Epoch: 5| Step: 2
Training loss: 1.3431949615478516
Validation loss: 2.005949317768056

Epoch: 5| Step: 3
Training loss: 1.1988239288330078
Validation loss: 2.0340365081705074

Epoch: 5| Step: 4
Training loss: 0.6017552614212036
Validation loss: 2.056059052867274

Epoch: 5| Step: 5
Training loss: 1.566114902496338
Validation loss: 2.036181534490278

Epoch: 5| Step: 6
Training loss: 1.2450692653656006
Validation loss: 2.0098943428326677

Epoch: 5| Step: 7
Training loss: 1.3557852506637573
Validation loss: 2.008706772199241

Epoch: 5| Step: 8
Training loss: 1.4128555059432983
Validation loss: 1.9906451317571825

Epoch: 5| Step: 9
Training loss: 1.120905876159668
Validation loss: 1.9898834548970705

Epoch: 5| Step: 10
Training loss: 1.0608400106430054
Validation loss: 1.994883204019198

Epoch: 391| Step: 0
Training loss: 1.6260795593261719
Validation loss: 1.9808630481843026

Epoch: 5| Step: 1
Training loss: 1.3628660440444946
Validation loss: 1.9645404200400076

Epoch: 5| Step: 2
Training loss: 1.1667182445526123
Validation loss: 1.9786274022953485

Epoch: 5| Step: 3
Training loss: 0.7291504740715027
Validation loss: 1.962479140168877

Epoch: 5| Step: 4
Training loss: 1.0142462253570557
Validation loss: 1.9648840453035088

Epoch: 5| Step: 5
Training loss: 1.5184929370880127
Validation loss: 1.9743189375887635

Epoch: 5| Step: 6
Training loss: 1.50312077999115
Validation loss: 1.982440278094302

Epoch: 5| Step: 7
Training loss: 1.2416938543319702
Validation loss: 2.000096380069692

Epoch: 5| Step: 8
Training loss: 0.7256170511245728
Validation loss: 2.004429130144017

Epoch: 5| Step: 9
Training loss: 1.7038615942001343
Validation loss: 1.9956927350772324

Epoch: 5| Step: 10
Training loss: 1.1625126600265503
Validation loss: 2.046074387847736

Epoch: 392| Step: 0
Training loss: 1.4151285886764526
Validation loss: 2.0237347913044754

Epoch: 5| Step: 1
Training loss: 1.0296094417572021
Validation loss: 1.9872839579018213

Epoch: 5| Step: 2
Training loss: 1.1183706521987915
Validation loss: 1.9735188779010568

Epoch: 5| Step: 3
Training loss: 1.8593246936798096
Validation loss: 1.9205157256895495

Epoch: 5| Step: 4
Training loss: 1.0768311023712158
Validation loss: 1.906258947105818

Epoch: 5| Step: 5
Training loss: 1.3993713855743408
Validation loss: 1.9228900504368607

Epoch: 5| Step: 6
Training loss: 1.1604361534118652
Validation loss: 1.9261664754600936

Epoch: 5| Step: 7
Training loss: 1.059840440750122
Validation loss: 1.895723569777704

Epoch: 5| Step: 8
Training loss: 1.3364577293395996
Validation loss: 1.9385238565424436

Epoch: 5| Step: 9
Training loss: 0.8173137903213501
Validation loss: 1.953725371309506

Epoch: 5| Step: 10
Training loss: 1.394278883934021
Validation loss: 2.0201171123853294

Epoch: 393| Step: 0
Training loss: 1.1933475732803345
Validation loss: 2.054411870177074

Epoch: 5| Step: 1
Training loss: 1.545533537864685
Validation loss: 2.0809005037430794

Epoch: 5| Step: 2
Training loss: 1.0357013940811157
Validation loss: 2.0557816400322864

Epoch: 5| Step: 3
Training loss: 1.2463085651397705
Validation loss: 2.043724630468635

Epoch: 5| Step: 4
Training loss: 1.5895402431488037
Validation loss: 2.0074838566523727

Epoch: 5| Step: 5
Training loss: 0.8228216171264648
Validation loss: 1.9643961024540726

Epoch: 5| Step: 6
Training loss: 1.4547350406646729
Validation loss: 1.9419664875153573

Epoch: 5| Step: 7
Training loss: 1.0460362434387207
Validation loss: 1.9175744248974709

Epoch: 5| Step: 8
Training loss: 1.4703028202056885
Validation loss: 1.9667574000614945

Epoch: 5| Step: 9
Training loss: 1.3636620044708252
Validation loss: 1.9657291648208455

Epoch: 5| Step: 10
Training loss: 0.9530889987945557
Validation loss: 1.969990796940301

Epoch: 394| Step: 0
Training loss: 1.475106954574585
Validation loss: 1.9878592029694588

Epoch: 5| Step: 1
Training loss: 1.1450698375701904
Validation loss: 2.0125363539623957

Epoch: 5| Step: 2
Training loss: 0.9194231033325195
Validation loss: 2.0117702202130388

Epoch: 5| Step: 3
Training loss: 1.2804349660873413
Validation loss: 2.0380085258073706

Epoch: 5| Step: 4
Training loss: 1.363248586654663
Validation loss: 2.063850748923517

Epoch: 5| Step: 5
Training loss: 0.9968813061714172
Validation loss: 2.0472688392926286

Epoch: 5| Step: 6
Training loss: 1.6392667293548584
Validation loss: 2.0503397180188085

Epoch: 5| Step: 7
Training loss: 1.2431573867797852
Validation loss: 2.01817754519883

Epoch: 5| Step: 8
Training loss: 1.1902587413787842
Validation loss: 1.9817076203643635

Epoch: 5| Step: 9
Training loss: 1.1136411428451538
Validation loss: 1.9616331618319276

Epoch: 5| Step: 10
Training loss: 1.2017168998718262
Validation loss: 1.95718567345732

Epoch: 395| Step: 0
Training loss: 1.4564836025238037
Validation loss: 1.94228950495361

Epoch: 5| Step: 1
Training loss: 0.9226412773132324
Validation loss: 1.919666829929557

Epoch: 5| Step: 2
Training loss: 1.5736124515533447
Validation loss: 1.9393561578566028

Epoch: 5| Step: 3
Training loss: 1.1160730123519897
Validation loss: 1.9501967250659902

Epoch: 5| Step: 4
Training loss: 1.3969330787658691
Validation loss: 1.9505882545184063

Epoch: 5| Step: 5
Training loss: 1.0085347890853882
Validation loss: 1.9591612264674196

Epoch: 5| Step: 6
Training loss: 1.613135576248169
Validation loss: 1.9977670843883226

Epoch: 5| Step: 7
Training loss: 0.934967041015625
Validation loss: 1.9863829176913026

Epoch: 5| Step: 8
Training loss: 1.1329189538955688
Validation loss: 1.9727902386778144

Epoch: 5| Step: 9
Training loss: 1.2667948007583618
Validation loss: 2.0004061422040387

Epoch: 5| Step: 10
Training loss: 1.098560094833374
Validation loss: 2.0400862334876932

Epoch: 396| Step: 0
Training loss: 0.790623664855957
Validation loss: 2.05345889060728

Epoch: 5| Step: 1
Training loss: 1.2703264951705933
Validation loss: 2.0658962585592784

Epoch: 5| Step: 2
Training loss: 1.2658283710479736
Validation loss: 2.0700478246135097

Epoch: 5| Step: 3
Training loss: 1.4152538776397705
Validation loss: 2.0525167539555538

Epoch: 5| Step: 4
Training loss: 0.6784814596176147
Validation loss: 2.01434152613404

Epoch: 5| Step: 5
Training loss: 0.9687676429748535
Validation loss: 1.9968340768608996

Epoch: 5| Step: 6
Training loss: 1.0607373714447021
Validation loss: 1.9844257165026922

Epoch: 5| Step: 7
Training loss: 1.9979482889175415
Validation loss: 1.9998403390248616

Epoch: 5| Step: 8
Training loss: 1.4084794521331787
Validation loss: 1.9781718254089355

Epoch: 5| Step: 9
Training loss: 1.7726738452911377
Validation loss: 1.9880594643213416

Epoch: 5| Step: 10
Training loss: 1.0529093742370605
Validation loss: 1.961971208613406

Epoch: 397| Step: 0
Training loss: 1.3001480102539062
Validation loss: 1.9604526053192795

Epoch: 5| Step: 1
Training loss: 0.9628399014472961
Validation loss: 1.93927417519272

Epoch: 5| Step: 2
Training loss: 1.3069835901260376
Validation loss: 1.9416896630358953

Epoch: 5| Step: 3
Training loss: 0.6192939877510071
Validation loss: 1.9577094201118714

Epoch: 5| Step: 4
Training loss: 1.3379976749420166
Validation loss: 1.9442495774197321

Epoch: 5| Step: 5
Training loss: 1.0899654626846313
Validation loss: 1.9900979470181208

Epoch: 5| Step: 6
Training loss: 1.4097360372543335
Validation loss: 1.985610883723023

Epoch: 5| Step: 7
Training loss: 1.6287739276885986
Validation loss: 2.024632559027723

Epoch: 5| Step: 8
Training loss: 1.5074381828308105
Validation loss: 2.0257944471092633

Epoch: 5| Step: 9
Training loss: 0.9892389178276062
Validation loss: 2.0417607317688646

Epoch: 5| Step: 10
Training loss: 1.3990249633789062
Validation loss: 1.9852171380032775

Epoch: 398| Step: 0
Training loss: 1.0926592350006104
Validation loss: 1.969684362411499

Epoch: 5| Step: 1
Training loss: 1.3535706996917725
Validation loss: 1.9576824993215582

Epoch: 5| Step: 2
Training loss: 1.1314060688018799
Validation loss: 1.973075694935296

Epoch: 5| Step: 3
Training loss: 1.2220118045806885
Validation loss: 1.9660749871243712

Epoch: 5| Step: 4
Training loss: 1.2601693868637085
Validation loss: 1.9555226884862429

Epoch: 5| Step: 5
Training loss: 1.00346839427948
Validation loss: 1.948137176934109

Epoch: 5| Step: 6
Training loss: 1.6956555843353271
Validation loss: 1.9519530868017545

Epoch: 5| Step: 7
Training loss: 0.9404069185256958
Validation loss: 1.928167155993882

Epoch: 5| Step: 8
Training loss: 1.1538946628570557
Validation loss: 1.9325934122967463

Epoch: 5| Step: 9
Training loss: 1.1803165674209595
Validation loss: 1.9451830605024933

Epoch: 5| Step: 10
Training loss: 1.448630690574646
Validation loss: 1.9589190688184512

Epoch: 399| Step: 0
Training loss: 1.1471526622772217
Validation loss: 1.9718017821670861

Epoch: 5| Step: 1
Training loss: 0.9564501643180847
Validation loss: 2.0065773635782223

Epoch: 5| Step: 2
Training loss: 1.5943492650985718
Validation loss: 2.0172407588651105

Epoch: 5| Step: 3
Training loss: 1.112008810043335
Validation loss: 2.0182923475901284

Epoch: 5| Step: 4
Training loss: 1.149762511253357
Validation loss: 1.9804098119017899

Epoch: 5| Step: 5
Training loss: 1.2218605279922485
Validation loss: 1.9911392106804797

Epoch: 5| Step: 6
Training loss: 0.9568303227424622
Validation loss: 1.970282507199113

Epoch: 5| Step: 7
Training loss: 1.0992283821105957
Validation loss: 1.9538679456198087

Epoch: 5| Step: 8
Training loss: 1.2268571853637695
Validation loss: 1.94631826877594

Epoch: 5| Step: 9
Training loss: 1.4257380962371826
Validation loss: 1.9274380771062707

Epoch: 5| Step: 10
Training loss: 1.37667977809906
Validation loss: 1.9454502315931423

Epoch: 400| Step: 0
Training loss: 0.8253390192985535
Validation loss: 1.9357330722193564

Epoch: 5| Step: 1
Training loss: 1.1334426403045654
Validation loss: 1.961737294350901

Epoch: 5| Step: 2
Training loss: 0.8468745946884155
Validation loss: 1.9368793913113174

Epoch: 5| Step: 3
Training loss: 1.5434138774871826
Validation loss: 1.9795926206855363

Epoch: 5| Step: 4
Training loss: 1.11850905418396
Validation loss: 1.968813891051918

Epoch: 5| Step: 5
Training loss: 1.3845657110214233
Validation loss: 1.979793297347202

Epoch: 5| Step: 6
Training loss: 1.4643999338150024
Validation loss: 2.0194390127735753

Epoch: 5| Step: 7
Training loss: 1.4006032943725586
Validation loss: 2.0297366419146137

Epoch: 5| Step: 8
Training loss: 0.7648167014122009
Validation loss: 2.017292659769776

Epoch: 5| Step: 9
Training loss: 1.7067779302597046
Validation loss: 1.9809863234079013

Epoch: 5| Step: 10
Training loss: 1.0165671110153198
Validation loss: 1.986003029731012

Epoch: 401| Step: 0
Training loss: 1.542401671409607
Validation loss: 1.9846136031612274

Epoch: 5| Step: 1
Training loss: 1.5985099077224731
Validation loss: 1.97487170978259

Epoch: 5| Step: 2
Training loss: 0.6967561841011047
Validation loss: 1.953926629917596

Epoch: 5| Step: 3
Training loss: 1.305294156074524
Validation loss: 1.9684358348128617

Epoch: 5| Step: 4
Training loss: 0.9974093437194824
Validation loss: 1.9604093695199618

Epoch: 5| Step: 5
Training loss: 1.0093421936035156
Validation loss: 2.0009288851932814

Epoch: 5| Step: 6
Training loss: 1.2220537662506104
Validation loss: 2.0019518149796354

Epoch: 5| Step: 7
Training loss: 0.9613435864448547
Validation loss: 2.013291901157748

Epoch: 5| Step: 8
Training loss: 1.6093581914901733
Validation loss: 2.0479860151967695

Epoch: 5| Step: 9
Training loss: 0.9943479299545288
Validation loss: 2.015537392708563

Epoch: 5| Step: 10
Training loss: 1.1926865577697754
Validation loss: 1.9902523320208314

Epoch: 402| Step: 0
Training loss: 1.194109559059143
Validation loss: 1.9786110231953282

Epoch: 5| Step: 1
Training loss: 1.3202106952667236
Validation loss: 1.9731302415170977

Epoch: 5| Step: 2
Training loss: 1.1819404363632202
Validation loss: 1.960501652891918

Epoch: 5| Step: 3
Training loss: 1.0798197984695435
Validation loss: 1.9434029235634753

Epoch: 5| Step: 4
Training loss: 1.4975545406341553
Validation loss: 1.9283716729892197

Epoch: 5| Step: 5
Training loss: 1.1516673564910889
Validation loss: 1.9295383191877795

Epoch: 5| Step: 6
Training loss: 1.303082823753357
Validation loss: 1.9396018879387968

Epoch: 5| Step: 7
Training loss: 0.8752694129943848
Validation loss: 1.9429993244909471

Epoch: 5| Step: 8
Training loss: 1.2149341106414795
Validation loss: 1.9648230332200245

Epoch: 5| Step: 9
Training loss: 1.1112473011016846
Validation loss: 2.017780516737251

Epoch: 5| Step: 10
Training loss: 1.278803825378418
Validation loss: 2.036590906881517

Epoch: 403| Step: 0
Training loss: 1.1846283674240112
Validation loss: 2.055123035625745

Epoch: 5| Step: 1
Training loss: 1.3190780878067017
Validation loss: 2.0700860343953615

Epoch: 5| Step: 2
Training loss: 0.7112442255020142
Validation loss: 2.042281581509498

Epoch: 5| Step: 3
Training loss: 1.2305339574813843
Validation loss: 1.9846651746380715

Epoch: 5| Step: 4
Training loss: 0.8473577499389648
Validation loss: 1.9128731604545348

Epoch: 5| Step: 5
Training loss: 1.4485969543457031
Validation loss: 1.918431141043222

Epoch: 5| Step: 6
Training loss: 1.7747688293457031
Validation loss: 1.8827340513147333

Epoch: 5| Step: 7
Training loss: 1.6391212940216064
Validation loss: 1.9032825693007438

Epoch: 5| Step: 8
Training loss: 1.2395814657211304
Validation loss: 1.9218173437221076

Epoch: 5| Step: 9
Training loss: 0.6086874604225159
Validation loss: 1.9268324516152824

Epoch: 5| Step: 10
Training loss: 1.3675737380981445
Validation loss: 1.9170067053969189

Epoch: 404| Step: 0
Training loss: 0.9017128944396973
Validation loss: 1.9575528149963708

Epoch: 5| Step: 1
Training loss: 1.6791232824325562
Validation loss: 1.9332097935420212

Epoch: 5| Step: 2
Training loss: 0.4163143038749695
Validation loss: 1.9979296948320122

Epoch: 5| Step: 3
Training loss: 0.8707367181777954
Validation loss: 1.9890175839906097

Epoch: 5| Step: 4
Training loss: 1.8974345922470093
Validation loss: 1.9914563881453646

Epoch: 5| Step: 5
Training loss: 0.66644287109375
Validation loss: 1.997594210409349

Epoch: 5| Step: 6
Training loss: 0.984941303730011
Validation loss: 1.9471604747156943

Epoch: 5| Step: 7
Training loss: 1.3153066635131836
Validation loss: 1.9525960183912707

Epoch: 5| Step: 8
Training loss: 1.0857815742492676
Validation loss: 1.954765982525323

Epoch: 5| Step: 9
Training loss: 1.7049190998077393
Validation loss: 1.9600308505437707

Epoch: 5| Step: 10
Training loss: 1.5718897581100464
Validation loss: 1.948604755504157

Epoch: 405| Step: 0
Training loss: 0.6974173784255981
Validation loss: 1.9534089590913506

Epoch: 5| Step: 1
Training loss: 1.3560609817504883
Validation loss: 1.9565681885647517

Epoch: 5| Step: 2
Training loss: 1.6388800144195557
Validation loss: 1.9383288762902702

Epoch: 5| Step: 3
Training loss: 0.9053980112075806
Validation loss: 1.950944128856864

Epoch: 5| Step: 4
Training loss: 1.1670277118682861
Validation loss: 1.9505812916704404

Epoch: 5| Step: 5
Training loss: 0.9494169354438782
Validation loss: 1.9232800634958411

Epoch: 5| Step: 6
Training loss: 1.1727054119110107
Validation loss: 1.9584456848841842

Epoch: 5| Step: 7
Training loss: 1.6544115543365479
Validation loss: 1.948162950495238

Epoch: 5| Step: 8
Training loss: 1.1323970556259155
Validation loss: 1.9506582085804274

Epoch: 5| Step: 9
Training loss: 0.916226863861084
Validation loss: 1.979251620590046

Epoch: 5| Step: 10
Training loss: 1.2944904565811157
Validation loss: 1.9653483565135668

Epoch: 406| Step: 0
Training loss: 1.2737032175064087
Validation loss: 1.97940242931407

Epoch: 5| Step: 1
Training loss: 0.9217273592948914
Validation loss: 1.9778648832792878

Epoch: 5| Step: 2
Training loss: 0.8248018026351929
Validation loss: 1.9893247645388368

Epoch: 5| Step: 3
Training loss: 2.0628862380981445
Validation loss: 1.9644281325801727

Epoch: 5| Step: 4
Training loss: 1.173134207725525
Validation loss: 1.969359601697614

Epoch: 5| Step: 5
Training loss: 0.8079551458358765
Validation loss: 1.9631984144128778

Epoch: 5| Step: 6
Training loss: 1.1472609043121338
Validation loss: 1.9664610752495386

Epoch: 5| Step: 7
Training loss: 0.9822870492935181
Validation loss: 1.9569986661275227

Epoch: 5| Step: 8
Training loss: 1.3205502033233643
Validation loss: 1.9433332643201273

Epoch: 5| Step: 9
Training loss: 1.281325101852417
Validation loss: 1.9582388477940713

Epoch: 5| Step: 10
Training loss: 0.8606430292129517
Validation loss: 1.9587406464802322

Epoch: 407| Step: 0
Training loss: 1.319749355316162
Validation loss: 1.9450166122887724

Epoch: 5| Step: 1
Training loss: 1.0720466375350952
Validation loss: 1.940199387970791

Epoch: 5| Step: 2
Training loss: 1.6286404132843018
Validation loss: 1.9326114475086171

Epoch: 5| Step: 3
Training loss: 1.4154846668243408
Validation loss: 1.9351956113692252

Epoch: 5| Step: 4
Training loss: 1.3003313541412354
Validation loss: 1.9275799797427269

Epoch: 5| Step: 5
Training loss: 1.0350990295410156
Validation loss: 1.9421613139490927

Epoch: 5| Step: 6
Training loss: 1.4245938062667847
Validation loss: 1.9030945390783331

Epoch: 5| Step: 7
Training loss: 1.3146179914474487
Validation loss: 1.9157061269206386

Epoch: 5| Step: 8
Training loss: 0.9166005849838257
Validation loss: 1.9146694201295094

Epoch: 5| Step: 9
Training loss: 0.7035297751426697
Validation loss: 1.9520397801553049

Epoch: 5| Step: 10
Training loss: 0.5318752527236938
Validation loss: 1.9710510776888939

Epoch: 408| Step: 0
Training loss: 1.6225143671035767
Validation loss: 1.9964295856414302

Epoch: 5| Step: 1
Training loss: 0.884621798992157
Validation loss: 2.0121312064509236

Epoch: 5| Step: 2
Training loss: 0.9341018795967102
Validation loss: 2.0356054318848478

Epoch: 5| Step: 3
Training loss: 1.3727365732192993
Validation loss: 2.0021398477656867

Epoch: 5| Step: 4
Training loss: 0.8531376123428345
Validation loss: 2.0048774301364856

Epoch: 5| Step: 5
Training loss: 1.139193058013916
Validation loss: 1.9631790217532907

Epoch: 5| Step: 6
Training loss: 1.2776483297348022
Validation loss: 1.9197320066472536

Epoch: 5| Step: 7
Training loss: 1.3704890012741089
Validation loss: 1.896568795686127

Epoch: 5| Step: 8
Training loss: 1.064087986946106
Validation loss: 1.8875122301040157

Epoch: 5| Step: 9
Training loss: 1.3636994361877441
Validation loss: 1.8747661600830734

Epoch: 5| Step: 10
Training loss: 0.9979488253593445
Validation loss: 1.907591373689713

Epoch: 409| Step: 0
Training loss: 1.3901431560516357
Validation loss: 1.8957173798673896

Epoch: 5| Step: 1
Training loss: 0.9516922235488892
Validation loss: 1.8880030685855496

Epoch: 5| Step: 2
Training loss: 1.2995113134384155
Validation loss: 1.9078597522551013

Epoch: 5| Step: 3
Training loss: 1.0961031913757324
Validation loss: 1.9701431746123939

Epoch: 5| Step: 4
Training loss: 0.995530903339386
Validation loss: 1.9976003131558817

Epoch: 5| Step: 5
Training loss: 1.429944396018982
Validation loss: 2.00991004384974

Epoch: 5| Step: 6
Training loss: 1.2251935005187988
Validation loss: 1.983927922864114

Epoch: 5| Step: 7
Training loss: 0.8545495271682739
Validation loss: 1.959044268695257

Epoch: 5| Step: 8
Training loss: 1.2602084875106812
Validation loss: 1.9342228430573658

Epoch: 5| Step: 9
Training loss: 1.3141512870788574
Validation loss: 1.9393870420353387

Epoch: 5| Step: 10
Training loss: 1.0124698877334595
Validation loss: 1.915015310369512

Epoch: 410| Step: 0
Training loss: 1.1269419193267822
Validation loss: 1.9182621086797407

Epoch: 5| Step: 1
Training loss: 0.9752640724182129
Validation loss: 1.947657750498864

Epoch: 5| Step: 2
Training loss: 0.7818952798843384
Validation loss: 1.9391292884785643

Epoch: 5| Step: 3
Training loss: 1.2613670825958252
Validation loss: 1.9496910546415596

Epoch: 5| Step: 4
Training loss: 1.5371654033660889
Validation loss: 1.953929796013781

Epoch: 5| Step: 5
Training loss: 1.0677618980407715
Validation loss: 1.9686389853877406

Epoch: 5| Step: 6
Training loss: 1.4801579713821411
Validation loss: 1.9725006985408005

Epoch: 5| Step: 7
Training loss: 1.4313238859176636
Validation loss: 1.9776101291820567

Epoch: 5| Step: 8
Training loss: 0.779191792011261
Validation loss: 1.9950113693873088

Epoch: 5| Step: 9
Training loss: 0.5416402816772461
Validation loss: 2.0124023447754564

Epoch: 5| Step: 10
Training loss: 1.8657392263412476
Validation loss: 2.043867767498057

Epoch: 411| Step: 0
Training loss: 0.711381196975708
Validation loss: 2.0523683217263993

Epoch: 5| Step: 1
Training loss: 1.7840197086334229
Validation loss: 2.0609170698350474

Epoch: 5| Step: 2
Training loss: 1.2577104568481445
Validation loss: 2.0398149644174883

Epoch: 5| Step: 3
Training loss: 1.3490396738052368
Validation loss: 2.020753663073304

Epoch: 5| Step: 4
Training loss: 1.372832179069519
Validation loss: 2.003699864110639

Epoch: 5| Step: 5
Training loss: 1.0038728713989258
Validation loss: 1.9579554168126916

Epoch: 5| Step: 6
Training loss: 0.6656266450881958
Validation loss: 1.939059874062897

Epoch: 5| Step: 7
Training loss: 1.1422488689422607
Validation loss: 1.9143119627429592

Epoch: 5| Step: 8
Training loss: 1.1492106914520264
Validation loss: 1.8934343066266788

Epoch: 5| Step: 9
Training loss: 1.274572730064392
Validation loss: 1.91650527779774

Epoch: 5| Step: 10
Training loss: 1.2308350801467896
Validation loss: 1.927750277262862

Epoch: 412| Step: 0
Training loss: 1.5243555307388306
Validation loss: 1.9271747450674734

Epoch: 5| Step: 1
Training loss: 0.6942970156669617
Validation loss: 1.9117664419194704

Epoch: 5| Step: 2
Training loss: 1.5117995738983154
Validation loss: 1.9175401221039474

Epoch: 5| Step: 3
Training loss: 1.0518052577972412
Validation loss: 1.9269841153134581

Epoch: 5| Step: 4
Training loss: 1.1731284856796265
Validation loss: 1.9522357986819359

Epoch: 5| Step: 5
Training loss: 0.8642069697380066
Validation loss: 1.9615664071934198

Epoch: 5| Step: 6
Training loss: 1.569493055343628
Validation loss: 2.0052271632738012

Epoch: 5| Step: 7
Training loss: 0.9047770500183105
Validation loss: 1.997527858262421

Epoch: 5| Step: 8
Training loss: 0.9166268110275269
Validation loss: 2.0140814512006697

Epoch: 5| Step: 9
Training loss: 0.9525488018989563
Validation loss: 2.0252244139230378

Epoch: 5| Step: 10
Training loss: 1.5349451303482056
Validation loss: 2.039002905609787

Epoch: 413| Step: 0
Training loss: 1.0958712100982666
Validation loss: 1.9919015053779847

Epoch: 5| Step: 1
Training loss: 1.632899522781372
Validation loss: 1.9770207520454162

Epoch: 5| Step: 2
Training loss: 1.1536635160446167
Validation loss: 1.9380562689996534

Epoch: 5| Step: 3
Training loss: 1.3298461437225342
Validation loss: 1.9173179134245841

Epoch: 5| Step: 4
Training loss: 1.1506025791168213
Validation loss: 1.904228356576735

Epoch: 5| Step: 5
Training loss: 0.9447506070137024
Validation loss: 1.9064695142930554

Epoch: 5| Step: 6
Training loss: 1.3058340549468994
Validation loss: 1.9245427193180207

Epoch: 5| Step: 7
Training loss: 0.632215678691864
Validation loss: 1.9164171923873246

Epoch: 5| Step: 8
Training loss: 1.4080145359039307
Validation loss: 1.9182652094030892

Epoch: 5| Step: 9
Training loss: 0.9827951192855835
Validation loss: 1.9208168957823066

Epoch: 5| Step: 10
Training loss: 0.8066843152046204
Validation loss: 1.943915795254451

Epoch: 414| Step: 0
Training loss: 1.011985182762146
Validation loss: 1.9685343619315856

Epoch: 5| Step: 1
Training loss: 1.7008339166641235
Validation loss: 1.9769171899364841

Epoch: 5| Step: 2
Training loss: 1.1182756423950195
Validation loss: 1.9738756982229089

Epoch: 5| Step: 3
Training loss: 0.9184536933898926
Validation loss: 1.9614863280327088

Epoch: 5| Step: 4
Training loss: 1.1910566091537476
Validation loss: 1.9604423635749406

Epoch: 5| Step: 5
Training loss: 1.4664055109024048
Validation loss: 1.9720744804669452

Epoch: 5| Step: 6
Training loss: 0.9965871572494507
Validation loss: 1.979027686580535

Epoch: 5| Step: 7
Training loss: 0.8262866735458374
Validation loss: 1.976588656825404

Epoch: 5| Step: 8
Training loss: 0.9739812612533569
Validation loss: 1.949256315026232

Epoch: 5| Step: 9
Training loss: 0.8252445459365845
Validation loss: 1.9504133193723616

Epoch: 5| Step: 10
Training loss: 1.4053739309310913
Validation loss: 1.9367565967703377

Epoch: 415| Step: 0
Training loss: 1.0422574281692505
Validation loss: 1.9231112477599934

Epoch: 5| Step: 1
Training loss: 0.7442271113395691
Validation loss: 1.9428822878868348

Epoch: 5| Step: 2
Training loss: 1.3294289112091064
Validation loss: 1.9532594168058006

Epoch: 5| Step: 3
Training loss: 1.5881459712982178
Validation loss: 1.9733250153962003

Epoch: 5| Step: 4
Training loss: 1.391719102859497
Validation loss: 1.9750581274750412

Epoch: 5| Step: 5
Training loss: 0.960859477519989
Validation loss: 1.9819355677532893

Epoch: 5| Step: 6
Training loss: 1.0837984085083008
Validation loss: 1.9770265548459944

Epoch: 5| Step: 7
Training loss: 1.133812427520752
Validation loss: 1.9274864440323205

Epoch: 5| Step: 8
Training loss: 0.8960837125778198
Validation loss: 1.9445291514037757

Epoch: 5| Step: 9
Training loss: 0.927369236946106
Validation loss: 1.9269706074909498

Epoch: 5| Step: 10
Training loss: 1.5079134702682495
Validation loss: 1.9273099104563396

Epoch: 416| Step: 0
Training loss: 0.6177165508270264
Validation loss: 1.9308904422226774

Epoch: 5| Step: 1
Training loss: 0.7757188081741333
Validation loss: 1.9272888770667456

Epoch: 5| Step: 2
Training loss: 1.0625981092453003
Validation loss: 1.9216473294842629

Epoch: 5| Step: 3
Training loss: 1.589176058769226
Validation loss: 1.9281027265774306

Epoch: 5| Step: 4
Training loss: 1.5539498329162598
Validation loss: 1.9676207034818587

Epoch: 5| Step: 5
Training loss: 1.5103412866592407
Validation loss: 1.969297089884358

Epoch: 5| Step: 6
Training loss: 1.2985728979110718
Validation loss: 1.990710461011497

Epoch: 5| Step: 7
Training loss: 0.7108267545700073
Validation loss: 1.994542711524553

Epoch: 5| Step: 8
Training loss: 1.5870815515518188
Validation loss: 2.0021808839613393

Epoch: 5| Step: 9
Training loss: 0.7176912426948547
Validation loss: 2.0100589900888424

Epoch: 5| Step: 10
Training loss: 0.8382315039634705
Validation loss: 1.988430764085503

Epoch: 417| Step: 0
Training loss: 1.1013809442520142
Validation loss: 2.0179829520563923

Epoch: 5| Step: 1
Training loss: 1.2620681524276733
Validation loss: 2.0062937608329197

Epoch: 5| Step: 2
Training loss: 1.0545501708984375
Validation loss: 1.9937654079929474

Epoch: 5| Step: 3
Training loss: 1.1214555501937866
Validation loss: 2.001757800579071

Epoch: 5| Step: 4
Training loss: 0.8502472639083862
Validation loss: 1.977055145848182

Epoch: 5| Step: 5
Training loss: 0.8467699289321899
Validation loss: 1.9972940260364163

Epoch: 5| Step: 6
Training loss: 1.146058440208435
Validation loss: 1.9674787034270584

Epoch: 5| Step: 7
Training loss: 1.21103835105896
Validation loss: 1.957444021778722

Epoch: 5| Step: 8
Training loss: 1.1540837287902832
Validation loss: 1.9337312316381803

Epoch: 5| Step: 9
Training loss: 0.92852783203125
Validation loss: 1.933628930840441

Epoch: 5| Step: 10
Training loss: 1.7801215648651123
Validation loss: 1.927279262132542

Epoch: 418| Step: 0
Training loss: 1.4893293380737305
Validation loss: 1.895927236926171

Epoch: 5| Step: 1
Training loss: 1.2654377222061157
Validation loss: 1.9319642179755754

Epoch: 5| Step: 2
Training loss: 1.5701984167099
Validation loss: 1.940244915664837

Epoch: 5| Step: 3
Training loss: 1.1999866962432861
Validation loss: 1.9478231758199713

Epoch: 5| Step: 4
Training loss: 0.8477312922477722
Validation loss: 1.926200682117093

Epoch: 5| Step: 5
Training loss: 1.4045740365982056
Validation loss: 1.975283694523637

Epoch: 5| Step: 6
Training loss: 1.0115578174591064
Validation loss: 1.9786989714509697

Epoch: 5| Step: 7
Training loss: 0.9486160278320312
Validation loss: 1.9848272108262586

Epoch: 5| Step: 8
Training loss: 0.49570417404174805
Validation loss: 1.9927021303484518

Epoch: 5| Step: 9
Training loss: 1.0193744897842407
Validation loss: 2.0157038473313853

Epoch: 5| Step: 10
Training loss: 0.9838380217552185
Validation loss: 2.040889411844233

Epoch: 419| Step: 0
Training loss: 1.598711609840393
Validation loss: 2.0369134833735805

Epoch: 5| Step: 1
Training loss: 1.2546080350875854
Validation loss: 2.023995339229543

Epoch: 5| Step: 2
Training loss: 0.5841723084449768
Validation loss: 2.0263101977686726

Epoch: 5| Step: 3
Training loss: 0.9300644993782043
Validation loss: 1.9858356496339202

Epoch: 5| Step: 4
Training loss: 0.9161819219589233
Validation loss: 1.9804526811004968

Epoch: 5| Step: 5
Training loss: 1.2964731454849243
Validation loss: 1.9520686031669698

Epoch: 5| Step: 6
Training loss: 1.2965030670166016
Validation loss: 1.9522948341984903

Epoch: 5| Step: 7
Training loss: 1.178318738937378
Validation loss: 1.9148432823919481

Epoch: 5| Step: 8
Training loss: 1.251051664352417
Validation loss: 1.9366759459177654

Epoch: 5| Step: 9
Training loss: 0.9711496233940125
Validation loss: 1.9198261486586703

Epoch: 5| Step: 10
Training loss: 0.9932160377502441
Validation loss: 1.9070281174875074

Epoch: 420| Step: 0
Training loss: 1.4946925640106201
Validation loss: 1.9449836836066297

Epoch: 5| Step: 1
Training loss: 0.9104445576667786
Validation loss: 1.9741969852037327

Epoch: 5| Step: 2
Training loss: 1.364280104637146
Validation loss: 1.9686586459477742

Epoch: 5| Step: 3
Training loss: 0.9049043655395508
Validation loss: 1.9635532004858858

Epoch: 5| Step: 4
Training loss: 1.270738959312439
Validation loss: 1.9835879687340028

Epoch: 5| Step: 5
Training loss: 1.2239763736724854
Validation loss: 1.9472941301202262

Epoch: 5| Step: 6
Training loss: 1.0585696697235107
Validation loss: 1.9432277448715702

Epoch: 5| Step: 7
Training loss: 1.0043987035751343
Validation loss: 1.9314121354010798

Epoch: 5| Step: 8
Training loss: 0.7790199518203735
Validation loss: 1.9236563969683904

Epoch: 5| Step: 9
Training loss: 1.3105719089508057
Validation loss: 1.938788947238717

Epoch: 5| Step: 10
Training loss: 0.703298032283783
Validation loss: 1.955335872147673

Epoch: 421| Step: 0
Training loss: 0.9336773157119751
Validation loss: 1.9940866270372946

Epoch: 5| Step: 1
Training loss: 1.1994000673294067
Validation loss: 1.9712919317265993

Epoch: 5| Step: 2
Training loss: 1.2411174774169922
Validation loss: 2.000941759796553

Epoch: 5| Step: 3
Training loss: 0.8862975239753723
Validation loss: 1.9917357801109232

Epoch: 5| Step: 4
Training loss: 1.061108946800232
Validation loss: 2.005708872631032

Epoch: 5| Step: 5
Training loss: 1.2995331287384033
Validation loss: 1.9675779804106681

Epoch: 5| Step: 6
Training loss: 0.9557545781135559
Validation loss: 1.940457328673332

Epoch: 5| Step: 7
Training loss: 1.019622564315796
Validation loss: 1.912636645378605

Epoch: 5| Step: 8
Training loss: 1.0573451519012451
Validation loss: 1.9104354176470029

Epoch: 5| Step: 9
Training loss: 1.4636160135269165
Validation loss: 1.9236929814020793

Epoch: 5| Step: 10
Training loss: 0.9287755489349365
Validation loss: 1.8793302312974007

Epoch: 422| Step: 0
Training loss: 1.3503448963165283
Validation loss: 1.9082614708972234

Epoch: 5| Step: 1
Training loss: 0.983620822429657
Validation loss: 1.8879767579417075

Epoch: 5| Step: 2
Training loss: 1.0848214626312256
Validation loss: 1.9135013639286

Epoch: 5| Step: 3
Training loss: 1.356467604637146
Validation loss: 1.9518886663580453

Epoch: 5| Step: 4
Training loss: 0.8611370921134949
Validation loss: 1.9661940336227417

Epoch: 5| Step: 5
Training loss: 0.646242618560791
Validation loss: 2.006661158736034

Epoch: 5| Step: 6
Training loss: 1.1869430541992188
Validation loss: 2.0219689107710317

Epoch: 5| Step: 7
Training loss: 1.4982445240020752
Validation loss: 2.000822679970854

Epoch: 5| Step: 8
Training loss: 0.9486897587776184
Validation loss: 1.9600951645963935

Epoch: 5| Step: 9
Training loss: 1.1153029203414917
Validation loss: 1.957341686371834

Epoch: 5| Step: 10
Training loss: 0.9898416996002197
Validation loss: 1.9557583165425125

Epoch: 423| Step: 0
Training loss: 0.8434215784072876
Validation loss: 1.9546279548316874

Epoch: 5| Step: 1
Training loss: 0.7633872032165527
Validation loss: 1.9456905767481814

Epoch: 5| Step: 2
Training loss: 0.9938262701034546
Validation loss: 1.9618551808018838

Epoch: 5| Step: 3
Training loss: 1.7191003561019897
Validation loss: 1.96033065806153

Epoch: 5| Step: 4
Training loss: 1.1748899221420288
Validation loss: 1.9505054976350518

Epoch: 5| Step: 5
Training loss: 1.3822826147079468
Validation loss: 1.9295799552753408

Epoch: 5| Step: 6
Training loss: 1.0213968753814697
Validation loss: 1.953081920582761

Epoch: 5| Step: 7
Training loss: 1.300179123878479
Validation loss: 1.9618731083408478

Epoch: 5| Step: 8
Training loss: 1.149362325668335
Validation loss: 1.9989968653648131

Epoch: 5| Step: 9
Training loss: 0.8624273538589478
Validation loss: 2.020805046122561

Epoch: 5| Step: 10
Training loss: 0.8541026711463928
Validation loss: 2.0314798073102067

Epoch: 424| Step: 0
Training loss: 1.4907866716384888
Validation loss: 2.0298266474918654

Epoch: 5| Step: 1
Training loss: 0.863974928855896
Validation loss: 1.996334916801863

Epoch: 5| Step: 2
Training loss: 0.9692880511283875
Validation loss: 1.9547924367330407

Epoch: 5| Step: 3
Training loss: 1.121577501296997
Validation loss: 1.9587203430873092

Epoch: 5| Step: 4
Training loss: 0.6580458879470825
Validation loss: 1.9353804601136075

Epoch: 5| Step: 5
Training loss: 1.222110390663147
Validation loss: 1.9336281514936877

Epoch: 5| Step: 6
Training loss: 1.070770502090454
Validation loss: 1.9245850347703504

Epoch: 5| Step: 7
Training loss: 1.289960265159607
Validation loss: 1.9522850128912157

Epoch: 5| Step: 8
Training loss: 1.0818735361099243
Validation loss: 1.976024373885124

Epoch: 5| Step: 9
Training loss: 1.0883307456970215
Validation loss: 1.9708776730363087

Epoch: 5| Step: 10
Training loss: 1.1312437057495117
Validation loss: 1.9722827224321262

Epoch: 425| Step: 0
Training loss: 1.052834153175354
Validation loss: 1.9759703387496292

Epoch: 5| Step: 1
Training loss: 0.7441931962966919
Validation loss: 1.9921507117568806

Epoch: 5| Step: 2
Training loss: 0.8013981580734253
Validation loss: 1.987589825866043

Epoch: 5| Step: 3
Training loss: 0.7599666714668274
Validation loss: 1.9837670864597443

Epoch: 5| Step: 4
Training loss: 0.9722340703010559
Validation loss: 1.9848726872474916

Epoch: 5| Step: 5
Training loss: 1.3086702823638916
Validation loss: 1.9729289982908516

Epoch: 5| Step: 6
Training loss: 1.273930311203003
Validation loss: 1.9739760544992262

Epoch: 5| Step: 7
Training loss: 1.5072277784347534
Validation loss: 1.9682795181069324

Epoch: 5| Step: 8
Training loss: 1.1138399839401245
Validation loss: 1.9439431544273131

Epoch: 5| Step: 9
Training loss: 1.0675028562545776
Validation loss: 1.9004860437044533

Epoch: 5| Step: 10
Training loss: 1.0554016828536987
Validation loss: 1.8951694221906765

Epoch: 426| Step: 0
Training loss: 0.934975802898407
Validation loss: 1.9084992818934943

Epoch: 5| Step: 1
Training loss: 0.47329553961753845
Validation loss: 1.8933714923038278

Epoch: 5| Step: 2
Training loss: 1.6294981241226196
Validation loss: 1.9280085679023498

Epoch: 5| Step: 3
Training loss: 1.198241949081421
Validation loss: 1.9512346713773665

Epoch: 5| Step: 4
Training loss: 1.4533427953720093
Validation loss: 1.9796596483517719

Epoch: 5| Step: 5
Training loss: 0.8717487454414368
Validation loss: 2.003309489578329

Epoch: 5| Step: 6
Training loss: 0.9602425694465637
Validation loss: 2.0166008498079036

Epoch: 5| Step: 7
Training loss: 1.3047603368759155
Validation loss: 2.009287561139753

Epoch: 5| Step: 8
Training loss: 0.9483343958854675
Validation loss: 1.9867571989695232

Epoch: 5| Step: 9
Training loss: 0.9289789199829102
Validation loss: 1.966872707489998

Epoch: 5| Step: 10
Training loss: 0.8996190428733826
Validation loss: 1.978818948550891

Epoch: 427| Step: 0
Training loss: 0.8551746606826782
Validation loss: 1.9305311915695027

Epoch: 5| Step: 1
Training loss: 1.060967206954956
Validation loss: 1.9043544184777044

Epoch: 5| Step: 2
Training loss: 1.4481995105743408
Validation loss: 1.9253193422030377

Epoch: 5| Step: 3
Training loss: 0.40618592500686646
Validation loss: 1.941331854430578

Epoch: 5| Step: 4
Training loss: 0.8261464238166809
Validation loss: 1.9375114312735937

Epoch: 5| Step: 5
Training loss: 1.2025294303894043
Validation loss: 1.9584113090269026

Epoch: 5| Step: 6
Training loss: 1.1066997051239014
Validation loss: 1.9350426171415596

Epoch: 5| Step: 7
Training loss: 1.0267667770385742
Validation loss: 1.9467479977556454

Epoch: 5| Step: 8
Training loss: 1.1453039646148682
Validation loss: 1.9273252641001055

Epoch: 5| Step: 9
Training loss: 1.4475752115249634
Validation loss: 1.9321881032759143

Epoch: 5| Step: 10
Training loss: 1.5890610218048096
Validation loss: 1.8968352502392185

Epoch: 428| Step: 0
Training loss: 0.768889844417572
Validation loss: 1.9509042347631147

Epoch: 5| Step: 1
Training loss: 0.9054650068283081
Validation loss: 1.9530249000877462

Epoch: 5| Step: 2
Training loss: 1.5476667881011963
Validation loss: 1.9670637640901791

Epoch: 5| Step: 3
Training loss: 1.1766506433486938
Validation loss: 1.990513857974801

Epoch: 5| Step: 4
Training loss: 1.1451212167739868
Validation loss: 2.014977039829377

Epoch: 5| Step: 5
Training loss: 0.8916826248168945
Validation loss: 1.9621009954842188

Epoch: 5| Step: 6
Training loss: 0.9311784505844116
Validation loss: 1.9559593495502268

Epoch: 5| Step: 7
Training loss: 1.1081699132919312
Validation loss: 1.9273973165019866

Epoch: 5| Step: 8
Training loss: 1.095058560371399
Validation loss: 1.9291644993648733

Epoch: 5| Step: 9
Training loss: 0.974116325378418
Validation loss: 1.931129886258033

Epoch: 5| Step: 10
Training loss: 1.5518776178359985
Validation loss: 1.9236682422699467

Epoch: 429| Step: 0
Training loss: 1.3710888624191284
Validation loss: 1.9075554237570813

Epoch: 5| Step: 1
Training loss: 1.1254478693008423
Validation loss: 1.9188008487865489

Epoch: 5| Step: 2
Training loss: 1.1276659965515137
Validation loss: 1.88077114987117

Epoch: 5| Step: 3
Training loss: 0.9430447816848755
Validation loss: 1.9036350224607734

Epoch: 5| Step: 4
Training loss: 1.6546415090560913
Validation loss: 1.923316300556224

Epoch: 5| Step: 5
Training loss: 0.6634625792503357
Validation loss: 1.9416379800406836

Epoch: 5| Step: 6
Training loss: 1.363534927368164
Validation loss: 1.950545705774779

Epoch: 5| Step: 7
Training loss: 0.6152902841567993
Validation loss: 1.951930094790715

Epoch: 5| Step: 8
Training loss: 0.7482645511627197
Validation loss: 1.9829828380256571

Epoch: 5| Step: 9
Training loss: 1.0833269357681274
Validation loss: 1.9841095965395692

Epoch: 5| Step: 10
Training loss: 1.2389073371887207
Validation loss: 1.9674712118282114

Epoch: 430| Step: 0
Training loss: 0.6403293609619141
Validation loss: 1.9538567425102316

Epoch: 5| Step: 1
Training loss: 1.596122145652771
Validation loss: 1.9713911638464978

Epoch: 5| Step: 2
Training loss: 1.09929621219635
Validation loss: 1.955571323312739

Epoch: 5| Step: 3
Training loss: 1.457101583480835
Validation loss: 1.9486472811750186

Epoch: 5| Step: 4
Training loss: 1.3967034816741943
Validation loss: 1.929106318822471

Epoch: 5| Step: 5
Training loss: 0.7443370819091797
Validation loss: 1.9279586243373092

Epoch: 5| Step: 6
Training loss: 1.0611134767532349
Validation loss: 1.9360175184024278

Epoch: 5| Step: 7
Training loss: 0.9823747873306274
Validation loss: 1.961784388429375

Epoch: 5| Step: 8
Training loss: 0.7637149095535278
Validation loss: 1.9570427684373752

Epoch: 5| Step: 9
Training loss: 0.772484302520752
Validation loss: 1.9503211603369763

Epoch: 5| Step: 10
Training loss: 1.135205626487732
Validation loss: 1.9314821484268352

Epoch: 431| Step: 0
Training loss: 0.8788967132568359
Validation loss: 1.943260976063308

Epoch: 5| Step: 1
Training loss: 1.1710493564605713
Validation loss: 1.9348293414679907

Epoch: 5| Step: 2
Training loss: 0.774802029132843
Validation loss: 1.9516592999940277

Epoch: 5| Step: 3
Training loss: 1.370714545249939
Validation loss: 1.943159375139462

Epoch: 5| Step: 4
Training loss: 0.8999016880989075
Validation loss: 1.9230946315232145

Epoch: 5| Step: 5
Training loss: 0.8675230145454407
Validation loss: 1.9310126996809436

Epoch: 5| Step: 6
Training loss: 0.9851808547973633
Validation loss: 1.9629362885669996

Epoch: 5| Step: 7
Training loss: 1.3025482892990112
Validation loss: 1.9536704337725075

Epoch: 5| Step: 8
Training loss: 1.4404600858688354
Validation loss: 1.920414573402815

Epoch: 5| Step: 9
Training loss: 0.3736127018928528
Validation loss: 1.9344491471526444

Epoch: 5| Step: 10
Training loss: 1.4087910652160645
Validation loss: 1.9322422742843628

Epoch: 432| Step: 0
Training loss: 1.6373987197875977
Validation loss: 1.9728287394328783

Epoch: 5| Step: 1
Training loss: 1.201067566871643
Validation loss: 1.966161976578415

Epoch: 5| Step: 2
Training loss: 0.7343945503234863
Validation loss: 1.98019060268197

Epoch: 5| Step: 3
Training loss: 1.1981370449066162
Validation loss: 1.951726992925008

Epoch: 5| Step: 4
Training loss: 0.3729792833328247
Validation loss: 1.96216631192033

Epoch: 5| Step: 5
Training loss: 1.466887354850769
Validation loss: 1.935076573843597

Epoch: 5| Step: 6
Training loss: 1.2051796913146973
Validation loss: 1.9070698868843816

Epoch: 5| Step: 7
Training loss: 1.0627243518829346
Validation loss: 1.9106783866882324

Epoch: 5| Step: 8
Training loss: 0.6374346017837524
Validation loss: 1.8981592398817821

Epoch: 5| Step: 9
Training loss: 0.9461051821708679
Validation loss: 1.9092281954262846

Epoch: 5| Step: 10
Training loss: 0.9282107353210449
Validation loss: 1.9222567927452825

Epoch: 433| Step: 0
Training loss: 1.1612918376922607
Validation loss: 1.943389114513192

Epoch: 5| Step: 1
Training loss: 0.9527652859687805
Validation loss: 1.94918304874051

Epoch: 5| Step: 2
Training loss: 0.9427202939987183
Validation loss: 1.9921091730876634

Epoch: 5| Step: 3
Training loss: 0.7784766554832458
Validation loss: 2.0028947566145208

Epoch: 5| Step: 4
Training loss: 1.1820361614227295
Validation loss: 2.021067113004705

Epoch: 5| Step: 5
Training loss: 1.0546703338623047
Validation loss: 2.0127999372379755

Epoch: 5| Step: 6
Training loss: 1.024515986442566
Validation loss: 1.9998719564048193

Epoch: 5| Step: 7
Training loss: 0.937832236289978
Validation loss: 1.956141206525987

Epoch: 5| Step: 8
Training loss: 1.4205923080444336
Validation loss: 1.9445570745775778

Epoch: 5| Step: 9
Training loss: 1.1406924724578857
Validation loss: 1.9270893732706706

Epoch: 5| Step: 10
Training loss: 0.825320839881897
Validation loss: 1.8994634664186867

Epoch: 434| Step: 0
Training loss: 0.7130249738693237
Validation loss: 1.9185041304557555

Epoch: 5| Step: 1
Training loss: 0.6216060519218445
Validation loss: 1.9077359732761179

Epoch: 5| Step: 2
Training loss: 1.6269413232803345
Validation loss: 1.9196885965203727

Epoch: 5| Step: 3
Training loss: 1.066585659980774
Validation loss: 1.9536633581243537

Epoch: 5| Step: 4
Training loss: 1.2194674015045166
Validation loss: 1.9387819382452196

Epoch: 5| Step: 5
Training loss: 1.2569806575775146
Validation loss: 1.9613139911364483

Epoch: 5| Step: 6
Training loss: 0.9926797151565552
Validation loss: 1.9627413839422247

Epoch: 5| Step: 7
Training loss: 1.0138225555419922
Validation loss: 1.985038706051406

Epoch: 5| Step: 8
Training loss: 1.1849181652069092
Validation loss: 2.0011447206620248

Epoch: 5| Step: 9
Training loss: 0.7280220985412598
Validation loss: 1.9949373314457555

Epoch: 5| Step: 10
Training loss: 1.021092176437378
Validation loss: 2.004484725254838

Epoch: 435| Step: 0
Training loss: 1.0022352933883667
Validation loss: 2.01368954361126

Epoch: 5| Step: 1
Training loss: 0.8701052665710449
Validation loss: 1.9453573137201288

Epoch: 5| Step: 2
Training loss: 1.1432825326919556
Validation loss: 1.925140243704601

Epoch: 5| Step: 3
Training loss: 0.7819117307662964
Validation loss: 1.9339570127507693

Epoch: 5| Step: 4
Training loss: 1.4134724140167236
Validation loss: 1.9192580997302968

Epoch: 5| Step: 5
Training loss: 1.13386869430542
Validation loss: 1.9313227399702995

Epoch: 5| Step: 6
Training loss: 1.0134456157684326
Validation loss: 1.8993402937407136

Epoch: 5| Step: 7
Training loss: 1.2563316822052002
Validation loss: 1.9147862503605504

Epoch: 5| Step: 8
Training loss: 1.0614378452301025
Validation loss: 1.903818053583945

Epoch: 5| Step: 9
Training loss: 0.9318965673446655
Validation loss: 1.9185105062300158

Epoch: 5| Step: 10
Training loss: 0.7681164741516113
Validation loss: 1.8984310985893331

Epoch: 436| Step: 0
Training loss: 0.7405254244804382
Validation loss: 1.9244366922686178

Epoch: 5| Step: 1
Training loss: 0.908683180809021
Validation loss: 1.9325340383796281

Epoch: 5| Step: 2
Training loss: 1.4005279541015625
Validation loss: 1.9115505372324297

Epoch: 5| Step: 3
Training loss: 0.9633672833442688
Validation loss: 1.9099671609940068

Epoch: 5| Step: 4
Training loss: 0.8626937866210938
Validation loss: 1.947515905544322

Epoch: 5| Step: 5
Training loss: 1.4317022562026978
Validation loss: 1.9435133741747948

Epoch: 5| Step: 6
Training loss: 0.4255409240722656
Validation loss: 1.9439777840850174

Epoch: 5| Step: 7
Training loss: 1.4184157848358154
Validation loss: 1.9415193155247679

Epoch: 5| Step: 8
Training loss: 0.8599287867546082
Validation loss: 1.9536962752701135

Epoch: 5| Step: 9
Training loss: 1.3313233852386475
Validation loss: 1.9761145255898918

Epoch: 5| Step: 10
Training loss: 1.2246371507644653
Validation loss: 2.0011157335773593

Epoch: 437| Step: 0
Training loss: 1.0758908987045288
Validation loss: 1.95733993540528

Epoch: 5| Step: 1
Training loss: 1.0895345211029053
Validation loss: 1.9579063641127719

Epoch: 5| Step: 2
Training loss: 1.3139688968658447
Validation loss: 1.934468121938808

Epoch: 5| Step: 3
Training loss: 0.7432805299758911
Validation loss: 1.9714789826382872

Epoch: 5| Step: 4
Training loss: 0.7161484360694885
Validation loss: 1.9626376705784951

Epoch: 5| Step: 5
Training loss: 0.755731999874115
Validation loss: 1.9677947028990714

Epoch: 5| Step: 6
Training loss: 0.973192572593689
Validation loss: 1.940640559760473

Epoch: 5| Step: 7
Training loss: 1.5115934610366821
Validation loss: 1.9425994144972933

Epoch: 5| Step: 8
Training loss: 1.0717029571533203
Validation loss: 1.915021240070302

Epoch: 5| Step: 9
Training loss: 0.874127209186554
Validation loss: 1.9355853373004543

Epoch: 5| Step: 10
Training loss: 1.328931450843811
Validation loss: 1.9392432833230624

Epoch: 438| Step: 0
Training loss: 0.9423215985298157
Validation loss: 1.8961893717447917

Epoch: 5| Step: 1
Training loss: 1.018213152885437
Validation loss: 1.914000057405041

Epoch: 5| Step: 2
Training loss: 1.120832920074463
Validation loss: 1.9506704781645088

Epoch: 5| Step: 3
Training loss: 1.0162168741226196
Validation loss: 1.9073559673883582

Epoch: 5| Step: 4
Training loss: 1.3453328609466553
Validation loss: 1.9171648858695902

Epoch: 5| Step: 5
Training loss: 1.1376992464065552
Validation loss: 1.920527745318669

Epoch: 5| Step: 6
Training loss: 0.9863758087158203
Validation loss: 1.9437091222373388

Epoch: 5| Step: 7
Training loss: 0.9368864297866821
Validation loss: 1.9483305433745026

Epoch: 5| Step: 8
Training loss: 0.8764436841011047
Validation loss: 1.9523375970061108

Epoch: 5| Step: 9
Training loss: 1.238511562347412
Validation loss: 1.9580117374338128

Epoch: 5| Step: 10
Training loss: 0.689480721950531
Validation loss: 1.9701713772230252

Epoch: 439| Step: 0
Training loss: 1.771436095237732
Validation loss: 1.9178566291768064

Epoch: 5| Step: 1
Training loss: 0.7447608113288879
Validation loss: 1.9430628553513558

Epoch: 5| Step: 2
Training loss: 0.9008835554122925
Validation loss: 1.9286807852406656

Epoch: 5| Step: 3
Training loss: 0.7749261260032654
Validation loss: 1.9167569760353333

Epoch: 5| Step: 4
Training loss: 0.986589789390564
Validation loss: 1.931237889874366

Epoch: 5| Step: 5
Training loss: 0.9289990663528442
Validation loss: 1.913218561039176

Epoch: 5| Step: 6
Training loss: 1.3000364303588867
Validation loss: 1.9245911657169301

Epoch: 5| Step: 7
Training loss: 1.1298363208770752
Validation loss: 1.9288611155684277

Epoch: 5| Step: 8
Training loss: 0.9466379880905151
Validation loss: 1.9500733947241178

Epoch: 5| Step: 9
Training loss: 0.7027114629745483
Validation loss: 1.9402413598952755

Epoch: 5| Step: 10
Training loss: 1.0538595914840698
Validation loss: 1.9238942746193177

Epoch: 440| Step: 0
Training loss: 0.6953666806221008
Validation loss: 1.9441052200973674

Epoch: 5| Step: 1
Training loss: 1.3636234998703003
Validation loss: 1.940941236352408

Epoch: 5| Step: 2
Training loss: 1.0333455801010132
Validation loss: 1.9217455489661104

Epoch: 5| Step: 3
Training loss: 0.8230386972427368
Validation loss: 1.9436416279885076

Epoch: 5| Step: 4
Training loss: 0.8166443109512329
Validation loss: 1.9603246745242868

Epoch: 5| Step: 5
Training loss: 0.9172784090042114
Validation loss: 1.9257768584835915

Epoch: 5| Step: 6
Training loss: 0.9357786178588867
Validation loss: 1.960250037972645

Epoch: 5| Step: 7
Training loss: 1.0857970714569092
Validation loss: 1.9068737235120548

Epoch: 5| Step: 8
Training loss: 1.2259290218353271
Validation loss: 1.9190971082256687

Epoch: 5| Step: 9
Training loss: 0.8784762620925903
Validation loss: 1.9130915775093982

Epoch: 5| Step: 10
Training loss: 1.3961522579193115
Validation loss: 1.8947196288775372

Epoch: 441| Step: 0
Training loss: 1.0172088146209717
Validation loss: 1.9068173772545272

Epoch: 5| Step: 1
Training loss: 0.9193387031555176
Validation loss: 1.9307141868017053

Epoch: 5| Step: 2
Training loss: 1.3813145160675049
Validation loss: 1.8852620240180724

Epoch: 5| Step: 3
Training loss: 0.8856403231620789
Validation loss: 1.8989370087141633

Epoch: 5| Step: 4
Training loss: 1.217085599899292
Validation loss: 1.8775506814320881

Epoch: 5| Step: 5
Training loss: 1.4096009731292725
Validation loss: 1.9057788284876014

Epoch: 5| Step: 6
Training loss: 0.8701869249343872
Validation loss: 1.9089860480318788

Epoch: 5| Step: 7
Training loss: 1.22078275680542
Validation loss: 1.936699204547431

Epoch: 5| Step: 8
Training loss: 1.134627342224121
Validation loss: 1.9366748794432609

Epoch: 5| Step: 9
Training loss: 0.7410188913345337
Validation loss: 1.950171088659635

Epoch: 5| Step: 10
Training loss: 0.4838244616985321
Validation loss: 1.9306546283024613

Epoch: 442| Step: 0
Training loss: 0.846308708190918
Validation loss: 1.9032468552230506

Epoch: 5| Step: 1
Training loss: 0.8488910794258118
Validation loss: 1.871831932375508

Epoch: 5| Step: 2
Training loss: 1.0596750974655151
Validation loss: 1.8711512921958842

Epoch: 5| Step: 3
Training loss: 1.5242866277694702
Validation loss: 1.873690676945512

Epoch: 5| Step: 4
Training loss: 1.2859776020050049
Validation loss: 1.8714744044888405

Epoch: 5| Step: 5
Training loss: 1.2214919328689575
Validation loss: 1.876279995005618

Epoch: 5| Step: 6
Training loss: 0.7764809727668762
Validation loss: 1.8827639087553947

Epoch: 5| Step: 7
Training loss: 0.7935845255851746
Validation loss: 1.933042060944342

Epoch: 5| Step: 8
Training loss: 0.9741159677505493
Validation loss: 1.9380649148776967

Epoch: 5| Step: 9
Training loss: 0.8485450744628906
Validation loss: 1.9480874692240069

Epoch: 5| Step: 10
Training loss: 0.9741604924201965
Validation loss: 2.005118557201919

Epoch: 443| Step: 0
Training loss: 0.8609565496444702
Validation loss: 1.9738064965894144

Epoch: 5| Step: 1
Training loss: 0.7242891788482666
Validation loss: 2.004437602976317

Epoch: 5| Step: 2
Training loss: 1.4613568782806396
Validation loss: 1.986590003454557

Epoch: 5| Step: 3
Training loss: 1.0784223079681396
Validation loss: 1.9387038843606108

Epoch: 5| Step: 4
Training loss: 0.9550056457519531
Validation loss: 1.915788112148162

Epoch: 5| Step: 5
Training loss: 1.4644029140472412
Validation loss: 1.9103490947395243

Epoch: 5| Step: 6
Training loss: 1.143316388130188
Validation loss: 1.8836219515851749

Epoch: 5| Step: 7
Training loss: 0.8904105424880981
Validation loss: 1.8729098073897823

Epoch: 5| Step: 8
Training loss: 0.7451077699661255
Validation loss: 1.8591154980403122

Epoch: 5| Step: 9
Training loss: 0.7851772904396057
Validation loss: 1.8420410297250236

Epoch: 5| Step: 10
Training loss: 1.0343308448791504
Validation loss: 1.8596480764368528

Epoch: 444| Step: 0
Training loss: 1.1053006649017334
Validation loss: 1.8593346559873192

Epoch: 5| Step: 1
Training loss: 1.1210620403289795
Validation loss: 1.8805007050114293

Epoch: 5| Step: 2
Training loss: 0.6815990209579468
Validation loss: 1.8656599329363914

Epoch: 5| Step: 3
Training loss: 0.5998300313949585
Validation loss: 1.9036131264061056

Epoch: 5| Step: 4
Training loss: 1.1642096042633057
Validation loss: 1.9259476251499628

Epoch: 5| Step: 5
Training loss: 0.6946736574172974
Validation loss: 1.8931023728462957

Epoch: 5| Step: 6
Training loss: 0.9548061490058899
Validation loss: 1.9272054895277946

Epoch: 5| Step: 7
Training loss: 1.244003415107727
Validation loss: 1.88973024839996

Epoch: 5| Step: 8
Training loss: 1.4897451400756836
Validation loss: 1.894951464027487

Epoch: 5| Step: 9
Training loss: 1.2139356136322021
Validation loss: 1.884324284010036

Epoch: 5| Step: 10
Training loss: 0.7368833422660828
Validation loss: 1.872125696110469

Epoch: 445| Step: 0
Training loss: 1.0071682929992676
Validation loss: 1.8959652787895613

Epoch: 5| Step: 1
Training loss: 0.9476307034492493
Validation loss: 1.8855625583279518

Epoch: 5| Step: 2
Training loss: 0.8025795221328735
Validation loss: 1.9057400944412395

Epoch: 5| Step: 3
Training loss: 0.8255568742752075
Validation loss: 1.9381762371268323

Epoch: 5| Step: 4
Training loss: 1.1987874507904053
Validation loss: 1.9125186435637935

Epoch: 5| Step: 5
Training loss: 0.9623619318008423
Validation loss: 1.9120049271532285

Epoch: 5| Step: 6
Training loss: 0.4408762454986572
Validation loss: 1.8892780939737956

Epoch: 5| Step: 7
Training loss: 0.5349797606468201
Validation loss: 1.9064960274645077

Epoch: 5| Step: 8
Training loss: 1.594436526298523
Validation loss: 1.9074452692462551

Epoch: 5| Step: 9
Training loss: 1.6349763870239258
Validation loss: 1.9248483027181318

Epoch: 5| Step: 10
Training loss: 0.8989039063453674
Validation loss: 1.912232478459676

Epoch: 446| Step: 0
Training loss: 1.2198951244354248
Validation loss: 1.9315299436610232

Epoch: 5| Step: 1
Training loss: 1.2488157749176025
Validation loss: 1.9436614103214715

Epoch: 5| Step: 2
Training loss: 0.7060521841049194
Validation loss: 1.9218354327704317

Epoch: 5| Step: 3
Training loss: 0.8611354827880859
Validation loss: 1.9254233708945654

Epoch: 5| Step: 4
Training loss: 1.0998899936676025
Validation loss: 1.9320772553002963

Epoch: 5| Step: 5
Training loss: 1.1183693408966064
Validation loss: 1.9295929067878312

Epoch: 5| Step: 6
Training loss: 1.0084116458892822
Validation loss: 1.9044398005290697

Epoch: 5| Step: 7
Training loss: 0.65574711561203
Validation loss: 1.8723381309099094

Epoch: 5| Step: 8
Training loss: 0.9257136583328247
Validation loss: 1.8771852588140836

Epoch: 5| Step: 9
Training loss: 1.1158863306045532
Validation loss: 1.8917032903240574

Epoch: 5| Step: 10
Training loss: 0.922420084476471
Validation loss: 1.857566325895248

Epoch: 447| Step: 0
Training loss: 0.583509624004364
Validation loss: 1.8690071003411406

Epoch: 5| Step: 1
Training loss: 1.2749154567718506
Validation loss: 1.9083095237772951

Epoch: 5| Step: 2
Training loss: 0.6656428575515747
Validation loss: 1.9370625813802083

Epoch: 5| Step: 3
Training loss: 1.4781887531280518
Validation loss: 1.932559690167827

Epoch: 5| Step: 4
Training loss: 0.8185480237007141
Validation loss: 1.939302468812594

Epoch: 5| Step: 5
Training loss: 1.1457114219665527
Validation loss: 1.9207138374287596

Epoch: 5| Step: 6
Training loss: 1.2539150714874268
Validation loss: 1.9065512457201559

Epoch: 5| Step: 7
Training loss: 0.7629148364067078
Validation loss: 1.8927075042519519

Epoch: 5| Step: 8
Training loss: 1.0682588815689087
Validation loss: 1.9009127539973105

Epoch: 5| Step: 9
Training loss: 0.8298231363296509
Validation loss: 1.8829116411106561

Epoch: 5| Step: 10
Training loss: 0.8903042674064636
Validation loss: 1.8564768452798166

Epoch: 448| Step: 0
Training loss: 0.8362029790878296
Validation loss: 1.8794270612860238

Epoch: 5| Step: 1
Training loss: 0.8283265829086304
Validation loss: 1.8892683393211775

Epoch: 5| Step: 2
Training loss: 1.0415045022964478
Validation loss: 1.905958834514823

Epoch: 5| Step: 3
Training loss: 1.0782339572906494
Validation loss: 1.9045663764399867

Epoch: 5| Step: 4
Training loss: 1.2613649368286133
Validation loss: 1.9033217019932245

Epoch: 5| Step: 5
Training loss: 1.3191735744476318
Validation loss: 1.898403606107158

Epoch: 5| Step: 6
Training loss: 1.1665369272232056
Validation loss: 1.928770565217541

Epoch: 5| Step: 7
Training loss: 0.9503911733627319
Validation loss: 1.9090211045357488

Epoch: 5| Step: 8
Training loss: 0.6098611354827881
Validation loss: 1.8961032244466967

Epoch: 5| Step: 9
Training loss: 0.804871678352356
Validation loss: 1.8929525882967058

Epoch: 5| Step: 10
Training loss: 0.9475910067558289
Validation loss: 1.9083964504221433

Epoch: 449| Step: 0
Training loss: 1.5715396404266357
Validation loss: 1.8787500704488447

Epoch: 5| Step: 1
Training loss: 0.6192716956138611
Validation loss: 1.875238387815414

Epoch: 5| Step: 2
Training loss: 1.041379690170288
Validation loss: 1.8846268077050485

Epoch: 5| Step: 3
Training loss: 0.9683871269226074
Validation loss: 1.881970774742865

Epoch: 5| Step: 4
Training loss: 0.866320788860321
Validation loss: 1.8738414138875983

Epoch: 5| Step: 5
Training loss: 1.0703730583190918
Validation loss: 1.8993024133866834

Epoch: 5| Step: 6
Training loss: 0.7783282995223999
Validation loss: 1.8743343635271954

Epoch: 5| Step: 7
Training loss: 1.4694833755493164
Validation loss: 1.8747593638717488

Epoch: 5| Step: 8
Training loss: 0.4901614189147949
Validation loss: 1.9146671500257266

Epoch: 5| Step: 9
Training loss: 0.75480717420578
Validation loss: 1.9026783845757926

Epoch: 5| Step: 10
Training loss: 0.9990701079368591
Validation loss: 1.8946387921610186

Epoch: 450| Step: 0
Training loss: 0.9468429684638977
Validation loss: 1.8834209672866329

Epoch: 5| Step: 1
Training loss: 0.7593452334403992
Validation loss: 1.8925057470157582

Epoch: 5| Step: 2
Training loss: 0.8724052309989929
Validation loss: 1.8696812365644722

Epoch: 5| Step: 3
Training loss: 0.984204113483429
Validation loss: 1.8930182021151307

Epoch: 5| Step: 4
Training loss: 0.9988389015197754
Validation loss: 1.8824729714342343

Epoch: 5| Step: 5
Training loss: 1.0580847263336182
Validation loss: 1.8898968696594238

Epoch: 5| Step: 6
Training loss: 0.7677422761917114
Validation loss: 1.9128468280197473

Epoch: 5| Step: 7
Training loss: 1.1226361989974976
Validation loss: 1.8911460497046029

Epoch: 5| Step: 8
Training loss: 0.9921339154243469
Validation loss: 1.9013362417938888

Epoch: 5| Step: 9
Training loss: 0.8075094223022461
Validation loss: 1.90321736310118

Epoch: 5| Step: 10
Training loss: 1.3710052967071533
Validation loss: 1.9210276039697791

Testing loss: 2.097927067014906
