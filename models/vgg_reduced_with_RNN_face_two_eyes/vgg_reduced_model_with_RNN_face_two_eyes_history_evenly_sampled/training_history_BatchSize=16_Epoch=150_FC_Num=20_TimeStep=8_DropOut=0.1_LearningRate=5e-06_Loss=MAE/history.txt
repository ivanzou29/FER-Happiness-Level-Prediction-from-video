Epoch: 1| Step: 0
Training loss: 4.804258346557617
Validation loss: 5.160279714933005

Epoch: 6| Step: 1
Training loss: 4.716734409332275
Validation loss: 5.155415083772393

Epoch: 6| Step: 2
Training loss: 4.769946098327637
Validation loss: 5.150869646380024

Epoch: 6| Step: 3
Training loss: 3.9664993286132812
Validation loss: 5.146666865194997

Epoch: 6| Step: 4
Training loss: 5.337071895599365
Validation loss: 5.1425675269096125

Epoch: 6| Step: 5
Training loss: 4.746536731719971
Validation loss: 5.138939016608782

Epoch: 6| Step: 6
Training loss: 4.288560390472412
Validation loss: 5.135262371391378

Epoch: 6| Step: 7
Training loss: 5.275696277618408
Validation loss: 5.131657810621364

Epoch: 6| Step: 8
Training loss: 5.919574737548828
Validation loss: 5.127786620970695

Epoch: 6| Step: 9
Training loss: 4.006719589233398
Validation loss: 5.123955516405003

Epoch: 6| Step: 10
Training loss: 5.656627655029297
Validation loss: 5.120036084164855

Epoch: 6| Step: 11
Training loss: 4.784422874450684
Validation loss: 5.115830934175881

Epoch: 6| Step: 12
Training loss: 5.622776508331299
Validation loss: 5.111546454891082

Epoch: 6| Step: 13
Training loss: 5.287307262420654
Validation loss: 5.107086273931688

Epoch: 2| Step: 0
Training loss: 4.674661636352539
Validation loss: 5.1022026564485286

Epoch: 6| Step: 1
Training loss: 4.779163360595703
Validation loss: 5.097124822678104

Epoch: 6| Step: 2
Training loss: 5.44798469543457
Validation loss: 5.091837078012446

Epoch: 6| Step: 3
Training loss: 4.696605205535889
Validation loss: 5.086862071867912

Epoch: 6| Step: 4
Training loss: 4.1586761474609375
Validation loss: 5.08092309582618

Epoch: 6| Step: 5
Training loss: 4.534160137176514
Validation loss: 5.074683091973745

Epoch: 6| Step: 6
Training loss: 4.848548889160156
Validation loss: 5.0687207406566985

Epoch: 6| Step: 7
Training loss: 5.140489101409912
Validation loss: 5.062399361723212

Epoch: 6| Step: 8
Training loss: 5.637091636657715
Validation loss: 5.05506347328104

Epoch: 6| Step: 9
Training loss: 5.284663200378418
Validation loss: 5.047321093979702

Epoch: 6| Step: 10
Training loss: 4.794419765472412
Validation loss: 5.039909911412065

Epoch: 6| Step: 11
Training loss: 4.525326251983643
Validation loss: 5.031327380928942

Epoch: 6| Step: 12
Training loss: 4.360649108886719
Validation loss: 5.0225340166399555

Epoch: 6| Step: 13
Training loss: 5.379157066345215
Validation loss: 5.013096358186456

Epoch: 3| Step: 0
Training loss: 5.778031349182129
Validation loss: 5.003617476391536

Epoch: 6| Step: 1
Training loss: 5.134310722351074
Validation loss: 4.992990524538102

Epoch: 6| Step: 2
Training loss: 4.762218475341797
Validation loss: 4.982350805754303

Epoch: 6| Step: 3
Training loss: 5.7529473304748535
Validation loss: 4.969903084539598

Epoch: 6| Step: 4
Training loss: 3.054227113723755
Validation loss: 4.9585942196589645

Epoch: 6| Step: 5
Training loss: 4.165866851806641
Validation loss: 4.944700000106647

Epoch: 6| Step: 6
Training loss: 5.103820323944092
Validation loss: 4.93226227196314

Epoch: 6| Step: 7
Training loss: 3.9621405601501465
Validation loss: 4.917871116310038

Epoch: 6| Step: 8
Training loss: 5.427268981933594
Validation loss: 4.902320948980188

Epoch: 6| Step: 9
Training loss: 5.1985859870910645
Validation loss: 4.887376913460352

Epoch: 6| Step: 10
Training loss: 4.167886734008789
Validation loss: 4.870448681616014

Epoch: 6| Step: 11
Training loss: 5.008370876312256
Validation loss: 4.85275621311639

Epoch: 6| Step: 12
Training loss: 3.772909641265869
Validation loss: 4.835661021612024

Epoch: 6| Step: 13
Training loss: 4.724127769470215
Validation loss: 4.81716638483027

Epoch: 4| Step: 0
Training loss: 4.110326290130615
Validation loss: 4.79667878407304

Epoch: 6| Step: 1
Training loss: 4.734140396118164
Validation loss: 4.776644522143949

Epoch: 6| Step: 2
Training loss: 4.393317222595215
Validation loss: 4.754770883949854

Epoch: 6| Step: 3
Training loss: 4.542790412902832
Validation loss: 4.73585493333878

Epoch: 6| Step: 4
Training loss: 4.77060604095459
Validation loss: 4.71327022839618

Epoch: 6| Step: 5
Training loss: 3.2194719314575195
Validation loss: 4.692276605995753

Epoch: 6| Step: 6
Training loss: 4.033137321472168
Validation loss: 4.670065469639276

Epoch: 6| Step: 7
Training loss: 6.002715587615967
Validation loss: 4.64843439286755

Epoch: 6| Step: 8
Training loss: 5.3899712562561035
Validation loss: 4.627705850908833

Epoch: 6| Step: 9
Training loss: 3.676187515258789
Validation loss: 4.606221993764241

Epoch: 6| Step: 10
Training loss: 3.548892021179199
Validation loss: 4.584867764544743

Epoch: 6| Step: 11
Training loss: 4.73012113571167
Validation loss: 4.564272260153166

Epoch: 6| Step: 12
Training loss: 4.786012649536133
Validation loss: 4.54340846051452

Epoch: 6| Step: 13
Training loss: 4.412851333618164
Validation loss: 4.524495140198739

Epoch: 5| Step: 0
Training loss: 3.1220884323120117
Validation loss: 4.5033854720413045

Epoch: 6| Step: 1
Training loss: 4.13358211517334
Validation loss: 4.485980920894171

Epoch: 6| Step: 2
Training loss: 3.56319522857666
Validation loss: 4.4666246752585135

Epoch: 6| Step: 3
Training loss: 4.21444034576416
Validation loss: 4.447952619162939

Epoch: 6| Step: 4
Training loss: 3.8893260955810547
Validation loss: 4.427893987265966

Epoch: 6| Step: 5
Training loss: 4.070624351501465
Validation loss: 4.409043563309536

Epoch: 6| Step: 6
Training loss: 4.262268543243408
Validation loss: 4.388661148727581

Epoch: 6| Step: 7
Training loss: 3.5048701763153076
Validation loss: 4.368736682399627

Epoch: 6| Step: 8
Training loss: 5.1784844398498535
Validation loss: 4.349711051551244

Epoch: 6| Step: 9
Training loss: 3.524691104888916
Validation loss: 4.328785804010207

Epoch: 6| Step: 10
Training loss: 4.692248344421387
Validation loss: 4.308369605771957

Epoch: 6| Step: 11
Training loss: 5.25681209564209
Validation loss: 4.286697885041596

Epoch: 6| Step: 12
Training loss: 4.507497787475586
Validation loss: 4.263891389293056

Epoch: 6| Step: 13
Training loss: 4.699769496917725
Validation loss: 4.242191919716456

Epoch: 6| Step: 0
Training loss: 4.440413951873779
Validation loss: 4.2208587636229815

Epoch: 6| Step: 1
Training loss: 4.155424118041992
Validation loss: 4.199191598482029

Epoch: 6| Step: 2
Training loss: 3.31350040435791
Validation loss: 4.179380768088884

Epoch: 6| Step: 3
Training loss: 4.312652111053467
Validation loss: 4.1605550678827425

Epoch: 6| Step: 4
Training loss: 4.387664794921875
Validation loss: 4.140586386444748

Epoch: 6| Step: 5
Training loss: 4.224660396575928
Validation loss: 4.123300593386414

Epoch: 6| Step: 6
Training loss: 4.085275650024414
Validation loss: 4.106159820351549

Epoch: 6| Step: 7
Training loss: 3.5636215209960938
Validation loss: 4.089108595284083

Epoch: 6| Step: 8
Training loss: 3.8243768215179443
Validation loss: 4.074275883295202

Epoch: 6| Step: 9
Training loss: 3.1443281173706055
Validation loss: 4.0574600209472

Epoch: 6| Step: 10
Training loss: 3.558401584625244
Validation loss: 4.041869532677435

Epoch: 6| Step: 11
Training loss: 2.94903564453125
Validation loss: 4.024950009520336

Epoch: 6| Step: 12
Training loss: 4.6502461433410645
Validation loss: 4.013597401239538

Epoch: 6| Step: 13
Training loss: 5.068746566772461
Validation loss: 3.9962848437729703

Epoch: 7| Step: 0
Training loss: 2.8115062713623047
Validation loss: 3.9829012552897134

Epoch: 6| Step: 1
Training loss: 4.00375509262085
Validation loss: 3.969902710248065

Epoch: 6| Step: 2
Training loss: 4.591472625732422
Validation loss: 3.9576947458328737

Epoch: 6| Step: 3
Training loss: 4.591072082519531
Validation loss: 3.94091393357964

Epoch: 6| Step: 4
Training loss: 4.585472106933594
Validation loss: 3.9283660175979778

Epoch: 6| Step: 5
Training loss: 3.086466073989868
Validation loss: 3.913844923819265

Epoch: 6| Step: 6
Training loss: 3.303875684738159
Validation loss: 3.900572612721433

Epoch: 6| Step: 7
Training loss: 2.5709848403930664
Validation loss: 3.88656279348558

Epoch: 6| Step: 8
Training loss: 3.4651803970336914
Validation loss: 3.872051541523267

Epoch: 6| Step: 9
Training loss: 4.569403648376465
Validation loss: 3.860771635527252

Epoch: 6| Step: 10
Training loss: 3.712656021118164
Validation loss: 3.8472763184578187

Epoch: 6| Step: 11
Training loss: 3.8240675926208496
Validation loss: 3.8353315066265803

Epoch: 6| Step: 12
Training loss: 3.417658567428589
Validation loss: 3.8235874663117113

Epoch: 6| Step: 13
Training loss: 4.6143717765808105
Validation loss: 3.810335228520055

Epoch: 8| Step: 0
Training loss: 3.5858287811279297
Validation loss: 3.798404565421484

Epoch: 6| Step: 1
Training loss: 3.0535168647766113
Validation loss: 3.789092663795717

Epoch: 6| Step: 2
Training loss: 3.7367076873779297
Validation loss: 3.777880104639197

Epoch: 6| Step: 3
Training loss: 4.776489734649658
Validation loss: 3.7665627438534974

Epoch: 6| Step: 4
Training loss: 3.418252468109131
Validation loss: 3.7574124848970802

Epoch: 6| Step: 5
Training loss: 3.913804531097412
Validation loss: 3.74361115629955

Epoch: 6| Step: 6
Training loss: 3.759906768798828
Validation loss: 3.733070194080312

Epoch: 6| Step: 7
Training loss: 3.2378642559051514
Validation loss: 3.7199089296402468

Epoch: 6| Step: 8
Training loss: 3.6080193519592285
Validation loss: 3.7073985709938952

Epoch: 6| Step: 9
Training loss: 3.5711593627929688
Validation loss: 3.700588903119487

Epoch: 6| Step: 10
Training loss: 5.046125411987305
Validation loss: 3.691396333838022

Epoch: 6| Step: 11
Training loss: 1.939702033996582
Validation loss: 3.680491473085137

Epoch: 6| Step: 12
Training loss: 3.6020655632019043
Validation loss: 3.673769804739183

Epoch: 6| Step: 13
Training loss: 3.4396474361419678
Validation loss: 3.6585998842793126

Epoch: 9| Step: 0
Training loss: 2.8707103729248047
Validation loss: 3.6524597803751626

Epoch: 6| Step: 1
Training loss: 3.5394740104675293
Validation loss: 3.641487254891344

Epoch: 6| Step: 2
Training loss: 3.8650898933410645
Validation loss: 3.633461183117282

Epoch: 6| Step: 3
Training loss: 3.7128818035125732
Validation loss: 3.62178716351909

Epoch: 6| Step: 4
Training loss: 4.342504501342773
Validation loss: 3.613027767468524

Epoch: 6| Step: 5
Training loss: 3.2862327098846436
Validation loss: 3.605202349283362

Epoch: 6| Step: 6
Training loss: 2.6182477474212646
Validation loss: 3.5984824857404156

Epoch: 6| Step: 7
Training loss: 4.460663795471191
Validation loss: 3.5910793555680143

Epoch: 6| Step: 8
Training loss: 2.872469425201416
Validation loss: 3.586174493194908

Epoch: 6| Step: 9
Training loss: 4.083545207977295
Validation loss: 3.579473385246851

Epoch: 6| Step: 10
Training loss: 3.6693074703216553
Validation loss: 3.5723207612191477

Epoch: 6| Step: 11
Training loss: 2.919773578643799
Validation loss: 3.565565227180399

Epoch: 6| Step: 12
Training loss: 3.494535207748413
Validation loss: 3.5615012056084088

Epoch: 6| Step: 13
Training loss: 3.5497870445251465
Validation loss: 3.553371701189267

Epoch: 10| Step: 0
Training loss: 2.467897891998291
Validation loss: 3.5474589229911886

Epoch: 6| Step: 1
Training loss: 4.717233657836914
Validation loss: 3.543264994057276

Epoch: 6| Step: 2
Training loss: 3.88748836517334
Validation loss: 3.5374428969557568

Epoch: 6| Step: 3
Training loss: 3.4846129417419434
Validation loss: 3.531512870583483

Epoch: 6| Step: 4
Training loss: 4.397143363952637
Validation loss: 3.5271227872499855

Epoch: 6| Step: 5
Training loss: 2.417940616607666
Validation loss: 3.5217647808854298

Epoch: 6| Step: 6
Training loss: 3.2011561393737793
Validation loss: 3.5164990681473927

Epoch: 6| Step: 7
Training loss: 3.7190630435943604
Validation loss: 3.510867077817199

Epoch: 6| Step: 8
Training loss: 3.0119595527648926
Validation loss: 3.504494479907456

Epoch: 6| Step: 9
Training loss: 2.7011802196502686
Validation loss: 3.5026274701600433

Epoch: 6| Step: 10
Training loss: 3.4732961654663086
Validation loss: 3.4956315050842943

Epoch: 6| Step: 11
Training loss: 3.3898770809173584
Validation loss: 3.491710329568514

Epoch: 6| Step: 12
Training loss: 3.1885523796081543
Validation loss: 3.4876707343644995

Epoch: 6| Step: 13
Training loss: 4.877887725830078
Validation loss: 3.4848866616525958

Epoch: 11| Step: 0
Training loss: 4.084409236907959
Validation loss: 3.4798340951242754

Epoch: 6| Step: 1
Training loss: 3.9093856811523438
Validation loss: 3.475591136563209

Epoch: 6| Step: 2
Training loss: 2.3787529468536377
Validation loss: 3.4668923962500786

Epoch: 6| Step: 3
Training loss: 3.343303680419922
Validation loss: 3.4656896206640426

Epoch: 6| Step: 4
Training loss: 4.341456413269043
Validation loss: 3.4579553911762853

Epoch: 6| Step: 5
Training loss: 2.816650867462158
Validation loss: 3.4547064740170716

Epoch: 6| Step: 6
Training loss: 3.7335803508758545
Validation loss: 3.4478592129163843

Epoch: 6| Step: 7
Training loss: 3.2717440128326416
Validation loss: 3.444550529603035

Epoch: 6| Step: 8
Training loss: 3.014853000640869
Validation loss: 3.437380749692199

Epoch: 6| Step: 9
Training loss: 3.0139684677124023
Validation loss: 3.434739866564351

Epoch: 6| Step: 10
Training loss: 3.4739906787872314
Validation loss: 3.429400587594637

Epoch: 6| Step: 11
Training loss: 4.389684677124023
Validation loss: 3.4264242110713834

Epoch: 6| Step: 12
Training loss: 2.982161521911621
Validation loss: 3.419323229020642

Epoch: 6| Step: 13
Training loss: 2.1669836044311523
Validation loss: 3.413850748410789

Epoch: 12| Step: 0
Training loss: 2.9764339923858643
Validation loss: 3.4100429960476455

Epoch: 6| Step: 1
Training loss: 4.078157901763916
Validation loss: 3.4039560876866823

Epoch: 6| Step: 2
Training loss: 3.262897491455078
Validation loss: 3.397428374136648

Epoch: 6| Step: 3
Training loss: 3.344348907470703
Validation loss: 3.388230385318879

Epoch: 6| Step: 4
Training loss: 3.2621631622314453
Validation loss: 3.383318511388635

Epoch: 6| Step: 5
Training loss: 3.3550331592559814
Validation loss: 3.376503413723361

Epoch: 6| Step: 6
Training loss: 3.100944757461548
Validation loss: 3.371273176644438

Epoch: 6| Step: 7
Training loss: 3.3297595977783203
Validation loss: 3.363894872767951

Epoch: 6| Step: 8
Training loss: 3.235802173614502
Validation loss: 3.3547519458237516

Epoch: 6| Step: 9
Training loss: 3.4810776710510254
Validation loss: 3.3503653541687997

Epoch: 6| Step: 10
Training loss: 2.757988214492798
Validation loss: 3.349797607750021

Epoch: 6| Step: 11
Training loss: 4.086579322814941
Validation loss: 3.3413650399895123

Epoch: 6| Step: 12
Training loss: 3.3404898643493652
Validation loss: 3.3389936929107993

Epoch: 6| Step: 13
Training loss: 2.7829484939575195
Validation loss: 3.328378654295398

Epoch: 13| Step: 0
Training loss: 3.2253198623657227
Validation loss: 3.3230662525341077

Epoch: 6| Step: 1
Training loss: 3.378969430923462
Validation loss: 3.3192794502422376

Epoch: 6| Step: 2
Training loss: 2.195746660232544
Validation loss: 3.3126915065191125

Epoch: 6| Step: 3
Training loss: 4.158888339996338
Validation loss: 3.306533141802716

Epoch: 6| Step: 4
Training loss: 3.818866014480591
Validation loss: 3.2998171519207697

Epoch: 6| Step: 5
Training loss: 3.0469486713409424
Validation loss: 3.2964614155471965

Epoch: 6| Step: 6
Training loss: 3.3072564601898193
Validation loss: 3.2886194618799354

Epoch: 6| Step: 7
Training loss: 3.9220714569091797
Validation loss: 3.286075225440405

Epoch: 6| Step: 8
Training loss: 2.38100266456604
Validation loss: 3.279425308268557

Epoch: 6| Step: 9
Training loss: 3.99782133102417
Validation loss: 3.273088547491258

Epoch: 6| Step: 10
Training loss: 3.5125553607940674
Validation loss: 3.2700116839460147

Epoch: 6| Step: 11
Training loss: 2.438382148742676
Validation loss: 3.2651389311718684

Epoch: 6| Step: 12
Training loss: 3.2599246501922607
Validation loss: 3.261751841473323

Epoch: 6| Step: 13
Training loss: 2.7958178520202637
Validation loss: 3.257562985984228

Epoch: 14| Step: 0
Training loss: 3.006751298904419
Validation loss: 3.2523091198295675

Epoch: 6| Step: 1
Training loss: 3.033787727355957
Validation loss: 3.2533399520381803

Epoch: 6| Step: 2
Training loss: 4.057179927825928
Validation loss: 3.2406723140388407

Epoch: 6| Step: 3
Training loss: 2.800833225250244
Validation loss: 3.24607434580403

Epoch: 6| Step: 4
Training loss: 3.1040711402893066
Validation loss: 3.2447390069243727

Epoch: 6| Step: 5
Training loss: 2.3462202548980713
Validation loss: 3.234612618723223

Epoch: 6| Step: 6
Training loss: 2.5054268836975098
Validation loss: 3.2261566321055093

Epoch: 6| Step: 7
Training loss: 4.40812873840332
Validation loss: 3.229462356977565

Epoch: 6| Step: 8
Training loss: 3.6955413818359375
Validation loss: 3.22965645533736

Epoch: 6| Step: 9
Training loss: 3.303338050842285
Validation loss: 3.2280694976929696

Epoch: 6| Step: 10
Training loss: 2.9164347648620605
Validation loss: 3.2244390313343336

Epoch: 6| Step: 11
Training loss: 3.204050302505493
Validation loss: 3.2225236123608005

Epoch: 6| Step: 12
Training loss: 3.175954818725586
Validation loss: 3.2187004627720004

Epoch: 6| Step: 13
Training loss: 3.760690927505493
Validation loss: 3.2092205016843733

Epoch: 15| Step: 0
Training loss: 3.1607513427734375
Validation loss: 3.206649341890889

Epoch: 6| Step: 1
Training loss: 3.120138645172119
Validation loss: 3.1965925180783836

Epoch: 6| Step: 2
Training loss: 2.6775691509246826
Validation loss: 3.191731458069176

Epoch: 6| Step: 3
Training loss: 3.0639212131500244
Validation loss: 3.18794907036648

Epoch: 6| Step: 4
Training loss: 4.086048603057861
Validation loss: 3.18203572047654

Epoch: 6| Step: 5
Training loss: 3.589885711669922
Validation loss: 3.1790309285604827

Epoch: 6| Step: 6
Training loss: 3.1876344680786133
Validation loss: 3.1806827258038264

Epoch: 6| Step: 7
Training loss: 2.1021201610565186
Validation loss: 3.1743425220571537

Epoch: 6| Step: 8
Training loss: 2.850775718688965
Validation loss: 3.1710074588816655

Epoch: 6| Step: 9
Training loss: 2.812221050262451
Validation loss: 3.1652159485765683

Epoch: 6| Step: 10
Training loss: 4.225767135620117
Validation loss: 3.163003013980004

Epoch: 6| Step: 11
Training loss: 3.399261951446533
Validation loss: 3.157412682810137

Epoch: 6| Step: 12
Training loss: 3.2840206623077393
Validation loss: 3.1544091291325067

Epoch: 6| Step: 13
Training loss: 2.775947332382202
Validation loss: 3.1500079965078704

Epoch: 16| Step: 0
Training loss: 3.6356091499328613
Validation loss: 3.1490181953676286

Epoch: 6| Step: 1
Training loss: 3.0164005756378174
Validation loss: 3.1430236754878873

Epoch: 6| Step: 2
Training loss: 2.515496253967285
Validation loss: 3.1424227529956448

Epoch: 6| Step: 3
Training loss: 2.181121587753296
Validation loss: 3.1425712723885812

Epoch: 6| Step: 4
Training loss: 3.081766366958618
Validation loss: 3.1347699344799085

Epoch: 6| Step: 5
Training loss: 3.509023427963257
Validation loss: 3.1345656969214

Epoch: 6| Step: 6
Training loss: 2.4908673763275146
Validation loss: 3.132666472465761

Epoch: 6| Step: 7
Training loss: 3.8116819858551025
Validation loss: 3.13700149648933

Epoch: 6| Step: 8
Training loss: 3.8121070861816406
Validation loss: 3.1261945129722677

Epoch: 6| Step: 9
Training loss: 3.5160555839538574
Validation loss: 3.1206606229146323

Epoch: 6| Step: 10
Training loss: 3.482297897338867
Validation loss: 3.1371768982179704

Epoch: 6| Step: 11
Training loss: 3.2805535793304443
Validation loss: 3.1463949552146335

Epoch: 6| Step: 12
Training loss: 3.0476603507995605
Validation loss: 3.146430338582685

Epoch: 6| Step: 13
Training loss: 2.396935224533081
Validation loss: 3.1342872368392123

Epoch: 17| Step: 0
Training loss: 3.710212469100952
Validation loss: 3.1245940039234776

Epoch: 6| Step: 1
Training loss: 2.968872547149658
Validation loss: 3.1209141208279516

Epoch: 6| Step: 2
Training loss: 2.440066337585449
Validation loss: 3.1175835055689656

Epoch: 6| Step: 3
Training loss: 4.063340187072754
Validation loss: 3.1179342680079962

Epoch: 6| Step: 4
Training loss: 3.050920248031616
Validation loss: 3.114479305923626

Epoch: 6| Step: 5
Training loss: 2.97819447517395
Validation loss: 3.116045052005399

Epoch: 6| Step: 6
Training loss: 4.05784797668457
Validation loss: 3.1091895821273967

Epoch: 6| Step: 7
Training loss: 2.6855642795562744
Validation loss: 3.1042869885762534

Epoch: 6| Step: 8
Training loss: 2.8929319381713867
Validation loss: 3.1026967392172864

Epoch: 6| Step: 9
Training loss: 2.6379833221435547
Validation loss: 3.098840513537007

Epoch: 6| Step: 10
Training loss: 3.2549431324005127
Validation loss: 3.0929205776542745

Epoch: 6| Step: 11
Training loss: 2.4366023540496826
Validation loss: 3.0912982520236763

Epoch: 6| Step: 12
Training loss: 4.073958873748779
Validation loss: 3.0863863063114945

Epoch: 6| Step: 13
Training loss: 2.18015193939209
Validation loss: 3.0893814666296846

Epoch: 18| Step: 0
Training loss: 2.806321144104004
Validation loss: 3.0838866592735372

Epoch: 6| Step: 1
Training loss: 3.2088215351104736
Validation loss: 3.0822853324233845

Epoch: 6| Step: 2
Training loss: 3.0142722129821777
Validation loss: 3.078870265714584

Epoch: 6| Step: 3
Training loss: 3.125208854675293
Validation loss: 3.0727770789977042

Epoch: 6| Step: 4
Training loss: 4.035290718078613
Validation loss: 3.0674303962338354

Epoch: 6| Step: 5
Training loss: 3.842622756958008
Validation loss: 3.06747870035069

Epoch: 6| Step: 6
Training loss: 1.8087584972381592
Validation loss: 3.061778527434154

Epoch: 6| Step: 7
Training loss: 3.5277976989746094
Validation loss: 3.058848588697372

Epoch: 6| Step: 8
Training loss: 2.6205151081085205
Validation loss: 3.0555695231242845

Epoch: 6| Step: 9
Training loss: 2.8215646743774414
Validation loss: 3.056790633868146

Epoch: 6| Step: 10
Training loss: 2.898775577545166
Validation loss: 3.05763945528256

Epoch: 6| Step: 11
Training loss: 3.62034273147583
Validation loss: 3.0523698355561946

Epoch: 6| Step: 12
Training loss: 2.983853816986084
Validation loss: 3.0547225859857376

Epoch: 6| Step: 13
Training loss: 3.1601381301879883
Validation loss: 3.0491869372706257

Epoch: 19| Step: 0
Training loss: 3.416999340057373
Validation loss: 3.048750190324681

Epoch: 6| Step: 1
Training loss: 3.297095775604248
Validation loss: 3.0445969694404194

Epoch: 6| Step: 2
Training loss: 3.2884297370910645
Validation loss: 3.0460580548932477

Epoch: 6| Step: 3
Training loss: 2.862987518310547
Validation loss: 3.041663344188403

Epoch: 6| Step: 4
Training loss: 3.406660318374634
Validation loss: 3.0463410141647502

Epoch: 6| Step: 5
Training loss: 3.1894264221191406
Validation loss: 3.0380055930024836

Epoch: 6| Step: 6
Training loss: 3.768476724624634
Validation loss: 3.0359706776116484

Epoch: 6| Step: 7
Training loss: 2.906193971633911
Validation loss: 3.0293288666714906

Epoch: 6| Step: 8
Training loss: 2.2959728240966797
Validation loss: 3.0262543873120378

Epoch: 6| Step: 9
Training loss: 3.268662452697754
Validation loss: 3.025614764100762

Epoch: 6| Step: 10
Training loss: 2.348940134048462
Validation loss: 3.027967563239477

Epoch: 6| Step: 11
Training loss: 3.379601240158081
Validation loss: 3.026770635317731

Epoch: 6| Step: 12
Training loss: 3.373352527618408
Validation loss: 3.022796441149968

Epoch: 6| Step: 13
Training loss: 1.907033085823059
Validation loss: 3.0190963616935154

Epoch: 20| Step: 0
Training loss: 3.666008710861206
Validation loss: 3.0215790887032785

Epoch: 6| Step: 1
Training loss: 2.8035805225372314
Validation loss: 3.0189076469790552

Epoch: 6| Step: 2
Training loss: 3.131401777267456
Validation loss: 3.016860972168625

Epoch: 6| Step: 3
Training loss: 1.839010238647461
Validation loss: 3.015847885480491

Epoch: 6| Step: 4
Training loss: 3.162961483001709
Validation loss: 3.0110896120789232

Epoch: 6| Step: 5
Training loss: 4.112491607666016
Validation loss: 3.0088750085523053

Epoch: 6| Step: 6
Training loss: 2.696713447570801
Validation loss: 3.0066483559147006

Epoch: 6| Step: 7
Training loss: 2.6700973510742188
Validation loss: 3.006115795463644

Epoch: 6| Step: 8
Training loss: 3.670632839202881
Validation loss: 3.004945724241195

Epoch: 6| Step: 9
Training loss: 1.895019292831421
Validation loss: 3.002750322382937

Epoch: 6| Step: 10
Training loss: 4.10347843170166
Validation loss: 2.9974224516140517

Epoch: 6| Step: 11
Training loss: 2.653747797012329
Validation loss: 2.996864611102689

Epoch: 6| Step: 12
Training loss: 3.2438433170318604
Validation loss: 2.99737641631916

Epoch: 6| Step: 13
Training loss: 3.5226783752441406
Validation loss: 2.9934609628492788

Epoch: 21| Step: 0
Training loss: 2.7763490676879883
Validation loss: 2.986594012988511

Epoch: 6| Step: 1
Training loss: 3.563464641571045
Validation loss: 2.987431708202567

Epoch: 6| Step: 2
Training loss: 2.8027172088623047
Validation loss: 2.9876812504183863

Epoch: 6| Step: 3
Training loss: 2.0969858169555664
Validation loss: 2.985355579724876

Epoch: 6| Step: 4
Training loss: 2.738252639770508
Validation loss: 2.989227525649532

Epoch: 6| Step: 5
Training loss: 3.2694926261901855
Validation loss: 2.996999748291508

Epoch: 6| Step: 6
Training loss: 3.376002311706543
Validation loss: 2.9813191967625774

Epoch: 6| Step: 7
Training loss: 1.9464311599731445
Validation loss: 2.97661930002192

Epoch: 6| Step: 8
Training loss: 2.5466651916503906
Validation loss: 2.978369225737869

Epoch: 6| Step: 9
Training loss: 2.7484638690948486
Validation loss: 2.9794706554823023

Epoch: 6| Step: 10
Training loss: 2.8474364280700684
Validation loss: 2.989667623273788

Epoch: 6| Step: 11
Training loss: 4.348556995391846
Validation loss: 3.0002630654201714

Epoch: 6| Step: 12
Training loss: 4.6309614181518555
Validation loss: 3.0042927239530828

Epoch: 6| Step: 13
Training loss: 3.0391664505004883
Validation loss: 2.9842909843690935

Epoch: 22| Step: 0
Training loss: 3.1092796325683594
Validation loss: 2.975430473204582

Epoch: 6| Step: 1
Training loss: 2.7741446495056152
Validation loss: 2.9726307289574736

Epoch: 6| Step: 2
Training loss: 2.199803352355957
Validation loss: 2.9703525855977047

Epoch: 6| Step: 3
Training loss: 3.220545530319214
Validation loss: 2.9759786128997803

Epoch: 6| Step: 4
Training loss: 3.230926990509033
Validation loss: 2.972876982022357

Epoch: 6| Step: 5
Training loss: 3.276780843734741
Validation loss: 2.9676537616278535

Epoch: 6| Step: 6
Training loss: 2.980030059814453
Validation loss: 2.9625917403928694

Epoch: 6| Step: 7
Training loss: 3.089451313018799
Validation loss: 2.960001617349604

Epoch: 6| Step: 8
Training loss: 2.494551420211792
Validation loss: 2.958220956146076

Epoch: 6| Step: 9
Training loss: 4.137918472290039
Validation loss: 2.9594674136049006

Epoch: 6| Step: 10
Training loss: 2.8313236236572266
Validation loss: 2.956603785996796

Epoch: 6| Step: 11
Training loss: 3.313218593597412
Validation loss: 2.951852916389383

Epoch: 6| Step: 12
Training loss: 2.583339214324951
Validation loss: 2.9511890872832267

Epoch: 6| Step: 13
Training loss: 3.5433411598205566
Validation loss: 2.9495706891500824

Epoch: 23| Step: 0
Training loss: 2.896738052368164
Validation loss: 2.9466523637053785

Epoch: 6| Step: 1
Training loss: 3.7722010612487793
Validation loss: 2.9424486852461293

Epoch: 6| Step: 2
Training loss: 2.915431499481201
Validation loss: 2.9425963535103747

Epoch: 6| Step: 3
Training loss: 3.8835134506225586
Validation loss: 2.9404017797080417

Epoch: 6| Step: 4
Training loss: 3.2798104286193848
Validation loss: 2.935747259406633

Epoch: 6| Step: 5
Training loss: 2.9950294494628906
Validation loss: 2.9328352661542993

Epoch: 6| Step: 6
Training loss: 3.4617743492126465
Validation loss: 2.930569556451613

Epoch: 6| Step: 7
Training loss: 1.8717119693756104
Validation loss: 2.9291867748383553

Epoch: 6| Step: 8
Training loss: 3.131589412689209
Validation loss: 2.9295474508757233

Epoch: 6| Step: 9
Training loss: 3.517312526702881
Validation loss: 2.926357653833205

Epoch: 6| Step: 10
Training loss: 3.096377372741699
Validation loss: 2.9255800683011293

Epoch: 6| Step: 11
Training loss: 2.5919158458709717
Validation loss: 2.924125599604781

Epoch: 6| Step: 12
Training loss: 2.427917718887329
Validation loss: 2.9268541156604724

Epoch: 6| Step: 13
Training loss: 1.939992904663086
Validation loss: 2.927704272731658

Epoch: 24| Step: 0
Training loss: 3.229191780090332
Validation loss: 2.918688892036356

Epoch: 6| Step: 1
Training loss: 3.1088128089904785
Validation loss: 2.917152209948468

Epoch: 6| Step: 2
Training loss: 2.79477596282959
Validation loss: 2.922343623253607

Epoch: 6| Step: 3
Training loss: 3.167175531387329
Validation loss: 2.92871077599064

Epoch: 6| Step: 4
Training loss: 3.018980026245117
Validation loss: 2.9334795398096882

Epoch: 6| Step: 5
Training loss: 1.9114359617233276
Validation loss: 2.9177016340276247

Epoch: 6| Step: 6
Training loss: 3.5899720191955566
Validation loss: 2.904194862611832

Epoch: 6| Step: 7
Training loss: 2.990264415740967
Validation loss: 2.90426694193194

Epoch: 6| Step: 8
Training loss: 3.739457368850708
Validation loss: 2.907950860197826

Epoch: 6| Step: 9
Training loss: 3.7362518310546875
Validation loss: 2.9121790726979575

Epoch: 6| Step: 10
Training loss: 2.908630847930908
Validation loss: 2.910755770180815

Epoch: 6| Step: 11
Training loss: 2.974644660949707
Validation loss: 2.924145434492378

Epoch: 6| Step: 12
Training loss: 2.4778220653533936
Validation loss: 2.9284000037818827

Epoch: 6| Step: 13
Training loss: 1.9238115549087524
Validation loss: 2.916940332740866

Epoch: 25| Step: 0
Training loss: 3.275118589401245
Validation loss: 2.9038738896769862

Epoch: 6| Step: 1
Training loss: 3.213468551635742
Validation loss: 2.8979159170581448

Epoch: 6| Step: 2
Training loss: 3.3471081256866455
Validation loss: 2.898208543818484

Epoch: 6| Step: 3
Training loss: 3.1145339012145996
Validation loss: 2.8958332564241145

Epoch: 6| Step: 4
Training loss: 1.9122390747070312
Validation loss: 2.899226083550402

Epoch: 6| Step: 5
Training loss: 3.729628801345825
Validation loss: 2.9045264515825497

Epoch: 6| Step: 6
Training loss: 2.950413465499878
Validation loss: 2.8968934371907222

Epoch: 6| Step: 7
Training loss: 3.227998733520508
Validation loss: 2.898000829963274

Epoch: 6| Step: 8
Training loss: 2.534416437149048
Validation loss: 2.8960998545410814

Epoch: 6| Step: 9
Training loss: 3.398632526397705
Validation loss: 2.896208358067338

Epoch: 6| Step: 10
Training loss: 3.01767635345459
Validation loss: 2.888019815568001

Epoch: 6| Step: 11
Training loss: 3.3465213775634766
Validation loss: 2.880989841235581

Epoch: 6| Step: 12
Training loss: 2.3537261486053467
Validation loss: 2.8785945984625045

Epoch: 6| Step: 13
Training loss: 1.9683115482330322
Validation loss: 2.8781137056248163

Epoch: 26| Step: 0
Training loss: 2.1631970405578613
Validation loss: 2.8704670577920894

Epoch: 6| Step: 1
Training loss: 2.5653188228607178
Validation loss: 2.872803734194848

Epoch: 6| Step: 2
Training loss: 2.7619881629943848
Validation loss: 2.874893808877596

Epoch: 6| Step: 3
Training loss: 3.4733123779296875
Validation loss: 2.8736801096188125

Epoch: 6| Step: 4
Training loss: 3.61680269241333
Validation loss: 2.879946898388606

Epoch: 6| Step: 5
Training loss: 3.1738033294677734
Validation loss: 2.874604002121956

Epoch: 6| Step: 6
Training loss: 3.5050196647644043
Validation loss: 2.876612965778638

Epoch: 6| Step: 7
Training loss: 1.8473140001296997
Validation loss: 2.863892052763252

Epoch: 6| Step: 8
Training loss: 2.165189027786255
Validation loss: 2.8572947312426824

Epoch: 6| Step: 9
Training loss: 3.3895578384399414
Validation loss: 2.858237656213904

Epoch: 6| Step: 10
Training loss: 3.0324244499206543
Validation loss: 2.8607568689571914

Epoch: 6| Step: 11
Training loss: 2.6295011043548584
Validation loss: 2.861168879334645

Epoch: 6| Step: 12
Training loss: 3.9702727794647217
Validation loss: 2.864818093597248

Epoch: 6| Step: 13
Training loss: 3.5470266342163086
Validation loss: 2.8572507596785024

Epoch: 27| Step: 0
Training loss: 2.711613655090332
Validation loss: 2.8554246092355378

Epoch: 6| Step: 1
Training loss: 2.126110076904297
Validation loss: 2.8532741377430577

Epoch: 6| Step: 2
Training loss: 3.3369622230529785
Validation loss: 2.850558962873233

Epoch: 6| Step: 3
Training loss: 3.775489330291748
Validation loss: 2.849034816988053

Epoch: 6| Step: 4
Training loss: 3.16041898727417
Validation loss: 2.849565400872179

Epoch: 6| Step: 5
Training loss: 3.6187984943389893
Validation loss: 2.8483372362711097

Epoch: 6| Step: 6
Training loss: 3.2298953533172607
Validation loss: 2.8465572211050216

Epoch: 6| Step: 7
Training loss: 2.298004627227783
Validation loss: 2.8395867962991037

Epoch: 6| Step: 8
Training loss: 3.208620309829712
Validation loss: 2.8364338233906734

Epoch: 6| Step: 9
Training loss: 3.205604076385498
Validation loss: 2.836593186983498

Epoch: 6| Step: 10
Training loss: 3.0113325119018555
Validation loss: 2.8361769312171528

Epoch: 6| Step: 11
Training loss: 2.5440335273742676
Validation loss: 2.839781330477807

Epoch: 6| Step: 12
Training loss: 2.768223762512207
Validation loss: 2.8374526987793627

Epoch: 6| Step: 13
Training loss: 1.958445429801941
Validation loss: 2.832436828203099

Epoch: 28| Step: 0
Training loss: 3.9848475456237793
Validation loss: 2.8365210102450464

Epoch: 6| Step: 1
Training loss: 2.399968385696411
Validation loss: 2.8305458663612284

Epoch: 6| Step: 2
Training loss: 2.7606325149536133
Validation loss: 2.8303233654268327

Epoch: 6| Step: 3
Training loss: 2.7844924926757812
Validation loss: 2.8237869457532

Epoch: 6| Step: 4
Training loss: 2.449739456176758
Validation loss: 2.82179424583271

Epoch: 6| Step: 5
Training loss: 2.6954710483551025
Validation loss: 2.819457036192699

Epoch: 6| Step: 6
Training loss: 2.6100826263427734
Validation loss: 2.8191705134607132

Epoch: 6| Step: 7
Training loss: 2.4807090759277344
Validation loss: 2.8192831623938774

Epoch: 6| Step: 8
Training loss: 3.068619966506958
Validation loss: 2.8200887941545054

Epoch: 6| Step: 9
Training loss: 3.9399657249450684
Validation loss: 2.816174958341865

Epoch: 6| Step: 10
Training loss: 2.994892120361328
Validation loss: 2.8146820093995784

Epoch: 6| Step: 11
Training loss: 2.824268341064453
Validation loss: 2.8123574692715883

Epoch: 6| Step: 12
Training loss: 2.872220993041992
Validation loss: 2.809546637278731

Epoch: 6| Step: 13
Training loss: 3.636420249938965
Validation loss: 2.810379925594535

Epoch: 29| Step: 0
Training loss: 2.8071956634521484
Validation loss: 2.8113298390501287

Epoch: 6| Step: 1
Training loss: 1.7495930194854736
Validation loss: 2.814328437210411

Epoch: 6| Step: 2
Training loss: 3.436160087585449
Validation loss: 2.8165480372726277

Epoch: 6| Step: 3
Training loss: 3.3730785846710205
Validation loss: 2.8101313652530795

Epoch: 6| Step: 4
Training loss: 3.065854549407959
Validation loss: 2.808264458051292

Epoch: 6| Step: 5
Training loss: 3.200669288635254
Validation loss: 2.8043679575766287

Epoch: 6| Step: 6
Training loss: 3.8413169384002686
Validation loss: 2.8004670989128853

Epoch: 6| Step: 7
Training loss: 2.694901466369629
Validation loss: 2.7995145807984056

Epoch: 6| Step: 8
Training loss: 2.9096827507019043
Validation loss: 2.7995355975243355

Epoch: 6| Step: 9
Training loss: 2.3792905807495117
Validation loss: 2.8002218713042555

Epoch: 6| Step: 10
Training loss: 2.5713112354278564
Validation loss: 2.805250447283509

Epoch: 6| Step: 11
Training loss: 3.1203880310058594
Validation loss: 2.8144780538415395

Epoch: 6| Step: 12
Training loss: 3.026230812072754
Validation loss: 2.8061913264695035

Epoch: 6| Step: 13
Training loss: 2.817765474319458
Validation loss: 2.8002115398324947

Epoch: 30| Step: 0
Training loss: 3.685854911804199
Validation loss: 2.7961310545603433

Epoch: 6| Step: 1
Training loss: 3.585994243621826
Validation loss: 2.7919931463015977

Epoch: 6| Step: 2
Training loss: 1.634586215019226
Validation loss: 2.796353627276677

Epoch: 6| Step: 3
Training loss: 3.283280372619629
Validation loss: 2.7965227455221195

Epoch: 6| Step: 4
Training loss: 2.4604477882385254
Validation loss: 2.803820079372775

Epoch: 6| Step: 5
Training loss: 2.518616199493408
Validation loss: 2.804310978099864

Epoch: 6| Step: 6
Training loss: 3.0271899700164795
Validation loss: 2.79142516146424

Epoch: 6| Step: 7
Training loss: 1.643797516822815
Validation loss: 2.7874923675291

Epoch: 6| Step: 8
Training loss: 3.648998498916626
Validation loss: 2.788099645286478

Epoch: 6| Step: 9
Training loss: 2.7632436752319336
Validation loss: 2.7887405477544314

Epoch: 6| Step: 10
Training loss: 3.507380485534668
Validation loss: 2.790427146419402

Epoch: 6| Step: 11
Training loss: 3.079131603240967
Validation loss: 2.7859060251584618

Epoch: 6| Step: 12
Training loss: 2.611433267593384
Validation loss: 2.788221502816805

Epoch: 6| Step: 13
Training loss: 3.9057857990264893
Validation loss: 2.7859843648890013

Epoch: 31| Step: 0
Training loss: 3.308175563812256
Validation loss: 2.7873427714070966

Epoch: 6| Step: 1
Training loss: 1.7635997533798218
Validation loss: 2.7849474260883946

Epoch: 6| Step: 2
Training loss: 2.0544729232788086
Validation loss: 2.780571199232532

Epoch: 6| Step: 3
Training loss: 3.567194938659668
Validation loss: 2.782441544276412

Epoch: 6| Step: 4
Training loss: 4.134791374206543
Validation loss: 2.780047861478662

Epoch: 6| Step: 5
Training loss: 3.0579099655151367
Validation loss: 2.779906595906904

Epoch: 6| Step: 6
Training loss: 2.830268383026123
Validation loss: 2.7792693594450593

Epoch: 6| Step: 7
Training loss: 3.133906841278076
Validation loss: 2.7804897574968237

Epoch: 6| Step: 8
Training loss: 2.422901153564453
Validation loss: 2.7762939237779185

Epoch: 6| Step: 9
Training loss: 2.9498205184936523
Validation loss: 2.7759797291089128

Epoch: 6| Step: 10
Training loss: 2.596957206726074
Validation loss: 2.774294199482087

Epoch: 6| Step: 11
Training loss: 3.3656091690063477
Validation loss: 2.7759719894778345

Epoch: 6| Step: 12
Training loss: 2.616140365600586
Validation loss: 2.7729993481789865

Epoch: 6| Step: 13
Training loss: 3.0988571643829346
Validation loss: 2.7734115713386127

Epoch: 32| Step: 0
Training loss: 3.039186716079712
Validation loss: 2.7726940467793453

Epoch: 6| Step: 1
Training loss: 3.522190570831299
Validation loss: 2.7689421458910872

Epoch: 6| Step: 2
Training loss: 2.778794527053833
Validation loss: 2.7677092090729745

Epoch: 6| Step: 3
Training loss: 2.638530731201172
Validation loss: 2.7697340929380028

Epoch: 6| Step: 4
Training loss: 3.495281219482422
Validation loss: 2.7670663864381853

Epoch: 6| Step: 5
Training loss: 3.65433931350708
Validation loss: 2.7689488600659113

Epoch: 6| Step: 6
Training loss: 2.1233022212982178
Validation loss: 2.7662644745201193

Epoch: 6| Step: 7
Training loss: 2.342848539352417
Validation loss: 2.7664409273414203

Epoch: 6| Step: 8
Training loss: 3.054394245147705
Validation loss: 2.7676517040498796

Epoch: 6| Step: 9
Training loss: 3.00896954536438
Validation loss: 2.7683056964669177

Epoch: 6| Step: 10
Training loss: 3.207504987716675
Validation loss: 2.7659937822690575

Epoch: 6| Step: 11
Training loss: 1.9244656562805176
Validation loss: 2.7658915519714355

Epoch: 6| Step: 12
Training loss: 3.194101333618164
Validation loss: 2.7647639064378637

Epoch: 6| Step: 13
Training loss: 2.5680723190307617
Validation loss: 2.7640765482379543

Epoch: 33| Step: 0
Training loss: 2.3278238773345947
Validation loss: 2.7639694572776876

Epoch: 6| Step: 1
Training loss: 2.5149242877960205
Validation loss: 2.7676258522977113

Epoch: 6| Step: 2
Training loss: 3.755269765853882
Validation loss: 2.7623245203366844

Epoch: 6| Step: 3
Training loss: 3.196176052093506
Validation loss: 2.76259587400703

Epoch: 6| Step: 4
Training loss: 2.6431949138641357
Validation loss: 2.7636967858960553

Epoch: 6| Step: 5
Training loss: 3.057619094848633
Validation loss: 2.761829173693093

Epoch: 6| Step: 6
Training loss: 3.221562147140503
Validation loss: 2.763439106684859

Epoch: 6| Step: 7
Training loss: 2.7005529403686523
Validation loss: 2.7624070080377723

Epoch: 6| Step: 8
Training loss: 2.8527300357818604
Validation loss: 2.7594462569041918

Epoch: 6| Step: 9
Training loss: 2.4272773265838623
Validation loss: 2.759068230147003

Epoch: 6| Step: 10
Training loss: 2.90374755859375
Validation loss: 2.7584850736843642

Epoch: 6| Step: 11
Training loss: 2.9642019271850586
Validation loss: 2.7590739650111042

Epoch: 6| Step: 12
Training loss: 2.9389100074768066
Validation loss: 2.7565479842565392

Epoch: 6| Step: 13
Training loss: 3.2353506088256836
Validation loss: 2.759184488686182

Epoch: 34| Step: 0
Training loss: 3.170090436935425
Validation loss: 2.758151346637357

Epoch: 6| Step: 1
Training loss: 2.452108383178711
Validation loss: 2.758312999561269

Epoch: 6| Step: 2
Training loss: 3.187713146209717
Validation loss: 2.765111674544632

Epoch: 6| Step: 3
Training loss: 2.6476645469665527
Validation loss: 2.763534584353047

Epoch: 6| Step: 4
Training loss: 1.9303035736083984
Validation loss: 2.7659523333272626

Epoch: 6| Step: 5
Training loss: 3.22861909866333
Validation loss: 2.758530701360395

Epoch: 6| Step: 6
Training loss: 2.7284955978393555
Validation loss: 2.7541414973556355

Epoch: 6| Step: 7
Training loss: 2.6218972206115723
Validation loss: 2.7554075743562434

Epoch: 6| Step: 8
Training loss: 3.8799996376037598
Validation loss: 2.752315769913376

Epoch: 6| Step: 9
Training loss: 2.6680564880371094
Validation loss: 2.7517545300145305

Epoch: 6| Step: 10
Training loss: 3.1130359172821045
Validation loss: 2.753597964522659

Epoch: 6| Step: 11
Training loss: 2.9865102767944336
Validation loss: 2.7520195796925533

Epoch: 6| Step: 12
Training loss: 3.0042521953582764
Validation loss: 2.755981663221954

Epoch: 6| Step: 13
Training loss: 2.8958053588867188
Validation loss: 2.753347594250915

Epoch: 35| Step: 0
Training loss: 2.6161835193634033
Validation loss: 2.7546108820105113

Epoch: 6| Step: 1
Training loss: 2.762585163116455
Validation loss: 2.748947323009532

Epoch: 6| Step: 2
Training loss: 2.5656166076660156
Validation loss: 2.744355647794662

Epoch: 6| Step: 3
Training loss: 2.868037223815918
Validation loss: 2.7519029109708724

Epoch: 6| Step: 4
Training loss: 2.7144699096679688
Validation loss: 2.7485987755560104

Epoch: 6| Step: 5
Training loss: 3.239194631576538
Validation loss: 2.7481458597285773

Epoch: 6| Step: 6
Training loss: 3.048814535140991
Validation loss: 2.7490586362859255

Epoch: 6| Step: 7
Training loss: 2.2967209815979004
Validation loss: 2.7449512302234607

Epoch: 6| Step: 8
Training loss: 3.1001930236816406
Validation loss: 2.7476937270933584

Epoch: 6| Step: 9
Training loss: 2.4779441356658936
Validation loss: 2.742538280384515

Epoch: 6| Step: 10
Training loss: 3.160862445831299
Validation loss: 2.7413096171553417

Epoch: 6| Step: 11
Training loss: 2.4762191772460938
Validation loss: 2.7424291744027087

Epoch: 6| Step: 12
Training loss: 3.927999496459961
Validation loss: 2.7390217806703303

Epoch: 6| Step: 13
Training loss: 3.56341290473938
Validation loss: 2.742415323052355

Epoch: 36| Step: 0
Training loss: 3.1064090728759766
Validation loss: 2.739766720802553

Epoch: 6| Step: 1
Training loss: 3.3553884029388428
Validation loss: 2.7398500057958786

Epoch: 6| Step: 2
Training loss: 3.4386301040649414
Validation loss: 2.7401412738266813

Epoch: 6| Step: 3
Training loss: 2.6046805381774902
Validation loss: 2.7447859984572216

Epoch: 6| Step: 4
Training loss: 4.037571430206299
Validation loss: 2.7427525520324707

Epoch: 6| Step: 5
Training loss: 2.101200580596924
Validation loss: 2.7413162646755094

Epoch: 6| Step: 6
Training loss: 3.2994492053985596
Validation loss: 2.7412924945995374

Epoch: 6| Step: 7
Training loss: 2.0829830169677734
Validation loss: 2.74324042566361

Epoch: 6| Step: 8
Training loss: 2.8871312141418457
Validation loss: 2.7367925233738397

Epoch: 6| Step: 9
Training loss: 2.340984344482422
Validation loss: 2.739004324841243

Epoch: 6| Step: 10
Training loss: 2.870605230331421
Validation loss: 2.7399971638956377

Epoch: 6| Step: 11
Training loss: 3.126563310623169
Validation loss: 2.7458251496796966

Epoch: 6| Step: 12
Training loss: 2.2232816219329834
Validation loss: 2.751650643605058

Epoch: 6| Step: 13
Training loss: 2.98309588432312
Validation loss: 2.7444567603449666

Epoch: 37| Step: 0
Training loss: 2.6512598991394043
Validation loss: 2.7420081195010932

Epoch: 6| Step: 1
Training loss: 2.6179394721984863
Validation loss: 2.7396334140531478

Epoch: 6| Step: 2
Training loss: 2.9910547733306885
Validation loss: 2.7385344889856156

Epoch: 6| Step: 3
Training loss: 2.584965229034424
Validation loss: 2.741301821124169

Epoch: 6| Step: 4
Training loss: 2.4691314697265625
Validation loss: 2.7452933531935497

Epoch: 6| Step: 5
Training loss: 2.719883441925049
Validation loss: 2.7575823594165105

Epoch: 6| Step: 6
Training loss: 2.9820051193237305
Validation loss: 2.7492744384273404

Epoch: 6| Step: 7
Training loss: 3.5065298080444336
Validation loss: 2.7644547980318785

Epoch: 6| Step: 8
Training loss: 2.5792880058288574
Validation loss: 2.753827743632819

Epoch: 6| Step: 9
Training loss: 2.514232635498047
Validation loss: 2.7402094461584605

Epoch: 6| Step: 10
Training loss: 3.2423267364501953
Validation loss: 2.7351736227671304

Epoch: 6| Step: 11
Training loss: 3.8643031120300293
Validation loss: 2.7334949072971138

Epoch: 6| Step: 12
Training loss: 3.1719446182250977
Validation loss: 2.7353788345090804

Epoch: 6| Step: 13
Training loss: 2.2262167930603027
Validation loss: 2.733826780831942

Epoch: 38| Step: 0
Training loss: 3.784736156463623
Validation loss: 2.7330581629148094

Epoch: 6| Step: 1
Training loss: 3.126307487487793
Validation loss: 2.732117329874346

Epoch: 6| Step: 2
Training loss: 3.545687675476074
Validation loss: 2.7346893151601157

Epoch: 6| Step: 3
Training loss: 2.2196896076202393
Validation loss: 2.732880510309691

Epoch: 6| Step: 4
Training loss: 2.7387290000915527
Validation loss: 2.7347735692096014

Epoch: 6| Step: 5
Training loss: 2.544229507446289
Validation loss: 2.731578416721795

Epoch: 6| Step: 6
Training loss: 2.764719009399414
Validation loss: 2.7299032339485745

Epoch: 6| Step: 7
Training loss: 2.7883810997009277
Validation loss: 2.732160396473382

Epoch: 6| Step: 8
Training loss: 2.5562620162963867
Validation loss: 2.730569016548895

Epoch: 6| Step: 9
Training loss: 2.224297046661377
Validation loss: 2.726861276934224

Epoch: 6| Step: 10
Training loss: 2.9452829360961914
Validation loss: 2.7295987157411474

Epoch: 6| Step: 11
Training loss: 3.105198383331299
Validation loss: 2.7406228178290912

Epoch: 6| Step: 12
Training loss: 2.534092903137207
Validation loss: 2.7382460589049966

Epoch: 6| Step: 13
Training loss: 3.902557373046875
Validation loss: 2.7329454601451917

Epoch: 39| Step: 0
Training loss: 2.1714413166046143
Validation loss: 2.731637821402601

Epoch: 6| Step: 1
Training loss: 3.4810290336608887
Validation loss: 2.7275465560215775

Epoch: 6| Step: 2
Training loss: 2.1178226470947266
Validation loss: 2.7250969179214968

Epoch: 6| Step: 3
Training loss: 3.0243687629699707
Validation loss: 2.7275990234908236

Epoch: 6| Step: 4
Training loss: 2.3213882446289062
Validation loss: 2.7292120290058914

Epoch: 6| Step: 5
Training loss: 3.115950107574463
Validation loss: 2.728324577372561

Epoch: 6| Step: 6
Training loss: 2.5300393104553223
Validation loss: 2.7205868792790238

Epoch: 6| Step: 7
Training loss: 3.091362476348877
Validation loss: 2.7247647790498633

Epoch: 6| Step: 8
Training loss: 3.1033666133880615
Validation loss: 2.722711488764773

Epoch: 6| Step: 9
Training loss: 3.3143486976623535
Validation loss: 2.7199446642270653

Epoch: 6| Step: 10
Training loss: 2.59293532371521
Validation loss: 2.7236778505386843

Epoch: 6| Step: 11
Training loss: 2.970938205718994
Validation loss: 2.7203482761177966

Epoch: 6| Step: 12
Training loss: 3.3002400398254395
Validation loss: 2.7215570147319506

Epoch: 6| Step: 13
Training loss: 3.265305519104004
Validation loss: 2.720075535517867

Epoch: 40| Step: 0
Training loss: 2.719675302505493
Validation loss: 2.7215962127972673

Epoch: 6| Step: 1
Training loss: 1.7326905727386475
Validation loss: 2.721416688734485

Epoch: 6| Step: 2
Training loss: 2.901571750640869
Validation loss: 2.719193245774956

Epoch: 6| Step: 3
Training loss: 3.210416793823242
Validation loss: 2.7189690387377174

Epoch: 6| Step: 4
Training loss: 3.035301685333252
Validation loss: 2.7216367055011053

Epoch: 6| Step: 5
Training loss: 3.0461339950561523
Validation loss: 2.7184304319402224

Epoch: 6| Step: 6
Training loss: 3.534066677093506
Validation loss: 2.7190648278882428

Epoch: 6| Step: 7
Training loss: 3.2002031803131104
Validation loss: 2.721317691187705

Epoch: 6| Step: 8
Training loss: 2.0697779655456543
Validation loss: 2.7162542727685746

Epoch: 6| Step: 9
Training loss: 2.5818350315093994
Validation loss: 2.72098268488402

Epoch: 6| Step: 10
Training loss: 3.603360652923584
Validation loss: 2.7242548209364696

Epoch: 6| Step: 11
Training loss: 3.2503280639648438
Validation loss: 2.722745633894397

Epoch: 6| Step: 12
Training loss: 2.3098864555358887
Validation loss: 2.7223180417091615

Epoch: 6| Step: 13
Training loss: 3.2023532390594482
Validation loss: 2.7189372867666264

Epoch: 41| Step: 0
Training loss: 3.638988494873047
Validation loss: 2.7134302790446947

Epoch: 6| Step: 1
Training loss: 3.3428215980529785
Validation loss: 2.712409173288653

Epoch: 6| Step: 2
Training loss: 2.6977040767669678
Validation loss: 2.714996676291189

Epoch: 6| Step: 3
Training loss: 2.462446451187134
Validation loss: 2.715729208402736

Epoch: 6| Step: 4
Training loss: 1.8190438747406006
Validation loss: 2.717032549201801

Epoch: 6| Step: 5
Training loss: 2.8450775146484375
Validation loss: 2.7220147399492163

Epoch: 6| Step: 6
Training loss: 3.2571611404418945
Validation loss: 2.730631600144089

Epoch: 6| Step: 7
Training loss: 2.8494772911071777
Validation loss: 2.714672791060581

Epoch: 6| Step: 8
Training loss: 2.8328585624694824
Validation loss: 2.714889931422408

Epoch: 6| Step: 9
Training loss: 3.554701566696167
Validation loss: 2.710797614948724

Epoch: 6| Step: 10
Training loss: 3.2806899547576904
Validation loss: 2.711956831716722

Epoch: 6| Step: 11
Training loss: 1.9969751834869385
Validation loss: 2.7104609397149857

Epoch: 6| Step: 12
Training loss: 2.63594913482666
Validation loss: 2.70634300093497

Epoch: 6| Step: 13
Training loss: 3.076277732849121
Validation loss: 2.7084139623949604

Epoch: 42| Step: 0
Training loss: 2.774634599685669
Validation loss: 2.7109132607777915

Epoch: 6| Step: 1
Training loss: 2.5818166732788086
Validation loss: 2.711779086820541

Epoch: 6| Step: 2
Training loss: 3.212045669555664
Validation loss: 2.712395627011535

Epoch: 6| Step: 3
Training loss: 2.925826072692871
Validation loss: 2.712359320732855

Epoch: 6| Step: 4
Training loss: 3.842986583709717
Validation loss: 2.7122634815913376

Epoch: 6| Step: 5
Training loss: 2.622469663619995
Validation loss: 2.7133124823211343

Epoch: 6| Step: 6
Training loss: 2.705775737762451
Validation loss: 2.7120744464217976

Epoch: 6| Step: 7
Training loss: 2.7125067710876465
Validation loss: 2.713427056548416

Epoch: 6| Step: 8
Training loss: 3.28133487701416
Validation loss: 2.71163147752003

Epoch: 6| Step: 9
Training loss: 2.418483257293701
Validation loss: 2.7087574261491016

Epoch: 6| Step: 10
Training loss: 2.9890828132629395
Validation loss: 2.707174362674836

Epoch: 6| Step: 11
Training loss: 2.759566068649292
Validation loss: 2.7033604832105738

Epoch: 6| Step: 12
Training loss: 2.700780153274536
Validation loss: 2.706972486229353

Epoch: 6| Step: 13
Training loss: 2.49050235748291
Validation loss: 2.709377178581812

Epoch: 43| Step: 0
Training loss: 2.934981107711792
Validation loss: 2.711741319266699

Epoch: 6| Step: 1
Training loss: 3.505159854888916
Validation loss: 2.7056663010710027

Epoch: 6| Step: 2
Training loss: 3.0400314331054688
Validation loss: 2.705492547763291

Epoch: 6| Step: 3
Training loss: 3.2239787578582764
Validation loss: 2.7038342234908894

Epoch: 6| Step: 4
Training loss: 2.7969369888305664
Validation loss: 2.7031517515900316

Epoch: 6| Step: 5
Training loss: 3.1438686847686768
Validation loss: 2.702836923701789

Epoch: 6| Step: 6
Training loss: 2.244363307952881
Validation loss: 2.7019538212847967

Epoch: 6| Step: 7
Training loss: 2.5446693897247314
Validation loss: 2.7034919518296436

Epoch: 6| Step: 8
Training loss: 2.9142324924468994
Validation loss: 2.701521911928731

Epoch: 6| Step: 9
Training loss: 2.7034361362457275
Validation loss: 2.697993234921527

Epoch: 6| Step: 10
Training loss: 2.955404281616211
Validation loss: 2.6992747809297297

Epoch: 6| Step: 11
Training loss: 2.789961576461792
Validation loss: 2.6973780637146323

Epoch: 6| Step: 12
Training loss: 2.8421778678894043
Validation loss: 2.7013101731577227

Epoch: 6| Step: 13
Training loss: 2.1413638591766357
Validation loss: 2.7023925447976715

Epoch: 44| Step: 0
Training loss: 2.3738930225372314
Validation loss: 2.7034924850668958

Epoch: 6| Step: 1
Training loss: 2.4407296180725098
Validation loss: 2.703530557693974

Epoch: 6| Step: 2
Training loss: 3.5890183448791504
Validation loss: 2.7064832307959117

Epoch: 6| Step: 3
Training loss: 2.7353687286376953
Validation loss: 2.6991307940534366

Epoch: 6| Step: 4
Training loss: 3.028520107269287
Validation loss: 2.699438715493807

Epoch: 6| Step: 5
Training loss: 1.9957962036132812
Validation loss: 2.7039369870257635

Epoch: 6| Step: 6
Training loss: 3.0375049114227295
Validation loss: 2.7020354373480684

Epoch: 6| Step: 7
Training loss: 2.4722776412963867
Validation loss: 2.7036212823724233

Epoch: 6| Step: 8
Training loss: 2.769439458847046
Validation loss: 2.7010431751128166

Epoch: 6| Step: 9
Training loss: 3.426102638244629
Validation loss: 2.7022157894667758

Epoch: 6| Step: 10
Training loss: 2.988201379776001
Validation loss: 2.702137698409378

Epoch: 6| Step: 11
Training loss: 2.4320499897003174
Validation loss: 2.7037018268339095

Epoch: 6| Step: 12
Training loss: 4.025599479675293
Validation loss: 2.704379545745029

Epoch: 6| Step: 13
Training loss: 2.6014490127563477
Validation loss: 2.7031967075922156

Epoch: 45| Step: 0
Training loss: 3.396050453186035
Validation loss: 2.699959675470988

Epoch: 6| Step: 1
Training loss: 2.9988515377044678
Validation loss: 2.698516527811686

Epoch: 6| Step: 2
Training loss: 3.1875274181365967
Validation loss: 2.6973097068007275

Epoch: 6| Step: 3
Training loss: 2.771512985229492
Validation loss: 2.6969596903811217

Epoch: 6| Step: 4
Training loss: 3.113407611846924
Validation loss: 2.7015375885912167

Epoch: 6| Step: 5
Training loss: 3.0061349868774414
Validation loss: 2.7004571371181036

Epoch: 6| Step: 6
Training loss: 3.057522773742676
Validation loss: 2.69933577763137

Epoch: 6| Step: 7
Training loss: 2.796536684036255
Validation loss: 2.6962705760873775

Epoch: 6| Step: 8
Training loss: 2.5396950244903564
Validation loss: 2.6931637282012613

Epoch: 6| Step: 9
Training loss: 2.4158918857574463
Validation loss: 2.696487985631471

Epoch: 6| Step: 10
Training loss: 3.031679391860962
Validation loss: 2.6939843393141225

Epoch: 6| Step: 11
Training loss: 2.083296775817871
Validation loss: 2.6928112737594114

Epoch: 6| Step: 12
Training loss: 2.6101155281066895
Validation loss: 2.6911836157562914

Epoch: 6| Step: 13
Training loss: 3.1494131088256836
Validation loss: 2.691596805408437

Epoch: 46| Step: 0
Training loss: 2.6730222702026367
Validation loss: 2.688125430896718

Epoch: 6| Step: 1
Training loss: 3.9687459468841553
Validation loss: 2.6967122554779053

Epoch: 6| Step: 2
Training loss: 3.457266330718994
Validation loss: 2.691154618417063

Epoch: 6| Step: 3
Training loss: 2.5414741039276123
Validation loss: 2.68908215338184

Epoch: 6| Step: 4
Training loss: 2.070531129837036
Validation loss: 2.686102867126465

Epoch: 6| Step: 5
Training loss: 2.6737782955169678
Validation loss: 2.6919945004165813

Epoch: 6| Step: 6
Training loss: 2.7583746910095215
Validation loss: 2.6981578693594983

Epoch: 6| Step: 7
Training loss: 2.7263312339782715
Validation loss: 2.6986199296930784

Epoch: 6| Step: 8
Training loss: 2.882697582244873
Validation loss: 2.6958004466948973

Epoch: 6| Step: 9
Training loss: 2.9244985580444336
Validation loss: 2.6954890528032855

Epoch: 6| Step: 10
Training loss: 2.308267593383789
Validation loss: 2.6961576554083053

Epoch: 6| Step: 11
Training loss: 2.796536684036255
Validation loss: 2.691387676423596

Epoch: 6| Step: 12
Training loss: 2.8047635555267334
Validation loss: 2.692311553544896

Epoch: 6| Step: 13
Training loss: 3.7703700065612793
Validation loss: 2.6939395858395483

Epoch: 47| Step: 0
Training loss: 2.7482831478118896
Validation loss: 2.6923354671847437

Epoch: 6| Step: 1
Training loss: 2.7169461250305176
Validation loss: 2.6880409743196223

Epoch: 6| Step: 2
Training loss: 2.4079196453094482
Validation loss: 2.6948398159396265

Epoch: 6| Step: 3
Training loss: 3.383502721786499
Validation loss: 2.6852101100388395

Epoch: 6| Step: 4
Training loss: 3.25665283203125
Validation loss: 2.6944891765553463

Epoch: 6| Step: 5
Training loss: 3.2308859825134277
Validation loss: 2.688675941959504

Epoch: 6| Step: 6
Training loss: 2.9771275520324707
Validation loss: 2.69213544425144

Epoch: 6| Step: 7
Training loss: 2.0523970127105713
Validation loss: 2.683102774363692

Epoch: 6| Step: 8
Training loss: 2.5907511711120605
Validation loss: 2.6833920350638767

Epoch: 6| Step: 9
Training loss: 2.796173572540283
Validation loss: 2.689043488553775

Epoch: 6| Step: 10
Training loss: 2.9466423988342285
Validation loss: 2.691916673414169

Epoch: 6| Step: 11
Training loss: 2.977642297744751
Validation loss: 2.6906108625473513

Epoch: 6| Step: 12
Training loss: 2.9219958782196045
Validation loss: 2.693562815266271

Epoch: 6| Step: 13
Training loss: 2.905914545059204
Validation loss: 2.693599990619126

Epoch: 48| Step: 0
Training loss: 2.7140462398529053
Validation loss: 2.6921971997907086

Epoch: 6| Step: 1
Training loss: 2.5314342975616455
Validation loss: 2.6887664384739374

Epoch: 6| Step: 2
Training loss: 3.4229624271392822
Validation loss: 2.6905825599547355

Epoch: 6| Step: 3
Training loss: 2.958314895629883
Validation loss: 2.6897531683726976

Epoch: 6| Step: 4
Training loss: 3.174485445022583
Validation loss: 2.683616504874281

Epoch: 6| Step: 5
Training loss: 2.4491143226623535
Validation loss: 2.6849764905950075

Epoch: 6| Step: 6
Training loss: 2.9031217098236084
Validation loss: 2.6864215866211922

Epoch: 6| Step: 7
Training loss: 2.5444374084472656
Validation loss: 2.6812213928468767

Epoch: 6| Step: 8
Training loss: 1.9686143398284912
Validation loss: 2.6879232570689213

Epoch: 6| Step: 9
Training loss: 3.1265368461608887
Validation loss: 2.6918043526270057

Epoch: 6| Step: 10
Training loss: 2.3794047832489014
Validation loss: 2.687611336349159

Epoch: 6| Step: 11
Training loss: 3.825106620788574
Validation loss: 2.697233333382555

Epoch: 6| Step: 12
Training loss: 2.8212881088256836
Validation loss: 2.6937392347602436

Epoch: 6| Step: 13
Training loss: 3.3846120834350586
Validation loss: 2.686736196599981

Epoch: 49| Step: 0
Training loss: 1.7998850345611572
Validation loss: 2.6811816307806198

Epoch: 6| Step: 1
Training loss: 3.049457550048828
Validation loss: 2.6834982338772027

Epoch: 6| Step: 2
Training loss: 2.1708223819732666
Validation loss: 2.6823949634387927

Epoch: 6| Step: 3
Training loss: 2.9388837814331055
Validation loss: 2.6820015830378376

Epoch: 6| Step: 4
Training loss: 3.2860541343688965
Validation loss: 2.684204480981314

Epoch: 6| Step: 5
Training loss: 3.480325937271118
Validation loss: 2.682025494114045

Epoch: 6| Step: 6
Training loss: 2.1901745796203613
Validation loss: 2.6899295596666235

Epoch: 6| Step: 7
Training loss: 3.441178798675537
Validation loss: 2.6845797005520073

Epoch: 6| Step: 8
Training loss: 2.8003456592559814
Validation loss: 2.689946090021441

Epoch: 6| Step: 9
Training loss: 2.085211992263794
Validation loss: 2.68533726661436

Epoch: 6| Step: 10
Training loss: 3.861983299255371
Validation loss: 2.6798049301229496

Epoch: 6| Step: 11
Training loss: 2.8761463165283203
Validation loss: 2.67584474625126

Epoch: 6| Step: 12
Training loss: 2.7024898529052734
Validation loss: 2.675908011774863

Epoch: 6| Step: 13
Training loss: 3.4240918159484863
Validation loss: 2.675889389489287

Epoch: 50| Step: 0
Training loss: 2.909849166870117
Validation loss: 2.6819881495609077

Epoch: 6| Step: 1
Training loss: 2.859257221221924
Validation loss: 2.6839949597594557

Epoch: 6| Step: 2
Training loss: 2.892388343811035
Validation loss: 2.6877545669514644

Epoch: 6| Step: 3
Training loss: 3.4336862564086914
Validation loss: 2.6838634167948077

Epoch: 6| Step: 4
Training loss: 2.9026875495910645
Validation loss: 2.6784005267645723

Epoch: 6| Step: 5
Training loss: 2.8368144035339355
Validation loss: 2.6751592210544053

Epoch: 6| Step: 6
Training loss: 2.6193838119506836
Validation loss: 2.672208470682944

Epoch: 6| Step: 7
Training loss: 2.8369221687316895
Validation loss: 2.6773412432721866

Epoch: 6| Step: 8
Training loss: 2.9118709564208984
Validation loss: 2.6799101983347247

Epoch: 6| Step: 9
Training loss: 2.100052833557129
Validation loss: 2.677853074125064

Epoch: 6| Step: 10
Training loss: 3.1100850105285645
Validation loss: 2.676730086726527

Epoch: 6| Step: 11
Training loss: 2.6618175506591797
Validation loss: 2.679716679357713

Epoch: 6| Step: 12
Training loss: 2.289902687072754
Validation loss: 2.6768814671424126

Epoch: 6| Step: 13
Training loss: 3.8293559551239014
Validation loss: 2.6725098932943037

Epoch: 51| Step: 0
Training loss: 2.633849620819092
Validation loss: 2.6745247020516345

Epoch: 6| Step: 1
Training loss: 2.504540205001831
Validation loss: 2.6784358537325295

Epoch: 6| Step: 2
Training loss: 2.9475088119506836
Validation loss: 2.6811477984151533

Epoch: 6| Step: 3
Training loss: 2.9612021446228027
Validation loss: 2.6912185427963093

Epoch: 6| Step: 4
Training loss: 2.8640661239624023
Validation loss: 2.688555758486512

Epoch: 6| Step: 5
Training loss: 2.522038459777832
Validation loss: 2.682965250425441

Epoch: 6| Step: 6
Training loss: 2.9333009719848633
Validation loss: 2.678659756978353

Epoch: 6| Step: 7
Training loss: 2.1289706230163574
Validation loss: 2.67861984878458

Epoch: 6| Step: 8
Training loss: 3.1887712478637695
Validation loss: 2.6727911451811432

Epoch: 6| Step: 9
Training loss: 2.134164810180664
Validation loss: 2.6777014245269117

Epoch: 6| Step: 10
Training loss: 2.162855863571167
Validation loss: 2.6786704499234437

Epoch: 6| Step: 11
Training loss: 3.1275715827941895
Validation loss: 2.6730791573883383

Epoch: 6| Step: 12
Training loss: 4.3696608543396
Validation loss: 2.6738304630402596

Epoch: 6| Step: 13
Training loss: 3.5616488456726074
Validation loss: 2.6712620283967707

Epoch: 52| Step: 0
Training loss: 2.7435765266418457
Validation loss: 2.6720217632991012

Epoch: 6| Step: 1
Training loss: 3.1877260208129883
Validation loss: 2.6721829291312926

Epoch: 6| Step: 2
Training loss: 2.731511354446411
Validation loss: 2.6683445489534767

Epoch: 6| Step: 3
Training loss: 3.5380473136901855
Validation loss: 2.6672440344287502

Epoch: 6| Step: 4
Training loss: 2.666412115097046
Validation loss: 2.6683636378216486

Epoch: 6| Step: 5
Training loss: 3.3178648948669434
Validation loss: 2.6678116834291847

Epoch: 6| Step: 6
Training loss: 2.5344090461730957
Validation loss: 2.668576091848394

Epoch: 6| Step: 7
Training loss: 2.4711837768554688
Validation loss: 2.671830097834269

Epoch: 6| Step: 8
Training loss: 2.754398822784424
Validation loss: 2.6718211558557328

Epoch: 6| Step: 9
Training loss: 3.1759982109069824
Validation loss: 2.6781499872925463

Epoch: 6| Step: 10
Training loss: 2.4352493286132812
Validation loss: 2.6830822498567644

Epoch: 6| Step: 11
Training loss: 2.587800979614258
Validation loss: 2.6877208986589984

Epoch: 6| Step: 12
Training loss: 2.8376922607421875
Validation loss: 2.6756175025816886

Epoch: 6| Step: 13
Training loss: 2.5727033615112305
Validation loss: 2.6771811157144527

Epoch: 53| Step: 0
Training loss: 2.630185604095459
Validation loss: 2.6692932626252532

Epoch: 6| Step: 1
Training loss: 2.771207332611084
Validation loss: 2.6649062069513465

Epoch: 6| Step: 2
Training loss: 2.6852478981018066
Validation loss: 2.6663061829023462

Epoch: 6| Step: 3
Training loss: 3.355902671813965
Validation loss: 2.6652956829276135

Epoch: 6| Step: 4
Training loss: 2.6926326751708984
Validation loss: 2.6611759226809264

Epoch: 6| Step: 5
Training loss: 2.1403322219848633
Validation loss: 2.6621774319679505

Epoch: 6| Step: 6
Training loss: 2.5960912704467773
Validation loss: 2.662064124179143

Epoch: 6| Step: 7
Training loss: 2.885392189025879
Validation loss: 2.663976756475305

Epoch: 6| Step: 8
Training loss: 2.6694746017456055
Validation loss: 2.6650776273460797

Epoch: 6| Step: 9
Training loss: 3.119046688079834
Validation loss: 2.663319592834801

Epoch: 6| Step: 10
Training loss: 3.112105369567871
Validation loss: 2.6624546794481176

Epoch: 6| Step: 11
Training loss: 3.2661855220794678
Validation loss: 2.6699163708635556

Epoch: 6| Step: 12
Training loss: 2.576275110244751
Validation loss: 2.66725343273532

Epoch: 6| Step: 13
Training loss: 3.4059574604034424
Validation loss: 2.6666847864786782

Epoch: 54| Step: 0
Training loss: 2.75907039642334
Validation loss: 2.661360893198239

Epoch: 6| Step: 1
Training loss: 2.9571259021759033
Validation loss: 2.665876498786352

Epoch: 6| Step: 2
Training loss: 2.875584602355957
Validation loss: 2.6733783957778767

Epoch: 6| Step: 3
Training loss: 2.509669780731201
Validation loss: 2.6845335319478023

Epoch: 6| Step: 4
Training loss: 2.16828989982605
Validation loss: 2.710426733057986

Epoch: 6| Step: 5
Training loss: 2.9609246253967285
Validation loss: 2.7319494370491273

Epoch: 6| Step: 6
Training loss: 3.3539886474609375
Validation loss: 2.729739125056933

Epoch: 6| Step: 7
Training loss: 2.6056385040283203
Validation loss: 2.717075670919111

Epoch: 6| Step: 8
Training loss: 2.487976312637329
Validation loss: 2.712297890775947

Epoch: 6| Step: 9
Training loss: 2.976691246032715
Validation loss: 2.700190426200949

Epoch: 6| Step: 10
Training loss: 3.553455352783203
Validation loss: 2.7079731213149203

Epoch: 6| Step: 11
Training loss: 3.208726406097412
Validation loss: 2.6968424063856884

Epoch: 6| Step: 12
Training loss: 2.5534703731536865
Validation loss: 2.6850390024082635

Epoch: 6| Step: 13
Training loss: 2.5910444259643555
Validation loss: 2.671712701038648

Epoch: 55| Step: 0
Training loss: 2.661583423614502
Validation loss: 2.6635269862349316

Epoch: 6| Step: 1
Training loss: 3.445866107940674
Validation loss: 2.661773358621905

Epoch: 6| Step: 2
Training loss: 3.56585431098938
Validation loss: 2.6742703555732645

Epoch: 6| Step: 3
Training loss: 2.691192150115967
Validation loss: 2.685742611526161

Epoch: 6| Step: 4
Training loss: 2.5137765407562256
Validation loss: 2.689722220102946

Epoch: 6| Step: 5
Training loss: 3.3572640419006348
Validation loss: 2.7116529095557427

Epoch: 6| Step: 6
Training loss: 3.0532619953155518
Validation loss: 2.717956607059766

Epoch: 6| Step: 7
Training loss: 2.444977283477783
Validation loss: 2.701246912761401

Epoch: 6| Step: 8
Training loss: 2.508269786834717
Validation loss: 2.6892345336175736

Epoch: 6| Step: 9
Training loss: 2.8636279106140137
Validation loss: 2.684800740211241

Epoch: 6| Step: 10
Training loss: 3.0720505714416504
Validation loss: 2.681496471487066

Epoch: 6| Step: 11
Training loss: 2.0324597358703613
Validation loss: 2.670133759898524

Epoch: 6| Step: 12
Training loss: 2.7278294563293457
Validation loss: 2.667313242471346

Epoch: 6| Step: 13
Training loss: 3.125230073928833
Validation loss: 2.6644642173603015

Epoch: 56| Step: 0
Training loss: 2.5453574657440186
Validation loss: 2.663971039556688

Epoch: 6| Step: 1
Training loss: 2.766155242919922
Validation loss: 2.6604760949329664

Epoch: 6| Step: 2
Training loss: 2.7611608505249023
Validation loss: 2.6627199726720012

Epoch: 6| Step: 3
Training loss: 3.425337791442871
Validation loss: 2.662651618321737

Epoch: 6| Step: 4
Training loss: 3.3258373737335205
Validation loss: 2.6650658551082818

Epoch: 6| Step: 5
Training loss: 2.709224224090576
Validation loss: 2.6626114665821032

Epoch: 6| Step: 6
Training loss: 2.4871480464935303
Validation loss: 2.6647833701102965

Epoch: 6| Step: 7
Training loss: 2.333804130554199
Validation loss: 2.6619033505839687

Epoch: 6| Step: 8
Training loss: 2.6765682697296143
Validation loss: 2.6703931311125397

Epoch: 6| Step: 9
Training loss: 3.4349989891052246
Validation loss: 2.6633794487163587

Epoch: 6| Step: 10
Training loss: 2.5772175788879395
Validation loss: 2.666857155420447

Epoch: 6| Step: 11
Training loss: 3.008221387863159
Validation loss: 2.6639423677998204

Epoch: 6| Step: 12
Training loss: 3.04256010055542
Validation loss: 2.672658125559489

Epoch: 6| Step: 13
Training loss: 2.2901220321655273
Validation loss: 2.6636646563006985

Epoch: 57| Step: 0
Training loss: 2.7232377529144287
Validation loss: 2.66318073836706

Epoch: 6| Step: 1
Training loss: 2.49418306350708
Validation loss: 2.6628428684767855

Epoch: 6| Step: 2
Training loss: 2.628706932067871
Validation loss: 2.660995444943828

Epoch: 6| Step: 3
Training loss: 1.9421876668930054
Validation loss: 2.662009982652562

Epoch: 6| Step: 4
Training loss: 2.0505666732788086
Validation loss: 2.6580415028397755

Epoch: 6| Step: 5
Training loss: 3.596679210662842
Validation loss: 2.657807780850318

Epoch: 6| Step: 6
Training loss: 2.706223249435425
Validation loss: 2.6579231805698846

Epoch: 6| Step: 7
Training loss: 3.3675179481506348
Validation loss: 2.649284739648142

Epoch: 6| Step: 8
Training loss: 2.592729091644287
Validation loss: 2.654073566518804

Epoch: 6| Step: 9
Training loss: 3.1764872074127197
Validation loss: 2.6528321004682973

Epoch: 6| Step: 10
Training loss: 2.8975675106048584
Validation loss: 2.659097692017914

Epoch: 6| Step: 11
Training loss: 2.6495234966278076
Validation loss: 2.654075453358312

Epoch: 6| Step: 12
Training loss: 3.3902440071105957
Validation loss: 2.6593518898051274

Epoch: 6| Step: 13
Training loss: 3.702639579772949
Validation loss: 2.6570516452994397

Epoch: 58| Step: 0
Training loss: 3.1004137992858887
Validation loss: 2.6557595576009443

Epoch: 6| Step: 1
Training loss: 1.0207982063293457
Validation loss: 2.6568083634940525

Epoch: 6| Step: 2
Training loss: 2.7623634338378906
Validation loss: 2.6592011733721663

Epoch: 6| Step: 3
Training loss: 2.975792169570923
Validation loss: 2.66441297787492

Epoch: 6| Step: 4
Training loss: 2.428997039794922
Validation loss: 2.677187540197885

Epoch: 6| Step: 5
Training loss: 2.765300989151001
Validation loss: 2.692446893261325

Epoch: 6| Step: 6
Training loss: 3.2867541313171387
Validation loss: 2.711658549565141

Epoch: 6| Step: 7
Training loss: 3.259275197982788
Validation loss: 2.7194208201541694

Epoch: 6| Step: 8
Training loss: 3.67020845413208
Validation loss: 2.700646733724943

Epoch: 6| Step: 9
Training loss: 3.2366952896118164
Validation loss: 2.676881087723599

Epoch: 6| Step: 10
Training loss: 3.325313091278076
Validation loss: 2.6668922516607467

Epoch: 6| Step: 11
Training loss: 1.929418921470642
Validation loss: 2.651349539397865

Epoch: 6| Step: 12
Training loss: 2.7310283184051514
Validation loss: 2.6470589535210722

Epoch: 6| Step: 13
Training loss: 3.439769983291626
Validation loss: 2.6445652464384675

Epoch: 59| Step: 0
Training loss: 2.612593412399292
Validation loss: 2.6584304122514624

Epoch: 6| Step: 1
Training loss: 2.731843948364258
Validation loss: 2.6624053268022436

Epoch: 6| Step: 2
Training loss: 2.847571849822998
Validation loss: 2.6756818679071244

Epoch: 6| Step: 3
Training loss: 2.962716579437256
Validation loss: 2.6703030652897333

Epoch: 6| Step: 4
Training loss: 2.70322847366333
Validation loss: 2.6763594765816965

Epoch: 6| Step: 5
Training loss: 2.926201820373535
Validation loss: 2.670441431383933

Epoch: 6| Step: 6
Training loss: 3.2637228965759277
Validation loss: 2.6716930020240044

Epoch: 6| Step: 7
Training loss: 2.4862866401672363
Validation loss: 2.677480318213022

Epoch: 6| Step: 8
Training loss: 2.5936789512634277
Validation loss: 2.672324570276404

Epoch: 6| Step: 9
Training loss: 3.4455528259277344
Validation loss: 2.674453076495919

Epoch: 6| Step: 10
Training loss: 3.268350839614868
Validation loss: 2.672808342082526

Epoch: 6| Step: 11
Training loss: 2.419142007827759
Validation loss: 2.665544640633368

Epoch: 6| Step: 12
Training loss: 2.773817539215088
Validation loss: 2.65843117108909

Epoch: 6| Step: 13
Training loss: 2.3927292823791504
Validation loss: 2.6617925654175463

Epoch: 60| Step: 0
Training loss: 3.3189573287963867
Validation loss: 2.6558181496076685

Epoch: 6| Step: 1
Training loss: 3.6762139797210693
Validation loss: 2.6519307705663864

Epoch: 6| Step: 2
Training loss: 2.725153684616089
Validation loss: 2.6486247226756108

Epoch: 6| Step: 3
Training loss: 3.243607521057129
Validation loss: 2.6485441525777182

Epoch: 6| Step: 4
Training loss: 2.585390090942383
Validation loss: 2.647983458734328

Epoch: 6| Step: 5
Training loss: 3.2619833946228027
Validation loss: 2.6465055814353367

Epoch: 6| Step: 6
Training loss: 2.439149856567383
Validation loss: 2.64490928188447

Epoch: 6| Step: 7
Training loss: 3.415186882019043
Validation loss: 2.645749630466584

Epoch: 6| Step: 8
Training loss: 2.629049062728882
Validation loss: 2.6493279190473658

Epoch: 6| Step: 9
Training loss: 2.6603479385375977
Validation loss: 2.6556798053044144

Epoch: 6| Step: 10
Training loss: 1.7832896709442139
Validation loss: 2.6558268224039385

Epoch: 6| Step: 11
Training loss: 2.373624801635742
Validation loss: 2.65408508751982

Epoch: 6| Step: 12
Training loss: 2.609192371368408
Validation loss: 2.6578353476780716

Epoch: 6| Step: 13
Training loss: 2.502826452255249
Validation loss: 2.6598727395457606

Epoch: 61| Step: 0
Training loss: 1.8752132654190063
Validation loss: 2.6702566005850352

Epoch: 6| Step: 1
Training loss: 3.2650649547576904
Validation loss: 2.673727563632432

Epoch: 6| Step: 2
Training loss: 3.5158579349517822
Validation loss: 2.6685558826692644

Epoch: 6| Step: 3
Training loss: 3.371856689453125
Validation loss: 2.669626533344228

Epoch: 6| Step: 4
Training loss: 3.385204315185547
Validation loss: 2.666525069103446

Epoch: 6| Step: 5
Training loss: 1.9829541444778442
Validation loss: 2.6577973058146815

Epoch: 6| Step: 6
Training loss: 2.6747231483459473
Validation loss: 2.6551116230667278

Epoch: 6| Step: 7
Training loss: 1.9877846240997314
Validation loss: 2.651086240686396

Epoch: 6| Step: 8
Training loss: 3.154733419418335
Validation loss: 2.646291591787851

Epoch: 6| Step: 9
Training loss: 2.3184409141540527
Validation loss: 2.650517766193677

Epoch: 6| Step: 10
Training loss: 3.086935520172119
Validation loss: 2.644731274215124

Epoch: 6| Step: 11
Training loss: 2.9524574279785156
Validation loss: 2.6423467538690053

Epoch: 6| Step: 12
Training loss: 3.2818353176116943
Validation loss: 2.6434078370371172

Epoch: 6| Step: 13
Training loss: 2.257817506790161
Validation loss: 2.6393957958426526

Epoch: 62| Step: 0
Training loss: 3.3464488983154297
Validation loss: 2.6471992538821314

Epoch: 6| Step: 1
Training loss: 2.784311532974243
Validation loss: 2.638329993012131

Epoch: 6| Step: 2
Training loss: 3.0342917442321777
Validation loss: 2.63875651103194

Epoch: 6| Step: 3
Training loss: 3.3837406635284424
Validation loss: 2.6352423698671403

Epoch: 6| Step: 4
Training loss: 2.9643280506134033
Validation loss: 2.639828328163393

Epoch: 6| Step: 5
Training loss: 2.69091796875
Validation loss: 2.633095282380299

Epoch: 6| Step: 6
Training loss: 2.4853439331054688
Validation loss: 2.6341890647847164

Epoch: 6| Step: 7
Training loss: 3.001007080078125
Validation loss: 2.635012213901807

Epoch: 6| Step: 8
Training loss: 3.567652940750122
Validation loss: 2.6360908080172796

Epoch: 6| Step: 9
Training loss: 1.7328935861587524
Validation loss: 2.6362036889599216

Epoch: 6| Step: 10
Training loss: 2.479261875152588
Validation loss: 2.63196595509847

Epoch: 6| Step: 11
Training loss: 2.737499713897705
Validation loss: 2.6350150198064823

Epoch: 6| Step: 12
Training loss: 2.448270797729492
Validation loss: 2.6316939784634497

Epoch: 6| Step: 13
Training loss: 2.4967598915100098
Validation loss: 2.6368447529372347

Epoch: 63| Step: 0
Training loss: 2.0748438835144043
Validation loss: 2.639916237964425

Epoch: 6| Step: 1
Training loss: 3.4492926597595215
Validation loss: 2.638851942554597

Epoch: 6| Step: 2
Training loss: 3.1132776737213135
Validation loss: 2.6331403255462646

Epoch: 6| Step: 3
Training loss: 2.7525343894958496
Validation loss: 2.631140608941355

Epoch: 6| Step: 4
Training loss: 3.287428140640259
Validation loss: 2.6347012289108767

Epoch: 6| Step: 5
Training loss: 2.9111452102661133
Validation loss: 2.6351755049920853

Epoch: 6| Step: 6
Training loss: 2.3828654289245605
Validation loss: 2.635850598735194

Epoch: 6| Step: 7
Training loss: 2.9974608421325684
Validation loss: 2.6372260944817656

Epoch: 6| Step: 8
Training loss: 3.094942808151245
Validation loss: 2.641439873685119

Epoch: 6| Step: 9
Training loss: 2.1692569255828857
Validation loss: 2.6417995934845298

Epoch: 6| Step: 10
Training loss: 3.0564980506896973
Validation loss: 2.636240928403793

Epoch: 6| Step: 11
Training loss: 2.2607421875
Validation loss: 2.6339266300201416

Epoch: 6| Step: 12
Training loss: 2.767029047012329
Validation loss: 2.6301066157638386

Epoch: 6| Step: 13
Training loss: 3.0878114700317383
Validation loss: 2.6315653247217976

Epoch: 64| Step: 0
Training loss: 3.38992977142334
Validation loss: 2.632801881400488

Epoch: 6| Step: 1
Training loss: 1.9841177463531494
Validation loss: 2.6327793521265828

Epoch: 6| Step: 2
Training loss: 2.303084373474121
Validation loss: 2.629119642319218

Epoch: 6| Step: 3
Training loss: 2.8513481616973877
Validation loss: 2.633501004147273

Epoch: 6| Step: 4
Training loss: 3.7149770259857178
Validation loss: 2.634703351605323

Epoch: 6| Step: 5
Training loss: 3.0139236450195312
Validation loss: 2.63465105846364

Epoch: 6| Step: 6
Training loss: 2.720472812652588
Validation loss: 2.6366461605154057

Epoch: 6| Step: 7
Training loss: 2.8698740005493164
Validation loss: 2.639257630994243

Epoch: 6| Step: 8
Training loss: 2.8710708618164062
Validation loss: 2.6485733652627594

Epoch: 6| Step: 9
Training loss: 2.945507526397705
Validation loss: 2.651865320820962

Epoch: 6| Step: 10
Training loss: 2.394325017929077
Validation loss: 2.659962074730986

Epoch: 6| Step: 11
Training loss: 2.2552294731140137
Validation loss: 2.6599733368042977

Epoch: 6| Step: 12
Training loss: 3.3143458366394043
Validation loss: 2.661707819149058

Epoch: 6| Step: 13
Training loss: 2.50097918510437
Validation loss: 2.670603803409043

Epoch: 65| Step: 0
Training loss: 2.1715173721313477
Validation loss: 2.6690957674416165

Epoch: 6| Step: 1
Training loss: 3.2641239166259766
Validation loss: 2.6477773779182026

Epoch: 6| Step: 2
Training loss: 1.9165587425231934
Validation loss: 2.6427021129156953

Epoch: 6| Step: 3
Training loss: 3.875600576400757
Validation loss: 2.6325911373220463

Epoch: 6| Step: 4
Training loss: 2.3364691734313965
Validation loss: 2.632748214147424

Epoch: 6| Step: 5
Training loss: 3.340163230895996
Validation loss: 2.6316783761465423

Epoch: 6| Step: 6
Training loss: 3.3621764183044434
Validation loss: 2.632202917529691

Epoch: 6| Step: 7
Training loss: 2.0542397499084473
Validation loss: 2.6306816377947406

Epoch: 6| Step: 8
Training loss: 1.7212398052215576
Validation loss: 2.6310275780257357

Epoch: 6| Step: 9
Training loss: 2.8241126537323
Validation loss: 2.6331516850379204

Epoch: 6| Step: 10
Training loss: 3.2428019046783447
Validation loss: 2.6350984317000195

Epoch: 6| Step: 11
Training loss: 2.826821804046631
Validation loss: 2.633777459462484

Epoch: 6| Step: 12
Training loss: 2.959303855895996
Validation loss: 2.637640683881698

Epoch: 6| Step: 13
Training loss: 3.8264193534851074
Validation loss: 2.6403230236422632

Epoch: 66| Step: 0
Training loss: 2.91196346282959
Validation loss: 2.6391357196274625

Epoch: 6| Step: 1
Training loss: 2.9645981788635254
Validation loss: 2.6414358103147118

Epoch: 6| Step: 2
Training loss: 2.586742401123047
Validation loss: 2.641968237456455

Epoch: 6| Step: 3
Training loss: 2.5309839248657227
Validation loss: 2.633886739771853

Epoch: 6| Step: 4
Training loss: 2.924339771270752
Validation loss: 2.635065258190196

Epoch: 6| Step: 5
Training loss: 2.7390103340148926
Validation loss: 2.6369455373415382

Epoch: 6| Step: 6
Training loss: 2.470884323120117
Validation loss: 2.638231574848134

Epoch: 6| Step: 7
Training loss: 3.1345293521881104
Validation loss: 2.6333365773641937

Epoch: 6| Step: 8
Training loss: 2.995728015899658
Validation loss: 2.6317625994323404

Epoch: 6| Step: 9
Training loss: 3.1130008697509766
Validation loss: 2.62585735577409

Epoch: 6| Step: 10
Training loss: 2.3373804092407227
Validation loss: 2.6235390888747347

Epoch: 6| Step: 11
Training loss: 2.757513999938965
Validation loss: 2.6264437475512104

Epoch: 6| Step: 12
Training loss: 2.423064708709717
Validation loss: 2.6239774996234524

Epoch: 6| Step: 13
Training loss: 3.714364767074585
Validation loss: 2.6283815522347727

Epoch: 67| Step: 0
Training loss: 2.3214707374572754
Validation loss: 2.622927996420091

Epoch: 6| Step: 1
Training loss: 2.39967679977417
Validation loss: 2.625014146169027

Epoch: 6| Step: 2
Training loss: 2.5840792655944824
Validation loss: 2.6261294298274542

Epoch: 6| Step: 3
Training loss: 3.1056103706359863
Validation loss: 2.6263357644440024

Epoch: 6| Step: 4
Training loss: 1.95322847366333
Validation loss: 2.622900260392056

Epoch: 6| Step: 5
Training loss: 4.30649471282959
Validation loss: 2.6237681399109545

Epoch: 6| Step: 6
Training loss: 2.8468332290649414
Validation loss: 2.6225854863402662

Epoch: 6| Step: 7
Training loss: 2.9293007850646973
Validation loss: 2.6215954980542584

Epoch: 6| Step: 8
Training loss: 2.123929977416992
Validation loss: 2.6216208370782996

Epoch: 6| Step: 9
Training loss: 3.400421619415283
Validation loss: 2.6205982469743296

Epoch: 6| Step: 10
Training loss: 3.2282378673553467
Validation loss: 2.6207511809564408

Epoch: 6| Step: 11
Training loss: 2.743272304534912
Validation loss: 2.62731961793797

Epoch: 6| Step: 12
Training loss: 2.4381744861602783
Validation loss: 2.6244306282330583

Epoch: 6| Step: 13
Training loss: 2.8158509731292725
Validation loss: 2.6195140936041392

Epoch: 68| Step: 0
Training loss: 3.9776315689086914
Validation loss: 2.6259019503029446

Epoch: 6| Step: 1
Training loss: 2.6003787517547607
Validation loss: 2.6216868790247108

Epoch: 6| Step: 2
Training loss: 1.6744542121887207
Validation loss: 2.6287212705099456

Epoch: 6| Step: 3
Training loss: 2.600959300994873
Validation loss: 2.6339958995901127

Epoch: 6| Step: 4
Training loss: 3.1846823692321777
Validation loss: 2.6321696081469135

Epoch: 6| Step: 5
Training loss: 2.0973477363586426
Validation loss: 2.634614772694085

Epoch: 6| Step: 6
Training loss: 2.601757287979126
Validation loss: 2.6325740301480858

Epoch: 6| Step: 7
Training loss: 2.6866345405578613
Validation loss: 2.6342606416312595

Epoch: 6| Step: 8
Training loss: 2.634831428527832
Validation loss: 2.632034396612516

Epoch: 6| Step: 9
Training loss: 3.0333125591278076
Validation loss: 2.63124494911522

Epoch: 6| Step: 10
Training loss: 3.0180675983428955
Validation loss: 2.627014152465328

Epoch: 6| Step: 11
Training loss: 2.8031046390533447
Validation loss: 2.632578129409462

Epoch: 6| Step: 12
Training loss: 3.6011528968811035
Validation loss: 2.6316282672266804

Epoch: 6| Step: 13
Training loss: 2.394960641860962
Validation loss: 2.630891453835272

Epoch: 69| Step: 0
Training loss: 3.1922340393066406
Validation loss: 2.6349236170450845

Epoch: 6| Step: 1
Training loss: 2.8654651641845703
Validation loss: 2.637584019732732

Epoch: 6| Step: 2
Training loss: 3.554861307144165
Validation loss: 2.64588564185686

Epoch: 6| Step: 3
Training loss: 3.5256776809692383
Validation loss: 2.634861061649938

Epoch: 6| Step: 4
Training loss: 2.2547848224639893
Validation loss: 2.628877503897554

Epoch: 6| Step: 5
Training loss: 2.4442248344421387
Validation loss: 2.6284005359936784

Epoch: 6| Step: 6
Training loss: 3.4016599655151367
Validation loss: 2.63059332806577

Epoch: 6| Step: 7
Training loss: 2.3866806030273438
Validation loss: 2.6289322837706535

Epoch: 6| Step: 8
Training loss: 1.9764907360076904
Validation loss: 2.6290593608733146

Epoch: 6| Step: 9
Training loss: 2.462599992752075
Validation loss: 2.6257704534838275

Epoch: 6| Step: 10
Training loss: 3.613847255706787
Validation loss: 2.626935746080132

Epoch: 6| Step: 11
Training loss: 2.0106120109558105
Validation loss: 2.640614245527534

Epoch: 6| Step: 12
Training loss: 2.3772695064544678
Validation loss: 2.6415372458837365

Epoch: 6| Step: 13
Training loss: 3.260714054107666
Validation loss: 2.656258370286675

Epoch: 70| Step: 0
Training loss: 3.236459255218506
Validation loss: 2.6598631617843465

Epoch: 6| Step: 1
Training loss: 3.0469777584075928
Validation loss: 2.6550666388644966

Epoch: 6| Step: 2
Training loss: 2.872394561767578
Validation loss: 2.6420346280579925

Epoch: 6| Step: 3
Training loss: 2.4244468212127686
Validation loss: 2.6291697486754386

Epoch: 6| Step: 4
Training loss: 2.321226119995117
Validation loss: 2.623701275035899

Epoch: 6| Step: 5
Training loss: 2.5754899978637695
Validation loss: 2.621813202417025

Epoch: 6| Step: 6
Training loss: 2.721954584121704
Validation loss: 2.6190515436151975

Epoch: 6| Step: 7
Training loss: 2.950676918029785
Validation loss: 2.62111178264823

Epoch: 6| Step: 8
Training loss: 2.7979512214660645
Validation loss: 2.6191711938509377

Epoch: 6| Step: 9
Training loss: 2.433107852935791
Validation loss: 2.6208312819080968

Epoch: 6| Step: 10
Training loss: 2.560898780822754
Validation loss: 2.6217771832660963

Epoch: 6| Step: 11
Training loss: 2.9759674072265625
Validation loss: 2.617128033791819

Epoch: 6| Step: 12
Training loss: 3.2451729774475098
Validation loss: 2.6287288742680706

Epoch: 6| Step: 13
Training loss: 3.035792350769043
Validation loss: 2.6288513137448217

Epoch: 71| Step: 0
Training loss: 3.217031240463257
Validation loss: 2.634901900445261

Epoch: 6| Step: 1
Training loss: 3.169285774230957
Validation loss: 2.6443336368888937

Epoch: 6| Step: 2
Training loss: 2.8815112113952637
Validation loss: 2.6437039606032835

Epoch: 6| Step: 3
Training loss: 2.7369613647460938
Validation loss: 2.6437096852128223

Epoch: 6| Step: 4
Training loss: 2.899832010269165
Validation loss: 2.6565284677731094

Epoch: 6| Step: 5
Training loss: 2.560284376144409
Validation loss: 2.6380060718905542

Epoch: 6| Step: 6
Training loss: 3.089747667312622
Validation loss: 2.635483823796754

Epoch: 6| Step: 7
Training loss: 3.0941178798675537
Validation loss: 2.6347044616617183

Epoch: 6| Step: 8
Training loss: 3.5412261486053467
Validation loss: 2.62617152737033

Epoch: 6| Step: 9
Training loss: 3.0298473834991455
Validation loss: 2.6265132427215576

Epoch: 6| Step: 10
Training loss: 2.046505928039551
Validation loss: 2.6230934614776285

Epoch: 6| Step: 11
Training loss: 2.3581607341766357
Validation loss: 2.6168729592395086

Epoch: 6| Step: 12
Training loss: 2.295210838317871
Validation loss: 2.623674092754241

Epoch: 6| Step: 13
Training loss: 1.7034491300582886
Validation loss: 2.624676094260267

Epoch: 72| Step: 0
Training loss: 2.987678050994873
Validation loss: 2.627513406097248

Epoch: 6| Step: 1
Training loss: 3.0299997329711914
Validation loss: 2.63062729630419

Epoch: 6| Step: 2
Training loss: 2.28800106048584
Validation loss: 2.6228047852875083

Epoch: 6| Step: 3
Training loss: 2.988032817840576
Validation loss: 2.624020443167738

Epoch: 6| Step: 4
Training loss: 2.7816810607910156
Validation loss: 2.6309347639801683

Epoch: 6| Step: 5
Training loss: 3.4130022525787354
Validation loss: 2.6220122255304807

Epoch: 6| Step: 6
Training loss: 2.637016534805298
Validation loss: 2.6169330381578013

Epoch: 6| Step: 7
Training loss: 2.409395456314087
Validation loss: 2.617362512055264

Epoch: 6| Step: 8
Training loss: 2.6046600341796875
Validation loss: 2.6134782145100255

Epoch: 6| Step: 9
Training loss: 2.8624062538146973
Validation loss: 2.6130838573619886

Epoch: 6| Step: 10
Training loss: 2.512801170349121
Validation loss: 2.6128745643041467

Epoch: 6| Step: 11
Training loss: 1.7015233039855957
Validation loss: 2.6083551247914634

Epoch: 6| Step: 12
Training loss: 3.7266218662261963
Validation loss: 2.6088122372986167

Epoch: 6| Step: 13
Training loss: 3.3437533378601074
Validation loss: 2.6110315527967227

Epoch: 73| Step: 0
Training loss: 2.8004589080810547
Validation loss: 2.6064911939764537

Epoch: 6| Step: 1
Training loss: 3.2868542671203613
Validation loss: 2.609745389671736

Epoch: 6| Step: 2
Training loss: 2.8371639251708984
Validation loss: 2.6117890137498097

Epoch: 6| Step: 3
Training loss: 3.229386806488037
Validation loss: 2.614435347177649

Epoch: 6| Step: 4
Training loss: 2.9273691177368164
Validation loss: 2.6116426529422885

Epoch: 6| Step: 5
Training loss: 2.282982349395752
Validation loss: 2.6135685495150986

Epoch: 6| Step: 6
Training loss: 2.2125892639160156
Validation loss: 2.60790511356887

Epoch: 6| Step: 7
Training loss: 2.6251964569091797
Validation loss: 2.6111220390565935

Epoch: 6| Step: 8
Training loss: 2.9230072498321533
Validation loss: 2.6087615361777683

Epoch: 6| Step: 9
Training loss: 2.6146795749664307
Validation loss: 2.6133521423544934

Epoch: 6| Step: 10
Training loss: 2.0897374153137207
Validation loss: 2.6140040325862106

Epoch: 6| Step: 11
Training loss: 2.8954715728759766
Validation loss: 2.618596899893976

Epoch: 6| Step: 12
Training loss: 2.97792649269104
Validation loss: 2.616264440680063

Epoch: 6| Step: 13
Training loss: 3.5511813163757324
Validation loss: 2.6283978236618863

Epoch: 74| Step: 0
Training loss: 2.9284884929656982
Validation loss: 2.618330934996246

Epoch: 6| Step: 1
Training loss: 3.281693935394287
Validation loss: 2.615463659327517

Epoch: 6| Step: 2
Training loss: 2.308901071548462
Validation loss: 2.623401895646126

Epoch: 6| Step: 3
Training loss: 3.077695608139038
Validation loss: 2.6221941722336637

Epoch: 6| Step: 4
Training loss: 2.42248272895813
Validation loss: 2.6147219647643385

Epoch: 6| Step: 5
Training loss: 2.044119119644165
Validation loss: 2.618387455581337

Epoch: 6| Step: 6
Training loss: 3.3336539268493652
Validation loss: 2.6135808165355394

Epoch: 6| Step: 7
Training loss: 2.1845693588256836
Validation loss: 2.6171433130900064

Epoch: 6| Step: 8
Training loss: 3.2811622619628906
Validation loss: 2.609758923130651

Epoch: 6| Step: 9
Training loss: 3.7647507190704346
Validation loss: 2.6150122304116525

Epoch: 6| Step: 10
Training loss: 2.78847599029541
Validation loss: 2.6073747552851194

Epoch: 6| Step: 11
Training loss: 2.8177223205566406
Validation loss: 2.610712989684074

Epoch: 6| Step: 12
Training loss: 2.3390307426452637
Validation loss: 2.614875449929186

Epoch: 6| Step: 13
Training loss: 1.8959568738937378
Validation loss: 2.60746584656418

Epoch: 75| Step: 0
Training loss: 3.756643295288086
Validation loss: 2.6040653669705955

Epoch: 6| Step: 1
Training loss: 2.4172263145446777
Validation loss: 2.6090340486136814

Epoch: 6| Step: 2
Training loss: 2.655517101287842
Validation loss: 2.610719334694647

Epoch: 6| Step: 3
Training loss: 2.1889939308166504
Validation loss: 2.613615130865446

Epoch: 6| Step: 4
Training loss: 2.7238352298736572
Validation loss: 2.609785069701492

Epoch: 6| Step: 5
Training loss: 2.4649314880371094
Validation loss: 2.6075388975040887

Epoch: 6| Step: 6
Training loss: 3.1075544357299805
Validation loss: 2.6083537583710044

Epoch: 6| Step: 7
Training loss: 3.0279154777526855
Validation loss: 2.6089882901919785

Epoch: 6| Step: 8
Training loss: 2.5779380798339844
Validation loss: 2.606647547855172

Epoch: 6| Step: 9
Training loss: 2.5627739429473877
Validation loss: 2.607589155115107

Epoch: 6| Step: 10
Training loss: 3.249959707260132
Validation loss: 2.609700818215647

Epoch: 6| Step: 11
Training loss: 2.475309371948242
Validation loss: 2.608734699987596

Epoch: 6| Step: 12
Training loss: 2.742279291152954
Validation loss: 2.6143571945928756

Epoch: 6| Step: 13
Training loss: 2.9540348052978516
Validation loss: 2.6097814447136334

Epoch: 76| Step: 0
Training loss: 2.8135557174682617
Validation loss: 2.614557930218276

Epoch: 6| Step: 1
Training loss: 2.8971757888793945
Validation loss: 2.619512718210938

Epoch: 6| Step: 2
Training loss: 2.407336711883545
Validation loss: 2.623154632506832

Epoch: 6| Step: 3
Training loss: 3.5813660621643066
Validation loss: 2.6378493309020996

Epoch: 6| Step: 4
Training loss: 3.0011870861053467
Validation loss: 2.6321824366046536

Epoch: 6| Step: 5
Training loss: 2.8602938652038574
Validation loss: 2.639062084177489

Epoch: 6| Step: 6
Training loss: 2.7392258644104004
Validation loss: 2.636665867220971

Epoch: 6| Step: 7
Training loss: 2.5731005668640137
Validation loss: 2.6215529646924747

Epoch: 6| Step: 8
Training loss: 3.199777603149414
Validation loss: 2.6205010644851194

Epoch: 6| Step: 9
Training loss: 2.7087950706481934
Validation loss: 2.6149578299573673

Epoch: 6| Step: 10
Training loss: 2.2435595989227295
Validation loss: 2.61169167487852

Epoch: 6| Step: 11
Training loss: 2.049750566482544
Validation loss: 2.613408947503695

Epoch: 6| Step: 12
Training loss: 3.0913119316101074
Validation loss: 2.6081760993567844

Epoch: 6| Step: 13
Training loss: 2.714477777481079
Validation loss: 2.6116510078471196

Epoch: 77| Step: 0
Training loss: 2.317751407623291
Validation loss: 2.6099342915319625

Epoch: 6| Step: 1
Training loss: 3.5108718872070312
Validation loss: 2.611769986409013

Epoch: 6| Step: 2
Training loss: 2.9794864654541016
Validation loss: 2.6085116760705107

Epoch: 6| Step: 3
Training loss: 2.3708057403564453
Validation loss: 2.609436435084189

Epoch: 6| Step: 4
Training loss: 3.0861918926239014
Validation loss: 2.6088068869806107

Epoch: 6| Step: 5
Training loss: 1.6018803119659424
Validation loss: 2.6075310502001035

Epoch: 6| Step: 6
Training loss: 2.301210880279541
Validation loss: 2.6149624624559955

Epoch: 6| Step: 7
Training loss: 2.534331798553467
Validation loss: 2.611856916899322

Epoch: 6| Step: 8
Training loss: 3.1886026859283447
Validation loss: 2.6143721688178276

Epoch: 6| Step: 9
Training loss: 2.5690367221832275
Validation loss: 2.6234936996172835

Epoch: 6| Step: 10
Training loss: 3.196037530899048
Validation loss: 2.622429273461783

Epoch: 6| Step: 11
Training loss: 3.434640407562256
Validation loss: 2.6170124033445954

Epoch: 6| Step: 12
Training loss: 3.179030418395996
Validation loss: 2.612718548825992

Epoch: 6| Step: 13
Training loss: 2.4099626541137695
Validation loss: 2.610838979803106

Epoch: 78| Step: 0
Training loss: 2.5421488285064697
Validation loss: 2.6173361168112805

Epoch: 6| Step: 1
Training loss: 3.136305332183838
Validation loss: 2.609392358410743

Epoch: 6| Step: 2
Training loss: 3.2207484245300293
Validation loss: 2.609781562641103

Epoch: 6| Step: 3
Training loss: 2.7158141136169434
Validation loss: 2.6175551183762087

Epoch: 6| Step: 4
Training loss: 3.413590669631958
Validation loss: 2.621565423985963

Epoch: 6| Step: 5
Training loss: 2.226665735244751
Validation loss: 2.631784208359257

Epoch: 6| Step: 6
Training loss: 3.1395652294158936
Validation loss: 2.623566791575442

Epoch: 6| Step: 7
Training loss: 2.9948647022247314
Validation loss: 2.605431866902177

Epoch: 6| Step: 8
Training loss: 3.479806423187256
Validation loss: 2.6056416111607708

Epoch: 6| Step: 9
Training loss: 2.0136497020721436
Validation loss: 2.601431664600167

Epoch: 6| Step: 10
Training loss: 2.462836742401123
Validation loss: 2.5946835087191675

Epoch: 6| Step: 11
Training loss: 2.739366054534912
Validation loss: 2.6014055641748572

Epoch: 6| Step: 12
Training loss: 2.1681084632873535
Validation loss: 2.611278377553468

Epoch: 6| Step: 13
Training loss: 2.426938056945801
Validation loss: 2.614326464232578

Epoch: 79| Step: 0
Training loss: 2.1788177490234375
Validation loss: 2.6117051980828725

Epoch: 6| Step: 1
Training loss: 2.518710136413574
Validation loss: 2.6186580068321637

Epoch: 6| Step: 2
Training loss: 3.2828845977783203
Validation loss: 2.613322550250638

Epoch: 6| Step: 3
Training loss: 2.849360466003418
Validation loss: 2.6106609323973298

Epoch: 6| Step: 4
Training loss: 2.268873691558838
Validation loss: 2.6046542172790854

Epoch: 6| Step: 5
Training loss: 3.1338765621185303
Validation loss: 2.597895554316941

Epoch: 6| Step: 6
Training loss: 3.4165701866149902
Validation loss: 2.592119724519791

Epoch: 6| Step: 7
Training loss: 3.2531676292419434
Validation loss: 2.5918358525922223

Epoch: 6| Step: 8
Training loss: 2.280150890350342
Validation loss: 2.590650937890494

Epoch: 6| Step: 9
Training loss: 2.986471176147461
Validation loss: 2.5922081598671536

Epoch: 6| Step: 10
Training loss: 2.3234658241271973
Validation loss: 2.5961251976669475

Epoch: 6| Step: 11
Training loss: 2.8296544551849365
Validation loss: 2.590489141402706

Epoch: 6| Step: 12
Training loss: 2.4629580974578857
Validation loss: 2.598165742812618

Epoch: 6| Step: 13
Training loss: 3.2907118797302246
Validation loss: 2.6009920540676323

Epoch: 80| Step: 0
Training loss: 2.648123025894165
Validation loss: 2.602110788386355

Epoch: 6| Step: 1
Training loss: 3.725780487060547
Validation loss: 2.6072797749632146

Epoch: 6| Step: 2
Training loss: 2.9608407020568848
Validation loss: 2.61445725605052

Epoch: 6| Step: 3
Training loss: 2.2763094902038574
Validation loss: 2.610594675105105

Epoch: 6| Step: 4
Training loss: 3.395883560180664
Validation loss: 2.605714649282476

Epoch: 6| Step: 5
Training loss: 2.3038718700408936
Validation loss: 2.605203905413228

Epoch: 6| Step: 6
Training loss: 2.4098877906799316
Validation loss: 2.6115134121269308

Epoch: 6| Step: 7
Training loss: 2.874690294265747
Validation loss: 2.598825672621368

Epoch: 6| Step: 8
Training loss: 2.9695048332214355
Validation loss: 2.593590174951861

Epoch: 6| Step: 9
Training loss: 2.8933019638061523
Validation loss: 2.5889537462624173

Epoch: 6| Step: 10
Training loss: 2.489821672439575
Validation loss: 2.5881123183875956

Epoch: 6| Step: 11
Training loss: 3.0912885665893555
Validation loss: 2.5889058472007833

Epoch: 6| Step: 12
Training loss: 2.61452054977417
Validation loss: 2.5940546117803103

Epoch: 6| Step: 13
Training loss: 1.6301751136779785
Validation loss: 2.585250323818576

Epoch: 81| Step: 0
Training loss: 2.8639607429504395
Validation loss: 2.5892517669226534

Epoch: 6| Step: 1
Training loss: 2.055875301361084
Validation loss: 2.5892727605758177

Epoch: 6| Step: 2
Training loss: 2.9730372428894043
Validation loss: 2.58639863229567

Epoch: 6| Step: 3
Training loss: 3.536632776260376
Validation loss: 2.5852567201019614

Epoch: 6| Step: 4
Training loss: 2.1756386756896973
Validation loss: 2.58478396425965

Epoch: 6| Step: 5
Training loss: 3.088062286376953
Validation loss: 2.5890110077396518

Epoch: 6| Step: 6
Training loss: 3.1421995162963867
Validation loss: 2.5892705045720583

Epoch: 6| Step: 7
Training loss: 2.673055648803711
Validation loss: 2.59505876674447

Epoch: 6| Step: 8
Training loss: 2.397048234939575
Validation loss: 2.590477599892565

Epoch: 6| Step: 9
Training loss: 3.4401681423187256
Validation loss: 2.592553233587614

Epoch: 6| Step: 10
Training loss: 2.1201412677764893
Validation loss: 2.6002023245698664

Epoch: 6| Step: 11
Training loss: 2.7860779762268066
Validation loss: 2.601577389624811

Epoch: 6| Step: 12
Training loss: 2.7897837162017822
Validation loss: 2.5965666873480684

Epoch: 6| Step: 13
Training loss: 2.7094404697418213
Validation loss: 2.5908579236717633

Epoch: 82| Step: 0
Training loss: 2.908745050430298
Validation loss: 2.588307488349176

Epoch: 6| Step: 1
Training loss: 4.312357425689697
Validation loss: 2.587869941547353

Epoch: 6| Step: 2
Training loss: 2.6542482376098633
Validation loss: 2.585276460134855

Epoch: 6| Step: 3
Training loss: 2.0202276706695557
Validation loss: 2.58238027685432

Epoch: 6| Step: 4
Training loss: 2.578411817550659
Validation loss: 2.5883946777671896

Epoch: 6| Step: 5
Training loss: 3.4572386741638184
Validation loss: 2.591244456588581

Epoch: 6| Step: 6
Training loss: 2.9561479091644287
Validation loss: 2.5986313050793064

Epoch: 6| Step: 7
Training loss: 2.8951644897460938
Validation loss: 2.5969340416692916

Epoch: 6| Step: 8
Training loss: 2.2135262489318848
Validation loss: 2.5960601863040718

Epoch: 6| Step: 9
Training loss: 2.2559807300567627
Validation loss: 2.593713116902177

Epoch: 6| Step: 10
Training loss: 2.555140972137451
Validation loss: 2.5883894376857306

Epoch: 6| Step: 11
Training loss: 2.9162497520446777
Validation loss: 2.5852210752425657

Epoch: 6| Step: 12
Training loss: 2.838120222091675
Validation loss: 2.5820352338975474

Epoch: 6| Step: 13
Training loss: 1.8167037963867188
Validation loss: 2.5834789045395388

Epoch: 83| Step: 0
Training loss: 2.817525863647461
Validation loss: 2.5817139071802937

Epoch: 6| Step: 1
Training loss: 2.1556143760681152
Validation loss: 2.585439823007071

Epoch: 6| Step: 2
Training loss: 2.915520191192627
Validation loss: 2.5792978194452103

Epoch: 6| Step: 3
Training loss: 2.5228381156921387
Validation loss: 2.5819972535615325

Epoch: 6| Step: 4
Training loss: 2.0661795139312744
Validation loss: 2.583360986043048

Epoch: 6| Step: 5
Training loss: 3.6292386054992676
Validation loss: 2.5808183429061726

Epoch: 6| Step: 6
Training loss: 2.93636417388916
Validation loss: 2.580484015967256

Epoch: 6| Step: 7
Training loss: 2.380858898162842
Validation loss: 2.582901365013533

Epoch: 6| Step: 8
Training loss: 3.118284225463867
Validation loss: 2.5802707159391014

Epoch: 6| Step: 9
Training loss: 2.314955234527588
Validation loss: 2.5787826635504283

Epoch: 6| Step: 10
Training loss: 2.4365286827087402
Validation loss: 2.5819007145461215

Epoch: 6| Step: 11
Training loss: 2.9453444480895996
Validation loss: 2.581470243392452

Epoch: 6| Step: 12
Training loss: 3.303312301635742
Validation loss: 2.5808840823429886

Epoch: 6| Step: 13
Training loss: 3.277179718017578
Validation loss: 2.585200020062026

Epoch: 84| Step: 0
Training loss: 2.932595729827881
Validation loss: 2.5822812100892425

Epoch: 6| Step: 1
Training loss: 3.0135960578918457
Validation loss: 2.5794823374799503

Epoch: 6| Step: 2
Training loss: 2.6714491844177246
Validation loss: 2.584031448569349

Epoch: 6| Step: 3
Training loss: 3.857759475708008
Validation loss: 2.5819625521218903

Epoch: 6| Step: 4
Training loss: 3.003481149673462
Validation loss: 2.5877307961064

Epoch: 6| Step: 5
Training loss: 2.3934988975524902
Validation loss: 2.5865719651663177

Epoch: 6| Step: 6
Training loss: 2.298004150390625
Validation loss: 2.5862049005364858

Epoch: 6| Step: 7
Training loss: 3.4203920364379883
Validation loss: 2.594865245203818

Epoch: 6| Step: 8
Training loss: 2.869251012802124
Validation loss: 2.5944815630553872

Epoch: 6| Step: 9
Training loss: 2.3085074424743652
Validation loss: 2.5930841456177416

Epoch: 6| Step: 10
Training loss: 2.788369655609131
Validation loss: 2.5921446533613306

Epoch: 6| Step: 11
Training loss: 2.30670166015625
Validation loss: 2.586339650615569

Epoch: 6| Step: 12
Training loss: 2.17393159866333
Validation loss: 2.5867342923277166

Epoch: 6| Step: 13
Training loss: 2.3492538928985596
Validation loss: 2.582285245259603

Epoch: 85| Step: 0
Training loss: 2.8771228790283203
Validation loss: 2.5797464411745787

Epoch: 6| Step: 1
Training loss: 2.6181087493896484
Validation loss: 2.5817862274826213

Epoch: 6| Step: 2
Training loss: 2.434821128845215
Validation loss: 2.5775244364174466

Epoch: 6| Step: 3
Training loss: 2.585137128829956
Validation loss: 2.579216100836313

Epoch: 6| Step: 4
Training loss: 2.864683151245117
Validation loss: 2.576353342302384

Epoch: 6| Step: 5
Training loss: 3.1687660217285156
Validation loss: 2.58260259320659

Epoch: 6| Step: 6
Training loss: 2.54310941696167
Validation loss: 2.582075427937251

Epoch: 6| Step: 7
Training loss: 3.102022647857666
Validation loss: 2.5793644100107174

Epoch: 6| Step: 8
Training loss: 3.347435474395752
Validation loss: 2.577931679705138

Epoch: 6| Step: 9
Training loss: 1.9693523645401
Validation loss: 2.576621583712998

Epoch: 6| Step: 10
Training loss: 2.293428897857666
Validation loss: 2.57461218936469

Epoch: 6| Step: 11
Training loss: 2.7094526290893555
Validation loss: 2.5741230031495452

Epoch: 6| Step: 12
Training loss: 3.267812728881836
Validation loss: 2.57571828749872

Epoch: 6| Step: 13
Training loss: 2.7577004432678223
Validation loss: 2.578466489750852

Epoch: 86| Step: 0
Training loss: 3.234665632247925
Validation loss: 2.5807948112487793

Epoch: 6| Step: 1
Training loss: 2.590162754058838
Validation loss: 2.5831173107188237

Epoch: 6| Step: 2
Training loss: 2.87333083152771
Validation loss: 2.5851041040112896

Epoch: 6| Step: 3
Training loss: 2.830758571624756
Validation loss: 2.584513315590479

Epoch: 6| Step: 4
Training loss: 2.8047029972076416
Validation loss: 2.586031113901446

Epoch: 6| Step: 5
Training loss: 3.1442670822143555
Validation loss: 2.596273745259931

Epoch: 6| Step: 6
Training loss: 2.092679262161255
Validation loss: 2.5880461841501217

Epoch: 6| Step: 7
Training loss: 3.2137856483459473
Validation loss: 2.5840518038759948

Epoch: 6| Step: 8
Training loss: 3.2775821685791016
Validation loss: 2.580638552224764

Epoch: 6| Step: 9
Training loss: 1.7417336702346802
Validation loss: 2.574951474384595

Epoch: 6| Step: 10
Training loss: 2.639097213745117
Validation loss: 2.5725647839166785

Epoch: 6| Step: 11
Training loss: 2.4785075187683105
Validation loss: 2.5725478561975623

Epoch: 6| Step: 12
Training loss: 3.3213229179382324
Validation loss: 2.5737984334268877

Epoch: 6| Step: 13
Training loss: 1.9464462995529175
Validation loss: 2.5781305413092337

Epoch: 87| Step: 0
Training loss: 3.0073819160461426
Validation loss: 2.5777482140448784

Epoch: 6| Step: 1
Training loss: 2.607875347137451
Validation loss: 2.576377240560388

Epoch: 6| Step: 2
Training loss: 2.6500535011291504
Validation loss: 2.5756938098579325

Epoch: 6| Step: 3
Training loss: 2.4271721839904785
Validation loss: 2.576126124269219

Epoch: 6| Step: 4
Training loss: 3.278113842010498
Validation loss: 2.5727488251142603

Epoch: 6| Step: 5
Training loss: 2.5624899864196777
Validation loss: 2.5714752110101844

Epoch: 6| Step: 6
Training loss: 3.8294992446899414
Validation loss: 2.5761642456054688

Epoch: 6| Step: 7
Training loss: 2.368716239929199
Validation loss: 2.579464012576688

Epoch: 6| Step: 8
Training loss: 2.4206058979034424
Validation loss: 2.5835852725531465

Epoch: 6| Step: 9
Training loss: 3.2664284706115723
Validation loss: 2.584329922993978

Epoch: 6| Step: 10
Training loss: 2.484781503677368
Validation loss: 2.5784609292143132

Epoch: 6| Step: 11
Training loss: 2.7294626235961914
Validation loss: 2.581788998778148

Epoch: 6| Step: 12
Training loss: 2.3152754306793213
Validation loss: 2.5813256207332818

Epoch: 6| Step: 13
Training loss: 2.5360870361328125
Validation loss: 2.575866483872937

Epoch: 88| Step: 0
Training loss: 2.5569920539855957
Validation loss: 2.5675814074854695

Epoch: 6| Step: 1
Training loss: 2.231553792953491
Validation loss: 2.563209447809445

Epoch: 6| Step: 2
Training loss: 3.2821273803710938
Validation loss: 2.5636583835847917

Epoch: 6| Step: 3
Training loss: 3.218416690826416
Validation loss: 2.5693574848995415

Epoch: 6| Step: 4
Training loss: 2.7159905433654785
Validation loss: 2.5716104661264727

Epoch: 6| Step: 5
Training loss: 2.3250651359558105
Validation loss: 2.5774059013653825

Epoch: 6| Step: 6
Training loss: 2.9156932830810547
Validation loss: 2.5824594523317073

Epoch: 6| Step: 7
Training loss: 3.986043930053711
Validation loss: 2.5903089738661245

Epoch: 6| Step: 8
Training loss: 2.8336026668548584
Validation loss: 2.576649865796489

Epoch: 6| Step: 9
Training loss: 1.8958491086959839
Validation loss: 2.5793039029644382

Epoch: 6| Step: 10
Training loss: 3.560011863708496
Validation loss: 2.574118568051246

Epoch: 6| Step: 11
Training loss: 2.275070905685425
Validation loss: 2.5727984084877917

Epoch: 6| Step: 12
Training loss: 2.4187068939208984
Validation loss: 2.5710251177510908

Epoch: 6| Step: 13
Training loss: 1.9055854082107544
Validation loss: 2.573328223279727

Epoch: 89| Step: 0
Training loss: 3.1358296871185303
Validation loss: 2.573027623597012

Epoch: 6| Step: 1
Training loss: 2.603569746017456
Validation loss: 2.5745881859974196

Epoch: 6| Step: 2
Training loss: 3.054309844970703
Validation loss: 2.5687064816874843

Epoch: 6| Step: 3
Training loss: 2.757591962814331
Validation loss: 2.5751319751944592

Epoch: 6| Step: 4
Training loss: 2.138172149658203
Validation loss: 2.5722712316820697

Epoch: 6| Step: 5
Training loss: 2.860248565673828
Validation loss: 2.57031007992324

Epoch: 6| Step: 6
Training loss: 2.6688425540924072
Validation loss: 2.5719905002142793

Epoch: 6| Step: 7
Training loss: 2.335108757019043
Validation loss: 2.5707410150958645

Epoch: 6| Step: 8
Training loss: 3.4949111938476562
Validation loss: 2.5738537914009503

Epoch: 6| Step: 9
Training loss: 2.6869804859161377
Validation loss: 2.572153878468339

Epoch: 6| Step: 10
Training loss: 1.4075531959533691
Validation loss: 2.5732976954470397

Epoch: 6| Step: 11
Training loss: 3.22121000289917
Validation loss: 2.5779059651077434

Epoch: 6| Step: 12
Training loss: 2.787916898727417
Validation loss: 2.595667267358431

Epoch: 6| Step: 13
Training loss: 3.849073648452759
Validation loss: 2.6056158055541334

Epoch: 90| Step: 0
Training loss: 1.9640432596206665
Validation loss: 2.6103223703240834

Epoch: 6| Step: 1
Training loss: 2.4268579483032227
Validation loss: 2.6348793532258723

Epoch: 6| Step: 2
Training loss: 3.0766029357910156
Validation loss: 2.650833414446923

Epoch: 6| Step: 3
Training loss: 2.844085216522217
Validation loss: 2.655167661687379

Epoch: 6| Step: 4
Training loss: 2.6397411823272705
Validation loss: 2.6516774431351693

Epoch: 6| Step: 5
Training loss: 2.8352208137512207
Validation loss: 2.6072522927356023

Epoch: 6| Step: 6
Training loss: 2.8142738342285156
Validation loss: 2.5835146711718653

Epoch: 6| Step: 7
Training loss: 2.9558558464050293
Validation loss: 2.563791290406258

Epoch: 6| Step: 8
Training loss: 2.3830502033233643
Validation loss: 2.5603997271548034

Epoch: 6| Step: 9
Training loss: 3.528942584991455
Validation loss: 2.56380880776272

Epoch: 6| Step: 10
Training loss: 2.2696194648742676
Validation loss: 2.56960048983174

Epoch: 6| Step: 11
Training loss: 3.6028037071228027
Validation loss: 2.579343931649321

Epoch: 6| Step: 12
Training loss: 3.010049343109131
Validation loss: 2.582191580085344

Epoch: 6| Step: 13
Training loss: 2.2518160343170166
Validation loss: 2.584968061857326

Epoch: 91| Step: 0
Training loss: 3.0463476181030273
Validation loss: 2.5753102020550798

Epoch: 6| Step: 1
Training loss: 2.280802011489868
Validation loss: 2.5690627662084435

Epoch: 6| Step: 2
Training loss: 2.87113618850708
Validation loss: 2.5698117889383787

Epoch: 6| Step: 3
Training loss: 2.827228307723999
Validation loss: 2.5655363426413587

Epoch: 6| Step: 4
Training loss: 3.198744535446167
Validation loss: 2.566944496605986

Epoch: 6| Step: 5
Training loss: 2.415194272994995
Validation loss: 2.564103739235991

Epoch: 6| Step: 6
Training loss: 2.793203830718994
Validation loss: 2.5590748479289394

Epoch: 6| Step: 7
Training loss: 2.580681800842285
Validation loss: 2.567498637783912

Epoch: 6| Step: 8
Training loss: 2.2918896675109863
Validation loss: 2.569301438587968

Epoch: 6| Step: 9
Training loss: 3.082061767578125
Validation loss: 2.5665989819393364

Epoch: 6| Step: 10
Training loss: 3.209568977355957
Validation loss: 2.5690345635978122

Epoch: 6| Step: 11
Training loss: 2.717391014099121
Validation loss: 2.571458843446547

Epoch: 6| Step: 12
Training loss: 2.0106232166290283
Validation loss: 2.5775581585463656

Epoch: 6| Step: 13
Training loss: 3.509423017501831
Validation loss: 2.581046289013278

Epoch: 92| Step: 0
Training loss: 2.598727226257324
Validation loss: 2.5698322839634393

Epoch: 6| Step: 1
Training loss: 3.7525854110717773
Validation loss: 2.5713461496496715

Epoch: 6| Step: 2
Training loss: 2.923457145690918
Validation loss: 2.561658784907351

Epoch: 6| Step: 3
Training loss: 2.347703695297241
Validation loss: 2.563452502732636

Epoch: 6| Step: 4
Training loss: 2.548609733581543
Validation loss: 2.567408687324934

Epoch: 6| Step: 5
Training loss: 3.2016243934631348
Validation loss: 2.5738387620577248

Epoch: 6| Step: 6
Training loss: 2.7300808429718018
Validation loss: 2.56688255007549

Epoch: 6| Step: 7
Training loss: 2.736387252807617
Validation loss: 2.573193544982582

Epoch: 6| Step: 8
Training loss: 2.4046411514282227
Validation loss: 2.5654919173127864

Epoch: 6| Step: 9
Training loss: 2.0288939476013184
Validation loss: 2.5678497129871

Epoch: 6| Step: 10
Training loss: 2.9107284545898438
Validation loss: 2.5565724911228305

Epoch: 6| Step: 11
Training loss: 2.5737626552581787
Validation loss: 2.5516817723551104

Epoch: 6| Step: 12
Training loss: 3.0496373176574707
Validation loss: 2.5587097880660847

Epoch: 6| Step: 13
Training loss: 2.4819462299346924
Validation loss: 2.5533725471906763

Epoch: 93| Step: 0
Training loss: 2.438689708709717
Validation loss: 2.553667122317899

Epoch: 6| Step: 1
Training loss: 3.249976634979248
Validation loss: 2.5517466888632825

Epoch: 6| Step: 2
Training loss: 2.3403267860412598
Validation loss: 2.552211812747422

Epoch: 6| Step: 3
Training loss: 2.334820508956909
Validation loss: 2.549640950336251

Epoch: 6| Step: 4
Training loss: 2.8819098472595215
Validation loss: 2.5573552295725834

Epoch: 6| Step: 5
Training loss: 3.3104677200317383
Validation loss: 2.5575668119615123

Epoch: 6| Step: 6
Training loss: 2.511202812194824
Validation loss: 2.55685923176427

Epoch: 6| Step: 7
Training loss: 2.4731335639953613
Validation loss: 2.554489356215282

Epoch: 6| Step: 8
Training loss: 2.3580756187438965
Validation loss: 2.5579690805045505

Epoch: 6| Step: 9
Training loss: 3.0079753398895264
Validation loss: 2.5590554616784535

Epoch: 6| Step: 10
Training loss: 2.7438793182373047
Validation loss: 2.551947063015353

Epoch: 6| Step: 11
Training loss: 2.2692747116088867
Validation loss: 2.5507650990639963

Epoch: 6| Step: 12
Training loss: 3.7431411743164062
Validation loss: 2.5440113621373333

Epoch: 6| Step: 13
Training loss: 2.6314897537231445
Validation loss: 2.540796531144009

Epoch: 94| Step: 0
Training loss: 3.4156017303466797
Validation loss: 2.5475726742898264

Epoch: 6| Step: 1
Training loss: 3.3058650493621826
Validation loss: 2.547162978879867

Epoch: 6| Step: 2
Training loss: 2.6173198223114014
Validation loss: 2.5452943232751664

Epoch: 6| Step: 3
Training loss: 2.4873452186584473
Validation loss: 2.551301371666693

Epoch: 6| Step: 4
Training loss: 2.2647030353546143
Validation loss: 2.5454098357949206

Epoch: 6| Step: 5
Training loss: 2.693024158477783
Validation loss: 2.5490301680821243

Epoch: 6| Step: 6
Training loss: 2.4068782329559326
Validation loss: 2.5518371007775746

Epoch: 6| Step: 7
Training loss: 2.503662347793579
Validation loss: 2.547048450798117

Epoch: 6| Step: 8
Training loss: 2.5284199714660645
Validation loss: 2.5532535173559703

Epoch: 6| Step: 9
Training loss: 3.176985740661621
Validation loss: 2.55329659933685

Epoch: 6| Step: 10
Training loss: 2.4659738540649414
Validation loss: 2.5618613842994935

Epoch: 6| Step: 11
Training loss: 2.8716840744018555
Validation loss: 2.563803508717527

Epoch: 6| Step: 12
Training loss: 2.6878485679626465
Validation loss: 2.5790475363372476

Epoch: 6| Step: 13
Training loss: 2.834292411804199
Validation loss: 2.5762440696839364

Epoch: 95| Step: 0
Training loss: 2.5444717407226562
Validation loss: 2.5920227983946442

Epoch: 6| Step: 1
Training loss: 3.2391655445098877
Validation loss: 2.5875279467592955

Epoch: 6| Step: 2
Training loss: 2.976940155029297
Validation loss: 2.5774830566939486

Epoch: 6| Step: 3
Training loss: 3.1804463863372803
Validation loss: 2.5725445414102204

Epoch: 6| Step: 4
Training loss: 2.2733426094055176
Validation loss: 2.5619351479314987

Epoch: 6| Step: 5
Training loss: 2.859943389892578
Validation loss: 2.555099969269127

Epoch: 6| Step: 6
Training loss: 2.430054187774658
Validation loss: 2.54713870633033

Epoch: 6| Step: 7
Training loss: 2.792767286300659
Validation loss: 2.543076907434771

Epoch: 6| Step: 8
Training loss: 1.7982137203216553
Validation loss: 2.543455546902072

Epoch: 6| Step: 9
Training loss: 2.8971283435821533
Validation loss: 2.541122587778235

Epoch: 6| Step: 10
Training loss: 2.614474296569824
Validation loss: 2.541919823615782

Epoch: 6| Step: 11
Training loss: 2.5582380294799805
Validation loss: 2.5426922741756646

Epoch: 6| Step: 12
Training loss: 3.421193838119507
Validation loss: 2.5427520839116906

Epoch: 6| Step: 13
Training loss: 2.8387773036956787
Validation loss: 2.541646008850426

Epoch: 96| Step: 0
Training loss: 2.840146541595459
Validation loss: 2.542202345786556

Epoch: 6| Step: 1
Training loss: 2.5685875415802
Validation loss: 2.543668447002288

Epoch: 6| Step: 2
Training loss: 3.2662177085876465
Validation loss: 2.543978896192325

Epoch: 6| Step: 3
Training loss: 2.5893030166625977
Validation loss: 2.54196834564209

Epoch: 6| Step: 4
Training loss: 2.147475481033325
Validation loss: 2.544879739002515

Epoch: 6| Step: 5
Training loss: 2.787665367126465
Validation loss: 2.547381688189763

Epoch: 6| Step: 6
Training loss: 2.7527289390563965
Validation loss: 2.5455752880342546

Epoch: 6| Step: 7
Training loss: 2.3196587562561035
Validation loss: 2.5476795729770454

Epoch: 6| Step: 8
Training loss: 1.7740617990493774
Validation loss: 2.5471754663734028

Epoch: 6| Step: 9
Training loss: 2.531799554824829
Validation loss: 2.5485387207359396

Epoch: 6| Step: 10
Training loss: 2.530946731567383
Validation loss: 2.5493174445244575

Epoch: 6| Step: 11
Training loss: 3.729897975921631
Validation loss: 2.552164864796464

Epoch: 6| Step: 12
Training loss: 3.0389223098754883
Validation loss: 2.548466641415832

Epoch: 6| Step: 13
Training loss: 3.7350034713745117
Validation loss: 2.5502878773596978

Epoch: 97| Step: 0
Training loss: 3.244765043258667
Validation loss: 2.5480030352069485

Epoch: 6| Step: 1
Training loss: 2.987461566925049
Validation loss: 2.546766798983338

Epoch: 6| Step: 2
Training loss: 3.429926633834839
Validation loss: 2.5448274945700042

Epoch: 6| Step: 3
Training loss: 2.233079195022583
Validation loss: 2.544616105735943

Epoch: 6| Step: 4
Training loss: 1.9243985414505005
Validation loss: 2.539757056902814

Epoch: 6| Step: 5
Training loss: 2.9777259826660156
Validation loss: 2.5493339902611187

Epoch: 6| Step: 6
Training loss: 2.8736114501953125
Validation loss: 2.544893164788523

Epoch: 6| Step: 7
Training loss: 2.4167447090148926
Validation loss: 2.5440674981763287

Epoch: 6| Step: 8
Training loss: 2.366637945175171
Validation loss: 2.5402010230607885

Epoch: 6| Step: 9
Training loss: 3.034205198287964
Validation loss: 2.5433352173015638

Epoch: 6| Step: 10
Training loss: 2.7159833908081055
Validation loss: 2.5427126705005603

Epoch: 6| Step: 11
Training loss: 2.60031795501709
Validation loss: 2.5401276901204097

Epoch: 6| Step: 12
Training loss: 2.7917613983154297
Validation loss: 2.545978412833265

Epoch: 6| Step: 13
Training loss: 2.3641695976257324
Validation loss: 2.5407660186931653

Epoch: 98| Step: 0
Training loss: 2.258340358734131
Validation loss: 2.544179718981507

Epoch: 6| Step: 1
Training loss: 2.5829286575317383
Validation loss: 2.5413881873571746

Epoch: 6| Step: 2
Training loss: 2.2442052364349365
Validation loss: 2.5407402669229815

Epoch: 6| Step: 3
Training loss: 3.1563963890075684
Validation loss: 2.5406866535063712

Epoch: 6| Step: 4
Training loss: 3.6972389221191406
Validation loss: 2.546801754223403

Epoch: 6| Step: 5
Training loss: 2.4049906730651855
Validation loss: 2.543987471570251

Epoch: 6| Step: 6
Training loss: 2.7426114082336426
Validation loss: 2.54070383246227

Epoch: 6| Step: 7
Training loss: 2.643068790435791
Validation loss: 2.5392192332975325

Epoch: 6| Step: 8
Training loss: 2.831058979034424
Validation loss: 2.5389913333359586

Epoch: 6| Step: 9
Training loss: 3.043870210647583
Validation loss: 2.543987745879799

Epoch: 6| Step: 10
Training loss: 2.6766390800476074
Validation loss: 2.542828634221067

Epoch: 6| Step: 11
Training loss: 2.5281805992126465
Validation loss: 2.541432588331161

Epoch: 6| Step: 12
Training loss: 2.881744861602783
Validation loss: 2.541867220273582

Epoch: 6| Step: 13
Training loss: 2.1841306686401367
Validation loss: 2.546221051164853

Epoch: 99| Step: 0
Training loss: 4.076607704162598
Validation loss: 2.56148164374854

Epoch: 6| Step: 1
Training loss: 2.5099849700927734
Validation loss: 2.5569006781424246

Epoch: 6| Step: 2
Training loss: 2.742434501647949
Validation loss: 2.55686290033402

Epoch: 6| Step: 3
Training loss: 2.5880541801452637
Validation loss: 2.559453095159223

Epoch: 6| Step: 4
Training loss: 2.9355156421661377
Validation loss: 2.5555544566082697

Epoch: 6| Step: 5
Training loss: 2.668818473815918
Validation loss: 2.5543835880935832

Epoch: 6| Step: 6
Training loss: 3.067784309387207
Validation loss: 2.5482334808636735

Epoch: 6| Step: 7
Training loss: 2.2525510787963867
Validation loss: 2.543683075135754

Epoch: 6| Step: 8
Training loss: 3.3451294898986816
Validation loss: 2.5414719017603065

Epoch: 6| Step: 9
Training loss: 2.774461269378662
Validation loss: 2.5431091887976534

Epoch: 6| Step: 10
Training loss: 2.2262043952941895
Validation loss: 2.5420236202978317

Epoch: 6| Step: 11
Training loss: 2.0983805656433105
Validation loss: 2.544538426142867

Epoch: 6| Step: 12
Training loss: 2.2952113151550293
Validation loss: 2.5514354885265393

Epoch: 6| Step: 13
Training loss: 2.7199630737304688
Validation loss: 2.555998038220149

Epoch: 100| Step: 0
Training loss: 1.9635355472564697
Validation loss: 2.558000249247397

Epoch: 6| Step: 1
Training loss: 2.0722339153289795
Validation loss: 2.563575408791983

Epoch: 6| Step: 2
Training loss: 3.151746988296509
Validation loss: 2.549795566066619

Epoch: 6| Step: 3
Training loss: 2.732257604598999
Validation loss: 2.5423794382361957

Epoch: 6| Step: 4
Training loss: 3.2502315044403076
Validation loss: 2.5373447223376204

Epoch: 6| Step: 5
Training loss: 2.976184844970703
Validation loss: 2.533502327498569

Epoch: 6| Step: 6
Training loss: 2.0421905517578125
Validation loss: 2.531565507253011

Epoch: 6| Step: 7
Training loss: 1.9659448862075806
Validation loss: 2.5354021800461637

Epoch: 6| Step: 8
Training loss: 2.9826560020446777
Validation loss: 2.53678911219361

Epoch: 6| Step: 9
Training loss: 3.3333349227905273
Validation loss: 2.5382680534034647

Epoch: 6| Step: 10
Training loss: 2.591500759124756
Validation loss: 2.539345928417739

Epoch: 6| Step: 11
Training loss: 2.704197645187378
Validation loss: 2.5340328011461484

Epoch: 6| Step: 12
Training loss: 3.2101593017578125
Validation loss: 2.536609962422361

Epoch: 6| Step: 13
Training loss: 3.524491786956787
Validation loss: 2.5328017306584183

Epoch: 101| Step: 0
Training loss: 2.29783034324646
Validation loss: 2.528636122262606

Epoch: 6| Step: 1
Training loss: 2.711042881011963
Validation loss: 2.5316409705787577

Epoch: 6| Step: 2
Training loss: 3.1264517307281494
Validation loss: 2.537369776797551

Epoch: 6| Step: 3
Training loss: 2.1393256187438965
Validation loss: 2.5369144357660764

Epoch: 6| Step: 4
Training loss: 2.339491128921509
Validation loss: 2.53744331482918

Epoch: 6| Step: 5
Training loss: 2.7618298530578613
Validation loss: 2.5363558415443666

Epoch: 6| Step: 6
Training loss: 2.5275673866271973
Validation loss: 2.5384228665341615

Epoch: 6| Step: 7
Training loss: 3.299443483352661
Validation loss: 2.550199624030821

Epoch: 6| Step: 8
Training loss: 2.240877866744995
Validation loss: 2.54265171481717

Epoch: 6| Step: 9
Training loss: 3.471273422241211
Validation loss: 2.5471270520200013

Epoch: 6| Step: 10
Training loss: 2.4295098781585693
Validation loss: 2.542968511581421

Epoch: 6| Step: 11
Training loss: 2.736323356628418
Validation loss: 2.5410516467145694

Epoch: 6| Step: 12
Training loss: 2.832158088684082
Validation loss: 2.5462807865553003

Epoch: 6| Step: 13
Training loss: 3.39663028717041
Validation loss: 2.5386175673495055

Epoch: 102| Step: 0
Training loss: 2.5749387741088867
Validation loss: 2.542128437308855

Epoch: 6| Step: 1
Training loss: 2.8732447624206543
Validation loss: 2.542166776554559

Epoch: 6| Step: 2
Training loss: 2.8153066635131836
Validation loss: 2.545089572988531

Epoch: 6| Step: 3
Training loss: 2.521676540374756
Validation loss: 2.539744718100435

Epoch: 6| Step: 4
Training loss: 2.8765156269073486
Validation loss: 2.5349521124234764

Epoch: 6| Step: 5
Training loss: 3.0825300216674805
Validation loss: 2.5408883120424006

Epoch: 6| Step: 6
Training loss: 2.361429214477539
Validation loss: 2.5373089826235207

Epoch: 6| Step: 7
Training loss: 2.6057772636413574
Validation loss: 2.5357282161712646

Epoch: 6| Step: 8
Training loss: 2.8031046390533447
Validation loss: 2.5338035911642094

Epoch: 6| Step: 9
Training loss: 2.2355968952178955
Validation loss: 2.534508233429283

Epoch: 6| Step: 10
Training loss: 2.8721699714660645
Validation loss: 2.5327723462094545

Epoch: 6| Step: 11
Training loss: 3.249433994293213
Validation loss: 2.5352969964345298

Epoch: 6| Step: 12
Training loss: 3.001760959625244
Validation loss: 2.530912750510759

Epoch: 6| Step: 13
Training loss: 1.558842420578003
Validation loss: 2.5331490168007473

Epoch: 103| Step: 0
Training loss: 2.277330160140991
Validation loss: 2.5317544526951288

Epoch: 6| Step: 1
Training loss: 3.5008137226104736
Validation loss: 2.5320325384857836

Epoch: 6| Step: 2
Training loss: 3.1503381729125977
Validation loss: 2.5323065993606404

Epoch: 6| Step: 3
Training loss: 2.3699960708618164
Validation loss: 2.537794510523478

Epoch: 6| Step: 4
Training loss: 2.465646266937256
Validation loss: 2.544872724881736

Epoch: 6| Step: 5
Training loss: 2.584568738937378
Validation loss: 2.545023625896823

Epoch: 6| Step: 6
Training loss: 3.4039783477783203
Validation loss: 2.543999295080862

Epoch: 6| Step: 7
Training loss: 2.5726656913757324
Validation loss: 2.5407729661592873

Epoch: 6| Step: 8
Training loss: 3.3039910793304443
Validation loss: 2.5326774299785657

Epoch: 6| Step: 9
Training loss: 2.0564494132995605
Validation loss: 2.533310720997472

Epoch: 6| Step: 10
Training loss: 2.544067859649658
Validation loss: 2.5300847458583053

Epoch: 6| Step: 11
Training loss: 2.1323025226593018
Validation loss: 2.528160184942266

Epoch: 6| Step: 12
Training loss: 2.806837320327759
Validation loss: 2.5344591474020355

Epoch: 6| Step: 13
Training loss: 3.0501115322113037
Validation loss: 2.541118629517094

Epoch: 104| Step: 0
Training loss: 2.4544589519500732
Validation loss: 2.5395392269216557

Epoch: 6| Step: 1
Training loss: 2.1658008098602295
Validation loss: 2.549103239531158

Epoch: 6| Step: 2
Training loss: 2.629701614379883
Validation loss: 2.55929466729523

Epoch: 6| Step: 3
Training loss: 3.4112119674682617
Validation loss: 2.561497426802112

Epoch: 6| Step: 4
Training loss: 2.946955680847168
Validation loss: 2.5594103285061416

Epoch: 6| Step: 5
Training loss: 3.1124420166015625
Validation loss: 2.552862423722462

Epoch: 6| Step: 6
Training loss: 3.435300827026367
Validation loss: 2.548261506583101

Epoch: 6| Step: 7
Training loss: 3.2161035537719727
Validation loss: 2.5418032189851165

Epoch: 6| Step: 8
Training loss: 3.085570812225342
Validation loss: 2.5339622523195002

Epoch: 6| Step: 9
Training loss: 2.207712411880493
Validation loss: 2.531101731843846

Epoch: 6| Step: 10
Training loss: 2.7085468769073486
Validation loss: 2.52305930916981

Epoch: 6| Step: 11
Training loss: 1.9264315366744995
Validation loss: 2.5265094875007548

Epoch: 6| Step: 12
Training loss: 2.067368507385254
Validation loss: 2.529054800669352

Epoch: 6| Step: 13
Training loss: 2.6457788944244385
Validation loss: 2.527134718433503

Epoch: 105| Step: 0
Training loss: 2.926166534423828
Validation loss: 2.53183408962783

Epoch: 6| Step: 1
Training loss: 3.6286392211914062
Validation loss: 2.5366188685099282

Epoch: 6| Step: 2
Training loss: 2.637446641921997
Validation loss: 2.5316767410565446

Epoch: 6| Step: 3
Training loss: 2.8368215560913086
Validation loss: 2.5303322320343344

Epoch: 6| Step: 4
Training loss: 2.7433676719665527
Validation loss: 2.5344184034614154

Epoch: 6| Step: 5
Training loss: 2.0248262882232666
Validation loss: 2.533498097491521

Epoch: 6| Step: 6
Training loss: 2.198352336883545
Validation loss: 2.5299317042032876

Epoch: 6| Step: 7
Training loss: 3.1526637077331543
Validation loss: 2.5276755927711405

Epoch: 6| Step: 8
Training loss: 3.8625881671905518
Validation loss: 2.524083919422601

Epoch: 6| Step: 9
Training loss: 2.8363285064697266
Validation loss: 2.525858873962074

Epoch: 6| Step: 10
Training loss: 2.110319137573242
Validation loss: 2.5308029164550123

Epoch: 6| Step: 11
Training loss: 2.0715761184692383
Validation loss: 2.5257677544829664

Epoch: 6| Step: 12
Training loss: 2.6688718795776367
Validation loss: 2.5541216378570883

Epoch: 6| Step: 13
Training loss: 2.1971826553344727
Validation loss: 2.563089686055337

Epoch: 106| Step: 0
Training loss: 2.164206027984619
Validation loss: 2.58427091311383

Epoch: 6| Step: 1
Training loss: 1.94366455078125
Validation loss: 2.5959315146169355

Epoch: 6| Step: 2
Training loss: 3.677734851837158
Validation loss: 2.5926489137834117

Epoch: 6| Step: 3
Training loss: 2.231630802154541
Validation loss: 2.5725936812739216

Epoch: 6| Step: 4
Training loss: 2.6289355754852295
Validation loss: 2.567652015275853

Epoch: 6| Step: 5
Training loss: 2.690244197845459
Validation loss: 2.550941144266436

Epoch: 6| Step: 6
Training loss: 3.074639320373535
Validation loss: 2.530599776134696

Epoch: 6| Step: 7
Training loss: 3.1729137897491455
Validation loss: 2.530038551617694

Epoch: 6| Step: 8
Training loss: 2.9118871688842773
Validation loss: 2.5241289061884724

Epoch: 6| Step: 9
Training loss: 2.7247607707977295
Validation loss: 2.531136938320693

Epoch: 6| Step: 10
Training loss: 3.0989902019500732
Validation loss: 2.528630712980865

Epoch: 6| Step: 11
Training loss: 2.452230215072632
Validation loss: 2.5247057099496164

Epoch: 6| Step: 12
Training loss: 2.6745476722717285
Validation loss: 2.5259648497386644

Epoch: 6| Step: 13
Training loss: 2.983934164047241
Validation loss: 2.5224620167927077

Epoch: 107| Step: 0
Training loss: 2.5720601081848145
Validation loss: 2.5294230009919856

Epoch: 6| Step: 1
Training loss: 2.0083413124084473
Validation loss: 2.5257496500527985

Epoch: 6| Step: 2
Training loss: 3.0479092597961426
Validation loss: 2.5254713642981743

Epoch: 6| Step: 3
Training loss: 2.1037912368774414
Validation loss: 2.5292650115105415

Epoch: 6| Step: 4
Training loss: 1.9839582443237305
Validation loss: 2.5321512478654102

Epoch: 6| Step: 5
Training loss: 3.2329232692718506
Validation loss: 2.5376838227753997

Epoch: 6| Step: 6
Training loss: 2.674412488937378
Validation loss: 2.5400066068095546

Epoch: 6| Step: 7
Training loss: 3.190364360809326
Validation loss: 2.543763114560035

Epoch: 6| Step: 8
Training loss: 2.731428384780884
Validation loss: 2.537750485122845

Epoch: 6| Step: 9
Training loss: 2.8381619453430176
Validation loss: 2.54214160929444

Epoch: 6| Step: 10
Training loss: 2.543041706085205
Validation loss: 2.5466201869390344

Epoch: 6| Step: 11
Training loss: 2.558864116668701
Validation loss: 2.540389530120357

Epoch: 6| Step: 12
Training loss: 3.200643539428711
Validation loss: 2.5387705167134604

Epoch: 6| Step: 13
Training loss: 3.807837963104248
Validation loss: 2.533604234777471

Epoch: 108| Step: 0
Training loss: 3.089906930923462
Validation loss: 2.5371535055098997

Epoch: 6| Step: 1
Training loss: 3.4451138973236084
Validation loss: 2.5333757131330428

Epoch: 6| Step: 2
Training loss: 2.57247257232666
Validation loss: 2.5367046581801547

Epoch: 6| Step: 3
Training loss: 2.48606538772583
Validation loss: 2.5359707135026173

Epoch: 6| Step: 4
Training loss: 2.538344144821167
Validation loss: 2.5414972177115818

Epoch: 6| Step: 5
Training loss: 1.7780425548553467
Validation loss: 2.5340481547899145

Epoch: 6| Step: 6
Training loss: 2.5516228675842285
Validation loss: 2.531198650278071

Epoch: 6| Step: 7
Training loss: 2.434067964553833
Validation loss: 2.5216245010334957

Epoch: 6| Step: 8
Training loss: 2.393190383911133
Validation loss: 2.5177108549302623

Epoch: 6| Step: 9
Training loss: 3.275317668914795
Validation loss: 2.515400299461939

Epoch: 6| Step: 10
Training loss: 3.2028913497924805
Validation loss: 2.515212284621372

Epoch: 6| Step: 11
Training loss: 2.700852394104004
Validation loss: 2.5181971442314888

Epoch: 6| Step: 12
Training loss: 2.4834375381469727
Validation loss: 2.5201127708599134

Epoch: 6| Step: 13
Training loss: 3.2128725051879883
Validation loss: 2.523477492793914

Epoch: 109| Step: 0
Training loss: 2.637033462524414
Validation loss: 2.520412934723721

Epoch: 6| Step: 1
Training loss: 3.0151190757751465
Validation loss: 2.5246457079405427

Epoch: 6| Step: 2
Training loss: 2.35205078125
Validation loss: 2.5244228070782078

Epoch: 6| Step: 3
Training loss: 2.675482749938965
Validation loss: 2.5191992687922653

Epoch: 6| Step: 4
Training loss: 2.8777689933776855
Validation loss: 2.5199723756441506

Epoch: 6| Step: 5
Training loss: 3.4936532974243164
Validation loss: 2.5183111672760337

Epoch: 6| Step: 6
Training loss: 2.82492733001709
Validation loss: 2.514256138955393

Epoch: 6| Step: 7
Training loss: 2.605679750442505
Validation loss: 2.5129207411120014

Epoch: 6| Step: 8
Training loss: 2.7346348762512207
Validation loss: 2.514615538299725

Epoch: 6| Step: 9
Training loss: 2.5327625274658203
Validation loss: 2.5180729230244956

Epoch: 6| Step: 10
Training loss: 2.5858845710754395
Validation loss: 2.5156133892715618

Epoch: 6| Step: 11
Training loss: 2.974405288696289
Validation loss: 2.521443715659521

Epoch: 6| Step: 12
Training loss: 2.0880870819091797
Validation loss: 2.5181858257580827

Epoch: 6| Step: 13
Training loss: 2.447333335876465
Validation loss: 2.5190769498066237

Epoch: 110| Step: 0
Training loss: 2.9626059532165527
Validation loss: 2.521084216333205

Epoch: 6| Step: 1
Training loss: 1.8275220394134521
Validation loss: 2.5209901332855225

Epoch: 6| Step: 2
Training loss: 2.64495849609375
Validation loss: 2.5137973395727014

Epoch: 6| Step: 3
Training loss: 3.267642021179199
Validation loss: 2.517793127285537

Epoch: 6| Step: 4
Training loss: 3.3147060871124268
Validation loss: 2.5182541313991753

Epoch: 6| Step: 5
Training loss: 2.160257339477539
Validation loss: 2.5247741745364283

Epoch: 6| Step: 6
Training loss: 2.6377663612365723
Validation loss: 2.5243255553707

Epoch: 6| Step: 7
Training loss: 2.911562919616699
Validation loss: 2.525048530229958

Epoch: 6| Step: 8
Training loss: 3.1374316215515137
Validation loss: 2.5285879642732683

Epoch: 6| Step: 9
Training loss: 2.7917726039886475
Validation loss: 2.521998587475028

Epoch: 6| Step: 10
Training loss: 2.6773085594177246
Validation loss: 2.5212181024653937

Epoch: 6| Step: 11
Training loss: 1.8223942518234253
Validation loss: 2.5171008058773574

Epoch: 6| Step: 12
Training loss: 2.8767974376678467
Validation loss: 2.519984875955889

Epoch: 6| Step: 13
Training loss: 2.9036073684692383
Validation loss: 2.5160848838026806

Epoch: 111| Step: 0
Training loss: 2.722355365753174
Validation loss: 2.5193646300223564

Epoch: 6| Step: 1
Training loss: 3.4001903533935547
Validation loss: 2.5306231488463697

Epoch: 6| Step: 2
Training loss: 2.0895330905914307
Validation loss: 2.5287052674960067

Epoch: 6| Step: 3
Training loss: 2.5827510356903076
Validation loss: 2.53346283717822

Epoch: 6| Step: 4
Training loss: 2.748440742492676
Validation loss: 2.546613811164774

Epoch: 6| Step: 5
Training loss: 3.0945992469787598
Validation loss: 2.5616786018494637

Epoch: 6| Step: 6
Training loss: 2.9899065494537354
Validation loss: 2.558442284983973

Epoch: 6| Step: 7
Training loss: 2.7955007553100586
Validation loss: 2.550827810841222

Epoch: 6| Step: 8
Training loss: 2.3033199310302734
Validation loss: 2.5443963209788003

Epoch: 6| Step: 9
Training loss: 2.9231784343719482
Validation loss: 2.5374320809559157

Epoch: 6| Step: 10
Training loss: 2.780538558959961
Validation loss: 2.5263693665945404

Epoch: 6| Step: 11
Training loss: 1.9079546928405762
Validation loss: 2.5234258841442805

Epoch: 6| Step: 12
Training loss: 2.819155216217041
Validation loss: 2.5215837647837978

Epoch: 6| Step: 13
Training loss: 2.95491623878479
Validation loss: 2.5216243343968547

Epoch: 112| Step: 0
Training loss: 2.4629788398742676
Validation loss: 2.52158292647331

Epoch: 6| Step: 1
Training loss: 2.5294153690338135
Validation loss: 2.5209919047612015

Epoch: 6| Step: 2
Training loss: 3.1543257236480713
Validation loss: 2.517770431374991

Epoch: 6| Step: 3
Training loss: 2.6000053882598877
Validation loss: 2.515760193588913

Epoch: 6| Step: 4
Training loss: 2.2792491912841797
Validation loss: 2.5192240566335697

Epoch: 6| Step: 5
Training loss: 2.8240702152252197
Validation loss: 2.5244620410344933

Epoch: 6| Step: 6
Training loss: 3.1732242107391357
Validation loss: 2.5230719530454246

Epoch: 6| Step: 7
Training loss: 2.3644938468933105
Validation loss: 2.525342631083663

Epoch: 6| Step: 8
Training loss: 2.7123026847839355
Validation loss: 2.527017967675322

Epoch: 6| Step: 9
Training loss: 2.5045881271362305
Validation loss: 2.5339276508618425

Epoch: 6| Step: 10
Training loss: 2.511354446411133
Validation loss: 2.528567365420762

Epoch: 6| Step: 11
Training loss: 2.8429136276245117
Validation loss: 2.530223564435077

Epoch: 6| Step: 12
Training loss: 2.7140369415283203
Validation loss: 2.5322595924459477

Epoch: 6| Step: 13
Training loss: 3.361551523208618
Validation loss: 2.533467931132163

Epoch: 113| Step: 0
Training loss: 2.8225886821746826
Validation loss: 2.5379860644699423

Epoch: 6| Step: 1
Training loss: 3.12839937210083
Validation loss: 2.536351091118269

Epoch: 6| Step: 2
Training loss: 1.9962363243103027
Validation loss: 2.523734897695562

Epoch: 6| Step: 3
Training loss: 2.860492706298828
Validation loss: 2.5200858116149902

Epoch: 6| Step: 4
Training loss: 3.055384635925293
Validation loss: 2.520423673814343

Epoch: 6| Step: 5
Training loss: 2.8086795806884766
Validation loss: 2.520879635246851

Epoch: 6| Step: 6
Training loss: 2.398686408996582
Validation loss: 2.5187734788463962

Epoch: 6| Step: 7
Training loss: 2.2971110343933105
Validation loss: 2.517388853975522

Epoch: 6| Step: 8
Training loss: 3.165424346923828
Validation loss: 2.5190916651038715

Epoch: 6| Step: 9
Training loss: 2.494227886199951
Validation loss: 2.5139236706559376

Epoch: 6| Step: 10
Training loss: 2.584437370300293
Validation loss: 2.5198204286636843

Epoch: 6| Step: 11
Training loss: 2.737457752227783
Validation loss: 2.5135663991333335

Epoch: 6| Step: 12
Training loss: 2.7881507873535156
Validation loss: 2.5263468501388386

Epoch: 6| Step: 13
Training loss: 2.6169943809509277
Validation loss: 2.529319847783735

Epoch: 114| Step: 0
Training loss: 2.364320755004883
Validation loss: 2.52686369803644

Epoch: 6| Step: 1
Training loss: 2.8767945766448975
Validation loss: 2.5325420364256828

Epoch: 6| Step: 2
Training loss: 3.623631477355957
Validation loss: 2.531532964398784

Epoch: 6| Step: 3
Training loss: 1.9070411920547485
Validation loss: 2.541285522522465

Epoch: 6| Step: 4
Training loss: 2.425116539001465
Validation loss: 2.5262029888809368

Epoch: 6| Step: 5
Training loss: 2.739278793334961
Validation loss: 2.5177166513217393

Epoch: 6| Step: 6
Training loss: 2.9998791217803955
Validation loss: 2.514447053273519

Epoch: 6| Step: 7
Training loss: 2.2680137157440186
Validation loss: 2.5177813345386135

Epoch: 6| Step: 8
Training loss: 2.5436620712280273
Validation loss: 2.518832927109093

Epoch: 6| Step: 9
Training loss: 2.4483861923217773
Validation loss: 2.5202971889126684

Epoch: 6| Step: 10
Training loss: 2.847970485687256
Validation loss: 2.525133281625727

Epoch: 6| Step: 11
Training loss: 3.217256784439087
Validation loss: 2.5273067643565517

Epoch: 6| Step: 12
Training loss: 2.4886436462402344
Validation loss: 2.5310454060954433

Epoch: 6| Step: 13
Training loss: 3.1619107723236084
Validation loss: 2.5254026484745804

Epoch: 115| Step: 0
Training loss: 2.3249073028564453
Validation loss: 2.5263711739611883

Epoch: 6| Step: 1
Training loss: 3.1470999717712402
Validation loss: 2.523374234476397

Epoch: 6| Step: 2
Training loss: 2.8610496520996094
Validation loss: 2.5178974866867065

Epoch: 6| Step: 3
Training loss: 3.0480899810791016
Validation loss: 2.5134590928272535

Epoch: 6| Step: 4
Training loss: 2.786856174468994
Validation loss: 2.5053260275112685

Epoch: 6| Step: 5
Training loss: 2.2803444862365723
Validation loss: 2.5105488172141452

Epoch: 6| Step: 6
Training loss: 3.224973201751709
Validation loss: 2.5081035962668796

Epoch: 6| Step: 7
Training loss: 3.1410574913024902
Validation loss: 2.510760430366762

Epoch: 6| Step: 8
Training loss: 3.278273105621338
Validation loss: 2.508828639984131

Epoch: 6| Step: 9
Training loss: 1.6715283393859863
Validation loss: 2.511369275790389

Epoch: 6| Step: 10
Training loss: 3.093550443649292
Validation loss: 2.511776296041345

Epoch: 6| Step: 11
Training loss: 2.3993029594421387
Validation loss: 2.5153010045328448

Epoch: 6| Step: 12
Training loss: 2.3500680923461914
Validation loss: 2.5160995555180374

Epoch: 6| Step: 13
Training loss: 2.01719069480896
Validation loss: 2.511388791504727

Epoch: 116| Step: 0
Training loss: 2.409264087677002
Validation loss: 2.5086376423476846

Epoch: 6| Step: 1
Training loss: 2.0987439155578613
Validation loss: 2.5037524712983

Epoch: 6| Step: 2
Training loss: 2.930819272994995
Validation loss: 2.5019028468798568

Epoch: 6| Step: 3
Training loss: 2.2880048751831055
Validation loss: 2.5014998015537055

Epoch: 6| Step: 4
Training loss: 3.0802576541900635
Validation loss: 2.501425140647478

Epoch: 6| Step: 5
Training loss: 2.8162240982055664
Validation loss: 2.5077704434753745

Epoch: 6| Step: 6
Training loss: 3.5640854835510254
Validation loss: 2.508359216874646

Epoch: 6| Step: 7
Training loss: 3.638530731201172
Validation loss: 2.5153473346464095

Epoch: 6| Step: 8
Training loss: 3.336862564086914
Validation loss: 2.5257579716303016

Epoch: 6| Step: 9
Training loss: 1.7541484832763672
Validation loss: 2.520311140245007

Epoch: 6| Step: 10
Training loss: 2.2997493743896484
Validation loss: 2.523846585263488

Epoch: 6| Step: 11
Training loss: 2.523127317428589
Validation loss: 2.5227982356984127

Epoch: 6| Step: 12
Training loss: 2.038057565689087
Validation loss: 2.5215690264137844

Epoch: 6| Step: 13
Training loss: 3.2928359508514404
Validation loss: 2.519625720157418

Epoch: 117| Step: 0
Training loss: 2.785187005996704
Validation loss: 2.5227549204262356

Epoch: 6| Step: 1
Training loss: 2.4567818641662598
Validation loss: 2.5161603778921147

Epoch: 6| Step: 2
Training loss: 3.5382485389709473
Validation loss: 2.5258539902266635

Epoch: 6| Step: 3
Training loss: 3.853853225708008
Validation loss: 2.519295638607394

Epoch: 6| Step: 4
Training loss: 2.2327568531036377
Validation loss: 2.5178525037662958

Epoch: 6| Step: 5
Training loss: 2.8109254837036133
Validation loss: 2.512584445297077

Epoch: 6| Step: 6
Training loss: 1.9752557277679443
Validation loss: 2.5039403438568115

Epoch: 6| Step: 7
Training loss: 2.8977549076080322
Validation loss: 2.502733043445054

Epoch: 6| Step: 8
Training loss: 2.8356027603149414
Validation loss: 2.502205571820659

Epoch: 6| Step: 9
Training loss: 2.3842906951904297
Validation loss: 2.5039981872804704

Epoch: 6| Step: 10
Training loss: 2.606994867324829
Validation loss: 2.50337637880797

Epoch: 6| Step: 11
Training loss: 2.4186320304870605
Validation loss: 2.501195030827676

Epoch: 6| Step: 12
Training loss: 2.6880359649658203
Validation loss: 2.502551729961108

Epoch: 6| Step: 13
Training loss: 1.993255376815796
Validation loss: 2.499354911106889

Epoch: 118| Step: 0
Training loss: 3.240269899368286
Validation loss: 2.5052436603012906

Epoch: 6| Step: 1
Training loss: 2.7511770725250244
Validation loss: 2.49854043991335

Epoch: 6| Step: 2
Training loss: 2.563854932785034
Validation loss: 2.5002689130844606

Epoch: 6| Step: 3
Training loss: 2.4413700103759766
Validation loss: 2.4976367745348202

Epoch: 6| Step: 4
Training loss: 3.569237232208252
Validation loss: 2.4997729537307576

Epoch: 6| Step: 5
Training loss: 1.374291181564331
Validation loss: 2.5032799910473567

Epoch: 6| Step: 6
Training loss: 3.403082847595215
Validation loss: 2.501466630607523

Epoch: 6| Step: 7
Training loss: 2.5492751598358154
Validation loss: 2.5009625855312554

Epoch: 6| Step: 8
Training loss: 3.1668832302093506
Validation loss: 2.4999062322801158

Epoch: 6| Step: 9
Training loss: 2.534292697906494
Validation loss: 2.4994452230391966

Epoch: 6| Step: 10
Training loss: 2.2213046550750732
Validation loss: 2.5010498057129564

Epoch: 6| Step: 11
Training loss: 2.369873046875
Validation loss: 2.501907640887845

Epoch: 6| Step: 12
Training loss: 2.7771823406219482
Validation loss: 2.500481923421224

Epoch: 6| Step: 13
Training loss: 2.7734827995300293
Validation loss: 2.506587461758685

Epoch: 119| Step: 0
Training loss: 2.008181095123291
Validation loss: 2.510615098860956

Epoch: 6| Step: 1
Training loss: 1.9079780578613281
Validation loss: 2.5081421611129597

Epoch: 6| Step: 2
Training loss: 2.703214406967163
Validation loss: 2.507961186029578

Epoch: 6| Step: 3
Training loss: 2.2622690200805664
Validation loss: 2.51126512148047

Epoch: 6| Step: 4
Training loss: 3.0130276679992676
Validation loss: 2.5038525186559206

Epoch: 6| Step: 5
Training loss: 2.2383689880371094
Validation loss: 2.5059049616577806

Epoch: 6| Step: 6
Training loss: 2.277848720550537
Validation loss: 2.5015571886493313

Epoch: 6| Step: 7
Training loss: 3.1617774963378906
Validation loss: 2.5064951617230653

Epoch: 6| Step: 8
Training loss: 3.5519516468048096
Validation loss: 2.503332007315851

Epoch: 6| Step: 9
Training loss: 3.3525021076202393
Validation loss: 2.5074196015634844

Epoch: 6| Step: 10
Training loss: 3.0304505825042725
Validation loss: 2.5091031136051303

Epoch: 6| Step: 11
Training loss: 2.6519336700439453
Validation loss: 2.508493620862243

Epoch: 6| Step: 12
Training loss: 2.641340970993042
Validation loss: 2.5085839968855663

Epoch: 6| Step: 13
Training loss: 3.0723636150360107
Validation loss: 2.512753427669566

Epoch: 120| Step: 0
Training loss: 2.3406314849853516
Validation loss: 2.5085708710455124

Epoch: 6| Step: 1
Training loss: 2.6455225944519043
Validation loss: 2.513066009808612

Epoch: 6| Step: 2
Training loss: 3.1445376873016357
Validation loss: 2.5028909098717476

Epoch: 6| Step: 3
Training loss: 2.102060317993164
Validation loss: 2.5014720142528577

Epoch: 6| Step: 4
Training loss: 3.033345937728882
Validation loss: 2.4967517288782264

Epoch: 6| Step: 5
Training loss: 2.216357469558716
Validation loss: 2.495736188786004

Epoch: 6| Step: 6
Training loss: 3.086531162261963
Validation loss: 2.4945614389193955

Epoch: 6| Step: 7
Training loss: 3.205869197845459
Validation loss: 2.498074080354424

Epoch: 6| Step: 8
Training loss: 1.9248239994049072
Validation loss: 2.5022479629003875

Epoch: 6| Step: 9
Training loss: 2.416388511657715
Validation loss: 2.509369691212972

Epoch: 6| Step: 10
Training loss: 2.9655444622039795
Validation loss: 2.5161689276336343

Epoch: 6| Step: 11
Training loss: 2.719210147857666
Validation loss: 2.5232465382545226

Epoch: 6| Step: 12
Training loss: 3.2701096534729004
Validation loss: 2.528384990589593

Epoch: 6| Step: 13
Training loss: 2.527676582336426
Validation loss: 2.5228416381343717

Epoch: 121| Step: 0
Training loss: 2.6727614402770996
Validation loss: 2.51269696604821

Epoch: 6| Step: 1
Training loss: 2.4452738761901855
Validation loss: 2.5005189577738443

Epoch: 6| Step: 2
Training loss: 2.1884613037109375
Validation loss: 2.502052750638736

Epoch: 6| Step: 3
Training loss: 2.7377007007598877
Validation loss: 2.505927167912965

Epoch: 6| Step: 4
Training loss: 3.057310104370117
Validation loss: 2.501367312605663

Epoch: 6| Step: 5
Training loss: 3.262214422225952
Validation loss: 2.5108959392834733

Epoch: 6| Step: 6
Training loss: 1.8869222402572632
Validation loss: 2.508904210982784

Epoch: 6| Step: 7
Training loss: 2.8707165718078613
Validation loss: 2.505388903361495

Epoch: 6| Step: 8
Training loss: 2.459721326828003
Validation loss: 2.5071332531590618

Epoch: 6| Step: 9
Training loss: 2.5298314094543457
Validation loss: 2.5079851586331605

Epoch: 6| Step: 10
Training loss: 3.220776081085205
Validation loss: 2.5013477815094816

Epoch: 6| Step: 11
Training loss: 2.261686325073242
Validation loss: 2.499914930712792

Epoch: 6| Step: 12
Training loss: 3.451005458831787
Validation loss: 2.5009871734085904

Epoch: 6| Step: 13
Training loss: 2.562258720397949
Validation loss: 2.5002946622910036

Epoch: 122| Step: 0
Training loss: 2.279473304748535
Validation loss: 2.4945830324644684

Epoch: 6| Step: 1
Training loss: 2.6212878227233887
Validation loss: 2.4938146196385866

Epoch: 6| Step: 2
Training loss: 2.8288309574127197
Validation loss: 2.4949747234262447

Epoch: 6| Step: 3
Training loss: 2.501267433166504
Validation loss: 2.4894802480615597

Epoch: 6| Step: 4
Training loss: 2.1594505310058594
Validation loss: 2.4906283527292232

Epoch: 6| Step: 5
Training loss: 3.1257925033569336
Validation loss: 2.4897945516852924

Epoch: 6| Step: 6
Training loss: 3.136465549468994
Validation loss: 2.4872230970731346

Epoch: 6| Step: 7
Training loss: 2.556511878967285
Validation loss: 2.4870953508602676

Epoch: 6| Step: 8
Training loss: 1.9870328903198242
Validation loss: 2.488979229363062

Epoch: 6| Step: 9
Training loss: 3.272826671600342
Validation loss: 2.491643856930476

Epoch: 6| Step: 10
Training loss: 3.361013889312744
Validation loss: 2.4921959856505036

Epoch: 6| Step: 11
Training loss: 2.1560254096984863
Validation loss: 2.4958834468677478

Epoch: 6| Step: 12
Training loss: 2.6290132999420166
Validation loss: 2.5030609048822874

Epoch: 6| Step: 13
Training loss: 3.363795280456543
Validation loss: 2.517313923887027

Epoch: 123| Step: 0
Training loss: 2.1286308765411377
Validation loss: 2.529387112586729

Epoch: 6| Step: 1
Training loss: 2.6195030212402344
Validation loss: 2.5336952568382345

Epoch: 6| Step: 2
Training loss: 3.172738552093506
Validation loss: 2.534039702466739

Epoch: 6| Step: 3
Training loss: 3.020601272583008
Validation loss: 2.5215204813147105

Epoch: 6| Step: 4
Training loss: 3.0749447345733643
Validation loss: 2.511999655795354

Epoch: 6| Step: 5
Training loss: 2.45808744430542
Validation loss: 2.5072290282095633

Epoch: 6| Step: 6
Training loss: 2.483574867248535
Validation loss: 2.5003563383574128

Epoch: 6| Step: 7
Training loss: 2.2877163887023926
Validation loss: 2.499475840599306

Epoch: 6| Step: 8
Training loss: 2.872447967529297
Validation loss: 2.4890225241261144

Epoch: 6| Step: 9
Training loss: 3.0459883213043213
Validation loss: 2.499461935412499

Epoch: 6| Step: 10
Training loss: 3.028101921081543
Validation loss: 2.48951724267775

Epoch: 6| Step: 11
Training loss: 2.3346521854400635
Validation loss: 2.4898485650298414

Epoch: 6| Step: 12
Training loss: 2.6872620582580566
Validation loss: 2.4926885789440525

Epoch: 6| Step: 13
Training loss: 2.2116470336914062
Validation loss: 2.4864579221253753

Epoch: 124| Step: 0
Training loss: 2.7464733123779297
Validation loss: 2.4871697425842285

Epoch: 6| Step: 1
Training loss: 2.370417594909668
Validation loss: 2.495327459868564

Epoch: 6| Step: 2
Training loss: 2.8218841552734375
Validation loss: 2.501285437614687

Epoch: 6| Step: 3
Training loss: 2.1629080772399902
Validation loss: 2.4984108273701002

Epoch: 6| Step: 4
Training loss: 2.683016300201416
Validation loss: 2.5041320426489717

Epoch: 6| Step: 5
Training loss: 2.8738255500793457
Validation loss: 2.4924653358356927

Epoch: 6| Step: 6
Training loss: 2.0641582012176514
Validation loss: 2.5023601516600578

Epoch: 6| Step: 7
Training loss: 2.5118801593780518
Validation loss: 2.504711133177562

Epoch: 6| Step: 8
Training loss: 2.2986502647399902
Validation loss: 2.504619800916282

Epoch: 6| Step: 9
Training loss: 3.1922719478607178
Validation loss: 2.5048493082805345

Epoch: 6| Step: 10
Training loss: 3.1741721630096436
Validation loss: 2.4989199817821546

Epoch: 6| Step: 11
Training loss: 3.075222969055176
Validation loss: 2.4943250879164665

Epoch: 6| Step: 12
Training loss: 3.426569938659668
Validation loss: 2.4970489548098658

Epoch: 6| Step: 13
Training loss: 2.0093441009521484
Validation loss: 2.490802918711016

Epoch: 125| Step: 0
Training loss: 3.426471710205078
Validation loss: 2.4915183282667592

Epoch: 6| Step: 1
Training loss: 1.6773608922958374
Validation loss: 2.493694789948002

Epoch: 6| Step: 2
Training loss: 3.0345046520233154
Validation loss: 2.4901128571520568

Epoch: 6| Step: 3
Training loss: 3.4025673866271973
Validation loss: 2.4853988001423497

Epoch: 6| Step: 4
Training loss: 2.6719119548797607
Validation loss: 2.4855639934539795

Epoch: 6| Step: 5
Training loss: 3.017366886138916
Validation loss: 2.4887298614748063

Epoch: 6| Step: 6
Training loss: 2.739131212234497
Validation loss: 2.4917153773769254

Epoch: 6| Step: 7
Training loss: 1.9234304428100586
Validation loss: 2.491641923945437

Epoch: 6| Step: 8
Training loss: 2.5070385932922363
Validation loss: 2.493455525367491

Epoch: 6| Step: 9
Training loss: 2.901301145553589
Validation loss: 2.499913410473895

Epoch: 6| Step: 10
Training loss: 2.245543956756592
Validation loss: 2.4994410084139917

Epoch: 6| Step: 11
Training loss: 2.6846466064453125
Validation loss: 2.4969575071847565

Epoch: 6| Step: 12
Training loss: 2.4273877143859863
Validation loss: 2.4940872269292034

Epoch: 6| Step: 13
Training loss: 3.2133629322052
Validation loss: 2.5016464059070875

Epoch: 126| Step: 0
Training loss: 2.4784631729125977
Validation loss: 2.497552366666896

Epoch: 6| Step: 1
Training loss: 2.7435474395751953
Validation loss: 2.5011047470954155

Epoch: 6| Step: 2
Training loss: 3.25490665435791
Validation loss: 2.5045333857177408

Epoch: 6| Step: 3
Training loss: 2.9974632263183594
Validation loss: 2.4934616037594375

Epoch: 6| Step: 4
Training loss: 2.962235927581787
Validation loss: 2.5005921676594722

Epoch: 6| Step: 5
Training loss: 1.9181023836135864
Validation loss: 2.487655584530164

Epoch: 6| Step: 6
Training loss: 2.664116859436035
Validation loss: 2.4939463676944857

Epoch: 6| Step: 7
Training loss: 3.343830108642578
Validation loss: 2.4845784992300053

Epoch: 6| Step: 8
Training loss: 2.3806796073913574
Validation loss: 2.483350315401631

Epoch: 6| Step: 9
Training loss: 2.161372184753418
Validation loss: 2.481560330237112

Epoch: 6| Step: 10
Training loss: 2.7552103996276855
Validation loss: 2.4868144117375857

Epoch: 6| Step: 11
Training loss: 2.1659159660339355
Validation loss: 2.478714427640361

Epoch: 6| Step: 12
Training loss: 3.4626834392547607
Validation loss: 2.4850373575764317

Epoch: 6| Step: 13
Training loss: 1.9447994232177734
Validation loss: 2.4936034346139557

Epoch: 127| Step: 0
Training loss: 2.411363124847412
Validation loss: 2.4921586616064912

Epoch: 6| Step: 1
Training loss: 3.025733470916748
Validation loss: 2.4927397030656055

Epoch: 6| Step: 2
Training loss: 3.018998146057129
Validation loss: 2.4890312225587907

Epoch: 6| Step: 3
Training loss: 1.688350796699524
Validation loss: 2.48943313219214

Epoch: 6| Step: 4
Training loss: 2.297823190689087
Validation loss: 2.495886907782606

Epoch: 6| Step: 5
Training loss: 3.221728801727295
Validation loss: 2.4840614564957155

Epoch: 6| Step: 6
Training loss: 2.4357728958129883
Validation loss: 2.4939941180649625

Epoch: 6| Step: 7
Training loss: 3.324342727661133
Validation loss: 2.487130388136833

Epoch: 6| Step: 8
Training loss: 2.816690444946289
Validation loss: 2.4905702042323288

Epoch: 6| Step: 9
Training loss: 2.6662960052490234
Validation loss: 2.493681579507807

Epoch: 6| Step: 10
Training loss: 2.209559679031372
Validation loss: 2.4894278049468994

Epoch: 6| Step: 11
Training loss: 2.8722410202026367
Validation loss: 2.4883253805098997

Epoch: 6| Step: 12
Training loss: 2.51302433013916
Validation loss: 2.4974637595556115

Epoch: 6| Step: 13
Training loss: 3.1705262660980225
Validation loss: 2.4960722141368414

Epoch: 128| Step: 0
Training loss: 3.120032787322998
Validation loss: 2.491704797232023

Epoch: 6| Step: 1
Training loss: 2.5493147373199463
Validation loss: 2.489170253917735

Epoch: 6| Step: 2
Training loss: 2.2230021953582764
Validation loss: 2.4866005835994596

Epoch: 6| Step: 3
Training loss: 2.4095089435577393
Validation loss: 2.486402873070009

Epoch: 6| Step: 4
Training loss: 3.07470703125
Validation loss: 2.489040364501297

Epoch: 6| Step: 5
Training loss: 3.1458277702331543
Validation loss: 2.4922279773219937

Epoch: 6| Step: 6
Training loss: 2.803816318511963
Validation loss: 2.5036375548249934

Epoch: 6| Step: 7
Training loss: 2.2352073192596436
Validation loss: 2.49642111152731

Epoch: 6| Step: 8
Training loss: 2.405447006225586
Validation loss: 2.493172004658689

Epoch: 6| Step: 9
Training loss: 2.8453304767608643
Validation loss: 2.494326627382668

Epoch: 6| Step: 10
Training loss: 2.4432880878448486
Validation loss: 2.5000395159567557

Epoch: 6| Step: 11
Training loss: 2.4913077354431152
Validation loss: 2.4989282802868913

Epoch: 6| Step: 12
Training loss: 2.702606678009033
Validation loss: 2.502294409659601

Epoch: 6| Step: 13
Training loss: 3.303297996520996
Validation loss: 2.5013072798329015

Epoch: 129| Step: 0
Training loss: 2.463942289352417
Validation loss: 2.500320365352015

Epoch: 6| Step: 1
Training loss: 2.8283510208129883
Validation loss: 2.4967966720622075

Epoch: 6| Step: 2
Training loss: 3.525831699371338
Validation loss: 2.488526159717191

Epoch: 6| Step: 3
Training loss: 2.243595600128174
Validation loss: 2.4963666880002586

Epoch: 6| Step: 4
Training loss: 3.7423348426818848
Validation loss: 2.497944862611832

Epoch: 6| Step: 5
Training loss: 2.382502555847168
Validation loss: 2.495182360372236

Epoch: 6| Step: 6
Training loss: 2.990797281265259
Validation loss: 2.499137588726577

Epoch: 6| Step: 7
Training loss: 2.417360782623291
Validation loss: 2.498882632101736

Epoch: 6| Step: 8
Training loss: 2.417104482650757
Validation loss: 2.4980325878307386

Epoch: 6| Step: 9
Training loss: 3.0702664852142334
Validation loss: 2.502863235371087

Epoch: 6| Step: 10
Training loss: 2.351752758026123
Validation loss: 2.509709499215567

Epoch: 6| Step: 11
Training loss: 2.0710644721984863
Validation loss: 2.509247021008563

Epoch: 6| Step: 12
Training loss: 2.3011960983276367
Validation loss: 2.5078659660072735

Epoch: 6| Step: 13
Training loss: 2.686267375946045
Validation loss: 2.5060461746749056

Epoch: 130| Step: 0
Training loss: 2.178649663925171
Validation loss: 2.5031890817867812

Epoch: 6| Step: 1
Training loss: 2.2482004165649414
Validation loss: 2.4967139946517123

Epoch: 6| Step: 2
Training loss: 3.4080471992492676
Validation loss: 2.5012938758378387

Epoch: 6| Step: 3
Training loss: 2.5333657264709473
Validation loss: 2.4971412202363372

Epoch: 6| Step: 4
Training loss: 2.1464829444885254
Validation loss: 2.494449815442485

Epoch: 6| Step: 5
Training loss: 3.594762086868286
Validation loss: 2.498435528047623

Epoch: 6| Step: 6
Training loss: 2.8591461181640625
Validation loss: 2.496615686724263

Epoch: 6| Step: 7
Training loss: 2.7849678993225098
Validation loss: 2.493388601528701

Epoch: 6| Step: 8
Training loss: 2.343096971511841
Validation loss: 2.49038545034265

Epoch: 6| Step: 9
Training loss: 3.1289310455322266
Validation loss: 2.4857308633865847

Epoch: 6| Step: 10
Training loss: 2.306165933609009
Validation loss: 2.488469785259616

Epoch: 6| Step: 11
Training loss: 2.3534774780273438
Validation loss: 2.4789003710592947

Epoch: 6| Step: 12
Training loss: 2.452944755554199
Validation loss: 2.4862820102322485

Epoch: 6| Step: 13
Training loss: 3.6032192707061768
Validation loss: 2.4870074026046263

Epoch: 131| Step: 0
Training loss: 1.9068151712417603
Validation loss: 2.4747131614274878

Epoch: 6| Step: 1
Training loss: 2.7254550457000732
Validation loss: 2.4735179639631704

Epoch: 6| Step: 2
Training loss: 2.500465154647827
Validation loss: 2.4671954237004763

Epoch: 6| Step: 3
Training loss: 2.846531629562378
Validation loss: 2.4740755352922665

Epoch: 6| Step: 4
Training loss: 2.9291234016418457
Validation loss: 2.476582451533246

Epoch: 6| Step: 5
Training loss: 2.364190101623535
Validation loss: 2.4734421904369066

Epoch: 6| Step: 6
Training loss: 2.7118759155273438
Validation loss: 2.482601906663628

Epoch: 6| Step: 7
Training loss: 2.718682289123535
Validation loss: 2.4745345372025684

Epoch: 6| Step: 8
Training loss: 3.0640904903411865
Validation loss: 2.473261338408275

Epoch: 6| Step: 9
Training loss: 2.912534236907959
Validation loss: 2.4787651928522254

Epoch: 6| Step: 10
Training loss: 2.8096230030059814
Validation loss: 2.4767153801456576

Epoch: 6| Step: 11
Training loss: 2.109182357788086
Validation loss: 2.4777149820840485

Epoch: 6| Step: 12
Training loss: 3.485236883163452
Validation loss: 2.4840073021509315

Epoch: 6| Step: 13
Training loss: 2.1271684169769287
Validation loss: 2.4857151495513095

Epoch: 132| Step: 0
Training loss: 2.81176495552063
Validation loss: 2.4930881069552515

Epoch: 6| Step: 1
Training loss: 2.0853161811828613
Validation loss: 2.4979415760245374

Epoch: 6| Step: 2
Training loss: 3.138286590576172
Validation loss: 2.490351661559074

Epoch: 6| Step: 3
Training loss: 2.603762149810791
Validation loss: 2.487868760221748

Epoch: 6| Step: 4
Training loss: 3.7076339721679688
Validation loss: 2.4911483154501965

Epoch: 6| Step: 5
Training loss: 2.4971799850463867
Validation loss: 2.49516886280429

Epoch: 6| Step: 6
Training loss: 2.7880964279174805
Validation loss: 2.499826236437726

Epoch: 6| Step: 7
Training loss: 3.3783483505249023
Validation loss: 2.495319740746611

Epoch: 6| Step: 8
Training loss: 2.097541093826294
Validation loss: 2.5001064321046234

Epoch: 6| Step: 9
Training loss: 2.8029561042785645
Validation loss: 2.501037428455968

Epoch: 6| Step: 10
Training loss: 2.4002203941345215
Validation loss: 2.4970068829033965

Epoch: 6| Step: 11
Training loss: 2.3956680297851562
Validation loss: 2.5035147846386

Epoch: 6| Step: 12
Training loss: 2.728234052658081
Validation loss: 2.5109379855535363

Epoch: 6| Step: 13
Training loss: 1.7176802158355713
Validation loss: 2.5198647642648346

Epoch: 133| Step: 0
Training loss: 2.69429349899292
Validation loss: 2.5247598130215883

Epoch: 6| Step: 1
Training loss: 2.6109869480133057
Validation loss: 2.532846809715353

Epoch: 6| Step: 2
Training loss: 2.6176562309265137
Validation loss: 2.5232530050380255

Epoch: 6| Step: 3
Training loss: 2.7320899963378906
Validation loss: 2.5133012648551696

Epoch: 6| Step: 4
Training loss: 3.366258144378662
Validation loss: 2.5030896202210458

Epoch: 6| Step: 5
Training loss: 2.693077564239502
Validation loss: 2.491742523767615

Epoch: 6| Step: 6
Training loss: 2.4231550693511963
Validation loss: 2.4861133713876047

Epoch: 6| Step: 7
Training loss: 2.8219003677368164
Validation loss: 2.481115846223729

Epoch: 6| Step: 8
Training loss: 2.8888208866119385
Validation loss: 2.4727798713150846

Epoch: 6| Step: 9
Training loss: 2.472064733505249
Validation loss: 2.4752026193885395

Epoch: 6| Step: 10
Training loss: 2.7075412273406982
Validation loss: 2.479059765415807

Epoch: 6| Step: 11
Training loss: 2.7209391593933105
Validation loss: 2.4776809189909246

Epoch: 6| Step: 12
Training loss: 2.538618564605713
Validation loss: 2.480826316341277

Epoch: 6| Step: 13
Training loss: 2.3351850509643555
Validation loss: 2.482809607700635

Epoch: 134| Step: 0
Training loss: 2.3761422634124756
Validation loss: 2.481258402588547

Epoch: 6| Step: 1
Training loss: 2.3528053760528564
Validation loss: 2.474138416269774

Epoch: 6| Step: 2
Training loss: 3.3545851707458496
Validation loss: 2.469258636556646

Epoch: 6| Step: 3
Training loss: 2.478647470474243
Validation loss: 2.4628390189140075

Epoch: 6| Step: 4
Training loss: 3.0094048976898193
Validation loss: 2.4612434551280034

Epoch: 6| Step: 5
Training loss: 2.839252233505249
Validation loss: 2.4672240941755232

Epoch: 6| Step: 6
Training loss: 2.6865944862365723
Validation loss: 2.4677864120852564

Epoch: 6| Step: 7
Training loss: 2.543919086456299
Validation loss: 2.464755076234059

Epoch: 6| Step: 8
Training loss: 3.8390300273895264
Validation loss: 2.464021139247443

Epoch: 6| Step: 9
Training loss: 1.9676883220672607
Validation loss: 2.463067229076098

Epoch: 6| Step: 10
Training loss: 2.5952796936035156
Validation loss: 2.4659312412302983

Epoch: 6| Step: 11
Training loss: 3.0435099601745605
Validation loss: 2.461792407497283

Epoch: 6| Step: 12
Training loss: 2.2570102214813232
Validation loss: 2.4664485172558854

Epoch: 6| Step: 13
Training loss: 1.7606234550476074
Validation loss: 2.466787204947523

Epoch: 135| Step: 0
Training loss: 2.867286205291748
Validation loss: 2.472857931608795

Epoch: 6| Step: 1
Training loss: 2.007357120513916
Validation loss: 2.4702384369347685

Epoch: 6| Step: 2
Training loss: 3.213465929031372
Validation loss: 2.4687407478209464

Epoch: 6| Step: 3
Training loss: 2.8843770027160645
Validation loss: 2.4747105593322427

Epoch: 6| Step: 4
Training loss: 2.663822889328003
Validation loss: 2.479080400159282

Epoch: 6| Step: 5
Training loss: 3.4753997325897217
Validation loss: 2.481111370107179

Epoch: 6| Step: 6
Training loss: 2.948831081390381
Validation loss: 2.4786978690854964

Epoch: 6| Step: 7
Training loss: 2.68672513961792
Validation loss: 2.4970778021761166

Epoch: 6| Step: 8
Training loss: 2.558595657348633
Validation loss: 2.496077932337279

Epoch: 6| Step: 9
Training loss: 2.395395040512085
Validation loss: 2.509184919377809

Epoch: 6| Step: 10
Training loss: 2.7484323978424072
Validation loss: 2.5175507196816067

Epoch: 6| Step: 11
Training loss: 2.4064791202545166
Validation loss: 2.5215156360339095

Epoch: 6| Step: 12
Training loss: 2.1028146743774414
Validation loss: 2.5155522720788115

Epoch: 6| Step: 13
Training loss: 2.4239602088928223
Validation loss: 2.51322465942752

Epoch: 136| Step: 0
Training loss: 2.126528263092041
Validation loss: 2.5088994285111785

Epoch: 6| Step: 1
Training loss: 2.395630359649658
Validation loss: 2.502863020025274

Epoch: 6| Step: 2
Training loss: 2.8270273208618164
Validation loss: 2.482570109828826

Epoch: 6| Step: 3
Training loss: 3.0195417404174805
Validation loss: 2.485485440941267

Epoch: 6| Step: 4
Training loss: 2.7592623233795166
Validation loss: 2.471526663790467

Epoch: 6| Step: 5
Training loss: 2.0325448513031006
Validation loss: 2.4776441948388213

Epoch: 6| Step: 6
Training loss: 3.6148242950439453
Validation loss: 2.4824201112152426

Epoch: 6| Step: 7
Training loss: 2.710994005203247
Validation loss: 2.469994410391777

Epoch: 6| Step: 8
Training loss: 2.6411871910095215
Validation loss: 2.4663113009545112

Epoch: 6| Step: 9
Training loss: 2.621487855911255
Validation loss: 2.4589219785505727

Epoch: 6| Step: 10
Training loss: 2.6868417263031006
Validation loss: 2.4578041440697125

Epoch: 6| Step: 11
Training loss: 2.7218689918518066
Validation loss: 2.4610108944677536

Epoch: 6| Step: 12
Training loss: 2.2990598678588867
Validation loss: 2.4641413611750447

Epoch: 6| Step: 13
Training loss: 3.1547749042510986
Validation loss: 2.4650090868755052

Epoch: 137| Step: 0
Training loss: 2.5460267066955566
Validation loss: 2.4675080930033038

Epoch: 6| Step: 1
Training loss: 3.395543098449707
Validation loss: 2.4670974516099498

Epoch: 6| Step: 2
Training loss: 2.6156563758850098
Validation loss: 2.465816859276064

Epoch: 6| Step: 3
Training loss: 2.705573558807373
Validation loss: 2.4703703388091056

Epoch: 6| Step: 4
Training loss: 2.2603325843811035
Validation loss: 2.4748279099823325

Epoch: 6| Step: 5
Training loss: 2.4264116287231445
Validation loss: 2.4773599614379225

Epoch: 6| Step: 6
Training loss: 2.6715142726898193
Validation loss: 2.4819276743037726

Epoch: 6| Step: 7
Training loss: 2.6000614166259766
Validation loss: 2.4829819228059504

Epoch: 6| Step: 8
Training loss: 2.9494900703430176
Validation loss: 2.472144606292889

Epoch: 6| Step: 9
Training loss: 2.3908143043518066
Validation loss: 2.474932773138887

Epoch: 6| Step: 10
Training loss: 2.5820887088775635
Validation loss: 2.4752976330377723

Epoch: 6| Step: 11
Training loss: 2.834904670715332
Validation loss: 2.4716894395889772

Epoch: 6| Step: 12
Training loss: 2.3928728103637695
Validation loss: 2.470853146686349

Epoch: 6| Step: 13
Training loss: 3.3724310398101807
Validation loss: 2.475439653601698

Epoch: 138| Step: 0
Training loss: 2.3265347480773926
Validation loss: 2.4759843862184914

Epoch: 6| Step: 1
Training loss: 3.715693473815918
Validation loss: 2.4821098363527687

Epoch: 6| Step: 2
Training loss: 1.9842963218688965
Validation loss: 2.479601198627103

Epoch: 6| Step: 3
Training loss: 2.7581892013549805
Validation loss: 2.4798011523421093

Epoch: 6| Step: 4
Training loss: 2.3762195110321045
Validation loss: 2.4825580376450733

Epoch: 6| Step: 5
Training loss: 3.4297778606414795
Validation loss: 2.4793032753852104

Epoch: 6| Step: 6
Training loss: 1.8803750276565552
Validation loss: 2.4883628429905063

Epoch: 6| Step: 7
Training loss: 3.1135265827178955
Validation loss: 2.486458957836192

Epoch: 6| Step: 8
Training loss: 2.2957825660705566
Validation loss: 2.4808634993850545

Epoch: 6| Step: 9
Training loss: 2.6908299922943115
Validation loss: 2.4714228671084166

Epoch: 6| Step: 10
Training loss: 2.988527297973633
Validation loss: 2.4687532224962787

Epoch: 6| Step: 11
Training loss: 2.472313404083252
Validation loss: 2.47585044881349

Epoch: 6| Step: 12
Training loss: 2.233616828918457
Validation loss: 2.4767187000602804

Epoch: 6| Step: 13
Training loss: 3.4369847774505615
Validation loss: 2.480553411668347

Epoch: 139| Step: 0
Training loss: 3.2588627338409424
Validation loss: 2.4692272755407516

Epoch: 6| Step: 1
Training loss: 2.669524669647217
Validation loss: 2.463407301133679

Epoch: 6| Step: 2
Training loss: 2.311295509338379
Validation loss: 2.458363761184036

Epoch: 6| Step: 3
Training loss: 2.7547621726989746
Validation loss: 2.4654351229308755

Epoch: 6| Step: 4
Training loss: 2.9988274574279785
Validation loss: 2.468093602888046

Epoch: 6| Step: 5
Training loss: 2.9734604358673096
Validation loss: 2.472120915689776

Epoch: 6| Step: 6
Training loss: 1.9244253635406494
Validation loss: 2.4636559973480883

Epoch: 6| Step: 7
Training loss: 2.7501983642578125
Validation loss: 2.4687488925072456

Epoch: 6| Step: 8
Training loss: 2.1906816959381104
Validation loss: 2.472503092981154

Epoch: 6| Step: 9
Training loss: 2.8812153339385986
Validation loss: 2.462747807143837

Epoch: 6| Step: 10
Training loss: 2.662903308868408
Validation loss: 2.46138846746055

Epoch: 6| Step: 11
Training loss: 2.2743239402770996
Validation loss: 2.463657679096345

Epoch: 6| Step: 12
Training loss: 3.373487710952759
Validation loss: 2.464551817986273

Epoch: 6| Step: 13
Training loss: 2.153623104095459
Validation loss: 2.454662597307595

Epoch: 140| Step: 0
Training loss: 1.7311128377914429
Validation loss: 2.4575075975028415

Epoch: 6| Step: 1
Training loss: 2.7369818687438965
Validation loss: 2.4578532582970074

Epoch: 6| Step: 2
Training loss: 2.7724013328552246
Validation loss: 2.4595750916388726

Epoch: 6| Step: 3
Training loss: 1.7465455532073975
Validation loss: 2.4606742038521716

Epoch: 6| Step: 4
Training loss: 2.7391629219055176
Validation loss: 2.4580057744056947

Epoch: 6| Step: 5
Training loss: 2.6063613891601562
Validation loss: 2.455711897983346

Epoch: 6| Step: 6
Training loss: 3.043266773223877
Validation loss: 2.465500339385002

Epoch: 6| Step: 7
Training loss: 2.920903205871582
Validation loss: 2.4656266115045034

Epoch: 6| Step: 8
Training loss: 2.2913851737976074
Validation loss: 2.470521973025414

Epoch: 6| Step: 9
Training loss: 3.1480226516723633
Validation loss: 2.465723124883508

Epoch: 6| Step: 10
Training loss: 2.843756914138794
Validation loss: 2.472431336679766

Epoch: 6| Step: 11
Training loss: 2.691805839538574
Validation loss: 2.478134757728987

Epoch: 6| Step: 12
Training loss: 3.1933541297912598
Validation loss: 2.4768040923662085

Epoch: 6| Step: 13
Training loss: 2.8334245681762695
Validation loss: 2.4734883898047992

Epoch: 141| Step: 0
Training loss: 3.3773584365844727
Validation loss: 2.4689381199498333

Epoch: 6| Step: 1
Training loss: 3.4819726943969727
Validation loss: 2.475267702533353

Epoch: 6| Step: 2
Training loss: 1.7536404132843018
Validation loss: 2.47255640645181

Epoch: 6| Step: 3
Training loss: 3.2716798782348633
Validation loss: 2.4785986997747935

Epoch: 6| Step: 4
Training loss: 1.561874508857727
Validation loss: 2.4697934965933523

Epoch: 6| Step: 5
Training loss: 2.833578109741211
Validation loss: 2.4721691249519266

Epoch: 6| Step: 6
Training loss: 2.772408962249756
Validation loss: 2.4729121961901264

Epoch: 6| Step: 7
Training loss: 2.6911215782165527
Validation loss: 2.4645551404645367

Epoch: 6| Step: 8
Training loss: 3.3677923679351807
Validation loss: 2.469720971199774

Epoch: 6| Step: 9
Training loss: 2.2760632038116455
Validation loss: 2.4789974586938017

Epoch: 6| Step: 10
Training loss: 2.4760825634002686
Validation loss: 2.469525052655128

Epoch: 6| Step: 11
Training loss: 2.2092084884643555
Validation loss: 2.4740949343609553

Epoch: 6| Step: 12
Training loss: 2.648392915725708
Validation loss: 2.476185901190645

Epoch: 6| Step: 13
Training loss: 2.6183831691741943
Validation loss: 2.4688003499020814

Epoch: 142| Step: 0
Training loss: 2.0682425498962402
Validation loss: 2.4729112681522163

Epoch: 6| Step: 1
Training loss: 2.8596322536468506
Validation loss: 2.4728626692166893

Epoch: 6| Step: 2
Training loss: 3.1786868572235107
Validation loss: 2.4749239849787887

Epoch: 6| Step: 3
Training loss: 2.6629767417907715
Validation loss: 2.462625095921178

Epoch: 6| Step: 4
Training loss: 2.5221445560455322
Validation loss: 2.461103182966991

Epoch: 6| Step: 5
Training loss: 1.6931161880493164
Validation loss: 2.4592970519937496

Epoch: 6| Step: 6
Training loss: 2.544442653656006
Validation loss: 2.4539365512068554

Epoch: 6| Step: 7
Training loss: 3.901355028152466
Validation loss: 2.4486912155664093

Epoch: 6| Step: 8
Training loss: 2.8479013442993164
Validation loss: 2.4532282660084386

Epoch: 6| Step: 9
Training loss: 2.861682415008545
Validation loss: 2.4530652415367866

Epoch: 6| Step: 10
Training loss: 2.6515328884124756
Validation loss: 2.457982258130145

Epoch: 6| Step: 11
Training loss: 2.8706207275390625
Validation loss: 2.4575370204064155

Epoch: 6| Step: 12
Training loss: 2.5084285736083984
Validation loss: 2.458360484851304

Epoch: 6| Step: 13
Training loss: 1.83143949508667
Validation loss: 2.454261382420858

Epoch: 143| Step: 0
Training loss: 2.002988576889038
Validation loss: 2.4628028626083047

Epoch: 6| Step: 1
Training loss: 2.8419480323791504
Validation loss: 2.4567164221117572

Epoch: 6| Step: 2
Training loss: 2.291656970977783
Validation loss: 2.452516778822868

Epoch: 6| Step: 3
Training loss: 3.1653623580932617
Validation loss: 2.4497476931541198

Epoch: 6| Step: 4
Training loss: 2.7139763832092285
Validation loss: 2.4477571287462787

Epoch: 6| Step: 5
Training loss: 3.641786575317383
Validation loss: 2.4512029745245494

Epoch: 6| Step: 6
Training loss: 3.026737689971924
Validation loss: 2.457250395128804

Epoch: 6| Step: 7
Training loss: 2.1395788192749023
Validation loss: 2.453269468840732

Epoch: 6| Step: 8
Training loss: 2.7468087673187256
Validation loss: 2.45330520086391

Epoch: 6| Step: 9
Training loss: 2.717987537384033
Validation loss: 2.4567480318007933

Epoch: 6| Step: 10
Training loss: 2.3917064666748047
Validation loss: 2.4639361955786265

Epoch: 6| Step: 11
Training loss: 2.4951295852661133
Validation loss: 2.46092047742618

Epoch: 6| Step: 12
Training loss: 2.7420051097869873
Validation loss: 2.4600149841718775

Epoch: 6| Step: 13
Training loss: 2.138913869857788
Validation loss: 2.465646315646428

Epoch: 144| Step: 0
Training loss: 1.875013828277588
Validation loss: 2.4699031358124106

Epoch: 6| Step: 1
Training loss: 2.07476806640625
Validation loss: 2.4742364011785036

Epoch: 6| Step: 2
Training loss: 3.1012818813323975
Validation loss: 2.4682449269038376

Epoch: 6| Step: 3
Training loss: 2.688157558441162
Validation loss: 2.4629418567944596

Epoch: 6| Step: 4
Training loss: 2.7986550331115723
Validation loss: 2.4666863436340005

Epoch: 6| Step: 5
Training loss: 3.125126600265503
Validation loss: 2.4603813181641283

Epoch: 6| Step: 6
Training loss: 2.3315467834472656
Validation loss: 2.463584828120406

Epoch: 6| Step: 7
Training loss: 3.34230899810791
Validation loss: 2.4690356459668887

Epoch: 6| Step: 8
Training loss: 3.315418243408203
Validation loss: 2.4618691282887615

Epoch: 6| Step: 9
Training loss: 2.29791259765625
Validation loss: 2.464516706364129

Epoch: 6| Step: 10
Training loss: 2.2504191398620605
Validation loss: 2.4611233921461206

Epoch: 6| Step: 11
Training loss: 2.937549591064453
Validation loss: 2.4598282972971597

Epoch: 6| Step: 12
Training loss: 2.1809377670288086
Validation loss: 2.4626180048911803

Epoch: 6| Step: 13
Training loss: 3.1548683643341064
Validation loss: 2.4633891146670104

Epoch: 145| Step: 0
Training loss: 3.5740222930908203
Validation loss: 2.4613040519017044

Epoch: 6| Step: 1
Training loss: 2.8480913639068604
Validation loss: 2.4561759374474965

Epoch: 6| Step: 2
Training loss: 2.6503632068634033
Validation loss: 2.4680904547373452

Epoch: 6| Step: 3
Training loss: 2.4218504428863525
Validation loss: 2.4618646431994695

Epoch: 6| Step: 4
Training loss: 2.6771035194396973
Validation loss: 2.4806610397113267

Epoch: 6| Step: 5
Training loss: 2.13859224319458
Validation loss: 2.4809838187310005

Epoch: 6| Step: 6
Training loss: 3.1020147800445557
Validation loss: 2.4782793573153916

Epoch: 6| Step: 7
Training loss: 2.1515629291534424
Validation loss: 2.479140809787217

Epoch: 6| Step: 8
Training loss: 2.4603495597839355
Validation loss: 2.4766039207417476

Epoch: 6| Step: 9
Training loss: 2.293452262878418
Validation loss: 2.4725011343597085

Epoch: 6| Step: 10
Training loss: 3.1109886169433594
Validation loss: 2.47705594442224

Epoch: 6| Step: 11
Training loss: 2.7868638038635254
Validation loss: 2.4717385051071004

Epoch: 6| Step: 12
Training loss: 2.3374195098876953
Validation loss: 2.4670761733926754

Epoch: 6| Step: 13
Training loss: 2.624159336090088
Validation loss: 2.4695969755931566

Epoch: 146| Step: 0
Training loss: 2.111794948577881
Validation loss: 2.4692284650700067

Epoch: 6| Step: 1
Training loss: 2.6261768341064453
Validation loss: 2.4718540945360736

Epoch: 6| Step: 2
Training loss: 2.6553456783294678
Validation loss: 2.481716558497439

Epoch: 6| Step: 3
Training loss: 2.3316659927368164
Validation loss: 2.477038057901526

Epoch: 6| Step: 4
Training loss: 3.087803840637207
Validation loss: 2.4751635213052072

Epoch: 6| Step: 5
Training loss: 3.6886398792266846
Validation loss: 2.475729229629681

Epoch: 6| Step: 6
Training loss: 2.143688678741455
Validation loss: 2.4719792771083053

Epoch: 6| Step: 7
Training loss: 3.114806652069092
Validation loss: 2.4704199324371996

Epoch: 6| Step: 8
Training loss: 2.2298824787139893
Validation loss: 2.4654103325259302

Epoch: 6| Step: 9
Training loss: 3.134925365447998
Validation loss: 2.4655586429821548

Epoch: 6| Step: 10
Training loss: 2.7574567794799805
Validation loss: 2.4570421147090133

Epoch: 6| Step: 11
Training loss: 2.553061008453369
Validation loss: 2.460252656731554

Epoch: 6| Step: 12
Training loss: 2.7644095420837402
Validation loss: 2.462657763111976

Epoch: 6| Step: 13
Training loss: 1.7044206857681274
Validation loss: 2.4584918637429514

Epoch: 147| Step: 0
Training loss: 3.3603668212890625
Validation loss: 2.4538860859409457

Epoch: 6| Step: 1
Training loss: 2.7852015495300293
Validation loss: 2.4550461320466894

Epoch: 6| Step: 2
Training loss: 2.28859281539917
Validation loss: 2.4496799515139673

Epoch: 6| Step: 3
Training loss: 2.857767105102539
Validation loss: 2.4467357794443765

Epoch: 6| Step: 4
Training loss: 1.8649187088012695
Validation loss: 2.4549119882686163

Epoch: 6| Step: 5
Training loss: 2.4051458835601807
Validation loss: 2.452472843149657

Epoch: 6| Step: 6
Training loss: 2.986269950866699
Validation loss: 2.4538956893387662

Epoch: 6| Step: 7
Training loss: 2.9997243881225586
Validation loss: 2.460058851908612

Epoch: 6| Step: 8
Training loss: 2.032278060913086
Validation loss: 2.454947128090807

Epoch: 6| Step: 9
Training loss: 3.003593921661377
Validation loss: 2.456814537766159

Epoch: 6| Step: 10
Training loss: 2.5115246772766113
Validation loss: 2.461547056833903

Epoch: 6| Step: 11
Training loss: 2.7228453159332275
Validation loss: 2.4626695033042663

Epoch: 6| Step: 12
Training loss: 3.0777711868286133
Validation loss: 2.457602394524441

Epoch: 6| Step: 13
Training loss: 2.0027999877929688
Validation loss: 2.4619527991100023

Epoch: 148| Step: 0
Training loss: 3.359469413757324
Validation loss: 2.472192613027429

Epoch: 6| Step: 1
Training loss: 3.097384452819824
Validation loss: 2.464057396816951

Epoch: 6| Step: 2
Training loss: 2.2457656860351562
Validation loss: 2.4615919820723997

Epoch: 6| Step: 3
Training loss: 2.051762819290161
Validation loss: 2.459879175309212

Epoch: 6| Step: 4
Training loss: 3.169130802154541
Validation loss: 2.4568907060930805

Epoch: 6| Step: 5
Training loss: 2.0172955989837646
Validation loss: 2.4589705569769746

Epoch: 6| Step: 6
Training loss: 2.3978328704833984
Validation loss: 2.4557348835852837

Epoch: 6| Step: 7
Training loss: 2.6554973125457764
Validation loss: 2.459375807034072

Epoch: 6| Step: 8
Training loss: 2.5345683097839355
Validation loss: 2.4543707114393993

Epoch: 6| Step: 9
Training loss: 2.733102560043335
Validation loss: 2.466624386848942

Epoch: 6| Step: 10
Training loss: 2.623734951019287
Validation loss: 2.467452279983028

Epoch: 6| Step: 11
Training loss: 2.9661738872528076
Validation loss: 2.4689243813996673

Epoch: 6| Step: 12
Training loss: 2.9127328395843506
Validation loss: 2.468180864087997

Epoch: 6| Step: 13
Training loss: 2.4385507106781006
Validation loss: 2.467401037934006

Epoch: 149| Step: 0
Training loss: 2.8286051750183105
Validation loss: 2.4664371205914404

Epoch: 6| Step: 1
Training loss: 2.1570444107055664
Validation loss: 2.474859488907681

Epoch: 6| Step: 2
Training loss: 2.156137228012085
Validation loss: 2.492608498501521

Epoch: 6| Step: 3
Training loss: 2.25506329536438
Validation loss: 2.5074351808076263

Epoch: 6| Step: 4
Training loss: 2.44168758392334
Validation loss: 2.5281535912585515

Epoch: 6| Step: 5
Training loss: 2.6301727294921875
Validation loss: 2.5278502510439966

Epoch: 6| Step: 6
Training loss: 2.100648880004883
Validation loss: 2.536558899828183

Epoch: 6| Step: 7
Training loss: 3.200195074081421
Validation loss: 2.5423207744475333

Epoch: 6| Step: 8
Training loss: 3.1456708908081055
Validation loss: 2.551020542780558

Epoch: 6| Step: 9
Training loss: 3.6848740577697754
Validation loss: 2.546195968504875

Epoch: 6| Step: 10
Training loss: 3.1388747692108154
Validation loss: 2.5360963575301634

Epoch: 6| Step: 11
Training loss: 1.9474817514419556
Validation loss: 2.514817555745443

Epoch: 6| Step: 12
Training loss: 2.9508590698242188
Validation loss: 2.5046903535883915

Epoch: 6| Step: 13
Training loss: 3.162113904953003
Validation loss: 2.4977296834350913

Epoch: 150| Step: 0
Training loss: 2.319657325744629
Validation loss: 2.4912915845071115

Epoch: 6| Step: 1
Training loss: 2.598435401916504
Validation loss: 2.4811711593340804

Epoch: 6| Step: 2
Training loss: 2.715481758117676
Validation loss: 2.4761188850607923

Epoch: 6| Step: 3
Training loss: 2.2620973587036133
Validation loss: 2.4751697714610765

Epoch: 6| Step: 4
Training loss: 2.6577494144439697
Validation loss: 2.476585095928561

Epoch: 6| Step: 5
Training loss: 3.191309928894043
Validation loss: 2.4727138703869236

Epoch: 6| Step: 6
Training loss: 2.2648000717163086
Validation loss: 2.464423692354592

Epoch: 6| Step: 7
Training loss: 3.068510055541992
Validation loss: 2.46114335777939

Epoch: 6| Step: 8
Training loss: 3.012348175048828
Validation loss: 2.4545037746429443

Epoch: 6| Step: 9
Training loss: 2.8395557403564453
Validation loss: 2.445305742243285

Epoch: 6| Step: 10
Training loss: 3.18048095703125
Validation loss: 2.44743933216218

Epoch: 6| Step: 11
Training loss: 2.234067916870117
Validation loss: 2.4440338303965907

Epoch: 6| Step: 12
Training loss: 2.293571710586548
Validation loss: 2.447254273199266

Epoch: 6| Step: 13
Training loss: 2.4899895191192627
Validation loss: 2.4472142547689457

Testing loss: 2.60770329369439
