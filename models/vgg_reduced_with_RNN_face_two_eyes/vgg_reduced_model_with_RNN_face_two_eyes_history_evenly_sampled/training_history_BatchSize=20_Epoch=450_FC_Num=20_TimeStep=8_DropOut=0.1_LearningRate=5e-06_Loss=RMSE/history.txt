Epoch: 1| Step: 0
Training loss: 4.764667952697532
Validation loss: 5.765557243232939

Epoch: 5| Step: 1
Training loss: 5.4277911270760075
Validation loss: 5.760149385250991

Epoch: 5| Step: 2
Training loss: 6.425362709583563
Validation loss: 5.755116749282894

Epoch: 5| Step: 3
Training loss: 5.813456138806934
Validation loss: 5.750202302017841

Epoch: 5| Step: 4
Training loss: 4.857601713096306
Validation loss: 5.745409880699494

Epoch: 5| Step: 5
Training loss: 6.800109795076669
Validation loss: 5.740857771657773

Epoch: 5| Step: 6
Training loss: 5.582781902051086
Validation loss: 5.736074834045435

Epoch: 5| Step: 7
Training loss: 5.631874122708462
Validation loss: 5.731763940623176

Epoch: 5| Step: 8
Training loss: 6.256881892316994
Validation loss: 5.72695838170807

Epoch: 5| Step: 9
Training loss: 5.965895044879975
Validation loss: 5.722634797050967

Epoch: 5| Step: 10
Training loss: 5.675744956439364
Validation loss: 5.717970210969118

Epoch: 2| Step: 0
Training loss: 5.709324474560064
Validation loss: 5.713162993375157

Epoch: 5| Step: 1
Training loss: 6.216124934233388
Validation loss: 5.708081058933414

Epoch: 5| Step: 2
Training loss: 5.153826149639983
Validation loss: 5.702757173331122

Epoch: 5| Step: 3
Training loss: 5.466443779906362
Validation loss: 5.69715733061558

Epoch: 5| Step: 4
Training loss: 5.84145044787345
Validation loss: 5.6917827140287285

Epoch: 5| Step: 5
Training loss: 5.75361055545369
Validation loss: 5.68592675144538

Epoch: 5| Step: 6
Training loss: 6.393187365942353
Validation loss: 5.679357614768628

Epoch: 5| Step: 7
Training loss: 5.583605897238256
Validation loss: 5.673078858902694

Epoch: 5| Step: 8
Training loss: 4.882120849451339
Validation loss: 5.666467760251796

Epoch: 5| Step: 9
Training loss: 5.634470617548258
Validation loss: 5.659518202190402

Epoch: 5| Step: 10
Training loss: 6.20481561256164
Validation loss: 5.651842474890499

Epoch: 3| Step: 0
Training loss: 5.07091736087854
Validation loss: 5.644690946975492

Epoch: 5| Step: 1
Training loss: 6.557449286406936
Validation loss: 5.63684517507268

Epoch: 5| Step: 2
Training loss: 5.662419616263398
Validation loss: 5.62849649390758

Epoch: 5| Step: 3
Training loss: 5.6455850957184275
Validation loss: 5.619861940563818

Epoch: 5| Step: 4
Training loss: 6.568224054508541
Validation loss: 5.610968364024919

Epoch: 5| Step: 5
Training loss: 5.33689395939146
Validation loss: 5.601507180809864

Epoch: 5| Step: 6
Training loss: 6.179037144290167
Validation loss: 5.591772774383622

Epoch: 5| Step: 7
Training loss: 6.009968424125403
Validation loss: 5.581356656793845

Epoch: 5| Step: 8
Training loss: 5.059382856526675
Validation loss: 5.571287519149478

Epoch: 5| Step: 9
Training loss: 5.5768966390858346
Validation loss: 5.560028815868722

Epoch: 5| Step: 10
Training loss: 3.437399984118501
Validation loss: 5.549196658259882

Epoch: 4| Step: 0
Training loss: 5.393364870681002
Validation loss: 5.537938106765955

Epoch: 5| Step: 1
Training loss: 4.73691221430689
Validation loss: 5.52641336410053

Epoch: 5| Step: 2
Training loss: 4.317528709046691
Validation loss: 5.514272322287447

Epoch: 5| Step: 3
Training loss: 5.488526253984199
Validation loss: 5.503303773571963

Epoch: 5| Step: 4
Training loss: 5.270911938630252
Validation loss: 5.490322918373324

Epoch: 5| Step: 5
Training loss: 6.810940625268123
Validation loss: 5.47794508872609

Epoch: 5| Step: 6
Training loss: 5.895602200384264
Validation loss: 5.465187544248775

Epoch: 5| Step: 7
Training loss: 5.446023859000503
Validation loss: 5.452216612447196

Epoch: 5| Step: 8
Training loss: 5.614021098544025
Validation loss: 5.438091545285164

Epoch: 5| Step: 9
Training loss: 6.399121295688463
Validation loss: 5.42393118715269

Epoch: 5| Step: 10
Training loss: 4.71678838314453
Validation loss: 5.40946170537423

Epoch: 5| Step: 0
Training loss: 5.552675293169677
Validation loss: 5.394738065933851

Epoch: 5| Step: 1
Training loss: 5.5059842585717265
Validation loss: 5.380107409543372

Epoch: 5| Step: 2
Training loss: 4.26479636167916
Validation loss: 5.365085511478309

Epoch: 5| Step: 3
Training loss: 5.57041214135548
Validation loss: 5.34984629619845

Epoch: 5| Step: 4
Training loss: 4.998022451337356
Validation loss: 5.334833035551649

Epoch: 5| Step: 5
Training loss: 5.5324273014937555
Validation loss: 5.32004793739356

Epoch: 5| Step: 6
Training loss: 4.868095007189511
Validation loss: 5.303956083180598

Epoch: 5| Step: 7
Training loss: 5.47475169415663
Validation loss: 5.288896245147887

Epoch: 5| Step: 8
Training loss: 6.0107446467551835
Validation loss: 5.27363830208406

Epoch: 5| Step: 9
Training loss: 5.714396169139908
Validation loss: 5.259020504113816

Epoch: 5| Step: 10
Training loss: 5.338900323000566
Validation loss: 5.242862564849103

Epoch: 6| Step: 0
Training loss: 4.9657362909251175
Validation loss: 5.226658500217573

Epoch: 5| Step: 1
Training loss: 4.9305185140492895
Validation loss: 5.210686139020227

Epoch: 5| Step: 2
Training loss: 3.3873061008491114
Validation loss: 5.195229982221479

Epoch: 5| Step: 3
Training loss: 6.120862536515419
Validation loss: 5.179365467400178

Epoch: 5| Step: 4
Training loss: 5.891049802321951
Validation loss: 5.162446243684396

Epoch: 5| Step: 5
Training loss: 5.221251659068839
Validation loss: 5.146192723023385

Epoch: 5| Step: 6
Training loss: 6.130169613655686
Validation loss: 5.1286432006199885

Epoch: 5| Step: 7
Training loss: 4.901850386030897
Validation loss: 5.112535180580246

Epoch: 5| Step: 8
Training loss: 5.47584134957522
Validation loss: 5.094285161910153

Epoch: 5| Step: 9
Training loss: 4.602165972737728
Validation loss: 5.076404880332606

Epoch: 5| Step: 10
Training loss: 4.990541667397759
Validation loss: 5.058040559350208

Epoch: 7| Step: 0
Training loss: 5.002303546515782
Validation loss: 5.040194925180635

Epoch: 5| Step: 1
Training loss: 4.779645264043939
Validation loss: 5.024794197959713

Epoch: 5| Step: 2
Training loss: 5.459186147601585
Validation loss: 5.010637432429249

Epoch: 5| Step: 3
Training loss: 5.35994777454725
Validation loss: 4.9947153856547875

Epoch: 5| Step: 4
Training loss: 5.00125297105811
Validation loss: 4.979329354402743

Epoch: 5| Step: 5
Training loss: 4.913136502640559
Validation loss: 4.966420118647844

Epoch: 5| Step: 6
Training loss: 4.721821978692327
Validation loss: 4.9531510321575904

Epoch: 5| Step: 7
Training loss: 4.33892378511505
Validation loss: 4.938379716366741

Epoch: 5| Step: 8
Training loss: 5.744129003197186
Validation loss: 4.925397487949318

Epoch: 5| Step: 9
Training loss: 4.691339166750815
Validation loss: 4.911573863725681

Epoch: 5| Step: 10
Training loss: 5.295892404886616
Validation loss: 4.898501202825468

Epoch: 8| Step: 0
Training loss: 4.863722447984197
Validation loss: 4.884022472730767

Epoch: 5| Step: 1
Training loss: 4.472491212157076
Validation loss: 4.87035758210395

Epoch: 5| Step: 2
Training loss: 5.169238752622692
Validation loss: 4.859092267088859

Epoch: 5| Step: 3
Training loss: 5.696396126763641
Validation loss: 4.845360101486501

Epoch: 5| Step: 4
Training loss: 5.322055973508382
Validation loss: 4.834057891873353

Epoch: 5| Step: 5
Training loss: 4.019266696301823
Validation loss: 4.819786165498291

Epoch: 5| Step: 6
Training loss: 5.092136993579116
Validation loss: 4.806915539751488

Epoch: 5| Step: 7
Training loss: 5.049503551291152
Validation loss: 4.79471497735619

Epoch: 5| Step: 8
Training loss: 5.236715858045505
Validation loss: 4.782832778672359

Epoch: 5| Step: 9
Training loss: 4.780725587496561
Validation loss: 4.772186374737784

Epoch: 5| Step: 10
Training loss: 3.735642222147304
Validation loss: 4.762044918646299

Epoch: 9| Step: 0
Training loss: 4.577143749497546
Validation loss: 4.751617708835798

Epoch: 5| Step: 1
Training loss: 5.500260260232952
Validation loss: 4.741067437318546

Epoch: 5| Step: 2
Training loss: 4.806993579267416
Validation loss: 4.730057645133105

Epoch: 5| Step: 3
Training loss: 4.388687738136106
Validation loss: 4.720689678733447

Epoch: 5| Step: 4
Training loss: 5.26849359542314
Validation loss: 4.710413673672306

Epoch: 5| Step: 5
Training loss: 4.478140401447695
Validation loss: 4.700576409484116

Epoch: 5| Step: 6
Training loss: 4.7762412969314765
Validation loss: 4.691888438637885

Epoch: 5| Step: 7
Training loss: 5.0737657822022575
Validation loss: 4.681959143311522

Epoch: 5| Step: 8
Training loss: 5.226230034852778
Validation loss: 4.671722022194963

Epoch: 5| Step: 9
Training loss: 4.776726671167196
Validation loss: 4.662903643369666

Epoch: 5| Step: 10
Training loss: 3.2761025880487065
Validation loss: 4.653128822800174

Epoch: 10| Step: 0
Training loss: 5.31573979939464
Validation loss: 4.6457731527327155

Epoch: 5| Step: 1
Training loss: 5.037930430914405
Validation loss: 4.6400633811476135

Epoch: 5| Step: 2
Training loss: 5.150649109459826
Validation loss: 4.633599538644551

Epoch: 5| Step: 3
Training loss: 4.621832097739733
Validation loss: 4.626334089140969

Epoch: 5| Step: 4
Training loss: 4.726180737423503
Validation loss: 4.618378448650246

Epoch: 5| Step: 5
Training loss: 3.8042430578934194
Validation loss: 4.611275490136585

Epoch: 5| Step: 6
Training loss: 4.452530456473073
Validation loss: 4.605522259475094

Epoch: 5| Step: 7
Training loss: 4.592228436360581
Validation loss: 4.598024815953117

Epoch: 5| Step: 8
Training loss: 4.1240496841235
Validation loss: 4.591238000672258

Epoch: 5| Step: 9
Training loss: 4.51961734198469
Validation loss: 4.58455191081035

Epoch: 5| Step: 10
Training loss: 5.308967403148687
Validation loss: 4.579141420763586

Epoch: 11| Step: 0
Training loss: 4.627309068134107
Validation loss: 4.572528398897538

Epoch: 5| Step: 1
Training loss: 4.866088155215252
Validation loss: 4.5669759399231085

Epoch: 5| Step: 2
Training loss: 4.886666838128545
Validation loss: 4.561093346025736

Epoch: 5| Step: 3
Training loss: 4.892717102878901
Validation loss: 4.554799529805942

Epoch: 5| Step: 4
Training loss: 4.668662711556943
Validation loss: 4.549586634997215

Epoch: 5| Step: 5
Training loss: 3.9586444665533227
Validation loss: 4.543960156269085

Epoch: 5| Step: 6
Training loss: 4.154302843642868
Validation loss: 4.538028142761737

Epoch: 5| Step: 7
Training loss: 4.161358211046549
Validation loss: 4.534318248795367

Epoch: 5| Step: 8
Training loss: 4.723883457564792
Validation loss: 4.528107351281743

Epoch: 5| Step: 9
Training loss: 4.317156944760447
Validation loss: 4.522939323133925

Epoch: 5| Step: 10
Training loss: 5.803725972895087
Validation loss: 4.517156680186322

Epoch: 12| Step: 0
Training loss: 4.9042828740839575
Validation loss: 4.5101710650542675

Epoch: 5| Step: 1
Training loss: 4.34057105671462
Validation loss: 4.50241248660483

Epoch: 5| Step: 2
Training loss: 5.2495215061661735
Validation loss: 4.493778298418804

Epoch: 5| Step: 3
Training loss: 4.474781793996422
Validation loss: 4.482839363650813

Epoch: 5| Step: 4
Training loss: 4.179457043150116
Validation loss: 4.474979365160255

Epoch: 5| Step: 5
Training loss: 5.125710414867394
Validation loss: 4.468071137126955

Epoch: 5| Step: 6
Training loss: 4.8758422906419865
Validation loss: 4.462741315353707

Epoch: 5| Step: 7
Training loss: 4.736675647688603
Validation loss: 4.458319315036788

Epoch: 5| Step: 8
Training loss: 3.9507917069486638
Validation loss: 4.453955928621565

Epoch: 5| Step: 9
Training loss: 4.2421546780210475
Validation loss: 4.447842714085354

Epoch: 5| Step: 10
Training loss: 4.014751413519088
Validation loss: 4.442847489679115

Epoch: 13| Step: 0
Training loss: 4.31785361763009
Validation loss: 4.437422099304214

Epoch: 5| Step: 1
Training loss: 4.997067163528664
Validation loss: 4.433851594136954

Epoch: 5| Step: 2
Training loss: 3.175072172050502
Validation loss: 4.428877397230376

Epoch: 5| Step: 3
Training loss: 4.692219304025581
Validation loss: 4.423700086807084

Epoch: 5| Step: 4
Training loss: 3.9132509284844827
Validation loss: 4.418176021997731

Epoch: 5| Step: 5
Training loss: 4.096653731108176
Validation loss: 4.414488806698762

Epoch: 5| Step: 6
Training loss: 4.85021895081548
Validation loss: 4.4098802964473665

Epoch: 5| Step: 7
Training loss: 3.879200535239515
Validation loss: 4.405135815092826

Epoch: 5| Step: 8
Training loss: 5.521884381513501
Validation loss: 4.400607194283777

Epoch: 5| Step: 9
Training loss: 4.990260938958163
Validation loss: 4.397051598614243

Epoch: 5| Step: 10
Training loss: 4.922474270623087
Validation loss: 4.391196380619757

Epoch: 14| Step: 0
Training loss: 4.77654458673704
Validation loss: 4.387396152341191

Epoch: 5| Step: 1
Training loss: 5.301663824946291
Validation loss: 4.384128234653541

Epoch: 5| Step: 2
Training loss: 3.114383516738273
Validation loss: 4.378515094205001

Epoch: 5| Step: 3
Training loss: 4.0473948258983805
Validation loss: 4.374671908497631

Epoch: 5| Step: 4
Training loss: 4.2254978044671425
Validation loss: 4.371364063567014

Epoch: 5| Step: 5
Training loss: 4.078903182459103
Validation loss: 4.367335626936883

Epoch: 5| Step: 6
Training loss: 4.724468883556061
Validation loss: 4.36125108569005

Epoch: 5| Step: 7
Training loss: 4.923841101914177
Validation loss: 4.35756039600706

Epoch: 5| Step: 8
Training loss: 4.647543325894278
Validation loss: 4.353970060381053

Epoch: 5| Step: 9
Training loss: 4.93909940286455
Validation loss: 4.348268125823025

Epoch: 5| Step: 10
Training loss: 4.07155082155796
Validation loss: 4.343506205467481

Epoch: 15| Step: 0
Training loss: 4.606250596272858
Validation loss: 4.3376504763513655

Epoch: 5| Step: 1
Training loss: 4.6902228013333715
Validation loss: 4.335834823969872

Epoch: 5| Step: 2
Training loss: 3.717492540117281
Validation loss: 4.330896389639741

Epoch: 5| Step: 3
Training loss: 4.696684727269669
Validation loss: 4.326934218250785

Epoch: 5| Step: 4
Training loss: 4.390230751664022
Validation loss: 4.322783702234199

Epoch: 5| Step: 5
Training loss: 4.194085252440194
Validation loss: 4.317920872502703

Epoch: 5| Step: 6
Training loss: 4.787209580180838
Validation loss: 4.313224756546992

Epoch: 5| Step: 7
Training loss: 4.793392942974915
Validation loss: 4.309197129869595

Epoch: 5| Step: 8
Training loss: 3.847224208373756
Validation loss: 4.3073203601018575

Epoch: 5| Step: 9
Training loss: 4.769664415754637
Validation loss: 4.3009573281689155

Epoch: 5| Step: 10
Training loss: 4.13698432221184
Validation loss: 4.297269869174631

Epoch: 16| Step: 0
Training loss: 4.197888824648223
Validation loss: 4.293006904342401

Epoch: 5| Step: 1
Training loss: 4.919549689425701
Validation loss: 4.287981475943885

Epoch: 5| Step: 2
Training loss: 4.677538650654759
Validation loss: 4.283821365505652

Epoch: 5| Step: 3
Training loss: 3.5069747638126163
Validation loss: 4.2790529371002135

Epoch: 5| Step: 4
Training loss: 4.739682285267991
Validation loss: 4.273330874615523

Epoch: 5| Step: 5
Training loss: 5.005556833424877
Validation loss: 4.269257479191345

Epoch: 5| Step: 6
Training loss: 4.053619538124327
Validation loss: 4.26496321640961

Epoch: 5| Step: 7
Training loss: 3.932819430406153
Validation loss: 4.261135128692434

Epoch: 5| Step: 8
Training loss: 4.785406960906683
Validation loss: 4.257172912866582

Epoch: 5| Step: 9
Training loss: 4.176032919655318
Validation loss: 4.249811654498843

Epoch: 5| Step: 10
Training loss: 4.05284732523326
Validation loss: 4.249260748233246

Epoch: 17| Step: 0
Training loss: 3.2606114500969627
Validation loss: 4.240013102992765

Epoch: 5| Step: 1
Training loss: 5.0445681753309195
Validation loss: 4.236919311767842

Epoch: 5| Step: 2
Training loss: 4.070647066684105
Validation loss: 4.231894475324894

Epoch: 5| Step: 3
Training loss: 4.6760321145892405
Validation loss: 4.228495460266461

Epoch: 5| Step: 4
Training loss: 4.119800874657193
Validation loss: 4.223722807763397

Epoch: 5| Step: 5
Training loss: 4.443473556225247
Validation loss: 4.218554775349966

Epoch: 5| Step: 6
Training loss: 3.8254042318330583
Validation loss: 4.212599324728731

Epoch: 5| Step: 7
Training loss: 4.396164193138959
Validation loss: 4.208862305353709

Epoch: 5| Step: 8
Training loss: 4.4873220084336545
Validation loss: 4.204718553057238

Epoch: 5| Step: 9
Training loss: 3.93753608808177
Validation loss: 4.199245047996079

Epoch: 5| Step: 10
Training loss: 5.337325668168089
Validation loss: 4.195073571131579

Epoch: 18| Step: 0
Training loss: 3.8138465379507687
Validation loss: 4.189855346295294

Epoch: 5| Step: 1
Training loss: 4.652928748773412
Validation loss: 4.186052529234722

Epoch: 5| Step: 2
Training loss: 4.363327149070358
Validation loss: 4.180827040496864

Epoch: 5| Step: 3
Training loss: 3.8454066482420606
Validation loss: 4.175965832804146

Epoch: 5| Step: 4
Training loss: 3.928405916765094
Validation loss: 4.173052214386326

Epoch: 5| Step: 5
Training loss: 5.245571266679956
Validation loss: 4.168631718267977

Epoch: 5| Step: 6
Training loss: 4.1155764125774255
Validation loss: 4.164690626271168

Epoch: 5| Step: 7
Training loss: 4.736889866816788
Validation loss: 4.160165048617188

Epoch: 5| Step: 8
Training loss: 4.318810752076995
Validation loss: 4.156650587748598

Epoch: 5| Step: 9
Training loss: 4.2403945084341155
Validation loss: 4.154034038862985

Epoch: 5| Step: 10
Training loss: 3.7549789436247747
Validation loss: 4.14687370017565

Epoch: 19| Step: 0
Training loss: 4.387979056350954
Validation loss: 4.146215520886533

Epoch: 5| Step: 1
Training loss: 4.256432993983975
Validation loss: 4.141346192197935

Epoch: 5| Step: 2
Training loss: 4.757589200296648
Validation loss: 4.137087189184868

Epoch: 5| Step: 3
Training loss: 3.5472489886633616
Validation loss: 4.131380505624561

Epoch: 5| Step: 4
Training loss: 4.389200325604998
Validation loss: 4.1282127326397235

Epoch: 5| Step: 5
Training loss: 4.573772353258162
Validation loss: 4.122154089398496

Epoch: 5| Step: 6
Training loss: 4.461893436870964
Validation loss: 4.120773213229374

Epoch: 5| Step: 7
Training loss: 4.892029386954574
Validation loss: 4.116816749309668

Epoch: 5| Step: 8
Training loss: 4.22018792407423
Validation loss: 4.113766316547454

Epoch: 5| Step: 9
Training loss: 3.5158851357750396
Validation loss: 4.110786978032983

Epoch: 5| Step: 10
Training loss: 3.5287119428722207
Validation loss: 4.105647096444055

Epoch: 20| Step: 0
Training loss: 3.9118229289321538
Validation loss: 4.10284091759624

Epoch: 5| Step: 1
Training loss: 4.417226983761896
Validation loss: 4.099974973688747

Epoch: 5| Step: 2
Training loss: 5.300272074499639
Validation loss: 4.095788789457962

Epoch: 5| Step: 3
Training loss: 3.9410265918329173
Validation loss: 4.092431130340768

Epoch: 5| Step: 4
Training loss: 3.6307565429309143
Validation loss: 4.09107747813298

Epoch: 5| Step: 5
Training loss: 3.435327294094947
Validation loss: 4.085410615388876

Epoch: 5| Step: 6
Training loss: 4.390469911490246
Validation loss: 4.083112318090198

Epoch: 5| Step: 7
Training loss: 4.742205398249276
Validation loss: 4.081437839765299

Epoch: 5| Step: 8
Training loss: 3.761816734551026
Validation loss: 4.077830197309742

Epoch: 5| Step: 9
Training loss: 4.143626841560375
Validation loss: 4.075247625541043

Epoch: 5| Step: 10
Training loss: 4.560471175094432
Validation loss: 4.071515539753048

Epoch: 21| Step: 0
Training loss: 4.582594632817263
Validation loss: 4.070994701825694

Epoch: 5| Step: 1
Training loss: 3.8113621749209257
Validation loss: 4.0661425671549445

Epoch: 5| Step: 2
Training loss: 3.442692112656016
Validation loss: 4.063710468899749

Epoch: 5| Step: 3
Training loss: 4.3046569269275015
Validation loss: 4.060736640286781

Epoch: 5| Step: 4
Training loss: 4.469002029674562
Validation loss: 4.057014122322327

Epoch: 5| Step: 5
Training loss: 4.38177815299959
Validation loss: 4.05656624497911

Epoch: 5| Step: 6
Training loss: 4.55320608345677
Validation loss: 4.053008602791449

Epoch: 5| Step: 7
Training loss: 4.869537618881704
Validation loss: 4.049888673014645

Epoch: 5| Step: 8
Training loss: 3.8614626037612463
Validation loss: 4.04516952178894

Epoch: 5| Step: 9
Training loss: 4.463147900133581
Validation loss: 4.041319648367298

Epoch: 5| Step: 10
Training loss: 2.9076979116976576
Validation loss: 4.039487891914466

Epoch: 22| Step: 0
Training loss: 4.532720918989317
Validation loss: 4.040160808305171

Epoch: 5| Step: 1
Training loss: 2.5517996701742987
Validation loss: 4.033918098915389

Epoch: 5| Step: 2
Training loss: 3.8795267551904162
Validation loss: 4.032628408714001

Epoch: 5| Step: 3
Training loss: 4.602360343741305
Validation loss: 4.032437382966469

Epoch: 5| Step: 4
Training loss: 4.61916106463501
Validation loss: 4.031493204813622

Epoch: 5| Step: 5
Training loss: 4.882459752883314
Validation loss: 4.031318177478739

Epoch: 5| Step: 6
Training loss: 4.277603935793794
Validation loss: 4.02407382099207

Epoch: 5| Step: 7
Training loss: 4.725013870138166
Validation loss: 4.0216271591654715

Epoch: 5| Step: 8
Training loss: 4.336796306067116
Validation loss: 4.0176933270023465

Epoch: 5| Step: 9
Training loss: 3.6773430549745734
Validation loss: 4.013156223110083

Epoch: 5| Step: 10
Training loss: 3.056070234320476
Validation loss: 4.009894660225059

Epoch: 23| Step: 0
Training loss: 3.658400335255901
Validation loss: 4.006488882040786

Epoch: 5| Step: 1
Training loss: 5.168384122987476
Validation loss: 4.003140611214581

Epoch: 5| Step: 2
Training loss: 3.4948093889510052
Validation loss: 3.9996796807861696

Epoch: 5| Step: 3
Training loss: 4.187538488410458
Validation loss: 3.9966987990058427

Epoch: 5| Step: 4
Training loss: 4.2031467820067565
Validation loss: 3.9961203903625226

Epoch: 5| Step: 5
Training loss: 3.7977275126790078
Validation loss: 3.991498702578242

Epoch: 5| Step: 6
Training loss: 4.659170374224343
Validation loss: 3.987512916458899

Epoch: 5| Step: 7
Training loss: 4.19166016676129
Validation loss: 3.983478280679648

Epoch: 5| Step: 8
Training loss: 3.859305809728974
Validation loss: 3.984855913338117

Epoch: 5| Step: 9
Training loss: 4.281441120420431
Validation loss: 3.9817307894475324

Epoch: 5| Step: 10
Training loss: 3.7595774100616803
Validation loss: 3.977246563040571

Epoch: 24| Step: 0
Training loss: 3.7388057201318476
Validation loss: 3.973618727277688

Epoch: 5| Step: 1
Training loss: 4.153219624080769
Validation loss: 3.973193838742116

Epoch: 5| Step: 2
Training loss: 3.377072722135735
Validation loss: 3.9704811197112395

Epoch: 5| Step: 3
Training loss: 4.589105243113634
Validation loss: 3.967258330980959

Epoch: 5| Step: 4
Training loss: 3.7562421344795327
Validation loss: 3.9657849950738173

Epoch: 5| Step: 5
Training loss: 4.623986416661464
Validation loss: 3.962444062512778

Epoch: 5| Step: 6
Training loss: 3.6293504851629903
Validation loss: 3.9598792916673187

Epoch: 5| Step: 7
Training loss: 3.692679178672521
Validation loss: 3.957636282943921

Epoch: 5| Step: 8
Training loss: 4.43252456477502
Validation loss: 3.9582635162016615

Epoch: 5| Step: 9
Training loss: 4.909640944457264
Validation loss: 3.955823796879204

Epoch: 5| Step: 10
Training loss: 4.105283143178914
Validation loss: 3.9492724045902095

Epoch: 25| Step: 0
Training loss: 4.367148847869539
Validation loss: 3.948226132581324

Epoch: 5| Step: 1
Training loss: 3.852153492865098
Validation loss: 3.9444300446533203

Epoch: 5| Step: 2
Training loss: 3.8354621173100267
Validation loss: 3.9433650180019884

Epoch: 5| Step: 3
Training loss: 4.84152505287812
Validation loss: 3.9436431689841767

Epoch: 5| Step: 4
Training loss: 3.5903701147277256
Validation loss: 3.9375754390013036

Epoch: 5| Step: 5
Training loss: 4.630453245582066
Validation loss: 3.9363466387864796

Epoch: 5| Step: 6
Training loss: 3.7914163416019364
Validation loss: 3.932443093351494

Epoch: 5| Step: 7
Training loss: 3.97336196257584
Validation loss: 3.930649724164892

Epoch: 5| Step: 8
Training loss: 4.022656885363006
Validation loss: 3.929330729734854

Epoch: 5| Step: 9
Training loss: 4.328120152439749
Validation loss: 3.927865748689849

Epoch: 5| Step: 10
Training loss: 3.5339716322774435
Validation loss: 3.926339408545837

Epoch: 26| Step: 0
Training loss: 4.473029161924037
Validation loss: 3.9256278235634094

Epoch: 5| Step: 1
Training loss: 4.67916209944482
Validation loss: 3.923882972203574

Epoch: 5| Step: 2
Training loss: 3.4767517724109798
Validation loss: 3.9228015539396424

Epoch: 5| Step: 3
Training loss: 3.1545518896043765
Validation loss: 3.917566900708881

Epoch: 5| Step: 4
Training loss: 4.384882854432342
Validation loss: 3.916737512398527

Epoch: 5| Step: 5
Training loss: 4.584996609452553
Validation loss: 3.915297305295247

Epoch: 5| Step: 6
Training loss: 3.9324467036860833
Validation loss: 3.911811363174286

Epoch: 5| Step: 7
Training loss: 4.342821419898801
Validation loss: 3.9089894614794156

Epoch: 5| Step: 8
Training loss: 3.5228341340891585
Validation loss: 3.906676844748412

Epoch: 5| Step: 9
Training loss: 3.5018839534091546
Validation loss: 3.9059646521912157

Epoch: 5| Step: 10
Training loss: 4.48019544038896
Validation loss: 3.9051684648173817

Epoch: 27| Step: 0
Training loss: 4.471203323986588
Validation loss: 3.9016501565502004

Epoch: 5| Step: 1
Training loss: 3.7559488794668727
Validation loss: 3.9001879283682652

Epoch: 5| Step: 2
Training loss: 4.759284933218595
Validation loss: 3.898247210131455

Epoch: 5| Step: 3
Training loss: 4.331114910270426
Validation loss: 3.896256669563348

Epoch: 5| Step: 4
Training loss: 4.402681244688739
Validation loss: 3.8966113679003285

Epoch: 5| Step: 5
Training loss: 3.2855767197569277
Validation loss: 3.8953439864621946

Epoch: 5| Step: 6
Training loss: 3.500161303481687
Validation loss: 3.8909143665695214

Epoch: 5| Step: 7
Training loss: 2.971031195929706
Validation loss: 3.8882212811953583

Epoch: 5| Step: 8
Training loss: 4.216019036136047
Validation loss: 3.8870280101907677

Epoch: 5| Step: 9
Training loss: 4.2222966862408695
Validation loss: 3.8845276539521514

Epoch: 5| Step: 10
Training loss: 4.355726239586087
Validation loss: 3.8822622426972586

Epoch: 28| Step: 0
Training loss: 3.751894027506659
Validation loss: 3.8813518976658186

Epoch: 5| Step: 1
Training loss: 4.853409321962118
Validation loss: 3.87844759572182

Epoch: 5| Step: 2
Training loss: 3.9703679428823313
Validation loss: 3.8767398629168093

Epoch: 5| Step: 3
Training loss: 4.093027531594388
Validation loss: 3.875947143838902

Epoch: 5| Step: 4
Training loss: 4.087740148553321
Validation loss: 3.874520788554257

Epoch: 5| Step: 5
Training loss: 4.248522782250182
Validation loss: 3.8741825444283795

Epoch: 5| Step: 6
Training loss: 4.3677523935165254
Validation loss: 3.8700831138218326

Epoch: 5| Step: 7
Training loss: 3.0892699199496416
Validation loss: 3.870769423528516

Epoch: 5| Step: 8
Training loss: 4.287822940330787
Validation loss: 3.872100907338467

Epoch: 5| Step: 9
Training loss: 3.243580861174655
Validation loss: 3.8710632213743335

Epoch: 5| Step: 10
Training loss: 4.166581928663076
Validation loss: 3.8633533817236705

Epoch: 29| Step: 0
Training loss: 3.89661996552932
Validation loss: 3.8593570249970144

Epoch: 5| Step: 1
Training loss: 3.828854736529557
Validation loss: 3.863491597473226

Epoch: 5| Step: 2
Training loss: 4.434217286480849
Validation loss: 3.8599978452490835

Epoch: 5| Step: 3
Training loss: 2.973222595884017
Validation loss: 3.8625033654596757

Epoch: 5| Step: 4
Training loss: 3.6774089262036744
Validation loss: 3.8556467572834245

Epoch: 5| Step: 5
Training loss: 4.088233317351701
Validation loss: 3.853178577539458

Epoch: 5| Step: 6
Training loss: 4.58237507368373
Validation loss: 3.8498492407556872

Epoch: 5| Step: 7
Training loss: 3.4870489833794696
Validation loss: 3.8580500445014065

Epoch: 5| Step: 8
Training loss: 4.236632023591418
Validation loss: 3.862060442907127

Epoch: 5| Step: 9
Training loss: 4.197305387128435
Validation loss: 3.846047670533275

Epoch: 5| Step: 10
Training loss: 4.625978108672161
Validation loss: 3.840412235720439

Epoch: 30| Step: 0
Training loss: 4.505884138220315
Validation loss: 3.8418591845323697

Epoch: 5| Step: 1
Training loss: 4.37042476658515
Validation loss: 3.841463546947776

Epoch: 5| Step: 2
Training loss: 4.594693871928074
Validation loss: 3.8366760127109814

Epoch: 5| Step: 3
Training loss: 3.817741792886963
Validation loss: 3.829367269024507

Epoch: 5| Step: 4
Training loss: 4.373522263687107
Validation loss: 3.8260271007444984

Epoch: 5| Step: 5
Training loss: 3.3497071721783773
Validation loss: 3.8230554010598152

Epoch: 5| Step: 6
Training loss: 3.8302333708895695
Validation loss: 3.8329050690697875

Epoch: 5| Step: 7
Training loss: 3.80063910380229
Validation loss: 3.820978394479674

Epoch: 5| Step: 8
Training loss: 3.9733737233901794
Validation loss: 3.8147378342096836

Epoch: 5| Step: 9
Training loss: 3.800439738880529
Validation loss: 3.8116971923541887

Epoch: 5| Step: 10
Training loss: 3.1830419144047446
Validation loss: 3.8100365894427397

Epoch: 31| Step: 0
Training loss: 4.651416907243976
Validation loss: 3.8134370590629616

Epoch: 5| Step: 1
Training loss: 4.19206353515059
Validation loss: 3.813261127262312

Epoch: 5| Step: 2
Training loss: 3.0598721810366896
Validation loss: 3.811177323347383

Epoch: 5| Step: 3
Training loss: 4.55211785461232
Validation loss: 3.809861439978124

Epoch: 5| Step: 4
Training loss: 3.4795278182816416
Validation loss: 3.806114577178295

Epoch: 5| Step: 5
Training loss: 4.167898047007511
Validation loss: 3.805005966179043

Epoch: 5| Step: 6
Training loss: 2.8957293009195633
Validation loss: 3.801787957643972

Epoch: 5| Step: 7
Training loss: 4.735858344936603
Validation loss: 3.799972539369661

Epoch: 5| Step: 8
Training loss: 3.865974744734982
Validation loss: 3.7995795100947554

Epoch: 5| Step: 9
Training loss: 3.6327376819412516
Validation loss: 3.7960472499343156

Epoch: 5| Step: 10
Training loss: 4.062474881608043
Validation loss: 3.797925471499489

Epoch: 32| Step: 0
Training loss: 2.8602326988041713
Validation loss: 3.7936913350422983

Epoch: 5| Step: 1
Training loss: 4.185550748437895
Validation loss: 3.7938199605148983

Epoch: 5| Step: 2
Training loss: 3.528523430572292
Validation loss: 3.7890432807444236

Epoch: 5| Step: 3
Training loss: 4.741294915096911
Validation loss: 3.7871733911913945

Epoch: 5| Step: 4
Training loss: 3.457361858529273
Validation loss: 3.788996761975122

Epoch: 5| Step: 5
Training loss: 3.9132579958897447
Validation loss: 3.786238023601022

Epoch: 5| Step: 6
Training loss: 3.395862243778912
Validation loss: 3.786369779819956

Epoch: 5| Step: 7
Training loss: 4.387821483517284
Validation loss: 3.7842508082221493

Epoch: 5| Step: 8
Training loss: 4.352175000024121
Validation loss: 3.7827598901720507

Epoch: 5| Step: 9
Training loss: 4.466011542107598
Validation loss: 3.7783767101057224

Epoch: 5| Step: 10
Training loss: 3.861308613459176
Validation loss: 3.77322469233644

Epoch: 33| Step: 0
Training loss: 3.8200541215827415
Validation loss: 3.7718883532621046

Epoch: 5| Step: 1
Training loss: 4.069201531970134
Validation loss: 3.7710377029262903

Epoch: 5| Step: 2
Training loss: 4.006605892471568
Validation loss: 3.77085454582775

Epoch: 5| Step: 3
Training loss: 5.011360613543452
Validation loss: 3.7708829229386134

Epoch: 5| Step: 4
Training loss: 3.070735057843837
Validation loss: 3.767040117669687

Epoch: 5| Step: 5
Training loss: 3.648878442555987
Validation loss: 3.7687266616725843

Epoch: 5| Step: 6
Training loss: 2.9513983951988956
Validation loss: 3.7668193287630496

Epoch: 5| Step: 7
Training loss: 3.198720592797397
Validation loss: 3.7680063500780303

Epoch: 5| Step: 8
Training loss: 4.609686579114248
Validation loss: 3.769089513075744

Epoch: 5| Step: 9
Training loss: 4.81430931263404
Validation loss: 3.7649293329363576

Epoch: 5| Step: 10
Training loss: 3.5522801558182207
Validation loss: 3.7645191013199915

Epoch: 34| Step: 0
Training loss: 4.084384134248824
Validation loss: 3.7618260641380994

Epoch: 5| Step: 1
Training loss: 4.538394110575378
Validation loss: 3.7591947051168493

Epoch: 5| Step: 2
Training loss: 3.739132838976466
Validation loss: 3.756653310897581

Epoch: 5| Step: 3
Training loss: 3.994511653763296
Validation loss: 3.7564448640115913

Epoch: 5| Step: 4
Training loss: 3.031742173971269
Validation loss: 3.754946329421915

Epoch: 5| Step: 5
Training loss: 3.628438174114866
Validation loss: 3.754627671638486

Epoch: 5| Step: 6
Training loss: 4.336455882934103
Validation loss: 3.752727767506143

Epoch: 5| Step: 7
Training loss: 4.1284068517461945
Validation loss: 3.7525060381154884

Epoch: 5| Step: 8
Training loss: 3.1182836455303313
Validation loss: 3.7494525113255612

Epoch: 5| Step: 9
Training loss: 3.889711694109662
Validation loss: 3.7475337624857046

Epoch: 5| Step: 10
Training loss: 4.564767770365025
Validation loss: 3.746196317660274

Epoch: 35| Step: 0
Training loss: 3.4914978848423206
Validation loss: 3.745398933070113

Epoch: 5| Step: 1
Training loss: 4.162758685714112
Validation loss: 3.74465304546323

Epoch: 5| Step: 2
Training loss: 4.226786552878988
Validation loss: 3.745941688368138

Epoch: 5| Step: 3
Training loss: 3.096257898338325
Validation loss: 3.743452256910537

Epoch: 5| Step: 4
Training loss: 4.13515793818157
Validation loss: 3.743491256592222

Epoch: 5| Step: 5
Training loss: 4.318975479709967
Validation loss: 3.741682355356221

Epoch: 5| Step: 6
Training loss: 3.381068813243122
Validation loss: 3.740308139437448

Epoch: 5| Step: 7
Training loss: 4.079137449903482
Validation loss: 3.740476306223596

Epoch: 5| Step: 8
Training loss: 3.5329138962688726
Validation loss: 3.737993617078319

Epoch: 5| Step: 9
Training loss: 3.950783861825874
Validation loss: 3.7363044243097154

Epoch: 5| Step: 10
Training loss: 4.61065304381912
Validation loss: 3.7387277083217954

Epoch: 36| Step: 0
Training loss: 3.193060568732335
Validation loss: 3.736586131820751

Epoch: 5| Step: 1
Training loss: 4.147617409891251
Validation loss: 3.735582799357947

Epoch: 5| Step: 2
Training loss: 2.9083406865446886
Validation loss: 3.7356961306217897

Epoch: 5| Step: 3
Training loss: 4.3603018045523205
Validation loss: 3.7325531640606147

Epoch: 5| Step: 4
Training loss: 3.6190028074305816
Validation loss: 3.7329194258801452

Epoch: 5| Step: 5
Training loss: 3.6829197773706466
Validation loss: 3.7336788481990797

Epoch: 5| Step: 6
Training loss: 3.271272439497066
Validation loss: 3.733815918186634

Epoch: 5| Step: 7
Training loss: 3.7299639455162397
Validation loss: 3.731128617644228

Epoch: 5| Step: 8
Training loss: 4.42070870806564
Validation loss: 3.7311141130359573

Epoch: 5| Step: 9
Training loss: 3.865283474217586
Validation loss: 3.7285710157711

Epoch: 5| Step: 10
Training loss: 5.485562014027479
Validation loss: 3.727123134827919

Epoch: 37| Step: 0
Training loss: 4.620863637088145
Validation loss: 3.727265094107342

Epoch: 5| Step: 1
Training loss: 3.2134633026378103
Validation loss: 3.727597363194786

Epoch: 5| Step: 2
Training loss: 3.994497567715049
Validation loss: 3.7247034173249967

Epoch: 5| Step: 3
Training loss: 3.658027412524577
Validation loss: 3.724403181411189

Epoch: 5| Step: 4
Training loss: 3.745999809415846
Validation loss: 3.723764357737894

Epoch: 5| Step: 5
Training loss: 3.905249139357706
Validation loss: 3.7227753254961806

Epoch: 5| Step: 6
Training loss: 3.3786203252398788
Validation loss: 3.7217456322934397

Epoch: 5| Step: 7
Training loss: 4.0676938234559685
Validation loss: 3.722424455323228

Epoch: 5| Step: 8
Training loss: 3.424965355690931
Validation loss: 3.721684918544834

Epoch: 5| Step: 9
Training loss: 4.77259791805796
Validation loss: 3.719963240504152

Epoch: 5| Step: 10
Training loss: 3.8923761188097896
Validation loss: 3.7217340930377394

Epoch: 38| Step: 0
Training loss: 3.788551280348863
Validation loss: 3.7216628343102927

Epoch: 5| Step: 1
Training loss: 3.054911183316409
Validation loss: 3.718537043692773

Epoch: 5| Step: 2
Training loss: 3.5077914298939166
Validation loss: 3.718213896258405

Epoch: 5| Step: 3
Training loss: 4.081801821453259
Validation loss: 3.718076677204794

Epoch: 5| Step: 4
Training loss: 3.8391637966530863
Validation loss: 3.7165730647565534

Epoch: 5| Step: 5
Training loss: 4.351779459778808
Validation loss: 3.715658783539795

Epoch: 5| Step: 6
Training loss: 4.103063341477887
Validation loss: 3.7150408463054445

Epoch: 5| Step: 7
Training loss: 3.736104269545356
Validation loss: 3.7147298874584624

Epoch: 5| Step: 8
Training loss: 4.227144155476797
Validation loss: 3.713961787603398

Epoch: 5| Step: 9
Training loss: 4.370471899885131
Validation loss: 3.713466040439463

Epoch: 5| Step: 10
Training loss: 3.611185783853128
Validation loss: 3.713653907011065

Epoch: 39| Step: 0
Training loss: 4.682169821076382
Validation loss: 3.712335392902644

Epoch: 5| Step: 1
Training loss: 3.4719539657388836
Validation loss: 3.711855938849908

Epoch: 5| Step: 2
Training loss: 3.905742154487896
Validation loss: 3.7110511956665095

Epoch: 5| Step: 3
Training loss: 3.740854937912443
Validation loss: 3.7092557374962043

Epoch: 5| Step: 4
Training loss: 2.9463311414587117
Validation loss: 3.7099418294892677

Epoch: 5| Step: 5
Training loss: 2.784376808448487
Validation loss: 3.709676087197755

Epoch: 5| Step: 6
Training loss: 4.536358288765102
Validation loss: 3.706739629113108

Epoch: 5| Step: 7
Training loss: 4.642125564619125
Validation loss: 3.707265070683615

Epoch: 5| Step: 8
Training loss: 4.038899342766662
Validation loss: 3.7053208253887417

Epoch: 5| Step: 9
Training loss: 3.7419538006848723
Validation loss: 3.7061732435866728

Epoch: 5| Step: 10
Training loss: 3.82746900270594
Validation loss: 3.7054989126314997

Epoch: 40| Step: 0
Training loss: 2.9558188448617986
Validation loss: 3.706189902975816

Epoch: 5| Step: 1
Training loss: 2.7053171430955305
Validation loss: 3.703699798647441

Epoch: 5| Step: 2
Training loss: 4.618766501762428
Validation loss: 3.7027950476496287

Epoch: 5| Step: 3
Training loss: 3.6071270965275026
Validation loss: 3.7017891134344056

Epoch: 5| Step: 4
Training loss: 4.685070374569933
Validation loss: 3.7022000028916344

Epoch: 5| Step: 5
Training loss: 4.570347973286479
Validation loss: 3.701919685576855

Epoch: 5| Step: 6
Training loss: 3.107093318926403
Validation loss: 3.7018962147316614

Epoch: 5| Step: 7
Training loss: 3.5016156963238
Validation loss: 3.7003196002357335

Epoch: 5| Step: 8
Training loss: 3.873443290826147
Validation loss: 3.7001439228684796

Epoch: 5| Step: 9
Training loss: 3.9941248662586433
Validation loss: 3.698727486627249

Epoch: 5| Step: 10
Training loss: 4.601686433894499
Validation loss: 3.698776305112404

Epoch: 41| Step: 0
Training loss: 3.300229070400153
Validation loss: 3.6984370423423547

Epoch: 5| Step: 1
Training loss: 3.8789114130913522
Validation loss: 3.6973249286368093

Epoch: 5| Step: 2
Training loss: 4.260409453867036
Validation loss: 3.6978369022948496

Epoch: 5| Step: 3
Training loss: 4.093262388585848
Validation loss: 3.69909063985995

Epoch: 5| Step: 4
Training loss: 4.180899357027594
Validation loss: 3.697235345996803

Epoch: 5| Step: 5
Training loss: 4.65490027200996
Validation loss: 3.696732648356079

Epoch: 5| Step: 6
Training loss: 3.768022336031078
Validation loss: 3.6961669211591004

Epoch: 5| Step: 7
Training loss: 3.5266883215813283
Validation loss: 3.6954514120671145

Epoch: 5| Step: 8
Training loss: 3.870982394652168
Validation loss: 3.6948590132505847

Epoch: 5| Step: 9
Training loss: 3.2064783918448856
Validation loss: 3.6944644984078487

Epoch: 5| Step: 10
Training loss: 3.728039718637369
Validation loss: 3.6935294142265924

Epoch: 42| Step: 0
Training loss: 3.5506959743352633
Validation loss: 3.694001623916431

Epoch: 5| Step: 1
Training loss: 3.867147302900305
Validation loss: 3.692212377465822

Epoch: 5| Step: 2
Training loss: 3.9022550372330036
Validation loss: 3.6924785767761903

Epoch: 5| Step: 3
Training loss: 3.253713100603684
Validation loss: 3.6920984502387575

Epoch: 5| Step: 4
Training loss: 3.580665719134851
Validation loss: 3.6903609587249755

Epoch: 5| Step: 5
Training loss: 3.7423646124417185
Validation loss: 3.6905114801321672

Epoch: 5| Step: 6
Training loss: 3.6855187993680896
Validation loss: 3.690883129456146

Epoch: 5| Step: 7
Training loss: 3.791830094277325
Validation loss: 3.6904779516519937

Epoch: 5| Step: 8
Training loss: 4.87886207383423
Validation loss: 3.6898962153577703

Epoch: 5| Step: 9
Training loss: 4.117625030490712
Validation loss: 3.6888262625062915

Epoch: 5| Step: 10
Training loss: 4.108474458716969
Validation loss: 3.689369206221189

Epoch: 43| Step: 0
Training loss: 3.572620939392663
Validation loss: 3.68899346544098

Epoch: 5| Step: 1
Training loss: 4.309958109641015
Validation loss: 3.687558771036677

Epoch: 5| Step: 2
Training loss: 2.7046844746855374
Validation loss: 3.6863249889285075

Epoch: 5| Step: 3
Training loss: 4.325489991055317
Validation loss: 3.6879319427608475

Epoch: 5| Step: 4
Training loss: 3.1801775430504295
Validation loss: 3.687342664540312

Epoch: 5| Step: 5
Training loss: 3.8518285446670917
Validation loss: 3.6866800694289785

Epoch: 5| Step: 6
Training loss: 3.0552951374245367
Validation loss: 3.686973050250048

Epoch: 5| Step: 7
Training loss: 4.802696646735707
Validation loss: 3.686650176346758

Epoch: 5| Step: 8
Training loss: 3.987075309499509
Validation loss: 3.6862445165816564

Epoch: 5| Step: 9
Training loss: 2.8990550244502153
Validation loss: 3.685840263061845

Epoch: 5| Step: 10
Training loss: 5.320492286277179
Validation loss: 3.684552582658443

Epoch: 44| Step: 0
Training loss: 3.615575443544757
Validation loss: 3.68499043788658

Epoch: 5| Step: 1
Training loss: 4.018460115267794
Validation loss: 3.6836921284582087

Epoch: 5| Step: 2
Training loss: 3.853936815710941
Validation loss: 3.6836551528082864

Epoch: 5| Step: 3
Training loss: 3.7225808038901853
Validation loss: 3.6826479640029945

Epoch: 5| Step: 4
Training loss: 3.819732684423943
Validation loss: 3.6826334564050374

Epoch: 5| Step: 5
Training loss: 3.6870952319393173
Validation loss: 3.6820571647675457

Epoch: 5| Step: 6
Training loss: 3.777873525777434
Validation loss: 3.6818442001064278

Epoch: 5| Step: 7
Training loss: 4.149769944398203
Validation loss: 3.6809931041397546

Epoch: 5| Step: 8
Training loss: 3.9070920723229556
Validation loss: 3.6814510641886193

Epoch: 5| Step: 9
Training loss: 4.533083419830005
Validation loss: 3.6800657639238294

Epoch: 5| Step: 10
Training loss: 3.304621269698696
Validation loss: 3.679579940389809

Epoch: 45| Step: 0
Training loss: 3.8835852485338074
Validation loss: 3.6797866001513406

Epoch: 5| Step: 1
Training loss: 4.568396115980943
Validation loss: 3.6790753920029178

Epoch: 5| Step: 2
Training loss: 3.5936788800707284
Validation loss: 3.678803807482534

Epoch: 5| Step: 3
Training loss: 3.9575797451175694
Validation loss: 3.6780215039157826

Epoch: 5| Step: 4
Training loss: 4.676772392602299
Validation loss: 3.6784304449919203

Epoch: 5| Step: 5
Training loss: 3.9225192205810333
Validation loss: 3.6779149174395105

Epoch: 5| Step: 6
Training loss: 3.068334820975116
Validation loss: 3.677759168324768

Epoch: 5| Step: 7
Training loss: 3.492213033629738
Validation loss: 3.6781785383172028

Epoch: 5| Step: 8
Training loss: 4.1699591534487075
Validation loss: 3.677855299431582

Epoch: 5| Step: 9
Training loss: 2.5142211788119058
Validation loss: 3.677333119253279

Epoch: 5| Step: 10
Training loss: 4.2564809414448
Validation loss: 3.677064155798883

Epoch: 46| Step: 0
Training loss: 4.327327723696402
Validation loss: 3.676206605828248

Epoch: 5| Step: 1
Training loss: 3.971095916189098
Validation loss: 3.676337676549016

Epoch: 5| Step: 2
Training loss: 3.367284078606977
Validation loss: 3.6763137467073896

Epoch: 5| Step: 3
Training loss: 3.4976657167757748
Validation loss: 3.675355019078681

Epoch: 5| Step: 4
Training loss: 4.545655391764077
Validation loss: 3.674402557846793

Epoch: 5| Step: 5
Training loss: 4.000566442436816
Validation loss: 3.674351125633597

Epoch: 5| Step: 6
Training loss: 4.330718547588579
Validation loss: 3.674152944827119

Epoch: 5| Step: 7
Training loss: 3.9888321424135613
Validation loss: 3.673674449670182

Epoch: 5| Step: 8
Training loss: 3.238265052451198
Validation loss: 3.6735750729769223

Epoch: 5| Step: 9
Training loss: 3.5348487003650746
Validation loss: 3.6724603685995354

Epoch: 5| Step: 10
Training loss: 3.3888569102489545
Validation loss: 3.6719191891313736

Epoch: 47| Step: 0
Training loss: 4.387162224355569
Validation loss: 3.672061686590755

Epoch: 5| Step: 1
Training loss: 4.663007914105104
Validation loss: 3.672288453251562

Epoch: 5| Step: 2
Training loss: 3.4027107820381577
Validation loss: 3.6710227338535617

Epoch: 5| Step: 3
Training loss: 3.9636697769347458
Validation loss: 3.6719166784947275

Epoch: 5| Step: 4
Training loss: 4.072995288346954
Validation loss: 3.670611768295742

Epoch: 5| Step: 5
Training loss: 4.072880087035357
Validation loss: 3.671240893165125

Epoch: 5| Step: 6
Training loss: 3.5056752106050806
Validation loss: 3.6702206960895247

Epoch: 5| Step: 7
Training loss: 3.937610200823328
Validation loss: 3.6704888842536785

Epoch: 5| Step: 8
Training loss: 3.704028055682121
Validation loss: 3.6699369413936758

Epoch: 5| Step: 9
Training loss: 3.106015024182004
Validation loss: 3.6691706787326526

Epoch: 5| Step: 10
Training loss: 3.29955771979219
Validation loss: 3.66893631410897

Epoch: 48| Step: 0
Training loss: 3.769316956748871
Validation loss: 3.6688869909629482

Epoch: 5| Step: 1
Training loss: 4.1513822344837275
Validation loss: 3.668141727439387

Epoch: 5| Step: 2
Training loss: 3.5722614870209086
Validation loss: 3.667771310524767

Epoch: 5| Step: 3
Training loss: 4.212708619156102
Validation loss: 3.667421674790879

Epoch: 5| Step: 4
Training loss: 3.82290555171061
Validation loss: 3.6675201025961868

Epoch: 5| Step: 5
Training loss: 4.2395346199005095
Validation loss: 3.6670586347591607

Epoch: 5| Step: 6
Training loss: 3.6841471024840606
Validation loss: 3.6670334321181066

Epoch: 5| Step: 7
Training loss: 3.68126396863065
Validation loss: 3.6666114044126847

Epoch: 5| Step: 8
Training loss: 3.7824127679360826
Validation loss: 3.6661515857622553

Epoch: 5| Step: 9
Training loss: 3.3790939367129
Validation loss: 3.6657424155287166

Epoch: 5| Step: 10
Training loss: 4.091549347375847
Validation loss: 3.6646966750749526

Epoch: 49| Step: 0
Training loss: 4.386924840717637
Validation loss: 3.6655229763938233

Epoch: 5| Step: 1
Training loss: 3.629748818400548
Validation loss: 3.665079291072887

Epoch: 5| Step: 2
Training loss: 3.9448525944428297
Validation loss: 3.6643790877420663

Epoch: 5| Step: 3
Training loss: 3.8096472901813283
Validation loss: 3.6642338483779446

Epoch: 5| Step: 4
Training loss: 3.4872942956124917
Validation loss: 3.663796564747969

Epoch: 5| Step: 5
Training loss: 4.04075743420585
Validation loss: 3.663532731903538

Epoch: 5| Step: 6
Training loss: 3.8496538427717732
Validation loss: 3.6633674110430166

Epoch: 5| Step: 7
Training loss: 3.7186053592538015
Validation loss: 3.6627799341275624

Epoch: 5| Step: 8
Training loss: 4.5683737791697885
Validation loss: 3.6628941503439

Epoch: 5| Step: 9
Training loss: 3.2899748562950615
Validation loss: 3.662610606379339

Epoch: 5| Step: 10
Training loss: 3.4410559554978453
Validation loss: 3.6623068215141483

Epoch: 50| Step: 0
Training loss: 3.8765809310481085
Validation loss: 3.662206051311283

Epoch: 5| Step: 1
Training loss: 3.614853569431295
Validation loss: 3.661377841922023

Epoch: 5| Step: 2
Training loss: 3.8899146967461156
Validation loss: 3.661264978815937

Epoch: 5| Step: 3
Training loss: 4.320455538432298
Validation loss: 3.6609024984048464

Epoch: 5| Step: 4
Training loss: 3.385687119856111
Validation loss: 3.6603383626478982

Epoch: 5| Step: 5
Training loss: 4.041092087845954
Validation loss: 3.6600618127751416

Epoch: 5| Step: 6
Training loss: 3.4509418197144672
Validation loss: 3.659601716195032

Epoch: 5| Step: 7
Training loss: 3.0629413831621086
Validation loss: 3.659781511196777

Epoch: 5| Step: 8
Training loss: 4.58439774146807
Validation loss: 3.659280133302585

Epoch: 5| Step: 9
Training loss: 4.152104884945217
Validation loss: 3.6594679752192962

Epoch: 5| Step: 10
Training loss: 3.7430022752343697
Validation loss: 3.659165676768646

Epoch: 51| Step: 0
Training loss: 2.7198454305262625
Validation loss: 3.6584527681376877

Epoch: 5| Step: 1
Training loss: 3.715189535612209
Validation loss: 3.658630419371607

Epoch: 5| Step: 2
Training loss: 4.543204487582659
Validation loss: 3.6580547712667597

Epoch: 5| Step: 3
Training loss: 3.6100442109082147
Validation loss: 3.658080672107809

Epoch: 5| Step: 4
Training loss: 4.076271776072742
Validation loss: 3.65735035898207

Epoch: 5| Step: 5
Training loss: 3.6332600635758507
Validation loss: 3.657032963677422

Epoch: 5| Step: 6
Training loss: 3.9400546551316777
Validation loss: 3.6568901063323325

Epoch: 5| Step: 7
Training loss: 3.4424227058858614
Validation loss: 3.656832137951859

Epoch: 5| Step: 8
Training loss: 4.872929451240555
Validation loss: 3.6575377462805085

Epoch: 5| Step: 9
Training loss: 3.2117608492835705
Validation loss: 3.6571609109801075

Epoch: 5| Step: 10
Training loss: 4.173181450693242
Validation loss: 3.656618471162202

Epoch: 52| Step: 0
Training loss: 4.386066065508573
Validation loss: 3.655506825229556

Epoch: 5| Step: 1
Training loss: 2.9465475149215616
Validation loss: 3.6563501869304385

Epoch: 5| Step: 2
Training loss: 3.2034858314292523
Validation loss: 3.6550897637032636

Epoch: 5| Step: 3
Training loss: 3.9006216776362583
Validation loss: 3.6549135143653677

Epoch: 5| Step: 4
Training loss: 3.7754544066731457
Validation loss: 3.6542561797584465

Epoch: 5| Step: 5
Training loss: 4.151478487944296
Validation loss: 3.65512971882439

Epoch: 5| Step: 6
Training loss: 3.2709540731575633
Validation loss: 3.6536990398436786

Epoch: 5| Step: 7
Training loss: 4.0150820591428005
Validation loss: 3.6531207872653813

Epoch: 5| Step: 8
Training loss: 3.728079497066847
Validation loss: 3.6529923812460545

Epoch: 5| Step: 9
Training loss: 4.048106591596707
Validation loss: 3.6532294585228207

Epoch: 5| Step: 10
Training loss: 4.6883680429992065
Validation loss: 3.65260592608656

Epoch: 53| Step: 0
Training loss: 3.7549733561498817
Validation loss: 3.651834304829172

Epoch: 5| Step: 1
Training loss: 3.917374053274285
Validation loss: 3.653078613615532

Epoch: 5| Step: 2
Training loss: 3.3872551410761886
Validation loss: 3.6532230010467037

Epoch: 5| Step: 3
Training loss: 4.432917418127423
Validation loss: 3.656291588763307

Epoch: 5| Step: 4
Training loss: 4.018803744750216
Validation loss: 3.6565441892850052

Epoch: 5| Step: 5
Training loss: 3.7914323140476074
Validation loss: 3.6517924062573806

Epoch: 5| Step: 6
Training loss: 3.254884570487824
Validation loss: 3.651065274377989

Epoch: 5| Step: 7
Training loss: 3.2440882982309143
Validation loss: 3.6511160052565637

Epoch: 5| Step: 8
Training loss: 4.615000456937063
Validation loss: 3.651337880144324

Epoch: 5| Step: 9
Training loss: 3.761915223565251
Validation loss: 3.6511585498396832

Epoch: 5| Step: 10
Training loss: 3.883945721868724
Validation loss: 3.652153393685805

Epoch: 54| Step: 0
Training loss: 4.253313007445683
Validation loss: 3.6512465401149976

Epoch: 5| Step: 1
Training loss: 4.5564246292033985
Validation loss: 3.6503497527733533

Epoch: 5| Step: 2
Training loss: 3.488704711226473
Validation loss: 3.6497529414149663

Epoch: 5| Step: 3
Training loss: 3.468700099276838
Validation loss: 3.6498702076889518

Epoch: 5| Step: 4
Training loss: 4.162534623102298
Validation loss: 3.649062700180015

Epoch: 5| Step: 5
Training loss: 3.938312991543505
Validation loss: 3.649030620305572

Epoch: 5| Step: 6
Training loss: 3.8317897148889077
Validation loss: 3.6483815671907287

Epoch: 5| Step: 7
Training loss: 3.6738346146440555
Validation loss: 3.647977767296485

Epoch: 5| Step: 8
Training loss: 3.2789566017994773
Validation loss: 3.6477497479640713

Epoch: 5| Step: 9
Training loss: 3.307930439615525
Validation loss: 3.647883571389993

Epoch: 5| Step: 10
Training loss: 4.137527862178421
Validation loss: 3.6469787659376833

Epoch: 55| Step: 0
Training loss: 5.007128402474535
Validation loss: 3.646925303450917

Epoch: 5| Step: 1
Training loss: 3.545008231127912
Validation loss: 3.646889709628012

Epoch: 5| Step: 2
Training loss: 4.289650131577489
Validation loss: 3.646611443853758

Epoch: 5| Step: 3
Training loss: 4.458264406806318
Validation loss: 3.6469884117932083

Epoch: 5| Step: 4
Training loss: 2.398097110414122
Validation loss: 3.6463301294077217

Epoch: 5| Step: 5
Training loss: 3.8335308908611294
Validation loss: 3.6459984854752068

Epoch: 5| Step: 6
Training loss: 3.4612407336209166
Validation loss: 3.6460879587071453

Epoch: 5| Step: 7
Training loss: 4.010669307264852
Validation loss: 3.645084610570912

Epoch: 5| Step: 8
Training loss: 3.5706340887033154
Validation loss: 3.644393132032213

Epoch: 5| Step: 9
Training loss: 3.5551891601713135
Validation loss: 3.6440454405507983

Epoch: 5| Step: 10
Training loss: 3.479951111461076
Validation loss: 3.6436232564402435

Epoch: 56| Step: 0
Training loss: 3.1762358655618823
Validation loss: 3.6438581009464532

Epoch: 5| Step: 1
Training loss: 3.4508817126535303
Validation loss: 3.643307949940297

Epoch: 5| Step: 2
Training loss: 3.430830015734209
Validation loss: 3.643362285960307

Epoch: 5| Step: 3
Training loss: 3.2737948056505304
Validation loss: 3.6434239009851286

Epoch: 5| Step: 4
Training loss: 2.789264062602409
Validation loss: 3.642568122603487

Epoch: 5| Step: 5
Training loss: 4.261826161570332
Validation loss: 3.6425182284489983

Epoch: 5| Step: 6
Training loss: 4.719480950539464
Validation loss: 3.6424820862202467

Epoch: 5| Step: 7
Training loss: 4.2163960989490095
Validation loss: 3.6424980487537155

Epoch: 5| Step: 8
Training loss: 4.076751126786606
Validation loss: 3.6423567567872914

Epoch: 5| Step: 9
Training loss: 3.6363282613767565
Validation loss: 3.641793095465684

Epoch: 5| Step: 10
Training loss: 4.795368566896898
Validation loss: 3.641460963699966

Epoch: 57| Step: 0
Training loss: 3.498043603432306
Validation loss: 3.6418618242817975

Epoch: 5| Step: 1
Training loss: 4.200168406425388
Validation loss: 3.6407569362438386

Epoch: 5| Step: 2
Training loss: 2.885372689436462
Validation loss: 3.6407798041620394

Epoch: 5| Step: 3
Training loss: 4.6057108135203535
Validation loss: 3.6405355122180967

Epoch: 5| Step: 4
Training loss: 3.6142929063076017
Validation loss: 3.6398534089601555

Epoch: 5| Step: 5
Training loss: 3.538960099580918
Validation loss: 3.6395219215026007

Epoch: 5| Step: 6
Training loss: 4.153746345603362
Validation loss: 3.6393777047786178

Epoch: 5| Step: 7
Training loss: 4.024316784229838
Validation loss: 3.6387803746903646

Epoch: 5| Step: 8
Training loss: 4.319967687274038
Validation loss: 3.638707862028604

Epoch: 5| Step: 9
Training loss: 3.407411989571382
Validation loss: 3.6382218866145886

Epoch: 5| Step: 10
Training loss: 3.583465455450932
Validation loss: 3.6380167809511086

Epoch: 58| Step: 0
Training loss: 4.125372436356196
Validation loss: 3.6373087671579403

Epoch: 5| Step: 1
Training loss: 4.111318614522848
Validation loss: 3.6376915829976553

Epoch: 5| Step: 2
Training loss: 3.2268797785420475
Validation loss: 3.636664055298799

Epoch: 5| Step: 3
Training loss: 4.112472005360407
Validation loss: 3.6367590860044454

Epoch: 5| Step: 4
Training loss: 3.382021628736459
Validation loss: 3.6365057132089684

Epoch: 5| Step: 5
Training loss: 3.6479997719463477
Validation loss: 3.636039171211453

Epoch: 5| Step: 6
Training loss: 4.16137012806761
Validation loss: 3.635616621493833

Epoch: 5| Step: 7
Training loss: 3.835848743165499
Validation loss: 3.6355883718237347

Epoch: 5| Step: 8
Training loss: 3.314834779560467
Validation loss: 3.6361598268266446

Epoch: 5| Step: 9
Training loss: 4.171241740766424
Validation loss: 3.6348316274159083

Epoch: 5| Step: 10
Training loss: 3.9097791674757967
Validation loss: 3.634850999087909

Epoch: 59| Step: 0
Training loss: 3.8372310780289745
Validation loss: 3.634448353039466

Epoch: 5| Step: 1
Training loss: 3.9497727968567444
Validation loss: 3.6343866895405967

Epoch: 5| Step: 2
Training loss: 3.80796694561693
Validation loss: 3.6339887447465626

Epoch: 5| Step: 3
Training loss: 3.08713046808481
Validation loss: 3.634197850338433

Epoch: 5| Step: 4
Training loss: 3.7259558097852112
Validation loss: 3.633971225263295

Epoch: 5| Step: 5
Training loss: 4.110465365606501
Validation loss: 3.6331440591145956

Epoch: 5| Step: 6
Training loss: 3.737057795566885
Validation loss: 3.6337704174803336

Epoch: 5| Step: 7
Training loss: 4.101999372194894
Validation loss: 3.63321852305531

Epoch: 5| Step: 8
Training loss: 4.420061905716504
Validation loss: 3.6327316439254558

Epoch: 5| Step: 9
Training loss: 3.4412685197857713
Validation loss: 3.6324195659015968

Epoch: 5| Step: 10
Training loss: 3.7422517201561574
Validation loss: 3.632145698350731

Epoch: 60| Step: 0
Training loss: 2.9897887971212285
Validation loss: 3.6320742616183224

Epoch: 5| Step: 1
Training loss: 4.0522255892981205
Validation loss: 3.631781423384192

Epoch: 5| Step: 2
Training loss: 4.360618714695332
Validation loss: 3.631440630201402

Epoch: 5| Step: 3
Training loss: 4.361632716146732
Validation loss: 3.6312808601647095

Epoch: 5| Step: 4
Training loss: 3.4726323576406712
Validation loss: 3.6313717225047695

Epoch: 5| Step: 5
Training loss: 4.3382089524691185
Validation loss: 3.6309866983585866

Epoch: 5| Step: 6
Training loss: 3.639442087950824
Validation loss: 3.630309729973271

Epoch: 5| Step: 7
Training loss: 3.6289655107765575
Validation loss: 3.6311124837759667

Epoch: 5| Step: 8
Training loss: 2.6205380073736
Validation loss: 3.629946964343953

Epoch: 5| Step: 9
Training loss: 4.346210688406909
Validation loss: 3.629740598635217

Epoch: 5| Step: 10
Training loss: 3.8440335797164034
Validation loss: 3.629891766451841

Epoch: 61| Step: 0
Training loss: 3.9619358467403942
Validation loss: 3.6295520841771856

Epoch: 5| Step: 1
Training loss: 3.756197322533211
Validation loss: 3.6295989838040437

Epoch: 5| Step: 2
Training loss: 3.909922102130241
Validation loss: 3.6286730659863125

Epoch: 5| Step: 3
Training loss: 4.083439780164809
Validation loss: 3.6286475953266835

Epoch: 5| Step: 4
Training loss: 3.9678976991063832
Validation loss: 3.6287928135587153

Epoch: 5| Step: 5
Training loss: 3.883617785818172
Validation loss: 3.6279233220802998

Epoch: 5| Step: 6
Training loss: 4.1125529369901
Validation loss: 3.6276553495436286

Epoch: 5| Step: 7
Training loss: 3.1541617255296055
Validation loss: 3.6271698242372907

Epoch: 5| Step: 8
Training loss: 4.267855218406923
Validation loss: 3.627524044919195

Epoch: 5| Step: 9
Training loss: 2.9213889630637584
Validation loss: 3.6266814615355325

Epoch: 5| Step: 10
Training loss: 3.855422865141407
Validation loss: 3.626479104884438

Epoch: 62| Step: 0
Training loss: 3.575951995006821
Validation loss: 3.6266091424094484

Epoch: 5| Step: 1
Training loss: 3.8161850926676792
Validation loss: 3.6256970494593364

Epoch: 5| Step: 2
Training loss: 3.7925161451123053
Validation loss: 3.6261451900958495

Epoch: 5| Step: 3
Training loss: 3.7855117363224435
Validation loss: 3.625244190391637

Epoch: 5| Step: 4
Training loss: 4.38053565629917
Validation loss: 3.625314497326658

Epoch: 5| Step: 5
Training loss: 4.017250770951929
Validation loss: 3.625011188064074

Epoch: 5| Step: 6
Training loss: 3.161286216881342
Validation loss: 3.6248569566384448

Epoch: 5| Step: 7
Training loss: 3.67696271631896
Validation loss: 3.6261213857364

Epoch: 5| Step: 8
Training loss: 4.009882639549315
Validation loss: 3.6247958930986983

Epoch: 5| Step: 9
Training loss: 3.3780458622784044
Validation loss: 3.6243613744560794

Epoch: 5| Step: 10
Training loss: 4.3634705259137
Validation loss: 3.624870435176489

Epoch: 63| Step: 0
Training loss: 4.248615712633094
Validation loss: 3.6250925897379678

Epoch: 5| Step: 1
Training loss: 4.218455890717445
Validation loss: 3.6236673889375264

Epoch: 5| Step: 2
Training loss: 3.797471992434598
Validation loss: 3.627835287632753

Epoch: 5| Step: 3
Training loss: 3.813004257123738
Validation loss: 3.6376635242192843

Epoch: 5| Step: 4
Training loss: 4.228052578212099
Validation loss: 3.623134728614142

Epoch: 5| Step: 5
Training loss: 4.1225426029851695
Validation loss: 3.6267357822844026

Epoch: 5| Step: 6
Training loss: 4.009312993891023
Validation loss: 3.626697362134097

Epoch: 5| Step: 7
Training loss: 3.4355062077876615
Validation loss: 3.6219666221877596

Epoch: 5| Step: 8
Training loss: 3.507082313034987
Validation loss: 3.6214837335313192

Epoch: 5| Step: 9
Training loss: 3.3815247372968003
Validation loss: 3.621826518269751

Epoch: 5| Step: 10
Training loss: 2.9151321370714767
Validation loss: 3.6222514254545346

Epoch: 64| Step: 0
Training loss: 3.8664006212940816
Validation loss: 3.6218324838634572

Epoch: 5| Step: 1
Training loss: 3.3482581435464613
Validation loss: 3.6225296361097294

Epoch: 5| Step: 2
Training loss: 3.251727305410157
Validation loss: 3.6229727086452264

Epoch: 5| Step: 3
Training loss: 3.79291318308615
Validation loss: 3.6232151139368622

Epoch: 5| Step: 4
Training loss: 3.9523204844254325
Validation loss: 3.623641793950871

Epoch: 5| Step: 5
Training loss: 4.153767008991987
Validation loss: 3.622802699258358

Epoch: 5| Step: 6
Training loss: 4.289122534159768
Validation loss: 3.622494470649601

Epoch: 5| Step: 7
Training loss: 4.041616196989102
Validation loss: 3.6212216829101225

Epoch: 5| Step: 8
Training loss: 3.6901890922829685
Validation loss: 3.621249723249558

Epoch: 5| Step: 9
Training loss: 3.6628350843441666
Validation loss: 3.6211989137795486

Epoch: 5| Step: 10
Training loss: 3.8597325456690235
Validation loss: 3.6202430956481817

Epoch: 65| Step: 0
Training loss: 3.7171453010950657
Validation loss: 3.6202667828693023

Epoch: 5| Step: 1
Training loss: 3.498610765767498
Validation loss: 3.619687907774715

Epoch: 5| Step: 2
Training loss: 3.6568835109050304
Validation loss: 3.6197256345901736

Epoch: 5| Step: 3
Training loss: 4.104155151557582
Validation loss: 3.6198432886221883

Epoch: 5| Step: 4
Training loss: 4.213545916743389
Validation loss: 3.62005913590897

Epoch: 5| Step: 5
Training loss: 3.8574873906619853
Validation loss: 3.6185773444979477

Epoch: 5| Step: 6
Training loss: 3.5648303524704414
Validation loss: 3.6193606748251104

Epoch: 5| Step: 7
Training loss: 3.992716476122943
Validation loss: 3.6194602155316775

Epoch: 5| Step: 8
Training loss: 3.018313775619709
Validation loss: 3.6202407290419685

Epoch: 5| Step: 9
Training loss: 4.447647312891732
Validation loss: 3.6177826866170752

Epoch: 5| Step: 10
Training loss: 3.7002195396244337
Validation loss: 3.6195386008312713

Epoch: 66| Step: 0
Training loss: 3.6147287799400463
Validation loss: 3.619713379155057

Epoch: 5| Step: 1
Training loss: 3.736589230209468
Validation loss: 3.623576200400887

Epoch: 5| Step: 2
Training loss: 3.4199317744627566
Validation loss: 3.618374076931245

Epoch: 5| Step: 3
Training loss: 3.3285493535397963
Validation loss: 3.6160462450432913

Epoch: 5| Step: 4
Training loss: 4.007505051864896
Validation loss: 3.6154452672734356

Epoch: 5| Step: 5
Training loss: 2.9538436096055127
Validation loss: 3.6155759966073537

Epoch: 5| Step: 6
Training loss: 4.4561966859429125
Validation loss: 3.6144642195733896

Epoch: 5| Step: 7
Training loss: 4.134809909127521
Validation loss: 3.614547587938417

Epoch: 5| Step: 8
Training loss: 4.724844729178278
Validation loss: 3.6143833403075742

Epoch: 5| Step: 9
Training loss: 3.7336854178300034
Validation loss: 3.613529687359669

Epoch: 5| Step: 10
Training loss: 3.4419287156166134
Validation loss: 3.6140140658363875

Epoch: 67| Step: 0
Training loss: 3.8116790638065825
Validation loss: 3.614048605877196

Epoch: 5| Step: 1
Training loss: 3.6267517066783785
Validation loss: 3.6130119261049662

Epoch: 5| Step: 2
Training loss: 4.059171516187404
Validation loss: 3.613186667506185

Epoch: 5| Step: 3
Training loss: 3.7820047933547105
Validation loss: 3.6126585817038808

Epoch: 5| Step: 4
Training loss: 4.400442638673951
Validation loss: 3.612455416832659

Epoch: 5| Step: 5
Training loss: 3.7198798763199985
Validation loss: 3.612462350273237

Epoch: 5| Step: 6
Training loss: 3.99660992015506
Validation loss: 3.612212982170038

Epoch: 5| Step: 7
Training loss: 3.7093637442156915
Validation loss: 3.611810185267211

Epoch: 5| Step: 8
Training loss: 3.410172330243803
Validation loss: 3.6108301038133055

Epoch: 5| Step: 9
Training loss: 4.182365800035039
Validation loss: 3.61129598394111

Epoch: 5| Step: 10
Training loss: 2.9041479568936883
Validation loss: 3.611078015489478

Epoch: 68| Step: 0
Training loss: 2.658253172460073
Validation loss: 3.610443161736541

Epoch: 5| Step: 1
Training loss: 3.721456744749232
Validation loss: 3.610099911102972

Epoch: 5| Step: 2
Training loss: 4.03160957093093
Validation loss: 3.609907222097922

Epoch: 5| Step: 3
Training loss: 4.53587263365122
Validation loss: 3.609474405561364

Epoch: 5| Step: 4
Training loss: 3.1320087419682636
Validation loss: 3.6095395792242746

Epoch: 5| Step: 5
Training loss: 4.2053908583053445
Validation loss: 3.6088622489471445

Epoch: 5| Step: 6
Training loss: 3.8699305198405765
Validation loss: 3.6089319146182417

Epoch: 5| Step: 7
Training loss: 4.040363980128393
Validation loss: 3.6091214620852594

Epoch: 5| Step: 8
Training loss: 3.6304519695619026
Validation loss: 3.6080236094029097

Epoch: 5| Step: 9
Training loss: 3.3265123355464175
Validation loss: 3.6078012749733186

Epoch: 5| Step: 10
Training loss: 4.428022983536175
Validation loss: 3.607436250146919

Epoch: 69| Step: 0
Training loss: 3.699493816908304
Validation loss: 3.60705769734779

Epoch: 5| Step: 1
Training loss: 2.928540954032537
Validation loss: 3.607521817613491

Epoch: 5| Step: 2
Training loss: 3.512824269595628
Validation loss: 3.6071225877464363

Epoch: 5| Step: 3
Training loss: 3.959845578621818
Validation loss: 3.606525990197264

Epoch: 5| Step: 4
Training loss: 3.8856173847842377
Validation loss: 3.6076160142397278

Epoch: 5| Step: 5
Training loss: 3.6383295640446813
Validation loss: 3.6060873449369812

Epoch: 5| Step: 6
Training loss: 4.165128016891525
Validation loss: 3.6062765030665354

Epoch: 5| Step: 7
Training loss: 4.131876444680016
Validation loss: 3.6056225636462274

Epoch: 5| Step: 8
Training loss: 3.695808232224703
Validation loss: 3.605993731160863

Epoch: 5| Step: 9
Training loss: 4.201872571666174
Validation loss: 3.6055009927779906

Epoch: 5| Step: 10
Training loss: 3.899175356220483
Validation loss: 3.6050626494747813

Epoch: 70| Step: 0
Training loss: 4.127357733878094
Validation loss: 3.604524941140736

Epoch: 5| Step: 1
Training loss: 3.416385933732541
Validation loss: 3.604151218164726

Epoch: 5| Step: 2
Training loss: 4.397634104233966
Validation loss: 3.6035008671147084

Epoch: 5| Step: 3
Training loss: 4.042070165464001
Validation loss: 3.6036126296994753

Epoch: 5| Step: 4
Training loss: 3.690520261978946
Validation loss: 3.603799022441449

Epoch: 5| Step: 5
Training loss: 3.730323924503886
Validation loss: 3.6030862756038875

Epoch: 5| Step: 6
Training loss: 3.753921492880083
Validation loss: 3.6024642191717247

Epoch: 5| Step: 7
Training loss: 3.291495902223338
Validation loss: 3.6024064581194755

Epoch: 5| Step: 8
Training loss: 3.904019504787624
Validation loss: 3.6029318442156897

Epoch: 5| Step: 9
Training loss: 4.126316438479224
Validation loss: 3.602131362010575

Epoch: 5| Step: 10
Training loss: 3.055194471197527
Validation loss: 3.6028646668225934

Epoch: 71| Step: 0
Training loss: 3.745091340971763
Validation loss: 3.602488675858397

Epoch: 5| Step: 1
Training loss: 3.6549769084321007
Validation loss: 3.6016609025945625

Epoch: 5| Step: 2
Training loss: 3.667377720870074
Validation loss: 3.60190797490194

Epoch: 5| Step: 3
Training loss: 4.352581459610931
Validation loss: 3.6021161429633914

Epoch: 5| Step: 4
Training loss: 3.0139599883037915
Validation loss: 3.600957155711288

Epoch: 5| Step: 5
Training loss: 3.3558055277915684
Validation loss: 3.6013116937627534

Epoch: 5| Step: 6
Training loss: 3.6271053645856037
Validation loss: 3.600764091362052

Epoch: 5| Step: 7
Training loss: 4.3171012767640615
Validation loss: 3.6002023577359514

Epoch: 5| Step: 8
Training loss: 4.719567436505143
Validation loss: 3.600019696852877

Epoch: 5| Step: 9
Training loss: 3.3990590195858514
Validation loss: 3.599632821961414

Epoch: 5| Step: 10
Training loss: 3.6162126516924777
Validation loss: 3.5995438976149408

Epoch: 72| Step: 0
Training loss: 4.2913767645736325
Validation loss: 3.5992536136806232

Epoch: 5| Step: 1
Training loss: 4.198070791489982
Validation loss: 3.5994512575012707

Epoch: 5| Step: 2
Training loss: 3.92492921607464
Validation loss: 3.599096207099709

Epoch: 5| Step: 3
Training loss: 3.5018572647922865
Validation loss: 3.5988756262938577

Epoch: 5| Step: 4
Training loss: 3.809556794307597
Validation loss: 3.5985952649214377

Epoch: 5| Step: 5
Training loss: 3.4398121773654675
Validation loss: 3.5984164451334486

Epoch: 5| Step: 6
Training loss: 3.0756218506289756
Validation loss: 3.598614283111737

Epoch: 5| Step: 7
Training loss: 3.7197213066466546
Validation loss: 3.597852402565066

Epoch: 5| Step: 8
Training loss: 4.14937211767603
Validation loss: 3.5978056919248402

Epoch: 5| Step: 9
Training loss: 3.5623745812541285
Validation loss: 3.5973641746636114

Epoch: 5| Step: 10
Training loss: 3.9785744724032117
Validation loss: 3.5972553565276417

Epoch: 73| Step: 0
Training loss: 4.311704479317637
Validation loss: 3.597154835046456

Epoch: 5| Step: 1
Training loss: 4.011191209913254
Validation loss: 3.5967171096704824

Epoch: 5| Step: 2
Training loss: 3.665719184413483
Validation loss: 3.5964838216817165

Epoch: 5| Step: 3
Training loss: 3.8932706730734092
Validation loss: 3.5960065878906846

Epoch: 5| Step: 4
Training loss: 3.333771835730508
Validation loss: 3.5955243553127443

Epoch: 5| Step: 5
Training loss: 3.7031528133844738
Validation loss: 3.595794980466016

Epoch: 5| Step: 6
Training loss: 4.279979210918954
Validation loss: 3.595202180670217

Epoch: 5| Step: 7
Training loss: 3.909309104894662
Validation loss: 3.5953535585455336

Epoch: 5| Step: 8
Training loss: 2.5997003529347045
Validation loss: 3.5945505899218744

Epoch: 5| Step: 9
Training loss: 3.992837453589381
Validation loss: 3.5945346027505045

Epoch: 5| Step: 10
Training loss: 3.7742224088227454
Validation loss: 3.5940467829630935

Epoch: 74| Step: 0
Training loss: 3.281255086259079
Validation loss: 3.5941347962149934

Epoch: 5| Step: 1
Training loss: 4.358150405886326
Validation loss: 3.59359123945778

Epoch: 5| Step: 2
Training loss: 4.263942065133444
Validation loss: 3.593737657408989

Epoch: 5| Step: 3
Training loss: 3.58672116428461
Validation loss: 3.5929790852356325

Epoch: 5| Step: 4
Training loss: 3.6062713093516456
Validation loss: 3.5931057524177383

Epoch: 5| Step: 5
Training loss: 3.28344028576255
Validation loss: 3.5924582522398802

Epoch: 5| Step: 6
Training loss: 3.201284931413817
Validation loss: 3.592525912520722

Epoch: 5| Step: 7
Training loss: 4.901638123084246
Validation loss: 3.5922515998305413

Epoch: 5| Step: 8
Training loss: 3.5962608522338266
Validation loss: 3.5922714152158455

Epoch: 5| Step: 9
Training loss: 3.570042706402419
Validation loss: 3.5919560188947033

Epoch: 5| Step: 10
Training loss: 3.721922987365127
Validation loss: 3.5924558345033932

Epoch: 75| Step: 0
Training loss: 3.293475816813085
Validation loss: 3.591304227509375

Epoch: 5| Step: 1
Training loss: 3.7504567186070195
Validation loss: 3.5911400261676394

Epoch: 5| Step: 2
Training loss: 3.539345567847963
Validation loss: 3.590957648211905

Epoch: 5| Step: 3
Training loss: 3.862621347440887
Validation loss: 3.5914695377488597

Epoch: 5| Step: 4
Training loss: 3.359871477212155
Validation loss: 3.5914791142624707

Epoch: 5| Step: 5
Training loss: 4.541822005015624
Validation loss: 3.590786139460907

Epoch: 5| Step: 6
Training loss: 3.4145897080689918
Validation loss: 3.5914603609465034

Epoch: 5| Step: 7
Training loss: 3.9431712165672015
Validation loss: 3.5910785891869774

Epoch: 5| Step: 8
Training loss: 3.3603379399789266
Validation loss: 3.588811792098627

Epoch: 5| Step: 9
Training loss: 4.6136215045722135
Validation loss: 3.589450714552725

Epoch: 5| Step: 10
Training loss: 3.7676292562302813
Validation loss: 3.5895868128410084

Epoch: 76| Step: 0
Training loss: 4.105292667638069
Validation loss: 3.588140917536719

Epoch: 5| Step: 1
Training loss: 4.018545076120037
Validation loss: 3.5884599640499424

Epoch: 5| Step: 2
Training loss: 4.1983906341878585
Validation loss: 3.589719308023683

Epoch: 5| Step: 3
Training loss: 3.3297997500949545
Validation loss: 3.5896040875842354

Epoch: 5| Step: 4
Training loss: 3.6257925811373526
Validation loss: 3.587552196729949

Epoch: 5| Step: 5
Training loss: 3.488188568285126
Validation loss: 3.587056620655951

Epoch: 5| Step: 6
Training loss: 3.9138012949269507
Validation loss: 3.587167327595647

Epoch: 5| Step: 7
Training loss: 3.8271706150480163
Validation loss: 3.586905477268341

Epoch: 5| Step: 8
Training loss: 4.760076576065742
Validation loss: 3.586819759621996

Epoch: 5| Step: 9
Training loss: 3.276035779857754
Validation loss: 3.5860436776091587

Epoch: 5| Step: 10
Training loss: 2.558031419300096
Validation loss: 3.586481214576984

Epoch: 77| Step: 0
Training loss: 3.9277099730019582
Validation loss: 3.5859459216892304

Epoch: 5| Step: 1
Training loss: 3.612132418717725
Validation loss: 3.5872326221051987

Epoch: 5| Step: 2
Training loss: 4.03482488580742
Validation loss: 3.5853508699486643

Epoch: 5| Step: 3
Training loss: 4.627765550377181
Validation loss: 3.585413300279896

Epoch: 5| Step: 4
Training loss: 3.1064153799937193
Validation loss: 3.5853515392185624

Epoch: 5| Step: 5
Training loss: 3.0013709114882214
Validation loss: 3.5852516135515304

Epoch: 5| Step: 6
Training loss: 3.6135293411450813
Validation loss: 3.584554694940548

Epoch: 5| Step: 7
Training loss: 3.7000902835037826
Validation loss: 3.5842127859506903

Epoch: 5| Step: 8
Training loss: 3.9663672315486536
Validation loss: 3.5836525097864396

Epoch: 5| Step: 9
Training loss: 3.6487967663466887
Validation loss: 3.5839532662664095

Epoch: 5| Step: 10
Training loss: 4.219137216387731
Validation loss: 3.5836781457254605

Epoch: 78| Step: 0
Training loss: 3.2180440184034658
Validation loss: 3.5835790275674198

Epoch: 5| Step: 1
Training loss: 3.14692579756861
Validation loss: 3.583598487432177

Epoch: 5| Step: 2
Training loss: 4.1563718390711895
Validation loss: 3.583086234690288

Epoch: 5| Step: 3
Training loss: 3.2405606152163107
Validation loss: 3.582480081237322

Epoch: 5| Step: 4
Training loss: 4.138909671967374
Validation loss: 3.5824948054954113

Epoch: 5| Step: 5
Training loss: 3.040226181550536
Validation loss: 3.581990296286085

Epoch: 5| Step: 6
Training loss: 3.9507442738916914
Validation loss: 3.581555647913258

Epoch: 5| Step: 7
Training loss: 3.9769870853650815
Validation loss: 3.5831905657541077

Epoch: 5| Step: 8
Training loss: 4.270697738852018
Validation loss: 3.582637725548897

Epoch: 5| Step: 9
Training loss: 4.522318067375917
Validation loss: 3.583658176950039

Epoch: 5| Step: 10
Training loss: 3.6016934385515342
Validation loss: 3.581051885506105

Epoch: 79| Step: 0
Training loss: 3.4724088050726256
Validation loss: 3.5807617906741758

Epoch: 5| Step: 1
Training loss: 4.1561887349367375
Validation loss: 3.5802890158784337

Epoch: 5| Step: 2
Training loss: 4.017128510785779
Validation loss: 3.581401433429066

Epoch: 5| Step: 3
Training loss: 4.0116954531638545
Validation loss: 3.5803269315828725

Epoch: 5| Step: 4
Training loss: 3.3787692180034776
Validation loss: 3.5799762833593904

Epoch: 5| Step: 5
Training loss: 3.91103576463554
Validation loss: 3.579836008437508

Epoch: 5| Step: 6
Training loss: 4.276659878621075
Validation loss: 3.579517807569856

Epoch: 5| Step: 7
Training loss: 3.6693080289249105
Validation loss: 3.579508428239021

Epoch: 5| Step: 8
Training loss: 3.193741017905667
Validation loss: 3.5791110460411772

Epoch: 5| Step: 9
Training loss: 4.190324428625864
Validation loss: 3.5786307619105977

Epoch: 5| Step: 10
Training loss: 2.9838358606802493
Validation loss: 3.5787554891735036

Epoch: 80| Step: 0
Training loss: 4.180687216160189
Validation loss: 3.5784525492305645

Epoch: 5| Step: 1
Training loss: 3.976774258774192
Validation loss: 3.578718327620416

Epoch: 5| Step: 2
Training loss: 3.6949185248078558
Validation loss: 3.577794589008666

Epoch: 5| Step: 3
Training loss: 3.6975403213623763
Validation loss: 3.577683133440086

Epoch: 5| Step: 4
Training loss: 4.3015049629506485
Validation loss: 3.5773954756980313

Epoch: 5| Step: 5
Training loss: 2.0780509992918748
Validation loss: 3.5773324969608407

Epoch: 5| Step: 6
Training loss: 3.9130168439354884
Validation loss: 3.577311925185714

Epoch: 5| Step: 7
Training loss: 3.9017324952171437
Validation loss: 3.576876825141516

Epoch: 5| Step: 8
Training loss: 3.3335795947342715
Validation loss: 3.5767700148873987

Epoch: 5| Step: 9
Training loss: 3.7824596645425848
Validation loss: 3.5767043014479287

Epoch: 5| Step: 10
Training loss: 4.305611457598527
Validation loss: 3.5770818208226647

Epoch: 81| Step: 0
Training loss: 3.747878809863693
Validation loss: 3.5752252483249882

Epoch: 5| Step: 1
Training loss: 3.6113153171673233
Validation loss: 3.575844250207999

Epoch: 5| Step: 2
Training loss: 4.3066034224583625
Validation loss: 3.5755109755557446

Epoch: 5| Step: 3
Training loss: 3.355609007136686
Validation loss: 3.575256083081279

Epoch: 5| Step: 4
Training loss: 3.823114970345131
Validation loss: 3.5751589514794

Epoch: 5| Step: 5
Training loss: 4.5544450279852375
Validation loss: 3.575129654731374

Epoch: 5| Step: 6
Training loss: 4.239423719146151
Validation loss: 3.575328478676601

Epoch: 5| Step: 7
Training loss: 2.9470724417925074
Validation loss: 3.575715004932065

Epoch: 5| Step: 8
Training loss: 4.056658491775773
Validation loss: 3.57487219930492

Epoch: 5| Step: 9
Training loss: 3.145766874373445
Validation loss: 3.5746498856081432

Epoch: 5| Step: 10
Training loss: 3.3930436047248866
Validation loss: 3.574944972704696

Epoch: 82| Step: 0
Training loss: 3.9614321307668976
Validation loss: 3.574588664369635

Epoch: 5| Step: 1
Training loss: 4.303777969007991
Validation loss: 3.5742513428184925

Epoch: 5| Step: 2
Training loss: 3.5748411876909882
Validation loss: 3.5734704385325697

Epoch: 5| Step: 3
Training loss: 3.618954978500503
Validation loss: 3.573224363002397

Epoch: 5| Step: 4
Training loss: 3.523345472398512
Validation loss: 3.5729851944705686

Epoch: 5| Step: 5
Training loss: 4.042747484132416
Validation loss: 3.572828658355903

Epoch: 5| Step: 6
Training loss: 3.6272340664701286
Validation loss: 3.572727684969677

Epoch: 5| Step: 7
Training loss: 3.495217734609548
Validation loss: 3.5723547877402764

Epoch: 5| Step: 8
Training loss: 3.350773929757829
Validation loss: 3.572018471737308

Epoch: 5| Step: 9
Training loss: 4.16729736641002
Validation loss: 3.5713437893321984

Epoch: 5| Step: 10
Training loss: 3.7638223852559656
Validation loss: 3.5718966342012934

Epoch: 83| Step: 0
Training loss: 3.929873270607421
Validation loss: 3.5715125630430173

Epoch: 5| Step: 1
Training loss: 3.7614489940920706
Validation loss: 3.5714047503519293

Epoch: 5| Step: 2
Training loss: 4.328324406296009
Validation loss: 3.571333916196449

Epoch: 5| Step: 3
Training loss: 3.503994161296143
Validation loss: 3.570799355050822

Epoch: 5| Step: 4
Training loss: 3.173163692470634
Validation loss: 3.5721579139813797

Epoch: 5| Step: 5
Training loss: 3.9369218189866912
Validation loss: 3.569973078938421

Epoch: 5| Step: 6
Training loss: 3.994693335458975
Validation loss: 3.569903559271565

Epoch: 5| Step: 7
Training loss: 3.6627136220247047
Validation loss: 3.5699248042485308

Epoch: 5| Step: 8
Training loss: 3.9457255836499483
Validation loss: 3.5705594798440425

Epoch: 5| Step: 9
Training loss: 3.3500593322510053
Validation loss: 3.5696036249299956

Epoch: 5| Step: 10
Training loss: 3.806558701097024
Validation loss: 3.5693536406410855

Epoch: 84| Step: 0
Training loss: 3.6951555859919485
Validation loss: 3.568785945771

Epoch: 5| Step: 1
Training loss: 4.452875284253888
Validation loss: 3.568800858704755

Epoch: 5| Step: 2
Training loss: 3.050236652135897
Validation loss: 3.5679260752734265

Epoch: 5| Step: 3
Training loss: 3.812072479791868
Validation loss: 3.569300943228368

Epoch: 5| Step: 4
Training loss: 4.374497521018999
Validation loss: 3.5674497410803565

Epoch: 5| Step: 5
Training loss: 3.606378541767827
Validation loss: 3.567311033231123

Epoch: 5| Step: 6
Training loss: 3.722381997989008
Validation loss: 3.5670230407018533

Epoch: 5| Step: 7
Training loss: 3.758244670039183
Validation loss: 3.567141592150874

Epoch: 5| Step: 8
Training loss: 3.500118389852114
Validation loss: 3.5665532506284143

Epoch: 5| Step: 9
Training loss: 3.4304835062702157
Validation loss: 3.566442293403407

Epoch: 5| Step: 10
Training loss: 3.9138665978295006
Validation loss: 3.566419689224714

Epoch: 85| Step: 0
Training loss: 3.5959755018882795
Validation loss: 3.56592206196799

Epoch: 5| Step: 1
Training loss: 3.6719453845481542
Validation loss: 3.565322894554912

Epoch: 5| Step: 2
Training loss: 3.706081578253891
Validation loss: 3.5649814882879225

Epoch: 5| Step: 3
Training loss: 2.721399441331795
Validation loss: 3.564887903982408

Epoch: 5| Step: 4
Training loss: 4.30673185844407
Validation loss: 3.564531020435592

Epoch: 5| Step: 5
Training loss: 3.4358484635693434
Validation loss: 3.564877994269113

Epoch: 5| Step: 6
Training loss: 4.026052036576366
Validation loss: 3.5644554696698356

Epoch: 5| Step: 7
Training loss: 4.0765499420381985
Validation loss: 3.564003572230706

Epoch: 5| Step: 8
Training loss: 3.496875594533643
Validation loss: 3.5638372289515634

Epoch: 5| Step: 9
Training loss: 3.7959754411970184
Validation loss: 3.5635912435904076

Epoch: 5| Step: 10
Training loss: 4.463584208276461
Validation loss: 3.563744971324148

Epoch: 86| Step: 0
Training loss: 4.163548765286994
Validation loss: 3.5637193632046094

Epoch: 5| Step: 1
Training loss: 3.969761636914546
Validation loss: 3.5632162203516313

Epoch: 5| Step: 2
Training loss: 3.6022947150462707
Validation loss: 3.5626009005880372

Epoch: 5| Step: 3
Training loss: 3.942089857055655
Validation loss: 3.562552695828219

Epoch: 5| Step: 4
Training loss: 4.130414241678591
Validation loss: 3.5622279752893586

Epoch: 5| Step: 5
Training loss: 3.2075299004270854
Validation loss: 3.5620875685645124

Epoch: 5| Step: 6
Training loss: 4.11346209093206
Validation loss: 3.5619427961773353

Epoch: 5| Step: 7
Training loss: 3.2407922155339017
Validation loss: 3.5616676741369377

Epoch: 5| Step: 8
Training loss: 3.586836292930743
Validation loss: 3.56140273819079

Epoch: 5| Step: 9
Training loss: 3.4768809654874504
Validation loss: 3.561343621548721

Epoch: 5| Step: 10
Training loss: 3.8788208121333936
Validation loss: 3.5609130851050703

Epoch: 87| Step: 0
Training loss: 2.8082559565478666
Validation loss: 3.5608777488778194

Epoch: 5| Step: 1
Training loss: 4.170423848226045
Validation loss: 3.560685950027406

Epoch: 5| Step: 2
Training loss: 2.899373111711904
Validation loss: 3.5603693815699393

Epoch: 5| Step: 3
Training loss: 4.785007571032044
Validation loss: 3.560233528761544

Epoch: 5| Step: 4
Training loss: 3.2227963688762125
Validation loss: 3.559573410845094

Epoch: 5| Step: 5
Training loss: 3.7248730938690633
Validation loss: 3.559826846629449

Epoch: 5| Step: 6
Training loss: 3.7182698941657497
Validation loss: 3.5594007089219337

Epoch: 5| Step: 7
Training loss: 4.295014245539212
Validation loss: 3.5593740655184285

Epoch: 5| Step: 8
Training loss: 3.8380235644119547
Validation loss: 3.559027867524374

Epoch: 5| Step: 9
Training loss: 2.922665086297956
Validation loss: 3.5587722230900853

Epoch: 5| Step: 10
Training loss: 4.5464544462268845
Validation loss: 3.5582861756546733

Epoch: 88| Step: 0
Training loss: 3.5527052498033074
Validation loss: 3.55835597560436

Epoch: 5| Step: 1
Training loss: 2.9444033082051835
Validation loss: 3.558142366813541

Epoch: 5| Step: 2
Training loss: 3.9406706139558674
Validation loss: 3.5576826712557756

Epoch: 5| Step: 3
Training loss: 3.834792951144744
Validation loss: 3.557614508285523

Epoch: 5| Step: 4
Training loss: 3.825112165414621
Validation loss: 3.5571918992742653

Epoch: 5| Step: 5
Training loss: 3.819584751827298
Validation loss: 3.557063907793473

Epoch: 5| Step: 6
Training loss: 4.539231000126538
Validation loss: 3.556841330081991

Epoch: 5| Step: 7
Training loss: 4.114413229729798
Validation loss: 3.5564858952985205

Epoch: 5| Step: 8
Training loss: 3.54858478222009
Validation loss: 3.5562243421196924

Epoch: 5| Step: 9
Training loss: 3.586977340426736
Validation loss: 3.555824467390253

Epoch: 5| Step: 10
Training loss: 3.4348285351287715
Validation loss: 3.5557110282552484

Epoch: 89| Step: 0
Training loss: 3.845595498271773
Validation loss: 3.555152482041388

Epoch: 5| Step: 1
Training loss: 3.50864650267902
Validation loss: 3.555361629706403

Epoch: 5| Step: 2
Training loss: 4.125293836820876
Validation loss: 3.5550350408311373

Epoch: 5| Step: 3
Training loss: 3.9266379565067484
Validation loss: 3.5554827835748055

Epoch: 5| Step: 4
Training loss: 2.9682028818425334
Validation loss: 3.554312652400719

Epoch: 5| Step: 5
Training loss: 3.65479177755955
Validation loss: 3.554221934910061

Epoch: 5| Step: 6
Training loss: 3.416756900123065
Validation loss: 3.554065650043256

Epoch: 5| Step: 7
Training loss: 4.53861852894084
Validation loss: 3.5546610823457265

Epoch: 5| Step: 8
Training loss: 3.709439716240561
Validation loss: 3.5540461770680754

Epoch: 5| Step: 9
Training loss: 3.9110631967509155
Validation loss: 3.5537568484269966

Epoch: 5| Step: 10
Training loss: 3.5202444964806694
Validation loss: 3.5534461052423

Epoch: 90| Step: 0
Training loss: 2.9267084463116433
Validation loss: 3.553446861323867

Epoch: 5| Step: 1
Training loss: 4.400072894793015
Validation loss: 3.5525647726867633

Epoch: 5| Step: 2
Training loss: 4.511989727387334
Validation loss: 3.552613608002943

Epoch: 5| Step: 3
Training loss: 4.173205445699576
Validation loss: 3.5520627187760345

Epoch: 5| Step: 4
Training loss: 3.80013446068037
Validation loss: 3.553412926954955

Epoch: 5| Step: 5
Training loss: 3.791114110124343
Validation loss: 3.552087853758144

Epoch: 5| Step: 6
Training loss: 3.414330932399843
Validation loss: 3.5517444578258597

Epoch: 5| Step: 7
Training loss: 3.6282008278978433
Validation loss: 3.5515745483804455

Epoch: 5| Step: 8
Training loss: 3.2961851727125495
Validation loss: 3.5510749996368682

Epoch: 5| Step: 9
Training loss: 3.320428392968231
Validation loss: 3.551135189625237

Epoch: 5| Step: 10
Training loss: 3.784306575493616
Validation loss: 3.5511254003569963

Epoch: 91| Step: 0
Training loss: 4.1988610403602165
Validation loss: 3.55037110229188

Epoch: 5| Step: 1
Training loss: 4.49434603371302
Validation loss: 3.5504506771527535

Epoch: 5| Step: 2
Training loss: 4.1224530766895136
Validation loss: 3.550735840656596

Epoch: 5| Step: 3
Training loss: 3.823775455705622
Validation loss: 3.5498718276132415

Epoch: 5| Step: 4
Training loss: 3.5445219460613924
Validation loss: 3.5495568052096327

Epoch: 5| Step: 5
Training loss: 3.475405245417151
Validation loss: 3.550496894508435

Epoch: 5| Step: 6
Training loss: 3.6833965940494617
Validation loss: 3.549452111732268

Epoch: 5| Step: 7
Training loss: 3.524471562593778
Validation loss: 3.5488875169426874

Epoch: 5| Step: 8
Training loss: 3.224390217700236
Validation loss: 3.5488213085142712

Epoch: 5| Step: 9
Training loss: 3.641454381160198
Validation loss: 3.54859726018692

Epoch: 5| Step: 10
Training loss: 3.3459865897594536
Validation loss: 3.548665337733245

Epoch: 92| Step: 0
Training loss: 3.7178048607730996
Validation loss: 3.5479297313816107

Epoch: 5| Step: 1
Training loss: 3.247580875038679
Validation loss: 3.5478658596289856

Epoch: 5| Step: 2
Training loss: 4.662048825277099
Validation loss: 3.5475088144716485

Epoch: 5| Step: 3
Training loss: 2.826201822982955
Validation loss: 3.5472871043076672

Epoch: 5| Step: 4
Training loss: 4.172180850358203
Validation loss: 3.5470030888282693

Epoch: 5| Step: 5
Training loss: 4.2020235000962725
Validation loss: 3.546842315351209

Epoch: 5| Step: 6
Training loss: 3.704414497269187
Validation loss: 3.546518466628657

Epoch: 5| Step: 7
Training loss: 3.835661029369848
Validation loss: 3.5465687803035295

Epoch: 5| Step: 8
Training loss: 3.4258177177897924
Validation loss: 3.545754962044106

Epoch: 5| Step: 9
Training loss: 3.9211466443464884
Validation loss: 3.5455810751164396

Epoch: 5| Step: 10
Training loss: 3.1356325465980794
Validation loss: 3.5456210235322767

Epoch: 93| Step: 0
Training loss: 3.1548685506530085
Validation loss: 3.5455984210992564

Epoch: 5| Step: 1
Training loss: 3.207926802867951
Validation loss: 3.544851282589171

Epoch: 5| Step: 2
Training loss: 4.082779256376571
Validation loss: 3.5450836452987557

Epoch: 5| Step: 3
Training loss: 3.8594932383599017
Validation loss: 3.5447596749582413

Epoch: 5| Step: 4
Training loss: 4.71369370132771
Validation loss: 3.544824581900995

Epoch: 5| Step: 5
Training loss: 3.6462832509310776
Validation loss: 3.5442663410334276

Epoch: 5| Step: 6
Training loss: 4.306235144247665
Validation loss: 3.5440477034240816

Epoch: 5| Step: 7
Training loss: 4.407557516691013
Validation loss: 3.5442410247241924

Epoch: 5| Step: 8
Training loss: 3.1766997225610316
Validation loss: 3.543372235897874

Epoch: 5| Step: 9
Training loss: 2.9278868164115903
Validation loss: 3.5435633447995416

Epoch: 5| Step: 10
Training loss: 3.2394942162001823
Validation loss: 3.543476763906896

Epoch: 94| Step: 0
Training loss: 4.536338527190885
Validation loss: 3.5425719178573116

Epoch: 5| Step: 1
Training loss: 3.8791213729841933
Validation loss: 3.5428239619345927

Epoch: 5| Step: 2
Training loss: 2.994332045515946
Validation loss: 3.5422312644185387

Epoch: 5| Step: 3
Training loss: 3.8344319607484088
Validation loss: 3.5425119818430826

Epoch: 5| Step: 4
Training loss: 3.3666928098311915
Validation loss: 3.5425489761075117

Epoch: 5| Step: 5
Training loss: 3.855738853570557
Validation loss: 3.5418256175054097

Epoch: 5| Step: 6
Training loss: 3.673444826288353
Validation loss: 3.5416713176506143

Epoch: 5| Step: 7
Training loss: 2.8538143933684395
Validation loss: 3.5416518995832527

Epoch: 5| Step: 8
Training loss: 3.8696915967417924
Validation loss: 3.5426430550077628

Epoch: 5| Step: 9
Training loss: 4.130734012947066
Validation loss: 3.542228997676353

Epoch: 5| Step: 10
Training loss: 3.9837006839779474
Validation loss: 3.543876244372753

Epoch: 95| Step: 0
Training loss: 3.5346390656734616
Validation loss: 3.5433704343748107

Epoch: 5| Step: 1
Training loss: 3.0916884518358785
Validation loss: 3.5399399405616694

Epoch: 5| Step: 2
Training loss: 4.468969806520491
Validation loss: 3.539715797948845

Epoch: 5| Step: 3
Training loss: 3.8213485841821675
Validation loss: 3.5397687344643423

Epoch: 5| Step: 4
Training loss: 4.149982057096
Validation loss: 3.5401071496511203

Epoch: 5| Step: 5
Training loss: 3.6698722409662503
Validation loss: 3.5406774805542365

Epoch: 5| Step: 6
Training loss: 3.2992102862933113
Validation loss: 3.5393546074270774

Epoch: 5| Step: 7
Training loss: 3.331035362328507
Validation loss: 3.5397262691458566

Epoch: 5| Step: 8
Training loss: 4.111082005326165
Validation loss: 3.538802113450611

Epoch: 5| Step: 9
Training loss: 3.131464413670459
Validation loss: 3.539057107680585

Epoch: 5| Step: 10
Training loss: 4.4016619664641
Validation loss: 3.537383282049549

Epoch: 96| Step: 0
Training loss: 4.054204364430147
Validation loss: 3.53820944649213

Epoch: 5| Step: 1
Training loss: 3.9074480584634577
Validation loss: 3.5386666251237413

Epoch: 5| Step: 2
Training loss: 2.981632910235827
Validation loss: 3.5372103461309563

Epoch: 5| Step: 3
Training loss: 3.970556854090794
Validation loss: 3.5366764813530405

Epoch: 5| Step: 4
Training loss: 3.9373246411224265
Validation loss: 3.536482357985188

Epoch: 5| Step: 5
Training loss: 4.104885651532598
Validation loss: 3.538171182337314

Epoch: 5| Step: 6
Training loss: 3.7654665838452446
Validation loss: 3.5372082109773033

Epoch: 5| Step: 7
Training loss: 3.427395204462602
Validation loss: 3.5359884318367283

Epoch: 5| Step: 8
Training loss: 4.031338476348602
Validation loss: 3.538346124616006

Epoch: 5| Step: 9
Training loss: 3.7811757230162732
Validation loss: 3.537130677790122

Epoch: 5| Step: 10
Training loss: 2.8915308177452825
Validation loss: 3.5376073796850247

Epoch: 97| Step: 0
Training loss: 3.3338146021233044
Validation loss: 3.536145689647005

Epoch: 5| Step: 1
Training loss: 3.905156707354595
Validation loss: 3.5375371413522427

Epoch: 5| Step: 2
Training loss: 3.3577678295801334
Validation loss: 3.5387312091532745

Epoch: 5| Step: 3
Training loss: 3.439171124778861
Validation loss: 3.5384420395972134

Epoch: 5| Step: 4
Training loss: 3.762645508243253
Validation loss: 3.5353329571003096

Epoch: 5| Step: 5
Training loss: 3.8512205393802543
Validation loss: 3.5337083052979046

Epoch: 5| Step: 6
Training loss: 3.7193303016075427
Validation loss: 3.533806822885686

Epoch: 5| Step: 7
Training loss: 3.7235879922886097
Validation loss: 3.5340610038303364

Epoch: 5| Step: 8
Training loss: 3.999288137988652
Validation loss: 3.5340852788429906

Epoch: 5| Step: 9
Training loss: 4.215946424487672
Validation loss: 3.5335873233530255

Epoch: 5| Step: 10
Training loss: 3.7996535946412298
Validation loss: 3.534279819666067

Epoch: 98| Step: 0
Training loss: 3.6212151598612294
Validation loss: 3.535654528336805

Epoch: 5| Step: 1
Training loss: 3.7047155642240877
Validation loss: 3.5360941546779023

Epoch: 5| Step: 2
Training loss: 3.715623069871765
Validation loss: 3.533337567613804

Epoch: 5| Step: 3
Training loss: 3.8751646437584237
Validation loss: 3.5327733302674917

Epoch: 5| Step: 4
Training loss: 3.6447387505406175
Validation loss: 3.5329981672982558

Epoch: 5| Step: 5
Training loss: 3.389404639793818
Validation loss: 3.533086213842263

Epoch: 5| Step: 6
Training loss: 4.804591232203769
Validation loss: 3.532455150117867

Epoch: 5| Step: 7
Training loss: 3.246367552005602
Validation loss: 3.5321742692306377

Epoch: 5| Step: 8
Training loss: 3.8664598184922516
Validation loss: 3.532141830321351

Epoch: 5| Step: 9
Training loss: 3.51201922835906
Validation loss: 3.532537035756966

Epoch: 5| Step: 10
Training loss: 3.5555318311721003
Validation loss: 3.5329909821274224

Epoch: 99| Step: 0
Training loss: 3.4247769805248645
Validation loss: 3.533454278914089

Epoch: 5| Step: 1
Training loss: 3.4996769619774626
Validation loss: 3.533775236152816

Epoch: 5| Step: 2
Training loss: 3.4394949932680263
Validation loss: 3.5319830325753645

Epoch: 5| Step: 3
Training loss: 4.117859642567807
Validation loss: 3.5304399672594378

Epoch: 5| Step: 4
Training loss: 4.629923699823413
Validation loss: 3.529602719244819

Epoch: 5| Step: 5
Training loss: 3.292017970271328
Validation loss: 3.5299787208598783

Epoch: 5| Step: 6
Training loss: 3.4302688835785835
Validation loss: 3.528782831992689

Epoch: 5| Step: 7
Training loss: 3.2595088942210833
Validation loss: 3.528746207771665

Epoch: 5| Step: 8
Training loss: 4.211839908307058
Validation loss: 3.528343407799555

Epoch: 5| Step: 9
Training loss: 3.3985964683096372
Validation loss: 3.5290536753854624

Epoch: 5| Step: 10
Training loss: 4.211049150957779
Validation loss: 3.528919485831682

Epoch: 100| Step: 0
Training loss: 3.358538004378612
Validation loss: 3.5286331869754757

Epoch: 5| Step: 1
Training loss: 4.170287784004363
Validation loss: 3.5280418665881506

Epoch: 5| Step: 2
Training loss: 3.647867358339402
Validation loss: 3.5281408897295026

Epoch: 5| Step: 3
Training loss: 3.5393440858762997
Validation loss: 3.5289611367974763

Epoch: 5| Step: 4
Training loss: 3.458121297073519
Validation loss: 3.5272034068309353

Epoch: 5| Step: 5
Training loss: 2.6751812561516988
Validation loss: 3.5283574628276377

Epoch: 5| Step: 6
Training loss: 3.457616172488271
Validation loss: 3.5266509544909135

Epoch: 5| Step: 7
Training loss: 4.519396411463615
Validation loss: 3.526089640122418

Epoch: 5| Step: 8
Training loss: 3.4034798933623045
Validation loss: 3.527338348487377

Epoch: 5| Step: 9
Training loss: 4.1934749052552895
Validation loss: 3.527693688178482

Epoch: 5| Step: 10
Training loss: 4.402424985039651
Validation loss: 3.5265152508465243

Epoch: 101| Step: 0
Training loss: 3.8963392340605925
Validation loss: 3.527475042296638

Epoch: 5| Step: 1
Training loss: 4.167753662737485
Validation loss: 3.5261114282653874

Epoch: 5| Step: 2
Training loss: 3.54916684219588
Validation loss: 3.525948608661417

Epoch: 5| Step: 3
Training loss: 3.5388186204429233
Validation loss: 3.525579075029859

Epoch: 5| Step: 4
Training loss: 4.382505463913919
Validation loss: 3.526222609096717

Epoch: 5| Step: 5
Training loss: 4.405982259637596
Validation loss: 3.5276848396416516

Epoch: 5| Step: 6
Training loss: 3.371473660063642
Validation loss: 3.5290578037333282

Epoch: 5| Step: 7
Training loss: 3.094172747464159
Validation loss: 3.5313375601737786

Epoch: 5| Step: 8
Training loss: 4.020114392982619
Validation loss: 3.534155183912594

Epoch: 5| Step: 9
Training loss: 3.329919322414076
Validation loss: 3.527574925824963

Epoch: 5| Step: 10
Training loss: 2.877014449554318
Validation loss: 3.5281217401629825

Epoch: 102| Step: 0
Training loss: 3.753303979676437
Validation loss: 3.522476724862594

Epoch: 5| Step: 1
Training loss: 4.4718429425661315
Validation loss: 3.5242792154631757

Epoch: 5| Step: 2
Training loss: 3.4507985282812563
Validation loss: 3.5226288219818125

Epoch: 5| Step: 3
Training loss: 3.337465744699996
Validation loss: 3.5226248221914163

Epoch: 5| Step: 4
Training loss: 3.565830748336389
Validation loss: 3.5223800942068078

Epoch: 5| Step: 5
Training loss: 3.9733604024652003
Validation loss: 3.52244670465017

Epoch: 5| Step: 6
Training loss: 2.943841946536696
Validation loss: 3.522952574524502

Epoch: 5| Step: 7
Training loss: 3.739356258089693
Validation loss: 3.52269600992173

Epoch: 5| Step: 8
Training loss: 3.292087061309023
Validation loss: 3.522190421998745

Epoch: 5| Step: 9
Training loss: 4.294729133919883
Validation loss: 3.521847424447092

Epoch: 5| Step: 10
Training loss: 4.025332106637363
Validation loss: 3.5217532326097567

Epoch: 103| Step: 0
Training loss: 3.7250310602109256
Validation loss: 3.5216575633979623

Epoch: 5| Step: 1
Training loss: 3.6791398274590104
Validation loss: 3.5207953662479294

Epoch: 5| Step: 2
Training loss: 4.319594366668439
Validation loss: 3.5204205786518634

Epoch: 5| Step: 3
Training loss: 3.7951364814833655
Validation loss: 3.5209095881044536

Epoch: 5| Step: 4
Training loss: 3.654401393355991
Validation loss: 3.5205908949923264

Epoch: 5| Step: 5
Training loss: 3.6481032943406633
Validation loss: 3.519818780103882

Epoch: 5| Step: 6
Training loss: 2.8656881710232325
Validation loss: 3.5194542408299654

Epoch: 5| Step: 7
Training loss: 3.9110751449010155
Validation loss: 3.5186547339045173

Epoch: 5| Step: 8
Training loss: 4.169197280428784
Validation loss: 3.5183286185172347

Epoch: 5| Step: 9
Training loss: 2.9302196782273677
Validation loss: 3.5176584081642672

Epoch: 5| Step: 10
Training loss: 4.138740542581595
Validation loss: 3.5182210152287965

Epoch: 104| Step: 0
Training loss: 3.6601746191257973
Validation loss: 3.5168496113519554

Epoch: 5| Step: 1
Training loss: 4.315983346788523
Validation loss: 3.5189302275065586

Epoch: 5| Step: 2
Training loss: 3.5645685715465376
Validation loss: 3.5172733897020714

Epoch: 5| Step: 3
Training loss: 3.309854134517814
Validation loss: 3.5174046001754284

Epoch: 5| Step: 4
Training loss: 3.445090358086188
Validation loss: 3.518435185316393

Epoch: 5| Step: 5
Training loss: 3.7898851897632615
Validation loss: 3.5203246634904732

Epoch: 5| Step: 6
Training loss: 3.412671956072066
Validation loss: 3.5206702633237725

Epoch: 5| Step: 7
Training loss: 3.7512782143660246
Validation loss: 3.5183514019648716

Epoch: 5| Step: 8
Training loss: 3.804504264790048
Validation loss: 3.5166930492534925

Epoch: 5| Step: 9
Training loss: 3.840304435344668
Validation loss: 3.517206507809411

Epoch: 5| Step: 10
Training loss: 4.067147985230516
Validation loss: 3.515358710373108

Epoch: 105| Step: 0
Training loss: 3.177698361427765
Validation loss: 3.515979915009066

Epoch: 5| Step: 1
Training loss: 3.7189428455774736
Validation loss: 3.5161464772013225

Epoch: 5| Step: 2
Training loss: 3.3107699788853315
Validation loss: 3.5161835272153152

Epoch: 5| Step: 3
Training loss: 4.550741432899844
Validation loss: 3.515904684483745

Epoch: 5| Step: 4
Training loss: 3.300290187445658
Validation loss: 3.5152345341611997

Epoch: 5| Step: 5
Training loss: 4.555275200278086
Validation loss: 3.5152372442179076

Epoch: 5| Step: 6
Training loss: 2.721999057609849
Validation loss: 3.514816706814352

Epoch: 5| Step: 7
Training loss: 3.6861080840104017
Validation loss: 3.5148137819951986

Epoch: 5| Step: 8
Training loss: 4.173800477724881
Validation loss: 3.5150334313299605

Epoch: 5| Step: 9
Training loss: 3.77864123431118
Validation loss: 3.51455083591395

Epoch: 5| Step: 10
Training loss: 3.570548218806841
Validation loss: 3.516485601208876

Epoch: 106| Step: 0
Training loss: 3.94765482951006
Validation loss: 3.514738046566187

Epoch: 5| Step: 1
Training loss: 3.971264020386544
Validation loss: 3.5139826919435055

Epoch: 5| Step: 2
Training loss: 3.6953690183805508
Validation loss: 3.513729850022026

Epoch: 5| Step: 3
Training loss: 3.7970759334692334
Validation loss: 3.513434644610856

Epoch: 5| Step: 4
Training loss: 3.7042221826112716
Validation loss: 3.512961388051122

Epoch: 5| Step: 5
Training loss: 3.722597455964428
Validation loss: 3.514756029082581

Epoch: 5| Step: 6
Training loss: 3.2515469317450765
Validation loss: 3.5115872942225055

Epoch: 5| Step: 7
Training loss: 3.510813629314822
Validation loss: 3.512134179436168

Epoch: 5| Step: 8
Training loss: 3.383679426434553
Validation loss: 3.5119438268531806

Epoch: 5| Step: 9
Training loss: 3.7517439283981604
Validation loss: 3.5113961709500745

Epoch: 5| Step: 10
Training loss: 4.226711193014644
Validation loss: 3.511090449331285

Epoch: 107| Step: 0
Training loss: 3.8177496615987927
Validation loss: 3.511184798707012

Epoch: 5| Step: 1
Training loss: 3.616622847776511
Validation loss: 3.5107773799097344

Epoch: 5| Step: 2
Training loss: 4.0623549215381125
Validation loss: 3.510173456289392

Epoch: 5| Step: 3
Training loss: 2.6489035947371558
Validation loss: 3.5106099685511625

Epoch: 5| Step: 4
Training loss: 4.1367620910737095
Validation loss: 3.50949158299046

Epoch: 5| Step: 5
Training loss: 3.4729407486808146
Validation loss: 3.5089058947787573

Epoch: 5| Step: 6
Training loss: 4.28692317897198
Validation loss: 3.509413488597394

Epoch: 5| Step: 7
Training loss: 2.330747113434018
Validation loss: 3.5090405625556214

Epoch: 5| Step: 8
Training loss: 3.859118371995063
Validation loss: 3.509038201314942

Epoch: 5| Step: 9
Training loss: 3.9703773105920748
Validation loss: 3.508294473168378

Epoch: 5| Step: 10
Training loss: 4.278472890704025
Validation loss: 3.5075982674703456

Epoch: 108| Step: 0
Training loss: 4.445954556348306
Validation loss: 3.505417356591519

Epoch: 5| Step: 1
Training loss: 3.415461412929153
Validation loss: 3.5079556330500727

Epoch: 5| Step: 2
Training loss: 3.519630151305324
Validation loss: 3.5068032656661736

Epoch: 5| Step: 3
Training loss: 3.5310866056466454
Validation loss: 3.5065960367481543

Epoch: 5| Step: 4
Training loss: 3.097941324169657
Validation loss: 3.508377681205676

Epoch: 5| Step: 5
Training loss: 3.3384704264847374
Validation loss: 3.5061119816490844

Epoch: 5| Step: 6
Training loss: 2.891720620860336
Validation loss: 3.5048630384704094

Epoch: 5| Step: 7
Training loss: 4.068497441623273
Validation loss: 3.504933979862095

Epoch: 5| Step: 8
Training loss: 3.67871314105157
Validation loss: 3.5069556975058074

Epoch: 5| Step: 9
Training loss: 4.69424949456894
Validation loss: 3.5114223789482564

Epoch: 5| Step: 10
Training loss: 3.838337879473608
Validation loss: 3.5094978374210646

Epoch: 109| Step: 0
Training loss: 4.0061502857861795
Validation loss: 3.507904775780564

Epoch: 5| Step: 1
Training loss: 3.6446624764943487
Validation loss: 3.504406376125578

Epoch: 5| Step: 2
Training loss: 3.2723923063808154
Validation loss: 3.5021678887828878

Epoch: 5| Step: 3
Training loss: 3.701744627105138
Validation loss: 3.50405529901136

Epoch: 5| Step: 4
Training loss: 3.896698894666587
Validation loss: 3.503075009161355

Epoch: 5| Step: 5
Training loss: 3.4740801574911635
Validation loss: 3.5042256703911483

Epoch: 5| Step: 6
Training loss: 3.8928353645245477
Validation loss: 3.5045220246027475

Epoch: 5| Step: 7
Training loss: 3.299652231560648
Validation loss: 3.5045643693231536

Epoch: 5| Step: 8
Training loss: 4.121065980356676
Validation loss: 3.502751050032197

Epoch: 5| Step: 9
Training loss: 3.455546776970619
Validation loss: 3.5097140248032765

Epoch: 5| Step: 10
Training loss: 4.052476460166681
Validation loss: 3.504575950646023

Epoch: 110| Step: 0
Training loss: 3.824952099070087
Validation loss: 3.5019446213779597

Epoch: 5| Step: 1
Training loss: 3.5874239763983833
Validation loss: 3.4998784857193015

Epoch: 5| Step: 2
Training loss: 3.5003739565935716
Validation loss: 3.5010651434084554

Epoch: 5| Step: 3
Training loss: 3.910190029550956
Validation loss: 3.500710867840971

Epoch: 5| Step: 4
Training loss: 3.62017316751801
Validation loss: 3.501567577429708

Epoch: 5| Step: 5
Training loss: 4.363712900747638
Validation loss: 3.5011962715505796

Epoch: 5| Step: 6
Training loss: 3.6133527758967925
Validation loss: 3.500112438007292

Epoch: 5| Step: 7
Training loss: 3.442729232347607
Validation loss: 3.4998383858279696

Epoch: 5| Step: 8
Training loss: 3.3959172868394742
Validation loss: 3.5000020714210205

Epoch: 5| Step: 9
Training loss: 3.9361238042542555
Validation loss: 3.4992242955531334

Epoch: 5| Step: 10
Training loss: 3.5086893120040403
Validation loss: 3.5004749268860995

Epoch: 111| Step: 0
Training loss: 3.5189903597275554
Validation loss: 3.499643124494172

Epoch: 5| Step: 1
Training loss: 3.2787991044282823
Validation loss: 3.4982959536818106

Epoch: 5| Step: 2
Training loss: 4.559078658201668
Validation loss: 3.499949529609149

Epoch: 5| Step: 3
Training loss: 3.188846827180515
Validation loss: 3.4989829717261727

Epoch: 5| Step: 4
Training loss: 3.249522394152731
Validation loss: 3.498540231082623

Epoch: 5| Step: 5
Training loss: 3.957842880114353
Validation loss: 3.499143655381183

Epoch: 5| Step: 6
Training loss: 3.637959695719658
Validation loss: 3.4979008431336207

Epoch: 5| Step: 7
Training loss: 3.4993375423747897
Validation loss: 3.4979947699372027

Epoch: 5| Step: 8
Training loss: 3.6813151329508944
Validation loss: 3.497157996850619

Epoch: 5| Step: 9
Training loss: 4.428158450757453
Validation loss: 3.4972047542923224

Epoch: 5| Step: 10
Training loss: 3.518120316695286
Validation loss: 3.496515033285107

Epoch: 112| Step: 0
Training loss: 3.9748139199901376
Validation loss: 3.4959890100937105

Epoch: 5| Step: 1
Training loss: 4.09610453445438
Validation loss: 3.496323915394822

Epoch: 5| Step: 2
Training loss: 4.289284399855272
Validation loss: 3.495969951337649

Epoch: 5| Step: 3
Training loss: 2.8163229497476654
Validation loss: 3.495824564588461

Epoch: 5| Step: 4
Training loss: 4.084826812621476
Validation loss: 3.4969097535093123

Epoch: 5| Step: 5
Training loss: 2.6392376206398476
Validation loss: 3.495647973918308

Epoch: 5| Step: 6
Training loss: 3.675402825524109
Validation loss: 3.494680248319727

Epoch: 5| Step: 7
Training loss: 3.3104631891616667
Validation loss: 3.4947346871456704

Epoch: 5| Step: 8
Training loss: 3.5350325589117166
Validation loss: 3.4943902168840073

Epoch: 5| Step: 9
Training loss: 4.294677616405849
Validation loss: 3.49293494541114

Epoch: 5| Step: 10
Training loss: 3.6479167689147856
Validation loss: 3.4941940127909836

Epoch: 113| Step: 0
Training loss: 3.650564353894985
Validation loss: 3.494765651096164

Epoch: 5| Step: 1
Training loss: 3.264088246274566
Validation loss: 3.49347610522707

Epoch: 5| Step: 2
Training loss: 3.2688285045058754
Validation loss: 3.493082118427574

Epoch: 5| Step: 3
Training loss: 4.466478957791641
Validation loss: 3.494171804050322

Epoch: 5| Step: 4
Training loss: 3.6759365263845756
Validation loss: 3.4933962628923463

Epoch: 5| Step: 5
Training loss: 3.77787390443262
Validation loss: 3.493921530325147

Epoch: 5| Step: 6
Training loss: 3.4256053083383127
Validation loss: 3.493975264116639

Epoch: 5| Step: 7
Training loss: 3.7473676979576327
Validation loss: 3.493499925481973

Epoch: 5| Step: 8
Training loss: 2.9730622143438046
Validation loss: 3.4915180312010294

Epoch: 5| Step: 9
Training loss: 4.199256222579896
Validation loss: 3.4906905559048944

Epoch: 5| Step: 10
Training loss: 4.122393160072306
Validation loss: 3.4909099077043235

Epoch: 114| Step: 0
Training loss: 4.125309325671313
Validation loss: 3.4912651601995575

Epoch: 5| Step: 1
Training loss: 3.941021752104589
Validation loss: 3.493152738371383

Epoch: 5| Step: 2
Training loss: 3.5962060911211546
Validation loss: 3.492629812798628

Epoch: 5| Step: 3
Training loss: 2.932225137953011
Validation loss: 3.491772597500454

Epoch: 5| Step: 4
Training loss: 4.343100080650557
Validation loss: 3.491743692138847

Epoch: 5| Step: 5
Training loss: 3.232867788115841
Validation loss: 3.4906967397343363

Epoch: 5| Step: 6
Training loss: 3.2842787070636055
Validation loss: 3.491548916478372

Epoch: 5| Step: 7
Training loss: 3.8823785980757193
Validation loss: 3.491388212247191

Epoch: 5| Step: 8
Training loss: 3.776355949564673
Validation loss: 3.4919102944537403

Epoch: 5| Step: 9
Training loss: 3.4106637898190164
Validation loss: 3.4907902126371004

Epoch: 5| Step: 10
Training loss: 4.016964937482024
Validation loss: 3.4908781502018833

Epoch: 115| Step: 0
Training loss: 3.6805737636923497
Validation loss: 3.489209343906066

Epoch: 5| Step: 1
Training loss: 4.117340142969156
Validation loss: 3.4887991281026394

Epoch: 5| Step: 2
Training loss: 4.080008236371871
Validation loss: 3.4874203252995652

Epoch: 5| Step: 3
Training loss: 4.004462137478396
Validation loss: 3.48831005617595

Epoch: 5| Step: 4
Training loss: 4.027769493591442
Validation loss: 3.48846952061676

Epoch: 5| Step: 5
Training loss: 4.005787953410109
Validation loss: 3.488276996225725

Epoch: 5| Step: 6
Training loss: 3.326126286479273
Validation loss: 3.487742835876305

Epoch: 5| Step: 7
Training loss: 2.248862614846741
Validation loss: 3.488022964179636

Epoch: 5| Step: 8
Training loss: 3.753987544645235
Validation loss: 3.487898745282897

Epoch: 5| Step: 9
Training loss: 3.072052207950181
Validation loss: 3.4872341623209104

Epoch: 5| Step: 10
Training loss: 3.9895975031323037
Validation loss: 3.4872495533899937

Epoch: 116| Step: 0
Training loss: 4.450819415825589
Validation loss: 3.4855797894441225

Epoch: 5| Step: 1
Training loss: 4.158833324720136
Validation loss: 3.4856789377193578

Epoch: 5| Step: 2
Training loss: 3.2267503291178885
Validation loss: 3.485580038042794

Epoch: 5| Step: 3
Training loss: 3.410091229110584
Validation loss: 3.484893492436765

Epoch: 5| Step: 4
Training loss: 3.2799476582142284
Validation loss: 3.485303947261328

Epoch: 5| Step: 5
Training loss: 3.6302357713199696
Validation loss: 3.485880602931487

Epoch: 5| Step: 6
Training loss: 3.737097988388436
Validation loss: 3.4854228009908423

Epoch: 5| Step: 7
Training loss: 3.9248966567897674
Validation loss: 3.486185893878458

Epoch: 5| Step: 8
Training loss: 4.134243405555235
Validation loss: 3.4848288772915312

Epoch: 5| Step: 9
Training loss: 3.3929692615541147
Validation loss: 3.4859956437506696

Epoch: 5| Step: 10
Training loss: 2.946835880282827
Validation loss: 3.4877107658067974

Epoch: 117| Step: 0
Training loss: 3.8259151386235972
Validation loss: 3.490371938731791

Epoch: 5| Step: 1
Training loss: 4.410844720397776
Validation loss: 3.4868194997633752

Epoch: 5| Step: 2
Training loss: 3.5509321896205233
Validation loss: 3.483213379950407

Epoch: 5| Step: 3
Training loss: 3.580924592205007
Validation loss: 3.483530879749673

Epoch: 5| Step: 4
Training loss: 3.836553271684068
Validation loss: 3.4843617196264307

Epoch: 5| Step: 5
Training loss: 3.9488831933125432
Validation loss: 3.4845302449163604

Epoch: 5| Step: 6
Training loss: 2.8038404455405574
Validation loss: 3.4826809648803745

Epoch: 5| Step: 7
Training loss: 3.375765960807051
Validation loss: 3.484484722643437

Epoch: 5| Step: 8
Training loss: 4.079259721878473
Validation loss: 3.4832620777021805

Epoch: 5| Step: 9
Training loss: 3.168812744000972
Validation loss: 3.4845871391962806

Epoch: 5| Step: 10
Training loss: 3.883100349302591
Validation loss: 3.4822641169389192

Epoch: 118| Step: 0
Training loss: 3.2667543931456984
Validation loss: 3.4813588598207517

Epoch: 5| Step: 1
Training loss: 4.009366275245647
Validation loss: 3.4810644294917785

Epoch: 5| Step: 2
Training loss: 3.7160774693374834
Validation loss: 3.48078983212877

Epoch: 5| Step: 3
Training loss: 3.6814191432882697
Validation loss: 3.4807242378248

Epoch: 5| Step: 4
Training loss: 3.921464511012794
Validation loss: 3.481206890480035

Epoch: 5| Step: 5
Training loss: 4.048050521912257
Validation loss: 3.4799216364216488

Epoch: 5| Step: 6
Training loss: 3.7401673154073216
Validation loss: 3.4798249924916154

Epoch: 5| Step: 7
Training loss: 3.282717131546224
Validation loss: 3.4802508733866495

Epoch: 5| Step: 8
Training loss: 4.133035174249901
Validation loss: 3.4795511062926225

Epoch: 5| Step: 9
Training loss: 3.3411939602143645
Validation loss: 3.4789849515642155

Epoch: 5| Step: 10
Training loss: 3.3181366377019437
Validation loss: 3.4790642138501697

Epoch: 119| Step: 0
Training loss: 3.531257831936143
Validation loss: 3.4794475099923297

Epoch: 5| Step: 1
Training loss: 4.4444416178588355
Validation loss: 3.4789221337924534

Epoch: 5| Step: 2
Training loss: 3.67284442198023
Validation loss: 3.478978440369091

Epoch: 5| Step: 3
Training loss: 3.27636311242295
Validation loss: 3.4792175028899397

Epoch: 5| Step: 4
Training loss: 3.9338620046083554
Validation loss: 3.478510930353309

Epoch: 5| Step: 5
Training loss: 3.5442000061327916
Validation loss: 3.4785675044775157

Epoch: 5| Step: 6
Training loss: 4.04162681533725
Validation loss: 3.480819397035102

Epoch: 5| Step: 7
Training loss: 3.056138886536217
Validation loss: 3.4791709561413935

Epoch: 5| Step: 8
Training loss: 3.9249775685440826
Validation loss: 3.4775678293863854

Epoch: 5| Step: 9
Training loss: 3.7411958977445026
Validation loss: 3.477421599544603

Epoch: 5| Step: 10
Training loss: 3.171876803994253
Validation loss: 3.477718075036207

Epoch: 120| Step: 0
Training loss: 3.8714938144686153
Validation loss: 3.4756524578389447

Epoch: 5| Step: 1
Training loss: 3.767818207949627
Validation loss: 3.4763231251053166

Epoch: 5| Step: 2
Training loss: 3.617723857752234
Validation loss: 3.4761621521004002

Epoch: 5| Step: 3
Training loss: 3.189885910768324
Validation loss: 3.4763915472157163

Epoch: 5| Step: 4
Training loss: 3.8958983934379225
Validation loss: 3.4747006703265537

Epoch: 5| Step: 5
Training loss: 3.123246273047403
Validation loss: 3.476063704418114

Epoch: 5| Step: 6
Training loss: 3.778741934790098
Validation loss: 3.474794110200806

Epoch: 5| Step: 7
Training loss: 4.040813133067055
Validation loss: 3.4748891868696483

Epoch: 5| Step: 8
Training loss: 4.213485937453356
Validation loss: 3.474396197144631

Epoch: 5| Step: 9
Training loss: 4.110387177062682
Validation loss: 3.4747916356790127

Epoch: 5| Step: 10
Training loss: 2.5077782744451906
Validation loss: 3.4748071674425542

Epoch: 121| Step: 0
Training loss: 3.7122450924068353
Validation loss: 3.4735625293178796

Epoch: 5| Step: 1
Training loss: 4.214407939847217
Validation loss: 3.4744276345434084

Epoch: 5| Step: 2
Training loss: 3.4607280728114587
Validation loss: 3.474036323956088

Epoch: 5| Step: 3
Training loss: 3.4469127441995813
Validation loss: 3.4727509865623203

Epoch: 5| Step: 4
Training loss: 4.1691984241431745
Validation loss: 3.473529875162825

Epoch: 5| Step: 5
Training loss: 4.018957514173597
Validation loss: 3.47495064483837

Epoch: 5| Step: 6
Training loss: 2.6148147075352073
Validation loss: 3.4716123289491416

Epoch: 5| Step: 7
Training loss: 3.0304290603670285
Validation loss: 3.472136046840819

Epoch: 5| Step: 8
Training loss: 3.906766811515075
Validation loss: 3.4723568055243716

Epoch: 5| Step: 9
Training loss: 4.121139338092044
Validation loss: 3.471216216565489

Epoch: 5| Step: 10
Training loss: 3.5333515766560524
Validation loss: 3.4715927110128337

Epoch: 122| Step: 0
Training loss: 3.610298600039242
Validation loss: 3.4709144940782393

Epoch: 5| Step: 1
Training loss: 2.288993235506834
Validation loss: 3.4706552629968206

Epoch: 5| Step: 2
Training loss: 4.126735206696272
Validation loss: 3.469953126386554

Epoch: 5| Step: 3
Training loss: 4.336491070025977
Validation loss: 3.469627595283895

Epoch: 5| Step: 4
Training loss: 3.5552212157278245
Validation loss: 3.470445785470526

Epoch: 5| Step: 5
Training loss: 4.1275647599738905
Validation loss: 3.4698581996549938

Epoch: 5| Step: 6
Training loss: 3.440639795865737
Validation loss: 3.4711137939832177

Epoch: 5| Step: 7
Training loss: 3.780648680234567
Validation loss: 3.474627728992962

Epoch: 5| Step: 8
Training loss: 3.802978883943958
Validation loss: 3.4726614073144275

Epoch: 5| Step: 9
Training loss: 4.104804104069777
Validation loss: 3.472870946080587

Epoch: 5| Step: 10
Training loss: 2.7353026642083758
Validation loss: 3.4694147527113026

Epoch: 123| Step: 0
Training loss: 3.6947711443198923
Validation loss: 3.4687116200087313

Epoch: 5| Step: 1
Training loss: 3.9052818624487142
Validation loss: 3.4672529683096927

Epoch: 5| Step: 2
Training loss: 4.0892150453968545
Validation loss: 3.467916372032312

Epoch: 5| Step: 3
Training loss: 3.777201100509016
Validation loss: 3.466993384331503

Epoch: 5| Step: 4
Training loss: 2.5978621092948546
Validation loss: 3.4675295270831707

Epoch: 5| Step: 5
Training loss: 3.5822009729675943
Validation loss: 3.467807850613083

Epoch: 5| Step: 6
Training loss: 3.6791767648721763
Validation loss: 3.4674740253084266

Epoch: 5| Step: 7
Training loss: 4.015312212328649
Validation loss: 3.46694497198417

Epoch: 5| Step: 8
Training loss: 3.9511636685839147
Validation loss: 3.4662768885719353

Epoch: 5| Step: 9
Training loss: 3.6507116904184063
Validation loss: 3.4658250613213815

Epoch: 5| Step: 10
Training loss: 3.327686549574163
Validation loss: 3.4664989655289715

Epoch: 124| Step: 0
Training loss: 4.587064276435143
Validation loss: 3.4669533817656406

Epoch: 5| Step: 1
Training loss: 3.9287435865456075
Validation loss: 3.4667397065036867

Epoch: 5| Step: 2
Training loss: 3.865408810095646
Validation loss: 3.46599723498805

Epoch: 5| Step: 3
Training loss: 3.6110314205538354
Validation loss: 3.4659608829951014

Epoch: 5| Step: 4
Training loss: 4.5244483147783425
Validation loss: 3.465972626593713

Epoch: 5| Step: 5
Training loss: 2.7047979216620948
Validation loss: 3.4652190739446804

Epoch: 5| Step: 6
Training loss: 3.226497769572399
Validation loss: 3.4656983779951656

Epoch: 5| Step: 7
Training loss: 3.747088255552231
Validation loss: 3.465703269009349

Epoch: 5| Step: 8
Training loss: 3.2505702472132287
Validation loss: 3.4664539445431517

Epoch: 5| Step: 9
Training loss: 3.571951391916724
Validation loss: 3.465322996473017

Epoch: 5| Step: 10
Training loss: 2.9177922574636534
Validation loss: 3.464274361394104

Epoch: 125| Step: 0
Training loss: 3.001506427199437
Validation loss: 3.464788656549

Epoch: 5| Step: 1
Training loss: 4.287446598354344
Validation loss: 3.463633877919724

Epoch: 5| Step: 2
Training loss: 2.9011666746389535
Validation loss: 3.4655331165404686

Epoch: 5| Step: 3
Training loss: 4.654399734621903
Validation loss: 3.4652690869394993

Epoch: 5| Step: 4
Training loss: 3.6846184544131635
Validation loss: 3.4652680112556293

Epoch: 5| Step: 5
Training loss: 3.54687795764951
Validation loss: 3.464943614450569

Epoch: 5| Step: 6
Training loss: 3.96949460711475
Validation loss: 3.464083554683383

Epoch: 5| Step: 7
Training loss: 3.125231924987478
Validation loss: 3.463814735550313

Epoch: 5| Step: 8
Training loss: 3.025905971581493
Validation loss: 3.464162003450721

Epoch: 5| Step: 9
Training loss: 4.022453469243795
Validation loss: 3.464335031599503

Epoch: 5| Step: 10
Training loss: 3.8326294847127924
Validation loss: 3.462743408134306

Epoch: 126| Step: 0
Training loss: 3.4345728115216954
Validation loss: 3.4640451866362323

Epoch: 5| Step: 1
Training loss: 3.468387206754604
Validation loss: 3.4624538245742174

Epoch: 5| Step: 2
Training loss: 3.868596107491128
Validation loss: 3.461258684476724

Epoch: 5| Step: 3
Training loss: 3.3838810807744473
Validation loss: 3.4612592140537024

Epoch: 5| Step: 4
Training loss: 3.959776217177495
Validation loss: 3.460482868669304

Epoch: 5| Step: 5
Training loss: 3.567693037385474
Validation loss: 3.46182812180056

Epoch: 5| Step: 6
Training loss: 2.802547222627764
Validation loss: 3.460999565704097

Epoch: 5| Step: 7
Training loss: 3.7057249060700355
Validation loss: 3.4601640660451363

Epoch: 5| Step: 8
Training loss: 3.610888935655547
Validation loss: 3.4600418269981645

Epoch: 5| Step: 9
Training loss: 4.239132169044846
Validation loss: 3.4599351836390606

Epoch: 5| Step: 10
Training loss: 4.2701269294401865
Validation loss: 3.4588230990611093

Epoch: 127| Step: 0
Training loss: 3.360325026913174
Validation loss: 3.4590028578528926

Epoch: 5| Step: 1
Training loss: 3.481723614840667
Validation loss: 3.4593406976345924

Epoch: 5| Step: 2
Training loss: 3.3618380721092884
Validation loss: 3.459675494460568

Epoch: 5| Step: 3
Training loss: 3.468423364055233
Validation loss: 3.4585642603485933

Epoch: 5| Step: 4
Training loss: 3.624195535778275
Validation loss: 3.458266372615564

Epoch: 5| Step: 5
Training loss: 4.532831797251344
Validation loss: 3.4581529847281316

Epoch: 5| Step: 6
Training loss: 3.3529273324174755
Validation loss: 3.4581552532043403

Epoch: 5| Step: 7
Training loss: 3.758641141704898
Validation loss: 3.4578891641391554

Epoch: 5| Step: 8
Training loss: 4.019720341838088
Validation loss: 3.4582276227450692

Epoch: 5| Step: 9
Training loss: 3.709293812583971
Validation loss: 3.45758251505968

Epoch: 5| Step: 10
Training loss: 3.5977467744023017
Validation loss: 3.4573049077427713

Epoch: 128| Step: 0
Training loss: 3.951897110051401
Validation loss: 3.457245814489216

Epoch: 5| Step: 1
Training loss: 3.7881492536681294
Validation loss: 3.4564292702935067

Epoch: 5| Step: 2
Training loss: 4.058216125132585
Validation loss: 3.4565496657217727

Epoch: 5| Step: 3
Training loss: 4.206210567295197
Validation loss: 3.4562503344952837

Epoch: 5| Step: 4
Training loss: 2.583674890232037
Validation loss: 3.455439619474543

Epoch: 5| Step: 5
Training loss: 3.434979294849167
Validation loss: 3.4555966183630837

Epoch: 5| Step: 6
Training loss: 3.7385955327659057
Validation loss: 3.455521347805449

Epoch: 5| Step: 7
Training loss: 3.478290394211973
Validation loss: 3.4562703154414356

Epoch: 5| Step: 8
Training loss: 3.7761577018360533
Validation loss: 3.456530557123231

Epoch: 5| Step: 9
Training loss: 3.4059793907254323
Validation loss: 3.453896929898743

Epoch: 5| Step: 10
Training loss: 3.745675072528636
Validation loss: 3.4550280535270312

Epoch: 129| Step: 0
Training loss: 3.480563692281443
Validation loss: 3.4554011465438834

Epoch: 5| Step: 1
Training loss: 3.1605299833565574
Validation loss: 3.4553057324802348

Epoch: 5| Step: 2
Training loss: 3.6058149739811824
Validation loss: 3.4537563471596835

Epoch: 5| Step: 3
Training loss: 3.996872275130094
Validation loss: 3.4570241650054023

Epoch: 5| Step: 4
Training loss: 3.1739319394079093
Validation loss: 3.4576377233321978

Epoch: 5| Step: 5
Training loss: 3.700738838247516
Validation loss: 3.4549153948827707

Epoch: 5| Step: 6
Training loss: 3.786747616610045
Validation loss: 3.454705895005515

Epoch: 5| Step: 7
Training loss: 3.7968345608539646
Validation loss: 3.4566451166479784

Epoch: 5| Step: 8
Training loss: 3.4363945310524047
Validation loss: 3.4547185428581355

Epoch: 5| Step: 9
Training loss: 3.510605140101494
Validation loss: 3.452722503244576

Epoch: 5| Step: 10
Training loss: 4.675713738612973
Validation loss: 3.4517695236438386

Epoch: 130| Step: 0
Training loss: 3.53568360836928
Validation loss: 3.4526007937458787

Epoch: 5| Step: 1
Training loss: 3.1926897472610185
Validation loss: 3.4516643418845607

Epoch: 5| Step: 2
Training loss: 4.008983537647286
Validation loss: 3.4522074308705526

Epoch: 5| Step: 3
Training loss: 3.9208140362958246
Validation loss: 3.4514979568660813

Epoch: 5| Step: 4
Training loss: 3.7012648920534534
Validation loss: 3.4511283893453473

Epoch: 5| Step: 5
Training loss: 3.170933626036657
Validation loss: 3.4513380231878226

Epoch: 5| Step: 6
Training loss: 4.276009352357091
Validation loss: 3.4510861006177773

Epoch: 5| Step: 7
Training loss: 3.556514329254746
Validation loss: 3.4506825027467927

Epoch: 5| Step: 8
Training loss: 3.513337200483574
Validation loss: 3.4498311149322936

Epoch: 5| Step: 9
Training loss: 4.140280885612421
Validation loss: 3.4497833468081573

Epoch: 5| Step: 10
Training loss: 3.052094512675949
Validation loss: 3.4497939780225653

Epoch: 131| Step: 0
Training loss: 3.9591326391746002
Validation loss: 3.4491455329005936

Epoch: 5| Step: 1
Training loss: 3.0435174684783095
Validation loss: 3.449511876350746

Epoch: 5| Step: 2
Training loss: 3.7938130909231496
Validation loss: 3.4494268707870344

Epoch: 5| Step: 3
Training loss: 3.3577879949627865
Validation loss: 3.4494752800245574

Epoch: 5| Step: 4
Training loss: 3.812183179354914
Validation loss: 3.4478137291496984

Epoch: 5| Step: 5
Training loss: 3.1891813144857473
Validation loss: 3.4500260596876116

Epoch: 5| Step: 6
Training loss: 2.897268218807825
Validation loss: 3.449324508757148

Epoch: 5| Step: 7
Training loss: 4.178119914494731
Validation loss: 3.4489153677234334

Epoch: 5| Step: 8
Training loss: 4.021351097384746
Validation loss: 3.4481133935045767

Epoch: 5| Step: 9
Training loss: 3.892237807737027
Validation loss: 3.449405866186864

Epoch: 5| Step: 10
Training loss: 3.9965370208312234
Validation loss: 3.4488918107827717

Epoch: 132| Step: 0
Training loss: 3.546823644056204
Validation loss: 3.4473815855703864

Epoch: 5| Step: 1
Training loss: 3.539900455260613
Validation loss: 3.446870177648672

Epoch: 5| Step: 2
Training loss: 2.682552129944655
Validation loss: 3.4471728013790544

Epoch: 5| Step: 3
Training loss: 3.330993419163163
Validation loss: 3.447060469080173

Epoch: 5| Step: 4
Training loss: 4.544114995723628
Validation loss: 3.4458757876253534

Epoch: 5| Step: 5
Training loss: 3.929338746872163
Validation loss: 3.446869417526914

Epoch: 5| Step: 6
Training loss: 4.072225110335032
Validation loss: 3.4464025610234357

Epoch: 5| Step: 7
Training loss: 4.156432642544773
Validation loss: 3.446601235810823

Epoch: 5| Step: 8
Training loss: 3.165043431567102
Validation loss: 3.4469021635988053

Epoch: 5| Step: 9
Training loss: 3.760032584881104
Validation loss: 3.4462463513692216

Epoch: 5| Step: 10
Training loss: 3.1316096786448857
Validation loss: 3.446026934452102

Epoch: 133| Step: 0
Training loss: 4.323901377595116
Validation loss: 3.445418130141171

Epoch: 5| Step: 1
Training loss: 4.140391217235721
Validation loss: 3.4467627980051265

Epoch: 5| Step: 2
Training loss: 3.622141533195386
Validation loss: 3.444685078314405

Epoch: 5| Step: 3
Training loss: 3.865586937953657
Validation loss: 3.4453905063415227

Epoch: 5| Step: 4
Training loss: 2.9305034670989065
Validation loss: 3.4449307743646194

Epoch: 5| Step: 5
Training loss: 4.1309787309145705
Validation loss: 3.443205276572091

Epoch: 5| Step: 6
Training loss: 2.640011868594685
Validation loss: 3.4447123423566155

Epoch: 5| Step: 7
Training loss: 3.7582050840116765
Validation loss: 3.4442683128952263

Epoch: 5| Step: 8
Training loss: 3.6587277355500643
Validation loss: 3.4438595545345363

Epoch: 5| Step: 9
Training loss: 3.1977762363345588
Validation loss: 3.443465481971198

Epoch: 5| Step: 10
Training loss: 3.6499379766759796
Validation loss: 3.4435208927517156

Epoch: 134| Step: 0
Training loss: 3.7412814196163593
Validation loss: 3.4424015051349417

Epoch: 5| Step: 1
Training loss: 3.84605313902837
Validation loss: 3.4430733046786046

Epoch: 5| Step: 2
Training loss: 3.9830475634187517
Validation loss: 3.4428934677336898

Epoch: 5| Step: 3
Training loss: 3.2418540691217053
Validation loss: 3.4421465184167146

Epoch: 5| Step: 4
Training loss: 3.3673220295595185
Validation loss: 3.4415886451772284

Epoch: 5| Step: 5
Training loss: 3.07965235890894
Validation loss: 3.440817952008674

Epoch: 5| Step: 6
Training loss: 3.257097710150747
Validation loss: 3.441827888430091

Epoch: 5| Step: 7
Training loss: 3.542818278657659
Validation loss: 3.4421642932816443

Epoch: 5| Step: 8
Training loss: 3.858817241689575
Validation loss: 3.4475999138982116

Epoch: 5| Step: 9
Training loss: 4.047644582502244
Validation loss: 3.442840557746658

Epoch: 5| Step: 10
Training loss: 4.221077961938941
Validation loss: 3.4447001266277475

Epoch: 135| Step: 0
Training loss: 3.69331483294631
Validation loss: 3.444732521210955

Epoch: 5| Step: 1
Training loss: 3.137056515418971
Validation loss: 3.4417283588332683

Epoch: 5| Step: 2
Training loss: 3.137155162812953
Validation loss: 3.4416858845868705

Epoch: 5| Step: 3
Training loss: 3.300478732901184
Validation loss: 3.445548124582842

Epoch: 5| Step: 4
Training loss: 3.7033289599686103
Validation loss: 3.4459070537182726

Epoch: 5| Step: 5
Training loss: 4.41979327585786
Validation loss: 3.4422915001258643

Epoch: 5| Step: 6
Training loss: 4.293991841664268
Validation loss: 3.4434167529814603

Epoch: 5| Step: 7
Training loss: 2.9270473129572125
Validation loss: 3.440254126865988

Epoch: 5| Step: 8
Training loss: 4.392445034319337
Validation loss: 3.4386940337561755

Epoch: 5| Step: 9
Training loss: 2.9596535508282344
Validation loss: 3.4400860318946567

Epoch: 5| Step: 10
Training loss: 3.876570352640928
Validation loss: 3.437642734580925

Epoch: 136| Step: 0
Training loss: 3.664926910920617
Validation loss: 3.437411591855647

Epoch: 5| Step: 1
Training loss: 3.6036322019168234
Validation loss: 3.4375906088662305

Epoch: 5| Step: 2
Training loss: 3.0815274560520054
Validation loss: 3.437509317842237

Epoch: 5| Step: 3
Training loss: 3.0669448671065305
Validation loss: 3.4384351977748397

Epoch: 5| Step: 4
Training loss: 4.417605006508648
Validation loss: 3.4378834410819796

Epoch: 5| Step: 5
Training loss: 3.47690290863285
Validation loss: 3.4374680578215067

Epoch: 5| Step: 6
Training loss: 3.6526021121436467
Validation loss: 3.4362900708646977

Epoch: 5| Step: 7
Training loss: 3.988687373153528
Validation loss: 3.4364549079210542

Epoch: 5| Step: 8
Training loss: 3.5364882515197484
Validation loss: 3.4375522479042093

Epoch: 5| Step: 9
Training loss: 3.4373168896542468
Validation loss: 3.436529602424405

Epoch: 5| Step: 10
Training loss: 4.148127370043088
Validation loss: 3.437479519153785

Epoch: 137| Step: 0
Training loss: 3.8030474690141203
Validation loss: 3.437213389808722

Epoch: 5| Step: 1
Training loss: 4.039606703319629
Validation loss: 3.436162777633337

Epoch: 5| Step: 2
Training loss: 3.410251332079385
Validation loss: 3.435467699677127

Epoch: 5| Step: 3
Training loss: 3.9198966944959173
Validation loss: 3.43490140360097

Epoch: 5| Step: 4
Training loss: 3.761469277163762
Validation loss: 3.435646340414939

Epoch: 5| Step: 5
Training loss: 3.1139730070263565
Validation loss: 3.4353438550135964

Epoch: 5| Step: 6
Training loss: 3.6598073493825773
Validation loss: 3.4353473250950315

Epoch: 5| Step: 7
Training loss: 3.4480379357961612
Validation loss: 3.434594129640471

Epoch: 5| Step: 8
Training loss: 3.4163683474183077
Validation loss: 3.433890010873204

Epoch: 5| Step: 9
Training loss: 3.803561128107319
Validation loss: 3.4349156752870043

Epoch: 5| Step: 10
Training loss: 3.746104060408452
Validation loss: 3.4349821458425276

Epoch: 138| Step: 0
Training loss: 3.2067240522593874
Validation loss: 3.4336567206028996

Epoch: 5| Step: 1
Training loss: 3.9322203101279576
Validation loss: 3.4340523054701477

Epoch: 5| Step: 2
Training loss: 3.6606426750382948
Validation loss: 3.431978684268207

Epoch: 5| Step: 3
Training loss: 3.622097168527426
Validation loss: 3.433047647733527

Epoch: 5| Step: 4
Training loss: 3.6469459507176762
Validation loss: 3.4340412925664605

Epoch: 5| Step: 5
Training loss: 3.9617852802892664
Validation loss: 3.4324817888954327

Epoch: 5| Step: 6
Training loss: 3.4638828807439825
Validation loss: 3.433714686284342

Epoch: 5| Step: 7
Training loss: 4.3499557843646794
Validation loss: 3.4331512455354005

Epoch: 5| Step: 8
Training loss: 2.9679747522930553
Validation loss: 3.434288725003092

Epoch: 5| Step: 9
Training loss: 3.4108859370655282
Validation loss: 3.4331690259023975

Epoch: 5| Step: 10
Training loss: 3.818191782207616
Validation loss: 3.432968263922705

Epoch: 139| Step: 0
Training loss: 4.129237223977315
Validation loss: 3.4320825287154193

Epoch: 5| Step: 1
Training loss: 3.7370072668350445
Validation loss: 3.432773957609375

Epoch: 5| Step: 2
Training loss: 2.2271609924117755
Validation loss: 3.431782056934149

Epoch: 5| Step: 3
Training loss: 3.4686677940181574
Validation loss: 3.430888901930611

Epoch: 5| Step: 4
Training loss: 3.8854995732329902
Validation loss: 3.4304194431195025

Epoch: 5| Step: 5
Training loss: 3.0115156092827435
Validation loss: 3.4314745974099603

Epoch: 5| Step: 6
Training loss: 3.304293850298592
Validation loss: 3.4295042072470054

Epoch: 5| Step: 7
Training loss: 3.998707800997566
Validation loss: 3.428767243190404

Epoch: 5| Step: 8
Training loss: 3.775694872836802
Validation loss: 3.4298815102753024

Epoch: 5| Step: 9
Training loss: 4.239788803382786
Validation loss: 3.42865224867886

Epoch: 5| Step: 10
Training loss: 3.9766044689429436
Validation loss: 3.4301527406054944

Epoch: 140| Step: 0
Training loss: 4.092431008812445
Validation loss: 3.4300232187874418

Epoch: 5| Step: 1
Training loss: 3.0610006905187
Validation loss: 3.4288645336792807

Epoch: 5| Step: 2
Training loss: 3.53604934117686
Validation loss: 3.427516045313402

Epoch: 5| Step: 3
Training loss: 4.379237928938874
Validation loss: 3.427587033343756

Epoch: 5| Step: 4
Training loss: 3.4055634252869735
Validation loss: 3.4316754348202125

Epoch: 5| Step: 5
Training loss: 2.805067116381493
Validation loss: 3.4290256172246063

Epoch: 5| Step: 6
Training loss: 3.4471723938348924
Validation loss: 3.430361891084035

Epoch: 5| Step: 7
Training loss: 3.9422900415995175
Validation loss: 3.431159413054553

Epoch: 5| Step: 8
Training loss: 3.695120873029242
Validation loss: 3.431112906229906

Epoch: 5| Step: 9
Training loss: 3.519441829989201
Validation loss: 3.4318477724439624

Epoch: 5| Step: 10
Training loss: 4.038735942810209
Validation loss: 3.432016944686904

Epoch: 141| Step: 0
Training loss: 3.950412830074236
Validation loss: 3.429514126891356

Epoch: 5| Step: 1
Training loss: 3.5267920247412956
Validation loss: 3.426557439515074

Epoch: 5| Step: 2
Training loss: 3.8354315336658633
Validation loss: 3.4281258736400084

Epoch: 5| Step: 3
Training loss: 3.3854586711136143
Validation loss: 3.4283467174039077

Epoch: 5| Step: 4
Training loss: 3.817415414408942
Validation loss: 3.4274691973445504

Epoch: 5| Step: 5
Training loss: 3.145185205922415
Validation loss: 3.4270830051873165

Epoch: 5| Step: 6
Training loss: 4.0806399954194434
Validation loss: 3.4271701597651396

Epoch: 5| Step: 7
Training loss: 3.1287760999187606
Validation loss: 3.4272489134014448

Epoch: 5| Step: 8
Training loss: 3.430967887023233
Validation loss: 3.428039269842923

Epoch: 5| Step: 9
Training loss: 3.716659599491351
Validation loss: 3.4299531818276274

Epoch: 5| Step: 10
Training loss: 3.9761480628830648
Validation loss: 3.427154570696064

Epoch: 142| Step: 0
Training loss: 3.632504029662279
Validation loss: 3.4263711855104804

Epoch: 5| Step: 1
Training loss: 3.5754355105309648
Validation loss: 3.426185279043931

Epoch: 5| Step: 2
Training loss: 3.139871383511222
Validation loss: 3.4288776775977845

Epoch: 5| Step: 3
Training loss: 3.7313820564760722
Validation loss: 3.4261808838248973

Epoch: 5| Step: 4
Training loss: 3.1811755398353267
Validation loss: 3.427200751237002

Epoch: 5| Step: 5
Training loss: 3.8250508323732455
Validation loss: 3.4303309302155007

Epoch: 5| Step: 6
Training loss: 4.527040617885093
Validation loss: 3.4281146053838225

Epoch: 5| Step: 7
Training loss: 3.9899865221450828
Validation loss: 3.4251205022835496

Epoch: 5| Step: 8
Training loss: 2.6435132004040476
Validation loss: 3.424612166773863

Epoch: 5| Step: 9
Training loss: 3.920494778995859
Validation loss: 3.4244199990608437

Epoch: 5| Step: 10
Training loss: 3.562679353181252
Validation loss: 3.422501686492655

Epoch: 143| Step: 0
Training loss: 3.9701204111590322
Validation loss: 3.42330910207455

Epoch: 5| Step: 1
Training loss: 3.9475840459456575
Validation loss: 3.422456106216664

Epoch: 5| Step: 2
Training loss: 3.3982657553586018
Validation loss: 3.4216879127068642

Epoch: 5| Step: 3
Training loss: 3.4769884855767077
Validation loss: 3.4217675267508567

Epoch: 5| Step: 4
Training loss: 3.479024842316391
Validation loss: 3.420748469148271

Epoch: 5| Step: 5
Training loss: 3.5197186182003457
Validation loss: 3.4215658979784784

Epoch: 5| Step: 6
Training loss: 3.707559754911939
Validation loss: 3.4219200456087076

Epoch: 5| Step: 7
Training loss: 3.8892716961112237
Validation loss: 3.4216927017992336

Epoch: 5| Step: 8
Training loss: 3.96322126593184
Validation loss: 3.419702115439934

Epoch: 5| Step: 9
Training loss: 3.280086347327285
Validation loss: 3.4200681946268983

Epoch: 5| Step: 10
Training loss: 3.298079284270169
Validation loss: 3.4212026856640767

Epoch: 144| Step: 0
Training loss: 3.8439233012015235
Validation loss: 3.4202266867503908

Epoch: 5| Step: 1
Training loss: 3.4662203801042004
Validation loss: 3.419222943675434

Epoch: 5| Step: 2
Training loss: 3.345634000991637
Validation loss: 3.4197827427629988

Epoch: 5| Step: 3
Training loss: 3.889470798612803
Validation loss: 3.4177586160924136

Epoch: 5| Step: 4
Training loss: 3.761050409540594
Validation loss: 3.419142835502919

Epoch: 5| Step: 5
Training loss: 3.7618461420942713
Validation loss: 3.4182582787679467

Epoch: 5| Step: 6
Training loss: 2.7216675987016243
Validation loss: 3.420023539904165

Epoch: 5| Step: 7
Training loss: 3.9738993242448153
Validation loss: 3.4189511477013785

Epoch: 5| Step: 8
Training loss: 4.015250221901796
Validation loss: 3.4190343136101258

Epoch: 5| Step: 9
Training loss: 3.2115901088910546
Validation loss: 3.420153115848506

Epoch: 5| Step: 10
Training loss: 3.865883840592927
Validation loss: 3.4184942412385353

Epoch: 145| Step: 0
Training loss: 4.329478138405105
Validation loss: 3.420263663491342

Epoch: 5| Step: 1
Training loss: 3.6543644664880737
Validation loss: 3.418334495840343

Epoch: 5| Step: 2
Training loss: 3.8933746548859265
Validation loss: 3.418243571540782

Epoch: 5| Step: 3
Training loss: 2.9124286561012758
Validation loss: 3.4204103065272804

Epoch: 5| Step: 4
Training loss: 3.4935227813261815
Validation loss: 3.417357460217609

Epoch: 5| Step: 5
Training loss: 4.164134642242682
Validation loss: 3.4194728233489715

Epoch: 5| Step: 6
Training loss: 4.012664772524632
Validation loss: 3.417090489962455

Epoch: 5| Step: 7
Training loss: 2.9692498037337067
Validation loss: 3.4175285394803194

Epoch: 5| Step: 8
Training loss: 3.7702658772500715
Validation loss: 3.4157707476354315

Epoch: 5| Step: 9
Training loss: 3.2411810726158756
Validation loss: 3.416789793731756

Epoch: 5| Step: 10
Training loss: 3.2044459154716756
Validation loss: 3.416938822421875

Epoch: 146| Step: 0
Training loss: 3.171010618395968
Validation loss: 3.41523051948686

Epoch: 5| Step: 1
Training loss: 4.262030683617342
Validation loss: 3.414593218762362

Epoch: 5| Step: 2
Training loss: 3.7475468558957057
Validation loss: 3.414510785588184

Epoch: 5| Step: 3
Training loss: 3.883077017602637
Validation loss: 3.414430643444844

Epoch: 5| Step: 4
Training loss: 4.457889831920483
Validation loss: 3.4149237408332547

Epoch: 5| Step: 5
Training loss: 3.3796054359239713
Validation loss: 3.414929976281333

Epoch: 5| Step: 6
Training loss: 3.825610646889492
Validation loss: 3.4150034405033924

Epoch: 5| Step: 7
Training loss: 3.351798949537415
Validation loss: 3.4144187939006767

Epoch: 5| Step: 8
Training loss: 2.690084501024112
Validation loss: 3.4138776609415804

Epoch: 5| Step: 9
Training loss: 3.2566114814427056
Validation loss: 3.4140893447904506

Epoch: 5| Step: 10
Training loss: 3.6214631024969153
Validation loss: 3.413739773804187

Epoch: 147| Step: 0
Training loss: 3.6760238259324765
Validation loss: 3.4135776865534995

Epoch: 5| Step: 1
Training loss: 3.7706743631873385
Validation loss: 3.4136568769337146

Epoch: 5| Step: 2
Training loss: 3.0157733149449064
Validation loss: 3.412674233746543

Epoch: 5| Step: 3
Training loss: 3.8288023057553673
Validation loss: 3.4134069410185393

Epoch: 5| Step: 4
Training loss: 3.9602228306200224
Validation loss: 3.412145342767787

Epoch: 5| Step: 5
Training loss: 3.841697330862754
Validation loss: 3.4138840905423544

Epoch: 5| Step: 6
Training loss: 3.907586441304229
Validation loss: 3.413217675577832

Epoch: 5| Step: 7
Training loss: 3.219306082975614
Validation loss: 3.411002143067421

Epoch: 5| Step: 8
Training loss: 3.8125207619023564
Validation loss: 3.4128004139368024

Epoch: 5| Step: 9
Training loss: 3.9478758689899465
Validation loss: 3.4134569936541705

Epoch: 5| Step: 10
Training loss: 2.587085388431807
Validation loss: 3.4109084626080306

Epoch: 148| Step: 0
Training loss: 4.065073459989059
Validation loss: 3.4108597735776742

Epoch: 5| Step: 1
Training loss: 3.2965996071295285
Validation loss: 3.410927506609298

Epoch: 5| Step: 2
Training loss: 4.117386004242809
Validation loss: 3.41034688509418

Epoch: 5| Step: 3
Training loss: 3.1339130703981724
Validation loss: 3.4098193533361068

Epoch: 5| Step: 4
Training loss: 3.5921510539419046
Validation loss: 3.409783824171515

Epoch: 5| Step: 5
Training loss: 4.168435954513967
Validation loss: 3.4095759392603506

Epoch: 5| Step: 6
Training loss: 4.081456486150483
Validation loss: 3.409633178987397

Epoch: 5| Step: 7
Training loss: 3.589879480958264
Validation loss: 3.409857689472901

Epoch: 5| Step: 8
Training loss: 2.9254904832986712
Validation loss: 3.408407931596205

Epoch: 5| Step: 9
Training loss: 3.5294242797891466
Validation loss: 3.4095112697240855

Epoch: 5| Step: 10
Training loss: 3.0942958774055063
Validation loss: 3.407628551402588

Epoch: 149| Step: 0
Training loss: 4.330417287686956
Validation loss: 3.4082447573529038

Epoch: 5| Step: 1
Training loss: 3.2169602242033464
Validation loss: 3.408689303031376

Epoch: 5| Step: 2
Training loss: 2.311617502442845
Validation loss: 3.408857795573456

Epoch: 5| Step: 3
Training loss: 3.3168962204309884
Validation loss: 3.409346318054029

Epoch: 5| Step: 4
Training loss: 3.793371271525857
Validation loss: 3.406704921473508

Epoch: 5| Step: 5
Training loss: 2.7098981200489662
Validation loss: 3.4084479548702094

Epoch: 5| Step: 6
Training loss: 4.3867815782594475
Validation loss: 3.4081953021407894

Epoch: 5| Step: 7
Training loss: 3.875133266003205
Validation loss: 3.4068214529470606

Epoch: 5| Step: 8
Training loss: 3.9392446860914103
Validation loss: 3.408231828721906

Epoch: 5| Step: 9
Training loss: 4.0170010238923455
Validation loss: 3.4072501866729588

Epoch: 5| Step: 10
Training loss: 3.400924999968055
Validation loss: 3.4058784943830767

Epoch: 150| Step: 0
Training loss: 3.6055593427557535
Validation loss: 3.4076625653041006

Epoch: 5| Step: 1
Training loss: 2.8161057987875027
Validation loss: 3.4091657893464418

Epoch: 5| Step: 2
Training loss: 4.196290766995523
Validation loss: 3.404616761468646

Epoch: 5| Step: 3
Training loss: 3.931484289420033
Validation loss: 3.4075793114430826

Epoch: 5| Step: 4
Training loss: 3.5130204110490544
Validation loss: 3.4061715390863774

Epoch: 5| Step: 5
Training loss: 3.9288506346729846
Validation loss: 3.4056118151584753

Epoch: 5| Step: 6
Training loss: 3.7624220779815896
Validation loss: 3.406275587765713

Epoch: 5| Step: 7
Training loss: 3.7511202092710727
Validation loss: 3.4060972634277245

Epoch: 5| Step: 8
Training loss: 3.6348473541237962
Validation loss: 3.4039971167154035

Epoch: 5| Step: 9
Training loss: 3.2479513020082806
Validation loss: 3.4049156595737102

Epoch: 5| Step: 10
Training loss: 3.250825043639763
Validation loss: 3.4032791336470094

Epoch: 151| Step: 0
Training loss: 3.962966910690713
Validation loss: 3.4040397991424154

Epoch: 5| Step: 1
Training loss: 3.520545737053011
Validation loss: 3.4064914760398577

Epoch: 5| Step: 2
Training loss: 4.306770831365013
Validation loss: 3.412074293438785

Epoch: 5| Step: 3
Training loss: 2.9355740016107763
Validation loss: 3.4080179952300127

Epoch: 5| Step: 4
Training loss: 3.3792596003825075
Validation loss: 3.4133483991423423

Epoch: 5| Step: 5
Training loss: 3.726917945656602
Validation loss: 3.4067768744251254

Epoch: 5| Step: 6
Training loss: 3.604218602035982
Validation loss: 3.4069627699291076

Epoch: 5| Step: 7
Training loss: 3.8695529677584317
Validation loss: 3.4014904709338407

Epoch: 5| Step: 8
Training loss: 3.667786485004949
Validation loss: 3.403000073639221

Epoch: 5| Step: 9
Training loss: 3.811993924931652
Validation loss: 3.40158071858103

Epoch: 5| Step: 10
Training loss: 2.7403733210774934
Validation loss: 3.401264791593249

Epoch: 152| Step: 0
Training loss: 3.055957578933838
Validation loss: 3.4011979108264385

Epoch: 5| Step: 1
Training loss: 3.6973542264789847
Validation loss: 3.4014598916745604

Epoch: 5| Step: 2
Training loss: 3.7886645550533733
Validation loss: 3.401137987460827

Epoch: 5| Step: 3
Training loss: 4.240031725566859
Validation loss: 3.4001167370217065

Epoch: 5| Step: 4
Training loss: 3.810872340222018
Validation loss: 3.400505856011202

Epoch: 5| Step: 5
Training loss: 3.181789443889489
Validation loss: 3.398881946582425

Epoch: 5| Step: 6
Training loss: 2.797813045110088
Validation loss: 3.400002195561452

Epoch: 5| Step: 7
Training loss: 3.541948569055248
Validation loss: 3.4000355981052612

Epoch: 5| Step: 8
Training loss: 4.364307088311269
Validation loss: 3.4002890094252556

Epoch: 5| Step: 9
Training loss: 3.4705600998860957
Validation loss: 3.398983675120856

Epoch: 5| Step: 10
Training loss: 3.6221058571995486
Validation loss: 3.3995232559709176

Epoch: 153| Step: 0
Training loss: 4.062635683581505
Validation loss: 3.398268771435463

Epoch: 5| Step: 1
Training loss: 3.482363954448569
Validation loss: 3.3993188748829213

Epoch: 5| Step: 2
Training loss: 3.094003994466303
Validation loss: 3.399752729256497

Epoch: 5| Step: 3
Training loss: 2.9892104356034075
Validation loss: 3.398665631512826

Epoch: 5| Step: 4
Training loss: 2.7797647003380708
Validation loss: 3.398841445597133

Epoch: 5| Step: 5
Training loss: 4.1256227890121995
Validation loss: 3.397104428675879

Epoch: 5| Step: 6
Training loss: 4.097882230943994
Validation loss: 3.398251967975662

Epoch: 5| Step: 7
Training loss: 4.367061933919919
Validation loss: 3.3982701142602174

Epoch: 5| Step: 8
Training loss: 3.823580290166739
Validation loss: 3.3970714289772963

Epoch: 5| Step: 9
Training loss: 3.6778358935719777
Validation loss: 3.3971333695582238

Epoch: 5| Step: 10
Training loss: 2.7563403471587105
Validation loss: 3.3973549481782226

Epoch: 154| Step: 0
Training loss: 3.8132339771594124
Validation loss: 3.3966730799376896

Epoch: 5| Step: 1
Training loss: 4.352669539110363
Validation loss: 3.396805219081353

Epoch: 5| Step: 2
Training loss: 3.6187258388523085
Validation loss: 3.3965805130585656

Epoch: 5| Step: 3
Training loss: 3.6868039783570135
Validation loss: 3.396995703841345

Epoch: 5| Step: 4
Training loss: 2.8399157823245043
Validation loss: 3.3967948914618624

Epoch: 5| Step: 5
Training loss: 3.8312652786721886
Validation loss: 3.3962880931095096

Epoch: 5| Step: 6
Training loss: 3.316096099261687
Validation loss: 3.3963715769488476

Epoch: 5| Step: 7
Training loss: 3.4660592855323746
Validation loss: 3.3962130932827086

Epoch: 5| Step: 8
Training loss: 4.290706687644184
Validation loss: 3.395973849388668

Epoch: 5| Step: 9
Training loss: 3.0729326323186057
Validation loss: 3.3954633919808703

Epoch: 5| Step: 10
Training loss: 3.147986443632182
Validation loss: 3.393661912021035

Epoch: 155| Step: 0
Training loss: 3.503101201108458
Validation loss: 3.394736691123457

Epoch: 5| Step: 1
Training loss: 2.9312061493609196
Validation loss: 3.3950614608103558

Epoch: 5| Step: 2
Training loss: 3.5803431669315113
Validation loss: 3.394926403902639

Epoch: 5| Step: 3
Training loss: 2.4893084790658175
Validation loss: 3.395236091831296

Epoch: 5| Step: 4
Training loss: 3.898015735263684
Validation loss: 3.39369473789005

Epoch: 5| Step: 5
Training loss: 3.9949406575747712
Validation loss: 3.39435195066988

Epoch: 5| Step: 6
Training loss: 3.672143804572468
Validation loss: 3.393291143637834

Epoch: 5| Step: 7
Training loss: 3.524472103766675
Validation loss: 3.3931341072560364

Epoch: 5| Step: 8
Training loss: 4.165454052267034
Validation loss: 3.3966840313494915

Epoch: 5| Step: 9
Training loss: 3.885748323223354
Validation loss: 3.3945213791726734

Epoch: 5| Step: 10
Training loss: 3.8580560940253315
Validation loss: 3.393777001353069

Epoch: 156| Step: 0
Training loss: 2.916824954142835
Validation loss: 3.393097209617795

Epoch: 5| Step: 1
Training loss: 3.6631354031417525
Validation loss: 3.3915501683808635

Epoch: 5| Step: 2
Training loss: 3.190733671812945
Validation loss: 3.3931967301734285

Epoch: 5| Step: 3
Training loss: 3.3356824862276357
Validation loss: 3.393005806223194

Epoch: 5| Step: 4
Training loss: 3.6330827509944954
Validation loss: 3.3915724292837526

Epoch: 5| Step: 5
Training loss: 4.379574591126764
Validation loss: 3.389285852984574

Epoch: 5| Step: 6
Training loss: 3.44918792123291
Validation loss: 3.391416466853072

Epoch: 5| Step: 7
Training loss: 3.8913448541037288
Validation loss: 3.3937694035862256

Epoch: 5| Step: 8
Training loss: 3.687289215787698
Validation loss: 3.4013683376595485

Epoch: 5| Step: 9
Training loss: 4.129229602404666
Validation loss: 3.394509392158463

Epoch: 5| Step: 10
Training loss: 3.1749987324389233
Validation loss: 3.397316671683089

Epoch: 157| Step: 0
Training loss: 2.622872898584006
Validation loss: 3.3890970998161345

Epoch: 5| Step: 1
Training loss: 4.165314391361333
Validation loss: 3.3907507849510803

Epoch: 5| Step: 2
Training loss: 4.5207954557505
Validation loss: 3.389299896194707

Epoch: 5| Step: 3
Training loss: 3.0966943158851112
Validation loss: 3.3909541522676023

Epoch: 5| Step: 4
Training loss: 3.676227214162825
Validation loss: 3.389828136113291

Epoch: 5| Step: 5
Training loss: 3.516265810738719
Validation loss: 3.3889042269339846

Epoch: 5| Step: 6
Training loss: 3.2079991913887205
Validation loss: 3.3902766044618153

Epoch: 5| Step: 7
Training loss: 3.49393127735421
Validation loss: 3.3900936552098555

Epoch: 5| Step: 8
Training loss: 3.836837631866335
Validation loss: 3.3895264916766386

Epoch: 5| Step: 9
Training loss: 3.486091362102307
Validation loss: 3.392112718949323

Epoch: 5| Step: 10
Training loss: 3.789838259222535
Validation loss: 3.3921226723619693

Epoch: 158| Step: 0
Training loss: 3.601707339736031
Validation loss: 3.3871017954584532

Epoch: 5| Step: 1
Training loss: 3.5819729433129415
Validation loss: 3.386917533272799

Epoch: 5| Step: 2
Training loss: 4.103443114245121
Validation loss: 3.387160821241749

Epoch: 5| Step: 3
Training loss: 4.341573705184427
Validation loss: 3.387564043988719

Epoch: 5| Step: 4
Training loss: 2.6488525605519695
Validation loss: 3.3884657347881717

Epoch: 5| Step: 5
Training loss: 3.5843470418516485
Validation loss: 3.3866340077897163

Epoch: 5| Step: 6
Training loss: 3.1797644303596715
Validation loss: 3.3866084926627282

Epoch: 5| Step: 7
Training loss: 3.3020402843344714
Validation loss: 3.3871045611087416

Epoch: 5| Step: 8
Training loss: 4.02320947093505
Validation loss: 3.387193292325693

Epoch: 5| Step: 9
Training loss: 3.6578215783490102
Validation loss: 3.386214625719895

Epoch: 5| Step: 10
Training loss: 3.367970245084915
Validation loss: 3.386090039601418

Epoch: 159| Step: 0
Training loss: 2.5506065507449165
Validation loss: 3.384687555268863

Epoch: 5| Step: 1
Training loss: 3.3392293442994547
Validation loss: 3.386639153788888

Epoch: 5| Step: 2
Training loss: 3.740268286807753
Validation loss: 3.3847433647745118

Epoch: 5| Step: 3
Training loss: 4.043091408163514
Validation loss: 3.385639034316821

Epoch: 5| Step: 4
Training loss: 3.2029792566404858
Validation loss: 3.3881153405858626

Epoch: 5| Step: 5
Training loss: 4.635437400285735
Validation loss: 3.3888831467772875

Epoch: 5| Step: 6
Training loss: 3.838891533168159
Validation loss: 3.3874776852113446

Epoch: 5| Step: 7
Training loss: 4.0174803251343745
Validation loss: 3.3853388568023233

Epoch: 5| Step: 8
Training loss: 3.6054024902074446
Validation loss: 3.3856810228801497

Epoch: 5| Step: 9
Training loss: 3.029100107951082
Validation loss: 3.3839408415373433

Epoch: 5| Step: 10
Training loss: 3.1757259950605192
Validation loss: 3.3853802031390474

Epoch: 160| Step: 0
Training loss: 3.836422021414172
Validation loss: 3.382871683986017

Epoch: 5| Step: 1
Training loss: 3.252816813562549
Validation loss: 3.384598432660578

Epoch: 5| Step: 2
Training loss: 2.8422728674065425
Validation loss: 3.38165676181498

Epoch: 5| Step: 3
Training loss: 3.1212804401885634
Validation loss: 3.383719731595027

Epoch: 5| Step: 4
Training loss: 4.201094693619255
Validation loss: 3.382474512437826

Epoch: 5| Step: 5
Training loss: 4.2002492376580784
Validation loss: 3.3818034892670776

Epoch: 5| Step: 6
Training loss: 3.9187842116619285
Validation loss: 3.385508322157359

Epoch: 5| Step: 7
Training loss: 4.1884516303684975
Validation loss: 3.381831793931667

Epoch: 5| Step: 8
Training loss: 2.9865960449429623
Validation loss: 3.382934311968411

Epoch: 5| Step: 9
Training loss: 3.2887518004322236
Validation loss: 3.380745348881827

Epoch: 5| Step: 10
Training loss: 3.4548164471285028
Validation loss: 3.3827074151052337

Epoch: 161| Step: 0
Training loss: 3.3223933622011472
Validation loss: 3.3802064852994924

Epoch: 5| Step: 1
Training loss: 3.646547403797138
Validation loss: 3.380815163909167

Epoch: 5| Step: 2
Training loss: 3.8272121041607265
Validation loss: 3.3820769273723643

Epoch: 5| Step: 3
Training loss: 4.3183732880118475
Validation loss: 3.3795823785913757

Epoch: 5| Step: 4
Training loss: 3.813154946025013
Validation loss: 3.3802431535402357

Epoch: 5| Step: 5
Training loss: 3.921735175934389
Validation loss: 3.3796154003811782

Epoch: 5| Step: 6
Training loss: 3.7977242481553155
Validation loss: 3.3796474099391944

Epoch: 5| Step: 7
Training loss: 2.5699112877582024
Validation loss: 3.3802425346702742

Epoch: 5| Step: 8
Training loss: 3.7350719870864957
Validation loss: 3.3797019418521623

Epoch: 5| Step: 9
Training loss: 2.9040936089132967
Validation loss: 3.3787406251531675

Epoch: 5| Step: 10
Training loss: 3.443671633733955
Validation loss: 3.3787063625812976

Epoch: 162| Step: 0
Training loss: 3.2966901537524924
Validation loss: 3.3787354018709643

Epoch: 5| Step: 1
Training loss: 3.614190394492465
Validation loss: 3.377988805250209

Epoch: 5| Step: 2
Training loss: 3.7429858413334736
Validation loss: 3.37848743994471

Epoch: 5| Step: 3
Training loss: 2.8316089394178383
Validation loss: 3.3777135842550576

Epoch: 5| Step: 4
Training loss: 3.0141276857279258
Validation loss: 3.377244715587752

Epoch: 5| Step: 5
Training loss: 4.133317134169142
Validation loss: 3.3768664174266916

Epoch: 5| Step: 6
Training loss: 4.114713616863719
Validation loss: 3.3768774816598577

Epoch: 5| Step: 7
Training loss: 3.397997737800694
Validation loss: 3.377902951511371

Epoch: 5| Step: 8
Training loss: 3.7408276597833527
Validation loss: 3.3768074683061293

Epoch: 5| Step: 9
Training loss: 3.402206821073189
Validation loss: 3.376517046416301

Epoch: 5| Step: 10
Training loss: 4.148920925443272
Validation loss: 3.375679889532392

Epoch: 163| Step: 0
Training loss: 3.019250459433929
Validation loss: 3.376428059687873

Epoch: 5| Step: 1
Training loss: 4.041713176866059
Validation loss: 3.375168993238563

Epoch: 5| Step: 2
Training loss: 3.1154257019028955
Validation loss: 3.3829337284502943

Epoch: 5| Step: 3
Training loss: 2.996943665355255
Validation loss: 3.3912818241877023

Epoch: 5| Step: 4
Training loss: 3.371659780568514
Validation loss: 3.4003167108648342

Epoch: 5| Step: 5
Training loss: 3.0161100797928007
Validation loss: 3.3817966075090324

Epoch: 5| Step: 6
Training loss: 3.3652492529506435
Validation loss: 3.3789818661321127

Epoch: 5| Step: 7
Training loss: 4.168308977078541
Validation loss: 3.3779746512666478

Epoch: 5| Step: 8
Training loss: 3.895281108266071
Validation loss: 3.37575281058034

Epoch: 5| Step: 9
Training loss: 4.514498982729255
Validation loss: 3.3767764278948054

Epoch: 5| Step: 10
Training loss: 3.7482139148632787
Validation loss: 3.3743190040355806

Epoch: 164| Step: 0
Training loss: 3.0651778366496267
Validation loss: 3.371534291632953

Epoch: 5| Step: 1
Training loss: 3.7522704562658236
Validation loss: 3.3725972116621086

Epoch: 5| Step: 2
Training loss: 4.298113058499911
Validation loss: 3.3735749621341764

Epoch: 5| Step: 3
Training loss: 2.711746227110908
Validation loss: 3.3749169552520497

Epoch: 5| Step: 4
Training loss: 2.7169339483415635
Validation loss: 3.3734662738587002

Epoch: 5| Step: 5
Training loss: 3.567860234871682
Validation loss: 3.3736647771772748

Epoch: 5| Step: 6
Training loss: 4.266010867820807
Validation loss: 3.372034449458032

Epoch: 5| Step: 7
Training loss: 3.409501370081897
Validation loss: 3.3730510308800925

Epoch: 5| Step: 8
Training loss: 3.9189415405772405
Validation loss: 3.3720853488327998

Epoch: 5| Step: 9
Training loss: 3.8071036999073384
Validation loss: 3.3710469803150023

Epoch: 5| Step: 10
Training loss: 3.7057157700761816
Validation loss: 3.372312608398998

Epoch: 165| Step: 0
Training loss: 3.1984278035354667
Validation loss: 3.3704875524155735

Epoch: 5| Step: 1
Training loss: 4.0708361268725355
Validation loss: 3.3722759147428114

Epoch: 5| Step: 2
Training loss: 3.899257413152335
Validation loss: 3.3715001991507947

Epoch: 5| Step: 3
Training loss: 3.8287013028815675
Validation loss: 3.373551099101974

Epoch: 5| Step: 4
Training loss: 3.433725122362357
Validation loss: 3.3712992369003656

Epoch: 5| Step: 5
Training loss: 3.4529943657239985
Validation loss: 3.3709022776445035

Epoch: 5| Step: 6
Training loss: 4.266251626292426
Validation loss: 3.3732363073982086

Epoch: 5| Step: 7
Training loss: 3.1504000091885964
Validation loss: 3.371375175731979

Epoch: 5| Step: 8
Training loss: 3.4446029797511284
Validation loss: 3.3727648210541465

Epoch: 5| Step: 9
Training loss: 3.2644579686622706
Validation loss: 3.370556930363612

Epoch: 5| Step: 10
Training loss: 3.343604396608987
Validation loss: 3.3706466295967

Epoch: 166| Step: 0
Training loss: 3.6046681284952373
Validation loss: 3.3705518815068105

Epoch: 5| Step: 1
Training loss: 3.48435118799669
Validation loss: 3.3711538408682173

Epoch: 5| Step: 2
Training loss: 4.277163594950367
Validation loss: 3.370455180520493

Epoch: 5| Step: 3
Training loss: 3.2664839057660178
Validation loss: 3.370274382028496

Epoch: 5| Step: 4
Training loss: 3.336414169097036
Validation loss: 3.3703964493811958

Epoch: 5| Step: 5
Training loss: 2.9669037549152444
Validation loss: 3.37075572974382

Epoch: 5| Step: 6
Training loss: 4.071061956778921
Validation loss: 3.3697263160357736

Epoch: 5| Step: 7
Training loss: 3.7260365624837632
Validation loss: 3.367961170252714

Epoch: 5| Step: 8
Training loss: 3.6873589181581985
Validation loss: 3.36949063378632

Epoch: 5| Step: 9
Training loss: 3.114791982204787
Validation loss: 3.3711712767383264

Epoch: 5| Step: 10
Training loss: 3.8246775771737855
Validation loss: 3.368808641310861

Epoch: 167| Step: 0
Training loss: 3.8005902986302
Validation loss: 3.367934108504245

Epoch: 5| Step: 1
Training loss: 3.863881557252572
Validation loss: 3.369574910893083

Epoch: 5| Step: 2
Training loss: 3.663239539151598
Validation loss: 3.3691267929994035

Epoch: 5| Step: 3
Training loss: 3.4529106798592313
Validation loss: 3.369154660869061

Epoch: 5| Step: 4
Training loss: 3.465731845649941
Validation loss: 3.368416334057941

Epoch: 5| Step: 5
Training loss: 4.055205618916793
Validation loss: 3.3674816826016465

Epoch: 5| Step: 6
Training loss: 3.598093741425106
Validation loss: 3.3676451587181435

Epoch: 5| Step: 7
Training loss: 3.672458423771277
Validation loss: 3.367889931742194

Epoch: 5| Step: 8
Training loss: 2.89001177907477
Validation loss: 3.3647552469681106

Epoch: 5| Step: 9
Training loss: 3.3907968503936723
Validation loss: 3.3685770159205988

Epoch: 5| Step: 10
Training loss: 3.5389541710448666
Validation loss: 3.369939915914491

Epoch: 168| Step: 0
Training loss: 4.177764963802229
Validation loss: 3.366032820431081

Epoch: 5| Step: 1
Training loss: 3.8550311519487255
Validation loss: 3.3661032985595485

Epoch: 5| Step: 2
Training loss: 3.842863027068752
Validation loss: 3.3658797418306086

Epoch: 5| Step: 3
Training loss: 3.852390409243899
Validation loss: 3.3653597210100044

Epoch: 5| Step: 4
Training loss: 3.1208135409845896
Validation loss: 3.366005246598419

Epoch: 5| Step: 5
Training loss: 3.4964671697396765
Validation loss: 3.3660663986017707

Epoch: 5| Step: 6
Training loss: 3.2169827544770175
Validation loss: 3.366238721365429

Epoch: 5| Step: 7
Training loss: 3.4345049207860106
Validation loss: 3.367436889339159

Epoch: 5| Step: 8
Training loss: 3.454718312816639
Validation loss: 3.364541588051915

Epoch: 5| Step: 9
Training loss: 3.846418493409217
Validation loss: 3.364679862749275

Epoch: 5| Step: 10
Training loss: 2.895304094066656
Validation loss: 3.3661764514347903

Epoch: 169| Step: 0
Training loss: 3.781621236941571
Validation loss: 3.3645710501863633

Epoch: 5| Step: 1
Training loss: 3.5937807828165322
Validation loss: 3.3636029731914503

Epoch: 5| Step: 2
Training loss: 3.330675750534746
Validation loss: 3.364011510144947

Epoch: 5| Step: 3
Training loss: 2.9521129024283748
Validation loss: 3.3638618346100455

Epoch: 5| Step: 4
Training loss: 3.8945216998535113
Validation loss: 3.3646012248623256

Epoch: 5| Step: 5
Training loss: 3.2924465430575487
Validation loss: 3.366185482336858

Epoch: 5| Step: 6
Training loss: 3.7101317484615532
Validation loss: 3.36808760675363

Epoch: 5| Step: 7
Training loss: 3.2749355047733086
Validation loss: 3.3692955641797706

Epoch: 5| Step: 8
Training loss: 4.1101254550321835
Validation loss: 3.363007288382344

Epoch: 5| Step: 9
Training loss: 3.085377161845041
Validation loss: 3.3634749565144806

Epoch: 5| Step: 10
Training loss: 4.324664002525654
Validation loss: 3.3620112323004685

Epoch: 170| Step: 0
Training loss: 4.1355836515880355
Validation loss: 3.3628683537192714

Epoch: 5| Step: 1
Training loss: 3.3855800804410316
Validation loss: 3.3617549935342863

Epoch: 5| Step: 2
Training loss: 2.82404838670769
Validation loss: 3.3626259963718756

Epoch: 5| Step: 3
Training loss: 3.819703348035314
Validation loss: 3.3633262884040884

Epoch: 5| Step: 4
Training loss: 3.5157820602937546
Validation loss: 3.364587469443509

Epoch: 5| Step: 5
Training loss: 3.786195153802268
Validation loss: 3.36285001182913

Epoch: 5| Step: 6
Training loss: 3.5436731077864154
Validation loss: 3.362316790852309

Epoch: 5| Step: 7
Training loss: 3.6048624473286295
Validation loss: 3.3621172576318816

Epoch: 5| Step: 8
Training loss: 3.36129336918224
Validation loss: 3.363178607718409

Epoch: 5| Step: 9
Training loss: 3.8503626565922686
Validation loss: 3.36352240008151

Epoch: 5| Step: 10
Training loss: 3.4790035978618286
Validation loss: 3.362938857001065

Epoch: 171| Step: 0
Training loss: 3.636056546769276
Validation loss: 3.3603757756014683

Epoch: 5| Step: 1
Training loss: 3.5885590588388556
Validation loss: 3.360490997912158

Epoch: 5| Step: 2
Training loss: 2.8301642215919554
Validation loss: 3.361108006378433

Epoch: 5| Step: 3
Training loss: 3.6384037428884453
Validation loss: 3.3590270861723006

Epoch: 5| Step: 4
Training loss: 3.519969104284466
Validation loss: 3.3609007506811044

Epoch: 5| Step: 5
Training loss: 3.722779214915627
Validation loss: 3.3587100722395293

Epoch: 5| Step: 6
Training loss: 3.0234662037356785
Validation loss: 3.3584149228123628

Epoch: 5| Step: 7
Training loss: 3.725608719622348
Validation loss: 3.3600750990403685

Epoch: 5| Step: 8
Training loss: 4.018609863495753
Validation loss: 3.361416786172725

Epoch: 5| Step: 9
Training loss: 3.9845676749522543
Validation loss: 3.3593685607009

Epoch: 5| Step: 10
Training loss: 3.580616579077512
Validation loss: 3.3592954534149624

Epoch: 172| Step: 0
Training loss: 4.227595345873025
Validation loss: 3.358825385274311

Epoch: 5| Step: 1
Training loss: 4.229340322653089
Validation loss: 3.3613198551767125

Epoch: 5| Step: 2
Training loss: 3.3311424366831988
Validation loss: 3.3576875592845346

Epoch: 5| Step: 3
Training loss: 2.862426130516058
Validation loss: 3.3576613279035143

Epoch: 5| Step: 4
Training loss: 3.466775693157121
Validation loss: 3.3583116707214735

Epoch: 5| Step: 5
Training loss: 4.033983353708596
Validation loss: 3.356815061216828

Epoch: 5| Step: 6
Training loss: 2.8451921767508153
Validation loss: 3.3564342481280236

Epoch: 5| Step: 7
Training loss: 3.7652343294088464
Validation loss: 3.3556246963307794

Epoch: 5| Step: 8
Training loss: 3.3414745253374303
Validation loss: 3.354006298289703

Epoch: 5| Step: 9
Training loss: 3.671358892003287
Validation loss: 3.3562988849653848

Epoch: 5| Step: 10
Training loss: 3.2888574966731
Validation loss: 3.3540561795149975

Epoch: 173| Step: 0
Training loss: 3.3109638322878525
Validation loss: 3.3544978994327534

Epoch: 5| Step: 1
Training loss: 4.125155359290272
Validation loss: 3.3524124647661426

Epoch: 5| Step: 2
Training loss: 3.0825530602806825
Validation loss: 3.3535199029355907

Epoch: 5| Step: 3
Training loss: 4.2633121913676995
Validation loss: 3.3555775108733785

Epoch: 5| Step: 4
Training loss: 3.3372051323064893
Validation loss: 3.3545425979894388

Epoch: 5| Step: 5
Training loss: 3.9106896157677897
Validation loss: 3.352800694291109

Epoch: 5| Step: 6
Training loss: 3.8443555897591857
Validation loss: 3.3530751335475117

Epoch: 5| Step: 7
Training loss: 3.5191560771787933
Validation loss: 3.354280765778472

Epoch: 5| Step: 8
Training loss: 3.1113684316970933
Validation loss: 3.3539655015304555

Epoch: 5| Step: 9
Training loss: 3.283890597176409
Validation loss: 3.352443949470877

Epoch: 5| Step: 10
Training loss: 3.3505278726570324
Validation loss: 3.3518325938162046

Epoch: 174| Step: 0
Training loss: 3.704914288475339
Validation loss: 3.3521242694703943

Epoch: 5| Step: 1
Training loss: 3.8323201761777757
Validation loss: 3.3515518233818598

Epoch: 5| Step: 2
Training loss: 3.409591016211057
Validation loss: 3.35173458177068

Epoch: 5| Step: 3
Training loss: 4.37331466911179
Validation loss: 3.3521747400415487

Epoch: 5| Step: 4
Training loss: 3.6282762652003515
Validation loss: 3.3516666315765833

Epoch: 5| Step: 5
Training loss: 3.408212358959554
Validation loss: 3.3518360998751136

Epoch: 5| Step: 6
Training loss: 3.233765033204798
Validation loss: 3.3513147214872174

Epoch: 5| Step: 7
Training loss: 2.9444039559929434
Validation loss: 3.350939584286784

Epoch: 5| Step: 8
Training loss: 3.753987290602211
Validation loss: 3.351702129716737

Epoch: 5| Step: 9
Training loss: 3.6721656197324646
Validation loss: 3.3497947251019227

Epoch: 5| Step: 10
Training loss: 3.127561206294945
Validation loss: 3.3502267040547635

Epoch: 175| Step: 0
Training loss: 3.3414709577701096
Validation loss: 3.3506499585462257

Epoch: 5| Step: 1
Training loss: 3.761253890710291
Validation loss: 3.350683571515911

Epoch: 5| Step: 2
Training loss: 3.51981331460254
Validation loss: 3.349832199196757

Epoch: 5| Step: 3
Training loss: 4.054008647561319
Validation loss: 3.350274925968432

Epoch: 5| Step: 4
Training loss: 3.7612457770301386
Validation loss: 3.3512878741453203

Epoch: 5| Step: 5
Training loss: 3.7070830877154717
Validation loss: 3.3503268201078558

Epoch: 5| Step: 6
Training loss: 3.787590700580583
Validation loss: 3.355432232766881

Epoch: 5| Step: 7
Training loss: 3.5890203783206602
Validation loss: 3.348907234282919

Epoch: 5| Step: 8
Training loss: 3.4124810857563053
Validation loss: 3.349886899632808

Epoch: 5| Step: 9
Training loss: 2.8725862736773005
Validation loss: 3.349854270497037

Epoch: 5| Step: 10
Training loss: 3.3706723476927403
Validation loss: 3.345970827789715

Epoch: 176| Step: 0
Training loss: 3.8320607408794487
Validation loss: 3.3465703095850383

Epoch: 5| Step: 1
Training loss: 3.389545602867868
Validation loss: 3.3477157951424985

Epoch: 5| Step: 2
Training loss: 3.3382461742412626
Validation loss: 3.3489858632917846

Epoch: 5| Step: 3
Training loss: 3.734684249012135
Validation loss: 3.348086838694749

Epoch: 5| Step: 4
Training loss: 3.8177357976670643
Validation loss: 3.3465353177640607

Epoch: 5| Step: 5
Training loss: 2.750805823431137
Validation loss: 3.3474586091425786

Epoch: 5| Step: 6
Training loss: 3.7181361356931735
Validation loss: 3.347383367673069

Epoch: 5| Step: 7
Training loss: 4.46658977233593
Validation loss: 3.3481217729529646

Epoch: 5| Step: 8
Training loss: 3.696459989236508
Validation loss: 3.3453023222780303

Epoch: 5| Step: 9
Training loss: 2.6635729208435195
Validation loss: 3.3462658505592193

Epoch: 5| Step: 10
Training loss: 3.5726143993643382
Validation loss: 3.3456015096856433

Epoch: 177| Step: 0
Training loss: 3.367070100866323
Validation loss: 3.3456878704863104

Epoch: 5| Step: 1
Training loss: 4.402613661174524
Validation loss: 3.3446577256708045

Epoch: 5| Step: 2
Training loss: 3.6601523416634683
Validation loss: 3.3444885597494176

Epoch: 5| Step: 3
Training loss: 2.9957353161166487
Validation loss: 3.3447987388953306

Epoch: 5| Step: 4
Training loss: 3.569310154019392
Validation loss: 3.3448512744340717

Epoch: 5| Step: 5
Training loss: 3.239411049991289
Validation loss: 3.343620971729521

Epoch: 5| Step: 6
Training loss: 3.751732616706353
Validation loss: 3.343736326710857

Epoch: 5| Step: 7
Training loss: 3.7164063321158283
Validation loss: 3.344932435252788

Epoch: 5| Step: 8
Training loss: 3.1375182618601376
Validation loss: 3.3441326500115722

Epoch: 5| Step: 9
Training loss: 3.437727764560123
Validation loss: 3.3435067276259645

Epoch: 5| Step: 10
Training loss: 3.881162972326881
Validation loss: 3.343072320568163

Epoch: 178| Step: 0
Training loss: 3.084143162819633
Validation loss: 3.3433777513096024

Epoch: 5| Step: 1
Training loss: 3.732575944867579
Validation loss: 3.3454807660336328

Epoch: 5| Step: 2
Training loss: 3.9260163953208504
Validation loss: 3.345864707621812

Epoch: 5| Step: 3
Training loss: 3.4619323816070318
Validation loss: 3.3503041076253557

Epoch: 5| Step: 4
Training loss: 3.924403131866838
Validation loss: 3.3437747657310317

Epoch: 5| Step: 5
Training loss: 4.569450414486856
Validation loss: 3.343669040494509

Epoch: 5| Step: 6
Training loss: 2.96596693795028
Validation loss: 3.33992162907632

Epoch: 5| Step: 7
Training loss: 3.229700368441269
Validation loss: 3.341013470476989

Epoch: 5| Step: 8
Training loss: 2.544191503052654
Validation loss: 3.3413146623595353

Epoch: 5| Step: 9
Training loss: 4.150752741555825
Validation loss: 3.3409228835526164

Epoch: 5| Step: 10
Training loss: 3.201974503986896
Validation loss: 3.3419215397708775

Epoch: 179| Step: 0
Training loss: 3.522925092227244
Validation loss: 3.341536588123814

Epoch: 5| Step: 1
Training loss: 3.6870067719163777
Validation loss: 3.3415052170001127

Epoch: 5| Step: 2
Training loss: 3.4480738916113323
Validation loss: 3.3408929769128006

Epoch: 5| Step: 3
Training loss: 2.805069156277004
Validation loss: 3.3408203692852765

Epoch: 5| Step: 4
Training loss: 4.174330770798261
Validation loss: 3.3397473350913867

Epoch: 5| Step: 5
Training loss: 3.215141569968795
Validation loss: 3.341640665413827

Epoch: 5| Step: 6
Training loss: 4.118448545685853
Validation loss: 3.3436540941222335

Epoch: 5| Step: 7
Training loss: 3.380109663092855
Validation loss: 3.342447581745527

Epoch: 5| Step: 8
Training loss: 3.6435350567348412
Validation loss: 3.340157134302163

Epoch: 5| Step: 9
Training loss: 3.118644354794938
Validation loss: 3.337930036081348

Epoch: 5| Step: 10
Training loss: 3.98650934236399
Validation loss: 3.339564124127032

Epoch: 180| Step: 0
Training loss: 3.103094150355293
Validation loss: 3.3388140295361177

Epoch: 5| Step: 1
Training loss: 4.238964563652239
Validation loss: 3.3394270991014556

Epoch: 5| Step: 2
Training loss: 3.284688691785101
Validation loss: 3.3378772886897594

Epoch: 5| Step: 3
Training loss: 3.085863329804866
Validation loss: 3.338246284827548

Epoch: 5| Step: 4
Training loss: 3.0493129269020383
Validation loss: 3.337166726699898

Epoch: 5| Step: 5
Training loss: 3.2906665650846363
Validation loss: 3.336951747315379

Epoch: 5| Step: 6
Training loss: 4.171971009253394
Validation loss: 3.335869569243615

Epoch: 5| Step: 7
Training loss: 3.821041981454227
Validation loss: 3.336546249813928

Epoch: 5| Step: 8
Training loss: 3.4712505778228753
Validation loss: 3.3356922099151207

Epoch: 5| Step: 9
Training loss: 3.7305992543026667
Validation loss: 3.3362423559918173

Epoch: 5| Step: 10
Training loss: 3.7911324736065453
Validation loss: 3.336497668125543

Epoch: 181| Step: 0
Training loss: 4.048455949488789
Validation loss: 3.3354994831714344

Epoch: 5| Step: 1
Training loss: 3.4174336913791237
Validation loss: 3.3357874532112763

Epoch: 5| Step: 2
Training loss: 3.2632922734244922
Validation loss: 3.3345820946293068

Epoch: 5| Step: 3
Training loss: 3.009532248566806
Validation loss: 3.3371382052922476

Epoch: 5| Step: 4
Training loss: 3.646114549236261
Validation loss: 3.335446397586698

Epoch: 5| Step: 5
Training loss: 4.027858519932372
Validation loss: 3.3349374500429425

Epoch: 5| Step: 6
Training loss: 3.9376100797252147
Validation loss: 3.3346666858485126

Epoch: 5| Step: 7
Training loss: 2.903953547345267
Validation loss: 3.334322043396227

Epoch: 5| Step: 8
Training loss: 3.974606615670111
Validation loss: 3.33409283250593

Epoch: 5| Step: 9
Training loss: 3.108343365391419
Validation loss: 3.3338449798168326

Epoch: 5| Step: 10
Training loss: 3.6499784756378535
Validation loss: 3.333786806414253

Epoch: 182| Step: 0
Training loss: 3.3454261927948714
Validation loss: 3.33319008324564

Epoch: 5| Step: 1
Training loss: 4.626216831454278
Validation loss: 3.334753920241835

Epoch: 5| Step: 2
Training loss: 3.571441405137028
Validation loss: 3.336159194834701

Epoch: 5| Step: 3
Training loss: 3.597496799576259
Validation loss: 3.3349524585424692

Epoch: 5| Step: 4
Training loss: 3.6578167549900495
Validation loss: 3.334097979632309

Epoch: 5| Step: 5
Training loss: 3.2548908699363968
Validation loss: 3.333547081298108

Epoch: 5| Step: 6
Training loss: 3.4825196394191993
Validation loss: 3.332653045966687

Epoch: 5| Step: 7
Training loss: 1.8835592727954995
Validation loss: 3.3329673817445777

Epoch: 5| Step: 8
Training loss: 3.036206784088032
Validation loss: 3.333425328820791

Epoch: 5| Step: 9
Training loss: 3.7511592344789886
Validation loss: 3.332566382765332

Epoch: 5| Step: 10
Training loss: 4.4173835076697845
Validation loss: 3.3326422687681965

Epoch: 183| Step: 0
Training loss: 3.680546168349349
Validation loss: 3.330946355036553

Epoch: 5| Step: 1
Training loss: 3.3863636433459985
Validation loss: 3.3311239616618122

Epoch: 5| Step: 2
Training loss: 3.5526553203391793
Validation loss: 3.3305605943900503

Epoch: 5| Step: 3
Training loss: 3.1168641039755594
Validation loss: 3.331042647569604

Epoch: 5| Step: 4
Training loss: 2.970853682595889
Validation loss: 3.3302781475570717

Epoch: 5| Step: 5
Training loss: 3.2692041085308308
Validation loss: 3.3314208625339434

Epoch: 5| Step: 6
Training loss: 3.068558908017354
Validation loss: 3.329784478157878

Epoch: 5| Step: 7
Training loss: 4.238638782802694
Validation loss: 3.3307417429218087

Epoch: 5| Step: 8
Training loss: 3.720561379763922
Validation loss: 3.329866705271464

Epoch: 5| Step: 9
Training loss: 3.650205130887659
Validation loss: 3.332588609955128

Epoch: 5| Step: 10
Training loss: 4.3843380046216245
Validation loss: 3.330459930335194

Epoch: 184| Step: 0
Training loss: 3.1970161056327653
Validation loss: 3.3293945288321933

Epoch: 5| Step: 1
Training loss: 3.434278053255198
Validation loss: 3.329191303686933

Epoch: 5| Step: 2
Training loss: 3.90457153880837
Validation loss: 3.3305946225492877

Epoch: 5| Step: 3
Training loss: 3.1254317938991134
Validation loss: 3.33082182826672

Epoch: 5| Step: 4
Training loss: 3.6427468595720955
Validation loss: 3.3314144369213192

Epoch: 5| Step: 5
Training loss: 3.7861705952299722
Validation loss: 3.334672550132837

Epoch: 5| Step: 6
Training loss: 3.790870596908753
Validation loss: 3.3340832164161474

Epoch: 5| Step: 7
Training loss: 3.934206963087448
Validation loss: 3.3373602566835356

Epoch: 5| Step: 8
Training loss: 2.9404399039282
Validation loss: 3.3292686649969108

Epoch: 5| Step: 9
Training loss: 3.1409508075912314
Validation loss: 3.330730357638884

Epoch: 5| Step: 10
Training loss: 4.136877127147035
Validation loss: 3.329649770110273

Epoch: 185| Step: 0
Training loss: 2.8811923801179957
Validation loss: 3.3291100409579037

Epoch: 5| Step: 1
Training loss: 3.5761540077550653
Validation loss: 3.33067132318371

Epoch: 5| Step: 2
Training loss: 2.547789239907086
Validation loss: 3.327927695212733

Epoch: 5| Step: 3
Training loss: 3.8611827740014593
Validation loss: 3.3286166265372303

Epoch: 5| Step: 4
Training loss: 3.0360644931904073
Validation loss: 3.3268918530698923

Epoch: 5| Step: 5
Training loss: 3.5730187908439723
Validation loss: 3.328014161835475

Epoch: 5| Step: 6
Training loss: 3.776858214739225
Validation loss: 3.3263194021626457

Epoch: 5| Step: 7
Training loss: 3.6200137868376316
Validation loss: 3.3275628214722968

Epoch: 5| Step: 8
Training loss: 3.2383064296649984
Validation loss: 3.3244970956151425

Epoch: 5| Step: 9
Training loss: 4.396418865432641
Validation loss: 3.326328906593017

Epoch: 5| Step: 10
Training loss: 4.337879852460172
Validation loss: 3.3252430524373455

Epoch: 186| Step: 0
Training loss: 3.5759102576172443
Validation loss: 3.3273764471421163

Epoch: 5| Step: 1
Training loss: 3.213121251696018
Validation loss: 3.3249914652322956

Epoch: 5| Step: 2
Training loss: 3.800289675061611
Validation loss: 3.3249646644093267

Epoch: 5| Step: 3
Training loss: 3.627776299541718
Validation loss: 3.324245251443575

Epoch: 5| Step: 4
Training loss: 3.5284166700359663
Validation loss: 3.324728599659115

Epoch: 5| Step: 5
Training loss: 3.87120017512637
Validation loss: 3.329558398177212

Epoch: 5| Step: 6
Training loss: 3.1751990728971395
Validation loss: 3.3293032345966465

Epoch: 5| Step: 7
Training loss: 3.032640590443527
Validation loss: 3.3259030688230946

Epoch: 5| Step: 8
Training loss: 3.6320072717299747
Validation loss: 3.322868326500105

Epoch: 5| Step: 9
Training loss: 4.214777906184609
Validation loss: 3.323021662984577

Epoch: 5| Step: 10
Training loss: 3.2541376331579257
Validation loss: 3.322249645543826

Epoch: 187| Step: 0
Training loss: 3.6828380792609114
Validation loss: 3.32331634400464

Epoch: 5| Step: 1
Training loss: 2.5842109748054023
Validation loss: 3.323227337486155

Epoch: 5| Step: 2
Training loss: 3.6375449580924157
Validation loss: 3.322705063878287

Epoch: 5| Step: 3
Training loss: 3.480630958621897
Validation loss: 3.3227283739337126

Epoch: 5| Step: 4
Training loss: 3.6862697812154694
Validation loss: 3.322176704538941

Epoch: 5| Step: 5
Training loss: 3.485827771780557
Validation loss: 3.3215584165090086

Epoch: 5| Step: 6
Training loss: 4.19216181192337
Validation loss: 3.3226820483943538

Epoch: 5| Step: 7
Training loss: 3.801062264791293
Validation loss: 3.321889138216012

Epoch: 5| Step: 8
Training loss: 3.2497976680276075
Validation loss: 3.3218612535249927

Epoch: 5| Step: 9
Training loss: 3.422091681879229
Validation loss: 3.3237375798740145

Epoch: 5| Step: 10
Training loss: 3.695268755728464
Validation loss: 3.321575692852084

Epoch: 188| Step: 0
Training loss: 2.9220931843776023
Validation loss: 3.3209651576293306

Epoch: 5| Step: 1
Training loss: 4.149632743303542
Validation loss: 3.3214679380670766

Epoch: 5| Step: 2
Training loss: 3.529080424930818
Validation loss: 3.321641949387952

Epoch: 5| Step: 3
Training loss: 3.529930746031336
Validation loss: 3.320793080979839

Epoch: 5| Step: 4
Training loss: 3.000681164022615
Validation loss: 3.320514330680309

Epoch: 5| Step: 5
Training loss: 3.777443096507355
Validation loss: 3.320292749412518

Epoch: 5| Step: 6
Training loss: 2.9952104800843835
Validation loss: 3.32152998258932

Epoch: 5| Step: 7
Training loss: 3.6839347026227918
Validation loss: 3.3211944269710774

Epoch: 5| Step: 8
Training loss: 3.904717106456948
Validation loss: 3.3204533249236308

Epoch: 5| Step: 9
Training loss: 3.4071308361982733
Validation loss: 3.320557321863846

Epoch: 5| Step: 10
Training loss: 4.021557177810532
Validation loss: 3.3210382765439475

Epoch: 189| Step: 0
Training loss: 3.1401183065978824
Validation loss: 3.320151598009758

Epoch: 5| Step: 1
Training loss: 4.020977564515975
Validation loss: 3.3196112651945677

Epoch: 5| Step: 2
Training loss: 3.230742105083683
Validation loss: 3.319675188566888

Epoch: 5| Step: 3
Training loss: 3.8570947745015682
Validation loss: 3.3200780039915943

Epoch: 5| Step: 4
Training loss: 3.969186353349662
Validation loss: 3.320551341549001

Epoch: 5| Step: 5
Training loss: 3.218028459877119
Validation loss: 3.3199178226820543

Epoch: 5| Step: 6
Training loss: 3.7272036338796624
Validation loss: 3.318388882128081

Epoch: 5| Step: 7
Training loss: 3.593822179981659
Validation loss: 3.3170823396422957

Epoch: 5| Step: 8
Training loss: 3.334448882037904
Validation loss: 3.3164243107356874

Epoch: 5| Step: 9
Training loss: 3.1559670198697214
Validation loss: 3.3162509641207656

Epoch: 5| Step: 10
Training loss: 3.6739285834052238
Validation loss: 3.3159438681675635

Epoch: 190| Step: 0
Training loss: 4.145292595083312
Validation loss: 3.3162039188208676

Epoch: 5| Step: 1
Training loss: 3.064604678275233
Validation loss: 3.3168605955724204

Epoch: 5| Step: 2
Training loss: 3.2772730386628286
Validation loss: 3.3165333146645497

Epoch: 5| Step: 3
Training loss: 3.666073115309076
Validation loss: 3.316344071740752

Epoch: 5| Step: 4
Training loss: 3.6353174904718792
Validation loss: 3.319390975208696

Epoch: 5| Step: 5
Training loss: 4.167354806660303
Validation loss: 3.317700339851957

Epoch: 5| Step: 6
Training loss: 3.8409331630303347
Validation loss: 3.314526232879746

Epoch: 5| Step: 7
Training loss: 3.6210491091251167
Validation loss: 3.3157210227275336

Epoch: 5| Step: 8
Training loss: 2.9704233372620927
Validation loss: 3.3175426726476056

Epoch: 5| Step: 9
Training loss: 3.008419144129544
Validation loss: 3.31289113003759

Epoch: 5| Step: 10
Training loss: 3.36474180684905
Validation loss: 3.315411199151797

Epoch: 191| Step: 0
Training loss: 3.3628887873513973
Validation loss: 3.3152882671857142

Epoch: 5| Step: 1
Training loss: 3.696360530187554
Validation loss: 3.3147025808270456

Epoch: 5| Step: 2
Training loss: 3.8010807056605396
Validation loss: 3.316419363445845

Epoch: 5| Step: 3
Training loss: 3.3858506301136377
Validation loss: 3.3151635721604666

Epoch: 5| Step: 4
Training loss: 3.106903781055398
Validation loss: 3.3154666213590898

Epoch: 5| Step: 5
Training loss: 3.0812057337183014
Validation loss: 3.316005368181513

Epoch: 5| Step: 6
Training loss: 3.35559579166881
Validation loss: 3.3140510740015157

Epoch: 5| Step: 7
Training loss: 3.6481872080651687
Validation loss: 3.3153027320989423

Epoch: 5| Step: 8
Training loss: 3.859022487340582
Validation loss: 3.314812597282428

Epoch: 5| Step: 9
Training loss: 3.8976813980181273
Validation loss: 3.313625334154786

Epoch: 5| Step: 10
Training loss: 3.753662990663006
Validation loss: 3.3139162307898267

Epoch: 192| Step: 0
Training loss: 3.1730358085547357
Validation loss: 3.314511622261233

Epoch: 5| Step: 1
Training loss: 4.240708685255124
Validation loss: 3.314156339330714

Epoch: 5| Step: 2
Training loss: 3.164987537184731
Validation loss: 3.3133584440819046

Epoch: 5| Step: 3
Training loss: 3.891496185445944
Validation loss: 3.3122593209301403

Epoch: 5| Step: 4
Training loss: 3.2692466985737334
Validation loss: 3.313992027104348

Epoch: 5| Step: 5
Training loss: 3.371600947233776
Validation loss: 3.3128419754910445

Epoch: 5| Step: 6
Training loss: 2.7283648023924663
Validation loss: 3.3129750006202907

Epoch: 5| Step: 7
Training loss: 4.1955782275162035
Validation loss: 3.312095956429163

Epoch: 5| Step: 8
Training loss: 3.5289471975015303
Validation loss: 3.315421959676826

Epoch: 5| Step: 9
Training loss: 3.6434285252715206
Validation loss: 3.3120393337923377

Epoch: 5| Step: 10
Training loss: 3.442112273278643
Validation loss: 3.320673848611898

Epoch: 193| Step: 0
Training loss: 2.559885039877556
Validation loss: 3.3254400269769255

Epoch: 5| Step: 1
Training loss: 3.4498008504691904
Validation loss: 3.3372194622765825

Epoch: 5| Step: 2
Training loss: 3.9670098762668133
Validation loss: 3.3203249602593723

Epoch: 5| Step: 3
Training loss: 3.8459704428740658
Validation loss: 3.311401126875313

Epoch: 5| Step: 4
Training loss: 3.820221008578211
Validation loss: 3.3130440399683816

Epoch: 5| Step: 5
Training loss: 3.8110392539315736
Validation loss: 3.3092203263325084

Epoch: 5| Step: 6
Training loss: 3.6736950847704684
Validation loss: 3.3084648632079454

Epoch: 5| Step: 7
Training loss: 3.291589051953247
Validation loss: 3.307522160788499

Epoch: 5| Step: 8
Training loss: 3.269738194195606
Validation loss: 3.3091474514015893

Epoch: 5| Step: 9
Training loss: 3.6417724372872824
Validation loss: 3.309600274447189

Epoch: 5| Step: 10
Training loss: 3.4862284157222625
Validation loss: 3.308781479829644

Epoch: 194| Step: 0
Training loss: 3.226156213779867
Validation loss: 3.3093879415696006

Epoch: 5| Step: 1
Training loss: 3.604277210341121
Validation loss: 3.307150153647445

Epoch: 5| Step: 2
Training loss: 3.604890225203342
Validation loss: 3.3084673327277967

Epoch: 5| Step: 3
Training loss: 4.140494636066907
Validation loss: 3.306199725541293

Epoch: 5| Step: 4
Training loss: 3.364837038535215
Validation loss: 3.3045828624357196

Epoch: 5| Step: 5
Training loss: 2.9446645170616623
Validation loss: 3.3070122305317504

Epoch: 5| Step: 6
Training loss: 4.660739654321641
Validation loss: 3.304870150481049

Epoch: 5| Step: 7
Training loss: 3.4839114577892665
Validation loss: 3.305560429169251

Epoch: 5| Step: 8
Training loss: 3.505153948440854
Validation loss: 3.3050795732013385

Epoch: 5| Step: 9
Training loss: 3.117116979886444
Validation loss: 3.303259900829461

Epoch: 5| Step: 10
Training loss: 2.8998468884793787
Validation loss: 3.303269057175376

Epoch: 195| Step: 0
Training loss: 3.5540180623932374
Validation loss: 3.3042306240206294

Epoch: 5| Step: 1
Training loss: 3.3036985247697643
Validation loss: 3.3078806347465686

Epoch: 5| Step: 2
Training loss: 3.9154566796392776
Validation loss: 3.3044873403926847

Epoch: 5| Step: 3
Training loss: 3.2063365188436337
Validation loss: 3.3071838676564926

Epoch: 5| Step: 4
Training loss: 2.768258430467431
Validation loss: 3.3050420105453893

Epoch: 5| Step: 5
Training loss: 3.388972710439624
Validation loss: 3.3064559680380805

Epoch: 5| Step: 6
Training loss: 4.650210976685417
Validation loss: 3.3102945240110127

Epoch: 5| Step: 7
Training loss: 3.6597059821762405
Validation loss: 3.310174727611999

Epoch: 5| Step: 8
Training loss: 3.083764810700525
Validation loss: 3.307608908173225

Epoch: 5| Step: 9
Training loss: 3.554631964281149
Validation loss: 3.3141876954993905

Epoch: 5| Step: 10
Training loss: 3.5609040282594138
Validation loss: 3.308927349574648

Epoch: 196| Step: 0
Training loss: 3.093794080632144
Validation loss: 3.3109398168741095

Epoch: 5| Step: 1
Training loss: 3.056654509004011
Validation loss: 3.3124767719800263

Epoch: 5| Step: 2
Training loss: 3.4011605413827906
Validation loss: 3.3080491377833234

Epoch: 5| Step: 3
Training loss: 3.132119270928126
Validation loss: 3.3084401477611998

Epoch: 5| Step: 4
Training loss: 3.6943092193968425
Validation loss: 3.310531038771616

Epoch: 5| Step: 5
Training loss: 3.454204407881888
Validation loss: 3.31022080533122

Epoch: 5| Step: 6
Training loss: 3.3202343740808606
Validation loss: 3.3093261961803178

Epoch: 5| Step: 7
Training loss: 4.076193867483795
Validation loss: 3.3073373220540194

Epoch: 5| Step: 8
Training loss: 3.3737349788505218
Validation loss: 3.305041334156147

Epoch: 5| Step: 9
Training loss: 4.174962647779206
Validation loss: 3.3037725115882273

Epoch: 5| Step: 10
Training loss: 3.98052229765718
Validation loss: 3.3045948932632885

Epoch: 197| Step: 0
Training loss: 3.3349669427105524
Validation loss: 3.303276511530469

Epoch: 5| Step: 1
Training loss: 3.8223934941644817
Validation loss: 3.3031398027354006

Epoch: 5| Step: 2
Training loss: 3.2621469182387104
Validation loss: 3.3030090995930155

Epoch: 5| Step: 3
Training loss: 3.6505562554384907
Validation loss: 3.302915893161004

Epoch: 5| Step: 4
Training loss: 2.8426793357084903
Validation loss: 3.3019347787109905

Epoch: 5| Step: 5
Training loss: 3.4876894390105666
Validation loss: 3.304221766720988

Epoch: 5| Step: 6
Training loss: 3.863347160000836
Validation loss: 3.3024707299226375

Epoch: 5| Step: 7
Training loss: 3.9010319151542143
Validation loss: 3.3013970911390254

Epoch: 5| Step: 8
Training loss: 3.2401447525184657
Validation loss: 3.301313643950819

Epoch: 5| Step: 9
Training loss: 3.617757204477901
Validation loss: 3.3021279474310363

Epoch: 5| Step: 10
Training loss: 3.753611796220226
Validation loss: 3.301279307763455

Epoch: 198| Step: 0
Training loss: 3.6798637331736295
Validation loss: 3.3000452914195417

Epoch: 5| Step: 1
Training loss: 3.3175002451525026
Validation loss: 3.3016963281789047

Epoch: 5| Step: 2
Training loss: 3.8160276508249193
Validation loss: 3.299559729022889

Epoch: 5| Step: 3
Training loss: 4.045837505009731
Validation loss: 3.3012705466047243

Epoch: 5| Step: 4
Training loss: 3.744041541056566
Validation loss: 3.3007479055377793

Epoch: 5| Step: 5
Training loss: 2.7230891536220807
Validation loss: 3.3000439987406613

Epoch: 5| Step: 6
Training loss: 3.2604216229255876
Validation loss: 3.2987619231627896

Epoch: 5| Step: 7
Training loss: 3.809888852317952
Validation loss: 3.3002365790068784

Epoch: 5| Step: 8
Training loss: 3.6443731962646666
Validation loss: 3.3001387358457848

Epoch: 5| Step: 9
Training loss: 3.2892124024072107
Validation loss: 3.300340750035152

Epoch: 5| Step: 10
Training loss: 3.3151065000339557
Validation loss: 3.297668496843148

Epoch: 199| Step: 0
Training loss: 3.894982161670819
Validation loss: 3.2988328049143125

Epoch: 5| Step: 1
Training loss: 3.747867995421984
Validation loss: 3.2981253304293885

Epoch: 5| Step: 2
Training loss: 3.7150563079961563
Validation loss: 3.298889479377471

Epoch: 5| Step: 3
Training loss: 3.383872907736473
Validation loss: 3.300139260981566

Epoch: 5| Step: 4
Training loss: 3.1796219652625344
Validation loss: 3.3020078454330797

Epoch: 5| Step: 5
Training loss: 3.011138424704506
Validation loss: 3.3047777164219294

Epoch: 5| Step: 6
Training loss: 3.6325682199035736
Validation loss: 3.3184950574108165

Epoch: 5| Step: 7
Training loss: 3.4916714621960856
Validation loss: 3.29767981280444

Epoch: 5| Step: 8
Training loss: 2.9974219052892948
Validation loss: 3.2996737745568496

Epoch: 5| Step: 9
Training loss: 3.4938074915869426
Validation loss: 3.2965906826669724

Epoch: 5| Step: 10
Training loss: 4.229851477790907
Validation loss: 3.2966344633167464

Epoch: 200| Step: 0
Training loss: 3.0670966081954294
Validation loss: 3.296067035089433

Epoch: 5| Step: 1
Training loss: 2.4895933994318487
Validation loss: 3.2965167819627545

Epoch: 5| Step: 2
Training loss: 3.793042418906751
Validation loss: 3.295408391486264

Epoch: 5| Step: 3
Training loss: 3.2179785239082115
Validation loss: 3.296591870937693

Epoch: 5| Step: 4
Training loss: 3.774630971896329
Validation loss: 3.2992968279631754

Epoch: 5| Step: 5
Training loss: 3.5997021022036497
Validation loss: 3.3021781154445384

Epoch: 5| Step: 6
Training loss: 3.4715787333686583
Validation loss: 3.3004551802607938

Epoch: 5| Step: 7
Training loss: 4.013617462754653
Validation loss: 3.3025595040637663

Epoch: 5| Step: 8
Training loss: 3.3083980281727565
Validation loss: 3.300401751604699

Epoch: 5| Step: 9
Training loss: 4.158470077151976
Validation loss: 3.295551028957496

Epoch: 5| Step: 10
Training loss: 3.702842347508261
Validation loss: 3.294241436508529

Epoch: 201| Step: 0
Training loss: 3.6413087652973015
Validation loss: 3.296214014256573

Epoch: 5| Step: 1
Training loss: 3.4276428384323308
Validation loss: 3.2940510133146486

Epoch: 5| Step: 2
Training loss: 3.051223546983569
Validation loss: 3.2915337845842454

Epoch: 5| Step: 3
Training loss: 3.616645129677303
Validation loss: 3.2921818249226016

Epoch: 5| Step: 4
Training loss: 3.669440708419999
Validation loss: 3.2922629167743747

Epoch: 5| Step: 5
Training loss: 4.2768661441401905
Validation loss: 3.2912359845079746

Epoch: 5| Step: 6
Training loss: 3.4954353266601528
Validation loss: 3.2916939857463485

Epoch: 5| Step: 7
Training loss: 2.870551274750493
Validation loss: 3.2926279486549896

Epoch: 5| Step: 8
Training loss: 3.094562308279117
Validation loss: 3.2921207753898742

Epoch: 5| Step: 9
Training loss: 3.5160884297418007
Validation loss: 3.2940361173119723

Epoch: 5| Step: 10
Training loss: 4.0162673614535125
Validation loss: 3.2911405385617

Epoch: 202| Step: 0
Training loss: 2.9852057294381424
Validation loss: 3.2924122125062594

Epoch: 5| Step: 1
Training loss: 3.5611860294829407
Validation loss: 3.2891141931114865

Epoch: 5| Step: 2
Training loss: 3.472048316839115
Validation loss: 3.289882818826262

Epoch: 5| Step: 3
Training loss: 3.306720369912969
Validation loss: 3.291028169695867

Epoch: 5| Step: 4
Training loss: 3.00786148625897
Validation loss: 3.2893173153751434

Epoch: 5| Step: 5
Training loss: 3.2746635089428286
Validation loss: 3.2900430629762165

Epoch: 5| Step: 6
Training loss: 4.170706710392296
Validation loss: 3.2883389746239486

Epoch: 5| Step: 7
Training loss: 3.573543497305753
Validation loss: 3.288770276511705

Epoch: 5| Step: 8
Training loss: 3.459323756554326
Validation loss: 3.288723867072018

Epoch: 5| Step: 9
Training loss: 4.115624147268799
Validation loss: 3.289742020953647

Epoch: 5| Step: 10
Training loss: 3.6888581700431162
Validation loss: 3.2885141433653935

Epoch: 203| Step: 0
Training loss: 3.3892449589704694
Validation loss: 3.288042144384835

Epoch: 5| Step: 1
Training loss: 2.919685073487332
Validation loss: 3.287369836564973

Epoch: 5| Step: 2
Training loss: 2.883983673959518
Validation loss: 3.2880906677889414

Epoch: 5| Step: 3
Training loss: 3.4311142302231565
Validation loss: 3.2864980798424037

Epoch: 5| Step: 4
Training loss: 3.547912177133249
Validation loss: 3.2889175825448023

Epoch: 5| Step: 5
Training loss: 3.2525394495360964
Validation loss: 3.2886282928686508

Epoch: 5| Step: 6
Training loss: 4.365880562491088
Validation loss: 3.2881029375045556

Epoch: 5| Step: 7
Training loss: 3.8725856519847315
Validation loss: 3.2868986123305457

Epoch: 5| Step: 8
Training loss: 3.5349645741804046
Validation loss: 3.288124536677274

Epoch: 5| Step: 9
Training loss: 4.123947934167053
Validation loss: 3.2866083914379867

Epoch: 5| Step: 10
Training loss: 3.0590999179569853
Validation loss: 3.287790958925061

Epoch: 204| Step: 0
Training loss: 3.573581526188595
Validation loss: 3.2884543260964265

Epoch: 5| Step: 1
Training loss: 4.048976043487096
Validation loss: 3.288150371605796

Epoch: 5| Step: 2
Training loss: 3.162695016992282
Validation loss: 3.28637016280431

Epoch: 5| Step: 3
Training loss: 3.129314648362646
Validation loss: 3.2835569679610073

Epoch: 5| Step: 4
Training loss: 3.4578970821635164
Validation loss: 3.2864357468260357

Epoch: 5| Step: 5
Training loss: 3.6382939157230685
Validation loss: 3.2864510392272757

Epoch: 5| Step: 6
Training loss: 2.9402037818506037
Validation loss: 3.285122414500366

Epoch: 5| Step: 7
Training loss: 2.922193866812956
Validation loss: 3.2859778498204

Epoch: 5| Step: 8
Training loss: 3.4098839929710247
Validation loss: 3.287332946545569

Epoch: 5| Step: 9
Training loss: 4.248035201133385
Validation loss: 3.285357289266017

Epoch: 5| Step: 10
Training loss: 4.013180950055782
Validation loss: 3.284782023627204

Epoch: 205| Step: 0
Training loss: 3.362899847258379
Validation loss: 3.283049615453616

Epoch: 5| Step: 1
Training loss: 3.03320045250003
Validation loss: 3.2843964147819444

Epoch: 5| Step: 2
Training loss: 3.4101850545568992
Validation loss: 3.2852210935071016

Epoch: 5| Step: 3
Training loss: 3.6931051553091994
Validation loss: 3.2850530817743984

Epoch: 5| Step: 4
Training loss: 4.189583558939822
Validation loss: 3.284876743557232

Epoch: 5| Step: 5
Training loss: 3.575473652653633
Validation loss: 3.283168194931443

Epoch: 5| Step: 6
Training loss: 3.1653185199925478
Validation loss: 3.28378889593072

Epoch: 5| Step: 7
Training loss: 3.964667676201228
Validation loss: 3.2825200636249385

Epoch: 5| Step: 8
Training loss: 3.41210350555806
Validation loss: 3.2828685122484464

Epoch: 5| Step: 9
Training loss: 3.7047395043682965
Validation loss: 3.2818655066668327

Epoch: 5| Step: 10
Training loss: 2.933304082840241
Validation loss: 3.283774250042358

Epoch: 206| Step: 0
Training loss: 3.3986280365947565
Validation loss: 3.283076567911642

Epoch: 5| Step: 1
Training loss: 3.47136884926135
Validation loss: 3.281686081745714

Epoch: 5| Step: 2
Training loss: 3.804456887903195
Validation loss: 3.2819687704066363

Epoch: 5| Step: 3
Training loss: 3.308484216383478
Validation loss: 3.2821382772483103

Epoch: 5| Step: 4
Training loss: 3.5064341124476477
Validation loss: 3.283183689173003

Epoch: 5| Step: 5
Training loss: 4.009532299211823
Validation loss: 3.2817444709536505

Epoch: 5| Step: 6
Training loss: 3.421064167543799
Validation loss: 3.281202632564113

Epoch: 5| Step: 7
Training loss: 4.048794442168745
Validation loss: 3.280999635363163

Epoch: 5| Step: 8
Training loss: 2.9534165980166818
Validation loss: 3.280771689215943

Epoch: 5| Step: 9
Training loss: 3.4061125281354534
Validation loss: 3.2815015158329786

Epoch: 5| Step: 10
Training loss: 3.1652703134529543
Validation loss: 3.2795487063439888

Epoch: 207| Step: 0
Training loss: 3.901305831025661
Validation loss: 3.280411051563196

Epoch: 5| Step: 1
Training loss: 3.2298171505975297
Validation loss: 3.2811395863884463

Epoch: 5| Step: 2
Training loss: 3.343954062251271
Validation loss: 3.2814329941091924

Epoch: 5| Step: 3
Training loss: 3.6737036514084234
Validation loss: 3.283181933063727

Epoch: 5| Step: 4
Training loss: 4.281587907584752
Validation loss: 3.2810357753907278

Epoch: 5| Step: 5
Training loss: 3.0307336741115267
Validation loss: 3.278575734446965

Epoch: 5| Step: 6
Training loss: 2.6053755027178624
Validation loss: 3.281449777016964

Epoch: 5| Step: 7
Training loss: 3.803919783258877
Validation loss: 3.2787834792207287

Epoch: 5| Step: 8
Training loss: 3.8707500655488323
Validation loss: 3.278389133876605

Epoch: 5| Step: 9
Training loss: 3.3984808557309867
Validation loss: 3.278107193854948

Epoch: 5| Step: 10
Training loss: 3.1934332882787784
Validation loss: 3.278945832628552

Epoch: 208| Step: 0
Training loss: 3.1219039839276417
Validation loss: 3.2790253238201035

Epoch: 5| Step: 1
Training loss: 3.8738906256774874
Validation loss: 3.2782113439295935

Epoch: 5| Step: 2
Training loss: 4.041405475999104
Validation loss: 3.277099747351309

Epoch: 5| Step: 3
Training loss: 3.4578748805111528
Validation loss: 3.277935061902596

Epoch: 5| Step: 4
Training loss: 3.427850392000287
Validation loss: 3.2783654569461707

Epoch: 5| Step: 5
Training loss: 3.9657381899817206
Validation loss: 3.277410490853513

Epoch: 5| Step: 6
Training loss: 3.396854145789683
Validation loss: 3.2792381373169213

Epoch: 5| Step: 7
Training loss: 3.0198304890434087
Validation loss: 3.278473295933464

Epoch: 5| Step: 8
Training loss: 3.2632028458418505
Validation loss: 3.2762910684804267

Epoch: 5| Step: 9
Training loss: 3.146694562298031
Validation loss: 3.2782116880202277

Epoch: 5| Step: 10
Training loss: 3.8506282888236516
Validation loss: 3.277263260546885

Epoch: 209| Step: 0
Training loss: 3.2691580173113195
Validation loss: 3.278077819960811

Epoch: 5| Step: 1
Training loss: 3.7121351377453635
Validation loss: 3.276366743060199

Epoch: 5| Step: 2
Training loss: 2.9480592583092577
Validation loss: 3.2769815412800183

Epoch: 5| Step: 3
Training loss: 3.3182912620842093
Validation loss: 3.2745724518961445

Epoch: 5| Step: 4
Training loss: 3.674475215889014
Validation loss: 3.2759705369880967

Epoch: 5| Step: 5
Training loss: 3.4466052063037504
Validation loss: 3.273136873131654

Epoch: 5| Step: 6
Training loss: 3.919016248306734
Validation loss: 3.275145532837072

Epoch: 5| Step: 7
Training loss: 3.238499467259255
Validation loss: 3.2757318696728364

Epoch: 5| Step: 8
Training loss: 3.8718999952690227
Validation loss: 3.274644331667142

Epoch: 5| Step: 9
Training loss: 3.5719102752625753
Validation loss: 3.2780213206156668

Epoch: 5| Step: 10
Training loss: 3.5961732075341457
Validation loss: 3.2801945627184423

Epoch: 210| Step: 0
Training loss: 2.924146126556949
Validation loss: 3.27751321445038

Epoch: 5| Step: 1
Training loss: 3.417676605818346
Validation loss: 3.272318893321219

Epoch: 5| Step: 2
Training loss: 3.9898763338203462
Validation loss: 3.2726838584540276

Epoch: 5| Step: 3
Training loss: 3.3967772188124385
Validation loss: 3.2724268305064794

Epoch: 5| Step: 4
Training loss: 3.37161494852912
Validation loss: 3.2720384250385095

Epoch: 5| Step: 5
Training loss: 3.469181343271764
Validation loss: 3.2733592295860268

Epoch: 5| Step: 6
Training loss: 3.6338574291052583
Validation loss: 3.2724733700088606

Epoch: 5| Step: 7
Training loss: 3.031073653607135
Validation loss: 3.2726315321543917

Epoch: 5| Step: 8
Training loss: 3.6833924514606164
Validation loss: 3.2723574160323112

Epoch: 5| Step: 9
Training loss: 4.210740461676035
Validation loss: 3.271404606534325

Epoch: 5| Step: 10
Training loss: 3.291782731211085
Validation loss: 3.2704049127609705

Epoch: 211| Step: 0
Training loss: 4.205810823228517
Validation loss: 3.268873699259107

Epoch: 5| Step: 1
Training loss: 3.1272922501146185
Validation loss: 3.2687921691243744

Epoch: 5| Step: 2
Training loss: 3.7858199570089446
Validation loss: 3.263585565372706

Epoch: 5| Step: 3
Training loss: 3.4538429860186626
Validation loss: 3.2640637728732216

Epoch: 5| Step: 4
Training loss: 2.8073178339052998
Validation loss: 3.2621918652800495

Epoch: 5| Step: 5
Training loss: 3.262705689008118
Validation loss: 3.2605820097926546

Epoch: 5| Step: 6
Training loss: 3.853917390477449
Validation loss: 3.2599304102909987

Epoch: 5| Step: 7
Training loss: 3.176521993773805
Validation loss: 3.25900691820227

Epoch: 5| Step: 8
Training loss: 3.385277534951523
Validation loss: 3.2613574628577835

Epoch: 5| Step: 9
Training loss: 4.0211355197916765
Validation loss: 3.2603336514860137

Epoch: 5| Step: 10
Training loss: 3.1699946801174064
Validation loss: 3.2605055505616902

Epoch: 212| Step: 0
Training loss: 3.229361661540533
Validation loss: 3.261246400128212

Epoch: 5| Step: 1
Training loss: 3.9777492108967905
Validation loss: 3.261528510944894

Epoch: 5| Step: 2
Training loss: 4.124787296244233
Validation loss: 3.261328577966436

Epoch: 5| Step: 3
Training loss: 3.4263386637179885
Validation loss: 3.263534351631577

Epoch: 5| Step: 4
Training loss: 4.013499844245152
Validation loss: 3.2600405309429794

Epoch: 5| Step: 5
Training loss: 3.468848699591722
Validation loss: 3.258313298867336

Epoch: 5| Step: 6
Training loss: 3.1977276243981234
Validation loss: 3.256484164880747

Epoch: 5| Step: 7
Training loss: 2.5749375493152327
Validation loss: 3.257520830462758

Epoch: 5| Step: 8
Training loss: 3.3561614523915626
Validation loss: 3.2578765688931144

Epoch: 5| Step: 9
Training loss: 3.257687499943793
Validation loss: 3.257698706107632

Epoch: 5| Step: 10
Training loss: 3.5897768033066617
Validation loss: 3.257259984336222

Epoch: 213| Step: 0
Training loss: 3.3039114110675873
Validation loss: 3.2555777564654336

Epoch: 5| Step: 1
Training loss: 4.39521500757
Validation loss: 3.255866411922963

Epoch: 5| Step: 2
Training loss: 3.1115325649837096
Validation loss: 3.2564766136481165

Epoch: 5| Step: 3
Training loss: 3.6074847932046956
Validation loss: 3.255867422145745

Epoch: 5| Step: 4
Training loss: 3.5823801384498357
Validation loss: 3.25561193209505

Epoch: 5| Step: 5
Training loss: 3.186658411560645
Validation loss: 3.2570376087060993

Epoch: 5| Step: 6
Training loss: 3.118944939462765
Validation loss: 3.256005296111206

Epoch: 5| Step: 7
Training loss: 2.8129710332828055
Validation loss: 3.254447255933993

Epoch: 5| Step: 8
Training loss: 4.110392977450836
Validation loss: 3.2572119752412547

Epoch: 5| Step: 9
Training loss: 3.137162002655936
Validation loss: 3.2560877928245784

Epoch: 5| Step: 10
Training loss: 3.8150517413429053
Validation loss: 3.255154262298739

Epoch: 214| Step: 0
Training loss: 3.6202449523920097
Validation loss: 3.2557800615194394

Epoch: 5| Step: 1
Training loss: 3.498114214088724
Validation loss: 3.253422984656976

Epoch: 5| Step: 2
Training loss: 3.972604636848224
Validation loss: 3.2524819879177436

Epoch: 5| Step: 3
Training loss: 3.210188506821463
Validation loss: 3.252355965584405

Epoch: 5| Step: 4
Training loss: 3.238972662541536
Validation loss: 3.2541780262652007

Epoch: 5| Step: 5
Training loss: 3.7712781584045323
Validation loss: 3.2519667506182706

Epoch: 5| Step: 6
Training loss: 3.451922176991164
Validation loss: 3.2530482292898437

Epoch: 5| Step: 7
Training loss: 4.353619895566029
Validation loss: 3.2530266635909713

Epoch: 5| Step: 8
Training loss: 2.875795337297403
Validation loss: 3.2522521107969427

Epoch: 5| Step: 9
Training loss: 3.370110537473517
Validation loss: 3.2531985563256356

Epoch: 5| Step: 10
Training loss: 2.6275360935392613
Validation loss: 3.2500614668442442

Epoch: 215| Step: 0
Training loss: 3.120445441946478
Validation loss: 3.2531686564906552

Epoch: 5| Step: 1
Training loss: 3.517121263623452
Validation loss: 3.250292358626918

Epoch: 5| Step: 2
Training loss: 3.404986505915809
Validation loss: 3.252852088467956

Epoch: 5| Step: 3
Training loss: 3.0083790431332096
Validation loss: 3.2516329932597308

Epoch: 5| Step: 4
Training loss: 3.428419430519688
Validation loss: 3.252242851808173

Epoch: 5| Step: 5
Training loss: 3.1395131130925815
Validation loss: 3.251762149062113

Epoch: 5| Step: 6
Training loss: 3.330682192966545
Validation loss: 3.248818472245725

Epoch: 5| Step: 7
Training loss: 3.6340946683084
Validation loss: 3.2501804957977516

Epoch: 5| Step: 8
Training loss: 3.75016072246723
Validation loss: 3.2489739684479333

Epoch: 5| Step: 9
Training loss: 4.076525845989751
Validation loss: 3.248801137264343

Epoch: 5| Step: 10
Training loss: 3.9001238583190525
Validation loss: 3.2483285213742445

Epoch: 216| Step: 0
Training loss: 3.2279270048621393
Validation loss: 3.2493147352405427

Epoch: 5| Step: 1
Training loss: 3.1769062597405533
Validation loss: 3.248579494178879

Epoch: 5| Step: 2
Training loss: 4.587636811505704
Validation loss: 3.247434205926354

Epoch: 5| Step: 3
Training loss: 3.4299341343375027
Validation loss: 3.249960844689097

Epoch: 5| Step: 4
Training loss: 3.6186513884026703
Validation loss: 3.2489250131186003

Epoch: 5| Step: 5
Training loss: 3.2606405520529833
Validation loss: 3.2505102884987958

Epoch: 5| Step: 6
Training loss: 3.4710313323026427
Validation loss: 3.254044381959125

Epoch: 5| Step: 7
Training loss: 3.7661626281631095
Validation loss: 3.25587058666855

Epoch: 5| Step: 8
Training loss: 2.7943312516069523
Validation loss: 3.246522814989789

Epoch: 5| Step: 9
Training loss: 3.672445569449776
Validation loss: 3.24799180756934

Epoch: 5| Step: 10
Training loss: 3.010746463719393
Validation loss: 3.246105362635796

Epoch: 217| Step: 0
Training loss: 3.137256998933297
Validation loss: 3.2459361034113288

Epoch: 5| Step: 1
Training loss: 3.4691456062239037
Validation loss: 3.2463358171621257

Epoch: 5| Step: 2
Training loss: 2.965303206998575
Validation loss: 3.246177823786622

Epoch: 5| Step: 3
Training loss: 3.737604636064032
Validation loss: 3.248733339933028

Epoch: 5| Step: 4
Training loss: 3.2664722274470828
Validation loss: 3.2478178111477765

Epoch: 5| Step: 5
Training loss: 3.8271096887790255
Validation loss: 3.247054694094441

Epoch: 5| Step: 6
Training loss: 4.31410740183419
Validation loss: 3.246239035266516

Epoch: 5| Step: 7
Training loss: 3.494278454607612
Validation loss: 3.247110036378305

Epoch: 5| Step: 8
Training loss: 3.5956540578367235
Validation loss: 3.24629618489315

Epoch: 5| Step: 9
Training loss: 3.2205688374539965
Validation loss: 3.2452021065845584

Epoch: 5| Step: 10
Training loss: 3.0664686063026867
Validation loss: 3.2458591459576054

Epoch: 218| Step: 0
Training loss: 4.1207075037450664
Validation loss: 3.247049330036701

Epoch: 5| Step: 1
Training loss: 3.4123395330127995
Validation loss: 3.2444075814332782

Epoch: 5| Step: 2
Training loss: 3.3118043564955832
Validation loss: 3.2456484517902537

Epoch: 5| Step: 3
Training loss: 3.0810882711620553
Validation loss: 3.2434173192724014

Epoch: 5| Step: 4
Training loss: 4.17671865391832
Validation loss: 3.246880453219788

Epoch: 5| Step: 5
Training loss: 3.5688192972112587
Validation loss: 3.244778034094198

Epoch: 5| Step: 6
Training loss: 3.230077127061386
Validation loss: 3.24460126423902

Epoch: 5| Step: 7
Training loss: 3.132868511812248
Validation loss: 3.2438772408900225

Epoch: 5| Step: 8
Training loss: 3.590883123218334
Validation loss: 3.244496279419388

Epoch: 5| Step: 9
Training loss: 3.051605621205107
Validation loss: 3.2419978687640993

Epoch: 5| Step: 10
Training loss: 3.4916157435768125
Validation loss: 3.2436716469564226

Epoch: 219| Step: 0
Training loss: 2.8790447144873554
Validation loss: 3.2427811716724477

Epoch: 5| Step: 1
Training loss: 2.7699036341130983
Validation loss: 3.245225372954681

Epoch: 5| Step: 2
Training loss: 3.694286244255064
Validation loss: 3.2435124425539934

Epoch: 5| Step: 3
Training loss: 4.182969332559562
Validation loss: 3.243923917333866

Epoch: 5| Step: 4
Training loss: 3.617257103137032
Validation loss: 3.2426792215187965

Epoch: 5| Step: 5
Training loss: 3.01396821518752
Validation loss: 3.242650733152806

Epoch: 5| Step: 6
Training loss: 3.503050428510486
Validation loss: 3.241742397513738

Epoch: 5| Step: 7
Training loss: 4.414552698513645
Validation loss: 3.2429617340712165

Epoch: 5| Step: 8
Training loss: 3.53918241251392
Validation loss: 3.245134112403039

Epoch: 5| Step: 9
Training loss: 3.0515806198558773
Validation loss: 3.2417434255819457

Epoch: 5| Step: 10
Training loss: 3.2524086756277018
Validation loss: 3.242672914158899

Epoch: 220| Step: 0
Training loss: 3.5721550992674795
Validation loss: 3.242885526616021

Epoch: 5| Step: 1
Training loss: 3.394027057951215
Validation loss: 3.240436506632161

Epoch: 5| Step: 2
Training loss: 3.916852554347064
Validation loss: 3.2422952265657696

Epoch: 5| Step: 3
Training loss: 4.0237868666582
Validation loss: 3.2405011785600735

Epoch: 5| Step: 4
Training loss: 3.459102927986713
Validation loss: 3.2389435590264726

Epoch: 5| Step: 5
Training loss: 2.9030701663913003
Validation loss: 3.240201068899777

Epoch: 5| Step: 6
Training loss: 2.8951423607381432
Validation loss: 3.2390089161165863

Epoch: 5| Step: 7
Training loss: 3.8548386821316907
Validation loss: 3.2403692653191025

Epoch: 5| Step: 8
Training loss: 3.0641795632557214
Validation loss: 3.2405809996893495

Epoch: 5| Step: 9
Training loss: 3.5519477766167253
Validation loss: 3.2381751110395687

Epoch: 5| Step: 10
Training loss: 3.4447159369609186
Validation loss: 3.238300919700333

Epoch: 221| Step: 0
Training loss: 3.6975258777427302
Validation loss: 3.238176116489549

Epoch: 5| Step: 1
Training loss: 3.5682812010371734
Validation loss: 3.2390474139233847

Epoch: 5| Step: 2
Training loss: 3.9035130792718484
Validation loss: 3.237121991240802

Epoch: 5| Step: 3
Training loss: 3.090195743076769
Validation loss: 3.2378564769232816

Epoch: 5| Step: 4
Training loss: 3.5378547948838457
Validation loss: 3.236246401553258

Epoch: 5| Step: 5
Training loss: 2.795233047405286
Validation loss: 3.2379041807704287

Epoch: 5| Step: 6
Training loss: 3.4520300600725555
Validation loss: 3.238041937618092

Epoch: 5| Step: 7
Training loss: 3.6244135415122627
Validation loss: 3.237697573307774

Epoch: 5| Step: 8
Training loss: 3.5857382991205973
Validation loss: 3.2392461309957175

Epoch: 5| Step: 9
Training loss: 3.5573251181835994
Validation loss: 3.2358366742948106

Epoch: 5| Step: 10
Training loss: 3.342636778721321
Validation loss: 3.2354680202420045

Epoch: 222| Step: 0
Training loss: 3.8333729175237683
Validation loss: 3.2371383536903635

Epoch: 5| Step: 1
Training loss: 3.207806994047424
Validation loss: 3.235577506854383

Epoch: 5| Step: 2
Training loss: 3.71831221367757
Validation loss: 3.234541180279732

Epoch: 5| Step: 3
Training loss: 3.6058673411006414
Validation loss: 3.235658797956476

Epoch: 5| Step: 4
Training loss: 3.3821879949131404
Validation loss: 3.236009267824385

Epoch: 5| Step: 5
Training loss: 3.4258366474818223
Validation loss: 3.234789738858316

Epoch: 5| Step: 6
Training loss: 3.1234306972748267
Validation loss: 3.23693022106336

Epoch: 5| Step: 7
Training loss: 3.0588282157896574
Validation loss: 3.2365552503053943

Epoch: 5| Step: 8
Training loss: 3.5863219077984314
Validation loss: 3.2345035252600205

Epoch: 5| Step: 9
Training loss: 3.7192738909304377
Validation loss: 3.2344757289497976

Epoch: 5| Step: 10
Training loss: 3.5316685791394495
Validation loss: 3.2336250471282044

Epoch: 223| Step: 0
Training loss: 3.0479651432697525
Validation loss: 3.2334756566362994

Epoch: 5| Step: 1
Training loss: 4.2100738602273164
Validation loss: 3.2327489385255954

Epoch: 5| Step: 2
Training loss: 3.1618486359359177
Validation loss: 3.234078283750538

Epoch: 5| Step: 3
Training loss: 3.362356025421313
Validation loss: 3.2327769637972987

Epoch: 5| Step: 4
Training loss: 3.5414453025901436
Validation loss: 3.232448862566213

Epoch: 5| Step: 5
Training loss: 2.3917919626766473
Validation loss: 3.231990500180824

Epoch: 5| Step: 6
Training loss: 3.446152772746076
Validation loss: 3.2339473856036047

Epoch: 5| Step: 7
Training loss: 3.5799350741162463
Validation loss: 3.2335152985757003

Epoch: 5| Step: 8
Training loss: 3.3803394607635364
Validation loss: 3.2336929336878657

Epoch: 5| Step: 9
Training loss: 4.353365348320427
Validation loss: 3.2333076907254177

Epoch: 5| Step: 10
Training loss: 3.3265775566423286
Validation loss: 3.233133726319713

Epoch: 224| Step: 0
Training loss: 3.1812157110078814
Validation loss: 3.2373113347511793

Epoch: 5| Step: 1
Training loss: 3.5841196809012845
Validation loss: 3.237392258436031

Epoch: 5| Step: 2
Training loss: 3.497974490849705
Validation loss: 3.234860226543623

Epoch: 5| Step: 3
Training loss: 3.4575394941103017
Validation loss: 3.2365609786898135

Epoch: 5| Step: 4
Training loss: 4.059739099021515
Validation loss: 3.2334755266099386

Epoch: 5| Step: 5
Training loss: 3.0706060138210924
Validation loss: 3.2304659423069957

Epoch: 5| Step: 6
Training loss: 3.3093577902313083
Validation loss: 3.230977890893837

Epoch: 5| Step: 7
Training loss: 3.693884543406782
Validation loss: 3.2286127229938124

Epoch: 5| Step: 8
Training loss: 3.4013995712013534
Validation loss: 3.2314999034747074

Epoch: 5| Step: 9
Training loss: 3.0209314966147063
Validation loss: 3.231951961148442

Epoch: 5| Step: 10
Training loss: 3.8552489677018666
Validation loss: 3.228543169295072

Epoch: 225| Step: 0
Training loss: 3.3691690725701178
Validation loss: 3.229773623095527

Epoch: 5| Step: 1
Training loss: 3.5565762710405235
Validation loss: 3.230532451756018

Epoch: 5| Step: 2
Training loss: 3.2237983298256605
Validation loss: 3.2303270243233113

Epoch: 5| Step: 3
Training loss: 3.7584763414420594
Validation loss: 3.230620349101926

Epoch: 5| Step: 4
Training loss: 3.6228616919065626
Validation loss: 3.229027696226436

Epoch: 5| Step: 5
Training loss: 3.6629643533207816
Validation loss: 3.2311094925073274

Epoch: 5| Step: 6
Training loss: 3.2618634768602446
Validation loss: 3.23039321125641

Epoch: 5| Step: 7
Training loss: 3.7539695075477946
Validation loss: 3.2275050090062956

Epoch: 5| Step: 8
Training loss: 3.4394617205138194
Validation loss: 3.227794169502003

Epoch: 5| Step: 9
Training loss: 2.471309735160364
Validation loss: 3.2275397583084504

Epoch: 5| Step: 10
Training loss: 3.915789133880376
Validation loss: 3.2262247565244184

Epoch: 226| Step: 0
Training loss: 4.25405824668188
Validation loss: 3.2253386758227474

Epoch: 5| Step: 1
Training loss: 3.5151001941189137
Validation loss: 3.2281817556080523

Epoch: 5| Step: 2
Training loss: 3.8497697786137337
Validation loss: 3.2246037255571696

Epoch: 5| Step: 3
Training loss: 3.6471958048718345
Validation loss: 3.225669001578623

Epoch: 5| Step: 4
Training loss: 2.746002760094619
Validation loss: 3.2273605000663035

Epoch: 5| Step: 5
Training loss: 3.2820503348722068
Validation loss: 3.2261346439334533

Epoch: 5| Step: 6
Training loss: 3.6079021933381643
Validation loss: 3.227286164319316

Epoch: 5| Step: 7
Training loss: 3.1883228212360413
Validation loss: 3.225761462123481

Epoch: 5| Step: 8
Training loss: 3.5753928335477445
Validation loss: 3.224188283913025

Epoch: 5| Step: 9
Training loss: 3.008047595063529
Validation loss: 3.2240171766900674

Epoch: 5| Step: 10
Training loss: 3.2083260342073188
Validation loss: 3.2244137598638627

Epoch: 227| Step: 0
Training loss: 3.3618599151255877
Validation loss: 3.22306404802642

Epoch: 5| Step: 1
Training loss: 4.056306078601058
Validation loss: 3.225157320739223

Epoch: 5| Step: 2
Training loss: 3.8957260579453847
Validation loss: 3.224032842289438

Epoch: 5| Step: 3
Training loss: 3.034487067528957
Validation loss: 3.224398103270845

Epoch: 5| Step: 4
Training loss: 2.9253300928858867
Validation loss: 3.2240988181106562

Epoch: 5| Step: 5
Training loss: 3.691108231397599
Validation loss: 3.2230579027230264

Epoch: 5| Step: 6
Training loss: 3.9988875034131195
Validation loss: 3.2235728362769045

Epoch: 5| Step: 7
Training loss: 2.4080060025834205
Validation loss: 3.2250388499631653

Epoch: 5| Step: 8
Training loss: 3.0327542691976257
Validation loss: 3.224965975849745

Epoch: 5| Step: 9
Training loss: 3.5378557383537887
Validation loss: 3.222177110082043

Epoch: 5| Step: 10
Training loss: 3.8726483253950468
Validation loss: 3.223505545405409

Epoch: 228| Step: 0
Training loss: 2.3043243639364137
Validation loss: 3.2229862485433194

Epoch: 5| Step: 1
Training loss: 3.9591939425601126
Validation loss: 3.223408509100928

Epoch: 5| Step: 2
Training loss: 3.0789753470305783
Validation loss: 3.22442727128669

Epoch: 5| Step: 3
Training loss: 3.480382025566199
Validation loss: 3.2228226893089222

Epoch: 5| Step: 4
Training loss: 3.0190099189648425
Validation loss: 3.2230346306408078

Epoch: 5| Step: 5
Training loss: 3.5731946801809085
Validation loss: 3.2239512588370607

Epoch: 5| Step: 6
Training loss: 3.7887242117028985
Validation loss: 3.223344290363355

Epoch: 5| Step: 7
Training loss: 4.268471910123079
Validation loss: 3.2232621892043283

Epoch: 5| Step: 8
Training loss: 3.9615641743378918
Validation loss: 3.2196179183635696

Epoch: 5| Step: 9
Training loss: 3.1937008549740553
Validation loss: 3.2226609100676025

Epoch: 5| Step: 10
Training loss: 2.974050828839267
Validation loss: 3.2229763152730158

Epoch: 229| Step: 0
Training loss: 2.8904648195167106
Validation loss: 3.22202236072914

Epoch: 5| Step: 1
Training loss: 3.5827170145093357
Validation loss: 3.2223650611638597

Epoch: 5| Step: 2
Training loss: 3.3775462682619892
Validation loss: 3.2211855976078896

Epoch: 5| Step: 3
Training loss: 3.960887178782298
Validation loss: 3.221889309775599

Epoch: 5| Step: 4
Training loss: 3.9541066274047583
Validation loss: 3.2212102041808497

Epoch: 5| Step: 5
Training loss: 2.916471492958277
Validation loss: 3.222314261558895

Epoch: 5| Step: 6
Training loss: 3.4565437619741464
Validation loss: 3.221786775705212

Epoch: 5| Step: 7
Training loss: 3.744029696656505
Validation loss: 3.218853829454766

Epoch: 5| Step: 8
Training loss: 3.1245455602192362
Validation loss: 3.2194583000798915

Epoch: 5| Step: 9
Training loss: 3.7063351651935754
Validation loss: 3.2200418618279167

Epoch: 5| Step: 10
Training loss: 3.213603970723813
Validation loss: 3.2205113530757936

Epoch: 230| Step: 0
Training loss: 3.7708081548422747
Validation loss: 3.221358172326763

Epoch: 5| Step: 1
Training loss: 3.239449910220128
Validation loss: 3.220734300510215

Epoch: 5| Step: 2
Training loss: 4.104881004997044
Validation loss: 3.219067895652299

Epoch: 5| Step: 3
Training loss: 2.903858143980406
Validation loss: 3.219782764651035

Epoch: 5| Step: 4
Training loss: 4.031195588446987
Validation loss: 3.2222877539860497

Epoch: 5| Step: 5
Training loss: 3.6226918995155963
Validation loss: 3.2207593793597855

Epoch: 5| Step: 6
Training loss: 3.22699681053796
Validation loss: 3.2197381937966436

Epoch: 5| Step: 7
Training loss: 3.382762036376632
Validation loss: 3.2170494853019607

Epoch: 5| Step: 8
Training loss: 3.0431194929165937
Validation loss: 3.2183171080836583

Epoch: 5| Step: 9
Training loss: 3.3213568268042915
Validation loss: 3.219846712852403

Epoch: 5| Step: 10
Training loss: 3.2209540663212
Validation loss: 3.2196816962586547

Epoch: 231| Step: 0
Training loss: 3.721104493607207
Validation loss: 3.2235963875910216

Epoch: 5| Step: 1
Training loss: 3.426299278909714
Validation loss: 3.2218748702693376

Epoch: 5| Step: 2
Training loss: 4.082894178377169
Validation loss: 3.2196133382948164

Epoch: 5| Step: 3
Training loss: 3.590918578254976
Validation loss: 3.215754157266784

Epoch: 5| Step: 4
Training loss: 2.6989295462267267
Validation loss: 3.21478385542051

Epoch: 5| Step: 5
Training loss: 3.626541599146067
Validation loss: 3.2142633600429398

Epoch: 5| Step: 6
Training loss: 3.984033188463337
Validation loss: 3.2141247994061413

Epoch: 5| Step: 7
Training loss: 3.662668186531358
Validation loss: 3.21601643758075

Epoch: 5| Step: 8
Training loss: 3.5501089267406476
Validation loss: 3.2152342846133366

Epoch: 5| Step: 9
Training loss: 2.817435194351653
Validation loss: 3.2157100886312042

Epoch: 5| Step: 10
Training loss: 2.3829804908443695
Validation loss: 3.2162070092629547

Epoch: 232| Step: 0
Training loss: 3.0441010196380196
Validation loss: 3.2153492767835505

Epoch: 5| Step: 1
Training loss: 4.143903938299429
Validation loss: 3.2130430614591194

Epoch: 5| Step: 2
Training loss: 3.0027280166020716
Validation loss: 3.214838271591859

Epoch: 5| Step: 3
Training loss: 4.007783231572588
Validation loss: 3.2128419034273197

Epoch: 5| Step: 4
Training loss: 3.920318172932698
Validation loss: 3.2135271388604525

Epoch: 5| Step: 5
Training loss: 3.63933255416695
Validation loss: 3.2130676745383435

Epoch: 5| Step: 6
Training loss: 2.964477355592599
Validation loss: 3.2119651926077086

Epoch: 5| Step: 7
Training loss: 3.4406986959743353
Validation loss: 3.214252642109641

Epoch: 5| Step: 8
Training loss: 2.509225417604026
Validation loss: 3.211226651472589

Epoch: 5| Step: 9
Training loss: 3.5559703482302374
Validation loss: 3.2135083546223804

Epoch: 5| Step: 10
Training loss: 3.4819964171976743
Validation loss: 3.2117497526311873

Epoch: 233| Step: 0
Training loss: 3.1472377715737196
Validation loss: 3.210264107326993

Epoch: 5| Step: 1
Training loss: 3.4851668617003178
Validation loss: 3.213340831315195

Epoch: 5| Step: 2
Training loss: 3.4983895547706965
Validation loss: 3.2197776027824316

Epoch: 5| Step: 3
Training loss: 3.4491671842390508
Validation loss: 3.2244601742346655

Epoch: 5| Step: 4
Training loss: 3.4336599922951003
Validation loss: 3.231290995902133

Epoch: 5| Step: 5
Training loss: 2.565148636227527
Validation loss: 3.231028784384329

Epoch: 5| Step: 6
Training loss: 3.440489422780096
Validation loss: 3.232819009179368

Epoch: 5| Step: 7
Training loss: 4.103096578809007
Validation loss: 3.2244231711156983

Epoch: 5| Step: 8
Training loss: 3.5967392140997885
Validation loss: 3.2110447628288283

Epoch: 5| Step: 9
Training loss: 3.9020899479136673
Validation loss: 3.209490001961818

Epoch: 5| Step: 10
Training loss: 3.255334877097645
Validation loss: 3.2124707310628327

Epoch: 234| Step: 0
Training loss: 3.377177066117956
Validation loss: 3.2124319905744416

Epoch: 5| Step: 1
Training loss: 3.370470751927631
Validation loss: 3.2131335691298064

Epoch: 5| Step: 2
Training loss: 3.5918700235125582
Validation loss: 3.2139473550311086

Epoch: 5| Step: 3
Training loss: 3.603376415840882
Validation loss: 3.220877787067244

Epoch: 5| Step: 4
Training loss: 3.7679252721661585
Validation loss: 3.2188371598138685

Epoch: 5| Step: 5
Training loss: 3.3660221074557515
Validation loss: 3.220490503252421

Epoch: 5| Step: 6
Training loss: 2.998032560531788
Validation loss: 3.2151135935065702

Epoch: 5| Step: 7
Training loss: 3.8607470586995625
Validation loss: 3.2128905228658025

Epoch: 5| Step: 8
Training loss: 3.561875673432227
Validation loss: 3.210445853342736

Epoch: 5| Step: 9
Training loss: 3.642933911495034
Validation loss: 3.2111483799752207

Epoch: 5| Step: 10
Training loss: 2.7356940875220186
Validation loss: 3.2117848112808676

Epoch: 235| Step: 0
Training loss: 3.101595707866935
Validation loss: 3.2073867343232134

Epoch: 5| Step: 1
Training loss: 2.7282809113546587
Validation loss: 3.2089678058809783

Epoch: 5| Step: 2
Training loss: 3.4546076150713394
Validation loss: 3.2085271829235955

Epoch: 5| Step: 3
Training loss: 3.4336851279258642
Validation loss: 3.209260803032029

Epoch: 5| Step: 4
Training loss: 3.4241347842025354
Validation loss: 3.2094863228303896

Epoch: 5| Step: 5
Training loss: 3.2236302978727696
Validation loss: 3.207354250905514

Epoch: 5| Step: 6
Training loss: 3.946382464365778
Validation loss: 3.2098651346089757

Epoch: 5| Step: 7
Training loss: 3.6047326821354955
Validation loss: 3.206380063882461

Epoch: 5| Step: 8
Training loss: 3.3829767130051107
Validation loss: 3.2110511115569484

Epoch: 5| Step: 9
Training loss: 3.941158109175032
Validation loss: 3.20689605099765

Epoch: 5| Step: 10
Training loss: 3.6405561055880695
Validation loss: 3.209698124022788

Epoch: 236| Step: 0
Training loss: 3.660493132925711
Validation loss: 3.212761808854436

Epoch: 5| Step: 1
Training loss: 3.6929206446352514
Validation loss: 3.2094776433863883

Epoch: 5| Step: 2
Training loss: 3.5833735057146248
Validation loss: 3.2107098192819565

Epoch: 5| Step: 3
Training loss: 3.682064511614101
Validation loss: 3.210116654025336

Epoch: 5| Step: 4
Training loss: 2.4867353442971982
Validation loss: 3.2070275008997666

Epoch: 5| Step: 5
Training loss: 3.540861838652393
Validation loss: 3.207956734395169

Epoch: 5| Step: 6
Training loss: 3.024054570275865
Validation loss: 3.2072147634983277

Epoch: 5| Step: 7
Training loss: 3.8451582647127123
Validation loss: 3.2049943776868695

Epoch: 5| Step: 8
Training loss: 3.465859798529999
Validation loss: 3.2051811071988485

Epoch: 5| Step: 9
Training loss: 3.4206423694930024
Validation loss: 3.2052375476003845

Epoch: 5| Step: 10
Training loss: 3.387829731451485
Validation loss: 3.2041337604519335

Epoch: 237| Step: 0
Training loss: 3.562431468639081
Validation loss: 3.2031736676840556

Epoch: 5| Step: 1
Training loss: 3.0030662443544194
Validation loss: 3.204049516381235

Epoch: 5| Step: 2
Training loss: 2.9918454923463615
Validation loss: 3.204828565949252

Epoch: 5| Step: 3
Training loss: 3.771324055532213
Validation loss: 3.2054893653403473

Epoch: 5| Step: 4
Training loss: 3.7646347580004385
Validation loss: 3.2023951153327666

Epoch: 5| Step: 5
Training loss: 3.925007697419801
Validation loss: 3.204433593444709

Epoch: 5| Step: 6
Training loss: 3.422965934028918
Validation loss: 3.2038451675000754

Epoch: 5| Step: 7
Training loss: 3.2516214287480567
Validation loss: 3.206341506460421

Epoch: 5| Step: 8
Training loss: 2.86667672162917
Validation loss: 3.211893412282576

Epoch: 5| Step: 9
Training loss: 3.5352425749128678
Validation loss: 3.207831220538889

Epoch: 5| Step: 10
Training loss: 3.7372829973893715
Validation loss: 3.2052854761706033

Epoch: 238| Step: 0
Training loss: 3.936371414478025
Validation loss: 3.2022915191698282

Epoch: 5| Step: 1
Training loss: 3.5000694812962454
Validation loss: 3.2009458318849133

Epoch: 5| Step: 2
Training loss: 2.911375714507729
Validation loss: 3.202413815857915

Epoch: 5| Step: 3
Training loss: 2.8909440148077805
Validation loss: 3.2016935698162263

Epoch: 5| Step: 4
Training loss: 2.9557288260886825
Validation loss: 3.2014002244387245

Epoch: 5| Step: 5
Training loss: 3.3314013763445045
Validation loss: 3.2039123527896676

Epoch: 5| Step: 6
Training loss: 3.4189726483304512
Validation loss: 3.2039665183232775

Epoch: 5| Step: 7
Training loss: 3.625629501931812
Validation loss: 3.207970390252017

Epoch: 5| Step: 8
Training loss: 3.514353068522623
Validation loss: 3.202444240802584

Epoch: 5| Step: 9
Training loss: 3.404068554538675
Validation loss: 3.2012507812282758

Epoch: 5| Step: 10
Training loss: 4.339101156159394
Validation loss: 3.201509566873844

Epoch: 239| Step: 0
Training loss: 3.9137917918018066
Validation loss: 3.1994423830993366

Epoch: 5| Step: 1
Training loss: 3.2336103484526575
Validation loss: 3.2001473285230793

Epoch: 5| Step: 2
Training loss: 2.5515184257330907
Validation loss: 3.2000673776629385

Epoch: 5| Step: 3
Training loss: 2.646825249034356
Validation loss: 3.1989719426335386

Epoch: 5| Step: 4
Training loss: 3.9205817411794923
Validation loss: 3.1987083897725817

Epoch: 5| Step: 5
Training loss: 3.979505128429879
Validation loss: 3.19843152905171

Epoch: 5| Step: 6
Training loss: 3.7016687547820095
Validation loss: 3.19861726714602

Epoch: 5| Step: 7
Training loss: 3.0409240512866083
Validation loss: 3.1983151126335656

Epoch: 5| Step: 8
Training loss: 3.5142313589706298
Validation loss: 3.198104523933067

Epoch: 5| Step: 9
Training loss: 3.686645408785226
Validation loss: 3.1988659178994987

Epoch: 5| Step: 10
Training loss: 3.3538635464448143
Validation loss: 3.199581153309865

Epoch: 240| Step: 0
Training loss: 3.7712297319038917
Validation loss: 3.197935856202454

Epoch: 5| Step: 1
Training loss: 3.5577845904462233
Validation loss: 3.1966291388142323

Epoch: 5| Step: 2
Training loss: 3.647109384204368
Validation loss: 3.197338099342352

Epoch: 5| Step: 3
Training loss: 3.207769385641293
Validation loss: 3.196408072713289

Epoch: 5| Step: 4
Training loss: 3.9055233699171166
Validation loss: 3.1978713688366702

Epoch: 5| Step: 5
Training loss: 2.780238792811897
Validation loss: 3.1969776373534677

Epoch: 5| Step: 6
Training loss: 3.082596527593047
Validation loss: 3.197221359261319

Epoch: 5| Step: 7
Training loss: 3.4601727538448417
Validation loss: 3.1984813421854583

Epoch: 5| Step: 8
Training loss: 2.85264102971639
Validation loss: 3.2002854497428173

Epoch: 5| Step: 9
Training loss: 4.062035636771826
Validation loss: 3.2015945375874093

Epoch: 5| Step: 10
Training loss: 3.3045823100778695
Validation loss: 3.204360781954569

Epoch: 241| Step: 0
Training loss: 3.974612974123063
Validation loss: 3.203210400058938

Epoch: 5| Step: 1
Training loss: 3.3513439614065654
Validation loss: 3.2031810068295834

Epoch: 5| Step: 2
Training loss: 3.226308447786161
Validation loss: 3.204489948610272

Epoch: 5| Step: 3
Training loss: 2.8099405298693756
Validation loss: 3.199779172681648

Epoch: 5| Step: 4
Training loss: 3.0906408851454445
Validation loss: 3.197359595653426

Epoch: 5| Step: 5
Training loss: 3.694800053040191
Validation loss: 3.19871892335967

Epoch: 5| Step: 6
Training loss: 3.4237923323767316
Validation loss: 3.2003695109280117

Epoch: 5| Step: 7
Training loss: 3.161925698707278
Validation loss: 3.200228810654107

Epoch: 5| Step: 8
Training loss: 3.7978460381002503
Validation loss: 3.197191022531683

Epoch: 5| Step: 9
Training loss: 3.417674513004897
Validation loss: 3.19621523451179

Epoch: 5| Step: 10
Training loss: 3.8104531468723346
Validation loss: 3.1967693687948002

Epoch: 242| Step: 0
Training loss: 3.6963000278486624
Validation loss: 3.1952355733072304

Epoch: 5| Step: 1
Training loss: 3.70850943386549
Validation loss: 3.195145544741023

Epoch: 5| Step: 2
Training loss: 2.7376113485744296
Validation loss: 3.1958144517480815

Epoch: 5| Step: 3
Training loss: 3.918490830510382
Validation loss: 3.195937354051231

Epoch: 5| Step: 4
Training loss: 3.315897656590434
Validation loss: 3.1951087846405137

Epoch: 5| Step: 5
Training loss: 2.8809500780212733
Validation loss: 3.1946315124462106

Epoch: 5| Step: 6
Training loss: 3.286779485730277
Validation loss: 3.1955389608547438

Epoch: 5| Step: 7
Training loss: 4.498256769554596
Validation loss: 3.195040990572395

Epoch: 5| Step: 8
Training loss: 3.530610288216923
Validation loss: 3.1951432620405606

Epoch: 5| Step: 9
Training loss: 2.7803668216502206
Validation loss: 3.1942813020778553

Epoch: 5| Step: 10
Training loss: 3.0235628796980216
Validation loss: 3.1935376622823823

Epoch: 243| Step: 0
Training loss: 3.938779229552328
Validation loss: 3.1939065568355196

Epoch: 5| Step: 1
Training loss: 3.273168438981387
Validation loss: 3.19406317162018

Epoch: 5| Step: 2
Training loss: 3.0989391849898613
Validation loss: 3.1933712982178926

Epoch: 5| Step: 3
Training loss: 3.4274080039601866
Validation loss: 3.19445395632471

Epoch: 5| Step: 4
Training loss: 2.3860684521905107
Validation loss: 3.193075577713334

Epoch: 5| Step: 5
Training loss: 4.093907011093256
Validation loss: 3.193946726009708

Epoch: 5| Step: 6
Training loss: 3.1897769350131053
Validation loss: 3.194426398979058

Epoch: 5| Step: 7
Training loss: 2.7310790333606976
Validation loss: 3.1943805176941655

Epoch: 5| Step: 8
Training loss: 3.837639269957613
Validation loss: 3.193044750375049

Epoch: 5| Step: 9
Training loss: 4.0998494376473085
Validation loss: 3.1929253064818317

Epoch: 5| Step: 10
Training loss: 3.2828421953139166
Validation loss: 3.193199322443189

Epoch: 244| Step: 0
Training loss: 3.359004226450236
Validation loss: 3.1927342942337025

Epoch: 5| Step: 1
Training loss: 3.268009756963165
Validation loss: 3.192768452005445

Epoch: 5| Step: 2
Training loss: 3.239248096910362
Validation loss: 3.1899209171758263

Epoch: 5| Step: 3
Training loss: 2.94154971559365
Validation loss: 3.18969620018637

Epoch: 5| Step: 4
Training loss: 3.966101055264024
Validation loss: 3.1913584053920614

Epoch: 5| Step: 5
Training loss: 3.7916747851162587
Validation loss: 3.192059925400323

Epoch: 5| Step: 6
Training loss: 3.2205038384940456
Validation loss: 3.1920123829340947

Epoch: 5| Step: 7
Training loss: 3.4921544562020275
Validation loss: 3.191985500036912

Epoch: 5| Step: 8
Training loss: 3.739722473332917
Validation loss: 3.190792463968887

Epoch: 5| Step: 9
Training loss: 3.4267967745897012
Validation loss: 3.1909385068575666

Epoch: 5| Step: 10
Training loss: 3.2008578581111706
Validation loss: 3.1899588613795307

Epoch: 245| Step: 0
Training loss: 3.5169330791303173
Validation loss: 3.190206930159894

Epoch: 5| Step: 1
Training loss: 3.275460357924585
Validation loss: 3.1905171356540416

Epoch: 5| Step: 2
Training loss: 3.469888311342092
Validation loss: 3.1894793669267094

Epoch: 5| Step: 3
Training loss: 3.2718484522226152
Validation loss: 3.1891451359642065

Epoch: 5| Step: 4
Training loss: 3.0469446418823893
Validation loss: 3.1890816549548346

Epoch: 5| Step: 5
Training loss: 3.522657896013144
Validation loss: 3.1894956836247643

Epoch: 5| Step: 6
Training loss: 3.2487376769339615
Validation loss: 3.1887792714099916

Epoch: 5| Step: 7
Training loss: 3.2175394392819743
Validation loss: 3.1879350854695288

Epoch: 5| Step: 8
Training loss: 4.1504685194896265
Validation loss: 3.1888223615930062

Epoch: 5| Step: 9
Training loss: 3.439644855308736
Validation loss: 3.188449487375062

Epoch: 5| Step: 10
Training loss: 3.5283954526838426
Validation loss: 3.187613869454221

Epoch: 246| Step: 0
Training loss: 3.0185990763781687
Validation loss: 3.187495762248945

Epoch: 5| Step: 1
Training loss: 3.5424057282884798
Validation loss: 3.18974452623586

Epoch: 5| Step: 2
Training loss: 3.635656674978124
Validation loss: 3.1872987050262083

Epoch: 5| Step: 3
Training loss: 3.415087792537302
Validation loss: 3.185670984602754

Epoch: 5| Step: 4
Training loss: 3.3418649368890856
Validation loss: 3.187324893105917

Epoch: 5| Step: 5
Training loss: 3.640247374502288
Validation loss: 3.1916889097580916

Epoch: 5| Step: 6
Training loss: 3.785649286210818
Validation loss: 3.1882577663350933

Epoch: 5| Step: 7
Training loss: 2.893681410435941
Validation loss: 3.18846840155378

Epoch: 5| Step: 8
Training loss: 3.6437725818909223
Validation loss: 3.1878300768757746

Epoch: 5| Step: 9
Training loss: 3.2755791479641636
Validation loss: 3.1857041389622114

Epoch: 5| Step: 10
Training loss: 3.486768370969102
Validation loss: 3.1876224540144644

Epoch: 247| Step: 0
Training loss: 3.8883017838548875
Validation loss: 3.1870787935603744

Epoch: 5| Step: 1
Training loss: 3.111332722748486
Validation loss: 3.185644233284042

Epoch: 5| Step: 2
Training loss: 2.9113377163400305
Validation loss: 3.184544015630236

Epoch: 5| Step: 3
Training loss: 3.2485050284305808
Validation loss: 3.1847297651254407

Epoch: 5| Step: 4
Training loss: 3.754487722021417
Validation loss: 3.184238773794749

Epoch: 5| Step: 5
Training loss: 3.7775434502375504
Validation loss: 3.1853356313007666

Epoch: 5| Step: 6
Training loss: 2.748570330664628
Validation loss: 3.185418410593714

Epoch: 5| Step: 7
Training loss: 3.9285780324508845
Validation loss: 3.1844621530972015

Epoch: 5| Step: 8
Training loss: 3.0494092525521697
Validation loss: 3.1831941582458714

Epoch: 5| Step: 9
Training loss: 3.3532147369748966
Validation loss: 3.1820835094923456

Epoch: 5| Step: 10
Training loss: 3.828415466499275
Validation loss: 3.180815291795241

Epoch: 248| Step: 0
Training loss: 3.6409998361052636
Validation loss: 3.180552444555599

Epoch: 5| Step: 1
Training loss: 3.694743009723132
Validation loss: 3.177949565337146

Epoch: 5| Step: 2
Training loss: 3.334041726815221
Validation loss: 3.17468256760032

Epoch: 5| Step: 3
Training loss: 3.024745608895921
Validation loss: 3.1727625754092843

Epoch: 5| Step: 4
Training loss: 3.314779109356043
Validation loss: 3.1677416955813995

Epoch: 5| Step: 5
Training loss: 3.4449718765417483
Validation loss: 3.159303544312821

Epoch: 5| Step: 6
Training loss: 3.8352365882837467
Validation loss: 3.1567534235401

Epoch: 5| Step: 7
Training loss: 3.5948601376381375
Validation loss: 3.1517295293397067

Epoch: 5| Step: 8
Training loss: 3.693327227310844
Validation loss: 3.1520967663397386

Epoch: 5| Step: 9
Training loss: 2.6803579131303468
Validation loss: 3.157236219498269

Epoch: 5| Step: 10
Training loss: 3.1434089126750844
Validation loss: 3.1587536617657315

Epoch: 249| Step: 0
Training loss: 2.811004495378969
Validation loss: 3.1552504129619265

Epoch: 5| Step: 1
Training loss: 3.470331329885458
Validation loss: 3.1517609315956436

Epoch: 5| Step: 2
Training loss: 3.4617673684099977
Validation loss: 3.151370954007786

Epoch: 5| Step: 3
Training loss: 4.346105142921657
Validation loss: 3.15459898567326

Epoch: 5| Step: 4
Training loss: 3.572158970395611
Validation loss: 3.1619865442622888

Epoch: 5| Step: 5
Training loss: 3.437071617483543
Validation loss: 3.160514810085905

Epoch: 5| Step: 6
Training loss: 2.4687728880774946
Validation loss: 3.1522207298518996

Epoch: 5| Step: 7
Training loss: 3.363785089021305
Validation loss: 3.1488982663241836

Epoch: 5| Step: 8
Training loss: 3.03515216527637
Validation loss: 3.154669919386778

Epoch: 5| Step: 9
Training loss: 3.341959964377703
Validation loss: 3.1506754208850287

Epoch: 5| Step: 10
Training loss: 3.8614586522023586
Validation loss: 3.1482476011490963

Epoch: 250| Step: 0
Training loss: 3.68710932844283
Validation loss: 3.145005287001502

Epoch: 5| Step: 1
Training loss: 3.9390510047463416
Validation loss: 3.143834502135349

Epoch: 5| Step: 2
Training loss: 2.8993806769612926
Validation loss: 3.1436990529307196

Epoch: 5| Step: 3
Training loss: 3.4956331258618314
Validation loss: 3.1422701013400216

Epoch: 5| Step: 4
Training loss: 3.4362510492983063
Validation loss: 3.143790782281568

Epoch: 5| Step: 5
Training loss: 3.8821728676498175
Validation loss: 3.141682616066831

Epoch: 5| Step: 6
Training loss: 2.354040316901695
Validation loss: 3.1423182095660103

Epoch: 5| Step: 7
Training loss: 2.9567619412742996
Validation loss: 3.1400939054825296

Epoch: 5| Step: 8
Training loss: 3.8099984889390406
Validation loss: 3.140178295404843

Epoch: 5| Step: 9
Training loss: 3.1677036762464654
Validation loss: 3.1424615174092745

Epoch: 5| Step: 10
Training loss: 3.4325182796027653
Validation loss: 3.1396933598048387

Epoch: 251| Step: 0
Training loss: 2.8154647459770907
Validation loss: 3.1417858623307198

Epoch: 5| Step: 1
Training loss: 3.810713552703971
Validation loss: 3.1414427052178655

Epoch: 5| Step: 2
Training loss: 3.7399764567159446
Validation loss: 3.1403548099388763

Epoch: 5| Step: 3
Training loss: 2.8108123802341276
Validation loss: 3.139084958107858

Epoch: 5| Step: 4
Training loss: 4.373817938107723
Validation loss: 3.1400050481590176

Epoch: 5| Step: 5
Training loss: 3.523892189342542
Validation loss: 3.1402583840110405

Epoch: 5| Step: 6
Training loss: 3.323416230887366
Validation loss: 3.140799157437002

Epoch: 5| Step: 7
Training loss: 3.0671640808175273
Validation loss: 3.1416417174399798

Epoch: 5| Step: 8
Training loss: 3.1296184743581676
Validation loss: 3.1406620296702696

Epoch: 5| Step: 9
Training loss: 2.8354399273488418
Validation loss: 3.1399943551639242

Epoch: 5| Step: 10
Training loss: 3.5928160407486955
Validation loss: 3.139518742539588

Epoch: 252| Step: 0
Training loss: 3.075175619925436
Validation loss: 3.137930091618529

Epoch: 5| Step: 1
Training loss: 2.8348119094053743
Validation loss: 3.1381487409485804

Epoch: 5| Step: 2
Training loss: 2.8280877379602414
Validation loss: 3.1380481657338093

Epoch: 5| Step: 3
Training loss: 3.727991242099675
Validation loss: 3.1375006959701373

Epoch: 5| Step: 4
Training loss: 3.3483441601950514
Validation loss: 3.1353965766537564

Epoch: 5| Step: 5
Training loss: 3.2322151970840727
Validation loss: 3.13806385039222

Epoch: 5| Step: 6
Training loss: 3.172880567686366
Validation loss: 3.1385664515789578

Epoch: 5| Step: 7
Training loss: 4.04150741630458
Validation loss: 3.137851060432697

Epoch: 5| Step: 8
Training loss: 3.582587511972991
Validation loss: 3.134900606433816

Epoch: 5| Step: 9
Training loss: 3.687046087744146
Validation loss: 3.1381208615330967

Epoch: 5| Step: 10
Training loss: 3.6463233981691263
Validation loss: 3.136140687372881

Epoch: 253| Step: 0
Training loss: 2.907160462540046
Validation loss: 3.1365185671957283

Epoch: 5| Step: 1
Training loss: 3.6254082811564996
Validation loss: 3.1346413776701514

Epoch: 5| Step: 2
Training loss: 3.6422996762289506
Validation loss: 3.138999296581804

Epoch: 5| Step: 3
Training loss: 3.840323805269718
Validation loss: 3.1364499219297732

Epoch: 5| Step: 4
Training loss: 2.675918642401056
Validation loss: 3.1363294457904427

Epoch: 5| Step: 5
Training loss: 3.540134562289435
Validation loss: 3.136767514650373

Epoch: 5| Step: 6
Training loss: 2.3964699493695307
Validation loss: 3.1380624174619434

Epoch: 5| Step: 7
Training loss: 3.6170820381494146
Validation loss: 3.141178226655712

Epoch: 5| Step: 8
Training loss: 3.949938066214293
Validation loss: 3.139800768670629

Epoch: 5| Step: 9
Training loss: 3.0009835538276843
Validation loss: 3.1353486541271294

Epoch: 5| Step: 10
Training loss: 3.796078194105295
Validation loss: 3.135048464688499

Epoch: 254| Step: 0
Training loss: 2.961222531733522
Validation loss: 3.1360515839726086

Epoch: 5| Step: 1
Training loss: 3.41177535974259
Validation loss: 3.134665847400238

Epoch: 5| Step: 2
Training loss: 3.428305519101208
Validation loss: 3.1347430795507885

Epoch: 5| Step: 3
Training loss: 4.0528160289214
Validation loss: 3.134720093951637

Epoch: 5| Step: 4
Training loss: 3.5829451298942616
Validation loss: 3.134629769202651

Epoch: 5| Step: 5
Training loss: 3.6372498678613385
Validation loss: 3.1350188649744277

Epoch: 5| Step: 6
Training loss: 3.182129468181725
Validation loss: 3.1341802707397406

Epoch: 5| Step: 7
Training loss: 3.849939093169938
Validation loss: 3.1355126457226676

Epoch: 5| Step: 8
Training loss: 2.7279911178824623
Validation loss: 3.1326526978231684

Epoch: 5| Step: 9
Training loss: 2.834735542086227
Validation loss: 3.1347077268346375

Epoch: 5| Step: 10
Training loss: 3.419466608180353
Validation loss: 3.1332327572824705

Epoch: 255| Step: 0
Training loss: 3.4366723191233
Validation loss: 3.1345572091727885

Epoch: 5| Step: 1
Training loss: 2.80090502009254
Validation loss: 3.1334813137255297

Epoch: 5| Step: 2
Training loss: 4.315756411419667
Validation loss: 3.134134641210523

Epoch: 5| Step: 3
Training loss: 3.4845635743709726
Validation loss: 3.133714576869582

Epoch: 5| Step: 4
Training loss: 3.449115894205377
Validation loss: 3.133239598324172

Epoch: 5| Step: 5
Training loss: 3.5028672054557846
Validation loss: 3.133384948725121

Epoch: 5| Step: 6
Training loss: 3.2024870446543883
Validation loss: 3.132935055633558

Epoch: 5| Step: 7
Training loss: 3.223100999140297
Validation loss: 3.1334679673051866

Epoch: 5| Step: 8
Training loss: 3.1581847049362333
Validation loss: 3.1314490307953906

Epoch: 5| Step: 9
Training loss: 2.963125743853804
Validation loss: 3.1324420610005292

Epoch: 5| Step: 10
Training loss: 3.5690287947109063
Validation loss: 3.1323234293579922

Epoch: 256| Step: 0
Training loss: 3.25850781675194
Validation loss: 3.131254284758569

Epoch: 5| Step: 1
Training loss: 3.5163441918454033
Validation loss: 3.133545816395503

Epoch: 5| Step: 2
Training loss: 3.522947560691311
Validation loss: 3.132689774264927

Epoch: 5| Step: 3
Training loss: 3.507759212777328
Validation loss: 3.1300867760845827

Epoch: 5| Step: 4
Training loss: 2.9840993704012604
Validation loss: 3.1347948680903075

Epoch: 5| Step: 5
Training loss: 3.536848508334877
Validation loss: 3.1317478363754687

Epoch: 5| Step: 6
Training loss: 3.1382725953639685
Validation loss: 3.130682849173776

Epoch: 5| Step: 7
Training loss: 3.073086405231085
Validation loss: 3.1319582808731394

Epoch: 5| Step: 8
Training loss: 3.32070525595266
Validation loss: 3.1322352862893

Epoch: 5| Step: 9
Training loss: 3.58186005460929
Validation loss: 3.131600788272305

Epoch: 5| Step: 10
Training loss: 3.8054232346176518
Validation loss: 3.132380193052057

Epoch: 257| Step: 0
Training loss: 3.47345778458919
Validation loss: 3.1337517389167764

Epoch: 5| Step: 1
Training loss: 2.892897583747774
Validation loss: 3.133786388246996

Epoch: 5| Step: 2
Training loss: 2.8394215937726854
Validation loss: 3.128225241391592

Epoch: 5| Step: 3
Training loss: 3.3702589572832453
Validation loss: 3.129681787796955

Epoch: 5| Step: 4
Training loss: 2.613583580057054
Validation loss: 3.1309686410035025

Epoch: 5| Step: 5
Training loss: 3.543941141453525
Validation loss: 3.1310004856547864

Epoch: 5| Step: 6
Training loss: 3.831347047656341
Validation loss: 3.1337908066123843

Epoch: 5| Step: 7
Training loss: 3.3195722405499013
Validation loss: 3.129081023626692

Epoch: 5| Step: 8
Training loss: 3.4851966881217793
Validation loss: 3.1280347826105177

Epoch: 5| Step: 9
Training loss: 3.6894993938172074
Validation loss: 3.127848539824102

Epoch: 5| Step: 10
Training loss: 4.014716257066726
Validation loss: 3.1255149695922806

Epoch: 258| Step: 0
Training loss: 3.305008099383011
Validation loss: 3.1274366399577187

Epoch: 5| Step: 1
Training loss: 3.5107390635851887
Validation loss: 3.1278479341264194

Epoch: 5| Step: 2
Training loss: 3.522634072063697
Validation loss: 3.127338209008442

Epoch: 5| Step: 3
Training loss: 3.5223229922999626
Validation loss: 3.128108087289701

Epoch: 5| Step: 4
Training loss: 3.465462166045388
Validation loss: 3.123965894994149

Epoch: 5| Step: 5
Training loss: 3.4223523786765453
Validation loss: 3.127760762433619

Epoch: 5| Step: 6
Training loss: 3.0051378123946955
Validation loss: 3.12556824470664

Epoch: 5| Step: 7
Training loss: 3.6272373529753104
Validation loss: 3.127347834517423

Epoch: 5| Step: 8
Training loss: 2.7817507518068947
Validation loss: 3.127212954187305

Epoch: 5| Step: 9
Training loss: 3.5122336072803266
Validation loss: 3.127019965228033

Epoch: 5| Step: 10
Training loss: 3.507082313034987
Validation loss: 3.12430954063177

Epoch: 259| Step: 0
Training loss: 3.687500258623534
Validation loss: 3.1249368657123213

Epoch: 5| Step: 1
Training loss: 2.7619330122087
Validation loss: 3.1245427623664566

Epoch: 5| Step: 2
Training loss: 3.6761037297935633
Validation loss: 3.124125974108389

Epoch: 5| Step: 3
Training loss: 3.606147545164046
Validation loss: 3.124766274192292

Epoch: 5| Step: 4
Training loss: 2.866207111102642
Validation loss: 3.128858550890818

Epoch: 5| Step: 5
Training loss: 3.0783827620501483
Validation loss: 3.1308721863832383

Epoch: 5| Step: 6
Training loss: 3.65714337772553
Validation loss: 3.1322568709059433

Epoch: 5| Step: 7
Training loss: 3.4409708706754425
Validation loss: 3.134564892175206

Epoch: 5| Step: 8
Training loss: 3.5976649976990553
Validation loss: 3.1308588222899054

Epoch: 5| Step: 9
Training loss: 3.0446272946724293
Validation loss: 3.124183932161303

Epoch: 5| Step: 10
Training loss: 3.67233611113179
Validation loss: 3.125160114739479

Epoch: 260| Step: 0
Training loss: 3.052371813232828
Validation loss: 3.1216835373279483

Epoch: 5| Step: 1
Training loss: 3.5433276750645595
Validation loss: 3.1260296608081775

Epoch: 5| Step: 2
Training loss: 3.3706040186894786
Validation loss: 3.1218452691080647

Epoch: 5| Step: 3
Training loss: 3.314628205314335
Validation loss: 3.1231824006675737

Epoch: 5| Step: 4
Training loss: 3.9292813464702725
Validation loss: 3.123148319103865

Epoch: 5| Step: 5
Training loss: 3.2064270862954305
Validation loss: 3.1226721069071584

Epoch: 5| Step: 6
Training loss: 3.6459645420260776
Validation loss: 3.123396837570346

Epoch: 5| Step: 7
Training loss: 2.7455181533305026
Validation loss: 3.1204043594484023

Epoch: 5| Step: 8
Training loss: 3.539363486183512
Validation loss: 3.122854850944391

Epoch: 5| Step: 9
Training loss: 3.5208265014822926
Validation loss: 3.120525099619708

Epoch: 5| Step: 10
Training loss: 3.140061209258218
Validation loss: 3.1244389873345284

Epoch: 261| Step: 0
Training loss: 2.3160194215503753
Validation loss: 3.1212879341095765

Epoch: 5| Step: 1
Training loss: 3.819773255653976
Validation loss: 3.118956295608906

Epoch: 5| Step: 2
Training loss: 3.640279597977693
Validation loss: 3.1202589252769406

Epoch: 5| Step: 3
Training loss: 3.3429254959207295
Validation loss: 3.120422203145997

Epoch: 5| Step: 4
Training loss: 3.033510918361971
Validation loss: 3.120536657043065

Epoch: 5| Step: 5
Training loss: 3.115157534808602
Validation loss: 3.120646700169014

Epoch: 5| Step: 6
Training loss: 3.7468899864170684
Validation loss: 3.120941458612586

Epoch: 5| Step: 7
Training loss: 2.9883101318559344
Validation loss: 3.1208627127001876

Epoch: 5| Step: 8
Training loss: 4.256464809649112
Validation loss: 3.120889492759891

Epoch: 5| Step: 9
Training loss: 3.5865536494925707
Validation loss: 3.121029807283365

Epoch: 5| Step: 10
Training loss: 2.778596619608451
Validation loss: 3.1223012793271576

Epoch: 262| Step: 0
Training loss: 3.905471968415795
Validation loss: 3.122634601188299

Epoch: 5| Step: 1
Training loss: 2.8285574397997615
Validation loss: 3.1219591370776407

Epoch: 5| Step: 2
Training loss: 3.5112688669612453
Validation loss: 3.1212734341282036

Epoch: 5| Step: 3
Training loss: 3.1092642759612046
Validation loss: 3.1197227399059266

Epoch: 5| Step: 4
Training loss: 3.151113579720249
Validation loss: 3.124381700281231

Epoch: 5| Step: 5
Training loss: 3.526540535928985
Validation loss: 3.1195513225104503

Epoch: 5| Step: 6
Training loss: 3.2896026385278176
Validation loss: 3.124758284870137

Epoch: 5| Step: 7
Training loss: 3.7141912390672305
Validation loss: 3.1182735135596347

Epoch: 5| Step: 8
Training loss: 3.0341169819216516
Validation loss: 3.119952309446173

Epoch: 5| Step: 9
Training loss: 3.136115029122993
Validation loss: 3.123393619266482

Epoch: 5| Step: 10
Training loss: 3.8316870485228023
Validation loss: 3.117713186688951

Epoch: 263| Step: 0
Training loss: 3.1786497329937182
Validation loss: 3.1180592809361727

Epoch: 5| Step: 1
Training loss: 3.9371911790632117
Validation loss: 3.114701902628212

Epoch: 5| Step: 2
Training loss: 3.217233244916704
Validation loss: 3.119685356507377

Epoch: 5| Step: 3
Training loss: 2.8005233071271176
Validation loss: 3.1176601490239753

Epoch: 5| Step: 4
Training loss: 3.48395457104782
Validation loss: 3.116723511432844

Epoch: 5| Step: 5
Training loss: 3.455102276758083
Validation loss: 3.1193967302824452

Epoch: 5| Step: 6
Training loss: 3.782105656431498
Validation loss: 3.1165161265135137

Epoch: 5| Step: 7
Training loss: 2.9715509954059915
Validation loss: 3.1190034754490714

Epoch: 5| Step: 8
Training loss: 2.722386701203764
Validation loss: 3.120214166847508

Epoch: 5| Step: 9
Training loss: 3.6094845181318207
Validation loss: 3.117810160231631

Epoch: 5| Step: 10
Training loss: 3.8100628176339044
Validation loss: 3.1183771303980894

Epoch: 264| Step: 0
Training loss: 3.269438784441446
Validation loss: 3.1173310354870942

Epoch: 5| Step: 1
Training loss: 3.2618810190736225
Validation loss: 3.1190873518807596

Epoch: 5| Step: 2
Training loss: 3.1239788675900044
Validation loss: 3.1166958096900683

Epoch: 5| Step: 3
Training loss: 3.351089266287886
Validation loss: 3.117684247148374

Epoch: 5| Step: 4
Training loss: 4.142451736270334
Validation loss: 3.115717417840287

Epoch: 5| Step: 5
Training loss: 3.563314779701378
Validation loss: 3.1186203545142117

Epoch: 5| Step: 6
Training loss: 3.197470982876988
Validation loss: 3.115903892068246

Epoch: 5| Step: 7
Training loss: 3.3166673465389405
Validation loss: 3.1151971928530067

Epoch: 5| Step: 8
Training loss: 2.955829653383181
Validation loss: 3.1176987029733754

Epoch: 5| Step: 9
Training loss: 3.932090676667894
Validation loss: 3.116767044243048

Epoch: 5| Step: 10
Training loss: 2.677793762305298
Validation loss: 3.116621014248229

Epoch: 265| Step: 0
Training loss: 3.0540377420967424
Validation loss: 3.1168720979048916

Epoch: 5| Step: 1
Training loss: 3.4599541845209996
Validation loss: 3.1168234620249513

Epoch: 5| Step: 2
Training loss: 3.3435708826879376
Validation loss: 3.1178278641927357

Epoch: 5| Step: 3
Training loss: 4.164306633468389
Validation loss: 3.1148204910035977

Epoch: 5| Step: 4
Training loss: 3.439439538498861
Validation loss: 3.115296795767718

Epoch: 5| Step: 5
Training loss: 3.420117349228695
Validation loss: 3.11467037202091

Epoch: 5| Step: 6
Training loss: 2.424205618456116
Validation loss: 3.114164539846948

Epoch: 5| Step: 7
Training loss: 4.034833158425886
Validation loss: 3.1139340562313254

Epoch: 5| Step: 8
Training loss: 3.220592082777243
Validation loss: 3.112524019272121

Epoch: 5| Step: 9
Training loss: 3.262032901459996
Validation loss: 3.1135582768920917

Epoch: 5| Step: 10
Training loss: 2.803918844743716
Validation loss: 3.1115613162143108

Epoch: 266| Step: 0
Training loss: 3.5952714436096285
Validation loss: 3.111810859738347

Epoch: 5| Step: 1
Training loss: 3.2195609839514336
Validation loss: 3.112398438440505

Epoch: 5| Step: 2
Training loss: 4.056957983644234
Validation loss: 3.1105458699656547

Epoch: 5| Step: 3
Training loss: 3.701771420355337
Validation loss: 3.1128790248916465

Epoch: 5| Step: 4
Training loss: 3.2200927896339477
Validation loss: 3.1117933497501684

Epoch: 5| Step: 5
Training loss: 3.509856106669669
Validation loss: 3.1141631222628345

Epoch: 5| Step: 6
Training loss: 3.4218065786270917
Validation loss: 3.1107010635847683

Epoch: 5| Step: 7
Training loss: 3.5987585576317747
Validation loss: 3.110444103859244

Epoch: 5| Step: 8
Training loss: 2.4691952653924467
Validation loss: 3.1123701174980707

Epoch: 5| Step: 9
Training loss: 3.172344003964921
Validation loss: 3.112668852861727

Epoch: 5| Step: 10
Training loss: 2.7016023084665095
Validation loss: 3.112643310809763

Epoch: 267| Step: 0
Training loss: 2.855222594874904
Validation loss: 3.1115240300289204

Epoch: 5| Step: 1
Training loss: 3.3116132880946796
Validation loss: 3.1101754429456956

Epoch: 5| Step: 2
Training loss: 3.7086557541030154
Validation loss: 3.109454466382009

Epoch: 5| Step: 3
Training loss: 3.5367778620615753
Validation loss: 3.1117332627359233

Epoch: 5| Step: 4
Training loss: 3.1455622339381755
Validation loss: 3.1079314878837354

Epoch: 5| Step: 5
Training loss: 3.7551214214254696
Validation loss: 3.1105478570559777

Epoch: 5| Step: 6
Training loss: 3.057032004945361
Validation loss: 3.10742494566955

Epoch: 5| Step: 7
Training loss: 3.737831973639155
Validation loss: 3.107159580605522

Epoch: 5| Step: 8
Training loss: 3.4053647352078693
Validation loss: 3.1075197174809195

Epoch: 5| Step: 9
Training loss: 2.540715169772789
Validation loss: 3.108398445747465

Epoch: 5| Step: 10
Training loss: 3.818733996968054
Validation loss: 3.1110611481312116

Epoch: 268| Step: 0
Training loss: 3.405152870365241
Validation loss: 3.109636292176893

Epoch: 5| Step: 1
Training loss: 3.1580530436471865
Validation loss: 3.111447498640991

Epoch: 5| Step: 2
Training loss: 3.4361088105048996
Validation loss: 3.109381107796961

Epoch: 5| Step: 3
Training loss: 2.9545216966220686
Validation loss: 3.1097056991673444

Epoch: 5| Step: 4
Training loss: 3.2063792003752645
Validation loss: 3.1078016349002726

Epoch: 5| Step: 5
Training loss: 3.3546383133202005
Validation loss: 3.1086104734100246

Epoch: 5| Step: 6
Training loss: 3.062108540331083
Validation loss: 3.108380426634431

Epoch: 5| Step: 7
Training loss: 3.2753674774170887
Validation loss: 3.1134108670309533

Epoch: 5| Step: 8
Training loss: 3.443925158689896
Validation loss: 3.108238068010162

Epoch: 5| Step: 9
Training loss: 3.788729245976335
Validation loss: 3.109075383318446

Epoch: 5| Step: 10
Training loss: 3.89775247613729
Validation loss: 3.1079362086133497

Epoch: 269| Step: 0
Training loss: 3.2679769269205763
Validation loss: 3.1057804953430175

Epoch: 5| Step: 1
Training loss: 3.1479576634973787
Validation loss: 3.105271367415884

Epoch: 5| Step: 2
Training loss: 3.236727978184256
Validation loss: 3.1045527284534304

Epoch: 5| Step: 3
Training loss: 3.077845681776869
Validation loss: 3.106081393876519

Epoch: 5| Step: 4
Training loss: 3.426058228451643
Validation loss: 3.103818647772858

Epoch: 5| Step: 5
Training loss: 3.263084482037519
Validation loss: 3.1055000652896942

Epoch: 5| Step: 6
Training loss: 3.882869113685924
Validation loss: 3.1043515664764167

Epoch: 5| Step: 7
Training loss: 3.5058444137041485
Validation loss: 3.1063308089952812

Epoch: 5| Step: 8
Training loss: 2.947216764112047
Validation loss: 3.105300962559333

Epoch: 5| Step: 9
Training loss: 3.3400362015092857
Validation loss: 3.104718356602572

Epoch: 5| Step: 10
Training loss: 3.8674627032759434
Validation loss: 3.1053558145394753

Epoch: 270| Step: 0
Training loss: 3.400419091593582
Validation loss: 3.1028588934444508

Epoch: 5| Step: 1
Training loss: 3.259924480757071
Validation loss: 3.104582498902553

Epoch: 5| Step: 2
Training loss: 3.000410687628211
Validation loss: 3.1059696997955246

Epoch: 5| Step: 3
Training loss: 3.180641574797692
Validation loss: 3.1029906428166876

Epoch: 5| Step: 4
Training loss: 3.8663062738861247
Validation loss: 3.1057199353991

Epoch: 5| Step: 5
Training loss: 3.2914847472577877
Validation loss: 3.111603453885899

Epoch: 5| Step: 6
Training loss: 3.5392216189826153
Validation loss: 3.1083361586207348

Epoch: 5| Step: 7
Training loss: 3.4252092673419896
Validation loss: 3.1156759027307084

Epoch: 5| Step: 8
Training loss: 3.227820052065044
Validation loss: 3.110742842877155

Epoch: 5| Step: 9
Training loss: 3.355267804027447
Validation loss: 3.1075264592075866

Epoch: 5| Step: 10
Training loss: 3.4060940488059814
Validation loss: 3.106107498306834

Epoch: 271| Step: 0
Training loss: 3.3468934016785936
Validation loss: 3.102066007848239

Epoch: 5| Step: 1
Training loss: 3.6990607126187656
Validation loss: 3.1024835657701164

Epoch: 5| Step: 2
Training loss: 3.799881863012528
Validation loss: 3.1036832429855363

Epoch: 5| Step: 3
Training loss: 3.4765823878030173
Validation loss: 3.1005561534822768

Epoch: 5| Step: 4
Training loss: 3.6231330799633223
Validation loss: 3.1021033688739665

Epoch: 5| Step: 5
Training loss: 2.494000388364907
Validation loss: 3.1037214022733055

Epoch: 5| Step: 6
Training loss: 3.843987806453677
Validation loss: 3.1027586681693475

Epoch: 5| Step: 7
Training loss: 3.1542377667159225
Validation loss: 3.1035468426999673

Epoch: 5| Step: 8
Training loss: 2.3757175566224187
Validation loss: 3.1024430444819915

Epoch: 5| Step: 9
Training loss: 3.2052385009959248
Validation loss: 3.1022939726866574

Epoch: 5| Step: 10
Training loss: 3.655873597161539
Validation loss: 3.100492296549735

Epoch: 272| Step: 0
Training loss: 3.4388434819140907
Validation loss: 3.100938215861514

Epoch: 5| Step: 1
Training loss: 3.422448375861499
Validation loss: 3.101215445935683

Epoch: 5| Step: 2
Training loss: 3.4201434209097554
Validation loss: 3.1027069067569886

Epoch: 5| Step: 3
Training loss: 3.14351115295849
Validation loss: 3.101459637334615

Epoch: 5| Step: 4
Training loss: 3.090298200866039
Validation loss: 3.102299387053875

Epoch: 5| Step: 5
Training loss: 2.8051583152605732
Validation loss: 3.102528351928237

Epoch: 5| Step: 6
Training loss: 3.3070358698087414
Validation loss: 3.101535272854588

Epoch: 5| Step: 7
Training loss: 3.249366405055262
Validation loss: 3.103733225461474

Epoch: 5| Step: 8
Training loss: 3.4695884447337666
Validation loss: 3.0996685788380396

Epoch: 5| Step: 9
Training loss: 3.7334061008128256
Validation loss: 3.1014038071789614

Epoch: 5| Step: 10
Training loss: 3.857455251042317
Validation loss: 3.099035544022584

Epoch: 273| Step: 0
Training loss: 3.6017904809384875
Validation loss: 3.1006437766465185

Epoch: 5| Step: 1
Training loss: 3.2017627331368885
Validation loss: 3.097613637900308

Epoch: 5| Step: 2
Training loss: 3.632525820341711
Validation loss: 3.098440592613177

Epoch: 5| Step: 3
Training loss: 2.869101901276716
Validation loss: 3.100858279899109

Epoch: 5| Step: 4
Training loss: 3.641229931258459
Validation loss: 3.0982969233665005

Epoch: 5| Step: 5
Training loss: 3.2294523215334987
Validation loss: 3.097873401384551

Epoch: 5| Step: 6
Training loss: 3.1234203160678193
Validation loss: 3.0985875911069467

Epoch: 5| Step: 7
Training loss: 3.3356317384482743
Validation loss: 3.0994783809799404

Epoch: 5| Step: 8
Training loss: 3.0605323854455193
Validation loss: 3.0998659236902992

Epoch: 5| Step: 9
Training loss: 3.560083205290133
Validation loss: 3.0975123225649823

Epoch: 5| Step: 10
Training loss: 3.6041463656579555
Validation loss: 3.0961005242575195

Epoch: 274| Step: 0
Training loss: 3.444204416081226
Validation loss: 3.095456028031492

Epoch: 5| Step: 1
Training loss: 3.075834864971972
Validation loss: 3.0964446999693473

Epoch: 5| Step: 2
Training loss: 3.4471770969510893
Validation loss: 3.096106501745569

Epoch: 5| Step: 3
Training loss: 3.202908987809659
Validation loss: 3.1023531682634924

Epoch: 5| Step: 4
Training loss: 3.013294327351225
Validation loss: 3.101220237234419

Epoch: 5| Step: 5
Training loss: 3.5754839216171392
Validation loss: 3.104707260502873

Epoch: 5| Step: 6
Training loss: 3.4359264586975136
Validation loss: 3.0997037050980683

Epoch: 5| Step: 7
Training loss: 3.1589667081899027
Validation loss: 3.0997563164129827

Epoch: 5| Step: 8
Training loss: 3.559303723727676
Validation loss: 3.099672346963353

Epoch: 5| Step: 9
Training loss: 3.5040182480619966
Validation loss: 3.094372130439765

Epoch: 5| Step: 10
Training loss: 3.4587319538843713
Validation loss: 3.095266039279438

Epoch: 275| Step: 0
Training loss: 3.442718705908558
Validation loss: 3.0926174146986654

Epoch: 5| Step: 1
Training loss: 3.391043079108208
Validation loss: 3.0927828075202846

Epoch: 5| Step: 2
Training loss: 2.7006763105720135
Validation loss: 3.094034052015075

Epoch: 5| Step: 3
Training loss: 2.964490866989451
Validation loss: 3.0932884779435366

Epoch: 5| Step: 4
Training loss: 3.9761123252522004
Validation loss: 3.0898881269683733

Epoch: 5| Step: 5
Training loss: 3.5367548073425645
Validation loss: 3.0936332308535768

Epoch: 5| Step: 6
Training loss: 2.990933546454866
Validation loss: 3.0941093089501712

Epoch: 5| Step: 7
Training loss: 3.272901686924083
Validation loss: 3.0924522716791634

Epoch: 5| Step: 8
Training loss: 3.953500119229671
Validation loss: 3.091308213513195

Epoch: 5| Step: 9
Training loss: 3.00919490604114
Validation loss: 3.0952431034158954

Epoch: 5| Step: 10
Training loss: 3.4144190551887497
Validation loss: 3.0911699194877325

Epoch: 276| Step: 0
Training loss: 3.6203706054239357
Validation loss: 3.094510820677605

Epoch: 5| Step: 1
Training loss: 3.337052098769197
Validation loss: 3.0933623242434134

Epoch: 5| Step: 2
Training loss: 2.908883491079155
Validation loss: 3.092382246148095

Epoch: 5| Step: 3
Training loss: 3.0428803691834667
Validation loss: 3.0901752716855952

Epoch: 5| Step: 4
Training loss: 3.8220977044584767
Validation loss: 3.092063910881376

Epoch: 5| Step: 5
Training loss: 3.3607494292760647
Validation loss: 3.092391072690456

Epoch: 5| Step: 6
Training loss: 3.5667689662297266
Validation loss: 3.0931633411381587

Epoch: 5| Step: 7
Training loss: 3.249195145936069
Validation loss: 3.090991009232685

Epoch: 5| Step: 8
Training loss: 3.28624425191801
Validation loss: 3.09357243477155

Epoch: 5| Step: 9
Training loss: 3.069095749033555
Validation loss: 3.093647870329213

Epoch: 5| Step: 10
Training loss: 3.5184346140697125
Validation loss: 3.090587850729578

Epoch: 277| Step: 0
Training loss: 2.9829908426561764
Validation loss: 3.090661399903427

Epoch: 5| Step: 1
Training loss: 4.118501572938734
Validation loss: 3.089942759728286

Epoch: 5| Step: 2
Training loss: 3.3892916681483443
Validation loss: 3.0901505525240016

Epoch: 5| Step: 3
Training loss: 3.4086980859253595
Validation loss: 3.0928544245720437

Epoch: 5| Step: 4
Training loss: 3.68858256855547
Validation loss: 3.0905006873669967

Epoch: 5| Step: 5
Training loss: 2.767806749720144
Validation loss: 3.08976769801315

Epoch: 5| Step: 6
Training loss: 3.9048692628122343
Validation loss: 3.0890869816860587

Epoch: 5| Step: 7
Training loss: 3.2096523859634245
Validation loss: 3.0899506084204775

Epoch: 5| Step: 8
Training loss: 3.1384383603142023
Validation loss: 3.0872616339461962

Epoch: 5| Step: 9
Training loss: 2.502222789612264
Validation loss: 3.0867015004518583

Epoch: 5| Step: 10
Training loss: 3.4042750241338324
Validation loss: 3.087617548959672

Epoch: 278| Step: 0
Training loss: 3.091934904679099
Validation loss: 3.089573213099358

Epoch: 5| Step: 1
Training loss: 3.6192564351327072
Validation loss: 3.0884978176384554

Epoch: 5| Step: 2
Training loss: 4.260554503408408
Validation loss: 3.088531268903186

Epoch: 5| Step: 3
Training loss: 3.8831783252826315
Validation loss: 3.087695790207809

Epoch: 5| Step: 4
Training loss: 2.878705829077749
Validation loss: 3.0871065184385333

Epoch: 5| Step: 5
Training loss: 3.1627432627845504
Validation loss: 3.0864679925499345

Epoch: 5| Step: 6
Training loss: 3.0680741943081795
Validation loss: 3.0876224128376544

Epoch: 5| Step: 7
Training loss: 2.6720100948691266
Validation loss: 3.087056932779341

Epoch: 5| Step: 8
Training loss: 3.6053066031219383
Validation loss: 3.086171102865708

Epoch: 5| Step: 9
Training loss: 3.385783311601272
Validation loss: 3.085036544570057

Epoch: 5| Step: 10
Training loss: 2.739522655284073
Validation loss: 3.0844429107130775

Epoch: 279| Step: 0
Training loss: 2.934751482812325
Validation loss: 3.0858869086101337

Epoch: 5| Step: 1
Training loss: 3.1181606982052004
Validation loss: 3.0902431662308327

Epoch: 5| Step: 2
Training loss: 3.4314059251609943
Validation loss: 3.0872771780347565

Epoch: 5| Step: 3
Training loss: 3.8333253998605206
Validation loss: 3.0881272812202165

Epoch: 5| Step: 4
Training loss: 2.670662409589361
Validation loss: 3.0857958631201834

Epoch: 5| Step: 5
Training loss: 3.10090395760802
Validation loss: 3.0873653258774367

Epoch: 5| Step: 6
Training loss: 2.9365927735932202
Validation loss: 3.0855291546828503

Epoch: 5| Step: 7
Training loss: 3.974082548200849
Validation loss: 3.085719492034038

Epoch: 5| Step: 8
Training loss: 3.951124084455172
Validation loss: 3.084269535862235

Epoch: 5| Step: 9
Training loss: 3.574802105101373
Validation loss: 3.084385022101197

Epoch: 5| Step: 10
Training loss: 2.88819147723195
Validation loss: 3.083753996680032

Epoch: 280| Step: 0
Training loss: 3.2768490296301844
Validation loss: 3.0872929960719926

Epoch: 5| Step: 1
Training loss: 4.251750136906515
Validation loss: 3.084917799347351

Epoch: 5| Step: 2
Training loss: 3.509863578775359
Validation loss: 3.0860067330451653

Epoch: 5| Step: 3
Training loss: 2.9781252946082946
Validation loss: 3.083370082694978

Epoch: 5| Step: 4
Training loss: 3.2445306974061956
Validation loss: 3.0854858067862496

Epoch: 5| Step: 5
Training loss: 3.33096779492172
Validation loss: 3.0816489332845065

Epoch: 5| Step: 6
Training loss: 2.3802133862019557
Validation loss: 3.0831064247729962

Epoch: 5| Step: 7
Training loss: 2.890179738985972
Validation loss: 3.0837643434903987

Epoch: 5| Step: 8
Training loss: 3.178079784450511
Validation loss: 3.0823178449655613

Epoch: 5| Step: 9
Training loss: 3.7177312401154645
Validation loss: 3.083321173615384

Epoch: 5| Step: 10
Training loss: 3.728929451727001
Validation loss: 3.0839791512603703

Epoch: 281| Step: 0
Training loss: 2.391097576829044
Validation loss: 3.082057719498642

Epoch: 5| Step: 1
Training loss: 3.531210164883515
Validation loss: 3.0846332336431077

Epoch: 5| Step: 2
Training loss: 4.175652212035148
Validation loss: 3.0818053591570593

Epoch: 5| Step: 3
Training loss: 3.5710923826840526
Validation loss: 3.081503205787814

Epoch: 5| Step: 4
Training loss: 2.9090769155122405
Validation loss: 3.0811489108693553

Epoch: 5| Step: 5
Training loss: 3.431826817124427
Validation loss: 3.080747486756578

Epoch: 5| Step: 6
Training loss: 3.5309850542718544
Validation loss: 3.0841245714131236

Epoch: 5| Step: 7
Training loss: 2.707983160611738
Validation loss: 3.0831921341971826

Epoch: 5| Step: 8
Training loss: 3.397692368473952
Validation loss: 3.087798279473852

Epoch: 5| Step: 9
Training loss: 3.600521839255195
Validation loss: 3.0824784876205307

Epoch: 5| Step: 10
Training loss: 3.159580399866833
Validation loss: 3.093076204767531

Epoch: 282| Step: 0
Training loss: 3.702860633652503
Validation loss: 3.091843621874053

Epoch: 5| Step: 1
Training loss: 2.9998359635329175
Validation loss: 3.0857350048432046

Epoch: 5| Step: 2
Training loss: 3.0317880998408224
Validation loss: 3.085740675074522

Epoch: 5| Step: 3
Training loss: 3.7252851492273984
Validation loss: 3.084018861102336

Epoch: 5| Step: 4
Training loss: 2.9359828196342534
Validation loss: 3.080960890608183

Epoch: 5| Step: 5
Training loss: 3.7966171616655555
Validation loss: 3.0783618556658463

Epoch: 5| Step: 6
Training loss: 3.355882825604102
Validation loss: 3.078732725534655

Epoch: 5| Step: 7
Training loss: 2.9906046293675024
Validation loss: 3.081497479506285

Epoch: 5| Step: 8
Training loss: 3.0703935685265846
Validation loss: 3.078323436983008

Epoch: 5| Step: 9
Training loss: 3.5503494789139163
Validation loss: 3.0794861068676322

Epoch: 5| Step: 10
Training loss: 3.453925682898496
Validation loss: 3.0771800309973822

Epoch: 283| Step: 0
Training loss: 3.5143285098554897
Validation loss: 3.0789560824596545

Epoch: 5| Step: 1
Training loss: 3.828006166443198
Validation loss: 3.0784689694051024

Epoch: 5| Step: 2
Training loss: 3.6918113203677287
Validation loss: 3.078988688197778

Epoch: 5| Step: 3
Training loss: 3.5256527451896176
Validation loss: 3.0779920813424715

Epoch: 5| Step: 4
Training loss: 2.3952311104460735
Validation loss: 3.0773769994159825

Epoch: 5| Step: 5
Training loss: 2.8066757083152174
Validation loss: 3.0789953683348585

Epoch: 5| Step: 6
Training loss: 3.427226997927728
Validation loss: 3.075890554132665

Epoch: 5| Step: 7
Training loss: 3.1770287347490105
Validation loss: 3.078381642782693

Epoch: 5| Step: 8
Training loss: 2.921644885135575
Validation loss: 3.078982380230028

Epoch: 5| Step: 9
Training loss: 3.3976704751333338
Validation loss: 3.0788463769359202

Epoch: 5| Step: 10
Training loss: 3.821652542090374
Validation loss: 3.0774289952689937

Epoch: 284| Step: 0
Training loss: 3.2364066557026883
Validation loss: 3.0809887655393595

Epoch: 5| Step: 1
Training loss: 3.274906093037309
Validation loss: 3.0780033253887367

Epoch: 5| Step: 2
Training loss: 2.69071404534596
Validation loss: 3.082096232204844

Epoch: 5| Step: 3
Training loss: 3.469865911569913
Validation loss: 3.076318335053768

Epoch: 5| Step: 4
Training loss: 3.5084082558455276
Validation loss: 3.0766403943083778

Epoch: 5| Step: 5
Training loss: 3.9107593600965793
Validation loss: 3.076421521681333

Epoch: 5| Step: 6
Training loss: 3.5782955745368494
Validation loss: 3.0765720104197047

Epoch: 5| Step: 7
Training loss: 2.838162476763238
Validation loss: 3.0804139700528164

Epoch: 5| Step: 8
Training loss: 3.6268733215591094
Validation loss: 3.078183980763666

Epoch: 5| Step: 9
Training loss: 2.2181402093790994
Validation loss: 3.073716012568413

Epoch: 5| Step: 10
Training loss: 4.068550182305424
Validation loss: 3.079263291248638

Epoch: 285| Step: 0
Training loss: 2.86200430630214
Validation loss: 3.0748011035424376

Epoch: 5| Step: 1
Training loss: 3.4337523405319144
Validation loss: 3.0807601586939812

Epoch: 5| Step: 2
Training loss: 2.9530139074673034
Validation loss: 3.0874680926516853

Epoch: 5| Step: 3
Training loss: 3.939565328835603
Validation loss: 3.086454131356138

Epoch: 5| Step: 4
Training loss: 2.990533516021718
Validation loss: 3.0774138221274785

Epoch: 5| Step: 5
Training loss: 3.5162904914832627
Validation loss: 3.0739765261786363

Epoch: 5| Step: 6
Training loss: 3.621905485852676
Validation loss: 3.0760987561181166

Epoch: 5| Step: 7
Training loss: 3.37891838644858
Validation loss: 3.0749596869327873

Epoch: 5| Step: 8
Training loss: 2.5827870150195533
Validation loss: 3.077100081042077

Epoch: 5| Step: 9
Training loss: 3.1287291592167894
Validation loss: 3.076588458455721

Epoch: 5| Step: 10
Training loss: 4.14415363169853
Validation loss: 3.0805276243393585

Epoch: 286| Step: 0
Training loss: 3.825434770994506
Validation loss: 3.075684008425662

Epoch: 5| Step: 1
Training loss: 3.271928316427014
Validation loss: 3.0758028792546335

Epoch: 5| Step: 2
Training loss: 3.1854286195286665
Validation loss: 3.0734836200656312

Epoch: 5| Step: 3
Training loss: 3.456765995517503
Validation loss: 3.073635492081903

Epoch: 5| Step: 4
Training loss: 3.3686857143064652
Validation loss: 3.074487211742113

Epoch: 5| Step: 5
Training loss: 3.4134751432236565
Validation loss: 3.0744997969136403

Epoch: 5| Step: 6
Training loss: 2.6787338116789035
Validation loss: 3.0724246262939294

Epoch: 5| Step: 7
Training loss: 2.9099181621881267
Validation loss: 3.0726343346748766

Epoch: 5| Step: 8
Training loss: 4.123684528868319
Validation loss: 3.075512642175838

Epoch: 5| Step: 9
Training loss: 3.6778222801330633
Validation loss: 3.0729183321462172

Epoch: 5| Step: 10
Training loss: 2.2174471401378253
Validation loss: 3.07705725425815

Epoch: 287| Step: 0
Training loss: 3.3028056962102608
Validation loss: 3.0761744218286093

Epoch: 5| Step: 1
Training loss: 3.1761352792174407
Validation loss: 3.08204866289984

Epoch: 5| Step: 2
Training loss: 3.2091534709898513
Validation loss: 3.083015293014024

Epoch: 5| Step: 3
Training loss: 3.5374482707093167
Validation loss: 3.0782701370538508

Epoch: 5| Step: 4
Training loss: 3.24951799192905
Validation loss: 3.081257318845237

Epoch: 5| Step: 5
Training loss: 3.4287601685799105
Validation loss: 3.079201365557384

Epoch: 5| Step: 6
Training loss: 3.691146470067094
Validation loss: 3.074902390155453

Epoch: 5| Step: 7
Training loss: 3.495129738993249
Validation loss: 3.072215377571635

Epoch: 5| Step: 8
Training loss: 3.0244588383632554
Validation loss: 3.071672974961264

Epoch: 5| Step: 9
Training loss: 3.4551679686859647
Validation loss: 3.0719239202706365

Epoch: 5| Step: 10
Training loss: 2.990592033180611
Validation loss: 3.0716590444995173

Epoch: 288| Step: 0
Training loss: 3.1442983221183964
Validation loss: 3.068553715664687

Epoch: 5| Step: 1
Training loss: 2.686592392364115
Validation loss: 3.069630882629312

Epoch: 5| Step: 2
Training loss: 3.6271629457685313
Validation loss: 3.0709363682470396

Epoch: 5| Step: 3
Training loss: 3.8404818651734414
Validation loss: 3.0713589379180624

Epoch: 5| Step: 4
Training loss: 3.997330012903071
Validation loss: 3.069113398208319

Epoch: 5| Step: 5
Training loss: 3.3620200456320073
Validation loss: 3.070001881155165

Epoch: 5| Step: 6
Training loss: 2.676446940459993
Validation loss: 3.0709353280767497

Epoch: 5| Step: 7
Training loss: 3.2287729002716063
Validation loss: 3.070464592322056

Epoch: 5| Step: 8
Training loss: 2.8287568624685457
Validation loss: 3.07265664834736

Epoch: 5| Step: 9
Training loss: 3.5030362719444677
Validation loss: 3.07083806976324

Epoch: 5| Step: 10
Training loss: 3.533782995749366
Validation loss: 3.0698579816405505

Epoch: 289| Step: 0
Training loss: 3.372609457469439
Validation loss: 3.073045404545173

Epoch: 5| Step: 1
Training loss: 3.408774184339487
Validation loss: 3.0676971713348653

Epoch: 5| Step: 2
Training loss: 3.7617854254053342
Validation loss: 3.070561778974323

Epoch: 5| Step: 3
Training loss: 2.4125835740234884
Validation loss: 3.072968684041769

Epoch: 5| Step: 4
Training loss: 3.739307928260072
Validation loss: 3.0689791294496604

Epoch: 5| Step: 5
Training loss: 2.948693234947176
Validation loss: 3.070327118744311

Epoch: 5| Step: 6
Training loss: 3.10003240014649
Validation loss: 3.073487461999686

Epoch: 5| Step: 7
Training loss: 3.862751584053764
Validation loss: 3.0737175405522796

Epoch: 5| Step: 8
Training loss: 3.383873753224075
Validation loss: 3.0757881765150006

Epoch: 5| Step: 9
Training loss: 2.6863237512687967
Validation loss: 3.078053416699314

Epoch: 5| Step: 10
Training loss: 3.6986726802931975
Validation loss: 3.073452064476356

Epoch: 290| Step: 0
Training loss: 2.88526064087099
Validation loss: 3.0713249715835036

Epoch: 5| Step: 1
Training loss: 3.1609303736924583
Validation loss: 3.0654671772457727

Epoch: 5| Step: 2
Training loss: 3.2125369355568343
Validation loss: 3.0713767911065997

Epoch: 5| Step: 3
Training loss: 3.824488317634613
Validation loss: 3.0661480714142195

Epoch: 5| Step: 4
Training loss: 3.148565625785483
Validation loss: 3.068318521699689

Epoch: 5| Step: 5
Training loss: 3.3430319041727516
Validation loss: 3.0654934477270914

Epoch: 5| Step: 6
Training loss: 3.8543574655405237
Validation loss: 3.063362547582622

Epoch: 5| Step: 7
Training loss: 3.4840569457908797
Validation loss: 3.0627025489551585

Epoch: 5| Step: 8
Training loss: 2.730381605424904
Validation loss: 3.0650597983296954

Epoch: 5| Step: 9
Training loss: 3.2616614422360777
Validation loss: 3.065509371478158

Epoch: 5| Step: 10
Training loss: 3.5999512616143203
Validation loss: 3.0617248469951988

Epoch: 291| Step: 0
Training loss: 3.683148159936278
Validation loss: 3.063754831060428

Epoch: 5| Step: 1
Training loss: 3.4230456157099987
Validation loss: 3.0638484133493713

Epoch: 5| Step: 2
Training loss: 3.569329792231372
Validation loss: 3.0646240037822534

Epoch: 5| Step: 3
Training loss: 3.219120633906044
Validation loss: 3.0624249842356535

Epoch: 5| Step: 4
Training loss: 3.256747503953046
Validation loss: 3.0642463186967586

Epoch: 5| Step: 5
Training loss: 2.7856200956832513
Validation loss: 3.062889913080869

Epoch: 5| Step: 6
Training loss: 3.240978190084141
Validation loss: 3.0641018326224505

Epoch: 5| Step: 7
Training loss: 3.692378163429366
Validation loss: 3.0646527534063446

Epoch: 5| Step: 8
Training loss: 2.986863621564139
Validation loss: 3.0643071779107616

Epoch: 5| Step: 9
Training loss: 3.224671629519058
Validation loss: 3.0617602327324014

Epoch: 5| Step: 10
Training loss: 3.459949085324041
Validation loss: 3.0623390795025554

Epoch: 292| Step: 0
Training loss: 3.6052736702793955
Validation loss: 3.061324598221917

Epoch: 5| Step: 1
Training loss: 3.337384019758127
Validation loss: 3.0606391096504897

Epoch: 5| Step: 2
Training loss: 2.2408149585511956
Validation loss: 3.059725479204852

Epoch: 5| Step: 3
Training loss: 3.5474073371855632
Validation loss: 3.0593059576374464

Epoch: 5| Step: 4
Training loss: 3.7197623277438496
Validation loss: 3.0627131669386456

Epoch: 5| Step: 5
Training loss: 3.2906194703145313
Validation loss: 3.0616534220071476

Epoch: 5| Step: 6
Training loss: 3.548952813233312
Validation loss: 3.06104164650935

Epoch: 5| Step: 7
Training loss: 3.4117341296506885
Validation loss: 3.0642023166585246

Epoch: 5| Step: 8
Training loss: 3.399763177589917
Validation loss: 3.060390348495872

Epoch: 5| Step: 9
Training loss: 3.3817026903525242
Validation loss: 3.059409080370101

Epoch: 5| Step: 10
Training loss: 2.7703356953277574
Validation loss: 3.059896225712144

Epoch: 293| Step: 0
Training loss: 3.0387370663441784
Validation loss: 3.0650416264749127

Epoch: 5| Step: 1
Training loss: 3.6765733892990435
Validation loss: 3.061240653232603

Epoch: 5| Step: 2
Training loss: 3.3118276813479266
Validation loss: 3.0661278408017343

Epoch: 5| Step: 3
Training loss: 3.433173074654796
Validation loss: 3.061962552654851

Epoch: 5| Step: 4
Training loss: 3.9292076834152176
Validation loss: 3.062121651076792

Epoch: 5| Step: 5
Training loss: 3.441754015044254
Validation loss: 3.0592804259221165

Epoch: 5| Step: 6
Training loss: 3.0678503827214523
Validation loss: 3.059584867777703

Epoch: 5| Step: 7
Training loss: 3.4824602143150334
Validation loss: 3.0602166019973343

Epoch: 5| Step: 8
Training loss: 2.5026275178505943
Validation loss: 3.0610440149753004

Epoch: 5| Step: 9
Training loss: 3.0989870385301757
Validation loss: 3.061856200283045

Epoch: 5| Step: 10
Training loss: 3.4008572787920532
Validation loss: 3.061150759866679

Epoch: 294| Step: 0
Training loss: 3.651171295143115
Validation loss: 3.0609795196864664

Epoch: 5| Step: 1
Training loss: 3.6681338467071236
Validation loss: 3.0598094976005705

Epoch: 5| Step: 2
Training loss: 2.517164339874202
Validation loss: 3.061195356819716

Epoch: 5| Step: 3
Training loss: 3.5760665369692233
Validation loss: 3.0576006550174775

Epoch: 5| Step: 4
Training loss: 3.123182760196538
Validation loss: 3.061098881969351

Epoch: 5| Step: 5
Training loss: 3.064098485942509
Validation loss: 3.0599529748877377

Epoch: 5| Step: 6
Training loss: 2.906496591258548
Validation loss: 3.0631125755998885

Epoch: 5| Step: 7
Training loss: 3.5716710417046205
Validation loss: 3.0592324356423752

Epoch: 5| Step: 8
Training loss: 3.360804763648551
Validation loss: 3.062439282342566

Epoch: 5| Step: 9
Training loss: 3.6541251504613763
Validation loss: 3.059149417083119

Epoch: 5| Step: 10
Training loss: 3.2568215891737906
Validation loss: 3.0602362467440183

Epoch: 295| Step: 0
Training loss: 3.203268057257005
Validation loss: 3.0628040439876236

Epoch: 5| Step: 1
Training loss: 2.803700052769711
Validation loss: 3.0584346801278226

Epoch: 5| Step: 2
Training loss: 3.0719356371773094
Validation loss: 3.0575822350872373

Epoch: 5| Step: 3
Training loss: 3.43144136044617
Validation loss: 3.0600025523716163

Epoch: 5| Step: 4
Training loss: 3.5224585008308735
Validation loss: 3.060401835637725

Epoch: 5| Step: 5
Training loss: 3.0715369968983657
Validation loss: 3.0583687701914295

Epoch: 5| Step: 6
Training loss: 3.29209502768764
Validation loss: 3.0569530342217437

Epoch: 5| Step: 7
Training loss: 3.949742253260015
Validation loss: 3.0606126659955546

Epoch: 5| Step: 8
Training loss: 3.1786804854052093
Validation loss: 3.058803994256939

Epoch: 5| Step: 9
Training loss: 3.610294637729145
Validation loss: 3.056963568186178

Epoch: 5| Step: 10
Training loss: 3.3240765945754025
Validation loss: 3.0584655130510874

Epoch: 296| Step: 0
Training loss: 3.1149694061001534
Validation loss: 3.0577271038494387

Epoch: 5| Step: 1
Training loss: 3.2274295851799653
Validation loss: 3.0551972201167934

Epoch: 5| Step: 2
Training loss: 2.767816741929772
Validation loss: 3.0548952286584456

Epoch: 5| Step: 3
Training loss: 3.579610457937932
Validation loss: 3.0553588255392086

Epoch: 5| Step: 4
Training loss: 3.72064968281009
Validation loss: 3.055041682442666

Epoch: 5| Step: 5
Training loss: 3.144707299274117
Validation loss: 3.056125468269851

Epoch: 5| Step: 6
Training loss: 3.3885618340382377
Validation loss: 3.055330611053461

Epoch: 5| Step: 7
Training loss: 3.6568563887677197
Validation loss: 3.0575557750560685

Epoch: 5| Step: 8
Training loss: 3.400950097121443
Validation loss: 3.0568849370230344

Epoch: 5| Step: 9
Training loss: 3.3705267755395307
Validation loss: 3.0571419549130425

Epoch: 5| Step: 10
Training loss: 3.073051958284772
Validation loss: 3.0563354864075376

Epoch: 297| Step: 0
Training loss: 3.5543244899637476
Validation loss: 3.0587417918116917

Epoch: 5| Step: 1
Training loss: 2.8424406285992707
Validation loss: 3.0596183309959475

Epoch: 5| Step: 2
Training loss: 3.6225931793507553
Validation loss: 3.0601962768819115

Epoch: 5| Step: 3
Training loss: 3.4420568606763173
Validation loss: 3.0586764567612836

Epoch: 5| Step: 4
Training loss: 3.3021627390526938
Validation loss: 3.058282470704893

Epoch: 5| Step: 5
Training loss: 2.9264321106205915
Validation loss: 3.054020010836386

Epoch: 5| Step: 6
Training loss: 3.62878509746297
Validation loss: 3.0549137512264317

Epoch: 5| Step: 7
Training loss: 3.149984050892008
Validation loss: 3.056566079384024

Epoch: 5| Step: 8
Training loss: 3.6985360213430227
Validation loss: 3.054374803657624

Epoch: 5| Step: 9
Training loss: 2.710130203047127
Validation loss: 3.054346296384459

Epoch: 5| Step: 10
Training loss: 3.5204805878368277
Validation loss: 3.052634719442753

Epoch: 298| Step: 0
Training loss: 3.8053979229977983
Validation loss: 3.0526833551135932

Epoch: 5| Step: 1
Training loss: 2.8281506279052913
Validation loss: 3.0523075143362077

Epoch: 5| Step: 2
Training loss: 3.5658993480895624
Validation loss: 3.050980356277989

Epoch: 5| Step: 3
Training loss: 3.120830500915084
Validation loss: 3.052589710202617

Epoch: 5| Step: 4
Training loss: 2.8703291724836446
Validation loss: 3.047917452579603

Epoch: 5| Step: 5
Training loss: 3.218259014718273
Validation loss: 3.05084805744148

Epoch: 5| Step: 6
Training loss: 4.067218563798007
Validation loss: 3.052760782765903

Epoch: 5| Step: 7
Training loss: 3.448073338447785
Validation loss: 3.0507518049516626

Epoch: 5| Step: 8
Training loss: 3.228783681164382
Validation loss: 3.0496394983431085

Epoch: 5| Step: 9
Training loss: 3.1965550476041047
Validation loss: 3.0490205869607148

Epoch: 5| Step: 10
Training loss: 2.866033420556889
Validation loss: 3.049727594175756

Epoch: 299| Step: 0
Training loss: 3.5997733680596617
Validation loss: 3.050485381571254

Epoch: 5| Step: 1
Training loss: 3.29922849711072
Validation loss: 3.0489819482290694

Epoch: 5| Step: 2
Training loss: 3.102770361174763
Validation loss: 3.051741046660935

Epoch: 5| Step: 3
Training loss: 3.6864701465519096
Validation loss: 3.051613660909973

Epoch: 5| Step: 4
Training loss: 3.2644443841871733
Validation loss: 3.0507479091756915

Epoch: 5| Step: 5
Training loss: 3.0790990847000814
Validation loss: 3.0496532326439696

Epoch: 5| Step: 6
Training loss: 3.164549839494633
Validation loss: 3.050372720790641

Epoch: 5| Step: 7
Training loss: 2.9235290088939987
Validation loss: 3.0511001173009253

Epoch: 5| Step: 8
Training loss: 3.615531789621706
Validation loss: 3.049268715254803

Epoch: 5| Step: 9
Training loss: 3.2508070017173507
Validation loss: 3.0499616942277257

Epoch: 5| Step: 10
Training loss: 3.4035824470873473
Validation loss: 3.052642417153943

Epoch: 300| Step: 0
Training loss: 3.216037681501174
Validation loss: 3.0499215056595026

Epoch: 5| Step: 1
Training loss: 3.4064725750639893
Validation loss: 3.05123269171598

Epoch: 5| Step: 2
Training loss: 3.1382788250025637
Validation loss: 3.052202156831229

Epoch: 5| Step: 3
Training loss: 3.3074663892034413
Validation loss: 3.0518976093652523

Epoch: 5| Step: 4
Training loss: 3.869594248908286
Validation loss: 3.0498315392444044

Epoch: 5| Step: 5
Training loss: 3.4935117254741526
Validation loss: 3.0510899437204553

Epoch: 5| Step: 6
Training loss: 3.071176810100872
Validation loss: 3.055717813789499

Epoch: 5| Step: 7
Training loss: 3.519729862684694
Validation loss: 3.051373947632003

Epoch: 5| Step: 8
Training loss: 2.887283786093426
Validation loss: 3.049200302674026

Epoch: 5| Step: 9
Training loss: 3.2066024140432576
Validation loss: 3.0505104507246377

Epoch: 5| Step: 10
Training loss: 3.2381382670201613
Validation loss: 3.0503411715301723

Epoch: 301| Step: 0
Training loss: 3.589467291451667
Validation loss: 3.0473878465150315

Epoch: 5| Step: 1
Training loss: 2.9530939978531414
Validation loss: 3.048960820907713

Epoch: 5| Step: 2
Training loss: 3.515039827601392
Validation loss: 3.0495611507833766

Epoch: 5| Step: 3
Training loss: 4.118715527495866
Validation loss: 3.0477219533237885

Epoch: 5| Step: 4
Training loss: 3.843354739824042
Validation loss: 3.0470936703312503

Epoch: 5| Step: 5
Training loss: 2.480402811931166
Validation loss: 3.0477768229410036

Epoch: 5| Step: 6
Training loss: 3.265628066358085
Validation loss: 3.045595460031145

Epoch: 5| Step: 7
Training loss: 3.403746778785731
Validation loss: 3.0483235817936847

Epoch: 5| Step: 8
Training loss: 2.478923742964151
Validation loss: 3.0471386160450313

Epoch: 5| Step: 9
Training loss: 3.5624927721452173
Validation loss: 3.046019179368626

Epoch: 5| Step: 10
Training loss: 2.6921313987904214
Validation loss: 3.0457389840384943

Epoch: 302| Step: 0
Training loss: 3.812818545182014
Validation loss: 3.0456507854608708

Epoch: 5| Step: 1
Training loss: 3.58955045047753
Validation loss: 3.0448983991046132

Epoch: 5| Step: 2
Training loss: 3.531007201363246
Validation loss: 3.046097070980481

Epoch: 5| Step: 3
Training loss: 3.5775805729630297
Validation loss: 3.0444195407532204

Epoch: 5| Step: 4
Training loss: 3.514398928999569
Validation loss: 3.0443850187019814

Epoch: 5| Step: 5
Training loss: 3.154764562367488
Validation loss: 3.0428733123569542

Epoch: 5| Step: 6
Training loss: 3.209564583740247
Validation loss: 3.0445151522278033

Epoch: 5| Step: 7
Training loss: 2.6943517769503154
Validation loss: 3.0446826301167946

Epoch: 5| Step: 8
Training loss: 2.5987654762853114
Validation loss: 3.0454380480588736

Epoch: 5| Step: 9
Training loss: 3.673247385236858
Validation loss: 3.0456174061493044

Epoch: 5| Step: 10
Training loss: 2.69396664839096
Validation loss: 3.0429220459144237

Epoch: 303| Step: 0
Training loss: 3.261426791527245
Validation loss: 3.0430442386510865

Epoch: 5| Step: 1
Training loss: 3.5473269540143546
Validation loss: 3.045277607424611

Epoch: 5| Step: 2
Training loss: 3.587535227958162
Validation loss: 3.046302090724683

Epoch: 5| Step: 3
Training loss: 3.3855693763133927
Validation loss: 3.042728546071285

Epoch: 5| Step: 4
Training loss: 3.5506942285128598
Validation loss: 3.0437645301624476

Epoch: 5| Step: 5
Training loss: 2.116417325970579
Validation loss: 3.044239761762543

Epoch: 5| Step: 6
Training loss: 3.333871384746895
Validation loss: 3.0421502050260956

Epoch: 5| Step: 7
Training loss: 3.186080616593775
Validation loss: 3.04353642922736

Epoch: 5| Step: 8
Training loss: 3.743130941266848
Validation loss: 3.041876170559332

Epoch: 5| Step: 9
Training loss: 3.0581246085666614
Validation loss: 3.043408497895692

Epoch: 5| Step: 10
Training loss: 3.3600200654747683
Validation loss: 3.0424179490004977

Epoch: 304| Step: 0
Training loss: 3.1596114887960254
Validation loss: 3.0427240451839412

Epoch: 5| Step: 1
Training loss: 3.213299182087774
Validation loss: 3.044719760665078

Epoch: 5| Step: 2
Training loss: 3.14429346927071
Validation loss: 3.043643370357105

Epoch: 5| Step: 3
Training loss: 3.385805422641022
Validation loss: 3.043883860882354

Epoch: 5| Step: 4
Training loss: 3.4091008007021655
Validation loss: 3.044178396092635

Epoch: 5| Step: 5
Training loss: 3.1743944807181523
Validation loss: 3.042661660615695

Epoch: 5| Step: 6
Training loss: 3.412142634980284
Validation loss: 3.0413911744987066

Epoch: 5| Step: 7
Training loss: 3.323202728745686
Validation loss: 3.0426831526912754

Epoch: 5| Step: 8
Training loss: 3.115708385028925
Validation loss: 3.042531567462691

Epoch: 5| Step: 9
Training loss: 3.339542201299126
Validation loss: 3.0410254824308924

Epoch: 5| Step: 10
Training loss: 3.739446412593213
Validation loss: 3.0417104850800976

Epoch: 305| Step: 0
Training loss: 3.031284135449308
Validation loss: 3.0418995121796493

Epoch: 5| Step: 1
Training loss: 3.0377231971149112
Validation loss: 3.0380984245319476

Epoch: 5| Step: 2
Training loss: 3.3448595719447285
Validation loss: 3.04174042220518

Epoch: 5| Step: 3
Training loss: 2.8767870449135136
Validation loss: 3.0409401947428063

Epoch: 5| Step: 4
Training loss: 3.865635909340343
Validation loss: 3.0406582304523697

Epoch: 5| Step: 5
Training loss: 3.4892978532459784
Validation loss: 3.0400906259956257

Epoch: 5| Step: 6
Training loss: 3.1863824717900333
Validation loss: 3.040208051834286

Epoch: 5| Step: 7
Training loss: 2.947865803597665
Validation loss: 3.0447767548136673

Epoch: 5| Step: 8
Training loss: 3.4312811344589425
Validation loss: 3.0482390836539737

Epoch: 5| Step: 9
Training loss: 3.551159258404535
Validation loss: 3.050566692952641

Epoch: 5| Step: 10
Training loss: 3.5333263403145545
Validation loss: 3.0548854033942114

Epoch: 306| Step: 0
Training loss: 3.1422107545816362
Validation loss: 3.0466722562409285

Epoch: 5| Step: 1
Training loss: 3.662868150558918
Validation loss: 3.0534843284845956

Epoch: 5| Step: 2
Training loss: 2.857845209851163
Validation loss: 3.0465084338175115

Epoch: 5| Step: 3
Training loss: 2.8405812813024793
Validation loss: 3.0414116632156976

Epoch: 5| Step: 4
Training loss: 3.42910156806224
Validation loss: 3.0429422126034216

Epoch: 5| Step: 5
Training loss: 3.4207642028241647
Validation loss: 3.0387901755443063

Epoch: 5| Step: 6
Training loss: 2.8429909835495337
Validation loss: 3.038084740099119

Epoch: 5| Step: 7
Training loss: 3.0879082290176565
Validation loss: 3.037396001122069

Epoch: 5| Step: 8
Training loss: 3.513772026869632
Validation loss: 3.0357999281825068

Epoch: 5| Step: 9
Training loss: 3.9359893322931887
Validation loss: 3.0367677125343757

Epoch: 5| Step: 10
Training loss: 3.453023641488248
Validation loss: 3.0354645615062124

Epoch: 307| Step: 0
Training loss: 3.1399954549185543
Validation loss: 3.036821318789101

Epoch: 5| Step: 1
Training loss: 3.741705049064442
Validation loss: 3.036301402880811

Epoch: 5| Step: 2
Training loss: 2.5635022320143355
Validation loss: 3.0363763590479644

Epoch: 5| Step: 3
Training loss: 2.587309965812348
Validation loss: 3.036328056576091

Epoch: 5| Step: 4
Training loss: 3.603922370760471
Validation loss: 3.035343416681077

Epoch: 5| Step: 5
Training loss: 3.30048220030295
Validation loss: 3.0346851478177332

Epoch: 5| Step: 6
Training loss: 3.289072358395261
Validation loss: 3.0360819839582347

Epoch: 5| Step: 7
Training loss: 3.177855917793148
Validation loss: 3.0361159029596396

Epoch: 5| Step: 8
Training loss: 4.037863813608142
Validation loss: 3.0338889364233896

Epoch: 5| Step: 9
Training loss: 2.832553326070268
Validation loss: 3.0336946576031334

Epoch: 5| Step: 10
Training loss: 3.7972975758688845
Validation loss: 3.034668924623576

Epoch: 308| Step: 0
Training loss: 2.3432618713696813
Validation loss: 3.0339584302390397

Epoch: 5| Step: 1
Training loss: 3.760805203274631
Validation loss: 3.035007272282419

Epoch: 5| Step: 2
Training loss: 3.5461095580567865
Validation loss: 3.03526625504696

Epoch: 5| Step: 3
Training loss: 3.7347729841945196
Validation loss: 3.0347309615686573

Epoch: 5| Step: 4
Training loss: 3.0937589394796667
Validation loss: 3.0340586620527734

Epoch: 5| Step: 5
Training loss: 3.13110396297816
Validation loss: 3.033611345808558

Epoch: 5| Step: 6
Training loss: 2.9707498339831377
Validation loss: 3.0372722188379524

Epoch: 5| Step: 7
Training loss: 3.7762505133741193
Validation loss: 3.03839640872029

Epoch: 5| Step: 8
Training loss: 3.407198712581437
Validation loss: 3.0382576174557827

Epoch: 5| Step: 9
Training loss: 3.0412870370512284
Validation loss: 3.038518007236609

Epoch: 5| Step: 10
Training loss: 3.239514087456196
Validation loss: 3.0371142522374877

Epoch: 309| Step: 0
Training loss: 3.7143079369267946
Validation loss: 3.034320478406899

Epoch: 5| Step: 1
Training loss: 3.7184758445916417
Validation loss: 3.0315329712771653

Epoch: 5| Step: 2
Training loss: 2.8699370876421533
Validation loss: 3.0307695460291426

Epoch: 5| Step: 3
Training loss: 3.3636678546584236
Validation loss: 3.0333039070416277

Epoch: 5| Step: 4
Training loss: 3.5970323251475986
Validation loss: 3.0311833602571014

Epoch: 5| Step: 5
Training loss: 3.108701086575985
Validation loss: 3.0331064554086584

Epoch: 5| Step: 6
Training loss: 2.978707409296891
Validation loss: 3.0318449413579884

Epoch: 5| Step: 7
Training loss: 3.2366652189409324
Validation loss: 3.0312697428229627

Epoch: 5| Step: 8
Training loss: 3.2428211741916395
Validation loss: 3.031134478565937

Epoch: 5| Step: 9
Training loss: 3.1168740480619253
Validation loss: 3.030195429328147

Epoch: 5| Step: 10
Training loss: 3.2433865088102323
Validation loss: 3.0312181882771605

Epoch: 310| Step: 0
Training loss: 3.033869604417983
Validation loss: 3.029863115333163

Epoch: 5| Step: 1
Training loss: 2.7879746824070035
Validation loss: 3.0310068577421947

Epoch: 5| Step: 2
Training loss: 3.390583090808823
Validation loss: 3.031102279955793

Epoch: 5| Step: 3
Training loss: 3.5407473698720526
Validation loss: 3.02964990990618

Epoch: 5| Step: 4
Training loss: 3.183459844288945
Validation loss: 3.0290128933216582

Epoch: 5| Step: 5
Training loss: 2.972292743769208
Validation loss: 3.0307525236695585

Epoch: 5| Step: 6
Training loss: 3.990404301860849
Validation loss: 3.0314230920737106

Epoch: 5| Step: 7
Training loss: 3.4010283317518697
Validation loss: 3.0312070142605108

Epoch: 5| Step: 8
Training loss: 3.494022987905868
Validation loss: 3.032404822654666

Epoch: 5| Step: 9
Training loss: 2.939176040719549
Validation loss: 3.030258931783453

Epoch: 5| Step: 10
Training loss: 3.386044128175482
Validation loss: 3.0314350061144775

Epoch: 311| Step: 0
Training loss: 3.823806132577667
Validation loss: 3.0310094915776973

Epoch: 5| Step: 1
Training loss: 2.845106534924195
Validation loss: 3.0328694854919536

Epoch: 5| Step: 2
Training loss: 3.7871501698099332
Validation loss: 3.033384298441617

Epoch: 5| Step: 3
Training loss: 3.447254005823195
Validation loss: 3.0385142628309074

Epoch: 5| Step: 4
Training loss: 3.0398604024657927
Validation loss: 3.0294385495165446

Epoch: 5| Step: 5
Training loss: 3.3945228216595598
Validation loss: 3.0321472653253765

Epoch: 5| Step: 6
Training loss: 3.181281212914012
Validation loss: 3.0309281875560687

Epoch: 5| Step: 7
Training loss: 3.607887655196532
Validation loss: 3.0288613924733987

Epoch: 5| Step: 8
Training loss: 3.4699891772362514
Validation loss: 3.027511527459852

Epoch: 5| Step: 9
Training loss: 2.9254349018443735
Validation loss: 3.027592622634295

Epoch: 5| Step: 10
Training loss: 2.3218826478649914
Validation loss: 3.031912385900035

Epoch: 312| Step: 0
Training loss: 3.772969787549488
Validation loss: 3.0291777067847496

Epoch: 5| Step: 1
Training loss: 3.457961479938827
Validation loss: 3.0270105648181826

Epoch: 5| Step: 2
Training loss: 3.3886600549145434
Validation loss: 3.0273671206797137

Epoch: 5| Step: 3
Training loss: 3.3246659763606505
Validation loss: 3.027864061009071

Epoch: 5| Step: 4
Training loss: 3.1103446636991783
Validation loss: 3.027274946105054

Epoch: 5| Step: 5
Training loss: 3.0929507369451317
Validation loss: 3.0257792028698405

Epoch: 5| Step: 6
Training loss: 4.202081600422739
Validation loss: 3.0302327796944484

Epoch: 5| Step: 7
Training loss: 2.412493544653918
Validation loss: 3.0263466926533034

Epoch: 5| Step: 8
Training loss: 2.96227208158112
Validation loss: 3.0254026068599633

Epoch: 5| Step: 9
Training loss: 3.525037448765297
Validation loss: 3.02736864157138

Epoch: 5| Step: 10
Training loss: 2.4797560261113683
Validation loss: 3.025657282187438

Epoch: 313| Step: 0
Training loss: 2.8467394866682225
Validation loss: 3.023929765415651

Epoch: 5| Step: 1
Training loss: 2.8747565124899737
Validation loss: 3.024249519240381

Epoch: 5| Step: 2
Training loss: 3.0127885355815858
Validation loss: 3.0254243147510174

Epoch: 5| Step: 3
Training loss: 3.714653130583554
Validation loss: 3.023932383372902

Epoch: 5| Step: 4
Training loss: 3.9881834490793855
Validation loss: 3.024181709676561

Epoch: 5| Step: 5
Training loss: 3.405939630489731
Validation loss: 3.0284421615265633

Epoch: 5| Step: 6
Training loss: 3.0132987581930752
Validation loss: 3.0266177565716608

Epoch: 5| Step: 7
Training loss: 3.6734064033519367
Validation loss: 3.026062005437652

Epoch: 5| Step: 8
Training loss: 3.3277338362226643
Validation loss: 3.0223962228108885

Epoch: 5| Step: 9
Training loss: 3.437987275699771
Validation loss: 3.0237204020367505

Epoch: 5| Step: 10
Training loss: 2.5918482967240197
Validation loss: 3.0257093619058124

Epoch: 314| Step: 0
Training loss: 3.303782670620509
Validation loss: 3.0240126614908074

Epoch: 5| Step: 1
Training loss: 3.6441631887683776
Validation loss: 3.026326132440101

Epoch: 5| Step: 2
Training loss: 3.4808019270943964
Validation loss: 3.0232394162751155

Epoch: 5| Step: 3
Training loss: 3.2506418327976827
Validation loss: 3.023524536294382

Epoch: 5| Step: 4
Training loss: 3.086020784823523
Validation loss: 3.0226952426873095

Epoch: 5| Step: 5
Training loss: 3.4097803701780505
Validation loss: 3.02376012407534

Epoch: 5| Step: 6
Training loss: 3.143151021816684
Validation loss: 3.0221563687374307

Epoch: 5| Step: 7
Training loss: 3.2310157322029807
Validation loss: 3.0238454987060477

Epoch: 5| Step: 8
Training loss: 3.2255896332384975
Validation loss: 3.020475762024615

Epoch: 5| Step: 9
Training loss: 2.989011029659276
Validation loss: 3.0227620848250734

Epoch: 5| Step: 10
Training loss: 3.4018651054052005
Validation loss: 3.022912895721734

Epoch: 315| Step: 0
Training loss: 3.196688404771749
Validation loss: 3.021520750412247

Epoch: 5| Step: 1
Training loss: 3.37465962706934
Validation loss: 3.0228426662594776

Epoch: 5| Step: 2
Training loss: 3.625050774580424
Validation loss: 3.020079150625132

Epoch: 5| Step: 3
Training loss: 3.525321236981614
Validation loss: 3.0222889489017666

Epoch: 5| Step: 4
Training loss: 2.9594316906116425
Validation loss: 3.021299139707101

Epoch: 5| Step: 5
Training loss: 3.080680289999976
Validation loss: 3.024072571334368

Epoch: 5| Step: 6
Training loss: 2.899546120740077
Validation loss: 3.021535055420344

Epoch: 5| Step: 7
Training loss: 3.3864396804175394
Validation loss: 3.0235506709438114

Epoch: 5| Step: 8
Training loss: 3.3835160931113877
Validation loss: 3.019858927392379

Epoch: 5| Step: 9
Training loss: 3.3248276113694537
Validation loss: 3.0267139795167

Epoch: 5| Step: 10
Training loss: 3.357260246891272
Validation loss: 3.018635206299523

Epoch: 316| Step: 0
Training loss: 3.7683483105822586
Validation loss: 3.0228735043266832

Epoch: 5| Step: 1
Training loss: 3.5134096752850668
Validation loss: 3.0245811040155344

Epoch: 5| Step: 2
Training loss: 2.9848776189358945
Validation loss: 3.022465626326335

Epoch: 5| Step: 3
Training loss: 2.44646682550238
Validation loss: 3.0193708999368924

Epoch: 5| Step: 4
Training loss: 3.4786080161263353
Validation loss: 3.0236079598351386

Epoch: 5| Step: 5
Training loss: 3.040130662870703
Validation loss: 3.0251178935098766

Epoch: 5| Step: 6
Training loss: 3.3142672448982546
Validation loss: 3.021631828803071

Epoch: 5| Step: 7
Training loss: 3.706067553913766
Validation loss: 3.021610119119048

Epoch: 5| Step: 8
Training loss: 3.4908624990019983
Validation loss: 3.0225421766641265

Epoch: 5| Step: 9
Training loss: 2.9498314631535716
Validation loss: 3.020803943755565

Epoch: 5| Step: 10
Training loss: 3.2683850173974673
Validation loss: 3.0180457645695604

Epoch: 317| Step: 0
Training loss: 2.9885615996454695
Validation loss: 3.0198270712280455

Epoch: 5| Step: 1
Training loss: 3.1638805949350157
Validation loss: 3.020152286282989

Epoch: 5| Step: 2
Training loss: 3.9344968696607965
Validation loss: 3.0210960016560677

Epoch: 5| Step: 3
Training loss: 3.8164126221399592
Validation loss: 3.02107222266309

Epoch: 5| Step: 4
Training loss: 3.405285900061436
Validation loss: 3.0153983046510198

Epoch: 5| Step: 5
Training loss: 3.432358937431546
Validation loss: 3.0211716838313367

Epoch: 5| Step: 6
Training loss: 3.487157147143224
Validation loss: 3.0161637268080184

Epoch: 5| Step: 7
Training loss: 2.4192688732871557
Validation loss: 3.0181526541672548

Epoch: 5| Step: 8
Training loss: 3.015462762293106
Validation loss: 3.0152089943920304

Epoch: 5| Step: 9
Training loss: 3.0320562489910867
Validation loss: 3.0166332292196483

Epoch: 5| Step: 10
Training loss: 3.1908426148930595
Validation loss: 3.0162542979670453

Epoch: 318| Step: 0
Training loss: 3.4981770536480044
Validation loss: 3.0154497224354833

Epoch: 5| Step: 1
Training loss: 3.5771148455118067
Validation loss: 3.014388870598188

Epoch: 5| Step: 2
Training loss: 3.362563921806523
Validation loss: 3.0144216440467115

Epoch: 5| Step: 3
Training loss: 3.0031761204777703
Validation loss: 3.0164081930044566

Epoch: 5| Step: 4
Training loss: 3.1689463658029835
Validation loss: 3.014986771801617

Epoch: 5| Step: 5
Training loss: 3.3787249036866673
Validation loss: 3.0160139919961337

Epoch: 5| Step: 6
Training loss: 3.6146857753751855
Validation loss: 3.01510667860087

Epoch: 5| Step: 7
Training loss: 2.741667869436199
Validation loss: 3.0165543923917193

Epoch: 5| Step: 8
Training loss: 2.8030024915310543
Validation loss: 3.014354186621311

Epoch: 5| Step: 9
Training loss: 3.932414691676351
Validation loss: 3.01436929616802

Epoch: 5| Step: 10
Training loss: 2.732199364655716
Validation loss: 3.016243394043864

Epoch: 319| Step: 0
Training loss: 3.5616526348841417
Validation loss: 3.0175309140849387

Epoch: 5| Step: 1
Training loss: 3.4224409915582537
Validation loss: 3.0116715340594538

Epoch: 5| Step: 2
Training loss: 3.0099810820837316
Validation loss: 3.0133557408930165

Epoch: 5| Step: 3
Training loss: 3.270257320020544
Validation loss: 3.013922598739616

Epoch: 5| Step: 4
Training loss: 3.583268113245076
Validation loss: 3.0107546261555576

Epoch: 5| Step: 5
Training loss: 3.228796529578621
Validation loss: 3.0114334954730073

Epoch: 5| Step: 6
Training loss: 3.4928145901681504
Validation loss: 3.0130253831295124

Epoch: 5| Step: 7
Training loss: 3.130332516932497
Validation loss: 3.0143250584741477

Epoch: 5| Step: 8
Training loss: 3.070615331260697
Validation loss: 3.0144950377253843

Epoch: 5| Step: 9
Training loss: 2.9158826773423003
Validation loss: 3.011866517627056

Epoch: 5| Step: 10
Training loss: 3.3662289275066857
Validation loss: 3.0141120119087015

Epoch: 320| Step: 0
Training loss: 3.7349786629635475
Validation loss: 3.015480149815767

Epoch: 5| Step: 1
Training loss: 3.3813909138140072
Validation loss: 3.0149539245672123

Epoch: 5| Step: 2
Training loss: 2.5588546503430067
Validation loss: 3.012260216284358

Epoch: 5| Step: 3
Training loss: 3.2020848516006857
Validation loss: 3.0164116486895587

Epoch: 5| Step: 4
Training loss: 2.701953612081151
Validation loss: 3.0116484825236833

Epoch: 5| Step: 5
Training loss: 3.633649569640183
Validation loss: 3.0122169025293912

Epoch: 5| Step: 6
Training loss: 3.9466581863449677
Validation loss: 3.012709984472974

Epoch: 5| Step: 7
Training loss: 3.0580857830702217
Validation loss: 3.011506781504374

Epoch: 5| Step: 8
Training loss: 3.831583632711212
Validation loss: 3.0120105415053766

Epoch: 5| Step: 9
Training loss: 3.1547316118758424
Validation loss: 3.0137427503001897

Epoch: 5| Step: 10
Training loss: 2.350204024690648
Validation loss: 3.0100320447636575

Epoch: 321| Step: 0
Training loss: 3.3746791263211144
Validation loss: 3.0112003138598014

Epoch: 5| Step: 1
Training loss: 3.2840715175558945
Validation loss: 3.0097407019844167

Epoch: 5| Step: 2
Training loss: 3.688609457411977
Validation loss: 3.0123906593255354

Epoch: 5| Step: 3
Training loss: 3.405067168482143
Validation loss: 3.0121228557573865

Epoch: 5| Step: 4
Training loss: 2.9998559917218253
Validation loss: 3.011416974201538

Epoch: 5| Step: 5
Training loss: 3.033213343360525
Validation loss: 3.0090189880995135

Epoch: 5| Step: 6
Training loss: 3.5320467429864393
Validation loss: 3.010919438599191

Epoch: 5| Step: 7
Training loss: 3.7466680347082644
Validation loss: 3.0074972076153466

Epoch: 5| Step: 8
Training loss: 3.1934650928601687
Validation loss: 3.009146288232537

Epoch: 5| Step: 9
Training loss: 2.5887890907920643
Validation loss: 3.008371605412495

Epoch: 5| Step: 10
Training loss: 3.0333710161600225
Validation loss: 3.0085674104035967

Epoch: 322| Step: 0
Training loss: 3.1823934901919366
Validation loss: 3.007049707588983

Epoch: 5| Step: 1
Training loss: 3.2641628952984956
Validation loss: 3.010044721421681

Epoch: 5| Step: 2
Training loss: 3.9351467790578654
Validation loss: 3.0088957663173246

Epoch: 5| Step: 3
Training loss: 3.139343607626149
Validation loss: 3.0109100641446727

Epoch: 5| Step: 4
Training loss: 3.4685553418776482
Validation loss: 3.0097983380612288

Epoch: 5| Step: 5
Training loss: 3.274495320345764
Validation loss: 3.0085618426894234

Epoch: 5| Step: 6
Training loss: 2.9824747956482796
Validation loss: 3.008354596925912

Epoch: 5| Step: 7
Training loss: 2.7292457646757
Validation loss: 3.0096842896884772

Epoch: 5| Step: 8
Training loss: 3.6172750310008697
Validation loss: 3.008238281490445

Epoch: 5| Step: 9
Training loss: 2.8381883500485943
Validation loss: 3.0079168741872997

Epoch: 5| Step: 10
Training loss: 3.4778684070737045
Validation loss: 3.009409259065345

Epoch: 323| Step: 0
Training loss: 3.3710288243765927
Validation loss: 3.0073905172574826

Epoch: 5| Step: 1
Training loss: 3.52372737123518
Validation loss: 3.008731391752026

Epoch: 5| Step: 2
Training loss: 3.164729144663415
Validation loss: 3.0071834576041003

Epoch: 5| Step: 3
Training loss: 2.7184688378884907
Validation loss: 3.006124179504385

Epoch: 5| Step: 4
Training loss: 3.0728463547415825
Validation loss: 3.0052774951365557

Epoch: 5| Step: 5
Training loss: 3.940533876991514
Validation loss: 3.007346754021614

Epoch: 5| Step: 6
Training loss: 3.515425070269969
Validation loss: 3.005981124722168

Epoch: 5| Step: 7
Training loss: 3.1868158241967914
Validation loss: 3.00707310896403

Epoch: 5| Step: 8
Training loss: 3.741679051526706
Validation loss: 3.004208537053697

Epoch: 5| Step: 9
Training loss: 2.9195812013847964
Validation loss: 3.0063867606382173

Epoch: 5| Step: 10
Training loss: 2.542655866978392
Validation loss: 3.0080376014384025

Epoch: 324| Step: 0
Training loss: 3.624561941052514
Validation loss: 3.021505080156907

Epoch: 5| Step: 1
Training loss: 3.757117066302612
Validation loss: 3.019697131949656

Epoch: 5| Step: 2
Training loss: 3.7908453139068765
Validation loss: 3.013002426186672

Epoch: 5| Step: 3
Training loss: 2.463155757902697
Validation loss: 3.0056448848094743

Epoch: 5| Step: 4
Training loss: 3.668280737530313
Validation loss: 3.007025518275408

Epoch: 5| Step: 5
Training loss: 2.9056883238425524
Validation loss: 3.0039702023719186

Epoch: 5| Step: 6
Training loss: 3.1583924528710074
Validation loss: 3.003683009399342

Epoch: 5| Step: 7
Training loss: 3.250734539654422
Validation loss: 3.004628362628213

Epoch: 5| Step: 8
Training loss: 2.986595086988366
Validation loss: 3.0023534219149

Epoch: 5| Step: 9
Training loss: 2.757176658231174
Validation loss: 3.005951686020758

Epoch: 5| Step: 10
Training loss: 3.4850862743584528
Validation loss: 3.005477255716565

Epoch: 325| Step: 0
Training loss: 3.4480238299508863
Validation loss: 3.0036152262993987

Epoch: 5| Step: 1
Training loss: 3.4193346879995716
Validation loss: 3.00246296380128

Epoch: 5| Step: 2
Training loss: 3.2057082761470688
Validation loss: 3.001669900930947

Epoch: 5| Step: 3
Training loss: 3.763456487901531
Validation loss: 3.003691096292082

Epoch: 5| Step: 4
Training loss: 3.4101320595773594
Validation loss: 3.0031388928705383

Epoch: 5| Step: 5
Training loss: 3.140011551951158
Validation loss: 3.004815066703538

Epoch: 5| Step: 6
Training loss: 2.8951865006692103
Validation loss: 3.004306435156515

Epoch: 5| Step: 7
Training loss: 2.3748399780974347
Validation loss: 3.0078384174561537

Epoch: 5| Step: 8
Training loss: 3.85794176678489
Validation loss: 3.0097553866569893

Epoch: 5| Step: 9
Training loss: 3.1653715463381524
Validation loss: 3.003885787957543

Epoch: 5| Step: 10
Training loss: 3.132657701278016
Validation loss: 3.003271936121365

Epoch: 326| Step: 0
Training loss: 3.4226682257426444
Validation loss: 3.0065359116127297

Epoch: 5| Step: 1
Training loss: 3.588234292621528
Validation loss: 3.0027326235442193

Epoch: 5| Step: 2
Training loss: 2.9388231584601447
Validation loss: 3.00483174713073

Epoch: 5| Step: 3
Training loss: 3.50251107736234
Validation loss: 3.0025514516690914

Epoch: 5| Step: 4
Training loss: 3.247996813307453
Validation loss: 3.003526774893055

Epoch: 5| Step: 5
Training loss: 3.3684906528836405
Validation loss: 3.0023560305081065

Epoch: 5| Step: 6
Training loss: 3.2757223890471825
Validation loss: 3.006388525791865

Epoch: 5| Step: 7
Training loss: 2.8209003036715767
Validation loss: 3.0004682466014696

Epoch: 5| Step: 8
Training loss: 3.591721600837454
Validation loss: 3.002822331149317

Epoch: 5| Step: 9
Training loss: 3.1550174232642636
Validation loss: 3.0056894216968266

Epoch: 5| Step: 10
Training loss: 2.9188521961561142
Validation loss: 3.00406478684735

Epoch: 327| Step: 0
Training loss: 3.0033496594029376
Validation loss: 2.999777560037312

Epoch: 5| Step: 1
Training loss: 3.3863836384450767
Validation loss: 2.9993457781574198

Epoch: 5| Step: 2
Training loss: 2.783679372630651
Validation loss: 3.0018965526941046

Epoch: 5| Step: 3
Training loss: 3.864443520264396
Validation loss: 3.0030043864736626

Epoch: 5| Step: 4
Training loss: 3.1488380650603713
Validation loss: 3.00037327703578

Epoch: 5| Step: 5
Training loss: 2.908107697078569
Validation loss: 2.999260881428252

Epoch: 5| Step: 6
Training loss: 2.8598570703924575
Validation loss: 2.9992969656524364

Epoch: 5| Step: 7
Training loss: 3.9320285869114144
Validation loss: 2.9994990809090214

Epoch: 5| Step: 8
Training loss: 3.984350825217715
Validation loss: 2.998720281521461

Epoch: 5| Step: 9
Training loss: 3.373420345656795
Validation loss: 2.9988719039477316

Epoch: 5| Step: 10
Training loss: 2.0843409453988713
Validation loss: 3.0021222941216914

Epoch: 328| Step: 0
Training loss: 4.05926361283561
Validation loss: 3.0001554192513105

Epoch: 5| Step: 1
Training loss: 3.0383420742437197
Validation loss: 2.9970931836223365

Epoch: 5| Step: 2
Training loss: 3.46703839387587
Validation loss: 2.9963138264882696

Epoch: 5| Step: 3
Training loss: 3.6076854367884446
Validation loss: 2.9968478603892725

Epoch: 5| Step: 4
Training loss: 3.6023136439623826
Validation loss: 2.996630387934638

Epoch: 5| Step: 5
Training loss: 2.993050791851441
Validation loss: 2.999978353394925

Epoch: 5| Step: 6
Training loss: 2.5668830602838377
Validation loss: 3.0004090231982836

Epoch: 5| Step: 7
Training loss: 3.2104625489861087
Validation loss: 2.9975829539615013

Epoch: 5| Step: 8
Training loss: 3.1030044086608153
Validation loss: 2.9995498387848447

Epoch: 5| Step: 9
Training loss: 3.4336016658131876
Validation loss: 2.9991872859073574

Epoch: 5| Step: 10
Training loss: 2.51553619417566
Validation loss: 2.998347967506644

Epoch: 329| Step: 0
Training loss: 3.2692815578192214
Validation loss: 2.9990971926159613

Epoch: 5| Step: 1
Training loss: 3.105492703327432
Validation loss: 2.998091208372761

Epoch: 5| Step: 2
Training loss: 3.7048216204617623
Validation loss: 2.998478207816871

Epoch: 5| Step: 3
Training loss: 3.232345902855319
Validation loss: 2.9977627858674314

Epoch: 5| Step: 4
Training loss: 3.2384201038441467
Validation loss: 2.998092685969545

Epoch: 5| Step: 5
Training loss: 2.6889444062602887
Validation loss: 2.9968926956742608

Epoch: 5| Step: 6
Training loss: 3.5628161373743876
Validation loss: 2.99704909381372

Epoch: 5| Step: 7
Training loss: 3.0709390947270427
Validation loss: 2.9979485005592217

Epoch: 5| Step: 8
Training loss: 3.2031784425324465
Validation loss: 3.002693308068858

Epoch: 5| Step: 9
Training loss: 3.664562199401349
Validation loss: 3.003368438407733

Epoch: 5| Step: 10
Training loss: 3.1186645373787965
Validation loss: 3.002554411010241

Epoch: 330| Step: 0
Training loss: 3.4068728936090364
Validation loss: 3.002749530688126

Epoch: 5| Step: 1
Training loss: 2.9690368513760657
Validation loss: 3.00971283923965

Epoch: 5| Step: 2
Training loss: 2.954152085053506
Validation loss: 3.0097228162290164

Epoch: 5| Step: 3
Training loss: 3.8397523514046044
Validation loss: 3.008846737254801

Epoch: 5| Step: 4
Training loss: 2.680846205674433
Validation loss: 3.0063057500560397

Epoch: 5| Step: 5
Training loss: 3.3609657956771763
Validation loss: 2.995276389822629

Epoch: 5| Step: 6
Training loss: 3.6783485001143457
Validation loss: 3.0002940112464773

Epoch: 5| Step: 7
Training loss: 3.3844359557068366
Validation loss: 2.9969488697160385

Epoch: 5| Step: 8
Training loss: 3.2092934365016026
Validation loss: 2.9969486396088905

Epoch: 5| Step: 9
Training loss: 3.2740435710657265
Validation loss: 3.0017545245559734

Epoch: 5| Step: 10
Training loss: 3.0431630534082306
Validation loss: 2.998824470348088

Epoch: 331| Step: 0
Training loss: 3.206366113415509
Validation loss: 3.0004343501168482

Epoch: 5| Step: 1
Training loss: 3.003659083164802
Validation loss: 2.9979181449423744

Epoch: 5| Step: 2
Training loss: 3.304084163628305
Validation loss: 3.0059371141065547

Epoch: 5| Step: 3
Training loss: 2.9194204863212403
Validation loss: 2.9966340306845862

Epoch: 5| Step: 4
Training loss: 3.182770754915397
Validation loss: 3.0004675784500225

Epoch: 5| Step: 5
Training loss: 2.637703989827452
Validation loss: 2.9985486112211377

Epoch: 5| Step: 6
Training loss: 3.131717785520747
Validation loss: 2.9970959841210214

Epoch: 5| Step: 7
Training loss: 3.1035580305079633
Validation loss: 2.9951508154823334

Epoch: 5| Step: 8
Training loss: 3.8180245567319373
Validation loss: 2.9938859155022906

Epoch: 5| Step: 9
Training loss: 3.6825231814771646
Validation loss: 2.9952793674781693

Epoch: 5| Step: 10
Training loss: 3.865911223069635
Validation loss: 2.9960979444473863

Epoch: 332| Step: 0
Training loss: 2.9196262784114717
Validation loss: 2.9988266126812593

Epoch: 5| Step: 1
Training loss: 2.9101505151474534
Validation loss: 2.996002434175644

Epoch: 5| Step: 2
Training loss: 3.186224888088659
Validation loss: 2.9927425618836616

Epoch: 5| Step: 3
Training loss: 3.3788328658938624
Validation loss: 2.9983210069667634

Epoch: 5| Step: 4
Training loss: 3.275260763488559
Validation loss: 3.0002247288663995

Epoch: 5| Step: 5
Training loss: 3.425558537515497
Validation loss: 2.9962462155022345

Epoch: 5| Step: 6
Training loss: 3.4398737254364793
Validation loss: 2.9960720931413003

Epoch: 5| Step: 7
Training loss: 3.3315741347312025
Validation loss: 2.9970460298113752

Epoch: 5| Step: 8
Training loss: 3.9466473124862924
Validation loss: 2.993101095491361

Epoch: 5| Step: 9
Training loss: 2.9278280231749565
Validation loss: 2.9910602612313957

Epoch: 5| Step: 10
Training loss: 3.059613482928357
Validation loss: 2.9941350081969005

Epoch: 333| Step: 0
Training loss: 4.032464842385873
Validation loss: 2.991436864828293

Epoch: 5| Step: 1
Training loss: 3.3834453457735822
Validation loss: 2.9924458605546893

Epoch: 5| Step: 2
Training loss: 3.7187011459090726
Validation loss: 2.9923196825147715

Epoch: 5| Step: 3
Training loss: 2.4120283229044315
Validation loss: 2.9893036475306105

Epoch: 5| Step: 4
Training loss: 2.9745006879561093
Validation loss: 2.9917054395390847

Epoch: 5| Step: 5
Training loss: 2.985181609592377
Validation loss: 2.989950337535474

Epoch: 5| Step: 6
Training loss: 2.84003096308418
Validation loss: 2.9892830829585573

Epoch: 5| Step: 7
Training loss: 3.737693174339345
Validation loss: 2.989430614056675

Epoch: 5| Step: 8
Training loss: 2.987374281532434
Validation loss: 2.991122715812456

Epoch: 5| Step: 9
Training loss: 3.448863165596711
Validation loss: 2.988030098372888

Epoch: 5| Step: 10
Training loss: 3.008768618327573
Validation loss: 2.9884144597232094

Epoch: 334| Step: 0
Training loss: 3.653590221167588
Validation loss: 2.9882179930761956

Epoch: 5| Step: 1
Training loss: 2.378626614375967
Validation loss: 2.9867346395373136

Epoch: 5| Step: 2
Training loss: 3.8220305840802125
Validation loss: 2.9894289478011946

Epoch: 5| Step: 3
Training loss: 3.4465884659366908
Validation loss: 2.98614776415857

Epoch: 5| Step: 4
Training loss: 3.936484190684411
Validation loss: 2.9901793179812777

Epoch: 5| Step: 5
Training loss: 3.3062257185334594
Validation loss: 2.9895599694182464

Epoch: 5| Step: 6
Training loss: 2.8584978603096802
Validation loss: 2.9931189760775294

Epoch: 5| Step: 7
Training loss: 2.900609274691907
Validation loss: 2.988536343673991

Epoch: 5| Step: 8
Training loss: 3.4124696276085134
Validation loss: 2.9909146688039043

Epoch: 5| Step: 9
Training loss: 2.6588098196627397
Validation loss: 2.9931550033012826

Epoch: 5| Step: 10
Training loss: 3.1085667158640073
Validation loss: 2.989267410942733

Epoch: 335| Step: 0
Training loss: 3.7099611945577693
Validation loss: 2.9899620429986076

Epoch: 5| Step: 1
Training loss: 3.101300514360241
Validation loss: 2.985433861284427

Epoch: 5| Step: 2
Training loss: 3.221345762191989
Validation loss: 2.9861601404271725

Epoch: 5| Step: 3
Training loss: 3.4610769273904407
Validation loss: 2.985379117620175

Epoch: 5| Step: 4
Training loss: 3.760851608582469
Validation loss: 2.98814266022064

Epoch: 5| Step: 5
Training loss: 3.857031971987602
Validation loss: 2.985490998000974

Epoch: 5| Step: 6
Training loss: 3.0834762608848525
Validation loss: 2.9837437521375842

Epoch: 5| Step: 7
Training loss: 2.6136550978038167
Validation loss: 2.9855984795249246

Epoch: 5| Step: 8
Training loss: 2.5188335546828595
Validation loss: 2.984522565841978

Epoch: 5| Step: 9
Training loss: 2.9259601940646727
Validation loss: 2.98444274162297

Epoch: 5| Step: 10
Training loss: 3.329580642367492
Validation loss: 2.983209519100812

Epoch: 336| Step: 0
Training loss: 3.3037604436229415
Validation loss: 2.9845349436961026

Epoch: 5| Step: 1
Training loss: 3.420723638661441
Validation loss: 2.9841134003351204

Epoch: 5| Step: 2
Training loss: 2.7456649076434467
Validation loss: 2.9837252568833192

Epoch: 5| Step: 3
Training loss: 2.8033245036938292
Validation loss: 2.984191353710778

Epoch: 5| Step: 4
Training loss: 3.645237959431975
Validation loss: 2.982404134862954

Epoch: 5| Step: 5
Training loss: 2.76328829742042
Validation loss: 2.9815319546834

Epoch: 5| Step: 6
Training loss: 3.784399943186856
Validation loss: 2.9847142579116737

Epoch: 5| Step: 7
Training loss: 3.4764291802035467
Validation loss: 2.9839842358547517

Epoch: 5| Step: 8
Training loss: 3.6564638776253355
Validation loss: 2.982056631078211

Epoch: 5| Step: 9
Training loss: 3.3892124591326005
Validation loss: 2.9860831596501636

Epoch: 5| Step: 10
Training loss: 2.4165504252222014
Validation loss: 2.983578393999304

Epoch: 337| Step: 0
Training loss: 3.722137318934956
Validation loss: 2.9894360681854613

Epoch: 5| Step: 1
Training loss: 3.079255027346306
Validation loss: 2.987726773369239

Epoch: 5| Step: 2
Training loss: 2.944181270554148
Validation loss: 2.9878626762509213

Epoch: 5| Step: 3
Training loss: 3.23546593000772
Validation loss: 2.984163599484141

Epoch: 5| Step: 4
Training loss: 3.39076084972306
Validation loss: 2.9885697883607305

Epoch: 5| Step: 5
Training loss: 3.061831810127444
Validation loss: 2.98491566347788

Epoch: 5| Step: 6
Training loss: 3.4052763781084954
Validation loss: 2.992467230105439

Epoch: 5| Step: 7
Training loss: 2.6371748918235776
Validation loss: 2.9834955525276263

Epoch: 5| Step: 8
Training loss: 3.9255818026916756
Validation loss: 2.981883326538749

Epoch: 5| Step: 9
Training loss: 2.9700292140153257
Validation loss: 2.981164929996735

Epoch: 5| Step: 10
Training loss: 3.2513916264024156
Validation loss: 2.9820741824327506

Epoch: 338| Step: 0
Training loss: 3.025051740724052
Validation loss: 2.9801293812657064

Epoch: 5| Step: 1
Training loss: 2.9401205832217627
Validation loss: 2.9800301495221873

Epoch: 5| Step: 2
Training loss: 2.993002359773602
Validation loss: 2.9813432361720014

Epoch: 5| Step: 3
Training loss: 3.3176260099073507
Validation loss: 2.981038494625799

Epoch: 5| Step: 4
Training loss: 3.25657311884649
Validation loss: 2.9803842935702782

Epoch: 5| Step: 5
Training loss: 3.462391016377695
Validation loss: 2.9793374216091144

Epoch: 5| Step: 6
Training loss: 3.1453166478409686
Validation loss: 2.9786993363382406

Epoch: 5| Step: 7
Training loss: 3.513706616351316
Validation loss: 2.9817649158090025

Epoch: 5| Step: 8
Training loss: 3.225382665361227
Validation loss: 2.9779638875248287

Epoch: 5| Step: 9
Training loss: 3.3858442926538546
Validation loss: 2.9804998974728965

Epoch: 5| Step: 10
Training loss: 3.538382290109003
Validation loss: 2.9768386009535477

Epoch: 339| Step: 0
Training loss: 2.8373075176274005
Validation loss: 2.9760292658001424

Epoch: 5| Step: 1
Training loss: 3.7578663019147456
Validation loss: 2.9795023887253866

Epoch: 5| Step: 2
Training loss: 2.69909031696302
Validation loss: 2.9770475412303132

Epoch: 5| Step: 3
Training loss: 3.4359901580314323
Validation loss: 2.981308026724112

Epoch: 5| Step: 4
Training loss: 3.505075317096
Validation loss: 2.978114009189084

Epoch: 5| Step: 5
Training loss: 3.4125200711173567
Validation loss: 2.9775487193831296

Epoch: 5| Step: 6
Training loss: 3.3314659292009514
Validation loss: 2.9753483791743975

Epoch: 5| Step: 7
Training loss: 3.5915962731587294
Validation loss: 2.97892429861224

Epoch: 5| Step: 8
Training loss: 3.323374478523224
Validation loss: 2.9789904585265083

Epoch: 5| Step: 9
Training loss: 2.6990225647488004
Validation loss: 2.9775784630062905

Epoch: 5| Step: 10
Training loss: 2.9641426071579025
Validation loss: 2.979169233031185

Epoch: 340| Step: 0
Training loss: 3.0536854849335016
Validation loss: 2.978555498022708

Epoch: 5| Step: 1
Training loss: 3.821647675959609
Validation loss: 2.9785508536856584

Epoch: 5| Step: 2
Training loss: 2.646018935374398
Validation loss: 2.9794066166354556

Epoch: 5| Step: 3
Training loss: 3.5584939216153426
Validation loss: 2.9802954305427747

Epoch: 5| Step: 4
Training loss: 3.0895755231831035
Validation loss: 2.9806154427052087

Epoch: 5| Step: 5
Training loss: 3.2354551713809334
Validation loss: 2.9787995203782187

Epoch: 5| Step: 6
Training loss: 3.07551518288184
Validation loss: 2.9767417846185236

Epoch: 5| Step: 7
Training loss: 3.3842467335692765
Validation loss: 2.975139919302133

Epoch: 5| Step: 8
Training loss: 3.0020563707237296
Validation loss: 2.975530203635919

Epoch: 5| Step: 9
Training loss: 3.2465070881357136
Validation loss: 2.9747534041225103

Epoch: 5| Step: 10
Training loss: 3.566735009106102
Validation loss: 2.974259834802339

Epoch: 341| Step: 0
Training loss: 3.09278361322134
Validation loss: 2.9754008517988155

Epoch: 5| Step: 1
Training loss: 2.853260611145134
Validation loss: 2.9750243070399973

Epoch: 5| Step: 2
Training loss: 2.8053448685032993
Validation loss: 2.9758589476181236

Epoch: 5| Step: 3
Training loss: 3.399876642794303
Validation loss: 2.974308201444443

Epoch: 5| Step: 4
Training loss: 2.823099634826362
Validation loss: 2.974620208322983

Epoch: 5| Step: 5
Training loss: 3.374977818168932
Validation loss: 2.9748533435940834

Epoch: 5| Step: 6
Training loss: 3.3017800529789247
Validation loss: 2.973594575324237

Epoch: 5| Step: 7
Training loss: 3.2609214676306144
Validation loss: 2.9756648052208208

Epoch: 5| Step: 8
Training loss: 3.8717817663216127
Validation loss: 2.974184663856431

Epoch: 5| Step: 9
Training loss: 3.557713287672332
Validation loss: 2.9728535708796153

Epoch: 5| Step: 10
Training loss: 3.279681602934342
Validation loss: 2.9720472159002065

Epoch: 342| Step: 0
Training loss: 3.0493237167771654
Validation loss: 2.9725667100694952

Epoch: 5| Step: 1
Training loss: 3.2026083925055637
Validation loss: 2.972041667754178

Epoch: 5| Step: 2
Training loss: 3.668370169062226
Validation loss: 2.9740707781070013

Epoch: 5| Step: 3
Training loss: 3.1962951790634264
Validation loss: 2.9733458371835058

Epoch: 5| Step: 4
Training loss: 2.6418178053820243
Validation loss: 2.9757092566704704

Epoch: 5| Step: 5
Training loss: 3.5130309983038783
Validation loss: 2.9709186605616216

Epoch: 5| Step: 6
Training loss: 3.163327129292275
Validation loss: 2.970991912237453

Epoch: 5| Step: 7
Training loss: 2.6990115228317233
Validation loss: 2.973551106148345

Epoch: 5| Step: 8
Training loss: 3.1643290843039655
Validation loss: 2.973915660254526

Epoch: 5| Step: 9
Training loss: 4.032052366855185
Validation loss: 2.9719367677188138

Epoch: 5| Step: 10
Training loss: 3.1623204839968166
Validation loss: 2.9767270300971735

Epoch: 343| Step: 0
Training loss: 3.111572869032528
Validation loss: 2.972245065402412

Epoch: 5| Step: 1
Training loss: 3.53009149232904
Validation loss: 2.9753173113257896

Epoch: 5| Step: 2
Training loss: 3.531655347397004
Validation loss: 2.973290182902604

Epoch: 5| Step: 3
Training loss: 3.229569260306504
Validation loss: 2.971529818805839

Epoch: 5| Step: 4
Training loss: 3.553597285169091
Validation loss: 2.9746287396447926

Epoch: 5| Step: 5
Training loss: 3.199106216780349
Validation loss: 2.9704636468656394

Epoch: 5| Step: 6
Training loss: 3.1182451103231443
Validation loss: 2.970985524252366

Epoch: 5| Step: 7
Training loss: 3.2469788227242455
Validation loss: 2.9754559841071564

Epoch: 5| Step: 8
Training loss: 2.535723277484755
Validation loss: 2.973430133139009

Epoch: 5| Step: 9
Training loss: 2.9180252907214563
Validation loss: 2.9710396435037927

Epoch: 5| Step: 10
Training loss: 3.6662922725848164
Validation loss: 2.9703516872442415

Epoch: 344| Step: 0
Training loss: 4.022357210478269
Validation loss: 2.969941701081035

Epoch: 5| Step: 1
Training loss: 3.524998625626533
Validation loss: 2.9750023003301553

Epoch: 5| Step: 2
Training loss: 3.472640047153567
Validation loss: 2.9738483891728325

Epoch: 5| Step: 3
Training loss: 3.427798087459872
Validation loss: 2.9714191624468675

Epoch: 5| Step: 4
Training loss: 3.2382163120656453
Validation loss: 2.9705831777718177

Epoch: 5| Step: 5
Training loss: 3.6636140138136706
Validation loss: 2.9690409717980195

Epoch: 5| Step: 6
Training loss: 3.7035085745025045
Validation loss: 2.972358105998058

Epoch: 5| Step: 7
Training loss: 2.4077169727384877
Validation loss: 2.9709575577801703

Epoch: 5| Step: 8
Training loss: 2.9069964362963447
Validation loss: 2.9716285553782065

Epoch: 5| Step: 9
Training loss: 2.635551951759552
Validation loss: 2.9723711951761564

Epoch: 5| Step: 10
Training loss: 1.9441555520056226
Validation loss: 2.973445996399997

Epoch: 345| Step: 0
Training loss: 3.3456355687684796
Validation loss: 2.970647397044861

Epoch: 5| Step: 1
Training loss: 3.4137834308318493
Validation loss: 2.970697408652323

Epoch: 5| Step: 2
Training loss: 3.373949099217249
Validation loss: 2.9676641251839757

Epoch: 5| Step: 3
Training loss: 3.0982620782098853
Validation loss: 2.9700296818535232

Epoch: 5| Step: 4
Training loss: 3.140582335832336
Validation loss: 2.9695572330409603

Epoch: 5| Step: 5
Training loss: 3.2165472400480826
Validation loss: 2.9670364901066626

Epoch: 5| Step: 6
Training loss: 3.608609997815365
Validation loss: 2.9666099671737327

Epoch: 5| Step: 7
Training loss: 3.27763385420809
Validation loss: 2.9670899305499785

Epoch: 5| Step: 8
Training loss: 3.4933240436352784
Validation loss: 2.965877872013181

Epoch: 5| Step: 9
Training loss: 3.114439706882311
Validation loss: 2.9666947275912974

Epoch: 5| Step: 10
Training loss: 2.3347055510102797
Validation loss: 2.967231000919982

Epoch: 346| Step: 0
Training loss: 3.4528419067887204
Validation loss: 2.9670137139032846

Epoch: 5| Step: 1
Training loss: 2.8203163041276715
Validation loss: 2.9654519483847164

Epoch: 5| Step: 2
Training loss: 3.5508060937060613
Validation loss: 2.9678542663502965

Epoch: 5| Step: 3
Training loss: 2.901195601939885
Validation loss: 2.9681207876277664

Epoch: 5| Step: 4
Training loss: 2.961472113263388
Validation loss: 2.969393503148433

Epoch: 5| Step: 5
Training loss: 3.277636763849421
Validation loss: 2.9651507395504555

Epoch: 5| Step: 6
Training loss: 3.0864067396902137
Validation loss: 2.9651515790675402

Epoch: 5| Step: 7
Training loss: 3.66685850913132
Validation loss: 2.9666630316178924

Epoch: 5| Step: 8
Training loss: 3.5020913279251324
Validation loss: 2.9666499639190467

Epoch: 5| Step: 9
Training loss: 3.1762358655618823
Validation loss: 2.9636696471875434

Epoch: 5| Step: 10
Training loss: 3.151528178507106
Validation loss: 2.968327514775762

Epoch: 347| Step: 0
Training loss: 3.1330251264833913
Validation loss: 2.9627483970093125

Epoch: 5| Step: 1
Training loss: 3.0357547597030248
Validation loss: 2.964725025350748

Epoch: 5| Step: 2
Training loss: 2.932485480309173
Validation loss: 2.9669807330287883

Epoch: 5| Step: 3
Training loss: 2.9505219466545967
Validation loss: 2.9665734058537168

Epoch: 5| Step: 4
Training loss: 3.1477363506169964
Validation loss: 2.967464853214014

Epoch: 5| Step: 5
Training loss: 3.4952384712384355
Validation loss: 2.9671972362262213

Epoch: 5| Step: 6
Training loss: 2.9672298354050977
Validation loss: 2.9686484318938864

Epoch: 5| Step: 7
Training loss: 3.684454225783587
Validation loss: 2.9660582069731354

Epoch: 5| Step: 8
Training loss: 3.5690211792646385
Validation loss: 2.9675765355928636

Epoch: 5| Step: 9
Training loss: 2.7265714191629726
Validation loss: 2.965991359262395

Epoch: 5| Step: 10
Training loss: 3.9437396549627217
Validation loss: 2.9658176700429095

Epoch: 348| Step: 0
Training loss: 3.4088764389083726
Validation loss: 2.966189844328813

Epoch: 5| Step: 1
Training loss: 3.2581301015187916
Validation loss: 2.9694412963681773

Epoch: 5| Step: 2
Training loss: 2.437141979040404
Validation loss: 2.9663833554321823

Epoch: 5| Step: 3
Training loss: 3.2156137538524185
Validation loss: 2.9640718189858255

Epoch: 5| Step: 4
Training loss: 3.3727210085697794
Validation loss: 2.965443784011828

Epoch: 5| Step: 5
Training loss: 3.5397288387777945
Validation loss: 2.962850399261934

Epoch: 5| Step: 6
Training loss: 2.8095523222399343
Validation loss: 2.9636103475786166

Epoch: 5| Step: 7
Training loss: 3.682463746679045
Validation loss: 2.9652196301716955

Epoch: 5| Step: 8
Training loss: 3.172790395253351
Validation loss: 2.962659163357719

Epoch: 5| Step: 9
Training loss: 3.6094147651100226
Validation loss: 2.9625990214547366

Epoch: 5| Step: 10
Training loss: 2.9511699360930095
Validation loss: 2.9665931755352233

Epoch: 349| Step: 0
Training loss: 3.511909250559798
Validation loss: 2.963421790604735

Epoch: 5| Step: 1
Training loss: 3.10376759125068
Validation loss: 2.9635236364596467

Epoch: 5| Step: 2
Training loss: 3.1831410840952183
Validation loss: 2.9639505706587363

Epoch: 5| Step: 3
Training loss: 3.0736012014244705
Validation loss: 2.9744660189288163

Epoch: 5| Step: 4
Training loss: 3.0305338534673587
Validation loss: 2.967071603653683

Epoch: 5| Step: 5
Training loss: 3.6725820307078005
Validation loss: 2.9753894595451116

Epoch: 5| Step: 6
Training loss: 2.421342557399394
Validation loss: 2.9672634563081086

Epoch: 5| Step: 7
Training loss: 3.4108392440057487
Validation loss: 2.966416778515953

Epoch: 5| Step: 8
Training loss: 3.731240333531828
Validation loss: 2.9673237041101017

Epoch: 5| Step: 9
Training loss: 2.7837799224136064
Validation loss: 2.9641098157502093

Epoch: 5| Step: 10
Training loss: 3.5649540797375225
Validation loss: 2.9604116699063887

Epoch: 350| Step: 0
Training loss: 3.5241674102784826
Validation loss: 2.961290470550181

Epoch: 5| Step: 1
Training loss: 3.1595236542364558
Validation loss: 2.9617674874254156

Epoch: 5| Step: 2
Training loss: 3.4687931642338308
Validation loss: 2.960427952777718

Epoch: 5| Step: 3
Training loss: 3.1856902725810277
Validation loss: 2.9598412703785915

Epoch: 5| Step: 4
Training loss: 3.6442553056959746
Validation loss: 2.959559661467552

Epoch: 5| Step: 5
Training loss: 3.1292131632987714
Validation loss: 2.960519206382679

Epoch: 5| Step: 6
Training loss: 2.407186845989552
Validation loss: 2.96015271838826

Epoch: 5| Step: 7
Training loss: 3.0272660965343094
Validation loss: 2.959156929279839

Epoch: 5| Step: 8
Training loss: 3.2171211936161286
Validation loss: 2.959046141179707

Epoch: 5| Step: 9
Training loss: 3.432790130556241
Validation loss: 2.9582260305334933

Epoch: 5| Step: 10
Training loss: 3.275918461959818
Validation loss: 2.960415492314797

Epoch: 351| Step: 0
Training loss: 3.102558888776359
Validation loss: 2.9608041156030382

Epoch: 5| Step: 1
Training loss: 3.132267397976935
Validation loss: 2.958511011546979

Epoch: 5| Step: 2
Training loss: 3.106162093394267
Validation loss: 2.9610109587704008

Epoch: 5| Step: 3
Training loss: 2.9481640679344765
Validation loss: 2.9593103873123328

Epoch: 5| Step: 4
Training loss: 2.9746412750156708
Validation loss: 2.9601159577963454

Epoch: 5| Step: 5
Training loss: 3.2291158036358834
Validation loss: 2.9576545802101646

Epoch: 5| Step: 6
Training loss: 3.7666966349892133
Validation loss: 2.9597417144283154

Epoch: 5| Step: 7
Training loss: 3.439127450110424
Validation loss: 2.959663276463099

Epoch: 5| Step: 8
Training loss: 3.735557337060862
Validation loss: 2.9575039331947455

Epoch: 5| Step: 9
Training loss: 3.322968118841264
Validation loss: 2.957240744510954

Epoch: 5| Step: 10
Training loss: 2.5837452057681847
Validation loss: 2.959495280425368

Epoch: 352| Step: 0
Training loss: 3.1341881526125013
Validation loss: 2.9574641118174334

Epoch: 5| Step: 1
Training loss: 3.3655723008020892
Validation loss: 2.959582875304679

Epoch: 5| Step: 2
Training loss: 2.415882794638266
Validation loss: 2.9578140047908525

Epoch: 5| Step: 3
Training loss: 3.73342423725718
Validation loss: 2.9592497216696367

Epoch: 5| Step: 4
Training loss: 2.27140302832226
Validation loss: 2.958346920741929

Epoch: 5| Step: 5
Training loss: 3.407459289352369
Validation loss: 2.957918792917941

Epoch: 5| Step: 6
Training loss: 3.368463048939791
Validation loss: 2.9586014473749485

Epoch: 5| Step: 7
Training loss: 3.1962020866851746
Validation loss: 2.9565733498735653

Epoch: 5| Step: 8
Training loss: 3.4162530571162826
Validation loss: 2.9542860500757517

Epoch: 5| Step: 9
Training loss: 3.0353645636163074
Validation loss: 2.958114918109104

Epoch: 5| Step: 10
Training loss: 3.9840951858700917
Validation loss: 2.9556387716137333

Epoch: 353| Step: 0
Training loss: 3.502471051528745
Validation loss: 2.956681586077387

Epoch: 5| Step: 1
Training loss: 2.956713882407609
Validation loss: 2.9566512134361487

Epoch: 5| Step: 2
Training loss: 2.832704997981756
Validation loss: 2.9555215759510145

Epoch: 5| Step: 3
Training loss: 2.8691346419695956
Validation loss: 2.958141983362821

Epoch: 5| Step: 4
Training loss: 3.476888371314505
Validation loss: 2.960006046567526

Epoch: 5| Step: 5
Training loss: 2.9668484671390503
Validation loss: 2.95580031017648

Epoch: 5| Step: 6
Training loss: 3.464830400684191
Validation loss: 2.9554182008924723

Epoch: 5| Step: 7
Training loss: 3.2982929669711996
Validation loss: 2.9554266783471994

Epoch: 5| Step: 8
Training loss: 3.2105497325638974
Validation loss: 2.9563710592531254

Epoch: 5| Step: 9
Training loss: 3.2389413048189084
Validation loss: 2.957744623581576

Epoch: 5| Step: 10
Training loss: 3.704286803509719
Validation loss: 2.9530354686073377

Epoch: 354| Step: 0
Training loss: 3.2263445099352843
Validation loss: 2.9554993988684406

Epoch: 5| Step: 1
Training loss: 3.4507004178895966
Validation loss: 2.953341703835228

Epoch: 5| Step: 2
Training loss: 3.123729447521971
Validation loss: 2.9557614710906663

Epoch: 5| Step: 3
Training loss: 2.724088229309174
Validation loss: 2.952851631310774

Epoch: 5| Step: 4
Training loss: 3.456842139292561
Validation loss: 2.9534718568649714

Epoch: 5| Step: 5
Training loss: 3.2612548498232403
Validation loss: 2.954610410748303

Epoch: 5| Step: 6
Training loss: 2.369181885010151
Validation loss: 2.954589525745

Epoch: 5| Step: 7
Training loss: 3.9133083203202497
Validation loss: 2.9546099769109326

Epoch: 5| Step: 8
Training loss: 3.6936007964954833
Validation loss: 2.9553417925382206

Epoch: 5| Step: 9
Training loss: 3.228970790377687
Validation loss: 2.950413690415226

Epoch: 5| Step: 10
Training loss: 2.746421566493104
Validation loss: 2.953286570157004

Epoch: 355| Step: 0
Training loss: 3.658988774585003
Validation loss: 2.955041117360139

Epoch: 5| Step: 1
Training loss: 2.8204804684822053
Validation loss: 2.9641797779256427

Epoch: 5| Step: 2
Training loss: 2.908927750346901
Validation loss: 2.9650093575056213

Epoch: 5| Step: 3
Training loss: 3.272926600243063
Validation loss: 2.9595997959367852

Epoch: 5| Step: 4
Training loss: 3.5061602195084127
Validation loss: 2.9661308604458183

Epoch: 5| Step: 5
Training loss: 3.584356620229277
Validation loss: 2.9533179817401636

Epoch: 5| Step: 6
Training loss: 3.3282195601663402
Validation loss: 2.9504184998219203

Epoch: 5| Step: 7
Training loss: 3.402341367455753
Validation loss: 2.9521355313365008

Epoch: 5| Step: 8
Training loss: 3.1064574389204527
Validation loss: 2.9513787157018907

Epoch: 5| Step: 9
Training loss: 2.9818281720685547
Validation loss: 2.950173518571865

Epoch: 5| Step: 10
Training loss: 2.8392687691648155
Validation loss: 2.954361726455403

Epoch: 356| Step: 0
Training loss: 4.04985849580693
Validation loss: 2.952278048308979

Epoch: 5| Step: 1
Training loss: 3.304116346273526
Validation loss: 2.952830674830404

Epoch: 5| Step: 2
Training loss: 2.2698464888706305
Validation loss: 2.952965711204292

Epoch: 5| Step: 3
Training loss: 2.6637189984855882
Validation loss: 2.952532699573514

Epoch: 5| Step: 4
Training loss: 3.048010668257819
Validation loss: 2.9521612289790022

Epoch: 5| Step: 5
Training loss: 3.4528279586695905
Validation loss: 2.9522947016731393

Epoch: 5| Step: 6
Training loss: 3.74520936775409
Validation loss: 2.9529060221380306

Epoch: 5| Step: 7
Training loss: 3.0990947447600745
Validation loss: 2.9529779105344987

Epoch: 5| Step: 8
Training loss: 3.413473047834275
Validation loss: 2.952673497354857

Epoch: 5| Step: 9
Training loss: 3.4122108309007815
Validation loss: 2.952612655407746

Epoch: 5| Step: 10
Training loss: 2.671996086009237
Validation loss: 2.951597779948748

Epoch: 357| Step: 0
Training loss: 2.9211398745188335
Validation loss: 2.950582739613719

Epoch: 5| Step: 1
Training loss: 3.6599840186765533
Validation loss: 2.9501647131883293

Epoch: 5| Step: 2
Training loss: 2.790391792215735
Validation loss: 2.9509496446838863

Epoch: 5| Step: 3
Training loss: 3.300030251566625
Validation loss: 2.9491298649918827

Epoch: 5| Step: 4
Training loss: 3.687987602453019
Validation loss: 2.95018813824861

Epoch: 5| Step: 5
Training loss: 3.8985047726378728
Validation loss: 2.9477406420989327

Epoch: 5| Step: 6
Training loss: 3.101022207250119
Validation loss: 2.9469505862614955

Epoch: 5| Step: 7
Training loss: 2.83361317617669
Validation loss: 2.949001460663894

Epoch: 5| Step: 8
Training loss: 2.708326241899645
Validation loss: 2.9484810420270042

Epoch: 5| Step: 9
Training loss: 3.330592713631716
Validation loss: 2.951297972451253

Epoch: 5| Step: 10
Training loss: 3.027587565786638
Validation loss: 2.9476205858366336

Epoch: 358| Step: 0
Training loss: 3.1606419287920886
Validation loss: 2.95452784514305

Epoch: 5| Step: 1
Training loss: 3.3862031150323637
Validation loss: 2.958888981961243

Epoch: 5| Step: 2
Training loss: 2.965562092603264
Validation loss: 2.957568568219111

Epoch: 5| Step: 3
Training loss: 3.4230679039601406
Validation loss: 2.95421544139506

Epoch: 5| Step: 4
Training loss: 2.395507016280952
Validation loss: 2.971137735424023

Epoch: 5| Step: 5
Training loss: 2.756895004542349
Validation loss: 2.9747858403506866

Epoch: 5| Step: 6
Training loss: 3.4436629102602296
Validation loss: 2.9644732910922498

Epoch: 5| Step: 7
Training loss: 3.4487804855874136
Validation loss: 2.9750807216492574

Epoch: 5| Step: 8
Training loss: 3.661402926652076
Validation loss: 2.956681863538771

Epoch: 5| Step: 9
Training loss: 3.3719846182638653
Validation loss: 2.949381576331982

Epoch: 5| Step: 10
Training loss: 3.343258830565515
Validation loss: 2.9483049995624055

Epoch: 359| Step: 0
Training loss: 2.988535911330253
Validation loss: 2.9436836934173076

Epoch: 5| Step: 1
Training loss: 2.8747075802905893
Validation loss: 2.9452467534304705

Epoch: 5| Step: 2
Training loss: 3.49346176896579
Validation loss: 2.947284937057396

Epoch: 5| Step: 3
Training loss: 2.375698087391431
Validation loss: 2.947857900118036

Epoch: 5| Step: 4
Training loss: 3.557907624579236
Validation loss: 2.946776818716351

Epoch: 5| Step: 5
Training loss: 3.005142889957564
Validation loss: 2.947707206415414

Epoch: 5| Step: 6
Training loss: 3.80230914277097
Validation loss: 2.950055424486091

Epoch: 5| Step: 7
Training loss: 3.6910245183328274
Validation loss: 2.949371450853046

Epoch: 5| Step: 8
Training loss: 3.3508381094080666
Validation loss: 2.949789527989218

Epoch: 5| Step: 9
Training loss: 2.9875972588321615
Validation loss: 2.948837102372386

Epoch: 5| Step: 10
Training loss: 3.1464704327360256
Validation loss: 2.947570581027451

Epoch: 360| Step: 0
Training loss: 3.270777383961582
Validation loss: 2.9447549924604592

Epoch: 5| Step: 1
Training loss: 2.7619728931861935
Validation loss: 2.9484435681384764

Epoch: 5| Step: 2
Training loss: 3.708136664043826
Validation loss: 2.9485970133862676

Epoch: 5| Step: 3
Training loss: 2.5314679464066066
Validation loss: 2.944553922859865

Epoch: 5| Step: 4
Training loss: 3.4504053789892444
Validation loss: 2.9443850151075903

Epoch: 5| Step: 5
Training loss: 3.0823641791821856
Validation loss: 2.9489622129878574

Epoch: 5| Step: 6
Training loss: 3.6014240097593744
Validation loss: 2.950358913022446

Epoch: 5| Step: 7
Training loss: 3.2170940695003245
Validation loss: 2.9482848907352905

Epoch: 5| Step: 8
Training loss: 3.199359001094329
Validation loss: 2.9547417008928307

Epoch: 5| Step: 9
Training loss: 3.408308894311513
Validation loss: 2.9661002029700083

Epoch: 5| Step: 10
Training loss: 3.0774891772726787
Validation loss: 2.9509377514578916

Epoch: 361| Step: 0
Training loss: 3.2621694287726752
Validation loss: 2.9582684561932258

Epoch: 5| Step: 1
Training loss: 2.8058605238168504
Validation loss: 2.95087591459774

Epoch: 5| Step: 2
Training loss: 3.7189831059588356
Validation loss: 2.9502180212890075

Epoch: 5| Step: 3
Training loss: 2.473734591890513
Validation loss: 2.9470247120619932

Epoch: 5| Step: 4
Training loss: 2.8803283408872606
Validation loss: 2.947213018529528

Epoch: 5| Step: 5
Training loss: 2.6115967206549042
Validation loss: 2.944893217942961

Epoch: 5| Step: 6
Training loss: 2.985518311400471
Validation loss: 2.948320868448323

Epoch: 5| Step: 7
Training loss: 3.8836276083410155
Validation loss: 2.942748379069594

Epoch: 5| Step: 8
Training loss: 3.365530504690595
Validation loss: 2.9405812005170526

Epoch: 5| Step: 9
Training loss: 3.532304724434143
Validation loss: 2.939219222817687

Epoch: 5| Step: 10
Training loss: 3.68017989506744
Validation loss: 2.939286661086598

Epoch: 362| Step: 0
Training loss: 3.437095202106675
Validation loss: 2.9417229021268843

Epoch: 5| Step: 1
Training loss: 3.4149813953970822
Validation loss: 2.9404096259516805

Epoch: 5| Step: 2
Training loss: 2.748505793292814
Validation loss: 2.9427284535511413

Epoch: 5| Step: 3
Training loss: 3.5096470171163108
Validation loss: 2.9409674097976866

Epoch: 5| Step: 4
Training loss: 3.2356379158008344
Validation loss: 2.9411516412619503

Epoch: 5| Step: 5
Training loss: 3.1530762380377704
Validation loss: 2.938804425861586

Epoch: 5| Step: 6
Training loss: 3.1278164188338735
Validation loss: 2.939135595086982

Epoch: 5| Step: 7
Training loss: 3.5718731630709404
Validation loss: 2.9377937231137428

Epoch: 5| Step: 8
Training loss: 2.934906809170544
Validation loss: 2.940306477265806

Epoch: 5| Step: 9
Training loss: 3.34438111240696
Validation loss: 2.941305200213515

Epoch: 5| Step: 10
Training loss: 2.8199627519406643
Validation loss: 2.940050174091627

Epoch: 363| Step: 0
Training loss: 3.5813649263964917
Validation loss: 2.9399250992941672

Epoch: 5| Step: 1
Training loss: 3.622021470880931
Validation loss: 2.9421532594820543

Epoch: 5| Step: 2
Training loss: 1.862993710002017
Validation loss: 2.943323449870416

Epoch: 5| Step: 3
Training loss: 3.4284137280844575
Validation loss: 2.9467391700364414

Epoch: 5| Step: 4
Training loss: 2.970457529603927
Validation loss: 2.951948983991698

Epoch: 5| Step: 5
Training loss: 3.2678813531412074
Validation loss: 2.9457683422101226

Epoch: 5| Step: 6
Training loss: 3.4473675677649798
Validation loss: 2.9419295941357126

Epoch: 5| Step: 7
Training loss: 3.304862087679167
Validation loss: 2.937292035346438

Epoch: 5| Step: 8
Training loss: 2.4573221443833644
Validation loss: 2.9406578555307354

Epoch: 5| Step: 9
Training loss: 3.965195272863736
Validation loss: 2.9366573136517458

Epoch: 5| Step: 10
Training loss: 3.014054912520015
Validation loss: 2.936116371180213

Epoch: 364| Step: 0
Training loss: 2.8498116748894873
Validation loss: 2.9352396059711743

Epoch: 5| Step: 1
Training loss: 3.519548185352221
Validation loss: 2.934835184803489

Epoch: 5| Step: 2
Training loss: 2.8622223898523624
Validation loss: 2.9375685258603585

Epoch: 5| Step: 3
Training loss: 3.507148254985279
Validation loss: 2.93658662767843

Epoch: 5| Step: 4
Training loss: 3.0538586518878783
Validation loss: 2.9348514270109964

Epoch: 5| Step: 5
Training loss: 2.968214769803178
Validation loss: 2.9376624312707005

Epoch: 5| Step: 6
Training loss: 3.189518009233619
Validation loss: 2.936128550584751

Epoch: 5| Step: 7
Training loss: 3.1009762303567876
Validation loss: 2.932862495388143

Epoch: 5| Step: 8
Training loss: 3.0137937055129784
Validation loss: 2.9363861476942272

Epoch: 5| Step: 9
Training loss: 3.7825665664614436
Validation loss: 2.937549169124971

Epoch: 5| Step: 10
Training loss: 3.4595653836483264
Validation loss: 2.933857724808749

Epoch: 365| Step: 0
Training loss: 3.7306565162578775
Validation loss: 2.9353556961104994

Epoch: 5| Step: 1
Training loss: 2.803716890069003
Validation loss: 2.9341449345641246

Epoch: 5| Step: 2
Training loss: 3.165183087879335
Validation loss: 2.9368785138752256

Epoch: 5| Step: 3
Training loss: 2.8462970770962097
Validation loss: 2.934380957084472

Epoch: 5| Step: 4
Training loss: 2.477186058316389
Validation loss: 2.934453940556928

Epoch: 5| Step: 5
Training loss: 2.422294235860249
Validation loss: 2.934504702659093

Epoch: 5| Step: 6
Training loss: 3.1264365899595017
Validation loss: 2.935802404684201

Epoch: 5| Step: 7
Training loss: 3.322846287347764
Validation loss: 2.9330441120714252

Epoch: 5| Step: 8
Training loss: 3.352170520041391
Validation loss: 2.933565205965415

Epoch: 5| Step: 9
Training loss: 4.0387524720080785
Validation loss: 2.9322531013893953

Epoch: 5| Step: 10
Training loss: 3.7731789447036412
Validation loss: 2.933947067249306

Epoch: 366| Step: 0
Training loss: 3.072381096844603
Validation loss: 2.9332950371631683

Epoch: 5| Step: 1
Training loss: 3.057436123521481
Validation loss: 2.932627459118417

Epoch: 5| Step: 2
Training loss: 2.744171641978845
Validation loss: 2.9353791860755263

Epoch: 5| Step: 3
Training loss: 3.8223765283556155
Validation loss: 2.9332534966087165

Epoch: 5| Step: 4
Training loss: 2.891344465468126
Validation loss: 2.939518582530272

Epoch: 5| Step: 5
Training loss: 3.075408821531808
Validation loss: 2.9384450655496983

Epoch: 5| Step: 6
Training loss: 2.391766942366647
Validation loss: 2.936126702154466

Epoch: 5| Step: 7
Training loss: 3.346857213704125
Validation loss: 2.9336937974318205

Epoch: 5| Step: 8
Training loss: 3.4379046115302496
Validation loss: 2.931653481474173

Epoch: 5| Step: 9
Training loss: 3.4973018327788217
Validation loss: 2.934407524854623

Epoch: 5| Step: 10
Training loss: 3.840868358180614
Validation loss: 2.9345421702145438

Epoch: 367| Step: 0
Training loss: 3.280121091375206
Validation loss: 2.9310265634487958

Epoch: 5| Step: 1
Training loss: 3.2124616806179147
Validation loss: 2.9374592188489643

Epoch: 5| Step: 2
Training loss: 3.318704229064375
Validation loss: 2.9334812929526697

Epoch: 5| Step: 3
Training loss: 3.1144654284628577
Validation loss: 2.933951581222132

Epoch: 5| Step: 4
Training loss: 3.631069626653551
Validation loss: 2.935184934065207

Epoch: 5| Step: 5
Training loss: 2.9445343203793026
Validation loss: 2.93541297789806

Epoch: 5| Step: 6
Training loss: 2.8788575539682473
Validation loss: 2.943299810780987

Epoch: 5| Step: 7
Training loss: 3.400748192985586
Validation loss: 2.939168440960492

Epoch: 5| Step: 8
Training loss: 3.4593292701958553
Validation loss: 2.932177476046146

Epoch: 5| Step: 9
Training loss: 3.2853392777956816
Validation loss: 2.9319205916591478

Epoch: 5| Step: 10
Training loss: 2.6340877715760915
Validation loss: 2.9328299958464537

Epoch: 368| Step: 0
Training loss: 3.2358187341929705
Validation loss: 2.9318674352896483

Epoch: 5| Step: 1
Training loss: 3.1207725923040237
Validation loss: 2.9322847487812598

Epoch: 5| Step: 2
Training loss: 3.105879001989614
Validation loss: 2.9310403864832133

Epoch: 5| Step: 3
Training loss: 2.141823648817301
Validation loss: 2.9273507040596987

Epoch: 5| Step: 4
Training loss: 3.265541185097408
Validation loss: 2.9294729581643457

Epoch: 5| Step: 5
Training loss: 3.713036644164806
Validation loss: 2.930188771450181

Epoch: 5| Step: 6
Training loss: 3.221300022386694
Validation loss: 2.9306066432760396

Epoch: 5| Step: 7
Training loss: 3.1540427468740635
Validation loss: 2.9278335342701594

Epoch: 5| Step: 8
Training loss: 3.5497553888856697
Validation loss: 2.9294808394852647

Epoch: 5| Step: 9
Training loss: 3.4826927058350075
Validation loss: 2.926302104966381

Epoch: 5| Step: 10
Training loss: 3.1109550716990246
Validation loss: 2.9282891102868107

Epoch: 369| Step: 0
Training loss: 3.6022195278798006
Validation loss: 2.9297163242029622

Epoch: 5| Step: 1
Training loss: 2.3767575235999083
Validation loss: 2.9273879952015065

Epoch: 5| Step: 2
Training loss: 3.2170158084745397
Validation loss: 2.9273704207307536

Epoch: 5| Step: 3
Training loss: 3.5224442868940398
Validation loss: 2.925437890121466

Epoch: 5| Step: 4
Training loss: 3.3781314027568543
Validation loss: 2.929148391397991

Epoch: 5| Step: 5
Training loss: 2.90455742227192
Validation loss: 2.929098908833264

Epoch: 5| Step: 6
Training loss: 3.843513791649714
Validation loss: 2.9276413175321543

Epoch: 5| Step: 7
Training loss: 2.6375259181190995
Validation loss: 2.9294055993966994

Epoch: 5| Step: 8
Training loss: 3.3691907265296512
Validation loss: 2.927062166379989

Epoch: 5| Step: 9
Training loss: 3.3095959583323262
Validation loss: 2.929739882134196

Epoch: 5| Step: 10
Training loss: 2.79328816328043
Validation loss: 2.928882317704052

Epoch: 370| Step: 0
Training loss: 3.5789223661228493
Validation loss: 2.926476931446793

Epoch: 5| Step: 1
Training loss: 3.4430290838382067
Validation loss: 2.9283277201814237

Epoch: 5| Step: 2
Training loss: 3.5752749357341553
Validation loss: 2.930583977598309

Epoch: 5| Step: 3
Training loss: 3.0177519417981595
Validation loss: 2.9401919611236957

Epoch: 5| Step: 4
Training loss: 2.585816348830746
Validation loss: 2.9301321513415166

Epoch: 5| Step: 5
Training loss: 2.940592010994057
Validation loss: 2.9363611684746993

Epoch: 5| Step: 6
Training loss: 3.3991934100052394
Validation loss: 2.9261414024615853

Epoch: 5| Step: 7
Training loss: 2.9028791341978453
Validation loss: 2.9321410834195416

Epoch: 5| Step: 8
Training loss: 3.3148373688495467
Validation loss: 2.9297672340180307

Epoch: 5| Step: 9
Training loss: 2.9096379375364334
Validation loss: 2.930120624205516

Epoch: 5| Step: 10
Training loss: 3.5160302500806817
Validation loss: 2.9328810841249386

Epoch: 371| Step: 0
Training loss: 3.6338204246916566
Validation loss: 2.924818001760875

Epoch: 5| Step: 1
Training loss: 3.2120751363438798
Validation loss: 2.9269805184807343

Epoch: 5| Step: 2
Training loss: 3.36438650651892
Validation loss: 2.922771503865925

Epoch: 5| Step: 3
Training loss: 3.33693463969731
Validation loss: 2.92309536316649

Epoch: 5| Step: 4
Training loss: 3.3503391549674646
Validation loss: 2.9224817087983244

Epoch: 5| Step: 5
Training loss: 3.103799853744518
Validation loss: 2.9243629597647227

Epoch: 5| Step: 6
Training loss: 3.3899297748595036
Validation loss: 2.922358757711379

Epoch: 5| Step: 7
Training loss: 3.0470900239631487
Validation loss: 2.9228421195984104

Epoch: 5| Step: 8
Training loss: 2.6434152521986856
Validation loss: 2.922593800508498

Epoch: 5| Step: 9
Training loss: 3.4386897022392313
Validation loss: 2.922375242955982

Epoch: 5| Step: 10
Training loss: 2.5254565213391253
Validation loss: 2.9244450042184145

Epoch: 372| Step: 0
Training loss: 3.157393899737273
Validation loss: 2.922304979130111

Epoch: 5| Step: 1
Training loss: 2.9304784088667133
Validation loss: 2.9204338335805917

Epoch: 5| Step: 2
Training loss: 2.8683524194939842
Validation loss: 2.922071779196669

Epoch: 5| Step: 3
Training loss: 3.008451002642844
Validation loss: 2.9240332794173414

Epoch: 5| Step: 4
Training loss: 3.3135760017222258
Validation loss: 2.9289771212914046

Epoch: 5| Step: 5
Training loss: 3.50459165471825
Validation loss: 2.926219653508795

Epoch: 5| Step: 6
Training loss: 3.1145923491042344
Validation loss: 2.926487925427028

Epoch: 5| Step: 7
Training loss: 3.57668518682581
Validation loss: 2.925240650274304

Epoch: 5| Step: 8
Training loss: 3.2857295385445022
Validation loss: 2.9289936025459014

Epoch: 5| Step: 9
Training loss: 3.427899913648758
Validation loss: 2.92469803448938

Epoch: 5| Step: 10
Training loss: 2.9872968660509738
Validation loss: 2.9214937221135484

Epoch: 373| Step: 0
Training loss: 3.480147324436176
Validation loss: 2.920928164677555

Epoch: 5| Step: 1
Training loss: 3.157763278885242
Validation loss: 2.9197572977891424

Epoch: 5| Step: 2
Training loss: 3.0097000342666456
Validation loss: 2.920008079328273

Epoch: 5| Step: 3
Training loss: 2.6025291686022065
Validation loss: 2.9201107966987374

Epoch: 5| Step: 4
Training loss: 3.103106904529314
Validation loss: 2.9213595863301243

Epoch: 5| Step: 5
Training loss: 2.9858679108068618
Validation loss: 2.920361108956448

Epoch: 5| Step: 6
Training loss: 3.6047125753879
Validation loss: 2.9226089572612666

Epoch: 5| Step: 7
Training loss: 2.894128604122019
Validation loss: 2.9195162012927223

Epoch: 5| Step: 8
Training loss: 4.088446756545022
Validation loss: 2.919701054023144

Epoch: 5| Step: 9
Training loss: 2.924060677228879
Validation loss: 2.9195233666175477

Epoch: 5| Step: 10
Training loss: 3.1668018680287053
Validation loss: 2.922949463049979

Epoch: 374| Step: 0
Training loss: 3.4961380769274393
Validation loss: 2.9184299084871648

Epoch: 5| Step: 1
Training loss: 2.733996032611505
Validation loss: 2.9201064544744546

Epoch: 5| Step: 2
Training loss: 3.270996057305661
Validation loss: 2.9211839919685647

Epoch: 5| Step: 3
Training loss: 3.5285638365655596
Validation loss: 2.919936950800517

Epoch: 5| Step: 4
Training loss: 2.690588750827655
Validation loss: 2.921675420752124

Epoch: 5| Step: 5
Training loss: 3.4724075691769034
Validation loss: 2.9193998255255145

Epoch: 5| Step: 6
Training loss: 2.692806062578889
Validation loss: 2.918436126018391

Epoch: 5| Step: 7
Training loss: 3.4074216454971693
Validation loss: 2.9215294207667224

Epoch: 5| Step: 8
Training loss: 2.977362577788721
Validation loss: 2.9213187904765183

Epoch: 5| Step: 9
Training loss: 3.575873053590962
Validation loss: 2.926638523906179

Epoch: 5| Step: 10
Training loss: 3.2380618399545917
Validation loss: 2.9236241842445

Epoch: 375| Step: 0
Training loss: 3.085997452938193
Validation loss: 2.9230098226043015

Epoch: 5| Step: 1
Training loss: 2.5110477482651308
Validation loss: 2.918078019254688

Epoch: 5| Step: 2
Training loss: 2.8873440654974734
Validation loss: 2.9187413819035997

Epoch: 5| Step: 3
Training loss: 2.6106740493312848
Validation loss: 2.916950178357279

Epoch: 5| Step: 4
Training loss: 2.9366638941612826
Validation loss: 2.920122736465339

Epoch: 5| Step: 5
Training loss: 3.373856244726946
Validation loss: 2.918591505534596

Epoch: 5| Step: 6
Training loss: 3.623521437501402
Validation loss: 2.917479716128513

Epoch: 5| Step: 7
Training loss: 3.5952591090940076
Validation loss: 2.9169410353847574

Epoch: 5| Step: 8
Training loss: 3.801342004417111
Validation loss: 2.917211589508019

Epoch: 5| Step: 9
Training loss: 3.6509508383749782
Validation loss: 2.9175371415128435

Epoch: 5| Step: 10
Training loss: 2.798196917085338
Validation loss: 2.9181100487949285

Epoch: 376| Step: 0
Training loss: 3.448932985800036
Validation loss: 2.9202218557134394

Epoch: 5| Step: 1
Training loss: 2.5058788795336504
Validation loss: 2.922545306090724

Epoch: 5| Step: 2
Training loss: 2.759168253807626
Validation loss: 2.917097802240353

Epoch: 5| Step: 3
Training loss: 3.0325979794667672
Validation loss: 2.9191965326392966

Epoch: 5| Step: 4
Training loss: 3.5862233831269523
Validation loss: 2.928379853499649

Epoch: 5| Step: 5
Training loss: 2.5855362226419785
Validation loss: 2.922273691248324

Epoch: 5| Step: 6
Training loss: 3.2294192471729697
Validation loss: 2.921164151046364

Epoch: 5| Step: 7
Training loss: 3.2201400273838208
Validation loss: 2.926878648319784

Epoch: 5| Step: 8
Training loss: 3.025345390085086
Validation loss: 2.9217715058316864

Epoch: 5| Step: 9
Training loss: 3.6432770986541945
Validation loss: 2.931751453615855

Epoch: 5| Step: 10
Training loss: 4.000375491637839
Validation loss: 2.9259725725783507

Epoch: 377| Step: 0
Training loss: 3.5639024617455424
Validation loss: 2.9279873924356017

Epoch: 5| Step: 1
Training loss: 2.8349930632975653
Validation loss: 2.9158633938106195

Epoch: 5| Step: 2
Training loss: 3.603184001932489
Validation loss: 2.919790494238114

Epoch: 5| Step: 3
Training loss: 3.27361054975911
Validation loss: 2.916081539181892

Epoch: 5| Step: 4
Training loss: 2.7521129640249415
Validation loss: 2.9167676421820974

Epoch: 5| Step: 5
Training loss: 3.2118188989493848
Validation loss: 2.913816092403519

Epoch: 5| Step: 6
Training loss: 3.4457256043525466
Validation loss: 2.914687437634316

Epoch: 5| Step: 7
Training loss: 3.230499451939959
Validation loss: 2.913354396301362

Epoch: 5| Step: 8
Training loss: 2.8162919654885727
Validation loss: 2.9126138407068938

Epoch: 5| Step: 9
Training loss: 3.042871750349447
Validation loss: 2.909366141595329

Epoch: 5| Step: 10
Training loss: 3.305319002023732
Validation loss: 2.9122482661404647

Epoch: 378| Step: 0
Training loss: 3.6134192857924092
Validation loss: 2.911745223293833

Epoch: 5| Step: 1
Training loss: 2.8386009466764883
Validation loss: 2.9102483408462128

Epoch: 5| Step: 2
Training loss: 2.947177771895145
Validation loss: 2.9147828489136223

Epoch: 5| Step: 3
Training loss: 3.420984579096708
Validation loss: 2.9109054998292505

Epoch: 5| Step: 4
Training loss: 3.2766030967136612
Validation loss: 2.9140145216684927

Epoch: 5| Step: 5
Training loss: 2.6886845129631336
Validation loss: 2.910659535757424

Epoch: 5| Step: 6
Training loss: 3.460544951417162
Validation loss: 2.9108887100756746

Epoch: 5| Step: 7
Training loss: 3.1983854631552546
Validation loss: 2.91239474019792

Epoch: 5| Step: 8
Training loss: 3.0308159586258343
Validation loss: 2.9105147483470573

Epoch: 5| Step: 9
Training loss: 3.207683167077759
Validation loss: 2.9103579307936984

Epoch: 5| Step: 10
Training loss: 3.4913677303078323
Validation loss: 2.909365631398954

Epoch: 379| Step: 0
Training loss: 3.148223188125095
Validation loss: 2.9106853027610535

Epoch: 5| Step: 1
Training loss: 2.9148190413720907
Validation loss: 2.90817923922279

Epoch: 5| Step: 2
Training loss: 2.8560852136802106
Validation loss: 2.9099737440065865

Epoch: 5| Step: 3
Training loss: 3.1231931421931596
Validation loss: 2.9118057429084208

Epoch: 5| Step: 4
Training loss: 3.54114624388503
Validation loss: 2.9154014784937803

Epoch: 5| Step: 5
Training loss: 3.299774774899565
Validation loss: 2.911716397279385

Epoch: 5| Step: 6
Training loss: 3.735947026679745
Validation loss: 2.91552263726093

Epoch: 5| Step: 7
Training loss: 2.2309589014444176
Validation loss: 2.9101135810167995

Epoch: 5| Step: 8
Training loss: 3.396265076571161
Validation loss: 2.9107477177688343

Epoch: 5| Step: 9
Training loss: 3.548453227738565
Validation loss: 2.912747833553213

Epoch: 5| Step: 10
Training loss: 3.1280899030639113
Validation loss: 2.90730461897552

Epoch: 380| Step: 0
Training loss: 3.170825201985731
Validation loss: 2.91447136938557

Epoch: 5| Step: 1
Training loss: 3.3671343947469037
Validation loss: 2.917102713152768

Epoch: 5| Step: 2
Training loss: 3.034901258442939
Validation loss: 2.917357158817282

Epoch: 5| Step: 3
Training loss: 2.7979855170812424
Validation loss: 2.916614921099087

Epoch: 5| Step: 4
Training loss: 3.403854367620512
Validation loss: 2.912638022824498

Epoch: 5| Step: 5
Training loss: 3.286395443628453
Validation loss: 2.9135413786677953

Epoch: 5| Step: 6
Training loss: 3.1163904227435584
Validation loss: 2.9170597977559893

Epoch: 5| Step: 7
Training loss: 3.3535261470605167
Validation loss: 2.9147041456961493

Epoch: 5| Step: 8
Training loss: 3.1974991682228993
Validation loss: 2.918473887705099

Epoch: 5| Step: 9
Training loss: 3.219668063001695
Validation loss: 2.911636207687458

Epoch: 5| Step: 10
Training loss: 3.1786281311218954
Validation loss: 2.9094164153257482

Epoch: 381| Step: 0
Training loss: 3.1311027446545103
Validation loss: 2.9091230259704446

Epoch: 5| Step: 1
Training loss: 3.1941426194464544
Validation loss: 2.9087951979093614

Epoch: 5| Step: 2
Training loss: 2.7879251677596786
Validation loss: 2.910370779984172

Epoch: 5| Step: 3
Training loss: 3.3714934606057336
Validation loss: 2.9070984264336843

Epoch: 5| Step: 4
Training loss: 3.164285835578569
Validation loss: 2.9075611256299556

Epoch: 5| Step: 5
Training loss: 3.076823777650553
Validation loss: 2.9072955003406125

Epoch: 5| Step: 6
Training loss: 3.3752483700386025
Validation loss: 2.905808498064548

Epoch: 5| Step: 7
Training loss: 3.656495958190128
Validation loss: 2.9066387546774397

Epoch: 5| Step: 8
Training loss: 2.497674718937082
Validation loss: 2.9069074102643695

Epoch: 5| Step: 9
Training loss: 3.040099293191487
Validation loss: 2.906847044428287

Epoch: 5| Step: 10
Training loss: 3.77522339822996
Validation loss: 2.906547406791457

Epoch: 382| Step: 0
Training loss: 2.9593016602271462
Validation loss: 2.9077708586972113

Epoch: 5| Step: 1
Training loss: 3.245084272798017
Validation loss: 2.9089129550298174

Epoch: 5| Step: 2
Training loss: 3.551597375526494
Validation loss: 2.910643065189522

Epoch: 5| Step: 3
Training loss: 2.673378861373372
Validation loss: 2.909139723691002

Epoch: 5| Step: 4
Training loss: 3.0840537973602546
Validation loss: 2.91341156685983

Epoch: 5| Step: 5
Training loss: 4.069944163696287
Validation loss: 2.915492993899097

Epoch: 5| Step: 6
Training loss: 3.297285732338584
Validation loss: 2.914596781799715

Epoch: 5| Step: 7
Training loss: 2.6557650852760655
Validation loss: 2.917813846040037

Epoch: 5| Step: 8
Training loss: 2.828686400274628
Validation loss: 2.9113267778619485

Epoch: 5| Step: 9
Training loss: 2.900121975668417
Validation loss: 2.907577789998155

Epoch: 5| Step: 10
Training loss: 3.6593131251523965
Validation loss: 2.90730961256455

Epoch: 383| Step: 0
Training loss: 3.022528302207687
Validation loss: 2.9058795277792497

Epoch: 5| Step: 1
Training loss: 3.2032872600860953
Validation loss: 2.9039720598221006

Epoch: 5| Step: 2
Training loss: 3.505583804890471
Validation loss: 2.9058763729396215

Epoch: 5| Step: 3
Training loss: 2.6051896387583846
Validation loss: 2.9040639830712407

Epoch: 5| Step: 4
Training loss: 2.7285635963761217
Validation loss: 2.90801540091652

Epoch: 5| Step: 5
Training loss: 3.323301446494504
Validation loss: 2.9037582110107616

Epoch: 5| Step: 6
Training loss: 3.414388470833502
Validation loss: 2.9046711209318543

Epoch: 5| Step: 7
Training loss: 3.8398742985019574
Validation loss: 2.905144477561066

Epoch: 5| Step: 8
Training loss: 3.150489762999578
Validation loss: 2.9033577339272822

Epoch: 5| Step: 9
Training loss: 3.0196545811346827
Validation loss: 2.9037811646538008

Epoch: 5| Step: 10
Training loss: 3.1431572417863918
Validation loss: 2.9044656205581894

Epoch: 384| Step: 0
Training loss: 3.232669989061474
Validation loss: 2.904324523872292

Epoch: 5| Step: 1
Training loss: 3.8938428448281943
Validation loss: 2.902114406190519

Epoch: 5| Step: 2
Training loss: 3.3797176026420312
Validation loss: 2.9013959687768405

Epoch: 5| Step: 3
Training loss: 2.8966941011605356
Validation loss: 2.9012150209607945

Epoch: 5| Step: 4
Training loss: 2.571833012957744
Validation loss: 2.9020703786986286

Epoch: 5| Step: 5
Training loss: 2.4453530597674566
Validation loss: 2.9009174280480923

Epoch: 5| Step: 6
Training loss: 3.237453304233858
Validation loss: 2.902405596250134

Epoch: 5| Step: 7
Training loss: 3.4303230965363682
Validation loss: 2.9021298262552646

Epoch: 5| Step: 8
Training loss: 3.183425243575402
Validation loss: 2.9012147417293437

Epoch: 5| Step: 9
Training loss: 3.3117682170480633
Validation loss: 2.9028394784159732

Epoch: 5| Step: 10
Training loss: 3.333500492355107
Validation loss: 2.8988601751845833

Epoch: 385| Step: 0
Training loss: 3.246857811420606
Validation loss: 2.8993290390554667

Epoch: 5| Step: 1
Training loss: 2.9210308303851478
Validation loss: 2.9017973792035363

Epoch: 5| Step: 2
Training loss: 2.598422885287091
Validation loss: 2.898062028892221

Epoch: 5| Step: 3
Training loss: 3.5935751167536454
Validation loss: 2.8995282378186698

Epoch: 5| Step: 4
Training loss: 3.4090893311930386
Validation loss: 2.9110508085289006

Epoch: 5| Step: 5
Training loss: 2.9710539862042946
Validation loss: 2.9001517619987736

Epoch: 5| Step: 6
Training loss: 3.24601163427462
Validation loss: 2.9017966141214875

Epoch: 5| Step: 7
Training loss: 3.6076987861961793
Validation loss: 2.901485552682971

Epoch: 5| Step: 8
Training loss: 3.407535135559609
Validation loss: 2.902974668645003

Epoch: 5| Step: 9
Training loss: 3.123094969874745
Validation loss: 2.9141350008896905

Epoch: 5| Step: 10
Training loss: 2.75977322738691
Validation loss: 2.904705784541256

Epoch: 386| Step: 0
Training loss: 2.968263285040815
Validation loss: 2.900630113521288

Epoch: 5| Step: 1
Training loss: 3.2444147388050575
Validation loss: 2.901365671246387

Epoch: 5| Step: 2
Training loss: 3.1240724331399363
Validation loss: 2.900693393600613

Epoch: 5| Step: 3
Training loss: 3.15588950940635
Validation loss: 2.9050936851413525

Epoch: 5| Step: 4
Training loss: 3.3698576852423043
Validation loss: 2.905046812687096

Epoch: 5| Step: 5
Training loss: 3.2294365226624677
Validation loss: 2.904694506005764

Epoch: 5| Step: 6
Training loss: 2.5354140140349264
Validation loss: 2.9007574836125425

Epoch: 5| Step: 7
Training loss: 3.4155736586053007
Validation loss: 2.904455660663906

Epoch: 5| Step: 8
Training loss: 3.4008018950473886
Validation loss: 2.9029669379058243

Epoch: 5| Step: 9
Training loss: 3.355105219411933
Validation loss: 2.898002547430598

Epoch: 5| Step: 10
Training loss: 3.167608689849761
Validation loss: 2.8976840761518585

Epoch: 387| Step: 0
Training loss: 3.165254043580134
Validation loss: 2.900169968141462

Epoch: 5| Step: 1
Training loss: 4.12746240350339
Validation loss: 2.899242644306687

Epoch: 5| Step: 2
Training loss: 3.250664569692376
Validation loss: 2.897851729384033

Epoch: 5| Step: 3
Training loss: 2.7217115736381183
Validation loss: 2.898313760665943

Epoch: 5| Step: 4
Training loss: 3.520944055625803
Validation loss: 2.895871104993495

Epoch: 5| Step: 5
Training loss: 2.393523111372454
Validation loss: 2.898804743753606

Epoch: 5| Step: 6
Training loss: 3.0610097256405946
Validation loss: 2.8979579364178183

Epoch: 5| Step: 7
Training loss: 2.9793510291045706
Validation loss: 2.900365425045412

Epoch: 5| Step: 8
Training loss: 2.807910650423934
Validation loss: 2.9082875628586233

Epoch: 5| Step: 9
Training loss: 3.4884839655805777
Validation loss: 2.9072405286777245

Epoch: 5| Step: 10
Training loss: 3.269300810464929
Validation loss: 2.9061315668722085

Epoch: 388| Step: 0
Training loss: 2.54516075810683
Validation loss: 2.9052069043918634

Epoch: 5| Step: 1
Training loss: 3.5103541216763747
Validation loss: 2.905293243994223

Epoch: 5| Step: 2
Training loss: 3.567441223986273
Validation loss: 2.909925218997097

Epoch: 5| Step: 3
Training loss: 3.4568643475776875
Validation loss: 2.9020647586083523

Epoch: 5| Step: 4
Training loss: 3.2984771451460415
Validation loss: 2.901776665375168

Epoch: 5| Step: 5
Training loss: 3.6699092716571107
Validation loss: 2.8988370340021143

Epoch: 5| Step: 6
Training loss: 2.9261218536098
Validation loss: 2.9003267628865648

Epoch: 5| Step: 7
Training loss: 2.5982259713585707
Validation loss: 2.9055575404689167

Epoch: 5| Step: 8
Training loss: 2.860183351414894
Validation loss: 2.898253189301909

Epoch: 5| Step: 9
Training loss: 3.1310631488778284
Validation loss: 2.8953173607006235

Epoch: 5| Step: 10
Training loss: 3.2874266119478426
Validation loss: 2.893349708042769

Epoch: 389| Step: 0
Training loss: 2.9152790220016755
Validation loss: 2.8951767125151546

Epoch: 5| Step: 1
Training loss: 3.080913384487601
Validation loss: 2.895156234676012

Epoch: 5| Step: 2
Training loss: 3.4595609730368486
Validation loss: 2.8935710391584237

Epoch: 5| Step: 3
Training loss: 3.1495845399596796
Validation loss: 2.895872725045245

Epoch: 5| Step: 4
Training loss: 3.427779725038321
Validation loss: 2.8954937029622774

Epoch: 5| Step: 5
Training loss: 2.5079717377586697
Validation loss: 2.8936508451951646

Epoch: 5| Step: 6
Training loss: 3.7325728788625825
Validation loss: 2.893843932359122

Epoch: 5| Step: 7
Training loss: 3.7014409996564837
Validation loss: 2.8942633358400043

Epoch: 5| Step: 8
Training loss: 2.687942645857503
Validation loss: 2.8938242494865554

Epoch: 5| Step: 9
Training loss: 3.118254897087544
Validation loss: 2.8967919317107507

Epoch: 5| Step: 10
Training loss: 3.0166994068483683
Validation loss: 2.8968008435767376

Epoch: 390| Step: 0
Training loss: 3.7161076237889064
Validation loss: 2.8943236860050447

Epoch: 5| Step: 1
Training loss: 1.8413653712697746
Validation loss: 2.892918141379848

Epoch: 5| Step: 2
Training loss: 3.6013051104474827
Validation loss: 2.8981851739299196

Epoch: 5| Step: 3
Training loss: 3.5752824044892715
Validation loss: 2.893223652863435

Epoch: 5| Step: 4
Training loss: 3.1378986424548234
Validation loss: 2.90219671125105

Epoch: 5| Step: 5
Training loss: 3.306473197686478
Validation loss: 2.911123669750223

Epoch: 5| Step: 6
Training loss: 3.432557454138875
Validation loss: 2.902924687824979

Epoch: 5| Step: 7
Training loss: 2.844315692683137
Validation loss: 2.9011040561534878

Epoch: 5| Step: 8
Training loss: 3.182360975610617
Validation loss: 2.905225072237365

Epoch: 5| Step: 9
Training loss: 2.9482074140359864
Validation loss: 2.8949690885326516

Epoch: 5| Step: 10
Training loss: 3.0045678014216692
Validation loss: 2.898102012769797

Epoch: 391| Step: 0
Training loss: 2.806999847210974
Validation loss: 2.897796062799212

Epoch: 5| Step: 1
Training loss: 3.085230029168934
Validation loss: 2.893926018186069

Epoch: 5| Step: 2
Training loss: 3.50008473974914
Validation loss: 2.8940474789684956

Epoch: 5| Step: 3
Training loss: 3.3962077927028878
Validation loss: 2.894384495490917

Epoch: 5| Step: 4
Training loss: 3.5104671365220845
Validation loss: 2.8918900151561067

Epoch: 5| Step: 5
Training loss: 2.92404371752327
Validation loss: 2.8954520441863854

Epoch: 5| Step: 6
Training loss: 3.287792694638377
Validation loss: 2.8987227041040997

Epoch: 5| Step: 7
Training loss: 2.7543342420082606
Validation loss: 2.9019393964943427

Epoch: 5| Step: 8
Training loss: 2.8852644419998237
Validation loss: 2.8920058056843394

Epoch: 5| Step: 9
Training loss: 3.2787527117934303
Validation loss: 2.8892601597999534

Epoch: 5| Step: 10
Training loss: 3.4876437742069015
Validation loss: 2.8910834474648808

Epoch: 392| Step: 0
Training loss: 3.5720380290314893
Validation loss: 2.893645518836695

Epoch: 5| Step: 1
Training loss: 3.1333343756112604
Validation loss: 2.8970123520758064

Epoch: 5| Step: 2
Training loss: 3.58957980807606
Validation loss: 2.895297713522791

Epoch: 5| Step: 3
Training loss: 2.413194024858202
Validation loss: 2.8933836177065597

Epoch: 5| Step: 4
Training loss: 3.133633855516929
Validation loss: 2.8937483516151463

Epoch: 5| Step: 5
Training loss: 2.8992254209326043
Validation loss: 2.8919348926361828

Epoch: 5| Step: 6
Training loss: 3.7322657546005304
Validation loss: 2.8950935198391514

Epoch: 5| Step: 7
Training loss: 3.4198973353631286
Validation loss: 2.8937613711225283

Epoch: 5| Step: 8
Training loss: 2.953238994678958
Validation loss: 2.8935155533605625

Epoch: 5| Step: 9
Training loss: 2.9291249459896296
Validation loss: 2.89864057545864

Epoch: 5| Step: 10
Training loss: 2.9328804215546653
Validation loss: 2.8938002716016085

Epoch: 393| Step: 0
Training loss: 3.513024890276143
Validation loss: 2.898441869380121

Epoch: 5| Step: 1
Training loss: 2.7986902920418046
Validation loss: 2.898200807735099

Epoch: 5| Step: 2
Training loss: 3.012585941845782
Validation loss: 2.891833901369457

Epoch: 5| Step: 3
Training loss: 2.2992367182815987
Validation loss: 2.889534897418312

Epoch: 5| Step: 4
Training loss: 3.202034815906953
Validation loss: 2.8905327682170467

Epoch: 5| Step: 5
Training loss: 2.67770988959561
Validation loss: 2.8892555972995804

Epoch: 5| Step: 6
Training loss: 3.279798059294721
Validation loss: 2.8928332380709234

Epoch: 5| Step: 7
Training loss: 3.4971643950273723
Validation loss: 2.885490460664772

Epoch: 5| Step: 8
Training loss: 3.377782875260751
Validation loss: 2.886946104042027

Epoch: 5| Step: 9
Training loss: 3.791838142513923
Validation loss: 2.8865974808537627

Epoch: 5| Step: 10
Training loss: 3.2458294739086107
Validation loss: 2.8924146039625542

Epoch: 394| Step: 0
Training loss: 2.947393436074764
Validation loss: 2.887351348840619

Epoch: 5| Step: 1
Training loss: 2.6543656790084422
Validation loss: 2.8865812060363027

Epoch: 5| Step: 2
Training loss: 2.816903968460639
Validation loss: 2.8845471448060165

Epoch: 5| Step: 3
Training loss: 3.537777564276663
Validation loss: 2.8843053262964675

Epoch: 5| Step: 4
Training loss: 3.2075245485979367
Validation loss: 2.8859838669595415

Epoch: 5| Step: 5
Training loss: 3.119208500552965
Validation loss: 2.8886063710793075

Epoch: 5| Step: 6
Training loss: 3.537539931432505
Validation loss: 2.8861841262350976

Epoch: 5| Step: 7
Training loss: 2.824547881685031
Validation loss: 2.890393622089265

Epoch: 5| Step: 8
Training loss: 3.4228971165388766
Validation loss: 2.8901999522750366

Epoch: 5| Step: 9
Training loss: 3.7344181585012604
Validation loss: 2.890316075715606

Epoch: 5| Step: 10
Training loss: 2.960805442099632
Validation loss: 2.8921128248483825

Epoch: 395| Step: 0
Training loss: 3.786936873569378
Validation loss: 2.886844646973271

Epoch: 5| Step: 1
Training loss: 3.8272545895427794
Validation loss: 2.889584470168552

Epoch: 5| Step: 2
Training loss: 2.645821238412521
Validation loss: 2.8897754878704696

Epoch: 5| Step: 3
Training loss: 3.2701451899875384
Validation loss: 2.8921562416109445

Epoch: 5| Step: 4
Training loss: 3.005388348155689
Validation loss: 2.888484720549983

Epoch: 5| Step: 5
Training loss: 3.281396045159436
Validation loss: 2.886032957958538

Epoch: 5| Step: 6
Training loss: 3.014418919176312
Validation loss: 2.886669354501355

Epoch: 5| Step: 7
Training loss: 3.294682067212439
Validation loss: 2.882306182281741

Epoch: 5| Step: 8
Training loss: 1.9653901995467997
Validation loss: 2.8875229811023564

Epoch: 5| Step: 9
Training loss: 3.15972376859485
Validation loss: 2.883529977093296

Epoch: 5| Step: 10
Training loss: 3.311856477235338
Validation loss: 2.884248120108998

Epoch: 396| Step: 0
Training loss: 2.8734511474152526
Validation loss: 2.8807605815596355

Epoch: 5| Step: 1
Training loss: 3.4466036844555594
Validation loss: 2.883226587846006

Epoch: 5| Step: 2
Training loss: 2.657153346221191
Validation loss: 2.8861443210061157

Epoch: 5| Step: 3
Training loss: 3.3174743729545164
Validation loss: 2.8834054886538905

Epoch: 5| Step: 4
Training loss: 2.74710416044069
Validation loss: 2.8902852637833636

Epoch: 5| Step: 5
Training loss: 2.8777456027293864
Validation loss: 2.8843597342734304

Epoch: 5| Step: 6
Training loss: 3.3805043581203966
Validation loss: 2.8851343904353235

Epoch: 5| Step: 7
Training loss: 2.8702054057235906
Validation loss: 2.883007265413583

Epoch: 5| Step: 8
Training loss: 3.567981451490968
Validation loss: 2.884013470518687

Epoch: 5| Step: 9
Training loss: 3.594127469349157
Validation loss: 2.883243199026199

Epoch: 5| Step: 10
Training loss: 3.4725899277008274
Validation loss: 2.882257536576541

Epoch: 397| Step: 0
Training loss: 3.2424431022175493
Validation loss: 2.883660334829085

Epoch: 5| Step: 1
Training loss: 3.404420553861722
Validation loss: 2.8797882149888467

Epoch: 5| Step: 2
Training loss: 3.3987565515643743
Validation loss: 2.880908254323807

Epoch: 5| Step: 3
Training loss: 3.2200122321234144
Validation loss: 2.881620975281771

Epoch: 5| Step: 4
Training loss: 3.0331702688074795
Validation loss: 2.879496544175179

Epoch: 5| Step: 5
Training loss: 3.3915045515927176
Validation loss: 2.881373979433668

Epoch: 5| Step: 6
Training loss: 3.1944456533531076
Validation loss: 2.881094048342876

Epoch: 5| Step: 7
Training loss: 2.1478019745401062
Validation loss: 2.8837446894406704

Epoch: 5| Step: 8
Training loss: 3.309120181380074
Validation loss: 2.881581798288193

Epoch: 5| Step: 9
Training loss: 3.3321746401774326
Validation loss: 2.8801649637359215

Epoch: 5| Step: 10
Training loss: 3.0363145186760945
Validation loss: 2.8830137407389724

Epoch: 398| Step: 0
Training loss: 3.30197342329692
Validation loss: 2.883340001126708

Epoch: 5| Step: 1
Training loss: 3.1316867242089246
Validation loss: 2.887445407353661

Epoch: 5| Step: 2
Training loss: 3.3498425460934973
Validation loss: 2.8881915580061284

Epoch: 5| Step: 3
Training loss: 3.416899386288046
Validation loss: 2.880383820824771

Epoch: 5| Step: 4
Training loss: 3.4470889816197943
Validation loss: 2.8821116390095844

Epoch: 5| Step: 5
Training loss: 3.6438678493384447
Validation loss: 2.8815572781443555

Epoch: 5| Step: 6
Training loss: 3.218001343408545
Validation loss: 2.8795416967138605

Epoch: 5| Step: 7
Training loss: 3.0729728219456325
Validation loss: 2.8793522055024297

Epoch: 5| Step: 8
Training loss: 2.6648377663649474
Validation loss: 2.8781163543196855

Epoch: 5| Step: 9
Training loss: 2.992424938054035
Validation loss: 2.877584400627877

Epoch: 5| Step: 10
Training loss: 2.343661293894245
Validation loss: 2.877231364205817

Epoch: 399| Step: 0
Training loss: 3.1194249586668863
Validation loss: 2.875326613340497

Epoch: 5| Step: 1
Training loss: 3.214498730821666
Validation loss: 2.8780574262134992

Epoch: 5| Step: 2
Training loss: 3.269678693612027
Validation loss: 2.8763217179543537

Epoch: 5| Step: 3
Training loss: 2.967652931289854
Validation loss: 2.8778717800047215

Epoch: 5| Step: 4
Training loss: 2.574750414113338
Validation loss: 2.877998769476974

Epoch: 5| Step: 5
Training loss: 3.0471820383156945
Validation loss: 2.8761657127831812

Epoch: 5| Step: 6
Training loss: 3.6671431549732803
Validation loss: 2.8761443651185425

Epoch: 5| Step: 7
Training loss: 3.1992923788650307
Validation loss: 2.8780976042746853

Epoch: 5| Step: 8
Training loss: 3.0882185991621345
Validation loss: 2.8803758603462533

Epoch: 5| Step: 9
Training loss: 3.5553252937010926
Validation loss: 2.877591779054211

Epoch: 5| Step: 10
Training loss: 3.0331210624563933
Validation loss: 2.8792786756295787

Epoch: 400| Step: 0
Training loss: 3.3122489402205546
Validation loss: 2.8793189470545126

Epoch: 5| Step: 1
Training loss: 2.9433235718106947
Validation loss: 2.87525390424064

Epoch: 5| Step: 2
Training loss: 2.941626714015457
Validation loss: 2.8888696397619147

Epoch: 5| Step: 3
Training loss: 3.005259354200689
Validation loss: 2.876482459638451

Epoch: 5| Step: 4
Training loss: 2.957264899795254
Validation loss: 2.8758776138030755

Epoch: 5| Step: 5
Training loss: 3.5619905341749236
Validation loss: 2.8770109984120626

Epoch: 5| Step: 6
Training loss: 2.899100585108368
Validation loss: 2.8759220119719267

Epoch: 5| Step: 7
Training loss: 3.120218509945207
Validation loss: 2.8764258670269127

Epoch: 5| Step: 8
Training loss: 3.1934906258864313
Validation loss: 2.873773654798871

Epoch: 5| Step: 9
Training loss: 3.6307096568446076
Validation loss: 2.8747054417730675

Epoch: 5| Step: 10
Training loss: 3.2343394696776566
Validation loss: 2.876752875454625

Epoch: 401| Step: 0
Training loss: 3.512440099239363
Validation loss: 2.878835133605167

Epoch: 5| Step: 1
Training loss: 3.2409419965064536
Validation loss: 2.874637916238567

Epoch: 5| Step: 2
Training loss: 2.984550910279026
Validation loss: 2.8758704859281528

Epoch: 5| Step: 3
Training loss: 3.023746602820151
Validation loss: 2.8776290914005185

Epoch: 5| Step: 4
Training loss: 2.690872117234904
Validation loss: 2.877559582712846

Epoch: 5| Step: 5
Training loss: 3.1446116182470383
Validation loss: 2.8754371588915584

Epoch: 5| Step: 6
Training loss: 2.5798615127182094
Validation loss: 2.879359152030219

Epoch: 5| Step: 7
Training loss: 3.0455851636849385
Validation loss: 2.8812455727304713

Epoch: 5| Step: 8
Training loss: 3.663394696314986
Validation loss: 2.8796637909175797

Epoch: 5| Step: 9
Training loss: 3.2260880756499173
Validation loss: 2.8799933896820655

Epoch: 5| Step: 10
Training loss: 3.6245232630343738
Validation loss: 2.883601912084583

Epoch: 402| Step: 0
Training loss: 2.673366554161654
Validation loss: 2.873905471107279

Epoch: 5| Step: 1
Training loss: 3.1268241136136177
Validation loss: 2.8766744997358518

Epoch: 5| Step: 2
Training loss: 3.3435172597155267
Validation loss: 2.8756620439345517

Epoch: 5| Step: 3
Training loss: 2.9172883778943355
Validation loss: 2.871256902234982

Epoch: 5| Step: 4
Training loss: 3.5875749693158228
Validation loss: 2.8710573688696917

Epoch: 5| Step: 5
Training loss: 3.211493747914747
Validation loss: 2.8735301436690883

Epoch: 5| Step: 6
Training loss: 3.2585604973035873
Validation loss: 2.8735607320083822

Epoch: 5| Step: 7
Training loss: 3.349444522637969
Validation loss: 2.874460352488779

Epoch: 5| Step: 8
Training loss: 3.0693379571163417
Validation loss: 2.876309643605241

Epoch: 5| Step: 9
Training loss: 3.026655195133243
Validation loss: 2.8755388151787207

Epoch: 5| Step: 10
Training loss: 3.2129375234039137
Validation loss: 2.87536993941479

Epoch: 403| Step: 0
Training loss: 2.854907605601876
Validation loss: 2.8810305949380868

Epoch: 5| Step: 1
Training loss: 2.882616320708844
Validation loss: 2.881377557919594

Epoch: 5| Step: 2
Training loss: 2.9040349907671734
Validation loss: 2.87639402216416

Epoch: 5| Step: 3
Training loss: 3.3195153569761047
Validation loss: 2.875377125591921

Epoch: 5| Step: 4
Training loss: 3.676537722703909
Validation loss: 2.876821455464559

Epoch: 5| Step: 5
Training loss: 2.8660793397706827
Validation loss: 2.8772621706962354

Epoch: 5| Step: 6
Training loss: 3.1747717948061527
Validation loss: 2.882155170850438

Epoch: 5| Step: 7
Training loss: 3.113739171447669
Validation loss: 2.8805420654811433

Epoch: 5| Step: 8
Training loss: 3.508102167144582
Validation loss: 2.8811954872441747

Epoch: 5| Step: 9
Training loss: 2.9920450281233038
Validation loss: 2.8767128327845137

Epoch: 5| Step: 10
Training loss: 3.423525756088319
Validation loss: 2.8732811674918635

Epoch: 404| Step: 0
Training loss: 3.3426573206899346
Validation loss: 2.876846455299622

Epoch: 5| Step: 1
Training loss: 3.361688429447275
Validation loss: 2.8810759761440043

Epoch: 5| Step: 2
Training loss: 3.3738292500197122
Validation loss: 2.8703088067563574

Epoch: 5| Step: 3
Training loss: 3.0885528684330397
Validation loss: 2.875172034311119

Epoch: 5| Step: 4
Training loss: 3.395076238256546
Validation loss: 2.8712918857551117

Epoch: 5| Step: 5
Training loss: 3.32710056925501
Validation loss: 2.870953619755053

Epoch: 5| Step: 6
Training loss: 3.4052795987720286
Validation loss: 2.8730241746131777

Epoch: 5| Step: 7
Training loss: 2.9762013934707223
Validation loss: 2.8724250105114697

Epoch: 5| Step: 8
Training loss: 2.557866256605714
Validation loss: 2.875855577594371

Epoch: 5| Step: 9
Training loss: 2.7873856662173404
Validation loss: 2.8737367313037314

Epoch: 5| Step: 10
Training loss: 3.0613116080026064
Validation loss: 2.8700930624708083

Epoch: 405| Step: 0
Training loss: 3.481547487105161
Validation loss: 2.871292004504515

Epoch: 5| Step: 1
Training loss: 3.5319789707944578
Validation loss: 2.8697126356935208

Epoch: 5| Step: 2
Training loss: 3.0201707486014775
Validation loss: 2.8708480434045915

Epoch: 5| Step: 3
Training loss: 3.8096124939586673
Validation loss: 2.8707489768777923

Epoch: 5| Step: 4
Training loss: 3.0330649379440664
Validation loss: 2.873220645694916

Epoch: 5| Step: 5
Training loss: 2.566431704413817
Validation loss: 2.8725219308560073

Epoch: 5| Step: 6
Training loss: 2.823143212118431
Validation loss: 2.8729075414092122

Epoch: 5| Step: 7
Training loss: 2.31744248369235
Validation loss: 2.8691973729226423

Epoch: 5| Step: 8
Training loss: 3.00290840947746
Validation loss: 2.871905688949887

Epoch: 5| Step: 9
Training loss: 3.4209568411817934
Validation loss: 2.8692906979452166

Epoch: 5| Step: 10
Training loss: 3.534115464237549
Validation loss: 2.8652725962607772

Epoch: 406| Step: 0
Training loss: 2.970012195703404
Validation loss: 2.8685202337637645

Epoch: 5| Step: 1
Training loss: 2.7604559745628983
Validation loss: 2.8695613546155774

Epoch: 5| Step: 2
Training loss: 3.140901316164018
Validation loss: 2.8668941421381406

Epoch: 5| Step: 3
Training loss: 2.809530767720052
Validation loss: 2.868614662176016

Epoch: 5| Step: 4
Training loss: 3.6238523837123924
Validation loss: 2.8699424383493723

Epoch: 5| Step: 5
Training loss: 2.915112508235136
Validation loss: 2.869730882187216

Epoch: 5| Step: 6
Training loss: 3.3889551225731718
Validation loss: 2.870757689182591

Epoch: 5| Step: 7
Training loss: 2.961224786112449
Validation loss: 2.8659658248761337

Epoch: 5| Step: 8
Training loss: 3.3395661891244153
Validation loss: 2.8688439549546314

Epoch: 5| Step: 9
Training loss: 2.914166241555696
Validation loss: 2.870196723004137

Epoch: 5| Step: 10
Training loss: 3.925488027373381
Validation loss: 2.8647795817849526

Epoch: 407| Step: 0
Training loss: 3.0290561878009097
Validation loss: 2.871281193378016

Epoch: 5| Step: 1
Training loss: 2.7900219717493693
Validation loss: 2.8718729530680767

Epoch: 5| Step: 2
Training loss: 3.388615025639854
Validation loss: 2.877234084456701

Epoch: 5| Step: 3
Training loss: 2.9994469768697734
Validation loss: 2.8817824622158317

Epoch: 5| Step: 4
Training loss: 3.2425625136091187
Validation loss: 2.8797599762305626

Epoch: 5| Step: 5
Training loss: 3.515863707173797
Validation loss: 2.90035876925095

Epoch: 5| Step: 6
Training loss: 2.9080722797336507
Validation loss: 2.89410576614462

Epoch: 5| Step: 7
Training loss: 3.7855328981690435
Validation loss: 2.892296459651639

Epoch: 5| Step: 8
Training loss: 2.9240937809862464
Validation loss: 2.8711003155912627

Epoch: 5| Step: 9
Training loss: 2.8434360875848235
Validation loss: 2.871740927411994

Epoch: 5| Step: 10
Training loss: 3.2754185765801966
Validation loss: 2.865585859322174

Epoch: 408| Step: 0
Training loss: 3.6184418647569134
Validation loss: 2.8619476808995734

Epoch: 5| Step: 1
Training loss: 2.9937931065651466
Validation loss: 2.866816986706797

Epoch: 5| Step: 2
Training loss: 3.8496854282029545
Validation loss: 2.86902974837737

Epoch: 5| Step: 3
Training loss: 2.9943170762993634
Validation loss: 2.864965086676277

Epoch: 5| Step: 4
Training loss: 2.589017111841425
Validation loss: 2.8711813649848903

Epoch: 5| Step: 5
Training loss: 3.3423978264085306
Validation loss: 2.8682956754113857

Epoch: 5| Step: 6
Training loss: 3.698499921909325
Validation loss: 2.863292509907227

Epoch: 5| Step: 7
Training loss: 2.576972380099684
Validation loss: 2.862210649230638

Epoch: 5| Step: 8
Training loss: 3.140155814125679
Validation loss: 2.871661788201338

Epoch: 5| Step: 9
Training loss: 2.7244305951929997
Validation loss: 2.8648714149278254

Epoch: 5| Step: 10
Training loss: 2.9413096296796915
Validation loss: 2.876017489870601

Epoch: 409| Step: 0
Training loss: 3.1008679743773424
Validation loss: 2.866666541012501

Epoch: 5| Step: 1
Training loss: 3.7611566521726556
Validation loss: 2.870712078777204

Epoch: 5| Step: 2
Training loss: 3.3089100800208477
Validation loss: 2.8731196702901043

Epoch: 5| Step: 3
Training loss: 2.7500915512104434
Validation loss: 2.873021213912712

Epoch: 5| Step: 4
Training loss: 2.7845402661051235
Validation loss: 2.8704694636066295

Epoch: 5| Step: 5
Training loss: 3.034324895443129
Validation loss: 2.866788148905359

Epoch: 5| Step: 6
Training loss: 3.592122646574338
Validation loss: 2.8683901773541143

Epoch: 5| Step: 7
Training loss: 3.510849213858894
Validation loss: 2.861527478510669

Epoch: 5| Step: 8
Training loss: 2.1707218319696215
Validation loss: 2.8700059305625487

Epoch: 5| Step: 9
Training loss: 3.200642586801098
Validation loss: 2.866271013415472

Epoch: 5| Step: 10
Training loss: 3.2220175740232166
Validation loss: 2.862097297983495

Epoch: 410| Step: 0
Training loss: 3.2497590782660275
Validation loss: 2.8632579188585514

Epoch: 5| Step: 1
Training loss: 3.542284578760756
Validation loss: 2.8623780515417496

Epoch: 5| Step: 2
Training loss: 3.09601302175223
Validation loss: 2.857603504655926

Epoch: 5| Step: 3
Training loss: 2.6745068710561233
Validation loss: 2.8616089611891047

Epoch: 5| Step: 4
Training loss: 3.2033852076093
Validation loss: 2.8615270923780187

Epoch: 5| Step: 5
Training loss: 2.9837129667466558
Validation loss: 2.8585214742434393

Epoch: 5| Step: 6
Training loss: 3.356834835195025
Validation loss: 2.865699489462411

Epoch: 5| Step: 7
Training loss: 3.183284590050032
Validation loss: 2.861299126154132

Epoch: 5| Step: 8
Training loss: 3.1734825533021733
Validation loss: 2.8629069582336952

Epoch: 5| Step: 9
Training loss: 3.212957558905749
Validation loss: 2.857316102816102

Epoch: 5| Step: 10
Training loss: 2.925372799322276
Validation loss: 2.8635760290168726

Epoch: 411| Step: 0
Training loss: 2.943090759454045
Validation loss: 2.8648157222748862

Epoch: 5| Step: 1
Training loss: 3.022902172710253
Validation loss: 2.861142189866477

Epoch: 5| Step: 2
Training loss: 2.6130761492290886
Validation loss: 2.8641632037489866

Epoch: 5| Step: 3
Training loss: 3.644788988491636
Validation loss: 2.85855062323667

Epoch: 5| Step: 4
Training loss: 3.243461781304387
Validation loss: 2.862225343809568

Epoch: 5| Step: 5
Training loss: 3.361310250624323
Validation loss: 2.8618353180573157

Epoch: 5| Step: 6
Training loss: 3.071020301982784
Validation loss: 2.86544302710157

Epoch: 5| Step: 7
Training loss: 3.328627427552179
Validation loss: 2.8585618963969157

Epoch: 5| Step: 8
Training loss: 2.6317661821112996
Validation loss: 2.8622024554877665

Epoch: 5| Step: 9
Training loss: 3.3099751476726302
Validation loss: 2.8645356067846848

Epoch: 5| Step: 10
Training loss: 3.403210464959673
Validation loss: 2.859936156186684

Epoch: 412| Step: 0
Training loss: 3.7987750287500806
Validation loss: 2.8721502580629177

Epoch: 5| Step: 1
Training loss: 3.0317173233819217
Validation loss: 2.862088027256197

Epoch: 5| Step: 2
Training loss: 3.2895846643298214
Validation loss: 2.867343998124215

Epoch: 5| Step: 3
Training loss: 3.12694702529074
Validation loss: 2.863722786764347

Epoch: 5| Step: 4
Training loss: 2.9007853332540106
Validation loss: 2.867628302997168

Epoch: 5| Step: 5
Training loss: 2.707340987899744
Validation loss: 2.871518833239236

Epoch: 5| Step: 6
Training loss: 3.1024191799902834
Validation loss: 2.8615261678096053

Epoch: 5| Step: 7
Training loss: 2.219106081475666
Validation loss: 2.8648241349452164

Epoch: 5| Step: 8
Training loss: 3.5501825312579385
Validation loss: 2.8620350482803687

Epoch: 5| Step: 9
Training loss: 3.272354711654395
Validation loss: 2.8687167192966903

Epoch: 5| Step: 10
Training loss: 3.456822689683426
Validation loss: 2.8604992367122235

Epoch: 413| Step: 0
Training loss: 3.2749116259583118
Validation loss: 2.8638375417644566

Epoch: 5| Step: 1
Training loss: 2.6930104030290627
Validation loss: 2.8614066764747315

Epoch: 5| Step: 2
Training loss: 3.244411652397834
Validation loss: 2.860906715079807

Epoch: 5| Step: 3
Training loss: 3.4232747598581588
Validation loss: 2.8595174575411417

Epoch: 5| Step: 4
Training loss: 3.546628162012488
Validation loss: 2.857297236912693

Epoch: 5| Step: 5
Training loss: 2.995997460918089
Validation loss: 2.8675887864308014

Epoch: 5| Step: 6
Training loss: 2.969770236134797
Validation loss: 2.8625850212946595

Epoch: 5| Step: 7
Training loss: 3.345235904420731
Validation loss: 2.8664383905624233

Epoch: 5| Step: 8
Training loss: 3.149379541961974
Validation loss: 2.868193651575099

Epoch: 5| Step: 9
Training loss: 2.8533486820711293
Validation loss: 2.866523069527855

Epoch: 5| Step: 10
Training loss: 3.10777694045063
Validation loss: 2.861672657110899

Epoch: 414| Step: 0
Training loss: 3.0308579653463665
Validation loss: 2.860510188516787

Epoch: 5| Step: 1
Training loss: 3.132982054424303
Validation loss: 2.868502369231512

Epoch: 5| Step: 2
Training loss: 3.3117790157290745
Validation loss: 2.857030143653344

Epoch: 5| Step: 3
Training loss: 3.696863345001242
Validation loss: 2.8544220588181717

Epoch: 5| Step: 4
Training loss: 3.102427940792117
Validation loss: 2.854040067766398

Epoch: 5| Step: 5
Training loss: 3.068227899892495
Validation loss: 2.8599208160890526

Epoch: 5| Step: 6
Training loss: 3.0280301011276225
Validation loss: 2.854228765825444

Epoch: 5| Step: 7
Training loss: 3.2769926517370425
Validation loss: 2.8563632140146744

Epoch: 5| Step: 8
Training loss: 2.8641471022010854
Validation loss: 2.8553384043807557

Epoch: 5| Step: 9
Training loss: 3.222121315687889
Validation loss: 2.865070040496191

Epoch: 5| Step: 10
Training loss: 2.789902675394141
Validation loss: 2.8573601084176796

Epoch: 415| Step: 0
Training loss: 2.82613205634527
Validation loss: 2.8615807428154656

Epoch: 5| Step: 1
Training loss: 3.3313053319748027
Validation loss: 2.8557678984406984

Epoch: 5| Step: 2
Training loss: 3.505686636151833
Validation loss: 2.8556084478971298

Epoch: 5| Step: 3
Training loss: 2.994058765902359
Validation loss: 2.854432827370476

Epoch: 5| Step: 4
Training loss: 2.9710392206942204
Validation loss: 2.8557574266783194

Epoch: 5| Step: 5
Training loss: 3.3328551585225585
Validation loss: 2.8539775048873075

Epoch: 5| Step: 6
Training loss: 2.97974888018723
Validation loss: 2.854394303787522

Epoch: 5| Step: 7
Training loss: 3.274924002195136
Validation loss: 2.853186997391698

Epoch: 5| Step: 8
Training loss: 2.804161086131226
Validation loss: 2.854938163586926

Epoch: 5| Step: 9
Training loss: 3.373784729480959
Validation loss: 2.8564351097775234

Epoch: 5| Step: 10
Training loss: 3.2034477257390934
Validation loss: 2.8510014194253888

Epoch: 416| Step: 0
Training loss: 3.710490695758191
Validation loss: 2.852637310933776

Epoch: 5| Step: 1
Training loss: 2.830214766316175
Validation loss: 2.8536044912134098

Epoch: 5| Step: 2
Training loss: 3.3090700349425646
Validation loss: 2.852420095241803

Epoch: 5| Step: 3
Training loss: 3.125592747739097
Validation loss: 2.8540250633639634

Epoch: 5| Step: 4
Training loss: 3.6646534132134585
Validation loss: 2.8521383156194213

Epoch: 5| Step: 5
Training loss: 2.6708184545839484
Validation loss: 2.853767443147484

Epoch: 5| Step: 6
Training loss: 2.718053969812318
Validation loss: 2.8485254143751613

Epoch: 5| Step: 7
Training loss: 2.5511739758570626
Validation loss: 2.8547882009331964

Epoch: 5| Step: 8
Training loss: 3.367421719576505
Validation loss: 2.8586740525032517

Epoch: 5| Step: 9
Training loss: 3.2699321469141167
Validation loss: 2.8547128493546436

Epoch: 5| Step: 10
Training loss: 3.155784497067433
Validation loss: 2.8594556053290403

Epoch: 417| Step: 0
Training loss: 3.629218442235855
Validation loss: 2.8579809200899446

Epoch: 5| Step: 1
Training loss: 2.7742390078914423
Validation loss: 2.857210482838606

Epoch: 5| Step: 2
Training loss: 3.3525379246466174
Validation loss: 2.861976215441235

Epoch: 5| Step: 3
Training loss: 2.8340609308125515
Validation loss: 2.8575412019158506

Epoch: 5| Step: 4
Training loss: 3.746312426408754
Validation loss: 2.8559839385343277

Epoch: 5| Step: 5
Training loss: 3.0736742712917673
Validation loss: 2.8576978075672166

Epoch: 5| Step: 6
Training loss: 2.8252634988963066
Validation loss: 2.8530127379301624

Epoch: 5| Step: 7
Training loss: 2.8794065788628957
Validation loss: 2.8585197666567472

Epoch: 5| Step: 8
Training loss: 2.401269092394552
Validation loss: 2.8525616419111843

Epoch: 5| Step: 9
Training loss: 3.763536309263863
Validation loss: 2.8497957999133616

Epoch: 5| Step: 10
Training loss: 3.0339624912204046
Validation loss: 2.850415717387279

Epoch: 418| Step: 0
Training loss: 2.988113059502948
Validation loss: 2.8515407406904867

Epoch: 5| Step: 1
Training loss: 3.1778242570935493
Validation loss: 2.8500124564237743

Epoch: 5| Step: 2
Training loss: 3.416606592410049
Validation loss: 2.85263139574081

Epoch: 5| Step: 3
Training loss: 2.7952533474714403
Validation loss: 2.8525238039509784

Epoch: 5| Step: 4
Training loss: 3.6170236373268225
Validation loss: 2.853662447354749

Epoch: 5| Step: 5
Training loss: 3.204436838361743
Validation loss: 2.850870784125253

Epoch: 5| Step: 6
Training loss: 2.8245370772526863
Validation loss: 2.8530015309038568

Epoch: 5| Step: 7
Training loss: 3.2780504885515667
Validation loss: 2.8512635622031386

Epoch: 5| Step: 8
Training loss: 2.6450523865961775
Validation loss: 2.853041161454374

Epoch: 5| Step: 9
Training loss: 3.162582390356567
Validation loss: 2.848061552139348

Epoch: 5| Step: 10
Training loss: 3.481125209907104
Validation loss: 2.84807172725019

Epoch: 419| Step: 0
Training loss: 2.2583874033218185
Validation loss: 2.8511860656180583

Epoch: 5| Step: 1
Training loss: 3.5818821533855894
Validation loss: 2.8507292704081397

Epoch: 5| Step: 2
Training loss: 2.8669312074123208
Validation loss: 2.8517725830187346

Epoch: 5| Step: 3
Training loss: 2.7649657762282303
Validation loss: 2.863241036835327

Epoch: 5| Step: 4
Training loss: 3.4833239693645086
Validation loss: 2.8525788486613735

Epoch: 5| Step: 5
Training loss: 3.43985043710669
Validation loss: 2.8621764678756976

Epoch: 5| Step: 6
Training loss: 2.6593129169824463
Validation loss: 2.880465741984517

Epoch: 5| Step: 7
Training loss: 3.1043054093113622
Validation loss: 2.867627627138115

Epoch: 5| Step: 8
Training loss: 3.5019094163387066
Validation loss: 2.8777913314954793

Epoch: 5| Step: 9
Training loss: 3.1963118876648347
Validation loss: 2.879918298784446

Epoch: 5| Step: 10
Training loss: 3.4983708813599743
Validation loss: 2.8760888488612

Epoch: 420| Step: 0
Training loss: 3.328223141938013
Validation loss: 2.8689655804625755

Epoch: 5| Step: 1
Training loss: 2.777617235842638
Validation loss: 2.8718051377592384

Epoch: 5| Step: 2
Training loss: 2.942363851633647
Validation loss: 2.8664565040686867

Epoch: 5| Step: 3
Training loss: 2.730917614018571
Validation loss: 2.861277608437076

Epoch: 5| Step: 4
Training loss: 3.7349575976884615
Validation loss: 2.8497403964803882

Epoch: 5| Step: 5
Training loss: 2.5706290655941
Validation loss: 2.8510244282430737

Epoch: 5| Step: 6
Training loss: 2.9211674613865224
Validation loss: 2.857545460679651

Epoch: 5| Step: 7
Training loss: 3.1019900241103575
Validation loss: 2.8456386896387844

Epoch: 5| Step: 8
Training loss: 3.427313258720434
Validation loss: 2.8443432918906524

Epoch: 5| Step: 9
Training loss: 3.4265860957260856
Validation loss: 2.84437733153587

Epoch: 5| Step: 10
Training loss: 3.4795929120367073
Validation loss: 2.8465792503123164

Epoch: 421| Step: 0
Training loss: 2.6763647181205767
Validation loss: 2.8440627248757306

Epoch: 5| Step: 1
Training loss: 3.1486848114037933
Validation loss: 2.84506855546401

Epoch: 5| Step: 2
Training loss: 3.2289719717747376
Validation loss: 2.8432497938891603

Epoch: 5| Step: 3
Training loss: 3.5430204309902114
Validation loss: 2.8470518354497365

Epoch: 5| Step: 4
Training loss: 3.17550106149835
Validation loss: 2.8487463791261542

Epoch: 5| Step: 5
Training loss: 2.6872890300892074
Validation loss: 2.8478921614484243

Epoch: 5| Step: 6
Training loss: 3.4713464590427296
Validation loss: 2.8546129642279743

Epoch: 5| Step: 7
Training loss: 3.039361384975305
Validation loss: 2.8521732635391364

Epoch: 5| Step: 8
Training loss: 3.0131734261521252
Validation loss: 2.849869988827128

Epoch: 5| Step: 9
Training loss: 3.4273701618290793
Validation loss: 2.848245839870888

Epoch: 5| Step: 10
Training loss: 3.045452392246101
Validation loss: 2.8475416945825422

Epoch: 422| Step: 0
Training loss: 3.507481888651565
Validation loss: 2.8487256485195296

Epoch: 5| Step: 1
Training loss: 2.508100831756387
Validation loss: 2.847486170764569

Epoch: 5| Step: 2
Training loss: 3.4348375586867905
Validation loss: 2.847190163511333

Epoch: 5| Step: 3
Training loss: 3.211737243109158
Validation loss: 2.845083726944574

Epoch: 5| Step: 4
Training loss: 3.786430530192406
Validation loss: 2.846133180427752

Epoch: 5| Step: 5
Training loss: 3.1008263009687105
Validation loss: 2.841851464438512

Epoch: 5| Step: 6
Training loss: 3.5654068180501146
Validation loss: 2.839187217808092

Epoch: 5| Step: 7
Training loss: 3.187219046384134
Validation loss: 2.840121691859693

Epoch: 5| Step: 8
Training loss: 2.8947391409613865
Validation loss: 2.8422217704309083

Epoch: 5| Step: 9
Training loss: 2.2371708377410005
Validation loss: 2.8421996446593667

Epoch: 5| Step: 10
Training loss: 2.7163510316684207
Validation loss: 2.8433463734100526

Epoch: 423| Step: 0
Training loss: 3.5729204331684925
Validation loss: 2.8427788663891564

Epoch: 5| Step: 1
Training loss: 3.141894942539622
Validation loss: 2.84453949442877

Epoch: 5| Step: 2
Training loss: 2.9805097064682684
Validation loss: 2.8441197478249842

Epoch: 5| Step: 3
Training loss: 3.3650945190486623
Validation loss: 2.8439142034849634

Epoch: 5| Step: 4
Training loss: 3.154986289065595
Validation loss: 2.840560026312562

Epoch: 5| Step: 5
Training loss: 2.985612223348097
Validation loss: 2.8425977676606844

Epoch: 5| Step: 6
Training loss: 3.3960756710774396
Validation loss: 2.845633549089237

Epoch: 5| Step: 7
Training loss: 2.8637999602097155
Validation loss: 2.842927621132511

Epoch: 5| Step: 8
Training loss: 2.462713466628503
Validation loss: 2.8415074413513546

Epoch: 5| Step: 9
Training loss: 3.343576872434651
Validation loss: 2.8438333875277517

Epoch: 5| Step: 10
Training loss: 3.1462969069987254
Validation loss: 2.848136957272425

Epoch: 424| Step: 0
Training loss: 3.7209150919772545
Validation loss: 2.860147034971398

Epoch: 5| Step: 1
Training loss: 2.7871631812266395
Validation loss: 2.849487069054398

Epoch: 5| Step: 2
Training loss: 2.8092624255614473
Validation loss: 2.847202780038833

Epoch: 5| Step: 3
Training loss: 3.6614185546334848
Validation loss: 2.8433884502730984

Epoch: 5| Step: 4
Training loss: 3.1049246833254323
Validation loss: 2.8450838278652406

Epoch: 5| Step: 5
Training loss: 3.1286816081772653
Validation loss: 2.840815367180914

Epoch: 5| Step: 6
Training loss: 3.565230277008848
Validation loss: 2.8390196174411026

Epoch: 5| Step: 7
Training loss: 3.3142427862140216
Validation loss: 2.8395652311123025

Epoch: 5| Step: 8
Training loss: 2.3428006093086124
Validation loss: 2.8385765673382894

Epoch: 5| Step: 9
Training loss: 2.5219129557158144
Validation loss: 2.8409799162462575

Epoch: 5| Step: 10
Training loss: 3.3053093363496195
Validation loss: 2.837668747171454

Epoch: 425| Step: 0
Training loss: 2.841067715464554
Validation loss: 2.839074720802611

Epoch: 5| Step: 1
Training loss: 2.75212899073216
Validation loss: 2.8404285082590497

Epoch: 5| Step: 2
Training loss: 3.0554409024855222
Validation loss: 2.8442702279005916

Epoch: 5| Step: 3
Training loss: 3.0294553812395697
Validation loss: 2.8396155750959284

Epoch: 5| Step: 4
Training loss: 3.5345274982556427
Validation loss: 2.841176037042133

Epoch: 5| Step: 5
Training loss: 3.3886141813352384
Validation loss: 2.8479772469232256

Epoch: 5| Step: 6
Training loss: 3.0877294045911086
Validation loss: 2.8464917021525915

Epoch: 5| Step: 7
Training loss: 2.5537012278735105
Validation loss: 2.8466256328412154

Epoch: 5| Step: 8
Training loss: 3.3463623680083514
Validation loss: 2.8599168683290004

Epoch: 5| Step: 9
Training loss: 3.375769633383739
Validation loss: 2.8567401139761825

Epoch: 5| Step: 10
Training loss: 3.4463554758583745
Validation loss: 2.8523618532118835

Epoch: 426| Step: 0
Training loss: 2.475283897378163
Validation loss: 2.8571375729252693

Epoch: 5| Step: 1
Training loss: 3.4328743069154277
Validation loss: 2.8451487551549204

Epoch: 5| Step: 2
Training loss: 3.5713843942362242
Validation loss: 2.854844651350166

Epoch: 5| Step: 3
Training loss: 3.4146529675672777
Validation loss: 2.847431501181746

Epoch: 5| Step: 4
Training loss: 3.2268552485705104
Validation loss: 2.8462209584897327

Epoch: 5| Step: 5
Training loss: 3.471902050939565
Validation loss: 2.840628944030621

Epoch: 5| Step: 6
Training loss: 2.8791823442384668
Validation loss: 2.8448989108689653

Epoch: 5| Step: 7
Training loss: 3.152737617703697
Validation loss: 2.850739365852528

Epoch: 5| Step: 8
Training loss: 2.8730951716177695
Validation loss: 2.8483451328371485

Epoch: 5| Step: 9
Training loss: 2.7366605961027974
Validation loss: 2.8429818984976216

Epoch: 5| Step: 10
Training loss: 3.09629763120345
Validation loss: 2.843748247483453

Epoch: 427| Step: 0
Training loss: 3.3044172316252105
Validation loss: 2.845369755981669

Epoch: 5| Step: 1
Training loss: 2.5650721410827297
Validation loss: 2.8352985675353928

Epoch: 5| Step: 2
Training loss: 3.250952067673942
Validation loss: 2.8391288794939364

Epoch: 5| Step: 3
Training loss: 3.106944605573857
Validation loss: 2.8350875449977964

Epoch: 5| Step: 4
Training loss: 2.9963544311912327
Validation loss: 2.8398118785843525

Epoch: 5| Step: 5
Training loss: 3.323293985371744
Validation loss: 2.836744702931355

Epoch: 5| Step: 6
Training loss: 2.7725747069328324
Validation loss: 2.8341383352934812

Epoch: 5| Step: 7
Training loss: 3.7371708447502856
Validation loss: 2.8385086537827524

Epoch: 5| Step: 8
Training loss: 3.1784968665916
Validation loss: 2.8441635555932967

Epoch: 5| Step: 9
Training loss: 3.047890987709604
Validation loss: 2.841540549613171

Epoch: 5| Step: 10
Training loss: 3.079702370122411
Validation loss: 2.8425168759453494

Epoch: 428| Step: 0
Training loss: 3.2384199566003815
Validation loss: 2.845503250264625

Epoch: 5| Step: 1
Training loss: 3.588105919472761
Validation loss: 2.8484237579395284

Epoch: 5| Step: 2
Training loss: 3.236160890981302
Validation loss: 2.8442746372285606

Epoch: 5| Step: 3
Training loss: 2.9439933919210493
Validation loss: 2.8492913849068766

Epoch: 5| Step: 4
Training loss: 2.6333342355010343
Validation loss: 2.8388673365033403

Epoch: 5| Step: 5
Training loss: 2.6015842196270995
Validation loss: 2.8427084343142814

Epoch: 5| Step: 6
Training loss: 3.437130717469111
Validation loss: 2.8374060242232253

Epoch: 5| Step: 7
Training loss: 3.13571922557577
Validation loss: 2.8393850975552932

Epoch: 5| Step: 8
Training loss: 3.4607559053127726
Validation loss: 2.8386388103702

Epoch: 5| Step: 9
Training loss: 2.6680225461839338
Validation loss: 2.8375783420054965

Epoch: 5| Step: 10
Training loss: 3.37883724076025
Validation loss: 2.8352891214761176

Epoch: 429| Step: 0
Training loss: 2.8223599850413046
Validation loss: 2.8417671752636178

Epoch: 5| Step: 1
Training loss: 2.809353063919939
Validation loss: 2.841689127401849

Epoch: 5| Step: 2
Training loss: 2.5279570458903566
Validation loss: 2.8346801237573827

Epoch: 5| Step: 3
Training loss: 3.3561978241969057
Validation loss: 2.8452345488857493

Epoch: 5| Step: 4
Training loss: 3.203188416388238
Validation loss: 2.852032272879065

Epoch: 5| Step: 5
Training loss: 3.310071234728868
Validation loss: 2.840871380537972

Epoch: 5| Step: 6
Training loss: 2.7300293313710906
Validation loss: 2.838530521120692

Epoch: 5| Step: 7
Training loss: 3.161838380865839
Validation loss: 2.8402338134284517

Epoch: 5| Step: 8
Training loss: 3.6674199775437515
Validation loss: 2.8471554578677964

Epoch: 5| Step: 9
Training loss: 3.46683153591828
Validation loss: 2.8462470197265923

Epoch: 5| Step: 10
Training loss: 3.269887524224884
Validation loss: 2.8481524409471923

Epoch: 430| Step: 0
Training loss: 2.910040895364756
Validation loss: 2.8462031476488745

Epoch: 5| Step: 1
Training loss: 3.360721194206748
Validation loss: 2.8431655073970115

Epoch: 5| Step: 2
Training loss: 3.285605165197837
Validation loss: 2.842816384960312

Epoch: 5| Step: 3
Training loss: 3.124820398891685
Validation loss: 2.840631525152278

Epoch: 5| Step: 4
Training loss: 3.214374864946511
Validation loss: 2.8362191582241105

Epoch: 5| Step: 5
Training loss: 3.5941932736555935
Validation loss: 2.835839310327092

Epoch: 5| Step: 6
Training loss: 2.9862955514492313
Validation loss: 2.8297509519984416

Epoch: 5| Step: 7
Training loss: 3.2740214334577473
Validation loss: 2.8313761269154676

Epoch: 5| Step: 8
Training loss: 2.4033391611537387
Validation loss: 2.829846225658022

Epoch: 5| Step: 9
Training loss: 3.4871724620952587
Validation loss: 2.8310118296552083

Epoch: 5| Step: 10
Training loss: 2.5371718659608176
Validation loss: 2.8270376849783836

Epoch: 431| Step: 0
Training loss: 3.305162328060687
Validation loss: 2.8311513307904703

Epoch: 5| Step: 1
Training loss: 3.563446722221936
Validation loss: 2.8289796295627934

Epoch: 5| Step: 2
Training loss: 2.5550428604144173
Validation loss: 2.8278340854203314

Epoch: 5| Step: 3
Training loss: 2.75133464677818
Validation loss: 2.8320548872762177

Epoch: 5| Step: 4
Training loss: 3.3989761101112395
Validation loss: 2.8271424825789353

Epoch: 5| Step: 5
Training loss: 3.520063929410753
Validation loss: 2.828457715035333

Epoch: 5| Step: 6
Training loss: 3.2826304120598433
Validation loss: 2.828906602849818

Epoch: 5| Step: 7
Training loss: 2.971535430024291
Validation loss: 2.830399187120082

Epoch: 5| Step: 8
Training loss: 2.994010350129834
Validation loss: 2.8289730831171473

Epoch: 5| Step: 9
Training loss: 3.3258482976691655
Validation loss: 2.8271243892265128

Epoch: 5| Step: 10
Training loss: 2.4245352624180363
Validation loss: 2.8336679314131414

Epoch: 432| Step: 0
Training loss: 3.0770752951676936
Validation loss: 2.8330298145982966

Epoch: 5| Step: 1
Training loss: 3.51393229106356
Validation loss: 2.8386736752281707

Epoch: 5| Step: 2
Training loss: 2.681447688286514
Validation loss: 2.845255382416602

Epoch: 5| Step: 3
Training loss: 2.6546542591620583
Validation loss: 2.8342624392002604

Epoch: 5| Step: 4
Training loss: 3.174222932174823
Validation loss: 2.842944630093504

Epoch: 5| Step: 5
Training loss: 3.64578915523829
Validation loss: 2.8331835512337844

Epoch: 5| Step: 6
Training loss: 3.2640263052796645
Validation loss: 2.842265617374378

Epoch: 5| Step: 7
Training loss: 3.465681213528404
Validation loss: 2.833611528672015

Epoch: 5| Step: 8
Training loss: 3.416684608102228
Validation loss: 2.83452322860915

Epoch: 5| Step: 9
Training loss: 2.3501113013024555
Validation loss: 2.8415782523415114

Epoch: 5| Step: 10
Training loss: 2.9067915545182212
Validation loss: 2.82618825730714

Epoch: 433| Step: 0
Training loss: 2.7645183008436502
Validation loss: 2.8315285997778923

Epoch: 5| Step: 1
Training loss: 2.8552586677806486
Validation loss: 2.827043630145094

Epoch: 5| Step: 2
Training loss: 3.0348836611928136
Validation loss: 2.828985813511378

Epoch: 5| Step: 3
Training loss: 3.4728344763214323
Validation loss: 2.830880241114682

Epoch: 5| Step: 4
Training loss: 3.2970795048206525
Validation loss: 2.8266031552013655

Epoch: 5| Step: 5
Training loss: 3.0911890084203537
Validation loss: 2.825327620410436

Epoch: 5| Step: 6
Training loss: 2.469648270216381
Validation loss: 2.8285551023425697

Epoch: 5| Step: 7
Training loss: 2.7814535002249405
Validation loss: 2.825492760227848

Epoch: 5| Step: 8
Training loss: 3.628875370941348
Validation loss: 2.832130247881528

Epoch: 5| Step: 9
Training loss: 3.320607466217913
Validation loss: 2.8309632026746723

Epoch: 5| Step: 10
Training loss: 3.54686720254856
Validation loss: 2.825584229824699

Epoch: 434| Step: 0
Training loss: 3.3945245073293218
Validation loss: 2.8356075648065526

Epoch: 5| Step: 1
Training loss: 3.0111583777170874
Validation loss: 2.8340031853247605

Epoch: 5| Step: 2
Training loss: 3.4088223045187
Validation loss: 2.8343734774310883

Epoch: 5| Step: 3
Training loss: 2.680440724559071
Validation loss: 2.8356199580267822

Epoch: 5| Step: 4
Training loss: 2.379374641195981
Validation loss: 2.8374504181154427

Epoch: 5| Step: 5
Training loss: 3.5408766519888277
Validation loss: 2.840190404485488

Epoch: 5| Step: 6
Training loss: 3.2514700865914516
Validation loss: 2.839298151928009

Epoch: 5| Step: 7
Training loss: 3.236777330255626
Validation loss: 2.8368893207484027

Epoch: 5| Step: 8
Training loss: 2.9447396528258327
Validation loss: 2.8404329452119543

Epoch: 5| Step: 9
Training loss: 3.059698263513106
Validation loss: 2.8395068491022304

Epoch: 5| Step: 10
Training loss: 3.325331110709069
Validation loss: 2.8305689453754845

Epoch: 435| Step: 0
Training loss: 3.43572508331859
Validation loss: 2.830102746939719

Epoch: 5| Step: 1
Training loss: 3.100421224709617
Validation loss: 2.8274983439415213

Epoch: 5| Step: 2
Training loss: 3.3005454797453084
Validation loss: 2.8264079379553886

Epoch: 5| Step: 3
Training loss: 2.8200338548291954
Validation loss: 2.831448547591726

Epoch: 5| Step: 4
Training loss: 3.488609307082256
Validation loss: 2.8324528930130897

Epoch: 5| Step: 5
Training loss: 3.2126267345084334
Validation loss: 2.8371115947715153

Epoch: 5| Step: 6
Training loss: 2.933120059438593
Validation loss: 2.831795452119037

Epoch: 5| Step: 7
Training loss: 3.4601672415473703
Validation loss: 2.8363710182434003

Epoch: 5| Step: 8
Training loss: 2.450919550944632
Validation loss: 2.837827127022073

Epoch: 5| Step: 9
Training loss: 2.8976361999887685
Validation loss: 2.839770637949214

Epoch: 5| Step: 10
Training loss: 3.09707847873679
Validation loss: 2.8421327079652685

Epoch: 436| Step: 0
Training loss: 2.9156543791538803
Validation loss: 2.837837518600882

Epoch: 5| Step: 1
Training loss: 3.412011829154471
Validation loss: 2.8385027597242174

Epoch: 5| Step: 2
Training loss: 3.4972622927093053
Validation loss: 2.8303168965138847

Epoch: 5| Step: 3
Training loss: 3.219340890515968
Validation loss: 2.824867723718396

Epoch: 5| Step: 4
Training loss: 2.799791318065176
Validation loss: 2.821347384425255

Epoch: 5| Step: 5
Training loss: 2.9121707779303643
Validation loss: 2.82826232486105

Epoch: 5| Step: 6
Training loss: 2.7411277875258544
Validation loss: 2.819525372425274

Epoch: 5| Step: 7
Training loss: 3.530519257952564
Validation loss: 2.8204763546278078

Epoch: 5| Step: 8
Training loss: 2.814768236827107
Validation loss: 2.824198734384593

Epoch: 5| Step: 9
Training loss: 3.1584969255928512
Validation loss: 2.826095098224545

Epoch: 5| Step: 10
Training loss: 3.2830430717419907
Validation loss: 2.8317806856388525

Epoch: 437| Step: 0
Training loss: 3.557704709798724
Validation loss: 2.8282887654946243

Epoch: 5| Step: 1
Training loss: 2.916692206861298
Validation loss: 2.835758882608125

Epoch: 5| Step: 2
Training loss: 3.373534696874064
Validation loss: 2.8305089857213632

Epoch: 5| Step: 3
Training loss: 3.020468187735159
Validation loss: 2.8440370627783778

Epoch: 5| Step: 4
Training loss: 2.8198561365212003
Validation loss: 2.853133234943206

Epoch: 5| Step: 5
Training loss: 3.3224503400204277
Validation loss: 2.837376495372398

Epoch: 5| Step: 6
Training loss: 3.129736553232422
Validation loss: 2.8237731915268096

Epoch: 5| Step: 7
Training loss: 2.696619396982113
Validation loss: 2.8218995374738975

Epoch: 5| Step: 8
Training loss: 3.3468755926849383
Validation loss: 2.824127829854637

Epoch: 5| Step: 9
Training loss: 3.169725563612819
Validation loss: 2.8235871104191785

Epoch: 5| Step: 10
Training loss: 2.912768201799125
Validation loss: 2.8218693548656235

Epoch: 438| Step: 0
Training loss: 3.037019253586528
Validation loss: 2.818516906147478

Epoch: 5| Step: 1
Training loss: 3.254113162126331
Validation loss: 2.8199881567495777

Epoch: 5| Step: 2
Training loss: 3.273627009402857
Validation loss: 2.8224828243151743

Epoch: 5| Step: 3
Training loss: 3.0766974687394844
Validation loss: 2.8281277538869247

Epoch: 5| Step: 4
Training loss: 2.9167618508929074
Validation loss: 2.8283251801058675

Epoch: 5| Step: 5
Training loss: 3.273348932274388
Validation loss: 2.8264428947278266

Epoch: 5| Step: 6
Training loss: 3.687636162781678
Validation loss: 2.82940205352017

Epoch: 5| Step: 7
Training loss: 2.385334518772781
Validation loss: 2.8341924313766835

Epoch: 5| Step: 8
Training loss: 3.036526364610733
Validation loss: 2.837875860424095

Epoch: 5| Step: 9
Training loss: 3.1969027490986996
Validation loss: 2.8280266977151065

Epoch: 5| Step: 10
Training loss: 3.092191823963074
Validation loss: 2.8366576519726934

Epoch: 439| Step: 0
Training loss: 2.471302885455394
Validation loss: 2.8253046436867217

Epoch: 5| Step: 1
Training loss: 3.1834835103612815
Validation loss: 2.82560245824533

Epoch: 5| Step: 2
Training loss: 2.752280243599231
Validation loss: 2.8213064545252178

Epoch: 5| Step: 3
Training loss: 3.1380951214408617
Validation loss: 2.8231587792954898

Epoch: 5| Step: 4
Training loss: 2.890282852956225
Validation loss: 2.818876665730599

Epoch: 5| Step: 5
Training loss: 3.277336475241479
Validation loss: 2.8180393501235375

Epoch: 5| Step: 6
Training loss: 2.4701944302471164
Validation loss: 2.819672882731031

Epoch: 5| Step: 7
Training loss: 3.393350938128038
Validation loss: 2.8172430536420814

Epoch: 5| Step: 8
Training loss: 3.769649270537482
Validation loss: 2.816586850125145

Epoch: 5| Step: 9
Training loss: 3.490874519411765
Validation loss: 2.8184484710299187

Epoch: 5| Step: 10
Training loss: 3.2481239479449333
Validation loss: 2.8162578694835814

Epoch: 440| Step: 0
Training loss: 2.683735717394295
Validation loss: 2.8168899966997687

Epoch: 5| Step: 1
Training loss: 3.0592327205627905
Validation loss: 2.8150857776811025

Epoch: 5| Step: 2
Training loss: 3.045175087942095
Validation loss: 2.8180678225503923

Epoch: 5| Step: 3
Training loss: 3.315523603005257
Validation loss: 2.8179527002214693

Epoch: 5| Step: 4
Training loss: 3.1265428930427506
Validation loss: 2.8170336007453125

Epoch: 5| Step: 5
Training loss: 3.295027518034484
Validation loss: 2.8236954143911452

Epoch: 5| Step: 6
Training loss: 3.6143265485476173
Validation loss: 2.8196472777837958

Epoch: 5| Step: 7
Training loss: 3.307854183548843
Validation loss: 2.82083391942772

Epoch: 5| Step: 8
Training loss: 2.6784988302655894
Validation loss: 2.8203515645564745

Epoch: 5| Step: 9
Training loss: 2.8531066893943686
Validation loss: 2.8180516968831677

Epoch: 5| Step: 10
Training loss: 3.22854605012509
Validation loss: 2.826625116456551

Epoch: 441| Step: 0
Training loss: 3.3267937088472417
Validation loss: 2.819259682930769

Epoch: 5| Step: 1
Training loss: 3.5633717858928318
Validation loss: 2.822262269506437

Epoch: 5| Step: 2
Training loss: 2.585764438335461
Validation loss: 2.823049554798712

Epoch: 5| Step: 3
Training loss: 3.198886355690989
Validation loss: 2.822594442201989

Epoch: 5| Step: 4
Training loss: 2.5887249907902334
Validation loss: 2.8253578559043824

Epoch: 5| Step: 5
Training loss: 3.323090806820659
Validation loss: 2.8194815028091806

Epoch: 5| Step: 6
Training loss: 3.637233087244317
Validation loss: 2.8224213976258694

Epoch: 5| Step: 7
Training loss: 2.78428818281568
Validation loss: 2.8204733742156263

Epoch: 5| Step: 8
Training loss: 3.0814288847647924
Validation loss: 2.8204336150886307

Epoch: 5| Step: 9
Training loss: 3.0200817006156564
Validation loss: 2.81971031415971

Epoch: 5| Step: 10
Training loss: 2.953171341143925
Validation loss: 2.816515106805008

Epoch: 442| Step: 0
Training loss: 3.079893272334242
Validation loss: 2.8192375579078637

Epoch: 5| Step: 1
Training loss: 3.1595690810059724
Validation loss: 2.822186698083875

Epoch: 5| Step: 2
Training loss: 2.817455334448976
Validation loss: 2.822519814294299

Epoch: 5| Step: 3
Training loss: 3.620588446362968
Validation loss: 2.8204135089841365

Epoch: 5| Step: 4
Training loss: 3.1477816445262228
Validation loss: 2.8224367707730633

Epoch: 5| Step: 5
Training loss: 2.794347633427461
Validation loss: 2.8226873916739046

Epoch: 5| Step: 6
Training loss: 2.9377246527293717
Validation loss: 2.8333655801297666

Epoch: 5| Step: 7
Training loss: 3.1881022164914743
Validation loss: 2.824253775624047

Epoch: 5| Step: 8
Training loss: 3.0990965911199524
Validation loss: 2.8245933072270297

Epoch: 5| Step: 9
Training loss: 3.0999997908069172
Validation loss: 2.822791151966117

Epoch: 5| Step: 10
Training loss: 3.296442084793239
Validation loss: 2.8342115053490695

Epoch: 443| Step: 0
Training loss: 2.8994957978859026
Validation loss: 2.8219881792471866

Epoch: 5| Step: 1
Training loss: 2.4623956145028765
Validation loss: 2.8189270254253764

Epoch: 5| Step: 2
Training loss: 3.0021740665176937
Validation loss: 2.82443454654218

Epoch: 5| Step: 3
Training loss: 3.368063828151196
Validation loss: 2.813401646260242

Epoch: 5| Step: 4
Training loss: 3.389011966228324
Validation loss: 2.817030967060196

Epoch: 5| Step: 5
Training loss: 3.180330028802365
Validation loss: 2.8153579647745963

Epoch: 5| Step: 6
Training loss: 3.4895579019255596
Validation loss: 2.813231901876168

Epoch: 5| Step: 7
Training loss: 3.2380877576201983
Validation loss: 2.8139303109402025

Epoch: 5| Step: 8
Training loss: 3.2617330767836554
Validation loss: 2.812587970009604

Epoch: 5| Step: 9
Training loss: 3.0140156775397777
Validation loss: 2.8122240320809175

Epoch: 5| Step: 10
Training loss: 2.7684129359103604
Validation loss: 2.814374678567018

Epoch: 444| Step: 0
Training loss: 2.7224885514003736
Validation loss: 2.8182212000879785

Epoch: 5| Step: 1
Training loss: 3.526081725455995
Validation loss: 2.8178639715341816

Epoch: 5| Step: 2
Training loss: 3.1825518629188836
Validation loss: 2.8155160663130374

Epoch: 5| Step: 3
Training loss: 2.6287283079056816
Validation loss: 2.8180281768598623

Epoch: 5| Step: 4
Training loss: 2.3640413937631846
Validation loss: 2.8269691405471318

Epoch: 5| Step: 5
Training loss: 2.863213968982712
Validation loss: 2.822663924809567

Epoch: 5| Step: 6
Training loss: 3.7522545712778848
Validation loss: 2.8248384576714343

Epoch: 5| Step: 7
Training loss: 3.4883333311219147
Validation loss: 2.8336904540168946

Epoch: 5| Step: 8
Training loss: 2.85333213764534
Validation loss: 2.830052036253558

Epoch: 5| Step: 9
Training loss: 3.4539104966416017
Validation loss: 2.828068032555229

Epoch: 5| Step: 10
Training loss: 3.125063475917829
Validation loss: 2.8246456343240878

Epoch: 445| Step: 0
Training loss: 2.8704180486768687
Validation loss: 2.8207020523927198

Epoch: 5| Step: 1
Training loss: 2.86730092003613
Validation loss: 2.8104136787728944

Epoch: 5| Step: 2
Training loss: 3.224712146066342
Validation loss: 2.8141754455870633

Epoch: 5| Step: 3
Training loss: 3.5778729878927615
Validation loss: 2.816947766278328

Epoch: 5| Step: 4
Training loss: 2.6389069695996596
Validation loss: 2.8175832244379286

Epoch: 5| Step: 5
Training loss: 3.0405227565531683
Validation loss: 2.818705086422664

Epoch: 5| Step: 6
Training loss: 3.0549812663451354
Validation loss: 2.8209400398627205

Epoch: 5| Step: 7
Training loss: 3.241160181745183
Validation loss: 2.820149940330577

Epoch: 5| Step: 8
Training loss: 3.3630684354399683
Validation loss: 2.8155212481926952

Epoch: 5| Step: 9
Training loss: 3.3796955928626233
Validation loss: 2.817375977045574

Epoch: 5| Step: 10
Training loss: 2.8129389102511944
Validation loss: 2.808443560085881

Epoch: 446| Step: 0
Training loss: 2.9320677179944656
Validation loss: 2.8088347749903644

Epoch: 5| Step: 1
Training loss: 2.9679549909505205
Validation loss: 2.804975063638743

Epoch: 5| Step: 2
Training loss: 3.1882196249844883
Validation loss: 2.806916670585324

Epoch: 5| Step: 3
Training loss: 3.26223783645508
Validation loss: 2.808155912513877

Epoch: 5| Step: 4
Training loss: 2.92125674963952
Validation loss: 2.8054025130345144

Epoch: 5| Step: 5
Training loss: 3.456770133809248
Validation loss: 2.807474834041635

Epoch: 5| Step: 6
Training loss: 3.0412341990532745
Validation loss: 2.8088477134822507

Epoch: 5| Step: 7
Training loss: 2.974537238024683
Validation loss: 2.820002423160815

Epoch: 5| Step: 8
Training loss: 2.6847872682828777
Validation loss: 2.8164209396154214

Epoch: 5| Step: 9
Training loss: 3.1738918262838087
Validation loss: 2.8235213795184393

Epoch: 5| Step: 10
Training loss: 3.6554182361782184
Validation loss: 2.8309039586375953

Epoch: 447| Step: 0
Training loss: 3.12360518798749
Validation loss: 2.8312993110770974

Epoch: 5| Step: 1
Training loss: 2.758429525797515
Validation loss: 2.8293377017764647

Epoch: 5| Step: 2
Training loss: 3.162682955429219
Validation loss: 2.8151981004591744

Epoch: 5| Step: 3
Training loss: 3.3312795669932593
Validation loss: 2.807916466269226

Epoch: 5| Step: 4
Training loss: 3.3897267923005874
Validation loss: 2.8082302429386043

Epoch: 5| Step: 5
Training loss: 2.9592475194976227
Validation loss: 2.8098420311676904

Epoch: 5| Step: 6
Training loss: 2.9058332246941374
Validation loss: 2.8065909126099045

Epoch: 5| Step: 7
Training loss: 3.4874113392925516
Validation loss: 2.8067561875587836

Epoch: 5| Step: 8
Training loss: 2.8299841065516538
Validation loss: 2.805055904241153

Epoch: 5| Step: 9
Training loss: 3.1882335342392434
Validation loss: 2.810932449064226

Epoch: 5| Step: 10
Training loss: 3.0063081224180106
Validation loss: 2.8079477109386337

Epoch: 448| Step: 0
Training loss: 3.471211153114549
Validation loss: 2.806459597660031

Epoch: 5| Step: 1
Training loss: 3.036502338350106
Validation loss: 2.80586923476726

Epoch: 5| Step: 2
Training loss: 3.8182232532482314
Validation loss: 2.8043163779668365

Epoch: 5| Step: 3
Training loss: 3.554041944300278
Validation loss: 2.8040885558841224

Epoch: 5| Step: 4
Training loss: 2.661393246287188
Validation loss: 2.806720422031163

Epoch: 5| Step: 5
Training loss: 3.284548890422278
Validation loss: 2.8055002373648184

Epoch: 5| Step: 6
Training loss: 2.6667565290886626
Validation loss: 2.814285497292024

Epoch: 5| Step: 7
Training loss: 2.971272250402299
Validation loss: 2.8218371069134616

Epoch: 5| Step: 8
Training loss: 2.5566856665902056
Validation loss: 2.8254803080700843

Epoch: 5| Step: 9
Training loss: 3.0202323228009145
Validation loss: 2.8273355482059364

Epoch: 5| Step: 10
Training loss: 2.9217752857839145
Validation loss: 2.826218695853366

Epoch: 449| Step: 0
Training loss: 2.8820578148130207
Validation loss: 2.843965115006711

Epoch: 5| Step: 1
Training loss: 2.4245702697048843
Validation loss: 2.8242244024567236

Epoch: 5| Step: 2
Training loss: 3.5872397457983554
Validation loss: 2.8232981844752434

Epoch: 5| Step: 3
Training loss: 3.4968419132252557
Validation loss: 2.820298006999201

Epoch: 5| Step: 4
Training loss: 2.620830039389703
Validation loss: 2.821590796206544

Epoch: 5| Step: 5
Training loss: 3.079682861200765
Validation loss: 2.822679631772556

Epoch: 5| Step: 6
Training loss: 3.18743836586398
Validation loss: 2.815712951005439

Epoch: 5| Step: 7
Training loss: 3.059412743059926
Validation loss: 2.815437837073254

Epoch: 5| Step: 8
Training loss: 3.0665191435229575
Validation loss: 2.813875649030413

Epoch: 5| Step: 9
Training loss: 3.6114494670579003
Validation loss: 2.8109524314607057

Epoch: 5| Step: 10
Training loss: 2.9325617411196165
Validation loss: 2.811135124718872

Epoch: 450| Step: 0
Training loss: 2.8741201630108963
Validation loss: 2.808009914386534

Epoch: 5| Step: 1
Training loss: 2.9870928626578723
Validation loss: 2.8086067827058043

Epoch: 5| Step: 2
Training loss: 3.1988335867809643
Validation loss: 2.813617620057107

Epoch: 5| Step: 3
Training loss: 2.9596446896279245
Validation loss: 2.806662439202781

Epoch: 5| Step: 4
Training loss: 2.8300395407458634
Validation loss: 2.8079420348464907

Epoch: 5| Step: 5
Training loss: 3.1310668038935763
Validation loss: 2.813663381513569

Epoch: 5| Step: 6
Training loss: 3.2977854840970315
Validation loss: 2.801237711946404

Epoch: 5| Step: 7
Training loss: 3.0376161403979682
Validation loss: 2.8075545790559056

Epoch: 5| Step: 8
Training loss: 2.735861935271886
Validation loss: 2.8077245662320367

Epoch: 5| Step: 9
Training loss: 3.532859907882443
Validation loss: 2.812083334919364

Epoch: 5| Step: 10
Training loss: 3.5588069311746127
Validation loss: 2.8064381911221203

Testing loss: 3.0161659313391493
