Epoch: 1| Step: 0
Training loss: 5.226125291177206
Validation loss: 5.853906067397893

Epoch: 6| Step: 1
Training loss: 6.3692655015931905
Validation loss: 5.8508281043466654

Epoch: 6| Step: 2
Training loss: 6.011534094995467
Validation loss: 5.847881357769761

Epoch: 6| Step: 3
Training loss: 5.542918510827647
Validation loss: 5.844931406231113

Epoch: 6| Step: 4
Training loss: 6.164732689921242
Validation loss: 5.8420895822380965

Epoch: 6| Step: 5
Training loss: 5.493632184914629
Validation loss: 5.839292559867468

Epoch: 6| Step: 6
Training loss: 5.736498031723601
Validation loss: 5.836479292659587

Epoch: 6| Step: 7
Training loss: 6.3524810389596436
Validation loss: 5.833641725583098

Epoch: 6| Step: 8
Training loss: 5.987238027300789
Validation loss: 5.830662634868511

Epoch: 6| Step: 9
Training loss: 5.718168635600564
Validation loss: 5.827588321976585

Epoch: 6| Step: 10
Training loss: 5.106717319652314
Validation loss: 5.824440411376992

Epoch: 6| Step: 11
Training loss: 6.582161360453633
Validation loss: 5.821435438548257

Epoch: 6| Step: 12
Training loss: 6.029083969860181
Validation loss: 5.817860834324385

Epoch: 6| Step: 13
Training loss: 5.420203751116122
Validation loss: 5.814350078526564

Epoch: 2| Step: 0
Training loss: 4.890633190014109
Validation loss: 5.810510650215761

Epoch: 6| Step: 1
Training loss: 6.062070851031823
Validation loss: 5.8066550267615735

Epoch: 6| Step: 2
Training loss: 5.113367789565619
Validation loss: 5.802672821508278

Epoch: 6| Step: 3
Training loss: 5.170220332219063
Validation loss: 5.79831163622348

Epoch: 6| Step: 4
Training loss: 6.363467387643588
Validation loss: 5.793539500321621

Epoch: 6| Step: 5
Training loss: 6.782938522858866
Validation loss: 5.788718691977975

Epoch: 6| Step: 6
Training loss: 5.904770438749179
Validation loss: 5.783563314141147

Epoch: 6| Step: 7
Training loss: 5.202151279008282
Validation loss: 5.778453512619626

Epoch: 6| Step: 8
Training loss: 5.756609228068855
Validation loss: 5.773016530614051

Epoch: 6| Step: 9
Training loss: 6.696649584801425
Validation loss: 5.767278984992653

Epoch: 6| Step: 10
Training loss: 5.244744349559502
Validation loss: 5.760953712792674

Epoch: 6| Step: 11
Training loss: 5.408195718778786
Validation loss: 5.754892152263762

Epoch: 6| Step: 12
Training loss: 6.107307884389534
Validation loss: 5.747753465961088

Epoch: 6| Step: 13
Training loss: 6.572654207030468
Validation loss: 5.740981138937534

Epoch: 3| Step: 0
Training loss: 6.051296303329031
Validation loss: 5.732843356838652

Epoch: 6| Step: 1
Training loss: 6.029809018680261
Validation loss: 5.725643538670928

Epoch: 6| Step: 2
Training loss: 5.760084513997901
Validation loss: 5.71724822464207

Epoch: 6| Step: 3
Training loss: 6.08794043982266
Validation loss: 5.708088162286474

Epoch: 6| Step: 4
Training loss: 5.185236793341972
Validation loss: 5.699584408519834

Epoch: 6| Step: 5
Training loss: 5.702187489831377
Validation loss: 5.690277481584022

Epoch: 6| Step: 6
Training loss: 5.9064938126553175
Validation loss: 5.68022271656877

Epoch: 6| Step: 7
Training loss: 4.631572692583962
Validation loss: 5.66990068914018

Epoch: 6| Step: 8
Training loss: 5.396032125966984
Validation loss: 5.659761149330464

Epoch: 6| Step: 9
Training loss: 5.551059573643281
Validation loss: 5.649212376113161

Epoch: 6| Step: 10
Training loss: 5.562502743152414
Validation loss: 5.637940166739131

Epoch: 6| Step: 11
Training loss: 6.6071259840819785
Validation loss: 5.626791235184384

Epoch: 6| Step: 12
Training loss: 5.7306960775248745
Validation loss: 5.614022287659525

Epoch: 6| Step: 13
Training loss: 5.3289296725588455
Validation loss: 5.601617507434507

Epoch: 4| Step: 0
Training loss: 5.706102069721337
Validation loss: 5.588324514201473

Epoch: 6| Step: 1
Training loss: 4.63050473454889
Validation loss: 5.574908580128876

Epoch: 6| Step: 2
Training loss: 5.8921071421612
Validation loss: 5.561846447783469

Epoch: 6| Step: 3
Training loss: 4.272422656078499
Validation loss: 5.547964476384234

Epoch: 6| Step: 4
Training loss: 5.600523869670238
Validation loss: 5.535213547654206

Epoch: 6| Step: 5
Training loss: 5.697584999190275
Validation loss: 5.52107518649829

Epoch: 6| Step: 6
Training loss: 4.88266152110333
Validation loss: 5.507194994217225

Epoch: 6| Step: 7
Training loss: 5.6989690818771255
Validation loss: 5.492546510799092

Epoch: 6| Step: 8
Training loss: 5.878715801005704
Validation loss: 5.478421664704915

Epoch: 6| Step: 9
Training loss: 5.777469202914456
Validation loss: 5.463556203921849

Epoch: 6| Step: 10
Training loss: 5.884417189630685
Validation loss: 5.447837232167748

Epoch: 6| Step: 11
Training loss: 6.425788967510563
Validation loss: 5.431885990070052

Epoch: 6| Step: 12
Training loss: 5.491196956816855
Validation loss: 5.416399785259595

Epoch: 6| Step: 13
Training loss: 5.121367120611647
Validation loss: 5.401295509638283

Epoch: 5| Step: 0
Training loss: 6.380530557605159
Validation loss: 5.386055200296007

Epoch: 6| Step: 1
Training loss: 5.419808205452174
Validation loss: 5.368868691197737

Epoch: 6| Step: 2
Training loss: 5.269115705909828
Validation loss: 5.353973627790179

Epoch: 6| Step: 3
Training loss: 5.965819593146339
Validation loss: 5.336882148239472

Epoch: 6| Step: 4
Training loss: 4.554154379578838
Validation loss: 5.321686729038597

Epoch: 6| Step: 5
Training loss: 5.184386456495875
Validation loss: 5.304705242085206

Epoch: 6| Step: 6
Training loss: 3.6250347267329084
Validation loss: 5.288987810146724

Epoch: 6| Step: 7
Training loss: 5.35751568541409
Validation loss: 5.274561461607075

Epoch: 6| Step: 8
Training loss: 4.6327355106640375
Validation loss: 5.257467893473046

Epoch: 6| Step: 9
Training loss: 6.48795640696075
Validation loss: 5.242563812738946

Epoch: 6| Step: 10
Training loss: 6.012067738814471
Validation loss: 5.225211282030149

Epoch: 6| Step: 11
Training loss: 5.171125374948147
Validation loss: 5.209398865352444

Epoch: 6| Step: 12
Training loss: 5.4151203393641145
Validation loss: 5.193287325041355

Epoch: 6| Step: 13
Training loss: 3.6868669645406507
Validation loss: 5.1752327312085615

Epoch: 6| Step: 0
Training loss: 5.1410097482585515
Validation loss: 5.159070743119558

Epoch: 6| Step: 1
Training loss: 4.549937472071002
Validation loss: 5.14253280999363

Epoch: 6| Step: 2
Training loss: 5.4908042674362285
Validation loss: 5.125695018127145

Epoch: 6| Step: 3
Training loss: 4.646010436829213
Validation loss: 5.108108018716125

Epoch: 6| Step: 4
Training loss: 4.4834349175233905
Validation loss: 5.0913836445019935

Epoch: 6| Step: 5
Training loss: 5.506773505725415
Validation loss: 5.072899367885031

Epoch: 6| Step: 6
Training loss: 5.023473950101041
Validation loss: 5.056635182006772

Epoch: 6| Step: 7
Training loss: 4.749479968063979
Validation loss: 5.0383932697091165

Epoch: 6| Step: 8
Training loss: 4.847793958307947
Validation loss: 5.021170976726905

Epoch: 6| Step: 9
Training loss: 5.845228038872052
Validation loss: 5.0050354756007955

Epoch: 6| Step: 10
Training loss: 5.309682660004379
Validation loss: 4.989195000245546

Epoch: 6| Step: 11
Training loss: 5.706256163678386
Validation loss: 4.9724614867652575

Epoch: 6| Step: 12
Training loss: 5.489899811377694
Validation loss: 4.955836818078211

Epoch: 6| Step: 13
Training loss: 3.989569893889869
Validation loss: 4.938752235342347

Epoch: 7| Step: 0
Training loss: 4.577157500957796
Validation loss: 4.924389816437292

Epoch: 6| Step: 1
Training loss: 5.3293332159140805
Validation loss: 4.908717827334187

Epoch: 6| Step: 2
Training loss: 3.780515489094212
Validation loss: 4.893680066348822

Epoch: 6| Step: 3
Training loss: 4.69044910484868
Validation loss: 4.880813409656919

Epoch: 6| Step: 4
Training loss: 5.348466364576198
Validation loss: 4.867447136096612

Epoch: 6| Step: 5
Training loss: 5.2827908226365
Validation loss: 4.852669661926542

Epoch: 6| Step: 6
Training loss: 4.752375560818961
Validation loss: 4.8380312819372575

Epoch: 6| Step: 7
Training loss: 4.6975715775490094
Validation loss: 4.824925083176212

Epoch: 6| Step: 8
Training loss: 5.505733622521886
Validation loss: 4.812059597260981

Epoch: 6| Step: 9
Training loss: 3.958459925718651
Validation loss: 4.799011731529184

Epoch: 6| Step: 10
Training loss: 5.643515736395475
Validation loss: 4.78585989973017

Epoch: 6| Step: 11
Training loss: 5.455230568716718
Validation loss: 4.772249102636241

Epoch: 6| Step: 12
Training loss: 4.601082898261009
Validation loss: 4.759953336430958

Epoch: 6| Step: 13
Training loss: 4.603448089635077
Validation loss: 4.749739861610634

Epoch: 8| Step: 0
Training loss: 3.647823698702612
Validation loss: 4.736216942146411

Epoch: 6| Step: 1
Training loss: 3.1853756276778875
Validation loss: 4.724287721824589

Epoch: 6| Step: 2
Training loss: 5.385138066044031
Validation loss: 4.7148212957339855

Epoch: 6| Step: 3
Training loss: 5.397165769730189
Validation loss: 4.705131922656058

Epoch: 6| Step: 4
Training loss: 4.932735027083059
Validation loss: 4.6949306994353295

Epoch: 6| Step: 5
Training loss: 4.214967062969643
Validation loss: 4.683217543279007

Epoch: 6| Step: 6
Training loss: 5.229781683309364
Validation loss: 4.673107992408887

Epoch: 6| Step: 7
Training loss: 4.857117548644222
Validation loss: 4.660509179802437

Epoch: 6| Step: 8
Training loss: 5.342900615803783
Validation loss: 4.6493144439986684

Epoch: 6| Step: 9
Training loss: 4.282994270016268
Validation loss: 4.637192622795209

Epoch: 6| Step: 10
Training loss: 4.55664606662234
Validation loss: 4.623761050750055

Epoch: 6| Step: 11
Training loss: 5.313831835583007
Validation loss: 4.614177934474239

Epoch: 6| Step: 12
Training loss: 5.033985792064963
Validation loss: 4.600262243063975

Epoch: 6| Step: 13
Training loss: 4.329457432537737
Validation loss: 4.588465555531555

Epoch: 9| Step: 0
Training loss: 3.841823808568845
Validation loss: 4.576019213835828

Epoch: 6| Step: 1
Training loss: 4.0444599737025255
Validation loss: 4.5626795170544066

Epoch: 6| Step: 2
Training loss: 3.670957539968817
Validation loss: 4.547776243173574

Epoch: 6| Step: 3
Training loss: 4.627324525380038
Validation loss: 4.535746083051867

Epoch: 6| Step: 4
Training loss: 4.960390364144466
Validation loss: 4.521101723844404

Epoch: 6| Step: 5
Training loss: 4.334408822233643
Validation loss: 4.5086228920455635

Epoch: 6| Step: 6
Training loss: 3.5112297557818946
Validation loss: 4.496486034709773

Epoch: 6| Step: 7
Training loss: 4.414860962074924
Validation loss: 4.482800455138358

Epoch: 6| Step: 8
Training loss: 5.398848566284741
Validation loss: 4.4703248003770835

Epoch: 6| Step: 9
Training loss: 4.204664891301628
Validation loss: 4.457978549687771

Epoch: 6| Step: 10
Training loss: 4.818130568138525
Validation loss: 4.44394537194212

Epoch: 6| Step: 11
Training loss: 5.577653111605135
Validation loss: 4.433554020737482

Epoch: 6| Step: 12
Training loss: 5.187810681702779
Validation loss: 4.420190657118876

Epoch: 6| Step: 13
Training loss: 5.360108261438459
Validation loss: 4.408250622024085

Epoch: 10| Step: 0
Training loss: 4.103842837085034
Validation loss: 4.395298520794798

Epoch: 6| Step: 1
Training loss: 5.219850709614602
Validation loss: 4.384629390111238

Epoch: 6| Step: 2
Training loss: 4.239454087795316
Validation loss: 4.373879333974757

Epoch: 6| Step: 3
Training loss: 4.0162072854214905
Validation loss: 4.362914519533927

Epoch: 6| Step: 4
Training loss: 5.2158816558424625
Validation loss: 4.352611740821082

Epoch: 6| Step: 5
Training loss: 4.4587073956489505
Validation loss: 4.338470853521046

Epoch: 6| Step: 6
Training loss: 4.228493297068649
Validation loss: 4.328427961742591

Epoch: 6| Step: 7
Training loss: 3.758169811494852
Validation loss: 4.318284349872353

Epoch: 6| Step: 8
Training loss: 4.478317582434348
Validation loss: 4.31006107378509

Epoch: 6| Step: 9
Training loss: 3.8304730123752546
Validation loss: 4.2986310527818565

Epoch: 6| Step: 10
Training loss: 4.054320566850759
Validation loss: 4.288891588115599

Epoch: 6| Step: 11
Training loss: 4.909588692213329
Validation loss: 4.277789632523962

Epoch: 6| Step: 12
Training loss: 4.396447498873558
Validation loss: 4.270866539578687

Epoch: 6| Step: 13
Training loss: 5.322436565488812
Validation loss: 4.258376499260104

Epoch: 11| Step: 0
Training loss: 4.445714305558276
Validation loss: 4.254407733598052

Epoch: 6| Step: 1
Training loss: 4.721709277150046
Validation loss: 4.246701839789007

Epoch: 6| Step: 2
Training loss: 4.132421579603449
Validation loss: 4.236687291821581

Epoch: 6| Step: 3
Training loss: 5.254452951342422
Validation loss: 4.228943505737266

Epoch: 6| Step: 4
Training loss: 3.832143115045028
Validation loss: 4.218875895588678

Epoch: 6| Step: 5
Training loss: 4.197962430163409
Validation loss: 4.212733722954621

Epoch: 6| Step: 6
Training loss: 4.885470760780721
Validation loss: 4.207204602578969

Epoch: 6| Step: 7
Training loss: 3.7051227830317996
Validation loss: 4.198094197227819

Epoch: 6| Step: 8
Training loss: 4.396610619161474
Validation loss: 4.1939323781147895

Epoch: 6| Step: 9
Training loss: 4.226713449317519
Validation loss: 4.186330116080581

Epoch: 6| Step: 10
Training loss: 3.658001602414439
Validation loss: 4.179784892598507

Epoch: 6| Step: 11
Training loss: 4.087911387981791
Validation loss: 4.172855883918729

Epoch: 6| Step: 12
Training loss: 4.826848426122345
Validation loss: 4.168808234537492

Epoch: 6| Step: 13
Training loss: 3.6817659958759834
Validation loss: 4.166546667688559

Epoch: 12| Step: 0
Training loss: 4.243163950122265
Validation loss: 4.16595900812263

Epoch: 6| Step: 1
Training loss: 5.19357256901866
Validation loss: 4.1583989044102285

Epoch: 6| Step: 2
Training loss: 4.540052401202442
Validation loss: 4.150077413960475

Epoch: 6| Step: 3
Training loss: 4.258035356481425
Validation loss: 4.14677647678853

Epoch: 6| Step: 4
Training loss: 4.779475262940744
Validation loss: 4.139345889919701

Epoch: 6| Step: 5
Training loss: 4.03488752092528
Validation loss: 4.13468517156004

Epoch: 6| Step: 6
Training loss: 3.862818984405899
Validation loss: 4.129173983620649

Epoch: 6| Step: 7
Training loss: 3.4293493569070432
Validation loss: 4.122598634596797

Epoch: 6| Step: 8
Training loss: 4.68917816639768
Validation loss: 4.11650366664495

Epoch: 6| Step: 9
Training loss: 4.6237976985883265
Validation loss: 4.114454583858417

Epoch: 6| Step: 10
Training loss: 4.010315230767037
Validation loss: 4.109636395535991

Epoch: 6| Step: 11
Training loss: 3.8235239210132512
Validation loss: 4.110814454159149

Epoch: 6| Step: 12
Training loss: 3.6065356162959668
Validation loss: 4.104945681301273

Epoch: 6| Step: 13
Training loss: 4.268361314361346
Validation loss: 4.101538663405198

Epoch: 13| Step: 0
Training loss: 4.15396491312959
Validation loss: 4.099204975374584

Epoch: 6| Step: 1
Training loss: 4.754889531501979
Validation loss: 4.092304787798792

Epoch: 6| Step: 2
Training loss: 5.129817838055826
Validation loss: 4.085306310412208

Epoch: 6| Step: 3
Training loss: 3.0760779375538054
Validation loss: 4.083625980527496

Epoch: 6| Step: 4
Training loss: 4.660036531558939
Validation loss: 4.082527057603831

Epoch: 6| Step: 5
Training loss: 4.405750219259693
Validation loss: 4.079283102937628

Epoch: 6| Step: 6
Training loss: 4.602494202153803
Validation loss: 4.070085912973176

Epoch: 6| Step: 7
Training loss: 4.160744896734613
Validation loss: 4.067957902349671

Epoch: 6| Step: 8
Training loss: 3.598225336284362
Validation loss: 4.062579100085653

Epoch: 6| Step: 9
Training loss: 3.681212803599284
Validation loss: 4.057242799156301

Epoch: 6| Step: 10
Training loss: 3.901348242874842
Validation loss: 4.055669515108725

Epoch: 6| Step: 11
Training loss: 3.825369952892041
Validation loss: 4.052911136675095

Epoch: 6| Step: 12
Training loss: 4.561346456940553
Validation loss: 4.048779068379412

Epoch: 6| Step: 13
Training loss: 3.8912997599017136
Validation loss: 4.0440827660150065

Epoch: 14| Step: 0
Training loss: 4.213689637228485
Validation loss: 4.037081746504442

Epoch: 6| Step: 1
Training loss: 3.4875893584804722
Validation loss: 4.032564664115651

Epoch: 6| Step: 2
Training loss: 4.17990106054875
Validation loss: 4.027234861345805

Epoch: 6| Step: 3
Training loss: 4.988341663445832
Validation loss: 4.026960905410888

Epoch: 6| Step: 4
Training loss: 3.422693999360275
Validation loss: 4.024810488573159

Epoch: 6| Step: 5
Training loss: 3.9337389709880495
Validation loss: 4.022464074443897

Epoch: 6| Step: 6
Training loss: 3.573663853997691
Validation loss: 4.018625796707424

Epoch: 6| Step: 7
Training loss: 3.8340439483320607
Validation loss: 4.012895783695867

Epoch: 6| Step: 8
Training loss: 5.079827126092131
Validation loss: 4.008299715384957

Epoch: 6| Step: 9
Training loss: 3.861425187275899
Validation loss: 4.001813087965432

Epoch: 6| Step: 10
Training loss: 3.7446604543449546
Validation loss: 3.9988416383994156

Epoch: 6| Step: 11
Training loss: 4.360982618983498
Validation loss: 3.997035041579845

Epoch: 6| Step: 12
Training loss: 5.042997116375488
Validation loss: 3.995965731875157

Epoch: 6| Step: 13
Training loss: 4.03263937494653
Validation loss: 3.9906491466930714

Epoch: 15| Step: 0
Training loss: 3.764475793504048
Validation loss: 3.9870532279525936

Epoch: 6| Step: 1
Training loss: 3.460799031469216
Validation loss: 3.979491663110576

Epoch: 6| Step: 2
Training loss: 5.3799256222486695
Validation loss: 3.9764510706296097

Epoch: 6| Step: 3
Training loss: 4.1509994957798835
Validation loss: 3.9703818937108326

Epoch: 6| Step: 4
Training loss: 3.648280922513396
Validation loss: 3.966308382715314

Epoch: 6| Step: 5
Training loss: 3.579077448119651
Validation loss: 3.964601557275374

Epoch: 6| Step: 6
Training loss: 4.39417533280919
Validation loss: 3.963230068363167

Epoch: 6| Step: 7
Training loss: 4.372569689797828
Validation loss: 3.957454402903103

Epoch: 6| Step: 8
Training loss: 4.680202449430085
Validation loss: 3.9518745867280365

Epoch: 6| Step: 9
Training loss: 3.481296428048937
Validation loss: 3.949355535502777

Epoch: 6| Step: 10
Training loss: 3.645625793362771
Validation loss: 3.9409934942173033

Epoch: 6| Step: 11
Training loss: 4.667048075393815
Validation loss: 3.937423216993534

Epoch: 6| Step: 12
Training loss: 3.7617083556288113
Validation loss: 3.9348114152944555

Epoch: 6| Step: 13
Training loss: 4.067913029103931
Validation loss: 3.9283763477753264

Epoch: 16| Step: 0
Training loss: 4.68187610223401
Validation loss: 3.9248639169572574

Epoch: 6| Step: 1
Training loss: 4.27053673187241
Validation loss: 3.915512609193408

Epoch: 6| Step: 2
Training loss: 3.6597343861238807
Validation loss: 3.9118174842222047

Epoch: 6| Step: 3
Training loss: 4.613145637295493
Validation loss: 3.9089285145303716

Epoch: 6| Step: 4
Training loss: 3.39339070534561
Validation loss: 3.909755218630265

Epoch: 6| Step: 5
Training loss: 2.98942641711495
Validation loss: 3.900568443544104

Epoch: 6| Step: 6
Training loss: 4.4688148760587945
Validation loss: 3.8993282929195257

Epoch: 6| Step: 7
Training loss: 4.017108806371996
Validation loss: 3.897535178201843

Epoch: 6| Step: 8
Training loss: 4.16053424962583
Validation loss: 3.888119598530557

Epoch: 6| Step: 9
Training loss: 3.938925227822739
Validation loss: 3.8860937448638704

Epoch: 6| Step: 10
Training loss: 4.358742069798381
Validation loss: 3.882100734284031

Epoch: 6| Step: 11
Training loss: 4.072781741874141
Validation loss: 3.881279682990924

Epoch: 6| Step: 12
Training loss: 3.5392093585871875
Validation loss: 3.8863662333130145

Epoch: 6| Step: 13
Training loss: 4.405872951093987
Validation loss: 3.892877024400613

Epoch: 17| Step: 0
Training loss: 3.6776893843918965
Validation loss: 3.887686999788791

Epoch: 6| Step: 1
Training loss: 3.9617893724986764
Validation loss: 3.8636612237197734

Epoch: 6| Step: 2
Training loss: 3.9277658181470785
Validation loss: 3.8564084429724725

Epoch: 6| Step: 3
Training loss: 4.528703065861156
Validation loss: 3.8528168345227813

Epoch: 6| Step: 4
Training loss: 3.9026723118141597
Validation loss: 3.8474632180199158

Epoch: 6| Step: 5
Training loss: 3.7678427595872575
Validation loss: 3.8416818943904825

Epoch: 6| Step: 6
Training loss: 4.172228166011861
Validation loss: 3.835683529310424

Epoch: 6| Step: 7
Training loss: 3.12053468206417
Validation loss: 3.8342015811060195

Epoch: 6| Step: 8
Training loss: 3.727825214774585
Validation loss: 3.839401037830577

Epoch: 6| Step: 9
Training loss: 4.554208406406581
Validation loss: 3.8237627842271698

Epoch: 6| Step: 10
Training loss: 4.250896583679344
Validation loss: 3.820047746121665

Epoch: 6| Step: 11
Training loss: 4.35067833182614
Validation loss: 3.820998584300768

Epoch: 6| Step: 12
Training loss: 4.577499190642422
Validation loss: 3.8222208761536534

Epoch: 6| Step: 13
Training loss: 2.4932410425897165
Validation loss: 3.813870274353246

Epoch: 18| Step: 0
Training loss: 3.9056681695592124
Validation loss: 3.812774027029524

Epoch: 6| Step: 1
Training loss: 3.519555094952521
Validation loss: 3.8082717696300925

Epoch: 6| Step: 2
Training loss: 3.073823198127167
Validation loss: 3.804735493913686

Epoch: 6| Step: 3
Training loss: 3.663145947047444
Validation loss: 3.8008581318407497

Epoch: 6| Step: 4
Training loss: 3.3620374907446173
Validation loss: 3.797498590942105

Epoch: 6| Step: 5
Training loss: 3.797062245214155
Validation loss: 3.795839748636269

Epoch: 6| Step: 6
Training loss: 4.354651732857352
Validation loss: 3.7937023067333224

Epoch: 6| Step: 7
Training loss: 3.7413779002159244
Validation loss: 3.789184173230552

Epoch: 6| Step: 8
Training loss: 4.399003800411538
Validation loss: 3.7859028416105422

Epoch: 6| Step: 9
Training loss: 5.340895933507654
Validation loss: 3.7821818415191077

Epoch: 6| Step: 10
Training loss: 4.113802189456791
Validation loss: 3.782859717922441

Epoch: 6| Step: 11
Training loss: 3.4969613644977606
Validation loss: 3.7797018726318785

Epoch: 6| Step: 12
Training loss: 4.554474761862811
Validation loss: 3.7765491472444923

Epoch: 6| Step: 13
Training loss: 3.3558266996121224
Validation loss: 3.7741436951514604

Epoch: 19| Step: 0
Training loss: 3.6565890684793465
Validation loss: 3.774115186326005

Epoch: 6| Step: 1
Training loss: 3.8872487075884967
Validation loss: 3.771901041326651

Epoch: 6| Step: 2
Training loss: 4.146951240350403
Validation loss: 3.769445528448528

Epoch: 6| Step: 3
Training loss: 4.1327368110980265
Validation loss: 3.766793362995621

Epoch: 6| Step: 4
Training loss: 3.6185696888014194
Validation loss: 3.76624637011754

Epoch: 6| Step: 5
Training loss: 3.7495335606722366
Validation loss: 3.7633696456769394

Epoch: 6| Step: 6
Training loss: 4.4724882269203805
Validation loss: 3.7579614412221503

Epoch: 6| Step: 7
Training loss: 3.4394992909753053
Validation loss: 3.759692836909755

Epoch: 6| Step: 8
Training loss: 3.407563122663544
Validation loss: 3.7553935801530174

Epoch: 6| Step: 9
Training loss: 4.510411827078933
Validation loss: 3.7542794997399853

Epoch: 6| Step: 10
Training loss: 3.1082827696041218
Validation loss: 3.7525717445175224

Epoch: 6| Step: 11
Training loss: 4.264729723757323
Validation loss: 3.7526660110892816

Epoch: 6| Step: 12
Training loss: 4.095983696651795
Validation loss: 3.7504774070029376

Epoch: 6| Step: 13
Training loss: 4.634600186680709
Validation loss: 3.7483990044327276

Epoch: 20| Step: 0
Training loss: 3.6791492886563075
Validation loss: 3.7483671263434464

Epoch: 6| Step: 1
Training loss: 3.7550034522232463
Validation loss: 3.7466243795928618

Epoch: 6| Step: 2
Training loss: 3.406016630525246
Validation loss: 3.744119664679686

Epoch: 6| Step: 3
Training loss: 3.186462233408927
Validation loss: 3.7421573844336873

Epoch: 6| Step: 4
Training loss: 4.6177868655762655
Validation loss: 3.7395006446541057

Epoch: 6| Step: 5
Training loss: 4.093845511916571
Validation loss: 3.7387184109219014

Epoch: 6| Step: 6
Training loss: 4.456753935281646
Validation loss: 3.7347649132035143

Epoch: 6| Step: 7
Training loss: 3.395289293640854
Validation loss: 3.737040425877869

Epoch: 6| Step: 8
Training loss: 3.3908090849095553
Validation loss: 3.736255768191849

Epoch: 6| Step: 9
Training loss: 4.544073021490059
Validation loss: 3.7371433023779717

Epoch: 6| Step: 10
Training loss: 4.900227537516354
Validation loss: 3.7343247754751077

Epoch: 6| Step: 11
Training loss: 4.236971013632419
Validation loss: 3.7303181612759704

Epoch: 6| Step: 12
Training loss: 2.513325368715141
Validation loss: 3.7291376073001468

Epoch: 6| Step: 13
Training loss: 3.99365637345629
Validation loss: 3.7291726608260274

Epoch: 21| Step: 0
Training loss: 3.5285295117714255
Validation loss: 3.7265400883174467

Epoch: 6| Step: 1
Training loss: 4.160792571640498
Validation loss: 3.7281907528373055

Epoch: 6| Step: 2
Training loss: 4.053409676418461
Validation loss: 3.7271126962501313

Epoch: 6| Step: 3
Training loss: 3.3453257047774767
Validation loss: 3.725220240185098

Epoch: 6| Step: 4
Training loss: 3.7682817512996203
Validation loss: 3.7233806914486456

Epoch: 6| Step: 5
Training loss: 4.844830792349113
Validation loss: 3.7220582504003015

Epoch: 6| Step: 6
Training loss: 4.2805611828973245
Validation loss: 3.7192662894849273

Epoch: 6| Step: 7
Training loss: 3.2178604229991543
Validation loss: 3.720441753816867

Epoch: 6| Step: 8
Training loss: 4.65671777615708
Validation loss: 3.7181941246270855

Epoch: 6| Step: 9
Training loss: 4.10287739340008
Validation loss: 3.7178430289700235

Epoch: 6| Step: 10
Training loss: 3.7670260153880477
Validation loss: 3.718533163624656

Epoch: 6| Step: 11
Training loss: 3.2389654488200246
Validation loss: 3.7179936182398614

Epoch: 6| Step: 12
Training loss: 3.4995637349302364
Validation loss: 3.7134102945660437

Epoch: 6| Step: 13
Training loss: 3.698634519434113
Validation loss: 3.7152611613880375

Epoch: 22| Step: 0
Training loss: 3.87426972429727
Validation loss: 3.7115965230713686

Epoch: 6| Step: 1
Training loss: 2.777688650184848
Validation loss: 3.712359013205245

Epoch: 6| Step: 2
Training loss: 3.2015877361057
Validation loss: 3.7102131703256935

Epoch: 6| Step: 3
Training loss: 3.714856971051329
Validation loss: 3.710281190028744

Epoch: 6| Step: 4
Training loss: 4.063677103731736
Validation loss: 3.71035536616571

Epoch: 6| Step: 5
Training loss: 4.175030946902402
Validation loss: 3.7098760342139783

Epoch: 6| Step: 6
Training loss: 3.783145145883808
Validation loss: 3.7087141097051823

Epoch: 6| Step: 7
Training loss: 4.127424510170743
Validation loss: 3.706938186764177

Epoch: 6| Step: 8
Training loss: 3.79177199556263
Validation loss: 3.7047301306674085

Epoch: 6| Step: 9
Training loss: 4.491917238813142
Validation loss: 3.704837926103757

Epoch: 6| Step: 10
Training loss: 4.838411798229668
Validation loss: 3.7031029518460703

Epoch: 6| Step: 11
Training loss: 3.4279883831276905
Validation loss: 3.7011655316466374

Epoch: 6| Step: 12
Training loss: 3.7516559759185686
Validation loss: 3.7036852399190354

Epoch: 6| Step: 13
Training loss: 4.193170835523373
Validation loss: 3.703457556193852

Epoch: 23| Step: 0
Training loss: 3.2243495492213565
Validation loss: 3.701137225390693

Epoch: 6| Step: 1
Training loss: 3.861382460416895
Validation loss: 3.697963740066388

Epoch: 6| Step: 2
Training loss: 3.5941443185504336
Validation loss: 3.697062770081862

Epoch: 6| Step: 3
Training loss: 4.605785148694792
Validation loss: 3.692106131226573

Epoch: 6| Step: 4
Training loss: 4.167160513539821
Validation loss: 3.690725907655954

Epoch: 6| Step: 5
Training loss: 4.145193897309155
Validation loss: 3.684076348426648

Epoch: 6| Step: 6
Training loss: 3.407333341736465
Validation loss: 3.6773214866451047

Epoch: 6| Step: 7
Training loss: 2.8995814777786215
Validation loss: 3.6758691767330296

Epoch: 6| Step: 8
Training loss: 3.255140787059617
Validation loss: 3.6744015489685307

Epoch: 6| Step: 9
Training loss: 4.221960583884577
Validation loss: 3.6721301295398594

Epoch: 6| Step: 10
Training loss: 4.402267062747108
Validation loss: 3.670307769777232

Epoch: 6| Step: 11
Training loss: 3.6932218738864604
Validation loss: 3.6691092403435897

Epoch: 6| Step: 12
Training loss: 4.338435812487291
Validation loss: 3.666852788778602

Epoch: 6| Step: 13
Training loss: 3.9564761707326377
Validation loss: 3.6640044058027983

Epoch: 24| Step: 0
Training loss: 4.495440398336964
Validation loss: 3.6620340620055942

Epoch: 6| Step: 1
Training loss: 3.963492688525133
Validation loss: 3.660130199947678

Epoch: 6| Step: 2
Training loss: 4.044684446873486
Validation loss: 3.6612058277146087

Epoch: 6| Step: 3
Training loss: 2.862114599677912
Validation loss: 3.6586648086783624

Epoch: 6| Step: 4
Training loss: 4.333268507448113
Validation loss: 3.6573668790690483

Epoch: 6| Step: 5
Training loss: 4.188175887035093
Validation loss: 3.6556914626603074

Epoch: 6| Step: 6
Training loss: 3.596386017360241
Validation loss: 3.655593221296479

Epoch: 6| Step: 7
Training loss: 3.1576335631669297
Validation loss: 3.6535881056104826

Epoch: 6| Step: 8
Training loss: 3.968300741404431
Validation loss: 3.6513212948655536

Epoch: 6| Step: 9
Training loss: 4.341672112186309
Validation loss: 3.6505215608070554

Epoch: 6| Step: 10
Training loss: 3.1369908501026793
Validation loss: 3.6502129014344598

Epoch: 6| Step: 11
Training loss: 4.229294998902789
Validation loss: 3.648401147987564

Epoch: 6| Step: 12
Training loss: 3.4472957793475767
Validation loss: 3.647963610236298

Epoch: 6| Step: 13
Training loss: 3.491039112904579
Validation loss: 3.6480177159822813

Epoch: 25| Step: 0
Training loss: 2.7830337633503475
Validation loss: 3.646566409523009

Epoch: 6| Step: 1
Training loss: 3.7042945270476584
Validation loss: 3.64696467318583

Epoch: 6| Step: 2
Training loss: 4.010801988726623
Validation loss: 3.6434683014913767

Epoch: 6| Step: 3
Training loss: 3.991799053845183
Validation loss: 3.645108669471819

Epoch: 6| Step: 4
Training loss: 4.9810519725919455
Validation loss: 3.6429578565216802

Epoch: 6| Step: 5
Training loss: 3.7274058925075493
Validation loss: 3.641941475269958

Epoch: 6| Step: 6
Training loss: 4.420382945529927
Validation loss: 3.641779402202479

Epoch: 6| Step: 7
Training loss: 3.4506795517986975
Validation loss: 3.641759112819717

Epoch: 6| Step: 8
Training loss: 3.4976636718234997
Validation loss: 3.6399958883508186

Epoch: 6| Step: 9
Training loss: 3.545848546666024
Validation loss: 3.640625204211025

Epoch: 6| Step: 10
Training loss: 3.711535082435818
Validation loss: 3.642223339842651

Epoch: 6| Step: 11
Training loss: 3.4810043933186456
Validation loss: 3.6375869439503425

Epoch: 6| Step: 12
Training loss: 4.346777430412215
Validation loss: 3.6365608924863486

Epoch: 6| Step: 13
Training loss: 3.368930303670768
Validation loss: 3.6376698415860633

Epoch: 26| Step: 0
Training loss: 4.1501523369095334
Validation loss: 3.6350245270298864

Epoch: 6| Step: 1
Training loss: 2.6878626379156234
Validation loss: 3.635416698635045

Epoch: 6| Step: 2
Training loss: 2.946816624440451
Validation loss: 3.63418098790814

Epoch: 6| Step: 3
Training loss: 3.0139610957702168
Validation loss: 3.634101875090048

Epoch: 6| Step: 4
Training loss: 4.002693223262405
Validation loss: 3.632290620043574

Epoch: 6| Step: 5
Training loss: 3.748538813428348
Validation loss: 3.633643448476196

Epoch: 6| Step: 6
Training loss: 2.4477826886679264
Validation loss: 3.63169157509607

Epoch: 6| Step: 7
Training loss: 5.057925005566855
Validation loss: 3.6326039328826996

Epoch: 6| Step: 8
Training loss: 3.6406244760930417
Validation loss: 3.632370784393831

Epoch: 6| Step: 9
Training loss: 4.568690033191655
Validation loss: 3.631116228507913

Epoch: 6| Step: 10
Training loss: 4.139612153171662
Validation loss: 3.629878830604557

Epoch: 6| Step: 11
Training loss: 3.3496535050846643
Validation loss: 3.6292887272785705

Epoch: 6| Step: 12
Training loss: 4.569504051760184
Validation loss: 3.6292155884224497

Epoch: 6| Step: 13
Training loss: 4.52500811834292
Validation loss: 3.6281745724318624

Epoch: 27| Step: 0
Training loss: 3.611238601259891
Validation loss: 3.630010870696881

Epoch: 6| Step: 1
Training loss: 3.902640666491463
Validation loss: 3.6288049125785786

Epoch: 6| Step: 2
Training loss: 4.276081613159686
Validation loss: 3.630333074692026

Epoch: 6| Step: 3
Training loss: 4.285955585771173
Validation loss: 3.6279700858901953

Epoch: 6| Step: 4
Training loss: 2.548578733907832
Validation loss: 3.6257578079261936

Epoch: 6| Step: 5
Training loss: 3.6502383115126826
Validation loss: 3.627109857008114

Epoch: 6| Step: 6
Training loss: 3.700232297461307
Validation loss: 3.6279067230370052

Epoch: 6| Step: 7
Training loss: 3.996011175680332
Validation loss: 3.627019015129001

Epoch: 6| Step: 8
Training loss: 3.624206456111936
Validation loss: 3.6249347181598233

Epoch: 6| Step: 9
Training loss: 2.9334614364510587
Validation loss: 3.6255511358894963

Epoch: 6| Step: 10
Training loss: 3.7995490559491993
Validation loss: 3.624251696133204

Epoch: 6| Step: 11
Training loss: 4.5284661521897585
Validation loss: 3.6206698554236985

Epoch: 6| Step: 12
Training loss: 3.90307475928903
Validation loss: 3.6227615879631

Epoch: 6| Step: 13
Training loss: 4.574212286836275
Validation loss: 3.6219821499475575

Epoch: 28| Step: 0
Training loss: 3.8925359850955354
Validation loss: 3.620998653668452

Epoch: 6| Step: 1
Training loss: 3.2892761885935684
Validation loss: 3.6211331103148643

Epoch: 6| Step: 2
Training loss: 3.3400640403866926
Validation loss: 3.620017557214332

Epoch: 6| Step: 3
Training loss: 3.400074531635845
Validation loss: 3.619540750455264

Epoch: 6| Step: 4
Training loss: 3.314952302477397
Validation loss: 3.619844889196051

Epoch: 6| Step: 5
Training loss: 3.8746438631864373
Validation loss: 3.618743956384393

Epoch: 6| Step: 6
Training loss: 3.8635182245317625
Validation loss: 3.6180554448089026

Epoch: 6| Step: 7
Training loss: 3.499176337190986
Validation loss: 3.6182992862389196

Epoch: 6| Step: 8
Training loss: 4.15217080388603
Validation loss: 3.6184865576346454

Epoch: 6| Step: 9
Training loss: 4.056699396992411
Validation loss: 3.6182948664828998

Epoch: 6| Step: 10
Training loss: 4.1162687431068585
Validation loss: 3.6182859745239258

Epoch: 6| Step: 11
Training loss: 4.145962711532741
Validation loss: 3.6169201014457055

Epoch: 6| Step: 12
Training loss: 4.729517493770052
Validation loss: 3.6183429336966517

Epoch: 6| Step: 13
Training loss: 3.1403714357567005
Validation loss: 3.614770627977041

Epoch: 29| Step: 0
Training loss: 3.8886981160434306
Validation loss: 3.61498231604619

Epoch: 6| Step: 1
Training loss: 3.9382442194902834
Validation loss: 3.614694888958685

Epoch: 6| Step: 2
Training loss: 3.327804048491475
Validation loss: 3.614638834027752

Epoch: 6| Step: 3
Training loss: 4.3639176740424785
Validation loss: 3.6130886966003355

Epoch: 6| Step: 4
Training loss: 3.982956577716557
Validation loss: 3.61329097162262

Epoch: 6| Step: 5
Training loss: 3.6810950565598937
Validation loss: 3.612056570439712

Epoch: 6| Step: 6
Training loss: 4.265459106349451
Validation loss: 3.611467229959596

Epoch: 6| Step: 7
Training loss: 3.984259629916703
Validation loss: 3.6118775965986716

Epoch: 6| Step: 8
Training loss: 3.5494386255976824
Validation loss: 3.61105206433137

Epoch: 6| Step: 9
Training loss: 3.051524834856997
Validation loss: 3.6120677758831436

Epoch: 6| Step: 10
Training loss: 3.1002884945912412
Validation loss: 3.611239017264894

Epoch: 6| Step: 11
Training loss: 3.8791841866452357
Validation loss: 3.6096640978342496

Epoch: 6| Step: 12
Training loss: 4.567833278546373
Validation loss: 3.6096845562538897

Epoch: 6| Step: 13
Training loss: 3.0878884630961756
Validation loss: 3.6096949793075

Epoch: 30| Step: 0
Training loss: 2.327562097690095
Validation loss: 3.6088330368438233

Epoch: 6| Step: 1
Training loss: 3.4838194810544802
Validation loss: 3.6097947950695604

Epoch: 6| Step: 2
Training loss: 4.372310574737674
Validation loss: 3.6125046787458044

Epoch: 6| Step: 3
Training loss: 3.629977262231322
Validation loss: 3.609841934341853

Epoch: 6| Step: 4
Training loss: 2.9315975219079005
Validation loss: 3.6082199884464816

Epoch: 6| Step: 5
Training loss: 3.6719379825466083
Validation loss: 3.608109481253872

Epoch: 6| Step: 6
Training loss: 4.549885071361436
Validation loss: 3.6079480342873915

Epoch: 6| Step: 7
Training loss: 3.411977310114164
Validation loss: 3.6067527433215454

Epoch: 6| Step: 8
Training loss: 3.6572351677135075
Validation loss: 3.6082423265002435

Epoch: 6| Step: 9
Training loss: 3.95788119226746
Validation loss: 3.6066045506950752

Epoch: 6| Step: 10
Training loss: 4.77368283304697
Validation loss: 3.606298258864041

Epoch: 6| Step: 11
Training loss: 3.7123875405075273
Validation loss: 3.6058611955255437

Epoch: 6| Step: 12
Training loss: 3.7730702602579207
Validation loss: 3.609717892022331

Epoch: 6| Step: 13
Training loss: 4.67685130789166
Validation loss: 3.609050424861594

Epoch: 31| Step: 0
Training loss: 4.4052726798034705
Validation loss: 3.6061400393851897

Epoch: 6| Step: 1
Training loss: 3.9512556277424777
Validation loss: 3.6097207612504425

Epoch: 6| Step: 2
Training loss: 4.402305406540538
Validation loss: 3.6045025530225083

Epoch: 6| Step: 3
Training loss: 4.088378177297872
Validation loss: 3.606188090886648

Epoch: 6| Step: 4
Training loss: 2.6524918842101632
Validation loss: 3.6036885489914696

Epoch: 6| Step: 5
Training loss: 3.871047434447955
Validation loss: 3.6028827481314254

Epoch: 6| Step: 6
Training loss: 3.58173784325196
Validation loss: 3.603265415747708

Epoch: 6| Step: 7
Training loss: 3.4197442375160767
Validation loss: 3.6035308950506226

Epoch: 6| Step: 8
Training loss: 2.7143129117936793
Validation loss: 3.6025255872290805

Epoch: 6| Step: 9
Training loss: 3.504934102743616
Validation loss: 3.6026224250301544

Epoch: 6| Step: 10
Training loss: 3.690697011479267
Validation loss: 3.600238282112397

Epoch: 6| Step: 11
Training loss: 4.061192228658382
Validation loss: 3.599502429507756

Epoch: 6| Step: 12
Training loss: 4.587284234817043
Validation loss: 3.5987262743914394

Epoch: 6| Step: 13
Training loss: 3.6911699814847805
Validation loss: 3.5976200447319675

Epoch: 32| Step: 0
Training loss: 4.003918159281069
Validation loss: 3.597057064649408

Epoch: 6| Step: 1
Training loss: 4.336009421911947
Validation loss: 3.5961239158085507

Epoch: 6| Step: 2
Training loss: 3.5159901069093986
Validation loss: 3.5964356633333034

Epoch: 6| Step: 3
Training loss: 4.843607451279453
Validation loss: 3.5954576356048853

Epoch: 6| Step: 4
Training loss: 3.6655718006849303
Validation loss: 3.5958886330380637

Epoch: 6| Step: 5
Training loss: 3.6727466603770855
Validation loss: 3.5951084674306073

Epoch: 6| Step: 6
Training loss: 3.107290518122448
Validation loss: 3.5953418781739703

Epoch: 6| Step: 7
Training loss: 3.9711486296282885
Validation loss: 3.593702581163243

Epoch: 6| Step: 8
Training loss: 3.2382856674992486
Validation loss: 3.591041870701627

Epoch: 6| Step: 9
Training loss: 4.788416857860088
Validation loss: 3.590749630030226

Epoch: 6| Step: 10
Training loss: 3.113171430730518
Validation loss: 3.589934527104931

Epoch: 6| Step: 11
Training loss: 3.0213276601144985
Validation loss: 3.5880732088635425

Epoch: 6| Step: 12
Training loss: 3.743011702400766
Validation loss: 3.5871323814950165

Epoch: 6| Step: 13
Training loss: 3.2961912485672533
Validation loss: 3.585644708892299

Epoch: 33| Step: 0
Training loss: 4.084621356051801
Validation loss: 3.5834492642955658

Epoch: 6| Step: 1
Training loss: 3.3216907468064263
Validation loss: 3.584085839526229

Epoch: 6| Step: 2
Training loss: 2.963166296348704
Validation loss: 3.5814434647317053

Epoch: 6| Step: 3
Training loss: 3.6819656997566628
Validation loss: 3.582154043922164

Epoch: 6| Step: 4
Training loss: 4.2109422559835155
Validation loss: 3.580495213119417

Epoch: 6| Step: 5
Training loss: 3.1947208966772065
Validation loss: 3.5804856201158795

Epoch: 6| Step: 6
Training loss: 3.065819945441384
Validation loss: 3.579847376323282

Epoch: 6| Step: 7
Training loss: 4.3037183608754335
Validation loss: 3.5818213363312843

Epoch: 6| Step: 8
Training loss: 2.516665794254514
Validation loss: 3.5794324931425523

Epoch: 6| Step: 9
Training loss: 4.2764783567346765
Validation loss: 3.578376204857919

Epoch: 6| Step: 10
Training loss: 3.555442109549859
Validation loss: 3.5773308243350375

Epoch: 6| Step: 11
Training loss: 4.714941647958365
Validation loss: 3.578208596008502

Epoch: 6| Step: 12
Training loss: 4.544666710982887
Validation loss: 3.5735153911114748

Epoch: 6| Step: 13
Training loss: 3.7753398514918755
Validation loss: 3.5738961152004673

Epoch: 34| Step: 0
Training loss: 2.820360769772829
Validation loss: 3.573462199795604

Epoch: 6| Step: 1
Training loss: 3.0996856776210113
Validation loss: 3.572231194083482

Epoch: 6| Step: 2
Training loss: 3.9709274446290017
Validation loss: 3.57336199761414

Epoch: 6| Step: 3
Training loss: 4.0260212426039725
Validation loss: 3.573571043715582

Epoch: 6| Step: 4
Training loss: 4.6000897523168085
Validation loss: 3.5711163715139578

Epoch: 6| Step: 5
Training loss: 3.5185614635308053
Validation loss: 3.5708123957957203

Epoch: 6| Step: 6
Training loss: 4.090841177174352
Validation loss: 3.5708100782741763

Epoch: 6| Step: 7
Training loss: 3.4512249306193468
Validation loss: 3.5694117447956764

Epoch: 6| Step: 8
Training loss: 4.519135796630665
Validation loss: 3.5691516667780268

Epoch: 6| Step: 9
Training loss: 3.511568025912406
Validation loss: 3.5676214669992943

Epoch: 6| Step: 10
Training loss: 3.128757049394104
Validation loss: 3.5677172545820084

Epoch: 6| Step: 11
Training loss: 3.773670134076739
Validation loss: 3.5670389326921232

Epoch: 6| Step: 12
Training loss: 4.0774837296639
Validation loss: 3.5659111558160226

Epoch: 6| Step: 13
Training loss: 3.768772819791571
Validation loss: 3.566146044090572

Epoch: 35| Step: 0
Training loss: 4.269562968060364
Validation loss: 3.5657528439079016

Epoch: 6| Step: 1
Training loss: 3.7310734283738616
Validation loss: 3.566153106387055

Epoch: 6| Step: 2
Training loss: 3.74491983264228
Validation loss: 3.563595106755908

Epoch: 6| Step: 3
Training loss: 3.4162928368974055
Validation loss: 3.5644126525909683

Epoch: 6| Step: 4
Training loss: 3.7589778243230487
Validation loss: 3.563196483692296

Epoch: 6| Step: 5
Training loss: 3.385021026185404
Validation loss: 3.562740373228979

Epoch: 6| Step: 6
Training loss: 4.520311082245716
Validation loss: 3.5623179793835082

Epoch: 6| Step: 7
Training loss: 3.364580530376074
Validation loss: 3.562471960677383

Epoch: 6| Step: 8
Training loss: 3.974054831170232
Validation loss: 3.561517651616367

Epoch: 6| Step: 9
Training loss: 3.0540108870416534
Validation loss: 3.562377469903007

Epoch: 6| Step: 10
Training loss: 2.731791294677055
Validation loss: 3.561894340678191

Epoch: 6| Step: 11
Training loss: 4.463463704315976
Validation loss: 3.561479354271511

Epoch: 6| Step: 12
Training loss: 4.0160992412843495
Validation loss: 3.56134678313768

Epoch: 6| Step: 13
Training loss: 3.9660263928541775
Validation loss: 3.560365192322029

Epoch: 36| Step: 0
Training loss: 3.704264147705528
Validation loss: 3.5597082200951253

Epoch: 6| Step: 1
Training loss: 4.220560095259893
Validation loss: 3.559052162410352

Epoch: 6| Step: 2
Training loss: 3.94039556211989
Validation loss: 3.559123094057535

Epoch: 6| Step: 3
Training loss: 3.956218971263343
Validation loss: 3.558368262248028

Epoch: 6| Step: 4
Training loss: 3.500653887021502
Validation loss: 3.5577302473588786

Epoch: 6| Step: 5
Training loss: 3.925963075896566
Validation loss: 3.558791960513721

Epoch: 6| Step: 6
Training loss: 2.6500662237565704
Validation loss: 3.5574453303246667

Epoch: 6| Step: 7
Training loss: 4.074057468868542
Validation loss: 3.5576629990170416

Epoch: 6| Step: 8
Training loss: 3.7604336865886188
Validation loss: 3.5570762378187735

Epoch: 6| Step: 9
Training loss: 3.98055524048882
Validation loss: 3.5564167578696475

Epoch: 6| Step: 10
Training loss: 3.558818990067483
Validation loss: 3.555761007097314

Epoch: 6| Step: 11
Training loss: 3.3536310814793064
Validation loss: 3.557655373653345

Epoch: 6| Step: 12
Training loss: 3.821018520403187
Validation loss: 3.5550175908967105

Epoch: 6| Step: 13
Training loss: 4.150225640103142
Validation loss: 3.556052933090861

Epoch: 37| Step: 0
Training loss: 4.827409709795263
Validation loss: 3.5544876563524013

Epoch: 6| Step: 1
Training loss: 3.634846567014193
Validation loss: 3.554696448638373

Epoch: 6| Step: 2
Training loss: 4.615522003574299
Validation loss: 3.554055086926828

Epoch: 6| Step: 3
Training loss: 3.875903485705671
Validation loss: 3.554188804257939

Epoch: 6| Step: 4
Training loss: 3.328495775084574
Validation loss: 3.5546116390470113

Epoch: 6| Step: 5
Training loss: 3.0294357061393193
Validation loss: 3.553954691031269

Epoch: 6| Step: 6
Training loss: 3.702872223415479
Validation loss: 3.5537832511615415

Epoch: 6| Step: 7
Training loss: 2.939379476340647
Validation loss: 3.556948665972123

Epoch: 6| Step: 8
Training loss: 3.744730998871114
Validation loss: 3.5559346052960286

Epoch: 6| Step: 9
Training loss: 3.630122807214514
Validation loss: 3.553185813158924

Epoch: 6| Step: 10
Training loss: 3.984654076470235
Validation loss: 3.551562321966714

Epoch: 6| Step: 11
Training loss: 4.377850720937667
Validation loss: 3.5521314011046194

Epoch: 6| Step: 12
Training loss: 3.3143708326186556
Validation loss: 3.5500954185486586

Epoch: 6| Step: 13
Training loss: 2.390356809245555
Validation loss: 3.549102940698925

Epoch: 38| Step: 0
Training loss: 3.0533289705547944
Validation loss: 3.549422534907983

Epoch: 6| Step: 1
Training loss: 3.7321608615318413
Validation loss: 3.547732669950915

Epoch: 6| Step: 2
Training loss: 3.1174657405876642
Validation loss: 3.546360525165649

Epoch: 6| Step: 3
Training loss: 3.870898383298539
Validation loss: 3.544999735326404

Epoch: 6| Step: 4
Training loss: 3.7521648516034576
Validation loss: 3.5429617514746203

Epoch: 6| Step: 5
Training loss: 4.418245045515986
Validation loss: 3.541880950139575

Epoch: 6| Step: 6
Training loss: 3.8755310679118042
Validation loss: 3.540791902359939

Epoch: 6| Step: 7
Training loss: 5.035760788475759
Validation loss: 3.542421079389258

Epoch: 6| Step: 8
Training loss: 3.409362770569124
Validation loss: 3.539747637302392

Epoch: 6| Step: 9
Training loss: 3.426261285361764
Validation loss: 3.5400923881319186

Epoch: 6| Step: 10
Training loss: 4.0140969304278284
Validation loss: 3.539683816354543

Epoch: 6| Step: 11
Training loss: 3.3262082880236745
Validation loss: 3.539371416057441

Epoch: 6| Step: 12
Training loss: 3.669379242413927
Validation loss: 3.540112869143928

Epoch: 6| Step: 13
Training loss: 2.9704838558336846
Validation loss: 3.5396848998427877

Epoch: 39| Step: 0
Training loss: 4.385647487531083
Validation loss: 3.5396619799398845

Epoch: 6| Step: 1
Training loss: 3.707919851389538
Validation loss: 3.53704809397348

Epoch: 6| Step: 2
Training loss: 4.139079024849634
Validation loss: 3.536434994778124

Epoch: 6| Step: 3
Training loss: 4.040123687588134
Validation loss: 3.5361012233446627

Epoch: 6| Step: 4
Training loss: 3.327099279382592
Validation loss: 3.5368775611545487

Epoch: 6| Step: 5
Training loss: 4.07203377262642
Validation loss: 3.535246444400931

Epoch: 6| Step: 6
Training loss: 4.342188931986877
Validation loss: 3.534881529271762

Epoch: 6| Step: 7
Training loss: 3.8008720802674536
Validation loss: 3.5349308264524475

Epoch: 6| Step: 8
Training loss: 3.529613419456599
Validation loss: 3.534729957928023

Epoch: 6| Step: 9
Training loss: 3.1371100194752484
Validation loss: 3.5328840561769477

Epoch: 6| Step: 10
Training loss: 2.9489834925311453
Validation loss: 3.533020073924631

Epoch: 6| Step: 11
Training loss: 2.4023737215483023
Validation loss: 3.5334234116677683

Epoch: 6| Step: 12
Training loss: 4.587913906124412
Validation loss: 3.533247913652262

Epoch: 6| Step: 13
Training loss: 2.9829253026016054
Validation loss: 3.532062751701451

Epoch: 40| Step: 0
Training loss: 4.255193790456075
Validation loss: 3.5329174316086216

Epoch: 6| Step: 1
Training loss: 3.1984281017051712
Validation loss: 3.5318993397831426

Epoch: 6| Step: 2
Training loss: 3.8360650377378747
Validation loss: 3.5311091848064793

Epoch: 6| Step: 3
Training loss: 3.005756101265605
Validation loss: 3.531223356186543

Epoch: 6| Step: 4
Training loss: 2.974885563292319
Validation loss: 3.5317811645409165

Epoch: 6| Step: 5
Training loss: 4.459287000722153
Validation loss: 3.531865902468774

Epoch: 6| Step: 6
Training loss: 4.115904982883473
Validation loss: 3.5311280858481027

Epoch: 6| Step: 7
Training loss: 2.857482116856856
Validation loss: 3.5306551678497264

Epoch: 6| Step: 8
Training loss: 3.6974247708253762
Validation loss: 3.5305567220657736

Epoch: 6| Step: 9
Training loss: 3.341113040056494
Validation loss: 3.5295079324878356

Epoch: 6| Step: 10
Training loss: 4.879618486593704
Validation loss: 3.530951718658715

Epoch: 6| Step: 11
Training loss: 2.9978615768775336
Validation loss: 3.529232759010958

Epoch: 6| Step: 12
Training loss: 3.63202171332637
Validation loss: 3.5309499964723035

Epoch: 6| Step: 13
Training loss: 4.797319720897972
Validation loss: 3.5306156411567535

Epoch: 41| Step: 0
Training loss: 3.807829200103792
Validation loss: 3.530550536164958

Epoch: 6| Step: 1
Training loss: 3.0442902385179127
Validation loss: 3.5290869599164307

Epoch: 6| Step: 2
Training loss: 3.4412269502277284
Validation loss: 3.528732196429238

Epoch: 6| Step: 3
Training loss: 3.617430050588185
Validation loss: 3.5264942488677344

Epoch: 6| Step: 4
Training loss: 4.3710330962335595
Validation loss: 3.5277472309455202

Epoch: 6| Step: 5
Training loss: 3.908075013126992
Validation loss: 3.5296127948184646

Epoch: 6| Step: 6
Training loss: 4.603260394123226
Validation loss: 3.528063565650726

Epoch: 6| Step: 7
Training loss: 3.3311530294135534
Validation loss: 3.526584772392434

Epoch: 6| Step: 8
Training loss: 3.9610805147073367
Validation loss: 3.525974789198781

Epoch: 6| Step: 9
Training loss: 3.2919349722019198
Validation loss: 3.524962071180015

Epoch: 6| Step: 10
Training loss: 3.9787881614587937
Validation loss: 3.5249294669877185

Epoch: 6| Step: 11
Training loss: 2.913383343381568
Validation loss: 3.5241546668606416

Epoch: 6| Step: 12
Training loss: 4.183310391387241
Validation loss: 3.5205161504023934

Epoch: 6| Step: 13
Training loss: 3.100803080486976
Validation loss: 3.5213488712084082

Epoch: 42| Step: 0
Training loss: 3.9535861142179036
Validation loss: 3.5182964483410544

Epoch: 6| Step: 1
Training loss: 4.141395583514136
Validation loss: 3.5180838700412034

Epoch: 6| Step: 2
Training loss: 4.72341627595091
Validation loss: 3.516568121156048

Epoch: 6| Step: 3
Training loss: 4.038508777551722
Validation loss: 3.5171764003383013

Epoch: 6| Step: 4
Training loss: 3.1329111288246403
Validation loss: 3.514941768637384

Epoch: 6| Step: 5
Training loss: 3.5252726780823616
Validation loss: 3.514118475396532

Epoch: 6| Step: 6
Training loss: 3.3149547478304395
Validation loss: 3.5151501712972664

Epoch: 6| Step: 7
Training loss: 3.6184404151799994
Validation loss: 3.5131764698504337

Epoch: 6| Step: 8
Training loss: 3.961003831537479
Validation loss: 3.512965401763168

Epoch: 6| Step: 9
Training loss: 3.3496905169654467
Validation loss: 3.513550219193688

Epoch: 6| Step: 10
Training loss: 2.719472679465251
Validation loss: 3.512156239556882

Epoch: 6| Step: 11
Training loss: 3.025921730032715
Validation loss: 3.5121869185295584

Epoch: 6| Step: 12
Training loss: 4.269844399683643
Validation loss: 3.5123852874226396

Epoch: 6| Step: 13
Training loss: 3.9504375746554965
Validation loss: 3.5104799938919493

Epoch: 43| Step: 0
Training loss: 3.286851733441433
Validation loss: 3.510126640807871

Epoch: 6| Step: 1
Training loss: 4.046414028704826
Validation loss: 3.5103925605112503

Epoch: 6| Step: 2
Training loss: 3.5776844003258534
Validation loss: 3.5075669855788316

Epoch: 6| Step: 3
Training loss: 3.197230129709048
Validation loss: 3.5071450679291765

Epoch: 6| Step: 4
Training loss: 3.9812456595069303
Validation loss: 3.506777083824334

Epoch: 6| Step: 5
Training loss: 4.363571061743887
Validation loss: 3.503768108419273

Epoch: 6| Step: 6
Training loss: 3.8821782720511853
Validation loss: 3.503538756959332

Epoch: 6| Step: 7
Training loss: 3.328268558468508
Validation loss: 3.502345927957695

Epoch: 6| Step: 8
Training loss: 3.708873552270743
Validation loss: 3.501845047815318

Epoch: 6| Step: 9
Training loss: 3.1427172623506334
Validation loss: 3.501110170384472

Epoch: 6| Step: 10
Training loss: 4.2443311695031545
Validation loss: 3.5030860070220617

Epoch: 6| Step: 11
Training loss: 3.5270871632001843
Validation loss: 3.501745209328145

Epoch: 6| Step: 12
Training loss: 4.12367042152514
Validation loss: 3.5006353882679417

Epoch: 6| Step: 13
Training loss: 2.975374720719851
Validation loss: 3.501619009946148

Epoch: 44| Step: 0
Training loss: 3.9938715240185445
Validation loss: 3.4987762453517024

Epoch: 6| Step: 1
Training loss: 4.093233498174891
Validation loss: 3.4999187821898654

Epoch: 6| Step: 2
Training loss: 2.619376289296362
Validation loss: 3.4991783402313636

Epoch: 6| Step: 3
Training loss: 2.8486185841798415
Validation loss: 3.4988401691574884

Epoch: 6| Step: 4
Training loss: 3.1903628788057814
Validation loss: 3.498110400264382

Epoch: 6| Step: 5
Training loss: 3.422693999360275
Validation loss: 3.4964094393319023

Epoch: 6| Step: 6
Training loss: 4.338321504658594
Validation loss: 3.496946935491024

Epoch: 6| Step: 7
Training loss: 4.153617771097734
Validation loss: 3.494888201387829

Epoch: 6| Step: 8
Training loss: 3.4505412243894344
Validation loss: 3.494103809355952

Epoch: 6| Step: 9
Training loss: 3.202337400788869
Validation loss: 3.49478989829671

Epoch: 6| Step: 10
Training loss: 3.926469399031186
Validation loss: 3.495469917758932

Epoch: 6| Step: 11
Training loss: 4.0653235380163775
Validation loss: 3.494692769104712

Epoch: 6| Step: 12
Training loss: 4.076804228546608
Validation loss: 3.495062770768928

Epoch: 6| Step: 13
Training loss: 4.274964110463613
Validation loss: 3.4954436319581643

Epoch: 45| Step: 0
Training loss: 3.191674883029279
Validation loss: 3.493726623657714

Epoch: 6| Step: 1
Training loss: 3.5686385155682783
Validation loss: 3.4949371061640284

Epoch: 6| Step: 2
Training loss: 2.390576829611964
Validation loss: 3.494847793364363

Epoch: 6| Step: 3
Training loss: 4.029949362841354
Validation loss: 3.4947025447930438

Epoch: 6| Step: 4
Training loss: 4.4601735865592955
Validation loss: 3.4944757940155142

Epoch: 6| Step: 5
Training loss: 4.170132276600552
Validation loss: 3.4930080739851723

Epoch: 6| Step: 6
Training loss: 4.1926038014272455
Validation loss: 3.4922999252682096

Epoch: 6| Step: 7
Training loss: 3.8251122900742724
Validation loss: 3.4922456613756125

Epoch: 6| Step: 8
Training loss: 2.94947468234505
Validation loss: 3.494835736739109

Epoch: 6| Step: 9
Training loss: 4.184976073348218
Validation loss: 3.4937105244000457

Epoch: 6| Step: 10
Training loss: 3.5972362028723346
Validation loss: 3.493446331881566

Epoch: 6| Step: 11
Training loss: 3.3964979929374066
Validation loss: 3.4917090479731234

Epoch: 6| Step: 12
Training loss: 4.2866818017133745
Validation loss: 3.489463936102792

Epoch: 6| Step: 13
Training loss: 2.241965252963481
Validation loss: 3.4906980051413146

Epoch: 46| Step: 0
Training loss: 3.537034689558699
Validation loss: 3.4902290835269487

Epoch: 6| Step: 1
Training loss: 3.4984637022208527
Validation loss: 3.489298705515661

Epoch: 6| Step: 2
Training loss: 3.5043667391806728
Validation loss: 3.488930549718584

Epoch: 6| Step: 3
Training loss: 3.175087790889946
Validation loss: 3.488575404870415

Epoch: 6| Step: 4
Training loss: 3.3493294913134233
Validation loss: 3.4889348952797983

Epoch: 6| Step: 5
Training loss: 3.984381223187542
Validation loss: 3.4885785177676945

Epoch: 6| Step: 6
Training loss: 4.728347012689753
Validation loss: 3.488167510463347

Epoch: 6| Step: 7
Training loss: 4.405892432023119
Validation loss: 3.488991755942529

Epoch: 6| Step: 8
Training loss: 2.9274234415756495
Validation loss: 3.4874073446874316

Epoch: 6| Step: 9
Training loss: 3.3843376122379394
Validation loss: 3.4872964142779788

Epoch: 6| Step: 10
Training loss: 3.1713212756070104
Validation loss: 3.4873793411567813

Epoch: 6| Step: 11
Training loss: 3.734251139992875
Validation loss: 3.4876808917903057

Epoch: 6| Step: 12
Training loss: 3.816909366426092
Validation loss: 3.486434547833905

Epoch: 6| Step: 13
Training loss: 4.480718843485955
Validation loss: 3.485787405817624

Epoch: 47| Step: 0
Training loss: 3.366873387955428
Validation loss: 3.4853016788019877

Epoch: 6| Step: 1
Training loss: 3.8888558038182164
Validation loss: 3.4867793246815753

Epoch: 6| Step: 2
Training loss: 3.1767752242644565
Validation loss: 3.486387682714772

Epoch: 6| Step: 3
Training loss: 3.9663489580477957
Validation loss: 3.4841931560177195

Epoch: 6| Step: 4
Training loss: 3.6594560700516268
Validation loss: 3.4844265317847096

Epoch: 6| Step: 5
Training loss: 3.6750004878660123
Validation loss: 3.484054636785285

Epoch: 6| Step: 6
Training loss: 3.2448351976016787
Validation loss: 3.484696532929866

Epoch: 6| Step: 7
Training loss: 3.6268066639619474
Validation loss: 3.4831901914971297

Epoch: 6| Step: 8
Training loss: 3.1422307857982457
Validation loss: 3.4831505309795676

Epoch: 6| Step: 9
Training loss: 4.217960990309356
Validation loss: 3.483239588766698

Epoch: 6| Step: 10
Training loss: 3.373138762229169
Validation loss: 3.4819495173767927

Epoch: 6| Step: 11
Training loss: 3.8249099621117515
Validation loss: 3.4822461595176795

Epoch: 6| Step: 12
Training loss: 4.626284859007245
Validation loss: 3.4815580507791877

Epoch: 6| Step: 13
Training loss: 3.659438870049332
Validation loss: 3.4810437203694504

Epoch: 48| Step: 0
Training loss: 3.952474668784767
Validation loss: 3.4806493088506882

Epoch: 6| Step: 1
Training loss: 3.9654433525213375
Validation loss: 3.4816747365246266

Epoch: 6| Step: 2
Training loss: 3.457231660195524
Validation loss: 3.480828790406265

Epoch: 6| Step: 3
Training loss: 3.022480026949006
Validation loss: 3.48049288908746

Epoch: 6| Step: 4
Training loss: 3.4563484164086167
Validation loss: 3.4797439278058806

Epoch: 6| Step: 5
Training loss: 4.156597839944026
Validation loss: 3.479317094776913

Epoch: 6| Step: 6
Training loss: 3.5889572692776217
Validation loss: 3.479499405046776

Epoch: 6| Step: 7
Training loss: 3.7122038597904434
Validation loss: 3.4793769861769346

Epoch: 6| Step: 8
Training loss: 3.9746891547966743
Validation loss: 3.4784330837858466

Epoch: 6| Step: 9
Training loss: 4.400579171643028
Validation loss: 3.479049607453671

Epoch: 6| Step: 10
Training loss: 3.597653996801344
Validation loss: 3.4789103815863562

Epoch: 6| Step: 11
Training loss: 3.667866178303254
Validation loss: 3.4791534793970547

Epoch: 6| Step: 12
Training loss: 3.1164409154502173
Validation loss: 3.47833735221465

Epoch: 6| Step: 13
Training loss: 3.135417815722554
Validation loss: 3.4781850724886367

Epoch: 49| Step: 0
Training loss: 4.4314297272426915
Validation loss: 3.4769406894498354

Epoch: 6| Step: 1
Training loss: 4.1040278119191465
Validation loss: 3.4772151941311407

Epoch: 6| Step: 2
Training loss: 3.7276828449312878
Validation loss: 3.47796680662033

Epoch: 6| Step: 3
Training loss: 2.9924279656659585
Validation loss: 3.4774725708776515

Epoch: 6| Step: 4
Training loss: 4.308169858525454
Validation loss: 3.47738955077051

Epoch: 6| Step: 5
Training loss: 3.185692517794542
Validation loss: 3.4769043125175463

Epoch: 6| Step: 6
Training loss: 3.8479013742508936
Validation loss: 3.4767042429097597

Epoch: 6| Step: 7
Training loss: 3.4352340165428448
Validation loss: 3.4764151305630815

Epoch: 6| Step: 8
Training loss: 3.2529925727091027
Validation loss: 3.475282524464979

Epoch: 6| Step: 9
Training loss: 3.698613118239469
Validation loss: 3.4746521801740258

Epoch: 6| Step: 10
Training loss: 3.206341277788195
Validation loss: 3.474463032451288

Epoch: 6| Step: 11
Training loss: 4.290068739404808
Validation loss: 3.4746905373409627

Epoch: 6| Step: 12
Training loss: 3.5321840384414993
Validation loss: 3.474185498873713

Epoch: 6| Step: 13
Training loss: 2.8679073583838046
Validation loss: 3.4738332316904423

Epoch: 50| Step: 0
Training loss: 3.8776562108462067
Validation loss: 3.4749312478930325

Epoch: 6| Step: 1
Training loss: 4.372426393215433
Validation loss: 3.4738112971983566

Epoch: 6| Step: 2
Training loss: 3.244434873865838
Validation loss: 3.4730892236533557

Epoch: 6| Step: 3
Training loss: 4.050505787855533
Validation loss: 3.473981265595815

Epoch: 6| Step: 4
Training loss: 3.8659473627081975
Validation loss: 3.472253217551965

Epoch: 6| Step: 5
Training loss: 2.8865426594423083
Validation loss: 3.4727651824286094

Epoch: 6| Step: 6
Training loss: 4.164664334146664
Validation loss: 3.472345940686244

Epoch: 6| Step: 7
Training loss: 3.522941063800766
Validation loss: 3.472359872420746

Epoch: 6| Step: 8
Training loss: 3.9048466717538637
Validation loss: 3.471603392116349

Epoch: 6| Step: 9
Training loss: 3.3403782467042094
Validation loss: 3.4735919608963495

Epoch: 6| Step: 10
Training loss: 3.786358621675775
Validation loss: 3.4769901283172606

Epoch: 6| Step: 11
Training loss: 3.6241227765706565
Validation loss: 3.484205644588983

Epoch: 6| Step: 12
Training loss: 3.392258351770792
Validation loss: 3.478151276523485

Epoch: 6| Step: 13
Training loss: 2.976397492248028
Validation loss: 3.470100631363486

Epoch: 51| Step: 0
Training loss: 3.693685483933849
Validation loss: 3.4712419251340396

Epoch: 6| Step: 1
Training loss: 3.4196209734309315
Validation loss: 3.468867684167338

Epoch: 6| Step: 2
Training loss: 3.3395459137119285
Validation loss: 3.4709151322343534

Epoch: 6| Step: 3
Training loss: 3.5578687580470567
Validation loss: 3.469323831113798

Epoch: 6| Step: 4
Training loss: 4.071679879561503
Validation loss: 3.4695983473096237

Epoch: 6| Step: 5
Training loss: 4.497891249885971
Validation loss: 3.4695894067670734

Epoch: 6| Step: 6
Training loss: 2.6345013824592476
Validation loss: 3.4693531139156657

Epoch: 6| Step: 7
Training loss: 3.675415669502965
Validation loss: 3.468904296139436

Epoch: 6| Step: 8
Training loss: 4.122763287410937
Validation loss: 3.4675700967141387

Epoch: 6| Step: 9
Training loss: 3.9368009400839283
Validation loss: 3.467630080107269

Epoch: 6| Step: 10
Training loss: 3.9831942136297664
Validation loss: 3.466891234825383

Epoch: 6| Step: 11
Training loss: 3.1017024011072016
Validation loss: 3.4667668725274905

Epoch: 6| Step: 12
Training loss: 3.617244184474184
Validation loss: 3.4663820381393853

Epoch: 6| Step: 13
Training loss: 3.472074685247148
Validation loss: 3.4662321901276383

Epoch: 52| Step: 0
Training loss: 4.112711085319935
Validation loss: 3.465738149462988

Epoch: 6| Step: 1
Training loss: 2.961242338003968
Validation loss: 3.4656454344700633

Epoch: 6| Step: 2
Training loss: 3.390955755036799
Validation loss: 3.467123235315181

Epoch: 6| Step: 3
Training loss: 3.991661201319341
Validation loss: 3.4666059556934745

Epoch: 6| Step: 4
Training loss: 3.6685247192881
Validation loss: 3.4653412901611866

Epoch: 6| Step: 5
Training loss: 4.121837906746478
Validation loss: 3.4640009034432304

Epoch: 6| Step: 6
Training loss: 4.1646863173091475
Validation loss: 3.4642437420918664

Epoch: 6| Step: 7
Training loss: 3.64293810009155
Validation loss: 3.463883179006703

Epoch: 6| Step: 8
Training loss: 4.115855861204914
Validation loss: 3.4640150537596424

Epoch: 6| Step: 9
Training loss: 2.7409616539773443
Validation loss: 3.463780922235605

Epoch: 6| Step: 10
Training loss: 3.4251601244396968
Validation loss: 3.465040096349339

Epoch: 6| Step: 11
Training loss: 4.116860190307425
Validation loss: 3.4669867958967315

Epoch: 6| Step: 12
Training loss: 3.1005221142545403
Validation loss: 3.4682740285227394

Epoch: 6| Step: 13
Training loss: 3.5282015174697685
Validation loss: 3.4670041165765544

Epoch: 53| Step: 0
Training loss: 3.3851363941475716
Validation loss: 3.4648894178557375

Epoch: 6| Step: 1
Training loss: 3.543909387519416
Validation loss: 3.465039087181699

Epoch: 6| Step: 2
Training loss: 4.153283917993904
Validation loss: 3.4630906324479063

Epoch: 6| Step: 3
Training loss: 4.817700041342808
Validation loss: 3.463202674271018

Epoch: 6| Step: 4
Training loss: 3.3990483579054716
Validation loss: 3.4632663886036097

Epoch: 6| Step: 5
Training loss: 3.6380201197272846
Validation loss: 3.4629469331374922

Epoch: 6| Step: 6
Training loss: 3.4428951580162583
Validation loss: 3.462261451437058

Epoch: 6| Step: 7
Training loss: 3.7306832296818624
Validation loss: 3.4613107603929048

Epoch: 6| Step: 8
Training loss: 3.424481796824481
Validation loss: 3.463172208350307

Epoch: 6| Step: 9
Training loss: 2.643510043750527
Validation loss: 3.4617757426333804

Epoch: 6| Step: 10
Training loss: 3.5158902894697794
Validation loss: 3.460771658593028

Epoch: 6| Step: 11
Training loss: 4.062798122324523
Validation loss: 3.4618201372316455

Epoch: 6| Step: 12
Training loss: 3.623960674855674
Validation loss: 3.461940322966831

Epoch: 6| Step: 13
Training loss: 3.780021530978124
Validation loss: 3.459387321489872

Epoch: 54| Step: 0
Training loss: 3.5239065327540846
Validation loss: 3.4606484187070152

Epoch: 6| Step: 1
Training loss: 3.1274017259997366
Validation loss: 3.4593005784135182

Epoch: 6| Step: 2
Training loss: 3.4786442042666463
Validation loss: 3.4586119887321347

Epoch: 6| Step: 3
Training loss: 2.7748969737680094
Validation loss: 3.4585610285224506

Epoch: 6| Step: 4
Training loss: 3.695438826419944
Validation loss: 3.4600471601912286

Epoch: 6| Step: 5
Training loss: 4.336994214209527
Validation loss: 3.458471313009185

Epoch: 6| Step: 6
Training loss: 3.5011999253189217
Validation loss: 3.457743174169521

Epoch: 6| Step: 7
Training loss: 4.475822347597798
Validation loss: 3.458012825596081

Epoch: 6| Step: 8
Training loss: 3.6476812130189673
Validation loss: 3.457939983009102

Epoch: 6| Step: 9
Training loss: 4.234748401576911
Validation loss: 3.458458733734481

Epoch: 6| Step: 10
Training loss: 3.734365167963979
Validation loss: 3.4584854592643954

Epoch: 6| Step: 11
Training loss: 2.9669579166504545
Validation loss: 3.4580635566519544

Epoch: 6| Step: 12
Training loss: 3.8877324761552643
Validation loss: 3.456971861367005

Epoch: 6| Step: 13
Training loss: 3.637612467596913
Validation loss: 3.4565226048178603

Epoch: 55| Step: 0
Training loss: 4.271824841040908
Validation loss: 3.4562842422513205

Epoch: 6| Step: 1
Training loss: 3.400391746840711
Validation loss: 3.456676326863243

Epoch: 6| Step: 2
Training loss: 4.0924002482492
Validation loss: 3.4556635605829147

Epoch: 6| Step: 3
Training loss: 2.664915960536315
Validation loss: 3.4560100652900108

Epoch: 6| Step: 4
Training loss: 3.5340932016998052
Validation loss: 3.454916528699898

Epoch: 6| Step: 5
Training loss: 2.5720287031408247
Validation loss: 3.4552219571726357

Epoch: 6| Step: 6
Training loss: 2.958625635741335
Validation loss: 3.4550816850762085

Epoch: 6| Step: 7
Training loss: 3.4337109577193754
Validation loss: 3.4539277715602763

Epoch: 6| Step: 8
Training loss: 4.04299705606033
Validation loss: 3.4543015118338465

Epoch: 6| Step: 9
Training loss: 3.838412541046899
Validation loss: 3.4540027665963096

Epoch: 6| Step: 10
Training loss: 4.048643454845449
Validation loss: 3.4530793309805228

Epoch: 6| Step: 11
Training loss: 4.249712541619888
Validation loss: 3.453512793344929

Epoch: 6| Step: 12
Training loss: 4.0524406896601075
Validation loss: 3.452431489556483

Epoch: 6| Step: 13
Training loss: 3.693957606643939
Validation loss: 3.454397523597368

Epoch: 56| Step: 0
Training loss: 3.946206050189442
Validation loss: 3.4524570914762807

Epoch: 6| Step: 1
Training loss: 2.428981077281481
Validation loss: 3.4529007650628833

Epoch: 6| Step: 2
Training loss: 3.5524111658917996
Validation loss: 3.453255927772425

Epoch: 6| Step: 3
Training loss: 3.5942980804464555
Validation loss: 3.4529529061487274

Epoch: 6| Step: 4
Training loss: 2.0769066932227638
Validation loss: 3.4522072645261113

Epoch: 6| Step: 5
Training loss: 3.44953186065562
Validation loss: 3.45273156319711

Epoch: 6| Step: 6
Training loss: 4.423561017391414
Validation loss: 3.455278127630799

Epoch: 6| Step: 7
Training loss: 4.467541938162224
Validation loss: 3.452432414787241

Epoch: 6| Step: 8
Training loss: 3.653934625952197
Validation loss: 3.4515705194689597

Epoch: 6| Step: 9
Training loss: 2.94518006530423
Validation loss: 3.453153610946177

Epoch: 6| Step: 10
Training loss: 4.448426454916917
Validation loss: 3.451993365676842

Epoch: 6| Step: 11
Training loss: 3.515904394279912
Validation loss: 3.4506703601587003

Epoch: 6| Step: 12
Training loss: 4.189860347705681
Validation loss: 3.4502011750977943

Epoch: 6| Step: 13
Training loss: 3.8242617673860564
Validation loss: 3.4497318206986303

Epoch: 57| Step: 0
Training loss: 3.877779794186636
Validation loss: 3.4488209234272658

Epoch: 6| Step: 1
Training loss: 3.059075133733744
Validation loss: 3.448971996191795

Epoch: 6| Step: 2
Training loss: 3.834317302192029
Validation loss: 3.449065129655268

Epoch: 6| Step: 3
Training loss: 3.8067962004028226
Validation loss: 3.4492279752383284

Epoch: 6| Step: 4
Training loss: 3.7362761825404767
Validation loss: 3.4500029691850136

Epoch: 6| Step: 5
Training loss: 3.863655465634702
Validation loss: 3.4494942032617217

Epoch: 6| Step: 6
Training loss: 4.035374623507808
Validation loss: 3.4474740079593458

Epoch: 6| Step: 7
Training loss: 2.6946130701982978
Validation loss: 3.447901059373037

Epoch: 6| Step: 8
Training loss: 3.8956745271733726
Validation loss: 3.447209288285415

Epoch: 6| Step: 9
Training loss: 3.912416153761929
Validation loss: 3.4473334087001115

Epoch: 6| Step: 10
Training loss: 4.394936396254674
Validation loss: 3.4468545869377465

Epoch: 6| Step: 11
Training loss: 2.6828941977074923
Validation loss: 3.4454706672066537

Epoch: 6| Step: 12
Training loss: 3.3541257077830045
Validation loss: 3.4460813399139703

Epoch: 6| Step: 13
Training loss: 3.89037729723372
Validation loss: 3.4454768369556286

Epoch: 58| Step: 0
Training loss: 3.9071434525105544
Validation loss: 3.447178585823665

Epoch: 6| Step: 1
Training loss: 4.030246343537775
Validation loss: 3.4453405106073935

Epoch: 6| Step: 2
Training loss: 3.470713017008976
Validation loss: 3.448163586204148

Epoch: 6| Step: 3
Training loss: 3.9408713545846976
Validation loss: 3.446226715497581

Epoch: 6| Step: 4
Training loss: 3.5977754024361377
Validation loss: 3.4469306343106445

Epoch: 6| Step: 5
Training loss: 4.276273856633112
Validation loss: 3.44685225003568

Epoch: 6| Step: 6
Training loss: 3.620124300303236
Validation loss: 3.446795116675477

Epoch: 6| Step: 7
Training loss: 3.7257506567862224
Validation loss: 3.4451064404719407

Epoch: 6| Step: 8
Training loss: 3.5834063736916124
Validation loss: 3.446817740754451

Epoch: 6| Step: 9
Training loss: 3.1151863118353433
Validation loss: 3.4450794883690117

Epoch: 6| Step: 10
Training loss: 3.608281089516097
Validation loss: 3.4451439419345284

Epoch: 6| Step: 11
Training loss: 3.6114635947583147
Validation loss: 3.4461552306364247

Epoch: 6| Step: 12
Training loss: 3.0068341930715143
Validation loss: 3.4458453649223606

Epoch: 6| Step: 13
Training loss: 3.6015313864996226
Validation loss: 3.4452726951392307

Epoch: 59| Step: 0
Training loss: 3.357548274689452
Validation loss: 3.4441211791105735

Epoch: 6| Step: 1
Training loss: 3.32623867969099
Validation loss: 3.443763238551519

Epoch: 6| Step: 2
Training loss: 2.7625580932584803
Validation loss: 3.443888647410866

Epoch: 6| Step: 3
Training loss: 2.740232460853305
Validation loss: 3.444973174371915

Epoch: 6| Step: 4
Training loss: 3.2018129220097835
Validation loss: 3.4492351996262376

Epoch: 6| Step: 5
Training loss: 3.8313560085348035
Validation loss: 3.4498769384178454

Epoch: 6| Step: 6
Training loss: 3.696573119039018
Validation loss: 3.4657280997504394

Epoch: 6| Step: 7
Training loss: 3.953981691193629
Validation loss: 3.448206344960335

Epoch: 6| Step: 8
Training loss: 3.9082104455516147
Validation loss: 3.4423168616899833

Epoch: 6| Step: 9
Training loss: 3.9934123151692353
Validation loss: 3.4423464218935584

Epoch: 6| Step: 10
Training loss: 5.091746679365164
Validation loss: 3.44123189464753

Epoch: 6| Step: 11
Training loss: 3.6776165165910144
Validation loss: 3.4405996836067803

Epoch: 6| Step: 12
Training loss: 3.8844823182580424
Validation loss: 3.4420910244386054

Epoch: 6| Step: 13
Training loss: 2.836637216214145
Validation loss: 3.4401195683796346

Epoch: 60| Step: 0
Training loss: 3.817763275680956
Validation loss: 3.4411805437042533

Epoch: 6| Step: 1
Training loss: 4.282435788966496
Validation loss: 3.439975283606207

Epoch: 6| Step: 2
Training loss: 3.4993983160278783
Validation loss: 3.439079399134643

Epoch: 6| Step: 3
Training loss: 3.2664652204356805
Validation loss: 3.4376201604908223

Epoch: 6| Step: 4
Training loss: 3.7126204037648627
Validation loss: 3.4379402602124136

Epoch: 6| Step: 5
Training loss: 3.1047554396484847
Validation loss: 3.4399032097502227

Epoch: 6| Step: 6
Training loss: 3.8439335973047557
Validation loss: 3.4398461458003506

Epoch: 6| Step: 7
Training loss: 3.225352801756853
Validation loss: 3.440713489019661

Epoch: 6| Step: 8
Training loss: 3.422388325688165
Validation loss: 3.444846399952902

Epoch: 6| Step: 9
Training loss: 3.8717268378948675
Validation loss: 3.4476642288834696

Epoch: 6| Step: 10
Training loss: 4.224570321349192
Validation loss: 3.441694569868763

Epoch: 6| Step: 11
Training loss: 3.785871849482701
Validation loss: 3.4382999895088644

Epoch: 6| Step: 12
Training loss: 3.8383070702813087
Validation loss: 3.438025103871758

Epoch: 6| Step: 13
Training loss: 2.6193475264626467
Validation loss: 3.4388799856287138

Epoch: 61| Step: 0
Training loss: 3.594287467239614
Validation loss: 3.437569551332938

Epoch: 6| Step: 1
Training loss: 3.2636426539685277
Validation loss: 3.43800136903544

Epoch: 6| Step: 2
Training loss: 4.12665801972288
Validation loss: 3.4386800073749932

Epoch: 6| Step: 3
Training loss: 3.809404961684879
Validation loss: 3.4380451788071067

Epoch: 6| Step: 4
Training loss: 2.6337847173907427
Validation loss: 3.4395815396800646

Epoch: 6| Step: 5
Training loss: 3.4367063126249002
Validation loss: 3.4389000511007053

Epoch: 6| Step: 6
Training loss: 4.5601522597608675
Validation loss: 3.4378559334728016

Epoch: 6| Step: 7
Training loss: 3.665213137852454
Validation loss: 3.438876696538097

Epoch: 6| Step: 8
Training loss: 3.586988374068576
Validation loss: 3.4371473263840566

Epoch: 6| Step: 9
Training loss: 3.8323129595100798
Validation loss: 3.4371816985575787

Epoch: 6| Step: 10
Training loss: 4.274975710794257
Validation loss: 3.4365313032970524

Epoch: 6| Step: 11
Training loss: 3.5466939064882386
Validation loss: 3.4368088416133906

Epoch: 6| Step: 12
Training loss: 2.9950023986093535
Validation loss: 3.436403765353316

Epoch: 6| Step: 13
Training loss: 3.250957054659479
Validation loss: 3.4349100582713272

Epoch: 62| Step: 0
Training loss: 2.422218150778021
Validation loss: 3.4347168933198713

Epoch: 6| Step: 1
Training loss: 4.305349420241184
Validation loss: 3.4330304036564536

Epoch: 6| Step: 2
Training loss: 4.041434736905449
Validation loss: 3.4345134659831094

Epoch: 6| Step: 3
Training loss: 3.242409277994589
Validation loss: 3.434585249875033

Epoch: 6| Step: 4
Training loss: 2.7250990123434407
Validation loss: 3.4338136582696484

Epoch: 6| Step: 5
Training loss: 4.2374591926702845
Validation loss: 3.434094630764239

Epoch: 6| Step: 6
Training loss: 3.7249538700396467
Validation loss: 3.4327697664915773

Epoch: 6| Step: 7
Training loss: 3.190316844260529
Validation loss: 3.432319566432568

Epoch: 6| Step: 8
Training loss: 3.5277073737167024
Validation loss: 3.4324173627075645

Epoch: 6| Step: 9
Training loss: 3.2878459211756867
Validation loss: 3.4324173970645373

Epoch: 6| Step: 10
Training loss: 3.5303627182261614
Validation loss: 3.4321139921709074

Epoch: 6| Step: 11
Training loss: 3.8243357062842107
Validation loss: 3.432508922818317

Epoch: 6| Step: 12
Training loss: 5.0348191011542465
Validation loss: 3.4312407678478842

Epoch: 6| Step: 13
Training loss: 2.877724558985821
Validation loss: 3.43156078728842

Epoch: 63| Step: 0
Training loss: 3.5757686402238336
Validation loss: 3.4313643257760913

Epoch: 6| Step: 1
Training loss: 3.5664224279565295
Validation loss: 3.4306344606699235

Epoch: 6| Step: 2
Training loss: 3.9498960553749516
Validation loss: 3.4299484954552737

Epoch: 6| Step: 3
Training loss: 2.9215112143501574
Validation loss: 3.4296609043735837

Epoch: 6| Step: 4
Training loss: 4.474623228440471
Validation loss: 3.430637870501702

Epoch: 6| Step: 5
Training loss: 2.74346285557895
Validation loss: 3.4296838238658327

Epoch: 6| Step: 6
Training loss: 4.230601300728143
Validation loss: 3.4301047746717557

Epoch: 6| Step: 7
Training loss: 3.4496738224361403
Validation loss: 3.428610482789401

Epoch: 6| Step: 8
Training loss: 2.6158330800409875
Validation loss: 3.428885202057235

Epoch: 6| Step: 9
Training loss: 4.47378192712221
Validation loss: 3.429617243146761

Epoch: 6| Step: 10
Training loss: 3.9870952819353898
Validation loss: 3.427729100726765

Epoch: 6| Step: 11
Training loss: 3.465136321057332
Validation loss: 3.428709536313484

Epoch: 6| Step: 12
Training loss: 3.2378053027801004
Validation loss: 3.4273952702852926

Epoch: 6| Step: 13
Training loss: 3.872572476895191
Validation loss: 3.4273540261380515

Epoch: 64| Step: 0
Training loss: 2.758419758882362
Validation loss: 3.427648735863882

Epoch: 6| Step: 1
Training loss: 3.2744765351090077
Validation loss: 3.4279289699649707

Epoch: 6| Step: 2
Training loss: 3.2733339279650777
Validation loss: 3.427186454904346

Epoch: 6| Step: 3
Training loss: 3.382240299876098
Validation loss: 3.4277280775826338

Epoch: 6| Step: 4
Training loss: 3.4723909532028165
Validation loss: 3.4269725638157653

Epoch: 6| Step: 5
Training loss: 4.66654373188673
Validation loss: 3.4264675983235384

Epoch: 6| Step: 6
Training loss: 3.7847135460119317
Validation loss: 3.4266982597955793

Epoch: 6| Step: 7
Training loss: 4.134079852421369
Validation loss: 3.4255151338361824

Epoch: 6| Step: 8
Training loss: 3.6957543010210547
Validation loss: 3.425000823179295

Epoch: 6| Step: 9
Training loss: 3.59598504929198
Validation loss: 3.4249023383156754

Epoch: 6| Step: 10
Training loss: 3.642940717961927
Validation loss: 3.4256694690013676

Epoch: 6| Step: 11
Training loss: 3.9076996821698406
Validation loss: 3.4250034878668627

Epoch: 6| Step: 12
Training loss: 3.190373341109793
Validation loss: 3.4246567377099923

Epoch: 6| Step: 13
Training loss: 4.077927624833342
Validation loss: 3.423743049331098

Epoch: 65| Step: 0
Training loss: 3.4868962356623645
Validation loss: 3.4242956253225327

Epoch: 6| Step: 1
Training loss: 3.232028275696601
Validation loss: 3.4239559007593066

Epoch: 6| Step: 2
Training loss: 3.637602505108063
Validation loss: 3.424133776455755

Epoch: 6| Step: 3
Training loss: 2.908595625482037
Validation loss: 3.4235624261233997

Epoch: 6| Step: 4
Training loss: 3.5836589280881923
Validation loss: 3.4232953211951362

Epoch: 6| Step: 5
Training loss: 3.340325999996839
Validation loss: 3.4228161041982315

Epoch: 6| Step: 6
Training loss: 4.406848623315573
Validation loss: 3.422775750103772

Epoch: 6| Step: 7
Training loss: 3.8587470528332153
Validation loss: 3.423093608663055

Epoch: 6| Step: 8
Training loss: 3.8649751750745915
Validation loss: 3.422480799790425

Epoch: 6| Step: 9
Training loss: 4.1481708218192015
Validation loss: 3.421958563831241

Epoch: 6| Step: 10
Training loss: 3.8466597297733727
Validation loss: 3.421825870646894

Epoch: 6| Step: 11
Training loss: 3.4380527398733833
Validation loss: 3.4215527184790995

Epoch: 6| Step: 12
Training loss: 3.1238486648615087
Validation loss: 3.4216016314743087

Epoch: 6| Step: 13
Training loss: 4.0125953734284465
Validation loss: 3.4215934091769267

Epoch: 66| Step: 0
Training loss: 4.894738365717134
Validation loss: 3.42135679874726

Epoch: 6| Step: 1
Training loss: 3.252502798186263
Validation loss: 3.421465567668037

Epoch: 6| Step: 2
Training loss: 2.7009488204688803
Validation loss: 3.4208876190628525

Epoch: 6| Step: 3
Training loss: 3.270255424486264
Validation loss: 3.421446201685222

Epoch: 6| Step: 4
Training loss: 3.3184944471111915
Validation loss: 3.4199224836911006

Epoch: 6| Step: 5
Training loss: 3.754532935381738
Validation loss: 3.4203173019913713

Epoch: 6| Step: 6
Training loss: 3.3387622175203795
Validation loss: 3.420839748042063

Epoch: 6| Step: 7
Training loss: 4.326089869425924
Validation loss: 3.4200289894726703

Epoch: 6| Step: 8
Training loss: 3.255859375
Validation loss: 3.4187736232510026

Epoch: 6| Step: 9
Training loss: 3.6819706209866196
Validation loss: 3.420617370355332

Epoch: 6| Step: 10
Training loss: 3.2671262949716104
Validation loss: 3.4199570349792774

Epoch: 6| Step: 11
Training loss: 3.66085655653688
Validation loss: 3.418793304319673

Epoch: 6| Step: 12
Training loss: 4.049090511728278
Validation loss: 3.419314143332803

Epoch: 6| Step: 13
Training loss: 3.688400546526064
Validation loss: 3.418664384736372

Epoch: 67| Step: 0
Training loss: 2.890435949793456
Validation loss: 3.4170174209809088

Epoch: 6| Step: 1
Training loss: 3.4623067313008717
Validation loss: 3.4175068302261673

Epoch: 6| Step: 2
Training loss: 3.4665248022640647
Validation loss: 3.4168065818052877

Epoch: 6| Step: 3
Training loss: 3.808767273691266
Validation loss: 3.416421454269337

Epoch: 6| Step: 4
Training loss: 4.760609072658222
Validation loss: 3.416716988435818

Epoch: 6| Step: 5
Training loss: 4.066060779858428
Validation loss: 3.4167392451883516

Epoch: 6| Step: 6
Training loss: 3.0882684716544864
Validation loss: 3.416120109291589

Epoch: 6| Step: 7
Training loss: 2.7359920406950797
Validation loss: 3.4157823072889246

Epoch: 6| Step: 8
Training loss: 3.8993227150504484
Validation loss: 3.4161179164646094

Epoch: 6| Step: 9
Training loss: 2.5988977663452926
Validation loss: 3.4187596291219

Epoch: 6| Step: 10
Training loss: 3.6325814778693366
Validation loss: 3.4182205573407343

Epoch: 6| Step: 11
Training loss: 4.131148178069269
Validation loss: 3.41508086975249

Epoch: 6| Step: 12
Training loss: 4.000886103711047
Validation loss: 3.4144538273472462

Epoch: 6| Step: 13
Training loss: 3.8339295269175993
Validation loss: 3.4144224624434574

Epoch: 68| Step: 0
Training loss: 2.2167207276293865
Validation loss: 3.4150849039165885

Epoch: 6| Step: 1
Training loss: 4.016877331623964
Validation loss: 3.4158360131571364

Epoch: 6| Step: 2
Training loss: 4.478712168264135
Validation loss: 3.4136796410305887

Epoch: 6| Step: 3
Training loss: 4.123049188032274
Validation loss: 3.4131732436877664

Epoch: 6| Step: 4
Training loss: 3.851430523141364
Validation loss: 3.414051338512272

Epoch: 6| Step: 5
Training loss: 3.491032693220835
Validation loss: 3.4132142761335547

Epoch: 6| Step: 6
Training loss: 3.7212227686256294
Validation loss: 3.412531867155137

Epoch: 6| Step: 7
Training loss: 3.8419517714706726
Validation loss: 3.4137764588418427

Epoch: 6| Step: 8
Training loss: 4.407473996107883
Validation loss: 3.4127735725290704

Epoch: 6| Step: 9
Training loss: 3.3692524324745023
Validation loss: 3.412848155845154

Epoch: 6| Step: 10
Training loss: 3.4630459461782768
Validation loss: 3.411604044580618

Epoch: 6| Step: 11
Training loss: 3.258898656898158
Validation loss: 3.4115029057898463

Epoch: 6| Step: 12
Training loss: 3.1878516807276136
Validation loss: 3.4112771974426153

Epoch: 6| Step: 13
Training loss: 2.09901154279511
Validation loss: 3.412650460819926

Epoch: 69| Step: 0
Training loss: 3.4846544367525314
Validation loss: 3.413090435960903

Epoch: 6| Step: 1
Training loss: 3.4315044482442847
Validation loss: 3.414725691493185

Epoch: 6| Step: 2
Training loss: 4.403984190674279
Validation loss: 3.4137121692737518

Epoch: 6| Step: 3
Training loss: 3.3944084751063803
Validation loss: 3.415520368939808

Epoch: 6| Step: 4
Training loss: 3.399268879539433
Validation loss: 3.4148678780375463

Epoch: 6| Step: 5
Training loss: 3.428020654444749
Validation loss: 3.415032797223387

Epoch: 6| Step: 6
Training loss: 3.4347556516757853
Validation loss: 3.413015494389209

Epoch: 6| Step: 7
Training loss: 3.737601063870579
Validation loss: 3.4124849156478994

Epoch: 6| Step: 8
Training loss: 3.261929113491412
Validation loss: 3.410989121920872

Epoch: 6| Step: 9
Training loss: 3.840607141339938
Validation loss: 3.411452274400105

Epoch: 6| Step: 10
Training loss: 3.9985144956210794
Validation loss: 3.4099497290261085

Epoch: 6| Step: 11
Training loss: 3.966404980487782
Validation loss: 3.4099279519743426

Epoch: 6| Step: 12
Training loss: 3.078307170608725
Validation loss: 3.409533300573084

Epoch: 6| Step: 13
Training loss: 3.9528861595647444
Validation loss: 3.4097141271091775

Epoch: 70| Step: 0
Training loss: 3.1100570467411646
Validation loss: 3.409161880527544

Epoch: 6| Step: 1
Training loss: 4.0039808015163025
Validation loss: 3.4086878725561762

Epoch: 6| Step: 2
Training loss: 2.839633183497701
Validation loss: 3.4077198251333725

Epoch: 6| Step: 3
Training loss: 4.0004501089525855
Validation loss: 3.4084684762809694

Epoch: 6| Step: 4
Training loss: 4.039917137882537
Validation loss: 3.408000409364712

Epoch: 6| Step: 5
Training loss: 3.8961382795856134
Validation loss: 3.406767571858514

Epoch: 6| Step: 6
Training loss: 3.2730683548756625
Validation loss: 3.4073178462466935

Epoch: 6| Step: 7
Training loss: 3.401168252284306
Validation loss: 3.407014516965847

Epoch: 6| Step: 8
Training loss: 3.8252707292077246
Validation loss: 3.406478987033314

Epoch: 6| Step: 9
Training loss: 4.0009025509157095
Validation loss: 3.4071759879506742

Epoch: 6| Step: 10
Training loss: 3.7168121417759896
Validation loss: 3.4059595452894618

Epoch: 6| Step: 11
Training loss: 3.680484628693724
Validation loss: 3.405648711201909

Epoch: 6| Step: 12
Training loss: 3.2819425306199363
Validation loss: 3.405568762494241

Epoch: 6| Step: 13
Training loss: 3.3999628962567887
Validation loss: 3.4062171566416453

Epoch: 71| Step: 0
Training loss: 4.388306572399456
Validation loss: 3.410412711452665

Epoch: 6| Step: 1
Training loss: 3.657795375700785
Validation loss: 3.42398280425225

Epoch: 6| Step: 2
Training loss: 4.009587480440558
Validation loss: 3.4415625690962903

Epoch: 6| Step: 3
Training loss: 4.065410099903269
Validation loss: 3.4402950583814924

Epoch: 6| Step: 4
Training loss: 3.0205867447454207
Validation loss: 3.4237540504334474

Epoch: 6| Step: 5
Training loss: 4.896292330822087
Validation loss: 3.4138434145901995

Epoch: 6| Step: 6
Training loss: 3.0998708882670876
Validation loss: 3.4032861211156207

Epoch: 6| Step: 7
Training loss: 2.97683770617107
Validation loss: 3.40383651621939

Epoch: 6| Step: 8
Training loss: 3.146307970497301
Validation loss: 3.405063885880654

Epoch: 6| Step: 9
Training loss: 3.3398186219814954
Validation loss: 3.4039917740314007

Epoch: 6| Step: 10
Training loss: 3.6414340843343243
Validation loss: 3.409257255030817

Epoch: 6| Step: 11
Training loss: 3.348110030231404
Validation loss: 3.4115727556746123

Epoch: 6| Step: 12
Training loss: 2.8663415310431883
Validation loss: 3.4050289244726772

Epoch: 6| Step: 13
Training loss: 4.023574263831523
Validation loss: 3.405987754586894

Epoch: 72| Step: 0
Training loss: 2.563285242116529
Validation loss: 3.406248967393619

Epoch: 6| Step: 1
Training loss: 3.4582722823181378
Validation loss: 3.4051097245641824

Epoch: 6| Step: 2
Training loss: 3.1144208748761395
Validation loss: 3.4068410909403526

Epoch: 6| Step: 3
Training loss: 4.523123142209896
Validation loss: 3.4025116164619376

Epoch: 6| Step: 4
Training loss: 3.5667200357835305
Validation loss: 3.4051063441291602

Epoch: 6| Step: 5
Training loss: 3.438801051058669
Validation loss: 3.4015131114524753

Epoch: 6| Step: 6
Training loss: 4.145265447678094
Validation loss: 3.4021417386807324

Epoch: 6| Step: 7
Training loss: 3.3607307005128555
Validation loss: 3.402016569314552

Epoch: 6| Step: 8
Training loss: 2.858742232218315
Validation loss: 3.401490332256431

Epoch: 6| Step: 9
Training loss: 4.392288707325712
Validation loss: 3.4009560521465714

Epoch: 6| Step: 10
Training loss: 4.110112461305661
Validation loss: 3.4008381708613

Epoch: 6| Step: 11
Training loss: 3.148396001878346
Validation loss: 3.4012919936566663

Epoch: 6| Step: 12
Training loss: 3.90052864697737
Validation loss: 3.4008421563376494

Epoch: 6| Step: 13
Training loss: 3.665529652792083
Validation loss: 3.4003722171092354

Epoch: 73| Step: 0
Training loss: 3.517495162299001
Validation loss: 3.4006646492310457

Epoch: 6| Step: 1
Training loss: 4.032037702384152
Validation loss: 3.4009808324771393

Epoch: 6| Step: 2
Training loss: 3.358635115651578
Validation loss: 3.400517907831816

Epoch: 6| Step: 3
Training loss: 3.1606153760555693
Validation loss: 3.4009094896024923

Epoch: 6| Step: 4
Training loss: 3.4813366973326945
Validation loss: 3.4019657696111105

Epoch: 6| Step: 5
Training loss: 3.594106772584367
Validation loss: 3.40156300899556

Epoch: 6| Step: 6
Training loss: 3.2494758770210614
Validation loss: 3.4032381305666806

Epoch: 6| Step: 7
Training loss: 3.8019880866396343
Validation loss: 3.401235242172602

Epoch: 6| Step: 8
Training loss: 3.5948580153311513
Validation loss: 3.399407530116444

Epoch: 6| Step: 9
Training loss: 3.7145669956386427
Validation loss: 3.4002802952846776

Epoch: 6| Step: 10
Training loss: 3.4039508864807733
Validation loss: 3.4004135156039244

Epoch: 6| Step: 11
Training loss: 3.6794941521323516
Validation loss: 3.397502247236761

Epoch: 6| Step: 12
Training loss: 4.08346173350552
Validation loss: 3.397390023267728

Epoch: 6| Step: 13
Training loss: 4.174495945272282
Validation loss: 3.397198722974363

Epoch: 74| Step: 0
Training loss: 4.072898116723995
Validation loss: 3.394116357472225

Epoch: 6| Step: 1
Training loss: 4.3087101745092955
Validation loss: 3.3957110806419104

Epoch: 6| Step: 2
Training loss: 3.2790902432200846
Validation loss: 3.394262387709804

Epoch: 6| Step: 3
Training loss: 2.969621068754764
Validation loss: 3.3945827560702133

Epoch: 6| Step: 4
Training loss: 3.6830860164229287
Validation loss: 3.3943034131152063

Epoch: 6| Step: 5
Training loss: 4.282937935318242
Validation loss: 3.393200563698647

Epoch: 6| Step: 6
Training loss: 4.222301655295432
Validation loss: 3.3934238042975156

Epoch: 6| Step: 7
Training loss: 3.38284308791923
Validation loss: 3.3932001632715014

Epoch: 6| Step: 8
Training loss: 3.9796908501025725
Validation loss: 3.392866016789293

Epoch: 6| Step: 9
Training loss: 3.5921229120647946
Validation loss: 3.393063149438332

Epoch: 6| Step: 10
Training loss: 3.745066130885679
Validation loss: 3.392834237726321

Epoch: 6| Step: 11
Training loss: 2.7344764036721894
Validation loss: 3.3920391852246086

Epoch: 6| Step: 12
Training loss: 2.510605347271314
Validation loss: 3.3925588767359636

Epoch: 6| Step: 13
Training loss: 3.146080782086587
Validation loss: 3.392387822941328

Epoch: 75| Step: 0
Training loss: 3.235880625697909
Validation loss: 3.3910914992784433

Epoch: 6| Step: 1
Training loss: 4.113859449360393
Validation loss: 3.390689727315085

Epoch: 6| Step: 2
Training loss: 3.538180681392584
Validation loss: 3.39144637697657

Epoch: 6| Step: 3
Training loss: 3.895028804726409
Validation loss: 3.3908169977795852

Epoch: 6| Step: 4
Training loss: 4.061087494825124
Validation loss: 3.390522359821127

Epoch: 6| Step: 5
Training loss: 3.1453738013792307
Validation loss: 3.39130553826684

Epoch: 6| Step: 6
Training loss: 3.431545440795394
Validation loss: 3.391338057355099

Epoch: 6| Step: 7
Training loss: 4.293851475300858
Validation loss: 3.389241450763903

Epoch: 6| Step: 8
Training loss: 2.5074447409720357
Validation loss: 3.3899194550311633

Epoch: 6| Step: 9
Training loss: 4.106493037215242
Validation loss: 3.391484400732222

Epoch: 6| Step: 10
Training loss: 3.8287762769095672
Validation loss: 3.390753080374964

Epoch: 6| Step: 11
Training loss: 3.222550601961457
Validation loss: 3.391111265407644

Epoch: 6| Step: 12
Training loss: 3.3204621404698993
Validation loss: 3.3901491639821004

Epoch: 6| Step: 13
Training loss: 3.4642974870169922
Validation loss: 3.388427775514422

Epoch: 76| Step: 0
Training loss: 2.681357972431966
Validation loss: 3.3905234546822274

Epoch: 6| Step: 1
Training loss: 4.4654161515193636
Validation loss: 3.3898927682298874

Epoch: 6| Step: 2
Training loss: 3.7712289732592477
Validation loss: 3.389638543377834

Epoch: 6| Step: 3
Training loss: 3.2095399214316034
Validation loss: 3.389967912425352

Epoch: 6| Step: 4
Training loss: 2.6208348608290484
Validation loss: 3.390407616720171

Epoch: 6| Step: 5
Training loss: 4.065549674131658
Validation loss: 3.389834222605137

Epoch: 6| Step: 6
Training loss: 3.844836693955419
Validation loss: 3.389724458366849

Epoch: 6| Step: 7
Training loss: 4.214790577239319
Validation loss: 3.3905696260442486

Epoch: 6| Step: 8
Training loss: 3.0130871782221793
Validation loss: 3.391854768757327

Epoch: 6| Step: 9
Training loss: 3.172817447252342
Validation loss: 3.391087380627364

Epoch: 6| Step: 10
Training loss: 3.863641889843584
Validation loss: 3.3901517592694663

Epoch: 6| Step: 11
Training loss: 3.8248327929283215
Validation loss: 3.3891949141131685

Epoch: 6| Step: 12
Training loss: 3.739588207075225
Validation loss: 3.3889265944814517

Epoch: 6| Step: 13
Training loss: 3.522920760940588
Validation loss: 3.388355254354718

Epoch: 77| Step: 0
Training loss: 3.82141209791068
Validation loss: 3.3870238219616793

Epoch: 6| Step: 1
Training loss: 3.515885949516816
Validation loss: 3.3877003554825893

Epoch: 6| Step: 2
Training loss: 2.562418680528951
Validation loss: 3.38688235881172

Epoch: 6| Step: 3
Training loss: 4.412818287724809
Validation loss: 3.385730985654082

Epoch: 6| Step: 4
Training loss: 3.4082912663208673
Validation loss: 3.385787132319303

Epoch: 6| Step: 5
Training loss: 2.511489596673986
Validation loss: 3.38556266122793

Epoch: 6| Step: 6
Training loss: 3.9367208769637907
Validation loss: 3.3865237719178336

Epoch: 6| Step: 7
Training loss: 4.326893545196698
Validation loss: 3.385148911154023

Epoch: 6| Step: 8
Training loss: 3.51900241956007
Validation loss: 3.385070392830798

Epoch: 6| Step: 9
Training loss: 3.9149726829696316
Validation loss: 3.384708038957955

Epoch: 6| Step: 10
Training loss: 3.15635877365166
Validation loss: 3.384656796175869

Epoch: 6| Step: 11
Training loss: 3.656744507824933
Validation loss: 3.384070579413385

Epoch: 6| Step: 12
Training loss: 3.3120786290901787
Validation loss: 3.38448083000603

Epoch: 6| Step: 13
Training loss: 4.157957256998368
Validation loss: 3.384230010476974

Epoch: 78| Step: 0
Training loss: 3.9542585715308127
Validation loss: 3.384055423609687

Epoch: 6| Step: 1
Training loss: 3.9267703200574866
Validation loss: 3.3830780165331293

Epoch: 6| Step: 2
Training loss: 4.1070218038785935
Validation loss: 3.3829041628954113

Epoch: 6| Step: 3
Training loss: 3.2320148499874737
Validation loss: 3.382940004674942

Epoch: 6| Step: 4
Training loss: 3.024694689010935
Validation loss: 3.382864399719092

Epoch: 6| Step: 5
Training loss: 3.364473386371564
Validation loss: 3.3824478851337676

Epoch: 6| Step: 6
Training loss: 3.0760790226561943
Validation loss: 3.3825122990207377

Epoch: 6| Step: 7
Training loss: 3.385647825516602
Validation loss: 3.3815396193866403

Epoch: 6| Step: 8
Training loss: 3.2915261797964113
Validation loss: 3.381463372054998

Epoch: 6| Step: 9
Training loss: 3.4760341285636787
Validation loss: 3.381659175610775

Epoch: 6| Step: 10
Training loss: 3.8850966552729402
Validation loss: 3.3820490719876237

Epoch: 6| Step: 11
Training loss: 3.902130640452245
Validation loss: 3.380820708526085

Epoch: 6| Step: 12
Training loss: 3.929883826870738
Validation loss: 3.381280635899436

Epoch: 6| Step: 13
Training loss: 3.8110188593201357
Validation loss: 3.3807956818488383

Epoch: 79| Step: 0
Training loss: 4.141048308992798
Validation loss: 3.379586433889658

Epoch: 6| Step: 1
Training loss: 3.800143997074129
Validation loss: 3.380359295830767

Epoch: 6| Step: 2
Training loss: 3.3651351869813726
Validation loss: 3.3800217819871197

Epoch: 6| Step: 3
Training loss: 3.197415207968148
Validation loss: 3.3796459034532154

Epoch: 6| Step: 4
Training loss: 4.051340592409273
Validation loss: 3.379721263339303

Epoch: 6| Step: 5
Training loss: 3.1960613986671618
Validation loss: 3.38010953415653

Epoch: 6| Step: 6
Training loss: 3.850666057886021
Validation loss: 3.3793973513794633

Epoch: 6| Step: 7
Training loss: 3.1828306816529355
Validation loss: 3.3783927660566144

Epoch: 6| Step: 8
Training loss: 4.5189439660701085
Validation loss: 3.379254911985642

Epoch: 6| Step: 9
Training loss: 3.0290409179220887
Validation loss: 3.378656182112611

Epoch: 6| Step: 10
Training loss: 4.172519134057058
Validation loss: 3.3782893186502303

Epoch: 6| Step: 11
Training loss: 2.2301504038224493
Validation loss: 3.3789315547039442

Epoch: 6| Step: 12
Training loss: 3.83686683724755
Validation loss: 3.378402137648412

Epoch: 6| Step: 13
Training loss: 2.957698288217298
Validation loss: 3.377343929019086

Epoch: 80| Step: 0
Training loss: 3.886935894138415
Validation loss: 3.3780480312491297

Epoch: 6| Step: 1
Training loss: 2.632531668969751
Validation loss: 3.377432953099751

Epoch: 6| Step: 2
Training loss: 4.170097286635515
Validation loss: 3.3776798645721477

Epoch: 6| Step: 3
Training loss: 3.0869491271043126
Validation loss: 3.3765157761808684

Epoch: 6| Step: 4
Training loss: 4.093832932425709
Validation loss: 3.3763666580017335

Epoch: 6| Step: 5
Training loss: 4.116866444876633
Validation loss: 3.3770394462229825

Epoch: 6| Step: 6
Training loss: 3.294957186199347
Validation loss: 3.3773909697808167

Epoch: 6| Step: 7
Training loss: 3.1167372758452174
Validation loss: 3.376383859667468

Epoch: 6| Step: 8
Training loss: 3.2793404972158178
Validation loss: 3.3766000100532523

Epoch: 6| Step: 9
Training loss: 3.726900161384424
Validation loss: 3.376493751604345

Epoch: 6| Step: 10
Training loss: 3.0537187449932173
Validation loss: 3.375972270495653

Epoch: 6| Step: 11
Training loss: 4.304366028788681
Validation loss: 3.375846042728866

Epoch: 6| Step: 12
Training loss: 3.6356905129956565
Validation loss: 3.3747211145097387

Epoch: 6| Step: 13
Training loss: 3.552160148498524
Validation loss: 3.374597822478509

Epoch: 81| Step: 0
Training loss: 3.5019561205892096
Validation loss: 3.374372120815731

Epoch: 6| Step: 1
Training loss: 3.8310682543014307
Validation loss: 3.3743734199684283

Epoch: 6| Step: 2
Training loss: 3.843769228507227
Validation loss: 3.373829867786496

Epoch: 6| Step: 3
Training loss: 3.144319856539645
Validation loss: 3.373985469226891

Epoch: 6| Step: 4
Training loss: 4.103715720148265
Validation loss: 3.373622187673136

Epoch: 6| Step: 5
Training loss: 3.499720698520293
Validation loss: 3.3727111529627005

Epoch: 6| Step: 6
Training loss: 3.5472602803030706
Validation loss: 3.3734310761749318

Epoch: 6| Step: 7
Training loss: 3.915648970717043
Validation loss: 3.3732385174611412

Epoch: 6| Step: 8
Training loss: 3.876864569202728
Validation loss: 3.3733021587484675

Epoch: 6| Step: 9
Training loss: 2.9597208950835943
Validation loss: 3.372695410231494

Epoch: 6| Step: 10
Training loss: 3.7811387731413575
Validation loss: 3.3726915161536244

Epoch: 6| Step: 11
Training loss: 3.3625464794250717
Validation loss: 3.3719670512694897

Epoch: 6| Step: 12
Training loss: 3.4523880806584675
Validation loss: 3.371800851387249

Epoch: 6| Step: 13
Training loss: 3.247589684731736
Validation loss: 3.371521108933106

Epoch: 82| Step: 0
Training loss: 3.056206289029508
Validation loss: 3.3717483753561766

Epoch: 6| Step: 1
Training loss: 3.6547699891656733
Validation loss: 3.3707384073289584

Epoch: 6| Step: 2
Training loss: 3.6902582230195593
Validation loss: 3.3700750430585273

Epoch: 6| Step: 3
Training loss: 4.495055979548791
Validation loss: 3.3711374132880607

Epoch: 6| Step: 4
Training loss: 3.61662535284913
Validation loss: 3.371324790328695

Epoch: 6| Step: 5
Training loss: 2.9488895459890254
Validation loss: 3.369990965597792

Epoch: 6| Step: 6
Training loss: 3.32880462727719
Validation loss: 3.370281655473482

Epoch: 6| Step: 7
Training loss: 4.36049755232228
Validation loss: 3.3698974436561726

Epoch: 6| Step: 8
Training loss: 3.888290010993872
Validation loss: 3.369543330620506

Epoch: 6| Step: 9
Training loss: 3.968527479767025
Validation loss: 3.3701486711123225

Epoch: 6| Step: 10
Training loss: 2.7329729245767744
Validation loss: 3.3699714148761073

Epoch: 6| Step: 11
Training loss: 3.2472026230092155
Validation loss: 3.368937852442728

Epoch: 6| Step: 12
Training loss: 3.419681769394729
Validation loss: 3.3698336604711043

Epoch: 6| Step: 13
Training loss: 3.4214951117075234
Validation loss: 3.370119938182021

Epoch: 83| Step: 0
Training loss: 3.4837806092044383
Validation loss: 3.3691997843537935

Epoch: 6| Step: 1
Training loss: 3.833243051101555
Validation loss: 3.370250749689559

Epoch: 6| Step: 2
Training loss: 2.9095863142621496
Validation loss: 3.3678634266247474

Epoch: 6| Step: 3
Training loss: 3.199637845527099
Validation loss: 3.3695681213268363

Epoch: 6| Step: 4
Training loss: 4.216040751526279
Validation loss: 3.370153614076642

Epoch: 6| Step: 5
Training loss: 3.892990434996924
Validation loss: 3.3675289555273937

Epoch: 6| Step: 6
Training loss: 3.177212438409522
Validation loss: 3.366810575431272

Epoch: 6| Step: 7
Training loss: 3.3428708640947637
Validation loss: 3.3665502761009374

Epoch: 6| Step: 8
Training loss: 3.9294219941680932
Validation loss: 3.3655260256888604

Epoch: 6| Step: 9
Training loss: 3.7426080965116704
Validation loss: 3.3666559940056473

Epoch: 6| Step: 10
Training loss: 3.3072690146964594
Validation loss: 3.3668122551782327

Epoch: 6| Step: 11
Training loss: 4.332766911582877
Validation loss: 3.366375366331546

Epoch: 6| Step: 12
Training loss: 3.369306495011135
Validation loss: 3.366787407629995

Epoch: 6| Step: 13
Training loss: 3.002645597588366
Validation loss: 3.365484433150315

Epoch: 84| Step: 0
Training loss: 4.415536172004403
Validation loss: 3.3653795514299096

Epoch: 6| Step: 1
Training loss: 3.5203597673882285
Validation loss: 3.3654338422436365

Epoch: 6| Step: 2
Training loss: 3.5244988917212248
Validation loss: 3.364630948200329

Epoch: 6| Step: 3
Training loss: 3.217899543479229
Validation loss: 3.3646989398249203

Epoch: 6| Step: 4
Training loss: 3.8892289073588158
Validation loss: 3.364134017357657

Epoch: 6| Step: 5
Training loss: 3.7550687230471733
Validation loss: 3.363939275002617

Epoch: 6| Step: 6
Training loss: 4.228332938461275
Validation loss: 3.36325546014082

Epoch: 6| Step: 7
Training loss: 3.554108222460032
Validation loss: 3.363771803549544

Epoch: 6| Step: 8
Training loss: 2.7362859533465147
Validation loss: 3.363398886569162

Epoch: 6| Step: 9
Training loss: 3.4257946122886493
Validation loss: 3.362894353901352

Epoch: 6| Step: 10
Training loss: 2.6642942803200245
Validation loss: 3.3639296695460192

Epoch: 6| Step: 11
Training loss: 2.8866031195126354
Validation loss: 3.3625634628377705

Epoch: 6| Step: 12
Training loss: 4.030168018482871
Validation loss: 3.362523660402333

Epoch: 6| Step: 13
Training loss: 4.176797655694637
Validation loss: 3.3623862215002114

Epoch: 85| Step: 0
Training loss: 4.081076770511861
Validation loss: 3.3614079590567907

Epoch: 6| Step: 1
Training loss: 2.6056014317439185
Validation loss: 3.3625687813821274

Epoch: 6| Step: 2
Training loss: 4.057982529995061
Validation loss: 3.3615973380880986

Epoch: 6| Step: 3
Training loss: 3.9890073886744575
Validation loss: 3.360876146236891

Epoch: 6| Step: 4
Training loss: 3.240336944814563
Validation loss: 3.3613208931958587

Epoch: 6| Step: 5
Training loss: 3.7019518833011396
Validation loss: 3.3605657879961077

Epoch: 6| Step: 6
Training loss: 3.816987820124913
Validation loss: 3.3610983943560218

Epoch: 6| Step: 7
Training loss: 3.6067934258186067
Validation loss: 3.3606526308367237

Epoch: 6| Step: 8
Training loss: 3.889684234002367
Validation loss: 3.360628100860499

Epoch: 6| Step: 9
Training loss: 3.519453752788574
Validation loss: 3.3597862440275414

Epoch: 6| Step: 10
Training loss: 3.0970626204518372
Validation loss: 3.360913484569686

Epoch: 6| Step: 11
Training loss: 3.161457713261669
Validation loss: 3.360404051717918

Epoch: 6| Step: 12
Training loss: 3.692011901580044
Validation loss: 3.3590941914409322

Epoch: 6| Step: 13
Training loss: 3.387466999188813
Validation loss: 3.358470358241864

Epoch: 86| Step: 0
Training loss: 3.9510530009845928
Validation loss: 3.3585164924136803

Epoch: 6| Step: 1
Training loss: 3.136664935228746
Validation loss: 3.358689706305778

Epoch: 6| Step: 2
Training loss: 3.9267420262055226
Validation loss: 3.3595696398855233

Epoch: 6| Step: 3
Training loss: 3.899529130337981
Validation loss: 3.358554618769749

Epoch: 6| Step: 4
Training loss: 4.832937860204257
Validation loss: 3.3588886402091007

Epoch: 6| Step: 5
Training loss: 3.3460813576884987
Validation loss: 3.3583318236781796

Epoch: 6| Step: 6
Training loss: 3.229095425383919
Validation loss: 3.357757825483665

Epoch: 6| Step: 7
Training loss: 3.035391740733699
Validation loss: 3.3583208418585087

Epoch: 6| Step: 8
Training loss: 3.525909436374625
Validation loss: 3.357590466417635

Epoch: 6| Step: 9
Training loss: 2.7171994753590694
Validation loss: 3.3575108103604485

Epoch: 6| Step: 10
Training loss: 3.8454149563504116
Validation loss: 3.3579582552285987

Epoch: 6| Step: 11
Training loss: 4.009849343073926
Validation loss: 3.35632314258006

Epoch: 6| Step: 12
Training loss: 2.7992178199078745
Validation loss: 3.3567161956884357

Epoch: 6| Step: 13
Training loss: 3.19970759009466
Validation loss: 3.356892793999985

Epoch: 87| Step: 0
Training loss: 4.03477714064941
Validation loss: 3.35687538171974

Epoch: 6| Step: 1
Training loss: 3.319827917304253
Validation loss: 3.355665072595924

Epoch: 6| Step: 2
Training loss: 3.4252816578684415
Validation loss: 3.354625917847411

Epoch: 6| Step: 3
Training loss: 4.277922736570107
Validation loss: 3.355591452204486

Epoch: 6| Step: 4
Training loss: 3.16191906323922
Validation loss: 3.355405858453111

Epoch: 6| Step: 5
Training loss: 2.96664161100058
Validation loss: 3.3558780953811387

Epoch: 6| Step: 6
Training loss: 3.2491357094274114
Validation loss: 3.3553715119401013

Epoch: 6| Step: 7
Training loss: 3.9076861373683984
Validation loss: 3.35549542178435

Epoch: 6| Step: 8
Training loss: 4.30848993918174
Validation loss: 3.356147855639322

Epoch: 6| Step: 9
Training loss: 2.6532369241819107
Validation loss: 3.35560261867386

Epoch: 6| Step: 10
Training loss: 3.7027185917218204
Validation loss: 3.3555082816190587

Epoch: 6| Step: 11
Training loss: 3.464487291856411
Validation loss: 3.354908533943368

Epoch: 6| Step: 12
Training loss: 3.777991285710864
Validation loss: 3.3576920976072255

Epoch: 6| Step: 13
Training loss: 3.4690267091648237
Validation loss: 3.3555594332018237

Epoch: 88| Step: 0
Training loss: 3.951582174074936
Validation loss: 3.35368966896987

Epoch: 6| Step: 1
Training loss: 3.264112496438243
Validation loss: 3.354739349235228

Epoch: 6| Step: 2
Training loss: 3.508175429704315
Validation loss: 3.3560013860981037

Epoch: 6| Step: 3
Training loss: 3.7051510962025445
Validation loss: 3.3533567748747526

Epoch: 6| Step: 4
Training loss: 4.23451959004174
Validation loss: 3.351312844260993

Epoch: 6| Step: 5
Training loss: 3.5607188272727366
Validation loss: 3.3519435529892707

Epoch: 6| Step: 6
Training loss: 2.9464180487903113
Validation loss: 3.351618591844307

Epoch: 6| Step: 7
Training loss: 3.4032845844161215
Validation loss: 3.3517908711277515

Epoch: 6| Step: 8
Training loss: 3.6527897037235673
Validation loss: 3.351585295743298

Epoch: 6| Step: 9
Training loss: 3.113597513980402
Validation loss: 3.3498709738747037

Epoch: 6| Step: 10
Training loss: 3.6093969303141935
Validation loss: 3.350864606891924

Epoch: 6| Step: 11
Training loss: 3.159424648781503
Validation loss: 3.3503252820731695

Epoch: 6| Step: 12
Training loss: 3.981066717842601
Validation loss: 3.3504893672639793

Epoch: 6| Step: 13
Training loss: 3.9959159505747386
Validation loss: 3.349683012066679

Epoch: 89| Step: 0
Training loss: 4.285020935648426
Validation loss: 3.350485487930508

Epoch: 6| Step: 1
Training loss: 4.408643140284651
Validation loss: 3.350253826192728

Epoch: 6| Step: 2
Training loss: 2.5899255892105675
Validation loss: 3.3500027291206136

Epoch: 6| Step: 3
Training loss: 3.2096672422779817
Validation loss: 3.3493657627955034

Epoch: 6| Step: 4
Training loss: 2.896405024094288
Validation loss: 3.349777591236106

Epoch: 6| Step: 5
Training loss: 3.3587285329106438
Validation loss: 3.3485084496506796

Epoch: 6| Step: 6
Training loss: 4.446706972144462
Validation loss: 3.3486507285155858

Epoch: 6| Step: 7
Training loss: 3.5247459265946954
Validation loss: 3.3489692014296093

Epoch: 6| Step: 8
Training loss: 2.655572872247281
Validation loss: 3.348789599266571

Epoch: 6| Step: 9
Training loss: 3.9241500274333516
Validation loss: 3.348537459129976

Epoch: 6| Step: 10
Training loss: 3.1440726567771535
Validation loss: 3.3472593482416033

Epoch: 6| Step: 11
Training loss: 4.1573363297039565
Validation loss: 3.3474657161938137

Epoch: 6| Step: 12
Training loss: 3.2154559714746815
Validation loss: 3.347711613937322

Epoch: 6| Step: 13
Training loss: 3.563709120768519
Validation loss: 3.3473173012892006

Epoch: 90| Step: 0
Training loss: 3.1138359542492897
Validation loss: 3.347651638339367

Epoch: 6| Step: 1
Training loss: 2.6881591520820725
Validation loss: 3.34690255814537

Epoch: 6| Step: 2
Training loss: 4.123673196744005
Validation loss: 3.3470682013048143

Epoch: 6| Step: 3
Training loss: 4.096729853871923
Validation loss: 3.346935157843802

Epoch: 6| Step: 4
Training loss: 2.930885985328768
Validation loss: 3.345535356773073

Epoch: 6| Step: 5
Training loss: 3.1538841520815213
Validation loss: 3.3461253220780125

Epoch: 6| Step: 6
Training loss: 3.4494178170188645
Validation loss: 3.3463437609747975

Epoch: 6| Step: 7
Training loss: 4.131989539547703
Validation loss: 3.346024768479132

Epoch: 6| Step: 8
Training loss: 3.313123968124589
Validation loss: 3.3456331718933225

Epoch: 6| Step: 9
Training loss: 4.132032930226308
Validation loss: 3.344960032578887

Epoch: 6| Step: 10
Training loss: 4.345896897014187
Validation loss: 3.3448403587231743

Epoch: 6| Step: 11
Training loss: 3.380309273378903
Validation loss: 3.344766049392631

Epoch: 6| Step: 12
Training loss: 3.546637304466527
Validation loss: 3.3447576489436206

Epoch: 6| Step: 13
Training loss: 2.786862314952068
Validation loss: 3.3449149929017596

Epoch: 91| Step: 0
Training loss: 3.098950263688723
Validation loss: 3.344663541011622

Epoch: 6| Step: 1
Training loss: 3.8833335358015235
Validation loss: 3.3444638314983957

Epoch: 6| Step: 2
Training loss: 4.029993142247577
Validation loss: 3.3445785304072615

Epoch: 6| Step: 3
Training loss: 4.314761246212402
Validation loss: 3.3434810413336438

Epoch: 6| Step: 4
Training loss: 2.9666141255330145
Validation loss: 3.3435290760732577

Epoch: 6| Step: 5
Training loss: 4.477101025635897
Validation loss: 3.3431929671664733

Epoch: 6| Step: 6
Training loss: 3.017592820807662
Validation loss: 3.3422095931274085

Epoch: 6| Step: 7
Training loss: 3.060631006541482
Validation loss: 3.3434650551591365

Epoch: 6| Step: 8
Training loss: 2.7138076232105877
Validation loss: 3.342041003639245

Epoch: 6| Step: 9
Training loss: 3.7078808854938616
Validation loss: 3.3430154089529345

Epoch: 6| Step: 10
Training loss: 3.8948674492079207
Validation loss: 3.3432332742607263

Epoch: 6| Step: 11
Training loss: 3.613689271726042
Validation loss: 3.342977809363388

Epoch: 6| Step: 12
Training loss: 3.1397682653552375
Validation loss: 3.3424874115593797

Epoch: 6| Step: 13
Training loss: 3.5908528467301633
Validation loss: 3.341350841309525

Epoch: 92| Step: 0
Training loss: 3.851192557189114
Validation loss: 3.3418251855756593

Epoch: 6| Step: 1
Training loss: 3.98555053124526
Validation loss: 3.342897990697112

Epoch: 6| Step: 2
Training loss: 4.419287905400632
Validation loss: 3.341323939995035

Epoch: 6| Step: 3
Training loss: 3.1163841493501407
Validation loss: 3.3399768878848666

Epoch: 6| Step: 4
Training loss: 3.344251933705616
Validation loss: 3.341221074343705

Epoch: 6| Step: 5
Training loss: 3.287954402022673
Validation loss: 3.340752244676234

Epoch: 6| Step: 6
Training loss: 3.7461146253654536
Validation loss: 3.3400605572776474

Epoch: 6| Step: 7
Training loss: 3.520143580542805
Validation loss: 3.3400441571426795

Epoch: 6| Step: 8
Training loss: 3.5933041503325147
Validation loss: 3.338821795356856

Epoch: 6| Step: 9
Training loss: 4.066987361666024
Validation loss: 3.3394589288609646

Epoch: 6| Step: 10
Training loss: 3.1073000324753464
Validation loss: 3.338868908946377

Epoch: 6| Step: 11
Training loss: 3.5042690399734724
Validation loss: 3.3385395621290117

Epoch: 6| Step: 12
Training loss: 2.391577836180288
Validation loss: 3.3389996748512263

Epoch: 6| Step: 13
Training loss: 3.68498325131879
Validation loss: 3.3390684801445714

Epoch: 93| Step: 0
Training loss: 2.724018473110214
Validation loss: 3.3386656638780376

Epoch: 6| Step: 1
Training loss: 3.934444513532491
Validation loss: 3.3402386731994627

Epoch: 6| Step: 2
Training loss: 3.8779216949757096
Validation loss: 3.3377155313786258

Epoch: 6| Step: 3
Training loss: 4.149605164646504
Validation loss: 3.3385180426306276

Epoch: 6| Step: 4
Training loss: 3.3417945919775955
Validation loss: 3.338221209293487

Epoch: 6| Step: 5
Training loss: 3.3381189008213155
Validation loss: 3.337086950341876

Epoch: 6| Step: 6
Training loss: 2.9005908627218133
Validation loss: 3.33801619906274

Epoch: 6| Step: 7
Training loss: 3.7542715539932705
Validation loss: 3.3370324656945938

Epoch: 6| Step: 8
Training loss: 3.46394675426659
Validation loss: 3.3374092644308107

Epoch: 6| Step: 9
Training loss: 4.242993357289743
Validation loss: 3.337006051974596

Epoch: 6| Step: 10
Training loss: 3.4972027090705047
Validation loss: 3.3363542163202

Epoch: 6| Step: 11
Training loss: 3.8712691528122436
Validation loss: 3.3365969268269278

Epoch: 6| Step: 12
Training loss: 3.4068513391933144
Validation loss: 3.3347859698823963

Epoch: 6| Step: 13
Training loss: 2.6657356087207535
Validation loss: 3.335858416644774

Epoch: 94| Step: 0
Training loss: 3.25195415141688
Validation loss: 3.335395266518619

Epoch: 6| Step: 1
Training loss: 4.125328282095692
Validation loss: 3.33552396583423

Epoch: 6| Step: 2
Training loss: 3.6000099393919323
Validation loss: 3.335922354529098

Epoch: 6| Step: 3
Training loss: 3.660488443353004
Validation loss: 3.3355933685257986

Epoch: 6| Step: 4
Training loss: 3.034683642419801
Validation loss: 3.3345732710521188

Epoch: 6| Step: 5
Training loss: 3.0032283578605887
Validation loss: 3.335172615413421

Epoch: 6| Step: 6
Training loss: 3.1786102794642535
Validation loss: 3.3339859236488416

Epoch: 6| Step: 7
Training loss: 4.050737930698939
Validation loss: 3.333519068024594

Epoch: 6| Step: 8
Training loss: 4.126679512049126
Validation loss: 3.332320381400392

Epoch: 6| Step: 9
Training loss: 4.1415355904687265
Validation loss: 3.3354902477484707

Epoch: 6| Step: 10
Training loss: 3.610401882721748
Validation loss: 3.333020351441814

Epoch: 6| Step: 11
Training loss: 2.911265977067949
Validation loss: 3.3339041487773122

Epoch: 6| Step: 12
Training loss: 3.000226965901718
Validation loss: 3.3334659601304026

Epoch: 6| Step: 13
Training loss: 4.045275279935113
Validation loss: 3.3323943112681063

Epoch: 95| Step: 0
Training loss: 3.475740828550221
Validation loss: 3.3323376234895976

Epoch: 6| Step: 1
Training loss: 3.4468088512004647
Validation loss: 3.3315700717776973

Epoch: 6| Step: 2
Training loss: 3.370198967603811
Validation loss: 3.332355516332569

Epoch: 6| Step: 3
Training loss: 4.025558357131334
Validation loss: 3.3320762006979283

Epoch: 6| Step: 4
Training loss: 3.942502915521002
Validation loss: 3.3311693001634914

Epoch: 6| Step: 5
Training loss: 3.064484867784929
Validation loss: 3.3326368178463945

Epoch: 6| Step: 6
Training loss: 3.576607061519306
Validation loss: 3.3309096744032556

Epoch: 6| Step: 7
Training loss: 2.9731387174176405
Validation loss: 3.3318991203353043

Epoch: 6| Step: 8
Training loss: 3.675382586436036
Validation loss: 3.3303953841517333

Epoch: 6| Step: 9
Training loss: 4.125085771998296
Validation loss: 3.3313752165600516

Epoch: 6| Step: 10
Training loss: 2.8632036435381463
Validation loss: 3.3311225163483944

Epoch: 6| Step: 11
Training loss: 3.837375472343965
Validation loss: 3.33046968928412

Epoch: 6| Step: 12
Training loss: 3.812499749855909
Validation loss: 3.3292168507365436

Epoch: 6| Step: 13
Training loss: 3.303448528227722
Validation loss: 3.330248448627328

Epoch: 96| Step: 0
Training loss: 3.406197783743625
Validation loss: 3.32962181028166

Epoch: 6| Step: 1
Training loss: 3.8611174445401457
Validation loss: 3.3286686711795124

Epoch: 6| Step: 2
Training loss: 3.559020367539711
Validation loss: 3.3298884808502076

Epoch: 6| Step: 3
Training loss: 4.037683365853572
Validation loss: 3.329487951871031

Epoch: 6| Step: 4
Training loss: 2.9834423904802407
Validation loss: 3.3302463332035654

Epoch: 6| Step: 5
Training loss: 2.956755813005893
Validation loss: 3.33813556615427

Epoch: 6| Step: 6
Training loss: 4.329877257688766
Validation loss: 3.349784887757303

Epoch: 6| Step: 7
Training loss: 3.643555603599791
Validation loss: 3.334172511346167

Epoch: 6| Step: 8
Training loss: 4.238471832912607
Validation loss: 3.3283276648109106

Epoch: 6| Step: 9
Training loss: 3.5413907710304504
Validation loss: 3.328394933046283

Epoch: 6| Step: 10
Training loss: 3.4136329921922335
Validation loss: 3.3275283216209233

Epoch: 6| Step: 11
Training loss: 3.092241632374204
Validation loss: 3.3280531629810586

Epoch: 6| Step: 12
Training loss: 2.7090692156190195
Validation loss: 3.32793091215706

Epoch: 6| Step: 13
Training loss: 3.725448089889186
Validation loss: 3.3290894215571054

Epoch: 97| Step: 0
Training loss: 3.794995882939253
Validation loss: 3.3292769536020748

Epoch: 6| Step: 1
Training loss: 2.938173095205614
Validation loss: 3.3278146271964526

Epoch: 6| Step: 2
Training loss: 2.941270721271768
Validation loss: 3.3279551392839557

Epoch: 6| Step: 3
Training loss: 3.7287279151520796
Validation loss: 3.3272221031983853

Epoch: 6| Step: 4
Training loss: 4.289743282577633
Validation loss: 3.3314170995120063

Epoch: 6| Step: 5
Training loss: 3.365150348767795
Validation loss: 3.336185163419949

Epoch: 6| Step: 6
Training loss: 4.173918605710898
Validation loss: 3.339589137377424

Epoch: 6| Step: 7
Training loss: 4.057850216119965
Validation loss: 3.3279649987882207

Epoch: 6| Step: 8
Training loss: 3.8801646117066255
Validation loss: 3.3258706329637953

Epoch: 6| Step: 9
Training loss: 2.9887257762710635
Validation loss: 3.32527184316931

Epoch: 6| Step: 10
Training loss: 3.3713876677888224
Validation loss: 3.325591871943929

Epoch: 6| Step: 11
Training loss: 3.2011264427736235
Validation loss: 3.326187279135752

Epoch: 6| Step: 12
Training loss: 2.9295753559265627
Validation loss: 3.32544103456623

Epoch: 6| Step: 13
Training loss: 3.9502965888206973
Validation loss: 3.328138375389009

Epoch: 98| Step: 0
Training loss: 4.323023244011269
Validation loss: 3.3272884137225964

Epoch: 6| Step: 1
Training loss: 2.9041351499083348
Validation loss: 3.329411364114602

Epoch: 6| Step: 2
Training loss: 3.3275954134106454
Validation loss: 3.328797950939752

Epoch: 6| Step: 3
Training loss: 4.221577918656839
Validation loss: 3.3289099589949904

Epoch: 6| Step: 4
Training loss: 4.110369543832432
Validation loss: 3.3271976133833663

Epoch: 6| Step: 5
Training loss: 3.5983976082820583
Validation loss: 3.32631074240987

Epoch: 6| Step: 6
Training loss: 2.069475112562631
Validation loss: 3.3243531722337782

Epoch: 6| Step: 7
Training loss: 2.604431494916433
Validation loss: 3.324726263277777

Epoch: 6| Step: 8
Training loss: 3.828700181996256
Validation loss: 3.3228454093584814

Epoch: 6| Step: 9
Training loss: 3.2248628217516804
Validation loss: 3.322300127028988

Epoch: 6| Step: 10
Training loss: 2.8196702896974566
Validation loss: 3.322412388867436

Epoch: 6| Step: 11
Training loss: 2.8216204793551882
Validation loss: 3.322473901863301

Epoch: 6| Step: 12
Training loss: 4.393858455442647
Validation loss: 3.3229245084724757

Epoch: 6| Step: 13
Training loss: 5.079222199676494
Validation loss: 3.3223865904162637

Epoch: 99| Step: 0
Training loss: 3.9867727208357513
Validation loss: 3.3217178163839765

Epoch: 6| Step: 1
Training loss: 3.063246655433004
Validation loss: 3.3208889229622494

Epoch: 6| Step: 2
Training loss: 3.7449123202196355
Validation loss: 3.3218770527177575

Epoch: 6| Step: 3
Training loss: 3.8041415282996485
Validation loss: 3.320980951821737

Epoch: 6| Step: 4
Training loss: 4.090587063840038
Validation loss: 3.320383809606937

Epoch: 6| Step: 5
Training loss: 3.63175965506236
Validation loss: 3.3204611769221035

Epoch: 6| Step: 6
Training loss: 3.4774253888768163
Validation loss: 3.3203335321618024

Epoch: 6| Step: 7
Training loss: 3.1922246287572458
Validation loss: 3.319855939539464

Epoch: 6| Step: 8
Training loss: 4.2225997878683525
Validation loss: 3.318647424856817

Epoch: 6| Step: 9
Training loss: 3.6729839841689245
Validation loss: 3.319207357385237

Epoch: 6| Step: 10
Training loss: 3.2839385144591313
Validation loss: 3.3185735943106445

Epoch: 6| Step: 11
Training loss: 2.363873569883663
Validation loss: 3.3183188028498956

Epoch: 6| Step: 12
Training loss: 3.3875012049373723
Validation loss: 3.3177880697929116

Epoch: 6| Step: 13
Training loss: 3.329450316553829
Validation loss: 3.317280910830739

Epoch: 100| Step: 0
Training loss: 3.8507723046057847
Validation loss: 3.3175292012193984

Epoch: 6| Step: 1
Training loss: 3.4782200665775833
Validation loss: 3.3183953885867967

Epoch: 6| Step: 2
Training loss: 3.2346309247328793
Validation loss: 3.3175835695686406

Epoch: 6| Step: 3
Training loss: 3.7847115301667507
Validation loss: 3.317376123222046

Epoch: 6| Step: 4
Training loss: 2.655226297019712
Validation loss: 3.31671589096362

Epoch: 6| Step: 5
Training loss: 3.1628919155047077
Validation loss: 3.3174089837067022

Epoch: 6| Step: 6
Training loss: 3.094537499895071
Validation loss: 3.317112734545607

Epoch: 6| Step: 7
Training loss: 3.482756782041555
Validation loss: 3.3164904970338243

Epoch: 6| Step: 8
Training loss: 4.329527259375191
Validation loss: 3.3167382954863234

Epoch: 6| Step: 9
Training loss: 3.545985980097062
Validation loss: 3.3164706595259372

Epoch: 6| Step: 10
Training loss: 3.695113259361845
Validation loss: 3.3159951012498996

Epoch: 6| Step: 11
Training loss: 3.9715401761211524
Validation loss: 3.315759375198612

Epoch: 6| Step: 12
Training loss: 3.805634742958652
Validation loss: 3.3159604949620674

Epoch: 6| Step: 13
Training loss: 3.119375737166657
Validation loss: 3.3151603412804325

Epoch: 101| Step: 0
Training loss: 3.4053070443029076
Validation loss: 3.316383867970827

Epoch: 6| Step: 1
Training loss: 2.991856330094538
Validation loss: 3.314993781978851

Epoch: 6| Step: 2
Training loss: 3.392389216458994
Validation loss: 3.3157166937043168

Epoch: 6| Step: 3
Training loss: 3.3373054361959276
Validation loss: 3.317980865681469

Epoch: 6| Step: 4
Training loss: 3.229473731095205
Validation loss: 3.315239191485386

Epoch: 6| Step: 5
Training loss: 3.244031560948909
Validation loss: 3.3145886966082907

Epoch: 6| Step: 6
Training loss: 3.9727851599199124
Validation loss: 3.314390678827125

Epoch: 6| Step: 7
Training loss: 3.9244813807261227
Validation loss: 3.3142423901705906

Epoch: 6| Step: 8
Training loss: 3.655405061040202
Validation loss: 3.314276015017536

Epoch: 6| Step: 9
Training loss: 3.505078037933243
Validation loss: 3.3145453944265433

Epoch: 6| Step: 10
Training loss: 3.1385000451273153
Validation loss: 3.3130167849965817

Epoch: 6| Step: 11
Training loss: 3.7396490291396356
Validation loss: 3.31366101236314

Epoch: 6| Step: 12
Training loss: 3.6321968459339184
Validation loss: 3.313037273835382

Epoch: 6| Step: 13
Training loss: 4.7953472873274885
Validation loss: 3.3121822697789542

Epoch: 102| Step: 0
Training loss: 3.7551391990248155
Validation loss: 3.3118736323436604

Epoch: 6| Step: 1
Training loss: 4.222944195128666
Validation loss: 3.311706502103962

Epoch: 6| Step: 2
Training loss: 3.116987102443922
Validation loss: 3.3111111900138894

Epoch: 6| Step: 3
Training loss: 3.66857840089598
Validation loss: 3.3120092290386394

Epoch: 6| Step: 4
Training loss: 3.3252510951176384
Validation loss: 3.3108681551944543

Epoch: 6| Step: 5
Training loss: 3.082061883462305
Validation loss: 3.309809343657627

Epoch: 6| Step: 6
Training loss: 2.8305304819314463
Validation loss: 3.310730772591312

Epoch: 6| Step: 7
Training loss: 4.637525763015955
Validation loss: 3.309728156548454

Epoch: 6| Step: 8
Training loss: 3.221866321274532
Validation loss: 3.310139749132935

Epoch: 6| Step: 9
Training loss: 3.3008426457400293
Validation loss: 3.309623328230283

Epoch: 6| Step: 10
Training loss: 3.8149201263025625
Validation loss: 3.31015915757211

Epoch: 6| Step: 11
Training loss: 3.664542420928588
Validation loss: 3.309309474079415

Epoch: 6| Step: 12
Training loss: 3.277934115573411
Validation loss: 3.310502493101019

Epoch: 6| Step: 13
Training loss: 3.1094199325918823
Validation loss: 3.3094822810567495

Epoch: 103| Step: 0
Training loss: 3.141196431417805
Validation loss: 3.3089151160148904

Epoch: 6| Step: 1
Training loss: 3.7965730774697803
Validation loss: 3.3090273074523586

Epoch: 6| Step: 2
Training loss: 4.246970499409145
Validation loss: 3.3095578597763833

Epoch: 6| Step: 3
Training loss: 2.7943183679202317
Validation loss: 3.309724017204231

Epoch: 6| Step: 4
Training loss: 3.6414772967953777
Validation loss: 3.3081802540009506

Epoch: 6| Step: 5
Training loss: 3.8969804567508226
Validation loss: 3.307768436193247

Epoch: 6| Step: 6
Training loss: 3.867657750370245
Validation loss: 3.3081222864441027

Epoch: 6| Step: 7
Training loss: 3.693016451888079
Validation loss: 3.308715291961682

Epoch: 6| Step: 8
Training loss: 4.1604205553510685
Validation loss: 3.3089674666559232

Epoch: 6| Step: 9
Training loss: 2.986566986850179
Validation loss: 3.3077141568551216

Epoch: 6| Step: 10
Training loss: 2.97776117494171
Validation loss: 3.309392031756194

Epoch: 6| Step: 11
Training loss: 3.382525918639944
Validation loss: 3.306464349495572

Epoch: 6| Step: 12
Training loss: 3.4039480848107706
Validation loss: 3.3070527537957033

Epoch: 6| Step: 13
Training loss: 2.9943078399369054
Validation loss: 3.3092536566968747

Epoch: 104| Step: 0
Training loss: 3.976641161427293
Validation loss: 3.3073125640748953

Epoch: 6| Step: 1
Training loss: 3.2031203851433983
Validation loss: 3.306927413331403

Epoch: 6| Step: 2
Training loss: 4.10139741111209
Validation loss: 3.3062124483463577

Epoch: 6| Step: 3
Training loss: 3.633517551709911
Validation loss: 3.3059487146222906

Epoch: 6| Step: 4
Training loss: 4.013082092464516
Validation loss: 3.304592651256571

Epoch: 6| Step: 5
Training loss: 3.6441434304309066
Validation loss: 3.3050304576119505

Epoch: 6| Step: 6
Training loss: 2.709372648702303
Validation loss: 3.304886584759247

Epoch: 6| Step: 7
Training loss: 4.181579047742555
Validation loss: 3.304326258999608

Epoch: 6| Step: 8
Training loss: 3.905928941884101
Validation loss: 3.3042221546550716

Epoch: 6| Step: 9
Training loss: 2.504435800148007
Validation loss: 3.304359137539388

Epoch: 6| Step: 10
Training loss: 3.1420518660899313
Validation loss: 3.3041489863776454

Epoch: 6| Step: 11
Training loss: 4.319128056939411
Validation loss: 3.303801646168938

Epoch: 6| Step: 12
Training loss: 2.5674135504471765
Validation loss: 3.3033736765985213

Epoch: 6| Step: 13
Training loss: 2.381032209874627
Validation loss: 3.303206115515836

Epoch: 105| Step: 0
Training loss: 3.1319513445371943
Validation loss: 3.302707017872691

Epoch: 6| Step: 1
Training loss: 3.7789001729781093
Validation loss: 3.3036069922481515

Epoch: 6| Step: 2
Training loss: 3.970335996423919
Validation loss: 3.3034465461958873

Epoch: 6| Step: 3
Training loss: 4.108160847621081
Validation loss: 3.3028278675373275

Epoch: 6| Step: 4
Training loss: 3.000947166966753
Validation loss: 3.302436044015691

Epoch: 6| Step: 5
Training loss: 2.985246141723051
Validation loss: 3.3017560701520052

Epoch: 6| Step: 6
Training loss: 3.3180186527272855
Validation loss: 3.302106096701579

Epoch: 6| Step: 7
Training loss: 3.150352482526385
Validation loss: 3.30275045042791

Epoch: 6| Step: 8
Training loss: 3.613308699220062
Validation loss: 3.3019104072494305

Epoch: 6| Step: 9
Training loss: 3.3230077238770868
Validation loss: 3.3012683644653134

Epoch: 6| Step: 10
Training loss: 3.163985639980827
Validation loss: 3.3010964042380047

Epoch: 6| Step: 11
Training loss: 3.58173784325196
Validation loss: 3.3016866115233037

Epoch: 6| Step: 12
Training loss: 4.359652383928265
Validation loss: 3.3020784261495

Epoch: 6| Step: 13
Training loss: 3.8473951222066334
Validation loss: 3.3013503684283045

Epoch: 106| Step: 0
Training loss: 3.819950266010022
Validation loss: 3.3021998407061814

Epoch: 6| Step: 1
Training loss: 4.022381631023554
Validation loss: 3.300288396161688

Epoch: 6| Step: 2
Training loss: 3.719511707417221
Validation loss: 3.301888080689876

Epoch: 6| Step: 3
Training loss: 3.162088263325139
Validation loss: 3.3010630769381883

Epoch: 6| Step: 4
Training loss: 3.496520356304362
Validation loss: 3.300319663481889

Epoch: 6| Step: 5
Training loss: 3.372206768298643
Validation loss: 3.300491048219577

Epoch: 6| Step: 6
Training loss: 3.738363394636927
Validation loss: 3.2999829470534734

Epoch: 6| Step: 7
Training loss: 2.789310732782146
Validation loss: 3.2995953526509694

Epoch: 6| Step: 8
Training loss: 3.2333904739784143
Validation loss: 3.2992141419970396

Epoch: 6| Step: 9
Training loss: 3.2395579509824235
Validation loss: 3.298473315006304

Epoch: 6| Step: 10
Training loss: 3.904363436033742
Validation loss: 3.298511683043718

Epoch: 6| Step: 11
Training loss: 3.0929593703977347
Validation loss: 3.2981258387850994

Epoch: 6| Step: 12
Training loss: 3.9070707145639836
Validation loss: 3.2986230617638457

Epoch: 6| Step: 13
Training loss: 3.932017066243293
Validation loss: 3.298670367126229

Epoch: 107| Step: 0
Training loss: 2.5080417991695905
Validation loss: 3.2974569023610023

Epoch: 6| Step: 1
Training loss: 3.4405595515069667
Validation loss: 3.2973264435577962

Epoch: 6| Step: 2
Training loss: 3.3717517055988844
Validation loss: 3.2973561746680184

Epoch: 6| Step: 3
Training loss: 3.1538081023692333
Validation loss: 3.2974857133454814

Epoch: 6| Step: 4
Training loss: 3.5284323464689527
Validation loss: 3.297067308165604

Epoch: 6| Step: 5
Training loss: 4.152006349106713
Validation loss: 3.298068218420574

Epoch: 6| Step: 6
Training loss: 3.482336157718902
Validation loss: 3.29716444472656

Epoch: 6| Step: 7
Training loss: 3.527497720156662
Validation loss: 3.297186742624884

Epoch: 6| Step: 8
Training loss: 4.002676306897405
Validation loss: 3.2957945040985295

Epoch: 6| Step: 9
Training loss: 3.706910335389722
Validation loss: 3.2961024366875455

Epoch: 6| Step: 10
Training loss: 4.068134332770108
Validation loss: 3.295633234302386

Epoch: 6| Step: 11
Training loss: 2.976715003885234
Validation loss: 3.2945810165719482

Epoch: 6| Step: 12
Training loss: 3.830167638033225
Validation loss: 3.2966456708456504

Epoch: 6| Step: 13
Training loss: 3.208162988541474
Validation loss: 3.2963055179708096

Epoch: 108| Step: 0
Training loss: 3.596209273387811
Validation loss: 3.2953448967043357

Epoch: 6| Step: 1
Training loss: 3.5463417761527345
Validation loss: 3.294427185874794

Epoch: 6| Step: 2
Training loss: 3.815879199709087
Validation loss: 3.294741128703259

Epoch: 6| Step: 3
Training loss: 2.434313231481533
Validation loss: 3.2951406716767013

Epoch: 6| Step: 4
Training loss: 3.6745608631823536
Validation loss: 3.2958229733619784

Epoch: 6| Step: 5
Training loss: 3.552504051254507
Validation loss: 3.2941300154814237

Epoch: 6| Step: 6
Training loss: 3.475190927214046
Validation loss: 3.2942134765446323

Epoch: 6| Step: 7
Training loss: 3.9953068380722248
Validation loss: 3.2943186893835192

Epoch: 6| Step: 8
Training loss: 2.8097870351653698
Validation loss: 3.294942971199638

Epoch: 6| Step: 9
Training loss: 3.23504012635711
Validation loss: 3.2937766203164847

Epoch: 6| Step: 10
Training loss: 3.6241906676671234
Validation loss: 3.2941397528700733

Epoch: 6| Step: 11
Training loss: 3.3927844505840627
Validation loss: 3.2937527006342573

Epoch: 6| Step: 12
Training loss: 3.8220269660337767
Validation loss: 3.2937717137291638

Epoch: 6| Step: 13
Training loss: 4.488831117046317
Validation loss: 3.293810464984631

Epoch: 109| Step: 0
Training loss: 1.833328471032833
Validation loss: 3.2936554463302095

Epoch: 6| Step: 1
Training loss: 3.5044026613240824
Validation loss: 3.292590118591874

Epoch: 6| Step: 2
Training loss: 3.9783696413294427
Validation loss: 3.293261270409293

Epoch: 6| Step: 3
Training loss: 4.438209154657797
Validation loss: 3.2928576409256882

Epoch: 6| Step: 4
Training loss: 2.9210047114254922
Validation loss: 3.292075122607186

Epoch: 6| Step: 5
Training loss: 3.6761604137847983
Validation loss: 3.2917956623821194

Epoch: 6| Step: 6
Training loss: 2.6306391498514117
Validation loss: 3.2909230580929707

Epoch: 6| Step: 7
Training loss: 4.030320171198939
Validation loss: 3.291426993497565

Epoch: 6| Step: 8
Training loss: 2.538169257692359
Validation loss: 3.292452066746749

Epoch: 6| Step: 9
Training loss: 3.4105842382935774
Validation loss: 3.2906970247971863

Epoch: 6| Step: 10
Training loss: 4.261994881779477
Validation loss: 3.291365151065142

Epoch: 6| Step: 11
Training loss: 3.686147668141858
Validation loss: 3.292847192823869

Epoch: 6| Step: 12
Training loss: 3.646036473019085
Validation loss: 3.291144480835612

Epoch: 6| Step: 13
Training loss: 4.07619503729344
Validation loss: 3.290976533912905

Epoch: 110| Step: 0
Training loss: 3.8155685333147766
Validation loss: 3.2900924194448082

Epoch: 6| Step: 1
Training loss: 3.378003797024207
Validation loss: 3.2913376371260434

Epoch: 6| Step: 2
Training loss: 3.760279616855113
Validation loss: 3.290979355416585

Epoch: 6| Step: 3
Training loss: 3.579198018396722
Validation loss: 3.2912631043829035

Epoch: 6| Step: 4
Training loss: 2.583709033185444
Validation loss: 3.2907920972060087

Epoch: 6| Step: 5
Training loss: 3.785511862286166
Validation loss: 3.289467871733681

Epoch: 6| Step: 6
Training loss: 3.876365175033803
Validation loss: 3.290186676383117

Epoch: 6| Step: 7
Training loss: 3.9985704251577574
Validation loss: 3.2898616597875177

Epoch: 6| Step: 8
Training loss: 4.0236605387966975
Validation loss: 3.2892884788274492

Epoch: 6| Step: 9
Training loss: 3.1875073301941605
Validation loss: 3.289968440125182

Epoch: 6| Step: 10
Training loss: 2.1120750947953266
Validation loss: 3.2901320758202393

Epoch: 6| Step: 11
Training loss: 3.5103917484172555
Validation loss: 3.290496257235385

Epoch: 6| Step: 12
Training loss: 3.7221055479093863
Validation loss: 3.2900988758912404

Epoch: 6| Step: 13
Training loss: 3.4461393510269978
Validation loss: 3.287650257053245

Epoch: 111| Step: 0
Training loss: 3.207285045101958
Validation loss: 3.2886786231622205

Epoch: 6| Step: 1
Training loss: 3.7385568865939858
Validation loss: 3.287696732333033

Epoch: 6| Step: 2
Training loss: 3.212925947279239
Validation loss: 3.2878071144350947

Epoch: 6| Step: 3
Training loss: 4.048895489821885
Validation loss: 3.2878472560776206

Epoch: 6| Step: 4
Training loss: 4.438345815077814
Validation loss: 3.287397369675557

Epoch: 6| Step: 5
Training loss: 3.27737212140394
Validation loss: 3.286824606806945

Epoch: 6| Step: 6
Training loss: 3.5237760867492556
Validation loss: 3.2865877659206397

Epoch: 6| Step: 7
Training loss: 3.8158759507143616
Validation loss: 3.287784440245124

Epoch: 6| Step: 8
Training loss: 3.004219267054423
Validation loss: 3.286125594645287

Epoch: 6| Step: 9
Training loss: 2.9947904813460062
Validation loss: 3.2858112499619962

Epoch: 6| Step: 10
Training loss: 3.4654255650531334
Validation loss: 3.2855011293421104

Epoch: 6| Step: 11
Training loss: 2.971127491673379
Validation loss: 3.2863819092691897

Epoch: 6| Step: 12
Training loss: 4.167996664767111
Validation loss: 3.285049299975639

Epoch: 6| Step: 13
Training loss: 2.5900458117524328
Validation loss: 3.285776274278576

Epoch: 112| Step: 0
Training loss: 3.6336755527235693
Validation loss: 3.2834793666330837

Epoch: 6| Step: 1
Training loss: 3.1893125878024002
Validation loss: 3.285088166607839

Epoch: 6| Step: 2
Training loss: 3.1851759273023226
Validation loss: 3.2841322218087736

Epoch: 6| Step: 3
Training loss: 3.0938036364905432
Validation loss: 3.283018616261297

Epoch: 6| Step: 4
Training loss: 3.678149248041621
Validation loss: 3.2840546590541924

Epoch: 6| Step: 5
Training loss: 3.8609084816385986
Validation loss: 3.2843140749303767

Epoch: 6| Step: 6
Training loss: 3.7557656786772364
Validation loss: 3.2837837136670283

Epoch: 6| Step: 7
Training loss: 3.538715673972101
Validation loss: 3.284315623583065

Epoch: 6| Step: 8
Training loss: 3.414275348234886
Validation loss: 3.282630686180811

Epoch: 6| Step: 9
Training loss: 3.0978157223688854
Validation loss: 3.283088861051363

Epoch: 6| Step: 10
Training loss: 4.144034655245652
Validation loss: 3.2827462015308315

Epoch: 6| Step: 11
Training loss: 3.5597989734940727
Validation loss: 3.282596160035254

Epoch: 6| Step: 12
Training loss: 3.97652280896357
Validation loss: 3.2833578782085255

Epoch: 6| Step: 13
Training loss: 2.3158454409137867
Validation loss: 3.282298007532678

Epoch: 113| Step: 0
Training loss: 2.9252591857844177
Validation loss: 3.2834110111109274

Epoch: 6| Step: 1
Training loss: 3.412960337236547
Validation loss: 3.281310900207494

Epoch: 6| Step: 2
Training loss: 4.564455632220107
Validation loss: 3.282440279053794

Epoch: 6| Step: 3
Training loss: 2.4450927245611074
Validation loss: 3.2817429648338647

Epoch: 6| Step: 4
Training loss: 3.7944579417589206
Validation loss: 3.284592883091568

Epoch: 6| Step: 5
Training loss: 3.2552852204461407
Validation loss: 3.2847717949038855

Epoch: 6| Step: 6
Training loss: 3.0101008442052497
Validation loss: 3.286918839681465

Epoch: 6| Step: 7
Training loss: 3.635565651771042
Validation loss: 3.2840035350171455

Epoch: 6| Step: 8
Training loss: 3.1698614033626646
Validation loss: 3.2816780541639354

Epoch: 6| Step: 9
Training loss: 3.952560686083498
Validation loss: 3.280578511758618

Epoch: 6| Step: 10
Training loss: 4.295212746659064
Validation loss: 3.2791519653384373

Epoch: 6| Step: 11
Training loss: 3.088216437487908
Validation loss: 3.27979924583295

Epoch: 6| Step: 12
Training loss: 3.3423827040754817
Validation loss: 3.280908013417312

Epoch: 6| Step: 13
Training loss: 3.9566470653516546
Validation loss: 3.280403214673673

Epoch: 114| Step: 0
Training loss: 3.8510651489785586
Validation loss: 3.2794318612065094

Epoch: 6| Step: 1
Training loss: 3.6563163816506705
Validation loss: 3.2789050964770796

Epoch: 6| Step: 2
Training loss: 3.938361542921273
Validation loss: 3.2795951440008135

Epoch: 6| Step: 3
Training loss: 3.5228457746962074
Validation loss: 3.2787591514750396

Epoch: 6| Step: 4
Training loss: 3.1255189083334782
Validation loss: 3.2781511368968603

Epoch: 6| Step: 5
Training loss: 3.907690408256804
Validation loss: 3.2782901772782465

Epoch: 6| Step: 6
Training loss: 4.007366787700746
Validation loss: 3.2777021331104526

Epoch: 6| Step: 7
Training loss: 2.8872674361202955
Validation loss: 3.277832684706772

Epoch: 6| Step: 8
Training loss: 3.286466974326662
Validation loss: 3.2765601437950655

Epoch: 6| Step: 9
Training loss: 3.214599748438921
Validation loss: 3.2767114600013456

Epoch: 6| Step: 10
Training loss: 3.796759709621158
Validation loss: 3.2775795850130858

Epoch: 6| Step: 11
Training loss: 3.1750358279151625
Validation loss: 3.2775894787290474

Epoch: 6| Step: 12
Training loss: 3.0568417029009267
Validation loss: 3.2768738440922065

Epoch: 6| Step: 13
Training loss: 3.5743296121382673
Validation loss: 3.2756897067394988

Epoch: 115| Step: 0
Training loss: 3.2488135593092835
Validation loss: 3.2760693022863987

Epoch: 6| Step: 1
Training loss: 3.5024764972472737
Validation loss: 3.275248801806555

Epoch: 6| Step: 2
Training loss: 4.451973106913129
Validation loss: 3.274861906049516

Epoch: 6| Step: 3
Training loss: 3.7096731501550706
Validation loss: 3.275023697691655

Epoch: 6| Step: 4
Training loss: 3.3215596807476686
Validation loss: 3.275698005697366

Epoch: 6| Step: 5
Training loss: 3.529483724776806
Validation loss: 3.2759762011461433

Epoch: 6| Step: 6
Training loss: 3.956980879106229
Validation loss: 3.2744661152610903

Epoch: 6| Step: 7
Training loss: 2.173028104660922
Validation loss: 3.276616209063914

Epoch: 6| Step: 8
Training loss: 3.720935339702384
Validation loss: 3.2755242420740274

Epoch: 6| Step: 9
Training loss: 3.3194787268861226
Validation loss: 3.2748097096662887

Epoch: 6| Step: 10
Training loss: 3.9042729371764917
Validation loss: 3.2751744571183004

Epoch: 6| Step: 11
Training loss: 3.0773427521160954
Validation loss: 3.27454202695772

Epoch: 6| Step: 12
Training loss: 3.0094832895033337
Validation loss: 3.27516941699144

Epoch: 6| Step: 13
Training loss: 3.904828476698315
Validation loss: 3.2730428410927277

Epoch: 116| Step: 0
Training loss: 3.600338808646811
Validation loss: 3.2743454269078596

Epoch: 6| Step: 1
Training loss: 4.307940961923793
Validation loss: 3.2758782250131566

Epoch: 6| Step: 2
Training loss: 2.6581084089481193
Validation loss: 3.273762017960007

Epoch: 6| Step: 3
Training loss: 3.2065896254052895
Validation loss: 3.274559747080004

Epoch: 6| Step: 4
Training loss: 3.0212651612765886
Validation loss: 3.273747100117748

Epoch: 6| Step: 5
Training loss: 2.5196138590200032
Validation loss: 3.2741465083502033

Epoch: 6| Step: 6
Training loss: 4.234323198628023
Validation loss: 3.2745688826839197

Epoch: 6| Step: 7
Training loss: 3.602428539025331
Validation loss: 3.2719470786848355

Epoch: 6| Step: 8
Training loss: 3.8445380418760493
Validation loss: 3.27176804697653

Epoch: 6| Step: 9
Training loss: 4.0916164749910235
Validation loss: 3.2718212364559065

Epoch: 6| Step: 10
Training loss: 3.598231034643873
Validation loss: 3.2712244981212484

Epoch: 6| Step: 11
Training loss: 3.5056202586457004
Validation loss: 3.272454471323286

Epoch: 6| Step: 12
Training loss: 3.227498138214449
Validation loss: 3.271091115300822

Epoch: 6| Step: 13
Training loss: 2.913829477110781
Validation loss: 3.270827490448199

Epoch: 117| Step: 0
Training loss: 3.9423635811628412
Validation loss: 3.270850146592485

Epoch: 6| Step: 1
Training loss: 3.5829406049928108
Validation loss: 3.270744558184717

Epoch: 6| Step: 2
Training loss: 2.882664622414023
Validation loss: 3.2707257561085448

Epoch: 6| Step: 3
Training loss: 3.152486540291449
Validation loss: 3.2707792305976944

Epoch: 6| Step: 4
Training loss: 4.240937837490085
Validation loss: 3.269785693212248

Epoch: 6| Step: 5
Training loss: 3.4682427112692764
Validation loss: 3.269942846986343

Epoch: 6| Step: 6
Training loss: 3.3825814606527453
Validation loss: 3.269560461528478

Epoch: 6| Step: 7
Training loss: 3.879602467730062
Validation loss: 3.269560068697683

Epoch: 6| Step: 8
Training loss: 3.0896696675834385
Validation loss: 3.2696080548647086

Epoch: 6| Step: 9
Training loss: 2.790084523387068
Validation loss: 3.268839576795885

Epoch: 6| Step: 10
Training loss: 3.964103201122285
Validation loss: 3.2692758428543423

Epoch: 6| Step: 11
Training loss: 3.053512620479125
Validation loss: 3.2684803348686153

Epoch: 6| Step: 12
Training loss: 3.5729908986438788
Validation loss: 3.269000628182006

Epoch: 6| Step: 13
Training loss: 3.9337635780199536
Validation loss: 3.2688596947324404

Epoch: 118| Step: 0
Training loss: 3.4737795545948074
Validation loss: 3.2688116771883884

Epoch: 6| Step: 1
Training loss: 3.2615303030797853
Validation loss: 3.268810823899288

Epoch: 6| Step: 2
Training loss: 3.4531823062888396
Validation loss: 3.2691101954942434

Epoch: 6| Step: 3
Training loss: 3.3200249760618976
Validation loss: 3.2686986865976215

Epoch: 6| Step: 4
Training loss: 3.280751217670443
Validation loss: 3.267182254556064

Epoch: 6| Step: 5
Training loss: 3.6993752338701302
Validation loss: 3.2674058016347707

Epoch: 6| Step: 6
Training loss: 2.92686403659003
Validation loss: 3.2683567028935077

Epoch: 6| Step: 7
Training loss: 3.2788585849339578
Validation loss: 3.2689216813852613

Epoch: 6| Step: 8
Training loss: 4.106617049210602
Validation loss: 3.267942257723775

Epoch: 6| Step: 9
Training loss: 3.7074881172632823
Validation loss: 3.266483266912822

Epoch: 6| Step: 10
Training loss: 2.744385710391067
Validation loss: 3.2676648155907664

Epoch: 6| Step: 11
Training loss: 3.8430110562255066
Validation loss: 3.267397273692996

Epoch: 6| Step: 12
Training loss: 4.071146054134117
Validation loss: 3.2682872655110486

Epoch: 6| Step: 13
Training loss: 3.7049375838197327
Validation loss: 3.2674909048647987

Epoch: 119| Step: 0
Training loss: 3.195233705477142
Validation loss: 3.2668713244563556

Epoch: 6| Step: 1
Training loss: 3.567013742072325
Validation loss: 3.267303614729685

Epoch: 6| Step: 2
Training loss: 3.426182931036916
Validation loss: 3.2645190847504986

Epoch: 6| Step: 3
Training loss: 3.413630058782389
Validation loss: 3.2662499178178233

Epoch: 6| Step: 4
Training loss: 3.091793482014089
Validation loss: 3.2667679711539463

Epoch: 6| Step: 5
Training loss: 3.758754556625847
Validation loss: 3.2656993799599596

Epoch: 6| Step: 6
Training loss: 3.4721562612414245
Validation loss: 3.2636862890414786

Epoch: 6| Step: 7
Training loss: 3.68882727577915
Validation loss: 3.2659818589041176

Epoch: 6| Step: 8
Training loss: 2.9879327309018406
Validation loss: 3.2642546432595507

Epoch: 6| Step: 9
Training loss: 3.5910812420069718
Validation loss: 3.2670263694663912

Epoch: 6| Step: 10
Training loss: 4.102828580633189
Validation loss: 3.264894641962221

Epoch: 6| Step: 11
Training loss: 3.627895645659602
Validation loss: 3.262088154670955

Epoch: 6| Step: 12
Training loss: 3.203194519777212
Validation loss: 3.2638952391478386

Epoch: 6| Step: 13
Training loss: 3.9462536586276893
Validation loss: 3.261460459395928

Epoch: 120| Step: 0
Training loss: 4.0139227795664265
Validation loss: 3.263076491972497

Epoch: 6| Step: 1
Training loss: 4.2035218232315374
Validation loss: 3.262516684609925

Epoch: 6| Step: 2
Training loss: 3.347463381896753
Validation loss: 3.2620745116017345

Epoch: 6| Step: 3
Training loss: 3.234407139125496
Validation loss: 3.2626845823733

Epoch: 6| Step: 4
Training loss: 4.062846007650888
Validation loss: 3.2620413208253165

Epoch: 6| Step: 5
Training loss: 3.3336219344770286
Validation loss: 3.2613076856652077

Epoch: 6| Step: 6
Training loss: 3.078297876450898
Validation loss: 3.2612056181915556

Epoch: 6| Step: 7
Training loss: 3.5678083790954704
Validation loss: 3.2606284887757213

Epoch: 6| Step: 8
Training loss: 3.597721857224469
Validation loss: 3.261387823710938

Epoch: 6| Step: 9
Training loss: 3.174026285881129
Validation loss: 3.261128593424471

Epoch: 6| Step: 10
Training loss: 4.106785179343734
Validation loss: 3.2606956165768493

Epoch: 6| Step: 11
Training loss: 3.018781048158947
Validation loss: 3.2605281164584468

Epoch: 6| Step: 12
Training loss: 2.7744989647340037
Validation loss: 3.259996648900348

Epoch: 6| Step: 13
Training loss: 2.773782885899311
Validation loss: 3.2602475664453974

Epoch: 121| Step: 0
Training loss: 2.9017047409665166
Validation loss: 3.259090216795658

Epoch: 6| Step: 1
Training loss: 3.0439818119703745
Validation loss: 3.260549548411886

Epoch: 6| Step: 2
Training loss: 3.3651969672906383
Validation loss: 3.259864329193686

Epoch: 6| Step: 3
Training loss: 3.869965513011636
Validation loss: 3.2600300264211928

Epoch: 6| Step: 4
Training loss: 4.27300297900881
Validation loss: 3.2604472511982876

Epoch: 6| Step: 5
Training loss: 4.065056334007836
Validation loss: 3.2598977977209245

Epoch: 6| Step: 6
Training loss: 3.4189884081741915
Validation loss: 3.259813524133663

Epoch: 6| Step: 7
Training loss: 3.8507108849481297
Validation loss: 3.2607852968922892

Epoch: 6| Step: 8
Training loss: 3.88274409581188
Validation loss: 3.259723036915292

Epoch: 6| Step: 9
Training loss: 3.5149673864118656
Validation loss: 3.2595818564863954

Epoch: 6| Step: 10
Training loss: 3.0338216667999496
Validation loss: 3.258223807015715

Epoch: 6| Step: 11
Training loss: 3.5447498290292407
Validation loss: 3.258702891027092

Epoch: 6| Step: 12
Training loss: 2.8114565291133338
Validation loss: 3.2563338611970973

Epoch: 6| Step: 13
Training loss: 2.566550890883402
Validation loss: 3.257948939778103

Epoch: 122| Step: 0
Training loss: 3.5242759231465834
Validation loss: 3.257259442842785

Epoch: 6| Step: 1
Training loss: 3.335625162623178
Validation loss: 3.256795823741171

Epoch: 6| Step: 2
Training loss: 3.990076391497455
Validation loss: 3.2566479983854646

Epoch: 6| Step: 3
Training loss: 3.4615418743866617
Validation loss: 3.2558924248628762

Epoch: 6| Step: 4
Training loss: 3.7972499834924998
Validation loss: 3.2552387336870106

Epoch: 6| Step: 5
Training loss: 3.6289543419680643
Validation loss: 3.256420443327062

Epoch: 6| Step: 6
Training loss: 2.4017157501386612
Validation loss: 3.2569061653004283

Epoch: 6| Step: 7
Training loss: 4.016307490792469
Validation loss: 3.2548283175570614

Epoch: 6| Step: 8
Training loss: 3.4000878547088704
Validation loss: 3.2558347090358097

Epoch: 6| Step: 9
Training loss: 3.3284542296994415
Validation loss: 3.2568402983458897

Epoch: 6| Step: 10
Training loss: 3.2169049354288393
Validation loss: 3.255237092446884

Epoch: 6| Step: 11
Training loss: 2.9867244080797506
Validation loss: 3.2572494283461926

Epoch: 6| Step: 12
Training loss: 3.110730513120085
Validation loss: 3.2547410487649597

Epoch: 6| Step: 13
Training loss: 4.859363420969424
Validation loss: 3.2550369006227515

Epoch: 123| Step: 0
Training loss: 3.596524966762757
Validation loss: 3.2550805029924366

Epoch: 6| Step: 1
Training loss: 2.7954809028302052
Validation loss: 3.254826022366435

Epoch: 6| Step: 2
Training loss: 3.1727952045144736
Validation loss: 3.255265291892892

Epoch: 6| Step: 3
Training loss: 3.8333144532996477
Validation loss: 3.2530517086318502

Epoch: 6| Step: 4
Training loss: 3.690692618684904
Validation loss: 3.25386623563844

Epoch: 6| Step: 5
Training loss: 3.686458634571165
Validation loss: 3.252966592534606

Epoch: 6| Step: 6
Training loss: 3.6065439458147828
Validation loss: 3.2531643663752954

Epoch: 6| Step: 7
Training loss: 3.5567792501986335
Validation loss: 3.252141687006912

Epoch: 6| Step: 8
Training loss: 2.6739847877143914
Validation loss: 3.252290280002213

Epoch: 6| Step: 9
Training loss: 3.3524935480634603
Validation loss: 3.252038497811763

Epoch: 6| Step: 10
Training loss: 3.453703266591111
Validation loss: 3.252772789931381

Epoch: 6| Step: 11
Training loss: 4.099807567267401
Validation loss: 3.250682342688077

Epoch: 6| Step: 12
Training loss: 3.440688163323065
Validation loss: 3.251249410808187

Epoch: 6| Step: 13
Training loss: 3.833303257920967
Validation loss: 3.2493848794379527

Epoch: 124| Step: 0
Training loss: 3.121914370176863
Validation loss: 3.250286285311303

Epoch: 6| Step: 1
Training loss: 2.6545830376578543
Validation loss: 3.250626617995982

Epoch: 6| Step: 2
Training loss: 3.1264443683564456
Validation loss: 3.251113809600484

Epoch: 6| Step: 3
Training loss: 4.07803660329843
Validation loss: 3.2493130633939087

Epoch: 6| Step: 4
Training loss: 3.4211522562756715
Validation loss: 3.2502784120688952

Epoch: 6| Step: 5
Training loss: 2.5891549645846896
Validation loss: 3.2493702615203164

Epoch: 6| Step: 6
Training loss: 4.056311015888351
Validation loss: 3.250891043510933

Epoch: 6| Step: 7
Training loss: 2.621911639024623
Validation loss: 3.2504577235513117

Epoch: 6| Step: 8
Training loss: 2.9702408109198006
Validation loss: 3.2501921348478082

Epoch: 6| Step: 9
Training loss: 3.454594226200842
Validation loss: 3.2501709816558

Epoch: 6| Step: 10
Training loss: 3.919986832654987
Validation loss: 3.2497782619739475

Epoch: 6| Step: 11
Training loss: 4.128245608512073
Validation loss: 3.2478857759834

Epoch: 6| Step: 12
Training loss: 4.363099834663004
Validation loss: 3.2489609520615153

Epoch: 6| Step: 13
Training loss: 3.8347857391305533
Validation loss: 3.2484782081899173

Epoch: 125| Step: 0
Training loss: 3.8174473914897624
Validation loss: 3.2484460101925965

Epoch: 6| Step: 1
Training loss: 3.936751279338838
Validation loss: 3.2477615842160024

Epoch: 6| Step: 2
Training loss: 2.4436951184756595
Validation loss: 3.24798837726879

Epoch: 6| Step: 3
Training loss: 3.1052017193075128
Validation loss: 3.2473681784284305

Epoch: 6| Step: 4
Training loss: 4.362312229782768
Validation loss: 3.2486597426064723

Epoch: 6| Step: 5
Training loss: 3.297790689445964
Validation loss: 3.2472291877288453

Epoch: 6| Step: 6
Training loss: 3.6377701596746244
Validation loss: 3.248468640922046

Epoch: 6| Step: 7
Training loss: 3.071772027060353
Validation loss: 3.246918222888839

Epoch: 6| Step: 8
Training loss: 3.0968316653517656
Validation loss: 3.2476406825963995

Epoch: 6| Step: 9
Training loss: 2.912719744468124
Validation loss: 3.246273990737532

Epoch: 6| Step: 10
Training loss: 3.62980622628212
Validation loss: 3.2463940540658798

Epoch: 6| Step: 11
Training loss: 4.064330642225843
Validation loss: 3.247184583065904

Epoch: 6| Step: 12
Training loss: 3.250814775891318
Validation loss: 3.2469677295775314

Epoch: 6| Step: 13
Training loss: 3.902668035434196
Validation loss: 3.246103789435664

Epoch: 126| Step: 0
Training loss: 2.95246774938478
Validation loss: 3.244580148869305

Epoch: 6| Step: 1
Training loss: 3.731311515160446
Validation loss: 3.2451872976095153

Epoch: 6| Step: 2
Training loss: 2.9578358048268045
Validation loss: 3.2482041571151012

Epoch: 6| Step: 3
Training loss: 4.073008400484821
Validation loss: 3.243976616604221

Epoch: 6| Step: 4
Training loss: 4.1423513592312755
Validation loss: 3.246620010879978

Epoch: 6| Step: 5
Training loss: 3.8700957488997423
Validation loss: 3.245575482771069

Epoch: 6| Step: 6
Training loss: 4.28958899318673
Validation loss: 3.2430630777259224

Epoch: 6| Step: 7
Training loss: 2.7589905035692674
Validation loss: 3.2445349736529843

Epoch: 6| Step: 8
Training loss: 3.7612999101587414
Validation loss: 3.2433679575775543

Epoch: 6| Step: 9
Training loss: 3.028654265234841
Validation loss: 3.2433024322252146

Epoch: 6| Step: 10
Training loss: 2.9046846501591386
Validation loss: 3.2426736683863364

Epoch: 6| Step: 11
Training loss: 2.9430021336269387
Validation loss: 3.243445326661254

Epoch: 6| Step: 12
Training loss: 3.0676759848753834
Validation loss: 3.2435420488571474

Epoch: 6| Step: 13
Training loss: 3.997167060924456
Validation loss: 3.2429577276906816

Epoch: 127| Step: 0
Training loss: 3.680364396671226
Validation loss: 3.243028766692156

Epoch: 6| Step: 1
Training loss: 3.1678046808431355
Validation loss: 3.2422106298616673

Epoch: 6| Step: 2
Training loss: 3.0419879552037172
Validation loss: 3.2418195159590706

Epoch: 6| Step: 3
Training loss: 3.7305541343304376
Validation loss: 3.242179803188028

Epoch: 6| Step: 4
Training loss: 4.066002846825199
Validation loss: 3.2411547683838626

Epoch: 6| Step: 5
Training loss: 3.376929120341953
Validation loss: 3.242288888412707

Epoch: 6| Step: 6
Training loss: 3.296578778161535
Validation loss: 3.241331099787469

Epoch: 6| Step: 7
Training loss: 3.210753646747526
Validation loss: 3.2412137991612444

Epoch: 6| Step: 8
Training loss: 3.583995018717165
Validation loss: 3.242333308990041

Epoch: 6| Step: 9
Training loss: 2.8543062570411704
Validation loss: 3.2408576128645907

Epoch: 6| Step: 10
Training loss: 2.9350358082863064
Validation loss: 3.241365803684776

Epoch: 6| Step: 11
Training loss: 4.252367594349141
Validation loss: 3.2395810109873273

Epoch: 6| Step: 12
Training loss: 3.9080162022702813
Validation loss: 3.2404926834515355

Epoch: 6| Step: 13
Training loss: 3.2343486102957986
Validation loss: 3.239655264037502

Epoch: 128| Step: 0
Training loss: 3.8081531445859196
Validation loss: 3.2389936767473246

Epoch: 6| Step: 1
Training loss: 3.761093261941854
Validation loss: 3.2393459336882633

Epoch: 6| Step: 2
Training loss: 2.7263685447109594
Validation loss: 3.2398804817604185

Epoch: 6| Step: 3
Training loss: 4.1046370544935025
Validation loss: 3.2399619394662413

Epoch: 6| Step: 4
Training loss: 3.3611624287312347
Validation loss: 3.2392937122848275

Epoch: 6| Step: 5
Training loss: 3.9257967972328958
Validation loss: 3.2404859113989763

Epoch: 6| Step: 6
Training loss: 3.4999287461793447
Validation loss: 3.2397881400829838

Epoch: 6| Step: 7
Training loss: 3.513338557703331
Validation loss: 3.2402965239511707

Epoch: 6| Step: 8
Training loss: 2.6286246388392622
Validation loss: 3.239996952372963

Epoch: 6| Step: 9
Training loss: 3.5922192838041735
Validation loss: 3.240817562377065

Epoch: 6| Step: 10
Training loss: 3.154643490292094
Validation loss: 3.2403106242360242

Epoch: 6| Step: 11
Training loss: 3.24231883323044
Validation loss: 3.237826832883942

Epoch: 6| Step: 12
Training loss: 3.4309680260035917
Validation loss: 3.239442350935496

Epoch: 6| Step: 13
Training loss: 3.8367062670412
Validation loss: 3.239069914033307

Epoch: 129| Step: 0
Training loss: 3.003456191140808
Validation loss: 3.23817908375271

Epoch: 6| Step: 1
Training loss: 4.073554389894855
Validation loss: 3.2374393791781766

Epoch: 6| Step: 2
Training loss: 3.311902118203973
Validation loss: 3.237002688023226

Epoch: 6| Step: 3
Training loss: 3.173475791741453
Validation loss: 3.2375503163005512

Epoch: 6| Step: 4
Training loss: 3.266260404690661
Validation loss: 3.2366297628680267

Epoch: 6| Step: 5
Training loss: 3.489775300320712
Validation loss: 3.237195526184656

Epoch: 6| Step: 6
Training loss: 3.2394241506508257
Validation loss: 3.2370138533347284

Epoch: 6| Step: 7
Training loss: 3.2689982974566405
Validation loss: 3.2372551898361226

Epoch: 6| Step: 8
Training loss: 3.3276558845399093
Validation loss: 3.2355587230654512

Epoch: 6| Step: 9
Training loss: 4.869495512036955
Validation loss: 3.237889010627367

Epoch: 6| Step: 10
Training loss: 2.908170988111557
Validation loss: 3.2372134317309835

Epoch: 6| Step: 11
Training loss: 3.344474642657046
Validation loss: 3.2376474046426056

Epoch: 6| Step: 12
Training loss: 3.2009818001455868
Validation loss: 3.2367706549785367

Epoch: 6| Step: 13
Training loss: 3.973323079635737
Validation loss: 3.2368913416727008

Epoch: 130| Step: 0
Training loss: 3.2207413226396184
Validation loss: 3.2353706050149333

Epoch: 6| Step: 1
Training loss: 3.6386704334823365
Validation loss: 3.2350848112958235

Epoch: 6| Step: 2
Training loss: 2.805390931221091
Validation loss: 3.2346282680690623

Epoch: 6| Step: 3
Training loss: 4.153147521865664
Validation loss: 3.2343081241046905

Epoch: 6| Step: 4
Training loss: 4.0693405074443385
Validation loss: 3.2345978969839755

Epoch: 6| Step: 5
Training loss: 2.8252619799103504
Validation loss: 3.2349891612534845

Epoch: 6| Step: 6
Training loss: 3.2024547340833
Validation loss: 3.2334680897276686

Epoch: 6| Step: 7
Training loss: 2.5840196210630006
Validation loss: 3.234404964188339

Epoch: 6| Step: 8
Training loss: 3.2841165283010225
Validation loss: 3.2343585007135593

Epoch: 6| Step: 9
Training loss: 3.9760758677407395
Validation loss: 3.233985963481512

Epoch: 6| Step: 10
Training loss: 3.4179606584725652
Validation loss: 3.2355459926226904

Epoch: 6| Step: 11
Training loss: 3.675403733685705
Validation loss: 3.2345947076864703

Epoch: 6| Step: 12
Training loss: 4.0803291532099655
Validation loss: 3.2344435405716436

Epoch: 6| Step: 13
Training loss: 3.093608660311103
Validation loss: 3.236157520229058

Epoch: 131| Step: 0
Training loss: 3.6351516903968153
Validation loss: 3.2337135485502926

Epoch: 6| Step: 1
Training loss: 3.707374677437036
Validation loss: 3.2332595535358566

Epoch: 6| Step: 2
Training loss: 3.7229952902977987
Validation loss: 3.233252749286183

Epoch: 6| Step: 3
Training loss: 2.924401807342167
Validation loss: 3.2329756999367465

Epoch: 6| Step: 4
Training loss: 3.3817973034177857
Validation loss: 3.232028001249838

Epoch: 6| Step: 5
Training loss: 2.984617532991004
Validation loss: 3.2306879678983416

Epoch: 6| Step: 6
Training loss: 3.2425658958874473
Validation loss: 3.2318251025676985

Epoch: 6| Step: 7
Training loss: 3.1694741770265127
Validation loss: 3.2317857794104405

Epoch: 6| Step: 8
Training loss: 3.959113970961002
Validation loss: 3.2311179186619077

Epoch: 6| Step: 9
Training loss: 4.164660670274969
Validation loss: 3.23124900997638

Epoch: 6| Step: 10
Training loss: 2.8768394225027945
Validation loss: 3.2310874955384605

Epoch: 6| Step: 11
Training loss: 3.4549105761558283
Validation loss: 3.2315045095360926

Epoch: 6| Step: 12
Training loss: 3.6209923525278853
Validation loss: 3.2310715919953252

Epoch: 6| Step: 13
Training loss: 3.5794472729097455
Validation loss: 3.2316618447158136

Epoch: 132| Step: 0
Training loss: 3.3292585421517993
Validation loss: 3.2297607817433174

Epoch: 6| Step: 1
Training loss: 3.0393820940264766
Validation loss: 3.2308259403875956

Epoch: 6| Step: 2
Training loss: 3.882304413555083
Validation loss: 3.2309528397858887

Epoch: 6| Step: 3
Training loss: 4.389677440984551
Validation loss: 3.23007670006268

Epoch: 6| Step: 4
Training loss: 2.8520855149640885
Validation loss: 3.2300752190592963

Epoch: 6| Step: 5
Training loss: 4.1861891331637375
Validation loss: 3.2294707018532702

Epoch: 6| Step: 6
Training loss: 3.451530537213369
Validation loss: 3.2292004401233374

Epoch: 6| Step: 7
Training loss: 3.104332904503385
Validation loss: 3.2286802774374386

Epoch: 6| Step: 8
Training loss: 3.400427224862263
Validation loss: 3.2278578319109226

Epoch: 6| Step: 9
Training loss: 3.249107531739696
Validation loss: 3.228696918491169

Epoch: 6| Step: 10
Training loss: 3.5995383708406687
Validation loss: 3.228131393789851

Epoch: 6| Step: 11
Training loss: 2.359342764324746
Validation loss: 3.228851368595614

Epoch: 6| Step: 12
Training loss: 3.154877165807799
Validation loss: 3.226990779178453

Epoch: 6| Step: 13
Training loss: 4.436993422270588
Validation loss: 3.226626962168129

Epoch: 133| Step: 0
Training loss: 3.8996714624771647
Validation loss: 3.2284873626319404

Epoch: 6| Step: 1
Training loss: 3.3909380368348403
Validation loss: 3.2263035164641254

Epoch: 6| Step: 2
Training loss: 2.9648554905996956
Validation loss: 3.2287997547750567

Epoch: 6| Step: 3
Training loss: 4.137842013234587
Validation loss: 3.228742921927457

Epoch: 6| Step: 4
Training loss: 3.252377447448089
Validation loss: 3.227328095356289

Epoch: 6| Step: 5
Training loss: 2.7717202471311806
Validation loss: 3.228097351309691

Epoch: 6| Step: 6
Training loss: 3.1974004438588346
Validation loss: 3.227232218594715

Epoch: 6| Step: 7
Training loss: 3.3200518337477765
Validation loss: 3.22788183961045

Epoch: 6| Step: 8
Training loss: 3.338719657323045
Validation loss: 3.228126825800023

Epoch: 6| Step: 9
Training loss: 4.040080017959257
Validation loss: 3.2272881549954207

Epoch: 6| Step: 10
Training loss: 2.8045644069001465
Validation loss: 3.2278112583072374

Epoch: 6| Step: 11
Training loss: 4.140578705150984
Validation loss: 3.2262396882986555

Epoch: 6| Step: 12
Training loss: 3.806898285477199
Validation loss: 3.22547914233962

Epoch: 6| Step: 13
Training loss: 2.7452806378655805
Validation loss: 3.2268956248871463

Epoch: 134| Step: 0
Training loss: 3.0140837056079945
Validation loss: 3.2251590631344604

Epoch: 6| Step: 1
Training loss: 4.003258808171797
Validation loss: 3.225103030983903

Epoch: 6| Step: 2
Training loss: 3.9349011518575834
Validation loss: 3.2240892317737617

Epoch: 6| Step: 3
Training loss: 3.1961353986511947
Validation loss: 3.2234121429150813

Epoch: 6| Step: 4
Training loss: 2.7587585555558833
Validation loss: 3.2242124016288893

Epoch: 6| Step: 5
Training loss: 3.5786878651172556
Validation loss: 3.224559498012104

Epoch: 6| Step: 6
Training loss: 4.117664172032802
Validation loss: 3.2239261881180155

Epoch: 6| Step: 7
Training loss: 3.5153507380000115
Validation loss: 3.2244156537244697

Epoch: 6| Step: 8
Training loss: 3.1312769601236132
Validation loss: 3.223826133905034

Epoch: 6| Step: 9
Training loss: 3.0621686483691075
Validation loss: 3.2259815990931577

Epoch: 6| Step: 10
Training loss: 3.2058921212687257
Validation loss: 3.224371391796398

Epoch: 6| Step: 11
Training loss: 3.783418648271801
Validation loss: 3.223043250509844

Epoch: 6| Step: 12
Training loss: 3.862691342450683
Validation loss: 3.2223935793031244

Epoch: 6| Step: 13
Training loss: 2.6187435250213618
Validation loss: 3.2229025433972756

Epoch: 135| Step: 0
Training loss: 4.23329875261095
Validation loss: 3.2228608125090648

Epoch: 6| Step: 1
Training loss: 3.439769619834535
Validation loss: 3.223892228465337

Epoch: 6| Step: 2
Training loss: 3.069047429419011
Validation loss: 3.222294799780336

Epoch: 6| Step: 3
Training loss: 3.3209233698172325
Validation loss: 3.2224827933219027

Epoch: 6| Step: 4
Training loss: 3.1404822777349946
Validation loss: 3.2205722428303116

Epoch: 6| Step: 5
Training loss: 3.708535406771958
Validation loss: 3.2226147259385938

Epoch: 6| Step: 6
Training loss: 3.419828595556485
Validation loss: 3.2208611414325152

Epoch: 6| Step: 7
Training loss: 3.2023067266553387
Validation loss: 3.2222473151569258

Epoch: 6| Step: 8
Training loss: 3.321758790015526
Validation loss: 3.2196556288349782

Epoch: 6| Step: 9
Training loss: 3.7651789864072356
Validation loss: 3.2212497312487955

Epoch: 6| Step: 10
Training loss: 2.953462773135108
Validation loss: 3.2216881621900706

Epoch: 6| Step: 11
Training loss: 3.789167076319436
Validation loss: 3.2215527490941867

Epoch: 6| Step: 12
Training loss: 3.6086771236681376
Validation loss: 3.222971437714283

Epoch: 6| Step: 13
Training loss: 3.2087228381705493
Validation loss: 3.220504465771244

Epoch: 136| Step: 0
Training loss: 3.1902714069151346
Validation loss: 3.2211217396578533

Epoch: 6| Step: 1
Training loss: 3.3693449892728826
Validation loss: 3.2206495466104994

Epoch: 6| Step: 2
Training loss: 3.0284675333551023
Validation loss: 3.2211799469355125

Epoch: 6| Step: 3
Training loss: 3.4983010937164005
Validation loss: 3.2225062412265264

Epoch: 6| Step: 4
Training loss: 4.058265474497574
Validation loss: 3.2203043199355195

Epoch: 6| Step: 5
Training loss: 3.4027591280955947
Validation loss: 3.221446089210179

Epoch: 6| Step: 6
Training loss: 3.074308556453103
Validation loss: 3.2201860702674465

Epoch: 6| Step: 7
Training loss: 3.180057588451684
Validation loss: 3.2194568763029565

Epoch: 6| Step: 8
Training loss: 3.8315470444993136
Validation loss: 3.220431664182795

Epoch: 6| Step: 9
Training loss: 3.2266777701488953
Validation loss: 3.22093883703979

Epoch: 6| Step: 10
Training loss: 3.41345488773909
Validation loss: 3.217818109661998

Epoch: 6| Step: 11
Training loss: 4.010836703940193
Validation loss: 3.2183208408460455

Epoch: 6| Step: 12
Training loss: 3.947423389119017
Validation loss: 3.2181810608362

Epoch: 6| Step: 13
Training loss: 2.5623546652169145
Validation loss: 3.219979380857059

Epoch: 137| Step: 0
Training loss: 3.308224203646391
Validation loss: 3.217335835657562

Epoch: 6| Step: 1
Training loss: 4.224983413934599
Validation loss: 3.218608981742108

Epoch: 6| Step: 2
Training loss: 3.073497101012402
Validation loss: 3.2184915682775017

Epoch: 6| Step: 3
Training loss: 4.015766067105116
Validation loss: 3.2169415134051604

Epoch: 6| Step: 4
Training loss: 3.5858944161014743
Validation loss: 3.2166946241169203

Epoch: 6| Step: 5
Training loss: 3.7967511694538296
Validation loss: 3.217798296430462

Epoch: 6| Step: 6
Training loss: 3.197831855833892
Validation loss: 3.2176098969293583

Epoch: 6| Step: 7
Training loss: 4.0158940681529405
Validation loss: 3.2179732213227523

Epoch: 6| Step: 8
Training loss: 3.394675933247894
Validation loss: 3.2167950738824027

Epoch: 6| Step: 9
Training loss: 3.693735830728428
Validation loss: 3.2163494814682534

Epoch: 6| Step: 10
Training loss: 2.9764365822898955
Validation loss: 3.2166579197998413

Epoch: 6| Step: 11
Training loss: 2.5787927860883944
Validation loss: 3.21523154654049

Epoch: 6| Step: 12
Training loss: 2.822968983370699
Validation loss: 3.216720634244487

Epoch: 6| Step: 13
Training loss: 3.234455347214959
Validation loss: 3.2155179710884756

Epoch: 138| Step: 0
Training loss: 3.3484664880135946
Validation loss: 3.2178935906704824

Epoch: 6| Step: 1
Training loss: 3.4845579638149276
Validation loss: 3.215313531436485

Epoch: 6| Step: 2
Training loss: 4.160842538022883
Validation loss: 3.215831793703219

Epoch: 6| Step: 3
Training loss: 3.4823056221394304
Validation loss: 3.215259721310262

Epoch: 6| Step: 4
Training loss: 3.2804406030641577
Validation loss: 3.2160473412606803

Epoch: 6| Step: 5
Training loss: 3.5750411291357485
Validation loss: 3.2161236043541064

Epoch: 6| Step: 6
Training loss: 3.181523872982554
Validation loss: 3.2138815377482763

Epoch: 6| Step: 7
Training loss: 3.9478255020660655
Validation loss: 3.215843270082303

Epoch: 6| Step: 8
Training loss: 3.398056675411922
Validation loss: 3.2133051465991738

Epoch: 6| Step: 9
Training loss: 3.768654392225367
Validation loss: 3.2149284336787214

Epoch: 6| Step: 10
Training loss: 3.0412047222638146
Validation loss: 3.212463792204469

Epoch: 6| Step: 11
Training loss: 3.4567128870003505
Validation loss: 3.2137375330136244

Epoch: 6| Step: 12
Training loss: 3.1389551990297844
Validation loss: 3.2118290614840603

Epoch: 6| Step: 13
Training loss: 2.453634124211845
Validation loss: 3.2118844743496826

Epoch: 139| Step: 0
Training loss: 2.4098448219833655
Validation loss: 3.2106993218404467

Epoch: 6| Step: 1
Training loss: 3.6745401003854647
Validation loss: 3.212003218002402

Epoch: 6| Step: 2
Training loss: 3.93501627258271
Validation loss: 3.2122284367250544

Epoch: 6| Step: 3
Training loss: 2.934736697134233
Validation loss: 3.214655751532899

Epoch: 6| Step: 4
Training loss: 3.5459602957803247
Validation loss: 3.2139568104913363

Epoch: 6| Step: 5
Training loss: 4.194643901492372
Validation loss: 3.2141314180253358

Epoch: 6| Step: 6
Training loss: 3.321567719997633
Validation loss: 3.214923023992919

Epoch: 6| Step: 7
Training loss: 3.0627385260666204
Validation loss: 3.2143269012281293

Epoch: 6| Step: 8
Training loss: 4.091921565447989
Validation loss: 3.2159934525370866

Epoch: 6| Step: 9
Training loss: 2.5302014474996253
Validation loss: 3.2142240708822896

Epoch: 6| Step: 10
Training loss: 3.4045293819410634
Validation loss: 3.2095712820531723

Epoch: 6| Step: 11
Training loss: 3.121749102523527
Validation loss: 3.2086492595187863

Epoch: 6| Step: 12
Training loss: 3.3774905022657737
Validation loss: 3.2137761612422175

Epoch: 6| Step: 13
Training loss: 4.641931009669915
Validation loss: 3.212080929137063

Epoch: 140| Step: 0
Training loss: 3.37034129986862
Validation loss: 3.2117008972114793

Epoch: 6| Step: 1
Training loss: 3.0908926667577754
Validation loss: 3.211034154708448

Epoch: 6| Step: 2
Training loss: 3.058243264960422
Validation loss: 3.209881263021466

Epoch: 6| Step: 3
Training loss: 3.457095525973792
Validation loss: 3.2102245200616126

Epoch: 6| Step: 4
Training loss: 3.0698547798626894
Validation loss: 3.2087786562142275

Epoch: 6| Step: 5
Training loss: 3.8247941454177345
Validation loss: 3.210410760906279

Epoch: 6| Step: 6
Training loss: 4.316810333531979
Validation loss: 3.210105750544618

Epoch: 6| Step: 7
Training loss: 2.5975506983372103
Validation loss: 3.2083348637931337

Epoch: 6| Step: 8
Training loss: 4.132306188710592
Validation loss: 3.207169218636487

Epoch: 6| Step: 9
Training loss: 3.369558398011143
Validation loss: 3.2077718391760692

Epoch: 6| Step: 10
Training loss: 2.9505103106309676
Validation loss: 3.206339944133073

Epoch: 6| Step: 11
Training loss: 3.137018210818178
Validation loss: 3.2078869462092587

Epoch: 6| Step: 12
Training loss: 3.869364424370491
Validation loss: 3.208314246472616

Epoch: 6| Step: 13
Training loss: 3.833450287955942
Validation loss: 3.2074071002352214

Epoch: 141| Step: 0
Training loss: 3.4722790336199787
Validation loss: 3.20677463675482

Epoch: 6| Step: 1
Training loss: 3.1423288155167115
Validation loss: 3.208274504099962

Epoch: 6| Step: 2
Training loss: 3.8030721693671605
Validation loss: 3.206438226953115

Epoch: 6| Step: 3
Training loss: 3.2322097386016773
Validation loss: 3.207554676498268

Epoch: 6| Step: 4
Training loss: 3.491134040892657
Validation loss: 3.207130868942382

Epoch: 6| Step: 5
Training loss: 3.1126792641610357
Validation loss: 3.206438951326388

Epoch: 6| Step: 6
Training loss: 4.3242593296424765
Validation loss: 3.2079267860856313

Epoch: 6| Step: 7
Training loss: 2.851824019471943
Validation loss: 3.2055841217864827

Epoch: 6| Step: 8
Training loss: 3.722566201240702
Validation loss: 3.208135437079255

Epoch: 6| Step: 9
Training loss: 4.139459179554056
Validation loss: 3.207155234832081

Epoch: 6| Step: 10
Training loss: 3.021020203872293
Validation loss: 3.207201935736476

Epoch: 6| Step: 11
Training loss: 3.0588283716784854
Validation loss: 3.207514848784475

Epoch: 6| Step: 12
Training loss: 2.6609466319619064
Validation loss: 3.205838001064781

Epoch: 6| Step: 13
Training loss: 4.109686894057441
Validation loss: 3.2056384030234293

Epoch: 142| Step: 0
Training loss: 3.5965847610844026
Validation loss: 3.20526441692949

Epoch: 6| Step: 1
Training loss: 4.099945737898361
Validation loss: 3.205567789411339

Epoch: 6| Step: 2
Training loss: 3.3557842137433367
Validation loss: 3.2042282593564972

Epoch: 6| Step: 3
Training loss: 3.759731128088494
Validation loss: 3.2031678507790144

Epoch: 6| Step: 4
Training loss: 4.206640878911683
Validation loss: 3.2028720998983458

Epoch: 6| Step: 5
Training loss: 2.8558020442884535
Validation loss: 3.2033065252243094

Epoch: 6| Step: 6
Training loss: 3.0559371382454374
Validation loss: 3.203653969295257

Epoch: 6| Step: 7
Training loss: 3.176972901139573
Validation loss: 3.2026660413301986

Epoch: 6| Step: 8
Training loss: 3.7522672792736156
Validation loss: 3.203720752089203

Epoch: 6| Step: 9
Training loss: 2.6245968827025408
Validation loss: 3.2038346739722696

Epoch: 6| Step: 10
Training loss: 2.9380960062751256
Validation loss: 3.20179410747998

Epoch: 6| Step: 11
Training loss: 3.2243529506047013
Validation loss: 3.202391970815929

Epoch: 6| Step: 12
Training loss: 4.2824039435539705
Validation loss: 3.2030460631065494

Epoch: 6| Step: 13
Training loss: 2.169448045420158
Validation loss: 3.202020646350729

Epoch: 143| Step: 0
Training loss: 2.780739383758525
Validation loss: 3.2018460653550727

Epoch: 6| Step: 1
Training loss: 3.2803403047479103
Validation loss: 3.2015652111990893

Epoch: 6| Step: 2
Training loss: 3.296434707529615
Validation loss: 3.2026542311622985

Epoch: 6| Step: 3
Training loss: 3.9561035032704677
Validation loss: 3.201520000758969

Epoch: 6| Step: 4
Training loss: 3.9158926395120397
Validation loss: 3.201103240295684

Epoch: 6| Step: 5
Training loss: 3.307201538459852
Validation loss: 3.2019611284057174

Epoch: 6| Step: 6
Training loss: 3.5312408177079178
Validation loss: 3.2018172208797258

Epoch: 6| Step: 7
Training loss: 3.2349350301594972
Validation loss: 3.2021931779282524

Epoch: 6| Step: 8
Training loss: 3.112223638192007
Validation loss: 3.2013566116638326

Epoch: 6| Step: 9
Training loss: 3.5916472544370466
Validation loss: 3.2032373007980257

Epoch: 6| Step: 10
Training loss: 3.01539381653117
Validation loss: 3.206211104676109

Epoch: 6| Step: 11
Training loss: 4.017297062665054
Validation loss: 3.20446449842598

Epoch: 6| Step: 12
Training loss: 3.1805655651869724
Validation loss: 3.203372633411035

Epoch: 6| Step: 13
Training loss: 3.993386165182378
Validation loss: 3.200560282167031

Epoch: 144| Step: 0
Training loss: 3.4926629137559178
Validation loss: 3.2002698321172742

Epoch: 6| Step: 1
Training loss: 3.525657073120018
Validation loss: 3.2004537925900154

Epoch: 6| Step: 2
Training loss: 3.7241943000069293
Validation loss: 3.201005730708344

Epoch: 6| Step: 3
Training loss: 2.7975432380832492
Validation loss: 3.199076518184392

Epoch: 6| Step: 4
Training loss: 3.6075305271773654
Validation loss: 3.19964454699422

Epoch: 6| Step: 5
Training loss: 3.249968455234908
Validation loss: 3.199766507397832

Epoch: 6| Step: 6
Training loss: 4.424338581200982
Validation loss: 3.1989724346901296

Epoch: 6| Step: 7
Training loss: 2.9737396070724462
Validation loss: 3.2000122616773945

Epoch: 6| Step: 8
Training loss: 3.2160025416691544
Validation loss: 3.1989607519319345

Epoch: 6| Step: 9
Training loss: 3.8332663129393354
Validation loss: 3.1991726056883603

Epoch: 6| Step: 10
Training loss: 3.793913514385729
Validation loss: 3.19710882790424

Epoch: 6| Step: 11
Training loss: 3.1438307461692467
Validation loss: 3.1986572561398963

Epoch: 6| Step: 12
Training loss: 3.257217316266408
Validation loss: 3.1987067235343316

Epoch: 6| Step: 13
Training loss: 2.157411787543749
Validation loss: 3.1976133021425133

Epoch: 145| Step: 0
Training loss: 4.187885095909161
Validation loss: 3.1972357762032573

Epoch: 6| Step: 1
Training loss: 3.1356486660279232
Validation loss: 3.197024579946761

Epoch: 6| Step: 2
Training loss: 3.2108861171945624
Validation loss: 3.1962354053158633

Epoch: 6| Step: 3
Training loss: 2.9787437476678016
Validation loss: 3.1982243515377755

Epoch: 6| Step: 4
Training loss: 3.70181341323232
Validation loss: 3.1985784943199236

Epoch: 6| Step: 5
Training loss: 3.363540409041038
Validation loss: 3.196153072214589

Epoch: 6| Step: 6
Training loss: 3.2559712647615804
Validation loss: 3.1968529450483345

Epoch: 6| Step: 7
Training loss: 2.967899883422212
Validation loss: 3.1966316249590228

Epoch: 6| Step: 8
Training loss: 3.3023975274982362
Validation loss: 3.194521514072264

Epoch: 6| Step: 9
Training loss: 3.4486023988347836
Validation loss: 3.1939625431104948

Epoch: 6| Step: 10
Training loss: 4.036221536232963
Validation loss: 3.1936466742714895

Epoch: 6| Step: 11
Training loss: 3.381789266345225
Validation loss: 3.1947440042760067

Epoch: 6| Step: 12
Training loss: 3.2646409883907688
Validation loss: 3.196222291259774

Epoch: 6| Step: 13
Training loss: 3.8958748935923797
Validation loss: 3.1949214704564164

Epoch: 146| Step: 0
Training loss: 4.23062203958199
Validation loss: 3.192674302859228

Epoch: 6| Step: 1
Training loss: 4.018193829674227
Validation loss: 3.1946663015426235

Epoch: 6| Step: 2
Training loss: 4.110531024273345
Validation loss: 3.1958970037404972

Epoch: 6| Step: 3
Training loss: 3.3347045621166447
Validation loss: 3.1940659583391415

Epoch: 6| Step: 4
Training loss: 3.6926102223923665
Validation loss: 3.195943748833242

Epoch: 6| Step: 5
Training loss: 3.308277533866962
Validation loss: 3.195934788755002

Epoch: 6| Step: 6
Training loss: 2.64293565044374
Validation loss: 3.1926280760029297

Epoch: 6| Step: 7
Training loss: 2.7960665935722844
Validation loss: 3.19408298359815

Epoch: 6| Step: 8
Training loss: 3.3792037215515798
Validation loss: 3.1948365236747556

Epoch: 6| Step: 9
Training loss: 3.2540217238288975
Validation loss: 3.196457404083949

Epoch: 6| Step: 10
Training loss: 3.488298063675534
Validation loss: 3.194054122793056

Epoch: 6| Step: 11
Training loss: 3.4481991808685275
Validation loss: 3.1959438065883647

Epoch: 6| Step: 12
Training loss: 2.6498933914620983
Validation loss: 3.193282508834415

Epoch: 6| Step: 13
Training loss: 3.2592057649560506
Validation loss: 3.1933499998449446

Epoch: 147| Step: 0
Training loss: 3.3115781544985543
Validation loss: 3.192623610585974

Epoch: 6| Step: 1
Training loss: 3.1634632437921923
Validation loss: 3.1915364156747548

Epoch: 6| Step: 2
Training loss: 4.087531805352176
Validation loss: 3.19229514240915

Epoch: 6| Step: 3
Training loss: 3.433203074999644
Validation loss: 3.1932260393711216

Epoch: 6| Step: 4
Training loss: 3.073585377147945
Validation loss: 3.1933139375944566

Epoch: 6| Step: 5
Training loss: 4.140007462425693
Validation loss: 3.1922806099976824

Epoch: 6| Step: 6
Training loss: 3.111817440581677
Validation loss: 3.192048022984347

Epoch: 6| Step: 7
Training loss: 3.691200339412467
Validation loss: 3.1933755193410547

Epoch: 6| Step: 8
Training loss: 3.111219309635913
Validation loss: 3.1953481385430145

Epoch: 6| Step: 9
Training loss: 3.5204566137053774
Validation loss: 3.197913082711751

Epoch: 6| Step: 10
Training loss: 3.4134057153040724
Validation loss: 3.196990656895462

Epoch: 6| Step: 11
Training loss: 3.183759701387911
Validation loss: 3.190484689398203

Epoch: 6| Step: 12
Training loss: 3.0541426619089016
Validation loss: 3.189500781169182

Epoch: 6| Step: 13
Training loss: 3.72008701940503
Validation loss: 3.1905427083422344

Epoch: 148| Step: 0
Training loss: 3.241121194901021
Validation loss: 3.190727035190823

Epoch: 6| Step: 1
Training loss: 3.73827869889542
Validation loss: 3.1890569170434877

Epoch: 6| Step: 2
Training loss: 3.6823914913187754
Validation loss: 3.1903681051407373

Epoch: 6| Step: 3
Training loss: 2.931133106886005
Validation loss: 3.1887322540644183

Epoch: 6| Step: 4
Training loss: 3.2204043386839265
Validation loss: 3.1891738691683003

Epoch: 6| Step: 5
Training loss: 3.6045362396979583
Validation loss: 3.188242491837943

Epoch: 6| Step: 6
Training loss: 3.743392973164598
Validation loss: 3.1877823667786864

Epoch: 6| Step: 7
Training loss: 3.7677559422543636
Validation loss: 3.189300749085336

Epoch: 6| Step: 8
Training loss: 3.23572530525037
Validation loss: 3.1890087879799296

Epoch: 6| Step: 9
Training loss: 3.1664588425017186
Validation loss: 3.188573784697965

Epoch: 6| Step: 10
Training loss: 3.7425733140429362
Validation loss: 3.1882969959517085

Epoch: 6| Step: 11
Training loss: 3.4281272032738475
Validation loss: 3.189575732296906

Epoch: 6| Step: 12
Training loss: 3.1956906269809697
Validation loss: 3.1866667316042196

Epoch: 6| Step: 13
Training loss: 3.063727308085781
Validation loss: 3.187677660371695

Epoch: 149| Step: 0
Training loss: 3.0710583428840863
Validation loss: 3.1894169801059364

Epoch: 6| Step: 1
Training loss: 3.2377664228124003
Validation loss: 3.187948911528305

Epoch: 6| Step: 2
Training loss: 2.7687106403110686
Validation loss: 3.1869234998982576

Epoch: 6| Step: 3
Training loss: 3.5759153248023434
Validation loss: 3.1867901411560218

Epoch: 6| Step: 4
Training loss: 3.4606375467418475
Validation loss: 3.1856868427930274

Epoch: 6| Step: 5
Training loss: 4.044669592416222
Validation loss: 3.186977310643598

Epoch: 6| Step: 6
Training loss: 2.8735751062563835
Validation loss: 3.1851878682757704

Epoch: 6| Step: 7
Training loss: 4.0095801071306765
Validation loss: 3.1842046807146653

Epoch: 6| Step: 8
Training loss: 3.8712117536094794
Validation loss: 3.1882035381617535

Epoch: 6| Step: 9
Training loss: 3.5132734105635794
Validation loss: 3.186513927989676

Epoch: 6| Step: 10
Training loss: 4.05869572853715
Validation loss: 3.184828135261993

Epoch: 6| Step: 11
Training loss: 2.622349809067845
Validation loss: 3.1870547085524645

Epoch: 6| Step: 12
Training loss: 3.383777084439478
Validation loss: 3.1833655011751345

Epoch: 6| Step: 13
Training loss: 2.8784802146179964
Validation loss: 3.1872951740146322

Epoch: 150| Step: 0
Training loss: 2.7644944978501584
Validation loss: 3.1841746450736785

Epoch: 6| Step: 1
Training loss: 3.4837990870745634
Validation loss: 3.1849600226593235

Epoch: 6| Step: 2
Training loss: 4.061031134693888
Validation loss: 3.183299391441603

Epoch: 6| Step: 3
Training loss: 2.569067563663416
Validation loss: 3.1839886007093052

Epoch: 6| Step: 4
Training loss: 3.318900779847841
Validation loss: 3.183557637629711

Epoch: 6| Step: 5
Training loss: 4.078002927860483
Validation loss: 3.180518447376017

Epoch: 6| Step: 6
Training loss: 2.4210505897439165
Validation loss: 3.182968375167069

Epoch: 6| Step: 7
Training loss: 3.2429827714404182
Validation loss: 3.1815794542908122

Epoch: 6| Step: 8
Training loss: 3.8213942542782546
Validation loss: 3.1821092836930576

Epoch: 6| Step: 9
Training loss: 3.806199918771382
Validation loss: 3.1788667017172663

Epoch: 6| Step: 10
Training loss: 4.21675232107947
Validation loss: 3.182110087723593

Epoch: 6| Step: 11
Training loss: 2.9242873407748453
Validation loss: 3.1801140998848196

Epoch: 6| Step: 12
Training loss: 2.899433962071742
Validation loss: 3.1811431272411905

Epoch: 6| Step: 13
Training loss: 4.01512552561563
Validation loss: 3.180450456762994

Epoch: 151| Step: 0
Training loss: 4.1868016813663145
Validation loss: 3.180670660474531

Epoch: 6| Step: 1
Training loss: 3.0127470682851785
Validation loss: 3.180754237395213

Epoch: 6| Step: 2
Training loss: 3.622314773994581
Validation loss: 3.1805965183135845

Epoch: 6| Step: 3
Training loss: 3.2722812695474772
Validation loss: 3.1811973403829454

Epoch: 6| Step: 4
Training loss: 3.325138668524516
Validation loss: 3.179760428201524

Epoch: 6| Step: 5
Training loss: 3.592746229553474
Validation loss: 3.1807798015290145

Epoch: 6| Step: 6
Training loss: 2.7501589989213615
Validation loss: 3.1797095639123256

Epoch: 6| Step: 7
Training loss: 3.570627945668885
Validation loss: 3.1818388488230442

Epoch: 6| Step: 8
Training loss: 2.717778701036944
Validation loss: 3.1823957457870597

Epoch: 6| Step: 9
Training loss: 3.2092405415480507
Validation loss: 3.1806974858635564

Epoch: 6| Step: 10
Training loss: 3.3434627801766776
Validation loss: 3.1804259507680315

Epoch: 6| Step: 11
Training loss: 3.8522717053142737
Validation loss: 3.1813202594090324

Epoch: 6| Step: 12
Training loss: 4.0386306266179925
Validation loss: 3.180951926509874

Epoch: 6| Step: 13
Training loss: 2.89288027651517
Validation loss: 3.1800960485815546

Epoch: 152| Step: 0
Training loss: 3.5101726383019387
Validation loss: 3.181004619718579

Epoch: 6| Step: 1
Training loss: 3.3408093222287074
Validation loss: 3.183713305636889

Epoch: 6| Step: 2
Training loss: 3.8064872980921804
Validation loss: 3.1807089471560306

Epoch: 6| Step: 3
Training loss: 3.2718723533933005
Validation loss: 3.179851251119473

Epoch: 6| Step: 4
Training loss: 3.8076781752056594
Validation loss: 3.178552216927877

Epoch: 6| Step: 5
Training loss: 2.936385572347778
Validation loss: 3.17822776179235

Epoch: 6| Step: 6
Training loss: 3.065890867815502
Validation loss: 3.1768810146606734

Epoch: 6| Step: 7
Training loss: 2.4442696099420838
Validation loss: 3.177194118871273

Epoch: 6| Step: 8
Training loss: 3.7412796352753657
Validation loss: 3.177616369328609

Epoch: 6| Step: 9
Training loss: 4.351509463742106
Validation loss: 3.1770086066167456

Epoch: 6| Step: 10
Training loss: 2.940885662399863
Validation loss: 3.17692845110079

Epoch: 6| Step: 11
Training loss: 3.6736684761464033
Validation loss: 3.1782455930131306

Epoch: 6| Step: 12
Training loss: 3.593190290568174
Validation loss: 3.1770159255121784

Epoch: 6| Step: 13
Training loss: 2.67240320528201
Validation loss: 3.1791611231447776

Epoch: 153| Step: 0
Training loss: 3.462960300078098
Validation loss: 3.1767920242348233

Epoch: 6| Step: 1
Training loss: 3.2197643274343464
Validation loss: 3.1780921166966003

Epoch: 6| Step: 2
Training loss: 3.3546617667744103
Validation loss: 3.1785447531655486

Epoch: 6| Step: 3
Training loss: 3.558418746983249
Validation loss: 3.1809982609900485

Epoch: 6| Step: 4
Training loss: 3.0718443642967843
Validation loss: 3.17934313767769

Epoch: 6| Step: 5
Training loss: 3.266930132251633
Validation loss: 3.181306722850779

Epoch: 6| Step: 6
Training loss: 3.6166314177546
Validation loss: 3.1826025625659975

Epoch: 6| Step: 7
Training loss: 3.815571282685836
Validation loss: 3.18253248825512

Epoch: 6| Step: 8
Training loss: 2.927872484651091
Validation loss: 3.1798022780783954

Epoch: 6| Step: 9
Training loss: 3.4112699422676234
Validation loss: 3.1809958351599716

Epoch: 6| Step: 10
Training loss: 2.554789036590766
Validation loss: 3.1772322554091312

Epoch: 6| Step: 11
Training loss: 4.1076104034241565
Validation loss: 3.1768029976711984

Epoch: 6| Step: 12
Training loss: 3.3226902963350176
Validation loss: 3.174073430604929

Epoch: 6| Step: 13
Training loss: 4.247597857016556
Validation loss: 3.1743469757219267

Epoch: 154| Step: 0
Training loss: 3.669053572356404
Validation loss: 3.172373146322699

Epoch: 6| Step: 1
Training loss: 2.8653184167229
Validation loss: 3.173396644057247

Epoch: 6| Step: 2
Training loss: 3.507441783593195
Validation loss: 3.1728827670214

Epoch: 6| Step: 3
Training loss: 3.809228963454482
Validation loss: 3.172332421940836

Epoch: 6| Step: 4
Training loss: 3.9258768402152624
Validation loss: 3.172165552702294

Epoch: 6| Step: 5
Training loss: 3.5808004846117445
Validation loss: 3.1724463574162147

Epoch: 6| Step: 6
Training loss: 3.1963860310298555
Validation loss: 3.1711617761111377

Epoch: 6| Step: 7
Training loss: 3.5576612839962025
Validation loss: 3.1704315598077106

Epoch: 6| Step: 8
Training loss: 2.5751382809147394
Validation loss: 3.171243395080237

Epoch: 6| Step: 9
Training loss: 3.414998151072145
Validation loss: 3.1720835339700595

Epoch: 6| Step: 10
Training loss: 3.614510453925013
Validation loss: 3.172301262110168

Epoch: 6| Step: 11
Training loss: 2.9239884347230314
Validation loss: 3.170273002102275

Epoch: 6| Step: 12
Training loss: 3.702108380446376
Validation loss: 3.170302045435529

Epoch: 6| Step: 13
Training loss: 3.1687862597315206
Validation loss: 3.171153344246331

Epoch: 155| Step: 0
Training loss: 2.199629154160428
Validation loss: 3.171313442370867

Epoch: 6| Step: 1
Training loss: 3.4837507706590998
Validation loss: 3.1713875299449996

Epoch: 6| Step: 2
Training loss: 3.2395965150685564
Validation loss: 3.1702877130253424

Epoch: 6| Step: 3
Training loss: 3.3739339769706564
Validation loss: 3.168614894621508

Epoch: 6| Step: 4
Training loss: 2.9044781277503326
Validation loss: 3.171461124313543

Epoch: 6| Step: 5
Training loss: 3.6504143989160296
Validation loss: 3.1694075882622825

Epoch: 6| Step: 6
Training loss: 3.2836472246679205
Validation loss: 3.1699416704518693

Epoch: 6| Step: 7
Training loss: 4.139418400993831
Validation loss: 3.1698246517138458

Epoch: 6| Step: 8
Training loss: 3.7492563146039584
Validation loss: 3.1692755988617374

Epoch: 6| Step: 9
Training loss: 2.7967701471376603
Validation loss: 3.169974382777772

Epoch: 6| Step: 10
Training loss: 3.3975809355155775
Validation loss: 3.1695016051338087

Epoch: 6| Step: 11
Training loss: 3.4312237403295596
Validation loss: 3.1728540842439537

Epoch: 6| Step: 12
Training loss: 3.620512190354814
Validation loss: 3.1753698049499857

Epoch: 6| Step: 13
Training loss: 4.55424861200197
Validation loss: 3.177674989498184

Epoch: 156| Step: 0
Training loss: 4.042816837423757
Validation loss: 3.180048421573767

Epoch: 6| Step: 1
Training loss: 2.767859983662497
Validation loss: 3.1798022748534893

Epoch: 6| Step: 2
Training loss: 3.585289857178266
Validation loss: 3.176459567147424

Epoch: 6| Step: 3
Training loss: 3.1882402645020176
Validation loss: 3.175885617280177

Epoch: 6| Step: 4
Training loss: 3.3954582397247717
Validation loss: 3.171718251450824

Epoch: 6| Step: 5
Training loss: 3.7823828899561334
Validation loss: 3.1694306409907065

Epoch: 6| Step: 6
Training loss: 3.7338404572151345
Validation loss: 3.1691911416570444

Epoch: 6| Step: 7
Training loss: 3.544937747467909
Validation loss: 3.1698637637126788

Epoch: 6| Step: 8
Training loss: 3.4396430531213182
Validation loss: 3.1676203190907053

Epoch: 6| Step: 9
Training loss: 3.7454045430420515
Validation loss: 3.16879492280443

Epoch: 6| Step: 10
Training loss: 2.9457586542471983
Validation loss: 3.1668816970027147

Epoch: 6| Step: 11
Training loss: 3.003397924622698
Validation loss: 3.166994740622593

Epoch: 6| Step: 12
Training loss: 2.9091436275668805
Validation loss: 3.1661001102329966

Epoch: 6| Step: 13
Training loss: 3.5427998394221305
Validation loss: 3.167294152421619

Epoch: 157| Step: 0
Training loss: 3.139206599207794
Validation loss: 3.166297269841681

Epoch: 6| Step: 1
Training loss: 3.8596948653268144
Validation loss: 3.1665947155207457

Epoch: 6| Step: 2
Training loss: 3.258441086830513
Validation loss: 3.165864271782228

Epoch: 6| Step: 3
Training loss: 3.8506646957295554
Validation loss: 3.1660681311637746

Epoch: 6| Step: 4
Training loss: 3.701532335267155
Validation loss: 3.1660406846477693

Epoch: 6| Step: 5
Training loss: 3.711768513038598
Validation loss: 3.1653870866989107

Epoch: 6| Step: 6
Training loss: 3.421419017492847
Validation loss: 3.1641061277228943

Epoch: 6| Step: 7
Training loss: 2.9108525409678156
Validation loss: 3.1646994199486107

Epoch: 6| Step: 8
Training loss: 2.8651436737411964
Validation loss: 3.165131078930601

Epoch: 6| Step: 9
Training loss: 2.9864627266407906
Validation loss: 3.163020136602514

Epoch: 6| Step: 10
Training loss: 3.1591135763948106
Validation loss: 3.1628250373973215

Epoch: 6| Step: 11
Training loss: 2.9287290098746332
Validation loss: 3.1629054822423877

Epoch: 6| Step: 12
Training loss: 3.942425145301576
Validation loss: 3.163601879934044

Epoch: 6| Step: 13
Training loss: 4.020771454382716
Validation loss: 3.164457456183996

Epoch: 158| Step: 0
Training loss: 3.7317137872453445
Validation loss: 3.1641345908296343

Epoch: 6| Step: 1
Training loss: 3.5865839622728224
Validation loss: 3.163469451377515

Epoch: 6| Step: 2
Training loss: 3.5296124737834735
Validation loss: 3.1636899667284433

Epoch: 6| Step: 3
Training loss: 3.6892044524785423
Validation loss: 3.163137932257402

Epoch: 6| Step: 4
Training loss: 3.1924846792786963
Validation loss: 3.1642030762446165

Epoch: 6| Step: 5
Training loss: 3.533805799984888
Validation loss: 3.162166978995853

Epoch: 6| Step: 6
Training loss: 3.0976888840100036
Validation loss: 3.163604681330076

Epoch: 6| Step: 7
Training loss: 3.7079995823091436
Validation loss: 3.162403009676655

Epoch: 6| Step: 8
Training loss: 3.723052284974036
Validation loss: 3.162010434291086

Epoch: 6| Step: 9
Training loss: 2.8474854469094883
Validation loss: 3.162433938720981

Epoch: 6| Step: 10
Training loss: 2.7193953526444763
Validation loss: 3.162298311728844

Epoch: 6| Step: 11
Training loss: 3.626677683949098
Validation loss: 3.162270731966866

Epoch: 6| Step: 12
Training loss: 3.241191370882865
Validation loss: 3.1636186882730257

Epoch: 6| Step: 13
Training loss: 3.26756221860855
Validation loss: 3.1623955734633937

Epoch: 159| Step: 0
Training loss: 3.6053409905079596
Validation loss: 3.162368383671807

Epoch: 6| Step: 1
Training loss: 3.4569106948435944
Validation loss: 3.162240293423581

Epoch: 6| Step: 2
Training loss: 3.7256467321792663
Validation loss: 3.162494952838098

Epoch: 6| Step: 3
Training loss: 1.950655787798535
Validation loss: 3.163333708318783

Epoch: 6| Step: 4
Training loss: 3.3051190466512126
Validation loss: 3.162463796598796

Epoch: 6| Step: 5
Training loss: 3.4917454791828746
Validation loss: 3.161271173748998

Epoch: 6| Step: 6
Training loss: 4.641638031922003
Validation loss: 3.1625868390153453

Epoch: 6| Step: 7
Training loss: 2.9055519496229985
Validation loss: 3.161796820248404

Epoch: 6| Step: 8
Training loss: 3.4207243356442434
Validation loss: 3.1624644564650883

Epoch: 6| Step: 9
Training loss: 2.691871281770291
Validation loss: 3.1610131238207324

Epoch: 6| Step: 10
Training loss: 3.2591901103143552
Validation loss: 3.1611896070982723

Epoch: 6| Step: 11
Training loss: 3.189609502730268
Validation loss: 3.1604474647385143

Epoch: 6| Step: 12
Training loss: 3.432658722410519
Validation loss: 3.1618000959499724

Epoch: 6| Step: 13
Training loss: 4.338311612493359
Validation loss: 3.16339434688116

Epoch: 160| Step: 0
Training loss: 4.049814460177804
Validation loss: 3.1635464779079134

Epoch: 6| Step: 1
Training loss: 3.4080937146657715
Validation loss: 3.1611029858442725

Epoch: 6| Step: 2
Training loss: 2.626317102518227
Validation loss: 3.1621369983272953

Epoch: 6| Step: 3
Training loss: 3.314447370354462
Validation loss: 3.16243977704778

Epoch: 6| Step: 4
Training loss: 3.1193732913575705
Validation loss: 3.1601338443225218

Epoch: 6| Step: 5
Training loss: 3.868698410651588
Validation loss: 3.159973105963494

Epoch: 6| Step: 6
Training loss: 3.812511256467117
Validation loss: 3.159237947028392

Epoch: 6| Step: 7
Training loss: 3.7433011303334864
Validation loss: 3.1586862585790536

Epoch: 6| Step: 8
Training loss: 3.4108648274080884
Validation loss: 3.1590977536049416

Epoch: 6| Step: 9
Training loss: 3.637477316244912
Validation loss: 3.1586109673022023

Epoch: 6| Step: 10
Training loss: 2.7379656077830994
Validation loss: 3.155243093954366

Epoch: 6| Step: 11
Training loss: 3.690950880271062
Validation loss: 3.1570010335934198

Epoch: 6| Step: 12
Training loss: 3.0513360646075687
Validation loss: 3.156878827545652

Epoch: 6| Step: 13
Training loss: 2.4967653329228896
Validation loss: 3.157017410962219

Epoch: 161| Step: 0
Training loss: 3.0077192812259264
Validation loss: 3.157968695452201

Epoch: 6| Step: 1
Training loss: 3.1054794983108023
Validation loss: 3.15847972636985

Epoch: 6| Step: 2
Training loss: 3.1853929923362676
Validation loss: 3.1581289562329964

Epoch: 6| Step: 3
Training loss: 3.675016317525955
Validation loss: 3.1607746793958023

Epoch: 6| Step: 4
Training loss: 3.2347367678680534
Validation loss: 3.159880048513903

Epoch: 6| Step: 5
Training loss: 3.636729370495032
Validation loss: 3.1620601985240757

Epoch: 6| Step: 6
Training loss: 2.7369517365208385
Validation loss: 3.158768087901201

Epoch: 6| Step: 7
Training loss: 3.2994175368015064
Validation loss: 3.155921081474461

Epoch: 6| Step: 8
Training loss: 4.175111579546127
Validation loss: 3.1618214122517845

Epoch: 6| Step: 9
Training loss: 3.7271305826830234
Validation loss: 3.159542012942022

Epoch: 6| Step: 10
Training loss: 3.0753985883216473
Validation loss: 3.160745579339184

Epoch: 6| Step: 11
Training loss: 3.1492759780775312
Validation loss: 3.160367174723832

Epoch: 6| Step: 12
Training loss: 3.788906573990473
Validation loss: 3.1591827143537836

Epoch: 6| Step: 13
Training loss: 3.7677563219263552
Validation loss: 3.154349499833058

Epoch: 162| Step: 0
Training loss: 2.9641192811344435
Validation loss: 3.1528491551699593

Epoch: 6| Step: 1
Training loss: 3.868654531555058
Validation loss: 3.152306154897628

Epoch: 6| Step: 2
Training loss: 3.039219555559778
Validation loss: 3.150888470829486

Epoch: 6| Step: 3
Training loss: 2.512290877563984
Validation loss: 3.152102327767734

Epoch: 6| Step: 4
Training loss: 3.8899637296108542
Validation loss: 3.1519357165320487

Epoch: 6| Step: 5
Training loss: 4.002108733324782
Validation loss: 3.1537854833265335

Epoch: 6| Step: 6
Training loss: 3.0794114266361143
Validation loss: 3.1515641511092047

Epoch: 6| Step: 7
Training loss: 3.7352719047878904
Validation loss: 3.1516827954751006

Epoch: 6| Step: 8
Training loss: 3.7777914829254877
Validation loss: 3.1522400281332197

Epoch: 6| Step: 9
Training loss: 2.7364318958675797
Validation loss: 3.1512220994950675

Epoch: 6| Step: 10
Training loss: 2.677439377754707
Validation loss: 3.1499724875721893

Epoch: 6| Step: 11
Training loss: 3.292558637718165
Validation loss: 3.1493777836901478

Epoch: 6| Step: 12
Training loss: 3.838671050183716
Validation loss: 3.1500710999719943

Epoch: 6| Step: 13
Training loss: 3.93801283145827
Validation loss: 3.1510317371157384

Epoch: 163| Step: 0
Training loss: 3.234609991557769
Validation loss: 3.152124636819431

Epoch: 6| Step: 1
Training loss: 4.0101832466398415
Validation loss: 3.149717724040178

Epoch: 6| Step: 2
Training loss: 3.314670643274935
Validation loss: 3.148043195267372

Epoch: 6| Step: 3
Training loss: 2.9863017787731714
Validation loss: 3.1499036488053505

Epoch: 6| Step: 4
Training loss: 2.994625204131598
Validation loss: 3.1503386778187314

Epoch: 6| Step: 5
Training loss: 3.0193605362378517
Validation loss: 3.1522897075092957

Epoch: 6| Step: 6
Training loss: 2.8315427582476427
Validation loss: 3.1507885235881585

Epoch: 6| Step: 7
Training loss: 2.88703670996069
Validation loss: 3.1499172478812865

Epoch: 6| Step: 8
Training loss: 3.2039656861714456
Validation loss: 3.153288437970048

Epoch: 6| Step: 9
Training loss: 3.5637630432168526
Validation loss: 3.156741188221251

Epoch: 6| Step: 10
Training loss: 3.6252032255887183
Validation loss: 3.1566372876141195

Epoch: 6| Step: 11
Training loss: 3.9422566580555607
Validation loss: 3.152136912830332

Epoch: 6| Step: 12
Training loss: 4.216943424676673
Validation loss: 3.1518654175313623

Epoch: 6| Step: 13
Training loss: 3.4238093234741185
Validation loss: 3.150247738080077

Epoch: 164| Step: 0
Training loss: 2.9081354075708186
Validation loss: 3.148629981466477

Epoch: 6| Step: 1
Training loss: 3.7837488414005236
Validation loss: 3.1479511565770077

Epoch: 6| Step: 2
Training loss: 3.44896008395365
Validation loss: 3.1473084948713534

Epoch: 6| Step: 3
Training loss: 3.758373575495576
Validation loss: 3.1471733075944655

Epoch: 6| Step: 4
Training loss: 3.154566249623964
Validation loss: 3.1469054100912763

Epoch: 6| Step: 5
Training loss: 3.402062598260848
Validation loss: 3.147245598345068

Epoch: 6| Step: 6
Training loss: 3.7491894163815234
Validation loss: 3.1437941599216668

Epoch: 6| Step: 7
Training loss: 3.3637624079639523
Validation loss: 3.1473871794331507

Epoch: 6| Step: 8
Training loss: 2.5551730286597776
Validation loss: 3.1462875757572815

Epoch: 6| Step: 9
Training loss: 3.28440821201653
Validation loss: 3.146142952643189

Epoch: 6| Step: 10
Training loss: 3.913477688346709
Validation loss: 3.1469588526016166

Epoch: 6| Step: 11
Training loss: 2.9814269199297567
Validation loss: 3.1442099374774934

Epoch: 6| Step: 12
Training loss: 3.455509518980754
Validation loss: 3.1470920777443587

Epoch: 6| Step: 13
Training loss: 3.7191837602775695
Validation loss: 3.145580051469247

Epoch: 165| Step: 0
Training loss: 3.42914620474871
Validation loss: 3.144608807268153

Epoch: 6| Step: 1
Training loss: 3.9222634415686457
Validation loss: 3.1431485145765286

Epoch: 6| Step: 2
Training loss: 3.358837279820869
Validation loss: 3.144715793895969

Epoch: 6| Step: 3
Training loss: 3.334352782442674
Validation loss: 3.144546771063741

Epoch: 6| Step: 4
Training loss: 2.443684093630535
Validation loss: 3.14349639828037

Epoch: 6| Step: 5
Training loss: 3.8104722931258386
Validation loss: 3.1452683270974955

Epoch: 6| Step: 6
Training loss: 3.0655923917476877
Validation loss: 3.1444449867742703

Epoch: 6| Step: 7
Training loss: 2.861253298669649
Validation loss: 3.144381346480104

Epoch: 6| Step: 8
Training loss: 3.6116732591804457
Validation loss: 3.144093524129974

Epoch: 6| Step: 9
Training loss: 3.704971689998973
Validation loss: 3.1438325401614313

Epoch: 6| Step: 10
Training loss: 3.0185542135938643
Validation loss: 3.1419839911948704

Epoch: 6| Step: 11
Training loss: 3.590699202897123
Validation loss: 3.1468580750505373

Epoch: 6| Step: 12
Training loss: 3.371401669969907
Validation loss: 3.1436567322162676

Epoch: 6| Step: 13
Training loss: 3.961901545534208
Validation loss: 3.146838780424118

Epoch: 166| Step: 0
Training loss: 3.076716841608519
Validation loss: 3.145196956382863

Epoch: 6| Step: 1
Training loss: 3.4842362312088087
Validation loss: 3.144365502143707

Epoch: 6| Step: 2
Training loss: 3.3478183417766463
Validation loss: 3.143438292294866

Epoch: 6| Step: 3
Training loss: 3.768390067706975
Validation loss: 3.1423604471441684

Epoch: 6| Step: 4
Training loss: 3.800801072260104
Validation loss: 3.141162582848669

Epoch: 6| Step: 5
Training loss: 2.9510186974228176
Validation loss: 3.1426098748517264

Epoch: 6| Step: 6
Training loss: 2.6935471212720485
Validation loss: 3.140990993703845

Epoch: 6| Step: 7
Training loss: 3.8395134132767947
Validation loss: 3.1404556231189633

Epoch: 6| Step: 8
Training loss: 2.976266761165431
Validation loss: 3.1406751079844444

Epoch: 6| Step: 9
Training loss: 3.1820064402286707
Validation loss: 3.141986210525104

Epoch: 6| Step: 10
Training loss: 2.974961378343712
Validation loss: 3.1417121211741734

Epoch: 6| Step: 11
Training loss: 3.1176223642766283
Validation loss: 3.1397196273299763

Epoch: 6| Step: 12
Training loss: 4.194382662174262
Validation loss: 3.1407190099735094

Epoch: 6| Step: 13
Training loss: 4.00422397748493
Validation loss: 3.1394521455511977

Epoch: 167| Step: 0
Training loss: 3.525171906087455
Validation loss: 3.140004221916822

Epoch: 6| Step: 1
Training loss: 3.0474244233696597
Validation loss: 3.140811296509875

Epoch: 6| Step: 2
Training loss: 3.932975712914335
Validation loss: 3.1399674931088395

Epoch: 6| Step: 3
Training loss: 3.2151439429254904
Validation loss: 3.139245948540912

Epoch: 6| Step: 4
Training loss: 3.6586623099674647
Validation loss: 3.1411462354441033

Epoch: 6| Step: 5
Training loss: 2.8722494485213588
Validation loss: 3.139337092650801

Epoch: 6| Step: 6
Training loss: 3.3631581849944143
Validation loss: 3.139094506763317

Epoch: 6| Step: 7
Training loss: 2.746572873248621
Validation loss: 3.140820459552502

Epoch: 6| Step: 8
Training loss: 3.8729292966661677
Validation loss: 3.1377321822901183

Epoch: 6| Step: 9
Training loss: 2.6473196365545206
Validation loss: 3.138831826478832

Epoch: 6| Step: 10
Training loss: 3.685450614800158
Validation loss: 3.1395955891161798

Epoch: 6| Step: 11
Training loss: 3.423647626089308
Validation loss: 3.138977250333368

Epoch: 6| Step: 12
Training loss: 3.4491858475391344
Validation loss: 3.144764900023637

Epoch: 6| Step: 13
Training loss: 3.9534938474322394
Validation loss: 3.1396366809712952

Epoch: 168| Step: 0
Training loss: 3.9643331866079214
Validation loss: 3.1434743591053182

Epoch: 6| Step: 1
Training loss: 3.349463314508648
Validation loss: 3.1414492476531417

Epoch: 6| Step: 2
Training loss: 3.2647852935998203
Validation loss: 3.137328091856798

Epoch: 6| Step: 3
Training loss: 3.1802959937767157
Validation loss: 3.1389126820457602

Epoch: 6| Step: 4
Training loss: 3.619839382085842
Validation loss: 3.137930405340609

Epoch: 6| Step: 5
Training loss: 3.690571039566031
Validation loss: 3.1405848092042254

Epoch: 6| Step: 6
Training loss: 3.3550426847695958
Validation loss: 3.1372112637942924

Epoch: 6| Step: 7
Training loss: 2.7739938956910666
Validation loss: 3.1356715148261904

Epoch: 6| Step: 8
Training loss: 3.795033828725303
Validation loss: 3.1371474044353698

Epoch: 6| Step: 9
Training loss: 1.7914615853801332
Validation loss: 3.1363348373666113

Epoch: 6| Step: 10
Training loss: 3.61169464743607
Validation loss: 3.136143947364878

Epoch: 6| Step: 11
Training loss: 3.5730392093978667
Validation loss: 3.1351016301333567

Epoch: 6| Step: 12
Training loss: 3.9921765112678997
Validation loss: 3.136576621556958

Epoch: 6| Step: 13
Training loss: 2.335837779898828
Validation loss: 3.1359592636398537

Epoch: 169| Step: 0
Training loss: 3.0256314461932337
Validation loss: 3.1335355979638537

Epoch: 6| Step: 1
Training loss: 3.3164887794317472
Validation loss: 3.133478113960591

Epoch: 6| Step: 2
Training loss: 3.218464810968254
Validation loss: 3.1371525870402603

Epoch: 6| Step: 3
Training loss: 2.8867912644710674
Validation loss: 3.1363706834289067

Epoch: 6| Step: 4
Training loss: 4.09773817244133
Validation loss: 3.135480528024991

Epoch: 6| Step: 5
Training loss: 3.7445443203891178
Validation loss: 3.1356043006048777

Epoch: 6| Step: 6
Training loss: 3.9151232228186017
Validation loss: 3.136610655291757

Epoch: 6| Step: 7
Training loss: 2.8777744340652163
Validation loss: 3.136394541341705

Epoch: 6| Step: 8
Training loss: 3.4843176593253413
Validation loss: 3.1350870648405973

Epoch: 6| Step: 9
Training loss: 3.6191042606443466
Validation loss: 3.1367298440123172

Epoch: 6| Step: 10
Training loss: 3.16842930241228
Validation loss: 3.1364013648610243

Epoch: 6| Step: 11
Training loss: 3.0394457891630884
Validation loss: 3.1371421711561496

Epoch: 6| Step: 12
Training loss: 3.2099260282460595
Validation loss: 3.132945055905395

Epoch: 6| Step: 13
Training loss: 3.6506135973485327
Validation loss: 3.1335312307809

Epoch: 170| Step: 0
Training loss: 3.325080159303817
Validation loss: 3.1323484835565916

Epoch: 6| Step: 1
Training loss: 3.287765863495901
Validation loss: 3.131945596714486

Epoch: 6| Step: 2
Training loss: 2.826986515764612
Validation loss: 3.1306906522321976

Epoch: 6| Step: 3
Training loss: 2.793389049997074
Validation loss: 3.1329377919847397

Epoch: 6| Step: 4
Training loss: 3.338942164036429
Validation loss: 3.131367451992797

Epoch: 6| Step: 5
Training loss: 3.076698553623374
Validation loss: 3.1324815149495704

Epoch: 6| Step: 6
Training loss: 3.8181585624944403
Validation loss: 3.1326636065556284

Epoch: 6| Step: 7
Training loss: 4.086555273789565
Validation loss: 3.1317037955256963

Epoch: 6| Step: 8
Training loss: 2.5228922818866875
Validation loss: 3.1322646152062052

Epoch: 6| Step: 9
Training loss: 3.269700423117322
Validation loss: 3.1318837025875066

Epoch: 6| Step: 10
Training loss: 3.885287380709525
Validation loss: 3.1312249594780526

Epoch: 6| Step: 11
Training loss: 3.4652801204478965
Validation loss: 3.131756937528135

Epoch: 6| Step: 12
Training loss: 3.225034929426425
Validation loss: 3.1312888020745198

Epoch: 6| Step: 13
Training loss: 4.48660212382976
Validation loss: 3.1306220478690396

Epoch: 171| Step: 0
Training loss: 2.952032623896428
Validation loss: 3.1292327452011692

Epoch: 6| Step: 1
Training loss: 3.83000616446614
Validation loss: 3.1301461667937587

Epoch: 6| Step: 2
Training loss: 3.26314322609187
Validation loss: 3.1301977005112307

Epoch: 6| Step: 3
Training loss: 3.44920520196589
Validation loss: 3.128586364627869

Epoch: 6| Step: 4
Training loss: 2.974952402455374
Validation loss: 3.130349874081841

Epoch: 6| Step: 5
Training loss: 3.276550415191412
Validation loss: 3.1295841892835585

Epoch: 6| Step: 6
Training loss: 3.883088560671715
Validation loss: 3.1298104102660154

Epoch: 6| Step: 7
Training loss: 2.9186669348061223
Validation loss: 3.1274867854644084

Epoch: 6| Step: 8
Training loss: 3.3613111017872246
Validation loss: 3.1289265187877366

Epoch: 6| Step: 9
Training loss: 2.9777118536387603
Validation loss: 3.1301528434072647

Epoch: 6| Step: 10
Training loss: 2.8551925337719744
Validation loss: 3.1305838692640586

Epoch: 6| Step: 11
Training loss: 3.946821653076542
Validation loss: 3.129058343818556

Epoch: 6| Step: 12
Training loss: 3.377533562166631
Validation loss: 3.1289671780487276

Epoch: 6| Step: 13
Training loss: 4.360423191076004
Validation loss: 3.1280790865628982

Epoch: 172| Step: 0
Training loss: 3.5569928082341677
Validation loss: 3.1264044380628304

Epoch: 6| Step: 1
Training loss: 3.5936863105769437
Validation loss: 3.126110827816091

Epoch: 6| Step: 2
Training loss: 3.6378560157455913
Validation loss: 3.1275940020476996

Epoch: 6| Step: 3
Training loss: 4.160782945020825
Validation loss: 3.127991237781848

Epoch: 6| Step: 4
Training loss: 2.6805819695137068
Validation loss: 3.1274689615806808

Epoch: 6| Step: 5
Training loss: 3.059565636965786
Validation loss: 3.1302327159604695

Epoch: 6| Step: 6
Training loss: 3.1672764408550464
Validation loss: 3.130354945096455

Epoch: 6| Step: 7
Training loss: 2.815381333183662
Validation loss: 3.1302137332686977

Epoch: 6| Step: 8
Training loss: 2.9364836537565293
Validation loss: 3.1339547823814864

Epoch: 6| Step: 9
Training loss: 3.8963682382050173
Validation loss: 3.1309183891377868

Epoch: 6| Step: 10
Training loss: 3.4294081728418666
Validation loss: 3.1300907123489834

Epoch: 6| Step: 11
Training loss: 3.116311468871574
Validation loss: 3.128339506505274

Epoch: 6| Step: 12
Training loss: 3.841236191888304
Validation loss: 3.125577319561705

Epoch: 6| Step: 13
Training loss: 2.764291042887416
Validation loss: 3.12672636112693

Epoch: 173| Step: 0
Training loss: 3.485234860096131
Validation loss: 3.1240281856120875

Epoch: 6| Step: 1
Training loss: 3.106243147353168
Validation loss: 3.1254458021256704

Epoch: 6| Step: 2
Training loss: 2.8634797530953
Validation loss: 3.1227252318491034

Epoch: 6| Step: 3
Training loss: 3.923276369712505
Validation loss: 3.124396712613552

Epoch: 6| Step: 4
Training loss: 3.2856932574244917
Validation loss: 3.126192451945822

Epoch: 6| Step: 5
Training loss: 3.692231973000051
Validation loss: 3.1253040157636116

Epoch: 6| Step: 6
Training loss: 3.127332808479954
Validation loss: 3.1239553859046447

Epoch: 6| Step: 7
Training loss: 3.25797247551051
Validation loss: 3.124398169862783

Epoch: 6| Step: 8
Training loss: 4.117035314653554
Validation loss: 3.1232936047787283

Epoch: 6| Step: 9
Training loss: 3.305284811378011
Validation loss: 3.123222155455194

Epoch: 6| Step: 10
Training loss: 2.8030525053552457
Validation loss: 3.1255960138113275

Epoch: 6| Step: 11
Training loss: 2.883715149694088
Validation loss: 3.1241530847923125

Epoch: 6| Step: 12
Training loss: 3.7925410397848234
Validation loss: 3.123109909589489

Epoch: 6| Step: 13
Training loss: 3.325932743349037
Validation loss: 3.1234322239200063

Epoch: 174| Step: 0
Training loss: 3.743027881401268
Validation loss: 3.1209820814376417

Epoch: 6| Step: 1
Training loss: 3.5344109355472404
Validation loss: 3.121739118123222

Epoch: 6| Step: 2
Training loss: 2.7882136915235907
Validation loss: 3.1223358348594688

Epoch: 6| Step: 3
Training loss: 3.4249897197931087
Validation loss: 3.1224135526197623

Epoch: 6| Step: 4
Training loss: 3.3068002571018185
Validation loss: 3.1221885980142297

Epoch: 6| Step: 5
Training loss: 3.8865209787936967
Validation loss: 3.123588960445512

Epoch: 6| Step: 6
Training loss: 3.0931590122673773
Validation loss: 3.1216077798001667

Epoch: 6| Step: 7
Training loss: 3.0880526090597615
Validation loss: 3.1212595229861266

Epoch: 6| Step: 8
Training loss: 3.334713284637056
Validation loss: 3.1217712589418105

Epoch: 6| Step: 9
Training loss: 3.441997568203889
Validation loss: 3.118788714280277

Epoch: 6| Step: 10
Training loss: 3.2235692066202963
Validation loss: 3.119718511163583

Epoch: 6| Step: 11
Training loss: 3.4534236727009597
Validation loss: 3.122324804652934

Epoch: 6| Step: 12
Training loss: 3.4669857177880314
Validation loss: 3.12172666837388

Epoch: 6| Step: 13
Training loss: 3.3229223428675723
Validation loss: 3.120962252268513

Epoch: 175| Step: 0
Training loss: 3.333563860233355
Validation loss: 3.119814179921114

Epoch: 6| Step: 1
Training loss: 3.332152602567427
Validation loss: 3.1196242759416157

Epoch: 6| Step: 2
Training loss: 2.5193586423433247
Validation loss: 3.118876007689059

Epoch: 6| Step: 3
Training loss: 2.9664339367164945
Validation loss: 3.122539692072611

Epoch: 6| Step: 4
Training loss: 3.226667868900338
Validation loss: 3.1214783528436625

Epoch: 6| Step: 5
Training loss: 3.3052028678001677
Validation loss: 3.118913297220778

Epoch: 6| Step: 6
Training loss: 2.32196407429637
Validation loss: 3.1193673461268148

Epoch: 6| Step: 7
Training loss: 3.8721192018902855
Validation loss: 3.1200960899516725

Epoch: 6| Step: 8
Training loss: 3.843294194185702
Validation loss: 3.118124106742914

Epoch: 6| Step: 9
Training loss: 3.09413684006286
Validation loss: 3.117233009159351

Epoch: 6| Step: 10
Training loss: 4.030776358288452
Validation loss: 3.118529958046365

Epoch: 6| Step: 11
Training loss: 3.2339726441971535
Validation loss: 3.119005905109322

Epoch: 6| Step: 12
Training loss: 3.231767423363095
Validation loss: 3.1170391119715215

Epoch: 6| Step: 13
Training loss: 4.976494853040528
Validation loss: 3.118233447393265

Epoch: 176| Step: 0
Training loss: 3.3289813878555217
Validation loss: 3.116989441558905

Epoch: 6| Step: 1
Training loss: 3.4169078989854156
Validation loss: 3.116448429234682

Epoch: 6| Step: 2
Training loss: 3.22703537697044
Validation loss: 3.119188074920736

Epoch: 6| Step: 3
Training loss: 3.7687982508668867
Validation loss: 3.1214022864510924

Epoch: 6| Step: 4
Training loss: 3.867003773650189
Validation loss: 3.126623143154398

Epoch: 6| Step: 5
Training loss: 3.2271568360565985
Validation loss: 3.127169297899838

Epoch: 6| Step: 6
Training loss: 4.024505414252253
Validation loss: 3.134516899682051

Epoch: 6| Step: 7
Training loss: 2.6768557876086283
Validation loss: 3.117391517894311

Epoch: 6| Step: 8
Training loss: 3.3854041622615623
Validation loss: 3.115659208489771

Epoch: 6| Step: 9
Training loss: 3.738601399806583
Validation loss: 3.1167568999393636

Epoch: 6| Step: 10
Training loss: 2.1208841069207467
Validation loss: 3.1140817920272936

Epoch: 6| Step: 11
Training loss: 3.755762631603106
Validation loss: 3.1146643733665704

Epoch: 6| Step: 12
Training loss: 2.828022148833349
Validation loss: 3.1125304618814544

Epoch: 6| Step: 13
Training loss: 3.300903173598797
Validation loss: 3.11558568002755

Epoch: 177| Step: 0
Training loss: 3.7344562090738505
Validation loss: 3.1142689848789065

Epoch: 6| Step: 1
Training loss: 3.227578213406644
Validation loss: 3.1144524573979395

Epoch: 6| Step: 2
Training loss: 3.1599703475912952
Validation loss: 3.1146647388173023

Epoch: 6| Step: 3
Training loss: 2.9267395650290355
Validation loss: 3.1151467392402385

Epoch: 6| Step: 4
Training loss: 4.202998162947405
Validation loss: 3.11430410698143

Epoch: 6| Step: 5
Training loss: 3.9050874734964873
Validation loss: 3.1138798526296667

Epoch: 6| Step: 6
Training loss: 3.470408275232434
Validation loss: 3.1141168141602766

Epoch: 6| Step: 7
Training loss: 3.046622397882337
Validation loss: 3.11389526960719

Epoch: 6| Step: 8
Training loss: 3.059243943054034
Validation loss: 3.1139551749465566

Epoch: 6| Step: 9
Training loss: 2.621936645510583
Validation loss: 3.113221410745815

Epoch: 6| Step: 10
Training loss: 3.4698693471271813
Validation loss: 3.1133516643125314

Epoch: 6| Step: 11
Training loss: 3.436711446308163
Validation loss: 3.112785320545237

Epoch: 6| Step: 12
Training loss: 3.1001274574903444
Validation loss: 3.112684492446929

Epoch: 6| Step: 13
Training loss: 3.6159868987360912
Validation loss: 3.1148874302639293

Epoch: 178| Step: 0
Training loss: 4.008884814439589
Validation loss: 3.1111794739882175

Epoch: 6| Step: 1
Training loss: 3.891116559332052
Validation loss: 3.1115881359558606

Epoch: 6| Step: 2
Training loss: 3.647004526121376
Validation loss: 3.112255875631198

Epoch: 6| Step: 3
Training loss: 3.836114510299818
Validation loss: 3.1118694112896192

Epoch: 6| Step: 4
Training loss: 3.486944371743797
Validation loss: 3.113463418813799

Epoch: 6| Step: 5
Training loss: 3.9463961180108953
Validation loss: 3.114402046048722

Epoch: 6| Step: 6
Training loss: 2.7648619552836453
Validation loss: 3.110928808519375

Epoch: 6| Step: 7
Training loss: 3.137852901961879
Validation loss: 3.1109636815566657

Epoch: 6| Step: 8
Training loss: 3.3972308943658494
Validation loss: 3.1134948611896442

Epoch: 6| Step: 9
Training loss: 2.969228123762124
Validation loss: 3.1112032902361393

Epoch: 6| Step: 10
Training loss: 2.6929682612937436
Validation loss: 3.1132963487967134

Epoch: 6| Step: 11
Training loss: 3.1748763293112536
Validation loss: 3.110998529481329

Epoch: 6| Step: 12
Training loss: 3.175373572051408
Validation loss: 3.1110149611378493

Epoch: 6| Step: 13
Training loss: 1.7216345423569206
Validation loss: 3.1109866168881113

Epoch: 179| Step: 0
Training loss: 3.4978239924544434
Validation loss: 3.11346077568336

Epoch: 6| Step: 1
Training loss: 3.9908969532570135
Validation loss: 3.1132014481516594

Epoch: 6| Step: 2
Training loss: 2.8148478562756267
Validation loss: 3.110985410463565

Epoch: 6| Step: 3
Training loss: 4.009350576348666
Validation loss: 3.1120544355841377

Epoch: 6| Step: 4
Training loss: 2.858988084307267
Validation loss: 3.10814404476354

Epoch: 6| Step: 5
Training loss: 2.780275238325945
Validation loss: 3.109549425319568

Epoch: 6| Step: 6
Training loss: 3.7373261223091876
Validation loss: 3.1093486962659256

Epoch: 6| Step: 7
Training loss: 2.3796916598448337
Validation loss: 3.1109428012921994

Epoch: 6| Step: 8
Training loss: 2.7453830282219585
Validation loss: 3.109299262485798

Epoch: 6| Step: 9
Training loss: 3.5783422145961308
Validation loss: 3.106967167912073

Epoch: 6| Step: 10
Training loss: 3.6327518581128095
Validation loss: 3.108549213167957

Epoch: 6| Step: 11
Training loss: 2.748194014806374
Validation loss: 3.108048651089333

Epoch: 6| Step: 12
Training loss: 4.16518182364509
Validation loss: 3.1084949140200058

Epoch: 6| Step: 13
Training loss: 3.674226438111574
Validation loss: 3.1073807861464444

Epoch: 180| Step: 0
Training loss: 2.553101026592905
Validation loss: 3.1069688297161986

Epoch: 6| Step: 1
Training loss: 3.494722747502179
Validation loss: 3.107797050075745

Epoch: 6| Step: 2
Training loss: 3.3348758625221144
Validation loss: 3.108874655817772

Epoch: 6| Step: 3
Training loss: 2.859622131674378
Validation loss: 3.1122397528347006

Epoch: 6| Step: 4
Training loss: 3.373530597824482
Validation loss: 3.111791524105379

Epoch: 6| Step: 5
Training loss: 3.591104611867221
Validation loss: 3.110066209720138

Epoch: 6| Step: 6
Training loss: 3.600902174121137
Validation loss: 3.109889445850273

Epoch: 6| Step: 7
Training loss: 4.156192635735475
Validation loss: 3.1062236846260096

Epoch: 6| Step: 8
Training loss: 2.798790984030433
Validation loss: 3.104702198792191

Epoch: 6| Step: 9
Training loss: 3.3284192738702405
Validation loss: 3.105691220067091

Epoch: 6| Step: 10
Training loss: 3.759334644535452
Validation loss: 3.106768149301427

Epoch: 6| Step: 11
Training loss: 3.187565522361946
Validation loss: 3.1042038119110775

Epoch: 6| Step: 12
Training loss: 3.6311314785076267
Validation loss: 3.1059414688056486

Epoch: 6| Step: 13
Training loss: 2.862589545702549
Validation loss: 3.105737527505156

Epoch: 181| Step: 0
Training loss: 2.900966147918591
Validation loss: 3.104151024083555

Epoch: 6| Step: 1
Training loss: 3.688463505445846
Validation loss: 3.1055951732065936

Epoch: 6| Step: 2
Training loss: 4.0388124488151345
Validation loss: 3.1059555566819244

Epoch: 6| Step: 3
Training loss: 3.488655232612023
Validation loss: 3.1046907244497834

Epoch: 6| Step: 4
Training loss: 2.786261340632063
Validation loss: 3.1051524688416494

Epoch: 6| Step: 5
Training loss: 3.1571178187466735
Validation loss: 3.1059989639092547

Epoch: 6| Step: 6
Training loss: 3.35887319676056
Validation loss: 3.103042016153167

Epoch: 6| Step: 7
Training loss: 3.538247795730149
Validation loss: 3.1065972549280145

Epoch: 6| Step: 8
Training loss: 3.4737136655529084
Validation loss: 3.1055247563812967

Epoch: 6| Step: 9
Training loss: 3.7568264180978304
Validation loss: 3.104269698396559

Epoch: 6| Step: 10
Training loss: 2.9598766832181367
Validation loss: 3.104674191611563

Epoch: 6| Step: 11
Training loss: 3.283312921089455
Validation loss: 3.1064603884047

Epoch: 6| Step: 12
Training loss: 3.5225171157930073
Validation loss: 3.1073923578072984

Epoch: 6| Step: 13
Training loss: 2.3849252808260664
Validation loss: 3.1074561801960017

Epoch: 182| Step: 0
Training loss: 3.973939881421502
Validation loss: 3.107484148278265

Epoch: 6| Step: 1
Training loss: 3.120993219888321
Validation loss: 3.10238858061754

Epoch: 6| Step: 2
Training loss: 3.1259815963232667
Validation loss: 3.101910712791876

Epoch: 6| Step: 3
Training loss: 3.0246232736103886
Validation loss: 3.102574705747355

Epoch: 6| Step: 4
Training loss: 2.795905685815133
Validation loss: 3.103954419972527

Epoch: 6| Step: 5
Training loss: 3.622045957597075
Validation loss: 3.1030940760012293

Epoch: 6| Step: 6
Training loss: 3.4633739153552967
Validation loss: 3.103688088294497

Epoch: 6| Step: 7
Training loss: 2.920354600565142
Validation loss: 3.102572178937528

Epoch: 6| Step: 8
Training loss: 3.6906076041642573
Validation loss: 3.1053010665810423

Epoch: 6| Step: 9
Training loss: 3.8226917557555544
Validation loss: 3.1020356686254873

Epoch: 6| Step: 10
Training loss: 2.892756980090415
Validation loss: 3.101662671355163

Epoch: 6| Step: 11
Training loss: 3.370740816774501
Validation loss: 3.1006752894902023

Epoch: 6| Step: 12
Training loss: 3.9342303551709867
Validation loss: 3.1006594628299733

Epoch: 6| Step: 13
Training loss: 2.6360923192495913
Validation loss: 3.1014781397068933

Epoch: 183| Step: 0
Training loss: 3.6300429420978766
Validation loss: 3.101056599775927

Epoch: 6| Step: 1
Training loss: 3.395418918028562
Validation loss: 3.099515059400421

Epoch: 6| Step: 2
Training loss: 2.973559850038787
Validation loss: 3.099092398756421

Epoch: 6| Step: 3
Training loss: 3.606225162731302
Validation loss: 3.099059882102575

Epoch: 6| Step: 4
Training loss: 3.510983671284567
Validation loss: 3.098131072735311

Epoch: 6| Step: 5
Training loss: 3.336517355058701
Validation loss: 3.098280554995661

Epoch: 6| Step: 6
Training loss: 3.12142556805449
Validation loss: 3.1003755010252294

Epoch: 6| Step: 7
Training loss: 3.036159982740682
Validation loss: 3.101390946807922

Epoch: 6| Step: 8
Training loss: 3.2288572265684015
Validation loss: 3.1042082897257903

Epoch: 6| Step: 9
Training loss: 3.03976377422664
Validation loss: 3.106102070769134

Epoch: 6| Step: 10
Training loss: 2.582787568883001
Validation loss: 3.1034232372055266

Epoch: 6| Step: 11
Training loss: 4.079586541786889
Validation loss: 3.100888965472726

Epoch: 6| Step: 12
Training loss: 3.6008695982649104
Validation loss: 3.0982540883932495

Epoch: 6| Step: 13
Training loss: 3.8174161638748387
Validation loss: 3.098414923340472

Epoch: 184| Step: 0
Training loss: 2.8571375029377495
Validation loss: 3.097476217168381

Epoch: 6| Step: 1
Training loss: 4.041910432890586
Validation loss: 3.0981541957423433

Epoch: 6| Step: 2
Training loss: 2.8374409539217176
Validation loss: 3.096404841488482

Epoch: 6| Step: 3
Training loss: 3.272310559156763
Validation loss: 3.0959933448369252

Epoch: 6| Step: 4
Training loss: 2.781234569721066
Validation loss: 3.0956276169596104

Epoch: 6| Step: 5
Training loss: 3.127763975424283
Validation loss: 3.096835504810665

Epoch: 6| Step: 6
Training loss: 3.3633400870924235
Validation loss: 3.0962420739378262

Epoch: 6| Step: 7
Training loss: 3.12808639700714
Validation loss: 3.09531592080008

Epoch: 6| Step: 8
Training loss: 3.902468628741995
Validation loss: 3.095581607976883

Epoch: 6| Step: 9
Training loss: 3.2994580026061726
Validation loss: 3.0940872328442715

Epoch: 6| Step: 10
Training loss: 3.7136183521686723
Validation loss: 3.0946140319521613

Epoch: 6| Step: 11
Training loss: 3.6300051106398574
Validation loss: 3.095572342495308

Epoch: 6| Step: 12
Training loss: 3.4824615835684782
Validation loss: 3.0938311056902

Epoch: 6| Step: 13
Training loss: 3.1980458253174042
Validation loss: 3.0937587240308866

Epoch: 185| Step: 0
Training loss: 3.403303359220687
Validation loss: 3.094703442876243

Epoch: 6| Step: 1
Training loss: 3.056587272397793
Validation loss: 3.094747409693323

Epoch: 6| Step: 2
Training loss: 3.601043465175884
Validation loss: 3.09615166995167

Epoch: 6| Step: 3
Training loss: 3.669506071774649
Validation loss: 3.0938558675352774

Epoch: 6| Step: 4
Training loss: 3.0616396259850465
Validation loss: 3.099302431841292

Epoch: 6| Step: 5
Training loss: 3.1498485649886154
Validation loss: 3.0961480416152565

Epoch: 6| Step: 6
Training loss: 2.144661765652172
Validation loss: 3.0960909084182733

Epoch: 6| Step: 7
Training loss: 3.9473385886687944
Validation loss: 3.095326278655939

Epoch: 6| Step: 8
Training loss: 2.978143867681084
Validation loss: 3.0958207667292568

Epoch: 6| Step: 9
Training loss: 3.45250824128313
Validation loss: 3.0987723809272465

Epoch: 6| Step: 10
Training loss: 3.470016248373637
Validation loss: 3.0931085978402093

Epoch: 6| Step: 11
Training loss: 3.2888721401916508
Validation loss: 3.094276031325122

Epoch: 6| Step: 12
Training loss: 3.732636753446377
Validation loss: 3.093795154549024

Epoch: 6| Step: 13
Training loss: 3.785470419995272
Validation loss: 3.093419003961361

Epoch: 186| Step: 0
Training loss: 3.1079911262650644
Validation loss: 3.093261415001263

Epoch: 6| Step: 1
Training loss: 3.690720008964418
Validation loss: 3.0910667051787053

Epoch: 6| Step: 2
Training loss: 3.025749643300097
Validation loss: 3.092631499440813

Epoch: 6| Step: 3
Training loss: 3.5914779778736996
Validation loss: 3.0933858956138214

Epoch: 6| Step: 4
Training loss: 2.794796304394408
Validation loss: 3.092326782686517

Epoch: 6| Step: 5
Training loss: 3.29236427994836
Validation loss: 3.0916092104214132

Epoch: 6| Step: 6
Training loss: 4.3458620055226005
Validation loss: 3.0927227424128394

Epoch: 6| Step: 7
Training loss: 2.3837586572466885
Validation loss: 3.0909842712515134

Epoch: 6| Step: 8
Training loss: 2.85589554672073
Validation loss: 3.091340262709063

Epoch: 6| Step: 9
Training loss: 3.6120030467209583
Validation loss: 3.09239814501499

Epoch: 6| Step: 10
Training loss: 3.8028249078366843
Validation loss: 3.092717893187505

Epoch: 6| Step: 11
Training loss: 3.349582896670127
Validation loss: 3.089676931170216

Epoch: 6| Step: 12
Training loss: 3.3798320229678582
Validation loss: 3.091125203469039

Epoch: 6| Step: 13
Training loss: 3.190258552811835
Validation loss: 3.0904662304588357

Epoch: 187| Step: 0
Training loss: 3.0940593218057453
Validation loss: 3.0898473774424167

Epoch: 6| Step: 1
Training loss: 3.0113395323532965
Validation loss: 3.0902353332143817

Epoch: 6| Step: 2
Training loss: 3.512409418098796
Validation loss: 3.090701211350734

Epoch: 6| Step: 3
Training loss: 3.58391199688497
Validation loss: 3.0903769400034355

Epoch: 6| Step: 4
Training loss: 2.7531610874058146
Validation loss: 3.0930041618483215

Epoch: 6| Step: 5
Training loss: 3.05276717682713
Validation loss: 3.0944943776022793

Epoch: 6| Step: 6
Training loss: 3.127213114045274
Validation loss: 3.0933703051473245

Epoch: 6| Step: 7
Training loss: 3.7396174068899817
Validation loss: 3.0924222982367695

Epoch: 6| Step: 8
Training loss: 3.543952443632602
Validation loss: 3.0947346525464763

Epoch: 6| Step: 9
Training loss: 3.499561418574546
Validation loss: 3.0925214227080335

Epoch: 6| Step: 10
Training loss: 3.107766506953694
Validation loss: 3.0904199140220348

Epoch: 6| Step: 11
Training loss: 3.606128900831758
Validation loss: 3.0895308654068216

Epoch: 6| Step: 12
Training loss: 3.7280644043364997
Validation loss: 3.087725282311406

Epoch: 6| Step: 13
Training loss: 3.3785141910369543
Validation loss: 3.0867402284639085

Epoch: 188| Step: 0
Training loss: 2.9827827080447284
Validation loss: 3.09084262593283

Epoch: 6| Step: 1
Training loss: 3.471656475177322
Validation loss: 3.0899339817804212

Epoch: 6| Step: 2
Training loss: 3.7573028662993835
Validation loss: 3.087866320929545

Epoch: 6| Step: 3
Training loss: 3.838601610948404
Validation loss: 3.0878691760907317

Epoch: 6| Step: 4
Training loss: 3.87944268304171
Validation loss: 3.0869542428391625

Epoch: 6| Step: 5
Training loss: 3.0762557342240244
Validation loss: 3.0877143684144013

Epoch: 6| Step: 6
Training loss: 2.469897426066128
Validation loss: 3.0860507639520938

Epoch: 6| Step: 7
Training loss: 3.366703857241638
Validation loss: 3.086193069461027

Epoch: 6| Step: 8
Training loss: 3.0154222805689037
Validation loss: 3.0862951301730552

Epoch: 6| Step: 9
Training loss: 3.701456845065049
Validation loss: 3.085369881488517

Epoch: 6| Step: 10
Training loss: 2.4252931162075906
Validation loss: 3.0859349279988773

Epoch: 6| Step: 11
Training loss: 3.005729925331483
Validation loss: 3.085289824684314

Epoch: 6| Step: 12
Training loss: 3.9204345732771984
Validation loss: 3.0866623068435226

Epoch: 6| Step: 13
Training loss: 3.5572771302015096
Validation loss: 3.0857259407594877

Epoch: 189| Step: 0
Training loss: 3.129827813723095
Validation loss: 3.089116927738357

Epoch: 6| Step: 1
Training loss: 3.3904312008086808
Validation loss: 3.088537995634851

Epoch: 6| Step: 2
Training loss: 3.503577719844282
Validation loss: 3.091109614870158

Epoch: 6| Step: 3
Training loss: 3.1462126412672466
Validation loss: 3.0903351632824863

Epoch: 6| Step: 4
Training loss: 2.7804120976849602
Validation loss: 3.089626087363686

Epoch: 6| Step: 5
Training loss: 3.002381015678334
Validation loss: 3.0859528007039736

Epoch: 6| Step: 6
Training loss: 3.1028558066891367
Validation loss: 3.09018871631773

Epoch: 6| Step: 7
Training loss: 3.629102424435477
Validation loss: 3.0878919168281374

Epoch: 6| Step: 8
Training loss: 4.329911176726359
Validation loss: 3.0860596210640865

Epoch: 6| Step: 9
Training loss: 3.167134317366525
Validation loss: 3.0829608701139435

Epoch: 6| Step: 10
Training loss: 3.0221382917954513
Validation loss: 3.084085680880581

Epoch: 6| Step: 11
Training loss: 3.7630066692081323
Validation loss: 3.081885814257099

Epoch: 6| Step: 12
Training loss: 3.1862500301703793
Validation loss: 3.083786797761787

Epoch: 6| Step: 13
Training loss: 3.39866241061619
Validation loss: 3.0830675629734494

Epoch: 190| Step: 0
Training loss: 2.6106387978249193
Validation loss: 3.080543480363156

Epoch: 6| Step: 1
Training loss: 3.1697055557159444
Validation loss: 3.0826015989890587

Epoch: 6| Step: 2
Training loss: 3.6893061724224667
Validation loss: 3.0821539982824167

Epoch: 6| Step: 3
Training loss: 2.7807635621289983
Validation loss: 3.082040735858658

Epoch: 6| Step: 4
Training loss: 3.6408636317815435
Validation loss: 3.0821044743488843

Epoch: 6| Step: 5
Training loss: 3.2641424436809063
Validation loss: 3.0810446977002433

Epoch: 6| Step: 6
Training loss: 3.7684487799723896
Validation loss: 3.079970090033938

Epoch: 6| Step: 7
Training loss: 3.4839822179995283
Validation loss: 3.0808538568499606

Epoch: 6| Step: 8
Training loss: 3.638149484022175
Validation loss: 3.079832761065193

Epoch: 6| Step: 9
Training loss: 1.8573919668908483
Validation loss: 3.0802864301150463

Epoch: 6| Step: 10
Training loss: 3.644271138058411
Validation loss: 3.082626260591561

Epoch: 6| Step: 11
Training loss: 4.030607896869968
Validation loss: 3.082029381771502

Epoch: 6| Step: 12
Training loss: 3.6056554876140523
Validation loss: 3.0854612278628353

Epoch: 6| Step: 13
Training loss: 2.632139940698335
Validation loss: 3.089387310417524

Epoch: 191| Step: 0
Training loss: 2.2736855073394384
Validation loss: 3.0840839169714207

Epoch: 6| Step: 1
Training loss: 2.6675656909236682
Validation loss: 3.0938101445998933

Epoch: 6| Step: 2
Training loss: 3.4246401131330546
Validation loss: 3.1003929605618508

Epoch: 6| Step: 3
Training loss: 3.298268678971821
Validation loss: 3.099931448351511

Epoch: 6| Step: 4
Training loss: 3.0338953803978175
Validation loss: 3.104575445250993

Epoch: 6| Step: 5
Training loss: 4.238193493475111
Validation loss: 3.1045685336148026

Epoch: 6| Step: 6
Training loss: 4.069027395797908
Validation loss: 3.0963026710509407

Epoch: 6| Step: 7
Training loss: 2.5461784299549723
Validation loss: 3.0799739738182974

Epoch: 6| Step: 8
Training loss: 2.901030087861674
Validation loss: 3.077965880056622

Epoch: 6| Step: 9
Training loss: 3.173426356782042
Validation loss: 3.077512175477426

Epoch: 6| Step: 10
Training loss: 3.759258792948855
Validation loss: 3.077908272757801

Epoch: 6| Step: 11
Training loss: 2.966680508127676
Validation loss: 3.078659070418123

Epoch: 6| Step: 12
Training loss: 4.436889176572427
Validation loss: 3.0779627383527215

Epoch: 6| Step: 13
Training loss: 3.0569941014665645
Validation loss: 3.079192360502382

Epoch: 192| Step: 0
Training loss: 3.2471917564225423
Validation loss: 3.0784346126682625

Epoch: 6| Step: 1
Training loss: 3.165192126910521
Validation loss: 3.0792982331736463

Epoch: 6| Step: 2
Training loss: 3.864189326653351
Validation loss: 3.0800129212623943

Epoch: 6| Step: 3
Training loss: 3.86594020881339
Validation loss: 3.0791302918450003

Epoch: 6| Step: 4
Training loss: 3.8835001591770437
Validation loss: 3.07927054275055

Epoch: 6| Step: 5
Training loss: 2.1762369387528855
Validation loss: 3.0791495977876084

Epoch: 6| Step: 6
Training loss: 2.9530132615682656
Validation loss: 3.0772215747613805

Epoch: 6| Step: 7
Training loss: 3.253977176035229
Validation loss: 3.078133416433713

Epoch: 6| Step: 8
Training loss: 3.0687752095292176
Validation loss: 3.077615893512842

Epoch: 6| Step: 9
Training loss: 3.2805033969707487
Validation loss: 3.077216859398264

Epoch: 6| Step: 10
Training loss: 3.367947025888242
Validation loss: 3.0770535417534353

Epoch: 6| Step: 11
Training loss: 3.7191609387984386
Validation loss: 3.0745189318123614

Epoch: 6| Step: 12
Training loss: 3.4277346532229234
Validation loss: 3.0770315065794023

Epoch: 6| Step: 13
Training loss: 2.9016942238270573
Validation loss: 3.077205524168957

Epoch: 193| Step: 0
Training loss: 3.417118197742617
Validation loss: 3.089989922933146

Epoch: 6| Step: 1
Training loss: 4.1347028883407715
Validation loss: 3.078936772805727

Epoch: 6| Step: 2
Training loss: 2.6891990436330397
Validation loss: 3.0781439024842108

Epoch: 6| Step: 3
Training loss: 3.222570281760544
Validation loss: 3.0894703586870205

Epoch: 6| Step: 4
Training loss: 3.7665954858811497
Validation loss: 3.105372205881891

Epoch: 6| Step: 5
Training loss: 3.803848205361722
Validation loss: 3.1065842592630286

Epoch: 6| Step: 6
Training loss: 2.7116555793721546
Validation loss: 3.0963656581030414

Epoch: 6| Step: 7
Training loss: 3.5538684614029528
Validation loss: 3.087810626908448

Epoch: 6| Step: 8
Training loss: 2.4892127001907194
Validation loss: 3.081227912100644

Epoch: 6| Step: 9
Training loss: 2.861976982210741
Validation loss: 3.079625996933736

Epoch: 6| Step: 10
Training loss: 3.5403809102186896
Validation loss: 3.074960684056007

Epoch: 6| Step: 11
Training loss: 3.426826135014606
Validation loss: 3.0753263730333202

Epoch: 6| Step: 12
Training loss: 2.9036420380206884
Validation loss: 3.0755386759772767

Epoch: 6| Step: 13
Training loss: 4.123158361679585
Validation loss: 3.0745159691961703

Epoch: 194| Step: 0
Training loss: 3.5189185418914963
Validation loss: 3.0732321072387143

Epoch: 6| Step: 1
Training loss: 2.772410371809043
Validation loss: 3.0766256372426435

Epoch: 6| Step: 2
Training loss: 3.8519869990223494
Validation loss: 3.072797718669366

Epoch: 6| Step: 3
Training loss: 3.495670365425055
Validation loss: 3.0758665019665004

Epoch: 6| Step: 4
Training loss: 3.0195854152544004
Validation loss: 3.0759949385878476

Epoch: 6| Step: 5
Training loss: 2.967745641168365
Validation loss: 3.074367918134165

Epoch: 6| Step: 6
Training loss: 3.7941510511702985
Validation loss: 3.0753197157703855

Epoch: 6| Step: 7
Training loss: 3.4107795486540318
Validation loss: 3.0780953776015507

Epoch: 6| Step: 8
Training loss: 2.7898804563117494
Validation loss: 3.0788388654762526

Epoch: 6| Step: 9
Training loss: 3.8614353132252073
Validation loss: 3.0764362838927455

Epoch: 6| Step: 10
Training loss: 3.6309232003366807
Validation loss: 3.078165314221269

Epoch: 6| Step: 11
Training loss: 1.837905932371828
Validation loss: 3.0791640163870198

Epoch: 6| Step: 12
Training loss: 3.636060087582472
Validation loss: 3.085662800494246

Epoch: 6| Step: 13
Training loss: 3.6387573166632468
Validation loss: 3.0798255058926456

Epoch: 195| Step: 0
Training loss: 2.3046917414222095
Validation loss: 3.0749412050786553

Epoch: 6| Step: 1
Training loss: 3.871258559890364
Validation loss: 3.074894551409074

Epoch: 6| Step: 2
Training loss: 3.139327810951615
Validation loss: 3.0729837189553195

Epoch: 6| Step: 3
Training loss: 2.725351671397305
Validation loss: 3.068898613324495

Epoch: 6| Step: 4
Training loss: 4.436829207318779
Validation loss: 3.0711950149377696

Epoch: 6| Step: 5
Training loss: 2.8784076564303187
Validation loss: 3.068761569163121

Epoch: 6| Step: 6
Training loss: 2.8772060389297986
Validation loss: 3.068071393421764

Epoch: 6| Step: 7
Training loss: 3.9629948255922436
Validation loss: 3.068954318084465

Epoch: 6| Step: 8
Training loss: 3.3664598143329374
Validation loss: 3.0685717990496277

Epoch: 6| Step: 9
Training loss: 2.5897767301377335
Validation loss: 3.068230797559101

Epoch: 6| Step: 10
Training loss: 3.191712681079237
Validation loss: 3.070900670002305

Epoch: 6| Step: 11
Training loss: 3.201329467692723
Validation loss: 3.0681350461095462

Epoch: 6| Step: 12
Training loss: 3.969472624104263
Validation loss: 3.070309387203783

Epoch: 6| Step: 13
Training loss: 3.5064969388936738
Validation loss: 3.073574467257732

Epoch: 196| Step: 0
Training loss: 3.8236062296749878
Validation loss: 3.0705613565101797

Epoch: 6| Step: 1
Training loss: 3.2720953254151253
Validation loss: 3.071776094802384

Epoch: 6| Step: 2
Training loss: 2.670976097191358
Validation loss: 3.0733508718715905

Epoch: 6| Step: 3
Training loss: 3.7486183164236078
Validation loss: 3.073040480888943

Epoch: 6| Step: 4
Training loss: 3.5215008947373194
Validation loss: 3.0665222835748684

Epoch: 6| Step: 5
Training loss: 4.117984701786833
Validation loss: 3.0697161264831867

Epoch: 6| Step: 6
Training loss: 3.0899343368812535
Validation loss: 3.072033729466914

Epoch: 6| Step: 7
Training loss: 3.229243681614787
Validation loss: 3.0765302203968226

Epoch: 6| Step: 8
Training loss: 3.132252935726797
Validation loss: 3.0787444823113055

Epoch: 6| Step: 9
Training loss: 3.601441486832884
Validation loss: 3.0769435925959305

Epoch: 6| Step: 10
Training loss: 3.1087652020606136
Validation loss: 3.080826882724441

Epoch: 6| Step: 11
Training loss: 3.2835847813195387
Validation loss: 3.07878563692113

Epoch: 6| Step: 12
Training loss: 2.236233984952228
Validation loss: 3.0699947881338714

Epoch: 6| Step: 13
Training loss: 3.4385937424562356
Validation loss: 3.069915765056504

Epoch: 197| Step: 0
Training loss: 3.6468083994193052
Validation loss: 3.0627161844983823

Epoch: 6| Step: 1
Training loss: 3.220663298296432
Validation loss: 3.0660537917420148

Epoch: 6| Step: 2
Training loss: 2.6403743466928753
Validation loss: 3.062997798881645

Epoch: 6| Step: 3
Training loss: 3.3398411800976953
Validation loss: 3.0621139420320915

Epoch: 6| Step: 4
Training loss: 3.1677452224913383
Validation loss: 3.0650926171323736

Epoch: 6| Step: 5
Training loss: 3.9685464641614074
Validation loss: 3.0620569557832074

Epoch: 6| Step: 6
Training loss: 2.8209598886639506
Validation loss: 3.0649005153364888

Epoch: 6| Step: 7
Training loss: 3.4485162557467963
Validation loss: 3.06318984927117

Epoch: 6| Step: 8
Training loss: 3.127931211949363
Validation loss: 3.062624589144946

Epoch: 6| Step: 9
Training loss: 3.2302606185786975
Validation loss: 3.0632111052566477

Epoch: 6| Step: 10
Training loss: 3.499904903754836
Validation loss: 3.0663395566305947

Epoch: 6| Step: 11
Training loss: 3.1631117157505453
Validation loss: 3.0635554642265537

Epoch: 6| Step: 12
Training loss: 3.667750472946506
Validation loss: 3.0627186060774583

Epoch: 6| Step: 13
Training loss: 3.5488168383488654
Validation loss: 3.062648917740672

Epoch: 198| Step: 0
Training loss: 3.445052018125818
Validation loss: 3.062693161405003

Epoch: 6| Step: 1
Training loss: 3.1359464043688976
Validation loss: 3.0631631547984046

Epoch: 6| Step: 2
Training loss: 4.042540360758242
Validation loss: 3.0639585128004305

Epoch: 6| Step: 3
Training loss: 3.6588634051911093
Validation loss: 3.0612393736064143

Epoch: 6| Step: 4
Training loss: 3.455293966724738
Validation loss: 3.0627075520095914

Epoch: 6| Step: 5
Training loss: 3.352604061733353
Validation loss: 3.0602247095545536

Epoch: 6| Step: 6
Training loss: 3.026095382730171
Validation loss: 3.063421094549297

Epoch: 6| Step: 7
Training loss: 2.4938308893914223
Validation loss: 3.061132221439337

Epoch: 6| Step: 8
Training loss: 3.62248221467406
Validation loss: 3.0608727989751348

Epoch: 6| Step: 9
Training loss: 2.265773373711075
Validation loss: 3.06118239117599

Epoch: 6| Step: 10
Training loss: 3.6259509187670504
Validation loss: 3.0609521375882562

Epoch: 6| Step: 11
Training loss: 3.265924175375068
Validation loss: 3.059693873051887

Epoch: 6| Step: 12
Training loss: 3.437060102579336
Validation loss: 3.059185027867768

Epoch: 6| Step: 13
Training loss: 3.3183141102434415
Validation loss: 3.060949702048725

Epoch: 199| Step: 0
Training loss: 3.3098214313939724
Validation loss: 3.0596360256233592

Epoch: 6| Step: 1
Training loss: 3.183174639302996
Validation loss: 3.059469714877249

Epoch: 6| Step: 2
Training loss: 3.613351984104947
Validation loss: 3.060134630522374

Epoch: 6| Step: 3
Training loss: 2.7512598619713264
Validation loss: 3.060404310146558

Epoch: 6| Step: 4
Training loss: 3.3970329802413834
Validation loss: 3.06011372345717

Epoch: 6| Step: 5
Training loss: 2.3909895874460414
Validation loss: 3.059926852049618

Epoch: 6| Step: 6
Training loss: 2.9332211761996163
Validation loss: 3.0600194622854904

Epoch: 6| Step: 7
Training loss: 3.7885909268806888
Validation loss: 3.058529638903178

Epoch: 6| Step: 8
Training loss: 3.61459488367586
Validation loss: 3.059382124145302

Epoch: 6| Step: 9
Training loss: 3.658556870660137
Validation loss: 3.060161795419451

Epoch: 6| Step: 10
Training loss: 3.7252077083154402
Validation loss: 3.0597292261403144

Epoch: 6| Step: 11
Training loss: 3.402094975342758
Validation loss: 3.0577960290720445

Epoch: 6| Step: 12
Training loss: 2.8677856486621107
Validation loss: 3.056586507479162

Epoch: 6| Step: 13
Training loss: 3.7761651520981454
Validation loss: 3.0579356907375566

Epoch: 200| Step: 0
Training loss: 3.78300523609643
Validation loss: 3.057653545567327

Epoch: 6| Step: 1
Training loss: 3.408707878095945
Validation loss: 3.0560217943218104

Epoch: 6| Step: 2
Training loss: 3.2552149088475253
Validation loss: 3.0565850044805924

Epoch: 6| Step: 3
Training loss: 3.2488763774202423
Validation loss: 3.0567366107063805

Epoch: 6| Step: 4
Training loss: 3.157950670181967
Validation loss: 3.055969447657909

Epoch: 6| Step: 5
Training loss: 3.7124213213562847
Validation loss: 3.0550787407950066

Epoch: 6| Step: 6
Training loss: 2.96924932195828
Validation loss: 3.0568121736574994

Epoch: 6| Step: 7
Training loss: 3.55862912475557
Validation loss: 3.05704594755111

Epoch: 6| Step: 8
Training loss: 2.5126773790593515
Validation loss: 3.057353941658815

Epoch: 6| Step: 9
Training loss: 3.710994808356833
Validation loss: 3.0587678476627724

Epoch: 6| Step: 10
Training loss: 3.2094182413636974
Validation loss: 3.0573401304282255

Epoch: 6| Step: 11
Training loss: 2.7117421827564963
Validation loss: 3.057013087647703

Epoch: 6| Step: 12
Training loss: 3.2963389462566495
Validation loss: 3.0580628525410667

Epoch: 6| Step: 13
Training loss: 3.9426357139978094
Validation loss: 3.0657868116477256

Epoch: 201| Step: 0
Training loss: 2.976791733452817
Validation loss: 3.0676470830729006

Epoch: 6| Step: 1
Training loss: 2.9690066577994765
Validation loss: 3.0770776562911877

Epoch: 6| Step: 2
Training loss: 3.2649986725084488
Validation loss: 3.0985105234234913

Epoch: 6| Step: 3
Training loss: 3.521293579958553
Validation loss: 3.089726152846715

Epoch: 6| Step: 4
Training loss: 3.48064438433463
Validation loss: 3.0601568778420067

Epoch: 6| Step: 5
Training loss: 3.703711225890539
Validation loss: 3.0583018604715764

Epoch: 6| Step: 6
Training loss: 3.055393459374644
Validation loss: 3.051980415268498

Epoch: 6| Step: 7
Training loss: 3.729660186220092
Validation loss: 3.052415844714834

Epoch: 6| Step: 8
Training loss: 3.409105556340974
Validation loss: 3.0520636447897367

Epoch: 6| Step: 9
Training loss: 2.442659346381439
Validation loss: 3.0534014122380406

Epoch: 6| Step: 10
Training loss: 3.694123090823619
Validation loss: 3.0563189654455383

Epoch: 6| Step: 11
Training loss: 3.572266425898625
Validation loss: 3.0553407528930445

Epoch: 6| Step: 12
Training loss: 3.4872758362622696
Validation loss: 3.0588172281215944

Epoch: 6| Step: 13
Training loss: 2.752716543357218
Validation loss: 3.0546456321438473

Epoch: 202| Step: 0
Training loss: 4.279392702743799
Validation loss: 3.053908089900392

Epoch: 6| Step: 1
Training loss: 2.879977851093742
Validation loss: 3.0535980473122493

Epoch: 6| Step: 2
Training loss: 2.6990212397211364
Validation loss: 3.053167715309223

Epoch: 6| Step: 3
Training loss: 2.8923023203145912
Validation loss: 3.05480522325672

Epoch: 6| Step: 4
Training loss: 2.66713128413361
Validation loss: 3.054091373433194

Epoch: 6| Step: 5
Training loss: 3.336423744659941
Validation loss: 3.052909690207528

Epoch: 6| Step: 6
Training loss: 3.717782672122101
Validation loss: 3.052834893933869

Epoch: 6| Step: 7
Training loss: 3.223949048219456
Validation loss: 3.0513216665824765

Epoch: 6| Step: 8
Training loss: 3.309241221374271
Validation loss: 3.051795038415429

Epoch: 6| Step: 9
Training loss: 3.178260726806187
Validation loss: 3.0518004482908796

Epoch: 6| Step: 10
Training loss: 3.2846699648448854
Validation loss: 3.051292022584954

Epoch: 6| Step: 11
Training loss: 3.4676036143206743
Validation loss: 3.0566973767474717

Epoch: 6| Step: 12
Training loss: 3.7093942103414737
Validation loss: 3.0521012357171142

Epoch: 6| Step: 13
Training loss: 3.583203705209876
Validation loss: 3.054854294324739

Epoch: 203| Step: 0
Training loss: 2.9988129174524034
Validation loss: 3.055374412785527

Epoch: 6| Step: 1
Training loss: 3.186305701216763
Validation loss: 3.055865438719337

Epoch: 6| Step: 2
Training loss: 2.7860222496026052
Validation loss: 3.053822276342501

Epoch: 6| Step: 3
Training loss: 2.9867244080797506
Validation loss: 3.06025534265729

Epoch: 6| Step: 4
Training loss: 3.3568459150481553
Validation loss: 3.0555975189260898

Epoch: 6| Step: 5
Training loss: 2.0758597281957707
Validation loss: 3.050357963553107

Epoch: 6| Step: 6
Training loss: 3.3606037110698495
Validation loss: 3.05312495082848

Epoch: 6| Step: 7
Training loss: 4.084183325498415
Validation loss: 3.049931283032467

Epoch: 6| Step: 8
Training loss: 3.5971688635234567
Validation loss: 3.0480498592725773

Epoch: 6| Step: 9
Training loss: 3.893755775312669
Validation loss: 3.0480518442105575

Epoch: 6| Step: 10
Training loss: 3.5893667275640486
Validation loss: 3.049282880841627

Epoch: 6| Step: 11
Training loss: 3.2497681755134593
Validation loss: 3.0474615028456853

Epoch: 6| Step: 12
Training loss: 3.0411142518227035
Validation loss: 3.0466710950314337

Epoch: 6| Step: 13
Training loss: 4.011734915072106
Validation loss: 3.0478675237488737

Epoch: 204| Step: 0
Training loss: 3.4451963790043645
Validation loss: 3.0469165446833357

Epoch: 6| Step: 1
Training loss: 2.8367703478550617
Validation loss: 3.0472969059659096

Epoch: 6| Step: 2
Training loss: 3.4347548187130985
Validation loss: 3.047897851237242

Epoch: 6| Step: 3
Training loss: 3.603651653089739
Validation loss: 3.0461133166292815

Epoch: 6| Step: 4
Training loss: 2.685547762783944
Validation loss: 3.046170300694598

Epoch: 6| Step: 5
Training loss: 3.605810477778908
Validation loss: 3.0480402995913054

Epoch: 6| Step: 6
Training loss: 3.2406920143783586
Validation loss: 3.046405297679324

Epoch: 6| Step: 7
Training loss: 2.9878891631561824
Validation loss: 3.0468623318552126

Epoch: 6| Step: 8
Training loss: 3.0151048913426446
Validation loss: 3.0476589400726053

Epoch: 6| Step: 9
Training loss: 3.685489429699369
Validation loss: 3.0481190672410166

Epoch: 6| Step: 10
Training loss: 3.147209590636992
Validation loss: 3.0516939291028597

Epoch: 6| Step: 11
Training loss: 3.183694849573784
Validation loss: 3.047448108623687

Epoch: 6| Step: 12
Training loss: 3.8200928170476924
Validation loss: 3.048022394663293

Epoch: 6| Step: 13
Training loss: 3.615162094935198
Validation loss: 3.0470650124862972

Epoch: 205| Step: 0
Training loss: 3.449105940256022
Validation loss: 3.0487873429692294

Epoch: 6| Step: 1
Training loss: 2.8322304280712878
Validation loss: 3.0467704811816856

Epoch: 6| Step: 2
Training loss: 2.4223813419787557
Validation loss: 3.046795042391329

Epoch: 6| Step: 3
Training loss: 3.1839484081593272
Validation loss: 3.0456434614879138

Epoch: 6| Step: 4
Training loss: 3.8070093859994474
Validation loss: 3.0479443125390997

Epoch: 6| Step: 5
Training loss: 2.703985617463951
Validation loss: 3.0464105690170085

Epoch: 6| Step: 6
Training loss: 3.4927937026284694
Validation loss: 3.0483561148704665

Epoch: 6| Step: 7
Training loss: 3.024021299317448
Validation loss: 3.049184545140191

Epoch: 6| Step: 8
Training loss: 3.1008339898316253
Validation loss: 3.054109085812285

Epoch: 6| Step: 9
Training loss: 3.696085359107866
Validation loss: 3.051045661194625

Epoch: 6| Step: 10
Training loss: 2.9840106841604292
Validation loss: 3.050064932005758

Epoch: 6| Step: 11
Training loss: 3.6579325138497163
Validation loss: 3.0524291113146482

Epoch: 6| Step: 12
Training loss: 3.7800924247462553
Validation loss: 3.0469528907683134

Epoch: 6| Step: 13
Training loss: 4.1927775817586195
Validation loss: 3.0463937434541846

Epoch: 206| Step: 0
Training loss: 3.5304305214446647
Validation loss: 3.047022648660748

Epoch: 6| Step: 1
Training loss: 3.2386193185263425
Validation loss: 3.0417582562308665

Epoch: 6| Step: 2
Training loss: 3.786719032068795
Validation loss: 3.044954296241686

Epoch: 6| Step: 3
Training loss: 2.5360470751054445
Validation loss: 3.0438925105395422

Epoch: 6| Step: 4
Training loss: 2.9066837766417897
Validation loss: 3.0415417697114773

Epoch: 6| Step: 5
Training loss: 3.7123379604542195
Validation loss: 3.04287894198038

Epoch: 6| Step: 6
Training loss: 3.054081459123178
Validation loss: 3.0442514252179746

Epoch: 6| Step: 7
Training loss: 3.102292990959721
Validation loss: 3.041507900262025

Epoch: 6| Step: 8
Training loss: 3.1039940361476903
Validation loss: 3.0419074064544525

Epoch: 6| Step: 9
Training loss: 2.8240105643250404
Validation loss: 3.0417572397953507

Epoch: 6| Step: 10
Training loss: 3.7634514198213678
Validation loss: 3.044869113549117

Epoch: 6| Step: 11
Training loss: 3.3695906628775494
Validation loss: 3.0463358050444564

Epoch: 6| Step: 12
Training loss: 3.8398654816828457
Validation loss: 3.046954489387033

Epoch: 6| Step: 13
Training loss: 3.248231259799504
Validation loss: 3.0490704775716546

Epoch: 207| Step: 0
Training loss: 2.6477067777664267
Validation loss: 3.0510899806909113

Epoch: 6| Step: 1
Training loss: 3.2295564149664844
Validation loss: 3.0434903369655832

Epoch: 6| Step: 2
Training loss: 3.625256759495198
Validation loss: 3.0452801110597796

Epoch: 6| Step: 3
Training loss: 2.734315010502659
Validation loss: 3.0427941831147916

Epoch: 6| Step: 4
Training loss: 3.859056590918514
Validation loss: 3.0404260363776454

Epoch: 6| Step: 5
Training loss: 3.817717437247558
Validation loss: 3.040311264972743

Epoch: 6| Step: 6
Training loss: 3.526678451369366
Validation loss: 3.0452110591381496

Epoch: 6| Step: 7
Training loss: 3.1031490082978928
Validation loss: 3.040638573882497

Epoch: 6| Step: 8
Training loss: 3.7272715663696645
Validation loss: 3.044491625198856

Epoch: 6| Step: 9
Training loss: 2.996938892117004
Validation loss: 3.048061270966164

Epoch: 6| Step: 10
Training loss: 3.0518810912600167
Validation loss: 3.0509925073668445

Epoch: 6| Step: 11
Training loss: 3.0970834055660683
Validation loss: 3.051128763293036

Epoch: 6| Step: 12
Training loss: 3.780229036567585
Validation loss: 3.0538416726018167

Epoch: 6| Step: 13
Training loss: 2.3255746684975143
Validation loss: 3.0460481887541384

Epoch: 208| Step: 0
Training loss: 2.8342505447671162
Validation loss: 3.041333518422418

Epoch: 6| Step: 1
Training loss: 2.5217566782671095
Validation loss: 3.0402570035065075

Epoch: 6| Step: 2
Training loss: 3.7769256328829304
Validation loss: 3.0416395610680977

Epoch: 6| Step: 3
Training loss: 3.2070519171361327
Validation loss: 3.0393509494224453

Epoch: 6| Step: 4
Training loss: 3.317897214358641
Validation loss: 3.037704329203661

Epoch: 6| Step: 5
Training loss: 2.471201777742635
Validation loss: 3.0367961214346604

Epoch: 6| Step: 6
Training loss: 3.7078523359638393
Validation loss: 3.03667853495583

Epoch: 6| Step: 7
Training loss: 3.878390397943124
Validation loss: 3.0355853467944067

Epoch: 6| Step: 8
Training loss: 2.463070093765949
Validation loss: 3.036357127311045

Epoch: 6| Step: 9
Training loss: 3.7570990442293923
Validation loss: 3.037716830463322

Epoch: 6| Step: 10
Training loss: 3.4047754578347638
Validation loss: 3.0357110185916674

Epoch: 6| Step: 11
Training loss: 3.757988368497006
Validation loss: 3.0353993723772033

Epoch: 6| Step: 12
Training loss: 3.0664258433888354
Validation loss: 3.0358911573919216

Epoch: 6| Step: 13
Training loss: 3.8555947759528593
Validation loss: 3.036056368401472

Epoch: 209| Step: 0
Training loss: 2.9760728969054693
Validation loss: 3.0344093890329478

Epoch: 6| Step: 1
Training loss: 3.1301268674348957
Validation loss: 3.035803769672113

Epoch: 6| Step: 2
Training loss: 3.3914796657388524
Validation loss: 3.0371743619848277

Epoch: 6| Step: 3
Training loss: 3.2451628854836105
Validation loss: 3.03791938201488

Epoch: 6| Step: 4
Training loss: 3.210656815115599
Validation loss: 3.0368114080347257

Epoch: 6| Step: 5
Training loss: 3.0807471555612973
Validation loss: 3.0371150743947837

Epoch: 6| Step: 6
Training loss: 3.5016941330086873
Validation loss: 3.0398171041580375

Epoch: 6| Step: 7
Training loss: 2.64964424480409
Validation loss: 3.038098782316131

Epoch: 6| Step: 8
Training loss: 2.8605234310028655
Validation loss: 3.038082311542535

Epoch: 6| Step: 9
Training loss: 4.440206427715669
Validation loss: 3.036717641749361

Epoch: 6| Step: 10
Training loss: 3.028683076970104
Validation loss: 3.0385570523891423

Epoch: 6| Step: 11
Training loss: 3.1856738076335716
Validation loss: 3.037191716372359

Epoch: 6| Step: 12
Training loss: 3.9123631365058187
Validation loss: 3.035208230077594

Epoch: 6| Step: 13
Training loss: 3.24192290547771
Validation loss: 3.038737491545425

Epoch: 210| Step: 0
Training loss: 3.4813419021721117
Validation loss: 3.035559701710682

Epoch: 6| Step: 1
Training loss: 3.4581309492955277
Validation loss: 3.037082047806582

Epoch: 6| Step: 2
Training loss: 3.549579009762342
Validation loss: 3.0397860297932233

Epoch: 6| Step: 3
Training loss: 3.318182910809747
Validation loss: 3.0399948829541428

Epoch: 6| Step: 4
Training loss: 3.4368560187798445
Validation loss: 3.0395350070067484

Epoch: 6| Step: 5
Training loss: 2.9045487213224934
Validation loss: 3.0405383549334135

Epoch: 6| Step: 6
Training loss: 3.1781325978776254
Validation loss: 3.0417416931779573

Epoch: 6| Step: 7
Training loss: 3.4832211623923186
Validation loss: 3.0463827681620157

Epoch: 6| Step: 8
Training loss: 3.2247189480645204
Validation loss: 3.048019627498087

Epoch: 6| Step: 9
Training loss: 2.7754572861012754
Validation loss: 3.0567985671302167

Epoch: 6| Step: 10
Training loss: 3.6565929806244704
Validation loss: 3.053579459673817

Epoch: 6| Step: 11
Training loss: 3.93461951601153
Validation loss: 3.0493015720179315

Epoch: 6| Step: 12
Training loss: 3.0319312205200757
Validation loss: 3.0409630259234985

Epoch: 6| Step: 13
Training loss: 1.8535304817593137
Validation loss: 3.0349669346827084

Epoch: 211| Step: 0
Training loss: 2.8086883147001735
Validation loss: 3.0341284122209435

Epoch: 6| Step: 1
Training loss: 3.2115941176825875
Validation loss: 3.0327059183346954

Epoch: 6| Step: 2
Training loss: 2.8305606364898286
Validation loss: 3.034856629887881

Epoch: 6| Step: 3
Training loss: 3.523947938878742
Validation loss: 3.032029549288384

Epoch: 6| Step: 4
Training loss: 3.6419960681908723
Validation loss: 3.036495302160626

Epoch: 6| Step: 5
Training loss: 3.3058287902087944
Validation loss: 3.032897225099739

Epoch: 6| Step: 6
Training loss: 2.514833029480926
Validation loss: 3.0364920913766396

Epoch: 6| Step: 7
Training loss: 2.947540331071977
Validation loss: 3.0316451652079315

Epoch: 6| Step: 8
Training loss: 3.855645481994514
Validation loss: 3.0368077830880367

Epoch: 6| Step: 9
Training loss: 2.8087273620317927
Validation loss: 3.0322377310686175

Epoch: 6| Step: 10
Training loss: 3.8052810112025566
Validation loss: 3.0429929425625586

Epoch: 6| Step: 11
Training loss: 3.999982356986237
Validation loss: 3.038765453458728

Epoch: 6| Step: 12
Training loss: 3.6237756700451977
Validation loss: 3.0396316737242737

Epoch: 6| Step: 13
Training loss: 2.5644406669180446
Validation loss: 3.0582671975411286

Epoch: 212| Step: 0
Training loss: 3.262313989474031
Validation loss: 3.043067018662773

Epoch: 6| Step: 1
Training loss: 3.0353043960687756
Validation loss: 3.03569640036023

Epoch: 6| Step: 2
Training loss: 3.010111616225995
Validation loss: 3.038078958983644

Epoch: 6| Step: 3
Training loss: 3.108208672390425
Validation loss: 3.0339378345748678

Epoch: 6| Step: 4
Training loss: 2.987278828753723
Validation loss: 3.0367192896553417

Epoch: 6| Step: 5
Training loss: 3.521798236758399
Validation loss: 3.030446857752231

Epoch: 6| Step: 6
Training loss: 3.846105210656993
Validation loss: 3.0345650414108243

Epoch: 6| Step: 7
Training loss: 2.870366218408934
Validation loss: 3.0293868732577045

Epoch: 6| Step: 8
Training loss: 2.913517714397311
Validation loss: 3.0344311752704893

Epoch: 6| Step: 9
Training loss: 3.170497350817074
Validation loss: 3.0348871836920064

Epoch: 6| Step: 10
Training loss: 3.5095028617033086
Validation loss: 3.033212681576928

Epoch: 6| Step: 11
Training loss: 4.163176995287589
Validation loss: 3.034893710019034

Epoch: 6| Step: 12
Training loss: 2.7754855478632394
Validation loss: 3.0331669505438317

Epoch: 6| Step: 13
Training loss: 3.9528108856489808
Validation loss: 3.031596422882862

Epoch: 213| Step: 0
Training loss: 3.0769245111021952
Validation loss: 3.0296033118990175

Epoch: 6| Step: 1
Training loss: 3.156134574970191
Validation loss: 3.0271623979619

Epoch: 6| Step: 2
Training loss: 3.2534934122016823
Validation loss: 3.0264898690510393

Epoch: 6| Step: 3
Training loss: 3.8379871618345387
Validation loss: 3.0254278232664493

Epoch: 6| Step: 4
Training loss: 3.5902815293457055
Validation loss: 3.026352862977212

Epoch: 6| Step: 5
Training loss: 3.002132293774905
Validation loss: 3.0283290811071875

Epoch: 6| Step: 6
Training loss: 3.4218028161086522
Validation loss: 3.0280716571456607

Epoch: 6| Step: 7
Training loss: 3.8427202039276587
Validation loss: 3.027463577233099

Epoch: 6| Step: 8
Training loss: 3.2743763453594954
Validation loss: 3.025213257416677

Epoch: 6| Step: 9
Training loss: 3.6728566257692434
Validation loss: 3.023866387777089

Epoch: 6| Step: 10
Training loss: 3.1213797389310667
Validation loss: 3.0247878202696428

Epoch: 6| Step: 11
Training loss: 3.124461928774353
Validation loss: 3.024109505637531

Epoch: 6| Step: 12
Training loss: 2.991242341646688
Validation loss: 3.0231785817184402

Epoch: 6| Step: 13
Training loss: 1.872403954358765
Validation loss: 3.0249548936906634

Epoch: 214| Step: 0
Training loss: 3.2604504340782507
Validation loss: 3.02441236042094

Epoch: 6| Step: 1
Training loss: 3.877423789716073
Validation loss: 3.0244154475576517

Epoch: 6| Step: 2
Training loss: 2.8287659651119914
Validation loss: 3.0236381770899152

Epoch: 6| Step: 3
Training loss: 2.5969144522083556
Validation loss: 3.023493389446047

Epoch: 6| Step: 4
Training loss: 3.2007175237165146
Validation loss: 3.0217520844598926

Epoch: 6| Step: 5
Training loss: 3.237265948816108
Validation loss: 3.0230523651884207

Epoch: 6| Step: 6
Training loss: 3.2456395167674943
Validation loss: 3.022211848411223

Epoch: 6| Step: 7
Training loss: 3.4437025118840396
Validation loss: 3.022199885287109

Epoch: 6| Step: 8
Training loss: 2.8506827891755955
Validation loss: 3.0238390239888364

Epoch: 6| Step: 9
Training loss: 3.4562884033718473
Validation loss: 3.0243011849503123

Epoch: 6| Step: 10
Training loss: 3.0585167340439314
Validation loss: 3.022915383957018

Epoch: 6| Step: 11
Training loss: 4.292404234878233
Validation loss: 3.021985319721764

Epoch: 6| Step: 12
Training loss: 3.455730577174888
Validation loss: 3.0241313431881247

Epoch: 6| Step: 13
Training loss: 2.6543419660790097
Validation loss: 3.026005038347775

Epoch: 215| Step: 0
Training loss: 3.166169997634122
Validation loss: 3.023996915980846

Epoch: 6| Step: 1
Training loss: 3.1830086574119116
Validation loss: 3.024945406792748

Epoch: 6| Step: 2
Training loss: 3.1217911076084923
Validation loss: 3.023202468798152

Epoch: 6| Step: 3
Training loss: 3.1254667315032947
Validation loss: 3.02850324080469

Epoch: 6| Step: 4
Training loss: 3.319455168497026
Validation loss: 3.0229714145043287

Epoch: 6| Step: 5
Training loss: 3.047383114432836
Validation loss: 3.0237583088664532

Epoch: 6| Step: 6
Training loss: 3.8003069904200566
Validation loss: 3.0226249250492323

Epoch: 6| Step: 7
Training loss: 4.054788635991814
Validation loss: 3.0263330508052153

Epoch: 6| Step: 8
Training loss: 3.123729905471801
Validation loss: 3.027704155646424

Epoch: 6| Step: 9
Training loss: 3.6090548815107186
Validation loss: 3.0247594782669704

Epoch: 6| Step: 10
Training loss: 2.885577770009407
Validation loss: 3.0215806392429085

Epoch: 6| Step: 11
Training loss: 3.598998905437162
Validation loss: 3.021445244979873

Epoch: 6| Step: 12
Training loss: 3.1802462150215947
Validation loss: 3.0213625321663446

Epoch: 6| Step: 13
Training loss: 1.9310295596435818
Validation loss: 3.0214824472742006

Epoch: 216| Step: 0
Training loss: 2.726675911105029
Validation loss: 3.0201122952408777

Epoch: 6| Step: 1
Training loss: 3.2264757491080758
Validation loss: 3.022773473250837

Epoch: 6| Step: 2
Training loss: 3.735145904264981
Validation loss: 3.0215514017363643

Epoch: 6| Step: 3
Training loss: 3.802547534492527
Validation loss: 3.018444178728234

Epoch: 6| Step: 4
Training loss: 2.9434283880636842
Validation loss: 3.0194495290780514

Epoch: 6| Step: 5
Training loss: 2.8773856838131877
Validation loss: 3.020653421364813

Epoch: 6| Step: 6
Training loss: 3.169075016606023
Validation loss: 3.0212939509868773

Epoch: 6| Step: 7
Training loss: 3.3513655882568743
Validation loss: 3.0175195262632735

Epoch: 6| Step: 8
Training loss: 3.555914698449805
Validation loss: 3.0178829859084044

Epoch: 6| Step: 9
Training loss: 3.214918355898827
Validation loss: 3.018503353181235

Epoch: 6| Step: 10
Training loss: 3.0597593539487953
Validation loss: 3.016823885386728

Epoch: 6| Step: 11
Training loss: 3.6417179677275566
Validation loss: 3.0184655595645085

Epoch: 6| Step: 12
Training loss: 3.2902254418119705
Validation loss: 3.0170535181566507

Epoch: 6| Step: 13
Training loss: 3.284285240507533
Validation loss: 3.016413690142596

Epoch: 217| Step: 0
Training loss: 3.060005885099848
Validation loss: 3.0177325386989375

Epoch: 6| Step: 1
Training loss: 2.9442352024641645
Validation loss: 3.016801644827589

Epoch: 6| Step: 2
Training loss: 3.0361317131209815
Validation loss: 3.0170272685954296

Epoch: 6| Step: 3
Training loss: 3.3762115846924963
Validation loss: 3.016566665155373

Epoch: 6| Step: 4
Training loss: 3.716065279170647
Validation loss: 3.017734953898865

Epoch: 6| Step: 5
Training loss: 2.581970029442765
Validation loss: 3.0178610827563177

Epoch: 6| Step: 6
Training loss: 3.586979334460907
Validation loss: 3.018027532192353

Epoch: 6| Step: 7
Training loss: 3.39541273886347
Validation loss: 3.020625220496723

Epoch: 6| Step: 8
Training loss: 3.258263572733092
Validation loss: 3.022178722580163

Epoch: 6| Step: 9
Training loss: 3.504317481703569
Validation loss: 3.0200251809797827

Epoch: 6| Step: 10
Training loss: 3.3609158552919083
Validation loss: 3.0262912726864672

Epoch: 6| Step: 11
Training loss: 3.72391670399408
Validation loss: 3.0195821949798334

Epoch: 6| Step: 12
Training loss: 2.8029756980438596
Validation loss: 3.01920008370574

Epoch: 6| Step: 13
Training loss: 3.595702064095444
Validation loss: 3.017482680367642

Epoch: 218| Step: 0
Training loss: 4.157880878997216
Validation loss: 3.0156576920057683

Epoch: 6| Step: 1
Training loss: 3.284409809018829
Validation loss: 3.0163009220145915

Epoch: 6| Step: 2
Training loss: 3.2487276961414846
Validation loss: 3.0170204189620717

Epoch: 6| Step: 3
Training loss: 3.359289265802796
Validation loss: 3.0139792047448943

Epoch: 6| Step: 4
Training loss: 3.3148037079337516
Validation loss: 3.0161083169286838

Epoch: 6| Step: 5
Training loss: 3.6993685312370848
Validation loss: 3.014221703117287

Epoch: 6| Step: 6
Training loss: 3.517476183628338
Validation loss: 3.0128890785567957

Epoch: 6| Step: 7
Training loss: 2.3499584113154235
Validation loss: 3.01399773209525

Epoch: 6| Step: 8
Training loss: 3.2866579086878263
Validation loss: 3.0129716929980046

Epoch: 6| Step: 9
Training loss: 3.0778752724285225
Validation loss: 3.0153995059594805

Epoch: 6| Step: 10
Training loss: 2.8886609802659664
Validation loss: 3.0134009516083653

Epoch: 6| Step: 11
Training loss: 3.1636848130098763
Validation loss: 3.0140986276885897

Epoch: 6| Step: 12
Training loss: 2.534146194383678
Validation loss: 3.013809790991874

Epoch: 6| Step: 13
Training loss: 4.032686435956442
Validation loss: 3.0139202485326666

Epoch: 219| Step: 0
Training loss: 3.102526305991638
Validation loss: 3.017161855085583

Epoch: 6| Step: 1
Training loss: 3.440336409686763
Validation loss: 3.0151966463825706

Epoch: 6| Step: 2
Training loss: 3.5264164074209714
Validation loss: 3.0155037178594752

Epoch: 6| Step: 3
Training loss: 3.564586630633353
Validation loss: 3.0167635876995744

Epoch: 6| Step: 4
Training loss: 3.028590343138658
Validation loss: 3.0149837362321867

Epoch: 6| Step: 5
Training loss: 2.8167412885302814
Validation loss: 3.0116974404382364

Epoch: 6| Step: 6
Training loss: 3.257130796247634
Validation loss: 3.0124695736316927

Epoch: 6| Step: 7
Training loss: 3.2427652970181806
Validation loss: 3.012700398599175

Epoch: 6| Step: 8
Training loss: 3.430835297196124
Validation loss: 3.0133657509111527

Epoch: 6| Step: 9
Training loss: 2.964377304999565
Validation loss: 3.0102494534678117

Epoch: 6| Step: 10
Training loss: 3.7968561619420798
Validation loss: 3.0124070016473508

Epoch: 6| Step: 11
Training loss: 3.4088631501843207
Validation loss: 3.0161690475988228

Epoch: 6| Step: 12
Training loss: 3.572144954222128
Validation loss: 3.016764262439367

Epoch: 6| Step: 13
Training loss: 1.980574565520981
Validation loss: 3.015108981968734

Epoch: 220| Step: 0
Training loss: 3.6335212262301213
Validation loss: 3.0186710011794884

Epoch: 6| Step: 1
Training loss: 3.8466359291192878
Validation loss: 3.0164991902584855

Epoch: 6| Step: 2
Training loss: 3.5364085640118295
Validation loss: 3.011182137090719

Epoch: 6| Step: 3
Training loss: 3.0504701971109167
Validation loss: 3.0111230775841333

Epoch: 6| Step: 4
Training loss: 3.6821433778910184
Validation loss: 3.0107292532191896

Epoch: 6| Step: 5
Training loss: 3.0241487046065116
Validation loss: 3.0109894983122363

Epoch: 6| Step: 6
Training loss: 2.968608652062707
Validation loss: 3.0092333485431166

Epoch: 6| Step: 7
Training loss: 3.4045509510572356
Validation loss: 3.01254949088656

Epoch: 6| Step: 8
Training loss: 2.1817094728813133
Validation loss: 3.0098943934653573

Epoch: 6| Step: 9
Training loss: 2.844652975736788
Validation loss: 3.0143097250267994

Epoch: 6| Step: 10
Training loss: 3.9008999006370364
Validation loss: 3.010266128479431

Epoch: 6| Step: 11
Training loss: 3.1910648233350063
Validation loss: 3.008020189644832

Epoch: 6| Step: 12
Training loss: 3.368372591353957
Validation loss: 3.008106676601465

Epoch: 6| Step: 13
Training loss: 2.5821021643060647
Validation loss: 3.010009445703259

Epoch: 221| Step: 0
Training loss: 3.311457055927489
Validation loss: 3.013734532158165

Epoch: 6| Step: 1
Training loss: 3.215684486483985
Validation loss: 3.009633624364872

Epoch: 6| Step: 2
Training loss: 3.687480861808122
Validation loss: 3.0092693702654802

Epoch: 6| Step: 3
Training loss: 3.424672833708986
Validation loss: 3.007136820925483

Epoch: 6| Step: 4
Training loss: 2.932112928310442
Validation loss: 3.009659127494157

Epoch: 6| Step: 5
Training loss: 3.101411215217825
Validation loss: 3.009230237311997

Epoch: 6| Step: 6
Training loss: 3.599962123035808
Validation loss: 3.0066810272818265

Epoch: 6| Step: 7
Training loss: 3.762509905526439
Validation loss: 3.007042223100419

Epoch: 6| Step: 8
Training loss: 2.677900869812488
Validation loss: 3.0085332779552254

Epoch: 6| Step: 9
Training loss: 3.162619933014121
Validation loss: 3.0057612988970823

Epoch: 6| Step: 10
Training loss: 3.7605749433323283
Validation loss: 3.008323638148657

Epoch: 6| Step: 11
Training loss: 3.5273291501981907
Validation loss: 3.007945258975992

Epoch: 6| Step: 12
Training loss: 2.7401700763404686
Validation loss: 3.0052503630257075

Epoch: 6| Step: 13
Training loss: 2.236444541866123
Validation loss: 3.007397749408038

Epoch: 222| Step: 0
Training loss: 3.703712127110828
Validation loss: 3.0067150716193725

Epoch: 6| Step: 1
Training loss: 2.8239158372954263
Validation loss: 3.005393943927338

Epoch: 6| Step: 2
Training loss: 3.5687198884832716
Validation loss: 3.006778778378133

Epoch: 6| Step: 3
Training loss: 3.6465003284499704
Validation loss: 3.008809400879951

Epoch: 6| Step: 4
Training loss: 3.3576028097152317
Validation loss: 3.006240564798442

Epoch: 6| Step: 5
Training loss: 2.7810389406508684
Validation loss: 3.0057322998537743

Epoch: 6| Step: 6
Training loss: 2.4920964239334
Validation loss: 3.0058259486982637

Epoch: 6| Step: 7
Training loss: 2.4252553667717502
Validation loss: 3.006653454223609

Epoch: 6| Step: 8
Training loss: 3.0787084965574287
Validation loss: 3.0065241564167398

Epoch: 6| Step: 9
Training loss: 4.011355969630206
Validation loss: 3.0030845573208196

Epoch: 6| Step: 10
Training loss: 3.2904926733524618
Validation loss: 3.006952008781274

Epoch: 6| Step: 11
Training loss: 3.3407933363150133
Validation loss: 3.008742816244247

Epoch: 6| Step: 12
Training loss: 3.3053321299836047
Validation loss: 3.0083981605816605

Epoch: 6| Step: 13
Training loss: 3.904855708192896
Validation loss: 3.0175502878958604

Epoch: 223| Step: 0
Training loss: 3.408270420404748
Validation loss: 3.008458065223763

Epoch: 6| Step: 1
Training loss: 2.7451706877346194
Validation loss: 3.007165133793639

Epoch: 6| Step: 2
Training loss: 3.4140923889388173
Validation loss: 3.008381107080405

Epoch: 6| Step: 3
Training loss: 3.5914965654941193
Validation loss: 3.012647371530101

Epoch: 6| Step: 4
Training loss: 4.090148273196036
Validation loss: 3.0073361852129437

Epoch: 6| Step: 5
Training loss: 3.5103663470154776
Validation loss: 3.005719433570986

Epoch: 6| Step: 6
Training loss: 3.3801876747350383
Validation loss: 3.004000988395802

Epoch: 6| Step: 7
Training loss: 3.1545063905843183
Validation loss: 3.0028697938012563

Epoch: 6| Step: 8
Training loss: 3.5106930194748935
Validation loss: 3.001548529796329

Epoch: 6| Step: 9
Training loss: 3.493057859372407
Validation loss: 3.0027053548858627

Epoch: 6| Step: 10
Training loss: 2.7269011453882905
Validation loss: 3.0012158644023677

Epoch: 6| Step: 11
Training loss: 3.1632754253504354
Validation loss: 3.000954583791927

Epoch: 6| Step: 12
Training loss: 2.2845001061202166
Validation loss: 3.002863103963942

Epoch: 6| Step: 13
Training loss: 2.767546078126914
Validation loss: 3.001000755294792

Epoch: 224| Step: 0
Training loss: 3.4406457552166896
Validation loss: 3.0019854842485807

Epoch: 6| Step: 1
Training loss: 2.9359665784466724
Validation loss: 2.9992381029100015

Epoch: 6| Step: 2
Training loss: 3.288584477352689
Validation loss: 2.999726183847873

Epoch: 6| Step: 3
Training loss: 3.62388988465684
Validation loss: 2.999259867685724

Epoch: 6| Step: 4
Training loss: 3.193476739529049
Validation loss: 3.0003571690790256

Epoch: 6| Step: 5
Training loss: 3.903531402614029
Validation loss: 3.001108719244164

Epoch: 6| Step: 6
Training loss: 2.773195927804543
Validation loss: 3.0065475942844615

Epoch: 6| Step: 7
Training loss: 2.6223318072587305
Validation loss: 3.003348534366104

Epoch: 6| Step: 8
Training loss: 3.5665673577811945
Validation loss: 3.0084701554239457

Epoch: 6| Step: 9
Training loss: 3.281401131192141
Validation loss: 3.0168743619758795

Epoch: 6| Step: 10
Training loss: 2.9817135112644264
Validation loss: 3.018700888237267

Epoch: 6| Step: 11
Training loss: 3.6479102331627993
Validation loss: 3.009584448883244

Epoch: 6| Step: 12
Training loss: 2.695757931377549
Validation loss: 3.0112242125258497

Epoch: 6| Step: 13
Training loss: 3.840563189612081
Validation loss: 3.0084734975189202

Epoch: 225| Step: 0
Training loss: 3.049688829901916
Validation loss: 3.009520300632057

Epoch: 6| Step: 1
Training loss: 3.8245845693742866
Validation loss: 3.00046647540172

Epoch: 6| Step: 2
Training loss: 3.1516287937104406
Validation loss: 3.0054471356523003

Epoch: 6| Step: 3
Training loss: 3.3495344948809618
Validation loss: 2.999959904392518

Epoch: 6| Step: 4
Training loss: 3.4711158176487356
Validation loss: 3.000788895988585

Epoch: 6| Step: 5
Training loss: 3.9108304443825577
Validation loss: 2.999637482729199

Epoch: 6| Step: 6
Training loss: 2.3401491096460494
Validation loss: 3.000038500508016

Epoch: 6| Step: 7
Training loss: 2.95447037341347
Validation loss: 2.998242813018764

Epoch: 6| Step: 8
Training loss: 3.094604528301552
Validation loss: 2.9984797279719557

Epoch: 6| Step: 9
Training loss: 3.3243980493838383
Validation loss: 2.996975751926175

Epoch: 6| Step: 10
Training loss: 3.251237633610856
Validation loss: 2.9964206511494926

Epoch: 6| Step: 11
Training loss: 2.5648352054357177
Validation loss: 2.996431169479969

Epoch: 6| Step: 12
Training loss: 3.606194353913927
Validation loss: 2.997490003769398

Epoch: 6| Step: 13
Training loss: 3.7682240487648095
Validation loss: 2.996669715369601

Epoch: 226| Step: 0
Training loss: 3.218856069057849
Validation loss: 2.9969839946379078

Epoch: 6| Step: 1
Training loss: 4.033268622727856
Validation loss: 2.998354462214192

Epoch: 6| Step: 2
Training loss: 3.5859603714888806
Validation loss: 2.996763448950822

Epoch: 6| Step: 3
Training loss: 3.1855163385645535
Validation loss: 2.9982871665802864

Epoch: 6| Step: 4
Training loss: 3.1184642347395313
Validation loss: 2.995972133714354

Epoch: 6| Step: 5
Training loss: 2.978005047170693
Validation loss: 2.996995010547064

Epoch: 6| Step: 6
Training loss: 3.025342080186708
Validation loss: 2.994138561511061

Epoch: 6| Step: 7
Training loss: 3.3484595101790604
Validation loss: 3.00002633531011

Epoch: 6| Step: 8
Training loss: 3.3330852098305574
Validation loss: 2.9991463203707536

Epoch: 6| Step: 9
Training loss: 3.1039757552527334
Validation loss: 3.0023769136879594

Epoch: 6| Step: 10
Training loss: 3.695390696434139
Validation loss: 3.002242200663364

Epoch: 6| Step: 11
Training loss: 3.0627231127373253
Validation loss: 3.0071317919129523

Epoch: 6| Step: 12
Training loss: 3.038827450642809
Validation loss: 3.0017234302373264

Epoch: 6| Step: 13
Training loss: 2.546008190720202
Validation loss: 2.999190858879117

Epoch: 227| Step: 0
Training loss: 3.6469715775725575
Validation loss: 2.997819107797562

Epoch: 6| Step: 1
Training loss: 4.109250839156262
Validation loss: 3.0013473520496787

Epoch: 6| Step: 2
Training loss: 3.17311049579208
Validation loss: 2.9970254636196416

Epoch: 6| Step: 3
Training loss: 3.162104700284145
Validation loss: 2.998088773072769

Epoch: 6| Step: 4
Training loss: 3.136368481377238
Validation loss: 2.997987667043022

Epoch: 6| Step: 5
Training loss: 3.6099044609636355
Validation loss: 2.995512235965596

Epoch: 6| Step: 6
Training loss: 2.9004478371882505
Validation loss: 2.9930686487554

Epoch: 6| Step: 7
Training loss: 2.6380465406776374
Validation loss: 2.993594935044096

Epoch: 6| Step: 8
Training loss: 3.3688326399085025
Validation loss: 2.9931646500579374

Epoch: 6| Step: 9
Training loss: 2.75056616417061
Validation loss: 2.9966417285244202

Epoch: 6| Step: 10
Training loss: 3.4229722027598615
Validation loss: 2.9977125416394466

Epoch: 6| Step: 11
Training loss: 3.0694785502185002
Validation loss: 2.9954470400571167

Epoch: 6| Step: 12
Training loss: 3.1667851543009635
Validation loss: 2.9948781267537647

Epoch: 6| Step: 13
Training loss: 3.299179356579433
Validation loss: 2.9943476627708705

Epoch: 228| Step: 0
Training loss: 3.509230567086414
Validation loss: 2.996560306483656

Epoch: 6| Step: 1
Training loss: 3.3405755206191583
Validation loss: 2.996519859423056

Epoch: 6| Step: 2
Training loss: 3.8180736386055276
Validation loss: 2.994884162462445

Epoch: 6| Step: 3
Training loss: 3.7408276597833527
Validation loss: 2.993700564499495

Epoch: 6| Step: 4
Training loss: 2.785417755819111
Validation loss: 2.993444999678227

Epoch: 6| Step: 5
Training loss: 2.2875509120924584
Validation loss: 2.993874293028065

Epoch: 6| Step: 6
Training loss: 3.4852014767436463
Validation loss: 2.994347770647026

Epoch: 6| Step: 7
Training loss: 3.5323182237294826
Validation loss: 2.992391080679774

Epoch: 6| Step: 8
Training loss: 3.2280982105956717
Validation loss: 2.99309838804131

Epoch: 6| Step: 9
Training loss: 3.290046454104564
Validation loss: 2.992178385580995

Epoch: 6| Step: 10
Training loss: 3.3239624068042866
Validation loss: 2.99430451799016

Epoch: 6| Step: 11
Training loss: 3.4520344803061653
Validation loss: 2.9980186649999587

Epoch: 6| Step: 12
Training loss: 2.539617859186106
Validation loss: 2.998596697234228

Epoch: 6| Step: 13
Training loss: 2.822903866521852
Validation loss: 3.0001155444765417

Epoch: 229| Step: 0
Training loss: 3.5300638012618135
Validation loss: 3.0041421474154637

Epoch: 6| Step: 1
Training loss: 2.3134345151043867
Validation loss: 3.002194856177928

Epoch: 6| Step: 2
Training loss: 3.616627726074221
Validation loss: 3.0082269377464836

Epoch: 6| Step: 3
Training loss: 3.3860720112641296
Validation loss: 3.0134862088242675

Epoch: 6| Step: 4
Training loss: 2.8218486966315024
Validation loss: 3.0087485523318294

Epoch: 6| Step: 5
Training loss: 3.081827792763653
Validation loss: 3.010051303314976

Epoch: 6| Step: 6
Training loss: 3.7822309750571343
Validation loss: 3.0177693297234662

Epoch: 6| Step: 7
Training loss: 2.7190376217292225
Validation loss: 3.0036321327427906

Epoch: 6| Step: 8
Training loss: 4.097383473702017
Validation loss: 3.0011441756082067

Epoch: 6| Step: 9
Training loss: 3.4155298218026213
Validation loss: 2.995414137742185

Epoch: 6| Step: 10
Training loss: 2.653241956309892
Validation loss: 3.004464561792956

Epoch: 6| Step: 11
Training loss: 3.279577501114348
Validation loss: 2.992903543706981

Epoch: 6| Step: 12
Training loss: 3.068167910560401
Validation loss: 2.9917014445934376

Epoch: 6| Step: 13
Training loss: 3.6912693220305224
Validation loss: 2.9910480098051146

Epoch: 230| Step: 0
Training loss: 3.338418578419478
Validation loss: 2.989982645771388

Epoch: 6| Step: 1
Training loss: 3.2769747538846947
Validation loss: 2.9894311303126875

Epoch: 6| Step: 2
Training loss: 3.2002716008796774
Validation loss: 2.99379625781583

Epoch: 6| Step: 3
Training loss: 3.2932502381913915
Validation loss: 2.9940689457532184

Epoch: 6| Step: 4
Training loss: 3.2408232610782557
Validation loss: 2.992760890051201

Epoch: 6| Step: 5
Training loss: 3.902468628741995
Validation loss: 2.995905888867289

Epoch: 6| Step: 6
Training loss: 2.596668853105923
Validation loss: 2.9947149234620882

Epoch: 6| Step: 7
Training loss: 3.2072951548599615
Validation loss: 2.9930473177598955

Epoch: 6| Step: 8
Training loss: 3.213323815544036
Validation loss: 2.9933298075075303

Epoch: 6| Step: 9
Training loss: 3.0042691055024293
Validation loss: 2.9903182728894966

Epoch: 6| Step: 10
Training loss: 2.9361333711667132
Validation loss: 2.990398353484088

Epoch: 6| Step: 11
Training loss: 3.974481484045007
Validation loss: 2.995577786471464

Epoch: 6| Step: 12
Training loss: 2.9569986762365397
Validation loss: 2.9938674049803464

Epoch: 6| Step: 13
Training loss: 3.389138594705672
Validation loss: 2.9932761058283304

Epoch: 231| Step: 0
Training loss: 4.138765889387584
Validation loss: 2.997053826673273

Epoch: 6| Step: 1
Training loss: 3.5483105145018268
Validation loss: 2.9972249154258437

Epoch: 6| Step: 2
Training loss: 3.2805820330151474
Validation loss: 2.9935114689787223

Epoch: 6| Step: 3
Training loss: 2.8048348985793394
Validation loss: 2.9896616665887734

Epoch: 6| Step: 4
Training loss: 3.4835989733680566
Validation loss: 2.989375775497472

Epoch: 6| Step: 5
Training loss: 3.0483548214257423
Validation loss: 2.9907962187676396

Epoch: 6| Step: 6
Training loss: 3.170404403354649
Validation loss: 2.986841987044431

Epoch: 6| Step: 7
Training loss: 3.0720056422599
Validation loss: 2.9875897693743885

Epoch: 6| Step: 8
Training loss: 2.7981666693738467
Validation loss: 2.985867905655313

Epoch: 6| Step: 9
Training loss: 3.1798466073233715
Validation loss: 2.9875002548280136

Epoch: 6| Step: 10
Training loss: 3.938411667655912
Validation loss: 2.9887760137481947

Epoch: 6| Step: 11
Training loss: 3.4510316329120867
Validation loss: 2.988889434390904

Epoch: 6| Step: 12
Training loss: 2.9283058265374042
Validation loss: 2.9906285048852683

Epoch: 6| Step: 13
Training loss: 1.396652446316331
Validation loss: 2.990401307706309

Epoch: 232| Step: 0
Training loss: 3.2634223189672515
Validation loss: 2.9901880355387256

Epoch: 6| Step: 1
Training loss: 3.344050028522558
Validation loss: 2.990120268034836

Epoch: 6| Step: 2
Training loss: 2.7074092364398052
Validation loss: 2.9952997042985032

Epoch: 6| Step: 3
Training loss: 3.6997619036798706
Validation loss: 2.9921987803188252

Epoch: 6| Step: 4
Training loss: 3.423175582024482
Validation loss: 2.986629419511574

Epoch: 6| Step: 5
Training loss: 3.6373831923564377
Validation loss: 2.9881327716128268

Epoch: 6| Step: 6
Training loss: 2.939179772121658
Validation loss: 2.9863007915363022

Epoch: 6| Step: 7
Training loss: 3.3715101495437563
Validation loss: 2.9857872776786043

Epoch: 6| Step: 8
Training loss: 3.565222118461525
Validation loss: 2.9802114655489267

Epoch: 6| Step: 9
Training loss: 3.0404394800843617
Validation loss: 2.980961280966127

Epoch: 6| Step: 10
Training loss: 2.7484546133856425
Validation loss: 2.980804131609739

Epoch: 6| Step: 11
Training loss: 3.852754915134908
Validation loss: 2.981829400657696

Epoch: 6| Step: 12
Training loss: 2.670891564062225
Validation loss: 2.9805517220452806

Epoch: 6| Step: 13
Training loss: 2.969227963169151
Validation loss: 2.981357371084197

Epoch: 233| Step: 0
Training loss: 2.722724815173016
Validation loss: 2.9818036053379946

Epoch: 6| Step: 1
Training loss: 2.8679351247688314
Validation loss: 2.9843563497379675

Epoch: 6| Step: 2
Training loss: 3.0198202253984565
Validation loss: 2.983391061241387

Epoch: 6| Step: 3
Training loss: 2.9837204779645496
Validation loss: 2.9818497140032436

Epoch: 6| Step: 4
Training loss: 3.645305718891035
Validation loss: 2.9816478709088843

Epoch: 6| Step: 5
Training loss: 4.132071935287859
Validation loss: 2.982428204966181

Epoch: 6| Step: 6
Training loss: 3.0618751044038786
Validation loss: 2.980943999982112

Epoch: 6| Step: 7
Training loss: 3.122457767197912
Validation loss: 2.9842087181191763

Epoch: 6| Step: 8
Training loss: 3.3178443262004307
Validation loss: 2.98538451045238

Epoch: 6| Step: 9
Training loss: 3.329792733142848
Validation loss: 2.983291717140956

Epoch: 6| Step: 10
Training loss: 3.798431454225701
Validation loss: 2.9842539357225415

Epoch: 6| Step: 11
Training loss: 3.396423444590768
Validation loss: 2.9809219423727478

Epoch: 6| Step: 12
Training loss: 2.8072442007681806
Validation loss: 2.979837763815292

Epoch: 6| Step: 13
Training loss: 3.0028358407591735
Validation loss: 2.981044714012019

Epoch: 234| Step: 0
Training loss: 2.6981342969234534
Validation loss: 2.9836340849286067

Epoch: 6| Step: 1
Training loss: 3.5153183188717927
Validation loss: 2.9820432732039857

Epoch: 6| Step: 2
Training loss: 3.0471225735755287
Validation loss: 2.9810662745077887

Epoch: 6| Step: 3
Training loss: 3.0240313910212366
Validation loss: 2.9793105063094596

Epoch: 6| Step: 4
Training loss: 3.671679422567348
Validation loss: 2.982292444703829

Epoch: 6| Step: 5
Training loss: 2.535138851629195
Validation loss: 2.98140293374961

Epoch: 6| Step: 6
Training loss: 3.6509781349883603
Validation loss: 2.980485987291877

Epoch: 6| Step: 7
Training loss: 3.555632547366171
Validation loss: 2.9806929766734154

Epoch: 6| Step: 8
Training loss: 3.0569465264761932
Validation loss: 2.9801156439857337

Epoch: 6| Step: 9
Training loss: 2.9885912765546143
Validation loss: 2.979287754669811

Epoch: 6| Step: 10
Training loss: 3.989573240474886
Validation loss: 2.9844151795752496

Epoch: 6| Step: 11
Training loss: 3.483302751130064
Validation loss: 2.9813754029317288

Epoch: 6| Step: 12
Training loss: 2.8313435318004703
Validation loss: 2.9808810104890977

Epoch: 6| Step: 13
Training loss: 3.141339880207323
Validation loss: 2.977185494487522

Epoch: 235| Step: 0
Training loss: 3.0008306942664817
Validation loss: 2.97468328385143

Epoch: 6| Step: 1
Training loss: 3.3507531529336103
Validation loss: 2.977151445720922

Epoch: 6| Step: 2
Training loss: 3.2215993176831113
Validation loss: 2.977823886063878

Epoch: 6| Step: 3
Training loss: 3.203479430895782
Validation loss: 2.978835036595514

Epoch: 6| Step: 4
Training loss: 2.919045286741431
Validation loss: 2.97793235195739

Epoch: 6| Step: 5
Training loss: 3.2901079052329227
Validation loss: 2.9774478130513518

Epoch: 6| Step: 6
Training loss: 3.390781943912364
Validation loss: 2.977259810395627

Epoch: 6| Step: 7
Training loss: 3.3494747034698693
Validation loss: 2.9767619457975516

Epoch: 6| Step: 8
Training loss: 3.3537075763170363
Validation loss: 2.976056585063054

Epoch: 6| Step: 9
Training loss: 3.1567173979998526
Validation loss: 2.9765637729650556

Epoch: 6| Step: 10
Training loss: 3.3915169241526666
Validation loss: 2.9786134578104244

Epoch: 6| Step: 11
Training loss: 3.1271306213286905
Validation loss: 2.9756819755722543

Epoch: 6| Step: 12
Training loss: 3.7907892127134435
Validation loss: 2.973807532342551

Epoch: 6| Step: 13
Training loss: 2.605158705901537
Validation loss: 2.9750705087092375

Epoch: 236| Step: 0
Training loss: 2.645818354847079
Validation loss: 2.9750533038071074

Epoch: 6| Step: 1
Training loss: 2.703205085405961
Validation loss: 2.9741483680474032

Epoch: 6| Step: 2
Training loss: 3.481476403481438
Validation loss: 2.9812167361289466

Epoch: 6| Step: 3
Training loss: 3.372964739834888
Validation loss: 2.9769087750895364

Epoch: 6| Step: 4
Training loss: 3.184049047197756
Validation loss: 2.9780042448505637

Epoch: 6| Step: 5
Training loss: 3.13068513629324
Validation loss: 2.976383578398238

Epoch: 6| Step: 6
Training loss: 2.7801949718083283
Validation loss: 2.9743115181429816

Epoch: 6| Step: 7
Training loss: 4.159007140300003
Validation loss: 2.977880301011823

Epoch: 6| Step: 8
Training loss: 3.3177063531235915
Validation loss: 2.9791215253100964

Epoch: 6| Step: 9
Training loss: 3.3407609360588753
Validation loss: 2.978976427700987

Epoch: 6| Step: 10
Training loss: 2.68631895861685
Validation loss: 2.97827876173468

Epoch: 6| Step: 11
Training loss: 3.689447179802648
Validation loss: 2.9745491739276777

Epoch: 6| Step: 12
Training loss: 3.5985670893760924
Validation loss: 2.9729892551253103

Epoch: 6| Step: 13
Training loss: 2.923891238829082
Validation loss: 2.971773974654515

Epoch: 237| Step: 0
Training loss: 2.813981238361598
Validation loss: 2.973057843394596

Epoch: 6| Step: 1
Training loss: 3.0195653600110903
Validation loss: 2.972355040693276

Epoch: 6| Step: 2
Training loss: 3.2359394215311474
Validation loss: 2.972405884324288

Epoch: 6| Step: 3
Training loss: 2.944685244360506
Validation loss: 2.9728235488709234

Epoch: 6| Step: 4
Training loss: 2.993828784009511
Validation loss: 2.9726971623237306

Epoch: 6| Step: 5
Training loss: 3.566797040772844
Validation loss: 2.971431565550853

Epoch: 6| Step: 6
Training loss: 3.95889789503783
Validation loss: 2.9728500240314535

Epoch: 6| Step: 7
Training loss: 3.1321810801886594
Validation loss: 2.973409415673766

Epoch: 6| Step: 8
Training loss: 3.8531537898736885
Validation loss: 2.971405837852597

Epoch: 6| Step: 9
Training loss: 3.3691437386760974
Validation loss: 2.9742393342938436

Epoch: 6| Step: 10
Training loss: 3.200304380484235
Validation loss: 2.977024516106448

Epoch: 6| Step: 11
Training loss: 2.495019529338844
Validation loss: 2.973210328726283

Epoch: 6| Step: 12
Training loss: 3.691397207743555
Validation loss: 2.9740761181747617

Epoch: 6| Step: 13
Training loss: 2.5326566202249445
Validation loss: 2.974628583652564

Epoch: 238| Step: 0
Training loss: 3.637419373972217
Validation loss: 2.9716270145855814

Epoch: 6| Step: 1
Training loss: 3.304851843532874
Validation loss: 2.9728228029304424

Epoch: 6| Step: 2
Training loss: 3.0886848678112964
Validation loss: 2.9703642648309443

Epoch: 6| Step: 3
Training loss: 3.801001296382644
Validation loss: 2.971720252668481

Epoch: 6| Step: 4
Training loss: 3.540846217248654
Validation loss: 2.9694447290103003

Epoch: 6| Step: 5
Training loss: 3.366994051233242
Validation loss: 2.970042652681372

Epoch: 6| Step: 6
Training loss: 3.565429018804717
Validation loss: 2.97109757733787

Epoch: 6| Step: 7
Training loss: 3.619192272297428
Validation loss: 2.972437989106532

Epoch: 6| Step: 8
Training loss: 2.356147427944498
Validation loss: 2.973729777469758

Epoch: 6| Step: 9
Training loss: 2.3698960724911924
Validation loss: 2.970063835569241

Epoch: 6| Step: 10
Training loss: 2.500614853590231
Validation loss: 2.975407975597072

Epoch: 6| Step: 11
Training loss: 3.3964944831649473
Validation loss: 2.9724011855295185

Epoch: 6| Step: 12
Training loss: 3.7036069403476537
Validation loss: 2.974929394723906

Epoch: 6| Step: 13
Training loss: 2.227646627341817
Validation loss: 2.970103506143092

Epoch: 239| Step: 0
Training loss: 3.5337438638780267
Validation loss: 2.972054848034413

Epoch: 6| Step: 1
Training loss: 3.576879559450178
Validation loss: 2.973477047589597

Epoch: 6| Step: 2
Training loss: 2.943959378128095
Validation loss: 2.9746316569565163

Epoch: 6| Step: 3
Training loss: 3.688281865393602
Validation loss: 2.972170398118385

Epoch: 6| Step: 4
Training loss: 3.3453492235201887
Validation loss: 2.978171406851672

Epoch: 6| Step: 5
Training loss: 3.7678397222799336
Validation loss: 2.9803466307377664

Epoch: 6| Step: 6
Training loss: 2.7258542952804943
Validation loss: 2.985659087197126

Epoch: 6| Step: 7
Training loss: 3.0711370627629706
Validation loss: 2.978709311344731

Epoch: 6| Step: 8
Training loss: 2.8280756824893234
Validation loss: 2.975510785408839

Epoch: 6| Step: 9
Training loss: 2.6060912891245724
Validation loss: 2.977348063993123

Epoch: 6| Step: 10
Training loss: 3.226312142697023
Validation loss: 2.9756109208614707

Epoch: 6| Step: 11
Training loss: 3.5472300347587593
Validation loss: 2.9827962551300815

Epoch: 6| Step: 12
Training loss: 3.5939178427602174
Validation loss: 2.975112888906724

Epoch: 6| Step: 13
Training loss: 2.152201514555022
Validation loss: 2.974127346134223

Epoch: 240| Step: 0
Training loss: 3.0236882541970718
Validation loss: 2.96855843254619

Epoch: 6| Step: 1
Training loss: 3.5824162100598542
Validation loss: 2.9679668004372357

Epoch: 6| Step: 2
Training loss: 3.6296152134765456
Validation loss: 2.9640892571498125

Epoch: 6| Step: 3
Training loss: 2.5486337404923973
Validation loss: 2.96625550524767

Epoch: 6| Step: 4
Training loss: 2.8588546529611842
Validation loss: 2.9647716607648724

Epoch: 6| Step: 5
Training loss: 3.9196319853026407
Validation loss: 2.965137064293782

Epoch: 6| Step: 6
Training loss: 2.855503316897051
Validation loss: 2.9653785650461737

Epoch: 6| Step: 7
Training loss: 3.2340127493300934
Validation loss: 2.9657088656707167

Epoch: 6| Step: 8
Training loss: 3.3621088303851074
Validation loss: 2.965926190369626

Epoch: 6| Step: 9
Training loss: 3.2557038359856025
Validation loss: 2.9650705624120497

Epoch: 6| Step: 10
Training loss: 3.058548226632804
Validation loss: 2.964825003681686

Epoch: 6| Step: 11
Training loss: 3.2162465850657758
Validation loss: 2.963842335228661

Epoch: 6| Step: 12
Training loss: 3.040097254151134
Validation loss: 2.9652151465070617

Epoch: 6| Step: 13
Training loss: 3.8723225110963897
Validation loss: 2.9626739368854955

Epoch: 241| Step: 0
Training loss: 3.4111330920769998
Validation loss: 2.96356465063859

Epoch: 6| Step: 1
Training loss: 2.853060394257586
Validation loss: 2.9666946022909433

Epoch: 6| Step: 2
Training loss: 3.039064382832
Validation loss: 2.963254476556673

Epoch: 6| Step: 3
Training loss: 3.3399015722790706
Validation loss: 2.964337163432832

Epoch: 6| Step: 4
Training loss: 2.551128369674315
Validation loss: 2.9649656517879275

Epoch: 6| Step: 5
Training loss: 3.7542344663356677
Validation loss: 2.9798530139668853

Epoch: 6| Step: 6
Training loss: 2.852094208775794
Validation loss: 2.9822409374995753

Epoch: 6| Step: 7
Training loss: 3.282635786700968
Validation loss: 2.981832830645485

Epoch: 6| Step: 8
Training loss: 3.1123213873787137
Validation loss: 2.980724228452288

Epoch: 6| Step: 9
Training loss: 3.2759660591817257
Validation loss: 2.9804903946552934

Epoch: 6| Step: 10
Training loss: 3.904747635896156
Validation loss: 2.9763669323389643

Epoch: 6| Step: 11
Training loss: 2.9014225726264504
Validation loss: 2.973859417507013

Epoch: 6| Step: 12
Training loss: 3.569213430908953
Validation loss: 2.9714337207315613

Epoch: 6| Step: 13
Training loss: 3.363564651015357
Validation loss: 2.9630459895138848

Epoch: 242| Step: 0
Training loss: 3.2515692223658585
Validation loss: 2.9601154883913106

Epoch: 6| Step: 1
Training loss: 3.7472034199058113
Validation loss: 2.9601789682511983

Epoch: 6| Step: 2
Training loss: 3.1690095633413335
Validation loss: 2.960744715307643

Epoch: 6| Step: 3
Training loss: 2.688635564024339
Validation loss: 2.9596834465726167

Epoch: 6| Step: 4
Training loss: 3.324386287640641
Validation loss: 2.962566268343791

Epoch: 6| Step: 5
Training loss: 3.032252509701785
Validation loss: 2.9620888885098884

Epoch: 6| Step: 6
Training loss: 3.6820573889607675
Validation loss: 2.962873920439524

Epoch: 6| Step: 7
Training loss: 3.2059139856423786
Validation loss: 2.9623220338089347

Epoch: 6| Step: 8
Training loss: 2.8496927062224553
Validation loss: 2.959687754119634

Epoch: 6| Step: 9
Training loss: 3.896014666629577
Validation loss: 2.9609841933359244

Epoch: 6| Step: 10
Training loss: 3.8369652639590854
Validation loss: 2.960709432343016

Epoch: 6| Step: 11
Training loss: 2.7213042964959278
Validation loss: 2.960778401193292

Epoch: 6| Step: 12
Training loss: 2.864635693620661
Validation loss: 2.960232869376285

Epoch: 6| Step: 13
Training loss: 2.436435564860838
Validation loss: 2.9603053800358663

Epoch: 243| Step: 0
Training loss: 3.432142486957855
Validation loss: 2.9591894065140836

Epoch: 6| Step: 1
Training loss: 2.5748682895789443
Validation loss: 2.9594393864655

Epoch: 6| Step: 2
Training loss: 3.462748241133006
Validation loss: 2.9583368354810142

Epoch: 6| Step: 3
Training loss: 3.001196940380816
Validation loss: 2.959346341869525

Epoch: 6| Step: 4
Training loss: 3.1380480162312447
Validation loss: 2.962868993675069

Epoch: 6| Step: 5
Training loss: 2.710083840822252
Validation loss: 2.95876553359517

Epoch: 6| Step: 6
Training loss: 3.296424147888248
Validation loss: 2.958249108379177

Epoch: 6| Step: 7
Training loss: 3.7497643714627857
Validation loss: 2.9628042112384603

Epoch: 6| Step: 8
Training loss: 3.521388911065643
Validation loss: 2.9616966121891197

Epoch: 6| Step: 9
Training loss: 3.1130297474283832
Validation loss: 2.963348649401321

Epoch: 6| Step: 10
Training loss: 2.5901035276363977
Validation loss: 2.9619099494742667

Epoch: 6| Step: 11
Training loss: 3.3348489812375512
Validation loss: 2.959934484765043

Epoch: 6| Step: 12
Training loss: 4.2617147220134495
Validation loss: 2.963095405255138

Epoch: 6| Step: 13
Training loss: 2.2339991540181496
Validation loss: 2.962483831011649

Epoch: 244| Step: 0
Training loss: 3.834698696510272
Validation loss: 2.9653901055532286

Epoch: 6| Step: 1
Training loss: 3.2728891573469605
Validation loss: 2.961868746196737

Epoch: 6| Step: 2
Training loss: 2.8782993127181458
Validation loss: 2.960946369452779

Epoch: 6| Step: 3
Training loss: 3.6142056988863134
Validation loss: 2.9629887842377203

Epoch: 6| Step: 4
Training loss: 3.3438118902165117
Validation loss: 2.9643040317017952

Epoch: 6| Step: 5
Training loss: 3.4196067503659595
Validation loss: 2.961407473405883

Epoch: 6| Step: 6
Training loss: 2.5142214632959052
Validation loss: 2.9603079182967944

Epoch: 6| Step: 7
Training loss: 3.173821814897573
Validation loss: 2.958612936332077

Epoch: 6| Step: 8
Training loss: 3.1915574522397785
Validation loss: 2.9641088185273214

Epoch: 6| Step: 9
Training loss: 2.597567770462121
Validation loss: 2.963558204256261

Epoch: 6| Step: 10
Training loss: 3.374647192705029
Validation loss: 2.96660758207725

Epoch: 6| Step: 11
Training loss: 3.2916009308894694
Validation loss: 2.9589813755490892

Epoch: 6| Step: 12
Training loss: 3.316345573741907
Validation loss: 2.9580064951489717

Epoch: 6| Step: 13
Training loss: 3.1817729587561363
Validation loss: 2.9616092226553508

Epoch: 245| Step: 0
Training loss: 2.5955256623168106
Validation loss: 2.964549865342342

Epoch: 6| Step: 1
Training loss: 3.232799791446595
Validation loss: 2.970181027958323

Epoch: 6| Step: 2
Training loss: 3.3046779767704093
Validation loss: 2.9759048270631063

Epoch: 6| Step: 3
Training loss: 3.313738321566499
Validation loss: 2.974116667897043

Epoch: 6| Step: 4
Training loss: 3.275692984376446
Validation loss: 2.974956076919849

Epoch: 6| Step: 5
Training loss: 2.7658756810603498
Validation loss: 2.9724676553627227

Epoch: 6| Step: 6
Training loss: 3.9090589265946547
Validation loss: 2.964086263729591

Epoch: 6| Step: 7
Training loss: 3.4431402923249927
Validation loss: 2.9627478518756956

Epoch: 6| Step: 8
Training loss: 2.9978006566240305
Validation loss: 2.956133919333649

Epoch: 6| Step: 9
Training loss: 3.3264785060787343
Validation loss: 2.9593048118219265

Epoch: 6| Step: 10
Training loss: 3.5864167069852018
Validation loss: 2.9580437811564493

Epoch: 6| Step: 11
Training loss: 3.29938863235146
Validation loss: 2.953927247936789

Epoch: 6| Step: 12
Training loss: 3.0980121268619323
Validation loss: 2.9584268892831376

Epoch: 6| Step: 13
Training loss: 2.625345025775472
Validation loss: 2.9536703907961397

Epoch: 246| Step: 0
Training loss: 3.1538587519839596
Validation loss: 2.954871275168595

Epoch: 6| Step: 1
Training loss: 2.7482520530468846
Validation loss: 2.9537875392668465

Epoch: 6| Step: 2
Training loss: 2.5795803701705893
Validation loss: 2.951346822234167

Epoch: 6| Step: 3
Training loss: 3.314374141617473
Validation loss: 2.953690681680696

Epoch: 6| Step: 4
Training loss: 3.4583579066372514
Validation loss: 2.9537580594714323

Epoch: 6| Step: 5
Training loss: 2.7128233053314967
Validation loss: 2.9510101282504273

Epoch: 6| Step: 6
Training loss: 3.2498735256528457
Validation loss: 2.9526594065916267

Epoch: 6| Step: 7
Training loss: 3.2754440530731115
Validation loss: 2.9542832428386543

Epoch: 6| Step: 8
Training loss: 3.3403475554314195
Validation loss: 2.9506825819979983

Epoch: 6| Step: 9
Training loss: 3.043712520172781
Validation loss: 2.9523229057172884

Epoch: 6| Step: 10
Training loss: 3.581947517040352
Validation loss: 2.951126853285806

Epoch: 6| Step: 11
Training loss: 3.4022363937030735
Validation loss: 2.949641595137015

Epoch: 6| Step: 12
Training loss: 3.672791711532091
Validation loss: 2.9512612752974454

Epoch: 6| Step: 13
Training loss: 3.729596388510613
Validation loss: 2.9554304699032925

Epoch: 247| Step: 0
Training loss: 2.9349146077667765
Validation loss: 2.9512120080037856

Epoch: 6| Step: 1
Training loss: 2.9066222577975154
Validation loss: 2.9624765895979293

Epoch: 6| Step: 2
Training loss: 3.8938639077659287
Validation loss: 2.9682148846749863

Epoch: 6| Step: 3
Training loss: 3.4133934220846363
Validation loss: 2.9553882203648323

Epoch: 6| Step: 4
Training loss: 2.6713816761770404
Validation loss: 2.9498280511420445

Epoch: 6| Step: 5
Training loss: 2.57208682331652
Validation loss: 2.950759568861394

Epoch: 6| Step: 6
Training loss: 3.499776151855736
Validation loss: 2.9513374887454766

Epoch: 6| Step: 7
Training loss: 4.288850372571949
Validation loss: 2.954001443404155

Epoch: 6| Step: 8
Training loss: 3.181263226254891
Validation loss: 2.954781722940889

Epoch: 6| Step: 9
Training loss: 3.1812744679287595
Validation loss: 2.9561409499386504

Epoch: 6| Step: 10
Training loss: 2.404527716629414
Validation loss: 2.953915437865457

Epoch: 6| Step: 11
Training loss: 3.320204789153667
Validation loss: 2.9562156379189206

Epoch: 6| Step: 12
Training loss: 3.1381835557632836
Validation loss: 2.9522499185159754

Epoch: 6| Step: 13
Training loss: 3.4552638821779444
Validation loss: 2.950666328756208

Epoch: 248| Step: 0
Training loss: 3.5574961538823477
Validation loss: 2.9492828746817294

Epoch: 6| Step: 1
Training loss: 3.4653633699992867
Validation loss: 2.952005820478625

Epoch: 6| Step: 2
Training loss: 3.4146169391225105
Validation loss: 2.950088972596128

Epoch: 6| Step: 3
Training loss: 3.0362765136164183
Validation loss: 2.949841954673207

Epoch: 6| Step: 4
Training loss: 3.304357922580055
Validation loss: 2.9538619343876045

Epoch: 6| Step: 5
Training loss: 3.4470653270421905
Validation loss: 2.949821682506812

Epoch: 6| Step: 6
Training loss: 3.1988186801515224
Validation loss: 2.955751621597787

Epoch: 6| Step: 7
Training loss: 2.712077755738915
Validation loss: 2.9541193910252463

Epoch: 6| Step: 8
Training loss: 3.268158874161079
Validation loss: 2.958275855229756

Epoch: 6| Step: 9
Training loss: 2.995227832821372
Validation loss: 2.9550569500725787

Epoch: 6| Step: 10
Training loss: 3.798985024475159
Validation loss: 2.9533403236395137

Epoch: 6| Step: 11
Training loss: 3.3025915835761035
Validation loss: 2.9475452399702693

Epoch: 6| Step: 12
Training loss: 2.1762028667466478
Validation loss: 2.94771488243654

Epoch: 6| Step: 13
Training loss: 3.348437437341416
Validation loss: 2.9475315012967096

Epoch: 249| Step: 0
Training loss: 3.2965264158690526
Validation loss: 2.9453120769788645

Epoch: 6| Step: 1
Training loss: 2.756304882653611
Validation loss: 2.947738539171294

Epoch: 6| Step: 2
Training loss: 3.0771679624896264
Validation loss: 2.945093149296049

Epoch: 6| Step: 3
Training loss: 3.1420445816111573
Validation loss: 2.946491260498251

Epoch: 6| Step: 4
Training loss: 2.9992573136684606
Validation loss: 2.947619872656116

Epoch: 6| Step: 5
Training loss: 3.472985508417046
Validation loss: 2.9466222337798893

Epoch: 6| Step: 6
Training loss: 3.4659949006374946
Validation loss: 2.946889426070224

Epoch: 6| Step: 7
Training loss: 2.9766653448645153
Validation loss: 2.945516681554367

Epoch: 6| Step: 8
Training loss: 2.8012711058012614
Validation loss: 2.9461354953055534

Epoch: 6| Step: 9
Training loss: 3.6043452106565774
Validation loss: 2.9479857689984326

Epoch: 6| Step: 10
Training loss: 3.3884634695911093
Validation loss: 2.946232127041541

Epoch: 6| Step: 11
Training loss: 3.7209025332063046
Validation loss: 2.948730075344269

Epoch: 6| Step: 12
Training loss: 3.6007978244035033
Validation loss: 2.9476221835343135

Epoch: 6| Step: 13
Training loss: 2.040871354986335
Validation loss: 2.9488038103982053

Epoch: 250| Step: 0
Training loss: 2.875453581481602
Validation loss: 2.948150471276866

Epoch: 6| Step: 1
Training loss: 3.564517604296937
Validation loss: 2.9492471538333938

Epoch: 6| Step: 2
Training loss: 2.935213213426985
Validation loss: 2.951165220860479

Epoch: 6| Step: 3
Training loss: 2.9203430076217978
Validation loss: 2.9490761808072827

Epoch: 6| Step: 4
Training loss: 3.1318837451527246
Validation loss: 2.9465909857277195

Epoch: 6| Step: 5
Training loss: 2.7262747976232626
Validation loss: 2.9470154257785124

Epoch: 6| Step: 6
Training loss: 3.677961264492919
Validation loss: 2.9524367672541603

Epoch: 6| Step: 7
Training loss: 2.7799106759190786
Validation loss: 2.948903379180631

Epoch: 6| Step: 8
Training loss: 3.601943519280788
Validation loss: 2.948968210534615

Epoch: 6| Step: 9
Training loss: 3.302923791508028
Validation loss: 2.9456481455107695

Epoch: 6| Step: 10
Training loss: 3.3002988564384714
Validation loss: 2.9466833995168975

Epoch: 6| Step: 11
Training loss: 3.293025223325804
Validation loss: 2.947440499667278

Epoch: 6| Step: 12
Training loss: 3.6942572024388065
Validation loss: 2.9519213808266813

Epoch: 6| Step: 13
Training loss: 3.036455855633012
Validation loss: 2.947606221304065

Testing loss: 3.1444929690561523
