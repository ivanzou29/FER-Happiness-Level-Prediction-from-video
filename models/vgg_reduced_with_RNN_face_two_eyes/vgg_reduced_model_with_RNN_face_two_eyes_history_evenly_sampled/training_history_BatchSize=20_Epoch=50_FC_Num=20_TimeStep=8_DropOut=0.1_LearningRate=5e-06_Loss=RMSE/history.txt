Epoch: 1| Step: 0
Training loss: 4.903648123906905
Validation loss: 5.783437277089798

Epoch: 5| Step: 1
Training loss: 5.781827330759268
Validation loss: 5.77929271234615

Epoch: 5| Step: 2
Training loss: 7.29996165435335
Validation loss: 5.775557667431414

Epoch: 5| Step: 3
Training loss: 5.526104964152337
Validation loss: 5.771907515250766

Epoch: 5| Step: 4
Training loss: 5.2289413261747475
Validation loss: 5.768602107429875

Epoch: 5| Step: 5
Training loss: 7.146034912587807
Validation loss: 5.765422049242279

Epoch: 5| Step: 6
Training loss: 6.235275930066949
Validation loss: 5.762347807362692

Epoch: 5| Step: 7
Training loss: 5.534082064853855
Validation loss: 5.759274775113225

Epoch: 5| Step: 8
Training loss: 5.011741013748775
Validation loss: 5.75614708693584

Epoch: 5| Step: 9
Training loss: 5.600636255359185
Validation loss: 5.752623595729288

Epoch: 5| Step: 10
Training loss: 4.792722812302669
Validation loss: 5.749459439656918

Epoch: 2| Step: 0
Training loss: 5.836824117410759
Validation loss: 5.746099028887429

Epoch: 5| Step: 1
Training loss: 5.32105777578777
Validation loss: 5.742154549582354

Epoch: 5| Step: 2
Training loss: 6.763510851660352
Validation loss: 5.738496345337463

Epoch: 5| Step: 3
Training loss: 5.602780857357469
Validation loss: 5.734540043439884

Epoch: 5| Step: 4
Training loss: 5.989157416638779
Validation loss: 5.730539419731303

Epoch: 5| Step: 5
Training loss: 5.5922641592215285
Validation loss: 5.726127799729738

Epoch: 5| Step: 6
Training loss: 4.289873112578213
Validation loss: 5.721565488191447

Epoch: 5| Step: 7
Training loss: 6.624374072178029
Validation loss: 5.717288037454681

Epoch: 5| Step: 8
Training loss: 5.999704671585113
Validation loss: 5.7118385761904555

Epoch: 5| Step: 9
Training loss: 6.061649223486439
Validation loss: 5.706632507009414

Epoch: 5| Step: 10
Training loss: 4.679544029520264
Validation loss: 5.701132597171071

Epoch: 3| Step: 0
Training loss: 6.063984797234715
Validation loss: 5.695390501885989

Epoch: 5| Step: 1
Training loss: 6.777056403760843
Validation loss: 5.689518251864393

Epoch: 5| Step: 2
Training loss: 6.065487469662179
Validation loss: 5.683271160921788

Epoch: 5| Step: 3
Training loss: 6.9510105304048295
Validation loss: 5.676578565745359

Epoch: 5| Step: 4
Training loss: 4.917225994472177
Validation loss: 5.669728432175656

Epoch: 5| Step: 5
Training loss: 5.166377992666656
Validation loss: 5.661916016619346

Epoch: 5| Step: 6
Training loss: 5.738980224086085
Validation loss: 5.654860716653518

Epoch: 5| Step: 7
Training loss: 5.734944411443214
Validation loss: 5.646669283322421

Epoch: 5| Step: 8
Training loss: 5.251777529662632
Validation loss: 5.637746310466534

Epoch: 5| Step: 9
Training loss: 4.976767351614372
Validation loss: 5.629803226314936

Epoch: 5| Step: 10
Training loss: 4.315595096647507
Validation loss: 5.6207496107698764

Epoch: 4| Step: 0
Training loss: 5.342675173453202
Validation loss: 5.611926492514693

Epoch: 5| Step: 1
Training loss: 5.422221675640002
Validation loss: 5.602112205909123

Epoch: 5| Step: 2
Training loss: 6.071632663918858
Validation loss: 5.592199168672593

Epoch: 5| Step: 3
Training loss: 6.110677985053027
Validation loss: 5.581818267470652

Epoch: 5| Step: 4
Training loss: 5.5514995370607165
Validation loss: 5.571302267930725

Epoch: 5| Step: 5
Training loss: 6.3086956382058546
Validation loss: 5.559500309116062

Epoch: 5| Step: 6
Training loss: 4.790007505789274
Validation loss: 5.547044477887939

Epoch: 5| Step: 7
Training loss: 6.209387397465763
Validation loss: 5.534338472912287

Epoch: 5| Step: 8
Training loss: 4.867606792483393
Validation loss: 5.521250387433657

Epoch: 5| Step: 9
Training loss: 4.595243250206071
Validation loss: 5.508454664303748

Epoch: 5| Step: 10
Training loss: 6.042219395401657
Validation loss: 5.496524590911887

Epoch: 5| Step: 0
Training loss: 5.699980404468784
Validation loss: 5.48162925825205

Epoch: 5| Step: 1
Training loss: 6.143563613315126
Validation loss: 5.466886840896476

Epoch: 5| Step: 2
Training loss: 5.127042409936846
Validation loss: 5.451071890077474

Epoch: 5| Step: 3
Training loss: 5.14206404095849
Validation loss: 5.435588730374234

Epoch: 5| Step: 4
Training loss: 4.014889898441356
Validation loss: 5.419780939012677

Epoch: 5| Step: 5
Training loss: 5.91776698810356
Validation loss: 5.403179847816914

Epoch: 5| Step: 6
Training loss: 5.848004918734339
Validation loss: 5.387459856859309

Epoch: 5| Step: 7
Training loss: 5.078444626359339
Validation loss: 5.368663856514037

Epoch: 5| Step: 8
Training loss: 5.7141294730488585
Validation loss: 5.350848989254787

Epoch: 5| Step: 9
Training loss: 5.081293144840564
Validation loss: 5.331118421139386

Epoch: 5| Step: 10
Training loss: 5.861071043595715
Validation loss: 5.31319595594307

Epoch: 6| Step: 0
Training loss: 6.049036551442188
Validation loss: 5.293344699455521

Epoch: 5| Step: 1
Training loss: 4.653778034446474
Validation loss: 5.272864890600295

Epoch: 5| Step: 2
Training loss: 6.097874267903381
Validation loss: 5.252900222480853

Epoch: 5| Step: 3
Training loss: 5.7102013568816306
Validation loss: 5.231172859324019

Epoch: 5| Step: 4
Training loss: 5.573025464098143
Validation loss: 5.2092818107414125

Epoch: 5| Step: 5
Training loss: 3.6791413827259905
Validation loss: 5.1884082444367845

Epoch: 5| Step: 6
Training loss: 4.648179196145254
Validation loss: 5.166010799452616

Epoch: 5| Step: 7
Training loss: 4.532689990413456
Validation loss: 5.144530181594381

Epoch: 5| Step: 8
Training loss: 5.254415562558098
Validation loss: 5.122635618868353

Epoch: 5| Step: 9
Training loss: 5.701296327649864
Validation loss: 5.100161000444428

Epoch: 5| Step: 10
Training loss: 5.257050820397979
Validation loss: 5.077168983349245

Epoch: 7| Step: 0
Training loss: 5.411514981964331
Validation loss: 5.0574817768956155

Epoch: 5| Step: 1
Training loss: 4.967954559953787
Validation loss: 5.034284296939422

Epoch: 5| Step: 2
Training loss: 5.603276159542092
Validation loss: 5.012988165908913

Epoch: 5| Step: 3
Training loss: 3.631445711675743
Validation loss: 4.991502684732411

Epoch: 5| Step: 4
Training loss: 4.747523816828877
Validation loss: 4.971561077580834

Epoch: 5| Step: 5
Training loss: 5.268530160247588
Validation loss: 4.950879879359405

Epoch: 5| Step: 6
Training loss: 6.054313874560784
Validation loss: 4.931643563107956

Epoch: 5| Step: 7
Training loss: 5.281840455043043
Validation loss: 4.9124259089170375

Epoch: 5| Step: 8
Training loss: 5.39151993109164
Validation loss: 4.894490277932567

Epoch: 5| Step: 9
Training loss: 4.456775761602661
Validation loss: 4.8727861336018

Epoch: 5| Step: 10
Training loss: 3.6460101856752747
Validation loss: 4.855194605448108

Epoch: 8| Step: 0
Training loss: 4.809597973429341
Validation loss: 4.835168758746087

Epoch: 5| Step: 1
Training loss: 5.896583680121879
Validation loss: 4.816753827374559

Epoch: 5| Step: 2
Training loss: 4.714603041830883
Validation loss: 4.798167575727639

Epoch: 5| Step: 3
Training loss: 4.870846470580429
Validation loss: 4.7774829548574145

Epoch: 5| Step: 4
Training loss: 3.4234729676213567
Validation loss: 4.760703268080852

Epoch: 5| Step: 5
Training loss: 5.204931546951148
Validation loss: 4.741698395597155

Epoch: 5| Step: 6
Training loss: 4.31707410521942
Validation loss: 4.725811694386339

Epoch: 5| Step: 7
Training loss: 5.229276354527135
Validation loss: 4.708433498471793

Epoch: 5| Step: 8
Training loss: 4.667122046640969
Validation loss: 4.689012487177267

Epoch: 5| Step: 9
Training loss: 4.318388967701634
Validation loss: 4.669461467444348

Epoch: 5| Step: 10
Training loss: 5.265785826086258
Validation loss: 4.652523007389528

Epoch: 9| Step: 0
Training loss: 4.735443296859697
Validation loss: 4.636609750062194

Epoch: 5| Step: 1
Training loss: 4.56372283852236
Validation loss: 4.621014335211446

Epoch: 5| Step: 2
Training loss: 4.804159889095099
Validation loss: 4.607170602067191

Epoch: 5| Step: 3
Training loss: 4.13677523162869
Validation loss: 4.593943282857729

Epoch: 5| Step: 4
Training loss: 4.744599735915848
Validation loss: 4.581531111413388

Epoch: 5| Step: 5
Training loss: 4.47899153019555
Validation loss: 4.569949799575611

Epoch: 5| Step: 6
Training loss: 4.564000758165168
Validation loss: 4.556758619879574

Epoch: 5| Step: 7
Training loss: 5.371227626172456
Validation loss: 4.545195245254619

Epoch: 5| Step: 8
Training loss: 3.8235473666913076
Validation loss: 4.5358929172298925

Epoch: 5| Step: 9
Training loss: 4.74232867312004
Validation loss: 4.523802975271986

Epoch: 5| Step: 10
Training loss: 5.234819900052563
Validation loss: 4.511201353130457

Epoch: 10| Step: 0
Training loss: 4.663010981891028
Validation loss: 4.500570226930585

Epoch: 5| Step: 1
Training loss: 5.031750198046599
Validation loss: 4.489781398195321

Epoch: 5| Step: 2
Training loss: 4.727748551796992
Validation loss: 4.477948449757569

Epoch: 5| Step: 3
Training loss: 4.132019082186896
Validation loss: 4.467361682584843

Epoch: 5| Step: 4
Training loss: 4.551943546246787
Validation loss: 4.456061989407757

Epoch: 5| Step: 5
Training loss: 4.273816414445614
Validation loss: 4.446267012879092

Epoch: 5| Step: 6
Training loss: 4.175698574807153
Validation loss: 4.434994156577851

Epoch: 5| Step: 7
Training loss: 4.250249069993713
Validation loss: 4.426007265865521

Epoch: 5| Step: 8
Training loss: 4.967822102210282
Validation loss: 4.415928214515916

Epoch: 5| Step: 9
Training loss: 3.9432536881423
Validation loss: 4.407421893240997

Epoch: 5| Step: 10
Training loss: 5.318965612539522
Validation loss: 4.397841383267224

Epoch: 11| Step: 0
Training loss: 4.707476557644391
Validation loss: 4.391405843311437

Epoch: 5| Step: 1
Training loss: 4.539135195335473
Validation loss: 4.379723611458113

Epoch: 5| Step: 2
Training loss: 4.417434673592693
Validation loss: 4.370399031701446

Epoch: 5| Step: 3
Training loss: 4.046319518389207
Validation loss: 4.360839242644978

Epoch: 5| Step: 4
Training loss: 3.598538732657606
Validation loss: 4.353849968351653

Epoch: 5| Step: 5
Training loss: 4.23761560513052
Validation loss: 4.342941003458043

Epoch: 5| Step: 6
Training loss: 5.12735303499845
Validation loss: 4.331912004421953

Epoch: 5| Step: 7
Training loss: 5.106182629293744
Validation loss: 4.3223033582149855

Epoch: 5| Step: 8
Training loss: 3.596887694865874
Validation loss: 4.308971950376741

Epoch: 5| Step: 9
Training loss: 4.276036115759694
Validation loss: 4.299343278286178

Epoch: 5| Step: 10
Training loss: 5.139306360190216
Validation loss: 4.2884295750230805

Epoch: 12| Step: 0
Training loss: 4.915239784391146
Validation loss: 4.276142047788355

Epoch: 5| Step: 1
Training loss: 4.202718381818487
Validation loss: 4.262316231005998

Epoch: 5| Step: 2
Training loss: 3.5348187533131616
Validation loss: 4.254055260026147

Epoch: 5| Step: 3
Training loss: 3.9372200033755376
Validation loss: 4.2416355116359385

Epoch: 5| Step: 4
Training loss: 4.301328702171688
Validation loss: 4.2347201495135245

Epoch: 5| Step: 5
Training loss: 4.383427160344283
Validation loss: 4.223770767226558

Epoch: 5| Step: 6
Training loss: 4.58892444250965
Validation loss: 4.216033812245391

Epoch: 5| Step: 7
Training loss: 4.42582369966679
Validation loss: 4.20646988118271

Epoch: 5| Step: 8
Training loss: 4.107154391254792
Validation loss: 4.19917400590964

Epoch: 5| Step: 9
Training loss: 4.7463957513869595
Validation loss: 4.192598219948907

Epoch: 5| Step: 10
Training loss: 4.609634650724413
Validation loss: 4.185358902379528

Epoch: 13| Step: 0
Training loss: 4.025079543944816
Validation loss: 4.177500501452619

Epoch: 5| Step: 1
Training loss: 3.86159893006665
Validation loss: 4.170719351835838

Epoch: 5| Step: 2
Training loss: 3.8997824877213456
Validation loss: 4.163050808256232

Epoch: 5| Step: 3
Training loss: 5.016648993138879
Validation loss: 4.156389595405759

Epoch: 5| Step: 4
Training loss: 4.494786527357409
Validation loss: 4.1486946386081405

Epoch: 5| Step: 5
Training loss: 4.337751899022763
Validation loss: 4.140825002014963

Epoch: 5| Step: 6
Training loss: 4.449123364800077
Validation loss: 4.136302167661859

Epoch: 5| Step: 7
Training loss: 4.438655434205119
Validation loss: 4.130613294474843

Epoch: 5| Step: 8
Training loss: 3.5727722909894104
Validation loss: 4.1237510500730385

Epoch: 5| Step: 9
Training loss: 4.192253944305488
Validation loss: 4.116999422590685

Epoch: 5| Step: 10
Training loss: 4.660058633656471
Validation loss: 4.110820789020963

Epoch: 14| Step: 0
Training loss: 3.5143050364938966
Validation loss: 4.102834121773735

Epoch: 5| Step: 1
Training loss: 4.640131965931021
Validation loss: 4.098856774431911

Epoch: 5| Step: 2
Training loss: 3.1257965598557367
Validation loss: 4.09244197641581

Epoch: 5| Step: 3
Training loss: 3.648683854144214
Validation loss: 4.088922784004803

Epoch: 5| Step: 4
Training loss: 4.002339155978966
Validation loss: 4.081410795257644

Epoch: 5| Step: 5
Training loss: 4.521853681934567
Validation loss: 4.077209484303293

Epoch: 5| Step: 6
Training loss: 4.376497067034181
Validation loss: 4.072354381152072

Epoch: 5| Step: 7
Training loss: 4.801069283593931
Validation loss: 4.0686358362532715

Epoch: 5| Step: 8
Training loss: 5.295411934683023
Validation loss: 4.063082170067309

Epoch: 5| Step: 9
Training loss: 3.7027621192025513
Validation loss: 4.056825017059372

Epoch: 5| Step: 10
Training loss: 4.300790785000216
Validation loss: 4.052157500399384

Epoch: 15| Step: 0
Training loss: 4.089542935301907
Validation loss: 4.044917387747507

Epoch: 5| Step: 1
Training loss: 3.5235338557362454
Validation loss: 4.041506596752939

Epoch: 5| Step: 2
Training loss: 4.3076522780748805
Validation loss: 4.036565856242475

Epoch: 5| Step: 3
Training loss: 4.389793453006485
Validation loss: 4.032326409201647

Epoch: 5| Step: 4
Training loss: 3.4248204205067054
Validation loss: 4.026274520486034

Epoch: 5| Step: 5
Training loss: 3.718326704793642
Validation loss: 4.021927473594399

Epoch: 5| Step: 6
Training loss: 4.340234225584441
Validation loss: 4.017638060571626

Epoch: 5| Step: 7
Training loss: 4.740546406023374
Validation loss: 4.014032401043252

Epoch: 5| Step: 8
Training loss: 4.2766761572344265
Validation loss: 4.009652852436472

Epoch: 5| Step: 9
Training loss: 4.718559614976575
Validation loss: 4.003901794895322

Epoch: 5| Step: 10
Training loss: 4.1173162856399665
Validation loss: 4.000751576007814

Epoch: 16| Step: 0
Training loss: 4.589874916782481
Validation loss: 3.9949844407319666

Epoch: 5| Step: 1
Training loss: 4.414605193408792
Validation loss: 3.989078576011162

Epoch: 5| Step: 2
Training loss: 4.385551806955341
Validation loss: 3.984900198449057

Epoch: 5| Step: 3
Training loss: 4.280555390304264
Validation loss: 3.978412327099557

Epoch: 5| Step: 4
Training loss: 4.016066471279254
Validation loss: 3.9747757852380725

Epoch: 5| Step: 5
Training loss: 4.407728014937186
Validation loss: 3.9693331126564915

Epoch: 5| Step: 6
Training loss: 4.370821019613826
Validation loss: 3.9624230820377715

Epoch: 5| Step: 7
Training loss: 3.1438469752376528
Validation loss: 3.9569106614716683

Epoch: 5| Step: 8
Training loss: 3.3049483681020364
Validation loss: 3.9521638511695403

Epoch: 5| Step: 9
Training loss: 4.325084072464571
Validation loss: 3.943854760805635

Epoch: 5| Step: 10
Training loss: 3.8155066719421753
Validation loss: 3.9361978940883113

Epoch: 17| Step: 0
Training loss: 3.6973232742385505
Validation loss: 3.9280805529600307

Epoch: 5| Step: 1
Training loss: 4.455784910095982
Validation loss: 3.920549007163358

Epoch: 5| Step: 2
Training loss: 4.248595286080709
Validation loss: 3.913274268954553

Epoch: 5| Step: 3
Training loss: 4.152678597299664
Validation loss: 3.904140541079514

Epoch: 5| Step: 4
Training loss: 4.307542909661969
Validation loss: 3.8951350115904857

Epoch: 5| Step: 5
Training loss: 4.02717846032658
Validation loss: 3.8863621988928587

Epoch: 5| Step: 6
Training loss: 3.343896737845172
Validation loss: 3.8777299963854746

Epoch: 5| Step: 7
Training loss: 4.3523914910407795
Validation loss: 3.86788584035646

Epoch: 5| Step: 8
Training loss: 4.215458242682613
Validation loss: 3.8579282054422865

Epoch: 5| Step: 9
Training loss: 4.217223845046468
Validation loss: 3.850834970208111

Epoch: 5| Step: 10
Training loss: 3.2083478819942473
Validation loss: 3.84382812863461

Epoch: 18| Step: 0
Training loss: 4.446033707560005
Validation loss: 3.8408153398291787

Epoch: 5| Step: 1
Training loss: 3.8723989801793843
Validation loss: 3.8314777223818046

Epoch: 5| Step: 2
Training loss: 4.309423040021275
Validation loss: 3.828461446034432

Epoch: 5| Step: 3
Training loss: 4.176382765522144
Validation loss: 3.8229781944409216

Epoch: 5| Step: 4
Training loss: 4.04146517746221
Validation loss: 3.816926879079961

Epoch: 5| Step: 5
Training loss: 4.395178120793397
Validation loss: 3.814973300244809

Epoch: 5| Step: 6
Training loss: 4.398065852832311
Validation loss: 3.810190906581638

Epoch: 5| Step: 7
Training loss: 3.5783840568748477
Validation loss: 3.8057047379035738

Epoch: 5| Step: 8
Training loss: 3.7255937448722256
Validation loss: 3.8024721538771122

Epoch: 5| Step: 9
Training loss: 2.761345780154692
Validation loss: 3.798109627525864

Epoch: 5| Step: 10
Training loss: 3.812853562267043
Validation loss: 3.7950610671509417

Epoch: 19| Step: 0
Training loss: 4.399274783623566
Validation loss: 3.7861922436163855

Epoch: 5| Step: 1
Training loss: 3.328606082728849
Validation loss: 3.7833007794475306

Epoch: 5| Step: 2
Training loss: 4.076536841291662
Validation loss: 3.778721192181772

Epoch: 5| Step: 3
Training loss: 3.7434918195192597
Validation loss: 3.7743520292361805

Epoch: 5| Step: 4
Training loss: 4.715022958353727
Validation loss: 3.76883852148684

Epoch: 5| Step: 5
Training loss: 3.4105326476481395
Validation loss: 3.7631043095709167

Epoch: 5| Step: 6
Training loss: 3.237971421019624
Validation loss: 3.759934638381892

Epoch: 5| Step: 7
Training loss: 3.7477922934562606
Validation loss: 3.7547272573199475

Epoch: 5| Step: 8
Training loss: 3.7883079800062975
Validation loss: 3.75129931783946

Epoch: 5| Step: 9
Training loss: 4.749700838004127
Validation loss: 3.748350960813582

Epoch: 5| Step: 10
Training loss: 3.785247959092826
Validation loss: 3.7427175080029915

Epoch: 20| Step: 0
Training loss: 4.1644818236189876
Validation loss: 3.739693682909397

Epoch: 5| Step: 1
Training loss: 3.159705206484036
Validation loss: 3.7362301307078845

Epoch: 5| Step: 2
Training loss: 4.550116887529984
Validation loss: 3.7348907481147577

Epoch: 5| Step: 3
Training loss: 4.116301642127842
Validation loss: 3.729196525083428

Epoch: 5| Step: 4
Training loss: 2.7789010404720815
Validation loss: 3.724744094478925

Epoch: 5| Step: 5
Training loss: 3.511025637244853
Validation loss: 3.722967764249116

Epoch: 5| Step: 6
Training loss: 3.534647159907753
Validation loss: 3.717509446693482

Epoch: 5| Step: 7
Training loss: 3.1996011843114855
Validation loss: 3.7150490898802317

Epoch: 5| Step: 8
Training loss: 4.302683174981916
Validation loss: 3.709003402235292

Epoch: 5| Step: 9
Training loss: 3.9941385954686166
Validation loss: 3.70860684653472

Epoch: 5| Step: 10
Training loss: 5.207166047580038
Validation loss: 3.7044706553296796

Epoch: 21| Step: 0
Training loss: 4.128557693941329
Validation loss: 3.702611122321395

Epoch: 5| Step: 1
Training loss: 3.7791635100419145
Validation loss: 3.700243932869487

Epoch: 5| Step: 2
Training loss: 4.3832422273593385
Validation loss: 3.6995230740134644

Epoch: 5| Step: 3
Training loss: 3.824026973852686
Validation loss: 3.6944180336342627

Epoch: 5| Step: 4
Training loss: 3.0348228556234793
Validation loss: 3.6913759507142823

Epoch: 5| Step: 5
Training loss: 4.0886762787188475
Validation loss: 3.6857819960221705

Epoch: 5| Step: 6
Training loss: 3.8276865182550215
Validation loss: 3.6826580260049795

Epoch: 5| Step: 7
Training loss: 3.4474906696638694
Validation loss: 3.6813474106066346

Epoch: 5| Step: 8
Training loss: 4.608674180369628
Validation loss: 3.6779665632931704

Epoch: 5| Step: 9
Training loss: 3.9912292166436694
Validation loss: 3.675422272130434

Epoch: 5| Step: 10
Training loss: 3.07825047580948
Validation loss: 3.6726917469471143

Epoch: 22| Step: 0
Training loss: 3.9911236026580705
Validation loss: 3.6682872411815635

Epoch: 5| Step: 1
Training loss: 4.484917052999982
Validation loss: 3.665476220283458

Epoch: 5| Step: 2
Training loss: 3.5706193988207917
Validation loss: 3.6639756137449955

Epoch: 5| Step: 3
Training loss: 4.492536076829136
Validation loss: 3.6597794027210355

Epoch: 5| Step: 4
Training loss: 3.2650579662931554
Validation loss: 3.65856922581463

Epoch: 5| Step: 5
Training loss: 3.9671471430321024
Validation loss: 3.6555623208093997

Epoch: 5| Step: 6
Training loss: 3.568936873852758
Validation loss: 3.652799244400177

Epoch: 5| Step: 7
Training loss: 4.178777007284706
Validation loss: 3.65215826383362

Epoch: 5| Step: 8
Training loss: 4.351306955720361
Validation loss: 3.649968938825991

Epoch: 5| Step: 9
Training loss: 2.820260847892015
Validation loss: 3.646142305328715

Epoch: 5| Step: 10
Training loss: 3.082339891419795
Validation loss: 3.643040477125932

Epoch: 23| Step: 0
Training loss: 3.626484139584874
Validation loss: 3.640292565881204

Epoch: 5| Step: 1
Training loss: 3.864932487460731
Validation loss: 3.638993839091753

Epoch: 5| Step: 2
Training loss: 3.9593955505367675
Validation loss: 3.6359938282573485

Epoch: 5| Step: 3
Training loss: 3.885801949033092
Validation loss: 3.635963983810056

Epoch: 5| Step: 4
Training loss: 3.2234561921473155
Validation loss: 3.6320937228146364

Epoch: 5| Step: 5
Training loss: 3.9134711087185012
Validation loss: 3.631756776421798

Epoch: 5| Step: 6
Training loss: 4.87175368769094
Validation loss: 3.627647517957259

Epoch: 5| Step: 7
Training loss: 3.182676967306399
Validation loss: 3.62493020323934

Epoch: 5| Step: 8
Training loss: 4.341102287136622
Validation loss: 3.623482301231985

Epoch: 5| Step: 9
Training loss: 3.716511413228239
Validation loss: 3.6212410792476497

Epoch: 5| Step: 10
Training loss: 2.993197835759705
Validation loss: 3.617881761962993

Epoch: 24| Step: 0
Training loss: 4.436896914481598
Validation loss: 3.617259453268456

Epoch: 5| Step: 1
Training loss: 4.338467466430443
Validation loss: 3.6161017336825863

Epoch: 5| Step: 2
Training loss: 3.4968105497719053
Validation loss: 3.6107922144748374

Epoch: 5| Step: 3
Training loss: 3.507653995322703
Validation loss: 3.6117606143445555

Epoch: 5| Step: 4
Training loss: 3.1961776196486285
Validation loss: 3.607522592208388

Epoch: 5| Step: 5
Training loss: 3.318013047977336
Validation loss: 3.60618581600458

Epoch: 5| Step: 6
Training loss: 4.164708300355594
Validation loss: 3.604659632487829

Epoch: 5| Step: 7
Training loss: 4.328721208512439
Validation loss: 3.6035457780231583

Epoch: 5| Step: 8
Training loss: 3.1326029034371015
Validation loss: 3.5976847918193293

Epoch: 5| Step: 9
Training loss: 3.823176583887979
Validation loss: 3.596837919709852

Epoch: 5| Step: 10
Training loss: 3.781531457435495
Validation loss: 3.5942524305959878

Epoch: 25| Step: 0
Training loss: 4.041187664368912
Validation loss: 3.594928472971361

Epoch: 5| Step: 1
Training loss: 3.7274779149097768
Validation loss: 3.5957052553638493

Epoch: 5| Step: 2
Training loss: 3.0903031385050244
Validation loss: 3.5935001452291897

Epoch: 5| Step: 3
Training loss: 3.897750885763258
Validation loss: 3.5907014447527135

Epoch: 5| Step: 4
Training loss: 4.55156913780412
Validation loss: 3.5910715816207532

Epoch: 5| Step: 5
Training loss: 3.7413369886670935
Validation loss: 3.5840500264887147

Epoch: 5| Step: 6
Training loss: 3.058398711902887
Validation loss: 3.582524842050041

Epoch: 5| Step: 7
Training loss: 3.87225798528482
Validation loss: 3.5826139984840384

Epoch: 5| Step: 8
Training loss: 3.4224128474639537
Validation loss: 3.5781247019459776

Epoch: 5| Step: 9
Training loss: 4.066407657150333
Validation loss: 3.576004333455111

Epoch: 5| Step: 10
Training loss: 3.9449803580797163
Validation loss: 3.575509758089886

Epoch: 26| Step: 0
Training loss: 4.238358429236798
Validation loss: 3.5731097284944293

Epoch: 5| Step: 1
Training loss: 2.8719848080501573
Validation loss: 3.574551542691937

Epoch: 5| Step: 2
Training loss: 3.6360051390188763
Validation loss: 3.581013934523585

Epoch: 5| Step: 3
Training loss: 3.4391433948949284
Validation loss: 3.563565112079382

Epoch: 5| Step: 4
Training loss: 3.8514313897959
Validation loss: 3.565039276103211

Epoch: 5| Step: 5
Training loss: 3.8156301437455733
Validation loss: 3.5635774800401

Epoch: 5| Step: 6
Training loss: 3.84492412715506
Validation loss: 3.5612257351802703

Epoch: 5| Step: 7
Training loss: 4.532871140498832
Validation loss: 3.5597315885099383

Epoch: 5| Step: 8
Training loss: 3.7010891625817233
Validation loss: 3.5570995500119125

Epoch: 5| Step: 9
Training loss: 3.912183603771886
Validation loss: 3.554390309903475

Epoch: 5| Step: 10
Training loss: 3.2635259133372796
Validation loss: 3.560199853502884

Epoch: 27| Step: 0
Training loss: 3.3614072818069176
Validation loss: 3.5551416798619435

Epoch: 5| Step: 1
Training loss: 2.910192952788687
Validation loss: 3.552224949086391

Epoch: 5| Step: 2
Training loss: 3.1536511589948235
Validation loss: 3.5481245463480953

Epoch: 5| Step: 3
Training loss: 3.5615792674109836
Validation loss: 3.544317279792924

Epoch: 5| Step: 4
Training loss: 3.7548386192945498
Validation loss: 3.5471888498139084

Epoch: 5| Step: 5
Training loss: 4.407450843748967
Validation loss: 3.542616602534792

Epoch: 5| Step: 6
Training loss: 4.347803433815365
Validation loss: 3.5427841672266327

Epoch: 5| Step: 7
Training loss: 2.7004864113262204
Validation loss: 3.539256816497702

Epoch: 5| Step: 8
Training loss: 4.623770473050232
Validation loss: 3.535842280521652

Epoch: 5| Step: 9
Training loss: 3.9756094459357763
Validation loss: 3.5361726443609554

Epoch: 5| Step: 10
Training loss: 3.9497103814289938
Validation loss: 3.5342399824306505

Epoch: 28| Step: 0
Training loss: 3.88284713146339
Validation loss: 3.5367389981812654

Epoch: 5| Step: 1
Training loss: 3.392688457339827
Validation loss: 3.535893020900059

Epoch: 5| Step: 2
Training loss: 4.461141444686769
Validation loss: 3.5318869770288503

Epoch: 5| Step: 3
Training loss: 3.70248909814068
Validation loss: 3.530965114219961

Epoch: 5| Step: 4
Training loss: 4.45007112424782
Validation loss: 3.5306725174565075

Epoch: 5| Step: 5
Training loss: 3.1980675942325347
Validation loss: 3.52619663542097

Epoch: 5| Step: 6
Training loss: 3.7300471681777774
Validation loss: 3.5246630467812192

Epoch: 5| Step: 7
Training loss: 3.96764712891961
Validation loss: 3.5247892160666665

Epoch: 5| Step: 8
Training loss: 4.124286474303057
Validation loss: 3.52111633866244

Epoch: 5| Step: 9
Training loss: 2.801691096386744
Validation loss: 3.5209333975103014

Epoch: 5| Step: 10
Training loss: 2.8114243039736775
Validation loss: 3.5184833882927693

Epoch: 29| Step: 0
Training loss: 4.320002125633565
Validation loss: 3.5215255649992736

Epoch: 5| Step: 1
Training loss: 4.179250990275851
Validation loss: 3.5186223699900805

Epoch: 5| Step: 2
Training loss: 3.137535587428122
Validation loss: 3.5142936316720856

Epoch: 5| Step: 3
Training loss: 3.0969546895788125
Validation loss: 3.5145055245034755

Epoch: 5| Step: 4
Training loss: 4.449792732812421
Validation loss: 3.511809054326466

Epoch: 5| Step: 5
Training loss: 3.9217413769333733
Validation loss: 3.5078703906159774

Epoch: 5| Step: 6
Training loss: 3.5052570643823464
Validation loss: 3.508613638733212

Epoch: 5| Step: 7
Training loss: 3.3060086542605873
Validation loss: 3.503071942809954

Epoch: 5| Step: 8
Training loss: 3.636977173241427
Validation loss: 3.503626496012208

Epoch: 5| Step: 9
Training loss: 3.6825182609856366
Validation loss: 3.503035904563839

Epoch: 5| Step: 10
Training loss: 3.3463013799439882
Validation loss: 3.502701275067142

Epoch: 30| Step: 0
Training loss: 3.1950501425185815
Validation loss: 3.500173409146391

Epoch: 5| Step: 1
Training loss: 3.945688241119153
Validation loss: 3.500190120285604

Epoch: 5| Step: 2
Training loss: 3.300997791297634
Validation loss: 3.4974143326068603

Epoch: 5| Step: 3
Training loss: 3.8283332612354988
Validation loss: 3.498685658859393

Epoch: 5| Step: 4
Training loss: 3.568775472199348
Validation loss: 3.5011208932392663

Epoch: 5| Step: 5
Training loss: 3.9336587243268393
Validation loss: 3.5022893792624474

Epoch: 5| Step: 6
Training loss: 3.855592673492832
Validation loss: 3.495152680999589

Epoch: 5| Step: 7
Training loss: 3.3817297632138277
Validation loss: 3.4915199020648

Epoch: 5| Step: 8
Training loss: 3.57541417210303
Validation loss: 3.4955403457153125

Epoch: 5| Step: 9
Training loss: 4.073281872596475
Validation loss: 3.4928746185795925

Epoch: 5| Step: 10
Training loss: 4.051144266370103
Validation loss: 3.490826362616201

Epoch: 31| Step: 0
Training loss: 4.482989479312979
Validation loss: 3.489071130361419

Epoch: 5| Step: 1
Training loss: 2.9201828243555457
Validation loss: 3.48991219163732

Epoch: 5| Step: 2
Training loss: 3.5945091440888666
Validation loss: 3.4952683496056567

Epoch: 5| Step: 3
Training loss: 3.710516269267266
Validation loss: 3.4858775376346265

Epoch: 5| Step: 4
Training loss: 2.325481578215075
Validation loss: 3.485417341866718

Epoch: 5| Step: 5
Training loss: 4.697092033239884
Validation loss: 3.485923746257578

Epoch: 5| Step: 6
Training loss: 3.8370429347710413
Validation loss: 3.4849150717480786

Epoch: 5| Step: 7
Training loss: 3.170983400607564
Validation loss: 3.486274932954657

Epoch: 5| Step: 8
Training loss: 4.137174730682434
Validation loss: 3.4830916612971965

Epoch: 5| Step: 9
Training loss: 3.789806175006343
Validation loss: 3.4814505481046347

Epoch: 5| Step: 10
Training loss: 3.359142916447241
Validation loss: 3.4805578174816194

Epoch: 32| Step: 0
Training loss: 3.5317775366030912
Validation loss: 3.48014796384585

Epoch: 5| Step: 1
Training loss: 4.533836941701855
Validation loss: 3.4785516637565257

Epoch: 5| Step: 2
Training loss: 2.901148923652399
Validation loss: 3.4798428202217337

Epoch: 5| Step: 3
Training loss: 2.948931102745989
Validation loss: 3.4764220034784863

Epoch: 5| Step: 4
Training loss: 3.91116646169982
Validation loss: 3.4749507009072778

Epoch: 5| Step: 5
Training loss: 3.5501437144672865
Validation loss: 3.4745598388037466

Epoch: 5| Step: 6
Training loss: 3.3136675234631925
Validation loss: 3.4720763864278865

Epoch: 5| Step: 7
Training loss: 4.584904673010738
Validation loss: 3.4706445272688957

Epoch: 5| Step: 8
Training loss: 3.18114361238489
Validation loss: 3.4708078509300875

Epoch: 5| Step: 9
Training loss: 3.987102696826238
Validation loss: 3.470115696530728

Epoch: 5| Step: 10
Training loss: 3.7140823691113067
Validation loss: 3.4684119872372277

Epoch: 33| Step: 0
Training loss: 2.9751525903886327
Validation loss: 3.4691173385199066

Epoch: 5| Step: 1
Training loss: 4.216551031002222
Validation loss: 3.4673541038407123

Epoch: 5| Step: 2
Training loss: 4.1381165013458645
Validation loss: 3.4668450121127976

Epoch: 5| Step: 3
Training loss: 3.0068284840257573
Validation loss: 3.4638523009077153

Epoch: 5| Step: 4
Training loss: 4.172564160291958
Validation loss: 3.4633200509857516

Epoch: 5| Step: 5
Training loss: 3.9362862547933797
Validation loss: 3.462442633976698

Epoch: 5| Step: 6
Training loss: 3.4782448801937793
Validation loss: 3.462826570604246

Epoch: 5| Step: 7
Training loss: 3.749371030830512
Validation loss: 3.4616926215704127

Epoch: 5| Step: 8
Training loss: 3.0296681789590703
Validation loss: 3.4588536655485025

Epoch: 5| Step: 9
Training loss: 3.9985308333278162
Validation loss: 3.4591599277293907

Epoch: 5| Step: 10
Training loss: 3.443576366665069
Validation loss: 3.4587099147282485

Epoch: 34| Step: 0
Training loss: 2.853137942365224
Validation loss: 3.455582811934613

Epoch: 5| Step: 1
Training loss: 3.5097934762128817
Validation loss: 3.4557777779278043

Epoch: 5| Step: 2
Training loss: 4.206371769269059
Validation loss: 3.4528728232109116

Epoch: 5| Step: 3
Training loss: 2.908956928310662
Validation loss: 3.4532680686927995

Epoch: 5| Step: 4
Training loss: 4.39466015435943
Validation loss: 3.4557089001914996

Epoch: 5| Step: 5
Training loss: 3.5557864994969655
Validation loss: 3.4564520597552106

Epoch: 5| Step: 6
Training loss: 3.5460226908655423
Validation loss: 3.4503525812227935

Epoch: 5| Step: 7
Training loss: 4.057210912459888
Validation loss: 3.4470169992374875

Epoch: 5| Step: 8
Training loss: 3.4541635461907427
Validation loss: 3.4483010737311113

Epoch: 5| Step: 9
Training loss: 4.19313376343477
Validation loss: 3.4446867245524793

Epoch: 5| Step: 10
Training loss: 3.2861461622128543
Validation loss: 3.4465175449673495

Epoch: 35| Step: 0
Training loss: 3.6895066313450715
Validation loss: 3.4445550021810507

Epoch: 5| Step: 1
Training loss: 3.6627671284302767
Validation loss: 3.4455107525202497

Epoch: 5| Step: 2
Training loss: 3.1434336387458113
Validation loss: 3.443665238904294

Epoch: 5| Step: 3
Training loss: 3.8691992873203107
Validation loss: 3.4426829696886845

Epoch: 5| Step: 4
Training loss: 3.0721538739211662
Validation loss: 3.442859127266995

Epoch: 5| Step: 5
Training loss: 4.026632103634806
Validation loss: 3.441492708122151

Epoch: 5| Step: 6
Training loss: 3.2404865996806653
Validation loss: 3.440708766637065

Epoch: 5| Step: 7
Training loss: 3.362076777374069
Validation loss: 3.4392328483124053

Epoch: 5| Step: 8
Training loss: 3.581326580726732
Validation loss: 3.4369178286450905

Epoch: 5| Step: 9
Training loss: 4.86972347218573
Validation loss: 3.437278564420834

Epoch: 5| Step: 10
Training loss: 3.35642457078258
Validation loss: 3.435880455126981

Epoch: 36| Step: 0
Training loss: 3.2823230260482683
Validation loss: 3.4349927512185228

Epoch: 5| Step: 1
Training loss: 3.7641748192269375
Validation loss: 3.435065404253748

Epoch: 5| Step: 2
Training loss: 4.69528772027051
Validation loss: 3.433236817607123

Epoch: 5| Step: 3
Training loss: 3.5054054752740864
Validation loss: 3.4358930663266625

Epoch: 5| Step: 4
Training loss: 4.047287378693589
Validation loss: 3.4377168454622855

Epoch: 5| Step: 5
Training loss: 2.705742246995773
Validation loss: 3.434040316095259

Epoch: 5| Step: 6
Training loss: 3.333837486924219
Validation loss: 3.432893678626859

Epoch: 5| Step: 7
Training loss: 3.6580785107913254
Validation loss: 3.431785578426935

Epoch: 5| Step: 8
Training loss: 3.3473632399390443
Validation loss: 3.4307837062008595

Epoch: 5| Step: 9
Training loss: 4.179507927290272
Validation loss: 3.428783919534299

Epoch: 5| Step: 10
Training loss: 3.220665223018339
Validation loss: 3.4336072013464847

Epoch: 37| Step: 0
Training loss: 3.1028250711635694
Validation loss: 3.4316008796962696

Epoch: 5| Step: 1
Training loss: 3.8797660558508325
Validation loss: 3.4350388025009764

Epoch: 5| Step: 2
Training loss: 2.9461726948659397
Validation loss: 3.427629308332255

Epoch: 5| Step: 3
Training loss: 4.058087578969185
Validation loss: 3.4244310436550567

Epoch: 5| Step: 4
Training loss: 4.074875278553517
Validation loss: 3.425826949170699

Epoch: 5| Step: 5
Training loss: 3.01301263903155
Validation loss: 3.428859320957716

Epoch: 5| Step: 6
Training loss: 3.594729348129524
Validation loss: 3.4357039173485244

Epoch: 5| Step: 7
Training loss: 4.159433393405261
Validation loss: 3.431894822093498

Epoch: 5| Step: 8
Training loss: 3.092381029978407
Validation loss: 3.422691202546407

Epoch: 5| Step: 9
Training loss: 3.2902461660754234
Validation loss: 3.4192342397349917

Epoch: 5| Step: 10
Training loss: 4.667628575144227
Validation loss: 3.41776495288165

Epoch: 38| Step: 0
Training loss: 3.6998594669768767
Validation loss: 3.4172706060229583

Epoch: 5| Step: 1
Training loss: 4.010724472850153
Validation loss: 3.4188324231629683

Epoch: 5| Step: 2
Training loss: 2.4288589683978565
Validation loss: 3.418124861426263

Epoch: 5| Step: 3
Training loss: 2.849147829847241
Validation loss: 3.421245414206313

Epoch: 5| Step: 4
Training loss: 4.185642114962862
Validation loss: 3.4167023773688183

Epoch: 5| Step: 5
Training loss: 3.5646945819331255
Validation loss: 3.415942304126129

Epoch: 5| Step: 6
Training loss: 3.555004868644889
Validation loss: 3.4151191137969192

Epoch: 5| Step: 7
Training loss: 3.929092149779636
Validation loss: 3.412209152465634

Epoch: 5| Step: 8
Training loss: 3.902631869290537
Validation loss: 3.414940870646318

Epoch: 5| Step: 9
Training loss: 4.246297233078531
Validation loss: 3.4172420112329753

Epoch: 5| Step: 10
Training loss: 3.138959604402594
Validation loss: 3.411199495474689

Epoch: 39| Step: 0
Training loss: 4.084358916947821
Validation loss: 3.409911993124807

Epoch: 5| Step: 1
Training loss: 3.862850955956568
Validation loss: 3.4099305908497897

Epoch: 5| Step: 2
Training loss: 3.769439411526978
Validation loss: 3.407080461883255

Epoch: 5| Step: 3
Training loss: 3.699233187009843
Validation loss: 3.406641988485683

Epoch: 5| Step: 4
Training loss: 3.5068426002007858
Validation loss: 3.406947767129551

Epoch: 5| Step: 5
Training loss: 3.1487469012346274
Validation loss: 3.4058636629423336

Epoch: 5| Step: 6
Training loss: 4.0845214257119045
Validation loss: 3.4041359994572087

Epoch: 5| Step: 7
Training loss: 3.395712836688416
Validation loss: 3.405862258378063

Epoch: 5| Step: 8
Training loss: 3.78658265439266
Validation loss: 3.404266446711792

Epoch: 5| Step: 9
Training loss: 3.2122458509557488
Validation loss: 3.4043131651602234

Epoch: 5| Step: 10
Training loss: 3.210239455183856
Validation loss: 3.404523252443792

Epoch: 40| Step: 0
Training loss: 3.3919407976670124
Validation loss: 3.403635116223719

Epoch: 5| Step: 1
Training loss: 3.3537807992949147
Validation loss: 3.4048626804602447

Epoch: 5| Step: 2
Training loss: 4.028943252023704
Validation loss: 3.4030606263964542

Epoch: 5| Step: 3
Training loss: 3.4887554192441144
Validation loss: 3.401465267729191

Epoch: 5| Step: 4
Training loss: 3.6361058555612322
Validation loss: 3.4000754771459745

Epoch: 5| Step: 5
Training loss: 3.471936386211225
Validation loss: 3.3983949750296008

Epoch: 5| Step: 6
Training loss: 3.637692035443155
Validation loss: 3.3997629332730184

Epoch: 5| Step: 7
Training loss: 4.3368453441484975
Validation loss: 3.3973775513613798

Epoch: 5| Step: 8
Training loss: 3.3186440258743013
Validation loss: 3.398560775050456

Epoch: 5| Step: 9
Training loss: 3.891999151388548
Validation loss: 3.397301938694341

Epoch: 5| Step: 10
Training loss: 3.0999988678960886
Validation loss: 3.397260621994165

Epoch: 41| Step: 0
Training loss: 3.5498418960825027
Validation loss: 3.39475106973917

Epoch: 5| Step: 1
Training loss: 3.279859702436001
Validation loss: 3.3956962561305764

Epoch: 5| Step: 2
Training loss: 4.515477795164974
Validation loss: 3.3935153588558067

Epoch: 5| Step: 3
Training loss: 3.12649790150462
Validation loss: 3.391811152219639

Epoch: 5| Step: 4
Training loss: 3.3991862557431167
Validation loss: 3.3942425719547558

Epoch: 5| Step: 5
Training loss: 2.976247535521902
Validation loss: 3.394153010640322

Epoch: 5| Step: 6
Training loss: 3.552596665744369
Validation loss: 3.394156392920676

Epoch: 5| Step: 7
Training loss: 3.479279628602563
Validation loss: 3.3911125543675484

Epoch: 5| Step: 8
Training loss: 3.7720813407177753
Validation loss: 3.394425812673313

Epoch: 5| Step: 9
Training loss: 4.252607331174509
Validation loss: 3.3906720682098825

Epoch: 5| Step: 10
Training loss: 3.634676547345142
Validation loss: 3.3902961878118396

Epoch: 42| Step: 0
Training loss: 3.1250382993258525
Validation loss: 3.3885256189677397

Epoch: 5| Step: 1
Training loss: 2.5410343905436976
Validation loss: 3.3884921619753436

Epoch: 5| Step: 2
Training loss: 4.075950071828299
Validation loss: 3.3876172603386268

Epoch: 5| Step: 3
Training loss: 3.5621832991253246
Validation loss: 3.386351524496091

Epoch: 5| Step: 4
Training loss: 3.0165745322417172
Validation loss: 3.39223740355081

Epoch: 5| Step: 5
Training loss: 3.355523603033168
Validation loss: 3.390417662851159

Epoch: 5| Step: 6
Training loss: 3.9687371441490233
Validation loss: 3.390301860595246

Epoch: 5| Step: 7
Training loss: 4.216504665072264
Validation loss: 3.3866475578442743

Epoch: 5| Step: 8
Training loss: 3.502731347404457
Validation loss: 3.384635500206674

Epoch: 5| Step: 9
Training loss: 4.143953417910193
Validation loss: 3.3846614164957844

Epoch: 5| Step: 10
Training loss: 3.912473923471345
Validation loss: 3.3877713711406883

Epoch: 43| Step: 0
Training loss: 3.2592657493356505
Validation loss: 3.384602873546398

Epoch: 5| Step: 1
Training loss: 3.6917123818993463
Validation loss: 3.383632607961095

Epoch: 5| Step: 2
Training loss: 3.8441340556988375
Validation loss: 3.382223059019935

Epoch: 5| Step: 3
Training loss: 3.632522013545691
Validation loss: 3.3845460171941064

Epoch: 5| Step: 4
Training loss: 4.358103139328217
Validation loss: 3.3824235799187097

Epoch: 5| Step: 5
Training loss: 3.7160940222368555
Validation loss: 3.3814814295120517

Epoch: 5| Step: 6
Training loss: 3.8408470046189844
Validation loss: 3.380854731285402

Epoch: 5| Step: 7
Training loss: 3.3325421030027713
Validation loss: 3.3815102053997697

Epoch: 5| Step: 8
Training loss: 3.4907472102424473
Validation loss: 3.3810556404217507

Epoch: 5| Step: 9
Training loss: 3.1848913251460753
Validation loss: 3.381001284267023

Epoch: 5| Step: 10
Training loss: 3.1364631976281316
Validation loss: 3.3811667362031765

Epoch: 44| Step: 0
Training loss: 4.063061719353808
Validation loss: 3.379783200279674

Epoch: 5| Step: 1
Training loss: 3.377718642899497
Validation loss: 3.3800875967069834

Epoch: 5| Step: 2
Training loss: 3.926133355439525
Validation loss: 3.3774064424138284

Epoch: 5| Step: 3
Training loss: 4.067346821381879
Validation loss: 3.381869650614356

Epoch: 5| Step: 4
Training loss: 3.629241960680974
Validation loss: 3.380350669858425

Epoch: 5| Step: 5
Training loss: 3.014485198143567
Validation loss: 3.3799969981738998

Epoch: 5| Step: 6
Training loss: 2.9299604365050502
Validation loss: 3.3778836029266177

Epoch: 5| Step: 7
Training loss: 3.1375307241204515
Validation loss: 3.3759364428296346

Epoch: 5| Step: 8
Training loss: 4.194365836804083
Validation loss: 3.380946714167017

Epoch: 5| Step: 9
Training loss: 3.4053532531153676
Validation loss: 3.3796486221061763

Epoch: 5| Step: 10
Training loss: 3.6758004491063425
Validation loss: 3.3894074111287416

Epoch: 45| Step: 0
Training loss: 3.6908547610116447
Validation loss: 3.3861032147937564

Epoch: 5| Step: 1
Training loss: 3.5697583325650326
Validation loss: 3.3801495876099623

Epoch: 5| Step: 2
Training loss: 3.0404757079810314
Validation loss: 3.375545210042661

Epoch: 5| Step: 3
Training loss: 3.1756042205905506
Validation loss: 3.37427019351006

Epoch: 5| Step: 4
Training loss: 3.8570918074766785
Validation loss: 3.3751926557031453

Epoch: 5| Step: 5
Training loss: 3.410486509011495
Validation loss: 3.374494678096045

Epoch: 5| Step: 6
Training loss: 4.211908288708946
Validation loss: 3.3725500173794365

Epoch: 5| Step: 7
Training loss: 3.1304066997687428
Validation loss: 3.3721618880340465

Epoch: 5| Step: 8
Training loss: 3.7156226848726623
Validation loss: 3.374647232208214

Epoch: 5| Step: 9
Training loss: 3.8313545150565154
Validation loss: 3.374211219546115

Epoch: 5| Step: 10
Training loss: 3.8718509799560117
Validation loss: 3.373496131870206

Epoch: 46| Step: 0
Training loss: 3.1055204950975916
Validation loss: 3.373965771449754

Epoch: 5| Step: 1
Training loss: 3.5374280511124003
Validation loss: 3.3741716517623774

Epoch: 5| Step: 2
Training loss: 3.0634734494525144
Validation loss: 3.374077675846477

Epoch: 5| Step: 3
Training loss: 4.2164612389584075
Validation loss: 3.372629826002439

Epoch: 5| Step: 4
Training loss: 3.1135338043048955
Validation loss: 3.3727451875979573

Epoch: 5| Step: 5
Training loss: 3.284057288224258
Validation loss: 3.374044683438294

Epoch: 5| Step: 6
Training loss: 4.283129203078477
Validation loss: 3.371058081899938

Epoch: 5| Step: 7
Training loss: 3.453013008338427
Validation loss: 3.373146851833578

Epoch: 5| Step: 8
Training loss: 3.99958763381171
Validation loss: 3.3721267588417216

Epoch: 5| Step: 9
Training loss: 3.224508818844001
Validation loss: 3.3689824476855064

Epoch: 5| Step: 10
Training loss: 4.102468277961414
Validation loss: 3.3693022386412275

Epoch: 47| Step: 0
Training loss: 3.582376544579495
Validation loss: 3.368859001945715

Epoch: 5| Step: 1
Training loss: 2.9196922594709616
Validation loss: 3.3676754535321853

Epoch: 5| Step: 2
Training loss: 3.4541867380207116
Validation loss: 3.3693519162454626

Epoch: 5| Step: 3
Training loss: 3.73093846744212
Validation loss: 3.370414859734222

Epoch: 5| Step: 4
Training loss: 3.2510336185947692
Validation loss: 3.370210063614684

Epoch: 5| Step: 5
Training loss: 3.336363289525711
Validation loss: 3.369147095842703

Epoch: 5| Step: 6
Training loss: 3.6209631179241786
Validation loss: 3.3677137867845737

Epoch: 5| Step: 7
Training loss: 4.222981683010707
Validation loss: 3.3681368668978835

Epoch: 5| Step: 8
Training loss: 4.39346015592763
Validation loss: 3.368413890984221

Epoch: 5| Step: 9
Training loss: 3.7256567152107194
Validation loss: 3.3667415756360333

Epoch: 5| Step: 10
Training loss: 2.961261339016964
Validation loss: 3.364628445232619

Epoch: 48| Step: 0
Training loss: 3.1623316422230725
Validation loss: 3.369466082936833

Epoch: 5| Step: 1
Training loss: 4.328661282913837
Validation loss: 3.3712770139899693

Epoch: 5| Step: 2
Training loss: 3.7473179444822367
Validation loss: 3.370200055375053

Epoch: 5| Step: 3
Training loss: 3.210393483653562
Validation loss: 3.3671897010899765

Epoch: 5| Step: 4
Training loss: 3.6955955993731844
Validation loss: 3.3634780464718896

Epoch: 5| Step: 5
Training loss: 3.2430183541022313
Validation loss: 3.363512744654157

Epoch: 5| Step: 6
Training loss: 3.7268539730581103
Validation loss: 3.3632506015574006

Epoch: 5| Step: 7
Training loss: 3.693431544897409
Validation loss: 3.361914218549024

Epoch: 5| Step: 8
Training loss: 3.674953387736853
Validation loss: 3.363091726433371

Epoch: 5| Step: 9
Training loss: 3.5496022498587285
Validation loss: 3.361594990725272

Epoch: 5| Step: 10
Training loss: 3.350156689295961
Validation loss: 3.362789193186802

Epoch: 49| Step: 0
Training loss: 3.7342516507642265
Validation loss: 3.361590846611588

Epoch: 5| Step: 1
Training loss: 3.584712199386333
Validation loss: 3.3617691670015675

Epoch: 5| Step: 2
Training loss: 3.3019108932828845
Validation loss: 3.3634494211929136

Epoch: 5| Step: 3
Training loss: 3.660902014514386
Validation loss: 3.365858598970682

Epoch: 5| Step: 4
Training loss: 3.2712948872362166
Validation loss: 3.3651820266401375

Epoch: 5| Step: 5
Training loss: 3.310184749276212
Validation loss: 3.3617809428455923

Epoch: 5| Step: 6
Training loss: 3.6875431898788222
Validation loss: 3.3610844773924615

Epoch: 5| Step: 7
Training loss: 3.2035593622220073
Validation loss: 3.359543966521269

Epoch: 5| Step: 8
Training loss: 3.6225708024060514
Validation loss: 3.3582346746260154

Epoch: 5| Step: 9
Training loss: 4.149809701991663
Validation loss: 3.3595622394691214

Epoch: 5| Step: 10
Training loss: 3.8980150012945542
Validation loss: 3.3580457167011386

Epoch: 50| Step: 0
Training loss: 3.517455442535437
Validation loss: 3.3569479032716765

Epoch: 5| Step: 1
Training loss: 3.9556010938968664
Validation loss: 3.357397637541078

Epoch: 5| Step: 2
Training loss: 3.9731488217858884
Validation loss: 3.3584439146592047

Epoch: 5| Step: 3
Training loss: 3.6503186491783906
Validation loss: 3.3574136436603124

Epoch: 5| Step: 4
Training loss: 4.0787673385864185
Validation loss: 3.35716679641168

Epoch: 5| Step: 5
Training loss: 3.1063459968700378
Validation loss: 3.356168039921828

Epoch: 5| Step: 6
Training loss: 2.8333718540340627
Validation loss: 3.35713166761985

Epoch: 5| Step: 7
Training loss: 3.5787177115531725
Validation loss: 3.3561124045223263

Epoch: 5| Step: 8
Training loss: 3.7047347420938714
Validation loss: 3.357252569538155

Epoch: 5| Step: 9
Training loss: 3.4850152629151374
Validation loss: 3.353601561839227

Epoch: 5| Step: 10
Training loss: 3.3612184656266293
Validation loss: 3.3567167440499057

Testing loss: 3.5283883952206763
