Epoch: 1| Step: 0
Training loss: 4.681400775909424
Validation loss: 5.164077702388968

Epoch: 5| Step: 1
Training loss: 5.211660861968994
Validation loss: 5.15945807836389

Epoch: 5| Step: 2
Training loss: 4.716616630554199
Validation loss: 5.15458349515033

Epoch: 5| Step: 3
Training loss: 6.4115400314331055
Validation loss: 5.149789810180664

Epoch: 5| Step: 4
Training loss: 5.034150123596191
Validation loss: 5.144897901883689

Epoch: 5| Step: 5
Training loss: 4.801328659057617
Validation loss: 5.139726115811255

Epoch: 5| Step: 6
Training loss: 4.900542736053467
Validation loss: 5.134670754914643

Epoch: 5| Step: 7
Training loss: 4.558085918426514
Validation loss: 5.1290132153418755

Epoch: 5| Step: 8
Training loss: 4.945813179016113
Validation loss: 5.123150558881862

Epoch: 5| Step: 9
Training loss: 4.772826194763184
Validation loss: 5.117208521853211

Epoch: 5| Step: 10
Training loss: 4.1330766677856445
Validation loss: 5.111042720015331

Epoch: 2| Step: 0
Training loss: 4.618067264556885
Validation loss: 5.1048980118126

Epoch: 5| Step: 1
Training loss: 5.396050453186035
Validation loss: 5.097903051683979

Epoch: 5| Step: 2
Training loss: 4.444985389709473
Validation loss: 5.09091317781838

Epoch: 5| Step: 3
Training loss: 3.388629198074341
Validation loss: 5.083874220489173

Epoch: 5| Step: 4
Training loss: 5.103539943695068
Validation loss: 5.075494950817477

Epoch: 5| Step: 5
Training loss: 5.879063606262207
Validation loss: 5.068054701692315

Epoch: 5| Step: 6
Training loss: 5.081747531890869
Validation loss: 5.059626912557951

Epoch: 5| Step: 7
Training loss: 4.620906829833984
Validation loss: 5.051384115731844

Epoch: 5| Step: 8
Training loss: 5.001109600067139
Validation loss: 5.042508104796051

Epoch: 5| Step: 9
Training loss: 4.878466606140137
Validation loss: 5.033083264545728

Epoch: 5| Step: 10
Training loss: 5.102859973907471
Validation loss: 5.02305551754531

Epoch: 3| Step: 0
Training loss: 4.229747295379639
Validation loss: 5.0136047486336

Epoch: 5| Step: 1
Training loss: 5.306787490844727
Validation loss: 5.002710593644009

Epoch: 5| Step: 2
Training loss: 5.2959113121032715
Validation loss: 4.990570719524096

Epoch: 5| Step: 3
Training loss: 4.330155372619629
Validation loss: 4.979732318591046

Epoch: 5| Step: 4
Training loss: 4.480277061462402
Validation loss: 4.967390850026121

Epoch: 5| Step: 5
Training loss: 5.414700508117676
Validation loss: 4.954136930486207

Epoch: 5| Step: 6
Training loss: 3.8154075145721436
Validation loss: 4.941996979457076

Epoch: 5| Step: 7
Training loss: 5.13672399520874
Validation loss: 4.928607807364515

Epoch: 5| Step: 8
Training loss: 4.085017204284668
Validation loss: 4.914057854683168

Epoch: 5| Step: 9
Training loss: 4.8365278244018555
Validation loss: 4.899850389008881

Epoch: 5| Step: 10
Training loss: 5.377676486968994
Validation loss: 4.88416212861256

Epoch: 4| Step: 0
Training loss: 5.998108386993408
Validation loss: 4.867762427176198

Epoch: 5| Step: 1
Training loss: 3.867959499359131
Validation loss: 4.851202364890806

Epoch: 5| Step: 2
Training loss: 4.820259094238281
Validation loss: 4.832576177453482

Epoch: 5| Step: 3
Training loss: 3.8319427967071533
Validation loss: 4.81401272742979

Epoch: 5| Step: 4
Training loss: 4.562018394470215
Validation loss: 4.796257439480033

Epoch: 5| Step: 5
Training loss: 5.38948392868042
Validation loss: 4.776099961291077

Epoch: 5| Step: 6
Training loss: 4.025936126708984
Validation loss: 4.755628637088242

Epoch: 5| Step: 7
Training loss: 4.546343803405762
Validation loss: 4.73490031560262

Epoch: 5| Step: 8
Training loss: 4.322094917297363
Validation loss: 4.714300391494587

Epoch: 5| Step: 9
Training loss: 4.618963718414307
Validation loss: 4.691325356883388

Epoch: 5| Step: 10
Training loss: 4.097459316253662
Validation loss: 4.668580121891473

Epoch: 5| Step: 0
Training loss: 4.086325168609619
Validation loss: 4.646072920932565

Epoch: 5| Step: 1
Training loss: 3.9812183380126953
Validation loss: 4.623168181347591

Epoch: 5| Step: 2
Training loss: 4.824038028717041
Validation loss: 4.600229411996821

Epoch: 5| Step: 3
Training loss: 4.495335102081299
Validation loss: 4.576954539104174

Epoch: 5| Step: 4
Training loss: 4.548147678375244
Validation loss: 4.5546491171724055

Epoch: 5| Step: 5
Training loss: 3.9953773021698
Validation loss: 4.529725172186411

Epoch: 5| Step: 6
Training loss: 3.549786329269409
Validation loss: 4.506971769435431

Epoch: 5| Step: 7
Training loss: 4.839505672454834
Validation loss: 4.482667441009193

Epoch: 5| Step: 8
Training loss: 3.7502903938293457
Validation loss: 4.461066725433514

Epoch: 5| Step: 9
Training loss: 4.2921905517578125
Validation loss: 4.4370040278280936

Epoch: 5| Step: 10
Training loss: 5.192586421966553
Validation loss: 4.4149571695635395

Epoch: 6| Step: 0
Training loss: 4.590748310089111
Validation loss: 4.393155395343739

Epoch: 5| Step: 1
Training loss: 3.525747776031494
Validation loss: 4.371990332039454

Epoch: 5| Step: 2
Training loss: 3.665634870529175
Validation loss: 4.351467114622875

Epoch: 5| Step: 3
Training loss: 4.925922393798828
Validation loss: 4.331518352672618

Epoch: 5| Step: 4
Training loss: 3.4565327167510986
Validation loss: 4.312140900601623

Epoch: 5| Step: 5
Training loss: 4.496465682983398
Validation loss: 4.29308081698674

Epoch: 5| Step: 6
Training loss: 3.592963457107544
Validation loss: 4.274814615967453

Epoch: 5| Step: 7
Training loss: 4.127582550048828
Validation loss: 4.258149193179223

Epoch: 5| Step: 8
Training loss: 4.98147439956665
Validation loss: 4.238196398622247

Epoch: 5| Step: 9
Training loss: 4.1924147605896
Validation loss: 4.220555008098644

Epoch: 5| Step: 10
Training loss: 3.4197354316711426
Validation loss: 4.200784534536382

Epoch: 7| Step: 0
Training loss: 3.3537204265594482
Validation loss: 4.180494585344868

Epoch: 5| Step: 1
Training loss: 3.6559364795684814
Validation loss: 4.158866989997126

Epoch: 5| Step: 2
Training loss: 3.0344645977020264
Validation loss: 4.137424917631252

Epoch: 5| Step: 3
Training loss: 3.9920411109924316
Validation loss: 4.115308935924243

Epoch: 5| Step: 4
Training loss: 3.29687237739563
Validation loss: 4.092852033594603

Epoch: 5| Step: 5
Training loss: 3.6839332580566406
Validation loss: 4.073996164465464

Epoch: 5| Step: 6
Training loss: 3.712019443511963
Validation loss: 4.055486973895822

Epoch: 5| Step: 7
Training loss: 4.780480861663818
Validation loss: 4.038139009988436

Epoch: 5| Step: 8
Training loss: 5.294661045074463
Validation loss: 4.016267484234225

Epoch: 5| Step: 9
Training loss: 3.664076566696167
Validation loss: 3.9945499512457077

Epoch: 5| Step: 10
Training loss: 4.614351272583008
Validation loss: 3.9698996261883805

Epoch: 8| Step: 0
Training loss: 3.005760431289673
Validation loss: 3.946585434739308

Epoch: 5| Step: 1
Training loss: 3.880039930343628
Validation loss: 3.9246598725677817

Epoch: 5| Step: 2
Training loss: 3.739903688430786
Validation loss: 3.906606597285117

Epoch: 5| Step: 3
Training loss: 4.1490068435668945
Validation loss: 3.887610594431559

Epoch: 5| Step: 4
Training loss: 3.1415624618530273
Validation loss: 3.8719462681842107

Epoch: 5| Step: 5
Training loss: 4.405648231506348
Validation loss: 3.8575036910272416

Epoch: 5| Step: 6
Training loss: 3.8935012817382812
Validation loss: 3.842931242399318

Epoch: 5| Step: 7
Training loss: 3.432706356048584
Validation loss: 3.828536210521575

Epoch: 5| Step: 8
Training loss: 3.798725128173828
Validation loss: 3.8135335522313274

Epoch: 5| Step: 9
Training loss: 4.060345649719238
Validation loss: 3.7997337336181314

Epoch: 5| Step: 10
Training loss: 3.481139659881592
Validation loss: 3.7887540273768927

Epoch: 9| Step: 0
Training loss: 3.966320037841797
Validation loss: 3.777098891555622

Epoch: 5| Step: 1
Training loss: 3.601720094680786
Validation loss: 3.7691949926396853

Epoch: 5| Step: 2
Training loss: 4.277679443359375
Validation loss: 3.756640593210856

Epoch: 5| Step: 3
Training loss: 3.3357532024383545
Validation loss: 3.7470846483784337

Epoch: 5| Step: 4
Training loss: 3.5306193828582764
Validation loss: 3.736255499624437

Epoch: 5| Step: 5
Training loss: 2.908853054046631
Validation loss: 3.726220679539506

Epoch: 5| Step: 6
Training loss: 3.9461262226104736
Validation loss: 3.7192442699145247

Epoch: 5| Step: 7
Training loss: 3.9409008026123047
Validation loss: 3.709514405137749

Epoch: 5| Step: 8
Training loss: 3.220986843109131
Validation loss: 3.700757964964836

Epoch: 5| Step: 9
Training loss: 3.2347893714904785
Validation loss: 3.6920048241974204

Epoch: 5| Step: 10
Training loss: 3.924992322921753
Validation loss: 3.686333333292315

Epoch: 10| Step: 0
Training loss: 4.000973701477051
Validation loss: 3.6770468578543714

Epoch: 5| Step: 1
Training loss: 3.798656463623047
Validation loss: 3.670168025519258

Epoch: 5| Step: 2
Training loss: 3.7277615070343018
Validation loss: 3.6646247474096154

Epoch: 5| Step: 3
Training loss: 2.9175641536712646
Validation loss: 3.657038006731259

Epoch: 5| Step: 4
Training loss: 2.773648977279663
Validation loss: 3.6486984042711157

Epoch: 5| Step: 5
Training loss: 3.2950758934020996
Validation loss: 3.6380046131790325

Epoch: 5| Step: 6
Training loss: 4.421757221221924
Validation loss: 3.632294129299861

Epoch: 5| Step: 7
Training loss: 4.172300338745117
Validation loss: 3.628034876238915

Epoch: 5| Step: 8
Training loss: 3.4411792755126953
Validation loss: 3.620302284917524

Epoch: 5| Step: 9
Training loss: 2.7219173908233643
Validation loss: 3.6144465425963044

Epoch: 5| Step: 10
Training loss: 3.7694616317749023
Validation loss: 3.6085449316168345

Epoch: 11| Step: 0
Training loss: 3.0339393615722656
Validation loss: 3.598927351736253

Epoch: 5| Step: 1
Training loss: 3.7240471839904785
Validation loss: 3.5929111383294545

Epoch: 5| Step: 2
Training loss: 3.694000244140625
Validation loss: 3.588036508970363

Epoch: 5| Step: 3
Training loss: 3.5453732013702393
Validation loss: 3.5812161558417865

Epoch: 5| Step: 4
Training loss: 4.410305976867676
Validation loss: 3.5760050768493326

Epoch: 5| Step: 5
Training loss: 4.202935218811035
Validation loss: 3.572244813365321

Epoch: 5| Step: 6
Training loss: 2.9993479251861572
Validation loss: 3.5643609723737164

Epoch: 5| Step: 7
Training loss: 3.870043992996216
Validation loss: 3.5587925705858456

Epoch: 5| Step: 8
Training loss: 2.392209529876709
Validation loss: 3.551955597375029

Epoch: 5| Step: 9
Training loss: 3.2866454124450684
Validation loss: 3.547296618902555

Epoch: 5| Step: 10
Training loss: 3.159050941467285
Validation loss: 3.538778684472525

Epoch: 12| Step: 0
Training loss: 3.728999376296997
Validation loss: 3.533532573330787

Epoch: 5| Step: 1
Training loss: 3.4934334754943848
Validation loss: 3.526090206638459

Epoch: 5| Step: 2
Training loss: 2.050363302230835
Validation loss: 3.5216167434569328

Epoch: 5| Step: 3
Training loss: 2.81915283203125
Validation loss: 3.515860721629153

Epoch: 5| Step: 4
Training loss: 2.422935962677002
Validation loss: 3.5133613232643373

Epoch: 5| Step: 5
Training loss: 4.579101085662842
Validation loss: 3.5071972647020893

Epoch: 5| Step: 6
Training loss: 4.225977897644043
Validation loss: 3.5025168926485124

Epoch: 5| Step: 7
Training loss: 3.981545925140381
Validation loss: 3.496354297925067

Epoch: 5| Step: 8
Training loss: 3.0716004371643066
Validation loss: 3.493664062151345

Epoch: 5| Step: 9
Training loss: 4.111092567443848
Validation loss: 3.4888185070407007

Epoch: 5| Step: 10
Training loss: 3.3007113933563232
Validation loss: 3.487547902650731

Epoch: 13| Step: 0
Training loss: 3.9568779468536377
Validation loss: 3.480185003690822

Epoch: 5| Step: 1
Training loss: 4.002640247344971
Validation loss: 3.471793656708092

Epoch: 5| Step: 2
Training loss: 2.420375347137451
Validation loss: 3.465670101104244

Epoch: 5| Step: 3
Training loss: 2.822495937347412
Validation loss: 3.4620320027874363

Epoch: 5| Step: 4
Training loss: 3.684810161590576
Validation loss: 3.4575151294790287

Epoch: 5| Step: 5
Training loss: 3.948812961578369
Validation loss: 3.4544043848591466

Epoch: 5| Step: 6
Training loss: 3.0729832649230957
Validation loss: 3.4501366922932286

Epoch: 5| Step: 7
Training loss: 3.2950751781463623
Validation loss: 3.44405863618338

Epoch: 5| Step: 8
Training loss: 3.459853410720825
Validation loss: 3.4377478527766403

Epoch: 5| Step: 9
Training loss: 3.528794527053833
Validation loss: 3.432391974233812

Epoch: 5| Step: 10
Training loss: 3.0564820766448975
Validation loss: 3.428502272534114

Epoch: 14| Step: 0
Training loss: 3.089533567428589
Validation loss: 3.4238380949984313

Epoch: 5| Step: 1
Training loss: 3.84552001953125
Validation loss: 3.4252141726914274

Epoch: 5| Step: 2
Training loss: 3.1361916065216064
Validation loss: 3.4208784513576056

Epoch: 5| Step: 3
Training loss: 2.6594078540802
Validation loss: 3.41270568806638

Epoch: 5| Step: 4
Training loss: 3.4993433952331543
Validation loss: 3.407177250872376

Epoch: 5| Step: 5
Training loss: 4.283169269561768
Validation loss: 3.4049191808187835

Epoch: 5| Step: 6
Training loss: 3.5350265502929688
Validation loss: 3.3978469858887377

Epoch: 5| Step: 7
Training loss: 3.211709976196289
Validation loss: 3.393555313028315

Epoch: 5| Step: 8
Training loss: 2.967315435409546
Validation loss: 3.3898971465326126

Epoch: 5| Step: 9
Training loss: 2.721553325653076
Validation loss: 3.3851793068711475

Epoch: 5| Step: 10
Training loss: 3.995710849761963
Validation loss: 3.38302033434632

Epoch: 15| Step: 0
Training loss: 3.294560194015503
Validation loss: 3.3790949980417886

Epoch: 5| Step: 1
Training loss: 4.470524787902832
Validation loss: 3.371514710046912

Epoch: 5| Step: 2
Training loss: 3.0519986152648926
Validation loss: 3.369833092535696

Epoch: 5| Step: 3
Training loss: 3.5669569969177246
Validation loss: 3.3613218261349584

Epoch: 5| Step: 4
Training loss: 2.8843460083007812
Validation loss: 3.358089485476094

Epoch: 5| Step: 5
Training loss: 2.9687280654907227
Validation loss: 3.354606064417029

Epoch: 5| Step: 6
Training loss: 2.9715943336486816
Validation loss: 3.351279445873794

Epoch: 5| Step: 7
Training loss: 3.6446335315704346
Validation loss: 3.345977485820811

Epoch: 5| Step: 8
Training loss: 3.3199970722198486
Validation loss: 3.344720358489662

Epoch: 5| Step: 9
Training loss: 2.898261070251465
Validation loss: 3.3421025968367055

Epoch: 5| Step: 10
Training loss: 3.338815927505493
Validation loss: 3.3358874756802797

Epoch: 16| Step: 0
Training loss: 2.6969780921936035
Validation loss: 3.330465511609149

Epoch: 5| Step: 1
Training loss: 3.0732693672180176
Validation loss: 3.32633448672551

Epoch: 5| Step: 2
Training loss: 3.6292412281036377
Validation loss: 3.32233077479947

Epoch: 5| Step: 3
Training loss: 3.8152222633361816
Validation loss: 3.3177008603208806

Epoch: 5| Step: 4
Training loss: 2.970660448074341
Validation loss: 3.315554536798949

Epoch: 5| Step: 5
Training loss: 2.9394896030426025
Validation loss: 3.317376039361441

Epoch: 5| Step: 6
Training loss: 3.470010280609131
Validation loss: 3.321647313333327

Epoch: 5| Step: 7
Training loss: 3.2220065593719482
Validation loss: 3.313378313536285

Epoch: 5| Step: 8
Training loss: 4.153323173522949
Validation loss: 3.304058959407191

Epoch: 5| Step: 9
Training loss: 2.9296066761016846
Validation loss: 3.294433621950047

Epoch: 5| Step: 10
Training loss: 3.0604639053344727
Validation loss: 3.287526676731725

Epoch: 17| Step: 0
Training loss: 3.2983882427215576
Validation loss: 3.2860194995839107

Epoch: 5| Step: 1
Training loss: 2.948416233062744
Validation loss: 3.28161798497682

Epoch: 5| Step: 2
Training loss: 2.544757127761841
Validation loss: 3.2787605075426

Epoch: 5| Step: 3
Training loss: 3.2778496742248535
Validation loss: 3.275501330693563

Epoch: 5| Step: 4
Training loss: 2.8340883255004883
Validation loss: 3.2741827195690525

Epoch: 5| Step: 5
Training loss: 2.948087215423584
Validation loss: 3.2686727252057803

Epoch: 5| Step: 6
Training loss: 3.7257683277130127
Validation loss: 3.26630489800566

Epoch: 5| Step: 7
Training loss: 3.356571912765503
Validation loss: 3.258396328136485

Epoch: 5| Step: 8
Training loss: 3.384446382522583
Validation loss: 3.2546064110212427

Epoch: 5| Step: 9
Training loss: 3.7408607006073
Validation loss: 3.250068554314234

Epoch: 5| Step: 10
Training loss: 3.6176233291625977
Validation loss: 3.2478329238071235

Epoch: 18| Step: 0
Training loss: 2.817312240600586
Validation loss: 3.25042026786394

Epoch: 5| Step: 1
Training loss: 3.6887383460998535
Validation loss: 3.249149235345984

Epoch: 5| Step: 2
Training loss: 3.8377387523651123
Validation loss: 3.2442805203058387

Epoch: 5| Step: 3
Training loss: 3.1711275577545166
Validation loss: 3.2457796732584634

Epoch: 5| Step: 4
Training loss: 3.532353162765503
Validation loss: 3.2514760289140927

Epoch: 5| Step: 5
Training loss: 2.8280959129333496
Validation loss: 3.2471422662017164

Epoch: 5| Step: 6
Training loss: 3.2627875804901123
Validation loss: 3.2334696528732136

Epoch: 5| Step: 7
Training loss: 2.908870220184326
Validation loss: 3.23139129659181

Epoch: 5| Step: 8
Training loss: 3.3416390419006348
Validation loss: 3.2233845803045456

Epoch: 5| Step: 9
Training loss: 2.918062210083008
Validation loss: 3.2219906853091334

Epoch: 5| Step: 10
Training loss: 2.9276981353759766
Validation loss: 3.223052227368919

Epoch: 19| Step: 0
Training loss: 2.767192840576172
Validation loss: 3.2143575068443053

Epoch: 5| Step: 1
Training loss: 2.8052477836608887
Validation loss: 3.209726743800666

Epoch: 5| Step: 2
Training loss: 3.1285688877105713
Validation loss: 3.2069359030774844

Epoch: 5| Step: 3
Training loss: 3.7766106128692627
Validation loss: 3.2007048181308213

Epoch: 5| Step: 4
Training loss: 2.5184426307678223
Validation loss: 3.1998067543070805

Epoch: 5| Step: 5
Training loss: 3.4735074043273926
Validation loss: 3.1955072751609226

Epoch: 5| Step: 6
Training loss: 3.6406807899475098
Validation loss: 3.193258882850729

Epoch: 5| Step: 7
Training loss: 3.7350852489471436
Validation loss: 3.182405869166056

Epoch: 5| Step: 8
Training loss: 3.240936279296875
Validation loss: 3.1798042353763374

Epoch: 5| Step: 9
Training loss: 3.17510986328125
Validation loss: 3.1779722603418494

Epoch: 5| Step: 10
Training loss: 2.682006597518921
Validation loss: 3.170259380853304

Epoch: 20| Step: 0
Training loss: 3.2950234413146973
Validation loss: 3.175257985309888

Epoch: 5| Step: 1
Training loss: 2.794302463531494
Validation loss: 3.1713572317554104

Epoch: 5| Step: 2
Training loss: 3.453094482421875
Validation loss: 3.1648173537305606

Epoch: 5| Step: 3
Training loss: 3.586909770965576
Validation loss: 3.159942057824904

Epoch: 5| Step: 4
Training loss: 2.8005547523498535
Validation loss: 3.154313410482099

Epoch: 5| Step: 5
Training loss: 2.757633686065674
Validation loss: 3.1485598625675326

Epoch: 5| Step: 6
Training loss: 2.9301934242248535
Validation loss: 3.145851483909033

Epoch: 5| Step: 7
Training loss: 2.8246567249298096
Validation loss: 3.1423464462321293

Epoch: 5| Step: 8
Training loss: 3.1687111854553223
Validation loss: 3.145105408084008

Epoch: 5| Step: 9
Training loss: 3.1204562187194824
Validation loss: 3.1396995129123813

Epoch: 5| Step: 10
Training loss: 4.099477767944336
Validation loss: 3.131744087383311

Epoch: 21| Step: 0
Training loss: 3.1943812370300293
Validation loss: 3.1323504294118574

Epoch: 5| Step: 1
Training loss: 3.085599660873413
Validation loss: 3.130947228400938

Epoch: 5| Step: 2
Training loss: 3.418541669845581
Validation loss: 3.128596585283997

Epoch: 5| Step: 3
Training loss: 3.767129421234131
Validation loss: 3.1222168040531937

Epoch: 5| Step: 4
Training loss: 2.1382575035095215
Validation loss: 3.1191897776819046

Epoch: 5| Step: 5
Training loss: 2.846322774887085
Validation loss: 3.1149856582764657

Epoch: 5| Step: 6
Training loss: 3.21281361579895
Validation loss: 3.113091074010377

Epoch: 5| Step: 7
Training loss: 2.9950063228607178
Validation loss: 3.113950898570399

Epoch: 5| Step: 8
Training loss: 2.6807849407196045
Validation loss: 3.1178703820833595

Epoch: 5| Step: 9
Training loss: 3.0364532470703125
Validation loss: 3.11097123289621

Epoch: 5| Step: 10
Training loss: 4.187349319458008
Validation loss: 3.108591100221039

Epoch: 22| Step: 0
Training loss: 3.612771987915039
Validation loss: 3.1041631416607927

Epoch: 5| Step: 1
Training loss: 4.151972770690918
Validation loss: 3.10501677502868

Epoch: 5| Step: 2
Training loss: 2.968825101852417
Validation loss: 3.1010368165149482

Epoch: 5| Step: 3
Training loss: 2.832787275314331
Validation loss: 3.1029246725061888

Epoch: 5| Step: 4
Training loss: 3.803447723388672
Validation loss: 3.0945757717214604

Epoch: 5| Step: 5
Training loss: 2.7955479621887207
Validation loss: 3.090585800909227

Epoch: 5| Step: 6
Training loss: 3.1668648719787598
Validation loss: 3.086784960121237

Epoch: 5| Step: 7
Training loss: 3.1225380897521973
Validation loss: 3.079065756131244

Epoch: 5| Step: 8
Training loss: 2.4988224506378174
Validation loss: 3.0759280061209076

Epoch: 5| Step: 9
Training loss: 2.8238673210144043
Validation loss: 3.0725940376199703

Epoch: 5| Step: 10
Training loss: 2.287803888320923
Validation loss: 3.0706930288704495

Epoch: 23| Step: 0
Training loss: 3.145939588546753
Validation loss: 3.0764037101499495

Epoch: 5| Step: 1
Training loss: 2.9208171367645264
Validation loss: 3.077735665023968

Epoch: 5| Step: 2
Training loss: 3.7110443115234375
Validation loss: 3.0864489796341106

Epoch: 5| Step: 3
Training loss: 2.0783333778381348
Validation loss: 3.0628055962183143

Epoch: 5| Step: 4
Training loss: 3.4454586505889893
Validation loss: 3.0698893582949074

Epoch: 5| Step: 5
Training loss: 3.73584246635437
Validation loss: 3.067638715108236

Epoch: 5| Step: 6
Training loss: 2.800729513168335
Validation loss: 3.064949704754737

Epoch: 5| Step: 7
Training loss: 3.816608428955078
Validation loss: 3.0658068836376233

Epoch: 5| Step: 8
Training loss: 2.8432083129882812
Validation loss: 3.063224856571485

Epoch: 5| Step: 9
Training loss: 2.905069351196289
Validation loss: 3.0567821892358924

Epoch: 5| Step: 10
Training loss: 2.5228798389434814
Validation loss: 3.049487836899296

Epoch: 24| Step: 0
Training loss: 2.485198736190796
Validation loss: 3.0484941236434446

Epoch: 5| Step: 1
Training loss: 3.694011688232422
Validation loss: 3.0531959251690934

Epoch: 5| Step: 2
Training loss: 3.403838634490967
Validation loss: 3.0558379234806186

Epoch: 5| Step: 3
Training loss: 3.1082985401153564
Validation loss: 3.053473867395873

Epoch: 5| Step: 4
Training loss: 3.223776340484619
Validation loss: 3.0564391254096903

Epoch: 5| Step: 5
Training loss: 2.6218748092651367
Validation loss: 3.0401464226425334

Epoch: 5| Step: 6
Training loss: 3.1075453758239746
Validation loss: 3.032290066442182

Epoch: 5| Step: 7
Training loss: 3.582737445831299
Validation loss: 3.0256454585700907

Epoch: 5| Step: 8
Training loss: 3.130777597427368
Validation loss: 3.024867134709512

Epoch: 5| Step: 9
Training loss: 2.4742329120635986
Validation loss: 3.0240219229011127

Epoch: 5| Step: 10
Training loss: 2.9776077270507812
Validation loss: 3.024444774914813

Epoch: 25| Step: 0
Training loss: 2.8140933513641357
Validation loss: 3.021850703864969

Epoch: 5| Step: 1
Training loss: 2.777939796447754
Validation loss: 3.0222817877287507

Epoch: 5| Step: 2
Training loss: 2.4406120777130127
Validation loss: 3.0203595033255954

Epoch: 5| Step: 3
Training loss: 3.14454984664917
Validation loss: 3.02089605023784

Epoch: 5| Step: 4
Training loss: 3.7335472106933594
Validation loss: 3.0205961196653304

Epoch: 5| Step: 5
Training loss: 2.7126293182373047
Validation loss: 3.019092236795733

Epoch: 5| Step: 6
Training loss: 2.9858925342559814
Validation loss: 3.0169318440139934

Epoch: 5| Step: 7
Training loss: 2.9767825603485107
Validation loss: 3.0180108521574285

Epoch: 5| Step: 8
Training loss: 3.5565052032470703
Validation loss: 3.014162440453806

Epoch: 5| Step: 9
Training loss: 2.8889920711517334
Validation loss: 3.011824015648134

Epoch: 5| Step: 10
Training loss: 3.687650680541992
Validation loss: 3.00016688787809

Epoch: 26| Step: 0
Training loss: 2.762360095977783
Validation loss: 3.000894543945148

Epoch: 5| Step: 1
Training loss: 3.621027708053589
Validation loss: 2.995386049311648

Epoch: 5| Step: 2
Training loss: 2.805432081222534
Validation loss: 2.990466930532968

Epoch: 5| Step: 3
Training loss: 4.2044219970703125
Validation loss: 2.9847421876845823

Epoch: 5| Step: 4
Training loss: 2.8299832344055176
Validation loss: 2.9863900292304253

Epoch: 5| Step: 5
Training loss: 3.567631483078003
Validation loss: 2.9830053416631555

Epoch: 5| Step: 6
Training loss: 2.9007742404937744
Validation loss: 2.9782414077430643

Epoch: 5| Step: 7
Training loss: 2.078063488006592
Validation loss: 2.983283835072671

Epoch: 5| Step: 8
Training loss: 2.580580234527588
Validation loss: 2.9863531512598835

Epoch: 5| Step: 9
Training loss: 2.859520435333252
Validation loss: 2.985604570757958

Epoch: 5| Step: 10
Training loss: 3.205094814300537
Validation loss: 2.9825130995883735

Epoch: 27| Step: 0
Training loss: 2.426837682723999
Validation loss: 2.9775627813031598

Epoch: 5| Step: 1
Training loss: 3.451371669769287
Validation loss: 2.976554657823296

Epoch: 5| Step: 2
Training loss: 4.081162452697754
Validation loss: 2.9688032468159995

Epoch: 5| Step: 3
Training loss: 1.9154659509658813
Validation loss: 2.961597001680764

Epoch: 5| Step: 4
Training loss: 3.130288600921631
Validation loss: 2.9586747025930755

Epoch: 5| Step: 5
Training loss: 3.1573259830474854
Validation loss: 2.9528126383340485

Epoch: 5| Step: 6
Training loss: 2.637789487838745
Validation loss: 2.957261844347882

Epoch: 5| Step: 7
Training loss: 3.0589280128479004
Validation loss: 2.955625872458181

Epoch: 5| Step: 8
Training loss: 2.874112606048584
Validation loss: 2.9570624443792526

Epoch: 5| Step: 9
Training loss: 3.540752410888672
Validation loss: 2.944686717884515

Epoch: 5| Step: 10
Training loss: 2.9021248817443848
Validation loss: 2.9448676468223653

Epoch: 28| Step: 0
Training loss: 2.6738510131835938
Validation loss: 2.9459292401549635

Epoch: 5| Step: 1
Training loss: 2.7831127643585205
Validation loss: 2.9459562070908083

Epoch: 5| Step: 2
Training loss: 2.686147689819336
Validation loss: 2.943053607017763

Epoch: 5| Step: 3
Training loss: 2.593695878982544
Validation loss: 2.9446913426922214

Epoch: 5| Step: 4
Training loss: 3.906817674636841
Validation loss: 2.939911570600284

Epoch: 5| Step: 5
Training loss: 3.123056650161743
Validation loss: 2.9367235757971324

Epoch: 5| Step: 6
Training loss: 2.8865580558776855
Validation loss: 2.9350130532377507

Epoch: 5| Step: 7
Training loss: 3.5321121215820312
Validation loss: 2.9313498568791214

Epoch: 5| Step: 8
Training loss: 2.617151975631714
Validation loss: 2.943728034214307

Epoch: 5| Step: 9
Training loss: 2.7769010066986084
Validation loss: 2.942435513260544

Epoch: 5| Step: 10
Training loss: 3.527677536010742
Validation loss: 2.935487865119852

Epoch: 29| Step: 0
Training loss: 3.2795345783233643
Validation loss: 2.9234999892532185

Epoch: 5| Step: 1
Training loss: 2.824451208114624
Validation loss: 2.9180631201754332

Epoch: 5| Step: 2
Training loss: 3.309605360031128
Validation loss: 2.9195207036951536

Epoch: 5| Step: 3
Training loss: 3.2515740394592285
Validation loss: 2.9206318496375956

Epoch: 5| Step: 4
Training loss: 2.5596835613250732
Validation loss: 2.918076935634818

Epoch: 5| Step: 5
Training loss: 3.5818533897399902
Validation loss: 2.919895220828313

Epoch: 5| Step: 6
Training loss: 2.642827272415161
Validation loss: 2.9171539865514284

Epoch: 5| Step: 7
Training loss: 2.766714096069336
Validation loss: 2.913412509425994

Epoch: 5| Step: 8
Training loss: 3.2513206005096436
Validation loss: 2.9053411663219495

Epoch: 5| Step: 9
Training loss: 2.6240100860595703
Validation loss: 2.904475176206199

Epoch: 5| Step: 10
Training loss: 2.753161907196045
Validation loss: 2.900819370823522

Epoch: 30| Step: 0
Training loss: 3.461885452270508
Validation loss: 2.900349606749832

Epoch: 5| Step: 1
Training loss: 3.2577412128448486
Validation loss: 2.9079943600521294

Epoch: 5| Step: 2
Training loss: 3.323892593383789
Validation loss: 2.9094910211460565

Epoch: 5| Step: 3
Training loss: 2.998093366622925
Validation loss: 2.9034373426950104

Epoch: 5| Step: 4
Training loss: 2.0978875160217285
Validation loss: 2.907052363118818

Epoch: 5| Step: 5
Training loss: 2.8825955390930176
Validation loss: 2.897152969914098

Epoch: 5| Step: 6
Training loss: 2.9929635524749756
Validation loss: 2.8932720563744985

Epoch: 5| Step: 7
Training loss: 2.943397283554077
Validation loss: 2.8949513178999706

Epoch: 5| Step: 8
Training loss: 2.6439919471740723
Validation loss: 2.890265426328105

Epoch: 5| Step: 9
Training loss: 2.651479482650757
Validation loss: 2.890457853194206

Epoch: 5| Step: 10
Training loss: 3.536945104598999
Validation loss: 2.894176313954015

Epoch: 31| Step: 0
Training loss: 2.9148876667022705
Validation loss: 2.891658459940264

Epoch: 5| Step: 1
Training loss: 3.514653444290161
Validation loss: 2.88776534347124

Epoch: 5| Step: 2
Training loss: 2.6475625038146973
Validation loss: 2.8868136687945296

Epoch: 5| Step: 3
Training loss: 2.5985748767852783
Validation loss: 2.8812205663291355

Epoch: 5| Step: 4
Training loss: 2.984863758087158
Validation loss: 2.877916225823023

Epoch: 5| Step: 5
Training loss: 3.684847354888916
Validation loss: 2.874116687364476

Epoch: 5| Step: 6
Training loss: 2.8506088256835938
Validation loss: 2.8723484854544363

Epoch: 5| Step: 7
Training loss: 2.3722469806671143
Validation loss: 2.87577574740174

Epoch: 5| Step: 8
Training loss: 2.5854105949401855
Validation loss: 2.8772735031702186

Epoch: 5| Step: 9
Training loss: 3.181006908416748
Validation loss: 2.8755904423293246

Epoch: 5| Step: 10
Training loss: 3.285141944885254
Validation loss: 2.8790332886480514

Epoch: 32| Step: 0
Training loss: 2.7718212604522705
Validation loss: 2.8746539290233324

Epoch: 5| Step: 1
Training loss: 2.7505805492401123
Validation loss: 2.8697543990227485

Epoch: 5| Step: 2
Training loss: 3.4364802837371826
Validation loss: 2.8655274991066224

Epoch: 5| Step: 3
Training loss: 2.1830410957336426
Validation loss: 2.858710058273808

Epoch: 5| Step: 4
Training loss: 3.2227795124053955
Validation loss: 2.8659326030362036

Epoch: 5| Step: 5
Training loss: 2.8895623683929443
Validation loss: 2.863616274249169

Epoch: 5| Step: 6
Training loss: 3.3853745460510254
Validation loss: 2.8596008721218316

Epoch: 5| Step: 7
Training loss: 3.1972217559814453
Validation loss: 2.8583320904803533

Epoch: 5| Step: 8
Training loss: 2.984818935394287
Validation loss: 2.8589690680144937

Epoch: 5| Step: 9
Training loss: 3.325425624847412
Validation loss: 2.8658872547970025

Epoch: 5| Step: 10
Training loss: 2.15967059135437
Validation loss: 2.8586407963947584

Epoch: 33| Step: 0
Training loss: 2.633455276489258
Validation loss: 2.85173544063363

Epoch: 5| Step: 1
Training loss: 3.675027370452881
Validation loss: 2.8469695609102965

Epoch: 5| Step: 2
Training loss: 2.3482747077941895
Validation loss: 2.8448497428688952

Epoch: 5| Step: 3
Training loss: 2.859893321990967
Validation loss: 2.8449639710046912

Epoch: 5| Step: 4
Training loss: 2.650803804397583
Validation loss: 2.845554813261955

Epoch: 5| Step: 5
Training loss: 3.1433298587799072
Validation loss: 2.847556875598046

Epoch: 5| Step: 6
Training loss: 2.836991786956787
Validation loss: 2.8427480728395524

Epoch: 5| Step: 7
Training loss: 3.26605486869812
Validation loss: 2.8415949524089856

Epoch: 5| Step: 8
Training loss: 3.0200016498565674
Validation loss: 2.8457165328405236

Epoch: 5| Step: 9
Training loss: 2.8813679218292236
Validation loss: 2.838785474018384

Epoch: 5| Step: 10
Training loss: 2.980363130569458
Validation loss: 2.8334197075136247

Epoch: 34| Step: 0
Training loss: 2.883077383041382
Validation loss: 2.8311299200980895

Epoch: 5| Step: 1
Training loss: 2.8851351737976074
Validation loss: 2.8336833933348298

Epoch: 5| Step: 2
Training loss: 2.7145442962646484
Validation loss: 2.839931082981889

Epoch: 5| Step: 3
Training loss: 2.8437047004699707
Validation loss: 2.845830935303883

Epoch: 5| Step: 4
Training loss: 2.55135178565979
Validation loss: 2.839022890213997

Epoch: 5| Step: 5
Training loss: 3.4404456615448
Validation loss: 2.8291687068118843

Epoch: 5| Step: 6
Training loss: 3.0767438411712646
Validation loss: 2.8304428208258843

Epoch: 5| Step: 7
Training loss: 2.743539333343506
Validation loss: 2.8296442006223943

Epoch: 5| Step: 8
Training loss: 3.777193784713745
Validation loss: 2.821621984563848

Epoch: 5| Step: 9
Training loss: 2.4603686332702637
Validation loss: 2.8211756201200586

Epoch: 5| Step: 10
Training loss: 2.811857223510742
Validation loss: 2.8219367765611216

Epoch: 35| Step: 0
Training loss: 3.0771610736846924
Validation loss: 2.8138175472136466

Epoch: 5| Step: 1
Training loss: 4.160235404968262
Validation loss: 2.8147928073842037

Epoch: 5| Step: 2
Training loss: 3.182229518890381
Validation loss: 2.817900485889886

Epoch: 5| Step: 3
Training loss: 3.3564560413360596
Validation loss: 2.81829672731379

Epoch: 5| Step: 4
Training loss: 3.0689728260040283
Validation loss: 2.816886668564171

Epoch: 5| Step: 5
Training loss: 2.522953748703003
Validation loss: 2.812136939776841

Epoch: 5| Step: 6
Training loss: 2.7157511711120605
Validation loss: 2.811414469954788

Epoch: 5| Step: 7
Training loss: 2.151390790939331
Validation loss: 2.8098075671862532

Epoch: 5| Step: 8
Training loss: 2.7868480682373047
Validation loss: 2.8106854474672707

Epoch: 5| Step: 9
Training loss: 2.2417168617248535
Validation loss: 2.802909602401077

Epoch: 5| Step: 10
Training loss: 2.7905476093292236
Validation loss: 2.8046038432787825

Epoch: 36| Step: 0
Training loss: 3.358738660812378
Validation loss: 2.810530613827449

Epoch: 5| Step: 1
Training loss: 3.490022659301758
Validation loss: 2.8046187662309214

Epoch: 5| Step: 2
Training loss: 2.5102715492248535
Validation loss: 2.805809200450938

Epoch: 5| Step: 3
Training loss: 2.990525722503662
Validation loss: 2.8037606875101724

Epoch: 5| Step: 4
Training loss: 3.0674610137939453
Validation loss: 2.7957381535601873

Epoch: 5| Step: 5
Training loss: 2.4630305767059326
Validation loss: 2.7987382078683503

Epoch: 5| Step: 6
Training loss: 2.032909870147705
Validation loss: 2.7961838450483096

Epoch: 5| Step: 7
Training loss: 3.568859815597534
Validation loss: 2.793370949324741

Epoch: 5| Step: 8
Training loss: 3.032160520553589
Validation loss: 2.7932930607949533

Epoch: 5| Step: 9
Training loss: 2.787299394607544
Validation loss: 2.7969129136813584

Epoch: 5| Step: 10
Training loss: 2.551381826400757
Validation loss: 2.794222347197994

Epoch: 37| Step: 0
Training loss: 2.5902493000030518
Validation loss: 2.791816352516092

Epoch: 5| Step: 1
Training loss: 3.4182350635528564
Validation loss: 2.7906929010986

Epoch: 5| Step: 2
Training loss: 2.215337038040161
Validation loss: 2.7893787789088424

Epoch: 5| Step: 3
Training loss: 3.7324531078338623
Validation loss: 2.786979377910655

Epoch: 5| Step: 4
Training loss: 3.1507275104522705
Validation loss: 2.7821066123183056

Epoch: 5| Step: 5
Training loss: 3.0244944095611572
Validation loss: 2.785562797259259

Epoch: 5| Step: 6
Training loss: 2.415515661239624
Validation loss: 2.78296019441338

Epoch: 5| Step: 7
Training loss: 3.010777711868286
Validation loss: 2.784620028670116

Epoch: 5| Step: 8
Training loss: 2.0837905406951904
Validation loss: 2.777201678163262

Epoch: 5| Step: 9
Training loss: 3.375072479248047
Validation loss: 2.7839636136126775

Epoch: 5| Step: 10
Training loss: 2.835538387298584
Validation loss: 2.78364574011936

Epoch: 38| Step: 0
Training loss: 3.4807426929473877
Validation loss: 2.7836071778369207

Epoch: 5| Step: 1
Training loss: 2.6286606788635254
Validation loss: 2.786271854113507

Epoch: 5| Step: 2
Training loss: 3.663754940032959
Validation loss: 2.782903161100162

Epoch: 5| Step: 3
Training loss: 3.5177955627441406
Validation loss: 2.7835933085410827

Epoch: 5| Step: 4
Training loss: 2.456251621246338
Validation loss: 2.7900966982687674

Epoch: 5| Step: 5
Training loss: 2.449575662612915
Validation loss: 2.78088713717717

Epoch: 5| Step: 6
Training loss: 3.2063040733337402
Validation loss: 2.772806380384712

Epoch: 5| Step: 7
Training loss: 2.8527982234954834
Validation loss: 2.77582965102247

Epoch: 5| Step: 8
Training loss: 2.7871456146240234
Validation loss: 2.7679948960581133

Epoch: 5| Step: 9
Training loss: 2.718055486679077
Validation loss: 2.763157190815095

Epoch: 5| Step: 10
Training loss: 1.8711941242218018
Validation loss: 2.7690751578218196

Epoch: 39| Step: 0
Training loss: 2.688121795654297
Validation loss: 2.765075822030344

Epoch: 5| Step: 1
Training loss: 3.2604870796203613
Validation loss: 2.7636572135392057

Epoch: 5| Step: 2
Training loss: 3.5701098442077637
Validation loss: 2.7634702959368305

Epoch: 5| Step: 3
Training loss: 3.0402393341064453
Validation loss: 2.76364645906674

Epoch: 5| Step: 4
Training loss: 2.921703815460205
Validation loss: 2.7634372044635076

Epoch: 5| Step: 5
Training loss: 2.603583812713623
Validation loss: 2.762674762356666

Epoch: 5| Step: 6
Training loss: 3.083082437515259
Validation loss: 2.7575309943127375

Epoch: 5| Step: 7
Training loss: 2.887054920196533
Validation loss: 2.7556428499119257

Epoch: 5| Step: 8
Training loss: 2.276832103729248
Validation loss: 2.7615483653160835

Epoch: 5| Step: 9
Training loss: 2.6679134368896484
Validation loss: 2.758513853114138

Epoch: 5| Step: 10
Training loss: 2.6423227787017822
Validation loss: 2.76118214156038

Epoch: 40| Step: 0
Training loss: 2.778688669204712
Validation loss: 2.759381604451005

Epoch: 5| Step: 1
Training loss: 2.851597309112549
Validation loss: 2.760827044005035

Epoch: 5| Step: 2
Training loss: 3.8635430335998535
Validation loss: 2.763186849573607

Epoch: 5| Step: 3
Training loss: 2.5596938133239746
Validation loss: 2.7647257389560824

Epoch: 5| Step: 4
Training loss: 2.0793704986572266
Validation loss: 2.757167257288451

Epoch: 5| Step: 5
Training loss: 2.9066975116729736
Validation loss: 2.7571029816904375

Epoch: 5| Step: 6
Training loss: 2.610556125640869
Validation loss: 2.751846698022658

Epoch: 5| Step: 7
Training loss: 2.7153713703155518
Validation loss: 2.7500288614662747

Epoch: 5| Step: 8
Training loss: 2.7646567821502686
Validation loss: 2.753450180894585

Epoch: 5| Step: 9
Training loss: 3.367189884185791
Validation loss: 2.750691265188238

Epoch: 5| Step: 10
Training loss: 3.197244644165039
Validation loss: 2.749683713400236

Epoch: 41| Step: 0
Training loss: 2.6522040367126465
Validation loss: 2.7458435899467877

Epoch: 5| Step: 1
Training loss: 3.6558165550231934
Validation loss: 2.7460584179047616

Epoch: 5| Step: 2
Training loss: 2.980794668197632
Validation loss: 2.748418697746851

Epoch: 5| Step: 3
Training loss: 3.027322769165039
Validation loss: 2.7422227551860194

Epoch: 5| Step: 4
Training loss: 2.3901450634002686
Validation loss: 2.74572919261071

Epoch: 5| Step: 5
Training loss: 2.785642385482788
Validation loss: 2.745551324659778

Epoch: 5| Step: 6
Training loss: 3.0723137855529785
Validation loss: 2.740957221677226

Epoch: 5| Step: 7
Training loss: 1.937135100364685
Validation loss: 2.740711437758579

Epoch: 5| Step: 8
Training loss: 3.372692823410034
Validation loss: 2.7408022598553727

Epoch: 5| Step: 9
Training loss: 2.8871750831604004
Validation loss: 2.7412860444796983

Epoch: 5| Step: 10
Training loss: 2.716115713119507
Validation loss: 2.737390197733397

Epoch: 42| Step: 0
Training loss: 2.8135178089141846
Validation loss: 2.741547643497426

Epoch: 5| Step: 1
Training loss: 3.093721866607666
Validation loss: 2.744204285324261

Epoch: 5| Step: 2
Training loss: 2.6927590370178223
Validation loss: 2.7429404258728027

Epoch: 5| Step: 3
Training loss: 2.851236343383789
Validation loss: 2.755305767059326

Epoch: 5| Step: 4
Training loss: 3.240734100341797
Validation loss: 2.7549940924490652

Epoch: 5| Step: 5
Training loss: 3.2367916107177734
Validation loss: 2.7474210031570925

Epoch: 5| Step: 6
Training loss: 2.6739001274108887
Validation loss: 2.737614788034911

Epoch: 5| Step: 7
Training loss: 2.5550498962402344
Validation loss: 2.7398354904626006

Epoch: 5| Step: 8
Training loss: 2.1729376316070557
Validation loss: 2.73352147686866

Epoch: 5| Step: 9
Training loss: 2.698509931564331
Validation loss: 2.734871059335688

Epoch: 5| Step: 10
Training loss: 3.5658931732177734
Validation loss: 2.7355577612435944

Epoch: 43| Step: 0
Training loss: 2.466078519821167
Validation loss: 2.7316125131422475

Epoch: 5| Step: 1
Training loss: 3.346179962158203
Validation loss: 2.733034672275666

Epoch: 5| Step: 2
Training loss: 2.6764144897460938
Validation loss: 2.7369905543583695

Epoch: 5| Step: 3
Training loss: 3.726193904876709
Validation loss: 2.730590412693639

Epoch: 5| Step: 4
Training loss: 2.31310772895813
Validation loss: 2.732372383917532

Epoch: 5| Step: 5
Training loss: 2.386565923690796
Validation loss: 2.7280929806411907

Epoch: 5| Step: 6
Training loss: 2.111093521118164
Validation loss: 2.732136003432735

Epoch: 5| Step: 7
Training loss: 3.0769131183624268
Validation loss: 2.7302630152753604

Epoch: 5| Step: 8
Training loss: 3.157585620880127
Validation loss: 2.728297971910046

Epoch: 5| Step: 9
Training loss: 2.88995099067688
Validation loss: 2.7345765713722474

Epoch: 5| Step: 10
Training loss: 3.404916763305664
Validation loss: 2.7324739399776665

Epoch: 44| Step: 0
Training loss: 3.5287203788757324
Validation loss: 2.7327198443874234

Epoch: 5| Step: 1
Training loss: 2.7547144889831543
Validation loss: 2.728956894208026

Epoch: 5| Step: 2
Training loss: 3.513740062713623
Validation loss: 2.7309301822416243

Epoch: 5| Step: 3
Training loss: 3.038060426712036
Validation loss: 2.726829946682017

Epoch: 5| Step: 4
Training loss: 2.6440560817718506
Validation loss: 2.727535399057532

Epoch: 5| Step: 5
Training loss: 2.29484224319458
Validation loss: 2.7263424088878017

Epoch: 5| Step: 6
Training loss: 2.332063913345337
Validation loss: 2.722158314079367

Epoch: 5| Step: 7
Training loss: 3.0284335613250732
Validation loss: 2.721761529163648

Epoch: 5| Step: 8
Training loss: 2.555732250213623
Validation loss: 2.72985743194498

Epoch: 5| Step: 9
Training loss: 2.5852978229522705
Validation loss: 2.726422930276522

Epoch: 5| Step: 10
Training loss: 3.1373231410980225
Validation loss: 2.7246828848315823

Epoch: 45| Step: 0
Training loss: 2.8584635257720947
Validation loss: 2.72217454448823

Epoch: 5| Step: 1
Training loss: 2.7560667991638184
Validation loss: 2.7201959599730787

Epoch: 5| Step: 2
Training loss: 2.9754390716552734
Validation loss: 2.7212768216286936

Epoch: 5| Step: 3
Training loss: 3.1596007347106934
Validation loss: 2.7187750647144933

Epoch: 5| Step: 4
Training loss: 2.622706890106201
Validation loss: 2.7264385325934297

Epoch: 5| Step: 5
Training loss: 2.647977828979492
Validation loss: 2.7232638507760982

Epoch: 5| Step: 6
Training loss: 2.9106595516204834
Validation loss: 2.72636386399628

Epoch: 5| Step: 7
Training loss: 3.1650900840759277
Validation loss: 2.727030555407206

Epoch: 5| Step: 8
Training loss: 2.7689528465270996
Validation loss: 2.723615805308024

Epoch: 5| Step: 9
Training loss: 2.5150530338287354
Validation loss: 2.7342487970987954

Epoch: 5| Step: 10
Training loss: 2.9717049598693848
Validation loss: 2.7327633391144457

Epoch: 46| Step: 0
Training loss: 3.0219597816467285
Validation loss: 2.7110645027570826

Epoch: 5| Step: 1
Training loss: 3.6236891746520996
Validation loss: 2.7131614890149844

Epoch: 5| Step: 2
Training loss: 2.304220676422119
Validation loss: 2.716195919180429

Epoch: 5| Step: 3
Training loss: 2.720283269882202
Validation loss: 2.7188663764666487

Epoch: 5| Step: 4
Training loss: 2.6190247535705566
Validation loss: 2.7304185077708256

Epoch: 5| Step: 5
Training loss: 2.435304641723633
Validation loss: 2.74057952819332

Epoch: 5| Step: 6
Training loss: 2.9382941722869873
Validation loss: 2.7354453840563373

Epoch: 5| Step: 7
Training loss: 3.144608974456787
Validation loss: 2.7177809310215775

Epoch: 5| Step: 8
Training loss: 2.8606715202331543
Validation loss: 2.7142077030674105

Epoch: 5| Step: 9
Training loss: 2.487006425857544
Validation loss: 2.711934120424332

Epoch: 5| Step: 10
Training loss: 3.2050223350524902
Validation loss: 2.708257862316665

Epoch: 47| Step: 0
Training loss: 2.630516767501831
Validation loss: 2.7117247555845525

Epoch: 5| Step: 1
Training loss: 3.0558032989501953
Validation loss: 2.717135762655607

Epoch: 5| Step: 2
Training loss: 2.6127071380615234
Validation loss: 2.716047999679401

Epoch: 5| Step: 3
Training loss: 2.4663031101226807
Validation loss: 2.710145527316678

Epoch: 5| Step: 4
Training loss: 3.34135365486145
Validation loss: 2.7082895284057944

Epoch: 5| Step: 5
Training loss: 2.7539286613464355
Validation loss: 2.7064901577529086

Epoch: 5| Step: 6
Training loss: 2.9942281246185303
Validation loss: 2.7099131358567106

Epoch: 5| Step: 7
Training loss: 3.2336418628692627
Validation loss: 2.7077374637767835

Epoch: 5| Step: 8
Training loss: 3.1183576583862305
Validation loss: 2.706854289577853

Epoch: 5| Step: 9
Training loss: 2.4670872688293457
Validation loss: 2.71165939300291

Epoch: 5| Step: 10
Training loss: 2.525533676147461
Validation loss: 2.7192694192291587

Epoch: 48| Step: 0
Training loss: 2.2028250694274902
Validation loss: 2.7174423330573627

Epoch: 5| Step: 1
Training loss: 2.741652011871338
Validation loss: 2.7185638719989407

Epoch: 5| Step: 2
Training loss: 2.839794635772705
Validation loss: 2.715613806119529

Epoch: 5| Step: 3
Training loss: 3.5463600158691406
Validation loss: 2.719234340934343

Epoch: 5| Step: 4
Training loss: 3.292611598968506
Validation loss: 2.718328606697821

Epoch: 5| Step: 5
Training loss: 2.787222385406494
Validation loss: 2.7166185199573474

Epoch: 5| Step: 6
Training loss: 2.7498745918273926
Validation loss: 2.7133691439064602

Epoch: 5| Step: 7
Training loss: 2.4463064670562744
Validation loss: 2.7119046898298365

Epoch: 5| Step: 8
Training loss: 2.778876543045044
Validation loss: 2.7014648247790594

Epoch: 5| Step: 9
Training loss: 3.283674716949463
Validation loss: 2.707926704037574

Epoch: 5| Step: 10
Training loss: 2.5336129665374756
Validation loss: 2.7058249622262935

Epoch: 49| Step: 0
Training loss: 3.520220994949341
Validation loss: 2.701473876994143

Epoch: 5| Step: 1
Training loss: 2.763701915740967
Validation loss: 2.7071029140103247

Epoch: 5| Step: 2
Training loss: 3.2871384620666504
Validation loss: 2.7099272768984557

Epoch: 5| Step: 3
Training loss: 2.1323599815368652
Validation loss: 2.706682825601229

Epoch: 5| Step: 4
Training loss: 2.892340898513794
Validation loss: 2.7008758693613033

Epoch: 5| Step: 5
Training loss: 2.537200927734375
Validation loss: 2.7030328448100756

Epoch: 5| Step: 6
Training loss: 3.155038833618164
Validation loss: 2.6968734008009716

Epoch: 5| Step: 7
Training loss: 3.137098789215088
Validation loss: 2.6945561901215584

Epoch: 5| Step: 8
Training loss: 2.592240571975708
Validation loss: 2.7000813535464707

Epoch: 5| Step: 9
Training loss: 2.8810155391693115
Validation loss: 2.701732735480032

Epoch: 5| Step: 10
Training loss: 2.2113006114959717
Validation loss: 2.7170168046028382

Epoch: 50| Step: 0
Training loss: 3.1093032360076904
Validation loss: 2.715879681289837

Epoch: 5| Step: 1
Training loss: 3.3198673725128174
Validation loss: 2.7147179777904222

Epoch: 5| Step: 2
Training loss: 2.4457314014434814
Validation loss: 2.704601441660235

Epoch: 5| Step: 3
Training loss: 2.749729633331299
Validation loss: 2.69947991319882

Epoch: 5| Step: 4
Training loss: 2.8806309700012207
Validation loss: 2.7014813346247517

Epoch: 5| Step: 5
Training loss: 3.1539885997772217
Validation loss: 2.7002287731375745

Epoch: 5| Step: 6
Training loss: 3.0114378929138184
Validation loss: 2.697115282858572

Epoch: 5| Step: 7
Training loss: 2.5700793266296387
Validation loss: 2.6973296185975433

Epoch: 5| Step: 8
Training loss: 2.994673013687134
Validation loss: 2.693474995192661

Epoch: 5| Step: 9
Training loss: 2.394315004348755
Validation loss: 2.6927269094733783

Epoch: 5| Step: 10
Training loss: 2.4618756771087646
Validation loss: 2.692859944476876

Epoch: 51| Step: 0
Training loss: 3.4753315448760986
Validation loss: 2.6915527646259596

Epoch: 5| Step: 1
Training loss: 3.5187182426452637
Validation loss: 2.6921358980158323

Epoch: 5| Step: 2
Training loss: 1.8772900104522705
Validation loss: 2.688450095474079

Epoch: 5| Step: 3
Training loss: 2.2642407417297363
Validation loss: 2.694310054984144

Epoch: 5| Step: 4
Training loss: 3.035700559616089
Validation loss: 2.693616456882928

Epoch: 5| Step: 5
Training loss: 2.2119476795196533
Validation loss: 2.687462411901002

Epoch: 5| Step: 6
Training loss: 3.533564805984497
Validation loss: 2.6915533286268993

Epoch: 5| Step: 7
Training loss: 3.0057549476623535
Validation loss: 2.689900449527207

Epoch: 5| Step: 8
Training loss: 2.810739040374756
Validation loss: 2.6886327651239212

Epoch: 5| Step: 9
Training loss: 2.9405479431152344
Validation loss: 2.6911083498308734

Epoch: 5| Step: 10
Training loss: 2.361837148666382
Validation loss: 2.6875581408059723

Epoch: 52| Step: 0
Training loss: 2.4452383518218994
Validation loss: 2.682562087171821

Epoch: 5| Step: 1
Training loss: 3.2616119384765625
Validation loss: 2.681605541577903

Epoch: 5| Step: 2
Training loss: 2.887969970703125
Validation loss: 2.683905481010355

Epoch: 5| Step: 3
Training loss: 2.4484317302703857
Validation loss: 2.678731290243005

Epoch: 5| Step: 4
Training loss: 2.3890862464904785
Validation loss: 2.6786289548361175

Epoch: 5| Step: 5
Training loss: 3.2424073219299316
Validation loss: 2.6790469231144076

Epoch: 5| Step: 6
Training loss: 3.267561674118042
Validation loss: 2.6784209025803434

Epoch: 5| Step: 7
Training loss: 3.013036012649536
Validation loss: 2.6812407637155182

Epoch: 5| Step: 8
Training loss: 2.248215913772583
Validation loss: 2.6768236980643323

Epoch: 5| Step: 9
Training loss: 2.934032917022705
Validation loss: 2.6818336158670406

Epoch: 5| Step: 10
Training loss: 2.9281699657440186
Validation loss: 2.6819663278518187

Epoch: 53| Step: 0
Training loss: 2.6296181678771973
Validation loss: 2.676483705479612

Epoch: 5| Step: 1
Training loss: 3.141005516052246
Validation loss: 2.679151222270022

Epoch: 5| Step: 2
Training loss: 2.8231472969055176
Validation loss: 2.6801737380284134

Epoch: 5| Step: 3
Training loss: 3.6856040954589844
Validation loss: 2.676606403884067

Epoch: 5| Step: 4
Training loss: 2.7427821159362793
Validation loss: 2.6775305399330716

Epoch: 5| Step: 5
Training loss: 3.345238447189331
Validation loss: 2.6768986794256393

Epoch: 5| Step: 6
Training loss: 3.1850104331970215
Validation loss: 2.6744718218362458

Epoch: 5| Step: 7
Training loss: 2.195894956588745
Validation loss: 2.6760076630500054

Epoch: 5| Step: 8
Training loss: 1.8597968816757202
Validation loss: 2.676086410399406

Epoch: 5| Step: 9
Training loss: 2.9422459602355957
Validation loss: 2.680933085821008

Epoch: 5| Step: 10
Training loss: 2.3731253147125244
Validation loss: 2.6861232301240325

Epoch: 54| Step: 0
Training loss: 3.6034648418426514
Validation loss: 2.6925521307094122

Epoch: 5| Step: 1
Training loss: 3.3129444122314453
Validation loss: 2.7012033693252073

Epoch: 5| Step: 2
Training loss: 2.5486416816711426
Validation loss: 2.681033052423949

Epoch: 5| Step: 3
Training loss: 2.009953260421753
Validation loss: 2.682089562057167

Epoch: 5| Step: 4
Training loss: 3.566479206085205
Validation loss: 2.6771777599088606

Epoch: 5| Step: 5
Training loss: 2.6619820594787598
Validation loss: 2.6741510821926977

Epoch: 5| Step: 6
Training loss: 3.295424699783325
Validation loss: 2.672670333616195

Epoch: 5| Step: 7
Training loss: 2.411633014678955
Validation loss: 2.6741459933660363

Epoch: 5| Step: 8
Training loss: 2.728208303451538
Validation loss: 2.6728650062314925

Epoch: 5| Step: 9
Training loss: 2.7297489643096924
Validation loss: 2.673832344752486

Epoch: 5| Step: 10
Training loss: 2.0010671615600586
Validation loss: 2.6732537566974597

Epoch: 55| Step: 0
Training loss: 3.0301172733306885
Validation loss: 2.6727593150190128

Epoch: 5| Step: 1
Training loss: 2.80072021484375
Validation loss: 2.677330196544688

Epoch: 5| Step: 2
Training loss: 2.0161826610565186
Validation loss: 2.6738876655537593

Epoch: 5| Step: 3
Training loss: 3.3117785453796387
Validation loss: 2.673496059192124

Epoch: 5| Step: 4
Training loss: 1.9569851160049438
Validation loss: 2.67749455154583

Epoch: 5| Step: 5
Training loss: 2.904735565185547
Validation loss: 2.6770890707610757

Epoch: 5| Step: 6
Training loss: 3.209918975830078
Validation loss: 2.6736705021191667

Epoch: 5| Step: 7
Training loss: 2.0533785820007324
Validation loss: 2.674121697743734

Epoch: 5| Step: 8
Training loss: 3.167293071746826
Validation loss: 2.6697448658686813

Epoch: 5| Step: 9
Training loss: 3.3993003368377686
Validation loss: 2.6697314580281577

Epoch: 5| Step: 10
Training loss: 3.123642921447754
Validation loss: 2.67125214299848

Epoch: 56| Step: 0
Training loss: 2.731745481491089
Validation loss: 2.6687867231266473

Epoch: 5| Step: 1
Training loss: 3.1280758380889893
Validation loss: 2.6690170764923096

Epoch: 5| Step: 2
Training loss: 2.903285503387451
Validation loss: 2.6685426517199446

Epoch: 5| Step: 3
Training loss: 3.4394240379333496
Validation loss: 2.6645065225580686

Epoch: 5| Step: 4
Training loss: 3.092219352722168
Validation loss: 2.6675921691361295

Epoch: 5| Step: 5
Training loss: 2.1279265880584717
Validation loss: 2.6614151436795472

Epoch: 5| Step: 6
Training loss: 2.1034178733825684
Validation loss: 2.663818823393955

Epoch: 5| Step: 7
Training loss: 3.392876148223877
Validation loss: 2.6640277370329826

Epoch: 5| Step: 8
Training loss: 2.349472761154175
Validation loss: 2.6622991074797926

Epoch: 5| Step: 9
Training loss: 2.672661066055298
Validation loss: 2.6658474553015923

Epoch: 5| Step: 10
Training loss: 2.9565250873565674
Validation loss: 2.66618094136638

Epoch: 57| Step: 0
Training loss: 2.829578399658203
Validation loss: 2.6691187991890857

Epoch: 5| Step: 1
Training loss: 2.934314250946045
Validation loss: 2.684133065644131

Epoch: 5| Step: 2
Training loss: 2.906677484512329
Validation loss: 2.681717993110739

Epoch: 5| Step: 3
Training loss: 2.9520955085754395
Validation loss: 2.6824178003495738

Epoch: 5| Step: 4
Training loss: 2.602240800857544
Validation loss: 2.678258231891099

Epoch: 5| Step: 5
Training loss: 2.894871711730957
Validation loss: 2.6743294551808345

Epoch: 5| Step: 6
Training loss: 2.681243419647217
Validation loss: 2.6587099208626697

Epoch: 5| Step: 7
Training loss: 2.7133240699768066
Validation loss: 2.659310858736756

Epoch: 5| Step: 8
Training loss: 2.863013982772827
Validation loss: 2.6577327687253236

Epoch: 5| Step: 9
Training loss: 2.8766534328460693
Validation loss: 2.6541390931734474

Epoch: 5| Step: 10
Training loss: 2.659147262573242
Validation loss: 2.659834995064684

Epoch: 58| Step: 0
Training loss: 2.46193528175354
Validation loss: 2.6599163034910798

Epoch: 5| Step: 1
Training loss: 2.726384401321411
Validation loss: 2.657934142697242

Epoch: 5| Step: 2
Training loss: 2.7329821586608887
Validation loss: 2.655697730279738

Epoch: 5| Step: 3
Training loss: 3.093902349472046
Validation loss: 2.6525266760139057

Epoch: 5| Step: 4
Training loss: 3.5048117637634277
Validation loss: 2.6605442954647924

Epoch: 5| Step: 5
Training loss: 3.3020992279052734
Validation loss: 2.656857018829674

Epoch: 5| Step: 6
Training loss: 2.713756799697876
Validation loss: 2.656684208941716

Epoch: 5| Step: 7
Training loss: 2.4999382495880127
Validation loss: 2.6614320303804133

Epoch: 5| Step: 8
Training loss: 3.2226250171661377
Validation loss: 2.6604653584059847

Epoch: 5| Step: 9
Training loss: 1.8944305181503296
Validation loss: 2.6555984276597218

Epoch: 5| Step: 10
Training loss: 2.6160366535186768
Validation loss: 2.659144301568308

Epoch: 59| Step: 0
Training loss: 2.586306095123291
Validation loss: 2.6626151607882593

Epoch: 5| Step: 1
Training loss: 2.9862301349639893
Validation loss: 2.6585885709331882

Epoch: 5| Step: 2
Training loss: 2.2421536445617676
Validation loss: 2.65748990479336

Epoch: 5| Step: 3
Training loss: 3.619074583053589
Validation loss: 2.6502144464882473

Epoch: 5| Step: 4
Training loss: 3.212210178375244
Validation loss: 2.6528958197562926

Epoch: 5| Step: 5
Training loss: 2.2233705520629883
Validation loss: 2.6536977470562024

Epoch: 5| Step: 6
Training loss: 2.789119005203247
Validation loss: 2.6558170472421954

Epoch: 5| Step: 7
Training loss: 2.523010730743408
Validation loss: 2.6505494630464943

Epoch: 5| Step: 8
Training loss: 2.5471463203430176
Validation loss: 2.6514781162302983

Epoch: 5| Step: 9
Training loss: 3.147124767303467
Validation loss: 2.649006679493894

Epoch: 5| Step: 10
Training loss: 2.8510725498199463
Validation loss: 2.654221252728534

Epoch: 60| Step: 0
Training loss: 2.9551920890808105
Validation loss: 2.6484974968817925

Epoch: 5| Step: 1
Training loss: 2.854647159576416
Validation loss: 2.6486347208740892

Epoch: 5| Step: 2
Training loss: 2.585026264190674
Validation loss: 2.6508096597527944

Epoch: 5| Step: 3
Training loss: 2.2158546447753906
Validation loss: 2.6456477206240416

Epoch: 5| Step: 4
Training loss: 2.9017343521118164
Validation loss: 2.6461049946405555

Epoch: 5| Step: 5
Training loss: 2.9314372539520264
Validation loss: 2.647800435302078

Epoch: 5| Step: 6
Training loss: 2.5478177070617676
Validation loss: 2.6557049623099704

Epoch: 5| Step: 7
Training loss: 3.2874298095703125
Validation loss: 2.6518495518674134

Epoch: 5| Step: 8
Training loss: 2.8017611503601074
Validation loss: 2.644604129175986

Epoch: 5| Step: 9
Training loss: 2.9237513542175293
Validation loss: 2.641986221395513

Epoch: 5| Step: 10
Training loss: 2.7924418449401855
Validation loss: 2.6420745849609375

Epoch: 61| Step: 0
Training loss: 3.3184974193573
Validation loss: 2.641474885325278

Epoch: 5| Step: 1
Training loss: 3.116316795349121
Validation loss: 2.642294463290963

Epoch: 5| Step: 2
Training loss: 2.7077102661132812
Validation loss: 2.6444758445985856

Epoch: 5| Step: 3
Training loss: 2.6382689476013184
Validation loss: 2.643855712747061

Epoch: 5| Step: 4
Training loss: 2.6964523792266846
Validation loss: 2.645783842250865

Epoch: 5| Step: 5
Training loss: 2.1812644004821777
Validation loss: 2.646029057041291

Epoch: 5| Step: 6
Training loss: 2.2635369300842285
Validation loss: 2.6425942887542067

Epoch: 5| Step: 7
Training loss: 3.200326442718506
Validation loss: 2.641646933811967

Epoch: 5| Step: 8
Training loss: 2.8044803142547607
Validation loss: 2.6375565118687128

Epoch: 5| Step: 9
Training loss: 3.0053470134735107
Validation loss: 2.6371764957263903

Epoch: 5| Step: 10
Training loss: 2.724041700363159
Validation loss: 2.6416166443978586

Epoch: 62| Step: 0
Training loss: 2.569628953933716
Validation loss: 2.641712778358049

Epoch: 5| Step: 1
Training loss: 2.817548990249634
Validation loss: 2.636993174911827

Epoch: 5| Step: 2
Training loss: 2.2706844806671143
Validation loss: 2.639102679426952

Epoch: 5| Step: 3
Training loss: 2.705676317214966
Validation loss: 2.643737731441375

Epoch: 5| Step: 4
Training loss: 2.829420566558838
Validation loss: 2.6465577207585818

Epoch: 5| Step: 5
Training loss: 2.6207714080810547
Validation loss: 2.6484541303368023

Epoch: 5| Step: 6
Training loss: 2.5314815044403076
Validation loss: 2.652207351499988

Epoch: 5| Step: 7
Training loss: 3.5036208629608154
Validation loss: 2.6550200318777435

Epoch: 5| Step: 8
Training loss: 3.1844263076782227
Validation loss: 2.645083240283433

Epoch: 5| Step: 9
Training loss: 2.8935906887054443
Validation loss: 2.6398215601521153

Epoch: 5| Step: 10
Training loss: 2.7396063804626465
Validation loss: 2.6349207252584477

Epoch: 63| Step: 0
Training loss: 2.558323621749878
Validation loss: 2.6348934532493673

Epoch: 5| Step: 1
Training loss: 2.8963379859924316
Validation loss: 2.6370341700892292

Epoch: 5| Step: 2
Training loss: 3.4319300651550293
Validation loss: 2.6375290629684285

Epoch: 5| Step: 3
Training loss: 2.718687057495117
Validation loss: 2.6366168273392545

Epoch: 5| Step: 4
Training loss: 2.0849480628967285
Validation loss: 2.6391840878353325

Epoch: 5| Step: 5
Training loss: 3.28568959236145
Validation loss: 2.6384055845199095

Epoch: 5| Step: 6
Training loss: 2.471400737762451
Validation loss: 2.637671983370217

Epoch: 5| Step: 7
Training loss: 3.466916561126709
Validation loss: 2.636935111015074

Epoch: 5| Step: 8
Training loss: 2.5604069232940674
Validation loss: 2.6415913335738646

Epoch: 5| Step: 9
Training loss: 2.9148058891296387
Validation loss: 2.642229800583214

Epoch: 5| Step: 10
Training loss: 2.216843366622925
Validation loss: 2.640093395786901

Epoch: 64| Step: 0
Training loss: 2.5311386585235596
Validation loss: 2.6521115482494397

Epoch: 5| Step: 1
Training loss: 3.3504550457000732
Validation loss: 2.6436058808398504

Epoch: 5| Step: 2
Training loss: 2.7429394721984863
Validation loss: 2.6470083754549742

Epoch: 5| Step: 3
Training loss: 2.8207011222839355
Validation loss: 2.6368950848938315

Epoch: 5| Step: 4
Training loss: 1.8878319263458252
Validation loss: 2.630433526090396

Epoch: 5| Step: 5
Training loss: 2.8640856742858887
Validation loss: 2.6285826852244716

Epoch: 5| Step: 6
Training loss: 3.2167935371398926
Validation loss: 2.6263977481472875

Epoch: 5| Step: 7
Training loss: 2.362675189971924
Validation loss: 2.629822725890785

Epoch: 5| Step: 8
Training loss: 3.621366024017334
Validation loss: 2.631630115611579

Epoch: 5| Step: 9
Training loss: 2.4583449363708496
Validation loss: 2.635695575385965

Epoch: 5| Step: 10
Training loss: 2.713693380355835
Validation loss: 2.649121910013178

Epoch: 65| Step: 0
Training loss: 2.652360439300537
Validation loss: 2.6489818762707453

Epoch: 5| Step: 1
Training loss: 2.611746311187744
Validation loss: 2.6469501859398297

Epoch: 5| Step: 2
Training loss: 3.0612711906433105
Validation loss: 2.6328691359489196

Epoch: 5| Step: 3
Training loss: 2.7039506435394287
Validation loss: 2.6319592845055366

Epoch: 5| Step: 4
Training loss: 2.4835894107818604
Validation loss: 2.6344017290299937

Epoch: 5| Step: 5
Training loss: 2.613236904144287
Validation loss: 2.6320790667687692

Epoch: 5| Step: 6
Training loss: 3.3184821605682373
Validation loss: 2.6306057283955235

Epoch: 5| Step: 7
Training loss: 3.0239737033843994
Validation loss: 2.628195949780044

Epoch: 5| Step: 8
Training loss: 2.566516399383545
Validation loss: 2.6290005125025266

Epoch: 5| Step: 9
Training loss: 2.5935890674591064
Validation loss: 2.628181921538486

Epoch: 5| Step: 10
Training loss: 3.007643699645996
Validation loss: 2.62623502362159

Epoch: 66| Step: 0
Training loss: 2.933769702911377
Validation loss: 2.6270354050461964

Epoch: 5| Step: 1
Training loss: 2.6408798694610596
Validation loss: 2.625570704860072

Epoch: 5| Step: 2
Training loss: 2.657987356185913
Validation loss: 2.620026006493517

Epoch: 5| Step: 3
Training loss: 3.2967963218688965
Validation loss: 2.616056062841928

Epoch: 5| Step: 4
Training loss: 3.175898313522339
Validation loss: 2.618198258902437

Epoch: 5| Step: 5
Training loss: 2.06489634513855
Validation loss: 2.618248678022815

Epoch: 5| Step: 6
Training loss: 2.3260021209716797
Validation loss: 2.616102618555869

Epoch: 5| Step: 7
Training loss: 3.348266124725342
Validation loss: 2.6137540430151005

Epoch: 5| Step: 8
Training loss: 2.8937530517578125
Validation loss: 2.615265666797597

Epoch: 5| Step: 9
Training loss: 2.66634464263916
Validation loss: 2.6131696624140583

Epoch: 5| Step: 10
Training loss: 2.424602508544922
Validation loss: 2.622065287764354

Epoch: 67| Step: 0
Training loss: 2.700892925262451
Validation loss: 2.628319268585533

Epoch: 5| Step: 1
Training loss: 2.8029608726501465
Validation loss: 2.6221092542012534

Epoch: 5| Step: 2
Training loss: 2.162153720855713
Validation loss: 2.6174475736515497

Epoch: 5| Step: 3
Training loss: 2.7929494380950928
Validation loss: 2.612259872498051

Epoch: 5| Step: 4
Training loss: 4.00345516204834
Validation loss: 2.6116042137145996

Epoch: 5| Step: 5
Training loss: 2.5735247135162354
Validation loss: 2.6072121640687347

Epoch: 5| Step: 6
Training loss: 2.255549907684326
Validation loss: 2.60576533245784

Epoch: 5| Step: 7
Training loss: 2.941767454147339
Validation loss: 2.6025281567727365

Epoch: 5| Step: 8
Training loss: 3.211181640625
Validation loss: 2.60411577070913

Epoch: 5| Step: 9
Training loss: 2.360604763031006
Validation loss: 2.599926769092519

Epoch: 5| Step: 10
Training loss: 2.5701847076416016
Validation loss: 2.604516495940506

Epoch: 68| Step: 0
Training loss: 3.337085247039795
Validation loss: 2.5986358811778407

Epoch: 5| Step: 1
Training loss: 2.789339780807495
Validation loss: 2.598148230583437

Epoch: 5| Step: 2
Training loss: 2.248631238937378
Validation loss: 2.6046977696880216

Epoch: 5| Step: 3
Training loss: 1.9745979309082031
Validation loss: 2.6081079436886694

Epoch: 5| Step: 4
Training loss: 3.2774300575256348
Validation loss: 2.620742531232936

Epoch: 5| Step: 5
Training loss: 2.73777174949646
Validation loss: 2.6279317102124615

Epoch: 5| Step: 6
Training loss: 3.148221969604492
Validation loss: 2.622367884523125

Epoch: 5| Step: 7
Training loss: 2.972325086593628
Validation loss: 2.603636987747685

Epoch: 5| Step: 8
Training loss: 2.655035972595215
Validation loss: 2.595299241363361

Epoch: 5| Step: 9
Training loss: 2.5724921226501465
Validation loss: 2.597249182321692

Epoch: 5| Step: 10
Training loss: 2.7011847496032715
Validation loss: 2.598443005674629

Epoch: 69| Step: 0
Training loss: 2.760856866836548
Validation loss: 2.5992545953360935

Epoch: 5| Step: 1
Training loss: 2.8010449409484863
Validation loss: 2.5995661392006824

Epoch: 5| Step: 2
Training loss: 2.714327573776245
Validation loss: 2.604866676433112

Epoch: 5| Step: 3
Training loss: 2.8840880393981934
Validation loss: 2.6064578563936296

Epoch: 5| Step: 4
Training loss: 3.35369610786438
Validation loss: 2.604599401515017

Epoch: 5| Step: 5
Training loss: 2.326174259185791
Validation loss: 2.6098738485766995

Epoch: 5| Step: 6
Training loss: 2.9097352027893066
Validation loss: 2.6040710428709626

Epoch: 5| Step: 7
Training loss: 2.5830790996551514
Validation loss: 2.6177419488148024

Epoch: 5| Step: 8
Training loss: 1.8670002222061157
Validation loss: 2.59936402433662

Epoch: 5| Step: 9
Training loss: 2.935260772705078
Validation loss: 2.5971639117886944

Epoch: 5| Step: 10
Training loss: 3.361544132232666
Validation loss: 2.594517984697896

Epoch: 70| Step: 0
Training loss: 2.9077086448669434
Validation loss: 2.6039417918010423

Epoch: 5| Step: 1
Training loss: 2.6310935020446777
Validation loss: 2.601561471980105

Epoch: 5| Step: 2
Training loss: 3.2086806297302246
Validation loss: 2.6032612528852237

Epoch: 5| Step: 3
Training loss: 3.0970911979675293
Validation loss: 2.602123809117143

Epoch: 5| Step: 4
Training loss: 2.6151440143585205
Validation loss: 2.599865057135141

Epoch: 5| Step: 5
Training loss: 2.880584716796875
Validation loss: 2.596071009994835

Epoch: 5| Step: 6
Training loss: 2.7916157245635986
Validation loss: 2.5906981729692027

Epoch: 5| Step: 7
Training loss: 2.43607759475708
Validation loss: 2.592801358110161

Epoch: 5| Step: 8
Training loss: 3.0751545429229736
Validation loss: 2.594640936902774

Epoch: 5| Step: 9
Training loss: 2.2388033866882324
Validation loss: 2.5971577885330364

Epoch: 5| Step: 10
Training loss: 2.365793466567993
Validation loss: 2.5917703490103445

Epoch: 71| Step: 0
Training loss: 2.3419082164764404
Validation loss: 2.591202997392224

Epoch: 5| Step: 1
Training loss: 3.818527936935425
Validation loss: 2.5870802710133214

Epoch: 5| Step: 2
Training loss: 3.342071533203125
Validation loss: 2.58719140227123

Epoch: 5| Step: 3
Training loss: 3.092520236968994
Validation loss: 2.588813840702016

Epoch: 5| Step: 4
Training loss: 2.958265781402588
Validation loss: 2.5891574275109077

Epoch: 5| Step: 5
Training loss: 2.4998319149017334
Validation loss: 2.5894103280959593

Epoch: 5| Step: 6
Training loss: 2.9738497734069824
Validation loss: 2.592311530984858

Epoch: 5| Step: 7
Training loss: 2.072781801223755
Validation loss: 2.5913332072637414

Epoch: 5| Step: 8
Training loss: 1.916983962059021
Validation loss: 2.591353219042542

Epoch: 5| Step: 9
Training loss: 2.449669122695923
Validation loss: 2.592559878544141

Epoch: 5| Step: 10
Training loss: 2.8626632690429688
Validation loss: 2.5861182264102403

Epoch: 72| Step: 0
Training loss: 3.052861452102661
Validation loss: 2.589452079547349

Epoch: 5| Step: 1
Training loss: 2.74593186378479
Validation loss: 2.58503637518934

Epoch: 5| Step: 2
Training loss: 2.4562594890594482
Validation loss: 2.585346216796547

Epoch: 5| Step: 3
Training loss: 2.803864002227783
Validation loss: 2.5844929449019896

Epoch: 5| Step: 4
Training loss: 2.7683215141296387
Validation loss: 2.582941544953213

Epoch: 5| Step: 5
Training loss: 3.378676176071167
Validation loss: 2.5822553557734333

Epoch: 5| Step: 6
Training loss: 2.6473426818847656
Validation loss: 2.5789302831055014

Epoch: 5| Step: 7
Training loss: 2.8836021423339844
Validation loss: 2.5843527624683995

Epoch: 5| Step: 8
Training loss: 2.1473400592803955
Validation loss: 2.5887627242713847

Epoch: 5| Step: 9
Training loss: 2.230881452560425
Validation loss: 2.5900911131212787

Epoch: 5| Step: 10
Training loss: 3.2144246101379395
Validation loss: 2.589715391077021

Epoch: 73| Step: 0
Training loss: 2.5673317909240723
Validation loss: 2.5877692045704013

Epoch: 5| Step: 1
Training loss: 3.1754331588745117
Validation loss: 2.5889507660301785

Epoch: 5| Step: 2
Training loss: 2.751420259475708
Validation loss: 2.583227780557448

Epoch: 5| Step: 3
Training loss: 2.113393545150757
Validation loss: 2.5845224088238132

Epoch: 5| Step: 4
Training loss: 2.7688469886779785
Validation loss: 2.5823279760217153

Epoch: 5| Step: 5
Training loss: 3.020643949508667
Validation loss: 2.5868084917786303

Epoch: 5| Step: 6
Training loss: 2.7259905338287354
Validation loss: 2.5889278329828733

Epoch: 5| Step: 7
Training loss: 2.879976511001587
Validation loss: 2.59244813201248

Epoch: 5| Step: 8
Training loss: 3.250699281692505
Validation loss: 2.579727207460711

Epoch: 5| Step: 9
Training loss: 2.7022738456726074
Validation loss: 2.582492320768295

Epoch: 5| Step: 10
Training loss: 2.198840379714966
Validation loss: 2.581331394051993

Epoch: 74| Step: 0
Training loss: 2.8816018104553223
Validation loss: 2.584761952841154

Epoch: 5| Step: 1
Training loss: 2.545259952545166
Validation loss: 2.588524108291954

Epoch: 5| Step: 2
Training loss: 2.9928841590881348
Validation loss: 2.5874286313210764

Epoch: 5| Step: 3
Training loss: 2.568201780319214
Validation loss: 2.598671805474066

Epoch: 5| Step: 4
Training loss: 2.7525172233581543
Validation loss: 2.6023616226770545

Epoch: 5| Step: 5
Training loss: 2.6008007526397705
Validation loss: 2.6089672093750327

Epoch: 5| Step: 6
Training loss: 2.306947946548462
Validation loss: 2.608164384800901

Epoch: 5| Step: 7
Training loss: 3.2454001903533936
Validation loss: 2.5921438304326867

Epoch: 5| Step: 8
Training loss: 2.837714433670044
Validation loss: 2.5862999321312032

Epoch: 5| Step: 9
Training loss: 2.6689722537994385
Validation loss: 2.5801911200246503

Epoch: 5| Step: 10
Training loss: 2.8775973320007324
Validation loss: 2.579142916587091

Epoch: 75| Step: 0
Training loss: 2.7282965183258057
Validation loss: 2.5752531251599713

Epoch: 5| Step: 1
Training loss: 2.440504550933838
Validation loss: 2.573189761049004

Epoch: 5| Step: 2
Training loss: 2.7917068004608154
Validation loss: 2.576064009820261

Epoch: 5| Step: 3
Training loss: 2.3289904594421387
Validation loss: 2.5731127185206257

Epoch: 5| Step: 4
Training loss: 3.02070951461792
Validation loss: 2.5706526540940806

Epoch: 5| Step: 5
Training loss: 2.995737075805664
Validation loss: 2.572457044355331

Epoch: 5| Step: 6
Training loss: 2.2452712059020996
Validation loss: 2.573072953890729

Epoch: 5| Step: 7
Training loss: 3.2824974060058594
Validation loss: 2.572492814833118

Epoch: 5| Step: 8
Training loss: 3.1879425048828125
Validation loss: 2.568937163199148

Epoch: 5| Step: 9
Training loss: 2.955522060394287
Validation loss: 2.570674829585578

Epoch: 5| Step: 10
Training loss: 2.072158098220825
Validation loss: 2.5749155423974477

Epoch: 76| Step: 0
Training loss: 2.7505698204040527
Validation loss: 2.5718259606310117

Epoch: 5| Step: 1
Training loss: 2.492619752883911
Validation loss: 2.57816634895981

Epoch: 5| Step: 2
Training loss: 3.2030868530273438
Validation loss: 2.5687765549587946

Epoch: 5| Step: 3
Training loss: 2.8901684284210205
Validation loss: 2.5701101569719214

Epoch: 5| Step: 4
Training loss: 2.754685163497925
Validation loss: 2.5715155396410214

Epoch: 5| Step: 5
Training loss: 3.276209592819214
Validation loss: 2.5649723468288297

Epoch: 5| Step: 6
Training loss: 2.741401195526123
Validation loss: 2.571036015787432

Epoch: 5| Step: 7
Training loss: 2.3383517265319824
Validation loss: 2.5674693686987764

Epoch: 5| Step: 8
Training loss: 2.928001880645752
Validation loss: 2.5648857060299126

Epoch: 5| Step: 9
Training loss: 2.0923690795898438
Validation loss: 2.5649465181494273

Epoch: 5| Step: 10
Training loss: 2.6005899906158447
Validation loss: 2.5687294237075315

Epoch: 77| Step: 0
Training loss: 2.2276253700256348
Validation loss: 2.5642566809090237

Epoch: 5| Step: 1
Training loss: 2.423565626144409
Validation loss: 2.5604149321074128

Epoch: 5| Step: 2
Training loss: 2.4943008422851562
Validation loss: 2.557166096984699

Epoch: 5| Step: 3
Training loss: 2.215372085571289
Validation loss: 2.552706790226762

Epoch: 5| Step: 4
Training loss: 3.0826809406280518
Validation loss: 2.5549206964431272

Epoch: 5| Step: 5
Training loss: 2.8804080486297607
Validation loss: 2.5602943422973796

Epoch: 5| Step: 6
Training loss: 2.6021475791931152
Validation loss: 2.5625636449424167

Epoch: 5| Step: 7
Training loss: 2.9951226711273193
Validation loss: 2.5599932875684512

Epoch: 5| Step: 8
Training loss: 2.758025646209717
Validation loss: 2.5663435151500087

Epoch: 5| Step: 9
Training loss: 3.5173537731170654
Validation loss: 2.5599323831578737

Epoch: 5| Step: 10
Training loss: 2.8300583362579346
Validation loss: 2.558517409909156

Epoch: 78| Step: 0
Training loss: 2.7282803058624268
Validation loss: 2.562411415961481

Epoch: 5| Step: 1
Training loss: 2.2065606117248535
Validation loss: 2.559331122265067

Epoch: 5| Step: 2
Training loss: 3.010632276535034
Validation loss: 2.5648829475525887

Epoch: 5| Step: 3
Training loss: 3.148361921310425
Validation loss: 2.5639668844079457

Epoch: 5| Step: 4
Training loss: 2.3217716217041016
Validation loss: 2.555776988306353

Epoch: 5| Step: 5
Training loss: 3.1641457080841064
Validation loss: 2.5486057625021985

Epoch: 5| Step: 6
Training loss: 2.7543463706970215
Validation loss: 2.5484586890025804

Epoch: 5| Step: 7
Training loss: 2.6366372108459473
Validation loss: 2.5455250996415333

Epoch: 5| Step: 8
Training loss: 2.3808748722076416
Validation loss: 2.544980541352303

Epoch: 5| Step: 9
Training loss: 3.1222996711730957
Validation loss: 2.547989358184158

Epoch: 5| Step: 10
Training loss: 2.3962483406066895
Validation loss: 2.560997716842159

Epoch: 79| Step: 0
Training loss: 2.471522569656372
Validation loss: 2.5559644160732145

Epoch: 5| Step: 1
Training loss: 2.433486223220825
Validation loss: 2.5529688071179133

Epoch: 5| Step: 2
Training loss: 2.7482025623321533
Validation loss: 2.546446249049197

Epoch: 5| Step: 3
Training loss: 2.6143648624420166
Validation loss: 2.536967736418529

Epoch: 5| Step: 4
Training loss: 2.833071231842041
Validation loss: 2.544263844848961

Epoch: 5| Step: 5
Training loss: 3.4743289947509766
Validation loss: 2.5457028573559177

Epoch: 5| Step: 6
Training loss: 2.6039047241210938
Validation loss: 2.5467315027790685

Epoch: 5| Step: 7
Training loss: 2.4257102012634277
Validation loss: 2.5530383561247136

Epoch: 5| Step: 8
Training loss: 3.150407075881958
Validation loss: 2.555002507343087

Epoch: 5| Step: 9
Training loss: 3.125670909881592
Validation loss: 2.560572188387635

Epoch: 5| Step: 10
Training loss: 2.012662172317505
Validation loss: 2.551465731795116

Epoch: 80| Step: 0
Training loss: 3.0923068523406982
Validation loss: 2.545793858907556

Epoch: 5| Step: 1
Training loss: 2.954860210418701
Validation loss: 2.5361430670625422

Epoch: 5| Step: 2
Training loss: 2.4725637435913086
Validation loss: 2.5404424334085114

Epoch: 5| Step: 3
Training loss: 1.746792197227478
Validation loss: 2.5361624199856996

Epoch: 5| Step: 4
Training loss: 2.6155331134796143
Validation loss: 2.539511121729369

Epoch: 5| Step: 5
Training loss: 3.085251569747925
Validation loss: 2.5387101839947444

Epoch: 5| Step: 6
Training loss: 2.7167086601257324
Validation loss: 2.5361767815005396

Epoch: 5| Step: 7
Training loss: 2.7288601398468018
Validation loss: 2.535782721734816

Epoch: 5| Step: 8
Training loss: 2.7358713150024414
Validation loss: 2.5459113121032715

Epoch: 5| Step: 9
Training loss: 2.7104506492614746
Validation loss: 2.5501787713778916

Epoch: 5| Step: 10
Training loss: 3.2186176776885986
Validation loss: 2.552601391269315

Epoch: 81| Step: 0
Training loss: 2.8649849891662598
Validation loss: 2.5416302270786737

Epoch: 5| Step: 1
Training loss: 2.339937686920166
Validation loss: 2.5397601230170137

Epoch: 5| Step: 2
Training loss: 2.5696377754211426
Validation loss: 2.5380945231324885

Epoch: 5| Step: 3
Training loss: 1.9164543151855469
Validation loss: 2.5351935996804187

Epoch: 5| Step: 4
Training loss: 3.0229275226593018
Validation loss: 2.5359378655751548

Epoch: 5| Step: 5
Training loss: 2.82384991645813
Validation loss: 2.5332062808416222

Epoch: 5| Step: 6
Training loss: 2.9609272480010986
Validation loss: 2.534675851944954

Epoch: 5| Step: 7
Training loss: 2.764617681503296
Validation loss: 2.533119391369563

Epoch: 5| Step: 8
Training loss: 2.494170904159546
Validation loss: 2.5343190828959146

Epoch: 5| Step: 9
Training loss: 3.2268881797790527
Validation loss: 2.5392367403994323

Epoch: 5| Step: 10
Training loss: 2.9183435440063477
Validation loss: 2.532694944771387

Epoch: 82| Step: 0
Training loss: 2.724503993988037
Validation loss: 2.5400526908136185

Epoch: 5| Step: 1
Training loss: 2.494399309158325
Validation loss: 2.5403099188240628

Epoch: 5| Step: 2
Training loss: 2.8931660652160645
Validation loss: 2.5438643706742154

Epoch: 5| Step: 3
Training loss: 2.8897101879119873
Validation loss: 2.5429525272820586

Epoch: 5| Step: 4
Training loss: 2.2023873329162598
Validation loss: 2.5473181457929712

Epoch: 5| Step: 5
Training loss: 3.3125357627868652
Validation loss: 2.5454612547351467

Epoch: 5| Step: 6
Training loss: 2.035595655441284
Validation loss: 2.550278268834596

Epoch: 5| Step: 7
Training loss: 3.5051727294921875
Validation loss: 2.53981868169641

Epoch: 5| Step: 8
Training loss: 2.197183132171631
Validation loss: 2.5342147811766593

Epoch: 5| Step: 9
Training loss: 3.3811259269714355
Validation loss: 2.5351704448781986

Epoch: 5| Step: 10
Training loss: 2.131774425506592
Validation loss: 2.532047989547894

Epoch: 83| Step: 0
Training loss: 2.921384334564209
Validation loss: 2.532126849697482

Epoch: 5| Step: 1
Training loss: 2.30981707572937
Validation loss: 2.529705059143805

Epoch: 5| Step: 2
Training loss: 2.408212184906006
Validation loss: 2.5312250839766635

Epoch: 5| Step: 3
Training loss: 3.1176981925964355
Validation loss: 2.5360034550389936

Epoch: 5| Step: 4
Training loss: 3.1805644035339355
Validation loss: 2.533852464409285

Epoch: 5| Step: 5
Training loss: 2.3553080558776855
Validation loss: 2.5391854804049254

Epoch: 5| Step: 6
Training loss: 2.7746410369873047
Validation loss: 2.531340463187105

Epoch: 5| Step: 7
Training loss: 2.634549617767334
Validation loss: 2.541054928174583

Epoch: 5| Step: 8
Training loss: 2.317862033843994
Validation loss: 2.548224333793886

Epoch: 5| Step: 9
Training loss: 2.3502261638641357
Validation loss: 2.5529085846357447

Epoch: 5| Step: 10
Training loss: 3.6398963928222656
Validation loss: 2.550916482043523

Epoch: 84| Step: 0
Training loss: 2.7181785106658936
Validation loss: 2.541608400242303

Epoch: 5| Step: 1
Training loss: 2.529479503631592
Validation loss: 2.536091004648516

Epoch: 5| Step: 2
Training loss: 2.536367416381836
Validation loss: 2.521277217454808

Epoch: 5| Step: 3
Training loss: 2.890918254852295
Validation loss: 2.5265690972728114

Epoch: 5| Step: 4
Training loss: 2.0338454246520996
Validation loss: 2.527100580994801

Epoch: 5| Step: 5
Training loss: 2.8087334632873535
Validation loss: 2.5260536234865905

Epoch: 5| Step: 6
Training loss: 3.031585693359375
Validation loss: 2.5246699676718762

Epoch: 5| Step: 7
Training loss: 2.4120473861694336
Validation loss: 2.5297899912762385

Epoch: 5| Step: 8
Training loss: 3.071079730987549
Validation loss: 2.523579910237302

Epoch: 5| Step: 9
Training loss: 2.9936721324920654
Validation loss: 2.523483912150065

Epoch: 5| Step: 10
Training loss: 2.780855655670166
Validation loss: 2.523626163441648

Epoch: 85| Step: 0
Training loss: 3.103801727294922
Validation loss: 2.5191168862004436

Epoch: 5| Step: 1
Training loss: 3.1101927757263184
Validation loss: 2.5208877389149

Epoch: 5| Step: 2
Training loss: 2.305342197418213
Validation loss: 2.523073883466823

Epoch: 5| Step: 3
Training loss: 2.480346202850342
Validation loss: 2.5215643708423903

Epoch: 5| Step: 4
Training loss: 2.2290148735046387
Validation loss: 2.522345701853434

Epoch: 5| Step: 5
Training loss: 1.7763961553573608
Validation loss: 2.519692272268316

Epoch: 5| Step: 6
Training loss: 2.383171796798706
Validation loss: 2.5213855261443765

Epoch: 5| Step: 7
Training loss: 2.917131185531616
Validation loss: 2.5280099684192288

Epoch: 5| Step: 8
Training loss: 3.0454165935516357
Validation loss: 2.526611017924483

Epoch: 5| Step: 9
Training loss: 3.122169017791748
Validation loss: 2.52460564080105

Epoch: 5| Step: 10
Training loss: 3.346271276473999
Validation loss: 2.525449747680336

Epoch: 86| Step: 0
Training loss: 2.474872589111328
Validation loss: 2.5231104973823792

Epoch: 5| Step: 1
Training loss: 2.3423893451690674
Validation loss: 2.5207870160379717

Epoch: 5| Step: 2
Training loss: 2.146623134613037
Validation loss: 2.5196693610119563

Epoch: 5| Step: 3
Training loss: 3.263777494430542
Validation loss: 2.523232936859131

Epoch: 5| Step: 4
Training loss: 2.9324193000793457
Validation loss: 2.5271706094024

Epoch: 5| Step: 5
Training loss: 3.1775729656219482
Validation loss: 2.5228892577591764

Epoch: 5| Step: 6
Training loss: 2.6438188552856445
Validation loss: 2.5209186205299954

Epoch: 5| Step: 7
Training loss: 2.1955676078796387
Validation loss: 2.5211621484448834

Epoch: 5| Step: 8
Training loss: 3.2975947856903076
Validation loss: 2.519514504299369

Epoch: 5| Step: 9
Training loss: 2.747424602508545
Validation loss: 2.5208336614793345

Epoch: 5| Step: 10
Training loss: 2.5344817638397217
Validation loss: 2.5218478018237698

Epoch: 87| Step: 0
Training loss: 2.2482075691223145
Validation loss: 2.5223856356836136

Epoch: 5| Step: 1
Training loss: 2.810473680496216
Validation loss: 2.5170567163857083

Epoch: 5| Step: 2
Training loss: 3.0464000701904297
Validation loss: 2.5225242876237437

Epoch: 5| Step: 3
Training loss: 2.691911220550537
Validation loss: 2.5239261068323606

Epoch: 5| Step: 4
Training loss: 3.5573647022247314
Validation loss: 2.5255107572001796

Epoch: 5| Step: 5
Training loss: 2.0067801475524902
Validation loss: 2.527878051163048

Epoch: 5| Step: 6
Training loss: 2.4073684215545654
Validation loss: 2.523242650493499

Epoch: 5| Step: 7
Training loss: 3.0534889698028564
Validation loss: 2.5250447719327864

Epoch: 5| Step: 8
Training loss: 3.009216070175171
Validation loss: 2.5223918320030294

Epoch: 5| Step: 9
Training loss: 2.5995075702667236
Validation loss: 2.5244492792314097

Epoch: 5| Step: 10
Training loss: 2.2818379402160645
Validation loss: 2.5177935861772105

Epoch: 88| Step: 0
Training loss: 2.6414623260498047
Validation loss: 2.516179143741567

Epoch: 5| Step: 1
Training loss: 2.8612799644470215
Validation loss: 2.5146528725982993

Epoch: 5| Step: 2
Training loss: 2.419821262359619
Validation loss: 2.5178679804648123

Epoch: 5| Step: 3
Training loss: 2.450171709060669
Validation loss: 2.517053452871179

Epoch: 5| Step: 4
Training loss: 2.164626121520996
Validation loss: 2.5159158014482066

Epoch: 5| Step: 5
Training loss: 2.786052942276001
Validation loss: 2.514242838787776

Epoch: 5| Step: 6
Training loss: 2.811220169067383
Validation loss: 2.518794890372984

Epoch: 5| Step: 7
Training loss: 2.615412712097168
Validation loss: 2.5205046310219714

Epoch: 5| Step: 8
Training loss: 2.8219382762908936
Validation loss: 2.5208151519939466

Epoch: 5| Step: 9
Training loss: 3.1338741779327393
Validation loss: 2.5130377559251684

Epoch: 5| Step: 10
Training loss: 3.0403783321380615
Validation loss: 2.5198824585125013

Epoch: 89| Step: 0
Training loss: 2.07789945602417
Validation loss: 2.5224826540998233

Epoch: 5| Step: 1
Training loss: 2.3452398777008057
Validation loss: 2.5196835943447646

Epoch: 5| Step: 2
Training loss: 2.102447748184204
Validation loss: 2.525892585836431

Epoch: 5| Step: 3
Training loss: 2.9900383949279785
Validation loss: 2.5359994621687036

Epoch: 5| Step: 4
Training loss: 2.6644208431243896
Validation loss: 2.530020765078965

Epoch: 5| Step: 5
Training loss: 3.5314812660217285
Validation loss: 2.5180447050320205

Epoch: 5| Step: 6
Training loss: 3.0655813217163086
Validation loss: 2.5281909665753766

Epoch: 5| Step: 7
Training loss: 2.6734566688537598
Validation loss: 2.5223303456460275

Epoch: 5| Step: 8
Training loss: 2.9184746742248535
Validation loss: 2.5238345925525953

Epoch: 5| Step: 9
Training loss: 2.652113676071167
Validation loss: 2.5247074801434755

Epoch: 5| Step: 10
Training loss: 2.7410695552825928
Validation loss: 2.5214300488912933

Epoch: 90| Step: 0
Training loss: 2.898357629776001
Validation loss: 2.524569078158307

Epoch: 5| Step: 1
Training loss: 3.3897452354431152
Validation loss: 2.5210363941807903

Epoch: 5| Step: 2
Training loss: 3.0001845359802246
Validation loss: 2.5188943237386723

Epoch: 5| Step: 3
Training loss: 2.4493772983551025
Validation loss: 2.517273719592761

Epoch: 5| Step: 4
Training loss: 2.7434048652648926
Validation loss: 2.5093608107618106

Epoch: 5| Step: 5
Training loss: 2.6832523345947266
Validation loss: 2.5152587147169214

Epoch: 5| Step: 6
Training loss: 2.50767183303833
Validation loss: 2.51454000319204

Epoch: 5| Step: 7
Training loss: 2.6886038780212402
Validation loss: 2.5136439210625103

Epoch: 5| Step: 8
Training loss: 2.456225633621216
Validation loss: 2.5177706185207573

Epoch: 5| Step: 9
Training loss: 2.4938323497772217
Validation loss: 2.5142513449474047

Epoch: 5| Step: 10
Training loss: 2.3643453121185303
Validation loss: 2.511428089552028

Epoch: 91| Step: 0
Training loss: 3.201767683029175
Validation loss: 2.5131930151293354

Epoch: 5| Step: 1
Training loss: 2.7382829189300537
Validation loss: 2.514493373132521

Epoch: 5| Step: 2
Training loss: 2.262455463409424
Validation loss: 2.5138923301491687

Epoch: 5| Step: 3
Training loss: 2.7055532932281494
Validation loss: 2.502713498248849

Epoch: 5| Step: 4
Training loss: 3.0100841522216797
Validation loss: 2.510961571047383

Epoch: 5| Step: 5
Training loss: 2.5359749794006348
Validation loss: 2.505079142508968

Epoch: 5| Step: 6
Training loss: 2.732501983642578
Validation loss: 2.5084543715241137

Epoch: 5| Step: 7
Training loss: 2.952953815460205
Validation loss: 2.5108480914946525

Epoch: 5| Step: 8
Training loss: 2.6634581089019775
Validation loss: 2.504013607578893

Epoch: 5| Step: 9
Training loss: 2.123643398284912
Validation loss: 2.5100635995147047

Epoch: 5| Step: 10
Training loss: 2.6830525398254395
Validation loss: 2.5093641870765278

Epoch: 92| Step: 0
Training loss: 2.415055513381958
Validation loss: 2.5091151652797574

Epoch: 5| Step: 1
Training loss: 2.6800827980041504
Validation loss: 2.511525200259301

Epoch: 5| Step: 2
Training loss: 2.9218127727508545
Validation loss: 2.5147356756271853

Epoch: 5| Step: 3
Training loss: 2.9868526458740234
Validation loss: 2.509025219948061

Epoch: 5| Step: 4
Training loss: 2.9095683097839355
Validation loss: 2.5067160001365085

Epoch: 5| Step: 5
Training loss: 3.2208175659179688
Validation loss: 2.5083557226324595

Epoch: 5| Step: 6
Training loss: 2.044217348098755
Validation loss: 2.514797059438562

Epoch: 5| Step: 7
Training loss: 3.104174852371216
Validation loss: 2.5097978140718196

Epoch: 5| Step: 8
Training loss: 2.1529173851013184
Validation loss: 2.5116664696765203

Epoch: 5| Step: 9
Training loss: 2.4488067626953125
Validation loss: 2.5068569311531643

Epoch: 5| Step: 10
Training loss: 2.6947929859161377
Validation loss: 2.509118269848567

Epoch: 93| Step: 0
Training loss: 2.4614129066467285
Validation loss: 2.5120101051945842

Epoch: 5| Step: 1
Training loss: 1.9180963039398193
Validation loss: 2.510294588663245

Epoch: 5| Step: 2
Training loss: 2.3967223167419434
Validation loss: 2.508666282059044

Epoch: 5| Step: 3
Training loss: 2.8551430702209473
Validation loss: 2.5086885190779165

Epoch: 5| Step: 4
Training loss: 3.182589530944824
Validation loss: 2.509668860384213

Epoch: 5| Step: 5
Training loss: 2.6576972007751465
Validation loss: 2.5102055431694112

Epoch: 5| Step: 6
Training loss: 2.8998379707336426
Validation loss: 2.5165974786204677

Epoch: 5| Step: 7
Training loss: 2.3622360229492188
Validation loss: 2.509232169838362

Epoch: 5| Step: 8
Training loss: 2.7838988304138184
Validation loss: 2.509957341737645

Epoch: 5| Step: 9
Training loss: 2.907285213470459
Validation loss: 2.507767831125567

Epoch: 5| Step: 10
Training loss: 3.2406094074249268
Validation loss: 2.5037089829803794

Epoch: 94| Step: 0
Training loss: 3.179518222808838
Validation loss: 2.5010565609060307

Epoch: 5| Step: 1
Training loss: 2.639803409576416
Validation loss: 2.5039434586801836

Epoch: 5| Step: 2
Training loss: 3.130934476852417
Validation loss: 2.5065680703809186

Epoch: 5| Step: 3
Training loss: 1.9967658519744873
Validation loss: 2.5087754700773504

Epoch: 5| Step: 4
Training loss: 2.4013588428497314
Validation loss: 2.505140448129305

Epoch: 5| Step: 5
Training loss: 3.006434679031372
Validation loss: 2.510526749395555

Epoch: 5| Step: 6
Training loss: 2.1364493370056152
Validation loss: 2.506172808267737

Epoch: 5| Step: 7
Training loss: 2.5095291137695312
Validation loss: 2.5065544036126908

Epoch: 5| Step: 8
Training loss: 3.789324998855591
Validation loss: 2.498874439988085

Epoch: 5| Step: 9
Training loss: 2.645501136779785
Validation loss: 2.5027357685950493

Epoch: 5| Step: 10
Training loss: 2.0652031898498535
Validation loss: 2.5082338676657727

Epoch: 95| Step: 0
Training loss: 2.251370906829834
Validation loss: 2.5065625072807394

Epoch: 5| Step: 1
Training loss: 3.3469035625457764
Validation loss: 2.509204315882857

Epoch: 5| Step: 2
Training loss: 3.1084835529327393
Validation loss: 2.5181926706785798

Epoch: 5| Step: 3
Training loss: 2.8246662616729736
Validation loss: 2.5161962765519337

Epoch: 5| Step: 4
Training loss: 2.374645709991455
Validation loss: 2.5115006841639036

Epoch: 5| Step: 5
Training loss: 2.1204981803894043
Validation loss: 2.5060180387189313

Epoch: 5| Step: 6
Training loss: 2.23760724067688
Validation loss: 2.5020196848018195

Epoch: 5| Step: 7
Training loss: 3.0024940967559814
Validation loss: 2.503768362024779

Epoch: 5| Step: 8
Training loss: 2.4237563610076904
Validation loss: 2.506104048862252

Epoch: 5| Step: 9
Training loss: 2.991171360015869
Validation loss: 2.5005108541057957

Epoch: 5| Step: 10
Training loss: 2.9666779041290283
Validation loss: 2.496510987640709

Epoch: 96| Step: 0
Training loss: 2.944902181625366
Validation loss: 2.498049489913448

Epoch: 5| Step: 1
Training loss: 2.504875421524048
Validation loss: 2.49508483435518

Epoch: 5| Step: 2
Training loss: 3.4214072227478027
Validation loss: 2.501068804853706

Epoch: 5| Step: 3
Training loss: 2.853710174560547
Validation loss: 2.5047059905144478

Epoch: 5| Step: 4
Training loss: 2.7390618324279785
Validation loss: 2.5051207157873336

Epoch: 5| Step: 5
Training loss: 2.957900285720825
Validation loss: 2.500105760430777

Epoch: 5| Step: 6
Training loss: 2.5219016075134277
Validation loss: 2.499559910066666

Epoch: 5| Step: 7
Training loss: 2.471933364868164
Validation loss: 2.496945881074475

Epoch: 5| Step: 8
Training loss: 2.506316661834717
Validation loss: 2.494476515759704

Epoch: 5| Step: 9
Training loss: 1.7999927997589111
Validation loss: 2.49521178583945

Epoch: 5| Step: 10
Training loss: 2.925050973892212
Validation loss: 2.5002044734134468

Epoch: 97| Step: 0
Training loss: 2.791544198989868
Validation loss: 2.5022517686249106

Epoch: 5| Step: 1
Training loss: 2.6936097145080566
Validation loss: 2.5096869186688493

Epoch: 5| Step: 2
Training loss: 2.3627655506134033
Validation loss: 2.506172985158941

Epoch: 5| Step: 3
Training loss: 2.9485278129577637
Validation loss: 2.5140573952787664

Epoch: 5| Step: 4
Training loss: 3.102639675140381
Validation loss: 2.511540553903067

Epoch: 5| Step: 5
Training loss: 3.6478259563446045
Validation loss: 2.5177422236370783

Epoch: 5| Step: 6
Training loss: 2.3309645652770996
Validation loss: 2.510634829921107

Epoch: 5| Step: 7
Training loss: 2.3944780826568604
Validation loss: 2.5071728716614428

Epoch: 5| Step: 8
Training loss: 2.0374560356140137
Validation loss: 2.506931527968376

Epoch: 5| Step: 9
Training loss: 2.604144811630249
Validation loss: 2.503542879576324

Epoch: 5| Step: 10
Training loss: 2.600421905517578
Validation loss: 2.492785329459816

Epoch: 98| Step: 0
Training loss: 2.3799431324005127
Validation loss: 2.491047674609769

Epoch: 5| Step: 1
Training loss: 2.9997498989105225
Validation loss: 2.491449043314944

Epoch: 5| Step: 2
Training loss: 3.3657450675964355
Validation loss: 2.5000961519056752

Epoch: 5| Step: 3
Training loss: 2.8081815242767334
Validation loss: 2.493308667213686

Epoch: 5| Step: 4
Training loss: 2.401779890060425
Validation loss: 2.492787984109694

Epoch: 5| Step: 5
Training loss: 2.4528539180755615
Validation loss: 2.4948408885668685

Epoch: 5| Step: 6
Training loss: 2.050945281982422
Validation loss: 2.492511385230608

Epoch: 5| Step: 7
Training loss: 3.2678160667419434
Validation loss: 2.4969007891993367

Epoch: 5| Step: 8
Training loss: 2.304203748703003
Validation loss: 2.4930542976625505

Epoch: 5| Step: 9
Training loss: 2.7055697441101074
Validation loss: 2.490800516579741

Epoch: 5| Step: 10
Training loss: 2.8326587677001953
Validation loss: 2.490541104347475

Epoch: 99| Step: 0
Training loss: 2.837519645690918
Validation loss: 2.4907361051087737

Epoch: 5| Step: 1
Training loss: 2.91845440864563
Validation loss: 2.4900658143463956

Epoch: 5| Step: 2
Training loss: 2.807626485824585
Validation loss: 2.49523663520813

Epoch: 5| Step: 3
Training loss: 2.5856404304504395
Validation loss: 2.4965792573908323

Epoch: 5| Step: 4
Training loss: 3.022066116333008
Validation loss: 2.501158170802619

Epoch: 5| Step: 5
Training loss: 2.1533806324005127
Validation loss: 2.4999659087068293

Epoch: 5| Step: 6
Training loss: 2.348198175430298
Validation loss: 2.507226005677254

Epoch: 5| Step: 7
Training loss: 3.2788376808166504
Validation loss: 2.498907473779494

Epoch: 5| Step: 8
Training loss: 2.7357990741729736
Validation loss: 2.5034344657774894

Epoch: 5| Step: 9
Training loss: 2.6930007934570312
Validation loss: 2.4891210115084084

Epoch: 5| Step: 10
Training loss: 2.0529842376708984
Validation loss: 2.489183013157178

Epoch: 100| Step: 0
Training loss: 3.1352028846740723
Validation loss: 2.4967168197836926

Epoch: 5| Step: 1
Training loss: 2.72778058052063
Validation loss: 2.4948705806527087

Epoch: 5| Step: 2
Training loss: 2.460926055908203
Validation loss: 2.4895529747009277

Epoch: 5| Step: 3
Training loss: 2.8118982315063477
Validation loss: 2.492686927959483

Epoch: 5| Step: 4
Training loss: 2.154390811920166
Validation loss: 2.507591547504548

Epoch: 5| Step: 5
Training loss: 2.445889472961426
Validation loss: 2.503439449494885

Epoch: 5| Step: 6
Training loss: 2.098301410675049
Validation loss: 2.4938041394756687

Epoch: 5| Step: 7
Training loss: 2.9323229789733887
Validation loss: 2.5050558966975056

Epoch: 5| Step: 8
Training loss: 2.783642292022705
Validation loss: 2.5105168716881865

Epoch: 5| Step: 9
Training loss: 2.9311728477478027
Validation loss: 2.503766687967444

Epoch: 5| Step: 10
Training loss: 3.0869646072387695
Validation loss: 2.500047581170195

Epoch: 101| Step: 0
Training loss: 2.5490105152130127
Validation loss: 2.4941493003599104

Epoch: 5| Step: 1
Training loss: 1.8692985773086548
Validation loss: 2.490952027741299

Epoch: 5| Step: 2
Training loss: 2.9681556224823
Validation loss: 2.4855415154528875

Epoch: 5| Step: 3
Training loss: 2.0832626819610596
Validation loss: 2.486041791977421

Epoch: 5| Step: 4
Training loss: 3.6101601123809814
Validation loss: 2.4874024480901737

Epoch: 5| Step: 5
Training loss: 3.220304012298584
Validation loss: 2.483849112705518

Epoch: 5| Step: 6
Training loss: 2.2640113830566406
Validation loss: 2.4873674120954288

Epoch: 5| Step: 7
Training loss: 2.7726187705993652
Validation loss: 2.4903097203982774

Epoch: 5| Step: 8
Training loss: 3.116619110107422
Validation loss: 2.4911280473073325

Epoch: 5| Step: 9
Training loss: 2.1498608589172363
Validation loss: 2.4863849019491546

Epoch: 5| Step: 10
Training loss: 2.9028446674346924
Validation loss: 2.496706126838602

Epoch: 102| Step: 0
Training loss: 3.1977877616882324
Validation loss: 2.490343257945071

Epoch: 5| Step: 1
Training loss: 3.408417224884033
Validation loss: 2.4866860963964976

Epoch: 5| Step: 2
Training loss: 2.9546008110046387
Validation loss: 2.4843923648198447

Epoch: 5| Step: 3
Training loss: 2.5660653114318848
Validation loss: 2.493783485504889

Epoch: 5| Step: 4
Training loss: 2.450803756713867
Validation loss: 2.4915386399915143

Epoch: 5| Step: 5
Training loss: 2.6754698753356934
Validation loss: 2.488988850706367

Epoch: 5| Step: 6
Training loss: 1.9058904647827148
Validation loss: 2.489673235083139

Epoch: 5| Step: 7
Training loss: 2.4654288291931152
Validation loss: 2.4875127807740243

Epoch: 5| Step: 8
Training loss: 2.3677423000335693
Validation loss: 2.4937874783751783

Epoch: 5| Step: 9
Training loss: 2.9675920009613037
Validation loss: 2.4845616894383586

Epoch: 5| Step: 10
Training loss: 2.4413838386535645
Validation loss: 2.4895038630372737

Epoch: 103| Step: 0
Training loss: 3.4267868995666504
Validation loss: 2.4833841067488476

Epoch: 5| Step: 1
Training loss: 2.2743046283721924
Validation loss: 2.484632433101695

Epoch: 5| Step: 2
Training loss: 3.0741591453552246
Validation loss: 2.484116461969191

Epoch: 5| Step: 3
Training loss: 2.4554495811462402
Validation loss: 2.4808621637282835

Epoch: 5| Step: 4
Training loss: 2.139887571334839
Validation loss: 2.4854374380521875

Epoch: 5| Step: 5
Training loss: 3.1002392768859863
Validation loss: 2.479462549250613

Epoch: 5| Step: 6
Training loss: 2.499080181121826
Validation loss: 2.483129588506555

Epoch: 5| Step: 7
Training loss: 3.0711464881896973
Validation loss: 2.4819657110398814

Epoch: 5| Step: 8
Training loss: 2.5444366931915283
Validation loss: 2.4856363727200415

Epoch: 5| Step: 9
Training loss: 2.364891290664673
Validation loss: 2.4912486448082873

Epoch: 5| Step: 10
Training loss: 2.424260139465332
Validation loss: 2.507495872436031

Epoch: 104| Step: 0
Training loss: 3.04258394241333
Validation loss: 2.5289042380548294

Epoch: 5| Step: 1
Training loss: 2.7739949226379395
Validation loss: 2.540887507059241

Epoch: 5| Step: 2
Training loss: 3.230020523071289
Validation loss: 2.5485834985650997

Epoch: 5| Step: 3
Training loss: 2.830160140991211
Validation loss: 2.5281273703421316

Epoch: 5| Step: 4
Training loss: 2.1576759815216064
Validation loss: 2.5108650435683546

Epoch: 5| Step: 5
Training loss: 3.2278411388397217
Validation loss: 2.5041415153011197

Epoch: 5| Step: 6
Training loss: 2.26479434967041
Validation loss: 2.4885108342734714

Epoch: 5| Step: 7
Training loss: 2.115812063217163
Validation loss: 2.495873171796081

Epoch: 5| Step: 8
Training loss: 2.1544597148895264
Validation loss: 2.4898892141157583

Epoch: 5| Step: 9
Training loss: 3.0880093574523926
Validation loss: 2.48747407749135

Epoch: 5| Step: 10
Training loss: 2.652186155319214
Validation loss: 2.4898379746303765

Epoch: 105| Step: 0
Training loss: 2.456266403198242
Validation loss: 2.4873501100847797

Epoch: 5| Step: 1
Training loss: 2.472536563873291
Validation loss: 2.481730353447699

Epoch: 5| Step: 2
Training loss: 2.668806552886963
Validation loss: 2.4814308612577376

Epoch: 5| Step: 3
Training loss: 2.4448304176330566
Validation loss: 2.487567368374076

Epoch: 5| Step: 4
Training loss: 2.7640156745910645
Validation loss: 2.487056791141469

Epoch: 5| Step: 5
Training loss: 2.2890851497650146
Validation loss: 2.487700236740933

Epoch: 5| Step: 6
Training loss: 2.576716899871826
Validation loss: 2.48182334438447

Epoch: 5| Step: 7
Training loss: 3.6026217937469482
Validation loss: 2.483619491259257

Epoch: 5| Step: 8
Training loss: 2.847879648208618
Validation loss: 2.483061913521059

Epoch: 5| Step: 9
Training loss: 2.6140353679656982
Validation loss: 2.4861110077109387

Epoch: 5| Step: 10
Training loss: 2.7887864112854004
Validation loss: 2.481083616133659

Epoch: 106| Step: 0
Training loss: 3.099897623062134
Validation loss: 2.4849240036420923

Epoch: 5| Step: 1
Training loss: 1.7171447277069092
Validation loss: 2.482524251425138

Epoch: 5| Step: 2
Training loss: 2.990283489227295
Validation loss: 2.482946644547165

Epoch: 5| Step: 3
Training loss: 2.758861541748047
Validation loss: 2.479077318663238

Epoch: 5| Step: 4
Training loss: 2.7024121284484863
Validation loss: 2.484357464698053

Epoch: 5| Step: 5
Training loss: 3.1733999252319336
Validation loss: 2.482141366568945

Epoch: 5| Step: 6
Training loss: 3.1877405643463135
Validation loss: 2.4803640163072975

Epoch: 5| Step: 7
Training loss: 2.2831010818481445
Validation loss: 2.4827737346772225

Epoch: 5| Step: 8
Training loss: 2.73952054977417
Validation loss: 2.4785675053955405

Epoch: 5| Step: 9
Training loss: 2.4591922760009766
Validation loss: 2.4810608843321442

Epoch: 5| Step: 10
Training loss: 2.3557560443878174
Validation loss: 2.4818916397710002

Epoch: 107| Step: 0
Training loss: 2.399742603302002
Validation loss: 2.4773631813705608

Epoch: 5| Step: 1
Training loss: 2.785897731781006
Validation loss: 2.47893770792151

Epoch: 5| Step: 2
Training loss: 1.8607170581817627
Validation loss: 2.483786936729185

Epoch: 5| Step: 3
Training loss: 2.6812093257904053
Validation loss: 2.4773139927976873

Epoch: 5| Step: 4
Training loss: 3.4960074424743652
Validation loss: 2.481002838380875

Epoch: 5| Step: 5
Training loss: 2.7111856937408447
Validation loss: 2.480528139298962

Epoch: 5| Step: 6
Training loss: 2.6902377605438232
Validation loss: 2.4794528381798857

Epoch: 5| Step: 7
Training loss: 3.1038880348205566
Validation loss: 2.480027691010506

Epoch: 5| Step: 8
Training loss: 2.7484614849090576
Validation loss: 2.4764136242610153

Epoch: 5| Step: 9
Training loss: 2.147876024246216
Validation loss: 2.480938370509814

Epoch: 5| Step: 10
Training loss: 2.863100290298462
Validation loss: 2.4807569724257275

Epoch: 108| Step: 0
Training loss: 2.0070865154266357
Validation loss: 2.4928151792095554

Epoch: 5| Step: 1
Training loss: 2.848529815673828
Validation loss: 2.49157980949648

Epoch: 5| Step: 2
Training loss: 2.0553276538848877
Validation loss: 2.507173615117227

Epoch: 5| Step: 3
Training loss: 2.7101352214813232
Validation loss: 2.5177018386061474

Epoch: 5| Step: 4
Training loss: 2.640986919403076
Validation loss: 2.5197506194473593

Epoch: 5| Step: 5
Training loss: 3.2266666889190674
Validation loss: 2.51389540139065

Epoch: 5| Step: 6
Training loss: 3.0815322399139404
Validation loss: 2.4931206087912283

Epoch: 5| Step: 7
Training loss: 2.9437968730926514
Validation loss: 2.480571085406888

Epoch: 5| Step: 8
Training loss: 3.0174026489257812
Validation loss: 2.4806812783723236

Epoch: 5| Step: 9
Training loss: 2.774219036102295
Validation loss: 2.4865899701272287

Epoch: 5| Step: 10
Training loss: 2.136906147003174
Validation loss: 2.4930723982472576

Epoch: 109| Step: 0
Training loss: 2.212653875350952
Validation loss: 2.4845636583143667

Epoch: 5| Step: 1
Training loss: 3.1183454990386963
Validation loss: 2.4763604005177817

Epoch: 5| Step: 2
Training loss: 2.5335617065429688
Validation loss: 2.482656871118853

Epoch: 5| Step: 3
Training loss: 2.309464693069458
Validation loss: 2.479233859687723

Epoch: 5| Step: 4
Training loss: 3.4371860027313232
Validation loss: 2.4809191560232513

Epoch: 5| Step: 5
Training loss: 3.131221055984497
Validation loss: 2.47279207680815

Epoch: 5| Step: 6
Training loss: 2.553767681121826
Validation loss: 2.472980837668142

Epoch: 5| Step: 7
Training loss: 2.4128005504608154
Validation loss: 2.476450871395808

Epoch: 5| Step: 8
Training loss: 2.7063610553741455
Validation loss: 2.4784325553524877

Epoch: 5| Step: 9
Training loss: 2.344271183013916
Validation loss: 2.497781761230961

Epoch: 5| Step: 10
Training loss: 2.7672901153564453
Validation loss: 2.501550743656774

Epoch: 110| Step: 0
Training loss: 2.872244119644165
Validation loss: 2.5094241942128828

Epoch: 5| Step: 1
Training loss: 2.4740538597106934
Validation loss: 2.5077558563601587

Epoch: 5| Step: 2
Training loss: 2.432987928390503
Validation loss: 2.5021779011654597

Epoch: 5| Step: 3
Training loss: 3.3133139610290527
Validation loss: 2.4967480295447895

Epoch: 5| Step: 4
Training loss: 2.9524459838867188
Validation loss: 2.4876711548015638

Epoch: 5| Step: 5
Training loss: 1.9650280475616455
Validation loss: 2.4795611340512513

Epoch: 5| Step: 6
Training loss: 2.6321568489074707
Validation loss: 2.473019358932331

Epoch: 5| Step: 7
Training loss: 2.9586939811706543
Validation loss: 2.479003132030528

Epoch: 5| Step: 8
Training loss: 2.7811288833618164
Validation loss: 2.4702348504015195

Epoch: 5| Step: 9
Training loss: 1.9667320251464844
Validation loss: 2.4724683812869492

Epoch: 5| Step: 10
Training loss: 3.216468334197998
Validation loss: 2.47509644621162

Epoch: 111| Step: 0
Training loss: 2.874046564102173
Validation loss: 2.4763015880379626

Epoch: 5| Step: 1
Training loss: 2.977477550506592
Validation loss: 2.4750950797911613

Epoch: 5| Step: 2
Training loss: 3.077810764312744
Validation loss: 2.4798801201646046

Epoch: 5| Step: 3
Training loss: 3.201404571533203
Validation loss: 2.4874964760195826

Epoch: 5| Step: 4
Training loss: 2.2447800636291504
Validation loss: 2.481086589956796

Epoch: 5| Step: 5
Training loss: 2.9653024673461914
Validation loss: 2.4845567313573693

Epoch: 5| Step: 6
Training loss: 2.047459840774536
Validation loss: 2.478187076507076

Epoch: 5| Step: 7
Training loss: 2.215743064880371
Validation loss: 2.4793780132006575

Epoch: 5| Step: 8
Training loss: 2.7410871982574463
Validation loss: 2.4807413931815856

Epoch: 5| Step: 9
Training loss: 2.302669048309326
Validation loss: 2.4891988410744617

Epoch: 5| Step: 10
Training loss: 2.865074634552002
Validation loss: 2.4870970659358527

Epoch: 112| Step: 0
Training loss: 2.5237152576446533
Validation loss: 2.4821991817925566

Epoch: 5| Step: 1
Training loss: 3.3512730598449707
Validation loss: 2.485453333905948

Epoch: 5| Step: 2
Training loss: 1.8577899932861328
Validation loss: 2.48650574427779

Epoch: 5| Step: 3
Training loss: 2.8332836627960205
Validation loss: 2.4844963730022473

Epoch: 5| Step: 4
Training loss: 2.9458260536193848
Validation loss: 2.482323210726502

Epoch: 5| Step: 5
Training loss: 2.5505969524383545
Validation loss: 2.4793622365561863

Epoch: 5| Step: 6
Training loss: 2.4393668174743652
Validation loss: 2.4724567526130268

Epoch: 5| Step: 7
Training loss: 2.4218316078186035
Validation loss: 2.4778095663234754

Epoch: 5| Step: 8
Training loss: 3.061660051345825
Validation loss: 2.482710302516978

Epoch: 5| Step: 9
Training loss: 3.05432391166687
Validation loss: 2.4817135154560046

Epoch: 5| Step: 10
Training loss: 2.358957290649414
Validation loss: 2.4954832958918747

Epoch: 113| Step: 0
Training loss: 2.1468117237091064
Validation loss: 2.506201961989044

Epoch: 5| Step: 1
Training loss: 2.3851828575134277
Validation loss: 2.50783206570533

Epoch: 5| Step: 2
Training loss: 3.004849910736084
Validation loss: 2.5110077678516345

Epoch: 5| Step: 3
Training loss: 2.6466808319091797
Validation loss: 2.5076604017647366

Epoch: 5| Step: 4
Training loss: 2.6395092010498047
Validation loss: 2.501438779215659

Epoch: 5| Step: 5
Training loss: 2.9074950218200684
Validation loss: 2.500222406079692

Epoch: 5| Step: 6
Training loss: 2.874072551727295
Validation loss: 2.4891152792079474

Epoch: 5| Step: 7
Training loss: 2.782824993133545
Validation loss: 2.4816369959103164

Epoch: 5| Step: 8
Training loss: 2.8683197498321533
Validation loss: 2.4800269706274873

Epoch: 5| Step: 9
Training loss: 2.6149849891662598
Validation loss: 2.473585287729899

Epoch: 5| Step: 10
Training loss: 2.535614490509033
Validation loss: 2.4736040176883822

Epoch: 114| Step: 0
Training loss: 2.532458543777466
Validation loss: 2.4768781418441446

Epoch: 5| Step: 1
Training loss: 2.5165023803710938
Validation loss: 2.47647964057102

Epoch: 5| Step: 2
Training loss: 2.7445411682128906
Validation loss: 2.4803747297615133

Epoch: 5| Step: 3
Training loss: 2.8115930557250977
Validation loss: 2.487575464351203

Epoch: 5| Step: 4
Training loss: 2.608715772628784
Validation loss: 2.4806512235313334

Epoch: 5| Step: 5
Training loss: 3.0740349292755127
Validation loss: 2.4804454836794125

Epoch: 5| Step: 6
Training loss: 2.7455837726593018
Validation loss: 2.4773122264492895

Epoch: 5| Step: 7
Training loss: 2.7953898906707764
Validation loss: 2.4743884507045952

Epoch: 5| Step: 8
Training loss: 2.698857069015503
Validation loss: 2.479240407225906

Epoch: 5| Step: 9
Training loss: 2.7591099739074707
Validation loss: 2.475941450365128

Epoch: 5| Step: 10
Training loss: 2.0488710403442383
Validation loss: 2.48297143238847

Epoch: 115| Step: 0
Training loss: 2.427865982055664
Validation loss: 2.488527600483228

Epoch: 5| Step: 1
Training loss: 2.683203935623169
Validation loss: 2.479924322456442

Epoch: 5| Step: 2
Training loss: 3.084989070892334
Validation loss: 2.4808751742045083

Epoch: 5| Step: 3
Training loss: 2.5763556957244873
Validation loss: 2.473745422978555

Epoch: 5| Step: 4
Training loss: 3.188185214996338
Validation loss: 2.4695208636663293

Epoch: 5| Step: 5
Training loss: 3.0549960136413574
Validation loss: 2.4628777914149786

Epoch: 5| Step: 6
Training loss: 3.5480542182922363
Validation loss: 2.4655495125760316

Epoch: 5| Step: 7
Training loss: 2.2246620655059814
Validation loss: 2.4645697429615963

Epoch: 5| Step: 8
Training loss: 2.381554365158081
Validation loss: 2.466220566021499

Epoch: 5| Step: 9
Training loss: 1.6359548568725586
Validation loss: 2.4618390144840365

Epoch: 5| Step: 10
Training loss: 2.5682578086853027
Validation loss: 2.4691170518116285

Epoch: 116| Step: 0
Training loss: 3.023961305618286
Validation loss: 2.4685380317831553

Epoch: 5| Step: 1
Training loss: 2.911839008331299
Validation loss: 2.469126063008462

Epoch: 5| Step: 2
Training loss: 3.091005563735962
Validation loss: 2.4836854755237536

Epoch: 5| Step: 3
Training loss: 2.7709567546844482
Validation loss: 2.4918762099358345

Epoch: 5| Step: 4
Training loss: 2.8519537448883057
Validation loss: 2.5048222387990644

Epoch: 5| Step: 5
Training loss: 1.9967609643936157
Validation loss: 2.4900340944208126

Epoch: 5| Step: 6
Training loss: 3.0825729370117188
Validation loss: 2.483650158810359

Epoch: 5| Step: 7
Training loss: 2.3237757682800293
Validation loss: 2.485721106170326

Epoch: 5| Step: 8
Training loss: 2.683320999145508
Validation loss: 2.4839595440895326

Epoch: 5| Step: 9
Training loss: 2.6930320262908936
Validation loss: 2.4894845075504755

Epoch: 5| Step: 10
Training loss: 1.8920353651046753
Validation loss: 2.48729448164663

Epoch: 117| Step: 0
Training loss: 2.7291078567504883
Validation loss: 2.5286866670013755

Epoch: 5| Step: 1
Training loss: 2.5030574798583984
Validation loss: 2.4977798667005313

Epoch: 5| Step: 2
Training loss: 3.303889513015747
Validation loss: 2.499575641847426

Epoch: 5| Step: 3
Training loss: 2.76432466506958
Validation loss: 2.4932105489956435

Epoch: 5| Step: 4
Training loss: 3.367034435272217
Validation loss: 2.477876878553821

Epoch: 5| Step: 5
Training loss: 2.7919344902038574
Validation loss: 2.4767081429881435

Epoch: 5| Step: 6
Training loss: 1.8744287490844727
Validation loss: 2.479399706727715

Epoch: 5| Step: 7
Training loss: 2.6178221702575684
Validation loss: 2.4831207311281593

Epoch: 5| Step: 8
Training loss: 2.5195510387420654
Validation loss: 2.4997420413519746

Epoch: 5| Step: 9
Training loss: 2.8540282249450684
Validation loss: 2.4927846462495866

Epoch: 5| Step: 10
Training loss: 1.9213216304779053
Validation loss: 2.497758121900661

Epoch: 118| Step: 0
Training loss: 2.709807872772217
Validation loss: 2.4928805956276516

Epoch: 5| Step: 1
Training loss: 2.7796380519866943
Validation loss: 2.482909987049718

Epoch: 5| Step: 2
Training loss: 2.6670141220092773
Validation loss: 2.4821887452115297

Epoch: 5| Step: 3
Training loss: 2.721848964691162
Validation loss: 2.4778907017041276

Epoch: 5| Step: 4
Training loss: 1.9020898342132568
Validation loss: 2.475014396893081

Epoch: 5| Step: 5
Training loss: 3.5125274658203125
Validation loss: 2.4744875213151336

Epoch: 5| Step: 6
Training loss: 2.7469496726989746
Validation loss: 2.4750457553453344

Epoch: 5| Step: 7
Training loss: 3.2520358562469482
Validation loss: 2.4770233759316067

Epoch: 5| Step: 8
Training loss: 1.5238759517669678
Validation loss: 2.469155324402676

Epoch: 5| Step: 9
Training loss: 2.4255881309509277
Validation loss: 2.4675731864026798

Epoch: 5| Step: 10
Training loss: 3.1595356464385986
Validation loss: 2.4662502068345264

Epoch: 119| Step: 0
Training loss: 2.6107964515686035
Validation loss: 2.4659024246277346

Epoch: 5| Step: 1
Training loss: 3.0544018745422363
Validation loss: 2.467315068808935

Epoch: 5| Step: 2
Training loss: 2.701972484588623
Validation loss: 2.468008728437526

Epoch: 5| Step: 3
Training loss: 2.8359782695770264
Validation loss: 2.4743238341423774

Epoch: 5| Step: 4
Training loss: 3.146038055419922
Validation loss: 2.474436088274884

Epoch: 5| Step: 5
Training loss: 3.1335887908935547
Validation loss: 2.4679814795012116

Epoch: 5| Step: 6
Training loss: 2.4731578826904297
Validation loss: 2.4755161628928235

Epoch: 5| Step: 7
Training loss: 1.8001445531845093
Validation loss: 2.467596969296855

Epoch: 5| Step: 8
Training loss: 2.50414776802063
Validation loss: 2.480802789811165

Epoch: 5| Step: 9
Training loss: 2.4818167686462402
Validation loss: 2.4767390040941137

Epoch: 5| Step: 10
Training loss: 2.5767292976379395
Validation loss: 2.475189621730517

Epoch: 120| Step: 0
Training loss: 3.1095480918884277
Validation loss: 2.4725143742817703

Epoch: 5| Step: 1
Training loss: 2.6915645599365234
Validation loss: 2.4742443612826768

Epoch: 5| Step: 2
Training loss: 2.8300843238830566
Validation loss: 2.4790036345040924

Epoch: 5| Step: 3
Training loss: 2.6959235668182373
Validation loss: 2.475134418856713

Epoch: 5| Step: 4
Training loss: 2.1428370475769043
Validation loss: 2.474131602112965

Epoch: 5| Step: 5
Training loss: 2.05189847946167
Validation loss: 2.4695119780878865

Epoch: 5| Step: 6
Training loss: 2.4326095581054688
Validation loss: 2.476882711533577

Epoch: 5| Step: 7
Training loss: 3.0405030250549316
Validation loss: 2.4628807883108816

Epoch: 5| Step: 8
Training loss: 3.160217046737671
Validation loss: 2.467943629910869

Epoch: 5| Step: 9
Training loss: 2.252337694168091
Validation loss: 2.46634276195239

Epoch: 5| Step: 10
Training loss: 2.8425707817077637
Validation loss: 2.4607543406947965

Epoch: 121| Step: 0
Training loss: 2.638272285461426
Validation loss: 2.461140522392847

Epoch: 5| Step: 1
Training loss: 2.925283908843994
Validation loss: 2.459363623331952

Epoch: 5| Step: 2
Training loss: 3.0299220085144043
Validation loss: 2.461503569797803

Epoch: 5| Step: 3
Training loss: 2.506359577178955
Validation loss: 2.458029588063558

Epoch: 5| Step: 4
Training loss: 2.5308427810668945
Validation loss: 2.4627803807617514

Epoch: 5| Step: 5
Training loss: 3.4742043018341064
Validation loss: 2.4581859060513076

Epoch: 5| Step: 6
Training loss: 2.38993763923645
Validation loss: 2.464904082718716

Epoch: 5| Step: 7
Training loss: 1.7463343143463135
Validation loss: 2.457458831930673

Epoch: 5| Step: 8
Training loss: 2.2478785514831543
Validation loss: 2.459442892382222

Epoch: 5| Step: 9
Training loss: 2.809882640838623
Validation loss: 2.452602166001515

Epoch: 5| Step: 10
Training loss: 2.984682083129883
Validation loss: 2.457132489450516

Epoch: 122| Step: 0
Training loss: 2.6115589141845703
Validation loss: 2.453454407312537

Epoch: 5| Step: 1
Training loss: 3.028148889541626
Validation loss: 2.4545580930607294

Epoch: 5| Step: 2
Training loss: 3.2168221473693848
Validation loss: 2.4541370740500827

Epoch: 5| Step: 3
Training loss: 2.0892441272735596
Validation loss: 2.454646646335561

Epoch: 5| Step: 4
Training loss: 1.9935935735702515
Validation loss: 2.4517039278502106

Epoch: 5| Step: 5
Training loss: 2.673553943634033
Validation loss: 2.454604817974952

Epoch: 5| Step: 6
Training loss: 2.349809408187866
Validation loss: 2.4520446946544032

Epoch: 5| Step: 7
Training loss: 2.8722920417785645
Validation loss: 2.452630171211817

Epoch: 5| Step: 8
Training loss: 2.7595162391662598
Validation loss: 2.449263039455619

Epoch: 5| Step: 9
Training loss: 2.730745553970337
Validation loss: 2.449639276791644

Epoch: 5| Step: 10
Training loss: 3.00624680519104
Validation loss: 2.452137234390423

Epoch: 123| Step: 0
Training loss: 1.9677619934082031
Validation loss: 2.4498373462307836

Epoch: 5| Step: 1
Training loss: 2.4461402893066406
Validation loss: 2.4524770731567056

Epoch: 5| Step: 2
Training loss: 2.9153876304626465
Validation loss: 2.451269777872229

Epoch: 5| Step: 3
Training loss: 2.253593921661377
Validation loss: 2.456690765196277

Epoch: 5| Step: 4
Training loss: 2.8658995628356934
Validation loss: 2.458378658499769

Epoch: 5| Step: 5
Training loss: 2.7770726680755615
Validation loss: 2.463495521135228

Epoch: 5| Step: 6
Training loss: 2.847142457962036
Validation loss: 2.471846326704948

Epoch: 5| Step: 7
Training loss: 3.242114543914795
Validation loss: 2.4912808813074583

Epoch: 5| Step: 8
Training loss: 2.6020262241363525
Validation loss: 2.4900014144118114

Epoch: 5| Step: 9
Training loss: 2.527679920196533
Validation loss: 2.473331013033467

Epoch: 5| Step: 10
Training loss: 2.8345911502838135
Validation loss: 2.4760183852205992

Epoch: 124| Step: 0
Training loss: 2.307307481765747
Validation loss: 2.4816802509369387

Epoch: 5| Step: 1
Training loss: 2.737003803253174
Validation loss: 2.470396181588532

Epoch: 5| Step: 2
Training loss: 2.742809772491455
Validation loss: 2.4841209765403502

Epoch: 5| Step: 3
Training loss: 3.1411385536193848
Validation loss: 2.4790603832532

Epoch: 5| Step: 4
Training loss: 3.193847417831421
Validation loss: 2.4721149065161265

Epoch: 5| Step: 5
Training loss: 3.165998935699463
Validation loss: 2.4652751850825485

Epoch: 5| Step: 6
Training loss: 2.5916662216186523
Validation loss: 2.467800671054471

Epoch: 5| Step: 7
Training loss: 2.6510777473449707
Validation loss: 2.4827706608721005

Epoch: 5| Step: 8
Training loss: 2.3466591835021973
Validation loss: 2.492141059649888

Epoch: 5| Step: 9
Training loss: 1.9806827306747437
Validation loss: 2.483580671330934

Epoch: 5| Step: 10
Training loss: 2.293060541152954
Validation loss: 2.49306300891343

Epoch: 125| Step: 0
Training loss: 3.0166172981262207
Validation loss: 2.501654883866669

Epoch: 5| Step: 1
Training loss: 2.6592860221862793
Validation loss: 2.5135867262399323

Epoch: 5| Step: 2
Training loss: 2.930882692337036
Validation loss: 2.521054331974317

Epoch: 5| Step: 3
Training loss: 2.6808879375457764
Validation loss: 2.518072748696932

Epoch: 5| Step: 4
Training loss: 2.3362624645233154
Validation loss: 2.5100093836425454

Epoch: 5| Step: 5
Training loss: 2.1175589561462402
Validation loss: 2.4850318021671747

Epoch: 5| Step: 6
Training loss: 3.0590062141418457
Validation loss: 2.4627840467678603

Epoch: 5| Step: 7
Training loss: 2.308528423309326
Validation loss: 2.4564105464566137

Epoch: 5| Step: 8
Training loss: 3.0365138053894043
Validation loss: 2.44972825050354

Epoch: 5| Step: 9
Training loss: 2.5735676288604736
Validation loss: 2.4514245910029255

Epoch: 5| Step: 10
Training loss: 2.6261045932769775
Validation loss: 2.445942073739985

Epoch: 126| Step: 0
Training loss: 2.7334156036376953
Validation loss: 2.455155177782941

Epoch: 5| Step: 1
Training loss: 2.2881619930267334
Validation loss: 2.454637248028991

Epoch: 5| Step: 2
Training loss: 2.80505108833313
Validation loss: 2.462911605834961

Epoch: 5| Step: 3
Training loss: 3.105698823928833
Validation loss: 2.4696505274823917

Epoch: 5| Step: 4
Training loss: 2.0605344772338867
Validation loss: 2.463982028345908

Epoch: 5| Step: 5
Training loss: 2.691257953643799
Validation loss: 2.4732644019588346

Epoch: 5| Step: 6
Training loss: 2.6500656604766846
Validation loss: 2.4741495193973666

Epoch: 5| Step: 7
Training loss: 2.6931521892547607
Validation loss: 2.475643232304563

Epoch: 5| Step: 8
Training loss: 2.73850417137146
Validation loss: 2.4796535673961846

Epoch: 5| Step: 9
Training loss: 2.273261547088623
Validation loss: 2.483323074156238

Epoch: 5| Step: 10
Training loss: 3.2343921661376953
Validation loss: 2.4804101695296583

Epoch: 127| Step: 0
Training loss: 3.1007487773895264
Validation loss: 2.478377575515419

Epoch: 5| Step: 1
Training loss: 3.2148399353027344
Validation loss: 2.473744735922865

Epoch: 5| Step: 2
Training loss: 2.2406253814697266
Validation loss: 2.461475605605751

Epoch: 5| Step: 3
Training loss: 2.3149380683898926
Validation loss: 2.4652567089244886

Epoch: 5| Step: 4
Training loss: 3.185037136077881
Validation loss: 2.461268466006043

Epoch: 5| Step: 5
Training loss: 2.871790647506714
Validation loss: 2.4506543118466615

Epoch: 5| Step: 6
Training loss: 2.203726291656494
Validation loss: 2.4473590645738827

Epoch: 5| Step: 7
Training loss: 2.5423054695129395
Validation loss: 2.44616243403445

Epoch: 5| Step: 8
Training loss: 2.831516981124878
Validation loss: 2.444729282009986

Epoch: 5| Step: 9
Training loss: 2.245333194732666
Validation loss: 2.452755376856814

Epoch: 5| Step: 10
Training loss: 2.3709144592285156
Validation loss: 2.4581805890606296

Epoch: 128| Step: 0
Training loss: 2.5624794960021973
Validation loss: 2.4672128795295634

Epoch: 5| Step: 1
Training loss: 2.213744878768921
Validation loss: 2.4761437600658787

Epoch: 5| Step: 2
Training loss: 3.368407726287842
Validation loss: 2.488751370419738

Epoch: 5| Step: 3
Training loss: 2.5986216068267822
Validation loss: 2.4988725108485066

Epoch: 5| Step: 4
Training loss: 2.4850242137908936
Validation loss: 2.508915639692737

Epoch: 5| Step: 5
Training loss: 3.221041202545166
Validation loss: 2.5040675491415043

Epoch: 5| Step: 6
Training loss: 2.8451876640319824
Validation loss: 2.516599392378202

Epoch: 5| Step: 7
Training loss: 2.138544797897339
Validation loss: 2.5123113996239117

Epoch: 5| Step: 8
Training loss: 2.4245686531066895
Validation loss: 2.4807447412962556

Epoch: 5| Step: 9
Training loss: 2.535539388656616
Validation loss: 2.469695924430765

Epoch: 5| Step: 10
Training loss: 2.8245651721954346
Validation loss: 2.457528316846458

Epoch: 129| Step: 0
Training loss: 2.5234005451202393
Validation loss: 2.4520617954192625

Epoch: 5| Step: 1
Training loss: 1.6200441122055054
Validation loss: 2.4482193557165

Epoch: 5| Step: 2
Training loss: 3.0916008949279785
Validation loss: 2.459475891564482

Epoch: 5| Step: 3
Training loss: 3.0590178966522217
Validation loss: 2.4675394001827446

Epoch: 5| Step: 4
Training loss: 3.022183895111084
Validation loss: 2.473983564684468

Epoch: 5| Step: 5
Training loss: 3.081909656524658
Validation loss: 2.4701728641345935

Epoch: 5| Step: 6
Training loss: 2.9880332946777344
Validation loss: 2.4617141216031966

Epoch: 5| Step: 7
Training loss: 2.374957323074341
Validation loss: 2.449948177542738

Epoch: 5| Step: 8
Training loss: 1.6727683544158936
Validation loss: 2.4453164351883756

Epoch: 5| Step: 9
Training loss: 3.111184597015381
Validation loss: 2.4464366346277218

Epoch: 5| Step: 10
Training loss: 2.698343276977539
Validation loss: 2.444811118546353

Epoch: 130| Step: 0
Training loss: 2.80963134765625
Validation loss: 2.4447486631331907

Epoch: 5| Step: 1
Training loss: 2.284914970397949
Validation loss: 2.4445583858797626

Epoch: 5| Step: 2
Training loss: 1.8976694345474243
Validation loss: 2.4404514451180734

Epoch: 5| Step: 3
Training loss: 2.6606335639953613
Validation loss: 2.442328183881698

Epoch: 5| Step: 4
Training loss: 2.310588836669922
Validation loss: 2.4438185871288343

Epoch: 5| Step: 5
Training loss: 3.424359083175659
Validation loss: 2.448789117156818

Epoch: 5| Step: 6
Training loss: 2.4880025386810303
Validation loss: 2.4531909752917547

Epoch: 5| Step: 7
Training loss: 3.0988078117370605
Validation loss: 2.451274428316342

Epoch: 5| Step: 8
Training loss: 2.9471778869628906
Validation loss: 2.4574868935410694

Epoch: 5| Step: 9
Training loss: 2.778475046157837
Validation loss: 2.462718632913405

Epoch: 5| Step: 10
Training loss: 2.4339914321899414
Validation loss: 2.4547085967115176

Epoch: 131| Step: 0
Training loss: 3.0853073596954346
Validation loss: 2.4540846886173373

Epoch: 5| Step: 1
Training loss: 2.111112356185913
Validation loss: 2.4569147979059527

Epoch: 5| Step: 2
Training loss: 2.9962191581726074
Validation loss: 2.4556934090070826

Epoch: 5| Step: 3
Training loss: 2.4438304901123047
Validation loss: 2.4602360533129786

Epoch: 5| Step: 4
Training loss: 2.753636360168457
Validation loss: 2.4636044809895177

Epoch: 5| Step: 5
Training loss: 2.6024131774902344
Validation loss: 2.457639963396134

Epoch: 5| Step: 6
Training loss: 2.583710193634033
Validation loss: 2.458289407914685

Epoch: 5| Step: 7
Training loss: 2.928680658340454
Validation loss: 2.459452400925339

Epoch: 5| Step: 8
Training loss: 2.951617479324341
Validation loss: 2.4536545661187943

Epoch: 5| Step: 9
Training loss: 2.4592204093933105
Validation loss: 2.4524894375954904

Epoch: 5| Step: 10
Training loss: 2.1359896659851074
Validation loss: 2.456186286864742

Epoch: 132| Step: 0
Training loss: 2.400850772857666
Validation loss: 2.453446119062362

Epoch: 5| Step: 1
Training loss: 3.128605604171753
Validation loss: 2.4533303194148566

Epoch: 5| Step: 2
Training loss: 2.463862180709839
Validation loss: 2.4494556278310795

Epoch: 5| Step: 3
Training loss: 2.5553507804870605
Validation loss: 2.4443294437982703

Epoch: 5| Step: 4
Training loss: 2.8169140815734863
Validation loss: 2.443125201809791

Epoch: 5| Step: 5
Training loss: 2.4986319541931152
Validation loss: 2.4476988341218684

Epoch: 5| Step: 6
Training loss: 2.304144859313965
Validation loss: 2.4506151368541103

Epoch: 5| Step: 7
Training loss: 2.5501604080200195
Validation loss: 2.4494692099991666

Epoch: 5| Step: 8
Training loss: 2.9974091053009033
Validation loss: 2.4559201425121677

Epoch: 5| Step: 9
Training loss: 2.762712001800537
Validation loss: 2.4577613594711467

Epoch: 5| Step: 10
Training loss: 2.6593639850616455
Validation loss: 2.460291726614839

Epoch: 133| Step: 0
Training loss: 2.810800790786743
Validation loss: 2.4697354583330053

Epoch: 5| Step: 1
Training loss: 2.698976516723633
Validation loss: 2.4642280006921418

Epoch: 5| Step: 2
Training loss: 2.7237205505371094
Validation loss: 2.455790642769106

Epoch: 5| Step: 3
Training loss: 3.177340030670166
Validation loss: 2.4466275040821364

Epoch: 5| Step: 4
Training loss: 2.1234114170074463
Validation loss: 2.4398608412793887

Epoch: 5| Step: 5
Training loss: 2.442777156829834
Validation loss: 2.44444937475266

Epoch: 5| Step: 6
Training loss: 2.334524631500244
Validation loss: 2.4606916109720864

Epoch: 5| Step: 7
Training loss: 2.089334011077881
Validation loss: 2.458237096827517

Epoch: 5| Step: 8
Training loss: 3.29990816116333
Validation loss: 2.4705099034053024

Epoch: 5| Step: 9
Training loss: 2.072721481323242
Validation loss: 2.473174477136263

Epoch: 5| Step: 10
Training loss: 3.508836030960083
Validation loss: 2.473298289442575

Epoch: 134| Step: 0
Training loss: 2.8509926795959473
Validation loss: 2.475704211060719

Epoch: 5| Step: 1
Training loss: 1.99356210231781
Validation loss: 2.4709557846028316

Epoch: 5| Step: 2
Training loss: 2.3752241134643555
Validation loss: 2.461835627914757

Epoch: 5| Step: 3
Training loss: 2.5626375675201416
Validation loss: 2.4549213481205765

Epoch: 5| Step: 4
Training loss: 2.642721176147461
Validation loss: 2.4556257660670946

Epoch: 5| Step: 5
Training loss: 3.169826030731201
Validation loss: 2.4511330384080128

Epoch: 5| Step: 6
Training loss: 1.8582267761230469
Validation loss: 2.449593879843271

Epoch: 5| Step: 7
Training loss: 3.3875930309295654
Validation loss: 2.4532432991971254

Epoch: 5| Step: 8
Training loss: 3.253659725189209
Validation loss: 2.4492064496522308

Epoch: 5| Step: 9
Training loss: 2.6497321128845215
Validation loss: 2.453479008008075

Epoch: 5| Step: 10
Training loss: 2.3020095825195312
Validation loss: 2.4581154315702376

Epoch: 135| Step: 0
Training loss: 2.6357877254486084
Validation loss: 2.4608940719276347

Epoch: 5| Step: 1
Training loss: 2.7762904167175293
Validation loss: 2.4572501285101778

Epoch: 5| Step: 2
Training loss: 2.2364819049835205
Validation loss: 2.4495182319353987

Epoch: 5| Step: 3
Training loss: 2.8569014072418213
Validation loss: 2.4490046039704354

Epoch: 5| Step: 4
Training loss: 2.356330394744873
Validation loss: 2.453043496736916

Epoch: 5| Step: 5
Training loss: 2.9524388313293457
Validation loss: 2.4483305344017605

Epoch: 5| Step: 6
Training loss: 3.2969298362731934
Validation loss: 2.450141636274194

Epoch: 5| Step: 7
Training loss: 2.4030299186706543
Validation loss: 2.449276711351128

Epoch: 5| Step: 8
Training loss: 2.961549997329712
Validation loss: 2.459471651302871

Epoch: 5| Step: 9
Training loss: 2.5685036182403564
Validation loss: 2.4596967748416367

Epoch: 5| Step: 10
Training loss: 1.8932369947433472
Validation loss: 2.46133687162912

Epoch: 136| Step: 0
Training loss: 2.6267342567443848
Validation loss: 2.4828603447124524

Epoch: 5| Step: 1
Training loss: 2.2623867988586426
Validation loss: 2.4914424393766668

Epoch: 5| Step: 2
Training loss: 2.869541645050049
Validation loss: 2.5038855204018216

Epoch: 5| Step: 3
Training loss: 2.7575504779815674
Validation loss: 2.5158179883033998

Epoch: 5| Step: 4
Training loss: 2.5514864921569824
Validation loss: 2.511119434910436

Epoch: 5| Step: 5
Training loss: 2.8478894233703613
Validation loss: 2.495405320198305

Epoch: 5| Step: 6
Training loss: 3.0017666816711426
Validation loss: 2.461143482115961

Epoch: 5| Step: 7
Training loss: 2.3062758445739746
Validation loss: 2.4454071778123097

Epoch: 5| Step: 8
Training loss: 1.9375746250152588
Validation loss: 2.432409360844602

Epoch: 5| Step: 9
Training loss: 2.619485378265381
Validation loss: 2.434725328158307

Epoch: 5| Step: 10
Training loss: 3.447984218597412
Validation loss: 2.431583491704797

Epoch: 137| Step: 0
Training loss: 2.4051902294158936
Validation loss: 2.430432552932411

Epoch: 5| Step: 1
Training loss: 3.0912296772003174
Validation loss: 2.4324168723116637

Epoch: 5| Step: 2
Training loss: 3.3825581073760986
Validation loss: 2.4362978832696074

Epoch: 5| Step: 3
Training loss: 3.3056724071502686
Validation loss: 2.43427264049489

Epoch: 5| Step: 4
Training loss: 2.761268138885498
Validation loss: 2.4324207587908675

Epoch: 5| Step: 5
Training loss: 2.491730213165283
Validation loss: 2.438424905141195

Epoch: 5| Step: 6
Training loss: 2.4846882820129395
Validation loss: 2.4388018269692697

Epoch: 5| Step: 7
Training loss: 2.1656389236450195
Validation loss: 2.439128533486397

Epoch: 5| Step: 8
Training loss: 2.351994276046753
Validation loss: 2.442101988741147

Epoch: 5| Step: 9
Training loss: 2.3869614601135254
Validation loss: 2.4491731915422665

Epoch: 5| Step: 10
Training loss: 2.242609977722168
Validation loss: 2.4482230601772184

Epoch: 138| Step: 0
Training loss: 2.215623378753662
Validation loss: 2.4595726331075034

Epoch: 5| Step: 1
Training loss: 2.331692934036255
Validation loss: 2.4668211936950684

Epoch: 5| Step: 2
Training loss: 2.6294007301330566
Validation loss: 2.479490323733258

Epoch: 5| Step: 3
Training loss: 3.0391054153442383
Validation loss: 2.4941371128123295

Epoch: 5| Step: 4
Training loss: 2.354228973388672
Validation loss: 2.492961529762514

Epoch: 5| Step: 5
Training loss: 2.7923898696899414
Validation loss: 2.478982771596601

Epoch: 5| Step: 6
Training loss: 2.359069347381592
Validation loss: 2.4778953342027563

Epoch: 5| Step: 7
Training loss: 3.163726329803467
Validation loss: 2.4716299118534213

Epoch: 5| Step: 8
Training loss: 2.4848718643188477
Validation loss: 2.4605162220616497

Epoch: 5| Step: 9
Training loss: 3.280884265899658
Validation loss: 2.456794220914123

Epoch: 5| Step: 10
Training loss: 2.433655023574829
Validation loss: 2.4541084894569973

Epoch: 139| Step: 0
Training loss: 2.875523090362549
Validation loss: 2.4453770550348426

Epoch: 5| Step: 1
Training loss: 3.1446914672851562
Validation loss: 2.4324156494550806

Epoch: 5| Step: 2
Training loss: 2.857966899871826
Validation loss: 2.430369004126518

Epoch: 5| Step: 3
Training loss: 2.620948553085327
Validation loss: 2.4308244797491256

Epoch: 5| Step: 4
Training loss: 2.562286853790283
Validation loss: 2.4335120544638684

Epoch: 5| Step: 5
Training loss: 2.7193620204925537
Validation loss: 2.4338245725118988

Epoch: 5| Step: 6
Training loss: 2.345872163772583
Validation loss: 2.4438532052501554

Epoch: 5| Step: 7
Training loss: 1.9743257761001587
Validation loss: 2.4542231713571856

Epoch: 5| Step: 8
Training loss: 1.9687793254852295
Validation loss: 2.450313232278311

Epoch: 5| Step: 9
Training loss: 3.7400856018066406
Validation loss: 2.4468918641408286

Epoch: 5| Step: 10
Training loss: 2.1772892475128174
Validation loss: 2.4481093524604716

Epoch: 140| Step: 0
Training loss: 2.496159553527832
Validation loss: 2.444635555308352

Epoch: 5| Step: 1
Training loss: 2.771986484527588
Validation loss: 2.436200529016474

Epoch: 5| Step: 2
Training loss: 2.9277470111846924
Validation loss: 2.434162260383688

Epoch: 5| Step: 3
Training loss: 2.7723889350891113
Validation loss: 2.4314185598845124

Epoch: 5| Step: 4
Training loss: 2.5427768230438232
Validation loss: 2.4309389668126262

Epoch: 5| Step: 5
Training loss: 2.7182846069335938
Validation loss: 2.421699541871266

Epoch: 5| Step: 6
Training loss: 2.507448673248291
Validation loss: 2.424285832271781

Epoch: 5| Step: 7
Training loss: 2.786724328994751
Validation loss: 2.4193798572786394

Epoch: 5| Step: 8
Training loss: 2.0525128841400146
Validation loss: 2.4211927806177447

Epoch: 5| Step: 9
Training loss: 2.488738536834717
Validation loss: 2.4141020467204433

Epoch: 5| Step: 10
Training loss: 3.0778064727783203
Validation loss: 2.4247045478513165

Epoch: 141| Step: 0
Training loss: 2.931889772415161
Validation loss: 2.425904038131878

Epoch: 5| Step: 1
Training loss: 2.3274331092834473
Validation loss: 2.437270279853575

Epoch: 5| Step: 2
Training loss: 3.096848964691162
Validation loss: 2.4491165889206754

Epoch: 5| Step: 3
Training loss: 2.740365982055664
Validation loss: 2.453142253301477

Epoch: 5| Step: 4
Training loss: 2.3359334468841553
Validation loss: 2.471076899959195

Epoch: 5| Step: 5
Training loss: 2.767354965209961
Validation loss: 2.466645433056739

Epoch: 5| Step: 6
Training loss: 2.825941324234009
Validation loss: 2.4515168769385225

Epoch: 5| Step: 7
Training loss: 2.610429048538208
Validation loss: 2.444089279379896

Epoch: 5| Step: 8
Training loss: 2.3827977180480957
Validation loss: 2.4419221749869724

Epoch: 5| Step: 9
Training loss: 2.5872890949249268
Validation loss: 2.4399391887008504

Epoch: 5| Step: 10
Training loss: 2.4343338012695312
Validation loss: 2.4384966460607385

Epoch: 142| Step: 0
Training loss: 2.5481858253479004
Validation loss: 2.4309024605699765

Epoch: 5| Step: 1
Training loss: 2.398411512374878
Validation loss: 2.435079010584021

Epoch: 5| Step: 2
Training loss: 2.3868556022644043
Validation loss: 2.4246965531379945

Epoch: 5| Step: 3
Training loss: 2.6978390216827393
Validation loss: 2.4288527196453464

Epoch: 5| Step: 4
Training loss: 2.573249101638794
Validation loss: 2.4331494787687897

Epoch: 5| Step: 5
Training loss: 2.954569101333618
Validation loss: 2.4402939196555846

Epoch: 5| Step: 6
Training loss: 2.4476089477539062
Validation loss: 2.446503021383798

Epoch: 5| Step: 7
Training loss: 2.9335250854492188
Validation loss: 2.4485834849778043

Epoch: 5| Step: 8
Training loss: 2.6103339195251465
Validation loss: 2.4510835063072944

Epoch: 5| Step: 9
Training loss: 2.689537525177002
Validation loss: 2.4419967538567

Epoch: 5| Step: 10
Training loss: 2.720048427581787
Validation loss: 2.4384577735777824

Epoch: 143| Step: 0
Training loss: 3.861509323120117
Validation loss: 2.4406042560454337

Epoch: 5| Step: 1
Training loss: 2.3762478828430176
Validation loss: 2.4279240869706675

Epoch: 5| Step: 2
Training loss: 2.591970920562744
Validation loss: 2.4220460179031535

Epoch: 5| Step: 3
Training loss: 2.8542869091033936
Validation loss: 2.419022011500533

Epoch: 5| Step: 4
Training loss: 2.2572107315063477
Validation loss: 2.4290017030572377

Epoch: 5| Step: 5
Training loss: 2.4736428260803223
Validation loss: 2.4235960309223463

Epoch: 5| Step: 6
Training loss: 2.376250743865967
Validation loss: 2.4350615419367307

Epoch: 5| Step: 7
Training loss: 2.8446452617645264
Validation loss: 2.4335953984209286

Epoch: 5| Step: 8
Training loss: 2.5390286445617676
Validation loss: 2.4333739844701623

Epoch: 5| Step: 9
Training loss: 2.6721572875976562
Validation loss: 2.439329010184093

Epoch: 5| Step: 10
Training loss: 2.119492292404175
Validation loss: 2.4364400435519475

Epoch: 144| Step: 0
Training loss: 1.837767243385315
Validation loss: 2.4432726034554104

Epoch: 5| Step: 1
Training loss: 2.3819212913513184
Validation loss: 2.4472873851817143

Epoch: 5| Step: 2
Training loss: 2.221893310546875
Validation loss: 2.458100506054458

Epoch: 5| Step: 3
Training loss: 2.3731186389923096
Validation loss: 2.4611972865237983

Epoch: 5| Step: 4
Training loss: 2.6928629875183105
Validation loss: 2.4620348586831042

Epoch: 5| Step: 5
Training loss: 3.2583611011505127
Validation loss: 2.46366705817561

Epoch: 5| Step: 6
Training loss: 1.9609113931655884
Validation loss: 2.4626872334429013

Epoch: 5| Step: 7
Training loss: 2.642174005508423
Validation loss: 2.4568088875021985

Epoch: 5| Step: 8
Training loss: 3.6658287048339844
Validation loss: 2.4559918680498676

Epoch: 5| Step: 9
Training loss: 2.5113844871520996
Validation loss: 2.4545622012948476

Epoch: 5| Step: 10
Training loss: 3.693418025970459
Validation loss: 2.44486484219951

Epoch: 145| Step: 0
Training loss: 2.201352596282959
Validation loss: 2.4381270049720682

Epoch: 5| Step: 1
Training loss: 2.5306968688964844
Validation loss: 2.439800211178359

Epoch: 5| Step: 2
Training loss: 2.8342223167419434
Validation loss: 2.437278619376562

Epoch: 5| Step: 3
Training loss: 3.2320899963378906
Validation loss: 2.4332541470886557

Epoch: 5| Step: 4
Training loss: 1.9805247783660889
Validation loss: 2.4295180792449624

Epoch: 5| Step: 5
Training loss: 1.8764934539794922
Validation loss: 2.4227869792651107

Epoch: 5| Step: 6
Training loss: 2.3377275466918945
Validation loss: 2.419634196066087

Epoch: 5| Step: 7
Training loss: 3.1153011322021484
Validation loss: 2.4215894027422835

Epoch: 5| Step: 8
Training loss: 2.9987075328826904
Validation loss: 2.4152732818357405

Epoch: 5| Step: 9
Training loss: 3.1506519317626953
Validation loss: 2.418910734115108

Epoch: 5| Step: 10
Training loss: 2.731187343597412
Validation loss: 2.413153712467481

Epoch: 146| Step: 0
Training loss: 2.383455991744995
Validation loss: 2.422019156076575

Epoch: 5| Step: 1
Training loss: 2.5425117015838623
Validation loss: 2.4088763293399604

Epoch: 5| Step: 2
Training loss: 3.2921454906463623
Validation loss: 2.4174069179001676

Epoch: 5| Step: 3
Training loss: 2.0073745250701904
Validation loss: 2.4142763307017665

Epoch: 5| Step: 4
Training loss: 2.345982789993286
Validation loss: 2.420435154309837

Epoch: 5| Step: 5
Training loss: 2.6350197792053223
Validation loss: 2.415971120198568

Epoch: 5| Step: 6
Training loss: 2.6471056938171387
Validation loss: 2.418268708772557

Epoch: 5| Step: 7
Training loss: 2.7577881813049316
Validation loss: 2.4229144588593514

Epoch: 5| Step: 8
Training loss: 2.557316541671753
Validation loss: 2.423235721485589

Epoch: 5| Step: 9
Training loss: 2.4186794757843018
Validation loss: 2.424449138743903

Epoch: 5| Step: 10
Training loss: 3.384106397628784
Validation loss: 2.4260017051491687

Epoch: 147| Step: 0
Training loss: 2.1572160720825195
Validation loss: 2.44090033987517

Epoch: 5| Step: 1
Training loss: 2.8881773948669434
Validation loss: 2.439332699262968

Epoch: 5| Step: 2
Training loss: 2.3332903385162354
Validation loss: 2.4469012163018666

Epoch: 5| Step: 3
Training loss: 2.209251880645752
Validation loss: 2.4435484896424

Epoch: 5| Step: 4
Training loss: 2.4827771186828613
Validation loss: 2.4386500966164375

Epoch: 5| Step: 5
Training loss: 2.942018508911133
Validation loss: 2.424295517706102

Epoch: 5| Step: 6
Training loss: 3.4819202423095703
Validation loss: 2.423490460200976

Epoch: 5| Step: 7
Training loss: 2.1828227043151855
Validation loss: 2.421219810362785

Epoch: 5| Step: 8
Training loss: 2.4965903759002686
Validation loss: 2.41493361226974

Epoch: 5| Step: 9
Training loss: 2.893984317779541
Validation loss: 2.4231695564844276

Epoch: 5| Step: 10
Training loss: 2.8264827728271484
Validation loss: 2.424522720357423

Epoch: 148| Step: 0
Training loss: 2.3450698852539062
Validation loss: 2.4209411041710966

Epoch: 5| Step: 1
Training loss: 2.4961912631988525
Validation loss: 2.4219594129952053

Epoch: 5| Step: 2
Training loss: 3.02459979057312
Validation loss: 2.4286143651572605

Epoch: 5| Step: 3
Training loss: 2.609123468399048
Validation loss: 2.431724538085281

Epoch: 5| Step: 4
Training loss: 3.693091630935669
Validation loss: 2.4413154125213623

Epoch: 5| Step: 5
Training loss: 2.622786045074463
Validation loss: 2.4285349256248883

Epoch: 5| Step: 6
Training loss: 2.034348726272583
Validation loss: 2.422107755496938

Epoch: 5| Step: 7
Training loss: 2.5842947959899902
Validation loss: 2.4150341685100267

Epoch: 5| Step: 8
Training loss: 2.335824489593506
Validation loss: 2.4122153712857153

Epoch: 5| Step: 9
Training loss: 2.7232425212860107
Validation loss: 2.419098702810144

Epoch: 5| Step: 10
Training loss: 2.3510379791259766
Validation loss: 2.4168774209996706

Epoch: 149| Step: 0
Training loss: 3.1081342697143555
Validation loss: 2.4263458098134687

Epoch: 5| Step: 1
Training loss: 2.643026351928711
Validation loss: 2.4295562133994153

Epoch: 5| Step: 2
Training loss: 2.226578950881958
Validation loss: 2.4293730797306186

Epoch: 5| Step: 3
Training loss: 2.7073941230773926
Validation loss: 2.4268015789729294

Epoch: 5| Step: 4
Training loss: 2.24765682220459
Validation loss: 2.422776214538082

Epoch: 5| Step: 5
Training loss: 3.810687303543091
Validation loss: 2.4161851098460536

Epoch: 5| Step: 6
Training loss: 2.7127599716186523
Validation loss: 2.4162530437592538

Epoch: 5| Step: 7
Training loss: 2.250438928604126
Validation loss: 2.4194134281527613

Epoch: 5| Step: 8
Training loss: 2.1028218269348145
Validation loss: 2.4185234859425533

Epoch: 5| Step: 9
Training loss: 2.856684684753418
Validation loss: 2.424346403409076

Epoch: 5| Step: 10
Training loss: 2.2016658782958984
Validation loss: 2.418928310435305

Epoch: 150| Step: 0
Training loss: 3.2439181804656982
Validation loss: 2.420427676170103

Epoch: 5| Step: 1
Training loss: 2.1178393363952637
Validation loss: 2.4270941826605026

Epoch: 5| Step: 2
Training loss: 2.6236329078674316
Validation loss: 2.4250466157031316

Epoch: 5| Step: 3
Training loss: 3.105131149291992
Validation loss: 2.4211759208351054

Epoch: 5| Step: 4
Training loss: 2.5405125617980957
Validation loss: 2.4266400516674085

Epoch: 5| Step: 5
Training loss: 2.415811061859131
Validation loss: 2.418552978064424

Epoch: 5| Step: 6
Training loss: 2.2535667419433594
Validation loss: 2.419462401379821

Epoch: 5| Step: 7
Training loss: 3.3487701416015625
Validation loss: 2.430845650293494

Epoch: 5| Step: 8
Training loss: 2.984998941421509
Validation loss: 2.4320578280315606

Epoch: 5| Step: 9
Training loss: 2.010958194732666
Validation loss: 2.4387325445810952

Epoch: 5| Step: 10
Training loss: 2.2414393424987793
Validation loss: 2.4334057325957925

Epoch: 151| Step: 0
Training loss: 2.2895636558532715
Validation loss: 2.429254836933587

Epoch: 5| Step: 1
Training loss: 2.9793148040771484
Validation loss: 2.418261777970099

Epoch: 5| Step: 2
Training loss: 2.6421611309051514
Validation loss: 2.414965501395605

Epoch: 5| Step: 3
Training loss: 2.2494022846221924
Validation loss: 2.409756545097597

Epoch: 5| Step: 4
Training loss: 2.3926820755004883
Validation loss: 2.4085579790094847

Epoch: 5| Step: 5
Training loss: 2.4611306190490723
Validation loss: 2.4130632928622666

Epoch: 5| Step: 6
Training loss: 2.8363037109375
Validation loss: 2.417597331026549

Epoch: 5| Step: 7
Training loss: 2.9065418243408203
Validation loss: 2.4264024278169036

Epoch: 5| Step: 8
Training loss: 2.8772799968719482
Validation loss: 2.433197723921909

Epoch: 5| Step: 9
Training loss: 2.280029773712158
Validation loss: 2.4441317268597182

Epoch: 5| Step: 10
Training loss: 2.993295192718506
Validation loss: 2.443029829250869

Epoch: 152| Step: 0
Training loss: 2.190650463104248
Validation loss: 2.4423233821827877

Epoch: 5| Step: 1
Training loss: 2.340973377227783
Validation loss: 2.463045791913104

Epoch: 5| Step: 2
Training loss: 2.386363983154297
Validation loss: 2.4728907590271323

Epoch: 5| Step: 3
Training loss: 2.4047698974609375
Validation loss: 2.4779140487793954

Epoch: 5| Step: 4
Training loss: 2.9512412548065186
Validation loss: 2.494129391126735

Epoch: 5| Step: 5
Training loss: 2.590054988861084
Validation loss: 2.5027451105015253

Epoch: 5| Step: 6
Training loss: 2.5924079418182373
Validation loss: 2.507023670340097

Epoch: 5| Step: 7
Training loss: 2.916656017303467
Validation loss: 2.4958572438968125

Epoch: 5| Step: 8
Training loss: 3.1828396320343018
Validation loss: 2.479226255929598

Epoch: 5| Step: 9
Training loss: 2.884293556213379
Validation loss: 2.4557837747758433

Epoch: 5| Step: 10
Training loss: 2.6761257648468018
Validation loss: 2.4431629027089765

Epoch: 153| Step: 0
Training loss: 2.8733878135681152
Validation loss: 2.433675955700618

Epoch: 5| Step: 1
Training loss: 3.4547958374023438
Validation loss: 2.4245203618080384

Epoch: 5| Step: 2
Training loss: 2.7736692428588867
Validation loss: 2.416210356579032

Epoch: 5| Step: 3
Training loss: 2.589661121368408
Validation loss: 2.4137073152808735

Epoch: 5| Step: 4
Training loss: 2.164355516433716
Validation loss: 2.413231216451173

Epoch: 5| Step: 5
Training loss: 2.0615508556365967
Validation loss: 2.421745959148612

Epoch: 5| Step: 6
Training loss: 3.1941428184509277
Validation loss: 2.424083061115716

Epoch: 5| Step: 7
Training loss: 2.3546600341796875
Validation loss: 2.411253321555353

Epoch: 5| Step: 8
Training loss: 2.419517755508423
Validation loss: 2.410344203313192

Epoch: 5| Step: 9
Training loss: 2.614845037460327
Validation loss: 2.420988013667445

Epoch: 5| Step: 10
Training loss: 2.3950934410095215
Validation loss: 2.4279607572863178

Epoch: 154| Step: 0
Training loss: 2.384744882583618
Validation loss: 2.4335644475875364

Epoch: 5| Step: 1
Training loss: 3.068190097808838
Validation loss: 2.451788730518792

Epoch: 5| Step: 2
Training loss: 2.4497427940368652
Validation loss: 2.4690970746419763

Epoch: 5| Step: 3
Training loss: 2.501746654510498
Validation loss: 2.4519716847327446

Epoch: 5| Step: 4
Training loss: 3.0475895404815674
Validation loss: 2.446122856550319

Epoch: 5| Step: 5
Training loss: 2.6875338554382324
Validation loss: 2.440994442150157

Epoch: 5| Step: 6
Training loss: 2.8114373683929443
Validation loss: 2.43209869246329

Epoch: 5| Step: 7
Training loss: 2.2541844844818115
Validation loss: 2.422130533443984

Epoch: 5| Step: 8
Training loss: 2.4152801036834717
Validation loss: 2.432321358752507

Epoch: 5| Step: 9
Training loss: 3.144442081451416
Validation loss: 2.4390210387527302

Epoch: 5| Step: 10
Training loss: 2.10080623626709
Validation loss: 2.448223375505017

Epoch: 155| Step: 0
Training loss: 2.8521921634674072
Validation loss: 2.453424322989679

Epoch: 5| Step: 1
Training loss: 2.985757350921631
Validation loss: 2.45490195674281

Epoch: 5| Step: 2
Training loss: 2.0862667560577393
Validation loss: 2.447644208067207

Epoch: 5| Step: 3
Training loss: 2.324054002761841
Validation loss: 2.439436976627637

Epoch: 5| Step: 4
Training loss: 1.9767593145370483
Validation loss: 2.4347764189525316

Epoch: 5| Step: 5
Training loss: 2.8372859954833984
Validation loss: 2.4333491838106545

Epoch: 5| Step: 6
Training loss: 3.4127631187438965
Validation loss: 2.4208413862412974

Epoch: 5| Step: 7
Training loss: 2.4681477546691895
Validation loss: 2.4219317974582797

Epoch: 5| Step: 8
Training loss: 3.11205792427063
Validation loss: 2.421969821376185

Epoch: 5| Step: 9
Training loss: 2.172147274017334
Validation loss: 2.4170785386075258

Epoch: 5| Step: 10
Training loss: 2.6061153411865234
Validation loss: 2.4137494769147647

Epoch: 156| Step: 0
Training loss: 2.4425199031829834
Validation loss: 2.4224047045553885

Epoch: 5| Step: 1
Training loss: 2.4976730346679688
Validation loss: 2.4230928779930196

Epoch: 5| Step: 2
Training loss: 3.3238472938537598
Validation loss: 2.4232304583313646

Epoch: 5| Step: 3
Training loss: 2.379828453063965
Validation loss: 2.419345162248099

Epoch: 5| Step: 4
Training loss: 2.267240524291992
Validation loss: 2.4239869886829006

Epoch: 5| Step: 5
Training loss: 2.6867318153381348
Validation loss: 2.4200642185826458

Epoch: 5| Step: 6
Training loss: 2.5943286418914795
Validation loss: 2.4144482907428535

Epoch: 5| Step: 7
Training loss: 2.9001498222351074
Validation loss: 2.415400617866106

Epoch: 5| Step: 8
Training loss: 2.3554060459136963
Validation loss: 2.4155453046162925

Epoch: 5| Step: 9
Training loss: 2.3767759799957275
Validation loss: 2.408454215654763

Epoch: 5| Step: 10
Training loss: 3.04659366607666
Validation loss: 2.411501746023855

Epoch: 157| Step: 0
Training loss: 1.956620454788208
Validation loss: 2.408096359622094

Epoch: 5| Step: 1
Training loss: 3.1793901920318604
Validation loss: 2.399707043042747

Epoch: 5| Step: 2
Training loss: 2.88774037361145
Validation loss: 2.4108493328094482

Epoch: 5| Step: 3
Training loss: 2.3409759998321533
Validation loss: 2.4048677721331195

Epoch: 5| Step: 4
Training loss: 1.8843425512313843
Validation loss: 2.410733484452771

Epoch: 5| Step: 5
Training loss: 2.6194357872009277
Validation loss: 2.409682386664934

Epoch: 5| Step: 6
Training loss: 2.4359493255615234
Validation loss: 2.4143846881005073

Epoch: 5| Step: 7
Training loss: 3.30316424369812
Validation loss: 2.4205833840113815

Epoch: 5| Step: 8
Training loss: 2.5733962059020996
Validation loss: 2.4174118836720786

Epoch: 5| Step: 9
Training loss: 2.7947921752929688
Validation loss: 2.420306505695466

Epoch: 5| Step: 10
Training loss: 2.8836824893951416
Validation loss: 2.415767902969032

Epoch: 158| Step: 0
Training loss: 2.228677272796631
Validation loss: 2.406420256501885

Epoch: 5| Step: 1
Training loss: 2.8207805156707764
Validation loss: 2.413897281051964

Epoch: 5| Step: 2
Training loss: 2.6756858825683594
Validation loss: 2.4092188830016763

Epoch: 5| Step: 3
Training loss: 2.384477138519287
Validation loss: 2.4115502372864754

Epoch: 5| Step: 4
Training loss: 2.3585832118988037
Validation loss: 2.4096261455166723

Epoch: 5| Step: 5
Training loss: 2.660313606262207
Validation loss: 2.4090556354932886

Epoch: 5| Step: 6
Training loss: 2.886504650115967
Validation loss: 2.411356376063439

Epoch: 5| Step: 7
Training loss: 2.6579575538635254
Validation loss: 2.411699382207727

Epoch: 5| Step: 8
Training loss: 2.722243547439575
Validation loss: 2.41731676747722

Epoch: 5| Step: 9
Training loss: 2.8768157958984375
Validation loss: 2.4286665608805995

Epoch: 5| Step: 10
Training loss: 2.3235208988189697
Validation loss: 2.438877631259221

Epoch: 159| Step: 0
Training loss: 2.824103593826294
Validation loss: 2.4447957367025395

Epoch: 5| Step: 1
Training loss: 2.2718634605407715
Validation loss: 2.441298695020778

Epoch: 5| Step: 2
Training loss: 2.408250093460083
Validation loss: 2.4424251433341735

Epoch: 5| Step: 3
Training loss: 3.393916606903076
Validation loss: 2.44294511887335

Epoch: 5| Step: 4
Training loss: 3.067143440246582
Validation loss: 2.4620618153643865

Epoch: 5| Step: 5
Training loss: 2.4425735473632812
Validation loss: 2.4527129075860463

Epoch: 5| Step: 6
Training loss: 2.213069438934326
Validation loss: 2.4354659306105746

Epoch: 5| Step: 7
Training loss: 2.1370129585266113
Validation loss: 2.4315388151394424

Epoch: 5| Step: 8
Training loss: 2.4624812602996826
Validation loss: 2.4161955618089244

Epoch: 5| Step: 9
Training loss: 2.929919481277466
Validation loss: 2.4110650682962067

Epoch: 5| Step: 10
Training loss: 2.5677006244659424
Validation loss: 2.404806165285008

Epoch: 160| Step: 0
Training loss: 3.3301615715026855
Validation loss: 2.408957671093684

Epoch: 5| Step: 1
Training loss: 2.613852024078369
Validation loss: 2.41051798353913

Epoch: 5| Step: 2
Training loss: 2.0223026275634766
Validation loss: 2.413586393479378

Epoch: 5| Step: 3
Training loss: 2.428379535675049
Validation loss: 2.4067249669823596

Epoch: 5| Step: 4
Training loss: 2.8780319690704346
Validation loss: 2.4166418403707524

Epoch: 5| Step: 5
Training loss: 2.896108627319336
Validation loss: 2.417138591889412

Epoch: 5| Step: 6
Training loss: 2.2113754749298096
Validation loss: 2.4261965379920056

Epoch: 5| Step: 7
Training loss: 2.865814208984375
Validation loss: 2.424225368807393

Epoch: 5| Step: 8
Training loss: 3.0721359252929688
Validation loss: 2.4134123145893054

Epoch: 5| Step: 9
Training loss: 2.066744089126587
Validation loss: 2.3989416501855336

Epoch: 5| Step: 10
Training loss: 2.2561542987823486
Validation loss: 2.3980011401637906

Epoch: 161| Step: 0
Training loss: 3.020376682281494
Validation loss: 2.391274998264928

Epoch: 5| Step: 1
Training loss: 3.9773991107940674
Validation loss: 2.3978569251234814

Epoch: 5| Step: 2
Training loss: 2.392807960510254
Validation loss: 2.401244581386607

Epoch: 5| Step: 3
Training loss: 2.441669464111328
Validation loss: 2.40622385855644

Epoch: 5| Step: 4
Training loss: 2.3816332817077637
Validation loss: 2.4124196062805834

Epoch: 5| Step: 5
Training loss: 2.599039077758789
Validation loss: 2.4076335430145264

Epoch: 5| Step: 6
Training loss: 2.023908853530884
Validation loss: 2.405399425055391

Epoch: 5| Step: 7
Training loss: 2.58038067817688
Validation loss: 2.4045989064760107

Epoch: 5| Step: 8
Training loss: 2.1405117511749268
Validation loss: 2.3951022445514636

Epoch: 5| Step: 9
Training loss: 2.670734167098999
Validation loss: 2.3885827397787445

Epoch: 5| Step: 10
Training loss: 2.513913869857788
Validation loss: 2.3895097727416665

Epoch: 162| Step: 0
Training loss: 2.5265743732452393
Validation loss: 2.3924453232877996

Epoch: 5| Step: 1
Training loss: 2.7659857273101807
Validation loss: 2.3949478518578315

Epoch: 5| Step: 2
Training loss: 2.8291571140289307
Validation loss: 2.4001595179239907

Epoch: 5| Step: 3
Training loss: 3.1408138275146484
Validation loss: 2.4040620429541475

Epoch: 5| Step: 4
Training loss: 3.4202377796173096
Validation loss: 2.39776748482899

Epoch: 5| Step: 5
Training loss: 2.173046827316284
Validation loss: 2.4036479380822953

Epoch: 5| Step: 6
Training loss: 1.9096286296844482
Validation loss: 2.4037384961241033

Epoch: 5| Step: 7
Training loss: 2.4337589740753174
Validation loss: 2.413440683836578

Epoch: 5| Step: 8
Training loss: 2.7156035900115967
Validation loss: 2.4249102582213697

Epoch: 5| Step: 9
Training loss: 2.5613327026367188
Validation loss: 2.414706794164514

Epoch: 5| Step: 10
Training loss: 2.205174207687378
Validation loss: 2.409934769394577

Epoch: 163| Step: 0
Training loss: 2.632600784301758
Validation loss: 2.411975186358216

Epoch: 5| Step: 1
Training loss: 2.96526837348938
Validation loss: 2.4074660424263246

Epoch: 5| Step: 2
Training loss: 2.2466862201690674
Validation loss: 2.398854737640709

Epoch: 5| Step: 3
Training loss: 2.042476177215576
Validation loss: 2.3941266562349055

Epoch: 5| Step: 4
Training loss: 3.366469621658325
Validation loss: 2.3882293675535466

Epoch: 5| Step: 5
Training loss: 2.3999454975128174
Validation loss: 2.386909451535953

Epoch: 5| Step: 6
Training loss: 2.6155788898468018
Validation loss: 2.3858252750929965

Epoch: 5| Step: 7
Training loss: 2.8654940128326416
Validation loss: 2.3853795041320143

Epoch: 5| Step: 8
Training loss: 2.9306211471557617
Validation loss: 2.394910899541711

Epoch: 5| Step: 9
Training loss: 2.310502290725708
Validation loss: 2.389303635525447

Epoch: 5| Step: 10
Training loss: 2.347160816192627
Validation loss: 2.3990433523731847

Epoch: 164| Step: 0
Training loss: 2.2661495208740234
Validation loss: 2.390298210164552

Epoch: 5| Step: 1
Training loss: 2.546208381652832
Validation loss: 2.388159559619042

Epoch: 5| Step: 2
Training loss: 2.616678476333618
Validation loss: 2.3971816262891217

Epoch: 5| Step: 3
Training loss: 2.657599925994873
Validation loss: 2.3979579915282545

Epoch: 5| Step: 4
Training loss: 3.1017985343933105
Validation loss: 2.391604967014764

Epoch: 5| Step: 5
Training loss: 3.297482967376709
Validation loss: 2.4054763752927064

Epoch: 5| Step: 6
Training loss: 2.2068722248077393
Validation loss: 2.3947128531753377

Epoch: 5| Step: 7
Training loss: 2.2951884269714355
Validation loss: 2.3960440517753683

Epoch: 5| Step: 8
Training loss: 2.676203966140747
Validation loss: 2.4046643831396617

Epoch: 5| Step: 9
Training loss: 2.9966514110565186
Validation loss: 2.402112522432881

Epoch: 5| Step: 10
Training loss: 1.9812101125717163
Validation loss: 2.4067795302278254

Epoch: 165| Step: 0
Training loss: 2.667306423187256
Validation loss: 2.4218335638764086

Epoch: 5| Step: 1
Training loss: 2.3993992805480957
Validation loss: 2.418391522540841

Epoch: 5| Step: 2
Training loss: 3.400874376296997
Validation loss: 2.4262513960561445

Epoch: 5| Step: 3
Training loss: 2.5261454582214355
Validation loss: 2.41778536124896

Epoch: 5| Step: 4
Training loss: 2.8543455600738525
Validation loss: 2.4121639010726765

Epoch: 5| Step: 5
Training loss: 2.9226930141448975
Validation loss: 2.4065520942852063

Epoch: 5| Step: 6
Training loss: 2.5544180870056152
Validation loss: 2.4036849391075874

Epoch: 5| Step: 7
Training loss: 1.5215173959732056
Validation loss: 2.3974616348102527

Epoch: 5| Step: 8
Training loss: 2.557469606399536
Validation loss: 2.3928351376646306

Epoch: 5| Step: 9
Training loss: 2.4526476860046387
Validation loss: 2.3941131176487094

Epoch: 5| Step: 10
Training loss: 2.856666326522827
Validation loss: 2.4009644754471315

Epoch: 166| Step: 0
Training loss: 2.545549154281616
Validation loss: 2.392855695498887

Epoch: 5| Step: 1
Training loss: 2.7008228302001953
Validation loss: 2.3881792432518414

Epoch: 5| Step: 2
Training loss: 2.0370993614196777
Validation loss: 2.387521741210773

Epoch: 5| Step: 3
Training loss: 3.104539394378662
Validation loss: 2.3921733287072953

Epoch: 5| Step: 4
Training loss: 2.802605390548706
Validation loss: 2.3975904090430147

Epoch: 5| Step: 5
Training loss: 2.5687737464904785
Validation loss: 2.3919787714558263

Epoch: 5| Step: 6
Training loss: 2.869128465652466
Validation loss: 2.4003437719037457

Epoch: 5| Step: 7
Training loss: 2.218761444091797
Validation loss: 2.39615975528635

Epoch: 5| Step: 8
Training loss: 2.0433437824249268
Validation loss: 2.39821264307986

Epoch: 5| Step: 9
Training loss: 2.8612239360809326
Validation loss: 2.4005547467098443

Epoch: 5| Step: 10
Training loss: 2.873786211013794
Validation loss: 2.4074907020855973

Epoch: 167| Step: 0
Training loss: 2.838268995285034
Validation loss: 2.411846222416047

Epoch: 5| Step: 1
Training loss: 2.312102794647217
Validation loss: 2.4155370625116492

Epoch: 5| Step: 2
Training loss: 2.9215073585510254
Validation loss: 2.4230528070080664

Epoch: 5| Step: 3
Training loss: 2.755282402038574
Validation loss: 2.4199686114506056

Epoch: 5| Step: 4
Training loss: 2.670870780944824
Validation loss: 2.4124294532242643

Epoch: 5| Step: 5
Training loss: 2.7052717208862305
Validation loss: 2.4075684547424316

Epoch: 5| Step: 6
Training loss: 2.1239051818847656
Validation loss: 2.398312291791362

Epoch: 5| Step: 7
Training loss: 2.9566943645477295
Validation loss: 2.391565017802741

Epoch: 5| Step: 8
Training loss: 1.9404083490371704
Validation loss: 2.396904665936706

Epoch: 5| Step: 9
Training loss: 2.491605520248413
Validation loss: 2.3961541780861477

Epoch: 5| Step: 10
Training loss: 3.003394603729248
Validation loss: 2.399745233597294

Epoch: 168| Step: 0
Training loss: 2.371995687484741
Validation loss: 2.4009650317571496

Epoch: 5| Step: 1
Training loss: 2.487706422805786
Validation loss: 2.404358815121394

Epoch: 5| Step: 2
Training loss: 3.249504566192627
Validation loss: 2.407370223793932

Epoch: 5| Step: 3
Training loss: 2.8265299797058105
Validation loss: 2.4066420421805432

Epoch: 5| Step: 4
Training loss: 3.1188454627990723
Validation loss: 2.4084566562406478

Epoch: 5| Step: 5
Training loss: 1.6579177379608154
Validation loss: 2.4128069851988103

Epoch: 5| Step: 6
Training loss: 2.1717731952667236
Validation loss: 2.4080916066323557

Epoch: 5| Step: 7
Training loss: 2.617602586746216
Validation loss: 2.418177802075622

Epoch: 5| Step: 8
Training loss: 2.642058849334717
Validation loss: 2.4146907893560265

Epoch: 5| Step: 9
Training loss: 2.9747965335845947
Validation loss: 2.4079531238925074

Epoch: 5| Step: 10
Training loss: 2.3981001377105713
Validation loss: 2.4077655064162387

Epoch: 169| Step: 0
Training loss: 2.191518783569336
Validation loss: 2.4079891763707644

Epoch: 5| Step: 1
Training loss: 3.5961060523986816
Validation loss: 2.393214693633459

Epoch: 5| Step: 2
Training loss: 2.878551959991455
Validation loss: 2.389171605469078

Epoch: 5| Step: 3
Training loss: 2.3897063732147217
Validation loss: 2.374043982516053

Epoch: 5| Step: 4
Training loss: 2.469616413116455
Validation loss: 2.386299092282531

Epoch: 5| Step: 5
Training loss: 2.9325995445251465
Validation loss: 2.37749546317644

Epoch: 5| Step: 6
Training loss: 2.3818321228027344
Validation loss: 2.3805644717267764

Epoch: 5| Step: 7
Training loss: 1.9792613983154297
Validation loss: 2.379270980435033

Epoch: 5| Step: 8
Training loss: 3.170011520385742
Validation loss: 2.374463468469599

Epoch: 5| Step: 9
Training loss: 2.5466761589050293
Validation loss: 2.3767104834638615

Epoch: 5| Step: 10
Training loss: 2.0055127143859863
Validation loss: 2.3862078600032355

Epoch: 170| Step: 0
Training loss: 2.5114479064941406
Validation loss: 2.391908927630353

Epoch: 5| Step: 1
Training loss: 2.8320813179016113
Validation loss: 2.3893110572650866

Epoch: 5| Step: 2
Training loss: 2.4884190559387207
Validation loss: 2.405096471950572

Epoch: 5| Step: 3
Training loss: 2.6821320056915283
Validation loss: 2.4142966706265687

Epoch: 5| Step: 4
Training loss: 2.162977933883667
Validation loss: 2.413786272848806

Epoch: 5| Step: 5
Training loss: 2.4574685096740723
Validation loss: 2.4187545122638827

Epoch: 5| Step: 6
Training loss: 2.5030970573425293
Validation loss: 2.4479764661481305

Epoch: 5| Step: 7
Training loss: 2.6191229820251465
Validation loss: 2.464501932103147

Epoch: 5| Step: 8
Training loss: 3.1746714115142822
Validation loss: 2.449746634370537

Epoch: 5| Step: 9
Training loss: 3.121392250061035
Validation loss: 2.4462857195126113

Epoch: 5| Step: 10
Training loss: 1.991642713546753
Validation loss: 2.4324941712041057

Epoch: 171| Step: 0
Training loss: 2.3394229412078857
Validation loss: 2.408407331794821

Epoch: 5| Step: 1
Training loss: 2.4680886268615723
Validation loss: 2.3833508337697675

Epoch: 5| Step: 2
Training loss: 2.824951648712158
Validation loss: 2.393781151822818

Epoch: 5| Step: 3
Training loss: 2.1599578857421875
Validation loss: 2.3809411884636007

Epoch: 5| Step: 4
Training loss: 2.677185535430908
Validation loss: 2.3837052237602974

Epoch: 5| Step: 5
Training loss: 2.273499011993408
Validation loss: 2.381049656098889

Epoch: 5| Step: 6
Training loss: 2.117318630218506
Validation loss: 2.378490947907971

Epoch: 5| Step: 7
Training loss: 2.7167468070983887
Validation loss: 2.3962246653854207

Epoch: 5| Step: 8
Training loss: 3.320319652557373
Validation loss: 2.39617173646086

Epoch: 5| Step: 9
Training loss: 3.1036524772644043
Validation loss: 2.3902612552847913

Epoch: 5| Step: 10
Training loss: 2.7080581188201904
Validation loss: 2.403104212976271

Epoch: 172| Step: 0
Training loss: 2.29963755607605
Validation loss: 2.4073433670946347

Epoch: 5| Step: 1
Training loss: 2.1489036083221436
Validation loss: 2.4262995463545605

Epoch: 5| Step: 2
Training loss: 2.904470920562744
Validation loss: 2.4084492857738207

Epoch: 5| Step: 3
Training loss: 2.987879991531372
Validation loss: 2.397388353142687

Epoch: 5| Step: 4
Training loss: 1.9325649738311768
Validation loss: 2.406431600611697

Epoch: 5| Step: 5
Training loss: 2.382174253463745
Validation loss: 2.411563196489888

Epoch: 5| Step: 6
Training loss: 2.747809886932373
Validation loss: 2.4026946175482964

Epoch: 5| Step: 7
Training loss: 2.9473583698272705
Validation loss: 2.3998233092728483

Epoch: 5| Step: 8
Training loss: 2.4726006984710693
Validation loss: 2.4098907029756935

Epoch: 5| Step: 9
Training loss: 3.150391101837158
Validation loss: 2.4125616704263995

Epoch: 5| Step: 10
Training loss: 2.6596999168395996
Validation loss: 2.4080933396534254

Epoch: 173| Step: 0
Training loss: 1.5237314701080322
Validation loss: 2.4003450434695006

Epoch: 5| Step: 1
Training loss: 2.320003032684326
Validation loss: 2.393113338819114

Epoch: 5| Step: 2
Training loss: 3.013171672821045
Validation loss: 2.388834276506978

Epoch: 5| Step: 3
Training loss: 2.7096285820007324
Validation loss: 2.380741519312705

Epoch: 5| Step: 4
Training loss: 2.3835129737854004
Validation loss: 2.378370369634321

Epoch: 5| Step: 5
Training loss: 2.635711669921875
Validation loss: 2.374999410362654

Epoch: 5| Step: 6
Training loss: 3.057762622833252
Validation loss: 2.375102843007734

Epoch: 5| Step: 7
Training loss: 2.34887433052063
Validation loss: 2.3719614603186168

Epoch: 5| Step: 8
Training loss: 3.118861436843872
Validation loss: 2.377655094669711

Epoch: 5| Step: 9
Training loss: 2.4182708263397217
Validation loss: 2.3801964303498626

Epoch: 5| Step: 10
Training loss: 3.168855667114258
Validation loss: 2.38369252604823

Epoch: 174| Step: 0
Training loss: 2.423741340637207
Validation loss: 2.3908480290443666

Epoch: 5| Step: 1
Training loss: 2.1129415035247803
Validation loss: 2.3899756887907624

Epoch: 5| Step: 2
Training loss: 2.419426441192627
Validation loss: 2.4111595153808594

Epoch: 5| Step: 3
Training loss: 2.951199769973755
Validation loss: 2.4029452326477214

Epoch: 5| Step: 4
Training loss: 3.0953686237335205
Validation loss: 2.4069796890340824

Epoch: 5| Step: 5
Training loss: 2.4116873741149902
Validation loss: 2.395438253238637

Epoch: 5| Step: 6
Training loss: 2.531911611557007
Validation loss: 2.397235021796278

Epoch: 5| Step: 7
Training loss: 2.6312954425811768
Validation loss: 2.3890974854910247

Epoch: 5| Step: 8
Training loss: 2.4027135372161865
Validation loss: 2.3832018683033604

Epoch: 5| Step: 9
Training loss: 2.387507915496826
Validation loss: 2.3988815661399596

Epoch: 5| Step: 10
Training loss: 3.250243663787842
Validation loss: 2.4016949438279673

Epoch: 175| Step: 0
Training loss: 2.687164068222046
Validation loss: 2.4024558451867875

Epoch: 5| Step: 1
Training loss: 2.744372844696045
Validation loss: 2.407908352472449

Epoch: 5| Step: 2
Training loss: 2.166571855545044
Validation loss: 2.410156028245085

Epoch: 5| Step: 3
Training loss: 2.430060863494873
Validation loss: 2.4129085566407893

Epoch: 5| Step: 4
Training loss: 2.243184804916382
Validation loss: 2.410998503367106

Epoch: 5| Step: 5
Training loss: 2.7130446434020996
Validation loss: 2.3957148739086684

Epoch: 5| Step: 6
Training loss: 2.710763454437256
Validation loss: 2.39756517769188

Epoch: 5| Step: 7
Training loss: 2.898813247680664
Validation loss: 2.39647606367706

Epoch: 5| Step: 8
Training loss: 2.277592182159424
Validation loss: 2.3926672435575917

Epoch: 5| Step: 9
Training loss: 2.7794241905212402
Validation loss: 2.389955723157493

Epoch: 5| Step: 10
Training loss: 2.9368371963500977
Validation loss: 2.3897892121345765

Epoch: 176| Step: 0
Training loss: 2.145357847213745
Validation loss: 2.3965931400176017

Epoch: 5| Step: 1
Training loss: 2.9890317916870117
Validation loss: 2.3846756642864597

Epoch: 5| Step: 2
Training loss: 2.224073886871338
Validation loss: 2.38536649621943

Epoch: 5| Step: 3
Training loss: 2.9769539833068848
Validation loss: 2.3735905898514615

Epoch: 5| Step: 4
Training loss: 2.41459321975708
Validation loss: 2.378045715311522

Epoch: 5| Step: 5
Training loss: 2.618379592895508
Validation loss: 2.3750782576940392

Epoch: 5| Step: 6
Training loss: 2.960808515548706
Validation loss: 2.3827876044857885

Epoch: 5| Step: 7
Training loss: 2.2111968994140625
Validation loss: 2.3893728281861994

Epoch: 5| Step: 8
Training loss: 2.7015902996063232
Validation loss: 2.388007697238717

Epoch: 5| Step: 9
Training loss: 2.456657886505127
Validation loss: 2.3902469988792174

Epoch: 5| Step: 10
Training loss: 2.795207977294922
Validation loss: 2.3877837247745965

Epoch: 177| Step: 0
Training loss: 2.1751017570495605
Validation loss: 2.388778563468687

Epoch: 5| Step: 1
Training loss: 2.0631911754608154
Validation loss: 2.3919661045074463

Epoch: 5| Step: 2
Training loss: 2.9289398193359375
Validation loss: 2.392008263577697

Epoch: 5| Step: 3
Training loss: 2.7358386516571045
Validation loss: 2.3956011085100073

Epoch: 5| Step: 4
Training loss: 2.580589532852173
Validation loss: 2.3960538423189552

Epoch: 5| Step: 5
Training loss: 2.3054916858673096
Validation loss: 2.4010684054384948

Epoch: 5| Step: 6
Training loss: 2.994119167327881
Validation loss: 2.396737575531006

Epoch: 5| Step: 7
Training loss: 2.837796688079834
Validation loss: 2.4076957087362967

Epoch: 5| Step: 8
Training loss: 2.775747776031494
Validation loss: 2.397504834718602

Epoch: 5| Step: 9
Training loss: 2.6773085594177246
Validation loss: 2.3840755185773297

Epoch: 5| Step: 10
Training loss: 2.3984665870666504
Validation loss: 2.3817995722575853

Epoch: 178| Step: 0
Training loss: 2.7403616905212402
Validation loss: 2.3768218101993686

Epoch: 5| Step: 1
Training loss: 2.4058454036712646
Validation loss: 2.377592526456361

Epoch: 5| Step: 2
Training loss: 2.7702224254608154
Validation loss: 2.3662917498619325

Epoch: 5| Step: 3
Training loss: 2.8630294799804688
Validation loss: 2.3697037158473844

Epoch: 5| Step: 4
Training loss: 2.722541093826294
Validation loss: 2.365431959911059

Epoch: 5| Step: 5
Training loss: 2.7554514408111572
Validation loss: 2.368924102475566

Epoch: 5| Step: 6
Training loss: 2.5341415405273438
Validation loss: 2.370902312699185

Epoch: 5| Step: 7
Training loss: 2.0969252586364746
Validation loss: 2.378769951481973

Epoch: 5| Step: 8
Training loss: 2.838291645050049
Validation loss: 2.3815662963415987

Epoch: 5| Step: 9
Training loss: 1.8685262203216553
Validation loss: 2.390164985451647

Epoch: 5| Step: 10
Training loss: 2.946962594985962
Validation loss: 2.392453452592255

Epoch: 179| Step: 0
Training loss: 2.1594111919403076
Validation loss: 2.40036202246143

Epoch: 5| Step: 1
Training loss: 2.6968801021575928
Validation loss: 2.4085931598499255

Epoch: 5| Step: 2
Training loss: 2.724353313446045
Validation loss: 2.4062999115195325

Epoch: 5| Step: 3
Training loss: 2.6290478706359863
Validation loss: 2.410974156471991

Epoch: 5| Step: 4
Training loss: 2.7023115158081055
Validation loss: 2.403393873604395

Epoch: 5| Step: 5
Training loss: 2.8688056468963623
Validation loss: 2.396986510163994

Epoch: 5| Step: 6
Training loss: 2.7570502758026123
Validation loss: 2.403105528123917

Epoch: 5| Step: 7
Training loss: 2.554088830947876
Validation loss: 2.393024121561358

Epoch: 5| Step: 8
Training loss: 2.5739362239837646
Validation loss: 2.3810555909269597

Epoch: 5| Step: 9
Training loss: 2.4562275409698486
Validation loss: 2.3843387442250408

Epoch: 5| Step: 10
Training loss: 2.2402327060699463
Validation loss: 2.3757366108637985

Epoch: 180| Step: 0
Training loss: 3.1022963523864746
Validation loss: 2.3666136623710714

Epoch: 5| Step: 1
Training loss: 2.3335964679718018
Validation loss: 2.3701484408429874

Epoch: 5| Step: 2
Training loss: 2.1958775520324707
Validation loss: 2.3593952296882548

Epoch: 5| Step: 3
Training loss: 2.6901183128356934
Validation loss: 2.3611033936982513

Epoch: 5| Step: 4
Training loss: 2.49776029586792
Validation loss: 2.3697870418589604

Epoch: 5| Step: 5
Training loss: 2.0083909034729004
Validation loss: 2.3605127283321914

Epoch: 5| Step: 6
Training loss: 2.6918463706970215
Validation loss: 2.361321690262005

Epoch: 5| Step: 7
Training loss: 2.8707735538482666
Validation loss: 2.357365905597646

Epoch: 5| Step: 8
Training loss: 2.435884952545166
Validation loss: 2.3592196869593796

Epoch: 5| Step: 9
Training loss: 2.92067289352417
Validation loss: 2.3658975785778416

Epoch: 5| Step: 10
Training loss: 2.8540549278259277
Validation loss: 2.372815878160538

Epoch: 181| Step: 0
Training loss: 2.5451700687408447
Validation loss: 2.37863185328822

Epoch: 5| Step: 1
Training loss: 2.925490140914917
Validation loss: 2.374644746062576

Epoch: 5| Step: 2
Training loss: 2.8587632179260254
Validation loss: 2.3701824398450952

Epoch: 5| Step: 3
Training loss: 2.2670679092407227
Validation loss: 2.3777730516208115

Epoch: 5| Step: 4
Training loss: 2.4050803184509277
Validation loss: 2.3850810015073387

Epoch: 5| Step: 5
Training loss: 1.9747257232666016
Validation loss: 2.391252040863037

Epoch: 5| Step: 6
Training loss: 3.0259745121002197
Validation loss: 2.4013273613427275

Epoch: 5| Step: 7
Training loss: 2.632535457611084
Validation loss: 2.415252818856188

Epoch: 5| Step: 8
Training loss: 2.9908077716827393
Validation loss: 2.4149159936494726

Epoch: 5| Step: 9
Training loss: 2.069267988204956
Validation loss: 2.424494392128401

Epoch: 5| Step: 10
Training loss: 2.9276063442230225
Validation loss: 2.4251196717703216

Epoch: 182| Step: 0
Training loss: 2.386849880218506
Validation loss: 2.4305922959440496

Epoch: 5| Step: 1
Training loss: 2.3791797161102295
Validation loss: 2.4115629452531055

Epoch: 5| Step: 2
Training loss: 2.2479283809661865
Validation loss: 2.4041700234977146

Epoch: 5| Step: 3
Training loss: 2.7096519470214844
Validation loss: 2.3974007842361287

Epoch: 5| Step: 4
Training loss: 3.5833029747009277
Validation loss: 2.3938738838318856

Epoch: 5| Step: 5
Training loss: 2.5982565879821777
Validation loss: 2.3773274703692366

Epoch: 5| Step: 6
Training loss: 2.0313522815704346
Validation loss: 2.369328065585065

Epoch: 5| Step: 7
Training loss: 3.273486375808716
Validation loss: 2.366022563749744

Epoch: 5| Step: 8
Training loss: 1.9638487100601196
Validation loss: 2.3682110181418796

Epoch: 5| Step: 9
Training loss: 2.728621006011963
Validation loss: 2.36045330057862

Epoch: 5| Step: 10
Training loss: 2.5845720767974854
Validation loss: 2.3615629211548836

Epoch: 183| Step: 0
Training loss: 2.027988910675049
Validation loss: 2.362577910064369

Epoch: 5| Step: 1
Training loss: 2.880143165588379
Validation loss: 2.3629983035467004

Epoch: 5| Step: 2
Training loss: 3.2539877891540527
Validation loss: 2.3646269690605903

Epoch: 5| Step: 3
Training loss: 3.1195974349975586
Validation loss: 2.37496369372132

Epoch: 5| Step: 4
Training loss: 2.0494015216827393
Validation loss: 2.379088096721198

Epoch: 5| Step: 5
Training loss: 2.53993558883667
Validation loss: 2.381216800341042

Epoch: 5| Step: 6
Training loss: 2.0829806327819824
Validation loss: 2.3880545913532214

Epoch: 5| Step: 7
Training loss: 2.371176242828369
Validation loss: 2.391747569525114

Epoch: 5| Step: 8
Training loss: 2.402791738510132
Validation loss: 2.382518527328327

Epoch: 5| Step: 9
Training loss: 3.3106884956359863
Validation loss: 2.3951623362879597

Epoch: 5| Step: 10
Training loss: 2.483718156814575
Validation loss: 2.385567065208189

Epoch: 184| Step: 0
Training loss: 2.591517210006714
Validation loss: 2.382773514716856

Epoch: 5| Step: 1
Training loss: 2.598092555999756
Validation loss: 2.378208542382845

Epoch: 5| Step: 2
Training loss: 2.4137284755706787
Validation loss: 2.384503964454897

Epoch: 5| Step: 3
Training loss: 2.8322997093200684
Validation loss: 2.4003865154840613

Epoch: 5| Step: 4
Training loss: 2.8391761779785156
Validation loss: 2.39960838133289

Epoch: 5| Step: 5
Training loss: 2.6009702682495117
Validation loss: 2.3917753004258677

Epoch: 5| Step: 6
Training loss: 2.7883200645446777
Validation loss: 2.3910702223418863

Epoch: 5| Step: 7
Training loss: 2.3789238929748535
Validation loss: 2.3810681425115114

Epoch: 5| Step: 8
Training loss: 2.0472686290740967
Validation loss: 2.381269011446225

Epoch: 5| Step: 9
Training loss: 2.400369167327881
Validation loss: 2.3755219059605754

Epoch: 5| Step: 10
Training loss: 2.9409079551696777
Validation loss: 2.363929989517376

Epoch: 185| Step: 0
Training loss: 3.0037829875946045
Validation loss: 2.362930285033359

Epoch: 5| Step: 1
Training loss: 2.886340618133545
Validation loss: 2.3531789638662852

Epoch: 5| Step: 2
Training loss: 2.4153385162353516
Validation loss: 2.3598505066287134

Epoch: 5| Step: 3
Training loss: 2.432892322540283
Validation loss: 2.3601547543720534

Epoch: 5| Step: 4
Training loss: 2.8662655353546143
Validation loss: 2.3593528014357372

Epoch: 5| Step: 5
Training loss: 2.3256936073303223
Validation loss: 2.3619276682535806

Epoch: 5| Step: 6
Training loss: 2.9137332439422607
Validation loss: 2.3556379759183494

Epoch: 5| Step: 7
Training loss: 2.1984524726867676
Validation loss: 2.3658198951393046

Epoch: 5| Step: 8
Training loss: 1.6025722026824951
Validation loss: 2.365658995925739

Epoch: 5| Step: 9
Training loss: 2.9364914894104004
Validation loss: 2.371606061535497

Epoch: 5| Step: 10
Training loss: 2.8564276695251465
Validation loss: 2.3694581421472694

Epoch: 186| Step: 0
Training loss: 2.9643425941467285
Validation loss: 2.3733147651918474

Epoch: 5| Step: 1
Training loss: 2.2926266193389893
Validation loss: 2.3800868321490545

Epoch: 5| Step: 2
Training loss: 1.7371647357940674
Validation loss: 2.3811473231161795

Epoch: 5| Step: 3
Training loss: 2.723909854888916
Validation loss: 2.3928240140279136

Epoch: 5| Step: 4
Training loss: 2.3415446281433105
Validation loss: 2.4051238888053486

Epoch: 5| Step: 5
Training loss: 2.1549174785614014
Validation loss: 2.3995784277557046

Epoch: 5| Step: 6
Training loss: 2.693850517272949
Validation loss: 2.398311925190751

Epoch: 5| Step: 7
Training loss: 3.025343656539917
Validation loss: 2.386955735503986

Epoch: 5| Step: 8
Training loss: 2.5394375324249268
Validation loss: 2.3820867871725433

Epoch: 5| Step: 9
Training loss: 2.973644495010376
Validation loss: 2.3863688873988327

Epoch: 5| Step: 10
Training loss: 3.0157806873321533
Validation loss: 2.3762752471431607

Epoch: 187| Step: 0
Training loss: 2.5172507762908936
Validation loss: 2.36800911349635

Epoch: 5| Step: 1
Training loss: 2.4170124530792236
Validation loss: 2.355065876437772

Epoch: 5| Step: 2
Training loss: 1.9342670440673828
Validation loss: 2.352226008651077

Epoch: 5| Step: 3
Training loss: 2.7931389808654785
Validation loss: 2.3517185590600453

Epoch: 5| Step: 4
Training loss: 2.787005662918091
Validation loss: 2.351684801040157

Epoch: 5| Step: 5
Training loss: 2.7816262245178223
Validation loss: 2.3476316775045087

Epoch: 5| Step: 6
Training loss: 2.717042922973633
Validation loss: 2.3600496092150287

Epoch: 5| Step: 7
Training loss: 2.3082189559936523
Validation loss: 2.3658519534654516

Epoch: 5| Step: 8
Training loss: 2.244201183319092
Validation loss: 2.3957378325923795

Epoch: 5| Step: 9
Training loss: 3.161362648010254
Validation loss: 2.3953651946078063

Epoch: 5| Step: 10
Training loss: 2.807729482650757
Validation loss: 2.403667447387531

Epoch: 188| Step: 0
Training loss: 2.122704029083252
Validation loss: 2.3926258343522266

Epoch: 5| Step: 1
Training loss: 2.043135166168213
Validation loss: 2.39892158457028

Epoch: 5| Step: 2
Training loss: 2.3014655113220215
Validation loss: 2.4131379230048067

Epoch: 5| Step: 3
Training loss: 2.6817588806152344
Validation loss: 2.4078910632800032

Epoch: 5| Step: 4
Training loss: 3.1664891242980957
Validation loss: 2.3840585293308383

Epoch: 5| Step: 5
Training loss: 2.971463441848755
Validation loss: 2.3752287818539526

Epoch: 5| Step: 6
Training loss: 2.8839409351348877
Validation loss: 2.3625674388741933

Epoch: 5| Step: 7
Training loss: 2.7825655937194824
Validation loss: 2.359426167703444

Epoch: 5| Step: 8
Training loss: 2.5622260570526123
Validation loss: 2.360010531640822

Epoch: 5| Step: 9
Training loss: 2.0725255012512207
Validation loss: 2.354516080630723

Epoch: 5| Step: 10
Training loss: 2.8153328895568848
Validation loss: 2.3576061161615516

Epoch: 189| Step: 0
Training loss: 1.8919792175292969
Validation loss: 2.3629124036399265

Epoch: 5| Step: 1
Training loss: 2.4112372398376465
Validation loss: 2.366652952727451

Epoch: 5| Step: 2
Training loss: 2.2771191596984863
Validation loss: 2.367498169663132

Epoch: 5| Step: 3
Training loss: 2.940845251083374
Validation loss: 2.3761006439885786

Epoch: 5| Step: 4
Training loss: 3.237046480178833
Validation loss: 2.371423731568039

Epoch: 5| Step: 5
Training loss: 2.5971317291259766
Validation loss: 2.3768980861991964

Epoch: 5| Step: 6
Training loss: 2.5484251976013184
Validation loss: 2.3855803833212903

Epoch: 5| Step: 7
Training loss: 3.1347098350524902
Validation loss: 2.3824581061640093

Epoch: 5| Step: 8
Training loss: 2.5613937377929688
Validation loss: 2.3737087595847344

Epoch: 5| Step: 9
Training loss: 1.9888839721679688
Validation loss: 2.387711532654301

Epoch: 5| Step: 10
Training loss: 2.7668018341064453
Validation loss: 2.3853100499799176

Epoch: 190| Step: 0
Training loss: 1.9353463649749756
Validation loss: 2.3909122969514582

Epoch: 5| Step: 1
Training loss: 2.152752637863159
Validation loss: 2.3843789100646973

Epoch: 5| Step: 2
Training loss: 2.9400522708892822
Validation loss: 2.391541278490456

Epoch: 5| Step: 3
Training loss: 3.1918177604675293
Validation loss: 2.3986722512911727

Epoch: 5| Step: 4
Training loss: 2.7808594703674316
Validation loss: 2.3986774567634828

Epoch: 5| Step: 5
Training loss: 2.460278272628784
Validation loss: 2.3872449244222333

Epoch: 5| Step: 6
Training loss: 2.444450616836548
Validation loss: 2.3880699078241983

Epoch: 5| Step: 7
Training loss: 2.7747600078582764
Validation loss: 2.378248107048773

Epoch: 5| Step: 8
Training loss: 3.137448787689209
Validation loss: 2.3798007708723827

Epoch: 5| Step: 9
Training loss: 2.128951072692871
Validation loss: 2.372065700510497

Epoch: 5| Step: 10
Training loss: 2.3276615142822266
Validation loss: 2.361234518789476

Epoch: 191| Step: 0
Training loss: 1.9971773624420166
Validation loss: 2.354106496739131

Epoch: 5| Step: 1
Training loss: 1.9741500616073608
Validation loss: 2.355122858478177

Epoch: 5| Step: 2
Training loss: 3.239140272140503
Validation loss: 2.3602957058978338

Epoch: 5| Step: 3
Training loss: 2.465707302093506
Validation loss: 2.3548760003941034

Epoch: 5| Step: 4
Training loss: 2.811549425125122
Validation loss: 2.349083718433175

Epoch: 5| Step: 5
Training loss: 2.954263210296631
Validation loss: 2.365719033825782

Epoch: 5| Step: 6
Training loss: 3.184638500213623
Validation loss: 2.3556417931792555

Epoch: 5| Step: 7
Training loss: 1.743807077407837
Validation loss: 2.3635210273086384

Epoch: 5| Step: 8
Training loss: 2.803420066833496
Validation loss: 2.3683773215099047

Epoch: 5| Step: 9
Training loss: 2.5177102088928223
Validation loss: 2.3811526554887013

Epoch: 5| Step: 10
Training loss: 2.5646722316741943
Validation loss: 2.3935265361621814

Epoch: 192| Step: 0
Training loss: 2.7765650749206543
Validation loss: 2.393047219963484

Epoch: 5| Step: 1
Training loss: 3.1515860557556152
Validation loss: 2.3962294670843307

Epoch: 5| Step: 2
Training loss: 2.564181089401245
Validation loss: 2.4107179000813472

Epoch: 5| Step: 3
Training loss: 2.6044228076934814
Validation loss: 2.4044818262900076

Epoch: 5| Step: 4
Training loss: 2.584294080734253
Validation loss: 2.394558216935845

Epoch: 5| Step: 5
Training loss: 2.216425657272339
Validation loss: 2.3866013852498864

Epoch: 5| Step: 6
Training loss: 1.5504933595657349
Validation loss: 2.3865348190389652

Epoch: 5| Step: 7
Training loss: 2.8563218116760254
Validation loss: 2.3901515340292327

Epoch: 5| Step: 8
Training loss: 2.4358983039855957
Validation loss: 2.3862987590092484

Epoch: 5| Step: 9
Training loss: 2.874516248703003
Validation loss: 2.389475876285184

Epoch: 5| Step: 10
Training loss: 2.7596261501312256
Validation loss: 2.3772902463072088

Epoch: 193| Step: 0
Training loss: 2.857348918914795
Validation loss: 2.381430079860072

Epoch: 5| Step: 1
Training loss: 2.4233672618865967
Validation loss: 2.377359692768384

Epoch: 5| Step: 2
Training loss: 2.7421765327453613
Validation loss: 2.3776905869924896

Epoch: 5| Step: 3
Training loss: 2.6739516258239746
Validation loss: 2.3770920666315223

Epoch: 5| Step: 4
Training loss: 2.8063340187072754
Validation loss: 2.370454006297614

Epoch: 5| Step: 5
Training loss: 2.40317964553833
Validation loss: 2.360634814026535

Epoch: 5| Step: 6
Training loss: 2.83994722366333
Validation loss: 2.366011345258323

Epoch: 5| Step: 7
Training loss: 2.545621156692505
Validation loss: 2.369043227164976

Epoch: 5| Step: 8
Training loss: 2.075671911239624
Validation loss: 2.3682015634352163

Epoch: 5| Step: 9
Training loss: 2.59869122505188
Validation loss: 2.3707367502233034

Epoch: 5| Step: 10
Training loss: 2.3972277641296387
Validation loss: 2.3760362991722683

Epoch: 194| Step: 0
Training loss: 3.2578303813934326
Validation loss: 2.3643097364774315

Epoch: 5| Step: 1
Training loss: 1.4737374782562256
Validation loss: 2.3692857116781254

Epoch: 5| Step: 2
Training loss: 2.5484085083007812
Validation loss: 2.3745271800666727

Epoch: 5| Step: 3
Training loss: 2.8795928955078125
Validation loss: 2.3645845843899633

Epoch: 5| Step: 4
Training loss: 2.885263442993164
Validation loss: 2.365155191831691

Epoch: 5| Step: 5
Training loss: 2.248471975326538
Validation loss: 2.364154636218984

Epoch: 5| Step: 6
Training loss: 1.8910363912582397
Validation loss: 2.3670695417670795

Epoch: 5| Step: 7
Training loss: 2.9276833534240723
Validation loss: 2.372463241700203

Epoch: 5| Step: 8
Training loss: 2.9989895820617676
Validation loss: 2.3652732756830033

Epoch: 5| Step: 9
Training loss: 2.3898677825927734
Validation loss: 2.3670696750763924

Epoch: 5| Step: 10
Training loss: 2.6827025413513184
Validation loss: 2.365470927248719

Epoch: 195| Step: 0
Training loss: 2.1252756118774414
Validation loss: 2.3646701176961265

Epoch: 5| Step: 1
Training loss: 2.446598529815674
Validation loss: 2.3753296162492488

Epoch: 5| Step: 2
Training loss: 2.229172945022583
Validation loss: 2.3748744098089074

Epoch: 5| Step: 3
Training loss: 2.7879302501678467
Validation loss: 2.380232713555777

Epoch: 5| Step: 4
Training loss: 3.5340073108673096
Validation loss: 2.3841809764985116

Epoch: 5| Step: 5
Training loss: 2.9666292667388916
Validation loss: 2.3773918908129454

Epoch: 5| Step: 6
Training loss: 2.391550302505493
Validation loss: 2.369410930141326

Epoch: 5| Step: 7
Training loss: 2.540153980255127
Validation loss: 2.365319762178647

Epoch: 5| Step: 8
Training loss: 2.6879611015319824
Validation loss: 2.3653409045229674

Epoch: 5| Step: 9
Training loss: 2.2360427379608154
Validation loss: 2.3541921569455053

Epoch: 5| Step: 10
Training loss: 2.089066743850708
Validation loss: 2.356179221983879

Epoch: 196| Step: 0
Training loss: 2.5435192584991455
Validation loss: 2.3560272698761313

Epoch: 5| Step: 1
Training loss: 2.2499587535858154
Validation loss: 2.3517575443431897

Epoch: 5| Step: 2
Training loss: 2.8960940837860107
Validation loss: 2.344304618015084

Epoch: 5| Step: 3
Training loss: 1.9961645603179932
Validation loss: 2.3447507889040056

Epoch: 5| Step: 4
Training loss: 2.3355369567871094
Validation loss: 2.3527575974823325

Epoch: 5| Step: 5
Training loss: 2.9841842651367188
Validation loss: 2.3445727440618698

Epoch: 5| Step: 6
Training loss: 3.1048717498779297
Validation loss: 2.36046068386365

Epoch: 5| Step: 7
Training loss: 2.2794525623321533
Validation loss: 2.3637606584897606

Epoch: 5| Step: 8
Training loss: 2.5529732704162598
Validation loss: 2.377329372590588

Epoch: 5| Step: 9
Training loss: 2.8440637588500977
Validation loss: 2.386715242939611

Epoch: 5| Step: 10
Training loss: 2.284911632537842
Validation loss: 2.385107640297182

Epoch: 197| Step: 0
Training loss: 3.1546497344970703
Validation loss: 2.373298063073107

Epoch: 5| Step: 1
Training loss: 2.937243700027466
Validation loss: 2.367936957267023

Epoch: 5| Step: 2
Training loss: 2.278271436691284
Validation loss: 2.364207452343356

Epoch: 5| Step: 3
Training loss: 2.1751761436462402
Validation loss: 2.3673017204448743

Epoch: 5| Step: 4
Training loss: 2.183077573776245
Validation loss: 2.369561154355285

Epoch: 5| Step: 5
Training loss: 2.777705669403076
Validation loss: 2.354105821219824

Epoch: 5| Step: 6
Training loss: 2.409228563308716
Validation loss: 2.355386087971349

Epoch: 5| Step: 7
Training loss: 1.7661930322647095
Validation loss: 2.368995133266654

Epoch: 5| Step: 8
Training loss: 2.801149845123291
Validation loss: 2.3635302743604107

Epoch: 5| Step: 9
Training loss: 2.8172214031219482
Validation loss: 2.3654381485395533

Epoch: 5| Step: 10
Training loss: 2.869760513305664
Validation loss: 2.358265156387001

Epoch: 198| Step: 0
Training loss: 2.4310030937194824
Validation loss: 2.3609419843201995

Epoch: 5| Step: 1
Training loss: 2.5970680713653564
Validation loss: 2.3683302312768917

Epoch: 5| Step: 2
Training loss: 2.0833206176757812
Validation loss: 2.3740258345039944

Epoch: 5| Step: 3
Training loss: 1.9721065759658813
Validation loss: 2.375147032481368

Epoch: 5| Step: 4
Training loss: 3.208289623260498
Validation loss: 2.3787869612375894

Epoch: 5| Step: 5
Training loss: 2.394369125366211
Validation loss: 2.3847620128303446

Epoch: 5| Step: 6
Training loss: 2.982414722442627
Validation loss: 2.382092939910068

Epoch: 5| Step: 7
Training loss: 2.475844144821167
Validation loss: 2.3780341738013813

Epoch: 5| Step: 8
Training loss: 2.467581033706665
Validation loss: 2.3633237256798694

Epoch: 5| Step: 9
Training loss: 2.862781047821045
Validation loss: 2.358240201909055

Epoch: 5| Step: 10
Training loss: 2.6478216648101807
Validation loss: 2.355176415494693

Epoch: 199| Step: 0
Training loss: 1.5358843803405762
Validation loss: 2.344778609532182

Epoch: 5| Step: 1
Training loss: 2.9789814949035645
Validation loss: 2.3593085991439

Epoch: 5| Step: 2
Training loss: 2.7566370964050293
Validation loss: 2.380773990384994

Epoch: 5| Step: 3
Training loss: 3.0488975048065186
Validation loss: 2.376873808522378

Epoch: 5| Step: 4
Training loss: 2.6500191688537598
Validation loss: 2.3735946429673063

Epoch: 5| Step: 5
Training loss: 2.675351619720459
Validation loss: 2.3584550170488257

Epoch: 5| Step: 6
Training loss: 2.352121591567993
Validation loss: 2.3649643185318157

Epoch: 5| Step: 7
Training loss: 2.954893112182617
Validation loss: 2.361977702827864

Epoch: 5| Step: 8
Training loss: 2.4154083728790283
Validation loss: 2.3525383010987313

Epoch: 5| Step: 9
Training loss: 2.1473991870880127
Validation loss: 2.3599917350276822

Epoch: 5| Step: 10
Training loss: 2.7388343811035156
Validation loss: 2.3600102598949144

Epoch: 200| Step: 0
Training loss: 2.91737961769104
Validation loss: 2.371161171185073

Epoch: 5| Step: 1
Training loss: 2.2406105995178223
Validation loss: 2.358173601088985

Epoch: 5| Step: 2
Training loss: 2.194352149963379
Validation loss: 2.3665353944224696

Epoch: 5| Step: 3
Training loss: 2.2460455894470215
Validation loss: 2.373441409039241

Epoch: 5| Step: 4
Training loss: 2.4481148719787598
Validation loss: 2.361906529754721

Epoch: 5| Step: 5
Training loss: 2.8428726196289062
Validation loss: 2.3713965018590293

Epoch: 5| Step: 6
Training loss: 3.116142988204956
Validation loss: 2.3618134272995817

Epoch: 5| Step: 7
Training loss: 1.97014582157135
Validation loss: 2.3613779519193914

Epoch: 5| Step: 8
Training loss: 2.9816811084747314
Validation loss: 2.361371119817098

Epoch: 5| Step: 9
Training loss: 3.109004020690918
Validation loss: 2.3610483138791976

Epoch: 5| Step: 10
Training loss: 2.048720359802246
Validation loss: 2.366199008880123

Epoch: 201| Step: 0
Training loss: 3.039860486984253
Validation loss: 2.359414836411835

Epoch: 5| Step: 1
Training loss: 2.8576438426971436
Validation loss: 2.354711935084353

Epoch: 5| Step: 2
Training loss: 2.008545398712158
Validation loss: 2.3580285374836256

Epoch: 5| Step: 3
Training loss: 2.3566412925720215
Validation loss: 2.3595271623262795

Epoch: 5| Step: 4
Training loss: 2.5706520080566406
Validation loss: 2.3578625520070395

Epoch: 5| Step: 5
Training loss: 2.9832775592803955
Validation loss: 2.3562348914402786

Epoch: 5| Step: 6
Training loss: 2.7268407344818115
Validation loss: 2.3585619605997556

Epoch: 5| Step: 7
Training loss: 2.7819526195526123
Validation loss: 2.359381362956057

Epoch: 5| Step: 8
Training loss: 2.196807861328125
Validation loss: 2.3663012955778386

Epoch: 5| Step: 9
Training loss: 1.9682714939117432
Validation loss: 2.3858051530776487

Epoch: 5| Step: 10
Training loss: 2.737452745437622
Validation loss: 2.392192079174903

Epoch: 202| Step: 0
Training loss: 2.818845748901367
Validation loss: 2.394235203343053

Epoch: 5| Step: 1
Training loss: 2.4675817489624023
Validation loss: 2.3813558650273148

Epoch: 5| Step: 2
Training loss: 2.4336628913879395
Validation loss: 2.3573638111032467

Epoch: 5| Step: 3
Training loss: 2.2225449085235596
Validation loss: 2.3554333538137455

Epoch: 5| Step: 4
Training loss: 2.7776598930358887
Validation loss: 2.3619770619177047

Epoch: 5| Step: 5
Training loss: 2.120307445526123
Validation loss: 2.3568564153486684

Epoch: 5| Step: 6
Training loss: 2.6571881771087646
Validation loss: 2.359248458698232

Epoch: 5| Step: 7
Training loss: 2.9156832695007324
Validation loss: 2.356787491870183

Epoch: 5| Step: 8
Training loss: 3.117676019668579
Validation loss: 2.3482392167532318

Epoch: 5| Step: 9
Training loss: 1.958513855934143
Validation loss: 2.3464771316897486

Epoch: 5| Step: 10
Training loss: 2.618009090423584
Validation loss: 2.3342588973301712

Epoch: 203| Step: 0
Training loss: 2.446399450302124
Validation loss: 2.3532620501774613

Epoch: 5| Step: 1
Training loss: 2.9958443641662598
Validation loss: 2.3508556350584953

Epoch: 5| Step: 2
Training loss: 2.943394422531128
Validation loss: 2.337506717251193

Epoch: 5| Step: 3
Training loss: 2.225156545639038
Validation loss: 2.340417661974507

Epoch: 5| Step: 4
Training loss: 1.9449313879013062
Validation loss: 2.3442976269670712

Epoch: 5| Step: 5
Training loss: 2.8148257732391357
Validation loss: 2.353811835729948

Epoch: 5| Step: 6
Training loss: 2.186444044113159
Validation loss: 2.3501351059124036

Epoch: 5| Step: 7
Training loss: 2.6233654022216797
Validation loss: 2.351512139843356

Epoch: 5| Step: 8
Training loss: 2.69681715965271
Validation loss: 2.3494898144916823

Epoch: 5| Step: 9
Training loss: 2.6182098388671875
Validation loss: 2.3646361597122683

Epoch: 5| Step: 10
Training loss: 2.533642292022705
Validation loss: 2.3600828647613525

Epoch: 204| Step: 0
Training loss: 3.34240460395813
Validation loss: 2.3678231226500643

Epoch: 5| Step: 1
Training loss: 1.5765451192855835
Validation loss: 2.369525496677686

Epoch: 5| Step: 2
Training loss: 2.5696933269500732
Validation loss: 2.373513706268803

Epoch: 5| Step: 3
Training loss: 2.6714835166931152
Validation loss: 2.365526081413351

Epoch: 5| Step: 4
Training loss: 2.029223680496216
Validation loss: 2.359784354445755

Epoch: 5| Step: 5
Training loss: 2.8894762992858887
Validation loss: 2.355101987879763

Epoch: 5| Step: 6
Training loss: 2.0166616439819336
Validation loss: 2.3583835171115015

Epoch: 5| Step: 7
Training loss: 2.7612433433532715
Validation loss: 2.354766091992778

Epoch: 5| Step: 8
Training loss: 2.6572184562683105
Validation loss: 2.3442198666193153

Epoch: 5| Step: 9
Training loss: 2.931255578994751
Validation loss: 2.3453393443938224

Epoch: 5| Step: 10
Training loss: 2.5115318298339844
Validation loss: 2.3457686067909322

Epoch: 205| Step: 0
Training loss: 3.220717668533325
Validation loss: 2.344486141717562

Epoch: 5| Step: 1
Training loss: 2.7487196922302246
Validation loss: 2.3478406065253803

Epoch: 5| Step: 2
Training loss: 2.059699296951294
Validation loss: 2.3391525489027782

Epoch: 5| Step: 3
Training loss: 2.10087513923645
Validation loss: 2.345742082083097

Epoch: 5| Step: 4
Training loss: 2.693087100982666
Validation loss: 2.342586548097672

Epoch: 5| Step: 5
Training loss: 2.3933327198028564
Validation loss: 2.3482531232218586

Epoch: 5| Step: 6
Training loss: 2.7530221939086914
Validation loss: 2.3623028262968986

Epoch: 5| Step: 7
Training loss: 2.0558998584747314
Validation loss: 2.3702629304701284

Epoch: 5| Step: 8
Training loss: 2.5661559104919434
Validation loss: 2.3711853129889375

Epoch: 5| Step: 9
Training loss: 2.5081472396850586
Validation loss: 2.3659685939870854

Epoch: 5| Step: 10
Training loss: 3.0354843139648438
Validation loss: 2.358557152491744

Epoch: 206| Step: 0
Training loss: 2.510706901550293
Validation loss: 2.3517373979732556

Epoch: 5| Step: 1
Training loss: 2.574965715408325
Validation loss: 2.3572408076255553

Epoch: 5| Step: 2
Training loss: 2.385969638824463
Validation loss: 2.3506303371921664

Epoch: 5| Step: 3
Training loss: 3.1443042755126953
Validation loss: 2.340657244446457

Epoch: 5| Step: 4
Training loss: 2.3022701740264893
Validation loss: 2.3497513930002847

Epoch: 5| Step: 5
Training loss: 2.617373466491699
Validation loss: 2.3426354623609975

Epoch: 5| Step: 6
Training loss: 2.4391772747039795
Validation loss: 2.3343536828153875

Epoch: 5| Step: 7
Training loss: 2.774014949798584
Validation loss: 2.331758511963711

Epoch: 5| Step: 8
Training loss: 2.4685988426208496
Validation loss: 2.337348994388375

Epoch: 5| Step: 9
Training loss: 2.567802906036377
Validation loss: 2.335316228610213

Epoch: 5| Step: 10
Training loss: 2.3059701919555664
Validation loss: 2.3518468000555552

Epoch: 207| Step: 0
Training loss: 2.9956679344177246
Validation loss: 2.3629175052847913

Epoch: 5| Step: 1
Training loss: 2.8508822917938232
Validation loss: 2.3731075448374592

Epoch: 5| Step: 2
Training loss: 2.8355820178985596
Validation loss: 2.3830120230233796

Epoch: 5| Step: 3
Training loss: 2.360236644744873
Validation loss: 2.3888341431976645

Epoch: 5| Step: 4
Training loss: 2.8231396675109863
Validation loss: 2.387202396187731

Epoch: 5| Step: 5
Training loss: 2.258755922317505
Validation loss: 2.3873150861391457

Epoch: 5| Step: 6
Training loss: 2.632388114929199
Validation loss: 2.39087321424997

Epoch: 5| Step: 7
Training loss: 2.6850290298461914
Validation loss: 2.390020844756916

Epoch: 5| Step: 8
Training loss: 2.113847017288208
Validation loss: 2.397593190593104

Epoch: 5| Step: 9
Training loss: 2.082958221435547
Validation loss: 2.3860714486850205

Epoch: 5| Step: 10
Training loss: 2.6074061393737793
Validation loss: 2.3725302245027278

Epoch: 208| Step: 0
Training loss: 2.41986346244812
Validation loss: 2.3562529510067356

Epoch: 5| Step: 1
Training loss: 2.4352307319641113
Validation loss: 2.344438078582928

Epoch: 5| Step: 2
Training loss: 2.975656509399414
Validation loss: 2.3442267705035467

Epoch: 5| Step: 3
Training loss: 2.6957015991210938
Validation loss: 2.3364344361007854

Epoch: 5| Step: 4
Training loss: 2.0299925804138184
Validation loss: 2.3399264940651516

Epoch: 5| Step: 5
Training loss: 2.955169200897217
Validation loss: 2.341117489722467

Epoch: 5| Step: 6
Training loss: 1.9871025085449219
Validation loss: 2.3442198486738306

Epoch: 5| Step: 7
Training loss: 2.6305770874023438
Validation loss: 2.343720587350989

Epoch: 5| Step: 8
Training loss: 2.6856606006622314
Validation loss: 2.3432608624940277

Epoch: 5| Step: 9
Training loss: 2.776155948638916
Validation loss: 2.346212466557821

Epoch: 5| Step: 10
Training loss: 2.2842977046966553
Validation loss: 2.349041123544016

Epoch: 209| Step: 0
Training loss: 2.687113046646118
Validation loss: 2.356987186657485

Epoch: 5| Step: 1
Training loss: 2.5817878246307373
Validation loss: 2.3623454801497923

Epoch: 5| Step: 2
Training loss: 2.1041197776794434
Validation loss: 2.3752881608983523

Epoch: 5| Step: 3
Training loss: 2.8400869369506836
Validation loss: 2.3583201464786323

Epoch: 5| Step: 4
Training loss: 2.626746654510498
Validation loss: 2.360236826763358

Epoch: 5| Step: 5
Training loss: 2.7167320251464844
Validation loss: 2.352583603192401

Epoch: 5| Step: 6
Training loss: 2.265336513519287
Validation loss: 2.359339473068073

Epoch: 5| Step: 7
Training loss: 2.4557292461395264
Validation loss: 2.347143917955378

Epoch: 5| Step: 8
Training loss: 2.7134432792663574
Validation loss: 2.344066583982078

Epoch: 5| Step: 9
Training loss: 2.834880828857422
Validation loss: 2.3476842116284113

Epoch: 5| Step: 10
Training loss: 2.170207977294922
Validation loss: 2.3392278122645553

Epoch: 210| Step: 0
Training loss: 2.9347636699676514
Validation loss: 2.3467611087265836

Epoch: 5| Step: 1
Training loss: 2.127924919128418
Validation loss: 2.348723119305026

Epoch: 5| Step: 2
Training loss: 2.4972987174987793
Validation loss: 2.345055892903318

Epoch: 5| Step: 3
Training loss: 1.6889060735702515
Validation loss: 2.3677176724198046

Epoch: 5| Step: 4
Training loss: 2.4731574058532715
Validation loss: 2.374759781745172

Epoch: 5| Step: 5
Training loss: 2.8231728076934814
Validation loss: 2.3718591877209243

Epoch: 5| Step: 6
Training loss: 2.7388668060302734
Validation loss: 2.3707565376835484

Epoch: 5| Step: 7
Training loss: 2.083040237426758
Validation loss: 2.3674282335465953

Epoch: 5| Step: 8
Training loss: 2.6019160747528076
Validation loss: 2.3576371464678036

Epoch: 5| Step: 9
Training loss: 3.2811570167541504
Validation loss: 2.3503872168961393

Epoch: 5| Step: 10
Training loss: 2.7998645305633545
Validation loss: 2.350891431172689

Epoch: 211| Step: 0
Training loss: 2.7549538612365723
Validation loss: 2.345386969145908

Epoch: 5| Step: 1
Training loss: 2.4533028602600098
Validation loss: 2.3403496460248063

Epoch: 5| Step: 2
Training loss: 2.6974892616271973
Validation loss: 2.3439463569271948

Epoch: 5| Step: 3
Training loss: 2.3613169193267822
Validation loss: 2.339327748103808

Epoch: 5| Step: 4
Training loss: 2.6953225135803223
Validation loss: 2.339781512496292

Epoch: 5| Step: 5
Training loss: 2.9132626056671143
Validation loss: 2.3390971460650043

Epoch: 5| Step: 6
Training loss: 2.7533299922943115
Validation loss: 2.3402735264070573

Epoch: 5| Step: 7
Training loss: 2.031071901321411
Validation loss: 2.3479737363835818

Epoch: 5| Step: 8
Training loss: 2.742427110671997
Validation loss: 2.339171560861731

Epoch: 5| Step: 9
Training loss: 2.3432226181030273
Validation loss: 2.33779973881219

Epoch: 5| Step: 10
Training loss: 2.1717214584350586
Validation loss: 2.3444736490967455

Epoch: 212| Step: 0
Training loss: 2.7950406074523926
Validation loss: 2.3601539160615657

Epoch: 5| Step: 1
Training loss: 2.415652275085449
Validation loss: 2.3580517461222987

Epoch: 5| Step: 2
Training loss: 2.256066083908081
Validation loss: 2.358594520117647

Epoch: 5| Step: 3
Training loss: 2.439614772796631
Validation loss: 2.3653270967545046

Epoch: 5| Step: 4
Training loss: 2.41633677482605
Validation loss: 2.3749818237878944

Epoch: 5| Step: 5
Training loss: 2.1655547618865967
Validation loss: 2.365350748903008

Epoch: 5| Step: 6
Training loss: 2.626906394958496
Validation loss: 2.365889803055794

Epoch: 5| Step: 7
Training loss: 2.764392852783203
Validation loss: 2.349574092895754

Epoch: 5| Step: 8
Training loss: 3.0718376636505127
Validation loss: 2.3289628695416194

Epoch: 5| Step: 9
Training loss: 2.5048794746398926
Validation loss: 2.3220557999867264

Epoch: 5| Step: 10
Training loss: 2.4464528560638428
Validation loss: 2.325822227744646

Epoch: 213| Step: 0
Training loss: 1.8795394897460938
Validation loss: 2.321585642394199

Epoch: 5| Step: 1
Training loss: 3.245126247406006
Validation loss: 2.3338982315473658

Epoch: 5| Step: 2
Training loss: 1.8940349817276
Validation loss: 2.331261952718099

Epoch: 5| Step: 3
Training loss: 2.3513081073760986
Validation loss: 2.327762493523218

Epoch: 5| Step: 4
Training loss: 2.7844650745391846
Validation loss: 2.3373645659415954

Epoch: 5| Step: 5
Training loss: 3.275286912918091
Validation loss: 2.3428766906902356

Epoch: 5| Step: 6
Training loss: 2.728476047515869
Validation loss: 2.3352238439744517

Epoch: 5| Step: 7
Training loss: 1.9616302251815796
Validation loss: 2.3457656624496623

Epoch: 5| Step: 8
Training loss: 2.7808632850646973
Validation loss: 2.350049549533475

Epoch: 5| Step: 9
Training loss: 2.1339762210845947
Validation loss: 2.3485287799630115

Epoch: 5| Step: 10
Training loss: 2.904818534851074
Validation loss: 2.3468729296038227

Epoch: 214| Step: 0
Training loss: 3.6055901050567627
Validation loss: 2.354936692022508

Epoch: 5| Step: 1
Training loss: 2.773594379425049
Validation loss: 2.3572937083500687

Epoch: 5| Step: 2
Training loss: 1.903158187866211
Validation loss: 2.3485614817629576

Epoch: 5| Step: 3
Training loss: 2.7693979740142822
Validation loss: 2.3573269613327517

Epoch: 5| Step: 4
Training loss: 2.454178810119629
Validation loss: 2.3476050592237905

Epoch: 5| Step: 5
Training loss: 2.390965700149536
Validation loss: 2.34721367589889

Epoch: 5| Step: 6
Training loss: 2.4669995307922363
Validation loss: 2.3458351012199157

Epoch: 5| Step: 7
Training loss: 2.4272260665893555
Validation loss: 2.3439634230829056

Epoch: 5| Step: 8
Training loss: 2.108243703842163
Validation loss: 2.344659005441973

Epoch: 5| Step: 9
Training loss: 2.2528491020202637
Validation loss: 2.349203537869197

Epoch: 5| Step: 10
Training loss: 2.777413845062256
Validation loss: 2.3615021115990094

Epoch: 215| Step: 0
Training loss: 2.3752758502960205
Validation loss: 2.3533491934499433

Epoch: 5| Step: 1
Training loss: 2.4361181259155273
Validation loss: 2.369414732020388

Epoch: 5| Step: 2
Training loss: 2.647437572479248
Validation loss: 2.3690395393679218

Epoch: 5| Step: 3
Training loss: 2.9401378631591797
Validation loss: 2.386231591624598

Epoch: 5| Step: 4
Training loss: 2.6380538940429688
Validation loss: 2.378969236086774

Epoch: 5| Step: 5
Training loss: 2.298186779022217
Validation loss: 2.3674899685767388

Epoch: 5| Step: 6
Training loss: 3.0830881595611572
Validation loss: 2.3614749857174453

Epoch: 5| Step: 7
Training loss: 2.291217803955078
Validation loss: 2.346378554580032

Epoch: 5| Step: 8
Training loss: 2.150601625442505
Validation loss: 2.3461495958348757

Epoch: 5| Step: 9
Training loss: 2.844975709915161
Validation loss: 2.343572860123009

Epoch: 5| Step: 10
Training loss: 2.2741897106170654
Validation loss: 2.338847424394341

Epoch: 216| Step: 0
Training loss: 2.6127090454101562
Validation loss: 2.3397418042664886

Epoch: 5| Step: 1
Training loss: 2.739238739013672
Validation loss: 2.3417135694975495

Epoch: 5| Step: 2
Training loss: 2.13202166557312
Validation loss: 2.3417964571265766

Epoch: 5| Step: 3
Training loss: 2.607125759124756
Validation loss: 2.334102940815751

Epoch: 5| Step: 4
Training loss: 2.338959217071533
Validation loss: 2.336446806948672

Epoch: 5| Step: 5
Training loss: 2.872377872467041
Validation loss: 2.3385152662954023

Epoch: 5| Step: 6
Training loss: 2.688056707382202
Validation loss: 2.3424461810819563

Epoch: 5| Step: 7
Training loss: 2.6335952281951904
Validation loss: 2.3375853056548745

Epoch: 5| Step: 8
Training loss: 1.9603917598724365
Validation loss: 2.3401018419573383

Epoch: 5| Step: 9
Training loss: 2.883862018585205
Validation loss: 2.351798308792935

Epoch: 5| Step: 10
Training loss: 2.514115810394287
Validation loss: 2.341368813668528

Epoch: 217| Step: 0
Training loss: 2.2137725353240967
Validation loss: 2.356636962582988

Epoch: 5| Step: 1
Training loss: 2.2633163928985596
Validation loss: 2.3466914981924076

Epoch: 5| Step: 2
Training loss: 2.660705089569092
Validation loss: 2.3540532486413115

Epoch: 5| Step: 3
Training loss: 3.2475154399871826
Validation loss: 2.3390003993947017

Epoch: 5| Step: 4
Training loss: 2.664768695831299
Validation loss: 2.344409009461762

Epoch: 5| Step: 5
Training loss: 2.332365036010742
Validation loss: 2.3523202121898694

Epoch: 5| Step: 6
Training loss: 2.158808946609497
Validation loss: 2.340606692016766

Epoch: 5| Step: 7
Training loss: 2.890089511871338
Validation loss: 2.3422022993846605

Epoch: 5| Step: 8
Training loss: 2.152564764022827
Validation loss: 2.3470789155652447

Epoch: 5| Step: 9
Training loss: 2.9700796604156494
Validation loss: 2.3468714324376916

Epoch: 5| Step: 10
Training loss: 2.154182195663452
Validation loss: 2.349852741405528

Epoch: 218| Step: 0
Training loss: 2.518796443939209
Validation loss: 2.35027140186679

Epoch: 5| Step: 1
Training loss: 2.2140636444091797
Validation loss: 2.3401211333531204

Epoch: 5| Step: 2
Training loss: 1.974897027015686
Validation loss: 2.3441339718398226

Epoch: 5| Step: 3
Training loss: 2.6257994174957275
Validation loss: 2.3450562313038814

Epoch: 5| Step: 4
Training loss: 2.6022090911865234
Validation loss: 2.344876489331645

Epoch: 5| Step: 5
Training loss: 2.7336459159851074
Validation loss: 2.3410855852147585

Epoch: 5| Step: 6
Training loss: 2.3650166988372803
Validation loss: 2.3558019566279587

Epoch: 5| Step: 7
Training loss: 2.263061285018921
Validation loss: 2.341199880005211

Epoch: 5| Step: 8
Training loss: 3.21476411819458
Validation loss: 2.339286824708344

Epoch: 5| Step: 9
Training loss: 2.9009175300598145
Validation loss: 2.3475224100133425

Epoch: 5| Step: 10
Training loss: 2.315061092376709
Validation loss: 2.3473273759247153

Epoch: 219| Step: 0
Training loss: 2.830219268798828
Validation loss: 2.3465501954478603

Epoch: 5| Step: 1
Training loss: 2.126739025115967
Validation loss: 2.3467452064637215

Epoch: 5| Step: 2
Training loss: 2.679377317428589
Validation loss: 2.34270336551051

Epoch: 5| Step: 3
Training loss: 2.4254658222198486
Validation loss: 2.3511962224078435

Epoch: 5| Step: 4
Training loss: 2.548032283782959
Validation loss: 2.3610810823338007

Epoch: 5| Step: 5
Training loss: 2.5090982913970947
Validation loss: 2.3593089093444166

Epoch: 5| Step: 6
Training loss: 2.6657519340515137
Validation loss: 2.356031871611072

Epoch: 5| Step: 7
Training loss: 2.4946305751800537
Validation loss: 2.355984445541136

Epoch: 5| Step: 8
Training loss: 2.787872314453125
Validation loss: 2.3591445030704623

Epoch: 5| Step: 9
Training loss: 1.8217099905014038
Validation loss: 2.3576809180680143

Epoch: 5| Step: 10
Training loss: 2.97951602935791
Validation loss: 2.3542398073339976

Epoch: 220| Step: 0
Training loss: 2.411360502243042
Validation loss: 2.3498506135838007

Epoch: 5| Step: 1
Training loss: 2.5615084171295166
Validation loss: 2.34698663732057

Epoch: 5| Step: 2
Training loss: 2.1148226261138916
Validation loss: 2.3434470648406656

Epoch: 5| Step: 3
Training loss: 2.1650471687316895
Validation loss: 2.3389333935194117

Epoch: 5| Step: 4
Training loss: 2.6422810554504395
Validation loss: 2.341287714178844

Epoch: 5| Step: 5
Training loss: 2.4104068279266357
Validation loss: 2.330629346191242

Epoch: 5| Step: 6
Training loss: 2.3546807765960693
Validation loss: 2.3184279857143277

Epoch: 5| Step: 7
Training loss: 2.973163604736328
Validation loss: 2.320970704478602

Epoch: 5| Step: 8
Training loss: 3.2001845836639404
Validation loss: 2.3192070094488

Epoch: 5| Step: 9
Training loss: 2.695538282394409
Validation loss: 2.3150054844476844

Epoch: 5| Step: 10
Training loss: 2.3301243782043457
Validation loss: 2.3138822688851306

Epoch: 221| Step: 0
Training loss: 2.1624715328216553
Validation loss: 2.3134274662181897

Epoch: 5| Step: 1
Training loss: 2.533184766769409
Validation loss: 2.310498740083428

Epoch: 5| Step: 2
Training loss: 2.967676877975464
Validation loss: 2.3136730988820395

Epoch: 5| Step: 3
Training loss: 2.616157054901123
Validation loss: 2.3168316784725396

Epoch: 5| Step: 4
Training loss: 2.6652305126190186
Validation loss: 2.3135233386870353

Epoch: 5| Step: 5
Training loss: 2.7377493381500244
Validation loss: 2.3152381809808875

Epoch: 5| Step: 6
Training loss: 2.2846872806549072
Validation loss: 2.326582642011745

Epoch: 5| Step: 7
Training loss: 2.743290662765503
Validation loss: 2.3253825992666264

Epoch: 5| Step: 8
Training loss: 2.1727395057678223
Validation loss: 2.3359725936766593

Epoch: 5| Step: 9
Training loss: 2.3958423137664795
Validation loss: 2.3396934181131344

Epoch: 5| Step: 10
Training loss: 2.568845510482788
Validation loss: 2.352091953318606

Epoch: 222| Step: 0
Training loss: 2.5391793251037598
Validation loss: 2.352007842832996

Epoch: 5| Step: 1
Training loss: 2.6766867637634277
Validation loss: 2.356982731050061

Epoch: 5| Step: 2
Training loss: 1.924795389175415
Validation loss: 2.3644488088546263

Epoch: 5| Step: 3
Training loss: 2.6832709312438965
Validation loss: 2.356380880519908

Epoch: 5| Step: 4
Training loss: 1.6247990131378174
Validation loss: 2.358088336965089

Epoch: 5| Step: 5
Training loss: 2.491673707962036
Validation loss: 2.350162567630891

Epoch: 5| Step: 6
Training loss: 2.5571818351745605
Validation loss: 2.3393654669484785

Epoch: 5| Step: 7
Training loss: 2.8794026374816895
Validation loss: 2.33949633823928

Epoch: 5| Step: 8
Training loss: 2.3869528770446777
Validation loss: 2.3276695243773924

Epoch: 5| Step: 9
Training loss: 3.285102128982544
Validation loss: 2.3343336479638213

Epoch: 5| Step: 10
Training loss: 2.6869797706604004
Validation loss: 2.3289764722188315

Epoch: 223| Step: 0
Training loss: 2.5951390266418457
Validation loss: 2.3370211534602667

Epoch: 5| Step: 1
Training loss: 2.709238052368164
Validation loss: 2.3183124937036985

Epoch: 5| Step: 2
Training loss: 2.7982780933380127
Validation loss: 2.32317413309569

Epoch: 5| Step: 3
Training loss: 2.8065192699432373
Validation loss: 2.314306292482602

Epoch: 5| Step: 4
Training loss: 2.3289666175842285
Validation loss: 2.30420187980898

Epoch: 5| Step: 5
Training loss: 2.4246411323547363
Validation loss: 2.3038994266140844

Epoch: 5| Step: 6
Training loss: 2.621760606765747
Validation loss: 2.313834872297061

Epoch: 5| Step: 7
Training loss: 2.3852994441986084
Validation loss: 2.3227561878901657

Epoch: 5| Step: 8
Training loss: 2.6279568672180176
Validation loss: 2.3177256891804356

Epoch: 5| Step: 9
Training loss: 2.7817304134368896
Validation loss: 2.326530674452423

Epoch: 5| Step: 10
Training loss: 1.5062787532806396
Validation loss: 2.32770368360704

Epoch: 224| Step: 0
Training loss: 2.462038278579712
Validation loss: 2.3402285037502164

Epoch: 5| Step: 1
Training loss: 2.4042410850524902
Validation loss: 2.3323511769694667

Epoch: 5| Step: 2
Training loss: 2.387216091156006
Validation loss: 2.3392709288545834

Epoch: 5| Step: 3
Training loss: 2.4382731914520264
Validation loss: 2.341337206543133

Epoch: 5| Step: 4
Training loss: 2.1830124855041504
Validation loss: 2.3310826927103023

Epoch: 5| Step: 5
Training loss: 2.6932337284088135
Validation loss: 2.3292640127161497

Epoch: 5| Step: 6
Training loss: 2.3533010482788086
Validation loss: 2.332624614879649

Epoch: 5| Step: 7
Training loss: 2.5207436084747314
Validation loss: 2.3244101411552838

Epoch: 5| Step: 8
Training loss: 3.0342459678649902
Validation loss: 2.322123945400279

Epoch: 5| Step: 9
Training loss: 2.7562289237976074
Validation loss: 2.326688843388711

Epoch: 5| Step: 10
Training loss: 2.402909994125366
Validation loss: 2.3215697580768215

Epoch: 225| Step: 0
Training loss: 2.418205738067627
Validation loss: 2.322824396112914

Epoch: 5| Step: 1
Training loss: 2.6157608032226562
Validation loss: 2.317622620572326

Epoch: 5| Step: 2
Training loss: 2.1770191192626953
Validation loss: 2.3100501901359967

Epoch: 5| Step: 3
Training loss: 2.4733405113220215
Validation loss: 2.3131570559675976

Epoch: 5| Step: 4
Training loss: 2.8750269412994385
Validation loss: 2.318849322616413

Epoch: 5| Step: 5
Training loss: 2.7318954467773438
Validation loss: 2.3376210966417865

Epoch: 5| Step: 6
Training loss: 2.6463072299957275
Validation loss: 2.342252628777617

Epoch: 5| Step: 7
Training loss: 2.871741533279419
Validation loss: 2.3409065302982124

Epoch: 5| Step: 8
Training loss: 1.9073978662490845
Validation loss: 2.340784949641074

Epoch: 5| Step: 9
Training loss: 2.8016932010650635
Validation loss: 2.3408074173876035

Epoch: 5| Step: 10
Training loss: 1.9684748649597168
Validation loss: 2.3396711939124653

Epoch: 226| Step: 0
Training loss: 3.0127272605895996
Validation loss: 2.345812669364355

Epoch: 5| Step: 1
Training loss: 2.7036402225494385
Validation loss: 2.337952680485223

Epoch: 5| Step: 2
Training loss: 2.5148398876190186
Validation loss: 2.3435370973361436

Epoch: 5| Step: 3
Training loss: 2.6383814811706543
Validation loss: 2.3428136430760866

Epoch: 5| Step: 4
Training loss: 2.797398567199707
Validation loss: 2.352687576765655

Epoch: 5| Step: 5
Training loss: 2.803757429122925
Validation loss: 2.3521042408481723

Epoch: 5| Step: 6
Training loss: 2.073720932006836
Validation loss: 2.323892806165962

Epoch: 5| Step: 7
Training loss: 2.798464298248291
Validation loss: 2.32338721008711

Epoch: 5| Step: 8
Training loss: 2.2290425300598145
Validation loss: 2.314079620504892

Epoch: 5| Step: 9
Training loss: 1.8114721775054932
Validation loss: 2.314964819979924

Epoch: 5| Step: 10
Training loss: 2.241938829421997
Validation loss: 2.3094374133694555

Epoch: 227| Step: 0
Training loss: 3.0360500812530518
Validation loss: 2.3154763303777224

Epoch: 5| Step: 1
Training loss: 2.4264254570007324
Validation loss: 2.3151490406323503

Epoch: 5| Step: 2
Training loss: 2.4744999408721924
Validation loss: 2.3157947089082453

Epoch: 5| Step: 3
Training loss: 2.19514536857605
Validation loss: 2.3236253876839914

Epoch: 5| Step: 4
Training loss: 2.0490174293518066
Validation loss: 2.3050570462339666

Epoch: 5| Step: 5
Training loss: 2.9082143306732178
Validation loss: 2.302318137179139

Epoch: 5| Step: 6
Training loss: 3.0961666107177734
Validation loss: 2.2946858611158145

Epoch: 5| Step: 7
Training loss: 2.822817087173462
Validation loss: 2.305683564114314

Epoch: 5| Step: 8
Training loss: 2.141178846359253
Validation loss: 2.3025681049593034

Epoch: 5| Step: 9
Training loss: 2.573399305343628
Validation loss: 2.308426864685551

Epoch: 5| Step: 10
Training loss: 1.9007713794708252
Validation loss: 2.3132120793865574

Epoch: 228| Step: 0
Training loss: 2.5926430225372314
Validation loss: 2.3336478997302312

Epoch: 5| Step: 1
Training loss: 2.6704747676849365
Validation loss: 2.341627408099431

Epoch: 5| Step: 2
Training loss: 2.0270895957946777
Validation loss: 2.3592479357155423

Epoch: 5| Step: 3
Training loss: 1.98638117313385
Validation loss: 2.3801077694021244

Epoch: 5| Step: 4
Training loss: 2.0573813915252686
Validation loss: 2.400409649777156

Epoch: 5| Step: 5
Training loss: 2.976945400238037
Validation loss: 2.395787928694038

Epoch: 5| Step: 6
Training loss: 2.9367518424987793
Validation loss: 2.3658517278650755

Epoch: 5| Step: 7
Training loss: 2.468151569366455
Validation loss: 2.372883099381642

Epoch: 5| Step: 8
Training loss: 2.769205093383789
Validation loss: 2.3521956936005624

Epoch: 5| Step: 9
Training loss: 2.3800997734069824
Validation loss: 2.3420052477108535

Epoch: 5| Step: 10
Training loss: 2.9380550384521484
Validation loss: 2.3279718006810834

Epoch: 229| Step: 0
Training loss: 2.522892475128174
Validation loss: 2.331776370284378

Epoch: 5| Step: 1
Training loss: 2.7608485221862793
Validation loss: 2.3152453181564168

Epoch: 5| Step: 2
Training loss: 2.3781497478485107
Validation loss: 2.3145106633504233

Epoch: 5| Step: 3
Training loss: 2.0269477367401123
Validation loss: 2.3122533239344114

Epoch: 5| Step: 4
Training loss: 2.586942672729492
Validation loss: 2.30855893576017

Epoch: 5| Step: 5
Training loss: 2.7992210388183594
Validation loss: 2.314168781362554

Epoch: 5| Step: 6
Training loss: 2.478203296661377
Validation loss: 2.3343314586147184

Epoch: 5| Step: 7
Training loss: 1.7869186401367188
Validation loss: 2.347067356109619

Epoch: 5| Step: 8
Training loss: 3.1910924911499023
Validation loss: 2.349569482188071

Epoch: 5| Step: 9
Training loss: 2.6900856494903564
Validation loss: 2.3447282468118975

Epoch: 5| Step: 10
Training loss: 2.3454205989837646
Validation loss: 2.3581230076410438

Epoch: 230| Step: 0
Training loss: 2.2682273387908936
Validation loss: 2.3435181853591756

Epoch: 5| Step: 1
Training loss: 2.933687448501587
Validation loss: 2.344682498644757

Epoch: 5| Step: 2
Training loss: 2.2850680351257324
Validation loss: 2.322066776214107

Epoch: 5| Step: 3
Training loss: 2.73575758934021
Validation loss: 2.32780449621139

Epoch: 5| Step: 4
Training loss: 2.7926905155181885
Validation loss: 2.328783251905954

Epoch: 5| Step: 5
Training loss: 2.959179639816284
Validation loss: 2.32282994895853

Epoch: 5| Step: 6
Training loss: 2.045837879180908
Validation loss: 2.3235001102570565

Epoch: 5| Step: 7
Training loss: 2.560220241546631
Validation loss: 2.329656985498244

Epoch: 5| Step: 8
Training loss: 2.267331838607788
Validation loss: 2.3408239477424213

Epoch: 5| Step: 9
Training loss: 3.0116066932678223
Validation loss: 2.335926371236001

Epoch: 5| Step: 10
Training loss: 1.6510404348373413
Validation loss: 2.335613466078235

Epoch: 231| Step: 0
Training loss: 2.9757397174835205
Validation loss: 2.3348550540144726

Epoch: 5| Step: 1
Training loss: 2.1467080116271973
Validation loss: 2.324277936771352

Epoch: 5| Step: 2
Training loss: 2.566192150115967
Validation loss: 2.322861004901189

Epoch: 5| Step: 3
Training loss: 2.492704391479492
Validation loss: 2.3261033873404227

Epoch: 5| Step: 4
Training loss: 2.9445767402648926
Validation loss: 2.342257994477467

Epoch: 5| Step: 5
Training loss: 2.236199140548706
Validation loss: 2.3487096396825646

Epoch: 5| Step: 6
Training loss: 2.259796619415283
Validation loss: 2.340485821488083

Epoch: 5| Step: 7
Training loss: 2.29101300239563
Validation loss: 2.3403798816024617

Epoch: 5| Step: 8
Training loss: 2.259678602218628
Validation loss: 2.332313452997515

Epoch: 5| Step: 9
Training loss: 2.748222589492798
Validation loss: 2.324598494396415

Epoch: 5| Step: 10
Training loss: 2.7559163570404053
Validation loss: 2.3073036439957155

Epoch: 232| Step: 0
Training loss: 2.8602452278137207
Validation loss: 2.304495744807746

Epoch: 5| Step: 1
Training loss: 2.6840298175811768
Validation loss: 2.318215572705833

Epoch: 5| Step: 2
Training loss: 2.1533782482147217
Validation loss: 2.2991420402321765

Epoch: 5| Step: 3
Training loss: 2.4684667587280273
Validation loss: 2.299932354240007

Epoch: 5| Step: 4
Training loss: 2.896519184112549
Validation loss: 2.3118021667644544

Epoch: 5| Step: 5
Training loss: 2.2957701683044434
Validation loss: 2.3007036383434007

Epoch: 5| Step: 6
Training loss: 2.2199923992156982
Validation loss: 2.317034423992198

Epoch: 5| Step: 7
Training loss: 2.2753806114196777
Validation loss: 2.3189867593908824

Epoch: 5| Step: 8
Training loss: 1.9964977502822876
Validation loss: 2.305304633673801

Epoch: 5| Step: 9
Training loss: 3.3498122692108154
Validation loss: 2.314432877366261

Epoch: 5| Step: 10
Training loss: 2.308023452758789
Validation loss: 2.326077015169205

Epoch: 233| Step: 0
Training loss: 2.2616357803344727
Validation loss: 2.327894208251789

Epoch: 5| Step: 1
Training loss: 2.000175952911377
Validation loss: 2.3199771476048294

Epoch: 5| Step: 2
Training loss: 2.716050624847412
Validation loss: 2.323051832055533

Epoch: 5| Step: 3
Training loss: 2.2565619945526123
Validation loss: 2.3130760218507502

Epoch: 5| Step: 4
Training loss: 2.562675714492798
Validation loss: 2.3233198529930523

Epoch: 5| Step: 5
Training loss: 2.6324245929718018
Validation loss: 2.3154262804215953

Epoch: 5| Step: 6
Training loss: 3.0373587608337402
Validation loss: 2.327298087458457

Epoch: 5| Step: 7
Training loss: 2.8857955932617188
Validation loss: 2.3129644086284022

Epoch: 5| Step: 8
Training loss: 2.6015021800994873
Validation loss: 2.306631329239056

Epoch: 5| Step: 9
Training loss: 2.193295478820801
Validation loss: 2.294829001990698

Epoch: 5| Step: 10
Training loss: 2.335770606994629
Validation loss: 2.2883027163884972

Epoch: 234| Step: 0
Training loss: 2.302119731903076
Validation loss: 2.291358845208281

Epoch: 5| Step: 1
Training loss: 2.5847573280334473
Validation loss: 2.2946565817761164

Epoch: 5| Step: 2
Training loss: 2.6431660652160645
Validation loss: 2.2983377082373506

Epoch: 5| Step: 3
Training loss: 2.7578511238098145
Validation loss: 2.2993355130636566

Epoch: 5| Step: 4
Training loss: 2.446781873703003
Validation loss: 2.3157281721791914

Epoch: 5| Step: 5
Training loss: 1.7063995599746704
Validation loss: 2.330817184140605

Epoch: 5| Step: 6
Training loss: 2.6929543018341064
Validation loss: 2.326179168557608

Epoch: 5| Step: 7
Training loss: 2.5349135398864746
Validation loss: 2.334039572746523

Epoch: 5| Step: 8
Training loss: 3.243450164794922
Validation loss: 2.3314802928637435

Epoch: 5| Step: 9
Training loss: 2.2503581047058105
Validation loss: 2.319883192739179

Epoch: 5| Step: 10
Training loss: 2.439749240875244
Validation loss: 2.308904100489873

Epoch: 235| Step: 0
Training loss: 2.6656854152679443
Validation loss: 2.3110241146497827

Epoch: 5| Step: 1
Training loss: 2.6280417442321777
Validation loss: 2.317808223027055

Epoch: 5| Step: 2
Training loss: 2.688138246536255
Validation loss: 2.308892544879708

Epoch: 5| Step: 3
Training loss: 1.9012253284454346
Validation loss: 2.3165317632818736

Epoch: 5| Step: 4
Training loss: 2.3216636180877686
Validation loss: 2.3167573636577976

Epoch: 5| Step: 5
Training loss: 2.4318296909332275
Validation loss: 2.3168342241676907

Epoch: 5| Step: 6
Training loss: 2.4133412837982178
Validation loss: 2.3142871061960855

Epoch: 5| Step: 7
Training loss: 2.532710313796997
Validation loss: 2.3139390791616132

Epoch: 5| Step: 8
Training loss: 2.0237693786621094
Validation loss: 2.311059921018539

Epoch: 5| Step: 9
Training loss: 2.553595781326294
Validation loss: 2.3054169634337067

Epoch: 5| Step: 10
Training loss: 3.4671249389648438
Validation loss: 2.3161401517929567

Epoch: 236| Step: 0
Training loss: 1.6644465923309326
Validation loss: 2.3283155989903275

Epoch: 5| Step: 1
Training loss: 2.3013832569122314
Validation loss: 2.3269605098232145

Epoch: 5| Step: 2
Training loss: 2.405545711517334
Validation loss: 2.326718912329725

Epoch: 5| Step: 3
Training loss: 2.790231704711914
Validation loss: 2.33523242960694

Epoch: 5| Step: 4
Training loss: 2.6701648235321045
Validation loss: 2.3265448283123713

Epoch: 5| Step: 5
Training loss: 2.6745309829711914
Validation loss: 2.333232154128372

Epoch: 5| Step: 6
Training loss: 2.846956253051758
Validation loss: 2.331089517121674

Epoch: 5| Step: 7
Training loss: 2.495746374130249
Validation loss: 2.34138479796789

Epoch: 5| Step: 8
Training loss: 2.8475635051727295
Validation loss: 2.3442275344684558

Epoch: 5| Step: 9
Training loss: 2.4686787128448486
Validation loss: 2.336942534292898

Epoch: 5| Step: 10
Training loss: 2.330169439315796
Validation loss: 2.322425724357687

Epoch: 237| Step: 0
Training loss: 2.1702542304992676
Validation loss: 2.307494507041029

Epoch: 5| Step: 1
Training loss: 2.2917983531951904
Validation loss: 2.2945371379134474

Epoch: 5| Step: 2
Training loss: 2.9048824310302734
Validation loss: 2.293046356529318

Epoch: 5| Step: 3
Training loss: 2.9634084701538086
Validation loss: 2.290403965980776

Epoch: 5| Step: 4
Training loss: 2.6784188747406006
Validation loss: 2.2906619502652075

Epoch: 5| Step: 5
Training loss: 2.6436173915863037
Validation loss: 2.281170663013253

Epoch: 5| Step: 6
Training loss: 2.0956826210021973
Validation loss: 2.2781739029833066

Epoch: 5| Step: 7
Training loss: 2.7158617973327637
Validation loss: 2.275989504270656

Epoch: 5| Step: 8
Training loss: 2.7588768005371094
Validation loss: 2.2849373817443848

Epoch: 5| Step: 9
Training loss: 2.4255897998809814
Validation loss: 2.2856052588391047

Epoch: 5| Step: 10
Training loss: 1.7249211072921753
Validation loss: 2.2815049822612474

Epoch: 238| Step: 0
Training loss: 2.3862721920013428
Validation loss: 2.2827160332792547

Epoch: 5| Step: 1
Training loss: 1.8972456455230713
Validation loss: 2.2930167336617746

Epoch: 5| Step: 2
Training loss: 2.770434856414795
Validation loss: 2.3059117512036393

Epoch: 5| Step: 3
Training loss: 2.339399814605713
Validation loss: 2.3212996323903403

Epoch: 5| Step: 4
Training loss: 2.3777923583984375
Validation loss: 2.3169095080385924

Epoch: 5| Step: 5
Training loss: 2.6344218254089355
Validation loss: 2.3204112745100454

Epoch: 5| Step: 6
Training loss: 2.7545182704925537
Validation loss: 2.3247792874613116

Epoch: 5| Step: 7
Training loss: 2.8541369438171387
Validation loss: 2.3362005423474055

Epoch: 5| Step: 8
Training loss: 2.7452266216278076
Validation loss: 2.332769728476001

Epoch: 5| Step: 9
Training loss: 2.076026439666748
Validation loss: 2.318823496500651

Epoch: 5| Step: 10
Training loss: 2.637105703353882
Validation loss: 2.3061333779365785

Epoch: 239| Step: 0
Training loss: 2.4270224571228027
Validation loss: 2.309754233206472

Epoch: 5| Step: 1
Training loss: 2.323197841644287
Validation loss: 2.3017666442419893

Epoch: 5| Step: 2
Training loss: 2.8892924785614014
Validation loss: 2.2974313407815914

Epoch: 5| Step: 3
Training loss: 2.3626294136047363
Validation loss: 2.3046798885509534

Epoch: 5| Step: 4
Training loss: 2.0366108417510986
Validation loss: 2.2980620784144246

Epoch: 5| Step: 5
Training loss: 2.582746744155884
Validation loss: 2.305927130483812

Epoch: 5| Step: 6
Training loss: 3.471416473388672
Validation loss: 2.2972840288633942

Epoch: 5| Step: 7
Training loss: 2.6058077812194824
Validation loss: 2.302896045869397

Epoch: 5| Step: 8
Training loss: 2.381591320037842
Validation loss: 2.3177076437140025

Epoch: 5| Step: 9
Training loss: 2.215927839279175
Validation loss: 2.3304657346458844

Epoch: 5| Step: 10
Training loss: 2.180649995803833
Validation loss: 2.3162917373000935

Epoch: 240| Step: 0
Training loss: 3.2506237030029297
Validation loss: 2.31401490652433

Epoch: 5| Step: 1
Training loss: 2.164076328277588
Validation loss: 2.331035805004899

Epoch: 5| Step: 2
Training loss: 2.0795724391937256
Validation loss: 2.32866790217738

Epoch: 5| Step: 3
Training loss: 1.9704347848892212
Validation loss: 2.326524724242508

Epoch: 5| Step: 4
Training loss: 2.4198269844055176
Validation loss: 2.3317328806846374

Epoch: 5| Step: 5
Training loss: 2.7179367542266846
Validation loss: 2.338540877065351

Epoch: 5| Step: 6
Training loss: 2.775651454925537
Validation loss: 2.3311138358167423

Epoch: 5| Step: 7
Training loss: 2.59751558303833
Validation loss: 2.3301448796385076

Epoch: 5| Step: 8
Training loss: 2.5822176933288574
Validation loss: 2.3410905099684194

Epoch: 5| Step: 9
Training loss: 2.4384751319885254
Validation loss: 2.321156230024112

Epoch: 5| Step: 10
Training loss: 2.3138692378997803
Validation loss: 2.3115387244891097

Epoch: 241| Step: 0
Training loss: 3.1663641929626465
Validation loss: 2.3083309409438924

Epoch: 5| Step: 1
Training loss: 2.2018558979034424
Validation loss: 2.3098402536043556

Epoch: 5| Step: 2
Training loss: 2.2787299156188965
Validation loss: 2.3034363126242035

Epoch: 5| Step: 3
Training loss: 2.6637895107269287
Validation loss: 2.2946269794176986

Epoch: 5| Step: 4
Training loss: 2.5157084465026855
Validation loss: 2.2944159789751937

Epoch: 5| Step: 5
Training loss: 2.376328468322754
Validation loss: 2.2940679442497993

Epoch: 5| Step: 6
Training loss: 2.485703945159912
Validation loss: 2.300642959533199

Epoch: 5| Step: 7
Training loss: 2.1454482078552246
Validation loss: 2.3017169096136607

Epoch: 5| Step: 8
Training loss: 2.5822677612304688
Validation loss: 2.3104070412215365

Epoch: 5| Step: 9
Training loss: 2.8452816009521484
Validation loss: 2.3237449738287155

Epoch: 5| Step: 10
Training loss: 2.267631769180298
Validation loss: 2.3328929203812794

Epoch: 242| Step: 0
Training loss: 2.882502317428589
Validation loss: 2.327531563338413

Epoch: 5| Step: 1
Training loss: 2.435014247894287
Validation loss: 2.316062499118108

Epoch: 5| Step: 2
Training loss: 2.342521905899048
Validation loss: 2.310246657299739

Epoch: 5| Step: 3
Training loss: 2.383281707763672
Validation loss: 2.285981168029129

Epoch: 5| Step: 4
Training loss: 2.0673699378967285
Validation loss: 2.2868366638819375

Epoch: 5| Step: 5
Training loss: 2.5243446826934814
Validation loss: 2.2979258119419055

Epoch: 5| Step: 6
Training loss: 3.197746753692627
Validation loss: 2.2985504596464095

Epoch: 5| Step: 7
Training loss: 2.0983896255493164
Validation loss: 2.2854085199294554

Epoch: 5| Step: 8
Training loss: 2.6266398429870605
Validation loss: 2.285262753886561

Epoch: 5| Step: 9
Training loss: 2.565031051635742
Validation loss: 2.290885010073262

Epoch: 5| Step: 10
Training loss: 2.2966084480285645
Validation loss: 2.2899425337391515

Epoch: 243| Step: 0
Training loss: 2.803138494491577
Validation loss: 2.292223471467213

Epoch: 5| Step: 1
Training loss: 2.536975860595703
Validation loss: 2.301542671777869

Epoch: 5| Step: 2
Training loss: 2.4948887825012207
Validation loss: 2.3116669295936503

Epoch: 5| Step: 3
Training loss: 2.1170456409454346
Validation loss: 2.3088399876830397

Epoch: 5| Step: 4
Training loss: 2.085728406906128
Validation loss: 2.326477725018737

Epoch: 5| Step: 5
Training loss: 2.3281638622283936
Validation loss: 2.3186091992162887

Epoch: 5| Step: 6
Training loss: 3.0495057106018066
Validation loss: 2.319505432600616

Epoch: 5| Step: 7
Training loss: 2.1952545642852783
Validation loss: 2.3362733561505555

Epoch: 5| Step: 8
Training loss: 2.0978732109069824
Validation loss: 2.327730414687946

Epoch: 5| Step: 9
Training loss: 2.942406177520752
Validation loss: 2.308922298492924

Epoch: 5| Step: 10
Training loss: 2.85357928276062
Validation loss: 2.3267742767128894

Epoch: 244| Step: 0
Training loss: 1.9909160137176514
Validation loss: 2.3180872496738227

Epoch: 5| Step: 1
Training loss: 3.0126500129699707
Validation loss: 2.321002601295389

Epoch: 5| Step: 2
Training loss: 2.4250359535217285
Validation loss: 2.304718525178971

Epoch: 5| Step: 3
Training loss: 2.0265777111053467
Validation loss: 2.319283926358787

Epoch: 5| Step: 4
Training loss: 2.6676409244537354
Validation loss: 2.305292096189273

Epoch: 5| Step: 5
Training loss: 3.3947224617004395
Validation loss: 2.3012206195503153

Epoch: 5| Step: 6
Training loss: 2.2242789268493652
Validation loss: 2.299178202946981

Epoch: 5| Step: 7
Training loss: 2.40738844871521
Validation loss: 2.3016793676601943

Epoch: 5| Step: 8
Training loss: 2.5740275382995605
Validation loss: 2.2807625237331597

Epoch: 5| Step: 9
Training loss: 2.470820903778076
Validation loss: 2.291627243000974

Epoch: 5| Step: 10
Training loss: 2.0974416732788086
Validation loss: 2.2991130121292604

Epoch: 245| Step: 0
Training loss: 2.6923441886901855
Validation loss: 2.2875384028239916

Epoch: 5| Step: 1
Training loss: 2.442523956298828
Validation loss: 2.2901288873405865

Epoch: 5| Step: 2
Training loss: 2.832803726196289
Validation loss: 2.297337350024972

Epoch: 5| Step: 3
Training loss: 2.604147434234619
Validation loss: 2.3017587277197067

Epoch: 5| Step: 4
Training loss: 1.8514522314071655
Validation loss: 2.311567506482524

Epoch: 5| Step: 5
Training loss: 2.255375862121582
Validation loss: 2.303831861865136

Epoch: 5| Step: 6
Training loss: 2.800208568572998
Validation loss: 2.3112866045326315

Epoch: 5| Step: 7
Training loss: 1.6008062362670898
Validation loss: 2.3002300364996797

Epoch: 5| Step: 8
Training loss: 2.633265256881714
Validation loss: 2.303998839470648

Epoch: 5| Step: 9
Training loss: 2.8817596435546875
Validation loss: 2.3276318196327455

Epoch: 5| Step: 10
Training loss: 2.8878016471862793
Validation loss: 2.3160871562137397

Epoch: 246| Step: 0
Training loss: 2.385754108428955
Validation loss: 2.299175734161049

Epoch: 5| Step: 1
Training loss: 3.1725316047668457
Validation loss: 2.2939277695071314

Epoch: 5| Step: 2
Training loss: 2.3852787017822266
Validation loss: 2.278088777296005

Epoch: 5| Step: 3
Training loss: 2.5300424098968506
Validation loss: 2.2902201298744447

Epoch: 5| Step: 4
Training loss: 2.2679357528686523
Validation loss: 2.2864738561773814

Epoch: 5| Step: 5
Training loss: 2.611581802368164
Validation loss: 2.284165318294238

Epoch: 5| Step: 6
Training loss: 2.604499101638794
Validation loss: 2.289499439218993

Epoch: 5| Step: 7
Training loss: 2.8063571453094482
Validation loss: 2.3028772800199446

Epoch: 5| Step: 8
Training loss: 2.351520538330078
Validation loss: 2.2927397105001632

Epoch: 5| Step: 9
Training loss: 1.9340879917144775
Validation loss: 2.2972334110608665

Epoch: 5| Step: 10
Training loss: 2.3301138877868652
Validation loss: 2.312130856257613

Epoch: 247| Step: 0
Training loss: 2.769747495651245
Validation loss: 2.3029381152122252

Epoch: 5| Step: 1
Training loss: 2.1568312644958496
Validation loss: 2.315314533889935

Epoch: 5| Step: 2
Training loss: 2.226900339126587
Validation loss: 2.3191386961167857

Epoch: 5| Step: 3
Training loss: 2.6700260639190674
Validation loss: 2.3197383765251405

Epoch: 5| Step: 4
Training loss: 2.5809433460235596
Validation loss: 2.3071319723642

Epoch: 5| Step: 5
Training loss: 2.3446907997131348
Validation loss: 2.2983297660786617

Epoch: 5| Step: 6
Training loss: 2.5064473152160645
Validation loss: 2.2907606581205964

Epoch: 5| Step: 7
Training loss: 2.419821262359619
Validation loss: 2.2806422325872604

Epoch: 5| Step: 8
Training loss: 2.6847400665283203
Validation loss: 2.2874633932626374

Epoch: 5| Step: 9
Training loss: 2.3909478187561035
Validation loss: 2.283336184358084

Epoch: 5| Step: 10
Training loss: 2.7789652347564697
Validation loss: 2.28700666786522

Epoch: 248| Step: 0
Training loss: 2.925682544708252
Validation loss: 2.27854069330359

Epoch: 5| Step: 1
Training loss: 1.673154592514038
Validation loss: 2.279152383086502

Epoch: 5| Step: 2
Training loss: 2.477433204650879
Validation loss: 2.2874788725247948

Epoch: 5| Step: 3
Training loss: 2.7017905712127686
Validation loss: 2.2881884574890137

Epoch: 5| Step: 4
Training loss: 2.105611801147461
Validation loss: 2.300285226555281

Epoch: 5| Step: 5
Training loss: 2.6974594593048096
Validation loss: 2.301472597224738

Epoch: 5| Step: 6
Training loss: 2.4149112701416016
Validation loss: 2.329399821578815

Epoch: 5| Step: 7
Training loss: 2.074705123901367
Validation loss: 2.3390386284038587

Epoch: 5| Step: 8
Training loss: 2.6150994300842285
Validation loss: 2.331032463299331

Epoch: 5| Step: 9
Training loss: 2.8353190422058105
Validation loss: 2.327066913727791

Epoch: 5| Step: 10
Training loss: 3.0005502700805664
Validation loss: 2.312100887298584

Epoch: 249| Step: 0
Training loss: 2.497722625732422
Validation loss: 2.3033862472862325

Epoch: 5| Step: 1
Training loss: 3.0678882598876953
Validation loss: 2.2943352704407065

Epoch: 5| Step: 2
Training loss: 2.81872296333313
Validation loss: 2.311825877876692

Epoch: 5| Step: 3
Training loss: 2.076003074645996
Validation loss: 2.2960154471858853

Epoch: 5| Step: 4
Training loss: 2.279015302658081
Validation loss: 2.3041244655527096

Epoch: 5| Step: 5
Training loss: 2.4209659099578857
Validation loss: 2.306572337304392

Epoch: 5| Step: 6
Training loss: 2.052269697189331
Validation loss: 2.288546839068013

Epoch: 5| Step: 7
Training loss: 2.529665470123291
Validation loss: 2.298707905636039

Epoch: 5| Step: 8
Training loss: 2.4604504108428955
Validation loss: 2.289692691577378

Epoch: 5| Step: 9
Training loss: 2.45573091506958
Validation loss: 2.28156082348157

Epoch: 5| Step: 10
Training loss: 2.615783452987671
Validation loss: 2.3014150947652836

Epoch: 250| Step: 0
Training loss: 2.290271282196045
Validation loss: 2.3127999100633847

Epoch: 5| Step: 1
Training loss: 2.32488751411438
Validation loss: 2.3009623558290544

Epoch: 5| Step: 2
Training loss: 2.203655958175659
Validation loss: 2.3122611917475218

Epoch: 5| Step: 3
Training loss: 3.209059476852417
Validation loss: 2.318751512035247

Epoch: 5| Step: 4
Training loss: 2.9430956840515137
Validation loss: 2.3171654798651256

Epoch: 5| Step: 5
Training loss: 2.251788854598999
Validation loss: 2.2875858711939987

Epoch: 5| Step: 6
Training loss: 2.359659194946289
Validation loss: 2.2763579378845873

Epoch: 5| Step: 7
Training loss: 2.6928207874298096
Validation loss: 2.2638493148229455

Epoch: 5| Step: 8
Training loss: 2.248241901397705
Validation loss: 2.2660083463115077

Epoch: 5| Step: 9
Training loss: 2.2447383403778076
Validation loss: 2.2670423574345087

Epoch: 5| Step: 10
Training loss: 2.429021120071411
Validation loss: 2.270434625687138

Testing loss: 2.507286296950446
