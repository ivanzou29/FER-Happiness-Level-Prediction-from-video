Epoch: 1| Step: 0
Training loss: 4.825987815856934
Validation loss: 5.228068900364701

Epoch: 5| Step: 1
Training loss: 4.693151473999023
Validation loss: 5.22105021630564

Epoch: 5| Step: 2
Training loss: 5.219287872314453
Validation loss: 5.2139999892122

Epoch: 5| Step: 3
Training loss: 6.164656162261963
Validation loss: 5.206635280322003

Epoch: 5| Step: 4
Training loss: 5.318560600280762
Validation loss: 5.198926597513179

Epoch: 5| Step: 5
Training loss: 5.267976760864258
Validation loss: 5.191245396931966

Epoch: 5| Step: 6
Training loss: 5.479244232177734
Validation loss: 5.182720353526454

Epoch: 5| Step: 7
Training loss: 4.427896499633789
Validation loss: 5.173566623400617

Epoch: 5| Step: 8
Training loss: 3.092167615890503
Validation loss: 5.163788851871286

Epoch: 5| Step: 9
Training loss: 4.602773189544678
Validation loss: 5.153443254450316

Epoch: 5| Step: 10
Training loss: 5.854538440704346
Validation loss: 5.1416361588303765

Epoch: 2| Step: 0
Training loss: 6.319191932678223
Validation loss: 5.129610435937041

Epoch: 5| Step: 1
Training loss: 4.805083751678467
Validation loss: 5.116215854562739

Epoch: 5| Step: 2
Training loss: 5.008429527282715
Validation loss: 5.101483601395802

Epoch: 5| Step: 3
Training loss: 4.794316291809082
Validation loss: 5.08543336519631

Epoch: 5| Step: 4
Training loss: 4.918438911437988
Validation loss: 5.068107948508314

Epoch: 5| Step: 5
Training loss: 5.036463737487793
Validation loss: 5.049197514851888

Epoch: 5| Step: 6
Training loss: 4.761449337005615
Validation loss: 5.030074178531605

Epoch: 5| Step: 7
Training loss: 4.752419948577881
Validation loss: 5.007802999147805

Epoch: 5| Step: 8
Training loss: 4.448514461517334
Validation loss: 4.983701811041883

Epoch: 5| Step: 9
Training loss: 4.311474800109863
Validation loss: 4.959764613900133

Epoch: 5| Step: 10
Training loss: 3.938704490661621
Validation loss: 4.933327562065535

Epoch: 3| Step: 0
Training loss: 5.027901649475098
Validation loss: 4.903271362345706

Epoch: 5| Step: 1
Training loss: 4.987834930419922
Validation loss: 4.872774816328479

Epoch: 5| Step: 2
Training loss: 3.6535873413085938
Validation loss: 4.839572921875985

Epoch: 5| Step: 3
Training loss: 4.478663444519043
Validation loss: 4.805168621001705

Epoch: 5| Step: 4
Training loss: 4.505043029785156
Validation loss: 4.769403749896634

Epoch: 5| Step: 5
Training loss: 3.6805806159973145
Validation loss: 4.732100030427338

Epoch: 5| Step: 6
Training loss: 5.002164363861084
Validation loss: 4.69449705718666

Epoch: 5| Step: 7
Training loss: 4.426934242248535
Validation loss: 4.653778676063784

Epoch: 5| Step: 8
Training loss: 4.2630934715271
Validation loss: 4.614600714816842

Epoch: 5| Step: 9
Training loss: 5.339303016662598
Validation loss: 4.574709589763354

Epoch: 5| Step: 10
Training loss: 4.216436862945557
Validation loss: 4.533775744899627

Epoch: 4| Step: 0
Training loss: 5.5177321434021
Validation loss: 4.490579030847036

Epoch: 5| Step: 1
Training loss: 4.279659271240234
Validation loss: 4.450537912307247

Epoch: 5| Step: 2
Training loss: 3.6694693565368652
Validation loss: 4.408043730643488

Epoch: 5| Step: 3
Training loss: 3.601090908050537
Validation loss: 4.365957901041995

Epoch: 5| Step: 4
Training loss: 3.6798834800720215
Validation loss: 4.327090535112607

Epoch: 5| Step: 5
Training loss: 3.982696533203125
Validation loss: 4.286714456414663

Epoch: 5| Step: 6
Training loss: 4.133992671966553
Validation loss: 4.248989840989472

Epoch: 5| Step: 7
Training loss: 3.4547038078308105
Validation loss: 4.214364723492694

Epoch: 5| Step: 8
Training loss: 5.785226345062256
Validation loss: 4.181729350038754

Epoch: 5| Step: 9
Training loss: 3.314324140548706
Validation loss: 4.150289838032056

Epoch: 5| Step: 10
Training loss: 3.648397207260132
Validation loss: 4.118526674086048

Epoch: 5| Step: 0
Training loss: 4.519668102264404
Validation loss: 4.090118295402937

Epoch: 5| Step: 1
Training loss: 3.6255409717559814
Validation loss: 4.06246252470119

Epoch: 5| Step: 2
Training loss: 4.108061790466309
Validation loss: 4.0339572814203075

Epoch: 5| Step: 3
Training loss: 3.868678331375122
Validation loss: 4.005569263171124

Epoch: 5| Step: 4
Training loss: 3.751476764678955
Validation loss: 3.9797326877552974

Epoch: 5| Step: 5
Training loss: 4.636518478393555
Validation loss: 3.953245480855306

Epoch: 5| Step: 6
Training loss: 3.9135303497314453
Validation loss: 3.9293100603165163

Epoch: 5| Step: 7
Training loss: 3.149435520172119
Validation loss: 3.904515004927112

Epoch: 5| Step: 8
Training loss: 3.7236740589141846
Validation loss: 3.8831591965049825

Epoch: 5| Step: 9
Training loss: 3.452272415161133
Validation loss: 3.8631100705874863

Epoch: 5| Step: 10
Training loss: 3.1847012042999268
Validation loss: 3.843906669206517

Epoch: 6| Step: 0
Training loss: 2.685723066329956
Validation loss: 3.823722324063701

Epoch: 5| Step: 1
Training loss: 4.184769630432129
Validation loss: 3.805595700458814

Epoch: 5| Step: 2
Training loss: 4.8389811515808105
Validation loss: 3.7814780153254026

Epoch: 5| Step: 3
Training loss: 2.9589755535125732
Validation loss: 3.760408996253885

Epoch: 5| Step: 4
Training loss: 2.8937947750091553
Validation loss: 3.7396773830536874

Epoch: 5| Step: 5
Training loss: 3.8005688190460205
Validation loss: 3.7183791847639185

Epoch: 5| Step: 6
Training loss: 4.742564678192139
Validation loss: 3.7011185564020628

Epoch: 5| Step: 7
Training loss: 3.840414047241211
Validation loss: 3.679083485757151

Epoch: 5| Step: 8
Training loss: 3.3288254737854004
Validation loss: 3.653749704360962

Epoch: 5| Step: 9
Training loss: 3.0560009479522705
Validation loss: 3.634592230601977

Epoch: 5| Step: 10
Training loss: 3.4362051486968994
Validation loss: 3.615719605517644

Epoch: 7| Step: 0
Training loss: 4.172122955322266
Validation loss: 3.596021777840071

Epoch: 5| Step: 1
Training loss: 4.42259407043457
Validation loss: 3.5783027166961343

Epoch: 5| Step: 2
Training loss: 3.326561450958252
Validation loss: 3.5616246141413206

Epoch: 5| Step: 3
Training loss: 3.8754944801330566
Validation loss: 3.5522589247713805

Epoch: 5| Step: 4
Training loss: 2.914951801300049
Validation loss: 3.544536006066107

Epoch: 5| Step: 5
Training loss: 3.2076351642608643
Validation loss: 3.539198496008432

Epoch: 5| Step: 6
Training loss: 3.957963466644287
Validation loss: 3.5267223568372827

Epoch: 5| Step: 7
Training loss: 2.939239025115967
Validation loss: 3.5156687280183196

Epoch: 5| Step: 8
Training loss: 3.390939712524414
Validation loss: 3.504814532495314

Epoch: 5| Step: 9
Training loss: 3.6128368377685547
Validation loss: 3.495881119082051

Epoch: 5| Step: 10
Training loss: 2.077755928039551
Validation loss: 3.4864157989460933

Epoch: 8| Step: 0
Training loss: 3.951211452484131
Validation loss: 3.47553163959134

Epoch: 5| Step: 1
Training loss: 3.80529522895813
Validation loss: 3.461083819789271

Epoch: 5| Step: 2
Training loss: 3.18695068359375
Validation loss: 3.4482475557634906

Epoch: 5| Step: 3
Training loss: 2.453580379486084
Validation loss: 3.438321239204817

Epoch: 5| Step: 4
Training loss: 3.647723436355591
Validation loss: 3.4322421166204635

Epoch: 5| Step: 5
Training loss: 3.932039737701416
Validation loss: 3.4244318828787854

Epoch: 5| Step: 6
Training loss: 2.5589325428009033
Validation loss: 3.4085043502110306

Epoch: 5| Step: 7
Training loss: 4.111884117126465
Validation loss: 3.4025514407824446

Epoch: 5| Step: 8
Training loss: 2.8634748458862305
Validation loss: 3.3983652155886412

Epoch: 5| Step: 9
Training loss: 3.111128091812134
Validation loss: 3.397364793285247

Epoch: 5| Step: 10
Training loss: 3.5189666748046875
Validation loss: 3.393477286061933

Epoch: 9| Step: 0
Training loss: 2.6534790992736816
Validation loss: 3.383975080264512

Epoch: 5| Step: 1
Training loss: 3.704125165939331
Validation loss: 3.374549799068

Epoch: 5| Step: 2
Training loss: 1.6985317468643188
Validation loss: 3.3720113000562115

Epoch: 5| Step: 3
Training loss: 3.836637020111084
Validation loss: 3.375476929449266

Epoch: 5| Step: 4
Training loss: 3.9040915966033936
Validation loss: 3.371349291134906

Epoch: 5| Step: 5
Training loss: 4.42901086807251
Validation loss: 3.3596123162136284

Epoch: 5| Step: 6
Training loss: 2.5181376934051514
Validation loss: 3.345156374798026

Epoch: 5| Step: 7
Training loss: 3.568441390991211
Validation loss: 3.348238621988604

Epoch: 5| Step: 8
Training loss: 3.2121150493621826
Validation loss: 3.3539826152145222

Epoch: 5| Step: 9
Training loss: 3.1529154777526855
Validation loss: 3.35229423481931

Epoch: 5| Step: 10
Training loss: 3.9464735984802246
Validation loss: 3.33352336319544

Epoch: 10| Step: 0
Training loss: 3.8355917930603027
Validation loss: 3.3224865672408894

Epoch: 5| Step: 1
Training loss: 3.627410411834717
Validation loss: 3.3209069621178413

Epoch: 5| Step: 2
Training loss: 3.3406944274902344
Validation loss: 3.329290659196915

Epoch: 5| Step: 3
Training loss: 3.4102768898010254
Validation loss: 3.331545868227559

Epoch: 5| Step: 4
Training loss: 2.4981322288513184
Validation loss: 3.30912967394757

Epoch: 5| Step: 5
Training loss: 2.8071932792663574
Validation loss: 3.2975286463255524

Epoch: 5| Step: 6
Training loss: 3.451678514480591
Validation loss: 3.294069472179618

Epoch: 5| Step: 7
Training loss: 3.472783327102661
Validation loss: 3.299375964749244

Epoch: 5| Step: 8
Training loss: 3.781935453414917
Validation loss: 3.294824161837178

Epoch: 5| Step: 9
Training loss: 2.8912079334259033
Validation loss: 3.2838710943857827

Epoch: 5| Step: 10
Training loss: 2.835362434387207
Validation loss: 3.269623984572708

Epoch: 11| Step: 0
Training loss: 3.4411702156066895
Validation loss: 3.260780801055252

Epoch: 5| Step: 1
Training loss: 3.9295566082000732
Validation loss: 3.253520852775984

Epoch: 5| Step: 2
Training loss: 3.0597846508026123
Validation loss: 3.2499808367862495

Epoch: 5| Step: 3
Training loss: 3.3319904804229736
Validation loss: 3.2503065037470993

Epoch: 5| Step: 4
Training loss: 3.0919086933135986
Validation loss: 3.242679677983766

Epoch: 5| Step: 5
Training loss: 3.5838470458984375
Validation loss: 3.2390775142177457

Epoch: 5| Step: 6
Training loss: 3.1260275840759277
Validation loss: 3.234267323247848

Epoch: 5| Step: 7
Training loss: 3.4009101390838623
Validation loss: 3.225749541354436

Epoch: 5| Step: 8
Training loss: 3.0038645267486572
Validation loss: 3.2145232103204213

Epoch: 5| Step: 9
Training loss: 3.543138027191162
Validation loss: 3.2110723654429116

Epoch: 5| Step: 10
Training loss: 1.7389196157455444
Validation loss: 3.2104395384429605

Epoch: 12| Step: 0
Training loss: 2.801504373550415
Validation loss: 3.218976984741867

Epoch: 5| Step: 1
Training loss: 3.498775005340576
Validation loss: 3.2255874039024435

Epoch: 5| Step: 2
Training loss: 2.6434104442596436
Validation loss: 3.203685983534782

Epoch: 5| Step: 3
Training loss: 2.9405388832092285
Validation loss: 3.1955417407456266

Epoch: 5| Step: 4
Training loss: 3.719156265258789
Validation loss: 3.190078330296342

Epoch: 5| Step: 5
Training loss: 2.578881025314331
Validation loss: 3.193477548578734

Epoch: 5| Step: 6
Training loss: 2.444334030151367
Validation loss: 3.187193485998338

Epoch: 5| Step: 7
Training loss: 4.210461616516113
Validation loss: 3.1781995604115147

Epoch: 5| Step: 8
Training loss: 3.290342330932617
Validation loss: 3.170844119082215

Epoch: 5| Step: 9
Training loss: 3.490967273712158
Validation loss: 3.1689136079562608

Epoch: 5| Step: 10
Training loss: 3.5340592861175537
Validation loss: 3.1686196993756037

Epoch: 13| Step: 0
Training loss: 3.019098997116089
Validation loss: 3.159631383034491

Epoch: 5| Step: 1
Training loss: 2.230015277862549
Validation loss: 3.1655886147611882

Epoch: 5| Step: 2
Training loss: 3.736362934112549
Validation loss: 3.1539652783383607

Epoch: 5| Step: 3
Training loss: 3.2007553577423096
Validation loss: 3.1484345543769097

Epoch: 5| Step: 4
Training loss: 2.760416030883789
Validation loss: 3.1414274349007556

Epoch: 5| Step: 5
Training loss: 3.65114164352417
Validation loss: 3.1423736003137406

Epoch: 5| Step: 6
Training loss: 3.5881175994873047
Validation loss: 3.142651475885863

Epoch: 5| Step: 7
Training loss: 3.6887454986572266
Validation loss: 3.1425822550250637

Epoch: 5| Step: 8
Training loss: 2.377692222595215
Validation loss: 3.127973348863663

Epoch: 5| Step: 9
Training loss: 3.083784580230713
Validation loss: 3.120210098963912

Epoch: 5| Step: 10
Training loss: 3.401832103729248
Validation loss: 3.1149179832909697

Epoch: 14| Step: 0
Training loss: 3.445405960083008
Validation loss: 3.114342466477425

Epoch: 5| Step: 1
Training loss: 2.8916449546813965
Validation loss: 3.109601818105226

Epoch: 5| Step: 2
Training loss: 3.8079848289489746
Validation loss: 3.110047132738175

Epoch: 5| Step: 3
Training loss: 2.987287759780884
Validation loss: 3.1013615977379585

Epoch: 5| Step: 4
Training loss: 2.943244218826294
Validation loss: 3.097965940352409

Epoch: 5| Step: 5
Training loss: 3.5084900856018066
Validation loss: 3.092926186899985

Epoch: 5| Step: 6
Training loss: 2.721703052520752
Validation loss: 3.08864604016786

Epoch: 5| Step: 7
Training loss: 2.8022351264953613
Validation loss: 3.0823566887968328

Epoch: 5| Step: 8
Training loss: 3.464916229248047
Validation loss: 3.0836899639457784

Epoch: 5| Step: 9
Training loss: 2.958549976348877
Validation loss: 3.0789234484395673

Epoch: 5| Step: 10
Training loss: 2.8104162216186523
Validation loss: 3.0713701812169885

Epoch: 15| Step: 0
Training loss: 2.7760419845581055
Validation loss: 3.0683073689860683

Epoch: 5| Step: 1
Training loss: 3.3845183849334717
Validation loss: 3.0632713199943624

Epoch: 5| Step: 2
Training loss: 3.2152366638183594
Validation loss: 3.063917011343023

Epoch: 5| Step: 3
Training loss: 3.358473539352417
Validation loss: 3.0600975713422223

Epoch: 5| Step: 4
Training loss: 3.3903846740722656
Validation loss: 3.0552763323630057

Epoch: 5| Step: 5
Training loss: 3.5711159706115723
Validation loss: 3.053888449104883

Epoch: 5| Step: 6
Training loss: 3.2627956867218018
Validation loss: 3.0521259641134613

Epoch: 5| Step: 7
Training loss: 2.7132041454315186
Validation loss: 3.0486677872237338

Epoch: 5| Step: 8
Training loss: 3.4247913360595703
Validation loss: 3.0444546899487896

Epoch: 5| Step: 9
Training loss: 2.8880393505096436
Validation loss: 3.0444792444987963

Epoch: 5| Step: 10
Training loss: 1.8902406692504883
Validation loss: 3.038327952866913

Epoch: 16| Step: 0
Training loss: 3.188441038131714
Validation loss: 3.0321418418679187

Epoch: 5| Step: 1
Training loss: 2.5573112964630127
Validation loss: 3.0324238782287924

Epoch: 5| Step: 2
Training loss: 2.781452178955078
Validation loss: 3.027269104475616

Epoch: 5| Step: 3
Training loss: 3.6391968727111816
Validation loss: 3.0258934779833724

Epoch: 5| Step: 4
Training loss: 3.5466949939727783
Validation loss: 3.0194945027751308

Epoch: 5| Step: 5
Training loss: 2.3285369873046875
Validation loss: 3.016654581151983

Epoch: 5| Step: 6
Training loss: 3.6128296852111816
Validation loss: 3.0149986077380437

Epoch: 5| Step: 7
Training loss: 3.068148374557495
Validation loss: 3.010565580860261

Epoch: 5| Step: 8
Training loss: 3.266413927078247
Validation loss: 3.0108511934998217

Epoch: 5| Step: 9
Training loss: 3.5181949138641357
Validation loss: 3.005658375319614

Epoch: 5| Step: 10
Training loss: 2.19221568107605
Validation loss: 3.01211146385439

Epoch: 17| Step: 0
Training loss: 3.5510926246643066
Validation loss: 3.0104508912691506

Epoch: 5| Step: 1
Training loss: 3.075855255126953
Validation loss: 2.9959594306125434

Epoch: 5| Step: 2
Training loss: 2.9225542545318604
Validation loss: 2.99217555856192

Epoch: 5| Step: 3
Training loss: 2.7514617443084717
Validation loss: 2.9898779264060398

Epoch: 5| Step: 4
Training loss: 3.2835910320281982
Validation loss: 2.9905735472197175

Epoch: 5| Step: 5
Training loss: 2.439791202545166
Validation loss: 2.988589379095262

Epoch: 5| Step: 6
Training loss: 3.5660736560821533
Validation loss: 2.9871726548799904

Epoch: 5| Step: 7
Training loss: 2.967174530029297
Validation loss: 2.9856415384559223

Epoch: 5| Step: 8
Training loss: 2.1224536895751953
Validation loss: 2.9809727463670956

Epoch: 5| Step: 9
Training loss: 3.0583336353302
Validation loss: 2.978761431991413

Epoch: 5| Step: 10
Training loss: 4.005739212036133
Validation loss: 2.9741852104022937

Epoch: 18| Step: 0
Training loss: 3.846402406692505
Validation loss: 2.9696598770797893

Epoch: 5| Step: 1
Training loss: 3.0048041343688965
Validation loss: 2.9698675934986403

Epoch: 5| Step: 2
Training loss: 3.078371524810791
Validation loss: 2.9637393105414604

Epoch: 5| Step: 3
Training loss: 2.578834056854248
Validation loss: 2.9696881207086707

Epoch: 5| Step: 4
Training loss: 2.064157247543335
Validation loss: 2.967860380808512

Epoch: 5| Step: 5
Training loss: 2.97880482673645
Validation loss: 2.9569370669703328

Epoch: 5| Step: 6
Training loss: 3.177128314971924
Validation loss: 2.95723355713711

Epoch: 5| Step: 7
Training loss: 3.5988121032714844
Validation loss: 2.955713813022901

Epoch: 5| Step: 8
Training loss: 2.9334073066711426
Validation loss: 2.954098786077192

Epoch: 5| Step: 9
Training loss: 3.420398712158203
Validation loss: 2.9501457342537503

Epoch: 5| Step: 10
Training loss: 2.676072359085083
Validation loss: 2.9491743579987557

Epoch: 19| Step: 0
Training loss: 2.5580625534057617
Validation loss: 2.944413938829976

Epoch: 5| Step: 1
Training loss: 2.728604555130005
Validation loss: 2.9434143650916313

Epoch: 5| Step: 2
Training loss: 3.841423511505127
Validation loss: 2.938600522215648

Epoch: 5| Step: 3
Training loss: 2.0757927894592285
Validation loss: 2.935537335693195

Epoch: 5| Step: 4
Training loss: 2.6201133728027344
Validation loss: 2.934044171405095

Epoch: 5| Step: 5
Training loss: 3.422527313232422
Validation loss: 2.9338833285916235

Epoch: 5| Step: 6
Training loss: 3.5816731452941895
Validation loss: 2.929487851358229

Epoch: 5| Step: 7
Training loss: 2.4982285499572754
Validation loss: 2.927288688639159

Epoch: 5| Step: 8
Training loss: 3.578068494796753
Validation loss: 2.921838742430492

Epoch: 5| Step: 9
Training loss: 2.8415629863739014
Validation loss: 2.9247752005054104

Epoch: 5| Step: 10
Training loss: 3.58455491065979
Validation loss: 2.9282503358779417

Epoch: 20| Step: 0
Training loss: 3.5584254264831543
Validation loss: 2.9271197447212796

Epoch: 5| Step: 1
Training loss: 3.006141424179077
Validation loss: 2.917061023814704

Epoch: 5| Step: 2
Training loss: 3.083700656890869
Validation loss: 2.9133405121423865

Epoch: 5| Step: 3
Training loss: 3.025146007537842
Validation loss: 2.911126490562193

Epoch: 5| Step: 4
Training loss: 2.8314998149871826
Validation loss: 2.90575139240552

Epoch: 5| Step: 5
Training loss: 3.170409679412842
Validation loss: 2.913237264079432

Epoch: 5| Step: 6
Training loss: 2.527787685394287
Validation loss: 2.9019495159067135

Epoch: 5| Step: 7
Training loss: 3.132107973098755
Validation loss: 2.8988879854961107

Epoch: 5| Step: 8
Training loss: 2.883118152618408
Validation loss: 2.8987081050872803

Epoch: 5| Step: 9
Training loss: 3.005831003189087
Validation loss: 2.896280545060353

Epoch: 5| Step: 10
Training loss: 2.7503504753112793
Validation loss: 2.896059013182117

Epoch: 21| Step: 0
Training loss: 2.914628267288208
Validation loss: 2.900238331928048

Epoch: 5| Step: 1
Training loss: 3.8665823936462402
Validation loss: 2.914721886316935

Epoch: 5| Step: 2
Training loss: 3.2298684120178223
Validation loss: 2.9084242287502495

Epoch: 5| Step: 3
Training loss: 3.5242621898651123
Validation loss: 2.9007025662288872

Epoch: 5| Step: 4
Training loss: 2.521322727203369
Validation loss: 2.888465932620469

Epoch: 5| Step: 5
Training loss: 2.8156018257141113
Validation loss: 2.8803704348943566

Epoch: 5| Step: 6
Training loss: 2.4572434425354004
Validation loss: 2.8748634989543627

Epoch: 5| Step: 7
Training loss: 3.20881986618042
Validation loss: 2.873111491562218

Epoch: 5| Step: 8
Training loss: 3.449836015701294
Validation loss: 2.872722848769157

Epoch: 5| Step: 9
Training loss: 2.5561394691467285
Validation loss: 2.8690866001190676

Epoch: 5| Step: 10
Training loss: 2.1412487030029297
Validation loss: 2.8770717190157984

Epoch: 22| Step: 0
Training loss: 2.4470438957214355
Validation loss: 2.8673073937816005

Epoch: 5| Step: 1
Training loss: 3.3416213989257812
Validation loss: 2.858421843539002

Epoch: 5| Step: 2
Training loss: 3.3595199584960938
Validation loss: 2.858523027871245

Epoch: 5| Step: 3
Training loss: 3.433262586593628
Validation loss: 2.8529223677932576

Epoch: 5| Step: 4
Training loss: 2.868542194366455
Validation loss: 2.8534209446240495

Epoch: 5| Step: 5
Training loss: 2.9695186614990234
Validation loss: 2.8625601491620465

Epoch: 5| Step: 6
Training loss: 3.0101277828216553
Validation loss: 2.8515401245445333

Epoch: 5| Step: 7
Training loss: 2.8781368732452393
Validation loss: 2.852726044193391

Epoch: 5| Step: 8
Training loss: 3.2346320152282715
Validation loss: 2.8450195045881372

Epoch: 5| Step: 9
Training loss: 2.8204197883605957
Validation loss: 2.8420377905650804

Epoch: 5| Step: 10
Training loss: 2.0508134365081787
Validation loss: 2.8476626975561983

Epoch: 23| Step: 0
Training loss: 2.5321998596191406
Validation loss: 2.84541844296199

Epoch: 5| Step: 1
Training loss: 3.669205904006958
Validation loss: 2.8357431170760945

Epoch: 5| Step: 2
Training loss: 2.92061185836792
Validation loss: 2.829401780200261

Epoch: 5| Step: 3
Training loss: 2.9197001457214355
Validation loss: 2.8277415460155857

Epoch: 5| Step: 4
Training loss: 3.70928692817688
Validation loss: 2.823704009415001

Epoch: 5| Step: 5
Training loss: 3.142012119293213
Validation loss: 2.8287801358007614

Epoch: 5| Step: 6
Training loss: 2.606158494949341
Validation loss: 2.8189197560792327

Epoch: 5| Step: 7
Training loss: 2.752464771270752
Validation loss: 2.815298559845135

Epoch: 5| Step: 8
Training loss: 2.1884326934814453
Validation loss: 2.8199223779862925

Epoch: 5| Step: 9
Training loss: 3.4182205200195312
Validation loss: 2.832062449506534

Epoch: 5| Step: 10
Training loss: 2.478022336959839
Validation loss: 2.827862403726065

Epoch: 24| Step: 0
Training loss: 2.5407230854034424
Validation loss: 2.8236663059521745

Epoch: 5| Step: 1
Training loss: 3.217702865600586
Validation loss: 2.8120729000337663

Epoch: 5| Step: 2
Training loss: 2.4071669578552246
Validation loss: 2.8097585555045836

Epoch: 5| Step: 3
Training loss: 3.3288028240203857
Validation loss: 2.807606566336847

Epoch: 5| Step: 4
Training loss: 2.8372066020965576
Validation loss: 2.8025198187879337

Epoch: 5| Step: 5
Training loss: 2.5219566822052
Validation loss: 2.8073986935359176

Epoch: 5| Step: 6
Training loss: 3.1619930267333984
Validation loss: 2.8040922867354525

Epoch: 5| Step: 7
Training loss: 2.793144941329956
Validation loss: 2.806448908262355

Epoch: 5| Step: 8
Training loss: 3.2553024291992188
Validation loss: 2.7996190722270677

Epoch: 5| Step: 9
Training loss: 3.1938507556915283
Validation loss: 2.798821662061958

Epoch: 5| Step: 10
Training loss: 3.0151824951171875
Validation loss: 2.8068300216428694

Epoch: 25| Step: 0
Training loss: 2.725738525390625
Validation loss: 2.809981115402714

Epoch: 5| Step: 1
Training loss: 2.904299259185791
Validation loss: 2.812402561146726

Epoch: 5| Step: 2
Training loss: 2.8478827476501465
Validation loss: 2.811051502022692

Epoch: 5| Step: 3
Training loss: 2.522984027862549
Validation loss: 2.803432377435828

Epoch: 5| Step: 4
Training loss: 3.21630597114563
Validation loss: 2.799243493746686

Epoch: 5| Step: 5
Training loss: 2.912200450897217
Validation loss: 2.7940047838354625

Epoch: 5| Step: 6
Training loss: 2.819350004196167
Validation loss: 2.7900193660489974

Epoch: 5| Step: 7
Training loss: 3.069044828414917
Validation loss: 2.7893084864462576

Epoch: 5| Step: 8
Training loss: 3.2130885124206543
Validation loss: 2.789529800415039

Epoch: 5| Step: 9
Training loss: 2.648494005203247
Validation loss: 2.7883453369140625

Epoch: 5| Step: 10
Training loss: 3.3022735118865967
Validation loss: 2.7839805362045125

Epoch: 26| Step: 0
Training loss: 2.9798343181610107
Validation loss: 2.7751240807194866

Epoch: 5| Step: 1
Training loss: 3.0443873405456543
Validation loss: 2.773200427332232

Epoch: 5| Step: 2
Training loss: 3.282288074493408
Validation loss: 2.774496529691963

Epoch: 5| Step: 3
Training loss: 2.6101677417755127
Validation loss: 2.7724007996179725

Epoch: 5| Step: 4
Training loss: 1.8522183895111084
Validation loss: 2.7728090132436445

Epoch: 5| Step: 5
Training loss: 2.399336338043213
Validation loss: 2.7780020262605403

Epoch: 5| Step: 6
Training loss: 3.5266165733337402
Validation loss: 2.781616113519156

Epoch: 5| Step: 7
Training loss: 2.8395495414733887
Validation loss: 2.775207927150111

Epoch: 5| Step: 8
Training loss: 2.770061492919922
Validation loss: 2.8010614379759757

Epoch: 5| Step: 9
Training loss: 3.2849297523498535
Validation loss: 2.7988554867365028

Epoch: 5| Step: 10
Training loss: 3.4278907775878906
Validation loss: 2.796480865888698

Epoch: 27| Step: 0
Training loss: 3.1723873615264893
Validation loss: 2.7681382112605597

Epoch: 5| Step: 1
Training loss: 1.8434680700302124
Validation loss: 2.76010049030345

Epoch: 5| Step: 2
Training loss: 3.607667922973633
Validation loss: 2.758048349811185

Epoch: 5| Step: 3
Training loss: 3.235370635986328
Validation loss: 2.7646325044734503

Epoch: 5| Step: 4
Training loss: 2.88273286819458
Validation loss: 2.763867352598457

Epoch: 5| Step: 5
Training loss: 2.6737732887268066
Validation loss: 2.7650314966837564

Epoch: 5| Step: 6
Training loss: 2.7841827869415283
Validation loss: 2.7601550497034544

Epoch: 5| Step: 7
Training loss: 3.202791690826416
Validation loss: 2.7548233770555064

Epoch: 5| Step: 8
Training loss: 2.3597779273986816
Validation loss: 2.7555594764729983

Epoch: 5| Step: 9
Training loss: 3.194819927215576
Validation loss: 2.7564058201287382

Epoch: 5| Step: 10
Training loss: 2.9661309719085693
Validation loss: 2.762466161481796

Epoch: 28| Step: 0
Training loss: 3.002960205078125
Validation loss: 2.7627243354756343

Epoch: 5| Step: 1
Training loss: 2.6544430255889893
Validation loss: 2.7671983703490226

Epoch: 5| Step: 2
Training loss: 2.307687282562256
Validation loss: 2.77835173760691

Epoch: 5| Step: 3
Training loss: 3.077885866165161
Validation loss: 2.760654144389655

Epoch: 5| Step: 4
Training loss: 2.285367488861084
Validation loss: 2.741882114000218

Epoch: 5| Step: 5
Training loss: 3.402432680130005
Validation loss: 2.7367827251393306

Epoch: 5| Step: 6
Training loss: 2.9355039596557617
Validation loss: 2.729247772565452

Epoch: 5| Step: 7
Training loss: 2.480625629425049
Validation loss: 2.7276555671486804

Epoch: 5| Step: 8
Training loss: 4.375060081481934
Validation loss: 2.724850675111176

Epoch: 5| Step: 9
Training loss: 2.7343051433563232
Validation loss: 2.725360219196607

Epoch: 5| Step: 10
Training loss: 2.476935386657715
Validation loss: 2.7247255207389913

Epoch: 29| Step: 0
Training loss: 2.531573534011841
Validation loss: 2.721900837395781

Epoch: 5| Step: 1
Training loss: 2.618694305419922
Validation loss: 2.7218678459044425

Epoch: 5| Step: 2
Training loss: 3.04557728767395
Validation loss: 2.7232710776790494

Epoch: 5| Step: 3
Training loss: 1.8386211395263672
Validation loss: 2.722097971106088

Epoch: 5| Step: 4
Training loss: 3.7556204795837402
Validation loss: 2.72014029308032

Epoch: 5| Step: 5
Training loss: 2.573251485824585
Validation loss: 2.7181717170182096

Epoch: 5| Step: 6
Training loss: 2.45457124710083
Validation loss: 2.715082550561556

Epoch: 5| Step: 7
Training loss: 3.2184360027313232
Validation loss: 2.70900829633077

Epoch: 5| Step: 8
Training loss: 3.6777100563049316
Validation loss: 2.7056013307263775

Epoch: 5| Step: 9
Training loss: 3.0547964572906494
Validation loss: 2.706934218765587

Epoch: 5| Step: 10
Training loss: 2.757715940475464
Validation loss: 2.7081304416861585

Epoch: 30| Step: 0
Training loss: 3.5026257038116455
Validation loss: 2.704894919549265

Epoch: 5| Step: 1
Training loss: 2.113809108734131
Validation loss: 2.7038739829935055

Epoch: 5| Step: 2
Training loss: 3.345080614089966
Validation loss: 2.7035027780840473

Epoch: 5| Step: 3
Training loss: 3.668520450592041
Validation loss: 2.709621367915984

Epoch: 5| Step: 4
Training loss: 3.0466113090515137
Validation loss: 2.705739480192943

Epoch: 5| Step: 5
Training loss: 2.703223466873169
Validation loss: 2.7017693032500563

Epoch: 5| Step: 6
Training loss: 2.4723968505859375
Validation loss: 2.699998401826428

Epoch: 5| Step: 7
Training loss: 3.089893341064453
Validation loss: 2.6971433547235306

Epoch: 5| Step: 8
Training loss: 2.5427281856536865
Validation loss: 2.6970892337060746

Epoch: 5| Step: 9
Training loss: 2.239553213119507
Validation loss: 2.696316078145017

Epoch: 5| Step: 10
Training loss: 2.677255630493164
Validation loss: 2.6910231010888213

Epoch: 31| Step: 0
Training loss: 3.3322746753692627
Validation loss: 2.6872809676713842

Epoch: 5| Step: 1
Training loss: 2.5685362815856934
Validation loss: 2.68783910300142

Epoch: 5| Step: 2
Training loss: 2.45466947555542
Validation loss: 2.6940981700856197

Epoch: 5| Step: 3
Training loss: 2.3444278240203857
Validation loss: 2.6896041875244467

Epoch: 5| Step: 4
Training loss: 2.7858033180236816
Validation loss: 2.688437987399358

Epoch: 5| Step: 5
Training loss: 3.113107204437256
Validation loss: 2.6820160676074285

Epoch: 5| Step: 6
Training loss: 3.0875372886657715
Validation loss: 2.6821405503057663

Epoch: 5| Step: 7
Training loss: 2.6070556640625
Validation loss: 2.6818275041477655

Epoch: 5| Step: 8
Training loss: 3.3263847827911377
Validation loss: 2.695135480614119

Epoch: 5| Step: 9
Training loss: 3.2157444953918457
Validation loss: 2.7097690079801824

Epoch: 5| Step: 10
Training loss: 2.4121055603027344
Validation loss: 2.7263928997901177

Epoch: 32| Step: 0
Training loss: 2.975353240966797
Validation loss: 2.7194297377781202

Epoch: 5| Step: 1
Training loss: 3.5325520038604736
Validation loss: 2.7054779965390443

Epoch: 5| Step: 2
Training loss: 2.470471143722534
Validation loss: 2.67864050403718

Epoch: 5| Step: 3
Training loss: 2.576368808746338
Validation loss: 2.6734470141831266

Epoch: 5| Step: 4
Training loss: 1.5587222576141357
Validation loss: 2.6665126098099576

Epoch: 5| Step: 5
Training loss: 2.707563877105713
Validation loss: 2.669732537320865

Epoch: 5| Step: 6
Training loss: 3.2767493724823
Validation loss: 2.6685955139898483

Epoch: 5| Step: 7
Training loss: 3.253709077835083
Validation loss: 2.66705741933597

Epoch: 5| Step: 8
Training loss: 3.106799364089966
Validation loss: 2.662452482408093

Epoch: 5| Step: 9
Training loss: 2.529453754425049
Validation loss: 2.662442796973772

Epoch: 5| Step: 10
Training loss: 3.271094560623169
Validation loss: 2.6622232698625132

Epoch: 33| Step: 0
Training loss: 2.969904661178589
Validation loss: 2.664856033940469

Epoch: 5| Step: 1
Training loss: 2.45926570892334
Validation loss: 2.6640445545155513

Epoch: 5| Step: 2
Training loss: 2.4375557899475098
Validation loss: 2.661364504086074

Epoch: 5| Step: 3
Training loss: 3.226163864135742
Validation loss: 2.6586747887314006

Epoch: 5| Step: 4
Training loss: 3.3500823974609375
Validation loss: 2.661216384621077

Epoch: 5| Step: 5
Training loss: 3.3352253437042236
Validation loss: 2.657529113113239

Epoch: 5| Step: 6
Training loss: 2.7777011394500732
Validation loss: 2.6677150444317888

Epoch: 5| Step: 7
Training loss: 2.472285032272339
Validation loss: 2.66361915937034

Epoch: 5| Step: 8
Training loss: 2.7353291511535645
Validation loss: 2.668151560650077

Epoch: 5| Step: 9
Training loss: 2.417874813079834
Validation loss: 2.6644295364297848

Epoch: 5| Step: 10
Training loss: 2.9085657596588135
Validation loss: 2.6627833330503075

Epoch: 34| Step: 0
Training loss: 2.6886274814605713
Validation loss: 2.6540707516413864

Epoch: 5| Step: 1
Training loss: 2.671306610107422
Validation loss: 2.6529052154992216

Epoch: 5| Step: 2
Training loss: 2.584184169769287
Validation loss: 2.6544214115347913

Epoch: 5| Step: 3
Training loss: 2.734621524810791
Validation loss: 2.64902990095077

Epoch: 5| Step: 4
Training loss: 3.154198169708252
Validation loss: 2.648119353478955

Epoch: 5| Step: 5
Training loss: 2.2007482051849365
Validation loss: 2.6527005677582114

Epoch: 5| Step: 6
Training loss: 3.390599012374878
Validation loss: 2.6434829004349245

Epoch: 5| Step: 7
Training loss: 3.185054302215576
Validation loss: 2.646856318237961

Epoch: 5| Step: 8
Training loss: 2.64487361907959
Validation loss: 2.6483762930798274

Epoch: 5| Step: 9
Training loss: 3.086444616317749
Validation loss: 2.647490014312088

Epoch: 5| Step: 10
Training loss: 2.6643824577331543
Validation loss: 2.654362142726939

Epoch: 35| Step: 0
Training loss: 2.773467779159546
Validation loss: 2.654550813859509

Epoch: 5| Step: 1
Training loss: 2.9351563453674316
Validation loss: 2.657341198254657

Epoch: 5| Step: 2
Training loss: 1.791383981704712
Validation loss: 2.6549460477726434

Epoch: 5| Step: 3
Training loss: 2.6528942584991455
Validation loss: 2.6489365869952786

Epoch: 5| Step: 4
Training loss: 3.13810396194458
Validation loss: 2.6454230508496686

Epoch: 5| Step: 5
Training loss: 2.6404120922088623
Validation loss: 2.6481644466359127

Epoch: 5| Step: 6
Training loss: 3.1646323204040527
Validation loss: 2.639587635635048

Epoch: 5| Step: 7
Training loss: 3.1700825691223145
Validation loss: 2.644210038646575

Epoch: 5| Step: 8
Training loss: 3.183663845062256
Validation loss: 2.64383267330867

Epoch: 5| Step: 9
Training loss: 2.9933395385742188
Validation loss: 2.6447003400453957

Epoch: 5| Step: 10
Training loss: 2.4192371368408203
Validation loss: 2.6467721872432257

Epoch: 36| Step: 0
Training loss: 3.2779526710510254
Validation loss: 2.645308417658652

Epoch: 5| Step: 1
Training loss: 2.0793004035949707
Validation loss: 2.6443723683716147

Epoch: 5| Step: 2
Training loss: 2.9925596714019775
Validation loss: 2.644300801779634

Epoch: 5| Step: 3
Training loss: 3.120617628097534
Validation loss: 2.641012135372367

Epoch: 5| Step: 4
Training loss: 2.5607028007507324
Validation loss: 2.637577515776439

Epoch: 5| Step: 5
Training loss: 3.254960536956787
Validation loss: 2.6373327457776634

Epoch: 5| Step: 6
Training loss: 2.625939130783081
Validation loss: 2.639930853279688

Epoch: 5| Step: 7
Training loss: 3.5214972496032715
Validation loss: 2.6369630982798915

Epoch: 5| Step: 8
Training loss: 3.0545849800109863
Validation loss: 2.6373857452023413

Epoch: 5| Step: 9
Training loss: 2.173476457595825
Validation loss: 2.63740885385903

Epoch: 5| Step: 10
Training loss: 2.1344077587127686
Validation loss: 2.6380521584582586

Epoch: 37| Step: 0
Training loss: 2.993401288986206
Validation loss: 2.6378013574948875

Epoch: 5| Step: 1
Training loss: 2.9926202297210693
Validation loss: 2.635192632675171

Epoch: 5| Step: 2
Training loss: 2.104215621948242
Validation loss: 2.630323028051725

Epoch: 5| Step: 3
Training loss: 2.881661891937256
Validation loss: 2.631956943901636

Epoch: 5| Step: 4
Training loss: 2.3296756744384766
Validation loss: 2.633266713029595

Epoch: 5| Step: 5
Training loss: 2.737333297729492
Validation loss: 2.630458342131748

Epoch: 5| Step: 6
Training loss: 3.170196533203125
Validation loss: 2.6288558052432154

Epoch: 5| Step: 7
Training loss: 2.7711799144744873
Validation loss: 2.6304361743311726

Epoch: 5| Step: 8
Training loss: 2.7533607482910156
Validation loss: 2.6319989722262145

Epoch: 5| Step: 9
Training loss: 3.004270076751709
Validation loss: 2.645561025988671

Epoch: 5| Step: 10
Training loss: 3.162381649017334
Validation loss: 2.650724449465352

Epoch: 38| Step: 0
Training loss: 3.0852959156036377
Validation loss: 2.6886845481011177

Epoch: 5| Step: 1
Training loss: 2.9362921714782715
Validation loss: 2.6755121600243355

Epoch: 5| Step: 2
Training loss: 2.0304768085479736
Validation loss: 2.6678273626553115

Epoch: 5| Step: 3
Training loss: 3.464068651199341
Validation loss: 2.680553792625345

Epoch: 5| Step: 4
Training loss: 3.119487762451172
Validation loss: 2.6609914661735616

Epoch: 5| Step: 5
Training loss: 2.6786816120147705
Validation loss: 2.645299198806927

Epoch: 5| Step: 6
Training loss: 2.8785648345947266
Validation loss: 2.6292362418226016

Epoch: 5| Step: 7
Training loss: 2.5915236473083496
Validation loss: 2.6334224670164046

Epoch: 5| Step: 8
Training loss: 3.619649887084961
Validation loss: 2.760759304928523

Epoch: 5| Step: 9
Training loss: 1.7602916955947876
Validation loss: 2.7944951518889396

Epoch: 5| Step: 10
Training loss: 2.961638927459717
Validation loss: 2.7964439648453907

Epoch: 39| Step: 0
Training loss: 2.6500415802001953
Validation loss: 2.7224509639124714

Epoch: 5| Step: 1
Training loss: 2.6582913398742676
Validation loss: 2.6583861022867183

Epoch: 5| Step: 2
Training loss: 2.729689121246338
Validation loss: 2.6211279207660305

Epoch: 5| Step: 3
Training loss: 2.992332696914673
Validation loss: 2.6390114138203282

Epoch: 5| Step: 4
Training loss: 3.0801026821136475
Validation loss: 2.6664080260902323

Epoch: 5| Step: 5
Training loss: 3.2735912799835205
Validation loss: 2.686646553777879

Epoch: 5| Step: 6
Training loss: 2.377683162689209
Validation loss: 2.711938691395585

Epoch: 5| Step: 7
Training loss: 2.646843194961548
Validation loss: 2.6970741774446223

Epoch: 5| Step: 8
Training loss: 2.5790858268737793
Validation loss: 2.677638589694936

Epoch: 5| Step: 9
Training loss: 3.408435821533203
Validation loss: 2.644423577093309

Epoch: 5| Step: 10
Training loss: 2.5067713260650635
Validation loss: 2.6357608302947013

Epoch: 40| Step: 0
Training loss: 2.854292154312134
Validation loss: 2.6328618398276706

Epoch: 5| Step: 1
Training loss: 1.8014103174209595
Validation loss: 2.637607882099767

Epoch: 5| Step: 2
Training loss: 2.544497013092041
Validation loss: 2.6379439087324243

Epoch: 5| Step: 3
Training loss: 3.3274970054626465
Validation loss: 2.646668823816443

Epoch: 5| Step: 4
Training loss: 2.9638094902038574
Validation loss: 2.636437218676331

Epoch: 5| Step: 5
Training loss: 3.5163307189941406
Validation loss: 2.626001973305979

Epoch: 5| Step: 6
Training loss: 2.534590721130371
Validation loss: 2.620466511736634

Epoch: 5| Step: 7
Training loss: 2.7825465202331543
Validation loss: 2.6236613924785326

Epoch: 5| Step: 8
Training loss: 2.635382890701294
Validation loss: 2.6361943342352427

Epoch: 5| Step: 9
Training loss: 3.415433168411255
Validation loss: 2.645625760478358

Epoch: 5| Step: 10
Training loss: 2.390611410140991
Validation loss: 2.6427986288583405

Epoch: 41| Step: 0
Training loss: 2.6621663570404053
Validation loss: 2.6409374706206785

Epoch: 5| Step: 1
Training loss: 2.4689836502075195
Validation loss: 2.6408513387044272

Epoch: 5| Step: 2
Training loss: 3.2884299755096436
Validation loss: 2.6197615438891995

Epoch: 5| Step: 3
Training loss: 2.43422269821167
Validation loss: 2.6167219479878745

Epoch: 5| Step: 4
Training loss: 2.613186836242676
Validation loss: 2.6128519529937417

Epoch: 5| Step: 5
Training loss: 2.814343214035034
Validation loss: 2.609596501114548

Epoch: 5| Step: 6
Training loss: 2.7595343589782715
Validation loss: 2.6088172210160123

Epoch: 5| Step: 7
Training loss: 3.4363110065460205
Validation loss: 2.6127219635953187

Epoch: 5| Step: 8
Training loss: 2.3866324424743652
Validation loss: 2.6131379860703663

Epoch: 5| Step: 9
Training loss: 2.818682909011841
Validation loss: 2.611122190311391

Epoch: 5| Step: 10
Training loss: 3.02229642868042
Validation loss: 2.606794106063022

Epoch: 42| Step: 0
Training loss: 3.423168182373047
Validation loss: 2.607448649662797

Epoch: 5| Step: 1
Training loss: 2.2455203533172607
Validation loss: 2.6063170484317246

Epoch: 5| Step: 2
Training loss: 3.1602797508239746
Validation loss: 2.610098164568665

Epoch: 5| Step: 3
Training loss: 2.7524807453155518
Validation loss: 2.6087377097017024

Epoch: 5| Step: 4
Training loss: 1.8890568017959595
Validation loss: 2.608402964889362

Epoch: 5| Step: 5
Training loss: 3.0693843364715576
Validation loss: 2.607433698510611

Epoch: 5| Step: 6
Training loss: 2.8538315296173096
Validation loss: 2.60620629402899

Epoch: 5| Step: 7
Training loss: 2.699449300765991
Validation loss: 2.604349910572011

Epoch: 5| Step: 8
Training loss: 2.3601207733154297
Validation loss: 2.603589606541459

Epoch: 5| Step: 9
Training loss: 3.353501558303833
Validation loss: 2.5995265732529345

Epoch: 5| Step: 10
Training loss: 2.657449722290039
Validation loss: 2.5948632404368412

Epoch: 43| Step: 0
Training loss: 2.8696937561035156
Validation loss: 2.5973245815564225

Epoch: 5| Step: 1
Training loss: 2.897120714187622
Validation loss: 2.5976813967509935

Epoch: 5| Step: 2
Training loss: 2.1047608852386475
Validation loss: 2.596169730668427

Epoch: 5| Step: 3
Training loss: 2.333029270172119
Validation loss: 2.596951061679471

Epoch: 5| Step: 4
Training loss: 2.7239794731140137
Validation loss: 2.601181330219392

Epoch: 5| Step: 5
Training loss: 3.5284183025360107
Validation loss: 2.6073638393032934

Epoch: 5| Step: 6
Training loss: 2.9146764278411865
Validation loss: 2.608265256368986

Epoch: 5| Step: 7
Training loss: 2.4715640544891357
Validation loss: 2.6167096527673865

Epoch: 5| Step: 8
Training loss: 2.4794623851776123
Validation loss: 2.6347428778166413

Epoch: 5| Step: 9
Training loss: 3.050128221511841
Validation loss: 2.6511475270794285

Epoch: 5| Step: 10
Training loss: 3.270439386367798
Validation loss: 2.657333502205469

Epoch: 44| Step: 0
Training loss: 2.781968593597412
Validation loss: 2.646090748489544

Epoch: 5| Step: 1
Training loss: 2.272510051727295
Validation loss: 2.628626213278822

Epoch: 5| Step: 2
Training loss: 2.431522846221924
Validation loss: 2.5976338155807985

Epoch: 5| Step: 3
Training loss: 3.38433837890625
Validation loss: 2.5904905103868052

Epoch: 5| Step: 4
Training loss: 2.54606294631958
Validation loss: 2.597728829230032

Epoch: 5| Step: 5
Training loss: 3.4068450927734375
Validation loss: 2.6039782313890356

Epoch: 5| Step: 6
Training loss: 2.9699368476867676
Validation loss: 2.6100931295784573

Epoch: 5| Step: 7
Training loss: 2.6647534370422363
Validation loss: 2.5887458221886748

Epoch: 5| Step: 8
Training loss: 2.8698863983154297
Validation loss: 2.5899857500548005

Epoch: 5| Step: 9
Training loss: 2.3050668239593506
Validation loss: 2.6043902648392545

Epoch: 5| Step: 10
Training loss: 2.930525302886963
Validation loss: 2.6236267833299536

Epoch: 45| Step: 0
Training loss: 2.8056766986846924
Validation loss: 2.650894126584453

Epoch: 5| Step: 1
Training loss: 3.083090305328369
Validation loss: 2.647276727102136

Epoch: 5| Step: 2
Training loss: 3.0067620277404785
Validation loss: 2.6501342788819344

Epoch: 5| Step: 3
Training loss: 2.805802822113037
Validation loss: 2.633683527669599

Epoch: 5| Step: 4
Training loss: 2.4058241844177246
Validation loss: 2.610567139041039

Epoch: 5| Step: 5
Training loss: 2.4955029487609863
Validation loss: 2.585683681631601

Epoch: 5| Step: 6
Training loss: 2.953951597213745
Validation loss: 2.5822362156324488

Epoch: 5| Step: 7
Training loss: 2.548844814300537
Validation loss: 2.587750842494349

Epoch: 5| Step: 8
Training loss: 2.7637810707092285
Validation loss: 2.5891630470111804

Epoch: 5| Step: 9
Training loss: 2.0746963024139404
Validation loss: 2.5979826988712436

Epoch: 5| Step: 10
Training loss: 3.7315518856048584
Validation loss: 2.5839415570741058

Epoch: 46| Step: 0
Training loss: 2.863982677459717
Validation loss: 2.5832719956674883

Epoch: 5| Step: 1
Training loss: 2.6552765369415283
Validation loss: 2.582068347161816

Epoch: 5| Step: 2
Training loss: 2.573821783065796
Validation loss: 2.5754112505143687

Epoch: 5| Step: 3
Training loss: 1.725273847579956
Validation loss: 2.5739422716120237

Epoch: 5| Step: 4
Training loss: 2.381181478500366
Validation loss: 2.578605713382844

Epoch: 5| Step: 5
Training loss: 2.870612621307373
Validation loss: 2.5876217298610236

Epoch: 5| Step: 6
Training loss: 3.276547908782959
Validation loss: 2.5904091686330815

Epoch: 5| Step: 7
Training loss: 2.798579216003418
Validation loss: 2.5951153232205297

Epoch: 5| Step: 8
Training loss: 3.7331299781799316
Validation loss: 2.595407730789595

Epoch: 5| Step: 9
Training loss: 2.0824201107025146
Validation loss: 2.5931470060861237

Epoch: 5| Step: 10
Training loss: 3.4204909801483154
Validation loss: 2.586733756526824

Epoch: 47| Step: 0
Training loss: 2.7239081859588623
Validation loss: 2.581262775646743

Epoch: 5| Step: 1
Training loss: 2.482070207595825
Validation loss: 2.5726392679317023

Epoch: 5| Step: 2
Training loss: 2.9086034297943115
Validation loss: 2.5716162368815434

Epoch: 5| Step: 3
Training loss: 2.158968448638916
Validation loss: 2.583668262727799

Epoch: 5| Step: 4
Training loss: 2.3781399726867676
Validation loss: 2.5742177937620427

Epoch: 5| Step: 5
Training loss: 2.3137471675872803
Validation loss: 2.5691763188249324

Epoch: 5| Step: 6
Training loss: 2.8497791290283203
Validation loss: 2.5638000760027158

Epoch: 5| Step: 7
Training loss: 2.9522926807403564
Validation loss: 2.559719426657564

Epoch: 5| Step: 8
Training loss: 2.4880988597869873
Validation loss: 2.5639462599190335

Epoch: 5| Step: 9
Training loss: 3.9160518646240234
Validation loss: 2.571947641270135

Epoch: 5| Step: 10
Training loss: 3.0687596797943115
Validation loss: 2.5807965109425206

Epoch: 48| Step: 0
Training loss: 2.8018276691436768
Validation loss: 2.5971008193108345

Epoch: 5| Step: 1
Training loss: 3.4987144470214844
Validation loss: 2.6084216910023845

Epoch: 5| Step: 2
Training loss: 2.7531561851501465
Validation loss: 2.5949833623824583

Epoch: 5| Step: 3
Training loss: 3.625164031982422
Validation loss: 2.57961291907936

Epoch: 5| Step: 4
Training loss: 2.7679250240325928
Validation loss: 2.572625670381772

Epoch: 5| Step: 5
Training loss: 2.267826795578003
Validation loss: 2.5649027824401855

Epoch: 5| Step: 6
Training loss: 2.9144082069396973
Validation loss: 2.56162368353977

Epoch: 5| Step: 7
Training loss: 2.2900164127349854
Validation loss: 2.5659554312306065

Epoch: 5| Step: 8
Training loss: 2.8665621280670166
Validation loss: 2.566305898850964

Epoch: 5| Step: 9
Training loss: 2.107543468475342
Validation loss: 2.5751803895478607

Epoch: 5| Step: 10
Training loss: 2.3324527740478516
Validation loss: 2.5864181159645

Epoch: 49| Step: 0
Training loss: 2.363537311553955
Validation loss: 2.5649516838853077

Epoch: 5| Step: 1
Training loss: 2.8220150470733643
Validation loss: 2.55813608631011

Epoch: 5| Step: 2
Training loss: 2.840555191040039
Validation loss: 2.556761541674214

Epoch: 5| Step: 3
Training loss: 2.8709325790405273
Validation loss: 2.5609235558458554

Epoch: 5| Step: 4
Training loss: 2.420738697052002
Validation loss: 2.5681876187683432

Epoch: 5| Step: 5
Training loss: 3.370072841644287
Validation loss: 2.5688896640654533

Epoch: 5| Step: 6
Training loss: 2.657421588897705
Validation loss: 2.5856268611005557

Epoch: 5| Step: 7
Training loss: 2.4549591541290283
Validation loss: 2.580018061463551

Epoch: 5| Step: 8
Training loss: 2.7023332118988037
Validation loss: 2.59710217291309

Epoch: 5| Step: 9
Training loss: 2.81013822555542
Validation loss: 2.596528301956833

Epoch: 5| Step: 10
Training loss: 2.8834218978881836
Validation loss: 2.5944524682978147

Epoch: 50| Step: 0
Training loss: 2.6864113807678223
Validation loss: 2.574248421576715

Epoch: 5| Step: 1
Training loss: 2.5698373317718506
Validation loss: 2.553435905005342

Epoch: 5| Step: 2
Training loss: 2.7138092517852783
Validation loss: 2.5464883542829946

Epoch: 5| Step: 3
Training loss: 2.5575008392333984
Validation loss: 2.5471430106829573

Epoch: 5| Step: 4
Training loss: 3.162759304046631
Validation loss: 2.548062978252288

Epoch: 5| Step: 5
Training loss: 2.6968350410461426
Validation loss: 2.5480607504485757

Epoch: 5| Step: 6
Training loss: 2.072995901107788
Validation loss: 2.549528221930227

Epoch: 5| Step: 7
Training loss: 2.6065800189971924
Validation loss: 2.5536546194425194

Epoch: 5| Step: 8
Training loss: 2.7450969219207764
Validation loss: 2.5477844425427016

Epoch: 5| Step: 9
Training loss: 3.2309699058532715
Validation loss: 2.5395576671887468

Epoch: 5| Step: 10
Training loss: 2.9847264289855957
Validation loss: 2.5398512078869726

Epoch: 51| Step: 0
Training loss: 2.4910173416137695
Validation loss: 2.5396405855814614

Epoch: 5| Step: 1
Training loss: 3.10209584236145
Validation loss: 2.539227326711019

Epoch: 5| Step: 2
Training loss: 2.039398193359375
Validation loss: 2.5424326594157884

Epoch: 5| Step: 3
Training loss: 3.085958242416382
Validation loss: 2.5487682178456295

Epoch: 5| Step: 4
Training loss: 2.8889832496643066
Validation loss: 2.5484526208651963

Epoch: 5| Step: 5
Training loss: 2.5829825401306152
Validation loss: 2.550453996145597

Epoch: 5| Step: 6
Training loss: 2.2519805431365967
Validation loss: 2.5423843527352936

Epoch: 5| Step: 7
Training loss: 2.468531370162964
Validation loss: 2.5408083136363695

Epoch: 5| Step: 8
Training loss: 3.03892183303833
Validation loss: 2.53609832127889

Epoch: 5| Step: 9
Training loss: 2.4204142093658447
Validation loss: 2.5384893135357927

Epoch: 5| Step: 10
Training loss: 3.7143607139587402
Validation loss: 2.5358328011728104

Epoch: 52| Step: 0
Training loss: 3.1169021129608154
Validation loss: 2.5352593955173286

Epoch: 5| Step: 1
Training loss: 2.8670647144317627
Validation loss: 2.53224955579286

Epoch: 5| Step: 2
Training loss: 3.1232874393463135
Validation loss: 2.533541202545166

Epoch: 5| Step: 3
Training loss: 2.7846312522888184
Validation loss: 2.527581681487381

Epoch: 5| Step: 4
Training loss: 2.0844929218292236
Validation loss: 2.5307641080630723

Epoch: 5| Step: 5
Training loss: 3.2904295921325684
Validation loss: 2.532138714226343

Epoch: 5| Step: 6
Training loss: 3.508578062057495
Validation loss: 2.528972516777695

Epoch: 5| Step: 7
Training loss: 2.164881467819214
Validation loss: 2.529564793391894

Epoch: 5| Step: 8
Training loss: 2.5325751304626465
Validation loss: 2.5312855115500827

Epoch: 5| Step: 9
Training loss: 2.3641390800476074
Validation loss: 2.5282547986635597

Epoch: 5| Step: 10
Training loss: 1.9480029344558716
Validation loss: 2.536381588187269

Epoch: 53| Step: 0
Training loss: 2.561156749725342
Validation loss: 2.5365458688428326

Epoch: 5| Step: 1
Training loss: 2.8771579265594482
Validation loss: 2.533335378093104

Epoch: 5| Step: 2
Training loss: 3.1598634719848633
Validation loss: 2.52895938709218

Epoch: 5| Step: 3
Training loss: 3.1253631114959717
Validation loss: 2.530910699598251

Epoch: 5| Step: 4
Training loss: 2.3385326862335205
Validation loss: 2.536690386392737

Epoch: 5| Step: 5
Training loss: 2.5402846336364746
Validation loss: 2.5270702838897705

Epoch: 5| Step: 6
Training loss: 2.5036561489105225
Validation loss: 2.520440319532989

Epoch: 5| Step: 7
Training loss: 2.511812686920166
Validation loss: 2.519643319550381

Epoch: 5| Step: 8
Training loss: 3.0582668781280518
Validation loss: 2.5181846977562032

Epoch: 5| Step: 9
Training loss: 2.1029839515686035
Validation loss: 2.5181954035194973

Epoch: 5| Step: 10
Training loss: 3.134514331817627
Validation loss: 2.51873698542195

Epoch: 54| Step: 0
Training loss: 2.699744939804077
Validation loss: 2.5205477194119523

Epoch: 5| Step: 1
Training loss: 2.5439400672912598
Validation loss: 2.518597613098801

Epoch: 5| Step: 2
Training loss: 3.096855640411377
Validation loss: 2.5241911795831498

Epoch: 5| Step: 3
Training loss: 2.428462266921997
Validation loss: 2.5320203791382494

Epoch: 5| Step: 4
Training loss: 2.383208751678467
Validation loss: 2.547679506322389

Epoch: 5| Step: 5
Training loss: 2.480098247528076
Validation loss: 2.547634234992407

Epoch: 5| Step: 6
Training loss: 3.2103514671325684
Validation loss: 2.5455026113858787

Epoch: 5| Step: 7
Training loss: 1.995928168296814
Validation loss: 2.5396250653010544

Epoch: 5| Step: 8
Training loss: 2.7490453720092773
Validation loss: 2.5256472479912544

Epoch: 5| Step: 9
Training loss: 3.2098708152770996
Validation loss: 2.523373588438957

Epoch: 5| Step: 10
Training loss: 3.129378318786621
Validation loss: 2.5187728122998307

Epoch: 55| Step: 0
Training loss: 2.9516172409057617
Validation loss: 2.516078600319483

Epoch: 5| Step: 1
Training loss: 2.600059986114502
Validation loss: 2.516800598431659

Epoch: 5| Step: 2
Training loss: 2.561323881149292
Validation loss: 2.5119480522730018

Epoch: 5| Step: 3
Training loss: 2.69343638420105
Validation loss: 2.510897546686152

Epoch: 5| Step: 4
Training loss: 2.716634750366211
Validation loss: 2.511296372259817

Epoch: 5| Step: 5
Training loss: 2.9053072929382324
Validation loss: 2.5119827639672065

Epoch: 5| Step: 6
Training loss: 2.2988550662994385
Validation loss: 2.5152702075178905

Epoch: 5| Step: 7
Training loss: 2.3668999671936035
Validation loss: 2.517311167973344

Epoch: 5| Step: 8
Training loss: 3.0817675590515137
Validation loss: 2.531426880949287

Epoch: 5| Step: 9
Training loss: 2.8933701515197754
Validation loss: 2.5273214155627834

Epoch: 5| Step: 10
Training loss: 2.741359233856201
Validation loss: 2.524695896333264

Epoch: 56| Step: 0
Training loss: 2.3796210289001465
Validation loss: 2.52816859111991

Epoch: 5| Step: 1
Training loss: 2.5856146812438965
Validation loss: 2.517546635802074

Epoch: 5| Step: 2
Training loss: 2.8192930221557617
Validation loss: 2.5225230596398793

Epoch: 5| Step: 3
Training loss: 2.328917980194092
Validation loss: 2.519314166038267

Epoch: 5| Step: 4
Training loss: 2.820061445236206
Validation loss: 2.518454610660512

Epoch: 5| Step: 5
Training loss: 3.2295289039611816
Validation loss: 2.5154231697000484

Epoch: 5| Step: 6
Training loss: 3.215740919113159
Validation loss: 2.519412940548312

Epoch: 5| Step: 7
Training loss: 2.104543685913086
Validation loss: 2.516312233863338

Epoch: 5| Step: 8
Training loss: 2.9553258419036865
Validation loss: 2.516367091927477

Epoch: 5| Step: 9
Training loss: 2.583890438079834
Validation loss: 2.5083267970751693

Epoch: 5| Step: 10
Training loss: 2.7042300701141357
Validation loss: 2.5082376900539605

Epoch: 57| Step: 0
Training loss: 2.6919853687286377
Validation loss: 2.5102459243548814

Epoch: 5| Step: 1
Training loss: 2.9349141120910645
Validation loss: 2.5053223204869095

Epoch: 5| Step: 2
Training loss: 2.828619956970215
Validation loss: 2.5040348499051985

Epoch: 5| Step: 3
Training loss: 3.0453896522521973
Validation loss: 2.501591233796971

Epoch: 5| Step: 4
Training loss: 2.6042141914367676
Validation loss: 2.5017025752734114

Epoch: 5| Step: 5
Training loss: 2.7108452320098877
Validation loss: 2.508260550037507

Epoch: 5| Step: 6
Training loss: 2.2552332878112793
Validation loss: 2.5070318329718804

Epoch: 5| Step: 7
Training loss: 2.893662929534912
Validation loss: 2.5111781371537076

Epoch: 5| Step: 8
Training loss: 2.485689878463745
Validation loss: 2.5176381372636363

Epoch: 5| Step: 9
Training loss: 2.781978130340576
Validation loss: 2.5114424972124

Epoch: 5| Step: 10
Training loss: 2.3699612617492676
Validation loss: 2.505475785142632

Epoch: 58| Step: 0
Training loss: 2.43570613861084
Validation loss: 2.5018373125342914

Epoch: 5| Step: 1
Training loss: 3.0608115196228027
Validation loss: 2.508119588257164

Epoch: 5| Step: 2
Training loss: 2.1858367919921875
Validation loss: 2.502680609303136

Epoch: 5| Step: 3
Training loss: 3.0004029273986816
Validation loss: 2.5053884419061805

Epoch: 5| Step: 4
Training loss: 2.566321611404419
Validation loss: 2.5034636887170936

Epoch: 5| Step: 5
Training loss: 2.5869698524475098
Validation loss: 2.5050061518146145

Epoch: 5| Step: 6
Training loss: 2.6739919185638428
Validation loss: 2.5019708525749946

Epoch: 5| Step: 7
Training loss: 2.574375629425049
Validation loss: 2.503887204713719

Epoch: 5| Step: 8
Training loss: 2.6843128204345703
Validation loss: 2.504428876343594

Epoch: 5| Step: 9
Training loss: 2.7841527462005615
Validation loss: 2.496802960672686

Epoch: 5| Step: 10
Training loss: 3.214820146560669
Validation loss: 2.5160097896411853

Epoch: 59| Step: 0
Training loss: 2.2675108909606934
Validation loss: 2.5260225393438853

Epoch: 5| Step: 1
Training loss: 2.8148646354675293
Validation loss: 2.517458441436932

Epoch: 5| Step: 2
Training loss: 2.825533151626587
Validation loss: 2.5079234620576263

Epoch: 5| Step: 3
Training loss: 2.7615914344787598
Validation loss: 2.5041749554295696

Epoch: 5| Step: 4
Training loss: 2.061613082885742
Validation loss: 2.4961884790851223

Epoch: 5| Step: 5
Training loss: 2.3660597801208496
Validation loss: 2.491091228300525

Epoch: 5| Step: 6
Training loss: 2.454760789871216
Validation loss: 2.4983423140741166

Epoch: 5| Step: 7
Training loss: 3.0136265754699707
Validation loss: 2.494213516994189

Epoch: 5| Step: 8
Training loss: 3.7010741233825684
Validation loss: 2.4950573649457706

Epoch: 5| Step: 9
Training loss: 2.7545111179351807
Validation loss: 2.4951389169180267

Epoch: 5| Step: 10
Training loss: 2.6068172454833984
Validation loss: 2.4964167635927916

Epoch: 60| Step: 0
Training loss: 2.420926094055176
Validation loss: 2.4917212993867937

Epoch: 5| Step: 1
Training loss: 2.1437830924987793
Validation loss: 2.49326797967316

Epoch: 5| Step: 2
Training loss: 1.9080976247787476
Validation loss: 2.4860254231319634

Epoch: 5| Step: 3
Training loss: 3.054018497467041
Validation loss: 2.4877886182518414

Epoch: 5| Step: 4
Training loss: 2.7862884998321533
Validation loss: 2.4843485227195163

Epoch: 5| Step: 5
Training loss: 2.8478450775146484
Validation loss: 2.48598712746815

Epoch: 5| Step: 6
Training loss: 2.4402427673339844
Validation loss: 2.488042926275602

Epoch: 5| Step: 7
Training loss: 2.50771164894104
Validation loss: 2.488047694647184

Epoch: 5| Step: 8
Training loss: 3.017024517059326
Validation loss: 2.4932870839231756

Epoch: 5| Step: 9
Training loss: 2.93693208694458
Validation loss: 2.4998103034111763

Epoch: 5| Step: 10
Training loss: 3.6685848236083984
Validation loss: 2.5080749091281684

Epoch: 61| Step: 0
Training loss: 3.3319594860076904
Validation loss: 2.4997391213652906

Epoch: 5| Step: 1
Training loss: 2.690387725830078
Validation loss: 2.4945946739565943

Epoch: 5| Step: 2
Training loss: 2.3984487056732178
Validation loss: 2.487984682924004

Epoch: 5| Step: 3
Training loss: 2.5775949954986572
Validation loss: 2.4871197926100863

Epoch: 5| Step: 4
Training loss: 2.329749584197998
Validation loss: 2.482450895411994

Epoch: 5| Step: 5
Training loss: 2.959362745285034
Validation loss: 2.488080060610207

Epoch: 5| Step: 6
Training loss: 2.825181484222412
Validation loss: 2.4900600628186296

Epoch: 5| Step: 7
Training loss: 3.1377320289611816
Validation loss: 2.491480802976957

Epoch: 5| Step: 8
Training loss: 2.432346820831299
Validation loss: 2.492231748437369

Epoch: 5| Step: 9
Training loss: 2.3626492023468018
Validation loss: 2.486285494219872

Epoch: 5| Step: 10
Training loss: 2.4475433826446533
Validation loss: 2.4828660859856555

Epoch: 62| Step: 0
Training loss: 2.158566951751709
Validation loss: 2.4809304257874847

Epoch: 5| Step: 1
Training loss: 2.298706531524658
Validation loss: 2.484633284230386

Epoch: 5| Step: 2
Training loss: 2.957437515258789
Validation loss: 2.4817533057223082

Epoch: 5| Step: 3
Training loss: 2.984823703765869
Validation loss: 2.480215521268947

Epoch: 5| Step: 4
Training loss: 3.0594260692596436
Validation loss: 2.4832737368922078

Epoch: 5| Step: 5
Training loss: 3.2436301708221436
Validation loss: 2.482128635529549

Epoch: 5| Step: 6
Training loss: 2.5470969676971436
Validation loss: 2.4795979825399255

Epoch: 5| Step: 7
Training loss: 2.5900392532348633
Validation loss: 2.481338483031078

Epoch: 5| Step: 8
Training loss: 2.6756856441497803
Validation loss: 2.48371398064398

Epoch: 5| Step: 9
Training loss: 2.6246635913848877
Validation loss: 2.487434228261312

Epoch: 5| Step: 10
Training loss: 2.397237777709961
Validation loss: 2.4846048483284573

Epoch: 63| Step: 0
Training loss: 3.3618454933166504
Validation loss: 2.490885829412809

Epoch: 5| Step: 1
Training loss: 2.612751007080078
Validation loss: 2.4873893004591747

Epoch: 5| Step: 2
Training loss: 2.8577780723571777
Validation loss: 2.4827083823501424

Epoch: 5| Step: 3
Training loss: 2.9545371532440186
Validation loss: 2.488577142838509

Epoch: 5| Step: 4
Training loss: 2.6518235206604004
Validation loss: 2.4962606096780426

Epoch: 5| Step: 5
Training loss: 2.2535367012023926
Validation loss: 2.501790843984132

Epoch: 5| Step: 6
Training loss: 2.58858585357666
Validation loss: 2.5238973991845244

Epoch: 5| Step: 7
Training loss: 2.7746970653533936
Validation loss: 2.515041815337314

Epoch: 5| Step: 8
Training loss: 2.685910940170288
Validation loss: 2.4974703840030137

Epoch: 5| Step: 9
Training loss: 2.7046926021575928
Validation loss: 2.498046898072766

Epoch: 5| Step: 10
Training loss: 2.0909504890441895
Validation loss: 2.5113538131918958

Epoch: 64| Step: 0
Training loss: 2.5689914226531982
Validation loss: 2.517490185717101

Epoch: 5| Step: 1
Training loss: 2.7960591316223145
Validation loss: 2.519920805449127

Epoch: 5| Step: 2
Training loss: 2.598238229751587
Validation loss: 2.5380598037473616

Epoch: 5| Step: 3
Training loss: 2.3488173484802246
Validation loss: 2.5398410315154702

Epoch: 5| Step: 4
Training loss: 3.054499387741089
Validation loss: 2.5216330841023433

Epoch: 5| Step: 5
Training loss: 2.892702341079712
Validation loss: 2.502992481313726

Epoch: 5| Step: 6
Training loss: 1.5941519737243652
Validation loss: 2.4856051296316166

Epoch: 5| Step: 7
Training loss: 2.5314953327178955
Validation loss: 2.4761190311883086

Epoch: 5| Step: 8
Training loss: 2.9980356693267822
Validation loss: 2.4774420287019465

Epoch: 5| Step: 9
Training loss: 3.3989920616149902
Validation loss: 2.4803632331150833

Epoch: 5| Step: 10
Training loss: 2.8404054641723633
Validation loss: 2.4999011639625794

Epoch: 65| Step: 0
Training loss: 2.0802502632141113
Validation loss: 2.502957138963925

Epoch: 5| Step: 1
Training loss: 2.3741183280944824
Validation loss: 2.533963587976271

Epoch: 5| Step: 2
Training loss: 3.3144843578338623
Validation loss: 2.553207201342429

Epoch: 5| Step: 3
Training loss: 3.462864637374878
Validation loss: 2.5078822464071293

Epoch: 5| Step: 4
Training loss: 2.90144944190979
Validation loss: 2.488476586598222

Epoch: 5| Step: 5
Training loss: 2.9230895042419434
Validation loss: 2.47882414889592

Epoch: 5| Step: 6
Training loss: 2.368305206298828
Validation loss: 2.4849173484310025

Epoch: 5| Step: 7
Training loss: 2.9318957328796387
Validation loss: 2.5047996967069563

Epoch: 5| Step: 8
Training loss: 2.3981316089630127
Validation loss: 2.5479626860669864

Epoch: 5| Step: 9
Training loss: 3.0731008052825928
Validation loss: 2.5749629569310013

Epoch: 5| Step: 10
Training loss: 2.0495107173919678
Validation loss: 2.5325812985820155

Epoch: 66| Step: 0
Training loss: 3.071971893310547
Validation loss: 2.5128116248756327

Epoch: 5| Step: 1
Training loss: 2.949155330657959
Validation loss: 2.4842612692104873

Epoch: 5| Step: 2
Training loss: 3.2564144134521484
Validation loss: 2.478263121779247

Epoch: 5| Step: 3
Training loss: 2.4226858615875244
Validation loss: 2.4787270304977254

Epoch: 5| Step: 4
Training loss: 3.372147798538208
Validation loss: 2.491563544478468

Epoch: 5| Step: 5
Training loss: 3.060955286026001
Validation loss: 2.503647470986971

Epoch: 5| Step: 6
Training loss: 2.295363426208496
Validation loss: 2.5108938576072775

Epoch: 5| Step: 7
Training loss: 2.509671688079834
Validation loss: 2.517390745942311

Epoch: 5| Step: 8
Training loss: 2.408940553665161
Validation loss: 2.5259469785997943

Epoch: 5| Step: 9
Training loss: 2.2404537200927734
Validation loss: 2.5368364626361477

Epoch: 5| Step: 10
Training loss: 2.1984245777130127
Validation loss: 2.5336080725475023

Epoch: 67| Step: 0
Training loss: 2.637897491455078
Validation loss: 2.5566336800975185

Epoch: 5| Step: 1
Training loss: 2.755479335784912
Validation loss: 2.527809181521016

Epoch: 5| Step: 2
Training loss: 3.2567641735076904
Validation loss: 2.499655915844825

Epoch: 5| Step: 3
Training loss: 3.1044492721557617
Validation loss: 2.4797262889082714

Epoch: 5| Step: 4
Training loss: 2.7285044193267822
Validation loss: 2.4708634397035003

Epoch: 5| Step: 5
Training loss: 2.756422281265259
Validation loss: 2.4748988818096858

Epoch: 5| Step: 6
Training loss: 2.8143486976623535
Validation loss: 2.4948231353554675

Epoch: 5| Step: 7
Training loss: 1.6579887866973877
Validation loss: 2.530829025853065

Epoch: 5| Step: 8
Training loss: 2.9000096321105957
Validation loss: 2.5656640555268977

Epoch: 5| Step: 9
Training loss: 2.5595431327819824
Validation loss: 2.5593447403241227

Epoch: 5| Step: 10
Training loss: 2.7302498817443848
Validation loss: 2.5445305147478656

Epoch: 68| Step: 0
Training loss: 2.0884430408477783
Validation loss: 2.5269279813253753

Epoch: 5| Step: 1
Training loss: 2.4985239505767822
Validation loss: 2.5172527451669016

Epoch: 5| Step: 2
Training loss: 3.392271041870117
Validation loss: 2.4916462308617047

Epoch: 5| Step: 3
Training loss: 2.6717429161071777
Validation loss: 2.482099792008759

Epoch: 5| Step: 4
Training loss: 2.710850238800049
Validation loss: 2.471435193092592

Epoch: 5| Step: 5
Training loss: 2.258103847503662
Validation loss: 2.4684903878037647

Epoch: 5| Step: 6
Training loss: 2.414715528488159
Validation loss: 2.4688311981898483

Epoch: 5| Step: 7
Training loss: 2.522732973098755
Validation loss: 2.4732136572560957

Epoch: 5| Step: 8
Training loss: 2.689526319503784
Validation loss: 2.4804408832262923

Epoch: 5| Step: 9
Training loss: 3.3894314765930176
Validation loss: 2.4739385343367055

Epoch: 5| Step: 10
Training loss: 3.019859552383423
Validation loss: 2.4704935909599386

Epoch: 69| Step: 0
Training loss: 2.7147274017333984
Validation loss: 2.468915488130303

Epoch: 5| Step: 1
Training loss: 2.468250274658203
Validation loss: 2.4675682385762534

Epoch: 5| Step: 2
Training loss: 2.9081523418426514
Validation loss: 2.4695801529833066

Epoch: 5| Step: 3
Training loss: 2.104199171066284
Validation loss: 2.4709977834455428

Epoch: 5| Step: 4
Training loss: 2.1891045570373535
Validation loss: 2.4724472594517533

Epoch: 5| Step: 5
Training loss: 3.027132034301758
Validation loss: 2.476545831208588

Epoch: 5| Step: 6
Training loss: 2.379772901535034
Validation loss: 2.4820356856110277

Epoch: 5| Step: 7
Training loss: 3.2317912578582764
Validation loss: 2.4835848898015995

Epoch: 5| Step: 8
Training loss: 2.8870816230773926
Validation loss: 2.4872924102249967

Epoch: 5| Step: 9
Training loss: 3.0232787132263184
Validation loss: 2.498902120897847

Epoch: 5| Step: 10
Training loss: 2.5324625968933105
Validation loss: 2.498735379147273

Epoch: 70| Step: 0
Training loss: 3.272573471069336
Validation loss: 2.486599793998144

Epoch: 5| Step: 1
Training loss: 2.61614990234375
Validation loss: 2.477571190044444

Epoch: 5| Step: 2
Training loss: 2.218029499053955
Validation loss: 2.473416486094075

Epoch: 5| Step: 3
Training loss: 1.9115562438964844
Validation loss: 2.4713042602744153

Epoch: 5| Step: 4
Training loss: 2.942770004272461
Validation loss: 2.4713517055716565

Epoch: 5| Step: 5
Training loss: 2.6244750022888184
Validation loss: 2.4628123673059608

Epoch: 5| Step: 6
Training loss: 2.397846221923828
Validation loss: 2.46671534610051

Epoch: 5| Step: 7
Training loss: 2.82869553565979
Validation loss: 2.4631361756273495

Epoch: 5| Step: 8
Training loss: 3.291226863861084
Validation loss: 2.4630299075957267

Epoch: 5| Step: 9
Training loss: 2.9497389793395996
Validation loss: 2.4656778638080885

Epoch: 5| Step: 10
Training loss: 2.3064098358154297
Validation loss: 2.4615215973187516

Epoch: 71| Step: 0
Training loss: 3.530319929122925
Validation loss: 2.4625570799714778

Epoch: 5| Step: 1
Training loss: 2.0524654388427734
Validation loss: 2.462648512214743

Epoch: 5| Step: 2
Training loss: 2.58746075630188
Validation loss: 2.45699659726953

Epoch: 5| Step: 3
Training loss: 2.63035249710083
Validation loss: 2.458832420328612

Epoch: 5| Step: 4
Training loss: 3.11769437789917
Validation loss: 2.463784566489599

Epoch: 5| Step: 5
Training loss: 2.805666208267212
Validation loss: 2.4602875581351658

Epoch: 5| Step: 6
Training loss: 2.755336284637451
Validation loss: 2.4642616959028345

Epoch: 5| Step: 7
Training loss: 3.0806286334991455
Validation loss: 2.4652334836221512

Epoch: 5| Step: 8
Training loss: 2.4775514602661133
Validation loss: 2.465668204010174

Epoch: 5| Step: 9
Training loss: 2.2019054889678955
Validation loss: 2.4685597547920803

Epoch: 5| Step: 10
Training loss: 2.059274911880493
Validation loss: 2.476107397387105

Epoch: 72| Step: 0
Training loss: 2.9561915397644043
Validation loss: 2.488390373927291

Epoch: 5| Step: 1
Training loss: 3.0846736431121826
Validation loss: 2.4784493343804472

Epoch: 5| Step: 2
Training loss: 2.550226926803589
Validation loss: 2.4792902802908294

Epoch: 5| Step: 3
Training loss: 2.6756370067596436
Validation loss: 2.46831742922465

Epoch: 5| Step: 4
Training loss: 3.2162272930145264
Validation loss: 2.4783322939308743

Epoch: 5| Step: 5
Training loss: 2.425867795944214
Validation loss: 2.483508474083357

Epoch: 5| Step: 6
Training loss: 3.4776344299316406
Validation loss: 2.490532062386954

Epoch: 5| Step: 7
Training loss: 2.180694818496704
Validation loss: 2.4919094013911423

Epoch: 5| Step: 8
Training loss: 2.3989193439483643
Validation loss: 2.4879264139359996

Epoch: 5| Step: 9
Training loss: 2.6301169395446777
Validation loss: 2.4686064386880524

Epoch: 5| Step: 10
Training loss: 1.8256820440292358
Validation loss: 2.4626917595504434

Epoch: 73| Step: 0
Training loss: 2.5533628463745117
Validation loss: 2.4553194610021447

Epoch: 5| Step: 1
Training loss: 2.6859936714172363
Validation loss: 2.453024261741228

Epoch: 5| Step: 2
Training loss: 1.9207022190093994
Validation loss: 2.4534217721672467

Epoch: 5| Step: 3
Training loss: 2.5079829692840576
Validation loss: 2.455346240792223

Epoch: 5| Step: 4
Training loss: 3.296825408935547
Validation loss: 2.4689288421343734

Epoch: 5| Step: 5
Training loss: 2.7756881713867188
Validation loss: 2.4836754696343535

Epoch: 5| Step: 6
Training loss: 2.9412834644317627
Validation loss: 2.5021367534514396

Epoch: 5| Step: 7
Training loss: 2.527991771697998
Validation loss: 2.4621907164973598

Epoch: 5| Step: 8
Training loss: 2.76698637008667
Validation loss: 2.461553478753695

Epoch: 5| Step: 9
Training loss: 2.948556661605835
Validation loss: 2.451754403370683

Epoch: 5| Step: 10
Training loss: 2.450002908706665
Validation loss: 2.4573361463444208

Epoch: 74| Step: 0
Training loss: 2.552980422973633
Validation loss: 2.458245826023881

Epoch: 5| Step: 1
Training loss: 2.746581554412842
Validation loss: 2.4605102923608597

Epoch: 5| Step: 2
Training loss: 2.2883827686309814
Validation loss: 2.46225877218349

Epoch: 5| Step: 3
Training loss: 2.8655881881713867
Validation loss: 2.4500488799105407

Epoch: 5| Step: 4
Training loss: 3.2991600036621094
Validation loss: 2.4558765503668014

Epoch: 5| Step: 5
Training loss: 2.4657979011535645
Validation loss: 2.4593618300653275

Epoch: 5| Step: 6
Training loss: 2.750356912612915
Validation loss: 2.468798824535903

Epoch: 5| Step: 7
Training loss: 2.6352391242980957
Validation loss: 2.473155662577639

Epoch: 5| Step: 8
Training loss: 2.5717225074768066
Validation loss: 2.4588886153313423

Epoch: 5| Step: 9
Training loss: 2.9182426929473877
Validation loss: 2.4537797563819477

Epoch: 5| Step: 10
Training loss: 2.148777723312378
Validation loss: 2.446401278177897

Epoch: 75| Step: 0
Training loss: 2.0777103900909424
Validation loss: 2.443305133491434

Epoch: 5| Step: 1
Training loss: 2.639772653579712
Validation loss: 2.4457952924953994

Epoch: 5| Step: 2
Training loss: 2.5995609760284424
Validation loss: 2.4445992772297194

Epoch: 5| Step: 3
Training loss: 3.3495452404022217
Validation loss: 2.445559540102559

Epoch: 5| Step: 4
Training loss: 2.1006929874420166
Validation loss: 2.4454624550316924

Epoch: 5| Step: 5
Training loss: 2.5499353408813477
Validation loss: 2.4430454828405894

Epoch: 5| Step: 6
Training loss: 2.9076812267303467
Validation loss: 2.4418609616576985

Epoch: 5| Step: 7
Training loss: 2.7762038707733154
Validation loss: 2.442089242319907

Epoch: 5| Step: 8
Training loss: 2.255728006362915
Validation loss: 2.4431585265744116

Epoch: 5| Step: 9
Training loss: 2.9076876640319824
Validation loss: 2.4431794535729194

Epoch: 5| Step: 10
Training loss: 3.2927982807159424
Validation loss: 2.445007267818656

Epoch: 76| Step: 0
Training loss: 2.8052568435668945
Validation loss: 2.4445628222598823

Epoch: 5| Step: 1
Training loss: 2.708965301513672
Validation loss: 2.444016871913787

Epoch: 5| Step: 2
Training loss: 2.711463451385498
Validation loss: 2.4469189695132676

Epoch: 5| Step: 3
Training loss: 3.1043941974639893
Validation loss: 2.449409379754015

Epoch: 5| Step: 4
Training loss: 2.3191072940826416
Validation loss: 2.450543426698254

Epoch: 5| Step: 5
Training loss: 2.0932822227478027
Validation loss: 2.4561515495341313

Epoch: 5| Step: 6
Training loss: 3.0384387969970703
Validation loss: 2.4575779130381923

Epoch: 5| Step: 7
Training loss: 2.751511812210083
Validation loss: 2.4530284430391047

Epoch: 5| Step: 8
Training loss: 3.1442508697509766
Validation loss: 2.4547522567933604

Epoch: 5| Step: 9
Training loss: 2.219194173812866
Validation loss: 2.442318683029503

Epoch: 5| Step: 10
Training loss: 2.283926248550415
Validation loss: 2.4427621877321632

Epoch: 77| Step: 0
Training loss: 2.198244571685791
Validation loss: 2.4390248201226674

Epoch: 5| Step: 1
Training loss: 2.6655235290527344
Validation loss: 2.4382803286275556

Epoch: 5| Step: 2
Training loss: 2.5937421321868896
Validation loss: 2.438177736856604

Epoch: 5| Step: 3
Training loss: 2.650388240814209
Validation loss: 2.4373671982877996

Epoch: 5| Step: 4
Training loss: 3.1273856163024902
Validation loss: 2.436953648444145

Epoch: 5| Step: 5
Training loss: 2.461021900177002
Validation loss: 2.4340656624045423

Epoch: 5| Step: 6
Training loss: 2.6371524333953857
Validation loss: 2.432985234004195

Epoch: 5| Step: 7
Training loss: 2.781379222869873
Validation loss: 2.4364365711007068

Epoch: 5| Step: 8
Training loss: 2.6536428928375244
Validation loss: 2.434180577596029

Epoch: 5| Step: 9
Training loss: 2.4934117794036865
Validation loss: 2.438183871648645

Epoch: 5| Step: 10
Training loss: 3.032060146331787
Validation loss: 2.4432310212043022

Epoch: 78| Step: 0
Training loss: 2.743544340133667
Validation loss: 2.437662580961822

Epoch: 5| Step: 1
Training loss: 1.845801591873169
Validation loss: 2.439910340052779

Epoch: 5| Step: 2
Training loss: 1.9975621700286865
Validation loss: 2.4389335468251216

Epoch: 5| Step: 3
Training loss: 3.0781097412109375
Validation loss: 2.4307628190645607

Epoch: 5| Step: 4
Training loss: 2.7876389026641846
Validation loss: 2.4391093023361696

Epoch: 5| Step: 5
Training loss: 2.9648194313049316
Validation loss: 2.4428956277908815

Epoch: 5| Step: 6
Training loss: 2.786130905151367
Validation loss: 2.4413377623404227

Epoch: 5| Step: 7
Training loss: 2.7144296169281006
Validation loss: 2.451459241169755

Epoch: 5| Step: 8
Training loss: 2.3248486518859863
Validation loss: 2.449260970597626

Epoch: 5| Step: 9
Training loss: 3.0495073795318604
Validation loss: 2.4537913107102916

Epoch: 5| Step: 10
Training loss: 2.9608213901519775
Validation loss: 2.450109456175117

Epoch: 79| Step: 0
Training loss: 2.45695161819458
Validation loss: 2.4510003238595943

Epoch: 5| Step: 1
Training loss: 3.3572659492492676
Validation loss: 2.453928562902635

Epoch: 5| Step: 2
Training loss: 2.695460319519043
Validation loss: 2.461359980285809

Epoch: 5| Step: 3
Training loss: 2.205003023147583
Validation loss: 2.461577518011934

Epoch: 5| Step: 4
Training loss: 2.911346912384033
Validation loss: 2.4542134961774273

Epoch: 5| Step: 5
Training loss: 2.225227117538452
Validation loss: 2.449581923023347

Epoch: 5| Step: 6
Training loss: 2.979996919631958
Validation loss: 2.446865584260674

Epoch: 5| Step: 7
Training loss: 3.1626815795898438
Validation loss: 2.43250992221217

Epoch: 5| Step: 8
Training loss: 2.5028250217437744
Validation loss: 2.4312304245528353

Epoch: 5| Step: 9
Training loss: 2.2092549800872803
Validation loss: 2.420898434936359

Epoch: 5| Step: 10
Training loss: 2.3987674713134766
Validation loss: 2.4266650445999636

Epoch: 80| Step: 0
Training loss: 2.688737392425537
Validation loss: 2.4225899199003815

Epoch: 5| Step: 1
Training loss: 2.776901960372925
Validation loss: 2.4206453754055883

Epoch: 5| Step: 2
Training loss: 2.376544713973999
Validation loss: 2.417766717172438

Epoch: 5| Step: 3
Training loss: 2.268484592437744
Validation loss: 2.413281165143495

Epoch: 5| Step: 4
Training loss: 2.6574182510375977
Validation loss: 2.4067333846963863

Epoch: 5| Step: 5
Training loss: 3.0611801147460938
Validation loss: 2.4062081754848523

Epoch: 5| Step: 6
Training loss: 3.3280651569366455
Validation loss: 2.4071010363999235

Epoch: 5| Step: 7
Training loss: 3.00469708442688
Validation loss: 2.4066816171010337

Epoch: 5| Step: 8
Training loss: 1.9883766174316406
Validation loss: 2.4061947996898363

Epoch: 5| Step: 9
Training loss: 1.977079153060913
Validation loss: 2.4077310921043478

Epoch: 5| Step: 10
Training loss: 2.9967000484466553
Validation loss: 2.406128957707395

Epoch: 81| Step: 0
Training loss: 2.6820273399353027
Validation loss: 2.41715427624282

Epoch: 5| Step: 1
Training loss: 2.7767117023468018
Validation loss: 2.413279738477481

Epoch: 5| Step: 2
Training loss: 2.337109088897705
Validation loss: 2.3980179679009224

Epoch: 5| Step: 3
Training loss: 2.023850917816162
Validation loss: 2.4033694139090915

Epoch: 5| Step: 4
Training loss: 2.3869853019714355
Validation loss: 2.39931910012358

Epoch: 5| Step: 5
Training loss: 3.1765408515930176
Validation loss: 2.396898495253696

Epoch: 5| Step: 6
Training loss: 3.216515302658081
Validation loss: 2.3963877667662916

Epoch: 5| Step: 7
Training loss: 2.537843704223633
Validation loss: 2.4041372986250025

Epoch: 5| Step: 8
Training loss: 2.2728004455566406
Validation loss: 2.4140633357468473

Epoch: 5| Step: 9
Training loss: 2.8327441215515137
Validation loss: 2.4211554860556

Epoch: 5| Step: 10
Training loss: 2.838179588317871
Validation loss: 2.436414623773226

Epoch: 82| Step: 0
Training loss: 2.854788303375244
Validation loss: 2.4281745546607563

Epoch: 5| Step: 1
Training loss: 2.339643955230713
Validation loss: 2.405453952409888

Epoch: 5| Step: 2
Training loss: 2.7616782188415527
Validation loss: 2.3898240648290163

Epoch: 5| Step: 3
Training loss: 2.8416497707366943
Validation loss: 2.3831308170031478

Epoch: 5| Step: 4
Training loss: 1.8116331100463867
Validation loss: 2.3831614807087886

Epoch: 5| Step: 5
Training loss: 2.972465753555298
Validation loss: 2.3849092786030104

Epoch: 5| Step: 6
Training loss: 3.021632194519043
Validation loss: 2.3925636917032223

Epoch: 5| Step: 7
Training loss: 2.8228535652160645
Validation loss: 2.4031237786816013

Epoch: 5| Step: 8
Training loss: 2.842287540435791
Validation loss: 2.409561623809158

Epoch: 5| Step: 9
Training loss: 3.0878310203552246
Validation loss: 2.3998109371431413

Epoch: 5| Step: 10
Training loss: 1.5352330207824707
Validation loss: 2.394002281209474

Epoch: 83| Step: 0
Training loss: 2.889901638031006
Validation loss: 2.394134970121486

Epoch: 5| Step: 1
Training loss: 2.8734962940216064
Validation loss: 2.393540584912864

Epoch: 5| Step: 2
Training loss: 2.9980978965759277
Validation loss: 2.388126165636124

Epoch: 5| Step: 3
Training loss: 2.1498875617980957
Validation loss: 2.3896161740826023

Epoch: 5| Step: 4
Training loss: 2.4520645141601562
Validation loss: 2.390768943294402

Epoch: 5| Step: 5
Training loss: 2.9475173950195312
Validation loss: 2.3960982727748092

Epoch: 5| Step: 6
Training loss: 2.5669660568237305
Validation loss: 2.398823945753036

Epoch: 5| Step: 7
Training loss: 2.784188747406006
Validation loss: 2.410950460741597

Epoch: 5| Step: 8
Training loss: 2.027270793914795
Validation loss: 2.426103230445616

Epoch: 5| Step: 9
Training loss: 2.5118918418884277
Validation loss: 2.4343212804486676

Epoch: 5| Step: 10
Training loss: 2.91098690032959
Validation loss: 2.4338997384553314

Epoch: 84| Step: 0
Training loss: 2.6443417072296143
Validation loss: 2.4189689441393782

Epoch: 5| Step: 1
Training loss: 1.7607008218765259
Validation loss: 2.403058800646054

Epoch: 5| Step: 2
Training loss: 2.5207340717315674
Validation loss: 2.4027475413455757

Epoch: 5| Step: 3
Training loss: 2.0287537574768066
Validation loss: 2.3851007312856694

Epoch: 5| Step: 4
Training loss: 2.9988808631896973
Validation loss: 2.3885818168681157

Epoch: 5| Step: 5
Training loss: 3.468001127243042
Validation loss: 2.386068772244197

Epoch: 5| Step: 6
Training loss: 2.736128568649292
Validation loss: 2.3797411636639665

Epoch: 5| Step: 7
Training loss: 2.6306474208831787
Validation loss: 2.3872560198589037

Epoch: 5| Step: 8
Training loss: 2.618814706802368
Validation loss: 2.3846922792414182

Epoch: 5| Step: 9
Training loss: 2.6623523235321045
Validation loss: 2.3794517286362185

Epoch: 5| Step: 10
Training loss: 2.8681459426879883
Validation loss: 2.3853864503163162

Epoch: 85| Step: 0
Training loss: 2.239185333251953
Validation loss: 2.384121856381816

Epoch: 5| Step: 1
Training loss: 2.7112784385681152
Validation loss: 2.384354083768783

Epoch: 5| Step: 2
Training loss: 2.4067459106445312
Validation loss: 2.383748491605123

Epoch: 5| Step: 3
Training loss: 2.969426393508911
Validation loss: 2.386219473295314

Epoch: 5| Step: 4
Training loss: 2.383913516998291
Validation loss: 2.386913009869155

Epoch: 5| Step: 5
Training loss: 2.844836711883545
Validation loss: 2.3973309788652646

Epoch: 5| Step: 6
Training loss: 2.9418880939483643
Validation loss: 2.4182068506876626

Epoch: 5| Step: 7
Training loss: 2.126300096511841
Validation loss: 2.400333373777328

Epoch: 5| Step: 8
Training loss: 2.1211600303649902
Validation loss: 2.3882513802538634

Epoch: 5| Step: 9
Training loss: 3.2422935962677
Validation loss: 2.3964886844799085

Epoch: 5| Step: 10
Training loss: 2.963932752609253
Validation loss: 2.3912946998432116

Epoch: 86| Step: 0
Training loss: 1.9662787914276123
Validation loss: 2.3970362422286824

Epoch: 5| Step: 1
Training loss: 2.902270793914795
Validation loss: 2.3960871722108577

Epoch: 5| Step: 2
Training loss: 2.3228423595428467
Validation loss: 2.420071530085738

Epoch: 5| Step: 3
Training loss: 2.8643898963928223
Validation loss: 2.4223946038112847

Epoch: 5| Step: 4
Training loss: 2.473161458969116
Validation loss: 2.425180624890071

Epoch: 5| Step: 5
Training loss: 2.840237617492676
Validation loss: 2.420105072759813

Epoch: 5| Step: 6
Training loss: 2.499110698699951
Validation loss: 2.398141755852648

Epoch: 5| Step: 7
Training loss: 2.6078498363494873
Validation loss: 2.3938212163986696

Epoch: 5| Step: 8
Training loss: 2.8301939964294434
Validation loss: 2.3912958432269353

Epoch: 5| Step: 9
Training loss: 2.9943244457244873
Validation loss: 2.3791330373415382

Epoch: 5| Step: 10
Training loss: 2.557521343231201
Validation loss: 2.3870561917622886

Epoch: 87| Step: 0
Training loss: 2.718691349029541
Validation loss: 2.3851566237788044

Epoch: 5| Step: 1
Training loss: 2.743354558944702
Validation loss: 2.3844213306262927

Epoch: 5| Step: 2
Training loss: 2.240662097930908
Validation loss: 2.390070166639102

Epoch: 5| Step: 3
Training loss: 2.5107383728027344
Validation loss: 2.400753915950816

Epoch: 5| Step: 4
Training loss: 2.2042720317840576
Validation loss: 2.4151148373080837

Epoch: 5| Step: 5
Training loss: 3.120995044708252
Validation loss: 2.424348532512624

Epoch: 5| Step: 6
Training loss: 2.604426622390747
Validation loss: 2.4239854658803632

Epoch: 5| Step: 7
Training loss: 3.0518460273742676
Validation loss: 2.422619342803955

Epoch: 5| Step: 8
Training loss: 2.125516176223755
Validation loss: 2.4016392128441924

Epoch: 5| Step: 9
Training loss: 3.10347056388855
Validation loss: 2.3831916265590216

Epoch: 5| Step: 10
Training loss: 2.4024598598480225
Validation loss: 2.3747557286293275

Epoch: 88| Step: 0
Training loss: 2.6939666271209717
Validation loss: 2.370817438248665

Epoch: 5| Step: 1
Training loss: 2.8980655670166016
Validation loss: 2.3676592432042605

Epoch: 5| Step: 2
Training loss: 2.6588499546051025
Validation loss: 2.370322371041903

Epoch: 5| Step: 3
Training loss: 2.4640822410583496
Validation loss: 2.370103825805008

Epoch: 5| Step: 4
Training loss: 1.7140499353408813
Validation loss: 2.3750403260671966

Epoch: 5| Step: 5
Training loss: 2.8379831314086914
Validation loss: 2.3733446777507825

Epoch: 5| Step: 6
Training loss: 2.743438720703125
Validation loss: 2.3736779843607256

Epoch: 5| Step: 7
Training loss: 2.9342525005340576
Validation loss: 2.372556150600474

Epoch: 5| Step: 8
Training loss: 2.8777239322662354
Validation loss: 2.369703338992211

Epoch: 5| Step: 9
Training loss: 2.8495399951934814
Validation loss: 2.3741361505241803

Epoch: 5| Step: 10
Training loss: 2.241813898086548
Validation loss: 2.3875955612428728

Epoch: 89| Step: 0
Training loss: 2.7429051399230957
Validation loss: 2.3929592793987644

Epoch: 5| Step: 1
Training loss: 2.3699519634246826
Validation loss: 2.425106668985018

Epoch: 5| Step: 2
Training loss: 3.4218616485595703
Validation loss: 2.4754366156875447

Epoch: 5| Step: 3
Training loss: 2.5806193351745605
Validation loss: 2.428329001190842

Epoch: 5| Step: 4
Training loss: 2.964582681655884
Validation loss: 2.391849463985812

Epoch: 5| Step: 5
Training loss: 2.3130245208740234
Validation loss: 2.376196030647524

Epoch: 5| Step: 6
Training loss: 2.260709047317505
Validation loss: 2.3704396345282115

Epoch: 5| Step: 7
Training loss: 2.8226253986358643
Validation loss: 2.373523881358485

Epoch: 5| Step: 8
Training loss: 2.1564781665802
Validation loss: 2.3862353473581295

Epoch: 5| Step: 9
Training loss: 3.049116611480713
Validation loss: 2.40954376036121

Epoch: 5| Step: 10
Training loss: 2.3481709957122803
Validation loss: 2.4216939121164303

Epoch: 90| Step: 0
Training loss: 2.306300640106201
Validation loss: 2.4082920730754895

Epoch: 5| Step: 1
Training loss: 3.3836731910705566
Validation loss: 2.383150654454385

Epoch: 5| Step: 2
Training loss: 2.412956714630127
Validation loss: 2.371614956086682

Epoch: 5| Step: 3
Training loss: 2.442194700241089
Validation loss: 2.3667924429780696

Epoch: 5| Step: 4
Training loss: 2.572819471359253
Validation loss: 2.3626372762905654

Epoch: 5| Step: 5
Training loss: 2.792515277862549
Validation loss: 2.365493589831937

Epoch: 5| Step: 6
Training loss: 3.1523847579956055
Validation loss: 2.3744201916520313

Epoch: 5| Step: 7
Training loss: 2.2674262523651123
Validation loss: 2.3860002692027757

Epoch: 5| Step: 8
Training loss: 2.381404399871826
Validation loss: 2.407739095790412

Epoch: 5| Step: 9
Training loss: 2.1221702098846436
Validation loss: 2.450583017000588

Epoch: 5| Step: 10
Training loss: 3.358238697052002
Validation loss: 2.47162728412177

Epoch: 91| Step: 0
Training loss: 2.4191994667053223
Validation loss: 2.4841493304057787

Epoch: 5| Step: 1
Training loss: 3.0979533195495605
Validation loss: 2.447774056465395

Epoch: 5| Step: 2
Training loss: 2.6794421672821045
Validation loss: 2.4047842589757775

Epoch: 5| Step: 3
Training loss: 2.848928928375244
Validation loss: 2.3811168414290234

Epoch: 5| Step: 4
Training loss: 2.864316463470459
Validation loss: 2.373456903683242

Epoch: 5| Step: 5
Training loss: 2.716437578201294
Validation loss: 2.3598237934932915

Epoch: 5| Step: 6
Training loss: 2.4722931385040283
Validation loss: 2.356310729057558

Epoch: 5| Step: 7
Training loss: 2.692777633666992
Validation loss: 2.3583736624768985

Epoch: 5| Step: 8
Training loss: 2.3301432132720947
Validation loss: 2.3545126248431463

Epoch: 5| Step: 9
Training loss: 2.4020020961761475
Validation loss: 2.3576689817572154

Epoch: 5| Step: 10
Training loss: 2.244945526123047
Validation loss: 2.354498573528823

Epoch: 92| Step: 0
Training loss: 3.1588118076324463
Validation loss: 2.353434185827932

Epoch: 5| Step: 1
Training loss: 2.1034295558929443
Validation loss: 2.3543724962460097

Epoch: 5| Step: 2
Training loss: 2.306675434112549
Validation loss: 2.3595316063973213

Epoch: 5| Step: 3
Training loss: 2.613490343093872
Validation loss: 2.3570847870201193

Epoch: 5| Step: 4
Training loss: 3.109229326248169
Validation loss: 2.3659392595291138

Epoch: 5| Step: 5
Training loss: 2.8054566383361816
Validation loss: 2.3612854275652158

Epoch: 5| Step: 6
Training loss: 2.438511610031128
Validation loss: 2.3660963812182025

Epoch: 5| Step: 7
Training loss: 2.7408857345581055
Validation loss: 2.3752021276822655

Epoch: 5| Step: 8
Training loss: 2.1768603324890137
Validation loss: 2.378113562060941

Epoch: 5| Step: 9
Training loss: 2.382434606552124
Validation loss: 2.384817869432511

Epoch: 5| Step: 10
Training loss: 2.8976094722747803
Validation loss: 2.3860100264190347

Epoch: 93| Step: 0
Training loss: 2.7255802154541016
Validation loss: 2.389241721040459

Epoch: 5| Step: 1
Training loss: 2.273930072784424
Validation loss: 2.3925769252161824

Epoch: 5| Step: 2
Training loss: 2.1469886302948
Validation loss: 2.396265939999652

Epoch: 5| Step: 3
Training loss: 2.7313880920410156
Validation loss: 2.3814864850813344

Epoch: 5| Step: 4
Training loss: 2.4940199851989746
Validation loss: 2.381806728660419

Epoch: 5| Step: 5
Training loss: 2.4361307621002197
Validation loss: 2.37458558236399

Epoch: 5| Step: 6
Training loss: 2.4707555770874023
Validation loss: 2.358553642867714

Epoch: 5| Step: 7
Training loss: 3.187999725341797
Validation loss: 2.3533446916969876

Epoch: 5| Step: 8
Training loss: 2.798067569732666
Validation loss: 2.352276440589659

Epoch: 5| Step: 9
Training loss: 2.5743818283081055
Validation loss: 2.350336851612214

Epoch: 5| Step: 10
Training loss: 2.8647170066833496
Validation loss: 2.3556650453998196

Epoch: 94| Step: 0
Training loss: 2.6484756469726562
Validation loss: 2.3515039746479323

Epoch: 5| Step: 1
Training loss: 2.4931721687316895
Validation loss: 2.3519501980914863

Epoch: 5| Step: 2
Training loss: 2.7006497383117676
Validation loss: 2.3497549128788773

Epoch: 5| Step: 3
Training loss: 2.9157938957214355
Validation loss: 2.348128270077449

Epoch: 5| Step: 4
Training loss: 2.5212783813476562
Validation loss: 2.357715816907985

Epoch: 5| Step: 5
Training loss: 2.9368505477905273
Validation loss: 2.3566787217252996

Epoch: 5| Step: 6
Training loss: 1.9110835790634155
Validation loss: 2.3551354587719007

Epoch: 5| Step: 7
Training loss: 3.3076083660125732
Validation loss: 2.352748194048482

Epoch: 5| Step: 8
Training loss: 2.0890603065490723
Validation loss: 2.3658807969862417

Epoch: 5| Step: 9
Training loss: 2.571472644805908
Validation loss: 2.37216886397331

Epoch: 5| Step: 10
Training loss: 2.4857921600341797
Validation loss: 2.380563692380023

Epoch: 95| Step: 0
Training loss: 2.422048330307007
Validation loss: 2.38486304847143

Epoch: 5| Step: 1
Training loss: 2.420384645462036
Validation loss: 2.4057750266085387

Epoch: 5| Step: 2
Training loss: 2.8172929286956787
Validation loss: 2.4168550596442273

Epoch: 5| Step: 3
Training loss: 3.0796070098876953
Validation loss: 2.4219706622503137

Epoch: 5| Step: 4
Training loss: 2.8428752422332764
Validation loss: 2.406985039352089

Epoch: 5| Step: 5
Training loss: 2.6221325397491455
Validation loss: 2.376210848490397

Epoch: 5| Step: 6
Training loss: 2.617135524749756
Validation loss: 2.3567038812944965

Epoch: 5| Step: 7
Training loss: 2.760368824005127
Validation loss: 2.3476225304347214

Epoch: 5| Step: 8
Training loss: 2.0595169067382812
Validation loss: 2.348275330758864

Epoch: 5| Step: 9
Training loss: 2.716373920440674
Validation loss: 2.351172779196052

Epoch: 5| Step: 10
Training loss: 2.305647611618042
Validation loss: 2.3574817667725267

Epoch: 96| Step: 0
Training loss: 1.898667573928833
Validation loss: 2.3656269350359516

Epoch: 5| Step: 1
Training loss: 3.1865572929382324
Validation loss: 2.370324783427741

Epoch: 5| Step: 2
Training loss: 3.029491424560547
Validation loss: 2.3633521782454623

Epoch: 5| Step: 3
Training loss: 2.797726631164551
Validation loss: 2.3610200599957536

Epoch: 5| Step: 4
Training loss: 2.357221841812134
Validation loss: 2.3606703614675872

Epoch: 5| Step: 5
Training loss: 2.9210879802703857
Validation loss: 2.358436207617483

Epoch: 5| Step: 6
Training loss: 2.275686025619507
Validation loss: 2.374383657209335

Epoch: 5| Step: 7
Training loss: 2.8006021976470947
Validation loss: 2.388805248404062

Epoch: 5| Step: 8
Training loss: 2.3857007026672363
Validation loss: 2.408793149455901

Epoch: 5| Step: 9
Training loss: 2.726459503173828
Validation loss: 2.4146033038375196

Epoch: 5| Step: 10
Training loss: 2.3132805824279785
Validation loss: 2.3965575746310654

Epoch: 97| Step: 0
Training loss: 2.213571071624756
Validation loss: 2.3779826971792404

Epoch: 5| Step: 1
Training loss: 2.8407905101776123
Validation loss: 2.346222944157098

Epoch: 5| Step: 2
Training loss: 2.6469104290008545
Validation loss: 2.3472527868004254

Epoch: 5| Step: 3
Training loss: 3.048726797103882
Validation loss: 2.3470178137543383

Epoch: 5| Step: 4
Training loss: 2.425705909729004
Validation loss: 2.3425087569862284

Epoch: 5| Step: 5
Training loss: 2.588181972503662
Validation loss: 2.3430220183505805

Epoch: 5| Step: 6
Training loss: 2.608731269836426
Validation loss: 2.3482164400880055

Epoch: 5| Step: 7
Training loss: 2.339630603790283
Validation loss: 2.3477815863906697

Epoch: 5| Step: 8
Training loss: 2.806725263595581
Validation loss: 2.344662256138299

Epoch: 5| Step: 9
Training loss: 2.8240737915039062
Validation loss: 2.343785144949472

Epoch: 5| Step: 10
Training loss: 2.1939220428466797
Validation loss: 2.3446885462730163

Epoch: 98| Step: 0
Training loss: 2.8194804191589355
Validation loss: 2.3491434768963884

Epoch: 5| Step: 1
Training loss: 2.624296188354492
Validation loss: 2.3451070195885113

Epoch: 5| Step: 2
Training loss: 3.2762069702148438
Validation loss: 2.346584863560174

Epoch: 5| Step: 3
Training loss: 2.397031545639038
Validation loss: 2.353523761995377

Epoch: 5| Step: 4
Training loss: 2.1154353618621826
Validation loss: 2.351291884658157

Epoch: 5| Step: 5
Training loss: 2.100398540496826
Validation loss: 2.363101374718451

Epoch: 5| Step: 6
Training loss: 2.2706546783447266
Validation loss: 2.383788525417287

Epoch: 5| Step: 7
Training loss: 3.0822036266326904
Validation loss: 2.3988962224734727

Epoch: 5| Step: 8
Training loss: 3.541119337081909
Validation loss: 2.3805535762540755

Epoch: 5| Step: 9
Training loss: 2.009629487991333
Validation loss: 2.3764765929150324

Epoch: 5| Step: 10
Training loss: 2.3001065254211426
Validation loss: 2.355810203859883

Epoch: 99| Step: 0
Training loss: 2.713536262512207
Validation loss: 2.3530165021137526

Epoch: 5| Step: 1
Training loss: 2.5798420906066895
Validation loss: 2.3570358061021373

Epoch: 5| Step: 2
Training loss: 2.3405792713165283
Validation loss: 2.3654520691082044

Epoch: 5| Step: 3
Training loss: 2.0036113262176514
Validation loss: 2.3474377278358705

Epoch: 5| Step: 4
Training loss: 2.2847537994384766
Validation loss: 2.355411380849859

Epoch: 5| Step: 5
Training loss: 2.630596160888672
Validation loss: 2.3443813580338673

Epoch: 5| Step: 6
Training loss: 2.1105079650878906
Validation loss: 2.345483047987825

Epoch: 5| Step: 7
Training loss: 2.750791072845459
Validation loss: 2.3735851818515408

Epoch: 5| Step: 8
Training loss: 2.943784236907959
Validation loss: 2.3990500152751966

Epoch: 5| Step: 9
Training loss: 3.129364013671875
Validation loss: 2.4143834626802834

Epoch: 5| Step: 10
Training loss: 3.3905022144317627
Validation loss: 2.43282901599843

Epoch: 100| Step: 0
Training loss: 2.923121929168701
Validation loss: 2.399395206923126

Epoch: 5| Step: 1
Training loss: 2.466954469680786
Validation loss: 2.366121489514587

Epoch: 5| Step: 2
Training loss: 2.316265106201172
Validation loss: 2.3446316719055176

Epoch: 5| Step: 3
Training loss: 3.341709613800049
Validation loss: 2.33883769794177

Epoch: 5| Step: 4
Training loss: 2.529270887374878
Validation loss: 2.3483522553597727

Epoch: 5| Step: 5
Training loss: 2.5722458362579346
Validation loss: 2.374114554415467

Epoch: 5| Step: 6
Training loss: 2.3144702911376953
Validation loss: 2.39886147745194

Epoch: 5| Step: 7
Training loss: 2.7835631370544434
Validation loss: 2.3946913724304526

Epoch: 5| Step: 8
Training loss: 2.6822171211242676
Validation loss: 2.368529676109232

Epoch: 5| Step: 9
Training loss: 2.6774203777313232
Validation loss: 2.331892745469206

Epoch: 5| Step: 10
Training loss: 2.2116994857788086
Validation loss: 2.3228130238030547

Epoch: 101| Step: 0
Training loss: 1.7765858173370361
Validation loss: 2.3217508357058287

Epoch: 5| Step: 1
Training loss: 2.633185863494873
Validation loss: 2.333433779337073

Epoch: 5| Step: 2
Training loss: 3.047060012817383
Validation loss: 2.3698358381948164

Epoch: 5| Step: 3
Training loss: 2.4033637046813965
Validation loss: 2.4081826902204946

Epoch: 5| Step: 4
Training loss: 2.8794913291931152
Validation loss: 2.4632007691168014

Epoch: 5| Step: 5
Training loss: 2.7770750522613525
Validation loss: 2.558497090493479

Epoch: 5| Step: 6
Training loss: 3.6058781147003174
Validation loss: 2.554522414361277

Epoch: 5| Step: 7
Training loss: 2.131075143814087
Validation loss: 2.4288358214080974

Epoch: 5| Step: 8
Training loss: 2.1054763793945312
Validation loss: 2.3602094496450117

Epoch: 5| Step: 9
Training loss: 2.5022776126861572
Validation loss: 2.3335314617362073

Epoch: 5| Step: 10
Training loss: 3.2011842727661133
Validation loss: 2.319458635904456

Epoch: 102| Step: 0
Training loss: 2.7909083366394043
Validation loss: 2.32310692597461

Epoch: 5| Step: 1
Training loss: 2.658552646636963
Validation loss: 2.327699709964055

Epoch: 5| Step: 2
Training loss: 2.487143039703369
Validation loss: 2.3472674174975325

Epoch: 5| Step: 3
Training loss: 2.7019286155700684
Validation loss: 2.3621369382386566

Epoch: 5| Step: 4
Training loss: 2.28779673576355
Validation loss: 2.369501139528008

Epoch: 5| Step: 5
Training loss: 2.4858884811401367
Validation loss: 2.4108149569521666

Epoch: 5| Step: 6
Training loss: 2.323953866958618
Validation loss: 2.4076828802785566

Epoch: 5| Step: 7
Training loss: 2.7734432220458984
Validation loss: 2.3763052878841275

Epoch: 5| Step: 8
Training loss: 3.1738009452819824
Validation loss: 2.3584010575407293

Epoch: 5| Step: 9
Training loss: 2.4656636714935303
Validation loss: 2.3353307888072026

Epoch: 5| Step: 10
Training loss: 2.641977310180664
Validation loss: 2.32223480491228

Epoch: 103| Step: 0
Training loss: 2.7641232013702393
Validation loss: 2.322643144156343

Epoch: 5| Step: 1
Training loss: 2.134584665298462
Validation loss: 2.325908301978983

Epoch: 5| Step: 2
Training loss: 2.5406153202056885
Validation loss: 2.3304632620144914

Epoch: 5| Step: 3
Training loss: 2.416943311691284
Validation loss: 2.331063707669576

Epoch: 5| Step: 4
Training loss: 2.0385098457336426
Validation loss: 2.343826599018548

Epoch: 5| Step: 5
Training loss: 2.817499876022339
Validation loss: 2.367087318051246

Epoch: 5| Step: 6
Training loss: 2.5365421772003174
Validation loss: 2.4613394224515526

Epoch: 5| Step: 7
Training loss: 2.400536060333252
Validation loss: 2.562666436677338

Epoch: 5| Step: 8
Training loss: 4.221323490142822
Validation loss: 2.5867441341441166

Epoch: 5| Step: 9
Training loss: 2.5386738777160645
Validation loss: 2.5494809022513767

Epoch: 5| Step: 10
Training loss: 2.7979414463043213
Validation loss: 2.4666262518975044

Epoch: 104| Step: 0
Training loss: 2.151716709136963
Validation loss: 2.3485526987301406

Epoch: 5| Step: 1
Training loss: 3.0013346672058105
Validation loss: 2.3193077323257283

Epoch: 5| Step: 2
Training loss: 3.222738265991211
Validation loss: 2.345916011000192

Epoch: 5| Step: 3
Training loss: 2.4120283126831055
Validation loss: 2.4159488652342107

Epoch: 5| Step: 4
Training loss: 3.2332770824432373
Validation loss: 2.4020916031252955

Epoch: 5| Step: 5
Training loss: 1.7893407344818115
Validation loss: 2.391080371795162

Epoch: 5| Step: 6
Training loss: 2.751936912536621
Validation loss: 2.385711290503061

Epoch: 5| Step: 7
Training loss: 2.8651599884033203
Validation loss: 2.403932217628725

Epoch: 5| Step: 8
Training loss: 2.8733177185058594
Validation loss: 2.4286291971001575

Epoch: 5| Step: 9
Training loss: 2.1287801265716553
Validation loss: 2.405200901851859

Epoch: 5| Step: 10
Training loss: 2.66115665435791
Validation loss: 2.379070710110408

Epoch: 105| Step: 0
Training loss: 2.296804189682007
Validation loss: 2.3499334935219056

Epoch: 5| Step: 1
Training loss: 2.7744650840759277
Validation loss: 2.3267780606464674

Epoch: 5| Step: 2
Training loss: 2.4459383487701416
Validation loss: 2.317543988586754

Epoch: 5| Step: 3
Training loss: 3.094069004058838
Validation loss: 2.31882030476806

Epoch: 5| Step: 4
Training loss: 3.2359910011291504
Validation loss: 2.3173069877009236

Epoch: 5| Step: 5
Training loss: 1.8066842555999756
Validation loss: 2.3244284788767495

Epoch: 5| Step: 6
Training loss: 2.6015658378601074
Validation loss: 2.3321261405944824

Epoch: 5| Step: 7
Training loss: 2.6997711658477783
Validation loss: 2.338724133788898

Epoch: 5| Step: 8
Training loss: 2.244497776031494
Validation loss: 2.3514443007848596

Epoch: 5| Step: 9
Training loss: 2.252511501312256
Validation loss: 2.3474673045578824

Epoch: 5| Step: 10
Training loss: 3.191981792449951
Validation loss: 2.3652419172307497

Epoch: 106| Step: 0
Training loss: 3.160796642303467
Validation loss: 2.3593480740824053

Epoch: 5| Step: 1
Training loss: 2.888221025466919
Validation loss: 2.346836305433704

Epoch: 5| Step: 2
Training loss: 2.7357680797576904
Validation loss: 2.3316640930791057

Epoch: 5| Step: 3
Training loss: 2.929964542388916
Validation loss: 2.324777574949367

Epoch: 5| Step: 4
Training loss: 2.1941635608673096
Validation loss: 2.321760380139915

Epoch: 5| Step: 5
Training loss: 2.2859768867492676
Validation loss: 2.3185081597297423

Epoch: 5| Step: 6
Training loss: 2.3505821228027344
Validation loss: 2.3160614428981656

Epoch: 5| Step: 7
Training loss: 2.719357967376709
Validation loss: 2.319099651869907

Epoch: 5| Step: 8
Training loss: 2.9006457328796387
Validation loss: 2.3199221318767917

Epoch: 5| Step: 9
Training loss: 2.159005641937256
Validation loss: 2.323360676406532

Epoch: 5| Step: 10
Training loss: 2.1067535877227783
Validation loss: 2.318565745507517

Epoch: 107| Step: 0
Training loss: 2.92750883102417
Validation loss: 2.320714299396802

Epoch: 5| Step: 1
Training loss: 2.440941333770752
Validation loss: 2.3194839492920907

Epoch: 5| Step: 2
Training loss: 3.438934803009033
Validation loss: 2.3177420503349713

Epoch: 5| Step: 3
Training loss: 2.900459051132202
Validation loss: 2.3081069389979043

Epoch: 5| Step: 4
Training loss: 2.093100070953369
Validation loss: 2.310761743976224

Epoch: 5| Step: 5
Training loss: 2.230518102645874
Validation loss: 2.308239047245313

Epoch: 5| Step: 6
Training loss: 2.598358631134033
Validation loss: 2.3249018256382277

Epoch: 5| Step: 7
Training loss: 2.1782755851745605
Validation loss: 2.321179384826332

Epoch: 5| Step: 8
Training loss: 2.5040974617004395
Validation loss: 2.311326224316833

Epoch: 5| Step: 9
Training loss: 2.5683581829071045
Validation loss: 2.3085158755702357

Epoch: 5| Step: 10
Training loss: 2.4849774837493896
Validation loss: 2.3013119800116426

Epoch: 108| Step: 0
Training loss: 2.695019245147705
Validation loss: 2.3025166988372803

Epoch: 5| Step: 1
Training loss: 2.0824429988861084
Validation loss: 2.2959019907059206

Epoch: 5| Step: 2
Training loss: 2.656118154525757
Validation loss: 2.299562382441695

Epoch: 5| Step: 3
Training loss: 2.222593069076538
Validation loss: 2.304410719102429

Epoch: 5| Step: 4
Training loss: 3.0819971561431885
Validation loss: 2.3050431615562847

Epoch: 5| Step: 5
Training loss: 2.7585582733154297
Validation loss: 2.3035421679096837

Epoch: 5| Step: 6
Training loss: 2.1557247638702393
Validation loss: 2.304517476789413

Epoch: 5| Step: 7
Training loss: 2.6811492443084717
Validation loss: 2.303836237999701

Epoch: 5| Step: 8
Training loss: 2.9063713550567627
Validation loss: 2.3035817607756583

Epoch: 5| Step: 9
Training loss: 2.1176581382751465
Validation loss: 2.310423502358057

Epoch: 5| Step: 10
Training loss: 2.948213577270508
Validation loss: 2.316202850751979

Epoch: 109| Step: 0
Training loss: 2.593770980834961
Validation loss: 2.317392387697774

Epoch: 5| Step: 1
Training loss: 2.9445695877075195
Validation loss: 2.302049970114103

Epoch: 5| Step: 2
Training loss: 2.008517026901245
Validation loss: 2.3024952950016147

Epoch: 5| Step: 3
Training loss: 2.635328769683838
Validation loss: 2.30421716936173

Epoch: 5| Step: 4
Training loss: 2.8245484828948975
Validation loss: 2.300079578994423

Epoch: 5| Step: 5
Training loss: 2.394564390182495
Validation loss: 2.3080640300627677

Epoch: 5| Step: 6
Training loss: 2.940556049346924
Validation loss: 2.307666837528188

Epoch: 5| Step: 7
Training loss: 3.239973545074463
Validation loss: 2.3087846258635163

Epoch: 5| Step: 8
Training loss: 1.3275173902511597
Validation loss: 2.310085827304471

Epoch: 5| Step: 9
Training loss: 2.350761890411377
Validation loss: 2.30999852508627

Epoch: 5| Step: 10
Training loss: 3.0427086353302
Validation loss: 2.3025966382795766

Epoch: 110| Step: 0
Training loss: 3.063293218612671
Validation loss: 2.2955777017019128

Epoch: 5| Step: 1
Training loss: 2.5342507362365723
Validation loss: 2.2973878742546163

Epoch: 5| Step: 2
Training loss: 2.7717719078063965
Validation loss: 2.3013778963396625

Epoch: 5| Step: 3
Training loss: 2.787463426589966
Validation loss: 2.3000589237418225

Epoch: 5| Step: 4
Training loss: 2.3639121055603027
Validation loss: 2.292885107378806

Epoch: 5| Step: 5
Training loss: 2.707350254058838
Validation loss: 2.3022277483376126

Epoch: 5| Step: 6
Training loss: 2.433547258377075
Validation loss: 2.3049175149650982

Epoch: 5| Step: 7
Training loss: 2.438149929046631
Validation loss: 2.308015218345068

Epoch: 5| Step: 8
Training loss: 2.356426239013672
Validation loss: 2.3250229307400283

Epoch: 5| Step: 9
Training loss: 2.47674298286438
Validation loss: 2.323260978985858

Epoch: 5| Step: 10
Training loss: 2.2420880794525146
Validation loss: 2.318821713488589

Epoch: 111| Step: 0
Training loss: 3.137807846069336
Validation loss: 2.319649306676721

Epoch: 5| Step: 1
Training loss: 3.1184563636779785
Validation loss: 2.327560568368563

Epoch: 5| Step: 2
Training loss: 2.573547601699829
Validation loss: 2.296958823357859

Epoch: 5| Step: 3
Training loss: 2.6510138511657715
Validation loss: 2.29879012415486

Epoch: 5| Step: 4
Training loss: 2.4792087078094482
Validation loss: 2.305432814423756

Epoch: 5| Step: 5
Training loss: 2.659830093383789
Validation loss: 2.2994609109817015

Epoch: 5| Step: 6
Training loss: 2.7164204120635986
Validation loss: 2.321993415073682

Epoch: 5| Step: 7
Training loss: 2.4465906620025635
Validation loss: 2.31312580262461

Epoch: 5| Step: 8
Training loss: 1.971289873123169
Validation loss: 2.3018194680572837

Epoch: 5| Step: 9
Training loss: 2.0668082237243652
Validation loss: 2.299599027120939

Epoch: 5| Step: 10
Training loss: 2.4742491245269775
Validation loss: 2.3021660120256486

Epoch: 112| Step: 0
Training loss: 2.4182963371276855
Validation loss: 2.299209569090156

Epoch: 5| Step: 1
Training loss: 2.211273670196533
Validation loss: 2.3017323760576147

Epoch: 5| Step: 2
Training loss: 2.807281017303467
Validation loss: 2.297636417932408

Epoch: 5| Step: 3
Training loss: 2.871690034866333
Validation loss: 2.2986459578237226

Epoch: 5| Step: 4
Training loss: 2.428438663482666
Validation loss: 2.3021103233419438

Epoch: 5| Step: 5
Training loss: 2.542221784591675
Validation loss: 2.297299128706737

Epoch: 5| Step: 6
Training loss: 2.589038133621216
Validation loss: 2.30268685279354

Epoch: 5| Step: 7
Training loss: 2.5650556087493896
Validation loss: 2.3039878568341656

Epoch: 5| Step: 8
Training loss: 3.3117122650146484
Validation loss: 2.313537061855357

Epoch: 5| Step: 9
Training loss: 2.011286497116089
Validation loss: 2.3073579777953444

Epoch: 5| Step: 10
Training loss: 2.3503408432006836
Validation loss: 2.3206739887114494

Epoch: 113| Step: 0
Training loss: 2.985557794570923
Validation loss: 2.3286872653551

Epoch: 5| Step: 1
Training loss: 2.8446195125579834
Validation loss: 2.3311123873597834

Epoch: 5| Step: 2
Training loss: 2.8845114707946777
Validation loss: 2.3169735400907454

Epoch: 5| Step: 3
Training loss: 2.339313268661499
Validation loss: 2.304642290197393

Epoch: 5| Step: 4
Training loss: 2.544111728668213
Validation loss: 2.301658127897529

Epoch: 5| Step: 5
Training loss: 1.8474582433700562
Validation loss: 2.3006929018164195

Epoch: 5| Step: 6
Training loss: 2.958423376083374
Validation loss: 2.311414590445898

Epoch: 5| Step: 7
Training loss: 2.3377127647399902
Validation loss: 2.3103715373623754

Epoch: 5| Step: 8
Training loss: 2.4434216022491455
Validation loss: 2.3033663021620883

Epoch: 5| Step: 9
Training loss: 2.6160407066345215
Validation loss: 2.312840341239847

Epoch: 5| Step: 10
Training loss: 2.4013288021087646
Validation loss: 2.296839129540228

Epoch: 114| Step: 0
Training loss: 2.230665922164917
Validation loss: 2.296289602915446

Epoch: 5| Step: 1
Training loss: 2.793017864227295
Validation loss: 2.2984119974156862

Epoch: 5| Step: 2
Training loss: 2.556826591491699
Validation loss: 2.2892907511803413

Epoch: 5| Step: 3
Training loss: 2.8188445568084717
Validation loss: 2.286288415232012

Epoch: 5| Step: 4
Training loss: 2.83785080909729
Validation loss: 2.2755594638086136

Epoch: 5| Step: 5
Training loss: 1.326448678970337
Validation loss: 2.283843401939638

Epoch: 5| Step: 6
Training loss: 2.40228009223938
Validation loss: 2.2841005607317855

Epoch: 5| Step: 7
Training loss: 2.8578293323516846
Validation loss: 2.277292133659445

Epoch: 5| Step: 8
Training loss: 2.8706066608428955
Validation loss: 2.28461395284181

Epoch: 5| Step: 9
Training loss: 2.6938443183898926
Validation loss: 2.28443915613236

Epoch: 5| Step: 10
Training loss: 2.8321704864501953
Validation loss: 2.296813531588483

Epoch: 115| Step: 0
Training loss: 2.4867055416107178
Validation loss: 2.2853511328338296

Epoch: 5| Step: 1
Training loss: 3.0688204765319824
Validation loss: 2.3069290537987985

Epoch: 5| Step: 2
Training loss: 2.1189656257629395
Validation loss: 2.303098109460646

Epoch: 5| Step: 3
Training loss: 2.610814332962036
Validation loss: 2.3120390394682526

Epoch: 5| Step: 4
Training loss: 1.9310983419418335
Validation loss: 2.292846223359467

Epoch: 5| Step: 5
Training loss: 2.946357011795044
Validation loss: 2.2950528103818177

Epoch: 5| Step: 6
Training loss: 2.1731622219085693
Validation loss: 2.292643754712997

Epoch: 5| Step: 7
Training loss: 2.687471866607666
Validation loss: 2.2975118134611394

Epoch: 5| Step: 8
Training loss: 2.4563136100769043
Validation loss: 2.3104582935251217

Epoch: 5| Step: 9
Training loss: 3.240318775177002
Validation loss: 2.3034974169987503

Epoch: 5| Step: 10
Training loss: 2.287038564682007
Validation loss: 2.2991575400034585

Epoch: 116| Step: 0
Training loss: 1.954808235168457
Validation loss: 2.2792095445817515

Epoch: 5| Step: 1
Training loss: 2.193025588989258
Validation loss: 2.2791488042441745

Epoch: 5| Step: 2
Training loss: 2.481415033340454
Validation loss: 2.2777715421492055

Epoch: 5| Step: 3
Training loss: 2.4986748695373535
Validation loss: 2.2745770318533785

Epoch: 5| Step: 4
Training loss: 2.0658318996429443
Validation loss: 2.284958835571043

Epoch: 5| Step: 5
Training loss: 3.1270973682403564
Validation loss: 2.28865417357414

Epoch: 5| Step: 6
Training loss: 2.2303972244262695
Validation loss: 2.296325647702781

Epoch: 5| Step: 7
Training loss: 3.290775775909424
Validation loss: 2.297142449245658

Epoch: 5| Step: 8
Training loss: 2.5254223346710205
Validation loss: 2.292972549315422

Epoch: 5| Step: 9
Training loss: 2.595440626144409
Validation loss: 2.2725089801255094

Epoch: 5| Step: 10
Training loss: 3.189786195755005
Validation loss: 2.2680957317352295

Epoch: 117| Step: 0
Training loss: 1.8393638134002686
Validation loss: 2.265917626760339

Epoch: 5| Step: 1
Training loss: 2.888472318649292
Validation loss: 2.271753111193257

Epoch: 5| Step: 2
Training loss: 2.659364700317383
Validation loss: 2.264412654343472

Epoch: 5| Step: 3
Training loss: 2.6604573726654053
Validation loss: 2.271066391339866

Epoch: 5| Step: 4
Training loss: 2.813296318054199
Validation loss: 2.272163660295548

Epoch: 5| Step: 5
Training loss: 2.2029623985290527
Validation loss: 2.2875291403903755

Epoch: 5| Step: 6
Training loss: 2.7697701454162598
Validation loss: 2.2858773585288756

Epoch: 5| Step: 7
Training loss: 2.613410234451294
Validation loss: 2.302796512521723

Epoch: 5| Step: 8
Training loss: 2.0358729362487793
Validation loss: 2.3062714146029566

Epoch: 5| Step: 9
Training loss: 2.8687679767608643
Validation loss: 2.311842715868386

Epoch: 5| Step: 10
Training loss: 2.805018186569214
Validation loss: 2.3054076715182235

Epoch: 118| Step: 0
Training loss: 2.4342637062072754
Validation loss: 2.3272850718549503

Epoch: 5| Step: 1
Training loss: 2.5455286502838135
Validation loss: 2.3150443979488906

Epoch: 5| Step: 2
Training loss: 2.549931049346924
Validation loss: 2.3222830141744306

Epoch: 5| Step: 3
Training loss: 2.5537734031677246
Validation loss: 2.308816191970661

Epoch: 5| Step: 4
Training loss: 2.3090076446533203
Validation loss: 2.290480198398713

Epoch: 5| Step: 5
Training loss: 2.6475729942321777
Validation loss: 2.270507950936594

Epoch: 5| Step: 6
Training loss: 2.4788174629211426
Validation loss: 2.273265464331514

Epoch: 5| Step: 7
Training loss: 2.9468624591827393
Validation loss: 2.26652556080972

Epoch: 5| Step: 8
Training loss: 2.832482099533081
Validation loss: 2.2631081791334253

Epoch: 5| Step: 9
Training loss: 2.3024792671203613
Validation loss: 2.2626979043406825

Epoch: 5| Step: 10
Training loss: 2.4146130084991455
Validation loss: 2.271242851852089

Epoch: 119| Step: 0
Training loss: 2.580277681350708
Validation loss: 2.289776272671197

Epoch: 5| Step: 1
Training loss: 2.7856781482696533
Validation loss: 2.317920489977765

Epoch: 5| Step: 2
Training loss: 2.612191677093506
Validation loss: 2.3344561951134795

Epoch: 5| Step: 3
Training loss: 2.1442508697509766
Validation loss: 2.3118853030666227

Epoch: 5| Step: 4
Training loss: 3.2146172523498535
Validation loss: 2.3060812616860993

Epoch: 5| Step: 5
Training loss: 2.8177552223205566
Validation loss: 2.2878974253131497

Epoch: 5| Step: 6
Training loss: 2.095154285430908
Validation loss: 2.2765412663900726

Epoch: 5| Step: 7
Training loss: 2.589777946472168
Validation loss: 2.2641119956970215

Epoch: 5| Step: 8
Training loss: 2.6730754375457764
Validation loss: 2.2639975265790055

Epoch: 5| Step: 9
Training loss: 2.05525279045105
Validation loss: 2.2630647254246536

Epoch: 5| Step: 10
Training loss: 2.5603089332580566
Validation loss: 2.2694380539719776

Epoch: 120| Step: 0
Training loss: 2.5245418548583984
Validation loss: 2.272120039950135

Epoch: 5| Step: 1
Training loss: 2.6966423988342285
Validation loss: 2.2757383674703617

Epoch: 5| Step: 2
Training loss: 2.677093982696533
Validation loss: 2.2783108654842583

Epoch: 5| Step: 3
Training loss: 2.499974250793457
Validation loss: 2.278658664354714

Epoch: 5| Step: 4
Training loss: 2.6095168590545654
Validation loss: 2.282726228878062

Epoch: 5| Step: 5
Training loss: 1.9474674463272095
Validation loss: 2.2888373431339057

Epoch: 5| Step: 6
Training loss: 2.6996512413024902
Validation loss: 2.2830085369848434

Epoch: 5| Step: 7
Training loss: 2.0421993732452393
Validation loss: 2.2880268968561643

Epoch: 5| Step: 8
Training loss: 3.321866512298584
Validation loss: 2.292886300753522

Epoch: 5| Step: 9
Training loss: 2.70929217338562
Validation loss: 2.2892186616056707

Epoch: 5| Step: 10
Training loss: 2.1932997703552246
Validation loss: 2.3034920589898222

Epoch: 121| Step: 0
Training loss: 2.13246488571167
Validation loss: 2.3128347140486523

Epoch: 5| Step: 1
Training loss: 2.4805662631988525
Validation loss: 2.306568614898189

Epoch: 5| Step: 2
Training loss: 2.27052640914917
Validation loss: 2.3208976894296627

Epoch: 5| Step: 3
Training loss: 2.325153350830078
Validation loss: 2.3222919253892798

Epoch: 5| Step: 4
Training loss: 2.7208850383758545
Validation loss: 2.3364785076469503

Epoch: 5| Step: 5
Training loss: 3.0562903881073
Validation loss: 2.3318454680904264

Epoch: 5| Step: 6
Training loss: 3.19920015335083
Validation loss: 2.3025670205393145

Epoch: 5| Step: 7
Training loss: 2.863832712173462
Validation loss: 2.2813228843032674

Epoch: 5| Step: 8
Training loss: 1.8504174947738647
Validation loss: 2.2765578134085542

Epoch: 5| Step: 9
Training loss: 2.2161879539489746
Validation loss: 2.2698570246337564

Epoch: 5| Step: 10
Training loss: 2.9483203887939453
Validation loss: 2.257569989850444

Epoch: 122| Step: 0
Training loss: 2.7335190773010254
Validation loss: 2.2618140738497496

Epoch: 5| Step: 1
Training loss: 2.2256436347961426
Validation loss: 2.266401724148822

Epoch: 5| Step: 2
Training loss: 2.1725046634674072
Validation loss: 2.270340495212104

Epoch: 5| Step: 3
Training loss: 2.8186681270599365
Validation loss: 2.2847675559341267

Epoch: 5| Step: 4
Training loss: 2.0612130165100098
Validation loss: 2.294291119421682

Epoch: 5| Step: 5
Training loss: 3.099522113800049
Validation loss: 2.2822691394436743

Epoch: 5| Step: 6
Training loss: 2.348857879638672
Validation loss: 2.2709268344345914

Epoch: 5| Step: 7
Training loss: 2.654961109161377
Validation loss: 2.2688451787476898

Epoch: 5| Step: 8
Training loss: 2.8137707710266113
Validation loss: 2.2677167615582867

Epoch: 5| Step: 9
Training loss: 2.311704158782959
Validation loss: 2.2719115826391403

Epoch: 5| Step: 10
Training loss: 2.884345769882202
Validation loss: 2.266873595535114

Epoch: 123| Step: 0
Training loss: 2.421967029571533
Validation loss: 2.273164922191251

Epoch: 5| Step: 1
Training loss: 2.4316155910491943
Validation loss: 2.282907327016195

Epoch: 5| Step: 2
Training loss: 3.4798309803009033
Validation loss: 2.278040437288182

Epoch: 5| Step: 3
Training loss: 2.532522201538086
Validation loss: 2.2801094388449066

Epoch: 5| Step: 4
Training loss: 2.36006498336792
Validation loss: 2.2894070135649813

Epoch: 5| Step: 5
Training loss: 1.9927332401275635
Validation loss: 2.282696162500689

Epoch: 5| Step: 6
Training loss: 2.567579507827759
Validation loss: 2.267670267371721

Epoch: 5| Step: 7
Training loss: 2.413034200668335
Validation loss: 2.265236908389676

Epoch: 5| Step: 8
Training loss: 2.4037654399871826
Validation loss: 2.265401309536349

Epoch: 5| Step: 9
Training loss: 2.4956579208374023
Validation loss: 2.277028473474646

Epoch: 5| Step: 10
Training loss: 2.8515377044677734
Validation loss: 2.276603598748484

Epoch: 124| Step: 0
Training loss: 2.3482203483581543
Validation loss: 2.276176325736507

Epoch: 5| Step: 1
Training loss: 2.6953253746032715
Validation loss: 2.280393405627179

Epoch: 5| Step: 2
Training loss: 2.541079044342041
Validation loss: 2.277085458078692

Epoch: 5| Step: 3
Training loss: 2.4031360149383545
Validation loss: 2.28764440936427

Epoch: 5| Step: 4
Training loss: 2.823094606399536
Validation loss: 2.281661116948692

Epoch: 5| Step: 5
Training loss: 2.956566333770752
Validation loss: 2.2841869772121473

Epoch: 5| Step: 6
Training loss: 2.2870049476623535
Validation loss: 2.27303506225668

Epoch: 5| Step: 7
Training loss: 2.1724891662597656
Validation loss: 2.281743908441195

Epoch: 5| Step: 8
Training loss: 2.9981822967529297
Validation loss: 2.3154334047789216

Epoch: 5| Step: 9
Training loss: 2.6548609733581543
Validation loss: 2.3330783972176175

Epoch: 5| Step: 10
Training loss: 1.969726800918579
Validation loss: 2.347320629704383

Epoch: 125| Step: 0
Training loss: 2.226444959640503
Validation loss: 2.301587002251738

Epoch: 5| Step: 1
Training loss: 2.9552645683288574
Validation loss: 2.2758901657596713

Epoch: 5| Step: 2
Training loss: 3.04771089553833
Validation loss: 2.284504162367954

Epoch: 5| Step: 3
Training loss: 2.569742202758789
Validation loss: 2.299676097849364

Epoch: 5| Step: 4
Training loss: 2.491100788116455
Validation loss: 2.309944978324316

Epoch: 5| Step: 5
Training loss: 2.520512104034424
Validation loss: 2.3057042065487114

Epoch: 5| Step: 6
Training loss: 2.397416591644287
Validation loss: 2.3012759608607136

Epoch: 5| Step: 7
Training loss: 2.325592279434204
Validation loss: 2.2897615868558168

Epoch: 5| Step: 8
Training loss: 2.9533305168151855
Validation loss: 2.2832978745942474

Epoch: 5| Step: 9
Training loss: 2.4327473640441895
Validation loss: 2.2740676992683

Epoch: 5| Step: 10
Training loss: 1.9469135999679565
Validation loss: 2.2713774378581713

Epoch: 126| Step: 0
Training loss: 2.458641767501831
Validation loss: 2.2719907683710896

Epoch: 5| Step: 1
Training loss: 2.865623950958252
Validation loss: 2.2768963524090347

Epoch: 5| Step: 2
Training loss: 2.8043558597564697
Validation loss: 2.2748611537359094

Epoch: 5| Step: 3
Training loss: 2.6572728157043457
Validation loss: 2.2763391476805492

Epoch: 5| Step: 4
Training loss: 2.2818379402160645
Validation loss: 2.2888869034346713

Epoch: 5| Step: 5
Training loss: 2.697917938232422
Validation loss: 2.282618520080402

Epoch: 5| Step: 6
Training loss: 1.847450613975525
Validation loss: 2.301414430782359

Epoch: 5| Step: 7
Training loss: 2.5085530281066895
Validation loss: 2.3187689627370527

Epoch: 5| Step: 8
Training loss: 2.7614665031433105
Validation loss: 2.330993511343515

Epoch: 5| Step: 9
Training loss: 2.1691038608551025
Validation loss: 2.31667592704937

Epoch: 5| Step: 10
Training loss: 2.720768690109253
Validation loss: 2.307661392355478

Epoch: 127| Step: 0
Training loss: 2.9788100719451904
Validation loss: 2.280301199164442

Epoch: 5| Step: 1
Training loss: 2.2946555614471436
Validation loss: 2.2737138450786634

Epoch: 5| Step: 2
Training loss: 2.307238817214966
Validation loss: 2.249622206534109

Epoch: 5| Step: 3
Training loss: 2.244201898574829
Validation loss: 2.2501042504464426

Epoch: 5| Step: 4
Training loss: 2.3829445838928223
Validation loss: 2.237235774276077

Epoch: 5| Step: 5
Training loss: 2.0585896968841553
Validation loss: 2.248324001989057

Epoch: 5| Step: 6
Training loss: 2.923954963684082
Validation loss: 2.249457323422996

Epoch: 5| Step: 7
Training loss: 2.213413953781128
Validation loss: 2.2468361623825563

Epoch: 5| Step: 8
Training loss: 3.4364635944366455
Validation loss: 2.270609439060252

Epoch: 5| Step: 9
Training loss: 2.5803568363189697
Validation loss: 2.2770731244035947

Epoch: 5| Step: 10
Training loss: 2.247779130935669
Validation loss: 2.284410097265756

Epoch: 128| Step: 0
Training loss: 2.569878339767456
Validation loss: 2.3013240778318016

Epoch: 5| Step: 1
Training loss: 2.099813938140869
Validation loss: 2.311938690882857

Epoch: 5| Step: 2
Training loss: 2.589150905609131
Validation loss: 2.321033449583156

Epoch: 5| Step: 3
Training loss: 2.6103572845458984
Validation loss: 2.3107524482152795

Epoch: 5| Step: 4
Training loss: 2.4938457012176514
Validation loss: 2.262922861242807

Epoch: 5| Step: 5
Training loss: 2.1596291065216064
Validation loss: 2.2482209333809475

Epoch: 5| Step: 6
Training loss: 2.8300621509552
Validation loss: 2.236836943575131

Epoch: 5| Step: 7
Training loss: 2.8521666526794434
Validation loss: 2.238519089196318

Epoch: 5| Step: 8
Training loss: 2.6159894466400146
Validation loss: 2.2438563787808983

Epoch: 5| Step: 9
Training loss: 2.536320924758911
Validation loss: 2.24861059393934

Epoch: 5| Step: 10
Training loss: 2.3108181953430176
Validation loss: 2.252549453448224

Epoch: 129| Step: 0
Training loss: 2.8167030811309814
Validation loss: 2.2539834437831754

Epoch: 5| Step: 1
Training loss: 2.9716367721557617
Validation loss: 2.2571356219630085

Epoch: 5| Step: 2
Training loss: 2.9716897010803223
Validation loss: 2.2555193183242634

Epoch: 5| Step: 3
Training loss: 2.5047214031219482
Validation loss: 2.245323483661939

Epoch: 5| Step: 4
Training loss: 2.422452449798584
Validation loss: 2.246129079531598

Epoch: 5| Step: 5
Training loss: 1.8000612258911133
Validation loss: 2.2433043397882932

Epoch: 5| Step: 6
Training loss: 2.3301808834075928
Validation loss: 2.236551897500151

Epoch: 5| Step: 7
Training loss: 2.1979877948760986
Validation loss: 2.2452701240457515

Epoch: 5| Step: 8
Training loss: 2.161881923675537
Validation loss: 2.2525737772705736

Epoch: 5| Step: 9
Training loss: 2.9249653816223145
Validation loss: 2.2807877435479114

Epoch: 5| Step: 10
Training loss: 2.6865620613098145
Validation loss: 2.3069840451722503

Epoch: 130| Step: 0
Training loss: 2.0574021339416504
Validation loss: 2.30858765878985

Epoch: 5| Step: 1
Training loss: 2.6152186393737793
Validation loss: 2.323532227546938

Epoch: 5| Step: 2
Training loss: 2.688997268676758
Validation loss: 2.324026979425902

Epoch: 5| Step: 3
Training loss: 2.309569835662842
Validation loss: 2.317819292827319

Epoch: 5| Step: 4
Training loss: 2.485649824142456
Validation loss: 2.293956459209483

Epoch: 5| Step: 5
Training loss: 2.767439365386963
Validation loss: 2.2686710921666955

Epoch: 5| Step: 6
Training loss: 2.359123468399048
Validation loss: 2.2507900627710486

Epoch: 5| Step: 7
Training loss: 2.392843723297119
Validation loss: 2.2333874779362834

Epoch: 5| Step: 8
Training loss: 2.4746575355529785
Validation loss: 2.2341822526788198

Epoch: 5| Step: 9
Training loss: 2.8493034839630127
Validation loss: 2.2259048159404466

Epoch: 5| Step: 10
Training loss: 2.638406753540039
Validation loss: 2.234712685308149

Epoch: 131| Step: 0
Training loss: 2.283527135848999
Validation loss: 2.237706261296426

Epoch: 5| Step: 1
Training loss: 2.5540664196014404
Validation loss: 2.2308618227640786

Epoch: 5| Step: 2
Training loss: 2.3823723793029785
Validation loss: 2.2357639215325795

Epoch: 5| Step: 3
Training loss: 3.02960467338562
Validation loss: 2.249971894807713

Epoch: 5| Step: 4
Training loss: 2.467712640762329
Validation loss: 2.2449296597511537

Epoch: 5| Step: 5
Training loss: 2.8163833618164062
Validation loss: 2.255362897790888

Epoch: 5| Step: 6
Training loss: 2.2431538105010986
Validation loss: 2.250380940334771

Epoch: 5| Step: 7
Training loss: 2.395143508911133
Validation loss: 2.2429084316376717

Epoch: 5| Step: 8
Training loss: 1.7300150394439697
Validation loss: 2.23697260502846

Epoch: 5| Step: 9
Training loss: 2.8375084400177
Validation loss: 2.2369942934282365

Epoch: 5| Step: 10
Training loss: 2.7326107025146484
Validation loss: 2.234633602121825

Epoch: 132| Step: 0
Training loss: 2.463391065597534
Validation loss: 2.235799915047102

Epoch: 5| Step: 1
Training loss: 2.60467529296875
Validation loss: 2.2377670734159407

Epoch: 5| Step: 2
Training loss: 2.358396530151367
Validation loss: 2.244396307135141

Epoch: 5| Step: 3
Training loss: 2.4515395164489746
Validation loss: 2.247420410956106

Epoch: 5| Step: 4
Training loss: 2.5110175609588623
Validation loss: 2.2546431736279557

Epoch: 5| Step: 5
Training loss: 1.7807016372680664
Validation loss: 2.2541338769338464

Epoch: 5| Step: 6
Training loss: 2.5169436931610107
Validation loss: 2.2778856985030638

Epoch: 5| Step: 7
Training loss: 2.7399096488952637
Validation loss: 2.2652365904982372

Epoch: 5| Step: 8
Training loss: 2.747666120529175
Validation loss: 2.2624287041284705

Epoch: 5| Step: 9
Training loss: 2.543402671813965
Validation loss: 2.248564632990027

Epoch: 5| Step: 10
Training loss: 2.7953901290893555
Validation loss: 2.244818672057121

Epoch: 133| Step: 0
Training loss: 2.6521620750427246
Validation loss: 2.232028107489309

Epoch: 5| Step: 1
Training loss: 2.1929409503936768
Validation loss: 2.2344136686735254

Epoch: 5| Step: 2
Training loss: 2.723540782928467
Validation loss: 2.2290811051604567

Epoch: 5| Step: 3
Training loss: 2.3947410583496094
Validation loss: 2.231882501673955

Epoch: 5| Step: 4
Training loss: 2.3684403896331787
Validation loss: 2.23862551617366

Epoch: 5| Step: 5
Training loss: 2.5022990703582764
Validation loss: 2.2465288280158915

Epoch: 5| Step: 6
Training loss: 2.744741916656494
Validation loss: 2.258582240791731

Epoch: 5| Step: 7
Training loss: 2.4999706745147705
Validation loss: 2.278308932499219

Epoch: 5| Step: 8
Training loss: 2.081078052520752
Validation loss: 2.313775804734999

Epoch: 5| Step: 9
Training loss: 3.0342860221862793
Validation loss: 2.3107417578338296

Epoch: 5| Step: 10
Training loss: 2.5140128135681152
Validation loss: 2.3216226716195383

Epoch: 134| Step: 0
Training loss: 2.447380542755127
Validation loss: 2.2920394456514748

Epoch: 5| Step: 1
Training loss: 2.7541401386260986
Validation loss: 2.26801291588814

Epoch: 5| Step: 2
Training loss: 2.678253173828125
Validation loss: 2.2510356236529607

Epoch: 5| Step: 3
Training loss: 2.039114475250244
Validation loss: 2.2405718577805387

Epoch: 5| Step: 4
Training loss: 2.48260760307312
Validation loss: 2.2398507518153035

Epoch: 5| Step: 5
Training loss: 2.205991268157959
Validation loss: 2.2402789772197766

Epoch: 5| Step: 6
Training loss: 2.6759254932403564
Validation loss: 2.2379709597556823

Epoch: 5| Step: 7
Training loss: 2.3874244689941406
Validation loss: 2.2243246416891775

Epoch: 5| Step: 8
Training loss: 2.629805088043213
Validation loss: 2.22274370860028

Epoch: 5| Step: 9
Training loss: 2.3813083171844482
Validation loss: 2.2225505023874264

Epoch: 5| Step: 10
Training loss: 2.7054567337036133
Validation loss: 2.221908066862373

Epoch: 135| Step: 0
Training loss: 2.5735065937042236
Validation loss: 2.2189280730421825

Epoch: 5| Step: 1
Training loss: 2.272674322128296
Validation loss: 2.2210845998538438

Epoch: 5| Step: 2
Training loss: 2.4749205112457275
Validation loss: 2.2202948806106404

Epoch: 5| Step: 3
Training loss: 2.6174817085266113
Validation loss: 2.223224752692766

Epoch: 5| Step: 4
Training loss: 2.407325029373169
Validation loss: 2.2373714818749377

Epoch: 5| Step: 5
Training loss: 2.9702975749969482
Validation loss: 2.2522348665422007

Epoch: 5| Step: 6
Training loss: 1.8737338781356812
Validation loss: 2.248390829691323

Epoch: 5| Step: 7
Training loss: 2.215768337249756
Validation loss: 2.2491216608273086

Epoch: 5| Step: 8
Training loss: 2.9929165840148926
Validation loss: 2.247413473744546

Epoch: 5| Step: 9
Training loss: 2.5185887813568115
Validation loss: 2.2530675729115806

Epoch: 5| Step: 10
Training loss: 2.464613437652588
Validation loss: 2.2355215472559773

Epoch: 136| Step: 0
Training loss: 2.310462474822998
Validation loss: 2.2157601259088002

Epoch: 5| Step: 1
Training loss: 3.3816800117492676
Validation loss: 2.2127733717682543

Epoch: 5| Step: 2
Training loss: 2.336921215057373
Validation loss: 2.2034591782477593

Epoch: 5| Step: 3
Training loss: 2.5553038120269775
Validation loss: 2.206958927134032

Epoch: 5| Step: 4
Training loss: 2.202387571334839
Validation loss: 2.2083020851176274

Epoch: 5| Step: 5
Training loss: 2.63757586479187
Validation loss: 2.208513823888635

Epoch: 5| Step: 6
Training loss: 2.132962942123413
Validation loss: 2.2061656982667985

Epoch: 5| Step: 7
Training loss: 2.7790675163269043
Validation loss: 2.2106097308538293

Epoch: 5| Step: 8
Training loss: 2.6233367919921875
Validation loss: 2.2279994333944013

Epoch: 5| Step: 9
Training loss: 1.9906322956085205
Validation loss: 2.243287568451256

Epoch: 5| Step: 10
Training loss: 2.545442819595337
Validation loss: 2.2480257788012104

Epoch: 137| Step: 0
Training loss: 2.2281699180603027
Validation loss: 2.2309913583981094

Epoch: 5| Step: 1
Training loss: 2.5480823516845703
Validation loss: 2.2374031441186064

Epoch: 5| Step: 2
Training loss: 2.536769390106201
Validation loss: 2.2313508295243785

Epoch: 5| Step: 3
Training loss: 2.8187942504882812
Validation loss: 2.2281704205338673

Epoch: 5| Step: 4
Training loss: 2.4938437938690186
Validation loss: 2.2270423596905125

Epoch: 5| Step: 5
Training loss: 2.6839065551757812
Validation loss: 2.2252895191151607

Epoch: 5| Step: 6
Training loss: 2.4351649284362793
Validation loss: 2.2246673619875343

Epoch: 5| Step: 7
Training loss: 2.5457046031951904
Validation loss: 2.224345350778231

Epoch: 5| Step: 8
Training loss: 2.596360683441162
Validation loss: 2.2296461571929274

Epoch: 5| Step: 9
Training loss: 2.518266201019287
Validation loss: 2.2270389064665763

Epoch: 5| Step: 10
Training loss: 1.8125064373016357
Validation loss: 2.2367003040928997

Epoch: 138| Step: 0
Training loss: 2.150020122528076
Validation loss: 2.2268722685434486

Epoch: 5| Step: 1
Training loss: 3.0699355602264404
Validation loss: 2.225280164390482

Epoch: 5| Step: 2
Training loss: 2.6347126960754395
Validation loss: 2.214912522223688

Epoch: 5| Step: 3
Training loss: 1.960580825805664
Validation loss: 2.221816638464569

Epoch: 5| Step: 4
Training loss: 2.3552234172821045
Validation loss: 2.2122598335307133

Epoch: 5| Step: 5
Training loss: 2.5619943141937256
Validation loss: 2.2062952492826726

Epoch: 5| Step: 6
Training loss: 2.359736442565918
Validation loss: 2.206301712220715

Epoch: 5| Step: 7
Training loss: 1.9973104000091553
Validation loss: 2.2130041327527774

Epoch: 5| Step: 8
Training loss: 2.415567398071289
Validation loss: 2.210238733599263

Epoch: 5| Step: 9
Training loss: 2.935791492462158
Validation loss: 2.211864963654549

Epoch: 5| Step: 10
Training loss: 3.037590742111206
Validation loss: 2.217664836555399

Epoch: 139| Step: 0
Training loss: 2.1388392448425293
Validation loss: 2.223401354205224

Epoch: 5| Step: 1
Training loss: 3.456676483154297
Validation loss: 2.2536763119441208

Epoch: 5| Step: 2
Training loss: 2.155003786087036
Validation loss: 2.256518269097933

Epoch: 5| Step: 3
Training loss: 2.209855794906616
Validation loss: 2.2719900428607898

Epoch: 5| Step: 4
Training loss: 3.0367891788482666
Validation loss: 2.2760755477413053

Epoch: 5| Step: 5
Training loss: 1.9279228448867798
Validation loss: 2.2783416394264466

Epoch: 5| Step: 6
Training loss: 2.5543155670166016
Validation loss: 2.271913231060069

Epoch: 5| Step: 7
Training loss: 2.2633674144744873
Validation loss: 2.265245804222681

Epoch: 5| Step: 8
Training loss: 2.4804341793060303
Validation loss: 2.250008234413721

Epoch: 5| Step: 9
Training loss: 2.846327066421509
Validation loss: 2.232969476330665

Epoch: 5| Step: 10
Training loss: 2.126829147338867
Validation loss: 2.220232968689293

Epoch: 140| Step: 0
Training loss: 2.2063546180725098
Validation loss: 2.2251896794124315

Epoch: 5| Step: 1
Training loss: 2.829007148742676
Validation loss: 2.2274336302152244

Epoch: 5| Step: 2
Training loss: 2.6516034603118896
Validation loss: 2.226471593303065

Epoch: 5| Step: 3
Training loss: 2.6136224269866943
Validation loss: 2.237469603938441

Epoch: 5| Step: 4
Training loss: 2.383100986480713
Validation loss: 2.247897626251303

Epoch: 5| Step: 5
Training loss: 2.7007699012756348
Validation loss: 2.245077489524759

Epoch: 5| Step: 6
Training loss: 2.5222115516662598
Validation loss: 2.2422110906211277

Epoch: 5| Step: 7
Training loss: 1.8990923166275024
Validation loss: 2.2464184017591577

Epoch: 5| Step: 8
Training loss: 1.8275468349456787
Validation loss: 2.2569748970770065

Epoch: 5| Step: 9
Training loss: 2.7474522590637207
Validation loss: 2.2743006342200824

Epoch: 5| Step: 10
Training loss: 2.96772837638855
Validation loss: 2.2912796274308236

Epoch: 141| Step: 0
Training loss: 2.1652565002441406
Validation loss: 2.2814657188230947

Epoch: 5| Step: 1
Training loss: 2.3690826892852783
Validation loss: 2.2637282571484967

Epoch: 5| Step: 2
Training loss: 2.9482789039611816
Validation loss: 2.223727112175316

Epoch: 5| Step: 3
Training loss: 2.115168333053589
Validation loss: 2.201716284598074

Epoch: 5| Step: 4
Training loss: 1.7768309116363525
Validation loss: 2.1994987405756468

Epoch: 5| Step: 5
Training loss: 2.5273005962371826
Validation loss: 2.1822209435124553

Epoch: 5| Step: 6
Training loss: 2.2497448921203613
Validation loss: 2.189047614733378

Epoch: 5| Step: 7
Training loss: 2.0332884788513184
Validation loss: 2.1859319697144213

Epoch: 5| Step: 8
Training loss: 3.1990551948547363
Validation loss: 2.1914509598926832

Epoch: 5| Step: 9
Training loss: 2.98559308052063
Validation loss: 2.1892070385717575

Epoch: 5| Step: 10
Training loss: 3.2443206310272217
Validation loss: 2.1927085204791

Epoch: 142| Step: 0
Training loss: 2.4663567543029785
Validation loss: 2.1924668076217815

Epoch: 5| Step: 1
Training loss: 2.2587597370147705
Validation loss: 2.2042918948717016

Epoch: 5| Step: 2
Training loss: 2.643202304840088
Validation loss: 2.207706497561547

Epoch: 5| Step: 3
Training loss: 2.823438882827759
Validation loss: 2.2055956753351356

Epoch: 5| Step: 4
Training loss: 2.365931272506714
Validation loss: 2.1977152901311077

Epoch: 5| Step: 5
Training loss: 2.517672300338745
Validation loss: 2.2067075647333616

Epoch: 5| Step: 6
Training loss: 2.6812844276428223
Validation loss: 2.218523463895244

Epoch: 5| Step: 7
Training loss: 2.930262804031372
Validation loss: 2.2150371395131594

Epoch: 5| Step: 8
Training loss: 2.910473585128784
Validation loss: 2.2215168783741612

Epoch: 5| Step: 9
Training loss: 2.0083441734313965
Validation loss: 2.210483261333999

Epoch: 5| Step: 10
Training loss: 1.567278265953064
Validation loss: 2.2011459386476906

Epoch: 143| Step: 0
Training loss: 2.442629098892212
Validation loss: 2.239723792640112

Epoch: 5| Step: 1
Training loss: 2.697908878326416
Validation loss: 2.2804505850679133

Epoch: 5| Step: 2
Training loss: 3.2148537635803223
Validation loss: 2.2989154272182013

Epoch: 5| Step: 3
Training loss: 1.8615257740020752
Validation loss: 2.3288971659957722

Epoch: 5| Step: 4
Training loss: 2.092170000076294
Validation loss: 2.3289746007611676

Epoch: 5| Step: 5
Training loss: 2.512629985809326
Validation loss: 2.3332421087449595

Epoch: 5| Step: 6
Training loss: 2.6158344745635986
Validation loss: 2.2877084465437036

Epoch: 5| Step: 7
Training loss: 2.653888463973999
Validation loss: 2.2267974884279313

Epoch: 5| Step: 8
Training loss: 2.248394727706909
Validation loss: 2.2018579847069195

Epoch: 5| Step: 9
Training loss: 2.6673014163970947
Validation loss: 2.2061149945823093

Epoch: 5| Step: 10
Training loss: 2.712994337081909
Validation loss: 2.2243207603372555

Epoch: 144| Step: 0
Training loss: 3.113511562347412
Validation loss: 2.222509499519102

Epoch: 5| Step: 1
Training loss: 2.7217588424682617
Validation loss: 2.2045838948219054

Epoch: 5| Step: 2
Training loss: 2.842404365539551
Validation loss: 2.1957875797825475

Epoch: 5| Step: 3
Training loss: 2.1709790229797363
Validation loss: 2.1907341480255127

Epoch: 5| Step: 4
Training loss: 2.6231517791748047
Validation loss: 2.1885982149390766

Epoch: 5| Step: 5
Training loss: 2.7980682849884033
Validation loss: 2.1984260338608936

Epoch: 5| Step: 6
Training loss: 1.7744004726409912
Validation loss: 2.213855330662061

Epoch: 5| Step: 7
Training loss: 2.4715347290039062
Validation loss: 2.235999427815919

Epoch: 5| Step: 8
Training loss: 2.361499786376953
Validation loss: 2.2544679462268786

Epoch: 5| Step: 9
Training loss: 2.4013137817382812
Validation loss: 2.2687408488283873

Epoch: 5| Step: 10
Training loss: 2.078017234802246
Validation loss: 2.2566971496869157

Epoch: 145| Step: 0
Training loss: 1.8924672603607178
Validation loss: 2.245562732860606

Epoch: 5| Step: 1
Training loss: 2.428309202194214
Validation loss: 2.2238662447980655

Epoch: 5| Step: 2
Training loss: 2.637233018875122
Validation loss: 2.234036681472614

Epoch: 5| Step: 3
Training loss: 2.096052646636963
Validation loss: 2.220970155090414

Epoch: 5| Step: 4
Training loss: 2.322129726409912
Validation loss: 2.2088712210296304

Epoch: 5| Step: 5
Training loss: 2.3269176483154297
Validation loss: 2.208358477520686

Epoch: 5| Step: 6
Training loss: 2.7705349922180176
Validation loss: 2.2111189378205167

Epoch: 5| Step: 7
Training loss: 2.4508278369903564
Validation loss: 2.197350909633021

Epoch: 5| Step: 8
Training loss: 2.704962968826294
Validation loss: 2.199259176049181

Epoch: 5| Step: 9
Training loss: 2.7157211303710938
Validation loss: 2.203689057339904

Epoch: 5| Step: 10
Training loss: 2.82275390625
Validation loss: 2.1976944195326937

Epoch: 146| Step: 0
Training loss: 1.914457082748413
Validation loss: 2.193800918517574

Epoch: 5| Step: 1
Training loss: 2.3522298336029053
Validation loss: 2.203800878217143

Epoch: 5| Step: 2
Training loss: 2.8193066120147705
Validation loss: 2.205355562189574

Epoch: 5| Step: 3
Training loss: 3.038329601287842
Validation loss: 2.2143721426686933

Epoch: 5| Step: 4
Training loss: 2.1906368732452393
Validation loss: 2.20912233988444

Epoch: 5| Step: 5
Training loss: 1.9254443645477295
Validation loss: 2.2074090947387037

Epoch: 5| Step: 6
Training loss: 2.748692512512207
Validation loss: 2.2146394791141635

Epoch: 5| Step: 7
Training loss: 1.5927425622940063
Validation loss: 2.225730070503809

Epoch: 5| Step: 8
Training loss: 3.23188853263855
Validation loss: 2.2140167836220033

Epoch: 5| Step: 9
Training loss: 2.3444395065307617
Validation loss: 2.227700969224335

Epoch: 5| Step: 10
Training loss: 2.833667755126953
Validation loss: 2.2182893906870196

Epoch: 147| Step: 0
Training loss: 2.9540514945983887
Validation loss: 2.2087864055428454

Epoch: 5| Step: 1
Training loss: 2.036623477935791
Validation loss: 2.2151007985556

Epoch: 5| Step: 2
Training loss: 2.1415603160858154
Validation loss: 2.2209758835454143

Epoch: 5| Step: 3
Training loss: 2.2730720043182373
Validation loss: 2.2198463178450063

Epoch: 5| Step: 4
Training loss: 2.502128839492798
Validation loss: 2.216503404801892

Epoch: 5| Step: 5
Training loss: 2.2676939964294434
Validation loss: 2.2203540289273827

Epoch: 5| Step: 6
Training loss: 2.2183456420898438
Validation loss: 2.2273555186487015

Epoch: 5| Step: 7
Training loss: 2.923548936843872
Validation loss: 2.235844135284424

Epoch: 5| Step: 8
Training loss: 2.9592533111572266
Validation loss: 2.224616483975482

Epoch: 5| Step: 9
Training loss: 2.285773992538452
Validation loss: 2.220180252546905

Epoch: 5| Step: 10
Training loss: 2.371950626373291
Validation loss: 2.2085595310375257

Epoch: 148| Step: 0
Training loss: 1.8903303146362305
Validation loss: 2.2032317384596793

Epoch: 5| Step: 1
Training loss: 2.147334337234497
Validation loss: 2.2084374735432286

Epoch: 5| Step: 2
Training loss: 2.4458096027374268
Validation loss: 2.2016948012895483

Epoch: 5| Step: 3
Training loss: 2.9020848274230957
Validation loss: 2.195548031919746

Epoch: 5| Step: 4
Training loss: 2.4572250843048096
Validation loss: 2.1834076963445193

Epoch: 5| Step: 5
Training loss: 1.8225183486938477
Validation loss: 2.1931519021270094

Epoch: 5| Step: 6
Training loss: 2.9549734592437744
Validation loss: 2.1985279257579515

Epoch: 5| Step: 7
Training loss: 3.6002564430236816
Validation loss: 2.200732672086326

Epoch: 5| Step: 8
Training loss: 1.9404098987579346
Validation loss: 2.193961886949437

Epoch: 5| Step: 9
Training loss: 2.3218166828155518
Validation loss: 2.200624127541819

Epoch: 5| Step: 10
Training loss: 2.4154062271118164
Validation loss: 2.215124355849399

Epoch: 149| Step: 0
Training loss: 2.9311680793762207
Validation loss: 2.208470836762459

Epoch: 5| Step: 1
Training loss: 2.2471249103546143
Validation loss: 2.2057209963439615

Epoch: 5| Step: 2
Training loss: 2.418726921081543
Validation loss: 2.1997205877816803

Epoch: 5| Step: 3
Training loss: 2.4516284465789795
Validation loss: 2.2011949682748444

Epoch: 5| Step: 4
Training loss: 2.247624158859253
Validation loss: 2.199662511066724

Epoch: 5| Step: 5
Training loss: 2.716740131378174
Validation loss: 2.2105273559529293

Epoch: 5| Step: 6
Training loss: 2.496882200241089
Validation loss: 2.224656971552039

Epoch: 5| Step: 7
Training loss: 2.6325347423553467
Validation loss: 2.220572169109057

Epoch: 5| Step: 8
Training loss: 2.80145263671875
Validation loss: 2.2240128337696032

Epoch: 5| Step: 9
Training loss: 2.1219563484191895
Validation loss: 2.222874777291411

Epoch: 5| Step: 10
Training loss: 1.8742790222167969
Validation loss: 2.230939708730226

Epoch: 150| Step: 0
Training loss: 1.8741750717163086
Validation loss: 2.2572640603588474

Epoch: 5| Step: 1
Training loss: 2.2069804668426514
Validation loss: 2.253724221260317

Epoch: 5| Step: 2
Training loss: 3.2008979320526123
Validation loss: 2.2385239216589157

Epoch: 5| Step: 3
Training loss: 2.348811626434326
Validation loss: 2.2169277232180358

Epoch: 5| Step: 4
Training loss: 2.6977028846740723
Validation loss: 2.1811106538259857

Epoch: 5| Step: 5
Training loss: 2.0557711124420166
Validation loss: 2.1771907293668358

Epoch: 5| Step: 6
Training loss: 2.650084972381592
Validation loss: 2.173764077566003

Epoch: 5| Step: 7
Training loss: 2.177860736846924
Validation loss: 2.1835434282979658

Epoch: 5| Step: 8
Training loss: 2.0087814331054688
Validation loss: 2.1810049062134116

Epoch: 5| Step: 9
Training loss: 2.909208297729492
Validation loss: 2.1752627998270015

Epoch: 5| Step: 10
Training loss: 3.1064863204956055
Validation loss: 2.179515047739911

Epoch: 151| Step: 0
Training loss: 2.388784646987915
Validation loss: 2.1785628949442217

Epoch: 5| Step: 1
Training loss: 2.9893624782562256
Validation loss: 2.1848164758374615

Epoch: 5| Step: 2
Training loss: 2.4951746463775635
Validation loss: 2.2002978837618263

Epoch: 5| Step: 3
Training loss: 1.639335036277771
Validation loss: 2.1992620627085366

Epoch: 5| Step: 4
Training loss: 2.137971878051758
Validation loss: 2.2138654878062587

Epoch: 5| Step: 5
Training loss: 2.3983044624328613
Validation loss: 2.245530487388693

Epoch: 5| Step: 6
Training loss: 2.7017459869384766
Validation loss: 2.296804089700022

Epoch: 5| Step: 7
Training loss: 2.7832908630371094
Validation loss: 2.295466676835091

Epoch: 5| Step: 8
Training loss: 2.821985960006714
Validation loss: 2.293156236730596

Epoch: 5| Step: 9
Training loss: 2.5885660648345947
Validation loss: 2.2532239985722367

Epoch: 5| Step: 10
Training loss: 2.222160577774048
Validation loss: 2.2269550446541078

Epoch: 152| Step: 0
Training loss: 1.874607801437378
Validation loss: 2.210745693534933

Epoch: 5| Step: 1
Training loss: 2.3942935466766357
Validation loss: 2.2073481544371574

Epoch: 5| Step: 2
Training loss: 2.090944766998291
Validation loss: 2.2111710092072845

Epoch: 5| Step: 3
Training loss: 2.7985942363739014
Validation loss: 2.2134459339162356

Epoch: 5| Step: 4
Training loss: 2.35860538482666
Validation loss: 2.21624493598938

Epoch: 5| Step: 5
Training loss: 3.097485065460205
Validation loss: 2.2127393676388647

Epoch: 5| Step: 6
Training loss: 2.636803388595581
Validation loss: 2.211393771633025

Epoch: 5| Step: 7
Training loss: 2.5514564514160156
Validation loss: 2.22395182424976

Epoch: 5| Step: 8
Training loss: 2.586280584335327
Validation loss: 2.2225735366985364

Epoch: 5| Step: 9
Training loss: 1.841295599937439
Validation loss: 2.2265768833057855

Epoch: 5| Step: 10
Training loss: 2.6855204105377197
Validation loss: 2.2230791173955446

Epoch: 153| Step: 0
Training loss: 1.860131859779358
Validation loss: 2.219751483650618

Epoch: 5| Step: 1
Training loss: 2.630977153778076
Validation loss: 2.2040563706428773

Epoch: 5| Step: 2
Training loss: 3.4771087169647217
Validation loss: 2.1958012016870643

Epoch: 5| Step: 3
Training loss: 2.3413467407226562
Validation loss: 2.192743996138214

Epoch: 5| Step: 4
Training loss: 2.138026714324951
Validation loss: 2.1830494942203647

Epoch: 5| Step: 5
Training loss: 2.236304521560669
Validation loss: 2.178017689335731

Epoch: 5| Step: 6
Training loss: 1.8858411312103271
Validation loss: 2.182309868515179

Epoch: 5| Step: 7
Training loss: 2.8906967639923096
Validation loss: 2.1883695920308432

Epoch: 5| Step: 8
Training loss: 2.1959073543548584
Validation loss: 2.184772435054984

Epoch: 5| Step: 9
Training loss: 2.2372024059295654
Validation loss: 2.1998371078122045

Epoch: 5| Step: 10
Training loss: 2.697777032852173
Validation loss: 2.192526234093533

Epoch: 154| Step: 0
Training loss: 2.4291272163391113
Validation loss: 2.1890632003866215

Epoch: 5| Step: 1
Training loss: 2.3956916332244873
Validation loss: 2.183932968365249

Epoch: 5| Step: 2
Training loss: 2.4355974197387695
Validation loss: 2.1822592353308075

Epoch: 5| Step: 3
Training loss: 2.7548980712890625
Validation loss: 2.1943331892772386

Epoch: 5| Step: 4
Training loss: 2.3864638805389404
Validation loss: 2.1871707183058544

Epoch: 5| Step: 5
Training loss: 2.1441311836242676
Validation loss: 2.195363913812945

Epoch: 5| Step: 6
Training loss: 1.5202136039733887
Validation loss: 2.1967212000200824

Epoch: 5| Step: 7
Training loss: 2.57368540763855
Validation loss: 2.22445253146592

Epoch: 5| Step: 8
Training loss: 2.935393810272217
Validation loss: 2.194140813683951

Epoch: 5| Step: 9
Training loss: 2.31624174118042
Validation loss: 2.2036963239792855

Epoch: 5| Step: 10
Training loss: 2.907611846923828
Validation loss: 2.187245189502675

Epoch: 155| Step: 0
Training loss: 2.255530595779419
Validation loss: 2.1717403781029487

Epoch: 5| Step: 1
Training loss: 2.5346360206604004
Validation loss: 2.169297343941145

Epoch: 5| Step: 2
Training loss: 2.4202046394348145
Validation loss: 2.161125652251705

Epoch: 5| Step: 3
Training loss: 1.8494688272476196
Validation loss: 2.1596865794991933

Epoch: 5| Step: 4
Training loss: 2.5322628021240234
Validation loss: 2.1683339841904177

Epoch: 5| Step: 5
Training loss: 2.3600218296051025
Validation loss: 2.1634746751477643

Epoch: 5| Step: 6
Training loss: 2.6898858547210693
Validation loss: 2.1772854917792865

Epoch: 5| Step: 7
Training loss: 2.697751760482788
Validation loss: 2.167328526896815

Epoch: 5| Step: 8
Training loss: 2.6009724140167236
Validation loss: 2.173525966623778

Epoch: 5| Step: 9
Training loss: 2.0169804096221924
Validation loss: 2.178929603228005

Epoch: 5| Step: 10
Training loss: 2.832718849182129
Validation loss: 2.185954504115607

Epoch: 156| Step: 0
Training loss: 2.1575005054473877
Validation loss: 2.1942748203072497

Epoch: 5| Step: 1
Training loss: 2.3245842456817627
Validation loss: 2.1799501629285913

Epoch: 5| Step: 2
Training loss: 2.3899426460266113
Validation loss: 2.1795965612575574

Epoch: 5| Step: 3
Training loss: 3.022444486618042
Validation loss: 2.1861296674256683

Epoch: 5| Step: 4
Training loss: 2.790353298187256
Validation loss: 2.1835155512696955

Epoch: 5| Step: 5
Training loss: 1.9473460912704468
Validation loss: 2.1996068569921676

Epoch: 5| Step: 6
Training loss: 1.9404335021972656
Validation loss: 2.182143739474717

Epoch: 5| Step: 7
Training loss: 3.077418804168701
Validation loss: 2.1861670235151887

Epoch: 5| Step: 8
Training loss: 2.0318431854248047
Validation loss: 2.180030261316607

Epoch: 5| Step: 9
Training loss: 2.4396023750305176
Validation loss: 2.193355142429311

Epoch: 5| Step: 10
Training loss: 2.5682239532470703
Validation loss: 2.1908926297259588

Epoch: 157| Step: 0
Training loss: 1.978427529335022
Validation loss: 2.175674766622564

Epoch: 5| Step: 1
Training loss: 2.164038896560669
Validation loss: 2.161520086308961

Epoch: 5| Step: 2
Training loss: 2.911484956741333
Validation loss: 2.1517546715274936

Epoch: 5| Step: 3
Training loss: 2.656395435333252
Validation loss: 2.158610854097592

Epoch: 5| Step: 4
Training loss: 2.543125867843628
Validation loss: 2.1525783231181483

Epoch: 5| Step: 5
Training loss: 2.2197012901306152
Validation loss: 2.1588275894041984

Epoch: 5| Step: 6
Training loss: 2.3581631183624268
Validation loss: 2.162022416309644

Epoch: 5| Step: 7
Training loss: 2.4842045307159424
Validation loss: 2.1580238316648748

Epoch: 5| Step: 8
Training loss: 2.9552199840545654
Validation loss: 2.1769002637555523

Epoch: 5| Step: 9
Training loss: 1.987356424331665
Validation loss: 2.179552734539073

Epoch: 5| Step: 10
Training loss: 2.4184579849243164
Validation loss: 2.2064776882048576

Epoch: 158| Step: 0
Training loss: 2.3129148483276367
Validation loss: 2.240738776422316

Epoch: 5| Step: 1
Training loss: 2.161540985107422
Validation loss: 2.2538827003971225

Epoch: 5| Step: 2
Training loss: 1.3086528778076172
Validation loss: 2.218038164159303

Epoch: 5| Step: 3
Training loss: 2.495422840118408
Validation loss: 2.1979582617359776

Epoch: 5| Step: 4
Training loss: 2.9094300270080566
Validation loss: 2.184369961420695

Epoch: 5| Step: 5
Training loss: 3.0058398246765137
Validation loss: 2.1698445684166363

Epoch: 5| Step: 6
Training loss: 2.9485974311828613
Validation loss: 2.17302530811679

Epoch: 5| Step: 7
Training loss: 1.8883224725723267
Validation loss: 2.1816275606873217

Epoch: 5| Step: 8
Training loss: 2.09710955619812
Validation loss: 2.177017302923305

Epoch: 5| Step: 9
Training loss: 3.0086896419525146
Validation loss: 2.178804684710759

Epoch: 5| Step: 10
Training loss: 2.7465384006500244
Validation loss: 2.1750002522622385

Epoch: 159| Step: 0
Training loss: 1.9995269775390625
Validation loss: 2.1690514908042005

Epoch: 5| Step: 1
Training loss: 2.153115749359131
Validation loss: 2.1724177637407855

Epoch: 5| Step: 2
Training loss: 2.795773983001709
Validation loss: 2.1795178985082977

Epoch: 5| Step: 3
Training loss: 2.673360586166382
Validation loss: 2.191455650073226

Epoch: 5| Step: 4
Training loss: 2.8129734992980957
Validation loss: 2.196313447849725

Epoch: 5| Step: 5
Training loss: 2.2308335304260254
Validation loss: 2.21494436007674

Epoch: 5| Step: 6
Training loss: 2.027527332305908
Validation loss: 2.2325185973157167

Epoch: 5| Step: 7
Training loss: 2.4033186435699463
Validation loss: 2.220431817475186

Epoch: 5| Step: 8
Training loss: 2.6403558254241943
Validation loss: 2.185131715190026

Epoch: 5| Step: 9
Training loss: 2.5306031703948975
Validation loss: 2.1789472615847023

Epoch: 5| Step: 10
Training loss: 2.3794071674346924
Validation loss: 2.171308873802103

Epoch: 160| Step: 0
Training loss: 2.069601535797119
Validation loss: 2.1890211656529415

Epoch: 5| Step: 1
Training loss: 1.9636211395263672
Validation loss: 2.1860024621409755

Epoch: 5| Step: 2
Training loss: 2.732137680053711
Validation loss: 2.192307549138223

Epoch: 5| Step: 3
Training loss: 2.2875168323516846
Validation loss: 2.1963408300953526

Epoch: 5| Step: 4
Training loss: 2.866962194442749
Validation loss: 2.203557792530265

Epoch: 5| Step: 5
Training loss: 2.5553107261657715
Validation loss: 2.202141974561958

Epoch: 5| Step: 6
Training loss: 2.3837122917175293
Validation loss: 2.20647886747955

Epoch: 5| Step: 7
Training loss: 2.30985164642334
Validation loss: 2.213232183969149

Epoch: 5| Step: 8
Training loss: 2.3634140491485596
Validation loss: 2.2143129405154975

Epoch: 5| Step: 9
Training loss: 2.7865960597991943
Validation loss: 2.215634484444895

Epoch: 5| Step: 10
Training loss: 2.378403425216675
Validation loss: 2.2017810267786824

Epoch: 161| Step: 0
Training loss: 2.5062415599823
Validation loss: 2.186075464371712

Epoch: 5| Step: 1
Training loss: 2.416856288909912
Validation loss: 2.153659923102266

Epoch: 5| Step: 2
Training loss: 2.509631872177124
Validation loss: 2.151864351764802

Epoch: 5| Step: 3
Training loss: 2.342909574508667
Validation loss: 2.1424938888959986

Epoch: 5| Step: 4
Training loss: 2.668034315109253
Validation loss: 2.1382103940492034

Epoch: 5| Step: 5
Training loss: 1.8582885265350342
Validation loss: 2.138101867450181

Epoch: 5| Step: 6
Training loss: 2.4607596397399902
Validation loss: 2.13895659805626

Epoch: 5| Step: 7
Training loss: 2.71638822555542
Validation loss: 2.1341791127317693

Epoch: 5| Step: 8
Training loss: 2.7026801109313965
Validation loss: 2.1338952228587162

Epoch: 5| Step: 9
Training loss: 2.0719332695007324
Validation loss: 2.1475210266728557

Epoch: 5| Step: 10
Training loss: 2.521965742111206
Validation loss: 2.1402219367283646

Epoch: 162| Step: 0
Training loss: 2.157982349395752
Validation loss: 2.168228551905642

Epoch: 5| Step: 1
Training loss: 2.412513017654419
Validation loss: 2.1817463674852924

Epoch: 5| Step: 2
Training loss: 2.544156074523926
Validation loss: 2.1803254619721444

Epoch: 5| Step: 3
Training loss: 2.0737175941467285
Validation loss: 2.1931121067334245

Epoch: 5| Step: 4
Training loss: 2.729043483734131
Validation loss: 2.160224158276794

Epoch: 5| Step: 5
Training loss: 2.801950693130493
Validation loss: 2.1652697388843825

Epoch: 5| Step: 6
Training loss: 2.306565523147583
Validation loss: 2.1439699306282947

Epoch: 5| Step: 7
Training loss: 2.683922052383423
Validation loss: 2.1374500233639955

Epoch: 5| Step: 8
Training loss: 3.078967809677124
Validation loss: 2.1309930970591884

Epoch: 5| Step: 9
Training loss: 2.154550552368164
Validation loss: 2.1289685003219114

Epoch: 5| Step: 10
Training loss: 1.8533334732055664
Validation loss: 2.132108603754351

Epoch: 163| Step: 0
Training loss: 2.116901159286499
Validation loss: 2.13929170690557

Epoch: 5| Step: 1
Training loss: 2.165073871612549
Validation loss: 2.1463324844196277

Epoch: 5| Step: 2
Training loss: 2.2955031394958496
Validation loss: 2.1368093439327773

Epoch: 5| Step: 3
Training loss: 2.6104538440704346
Validation loss: 2.150415705096337

Epoch: 5| Step: 4
Training loss: 2.7105274200439453
Validation loss: 2.164066360842797

Epoch: 5| Step: 5
Training loss: 2.548048496246338
Validation loss: 2.1776957870811544

Epoch: 5| Step: 6
Training loss: 2.5203018188476562
Validation loss: 2.178866711995935

Epoch: 5| Step: 7
Training loss: 2.5866923332214355
Validation loss: 2.1877152278859127

Epoch: 5| Step: 8
Training loss: 2.1200480461120605
Validation loss: 2.1914797649588635

Epoch: 5| Step: 9
Training loss: 2.569777011871338
Validation loss: 2.1992672079352924

Epoch: 5| Step: 10
Training loss: 2.3757333755493164
Validation loss: 2.1835714591446744

Epoch: 164| Step: 0
Training loss: 2.3534018993377686
Validation loss: 2.1577820982984317

Epoch: 5| Step: 1
Training loss: 2.0926671028137207
Validation loss: 2.157701805073728

Epoch: 5| Step: 2
Training loss: 2.5082809925079346
Validation loss: 2.165865898132324

Epoch: 5| Step: 3
Training loss: 2.171140670776367
Validation loss: 2.1760740305787776

Epoch: 5| Step: 4
Training loss: 2.095646619796753
Validation loss: 2.163944608421736

Epoch: 5| Step: 5
Training loss: 1.95537531375885
Validation loss: 2.173845186028429

Epoch: 5| Step: 6
Training loss: 2.1686275005340576
Validation loss: 2.1581922577273462

Epoch: 5| Step: 7
Training loss: 2.450974941253662
Validation loss: 2.1445380949204966

Epoch: 5| Step: 8
Training loss: 2.788191080093384
Validation loss: 2.1473461620269285

Epoch: 5| Step: 9
Training loss: 2.826720714569092
Validation loss: 2.157785097757975

Epoch: 5| Step: 10
Training loss: 3.1983118057250977
Validation loss: 2.1635479081061577

Epoch: 165| Step: 0
Training loss: 2.242480754852295
Validation loss: 2.162600632636778

Epoch: 5| Step: 1
Training loss: 2.190406322479248
Validation loss: 2.1604129832278014

Epoch: 5| Step: 2
Training loss: 1.946571707725525
Validation loss: 2.159384350622854

Epoch: 5| Step: 3
Training loss: 2.741314649581909
Validation loss: 2.1593165679644515

Epoch: 5| Step: 4
Training loss: 3.047431230545044
Validation loss: 2.1716067585893857

Epoch: 5| Step: 5
Training loss: 2.950300693511963
Validation loss: 2.1738010145002797

Epoch: 5| Step: 6
Training loss: 1.8783061504364014
Validation loss: 2.1690603968917683

Epoch: 5| Step: 7
Training loss: 2.365903377532959
Validation loss: 2.1617828594741

Epoch: 5| Step: 8
Training loss: 2.3998236656188965
Validation loss: 2.1687001156550583

Epoch: 5| Step: 9
Training loss: 2.4511237144470215
Validation loss: 2.1662819180437314

Epoch: 5| Step: 10
Training loss: 2.023064613342285
Validation loss: 2.1700403485246884

Epoch: 166| Step: 0
Training loss: 2.2668750286102295
Validation loss: 2.16021534832575

Epoch: 5| Step: 1
Training loss: 2.058711528778076
Validation loss: 2.1629691457235687

Epoch: 5| Step: 2
Training loss: 2.028391122817993
Validation loss: 2.1651422157082507

Epoch: 5| Step: 3
Training loss: 2.755582571029663
Validation loss: 2.180154590196507

Epoch: 5| Step: 4
Training loss: 1.7701011896133423
Validation loss: 2.164752124458231

Epoch: 5| Step: 5
Training loss: 2.9160988330841064
Validation loss: 2.1570833447158977

Epoch: 5| Step: 6
Training loss: 2.2574448585510254
Validation loss: 2.1627390000127975

Epoch: 5| Step: 7
Training loss: 2.611358880996704
Validation loss: 2.1666393305665705

Epoch: 5| Step: 8
Training loss: 2.071810722351074
Validation loss: 2.181124605158324

Epoch: 5| Step: 9
Training loss: 2.8045859336853027
Validation loss: 2.1936532323078444

Epoch: 5| Step: 10
Training loss: 2.9139163494110107
Validation loss: 2.1966874163637877

Epoch: 167| Step: 0
Training loss: 2.1313605308532715
Validation loss: 2.1964014858327885

Epoch: 5| Step: 1
Training loss: 2.1404240131378174
Validation loss: 2.1627330780029297

Epoch: 5| Step: 2
Training loss: 2.7311739921569824
Validation loss: 2.1521550583583053

Epoch: 5| Step: 3
Training loss: 3.162527084350586
Validation loss: 2.148499934904037

Epoch: 5| Step: 4
Training loss: 2.6898605823516846
Validation loss: 2.173534110028257

Epoch: 5| Step: 5
Training loss: 1.8883873224258423
Validation loss: 2.1694433304571334

Epoch: 5| Step: 6
Training loss: 2.4552624225616455
Validation loss: 2.178121288617452

Epoch: 5| Step: 7
Training loss: 2.808806896209717
Validation loss: 2.1837963827194704

Epoch: 5| Step: 8
Training loss: 1.8391904830932617
Validation loss: 2.189236148711174

Epoch: 5| Step: 9
Training loss: 2.063995122909546
Validation loss: 2.1701651221962384

Epoch: 5| Step: 10
Training loss: 2.343609094619751
Validation loss: 2.153997402037344

Epoch: 168| Step: 0
Training loss: 2.603790044784546
Validation loss: 2.1676466490632746

Epoch: 5| Step: 1
Training loss: 1.6374647617340088
Validation loss: 2.192019521549184

Epoch: 5| Step: 2
Training loss: 3.2688636779785156
Validation loss: 2.220449621959399

Epoch: 5| Step: 3
Training loss: 2.4239959716796875
Validation loss: 2.2545532539326656

Epoch: 5| Step: 4
Training loss: 3.0214922428131104
Validation loss: 2.2496678265192176

Epoch: 5| Step: 5
Training loss: 2.179234027862549
Validation loss: 2.217426097521218

Epoch: 5| Step: 6
Training loss: 2.539360523223877
Validation loss: 2.172072478519973

Epoch: 5| Step: 7
Training loss: 1.7280504703521729
Validation loss: 2.172682564745667

Epoch: 5| Step: 8
Training loss: 1.5456640720367432
Validation loss: 2.1576891893981607

Epoch: 5| Step: 9
Training loss: 2.7919211387634277
Validation loss: 2.1585052961944253

Epoch: 5| Step: 10
Training loss: 2.5594561100006104
Validation loss: 2.1660324886281

Epoch: 169| Step: 0
Training loss: 2.2762033939361572
Validation loss: 2.1620115926188808

Epoch: 5| Step: 1
Training loss: 2.2227165699005127
Validation loss: 2.1487862256265458

Epoch: 5| Step: 2
Training loss: 2.0695695877075195
Validation loss: 2.1441906088141987

Epoch: 5| Step: 3
Training loss: 2.5114588737487793
Validation loss: 2.1502227373020624

Epoch: 5| Step: 4
Training loss: 2.10801362991333
Validation loss: 2.147121403806953

Epoch: 5| Step: 5
Training loss: 1.9586877822875977
Validation loss: 2.152260145833415

Epoch: 5| Step: 6
Training loss: 2.450596570968628
Validation loss: 2.1566410141606487

Epoch: 5| Step: 7
Training loss: 1.9375712871551514
Validation loss: 2.1606967141551356

Epoch: 5| Step: 8
Training loss: 2.7066941261291504
Validation loss: 2.18436163215227

Epoch: 5| Step: 9
Training loss: 2.8571600914001465
Validation loss: 2.1632312061966106

Epoch: 5| Step: 10
Training loss: 2.9404044151306152
Validation loss: 2.1575772736662175

Epoch: 170| Step: 0
Training loss: 2.6079230308532715
Validation loss: 2.157819947888774

Epoch: 5| Step: 1
Training loss: 2.3867387771606445
Validation loss: 2.1451390122854583

Epoch: 5| Step: 2
Training loss: 2.335519313812256
Validation loss: 2.1404919829419864

Epoch: 5| Step: 3
Training loss: 2.773622751235962
Validation loss: 2.1450154140431392

Epoch: 5| Step: 4
Training loss: 2.522962808609009
Validation loss: 2.1320186212498653

Epoch: 5| Step: 5
Training loss: 1.911515235900879
Validation loss: 2.1416114607164936

Epoch: 5| Step: 6
Training loss: 2.5140604972839355
Validation loss: 2.1373190674730527

Epoch: 5| Step: 7
Training loss: 2.4102396965026855
Validation loss: 2.1551308836988223

Epoch: 5| Step: 8
Training loss: 2.1276919841766357
Validation loss: 2.1560983619382306

Epoch: 5| Step: 9
Training loss: 2.5279948711395264
Validation loss: 2.139782000613469

Epoch: 5| Step: 10
Training loss: 1.663207769393921
Validation loss: 2.140039615733649

Epoch: 171| Step: 0
Training loss: 2.495539426803589
Validation loss: 2.1641098119879283

Epoch: 5| Step: 1
Training loss: 2.783238172531128
Validation loss: 2.164135156139251

Epoch: 5| Step: 2
Training loss: 2.3003687858581543
Validation loss: 2.1834962521829913

Epoch: 5| Step: 3
Training loss: 1.751893401145935
Validation loss: 2.1809867607649935

Epoch: 5| Step: 4
Training loss: 2.106233596801758
Validation loss: 2.1917503469733783

Epoch: 5| Step: 5
Training loss: 2.844212293624878
Validation loss: 2.187735016627978

Epoch: 5| Step: 6
Training loss: 2.5291504859924316
Validation loss: 2.1727462686518186

Epoch: 5| Step: 7
Training loss: 2.4473698139190674
Validation loss: 2.165078592556779

Epoch: 5| Step: 8
Training loss: 2.1299729347229004
Validation loss: 2.1578941870761175

Epoch: 5| Step: 9
Training loss: 1.981300950050354
Validation loss: 2.143144771616946

Epoch: 5| Step: 10
Training loss: 2.5183730125427246
Validation loss: 2.152975736125823

Epoch: 172| Step: 0
Training loss: 1.990749716758728
Validation loss: 2.170240238148679

Epoch: 5| Step: 1
Training loss: 2.1646249294281006
Validation loss: 2.2149700708286737

Epoch: 5| Step: 2
Training loss: 2.6457502841949463
Validation loss: 2.2586410635261127

Epoch: 5| Step: 3
Training loss: 2.922987461090088
Validation loss: 2.211637140602194

Epoch: 5| Step: 4
Training loss: 2.1779627799987793
Validation loss: 2.17518642897247

Epoch: 5| Step: 5
Training loss: 2.5703349113464355
Validation loss: 2.143215822917159

Epoch: 5| Step: 6
Training loss: 2.5545601844787598
Validation loss: 2.1364105311773156

Epoch: 5| Step: 7
Training loss: 2.245659828186035
Validation loss: 2.133597502144434

Epoch: 5| Step: 8
Training loss: 2.1164817810058594
Validation loss: 2.1377819456079954

Epoch: 5| Step: 9
Training loss: 2.3049044609069824
Validation loss: 2.128354982663226

Epoch: 5| Step: 10
Training loss: 2.5536630153656006
Validation loss: 2.142703708781991

Epoch: 173| Step: 0
Training loss: 2.4694323539733887
Validation loss: 2.1597377613026607

Epoch: 5| Step: 1
Training loss: 2.325228214263916
Validation loss: 2.1824326194742674

Epoch: 5| Step: 2
Training loss: 2.539639711380005
Validation loss: 2.1957313988798406

Epoch: 5| Step: 3
Training loss: 2.5529048442840576
Validation loss: 2.192311190789746

Epoch: 5| Step: 4
Training loss: 2.3800101280212402
Validation loss: 2.188202424715924

Epoch: 5| Step: 5
Training loss: 2.254599094390869
Validation loss: 2.1864673514519968

Epoch: 5| Step: 6
Training loss: 1.8079417943954468
Validation loss: 2.1830617791862896

Epoch: 5| Step: 7
Training loss: 2.493837833404541
Validation loss: 2.181118631875643

Epoch: 5| Step: 8
Training loss: 2.376479148864746
Validation loss: 2.156505691107883

Epoch: 5| Step: 9
Training loss: 2.1176517009735107
Validation loss: 2.165525374873992

Epoch: 5| Step: 10
Training loss: 2.4411838054656982
Validation loss: 2.1716061817702426

Epoch: 174| Step: 0
Training loss: 2.5054566860198975
Validation loss: 2.1746297369721117

Epoch: 5| Step: 1
Training loss: 2.0367937088012695
Validation loss: 2.177683609788136

Epoch: 5| Step: 2
Training loss: 2.547267436981201
Validation loss: 2.172361819974838

Epoch: 5| Step: 3
Training loss: 2.618849992752075
Validation loss: 2.161405970973353

Epoch: 5| Step: 4
Training loss: 2.4953715801239014
Validation loss: 2.1463453679956417

Epoch: 5| Step: 5
Training loss: 1.8688137531280518
Validation loss: 2.165676168216172

Epoch: 5| Step: 6
Training loss: 1.5921761989593506
Validation loss: 2.173594496583426

Epoch: 5| Step: 7
Training loss: 2.6692514419555664
Validation loss: 2.18631318307692

Epoch: 5| Step: 8
Training loss: 2.7859387397766113
Validation loss: 2.189844180178899

Epoch: 5| Step: 9
Training loss: 1.994183897972107
Validation loss: 2.2086547267052437

Epoch: 5| Step: 10
Training loss: 2.722231388092041
Validation loss: 2.1973235478965183

Epoch: 175| Step: 0
Training loss: 2.042330265045166
Validation loss: 2.1891828006313694

Epoch: 5| Step: 1
Training loss: 2.8555045127868652
Validation loss: 2.2031595053211337

Epoch: 5| Step: 2
Training loss: 2.4950528144836426
Validation loss: 2.1896546117721067

Epoch: 5| Step: 3
Training loss: 2.4170596599578857
Validation loss: 2.221660752450266

Epoch: 5| Step: 4
Training loss: 2.039930582046509
Validation loss: 2.243133734631282

Epoch: 5| Step: 5
Training loss: 2.320971727371216
Validation loss: 2.2708863007125033

Epoch: 5| Step: 6
Training loss: 3.167271852493286
Validation loss: 2.2629542927588187

Epoch: 5| Step: 7
Training loss: 2.3401477336883545
Validation loss: 2.264469390274376

Epoch: 5| Step: 8
Training loss: 1.9259341955184937
Validation loss: 2.251317813832273

Epoch: 5| Step: 9
Training loss: 2.123537063598633
Validation loss: 2.2070542714929067

Epoch: 5| Step: 10
Training loss: 2.432403564453125
Validation loss: 2.1681781712398736

Epoch: 176| Step: 0
Training loss: 2.1202139854431152
Validation loss: 2.1582093392649004

Epoch: 5| Step: 1
Training loss: 2.0028562545776367
Validation loss: 2.1585232775698424

Epoch: 5| Step: 2
Training loss: 2.77701473236084
Validation loss: 2.146757787273776

Epoch: 5| Step: 3
Training loss: 2.724868059158325
Validation loss: 2.1483784516652427

Epoch: 5| Step: 4
Training loss: 1.4774134159088135
Validation loss: 2.130102111447242

Epoch: 5| Step: 5
Training loss: 3.0247104167938232
Validation loss: 2.1134761687247985

Epoch: 5| Step: 6
Training loss: 3.005852699279785
Validation loss: 2.086034902962305

Epoch: 5| Step: 7
Training loss: 1.9996086359024048
Validation loss: 2.0857927145496493

Epoch: 5| Step: 8
Training loss: 2.700302839279175
Validation loss: 2.0839333380422285

Epoch: 5| Step: 9
Training loss: 2.0942413806915283
Validation loss: 2.0839896253360215

Epoch: 5| Step: 10
Training loss: 2.099332809448242
Validation loss: 2.071122015676191

Epoch: 177| Step: 0
Training loss: 1.939574956893921
Validation loss: 2.079852270823653

Epoch: 5| Step: 1
Training loss: 2.9237234592437744
Validation loss: 2.0825485747347594

Epoch: 5| Step: 2
Training loss: 2.6848740577697754
Validation loss: 2.08356483264636

Epoch: 5| Step: 3
Training loss: 2.844407796859741
Validation loss: 2.079591110188474

Epoch: 5| Step: 4
Training loss: 2.018217086791992
Validation loss: 2.0884599839487383

Epoch: 5| Step: 5
Training loss: 2.3102378845214844
Validation loss: 2.091659620244016

Epoch: 5| Step: 6
Training loss: 2.52445387840271
Validation loss: 2.092177955053186

Epoch: 5| Step: 7
Training loss: 2.482734203338623
Validation loss: 2.1067290703455606

Epoch: 5| Step: 8
Training loss: 2.0268354415893555
Validation loss: 2.0993578587808917

Epoch: 5| Step: 9
Training loss: 1.7975072860717773
Validation loss: 2.1181509520417903

Epoch: 5| Step: 10
Training loss: 2.4841063022613525
Validation loss: 2.126077663513922

Epoch: 178| Step: 0
Training loss: 2.5114316940307617
Validation loss: 2.138680314504972

Epoch: 5| Step: 1
Training loss: 2.3336689472198486
Validation loss: 2.163680499599826

Epoch: 5| Step: 2
Training loss: 2.0639448165893555
Validation loss: 2.166394143976191

Epoch: 5| Step: 3
Training loss: 2.179133653640747
Validation loss: 2.1572227170390468

Epoch: 5| Step: 4
Training loss: 2.5786328315734863
Validation loss: 2.144541562244456

Epoch: 5| Step: 5
Training loss: 2.18937087059021
Validation loss: 2.1400128820891022

Epoch: 5| Step: 6
Training loss: 2.55435848236084
Validation loss: 2.14057634979166

Epoch: 5| Step: 7
Training loss: 2.3359785079956055
Validation loss: 2.1474841922842045

Epoch: 5| Step: 8
Training loss: 1.9309337139129639
Validation loss: 2.146559694761871

Epoch: 5| Step: 9
Training loss: 2.915733814239502
Validation loss: 2.144738015308175

Epoch: 5| Step: 10
Training loss: 2.4987897872924805
Validation loss: 2.126310570265657

Epoch: 179| Step: 0
Training loss: 2.3878190517425537
Validation loss: 2.1341294345035347

Epoch: 5| Step: 1
Training loss: 1.8016935586929321
Validation loss: 2.148940893911546

Epoch: 5| Step: 2
Training loss: 3.379643201828003
Validation loss: 2.1641149572146836

Epoch: 5| Step: 3
Training loss: 2.3791146278381348
Validation loss: 2.1560714398660967

Epoch: 5| Step: 4
Training loss: 1.5701014995574951
Validation loss: 2.18230075733636

Epoch: 5| Step: 5
Training loss: 3.0017688274383545
Validation loss: 2.179305504727107

Epoch: 5| Step: 6
Training loss: 1.6881868839263916
Validation loss: 2.171386485458702

Epoch: 5| Step: 7
Training loss: 2.3450405597686768
Validation loss: 2.168451416877008

Epoch: 5| Step: 8
Training loss: 2.320662498474121
Validation loss: 2.137967066098285

Epoch: 5| Step: 9
Training loss: 2.400102376937866
Validation loss: 2.1105154560458277

Epoch: 5| Step: 10
Training loss: 2.5673351287841797
Validation loss: 2.090249305130333

Epoch: 180| Step: 0
Training loss: 2.532510757446289
Validation loss: 2.1186206981699955

Epoch: 5| Step: 1
Training loss: 1.8539493083953857
Validation loss: 2.115030093859601

Epoch: 5| Step: 2
Training loss: 2.1324079036712646
Validation loss: 2.1323702783994776

Epoch: 5| Step: 3
Training loss: 2.0684237480163574
Validation loss: 2.120022363560174

Epoch: 5| Step: 4
Training loss: 1.834106206893921
Validation loss: 2.0921459595362344

Epoch: 5| Step: 5
Training loss: 2.5264503955841064
Validation loss: 2.0771625503416984

Epoch: 5| Step: 6
Training loss: 2.7402610778808594
Validation loss: 2.0872793607814337

Epoch: 5| Step: 7
Training loss: 2.495762586593628
Validation loss: 2.089291607179949

Epoch: 5| Step: 8
Training loss: 2.051831007003784
Validation loss: 2.1042436835586384

Epoch: 5| Step: 9
Training loss: 3.1619880199432373
Validation loss: 2.1147217930004163

Epoch: 5| Step: 10
Training loss: 2.658808469772339
Validation loss: 2.129801852728731

Epoch: 181| Step: 0
Training loss: 1.7865957021713257
Validation loss: 2.1274908255505305

Epoch: 5| Step: 1
Training loss: 2.4456264972686768
Validation loss: 2.1270408630371094

Epoch: 5| Step: 2
Training loss: 2.6078286170959473
Validation loss: 2.102745376607423

Epoch: 5| Step: 3
Training loss: 2.3259406089782715
Validation loss: 2.094355111481041

Epoch: 5| Step: 4
Training loss: 1.902316689491272
Validation loss: 2.1038498814387987

Epoch: 5| Step: 5
Training loss: 1.9607919454574585
Validation loss: 2.123063805282757

Epoch: 5| Step: 6
Training loss: 2.579232931137085
Validation loss: 2.1335123969662573

Epoch: 5| Step: 7
Training loss: 2.5200371742248535
Validation loss: 2.132930681269656

Epoch: 5| Step: 8
Training loss: 2.7081215381622314
Validation loss: 2.127526834446897

Epoch: 5| Step: 9
Training loss: 2.6724419593811035
Validation loss: 2.109497388203939

Epoch: 5| Step: 10
Training loss: 2.3366808891296387
Validation loss: 2.1041757137544694

Epoch: 182| Step: 0
Training loss: 2.1378982067108154
Validation loss: 2.1088095403486684

Epoch: 5| Step: 1
Training loss: 2.353684663772583
Validation loss: 2.1142554834324825

Epoch: 5| Step: 2
Training loss: 2.1013245582580566
Validation loss: 2.1335641389252036

Epoch: 5| Step: 3
Training loss: 3.0107641220092773
Validation loss: 2.1334412405567784

Epoch: 5| Step: 4
Training loss: 2.7938714027404785
Validation loss: 2.1509252030362367

Epoch: 5| Step: 5
Training loss: 2.381345272064209
Validation loss: 2.144983732572166

Epoch: 5| Step: 6
Training loss: 2.4438729286193848
Validation loss: 2.1440541410958893

Epoch: 5| Step: 7
Training loss: 1.6956819295883179
Validation loss: 2.1482074132529636

Epoch: 5| Step: 8
Training loss: 2.506295680999756
Validation loss: 2.169527192269602

Epoch: 5| Step: 9
Training loss: 1.8268301486968994
Validation loss: 2.1533909190085625

Epoch: 5| Step: 10
Training loss: 2.3800389766693115
Validation loss: 2.145887044168288

Epoch: 183| Step: 0
Training loss: 2.5230987071990967
Validation loss: 2.1488271067219396

Epoch: 5| Step: 1
Training loss: 2.3390355110168457
Validation loss: 2.16937631048182

Epoch: 5| Step: 2
Training loss: 2.2076456546783447
Validation loss: 2.1936896001138995

Epoch: 5| Step: 3
Training loss: 2.1593050956726074
Validation loss: 2.200283876029394

Epoch: 5| Step: 4
Training loss: 2.151332139968872
Validation loss: 2.173987157883183

Epoch: 5| Step: 5
Training loss: 2.1575076580047607
Validation loss: 2.1675109119825464

Epoch: 5| Step: 6
Training loss: 2.312371015548706
Validation loss: 2.1407795131847425

Epoch: 5| Step: 7
Training loss: 2.251067638397217
Validation loss: 2.105135638226745

Epoch: 5| Step: 8
Training loss: 2.7615232467651367
Validation loss: 2.106270287626533

Epoch: 5| Step: 9
Training loss: 2.0831449031829834
Validation loss: 2.106144312889345

Epoch: 5| Step: 10
Training loss: 2.551852226257324
Validation loss: 2.122723728097895

Epoch: 184| Step: 0
Training loss: 2.6262879371643066
Validation loss: 2.142607323585018

Epoch: 5| Step: 1
Training loss: 2.083940029144287
Validation loss: 2.1384898206239105

Epoch: 5| Step: 2
Training loss: 2.060554027557373
Validation loss: 2.1375486555919854

Epoch: 5| Step: 3
Training loss: 2.2416634559631348
Validation loss: 2.1392131890020063

Epoch: 5| Step: 4
Training loss: 2.305178642272949
Validation loss: 2.157332371639949

Epoch: 5| Step: 5
Training loss: 1.6506401300430298
Validation loss: 2.142159664502708

Epoch: 5| Step: 6
Training loss: 2.0810952186584473
Validation loss: 2.137446721394857

Epoch: 5| Step: 7
Training loss: 2.8474326133728027
Validation loss: 2.1626034962233676

Epoch: 5| Step: 8
Training loss: 2.4851958751678467
Validation loss: 2.1779339774962394

Epoch: 5| Step: 9
Training loss: 1.7114684581756592
Validation loss: 2.2135732558465775

Epoch: 5| Step: 10
Training loss: 3.597275972366333
Validation loss: 2.212818314952235

Epoch: 185| Step: 0
Training loss: 2.156731605529785
Validation loss: 2.1765933754623576

Epoch: 5| Step: 1
Training loss: 2.8555099964141846
Validation loss: 2.166174057991274

Epoch: 5| Step: 2
Training loss: 2.783351421356201
Validation loss: 2.1498185383376254

Epoch: 5| Step: 3
Training loss: 2.202934980392456
Validation loss: 2.1605875363913913

Epoch: 5| Step: 4
Training loss: 1.9152116775512695
Validation loss: 2.1625451067442536

Epoch: 5| Step: 5
Training loss: 2.627904176712036
Validation loss: 2.15278539862684

Epoch: 5| Step: 6
Training loss: 2.254887819290161
Validation loss: 2.1542936140491116

Epoch: 5| Step: 7
Training loss: 2.330214023590088
Validation loss: 2.126453443240094

Epoch: 5| Step: 8
Training loss: 2.0439651012420654
Validation loss: 2.1230651486304497

Epoch: 5| Step: 9
Training loss: 2.4471817016601562
Validation loss: 2.121751244350146

Epoch: 5| Step: 10
Training loss: 1.8547300100326538
Validation loss: 2.108570908987394

Epoch: 186| Step: 0
Training loss: 1.5055224895477295
Validation loss: 2.1173300256011305

Epoch: 5| Step: 1
Training loss: 2.335599184036255
Validation loss: 2.114074863413329

Epoch: 5| Step: 2
Training loss: 2.4452996253967285
Validation loss: 2.123323581551993

Epoch: 5| Step: 3
Training loss: 2.432431221008301
Validation loss: 2.136674501562631

Epoch: 5| Step: 4
Training loss: 2.7484443187713623
Validation loss: 2.151217823387474

Epoch: 5| Step: 5
Training loss: 2.3908114433288574
Validation loss: 2.160895284786019

Epoch: 5| Step: 6
Training loss: 1.9205024242401123
Validation loss: 2.1709781026327484

Epoch: 5| Step: 7
Training loss: 2.495025157928467
Validation loss: 2.176451216461838

Epoch: 5| Step: 8
Training loss: 1.6872894763946533
Validation loss: 2.169794979915824

Epoch: 5| Step: 9
Training loss: 3.0210227966308594
Validation loss: 2.1442932031487905

Epoch: 5| Step: 10
Training loss: 2.322688341140747
Validation loss: 2.1701292248182398

Epoch: 187| Step: 0
Training loss: 2.555248737335205
Validation loss: 2.206114005017024

Epoch: 5| Step: 1
Training loss: 2.673076629638672
Validation loss: 2.2238911351849957

Epoch: 5| Step: 2
Training loss: 1.794036865234375
Validation loss: 2.2011016722648375

Epoch: 5| Step: 3
Training loss: 2.7649037837982178
Validation loss: 2.161613115700342

Epoch: 5| Step: 4
Training loss: 2.176161289215088
Validation loss: 2.114684397174466

Epoch: 5| Step: 5
Training loss: 1.7530397176742554
Validation loss: 2.1121382559499433

Epoch: 5| Step: 6
Training loss: 1.8771864175796509
Validation loss: 2.1080368846975346

Epoch: 5| Step: 7
Training loss: 2.0532593727111816
Validation loss: 2.119762146344749

Epoch: 5| Step: 8
Training loss: 2.541090726852417
Validation loss: 2.1323959545422624

Epoch: 5| Step: 9
Training loss: 2.88639497756958
Validation loss: 2.1200211381399505

Epoch: 5| Step: 10
Training loss: 2.589707851409912
Validation loss: 2.125161865706085

Epoch: 188| Step: 0
Training loss: 2.3761544227600098
Validation loss: 2.106710664687618

Epoch: 5| Step: 1
Training loss: 2.094609498977661
Validation loss: 2.1062587627800564

Epoch: 5| Step: 2
Training loss: 2.1531014442443848
Validation loss: 2.109781842077932

Epoch: 5| Step: 3
Training loss: 2.395707845687866
Validation loss: 2.0989251111143377

Epoch: 5| Step: 4
Training loss: 2.562950611114502
Validation loss: 2.1127484870213333

Epoch: 5| Step: 5
Training loss: 2.6069815158843994
Validation loss: 2.0980709522001204

Epoch: 5| Step: 6
Training loss: 1.9345815181732178
Validation loss: 2.1123739339972056

Epoch: 5| Step: 7
Training loss: 2.4906442165374756
Validation loss: 2.107487327309065

Epoch: 5| Step: 8
Training loss: 1.815842866897583
Validation loss: 2.1269057309755715

Epoch: 5| Step: 9
Training loss: 2.2146084308624268
Validation loss: 2.1331340664176532

Epoch: 5| Step: 10
Training loss: 2.4980251789093018
Validation loss: 2.154215846010434

Epoch: 189| Step: 0
Training loss: 2.1505861282348633
Validation loss: 2.1414886623300533

Epoch: 5| Step: 1
Training loss: 2.179295301437378
Validation loss: 2.147967420598512

Epoch: 5| Step: 2
Training loss: 1.7966378927230835
Validation loss: 2.129580941251529

Epoch: 5| Step: 3
Training loss: 2.93792986869812
Validation loss: 2.1250966056700675

Epoch: 5| Step: 4
Training loss: 2.305457592010498
Validation loss: 2.1369765343204623

Epoch: 5| Step: 5
Training loss: 2.2536683082580566
Validation loss: 2.1251101032380135

Epoch: 5| Step: 6
Training loss: 2.3433187007904053
Validation loss: 2.1172534265825824

Epoch: 5| Step: 7
Training loss: 1.9494531154632568
Validation loss: 2.1120520202062463

Epoch: 5| Step: 8
Training loss: 2.2645277976989746
Validation loss: 2.115102726926086

Epoch: 5| Step: 9
Training loss: 2.332174062728882
Validation loss: 2.117368568656265

Epoch: 5| Step: 10
Training loss: 2.6957855224609375
Validation loss: 2.1231004115073913

Epoch: 190| Step: 0
Training loss: 3.001105546951294
Validation loss: 2.1109166183779315

Epoch: 5| Step: 1
Training loss: 2.2370212078094482
Validation loss: 2.101659077470021

Epoch: 5| Step: 2
Training loss: 2.390739917755127
Validation loss: 2.1184230491679203

Epoch: 5| Step: 3
Training loss: 2.1258785724639893
Validation loss: 2.1061870180150515

Epoch: 5| Step: 4
Training loss: 1.934698462486267
Validation loss: 2.1251090341998684

Epoch: 5| Step: 5
Training loss: 2.3973488807678223
Validation loss: 2.1235595723634124

Epoch: 5| Step: 6
Training loss: 2.2489089965820312
Validation loss: 2.1213090342860066

Epoch: 5| Step: 7
Training loss: 1.8975290060043335
Validation loss: 2.1204884539368334

Epoch: 5| Step: 8
Training loss: 2.132026195526123
Validation loss: 2.1346181310633177

Epoch: 5| Step: 9
Training loss: 2.0019893646240234
Validation loss: 2.115657485941405

Epoch: 5| Step: 10
Training loss: 2.7047531604766846
Validation loss: 2.131030369830388

Epoch: 191| Step: 0
Training loss: 2.186666965484619
Validation loss: 2.1133446834420644

Epoch: 5| Step: 1
Training loss: 2.1759612560272217
Validation loss: 2.131287705513739

Epoch: 5| Step: 2
Training loss: 2.356593132019043
Validation loss: 2.1261944796449397

Epoch: 5| Step: 3
Training loss: 2.1944401264190674
Validation loss: 2.106828731875266

Epoch: 5| Step: 4
Training loss: 2.201404094696045
Validation loss: 2.1075452348237396

Epoch: 5| Step: 5
Training loss: 2.119375705718994
Validation loss: 2.1165456797486994

Epoch: 5| Step: 6
Training loss: 2.2226614952087402
Validation loss: 2.138830490009759

Epoch: 5| Step: 7
Training loss: 2.4851431846618652
Validation loss: 2.1409489929035144

Epoch: 5| Step: 8
Training loss: 2.0140509605407715
Validation loss: 2.13935334708101

Epoch: 5| Step: 9
Training loss: 2.2359933853149414
Validation loss: 2.157191986678749

Epoch: 5| Step: 10
Training loss: 2.797189712524414
Validation loss: 2.145728706031717

Epoch: 192| Step: 0
Training loss: 2.0139403343200684
Validation loss: 2.1292645162151707

Epoch: 5| Step: 1
Training loss: 1.9679912328720093
Validation loss: 2.1184297787245883

Epoch: 5| Step: 2
Training loss: 2.1958775520324707
Validation loss: 2.143768281065008

Epoch: 5| Step: 3
Training loss: 2.440762996673584
Validation loss: 2.107875071546083

Epoch: 5| Step: 4
Training loss: 2.524104356765747
Validation loss: 2.103920349510767

Epoch: 5| Step: 5
Training loss: 2.174678325653076
Validation loss: 2.098780201327416

Epoch: 5| Step: 6
Training loss: 2.474917411804199
Validation loss: 2.0902501998409146

Epoch: 5| Step: 7
Training loss: 1.3174352645874023
Validation loss: 2.0998981332266204

Epoch: 5| Step: 8
Training loss: 2.404575824737549
Validation loss: 2.094600203216717

Epoch: 5| Step: 9
Training loss: 2.9690258502960205
Validation loss: 2.082750233270789

Epoch: 5| Step: 10
Training loss: 2.318302631378174
Validation loss: 2.097721674109018

Epoch: 193| Step: 0
Training loss: 2.617208480834961
Validation loss: 2.1284858026812152

Epoch: 5| Step: 1
Training loss: 1.7291533946990967
Validation loss: 2.163912139913087

Epoch: 5| Step: 2
Training loss: 2.147270679473877
Validation loss: 2.168342846696095

Epoch: 5| Step: 3
Training loss: 2.0500855445861816
Validation loss: 2.163255928665079

Epoch: 5| Step: 4
Training loss: 2.090332508087158
Validation loss: 2.157420127622543

Epoch: 5| Step: 5
Training loss: 2.707064390182495
Validation loss: 2.154405329817085

Epoch: 5| Step: 6
Training loss: 2.04127836227417
Validation loss: 2.1419394285448137

Epoch: 5| Step: 7
Training loss: 2.5250496864318848
Validation loss: 2.13833648415022

Epoch: 5| Step: 8
Training loss: 2.1447174549102783
Validation loss: 2.1453906259229107

Epoch: 5| Step: 9
Training loss: 2.0892481803894043
Validation loss: 2.1434009049528386

Epoch: 5| Step: 10
Training loss: 3.066202402114868
Validation loss: 2.159527055678829

Epoch: 194| Step: 0
Training loss: 2.1536762714385986
Validation loss: 2.152100078521236

Epoch: 5| Step: 1
Training loss: 2.1178536415100098
Validation loss: 2.145596206829112

Epoch: 5| Step: 2
Training loss: 3.0317206382751465
Validation loss: 2.1321764710128948

Epoch: 5| Step: 3
Training loss: 2.8078854084014893
Validation loss: 2.133646249771118

Epoch: 5| Step: 4
Training loss: 2.4639580249786377
Validation loss: 2.137591290217574

Epoch: 5| Step: 5
Training loss: 1.9637534618377686
Validation loss: 2.1457642201454408

Epoch: 5| Step: 6
Training loss: 1.7403287887573242
Validation loss: 2.126980778991535

Epoch: 5| Step: 7
Training loss: 1.789797067642212
Validation loss: 2.1471794420673

Epoch: 5| Step: 8
Training loss: 2.153316020965576
Validation loss: 2.1343246403560845

Epoch: 5| Step: 9
Training loss: 2.3892264366149902
Validation loss: 2.147078450008105

Epoch: 5| Step: 10
Training loss: 1.9292900562286377
Validation loss: 2.124796114942079

Epoch: 195| Step: 0
Training loss: 2.63165020942688
Validation loss: 2.1053574854327786

Epoch: 5| Step: 1
Training loss: 1.6781723499298096
Validation loss: 2.1133670447975077

Epoch: 5| Step: 2
Training loss: 2.6542208194732666
Validation loss: 2.116422486561601

Epoch: 5| Step: 3
Training loss: 2.492314577102661
Validation loss: 2.0964957821753716

Epoch: 5| Step: 4
Training loss: 2.0847814083099365
Validation loss: 2.105095624923706

Epoch: 5| Step: 5
Training loss: 2.6153087615966797
Validation loss: 2.1004408251854683

Epoch: 5| Step: 6
Training loss: 2.365572690963745
Validation loss: 2.0977219612367692

Epoch: 5| Step: 7
Training loss: 1.9825313091278076
Validation loss: 2.1119951330205446

Epoch: 5| Step: 8
Training loss: 2.0243873596191406
Validation loss: 2.1047881957023375

Epoch: 5| Step: 9
Training loss: 1.833380103111267
Validation loss: 2.1036044115661294

Epoch: 5| Step: 10
Training loss: 2.478600025177002
Validation loss: 2.1169085758988575

Epoch: 196| Step: 0
Training loss: 2.774571180343628
Validation loss: 2.135776130102014

Epoch: 5| Step: 1
Training loss: 1.6573162078857422
Validation loss: 2.1250643755799983

Epoch: 5| Step: 2
Training loss: 1.801630973815918
Validation loss: 2.124892511675435

Epoch: 5| Step: 3
Training loss: 2.095705509185791
Validation loss: 2.1098941756832983

Epoch: 5| Step: 4
Training loss: 2.799647808074951
Validation loss: 2.1000175014618905

Epoch: 5| Step: 5
Training loss: 2.6527576446533203
Validation loss: 2.1091468000924714

Epoch: 5| Step: 6
Training loss: 2.2651939392089844
Validation loss: 2.133177063798392

Epoch: 5| Step: 7
Training loss: 1.946984052658081
Validation loss: 2.123920597055907

Epoch: 5| Step: 8
Training loss: 2.4123454093933105
Validation loss: 2.1151869450846026

Epoch: 5| Step: 9
Training loss: 2.284946918487549
Validation loss: 2.11876614375781

Epoch: 5| Step: 10
Training loss: 1.9133634567260742
Validation loss: 2.1096228015038276

Epoch: 197| Step: 0
Training loss: 1.61284601688385
Validation loss: 2.1022366169960267

Epoch: 5| Step: 1
Training loss: 2.065932035446167
Validation loss: 2.0966634032546834

Epoch: 5| Step: 2
Training loss: 2.6729085445404053
Validation loss: 2.0992907183144682

Epoch: 5| Step: 3
Training loss: 2.3875153064727783
Validation loss: 2.1134353530022407

Epoch: 5| Step: 4
Training loss: 2.0545055866241455
Validation loss: 2.1106312467205908

Epoch: 5| Step: 5
Training loss: 2.2330737113952637
Validation loss: 2.1171067683927474

Epoch: 5| Step: 6
Training loss: 2.350726366043091
Validation loss: 2.129189616890364

Epoch: 5| Step: 7
Training loss: 2.268644332885742
Validation loss: 2.116337880011528

Epoch: 5| Step: 8
Training loss: 2.474419116973877
Validation loss: 2.110633606551796

Epoch: 5| Step: 9
Training loss: 1.93491530418396
Validation loss: 2.1243230271083053

Epoch: 5| Step: 10
Training loss: 2.2724997997283936
Validation loss: 2.1138624375866306

Epoch: 198| Step: 0
Training loss: 2.119445323944092
Validation loss: 2.13048739587107

Epoch: 5| Step: 1
Training loss: 2.0261359214782715
Validation loss: 2.1177064180374146

Epoch: 5| Step: 2
Training loss: 2.2325873374938965
Validation loss: 2.115386438626115

Epoch: 5| Step: 3
Training loss: 1.7190929651260376
Validation loss: 2.0955509216554704

Epoch: 5| Step: 4
Training loss: 2.7591347694396973
Validation loss: 2.0906257475576093

Epoch: 5| Step: 5
Training loss: 2.1746582984924316
Validation loss: 2.1012508356443016

Epoch: 5| Step: 6
Training loss: 2.0616440773010254
Validation loss: 2.096471281461818

Epoch: 5| Step: 7
Training loss: 2.604954957962036
Validation loss: 2.0931872283258746

Epoch: 5| Step: 8
Training loss: 2.426433563232422
Validation loss: 2.0951250958186325

Epoch: 5| Step: 9
Training loss: 2.25769305229187
Validation loss: 2.0963932878227642

Epoch: 5| Step: 10
Training loss: 2.0637176036834717
Validation loss: 2.095591442559355

Epoch: 199| Step: 0
Training loss: 2.4854369163513184
Validation loss: 2.1002643057095107

Epoch: 5| Step: 1
Training loss: 2.0093517303466797
Validation loss: 2.0864048619424143

Epoch: 5| Step: 2
Training loss: 1.8778655529022217
Validation loss: 2.099445846772963

Epoch: 5| Step: 3
Training loss: 2.713974714279175
Validation loss: 2.109828297809888

Epoch: 5| Step: 4
Training loss: 2.128284454345703
Validation loss: 2.108344475428263

Epoch: 5| Step: 5
Training loss: 1.8513309955596924
Validation loss: 2.113528113211355

Epoch: 5| Step: 6
Training loss: 2.6350276470184326
Validation loss: 2.123169501622518

Epoch: 5| Step: 7
Training loss: 1.7783979177474976
Validation loss: 2.152752931400012

Epoch: 5| Step: 8
Training loss: 2.834812879562378
Validation loss: 2.1471934651815765

Epoch: 5| Step: 9
Training loss: 1.870867133140564
Validation loss: 2.132469736119752

Epoch: 5| Step: 10
Training loss: 2.199207067489624
Validation loss: 2.1349591888407224

Epoch: 200| Step: 0
Training loss: 2.3158576488494873
Validation loss: 2.1385516505087576

Epoch: 5| Step: 1
Training loss: 2.2693088054656982
Validation loss: 2.1286919219519502

Epoch: 5| Step: 2
Training loss: 2.9708023071289062
Validation loss: 2.1483393625546525

Epoch: 5| Step: 3
Training loss: 1.988663911819458
Validation loss: 2.1348324629568283

Epoch: 5| Step: 4
Training loss: 2.4308764934539795
Validation loss: 2.119857097184786

Epoch: 5| Step: 5
Training loss: 2.274840831756592
Validation loss: 2.117723265001851

Epoch: 5| Step: 6
Training loss: 1.703805923461914
Validation loss: 2.1310164748981433

Epoch: 5| Step: 7
Training loss: 2.312771797180176
Validation loss: 2.1504004091344853

Epoch: 5| Step: 8
Training loss: 2.056137800216675
Validation loss: 2.131313225274445

Epoch: 5| Step: 9
Training loss: 1.6370700597763062
Validation loss: 2.1244583386246876

Epoch: 5| Step: 10
Training loss: 2.374587059020996
Validation loss: 2.1239047524749592

Epoch: 201| Step: 0
Training loss: 2.213148832321167
Validation loss: 2.132449424394997

Epoch: 5| Step: 1
Training loss: 2.0533416271209717
Validation loss: 2.1128992393452632

Epoch: 5| Step: 2
Training loss: 2.05312180519104
Validation loss: 2.1197723445071968

Epoch: 5| Step: 3
Training loss: 2.046140670776367
Validation loss: 2.115660728946809

Epoch: 5| Step: 4
Training loss: 1.6874834299087524
Validation loss: 2.11294888424617

Epoch: 5| Step: 5
Training loss: 2.178025722503662
Validation loss: 2.103409236477267

Epoch: 5| Step: 6
Training loss: 2.8545615673065186
Validation loss: 2.100844353757879

Epoch: 5| Step: 7
Training loss: 2.295604705810547
Validation loss: 2.094050822719451

Epoch: 5| Step: 8
Training loss: 1.9479681253433228
Validation loss: 2.0996160635384182

Epoch: 5| Step: 9
Training loss: 2.5529489517211914
Validation loss: 2.1037025682387815

Epoch: 5| Step: 10
Training loss: 2.431408166885376
Validation loss: 2.1156991553562943

Epoch: 202| Step: 0
Training loss: 2.8127074241638184
Validation loss: 2.1007062235186176

Epoch: 5| Step: 1
Training loss: 1.6549047231674194
Validation loss: 2.1030683132909958

Epoch: 5| Step: 2
Training loss: 2.4003424644470215
Validation loss: 2.1081947690697125

Epoch: 5| Step: 3
Training loss: 1.8309314250946045
Validation loss: 2.116595552813622

Epoch: 5| Step: 4
Training loss: 1.7271007299423218
Validation loss: 2.1037441953536002

Epoch: 5| Step: 5
Training loss: 2.440450429916382
Validation loss: 2.103731511741556

Epoch: 5| Step: 6
Training loss: 1.6744340658187866
Validation loss: 2.1049763553886005

Epoch: 5| Step: 7
Training loss: 2.7942123413085938
Validation loss: 2.124283527815214

Epoch: 5| Step: 8
Training loss: 2.433868885040283
Validation loss: 2.101495906870852

Epoch: 5| Step: 9
Training loss: 2.4764058589935303
Validation loss: 2.12355395542678

Epoch: 5| Step: 10
Training loss: 1.768073320388794
Validation loss: 2.1255253514935895

Epoch: 203| Step: 0
Training loss: 2.013711929321289
Validation loss: 2.122600970729705

Epoch: 5| Step: 1
Training loss: 2.5030970573425293
Validation loss: 2.1381532684449227

Epoch: 5| Step: 2
Training loss: 1.3371407985687256
Validation loss: 2.132087956192673

Epoch: 5| Step: 3
Training loss: 2.1327242851257324
Validation loss: 2.125010709608755

Epoch: 5| Step: 4
Training loss: 2.080583333969116
Validation loss: 2.129175314339258

Epoch: 5| Step: 5
Training loss: 2.8288707733154297
Validation loss: 2.1354170409581994

Epoch: 5| Step: 6
Training loss: 2.7036168575286865
Validation loss: 2.127022768861504

Epoch: 5| Step: 7
Training loss: 2.9032821655273438
Validation loss: 2.111190067824497

Epoch: 5| Step: 8
Training loss: 1.8057899475097656
Validation loss: 2.1106812428402644

Epoch: 5| Step: 9
Training loss: 1.8356584310531616
Validation loss: 2.1044892931497223

Epoch: 5| Step: 10
Training loss: 1.9664546251296997
Validation loss: 2.1169859568277993

Epoch: 204| Step: 0
Training loss: 2.1197710037231445
Validation loss: 2.084493407639124

Epoch: 5| Step: 1
Training loss: 2.536470651626587
Validation loss: 2.1093512581240748

Epoch: 5| Step: 2
Training loss: 1.9337142705917358
Validation loss: 2.1065050145631194

Epoch: 5| Step: 3
Training loss: 1.9449126720428467
Validation loss: 2.09803867852816

Epoch: 5| Step: 4
Training loss: 1.6797332763671875
Validation loss: 2.113860978875109

Epoch: 5| Step: 5
Training loss: 2.17226505279541
Validation loss: 2.110487012452977

Epoch: 5| Step: 6
Training loss: 2.243887186050415
Validation loss: 2.0976286062630276

Epoch: 5| Step: 7
Training loss: 2.572707176208496
Validation loss: 2.1103710525779316

Epoch: 5| Step: 8
Training loss: 2.3126041889190674
Validation loss: 2.103908238872405

Epoch: 5| Step: 9
Training loss: 2.1932520866394043
Validation loss: 2.1162011854110228

Epoch: 5| Step: 10
Training loss: 2.4489221572875977
Validation loss: 2.1074571981224963

Epoch: 205| Step: 0
Training loss: 2.1987483501434326
Validation loss: 2.0982744693756104

Epoch: 5| Step: 1
Training loss: 1.5198068618774414
Validation loss: 2.106196444521668

Epoch: 5| Step: 2
Training loss: 2.114572525024414
Validation loss: 2.0973924539422475

Epoch: 5| Step: 3
Training loss: 1.935400366783142
Validation loss: 2.1098006463819936

Epoch: 5| Step: 4
Training loss: 2.8011653423309326
Validation loss: 2.084834593598561

Epoch: 5| Step: 5
Training loss: 1.7687400579452515
Validation loss: 2.1059622815860215

Epoch: 5| Step: 6
Training loss: 2.6490345001220703
Validation loss: 2.102244584791122

Epoch: 5| Step: 7
Training loss: 2.5197031497955322
Validation loss: 2.12867263824709

Epoch: 5| Step: 8
Training loss: 2.0857882499694824
Validation loss: 2.1321456304160495

Epoch: 5| Step: 9
Training loss: 1.8539434671401978
Validation loss: 2.159969170888265

Epoch: 5| Step: 10
Training loss: 2.7421481609344482
Validation loss: 2.152620792388916

Epoch: 206| Step: 0
Training loss: 2.3152682781219482
Validation loss: 2.1828111192231536

Epoch: 5| Step: 1
Training loss: 2.5707857608795166
Validation loss: 2.1814389972276587

Epoch: 5| Step: 2
Training loss: 1.429994821548462
Validation loss: 2.1923417839952695

Epoch: 5| Step: 3
Training loss: 2.171668529510498
Validation loss: 2.1833557646761657

Epoch: 5| Step: 4
Training loss: 2.189009428024292
Validation loss: 2.180905959939444

Epoch: 5| Step: 5
Training loss: 1.7039234638214111
Validation loss: 2.180707977664086

Epoch: 5| Step: 6
Training loss: 2.9481663703918457
Validation loss: 2.1645298465605705

Epoch: 5| Step: 7
Training loss: 1.8020187616348267
Validation loss: 2.1469396352767944

Epoch: 5| Step: 8
Training loss: 2.5910775661468506
Validation loss: 2.122991934899361

Epoch: 5| Step: 9
Training loss: 2.3976516723632812
Validation loss: 2.1195428140701784

Epoch: 5| Step: 10
Training loss: 2.0737454891204834
Validation loss: 2.1097227937431744

Epoch: 207| Step: 0
Training loss: 2.526987314224243
Validation loss: 2.1054793173266995

Epoch: 5| Step: 1
Training loss: 2.234684467315674
Validation loss: 2.135453765110303

Epoch: 5| Step: 2
Training loss: 2.624821424484253
Validation loss: 2.148114227479504

Epoch: 5| Step: 3
Training loss: 2.032937526702881
Validation loss: 2.119541621977283

Epoch: 5| Step: 4
Training loss: 2.0792956352233887
Validation loss: 2.1104872457442747

Epoch: 5| Step: 5
Training loss: 2.2916672229766846
Validation loss: 2.091589320090509

Epoch: 5| Step: 6
Training loss: 1.8693897724151611
Validation loss: 2.0870816528156237

Epoch: 5| Step: 7
Training loss: 1.5284106731414795
Validation loss: 2.0905997163505963

Epoch: 5| Step: 8
Training loss: 2.6055800914764404
Validation loss: 2.1354317613827285

Epoch: 5| Step: 9
Training loss: 1.9195398092269897
Validation loss: 2.1315654208583217

Epoch: 5| Step: 10
Training loss: 2.5708718299865723
Validation loss: 2.1310566779105895

Epoch: 208| Step: 0
Training loss: 2.2577826976776123
Validation loss: 2.121363164276205

Epoch: 5| Step: 1
Training loss: 2.2231733798980713
Validation loss: 2.1434644088950208

Epoch: 5| Step: 2
Training loss: 2.596762180328369
Validation loss: 2.1486560503641763

Epoch: 5| Step: 3
Training loss: 2.254793167114258
Validation loss: 2.1452440151604275

Epoch: 5| Step: 4
Training loss: 2.084224224090576
Validation loss: 2.1415747775826404

Epoch: 5| Step: 5
Training loss: 2.5436489582061768
Validation loss: 2.128340623712027

Epoch: 5| Step: 6
Training loss: 1.69588303565979
Validation loss: 2.1217630781153196

Epoch: 5| Step: 7
Training loss: 2.2854714393615723
Validation loss: 2.124356133963472

Epoch: 5| Step: 8
Training loss: 2.0785634517669678
Validation loss: 2.1215050323035127

Epoch: 5| Step: 9
Training loss: 1.6270506381988525
Validation loss: 2.136194024034726

Epoch: 5| Step: 10
Training loss: 2.081265449523926
Validation loss: 2.143618445242605

Epoch: 209| Step: 0
Training loss: 2.269274950027466
Validation loss: 2.1321015460516817

Epoch: 5| Step: 1
Training loss: 2.4633660316467285
Validation loss: 2.120948629994546

Epoch: 5| Step: 2
Training loss: 2.1309897899627686
Validation loss: 2.0958116541626635

Epoch: 5| Step: 3
Training loss: 2.274064064025879
Validation loss: 2.077989708992743

Epoch: 5| Step: 4
Training loss: 1.7233524322509766
Validation loss: 2.085709730784098

Epoch: 5| Step: 5
Training loss: 1.6021356582641602
Validation loss: 2.083254793638824

Epoch: 5| Step: 6
Training loss: 2.0197129249572754
Validation loss: 2.0747097794727614

Epoch: 5| Step: 7
Training loss: 2.5128426551818848
Validation loss: 2.0710530845067834

Epoch: 5| Step: 8
Training loss: 2.717604875564575
Validation loss: 2.076223240103773

Epoch: 5| Step: 9
Training loss: 1.684823989868164
Validation loss: 2.050720258425641

Epoch: 5| Step: 10
Training loss: 2.1824262142181396
Validation loss: 2.0822939898378108

Epoch: 210| Step: 0
Training loss: 2.661921262741089
Validation loss: 2.066271766539543

Epoch: 5| Step: 1
Training loss: 1.6506965160369873
Validation loss: 2.0740996663288405

Epoch: 5| Step: 2
Training loss: 2.4851107597351074
Validation loss: 2.0775076394440024

Epoch: 5| Step: 3
Training loss: 2.2970118522644043
Validation loss: 2.097345189381671

Epoch: 5| Step: 4
Training loss: 2.2290751934051514
Validation loss: 2.0972726934699604

Epoch: 5| Step: 5
Training loss: 2.215179920196533
Validation loss: 2.0944282047210203

Epoch: 5| Step: 6
Training loss: 1.873781442642212
Validation loss: 2.093198678826773

Epoch: 5| Step: 7
Training loss: 2.105991840362549
Validation loss: 2.0946173834544357

Epoch: 5| Step: 8
Training loss: 1.828945517539978
Validation loss: 2.09079643218748

Epoch: 5| Step: 9
Training loss: 1.9614334106445312
Validation loss: 2.113674076654578

Epoch: 5| Step: 10
Training loss: 2.305696487426758
Validation loss: 2.1087599185205277

Epoch: 211| Step: 0
Training loss: 2.024197816848755
Validation loss: 2.110493959919099

Epoch: 5| Step: 1
Training loss: 2.573148250579834
Validation loss: 2.1237476525768155

Epoch: 5| Step: 2
Training loss: 2.2874703407287598
Validation loss: 2.108666405882887

Epoch: 5| Step: 3
Training loss: 2.434069871902466
Validation loss: 2.129611030701668

Epoch: 5| Step: 4
Training loss: 2.062854766845703
Validation loss: 2.1190381742292836

Epoch: 5| Step: 5
Training loss: 2.056472063064575
Validation loss: 2.119071670757827

Epoch: 5| Step: 6
Training loss: 2.027994394302368
Validation loss: 2.110660088959561

Epoch: 5| Step: 7
Training loss: 1.5658620595932007
Validation loss: 2.1168582234331357

Epoch: 5| Step: 8
Training loss: 1.747536301612854
Validation loss: 2.124392890161084

Epoch: 5| Step: 9
Training loss: 2.374523878097534
Validation loss: 2.1241903125598864

Epoch: 5| Step: 10
Training loss: 2.332265615463257
Validation loss: 2.102001650359041

Epoch: 212| Step: 0
Training loss: 1.875032663345337
Validation loss: 2.1100624620273547

Epoch: 5| Step: 1
Training loss: 1.7181068658828735
Validation loss: 2.1072975461201002

Epoch: 5| Step: 2
Training loss: 2.1380867958068848
Validation loss: 2.1011838579690583

Epoch: 5| Step: 3
Training loss: 2.327241897583008
Validation loss: 2.104753896754275

Epoch: 5| Step: 4
Training loss: 1.7580070495605469
Validation loss: 2.10187392978258

Epoch: 5| Step: 5
Training loss: 2.0539536476135254
Validation loss: 2.101381242916148

Epoch: 5| Step: 6
Training loss: 2.6991143226623535
Validation loss: 2.1164589197404924

Epoch: 5| Step: 7
Training loss: 2.6821742057800293
Validation loss: 2.1235376634905414

Epoch: 5| Step: 8
Training loss: 2.2703113555908203
Validation loss: 2.1310014929822696

Epoch: 5| Step: 9
Training loss: 2.1118171215057373
Validation loss: 2.1366883990585164

Epoch: 5| Step: 10
Training loss: 1.929669737815857
Validation loss: 2.1355313383122927

Epoch: 213| Step: 0
Training loss: 1.678342580795288
Validation loss: 2.1280904136678225

Epoch: 5| Step: 1
Training loss: 2.5818448066711426
Validation loss: 2.1164071764997257

Epoch: 5| Step: 2
Training loss: 2.025831937789917
Validation loss: 2.130102342174899

Epoch: 5| Step: 3
Training loss: 1.8516464233398438
Validation loss: 2.123478312646189

Epoch: 5| Step: 4
Training loss: 2.402987003326416
Validation loss: 2.1346101991591917

Epoch: 5| Step: 5
Training loss: 2.2251968383789062
Validation loss: 2.128049067271653

Epoch: 5| Step: 6
Training loss: 2.727670431137085
Validation loss: 2.131722829675162

Epoch: 5| Step: 7
Training loss: 2.222325086593628
Validation loss: 2.1290156392640966

Epoch: 5| Step: 8
Training loss: 1.7592569589614868
Validation loss: 2.1460967217722247

Epoch: 5| Step: 9
Training loss: 2.1126537322998047
Validation loss: 2.138573593990777

Epoch: 5| Step: 10
Training loss: 1.9431536197662354
Validation loss: 2.136909479736

Epoch: 214| Step: 0
Training loss: 2.620537757873535
Validation loss: 2.1018081185638264

Epoch: 5| Step: 1
Training loss: 2.6360583305358887
Validation loss: 2.103016182940493

Epoch: 5| Step: 2
Training loss: 2.0238914489746094
Validation loss: 2.102161640762001

Epoch: 5| Step: 3
Training loss: 2.1596670150756836
Validation loss: 2.103393175268686

Epoch: 5| Step: 4
Training loss: 2.6014389991760254
Validation loss: 2.096277959885136

Epoch: 5| Step: 5
Training loss: 1.6057255268096924
Validation loss: 2.08110313518073

Epoch: 5| Step: 6
Training loss: 2.739853858947754
Validation loss: 2.085119689664533

Epoch: 5| Step: 7
Training loss: 1.3773037195205688
Validation loss: 2.073506521922286

Epoch: 5| Step: 8
Training loss: 1.6391489505767822
Validation loss: 2.0869228404055358

Epoch: 5| Step: 9
Training loss: 1.8122546672821045
Validation loss: 2.1050012342391478

Epoch: 5| Step: 10
Training loss: 2.5259673595428467
Validation loss: 2.1150812602812246

Epoch: 215| Step: 0
Training loss: 2.8648881912231445
Validation loss: 2.121832892458926

Epoch: 5| Step: 1
Training loss: 2.092998504638672
Validation loss: 2.0959099646537536

Epoch: 5| Step: 2
Training loss: 2.1693921089172363
Validation loss: 2.098121138029201

Epoch: 5| Step: 3
Training loss: 2.1584136486053467
Validation loss: 2.09725958301175

Epoch: 5| Step: 4
Training loss: 2.334321975708008
Validation loss: 2.11263289759236

Epoch: 5| Step: 5
Training loss: 2.194845676422119
Validation loss: 2.1203000930047806

Epoch: 5| Step: 6
Training loss: 2.35762357711792
Validation loss: 2.0967880115714124

Epoch: 5| Step: 7
Training loss: 1.9154908657073975
Validation loss: 2.075994524904477

Epoch: 5| Step: 8
Training loss: 1.9343379735946655
Validation loss: 2.069321163239018

Epoch: 5| Step: 9
Training loss: 1.8178684711456299
Validation loss: 2.076699759370537

Epoch: 5| Step: 10
Training loss: 1.760770320892334
Validation loss: 2.106299597729919

Epoch: 216| Step: 0
Training loss: 2.6494946479797363
Validation loss: 2.1663954642511185

Epoch: 5| Step: 1
Training loss: 2.728541612625122
Validation loss: 2.180250193483086

Epoch: 5| Step: 2
Training loss: 2.686431407928467
Validation loss: 2.154986491767309

Epoch: 5| Step: 3
Training loss: 2.0486721992492676
Validation loss: 2.1205485418278682

Epoch: 5| Step: 4
Training loss: 1.514978051185608
Validation loss: 2.0892921955354753

Epoch: 5| Step: 5
Training loss: 1.8338356018066406
Validation loss: 2.0772616965796358

Epoch: 5| Step: 6
Training loss: 2.203608989715576
Validation loss: 2.11725547236781

Epoch: 5| Step: 7
Training loss: 2.351825714111328
Validation loss: 2.1572217992556992

Epoch: 5| Step: 8
Training loss: 2.2742528915405273
Validation loss: 2.155473521960679

Epoch: 5| Step: 9
Training loss: 1.9622890949249268
Validation loss: 2.1680352764744915

Epoch: 5| Step: 10
Training loss: 2.015413999557495
Validation loss: 2.160805808600559

Epoch: 217| Step: 0
Training loss: 2.1260695457458496
Validation loss: 2.14064436317772

Epoch: 5| Step: 1
Training loss: 2.6659631729125977
Validation loss: 2.1324154151383268

Epoch: 5| Step: 2
Training loss: 2.142756462097168
Validation loss: 2.172325271432118

Epoch: 5| Step: 3
Training loss: 2.037219524383545
Validation loss: 2.1674073306463097

Epoch: 5| Step: 4
Training loss: 2.4070115089416504
Validation loss: 2.161346194564655

Epoch: 5| Step: 5
Training loss: 2.2098517417907715
Validation loss: 2.14177966630587

Epoch: 5| Step: 6
Training loss: 2.509873628616333
Validation loss: 2.1191734690820017

Epoch: 5| Step: 7
Training loss: 1.6223112344741821
Validation loss: 2.117426485143682

Epoch: 5| Step: 8
Training loss: 1.957313895225525
Validation loss: 2.089597943008587

Epoch: 5| Step: 9
Training loss: 1.888523817062378
Validation loss: 2.1004192483040596

Epoch: 5| Step: 10
Training loss: 1.7099343538284302
Validation loss: 2.1074205265250257

Epoch: 218| Step: 0
Training loss: 1.647422194480896
Validation loss: 2.103082077477568

Epoch: 5| Step: 1
Training loss: 3.1583189964294434
Validation loss: 2.0919697284698486

Epoch: 5| Step: 2
Training loss: 2.0645313262939453
Validation loss: 2.0968678664135676

Epoch: 5| Step: 3
Training loss: 2.1757209300994873
Validation loss: 2.095790268272482

Epoch: 5| Step: 4
Training loss: 2.146176338195801
Validation loss: 2.101299738371244

Epoch: 5| Step: 5
Training loss: 2.329188108444214
Validation loss: 2.1170764892332015

Epoch: 5| Step: 6
Training loss: 1.978005051612854
Validation loss: 2.1103402824812036

Epoch: 5| Step: 7
Training loss: 1.8238455057144165
Validation loss: 2.098042053561057

Epoch: 5| Step: 8
Training loss: 1.9511148929595947
Validation loss: 2.1098921119525866

Epoch: 5| Step: 9
Training loss: 2.2550487518310547
Validation loss: 2.073573593170412

Epoch: 5| Step: 10
Training loss: 1.6794323921203613
Validation loss: 2.059654671658752

Epoch: 219| Step: 0
Training loss: 1.9876022338867188
Validation loss: 2.0830905898924796

Epoch: 5| Step: 1
Training loss: 2.4576218128204346
Validation loss: 2.091108524671165

Epoch: 5| Step: 2
Training loss: 1.7385694980621338
Validation loss: 2.113160458944177

Epoch: 5| Step: 3
Training loss: 2.096606492996216
Validation loss: 2.104229091316141

Epoch: 5| Step: 4
Training loss: 2.0812201499938965
Validation loss: 2.1273670529806488

Epoch: 5| Step: 5
Training loss: 1.566559910774231
Validation loss: 2.1263530280000422

Epoch: 5| Step: 6
Training loss: 3.0044968128204346
Validation loss: 2.127142657515823

Epoch: 5| Step: 7
Training loss: 2.760605812072754
Validation loss: 2.1087095763093684

Epoch: 5| Step: 8
Training loss: 1.4503989219665527
Validation loss: 2.1010733573667464

Epoch: 5| Step: 9
Training loss: 1.7804409265518188
Validation loss: 2.09513020899988

Epoch: 5| Step: 10
Training loss: 2.188314199447632
Validation loss: 2.1034221700442735

Epoch: 220| Step: 0
Training loss: 1.8180040121078491
Validation loss: 2.1377670739286687

Epoch: 5| Step: 1
Training loss: 1.747736930847168
Validation loss: 2.125724164388513

Epoch: 5| Step: 2
Training loss: 2.7310359477996826
Validation loss: 2.1363907590989144

Epoch: 5| Step: 3
Training loss: 1.7332929372787476
Validation loss: 2.1312714674139537

Epoch: 5| Step: 4
Training loss: 2.1499228477478027
Validation loss: 2.103154411879919

Epoch: 5| Step: 5
Training loss: 2.3130524158477783
Validation loss: 2.102058215807843

Epoch: 5| Step: 6
Training loss: 1.659788727760315
Validation loss: 2.0948193098909114

Epoch: 5| Step: 7
Training loss: 2.9405274391174316
Validation loss: 2.1003228156797347

Epoch: 5| Step: 8
Training loss: 2.0304009914398193
Validation loss: 2.1389654400528118

Epoch: 5| Step: 9
Training loss: 2.345865249633789
Validation loss: 2.12781378915233

Epoch: 5| Step: 10
Training loss: 1.5145241022109985
Validation loss: 2.1305420937076693

Epoch: 221| Step: 0
Training loss: 1.7277454137802124
Validation loss: 2.125590311583652

Epoch: 5| Step: 1
Training loss: 2.553630828857422
Validation loss: 2.106925154245028

Epoch: 5| Step: 2
Training loss: 1.5752286911010742
Validation loss: 2.1154230089597803

Epoch: 5| Step: 3
Training loss: 2.111422300338745
Validation loss: 2.118816473150766

Epoch: 5| Step: 4
Training loss: 2.4498326778411865
Validation loss: 2.1281943359682636

Epoch: 5| Step: 5
Training loss: 2.478341579437256
Validation loss: 2.095699773039869

Epoch: 5| Step: 6
Training loss: 2.1026644706726074
Validation loss: 2.1259817000358336

Epoch: 5| Step: 7
Training loss: 2.7876360416412354
Validation loss: 2.1296980265648133

Epoch: 5| Step: 8
Training loss: 1.2803614139556885
Validation loss: 2.118903935596507

Epoch: 5| Step: 9
Training loss: 2.3613038063049316
Validation loss: 2.1109362135651293

Epoch: 5| Step: 10
Training loss: 1.3080356121063232
Validation loss: 2.1113500646365586

Epoch: 222| Step: 0
Training loss: 2.0400052070617676
Validation loss: 2.0951391035510647

Epoch: 5| Step: 1
Training loss: 2.3944694995880127
Validation loss: 2.0900494155063423

Epoch: 5| Step: 2
Training loss: 1.8542661666870117
Validation loss: 2.101397575870637

Epoch: 5| Step: 3
Training loss: 1.894408941268921
Validation loss: 2.086954370621712

Epoch: 5| Step: 4
Training loss: 1.779658555984497
Validation loss: 2.09609975225182

Epoch: 5| Step: 5
Training loss: 2.2139627933502197
Validation loss: 2.095241690194735

Epoch: 5| Step: 6
Training loss: 1.9589998722076416
Validation loss: 2.0951030305636826

Epoch: 5| Step: 7
Training loss: 1.8586724996566772
Validation loss: 2.0951572515631236

Epoch: 5| Step: 8
Training loss: 2.217865467071533
Validation loss: 2.094703814034821

Epoch: 5| Step: 9
Training loss: 2.88051176071167
Validation loss: 2.0893825100314234

Epoch: 5| Step: 10
Training loss: 1.6382890939712524
Validation loss: 2.1102234701956473

Epoch: 223| Step: 0
Training loss: 1.959803581237793
Validation loss: 2.1122500640089794

Epoch: 5| Step: 1
Training loss: 2.1310315132141113
Validation loss: 2.0965646184900755

Epoch: 5| Step: 2
Training loss: 2.4495983123779297
Validation loss: 2.1012473208929903

Epoch: 5| Step: 3
Training loss: 2.117786407470703
Validation loss: 2.1014600364110803

Epoch: 5| Step: 4
Training loss: 2.367396593093872
Validation loss: 2.101464897073725

Epoch: 5| Step: 5
Training loss: 2.087448835372925
Validation loss: 2.114860280867546

Epoch: 5| Step: 6
Training loss: 2.3116109371185303
Validation loss: 2.1213235162919566

Epoch: 5| Step: 7
Training loss: 2.2874813079833984
Validation loss: 2.1396607275932067

Epoch: 5| Step: 8
Training loss: 2.2492153644561768
Validation loss: 2.133143772361099

Epoch: 5| Step: 9
Training loss: 1.3710821866989136
Validation loss: 2.1069772358863585

Epoch: 5| Step: 10
Training loss: 1.551361322402954
Validation loss: 2.077086571724184

Epoch: 224| Step: 0
Training loss: 1.8633540868759155
Validation loss: 2.0959261386625228

Epoch: 5| Step: 1
Training loss: 2.5825984477996826
Validation loss: 2.106807583121843

Epoch: 5| Step: 2
Training loss: 2.1372485160827637
Validation loss: 2.1004085976590394

Epoch: 5| Step: 3
Training loss: 1.7182486057281494
Validation loss: 2.0934117635091147

Epoch: 5| Step: 4
Training loss: 1.937475562095642
Validation loss: 2.0839271571046565

Epoch: 5| Step: 5
Training loss: 1.695878028869629
Validation loss: 2.075144952343356

Epoch: 5| Step: 6
Training loss: 2.361595392227173
Validation loss: 2.077621304860679

Epoch: 5| Step: 7
Training loss: 2.430102825164795
Validation loss: 2.1129322718548518

Epoch: 5| Step: 8
Training loss: 2.037804365158081
Validation loss: 2.0867523198486655

Epoch: 5| Step: 9
Training loss: 2.005357265472412
Validation loss: 2.1031724740100164

Epoch: 5| Step: 10
Training loss: 2.1582417488098145
Validation loss: 2.1061503169357136

Epoch: 225| Step: 0
Training loss: 1.9999656677246094
Validation loss: 2.1307403451652935

Epoch: 5| Step: 1
Training loss: 2.1660232543945312
Validation loss: 2.123687244230701

Epoch: 5| Step: 2
Training loss: 2.1949238777160645
Validation loss: 2.122237085014261

Epoch: 5| Step: 3
Training loss: 2.521684169769287
Validation loss: 2.1208445692575104

Epoch: 5| Step: 4
Training loss: 2.7736709117889404
Validation loss: 2.1165629458683792

Epoch: 5| Step: 5
Training loss: 2.0626187324523926
Validation loss: 2.1042085155364005

Epoch: 5| Step: 6
Training loss: 1.5503939390182495
Validation loss: 2.087961922409714

Epoch: 5| Step: 7
Training loss: 2.296201467514038
Validation loss: 2.0986490057360743

Epoch: 5| Step: 8
Training loss: 1.6491060256958008
Validation loss: 2.076599697912893

Epoch: 5| Step: 9
Training loss: 1.3079684972763062
Validation loss: 2.0721097351402364

Epoch: 5| Step: 10
Training loss: 2.3669559955596924
Validation loss: 2.0707892217943744

Epoch: 226| Step: 0
Training loss: 2.1408183574676514
Validation loss: 2.0730532907670542

Epoch: 5| Step: 1
Training loss: 1.8919522762298584
Validation loss: 2.0993643217189337

Epoch: 5| Step: 2
Training loss: 2.06069278717041
Validation loss: 2.0998954965222265

Epoch: 5| Step: 3
Training loss: 2.141817808151245
Validation loss: 2.081939652401914

Epoch: 5| Step: 4
Training loss: 2.195857286453247
Validation loss: 2.0921010483977613

Epoch: 5| Step: 5
Training loss: 1.3814259767532349
Validation loss: 2.118983639183865

Epoch: 5| Step: 6
Training loss: 2.345752239227295
Validation loss: 2.1470746917109333

Epoch: 5| Step: 7
Training loss: 2.021879196166992
Validation loss: 2.1566482949000534

Epoch: 5| Step: 8
Training loss: 2.4289464950561523
Validation loss: 2.1736243758150326

Epoch: 5| Step: 9
Training loss: 1.9749122858047485
Validation loss: 2.152115329619377

Epoch: 5| Step: 10
Training loss: 2.113114595413208
Validation loss: 2.1651935731211016

Epoch: 227| Step: 0
Training loss: 2.2554070949554443
Validation loss: 2.1375112251568864

Epoch: 5| Step: 1
Training loss: 1.9238672256469727
Validation loss: 2.1246675675915134

Epoch: 5| Step: 2
Training loss: 2.2840240001678467
Validation loss: 2.114091673204976

Epoch: 5| Step: 3
Training loss: 1.9961175918579102
Validation loss: 2.0947642172536542

Epoch: 5| Step: 4
Training loss: 2.6282360553741455
Validation loss: 2.0913236500114523

Epoch: 5| Step: 5
Training loss: 1.4683115482330322
Validation loss: 2.08343082345942

Epoch: 5| Step: 6
Training loss: 2.006221055984497
Validation loss: 2.0949358952942716

Epoch: 5| Step: 7
Training loss: 2.323343515396118
Validation loss: 2.091376622517904

Epoch: 5| Step: 8
Training loss: 1.842195749282837
Validation loss: 2.099567174911499

Epoch: 5| Step: 9
Training loss: 2.2028355598449707
Validation loss: 2.095580700905092

Epoch: 5| Step: 10
Training loss: 1.612637996673584
Validation loss: 2.0856123534581994

Epoch: 228| Step: 0
Training loss: 2.0693552494049072
Validation loss: 2.07199675549743

Epoch: 5| Step: 1
Training loss: 1.3692325353622437
Validation loss: 2.08372901972904

Epoch: 5| Step: 2
Training loss: 1.9417577981948853
Validation loss: 2.096210102881155

Epoch: 5| Step: 3
Training loss: 2.4844107627868652
Validation loss: 2.110813266487532

Epoch: 5| Step: 4
Training loss: 1.8663638830184937
Validation loss: 2.1389886397187428

Epoch: 5| Step: 5
Training loss: 2.448115587234497
Validation loss: 2.154937417276444

Epoch: 5| Step: 6
Training loss: 2.526901960372925
Validation loss: 2.146025667908371

Epoch: 5| Step: 7
Training loss: 2.505742311477661
Validation loss: 2.160558899243673

Epoch: 5| Step: 8
Training loss: 2.2054171562194824
Validation loss: 2.1771451196362896

Epoch: 5| Step: 9
Training loss: 1.6011158227920532
Validation loss: 2.1423201099518807

Epoch: 5| Step: 10
Training loss: 1.6291106939315796
Validation loss: 2.1206307001011346

Epoch: 229| Step: 0
Training loss: 1.7514396905899048
Validation loss: 2.1076342059719946

Epoch: 5| Step: 1
Training loss: 1.993708610534668
Validation loss: 2.077618142609955

Epoch: 5| Step: 2
Training loss: 1.7989565134048462
Validation loss: 2.0620831238326205

Epoch: 5| Step: 3
Training loss: 1.6940643787384033
Validation loss: 2.0678598073221024

Epoch: 5| Step: 4
Training loss: 2.140193223953247
Validation loss: 2.0577724390132452

Epoch: 5| Step: 5
Training loss: 2.0618245601654053
Validation loss: 2.059265177737

Epoch: 5| Step: 6
Training loss: 2.4941787719726562
Validation loss: 2.0471775224131923

Epoch: 5| Step: 7
Training loss: 2.3051912784576416
Validation loss: 2.0433779967728483

Epoch: 5| Step: 8
Training loss: 1.801203727722168
Validation loss: 2.074509451466222

Epoch: 5| Step: 9
Training loss: 2.232081174850464
Validation loss: 2.069361040669103

Epoch: 5| Step: 10
Training loss: 2.4582834243774414
Validation loss: 2.0985813653597267

Epoch: 230| Step: 0
Training loss: 2.132033348083496
Validation loss: 2.104296194609775

Epoch: 5| Step: 1
Training loss: 1.2206064462661743
Validation loss: 2.092960503793532

Epoch: 5| Step: 2
Training loss: 2.416443347930908
Validation loss: 2.1011171392215195

Epoch: 5| Step: 3
Training loss: 1.5976308584213257
Validation loss: 2.105721583930395

Epoch: 5| Step: 4
Training loss: 1.815711259841919
Validation loss: 2.10013339852774

Epoch: 5| Step: 5
Training loss: 1.4276988506317139
Validation loss: 2.118016976182179

Epoch: 5| Step: 6
Training loss: 2.3247666358947754
Validation loss: 2.113029231307327

Epoch: 5| Step: 7
Training loss: 2.55564284324646
Validation loss: 2.152637240707233

Epoch: 5| Step: 8
Training loss: 2.1944220066070557
Validation loss: 2.1219556203452488

Epoch: 5| Step: 9
Training loss: 2.436488389968872
Validation loss: 2.1511559140297676

Epoch: 5| Step: 10
Training loss: 2.253502607345581
Validation loss: 2.129514269931342

Epoch: 231| Step: 0
Training loss: 1.846483588218689
Validation loss: 2.1596096433619016

Epoch: 5| Step: 1
Training loss: 2.7061219215393066
Validation loss: 2.185737359908319

Epoch: 5| Step: 2
Training loss: 1.9844318628311157
Validation loss: 2.16385002674595

Epoch: 5| Step: 3
Training loss: 1.9084984064102173
Validation loss: 2.1295322025975874

Epoch: 5| Step: 4
Training loss: 1.8959770202636719
Validation loss: 2.125496942509887

Epoch: 5| Step: 5
Training loss: 2.035116672515869
Validation loss: 2.0929094476084553

Epoch: 5| Step: 6
Training loss: 1.8629016876220703
Validation loss: 2.0847664981760006

Epoch: 5| Step: 7
Training loss: 1.9675743579864502
Validation loss: 2.08054292842906

Epoch: 5| Step: 8
Training loss: 2.2707924842834473
Validation loss: 2.0723329308212444

Epoch: 5| Step: 9
Training loss: 2.488717555999756
Validation loss: 2.066447463086856

Epoch: 5| Step: 10
Training loss: 1.7965673208236694
Validation loss: 2.076369498365669

Epoch: 232| Step: 0
Training loss: 2.5859296321868896
Validation loss: 2.068054735019643

Epoch: 5| Step: 1
Training loss: 2.075072765350342
Validation loss: 2.114729077585282

Epoch: 5| Step: 2
Training loss: 1.4194719791412354
Validation loss: 2.108455411849483

Epoch: 5| Step: 3
Training loss: 2.779322862625122
Validation loss: 2.116643677475632

Epoch: 5| Step: 4
Training loss: 2.112274169921875
Validation loss: 2.12292153604569

Epoch: 5| Step: 5
Training loss: 1.5889880657196045
Validation loss: 2.132902609404697

Epoch: 5| Step: 6
Training loss: 1.6678569316864014
Validation loss: 2.0686606194383357

Epoch: 5| Step: 7
Training loss: 2.063910722732544
Validation loss: 2.05742980587867

Epoch: 5| Step: 8
Training loss: 1.6638011932373047
Validation loss: 2.0536383621154295

Epoch: 5| Step: 9
Training loss: 1.8726171255111694
Validation loss: 2.061642628844066

Epoch: 5| Step: 10
Training loss: 2.9346725940704346
Validation loss: 2.0727561878901657

Epoch: 233| Step: 0
Training loss: 1.5202019214630127
Validation loss: 2.080276482848711

Epoch: 5| Step: 1
Training loss: 2.035391330718994
Validation loss: 2.105297601351174

Epoch: 5| Step: 2
Training loss: 2.2562615871429443
Validation loss: 2.103961572852186

Epoch: 5| Step: 3
Training loss: 1.387765645980835
Validation loss: 2.1295485060702086

Epoch: 5| Step: 4
Training loss: 1.7315067052841187
Validation loss: 2.12187526559317

Epoch: 5| Step: 5
Training loss: 2.5249245166778564
Validation loss: 2.1825824117147796

Epoch: 5| Step: 6
Training loss: 2.094177007675171
Validation loss: 2.206525980785329

Epoch: 5| Step: 7
Training loss: 1.7316936254501343
Validation loss: 2.1755910176102833

Epoch: 5| Step: 8
Training loss: 1.966317892074585
Validation loss: 2.1713749977850143

Epoch: 5| Step: 9
Training loss: 2.530224561691284
Validation loss: 2.1492271884795158

Epoch: 5| Step: 10
Training loss: 2.7845897674560547
Validation loss: 2.130889420868248

Epoch: 234| Step: 0
Training loss: 1.9621860980987549
Validation loss: 2.1246080860014884

Epoch: 5| Step: 1
Training loss: 2.4363996982574463
Validation loss: 2.101040719657816

Epoch: 5| Step: 2
Training loss: 2.067643404006958
Validation loss: 2.0979486332144788

Epoch: 5| Step: 3
Training loss: 1.9941720962524414
Validation loss: 2.0917043045002925

Epoch: 5| Step: 4
Training loss: 1.9106037616729736
Validation loss: 2.1088809928586407

Epoch: 5| Step: 5
Training loss: 1.9503650665283203
Validation loss: 2.1134448884635844

Epoch: 5| Step: 6
Training loss: 2.0694870948791504
Validation loss: 2.095345479185863

Epoch: 5| Step: 7
Training loss: 2.2920737266540527
Validation loss: 2.0900575935199694

Epoch: 5| Step: 8
Training loss: 2.4805877208709717
Validation loss: 2.0860318060844176

Epoch: 5| Step: 9
Training loss: 1.515221357345581
Validation loss: 2.0879445973262993

Epoch: 5| Step: 10
Training loss: 1.4315030574798584
Validation loss: 2.116338037675427

Epoch: 235| Step: 0
Training loss: 2.5268821716308594
Validation loss: 2.131893309213782

Epoch: 5| Step: 1
Training loss: 2.3676109313964844
Validation loss: 2.1335849864508516

Epoch: 5| Step: 2
Training loss: 1.6144511699676514
Validation loss: 2.135485044089697

Epoch: 5| Step: 3
Training loss: 2.0329575538635254
Validation loss: 2.1547559717650056

Epoch: 5| Step: 4
Training loss: 1.3254387378692627
Validation loss: 2.148033834272815

Epoch: 5| Step: 5
Training loss: 1.8735145330429077
Validation loss: 2.1746626130996214

Epoch: 5| Step: 6
Training loss: 2.1466355323791504
Validation loss: 2.1905932298270603

Epoch: 5| Step: 7
Training loss: 1.7170480489730835
Validation loss: 2.17163259495971

Epoch: 5| Step: 8
Training loss: 1.8293718099594116
Validation loss: 2.1597351207528064

Epoch: 5| Step: 9
Training loss: 2.4007017612457275
Validation loss: 2.143493870253204

Epoch: 5| Step: 10
Training loss: 2.4109740257263184
Validation loss: 2.126413345336914

Epoch: 236| Step: 0
Training loss: 2.3235697746276855
Validation loss: 2.1250791498409805

Epoch: 5| Step: 1
Training loss: 1.7290220260620117
Validation loss: 2.1258281277072046

Epoch: 5| Step: 2
Training loss: 1.9710371494293213
Validation loss: 2.137355791625156

Epoch: 5| Step: 3
Training loss: 1.5430729389190674
Validation loss: 2.1392101562151344

Epoch: 5| Step: 4
Training loss: 1.5059703588485718
Validation loss: 2.149698272828133

Epoch: 5| Step: 5
Training loss: 2.776885986328125
Validation loss: 2.14886869922761

Epoch: 5| Step: 6
Training loss: 1.9333617687225342
Validation loss: 2.1468125222831644

Epoch: 5| Step: 7
Training loss: 1.7117173671722412
Validation loss: 2.143209106178694

Epoch: 5| Step: 8
Training loss: 2.1338112354278564
Validation loss: 2.129335823879447

Epoch: 5| Step: 9
Training loss: 2.118983745574951
Validation loss: 2.1248351117616058

Epoch: 5| Step: 10
Training loss: 2.42484188079834
Validation loss: 2.0995820030089347

Epoch: 237| Step: 0
Training loss: 1.9673030376434326
Validation loss: 2.0794439341432307

Epoch: 5| Step: 1
Training loss: 2.2719669342041016
Validation loss: 2.0983193177048878

Epoch: 5| Step: 2
Training loss: 1.9185771942138672
Validation loss: 2.0839176767615863

Epoch: 5| Step: 3
Training loss: 2.0193090438842773
Validation loss: 2.0497707141342985

Epoch: 5| Step: 4
Training loss: 2.398650646209717
Validation loss: 2.0707080569318546

Epoch: 5| Step: 5
Training loss: 1.4221935272216797
Validation loss: 2.062451554882911

Epoch: 5| Step: 6
Training loss: 2.817107677459717
Validation loss: 2.0883350141586794

Epoch: 5| Step: 7
Training loss: 2.1333956718444824
Validation loss: 2.073669743794267

Epoch: 5| Step: 8
Training loss: 1.6546121835708618
Validation loss: 2.0947732592141755

Epoch: 5| Step: 9
Training loss: 1.7229087352752686
Validation loss: 2.1079319382226593

Epoch: 5| Step: 10
Training loss: 1.615142822265625
Validation loss: 2.1324326428033973

Epoch: 238| Step: 0
Training loss: 2.106518030166626
Validation loss: 2.155939873828683

Epoch: 5| Step: 1
Training loss: 2.502078056335449
Validation loss: 2.170928793568765

Epoch: 5| Step: 2
Training loss: 1.7164056301116943
Validation loss: 2.169579111119752

Epoch: 5| Step: 3
Training loss: 1.7033615112304688
Validation loss: 2.1698647391411567

Epoch: 5| Step: 4
Training loss: 1.2500184774398804
Validation loss: 2.1194306342832503

Epoch: 5| Step: 5
Training loss: 1.8374207019805908
Validation loss: 2.1037654876708984

Epoch: 5| Step: 6
Training loss: 2.15750789642334
Validation loss: 2.1026211502731487

Epoch: 5| Step: 7
Training loss: 2.3235764503479004
Validation loss: 2.0812137229468233

Epoch: 5| Step: 8
Training loss: 1.7942196130752563
Validation loss: 2.092101898244632

Epoch: 5| Step: 9
Training loss: 1.9202629327774048
Validation loss: 2.0976024423876116

Epoch: 5| Step: 10
Training loss: 2.8985729217529297
Validation loss: 2.104347131585562

Epoch: 239| Step: 0
Training loss: 1.480769395828247
Validation loss: 2.1006636235021774

Epoch: 5| Step: 1
Training loss: 2.256126642227173
Validation loss: 2.109538992245992

Epoch: 5| Step: 2
Training loss: 2.637336015701294
Validation loss: 2.1067324094874884

Epoch: 5| Step: 3
Training loss: 1.8744852542877197
Validation loss: 2.0948499735965522

Epoch: 5| Step: 4
Training loss: 1.4262983798980713
Validation loss: 2.0998773677374727

Epoch: 5| Step: 5
Training loss: 1.4865926504135132
Validation loss: 2.108985854733375

Epoch: 5| Step: 6
Training loss: 2.5250887870788574
Validation loss: 2.087843853940246

Epoch: 5| Step: 7
Training loss: 2.142393112182617
Validation loss: 2.10108595766047

Epoch: 5| Step: 8
Training loss: 1.8341491222381592
Validation loss: 2.1303188339356454

Epoch: 5| Step: 9
Training loss: 1.9647178649902344
Validation loss: 2.1023396022858156

Epoch: 5| Step: 10
Training loss: 2.092447280883789
Validation loss: 2.121589900344931

Epoch: 240| Step: 0
Training loss: 1.5005959272384644
Validation loss: 2.1113735616848035

Epoch: 5| Step: 1
Training loss: 1.9864399433135986
Validation loss: 2.1335383076821604

Epoch: 5| Step: 2
Training loss: 2.345412015914917
Validation loss: 2.0987957844170193

Epoch: 5| Step: 3
Training loss: 2.0518317222595215
Validation loss: 2.1067444444984518

Epoch: 5| Step: 4
Training loss: 1.6500608921051025
Validation loss: 2.1096291542053223

Epoch: 5| Step: 5
Training loss: 1.7549136877059937
Validation loss: 2.09335300999303

Epoch: 5| Step: 6
Training loss: 2.187523365020752
Validation loss: 2.08431573324306

Epoch: 5| Step: 7
Training loss: 2.100205898284912
Validation loss: 2.0892498429103563

Epoch: 5| Step: 8
Training loss: 2.1001923084259033
Validation loss: 2.0790763798580376

Epoch: 5| Step: 9
Training loss: 1.9909675121307373
Validation loss: 2.1061331687435025

Epoch: 5| Step: 10
Training loss: 2.058126211166382
Validation loss: 2.081791936710317

Epoch: 241| Step: 0
Training loss: 2.135948419570923
Validation loss: 2.1064370447589504

Epoch: 5| Step: 1
Training loss: 1.6318235397338867
Validation loss: 2.1147290199033675

Epoch: 5| Step: 2
Training loss: 2.4098422527313232
Validation loss: 2.1252046451773694

Epoch: 5| Step: 3
Training loss: 1.8363761901855469
Validation loss: 2.145102357351652

Epoch: 5| Step: 4
Training loss: 1.7915016412734985
Validation loss: 2.1751100465815556

Epoch: 5| Step: 5
Training loss: 1.9975078105926514
Validation loss: 2.188347476784901

Epoch: 5| Step: 6
Training loss: 2.1452198028564453
Validation loss: 2.183216153934438

Epoch: 5| Step: 7
Training loss: 2.183889389038086
Validation loss: 2.2147972917044036

Epoch: 5| Step: 8
Training loss: 2.039719581604004
Validation loss: 2.208058839203209

Epoch: 5| Step: 9
Training loss: 1.7832103967666626
Validation loss: 2.2202736370025145

Epoch: 5| Step: 10
Training loss: 1.964781403541565
Validation loss: 2.1823043566878124

Epoch: 242| Step: 0
Training loss: 2.2488999366760254
Validation loss: 2.1811813077619

Epoch: 5| Step: 1
Training loss: 2.06744647026062
Validation loss: 2.142906765783987

Epoch: 5| Step: 2
Training loss: 1.547055959701538
Validation loss: 2.1029318481363277

Epoch: 5| Step: 3
Training loss: 2.093337059020996
Validation loss: 2.063679547720058

Epoch: 5| Step: 4
Training loss: 2.0968432426452637
Validation loss: 2.0885344423273557

Epoch: 5| Step: 5
Training loss: 2.4607045650482178
Validation loss: 2.1112271252498833

Epoch: 5| Step: 6
Training loss: 2.057976484298706
Validation loss: 2.140369507574266

Epoch: 5| Step: 7
Training loss: 1.7873340845108032
Validation loss: 2.136490819274738

Epoch: 5| Step: 8
Training loss: 1.305374264717102
Validation loss: 2.1071056550548923

Epoch: 5| Step: 9
Training loss: 2.5157294273376465
Validation loss: 2.0554122258258123

Epoch: 5| Step: 10
Training loss: 2.5258500576019287
Validation loss: 2.054381570508403

Epoch: 243| Step: 0
Training loss: 2.2496612071990967
Validation loss: 2.0634222902277464

Epoch: 5| Step: 1
Training loss: 2.232966899871826
Validation loss: 2.077328371745284

Epoch: 5| Step: 2
Training loss: 2.10615873336792
Validation loss: 2.0827927268961424

Epoch: 5| Step: 3
Training loss: 2.2823574542999268
Validation loss: 2.109673128333143

Epoch: 5| Step: 4
Training loss: 2.5236988067626953
Validation loss: 2.115426213510575

Epoch: 5| Step: 5
Training loss: 1.6317211389541626
Validation loss: 2.1202066559945383

Epoch: 5| Step: 6
Training loss: 1.3379127979278564
Validation loss: 2.1105522673617125

Epoch: 5| Step: 7
Training loss: 1.6059544086456299
Validation loss: 2.1312411472361577

Epoch: 5| Step: 8
Training loss: 1.9289964437484741
Validation loss: 2.155168466670539

Epoch: 5| Step: 9
Training loss: 1.7122671604156494
Validation loss: 2.171534538269043

Epoch: 5| Step: 10
Training loss: 2.5502564907073975
Validation loss: 2.1878516417677685

Epoch: 244| Step: 0
Training loss: 1.394939661026001
Validation loss: 2.1918862801726147

Epoch: 5| Step: 1
Training loss: 1.5092970132827759
Validation loss: 2.140549607174371

Epoch: 5| Step: 2
Training loss: 1.7824490070343018
Validation loss: 2.120346519254869

Epoch: 5| Step: 3
Training loss: 2.230822801589966
Validation loss: 2.1288200886018815

Epoch: 5| Step: 4
Training loss: 1.9831225872039795
Validation loss: 2.137910945441133

Epoch: 5| Step: 5
Training loss: 1.9401391744613647
Validation loss: 2.144903403456493

Epoch: 5| Step: 6
Training loss: 2.1267752647399902
Validation loss: 2.145037207552182

Epoch: 5| Step: 7
Training loss: 2.679628610610962
Validation loss: 2.1260723247322986

Epoch: 5| Step: 8
Training loss: 1.8063945770263672
Validation loss: 2.1283234703925347

Epoch: 5| Step: 9
Training loss: 2.0026683807373047
Validation loss: 2.115955706565611

Epoch: 5| Step: 10
Training loss: 2.277137517929077
Validation loss: 2.0977849985963557

Epoch: 245| Step: 0
Training loss: 1.8277002573013306
Validation loss: 2.1161765616427184

Epoch: 5| Step: 1
Training loss: 2.012162446975708
Validation loss: 2.119710906859367

Epoch: 5| Step: 2
Training loss: 1.8725337982177734
Validation loss: 2.130067390780295

Epoch: 5| Step: 3
Training loss: 1.7534968852996826
Validation loss: 2.119174570165655

Epoch: 5| Step: 4
Training loss: 1.7794002294540405
Validation loss: 2.1419950890284714

Epoch: 5| Step: 5
Training loss: 2.021876811981201
Validation loss: 2.152460987849902

Epoch: 5| Step: 6
Training loss: 1.9634615182876587
Validation loss: 2.169227797497985

Epoch: 5| Step: 7
Training loss: 1.7282307147979736
Validation loss: 2.1377172598274807

Epoch: 5| Step: 8
Training loss: 2.142958879470825
Validation loss: 2.1338859860615065

Epoch: 5| Step: 9
Training loss: 2.4726758003234863
Validation loss: 2.113041834164691

Epoch: 5| Step: 10
Training loss: 1.6433823108673096
Validation loss: 2.1220678911414197

Epoch: 246| Step: 0
Training loss: 2.2936341762542725
Validation loss: 2.085134688244071

Epoch: 5| Step: 1
Training loss: 2.3666043281555176
Validation loss: 2.071204444413544

Epoch: 5| Step: 2
Training loss: 1.620523452758789
Validation loss: 2.0824048570407334

Epoch: 5| Step: 3
Training loss: 1.7286088466644287
Validation loss: 2.077440068285952

Epoch: 5| Step: 4
Training loss: 1.9247499704360962
Validation loss: 2.06354231860048

Epoch: 5| Step: 5
Training loss: 2.267033815383911
Validation loss: 2.066654492450017

Epoch: 5| Step: 6
Training loss: 1.6201118230819702
Validation loss: 2.069483618582449

Epoch: 5| Step: 7
Training loss: 1.8035087585449219
Validation loss: 2.0863866729121052

Epoch: 5| Step: 8
Training loss: 2.245720148086548
Validation loss: 2.1008622684786395

Epoch: 5| Step: 9
Training loss: 2.063573122024536
Validation loss: 2.119442496248471

Epoch: 5| Step: 10
Training loss: 1.4122865200042725
Validation loss: 2.096164870005782

Epoch: 247| Step: 0
Training loss: 1.7117217779159546
Validation loss: 2.1370802438387306

Epoch: 5| Step: 1
Training loss: 1.8353688716888428
Validation loss: 2.149284719139017

Epoch: 5| Step: 2
Training loss: 1.3361846208572388
Validation loss: 2.1416402798826977

Epoch: 5| Step: 3
Training loss: 1.8701248168945312
Validation loss: 2.1758195405365317

Epoch: 5| Step: 4
Training loss: 2.1836209297180176
Validation loss: 2.16347183463394

Epoch: 5| Step: 5
Training loss: 2.1101112365722656
Validation loss: 2.1677970834957656

Epoch: 5| Step: 6
Training loss: 2.019641399383545
Validation loss: 2.180921721202071

Epoch: 5| Step: 7
Training loss: 2.371407985687256
Validation loss: 2.147101734274177

Epoch: 5| Step: 8
Training loss: 1.5916173458099365
Validation loss: 2.142877217262022

Epoch: 5| Step: 9
Training loss: 2.2109248638153076
Validation loss: 2.1297013939067884

Epoch: 5| Step: 10
Training loss: 2.073899745941162
Validation loss: 2.1346554935619397

Epoch: 248| Step: 0
Training loss: 1.167606234550476
Validation loss: 2.166303380843132

Epoch: 5| Step: 1
Training loss: 2.2765166759490967
Validation loss: 2.1414853936882428

Epoch: 5| Step: 2
Training loss: 2.140343189239502
Validation loss: 2.1466082860064764

Epoch: 5| Step: 3
Training loss: 1.7628530263900757
Validation loss: 2.1235423139346543

Epoch: 5| Step: 4
Training loss: 2.236550807952881
Validation loss: 2.119833056644727

Epoch: 5| Step: 5
Training loss: 1.595309853553772
Validation loss: 2.125073566231676

Epoch: 5| Step: 6
Training loss: 2.2059929370880127
Validation loss: 2.093962164335353

Epoch: 5| Step: 7
Training loss: 1.625431776046753
Validation loss: 2.0986718759741834

Epoch: 5| Step: 8
Training loss: 1.9152250289916992
Validation loss: 2.100296269180954

Epoch: 5| Step: 9
Training loss: 2.080720901489258
Validation loss: 2.1278041011543682

Epoch: 5| Step: 10
Training loss: 2.2669517993927
Validation loss: 2.0995177325382026

Epoch: 249| Step: 0
Training loss: 1.8840982913970947
Validation loss: 2.111977695136942

Epoch: 5| Step: 1
Training loss: 2.4932799339294434
Validation loss: 2.1201405102206814

Epoch: 5| Step: 2
Training loss: 1.8152440786361694
Validation loss: 2.1284314086360316

Epoch: 5| Step: 3
Training loss: 2.135152578353882
Validation loss: 2.1262451628203034

Epoch: 5| Step: 4
Training loss: 1.403444766998291
Validation loss: 2.147415381605907

Epoch: 5| Step: 5
Training loss: 1.3922374248504639
Validation loss: 2.1399653855190484

Epoch: 5| Step: 6
Training loss: 1.6136844158172607
Validation loss: 2.1238342562029437

Epoch: 5| Step: 7
Training loss: 1.8952299356460571
Validation loss: 2.113183508637131

Epoch: 5| Step: 8
Training loss: 2.230811357498169
Validation loss: 2.121701458449005

Epoch: 5| Step: 9
Training loss: 2.335395336151123
Validation loss: 2.1528902733197777

Epoch: 5| Step: 10
Training loss: 2.1201541423797607
Validation loss: 2.1506489156394877

Epoch: 250| Step: 0
Training loss: 2.022277355194092
Validation loss: 2.161111318936912

Epoch: 5| Step: 1
Training loss: 1.72431218624115
Validation loss: 2.1602939098112044

Epoch: 5| Step: 2
Training loss: 1.6269235610961914
Validation loss: 2.169535490774339

Epoch: 5| Step: 3
Training loss: 1.5175514221191406
Validation loss: 2.1707089639479116

Epoch: 5| Step: 4
Training loss: 2.220311403274536
Validation loss: 2.138956723674651

Epoch: 5| Step: 5
Training loss: 1.8261076211929321
Validation loss: 2.1489882148722166

Epoch: 5| Step: 6
Training loss: 2.2013161182403564
Validation loss: 2.120303976920343

Epoch: 5| Step: 7
Training loss: 1.9206931591033936
Validation loss: 2.10068944961794

Epoch: 5| Step: 8
Training loss: 2.029625415802002
Validation loss: 2.0737220074540827

Epoch: 5| Step: 9
Training loss: 2.3925840854644775
Validation loss: 2.0545099243041007

Epoch: 5| Step: 10
Training loss: 1.6326994895935059
Validation loss: 2.05254449126541

Epoch: 251| Step: 0
Training loss: 1.8652279376983643
Validation loss: 2.0550161869295183

Epoch: 5| Step: 1
Training loss: 2.1875486373901367
Validation loss: 2.072377820168772

Epoch: 5| Step: 2
Training loss: 1.727168083190918
Validation loss: 2.073444903537791

Epoch: 5| Step: 3
Training loss: 2.557508707046509
Validation loss: 2.1089654942994476

Epoch: 5| Step: 4
Training loss: 1.9427311420440674
Validation loss: 2.0846683056123796

Epoch: 5| Step: 5
Training loss: 1.834297776222229
Validation loss: 2.101471749685144

Epoch: 5| Step: 6
Training loss: 1.2942783832550049
Validation loss: 2.1122699194057013

Epoch: 5| Step: 7
Training loss: 2.247098922729492
Validation loss: 2.093095426918358

Epoch: 5| Step: 8
Training loss: 1.6994960308074951
Validation loss: 2.1019426699607604

Epoch: 5| Step: 9
Training loss: 1.9613615274429321
Validation loss: 2.1070197218207904

Epoch: 5| Step: 10
Training loss: 1.519873023033142
Validation loss: 2.099107970473587

Epoch: 252| Step: 0
Training loss: 1.5896331071853638
Validation loss: 2.146635374715251

Epoch: 5| Step: 1
Training loss: 1.1478097438812256
Validation loss: 2.1272166236754386

Epoch: 5| Step: 2
Training loss: 1.4698619842529297
Validation loss: 2.154429039647502

Epoch: 5| Step: 3
Training loss: 1.7628581523895264
Validation loss: 2.1587327295734036

Epoch: 5| Step: 4
Training loss: 2.146662712097168
Validation loss: 2.1610853390027116

Epoch: 5| Step: 5
Training loss: 2.5647711753845215
Validation loss: 2.1728812417676373

Epoch: 5| Step: 6
Training loss: 1.883744239807129
Validation loss: 2.168505376385104

Epoch: 5| Step: 7
Training loss: 2.258188486099243
Validation loss: 2.1541088217048237

Epoch: 5| Step: 8
Training loss: 2.557098150253296
Validation loss: 2.126101447689918

Epoch: 5| Step: 9
Training loss: 1.8592357635498047
Validation loss: 2.104339627809422

Epoch: 5| Step: 10
Training loss: 1.5828971862792969
Validation loss: 2.0825295371394

Epoch: 253| Step: 0
Training loss: 1.7937633991241455
Validation loss: 2.0866465709542714

Epoch: 5| Step: 1
Training loss: 2.1154868602752686
Validation loss: 2.102752685546875

Epoch: 5| Step: 2
Training loss: 2.2616350650787354
Validation loss: 2.102056981414877

Epoch: 5| Step: 3
Training loss: 1.9252851009368896
Validation loss: 2.106272259066182

Epoch: 5| Step: 4
Training loss: 2.0520362854003906
Validation loss: 2.098852975394136

Epoch: 5| Step: 5
Training loss: 2.2917773723602295
Validation loss: 2.082959385328395

Epoch: 5| Step: 6
Training loss: 2.0145411491394043
Validation loss: 2.0862243906144173

Epoch: 5| Step: 7
Training loss: 1.7214444875717163
Validation loss: 2.0927740399555494

Epoch: 5| Step: 8
Training loss: 1.5660804510116577
Validation loss: 2.1011063232216785

Epoch: 5| Step: 9
Training loss: 1.4951225519180298
Validation loss: 2.1182291892267044

Epoch: 5| Step: 10
Training loss: 1.3851618766784668
Validation loss: 2.1188226899793072

Epoch: 254| Step: 0
Training loss: 2.184753179550171
Validation loss: 2.1507118337897846

Epoch: 5| Step: 1
Training loss: 2.057424306869507
Validation loss: 2.173953272963083

Epoch: 5| Step: 2
Training loss: 1.3285629749298096
Validation loss: 2.190750575834705

Epoch: 5| Step: 3
Training loss: 1.5336055755615234
Validation loss: 2.2212729159221856

Epoch: 5| Step: 4
Training loss: 2.4391961097717285
Validation loss: 2.2199508913101687

Epoch: 5| Step: 5
Training loss: 1.937168836593628
Validation loss: 2.207965240683607

Epoch: 5| Step: 6
Training loss: 1.2317795753479004
Validation loss: 2.1794382269664476

Epoch: 5| Step: 7
Training loss: 2.2329177856445312
Validation loss: 2.1643271830774125

Epoch: 5| Step: 8
Training loss: 1.9187629222869873
Validation loss: 2.174314098973428

Epoch: 5| Step: 9
Training loss: 2.2497851848602295
Validation loss: 2.134354335005565

Epoch: 5| Step: 10
Training loss: 1.4161125421524048
Validation loss: 2.1230470775276102

Epoch: 255| Step: 0
Training loss: 2.2028489112854004
Validation loss: 2.10158028910237

Epoch: 5| Step: 1
Training loss: 1.5322760343551636
Validation loss: 2.0923241030785347

Epoch: 5| Step: 2
Training loss: 1.9521701335906982
Validation loss: 2.0942779484615532

Epoch: 5| Step: 3
Training loss: 1.8467715978622437
Validation loss: 2.0693843133987917

Epoch: 5| Step: 4
Training loss: 2.2006542682647705
Validation loss: 2.082280279487692

Epoch: 5| Step: 5
Training loss: 2.0856411457061768
Validation loss: 2.0669594464763517

Epoch: 5| Step: 6
Training loss: 1.5556681156158447
Validation loss: 2.086980614610898

Epoch: 5| Step: 7
Training loss: 2.2986397743225098
Validation loss: 2.1358232087986444

Epoch: 5| Step: 8
Training loss: 1.5801160335540771
Validation loss: 2.176652980107133

Epoch: 5| Step: 9
Training loss: 1.8271421194076538
Validation loss: 2.195075591405233

Epoch: 5| Step: 10
Training loss: 1.7564600706100464
Validation loss: 2.186016087890953

Epoch: 256| Step: 0
Training loss: 2.153524398803711
Validation loss: 2.1559521767400924

Epoch: 5| Step: 1
Training loss: 1.5736852884292603
Validation loss: 2.12402505131178

Epoch: 5| Step: 2
Training loss: 2.1270172595977783
Validation loss: 2.1108472398532334

Epoch: 5| Step: 3
Training loss: 1.0610853433609009
Validation loss: 2.1190757597646406

Epoch: 5| Step: 4
Training loss: 2.1119189262390137
Validation loss: 2.088816132596744

Epoch: 5| Step: 5
Training loss: 1.5676915645599365
Validation loss: 2.094950663146152

Epoch: 5| Step: 6
Training loss: 2.3467845916748047
Validation loss: 2.0951938500968357

Epoch: 5| Step: 7
Training loss: 1.827214241027832
Validation loss: 2.108766991605041

Epoch: 5| Step: 8
Training loss: 2.156705141067505
Validation loss: 2.08378029125993

Epoch: 5| Step: 9
Training loss: 2.0524563789367676
Validation loss: 2.1389550547445975

Epoch: 5| Step: 10
Training loss: 1.673813819885254
Validation loss: 2.1279429005038355

Epoch: 257| Step: 0
Training loss: 1.8911917209625244
Validation loss: 2.1217288406946326

Epoch: 5| Step: 1
Training loss: 1.9738785028457642
Validation loss: 2.0978994113142773

Epoch: 5| Step: 2
Training loss: 1.4430129528045654
Validation loss: 2.106946793935632

Epoch: 5| Step: 3
Training loss: 1.8125505447387695
Validation loss: 2.1365189577943537

Epoch: 5| Step: 4
Training loss: 1.6083519458770752
Validation loss: 2.1134513834471345

Epoch: 5| Step: 5
Training loss: 2.1798322200775146
Validation loss: 2.116594135120351

Epoch: 5| Step: 6
Training loss: 2.278550863265991
Validation loss: 2.1286872433077906

Epoch: 5| Step: 7
Training loss: 1.4467450380325317
Validation loss: 2.145849702178791

Epoch: 5| Step: 8
Training loss: 1.8287475109100342
Validation loss: 2.1220669182397986

Epoch: 5| Step: 9
Training loss: 2.047311782836914
Validation loss: 2.1281470790986092

Epoch: 5| Step: 10
Training loss: 1.7916536331176758
Validation loss: 2.1202755538366174

Epoch: 258| Step: 0
Training loss: 1.4263763427734375
Validation loss: 2.1399120002664547

Epoch: 5| Step: 1
Training loss: 2.467890977859497
Validation loss: 2.112882343671655

Epoch: 5| Step: 2
Training loss: 1.9523500204086304
Validation loss: 2.1135184226497525

Epoch: 5| Step: 3
Training loss: 1.3266624212265015
Validation loss: 2.1152869885967625

Epoch: 5| Step: 4
Training loss: 1.3676559925079346
Validation loss: 2.125817104052472

Epoch: 5| Step: 5
Training loss: 2.0617191791534424
Validation loss: 2.1075491597575526

Epoch: 5| Step: 6
Training loss: 1.6767733097076416
Validation loss: 2.0928647389975925

Epoch: 5| Step: 7
Training loss: 2.1224608421325684
Validation loss: 2.0871893705860263

Epoch: 5| Step: 8
Training loss: 1.9426014423370361
Validation loss: 2.085589152510448

Epoch: 5| Step: 9
Training loss: 1.7289247512817383
Validation loss: 2.087478668459

Epoch: 5| Step: 10
Training loss: 2.422758102416992
Validation loss: 2.1025498759362007

Epoch: 259| Step: 0
Training loss: 1.6763191223144531
Validation loss: 2.1207782786379576

Epoch: 5| Step: 1
Training loss: 1.484784483909607
Validation loss: 2.1198601312534784

Epoch: 5| Step: 2
Training loss: 1.6758606433868408
Validation loss: 2.1373667768252793

Epoch: 5| Step: 3
Training loss: 2.160130500793457
Validation loss: 2.1502239447768017

Epoch: 5| Step: 4
Training loss: 1.3983756303787231
Validation loss: 2.1734938980430685

Epoch: 5| Step: 5
Training loss: 1.0232878923416138
Validation loss: 2.1632897802578506

Epoch: 5| Step: 6
Training loss: 2.4805312156677246
Validation loss: 2.1881109873453775

Epoch: 5| Step: 7
Training loss: 2.4678711891174316
Validation loss: 2.1689869716603267

Epoch: 5| Step: 8
Training loss: 1.5670111179351807
Validation loss: 2.188501860505791

Epoch: 5| Step: 9
Training loss: 2.1406826972961426
Validation loss: 2.1730319992188485

Epoch: 5| Step: 10
Training loss: 2.1023993492126465
Validation loss: 2.194952746873261

Epoch: 260| Step: 0
Training loss: 1.2844781875610352
Validation loss: 2.1795253215297574

Epoch: 5| Step: 1
Training loss: 2.5169224739074707
Validation loss: 2.1668708298795964

Epoch: 5| Step: 2
Training loss: 1.8533920049667358
Validation loss: 2.1366514800697245

Epoch: 5| Step: 3
Training loss: 2.0835344791412354
Validation loss: 2.1086032518776516

Epoch: 5| Step: 4
Training loss: 2.1471645832061768
Validation loss: 2.1128665003725278

Epoch: 5| Step: 5
Training loss: 1.7497036457061768
Validation loss: 2.126151712991858

Epoch: 5| Step: 6
Training loss: 1.4730374813079834
Validation loss: 2.115314306751374

Epoch: 5| Step: 7
Training loss: 1.5175126791000366
Validation loss: 2.117691127202844

Epoch: 5| Step: 8
Training loss: 2.3596298694610596
Validation loss: 2.11473431382128

Epoch: 5| Step: 9
Training loss: 1.5121443271636963
Validation loss: 2.1239870645666636

Epoch: 5| Step: 10
Training loss: 1.6277004480361938
Validation loss: 2.127898675139232

Epoch: 261| Step: 0
Training loss: 1.7421766519546509
Validation loss: 2.103293372738746

Epoch: 5| Step: 1
Training loss: 1.4801808595657349
Validation loss: 2.115067534549262

Epoch: 5| Step: 2
Training loss: 1.5406100749969482
Validation loss: 2.1231730086829073

Epoch: 5| Step: 3
Training loss: 2.0900237560272217
Validation loss: 2.1428503887627715

Epoch: 5| Step: 4
Training loss: 2.8994851112365723
Validation loss: 2.1598755377595142

Epoch: 5| Step: 5
Training loss: 1.6830717325210571
Validation loss: 2.128436593599217

Epoch: 5| Step: 6
Training loss: 1.947654366493225
Validation loss: 2.154747288714173

Epoch: 5| Step: 7
Training loss: 1.6073100566864014
Validation loss: 2.1362371803611837

Epoch: 5| Step: 8
Training loss: 1.785906434059143
Validation loss: 2.1121679685449086

Epoch: 5| Step: 9
Training loss: 1.7864192724227905
Validation loss: 2.1116021064019974

Epoch: 5| Step: 10
Training loss: 1.6611248254776
Validation loss: 2.109595675622263

Epoch: 262| Step: 0
Training loss: 1.020029067993164
Validation loss: 2.105143239421229

Epoch: 5| Step: 1
Training loss: 1.6851905584335327
Validation loss: 2.0986727206937728

Epoch: 5| Step: 2
Training loss: 1.2388107776641846
Validation loss: 2.1473295060537194

Epoch: 5| Step: 3
Training loss: 2.411947727203369
Validation loss: 2.1556302347490863

Epoch: 5| Step: 4
Training loss: 2.8217051029205322
Validation loss: 2.192297271502915

Epoch: 5| Step: 5
Training loss: 1.751590371131897
Validation loss: 2.1770082160990727

Epoch: 5| Step: 6
Training loss: 1.3381049633026123
Validation loss: 2.1537585899394047

Epoch: 5| Step: 7
Training loss: 1.8596878051757812
Validation loss: 2.153336223735604

Epoch: 5| Step: 8
Training loss: 2.37689208984375
Validation loss: 2.1518506516692457

Epoch: 5| Step: 9
Training loss: 1.694909691810608
Validation loss: 2.1615528573272047

Epoch: 5| Step: 10
Training loss: 2.2042129039764404
Validation loss: 2.1571433697977374

Epoch: 263| Step: 0
Training loss: 2.2406606674194336
Validation loss: 2.1667804102743826

Epoch: 5| Step: 1
Training loss: 1.5222365856170654
Validation loss: 2.187197664732574

Epoch: 5| Step: 2
Training loss: 1.755694031715393
Validation loss: 2.2040873266035512

Epoch: 5| Step: 3
Training loss: 1.3750102519989014
Validation loss: 2.2232758665597565

Epoch: 5| Step: 4
Training loss: 2.340244770050049
Validation loss: 2.2501368599553264

Epoch: 5| Step: 5
Training loss: 1.525812029838562
Validation loss: 2.2272524577315136

Epoch: 5| Step: 6
Training loss: 1.7978805303573608
Validation loss: 2.1961128096426688

Epoch: 5| Step: 7
Training loss: 2.1358113288879395
Validation loss: 2.184457281584381

Epoch: 5| Step: 8
Training loss: 2.1746773719787598
Validation loss: 2.141039830382152

Epoch: 5| Step: 9
Training loss: 1.829763412475586
Validation loss: 2.0986309154059297

Epoch: 5| Step: 10
Training loss: 2.065788507461548
Validation loss: 2.1050686387605566

Epoch: 264| Step: 0
Training loss: 1.8085839748382568
Validation loss: 2.0937770976815173

Epoch: 5| Step: 1
Training loss: 0.9428704977035522
Validation loss: 2.0714585191460064

Epoch: 5| Step: 2
Training loss: 1.7673122882843018
Validation loss: 2.051120978529735

Epoch: 5| Step: 3
Training loss: 1.8141889572143555
Validation loss: 2.0936911567564933

Epoch: 5| Step: 4
Training loss: 2.0178520679473877
Validation loss: 2.0868562447127474

Epoch: 5| Step: 5
Training loss: 2.011176586151123
Validation loss: 2.116819384277508

Epoch: 5| Step: 6
Training loss: 1.9359657764434814
Validation loss: 2.1032172608119186

Epoch: 5| Step: 7
Training loss: 1.9937629699707031
Validation loss: 2.119510755744032

Epoch: 5| Step: 8
Training loss: 1.7641270160675049
Validation loss: 2.1000715173700804

Epoch: 5| Step: 9
Training loss: 2.342270851135254
Validation loss: 2.1146068137179137

Epoch: 5| Step: 10
Training loss: 1.8914990425109863
Validation loss: 2.127192561344434

Epoch: 265| Step: 0
Training loss: 1.654984712600708
Validation loss: 2.150540257012972

Epoch: 5| Step: 1
Training loss: 2.455894708633423
Validation loss: 2.1593601857462237

Epoch: 5| Step: 2
Training loss: 2.368002414703369
Validation loss: 2.146838982899984

Epoch: 5| Step: 3
Training loss: 1.1977474689483643
Validation loss: 2.1402378595003517

Epoch: 5| Step: 4
Training loss: 2.068390369415283
Validation loss: 2.147242267926534

Epoch: 5| Step: 5
Training loss: 2.2016654014587402
Validation loss: 2.1307140140123266

Epoch: 5| Step: 6
Training loss: 1.859679937362671
Validation loss: 2.1552061188605522

Epoch: 5| Step: 7
Training loss: 1.3155921697616577
Validation loss: 2.142459084910731

Epoch: 5| Step: 8
Training loss: 1.4960150718688965
Validation loss: 2.148384878712316

Epoch: 5| Step: 9
Training loss: 1.6914710998535156
Validation loss: 2.1404014197728967

Epoch: 5| Step: 10
Training loss: 1.5860453844070435
Validation loss: 2.1154687327723347

Epoch: 266| Step: 0
Training loss: 1.5071321725845337
Validation loss: 2.102165050404046

Epoch: 5| Step: 1
Training loss: 1.2606542110443115
Validation loss: 2.1131648402060232

Epoch: 5| Step: 2
Training loss: 1.4217482805252075
Validation loss: 2.1073821693338375

Epoch: 5| Step: 3
Training loss: 1.7398605346679688
Validation loss: 2.1010884072190974

Epoch: 5| Step: 4
Training loss: 1.797929048538208
Validation loss: 2.0838330022750364

Epoch: 5| Step: 5
Training loss: 2.2102997303009033
Validation loss: 2.0972755339837845

Epoch: 5| Step: 6
Training loss: 1.9427964687347412
Validation loss: 2.157813605441842

Epoch: 5| Step: 7
Training loss: 1.6912164688110352
Validation loss: 2.167902910581199

Epoch: 5| Step: 8
Training loss: 1.9686943292617798
Validation loss: 2.1999218258806454

Epoch: 5| Step: 9
Training loss: 2.1917243003845215
Validation loss: 2.203947815843808

Epoch: 5| Step: 10
Training loss: 2.3400793075561523
Validation loss: 2.218895491733346

Epoch: 267| Step: 0
Training loss: 1.6879936456680298
Validation loss: 2.203849470743569

Epoch: 5| Step: 1
Training loss: 1.9136632680892944
Validation loss: 2.212716175663856

Epoch: 5| Step: 2
Training loss: 1.9334046840667725
Validation loss: 2.1896765334631807

Epoch: 5| Step: 3
Training loss: 2.3801631927490234
Validation loss: 2.1911071961925876

Epoch: 5| Step: 4
Training loss: 1.0583741664886475
Validation loss: 2.1746961942283054

Epoch: 5| Step: 5
Training loss: 1.47898268699646
Validation loss: 2.1667970995749197

Epoch: 5| Step: 6
Training loss: 1.449040412902832
Validation loss: 2.1284900788337953

Epoch: 5| Step: 7
Training loss: 2.183049440383911
Validation loss: 2.1247317790985107

Epoch: 5| Step: 8
Training loss: 1.658302664756775
Validation loss: 2.114695300338089

Epoch: 5| Step: 9
Training loss: 2.139129877090454
Validation loss: 2.0910618048842236

Epoch: 5| Step: 10
Training loss: 1.5425299406051636
Validation loss: 2.093296632971815

Epoch: 268| Step: 0
Training loss: 1.8886951208114624
Validation loss: 2.0902464415437434

Epoch: 5| Step: 1
Training loss: 2.0814127922058105
Validation loss: 2.1199641766086703

Epoch: 5| Step: 2
Training loss: 1.3279407024383545
Validation loss: 2.1112977176584224

Epoch: 5| Step: 3
Training loss: 1.9488452672958374
Validation loss: 2.1303892058710896

Epoch: 5| Step: 4
Training loss: 1.787878394126892
Validation loss: 2.0951278812141827

Epoch: 5| Step: 5
Training loss: 2.036003589630127
Validation loss: 2.0996554308040167

Epoch: 5| Step: 6
Training loss: 1.6960432529449463
Validation loss: 2.1478644686360515

Epoch: 5| Step: 7
Training loss: 1.8921880722045898
Validation loss: 2.1167417803118305

Epoch: 5| Step: 8
Training loss: 1.4393532276153564
Validation loss: 2.112038166292252

Epoch: 5| Step: 9
Training loss: 1.5944766998291016
Validation loss: 2.1337953741832445

Epoch: 5| Step: 10
Training loss: 2.1847288608551025
Validation loss: 2.1315571825991393

Epoch: 269| Step: 0
Training loss: 1.3172082901000977
Validation loss: 2.162239428489439

Epoch: 5| Step: 1
Training loss: 1.7922195196151733
Validation loss: 2.1957009095017628

Epoch: 5| Step: 2
Training loss: 2.2447004318237305
Validation loss: 2.150090353463286

Epoch: 5| Step: 3
Training loss: 1.9302005767822266
Validation loss: 2.1456615976108018

Epoch: 5| Step: 4
Training loss: 2.0862269401550293
Validation loss: 2.1322554311444684

Epoch: 5| Step: 5
Training loss: 1.7080042362213135
Validation loss: 2.1289212114067486

Epoch: 5| Step: 6
Training loss: 1.792589545249939
Validation loss: 2.0831937482280116

Epoch: 5| Step: 7
Training loss: 1.6755861043930054
Validation loss: 2.0930204519661526

Epoch: 5| Step: 8
Training loss: 1.6221427917480469
Validation loss: 2.1050549566104846

Epoch: 5| Step: 9
Training loss: 1.4548395872116089
Validation loss: 2.076161939610717

Epoch: 5| Step: 10
Training loss: 1.9799797534942627
Validation loss: 2.1193208873912854

Epoch: 270| Step: 0
Training loss: 2.252164363861084
Validation loss: 2.1416334580349665

Epoch: 5| Step: 1
Training loss: 1.9419851303100586
Validation loss: 2.2133391621292278

Epoch: 5| Step: 2
Training loss: 2.3884425163269043
Validation loss: 2.248533042528296

Epoch: 5| Step: 3
Training loss: 1.1172587871551514
Validation loss: 2.289036509811237

Epoch: 5| Step: 4
Training loss: 2.348893404006958
Validation loss: 2.269996932757798

Epoch: 5| Step: 5
Training loss: 1.8578217029571533
Validation loss: 2.1892575781832457

Epoch: 5| Step: 6
Training loss: 1.5233995914459229
Validation loss: 2.161830855954078

Epoch: 5| Step: 7
Training loss: 1.5352181196212769
Validation loss: 2.1655189350087154

Epoch: 5| Step: 8
Training loss: 1.5952436923980713
Validation loss: 2.158939048808108

Epoch: 5| Step: 9
Training loss: 2.0891590118408203
Validation loss: 2.175999620909332

Epoch: 5| Step: 10
Training loss: 1.7247579097747803
Validation loss: 2.1480103769610004

Epoch: 271| Step: 0
Training loss: 1.7470550537109375
Validation loss: 2.099477123188716

Epoch: 5| Step: 1
Training loss: 1.5982778072357178
Validation loss: 2.1154555351503435

Epoch: 5| Step: 2
Training loss: 1.8947662115097046
Validation loss: 2.0986809807439006

Epoch: 5| Step: 3
Training loss: 1.7431977987289429
Validation loss: 2.1020058880570116

Epoch: 5| Step: 4
Training loss: 1.637110710144043
Validation loss: 2.101184662952218

Epoch: 5| Step: 5
Training loss: 2.261977434158325
Validation loss: 2.1207422492324666

Epoch: 5| Step: 6
Training loss: 1.9361873865127563
Validation loss: 2.116088269859232

Epoch: 5| Step: 7
Training loss: 2.0581471920013428
Validation loss: 2.1182082853009625

Epoch: 5| Step: 8
Training loss: 1.72848379611969
Validation loss: 2.15454315370129

Epoch: 5| Step: 9
Training loss: 1.7792831659317017
Validation loss: 2.125837782377838

Epoch: 5| Step: 10
Training loss: 0.9275446534156799
Validation loss: 2.1605967090975855

Epoch: 272| Step: 0
Training loss: 1.203757405281067
Validation loss: 2.1608909048059934

Epoch: 5| Step: 1
Training loss: 1.675032377243042
Validation loss: 2.1465780042832896

Epoch: 5| Step: 2
Training loss: 2.002215623855591
Validation loss: 2.1219865096512662

Epoch: 5| Step: 3
Training loss: 2.2104554176330566
Validation loss: 2.113017976924937

Epoch: 5| Step: 4
Training loss: 1.634082555770874
Validation loss: 2.101940624175533

Epoch: 5| Step: 5
Training loss: 1.6562492847442627
Validation loss: 2.0975255940550115

Epoch: 5| Step: 6
Training loss: 2.034320116043091
Validation loss: 2.0764552841904345

Epoch: 5| Step: 7
Training loss: 1.5209271907806396
Validation loss: 2.0873641147408435

Epoch: 5| Step: 8
Training loss: 1.9252744913101196
Validation loss: 2.105241815249125

Epoch: 5| Step: 9
Training loss: 1.7487436532974243
Validation loss: 2.145106300230949

Epoch: 5| Step: 10
Training loss: 2.304414749145508
Validation loss: 2.117051250191145

Epoch: 273| Step: 0
Training loss: 2.1484134197235107
Validation loss: 2.1197334874060845

Epoch: 5| Step: 1
Training loss: 1.470240831375122
Validation loss: 2.0993209551739436

Epoch: 5| Step: 2
Training loss: 2.4039885997772217
Validation loss: 2.0975666610143517

Epoch: 5| Step: 3
Training loss: 2.0595955848693848
Validation loss: 2.0890806874921246

Epoch: 5| Step: 4
Training loss: 1.5627771615982056
Validation loss: 2.110121860299059

Epoch: 5| Step: 5
Training loss: 1.8918644189834595
Validation loss: 2.1364676413997525

Epoch: 5| Step: 6
Training loss: 1.425713062286377
Validation loss: 2.121149496365619

Epoch: 5| Step: 7
Training loss: 1.5253432989120483
Validation loss: 2.139145408907244

Epoch: 5| Step: 8
Training loss: 1.3774917125701904
Validation loss: 2.1106865611127628

Epoch: 5| Step: 9
Training loss: 1.4026685953140259
Validation loss: 2.1487501923755934

Epoch: 5| Step: 10
Training loss: 2.0389883518218994
Validation loss: 2.1248576192445654

Epoch: 274| Step: 0
Training loss: 1.645063042640686
Validation loss: 2.1261604678246284

Epoch: 5| Step: 1
Training loss: 1.4231270551681519
Validation loss: 2.114871043030934

Epoch: 5| Step: 2
Training loss: 1.7680881023406982
Validation loss: 2.113521529782203

Epoch: 5| Step: 3
Training loss: 1.391563057899475
Validation loss: 2.1030207141753166

Epoch: 5| Step: 4
Training loss: 1.6192874908447266
Validation loss: 2.0794155495141142

Epoch: 5| Step: 5
Training loss: 2.034738779067993
Validation loss: 2.085895578066508

Epoch: 5| Step: 6
Training loss: 1.6846809387207031
Validation loss: 2.1072440044854277

Epoch: 5| Step: 7
Training loss: 1.9648354053497314
Validation loss: 2.1269872573114212

Epoch: 5| Step: 8
Training loss: 1.864014983177185
Validation loss: 2.137331347311697

Epoch: 5| Step: 9
Training loss: 1.91301691532135
Validation loss: 2.152738904440275

Epoch: 5| Step: 10
Training loss: 1.680949330329895
Validation loss: 2.154458971433742

Epoch: 275| Step: 0
Training loss: 2.2231414318084717
Validation loss: 2.1663578300065893

Epoch: 5| Step: 1
Training loss: 1.8428356647491455
Validation loss: 2.1760690891614525

Epoch: 5| Step: 2
Training loss: 1.1073447465896606
Validation loss: 2.17936957779751

Epoch: 5| Step: 3
Training loss: 1.6867625713348389
Validation loss: 2.201582557411604

Epoch: 5| Step: 4
Training loss: 1.8144985437393188
Validation loss: 2.210810486988355

Epoch: 5| Step: 5
Training loss: 1.6733372211456299
Validation loss: 2.2084182257293374

Epoch: 5| Step: 6
Training loss: 1.6767616271972656
Validation loss: 2.1901097297668457

Epoch: 5| Step: 7
Training loss: 1.6879297494888306
Validation loss: 2.209170409428176

Epoch: 5| Step: 8
Training loss: 1.8756239414215088
Validation loss: 2.1960428581442883

Epoch: 5| Step: 9
Training loss: 1.9321922063827515
Validation loss: 2.1820389481001

Epoch: 5| Step: 10
Training loss: 1.5132083892822266
Validation loss: 2.184756850683561

Epoch: 276| Step: 0
Training loss: 1.3571196794509888
Validation loss: 2.1652878792055192

Epoch: 5| Step: 1
Training loss: 1.7127532958984375
Validation loss: 2.158469589807654

Epoch: 5| Step: 2
Training loss: 2.1428325176239014
Validation loss: 2.1358935038248696

Epoch: 5| Step: 3
Training loss: 1.9304249286651611
Validation loss: 2.1155966174217964

Epoch: 5| Step: 4
Training loss: 1.4865511655807495
Validation loss: 2.079958813164824

Epoch: 5| Step: 5
Training loss: 2.1390156745910645
Validation loss: 2.1057678320074595

Epoch: 5| Step: 6
Training loss: 1.5802178382873535
Validation loss: 2.0970302038295294

Epoch: 5| Step: 7
Training loss: 1.582578420639038
Validation loss: 2.105631248925322

Epoch: 5| Step: 8
Training loss: 2.0536715984344482
Validation loss: 2.1236912204373266

Epoch: 5| Step: 9
Training loss: 1.4799096584320068
Validation loss: 2.147490724440544

Epoch: 5| Step: 10
Training loss: 1.385573148727417
Validation loss: 2.153649176320722

Epoch: 277| Step: 0
Training loss: 1.8789771795272827
Validation loss: 2.151890285553471

Epoch: 5| Step: 1
Training loss: 1.748002290725708
Validation loss: 2.1658627320361394

Epoch: 5| Step: 2
Training loss: 1.8173930644989014
Validation loss: 2.176375381408199

Epoch: 5| Step: 3
Training loss: 1.9955556392669678
Validation loss: 2.154738210862683

Epoch: 5| Step: 4
Training loss: 1.6308332681655884
Validation loss: 2.174670196348621

Epoch: 5| Step: 5
Training loss: 1.6767101287841797
Validation loss: 2.1701815102690007

Epoch: 5| Step: 6
Training loss: 1.7347469329833984
Validation loss: 2.1458270242137294

Epoch: 5| Step: 7
Training loss: 1.6666946411132812
Validation loss: 2.151610848724201

Epoch: 5| Step: 8
Training loss: 1.4539625644683838
Validation loss: 2.146895857267482

Epoch: 5| Step: 9
Training loss: 2.1376898288726807
Validation loss: 2.1564670455071235

Epoch: 5| Step: 10
Training loss: 0.980105459690094
Validation loss: 2.138699452082316

Epoch: 278| Step: 0
Training loss: 1.3950222730636597
Validation loss: 2.111494941096152

Epoch: 5| Step: 1
Training loss: 2.049985408782959
Validation loss: 2.100209173335824

Epoch: 5| Step: 2
Training loss: 1.9425475597381592
Validation loss: 2.107101217392952

Epoch: 5| Step: 3
Training loss: 1.6600711345672607
Validation loss: 2.1056436672005603

Epoch: 5| Step: 4
Training loss: 1.7357661724090576
Validation loss: 2.100331409003145

Epoch: 5| Step: 5
Training loss: 1.392532467842102
Validation loss: 2.126531672734086

Epoch: 5| Step: 6
Training loss: 1.141601800918579
Validation loss: 2.1642098144818376

Epoch: 5| Step: 7
Training loss: 1.7425380945205688
Validation loss: 2.1454489179836806

Epoch: 5| Step: 8
Training loss: 2.688204288482666
Validation loss: 2.1463289209591445

Epoch: 5| Step: 9
Training loss: 1.4822293519973755
Validation loss: 2.1384830385126095

Epoch: 5| Step: 10
Training loss: 1.8174710273742676
Validation loss: 2.1360567692787416

Epoch: 279| Step: 0
Training loss: 1.6770232915878296
Validation loss: 2.1252306046024447

Epoch: 5| Step: 1
Training loss: 1.8093936443328857
Validation loss: 2.12486723930605

Epoch: 5| Step: 2
Training loss: 1.6922132968902588
Validation loss: 2.136032412129064

Epoch: 5| Step: 3
Training loss: 1.622799277305603
Validation loss: 2.1286585356599543

Epoch: 5| Step: 4
Training loss: 1.5201060771942139
Validation loss: 2.1321606482228925

Epoch: 5| Step: 5
Training loss: 2.0399303436279297
Validation loss: 2.116511175709386

Epoch: 5| Step: 6
Training loss: 2.465927839279175
Validation loss: 2.132974232396772

Epoch: 5| Step: 7
Training loss: 1.38540780544281
Validation loss: 2.1452236008900467

Epoch: 5| Step: 8
Training loss: 1.4160096645355225
Validation loss: 2.1199047975642706

Epoch: 5| Step: 9
Training loss: 1.8173596858978271
Validation loss: 2.106833625865239

Epoch: 5| Step: 10
Training loss: 1.2752699851989746
Validation loss: 2.1181880222853793

Epoch: 280| Step: 0
Training loss: 1.829345464706421
Validation loss: 2.1387025681875085

Epoch: 5| Step: 1
Training loss: 1.6114568710327148
Validation loss: 2.1251688580359183

Epoch: 5| Step: 2
Training loss: 2.2569804191589355
Validation loss: 2.1230802792374805

Epoch: 5| Step: 3
Training loss: 1.9001634120941162
Validation loss: 2.1411351388500584

Epoch: 5| Step: 4
Training loss: 1.635702133178711
Validation loss: 2.1351890845965316

Epoch: 5| Step: 5
Training loss: 1.5576578378677368
Validation loss: 2.1387994904671945

Epoch: 5| Step: 6
Training loss: 1.0860040187835693
Validation loss: 2.1723208965793734

Epoch: 5| Step: 7
Training loss: 1.337175726890564
Validation loss: 2.1657577701794204

Epoch: 5| Step: 8
Training loss: 2.5101428031921387
Validation loss: 2.1580199938948437

Epoch: 5| Step: 9
Training loss: 1.2899991273880005
Validation loss: 2.1769571765776603

Epoch: 5| Step: 10
Training loss: 1.683910846710205
Validation loss: 2.169007287230543

Epoch: 281| Step: 0
Training loss: 1.641653299331665
Validation loss: 2.149834132963611

Epoch: 5| Step: 1
Training loss: 1.5710556507110596
Validation loss: 2.1430754969196935

Epoch: 5| Step: 2
Training loss: 1.9291328191757202
Validation loss: 2.1280334124001126

Epoch: 5| Step: 3
Training loss: 1.7526271343231201
Validation loss: 2.121509814775118

Epoch: 5| Step: 4
Training loss: 1.7356007099151611
Validation loss: 2.1141686695878223

Epoch: 5| Step: 5
Training loss: 2.2631545066833496
Validation loss: 2.1154389791591193

Epoch: 5| Step: 6
Training loss: 1.9696168899536133
Validation loss: 2.1339289129421277

Epoch: 5| Step: 7
Training loss: 1.4444578886032104
Validation loss: 2.1357893277240056

Epoch: 5| Step: 8
Training loss: 1.5153553485870361
Validation loss: 2.1447551276094172

Epoch: 5| Step: 9
Training loss: 1.1676315069198608
Validation loss: 2.168095996302943

Epoch: 5| Step: 10
Training loss: 1.6211748123168945
Validation loss: 2.179106012467415

Epoch: 282| Step: 0
Training loss: 1.7949230670928955
Validation loss: 2.1593207325986636

Epoch: 5| Step: 1
Training loss: 2.2381234169006348
Validation loss: 2.1862944505547963

Epoch: 5| Step: 2
Training loss: 1.129242181777954
Validation loss: 2.1688292949430403

Epoch: 5| Step: 3
Training loss: 1.6277583837509155
Validation loss: 2.1374565875658424

Epoch: 5| Step: 4
Training loss: 1.6319215297698975
Validation loss: 2.128775852982716

Epoch: 5| Step: 5
Training loss: 1.3424901962280273
Validation loss: 2.1125077791111444

Epoch: 5| Step: 6
Training loss: 2.1061532497406006
Validation loss: 2.1143003625254475

Epoch: 5| Step: 7
Training loss: 1.6352430582046509
Validation loss: 2.083122707182361

Epoch: 5| Step: 8
Training loss: 1.4077802896499634
Validation loss: 2.1119659587901127

Epoch: 5| Step: 9
Training loss: 1.2712472677230835
Validation loss: 2.100821823202154

Epoch: 5| Step: 10
Training loss: 2.3119683265686035
Validation loss: 2.1085490795873825

Epoch: 283| Step: 0
Training loss: 1.4965829849243164
Validation loss: 2.1116255252592024

Epoch: 5| Step: 1
Training loss: 1.3760573863983154
Validation loss: 2.1314798247429634

Epoch: 5| Step: 2
Training loss: 2.1039345264434814
Validation loss: 2.1439792738165906

Epoch: 5| Step: 3
Training loss: 1.8273594379425049
Validation loss: 2.1545781012504333

Epoch: 5| Step: 4
Training loss: 1.3527371883392334
Validation loss: 2.1612788092705513

Epoch: 5| Step: 5
Training loss: 1.486464262008667
Validation loss: 2.163778284544586

Epoch: 5| Step: 6
Training loss: 1.6203925609588623
Validation loss: 2.1821619041504396

Epoch: 5| Step: 7
Training loss: 1.8595459461212158
Validation loss: 2.172717732767905

Epoch: 5| Step: 8
Training loss: 1.863421082496643
Validation loss: 2.1594178715059833

Epoch: 5| Step: 9
Training loss: 1.5914026498794556
Validation loss: 2.139360697038712

Epoch: 5| Step: 10
Training loss: 1.8541297912597656
Validation loss: 2.131879634754632

Epoch: 284| Step: 0
Training loss: 1.0393680334091187
Validation loss: 2.120915803858029

Epoch: 5| Step: 1
Training loss: 2.1116466522216797
Validation loss: 2.106257556587137

Epoch: 5| Step: 2
Training loss: 1.5848559141159058
Validation loss: 2.1163141791538527

Epoch: 5| Step: 3
Training loss: 2.2139892578125
Validation loss: 2.1140490526794107

Epoch: 5| Step: 4
Training loss: 1.7794668674468994
Validation loss: 2.1218954055540022

Epoch: 5| Step: 5
Training loss: 2.071011781692505
Validation loss: 2.118801751444417

Epoch: 5| Step: 6
Training loss: 1.1706246137619019
Validation loss: 2.0946375016243226

Epoch: 5| Step: 7
Training loss: 2.0845112800598145
Validation loss: 2.0995676068849463

Epoch: 5| Step: 8
Training loss: 1.4269399642944336
Validation loss: 2.1160601595396638

Epoch: 5| Step: 9
Training loss: 1.5805952548980713
Validation loss: 2.1378442625845633

Epoch: 5| Step: 10
Training loss: 1.8119481801986694
Validation loss: 2.1400375622575

Epoch: 285| Step: 0
Training loss: 2.056623935699463
Validation loss: 2.129663032870139

Epoch: 5| Step: 1
Training loss: 1.4688451290130615
Validation loss: 2.1210776836641374

Epoch: 5| Step: 2
Training loss: 1.5043312311172485
Validation loss: 2.1148464628445205

Epoch: 5| Step: 3
Training loss: 2.2644455432891846
Validation loss: 2.1185307028473064

Epoch: 5| Step: 4
Training loss: 1.0604841709136963
Validation loss: 2.167780658250214

Epoch: 5| Step: 5
Training loss: 1.4447799921035767
Validation loss: 2.1712025826977146

Epoch: 5| Step: 6
Training loss: 1.5951341390609741
Validation loss: 2.143746816983787

Epoch: 5| Step: 7
Training loss: 1.6946725845336914
Validation loss: 2.1361113235514653

Epoch: 5| Step: 8
Training loss: 1.7479057312011719
Validation loss: 2.1173640963851765

Epoch: 5| Step: 9
Training loss: 1.6998794078826904
Validation loss: 2.119879852059067

Epoch: 5| Step: 10
Training loss: 2.0886523723602295
Validation loss: 2.1067397978998

Epoch: 286| Step: 0
Training loss: 1.6698191165924072
Validation loss: 2.125794312005402

Epoch: 5| Step: 1
Training loss: 1.6601028442382812
Validation loss: 2.099938654130505

Epoch: 5| Step: 2
Training loss: 1.3757123947143555
Validation loss: 2.1420520223597044

Epoch: 5| Step: 3
Training loss: 1.3865293264389038
Validation loss: 2.1456565087841404

Epoch: 5| Step: 4
Training loss: 1.9253994226455688
Validation loss: 2.1710954020100255

Epoch: 5| Step: 5
Training loss: 1.8095861673355103
Validation loss: 2.173852716722796

Epoch: 5| Step: 6
Training loss: 1.3609135150909424
Validation loss: 2.1730268847557808

Epoch: 5| Step: 7
Training loss: 2.1158547401428223
Validation loss: 2.166174065682196

Epoch: 5| Step: 8
Training loss: 1.4208792448043823
Validation loss: 2.138350445737121

Epoch: 5| Step: 9
Training loss: 1.3517879247665405
Validation loss: 2.1160944149058354

Epoch: 5| Step: 10
Training loss: 2.1028594970703125
Validation loss: 2.109809611433296

Epoch: 287| Step: 0
Training loss: 1.4202773571014404
Validation loss: 2.097187525482588

Epoch: 5| Step: 1
Training loss: 1.7101812362670898
Validation loss: 2.098942554125222

Epoch: 5| Step: 2
Training loss: 1.8864589929580688
Validation loss: 2.1237086096117572

Epoch: 5| Step: 3
Training loss: 1.650516152381897
Validation loss: 2.111302614212036

Epoch: 5| Step: 4
Training loss: 2.0836639404296875
Validation loss: 2.1110497097815237

Epoch: 5| Step: 5
Training loss: 1.4998948574066162
Validation loss: 2.0884021443705403

Epoch: 5| Step: 6
Training loss: 1.2906107902526855
Validation loss: 2.0843448408188356

Epoch: 5| Step: 7
Training loss: 1.5648924112319946
Validation loss: 2.090485603578629

Epoch: 5| Step: 8
Training loss: 1.5276607275009155
Validation loss: 2.1109696742027038

Epoch: 5| Step: 9
Training loss: 1.6454403400421143
Validation loss: 2.1312280008869786

Epoch: 5| Step: 10
Training loss: 1.8793742656707764
Validation loss: 2.1479112204685005

Epoch: 288| Step: 0
Training loss: 2.129878520965576
Validation loss: 2.1390757612002793

Epoch: 5| Step: 1
Training loss: 1.1352176666259766
Validation loss: 2.166583038145496

Epoch: 5| Step: 2
Training loss: 1.2503036260604858
Validation loss: 2.1432513498490855

Epoch: 5| Step: 3
Training loss: 1.9954344034194946
Validation loss: 2.1639417038168958

Epoch: 5| Step: 4
Training loss: 1.196262001991272
Validation loss: 2.174151284720308

Epoch: 5| Step: 5
Training loss: 1.571044683456421
Validation loss: 2.1604072534909813

Epoch: 5| Step: 6
Training loss: 1.3408092260360718
Validation loss: 2.185594925316431

Epoch: 5| Step: 7
Training loss: 1.6335750818252563
Validation loss: 2.1907053134774648

Epoch: 5| Step: 8
Training loss: 1.8946774005889893
Validation loss: 2.199782653521466

Epoch: 5| Step: 9
Training loss: 1.920464277267456
Validation loss: 2.16073045679318

Epoch: 5| Step: 10
Training loss: 2.262622117996216
Validation loss: 2.157535961879197

Epoch: 289| Step: 0
Training loss: 1.7828178405761719
Validation loss: 2.130670706431071

Epoch: 5| Step: 1
Training loss: 1.6906964778900146
Validation loss: 2.0930736411002373

Epoch: 5| Step: 2
Training loss: 1.6465203762054443
Validation loss: 2.0457454266086703

Epoch: 5| Step: 3
Training loss: 1.7404882907867432
Validation loss: 2.082067815206384

Epoch: 5| Step: 4
Training loss: 1.7647533416748047
Validation loss: 2.061994203957178

Epoch: 5| Step: 5
Training loss: 1.4442355632781982
Validation loss: 2.0650976357921476

Epoch: 5| Step: 6
Training loss: 1.0289137363433838
Validation loss: 2.1026937218122583

Epoch: 5| Step: 7
Training loss: 2.2138218879699707
Validation loss: 2.1395059836808072

Epoch: 5| Step: 8
Training loss: 1.34394371509552
Validation loss: 2.149729421061854

Epoch: 5| Step: 9
Training loss: 2.1890223026275635
Validation loss: 2.1887553609827513

Epoch: 5| Step: 10
Training loss: 1.745284914970398
Validation loss: 2.1287152536453737

Epoch: 290| Step: 0
Training loss: 1.368571400642395
Validation loss: 2.1206289440072994

Epoch: 5| Step: 1
Training loss: 1.1712119579315186
Validation loss: 2.154627646169355

Epoch: 5| Step: 2
Training loss: 1.5845946073532104
Validation loss: 2.153036812300323

Epoch: 5| Step: 3
Training loss: 1.8490211963653564
Validation loss: 2.18032100636472

Epoch: 5| Step: 4
Training loss: 1.5216783285140991
Validation loss: 2.198218389223981

Epoch: 5| Step: 5
Training loss: 2.0135364532470703
Validation loss: 2.1803600377933954

Epoch: 5| Step: 6
Training loss: 2.0163774490356445
Validation loss: 2.220227828589819

Epoch: 5| Step: 7
Training loss: 1.4751884937286377
Validation loss: 2.198693480542911

Epoch: 5| Step: 8
Training loss: 1.908422827720642
Validation loss: 2.2252078774154826

Epoch: 5| Step: 9
Training loss: 1.6998412609100342
Validation loss: 2.2894627407032955

Epoch: 5| Step: 10
Training loss: 1.612776279449463
Validation loss: 2.242446030339887

Epoch: 291| Step: 0
Training loss: 1.0714834928512573
Validation loss: 2.1796131698034142

Epoch: 5| Step: 1
Training loss: 1.7907260656356812
Validation loss: 2.147439182445567

Epoch: 5| Step: 2
Training loss: 1.739627480506897
Validation loss: 2.131450019856935

Epoch: 5| Step: 3
Training loss: 1.8495566844940186
Validation loss: 2.131913153074121

Epoch: 5| Step: 4
Training loss: 1.6080856323242188
Validation loss: 2.0951977724670083

Epoch: 5| Step: 5
Training loss: 1.9339542388916016
Validation loss: 2.0566103676313996

Epoch: 5| Step: 6
Training loss: 1.5637133121490479
Validation loss: 2.0644938433042137

Epoch: 5| Step: 7
Training loss: 1.5844249725341797
Validation loss: 2.08348863099211

Epoch: 5| Step: 8
Training loss: 1.7504297494888306
Validation loss: 2.1126095146261235

Epoch: 5| Step: 9
Training loss: 1.6563787460327148
Validation loss: 2.1213916578600482

Epoch: 5| Step: 10
Training loss: 1.6143031120300293
Validation loss: 2.1252755054863552

Epoch: 292| Step: 0
Training loss: 1.6200530529022217
Validation loss: 2.1476696050295265

Epoch: 5| Step: 1
Training loss: 0.820324718952179
Validation loss: 2.157477242972261

Epoch: 5| Step: 2
Training loss: 1.7013190984725952
Validation loss: 2.136465013668101

Epoch: 5| Step: 3
Training loss: 1.919965386390686
Validation loss: 2.1368360942409885

Epoch: 5| Step: 4
Training loss: 1.3871381282806396
Validation loss: 2.1640991395519626

Epoch: 5| Step: 5
Training loss: 1.4649088382720947
Validation loss: 2.1733758090644755

Epoch: 5| Step: 6
Training loss: 1.7617301940917969
Validation loss: 2.1893162522264706

Epoch: 5| Step: 7
Training loss: 1.932918906211853
Validation loss: 2.181866576594691

Epoch: 5| Step: 8
Training loss: 1.3810536861419678
Validation loss: 2.210734336606918

Epoch: 5| Step: 9
Training loss: 2.0376393795013428
Validation loss: 2.1827019542776127

Epoch: 5| Step: 10
Training loss: 1.8773927688598633
Validation loss: 2.1798507321265435

Epoch: 293| Step: 0
Training loss: 1.7086063623428345
Validation loss: 2.167444216307773

Epoch: 5| Step: 1
Training loss: 1.2623589038848877
Validation loss: 2.1652599342407717

Epoch: 5| Step: 2
Training loss: 1.7750194072723389
Validation loss: 2.186062007822016

Epoch: 5| Step: 3
Training loss: 1.5893197059631348
Validation loss: 2.172275920068064

Epoch: 5| Step: 4
Training loss: 1.7502467632293701
Validation loss: 2.1348448671320432

Epoch: 5| Step: 5
Training loss: 1.8188984394073486
Validation loss: 2.106088751105852

Epoch: 5| Step: 6
Training loss: 1.5322514772415161
Validation loss: 2.1116702864246983

Epoch: 5| Step: 7
Training loss: 1.5636647939682007
Validation loss: 2.1160308314907934

Epoch: 5| Step: 8
Training loss: 1.8217767477035522
Validation loss: 2.1266545377751833

Epoch: 5| Step: 9
Training loss: 1.4925487041473389
Validation loss: 2.126407757882149

Epoch: 5| Step: 10
Training loss: 1.8857121467590332
Validation loss: 2.1560417439347956

Epoch: 294| Step: 0
Training loss: 2.102116823196411
Validation loss: 2.1169496787491666

Epoch: 5| Step: 1
Training loss: 2.1375176906585693
Validation loss: 2.128103648462603

Epoch: 5| Step: 2
Training loss: 1.3537015914916992
Validation loss: 2.092771335314679

Epoch: 5| Step: 3
Training loss: 1.6867961883544922
Validation loss: 2.1283591742156656

Epoch: 5| Step: 4
Training loss: 1.113779067993164
Validation loss: 2.1423942530027

Epoch: 5| Step: 5
Training loss: 1.8505264520645142
Validation loss: 2.135621481044318

Epoch: 5| Step: 6
Training loss: 1.5364253520965576
Validation loss: 2.1502589487260386

Epoch: 5| Step: 7
Training loss: 1.8644294738769531
Validation loss: 2.1823188745847313

Epoch: 5| Step: 8
Training loss: 1.9044805765151978
Validation loss: 2.1170445231981176

Epoch: 5| Step: 9
Training loss: 1.0578571557998657
Validation loss: 2.118367382275161

Epoch: 5| Step: 10
Training loss: 1.3426897525787354
Validation loss: 2.1597313137464624

Epoch: 295| Step: 0
Training loss: 1.5642133951187134
Validation loss: 2.1540930373694307

Epoch: 5| Step: 1
Training loss: 1.7131105661392212
Validation loss: 2.166356441795185

Epoch: 5| Step: 2
Training loss: 1.3663432598114014
Validation loss: 2.172128423567741

Epoch: 5| Step: 3
Training loss: 1.6976807117462158
Validation loss: 2.2205430615332817

Epoch: 5| Step: 4
Training loss: 1.8709499835968018
Validation loss: 2.259019015937723

Epoch: 5| Step: 5
Training loss: 1.82126784324646
Validation loss: 2.2891681373760266

Epoch: 5| Step: 6
Training loss: 1.8776664733886719
Validation loss: 2.265778595401395

Epoch: 5| Step: 7
Training loss: 1.0801661014556885
Validation loss: 2.2095312046748337

Epoch: 5| Step: 8
Training loss: 2.1465539932250977
Validation loss: 2.182692197061354

Epoch: 5| Step: 9
Training loss: 1.458252191543579
Validation loss: 2.175414139224637

Epoch: 5| Step: 10
Training loss: 1.8245599269866943
Validation loss: 2.1473117195149904

Epoch: 296| Step: 0
Training loss: 1.5089874267578125
Validation loss: 2.1368861967517483

Epoch: 5| Step: 1
Training loss: 1.8005311489105225
Validation loss: 2.0976231559630363

Epoch: 5| Step: 2
Training loss: 1.4829022884368896
Validation loss: 2.086912106442195

Epoch: 5| Step: 3
Training loss: 2.317173480987549
Validation loss: 2.0671329780291487

Epoch: 5| Step: 4
Training loss: 1.4002435207366943
Validation loss: 2.096913156970855

Epoch: 5| Step: 5
Training loss: 1.224941611289978
Validation loss: 2.0992017792117212

Epoch: 5| Step: 6
Training loss: 2.2922818660736084
Validation loss: 2.1317077118863343

Epoch: 5| Step: 7
Training loss: 2.073681116104126
Validation loss: 2.1093504018681024

Epoch: 5| Step: 8
Training loss: 1.4710519313812256
Validation loss: 2.1194514023360385

Epoch: 5| Step: 9
Training loss: 1.4639379978179932
Validation loss: 2.1310573111298265

Epoch: 5| Step: 10
Training loss: 1.1264382600784302
Validation loss: 2.113139001272058

Epoch: 297| Step: 0
Training loss: 1.9638839960098267
Validation loss: 2.109873661430933

Epoch: 5| Step: 1
Training loss: 1.6871297359466553
Validation loss: 2.131920078749298

Epoch: 5| Step: 2
Training loss: 1.5825607776641846
Validation loss: 2.149019069569085

Epoch: 5| Step: 3
Training loss: 1.0702345371246338
Validation loss: 2.141998888343893

Epoch: 5| Step: 4
Training loss: 1.0854946374893188
Validation loss: 2.189362205484862

Epoch: 5| Step: 5
Training loss: 1.7937349081039429
Validation loss: 2.1850698763324368

Epoch: 5| Step: 6
Training loss: 1.5953782796859741
Validation loss: 2.183612956795641

Epoch: 5| Step: 7
Training loss: 1.659860610961914
Validation loss: 2.1720804193968415

Epoch: 5| Step: 8
Training loss: 1.5760135650634766
Validation loss: 2.1558867346855903

Epoch: 5| Step: 9
Training loss: 2.166914224624634
Validation loss: 2.1262308397600727

Epoch: 5| Step: 10
Training loss: 1.3191514015197754
Validation loss: 2.144539301113416

Epoch: 298| Step: 0
Training loss: 1.6289962530136108
Validation loss: 2.11538972649523

Epoch: 5| Step: 1
Training loss: 1.8527634143829346
Validation loss: 2.1040656733256515

Epoch: 5| Step: 2
Training loss: 1.0837324857711792
Validation loss: 2.1167133572281047

Epoch: 5| Step: 3
Training loss: 1.6669899225234985
Validation loss: 2.0926517773700017

Epoch: 5| Step: 4
Training loss: 1.5139394998550415
Validation loss: 2.106278242603425

Epoch: 5| Step: 5
Training loss: 1.7772613763809204
Validation loss: 2.144216299057007

Epoch: 5| Step: 6
Training loss: 1.6776630878448486
Validation loss: 2.111931803405926

Epoch: 5| Step: 7
Training loss: 1.3951295614242554
Validation loss: 2.095855846199938

Epoch: 5| Step: 8
Training loss: 1.926203727722168
Validation loss: 2.1284790551790627

Epoch: 5| Step: 9
Training loss: 1.571163535118103
Validation loss: 2.13119174075383

Epoch: 5| Step: 10
Training loss: 1.47501802444458
Validation loss: 2.1480102410880466

Epoch: 299| Step: 0
Training loss: 1.3534635305404663
Validation loss: 2.152025972643206

Epoch: 5| Step: 1
Training loss: 1.9373023509979248
Validation loss: 2.126266857629181

Epoch: 5| Step: 2
Training loss: 2.0192277431488037
Validation loss: 2.1133021026529293

Epoch: 5| Step: 3
Training loss: 1.320404291152954
Validation loss: 2.1174696722338275

Epoch: 5| Step: 4
Training loss: 1.3167473077774048
Validation loss: 2.1521923183113016

Epoch: 5| Step: 5
Training loss: 2.250701904296875
Validation loss: 2.200294192119311

Epoch: 5| Step: 6
Training loss: 1.5577256679534912
Validation loss: 2.1686008271350654

Epoch: 5| Step: 7
Training loss: 0.8927599191665649
Validation loss: 2.1309796353822112

Epoch: 5| Step: 8
Training loss: 1.8650596141815186
Validation loss: 2.1456746926871677

Epoch: 5| Step: 9
Training loss: 1.5849659442901611
Validation loss: 2.1050038670980804

Epoch: 5| Step: 10
Training loss: 1.720589518547058
Validation loss: 2.1057795709179294

Epoch: 300| Step: 0
Training loss: 2.3159217834472656
Validation loss: 2.115032301154188

Epoch: 5| Step: 1
Training loss: 1.5971215963363647
Validation loss: 2.1084748673182663

Epoch: 5| Step: 2
Training loss: 1.690247893333435
Validation loss: 2.096857661842018

Epoch: 5| Step: 3
Training loss: 1.045143485069275
Validation loss: 2.113901775370362

Epoch: 5| Step: 4
Training loss: 1.378678560256958
Validation loss: 2.1277366004964358

Epoch: 5| Step: 5
Training loss: 1.6314338445663452
Validation loss: 2.1499868746726745

Epoch: 5| Step: 6
Training loss: 1.2288204431533813
Validation loss: 2.151454182081325

Epoch: 5| Step: 7
Training loss: 1.421549677848816
Validation loss: 2.149249851062734

Epoch: 5| Step: 8
Training loss: 1.5311744213104248
Validation loss: 2.1788646200651764

Epoch: 5| Step: 9
Training loss: 1.4169561862945557
Validation loss: 2.174788669873309

Epoch: 5| Step: 10
Training loss: 2.078244686126709
Validation loss: 2.179341076522745

Epoch: 301| Step: 0
Training loss: 1.4199765920639038
Validation loss: 2.181447336750646

Epoch: 5| Step: 1
Training loss: 0.7925125360488892
Validation loss: 2.1264028587648944

Epoch: 5| Step: 2
Training loss: 1.4183648824691772
Validation loss: 2.109199180397936

Epoch: 5| Step: 3
Training loss: 1.8057870864868164
Validation loss: 2.110684096172292

Epoch: 5| Step: 4
Training loss: 1.7960975170135498
Validation loss: 2.100003129692488

Epoch: 5| Step: 5
Training loss: 1.662118911743164
Validation loss: 2.087260848732405

Epoch: 5| Step: 6
Training loss: 1.191347599029541
Validation loss: 2.074471653148692

Epoch: 5| Step: 7
Training loss: 1.9779857397079468
Validation loss: 2.0785230385359896

Epoch: 5| Step: 8
Training loss: 1.3218088150024414
Validation loss: 2.096587250309606

Epoch: 5| Step: 9
Training loss: 2.448317289352417
Validation loss: 2.112647427025662

Epoch: 5| Step: 10
Training loss: 1.4595212936401367
Validation loss: 2.102717626479364

Epoch: 302| Step: 0
Training loss: 1.7640297412872314
Validation loss: 2.1070542566237913

Epoch: 5| Step: 1
Training loss: 1.1997499465942383
Validation loss: 2.0899348361517793

Epoch: 5| Step: 2
Training loss: 1.7080272436141968
Validation loss: 2.1186500505734513

Epoch: 5| Step: 3
Training loss: 1.5575106143951416
Validation loss: 2.1549495215057046

Epoch: 5| Step: 4
Training loss: 1.5804486274719238
Validation loss: 2.1516659695615052

Epoch: 5| Step: 5
Training loss: 1.2007278203964233
Validation loss: 2.173685248180102

Epoch: 5| Step: 6
Training loss: 1.9187625646591187
Validation loss: 2.18221870545418

Epoch: 5| Step: 7
Training loss: 1.3637713193893433
Validation loss: 2.2086342893620974

Epoch: 5| Step: 8
Training loss: 2.045560121536255
Validation loss: 2.179691030133155

Epoch: 5| Step: 9
Training loss: 1.459221601486206
Validation loss: 2.1584899553688626

Epoch: 5| Step: 10
Training loss: 1.495262861251831
Validation loss: 2.1610119932441303

Epoch: 303| Step: 0
Training loss: 1.5791966915130615
Validation loss: 2.140657405699453

Epoch: 5| Step: 1
Training loss: 1.8897132873535156
Validation loss: 2.1267778783716182

Epoch: 5| Step: 2
Training loss: 1.2841955423355103
Validation loss: 2.11342446009318

Epoch: 5| Step: 3
Training loss: 1.6789840459823608
Validation loss: 2.0982651505419003

Epoch: 5| Step: 4
Training loss: 1.002805471420288
Validation loss: 2.0805368859280824

Epoch: 5| Step: 5
Training loss: 1.6527843475341797
Validation loss: 2.1006264058492516

Epoch: 5| Step: 6
Training loss: 2.0377674102783203
Validation loss: 2.090505623048352

Epoch: 5| Step: 7
Training loss: 1.5529093742370605
Validation loss: 2.103489265646986

Epoch: 5| Step: 8
Training loss: 1.3926477432250977
Validation loss: 2.1034809620149675

Epoch: 5| Step: 9
Training loss: 1.3952319622039795
Validation loss: 2.1163096171553417

Epoch: 5| Step: 10
Training loss: 1.9108442068099976
Validation loss: 2.1348058305760866

Epoch: 304| Step: 0
Training loss: 1.460827112197876
Validation loss: 2.153800997682797

Epoch: 5| Step: 1
Training loss: 1.7794249057769775
Validation loss: 2.145238927615586

Epoch: 5| Step: 2
Training loss: 1.590700387954712
Validation loss: 2.1633755801826395

Epoch: 5| Step: 3
Training loss: 1.1944862604141235
Validation loss: 2.1251775372412895

Epoch: 5| Step: 4
Training loss: 1.3136717081069946
Validation loss: 2.1515277252402356

Epoch: 5| Step: 5
Training loss: 1.184692144393921
Validation loss: 2.133549637691949

Epoch: 5| Step: 6
Training loss: 2.1548264026641846
Validation loss: 2.180998251002322

Epoch: 5| Step: 7
Training loss: 1.7939155101776123
Validation loss: 2.1484334609841786

Epoch: 5| Step: 8
Training loss: 1.8028154373168945
Validation loss: 2.14828880499768

Epoch: 5| Step: 9
Training loss: 1.4810341596603394
Validation loss: 2.14335012179549

Epoch: 5| Step: 10
Training loss: 1.7381895780563354
Validation loss: 2.1310293879560245

Epoch: 305| Step: 0
Training loss: 1.2645866870880127
Validation loss: 2.1787997420116136

Epoch: 5| Step: 1
Training loss: 1.6901010274887085
Validation loss: 2.206525525739116

Epoch: 5| Step: 2
Training loss: 1.7633025646209717
Validation loss: 2.191747891005649

Epoch: 5| Step: 3
Training loss: 1.9195709228515625
Validation loss: 2.1603138087898173

Epoch: 5| Step: 4
Training loss: 1.792868971824646
Validation loss: 2.1428567542824695

Epoch: 5| Step: 5
Training loss: 1.5841253995895386
Validation loss: 2.126264379870507

Epoch: 5| Step: 6
Training loss: 1.7299808263778687
Validation loss: 2.1329017992942565

Epoch: 5| Step: 7
Training loss: 1.2356700897216797
Validation loss: 2.111700245129165

Epoch: 5| Step: 8
Training loss: 1.200013518333435
Validation loss: 2.080707447503203

Epoch: 5| Step: 9
Training loss: 1.2941704988479614
Validation loss: 2.1079962997026342

Epoch: 5| Step: 10
Training loss: 1.596742033958435
Validation loss: 2.1376195428191975

Epoch: 306| Step: 0
Training loss: 2.120504140853882
Validation loss: 2.113483784019306

Epoch: 5| Step: 1
Training loss: 1.6825520992279053
Validation loss: 2.1347443262736

Epoch: 5| Step: 2
Training loss: 2.2685043811798096
Validation loss: 2.14873489000464

Epoch: 5| Step: 3
Training loss: 1.8247102499008179
Validation loss: 2.1132518886238016

Epoch: 5| Step: 4
Training loss: 1.5795308351516724
Validation loss: 2.075277179800054

Epoch: 5| Step: 5
Training loss: 0.9822129011154175
Validation loss: 2.0741114385666384

Epoch: 5| Step: 6
Training loss: 1.6690021753311157
Validation loss: 2.090688920790149

Epoch: 5| Step: 7
Training loss: 1.4335602521896362
Validation loss: 2.0980313542068645

Epoch: 5| Step: 8
Training loss: 1.297616720199585
Validation loss: 2.1091018671630533

Epoch: 5| Step: 9
Training loss: 1.2911049127578735
Validation loss: 2.157457649066884

Epoch: 5| Step: 10
Training loss: 1.1118379831314087
Validation loss: 2.143880175006005

Epoch: 307| Step: 0
Training loss: 1.4694697856903076
Validation loss: 2.1758222733774493

Epoch: 5| Step: 1
Training loss: 2.0098228454589844
Validation loss: 2.189748487164897

Epoch: 5| Step: 2
Training loss: 1.333770990371704
Validation loss: 2.207461416080434

Epoch: 5| Step: 3
Training loss: 1.8428280353546143
Validation loss: 2.1903499723762594

Epoch: 5| Step: 4
Training loss: 1.4289004802703857
Validation loss: 2.182493817421698

Epoch: 5| Step: 5
Training loss: 1.5658433437347412
Validation loss: 2.1424000365759737

Epoch: 5| Step: 6
Training loss: 1.9401721954345703
Validation loss: 2.1488374894665134

Epoch: 5| Step: 7
Training loss: 1.456485629081726
Validation loss: 2.1272354254158596

Epoch: 5| Step: 8
Training loss: 1.6192634105682373
Validation loss: 2.1212331043776644

Epoch: 5| Step: 9
Training loss: 0.8682597875595093
Validation loss: 2.1099375627374135

Epoch: 5| Step: 10
Training loss: 1.6874889135360718
Validation loss: 2.1292351804753786

Epoch: 308| Step: 0
Training loss: 1.2269699573516846
Validation loss: 2.1311155762723697

Epoch: 5| Step: 1
Training loss: 1.2566992044448853
Validation loss: 2.1091854700478176

Epoch: 5| Step: 2
Training loss: 1.8317995071411133
Validation loss: 2.085938342155949

Epoch: 5| Step: 3
Training loss: 1.2353047132492065
Validation loss: 2.0773824389262865

Epoch: 5| Step: 4
Training loss: 1.8509489297866821
Validation loss: 2.0835785968329317

Epoch: 5| Step: 5
Training loss: 2.0956668853759766
Validation loss: 2.0934268825797626

Epoch: 5| Step: 6
Training loss: 1.6420797109603882
Validation loss: 2.0940202025957007

Epoch: 5| Step: 7
Training loss: 0.8286721110343933
Validation loss: 2.0853574827153194

Epoch: 5| Step: 8
Training loss: 1.9394382238388062
Validation loss: 2.109100236687609

Epoch: 5| Step: 9
Training loss: 1.2283284664154053
Validation loss: 2.160182745225968

Epoch: 5| Step: 10
Training loss: 2.1131088733673096
Validation loss: 2.222126414698939

Epoch: 309| Step: 0
Training loss: 1.737605333328247
Validation loss: 2.1929990629996023

Epoch: 5| Step: 1
Training loss: 1.3126431703567505
Validation loss: 2.178415903481104

Epoch: 5| Step: 2
Training loss: 1.1205114126205444
Validation loss: 2.141816767313147

Epoch: 5| Step: 3
Training loss: 1.5614449977874756
Validation loss: 2.169378739531322

Epoch: 5| Step: 4
Training loss: 1.6024402379989624
Validation loss: 2.14135161266532

Epoch: 5| Step: 5
Training loss: 1.5145162343978882
Validation loss: 2.1594702556569088

Epoch: 5| Step: 6
Training loss: 1.5927263498306274
Validation loss: 2.1438786650216706

Epoch: 5| Step: 7
Training loss: 1.6173629760742188
Validation loss: 2.1216066088727725

Epoch: 5| Step: 8
Training loss: 1.8736155033111572
Validation loss: 2.1049399209278885

Epoch: 5| Step: 9
Training loss: 1.1781270503997803
Validation loss: 2.11664677691716

Epoch: 5| Step: 10
Training loss: 1.897162914276123
Validation loss: 2.1338026228771416

Epoch: 310| Step: 0
Training loss: 1.6964820623397827
Validation loss: 2.1213280090721707

Epoch: 5| Step: 1
Training loss: 1.7106930017471313
Validation loss: 2.0885942007905696

Epoch: 5| Step: 2
Training loss: 1.448083758354187
Validation loss: 2.106947034917852

Epoch: 5| Step: 3
Training loss: 1.4668270349502563
Validation loss: 2.1146678463105233

Epoch: 5| Step: 4
Training loss: 1.3946149349212646
Validation loss: 2.0840459087843537

Epoch: 5| Step: 5
Training loss: 1.656240463256836
Validation loss: 2.0999317169189453

Epoch: 5| Step: 6
Training loss: 1.3179432153701782
Validation loss: 2.118863028864707

Epoch: 5| Step: 7
Training loss: 1.1899834871292114
Validation loss: 2.1228935872354815

Epoch: 5| Step: 8
Training loss: 1.538588285446167
Validation loss: 2.143412151644307

Epoch: 5| Step: 9
Training loss: 1.5226560831069946
Validation loss: 2.1589383976433867

Epoch: 5| Step: 10
Training loss: 1.829683542251587
Validation loss: 2.1425403471915954

Epoch: 311| Step: 0
Training loss: 1.4536241292953491
Validation loss: 2.162367856630715

Epoch: 5| Step: 1
Training loss: 1.7266336679458618
Validation loss: 2.1637494435874363

Epoch: 5| Step: 2
Training loss: 1.0755798816680908
Validation loss: 2.1571233785280617

Epoch: 5| Step: 3
Training loss: 1.3820898532867432
Validation loss: 2.148213137862503

Epoch: 5| Step: 4
Training loss: 1.820575475692749
Validation loss: 2.1457052512835433

Epoch: 5| Step: 5
Training loss: 1.45943284034729
Validation loss: 2.128865147149691

Epoch: 5| Step: 6
Training loss: 1.6555629968643188
Validation loss: 2.1179074471996677

Epoch: 5| Step: 7
Training loss: 1.6436316967010498
Validation loss: 2.08087690671285

Epoch: 5| Step: 8
Training loss: 1.444100022315979
Validation loss: 2.099158187066355

Epoch: 5| Step: 9
Training loss: 1.6652424335479736
Validation loss: 2.083966532061177

Epoch: 5| Step: 10
Training loss: 1.2274376153945923
Validation loss: 2.0935882624759468

Epoch: 312| Step: 0
Training loss: 1.631873369216919
Validation loss: 2.096831758817037

Epoch: 5| Step: 1
Training loss: 1.5913841724395752
Validation loss: 2.130819243769492

Epoch: 5| Step: 2
Training loss: 1.4455525875091553
Validation loss: 2.1271438854996876

Epoch: 5| Step: 3
Training loss: 1.8881704807281494
Validation loss: 2.105608924742668

Epoch: 5| Step: 4
Training loss: 1.752107858657837
Validation loss: 2.124303412693803

Epoch: 5| Step: 5
Training loss: 0.965294361114502
Validation loss: 2.098882529043382

Epoch: 5| Step: 6
Training loss: 1.3307859897613525
Validation loss: 2.0955971364052064

Epoch: 5| Step: 7
Training loss: 1.6623468399047852
Validation loss: 2.0918289435807096

Epoch: 5| Step: 8
Training loss: 1.1487510204315186
Validation loss: 2.1203875618596233

Epoch: 5| Step: 9
Training loss: 1.8912655115127563
Validation loss: 2.1168394563018635

Epoch: 5| Step: 10
Training loss: 1.2794122695922852
Validation loss: 2.1427488352662776

Epoch: 313| Step: 0
Training loss: 1.5269443988800049
Validation loss: 2.170990620889971

Epoch: 5| Step: 1
Training loss: 1.27867591381073
Validation loss: 2.1545334580124065

Epoch: 5| Step: 2
Training loss: 1.3644107580184937
Validation loss: 2.1520956459865777

Epoch: 5| Step: 3
Training loss: 1.0984280109405518
Validation loss: 2.1474727789560952

Epoch: 5| Step: 4
Training loss: 2.0405898094177246
Validation loss: 2.1652234241526616

Epoch: 5| Step: 5
Training loss: 1.6995948553085327
Validation loss: 2.178152791915401

Epoch: 5| Step: 6
Training loss: 1.5513648986816406
Validation loss: 2.1742813869189193

Epoch: 5| Step: 7
Training loss: 1.5187203884124756
Validation loss: 2.1557517449061074

Epoch: 5| Step: 8
Training loss: 1.724231481552124
Validation loss: 2.128721833229065

Epoch: 5| Step: 9
Training loss: 1.464115858078003
Validation loss: 2.1193846425702496

Epoch: 5| Step: 10
Training loss: 1.3818740844726562
Validation loss: 2.1255819464242585

Epoch: 314| Step: 0
Training loss: 1.556881308555603
Validation loss: 2.1247023049221245

Epoch: 5| Step: 1
Training loss: 1.1146063804626465
Validation loss: 2.1359903735499226

Epoch: 5| Step: 2
Training loss: 1.6765086650848389
Validation loss: 2.111901493482692

Epoch: 5| Step: 3
Training loss: 1.4959505796432495
Validation loss: 2.1246492375609694

Epoch: 5| Step: 4
Training loss: 1.3874428272247314
Validation loss: 2.150316487076462

Epoch: 5| Step: 5
Training loss: 1.4201602935791016
Validation loss: 2.17612724919473

Epoch: 5| Step: 6
Training loss: 1.284959077835083
Validation loss: 2.162674803887644

Epoch: 5| Step: 7
Training loss: 1.5529212951660156
Validation loss: 2.159264151768018

Epoch: 5| Step: 8
Training loss: 1.7601861953735352
Validation loss: 2.1089612386559926

Epoch: 5| Step: 9
Training loss: 1.703212022781372
Validation loss: 2.129324648969917

Epoch: 5| Step: 10
Training loss: 1.4613271951675415
Validation loss: 2.097728636956984

Epoch: 315| Step: 0
Training loss: 1.3337032794952393
Validation loss: 2.104357668148574

Epoch: 5| Step: 1
Training loss: 1.2992916107177734
Validation loss: 2.1039578914642334

Epoch: 5| Step: 2
Training loss: 1.8162338733673096
Validation loss: 2.093595914943244

Epoch: 5| Step: 3
Training loss: 1.6426292657852173
Validation loss: 2.136142664058234

Epoch: 5| Step: 4
Training loss: 1.5532686710357666
Validation loss: 2.101090338922316

Epoch: 5| Step: 5
Training loss: 1.6219285726547241
Validation loss: 2.115736661418792

Epoch: 5| Step: 6
Training loss: 1.2900707721710205
Validation loss: 2.132247696640671

Epoch: 5| Step: 7
Training loss: 1.577868103981018
Validation loss: 2.1386654069346767

Epoch: 5| Step: 8
Training loss: 1.459429144859314
Validation loss: 2.150577352892968

Epoch: 5| Step: 9
Training loss: 1.177813172340393
Validation loss: 2.1517806463344122

Epoch: 5| Step: 10
Training loss: 1.3660292625427246
Validation loss: 2.148061816410352

Epoch: 316| Step: 0
Training loss: 1.532785415649414
Validation loss: 2.145413706379552

Epoch: 5| Step: 1
Training loss: 1.4917608499526978
Validation loss: 2.1695633985662974

Epoch: 5| Step: 2
Training loss: 1.6050584316253662
Validation loss: 2.1359158023711173

Epoch: 5| Step: 3
Training loss: 1.4817924499511719
Validation loss: 2.117870294919578

Epoch: 5| Step: 4
Training loss: 1.5564205646514893
Validation loss: 2.115324076785836

Epoch: 5| Step: 5
Training loss: 1.4085947275161743
Validation loss: 2.101953908961306

Epoch: 5| Step: 6
Training loss: 1.5067392587661743
Validation loss: 2.0570478849513556

Epoch: 5| Step: 7
Training loss: 1.085054636001587
Validation loss: 2.0704873377277004

Epoch: 5| Step: 8
Training loss: 0.8985382318496704
Validation loss: 2.066905202404145

Epoch: 5| Step: 9
Training loss: 1.8578462600708008
Validation loss: 2.1197281729790474

Epoch: 5| Step: 10
Training loss: 2.011958599090576
Validation loss: 2.1161930689247708

Epoch: 317| Step: 0
Training loss: 1.2309973239898682
Validation loss: 2.1249128387820337

Epoch: 5| Step: 1
Training loss: 1.77059805393219
Validation loss: 2.0987342839599936

Epoch: 5| Step: 2
Training loss: 1.6140384674072266
Validation loss: 2.111222440196622

Epoch: 5| Step: 3
Training loss: 0.8551225662231445
Validation loss: 2.1059497953743063

Epoch: 5| Step: 4
Training loss: 1.2608880996704102
Validation loss: 2.1078153976830105

Epoch: 5| Step: 5
Training loss: 1.339903473854065
Validation loss: 2.1145270819305093

Epoch: 5| Step: 6
Training loss: 2.0983524322509766
Validation loss: 2.115738989204489

Epoch: 5| Step: 7
Training loss: 1.6072337627410889
Validation loss: 2.120058480129447

Epoch: 5| Step: 8
Training loss: 1.2794342041015625
Validation loss: 2.1025890701560566

Epoch: 5| Step: 9
Training loss: 1.306623101234436
Validation loss: 2.102460262595966

Epoch: 5| Step: 10
Training loss: 1.7674784660339355
Validation loss: 2.0948127149253764

Epoch: 318| Step: 0
Training loss: 1.0722790956497192
Validation loss: 2.1224546381222305

Epoch: 5| Step: 1
Training loss: 1.6211154460906982
Validation loss: 2.1282607163152387

Epoch: 5| Step: 2
Training loss: 1.2058842182159424
Validation loss: 2.1166197869085495

Epoch: 5| Step: 3
Training loss: 0.9175716638565063
Validation loss: 2.1390384704835954

Epoch: 5| Step: 4
Training loss: 1.6088050603866577
Validation loss: 2.115744208776823

Epoch: 5| Step: 5
Training loss: 1.1360644102096558
Validation loss: 2.113494344936904

Epoch: 5| Step: 6
Training loss: 1.239890456199646
Validation loss: 2.1076423993674656

Epoch: 5| Step: 7
Training loss: 2.0457425117492676
Validation loss: 2.1164313490672777

Epoch: 5| Step: 8
Training loss: 1.3802025318145752
Validation loss: 2.143629143314977

Epoch: 5| Step: 9
Training loss: 2.207942247390747
Validation loss: 2.0997316657855944

Epoch: 5| Step: 10
Training loss: 1.59061861038208
Validation loss: 2.112444018804899

Epoch: 319| Step: 0
Training loss: 1.3238961696624756
Validation loss: 2.142638547446138

Epoch: 5| Step: 1
Training loss: 1.7309919595718384
Validation loss: 2.1435822620186755

Epoch: 5| Step: 2
Training loss: 1.6556377410888672
Validation loss: 2.136067686542388

Epoch: 5| Step: 3
Training loss: 1.2731775045394897
Validation loss: 2.1071803736430343

Epoch: 5| Step: 4
Training loss: 1.1529905796051025
Validation loss: 2.119809171204926

Epoch: 5| Step: 5
Training loss: 1.5523532629013062
Validation loss: 2.104151746278168

Epoch: 5| Step: 6
Training loss: 1.95546555519104
Validation loss: 2.0660153358213362

Epoch: 5| Step: 7
Training loss: 1.2526657581329346
Validation loss: 2.115288278108002

Epoch: 5| Step: 8
Training loss: 1.6223909854888916
Validation loss: 2.1126975064636557

Epoch: 5| Step: 9
Training loss: 1.5928839445114136
Validation loss: 2.1620491922542615

Epoch: 5| Step: 10
Training loss: 1.025644063949585
Validation loss: 2.160547892252604

Epoch: 320| Step: 0
Training loss: 1.5652384757995605
Validation loss: 2.119910224791496

Epoch: 5| Step: 1
Training loss: 1.2512314319610596
Validation loss: 2.1085568448548675

Epoch: 5| Step: 2
Training loss: 1.5761849880218506
Validation loss: 2.0971582525519916

Epoch: 5| Step: 3
Training loss: 1.283095121383667
Validation loss: 2.0674755496363484

Epoch: 5| Step: 4
Training loss: 1.4764065742492676
Validation loss: 2.0746237308748308

Epoch: 5| Step: 5
Training loss: 1.4543269872665405
Validation loss: 2.088678821440666

Epoch: 5| Step: 6
Training loss: 1.200803279876709
Validation loss: 2.097707171593943

Epoch: 5| Step: 7
Training loss: 1.8941913843154907
Validation loss: 2.1041887242306947

Epoch: 5| Step: 8
Training loss: 1.7646198272705078
Validation loss: 2.093939741452535

Epoch: 5| Step: 9
Training loss: 1.4263737201690674
Validation loss: 2.0992987912188292

Epoch: 5| Step: 10
Training loss: 1.4280563592910767
Validation loss: 2.128223708880845

Epoch: 321| Step: 0
Training loss: 1.1778613328933716
Validation loss: 2.125975142243088

Epoch: 5| Step: 1
Training loss: 1.4491442441940308
Validation loss: 2.14374682980199

Epoch: 5| Step: 2
Training loss: 1.9338676929473877
Validation loss: 2.1839013240670644

Epoch: 5| Step: 3
Training loss: 1.5921732187271118
Validation loss: 2.1617348681214037

Epoch: 5| Step: 4
Training loss: 1.1563605070114136
Validation loss: 2.1772099951262116

Epoch: 5| Step: 5
Training loss: 1.56035578250885
Validation loss: 2.18371928891828

Epoch: 5| Step: 6
Training loss: 1.170567512512207
Validation loss: 2.1775415174422728

Epoch: 5| Step: 7
Training loss: 1.2346651554107666
Validation loss: 2.160391753719699

Epoch: 5| Step: 8
Training loss: 1.894410490989685
Validation loss: 2.134545915870256

Epoch: 5| Step: 9
Training loss: 1.6845155954360962
Validation loss: 2.1286763811624176

Epoch: 5| Step: 10
Training loss: 1.1148971319198608
Validation loss: 2.099471246042559

Epoch: 322| Step: 0
Training loss: 1.7167425155639648
Validation loss: 2.084570574504073

Epoch: 5| Step: 1
Training loss: 1.2130330801010132
Validation loss: 2.079367519706808

Epoch: 5| Step: 2
Training loss: 1.5376431941986084
Validation loss: 2.064734205122917

Epoch: 5| Step: 3
Training loss: 1.6453306674957275
Validation loss: 2.0712478417222218

Epoch: 5| Step: 4
Training loss: 1.8904231786727905
Validation loss: 2.0535880955316688

Epoch: 5| Step: 5
Training loss: 1.0837528705596924
Validation loss: 2.0841365424535607

Epoch: 5| Step: 6
Training loss: 1.5391350984573364
Validation loss: 2.0715693017487884

Epoch: 5| Step: 7
Training loss: 1.3016173839569092
Validation loss: 2.101851681227325

Epoch: 5| Step: 8
Training loss: 1.2861201763153076
Validation loss: 2.1209566234260477

Epoch: 5| Step: 9
Training loss: 1.8810256719589233
Validation loss: 2.1568129652289936

Epoch: 5| Step: 10
Training loss: 0.7627437114715576
Validation loss: 2.151835713335263

Epoch: 323| Step: 0
Training loss: 1.4615710973739624
Validation loss: 2.181623307607507

Epoch: 5| Step: 1
Training loss: 1.369783639907837
Validation loss: 2.160812270256781

Epoch: 5| Step: 2
Training loss: 1.3645216226577759
Validation loss: 2.1521107663390455

Epoch: 5| Step: 3
Training loss: 1.4901162385940552
Validation loss: 2.1454593494374263

Epoch: 5| Step: 4
Training loss: 1.263183355331421
Validation loss: 2.155445073240547

Epoch: 5| Step: 5
Training loss: 1.317006230354309
Validation loss: 2.1381602389838106

Epoch: 5| Step: 6
Training loss: 1.9027332067489624
Validation loss: 2.116178535646008

Epoch: 5| Step: 7
Training loss: 1.0330859422683716
Validation loss: 2.1427957242535007

Epoch: 5| Step: 8
Training loss: 1.5266942977905273
Validation loss: 2.075058844781691

Epoch: 5| Step: 9
Training loss: 1.9506734609603882
Validation loss: 2.1130228632239887

Epoch: 5| Step: 10
Training loss: 1.246909260749817
Validation loss: 2.075679345797467

Epoch: 324| Step: 0
Training loss: 0.9701130986213684
Validation loss: 2.0868950672047113

Epoch: 5| Step: 1
Training loss: 1.322191834449768
Validation loss: 2.066457509994507

Epoch: 5| Step: 2
Training loss: 1.668172836303711
Validation loss: 2.085328120057301

Epoch: 5| Step: 3
Training loss: 1.5923789739608765
Validation loss: 2.1133622200258317

Epoch: 5| Step: 4
Training loss: 1.4613059759140015
Validation loss: 2.1037172399541384

Epoch: 5| Step: 5
Training loss: 1.6455669403076172
Validation loss: 2.1312442338594826

Epoch: 5| Step: 6
Training loss: 1.6761480569839478
Validation loss: 2.1518050214295745

Epoch: 5| Step: 7
Training loss: 1.3330618143081665
Validation loss: 2.172207683645269

Epoch: 5| Step: 8
Training loss: 1.690386176109314
Validation loss: 2.152376118526664

Epoch: 5| Step: 9
Training loss: 1.1239618062973022
Validation loss: 2.1220942158852854

Epoch: 5| Step: 10
Training loss: 1.3112530708312988
Validation loss: 2.1086797611687773

Epoch: 325| Step: 0
Training loss: 1.552178978919983
Validation loss: 2.0853386463657504

Epoch: 5| Step: 1
Training loss: 1.9261443614959717
Validation loss: 2.0836481766034196

Epoch: 5| Step: 2
Training loss: 1.3754875659942627
Validation loss: 2.0700638396765596

Epoch: 5| Step: 3
Training loss: 1.7754108905792236
Validation loss: 2.058752800828667

Epoch: 5| Step: 4
Training loss: 1.6515471935272217
Validation loss: 2.0487554291243195

Epoch: 5| Step: 5
Training loss: 0.9248853921890259
Validation loss: 2.071083185493305

Epoch: 5| Step: 6
Training loss: 0.9005616307258606
Validation loss: 2.0734560669109388

Epoch: 5| Step: 7
Training loss: 1.6601682901382446
Validation loss: 2.089369998183302

Epoch: 5| Step: 8
Training loss: 1.5438568592071533
Validation loss: 2.1186825716367332

Epoch: 5| Step: 9
Training loss: 1.098210096359253
Validation loss: 2.102914020579348

Epoch: 5| Step: 10
Training loss: 1.2167333364486694
Validation loss: 2.098124434871058

Epoch: 326| Step: 0
Training loss: 1.5955363512039185
Validation loss: 2.117569044072141

Epoch: 5| Step: 1
Training loss: 1.3457410335540771
Validation loss: 2.1359113288182083

Epoch: 5| Step: 2
Training loss: 1.106651782989502
Validation loss: 2.104566917624525

Epoch: 5| Step: 3
Training loss: 1.0895798206329346
Validation loss: 2.088705590976182

Epoch: 5| Step: 4
Training loss: 1.4083373546600342
Validation loss: 2.090257462634835

Epoch: 5| Step: 5
Training loss: 1.7401115894317627
Validation loss: 2.0660996719073226

Epoch: 5| Step: 6
Training loss: 1.4084899425506592
Validation loss: 2.064045061347305

Epoch: 5| Step: 7
Training loss: 1.8456408977508545
Validation loss: 2.072933563622095

Epoch: 5| Step: 8
Training loss: 1.164168357849121
Validation loss: 2.059384351135582

Epoch: 5| Step: 9
Training loss: 1.2451107501983643
Validation loss: 2.046442101078649

Epoch: 5| Step: 10
Training loss: 1.622074007987976
Validation loss: 2.0929790196880216

Epoch: 327| Step: 0
Training loss: 1.798305869102478
Validation loss: 2.0763001211227907

Epoch: 5| Step: 1
Training loss: 1.7801220417022705
Validation loss: 2.0860110175225044

Epoch: 5| Step: 2
Training loss: 1.1630020141601562
Validation loss: 2.086987510804207

Epoch: 5| Step: 3
Training loss: 1.5626771450042725
Validation loss: 2.1050959248696604

Epoch: 5| Step: 4
Training loss: 1.2248495817184448
Validation loss: 2.099594359756798

Epoch: 5| Step: 5
Training loss: 1.478033423423767
Validation loss: 2.107309228630476

Epoch: 5| Step: 6
Training loss: 1.3296586275100708
Validation loss: 2.1245367398826023

Epoch: 5| Step: 7
Training loss: 1.5569918155670166
Validation loss: 2.110808223806402

Epoch: 5| Step: 8
Training loss: 1.6153948307037354
Validation loss: 2.135232997196977

Epoch: 5| Step: 9
Training loss: 1.1411117315292358
Validation loss: 2.1407933299259474

Epoch: 5| Step: 10
Training loss: 0.8624422550201416
Validation loss: 2.1401698486779326

Epoch: 328| Step: 0
Training loss: 1.8006178140640259
Validation loss: 2.1422916355953423

Epoch: 5| Step: 1
Training loss: 2.125190258026123
Validation loss: 2.153372597950761

Epoch: 5| Step: 2
Training loss: 1.5759899616241455
Validation loss: 2.1043762635159236

Epoch: 5| Step: 3
Training loss: 0.8762258291244507
Validation loss: 2.126289103620796

Epoch: 5| Step: 4
Training loss: 1.6199671030044556
Validation loss: 2.1270732341274137

Epoch: 5| Step: 5
Training loss: 1.21714186668396
Validation loss: 2.101594432707756

Epoch: 5| Step: 6
Training loss: 1.1438812017440796
Validation loss: 2.079758835095231

Epoch: 5| Step: 7
Training loss: 1.2487174272537231
Validation loss: 2.0825133003214353

Epoch: 5| Step: 8
Training loss: 1.047838807106018
Validation loss: 2.0735656343480593

Epoch: 5| Step: 9
Training loss: 1.4822171926498413
Validation loss: 2.0589428511998986

Epoch: 5| Step: 10
Training loss: 1.2418739795684814
Validation loss: 2.0711087552450036

Epoch: 329| Step: 0
Training loss: 1.5127118825912476
Validation loss: 2.097502585380308

Epoch: 5| Step: 1
Training loss: 1.728255033493042
Validation loss: 2.0828850576954503

Epoch: 5| Step: 2
Training loss: 1.1073031425476074
Validation loss: 2.1178485014105357

Epoch: 5| Step: 3
Training loss: 1.4041913747787476
Validation loss: 2.0973112326796337

Epoch: 5| Step: 4
Training loss: 1.5483142137527466
Validation loss: 2.127235980444057

Epoch: 5| Step: 5
Training loss: 1.276559591293335
Validation loss: 2.1627876374029342

Epoch: 5| Step: 6
Training loss: 1.1787927150726318
Validation loss: 2.1851786810864686

Epoch: 5| Step: 7
Training loss: 1.7821515798568726
Validation loss: 2.1846217032401793

Epoch: 5| Step: 8
Training loss: 1.5123460292816162
Validation loss: 2.162977026354882

Epoch: 5| Step: 9
Training loss: 0.993451714515686
Validation loss: 2.1485115225597093

Epoch: 5| Step: 10
Training loss: 1.326658844947815
Validation loss: 2.1304117428359164

Epoch: 330| Step: 0
Training loss: 1.4671016931533813
Validation loss: 2.1127436417405323

Epoch: 5| Step: 1
Training loss: 1.821977972984314
Validation loss: 2.1263862066371466

Epoch: 5| Step: 2
Training loss: 1.7127702236175537
Validation loss: 2.1136363167916574

Epoch: 5| Step: 3
Training loss: 0.9446529150009155
Validation loss: 2.077948006250525

Epoch: 5| Step: 4
Training loss: 1.515328288078308
Validation loss: 2.063490095958915

Epoch: 5| Step: 5
Training loss: 1.53592848777771
Validation loss: 2.0859698275084138

Epoch: 5| Step: 6
Training loss: 1.6041457653045654
Validation loss: 2.041405777777395

Epoch: 5| Step: 7
Training loss: 0.8226906061172485
Validation loss: 2.05064949809864

Epoch: 5| Step: 8
Training loss: 1.2264764308929443
Validation loss: 2.029570589783371

Epoch: 5| Step: 9
Training loss: 1.4744360446929932
Validation loss: 2.0281509686541814

Epoch: 5| Step: 10
Training loss: 1.3578870296478271
Validation loss: 2.0646950275667253

Epoch: 331| Step: 0
Training loss: 1.767899513244629
Validation loss: 2.08009918274418

Epoch: 5| Step: 1
Training loss: 1.4316585063934326
Validation loss: 2.089997660729193

Epoch: 5| Step: 2
Training loss: 1.3527929782867432
Validation loss: 2.123997644711566

Epoch: 5| Step: 3
Training loss: 1.0642035007476807
Validation loss: 2.0954543672582155

Epoch: 5| Step: 4
Training loss: 1.489898443222046
Validation loss: 2.1350472434874503

Epoch: 5| Step: 5
Training loss: 1.9180456399917603
Validation loss: 2.116811038345419

Epoch: 5| Step: 6
Training loss: 1.4479175806045532
Validation loss: 2.1089560331836825

Epoch: 5| Step: 7
Training loss: 1.107511281967163
Validation loss: 2.1208355157606062

Epoch: 5| Step: 8
Training loss: 1.1677614450454712
Validation loss: 2.099653092763757

Epoch: 5| Step: 9
Training loss: 1.3687021732330322
Validation loss: 2.1187774609493952

Epoch: 5| Step: 10
Training loss: 1.4767370223999023
Validation loss: 2.096392644348965

Epoch: 332| Step: 0
Training loss: 1.2946016788482666
Validation loss: 2.1400103146030056

Epoch: 5| Step: 1
Training loss: 0.942419707775116
Validation loss: 2.139679193496704

Epoch: 5| Step: 2
Training loss: 1.2983930110931396
Validation loss: 2.145741776753497

Epoch: 5| Step: 3
Training loss: 1.4390127658843994
Validation loss: 2.1092240964212725

Epoch: 5| Step: 4
Training loss: 1.5360809564590454
Validation loss: 2.0768332430111465

Epoch: 5| Step: 5
Training loss: 1.3093149662017822
Validation loss: 2.0591258310502574

Epoch: 5| Step: 6
Training loss: 1.36125910282135
Validation loss: 2.069678738553037

Epoch: 5| Step: 7
Training loss: 1.5141150951385498
Validation loss: 2.1001569276214926

Epoch: 5| Step: 8
Training loss: 1.5876353979110718
Validation loss: 2.1233786652165074

Epoch: 5| Step: 9
Training loss: 1.717731237411499
Validation loss: 2.1060090321366505

Epoch: 5| Step: 10
Training loss: 1.282716989517212
Validation loss: 2.075409471347768

Epoch: 333| Step: 0
Training loss: 1.6582225561141968
Validation loss: 2.0735195144530265

Epoch: 5| Step: 1
Training loss: 0.5995864868164062
Validation loss: 2.063763917133372

Epoch: 5| Step: 2
Training loss: 1.580579400062561
Validation loss: 2.078640330222345

Epoch: 5| Step: 3
Training loss: 1.4481542110443115
Validation loss: 2.100565584756995

Epoch: 5| Step: 4
Training loss: 1.9915635585784912
Validation loss: 2.044336611224759

Epoch: 5| Step: 5
Training loss: 2.070486068725586
Validation loss: 2.0520781534974293

Epoch: 5| Step: 6
Training loss: 1.5892970561981201
Validation loss: 2.043831789365379

Epoch: 5| Step: 7
Training loss: 1.1012908220291138
Validation loss: 2.0671991199575444

Epoch: 5| Step: 8
Training loss: 1.025538682937622
Validation loss: 2.0367545056086716

Epoch: 5| Step: 9
Training loss: 0.9443317651748657
Validation loss: 2.062816740364157

Epoch: 5| Step: 10
Training loss: 1.3540221452713013
Validation loss: 2.065359784710792

Epoch: 334| Step: 0
Training loss: 1.6058399677276611
Validation loss: 2.0776828053177043

Epoch: 5| Step: 1
Training loss: 0.9245526194572449
Validation loss: 2.1042907878916752

Epoch: 5| Step: 2
Training loss: 1.3859601020812988
Validation loss: 2.1443383924422728

Epoch: 5| Step: 3
Training loss: 1.6155059337615967
Validation loss: 2.118212462753378

Epoch: 5| Step: 4
Training loss: 1.6309592723846436
Validation loss: 2.118974881787454

Epoch: 5| Step: 5
Training loss: 1.1234982013702393
Validation loss: 2.140861649667063

Epoch: 5| Step: 6
Training loss: 1.017917275428772
Validation loss: 2.1186512080571984

Epoch: 5| Step: 7
Training loss: 1.8831737041473389
Validation loss: 2.1368692382689445

Epoch: 5| Step: 8
Training loss: 1.5625375509262085
Validation loss: 2.121790316797072

Epoch: 5| Step: 9
Training loss: 1.0453931093215942
Validation loss: 2.102010080891271

Epoch: 5| Step: 10
Training loss: 1.4476608037948608
Validation loss: 2.092667087431877

Epoch: 335| Step: 0
Training loss: 1.1995477676391602
Validation loss: 2.0919987642636864

Epoch: 5| Step: 1
Training loss: 1.3547171354293823
Validation loss: 2.099233386337116

Epoch: 5| Step: 2
Training loss: 1.5819168090820312
Validation loss: 2.0791612440539944

Epoch: 5| Step: 3
Training loss: 1.43710458278656
Validation loss: 2.0787848528995307

Epoch: 5| Step: 4
Training loss: 1.3041808605194092
Validation loss: 2.04596830696188

Epoch: 5| Step: 5
Training loss: 1.4860056638717651
Validation loss: 2.0845225959695797

Epoch: 5| Step: 6
Training loss: 1.3343511819839478
Validation loss: 2.0835007518850346

Epoch: 5| Step: 7
Training loss: 1.4376503229141235
Validation loss: 2.129037904483016

Epoch: 5| Step: 8
Training loss: 1.3540884256362915
Validation loss: 2.0804319215077225

Epoch: 5| Step: 9
Training loss: 1.7543461322784424
Validation loss: 2.1104179607924594

Epoch: 5| Step: 10
Training loss: 0.7384940385818481
Validation loss: 2.0763315616115445

Epoch: 336| Step: 0
Training loss: 1.393366813659668
Validation loss: 2.1128137701301166

Epoch: 5| Step: 1
Training loss: 1.3306974172592163
Validation loss: 2.0965166245737383

Epoch: 5| Step: 2
Training loss: 1.4249593019485474
Validation loss: 2.104116539801321

Epoch: 5| Step: 3
Training loss: 0.8841883540153503
Validation loss: 2.0760133317721787

Epoch: 5| Step: 4
Training loss: 1.0751469135284424
Validation loss: 2.064798702475845

Epoch: 5| Step: 5
Training loss: 1.6899604797363281
Validation loss: 2.058716848332395

Epoch: 5| Step: 6
Training loss: 1.2053617238998413
Validation loss: 2.0595821231924076

Epoch: 5| Step: 7
Training loss: 1.2720495462417603
Validation loss: 2.0562612574587584

Epoch: 5| Step: 8
Training loss: 1.477887749671936
Validation loss: 2.1007635144777197

Epoch: 5| Step: 9
Training loss: 1.5342435836791992
Validation loss: 2.0950941834398495

Epoch: 5| Step: 10
Training loss: 1.6436997652053833
Validation loss: 2.108493838258969

Epoch: 337| Step: 0
Training loss: 0.9056785702705383
Validation loss: 2.1011168149209793

Epoch: 5| Step: 1
Training loss: 1.2786163091659546
Validation loss: 2.120914661756126

Epoch: 5| Step: 2
Training loss: 1.3754475116729736
Validation loss: 2.1171033549052414

Epoch: 5| Step: 3
Training loss: 1.074545979499817
Validation loss: 2.111925140503914

Epoch: 5| Step: 4
Training loss: 1.4587419033050537
Validation loss: 2.123544381510827

Epoch: 5| Step: 5
Training loss: 1.3763386011123657
Validation loss: 2.078171453168315

Epoch: 5| Step: 6
Training loss: 1.432124376296997
Validation loss: 2.0736245032279723

Epoch: 5| Step: 7
Training loss: 1.3622019290924072
Validation loss: 2.0957075806074243

Epoch: 5| Step: 8
Training loss: 1.6547437906265259
Validation loss: 2.1018482254397486

Epoch: 5| Step: 9
Training loss: 1.7784312963485718
Validation loss: 2.0865010189753708

Epoch: 5| Step: 10
Training loss: 1.3945422172546387
Validation loss: 2.0712471495392504

Epoch: 338| Step: 0
Training loss: 1.1855580806732178
Validation loss: 2.0646556449192826

Epoch: 5| Step: 1
Training loss: 1.6950947046279907
Validation loss: 2.0716410260046683

Epoch: 5| Step: 2
Training loss: 1.0994840860366821
Validation loss: 2.0972117044592418

Epoch: 5| Step: 3
Training loss: 1.1632106304168701
Validation loss: 2.0748655860142042

Epoch: 5| Step: 4
Training loss: 1.3692519664764404
Validation loss: 2.0923188219788256

Epoch: 5| Step: 5
Training loss: 0.8880952000617981
Validation loss: 2.0928297632484028

Epoch: 5| Step: 6
Training loss: 1.8372046947479248
Validation loss: 2.0617830496962353

Epoch: 5| Step: 7
Training loss: 1.0830515623092651
Validation loss: 2.0542439632518317

Epoch: 5| Step: 8
Training loss: 1.2292991876602173
Validation loss: 2.025919052862352

Epoch: 5| Step: 9
Training loss: 1.8476953506469727
Validation loss: 2.062300611567754

Epoch: 5| Step: 10
Training loss: 1.7766779661178589
Validation loss: 2.0536811659413

Epoch: 339| Step: 0
Training loss: 1.060548186302185
Validation loss: 2.0463949659819245

Epoch: 5| Step: 1
Training loss: 0.9051340818405151
Validation loss: 2.0454921824957735

Epoch: 5| Step: 2
Training loss: 1.4966847896575928
Validation loss: 2.0740466835678264

Epoch: 5| Step: 3
Training loss: 1.1119943857192993
Validation loss: 2.093603398210259

Epoch: 5| Step: 4
Training loss: 1.0891516208648682
Validation loss: 2.119455809234291

Epoch: 5| Step: 5
Training loss: 1.548415184020996
Validation loss: 2.1306928114224504

Epoch: 5| Step: 6
Training loss: 1.8601055145263672
Validation loss: 2.140477277899301

Epoch: 5| Step: 7
Training loss: 0.9694693684577942
Validation loss: 2.160055847578151

Epoch: 5| Step: 8
Training loss: 1.5240885019302368
Validation loss: 2.146932086636943

Epoch: 5| Step: 9
Training loss: 1.6921937465667725
Validation loss: 2.144228703232222

Epoch: 5| Step: 10
Training loss: 1.6897071599960327
Validation loss: 2.1282883254430627

Epoch: 340| Step: 0
Training loss: 1.1218955516815186
Validation loss: 2.0928958564676265

Epoch: 5| Step: 1
Training loss: 1.2969515323638916
Validation loss: 2.0707936004925798

Epoch: 5| Step: 2
Training loss: 1.4852814674377441
Validation loss: 2.057304795070361

Epoch: 5| Step: 3
Training loss: 1.6272494792938232
Validation loss: 2.0637878141095563

Epoch: 5| Step: 4
Training loss: 1.4054709672927856
Validation loss: 2.051921861146086

Epoch: 5| Step: 5
Training loss: 1.5741963386535645
Validation loss: 2.0472141773469987

Epoch: 5| Step: 6
Training loss: 1.4303830862045288
Validation loss: 2.0193731490001885

Epoch: 5| Step: 7
Training loss: 1.8844554424285889
Validation loss: 2.0561515105667936

Epoch: 5| Step: 8
Training loss: 0.9561243057250977
Validation loss: 2.07683906503903

Epoch: 5| Step: 9
Training loss: 1.3128849267959595
Validation loss: 2.0824597445867394

Epoch: 5| Step: 10
Training loss: 0.5895024538040161
Validation loss: 2.0970623236830517

Epoch: 341| Step: 0
Training loss: 1.0291086435317993
Validation loss: 2.0759367404445523

Epoch: 5| Step: 1
Training loss: 1.7575113773345947
Validation loss: 2.0691800117492676

Epoch: 5| Step: 2
Training loss: 1.2143198251724243
Validation loss: 2.0745865414219518

Epoch: 5| Step: 3
Training loss: 1.1431320905685425
Validation loss: 2.070963813412574

Epoch: 5| Step: 4
Training loss: 0.917923629283905
Validation loss: 2.0600970791232203

Epoch: 5| Step: 5
Training loss: 0.8754493594169617
Validation loss: 2.0731057249089724

Epoch: 5| Step: 6
Training loss: 1.5830268859863281
Validation loss: 2.0665863483182845

Epoch: 5| Step: 7
Training loss: 1.3979072570800781
Validation loss: 2.07688933034097

Epoch: 5| Step: 8
Training loss: 1.534121036529541
Validation loss: 2.1149365184127644

Epoch: 5| Step: 9
Training loss: 1.853772521018982
Validation loss: 2.078686883372645

Epoch: 5| Step: 10
Training loss: 1.3773157596588135
Validation loss: 2.1006565837449926

Epoch: 342| Step: 0
Training loss: 1.46359121799469
Validation loss: 2.070264284328748

Epoch: 5| Step: 1
Training loss: 1.427107334136963
Validation loss: 2.0826398531595864

Epoch: 5| Step: 2
Training loss: 1.12548828125
Validation loss: 2.109906304267145

Epoch: 5| Step: 3
Training loss: 1.2556684017181396
Validation loss: 2.101435212678807

Epoch: 5| Step: 4
Training loss: 1.4251772165298462
Validation loss: 2.14851100085884

Epoch: 5| Step: 5
Training loss: 1.2096143960952759
Validation loss: 2.1238076302313034

Epoch: 5| Step: 6
Training loss: 1.3696098327636719
Validation loss: 2.0859072823678293

Epoch: 5| Step: 7
Training loss: 1.6664358377456665
Validation loss: 2.0885387979527956

Epoch: 5| Step: 8
Training loss: 1.663710355758667
Validation loss: 2.1302940973671536

Epoch: 5| Step: 9
Training loss: 1.2304818630218506
Validation loss: 2.1376256199293238

Epoch: 5| Step: 10
Training loss: 1.4271953105926514
Validation loss: 2.14793409070661

Epoch: 343| Step: 0
Training loss: 1.3661378622055054
Validation loss: 2.0642978734867548

Epoch: 5| Step: 1
Training loss: 1.0415853261947632
Validation loss: 2.0748191302822483

Epoch: 5| Step: 2
Training loss: 1.416636347770691
Validation loss: 2.1003879039518294

Epoch: 5| Step: 3
Training loss: 1.6275699138641357
Validation loss: 2.1482411725546724

Epoch: 5| Step: 4
Training loss: 1.2721977233886719
Validation loss: 2.0963152339381557

Epoch: 5| Step: 5
Training loss: 1.4645689725875854
Validation loss: 2.0306321523522817

Epoch: 5| Step: 6
Training loss: 1.5774132013320923
Validation loss: 2.042482154343718

Epoch: 5| Step: 7
Training loss: 1.2666784524917603
Validation loss: 2.085574657686295

Epoch: 5| Step: 8
Training loss: 1.1966005563735962
Validation loss: 2.1233927819036666

Epoch: 5| Step: 9
Training loss: 1.8000234365463257
Validation loss: 2.139314454088929

Epoch: 5| Step: 10
Training loss: 1.3067799806594849
Validation loss: 2.11368392872554

Epoch: 344| Step: 0
Training loss: 1.2679897546768188
Validation loss: 2.124858194781888

Epoch: 5| Step: 1
Training loss: 1.1968127489089966
Validation loss: 2.139635411641931

Epoch: 5| Step: 2
Training loss: 1.274848222732544
Validation loss: 2.192376063716027

Epoch: 5| Step: 3
Training loss: 1.4333574771881104
Validation loss: 2.274301564821633

Epoch: 5| Step: 4
Training loss: 1.3528308868408203
Validation loss: 2.245775857279378

Epoch: 5| Step: 5
Training loss: 1.4241317510604858
Validation loss: 2.2016299257996264

Epoch: 5| Step: 6
Training loss: 1.2754987478256226
Validation loss: 2.1059905803331764

Epoch: 5| Step: 7
Training loss: 1.5958173274993896
Validation loss: 2.077786349481152

Epoch: 5| Step: 8
Training loss: 1.8676941394805908
Validation loss: 2.0712763006969164

Epoch: 5| Step: 9
Training loss: 1.8212785720825195
Validation loss: 2.0718706846237183

Epoch: 5| Step: 10
Training loss: 0.8165621161460876
Validation loss: 2.082435736092188

Epoch: 345| Step: 0
Training loss: 1.3185842037200928
Validation loss: 2.068762006298188

Epoch: 5| Step: 1
Training loss: 1.5716253519058228
Validation loss: 2.0720577470717894

Epoch: 5| Step: 2
Training loss: 1.3355004787445068
Validation loss: 2.06888517256706

Epoch: 5| Step: 3
Training loss: 0.8952604532241821
Validation loss: 2.07575959544028

Epoch: 5| Step: 4
Training loss: 1.4203062057495117
Validation loss: 2.0902293574425483

Epoch: 5| Step: 5
Training loss: 1.1992294788360596
Validation loss: 2.113349317222513

Epoch: 5| Step: 6
Training loss: 1.0154515504837036
Validation loss: 2.088243220442085

Epoch: 5| Step: 7
Training loss: 1.349966049194336
Validation loss: 2.1286166226992043

Epoch: 5| Step: 8
Training loss: 1.3782848119735718
Validation loss: 2.106832170999178

Epoch: 5| Step: 9
Training loss: 2.1817715167999268
Validation loss: 2.081406726632067

Epoch: 5| Step: 10
Training loss: 0.9697651863098145
Validation loss: 2.079440002800316

Epoch: 346| Step: 0
Training loss: 1.2877891063690186
Validation loss: 2.075055350539505

Epoch: 5| Step: 1
Training loss: 1.3565304279327393
Validation loss: 2.0934186007386897

Epoch: 5| Step: 2
Training loss: 1.591619849205017
Validation loss: 2.1459637534233833

Epoch: 5| Step: 3
Training loss: 1.681557297706604
Validation loss: 2.1635446317734255

Epoch: 5| Step: 4
Training loss: 1.054647445678711
Validation loss: 2.1316099282233947

Epoch: 5| Step: 5
Training loss: 1.6504271030426025
Validation loss: 2.134297824675037

Epoch: 5| Step: 6
Training loss: 1.1434128284454346
Validation loss: 2.113737972833777

Epoch: 5| Step: 7
Training loss: 1.3472189903259277
Validation loss: 2.1176445689252628

Epoch: 5| Step: 8
Training loss: 1.0850127935409546
Validation loss: 2.094249471541374

Epoch: 5| Step: 9
Training loss: 1.0469639301300049
Validation loss: 2.058650080875684

Epoch: 5| Step: 10
Training loss: 1.463529348373413
Validation loss: 2.048125822057006

Epoch: 347| Step: 0
Training loss: 1.226668357849121
Validation loss: 2.0576613333917435

Epoch: 5| Step: 1
Training loss: 1.179469108581543
Validation loss: 2.0599127443887855

Epoch: 5| Step: 2
Training loss: 1.4129928350448608
Validation loss: 2.100805372320196

Epoch: 5| Step: 3
Training loss: 1.2447242736816406
Validation loss: 2.0936276297415457

Epoch: 5| Step: 4
Training loss: 1.4650660753250122
Validation loss: 2.08995569393199

Epoch: 5| Step: 5
Training loss: 1.5491368770599365
Validation loss: 2.048184028235815

Epoch: 5| Step: 6
Training loss: 1.2778480052947998
Validation loss: 2.059340206525659

Epoch: 5| Step: 7
Training loss: 1.3542228937149048
Validation loss: 2.0530759032054613

Epoch: 5| Step: 8
Training loss: 1.028755784034729
Validation loss: 2.032173142638258

Epoch: 5| Step: 9
Training loss: 1.264971137046814
Validation loss: 2.042278366704141

Epoch: 5| Step: 10
Training loss: 1.3138059377670288
Validation loss: 2.0406847666668635

Epoch: 348| Step: 0
Training loss: 1.076987624168396
Validation loss: 2.0623982183394896

Epoch: 5| Step: 1
Training loss: 1.6850961446762085
Validation loss: 2.0359699956832396

Epoch: 5| Step: 2
Training loss: 1.2823961973190308
Validation loss: 2.0609979039879254

Epoch: 5| Step: 3
Training loss: 0.579262375831604
Validation loss: 2.0586424848084808

Epoch: 5| Step: 4
Training loss: 1.031595230102539
Validation loss: 2.068895834748463

Epoch: 5| Step: 5
Training loss: 1.4028503894805908
Validation loss: 2.073802342978857

Epoch: 5| Step: 6
Training loss: 1.8096498250961304
Validation loss: 2.047110019191619

Epoch: 5| Step: 7
Training loss: 1.3390939235687256
Validation loss: 2.0354491356880433

Epoch: 5| Step: 8
Training loss: 0.8325088620185852
Validation loss: 2.0517653496034685

Epoch: 5| Step: 9
Training loss: 1.7607330083847046
Validation loss: 2.042789364373812

Epoch: 5| Step: 10
Training loss: 1.4767192602157593
Validation loss: 2.0661317712517193

Epoch: 349| Step: 0
Training loss: 0.8671137094497681
Validation loss: 2.071272457799604

Epoch: 5| Step: 1
Training loss: 1.7909200191497803
Validation loss: 2.0746763008897022

Epoch: 5| Step: 2
Training loss: 1.707497000694275
Validation loss: 2.0740697973517963

Epoch: 5| Step: 3
Training loss: 1.0495349168777466
Validation loss: 2.0950162436372493

Epoch: 5| Step: 4
Training loss: 1.746421456336975
Validation loss: 2.085074181197792

Epoch: 5| Step: 5
Training loss: 1.0118050575256348
Validation loss: 2.080234031523428

Epoch: 5| Step: 6
Training loss: 1.1914889812469482
Validation loss: 2.048794984817505

Epoch: 5| Step: 7
Training loss: 1.198791265487671
Validation loss: 2.0724004289155364

Epoch: 5| Step: 8
Training loss: 0.6412259340286255
Validation loss: 2.0999198216263966

Epoch: 5| Step: 9
Training loss: 1.5996325016021729
Validation loss: 2.1087400682510866

Epoch: 5| Step: 10
Training loss: 1.4595354795455933
Validation loss: 2.109298385599608

Epoch: 350| Step: 0
Training loss: 1.2525101900100708
Validation loss: 2.1126315491173857

Epoch: 5| Step: 1
Training loss: 1.3793214559555054
Validation loss: 2.1098354811309488

Epoch: 5| Step: 2
Training loss: 1.070314884185791
Validation loss: 2.086418351819438

Epoch: 5| Step: 3
Training loss: 0.8654324412345886
Validation loss: 2.088944573556223

Epoch: 5| Step: 4
Training loss: 1.2503345012664795
Validation loss: 2.084415158917827

Epoch: 5| Step: 5
Training loss: 1.2494409084320068
Validation loss: 2.0472240601816485

Epoch: 5| Step: 6
Training loss: 1.292488694190979
Validation loss: 2.062720739713279

Epoch: 5| Step: 7
Training loss: 1.5359357595443726
Validation loss: 2.0646200885054884

Epoch: 5| Step: 8
Training loss: 1.5467065572738647
Validation loss: 2.0881556028960855

Epoch: 5| Step: 9
Training loss: 1.18259596824646
Validation loss: 2.0783387102106565

Epoch: 5| Step: 10
Training loss: 1.607524037361145
Validation loss: 2.0486848303066787

Testing loss: 2.2320878505706787
