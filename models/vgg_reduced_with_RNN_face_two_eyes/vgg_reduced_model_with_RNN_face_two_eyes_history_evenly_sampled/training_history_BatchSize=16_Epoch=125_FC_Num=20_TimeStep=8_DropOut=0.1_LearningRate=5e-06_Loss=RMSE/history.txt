Epoch: 1| Step: 0
Training loss: 5.456983540134587
Validation loss: 5.743667282617036

Epoch: 6| Step: 1
Training loss: 6.163548205137263
Validation loss: 5.739578978101721

Epoch: 6| Step: 2
Training loss: 6.283015823774191
Validation loss: 5.735731171670506

Epoch: 6| Step: 3
Training loss: 5.776680785152897
Validation loss: 5.731974850937875

Epoch: 6| Step: 4
Training loss: 6.7307164284448
Validation loss: 5.727890609377248

Epoch: 6| Step: 5
Training loss: 5.65961267824262
Validation loss: 5.724065594567337

Epoch: 6| Step: 6
Training loss: 4.36137448195247
Validation loss: 5.720287704191071

Epoch: 6| Step: 7
Training loss: 5.779429216020236
Validation loss: 5.716431834944268

Epoch: 6| Step: 8
Training loss: 5.525786551849571
Validation loss: 5.712708161690749

Epoch: 6| Step: 9
Training loss: 5.7100791025110675
Validation loss: 5.709197114723671

Epoch: 6| Step: 10
Training loss: 5.188081823605219
Validation loss: 5.7051890586145735

Epoch: 6| Step: 11
Training loss: 5.944803664780946
Validation loss: 5.701037882835633

Epoch: 6| Step: 12
Training loss: 5.761239055772957
Validation loss: 5.696528827599533

Epoch: 6| Step: 13
Training loss: 6.021907231037252
Validation loss: 5.692398779660082

Epoch: 2| Step: 0
Training loss: 3.9586679551415958
Validation loss: 5.687683663236285

Epoch: 6| Step: 1
Training loss: 5.966056815296
Validation loss: 5.6831002998349165

Epoch: 6| Step: 2
Training loss: 6.522132167306371
Validation loss: 5.678082638414558

Epoch: 6| Step: 3
Training loss: 5.561428695554964
Validation loss: 5.672687339120465

Epoch: 6| Step: 4
Training loss: 6.324455798715202
Validation loss: 5.667059030044779

Epoch: 6| Step: 5
Training loss: 5.186803012582318
Validation loss: 5.661434564282921

Epoch: 6| Step: 6
Training loss: 6.496303093909601
Validation loss: 5.655506100298587

Epoch: 6| Step: 7
Training loss: 5.1424688957137885
Validation loss: 5.64937397919611

Epoch: 6| Step: 8
Training loss: 4.645078634822196
Validation loss: 5.642871178461562

Epoch: 6| Step: 9
Training loss: 6.0950835504977965
Validation loss: 5.636531255672269

Epoch: 6| Step: 10
Training loss: 6.259004438899377
Validation loss: 5.629017890493195

Epoch: 6| Step: 11
Training loss: 6.706022192222311
Validation loss: 5.621863289316141

Epoch: 6| Step: 12
Training loss: 5.306286937284019
Validation loss: 5.6146672698960804

Epoch: 6| Step: 13
Training loss: 3.755314176904609
Validation loss: 5.606256773704927

Epoch: 3| Step: 0
Training loss: 4.591327677338903
Validation loss: 5.597552773823827

Epoch: 6| Step: 1
Training loss: 6.15183808685858
Validation loss: 5.5890756365395875

Epoch: 6| Step: 2
Training loss: 6.661904668780391
Validation loss: 5.581076602901555

Epoch: 6| Step: 3
Training loss: 6.592798245699325
Validation loss: 5.571313644693879

Epoch: 6| Step: 4
Training loss: 5.644296397038957
Validation loss: 5.561080229711114

Epoch: 6| Step: 5
Training loss: 5.295898347461045
Validation loss: 5.550678648581379

Epoch: 6| Step: 6
Training loss: 4.191815330543661
Validation loss: 5.539652213157272

Epoch: 6| Step: 7
Training loss: 5.6239646806543915
Validation loss: 5.529184641669256

Epoch: 6| Step: 8
Training loss: 4.615808374562747
Validation loss: 5.517245546612705

Epoch: 6| Step: 9
Training loss: 4.679974020209299
Validation loss: 5.505679329671477

Epoch: 6| Step: 10
Training loss: 6.295146695488883
Validation loss: 5.49367813921423

Epoch: 6| Step: 11
Training loss: 6.077292103320526
Validation loss: 5.481279191521145

Epoch: 6| Step: 12
Training loss: 6.135795888099597
Validation loss: 5.468292279052026

Epoch: 6| Step: 13
Training loss: 3.8505019764812785
Validation loss: 5.454544419999831

Epoch: 4| Step: 0
Training loss: 6.091865443766871
Validation loss: 5.44026187301407

Epoch: 6| Step: 1
Training loss: 6.3063856671714476
Validation loss: 5.426043061195649

Epoch: 6| Step: 2
Training loss: 5.275180195266253
Validation loss: 5.410417060315498

Epoch: 6| Step: 3
Training loss: 5.468909735390378
Validation loss: 5.394651390493191

Epoch: 6| Step: 4
Training loss: 5.834813429751612
Validation loss: 5.378386895393746

Epoch: 6| Step: 5
Training loss: 6.013872956608946
Validation loss: 5.361811732774742

Epoch: 6| Step: 6
Training loss: 4.780294085916845
Validation loss: 5.343403015596375

Epoch: 6| Step: 7
Training loss: 4.700921946254308
Validation loss: 5.324382054902469

Epoch: 6| Step: 8
Training loss: 5.313934132596693
Validation loss: 5.306680896103245

Epoch: 6| Step: 9
Training loss: 4.838138603227792
Validation loss: 5.286750873703561

Epoch: 6| Step: 10
Training loss: 5.307465085935822
Validation loss: 5.268151729480703

Epoch: 6| Step: 11
Training loss: 5.850544126587581
Validation loss: 5.248717296375286

Epoch: 6| Step: 12
Training loss: 3.7766707253721896
Validation loss: 5.228286211467118

Epoch: 6| Step: 13
Training loss: 5.259305971432681
Validation loss: 5.20708896005033

Epoch: 5| Step: 0
Training loss: 5.266692916386211
Validation loss: 5.185522800521997

Epoch: 6| Step: 1
Training loss: 5.090440669741492
Validation loss: 5.161449107488671

Epoch: 6| Step: 2
Training loss: 5.640217520665309
Validation loss: 5.137507870787392

Epoch: 6| Step: 3
Training loss: 5.6594310266932695
Validation loss: 5.11415751175184

Epoch: 6| Step: 4
Training loss: 5.000909722538342
Validation loss: 5.0869460754386955

Epoch: 6| Step: 5
Training loss: 4.718400348567853
Validation loss: 5.0618670073019505

Epoch: 6| Step: 6
Training loss: 5.49106079525865
Validation loss: 5.033765360374361

Epoch: 6| Step: 7
Training loss: 3.9408674826499945
Validation loss: 5.004573240040644

Epoch: 6| Step: 8
Training loss: 5.598257965522414
Validation loss: 4.975221333388309

Epoch: 6| Step: 9
Training loss: 4.8786984621610285
Validation loss: 4.946111734793895

Epoch: 6| Step: 10
Training loss: 5.268262072649128
Validation loss: 4.921444382770915

Epoch: 6| Step: 11
Training loss: 4.834444422553212
Validation loss: 4.893910625544034

Epoch: 6| Step: 12
Training loss: 5.116212521920684
Validation loss: 4.867194505359032

Epoch: 6| Step: 13
Training loss: 3.836962778467141
Validation loss: 4.84049863955767

Epoch: 6| Step: 0
Training loss: 5.137473581065169
Validation loss: 4.8150214547068275

Epoch: 6| Step: 1
Training loss: 4.0112656260346835
Validation loss: 4.791141288956743

Epoch: 6| Step: 2
Training loss: 4.900022016203329
Validation loss: 4.767367248688148

Epoch: 6| Step: 3
Training loss: 5.3157349554370255
Validation loss: 4.743417497675309

Epoch: 6| Step: 4
Training loss: 4.516834136748491
Validation loss: 4.720578807483816

Epoch: 6| Step: 5
Training loss: 4.45904532953574
Validation loss: 4.698095781492337

Epoch: 6| Step: 6
Training loss: 4.284818178679326
Validation loss: 4.675100242352067

Epoch: 6| Step: 7
Training loss: 4.880764023428359
Validation loss: 4.652704609541658

Epoch: 6| Step: 8
Training loss: 4.490769137496278
Validation loss: 4.63313971364494

Epoch: 6| Step: 9
Training loss: 4.997336822792173
Validation loss: 4.612432166742737

Epoch: 6| Step: 10
Training loss: 3.771861882728201
Validation loss: 4.5926418668611975

Epoch: 6| Step: 11
Training loss: 4.7983177575064735
Validation loss: 4.575746344948132

Epoch: 6| Step: 12
Training loss: 5.176184941509147
Validation loss: 4.558136700408841

Epoch: 6| Step: 13
Training loss: 6.00932096634574
Validation loss: 4.541080820156131

Epoch: 7| Step: 0
Training loss: 5.132184087411526
Validation loss: 4.524398508650278

Epoch: 6| Step: 1
Training loss: 4.1614640879999065
Validation loss: 4.509201645890468

Epoch: 6| Step: 2
Training loss: 3.5169478576716977
Validation loss: 4.494306827805111

Epoch: 6| Step: 3
Training loss: 5.561022444373971
Validation loss: 4.480675403403699

Epoch: 6| Step: 4
Training loss: 3.8177421675878938
Validation loss: 4.467055177406185

Epoch: 6| Step: 5
Training loss: 4.798014055136877
Validation loss: 4.455331303233942

Epoch: 6| Step: 6
Training loss: 5.164358525873727
Validation loss: 4.443763417874353

Epoch: 6| Step: 7
Training loss: 4.039897544619233
Validation loss: 4.431158169449594

Epoch: 6| Step: 8
Training loss: 4.470710377751871
Validation loss: 4.419421315394926

Epoch: 6| Step: 9
Training loss: 4.248817503736035
Validation loss: 4.4073110033350895

Epoch: 6| Step: 10
Training loss: 3.8051703614683747
Validation loss: 4.39755264311253

Epoch: 6| Step: 11
Training loss: 5.38934576363493
Validation loss: 4.386228821407815

Epoch: 6| Step: 12
Training loss: 4.273203618485675
Validation loss: 4.376512320577092

Epoch: 6| Step: 13
Training loss: 4.858261520526767
Validation loss: 4.366754222468961

Epoch: 8| Step: 0
Training loss: 5.006619268126116
Validation loss: 4.358895250023063

Epoch: 6| Step: 1
Training loss: 4.775006974300065
Validation loss: 4.3479829131163665

Epoch: 6| Step: 2
Training loss: 4.000530446166859
Validation loss: 4.339231607910372

Epoch: 6| Step: 3
Training loss: 4.414622259515967
Validation loss: 4.33248134942873

Epoch: 6| Step: 4
Training loss: 4.471614746368632
Validation loss: 4.324467519606041

Epoch: 6| Step: 5
Training loss: 4.320078507169224
Validation loss: 4.316215824902203

Epoch: 6| Step: 6
Training loss: 4.292978080204829
Validation loss: 4.3100806641979945

Epoch: 6| Step: 7
Training loss: 4.192965911471929
Validation loss: 4.301887621970825

Epoch: 6| Step: 8
Training loss: 4.319901458887917
Validation loss: 4.293315291632097

Epoch: 6| Step: 9
Training loss: 4.647561793827104
Validation loss: 4.285564323346694

Epoch: 6| Step: 10
Training loss: 4.237740730942084
Validation loss: 4.277553846985336

Epoch: 6| Step: 11
Training loss: 4.660410206630676
Validation loss: 4.273192303713266

Epoch: 6| Step: 12
Training loss: 4.1424056920589685
Validation loss: 4.263416076391254

Epoch: 6| Step: 13
Training loss: 4.433816159757347
Validation loss: 4.256375001938327

Epoch: 9| Step: 0
Training loss: 5.376152979479346
Validation loss: 4.250039845423998

Epoch: 6| Step: 1
Training loss: 2.169263518383306
Validation loss: 4.240897014299721

Epoch: 6| Step: 2
Training loss: 4.673819963166714
Validation loss: 4.234579702456813

Epoch: 6| Step: 3
Training loss: 3.097670411971095
Validation loss: 4.230223157555483

Epoch: 6| Step: 4
Training loss: 4.01485830624672
Validation loss: 4.223360911607062

Epoch: 6| Step: 5
Training loss: 4.523864620513785
Validation loss: 4.215499416825004

Epoch: 6| Step: 6
Training loss: 4.912281386774536
Validation loss: 4.208932711863749

Epoch: 6| Step: 7
Training loss: 3.580783572621713
Validation loss: 4.202969453477433

Epoch: 6| Step: 8
Training loss: 4.542421657325468
Validation loss: 4.19545635136332

Epoch: 6| Step: 9
Training loss: 4.405895029473829
Validation loss: 4.186903664828123

Epoch: 6| Step: 10
Training loss: 4.54407763867473
Validation loss: 4.182202047112845

Epoch: 6| Step: 11
Training loss: 4.612606041162284
Validation loss: 4.177411075320464

Epoch: 6| Step: 12
Training loss: 4.60312054977668
Validation loss: 4.1702907814730965

Epoch: 6| Step: 13
Training loss: 4.80961700881519
Validation loss: 4.1620906279813425

Epoch: 10| Step: 0
Training loss: 4.752047850216994
Validation loss: 4.153123287517023

Epoch: 6| Step: 1
Training loss: 4.598781399403223
Validation loss: 4.147547522017591

Epoch: 6| Step: 2
Training loss: 4.846243923873182
Validation loss: 4.14103507303893

Epoch: 6| Step: 3
Training loss: 3.9026607044862125
Validation loss: 4.132993265413715

Epoch: 6| Step: 4
Training loss: 3.586638072607744
Validation loss: 4.127481901589351

Epoch: 6| Step: 5
Training loss: 3.3262247741040847
Validation loss: 4.117501934054621

Epoch: 6| Step: 6
Training loss: 4.548141250738583
Validation loss: 4.111641745165308

Epoch: 6| Step: 7
Training loss: 4.220009170811528
Validation loss: 4.102902781807782

Epoch: 6| Step: 8
Training loss: 4.442901976801184
Validation loss: 4.0952337751521455

Epoch: 6| Step: 9
Training loss: 5.6086969417394394
Validation loss: 4.089992637191393

Epoch: 6| Step: 10
Training loss: 3.026133988373347
Validation loss: 4.081823637892917

Epoch: 6| Step: 11
Training loss: 4.142912840821133
Validation loss: 4.076201381932586

Epoch: 6| Step: 12
Training loss: 3.878197366068502
Validation loss: 4.0664696444132655

Epoch: 6| Step: 13
Training loss: 3.6717378631306015
Validation loss: 4.05861923224144

Epoch: 11| Step: 0
Training loss: 4.9245528429619885
Validation loss: 4.052260172331719

Epoch: 6| Step: 1
Training loss: 4.135758213701239
Validation loss: 4.04544075542214

Epoch: 6| Step: 2
Training loss: 3.6944561020389157
Validation loss: 4.040871741915475

Epoch: 6| Step: 3
Training loss: 3.6857650037298533
Validation loss: 4.034319336903705

Epoch: 6| Step: 4
Training loss: 4.732045825055976
Validation loss: 4.029057515683893

Epoch: 6| Step: 5
Training loss: 4.4987729836884025
Validation loss: 4.023563804280732

Epoch: 6| Step: 6
Training loss: 3.6286143995514766
Validation loss: 4.019542118027801

Epoch: 6| Step: 7
Training loss: 3.4678118012609684
Validation loss: 4.018266819702066

Epoch: 6| Step: 8
Training loss: 4.72908595796299
Validation loss: 4.0139208379572215

Epoch: 6| Step: 9
Training loss: 2.8134114801783467
Validation loss: 4.000074603810417

Epoch: 6| Step: 10
Training loss: 3.9092204282163827
Validation loss: 3.9980342916150184

Epoch: 6| Step: 11
Training loss: 3.513516077528432
Validation loss: 3.995089217266852

Epoch: 6| Step: 12
Training loss: 5.076802900310256
Validation loss: 3.989920676293548

Epoch: 6| Step: 13
Training loss: 5.228962665038656
Validation loss: 3.986179685127264

Epoch: 12| Step: 0
Training loss: 4.069910655622673
Validation loss: 3.9793886856036034

Epoch: 6| Step: 1
Training loss: 4.645338548163178
Validation loss: 3.9751740646405698

Epoch: 6| Step: 2
Training loss: 3.726298004936567
Validation loss: 3.969367242430808

Epoch: 6| Step: 3
Training loss: 4.13374003798741
Validation loss: 3.965978140071324

Epoch: 6| Step: 4
Training loss: 4.074399920318741
Validation loss: 3.9618829809582565

Epoch: 6| Step: 5
Training loss: 4.306950412256646
Validation loss: 3.9586717967138223

Epoch: 6| Step: 6
Training loss: 2.8870228360749186
Validation loss: 3.9550678654411935

Epoch: 6| Step: 7
Training loss: 2.9067206873233915
Validation loss: 3.9475945405613815

Epoch: 6| Step: 8
Training loss: 3.9350918868895755
Validation loss: 3.943584144866859

Epoch: 6| Step: 9
Training loss: 4.5077962098248765
Validation loss: 3.93887611063994

Epoch: 6| Step: 10
Training loss: 4.257752472340619
Validation loss: 3.9329935600424295

Epoch: 6| Step: 11
Training loss: 4.846491081139069
Validation loss: 3.9306684858240826

Epoch: 6| Step: 12
Training loss: 4.223203667685232
Validation loss: 3.922705300599462

Epoch: 6| Step: 13
Training loss: 4.6715124493522575
Validation loss: 3.9206109726995306

Epoch: 13| Step: 0
Training loss: 3.522759958154731
Validation loss: 3.9151906605619624

Epoch: 6| Step: 1
Training loss: 4.65269221643124
Validation loss: 3.9105907003491946

Epoch: 6| Step: 2
Training loss: 4.785509792424279
Validation loss: 3.910970462972524

Epoch: 6| Step: 3
Training loss: 3.2862542638682104
Validation loss: 3.905808206493582

Epoch: 6| Step: 4
Training loss: 3.789130204372565
Validation loss: 3.901804964737277

Epoch: 6| Step: 5
Training loss: 4.712674707872556
Validation loss: 3.8964614129364583

Epoch: 6| Step: 6
Training loss: 3.8834119982521744
Validation loss: 3.8927938872824948

Epoch: 6| Step: 7
Training loss: 4.385769042342909
Validation loss: 3.8867424041428964

Epoch: 6| Step: 8
Training loss: 2.693062636617666
Validation loss: 3.88347998006868

Epoch: 6| Step: 9
Training loss: 3.4777110056481337
Validation loss: 3.880014380544762

Epoch: 6| Step: 10
Training loss: 4.148620256611749
Validation loss: 3.876380400642365

Epoch: 6| Step: 11
Training loss: 4.509200122215414
Validation loss: 3.873792644806386

Epoch: 6| Step: 12
Training loss: 3.0082154635711444
Validation loss: 3.8701778195959173

Epoch: 6| Step: 13
Training loss: 5.69124169985616
Validation loss: 3.8635768209320673

Epoch: 14| Step: 0
Training loss: 3.1081976266917564
Validation loss: 3.8595480592581897

Epoch: 6| Step: 1
Training loss: 3.6354483937333693
Validation loss: 3.8554479986160697

Epoch: 6| Step: 2
Training loss: 4.456923407437649
Validation loss: 3.8522302970966957

Epoch: 6| Step: 3
Training loss: 3.683855745255977
Validation loss: 3.8494219193218777

Epoch: 6| Step: 4
Training loss: 3.4732697055526462
Validation loss: 3.846642964296596

Epoch: 6| Step: 5
Training loss: 4.61010612249798
Validation loss: 3.8409878870750975

Epoch: 6| Step: 6
Training loss: 4.074494247411866
Validation loss: 3.837523214816389

Epoch: 6| Step: 7
Training loss: 3.455525526166361
Validation loss: 3.8319578275486843

Epoch: 6| Step: 8
Training loss: 3.6202678705657787
Validation loss: 3.8277875010235567

Epoch: 6| Step: 9
Training loss: 5.205707447591271
Validation loss: 3.822740455802986

Epoch: 6| Step: 10
Training loss: 2.8660317568034483
Validation loss: 3.817805770859243

Epoch: 6| Step: 11
Training loss: 4.730871937813598
Validation loss: 3.817096378395873

Epoch: 6| Step: 12
Training loss: 4.481683115864551
Validation loss: 3.8108179075668884

Epoch: 6| Step: 13
Training loss: 3.7838144985079083
Validation loss: 3.804982043769629

Epoch: 15| Step: 0
Training loss: 3.7286207485016796
Validation loss: 3.799654184332286

Epoch: 6| Step: 1
Training loss: 4.200476964479864
Validation loss: 3.7964201434912472

Epoch: 6| Step: 2
Training loss: 3.745434079446793
Validation loss: 3.7944099421658075

Epoch: 6| Step: 3
Training loss: 3.7330310909224234
Validation loss: 3.7923271192673043

Epoch: 6| Step: 4
Training loss: 3.274980932282129
Validation loss: 3.786743103703353

Epoch: 6| Step: 5
Training loss: 3.911300933691562
Validation loss: 3.7859232685940163

Epoch: 6| Step: 6
Training loss: 4.081659298245399
Validation loss: 3.779155069853412

Epoch: 6| Step: 7
Training loss: 4.429069570133222
Validation loss: 3.7758401076765824

Epoch: 6| Step: 8
Training loss: 3.6003863551191184
Validation loss: 3.7703073493145793

Epoch: 6| Step: 9
Training loss: 4.883867073618347
Validation loss: 3.7676854355496827

Epoch: 6| Step: 10
Training loss: 4.268407563846676
Validation loss: 3.7655009301739306

Epoch: 6| Step: 11
Training loss: 2.6066537704376405
Validation loss: 3.7617884648749804

Epoch: 6| Step: 12
Training loss: 4.450499714428694
Validation loss: 3.7569218512311493

Epoch: 6| Step: 13
Training loss: 3.8509260971122155
Validation loss: 3.755884140641421

Epoch: 16| Step: 0
Training loss: 3.9843393361608537
Validation loss: 3.74872807087193

Epoch: 6| Step: 1
Training loss: 3.2069406996104357
Validation loss: 3.745609194495003

Epoch: 6| Step: 2
Training loss: 4.361443797797098
Validation loss: 3.744447550295561

Epoch: 6| Step: 3
Training loss: 3.3147661626628757
Validation loss: 3.7482859177206893

Epoch: 6| Step: 4
Training loss: 3.6627559325074013
Validation loss: 3.74550171961931

Epoch: 6| Step: 5
Training loss: 4.0060629195453785
Validation loss: 3.7380053694999043

Epoch: 6| Step: 6
Training loss: 3.816059389623898
Validation loss: 3.7359258145255745

Epoch: 6| Step: 7
Training loss: 3.413464945649898
Validation loss: 3.7330261065234986

Epoch: 6| Step: 8
Training loss: 5.0721291225134655
Validation loss: 3.7257438722421106

Epoch: 6| Step: 9
Training loss: 4.273837389882335
Validation loss: 3.7223641341936218

Epoch: 6| Step: 10
Training loss: 3.2886594403049156
Validation loss: 3.7222921877816546

Epoch: 6| Step: 11
Training loss: 2.8218082255323678
Validation loss: 3.7208871633295333

Epoch: 6| Step: 12
Training loss: 4.400526292710001
Validation loss: 3.716334179306108

Epoch: 6| Step: 13
Training loss: 4.882304075092521
Validation loss: 3.712467852214662

Epoch: 17| Step: 0
Training loss: 3.3056105458648055
Validation loss: 3.7078540091720407

Epoch: 6| Step: 1
Training loss: 4.481578420099112
Validation loss: 3.7062456343275327

Epoch: 6| Step: 2
Training loss: 3.3573403517771174
Validation loss: 3.7021232978473892

Epoch: 6| Step: 3
Training loss: 4.3112180711864045
Validation loss: 3.7000804587509553

Epoch: 6| Step: 4
Training loss: 4.16386415964669
Validation loss: 3.6998994943326338

Epoch: 6| Step: 5
Training loss: 3.7401637456614587
Validation loss: 3.6964299921487536

Epoch: 6| Step: 6
Training loss: 3.8474776638044466
Validation loss: 3.691910885305672

Epoch: 6| Step: 7
Training loss: 3.4991107901024128
Validation loss: 3.687767382021838

Epoch: 6| Step: 8
Training loss: 4.448236077280381
Validation loss: 3.6857660637507075

Epoch: 6| Step: 9
Training loss: 2.772325061614063
Validation loss: 3.682273493738461

Epoch: 6| Step: 10
Training loss: 3.8072672720082803
Validation loss: 3.680500869411784

Epoch: 6| Step: 11
Training loss: 3.6622872352642006
Validation loss: 3.6793628510484275

Epoch: 6| Step: 12
Training loss: 3.9499996330164486
Validation loss: 3.6753181576512266

Epoch: 6| Step: 13
Training loss: 4.908304355365248
Validation loss: 3.673632842758728

Epoch: 18| Step: 0
Training loss: 3.7752778361563455
Validation loss: 3.6706301926550875

Epoch: 6| Step: 1
Training loss: 3.943630592726972
Validation loss: 3.668020741377528

Epoch: 6| Step: 2
Training loss: 4.554171341558898
Validation loss: 3.666146878253732

Epoch: 6| Step: 3
Training loss: 3.7560873850121825
Validation loss: 3.6617364617478554

Epoch: 6| Step: 4
Training loss: 3.978392174462347
Validation loss: 3.6614646609910153

Epoch: 6| Step: 5
Training loss: 3.6705628992949655
Validation loss: 3.661659526582093

Epoch: 6| Step: 6
Training loss: 3.2902180506095093
Validation loss: 3.6589922567733018

Epoch: 6| Step: 7
Training loss: 2.2776718295921983
Validation loss: 3.6550432935650776

Epoch: 6| Step: 8
Training loss: 4.161909566707941
Validation loss: 3.653898866069038

Epoch: 6| Step: 9
Training loss: 3.9338427316156097
Validation loss: 3.648876627080587

Epoch: 6| Step: 10
Training loss: 4.208517819631893
Validation loss: 3.647540239906091

Epoch: 6| Step: 11
Training loss: 4.040042485306442
Validation loss: 3.6458799991463087

Epoch: 6| Step: 12
Training loss: 3.660900581750071
Validation loss: 3.6438089983722564

Epoch: 6| Step: 13
Training loss: 4.328855377157196
Validation loss: 3.644536349096891

Epoch: 19| Step: 0
Training loss: 4.1707160854468714
Validation loss: 3.642225203681859

Epoch: 6| Step: 1
Training loss: 3.9103358758145226
Validation loss: 3.6412780245057945

Epoch: 6| Step: 2
Training loss: 3.6508497477039588
Validation loss: 3.639882148133899

Epoch: 6| Step: 3
Training loss: 2.696682877399522
Validation loss: 3.6338895695581646

Epoch: 6| Step: 4
Training loss: 4.096902579790129
Validation loss: 3.6326320561479255

Epoch: 6| Step: 5
Training loss: 4.441538517709475
Validation loss: 3.6293156019413004

Epoch: 6| Step: 6
Training loss: 3.16894140022871
Validation loss: 3.6276903434260324

Epoch: 6| Step: 7
Training loss: 3.990193027425887
Validation loss: 3.626810547442765

Epoch: 6| Step: 8
Training loss: 4.219466537095183
Validation loss: 3.623859847145775

Epoch: 6| Step: 9
Training loss: 4.869951225835491
Validation loss: 3.62338267149662

Epoch: 6| Step: 10
Training loss: 3.323047184946941
Validation loss: 3.6226367212902613

Epoch: 6| Step: 11
Training loss: 3.653775282415722
Validation loss: 3.6209226130374113

Epoch: 6| Step: 12
Training loss: 2.970667490848904
Validation loss: 3.615910162831755

Epoch: 6| Step: 13
Training loss: 3.6889736011333016
Validation loss: 3.6163370312734595

Epoch: 20| Step: 0
Training loss: 3.543655076681453
Validation loss: 3.6144965126131385

Epoch: 6| Step: 1
Training loss: 3.7784043630803765
Validation loss: 3.612581522469144

Epoch: 6| Step: 2
Training loss: 3.492531437332995
Validation loss: 3.6124509970234704

Epoch: 6| Step: 3
Training loss: 2.2948354372019555
Validation loss: 3.611514397801932

Epoch: 6| Step: 4
Training loss: 3.3497007663370506
Validation loss: 3.6078977906891403

Epoch: 6| Step: 5
Training loss: 3.702370482245824
Validation loss: 3.6064601791803725

Epoch: 6| Step: 6
Training loss: 3.4445453922970337
Validation loss: 3.604721094028598

Epoch: 6| Step: 7
Training loss: 3.331205276847493
Validation loss: 3.6050359865546637

Epoch: 6| Step: 8
Training loss: 3.8915641907317857
Validation loss: 3.60262343266132

Epoch: 6| Step: 9
Training loss: 4.104248562429794
Validation loss: 3.6006832603548578

Epoch: 6| Step: 10
Training loss: 4.68722635106188
Validation loss: 3.605075900504362

Epoch: 6| Step: 11
Training loss: 4.234380405324041
Validation loss: 3.60525408421855

Epoch: 6| Step: 12
Training loss: 4.390358261748568
Validation loss: 3.6026823458607695

Epoch: 6| Step: 13
Training loss: 4.74827966154719
Validation loss: 3.596226449309808

Epoch: 21| Step: 0
Training loss: 3.6150053952336445
Validation loss: 3.5974455035484523

Epoch: 6| Step: 1
Training loss: 3.7413670669833006
Validation loss: 3.5963034098920863

Epoch: 6| Step: 2
Training loss: 4.1544674370692745
Validation loss: 3.591911706778007

Epoch: 6| Step: 3
Training loss: 4.405288916129146
Validation loss: 3.5911570450105375

Epoch: 6| Step: 4
Training loss: 3.3618858712526403
Validation loss: 3.590271669729346

Epoch: 6| Step: 5
Training loss: 3.5541795975575483
Validation loss: 3.5891688412721114

Epoch: 6| Step: 6
Training loss: 3.0289253680964223
Validation loss: 3.588959169351034

Epoch: 6| Step: 7
Training loss: 3.755063643646333
Validation loss: 3.585474379590415

Epoch: 6| Step: 8
Training loss: 3.177584165693478
Validation loss: 3.5830743476204883

Epoch: 6| Step: 9
Training loss: 3.386466715409321
Validation loss: 3.582211162530863

Epoch: 6| Step: 10
Training loss: 4.056640625
Validation loss: 3.5799588841022567

Epoch: 6| Step: 11
Training loss: 4.5093756598394785
Validation loss: 3.581414333923239

Epoch: 6| Step: 12
Training loss: 3.658811535931955
Validation loss: 3.5803313194447877

Epoch: 6| Step: 13
Training loss: 4.5701463978897365
Validation loss: 3.5802469781833355

Epoch: 22| Step: 0
Training loss: 3.9022285207665237
Validation loss: 3.5805524885007696

Epoch: 6| Step: 1
Training loss: 3.6289761539620775
Validation loss: 3.579482614898781

Epoch: 6| Step: 2
Training loss: 4.567897582474306
Validation loss: 3.5742947241369047

Epoch: 6| Step: 3
Training loss: 3.140682694393885
Validation loss: 3.574813675451244

Epoch: 6| Step: 4
Training loss: 3.571963940411712
Validation loss: 3.573188337788355

Epoch: 6| Step: 5
Training loss: 4.2016694338672265
Validation loss: 3.568919736120348

Epoch: 6| Step: 6
Training loss: 3.78817682041661
Validation loss: 3.5726420892772195

Epoch: 6| Step: 7
Training loss: 3.848588085132447
Validation loss: 3.5703087920200636

Epoch: 6| Step: 8
Training loss: 3.344603242480246
Validation loss: 3.569024242109724

Epoch: 6| Step: 9
Training loss: 4.08226860852976
Validation loss: 3.5704414784360208

Epoch: 6| Step: 10
Training loss: 3.3333109537009147
Validation loss: 3.5652034470674745

Epoch: 6| Step: 11
Training loss: 3.675624280571766
Validation loss: 3.5662351801159655

Epoch: 6| Step: 12
Training loss: 3.841139488430494
Validation loss: 3.5632447315444353

Epoch: 6| Step: 13
Training loss: 3.5710581996152153
Validation loss: 3.5669390704240915

Epoch: 23| Step: 0
Training loss: 2.330167757470286
Validation loss: 3.5699807742187035

Epoch: 6| Step: 1
Training loss: 2.548860302718342
Validation loss: 3.574355557367117

Epoch: 6| Step: 2
Training loss: 3.887212888657894
Validation loss: 3.573306442196137

Epoch: 6| Step: 3
Training loss: 4.763468870597597
Validation loss: 3.5629159640987558

Epoch: 6| Step: 4
Training loss: 4.280326799412123
Validation loss: 3.560109029671677

Epoch: 6| Step: 5
Training loss: 4.642273683881067
Validation loss: 3.558703021300992

Epoch: 6| Step: 6
Training loss: 3.2387487352457818
Validation loss: 3.5622449350717806

Epoch: 6| Step: 7
Training loss: 3.518958922666484
Validation loss: 3.5606568538728705

Epoch: 6| Step: 8
Training loss: 4.128401769677341
Validation loss: 3.565803779122768

Epoch: 6| Step: 9
Training loss: 3.3765736902308356
Validation loss: 3.5600312736790287

Epoch: 6| Step: 10
Training loss: 2.9680529930648327
Validation loss: 3.5595518476901167

Epoch: 6| Step: 11
Training loss: 4.362280530245682
Validation loss: 3.5612073595802496

Epoch: 6| Step: 12
Training loss: 3.8856797252849127
Validation loss: 3.559301812144793

Epoch: 6| Step: 13
Training loss: 3.8893087221015805
Validation loss: 3.5593660808134104

Epoch: 24| Step: 0
Training loss: 3.8397953189500433
Validation loss: 3.564538514579194

Epoch: 6| Step: 1
Training loss: 3.1450426905998907
Validation loss: 3.5645795637949043

Epoch: 6| Step: 2
Training loss: 4.191630589435454
Validation loss: 3.564143491324858

Epoch: 6| Step: 3
Training loss: 4.045847169411779
Validation loss: 3.561413481068794

Epoch: 6| Step: 4
Training loss: 4.132198641497402
Validation loss: 3.5617001694741637

Epoch: 6| Step: 5
Training loss: 4.344240668597256
Validation loss: 3.561237191267159

Epoch: 6| Step: 6
Training loss: 3.8038196239687094
Validation loss: 3.560562278928397

Epoch: 6| Step: 7
Training loss: 3.6848876234127106
Validation loss: 3.5610814676849203

Epoch: 6| Step: 8
Training loss: 3.4877232087053573
Validation loss: 3.5579479461761365

Epoch: 6| Step: 9
Training loss: 3.079031099286913
Validation loss: 3.5587397103823064

Epoch: 6| Step: 10
Training loss: 3.8559783938819563
Validation loss: 3.555688524569182

Epoch: 6| Step: 11
Training loss: 3.710320158354294
Validation loss: 3.553310153678331

Epoch: 6| Step: 12
Training loss: 3.242838966457929
Validation loss: 3.5530104153408484

Epoch: 6| Step: 13
Training loss: 3.966348717606434
Validation loss: 3.551890514898451

Epoch: 25| Step: 0
Training loss: 4.375686155735589
Validation loss: 3.5477519636872845

Epoch: 6| Step: 1
Training loss: 3.4742281159398436
Validation loss: 3.5476418550201196

Epoch: 6| Step: 2
Training loss: 3.1437515713818605
Validation loss: 3.545821299666916

Epoch: 6| Step: 3
Training loss: 3.7200351065342994
Validation loss: 3.545332965491581

Epoch: 6| Step: 4
Training loss: 4.012054399602664
Validation loss: 3.542170564151868

Epoch: 6| Step: 5
Training loss: 3.8158821987786853
Validation loss: 3.5430681750343793

Epoch: 6| Step: 6
Training loss: 3.694040736908891
Validation loss: 3.5411837794529095

Epoch: 6| Step: 7
Training loss: 3.654876711914764
Validation loss: 3.540489624182201

Epoch: 6| Step: 8
Training loss: 4.028342921338069
Validation loss: 3.5402594292622585

Epoch: 6| Step: 9
Training loss: 4.464765786652541
Validation loss: 3.5396966617526546

Epoch: 6| Step: 10
Training loss: 3.4377052939407533
Validation loss: 3.5370093635272486

Epoch: 6| Step: 11
Training loss: 3.317627878376338
Validation loss: 3.538695142854863

Epoch: 6| Step: 12
Training loss: 3.3464799236411826
Validation loss: 3.5349994819330806

Epoch: 6| Step: 13
Training loss: 3.760601951423248
Validation loss: 3.5369218480882787

Epoch: 26| Step: 0
Training loss: 3.725631245628821
Validation loss: 3.53521143321155

Epoch: 6| Step: 1
Training loss: 4.410903529469791
Validation loss: 3.5340203502098424

Epoch: 6| Step: 2
Training loss: 3.9925462893750816
Validation loss: 3.5349961016964566

Epoch: 6| Step: 3
Training loss: 3.7248902477506753
Validation loss: 3.5320047800083327

Epoch: 6| Step: 4
Training loss: 3.186884801998801
Validation loss: 3.5312287866040712

Epoch: 6| Step: 5
Training loss: 3.692690025610617
Validation loss: 3.531235253726778

Epoch: 6| Step: 6
Training loss: 3.774362896847574
Validation loss: 3.5298270290474

Epoch: 6| Step: 7
Training loss: 4.062258903978685
Validation loss: 3.5283547003622084

Epoch: 6| Step: 8
Training loss: 4.430579147887255
Validation loss: 3.528554406071609

Epoch: 6| Step: 9
Training loss: 3.022554017145113
Validation loss: 3.52768325248388

Epoch: 6| Step: 10
Training loss: 2.5858346048496017
Validation loss: 3.5261926832992523

Epoch: 6| Step: 11
Training loss: 4.532939096212918
Validation loss: 3.5251351759897647

Epoch: 6| Step: 12
Training loss: 2.9835229426250307
Validation loss: 3.5247827902113116

Epoch: 6| Step: 13
Training loss: 3.5188389985397235
Validation loss: 3.5229273495590054

Epoch: 27| Step: 0
Training loss: 3.7232638620733147
Validation loss: 3.523580287911102

Epoch: 6| Step: 1
Training loss: 2.872881067031
Validation loss: 3.5238696774310094

Epoch: 6| Step: 2
Training loss: 3.9769303726880842
Validation loss: 3.5194726654356185

Epoch: 6| Step: 3
Training loss: 3.1836869115011712
Validation loss: 3.515196148273534

Epoch: 6| Step: 4
Training loss: 4.077421514994188
Validation loss: 3.5157262323131375

Epoch: 6| Step: 5
Training loss: 3.576467204959645
Validation loss: 3.5161117832889315

Epoch: 6| Step: 6
Training loss: 3.5219422950848056
Validation loss: 3.5144415778015303

Epoch: 6| Step: 7
Training loss: 4.2191867178472435
Validation loss: 3.513286285392039

Epoch: 6| Step: 8
Training loss: 4.0210245248406675
Validation loss: 3.514187372611347

Epoch: 6| Step: 9
Training loss: 3.6931076085030883
Validation loss: 3.510747396939414

Epoch: 6| Step: 10
Training loss: 3.438101975877563
Validation loss: 3.5087568223954

Epoch: 6| Step: 11
Training loss: 4.430503379862677
Validation loss: 3.5065325789414965

Epoch: 6| Step: 12
Training loss: 3.151905809350601
Validation loss: 3.506691438433105

Epoch: 6| Step: 13
Training loss: 4.07390320416361
Validation loss: 3.5056464622904646

Epoch: 28| Step: 0
Training loss: 3.991262310043739
Validation loss: 3.5052193093854447

Epoch: 6| Step: 1
Training loss: 3.973677692361447
Validation loss: 3.5035287966510964

Epoch: 6| Step: 2
Training loss: 3.535086649004066
Validation loss: 3.5011412932260715

Epoch: 6| Step: 3
Training loss: 4.027095102502498
Validation loss: 3.50310021461453

Epoch: 6| Step: 4
Training loss: 3.213606344815886
Validation loss: 3.4995063867282554

Epoch: 6| Step: 5
Training loss: 3.5219964508264043
Validation loss: 3.499882519562448

Epoch: 6| Step: 6
Training loss: 3.51602699524603
Validation loss: 3.5000565300168986

Epoch: 6| Step: 7
Training loss: 2.5950786450767347
Validation loss: 3.498000990690462

Epoch: 6| Step: 8
Training loss: 3.5047297535975512
Validation loss: 3.4969499778889226

Epoch: 6| Step: 9
Training loss: 4.222536097677722
Validation loss: 3.4969095555679757

Epoch: 6| Step: 10
Training loss: 4.284337621925071
Validation loss: 3.49716666019026

Epoch: 6| Step: 11
Training loss: 3.9805654227634424
Validation loss: 3.495677737312505

Epoch: 6| Step: 12
Training loss: 3.4993737886715954
Validation loss: 3.496494795473191

Epoch: 6| Step: 13
Training loss: 3.7900250972027556
Validation loss: 3.495307909297503

Epoch: 29| Step: 0
Training loss: 3.423766567027192
Validation loss: 3.4951898068584812

Epoch: 6| Step: 1
Training loss: 3.414095042617
Validation loss: 3.4940479167468657

Epoch: 6| Step: 2
Training loss: 2.7909587323080896
Validation loss: 3.4928745804135177

Epoch: 6| Step: 3
Training loss: 3.8509924662161463
Validation loss: 3.4913729715927766

Epoch: 6| Step: 4
Training loss: 3.9920589777196174
Validation loss: 3.491798935898713

Epoch: 6| Step: 5
Training loss: 3.7382427281355084
Validation loss: 3.4911780239796566

Epoch: 6| Step: 6
Training loss: 3.395691913554194
Validation loss: 3.48993749656409

Epoch: 6| Step: 7
Training loss: 4.435492262846316
Validation loss: 3.4907085712349577

Epoch: 6| Step: 8
Training loss: 4.3010610823756235
Validation loss: 3.487617133923438

Epoch: 6| Step: 9
Training loss: 4.236144874869002
Validation loss: 3.491487476065051

Epoch: 6| Step: 10
Training loss: 2.364719123694411
Validation loss: 3.4941758584216376

Epoch: 6| Step: 11
Training loss: 3.7606571081894686
Validation loss: 3.498107594858273

Epoch: 6| Step: 12
Training loss: 3.905109452632043
Validation loss: 3.4965648508560503

Epoch: 6| Step: 13
Training loss: 3.634331367211077
Validation loss: 3.483522532802875

Epoch: 30| Step: 0
Training loss: 3.891157121539406
Validation loss: 3.4814226454074975

Epoch: 6| Step: 1
Training loss: 4.0934531999696535
Validation loss: 3.481770134826517

Epoch: 6| Step: 2
Training loss: 3.877468922316499
Validation loss: 3.4797184043496316

Epoch: 6| Step: 3
Training loss: 3.6207700582637576
Validation loss: 3.480563846958837

Epoch: 6| Step: 4
Training loss: 2.8822224331008233
Validation loss: 3.480498378032722

Epoch: 6| Step: 5
Training loss: 3.474360696729193
Validation loss: 3.4814547616192706

Epoch: 6| Step: 6
Training loss: 3.9500056689257925
Validation loss: 3.4803530152900723

Epoch: 6| Step: 7
Training loss: 3.3255112104443456
Validation loss: 3.4774184855066346

Epoch: 6| Step: 8
Training loss: 3.2232152095743536
Validation loss: 3.468894426317016

Epoch: 6| Step: 9
Training loss: 3.232214754504762
Validation loss: 3.457265653241927

Epoch: 6| Step: 10
Training loss: 3.999122881089577
Validation loss: 3.448622889448769

Epoch: 6| Step: 11
Training loss: 3.7382358400781674
Validation loss: 3.4540398745830054

Epoch: 6| Step: 12
Training loss: 3.8974939706693337
Validation loss: 3.4547220691697382

Epoch: 6| Step: 13
Training loss: 4.430127749355582
Validation loss: 3.445138996432053

Epoch: 31| Step: 0
Training loss: 3.7414351246536652
Validation loss: 3.4414209670000924

Epoch: 6| Step: 1
Training loss: 3.598947233338451
Validation loss: 3.4403206284085863

Epoch: 6| Step: 2
Training loss: 3.51162804474765
Validation loss: 3.440579477533046

Epoch: 6| Step: 3
Training loss: 2.6822877951782336
Validation loss: 3.440052353488465

Epoch: 6| Step: 4
Training loss: 3.9903674969381098
Validation loss: 3.4411384217850984

Epoch: 6| Step: 5
Training loss: 3.6035812578711304
Validation loss: 3.4379461630962083

Epoch: 6| Step: 6
Training loss: 3.0237519645290294
Validation loss: 3.4403093225961827

Epoch: 6| Step: 7
Training loss: 3.759670757731715
Validation loss: 3.4465408105622894

Epoch: 6| Step: 8
Training loss: 4.226395750017573
Validation loss: 3.4490688096605844

Epoch: 6| Step: 9
Training loss: 4.490182976679514
Validation loss: 3.4331348584833923

Epoch: 6| Step: 10
Training loss: 3.6209690438764355
Validation loss: 3.4312134490627284

Epoch: 6| Step: 11
Training loss: 3.7766075955445912
Validation loss: 3.4321438942123574

Epoch: 6| Step: 12
Training loss: 3.6650611801557513
Validation loss: 3.434611062449438

Epoch: 6| Step: 13
Training loss: 2.6614512961656036
Validation loss: 3.432735757905656

Epoch: 32| Step: 0
Training loss: 4.061166867350182
Validation loss: 3.4348441177312896

Epoch: 6| Step: 1
Training loss: 3.8556087510992003
Validation loss: 3.4295955446333397

Epoch: 6| Step: 2
Training loss: 2.7675102403239364
Validation loss: 3.425937816590985

Epoch: 6| Step: 3
Training loss: 2.9440361515603604
Validation loss: 3.4279731432904574

Epoch: 6| Step: 4
Training loss: 4.433183316630123
Validation loss: 3.423520280635043

Epoch: 6| Step: 5
Training loss: 3.0899187505712566
Validation loss: 3.424117442830626

Epoch: 6| Step: 6
Training loss: 4.137573960671796
Validation loss: 3.423615487275813

Epoch: 6| Step: 7
Training loss: 3.7594315496870303
Validation loss: 3.422801064530458

Epoch: 6| Step: 8
Training loss: 4.180732382537124
Validation loss: 3.422074024501436

Epoch: 6| Step: 9
Training loss: 3.410644636106387
Validation loss: 3.4204985117807643

Epoch: 6| Step: 10
Training loss: 3.2804233054574348
Validation loss: 3.4203424981993744

Epoch: 6| Step: 11
Training loss: 3.657540900418261
Validation loss: 3.4210205959347757

Epoch: 6| Step: 12
Training loss: 3.032565116717824
Validation loss: 3.4197420784986625

Epoch: 6| Step: 13
Training loss: 4.210635144307975
Validation loss: 3.4168560811944104

Epoch: 33| Step: 0
Training loss: 3.491278545018465
Validation loss: 3.419404371902741

Epoch: 6| Step: 1
Training loss: 3.4758175169582546
Validation loss: 3.421389442824355

Epoch: 6| Step: 2
Training loss: 4.091798506488338
Validation loss: 3.4197297765713444

Epoch: 6| Step: 3
Training loss: 3.9573337028876834
Validation loss: 3.4189082735107212

Epoch: 6| Step: 4
Training loss: 3.5827154173842626
Validation loss: 3.4179753324149367

Epoch: 6| Step: 5
Training loss: 3.2911993411258673
Validation loss: 3.4165013501150354

Epoch: 6| Step: 6
Training loss: 3.7844766768539304
Validation loss: 3.4162373461888826

Epoch: 6| Step: 7
Training loss: 2.8624507849847762
Validation loss: 3.4141489237021947

Epoch: 6| Step: 8
Training loss: 3.176953389162967
Validation loss: 3.41565774587176

Epoch: 6| Step: 9
Training loss: 4.078997405413985
Validation loss: 3.4129178940679

Epoch: 6| Step: 10
Training loss: 4.125422600570853
Validation loss: 3.4143293068153855

Epoch: 6| Step: 11
Training loss: 3.650955932016887
Validation loss: 3.41298481558179

Epoch: 6| Step: 12
Training loss: 3.718573686282812
Validation loss: 3.4112910591878536

Epoch: 6| Step: 13
Training loss: 3.2845353890410123
Validation loss: 3.412161610484764

Epoch: 34| Step: 0
Training loss: 3.683188552657698
Validation loss: 3.412149472064458

Epoch: 6| Step: 1
Training loss: 3.698947143251292
Validation loss: 3.4104882995450083

Epoch: 6| Step: 2
Training loss: 4.162507129926561
Validation loss: 3.4109562821054547

Epoch: 6| Step: 3
Training loss: 3.8368700684675585
Validation loss: 3.4110098460010763

Epoch: 6| Step: 4
Training loss: 3.643828852799771
Validation loss: 3.4108761180771228

Epoch: 6| Step: 5
Training loss: 4.190764563822994
Validation loss: 3.4099006436285397

Epoch: 6| Step: 6
Training loss: 3.1213068692393016
Validation loss: 3.4111807761543327

Epoch: 6| Step: 7
Training loss: 2.257125802863813
Validation loss: 3.4083341732746693

Epoch: 6| Step: 8
Training loss: 3.125951393262075
Validation loss: 3.410215285698584

Epoch: 6| Step: 9
Training loss: 4.56931037023329
Validation loss: 3.408819789627432

Epoch: 6| Step: 10
Training loss: 3.298159959068175
Validation loss: 3.4077324555387682

Epoch: 6| Step: 11
Training loss: 3.75207296931678
Validation loss: 3.4072832202122316

Epoch: 6| Step: 12
Training loss: 3.2139419644331833
Validation loss: 3.4043818100992667

Epoch: 6| Step: 13
Training loss: 3.841893437795735
Validation loss: 3.4058699194938282

Epoch: 35| Step: 0
Training loss: 3.517947095532816
Validation loss: 3.404584441500392

Epoch: 6| Step: 1
Training loss: 4.117455721665146
Validation loss: 3.4039222279990944

Epoch: 6| Step: 2
Training loss: 3.69838066234678
Validation loss: 3.4035862704213664

Epoch: 6| Step: 3
Training loss: 4.398743640822431
Validation loss: 3.403849517278614

Epoch: 6| Step: 4
Training loss: 4.524467706722505
Validation loss: 3.4027022699870364

Epoch: 6| Step: 5
Training loss: 4.397661428606051
Validation loss: 3.402466193348543

Epoch: 6| Step: 6
Training loss: 3.181334422851828
Validation loss: 3.4030928109247283

Epoch: 6| Step: 7
Training loss: 2.9484247818891376
Validation loss: 3.4046485013336376

Epoch: 6| Step: 8
Training loss: 3.5966360693883113
Validation loss: 3.406339809968182

Epoch: 6| Step: 9
Training loss: 2.286846872278189
Validation loss: 3.400896866271619

Epoch: 6| Step: 10
Training loss: 3.3354852088368103
Validation loss: 3.3992670649960024

Epoch: 6| Step: 11
Training loss: 2.801345066157952
Validation loss: 3.397786166592097

Epoch: 6| Step: 12
Training loss: 2.9418184718513283
Validation loss: 3.3975878698120208

Epoch: 6| Step: 13
Training loss: 4.596592860377376
Validation loss: 3.39802709658443

Epoch: 36| Step: 0
Training loss: 3.656234741179097
Validation loss: 3.3959615474201255

Epoch: 6| Step: 1
Training loss: 3.50606175425622
Validation loss: 3.3972433758660876

Epoch: 6| Step: 2
Training loss: 3.457915560448716
Validation loss: 3.3967294049894647

Epoch: 6| Step: 3
Training loss: 4.049644906760296
Validation loss: 3.3967854060847578

Epoch: 6| Step: 4
Training loss: 3.259244535473919
Validation loss: 3.395641860279679

Epoch: 6| Step: 5
Training loss: 3.1787974918611432
Validation loss: 3.3945379216661156

Epoch: 6| Step: 6
Training loss: 3.716915800243674
Validation loss: 3.395710253200938

Epoch: 6| Step: 7
Training loss: 3.550003889914517
Validation loss: 3.3949967564347094

Epoch: 6| Step: 8
Training loss: 4.188195242031582
Validation loss: 3.395758099492926

Epoch: 6| Step: 9
Training loss: 2.9651155410049013
Validation loss: 3.394965824939446

Epoch: 6| Step: 10
Training loss: 3.3537101355937105
Validation loss: 3.3953870405435356

Epoch: 6| Step: 11
Training loss: 4.18709915292273
Validation loss: 3.395358996867639

Epoch: 6| Step: 12
Training loss: 3.7239387280497183
Validation loss: 3.3943376602405793

Epoch: 6| Step: 13
Training loss: 3.7556401117826717
Validation loss: 3.3981884303209635

Epoch: 37| Step: 0
Training loss: 4.177251772762431
Validation loss: 3.3972286712353004

Epoch: 6| Step: 1
Training loss: 2.722441961757484
Validation loss: 3.394203145539125

Epoch: 6| Step: 2
Training loss: 4.351615535611503
Validation loss: 3.393472332525012

Epoch: 6| Step: 3
Training loss: 3.7919402530325237
Validation loss: 3.3926586881373644

Epoch: 6| Step: 4
Training loss: 3.9911982734690206
Validation loss: 3.392230368384168

Epoch: 6| Step: 5
Training loss: 3.4798062739765756
Validation loss: 3.3910404013425457

Epoch: 6| Step: 6
Training loss: 3.206565981161237
Validation loss: 3.390461104501377

Epoch: 6| Step: 7
Training loss: 3.6961541215460927
Validation loss: 3.392165129347236

Epoch: 6| Step: 8
Training loss: 3.153963526067968
Validation loss: 3.390004647502496

Epoch: 6| Step: 9
Training loss: 3.5544173253267557
Validation loss: 3.391218278407073

Epoch: 6| Step: 10
Training loss: 2.5138840426497233
Validation loss: 3.3898870750990926

Epoch: 6| Step: 11
Training loss: 3.4139474111751533
Validation loss: 3.388830542643493

Epoch: 6| Step: 12
Training loss: 4.0414913703159
Validation loss: 3.389115948677006

Epoch: 6| Step: 13
Training loss: 4.322956180008924
Validation loss: 3.3882709495441605

Epoch: 38| Step: 0
Training loss: 4.46841728198939
Validation loss: 3.389154490254489

Epoch: 6| Step: 1
Training loss: 4.277321231033759
Validation loss: 3.3886819066070024

Epoch: 6| Step: 2
Training loss: 3.7379416826739402
Validation loss: 3.38728905985074

Epoch: 6| Step: 3
Training loss: 3.548923791363277
Validation loss: 3.387986320572109

Epoch: 6| Step: 4
Training loss: 3.7201172695339153
Validation loss: 3.385578263104259

Epoch: 6| Step: 5
Training loss: 3.7013828992447255
Validation loss: 3.387537381011679

Epoch: 6| Step: 6
Training loss: 3.4066790389292305
Validation loss: 3.388003566907577

Epoch: 6| Step: 7
Training loss: 3.22226974481492
Validation loss: 3.3866016009868396

Epoch: 6| Step: 8
Training loss: 2.327965442899125
Validation loss: 3.3857305941869837

Epoch: 6| Step: 9
Training loss: 3.22304330062067
Validation loss: 3.3850243827523427

Epoch: 6| Step: 10
Training loss: 3.1551100683584767
Validation loss: 3.385883462811246

Epoch: 6| Step: 11
Training loss: 3.3137976066194383
Validation loss: 3.387125355638507

Epoch: 6| Step: 12
Training loss: 4.054904351288166
Validation loss: 3.3851196284961103

Epoch: 6| Step: 13
Training loss: 4.14214230933301
Validation loss: 3.385090263792923

Epoch: 39| Step: 0
Training loss: 3.8034284885905594
Validation loss: 3.3851586396714817

Epoch: 6| Step: 1
Training loss: 3.587943519530487
Validation loss: 3.3838775957958935

Epoch: 6| Step: 2
Training loss: 4.318265737055801
Validation loss: 3.383979873877814

Epoch: 6| Step: 3
Training loss: 3.8086273035380946
Validation loss: 3.383480474134763

Epoch: 6| Step: 4
Training loss: 2.3083927693157418
Validation loss: 3.383126785610875

Epoch: 6| Step: 5
Training loss: 3.69784517174321
Validation loss: 3.382865756236905

Epoch: 6| Step: 6
Training loss: 2.832000269227096
Validation loss: 3.3834945391670774

Epoch: 6| Step: 7
Training loss: 3.7739829859751852
Validation loss: 3.3828299364058685

Epoch: 6| Step: 8
Training loss: 3.8285549623017343
Validation loss: 3.3831053208773283

Epoch: 6| Step: 9
Training loss: 3.768700953934656
Validation loss: 3.383454571530948

Epoch: 6| Step: 10
Training loss: 3.957278756989765
Validation loss: 3.3817880685908404

Epoch: 6| Step: 11
Training loss: 2.8555529121488945
Validation loss: 3.382273112288861

Epoch: 6| Step: 12
Training loss: 3.814404996616176
Validation loss: 3.381938627540595

Epoch: 6| Step: 13
Training loss: 3.7512080471968616
Validation loss: 3.3806262699399534

Epoch: 40| Step: 0
Training loss: 3.5824076913360043
Validation loss: 3.380521298332556

Epoch: 6| Step: 1
Training loss: 3.706212812626332
Validation loss: 3.379806011999751

Epoch: 6| Step: 2
Training loss: 3.644710622218773
Validation loss: 3.382382293698438

Epoch: 6| Step: 3
Training loss: 4.065863522709873
Validation loss: 3.388775940509064

Epoch: 6| Step: 4
Training loss: 3.5820581399788134
Validation loss: 3.394967697661397

Epoch: 6| Step: 5
Training loss: 4.075655485453646
Validation loss: 3.388321683701716

Epoch: 6| Step: 6
Training loss: 3.117605233943893
Validation loss: 3.414345426722381

Epoch: 6| Step: 7
Training loss: 3.425168198959302
Validation loss: 3.399391836356782

Epoch: 6| Step: 8
Training loss: 2.9474587955458222
Validation loss: 3.3792723424716113

Epoch: 6| Step: 9
Training loss: 3.6249701400053183
Validation loss: 3.3789594964853698

Epoch: 6| Step: 10
Training loss: 3.2524372645433206
Validation loss: 3.3774595030478753

Epoch: 6| Step: 11
Training loss: 4.21552973159587
Validation loss: 3.3784760228230355

Epoch: 6| Step: 12
Training loss: 3.2596720047221224
Validation loss: 3.3786523973396236

Epoch: 6| Step: 13
Training loss: 3.932899087976458
Validation loss: 3.378135063655218

Epoch: 41| Step: 0
Training loss: 3.399418691419931
Validation loss: 3.3771936616866127

Epoch: 6| Step: 1
Training loss: 3.759954971896078
Validation loss: 3.3758770294240765

Epoch: 6| Step: 2
Training loss: 3.2925941190830095
Validation loss: 3.374935916731287

Epoch: 6| Step: 3
Training loss: 3.914331362202561
Validation loss: 3.375847699754223

Epoch: 6| Step: 4
Training loss: 3.2506283372752978
Validation loss: 3.3743087200368005

Epoch: 6| Step: 5
Training loss: 2.2426361804724073
Validation loss: 3.37502686532774

Epoch: 6| Step: 6
Training loss: 3.704919050518977
Validation loss: 3.375112050884233

Epoch: 6| Step: 7
Training loss: 3.997796763175407
Validation loss: 3.3762676375718854

Epoch: 6| Step: 8
Training loss: 3.6952568840374114
Validation loss: 3.375625772621221

Epoch: 6| Step: 9
Training loss: 4.669720104905036
Validation loss: 3.375677828400106

Epoch: 6| Step: 10
Training loss: 3.097260304337087
Validation loss: 3.3757891414122816

Epoch: 6| Step: 11
Training loss: 3.812554405949853
Validation loss: 3.373494915972634

Epoch: 6| Step: 12
Training loss: 3.5885773958255487
Validation loss: 3.3740753204505713

Epoch: 6| Step: 13
Training loss: 3.4741788429076768
Validation loss: 3.3751312634439037

Epoch: 42| Step: 0
Training loss: 3.098693904761371
Validation loss: 3.374237156638358

Epoch: 6| Step: 1
Training loss: 4.260992755818381
Validation loss: 3.3730488723768066

Epoch: 6| Step: 2
Training loss: 3.7863601329020824
Validation loss: 3.3728089704496687

Epoch: 6| Step: 3
Training loss: 3.5651329082094882
Validation loss: 3.373421677094045

Epoch: 6| Step: 4
Training loss: 3.476442759305556
Validation loss: 3.3730939544071874

Epoch: 6| Step: 5
Training loss: 3.864152306771403
Validation loss: 3.3725223387192558

Epoch: 6| Step: 6
Training loss: 2.6547770286942214
Validation loss: 3.372895706321308

Epoch: 6| Step: 7
Training loss: 4.025060826191452
Validation loss: 3.3713286563286586

Epoch: 6| Step: 8
Training loss: 3.999750487174889
Validation loss: 3.372377211313086

Epoch: 6| Step: 9
Training loss: 3.1663489098654853
Validation loss: 3.3713905497456937

Epoch: 6| Step: 10
Training loss: 3.196308456441315
Validation loss: 3.371260322376963

Epoch: 6| Step: 11
Training loss: 3.981010542394942
Validation loss: 3.370822639549267

Epoch: 6| Step: 12
Training loss: 3.2458397574273437
Validation loss: 3.3708852297715404

Epoch: 6| Step: 13
Training loss: 3.8544351570157036
Validation loss: 3.369703725180296

Epoch: 43| Step: 0
Training loss: 3.8287395373284596
Validation loss: 3.370181433900035

Epoch: 6| Step: 1
Training loss: 3.8223070426026333
Validation loss: 3.37093338583574

Epoch: 6| Step: 2
Training loss: 3.5639375162180995
Validation loss: 3.3750579020806035

Epoch: 6| Step: 3
Training loss: 3.6059761723531416
Validation loss: 3.369162029562773

Epoch: 6| Step: 4
Training loss: 3.8119816662246437
Validation loss: 3.3685419840495294

Epoch: 6| Step: 5
Training loss: 3.3088929312414934
Validation loss: 3.3691932801324036

Epoch: 6| Step: 6
Training loss: 4.023099481401853
Validation loss: 3.368657605116827

Epoch: 6| Step: 7
Training loss: 2.1031880384863197
Validation loss: 3.3671600239415027

Epoch: 6| Step: 8
Training loss: 3.483309595735942
Validation loss: 3.3693278452588555

Epoch: 6| Step: 9
Training loss: 3.180985319447272
Validation loss: 3.367356613522817

Epoch: 6| Step: 10
Training loss: 3.8980928012532767
Validation loss: 3.36713293367441

Epoch: 6| Step: 11
Training loss: 3.972405379784744
Validation loss: 3.366597298628659

Epoch: 6| Step: 12
Training loss: 3.646787740125987
Validation loss: 3.3682778295298985

Epoch: 6| Step: 13
Training loss: 3.7591379092472446
Validation loss: 3.366690135542209

Epoch: 44| Step: 0
Training loss: 3.682276242379883
Validation loss: 3.3654950503341188

Epoch: 6| Step: 1
Training loss: 3.8696721273710066
Validation loss: 3.367725709314546

Epoch: 6| Step: 2
Training loss: 3.542736714597216
Validation loss: 3.366634186675635

Epoch: 6| Step: 3
Training loss: 2.7242965245173503
Validation loss: 3.365481252102069

Epoch: 6| Step: 4
Training loss: 3.6860741913770454
Validation loss: 3.3671040021766214

Epoch: 6| Step: 5
Training loss: 4.113478319857715
Validation loss: 3.366382314645526

Epoch: 6| Step: 6
Training loss: 3.5743983155884353
Validation loss: 3.3666749532770814

Epoch: 6| Step: 7
Training loss: 3.0910447748767678
Validation loss: 3.3644132043791046

Epoch: 6| Step: 8
Training loss: 3.5439221698576144
Validation loss: 3.3634902401142974

Epoch: 6| Step: 9
Training loss: 4.380502346965194
Validation loss: 3.3617636351927054

Epoch: 6| Step: 10
Training loss: 3.8495749399937558
Validation loss: 3.364093613949716

Epoch: 6| Step: 11
Training loss: 3.3703097495968435
Validation loss: 3.3608469854351335

Epoch: 6| Step: 12
Training loss: 2.566412567177347
Validation loss: 3.3631442475879862

Epoch: 6| Step: 13
Training loss: 4.051797237282584
Validation loss: 3.3631820470661156

Epoch: 45| Step: 0
Training loss: 3.465752758701671
Validation loss: 3.3638472248846405

Epoch: 6| Step: 1
Training loss: 3.573338134344871
Validation loss: 3.365749674463649

Epoch: 6| Step: 2
Training loss: 3.2298976111939504
Validation loss: 3.3684372683110753

Epoch: 6| Step: 3
Training loss: 3.7307052137916115
Validation loss: 3.369348174282035

Epoch: 6| Step: 4
Training loss: 4.391892219749645
Validation loss: 3.3680571938607176

Epoch: 6| Step: 5
Training loss: 3.5891360974934576
Validation loss: 3.361152023628707

Epoch: 6| Step: 6
Training loss: 3.1675513353530937
Validation loss: 3.3620172822227015

Epoch: 6| Step: 7
Training loss: 2.8439770283046264
Validation loss: 3.364412423341878

Epoch: 6| Step: 8
Training loss: 3.6741284537164973
Validation loss: 3.366320720586345

Epoch: 6| Step: 9
Training loss: 4.085250534163099
Validation loss: 3.3801047665428667

Epoch: 6| Step: 10
Training loss: 2.677357987342917
Validation loss: 3.3880508788634236

Epoch: 6| Step: 11
Training loss: 3.535003557648548
Validation loss: 3.368382799101221

Epoch: 6| Step: 12
Training loss: 3.893461732924451
Validation loss: 3.3600339074970487

Epoch: 6| Step: 13
Training loss: 4.4126730563454695
Validation loss: 3.361577346557677

Epoch: 46| Step: 0
Training loss: 4.436997935946528
Validation loss: 3.3575619803019174

Epoch: 6| Step: 1
Training loss: 3.590593228643638
Validation loss: 3.354715228421209

Epoch: 6| Step: 2
Training loss: 3.8875969436186044
Validation loss: 3.358081132139756

Epoch: 6| Step: 3
Training loss: 3.196722414434242
Validation loss: 3.3582762531337718

Epoch: 6| Step: 4
Training loss: 3.9973050814421875
Validation loss: 3.357542725236693

Epoch: 6| Step: 5
Training loss: 3.877044630532214
Validation loss: 3.357297051209372

Epoch: 6| Step: 6
Training loss: 3.6080338269358667
Validation loss: 3.3577108982918746

Epoch: 6| Step: 7
Training loss: 4.015019590109114
Validation loss: 3.3575116243088585

Epoch: 6| Step: 8
Training loss: 3.6818936936398163
Validation loss: 3.357337108033696

Epoch: 6| Step: 9
Training loss: 2.529218447143137
Validation loss: 3.351878170766295

Epoch: 6| Step: 10
Training loss: 3.5956389397109416
Validation loss: 3.353123468172524

Epoch: 6| Step: 11
Training loss: 3.3661044120256713
Validation loss: 3.3509418503679247

Epoch: 6| Step: 12
Training loss: 2.201091395940312
Validation loss: 3.348678318930872

Epoch: 6| Step: 13
Training loss: 3.657328259183521
Validation loss: 3.3488164467331045

Epoch: 47| Step: 0
Training loss: 4.040216218431237
Validation loss: 3.3461918824040358

Epoch: 6| Step: 1
Training loss: 2.8030353238359953
Validation loss: 3.34689059973654

Epoch: 6| Step: 2
Training loss: 3.142416675467443
Validation loss: 3.345693401289998

Epoch: 6| Step: 3
Training loss: 3.999842163786601
Validation loss: 3.3487874526848187

Epoch: 6| Step: 4
Training loss: 3.481969165312708
Validation loss: 3.349291506411689

Epoch: 6| Step: 5
Training loss: 3.617063318349597
Validation loss: 3.3497658405433257

Epoch: 6| Step: 6
Training loss: 3.410906487401245
Validation loss: 3.3383869276510567

Epoch: 6| Step: 7
Training loss: 3.2216591142018918
Validation loss: 3.337030810905989

Epoch: 6| Step: 8
Training loss: 4.466492195897217
Validation loss: 3.335843419906434

Epoch: 6| Step: 9
Training loss: 2.6711946033808283
Validation loss: 3.334929272365572

Epoch: 6| Step: 10
Training loss: 3.7781758067561935
Validation loss: 3.3356260833624423

Epoch: 6| Step: 11
Training loss: 3.4785246723106655
Validation loss: 3.3340566885978395

Epoch: 6| Step: 12
Training loss: 3.7822050039325554
Validation loss: 3.33511208840449

Epoch: 6| Step: 13
Training loss: 3.822667431654209
Validation loss: 3.335386933165516

Epoch: 48| Step: 0
Training loss: 3.6466082085544613
Validation loss: 3.3349431685628916

Epoch: 6| Step: 1
Training loss: 4.036701154070659
Validation loss: 3.333138296102419

Epoch: 6| Step: 2
Training loss: 4.774429343111924
Validation loss: 3.331849711455239

Epoch: 6| Step: 3
Training loss: 3.06106502623656
Validation loss: 3.3330453691895547

Epoch: 6| Step: 4
Training loss: 3.1818577813495788
Validation loss: 3.3313330129470797

Epoch: 6| Step: 5
Training loss: 2.9354796259138425
Validation loss: 3.3332954409711815

Epoch: 6| Step: 6
Training loss: 3.5830153982186665
Validation loss: 3.331480537799134

Epoch: 6| Step: 7
Training loss: 4.120866959103255
Validation loss: 3.331849514479961

Epoch: 6| Step: 8
Training loss: 3.454886009003058
Validation loss: 3.3307652722805705

Epoch: 6| Step: 9
Training loss: 3.087648173494858
Validation loss: 3.32968597263477

Epoch: 6| Step: 10
Training loss: 3.8038339146920603
Validation loss: 3.3311889585588674

Epoch: 6| Step: 11
Training loss: 3.4565099635665546
Validation loss: 3.3296739570127944

Epoch: 6| Step: 12
Training loss: 2.7749498998569884
Validation loss: 3.329494221045963

Epoch: 6| Step: 13
Training loss: 3.3428430485923166
Validation loss: 3.3284581570467884

Epoch: 49| Step: 0
Training loss: 4.202987952284753
Validation loss: 3.3314075049411325

Epoch: 6| Step: 1
Training loss: 3.534583214951654
Validation loss: 3.332836253009042

Epoch: 6| Step: 2
Training loss: 3.8490891010678077
Validation loss: 3.3356180610864246

Epoch: 6| Step: 3
Training loss: 3.8197158316324824
Validation loss: 3.328893979088198

Epoch: 6| Step: 4
Training loss: 3.7315900944742992
Validation loss: 3.3289554139017494

Epoch: 6| Step: 5
Training loss: 4.48410277919396
Validation loss: 3.326703180136604

Epoch: 6| Step: 6
Training loss: 3.200413891728559
Validation loss: 3.3281857264839174

Epoch: 6| Step: 7
Training loss: 3.679362742353536
Validation loss: 3.325667605663668

Epoch: 6| Step: 8
Training loss: 2.8229998098894273
Validation loss: 3.328855144899562

Epoch: 6| Step: 9
Training loss: 2.7005543916702335
Validation loss: 3.328933800873321

Epoch: 6| Step: 10
Training loss: 2.785922123069068
Validation loss: 3.3387680346835285

Epoch: 6| Step: 11
Training loss: 3.374589541871847
Validation loss: 3.3361813012646246

Epoch: 6| Step: 12
Training loss: 3.4607193923320883
Validation loss: 3.3246992197370684

Epoch: 6| Step: 13
Training loss: 3.8277106858863608
Validation loss: 3.325270375267413

Epoch: 50| Step: 0
Training loss: 3.883613120111119
Validation loss: 3.324428806932187

Epoch: 6| Step: 1
Training loss: 4.010091211894059
Validation loss: 3.323563446867858

Epoch: 6| Step: 2
Training loss: 3.6850985449938674
Validation loss: 3.3283212424696047

Epoch: 6| Step: 3
Training loss: 3.0000023841848438
Validation loss: 3.3309362919348486

Epoch: 6| Step: 4
Training loss: 3.3496540745013124
Validation loss: 3.329680727835739

Epoch: 6| Step: 5
Training loss: 4.172444622570558
Validation loss: 3.329788383148655

Epoch: 6| Step: 6
Training loss: 3.3426902731675727
Validation loss: 3.3306181914333486

Epoch: 6| Step: 7
Training loss: 3.4596964589415493
Validation loss: 3.3276927004202874

Epoch: 6| Step: 8
Training loss: 3.31450405317753
Validation loss: 3.32889242807051

Epoch: 6| Step: 9
Training loss: 3.7400970672821945
Validation loss: 3.323583363142645

Epoch: 6| Step: 10
Training loss: 3.975875585317261
Validation loss: 3.3229487975596763

Epoch: 6| Step: 11
Training loss: 3.5269955012198415
Validation loss: 3.321848436305198

Epoch: 6| Step: 12
Training loss: 2.8375419512769056
Validation loss: 3.3217173255308534

Epoch: 6| Step: 13
Training loss: 2.9396760063964544
Validation loss: 3.318623304365589

Epoch: 51| Step: 0
Training loss: 3.5292871471919063
Validation loss: 3.3216239093042073

Epoch: 6| Step: 1
Training loss: 3.8653075301392605
Validation loss: 3.3217401624727745

Epoch: 6| Step: 2
Training loss: 3.951768604724427
Validation loss: 3.3202464763680974

Epoch: 6| Step: 3
Training loss: 2.777714056767642
Validation loss: 3.3210877327957573

Epoch: 6| Step: 4
Training loss: 3.0809260757130783
Validation loss: 3.31843075052648

Epoch: 6| Step: 5
Training loss: 4.056796251378088
Validation loss: 3.3190494837050952

Epoch: 6| Step: 6
Training loss: 3.5491266707631146
Validation loss: 3.319375059146602

Epoch: 6| Step: 7
Training loss: 3.6341846786877237
Validation loss: 3.3172094209151224

Epoch: 6| Step: 8
Training loss: 3.698145484113285
Validation loss: 3.319166314411019

Epoch: 6| Step: 9
Training loss: 2.7874173139274325
Validation loss: 3.3174692417658256

Epoch: 6| Step: 10
Training loss: 3.156894278156852
Validation loss: 3.317176531404229

Epoch: 6| Step: 11
Training loss: 3.2735221323803634
Validation loss: 3.3175770939730627

Epoch: 6| Step: 12
Training loss: 4.625696284488748
Validation loss: 3.3171248173079086

Epoch: 6| Step: 13
Training loss: 3.029223521738421
Validation loss: 3.316977958604409

Epoch: 52| Step: 0
Training loss: 3.798946616082635
Validation loss: 3.3166559515899685

Epoch: 6| Step: 1
Training loss: 3.4702409169226818
Validation loss: 3.315097016014746

Epoch: 6| Step: 2
Training loss: 4.314314308540913
Validation loss: 3.3165934665035106

Epoch: 6| Step: 3
Training loss: 3.236735786174014
Validation loss: 3.3148933706248807

Epoch: 6| Step: 4
Training loss: 3.8947188199251683
Validation loss: 3.3158730135544547

Epoch: 6| Step: 5
Training loss: 3.426887359735998
Validation loss: 3.317400510891936

Epoch: 6| Step: 6
Training loss: 3.4649417351562124
Validation loss: 3.31646990584826

Epoch: 6| Step: 7
Training loss: 3.739661142430565
Validation loss: 3.3158916663254616

Epoch: 6| Step: 8
Training loss: 3.548716331824758
Validation loss: 3.315318514603605

Epoch: 6| Step: 9
Training loss: 3.565915795787456
Validation loss: 3.3162949583245815

Epoch: 6| Step: 10
Training loss: 2.8754494357226075
Validation loss: 3.3151009761992567

Epoch: 6| Step: 11
Training loss: 3.4676203907458505
Validation loss: 3.3145335544073937

Epoch: 6| Step: 12
Training loss: 3.519763189499579
Validation loss: 3.3148580196723185

Epoch: 6| Step: 13
Training loss: 2.885303279333545
Validation loss: 3.3144054972725834

Epoch: 53| Step: 0
Training loss: 3.8245905538584237
Validation loss: 3.312614647894845

Epoch: 6| Step: 1
Training loss: 3.0787136076659265
Validation loss: 3.312956883937052

Epoch: 6| Step: 2
Training loss: 4.095801618316791
Validation loss: 3.3126478048060375

Epoch: 6| Step: 3
Training loss: 2.3676519662167164
Validation loss: 3.3125656177153444

Epoch: 6| Step: 4
Training loss: 3.8228409401914574
Validation loss: 3.311998104460613

Epoch: 6| Step: 5
Training loss: 3.915360956810897
Validation loss: 3.3144517327479637

Epoch: 6| Step: 6
Training loss: 3.548603191395926
Validation loss: 3.314445510921161

Epoch: 6| Step: 7
Training loss: 3.402225461670789
Validation loss: 3.312972115824466

Epoch: 6| Step: 8
Training loss: 3.166691796721747
Validation loss: 3.312452023778459

Epoch: 6| Step: 9
Training loss: 3.4597240240915137
Validation loss: 3.3135276418563837

Epoch: 6| Step: 10
Training loss: 3.9146330944807963
Validation loss: 3.311238247280835

Epoch: 6| Step: 11
Training loss: 3.865496888192636
Validation loss: 3.3097252844142027

Epoch: 6| Step: 12
Training loss: 3.1901527286907516
Validation loss: 3.3125955014925745

Epoch: 6| Step: 13
Training loss: 3.6703747870306795
Validation loss: 3.3077623351018066

Epoch: 54| Step: 0
Training loss: 2.9959979383922457
Validation loss: 3.3078598737130136

Epoch: 6| Step: 1
Training loss: 3.6372146022562664
Validation loss: 3.3111592584419167

Epoch: 6| Step: 2
Training loss: 4.305783777785415
Validation loss: 3.3059970287108675

Epoch: 6| Step: 3
Training loss: 3.656527516845089
Validation loss: 3.3059615019810704

Epoch: 6| Step: 4
Training loss: 3.2282959943537772
Validation loss: 3.30577472873476

Epoch: 6| Step: 5
Training loss: 3.4893803931291445
Validation loss: 3.304879108437213

Epoch: 6| Step: 6
Training loss: 3.462888972609589
Validation loss: 3.305510578508462

Epoch: 6| Step: 7
Training loss: 3.1318374600479615
Validation loss: 3.3035262844003723

Epoch: 6| Step: 8
Training loss: 3.8802612027997707
Validation loss: 3.306591042600906

Epoch: 6| Step: 9
Training loss: 4.215608458490063
Validation loss: 3.3046043112264494

Epoch: 6| Step: 10
Training loss: 3.2957868904735017
Validation loss: 3.3048122474291093

Epoch: 6| Step: 11
Training loss: 3.72427880390995
Validation loss: 3.304412980116174

Epoch: 6| Step: 12
Training loss: 2.366694332910291
Validation loss: 3.301742817717467

Epoch: 6| Step: 13
Training loss: 3.8441277295107477
Validation loss: 3.304403175246561

Epoch: 55| Step: 0
Training loss: 4.150901622954616
Validation loss: 3.3018116120887413

Epoch: 6| Step: 1
Training loss: 2.819612284040487
Validation loss: 3.3034063892297856

Epoch: 6| Step: 2
Training loss: 2.663007241944376
Validation loss: 3.3036292714946343

Epoch: 6| Step: 3
Training loss: 3.4202642961070433
Validation loss: 3.3083999003036095

Epoch: 6| Step: 4
Training loss: 2.7952462680533467
Validation loss: 3.3034664968363843

Epoch: 6| Step: 5
Training loss: 3.614303196908379
Validation loss: 3.305809615361513

Epoch: 6| Step: 6
Training loss: 3.9898494435828646
Validation loss: 3.3045411157139655

Epoch: 6| Step: 7
Training loss: 3.861644247618625
Validation loss: 3.30256575138809

Epoch: 6| Step: 8
Training loss: 3.191614972950071
Validation loss: 3.302961739945782

Epoch: 6| Step: 9
Training loss: 3.7823217465188566
Validation loss: 3.3003194654015666

Epoch: 6| Step: 10
Training loss: 3.431328105211274
Validation loss: 3.3003865222908004

Epoch: 6| Step: 11
Training loss: 3.5582524459424145
Validation loss: 3.301757112144544

Epoch: 6| Step: 12
Training loss: 4.153054751569169
Validation loss: 3.302484304695988

Epoch: 6| Step: 13
Training loss: 3.779567375655465
Validation loss: 3.302354101945981

Epoch: 56| Step: 0
Training loss: 3.1068052474890013
Validation loss: 3.3006044673841233

Epoch: 6| Step: 1
Training loss: 4.124632616733575
Validation loss: 3.301614531587818

Epoch: 6| Step: 2
Training loss: 3.5942886612269485
Validation loss: 3.299427151360031

Epoch: 6| Step: 3
Training loss: 3.4857642992081077
Validation loss: 3.2988484517267445

Epoch: 6| Step: 4
Training loss: 3.6083967195953286
Validation loss: 3.298152559219007

Epoch: 6| Step: 5
Training loss: 3.7788717814465196
Validation loss: 3.2977659033291675

Epoch: 6| Step: 6
Training loss: 3.7167750652112344
Validation loss: 3.2968239550168956

Epoch: 6| Step: 7
Training loss: 2.978213675780903
Validation loss: 3.2968609347925746

Epoch: 6| Step: 8
Training loss: 3.8903776649387773
Validation loss: 3.2984895681985438

Epoch: 6| Step: 9
Training loss: 3.960628941422473
Validation loss: 3.2964612114738396

Epoch: 6| Step: 10
Training loss: 2.752915137754208
Validation loss: 3.296544395767399

Epoch: 6| Step: 11
Training loss: 3.9258674877810398
Validation loss: 3.296942305012736

Epoch: 6| Step: 12
Training loss: 2.826231348852664
Validation loss: 3.2954242257046475

Epoch: 6| Step: 13
Training loss: 3.2525585080747903
Validation loss: 3.295207850291264

Epoch: 57| Step: 0
Training loss: 3.6499038788144764
Validation loss: 3.2952350580651726

Epoch: 6| Step: 1
Training loss: 3.4219636252435874
Validation loss: 3.2952569644699654

Epoch: 6| Step: 2
Training loss: 3.164095051915886
Validation loss: 3.2956985484238457

Epoch: 6| Step: 3
Training loss: 4.2019613137005365
Validation loss: 3.2959846710020257

Epoch: 6| Step: 4
Training loss: 3.313538874257524
Validation loss: 3.294848030234877

Epoch: 6| Step: 5
Training loss: 3.4465212269490024
Validation loss: 3.2923313672768604

Epoch: 6| Step: 6
Training loss: 3.629693511550661
Validation loss: 3.293785072954531

Epoch: 6| Step: 7
Training loss: 4.127217708109403
Validation loss: 3.294599387594762

Epoch: 6| Step: 8
Training loss: 3.9206003496199955
Validation loss: 3.293298691865511

Epoch: 6| Step: 9
Training loss: 3.0406212425404746
Validation loss: 3.294403426552241

Epoch: 6| Step: 10
Training loss: 3.8359466987701567
Validation loss: 3.2907864562122287

Epoch: 6| Step: 11
Training loss: 2.2330664157309403
Validation loss: 3.2941074859861708

Epoch: 6| Step: 12
Training loss: 3.9269217433451526
Validation loss: 3.2928932342922748

Epoch: 6| Step: 13
Training loss: 2.54113009266097
Validation loss: 3.291389281264044

Epoch: 58| Step: 0
Training loss: 3.2014743924991245
Validation loss: 3.292115562633365

Epoch: 6| Step: 1
Training loss: 3.627589386167992
Validation loss: 3.291659435504672

Epoch: 6| Step: 2
Training loss: 2.8931586631519015
Validation loss: 3.290161569618104

Epoch: 6| Step: 3
Training loss: 3.4422622984223814
Validation loss: 3.289467491411771

Epoch: 6| Step: 4
Training loss: 4.223932996016152
Validation loss: 3.2903699681957193

Epoch: 6| Step: 5
Training loss: 3.4454532516689347
Validation loss: 3.2900357025325784

Epoch: 6| Step: 6
Training loss: 3.636077791596732
Validation loss: 3.2904710001268564

Epoch: 6| Step: 7
Training loss: 2.6022222558700308
Validation loss: 3.2912881871667934

Epoch: 6| Step: 8
Training loss: 4.073978581577755
Validation loss: 3.2898292621078435

Epoch: 6| Step: 9
Training loss: 3.9630465638984047
Validation loss: 3.288359386458408

Epoch: 6| Step: 10
Training loss: 3.65264532302754
Validation loss: 3.2899967369454637

Epoch: 6| Step: 11
Training loss: 4.015599825887774
Validation loss: 3.288933968701595

Epoch: 6| Step: 12
Training loss: 3.4683357884992434
Validation loss: 3.2895476401650305

Epoch: 6| Step: 13
Training loss: 1.7891643112065245
Validation loss: 3.2886111677334577

Epoch: 59| Step: 0
Training loss: 4.407052907094234
Validation loss: 3.288634487144042

Epoch: 6| Step: 1
Training loss: 3.8463038202536413
Validation loss: 3.290124812195609

Epoch: 6| Step: 2
Training loss: 3.173014168463331
Validation loss: 3.2901699941426994

Epoch: 6| Step: 3
Training loss: 4.220057758098751
Validation loss: 3.2907083756384687

Epoch: 6| Step: 4
Training loss: 3.1872555508096605
Validation loss: 3.2911814831420227

Epoch: 6| Step: 5
Training loss: 4.044011697452278
Validation loss: 3.290698593817661

Epoch: 6| Step: 6
Training loss: 2.3555401084301444
Validation loss: 3.2890076765569844

Epoch: 6| Step: 7
Training loss: 3.187324668699625
Validation loss: 3.291880476957181

Epoch: 6| Step: 8
Training loss: 2.868696351058724
Validation loss: 3.2875022929973663

Epoch: 6| Step: 9
Training loss: 3.1922279149959354
Validation loss: 3.288363560492216

Epoch: 6| Step: 10
Training loss: 2.9877096190393395
Validation loss: 3.2875090812720815

Epoch: 6| Step: 11
Training loss: 3.6556612502577073
Validation loss: 3.287387665344876

Epoch: 6| Step: 12
Training loss: 3.813851289007358
Validation loss: 3.286051759730633

Epoch: 6| Step: 13
Training loss: 3.9869506888075392
Validation loss: 3.2849480529085175

Epoch: 60| Step: 0
Training loss: 4.1416907900153115
Validation loss: 3.284741650188684

Epoch: 6| Step: 1
Training loss: 3.748113920835653
Validation loss: 3.285798641656466

Epoch: 6| Step: 2
Training loss: 3.5142404500192868
Validation loss: 3.284937698273676

Epoch: 6| Step: 3
Training loss: 3.6302355086168254
Validation loss: 3.2833411222317297

Epoch: 6| Step: 4
Training loss: 3.765342860118856
Validation loss: 3.2860160906984435

Epoch: 6| Step: 5
Training loss: 3.572086219182761
Validation loss: 3.285298369651332

Epoch: 6| Step: 6
Training loss: 2.961170036424646
Validation loss: 3.284951438370682

Epoch: 6| Step: 7
Training loss: 3.2718528244010328
Validation loss: 3.2865703321795525

Epoch: 6| Step: 8
Training loss: 4.097177948505975
Validation loss: 3.285897879260015

Epoch: 6| Step: 9
Training loss: 4.0698935499962134
Validation loss: 3.2840106966457174

Epoch: 6| Step: 10
Training loss: 3.3615502700235655
Validation loss: 3.284609245554232

Epoch: 6| Step: 11
Training loss: 3.116179568599949
Validation loss: 3.2846467671425743

Epoch: 6| Step: 12
Training loss: 3.103444179627211
Validation loss: 3.2835054426702395

Epoch: 6| Step: 13
Training loss: 1.3766703430262162
Validation loss: 3.282943463596155

Epoch: 61| Step: 0
Training loss: 3.16670068086794
Validation loss: 3.2812065563070254

Epoch: 6| Step: 1
Training loss: 3.793190632389179
Validation loss: 3.282683569232217

Epoch: 6| Step: 2
Training loss: 3.1765943474024536
Validation loss: 3.281924555088886

Epoch: 6| Step: 3
Training loss: 3.049684764643108
Validation loss: 3.2818448513417233

Epoch: 6| Step: 4
Training loss: 3.6123784767487117
Validation loss: 3.282423762071319

Epoch: 6| Step: 5
Training loss: 4.345089273709895
Validation loss: 3.2810841125339025

Epoch: 6| Step: 6
Training loss: 3.1593915959647725
Validation loss: 3.280737358397571

Epoch: 6| Step: 7
Training loss: 3.0962366456662833
Validation loss: 3.28126540094952

Epoch: 6| Step: 8
Training loss: 3.771511937124171
Validation loss: 3.2809716422539212

Epoch: 6| Step: 9
Training loss: 3.8865624477837044
Validation loss: 3.2794343111573214

Epoch: 6| Step: 10
Training loss: 3.493187541418858
Validation loss: 3.2808970553056658

Epoch: 6| Step: 11
Training loss: 3.6932435645430393
Validation loss: 3.2796389936277888

Epoch: 6| Step: 12
Training loss: 2.723031367070494
Validation loss: 3.2794031824183625

Epoch: 6| Step: 13
Training loss: 4.243440390347854
Validation loss: 3.2796345802381457

Epoch: 62| Step: 0
Training loss: 4.286662446450568
Validation loss: 3.2785091987275417

Epoch: 6| Step: 1
Training loss: 3.5699110076668763
Validation loss: 3.278567697685615

Epoch: 6| Step: 2
Training loss: 2.9689790336200077
Validation loss: 3.278031012007115

Epoch: 6| Step: 3
Training loss: 4.199811458897078
Validation loss: 3.278462848908166

Epoch: 6| Step: 4
Training loss: 3.4037561649262478
Validation loss: 3.2777602554065206

Epoch: 6| Step: 5
Training loss: 3.154443960628343
Validation loss: 3.278289991160955

Epoch: 6| Step: 6
Training loss: 3.3980408184884667
Validation loss: 3.278770359118043

Epoch: 6| Step: 7
Training loss: 3.31261702996577
Validation loss: 3.2786461745113264

Epoch: 6| Step: 8
Training loss: 3.344993003758069
Validation loss: 3.2818450075733976

Epoch: 6| Step: 9
Training loss: 3.719706820963628
Validation loss: 3.277950505017785

Epoch: 6| Step: 10
Training loss: 4.168436183298648
Validation loss: 3.278615497281078

Epoch: 6| Step: 11
Training loss: 3.2984934807042645
Validation loss: 3.2782636046269142

Epoch: 6| Step: 12
Training loss: 2.367359318808225
Validation loss: 3.277530888785712

Epoch: 6| Step: 13
Training loss: 3.5927111907236813
Validation loss: 3.2770352093988424

Epoch: 63| Step: 0
Training loss: 3.022246370109999
Validation loss: 3.275306953549548

Epoch: 6| Step: 1
Training loss: 3.372117683791573
Validation loss: 3.2757657489503913

Epoch: 6| Step: 2
Training loss: 3.881005340580361
Validation loss: 3.2771902632516343

Epoch: 6| Step: 3
Training loss: 3.9924755850984766
Validation loss: 3.278188796530039

Epoch: 6| Step: 4
Training loss: 3.34562658967298
Validation loss: 3.276446524515719

Epoch: 6| Step: 5
Training loss: 3.7324085884117255
Validation loss: 3.2759359289105685

Epoch: 6| Step: 6
Training loss: 3.327153023643009
Validation loss: 3.275210422687372

Epoch: 6| Step: 7
Training loss: 3.802567849140164
Validation loss: 3.275557743910102

Epoch: 6| Step: 8
Training loss: 3.6449886251724735
Validation loss: 3.2749798113186506

Epoch: 6| Step: 9
Training loss: 3.6720090151740545
Validation loss: 3.2742117358893252

Epoch: 6| Step: 10
Training loss: 3.428729434005578
Validation loss: 3.2730719092758847

Epoch: 6| Step: 11
Training loss: 2.74319187474776
Validation loss: 3.2745368128361467

Epoch: 6| Step: 12
Training loss: 3.5215504534843096
Validation loss: 3.2739634984913994

Epoch: 6| Step: 13
Training loss: 3.505355552238235
Validation loss: 3.27335108525164

Epoch: 64| Step: 0
Training loss: 3.574323342048901
Validation loss: 3.2731110324873445

Epoch: 6| Step: 1
Training loss: 3.7237802031624856
Validation loss: 3.273614751212818

Epoch: 6| Step: 2
Training loss: 3.491876712086512
Validation loss: 3.274083797672997

Epoch: 6| Step: 3
Training loss: 2.921952680075365
Validation loss: 3.2728461556865276

Epoch: 6| Step: 4
Training loss: 3.6140591170727654
Validation loss: 3.2718130154226053

Epoch: 6| Step: 5
Training loss: 3.3509286134333958
Validation loss: 3.273222161788104

Epoch: 6| Step: 6
Training loss: 2.7014859031466187
Validation loss: 3.27287044905438

Epoch: 6| Step: 7
Training loss: 3.463043880782779
Validation loss: 3.2733109632031385

Epoch: 6| Step: 8
Training loss: 3.832012087028411
Validation loss: 3.272668031712771

Epoch: 6| Step: 9
Training loss: 2.82540763007075
Validation loss: 3.272012472296472

Epoch: 6| Step: 10
Training loss: 4.25863712269809
Validation loss: 3.2732159336469264

Epoch: 6| Step: 11
Training loss: 3.5262710444090506
Validation loss: 3.2711012911892534

Epoch: 6| Step: 12
Training loss: 4.062815257824784
Validation loss: 3.271993334328685

Epoch: 6| Step: 13
Training loss: 3.4036271382494334
Validation loss: 3.271000294251245

Epoch: 65| Step: 0
Training loss: 3.015254180720595
Validation loss: 3.271469479684434

Epoch: 6| Step: 1
Training loss: 3.5988982104051543
Validation loss: 3.271589002336614

Epoch: 6| Step: 2
Training loss: 3.7103497170190045
Validation loss: 3.2702063283545884

Epoch: 6| Step: 3
Training loss: 3.5316623683277406
Validation loss: 3.269252208137736

Epoch: 6| Step: 4
Training loss: 3.6611626380403557
Validation loss: 3.270723039408095

Epoch: 6| Step: 5
Training loss: 3.058740137331409
Validation loss: 3.2703007414085863

Epoch: 6| Step: 6
Training loss: 4.045963140435742
Validation loss: 3.2696564786228226

Epoch: 6| Step: 7
Training loss: 3.703959310683004
Validation loss: 3.270183786909343

Epoch: 6| Step: 8
Training loss: 4.101106280430766
Validation loss: 3.269590433359643

Epoch: 6| Step: 9
Training loss: 2.466996161474513
Validation loss: 3.270100350695534

Epoch: 6| Step: 10
Training loss: 3.6725709945433236
Validation loss: 3.27132231740574

Epoch: 6| Step: 11
Training loss: 3.5233583293402266
Validation loss: 3.2684360210065133

Epoch: 6| Step: 12
Training loss: 3.768277955107378
Validation loss: 3.2698845159582173

Epoch: 6| Step: 13
Training loss: 2.237864723528433
Validation loss: 3.2687742193125517

Epoch: 66| Step: 0
Training loss: 2.978078541188152
Validation loss: 3.268476445262385

Epoch: 6| Step: 1
Training loss: 2.9861197439458294
Validation loss: 3.2678172725065195

Epoch: 6| Step: 2
Training loss: 2.8901190237595027
Validation loss: 3.2689161830278937

Epoch: 6| Step: 3
Training loss: 3.888809577193687
Validation loss: 3.2669602247342793

Epoch: 6| Step: 4
Training loss: 3.99110412828089
Validation loss: 3.2668011429434443

Epoch: 6| Step: 5
Training loss: 3.5738164956790377
Validation loss: 3.266815723670775

Epoch: 6| Step: 6
Training loss: 4.0507092078634725
Validation loss: 3.2665289406772917

Epoch: 6| Step: 7
Training loss: 3.1170109672561495
Validation loss: 3.2660993186544025

Epoch: 6| Step: 8
Training loss: 3.840331627711756
Validation loss: 3.2661981595328973

Epoch: 6| Step: 9
Training loss: 3.9603628610765003
Validation loss: 3.266095855566671

Epoch: 6| Step: 10
Training loss: 3.817456384995482
Validation loss: 3.269085496195151

Epoch: 6| Step: 11
Training loss: 3.001242062622912
Validation loss: 3.2669474856066634

Epoch: 6| Step: 12
Training loss: 3.580200393012377
Validation loss: 3.2669359439172916

Epoch: 6| Step: 13
Training loss: 2.632389204369067
Validation loss: 3.2684355009737316

Epoch: 67| Step: 0
Training loss: 2.903100552984644
Validation loss: 3.2664261118063247

Epoch: 6| Step: 1
Training loss: 4.149887147770816
Validation loss: 3.267801047981346

Epoch: 6| Step: 2
Training loss: 3.6747487611592717
Validation loss: 3.268317408249445

Epoch: 6| Step: 3
Training loss: 3.767387262694051
Validation loss: 3.2697233207193284

Epoch: 6| Step: 4
Training loss: 4.300853316338192
Validation loss: 3.270227599672598

Epoch: 6| Step: 5
Training loss: 3.3391516609765484
Validation loss: 3.264898414912802

Epoch: 6| Step: 6
Training loss: 3.77828182024364
Validation loss: 3.263659803289467

Epoch: 6| Step: 7
Training loss: 2.332309520994414
Validation loss: 3.264762075535221

Epoch: 6| Step: 8
Training loss: 3.316318254685069
Validation loss: 3.263408111150753

Epoch: 6| Step: 9
Training loss: 2.8553171182807815
Validation loss: 3.2642996916483082

Epoch: 6| Step: 10
Training loss: 2.8253203758937553
Validation loss: 3.262787408159969

Epoch: 6| Step: 11
Training loss: 3.5703627167557106
Validation loss: 3.2641066499001705

Epoch: 6| Step: 12
Training loss: 3.1062026206380975
Validation loss: 3.264067869588878

Epoch: 6| Step: 13
Training loss: 5.070887270002965
Validation loss: 3.2626985953334127

Epoch: 68| Step: 0
Training loss: 3.9155474071319274
Validation loss: 3.2623542577703204

Epoch: 6| Step: 1
Training loss: 2.849869065874247
Validation loss: 3.262275291583937

Epoch: 6| Step: 2
Training loss: 2.303527954130669
Validation loss: 3.262157879608754

Epoch: 6| Step: 3
Training loss: 3.2638936541006234
Validation loss: 3.2616135781004547

Epoch: 6| Step: 4
Training loss: 2.578825884251238
Validation loss: 3.262519162978704

Epoch: 6| Step: 5
Training loss: 3.252194030819674
Validation loss: 3.2624482277682767

Epoch: 6| Step: 6
Training loss: 3.9052832055548006
Validation loss: 3.2631887941946505

Epoch: 6| Step: 7
Training loss: 3.733368678152711
Validation loss: 3.269683666148496

Epoch: 6| Step: 8
Training loss: 4.255583069205809
Validation loss: 3.26740721314861

Epoch: 6| Step: 9
Training loss: 3.3335019227945413
Validation loss: 3.2661063107523485

Epoch: 6| Step: 10
Training loss: 4.2674699643044045
Validation loss: 3.264307072425115

Epoch: 6| Step: 11
Training loss: 3.34288013587748
Validation loss: 3.259724850490738

Epoch: 6| Step: 12
Training loss: 3.581228051775771
Validation loss: 3.2584063507913035

Epoch: 6| Step: 13
Training loss: 4.0429269981992695
Validation loss: 3.2583176829135283

Epoch: 69| Step: 0
Training loss: 3.3606332241281938
Validation loss: 3.2581650057386646

Epoch: 6| Step: 1
Training loss: 2.256160567352481
Validation loss: 3.2587310832960665

Epoch: 6| Step: 2
Training loss: 2.8162945898516
Validation loss: 3.2596678285533316

Epoch: 6| Step: 3
Training loss: 3.8846838756952815
Validation loss: 3.2593871856144845

Epoch: 6| Step: 4
Training loss: 4.260035615154269
Validation loss: 3.2566066684306167

Epoch: 6| Step: 5
Training loss: 3.0990428923709468
Validation loss: 3.2576794667374545

Epoch: 6| Step: 6
Training loss: 3.336948786446855
Validation loss: 3.257106226491944

Epoch: 6| Step: 7
Training loss: 4.540774943218496
Validation loss: 3.2558731992282293

Epoch: 6| Step: 8
Training loss: 3.3666379971432323
Validation loss: 3.255215126998539

Epoch: 6| Step: 9
Training loss: 2.234288780843061
Validation loss: 3.2554449642025554

Epoch: 6| Step: 10
Training loss: 3.8204321969282065
Validation loss: 3.25519559179294

Epoch: 6| Step: 11
Training loss: 3.934819838242131
Validation loss: 3.254364177234062

Epoch: 6| Step: 12
Training loss: 3.7585118648194102
Validation loss: 3.253354914857737

Epoch: 6| Step: 13
Training loss: 3.4708655152464143
Validation loss: 3.2546970039009033

Epoch: 70| Step: 0
Training loss: 3.8388639579609922
Validation loss: 3.255544492366378

Epoch: 6| Step: 1
Training loss: 3.4342372321698003
Validation loss: 3.2561749263206816

Epoch: 6| Step: 2
Training loss: 3.188316689378202
Validation loss: 3.252545923776778

Epoch: 6| Step: 3
Training loss: 3.3784136991974214
Validation loss: 3.253034841472122

Epoch: 6| Step: 4
Training loss: 3.3554565287357474
Validation loss: 3.2543235934350188

Epoch: 6| Step: 5
Training loss: 3.31803173044035
Validation loss: 3.257603074739967

Epoch: 6| Step: 6
Training loss: 3.8910790603593863
Validation loss: 3.2588890580758574

Epoch: 6| Step: 7
Training loss: 3.9116086291794447
Validation loss: 3.256502961013038

Epoch: 6| Step: 8
Training loss: 3.943370983452453
Validation loss: 3.251293666384075

Epoch: 6| Step: 9
Training loss: 2.8371937389034176
Validation loss: 3.251074961045327

Epoch: 6| Step: 10
Training loss: 4.003699737433418
Validation loss: 3.2499375980214165

Epoch: 6| Step: 11
Training loss: 3.354567667682461
Validation loss: 3.251509247381159

Epoch: 6| Step: 12
Training loss: 3.1960725882908267
Validation loss: 3.250320068576962

Epoch: 6| Step: 13
Training loss: 2.6206609195182677
Validation loss: 3.24862442060055

Epoch: 71| Step: 0
Training loss: 4.035536269012536
Validation loss: 3.2496869367917256

Epoch: 6| Step: 1
Training loss: 3.942628457365978
Validation loss: 3.248690501479224

Epoch: 6| Step: 2
Training loss: 4.144154782324531
Validation loss: 3.2470251466637055

Epoch: 6| Step: 3
Training loss: 3.7534232726989485
Validation loss: 3.2432392927295126

Epoch: 6| Step: 4
Training loss: 3.59412680599316
Validation loss: 3.2402340822597324

Epoch: 6| Step: 5
Training loss: 3.2909967891708747
Validation loss: 3.237523594561749

Epoch: 6| Step: 6
Training loss: 3.635733400263018
Validation loss: 3.2384109541355315

Epoch: 6| Step: 7
Training loss: 3.398738032239612
Validation loss: 3.237232711165824

Epoch: 6| Step: 8
Training loss: 2.8791119568002284
Validation loss: 3.2367306758951617

Epoch: 6| Step: 9
Training loss: 2.9323397825007627
Validation loss: 3.23677574143321

Epoch: 6| Step: 10
Training loss: 3.312842873156178
Validation loss: 3.2372123689631525

Epoch: 6| Step: 11
Training loss: 3.128949682955806
Validation loss: 3.2378480730557193

Epoch: 6| Step: 12
Training loss: 3.149448128449482
Validation loss: 3.236858935751636

Epoch: 6| Step: 13
Training loss: 3.210342834798701
Validation loss: 3.237557968689364

Epoch: 72| Step: 0
Training loss: 3.2534794888211125
Validation loss: 3.2358481858869967

Epoch: 6| Step: 1
Training loss: 3.562327062859782
Validation loss: 3.235075358154529

Epoch: 6| Step: 2
Training loss: 3.5907293478840563
Validation loss: 3.2352087337259485

Epoch: 6| Step: 3
Training loss: 3.7498304964539706
Validation loss: 3.2353374469416063

Epoch: 6| Step: 4
Training loss: 3.91412402197938
Validation loss: 3.235331399435299

Epoch: 6| Step: 5
Training loss: 3.361627719434778
Validation loss: 3.2331491851972514

Epoch: 6| Step: 6
Training loss: 3.4587829634595275
Validation loss: 3.2342847316407894

Epoch: 6| Step: 7
Training loss: 2.519994128386908
Validation loss: 3.234308669440676

Epoch: 6| Step: 8
Training loss: 4.035937046312402
Validation loss: 3.2342544809835707

Epoch: 6| Step: 9
Training loss: 2.856515924607994
Validation loss: 3.234555299313024

Epoch: 6| Step: 10
Training loss: 3.4812254762727437
Validation loss: 3.2342955670840765

Epoch: 6| Step: 11
Training loss: 3.4110655735661206
Validation loss: 3.23329730471028

Epoch: 6| Step: 12
Training loss: 3.526042508116283
Validation loss: 3.2336231681750225

Epoch: 6| Step: 13
Training loss: 3.8215904048780858
Validation loss: 3.232182936224807

Epoch: 73| Step: 0
Training loss: 4.3437262884357315
Validation loss: 3.2318376913979585

Epoch: 6| Step: 1
Training loss: 2.902989188673155
Validation loss: 3.2315474774417754

Epoch: 6| Step: 2
Training loss: 3.315403942968897
Validation loss: 3.2313193860760965

Epoch: 6| Step: 3
Training loss: 3.896241572948909
Validation loss: 3.2305677573133327

Epoch: 6| Step: 4
Training loss: 3.6085747166007978
Validation loss: 3.230945312989739

Epoch: 6| Step: 5
Training loss: 3.0766343898326904
Validation loss: 3.2299713042615834

Epoch: 6| Step: 6
Training loss: 4.0666456930734896
Validation loss: 3.2296947025030023

Epoch: 6| Step: 7
Training loss: 3.3695518883953794
Validation loss: 3.229838563297056

Epoch: 6| Step: 8
Training loss: 2.817332206813709
Validation loss: 3.2284602641311055

Epoch: 6| Step: 9
Training loss: 3.273711636884001
Validation loss: 3.2279129966173503

Epoch: 6| Step: 10
Training loss: 2.9898828939004085
Validation loss: 3.2298691069254466

Epoch: 6| Step: 11
Training loss: 3.7266072844367426
Validation loss: 3.2284893398623

Epoch: 6| Step: 12
Training loss: 3.1242986273469118
Validation loss: 3.2270083647863346

Epoch: 6| Step: 13
Training loss: 3.9205135094753234
Validation loss: 3.2282933181826525

Epoch: 74| Step: 0
Training loss: 3.6191231016423453
Validation loss: 3.22780361299219

Epoch: 6| Step: 1
Training loss: 3.1461151872562416
Validation loss: 3.227983980734205

Epoch: 6| Step: 2
Training loss: 3.1149184302951785
Validation loss: 3.2292361810024945

Epoch: 6| Step: 3
Training loss: 4.205971587037506
Validation loss: 3.2274629468219

Epoch: 6| Step: 4
Training loss: 2.9833955605550777
Validation loss: 3.226348263604888

Epoch: 6| Step: 5
Training loss: 3.6392756896346854
Validation loss: 3.2262584007949604

Epoch: 6| Step: 6
Training loss: 3.044087391665309
Validation loss: 3.2262272015863225

Epoch: 6| Step: 7
Training loss: 3.9424677195464173
Validation loss: 3.2258534773608574

Epoch: 6| Step: 8
Training loss: 4.243330940152013
Validation loss: 3.2257975685345976

Epoch: 6| Step: 9
Training loss: 2.3002346665458284
Validation loss: 3.225521303515175

Epoch: 6| Step: 10
Training loss: 3.1904890220129203
Validation loss: 3.225102251979914

Epoch: 6| Step: 11
Training loss: 4.016207760334359
Validation loss: 3.224127535602913

Epoch: 6| Step: 12
Training loss: 3.3259029223691177
Validation loss: 3.225338066972295

Epoch: 6| Step: 13
Training loss: 3.1525013634892782
Validation loss: 3.223734083067776

Epoch: 75| Step: 0
Training loss: 2.83247555108558
Validation loss: 3.2241868685858384

Epoch: 6| Step: 1
Training loss: 3.9243467528396923
Validation loss: 3.2228272091343304

Epoch: 6| Step: 2
Training loss: 2.779318835559761
Validation loss: 3.221901912761209

Epoch: 6| Step: 3
Training loss: 4.343426809019866
Validation loss: 3.2225481039914605

Epoch: 6| Step: 4
Training loss: 3.6063654519150043
Validation loss: 3.220482214868829

Epoch: 6| Step: 5
Training loss: 3.2980761035029302
Validation loss: 3.2213519632862146

Epoch: 6| Step: 6
Training loss: 3.46742539417011
Validation loss: 3.2211729090489993

Epoch: 6| Step: 7
Training loss: 4.251978694083662
Validation loss: 3.2206445572716356

Epoch: 6| Step: 8
Training loss: 3.55703945950726
Validation loss: 3.220393317986538

Epoch: 6| Step: 9
Training loss: 2.8291662838860216
Validation loss: 3.2187288520357993

Epoch: 6| Step: 10
Training loss: 3.5294476525969154
Validation loss: 3.219991278751532

Epoch: 6| Step: 11
Training loss: 2.728415572694709
Validation loss: 3.219836575623254

Epoch: 6| Step: 12
Training loss: 3.3872811841498494
Validation loss: 3.219254210999243

Epoch: 6| Step: 13
Training loss: 3.534625845050923
Validation loss: 3.2181173535760013

Epoch: 76| Step: 0
Training loss: 2.028581245252777
Validation loss: 3.2194877342176977

Epoch: 6| Step: 1
Training loss: 3.154751261293017
Validation loss: 3.2185475323281265

Epoch: 6| Step: 2
Training loss: 3.7338967755295616
Validation loss: 3.2199967404308723

Epoch: 6| Step: 3
Training loss: 2.459352109771028
Validation loss: 3.2192802737099164

Epoch: 6| Step: 4
Training loss: 3.3063873897050815
Validation loss: 3.2176792822210425

Epoch: 6| Step: 5
Training loss: 3.327463576807486
Validation loss: 3.2189081385938123

Epoch: 6| Step: 6
Training loss: 3.604435434775715
Validation loss: 3.22183793851276

Epoch: 6| Step: 7
Training loss: 3.6054306606872135
Validation loss: 3.217618121004268

Epoch: 6| Step: 8
Training loss: 3.473880444768279
Validation loss: 3.2190749707930277

Epoch: 6| Step: 9
Training loss: 3.532655959307537
Validation loss: 3.2159293695209343

Epoch: 6| Step: 10
Training loss: 3.373621906507368
Validation loss: 3.2162091885353408

Epoch: 6| Step: 11
Training loss: 4.3161682891844615
Validation loss: 3.216406442440049

Epoch: 6| Step: 12
Training loss: 4.000301111331901
Validation loss: 3.2172466844995244

Epoch: 6| Step: 13
Training loss: 4.235258904011512
Validation loss: 3.2255955702547023

Epoch: 77| Step: 0
Training loss: 3.877635428783202
Validation loss: 3.2251428664533877

Epoch: 6| Step: 1
Training loss: 3.3751702442323217
Validation loss: 3.2228912066999644

Epoch: 6| Step: 2
Training loss: 2.842182272245141
Validation loss: 3.217936039246096

Epoch: 6| Step: 3
Training loss: 2.9193260784292776
Validation loss: 3.217389883569437

Epoch: 6| Step: 4
Training loss: 3.562438161212882
Validation loss: 3.218379292345199

Epoch: 6| Step: 5
Training loss: 2.3871760203453403
Validation loss: 3.221712328064154

Epoch: 6| Step: 6
Training loss: 3.8823821598796227
Validation loss: 3.2271182758420776

Epoch: 6| Step: 7
Training loss: 4.114637363256149
Validation loss: 3.231688575259337

Epoch: 6| Step: 8
Training loss: 4.223387930942927
Validation loss: 3.217365706743116

Epoch: 6| Step: 9
Training loss: 3.32225041102851
Validation loss: 3.2164881949433326

Epoch: 6| Step: 10
Training loss: 3.3648385973648005
Validation loss: 3.2151637924482834

Epoch: 6| Step: 11
Training loss: 3.4008488661294414
Validation loss: 3.2153639281787587

Epoch: 6| Step: 12
Training loss: 3.1855492700021655
Validation loss: 3.2151739252738447

Epoch: 6| Step: 13
Training loss: 3.6536335508756856
Validation loss: 3.2153642678326446

Epoch: 78| Step: 0
Training loss: 3.369684059433524
Validation loss: 3.2149133161996115

Epoch: 6| Step: 1
Training loss: 3.249956570848654
Validation loss: 3.2137410445449164

Epoch: 6| Step: 2
Training loss: 3.611741780367101
Validation loss: 3.212489250838332

Epoch: 6| Step: 3
Training loss: 3.1222661075999723
Validation loss: 3.2128984566086998

Epoch: 6| Step: 4
Training loss: 3.7404307022559458
Validation loss: 3.2113362516745254

Epoch: 6| Step: 5
Training loss: 2.6866286883576684
Validation loss: 3.2103841119268357

Epoch: 6| Step: 6
Training loss: 4.311846255079303
Validation loss: 3.2104530848316033

Epoch: 6| Step: 7
Training loss: 3.3816541842673176
Validation loss: 3.2104700663093353

Epoch: 6| Step: 8
Training loss: 3.5512646638754797
Validation loss: 3.21095004457397

Epoch: 6| Step: 9
Training loss: 2.9113496727135133
Validation loss: 3.2104452911768413

Epoch: 6| Step: 10
Training loss: 3.6058434057186872
Validation loss: 3.2100350978392966

Epoch: 6| Step: 11
Training loss: 4.32412810605369
Validation loss: 3.211321252998284

Epoch: 6| Step: 12
Training loss: 2.952117263573828
Validation loss: 3.21037814598123

Epoch: 6| Step: 13
Training loss: 2.933444856199829
Validation loss: 3.2115961516115434

Epoch: 79| Step: 0
Training loss: 4.176871404559232
Validation loss: 3.210965936000567

Epoch: 6| Step: 1
Training loss: 3.4702734823493904
Validation loss: 3.209942833613089

Epoch: 6| Step: 2
Training loss: 3.956284658753263
Validation loss: 3.208960539088965

Epoch: 6| Step: 3
Training loss: 3.2907130795652004
Validation loss: 3.2095648153778225

Epoch: 6| Step: 4
Training loss: 2.9478533483024805
Validation loss: 3.2087205531446377

Epoch: 6| Step: 5
Training loss: 2.9658519854972414
Validation loss: 3.207739939880783

Epoch: 6| Step: 6
Training loss: 3.361867290657482
Validation loss: 3.208692506316411

Epoch: 6| Step: 7
Training loss: 4.286414602372549
Validation loss: 3.2091474060950835

Epoch: 6| Step: 8
Training loss: 2.8199143062584566
Validation loss: 3.208366253772776

Epoch: 6| Step: 9
Training loss: 3.458647993242751
Validation loss: 3.2085387589385106

Epoch: 6| Step: 10
Training loss: 3.05346530357026
Validation loss: 3.208147009713094

Epoch: 6| Step: 11
Training loss: 3.361087522257549
Validation loss: 3.2068943658305

Epoch: 6| Step: 12
Training loss: 3.5564930113776447
Validation loss: 3.2071553947021454

Epoch: 6| Step: 13
Training loss: 3.17799921227572
Validation loss: 3.207373047206708

Epoch: 80| Step: 0
Training loss: 3.82029827091867
Validation loss: 3.2062620906541497

Epoch: 6| Step: 1
Training loss: 2.6595880514974897
Validation loss: 3.207444753652463

Epoch: 6| Step: 2
Training loss: 3.926706688962467
Validation loss: 3.210044968930599

Epoch: 6| Step: 3
Training loss: 3.159980910521201
Validation loss: 3.2076743708637783

Epoch: 6| Step: 4
Training loss: 3.346660452554514
Validation loss: 3.206001716721344

Epoch: 6| Step: 5
Training loss: 3.049290096025906
Validation loss: 3.205000650412441

Epoch: 6| Step: 6
Training loss: 3.9254322712970766
Validation loss: 3.204642120686568

Epoch: 6| Step: 7
Training loss: 3.8526221127375946
Validation loss: 3.2054408575805007

Epoch: 6| Step: 8
Training loss: 3.5821686263869674
Validation loss: 3.2049234939148437

Epoch: 6| Step: 9
Training loss: 4.475259161749109
Validation loss: 3.2047342359374484

Epoch: 6| Step: 10
Training loss: 2.399536676188963
Validation loss: 3.204444638629633

Epoch: 6| Step: 11
Training loss: 3.802149370569311
Validation loss: 3.203416810948502

Epoch: 6| Step: 12
Training loss: 2.438436083902615
Validation loss: 3.204191511447153

Epoch: 6| Step: 13
Training loss: 2.9747994876255355
Validation loss: 3.2085013604615327

Epoch: 81| Step: 0
Training loss: 3.102929263361918
Validation loss: 3.218244524670105

Epoch: 6| Step: 1
Training loss: 2.6954994910792864
Validation loss: 3.2395323030628114

Epoch: 6| Step: 2
Training loss: 3.157998988455187
Validation loss: 3.2706001153656192

Epoch: 6| Step: 3
Training loss: 3.5668692314404766
Validation loss: 3.2276672428179967

Epoch: 6| Step: 4
Training loss: 3.461186591628702
Validation loss: 3.2020451287872764

Epoch: 6| Step: 5
Training loss: 3.3852102050425494
Validation loss: 3.202567131229876

Epoch: 6| Step: 6
Training loss: 2.6295984952373974
Validation loss: 3.211940468915765

Epoch: 6| Step: 7
Training loss: 3.9997961469203585
Validation loss: 3.2279180287277023

Epoch: 6| Step: 8
Training loss: 3.2322657982523277
Validation loss: 3.232143841095097

Epoch: 6| Step: 9
Training loss: 4.684983862459283
Validation loss: 3.2185512568580754

Epoch: 6| Step: 10
Training loss: 3.456976352406628
Validation loss: 3.213524992870917

Epoch: 6| Step: 11
Training loss: 3.640285492485016
Validation loss: 3.2052536849014386

Epoch: 6| Step: 12
Training loss: 3.2564673997350426
Validation loss: 3.2037968396941063

Epoch: 6| Step: 13
Training loss: 3.971022188246177
Validation loss: 3.2044442722174735

Epoch: 82| Step: 0
Training loss: 3.3506422935911933
Validation loss: 3.2032951832003347

Epoch: 6| Step: 1
Training loss: 3.5870275897498285
Validation loss: 3.2017867091070538

Epoch: 6| Step: 2
Training loss: 3.666858769210699
Validation loss: 3.200710707555802

Epoch: 6| Step: 3
Training loss: 2.6806669975223003
Validation loss: 3.2016118078730265

Epoch: 6| Step: 4
Training loss: 3.161803694352882
Validation loss: 3.2007529803334216

Epoch: 6| Step: 5
Training loss: 3.7306942217529304
Validation loss: 3.202371095885033

Epoch: 6| Step: 6
Training loss: 3.6460797617145158
Validation loss: 3.201157751276641

Epoch: 6| Step: 7
Training loss: 4.313504309432209
Validation loss: 3.2027761746124503

Epoch: 6| Step: 8
Training loss: 3.850192122186448
Validation loss: 3.2058391478039527

Epoch: 6| Step: 9
Training loss: 3.6050426028799025
Validation loss: 3.2027455831254446

Epoch: 6| Step: 10
Training loss: 2.90163358520137
Validation loss: 3.1974988459136404

Epoch: 6| Step: 11
Training loss: 3.753338662703295
Validation loss: 3.197314370646751

Epoch: 6| Step: 12
Training loss: 2.5901623468073587
Validation loss: 3.1974884838941824

Epoch: 6| Step: 13
Training loss: 2.6921298046870668
Validation loss: 3.19616177099848

Epoch: 83| Step: 0
Training loss: 3.4130151045493244
Validation loss: 3.1961127904004463

Epoch: 6| Step: 1
Training loss: 2.7431760565664276
Validation loss: 3.197336580723937

Epoch: 6| Step: 2
Training loss: 3.064187655307435
Validation loss: 3.197677390646059

Epoch: 6| Step: 3
Training loss: 3.675390370713869
Validation loss: 3.1961980056503942

Epoch: 6| Step: 4
Training loss: 3.6682017031989345
Validation loss: 3.195167440930803

Epoch: 6| Step: 5
Training loss: 2.963242089404766
Validation loss: 3.1976113651485534

Epoch: 6| Step: 6
Training loss: 3.9715462993567847
Validation loss: 3.202392960282354

Epoch: 6| Step: 7
Training loss: 3.0480034719132
Validation loss: 3.2004558816602

Epoch: 6| Step: 8
Training loss: 3.2290338468410966
Validation loss: 3.198870138183508

Epoch: 6| Step: 9
Training loss: 3.799152083913154
Validation loss: 3.1952908246395086

Epoch: 6| Step: 10
Training loss: 3.8683685657014926
Validation loss: 3.1946512021326567

Epoch: 6| Step: 11
Training loss: 2.8614167808364344
Validation loss: 3.1952087006792493

Epoch: 6| Step: 12
Training loss: 3.9700521900964785
Validation loss: 3.1948352582384643

Epoch: 6| Step: 13
Training loss: 3.7756444822988655
Validation loss: 3.1946419350912416

Epoch: 84| Step: 0
Training loss: 3.6992272575304757
Validation loss: 3.1935879250269976

Epoch: 6| Step: 1
Training loss: 3.0195413567101235
Validation loss: 3.192379685424674

Epoch: 6| Step: 2
Training loss: 3.479387896846046
Validation loss: 3.1943344961050713

Epoch: 6| Step: 3
Training loss: 3.239928853702004
Validation loss: 3.1925312719757506

Epoch: 6| Step: 4
Training loss: 3.584210015036056
Validation loss: 3.192825995863353

Epoch: 6| Step: 5
Training loss: 3.3428434765248762
Validation loss: 3.1921789953052375

Epoch: 6| Step: 6
Training loss: 3.937166714565342
Validation loss: 3.192181517039898

Epoch: 6| Step: 7
Training loss: 3.25098448294319
Validation loss: 3.1920665239135664

Epoch: 6| Step: 8
Training loss: 3.2149784249965596
Validation loss: 3.1922296528783716

Epoch: 6| Step: 9
Training loss: 3.74572421131729
Validation loss: 3.1913612073257447

Epoch: 6| Step: 10
Training loss: 2.9918875680902137
Validation loss: 3.1907064680022894

Epoch: 6| Step: 11
Training loss: 3.3623798504886637
Validation loss: 3.1910538555596584

Epoch: 6| Step: 12
Training loss: 3.3548303425355606
Validation loss: 3.191289754035058

Epoch: 6| Step: 13
Training loss: 4.099950390027128
Validation loss: 3.1915783464906022

Epoch: 85| Step: 0
Training loss: 2.8448541195547885
Validation loss: 3.1901099779261517

Epoch: 6| Step: 1
Training loss: 3.0973523677591928
Validation loss: 3.1896299491971605

Epoch: 6| Step: 2
Training loss: 3.0253903097764523
Validation loss: 3.19082936137076

Epoch: 6| Step: 3
Training loss: 3.4872591543950544
Validation loss: 3.1907425826214584

Epoch: 6| Step: 4
Training loss: 3.2322175575060372
Validation loss: 3.1904798923383235

Epoch: 6| Step: 5
Training loss: 2.9732864253302647
Validation loss: 3.1896127112886385

Epoch: 6| Step: 6
Training loss: 3.9767346897579943
Validation loss: 3.190852840217849

Epoch: 6| Step: 7
Training loss: 4.059457196937129
Validation loss: 3.190911451015574

Epoch: 6| Step: 8
Training loss: 3.2961011222400667
Validation loss: 3.190624538602905

Epoch: 6| Step: 9
Training loss: 3.319079217188946
Validation loss: 3.1892670292395158

Epoch: 6| Step: 10
Training loss: 3.281382240173785
Validation loss: 3.190059549481319

Epoch: 6| Step: 11
Training loss: 3.8866152035516093
Validation loss: 3.188524310451055

Epoch: 6| Step: 12
Training loss: 3.753505467069523
Validation loss: 3.188465142797695

Epoch: 6| Step: 13
Training loss: 3.786328019213284
Validation loss: 3.1880661318702437

Epoch: 86| Step: 0
Training loss: 3.3497972797149305
Validation loss: 3.1871448088118246

Epoch: 6| Step: 1
Training loss: 3.230566906619792
Validation loss: 3.187667128098108

Epoch: 6| Step: 2
Training loss: 3.178316837848758
Validation loss: 3.1885489809372376

Epoch: 6| Step: 3
Training loss: 3.906157713753606
Validation loss: 3.187323516907939

Epoch: 6| Step: 4
Training loss: 3.562760862202609
Validation loss: 3.188146476969584

Epoch: 6| Step: 5
Training loss: 3.0497274495903186
Validation loss: 3.187454577192111

Epoch: 6| Step: 6
Training loss: 3.7307404903481616
Validation loss: 3.186691231440057

Epoch: 6| Step: 7
Training loss: 3.386250147800154
Validation loss: 3.1875585075733652

Epoch: 6| Step: 8
Training loss: 2.900451782814807
Validation loss: 3.1863018504903584

Epoch: 6| Step: 9
Training loss: 3.2203605104113113
Validation loss: 3.187402040479098

Epoch: 6| Step: 10
Training loss: 3.314475855752197
Validation loss: 3.1881603608118576

Epoch: 6| Step: 11
Training loss: 3.492067066138504
Validation loss: 3.187124767089612

Epoch: 6| Step: 12
Training loss: 3.569999831383966
Validation loss: 3.186564994209845

Epoch: 6| Step: 13
Training loss: 4.427131467071359
Validation loss: 3.1852296339653225

Epoch: 87| Step: 0
Training loss: 3.087662690235427
Validation loss: 3.1850179885047445

Epoch: 6| Step: 1
Training loss: 3.326023351609128
Validation loss: 3.1859501226042015

Epoch: 6| Step: 2
Training loss: 3.701411241022929
Validation loss: 3.1852775963856534

Epoch: 6| Step: 3
Training loss: 3.514646673771786
Validation loss: 3.185577213170577

Epoch: 6| Step: 4
Training loss: 3.023860300551025
Validation loss: 3.185936916321713

Epoch: 6| Step: 5
Training loss: 3.20281236565
Validation loss: 3.184323219943353

Epoch: 6| Step: 6
Training loss: 3.704361206255558
Validation loss: 3.18425757611797

Epoch: 6| Step: 7
Training loss: 3.043446024729917
Validation loss: 3.1845185203557063

Epoch: 6| Step: 8
Training loss: 3.7195105536273076
Validation loss: 3.183126582375938

Epoch: 6| Step: 9
Training loss: 3.6827879719166225
Validation loss: 3.183932372222519

Epoch: 6| Step: 10
Training loss: 3.4168508216416935
Validation loss: 3.181512543552711

Epoch: 6| Step: 11
Training loss: 3.142989601712772
Validation loss: 3.181843574311002

Epoch: 6| Step: 12
Training loss: 3.6412651579751225
Validation loss: 3.1841850761829527

Epoch: 6| Step: 13
Training loss: 3.9239984971878643
Validation loss: 3.1816107810992023

Epoch: 88| Step: 0
Training loss: 4.0879270184715395
Validation loss: 3.18076435813446

Epoch: 6| Step: 1
Training loss: 3.745318351425928
Validation loss: 3.1806273405641687

Epoch: 6| Step: 2
Training loss: 2.565997922978263
Validation loss: 3.180810096510537

Epoch: 6| Step: 3
Training loss: 2.527408086084627
Validation loss: 3.1817082195380855

Epoch: 6| Step: 4
Training loss: 4.15308506288407
Validation loss: 3.181863793519092

Epoch: 6| Step: 5
Training loss: 3.0761073901971288
Validation loss: 3.180009229668181

Epoch: 6| Step: 6
Training loss: 2.6234027907964856
Validation loss: 3.1806581060954056

Epoch: 6| Step: 7
Training loss: 3.1923542832447303
Validation loss: 3.180691129745019

Epoch: 6| Step: 8
Training loss: 4.039773136983191
Validation loss: 3.181564400746387

Epoch: 6| Step: 9
Training loss: 3.220881672866973
Validation loss: 3.180637397226021

Epoch: 6| Step: 10
Training loss: 4.0742278789297295
Validation loss: 3.1791405956395087

Epoch: 6| Step: 11
Training loss: 3.1837800702763173
Validation loss: 3.1809994231312437

Epoch: 6| Step: 12
Training loss: 3.8408385624804784
Validation loss: 3.178197589406302

Epoch: 6| Step: 13
Training loss: 2.7326561457212817
Validation loss: 3.1800336050506335

Epoch: 89| Step: 0
Training loss: 3.7033288312095474
Validation loss: 3.179937096434943

Epoch: 6| Step: 1
Training loss: 2.998094589400439
Validation loss: 3.1824771056454413

Epoch: 6| Step: 2
Training loss: 3.69237519318673
Validation loss: 3.182009488874769

Epoch: 6| Step: 3
Training loss: 3.3888120242992463
Validation loss: 3.178943666456232

Epoch: 6| Step: 4
Training loss: 3.3103649528278063
Validation loss: 3.1788717969509057

Epoch: 6| Step: 5
Training loss: 3.849538151175535
Validation loss: 3.177671659165748

Epoch: 6| Step: 6
Training loss: 3.5968879600046164
Validation loss: 3.177075420163348

Epoch: 6| Step: 7
Training loss: 3.3242368238161717
Validation loss: 3.177949057118341

Epoch: 6| Step: 8
Training loss: 3.565509261343267
Validation loss: 3.1774251209687896

Epoch: 6| Step: 9
Training loss: 4.038890606231067
Validation loss: 3.1778321710879314

Epoch: 6| Step: 10
Training loss: 2.789436122969077
Validation loss: 3.176824553850908

Epoch: 6| Step: 11
Training loss: 3.375717510671328
Validation loss: 3.177922739340145

Epoch: 6| Step: 12
Training loss: 3.068029744139599
Validation loss: 3.1769178880326487

Epoch: 6| Step: 13
Training loss: 2.8529865210395577
Validation loss: 3.1762567782752344

Epoch: 90| Step: 0
Training loss: 3.804908573691409
Validation loss: 3.176506490132752

Epoch: 6| Step: 1
Training loss: 3.236418884514939
Validation loss: 3.174797142252679

Epoch: 6| Step: 2
Training loss: 4.251843669640789
Validation loss: 3.176027775351829

Epoch: 6| Step: 3
Training loss: 2.3230991263356047
Validation loss: 3.1757637940377994

Epoch: 6| Step: 4
Training loss: 3.577638284821634
Validation loss: 3.1750990641174495

Epoch: 6| Step: 5
Training loss: 3.4788171893425552
Validation loss: 3.174277843383932

Epoch: 6| Step: 6
Training loss: 3.6896643025355673
Validation loss: 3.1753311002671794

Epoch: 6| Step: 7
Training loss: 2.830503190936871
Validation loss: 3.1747283814841527

Epoch: 6| Step: 8
Training loss: 3.7449924095087073
Validation loss: 3.1750321460014113

Epoch: 6| Step: 9
Training loss: 3.473212044246201
Validation loss: 3.174905627683213

Epoch: 6| Step: 10
Training loss: 3.0910791755737232
Validation loss: 3.175163629662827

Epoch: 6| Step: 11
Training loss: 2.523741712627436
Validation loss: 3.1752344140051534

Epoch: 6| Step: 12
Training loss: 3.8077520604398836
Validation loss: 3.1746367385196477

Epoch: 6| Step: 13
Training loss: 3.7825325296217196
Validation loss: 3.174010421124296

Epoch: 91| Step: 0
Training loss: 2.8075098484916206
Validation loss: 3.175027038146448

Epoch: 6| Step: 1
Training loss: 3.2595128440785275
Validation loss: 3.173395477516101

Epoch: 6| Step: 2
Training loss: 3.161784692014886
Validation loss: 3.1732407195901176

Epoch: 6| Step: 3
Training loss: 3.5215667021019943
Validation loss: 3.1740657648898205

Epoch: 6| Step: 4
Training loss: 3.2249258106776657
Validation loss: 3.174066306845422

Epoch: 6| Step: 5
Training loss: 2.988381776801769
Validation loss: 3.1733450031966446

Epoch: 6| Step: 6
Training loss: 3.5777950218001
Validation loss: 3.1723466513711314

Epoch: 6| Step: 7
Training loss: 3.616072217076668
Validation loss: 3.172121824081799

Epoch: 6| Step: 8
Training loss: 3.864176493134439
Validation loss: 3.1719863979535887

Epoch: 6| Step: 9
Training loss: 3.6959664086801163
Validation loss: 3.1729349373546514

Epoch: 6| Step: 10
Training loss: 4.211101465093949
Validation loss: 3.171248547832675

Epoch: 6| Step: 11
Training loss: 3.6640725206835922
Validation loss: 3.1709848445322253

Epoch: 6| Step: 12
Training loss: 2.8720711426278127
Validation loss: 3.1712758215498016

Epoch: 6| Step: 13
Training loss: 2.9887431666584465
Validation loss: 3.171602093639216

Epoch: 92| Step: 0
Training loss: 3.3161402439513488
Validation loss: 3.1706361232903255

Epoch: 6| Step: 1
Training loss: 3.9167709877784693
Validation loss: 3.1694513074169848

Epoch: 6| Step: 2
Training loss: 3.4878202776672196
Validation loss: 3.171872347350673

Epoch: 6| Step: 3
Training loss: 2.462220453960979
Validation loss: 3.171439171153589

Epoch: 6| Step: 4
Training loss: 2.5042631040803216
Validation loss: 3.17277482974533

Epoch: 6| Step: 5
Training loss: 3.5346333996984285
Validation loss: 3.1748684693172735

Epoch: 6| Step: 6
Training loss: 4.748247325185664
Validation loss: 3.1715608848720187

Epoch: 6| Step: 7
Training loss: 2.727339756748813
Validation loss: 3.171366835717702

Epoch: 6| Step: 8
Training loss: 3.9462877333501227
Validation loss: 3.1696548665374764

Epoch: 6| Step: 9
Training loss: 2.9699999938348327
Validation loss: 3.170396207209374

Epoch: 6| Step: 10
Training loss: 3.1457420150605775
Validation loss: 3.1690982529583542

Epoch: 6| Step: 11
Training loss: 3.196836970635395
Validation loss: 3.1672604645841305

Epoch: 6| Step: 12
Training loss: 3.3276171946075253
Validation loss: 3.1683041986081975

Epoch: 6| Step: 13
Training loss: 4.264218947523904
Validation loss: 3.166832758158984

Epoch: 93| Step: 0
Training loss: 3.0058206675951555
Validation loss: 3.1666397348326236

Epoch: 6| Step: 1
Training loss: 3.4673802876177224
Validation loss: 3.1652054958819034

Epoch: 6| Step: 2
Training loss: 3.11899600234147
Validation loss: 3.165868021042491

Epoch: 6| Step: 3
Training loss: 4.187123979225744
Validation loss: 3.1648766607910224

Epoch: 6| Step: 4
Training loss: 3.4177241820983597
Validation loss: 3.16447697391826

Epoch: 6| Step: 5
Training loss: 3.772213059946231
Validation loss: 3.1644084636454415

Epoch: 6| Step: 6
Training loss: 3.03551285660468
Validation loss: 3.163901313819451

Epoch: 6| Step: 7
Training loss: 2.646239682530186
Validation loss: 3.1624486293638814

Epoch: 6| Step: 8
Training loss: 3.823996298752274
Validation loss: 3.1594692055149514

Epoch: 6| Step: 9
Training loss: 3.490798025188672
Validation loss: 3.1574521061510814

Epoch: 6| Step: 10
Training loss: 3.367106213219095
Validation loss: 3.156007381939587

Epoch: 6| Step: 11
Training loss: 3.7703578220620226
Validation loss: 3.15245977411021

Epoch: 6| Step: 12
Training loss: 3.316097393414045
Validation loss: 3.1521344029780094

Epoch: 6| Step: 13
Training loss: 2.829773143396979
Validation loss: 3.151366242211594

Epoch: 94| Step: 0
Training loss: 2.2489671455789013
Validation loss: 3.1493132072211933

Epoch: 6| Step: 1
Training loss: 3.269737465028341
Validation loss: 3.1484656373760616

Epoch: 6| Step: 2
Training loss: 2.9034436530414567
Validation loss: 3.1494241415010222

Epoch: 6| Step: 3
Training loss: 3.6813849484331036
Validation loss: 3.1476980269357795

Epoch: 6| Step: 4
Training loss: 3.4805557462735
Validation loss: 3.147617607993382

Epoch: 6| Step: 5
Training loss: 3.5130186465034816
Validation loss: 3.147348520797111

Epoch: 6| Step: 6
Training loss: 3.6732044167117466
Validation loss: 3.1464679982109454

Epoch: 6| Step: 7
Training loss: 3.4933744116059313
Validation loss: 3.144883200112755

Epoch: 6| Step: 8
Training loss: 3.7937526344654673
Validation loss: 3.145024380939501

Epoch: 6| Step: 9
Training loss: 3.695990792539613
Validation loss: 3.144410610617247

Epoch: 6| Step: 10
Training loss: 3.4237459546079547
Validation loss: 3.1445141325535486

Epoch: 6| Step: 11
Training loss: 2.816540761161366
Validation loss: 3.1457633782388372

Epoch: 6| Step: 12
Training loss: 3.194772240963487
Validation loss: 3.143337181665818

Epoch: 6| Step: 13
Training loss: 4.507109853370193
Validation loss: 3.1442011838367625

Epoch: 95| Step: 0
Training loss: 3.156843677245276
Validation loss: 3.1436672390538662

Epoch: 6| Step: 1
Training loss: 3.570006910472347
Validation loss: 3.1434771874095158

Epoch: 6| Step: 2
Training loss: 3.9710591724668256
Validation loss: 3.1436168378809914

Epoch: 6| Step: 3
Training loss: 3.52107203349714
Validation loss: 3.14279414981321

Epoch: 6| Step: 4
Training loss: 2.603910286045008
Validation loss: 3.1461616224750575

Epoch: 6| Step: 5
Training loss: 2.805212370232984
Validation loss: 3.142989405952095

Epoch: 6| Step: 6
Training loss: 3.785730151120073
Validation loss: 3.1431070689707874

Epoch: 6| Step: 7
Training loss: 2.9169679940200246
Validation loss: 3.1424361522501814

Epoch: 6| Step: 8
Training loss: 2.4293141952218624
Validation loss: 3.1442027737789076

Epoch: 6| Step: 9
Training loss: 3.521025041104918
Validation loss: 3.1445146836787288

Epoch: 6| Step: 10
Training loss: 4.255077470551566
Validation loss: 3.1432341527419703

Epoch: 6| Step: 11
Training loss: 3.65291084334049
Validation loss: 3.1415847440798803

Epoch: 6| Step: 12
Training loss: 3.890618136602882
Validation loss: 3.1404770304212652

Epoch: 6| Step: 13
Training loss: 2.483432519028573
Validation loss: 3.140319871433864

Epoch: 96| Step: 0
Training loss: 3.154990218641592
Validation loss: 3.140747144667942

Epoch: 6| Step: 1
Training loss: 2.546161387816015
Validation loss: 3.14311458425934

Epoch: 6| Step: 2
Training loss: 3.060732272922411
Validation loss: 3.1402254168258916

Epoch: 6| Step: 3
Training loss: 2.6422938203089785
Validation loss: 3.140049743292296

Epoch: 6| Step: 4
Training loss: 3.4694609042421063
Validation loss: 3.139843796180487

Epoch: 6| Step: 5
Training loss: 2.8389946718988948
Validation loss: 3.1397000373457384

Epoch: 6| Step: 6
Training loss: 3.8723433216727208
Validation loss: 3.138663221898493

Epoch: 6| Step: 7
Training loss: 3.985738124668692
Validation loss: 3.1384685935064094

Epoch: 6| Step: 8
Training loss: 3.2123899864032155
Validation loss: 3.1393728113392294

Epoch: 6| Step: 9
Training loss: 3.3969132436162925
Validation loss: 3.1412669675495017

Epoch: 6| Step: 10
Training loss: 3.6141285165842136
Validation loss: 3.1437062724145517

Epoch: 6| Step: 11
Training loss: 3.6987435862494293
Validation loss: 3.1413491755477665

Epoch: 6| Step: 12
Training loss: 3.9043694203646653
Validation loss: 3.1409420334406595

Epoch: 6| Step: 13
Training loss: 4.033883823838217
Validation loss: 3.1385184296071493

Epoch: 97| Step: 0
Training loss: 2.404235194489583
Validation loss: 3.13951501244006

Epoch: 6| Step: 1
Training loss: 3.601199183477919
Validation loss: 3.137715156844544

Epoch: 6| Step: 2
Training loss: 3.7756281904773212
Validation loss: 3.1360853176732992

Epoch: 6| Step: 3
Training loss: 3.291046921216178
Validation loss: 3.137469404288995

Epoch: 6| Step: 4
Training loss: 3.458578093419851
Validation loss: 3.1364274907597274

Epoch: 6| Step: 5
Training loss: 3.3967091341767413
Validation loss: 3.1353810364586088

Epoch: 6| Step: 6
Training loss: 3.0273176032136995
Validation loss: 3.1358420175103348

Epoch: 6| Step: 7
Training loss: 2.259077199723711
Validation loss: 3.136021211396499

Epoch: 6| Step: 8
Training loss: 2.8049057899470555
Validation loss: 3.1359676936685874

Epoch: 6| Step: 9
Training loss: 2.984659071579126
Validation loss: 3.1358785935280324

Epoch: 6| Step: 10
Training loss: 3.752349117735074
Validation loss: 3.135184395560484

Epoch: 6| Step: 11
Training loss: 3.812296627436213
Validation loss: 3.135734067536611

Epoch: 6| Step: 12
Training loss: 4.230370461404374
Validation loss: 3.135712544463054

Epoch: 6| Step: 13
Training loss: 4.517622667514413
Validation loss: 3.134731594132645

Epoch: 98| Step: 0
Training loss: 4.040915560324644
Validation loss: 3.1342718795187543

Epoch: 6| Step: 1
Training loss: 3.161518798115843
Validation loss: 3.1347887419316356

Epoch: 6| Step: 2
Training loss: 3.958109370805684
Validation loss: 3.1343289743554146

Epoch: 6| Step: 3
Training loss: 2.944525575619698
Validation loss: 3.1345390541812437

Epoch: 6| Step: 4
Training loss: 3.6926525777132597
Validation loss: 3.135539553300738

Epoch: 6| Step: 5
Training loss: 4.290950727775065
Validation loss: 3.133507427972361

Epoch: 6| Step: 6
Training loss: 3.5301611918099622
Validation loss: 3.1329221970422045

Epoch: 6| Step: 7
Training loss: 3.1813678472308937
Validation loss: 3.131777158397059

Epoch: 6| Step: 8
Training loss: 2.7521781098426605
Validation loss: 3.13477576745514

Epoch: 6| Step: 9
Training loss: 2.910617786650006
Validation loss: 3.13564268461394

Epoch: 6| Step: 10
Training loss: 2.652182392948322
Validation loss: 3.13249152567174

Epoch: 6| Step: 11
Training loss: 3.7344366730900425
Validation loss: 3.134354724110345

Epoch: 6| Step: 12
Training loss: 2.808270813862021
Validation loss: 3.1330775014665475

Epoch: 6| Step: 13
Training loss: 3.2710708402346618
Validation loss: 3.134117111978775

Epoch: 99| Step: 0
Training loss: 3.0774285937406822
Validation loss: 3.1326657882975617

Epoch: 6| Step: 1
Training loss: 3.614170868102776
Validation loss: 3.1335587223334125

Epoch: 6| Step: 2
Training loss: 2.6664588867142416
Validation loss: 3.1303908162299448

Epoch: 6| Step: 3
Training loss: 3.4551243582177347
Validation loss: 3.1317069144240963

Epoch: 6| Step: 4
Training loss: 3.521265007206439
Validation loss: 3.1313339753000937

Epoch: 6| Step: 5
Training loss: 3.7964047741230615
Validation loss: 3.129766375737281

Epoch: 6| Step: 6
Training loss: 3.6260519145735652
Validation loss: 3.1311452677994835

Epoch: 6| Step: 7
Training loss: 3.8799258272219137
Validation loss: 3.1284994093584344

Epoch: 6| Step: 8
Training loss: 2.9871698045410993
Validation loss: 3.130782022478225

Epoch: 6| Step: 9
Training loss: 3.830751102193669
Validation loss: 3.1284838054025643

Epoch: 6| Step: 10
Training loss: 3.4868423552830294
Validation loss: 3.1296755000889322

Epoch: 6| Step: 11
Training loss: 2.374109201517997
Validation loss: 3.129603747566336

Epoch: 6| Step: 12
Training loss: 3.510400849409531
Validation loss: 3.128843766444617

Epoch: 6| Step: 13
Training loss: 3.1403085729510103
Validation loss: 3.128084271079265

Epoch: 100| Step: 0
Training loss: 3.031582843557721
Validation loss: 3.130540005302971

Epoch: 6| Step: 1
Training loss: 2.997908658000825
Validation loss: 3.1305968455544297

Epoch: 6| Step: 2
Training loss: 3.5106684352041104
Validation loss: 3.133888828749245

Epoch: 6| Step: 3
Training loss: 2.945865973723863
Validation loss: 3.1330877246652484

Epoch: 6| Step: 4
Training loss: 4.3377796006025156
Validation loss: 3.134382922474843

Epoch: 6| Step: 5
Training loss: 3.434371634456523
Validation loss: 3.1305487840405153

Epoch: 6| Step: 6
Training loss: 2.8737317480674975
Validation loss: 3.135642668262328

Epoch: 6| Step: 7
Training loss: 2.401664923306145
Validation loss: 3.13477069704948

Epoch: 6| Step: 8
Training loss: 3.3412580384551287
Validation loss: 3.13062406234215

Epoch: 6| Step: 9
Training loss: 3.491479447716352
Validation loss: 3.127350926609575

Epoch: 6| Step: 10
Training loss: 3.6847363476786636
Validation loss: 3.1278097093656885

Epoch: 6| Step: 11
Training loss: 3.6340537299056024
Validation loss: 3.126485116475563

Epoch: 6| Step: 12
Training loss: 3.2481321689511184
Validation loss: 3.1254246363748814

Epoch: 6| Step: 13
Training loss: 4.477202417994882
Validation loss: 3.1249907019692196

Epoch: 101| Step: 0
Training loss: 3.6074139440559816
Validation loss: 3.1236661611642416

Epoch: 6| Step: 1
Training loss: 3.5918032473434502
Validation loss: 3.1253786739498177

Epoch: 6| Step: 2
Training loss: 3.138495335245912
Validation loss: 3.1249848215698464

Epoch: 6| Step: 3
Training loss: 3.4997880054031376
Validation loss: 3.1242696355692363

Epoch: 6| Step: 4
Training loss: 2.6727022373911873
Validation loss: 3.1218226599127075

Epoch: 6| Step: 5
Training loss: 3.3565360915222415
Validation loss: 3.122646710714671

Epoch: 6| Step: 6
Training loss: 3.357776634198722
Validation loss: 3.122068841026061

Epoch: 6| Step: 7
Training loss: 3.0838575862553523
Validation loss: 3.119664966868023

Epoch: 6| Step: 8
Training loss: 2.7277214844284505
Validation loss: 3.1202460834626717

Epoch: 6| Step: 9
Training loss: 3.4592256122646656
Validation loss: 3.1207744307673795

Epoch: 6| Step: 10
Training loss: 3.9253168694947345
Validation loss: 3.11837884202504

Epoch: 6| Step: 11
Training loss: 3.301730228321259
Validation loss: 3.1188925096317823

Epoch: 6| Step: 12
Training loss: 3.4044883442193328
Validation loss: 3.1171669788822634

Epoch: 6| Step: 13
Training loss: 4.384291890472094
Validation loss: 3.118798058748837

Epoch: 102| Step: 0
Training loss: 3.938672814467928
Validation loss: 3.1181043103739894

Epoch: 6| Step: 1
Training loss: 2.9408731775421257
Validation loss: 3.1172230201630335

Epoch: 6| Step: 2
Training loss: 2.9909729247964174
Validation loss: 3.1147689036974135

Epoch: 6| Step: 3
Training loss: 3.5926307593900364
Validation loss: 3.1162639932487037

Epoch: 6| Step: 4
Training loss: 3.0880592488351652
Validation loss: 3.119525256616677

Epoch: 6| Step: 5
Training loss: 3.299762636375668
Validation loss: 3.1202474834941265

Epoch: 6| Step: 6
Training loss: 3.7345134118896914
Validation loss: 3.120117013310443

Epoch: 6| Step: 7
Training loss: 3.9521529016453045
Validation loss: 3.121526907162635

Epoch: 6| Step: 8
Training loss: 3.585016003390762
Validation loss: 3.1219243720824945

Epoch: 6| Step: 9
Training loss: 2.98206979288443
Validation loss: 3.1199179838852644

Epoch: 6| Step: 10
Training loss: 3.4125607327936134
Validation loss: 3.120381319985734

Epoch: 6| Step: 11
Training loss: 2.842917184134059
Validation loss: 3.1301570891756683

Epoch: 6| Step: 12
Training loss: 2.8064737821190633
Validation loss: 3.1246620865112718

Epoch: 6| Step: 13
Training loss: 4.105192775869457
Validation loss: 3.12477468026952

Epoch: 103| Step: 0
Training loss: 3.320233943234298
Validation loss: 3.1152129061539027

Epoch: 6| Step: 1
Training loss: 4.049069314149984
Validation loss: 3.114646185553782

Epoch: 6| Step: 2
Training loss: 3.0690718223741706
Validation loss: 3.1130984479593278

Epoch: 6| Step: 3
Training loss: 2.597685253010082
Validation loss: 3.111676697463869

Epoch: 6| Step: 4
Training loss: 3.746341701094205
Validation loss: 3.1118856109726964

Epoch: 6| Step: 5
Training loss: 3.1820199270817295
Validation loss: 3.1124419658502327

Epoch: 6| Step: 6
Training loss: 3.7818945973685554
Validation loss: 3.1107769540438817

Epoch: 6| Step: 7
Training loss: 2.9888227782408654
Validation loss: 3.112249936573692

Epoch: 6| Step: 8
Training loss: 3.5213034652643076
Validation loss: 3.112522971584965

Epoch: 6| Step: 9
Training loss: 3.3002945219449114
Validation loss: 3.11231757361338

Epoch: 6| Step: 10
Training loss: 3.7135758507623398
Validation loss: 3.112088608985154

Epoch: 6| Step: 11
Training loss: 2.8979062315814454
Validation loss: 3.112505768709108

Epoch: 6| Step: 12
Training loss: 3.815575781652387
Validation loss: 3.1106281596626393

Epoch: 6| Step: 13
Training loss: 2.5243531446651266
Validation loss: 3.110834829514359

Epoch: 104| Step: 0
Training loss: 3.3208702426775383
Validation loss: 3.1111114891870426

Epoch: 6| Step: 1
Training loss: 2.4512319853809807
Validation loss: 3.1128148310724195

Epoch: 6| Step: 2
Training loss: 3.122367971177728
Validation loss: 3.111037602730596

Epoch: 6| Step: 3
Training loss: 3.3381843236791795
Validation loss: 3.1108652469162568

Epoch: 6| Step: 4
Training loss: 3.59434809476188
Validation loss: 3.1127043694070577

Epoch: 6| Step: 5
Training loss: 3.4552633301654643
Validation loss: 3.1107617795614773

Epoch: 6| Step: 6
Training loss: 2.896501825322518
Validation loss: 3.1075679569685577

Epoch: 6| Step: 7
Training loss: 4.01234676270502
Validation loss: 3.109167543794384

Epoch: 6| Step: 8
Training loss: 3.1932514137426806
Validation loss: 3.109460432214937

Epoch: 6| Step: 9
Training loss: 3.3482568618247237
Validation loss: 3.108912264865362

Epoch: 6| Step: 10
Training loss: 3.669342076422381
Validation loss: 3.108974471184155

Epoch: 6| Step: 11
Training loss: 3.118358726649532
Validation loss: 3.109407453305274

Epoch: 6| Step: 12
Training loss: 3.4405684214417347
Validation loss: 3.108655914333365

Epoch: 6| Step: 13
Training loss: 4.332366517614171
Validation loss: 3.1095704072771215

Epoch: 105| Step: 0
Training loss: 3.29661334839053
Validation loss: 3.1108563829649856

Epoch: 6| Step: 1
Training loss: 3.5400494342520474
Validation loss: 3.1074040267762895

Epoch: 6| Step: 2
Training loss: 2.2503444619882793
Validation loss: 3.105914836370936

Epoch: 6| Step: 3
Training loss: 3.5685660934495624
Validation loss: 3.112338547617479

Epoch: 6| Step: 4
Training loss: 3.439161142046402
Validation loss: 3.1068992625677594

Epoch: 6| Step: 5
Training loss: 3.118572185699249
Validation loss: 3.1065356199378606

Epoch: 6| Step: 6
Training loss: 3.315994434825981
Validation loss: 3.107131982539115

Epoch: 6| Step: 7
Training loss: 3.29335912017405
Validation loss: 3.108792998385832

Epoch: 6| Step: 8
Training loss: 2.7598887292574097
Validation loss: 3.109099452332949

Epoch: 6| Step: 9
Training loss: 3.926590960301193
Validation loss: 3.1058680057850023

Epoch: 6| Step: 10
Training loss: 1.9974472921242385
Validation loss: 3.107416877111691

Epoch: 6| Step: 11
Training loss: 4.107737167671743
Validation loss: 3.1087873462858373

Epoch: 6| Step: 12
Training loss: 4.363245841815821
Validation loss: 3.107819622723334

Epoch: 6| Step: 13
Training loss: 3.3609643769264723
Validation loss: 3.1057765876996983

Epoch: 106| Step: 0
Training loss: 4.5406104910002405
Validation loss: 3.106793287460634

Epoch: 6| Step: 1
Training loss: 3.273483385297063
Validation loss: 3.1042857444923073

Epoch: 6| Step: 2
Training loss: 3.431613390081169
Validation loss: 3.1078214045069816

Epoch: 6| Step: 3
Training loss: 3.2477329857161576
Validation loss: 3.103627492478295

Epoch: 6| Step: 4
Training loss: 3.8826214073638345
Validation loss: 3.1057454023176403

Epoch: 6| Step: 5
Training loss: 3.043027355721749
Validation loss: 3.103352070575579

Epoch: 6| Step: 6
Training loss: 2.882845250385615
Validation loss: 3.1035660149304434

Epoch: 6| Step: 7
Training loss: 3.006816748730993
Validation loss: 3.101844338986309

Epoch: 6| Step: 8
Training loss: 3.3134638985353337
Validation loss: 3.1018506219503275

Epoch: 6| Step: 9
Training loss: 3.677864027852722
Validation loss: 3.102535585410551

Epoch: 6| Step: 10
Training loss: 3.1448709055691477
Validation loss: 3.1036487102346357

Epoch: 6| Step: 11
Training loss: 2.8608751374577714
Validation loss: 3.103052222642206

Epoch: 6| Step: 12
Training loss: 3.445765597420719
Validation loss: 3.1018182747155336

Epoch: 6| Step: 13
Training loss: 2.6863383066778472
Validation loss: 3.103385480682259

Epoch: 107| Step: 0
Training loss: 3.1727233654176024
Validation loss: 3.1031522252918022

Epoch: 6| Step: 1
Training loss: 3.841548630451911
Validation loss: 3.104569664911146

Epoch: 6| Step: 2
Training loss: 3.7432594754911785
Validation loss: 3.105698590638873

Epoch: 6| Step: 3
Training loss: 3.611337895893353
Validation loss: 3.104201359103157

Epoch: 6| Step: 4
Training loss: 3.1028435125154443
Validation loss: 3.103690010391609

Epoch: 6| Step: 5
Training loss: 3.56969942467765
Validation loss: 3.1025738926733903

Epoch: 6| Step: 6
Training loss: 3.3995314667944445
Validation loss: 3.102396519295573

Epoch: 6| Step: 7
Training loss: 2.7922123238133025
Validation loss: 3.101460278769668

Epoch: 6| Step: 8
Training loss: 3.5987329849524627
Validation loss: 3.1026949920740825

Epoch: 6| Step: 9
Training loss: 3.359955067788281
Validation loss: 3.1017934764281123

Epoch: 6| Step: 10
Training loss: 3.724322079408798
Validation loss: 3.1004699516871925

Epoch: 6| Step: 11
Training loss: 2.861726888009262
Validation loss: 3.1020664565997365

Epoch: 6| Step: 12
Training loss: 3.027740019427715
Validation loss: 3.099797264010211

Epoch: 6| Step: 13
Training loss: 2.832297603315216
Validation loss: 3.100304323145216

Epoch: 108| Step: 0
Training loss: 3.502346614553117
Validation loss: 3.100599307224477

Epoch: 6| Step: 1
Training loss: 3.356269287963228
Validation loss: 3.1004780069030202

Epoch: 6| Step: 2
Training loss: 2.735525532222093
Validation loss: 3.101174045036725

Epoch: 6| Step: 3
Training loss: 2.692414160080023
Validation loss: 3.101520773103596

Epoch: 6| Step: 4
Training loss: 3.3843419799884598
Validation loss: 3.10086152324532

Epoch: 6| Step: 5
Training loss: 3.5774942033615442
Validation loss: 3.100975891401362

Epoch: 6| Step: 6
Training loss: 3.0857010762875507
Validation loss: 3.098930814722027

Epoch: 6| Step: 7
Training loss: 3.202916878242497
Validation loss: 3.0983150309104555

Epoch: 6| Step: 8
Training loss: 3.4892405934713673
Validation loss: 3.098199729621973

Epoch: 6| Step: 9
Training loss: 4.453118361083319
Validation loss: 3.0968605762443517

Epoch: 6| Step: 10
Training loss: 3.2290209993711536
Validation loss: 3.0971551665286685

Epoch: 6| Step: 11
Training loss: 3.5285392416682395
Validation loss: 3.0975489688142184

Epoch: 6| Step: 12
Training loss: 2.9786741120744282
Validation loss: 3.098028842548963

Epoch: 6| Step: 13
Training loss: 3.595789057229553
Validation loss: 3.0959758571767595

Epoch: 109| Step: 0
Training loss: 3.1476422765691017
Validation loss: 3.0989846610094176

Epoch: 6| Step: 1
Training loss: 3.1554361937189976
Validation loss: 3.0959762364262735

Epoch: 6| Step: 2
Training loss: 3.5294646754693186
Validation loss: 3.0964658700767815

Epoch: 6| Step: 3
Training loss: 3.458138671053737
Validation loss: 3.0974467483839154

Epoch: 6| Step: 4
Training loss: 3.688171713474541
Validation loss: 3.0980092587057753

Epoch: 6| Step: 5
Training loss: 2.9398080402428595
Validation loss: 3.0981759118819516

Epoch: 6| Step: 6
Training loss: 3.9233925607554254
Validation loss: 3.0970185085305943

Epoch: 6| Step: 7
Training loss: 3.0353565518184977
Validation loss: 3.0974616379971773

Epoch: 6| Step: 8
Training loss: 3.608262059753686
Validation loss: 3.0971533901971364

Epoch: 6| Step: 9
Training loss: 2.792312395561123
Validation loss: 3.0977856468935854

Epoch: 6| Step: 10
Training loss: 3.175101607491563
Validation loss: 3.0992756331695848

Epoch: 6| Step: 11
Training loss: 3.9203096586652717
Validation loss: 3.0972731520616894

Epoch: 6| Step: 12
Training loss: 3.2552858063697485
Validation loss: 3.097366491390886

Epoch: 6| Step: 13
Training loss: 3.0602963362673696
Validation loss: 3.0958655499041394

Epoch: 110| Step: 0
Training loss: 3.655858728062503
Validation loss: 3.0982242174173904

Epoch: 6| Step: 1
Training loss: 4.085547696660688
Validation loss: 3.0937911621617022

Epoch: 6| Step: 2
Training loss: 3.34616771529854
Validation loss: 3.0952046888595777

Epoch: 6| Step: 3
Training loss: 3.2620821630443566
Validation loss: 3.0919442954815057

Epoch: 6| Step: 4
Training loss: 3.047067019940853
Validation loss: 3.0956255233984593

Epoch: 6| Step: 5
Training loss: 2.8695147058190207
Validation loss: 3.092420478565228

Epoch: 6| Step: 6
Training loss: 3.4481437277963782
Validation loss: 3.093761087337451

Epoch: 6| Step: 7
Training loss: 3.2774359925375602
Validation loss: 3.0939742349184662

Epoch: 6| Step: 8
Training loss: 3.2541643019768154
Validation loss: 3.0941858897108014

Epoch: 6| Step: 9
Training loss: 3.4408734501275227
Validation loss: 3.093834946386916

Epoch: 6| Step: 10
Training loss: 3.06735825065779
Validation loss: 3.09369105911333

Epoch: 6| Step: 11
Training loss: 2.8968596983734898
Validation loss: 3.094815109500515

Epoch: 6| Step: 12
Training loss: 3.526845294800932
Validation loss: 3.0935137159121564

Epoch: 6| Step: 13
Training loss: 3.8796800223872636
Validation loss: 3.093985673602458

Epoch: 111| Step: 0
Training loss: 4.0359223959563
Validation loss: 3.0929373258697743

Epoch: 6| Step: 1
Training loss: 3.2221439578610798
Validation loss: 3.0904032484294386

Epoch: 6| Step: 2
Training loss: 3.0992447579140965
Validation loss: 3.0916599204507214

Epoch: 6| Step: 3
Training loss: 3.5655148782533357
Validation loss: 3.0903071586266377

Epoch: 6| Step: 4
Training loss: 3.1222103637554586
Validation loss: 3.0918783055448396

Epoch: 6| Step: 5
Training loss: 3.687471551300483
Validation loss: 3.096173098743643

Epoch: 6| Step: 6
Training loss: 2.9237937135270426
Validation loss: 3.0934735362423087

Epoch: 6| Step: 7
Training loss: 2.812684116694873
Validation loss: 3.096135778767198

Epoch: 6| Step: 8
Training loss: 3.9914194103478726
Validation loss: 3.095365836302082

Epoch: 6| Step: 9
Training loss: 2.412313970004811
Validation loss: 3.092459019725753

Epoch: 6| Step: 10
Training loss: 3.0623290345096144
Validation loss: 3.0927093502431457

Epoch: 6| Step: 11
Training loss: 3.4621466941849337
Validation loss: 3.0910466957126985

Epoch: 6| Step: 12
Training loss: 3.978984102917725
Validation loss: 3.0904930988835444

Epoch: 6| Step: 13
Training loss: 3.115295294760927
Validation loss: 3.0896815262886044

Epoch: 112| Step: 0
Training loss: 3.1861307531754823
Validation loss: 3.0893821721572734

Epoch: 6| Step: 1
Training loss: 3.0112939280167663
Validation loss: 3.089107410495474

Epoch: 6| Step: 2
Training loss: 3.8821716393757297
Validation loss: 3.0881171798133016

Epoch: 6| Step: 3
Training loss: 2.574684297782128
Validation loss: 3.090642152598453

Epoch: 6| Step: 4
Training loss: 2.0990008656725796
Validation loss: 3.091333462462391

Epoch: 6| Step: 5
Training loss: 3.81573436683422
Validation loss: 3.0877498141534665

Epoch: 6| Step: 6
Training loss: 3.4486720860505846
Validation loss: 3.0898115923542266

Epoch: 6| Step: 7
Training loss: 2.9098098446306038
Validation loss: 3.0892469959988365

Epoch: 6| Step: 8
Training loss: 4.535591098069436
Validation loss: 3.0893534418889383

Epoch: 6| Step: 9
Training loss: 3.6812700565743817
Validation loss: 3.08933121064184

Epoch: 6| Step: 10
Training loss: 3.280699474836038
Validation loss: 3.0897645575230923

Epoch: 6| Step: 11
Training loss: 3.3115744107327294
Validation loss: 3.0925708660388445

Epoch: 6| Step: 12
Training loss: 3.2071552508190875
Validation loss: 3.0909215104480525

Epoch: 6| Step: 13
Training loss: 3.3516342048710683
Validation loss: 3.0893420731860717

Epoch: 113| Step: 0
Training loss: 3.6316666959844564
Validation loss: 3.0897075004443364

Epoch: 6| Step: 1
Training loss: 3.3612188912197287
Validation loss: 3.0883263704843804

Epoch: 6| Step: 2
Training loss: 2.2152413578155463
Validation loss: 3.0878130661685326

Epoch: 6| Step: 3
Training loss: 3.445419621261995
Validation loss: 3.08710151589534

Epoch: 6| Step: 4
Training loss: 3.7518545015668896
Validation loss: 3.087348376417049

Epoch: 6| Step: 5
Training loss: 3.7628336964398237
Validation loss: 3.0889047114883597

Epoch: 6| Step: 6
Training loss: 3.61184119318798
Validation loss: 3.0886281991597806

Epoch: 6| Step: 7
Training loss: 2.8388542539802564
Validation loss: 3.0865694062865088

Epoch: 6| Step: 8
Training loss: 3.644601377607729
Validation loss: 3.089634876143371

Epoch: 6| Step: 9
Training loss: 2.9533786563825632
Validation loss: 3.0883336272692588

Epoch: 6| Step: 10
Training loss: 3.1238794988233693
Validation loss: 3.085062939255497

Epoch: 6| Step: 11
Training loss: 3.415791996593068
Validation loss: 3.091514566999355

Epoch: 6| Step: 12
Training loss: 3.3182889628896626
Validation loss: 3.087730503864767

Epoch: 6| Step: 13
Training loss: 3.5914546104429705
Validation loss: 3.0869775375960153

Epoch: 114| Step: 0
Training loss: 3.846603698832145
Validation loss: 3.091769880261257

Epoch: 6| Step: 1
Training loss: 3.0693051770253077
Validation loss: 3.094703945712708

Epoch: 6| Step: 2
Training loss: 2.7497072063979373
Validation loss: 3.0919477164924944

Epoch: 6| Step: 3
Training loss: 3.7576910621863857
Validation loss: 3.087212395397047

Epoch: 6| Step: 4
Training loss: 2.8943042331480213
Validation loss: 3.085684220706928

Epoch: 6| Step: 5
Training loss: 3.061692267573735
Validation loss: 3.0864807008045054

Epoch: 6| Step: 6
Training loss: 3.855423607218936
Validation loss: 3.0832183160146216

Epoch: 6| Step: 7
Training loss: 3.624754272551031
Validation loss: 3.0829644108580587

Epoch: 6| Step: 8
Training loss: 2.684035618814319
Validation loss: 3.0861534540501157

Epoch: 6| Step: 9
Training loss: 3.9142425556607883
Validation loss: 3.0850442254193937

Epoch: 6| Step: 10
Training loss: 3.710264895871207
Validation loss: 3.0861342160117573

Epoch: 6| Step: 11
Training loss: 2.9710035905742487
Validation loss: 3.084852053016421

Epoch: 6| Step: 12
Training loss: 3.1627040631343926
Validation loss: 3.084855827605426

Epoch: 6| Step: 13
Training loss: 3.164252381455203
Validation loss: 3.0847669781064364

Epoch: 115| Step: 0
Training loss: 3.1242421566429077
Validation loss: 3.083555016257389

Epoch: 6| Step: 1
Training loss: 2.168312719053094
Validation loss: 3.083097346309326

Epoch: 6| Step: 2
Training loss: 3.6042801208867403
Validation loss: 3.085331923980537

Epoch: 6| Step: 3
Training loss: 4.006531151771715
Validation loss: 3.0841510645075174

Epoch: 6| Step: 4
Training loss: 3.562825505962578
Validation loss: 3.0824781033836084

Epoch: 6| Step: 5
Training loss: 3.6634518372722837
Validation loss: 3.0823010648691507

Epoch: 6| Step: 6
Training loss: 2.8789852550747788
Validation loss: 3.081455264594528

Epoch: 6| Step: 7
Training loss: 3.6860164955668364
Validation loss: 3.0809658631815515

Epoch: 6| Step: 8
Training loss: 3.9211583185589562
Validation loss: 3.0819636370414445

Epoch: 6| Step: 9
Training loss: 3.263553820426187
Validation loss: 3.081511585124667

Epoch: 6| Step: 10
Training loss: 2.717062941904997
Validation loss: 3.0812964747080915

Epoch: 6| Step: 11
Training loss: 3.383488470820868
Validation loss: 3.080899664724778

Epoch: 6| Step: 12
Training loss: 3.280962104883139
Validation loss: 3.0805335987568996

Epoch: 6| Step: 13
Training loss: 2.988307100072016
Validation loss: 3.082239201873717

Epoch: 116| Step: 0
Training loss: 4.286587471791555
Validation loss: 3.0809363396576805

Epoch: 6| Step: 1
Training loss: 3.337601329393936
Validation loss: 3.082195924153433

Epoch: 6| Step: 2
Training loss: 3.793417906955294
Validation loss: 3.0792037500275975

Epoch: 6| Step: 3
Training loss: 3.2241461991322455
Validation loss: 3.0801340112736098

Epoch: 6| Step: 4
Training loss: 3.6243192099224095
Validation loss: 3.0797086583020024

Epoch: 6| Step: 5
Training loss: 3.768137872939362
Validation loss: 3.0791283918832644

Epoch: 6| Step: 6
Training loss: 3.2770530380785545
Validation loss: 3.078643348749151

Epoch: 6| Step: 7
Training loss: 2.9511334197734453
Validation loss: 3.078950637867238

Epoch: 6| Step: 8
Training loss: 2.8312859337149523
Validation loss: 3.0802082819752097

Epoch: 6| Step: 9
Training loss: 2.620865608667543
Validation loss: 3.0776781159925144

Epoch: 6| Step: 10
Training loss: 3.3048164937701334
Validation loss: 3.0744126018715816

Epoch: 6| Step: 11
Training loss: 2.7015415912302236
Validation loss: 3.078392059282834

Epoch: 6| Step: 12
Training loss: 2.9827761536467454
Validation loss: 3.0754813699808428

Epoch: 6| Step: 13
Training loss: 3.95734406540573
Validation loss: 3.07562620501643

Epoch: 117| Step: 0
Training loss: 2.6731027381296424
Validation loss: 3.076793678621819

Epoch: 6| Step: 1
Training loss: 3.708596352382829
Validation loss: 3.0766341998490887

Epoch: 6| Step: 2
Training loss: 4.047399538429786
Validation loss: 3.075816420048931

Epoch: 6| Step: 3
Training loss: 3.51677742613402
Validation loss: 3.0775227298698384

Epoch: 6| Step: 4
Training loss: 3.570915588594771
Validation loss: 3.0755705210717794

Epoch: 6| Step: 5
Training loss: 3.4839493701115947
Validation loss: 3.0748696393702337

Epoch: 6| Step: 6
Training loss: 2.2828777202085977
Validation loss: 3.0751109941821064

Epoch: 6| Step: 7
Training loss: 3.327544398996792
Validation loss: 3.0746600967898554

Epoch: 6| Step: 8
Training loss: 4.024379819869182
Validation loss: 3.075201168061306

Epoch: 6| Step: 9
Training loss: 4.0975957380541495
Validation loss: 3.075222562773654

Epoch: 6| Step: 10
Training loss: 3.0493395105835073
Validation loss: 3.075296353548455

Epoch: 6| Step: 11
Training loss: 2.29522978320046
Validation loss: 3.077284643298089

Epoch: 6| Step: 12
Training loss: 3.038368283097108
Validation loss: 3.077296086536651

Epoch: 6| Step: 13
Training loss: 2.6884388725279917
Validation loss: 3.0761655112528046

Epoch: 118| Step: 0
Training loss: 3.5112776940768833
Validation loss: 3.0747435695195278

Epoch: 6| Step: 1
Training loss: 3.396783957011448
Validation loss: 3.075202968744204

Epoch: 6| Step: 2
Training loss: 3.491029141901352
Validation loss: 3.07389781479772

Epoch: 6| Step: 3
Training loss: 3.264922143963028
Validation loss: 3.075101116794562

Epoch: 6| Step: 4
Training loss: 2.8417045866672597
Validation loss: 3.074675198473846

Epoch: 6| Step: 5
Training loss: 3.2755485774097735
Validation loss: 3.073710881472928

Epoch: 6| Step: 6
Training loss: 2.6613175466269285
Validation loss: 3.0734160701396367

Epoch: 6| Step: 7
Training loss: 3.798634062764911
Validation loss: 3.074116822076047

Epoch: 6| Step: 8
Training loss: 3.7584013606397457
Validation loss: 3.0727939284339985

Epoch: 6| Step: 9
Training loss: 3.5022484505371048
Validation loss: 3.0731599094455633

Epoch: 6| Step: 10
Training loss: 3.00994749714125
Validation loss: 3.0740204149942536

Epoch: 6| Step: 11
Training loss: 3.847943507281453
Validation loss: 3.073846625756664

Epoch: 6| Step: 12
Training loss: 3.5594814964485444
Validation loss: 3.0735612151922105

Epoch: 6| Step: 13
Training loss: 1.7010619941551173
Validation loss: 3.071332128308826

Epoch: 119| Step: 0
Training loss: 3.640719040077685
Validation loss: 3.0733813749769787

Epoch: 6| Step: 1
Training loss: 3.397262334981016
Validation loss: 3.073558372596695

Epoch: 6| Step: 2
Training loss: 3.240669943222883
Validation loss: 3.074900460901923

Epoch: 6| Step: 3
Training loss: 3.679986832221978
Validation loss: 3.0722849690728666

Epoch: 6| Step: 4
Training loss: 2.4138541023646067
Validation loss: 3.072269241488068

Epoch: 6| Step: 5
Training loss: 3.324479519828448
Validation loss: 3.07398694759819

Epoch: 6| Step: 6
Training loss: 3.5544338261562736
Validation loss: 3.076727738689591

Epoch: 6| Step: 7
Training loss: 2.8254138744636546
Validation loss: 3.078757212454139

Epoch: 6| Step: 8
Training loss: 3.310960663898516
Validation loss: 3.0759767788275716

Epoch: 6| Step: 9
Training loss: 4.2110790448294555
Validation loss: 3.077470492354323

Epoch: 6| Step: 10
Training loss: 2.557644593746348
Validation loss: 3.0718305305871882

Epoch: 6| Step: 11
Training loss: 3.5178055845912586
Validation loss: 3.073984328902938

Epoch: 6| Step: 12
Training loss: 3.1523133457234964
Validation loss: 3.0723269178059684

Epoch: 6| Step: 13
Training loss: 3.6074801669034926
Validation loss: 3.0703359485724335

Epoch: 120| Step: 0
Training loss: 3.9971568016464207
Validation loss: 3.0725584115743647

Epoch: 6| Step: 1
Training loss: 4.780911302724773
Validation loss: 3.070706460340769

Epoch: 6| Step: 2
Training loss: 3.039546663212572
Validation loss: 3.071529465059588

Epoch: 6| Step: 3
Training loss: 3.769177166214788
Validation loss: 3.0734234547184776

Epoch: 6| Step: 4
Training loss: 3.5862098208144837
Validation loss: 3.069941602477966

Epoch: 6| Step: 5
Training loss: 2.860517096556562
Validation loss: 3.0722311304658474

Epoch: 6| Step: 6
Training loss: 3.5222169914835195
Validation loss: 3.0710143783451307

Epoch: 6| Step: 7
Training loss: 2.107806491489768
Validation loss: 3.0733234423411786

Epoch: 6| Step: 8
Training loss: 3.0719725801913116
Validation loss: 3.072022582071815

Epoch: 6| Step: 9
Training loss: 3.002119904788863
Validation loss: 3.0704106566692193

Epoch: 6| Step: 10
Training loss: 3.0586205648170033
Validation loss: 3.070157306398475

Epoch: 6| Step: 11
Training loss: 3.3929303326277465
Validation loss: 3.0697852652185302

Epoch: 6| Step: 12
Training loss: 2.6961594287584707
Validation loss: 3.0673013050067803

Epoch: 6| Step: 13
Training loss: 2.8375159040501083
Validation loss: 3.066752140687339

Epoch: 121| Step: 0
Training loss: 3.5016419782559547
Validation loss: 3.068521233811332

Epoch: 6| Step: 1
Training loss: 2.986468634284387
Validation loss: 3.068296729596936

Epoch: 6| Step: 2
Training loss: 3.2332401956993446
Validation loss: 3.0698447260580752

Epoch: 6| Step: 3
Training loss: 2.802799960442346
Validation loss: 3.0725580644777692

Epoch: 6| Step: 4
Training loss: 3.7739375002345055
Validation loss: 3.0774056548910926

Epoch: 6| Step: 5
Training loss: 2.8538448031598462
Validation loss: 3.089469401928169

Epoch: 6| Step: 6
Training loss: 3.758738699040679
Validation loss: 3.090992717778014

Epoch: 6| Step: 7
Training loss: 3.5480407949981623
Validation loss: 3.0777376667370238

Epoch: 6| Step: 8
Training loss: 3.5937064790163675
Validation loss: 3.0695479899605576

Epoch: 6| Step: 9
Training loss: 3.5911335584150863
Validation loss: 3.0674718813772395

Epoch: 6| Step: 10
Training loss: 3.5600108770140024
Validation loss: 3.065051521224629

Epoch: 6| Step: 11
Training loss: 2.169744201033546
Validation loss: 3.0670253835336156

Epoch: 6| Step: 12
Training loss: 3.389219634448288
Validation loss: 3.0709064452621218

Epoch: 6| Step: 13
Training loss: 3.760305358986457
Validation loss: 3.066874470654379

Epoch: 122| Step: 0
Training loss: 3.432597878457427
Validation loss: 3.0686768067296013

Epoch: 6| Step: 1
Training loss: 3.4036586598760485
Validation loss: 3.066618473277083

Epoch: 6| Step: 2
Training loss: 2.292150400143643
Validation loss: 3.066236102622823

Epoch: 6| Step: 3
Training loss: 3.615187683298563
Validation loss: 3.0648638885793247

Epoch: 6| Step: 4
Training loss: 3.1647870023146156
Validation loss: 3.064776408514607

Epoch: 6| Step: 5
Training loss: 3.533933447012006
Validation loss: 3.062938070367689

Epoch: 6| Step: 6
Training loss: 3.643170821418233
Validation loss: 3.0637104420668164

Epoch: 6| Step: 7
Training loss: 3.120378662997214
Validation loss: 3.062809811914899

Epoch: 6| Step: 8
Training loss: 3.3774103105610056
Validation loss: 3.0621118649067154

Epoch: 6| Step: 9
Training loss: 3.753588929990427
Validation loss: 3.063773771998344

Epoch: 6| Step: 10
Training loss: 3.02066977924138
Validation loss: 3.064575734122828

Epoch: 6| Step: 11
Training loss: 2.6301651047783206
Validation loss: 3.063549540799348

Epoch: 6| Step: 12
Training loss: 3.562002582289945
Validation loss: 3.0619998562830864

Epoch: 6| Step: 13
Training loss: 4.081369563596078
Validation loss: 3.063202187100687

Epoch: 123| Step: 0
Training loss: 2.717176135293316
Validation loss: 3.0615466720328213

Epoch: 6| Step: 1
Training loss: 2.70415067232062
Validation loss: 3.0633639133565125

Epoch: 6| Step: 2
Training loss: 3.7135314227904086
Validation loss: 3.0643597786940826

Epoch: 6| Step: 3
Training loss: 3.3465712579549702
Validation loss: 3.062547909778553

Epoch: 6| Step: 4
Training loss: 3.621371590861214
Validation loss: 3.064497872996072

Epoch: 6| Step: 5
Training loss: 3.415355306659549
Validation loss: 3.063699433416543

Epoch: 6| Step: 6
Training loss: 3.159340280404321
Validation loss: 3.0665496376716965

Epoch: 6| Step: 7
Training loss: 2.967583196127775
Validation loss: 3.0640299384397673

Epoch: 6| Step: 8
Training loss: 2.4095080228863144
Validation loss: 3.0702496472902423

Epoch: 6| Step: 9
Training loss: 3.866484853701275
Validation loss: 3.0689876833180367

Epoch: 6| Step: 10
Training loss: 3.601088751294829
Validation loss: 3.0720341417144676

Epoch: 6| Step: 11
Training loss: 3.8698284956906774
Validation loss: 3.065863836463199

Epoch: 6| Step: 12
Training loss: 3.11649094832532
Validation loss: 3.0644124555403045

Epoch: 6| Step: 13
Training loss: 3.927075589254149
Validation loss: 3.0600704679311423

Epoch: 124| Step: 0
Training loss: 3.154813685167883
Validation loss: 3.059199951189067

Epoch: 6| Step: 1
Training loss: 3.2434142951491762
Validation loss: 3.059010117562072

Epoch: 6| Step: 2
Training loss: 3.0599413712812717
Validation loss: 3.057817959727533

Epoch: 6| Step: 3
Training loss: 3.20183987772657
Validation loss: 3.0590448298999093

Epoch: 6| Step: 4
Training loss: 3.5600707488584327
Validation loss: 3.0584430614765425

Epoch: 6| Step: 5
Training loss: 3.3173901431789035
Validation loss: 3.0586880232588776

Epoch: 6| Step: 6
Training loss: 3.462065846461031
Validation loss: 3.0603127117773066

Epoch: 6| Step: 7
Training loss: 3.7310216683663655
Validation loss: 3.0597366630227785

Epoch: 6| Step: 8
Training loss: 3.3292486595270847
Validation loss: 3.0571016343182746

Epoch: 6| Step: 9
Training loss: 4.137022589024577
Validation loss: 3.0586796819745756

Epoch: 6| Step: 10
Training loss: 3.4951522497106224
Validation loss: 3.0570995428857035

Epoch: 6| Step: 11
Training loss: 3.048398932795181
Validation loss: 3.057087367432472

Epoch: 6| Step: 12
Training loss: 2.723713870533239
Validation loss: 3.05815422070317

Epoch: 6| Step: 13
Training loss: 2.5044798766744436
Validation loss: 3.0568271471413784

Epoch: 125| Step: 0
Training loss: 3.0632807456543674
Validation loss: 3.0575932087474196

Epoch: 6| Step: 1
Training loss: 4.207963958745439
Validation loss: 3.056635904726207

Epoch: 6| Step: 2
Training loss: 2.8822727266623844
Validation loss: 3.0573828250494492

Epoch: 6| Step: 3
Training loss: 3.601704029935065
Validation loss: 3.054953621528945

Epoch: 6| Step: 4
Training loss: 2.75805922315054
Validation loss: 3.0556660223563457

Epoch: 6| Step: 5
Training loss: 2.6175494954294463
Validation loss: 3.054866548331599

Epoch: 6| Step: 6
Training loss: 2.962296066025151
Validation loss: 3.0576878859534933

Epoch: 6| Step: 7
Training loss: 3.5023756139370708
Validation loss: 3.0537001580894625

Epoch: 6| Step: 8
Training loss: 3.803497190921489
Validation loss: 3.057442680534437

Epoch: 6| Step: 9
Training loss: 3.1016307602296465
Validation loss: 3.0538995374467497

Epoch: 6| Step: 10
Training loss: 3.0881962103200404
Validation loss: 3.0533432709546116

Epoch: 6| Step: 11
Training loss: 4.029105628944152
Validation loss: 3.0559582223695236

Epoch: 6| Step: 12
Training loss: 2.968021343555464
Validation loss: 3.0562163340144517

Epoch: 6| Step: 13
Training loss: 3.6885620139608553
Validation loss: 3.0531167824338468

Testing loss: 3.251269628861598
