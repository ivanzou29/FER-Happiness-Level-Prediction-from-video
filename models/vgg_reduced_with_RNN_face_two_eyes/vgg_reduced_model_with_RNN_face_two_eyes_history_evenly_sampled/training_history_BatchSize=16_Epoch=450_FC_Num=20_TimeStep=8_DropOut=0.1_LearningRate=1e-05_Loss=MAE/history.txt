Epoch: 1| Step: 0
Training loss: 5.082153797149658
Validation loss: 5.1322384085706485

Epoch: 6| Step: 1
Training loss: 5.336383819580078
Validation loss: 5.117815227918728

Epoch: 6| Step: 2
Training loss: 4.385074138641357
Validation loss: 5.104151300204697

Epoch: 6| Step: 3
Training loss: 4.698182582855225
Validation loss: 5.090805366475095

Epoch: 6| Step: 4
Training loss: 4.786983489990234
Validation loss: 5.077150662740071

Epoch: 6| Step: 5
Training loss: 4.982191562652588
Validation loss: 5.06352940938806

Epoch: 6| Step: 6
Training loss: 5.039710998535156
Validation loss: 5.049146334330241

Epoch: 6| Step: 7
Training loss: 4.118338584899902
Validation loss: 5.033404657917638

Epoch: 6| Step: 8
Training loss: 4.113142490386963
Validation loss: 5.017336871034356

Epoch: 6| Step: 9
Training loss: 4.8268632888793945
Validation loss: 4.999636362957698

Epoch: 6| Step: 10
Training loss: 6.317276954650879
Validation loss: 4.980808099110921

Epoch: 6| Step: 11
Training loss: 4.161068439483643
Validation loss: 4.961451463801886

Epoch: 6| Step: 12
Training loss: 5.555898189544678
Validation loss: 4.9412667110402095

Epoch: 6| Step: 13
Training loss: 3.859351634979248
Validation loss: 4.919957724950647

Epoch: 2| Step: 0
Training loss: 6.1390204429626465
Validation loss: 4.895914775069042

Epoch: 6| Step: 1
Training loss: 5.46937894821167
Validation loss: 4.871559573758033

Epoch: 6| Step: 2
Training loss: 4.70739221572876
Validation loss: 4.84418398334134

Epoch: 6| Step: 3
Training loss: 4.751440048217773
Validation loss: 4.816678298416958

Epoch: 6| Step: 4
Training loss: 4.043934345245361
Validation loss: 4.787524966783421

Epoch: 6| Step: 5
Training loss: 3.254761219024658
Validation loss: 4.757073956151163

Epoch: 6| Step: 6
Training loss: 4.001652717590332
Validation loss: 4.724660417085053

Epoch: 6| Step: 7
Training loss: 3.6695051193237305
Validation loss: 4.692534779989591

Epoch: 6| Step: 8
Training loss: 3.939899206161499
Validation loss: 4.660402026227725

Epoch: 6| Step: 9
Training loss: 3.700510025024414
Validation loss: 4.626825101913944

Epoch: 6| Step: 10
Training loss: 5.074858665466309
Validation loss: 4.592142951103948

Epoch: 6| Step: 11
Training loss: 4.457045555114746
Validation loss: 4.557813675172867

Epoch: 6| Step: 12
Training loss: 5.34063720703125
Validation loss: 4.523647477549892

Epoch: 6| Step: 13
Training loss: 4.33338737487793
Validation loss: 4.489966961645311

Epoch: 3| Step: 0
Training loss: 4.950588226318359
Validation loss: 4.455651872901506

Epoch: 6| Step: 1
Training loss: 4.276431083679199
Validation loss: 4.424010976668327

Epoch: 6| Step: 2
Training loss: 3.6033523082733154
Validation loss: 4.391747443906723

Epoch: 6| Step: 3
Training loss: 4.7595367431640625
Validation loss: 4.360812248722199

Epoch: 6| Step: 4
Training loss: 4.279758930206299
Validation loss: 4.330554326375325

Epoch: 6| Step: 5
Training loss: 5.235755920410156
Validation loss: 4.301594380409487

Epoch: 6| Step: 6
Training loss: 3.1681063175201416
Validation loss: 4.271905432465256

Epoch: 6| Step: 7
Training loss: 3.9255599975585938
Validation loss: 4.242666413707118

Epoch: 6| Step: 8
Training loss: 3.920206069946289
Validation loss: 4.209771084529097

Epoch: 6| Step: 9
Training loss: 2.511643648147583
Validation loss: 4.17889594006282

Epoch: 6| Step: 10
Training loss: 5.437037467956543
Validation loss: 4.148761800540391

Epoch: 6| Step: 11
Training loss: 2.910865306854248
Validation loss: 4.114122970129854

Epoch: 6| Step: 12
Training loss: 3.999619722366333
Validation loss: 4.0801853979787515

Epoch: 6| Step: 13
Training loss: 4.051390647888184
Validation loss: 4.043223037514635

Epoch: 4| Step: 0
Training loss: 3.363156318664551
Validation loss: 4.0067873821463635

Epoch: 6| Step: 1
Training loss: 4.068001747131348
Validation loss: 3.971402688692975

Epoch: 6| Step: 2
Training loss: 2.7433111667633057
Validation loss: 3.937579062677199

Epoch: 6| Step: 3
Training loss: 3.940706253051758
Validation loss: 3.9060364102804535

Epoch: 6| Step: 4
Training loss: 2.8768980503082275
Validation loss: 3.8761745473389984

Epoch: 6| Step: 5
Training loss: 2.8822391033172607
Validation loss: 3.8508677610787014

Epoch: 6| Step: 6
Training loss: 3.5966811180114746
Validation loss: 3.82541161711498

Epoch: 6| Step: 7
Training loss: 4.5782599449157715
Validation loss: 3.7973589384427635

Epoch: 6| Step: 8
Training loss: 3.1249513626098633
Validation loss: 3.7740162752007924

Epoch: 6| Step: 9
Training loss: 4.255887985229492
Validation loss: 3.7507938825955955

Epoch: 6| Step: 10
Training loss: 4.4777750968933105
Validation loss: 3.7285302582607476

Epoch: 6| Step: 11
Training loss: 4.045465469360352
Validation loss: 3.708293325157576

Epoch: 6| Step: 12
Training loss: 4.270512580871582
Validation loss: 3.689569050265897

Epoch: 6| Step: 13
Training loss: 3.400355339050293
Validation loss: 3.6695289201633905

Epoch: 5| Step: 0
Training loss: 3.2549211978912354
Validation loss: 3.6507509241821947

Epoch: 6| Step: 1
Training loss: 4.2885637283325195
Validation loss: 3.632604242652975

Epoch: 6| Step: 2
Training loss: 3.9590578079223633
Validation loss: 3.6164632074294554

Epoch: 6| Step: 3
Training loss: 2.751103401184082
Validation loss: 3.6000586325122463

Epoch: 6| Step: 4
Training loss: 4.218088150024414
Validation loss: 3.5865281217841694

Epoch: 6| Step: 5
Training loss: 3.46706485748291
Validation loss: 3.5749380383440243

Epoch: 6| Step: 6
Training loss: 2.927802085876465
Validation loss: 3.5606125759822067

Epoch: 6| Step: 7
Training loss: 3.339043617248535
Validation loss: 3.5508699160750195

Epoch: 6| Step: 8
Training loss: 4.118049621582031
Validation loss: 3.53654315651104

Epoch: 6| Step: 9
Training loss: 2.492283344268799
Validation loss: 3.523776897820093

Epoch: 6| Step: 10
Training loss: 3.8495075702667236
Validation loss: 3.5110346988965104

Epoch: 6| Step: 11
Training loss: 3.4388084411621094
Validation loss: 3.498739101553476

Epoch: 6| Step: 12
Training loss: 3.225813627243042
Validation loss: 3.488678168225032

Epoch: 6| Step: 13
Training loss: 3.4761831760406494
Validation loss: 3.477289286992883

Epoch: 6| Step: 0
Training loss: 3.019763946533203
Validation loss: 3.466263594165925

Epoch: 6| Step: 1
Training loss: 3.4741053581237793
Validation loss: 3.4551983366730394

Epoch: 6| Step: 2
Training loss: 3.547741413116455
Validation loss: 3.4434590775479554

Epoch: 6| Step: 3
Training loss: 3.969475269317627
Validation loss: 3.4327499712667158

Epoch: 6| Step: 4
Training loss: 4.323861122131348
Validation loss: 3.4232549974995274

Epoch: 6| Step: 5
Training loss: 2.7614428997039795
Validation loss: 3.4128466319012385

Epoch: 6| Step: 6
Training loss: 4.1837477684021
Validation loss: 3.40106544186992

Epoch: 6| Step: 7
Training loss: 3.3571043014526367
Validation loss: 3.3898686183396207

Epoch: 6| Step: 8
Training loss: 2.7966036796569824
Validation loss: 3.377269624381937

Epoch: 6| Step: 9
Training loss: 2.255985736846924
Validation loss: 3.3662224533737346

Epoch: 6| Step: 10
Training loss: 3.8775839805603027
Validation loss: 3.3583209565890733

Epoch: 6| Step: 11
Training loss: 3.395364999771118
Validation loss: 3.3474864498261483

Epoch: 6| Step: 12
Training loss: 3.523275375366211
Validation loss: 3.338769881956039

Epoch: 6| Step: 13
Training loss: 1.7088266611099243
Validation loss: 3.33026409405534

Epoch: 7| Step: 0
Training loss: 2.8767881393432617
Validation loss: 3.3207436966639694

Epoch: 6| Step: 1
Training loss: 3.5560226440429688
Validation loss: 3.312594247120683

Epoch: 6| Step: 2
Training loss: 3.8070499897003174
Validation loss: 3.3033475850218084

Epoch: 6| Step: 3
Training loss: 3.5305800437927246
Validation loss: 3.2973858464148735

Epoch: 6| Step: 4
Training loss: 1.7574055194854736
Validation loss: 3.2878946283812165

Epoch: 6| Step: 5
Training loss: 4.337996482849121
Validation loss: 3.280732213809926

Epoch: 6| Step: 6
Training loss: 2.9430360794067383
Validation loss: 3.2733902803031345

Epoch: 6| Step: 7
Training loss: 3.994279146194458
Validation loss: 3.263492863665345

Epoch: 6| Step: 8
Training loss: 3.0786564350128174
Validation loss: 3.254995310178367

Epoch: 6| Step: 9
Training loss: 2.8429031372070312
Validation loss: 3.247274286003523

Epoch: 6| Step: 10
Training loss: 3.302971601486206
Validation loss: 3.2380725055612545

Epoch: 6| Step: 11
Training loss: 3.474522590637207
Validation loss: 3.232380518349268

Epoch: 6| Step: 12
Training loss: 2.885141372680664
Validation loss: 3.221883561021538

Epoch: 6| Step: 13
Training loss: 2.929478883743286
Validation loss: 3.213591683295465

Epoch: 8| Step: 0
Training loss: 3.4546093940734863
Validation loss: 3.207593248736474

Epoch: 6| Step: 1
Training loss: 2.77675199508667
Validation loss: 3.1998287682892173

Epoch: 6| Step: 2
Training loss: 2.559417247772217
Validation loss: 3.1921620548412366

Epoch: 6| Step: 3
Training loss: 2.7290632724761963
Validation loss: 3.183677381084811

Epoch: 6| Step: 4
Training loss: 3.070183277130127
Validation loss: 3.17730543433979

Epoch: 6| Step: 5
Training loss: 2.457460880279541
Validation loss: 3.1676590493930283

Epoch: 6| Step: 6
Training loss: 3.2397334575653076
Validation loss: 3.1608392038652973

Epoch: 6| Step: 7
Training loss: 3.9677000045776367
Validation loss: 3.1539148694725445

Epoch: 6| Step: 8
Training loss: 3.3807778358459473
Validation loss: 3.14846533601002

Epoch: 6| Step: 9
Training loss: 2.997159719467163
Validation loss: 3.14027303008623

Epoch: 6| Step: 10
Training loss: 4.152801513671875
Validation loss: 3.1336690687364146

Epoch: 6| Step: 11
Training loss: 3.330341339111328
Validation loss: 3.12657440862348

Epoch: 6| Step: 12
Training loss: 3.2289366722106934
Validation loss: 3.120728902919318

Epoch: 6| Step: 13
Training loss: 2.925786256790161
Validation loss: 3.1146140201117403

Epoch: 9| Step: 0
Training loss: 3.0925750732421875
Validation loss: 3.1081705247202227

Epoch: 6| Step: 1
Training loss: 3.596867322921753
Validation loss: 3.100608402682889

Epoch: 6| Step: 2
Training loss: 1.9902734756469727
Validation loss: 3.094981321724512

Epoch: 6| Step: 3
Training loss: 2.767113447189331
Validation loss: 3.0910076274666736

Epoch: 6| Step: 4
Training loss: 2.748724937438965
Validation loss: 3.0841336763033302

Epoch: 6| Step: 5
Training loss: 3.6277384757995605
Validation loss: 3.079834520175893

Epoch: 6| Step: 6
Training loss: 2.702646017074585
Validation loss: 3.0735206475821872

Epoch: 6| Step: 7
Training loss: 1.9175217151641846
Validation loss: 3.0681963812920356

Epoch: 6| Step: 8
Training loss: 3.9409399032592773
Validation loss: 3.0648615052623134

Epoch: 6| Step: 9
Training loss: 3.3972017765045166
Validation loss: 3.0571391223579325

Epoch: 6| Step: 10
Training loss: 4.199840545654297
Validation loss: 3.0549006821006857

Epoch: 6| Step: 11
Training loss: 3.447157859802246
Validation loss: 3.048867589683943

Epoch: 6| Step: 12
Training loss: 2.9975154399871826
Validation loss: 3.0446142278691775

Epoch: 6| Step: 13
Training loss: 3.0973405838012695
Validation loss: 3.0385734547850904

Epoch: 10| Step: 0
Training loss: 3.0847978591918945
Validation loss: 3.0271046007833173

Epoch: 6| Step: 1
Training loss: 2.282540798187256
Validation loss: 3.0285470921506166

Epoch: 6| Step: 2
Training loss: 2.3535306453704834
Validation loss: 3.028075425855575

Epoch: 6| Step: 3
Training loss: 3.0662789344787598
Validation loss: 3.03757034578631

Epoch: 6| Step: 4
Training loss: 1.9598751068115234
Validation loss: 3.010174007825954

Epoch: 6| Step: 5
Training loss: 2.9525914192199707
Validation loss: 3.0041947877535256

Epoch: 6| Step: 6
Training loss: 3.8161957263946533
Validation loss: 2.999996059684343

Epoch: 6| Step: 7
Training loss: 3.879319190979004
Validation loss: 3.002097729713686

Epoch: 6| Step: 8
Training loss: 3.5754380226135254
Validation loss: 2.994176100659114

Epoch: 6| Step: 9
Training loss: 2.9542489051818848
Validation loss: 2.992246755989649

Epoch: 6| Step: 10
Training loss: 3.6204261779785156
Validation loss: 2.9918587951249975

Epoch: 6| Step: 11
Training loss: 3.0857717990875244
Validation loss: 2.9813912581372004

Epoch: 6| Step: 12
Training loss: 3.635225772857666
Validation loss: 2.9757635952323995

Epoch: 6| Step: 13
Training loss: 2.327636480331421
Validation loss: 2.977487958887572

Epoch: 11| Step: 0
Training loss: 3.5314865112304688
Validation loss: 2.9706239546498945

Epoch: 6| Step: 1
Training loss: 3.077699661254883
Validation loss: 2.9704820212497505

Epoch: 6| Step: 2
Training loss: 3.316969394683838
Validation loss: 2.9641955052652667

Epoch: 6| Step: 3
Training loss: 2.789339542388916
Validation loss: 2.960064180435673

Epoch: 6| Step: 4
Training loss: 2.9898581504821777
Validation loss: 2.957386544955674

Epoch: 6| Step: 5
Training loss: 3.173377513885498
Validation loss: 2.9554401520759828

Epoch: 6| Step: 6
Training loss: 2.6210460662841797
Validation loss: 2.961730267411919

Epoch: 6| Step: 7
Training loss: 2.785151720046997
Validation loss: 2.991995826844246

Epoch: 6| Step: 8
Training loss: 2.6600773334503174
Validation loss: 3.003052137231314

Epoch: 6| Step: 9
Training loss: 2.7682042121887207
Validation loss: 2.9481788168671312

Epoch: 6| Step: 10
Training loss: 4.6756486892700195
Validation loss: 2.9465992271259265

Epoch: 6| Step: 11
Training loss: 2.663215160369873
Validation loss: 2.9469163110179286

Epoch: 6| Step: 12
Training loss: 2.2340822219848633
Validation loss: 2.968342124774892

Epoch: 6| Step: 13
Training loss: 3.4056129455566406
Validation loss: 2.98933768528764

Epoch: 12| Step: 0
Training loss: 2.710479736328125
Validation loss: 2.9800478360986196

Epoch: 6| Step: 1
Training loss: 3.0619425773620605
Validation loss: 2.9583739132009526

Epoch: 6| Step: 2
Training loss: 3.147974967956543
Validation loss: 2.9456285404902633

Epoch: 6| Step: 3
Training loss: 2.3629088401794434
Validation loss: 2.9433130910319667

Epoch: 6| Step: 4
Training loss: 2.9154539108276367
Validation loss: 2.942076454880417

Epoch: 6| Step: 5
Training loss: 3.2456321716308594
Validation loss: 2.943473882572625

Epoch: 6| Step: 6
Training loss: 2.794710636138916
Validation loss: 2.9465986810704714

Epoch: 6| Step: 7
Training loss: 2.5570871829986572
Validation loss: 2.944886315253473

Epoch: 6| Step: 8
Training loss: 3.6347012519836426
Validation loss: 2.9453564049095236

Epoch: 6| Step: 9
Training loss: 2.8107008934020996
Validation loss: 2.938543140247304

Epoch: 6| Step: 10
Training loss: 2.5160350799560547
Validation loss: 2.9329858697870725

Epoch: 6| Step: 11
Training loss: 3.5691518783569336
Validation loss: 2.9306511058602283

Epoch: 6| Step: 12
Training loss: 3.6901097297668457
Validation loss: 2.929670108261929

Epoch: 6| Step: 13
Training loss: 3.4798049926757812
Validation loss: 2.9265321736694663

Epoch: 13| Step: 0
Training loss: 2.4964818954467773
Validation loss: 2.921057552419683

Epoch: 6| Step: 1
Training loss: 2.990654468536377
Validation loss: 2.9168066311908025

Epoch: 6| Step: 2
Training loss: 2.5253913402557373
Validation loss: 2.9168679022019908

Epoch: 6| Step: 3
Training loss: 2.8882155418395996
Validation loss: 2.913771898515763

Epoch: 6| Step: 4
Training loss: 3.596993923187256
Validation loss: 2.910271877883583

Epoch: 6| Step: 5
Training loss: 2.169802665710449
Validation loss: 2.906033618475801

Epoch: 6| Step: 6
Training loss: 2.845477819442749
Validation loss: 2.9080825057080997

Epoch: 6| Step: 7
Training loss: 2.516184091567993
Validation loss: 2.9047027787854596

Epoch: 6| Step: 8
Training loss: 3.386251211166382
Validation loss: 2.902200791143602

Epoch: 6| Step: 9
Training loss: 2.8186862468719482
Validation loss: 2.893711656652471

Epoch: 6| Step: 10
Training loss: 3.1730690002441406
Validation loss: 2.8887036333801928

Epoch: 6| Step: 11
Training loss: 3.2813003063201904
Validation loss: 2.88503844763643

Epoch: 6| Step: 12
Training loss: 3.344447612762451
Validation loss: 2.886689552696802

Epoch: 6| Step: 13
Training loss: 4.568672180175781
Validation loss: 2.8823515317773305

Epoch: 14| Step: 0
Training loss: 2.6918015480041504
Validation loss: 2.8800221591867428

Epoch: 6| Step: 1
Training loss: 2.6115803718566895
Validation loss: 2.87669381531336

Epoch: 6| Step: 2
Training loss: 3.3459391593933105
Validation loss: 2.874075505041307

Epoch: 6| Step: 3
Training loss: 2.6085517406463623
Validation loss: 2.870794350101102

Epoch: 6| Step: 4
Training loss: 3.0748226642608643
Validation loss: 2.8658082767199446

Epoch: 6| Step: 5
Training loss: 3.467524766921997
Validation loss: 2.863120025204074

Epoch: 6| Step: 6
Training loss: 3.3216190338134766
Validation loss: 2.8580638567606607

Epoch: 6| Step: 7
Training loss: 2.9396274089813232
Validation loss: 2.8548007652323735

Epoch: 6| Step: 8
Training loss: 2.806717872619629
Validation loss: 2.8537289019553893

Epoch: 6| Step: 9
Training loss: 2.4229536056518555
Validation loss: 2.8533689745010866

Epoch: 6| Step: 10
Training loss: 3.086852550506592
Validation loss: 2.856168762330086

Epoch: 6| Step: 11
Training loss: 2.065335273742676
Validation loss: 2.8543604702077885

Epoch: 6| Step: 12
Training loss: 3.858729362487793
Validation loss: 2.8554691268551733

Epoch: 6| Step: 13
Training loss: 3.4106054306030273
Validation loss: 2.846737882142426

Epoch: 15| Step: 0
Training loss: 3.052706718444824
Validation loss: 2.8392835893938617

Epoch: 6| Step: 1
Training loss: 3.633953809738159
Validation loss: 2.8355384001167874

Epoch: 6| Step: 2
Training loss: 2.877394199371338
Validation loss: 2.8343180277014293

Epoch: 6| Step: 3
Training loss: 3.4593417644500732
Validation loss: 2.832708945838354

Epoch: 6| Step: 4
Training loss: 2.4328713417053223
Validation loss: 2.831048560398881

Epoch: 6| Step: 5
Training loss: 2.9620742797851562
Validation loss: 2.82980740070343

Epoch: 6| Step: 6
Training loss: 2.8766140937805176
Validation loss: 2.8296640970373668

Epoch: 6| Step: 7
Training loss: 2.414428472518921
Validation loss: 2.82807324265921

Epoch: 6| Step: 8
Training loss: 2.816734790802002
Validation loss: 2.824491946927963

Epoch: 6| Step: 9
Training loss: 2.73526668548584
Validation loss: 2.8194385933619674

Epoch: 6| Step: 10
Training loss: 3.6593384742736816
Validation loss: 2.8188133649928595

Epoch: 6| Step: 11
Training loss: 2.8575639724731445
Validation loss: 2.8160822263327976

Epoch: 6| Step: 12
Training loss: 2.366069793701172
Validation loss: 2.813721856763286

Epoch: 6| Step: 13
Training loss: 3.243474245071411
Validation loss: 2.8152411932586343

Epoch: 16| Step: 0
Training loss: 2.3017101287841797
Validation loss: 2.8122845029318206

Epoch: 6| Step: 1
Training loss: 2.805622100830078
Validation loss: 2.8117019591792936

Epoch: 6| Step: 2
Training loss: 3.051644802093506
Validation loss: 2.810049864553636

Epoch: 6| Step: 3
Training loss: 2.410930633544922
Validation loss: 2.8103054108158236

Epoch: 6| Step: 4
Training loss: 2.6303465366363525
Validation loss: 2.808210257560976

Epoch: 6| Step: 5
Training loss: 2.5757386684417725
Validation loss: 2.8082104472703833

Epoch: 6| Step: 6
Training loss: 3.1199421882629395
Validation loss: 2.807941516240438

Epoch: 6| Step: 7
Training loss: 2.546947717666626
Validation loss: 2.804178709624916

Epoch: 6| Step: 8
Training loss: 3.7063698768615723
Validation loss: 2.804319122786163

Epoch: 6| Step: 9
Training loss: 3.3960442543029785
Validation loss: 2.7998273372650146

Epoch: 6| Step: 10
Training loss: 3.216732978820801
Validation loss: 2.8011922887576524

Epoch: 6| Step: 11
Training loss: 3.369462728500366
Validation loss: 2.79998956700807

Epoch: 6| Step: 12
Training loss: 3.442964553833008
Validation loss: 2.7983939827129407

Epoch: 6| Step: 13
Training loss: 2.0779736042022705
Validation loss: 2.7979597660803024

Epoch: 17| Step: 0
Training loss: 2.668764591217041
Validation loss: 2.798228194636683

Epoch: 6| Step: 1
Training loss: 1.8952953815460205
Validation loss: 2.804519071373888

Epoch: 6| Step: 2
Training loss: 2.661181926727295
Validation loss: 2.797839577480029

Epoch: 6| Step: 3
Training loss: 2.4208545684814453
Validation loss: 2.7937839159401516

Epoch: 6| Step: 4
Training loss: 2.2851033210754395
Validation loss: 2.7984387361875145

Epoch: 6| Step: 5
Training loss: 3.6202282905578613
Validation loss: 2.8137106895446777

Epoch: 6| Step: 6
Training loss: 3.672464370727539
Validation loss: 2.8584017138327322

Epoch: 6| Step: 7
Training loss: 2.710172653198242
Validation loss: 2.8624157982487834

Epoch: 6| Step: 8
Training loss: 3.6719465255737305
Validation loss: 2.8504126917931343

Epoch: 6| Step: 9
Training loss: 3.152574300765991
Validation loss: 2.8412224605519283

Epoch: 6| Step: 10
Training loss: 2.997840642929077
Validation loss: 2.843359931822746

Epoch: 6| Step: 11
Training loss: 3.6927809715270996
Validation loss: 2.838627815246582

Epoch: 6| Step: 12
Training loss: 2.501434087753296
Validation loss: 2.83506533920124

Epoch: 6| Step: 13
Training loss: 3.5270919799804688
Validation loss: 2.8380901352051766

Epoch: 18| Step: 0
Training loss: 3.3110036849975586
Validation loss: 2.798792036630774

Epoch: 6| Step: 1
Training loss: 3.504244565963745
Validation loss: 2.78180532814354

Epoch: 6| Step: 2
Training loss: 3.121598243713379
Validation loss: 2.7858894691672376

Epoch: 6| Step: 3
Training loss: 3.2643136978149414
Validation loss: 2.7787108011143182

Epoch: 6| Step: 4
Training loss: 2.554067850112915
Validation loss: 2.7846306318877847

Epoch: 6| Step: 5
Training loss: 3.315310001373291
Validation loss: 2.794622177718788

Epoch: 6| Step: 6
Training loss: 3.685448169708252
Validation loss: 2.8420727534960677

Epoch: 6| Step: 7
Training loss: 2.361138343811035
Validation loss: 2.8271616556311168

Epoch: 6| Step: 8
Training loss: 2.962390184402466
Validation loss: 2.780999158018379

Epoch: 6| Step: 9
Training loss: 2.949272394180298
Validation loss: 2.7753882536324124

Epoch: 6| Step: 10
Training loss: 2.3374691009521484
Validation loss: 2.7819971397358882

Epoch: 6| Step: 11
Training loss: 2.427900791168213
Validation loss: 2.7797608888277443

Epoch: 6| Step: 12
Training loss: 2.669506072998047
Validation loss: 2.778717279434204

Epoch: 6| Step: 13
Training loss: 2.137293815612793
Validation loss: 2.7730455244741132

Epoch: 19| Step: 0
Training loss: 2.8935108184814453
Validation loss: 2.766776966792281

Epoch: 6| Step: 1
Training loss: 2.8763489723205566
Validation loss: 2.7642005925537436

Epoch: 6| Step: 2
Training loss: 2.1496219635009766
Validation loss: 2.7609851360321045

Epoch: 6| Step: 3
Training loss: 2.4956345558166504
Validation loss: 2.760978324438936

Epoch: 6| Step: 4
Training loss: 3.622906446456909
Validation loss: 2.7639614612825456

Epoch: 6| Step: 5
Training loss: 2.5578413009643555
Validation loss: 2.7743628563419467

Epoch: 6| Step: 6
Training loss: 3.981910467147827
Validation loss: 2.7622765148839643

Epoch: 6| Step: 7
Training loss: 2.6377415657043457
Validation loss: 2.7568258418831775

Epoch: 6| Step: 8
Training loss: 2.6665706634521484
Validation loss: 2.7545270765981367

Epoch: 6| Step: 9
Training loss: 2.865133285522461
Validation loss: 2.7536371984789447

Epoch: 6| Step: 10
Training loss: 3.1405999660491943
Validation loss: 2.7535295870996292

Epoch: 6| Step: 11
Training loss: 2.0455424785614014
Validation loss: 2.7522238146874214

Epoch: 6| Step: 12
Training loss: 3.2046375274658203
Validation loss: 2.751194246353642

Epoch: 6| Step: 13
Training loss: 3.93861985206604
Validation loss: 2.7507491291210218

Epoch: 20| Step: 0
Training loss: 2.789140462875366
Validation loss: 2.748869542152651

Epoch: 6| Step: 1
Training loss: 3.133408308029175
Validation loss: 2.7473100308449037

Epoch: 6| Step: 2
Training loss: 2.681454658508301
Validation loss: 2.746982987209033

Epoch: 6| Step: 3
Training loss: 2.835885524749756
Validation loss: 2.748539588784659

Epoch: 6| Step: 4
Training loss: 2.3891501426696777
Validation loss: 2.751179425947128

Epoch: 6| Step: 5
Training loss: 2.9679815769195557
Validation loss: 2.758506885138891

Epoch: 6| Step: 6
Training loss: 3.118058204650879
Validation loss: 2.7500142589692147

Epoch: 6| Step: 7
Training loss: 2.6136069297790527
Validation loss: 2.746062642784529

Epoch: 6| Step: 8
Training loss: 3.562771797180176
Validation loss: 2.744467922436294

Epoch: 6| Step: 9
Training loss: 3.036001443862915
Validation loss: 2.7449606131481867

Epoch: 6| Step: 10
Training loss: 3.2181527614593506
Validation loss: 2.7429527287842124

Epoch: 6| Step: 11
Training loss: 3.6373534202575684
Validation loss: 2.7422277747943835

Epoch: 6| Step: 12
Training loss: 1.8102022409439087
Validation loss: 2.7404029318081435

Epoch: 6| Step: 13
Training loss: 2.5422306060791016
Validation loss: 2.740190834127447

Epoch: 21| Step: 0
Training loss: 2.3406009674072266
Validation loss: 2.741214262541904

Epoch: 6| Step: 1
Training loss: 2.8875508308410645
Validation loss: 2.7403774005110546

Epoch: 6| Step: 2
Training loss: 2.5741679668426514
Validation loss: 2.744120769603278

Epoch: 6| Step: 3
Training loss: 2.5104968547821045
Validation loss: 2.74372249521235

Epoch: 6| Step: 4
Training loss: 2.233001708984375
Validation loss: 2.7431843511519896

Epoch: 6| Step: 5
Training loss: 3.0567355155944824
Validation loss: 2.740911140236803

Epoch: 6| Step: 6
Training loss: 2.8088114261627197
Validation loss: 2.7407665893595707

Epoch: 6| Step: 7
Training loss: 3.2305479049682617
Validation loss: 2.7379590285721647

Epoch: 6| Step: 8
Training loss: 3.1685402393341064
Validation loss: 2.7352975901737007

Epoch: 6| Step: 9
Training loss: 2.845132350921631
Validation loss: 2.736435495397096

Epoch: 6| Step: 10
Training loss: 3.1375200748443604
Validation loss: 2.7360414766496226

Epoch: 6| Step: 11
Training loss: 3.972205400466919
Validation loss: 2.73484871977119

Epoch: 6| Step: 12
Training loss: 2.8360095024108887
Validation loss: 2.7398546382945073

Epoch: 6| Step: 13
Training loss: 2.731076240539551
Validation loss: 2.7426428487223964

Epoch: 22| Step: 0
Training loss: 4.37791109085083
Validation loss: 2.742989888755224

Epoch: 6| Step: 1
Training loss: 3.2132554054260254
Validation loss: 2.7332061772705405

Epoch: 6| Step: 2
Training loss: 3.791287422180176
Validation loss: 2.73207837535489

Epoch: 6| Step: 3
Training loss: 2.2511894702911377
Validation loss: 2.7321272819272933

Epoch: 6| Step: 4
Training loss: 3.075023651123047
Validation loss: 2.731142900323355

Epoch: 6| Step: 5
Training loss: 2.2905046939849854
Validation loss: 2.7378447799272436

Epoch: 6| Step: 6
Training loss: 3.095785617828369
Validation loss: 2.738201766885737

Epoch: 6| Step: 7
Training loss: 2.965606212615967
Validation loss: 2.739488573484523

Epoch: 6| Step: 8
Training loss: 3.005852222442627
Validation loss: 2.7384343352369083

Epoch: 6| Step: 9
Training loss: 2.7066352367401123
Validation loss: 2.732200784067954

Epoch: 6| Step: 10
Training loss: 2.7328662872314453
Validation loss: 2.7329650386687248

Epoch: 6| Step: 11
Training loss: 2.451509714126587
Validation loss: 2.73286949178224

Epoch: 6| Step: 12
Training loss: 2.379903554916382
Validation loss: 2.7287731760291645

Epoch: 6| Step: 13
Training loss: 1.5065003633499146
Validation loss: 2.730446461708315

Epoch: 23| Step: 0
Training loss: 3.440258264541626
Validation loss: 2.726721373937463

Epoch: 6| Step: 1
Training loss: 3.3096251487731934
Validation loss: 2.725023382453508

Epoch: 6| Step: 2
Training loss: 3.6115641593933105
Validation loss: 2.726016101016793

Epoch: 6| Step: 3
Training loss: 2.539124011993408
Validation loss: 2.723595226964643

Epoch: 6| Step: 4
Training loss: 2.0523171424865723
Validation loss: 2.7269553164000153

Epoch: 6| Step: 5
Training loss: 3.547347068786621
Validation loss: 2.7241211475864535

Epoch: 6| Step: 6
Training loss: 2.2130892276763916
Validation loss: 2.7241692055938063

Epoch: 6| Step: 7
Training loss: 2.7065324783325195
Validation loss: 2.7247208497857534

Epoch: 6| Step: 8
Training loss: 2.4933149814605713
Validation loss: 2.725799855365548

Epoch: 6| Step: 9
Training loss: 1.8495897054672241
Validation loss: 2.7224523149510866

Epoch: 6| Step: 10
Training loss: 2.5958075523376465
Validation loss: 2.72449860008814

Epoch: 6| Step: 11
Training loss: 4.175494194030762
Validation loss: 2.727835906449185

Epoch: 6| Step: 12
Training loss: 3.2223591804504395
Validation loss: 2.7272800578865954

Epoch: 6| Step: 13
Training loss: 2.181107997894287
Validation loss: 2.7292012783788864

Epoch: 24| Step: 0
Training loss: 3.3190839290618896
Validation loss: 2.7258880522943314

Epoch: 6| Step: 1
Training loss: 3.0016045570373535
Validation loss: 2.7259147705570346

Epoch: 6| Step: 2
Training loss: 2.260547161102295
Validation loss: 2.7226300470290647

Epoch: 6| Step: 3
Training loss: 1.9399853944778442
Validation loss: 2.7210336090416036

Epoch: 6| Step: 4
Training loss: 2.9166083335876465
Validation loss: 2.722161534012005

Epoch: 6| Step: 5
Training loss: 2.9073386192321777
Validation loss: 2.718022777188209

Epoch: 6| Step: 6
Training loss: 2.6943938732147217
Validation loss: 2.7188539761368946

Epoch: 6| Step: 7
Training loss: 2.501633644104004
Validation loss: 2.7190910411137406

Epoch: 6| Step: 8
Training loss: 2.72210693359375
Validation loss: 2.7188279321116786

Epoch: 6| Step: 9
Training loss: 3.993873357772827
Validation loss: 2.718799227027483

Epoch: 6| Step: 10
Training loss: 2.7725794315338135
Validation loss: 2.719597247339064

Epoch: 6| Step: 11
Training loss: 2.708993911743164
Validation loss: 2.719568201290664

Epoch: 6| Step: 12
Training loss: 3.002943515777588
Validation loss: 2.7174018557353685

Epoch: 6| Step: 13
Training loss: 3.8230862617492676
Validation loss: 2.717104732349355

Epoch: 25| Step: 0
Training loss: 2.9685544967651367
Validation loss: 2.7187561296647593

Epoch: 6| Step: 1
Training loss: 3.519296646118164
Validation loss: 2.717255530818816

Epoch: 6| Step: 2
Training loss: 3.528120517730713
Validation loss: 2.7160514964852283

Epoch: 6| Step: 3
Training loss: 2.4309327602386475
Validation loss: 2.7183163858229116

Epoch: 6| Step: 4
Training loss: 2.381636142730713
Validation loss: 2.716614002822548

Epoch: 6| Step: 5
Training loss: 2.6347339153289795
Validation loss: 2.7189878981600524

Epoch: 6| Step: 6
Training loss: 2.8131282329559326
Validation loss: 2.716645389474848

Epoch: 6| Step: 7
Training loss: 2.0713541507720947
Validation loss: 2.7152752799372517

Epoch: 6| Step: 8
Training loss: 3.019263505935669
Validation loss: 2.7141686742023756

Epoch: 6| Step: 9
Training loss: 3.3971619606018066
Validation loss: 2.716568047000516

Epoch: 6| Step: 10
Training loss: 2.721231460571289
Validation loss: 2.713609149379115

Epoch: 6| Step: 11
Training loss: 3.0603842735290527
Validation loss: 2.7137005713678177

Epoch: 6| Step: 12
Training loss: 2.5678601264953613
Validation loss: 2.713196369909471

Epoch: 6| Step: 13
Training loss: 3.077911853790283
Validation loss: 2.710428176387664

Epoch: 26| Step: 0
Training loss: 2.2186009883880615
Validation loss: 2.7105672615830616

Epoch: 6| Step: 1
Training loss: 2.6876628398895264
Validation loss: 2.7102346830470587

Epoch: 6| Step: 2
Training loss: 3.389434337615967
Validation loss: 2.7113230305333293

Epoch: 6| Step: 3
Training loss: 3.056117534637451
Validation loss: 2.7100821182291996

Epoch: 6| Step: 4
Training loss: 2.977233648300171
Validation loss: 2.710607700450446

Epoch: 6| Step: 5
Training loss: 2.8474323749542236
Validation loss: 2.7101873582409275

Epoch: 6| Step: 6
Training loss: 2.663294792175293
Validation loss: 2.7077136424279984

Epoch: 6| Step: 7
Training loss: 2.875602960586548
Validation loss: 2.7079624924608456

Epoch: 6| Step: 8
Training loss: 3.5960137844085693
Validation loss: 2.710163470237486

Epoch: 6| Step: 9
Training loss: 3.142428398132324
Validation loss: 2.7144112176792596

Epoch: 6| Step: 10
Training loss: 2.353900909423828
Validation loss: 2.7153564781271

Epoch: 6| Step: 11
Training loss: 2.654254913330078
Validation loss: 2.713080624098419

Epoch: 6| Step: 12
Training loss: 2.9899866580963135
Validation loss: 2.7149965865637666

Epoch: 6| Step: 13
Training loss: 2.332024097442627
Validation loss: 2.708931674239456

Epoch: 27| Step: 0
Training loss: 3.320082187652588
Validation loss: 2.703513058282996

Epoch: 6| Step: 1
Training loss: 3.3236210346221924
Validation loss: 2.704969459964383

Epoch: 6| Step: 2
Training loss: 2.698939323425293
Validation loss: 2.7052720721049974

Epoch: 6| Step: 3
Training loss: 2.796382427215576
Validation loss: 2.7067515542430263

Epoch: 6| Step: 4
Training loss: 2.6217570304870605
Validation loss: 2.7075582140235492

Epoch: 6| Step: 5
Training loss: 3.575554370880127
Validation loss: 2.707151387327461

Epoch: 6| Step: 6
Training loss: 3.717444658279419
Validation loss: 2.705405399363528

Epoch: 6| Step: 7
Training loss: 2.4375295639038086
Validation loss: 2.7056849848839546

Epoch: 6| Step: 8
Training loss: 1.6811037063598633
Validation loss: 2.7036315343713246

Epoch: 6| Step: 9
Training loss: 2.381979465484619
Validation loss: 2.703594543600595

Epoch: 6| Step: 10
Training loss: 3.1296021938323975
Validation loss: 2.7020477018048688

Epoch: 6| Step: 11
Training loss: 3.5192413330078125
Validation loss: 2.702442874190628

Epoch: 6| Step: 12
Training loss: 2.4956676959991455
Validation loss: 2.7034075490890013

Epoch: 6| Step: 13
Training loss: 1.8979954719543457
Validation loss: 2.701453819069811

Epoch: 28| Step: 0
Training loss: 3.3953237533569336
Validation loss: 2.701186587733607

Epoch: 6| Step: 1
Training loss: 2.226391315460205
Validation loss: 2.7054627864591536

Epoch: 6| Step: 2
Training loss: 3.50455379486084
Validation loss: 2.716907734512001

Epoch: 6| Step: 3
Training loss: 2.256946563720703
Validation loss: 2.726962422811857

Epoch: 6| Step: 4
Training loss: 2.2943906784057617
Validation loss: 2.7411639562217136

Epoch: 6| Step: 5
Training loss: 3.35123610496521
Validation loss: 2.7224689965607016

Epoch: 6| Step: 6
Training loss: 2.126836061477661
Validation loss: 2.709606760291643

Epoch: 6| Step: 7
Training loss: 3.0961203575134277
Validation loss: 2.7062230340896116

Epoch: 6| Step: 8
Training loss: 2.943143129348755
Validation loss: 2.6999344774471816

Epoch: 6| Step: 9
Training loss: 2.985895872116089
Validation loss: 2.69943263453822

Epoch: 6| Step: 10
Training loss: 2.4088003635406494
Validation loss: 2.702286017838345

Epoch: 6| Step: 11
Training loss: 3.6044974327087402
Validation loss: 2.7025489884038127

Epoch: 6| Step: 12
Training loss: 3.2448298931121826
Validation loss: 2.703921212944933

Epoch: 6| Step: 13
Training loss: 2.3287458419799805
Validation loss: 2.702255395150954

Epoch: 29| Step: 0
Training loss: 3.092668056488037
Validation loss: 2.7023283384179555

Epoch: 6| Step: 1
Training loss: 2.9800381660461426
Validation loss: 2.701581960083336

Epoch: 6| Step: 2
Training loss: 2.2611007690429688
Validation loss: 2.697479660793017

Epoch: 6| Step: 3
Training loss: 3.0283870697021484
Validation loss: 2.695968506156757

Epoch: 6| Step: 4
Training loss: 2.3010311126708984
Validation loss: 2.6993045601793515

Epoch: 6| Step: 5
Training loss: 2.862640380859375
Validation loss: 2.6963998502300632

Epoch: 6| Step: 6
Training loss: 2.6373066902160645
Validation loss: 2.705043092850716

Epoch: 6| Step: 7
Training loss: 3.1786296367645264
Validation loss: 2.7070793515892437

Epoch: 6| Step: 8
Training loss: 3.144216537475586
Validation loss: 2.7037500386597006

Epoch: 6| Step: 9
Training loss: 3.137519598007202
Validation loss: 2.696143822003436

Epoch: 6| Step: 10
Training loss: 2.9253339767456055
Validation loss: 2.6950290536367767

Epoch: 6| Step: 11
Training loss: 2.799323320388794
Validation loss: 2.6912627886700373

Epoch: 6| Step: 12
Training loss: 2.423055648803711
Validation loss: 2.6955061958682154

Epoch: 6| Step: 13
Training loss: 3.3760826587677
Validation loss: 2.6893559014925392

Epoch: 30| Step: 0
Training loss: 2.7785892486572266
Validation loss: 2.6909089421713226

Epoch: 6| Step: 1
Training loss: 3.0034306049346924
Validation loss: 2.691686486685148

Epoch: 6| Step: 2
Training loss: 3.195338487625122
Validation loss: 2.689077074809741

Epoch: 6| Step: 3
Training loss: 3.255781650543213
Validation loss: 2.6885785646336053

Epoch: 6| Step: 4
Training loss: 2.731985092163086
Validation loss: 2.689080686979396

Epoch: 6| Step: 5
Training loss: 2.828958511352539
Validation loss: 2.6956080877652733

Epoch: 6| Step: 6
Training loss: 2.536627769470215
Validation loss: 2.7005678825480963

Epoch: 6| Step: 7
Training loss: 3.2276835441589355
Validation loss: 2.702265739440918

Epoch: 6| Step: 8
Training loss: 3.0162391662597656
Validation loss: 2.6935497406990296

Epoch: 6| Step: 9
Training loss: 3.225569725036621
Validation loss: 2.6908163203988025

Epoch: 6| Step: 10
Training loss: 3.388864517211914
Validation loss: 2.689169406890869

Epoch: 6| Step: 11
Training loss: 2.5072789192199707
Validation loss: 2.6882664593317176

Epoch: 6| Step: 12
Training loss: 1.807605504989624
Validation loss: 2.6871503655628493

Epoch: 6| Step: 13
Training loss: 1.9439648389816284
Validation loss: 2.688297656274611

Epoch: 31| Step: 0
Training loss: 2.323578357696533
Validation loss: 2.6859459364286034

Epoch: 6| Step: 1
Training loss: 3.267413377761841
Validation loss: 2.687780744285994

Epoch: 6| Step: 2
Training loss: 3.340012550354004
Validation loss: 2.687421116777646

Epoch: 6| Step: 3
Training loss: 1.8373539447784424
Validation loss: 2.6863980036909862

Epoch: 6| Step: 4
Training loss: 2.8786721229553223
Validation loss: 2.694358615465062

Epoch: 6| Step: 5
Training loss: 2.6937596797943115
Validation loss: 2.6916615860436552

Epoch: 6| Step: 6
Training loss: 3.0665600299835205
Validation loss: 2.6886161578598844

Epoch: 6| Step: 7
Training loss: 2.846804141998291
Validation loss: 2.6876625860891035

Epoch: 6| Step: 8
Training loss: 3.222775936126709
Validation loss: 2.689877020415439

Epoch: 6| Step: 9
Training loss: 2.092510461807251
Validation loss: 2.6858576395178355

Epoch: 6| Step: 10
Training loss: 2.889883518218994
Validation loss: 2.687008560344737

Epoch: 6| Step: 11
Training loss: 3.693789482116699
Validation loss: 2.681579174533967

Epoch: 6| Step: 12
Training loss: 2.3693225383758545
Validation loss: 2.6813775826525945

Epoch: 6| Step: 13
Training loss: 3.5633931159973145
Validation loss: 2.6841898707933325

Epoch: 32| Step: 0
Training loss: 2.5561039447784424
Validation loss: 2.6810173552523375

Epoch: 6| Step: 1
Training loss: 3.6627345085144043
Validation loss: 2.6794305129717757

Epoch: 6| Step: 2
Training loss: 3.02264404296875
Validation loss: 2.683893918991089

Epoch: 6| Step: 3
Training loss: 3.2072160243988037
Validation loss: 2.6876231778052544

Epoch: 6| Step: 4
Training loss: 3.2907257080078125
Validation loss: 2.686761999642977

Epoch: 6| Step: 5
Training loss: 2.2776172161102295
Validation loss: 2.6936017185129146

Epoch: 6| Step: 6
Training loss: 2.887087821960449
Validation loss: 2.689924070912023

Epoch: 6| Step: 7
Training loss: 2.415867328643799
Validation loss: 2.6834906378099994

Epoch: 6| Step: 8
Training loss: 2.4396891593933105
Validation loss: 2.680706524079846

Epoch: 6| Step: 9
Training loss: 2.548647880554199
Validation loss: 2.6811207904610583

Epoch: 6| Step: 10
Training loss: 2.7475099563598633
Validation loss: 2.6896944379293792

Epoch: 6| Step: 11
Training loss: 2.6864657402038574
Validation loss: 2.6923462498572563

Epoch: 6| Step: 12
Training loss: 3.3325700759887695
Validation loss: 2.6953427458322174

Epoch: 6| Step: 13
Training loss: 2.5267300605773926
Validation loss: 2.6890465110860844

Epoch: 33| Step: 0
Training loss: 2.9579148292541504
Validation loss: 2.6874217858878513

Epoch: 6| Step: 1
Training loss: 2.5904242992401123
Validation loss: 2.683853651887627

Epoch: 6| Step: 2
Training loss: 3.5396387577056885
Validation loss: 2.6844274536255868

Epoch: 6| Step: 3
Training loss: 3.0765299797058105
Validation loss: 2.6847868991154495

Epoch: 6| Step: 4
Training loss: 1.2360637187957764
Validation loss: 2.6847164477071455

Epoch: 6| Step: 5
Training loss: 2.0513360500335693
Validation loss: 2.68236017739901

Epoch: 6| Step: 6
Training loss: 3.7616734504699707
Validation loss: 2.6865068084450177

Epoch: 6| Step: 7
Training loss: 3.0135459899902344
Validation loss: 2.6837013844520814

Epoch: 6| Step: 8
Training loss: 2.6054842472076416
Validation loss: 2.6873839619339153

Epoch: 6| Step: 9
Training loss: 2.970414638519287
Validation loss: 2.6881799287693475

Epoch: 6| Step: 10
Training loss: 2.622109889984131
Validation loss: 2.6882634444903304

Epoch: 6| Step: 11
Training loss: 3.9837794303894043
Validation loss: 2.6858425730018207

Epoch: 6| Step: 12
Training loss: 2.4411673545837402
Validation loss: 2.685471555238129

Epoch: 6| Step: 13
Training loss: 2.9382357597351074
Validation loss: 2.68132161325024

Epoch: 34| Step: 0
Training loss: 2.8010659217834473
Validation loss: 2.6744797665585756

Epoch: 6| Step: 1
Training loss: 2.9331507682800293
Validation loss: 2.672427149229152

Epoch: 6| Step: 2
Training loss: 2.1978070735931396
Validation loss: 2.670392841421148

Epoch: 6| Step: 3
Training loss: 2.3084239959716797
Validation loss: 2.6698051037326938

Epoch: 6| Step: 4
Training loss: 3.025435447692871
Validation loss: 2.6715801736359954

Epoch: 6| Step: 5
Training loss: 2.284895896911621
Validation loss: 2.67262012984163

Epoch: 6| Step: 6
Training loss: 2.9157824516296387
Validation loss: 2.672586412839992

Epoch: 6| Step: 7
Training loss: 3.7161765098571777
Validation loss: 2.6718101642465077

Epoch: 6| Step: 8
Training loss: 3.2598843574523926
Validation loss: 2.6716928507692073

Epoch: 6| Step: 9
Training loss: 2.95855712890625
Validation loss: 2.6691366088005806

Epoch: 6| Step: 10
Training loss: 2.299853563308716
Validation loss: 2.6712508022144275

Epoch: 6| Step: 11
Training loss: 3.7108497619628906
Validation loss: 2.6709643640825824

Epoch: 6| Step: 12
Training loss: 2.1901607513427734
Validation loss: 2.6684413366420294

Epoch: 6| Step: 13
Training loss: 3.0998082160949707
Validation loss: 2.668296319182201

Epoch: 35| Step: 0
Training loss: 2.9378232955932617
Validation loss: 2.6670535354204077

Epoch: 6| Step: 1
Training loss: 2.7258713245391846
Validation loss: 2.667987056957778

Epoch: 6| Step: 2
Training loss: 2.5222020149230957
Validation loss: 2.668175141016642

Epoch: 6| Step: 3
Training loss: 2.9103002548217773
Validation loss: 2.6668200800495763

Epoch: 6| Step: 4
Training loss: 1.8791158199310303
Validation loss: 2.668405814837384

Epoch: 6| Step: 5
Training loss: 3.337522268295288
Validation loss: 2.672827623223746

Epoch: 6| Step: 6
Training loss: 2.2515456676483154
Validation loss: 2.670401588562996

Epoch: 6| Step: 7
Training loss: 3.166046619415283
Validation loss: 2.673813404575471

Epoch: 6| Step: 8
Training loss: 2.8950934410095215
Validation loss: 2.6667505771883073

Epoch: 6| Step: 9
Training loss: 2.7349672317504883
Validation loss: 2.6694935726863083

Epoch: 6| Step: 10
Training loss: 2.666025161743164
Validation loss: 2.670215365707233

Epoch: 6| Step: 11
Training loss: 3.482828140258789
Validation loss: 2.67226662687076

Epoch: 6| Step: 12
Training loss: 2.583383321762085
Validation loss: 2.6709655484845563

Epoch: 6| Step: 13
Training loss: 3.860485553741455
Validation loss: 2.6721987903759046

Epoch: 36| Step: 0
Training loss: 2.07743239402771
Validation loss: 2.6724167998119066

Epoch: 6| Step: 1
Training loss: 3.0317511558532715
Validation loss: 2.6766074601040093

Epoch: 6| Step: 2
Training loss: 3.524846315383911
Validation loss: 2.6786783767002884

Epoch: 6| Step: 3
Training loss: 2.9181973934173584
Validation loss: 2.6844850432488228

Epoch: 6| Step: 4
Training loss: 1.8291759490966797
Validation loss: 2.6976571441978536

Epoch: 6| Step: 5
Training loss: 3.0751447677612305
Validation loss: 2.6993768650998353

Epoch: 6| Step: 6
Training loss: 2.538738250732422
Validation loss: 2.6831288004434235

Epoch: 6| Step: 7
Training loss: 2.7223927974700928
Validation loss: 2.6811248512678247

Epoch: 6| Step: 8
Training loss: 3.4986636638641357
Validation loss: 2.6676007009321645

Epoch: 6| Step: 9
Training loss: 3.0037059783935547
Validation loss: 2.664969223801808

Epoch: 6| Step: 10
Training loss: 2.914340019226074
Validation loss: 2.6594459292709187

Epoch: 6| Step: 11
Training loss: 2.2969722747802734
Validation loss: 2.6601107351241575

Epoch: 6| Step: 12
Training loss: 2.831848621368408
Validation loss: 2.6638396401559152

Epoch: 6| Step: 13
Training loss: 3.759263753890991
Validation loss: 2.6628557917892293

Epoch: 37| Step: 0
Training loss: 2.442092180252075
Validation loss: 2.6614250521506033

Epoch: 6| Step: 1
Training loss: 3.1509320735931396
Validation loss: 2.665943063715453

Epoch: 6| Step: 2
Training loss: 3.4315357208251953
Validation loss: 2.6630268609651955

Epoch: 6| Step: 3
Training loss: 1.9859365224838257
Validation loss: 2.660303702918432

Epoch: 6| Step: 4
Training loss: 2.957973003387451
Validation loss: 2.6544976670254945

Epoch: 6| Step: 5
Training loss: 2.1284070014953613
Validation loss: 2.6562481541787424

Epoch: 6| Step: 6
Training loss: 3.0091943740844727
Validation loss: 2.655773972952238

Epoch: 6| Step: 7
Training loss: 2.5579776763916016
Validation loss: 2.657447358613373

Epoch: 6| Step: 8
Training loss: 2.6626386642456055
Validation loss: 2.6593713119465816

Epoch: 6| Step: 9
Training loss: 3.4749698638916016
Validation loss: 2.6624839690423783

Epoch: 6| Step: 10
Training loss: 3.282092332839966
Validation loss: 2.6610977752234346

Epoch: 6| Step: 11
Training loss: 2.3170440196990967
Validation loss: 2.662015102242911

Epoch: 6| Step: 12
Training loss: 3.2960805892944336
Validation loss: 2.6596347952401764

Epoch: 6| Step: 13
Training loss: 2.7515974044799805
Validation loss: 2.6606079814254597

Epoch: 38| Step: 0
Training loss: 2.437242031097412
Validation loss: 2.656595000656702

Epoch: 6| Step: 1
Training loss: 2.241014242172241
Validation loss: 2.656574797886674

Epoch: 6| Step: 2
Training loss: 3.1222541332244873
Validation loss: 2.655616893563219

Epoch: 6| Step: 3
Training loss: 3.0540242195129395
Validation loss: 2.650482516134939

Epoch: 6| Step: 4
Training loss: 3.687502861022949
Validation loss: 2.652398911855554

Epoch: 6| Step: 5
Training loss: 2.5599656105041504
Validation loss: 2.6569044102904615

Epoch: 6| Step: 6
Training loss: 2.2624263763427734
Validation loss: 2.661020440440024

Epoch: 6| Step: 7
Training loss: 3.1362671852111816
Validation loss: 2.665457089742025

Epoch: 6| Step: 8
Training loss: 2.544428825378418
Validation loss: 2.6722590872036514

Epoch: 6| Step: 9
Training loss: 2.8380815982818604
Validation loss: 2.6775276917283253

Epoch: 6| Step: 10
Training loss: 2.936619520187378
Validation loss: 2.682121023055046

Epoch: 6| Step: 11
Training loss: 1.69875168800354
Validation loss: 2.672834260489351

Epoch: 6| Step: 12
Training loss: 3.643183708190918
Validation loss: 2.6739722118582776

Epoch: 6| Step: 13
Training loss: 3.6550533771514893
Validation loss: 2.662069818024994

Epoch: 39| Step: 0
Training loss: 2.749119520187378
Validation loss: 2.6565217125800347

Epoch: 6| Step: 1
Training loss: 2.4452013969421387
Validation loss: 2.6491147882194928

Epoch: 6| Step: 2
Training loss: 2.3785476684570312
Validation loss: 2.6476990586967877

Epoch: 6| Step: 3
Training loss: 2.473616600036621
Validation loss: 2.6535099860160583

Epoch: 6| Step: 4
Training loss: 3.3185176849365234
Validation loss: 2.6516492264245146

Epoch: 6| Step: 5
Training loss: 3.618919849395752
Validation loss: 2.6496406037320375

Epoch: 6| Step: 6
Training loss: 2.4742138385772705
Validation loss: 2.6497636969371507

Epoch: 6| Step: 7
Training loss: 2.6895432472229004
Validation loss: 2.6504474788583736

Epoch: 6| Step: 8
Training loss: 3.294734477996826
Validation loss: 2.6524180391783356

Epoch: 6| Step: 9
Training loss: 3.5940189361572266
Validation loss: 2.6604685962841077

Epoch: 6| Step: 10
Training loss: 2.4160337448120117
Validation loss: 2.666975644326979

Epoch: 6| Step: 11
Training loss: 1.6249562501907349
Validation loss: 2.682797867764709

Epoch: 6| Step: 12
Training loss: 3.013835906982422
Validation loss: 2.7087037178777877

Epoch: 6| Step: 13
Training loss: 3.955885171890259
Validation loss: 2.720909010979437

Epoch: 40| Step: 0
Training loss: 2.3833727836608887
Validation loss: 2.7188673839774182

Epoch: 6| Step: 1
Training loss: 3.5548858642578125
Validation loss: 2.718729926693824

Epoch: 6| Step: 2
Training loss: 3.0870962142944336
Validation loss: 2.7129526394669727

Epoch: 6| Step: 3
Training loss: 3.3274383544921875
Validation loss: 2.710288514373123

Epoch: 6| Step: 4
Training loss: 1.732493281364441
Validation loss: 2.7059052067418254

Epoch: 6| Step: 5
Training loss: 3.2409725189208984
Validation loss: 2.7063422997792563

Epoch: 6| Step: 6
Training loss: 2.5855050086975098
Validation loss: 2.7109714605474986

Epoch: 6| Step: 7
Training loss: 2.775543212890625
Validation loss: 2.7053719233441096

Epoch: 6| Step: 8
Training loss: 2.525254249572754
Validation loss: 2.701955231287146

Epoch: 6| Step: 9
Training loss: 3.1132383346557617
Validation loss: 2.7000662895940963

Epoch: 6| Step: 10
Training loss: 2.4721145629882812
Validation loss: 2.702811377022856

Epoch: 6| Step: 11
Training loss: 2.9792842864990234
Validation loss: 2.699514965857229

Epoch: 6| Step: 12
Training loss: 3.805659770965576
Validation loss: 2.700793743133545

Epoch: 6| Step: 13
Training loss: 1.9001519680023193
Validation loss: 2.698024295991467

Epoch: 41| Step: 0
Training loss: 2.2089200019836426
Validation loss: 2.6966311598336823

Epoch: 6| Step: 1
Training loss: 3.7235941886901855
Validation loss: 2.6983674008359193

Epoch: 6| Step: 2
Training loss: 4.026294708251953
Validation loss: 2.6944473148674093

Epoch: 6| Step: 3
Training loss: 2.598837375640869
Validation loss: 2.6899246349129626

Epoch: 6| Step: 4
Training loss: 2.334782123565674
Validation loss: 2.6867737154806814

Epoch: 6| Step: 5
Training loss: 2.31209397315979
Validation loss: 2.67715016488106

Epoch: 6| Step: 6
Training loss: 2.1031301021575928
Validation loss: 2.6674446521266812

Epoch: 6| Step: 7
Training loss: 2.546647787094116
Validation loss: 2.6581680031232935

Epoch: 6| Step: 8
Training loss: 2.548997163772583
Validation loss: 2.653911969994986

Epoch: 6| Step: 9
Training loss: 3.231950283050537
Validation loss: 2.6468107161983365

Epoch: 6| Step: 10
Training loss: 3.261965751647949
Validation loss: 2.6466956625702562

Epoch: 6| Step: 11
Training loss: 2.638622999191284
Validation loss: 2.6508524853696107

Epoch: 6| Step: 12
Training loss: 2.8769915103912354
Validation loss: 2.6532107501901607

Epoch: 6| Step: 13
Training loss: 3.3519058227539062
Validation loss: 2.653470867423601

Epoch: 42| Step: 0
Training loss: 2.5900821685791016
Validation loss: 2.6467529368656937

Epoch: 6| Step: 1
Training loss: 2.5536320209503174
Validation loss: 2.6428361605572444

Epoch: 6| Step: 2
Training loss: 2.4196207523345947
Validation loss: 2.641325589149229

Epoch: 6| Step: 3
Training loss: 2.6111562252044678
Validation loss: 2.637971208941552

Epoch: 6| Step: 4
Training loss: 2.769798517227173
Validation loss: 2.632877803617908

Epoch: 6| Step: 5
Training loss: 3.3184127807617188
Validation loss: 2.6356164229813444

Epoch: 6| Step: 6
Training loss: 2.903994560241699
Validation loss: 2.6399680414507465

Epoch: 6| Step: 7
Training loss: 2.482992649078369
Validation loss: 2.644654796969506

Epoch: 6| Step: 8
Training loss: 2.7157626152038574
Validation loss: 2.6525584651577856

Epoch: 6| Step: 9
Training loss: 2.8647820949554443
Validation loss: 2.6562808995605796

Epoch: 6| Step: 10
Training loss: 3.007327079772949
Validation loss: 2.6552798081469793

Epoch: 6| Step: 11
Training loss: 3.0093986988067627
Validation loss: 2.6597446574959704

Epoch: 6| Step: 12
Training loss: 3.6018869876861572
Validation loss: 2.6532426803342757

Epoch: 6| Step: 13
Training loss: 2.012525796890259
Validation loss: 2.6437776139987412

Epoch: 43| Step: 0
Training loss: 2.7208943367004395
Validation loss: 2.6375199210259224

Epoch: 6| Step: 1
Training loss: 3.2524542808532715
Validation loss: 2.6301561581191195

Epoch: 6| Step: 2
Training loss: 2.7611730098724365
Validation loss: 2.6355516500370477

Epoch: 6| Step: 3
Training loss: 2.5707249641418457
Validation loss: 2.636695777216265

Epoch: 6| Step: 4
Training loss: 3.250892162322998
Validation loss: 2.6394965135922996

Epoch: 6| Step: 5
Training loss: 2.712467670440674
Validation loss: 2.634067314927296

Epoch: 6| Step: 6
Training loss: 2.4373903274536133
Validation loss: 2.630750343363772

Epoch: 6| Step: 7
Training loss: 3.257387399673462
Validation loss: 2.6281829059764905

Epoch: 6| Step: 8
Training loss: 3.8979251384735107
Validation loss: 2.6252716228526127

Epoch: 6| Step: 9
Training loss: 2.2750673294067383
Validation loss: 2.628573881682529

Epoch: 6| Step: 10
Training loss: 2.9566895961761475
Validation loss: 2.631332310297156

Epoch: 6| Step: 11
Training loss: 2.495506763458252
Validation loss: 2.6366467296436267

Epoch: 6| Step: 12
Training loss: 1.965539813041687
Validation loss: 2.6298370771510626

Epoch: 6| Step: 13
Training loss: 2.3896408081054688
Validation loss: 2.631043500797723

Epoch: 44| Step: 0
Training loss: 3.6461963653564453
Validation loss: 2.6392637811681277

Epoch: 6| Step: 1
Training loss: 2.986600875854492
Validation loss: 2.635644515355428

Epoch: 6| Step: 2
Training loss: 2.0842809677124023
Validation loss: 2.64217625382126

Epoch: 6| Step: 3
Training loss: 2.512587308883667
Validation loss: 2.6354302437074724

Epoch: 6| Step: 4
Training loss: 2.650479316711426
Validation loss: 2.6338669920480378

Epoch: 6| Step: 5
Training loss: 2.834501266479492
Validation loss: 2.6284166202750257

Epoch: 6| Step: 6
Training loss: 2.439497709274292
Validation loss: 2.6244939834840837

Epoch: 6| Step: 7
Training loss: 3.2764368057250977
Validation loss: 2.627146501694956

Epoch: 6| Step: 8
Training loss: 2.9781174659729004
Validation loss: 2.623415188122821

Epoch: 6| Step: 9
Training loss: 2.212324619293213
Validation loss: 2.6281384319387455

Epoch: 6| Step: 10
Training loss: 2.5138580799102783
Validation loss: 2.6303003705957884

Epoch: 6| Step: 11
Training loss: 2.5965065956115723
Validation loss: 2.6294066547065653

Epoch: 6| Step: 12
Training loss: 3.1025118827819824
Validation loss: 2.633045898970737

Epoch: 6| Step: 13
Training loss: 3.5260159969329834
Validation loss: 2.623379873973067

Epoch: 45| Step: 0
Training loss: 3.0843982696533203
Validation loss: 2.62444806098938

Epoch: 6| Step: 1
Training loss: 2.9787325859069824
Validation loss: 2.625908459386518

Epoch: 6| Step: 2
Training loss: 2.4163479804992676
Validation loss: 2.6266614544776177

Epoch: 6| Step: 3
Training loss: 2.9531469345092773
Validation loss: 2.6236289496062906

Epoch: 6| Step: 4
Training loss: 2.17641282081604
Validation loss: 2.62370632028067

Epoch: 6| Step: 5
Training loss: 2.1154465675354004
Validation loss: 2.6219859225775606

Epoch: 6| Step: 6
Training loss: 2.6002001762390137
Validation loss: 2.622943324427451

Epoch: 6| Step: 7
Training loss: 3.2712507247924805
Validation loss: 2.620551609223889

Epoch: 6| Step: 8
Training loss: 2.920921802520752
Validation loss: 2.6169387396945747

Epoch: 6| Step: 9
Training loss: 2.8036623001098633
Validation loss: 2.6218114411959084

Epoch: 6| Step: 10
Training loss: 3.2778728008270264
Validation loss: 2.624143185154084

Epoch: 6| Step: 11
Training loss: 2.5922775268554688
Validation loss: 2.6193456854871524

Epoch: 6| Step: 12
Training loss: 3.310694694519043
Validation loss: 2.617570500220022

Epoch: 6| Step: 13
Training loss: 2.336798667907715
Validation loss: 2.6208426798543623

Epoch: 46| Step: 0
Training loss: 2.3790183067321777
Validation loss: 2.6256074649031445

Epoch: 6| Step: 1
Training loss: 2.2933526039123535
Validation loss: 2.629328861031481

Epoch: 6| Step: 2
Training loss: 3.255797863006592
Validation loss: 2.631993245053035

Epoch: 6| Step: 3
Training loss: 3.261664390563965
Validation loss: 2.633179118556361

Epoch: 6| Step: 4
Training loss: 2.0923266410827637
Validation loss: 2.6481994813488376

Epoch: 6| Step: 5
Training loss: 2.098292827606201
Validation loss: 2.6514273100001837

Epoch: 6| Step: 6
Training loss: 2.6329357624053955
Validation loss: 2.6516798362937024

Epoch: 6| Step: 7
Training loss: 2.932448387145996
Validation loss: 2.6275489714837845

Epoch: 6| Step: 8
Training loss: 3.2544772624969482
Validation loss: 2.6202361147890807

Epoch: 6| Step: 9
Training loss: 2.379256248474121
Validation loss: 2.6163757385746127

Epoch: 6| Step: 10
Training loss: 3.2975807189941406
Validation loss: 2.6135429079814623

Epoch: 6| Step: 11
Training loss: 3.040393829345703
Validation loss: 2.6153146836065475

Epoch: 6| Step: 12
Training loss: 3.448441982269287
Validation loss: 2.618131899064587

Epoch: 6| Step: 13
Training loss: 2.636931896209717
Validation loss: 2.6200504533706175

Epoch: 47| Step: 0
Training loss: 2.932556629180908
Validation loss: 2.6217780318311465

Epoch: 6| Step: 1
Training loss: 2.382345676422119
Validation loss: 2.6264061876522597

Epoch: 6| Step: 2
Training loss: 2.6987690925598145
Validation loss: 2.622982781420472

Epoch: 6| Step: 3
Training loss: 3.664602756500244
Validation loss: 2.6256511134486042

Epoch: 6| Step: 4
Training loss: 2.4382431507110596
Validation loss: 2.621014950095966

Epoch: 6| Step: 5
Training loss: 2.164975643157959
Validation loss: 2.6193395224950646

Epoch: 6| Step: 6
Training loss: 2.987563133239746
Validation loss: 2.6167567545367825

Epoch: 6| Step: 7
Training loss: 2.5955426692962646
Validation loss: 2.6161410859836045

Epoch: 6| Step: 8
Training loss: 3.3144893646240234
Validation loss: 2.616583613939183

Epoch: 6| Step: 9
Training loss: 2.412583827972412
Validation loss: 2.6255665030530704

Epoch: 6| Step: 10
Training loss: 3.3037216663360596
Validation loss: 2.6296783006319435

Epoch: 6| Step: 11
Training loss: 2.985870838165283
Validation loss: 2.6440814002867667

Epoch: 6| Step: 12
Training loss: 2.1543188095092773
Validation loss: 2.642647139487728

Epoch: 6| Step: 13
Training loss: 3.297605276107788
Validation loss: 2.636162914255614

Epoch: 48| Step: 0
Training loss: 2.6805858612060547
Validation loss: 2.6295323115523144

Epoch: 6| Step: 1
Training loss: 3.4100341796875
Validation loss: 2.6222031629213722

Epoch: 6| Step: 2
Training loss: 2.815654754638672
Validation loss: 2.622019011487243

Epoch: 6| Step: 3
Training loss: 3.0044445991516113
Validation loss: 2.618748585383097

Epoch: 6| Step: 4
Training loss: 2.7180943489074707
Validation loss: 2.6182758961954424

Epoch: 6| Step: 5
Training loss: 2.443325996398926
Validation loss: 2.611231691093855

Epoch: 6| Step: 6
Training loss: 2.398630380630493
Validation loss: 2.606426969651253

Epoch: 6| Step: 7
Training loss: 2.84385085105896
Validation loss: 2.6083515433854956

Epoch: 6| Step: 8
Training loss: 2.33072829246521
Validation loss: 2.609940476314996

Epoch: 6| Step: 9
Training loss: 3.4543466567993164
Validation loss: 2.6088397041443856

Epoch: 6| Step: 10
Training loss: 2.401878595352173
Validation loss: 2.609481268031623

Epoch: 6| Step: 11
Training loss: 3.266357660293579
Validation loss: 2.608866404461604

Epoch: 6| Step: 12
Training loss: 2.7025840282440186
Validation loss: 2.6088884799711165

Epoch: 6| Step: 13
Training loss: 2.1787586212158203
Validation loss: 2.6089353740856214

Epoch: 49| Step: 0
Training loss: 2.641552448272705
Validation loss: 2.60853668438491

Epoch: 6| Step: 1
Training loss: 3.137434720993042
Validation loss: 2.607343268650834

Epoch: 6| Step: 2
Training loss: 3.079550266265869
Validation loss: 2.607136341833299

Epoch: 6| Step: 3
Training loss: 2.3178834915161133
Validation loss: 2.6069614707782702

Epoch: 6| Step: 4
Training loss: 3.5877227783203125
Validation loss: 2.6043532612503215

Epoch: 6| Step: 5
Training loss: 2.661486864089966
Validation loss: 2.6081254225905224

Epoch: 6| Step: 6
Training loss: 2.2633841037750244
Validation loss: 2.606250693721156

Epoch: 6| Step: 7
Training loss: 2.5388641357421875
Validation loss: 2.6070797699753956

Epoch: 6| Step: 8
Training loss: 2.8628292083740234
Validation loss: 2.6059409264595277

Epoch: 6| Step: 9
Training loss: 2.574049472808838
Validation loss: 2.6007666716011624

Epoch: 6| Step: 10
Training loss: 2.74173903465271
Validation loss: 2.6008741163438365

Epoch: 6| Step: 11
Training loss: 2.5164308547973633
Validation loss: 2.604696709622619

Epoch: 6| Step: 12
Training loss: 2.5809166431427
Validation loss: 2.6134598537157943

Epoch: 6| Step: 13
Training loss: 3.739192485809326
Validation loss: 2.6225799565674155

Epoch: 50| Step: 0
Training loss: 1.9341304302215576
Validation loss: 2.625401173868487

Epoch: 6| Step: 1
Training loss: 2.4579358100891113
Validation loss: 2.6261161424780406

Epoch: 6| Step: 2
Training loss: 3.3950307369232178
Validation loss: 2.632150434678601

Epoch: 6| Step: 3
Training loss: 2.4753262996673584
Validation loss: 2.6384563907500236

Epoch: 6| Step: 4
Training loss: 2.891014814376831
Validation loss: 2.64291295184884

Epoch: 6| Step: 5
Training loss: 2.852753162384033
Validation loss: 2.6363102877011864

Epoch: 6| Step: 6
Training loss: 2.2728939056396484
Validation loss: 2.641494938122329

Epoch: 6| Step: 7
Training loss: 2.744095802307129
Validation loss: 2.6242463255441315

Epoch: 6| Step: 8
Training loss: 2.964700222015381
Validation loss: 2.617877660259124

Epoch: 6| Step: 9
Training loss: 3.0335233211517334
Validation loss: 2.6049734469382995

Epoch: 6| Step: 10
Training loss: 3.325291156768799
Validation loss: 2.5936842631268244

Epoch: 6| Step: 11
Training loss: 2.806896924972534
Validation loss: 2.600212376604798

Epoch: 6| Step: 12
Training loss: 3.146437644958496
Validation loss: 2.6029781064679547

Epoch: 6| Step: 13
Training loss: 2.4805924892425537
Validation loss: 2.6112759651676303

Epoch: 51| Step: 0
Training loss: 2.8232526779174805
Validation loss: 2.6111364492806057

Epoch: 6| Step: 1
Training loss: 3.0278801918029785
Validation loss: 2.6094194086649085

Epoch: 6| Step: 2
Training loss: 3.758551597595215
Validation loss: 2.611141586816439

Epoch: 6| Step: 3
Training loss: 2.7413578033447266
Validation loss: 2.6113408868030836

Epoch: 6| Step: 4
Training loss: 2.5070512294769287
Validation loss: 2.605753360256072

Epoch: 6| Step: 5
Training loss: 2.0728654861450195
Validation loss: 2.6068813518811296

Epoch: 6| Step: 6
Training loss: 1.627643346786499
Validation loss: 2.606050588751352

Epoch: 6| Step: 7
Training loss: 2.7771100997924805
Validation loss: 2.6024927170045915

Epoch: 6| Step: 8
Training loss: 3.4477128982543945
Validation loss: 2.60066883794723

Epoch: 6| Step: 9
Training loss: 2.7356791496276855
Validation loss: 2.598368203768166

Epoch: 6| Step: 10
Training loss: 2.625258445739746
Validation loss: 2.5952588319778442

Epoch: 6| Step: 11
Training loss: 2.77913236618042
Validation loss: 2.597002875420355

Epoch: 6| Step: 12
Training loss: 3.1982641220092773
Validation loss: 2.5947726695768294

Epoch: 6| Step: 13
Training loss: 2.735252618789673
Validation loss: 2.6063702824295207

Epoch: 52| Step: 0
Training loss: 2.8837544918060303
Validation loss: 2.593508033342259

Epoch: 6| Step: 1
Training loss: 2.911212682723999
Validation loss: 2.5915740228468374

Epoch: 6| Step: 2
Training loss: 2.2495133876800537
Validation loss: 2.5909100194131174

Epoch: 6| Step: 3
Training loss: 3.0000100135803223
Validation loss: 2.586258416534752

Epoch: 6| Step: 4
Training loss: 2.3788509368896484
Validation loss: 2.5878795244360484

Epoch: 6| Step: 5
Training loss: 2.945830821990967
Validation loss: 2.5932004374842488

Epoch: 6| Step: 6
Training loss: 3.1508188247680664
Validation loss: 2.5880785654949885

Epoch: 6| Step: 7
Training loss: 2.3575005531311035
Validation loss: 2.5898451228295603

Epoch: 6| Step: 8
Training loss: 2.5581438541412354
Validation loss: 2.5859016397947907

Epoch: 6| Step: 9
Training loss: 3.348623275756836
Validation loss: 2.5908973088828464

Epoch: 6| Step: 10
Training loss: 2.78265118598938
Validation loss: 2.5878261545652985

Epoch: 6| Step: 11
Training loss: 2.399162769317627
Validation loss: 2.589297492017028

Epoch: 6| Step: 12
Training loss: 2.470442771911621
Validation loss: 2.5877089013335524

Epoch: 6| Step: 13
Training loss: 3.6092708110809326
Validation loss: 2.5855657208350395

Epoch: 53| Step: 0
Training loss: 3.0031003952026367
Validation loss: 2.588733842295985

Epoch: 6| Step: 1
Training loss: 2.8402366638183594
Validation loss: 2.5863288243611655

Epoch: 6| Step: 2
Training loss: 2.4342281818389893
Validation loss: 2.586588967231012

Epoch: 6| Step: 3
Training loss: 2.2326674461364746
Validation loss: 2.5873897998563704

Epoch: 6| Step: 4
Training loss: 3.130861282348633
Validation loss: 2.590876166538526

Epoch: 6| Step: 5
Training loss: 3.0826549530029297
Validation loss: 2.585019180851598

Epoch: 6| Step: 6
Training loss: 2.6548666954040527
Validation loss: 2.5921109466142553

Epoch: 6| Step: 7
Training loss: 2.676955461502075
Validation loss: 2.5998243260127243

Epoch: 6| Step: 8
Training loss: 2.780085563659668
Validation loss: 2.6009460264636624

Epoch: 6| Step: 9
Training loss: 2.919093608856201
Validation loss: 2.612488741515785

Epoch: 6| Step: 10
Training loss: 3.2137818336486816
Validation loss: 2.6217728507134224

Epoch: 6| Step: 11
Training loss: 3.657700300216675
Validation loss: 2.620401890047135

Epoch: 6| Step: 12
Training loss: 1.88145112991333
Validation loss: 2.6083927308359454

Epoch: 6| Step: 13
Training loss: 1.7373337745666504
Validation loss: 2.599310459629182

Epoch: 54| Step: 0
Training loss: 3.2131829261779785
Validation loss: 2.5975572191258913

Epoch: 6| Step: 1
Training loss: 2.8726863861083984
Validation loss: 2.595006671003116

Epoch: 6| Step: 2
Training loss: 2.4611501693725586
Validation loss: 2.597792281899401

Epoch: 6| Step: 3
Training loss: 2.5827674865722656
Validation loss: 2.5969672177427556

Epoch: 6| Step: 4
Training loss: 3.207385540008545
Validation loss: 2.5973827864534114

Epoch: 6| Step: 5
Training loss: 2.220367431640625
Validation loss: 2.601205489968741

Epoch: 6| Step: 6
Training loss: 2.5283749103546143
Validation loss: 2.6031795073581

Epoch: 6| Step: 7
Training loss: 3.6854214668273926
Validation loss: 2.5976567396553616

Epoch: 6| Step: 8
Training loss: 2.507533550262451
Validation loss: 2.592497561567573

Epoch: 6| Step: 9
Training loss: 2.0313806533813477
Validation loss: 2.591692611735354

Epoch: 6| Step: 10
Training loss: 3.651949644088745
Validation loss: 2.5861744983221895

Epoch: 6| Step: 11
Training loss: 2.9533743858337402
Validation loss: 2.586406392435874

Epoch: 6| Step: 12
Training loss: 2.0226359367370605
Validation loss: 2.5829278525485786

Epoch: 6| Step: 13
Training loss: 2.394631862640381
Validation loss: 2.580960196833457

Epoch: 55| Step: 0
Training loss: 3.0350613594055176
Validation loss: 2.5800612921355874

Epoch: 6| Step: 1
Training loss: 2.8509037494659424
Validation loss: 2.5799162259665867

Epoch: 6| Step: 2
Training loss: 2.145531177520752
Validation loss: 2.5814430034288796

Epoch: 6| Step: 3
Training loss: 3.3668761253356934
Validation loss: 2.578128486551264

Epoch: 6| Step: 4
Training loss: 2.8517534732818604
Validation loss: 2.5801490814455095

Epoch: 6| Step: 5
Training loss: 2.6360459327697754
Validation loss: 2.580816665644287

Epoch: 6| Step: 6
Training loss: 2.3599581718444824
Validation loss: 2.5774451071216213

Epoch: 6| Step: 7
Training loss: 2.31455397605896
Validation loss: 2.576484951921689

Epoch: 6| Step: 8
Training loss: 2.9658145904541016
Validation loss: 2.5757101017941713

Epoch: 6| Step: 9
Training loss: 3.292198657989502
Validation loss: 2.5741040680998113

Epoch: 6| Step: 10
Training loss: 3.1585593223571777
Validation loss: 2.5760586287385676

Epoch: 6| Step: 11
Training loss: 2.530107259750366
Validation loss: 2.5733824724792154

Epoch: 6| Step: 12
Training loss: 2.069549560546875
Validation loss: 2.5810819723272838

Epoch: 6| Step: 13
Training loss: 3.0144762992858887
Validation loss: 2.5729087911626345

Epoch: 56| Step: 0
Training loss: 3.0884532928466797
Validation loss: 2.5824992502889326

Epoch: 6| Step: 1
Training loss: 2.914418935775757
Validation loss: 2.5916022152029057

Epoch: 6| Step: 2
Training loss: 2.3144164085388184
Validation loss: 2.6071947031123663

Epoch: 6| Step: 3
Training loss: 2.972771644592285
Validation loss: 2.625369107851418

Epoch: 6| Step: 4
Training loss: 2.9848108291625977
Validation loss: 2.6105940598313526

Epoch: 6| Step: 5
Training loss: 3.1505041122436523
Validation loss: 2.6039094386562223

Epoch: 6| Step: 6
Training loss: 2.8666415214538574
Validation loss: 2.5966913802649385

Epoch: 6| Step: 7
Training loss: 3.432002067565918
Validation loss: 2.5911102858922814

Epoch: 6| Step: 8
Training loss: 2.6812777519226074
Validation loss: 2.5785189110745668

Epoch: 6| Step: 9
Training loss: 2.4666635990142822
Validation loss: 2.5663036787381737

Epoch: 6| Step: 10
Training loss: 2.5346546173095703
Validation loss: 2.5701759169178624

Epoch: 6| Step: 11
Training loss: 1.9081820249557495
Validation loss: 2.5755384224717335

Epoch: 6| Step: 12
Training loss: 2.519958019256592
Validation loss: 2.5756512790597896

Epoch: 6| Step: 13
Training loss: 2.771209716796875
Validation loss: 2.5720583751637447

Epoch: 57| Step: 0
Training loss: 2.5485122203826904
Validation loss: 2.568597441078514

Epoch: 6| Step: 1
Training loss: 2.579702377319336
Validation loss: 2.5690887153789563

Epoch: 6| Step: 2
Training loss: 2.6734235286712646
Validation loss: 2.567348300769765

Epoch: 6| Step: 3
Training loss: 2.976670265197754
Validation loss: 2.567406392866565

Epoch: 6| Step: 4
Training loss: 2.253309726715088
Validation loss: 2.566968115427161

Epoch: 6| Step: 5
Training loss: 2.3183913230895996
Validation loss: 2.569079024817354

Epoch: 6| Step: 6
Training loss: 2.548546314239502
Validation loss: 2.5744783801417195

Epoch: 6| Step: 7
Training loss: 2.749868869781494
Validation loss: 2.5788248072388353

Epoch: 6| Step: 8
Training loss: 3.294541597366333
Validation loss: 2.578293561935425

Epoch: 6| Step: 9
Training loss: 3.460197687149048
Validation loss: 2.5784960869819886

Epoch: 6| Step: 10
Training loss: 2.9512884616851807
Validation loss: 2.578051967005576

Epoch: 6| Step: 11
Training loss: 2.653411388397217
Validation loss: 2.578594802528299

Epoch: 6| Step: 12
Training loss: 2.72001051902771
Validation loss: 2.572741554629418

Epoch: 6| Step: 13
Training loss: 2.656477451324463
Validation loss: 2.574769860954695

Epoch: 58| Step: 0
Training loss: 3.2156548500061035
Validation loss: 2.577702388968519

Epoch: 6| Step: 1
Training loss: 2.7081680297851562
Validation loss: 2.579482998899234

Epoch: 6| Step: 2
Training loss: 2.845301628112793
Validation loss: 2.576512038066823

Epoch: 6| Step: 3
Training loss: 2.8148179054260254
Validation loss: 2.5783885166209233

Epoch: 6| Step: 4
Training loss: 2.9903597831726074
Validation loss: 2.573730109840311

Epoch: 6| Step: 5
Training loss: 3.184699296951294
Validation loss: 2.569470287651144

Epoch: 6| Step: 6
Training loss: 2.273232936859131
Validation loss: 2.57331552684948

Epoch: 6| Step: 7
Training loss: 2.4093217849731445
Validation loss: 2.5747193367250505

Epoch: 6| Step: 8
Training loss: 2.4737091064453125
Validation loss: 2.576374961483863

Epoch: 6| Step: 9
Training loss: 2.265378713607788
Validation loss: 2.580100095400246

Epoch: 6| Step: 10
Training loss: 2.319382667541504
Validation loss: 2.5743296146392822

Epoch: 6| Step: 11
Training loss: 3.378943920135498
Validation loss: 2.573248096691665

Epoch: 6| Step: 12
Training loss: 2.0992772579193115
Validation loss: 2.564527988433838

Epoch: 6| Step: 13
Training loss: 3.7734081745147705
Validation loss: 2.5622435000634964

Epoch: 59| Step: 0
Training loss: 3.0745561122894287
Validation loss: 2.559873298932147

Epoch: 6| Step: 1
Training loss: 2.8490066528320312
Validation loss: 2.5575504097887265

Epoch: 6| Step: 2
Training loss: 3.040060043334961
Validation loss: 2.5601839737225602

Epoch: 6| Step: 3
Training loss: 2.9932703971862793
Validation loss: 2.5580516322966544

Epoch: 6| Step: 4
Training loss: 2.73274564743042
Validation loss: 2.5574968502085698

Epoch: 6| Step: 5
Training loss: 2.4542465209960938
Validation loss: 2.558496185528335

Epoch: 6| Step: 6
Training loss: 2.386733055114746
Validation loss: 2.5610842422772477

Epoch: 6| Step: 7
Training loss: 1.7497118711471558
Validation loss: 2.5706492675248014

Epoch: 6| Step: 8
Training loss: 3.45365834236145
Validation loss: 2.5782025373110207

Epoch: 6| Step: 9
Training loss: 2.929184913635254
Validation loss: 2.592371917540027

Epoch: 6| Step: 10
Training loss: 2.3803272247314453
Validation loss: 2.591056421238889

Epoch: 6| Step: 11
Training loss: 2.6173346042633057
Validation loss: 2.5913099101794663

Epoch: 6| Step: 12
Training loss: 3.232128620147705
Validation loss: 2.5752806868604434

Epoch: 6| Step: 13
Training loss: 2.458510160446167
Validation loss: 2.5671350725235476

Epoch: 60| Step: 0
Training loss: 3.133638858795166
Validation loss: 2.5602360335729455

Epoch: 6| Step: 1
Training loss: 2.6018168926239014
Validation loss: 2.5567708015441895

Epoch: 6| Step: 2
Training loss: 2.1792850494384766
Validation loss: 2.556966006114919

Epoch: 6| Step: 3
Training loss: 2.6526451110839844
Validation loss: 2.5629471322541595

Epoch: 6| Step: 4
Training loss: 2.515058994293213
Validation loss: 2.5648095761576006

Epoch: 6| Step: 5
Training loss: 2.8233070373535156
Validation loss: 2.5646407347853466

Epoch: 6| Step: 6
Training loss: 2.9576478004455566
Validation loss: 2.557804156375188

Epoch: 6| Step: 7
Training loss: 2.393585205078125
Validation loss: 2.5566987914423787

Epoch: 6| Step: 8
Training loss: 3.0036208629608154
Validation loss: 2.555786927541097

Epoch: 6| Step: 9
Training loss: 3.458721160888672
Validation loss: 2.5533425474679596

Epoch: 6| Step: 10
Training loss: 2.814302921295166
Validation loss: 2.5593240517441944

Epoch: 6| Step: 11
Training loss: 2.5419511795043945
Validation loss: 2.566494244401173

Epoch: 6| Step: 12
Training loss: 2.9807851314544678
Validation loss: 2.5702931393859205

Epoch: 6| Step: 13
Training loss: 2.070589542388916
Validation loss: 2.5690211378118044

Epoch: 61| Step: 0
Training loss: 2.518238067626953
Validation loss: 2.5674100896363616

Epoch: 6| Step: 1
Training loss: 2.6159000396728516
Validation loss: 2.571821238404961

Epoch: 6| Step: 2
Training loss: 2.5078818798065186
Validation loss: 2.5714253353816208

Epoch: 6| Step: 3
Training loss: 3.4933156967163086
Validation loss: 2.5672783646532285

Epoch: 6| Step: 4
Training loss: 2.0552875995635986
Validation loss: 2.562809018678563

Epoch: 6| Step: 5
Training loss: 2.8778772354125977
Validation loss: 2.563919267346782

Epoch: 6| Step: 6
Training loss: 2.641505718231201
Validation loss: 2.5557640201301983

Epoch: 6| Step: 7
Training loss: 2.580538511276245
Validation loss: 2.558178919617848

Epoch: 6| Step: 8
Training loss: 3.3197898864746094
Validation loss: 2.554640298248619

Epoch: 6| Step: 9
Training loss: 2.5145978927612305
Validation loss: 2.5540642815251506

Epoch: 6| Step: 10
Training loss: 2.3805813789367676
Validation loss: 2.548737141393846

Epoch: 6| Step: 11
Training loss: 3.0086774826049805
Validation loss: 2.5529834506332234

Epoch: 6| Step: 12
Training loss: 2.8330230712890625
Validation loss: 2.552141225466164

Epoch: 6| Step: 13
Training loss: 3.074429988861084
Validation loss: 2.5540082813591085

Epoch: 62| Step: 0
Training loss: 2.3854026794433594
Validation loss: 2.554037199225477

Epoch: 6| Step: 1
Training loss: 2.6299033164978027
Validation loss: 2.5525408714048323

Epoch: 6| Step: 2
Training loss: 2.313969850540161
Validation loss: 2.553431559634465

Epoch: 6| Step: 3
Training loss: 3.547814130783081
Validation loss: 2.551980580053022

Epoch: 6| Step: 4
Training loss: 3.504180431365967
Validation loss: 2.552356017533169

Epoch: 6| Step: 5
Training loss: 2.4304301738739014
Validation loss: 2.553580966047061

Epoch: 6| Step: 6
Training loss: 2.801462411880493
Validation loss: 2.5484681001273533

Epoch: 6| Step: 7
Training loss: 1.8535881042480469
Validation loss: 2.546831218145227

Epoch: 6| Step: 8
Training loss: 2.061880111694336
Validation loss: 2.54424407405238

Epoch: 6| Step: 9
Training loss: 3.1797893047332764
Validation loss: 2.5470184408208376

Epoch: 6| Step: 10
Training loss: 2.2338032722473145
Validation loss: 2.5502876184319936

Epoch: 6| Step: 11
Training loss: 2.836585283279419
Validation loss: 2.5474213707831597

Epoch: 6| Step: 12
Training loss: 3.6192703247070312
Validation loss: 2.552834346730222

Epoch: 6| Step: 13
Training loss: 2.8848817348480225
Validation loss: 2.561509014457785

Epoch: 63| Step: 0
Training loss: 3.3477511405944824
Validation loss: 2.5689290646583802

Epoch: 6| Step: 1
Training loss: 2.9461565017700195
Validation loss: 2.570171258782828

Epoch: 6| Step: 2
Training loss: 2.5079126358032227
Validation loss: 2.5668722045037056

Epoch: 6| Step: 3
Training loss: 3.377500057220459
Validation loss: 2.5712532381857596

Epoch: 6| Step: 4
Training loss: 2.3899097442626953
Validation loss: 2.5804313485340407

Epoch: 6| Step: 5
Training loss: 2.386415481567383
Validation loss: 2.5789604981740317

Epoch: 6| Step: 6
Training loss: 2.784675121307373
Validation loss: 2.5757488512223765

Epoch: 6| Step: 7
Training loss: 3.2013814449310303
Validation loss: 2.5807869613811536

Epoch: 6| Step: 8
Training loss: 2.2800354957580566
Validation loss: 2.563083758918188

Epoch: 6| Step: 9
Training loss: 2.688483238220215
Validation loss: 2.5577834037042435

Epoch: 6| Step: 10
Training loss: 2.696622848510742
Validation loss: 2.5529172676865772

Epoch: 6| Step: 11
Training loss: 1.5406521558761597
Validation loss: 2.5472214811591694

Epoch: 6| Step: 12
Training loss: 3.174062728881836
Validation loss: 2.5402927244863203

Epoch: 6| Step: 13
Training loss: 2.9001989364624023
Validation loss: 2.5417516949356243

Epoch: 64| Step: 0
Training loss: 2.4457969665527344
Validation loss: 2.54643536895834

Epoch: 6| Step: 1
Training loss: 2.38026762008667
Validation loss: 2.5464057409635155

Epoch: 6| Step: 2
Training loss: 2.913956642150879
Validation loss: 2.5472004003422235

Epoch: 6| Step: 3
Training loss: 2.8159923553466797
Validation loss: 2.548700714624056

Epoch: 6| Step: 4
Training loss: 2.3077545166015625
Validation loss: 2.5483847241247854

Epoch: 6| Step: 5
Training loss: 2.5494346618652344
Validation loss: 2.5449432865265877

Epoch: 6| Step: 6
Training loss: 2.861204147338867
Validation loss: 2.5432751563287552

Epoch: 6| Step: 7
Training loss: 3.338947296142578
Validation loss: 2.544492165247599

Epoch: 6| Step: 8
Training loss: 3.5780413150787354
Validation loss: 2.5418614213184645

Epoch: 6| Step: 9
Training loss: 2.4154562950134277
Validation loss: 2.5407752939449844

Epoch: 6| Step: 10
Training loss: 2.6814465522766113
Validation loss: 2.5362076015882593

Epoch: 6| Step: 11
Training loss: 3.2520551681518555
Validation loss: 2.5387262452033257

Epoch: 6| Step: 12
Training loss: 2.252202033996582
Validation loss: 2.538619610571092

Epoch: 6| Step: 13
Training loss: 2.2404468059539795
Validation loss: 2.5369024020369335

Epoch: 65| Step: 0
Training loss: 2.452380657196045
Validation loss: 2.5354462926105787

Epoch: 6| Step: 1
Training loss: 3.436779737472534
Validation loss: 2.5377441272940686

Epoch: 6| Step: 2
Training loss: 2.7885243892669678
Validation loss: 2.5421227511539253

Epoch: 6| Step: 3
Training loss: 3.075160264968872
Validation loss: 2.540696426104474

Epoch: 6| Step: 4
Training loss: 2.373340368270874
Validation loss: 2.544230409847793

Epoch: 6| Step: 5
Training loss: 2.948362350463867
Validation loss: 2.5490391972244426

Epoch: 6| Step: 6
Training loss: 3.045053005218506
Validation loss: 2.5462269475383144

Epoch: 6| Step: 7
Training loss: 3.4374821186065674
Validation loss: 2.5446456504124466

Epoch: 6| Step: 8
Training loss: 2.033895492553711
Validation loss: 2.5440284590567313

Epoch: 6| Step: 9
Training loss: 2.4717085361480713
Validation loss: 2.5484578045465613

Epoch: 6| Step: 10
Training loss: 2.380772829055786
Validation loss: 2.5442360780572377

Epoch: 6| Step: 11
Training loss: 1.9879249334335327
Validation loss: 2.5454924491143998

Epoch: 6| Step: 12
Training loss: 2.8770675659179688
Validation loss: 2.541752184590986

Epoch: 6| Step: 13
Training loss: 2.7426278591156006
Validation loss: 2.542910818130739

Epoch: 66| Step: 0
Training loss: 3.1256067752838135
Validation loss: 2.546949473760461

Epoch: 6| Step: 1
Training loss: 2.234353542327881
Validation loss: 2.5423299599719305

Epoch: 6| Step: 2
Training loss: 2.594609260559082
Validation loss: 2.5403219474259244

Epoch: 6| Step: 3
Training loss: 3.5661282539367676
Validation loss: 2.5392256577809653

Epoch: 6| Step: 4
Training loss: 2.4425597190856934
Validation loss: 2.534128983815511

Epoch: 6| Step: 5
Training loss: 1.8160581588745117
Validation loss: 2.534480448692076

Epoch: 6| Step: 6
Training loss: 2.186342716217041
Validation loss: 2.538659998165664

Epoch: 6| Step: 7
Training loss: 3.0992164611816406
Validation loss: 2.534099317366077

Epoch: 6| Step: 8
Training loss: 2.835111141204834
Validation loss: 2.5327896738565094

Epoch: 6| Step: 9
Training loss: 2.7391066551208496
Validation loss: 2.531671872702978

Epoch: 6| Step: 10
Training loss: 2.476635217666626
Validation loss: 2.5303199855230187

Epoch: 6| Step: 11
Training loss: 2.857309341430664
Validation loss: 2.5286345661327405

Epoch: 6| Step: 12
Training loss: 3.019057273864746
Validation loss: 2.530647841832971

Epoch: 6| Step: 13
Training loss: 3.5129220485687256
Validation loss: 2.529502655870171

Epoch: 67| Step: 0
Training loss: 2.2153868675231934
Validation loss: 2.5307102741733676

Epoch: 6| Step: 1
Training loss: 2.9362549781799316
Validation loss: 2.5292225217306488

Epoch: 6| Step: 2
Training loss: 2.554096221923828
Validation loss: 2.5325334174658662

Epoch: 6| Step: 3
Training loss: 2.098479747772217
Validation loss: 2.5332818954221663

Epoch: 6| Step: 4
Training loss: 2.269362688064575
Validation loss: 2.534100978605209

Epoch: 6| Step: 5
Training loss: 2.884634256362915
Validation loss: 2.535185747249152

Epoch: 6| Step: 6
Training loss: 3.4358644485473633
Validation loss: 2.5361705364719516

Epoch: 6| Step: 7
Training loss: 2.372344970703125
Validation loss: 2.5351427088501635

Epoch: 6| Step: 8
Training loss: 2.4654030799865723
Validation loss: 2.5351142088572183

Epoch: 6| Step: 9
Training loss: 2.82712984085083
Validation loss: 2.538196045865295

Epoch: 6| Step: 10
Training loss: 3.013321876525879
Validation loss: 2.5362909250361945

Epoch: 6| Step: 11
Training loss: 2.274887800216675
Validation loss: 2.541050901976965

Epoch: 6| Step: 12
Training loss: 3.5388970375061035
Validation loss: 2.5398073811684885

Epoch: 6| Step: 13
Training loss: 3.43656063079834
Validation loss: 2.542523040566393

Epoch: 68| Step: 0
Training loss: 2.5959019660949707
Validation loss: 2.5492206311994985

Epoch: 6| Step: 1
Training loss: 3.3045384883880615
Validation loss: 2.546745307983891

Epoch: 6| Step: 2
Training loss: 3.0284461975097656
Validation loss: 2.5445630845203193

Epoch: 6| Step: 3
Training loss: 2.580430030822754
Validation loss: 2.536980826367614

Epoch: 6| Step: 4
Training loss: 1.757218360900879
Validation loss: 2.5354502329262356

Epoch: 6| Step: 5
Training loss: 2.0767855644226074
Validation loss: 2.5368412412622923

Epoch: 6| Step: 6
Training loss: 1.9878242015838623
Validation loss: 2.5458663894284155

Epoch: 6| Step: 7
Training loss: 3.213195323944092
Validation loss: 2.5501583827439176

Epoch: 6| Step: 8
Training loss: 2.6092259883880615
Validation loss: 2.544090796542424

Epoch: 6| Step: 9
Training loss: 3.4064786434173584
Validation loss: 2.534165838713287

Epoch: 6| Step: 10
Training loss: 3.0251870155334473
Validation loss: 2.5383379023562194

Epoch: 6| Step: 11
Training loss: 2.3999390602111816
Validation loss: 2.5332171929779874

Epoch: 6| Step: 12
Training loss: 3.4947333335876465
Validation loss: 2.527776354102678

Epoch: 6| Step: 13
Training loss: 2.38137149810791
Validation loss: 2.5253005745590373

Epoch: 69| Step: 0
Training loss: 3.2850780487060547
Validation loss: 2.5228196959341727

Epoch: 6| Step: 1
Training loss: 3.1165499687194824
Validation loss: 2.519890554489628

Epoch: 6| Step: 2
Training loss: 2.604098081588745
Validation loss: 2.5187723559717976

Epoch: 6| Step: 3
Training loss: 3.1079533100128174
Validation loss: 2.5209672451019287

Epoch: 6| Step: 4
Training loss: 2.232290744781494
Validation loss: 2.5194866554711455

Epoch: 6| Step: 5
Training loss: 3.772946834564209
Validation loss: 2.515894497594526

Epoch: 6| Step: 6
Training loss: 2.096653938293457
Validation loss: 2.5164089792518207

Epoch: 6| Step: 7
Training loss: 2.0466113090515137
Validation loss: 2.51785377020477

Epoch: 6| Step: 8
Training loss: 2.5788583755493164
Validation loss: 2.5219768093478296

Epoch: 6| Step: 9
Training loss: 2.280311107635498
Validation loss: 2.5238811867211455

Epoch: 6| Step: 10
Training loss: 1.9172660112380981
Validation loss: 2.535736689003565

Epoch: 6| Step: 11
Training loss: 2.9080848693847656
Validation loss: 2.5446786367765037

Epoch: 6| Step: 12
Training loss: 3.458735466003418
Validation loss: 2.5408523492915656

Epoch: 6| Step: 13
Training loss: 2.4078147411346436
Validation loss: 2.536270544093142

Epoch: 70| Step: 0
Training loss: 2.3795740604400635
Validation loss: 2.5389469951711674

Epoch: 6| Step: 1
Training loss: 3.2742815017700195
Validation loss: 2.53270806548416

Epoch: 6| Step: 2
Training loss: 2.361384391784668
Validation loss: 2.525737665032828

Epoch: 6| Step: 3
Training loss: 2.8303778171539307
Validation loss: 2.519743945008965

Epoch: 6| Step: 4
Training loss: 2.654135227203369
Validation loss: 2.5165698169380106

Epoch: 6| Step: 5
Training loss: 2.4056320190429688
Validation loss: 2.5107005180851107

Epoch: 6| Step: 6
Training loss: 2.354470729827881
Validation loss: 2.5114018404355614

Epoch: 6| Step: 7
Training loss: 3.4885716438293457
Validation loss: 2.5142302872032247

Epoch: 6| Step: 8
Training loss: 3.266704559326172
Validation loss: 2.512967355789677

Epoch: 6| Step: 9
Training loss: 2.923999071121216
Validation loss: 2.5133377531523347

Epoch: 6| Step: 10
Training loss: 2.547379970550537
Validation loss: 2.51397212859123

Epoch: 6| Step: 11
Training loss: 2.48455810546875
Validation loss: 2.5142722078548965

Epoch: 6| Step: 12
Training loss: 2.342461585998535
Validation loss: 2.5125431091554704

Epoch: 6| Step: 13
Training loss: 2.543879270553589
Validation loss: 2.512497099496985

Epoch: 71| Step: 0
Training loss: 2.9294919967651367
Validation loss: 2.5132576624552407

Epoch: 6| Step: 1
Training loss: 3.261345863342285
Validation loss: 2.5171836986336658

Epoch: 6| Step: 2
Training loss: 3.2438926696777344
Validation loss: 2.5180707208571897

Epoch: 6| Step: 3
Training loss: 2.3995044231414795
Validation loss: 2.5272215309963433

Epoch: 6| Step: 4
Training loss: 2.0045158863067627
Validation loss: 2.526687199069608

Epoch: 6| Step: 5
Training loss: 2.934302806854248
Validation loss: 2.5335517852537093

Epoch: 6| Step: 6
Training loss: 2.268329381942749
Validation loss: 2.530294346553023

Epoch: 6| Step: 7
Training loss: 2.4387965202331543
Validation loss: 2.5317501329606578

Epoch: 6| Step: 8
Training loss: 3.0547385215759277
Validation loss: 2.5312064463092434

Epoch: 6| Step: 9
Training loss: 2.768392562866211
Validation loss: 2.5247156696934856

Epoch: 6| Step: 10
Training loss: 2.4460549354553223
Validation loss: 2.524356590804233

Epoch: 6| Step: 11
Training loss: 2.676241874694824
Validation loss: 2.515947787992416

Epoch: 6| Step: 12
Training loss: 2.705580234527588
Validation loss: 2.5101750025185208

Epoch: 6| Step: 13
Training loss: 2.634289264678955
Validation loss: 2.512988939080187

Epoch: 72| Step: 0
Training loss: 3.0571584701538086
Validation loss: 2.5091506537570747

Epoch: 6| Step: 1
Training loss: 2.2647581100463867
Validation loss: 2.5121182677566365

Epoch: 6| Step: 2
Training loss: 2.932283639907837
Validation loss: 2.5153698562293925

Epoch: 6| Step: 3
Training loss: 2.2156808376312256
Validation loss: 2.513867549998786

Epoch: 6| Step: 4
Training loss: 3.4802396297454834
Validation loss: 2.513555460078742

Epoch: 6| Step: 5
Training loss: 2.78061580657959
Validation loss: 2.508569117515318

Epoch: 6| Step: 6
Training loss: 3.5039238929748535
Validation loss: 2.509929694155211

Epoch: 6| Step: 7
Training loss: 2.5021750926971436
Validation loss: 2.513119056660642

Epoch: 6| Step: 8
Training loss: 1.7679493427276611
Validation loss: 2.514387115355461

Epoch: 6| Step: 9
Training loss: 2.863831043243408
Validation loss: 2.5113287523228633

Epoch: 6| Step: 10
Training loss: 2.881692886352539
Validation loss: 2.516870980621666

Epoch: 6| Step: 11
Training loss: 2.87157940864563
Validation loss: 2.5200300293584026

Epoch: 6| Step: 12
Training loss: 2.2688090801239014
Validation loss: 2.5120911367477907

Epoch: 6| Step: 13
Training loss: 2.319826126098633
Validation loss: 2.510656133774788

Epoch: 73| Step: 0
Training loss: 2.0359420776367188
Validation loss: 2.510285864594162

Epoch: 6| Step: 1
Training loss: 2.736952304840088
Validation loss: 2.5086358875356694

Epoch: 6| Step: 2
Training loss: 3.1778531074523926
Validation loss: 2.511912807341545

Epoch: 6| Step: 3
Training loss: 2.733369827270508
Validation loss: 2.508801785848474

Epoch: 6| Step: 4
Training loss: 2.94354510307312
Validation loss: 2.5108195915017077

Epoch: 6| Step: 5
Training loss: 2.3011746406555176
Validation loss: 2.5066166898255706

Epoch: 6| Step: 6
Training loss: 3.094090461730957
Validation loss: 2.505561528667327

Epoch: 6| Step: 7
Training loss: 3.5421009063720703
Validation loss: 2.511307324132612

Epoch: 6| Step: 8
Training loss: 2.9654526710510254
Validation loss: 2.509928818671934

Epoch: 6| Step: 9
Training loss: 2.831000328063965
Validation loss: 2.504404822985331

Epoch: 6| Step: 10
Training loss: 1.7638111114501953
Validation loss: 2.5122427555822555

Epoch: 6| Step: 11
Training loss: 2.3217673301696777
Validation loss: 2.509354591369629

Epoch: 6| Step: 12
Training loss: 2.8246641159057617
Validation loss: 2.5099854494935725

Epoch: 6| Step: 13
Training loss: 2.3452813625335693
Validation loss: 2.5071486144937496

Epoch: 74| Step: 0
Training loss: 1.962698221206665
Validation loss: 2.50492755059273

Epoch: 6| Step: 1
Training loss: 2.442591667175293
Validation loss: 2.5045064341637397

Epoch: 6| Step: 2
Training loss: 2.14797306060791
Validation loss: 2.500897922823506

Epoch: 6| Step: 3
Training loss: 2.6936988830566406
Validation loss: 2.5016159857473066

Epoch: 6| Step: 4
Training loss: 2.715895175933838
Validation loss: 2.502709593824161

Epoch: 6| Step: 5
Training loss: 2.1447861194610596
Validation loss: 2.501043640157228

Epoch: 6| Step: 6
Training loss: 2.557346820831299
Validation loss: 2.499043510806176

Epoch: 6| Step: 7
Training loss: 2.9954915046691895
Validation loss: 2.502163315332064

Epoch: 6| Step: 8
Training loss: 2.8628530502319336
Validation loss: 2.505634625752767

Epoch: 6| Step: 9
Training loss: 3.7653262615203857
Validation loss: 2.509411438818901

Epoch: 6| Step: 10
Training loss: 2.693042755126953
Validation loss: 2.5139107934890257

Epoch: 6| Step: 11
Training loss: 2.4128475189208984
Validation loss: 2.5303370593696513

Epoch: 6| Step: 12
Training loss: 3.2236335277557373
Validation loss: 2.5403301254395516

Epoch: 6| Step: 13
Training loss: 3.444434642791748
Validation loss: 2.549397276293847

Epoch: 75| Step: 0
Training loss: 2.556657314300537
Validation loss: 2.542860654092604

Epoch: 6| Step: 1
Training loss: 2.719309091567993
Validation loss: 2.5217617019530265

Epoch: 6| Step: 2
Training loss: 2.139207363128662
Validation loss: 2.5139838546834965

Epoch: 6| Step: 3
Training loss: 2.625087261199951
Validation loss: 2.498456073063676

Epoch: 6| Step: 4
Training loss: 3.360542058944702
Validation loss: 2.502261902696343

Epoch: 6| Step: 5
Training loss: 2.5078842639923096
Validation loss: 2.5082773418836695

Epoch: 6| Step: 6
Training loss: 2.4190638065338135
Validation loss: 2.5158156348812963

Epoch: 6| Step: 7
Training loss: 3.2440085411071777
Validation loss: 2.5122339648585164

Epoch: 6| Step: 8
Training loss: 2.4346728324890137
Validation loss: 2.5106060197276454

Epoch: 6| Step: 9
Training loss: 2.4915292263031006
Validation loss: 2.5153551793867543

Epoch: 6| Step: 10
Training loss: 2.6750733852386475
Validation loss: 2.5056387480869087

Epoch: 6| Step: 11
Training loss: 3.276726245880127
Validation loss: 2.506188718221521

Epoch: 6| Step: 12
Training loss: 2.889667272567749
Validation loss: 2.4997497297102407

Epoch: 6| Step: 13
Training loss: 2.390004873275757
Validation loss: 2.4979671714126424

Epoch: 76| Step: 0
Training loss: 3.0306146144866943
Validation loss: 2.5004523031173216

Epoch: 6| Step: 1
Training loss: 3.2381856441497803
Validation loss: 2.4982906823517173

Epoch: 6| Step: 2
Training loss: 2.7162270545959473
Validation loss: 2.495818284250075

Epoch: 6| Step: 3
Training loss: 2.6410574913024902
Validation loss: 2.504055569248815

Epoch: 6| Step: 4
Training loss: 2.9596400260925293
Validation loss: 2.50636355082194

Epoch: 6| Step: 5
Training loss: 2.265285015106201
Validation loss: 2.505642952457551

Epoch: 6| Step: 6
Training loss: 3.0542330741882324
Validation loss: 2.5015468417957263

Epoch: 6| Step: 7
Training loss: 2.119124174118042
Validation loss: 2.501484212055001

Epoch: 6| Step: 8
Training loss: 2.333881378173828
Validation loss: 2.503070669789468

Epoch: 6| Step: 9
Training loss: 1.9247946739196777
Validation loss: 2.505907157415985

Epoch: 6| Step: 10
Training loss: 2.9565088748931885
Validation loss: 2.5096552884706886

Epoch: 6| Step: 11
Training loss: 3.3996925354003906
Validation loss: 2.5184842104552896

Epoch: 6| Step: 12
Training loss: 2.405423164367676
Validation loss: 2.525120750550301

Epoch: 6| Step: 13
Training loss: 2.612250566482544
Validation loss: 2.532390297100108

Epoch: 77| Step: 0
Training loss: 2.709697723388672
Validation loss: 2.5227724736736667

Epoch: 6| Step: 1
Training loss: 2.237170934677124
Validation loss: 2.5135678257993472

Epoch: 6| Step: 2
Training loss: 2.8081793785095215
Validation loss: 2.513855649578956

Epoch: 6| Step: 3
Training loss: 2.5904459953308105
Validation loss: 2.5099890539723058

Epoch: 6| Step: 4
Training loss: 2.7418246269226074
Validation loss: 2.500838707852107

Epoch: 6| Step: 5
Training loss: 2.3125386238098145
Validation loss: 2.5001024917889665

Epoch: 6| Step: 6
Training loss: 3.6195971965789795
Validation loss: 2.4955163309651036

Epoch: 6| Step: 7
Training loss: 2.1443822383880615
Validation loss: 2.5005874531243437

Epoch: 6| Step: 8
Training loss: 3.060331344604492
Validation loss: 2.4937902778707524

Epoch: 6| Step: 9
Training loss: 2.8032989501953125
Validation loss: 2.490331208834084

Epoch: 6| Step: 10
Training loss: 3.2262439727783203
Validation loss: 2.492643433232461

Epoch: 6| Step: 11
Training loss: 2.6399595737457275
Validation loss: 2.4949634434074484

Epoch: 6| Step: 12
Training loss: 1.9686440229415894
Validation loss: 2.495792258170343

Epoch: 6| Step: 13
Training loss: 2.880591630935669
Validation loss: 2.4938064006067093

Epoch: 78| Step: 0
Training loss: 3.0893850326538086
Validation loss: 2.4945996935649584

Epoch: 6| Step: 1
Training loss: 2.8355607986450195
Validation loss: 2.494660110883815

Epoch: 6| Step: 2
Training loss: 1.9809200763702393
Validation loss: 2.4892968285468315

Epoch: 6| Step: 3
Training loss: 1.94795823097229
Validation loss: 2.489185110215218

Epoch: 6| Step: 4
Training loss: 2.5703108310699463
Validation loss: 2.4888054465734832

Epoch: 6| Step: 5
Training loss: 2.318171977996826
Validation loss: 2.490715326801423

Epoch: 6| Step: 6
Training loss: 2.5281803607940674
Validation loss: 2.488785841131723

Epoch: 6| Step: 7
Training loss: 2.486828327178955
Validation loss: 2.4899037935400523

Epoch: 6| Step: 8
Training loss: 3.3922386169433594
Validation loss: 2.4903551609285417

Epoch: 6| Step: 9
Training loss: 2.924997329711914
Validation loss: 2.490686596080821

Epoch: 6| Step: 10
Training loss: 2.742722272872925
Validation loss: 2.4898177449421217

Epoch: 6| Step: 11
Training loss: 3.5611793994903564
Validation loss: 2.489869343337192

Epoch: 6| Step: 12
Training loss: 2.9762730598449707
Validation loss: 2.4904810023564163

Epoch: 6| Step: 13
Training loss: 1.9836679697036743
Validation loss: 2.484400580006261

Epoch: 79| Step: 0
Training loss: 1.568986177444458
Validation loss: 2.4882034409430718

Epoch: 6| Step: 1
Training loss: 2.4893717765808105
Validation loss: 2.4916686524627027

Epoch: 6| Step: 2
Training loss: 3.1286001205444336
Validation loss: 2.4968014404337895

Epoch: 6| Step: 3
Training loss: 2.900836229324341
Validation loss: 2.501203311386929

Epoch: 6| Step: 4
Training loss: 2.4083476066589355
Validation loss: 2.5058310826619468

Epoch: 6| Step: 5
Training loss: 2.851170539855957
Validation loss: 2.5123229103703655

Epoch: 6| Step: 6
Training loss: 2.5426833629608154
Validation loss: 2.512676223631828

Epoch: 6| Step: 7
Training loss: 3.0782999992370605
Validation loss: 2.528817481892083

Epoch: 6| Step: 8
Training loss: 2.808560848236084
Validation loss: 2.5236655563436527

Epoch: 6| Step: 9
Training loss: 2.5202927589416504
Validation loss: 2.508737712778071

Epoch: 6| Step: 10
Training loss: 2.310612678527832
Validation loss: 2.5122816472925167

Epoch: 6| Step: 11
Training loss: 3.373745918273926
Validation loss: 2.4993777582722325

Epoch: 6| Step: 12
Training loss: 3.219702959060669
Validation loss: 2.495077343397243

Epoch: 6| Step: 13
Training loss: 2.3171794414520264
Validation loss: 2.492100618218863

Epoch: 80| Step: 0
Training loss: 2.2513983249664307
Validation loss: 2.4924804190153718

Epoch: 6| Step: 1
Training loss: 2.6807525157928467
Validation loss: 2.4910248658990346

Epoch: 6| Step: 2
Training loss: 3.4750499725341797
Validation loss: 2.4886574437541347

Epoch: 6| Step: 3
Training loss: 3.117910861968994
Validation loss: 2.4900778109027493

Epoch: 6| Step: 4
Training loss: 3.147824764251709
Validation loss: 2.4875793969759377

Epoch: 6| Step: 5
Training loss: 2.7262465953826904
Validation loss: 2.483982075927078

Epoch: 6| Step: 6
Training loss: 2.4385390281677246
Validation loss: 2.4871731547899145

Epoch: 6| Step: 7
Training loss: 2.735004425048828
Validation loss: 2.488086438948108

Epoch: 6| Step: 8
Training loss: 3.2260220050811768
Validation loss: 2.4859556408338648

Epoch: 6| Step: 9
Training loss: 1.807387351989746
Validation loss: 2.484021338083411

Epoch: 6| Step: 10
Training loss: 2.384997606277466
Validation loss: 2.4852719127490954

Epoch: 6| Step: 11
Training loss: 2.2068052291870117
Validation loss: 2.486182584557482

Epoch: 6| Step: 12
Training loss: 2.3842039108276367
Validation loss: 2.4894858457708873

Epoch: 6| Step: 13
Training loss: 3.255659341812134
Validation loss: 2.4998500039500575

Epoch: 81| Step: 0
Training loss: 1.9343701601028442
Validation loss: 2.497161574261163

Epoch: 6| Step: 1
Training loss: 2.820587635040283
Validation loss: 2.503838418632425

Epoch: 6| Step: 2
Training loss: 2.995159149169922
Validation loss: 2.5114574586191485

Epoch: 6| Step: 3
Training loss: 2.6500818729400635
Validation loss: 2.519988880362562

Epoch: 6| Step: 4
Training loss: 2.4053115844726562
Validation loss: 2.516761682366812

Epoch: 6| Step: 5
Training loss: 2.32188081741333
Validation loss: 2.5135883080062045

Epoch: 6| Step: 6
Training loss: 3.622979164123535
Validation loss: 2.5162077770438245

Epoch: 6| Step: 7
Training loss: 3.5669479370117188
Validation loss: 2.5063359199031705

Epoch: 6| Step: 8
Training loss: 2.9064488410949707
Validation loss: 2.4969554613995295

Epoch: 6| Step: 9
Training loss: 2.3605847358703613
Validation loss: 2.4928266643196024

Epoch: 6| Step: 10
Training loss: 1.8598697185516357
Validation loss: 2.491831312897385

Epoch: 6| Step: 11
Training loss: 2.3118762969970703
Validation loss: 2.485190581249934

Epoch: 6| Step: 12
Training loss: 3.2084085941314697
Validation loss: 2.4842814399350073

Epoch: 6| Step: 13
Training loss: 2.503472089767456
Validation loss: 2.4816943368604107

Epoch: 82| Step: 0
Training loss: 2.695535898208618
Validation loss: 2.480121656130719

Epoch: 6| Step: 1
Training loss: 3.574458599090576
Validation loss: 2.482844063030776

Epoch: 6| Step: 2
Training loss: 2.567972183227539
Validation loss: 2.479031139804471

Epoch: 6| Step: 3
Training loss: 1.8279240131378174
Validation loss: 2.4801299315626903

Epoch: 6| Step: 4
Training loss: 2.795588970184326
Validation loss: 2.4797276681469334

Epoch: 6| Step: 5
Training loss: 2.270991325378418
Validation loss: 2.477211111335344

Epoch: 6| Step: 6
Training loss: 2.632352352142334
Validation loss: 2.476595401763916

Epoch: 6| Step: 7
Training loss: 3.4972143173217773
Validation loss: 2.4779570807692823

Epoch: 6| Step: 8
Training loss: 2.5996358394622803
Validation loss: 2.478805741956157

Epoch: 6| Step: 9
Training loss: 2.677849769592285
Validation loss: 2.479907920283656

Epoch: 6| Step: 10
Training loss: 2.4958081245422363
Validation loss: 2.484046459197998

Epoch: 6| Step: 11
Training loss: 2.8277690410614014
Validation loss: 2.481648752766271

Epoch: 6| Step: 12
Training loss: 2.619586706161499
Validation loss: 2.4851488221076226

Epoch: 6| Step: 13
Training loss: 2.3450655937194824
Validation loss: 2.487007784587081

Epoch: 83| Step: 0
Training loss: 2.6208508014678955
Validation loss: 2.4859808311667493

Epoch: 6| Step: 1
Training loss: 1.9109798669815063
Validation loss: 2.4950785226719354

Epoch: 6| Step: 2
Training loss: 2.174485206604004
Validation loss: 2.489399818963902

Epoch: 6| Step: 3
Training loss: 3.248918056488037
Validation loss: 2.4910311609186153

Epoch: 6| Step: 4
Training loss: 2.756741523742676
Validation loss: 2.488004945939587

Epoch: 6| Step: 5
Training loss: 2.6431379318237305
Validation loss: 2.4903748022612704

Epoch: 6| Step: 6
Training loss: 2.8935744762420654
Validation loss: 2.4825736579074653

Epoch: 6| Step: 7
Training loss: 1.7546136379241943
Validation loss: 2.476056073301582

Epoch: 6| Step: 8
Training loss: 3.052623987197876
Validation loss: 2.478339713106873

Epoch: 6| Step: 9
Training loss: 2.583679676055908
Validation loss: 2.4817260824224

Epoch: 6| Step: 10
Training loss: 3.6706104278564453
Validation loss: 2.4829095743035756

Epoch: 6| Step: 11
Training loss: 2.812408685684204
Validation loss: 2.4837788817703084

Epoch: 6| Step: 12
Training loss: 2.7687816619873047
Validation loss: 2.4826177063808648

Epoch: 6| Step: 13
Training loss: 2.690981864929199
Validation loss: 2.4819806698829896

Epoch: 84| Step: 0
Training loss: 2.6005051136016846
Validation loss: 2.476327003971223

Epoch: 6| Step: 1
Training loss: 2.6663928031921387
Validation loss: 2.4822385093217254

Epoch: 6| Step: 2
Training loss: 2.7453067302703857
Validation loss: 2.475175747307398

Epoch: 6| Step: 3
Training loss: 2.056943893432617
Validation loss: 2.4838063896343274

Epoch: 6| Step: 4
Training loss: 3.1267919540405273
Validation loss: 2.484798541633032

Epoch: 6| Step: 5
Training loss: 2.2553679943084717
Validation loss: 2.478494882583618

Epoch: 6| Step: 6
Training loss: 2.1975183486938477
Validation loss: 2.4757971020155054

Epoch: 6| Step: 7
Training loss: 2.8166282176971436
Validation loss: 2.4737889689783894

Epoch: 6| Step: 8
Training loss: 2.9510059356689453
Validation loss: 2.472854088711482

Epoch: 6| Step: 9
Training loss: 2.386767864227295
Validation loss: 2.4743386199397426

Epoch: 6| Step: 10
Training loss: 2.414278984069824
Validation loss: 2.472398852789274

Epoch: 6| Step: 11
Training loss: 3.6126201152801514
Validation loss: 2.4741396596354823

Epoch: 6| Step: 12
Training loss: 2.7879300117492676
Validation loss: 2.472760861919772

Epoch: 6| Step: 13
Training loss: 2.951888084411621
Validation loss: 2.4741158203412126

Epoch: 85| Step: 0
Training loss: 3.1074814796447754
Validation loss: 2.4833136271404963

Epoch: 6| Step: 1
Training loss: 2.130859613418579
Validation loss: 2.4831297602704776

Epoch: 6| Step: 2
Training loss: 1.987687587738037
Validation loss: 2.4835458955457135

Epoch: 6| Step: 3
Training loss: 2.706859588623047
Validation loss: 2.4837210742376183

Epoch: 6| Step: 4
Training loss: 2.695284843444824
Validation loss: 2.4729683232563797

Epoch: 6| Step: 5
Training loss: 2.83219575881958
Validation loss: 2.467641261316115

Epoch: 6| Step: 6
Training loss: 2.5201401710510254
Validation loss: 2.4678007223272838

Epoch: 6| Step: 7
Training loss: 2.26092267036438
Validation loss: 2.467916786029775

Epoch: 6| Step: 8
Training loss: 2.7561206817626953
Validation loss: 2.4666874844540834

Epoch: 6| Step: 9
Training loss: 3.1833596229553223
Validation loss: 2.469029308647238

Epoch: 6| Step: 10
Training loss: 2.470604181289673
Validation loss: 2.466877214370235

Epoch: 6| Step: 11
Training loss: 2.616608142852783
Validation loss: 2.4689597673313592

Epoch: 6| Step: 12
Training loss: 3.467341661453247
Validation loss: 2.468667801990304

Epoch: 6| Step: 13
Training loss: 2.7092125415802
Validation loss: 2.4719126634700324

Epoch: 86| Step: 0
Training loss: 2.196256637573242
Validation loss: 2.473018644958414

Epoch: 6| Step: 1
Training loss: 2.9709458351135254
Validation loss: 2.474507460030176

Epoch: 6| Step: 2
Training loss: 1.877737283706665
Validation loss: 2.480020799944478

Epoch: 6| Step: 3
Training loss: 2.273956537246704
Validation loss: 2.4771330484779934

Epoch: 6| Step: 4
Training loss: 2.408184766769409
Validation loss: 2.4775729025563886

Epoch: 6| Step: 5
Training loss: 2.5020039081573486
Validation loss: 2.4830125429297007

Epoch: 6| Step: 6
Training loss: 3.131840705871582
Validation loss: 2.4911403117641324

Epoch: 6| Step: 7
Training loss: 2.916663646697998
Validation loss: 2.4902231795813448

Epoch: 6| Step: 8
Training loss: 2.223531484603882
Validation loss: 2.4864557558490383

Epoch: 6| Step: 9
Training loss: 3.2676398754119873
Validation loss: 2.477779716573736

Epoch: 6| Step: 10
Training loss: 3.0197176933288574
Validation loss: 2.474189691646125

Epoch: 6| Step: 11
Training loss: 2.8002889156341553
Validation loss: 2.468698804096509

Epoch: 6| Step: 12
Training loss: 2.667541027069092
Validation loss: 2.468867504468528

Epoch: 6| Step: 13
Training loss: 3.496344566345215
Validation loss: 2.469735490378513

Epoch: 87| Step: 0
Training loss: 2.9595625400543213
Validation loss: 2.4679671179863716

Epoch: 6| Step: 1
Training loss: 2.489055633544922
Validation loss: 2.4685124479314333

Epoch: 6| Step: 2
Training loss: 2.9682517051696777
Validation loss: 2.4715639903981197

Epoch: 6| Step: 3
Training loss: 2.479473114013672
Validation loss: 2.472064430995654

Epoch: 6| Step: 4
Training loss: 2.508347511291504
Validation loss: 2.4741879970796647

Epoch: 6| Step: 5
Training loss: 2.180645227432251
Validation loss: 2.4705256146769368

Epoch: 6| Step: 6
Training loss: 2.9987940788269043
Validation loss: 2.4665213810500277

Epoch: 6| Step: 7
Training loss: 2.883582830429077
Validation loss: 2.4656137112648255

Epoch: 6| Step: 8
Training loss: 3.1413486003875732
Validation loss: 2.465275523483112

Epoch: 6| Step: 9
Training loss: 2.1924920082092285
Validation loss: 2.4668856666934107

Epoch: 6| Step: 10
Training loss: 3.074464797973633
Validation loss: 2.46636224562122

Epoch: 6| Step: 11
Training loss: 2.1194663047790527
Validation loss: 2.469355474236191

Epoch: 6| Step: 12
Training loss: 3.189227819442749
Validation loss: 2.479580820247691

Epoch: 6| Step: 13
Training loss: 1.8760462999343872
Validation loss: 2.4871290960619525

Epoch: 88| Step: 0
Training loss: 2.7536840438842773
Validation loss: 2.4895078546257428

Epoch: 6| Step: 1
Training loss: 3.3063526153564453
Validation loss: 2.498133813181231

Epoch: 6| Step: 2
Training loss: 3.054443836212158
Validation loss: 2.5001387698675996

Epoch: 6| Step: 3
Training loss: 2.3311727046966553
Validation loss: 2.498441319311819

Epoch: 6| Step: 4
Training loss: 2.5575156211853027
Validation loss: 2.4891107697640695

Epoch: 6| Step: 5
Training loss: 2.960531234741211
Validation loss: 2.496898119167615

Epoch: 6| Step: 6
Training loss: 2.736903190612793
Validation loss: 2.5014861886219313

Epoch: 6| Step: 7
Training loss: 2.0428061485290527
Validation loss: 2.496176512010636

Epoch: 6| Step: 8
Training loss: 3.168036460876465
Validation loss: 2.4802473309219524

Epoch: 6| Step: 9
Training loss: 2.883938789367676
Validation loss: 2.464028968605944

Epoch: 6| Step: 10
Training loss: 2.067260980606079
Validation loss: 2.4620006263896985

Epoch: 6| Step: 11
Training loss: 2.5073275566101074
Validation loss: 2.458257011187974

Epoch: 6| Step: 12
Training loss: 2.380178213119507
Validation loss: 2.454354888649397

Epoch: 6| Step: 13
Training loss: 2.4753940105438232
Validation loss: 2.459831671048236

Epoch: 89| Step: 0
Training loss: 2.517486333847046
Validation loss: 2.462232038538943

Epoch: 6| Step: 1
Training loss: 3.1192126274108887
Validation loss: 2.468114406831803

Epoch: 6| Step: 2
Training loss: 2.5509557723999023
Validation loss: 2.465758797942951

Epoch: 6| Step: 3
Training loss: 2.878962516784668
Validation loss: 2.460610173081839

Epoch: 6| Step: 4
Training loss: 2.603689670562744
Validation loss: 2.458956718444824

Epoch: 6| Step: 5
Training loss: 2.58951735496521
Validation loss: 2.4576177340681835

Epoch: 6| Step: 6
Training loss: 2.4824352264404297
Validation loss: 2.456504298794654

Epoch: 6| Step: 7
Training loss: 3.341944694519043
Validation loss: 2.453743427030502

Epoch: 6| Step: 8
Training loss: 2.191371440887451
Validation loss: 2.4533767956559376

Epoch: 6| Step: 9
Training loss: 3.333510398864746
Validation loss: 2.45072280463352

Epoch: 6| Step: 10
Training loss: 2.281594753265381
Validation loss: 2.456323218602006

Epoch: 6| Step: 11
Training loss: 2.6433353424072266
Validation loss: 2.4544829348082184

Epoch: 6| Step: 12
Training loss: 2.2304887771606445
Validation loss: 2.4563588365431754

Epoch: 6| Step: 13
Training loss: 2.6511170864105225
Validation loss: 2.466117430758733

Epoch: 90| Step: 0
Training loss: 2.3233048915863037
Validation loss: 2.4745696872793217

Epoch: 6| Step: 1
Training loss: 2.444413661956787
Validation loss: 2.4825151684463664

Epoch: 6| Step: 2
Training loss: 2.036328077316284
Validation loss: 2.4885967598166516

Epoch: 6| Step: 3
Training loss: 2.3459043502807617
Validation loss: 2.4864176229764055

Epoch: 6| Step: 4
Training loss: 2.8164896965026855
Validation loss: 2.4988111834372244

Epoch: 6| Step: 5
Training loss: 3.30435848236084
Validation loss: 2.4952533834724018

Epoch: 6| Step: 6
Training loss: 2.714179515838623
Validation loss: 2.4896524234484603

Epoch: 6| Step: 7
Training loss: 2.2365217208862305
Validation loss: 2.4786459707444712

Epoch: 6| Step: 8
Training loss: 2.8215227127075195
Validation loss: 2.4649292371606313

Epoch: 6| Step: 9
Training loss: 3.2442188262939453
Validation loss: 2.4540851987818235

Epoch: 6| Step: 10
Training loss: 2.4901022911071777
Validation loss: 2.4492853328745854

Epoch: 6| Step: 11
Training loss: 2.601067543029785
Validation loss: 2.4507282498062297

Epoch: 6| Step: 12
Training loss: 2.8192403316497803
Validation loss: 2.449694425828995

Epoch: 6| Step: 13
Training loss: 3.639285087585449
Validation loss: 2.4586421699934107

Epoch: 91| Step: 0
Training loss: 2.9986658096313477
Validation loss: 2.463587550706761

Epoch: 6| Step: 1
Training loss: 2.163724899291992
Validation loss: 2.4597449687219437

Epoch: 6| Step: 2
Training loss: 1.8459556102752686
Validation loss: 2.4667370729548956

Epoch: 6| Step: 3
Training loss: 2.6262784004211426
Validation loss: 2.470793370277651

Epoch: 6| Step: 4
Training loss: 2.769253730773926
Validation loss: 2.4736810781622447

Epoch: 6| Step: 5
Training loss: 1.788022756576538
Validation loss: 2.480310017062772

Epoch: 6| Step: 6
Training loss: 2.8076417446136475
Validation loss: 2.4728877993040186

Epoch: 6| Step: 7
Training loss: 2.7436399459838867
Validation loss: 2.500978264757382

Epoch: 6| Step: 8
Training loss: 3.5526726245880127
Validation loss: 2.542644677623626

Epoch: 6| Step: 9
Training loss: 3.1646852493286133
Validation loss: 2.510092294344338

Epoch: 6| Step: 10
Training loss: 3.1047658920288086
Validation loss: 2.492702320057859

Epoch: 6| Step: 11
Training loss: 2.549184799194336
Validation loss: 2.480497347411289

Epoch: 6| Step: 12
Training loss: 2.9905500411987305
Validation loss: 2.4739888637296614

Epoch: 6| Step: 13
Training loss: 2.401543378829956
Validation loss: 2.465600977661789

Epoch: 92| Step: 0
Training loss: 2.136686325073242
Validation loss: 2.463839702708747

Epoch: 6| Step: 1
Training loss: 2.878246307373047
Validation loss: 2.4639151416799074

Epoch: 6| Step: 2
Training loss: 2.5481557846069336
Validation loss: 2.4694154288179133

Epoch: 6| Step: 3
Training loss: 3.3434901237487793
Validation loss: 2.4757830225011355

Epoch: 6| Step: 4
Training loss: 2.525916337966919
Validation loss: 2.475696289411155

Epoch: 6| Step: 5
Training loss: 1.8462977409362793
Validation loss: 2.4815466660325245

Epoch: 6| Step: 6
Training loss: 2.3801918029785156
Validation loss: 2.4880722671426754

Epoch: 6| Step: 7
Training loss: 2.6541552543640137
Validation loss: 2.4818846102683776

Epoch: 6| Step: 8
Training loss: 3.222703695297241
Validation loss: 2.4718402842039704

Epoch: 6| Step: 9
Training loss: 2.9975638389587402
Validation loss: 2.463572471372543

Epoch: 6| Step: 10
Training loss: 1.782140851020813
Validation loss: 2.4509327309105986

Epoch: 6| Step: 11
Training loss: 2.4917850494384766
Validation loss: 2.451249837875366

Epoch: 6| Step: 12
Training loss: 3.731189250946045
Validation loss: 2.4482403006604923

Epoch: 6| Step: 13
Training loss: 2.7158923149108887
Validation loss: 2.444535360541395

Epoch: 93| Step: 0
Training loss: 2.5029916763305664
Validation loss: 2.4415020250505015

Epoch: 6| Step: 1
Training loss: 2.6790144443511963
Validation loss: 2.4435313158137824

Epoch: 6| Step: 2
Training loss: 2.6750268936157227
Validation loss: 2.4452120129780104

Epoch: 6| Step: 3
Training loss: 3.127054214477539
Validation loss: 2.4384135200131323

Epoch: 6| Step: 4
Training loss: 2.207986831665039
Validation loss: 2.441651109726198

Epoch: 6| Step: 5
Training loss: 3.1611499786376953
Validation loss: 2.4428486054943455

Epoch: 6| Step: 6
Training loss: 3.001399517059326
Validation loss: 2.445860493567682

Epoch: 6| Step: 7
Training loss: 2.4918947219848633
Validation loss: 2.4442959011241956

Epoch: 6| Step: 8
Training loss: 1.8010203838348389
Validation loss: 2.4453441609618483

Epoch: 6| Step: 9
Training loss: 3.033198356628418
Validation loss: 2.44533383974465

Epoch: 6| Step: 10
Training loss: 2.7226672172546387
Validation loss: 2.4437192383632866

Epoch: 6| Step: 11
Training loss: 2.464766025543213
Validation loss: 2.457817604464869

Epoch: 6| Step: 12
Training loss: 2.811891555786133
Validation loss: 2.478383207833895

Epoch: 6| Step: 13
Training loss: 2.58687686920166
Validation loss: 2.494393466621317

Epoch: 94| Step: 0
Training loss: 2.899946689605713
Validation loss: 2.47981010970249

Epoch: 6| Step: 1
Training loss: 1.936133623123169
Validation loss: 2.473018148893951

Epoch: 6| Step: 2
Training loss: 3.1324398517608643
Validation loss: 2.458921819604853

Epoch: 6| Step: 3
Training loss: 2.59987211227417
Validation loss: 2.4488322299013854

Epoch: 6| Step: 4
Training loss: 2.2224221229553223
Validation loss: 2.449951849957948

Epoch: 6| Step: 5
Training loss: 3.1523120403289795
Validation loss: 2.447044869904877

Epoch: 6| Step: 6
Training loss: 2.4424195289611816
Validation loss: 2.449473470769903

Epoch: 6| Step: 7
Training loss: 2.179654121398926
Validation loss: 2.4523419564770115

Epoch: 6| Step: 8
Training loss: 2.136453151702881
Validation loss: 2.4526321221423406

Epoch: 6| Step: 9
Training loss: 3.150132179260254
Validation loss: 2.4518939948851064

Epoch: 6| Step: 10
Training loss: 2.8797428607940674
Validation loss: 2.4467528712364937

Epoch: 6| Step: 11
Training loss: 2.7970423698425293
Validation loss: 2.446239238144249

Epoch: 6| Step: 12
Training loss: 3.0886311531066895
Validation loss: 2.451208027460242

Epoch: 6| Step: 13
Training loss: 2.6166064739227295
Validation loss: 2.450519300276233

Epoch: 95| Step: 0
Training loss: 2.602877616882324
Validation loss: 2.46214174455212

Epoch: 6| Step: 1
Training loss: 2.5349605083465576
Validation loss: 2.4717122406087895

Epoch: 6| Step: 2
Training loss: 2.0925276279449463
Validation loss: 2.4648804690248225

Epoch: 6| Step: 3
Training loss: 2.9449081420898438
Validation loss: 2.47678554186257

Epoch: 6| Step: 4
Training loss: 2.849827527999878
Validation loss: 2.453095354059691

Epoch: 6| Step: 5
Training loss: 2.476733446121216
Validation loss: 2.4464548480126167

Epoch: 6| Step: 6
Training loss: 2.971242904663086
Validation loss: 2.450482928624717

Epoch: 6| Step: 7
Training loss: 3.0429327487945557
Validation loss: 2.4480529292937248

Epoch: 6| Step: 8
Training loss: 2.391115188598633
Validation loss: 2.4527710586465816

Epoch: 6| Step: 9
Training loss: 2.6954755783081055
Validation loss: 2.4621570597412767

Epoch: 6| Step: 10
Training loss: 2.2804694175720215
Validation loss: 2.4639656005367154

Epoch: 6| Step: 11
Training loss: 1.558410882949829
Validation loss: 2.4764941482133764

Epoch: 6| Step: 12
Training loss: 3.51153564453125
Validation loss: 2.4635919858050603

Epoch: 6| Step: 13
Training loss: 3.8401172161102295
Validation loss: 2.4562360855840866

Epoch: 96| Step: 0
Training loss: 3.098999500274658
Validation loss: 2.4496171423183974

Epoch: 6| Step: 1
Training loss: 2.262584686279297
Validation loss: 2.448290806944652

Epoch: 6| Step: 2
Training loss: 2.0377442836761475
Validation loss: 2.435981224941951

Epoch: 6| Step: 3
Training loss: 2.3903210163116455
Validation loss: 2.4409148052174556

Epoch: 6| Step: 4
Training loss: 2.6789865493774414
Validation loss: 2.4403800425990934

Epoch: 6| Step: 5
Training loss: 2.7511839866638184
Validation loss: 2.434909095046341

Epoch: 6| Step: 6
Training loss: 2.690268039703369
Validation loss: 2.43706089450467

Epoch: 6| Step: 7
Training loss: 3.2561419010162354
Validation loss: 2.43377108727732

Epoch: 6| Step: 8
Training loss: 2.42567777633667
Validation loss: 2.4393368895335863

Epoch: 6| Step: 9
Training loss: 2.2552433013916016
Validation loss: 2.428296935173773

Epoch: 6| Step: 10
Training loss: 2.8677592277526855
Validation loss: 2.4351072055037304

Epoch: 6| Step: 11
Training loss: 2.9998831748962402
Validation loss: 2.433431110074443

Epoch: 6| Step: 12
Training loss: 2.66456937789917
Validation loss: 2.4323631281493814

Epoch: 6| Step: 13
Training loss: 2.8230013847351074
Validation loss: 2.4324552628301803

Epoch: 97| Step: 0
Training loss: 2.2339515686035156
Validation loss: 2.435059989652326

Epoch: 6| Step: 1
Training loss: 2.170795440673828
Validation loss: 2.439545703190629

Epoch: 6| Step: 2
Training loss: 2.3708977699279785
Validation loss: 2.4412241917784496

Epoch: 6| Step: 3
Training loss: 3.3277688026428223
Validation loss: 2.4374547440518617

Epoch: 6| Step: 4
Training loss: 2.982409954071045
Validation loss: 2.4404656887054443

Epoch: 6| Step: 5
Training loss: 2.191227674484253
Validation loss: 2.4472225840373705

Epoch: 6| Step: 6
Training loss: 2.7967417240142822
Validation loss: 2.4379618167877197

Epoch: 6| Step: 7
Training loss: 1.7130080461502075
Validation loss: 2.4443102549481135

Epoch: 6| Step: 8
Training loss: 2.434744119644165
Validation loss: 2.4390247714134956

Epoch: 6| Step: 9
Training loss: 2.7472805976867676
Validation loss: 2.4428061259690153

Epoch: 6| Step: 10
Training loss: 3.1731905937194824
Validation loss: 2.442524302390314

Epoch: 6| Step: 11
Training loss: 2.9938783645629883
Validation loss: 2.443766229896135

Epoch: 6| Step: 12
Training loss: 3.240361213684082
Validation loss: 2.437035895163013

Epoch: 6| Step: 13
Training loss: 2.6744396686553955
Validation loss: 2.4370044559560795

Epoch: 98| Step: 0
Training loss: 2.7608962059020996
Validation loss: 2.4404300156460015

Epoch: 6| Step: 1
Training loss: 2.843488931655884
Validation loss: 2.4382564431877545

Epoch: 6| Step: 2
Training loss: 2.693568706512451
Validation loss: 2.436838262824602

Epoch: 6| Step: 3
Training loss: 2.7740533351898193
Validation loss: 2.438340243472848

Epoch: 6| Step: 4
Training loss: 2.413076639175415
Validation loss: 2.444579544887748

Epoch: 6| Step: 5
Training loss: 2.5545811653137207
Validation loss: 2.4436846228056055

Epoch: 6| Step: 6
Training loss: 2.529111623764038
Validation loss: 2.450991884354622

Epoch: 6| Step: 7
Training loss: 3.1035451889038086
Validation loss: 2.445392721442766

Epoch: 6| Step: 8
Training loss: 3.2583470344543457
Validation loss: 2.442159504018804

Epoch: 6| Step: 9
Training loss: 2.3766915798187256
Validation loss: 2.443925844725742

Epoch: 6| Step: 10
Training loss: 2.346750259399414
Validation loss: 2.4459632186479467

Epoch: 6| Step: 11
Training loss: 1.8807625770568848
Validation loss: 2.451294199112923

Epoch: 6| Step: 12
Training loss: 3.1236982345581055
Validation loss: 2.4534352517897084

Epoch: 6| Step: 13
Training loss: 2.139498472213745
Validation loss: 2.452481987655804

Epoch: 99| Step: 0
Training loss: 2.973578929901123
Validation loss: 2.4456137841747654

Epoch: 6| Step: 1
Training loss: 2.093723773956299
Validation loss: 2.455247866210117

Epoch: 6| Step: 2
Training loss: 2.5576844215393066
Validation loss: 2.4414053604166996

Epoch: 6| Step: 3
Training loss: 1.9640527963638306
Validation loss: 2.449755786567606

Epoch: 6| Step: 4
Training loss: 3.3278450965881348
Validation loss: 2.4494846123521046

Epoch: 6| Step: 5
Training loss: 2.083465337753296
Validation loss: 2.4418954926152385

Epoch: 6| Step: 6
Training loss: 2.8791937828063965
Validation loss: 2.446307956531484

Epoch: 6| Step: 7
Training loss: 2.8484647274017334
Validation loss: 2.4433147522710983

Epoch: 6| Step: 8
Training loss: 2.4232282638549805
Validation loss: 2.4409309202624905

Epoch: 6| Step: 9
Training loss: 3.088585138320923
Validation loss: 2.443468024653773

Epoch: 6| Step: 10
Training loss: 2.699096202850342
Validation loss: 2.4347451527913413

Epoch: 6| Step: 11
Training loss: 2.590399742126465
Validation loss: 2.4378552257373767

Epoch: 6| Step: 12
Training loss: 2.759110927581787
Validation loss: 2.4322232200253393

Epoch: 6| Step: 13
Training loss: 2.766094446182251
Validation loss: 2.429060148936446

Epoch: 100| Step: 0
Training loss: 3.093336820602417
Validation loss: 2.425234261379447

Epoch: 6| Step: 1
Training loss: 1.9879783391952515
Validation loss: 2.4246042774569605

Epoch: 6| Step: 2
Training loss: 2.033418655395508
Validation loss: 2.4217469307684127

Epoch: 6| Step: 3
Training loss: 3.3334202766418457
Validation loss: 2.424541888698455

Epoch: 6| Step: 4
Training loss: 3.1647496223449707
Validation loss: 2.420061872851464

Epoch: 6| Step: 5
Training loss: 2.82181453704834
Validation loss: 2.4185531831556752

Epoch: 6| Step: 6
Training loss: 2.868253707885742
Validation loss: 2.417497052941271

Epoch: 6| Step: 7
Training loss: 2.824089527130127
Validation loss: 2.420124879447363

Epoch: 6| Step: 8
Training loss: 2.585724353790283
Validation loss: 2.418379881048715

Epoch: 6| Step: 9
Training loss: 2.185580253601074
Validation loss: 2.4179757307934504

Epoch: 6| Step: 10
Training loss: 3.1751492023468018
Validation loss: 2.4185277620951333

Epoch: 6| Step: 11
Training loss: 2.0776419639587402
Validation loss: 2.424832167163972

Epoch: 6| Step: 12
Training loss: 1.8781259059906006
Validation loss: 2.425813854381602

Epoch: 6| Step: 13
Training loss: 3.212296724319458
Validation loss: 2.437150057925973

Epoch: 101| Step: 0
Training loss: 1.7297414541244507
Validation loss: 2.4380766166153776

Epoch: 6| Step: 1
Training loss: 2.768307685852051
Validation loss: 2.4455012711145545

Epoch: 6| Step: 2
Training loss: 2.4803214073181152
Validation loss: 2.4352565503889516

Epoch: 6| Step: 3
Training loss: 2.6540756225585938
Validation loss: 2.436399139383788

Epoch: 6| Step: 4
Training loss: 3.3736562728881836
Validation loss: 2.425795675605856

Epoch: 6| Step: 5
Training loss: 2.428105115890503
Validation loss: 2.425029964857204

Epoch: 6| Step: 6
Training loss: 2.5584654808044434
Validation loss: 2.4224976083283782

Epoch: 6| Step: 7
Training loss: 2.960155487060547
Validation loss: 2.4157596916280766

Epoch: 6| Step: 8
Training loss: 2.129024028778076
Validation loss: 2.4159219111165693

Epoch: 6| Step: 9
Training loss: 2.940929412841797
Validation loss: 2.4141809658337663

Epoch: 6| Step: 10
Training loss: 2.7533957958221436
Validation loss: 2.41353077273215

Epoch: 6| Step: 11
Training loss: 2.5805790424346924
Validation loss: 2.4150699005332044

Epoch: 6| Step: 12
Training loss: 2.726377248764038
Validation loss: 2.4170561477702153

Epoch: 6| Step: 13
Training loss: 3.051961660385132
Validation loss: 2.4217193716315815

Epoch: 102| Step: 0
Training loss: 2.460268497467041
Validation loss: 2.4256402946287587

Epoch: 6| Step: 1
Training loss: 1.6023328304290771
Validation loss: 2.4243323982402845

Epoch: 6| Step: 2
Training loss: 2.916964054107666
Validation loss: 2.4319617620078464

Epoch: 6| Step: 3
Training loss: 3.3528692722320557
Validation loss: 2.4412946726686213

Epoch: 6| Step: 4
Training loss: 2.6174962520599365
Validation loss: 2.4329400549652758

Epoch: 6| Step: 5
Training loss: 2.2158327102661133
Validation loss: 2.4327518375970985

Epoch: 6| Step: 6
Training loss: 2.4749326705932617
Validation loss: 2.4208076333486908

Epoch: 6| Step: 7
Training loss: 2.568598985671997
Validation loss: 2.422055931501491

Epoch: 6| Step: 8
Training loss: 2.1331937313079834
Validation loss: 2.420816203599335

Epoch: 6| Step: 9
Training loss: 2.2647552490234375
Validation loss: 2.419424626135057

Epoch: 6| Step: 10
Training loss: 3.128504753112793
Validation loss: 2.4255420648923485

Epoch: 6| Step: 11
Training loss: 3.7857699394226074
Validation loss: 2.421425509196456

Epoch: 6| Step: 12
Training loss: 2.672288417816162
Validation loss: 2.423119524473785

Epoch: 6| Step: 13
Training loss: 2.681917667388916
Validation loss: 2.419790119253179

Epoch: 103| Step: 0
Training loss: 2.907294273376465
Validation loss: 2.4199176321747484

Epoch: 6| Step: 1
Training loss: 2.4749832153320312
Validation loss: 2.4245440472838697

Epoch: 6| Step: 2
Training loss: 2.3165252208709717
Validation loss: 2.421102785295056

Epoch: 6| Step: 3
Training loss: 2.887321949005127
Validation loss: 2.4272224005832466

Epoch: 6| Step: 4
Training loss: 2.6397409439086914
Validation loss: 2.4257455884769397

Epoch: 6| Step: 5
Training loss: 2.6998631954193115
Validation loss: 2.4263405620410876

Epoch: 6| Step: 6
Training loss: 2.3144521713256836
Validation loss: 2.4232727353290846

Epoch: 6| Step: 7
Training loss: 2.4619572162628174
Validation loss: 2.419201076671641

Epoch: 6| Step: 8
Training loss: 2.1228408813476562
Validation loss: 2.418142654562509

Epoch: 6| Step: 9
Training loss: 2.7848262786865234
Validation loss: 2.419254381169555

Epoch: 6| Step: 10
Training loss: 2.310256004333496
Validation loss: 2.420281578135747

Epoch: 6| Step: 11
Training loss: 3.0684003829956055
Validation loss: 2.4192682363653697

Epoch: 6| Step: 12
Training loss: 3.333010196685791
Validation loss: 2.42207936574054

Epoch: 6| Step: 13
Training loss: 2.381424903869629
Validation loss: 2.418872082105247

Epoch: 104| Step: 0
Training loss: 3.5638203620910645
Validation loss: 2.415454423555764

Epoch: 6| Step: 1
Training loss: 2.8774662017822266
Validation loss: 2.4140432752588743

Epoch: 6| Step: 2
Training loss: 2.798084259033203
Validation loss: 2.409841304184288

Epoch: 6| Step: 3
Training loss: 2.2727224826812744
Validation loss: 2.4110424544221614

Epoch: 6| Step: 4
Training loss: 2.5650432109832764
Validation loss: 2.406400047322755

Epoch: 6| Step: 5
Training loss: 2.5210602283477783
Validation loss: 2.4074869309702227

Epoch: 6| Step: 6
Training loss: 2.708359718322754
Validation loss: 2.407163325176444

Epoch: 6| Step: 7
Training loss: 2.203442335128784
Validation loss: 2.4056777441373436

Epoch: 6| Step: 8
Training loss: 2.379676342010498
Validation loss: 2.4060664843487483

Epoch: 6| Step: 9
Training loss: 2.8219847679138184
Validation loss: 2.406005467137983

Epoch: 6| Step: 10
Training loss: 2.583347797393799
Validation loss: 2.4042338966041483

Epoch: 6| Step: 11
Training loss: 2.4989891052246094
Validation loss: 2.409310725427443

Epoch: 6| Step: 12
Training loss: 2.337277412414551
Validation loss: 2.4172187979503343

Epoch: 6| Step: 13
Training loss: 2.845660924911499
Validation loss: 2.4237051599769184

Epoch: 105| Step: 0
Training loss: 2.3338470458984375
Validation loss: 2.4293427557073612

Epoch: 6| Step: 1
Training loss: 2.581455707550049
Validation loss: 2.426562947611655

Epoch: 6| Step: 2
Training loss: 2.7490477561950684
Validation loss: 2.434349593295846

Epoch: 6| Step: 3
Training loss: 2.945680856704712
Validation loss: 2.4367817550577144

Epoch: 6| Step: 4
Training loss: 2.5972280502319336
Validation loss: 2.433760740423715

Epoch: 6| Step: 5
Training loss: 2.561501979827881
Validation loss: 2.4208361615416822

Epoch: 6| Step: 6
Training loss: 2.827866554260254
Validation loss: 2.4175740570150395

Epoch: 6| Step: 7
Training loss: 2.3971052169799805
Validation loss: 2.411547235263291

Epoch: 6| Step: 8
Training loss: 2.679215908050537
Validation loss: 2.4215327014205275

Epoch: 6| Step: 9
Training loss: 2.9142539501190186
Validation loss: 2.4121894913335002

Epoch: 6| Step: 10
Training loss: 1.9578886032104492
Validation loss: 2.4084911500253985

Epoch: 6| Step: 11
Training loss: 2.9458112716674805
Validation loss: 2.4159830924003356

Epoch: 6| Step: 12
Training loss: 3.209484338760376
Validation loss: 2.418551673171341

Epoch: 6| Step: 13
Training loss: 1.616193175315857
Validation loss: 2.42043290856064

Epoch: 106| Step: 0
Training loss: 2.597165107727051
Validation loss: 2.4141130652478946

Epoch: 6| Step: 1
Training loss: 2.7203383445739746
Validation loss: 2.4124586505274617

Epoch: 6| Step: 2
Training loss: 2.8262863159179688
Validation loss: 2.410086553583863

Epoch: 6| Step: 3
Training loss: 1.3640540838241577
Validation loss: 2.4077784117831977

Epoch: 6| Step: 4
Training loss: 2.714789867401123
Validation loss: 2.4042806035728863

Epoch: 6| Step: 5
Training loss: 2.8461408615112305
Validation loss: 2.4042872280202885

Epoch: 6| Step: 6
Training loss: 1.821063756942749
Validation loss: 2.4025745084208827

Epoch: 6| Step: 7
Training loss: 2.8253884315490723
Validation loss: 2.3994923663395706

Epoch: 6| Step: 8
Training loss: 2.919234275817871
Validation loss: 2.4010078368648404

Epoch: 6| Step: 9
Training loss: 2.9071712493896484
Validation loss: 2.4025769054248767

Epoch: 6| Step: 10
Training loss: 2.474785566329956
Validation loss: 2.4048380621017946

Epoch: 6| Step: 11
Training loss: 2.8934054374694824
Validation loss: 2.4050783534203806

Epoch: 6| Step: 12
Training loss: 2.5889620780944824
Validation loss: 2.4088166375314035

Epoch: 6| Step: 13
Training loss: 3.6905500888824463
Validation loss: 2.419701330123409

Epoch: 107| Step: 0
Training loss: 1.5992989540100098
Validation loss: 2.4143502455885693

Epoch: 6| Step: 1
Training loss: 1.7744479179382324
Validation loss: 2.4357709653915895

Epoch: 6| Step: 2
Training loss: 2.499476432800293
Validation loss: 2.4450037274309384

Epoch: 6| Step: 3
Training loss: 2.608494758605957
Validation loss: 2.4444108880976194

Epoch: 6| Step: 4
Training loss: 3.369081497192383
Validation loss: 2.435038387134511

Epoch: 6| Step: 5
Training loss: 2.341240882873535
Validation loss: 2.433548499179143

Epoch: 6| Step: 6
Training loss: 3.6505706310272217
Validation loss: 2.430403455611198

Epoch: 6| Step: 7
Training loss: 2.112738847732544
Validation loss: 2.4243094536565963

Epoch: 6| Step: 8
Training loss: 3.146841049194336
Validation loss: 2.42464251928432

Epoch: 6| Step: 9
Training loss: 3.630631923675537
Validation loss: 2.4110894844096196

Epoch: 6| Step: 10
Training loss: 1.885594367980957
Validation loss: 2.404707436920494

Epoch: 6| Step: 11
Training loss: 2.5502727031707764
Validation loss: 2.4031330372697566

Epoch: 6| Step: 12
Training loss: 3.1631343364715576
Validation loss: 2.3999126572762766

Epoch: 6| Step: 13
Training loss: 2.2758092880249023
Validation loss: 2.3970200451471473

Epoch: 108| Step: 0
Training loss: 2.5979669094085693
Validation loss: 2.3957097107364285

Epoch: 6| Step: 1
Training loss: 2.0365395545959473
Validation loss: 2.3991444187779583

Epoch: 6| Step: 2
Training loss: 2.3355000019073486
Validation loss: 2.3977374287061792

Epoch: 6| Step: 3
Training loss: 3.1660125255584717
Validation loss: 2.3967030714916926

Epoch: 6| Step: 4
Training loss: 2.289163827896118
Validation loss: 2.3864297738639255

Epoch: 6| Step: 5
Training loss: 2.9580302238464355
Validation loss: 2.387683085215989

Epoch: 6| Step: 6
Training loss: 3.0414626598358154
Validation loss: 2.3836807589377127

Epoch: 6| Step: 7
Training loss: 2.7987828254699707
Validation loss: 2.391716205945579

Epoch: 6| Step: 8
Training loss: 2.5399718284606934
Validation loss: 2.3952052926504486

Epoch: 6| Step: 9
Training loss: 2.068911075592041
Validation loss: 2.3996902024874123

Epoch: 6| Step: 10
Training loss: 2.3100082874298096
Validation loss: 2.4062021291384132

Epoch: 6| Step: 11
Training loss: 2.4861502647399902
Validation loss: 2.4128534947672198

Epoch: 6| Step: 12
Training loss: 3.433645725250244
Validation loss: 2.411765880482171

Epoch: 6| Step: 13
Training loss: 2.8716442584991455
Validation loss: 2.4049860251847135

Epoch: 109| Step: 0
Training loss: 3.4278881549835205
Validation loss: 2.402891161621258

Epoch: 6| Step: 1
Training loss: 2.682058095932007
Validation loss: 2.4111186996583016

Epoch: 6| Step: 2
Training loss: 2.892468214035034
Validation loss: 2.4067875428866317

Epoch: 6| Step: 3
Training loss: 2.5711686611175537
Validation loss: 2.4084351652412006

Epoch: 6| Step: 4
Training loss: 2.44218111038208
Validation loss: 2.4101771641803045

Epoch: 6| Step: 5
Training loss: 3.453486442565918
Validation loss: 2.4140603824328353

Epoch: 6| Step: 6
Training loss: 1.9762561321258545
Validation loss: 2.4141791789762435

Epoch: 6| Step: 7
Training loss: 2.7637686729431152
Validation loss: 2.416688758839843

Epoch: 6| Step: 8
Training loss: 2.6406331062316895
Validation loss: 2.412467336141935

Epoch: 6| Step: 9
Training loss: 2.53778076171875
Validation loss: 2.404215238427603

Epoch: 6| Step: 10
Training loss: 2.000232696533203
Validation loss: 2.406151012707782

Epoch: 6| Step: 11
Training loss: 1.9906790256500244
Validation loss: 2.4007203220039286

Epoch: 6| Step: 12
Training loss: 2.867980480194092
Validation loss: 2.39507290112075

Epoch: 6| Step: 13
Training loss: 2.202049732208252
Validation loss: 2.3975806133721465

Epoch: 110| Step: 0
Training loss: 2.5301337242126465
Validation loss: 2.388087513626263

Epoch: 6| Step: 1
Training loss: 2.6893110275268555
Validation loss: 2.3867960642742854

Epoch: 6| Step: 2
Training loss: 2.0956151485443115
Validation loss: 2.3868383874175367

Epoch: 6| Step: 3
Training loss: 3.1763439178466797
Validation loss: 2.3932835619936705

Epoch: 6| Step: 4
Training loss: 2.290465831756592
Validation loss: 2.3976787649175173

Epoch: 6| Step: 5
Training loss: 2.9511799812316895
Validation loss: 2.4011690539698445

Epoch: 6| Step: 6
Training loss: 3.1236679553985596
Validation loss: 2.4050356085582445

Epoch: 6| Step: 7
Training loss: 2.3218557834625244
Validation loss: 2.414548453464303

Epoch: 6| Step: 8
Training loss: 2.3491666316986084
Validation loss: 2.4198439659610873

Epoch: 6| Step: 9
Training loss: 2.9433634281158447
Validation loss: 2.414907791281259

Epoch: 6| Step: 10
Training loss: 2.473891258239746
Validation loss: 2.3980238386379775

Epoch: 6| Step: 11
Training loss: 1.862349033355713
Validation loss: 2.393529966313352

Epoch: 6| Step: 12
Training loss: 3.2740769386291504
Validation loss: 2.390158858350528

Epoch: 6| Step: 13
Training loss: 2.5399744510650635
Validation loss: 2.388921554370593

Epoch: 111| Step: 0
Training loss: 3.5596961975097656
Validation loss: 2.3927393959414576

Epoch: 6| Step: 1
Training loss: 2.475492000579834
Validation loss: 2.382997417962679

Epoch: 6| Step: 2
Training loss: 2.8635878562927246
Validation loss: 2.3877991707094255

Epoch: 6| Step: 3
Training loss: 2.1337108612060547
Validation loss: 2.3951386918303785

Epoch: 6| Step: 4
Training loss: 2.8353209495544434
Validation loss: 2.4068287957099175

Epoch: 6| Step: 5
Training loss: 2.94340443611145
Validation loss: 2.4001336815536662

Epoch: 6| Step: 6
Training loss: 2.4760851860046387
Validation loss: 2.3959697831061577

Epoch: 6| Step: 7
Training loss: 2.4395110607147217
Validation loss: 2.3846075970639466

Epoch: 6| Step: 8
Training loss: 2.3589701652526855
Validation loss: 2.386184443709671

Epoch: 6| Step: 9
Training loss: 2.4375267028808594
Validation loss: 2.3907569634017123

Epoch: 6| Step: 10
Training loss: 2.3951992988586426
Validation loss: 2.388632469279792

Epoch: 6| Step: 11
Training loss: 2.524852752685547
Validation loss: 2.3913655639976583

Epoch: 6| Step: 12
Training loss: 2.3530454635620117
Validation loss: 2.3972263797636955

Epoch: 6| Step: 13
Training loss: 2.9290971755981445
Validation loss: 2.3982502337424987

Epoch: 112| Step: 0
Training loss: 2.6877646446228027
Validation loss: 2.39341393850183

Epoch: 6| Step: 1
Training loss: 2.6164653301239014
Validation loss: 2.4037406726550032

Epoch: 6| Step: 2
Training loss: 2.827702045440674
Validation loss: 2.4044734124214417

Epoch: 6| Step: 3
Training loss: 2.229855537414551
Validation loss: 2.403131003020912

Epoch: 6| Step: 4
Training loss: 2.5959115028381348
Validation loss: 2.418254675403718

Epoch: 6| Step: 5
Training loss: 2.573237657546997
Validation loss: 2.417858897998769

Epoch: 6| Step: 6
Training loss: 3.0038723945617676
Validation loss: 2.4136606134394163

Epoch: 6| Step: 7
Training loss: 3.2498440742492676
Validation loss: 2.421121302471366

Epoch: 6| Step: 8
Training loss: 1.5198700428009033
Validation loss: 2.4141758705980036

Epoch: 6| Step: 9
Training loss: 2.5191617012023926
Validation loss: 2.407741932458775

Epoch: 6| Step: 10
Training loss: 2.3599700927734375
Validation loss: 2.406902925942534

Epoch: 6| Step: 11
Training loss: 2.5854854583740234
Validation loss: 2.408815396729336

Epoch: 6| Step: 12
Training loss: 3.590111255645752
Validation loss: 2.406331067444176

Epoch: 6| Step: 13
Training loss: 1.9674620628356934
Validation loss: 2.401903731848604

Epoch: 113| Step: 0
Training loss: 2.7663230895996094
Validation loss: 2.4021525818814515

Epoch: 6| Step: 1
Training loss: 2.9712448120117188
Validation loss: 2.401305075614683

Epoch: 6| Step: 2
Training loss: 2.724362373352051
Validation loss: 2.4026352487584597

Epoch: 6| Step: 3
Training loss: 2.829805612564087
Validation loss: 2.4018561814420964

Epoch: 6| Step: 4
Training loss: 3.2770791053771973
Validation loss: 2.41133362759826

Epoch: 6| Step: 5
Training loss: 2.3477954864501953
Validation loss: 2.4087128946858067

Epoch: 6| Step: 6
Training loss: 2.2792348861694336
Validation loss: 2.4116829646530973

Epoch: 6| Step: 7
Training loss: 2.6281349658966064
Validation loss: 2.4163505338853404

Epoch: 6| Step: 8
Training loss: 2.5816640853881836
Validation loss: 2.413819912941225

Epoch: 6| Step: 9
Training loss: 2.6998231410980225
Validation loss: 2.404516309820196

Epoch: 6| Step: 10
Training loss: 2.1632332801818848
Validation loss: 2.3932245751862884

Epoch: 6| Step: 11
Training loss: 2.2049498558044434
Validation loss: 2.3929421158247095

Epoch: 6| Step: 12
Training loss: 2.5409724712371826
Validation loss: 2.385625336759834

Epoch: 6| Step: 13
Training loss: 2.313500165939331
Validation loss: 2.3851878335399013

Epoch: 114| Step: 0
Training loss: 3.212074041366577
Validation loss: 2.3860626195066716

Epoch: 6| Step: 1
Training loss: 2.8965463638305664
Validation loss: 2.385476750712241

Epoch: 6| Step: 2
Training loss: 2.8038668632507324
Validation loss: 2.3799304526339293

Epoch: 6| Step: 3
Training loss: 2.3310060501098633
Validation loss: 2.3779497864425823

Epoch: 6| Step: 4
Training loss: 2.285686492919922
Validation loss: 2.3746552108436503

Epoch: 6| Step: 5
Training loss: 2.5091919898986816
Validation loss: 2.3910893009554957

Epoch: 6| Step: 6
Training loss: 2.988104820251465
Validation loss: 2.397600225223008

Epoch: 6| Step: 7
Training loss: 2.469414710998535
Validation loss: 2.4025338439531225

Epoch: 6| Step: 8
Training loss: 2.1315503120422363
Validation loss: 2.4061591599577214

Epoch: 6| Step: 9
Training loss: 3.0119004249572754
Validation loss: 2.4071461821115143

Epoch: 6| Step: 10
Training loss: 1.6302413940429688
Validation loss: 2.410801563211667

Epoch: 6| Step: 11
Training loss: 2.28470778465271
Validation loss: 2.4097467058448383

Epoch: 6| Step: 12
Training loss: 3.194279432296753
Validation loss: 2.409807519246173

Epoch: 6| Step: 13
Training loss: 2.763915538787842
Validation loss: 2.402017302410577

Epoch: 115| Step: 0
Training loss: 2.8386788368225098
Validation loss: 2.398854640222365

Epoch: 6| Step: 1
Training loss: 2.5746965408325195
Validation loss: 2.4092876013889106

Epoch: 6| Step: 2
Training loss: 3.3907694816589355
Validation loss: 2.4127833817594793

Epoch: 6| Step: 3
Training loss: 2.7527496814727783
Validation loss: 2.3943099719221874

Epoch: 6| Step: 4
Training loss: 2.181382179260254
Validation loss: 2.374725539197204

Epoch: 6| Step: 5
Training loss: 2.639659881591797
Validation loss: 2.372266302826584

Epoch: 6| Step: 6
Training loss: 2.7946367263793945
Validation loss: 2.3775328436205463

Epoch: 6| Step: 7
Training loss: 3.0081615447998047
Validation loss: 2.3713440664352907

Epoch: 6| Step: 8
Training loss: 2.884589672088623
Validation loss: 2.3769606185215775

Epoch: 6| Step: 9
Training loss: 2.8774571418762207
Validation loss: 2.37526685191739

Epoch: 6| Step: 10
Training loss: 2.385751724243164
Validation loss: 2.375281382632512

Epoch: 6| Step: 11
Training loss: 2.0600996017456055
Validation loss: 2.3769821402847127

Epoch: 6| Step: 12
Training loss: 1.5437116622924805
Validation loss: 2.375570833042104

Epoch: 6| Step: 13
Training loss: 2.3581535816192627
Validation loss: 2.3832362467242825

Epoch: 116| Step: 0
Training loss: 2.0963525772094727
Validation loss: 2.3709110611228534

Epoch: 6| Step: 1
Training loss: 2.6843485832214355
Validation loss: 2.376297830253519

Epoch: 6| Step: 2
Training loss: 2.9049744606018066
Validation loss: 2.3729827968023156

Epoch: 6| Step: 3
Training loss: 2.5740089416503906
Validation loss: 2.379854402234477

Epoch: 6| Step: 4
Training loss: 2.8749611377716064
Validation loss: 2.376826309388684

Epoch: 6| Step: 5
Training loss: 1.663946509361267
Validation loss: 2.3740768970981723

Epoch: 6| Step: 6
Training loss: 2.518831968307495
Validation loss: 2.3720150275896956

Epoch: 6| Step: 7
Training loss: 3.0688345432281494
Validation loss: 2.3789550232630905

Epoch: 6| Step: 8
Training loss: 2.481104612350464
Validation loss: 2.3676803855485815

Epoch: 6| Step: 9
Training loss: 2.527388095855713
Validation loss: 2.378913166702435

Epoch: 6| Step: 10
Training loss: 2.8123440742492676
Validation loss: 2.3858687595654557

Epoch: 6| Step: 11
Training loss: 2.8269777297973633
Validation loss: 2.395982796146024

Epoch: 6| Step: 12
Training loss: 3.1679275035858154
Validation loss: 2.4172242841412945

Epoch: 6| Step: 13
Training loss: 1.9037213325500488
Validation loss: 2.402887313596664

Epoch: 117| Step: 0
Training loss: 2.7697722911834717
Validation loss: 2.3855994234802904

Epoch: 6| Step: 1
Training loss: 2.526071071624756
Validation loss: 2.389229323274346

Epoch: 6| Step: 2
Training loss: 2.6287267208099365
Validation loss: 2.377965627178069

Epoch: 6| Step: 3
Training loss: 3.5021204948425293
Validation loss: 2.3795767214990433

Epoch: 6| Step: 4
Training loss: 2.3210155963897705
Validation loss: 2.369193741070327

Epoch: 6| Step: 5
Training loss: 2.5525853633880615
Validation loss: 2.366976789248887

Epoch: 6| Step: 6
Training loss: 2.7693686485290527
Validation loss: 2.3691357540827926

Epoch: 6| Step: 7
Training loss: 2.898693561553955
Validation loss: 2.3707774864730013

Epoch: 6| Step: 8
Training loss: 2.1682910919189453
Validation loss: 2.365384417195474

Epoch: 6| Step: 9
Training loss: 2.0914971828460693
Validation loss: 2.362919210105814

Epoch: 6| Step: 10
Training loss: 2.553436756134033
Validation loss: 2.3687663488490607

Epoch: 6| Step: 11
Training loss: 2.5055317878723145
Validation loss: 2.3788684529642903

Epoch: 6| Step: 12
Training loss: 2.8021490573883057
Validation loss: 2.376738420096777

Epoch: 6| Step: 13
Training loss: 1.8198983669281006
Validation loss: 2.374572374487436

Epoch: 118| Step: 0
Training loss: 2.365896463394165
Validation loss: 2.389134330134238

Epoch: 6| Step: 1
Training loss: 2.9826924800872803
Validation loss: 2.401072689281997

Epoch: 6| Step: 2
Training loss: 3.1668925285339355
Validation loss: 2.404827558866111

Epoch: 6| Step: 3
Training loss: 3.1578071117401123
Validation loss: 2.400399649015037

Epoch: 6| Step: 4
Training loss: 2.47977876663208
Validation loss: 2.3919343051090034

Epoch: 6| Step: 5
Training loss: 2.3781509399414062
Validation loss: 2.383634223732897

Epoch: 6| Step: 6
Training loss: 2.4319722652435303
Validation loss: 2.370276394710746

Epoch: 6| Step: 7
Training loss: 2.519080638885498
Validation loss: 2.364641179320633

Epoch: 6| Step: 8
Training loss: 2.3887057304382324
Validation loss: 2.3670379436144264

Epoch: 6| Step: 9
Training loss: 2.445233106613159
Validation loss: 2.3650158682177143

Epoch: 6| Step: 10
Training loss: 2.697256565093994
Validation loss: 2.3628777534730974

Epoch: 6| Step: 11
Training loss: 2.830230236053467
Validation loss: 2.361656524801767

Epoch: 6| Step: 12
Training loss: 2.4706690311431885
Validation loss: 2.372123349097467

Epoch: 6| Step: 13
Training loss: 1.6788547039031982
Validation loss: 2.378238667723953

Epoch: 119| Step: 0
Training loss: 2.2872796058654785
Validation loss: 2.4045405490424043

Epoch: 6| Step: 1
Training loss: 2.321718215942383
Validation loss: 2.4215493663664787

Epoch: 6| Step: 2
Training loss: 3.1232824325561523
Validation loss: 2.405052443986298

Epoch: 6| Step: 3
Training loss: 2.838557243347168
Validation loss: 2.3921518146350818

Epoch: 6| Step: 4
Training loss: 2.6630795001983643
Validation loss: 2.380859951819143

Epoch: 6| Step: 5
Training loss: 3.109760046005249
Validation loss: 2.3766133144337642

Epoch: 6| Step: 6
Training loss: 1.875952124595642
Validation loss: 2.3751186145249235

Epoch: 6| Step: 7
Training loss: 2.749786376953125
Validation loss: 2.372524807530065

Epoch: 6| Step: 8
Training loss: 2.8667073249816895
Validation loss: 2.370826998064595

Epoch: 6| Step: 9
Training loss: 2.283660650253296
Validation loss: 2.3713166175350064

Epoch: 6| Step: 10
Training loss: 2.6969332695007324
Validation loss: 2.3612510593988563

Epoch: 6| Step: 11
Training loss: 2.869637966156006
Validation loss: 2.362673913278887

Epoch: 6| Step: 12
Training loss: 2.452685832977295
Validation loss: 2.3704074762200795

Epoch: 6| Step: 13
Training loss: 2.061206340789795
Validation loss: 2.3831709174699682

Epoch: 120| Step: 0
Training loss: 2.52744722366333
Validation loss: 2.392388141283425

Epoch: 6| Step: 1
Training loss: 3.1543989181518555
Validation loss: 2.3828657468159995

Epoch: 6| Step: 2
Training loss: 3.2862067222595215
Validation loss: 2.38566691132002

Epoch: 6| Step: 3
Training loss: 2.728646755218506
Validation loss: 2.375428327950098

Epoch: 6| Step: 4
Training loss: 2.417282819747925
Validation loss: 2.366658454300255

Epoch: 6| Step: 5
Training loss: 2.755917549133301
Validation loss: 2.365112443124094

Epoch: 6| Step: 6
Training loss: 2.5662403106689453
Validation loss: 2.3581256789545857

Epoch: 6| Step: 7
Training loss: 2.611020565032959
Validation loss: 2.3616654257620535

Epoch: 6| Step: 8
Training loss: 2.3530569076538086
Validation loss: 2.3579155962954284

Epoch: 6| Step: 9
Training loss: 1.92793869972229
Validation loss: 2.35417773390329

Epoch: 6| Step: 10
Training loss: 2.2399039268493652
Validation loss: 2.354287669222842

Epoch: 6| Step: 11
Training loss: 2.527848482131958
Validation loss: 2.3559694264524724

Epoch: 6| Step: 12
Training loss: 2.3475589752197266
Validation loss: 2.3600835825807307

Epoch: 6| Step: 13
Training loss: 3.0587611198425293
Validation loss: 2.364799404657015

Epoch: 121| Step: 0
Training loss: 2.1810097694396973
Validation loss: 2.385420378818307

Epoch: 6| Step: 1
Training loss: 2.287116527557373
Validation loss: 2.4020295117491033

Epoch: 6| Step: 2
Training loss: 1.8842138051986694
Validation loss: 2.416024492632958

Epoch: 6| Step: 3
Training loss: 2.682034730911255
Validation loss: 2.4033938095133793

Epoch: 6| Step: 4
Training loss: 2.1110198497772217
Validation loss: 2.394764079842516

Epoch: 6| Step: 5
Training loss: 2.8718032836914062
Validation loss: 2.37515914311973

Epoch: 6| Step: 6
Training loss: 2.695127010345459
Validation loss: 2.3662957811868317

Epoch: 6| Step: 7
Training loss: 3.807492256164551
Validation loss: 2.3609402333536456

Epoch: 6| Step: 8
Training loss: 2.871349334716797
Validation loss: 2.3603867664132068

Epoch: 6| Step: 9
Training loss: 2.3975534439086914
Validation loss: 2.3616645541242374

Epoch: 6| Step: 10
Training loss: 2.2029857635498047
Validation loss: 2.3638521907150105

Epoch: 6| Step: 11
Training loss: 3.155092716217041
Validation loss: 2.3668817448359665

Epoch: 6| Step: 12
Training loss: 2.9641218185424805
Validation loss: 2.3671395496655534

Epoch: 6| Step: 13
Training loss: 1.6390900611877441
Validation loss: 2.3680493613725067

Epoch: 122| Step: 0
Training loss: 2.2531023025512695
Validation loss: 2.3772099748734505

Epoch: 6| Step: 1
Training loss: 2.868074893951416
Validation loss: 2.3827719714051936

Epoch: 6| Step: 2
Training loss: 3.0653514862060547
Validation loss: 2.389444976724604

Epoch: 6| Step: 3
Training loss: 2.4004735946655273
Validation loss: 2.3965303641493603

Epoch: 6| Step: 4
Training loss: 2.7459473609924316
Validation loss: 2.3923771791560675

Epoch: 6| Step: 5
Training loss: 1.9214863777160645
Validation loss: 2.384979896647956

Epoch: 6| Step: 6
Training loss: 3.1862168312072754
Validation loss: 2.3709279439782582

Epoch: 6| Step: 7
Training loss: 2.5867977142333984
Validation loss: 2.3807345603101995

Epoch: 6| Step: 8
Training loss: 1.5306048393249512
Validation loss: 2.389770746231079

Epoch: 6| Step: 9
Training loss: 2.75557279586792
Validation loss: 2.4037821728696107

Epoch: 6| Step: 10
Training loss: 2.992727041244507
Validation loss: 2.402144355158652

Epoch: 6| Step: 11
Training loss: 2.560029983520508
Validation loss: 2.3916294959283646

Epoch: 6| Step: 12
Training loss: 2.590067148208618
Validation loss: 2.382999409911453

Epoch: 6| Step: 13
Training loss: 2.8253438472747803
Validation loss: 2.371591168065225

Epoch: 123| Step: 0
Training loss: 2.1087098121643066
Validation loss: 2.3648379259212042

Epoch: 6| Step: 1
Training loss: 2.166856050491333
Validation loss: 2.3638434410095215

Epoch: 6| Step: 2
Training loss: 2.4478466510772705
Validation loss: 2.3563315791468464

Epoch: 6| Step: 3
Training loss: 2.2209506034851074
Validation loss: 2.3521248320097565

Epoch: 6| Step: 4
Training loss: 2.8325772285461426
Validation loss: 2.3575915726282264

Epoch: 6| Step: 5
Training loss: 2.5684242248535156
Validation loss: 2.3613046523063415

Epoch: 6| Step: 6
Training loss: 2.8092050552368164
Validation loss: 2.350858748600047

Epoch: 6| Step: 7
Training loss: 2.6281137466430664
Validation loss: 2.3525529805050103

Epoch: 6| Step: 8
Training loss: 2.8318214416503906
Validation loss: 2.353208008632865

Epoch: 6| Step: 9
Training loss: 2.44329833984375
Validation loss: 2.3585736251646474

Epoch: 6| Step: 10
Training loss: 3.157266616821289
Validation loss: 2.369555719437138

Epoch: 6| Step: 11
Training loss: 2.6208853721618652
Validation loss: 2.3705273751289613

Epoch: 6| Step: 12
Training loss: 3.0530788898468018
Validation loss: 2.3703723133251233

Epoch: 6| Step: 13
Training loss: 2.1125741004943848
Validation loss: 2.360783597474457

Epoch: 124| Step: 0
Training loss: 2.153048515319824
Validation loss: 2.3592307849596907

Epoch: 6| Step: 1
Training loss: 2.59555983543396
Validation loss: 2.3504701865616666

Epoch: 6| Step: 2
Training loss: 2.7249069213867188
Validation loss: 2.348620496770387

Epoch: 6| Step: 3
Training loss: 2.2059085369110107
Validation loss: 2.345749324367892

Epoch: 6| Step: 4
Training loss: 3.069795608520508
Validation loss: 2.346804912372302

Epoch: 6| Step: 5
Training loss: 2.79848575592041
Validation loss: 2.347361456963324

Epoch: 6| Step: 6
Training loss: 2.294501304626465
Validation loss: 2.3505782645235778

Epoch: 6| Step: 7
Training loss: 3.1910457611083984
Validation loss: 2.346990798109321

Epoch: 6| Step: 8
Training loss: 2.829878568649292
Validation loss: 2.358416324020714

Epoch: 6| Step: 9
Training loss: 2.631521701812744
Validation loss: 2.352552242176507

Epoch: 6| Step: 10
Training loss: 2.221616268157959
Validation loss: 2.3559923787270822

Epoch: 6| Step: 11
Training loss: 1.807063341140747
Validation loss: 2.360642558784895

Epoch: 6| Step: 12
Training loss: 2.9006824493408203
Validation loss: 2.370407672338588

Epoch: 6| Step: 13
Training loss: 2.806108236312866
Validation loss: 2.372842655386976

Epoch: 125| Step: 0
Training loss: 1.6488728523254395
Validation loss: 2.377929469590546

Epoch: 6| Step: 1
Training loss: 3.2070565223693848
Validation loss: 2.3920189103772564

Epoch: 6| Step: 2
Training loss: 2.724355936050415
Validation loss: 2.3804798767130864

Epoch: 6| Step: 3
Training loss: 2.181537389755249
Validation loss: 2.3817563031309392

Epoch: 6| Step: 4
Training loss: 2.057495355606079
Validation loss: 2.3767372100583968

Epoch: 6| Step: 5
Training loss: 1.8898022174835205
Validation loss: 2.368698158571797

Epoch: 6| Step: 6
Training loss: 2.8563756942749023
Validation loss: 2.3736787919075257

Epoch: 6| Step: 7
Training loss: 1.921042799949646
Validation loss: 2.3789834848014255

Epoch: 6| Step: 8
Training loss: 3.485335350036621
Validation loss: 2.392202613174274

Epoch: 6| Step: 9
Training loss: 2.209289312362671
Validation loss: 2.3893227192663375

Epoch: 6| Step: 10
Training loss: 2.992159366607666
Validation loss: 2.3998133264562136

Epoch: 6| Step: 11
Training loss: 3.1202549934387207
Validation loss: 2.38250425810455

Epoch: 6| Step: 12
Training loss: 2.525949478149414
Validation loss: 2.350645396017259

Epoch: 6| Step: 13
Training loss: 3.954453468322754
Validation loss: 2.3545026945811447

Epoch: 126| Step: 0
Training loss: 2.3724045753479004
Validation loss: 2.3426101233369563

Epoch: 6| Step: 1
Training loss: 2.4239559173583984
Validation loss: 2.3485257471761396

Epoch: 6| Step: 2
Training loss: 2.2672066688537598
Validation loss: 2.355757624872269

Epoch: 6| Step: 3
Training loss: 3.24666166305542
Validation loss: 2.35968029627236

Epoch: 6| Step: 4
Training loss: 2.1420745849609375
Validation loss: 2.3830290814881683

Epoch: 6| Step: 5
Training loss: 2.808570146560669
Validation loss: 2.385946842931932

Epoch: 6| Step: 6
Training loss: 2.575821876525879
Validation loss: 2.380789638847433

Epoch: 6| Step: 7
Training loss: 3.004161834716797
Validation loss: 2.3780389037183536

Epoch: 6| Step: 8
Training loss: 3.075127124786377
Validation loss: 2.36405013966304

Epoch: 6| Step: 9
Training loss: 2.565391778945923
Validation loss: 2.36489184441105

Epoch: 6| Step: 10
Training loss: 2.062845468521118
Validation loss: 2.3513886800376316

Epoch: 6| Step: 11
Training loss: 2.8040285110473633
Validation loss: 2.336733064343852

Epoch: 6| Step: 12
Training loss: 2.273935317993164
Validation loss: 2.3292840450040755

Epoch: 6| Step: 13
Training loss: 2.2908918857574463
Validation loss: 2.3306643885950886

Epoch: 127| Step: 0
Training loss: 2.552600383758545
Validation loss: 2.3439900875091553

Epoch: 6| Step: 1
Training loss: 2.005202531814575
Validation loss: 2.3388458862099597

Epoch: 6| Step: 2
Training loss: 2.4778575897216797
Validation loss: 2.3468966919888734

Epoch: 6| Step: 3
Training loss: 2.864696979522705
Validation loss: 2.349001561441729

Epoch: 6| Step: 4
Training loss: 3.0848288536071777
Validation loss: 2.35304598141742

Epoch: 6| Step: 5
Training loss: 2.133455514907837
Validation loss: 2.3508268171741116

Epoch: 6| Step: 6
Training loss: 2.016052722930908
Validation loss: 2.35095880364859

Epoch: 6| Step: 7
Training loss: 2.2504806518554688
Validation loss: 2.3480361046329623

Epoch: 6| Step: 8
Training loss: 2.8487420082092285
Validation loss: 2.351472106031192

Epoch: 6| Step: 9
Training loss: 2.542952060699463
Validation loss: 2.3490557888502717

Epoch: 6| Step: 10
Training loss: 2.8181803226470947
Validation loss: 2.351421715110861

Epoch: 6| Step: 11
Training loss: 3.023134708404541
Validation loss: 2.3425763166078957

Epoch: 6| Step: 12
Training loss: 2.5847697257995605
Validation loss: 2.345854269560947

Epoch: 6| Step: 13
Training loss: 3.413834571838379
Validation loss: 2.34556318354863

Epoch: 128| Step: 0
Training loss: 2.817216157913208
Validation loss: 2.346702342392296

Epoch: 6| Step: 1
Training loss: 2.163421392440796
Validation loss: 2.351517128688033

Epoch: 6| Step: 2
Training loss: 2.704946756362915
Validation loss: 2.3563304229449202

Epoch: 6| Step: 3
Training loss: 2.718482494354248
Validation loss: 2.3722769265533774

Epoch: 6| Step: 4
Training loss: 2.621283531188965
Validation loss: 2.384508127807289

Epoch: 6| Step: 5
Training loss: 2.4747109413146973
Validation loss: 2.393311944059146

Epoch: 6| Step: 6
Training loss: 2.3589224815368652
Validation loss: 2.401084771720312

Epoch: 6| Step: 7
Training loss: 2.195516586303711
Validation loss: 2.3782929271780033

Epoch: 6| Step: 8
Training loss: 2.7009811401367188
Validation loss: 2.3627164363861084

Epoch: 6| Step: 9
Training loss: 1.8663318157196045
Validation loss: 2.349282959456085

Epoch: 6| Step: 10
Training loss: 2.8626303672790527
Validation loss: 2.3405437161845546

Epoch: 6| Step: 11
Training loss: 2.744762897491455
Validation loss: 2.3372613717150945

Epoch: 6| Step: 12
Training loss: 2.9921207427978516
Validation loss: 2.341588156197661

Epoch: 6| Step: 13
Training loss: 3.0149097442626953
Validation loss: 2.3482154466772593

Epoch: 129| Step: 0
Training loss: 2.6821413040161133
Validation loss: 2.3388075828552246

Epoch: 6| Step: 1
Training loss: 2.475864887237549
Validation loss: 2.3416129209661998

Epoch: 6| Step: 2
Training loss: 2.6723849773406982
Validation loss: 2.3377424247803225

Epoch: 6| Step: 3
Training loss: 2.751521348953247
Validation loss: 2.3264590694058325

Epoch: 6| Step: 4
Training loss: 2.7409493923187256
Validation loss: 2.3263168719507035

Epoch: 6| Step: 5
Training loss: 2.3044450283050537
Validation loss: 2.327340925893476

Epoch: 6| Step: 6
Training loss: 3.0225279331207275
Validation loss: 2.3184781638524865

Epoch: 6| Step: 7
Training loss: 2.827770709991455
Validation loss: 2.3167786393114316

Epoch: 6| Step: 8
Training loss: 2.296703815460205
Validation loss: 2.3153476458723827

Epoch: 6| Step: 9
Training loss: 3.3317456245422363
Validation loss: 2.311060787529074

Epoch: 6| Step: 10
Training loss: 2.660649299621582
Validation loss: 2.3167943108466362

Epoch: 6| Step: 11
Training loss: 1.5578714609146118
Validation loss: 2.315523603911041

Epoch: 6| Step: 12
Training loss: 2.080967903137207
Validation loss: 2.3277001727011895

Epoch: 6| Step: 13
Training loss: 2.578909158706665
Validation loss: 2.3378130633343934

Epoch: 130| Step: 0
Training loss: 2.725922107696533
Validation loss: 2.3487067299504436

Epoch: 6| Step: 1
Training loss: 2.6036434173583984
Validation loss: 2.3561349709828696

Epoch: 6| Step: 2
Training loss: 1.9163864850997925
Validation loss: 2.3564585049947104

Epoch: 6| Step: 3
Training loss: 1.6833879947662354
Validation loss: 2.353937659212338

Epoch: 6| Step: 4
Training loss: 3.434844970703125
Validation loss: 2.340533817968061

Epoch: 6| Step: 5
Training loss: 2.6664156913757324
Validation loss: 2.3357001068771526

Epoch: 6| Step: 6
Training loss: 2.394632339477539
Validation loss: 2.341479993635608

Epoch: 6| Step: 7
Training loss: 2.579129695892334
Validation loss: 2.3441009034392652

Epoch: 6| Step: 8
Training loss: 2.663541316986084
Validation loss: 2.3404519224679596

Epoch: 6| Step: 9
Training loss: 3.7786622047424316
Validation loss: 2.340220865382943

Epoch: 6| Step: 10
Training loss: 2.3670310974121094
Validation loss: 2.3412521808378157

Epoch: 6| Step: 11
Training loss: 2.9246914386749268
Validation loss: 2.340370944751206

Epoch: 6| Step: 12
Training loss: 2.1215522289276123
Validation loss: 2.341391258342292

Epoch: 6| Step: 13
Training loss: 1.8878822326660156
Validation loss: 2.3509924719410558

Epoch: 131| Step: 0
Training loss: 2.094933271408081
Validation loss: 2.3358142734855734

Epoch: 6| Step: 1
Training loss: 2.463193893432617
Validation loss: 2.341697782598516

Epoch: 6| Step: 2
Training loss: 2.0971386432647705
Validation loss: 2.340016177905503

Epoch: 6| Step: 3
Training loss: 1.9811451435089111
Validation loss: 2.347520484719225

Epoch: 6| Step: 4
Training loss: 2.4406237602233887
Validation loss: 2.3476914846768944

Epoch: 6| Step: 5
Training loss: 2.5980167388916016
Validation loss: 2.3538744398342666

Epoch: 6| Step: 6
Training loss: 3.055701732635498
Validation loss: 2.3544478236988025

Epoch: 6| Step: 7
Training loss: 2.124317169189453
Validation loss: 2.3606014815709924

Epoch: 6| Step: 8
Training loss: 3.1356635093688965
Validation loss: 2.3521891101714103

Epoch: 6| Step: 9
Training loss: 3.052542209625244
Validation loss: 2.363727395252515

Epoch: 6| Step: 10
Training loss: 2.770073413848877
Validation loss: 2.3574584209790794

Epoch: 6| Step: 11
Training loss: 2.5296630859375
Validation loss: 2.3496154739010717

Epoch: 6| Step: 12
Training loss: 2.6844887733459473
Validation loss: 2.3563033893544185

Epoch: 6| Step: 13
Training loss: 2.7927722930908203
Validation loss: 2.360730355785739

Epoch: 132| Step: 0
Training loss: 3.179056167602539
Validation loss: 2.3484808885922996

Epoch: 6| Step: 1
Training loss: 2.54929256439209
Validation loss: 2.342487553114532

Epoch: 6| Step: 2
Training loss: 2.327526569366455
Validation loss: 2.340640639746061

Epoch: 6| Step: 3
Training loss: 2.209259510040283
Validation loss: 2.3381933858317714

Epoch: 6| Step: 4
Training loss: 2.374098062515259
Validation loss: 2.3509269247772875

Epoch: 6| Step: 5
Training loss: 2.123039960861206
Validation loss: 2.3571294405127086

Epoch: 6| Step: 6
Training loss: 2.740645408630371
Validation loss: 2.370119017939414

Epoch: 6| Step: 7
Training loss: 2.851585626602173
Validation loss: 2.3716059346352854

Epoch: 6| Step: 8
Training loss: 2.0125389099121094
Validation loss: 2.3676100853950746

Epoch: 6| Step: 9
Training loss: 2.4386205673217773
Validation loss: 2.342129340735815

Epoch: 6| Step: 10
Training loss: 2.3518733978271484
Validation loss: 2.3426513543692966

Epoch: 6| Step: 11
Training loss: 2.84692645072937
Validation loss: 2.33504750908062

Epoch: 6| Step: 12
Training loss: 3.219183921813965
Validation loss: 2.3283766418374996

Epoch: 6| Step: 13
Training loss: 2.7856316566467285
Validation loss: 2.327923051772579

Epoch: 133| Step: 0
Training loss: 1.9679107666015625
Validation loss: 2.311508132565406

Epoch: 6| Step: 1
Training loss: 2.7977116107940674
Validation loss: 2.315060979576521

Epoch: 6| Step: 2
Training loss: 2.2225918769836426
Validation loss: 2.316168333894463

Epoch: 6| Step: 3
Training loss: 3.220414161682129
Validation loss: 2.3201279435106503

Epoch: 6| Step: 4
Training loss: 2.11525559425354
Validation loss: 2.3125049273173013

Epoch: 6| Step: 5
Training loss: 2.4112613201141357
Validation loss: 2.3170553099724556

Epoch: 6| Step: 6
Training loss: 3.0369439125061035
Validation loss: 2.321675936381022

Epoch: 6| Step: 7
Training loss: 2.9235568046569824
Validation loss: 2.3234049632985103

Epoch: 6| Step: 8
Training loss: 2.6061339378356934
Validation loss: 2.3418962429928523

Epoch: 6| Step: 9
Training loss: 2.364884376525879
Validation loss: 2.3563255033185406

Epoch: 6| Step: 10
Training loss: 3.0255861282348633
Validation loss: 2.3528500808182584

Epoch: 6| Step: 11
Training loss: 2.6031494140625
Validation loss: 2.3727837916343444

Epoch: 6| Step: 12
Training loss: 2.336012363433838
Validation loss: 2.35740222982181

Epoch: 6| Step: 13
Training loss: 1.9029570817947388
Validation loss: 2.3540332753171205

Epoch: 134| Step: 0
Training loss: 2.9073972702026367
Validation loss: 2.3523743870437785

Epoch: 6| Step: 1
Training loss: 2.9240989685058594
Validation loss: 2.3510564604113178

Epoch: 6| Step: 2
Training loss: 2.9476888179779053
Validation loss: 2.347571551158864

Epoch: 6| Step: 3
Training loss: 2.6718592643737793
Validation loss: 2.360064865440451

Epoch: 6| Step: 4
Training loss: 2.5792946815490723
Validation loss: 2.3669935682768464

Epoch: 6| Step: 5
Training loss: 2.5375447273254395
Validation loss: 2.3692417683139926

Epoch: 6| Step: 6
Training loss: 2.307203769683838
Validation loss: 2.3577246563408965

Epoch: 6| Step: 7
Training loss: 1.4027137756347656
Validation loss: 2.3590722865955804

Epoch: 6| Step: 8
Training loss: 2.182642936706543
Validation loss: 2.3504807359428814

Epoch: 6| Step: 9
Training loss: 2.7001664638519287
Validation loss: 2.341767890478975

Epoch: 6| Step: 10
Training loss: 2.3057312965393066
Validation loss: 2.3393843609799623

Epoch: 6| Step: 11
Training loss: 2.200565814971924
Validation loss: 2.3322899764583958

Epoch: 6| Step: 12
Training loss: 3.101841449737549
Validation loss: 2.332906384621897

Epoch: 6| Step: 13
Training loss: 3.3545684814453125
Validation loss: 2.3257545271227436

Epoch: 135| Step: 0
Training loss: 3.0426743030548096
Validation loss: 2.325843700798609

Epoch: 6| Step: 1
Training loss: 2.7952284812927246
Validation loss: 2.3237815505714825

Epoch: 6| Step: 2
Training loss: 3.392953395843506
Validation loss: 2.334318043083273

Epoch: 6| Step: 3
Training loss: 2.29624605178833
Validation loss: 2.332321233646844

Epoch: 6| Step: 4
Training loss: 2.512600898742676
Validation loss: 2.324136878854485

Epoch: 6| Step: 5
Training loss: 1.7812833786010742
Validation loss: 2.3205976076023553

Epoch: 6| Step: 6
Training loss: 3.3594911098480225
Validation loss: 2.3151173078885643

Epoch: 6| Step: 7
Training loss: 2.804978609085083
Validation loss: 2.3023937222778157

Epoch: 6| Step: 8
Training loss: 2.323707103729248
Validation loss: 2.3057386900788996

Epoch: 6| Step: 9
Training loss: 1.8287858963012695
Validation loss: 2.301996361824774

Epoch: 6| Step: 10
Training loss: 2.9592902660369873
Validation loss: 2.3049834056567122

Epoch: 6| Step: 11
Training loss: 2.177982807159424
Validation loss: 2.3034662328740603

Epoch: 6| Step: 12
Training loss: 2.1962413787841797
Validation loss: 2.3055356164132395

Epoch: 6| Step: 13
Training loss: 2.019871234893799
Validation loss: 2.3037115784101587

Epoch: 136| Step: 0
Training loss: 3.0503711700439453
Validation loss: 2.315372920805408

Epoch: 6| Step: 1
Training loss: 3.397490978240967
Validation loss: 2.324407726205805

Epoch: 6| Step: 2
Training loss: 2.5601837635040283
Validation loss: 2.3215141962933283

Epoch: 6| Step: 3
Training loss: 3.013828754425049
Validation loss: 2.324316842581636

Epoch: 6| Step: 4
Training loss: 1.8871697187423706
Validation loss: 2.342324523515599

Epoch: 6| Step: 5
Training loss: 2.2991209030151367
Validation loss: 2.3346933805814354

Epoch: 6| Step: 6
Training loss: 2.876635789871216
Validation loss: 2.3472725857970533

Epoch: 6| Step: 7
Training loss: 2.1157708168029785
Validation loss: 2.3379721385176464

Epoch: 6| Step: 8
Training loss: 2.40512752532959
Validation loss: 2.328549074870284

Epoch: 6| Step: 9
Training loss: 2.7774300575256348
Validation loss: 2.333329298162973

Epoch: 6| Step: 10
Training loss: 1.8279345035552979
Validation loss: 2.324379139049079

Epoch: 6| Step: 11
Training loss: 2.176074266433716
Validation loss: 2.324546480691561

Epoch: 6| Step: 12
Training loss: 2.546719551086426
Validation loss: 2.3367415397397933

Epoch: 6| Step: 13
Training loss: 2.690200090408325
Validation loss: 2.3464466474389516

Epoch: 137| Step: 0
Training loss: 2.3726606369018555
Validation loss: 2.3385436022153465

Epoch: 6| Step: 1
Training loss: 2.01556134223938
Validation loss: 2.3393751036736274

Epoch: 6| Step: 2
Training loss: 2.9084038734436035
Validation loss: 2.336333426096106

Epoch: 6| Step: 3
Training loss: 2.0488383769989014
Validation loss: 2.3325942101017123

Epoch: 6| Step: 4
Training loss: 1.6945278644561768
Validation loss: 2.337797657135994

Epoch: 6| Step: 5
Training loss: 2.890758991241455
Validation loss: 2.345492568067325

Epoch: 6| Step: 6
Training loss: 2.960521936416626
Validation loss: 2.3388325424604517

Epoch: 6| Step: 7
Training loss: 2.2236907482147217
Validation loss: 2.3389875504278366

Epoch: 6| Step: 8
Training loss: 2.677842617034912
Validation loss: 2.350425148522982

Epoch: 6| Step: 9
Training loss: 3.1741514205932617
Validation loss: 2.3581558555685063

Epoch: 6| Step: 10
Training loss: 2.201620578765869
Validation loss: 2.3499587300003215

Epoch: 6| Step: 11
Training loss: 2.9261550903320312
Validation loss: 2.331026646398729

Epoch: 6| Step: 12
Training loss: 2.6547625064849854
Validation loss: 2.3161443125817085

Epoch: 6| Step: 13
Training loss: 3.0495824813842773
Validation loss: 2.3119500631927163

Epoch: 138| Step: 0
Training loss: 2.216708183288574
Validation loss: 2.3391433967057096

Epoch: 6| Step: 1
Training loss: 2.744752883911133
Validation loss: 2.3493292511150403

Epoch: 6| Step: 2
Training loss: 3.4879016876220703
Validation loss: 2.345445979026056

Epoch: 6| Step: 3
Training loss: 2.5530686378479004
Validation loss: 2.327243261439826

Epoch: 6| Step: 4
Training loss: 1.741106629371643
Validation loss: 2.3182131026380803

Epoch: 6| Step: 5
Training loss: 2.9959092140197754
Validation loss: 2.3109424537228

Epoch: 6| Step: 6
Training loss: 1.431396245956421
Validation loss: 2.3244803041540165

Epoch: 6| Step: 7
Training loss: 2.410966396331787
Validation loss: 2.322948181500999

Epoch: 6| Step: 8
Training loss: 2.245511531829834
Validation loss: 2.322843684945055

Epoch: 6| Step: 9
Training loss: 2.5287678241729736
Validation loss: 2.335197884549377

Epoch: 6| Step: 10
Training loss: 2.954274892807007
Validation loss: 2.324501370870939

Epoch: 6| Step: 11
Training loss: 3.3079276084899902
Validation loss: 2.3225974882802656

Epoch: 6| Step: 12
Training loss: 3.0055630207061768
Validation loss: 2.3096417124553392

Epoch: 6| Step: 13
Training loss: 2.0219974517822266
Validation loss: 2.3028195840056225

Epoch: 139| Step: 0
Training loss: 2.6263668537139893
Validation loss: 2.2969171949612197

Epoch: 6| Step: 1
Training loss: 2.7411763668060303
Validation loss: 2.306521474674184

Epoch: 6| Step: 2
Training loss: 2.6988003253936768
Validation loss: 2.301759676266742

Epoch: 6| Step: 3
Training loss: 2.947225570678711
Validation loss: 2.30022527581902

Epoch: 6| Step: 4
Training loss: 2.3895318508148193
Validation loss: 2.3056840665878786

Epoch: 6| Step: 5
Training loss: 2.76485013961792
Validation loss: 2.3016619989948888

Epoch: 6| Step: 6
Training loss: 1.9348740577697754
Validation loss: 2.3159119672672723

Epoch: 6| Step: 7
Training loss: 3.10501766204834
Validation loss: 2.3234317815431984

Epoch: 6| Step: 8
Training loss: 1.5592050552368164
Validation loss: 2.3039048000048568

Epoch: 6| Step: 9
Training loss: 2.8632700443267822
Validation loss: 2.2974323611105643

Epoch: 6| Step: 10
Training loss: 2.324873924255371
Validation loss: 2.2902697747753513

Epoch: 6| Step: 11
Training loss: 2.7989449501037598
Validation loss: 2.285883900939777

Epoch: 6| Step: 12
Training loss: 2.601414203643799
Validation loss: 2.2836262615778113

Epoch: 6| Step: 13
Training loss: 2.0964694023132324
Validation loss: 2.286746645486483

Epoch: 140| Step: 0
Training loss: 2.65364933013916
Validation loss: 2.3001966655895276

Epoch: 6| Step: 1
Training loss: 2.610412836074829
Validation loss: 2.2990527332469983

Epoch: 6| Step: 2
Training loss: 2.399385452270508
Validation loss: 2.311460820577478

Epoch: 6| Step: 3
Training loss: 2.4314780235290527
Validation loss: 2.3192518488053353

Epoch: 6| Step: 4
Training loss: 2.037523031234741
Validation loss: 2.315500395272368

Epoch: 6| Step: 5
Training loss: 2.562265396118164
Validation loss: 2.3223033489719516

Epoch: 6| Step: 6
Training loss: 3.1402664184570312
Validation loss: 2.3148816195867394

Epoch: 6| Step: 7
Training loss: 2.6562156677246094
Validation loss: 2.308814520476967

Epoch: 6| Step: 8
Training loss: 2.6650168895721436
Validation loss: 2.2973895354937484

Epoch: 6| Step: 9
Training loss: 2.5582563877105713
Validation loss: 2.300685303185576

Epoch: 6| Step: 10
Training loss: 2.28062105178833
Validation loss: 2.306026945831955

Epoch: 6| Step: 11
Training loss: 1.851509690284729
Validation loss: 2.3125546440001457

Epoch: 6| Step: 12
Training loss: 2.8051023483276367
Validation loss: 2.3207446298291607

Epoch: 6| Step: 13
Training loss: 3.191659450531006
Validation loss: 2.303955767744331

Epoch: 141| Step: 0
Training loss: 2.04050612449646
Validation loss: 2.31333952565347

Epoch: 6| Step: 1
Training loss: 2.8324108123779297
Validation loss: 2.3147756245828446

Epoch: 6| Step: 2
Training loss: 2.213784694671631
Validation loss: 2.315380580963627

Epoch: 6| Step: 3
Training loss: 2.394684076309204
Validation loss: 2.3216752647071757

Epoch: 6| Step: 4
Training loss: 2.1901557445526123
Validation loss: 2.3136700942952144

Epoch: 6| Step: 5
Training loss: 1.5589781999588013
Validation loss: 2.3272148998834754

Epoch: 6| Step: 6
Training loss: 3.344289779663086
Validation loss: 2.323559784120129

Epoch: 6| Step: 7
Training loss: 2.4066033363342285
Validation loss: 2.316892534173945

Epoch: 6| Step: 8
Training loss: 2.6878533363342285
Validation loss: 2.3221644611768824

Epoch: 6| Step: 9
Training loss: 2.2740888595581055
Validation loss: 2.3183032748519734

Epoch: 6| Step: 10
Training loss: 2.4170737266540527
Validation loss: 2.307058116441132

Epoch: 6| Step: 11
Training loss: 2.966447353363037
Validation loss: 2.3019802288342546

Epoch: 6| Step: 12
Training loss: 2.889984130859375
Validation loss: 2.317939522445843

Epoch: 6| Step: 13
Training loss: 3.72957444190979
Validation loss: 2.320549798268144

Epoch: 142| Step: 0
Training loss: 2.2372891902923584
Validation loss: 2.325550853565175

Epoch: 6| Step: 1
Training loss: 1.7673089504241943
Validation loss: 2.334093716836745

Epoch: 6| Step: 2
Training loss: 2.240018129348755
Validation loss: 2.3552334218896847

Epoch: 6| Step: 3
Training loss: 3.128169298171997
Validation loss: 2.3287102201933503

Epoch: 6| Step: 4
Training loss: 2.8066773414611816
Validation loss: 2.327107805077748

Epoch: 6| Step: 5
Training loss: 2.903367519378662
Validation loss: 2.316965881214347

Epoch: 6| Step: 6
Training loss: 2.848093032836914
Validation loss: 2.2995689504890033

Epoch: 6| Step: 7
Training loss: 3.364469051361084
Validation loss: 2.2954447333530714

Epoch: 6| Step: 8
Training loss: 2.9628238677978516
Validation loss: 2.295937591983426

Epoch: 6| Step: 9
Training loss: 2.344050645828247
Validation loss: 2.295310454983865

Epoch: 6| Step: 10
Training loss: 1.75925874710083
Validation loss: 2.2897007003907235

Epoch: 6| Step: 11
Training loss: 3.2694482803344727
Validation loss: 2.299941791001187

Epoch: 6| Step: 12
Training loss: 2.2904207706451416
Validation loss: 2.295367463942497

Epoch: 6| Step: 13
Training loss: 0.5599243640899658
Validation loss: 2.2981173684520106

Epoch: 143| Step: 0
Training loss: 1.983841061592102
Validation loss: 2.313999838726495

Epoch: 6| Step: 1
Training loss: 2.248267412185669
Validation loss: 2.3049218680268977

Epoch: 6| Step: 2
Training loss: 2.2310962677001953
Validation loss: 2.2975558286072104

Epoch: 6| Step: 3
Training loss: 3.306626558303833
Validation loss: 2.2997291677741596

Epoch: 6| Step: 4
Training loss: 2.9923458099365234
Validation loss: 2.306998401559809

Epoch: 6| Step: 5
Training loss: 2.621182441711426
Validation loss: 2.3006798605765066

Epoch: 6| Step: 6
Training loss: 1.7356857061386108
Validation loss: 2.289989297107984

Epoch: 6| Step: 7
Training loss: 2.908285617828369
Validation loss: 2.295114758194134

Epoch: 6| Step: 8
Training loss: 2.571579694747925
Validation loss: 2.2964235685204946

Epoch: 6| Step: 9
Training loss: 2.729405403137207
Validation loss: 2.301451636898902

Epoch: 6| Step: 10
Training loss: 2.255981683731079
Validation loss: 2.3428518490124772

Epoch: 6| Step: 11
Training loss: 2.8340330123901367
Validation loss: 2.406614713771369

Epoch: 6| Step: 12
Training loss: 2.6012706756591797
Validation loss: 2.363639341887607

Epoch: 6| Step: 13
Training loss: 2.2959792613983154
Validation loss: 2.3445348175623084

Epoch: 144| Step: 0
Training loss: 3.2156453132629395
Validation loss: 2.2894507685015277

Epoch: 6| Step: 1
Training loss: 1.9790419340133667
Validation loss: 2.272586440527311

Epoch: 6| Step: 2
Training loss: 2.894657611846924
Validation loss: 2.2860637108484902

Epoch: 6| Step: 3
Training loss: 3.0569348335266113
Validation loss: 2.294196669773389

Epoch: 6| Step: 4
Training loss: 2.3519105911254883
Validation loss: 2.3288319444143646

Epoch: 6| Step: 5
Training loss: 2.5191986560821533
Validation loss: 2.345070077526954

Epoch: 6| Step: 6
Training loss: 3.091501235961914
Validation loss: 2.3320425146369526

Epoch: 6| Step: 7
Training loss: 2.3494155406951904
Validation loss: 2.314805675578374

Epoch: 6| Step: 8
Training loss: 2.403560161590576
Validation loss: 2.314764589391729

Epoch: 6| Step: 9
Training loss: 2.438237190246582
Validation loss: 2.296838378393522

Epoch: 6| Step: 10
Training loss: 2.7251269817352295
Validation loss: 2.2906884890730663

Epoch: 6| Step: 11
Training loss: 2.660646438598633
Validation loss: 2.2929791788901053

Epoch: 6| Step: 12
Training loss: 2.1621768474578857
Validation loss: 2.2802285840434413

Epoch: 6| Step: 13
Training loss: 1.3082271814346313
Validation loss: 2.2700020446572253

Epoch: 145| Step: 0
Training loss: 2.5510919094085693
Validation loss: 2.26697560023236

Epoch: 6| Step: 1
Training loss: 2.752443790435791
Validation loss: 2.2792616787777153

Epoch: 6| Step: 2
Training loss: 2.6796975135803223
Validation loss: 2.2786318999464794

Epoch: 6| Step: 3
Training loss: 2.2427077293395996
Validation loss: 2.285460651561778

Epoch: 6| Step: 4
Training loss: 2.8476622104644775
Validation loss: 2.2990049803128807

Epoch: 6| Step: 5
Training loss: 2.204376220703125
Validation loss: 2.3059407998156805

Epoch: 6| Step: 6
Training loss: 2.3384695053100586
Validation loss: 2.3025263253078667

Epoch: 6| Step: 7
Training loss: 1.8989410400390625
Validation loss: 2.295588941984279

Epoch: 6| Step: 8
Training loss: 3.235924243927002
Validation loss: 2.2884485721588135

Epoch: 6| Step: 9
Training loss: 2.487694501876831
Validation loss: 2.2895697265542965

Epoch: 6| Step: 10
Training loss: 1.991010308265686
Validation loss: 2.291061241139648

Epoch: 6| Step: 11
Training loss: 3.3347420692443848
Validation loss: 2.2836671952278382

Epoch: 6| Step: 12
Training loss: 2.3207521438598633
Validation loss: 2.291033688411918

Epoch: 6| Step: 13
Training loss: 2.4714345932006836
Validation loss: 2.287428461095338

Epoch: 146| Step: 0
Training loss: 2.390103578567505
Validation loss: 2.2901496579570155

Epoch: 6| Step: 1
Training loss: 1.9679979085922241
Validation loss: 2.2986855583806194

Epoch: 6| Step: 2
Training loss: 2.8016865253448486
Validation loss: 2.307336363741147

Epoch: 6| Step: 3
Training loss: 2.518296957015991
Validation loss: 2.3080173243758497

Epoch: 6| Step: 4
Training loss: 2.533275604248047
Validation loss: 2.3090942162339405

Epoch: 6| Step: 5
Training loss: 2.252833127975464
Validation loss: 2.303080353685605

Epoch: 6| Step: 6
Training loss: 2.4592156410217285
Validation loss: 2.2841112562405166

Epoch: 6| Step: 7
Training loss: 2.4787535667419434
Validation loss: 2.2794688388865483

Epoch: 6| Step: 8
Training loss: 2.622298240661621
Validation loss: 2.27975607046517

Epoch: 6| Step: 9
Training loss: 2.6771860122680664
Validation loss: 2.2759881250319944

Epoch: 6| Step: 10
Training loss: 2.062387466430664
Validation loss: 2.281046559733729

Epoch: 6| Step: 11
Training loss: 3.1253137588500977
Validation loss: 2.277602836649905

Epoch: 6| Step: 12
Training loss: 2.7563087940216064
Validation loss: 2.277160090784873

Epoch: 6| Step: 13
Training loss: 2.899134874343872
Validation loss: 2.2795990667035504

Epoch: 147| Step: 0
Training loss: 2.690122365951538
Validation loss: 2.287341662632522

Epoch: 6| Step: 1
Training loss: 2.7222139835357666
Validation loss: 2.289683513743903

Epoch: 6| Step: 2
Training loss: 2.40743350982666
Validation loss: 2.2913075493228052

Epoch: 6| Step: 3
Training loss: 2.6193370819091797
Validation loss: 2.2967641225425144

Epoch: 6| Step: 4
Training loss: 3.1100895404815674
Validation loss: 2.3057602041511127

Epoch: 6| Step: 5
Training loss: 1.905595302581787
Validation loss: 2.3048870076415358

Epoch: 6| Step: 6
Training loss: 2.564415454864502
Validation loss: 2.3093054550950245

Epoch: 6| Step: 7
Training loss: 2.4419145584106445
Validation loss: 2.312006542759557

Epoch: 6| Step: 8
Training loss: 2.7819886207580566
Validation loss: 2.312641623199627

Epoch: 6| Step: 9
Training loss: 1.9776501655578613
Validation loss: 2.3507928694448164

Epoch: 6| Step: 10
Training loss: 2.59905743598938
Validation loss: 2.337415643917617

Epoch: 6| Step: 11
Training loss: 2.615083932876587
Validation loss: 2.3267716361630346

Epoch: 6| Step: 12
Training loss: 2.6983625888824463
Validation loss: 2.304745756169801

Epoch: 6| Step: 13
Training loss: 2.0506153106689453
Validation loss: 2.292558120143029

Epoch: 148| Step: 0
Training loss: 2.4777307510375977
Validation loss: 2.309863372515607

Epoch: 6| Step: 1
Training loss: 2.0788068771362305
Validation loss: 2.3382501935446136

Epoch: 6| Step: 2
Training loss: 2.7069108486175537
Validation loss: 2.374375440741098

Epoch: 6| Step: 3
Training loss: 2.7309327125549316
Validation loss: 2.3664534912314465

Epoch: 6| Step: 4
Training loss: 2.1065421104431152
Validation loss: 2.3433825046785417

Epoch: 6| Step: 5
Training loss: 2.451429605484009
Validation loss: 2.307705069100985

Epoch: 6| Step: 6
Training loss: 2.098301649093628
Validation loss: 2.2674572698531614

Epoch: 6| Step: 7
Training loss: 3.3014283180236816
Validation loss: 2.251606379785845

Epoch: 6| Step: 8
Training loss: 2.6023077964782715
Validation loss: 2.248013914272349

Epoch: 6| Step: 9
Training loss: 2.2897610664367676
Validation loss: 2.2447295957996

Epoch: 6| Step: 10
Training loss: 2.8561179637908936
Validation loss: 2.249149303282461

Epoch: 6| Step: 11
Training loss: 2.9204530715942383
Validation loss: 2.25191605219277

Epoch: 6| Step: 12
Training loss: 2.58413028717041
Validation loss: 2.259027668224868

Epoch: 6| Step: 13
Training loss: 2.1187384128570557
Validation loss: 2.265545129776001

Epoch: 149| Step: 0
Training loss: 2.310393810272217
Validation loss: 2.263250643207181

Epoch: 6| Step: 1
Training loss: 1.987714409828186
Validation loss: 2.2783705598564556

Epoch: 6| Step: 2
Training loss: 3.0578489303588867
Validation loss: 2.2712012337100123

Epoch: 6| Step: 3
Training loss: 3.128236770629883
Validation loss: 2.260574328002109

Epoch: 6| Step: 4
Training loss: 2.8051609992980957
Validation loss: 2.2670193461961645

Epoch: 6| Step: 5
Training loss: 1.6502759456634521
Validation loss: 2.262741375994939

Epoch: 6| Step: 6
Training loss: 2.7181286811828613
Validation loss: 2.259780351833631

Epoch: 6| Step: 7
Training loss: 2.9739773273468018
Validation loss: 2.271733125050863

Epoch: 6| Step: 8
Training loss: 3.0456764698028564
Validation loss: 2.2731944514859106

Epoch: 6| Step: 9
Training loss: 2.5480315685272217
Validation loss: 2.273883875980172

Epoch: 6| Step: 10
Training loss: 2.0380256175994873
Validation loss: 2.271806477218546

Epoch: 6| Step: 11
Training loss: 2.3956217765808105
Validation loss: 2.283381435178941

Epoch: 6| Step: 12
Training loss: 2.3662214279174805
Validation loss: 2.2805136685730307

Epoch: 6| Step: 13
Training loss: 2.2298707962036133
Validation loss: 2.285647146163448

Epoch: 150| Step: 0
Training loss: 2.1942381858825684
Validation loss: 2.287557089200584

Epoch: 6| Step: 1
Training loss: 2.544698715209961
Validation loss: 2.2819904358156267

Epoch: 6| Step: 2
Training loss: 2.561628818511963
Validation loss: 2.291255876582156

Epoch: 6| Step: 3
Training loss: 1.9851746559143066
Validation loss: 2.2868795266715427

Epoch: 6| Step: 4
Training loss: 2.3858819007873535
Validation loss: 2.2788068376561648

Epoch: 6| Step: 5
Training loss: 2.773284912109375
Validation loss: 2.2884209899492163

Epoch: 6| Step: 6
Training loss: 2.8458011150360107
Validation loss: 2.2878696841578328

Epoch: 6| Step: 7
Training loss: 2.7207329273223877
Validation loss: 2.2852080893772904

Epoch: 6| Step: 8
Training loss: 2.46246337890625
Validation loss: 2.291080326162359

Epoch: 6| Step: 9
Training loss: 2.4965901374816895
Validation loss: 2.28377478994349

Epoch: 6| Step: 10
Training loss: 2.711512804031372
Validation loss: 2.2922331261378464

Epoch: 6| Step: 11
Training loss: 2.302858352661133
Validation loss: 2.2882171420640844

Epoch: 6| Step: 12
Training loss: 1.914860725402832
Validation loss: 2.3100290349734727

Epoch: 6| Step: 13
Training loss: 3.679509162902832
Validation loss: 2.313031801613428

Epoch: 151| Step: 0
Training loss: 2.2594428062438965
Validation loss: 2.3123371601104736

Epoch: 6| Step: 1
Training loss: 2.997720718383789
Validation loss: 2.316674822120256

Epoch: 6| Step: 2
Training loss: 2.4247121810913086
Validation loss: 2.3242279227061937

Epoch: 6| Step: 3
Training loss: 2.3507137298583984
Validation loss: 2.3093117616509877

Epoch: 6| Step: 4
Training loss: 2.4478230476379395
Validation loss: 2.3007501120208413

Epoch: 6| Step: 5
Training loss: 2.045095205307007
Validation loss: 2.2920005347139094

Epoch: 6| Step: 6
Training loss: 3.2741270065307617
Validation loss: 2.2868087830082064

Epoch: 6| Step: 7
Training loss: 2.549143075942993
Validation loss: 2.27690169888158

Epoch: 6| Step: 8
Training loss: 2.3102498054504395
Validation loss: 2.272413505020962

Epoch: 6| Step: 9
Training loss: 2.658720016479492
Validation loss: 2.2662037918644566

Epoch: 6| Step: 10
Training loss: 1.6881048679351807
Validation loss: 2.2727545384437806

Epoch: 6| Step: 11
Training loss: 2.9160242080688477
Validation loss: 2.271582277872229

Epoch: 6| Step: 12
Training loss: 2.4128570556640625
Validation loss: 2.269928193861438

Epoch: 6| Step: 13
Training loss: 2.7447400093078613
Validation loss: 2.2779938021013812

Epoch: 152| Step: 0
Training loss: 2.5803890228271484
Validation loss: 2.2865359090989634

Epoch: 6| Step: 1
Training loss: 2.992142915725708
Validation loss: 2.27126556827176

Epoch: 6| Step: 2
Training loss: 2.373253107070923
Validation loss: 2.2734914748899397

Epoch: 6| Step: 3
Training loss: 3.1888656616210938
Validation loss: 2.279898323038573

Epoch: 6| Step: 4
Training loss: 2.601670026779175
Validation loss: 2.2856037129638014

Epoch: 6| Step: 5
Training loss: 2.1288411617279053
Validation loss: 2.294302052067172

Epoch: 6| Step: 6
Training loss: 2.5574941635131836
Validation loss: 2.2901552210571947

Epoch: 6| Step: 7
Training loss: 2.3979477882385254
Validation loss: 2.283849964859665

Epoch: 6| Step: 8
Training loss: 1.8016042709350586
Validation loss: 2.2998606107568227

Epoch: 6| Step: 9
Training loss: 3.053325891494751
Validation loss: 2.296645172180668

Epoch: 6| Step: 10
Training loss: 2.469968318939209
Validation loss: 2.2990730475353938

Epoch: 6| Step: 11
Training loss: 2.182781457901001
Validation loss: 2.3110948172948693

Epoch: 6| Step: 12
Training loss: 2.284475803375244
Validation loss: 2.320251129006827

Epoch: 6| Step: 13
Training loss: 2.0371077060699463
Validation loss: 2.3410337355829056

Epoch: 153| Step: 0
Training loss: 2.122246742248535
Validation loss: 2.3550411219237954

Epoch: 6| Step: 1
Training loss: 2.479576349258423
Validation loss: 2.317403019115489

Epoch: 6| Step: 2
Training loss: 3.24350643157959
Validation loss: 2.3042316667495237

Epoch: 6| Step: 3
Training loss: 1.6484837532043457
Validation loss: 2.2803006941272366

Epoch: 6| Step: 4
Training loss: 2.9890871047973633
Validation loss: 2.2773612596655406

Epoch: 6| Step: 5
Training loss: 1.8830900192260742
Validation loss: 2.276595610444264

Epoch: 6| Step: 6
Training loss: 2.3183655738830566
Validation loss: 2.2838374440388014

Epoch: 6| Step: 7
Training loss: 2.3964900970458984
Validation loss: 2.281479604782597

Epoch: 6| Step: 8
Training loss: 2.3190908432006836
Validation loss: 2.275134409627607

Epoch: 6| Step: 9
Training loss: 2.4885683059692383
Validation loss: 2.2713760919468378

Epoch: 6| Step: 10
Training loss: 3.3819565773010254
Validation loss: 2.2597627101405973

Epoch: 6| Step: 11
Training loss: 2.9473323822021484
Validation loss: 2.267191833065402

Epoch: 6| Step: 12
Training loss: 2.37484073638916
Validation loss: 2.2632054487864175

Epoch: 6| Step: 13
Training loss: 2.3942651748657227
Validation loss: 2.2616862379094607

Epoch: 154| Step: 0
Training loss: 1.9701764583587646
Validation loss: 2.2615360060045795

Epoch: 6| Step: 1
Training loss: 2.520796298980713
Validation loss: 2.2607346888511413

Epoch: 6| Step: 2
Training loss: 2.712462902069092
Validation loss: 2.2653901974360147

Epoch: 6| Step: 3
Training loss: 2.275111198425293
Validation loss: 2.2685128488848285

Epoch: 6| Step: 4
Training loss: 2.8406548500061035
Validation loss: 2.2771559684507308

Epoch: 6| Step: 5
Training loss: 2.3697898387908936
Validation loss: 2.2657689368853005

Epoch: 6| Step: 6
Training loss: 2.686502695083618
Validation loss: 2.265943104220975

Epoch: 6| Step: 7
Training loss: 1.8421531915664673
Validation loss: 2.271767662417504

Epoch: 6| Step: 8
Training loss: 3.022523880004883
Validation loss: 2.268349116848361

Epoch: 6| Step: 9
Training loss: 2.267002582550049
Validation loss: 2.2795990320944015

Epoch: 6| Step: 10
Training loss: 2.496152877807617
Validation loss: 2.2878440990242908

Epoch: 6| Step: 11
Training loss: 2.3149709701538086
Validation loss: 2.290530497027982

Epoch: 6| Step: 12
Training loss: 2.8674941062927246
Validation loss: 2.3085183969108005

Epoch: 6| Step: 13
Training loss: 2.835767984390259
Validation loss: 2.304153767965173

Epoch: 155| Step: 0
Training loss: 2.4888174533843994
Validation loss: 2.3114859955285185

Epoch: 6| Step: 1
Training loss: 3.1621155738830566
Validation loss: 2.3154152439486597

Epoch: 6| Step: 2
Training loss: 1.9727728366851807
Validation loss: 2.3018093057858047

Epoch: 6| Step: 3
Training loss: 2.2291319370269775
Validation loss: 2.300293631451104

Epoch: 6| Step: 4
Training loss: 2.795254945755005
Validation loss: 2.298262006493025

Epoch: 6| Step: 5
Training loss: 1.7558577060699463
Validation loss: 2.2995262222905315

Epoch: 6| Step: 6
Training loss: 2.908785343170166
Validation loss: 2.2988195650039183

Epoch: 6| Step: 7
Training loss: 2.2880923748016357
Validation loss: 2.30085305629238

Epoch: 6| Step: 8
Training loss: 2.1787123680114746
Validation loss: 2.3047216938387964

Epoch: 6| Step: 9
Training loss: 2.290804386138916
Validation loss: 2.2919936692842873

Epoch: 6| Step: 10
Training loss: 2.6622776985168457
Validation loss: 2.2868773834679716

Epoch: 6| Step: 11
Training loss: 2.6901304721832275
Validation loss: 2.275327072348646

Epoch: 6| Step: 12
Training loss: 2.7492482662200928
Validation loss: 2.271581131924865

Epoch: 6| Step: 13
Training loss: 2.67172908782959
Validation loss: 2.2648214088973178

Epoch: 156| Step: 0
Training loss: 2.4837746620178223
Validation loss: 2.25647904539621

Epoch: 6| Step: 1
Training loss: 2.3131113052368164
Validation loss: 2.2581038654491468

Epoch: 6| Step: 2
Training loss: 3.254002332687378
Validation loss: 2.2579108976548716

Epoch: 6| Step: 3
Training loss: 2.7253427505493164
Validation loss: 2.2635150442841234

Epoch: 6| Step: 4
Training loss: 2.2322661876678467
Validation loss: 2.281960528383973

Epoch: 6| Step: 5
Training loss: 1.6442420482635498
Validation loss: 2.3151562188261297

Epoch: 6| Step: 6
Training loss: 2.9374332427978516
Validation loss: 2.3233484580952632

Epoch: 6| Step: 7
Training loss: 2.495987892150879
Validation loss: 2.32083446492431

Epoch: 6| Step: 8
Training loss: 2.820138454437256
Validation loss: 2.290418658205258

Epoch: 6| Step: 9
Training loss: 2.6516616344451904
Validation loss: 2.284794069105579

Epoch: 6| Step: 10
Training loss: 1.8541418313980103
Validation loss: 2.2756807317015944

Epoch: 6| Step: 11
Training loss: 2.3667736053466797
Validation loss: 2.263366723573336

Epoch: 6| Step: 12
Training loss: 2.492382764816284
Validation loss: 2.2635305940463977

Epoch: 6| Step: 13
Training loss: 2.6988303661346436
Validation loss: 2.2717508346803728

Epoch: 157| Step: 0
Training loss: 1.8093901872634888
Validation loss: 2.2776037775060183

Epoch: 6| Step: 1
Training loss: 3.228775978088379
Validation loss: 2.3004549293107885

Epoch: 6| Step: 2
Training loss: 3.4030566215515137
Validation loss: 2.305353182618336

Epoch: 6| Step: 3
Training loss: 2.97687029838562
Validation loss: 2.298739428161293

Epoch: 6| Step: 4
Training loss: 2.9250173568725586
Validation loss: 2.2818749617504817

Epoch: 6| Step: 5
Training loss: 2.1679298877716064
Validation loss: 2.277668035158547

Epoch: 6| Step: 6
Training loss: 2.248170852661133
Validation loss: 2.2781900590465916

Epoch: 6| Step: 7
Training loss: 2.568368911743164
Validation loss: 2.2751976418238815

Epoch: 6| Step: 8
Training loss: 2.64418363571167
Validation loss: 2.279896154198595

Epoch: 6| Step: 9
Training loss: 2.224254846572876
Validation loss: 2.2809916234785512

Epoch: 6| Step: 10
Training loss: 1.401106834411621
Validation loss: 2.259828803359821

Epoch: 6| Step: 11
Training loss: 2.0975286960601807
Validation loss: 2.2650718035236483

Epoch: 6| Step: 12
Training loss: 2.7106752395629883
Validation loss: 2.2528865516826673

Epoch: 6| Step: 13
Training loss: 2.892717123031616
Validation loss: 2.2627230280189106

Epoch: 158| Step: 0
Training loss: 2.111279010772705
Validation loss: 2.2544468141371206

Epoch: 6| Step: 1
Training loss: 2.6345677375793457
Validation loss: 2.253297359712662

Epoch: 6| Step: 2
Training loss: 2.7008094787597656
Validation loss: 2.2500610813017814

Epoch: 6| Step: 3
Training loss: 3.092296600341797
Validation loss: 2.2363269803344563

Epoch: 6| Step: 4
Training loss: 2.25266432762146
Validation loss: 2.255560851866199

Epoch: 6| Step: 5
Training loss: 3.0970754623413086
Validation loss: 2.2498904376901607

Epoch: 6| Step: 6
Training loss: 1.8608167171478271
Validation loss: 2.240729396061231

Epoch: 6| Step: 7
Training loss: 1.9948617219924927
Validation loss: 2.260115385055542

Epoch: 6| Step: 8
Training loss: 1.9050097465515137
Validation loss: 2.2589159550205355

Epoch: 6| Step: 9
Training loss: 2.4718058109283447
Validation loss: 2.2600553445918585

Epoch: 6| Step: 10
Training loss: 2.7778148651123047
Validation loss: 2.2721748813506095

Epoch: 6| Step: 11
Training loss: 2.8943464756011963
Validation loss: 2.2732777903156896

Epoch: 6| Step: 12
Training loss: 2.529247760772705
Validation loss: 2.2807763494471067

Epoch: 6| Step: 13
Training loss: 2.405986785888672
Validation loss: 2.284802172773628

Epoch: 159| Step: 0
Training loss: 2.7891287803649902
Validation loss: 2.267735546635043

Epoch: 6| Step: 1
Training loss: 2.472214698791504
Validation loss: 2.283711720538396

Epoch: 6| Step: 2
Training loss: 2.331648111343384
Validation loss: 2.2654217699522614

Epoch: 6| Step: 3
Training loss: 2.7801218032836914
Validation loss: 2.259881575902303

Epoch: 6| Step: 4
Training loss: 2.288910388946533
Validation loss: 2.2542737773669663

Epoch: 6| Step: 5
Training loss: 1.9291527271270752
Validation loss: 2.2561310465617845

Epoch: 6| Step: 6
Training loss: 2.5026135444641113
Validation loss: 2.247545248718672

Epoch: 6| Step: 7
Training loss: 1.98167085647583
Validation loss: 2.242967462026945

Epoch: 6| Step: 8
Training loss: 2.8496549129486084
Validation loss: 2.2460539289700088

Epoch: 6| Step: 9
Training loss: 2.5408101081848145
Validation loss: 2.2511270558962257

Epoch: 6| Step: 10
Training loss: 3.371093511581421
Validation loss: 2.2530571440214753

Epoch: 6| Step: 11
Training loss: 2.6439671516418457
Validation loss: 2.2569555210810837

Epoch: 6| Step: 12
Training loss: 1.7941162586212158
Validation loss: 2.2631013111401628

Epoch: 6| Step: 13
Training loss: 2.026402711868286
Validation loss: 2.254497646003641

Epoch: 160| Step: 0
Training loss: 2.2381751537323
Validation loss: 2.2548636005770777

Epoch: 6| Step: 1
Training loss: 2.608882427215576
Validation loss: 2.2535391904974498

Epoch: 6| Step: 2
Training loss: 2.579326868057251
Validation loss: 2.257123183178645

Epoch: 6| Step: 3
Training loss: 3.156782627105713
Validation loss: 2.263435968788721

Epoch: 6| Step: 4
Training loss: 1.7300188541412354
Validation loss: 2.263999887692031

Epoch: 6| Step: 5
Training loss: 3.1302313804626465
Validation loss: 2.27649865611907

Epoch: 6| Step: 6
Training loss: 2.17144775390625
Validation loss: 2.2947446479592273

Epoch: 6| Step: 7
Training loss: 1.9352607727050781
Validation loss: 2.2970054739265033

Epoch: 6| Step: 8
Training loss: 2.048074245452881
Validation loss: 2.3033461083648024

Epoch: 6| Step: 9
Training loss: 2.1503677368164062
Validation loss: 2.2946488165086314

Epoch: 6| Step: 10
Training loss: 2.7161245346069336
Validation loss: 2.2916742088974162

Epoch: 6| Step: 11
Training loss: 3.11373233795166
Validation loss: 2.2740522097515803

Epoch: 6| Step: 12
Training loss: 2.6962344646453857
Validation loss: 2.2539967875326834

Epoch: 6| Step: 13
Training loss: 2.0412468910217285
Validation loss: 2.2497608277105514

Epoch: 161| Step: 0
Training loss: 2.9020724296569824
Validation loss: 2.256129874978014

Epoch: 6| Step: 1
Training loss: 2.71420955657959
Validation loss: 2.2642704979065926

Epoch: 6| Step: 2
Training loss: 1.9711906909942627
Validation loss: 2.251850164064797

Epoch: 6| Step: 3
Training loss: 2.21701979637146
Validation loss: 2.261848008760842

Epoch: 6| Step: 4
Training loss: 2.475125312805176
Validation loss: 2.258791273640048

Epoch: 6| Step: 5
Training loss: 1.8054660558700562
Validation loss: 2.2615753348155687

Epoch: 6| Step: 6
Training loss: 2.099210739135742
Validation loss: 2.2545822743446595

Epoch: 6| Step: 7
Training loss: 2.847564697265625
Validation loss: 2.2592011215866252

Epoch: 6| Step: 8
Training loss: 2.166438102722168
Validation loss: 2.2601989994766893

Epoch: 6| Step: 9
Training loss: 2.3858046531677246
Validation loss: 2.2560140420031805

Epoch: 6| Step: 10
Training loss: 2.973914623260498
Validation loss: 2.265207939250495

Epoch: 6| Step: 11
Training loss: 2.848116397857666
Validation loss: 2.296886190291374

Epoch: 6| Step: 12
Training loss: 2.472693681716919
Validation loss: 2.3086802908169326

Epoch: 6| Step: 13
Training loss: 2.6514711380004883
Validation loss: 2.2884569950001215

Epoch: 162| Step: 0
Training loss: 2.8093178272247314
Validation loss: 2.302096936010545

Epoch: 6| Step: 1
Training loss: 2.770282030105591
Validation loss: 2.3002107015220066

Epoch: 6| Step: 2
Training loss: 2.546252727508545
Validation loss: 2.3077984138201644

Epoch: 6| Step: 3
Training loss: 2.378556728363037
Validation loss: 2.269697217531102

Epoch: 6| Step: 4
Training loss: 3.371567726135254
Validation loss: 2.266254122539233

Epoch: 6| Step: 5
Training loss: 2.388704538345337
Validation loss: 2.258622287422098

Epoch: 6| Step: 6
Training loss: 2.2691328525543213
Validation loss: 2.2455214262008667

Epoch: 6| Step: 7
Training loss: 2.462754964828491
Validation loss: 2.2444881726336736

Epoch: 6| Step: 8
Training loss: 1.7880375385284424
Validation loss: 2.2646120850757887

Epoch: 6| Step: 9
Training loss: 2.820777654647827
Validation loss: 2.265940338052729

Epoch: 6| Step: 10
Training loss: 2.9425323009490967
Validation loss: 2.2585614060842865

Epoch: 6| Step: 11
Training loss: 1.556997537612915
Validation loss: 2.2499431333234234

Epoch: 6| Step: 12
Training loss: 2.4742703437805176
Validation loss: 2.241296555406304

Epoch: 6| Step: 13
Training loss: 1.66629159450531
Validation loss: 2.2407733368617233

Epoch: 163| Step: 0
Training loss: 2.7812135219573975
Validation loss: 2.243507863372885

Epoch: 6| Step: 1
Training loss: 1.9648733139038086
Validation loss: 2.2419310051907777

Epoch: 6| Step: 2
Training loss: 1.4816209077835083
Validation loss: 2.261356512705485

Epoch: 6| Step: 3
Training loss: 2.357154369354248
Validation loss: 2.2774475236092844

Epoch: 6| Step: 4
Training loss: 2.819986343383789
Validation loss: 2.2845699684594267

Epoch: 6| Step: 5
Training loss: 2.9345052242279053
Validation loss: 2.276880464246196

Epoch: 6| Step: 6
Training loss: 2.2268264293670654
Validation loss: 2.271868259676041

Epoch: 6| Step: 7
Training loss: 1.8284639120101929
Validation loss: 2.256267291243358

Epoch: 6| Step: 8
Training loss: 2.698014974594116
Validation loss: 2.246303173803514

Epoch: 6| Step: 9
Training loss: 2.4726836681365967
Validation loss: 2.238031801357064

Epoch: 6| Step: 10
Training loss: 2.894387722015381
Validation loss: 2.2479864807539087

Epoch: 6| Step: 11
Training loss: 3.114475727081299
Validation loss: 2.2431870698928833

Epoch: 6| Step: 12
Training loss: 2.5642480850219727
Validation loss: 2.2510379027294856

Epoch: 6| Step: 13
Training loss: 2.5937318801879883
Validation loss: 2.2520831951531033

Epoch: 164| Step: 0
Training loss: 1.6447818279266357
Validation loss: 2.251575444334297

Epoch: 6| Step: 1
Training loss: 2.693047285079956
Validation loss: 2.2602801630573888

Epoch: 6| Step: 2
Training loss: 2.085662364959717
Validation loss: 2.25092319262925

Epoch: 6| Step: 3
Training loss: 2.4591479301452637
Validation loss: 2.2594241660128356

Epoch: 6| Step: 4
Training loss: 2.6345088481903076
Validation loss: 2.2497621979764713

Epoch: 6| Step: 5
Training loss: 2.0663392543792725
Validation loss: 2.2495886946237214

Epoch: 6| Step: 6
Training loss: 2.704261302947998
Validation loss: 2.2512253766418784

Epoch: 6| Step: 7
Training loss: 2.7537992000579834
Validation loss: 2.248074767410114

Epoch: 6| Step: 8
Training loss: 2.880235433578491
Validation loss: 2.257257312856695

Epoch: 6| Step: 9
Training loss: 2.6229500770568848
Validation loss: 2.2675578209661666

Epoch: 6| Step: 10
Training loss: 2.4567508697509766
Validation loss: 2.258133260152673

Epoch: 6| Step: 11
Training loss: 2.7042107582092285
Validation loss: 2.2759242391073577

Epoch: 6| Step: 12
Training loss: 2.686640739440918
Validation loss: 2.2672760973694506

Epoch: 6| Step: 13
Training loss: 2.083085775375366
Validation loss: 2.2874284303316506

Epoch: 165| Step: 0
Training loss: 2.4436018466949463
Validation loss: 2.263519897255846

Epoch: 6| Step: 1
Training loss: 2.795630931854248
Validation loss: 2.2732341725339174

Epoch: 6| Step: 2
Training loss: 2.4620866775512695
Validation loss: 2.2794046440432147

Epoch: 6| Step: 3
Training loss: 2.3241281509399414
Validation loss: 2.299519899070904

Epoch: 6| Step: 4
Training loss: 2.917855978012085
Validation loss: 2.2861659706279798

Epoch: 6| Step: 5
Training loss: 1.7988735437393188
Validation loss: 2.2991638311775784

Epoch: 6| Step: 6
Training loss: 2.271049976348877
Validation loss: 2.292663016626912

Epoch: 6| Step: 7
Training loss: 2.381899118423462
Validation loss: 2.2740918500449068

Epoch: 6| Step: 8
Training loss: 2.9896373748779297
Validation loss: 2.257879513566212

Epoch: 6| Step: 9
Training loss: 3.204615592956543
Validation loss: 2.2618392616189937

Epoch: 6| Step: 10
Training loss: 2.2099814414978027
Validation loss: 2.2459777965340564

Epoch: 6| Step: 11
Training loss: 2.3916003704071045
Validation loss: 2.24569760599444

Epoch: 6| Step: 12
Training loss: 1.6562470197677612
Validation loss: 2.243390264049653

Epoch: 6| Step: 13
Training loss: 2.5383996963500977
Validation loss: 2.262709732978575

Epoch: 166| Step: 0
Training loss: 2.016296863555908
Validation loss: 2.2682717871922318

Epoch: 6| Step: 1
Training loss: 2.7990193367004395
Validation loss: 2.2811918950849965

Epoch: 6| Step: 2
Training loss: 2.637829065322876
Validation loss: 2.2878240180271927

Epoch: 6| Step: 3
Training loss: 2.902127265930176
Validation loss: 2.2621675281114477

Epoch: 6| Step: 4
Training loss: 2.3724827766418457
Validation loss: 2.2501603762308755

Epoch: 6| Step: 5
Training loss: 2.515918731689453
Validation loss: 2.2496796897662583

Epoch: 6| Step: 6
Training loss: 2.5849316120147705
Validation loss: 2.2478437398069646

Epoch: 6| Step: 7
Training loss: 1.8973639011383057
Validation loss: 2.252276523138887

Epoch: 6| Step: 8
Training loss: 3.0648677349090576
Validation loss: 2.2604663654040267

Epoch: 6| Step: 9
Training loss: 3.1038997173309326
Validation loss: 2.2648779243551274

Epoch: 6| Step: 10
Training loss: 2.2339744567871094
Validation loss: 2.2618668002467

Epoch: 6| Step: 11
Training loss: 1.96864652633667
Validation loss: 2.259686057285596

Epoch: 6| Step: 12
Training loss: 2.0967650413513184
Validation loss: 2.259219076043816

Epoch: 6| Step: 13
Training loss: 2.349571943283081
Validation loss: 2.243098961409702

Epoch: 167| Step: 0
Training loss: 2.243661642074585
Validation loss: 2.2345802066146687

Epoch: 6| Step: 1
Training loss: 2.0994582176208496
Validation loss: 2.2402981942699802

Epoch: 6| Step: 2
Training loss: 2.2424373626708984
Validation loss: 2.238081411648822

Epoch: 6| Step: 3
Training loss: 3.4503302574157715
Validation loss: 2.2620488597500708

Epoch: 6| Step: 4
Training loss: 2.239473581314087
Validation loss: 2.2621524513408704

Epoch: 6| Step: 5
Training loss: 2.3827462196350098
Validation loss: 2.2567217760188605

Epoch: 6| Step: 6
Training loss: 2.2735037803649902
Validation loss: 2.2560833525914017

Epoch: 6| Step: 7
Training loss: 1.31343674659729
Validation loss: 2.2450796045282835

Epoch: 6| Step: 8
Training loss: 2.613095283508301
Validation loss: 2.2381587182321856

Epoch: 6| Step: 9
Training loss: 2.436936140060425
Validation loss: 2.2415471692239084

Epoch: 6| Step: 10
Training loss: 2.825197219848633
Validation loss: 2.2432511955179195

Epoch: 6| Step: 11
Training loss: 2.451775550842285
Validation loss: 2.2416956399076726

Epoch: 6| Step: 12
Training loss: 2.9917314052581787
Validation loss: 2.231539403238604

Epoch: 6| Step: 13
Training loss: 2.9268956184387207
Validation loss: 2.23648117690958

Epoch: 168| Step: 0
Training loss: 1.9585700035095215
Validation loss: 2.232047506557998

Epoch: 6| Step: 1
Training loss: 2.2022769451141357
Validation loss: 2.233926216761271

Epoch: 6| Step: 2
Training loss: 2.5309576988220215
Validation loss: 2.238496808595555

Epoch: 6| Step: 3
Training loss: 2.5936155319213867
Validation loss: 2.2340267883834017

Epoch: 6| Step: 4
Training loss: 2.344165325164795
Validation loss: 2.2274768583236204

Epoch: 6| Step: 5
Training loss: 2.0582451820373535
Validation loss: 2.231329946107762

Epoch: 6| Step: 6
Training loss: 2.549734115600586
Validation loss: 2.2295038853922198

Epoch: 6| Step: 7
Training loss: 2.7816967964172363
Validation loss: 2.2293604650805072

Epoch: 6| Step: 8
Training loss: 2.127833366394043
Validation loss: 2.2419572748163694

Epoch: 6| Step: 9
Training loss: 3.480011463165283
Validation loss: 2.2335705398231425

Epoch: 6| Step: 10
Training loss: 2.7269301414489746
Validation loss: 2.249617802199497

Epoch: 6| Step: 11
Training loss: 1.5155458450317383
Validation loss: 2.249129678613396

Epoch: 6| Step: 12
Training loss: 2.2008209228515625
Validation loss: 2.273349359471311

Epoch: 6| Step: 13
Training loss: 3.2495641708374023
Validation loss: 2.278496326938752

Epoch: 169| Step: 0
Training loss: 3.0478529930114746
Validation loss: 2.2912801875863025

Epoch: 6| Step: 1
Training loss: 3.1494832038879395
Validation loss: 2.2729321269578833

Epoch: 6| Step: 2
Training loss: 2.3483943939208984
Validation loss: 2.266549023248816

Epoch: 6| Step: 3
Training loss: 2.236569404602051
Validation loss: 2.265483235800138

Epoch: 6| Step: 4
Training loss: 2.902576446533203
Validation loss: 2.2667822120010213

Epoch: 6| Step: 5
Training loss: 2.201862096786499
Validation loss: 2.265910658785092

Epoch: 6| Step: 6
Training loss: 1.982492208480835
Validation loss: 2.271468949574296

Epoch: 6| Step: 7
Training loss: 2.208235025405884
Validation loss: 2.2730688292493104

Epoch: 6| Step: 8
Training loss: 2.474998950958252
Validation loss: 2.265887624473982

Epoch: 6| Step: 9
Training loss: 2.3452932834625244
Validation loss: 2.2724366572595414

Epoch: 6| Step: 10
Training loss: 2.6791930198669434
Validation loss: 2.2753192532447075

Epoch: 6| Step: 11
Training loss: 2.422852039337158
Validation loss: 2.2676409982865855

Epoch: 6| Step: 12
Training loss: 2.310389995574951
Validation loss: 2.3042025489191853

Epoch: 6| Step: 13
Training loss: 1.213551640510559
Validation loss: 2.327721413745675

Epoch: 170| Step: 0
Training loss: 2.7925758361816406
Validation loss: 2.3354989123600784

Epoch: 6| Step: 1
Training loss: 2.4051015377044678
Validation loss: 2.3217767771854194

Epoch: 6| Step: 2
Training loss: 1.7880713939666748
Validation loss: 2.3300789376740814

Epoch: 6| Step: 3
Training loss: 1.4119150638580322
Validation loss: 2.325593602272772

Epoch: 6| Step: 4
Training loss: 2.991342067718506
Validation loss: 2.3331100735613095

Epoch: 6| Step: 5
Training loss: 3.311537742614746
Validation loss: 2.335498509868499

Epoch: 6| Step: 6
Training loss: 2.8492486476898193
Validation loss: 2.3366432907760784

Epoch: 6| Step: 7
Training loss: 2.315746307373047
Validation loss: 2.2959761696477092

Epoch: 6| Step: 8
Training loss: 2.033130168914795
Validation loss: 2.284775910838958

Epoch: 6| Step: 9
Training loss: 2.1839170455932617
Validation loss: 2.273762459396034

Epoch: 6| Step: 10
Training loss: 1.8697118759155273
Validation loss: 2.2637569468508483

Epoch: 6| Step: 11
Training loss: 3.0872669219970703
Validation loss: 2.291369563789778

Epoch: 6| Step: 12
Training loss: 2.966662645339966
Validation loss: 2.2817080687451106

Epoch: 6| Step: 13
Training loss: 2.413966178894043
Validation loss: 2.2673506711118963

Epoch: 171| Step: 0
Training loss: 1.5629910230636597
Validation loss: 2.2502574459198983

Epoch: 6| Step: 1
Training loss: 2.970076084136963
Validation loss: 2.231188076798634

Epoch: 6| Step: 2
Training loss: 1.9762424230575562
Validation loss: 2.2263301162309546

Epoch: 6| Step: 3
Training loss: 2.5215210914611816
Validation loss: 2.217641661244054

Epoch: 6| Step: 4
Training loss: 2.3356246948242188
Validation loss: 2.2035721143086753

Epoch: 6| Step: 5
Training loss: 2.2042763233184814
Validation loss: 2.2005939278551327

Epoch: 6| Step: 6
Training loss: 2.9083030223846436
Validation loss: 2.21015138523553

Epoch: 6| Step: 7
Training loss: 2.4293928146362305
Validation loss: 2.204945710397536

Epoch: 6| Step: 8
Training loss: 2.196876049041748
Validation loss: 2.2174540847860356

Epoch: 6| Step: 9
Training loss: 2.482816219329834
Validation loss: 2.2157523093685025

Epoch: 6| Step: 10
Training loss: 2.909684658050537
Validation loss: 2.218108659149498

Epoch: 6| Step: 11
Training loss: 2.5866594314575195
Validation loss: 2.223464653056155

Epoch: 6| Step: 12
Training loss: 2.6647353172302246
Validation loss: 2.2723279255692677

Epoch: 6| Step: 13
Training loss: 2.476116418838501
Validation loss: 2.3217908028633363

Epoch: 172| Step: 0
Training loss: 3.0376029014587402
Validation loss: 2.3394131455370175

Epoch: 6| Step: 1
Training loss: 2.486635446548462
Validation loss: 2.303350915190994

Epoch: 6| Step: 2
Training loss: 2.6644794940948486
Validation loss: 2.3044068249323035

Epoch: 6| Step: 3
Training loss: 3.078503131866455
Validation loss: 2.2985986586539977

Epoch: 6| Step: 4
Training loss: 2.3943209648132324
Validation loss: 2.267577512289888

Epoch: 6| Step: 5
Training loss: 2.140713691711426
Validation loss: 2.2707474359902005

Epoch: 6| Step: 6
Training loss: 1.7979788780212402
Validation loss: 2.2554613492822133

Epoch: 6| Step: 7
Training loss: 2.2625629901885986
Validation loss: 2.2457617918650308

Epoch: 6| Step: 8
Training loss: 2.5051794052124023
Validation loss: 2.241025686264038

Epoch: 6| Step: 9
Training loss: 2.501796245574951
Validation loss: 2.265278726495722

Epoch: 6| Step: 10
Training loss: 2.5024640560150146
Validation loss: 2.296734086928829

Epoch: 6| Step: 11
Training loss: 2.079108238220215
Validation loss: 2.306081243740615

Epoch: 6| Step: 12
Training loss: 2.638075351715088
Validation loss: 2.3207712532371603

Epoch: 6| Step: 13
Training loss: 2.7409090995788574
Validation loss: 2.2778544874601465

Epoch: 173| Step: 0
Training loss: 2.751067876815796
Validation loss: 2.2688026171858593

Epoch: 6| Step: 1
Training loss: 2.9143996238708496
Validation loss: 2.2358858354630007

Epoch: 6| Step: 2
Training loss: 2.5126266479492188
Validation loss: 2.2237148105457263

Epoch: 6| Step: 3
Training loss: 2.88824200630188
Validation loss: 2.222121188717504

Epoch: 6| Step: 4
Training loss: 1.3381288051605225
Validation loss: 2.218022172169019

Epoch: 6| Step: 5
Training loss: 2.555537700653076
Validation loss: 2.2213180193337063

Epoch: 6| Step: 6
Training loss: 2.8743386268615723
Validation loss: 2.228869985508662

Epoch: 6| Step: 7
Training loss: 2.3526482582092285
Validation loss: 2.243784478915635

Epoch: 6| Step: 8
Training loss: 1.8155827522277832
Validation loss: 2.2379190460328133

Epoch: 6| Step: 9
Training loss: 2.815708637237549
Validation loss: 2.2591450598932084

Epoch: 6| Step: 10
Training loss: 1.6183040142059326
Validation loss: 2.2591733881222305

Epoch: 6| Step: 11
Training loss: 2.8045952320098877
Validation loss: 2.2660874012977845

Epoch: 6| Step: 12
Training loss: 2.5190210342407227
Validation loss: 2.2534193710614274

Epoch: 6| Step: 13
Training loss: 2.4911015033721924
Validation loss: 2.2659170473775556

Epoch: 174| Step: 0
Training loss: 1.888382077217102
Validation loss: 2.2790453574990712

Epoch: 6| Step: 1
Training loss: 2.715003490447998
Validation loss: 2.300758852753588

Epoch: 6| Step: 2
Training loss: 2.022824287414551
Validation loss: 2.314264343630883

Epoch: 6| Step: 3
Training loss: 2.6837239265441895
Validation loss: 2.2754240010374334

Epoch: 6| Step: 4
Training loss: 2.299302577972412
Validation loss: 2.262315901376868

Epoch: 6| Step: 5
Training loss: 2.8022725582122803
Validation loss: 2.2719994360400784

Epoch: 6| Step: 6
Training loss: 2.3960938453674316
Validation loss: 2.2487038745675036

Epoch: 6| Step: 7
Training loss: 2.6527862548828125
Validation loss: 2.2403325162908083

Epoch: 6| Step: 8
Training loss: 2.4470534324645996
Validation loss: 2.242462974722667

Epoch: 6| Step: 9
Training loss: 2.6498122215270996
Validation loss: 2.2236484019987044

Epoch: 6| Step: 10
Training loss: 2.565117835998535
Validation loss: 2.227344156593405

Epoch: 6| Step: 11
Training loss: 2.2899179458618164
Validation loss: 2.222622581707534

Epoch: 6| Step: 12
Training loss: 2.5172038078308105
Validation loss: 2.2136334732014644

Epoch: 6| Step: 13
Training loss: 1.645647644996643
Validation loss: 2.2089659501147527

Epoch: 175| Step: 0
Training loss: 1.9919874668121338
Validation loss: 2.2126597101970384

Epoch: 6| Step: 1
Training loss: 1.7425259351730347
Validation loss: 2.204697980675646

Epoch: 6| Step: 2
Training loss: 2.681823492050171
Validation loss: 2.2174170350515716

Epoch: 6| Step: 3
Training loss: 2.041728973388672
Validation loss: 2.2239736792861775

Epoch: 6| Step: 4
Training loss: 2.932637929916382
Validation loss: 2.220092891364969

Epoch: 6| Step: 5
Training loss: 2.5384631156921387
Validation loss: 2.219562489499328

Epoch: 6| Step: 6
Training loss: 2.281200885772705
Validation loss: 2.21862687987666

Epoch: 6| Step: 7
Training loss: 2.5034408569335938
Validation loss: 2.2016150669385026

Epoch: 6| Step: 8
Training loss: 2.445899724960327
Validation loss: 2.204851891404839

Epoch: 6| Step: 9
Training loss: 2.723327159881592
Validation loss: 2.198231553518644

Epoch: 6| Step: 10
Training loss: 2.4332187175750732
Validation loss: 2.1959470625846618

Epoch: 6| Step: 11
Training loss: 2.670862913131714
Validation loss: 2.203052000332904

Epoch: 6| Step: 12
Training loss: 2.5518598556518555
Validation loss: 2.2046367942645984

Epoch: 6| Step: 13
Training loss: 2.2324936389923096
Validation loss: 2.220081272945609

Epoch: 176| Step: 0
Training loss: 2.6462514400482178
Validation loss: 2.210928778494558

Epoch: 6| Step: 1
Training loss: 2.9551565647125244
Validation loss: 2.2099942481645973

Epoch: 6| Step: 2
Training loss: 2.513436794281006
Validation loss: 2.205034872537018

Epoch: 6| Step: 3
Training loss: 3.081533432006836
Validation loss: 2.2034889908247095

Epoch: 6| Step: 4
Training loss: 2.506253480911255
Validation loss: 2.192473829433482

Epoch: 6| Step: 5
Training loss: 1.3751873970031738
Validation loss: 2.1913610248155493

Epoch: 6| Step: 6
Training loss: 3.054955005645752
Validation loss: 2.204870334235571

Epoch: 6| Step: 7
Training loss: 2.2293882369995117
Validation loss: 2.2047232914996404

Epoch: 6| Step: 8
Training loss: 2.3228487968444824
Validation loss: 2.2184228410003004

Epoch: 6| Step: 9
Training loss: 1.884774088859558
Validation loss: 2.230586282668575

Epoch: 6| Step: 10
Training loss: 2.0786733627319336
Validation loss: 2.2541585532567834

Epoch: 6| Step: 11
Training loss: 2.446605682373047
Validation loss: 2.2545236259378414

Epoch: 6| Step: 12
Training loss: 2.584691047668457
Validation loss: 2.2662589908928

Epoch: 6| Step: 13
Training loss: 1.8075460195541382
Validation loss: 2.2636504301460842

Epoch: 177| Step: 0
Training loss: 2.9973604679107666
Validation loss: 2.261051029287359

Epoch: 6| Step: 1
Training loss: 2.5998992919921875
Validation loss: 2.254537151705834

Epoch: 6| Step: 2
Training loss: 2.7693979740142822
Validation loss: 2.2457900137029667

Epoch: 6| Step: 3
Training loss: 1.838604211807251
Validation loss: 2.2368248278094875

Epoch: 6| Step: 4
Training loss: 1.9209942817687988
Validation loss: 2.248871531537784

Epoch: 6| Step: 5
Training loss: 2.289400577545166
Validation loss: 2.2467638728439168

Epoch: 6| Step: 6
Training loss: 2.6735894680023193
Validation loss: 2.2281403913292834

Epoch: 6| Step: 7
Training loss: 2.0351152420043945
Validation loss: 2.2250362865386473

Epoch: 6| Step: 8
Training loss: 2.524970769882202
Validation loss: 2.235103935323736

Epoch: 6| Step: 9
Training loss: 2.2716078758239746
Validation loss: 2.2254559147742485

Epoch: 6| Step: 10
Training loss: 3.0949254035949707
Validation loss: 2.239201561097176

Epoch: 6| Step: 11
Training loss: 1.6897753477096558
Validation loss: 2.2179395896132275

Epoch: 6| Step: 12
Training loss: 2.585081100463867
Validation loss: 2.231277519656766

Epoch: 6| Step: 13
Training loss: 1.9105453491210938
Validation loss: 2.2197269278187908

Epoch: 178| Step: 0
Training loss: 2.214083671569824
Validation loss: 2.2192789469995806

Epoch: 6| Step: 1
Training loss: 1.8193728923797607
Validation loss: 2.2210294123618834

Epoch: 6| Step: 2
Training loss: 1.6897025108337402
Validation loss: 2.2130723089300175

Epoch: 6| Step: 3
Training loss: 2.718754768371582
Validation loss: 2.2135602889522428

Epoch: 6| Step: 4
Training loss: 2.4777188301086426
Validation loss: 2.2260209565521567

Epoch: 6| Step: 5
Training loss: 2.1032919883728027
Validation loss: 2.2406271196180776

Epoch: 6| Step: 6
Training loss: 1.868175745010376
Validation loss: 2.262927891105734

Epoch: 6| Step: 7
Training loss: 2.08604097366333
Validation loss: 2.2539805263601322

Epoch: 6| Step: 8
Training loss: 2.1393003463745117
Validation loss: 2.2625772312123287

Epoch: 6| Step: 9
Training loss: 3.5043485164642334
Validation loss: 2.2732500568512948

Epoch: 6| Step: 10
Training loss: 2.9382758140563965
Validation loss: 2.2858970395980345

Epoch: 6| Step: 11
Training loss: 2.797492504119873
Validation loss: 2.246226131275136

Epoch: 6| Step: 12
Training loss: 2.341391086578369
Validation loss: 2.233105715884957

Epoch: 6| Step: 13
Training loss: 3.251356840133667
Validation loss: 2.224868461649905

Epoch: 179| Step: 0
Training loss: 2.706096649169922
Validation loss: 2.213995287495275

Epoch: 6| Step: 1
Training loss: 2.423600912094116
Validation loss: 2.2155543655477543

Epoch: 6| Step: 2
Training loss: 1.7580716609954834
Validation loss: 2.1978652297809558

Epoch: 6| Step: 3
Training loss: 2.9990615844726562
Validation loss: 2.2175097414242324

Epoch: 6| Step: 4
Training loss: 2.132370710372925
Validation loss: 2.2252971382551294

Epoch: 6| Step: 5
Training loss: 2.7164134979248047
Validation loss: 2.250137572647423

Epoch: 6| Step: 6
Training loss: 3.021078586578369
Validation loss: 2.239383130945185

Epoch: 6| Step: 7
Training loss: 1.7669696807861328
Validation loss: 2.2229199409484863

Epoch: 6| Step: 8
Training loss: 2.5061421394348145
Validation loss: 2.1997940155767624

Epoch: 6| Step: 9
Training loss: 2.594081401824951
Validation loss: 2.193138041803914

Epoch: 6| Step: 10
Training loss: 2.605201244354248
Validation loss: 2.1916225648695424

Epoch: 6| Step: 11
Training loss: 2.246687412261963
Validation loss: 2.1857913360800794

Epoch: 6| Step: 12
Training loss: 1.9919638633728027
Validation loss: 2.173506654718871

Epoch: 6| Step: 13
Training loss: 1.9680684804916382
Validation loss: 2.1898861777397896

Epoch: 180| Step: 0
Training loss: 2.239140033721924
Validation loss: 2.1925627954544558

Epoch: 6| Step: 1
Training loss: 3.3168811798095703
Validation loss: 2.1855268504029963

Epoch: 6| Step: 2
Training loss: 2.808094024658203
Validation loss: 2.2003784512960785

Epoch: 6| Step: 3
Training loss: 2.493305206298828
Validation loss: 2.2224186184585735

Epoch: 6| Step: 4
Training loss: 2.0498690605163574
Validation loss: 2.2216327677490892

Epoch: 6| Step: 5
Training loss: 2.328059673309326
Validation loss: 2.2207371701476393

Epoch: 6| Step: 6
Training loss: 2.3265604972839355
Validation loss: 2.233761815614598

Epoch: 6| Step: 7
Training loss: 2.2664830684661865
Validation loss: 2.2403333917740853

Epoch: 6| Step: 8
Training loss: 2.714083671569824
Validation loss: 2.2202209657238376

Epoch: 6| Step: 9
Training loss: 1.8261123895645142
Validation loss: 2.2271911764657624

Epoch: 6| Step: 10
Training loss: 1.9473974704742432
Validation loss: 2.2316105724662862

Epoch: 6| Step: 11
Training loss: 2.820469856262207
Validation loss: 2.226891392020769

Epoch: 6| Step: 12
Training loss: 2.1798837184906006
Validation loss: 2.211225522461758

Epoch: 6| Step: 13
Training loss: 2.2645695209503174
Validation loss: 2.19760827608006

Epoch: 181| Step: 0
Training loss: 2.8666980266571045
Validation loss: 2.1875670443299

Epoch: 6| Step: 1
Training loss: 3.0543277263641357
Validation loss: 2.1945976852088847

Epoch: 6| Step: 2
Training loss: 2.5244812965393066
Validation loss: 2.1916102824672574

Epoch: 6| Step: 3
Training loss: 2.813162326812744
Validation loss: 2.1882650557384697

Epoch: 6| Step: 4
Training loss: 1.7468994855880737
Validation loss: 2.186055980702882

Epoch: 6| Step: 5
Training loss: 2.4064931869506836
Validation loss: 2.219385785441245

Epoch: 6| Step: 6
Training loss: 2.2816600799560547
Validation loss: 2.2311969469952326

Epoch: 6| Step: 7
Training loss: 1.4112733602523804
Validation loss: 2.235379267764348

Epoch: 6| Step: 8
Training loss: 2.0336246490478516
Validation loss: 2.233778220351024

Epoch: 6| Step: 9
Training loss: 2.2878987789154053
Validation loss: 2.2245884967106644

Epoch: 6| Step: 10
Training loss: 2.584211587905884
Validation loss: 2.241973600079936

Epoch: 6| Step: 11
Training loss: 2.822146415710449
Validation loss: 2.2320259437766126

Epoch: 6| Step: 12
Training loss: 2.4825799465179443
Validation loss: 2.226014728187233

Epoch: 6| Step: 13
Training loss: 1.7568732500076294
Validation loss: 2.224230057449751

Epoch: 182| Step: 0
Training loss: 2.9368791580200195
Validation loss: 2.222758639243341

Epoch: 6| Step: 1
Training loss: 2.3400793075561523
Validation loss: 2.2250974357769056

Epoch: 6| Step: 2
Training loss: 2.1422324180603027
Validation loss: 2.22222650179299

Epoch: 6| Step: 3
Training loss: 1.8176584243774414
Validation loss: 2.2220337903627785

Epoch: 6| Step: 4
Training loss: 2.1540818214416504
Validation loss: 2.2227162545727146

Epoch: 6| Step: 5
Training loss: 2.5072805881500244
Validation loss: 2.2284950646021033

Epoch: 6| Step: 6
Training loss: 2.478261947631836
Validation loss: 2.226126996419763

Epoch: 6| Step: 7
Training loss: 2.5149998664855957
Validation loss: 2.2313647500930296

Epoch: 6| Step: 8
Training loss: 2.1526780128479004
Validation loss: 2.2262003088510163

Epoch: 6| Step: 9
Training loss: 2.2666993141174316
Validation loss: 2.2058554246861446

Epoch: 6| Step: 10
Training loss: 2.381899356842041
Validation loss: 2.2294191378419117

Epoch: 6| Step: 11
Training loss: 2.308417320251465
Validation loss: 2.238452289694099

Epoch: 6| Step: 12
Training loss: 2.8173067569732666
Validation loss: 2.25286465819164

Epoch: 6| Step: 13
Training loss: 2.356964111328125
Validation loss: 2.2476264815176688

Epoch: 183| Step: 0
Training loss: 2.3493564128875732
Validation loss: 2.2508672129723335

Epoch: 6| Step: 1
Training loss: 2.592535972595215
Validation loss: 2.238111872826853

Epoch: 6| Step: 2
Training loss: 2.2417614459991455
Validation loss: 2.216416710166521

Epoch: 6| Step: 3
Training loss: 2.1307759284973145
Validation loss: 2.2012933056841613

Epoch: 6| Step: 4
Training loss: 2.180267095565796
Validation loss: 2.2130979491818334

Epoch: 6| Step: 5
Training loss: 2.2310681343078613
Validation loss: 2.1988332297212336

Epoch: 6| Step: 6
Training loss: 2.2298831939697266
Validation loss: 2.2034668422514394

Epoch: 6| Step: 7
Training loss: 2.864805221557617
Validation loss: 2.197819335486299

Epoch: 6| Step: 8
Training loss: 1.9903843402862549
Validation loss: 2.2075658485453618

Epoch: 6| Step: 9
Training loss: 1.989504098892212
Validation loss: 2.195625962749604

Epoch: 6| Step: 10
Training loss: 3.183656692504883
Validation loss: 2.207495140772994

Epoch: 6| Step: 11
Training loss: 2.8096444606781006
Validation loss: 2.205407954031421

Epoch: 6| Step: 12
Training loss: 2.279012680053711
Validation loss: 2.2145455780849663

Epoch: 6| Step: 13
Training loss: 2.166508913040161
Validation loss: 2.20710930773007

Epoch: 184| Step: 0
Training loss: 2.8247547149658203
Validation loss: 2.198916482669051

Epoch: 6| Step: 1
Training loss: 2.311337471008301
Validation loss: 2.2011359301946496

Epoch: 6| Step: 2
Training loss: 1.9445043802261353
Validation loss: 2.200758090583227

Epoch: 6| Step: 3
Training loss: 2.536590576171875
Validation loss: 2.2067763895116825

Epoch: 6| Step: 4
Training loss: 1.9353573322296143
Validation loss: 2.2047847868293844

Epoch: 6| Step: 5
Training loss: 2.7844743728637695
Validation loss: 2.2054849286233225

Epoch: 6| Step: 6
Training loss: 1.968458652496338
Validation loss: 2.2003484592642835

Epoch: 6| Step: 7
Training loss: 2.7884974479675293
Validation loss: 2.217277216654952

Epoch: 6| Step: 8
Training loss: 2.9508652687072754
Validation loss: 2.2103346624682025

Epoch: 6| Step: 9
Training loss: 1.5420658588409424
Validation loss: 2.2047044948865007

Epoch: 6| Step: 10
Training loss: 1.7691961526870728
Validation loss: 2.2001732318632063

Epoch: 6| Step: 11
Training loss: 2.6865875720977783
Validation loss: 2.1989084533465806

Epoch: 6| Step: 12
Training loss: 2.9852046966552734
Validation loss: 2.2158857225089945

Epoch: 6| Step: 13
Training loss: 1.959694743156433
Validation loss: 2.2208114798351

Epoch: 185| Step: 0
Training loss: 1.92604660987854
Validation loss: 2.2098435368589175

Epoch: 6| Step: 1
Training loss: 2.0077736377716064
Validation loss: 2.2018658679018737

Epoch: 6| Step: 2
Training loss: 2.396345615386963
Validation loss: 2.1983761454141266

Epoch: 6| Step: 3
Training loss: 2.8728132247924805
Validation loss: 2.2090322253524617

Epoch: 6| Step: 4
Training loss: 2.7557621002197266
Validation loss: 2.1915695410902782

Epoch: 6| Step: 5
Training loss: 2.5655622482299805
Validation loss: 2.1834749162838025

Epoch: 6| Step: 6
Training loss: 1.609038233757019
Validation loss: 2.178195963623703

Epoch: 6| Step: 7
Training loss: 2.7421374320983887
Validation loss: 2.1884114588460615

Epoch: 6| Step: 8
Training loss: 1.9527254104614258
Validation loss: 2.1910865486309095

Epoch: 6| Step: 9
Training loss: 2.833306312561035
Validation loss: 2.1786400964183192

Epoch: 6| Step: 10
Training loss: 2.5348331928253174
Validation loss: 2.189171289884916

Epoch: 6| Step: 11
Training loss: 2.130326271057129
Validation loss: 2.192980081804337

Epoch: 6| Step: 12
Training loss: 2.661147356033325
Validation loss: 2.208946419018571

Epoch: 6| Step: 13
Training loss: 1.5438148975372314
Validation loss: 2.214799993781633

Epoch: 186| Step: 0
Training loss: 2.0832266807556152
Validation loss: 2.1877692694305093

Epoch: 6| Step: 1
Training loss: 2.498319625854492
Validation loss: 2.187941651190481

Epoch: 6| Step: 2
Training loss: 2.370924711227417
Validation loss: 2.18230761507506

Epoch: 6| Step: 3
Training loss: 2.2114224433898926
Validation loss: 2.194582244401337

Epoch: 6| Step: 4
Training loss: 2.155330181121826
Validation loss: 2.1864750410920832

Epoch: 6| Step: 5
Training loss: 3.0041394233703613
Validation loss: 2.1828252038648053

Epoch: 6| Step: 6
Training loss: 2.243696689605713
Validation loss: 2.1934358022546254

Epoch: 6| Step: 7
Training loss: 2.279686450958252
Validation loss: 2.192785488661899

Epoch: 6| Step: 8
Training loss: 2.2162973880767822
Validation loss: 2.209746391542496

Epoch: 6| Step: 9
Training loss: 2.324629306793213
Validation loss: 2.228325991220372

Epoch: 6| Step: 10
Training loss: 2.5634775161743164
Validation loss: 2.205850411486882

Epoch: 6| Step: 11
Training loss: 2.554079532623291
Validation loss: 2.2214283238175097

Epoch: 6| Step: 12
Training loss: 1.967854380607605
Validation loss: 2.209679436940019

Epoch: 6| Step: 13
Training loss: 2.595823287963867
Validation loss: 2.2175392514915875

Epoch: 187| Step: 0
Training loss: 1.8800427913665771
Validation loss: 2.2077050901228383

Epoch: 6| Step: 1
Training loss: 2.6691160202026367
Validation loss: 2.2066281739101616

Epoch: 6| Step: 2
Training loss: 2.633098602294922
Validation loss: 2.2046615513422156

Epoch: 6| Step: 3
Training loss: 2.1374285221099854
Validation loss: 2.213167493061353

Epoch: 6| Step: 4
Training loss: 2.611013889312744
Validation loss: 2.229155590457301

Epoch: 6| Step: 5
Training loss: 3.458889961242676
Validation loss: 2.2226450250994776

Epoch: 6| Step: 6
Training loss: 1.9248838424682617
Validation loss: 2.2250337780162854

Epoch: 6| Step: 7
Training loss: 2.0701088905334473
Validation loss: 2.20487944797803

Epoch: 6| Step: 8
Training loss: 2.5506820678710938
Validation loss: 2.204685257327172

Epoch: 6| Step: 9
Training loss: 2.380178451538086
Validation loss: 2.187991219182168

Epoch: 6| Step: 10
Training loss: 1.6830015182495117
Validation loss: 2.2026529824861916

Epoch: 6| Step: 11
Training loss: 2.4821557998657227
Validation loss: 2.227613687515259

Epoch: 6| Step: 12
Training loss: 2.0224153995513916
Validation loss: 2.215730651732414

Epoch: 6| Step: 13
Training loss: 2.3333523273468018
Validation loss: 2.2044798046030025

Epoch: 188| Step: 0
Training loss: 1.823306918144226
Validation loss: 2.185615216532061

Epoch: 6| Step: 1
Training loss: 2.4371180534362793
Validation loss: 2.1867744640637468

Epoch: 6| Step: 2
Training loss: 2.5698599815368652
Validation loss: 2.1821009241124636

Epoch: 6| Step: 3
Training loss: 2.7510876655578613
Validation loss: 2.1914396747466056

Epoch: 6| Step: 4
Training loss: 2.1335132122039795
Validation loss: 2.2053016872816187

Epoch: 6| Step: 5
Training loss: 2.481461524963379
Validation loss: 2.207554696708597

Epoch: 6| Step: 6
Training loss: 2.4526960849761963
Validation loss: 2.22166274439904

Epoch: 6| Step: 7
Training loss: 1.481877088546753
Validation loss: 2.23656488233997

Epoch: 6| Step: 8
Training loss: 2.4249985218048096
Validation loss: 2.2302384889254006

Epoch: 6| Step: 9
Training loss: 2.554563045501709
Validation loss: 2.217450454670896

Epoch: 6| Step: 10
Training loss: 2.5817832946777344
Validation loss: 2.224030661326583

Epoch: 6| Step: 11
Training loss: 2.344456911087036
Validation loss: 2.2047454772457

Epoch: 6| Step: 12
Training loss: 2.395463466644287
Validation loss: 2.1899763153445337

Epoch: 6| Step: 13
Training loss: 2.1160664558410645
Validation loss: 2.1951972771716375

Epoch: 189| Step: 0
Training loss: 2.261645793914795
Validation loss: 2.202055723436417

Epoch: 6| Step: 1
Training loss: 2.707951068878174
Validation loss: 2.1860619437310005

Epoch: 6| Step: 2
Training loss: 2.379148244857788
Validation loss: 2.1925434143312517

Epoch: 6| Step: 3
Training loss: 1.897346019744873
Validation loss: 2.1923068543916107

Epoch: 6| Step: 4
Training loss: 3.320343017578125
Validation loss: 2.1968252940844466

Epoch: 6| Step: 5
Training loss: 2.8330469131469727
Validation loss: 2.197322068675872

Epoch: 6| Step: 6
Training loss: 1.9555375576019287
Validation loss: 2.197447338411885

Epoch: 6| Step: 7
Training loss: 1.8311123847961426
Validation loss: 2.1906513783239547

Epoch: 6| Step: 8
Training loss: 2.1085987091064453
Validation loss: 2.196119168753265

Epoch: 6| Step: 9
Training loss: 2.5299487113952637
Validation loss: 2.194377012150262

Epoch: 6| Step: 10
Training loss: 2.0802390575408936
Validation loss: 2.190844161536104

Epoch: 6| Step: 11
Training loss: 1.9337090253829956
Validation loss: 2.193351561023343

Epoch: 6| Step: 12
Training loss: 2.7180681228637695
Validation loss: 2.1878377570900867

Epoch: 6| Step: 13
Training loss: 2.481167793273926
Validation loss: 2.202818032233946

Epoch: 190| Step: 0
Training loss: 2.5019912719726562
Validation loss: 2.2138306440845614

Epoch: 6| Step: 1
Training loss: 2.457164764404297
Validation loss: 2.2204522496910504

Epoch: 6| Step: 2
Training loss: 1.824414610862732
Validation loss: 2.2251392615738737

Epoch: 6| Step: 3
Training loss: 2.237029552459717
Validation loss: 2.279268423716227

Epoch: 6| Step: 4
Training loss: 3.4333460330963135
Validation loss: 2.2947367878370386

Epoch: 6| Step: 5
Training loss: 1.9073913097381592
Validation loss: 2.2889358048797934

Epoch: 6| Step: 6
Training loss: 2.070779800415039
Validation loss: 2.2837578327425065

Epoch: 6| Step: 7
Training loss: 1.9995325803756714
Validation loss: 2.2528007902124876

Epoch: 6| Step: 8
Training loss: 1.5732667446136475
Validation loss: 2.226082378818143

Epoch: 6| Step: 9
Training loss: 2.555614948272705
Validation loss: 2.2110084000454155

Epoch: 6| Step: 10
Training loss: 3.062753200531006
Validation loss: 2.2059634911116732

Epoch: 6| Step: 11
Training loss: 3.0358047485351562
Validation loss: 2.18902321784727

Epoch: 6| Step: 12
Training loss: 1.6546497344970703
Validation loss: 2.1950916577410955

Epoch: 6| Step: 13
Training loss: 2.316311836242676
Validation loss: 2.1951018789763093

Epoch: 191| Step: 0
Training loss: 1.4575347900390625
Validation loss: 2.207445252326227

Epoch: 6| Step: 1
Training loss: 2.426900625228882
Validation loss: 2.2077050542318695

Epoch: 6| Step: 2
Training loss: 2.9496796131134033
Validation loss: 2.214383429096591

Epoch: 6| Step: 3
Training loss: 2.53745698928833
Validation loss: 2.2186241995903755

Epoch: 6| Step: 4
Training loss: 2.05503511428833
Validation loss: 2.194132625415761

Epoch: 6| Step: 5
Training loss: 2.841818332672119
Validation loss: 2.199395841167819

Epoch: 6| Step: 6
Training loss: 2.7057416439056396
Validation loss: 2.180240877213017

Epoch: 6| Step: 7
Training loss: 2.5988264083862305
Validation loss: 2.177391531646893

Epoch: 6| Step: 8
Training loss: 2.873135566711426
Validation loss: 2.1783985707067672

Epoch: 6| Step: 9
Training loss: 1.766298770904541
Validation loss: 2.176375645463185

Epoch: 6| Step: 10
Training loss: 1.6779909133911133
Validation loss: 2.1892910670208674

Epoch: 6| Step: 11
Training loss: 2.5310616493225098
Validation loss: 2.1998615803257113

Epoch: 6| Step: 12
Training loss: 2.3007750511169434
Validation loss: 2.2153584123939596

Epoch: 6| Step: 13
Training loss: 1.4834976196289062
Validation loss: 2.1923230745459117

Epoch: 192| Step: 0
Training loss: 2.455728769302368
Validation loss: 2.192827852823401

Epoch: 6| Step: 1
Training loss: 2.3347315788269043
Validation loss: 2.2069248589136268

Epoch: 6| Step: 2
Training loss: 1.8928959369659424
Validation loss: 2.2013479035387755

Epoch: 6| Step: 3
Training loss: 1.8867144584655762
Validation loss: 2.1952925228303477

Epoch: 6| Step: 4
Training loss: 2.0658416748046875
Validation loss: 2.206962823867798

Epoch: 6| Step: 5
Training loss: 2.2678945064544678
Validation loss: 2.2047861186406945

Epoch: 6| Step: 6
Training loss: 2.924189567565918
Validation loss: 2.2114615286550214

Epoch: 6| Step: 7
Training loss: 2.823674201965332
Validation loss: 2.217517611800983

Epoch: 6| Step: 8
Training loss: 2.5393354892730713
Validation loss: 2.2351111929903746

Epoch: 6| Step: 9
Training loss: 2.2906343936920166
Validation loss: 2.2457393882095174

Epoch: 6| Step: 10
Training loss: 2.230386734008789
Validation loss: 2.2454538319700506

Epoch: 6| Step: 11
Training loss: 2.398472309112549
Validation loss: 2.2584648875780005

Epoch: 6| Step: 12
Training loss: 1.6266188621520996
Validation loss: 2.2431956542435514

Epoch: 6| Step: 13
Training loss: 3.012864112854004
Validation loss: 2.2321818310727357

Epoch: 193| Step: 0
Training loss: 2.398197650909424
Validation loss: 2.208943856659756

Epoch: 6| Step: 1
Training loss: 2.5998120307922363
Validation loss: 2.1889733858005975

Epoch: 6| Step: 2
Training loss: 2.3782052993774414
Validation loss: 2.2020551568718365

Epoch: 6| Step: 3
Training loss: 2.399148941040039
Validation loss: 2.1941681062021563

Epoch: 6| Step: 4
Training loss: 1.722989797592163
Validation loss: 2.1912753043636197

Epoch: 6| Step: 5
Training loss: 2.176939010620117
Validation loss: 2.1778579758059595

Epoch: 6| Step: 6
Training loss: 2.095170021057129
Validation loss: 2.171537676165181

Epoch: 6| Step: 7
Training loss: 2.8848400115966797
Validation loss: 2.159682709683654

Epoch: 6| Step: 8
Training loss: 2.0187196731567383
Validation loss: 2.178447860543446

Epoch: 6| Step: 9
Training loss: 1.8222229480743408
Validation loss: 2.182998308571436

Epoch: 6| Step: 10
Training loss: 1.784386396408081
Validation loss: 2.1636171981852543

Epoch: 6| Step: 11
Training loss: 2.1652209758758545
Validation loss: 2.1767051501940657

Epoch: 6| Step: 12
Training loss: 2.9758896827697754
Validation loss: 2.1562372612696823

Epoch: 6| Step: 13
Training loss: 3.563398599624634
Validation loss: 2.16651858950174

Epoch: 194| Step: 0
Training loss: 2.3478002548217773
Validation loss: 2.155813624781947

Epoch: 6| Step: 1
Training loss: 2.66931414604187
Validation loss: 2.159647264788228

Epoch: 6| Step: 2
Training loss: 2.417598247528076
Validation loss: 2.159014223724283

Epoch: 6| Step: 3
Training loss: 2.469102621078491
Validation loss: 2.1548526043533

Epoch: 6| Step: 4
Training loss: 2.2383038997650146
Validation loss: 2.1411599036185973

Epoch: 6| Step: 5
Training loss: 2.635206699371338
Validation loss: 2.145348051542877

Epoch: 6| Step: 6
Training loss: 2.0269436836242676
Validation loss: 2.1477344061738703

Epoch: 6| Step: 7
Training loss: 2.1789941787719727
Validation loss: 2.1590385334466093

Epoch: 6| Step: 8
Training loss: 1.6880202293395996
Validation loss: 2.158684851020895

Epoch: 6| Step: 9
Training loss: 2.4696953296661377
Validation loss: 2.1662471243130264

Epoch: 6| Step: 10
Training loss: 2.260704517364502
Validation loss: 2.1649488505496772

Epoch: 6| Step: 11
Training loss: 1.934173345565796
Validation loss: 2.1712268321744856

Epoch: 6| Step: 12
Training loss: 2.09731388092041
Validation loss: 2.162319906296269

Epoch: 6| Step: 13
Training loss: 3.1410577297210693
Validation loss: 2.182632815453314

Epoch: 195| Step: 0
Training loss: 1.8957698345184326
Validation loss: 2.173895428257604

Epoch: 6| Step: 1
Training loss: 2.1537647247314453
Validation loss: 2.1731982872050297

Epoch: 6| Step: 2
Training loss: 2.687750816345215
Validation loss: 2.1768803647769395

Epoch: 6| Step: 3
Training loss: 2.684792995452881
Validation loss: 2.1812515540789534

Epoch: 6| Step: 4
Training loss: 2.417072296142578
Validation loss: 2.180282969628611

Epoch: 6| Step: 5
Training loss: 1.8531781435012817
Validation loss: 2.1726011076281146

Epoch: 6| Step: 6
Training loss: 2.2310948371887207
Validation loss: 2.170352437162912

Epoch: 6| Step: 7
Training loss: 2.400696277618408
Validation loss: 2.1809842791608585

Epoch: 6| Step: 8
Training loss: 1.8389533758163452
Validation loss: 2.1957085055689656

Epoch: 6| Step: 9
Training loss: 2.903719425201416
Validation loss: 2.2133469953331897

Epoch: 6| Step: 10
Training loss: 1.8902783393859863
Validation loss: 2.190660386957148

Epoch: 6| Step: 11
Training loss: 1.9377200603485107
Validation loss: 2.1809647749829035

Epoch: 6| Step: 12
Training loss: 2.6000771522521973
Validation loss: 2.182270485867736

Epoch: 6| Step: 13
Training loss: 2.7691361904144287
Validation loss: 2.171392385677625

Epoch: 196| Step: 0
Training loss: 2.7767415046691895
Validation loss: 2.1829349071748796

Epoch: 6| Step: 1
Training loss: 2.2573580741882324
Validation loss: 2.1736074032322055

Epoch: 6| Step: 2
Training loss: 1.983954906463623
Validation loss: 2.197837383516373

Epoch: 6| Step: 3
Training loss: 2.4613776206970215
Validation loss: 2.185010452424326

Epoch: 6| Step: 4
Training loss: 1.7393602132797241
Validation loss: 2.1893769156548286

Epoch: 6| Step: 5
Training loss: 2.4092295169830322
Validation loss: 2.2016563697527816

Epoch: 6| Step: 6
Training loss: 2.8733162879943848
Validation loss: 2.193536473858741

Epoch: 6| Step: 7
Training loss: 1.8748626708984375
Validation loss: 2.19262844516385

Epoch: 6| Step: 8
Training loss: 2.05311918258667
Validation loss: 2.1913879379149406

Epoch: 6| Step: 9
Training loss: 2.244232654571533
Validation loss: 2.1917792763761295

Epoch: 6| Step: 10
Training loss: 2.1218011379241943
Validation loss: 2.208394403098732

Epoch: 6| Step: 11
Training loss: 2.9245219230651855
Validation loss: 2.1911831030281643

Epoch: 6| Step: 12
Training loss: 1.8459117412567139
Validation loss: 2.190022196820987

Epoch: 6| Step: 13
Training loss: 2.286128520965576
Validation loss: 2.198796856787897

Epoch: 197| Step: 0
Training loss: 2.8210222721099854
Validation loss: 2.2104755511847873

Epoch: 6| Step: 1
Training loss: 1.9417701959609985
Validation loss: 2.2207229393784718

Epoch: 6| Step: 2
Training loss: 2.540621757507324
Validation loss: 2.199787908984769

Epoch: 6| Step: 3
Training loss: 1.5524448156356812
Validation loss: 2.204034177205896

Epoch: 6| Step: 4
Training loss: 2.333462715148926
Validation loss: 2.1841469977491643

Epoch: 6| Step: 5
Training loss: 1.4166171550750732
Validation loss: 2.1739327881925847

Epoch: 6| Step: 6
Training loss: 1.9426636695861816
Validation loss: 2.1817117198821037

Epoch: 6| Step: 7
Training loss: 2.287992477416992
Validation loss: 2.170702451018877

Epoch: 6| Step: 8
Training loss: 2.8934597969055176
Validation loss: 2.1706071976692445

Epoch: 6| Step: 9
Training loss: 1.8191492557525635
Validation loss: 2.16475425740724

Epoch: 6| Step: 10
Training loss: 2.563455104827881
Validation loss: 2.16782840477523

Epoch: 6| Step: 11
Training loss: 2.542358875274658
Validation loss: 2.1719081453097764

Epoch: 6| Step: 12
Training loss: 2.805163860321045
Validation loss: 2.1714237172116517

Epoch: 6| Step: 13
Training loss: 2.272099733352661
Validation loss: 2.177872509084722

Epoch: 198| Step: 0
Training loss: 2.1925530433654785
Validation loss: 2.1975402344939527

Epoch: 6| Step: 1
Training loss: 2.081716537475586
Validation loss: 2.2092100445942213

Epoch: 6| Step: 2
Training loss: 2.587743043899536
Validation loss: 2.1999480083424556

Epoch: 6| Step: 3
Training loss: 2.5510973930358887
Validation loss: 2.2014509375377367

Epoch: 6| Step: 4
Training loss: 2.3544020652770996
Validation loss: 2.2027921112634803

Epoch: 6| Step: 5
Training loss: 2.241232395172119
Validation loss: 2.1994952373607184

Epoch: 6| Step: 6
Training loss: 2.4903812408447266
Validation loss: 2.1940843956444853

Epoch: 6| Step: 7
Training loss: 1.8448402881622314
Validation loss: 2.192005149779781

Epoch: 6| Step: 8
Training loss: 2.58123779296875
Validation loss: 2.166213107365434

Epoch: 6| Step: 9
Training loss: 1.9706649780273438
Validation loss: 2.1549213188950733

Epoch: 6| Step: 10
Training loss: 2.2474186420440674
Validation loss: 2.1600967786645375

Epoch: 6| Step: 11
Training loss: 1.737059235572815
Validation loss: 2.1417204769708778

Epoch: 6| Step: 12
Training loss: 2.0447192192077637
Validation loss: 2.1391171793783865

Epoch: 6| Step: 13
Training loss: 3.4638051986694336
Validation loss: 2.1333465729990313

Epoch: 199| Step: 0
Training loss: 1.8346800804138184
Validation loss: 2.133398554658377

Epoch: 6| Step: 1
Training loss: 2.776587724685669
Validation loss: 2.1541803088239444

Epoch: 6| Step: 2
Training loss: 2.607710838317871
Validation loss: 2.1679349458345802

Epoch: 6| Step: 3
Training loss: 1.0545082092285156
Validation loss: 2.150330292281284

Epoch: 6| Step: 4
Training loss: 2.7306647300720215
Validation loss: 2.1498114421803463

Epoch: 6| Step: 5
Training loss: 2.558116912841797
Validation loss: 2.1376083486823627

Epoch: 6| Step: 6
Training loss: 2.355438470840454
Validation loss: 2.144119208858859

Epoch: 6| Step: 7
Training loss: 2.3677735328674316
Validation loss: 2.140367108006631

Epoch: 6| Step: 8
Training loss: 1.6724300384521484
Validation loss: 2.139065278473721

Epoch: 6| Step: 9
Training loss: 2.575395107269287
Validation loss: 2.1399824221928916

Epoch: 6| Step: 10
Training loss: 2.3875560760498047
Validation loss: 2.158150503712316

Epoch: 6| Step: 11
Training loss: 2.274550437927246
Validation loss: 2.147847754980928

Epoch: 6| Step: 12
Training loss: 2.292239189147949
Validation loss: 2.1603684861172914

Epoch: 6| Step: 13
Training loss: 2.930985450744629
Validation loss: 2.149844636199295

Epoch: 200| Step: 0
Training loss: 2.204784393310547
Validation loss: 2.1628869272047475

Epoch: 6| Step: 1
Training loss: 2.5951035022735596
Validation loss: 2.1567912947747017

Epoch: 6| Step: 2
Training loss: 2.0310115814208984
Validation loss: 2.1728066321342223

Epoch: 6| Step: 3
Training loss: 2.376004695892334
Validation loss: 2.197428225189127

Epoch: 6| Step: 4
Training loss: 2.850794553756714
Validation loss: 2.1877575869201333

Epoch: 6| Step: 5
Training loss: 1.5351035594940186
Validation loss: 2.181120213641915

Epoch: 6| Step: 6
Training loss: 2.7250237464904785
Validation loss: 2.172724357215307

Epoch: 6| Step: 7
Training loss: 1.8596605062484741
Validation loss: 2.171065099777714

Epoch: 6| Step: 8
Training loss: 2.1564342975616455
Validation loss: 2.1606588004737772

Epoch: 6| Step: 9
Training loss: 2.2142467498779297
Validation loss: 2.1806359752531974

Epoch: 6| Step: 10
Training loss: 2.7203526496887207
Validation loss: 2.1835062362814464

Epoch: 6| Step: 11
Training loss: 2.673374891281128
Validation loss: 2.1980342916263047

Epoch: 6| Step: 12
Training loss: 1.9680516719818115
Validation loss: 2.208321837968724

Epoch: 6| Step: 13
Training loss: 1.3511719703674316
Validation loss: 2.177836787316107

Epoch: 201| Step: 0
Training loss: 2.1745004653930664
Validation loss: 2.189193069293935

Epoch: 6| Step: 1
Training loss: 2.433466911315918
Validation loss: 2.1844853175583707

Epoch: 6| Step: 2
Training loss: 2.2128944396972656
Validation loss: 2.1671823263168335

Epoch: 6| Step: 3
Training loss: 2.327493667602539
Validation loss: 2.17022991436784

Epoch: 6| Step: 4
Training loss: 2.081514596939087
Validation loss: 2.169373321276839

Epoch: 6| Step: 5
Training loss: 2.4215807914733887
Validation loss: 2.1606520452807025

Epoch: 6| Step: 6
Training loss: 2.1298482418060303
Validation loss: 2.151452038877754

Epoch: 6| Step: 7
Training loss: 2.654360294342041
Validation loss: 2.149207870165507

Epoch: 6| Step: 8
Training loss: 2.031601905822754
Validation loss: 2.133277763602554

Epoch: 6| Step: 9
Training loss: 2.626157760620117
Validation loss: 2.1356799243598856

Epoch: 6| Step: 10
Training loss: 2.416154384613037
Validation loss: 2.1433305150719097

Epoch: 6| Step: 11
Training loss: 1.926448941230774
Validation loss: 2.136397953956358

Epoch: 6| Step: 12
Training loss: 2.1935009956359863
Validation loss: 2.142990178959344

Epoch: 6| Step: 13
Training loss: 1.629044532775879
Validation loss: 2.1467200145926526

Epoch: 202| Step: 0
Training loss: 2.184279680252075
Validation loss: 2.1558941307888237

Epoch: 6| Step: 1
Training loss: 2.737771511077881
Validation loss: 2.159849812907557

Epoch: 6| Step: 2
Training loss: 2.0970377922058105
Validation loss: 2.172579824283559

Epoch: 6| Step: 3
Training loss: 2.121803045272827
Validation loss: 2.1641807581788752

Epoch: 6| Step: 4
Training loss: 2.371490955352783
Validation loss: 2.162525194947438

Epoch: 6| Step: 5
Training loss: 1.6154987812042236
Validation loss: 2.1542654806567776

Epoch: 6| Step: 6
Training loss: 1.8213534355163574
Validation loss: 2.1504644091411302

Epoch: 6| Step: 7
Training loss: 2.4236762523651123
Validation loss: 2.134180700907143

Epoch: 6| Step: 8
Training loss: 1.6259031295776367
Validation loss: 2.1409309679462063

Epoch: 6| Step: 9
Training loss: 2.6839537620544434
Validation loss: 2.151782358846357

Epoch: 6| Step: 10
Training loss: 2.806865692138672
Validation loss: 2.158295831372661

Epoch: 6| Step: 11
Training loss: 1.7752163410186768
Validation loss: 2.167647420719106

Epoch: 6| Step: 12
Training loss: 2.7577714920043945
Validation loss: 2.168293527377549

Epoch: 6| Step: 13
Training loss: 2.6795034408569336
Validation loss: 2.1739364900896625

Epoch: 203| Step: 0
Training loss: 2.8069300651550293
Validation loss: 2.19032617281842

Epoch: 6| Step: 1
Training loss: 1.7781455516815186
Validation loss: 2.174995078835436

Epoch: 6| Step: 2
Training loss: 2.002506732940674
Validation loss: 2.192916621444046

Epoch: 6| Step: 3
Training loss: 2.0928781032562256
Validation loss: 2.1866429313536613

Epoch: 6| Step: 4
Training loss: 2.689695358276367
Validation loss: 2.2214227286718224

Epoch: 6| Step: 5
Training loss: 2.0649614334106445
Validation loss: 2.2052498966135006

Epoch: 6| Step: 6
Training loss: 2.199644088745117
Validation loss: 2.213971000845714

Epoch: 6| Step: 7
Training loss: 3.022341728210449
Validation loss: 2.2368524484736945

Epoch: 6| Step: 8
Training loss: 1.8043653964996338
Validation loss: 2.199842399166476

Epoch: 6| Step: 9
Training loss: 2.6729397773742676
Validation loss: 2.1743307370011524

Epoch: 6| Step: 10
Training loss: 2.0769808292388916
Validation loss: 2.164460487263177

Epoch: 6| Step: 11
Training loss: 2.2051620483398438
Validation loss: 2.1811189190033944

Epoch: 6| Step: 12
Training loss: 1.90631902217865
Validation loss: 2.160615990238805

Epoch: 6| Step: 13
Training loss: 2.5694522857666016
Validation loss: 2.171510204192131

Epoch: 204| Step: 0
Training loss: 2.6159911155700684
Validation loss: 2.171759605407715

Epoch: 6| Step: 1
Training loss: 1.8550348281860352
Validation loss: 2.1811015631562922

Epoch: 6| Step: 2
Training loss: 2.588992118835449
Validation loss: 2.1610562442451395

Epoch: 6| Step: 3
Training loss: 2.487509250640869
Validation loss: 2.1696289662391908

Epoch: 6| Step: 4
Training loss: 2.397428035736084
Validation loss: 2.1723046200249785

Epoch: 6| Step: 5
Training loss: 2.202901601791382
Validation loss: 2.1886636185389694

Epoch: 6| Step: 6
Training loss: 2.965543508529663
Validation loss: 2.197083916715396

Epoch: 6| Step: 7
Training loss: 2.2432470321655273
Validation loss: 2.188141901005981

Epoch: 6| Step: 8
Training loss: 2.557229518890381
Validation loss: 2.1971396066809215

Epoch: 6| Step: 9
Training loss: 1.6835802793502808
Validation loss: 2.197386372473932

Epoch: 6| Step: 10
Training loss: 1.4579044580459595
Validation loss: 2.190609408963111

Epoch: 6| Step: 11
Training loss: 2.27327299118042
Validation loss: 2.1738600705259588

Epoch: 6| Step: 12
Training loss: 1.986811876296997
Validation loss: 2.1664800156829176

Epoch: 6| Step: 13
Training loss: 2.2226898670196533
Validation loss: 2.1455744774110856

Epoch: 205| Step: 0
Training loss: 1.594963550567627
Validation loss: 2.1494414729456746

Epoch: 6| Step: 1
Training loss: 2.0941758155822754
Validation loss: 2.1418179465878393

Epoch: 6| Step: 2
Training loss: 2.6330785751342773
Validation loss: 2.1469721627491776

Epoch: 6| Step: 3
Training loss: 2.308701276779175
Validation loss: 2.1231582805674565

Epoch: 6| Step: 4
Training loss: 1.4925317764282227
Validation loss: 2.125447521927536

Epoch: 6| Step: 5
Training loss: 2.258333921432495
Validation loss: 2.1266389995492916

Epoch: 6| Step: 6
Training loss: 2.3513224124908447
Validation loss: 2.114117878739552

Epoch: 6| Step: 7
Training loss: 2.8266801834106445
Validation loss: 2.1199463823790192

Epoch: 6| Step: 8
Training loss: 2.493938446044922
Validation loss: 2.1247389957469

Epoch: 6| Step: 9
Training loss: 1.4953744411468506
Validation loss: 2.13689689226048

Epoch: 6| Step: 10
Training loss: 2.7066762447357178
Validation loss: 2.1446221848969818

Epoch: 6| Step: 11
Training loss: 2.196810245513916
Validation loss: 2.1729485347706783

Epoch: 6| Step: 12
Training loss: 3.0880346298217773
Validation loss: 2.1623960848777526

Epoch: 6| Step: 13
Training loss: 1.462400197982788
Validation loss: 2.158743522500479

Epoch: 206| Step: 0
Training loss: 2.5063605308532715
Validation loss: 2.148111561293243

Epoch: 6| Step: 1
Training loss: 2.144118309020996
Validation loss: 2.1480685562215824

Epoch: 6| Step: 2
Training loss: 2.2162084579467773
Validation loss: 2.1693303431234052

Epoch: 6| Step: 3
Training loss: 2.486483573913574
Validation loss: 2.1676641407833306

Epoch: 6| Step: 4
Training loss: 1.9417498111724854
Validation loss: 2.1885835304055163

Epoch: 6| Step: 5
Training loss: 2.6410136222839355
Validation loss: 2.1942205736714024

Epoch: 6| Step: 6
Training loss: 2.447659730911255
Validation loss: 2.1912792921066284

Epoch: 6| Step: 7
Training loss: 1.781688928604126
Validation loss: 2.1689823186525734

Epoch: 6| Step: 8
Training loss: 2.1664681434631348
Validation loss: 2.166630152733095

Epoch: 6| Step: 9
Training loss: 3.18886399269104
Validation loss: 2.1699227004922848

Epoch: 6| Step: 10
Training loss: 1.2746126651763916
Validation loss: 2.1697695793644076

Epoch: 6| Step: 11
Training loss: 2.330632209777832
Validation loss: 2.182321189552225

Epoch: 6| Step: 12
Training loss: 2.1021270751953125
Validation loss: 2.2046844523440123

Epoch: 6| Step: 13
Training loss: 2.3817265033721924
Validation loss: 2.197337970938734

Epoch: 207| Step: 0
Training loss: 2.5786690711975098
Validation loss: 2.1913806174391057

Epoch: 6| Step: 1
Training loss: 2.262538433074951
Validation loss: 2.196559670150921

Epoch: 6| Step: 2
Training loss: 2.1136937141418457
Validation loss: 2.162301601902131

Epoch: 6| Step: 3
Training loss: 1.9882932901382446
Validation loss: 2.1623864866072133

Epoch: 6| Step: 4
Training loss: 2.4966249465942383
Validation loss: 2.165115069317561

Epoch: 6| Step: 5
Training loss: 2.0778067111968994
Validation loss: 2.147349460150606

Epoch: 6| Step: 6
Training loss: 2.306769609451294
Validation loss: 2.148521149030296

Epoch: 6| Step: 7
Training loss: 1.7959128618240356
Validation loss: 2.1719522578741914

Epoch: 6| Step: 8
Training loss: 2.4251246452331543
Validation loss: 2.158261946452561

Epoch: 6| Step: 9
Training loss: 1.867936134338379
Validation loss: 2.1575450820307576

Epoch: 6| Step: 10
Training loss: 2.2046351432800293
Validation loss: 2.157056816162602

Epoch: 6| Step: 11
Training loss: 2.368093490600586
Validation loss: 2.1522240972006195

Epoch: 6| Step: 12
Training loss: 2.0562691688537598
Validation loss: 2.1622458786092777

Epoch: 6| Step: 13
Training loss: 2.63491153717041
Validation loss: 2.173507405865577

Epoch: 208| Step: 0
Training loss: 2.3074216842651367
Validation loss: 2.170446377928539

Epoch: 6| Step: 1
Training loss: 1.9101332426071167
Validation loss: 2.1693819594639603

Epoch: 6| Step: 2
Training loss: 2.297865867614746
Validation loss: 2.162134680696713

Epoch: 6| Step: 3
Training loss: 2.005817174911499
Validation loss: 2.150701594609086

Epoch: 6| Step: 4
Training loss: 2.325376510620117
Validation loss: 2.1419654020699124

Epoch: 6| Step: 5
Training loss: 1.849785327911377
Validation loss: 2.148311698308555

Epoch: 6| Step: 6
Training loss: 2.2268571853637695
Validation loss: 2.1440114334065425

Epoch: 6| Step: 7
Training loss: 2.5268259048461914
Validation loss: 2.1363036414628387

Epoch: 6| Step: 8
Training loss: 2.0134694576263428
Validation loss: 2.1373231321252804

Epoch: 6| Step: 9
Training loss: 2.214996814727783
Validation loss: 2.1226707248277563

Epoch: 6| Step: 10
Training loss: 2.2339789867401123
Validation loss: 2.123093253822737

Epoch: 6| Step: 11
Training loss: 2.1252756118774414
Validation loss: 2.1124730904897056

Epoch: 6| Step: 12
Training loss: 2.8295817375183105
Validation loss: 2.136507398338728

Epoch: 6| Step: 13
Training loss: 2.000229597091675
Validation loss: 2.132413036079817

Epoch: 209| Step: 0
Training loss: 1.4252564907073975
Validation loss: 2.126501606356713

Epoch: 6| Step: 1
Training loss: 2.9610705375671387
Validation loss: 2.1379445137516147

Epoch: 6| Step: 2
Training loss: 2.4885315895080566
Validation loss: 2.1291600786229616

Epoch: 6| Step: 3
Training loss: 2.0267443656921387
Validation loss: 2.1456324695259013

Epoch: 6| Step: 4
Training loss: 2.1232500076293945
Validation loss: 2.142291979123187

Epoch: 6| Step: 5
Training loss: 2.1988885402679443
Validation loss: 2.171907909454838

Epoch: 6| Step: 6
Training loss: 1.9987685680389404
Validation loss: 2.1593485057994886

Epoch: 6| Step: 7
Training loss: 1.935956358909607
Validation loss: 2.143159253622896

Epoch: 6| Step: 8
Training loss: 2.088235855102539
Validation loss: 2.1629283966556674

Epoch: 6| Step: 9
Training loss: 2.2570090293884277
Validation loss: 2.155673159066067

Epoch: 6| Step: 10
Training loss: 2.1557517051696777
Validation loss: 2.1575808909631546

Epoch: 6| Step: 11
Training loss: 2.5442209243774414
Validation loss: 2.146534503147166

Epoch: 6| Step: 12
Training loss: 2.2609493732452393
Validation loss: 2.1275481588097027

Epoch: 6| Step: 13
Training loss: 2.2310752868652344
Validation loss: 2.141852225026777

Epoch: 210| Step: 0
Training loss: 1.4735417366027832
Validation loss: 2.1321188916442213

Epoch: 6| Step: 1
Training loss: 2.705578565597534
Validation loss: 2.1328537541051067

Epoch: 6| Step: 2
Training loss: 2.949131965637207
Validation loss: 2.0994795086563274

Epoch: 6| Step: 3
Training loss: 1.4504725933074951
Validation loss: 2.0847546900472333

Epoch: 6| Step: 4
Training loss: 2.4643473625183105
Validation loss: 2.1007081359945317

Epoch: 6| Step: 5
Training loss: 1.9982459545135498
Validation loss: 2.114387430170531

Epoch: 6| Step: 6
Training loss: 2.4479286670684814
Validation loss: 2.1003635006566204

Epoch: 6| Step: 7
Training loss: 2.115438461303711
Validation loss: 2.097723573766729

Epoch: 6| Step: 8
Training loss: 1.809625506401062
Validation loss: 2.096464756996401

Epoch: 6| Step: 9
Training loss: 2.4619040489196777
Validation loss: 2.1055109449612197

Epoch: 6| Step: 10
Training loss: 2.5418901443481445
Validation loss: 2.1263342903506373

Epoch: 6| Step: 11
Training loss: 2.488670825958252
Validation loss: 2.152066555074466

Epoch: 6| Step: 12
Training loss: 1.8426250219345093
Validation loss: 2.135684133857809

Epoch: 6| Step: 13
Training loss: 2.64682674407959
Validation loss: 2.1198276294175016

Epoch: 211| Step: 0
Training loss: 1.8811450004577637
Validation loss: 2.1378804560630553

Epoch: 6| Step: 1
Training loss: 2.0522236824035645
Validation loss: 2.1214240571503997

Epoch: 6| Step: 2
Training loss: 2.6226165294647217
Validation loss: 2.132011518683485

Epoch: 6| Step: 3
Training loss: 2.3286170959472656
Validation loss: 2.136065286974753

Epoch: 6| Step: 4
Training loss: 2.323345184326172
Validation loss: 2.1453788062577606

Epoch: 6| Step: 5
Training loss: 2.2841362953186035
Validation loss: 2.145309050877889

Epoch: 6| Step: 6
Training loss: 2.161015033721924
Validation loss: 2.1570034411645707

Epoch: 6| Step: 7
Training loss: 1.8970798254013062
Validation loss: 2.173217878546766

Epoch: 6| Step: 8
Training loss: 2.3073108196258545
Validation loss: 2.1845654544009956

Epoch: 6| Step: 9
Training loss: 2.534940719604492
Validation loss: 2.181816224128969

Epoch: 6| Step: 10
Training loss: 2.1780924797058105
Validation loss: 2.1666803488167385

Epoch: 6| Step: 11
Training loss: 1.9795101881027222
Validation loss: 2.163638645602811

Epoch: 6| Step: 12
Training loss: 2.213564157485962
Validation loss: 2.149706022713774

Epoch: 6| Step: 13
Training loss: 2.104926586151123
Validation loss: 2.1438381005358953

Epoch: 212| Step: 0
Training loss: 1.7903470993041992
Validation loss: 2.1262428760528564

Epoch: 6| Step: 1
Training loss: 2.5550308227539062
Validation loss: 2.1316490865522817

Epoch: 6| Step: 2
Training loss: 1.922330379486084
Validation loss: 2.120516602711011

Epoch: 6| Step: 3
Training loss: 1.7303951978683472
Validation loss: 2.132283115899691

Epoch: 6| Step: 4
Training loss: 1.1108688116073608
Validation loss: 2.1274539655254734

Epoch: 6| Step: 5
Training loss: 1.7555607557296753
Validation loss: 2.1179566408998225

Epoch: 6| Step: 6
Training loss: 2.5024428367614746
Validation loss: 2.1349923379959597

Epoch: 6| Step: 7
Training loss: 2.732170581817627
Validation loss: 2.1302122864671933

Epoch: 6| Step: 8
Training loss: 2.0041556358337402
Validation loss: 2.138400031674293

Epoch: 6| Step: 9
Training loss: 3.091325044631958
Validation loss: 2.1492926894977527

Epoch: 6| Step: 10
Training loss: 2.392064094543457
Validation loss: 2.1431838761093798

Epoch: 6| Step: 11
Training loss: 2.5807228088378906
Validation loss: 2.157760235571092

Epoch: 6| Step: 12
Training loss: 2.0415401458740234
Validation loss: 2.1372311128083097

Epoch: 6| Step: 13
Training loss: 2.3743486404418945
Validation loss: 2.1347033054597917

Epoch: 213| Step: 0
Training loss: 2.4771995544433594
Validation loss: 2.1464913019569973

Epoch: 6| Step: 1
Training loss: 2.550966262817383
Validation loss: 2.1455600069415186

Epoch: 6| Step: 2
Training loss: 2.1304962635040283
Validation loss: 2.137791077295939

Epoch: 6| Step: 3
Training loss: 2.2492122650146484
Validation loss: 2.158205441249314

Epoch: 6| Step: 4
Training loss: 1.80130934715271
Validation loss: 2.149481455485026

Epoch: 6| Step: 5
Training loss: 3.0344581604003906
Validation loss: 2.1515900870805145

Epoch: 6| Step: 6
Training loss: 2.089664936065674
Validation loss: 2.149428898288358

Epoch: 6| Step: 7
Training loss: 1.698394775390625
Validation loss: 2.1608041691523727

Epoch: 6| Step: 8
Training loss: 2.0448756217956543
Validation loss: 2.1606585043732838

Epoch: 6| Step: 9
Training loss: 2.0513968467712402
Validation loss: 2.157524134523125

Epoch: 6| Step: 10
Training loss: 1.3870482444763184
Validation loss: 2.1331149685767388

Epoch: 6| Step: 11
Training loss: 2.161787509918213
Validation loss: 2.1369863915187057

Epoch: 6| Step: 12
Training loss: 2.212796688079834
Validation loss: 2.1470299664364068

Epoch: 6| Step: 13
Training loss: 2.8779962062835693
Validation loss: 2.1730073344322944

Epoch: 214| Step: 0
Training loss: 2.3268167972564697
Validation loss: 2.1595353849472536

Epoch: 6| Step: 1
Training loss: 1.5699031352996826
Validation loss: 2.1540162768415225

Epoch: 6| Step: 2
Training loss: 1.4412057399749756
Validation loss: 2.1401505367730254

Epoch: 6| Step: 3
Training loss: 3.4351086616516113
Validation loss: 2.1271087046592467

Epoch: 6| Step: 4
Training loss: 2.312725067138672
Validation loss: 2.1306872393495295

Epoch: 6| Step: 5
Training loss: 1.7553740739822388
Validation loss: 2.1457504572406894

Epoch: 6| Step: 6
Training loss: 1.687819004058838
Validation loss: 2.1401626756114345

Epoch: 6| Step: 7
Training loss: 1.9275245666503906
Validation loss: 2.1152945526184572

Epoch: 6| Step: 8
Training loss: 2.488396406173706
Validation loss: 2.0960099261294127

Epoch: 6| Step: 9
Training loss: 1.7712111473083496
Validation loss: 2.082411020032821

Epoch: 6| Step: 10
Training loss: 2.1433181762695312
Validation loss: 2.0896470803086475

Epoch: 6| Step: 11
Training loss: 2.8051552772521973
Validation loss: 2.0830475566207722

Epoch: 6| Step: 12
Training loss: 2.284723997116089
Validation loss: 2.096309318337389

Epoch: 6| Step: 13
Training loss: 2.8682217597961426
Validation loss: 2.100123615675075

Epoch: 215| Step: 0
Training loss: 2.0519042015075684
Validation loss: 2.10130097148239

Epoch: 6| Step: 1
Training loss: 2.5097904205322266
Validation loss: 2.10919790626854

Epoch: 6| Step: 2
Training loss: 2.184476375579834
Validation loss: 2.106088169159428

Epoch: 6| Step: 3
Training loss: 1.6683709621429443
Validation loss: 2.1094468921743412

Epoch: 6| Step: 4
Training loss: 2.3029911518096924
Validation loss: 2.110410154506724

Epoch: 6| Step: 5
Training loss: 3.164011240005493
Validation loss: 2.11557274992748

Epoch: 6| Step: 6
Training loss: 2.0317060947418213
Validation loss: 2.141378173264124

Epoch: 6| Step: 7
Training loss: 2.1509203910827637
Validation loss: 2.173683899705128

Epoch: 6| Step: 8
Training loss: 1.542285442352295
Validation loss: 2.148311456044515

Epoch: 6| Step: 9
Training loss: 2.3394882678985596
Validation loss: 2.1213373881514355

Epoch: 6| Step: 10
Training loss: 2.3644471168518066
Validation loss: 2.1328241158557195

Epoch: 6| Step: 11
Training loss: 1.816007375717163
Validation loss: 2.124539035622792

Epoch: 6| Step: 12
Training loss: 1.993656873703003
Validation loss: 2.1230822711862545

Epoch: 6| Step: 13
Training loss: 1.9005217552185059
Validation loss: 2.1409268789393927

Epoch: 216| Step: 0
Training loss: 1.9203555583953857
Validation loss: 2.1423421546977055

Epoch: 6| Step: 1
Training loss: 2.3546082973480225
Validation loss: 2.14121340679866

Epoch: 6| Step: 2
Training loss: 1.9148446321487427
Validation loss: 2.1328162736790155

Epoch: 6| Step: 3
Training loss: 2.73724102973938
Validation loss: 2.139259793425119

Epoch: 6| Step: 4
Training loss: 1.801087498664856
Validation loss: 2.1394332070504465

Epoch: 6| Step: 5
Training loss: 1.435336947441101
Validation loss: 2.118627370044749

Epoch: 6| Step: 6
Training loss: 2.158376693725586
Validation loss: 2.1231580306124944

Epoch: 6| Step: 7
Training loss: 2.842564105987549
Validation loss: 2.12945036221576

Epoch: 6| Step: 8
Training loss: 2.391618251800537
Validation loss: 2.1210426925331034

Epoch: 6| Step: 9
Training loss: 1.9969139099121094
Validation loss: 2.1435918551619335

Epoch: 6| Step: 10
Training loss: 1.7217015027999878
Validation loss: 2.146867116292318

Epoch: 6| Step: 11
Training loss: 2.773031711578369
Validation loss: 2.1452438780056533

Epoch: 6| Step: 12
Training loss: 2.190809726715088
Validation loss: 2.1547556282371603

Epoch: 6| Step: 13
Training loss: 1.8817509412765503
Validation loss: 2.1230471467459076

Epoch: 217| Step: 0
Training loss: 2.7109484672546387
Validation loss: 2.1402868122182865

Epoch: 6| Step: 1
Training loss: 1.9298889636993408
Validation loss: 2.1235047745448288

Epoch: 6| Step: 2
Training loss: 2.585319995880127
Validation loss: 2.1149811795962754

Epoch: 6| Step: 3
Training loss: 2.126546859741211
Validation loss: 2.135911190381614

Epoch: 6| Step: 4
Training loss: 2.1271891593933105
Validation loss: 2.136599616337848

Epoch: 6| Step: 5
Training loss: 2.166602611541748
Validation loss: 2.1227781413703837

Epoch: 6| Step: 6
Training loss: 2.749640941619873
Validation loss: 2.1254173119862876

Epoch: 6| Step: 7
Training loss: 2.426849365234375
Validation loss: 2.1288217575319353

Epoch: 6| Step: 8
Training loss: 1.508278250694275
Validation loss: 2.1524669201143327

Epoch: 6| Step: 9
Training loss: 1.791330099105835
Validation loss: 2.134736919915804

Epoch: 6| Step: 10
Training loss: 1.7725119590759277
Validation loss: 2.1455524275379796

Epoch: 6| Step: 11
Training loss: 2.008556365966797
Validation loss: 2.1350745513874996

Epoch: 6| Step: 12
Training loss: 2.5387213230133057
Validation loss: 2.1382935764969035

Epoch: 6| Step: 13
Training loss: 1.1190193891525269
Validation loss: 2.1524130682791434

Epoch: 218| Step: 0
Training loss: 2.0558366775512695
Validation loss: 2.1597082345716414

Epoch: 6| Step: 1
Training loss: 1.6545156240463257
Validation loss: 2.1338887240297053

Epoch: 6| Step: 2
Training loss: 2.3541107177734375
Validation loss: 2.129134661407881

Epoch: 6| Step: 3
Training loss: 2.01155161857605
Validation loss: 2.139470156802926

Epoch: 6| Step: 4
Training loss: 2.403622627258301
Validation loss: 2.1288888198073193

Epoch: 6| Step: 5
Training loss: 2.001091718673706
Validation loss: 2.1206256369108796

Epoch: 6| Step: 6
Training loss: 3.1321840286254883
Validation loss: 2.1243643837590374

Epoch: 6| Step: 7
Training loss: 2.789777994155884
Validation loss: 2.1274387375000985

Epoch: 6| Step: 8
Training loss: 1.6114106178283691
Validation loss: 2.118835292836671

Epoch: 6| Step: 9
Training loss: 2.2558536529541016
Validation loss: 2.1184887296410015

Epoch: 6| Step: 10
Training loss: 3.044625759124756
Validation loss: 2.1224192111722884

Epoch: 6| Step: 11
Training loss: 1.4199668169021606
Validation loss: 2.1288385698872228

Epoch: 6| Step: 12
Training loss: 1.9614508152008057
Validation loss: 2.1431793371836343

Epoch: 6| Step: 13
Training loss: 0.7398408055305481
Validation loss: 2.175296450173983

Epoch: 219| Step: 0
Training loss: 1.8942461013793945
Validation loss: 2.1927723782036894

Epoch: 6| Step: 1
Training loss: 2.228367805480957
Validation loss: 2.2087828484914636

Epoch: 6| Step: 2
Training loss: 2.600538492202759
Validation loss: 2.145864875085892

Epoch: 6| Step: 3
Training loss: 2.119417667388916
Validation loss: 2.131213177916824

Epoch: 6| Step: 4
Training loss: 2.627155303955078
Validation loss: 2.110389339026584

Epoch: 6| Step: 5
Training loss: 2.03133487701416
Validation loss: 2.103146650457895

Epoch: 6| Step: 6
Training loss: 2.0774800777435303
Validation loss: 2.1182646289948495

Epoch: 6| Step: 7
Training loss: 2.167248249053955
Validation loss: 2.122600843829493

Epoch: 6| Step: 8
Training loss: 2.53832745552063
Validation loss: 2.1280094628692954

Epoch: 6| Step: 9
Training loss: 2.285710334777832
Validation loss: 2.1311098273082445

Epoch: 6| Step: 10
Training loss: 1.8804960250854492
Validation loss: 2.121058528141309

Epoch: 6| Step: 11
Training loss: 1.7537765502929688
Validation loss: 2.1310910563315115

Epoch: 6| Step: 12
Training loss: 1.8060280084609985
Validation loss: 2.1554529051626883

Epoch: 6| Step: 13
Training loss: 2.282280921936035
Validation loss: 2.175847618810592

Epoch: 220| Step: 0
Training loss: 2.8646047115325928
Validation loss: 2.1990228519644788

Epoch: 6| Step: 1
Training loss: 2.12199330329895
Validation loss: 2.2118654187007616

Epoch: 6| Step: 2
Training loss: 2.174576759338379
Validation loss: 2.2031595155756962

Epoch: 6| Step: 3
Training loss: 2.4211602210998535
Validation loss: 2.210782266432239

Epoch: 6| Step: 4
Training loss: 2.35599422454834
Validation loss: 2.1982744278446322

Epoch: 6| Step: 5
Training loss: 2.463200092315674
Validation loss: 2.171776504926784

Epoch: 6| Step: 6
Training loss: 1.3651623725891113
Validation loss: 2.1451979708927933

Epoch: 6| Step: 7
Training loss: 1.3626515865325928
Validation loss: 2.163564033405755

Epoch: 6| Step: 8
Training loss: 2.5888912677764893
Validation loss: 2.156007651359804

Epoch: 6| Step: 9
Training loss: 1.9379467964172363
Validation loss: 2.1837056811137865

Epoch: 6| Step: 10
Training loss: 2.36114501953125
Validation loss: 2.1789513518733363

Epoch: 6| Step: 11
Training loss: 1.8521416187286377
Validation loss: 2.161092947888118

Epoch: 6| Step: 12
Training loss: 2.093813419342041
Validation loss: 2.1677598081609255

Epoch: 6| Step: 13
Training loss: 2.737088203430176
Validation loss: 2.165128146448443

Epoch: 221| Step: 0
Training loss: 1.8483120203018188
Validation loss: 2.1572518707603536

Epoch: 6| Step: 1
Training loss: 1.985601782798767
Validation loss: 2.160760052742497

Epoch: 6| Step: 2
Training loss: 2.560499668121338
Validation loss: 2.1622920600316857

Epoch: 6| Step: 3
Training loss: 2.40017032623291
Validation loss: 2.1655317544937134

Epoch: 6| Step: 4
Training loss: 1.700951337814331
Validation loss: 2.175842069810437

Epoch: 6| Step: 5
Training loss: 2.411989688873291
Validation loss: 2.17103825846026

Epoch: 6| Step: 6
Training loss: 2.334007740020752
Validation loss: 2.1566484974276636

Epoch: 6| Step: 7
Training loss: 1.5569093227386475
Validation loss: 2.1301904891126897

Epoch: 6| Step: 8
Training loss: 2.9758784770965576
Validation loss: 2.123718284791516

Epoch: 6| Step: 9
Training loss: 2.1320838928222656
Validation loss: 2.1110530437961703

Epoch: 6| Step: 10
Training loss: 1.6447327136993408
Validation loss: 2.1165391873287898

Epoch: 6| Step: 11
Training loss: 1.9497096538543701
Validation loss: 2.1135135081506546

Epoch: 6| Step: 12
Training loss: 2.1806068420410156
Validation loss: 2.1262412609592563

Epoch: 6| Step: 13
Training loss: 2.252115488052368
Validation loss: 2.137691367057062

Epoch: 222| Step: 0
Training loss: 2.106783628463745
Validation loss: 2.1217202153257144

Epoch: 6| Step: 1
Training loss: 2.263538360595703
Validation loss: 2.1463818550109863

Epoch: 6| Step: 2
Training loss: 2.103095054626465
Validation loss: 2.148015283769177

Epoch: 6| Step: 3
Training loss: 1.2633064985275269
Validation loss: 2.142285721276396

Epoch: 6| Step: 4
Training loss: 1.9422448873519897
Validation loss: 2.163725427401963

Epoch: 6| Step: 5
Training loss: 2.1357192993164062
Validation loss: 2.1793810603439168

Epoch: 6| Step: 6
Training loss: 2.644674301147461
Validation loss: 2.2145331700642905

Epoch: 6| Step: 7
Training loss: 2.146026611328125
Validation loss: 2.1704734525372906

Epoch: 6| Step: 8
Training loss: 2.519777297973633
Validation loss: 2.1931728586073844

Epoch: 6| Step: 9
Training loss: 1.5702593326568604
Validation loss: 2.177266169619817

Epoch: 6| Step: 10
Training loss: 3.0351152420043945
Validation loss: 2.169004242907288

Epoch: 6| Step: 11
Training loss: 2.412360668182373
Validation loss: 2.163968955316851

Epoch: 6| Step: 12
Training loss: 1.9550986289978027
Validation loss: 2.148498317246796

Epoch: 6| Step: 13
Training loss: 1.2226625680923462
Validation loss: 2.1475046193727882

Epoch: 223| Step: 0
Training loss: 2.3248682022094727
Validation loss: 2.1107998048105547

Epoch: 6| Step: 1
Training loss: 2.05532169342041
Validation loss: 2.1149969690589496

Epoch: 6| Step: 2
Training loss: 1.2208824157714844
Validation loss: 2.111101770913729

Epoch: 6| Step: 3
Training loss: 2.393934965133667
Validation loss: 2.109978106714064

Epoch: 6| Step: 4
Training loss: 2.439776659011841
Validation loss: 2.108233344170355

Epoch: 6| Step: 5
Training loss: 1.9995753765106201
Validation loss: 2.1033131050807174

Epoch: 6| Step: 6
Training loss: 2.1199893951416016
Validation loss: 2.1235558166298816

Epoch: 6| Step: 7
Training loss: 1.8556327819824219
Validation loss: 2.108605812954646

Epoch: 6| Step: 8
Training loss: 2.2789087295532227
Validation loss: 2.116973876953125

Epoch: 6| Step: 9
Training loss: 2.5594584941864014
Validation loss: 2.100971519306142

Epoch: 6| Step: 10
Training loss: 1.8305786848068237
Validation loss: 2.1135259315531743

Epoch: 6| Step: 11
Training loss: 2.5720481872558594
Validation loss: 2.119444083142024

Epoch: 6| Step: 12
Training loss: 1.9441365003585815
Validation loss: 2.1249388417889996

Epoch: 6| Step: 13
Training loss: 2.147508144378662
Validation loss: 2.133393303040535

Epoch: 224| Step: 0
Training loss: 1.7022311687469482
Validation loss: 2.140166756927326

Epoch: 6| Step: 1
Training loss: 2.760899066925049
Validation loss: 2.1461039179114887

Epoch: 6| Step: 2
Training loss: 2.2019131183624268
Validation loss: 2.1402668594032206

Epoch: 6| Step: 3
Training loss: 2.4197306632995605
Validation loss: 2.1305068615944154

Epoch: 6| Step: 4
Training loss: 1.9175611734390259
Validation loss: 2.128532184067593

Epoch: 6| Step: 5
Training loss: 2.6332945823669434
Validation loss: 2.127265712266327

Epoch: 6| Step: 6
Training loss: 2.5773606300354004
Validation loss: 2.106657116643844

Epoch: 6| Step: 7
Training loss: 1.7906155586242676
Validation loss: 2.1218145585829213

Epoch: 6| Step: 8
Training loss: 1.7553534507751465
Validation loss: 2.111194122222162

Epoch: 6| Step: 9
Training loss: 2.630415916442871
Validation loss: 2.0990965161272275

Epoch: 6| Step: 10
Training loss: 1.9553565979003906
Validation loss: 2.1126386157927977

Epoch: 6| Step: 11
Training loss: 1.5941972732543945
Validation loss: 2.1030128886622768

Epoch: 6| Step: 12
Training loss: 1.223806619644165
Validation loss: 2.1117919106637277

Epoch: 6| Step: 13
Training loss: 2.1279563903808594
Validation loss: 2.1260285633866505

Epoch: 225| Step: 0
Training loss: 2.4775094985961914
Validation loss: 2.1320660742380286

Epoch: 6| Step: 1
Training loss: 2.5997238159179688
Validation loss: 2.1153804422706686

Epoch: 6| Step: 2
Training loss: 1.9647258520126343
Validation loss: 2.1124386402868454

Epoch: 6| Step: 3
Training loss: 2.305351734161377
Validation loss: 2.111928064336059

Epoch: 6| Step: 4
Training loss: 1.7715539932250977
Validation loss: 2.123367835116643

Epoch: 6| Step: 5
Training loss: 2.16599440574646
Validation loss: 2.1207133236751763

Epoch: 6| Step: 6
Training loss: 1.0746580362319946
Validation loss: 2.148423476885724

Epoch: 6| Step: 7
Training loss: 2.2148032188415527
Validation loss: 2.131492171236264

Epoch: 6| Step: 8
Training loss: 2.147627115249634
Validation loss: 2.143598439872906

Epoch: 6| Step: 9
Training loss: 1.869657039642334
Validation loss: 2.1365519646675355

Epoch: 6| Step: 10
Training loss: 2.333758592605591
Validation loss: 2.138870482803673

Epoch: 6| Step: 11
Training loss: 2.474574327468872
Validation loss: 2.128170995302098

Epoch: 6| Step: 12
Training loss: 1.974744200706482
Validation loss: 2.1381235148317073

Epoch: 6| Step: 13
Training loss: 1.8935233354568481
Validation loss: 2.152265953761275

Epoch: 226| Step: 0
Training loss: 2.5845391750335693
Validation loss: 2.158781818164292

Epoch: 6| Step: 1
Training loss: 2.281407117843628
Validation loss: 2.1522612725534747

Epoch: 6| Step: 2
Training loss: 2.1125857830047607
Validation loss: 2.1425609511713826

Epoch: 6| Step: 3
Training loss: 1.8442270755767822
Validation loss: 2.143498674515755

Epoch: 6| Step: 4
Training loss: 2.6399168968200684
Validation loss: 2.129763155855158

Epoch: 6| Step: 5
Training loss: 2.302098035812378
Validation loss: 2.1081749098275298

Epoch: 6| Step: 6
Training loss: 1.850055456161499
Validation loss: 2.091538188278034

Epoch: 6| Step: 7
Training loss: 1.7077207565307617
Validation loss: 2.09620225685899

Epoch: 6| Step: 8
Training loss: 2.1184773445129395
Validation loss: 2.0856540215912687

Epoch: 6| Step: 9
Training loss: 2.385312795639038
Validation loss: 2.098757084979806

Epoch: 6| Step: 10
Training loss: 1.7035998106002808
Validation loss: 2.107143280326679

Epoch: 6| Step: 11
Training loss: 1.6687686443328857
Validation loss: 2.1218478166928856

Epoch: 6| Step: 12
Training loss: 2.1430981159210205
Validation loss: 2.123899572639055

Epoch: 6| Step: 13
Training loss: 2.897695302963257
Validation loss: 2.130310537994549

Epoch: 227| Step: 0
Training loss: 2.4056272506713867
Validation loss: 2.140467780892567

Epoch: 6| Step: 1
Training loss: 2.051694869995117
Validation loss: 2.1238032092330275

Epoch: 6| Step: 2
Training loss: 2.6848061084747314
Validation loss: 2.1309721598061184

Epoch: 6| Step: 3
Training loss: 2.511582851409912
Validation loss: 2.138982137044271

Epoch: 6| Step: 4
Training loss: 1.7248497009277344
Validation loss: 2.138593434005655

Epoch: 6| Step: 5
Training loss: 2.280686140060425
Validation loss: 2.1290557974128315

Epoch: 6| Step: 6
Training loss: 2.5777554512023926
Validation loss: 2.132571716462412

Epoch: 6| Step: 7
Training loss: 2.197377920150757
Validation loss: 2.1482343442978395

Epoch: 6| Step: 8
Training loss: 2.044757843017578
Validation loss: 2.1677943429639264

Epoch: 6| Step: 9
Training loss: 2.420499801635742
Validation loss: 2.1737881450242895

Epoch: 6| Step: 10
Training loss: 1.8870453834533691
Validation loss: 2.1737330805870796

Epoch: 6| Step: 11
Training loss: 1.453056812286377
Validation loss: 2.1867838290429886

Epoch: 6| Step: 12
Training loss: 1.700790524482727
Validation loss: 2.206694656802762

Epoch: 6| Step: 13
Training loss: 1.403199553489685
Validation loss: 2.2188935972029165

Epoch: 228| Step: 0
Training loss: 2.183784008026123
Validation loss: 2.2281998729193084

Epoch: 6| Step: 1
Training loss: 2.198957681655884
Validation loss: 2.2413814247295423

Epoch: 6| Step: 2
Training loss: 2.080204963684082
Validation loss: 2.250345858194495

Epoch: 6| Step: 3
Training loss: 1.653796911239624
Validation loss: 2.209813925527757

Epoch: 6| Step: 4
Training loss: 2.589198112487793
Validation loss: 2.2132218191700597

Epoch: 6| Step: 5
Training loss: 2.339191436767578
Validation loss: 2.1949100699476016

Epoch: 6| Step: 6
Training loss: 2.170377254486084
Validation loss: 2.162858029847504

Epoch: 6| Step: 7
Training loss: 2.291598320007324
Validation loss: 2.133156866155645

Epoch: 6| Step: 8
Training loss: 1.9006145000457764
Validation loss: 2.097665266324115

Epoch: 6| Step: 9
Training loss: 2.3668668270111084
Validation loss: 2.0846416052951606

Epoch: 6| Step: 10
Training loss: 2.5961596965789795
Validation loss: 2.1013272936626146

Epoch: 6| Step: 11
Training loss: 2.298927068710327
Validation loss: 2.10046180986589

Epoch: 6| Step: 12
Training loss: 1.6350175142288208
Validation loss: 2.115252343557214

Epoch: 6| Step: 13
Training loss: 2.055088520050049
Validation loss: 2.1152902803113385

Epoch: 229| Step: 0
Training loss: 2.34574556350708
Validation loss: 2.137631289420589

Epoch: 6| Step: 1
Training loss: 1.9451931715011597
Validation loss: 2.114479232859868

Epoch: 6| Step: 2
Training loss: 2.7834558486938477
Validation loss: 2.1188886806529057

Epoch: 6| Step: 3
Training loss: 1.7897974252700806
Validation loss: 2.1064140078842

Epoch: 6| Step: 4
Training loss: 2.849280595779419
Validation loss: 2.109125647493588

Epoch: 6| Step: 5
Training loss: 1.6707031726837158
Validation loss: 2.152634133574783

Epoch: 6| Step: 6
Training loss: 1.8255064487457275
Validation loss: 2.148307215782904

Epoch: 6| Step: 7
Training loss: 1.7693196535110474
Validation loss: 2.1649542418859338

Epoch: 6| Step: 8
Training loss: 2.00880765914917
Validation loss: 2.172701358795166

Epoch: 6| Step: 9
Training loss: 1.8669830560684204
Validation loss: 2.1699388642464914

Epoch: 6| Step: 10
Training loss: 1.9238505363464355
Validation loss: 2.1815200415990685

Epoch: 6| Step: 11
Training loss: 1.8677562475204468
Validation loss: 2.172437716555852

Epoch: 6| Step: 12
Training loss: 2.436784505844116
Validation loss: 2.15049853632527

Epoch: 6| Step: 13
Training loss: 2.6062657833099365
Validation loss: 2.1351225504311184

Epoch: 230| Step: 0
Training loss: 2.326026201248169
Validation loss: 2.128786758709979

Epoch: 6| Step: 1
Training loss: 1.8359813690185547
Validation loss: 2.12477106689125

Epoch: 6| Step: 2
Training loss: 2.140413284301758
Validation loss: 2.1192207528698828

Epoch: 6| Step: 3
Training loss: 1.8210030794143677
Validation loss: 2.1132644504629154

Epoch: 6| Step: 4
Training loss: 1.6366958618164062
Validation loss: 2.1329317323623167

Epoch: 6| Step: 5
Training loss: 2.217106580734253
Validation loss: 2.127463251031855

Epoch: 6| Step: 6
Training loss: 2.079331874847412
Validation loss: 2.1164564445454586

Epoch: 6| Step: 7
Training loss: 1.9359955787658691
Validation loss: 2.121351352301977

Epoch: 6| Step: 8
Training loss: 2.080756664276123
Validation loss: 2.117387984388618

Epoch: 6| Step: 9
Training loss: 2.1767120361328125
Validation loss: 2.104427699119814

Epoch: 6| Step: 10
Training loss: 2.7527503967285156
Validation loss: 2.121129478177717

Epoch: 6| Step: 11
Training loss: 2.564499855041504
Validation loss: 2.126561518638365

Epoch: 6| Step: 12
Training loss: 1.630113124847412
Validation loss: 2.137713133647878

Epoch: 6| Step: 13
Training loss: 2.007615327835083
Validation loss: 2.1234762091790476

Epoch: 231| Step: 0
Training loss: 1.8577818870544434
Validation loss: 2.129884704466789

Epoch: 6| Step: 1
Training loss: 2.693643569946289
Validation loss: 2.1295818410893923

Epoch: 6| Step: 2
Training loss: 2.183971405029297
Validation loss: 2.1021103243674

Epoch: 6| Step: 3
Training loss: 1.7318603992462158
Validation loss: 2.1042868937215498

Epoch: 6| Step: 4
Training loss: 2.169034719467163
Validation loss: 2.11877155047591

Epoch: 6| Step: 5
Training loss: 2.0495965480804443
Validation loss: 2.1240707071878577

Epoch: 6| Step: 6
Training loss: 2.1957883834838867
Validation loss: 2.1132007209203576

Epoch: 6| Step: 7
Training loss: 2.4062018394470215
Validation loss: 2.115936510024532

Epoch: 6| Step: 8
Training loss: 2.421872615814209
Validation loss: 2.120021873904813

Epoch: 6| Step: 9
Training loss: 1.4996273517608643
Validation loss: 2.1063416516909035

Epoch: 6| Step: 10
Training loss: 2.0730082988739014
Validation loss: 2.1144310351341002

Epoch: 6| Step: 11
Training loss: 2.313218593597412
Validation loss: 2.1051051719214326

Epoch: 6| Step: 12
Training loss: 1.161475419998169
Validation loss: 2.1023543163012435

Epoch: 6| Step: 13
Training loss: 2.577549934387207
Validation loss: 2.0857272122495916

Epoch: 232| Step: 0
Training loss: 2.1804709434509277
Validation loss: 2.111196348744054

Epoch: 6| Step: 1
Training loss: 1.52628493309021
Validation loss: 2.144260729512861

Epoch: 6| Step: 2
Training loss: 2.6225385665893555
Validation loss: 2.125917439819664

Epoch: 6| Step: 3
Training loss: 1.5649441480636597
Validation loss: 2.1213683748757965

Epoch: 6| Step: 4
Training loss: 1.5163873434066772
Validation loss: 2.1208379114827802

Epoch: 6| Step: 5
Training loss: 2.4776506423950195
Validation loss: 2.1131096424595004

Epoch: 6| Step: 6
Training loss: 1.6553421020507812
Validation loss: 2.095413774572393

Epoch: 6| Step: 7
Training loss: 2.2190542221069336
Validation loss: 2.090070286104756

Epoch: 6| Step: 8
Training loss: 2.2042884826660156
Validation loss: 2.089121308377994

Epoch: 6| Step: 9
Training loss: 2.1791234016418457
Validation loss: 2.09729475872491

Epoch: 6| Step: 10
Training loss: 2.3131699562072754
Validation loss: 2.0920798406806043

Epoch: 6| Step: 11
Training loss: 2.164853096008301
Validation loss: 2.0949521398031585

Epoch: 6| Step: 12
Training loss: 2.2595295906066895
Validation loss: 2.0956226395022486

Epoch: 6| Step: 13
Training loss: 2.0248773097991943
Validation loss: 2.1150499954018542

Epoch: 233| Step: 0
Training loss: 2.084240436553955
Validation loss: 2.101176823339155

Epoch: 6| Step: 1
Training loss: 1.9193307161331177
Validation loss: 2.1110713366539247

Epoch: 6| Step: 2
Training loss: 2.329986095428467
Validation loss: 2.1037976382881083

Epoch: 6| Step: 3
Training loss: 3.0303573608398438
Validation loss: 2.111586309248401

Epoch: 6| Step: 4
Training loss: 2.6262869834899902
Validation loss: 2.0984252216995403

Epoch: 6| Step: 5
Training loss: 1.6764999628067017
Validation loss: 2.1126644188357937

Epoch: 6| Step: 6
Training loss: 1.4013009071350098
Validation loss: 2.1087962978629657

Epoch: 6| Step: 7
Training loss: 2.07623553276062
Validation loss: 2.1081197107991865

Epoch: 6| Step: 8
Training loss: 1.7498070001602173
Validation loss: 2.082794253544141

Epoch: 6| Step: 9
Training loss: 2.502164125442505
Validation loss: 2.0893345417514926

Epoch: 6| Step: 10
Training loss: 1.8592923879623413
Validation loss: 2.0860247893999984

Epoch: 6| Step: 11
Training loss: 1.8313847780227661
Validation loss: 2.0744816564744517

Epoch: 6| Step: 12
Training loss: 1.888514757156372
Validation loss: 2.075699631885816

Epoch: 6| Step: 13
Training loss: 1.715139389038086
Validation loss: 2.069883895176713

Epoch: 234| Step: 0
Training loss: 1.8734536170959473
Validation loss: 2.0802557673505557

Epoch: 6| Step: 1
Training loss: 1.4789769649505615
Validation loss: 2.077814613619158

Epoch: 6| Step: 2
Training loss: 2.505420207977295
Validation loss: 2.0885646753413702

Epoch: 6| Step: 3
Training loss: 2.568171262741089
Validation loss: 2.0888187116192234

Epoch: 6| Step: 4
Training loss: 2.454658031463623
Validation loss: 2.093040225326374

Epoch: 6| Step: 5
Training loss: 2.1971426010131836
Validation loss: 2.113501202675604

Epoch: 6| Step: 6
Training loss: 2.1103625297546387
Validation loss: 2.10904013469655

Epoch: 6| Step: 7
Training loss: 2.5687499046325684
Validation loss: 2.114226721948193

Epoch: 6| Step: 8
Training loss: 1.679868221282959
Validation loss: 2.1126991036117717

Epoch: 6| Step: 9
Training loss: 2.521528482437134
Validation loss: 2.120792155624718

Epoch: 6| Step: 10
Training loss: 1.3165254592895508
Validation loss: 2.1201907101497857

Epoch: 6| Step: 11
Training loss: 1.5840998888015747
Validation loss: 2.1276322513498287

Epoch: 6| Step: 12
Training loss: 1.8303449153900146
Validation loss: 2.1428924888692875

Epoch: 6| Step: 13
Training loss: 1.7599318027496338
Validation loss: 2.14192456840187

Epoch: 235| Step: 0
Training loss: 2.52070951461792
Validation loss: 2.137605708132508

Epoch: 6| Step: 1
Training loss: 1.7529585361480713
Validation loss: 2.1030532608750048

Epoch: 6| Step: 2
Training loss: 2.6160264015197754
Validation loss: 2.084632186479466

Epoch: 6| Step: 3
Training loss: 2.4027528762817383
Validation loss: 2.0979427342773764

Epoch: 6| Step: 4
Training loss: 2.2249503135681152
Validation loss: 2.102852604722464

Epoch: 6| Step: 5
Training loss: 2.9494032859802246
Validation loss: 2.0914402225966096

Epoch: 6| Step: 6
Training loss: 1.8681824207305908
Validation loss: 2.088368108195643

Epoch: 6| Step: 7
Training loss: 2.069342851638794
Validation loss: 2.0959336219295377

Epoch: 6| Step: 8
Training loss: 1.7322123050689697
Validation loss: 2.0837812577524493

Epoch: 6| Step: 9
Training loss: 1.298549771308899
Validation loss: 2.0914399995598743

Epoch: 6| Step: 10
Training loss: 2.135481834411621
Validation loss: 2.0952261365869993

Epoch: 6| Step: 11
Training loss: 1.9460761547088623
Validation loss: 2.0964298094472578

Epoch: 6| Step: 12
Training loss: 1.4512457847595215
Validation loss: 2.0980081737682386

Epoch: 6| Step: 13
Training loss: 1.908303141593933
Validation loss: 2.1385774240698865

Epoch: 236| Step: 0
Training loss: 1.5880197286605835
Validation loss: 2.144051456964144

Epoch: 6| Step: 1
Training loss: 1.166224479675293
Validation loss: 2.143578875449396

Epoch: 6| Step: 2
Training loss: 2.493448257446289
Validation loss: 2.1571967896594795

Epoch: 6| Step: 3
Training loss: 2.234581470489502
Validation loss: 2.147495359502813

Epoch: 6| Step: 4
Training loss: 1.9039534330368042
Validation loss: 2.1370882590611777

Epoch: 6| Step: 5
Training loss: 1.7587908506393433
Validation loss: 2.140931634492772

Epoch: 6| Step: 6
Training loss: 2.1575186252593994
Validation loss: 2.1292794494218725

Epoch: 6| Step: 7
Training loss: 1.8161048889160156
Validation loss: 2.123452380139341

Epoch: 6| Step: 8
Training loss: 2.3186705112457275
Validation loss: 2.1370866324311946

Epoch: 6| Step: 9
Training loss: 2.787562370300293
Validation loss: 2.1293004276931926

Epoch: 6| Step: 10
Training loss: 2.7394309043884277
Validation loss: 2.1275368659727034

Epoch: 6| Step: 11
Training loss: 1.8039641380310059
Validation loss: 2.129254948708319

Epoch: 6| Step: 12
Training loss: 2.2095513343811035
Validation loss: 2.11927992169575

Epoch: 6| Step: 13
Training loss: 1.7701541185379028
Validation loss: 2.1151596833300847

Epoch: 237| Step: 0
Training loss: 1.998534917831421
Validation loss: 2.08256576009976

Epoch: 6| Step: 1
Training loss: 2.4801511764526367
Validation loss: 2.097544664977699

Epoch: 6| Step: 2
Training loss: 2.2815659046173096
Validation loss: 2.0989867128351682

Epoch: 6| Step: 3
Training loss: 1.8917803764343262
Validation loss: 2.0877129070220457

Epoch: 6| Step: 4
Training loss: 1.7833030223846436
Validation loss: 2.071557988402664

Epoch: 6| Step: 5
Training loss: 1.591460108757019
Validation loss: 2.0860339556970904

Epoch: 6| Step: 6
Training loss: 2.199209451675415
Validation loss: 2.08334162927443

Epoch: 6| Step: 7
Training loss: 2.238128900527954
Validation loss: 2.0621173599714875

Epoch: 6| Step: 8
Training loss: 1.8649886846542358
Validation loss: 2.064359659789711

Epoch: 6| Step: 9
Training loss: 1.8889905214309692
Validation loss: 2.071005459754698

Epoch: 6| Step: 10
Training loss: 2.658449649810791
Validation loss: 2.071567755873485

Epoch: 6| Step: 11
Training loss: 1.683934211730957
Validation loss: 2.0658919554884716

Epoch: 6| Step: 12
Training loss: 1.9988799095153809
Validation loss: 2.0805793487897484

Epoch: 6| Step: 13
Training loss: 1.7182186841964722
Validation loss: 2.069224383241387

Epoch: 238| Step: 0
Training loss: 1.8411115407943726
Validation loss: 2.082442834813108

Epoch: 6| Step: 1
Training loss: 1.4932305812835693
Validation loss: 2.091936498559931

Epoch: 6| Step: 2
Training loss: 1.9164845943450928
Validation loss: 2.108327829709617

Epoch: 6| Step: 3
Training loss: 2.274092674255371
Validation loss: 2.118541250946701

Epoch: 6| Step: 4
Training loss: 1.5401283502578735
Validation loss: 2.122657019604919

Epoch: 6| Step: 5
Training loss: 2.976613759994507
Validation loss: 2.128471747521431

Epoch: 6| Step: 6
Training loss: 2.2542362213134766
Validation loss: 2.1152308192304385

Epoch: 6| Step: 7
Training loss: 1.4836927652359009
Validation loss: 2.1189123007559005

Epoch: 6| Step: 8
Training loss: 2.2160401344299316
Validation loss: 2.1101352476304576

Epoch: 6| Step: 9
Training loss: 1.9715027809143066
Validation loss: 2.1229021472315632

Epoch: 6| Step: 10
Training loss: 1.7284590005874634
Validation loss: 2.0920510497144473

Epoch: 6| Step: 11
Training loss: 2.601168394088745
Validation loss: 2.0900236791180027

Epoch: 6| Step: 12
Training loss: 2.326671600341797
Validation loss: 2.08884302390519

Epoch: 6| Step: 13
Training loss: 1.43899405002594
Validation loss: 2.077692113896852

Epoch: 239| Step: 0
Training loss: 1.7354849576950073
Validation loss: 2.090624083754837

Epoch: 6| Step: 1
Training loss: 2.127253293991089
Validation loss: 2.087323416945755

Epoch: 6| Step: 2
Training loss: 2.3509950637817383
Validation loss: 2.084512993853579

Epoch: 6| Step: 3
Training loss: 1.645841121673584
Validation loss: 2.081095906995958

Epoch: 6| Step: 4
Training loss: 1.5420546531677246
Validation loss: 2.0791204642224055

Epoch: 6| Step: 5
Training loss: 1.8154146671295166
Validation loss: 2.0739450429075506

Epoch: 6| Step: 6
Training loss: 2.3373255729675293
Validation loss: 2.093824633988001

Epoch: 6| Step: 7
Training loss: 2.1440765857696533
Validation loss: 2.0751245124365694

Epoch: 6| Step: 8
Training loss: 1.797250509262085
Validation loss: 2.077914114921324

Epoch: 6| Step: 9
Training loss: 2.345264434814453
Validation loss: 2.0838095218904558

Epoch: 6| Step: 10
Training loss: 1.5203144550323486
Validation loss: 2.086482955563453

Epoch: 6| Step: 11
Training loss: 2.2036070823669434
Validation loss: 2.0936643590209303

Epoch: 6| Step: 12
Training loss: 1.6883331537246704
Validation loss: 2.091216725687827

Epoch: 6| Step: 13
Training loss: 3.311969757080078
Validation loss: 2.1011313469179216

Epoch: 240| Step: 0
Training loss: 1.3504770994186401
Validation loss: 2.10333949904288

Epoch: 6| Step: 1
Training loss: 2.4239625930786133
Validation loss: 2.1068713639372136

Epoch: 6| Step: 2
Training loss: 2.0787975788116455
Validation loss: 2.122422964342179

Epoch: 6| Step: 3
Training loss: 1.917630910873413
Validation loss: 2.1048394556968444

Epoch: 6| Step: 4
Training loss: 1.8571540117263794
Validation loss: 2.106363599018384

Epoch: 6| Step: 5
Training loss: 1.9728126525878906
Validation loss: 2.10602915927928

Epoch: 6| Step: 6
Training loss: 1.8388683795928955
Validation loss: 2.114337352014357

Epoch: 6| Step: 7
Training loss: 1.8325424194335938
Validation loss: 2.1016805864149526

Epoch: 6| Step: 8
Training loss: 1.8138940334320068
Validation loss: 2.0980873146364765

Epoch: 6| Step: 9
Training loss: 2.2302699089050293
Validation loss: 2.098569320094201

Epoch: 6| Step: 10
Training loss: 1.9096240997314453
Validation loss: 2.084737475200366

Epoch: 6| Step: 11
Training loss: 2.2691574096679688
Validation loss: 2.0808064783773115

Epoch: 6| Step: 12
Training loss: 1.843005657196045
Validation loss: 2.0792221587191344

Epoch: 6| Step: 13
Training loss: 2.963451862335205
Validation loss: 2.0792787690316477

Epoch: 241| Step: 0
Training loss: 1.5185976028442383
Validation loss: 2.0661299690123527

Epoch: 6| Step: 1
Training loss: 2.013339042663574
Validation loss: 2.0629089378541514

Epoch: 6| Step: 2
Training loss: 1.6033551692962646
Validation loss: 2.0636447065620014

Epoch: 6| Step: 3
Training loss: 2.3041539192199707
Validation loss: 2.0671535153542795

Epoch: 6| Step: 4
Training loss: 1.8191533088684082
Validation loss: 2.0803667268445416

Epoch: 6| Step: 5
Training loss: 2.2681236267089844
Validation loss: 2.086970449775778

Epoch: 6| Step: 6
Training loss: 1.8336818218231201
Validation loss: 2.0862093035892775

Epoch: 6| Step: 7
Training loss: 2.631993055343628
Validation loss: 2.1013115939273628

Epoch: 6| Step: 8
Training loss: 1.3635916709899902
Validation loss: 2.099256379629976

Epoch: 6| Step: 9
Training loss: 2.6534972190856934
Validation loss: 2.0987230347048853

Epoch: 6| Step: 10
Training loss: 2.096135139465332
Validation loss: 2.0840254881048716

Epoch: 6| Step: 11
Training loss: 2.0570969581604004
Validation loss: 2.0915696954214447

Epoch: 6| Step: 12
Training loss: 2.227977991104126
Validation loss: 2.085395090041622

Epoch: 6| Step: 13
Training loss: 1.277647852897644
Validation loss: 2.083508501770676

Epoch: 242| Step: 0
Training loss: 2.246748447418213
Validation loss: 2.0912656707148396

Epoch: 6| Step: 1
Training loss: 2.0321648120880127
Validation loss: 2.0587933755690053

Epoch: 6| Step: 2
Training loss: 2.275775909423828
Validation loss: 2.0660364832929385

Epoch: 6| Step: 3
Training loss: 1.73539400100708
Validation loss: 2.060837040665329

Epoch: 6| Step: 4
Training loss: 1.169346570968628
Validation loss: 2.0823236485963226

Epoch: 6| Step: 5
Training loss: 2.3367881774902344
Validation loss: 2.084931878633397

Epoch: 6| Step: 6
Training loss: 2.314988136291504
Validation loss: 2.0697682929295365

Epoch: 6| Step: 7
Training loss: 1.6333147287368774
Validation loss: 2.0687083582724295

Epoch: 6| Step: 8
Training loss: 2.313394069671631
Validation loss: 2.0749145887231313

Epoch: 6| Step: 9
Training loss: 2.0526952743530273
Validation loss: 2.0712904725023495

Epoch: 6| Step: 10
Training loss: 1.9333292245864868
Validation loss: 2.0738854664628223

Epoch: 6| Step: 11
Training loss: 1.995856523513794
Validation loss: 2.0707434377362652

Epoch: 6| Step: 12
Training loss: 1.9743456840515137
Validation loss: 2.0707447990294425

Epoch: 6| Step: 13
Training loss: 1.8135085105895996
Validation loss: 2.0808745930271764

Epoch: 243| Step: 0
Training loss: 1.989564061164856
Validation loss: 2.0744619407961444

Epoch: 6| Step: 1
Training loss: 2.2873573303222656
Validation loss: 2.0938060745116203

Epoch: 6| Step: 2
Training loss: 2.0269312858581543
Validation loss: 2.1159791561865036

Epoch: 6| Step: 3
Training loss: 2.0925612449645996
Validation loss: 2.135138537294121

Epoch: 6| Step: 4
Training loss: 2.1961166858673096
Validation loss: 2.116086441983459

Epoch: 6| Step: 5
Training loss: 1.5194087028503418
Validation loss: 2.115308024549997

Epoch: 6| Step: 6
Training loss: 1.9287174940109253
Validation loss: 2.1156072078212613

Epoch: 6| Step: 7
Training loss: 2.0767054557800293
Validation loss: 2.0987361913086264

Epoch: 6| Step: 8
Training loss: 2.268263816833496
Validation loss: 2.0747415929712276

Epoch: 6| Step: 9
Training loss: 1.6227701902389526
Validation loss: 2.078867099618399

Epoch: 6| Step: 10
Training loss: 1.660014033317566
Validation loss: 2.0820027833343833

Epoch: 6| Step: 11
Training loss: 2.8708713054656982
Validation loss: 2.096809443607125

Epoch: 6| Step: 12
Training loss: 1.7822896242141724
Validation loss: 2.1036926315676783

Epoch: 6| Step: 13
Training loss: 1.7218966484069824
Validation loss: 2.1003641672031854

Epoch: 244| Step: 0
Training loss: 2.0082154273986816
Validation loss: 2.0943398962738695

Epoch: 6| Step: 1
Training loss: 2.404726505279541
Validation loss: 2.0864965044042116

Epoch: 6| Step: 2
Training loss: 1.7034238576889038
Validation loss: 2.065165384482312

Epoch: 6| Step: 3
Training loss: 1.946764588356018
Validation loss: 2.0564675907934866

Epoch: 6| Step: 4
Training loss: 1.4299333095550537
Validation loss: 2.0805434744845153

Epoch: 6| Step: 5
Training loss: 2.870041847229004
Validation loss: 2.0845880790423323

Epoch: 6| Step: 6
Training loss: 2.0365147590637207
Validation loss: 2.0834212995344594

Epoch: 6| Step: 7
Training loss: 1.4222626686096191
Validation loss: 2.084156410668486

Epoch: 6| Step: 8
Training loss: 2.0258989334106445
Validation loss: 2.0840690828138784

Epoch: 6| Step: 9
Training loss: 1.697877287864685
Validation loss: 2.0858278325808945

Epoch: 6| Step: 10
Training loss: 1.7762184143066406
Validation loss: 2.0838238013687955

Epoch: 6| Step: 11
Training loss: 2.0728511810302734
Validation loss: 2.072794509190385

Epoch: 6| Step: 12
Training loss: 2.340137481689453
Validation loss: 2.0718933766888035

Epoch: 6| Step: 13
Training loss: 1.93111252784729
Validation loss: 2.072851824504073

Epoch: 245| Step: 0
Training loss: 2.0069470405578613
Validation loss: 2.0781232631334694

Epoch: 6| Step: 1
Training loss: 1.3421275615692139
Validation loss: 2.068515823733422

Epoch: 6| Step: 2
Training loss: 2.1220107078552246
Validation loss: 2.08381788961349

Epoch: 6| Step: 3
Training loss: 1.8464086055755615
Validation loss: 2.0859084693334435

Epoch: 6| Step: 4
Training loss: 1.7939729690551758
Validation loss: 2.102369664817728

Epoch: 6| Step: 5
Training loss: 1.5476300716400146
Validation loss: 2.086127363225465

Epoch: 6| Step: 6
Training loss: 2.042635440826416
Validation loss: 2.1018552728878555

Epoch: 6| Step: 7
Training loss: 1.4631896018981934
Validation loss: 2.0907624101126068

Epoch: 6| Step: 8
Training loss: 2.74218487739563
Validation loss: 2.0803355606653358

Epoch: 6| Step: 9
Training loss: 3.086062431335449
Validation loss: 2.076106425254576

Epoch: 6| Step: 10
Training loss: 2.562436580657959
Validation loss: 2.0565412275252806

Epoch: 6| Step: 11
Training loss: 1.5252885818481445
Validation loss: 2.0577383272109495

Epoch: 6| Step: 12
Training loss: 1.9011085033416748
Validation loss: 2.052566751357048

Epoch: 6| Step: 13
Training loss: 1.5604227781295776
Validation loss: 2.0573924895255797

Epoch: 246| Step: 0
Training loss: 1.6709929704666138
Validation loss: 2.077379439466743

Epoch: 6| Step: 1
Training loss: 2.810270309448242
Validation loss: 2.074246821864959

Epoch: 6| Step: 2
Training loss: 2.3633058071136475
Validation loss: 2.0857511899804555

Epoch: 6| Step: 3
Training loss: 2.122206687927246
Validation loss: 2.1018055305686048

Epoch: 6| Step: 4
Training loss: 1.8641729354858398
Validation loss: 2.1087726367417203

Epoch: 6| Step: 5
Training loss: 1.5140095949172974
Validation loss: 2.1118534380389797

Epoch: 6| Step: 6
Training loss: 1.849829912185669
Validation loss: 2.1165868364354616

Epoch: 6| Step: 7
Training loss: 1.99399733543396
Validation loss: 2.105547648604198

Epoch: 6| Step: 8
Training loss: 1.4244906902313232
Validation loss: 2.1072037040546374

Epoch: 6| Step: 9
Training loss: 1.7182835340499878
Validation loss: 2.09820532542403

Epoch: 6| Step: 10
Training loss: 1.7453628778457642
Validation loss: 2.1081406724068428

Epoch: 6| Step: 11
Training loss: 2.4007441997528076
Validation loss: 2.1218370160748883

Epoch: 6| Step: 12
Training loss: 2.3383781909942627
Validation loss: 2.1315336201780584

Epoch: 6| Step: 13
Training loss: 1.735819697380066
Validation loss: 2.14137404195724

Epoch: 247| Step: 0
Training loss: 1.82444167137146
Validation loss: 2.137165214425774

Epoch: 6| Step: 1
Training loss: 1.94636869430542
Validation loss: 2.1174126273842266

Epoch: 6| Step: 2
Training loss: 2.7132089138031006
Validation loss: 2.1076960358568417

Epoch: 6| Step: 3
Training loss: 2.455747604370117
Validation loss: 2.0775206768384544

Epoch: 6| Step: 4
Training loss: 1.4844231605529785
Validation loss: 2.064571693379392

Epoch: 6| Step: 5
Training loss: 1.6610263586044312
Validation loss: 2.064127040165727

Epoch: 6| Step: 6
Training loss: 2.5328006744384766
Validation loss: 2.072154070741387

Epoch: 6| Step: 7
Training loss: 2.2046754360198975
Validation loss: 2.0811021866336947

Epoch: 6| Step: 8
Training loss: 2.0002689361572266
Validation loss: 2.0716316956345753

Epoch: 6| Step: 9
Training loss: 1.5470186471939087
Validation loss: 2.050919966031146

Epoch: 6| Step: 10
Training loss: 1.5032020807266235
Validation loss: 2.0401146463168565

Epoch: 6| Step: 11
Training loss: 1.6151001453399658
Validation loss: 2.044139277550482

Epoch: 6| Step: 12
Training loss: 1.7096383571624756
Validation loss: 2.0370885543925787

Epoch: 6| Step: 13
Training loss: 2.89107084274292
Validation loss: 2.041565533607237

Epoch: 248| Step: 0
Training loss: 2.2942607402801514
Validation loss: 2.0518644740504604

Epoch: 6| Step: 1
Training loss: 2.329808235168457
Validation loss: 2.0964027399657876

Epoch: 6| Step: 2
Training loss: 2.0551483631134033
Validation loss: 2.096441658594275

Epoch: 6| Step: 3
Training loss: 1.8314169645309448
Validation loss: 2.0932746164260374

Epoch: 6| Step: 4
Training loss: 2.2327346801757812
Validation loss: 2.095033279029272

Epoch: 6| Step: 5
Training loss: 1.6084649562835693
Validation loss: 2.0848310762836086

Epoch: 6| Step: 6
Training loss: 2.1495542526245117
Validation loss: 2.0756568742054764

Epoch: 6| Step: 7
Training loss: 1.6739970445632935
Validation loss: 2.084947306622741

Epoch: 6| Step: 8
Training loss: 1.5899724960327148
Validation loss: 2.0449762510996994

Epoch: 6| Step: 9
Training loss: 2.122260570526123
Validation loss: 2.0806891328545025

Epoch: 6| Step: 10
Training loss: 2.378000497817993
Validation loss: 2.0839053789774575

Epoch: 6| Step: 11
Training loss: 1.9584662914276123
Validation loss: 2.0890090747546126

Epoch: 6| Step: 12
Training loss: 2.0503973960876465
Validation loss: 2.080447554588318

Epoch: 6| Step: 13
Training loss: 1.5088622570037842
Validation loss: 2.0843215309163576

Epoch: 249| Step: 0
Training loss: 2.1388022899627686
Validation loss: 2.0841312382810857

Epoch: 6| Step: 1
Training loss: 2.262495279312134
Validation loss: 2.0624127977637836

Epoch: 6| Step: 2
Training loss: 2.3806893825531006
Validation loss: 2.0655018257838424

Epoch: 6| Step: 3
Training loss: 1.280199408531189
Validation loss: 2.0715569501282065

Epoch: 6| Step: 4
Training loss: 1.9127554893493652
Validation loss: 2.1115086617008334

Epoch: 6| Step: 5
Training loss: 2.0448222160339355
Validation loss: 2.1097159642045216

Epoch: 6| Step: 6
Training loss: 1.8001904487609863
Validation loss: 2.0969014372876895

Epoch: 6| Step: 7
Training loss: 1.8538521528244019
Validation loss: 2.0972234972061647

Epoch: 6| Step: 8
Training loss: 2.2378926277160645
Validation loss: 2.0784171653050247

Epoch: 6| Step: 9
Training loss: 1.510864019393921
Validation loss: 2.0730251817293066

Epoch: 6| Step: 10
Training loss: 2.77036714553833
Validation loss: 2.0938795484522337

Epoch: 6| Step: 11
Training loss: 1.565749168395996
Validation loss: 2.0960495753954818

Epoch: 6| Step: 12
Training loss: 1.9667108058929443
Validation loss: 2.133482106270329

Epoch: 6| Step: 13
Training loss: 2.1571414470672607
Validation loss: 2.170634768342459

Epoch: 250| Step: 0
Training loss: 1.9890886545181274
Validation loss: 2.192226723958087

Epoch: 6| Step: 1
Training loss: 1.624017357826233
Validation loss: 2.164606818588831

Epoch: 6| Step: 2
Training loss: 1.728489637374878
Validation loss: 2.1498991391992055

Epoch: 6| Step: 3
Training loss: 2.5526931285858154
Validation loss: 2.1058360607393327

Epoch: 6| Step: 4
Training loss: 1.8336337804794312
Validation loss: 2.0809742430204987

Epoch: 6| Step: 5
Training loss: 1.9210333824157715
Validation loss: 2.060670297632935

Epoch: 6| Step: 6
Training loss: 2.4299495220184326
Validation loss: 2.0374221032665623

Epoch: 6| Step: 7
Training loss: 1.9982908964157104
Validation loss: 2.0149442124110397

Epoch: 6| Step: 8
Training loss: 2.295387029647827
Validation loss: 2.046196719651581

Epoch: 6| Step: 9
Training loss: 2.183938503265381
Validation loss: 2.0872282289689585

Epoch: 6| Step: 10
Training loss: 1.6040395498275757
Validation loss: 2.116303179853706

Epoch: 6| Step: 11
Training loss: 1.7543554306030273
Validation loss: 2.1086503331379225

Epoch: 6| Step: 12
Training loss: 2.797180652618408
Validation loss: 2.1070480295406875

Epoch: 6| Step: 13
Training loss: 1.9310564994812012
Validation loss: 2.084492770574426

Epoch: 251| Step: 0
Training loss: 1.5715742111206055
Validation loss: 2.08027308987033

Epoch: 6| Step: 1
Training loss: 1.7887179851531982
Validation loss: 2.0627956082743983

Epoch: 6| Step: 2
Training loss: 2.6208362579345703
Validation loss: 2.0592256771620883

Epoch: 6| Step: 3
Training loss: 1.7469546794891357
Validation loss: 2.045832055871205

Epoch: 6| Step: 4
Training loss: 2.3403189182281494
Validation loss: 2.054572591217615

Epoch: 6| Step: 5
Training loss: 2.093323230743408
Validation loss: 2.066173730358001

Epoch: 6| Step: 6
Training loss: 2.0650742053985596
Validation loss: 2.0665616873771913

Epoch: 6| Step: 7
Training loss: 2.22546124458313
Validation loss: 2.0775091571192585

Epoch: 6| Step: 8
Training loss: 2.0306034088134766
Validation loss: 2.0852091235499226

Epoch: 6| Step: 9
Training loss: 1.545074701309204
Validation loss: 2.1112190472182406

Epoch: 6| Step: 10
Training loss: 2.323293685913086
Validation loss: 2.096409149067376

Epoch: 6| Step: 11
Training loss: 2.1526472568511963
Validation loss: 2.1073906447297786

Epoch: 6| Step: 12
Training loss: 1.7957993745803833
Validation loss: 2.1031168455718667

Epoch: 6| Step: 13
Training loss: 1.4106069803237915
Validation loss: 2.1166153851375786

Epoch: 252| Step: 0
Training loss: 1.857422113418579
Validation loss: 2.134257826753842

Epoch: 6| Step: 1
Training loss: 1.315830945968628
Validation loss: 2.1281234243864655

Epoch: 6| Step: 2
Training loss: 2.368438720703125
Validation loss: 2.135895852119692

Epoch: 6| Step: 3
Training loss: 2.1584527492523193
Validation loss: 2.119093833431121

Epoch: 6| Step: 4
Training loss: 2.1765801906585693
Validation loss: 2.1230196722092165

Epoch: 6| Step: 5
Training loss: 2.2182865142822266
Validation loss: 2.0999863070826374

Epoch: 6| Step: 6
Training loss: 1.748899221420288
Validation loss: 2.0952954087206113

Epoch: 6| Step: 7
Training loss: 1.4416548013687134
Validation loss: 2.075487800823745

Epoch: 6| Step: 8
Training loss: 2.475188732147217
Validation loss: 2.0776903539575557

Epoch: 6| Step: 9
Training loss: 2.374783515930176
Validation loss: 2.069724116274106

Epoch: 6| Step: 10
Training loss: 2.0991148948669434
Validation loss: 2.056874434153239

Epoch: 6| Step: 11
Training loss: 1.0676023960113525
Validation loss: 2.059565774856075

Epoch: 6| Step: 12
Training loss: 1.73896324634552
Validation loss: 2.0460357717288438

Epoch: 6| Step: 13
Training loss: 2.8503198623657227
Validation loss: 2.0390077957542996

Epoch: 253| Step: 0
Training loss: 1.7047911882400513
Validation loss: 2.0272904339657036

Epoch: 6| Step: 1
Training loss: 2.0871665477752686
Validation loss: 2.0354022159371326

Epoch: 6| Step: 2
Training loss: 2.233016014099121
Validation loss: 2.0160227642264417

Epoch: 6| Step: 3
Training loss: 2.801027536392212
Validation loss: 2.041480072083012

Epoch: 6| Step: 4
Training loss: 2.0960705280303955
Validation loss: 2.051467751943937

Epoch: 6| Step: 5
Training loss: 1.6793212890625
Validation loss: 2.0445410795109247

Epoch: 6| Step: 6
Training loss: 2.2205257415771484
Validation loss: 2.0391847907855944

Epoch: 6| Step: 7
Training loss: 2.113719940185547
Validation loss: 2.0524904061389226

Epoch: 6| Step: 8
Training loss: 1.5377953052520752
Validation loss: 2.055983417777605

Epoch: 6| Step: 9
Training loss: 1.6945910453796387
Validation loss: 2.026069788522618

Epoch: 6| Step: 10
Training loss: 1.4029829502105713
Validation loss: 2.038643208883142

Epoch: 6| Step: 11
Training loss: 2.224811553955078
Validation loss: 2.0538942352417977

Epoch: 6| Step: 12
Training loss: 1.8239009380340576
Validation loss: 2.0470748575784827

Epoch: 6| Step: 13
Training loss: 1.4032912254333496
Validation loss: 2.0747213030374176

Epoch: 254| Step: 0
Training loss: 2.3935351371765137
Validation loss: 2.095164232356574

Epoch: 6| Step: 1
Training loss: 1.4826682806015015
Validation loss: 2.0869812478301344

Epoch: 6| Step: 2
Training loss: 1.9599063396453857
Validation loss: 2.114744267156047

Epoch: 6| Step: 3
Training loss: 1.971705436706543
Validation loss: 2.1196519713247977

Epoch: 6| Step: 4
Training loss: 1.434262990951538
Validation loss: 2.1365875121085875

Epoch: 6| Step: 5
Training loss: 2.6381657123565674
Validation loss: 2.1374629415491575

Epoch: 6| Step: 6
Training loss: 2.2137222290039062
Validation loss: 2.1337674099911927

Epoch: 6| Step: 7
Training loss: 2.123072624206543
Validation loss: 2.1300660410235004

Epoch: 6| Step: 8
Training loss: 1.6284968852996826
Validation loss: 2.1189836737930134

Epoch: 6| Step: 9
Training loss: 1.6639437675476074
Validation loss: 2.107504674183425

Epoch: 6| Step: 10
Training loss: 1.7482972145080566
Validation loss: 2.088314128178422

Epoch: 6| Step: 11
Training loss: 1.559598684310913
Validation loss: 2.0880551953469553

Epoch: 6| Step: 12
Training loss: 1.9144726991653442
Validation loss: 2.0820812461196736

Epoch: 6| Step: 13
Training loss: 2.767160177230835
Validation loss: 2.073284169679047

Epoch: 255| Step: 0
Training loss: 2.617229461669922
Validation loss: 2.0614709738762147

Epoch: 6| Step: 1
Training loss: 1.459709644317627
Validation loss: 2.053916997807

Epoch: 6| Step: 2
Training loss: 1.6542813777923584
Validation loss: 2.051449680841097

Epoch: 6| Step: 3
Training loss: 1.2139382362365723
Validation loss: 2.0390532978119387

Epoch: 6| Step: 4
Training loss: 1.5575008392333984
Validation loss: 2.056266415503717

Epoch: 6| Step: 5
Training loss: 1.4321962594985962
Validation loss: 2.0356466257443993

Epoch: 6| Step: 6
Training loss: 2.259901523590088
Validation loss: 2.0328300127419094

Epoch: 6| Step: 7
Training loss: 2.2506103515625
Validation loss: 2.0339480471867386

Epoch: 6| Step: 8
Training loss: 2.075453996658325
Validation loss: 2.0503104297063683

Epoch: 6| Step: 9
Training loss: 1.900793194770813
Validation loss: 2.048441397246494

Epoch: 6| Step: 10
Training loss: 1.5795161724090576
Validation loss: 2.054576591778827

Epoch: 6| Step: 11
Training loss: 2.396655559539795
Validation loss: 2.0403358577400126

Epoch: 6| Step: 12
Training loss: 2.2965450286865234
Validation loss: 2.034663318305887

Epoch: 6| Step: 13
Training loss: 2.6130878925323486
Validation loss: 2.0430759358149704

Epoch: 256| Step: 0
Training loss: 2.2726566791534424
Validation loss: 2.0623661189950924

Epoch: 6| Step: 1
Training loss: 2.74965238571167
Validation loss: 2.0767845158935874

Epoch: 6| Step: 2
Training loss: 0.9936386346817017
Validation loss: 2.0710581682061635

Epoch: 6| Step: 3
Training loss: 1.9885090589523315
Validation loss: 2.091592570786835

Epoch: 6| Step: 4
Training loss: 2.040071964263916
Validation loss: 2.0725663246647006

Epoch: 6| Step: 5
Training loss: 1.4040789604187012
Validation loss: 2.0711386242220478

Epoch: 6| Step: 6
Training loss: 1.5227200984954834
Validation loss: 2.0677831096033894

Epoch: 6| Step: 7
Training loss: 1.819352388381958
Validation loss: 2.0672769238871913

Epoch: 6| Step: 8
Training loss: 1.8572382926940918
Validation loss: 2.055601591704994

Epoch: 6| Step: 9
Training loss: 2.3233377933502197
Validation loss: 2.087558195155154

Epoch: 6| Step: 10
Training loss: 2.0826354026794434
Validation loss: 2.0695395123574043

Epoch: 6| Step: 11
Training loss: 1.7089322805404663
Validation loss: 2.0751277631328953

Epoch: 6| Step: 12
Training loss: 2.1319472789764404
Validation loss: 2.064861512953235

Epoch: 6| Step: 13
Training loss: 1.9111080169677734
Validation loss: 2.0813190565314343

Epoch: 257| Step: 0
Training loss: 1.7294528484344482
Validation loss: 2.0828600057991604

Epoch: 6| Step: 1
Training loss: 2.324481964111328
Validation loss: 2.064029473130421

Epoch: 6| Step: 2
Training loss: 2.1266374588012695
Validation loss: 2.069995444308045

Epoch: 6| Step: 3
Training loss: 1.681907296180725
Validation loss: 2.0525786440859557

Epoch: 6| Step: 4
Training loss: 1.1563135385513306
Validation loss: 2.0589851358885407

Epoch: 6| Step: 5
Training loss: 2.4719395637512207
Validation loss: 2.0502481819480978

Epoch: 6| Step: 6
Training loss: 1.4329001903533936
Validation loss: 2.043959549678269

Epoch: 6| Step: 7
Training loss: 1.8720614910125732
Validation loss: 2.037200697006718

Epoch: 6| Step: 8
Training loss: 1.2806147336959839
Validation loss: 2.032850298830258

Epoch: 6| Step: 9
Training loss: 2.3510947227478027
Validation loss: 2.039504443445513

Epoch: 6| Step: 10
Training loss: 2.324542999267578
Validation loss: 2.0468574954617407

Epoch: 6| Step: 11
Training loss: 1.9589630365371704
Validation loss: 2.062505050372052

Epoch: 6| Step: 12
Training loss: 1.654788613319397
Validation loss: 2.0579004313356135

Epoch: 6| Step: 13
Training loss: 2.5875461101531982
Validation loss: 2.060259965158278

Epoch: 258| Step: 0
Training loss: 2.0350818634033203
Validation loss: 2.0685749733319847

Epoch: 6| Step: 1
Training loss: 1.7810752391815186
Validation loss: 2.0636452231355893

Epoch: 6| Step: 2
Training loss: 2.0554146766662598
Validation loss: 2.065687052665218

Epoch: 6| Step: 3
Training loss: 2.3331520557403564
Validation loss: 2.072418382090907

Epoch: 6| Step: 4
Training loss: 1.3701128959655762
Validation loss: 2.066762219193161

Epoch: 6| Step: 5
Training loss: 2.612337112426758
Validation loss: 2.063589216560446

Epoch: 6| Step: 6
Training loss: 2.266542911529541
Validation loss: 2.0524922981057117

Epoch: 6| Step: 7
Training loss: 1.4465394020080566
Validation loss: 2.064154346783956

Epoch: 6| Step: 8
Training loss: 2.334048271179199
Validation loss: 2.0648659724061207

Epoch: 6| Step: 9
Training loss: 1.8421969413757324
Validation loss: 2.0518369033772457

Epoch: 6| Step: 10
Training loss: 1.4572651386260986
Validation loss: 2.0534928537184194

Epoch: 6| Step: 11
Training loss: 1.9705228805541992
Validation loss: 2.045849561691284

Epoch: 6| Step: 12
Training loss: 1.655792474746704
Validation loss: 2.0490745575197282

Epoch: 6| Step: 13
Training loss: 1.167812466621399
Validation loss: 2.0417810678482056

Epoch: 259| Step: 0
Training loss: 1.9003851413726807
Validation loss: 2.058511339208131

Epoch: 6| Step: 1
Training loss: 2.1104345321655273
Validation loss: 2.0491064953547653

Epoch: 6| Step: 2
Training loss: 1.940305233001709
Validation loss: 2.0611891951612247

Epoch: 6| Step: 3
Training loss: 2.382185220718384
Validation loss: 2.060747669589135

Epoch: 6| Step: 4
Training loss: 1.8265929222106934
Validation loss: 2.052179305784164

Epoch: 6| Step: 5
Training loss: 2.0318307876586914
Validation loss: 2.05584474789199

Epoch: 6| Step: 6
Training loss: 2.2342529296875
Validation loss: 2.0340772610838695

Epoch: 6| Step: 7
Training loss: 1.5000419616699219
Validation loss: 2.042131203477101

Epoch: 6| Step: 8
Training loss: 1.8677042722702026
Validation loss: 2.048367892542193

Epoch: 6| Step: 9
Training loss: 2.050699234008789
Validation loss: 2.05044880477331

Epoch: 6| Step: 10
Training loss: 1.7961570024490356
Validation loss: 2.0555413602500834

Epoch: 6| Step: 11
Training loss: 1.4288495779037476
Validation loss: 2.0609871854064283

Epoch: 6| Step: 12
Training loss: 1.4326512813568115
Validation loss: 2.0541416188722015

Epoch: 6| Step: 13
Training loss: 2.2759268283843994
Validation loss: 2.05356926174574

Epoch: 260| Step: 0
Training loss: 1.73219633102417
Validation loss: 2.0394952271574285

Epoch: 6| Step: 1
Training loss: 1.2453097105026245
Validation loss: 2.0423927871129846

Epoch: 6| Step: 2
Training loss: 2.7239952087402344
Validation loss: 2.0391057665630052

Epoch: 6| Step: 3
Training loss: 1.8922314643859863
Validation loss: 2.0509015501186414

Epoch: 6| Step: 4
Training loss: 2.3493452072143555
Validation loss: 2.0714014243054133

Epoch: 6| Step: 5
Training loss: 1.4902085065841675
Validation loss: 2.0559893833693637

Epoch: 6| Step: 6
Training loss: 1.6172857284545898
Validation loss: 2.0471280928580993

Epoch: 6| Step: 7
Training loss: 1.8773488998413086
Validation loss: 2.040580846930063

Epoch: 6| Step: 8
Training loss: 1.5764918327331543
Validation loss: 2.054036681370069

Epoch: 6| Step: 9
Training loss: 1.6608810424804688
Validation loss: 2.064457893371582

Epoch: 6| Step: 10
Training loss: 2.469599723815918
Validation loss: 2.047880558557408

Epoch: 6| Step: 11
Training loss: 1.756797194480896
Validation loss: 2.065046025860694

Epoch: 6| Step: 12
Training loss: 2.458695888519287
Validation loss: 2.0526964587550007

Epoch: 6| Step: 13
Training loss: 1.3693937063217163
Validation loss: 2.0650094221997004

Epoch: 261| Step: 0
Training loss: 2.2525081634521484
Validation loss: 2.045421656741891

Epoch: 6| Step: 1
Training loss: 1.339081883430481
Validation loss: 2.064699803629229

Epoch: 6| Step: 2
Training loss: 1.7173466682434082
Validation loss: 2.0509834366460002

Epoch: 6| Step: 3
Training loss: 1.592456340789795
Validation loss: 2.057851896491102

Epoch: 6| Step: 4
Training loss: 2.2142088413238525
Validation loss: 2.0673126174557592

Epoch: 6| Step: 5
Training loss: 1.7099560499191284
Validation loss: 2.0608386352498043

Epoch: 6| Step: 6
Training loss: 1.6542189121246338
Validation loss: 2.05678617313344

Epoch: 6| Step: 7
Training loss: 1.9911394119262695
Validation loss: 2.0697631412936794

Epoch: 6| Step: 8
Training loss: 1.5822731256484985
Validation loss: 2.0530712578886297

Epoch: 6| Step: 9
Training loss: 1.2962472438812256
Validation loss: 2.043680626858947

Epoch: 6| Step: 10
Training loss: 2.5923221111297607
Validation loss: 2.0449541179082726

Epoch: 6| Step: 11
Training loss: 1.9206421375274658
Validation loss: 2.0656028627067484

Epoch: 6| Step: 12
Training loss: 2.1461219787597656
Validation loss: 2.048606299584912

Epoch: 6| Step: 13
Training loss: 2.66812801361084
Validation loss: 2.0244178515608593

Epoch: 262| Step: 0
Training loss: 1.9734821319580078
Validation loss: 2.0426386863954606

Epoch: 6| Step: 1
Training loss: 1.434917688369751
Validation loss: 2.048624224560235

Epoch: 6| Step: 2
Training loss: 1.8534131050109863
Validation loss: 2.062583810539656

Epoch: 6| Step: 3
Training loss: 1.9485565423965454
Validation loss: 2.053766119864679

Epoch: 6| Step: 4
Training loss: 2.263118267059326
Validation loss: 2.0746228515460925

Epoch: 6| Step: 5
Training loss: 2.093841314315796
Validation loss: 2.0636767982154764

Epoch: 6| Step: 6
Training loss: 1.3381376266479492
Validation loss: 2.0891505825904106

Epoch: 6| Step: 7
Training loss: 2.0802266597747803
Validation loss: 2.1024335507423646

Epoch: 6| Step: 8
Training loss: 2.2023158073425293
Validation loss: 2.1094825011427685

Epoch: 6| Step: 9
Training loss: 1.9438083171844482
Validation loss: 2.1294137713729695

Epoch: 6| Step: 10
Training loss: 1.350959300994873
Validation loss: 2.1157557938688543

Epoch: 6| Step: 11
Training loss: 2.3723397254943848
Validation loss: 2.1126054615102787

Epoch: 6| Step: 12
Training loss: 1.8381584882736206
Validation loss: 2.1035879453023276

Epoch: 6| Step: 13
Training loss: 1.729212760925293
Validation loss: 2.0913120341557327

Epoch: 263| Step: 0
Training loss: 2.367516040802002
Validation loss: 2.0773600134798276

Epoch: 6| Step: 1
Training loss: 1.7258427143096924
Validation loss: 2.043569173864139

Epoch: 6| Step: 2
Training loss: 1.7388908863067627
Validation loss: 2.019916252423358

Epoch: 6| Step: 3
Training loss: 2.5348916053771973
Validation loss: 2.0371679041975286

Epoch: 6| Step: 4
Training loss: 1.660057783126831
Validation loss: 2.022393657315162

Epoch: 6| Step: 5
Training loss: 1.6906903982162476
Validation loss: 2.0152810209540912

Epoch: 6| Step: 6
Training loss: 2.0448055267333984
Validation loss: 2.010955802855953

Epoch: 6| Step: 7
Training loss: 2.2685976028442383
Validation loss: 2.015464543014444

Epoch: 6| Step: 8
Training loss: 1.9720475673675537
Validation loss: 2.020137047254911

Epoch: 6| Step: 9
Training loss: 1.5053114891052246
Validation loss: 2.014034269958414

Epoch: 6| Step: 10
Training loss: 1.850701093673706
Validation loss: 2.015211247628735

Epoch: 6| Step: 11
Training loss: 1.7947214841842651
Validation loss: 2.0314049541309314

Epoch: 6| Step: 12
Training loss: 1.4747370481491089
Validation loss: 2.047335304239745

Epoch: 6| Step: 13
Training loss: 1.6230754852294922
Validation loss: 2.0526442502134588

Epoch: 264| Step: 0
Training loss: 2.153362989425659
Validation loss: 2.053292550066466

Epoch: 6| Step: 1
Training loss: 1.780055284500122
Validation loss: 2.067799663030973

Epoch: 6| Step: 2
Training loss: 1.5875344276428223
Validation loss: 2.073615574067639

Epoch: 6| Step: 3
Training loss: 2.054654598236084
Validation loss: 2.075558606014457

Epoch: 6| Step: 4
Training loss: 2.152657985687256
Validation loss: 2.08644736325869

Epoch: 6| Step: 5
Training loss: 2.2324931621551514
Validation loss: 2.0868795584606867

Epoch: 6| Step: 6
Training loss: 1.9302184581756592
Validation loss: 2.0847864586819886

Epoch: 6| Step: 7
Training loss: 1.9671833515167236
Validation loss: 2.0811996690688597

Epoch: 6| Step: 8
Training loss: 1.4890059232711792
Validation loss: 2.08255075639294

Epoch: 6| Step: 9
Training loss: 1.3570269346237183
Validation loss: 2.06565571472209

Epoch: 6| Step: 10
Training loss: 1.1958446502685547
Validation loss: 2.060348008268623

Epoch: 6| Step: 11
Training loss: 1.731642484664917
Validation loss: 2.0843729152474353

Epoch: 6| Step: 12
Training loss: 2.4550929069519043
Validation loss: 2.0591671748827864

Epoch: 6| Step: 13
Training loss: 2.148331880569458
Validation loss: 2.0617422544828026

Epoch: 265| Step: 0
Training loss: 2.4556214809417725
Validation loss: 2.0659542109376643

Epoch: 6| Step: 1
Training loss: 2.142225742340088
Validation loss: 2.091633395482135

Epoch: 6| Step: 2
Training loss: 2.1141319274902344
Validation loss: 2.057664366178615

Epoch: 6| Step: 3
Training loss: 2.0526328086853027
Validation loss: 2.03369588364837

Epoch: 6| Step: 4
Training loss: 1.6261520385742188
Validation loss: 2.047194675732684

Epoch: 6| Step: 5
Training loss: 1.5501408576965332
Validation loss: 2.037504073112242

Epoch: 6| Step: 6
Training loss: 1.5348374843597412
Validation loss: 2.0293666829345045

Epoch: 6| Step: 7
Training loss: 2.0173356533050537
Validation loss: 2.0268321934566704

Epoch: 6| Step: 8
Training loss: 2.1952943801879883
Validation loss: 2.0151414563578944

Epoch: 6| Step: 9
Training loss: 1.6528480052947998
Validation loss: 2.0147223446958806

Epoch: 6| Step: 10
Training loss: 1.6736822128295898
Validation loss: 2.0300942467105005

Epoch: 6| Step: 11
Training loss: 1.718140721321106
Validation loss: 2.022330827610467

Epoch: 6| Step: 12
Training loss: 1.4363553524017334
Validation loss: 2.0417720002512776

Epoch: 6| Step: 13
Training loss: 1.9717597961425781
Validation loss: 2.033054082624374

Epoch: 266| Step: 0
Training loss: 1.8037042617797852
Validation loss: 2.0419115789474978

Epoch: 6| Step: 1
Training loss: 2.120309352874756
Validation loss: 2.0575400219168714

Epoch: 6| Step: 2
Training loss: 1.589217185974121
Validation loss: 2.062755302716327

Epoch: 6| Step: 3
Training loss: 1.915730357170105
Validation loss: 2.056516524284117

Epoch: 6| Step: 4
Training loss: 1.7419171333312988
Validation loss: 2.0499719163422943

Epoch: 6| Step: 5
Training loss: 2.1239864826202393
Validation loss: 2.0608513098891064

Epoch: 6| Step: 6
Training loss: 2.0405807495117188
Validation loss: 2.081603015622785

Epoch: 6| Step: 7
Training loss: 1.5640757083892822
Validation loss: 2.0821142273564495

Epoch: 6| Step: 8
Training loss: 1.818141222000122
Validation loss: 2.082891962861502

Epoch: 6| Step: 9
Training loss: 1.7210557460784912
Validation loss: 2.096365236466931

Epoch: 6| Step: 10
Training loss: 1.4152615070343018
Validation loss: 2.0816205624611146

Epoch: 6| Step: 11
Training loss: 1.7033767700195312
Validation loss: 2.076906383678477

Epoch: 6| Step: 12
Training loss: 2.517221450805664
Validation loss: 2.0751265415581326

Epoch: 6| Step: 13
Training loss: 1.8092375993728638
Validation loss: 2.0580968767084102

Epoch: 267| Step: 0
Training loss: 1.0412839651107788
Validation loss: 2.051885617676602

Epoch: 6| Step: 1
Training loss: 1.5258233547210693
Validation loss: 2.04753388127973

Epoch: 6| Step: 2
Training loss: 2.217430353164673
Validation loss: 2.05432641121649

Epoch: 6| Step: 3
Training loss: 2.5349087715148926
Validation loss: 2.0590727072890087

Epoch: 6| Step: 4
Training loss: 1.483661413192749
Validation loss: 2.055794256989674

Epoch: 6| Step: 5
Training loss: 1.9407190084457397
Validation loss: 2.063220715010038

Epoch: 6| Step: 6
Training loss: 2.166872024536133
Validation loss: 2.0551540415774108

Epoch: 6| Step: 7
Training loss: 2.3866748809814453
Validation loss: 2.048829843921046

Epoch: 6| Step: 8
Training loss: 1.7787561416625977
Validation loss: 2.067306900537142

Epoch: 6| Step: 9
Training loss: 1.865966796875
Validation loss: 2.055778593145391

Epoch: 6| Step: 10
Training loss: 1.8118972778320312
Validation loss: 2.0460880725614485

Epoch: 6| Step: 11
Training loss: 1.652491569519043
Validation loss: 2.0643799817690285

Epoch: 6| Step: 12
Training loss: 1.1958426237106323
Validation loss: 2.059900756805174

Epoch: 6| Step: 13
Training loss: 2.4218385219573975
Validation loss: 2.077682207989436

Epoch: 268| Step: 0
Training loss: 2.3174757957458496
Validation loss: 2.0773054322888775

Epoch: 6| Step: 1
Training loss: 1.8734142780303955
Validation loss: 2.076640329053325

Epoch: 6| Step: 2
Training loss: 1.0656728744506836
Validation loss: 2.061562177955463

Epoch: 6| Step: 3
Training loss: 2.2329025268554688
Validation loss: 2.0592616424765637

Epoch: 6| Step: 4
Training loss: 2.152329444885254
Validation loss: 2.039204412891019

Epoch: 6| Step: 5
Training loss: 1.7497719526290894
Validation loss: 2.0398100960639214

Epoch: 6| Step: 6
Training loss: 2.0106844902038574
Validation loss: 2.0419551941656295

Epoch: 6| Step: 7
Training loss: 1.9097946882247925
Validation loss: 2.0338645904294905

Epoch: 6| Step: 8
Training loss: 2.285583734512329
Validation loss: 2.042455892409048

Epoch: 6| Step: 9
Training loss: 1.3949190378189087
Validation loss: 2.060546482762983

Epoch: 6| Step: 10
Training loss: 1.1376738548278809
Validation loss: 2.050829691271628

Epoch: 6| Step: 11
Training loss: 2.426562786102295
Validation loss: 2.0606440882528982

Epoch: 6| Step: 12
Training loss: 1.4055545330047607
Validation loss: 2.0551171674523303

Epoch: 6| Step: 13
Training loss: 2.151665449142456
Validation loss: 2.0615734169560094

Epoch: 269| Step: 0
Training loss: 1.7847845554351807
Validation loss: 2.070624359192387

Epoch: 6| Step: 1
Training loss: 1.7269189357757568
Validation loss: 2.0576010160548712

Epoch: 6| Step: 2
Training loss: 1.7985814809799194
Validation loss: 2.0485085684766053

Epoch: 6| Step: 3
Training loss: 1.4924978017807007
Validation loss: 2.0486665182216193

Epoch: 6| Step: 4
Training loss: 2.0716116428375244
Validation loss: 2.066702576093776

Epoch: 6| Step: 5
Training loss: 2.4635462760925293
Validation loss: 2.0541817090844594

Epoch: 6| Step: 6
Training loss: 1.9097038507461548
Validation loss: 2.05939947020623

Epoch: 6| Step: 7
Training loss: 1.4441616535186768
Validation loss: 2.057414702189866

Epoch: 6| Step: 8
Training loss: 0.9042449593544006
Validation loss: 2.0642122094349196

Epoch: 6| Step: 9
Training loss: 1.9338719844818115
Validation loss: 2.0426628307629655

Epoch: 6| Step: 10
Training loss: 1.9393669366836548
Validation loss: 2.068836130121703

Epoch: 6| Step: 11
Training loss: 2.48238468170166
Validation loss: 2.0517251824819915

Epoch: 6| Step: 12
Training loss: 1.559383511543274
Validation loss: 2.053911124506304

Epoch: 6| Step: 13
Training loss: 2.2584474086761475
Validation loss: 2.0545870309234946

Epoch: 270| Step: 0
Training loss: 1.6595759391784668
Validation loss: 2.0439308766395814

Epoch: 6| Step: 1
Training loss: 2.018528461456299
Validation loss: 2.0271125044873965

Epoch: 6| Step: 2
Training loss: 2.360729217529297
Validation loss: 2.0236496515171503

Epoch: 6| Step: 3
Training loss: 1.9425827264785767
Validation loss: 2.0362359016172347

Epoch: 6| Step: 4
Training loss: 1.411934494972229
Validation loss: 2.041100751969122

Epoch: 6| Step: 5
Training loss: 1.760835886001587
Validation loss: 2.0520024991804555

Epoch: 6| Step: 6
Training loss: 1.4277453422546387
Validation loss: 2.0611631665178525

Epoch: 6| Step: 7
Training loss: 1.7938206195831299
Validation loss: 2.062674883873232

Epoch: 6| Step: 8
Training loss: 1.9079378843307495
Validation loss: 2.0470382372538247

Epoch: 6| Step: 9
Training loss: 2.032736301422119
Validation loss: 2.046717277137182

Epoch: 6| Step: 10
Training loss: 1.677460789680481
Validation loss: 2.055882574409567

Epoch: 6| Step: 11
Training loss: 1.675518274307251
Validation loss: 2.0545024653916717

Epoch: 6| Step: 12
Training loss: 1.9680715799331665
Validation loss: 2.055358024053676

Epoch: 6| Step: 13
Training loss: 2.0054121017456055
Validation loss: 2.0383334159851074

Epoch: 271| Step: 0
Training loss: 2.320624351501465
Validation loss: 2.058737051102423

Epoch: 6| Step: 1
Training loss: 2.0112662315368652
Validation loss: 2.048493566051606

Epoch: 6| Step: 2
Training loss: 2.2454848289489746
Validation loss: 2.0430291711643176

Epoch: 6| Step: 3
Training loss: 1.8715312480926514
Validation loss: 2.0337175041116695

Epoch: 6| Step: 4
Training loss: 1.761234998703003
Validation loss: 2.0329723665791173

Epoch: 6| Step: 5
Training loss: 1.9204398393630981
Validation loss: 2.029851803215601

Epoch: 6| Step: 6
Training loss: 1.8443803787231445
Validation loss: 2.048358617290374

Epoch: 6| Step: 7
Training loss: 1.3104902505874634
Validation loss: 2.0315538503790416

Epoch: 6| Step: 8
Training loss: 1.3992924690246582
Validation loss: 2.0384511152903237

Epoch: 6| Step: 9
Training loss: 2.5445990562438965
Validation loss: 2.0315423652689946

Epoch: 6| Step: 10
Training loss: 1.6011850833892822
Validation loss: 2.044441766636346

Epoch: 6| Step: 11
Training loss: 1.5172810554504395
Validation loss: 2.028699049385645

Epoch: 6| Step: 12
Training loss: 1.2561172246932983
Validation loss: 2.034555645399196

Epoch: 6| Step: 13
Training loss: 2.194671392440796
Validation loss: 2.034924864768982

Epoch: 272| Step: 0
Training loss: 2.116680145263672
Validation loss: 2.051422965142035

Epoch: 6| Step: 1
Training loss: 2.512709140777588
Validation loss: 2.0591541285155923

Epoch: 6| Step: 2
Training loss: 1.916501760482788
Validation loss: 2.0730573182464926

Epoch: 6| Step: 3
Training loss: 1.6105868816375732
Validation loss: 2.066621757322742

Epoch: 6| Step: 4
Training loss: 2.808321714401245
Validation loss: 2.065632204855642

Epoch: 6| Step: 5
Training loss: 1.6712123155593872
Validation loss: 2.068699265039095

Epoch: 6| Step: 6
Training loss: 1.2681465148925781
Validation loss: 2.059335071553466

Epoch: 6| Step: 7
Training loss: 2.854681968688965
Validation loss: 2.063454612608879

Epoch: 6| Step: 8
Training loss: 1.6268396377563477
Validation loss: 2.101825475692749

Epoch: 6| Step: 9
Training loss: 1.2465626001358032
Validation loss: 2.087863535009405

Epoch: 6| Step: 10
Training loss: 1.7534308433532715
Validation loss: 2.077655489726733

Epoch: 6| Step: 11
Training loss: 1.7467873096466064
Validation loss: 2.0560669399076894

Epoch: 6| Step: 12
Training loss: 1.1286814212799072
Validation loss: 2.0296597890956427

Epoch: 6| Step: 13
Training loss: 0.837064802646637
Validation loss: 2.033042615459811

Epoch: 273| Step: 0
Training loss: 1.3943347930908203
Validation loss: 2.0270426811710482

Epoch: 6| Step: 1
Training loss: 1.7318854331970215
Validation loss: 2.0344408942807104

Epoch: 6| Step: 2
Training loss: 1.438759446144104
Validation loss: 2.0565200851809595

Epoch: 6| Step: 3
Training loss: 1.847398042678833
Validation loss: 2.0555232801745014

Epoch: 6| Step: 4
Training loss: 2.1577000617980957
Validation loss: 2.0621907608483427

Epoch: 6| Step: 5
Training loss: 1.6865622997283936
Validation loss: 2.059302778654201

Epoch: 6| Step: 6
Training loss: 1.4834767580032349
Validation loss: 2.0933800794745006

Epoch: 6| Step: 7
Training loss: 2.1685242652893066
Validation loss: 2.0955158138787873

Epoch: 6| Step: 8
Training loss: 1.4248647689819336
Validation loss: 2.0966061315228863

Epoch: 6| Step: 9
Training loss: 2.045398473739624
Validation loss: 2.107092503578432

Epoch: 6| Step: 10
Training loss: 1.8185911178588867
Validation loss: 2.096598740546934

Epoch: 6| Step: 11
Training loss: 2.2021541595458984
Validation loss: 2.1093057560664352

Epoch: 6| Step: 12
Training loss: 2.0217137336730957
Validation loss: 2.06894491821207

Epoch: 6| Step: 13
Training loss: 2.2282888889312744
Validation loss: 2.080340869965092

Epoch: 274| Step: 0
Training loss: 1.0432980060577393
Validation loss: 2.0685399040099113

Epoch: 6| Step: 1
Training loss: 1.7577886581420898
Validation loss: 2.051136824392503

Epoch: 6| Step: 2
Training loss: 2.28326416015625
Validation loss: 2.038765363795783

Epoch: 6| Step: 3
Training loss: 1.6942052841186523
Validation loss: 2.0463386966336157

Epoch: 6| Step: 4
Training loss: 1.802437424659729
Validation loss: 2.0392138675976823

Epoch: 6| Step: 5
Training loss: 1.9878208637237549
Validation loss: 2.034798983604677

Epoch: 6| Step: 6
Training loss: 1.8336111307144165
Validation loss: 2.0323727669254428

Epoch: 6| Step: 7
Training loss: 1.6598374843597412
Validation loss: 2.023430501261065

Epoch: 6| Step: 8
Training loss: 2.135826826095581
Validation loss: 2.0217501309610184

Epoch: 6| Step: 9
Training loss: 1.8082060813903809
Validation loss: 2.025979911127398

Epoch: 6| Step: 10
Training loss: 1.4273406267166138
Validation loss: 2.0113907347443285

Epoch: 6| Step: 11
Training loss: 1.988304853439331
Validation loss: 2.0139801963683097

Epoch: 6| Step: 12
Training loss: 1.7963624000549316
Validation loss: 2.017247797340475

Epoch: 6| Step: 13
Training loss: 2.037522315979004
Validation loss: 2.03773828219342

Epoch: 275| Step: 0
Training loss: 1.6190201044082642
Validation loss: 2.0382998271655013

Epoch: 6| Step: 1
Training loss: 2.190246820449829
Validation loss: 2.02799649905133

Epoch: 6| Step: 2
Training loss: 1.989748239517212
Validation loss: 2.04048906090439

Epoch: 6| Step: 3
Training loss: 1.6868414878845215
Validation loss: 2.0426847870631883

Epoch: 6| Step: 4
Training loss: 1.8579773902893066
Validation loss: 2.0621702107050086

Epoch: 6| Step: 5
Training loss: 2.0210912227630615
Validation loss: 2.060865749594986

Epoch: 6| Step: 6
Training loss: 1.4793940782546997
Validation loss: 2.062335334798341

Epoch: 6| Step: 7
Training loss: 1.9826629161834717
Validation loss: 2.089349494185499

Epoch: 6| Step: 8
Training loss: 1.4147133827209473
Validation loss: 2.071527801534181

Epoch: 6| Step: 9
Training loss: 1.9093329906463623
Validation loss: 2.0896283452228834

Epoch: 6| Step: 10
Training loss: 1.382213830947876
Validation loss: 2.1015898207182526

Epoch: 6| Step: 11
Training loss: 1.5568175315856934
Validation loss: 2.0896651283387215

Epoch: 6| Step: 12
Training loss: 2.352691888809204
Validation loss: 2.097860238885367

Epoch: 6| Step: 13
Training loss: 1.6949394941329956
Validation loss: 2.097155708138661

Epoch: 276| Step: 0
Training loss: 2.3854594230651855
Validation loss: 2.0870086967304187

Epoch: 6| Step: 1
Training loss: 1.8506042957305908
Validation loss: 2.0607391403567408

Epoch: 6| Step: 2
Training loss: 1.677748680114746
Validation loss: 2.0800964345214186

Epoch: 6| Step: 3
Training loss: 1.093698263168335
Validation loss: 2.079810433490302

Epoch: 6| Step: 4
Training loss: 2.406764507293701
Validation loss: 2.058174015373312

Epoch: 6| Step: 5
Training loss: 2.2640039920806885
Validation loss: 2.050157231669272

Epoch: 6| Step: 6
Training loss: 2.0897607803344727
Validation loss: 2.0672895549446024

Epoch: 6| Step: 7
Training loss: 1.5357173681259155
Validation loss: 2.0441079216618694

Epoch: 6| Step: 8
Training loss: 1.5147905349731445
Validation loss: 2.026935165928256

Epoch: 6| Step: 9
Training loss: 2.0512452125549316
Validation loss: 2.0227208291330645

Epoch: 6| Step: 10
Training loss: 1.2870240211486816
Validation loss: 2.036331195985117

Epoch: 6| Step: 11
Training loss: 0.8396556377410889
Validation loss: 2.042671162595031

Epoch: 6| Step: 12
Training loss: 1.7244259119033813
Validation loss: 2.047820101502121

Epoch: 6| Step: 13
Training loss: 2.9846911430358887
Validation loss: 2.037476449884394

Epoch: 277| Step: 0
Training loss: 1.1601334810256958
Validation loss: 2.0433770302803285

Epoch: 6| Step: 1
Training loss: 1.7221778631210327
Validation loss: 2.0722307210327475

Epoch: 6| Step: 2
Training loss: 2.3702423572540283
Validation loss: 2.067490387988347

Epoch: 6| Step: 3
Training loss: 1.9231224060058594
Validation loss: 2.07879057750907

Epoch: 6| Step: 4
Training loss: 1.2857189178466797
Validation loss: 2.080610745696611

Epoch: 6| Step: 5
Training loss: 2.392393112182617
Validation loss: 2.094237700585396

Epoch: 6| Step: 6
Training loss: 1.869876742362976
Validation loss: 2.071498642685593

Epoch: 6| Step: 7
Training loss: 1.4527297019958496
Validation loss: 2.071660216136645

Epoch: 6| Step: 8
Training loss: 1.6421492099761963
Validation loss: 2.065632999584239

Epoch: 6| Step: 9
Training loss: 2.0938315391540527
Validation loss: 2.076097678112727

Epoch: 6| Step: 10
Training loss: 2.0387001037597656
Validation loss: 2.0637659924004668

Epoch: 6| Step: 11
Training loss: 1.6549662351608276
Validation loss: 2.064488549386301

Epoch: 6| Step: 12
Training loss: 1.8745582103729248
Validation loss: 2.0640371794341714

Epoch: 6| Step: 13
Training loss: 1.2394094467163086
Validation loss: 2.0788959687755955

Epoch: 278| Step: 0
Training loss: 2.047445774078369
Validation loss: 2.1005394625407394

Epoch: 6| Step: 1
Training loss: 0.9709317684173584
Validation loss: 2.0708957410627797

Epoch: 6| Step: 2
Training loss: 1.409498929977417
Validation loss: 2.077981637370202

Epoch: 6| Step: 3
Training loss: 1.7798789739608765
Validation loss: 2.0866164776586715

Epoch: 6| Step: 4
Training loss: 2.135593891143799
Validation loss: 2.081043447217634

Epoch: 6| Step: 5
Training loss: 1.83031165599823
Validation loss: 2.069950916433847

Epoch: 6| Step: 6
Training loss: 1.459869623184204
Validation loss: 2.0510516217959824

Epoch: 6| Step: 7
Training loss: 2.3707406520843506
Validation loss: 2.039191008895956

Epoch: 6| Step: 8
Training loss: 1.1333283185958862
Validation loss: 2.0589673570407334

Epoch: 6| Step: 9
Training loss: 2.2141590118408203
Validation loss: 2.041864847624174

Epoch: 6| Step: 10
Training loss: 2.419160842895508
Validation loss: 2.0467713597000285

Epoch: 6| Step: 11
Training loss: 2.313535690307617
Validation loss: 2.0483680925061627

Epoch: 6| Step: 12
Training loss: 1.559682846069336
Validation loss: 2.022892487946377

Epoch: 6| Step: 13
Training loss: 1.1183292865753174
Validation loss: 2.027109428118634

Epoch: 279| Step: 0
Training loss: 1.7919836044311523
Validation loss: 1.9990994340629988

Epoch: 6| Step: 1
Training loss: 1.493622064590454
Validation loss: 2.0183847873441634

Epoch: 6| Step: 2
Training loss: 1.9727303981781006
Validation loss: 2.0098893386061474

Epoch: 6| Step: 3
Training loss: 0.9512848854064941
Validation loss: 2.014923272594329

Epoch: 6| Step: 4
Training loss: 1.3916332721710205
Validation loss: 2.040879939192085

Epoch: 6| Step: 5
Training loss: 1.977657437324524
Validation loss: 2.0343571427047893

Epoch: 6| Step: 6
Training loss: 1.7548766136169434
Validation loss: 2.064382895346611

Epoch: 6| Step: 7
Training loss: 2.0377862453460693
Validation loss: 2.0667111565989833

Epoch: 6| Step: 8
Training loss: 1.7559874057769775
Validation loss: 2.0774974412815546

Epoch: 6| Step: 9
Training loss: 2.0479278564453125
Validation loss: 2.0802308641454226

Epoch: 6| Step: 10
Training loss: 2.120603561401367
Validation loss: 2.0777191961965253

Epoch: 6| Step: 11
Training loss: 1.3303039073944092
Validation loss: 2.0755250300130537

Epoch: 6| Step: 12
Training loss: 1.9506793022155762
Validation loss: 2.070314400939531

Epoch: 6| Step: 13
Training loss: 2.6064443588256836
Validation loss: 2.056221846611269

Epoch: 280| Step: 0
Training loss: 1.8727445602416992
Validation loss: 2.060774210960634

Epoch: 6| Step: 1
Training loss: 1.0566705465316772
Validation loss: 2.0418656692709973

Epoch: 6| Step: 2
Training loss: 2.151935577392578
Validation loss: 2.0356848662899387

Epoch: 6| Step: 3
Training loss: 1.51319420337677
Validation loss: 2.0354744708666237

Epoch: 6| Step: 4
Training loss: 1.6367003917694092
Validation loss: 2.04006774451143

Epoch: 6| Step: 5
Training loss: 1.4894734621047974
Validation loss: 2.0648222046513713

Epoch: 6| Step: 6
Training loss: 1.6781260967254639
Validation loss: 2.0663268232858307

Epoch: 6| Step: 7
Training loss: 1.9049901962280273
Validation loss: 2.0469779801625076

Epoch: 6| Step: 8
Training loss: 2.171863555908203
Validation loss: 2.0651658709331224

Epoch: 6| Step: 9
Training loss: 1.2768149375915527
Validation loss: 2.0575078020813646

Epoch: 6| Step: 10
Training loss: 2.0085129737854004
Validation loss: 2.0775195475547545

Epoch: 6| Step: 11
Training loss: 1.9647631645202637
Validation loss: 2.092957136451557

Epoch: 6| Step: 12
Training loss: 1.7393267154693604
Validation loss: 2.0663627245092906

Epoch: 6| Step: 13
Training loss: 2.4808712005615234
Validation loss: 2.069864913981448

Epoch: 281| Step: 0
Training loss: 1.5470356941223145
Validation loss: 2.069812347812037

Epoch: 6| Step: 1
Training loss: 2.1197781562805176
Validation loss: 2.0709023475646973

Epoch: 6| Step: 2
Training loss: 1.8024488687515259
Validation loss: 2.065098674066605

Epoch: 6| Step: 3
Training loss: 1.2556304931640625
Validation loss: 2.0601195186697026

Epoch: 6| Step: 4
Training loss: 2.1505396366119385
Validation loss: 2.046318446436236

Epoch: 6| Step: 5
Training loss: 1.897244930267334
Validation loss: 2.031101498552548

Epoch: 6| Step: 6
Training loss: 2.080843687057495
Validation loss: 2.0552468556229786

Epoch: 6| Step: 7
Training loss: 1.1847941875457764
Validation loss: 2.0598023040320284

Epoch: 6| Step: 8
Training loss: 1.9912391901016235
Validation loss: 2.065505776354062

Epoch: 6| Step: 9
Training loss: 1.0830814838409424
Validation loss: 2.058756579634964

Epoch: 6| Step: 10
Training loss: 1.7201652526855469
Validation loss: 2.067769697917405

Epoch: 6| Step: 11
Training loss: 2.425337076187134
Validation loss: 2.0660803933297434

Epoch: 6| Step: 12
Training loss: 1.7275242805480957
Validation loss: 2.0726487367383895

Epoch: 6| Step: 13
Training loss: 1.5738158226013184
Validation loss: 2.0721466515653875

Epoch: 282| Step: 0
Training loss: 2.004094362258911
Validation loss: 2.073999212634179

Epoch: 6| Step: 1
Training loss: 1.8066802024841309
Validation loss: 2.061350582748331

Epoch: 6| Step: 2
Training loss: 1.8535856008529663
Validation loss: 2.0636339008167224

Epoch: 6| Step: 3
Training loss: 1.7066538333892822
Validation loss: 2.0625525495057464

Epoch: 6| Step: 4
Training loss: 1.5981647968292236
Validation loss: 2.083729085101876

Epoch: 6| Step: 5
Training loss: 2.168642520904541
Validation loss: 2.09089760370152

Epoch: 6| Step: 6
Training loss: 1.4046804904937744
Validation loss: 2.0761548806262273

Epoch: 6| Step: 7
Training loss: 1.828709363937378
Validation loss: 2.0892175910293416

Epoch: 6| Step: 8
Training loss: 1.5980372428894043
Validation loss: 2.0929292299414195

Epoch: 6| Step: 9
Training loss: 1.3886923789978027
Validation loss: 2.090979690192848

Epoch: 6| Step: 10
Training loss: 2.2574310302734375
Validation loss: 2.0660600136685114

Epoch: 6| Step: 11
Training loss: 1.8404299020767212
Validation loss: 2.0828866574072067

Epoch: 6| Step: 12
Training loss: 1.497119426727295
Validation loss: 2.057183222104144

Epoch: 6| Step: 13
Training loss: 1.696580410003662
Validation loss: 2.0442978233419438

Epoch: 283| Step: 0
Training loss: 2.214040756225586
Validation loss: 2.0478917116759927

Epoch: 6| Step: 1
Training loss: 2.0422451496124268
Validation loss: 2.0568218897747736

Epoch: 6| Step: 2
Training loss: 1.1427669525146484
Validation loss: 2.045914476917636

Epoch: 6| Step: 3
Training loss: 2.2830355167388916
Validation loss: 2.06352739180288

Epoch: 6| Step: 4
Training loss: 1.4562430381774902
Validation loss: 2.0549724178929485

Epoch: 6| Step: 5
Training loss: 2.4479122161865234
Validation loss: 2.0641532713367092

Epoch: 6| Step: 6
Training loss: 2.222050666809082
Validation loss: 2.0658675624478247

Epoch: 6| Step: 7
Training loss: 2.0384681224823
Validation loss: 2.0593497240415184

Epoch: 6| Step: 8
Training loss: 1.8534793853759766
Validation loss: 2.0659641245360016

Epoch: 6| Step: 9
Training loss: 1.4043002128601074
Validation loss: 2.091408221952377

Epoch: 6| Step: 10
Training loss: 1.2519185543060303
Validation loss: 2.0851935750694683

Epoch: 6| Step: 11
Training loss: 1.7024760246276855
Validation loss: 2.0943326386072303

Epoch: 6| Step: 12
Training loss: 0.9798332452774048
Validation loss: 2.097444483028945

Epoch: 6| Step: 13
Training loss: 1.2084146738052368
Validation loss: 2.1006814741319224

Epoch: 284| Step: 0
Training loss: 1.9390814304351807
Validation loss: 2.0802215094207437

Epoch: 6| Step: 1
Training loss: 1.870733618736267
Validation loss: 2.081744924668343

Epoch: 6| Step: 2
Training loss: 2.1869659423828125
Validation loss: 2.0845650139675347

Epoch: 6| Step: 3
Training loss: 1.141716480255127
Validation loss: 2.0787608777323077

Epoch: 6| Step: 4
Training loss: 1.4646100997924805
Validation loss: 2.060427724674184

Epoch: 6| Step: 5
Training loss: 1.6484878063201904
Validation loss: 2.0407979334554365

Epoch: 6| Step: 6
Training loss: 1.5363521575927734
Validation loss: 2.0352048822628555

Epoch: 6| Step: 7
Training loss: 1.5350689888000488
Validation loss: 2.034073316922752

Epoch: 6| Step: 8
Training loss: 1.867049217224121
Validation loss: 2.0305159784132436

Epoch: 6| Step: 9
Training loss: 2.121530055999756
Validation loss: 2.058261799555953

Epoch: 6| Step: 10
Training loss: 2.3182497024536133
Validation loss: 2.086860878493196

Epoch: 6| Step: 11
Training loss: 1.6477410793304443
Validation loss: 2.0727082888285318

Epoch: 6| Step: 12
Training loss: 1.5742186307907104
Validation loss: 2.0726136712617773

Epoch: 6| Step: 13
Training loss: 1.5618594884872437
Validation loss: 2.0680755556270642

Epoch: 285| Step: 0
Training loss: 1.0729849338531494
Validation loss: 2.088010190635599

Epoch: 6| Step: 1
Training loss: 2.3695530891418457
Validation loss: 2.0833531169481176

Epoch: 6| Step: 2
Training loss: 1.7616331577301025
Validation loss: 2.0538977038475776

Epoch: 6| Step: 3
Training loss: 1.7398567199707031
Validation loss: 2.0489083515700472

Epoch: 6| Step: 4
Training loss: 1.7712206840515137
Validation loss: 2.061205839598051

Epoch: 6| Step: 5
Training loss: 1.1894662380218506
Validation loss: 2.0658840851117204

Epoch: 6| Step: 6
Training loss: 1.4476954936981201
Validation loss: 2.0838763380563385

Epoch: 6| Step: 7
Training loss: 1.8022828102111816
Validation loss: 2.096213940651186

Epoch: 6| Step: 8
Training loss: 2.6364924907684326
Validation loss: 2.0858331700806976

Epoch: 6| Step: 9
Training loss: 1.102608323097229
Validation loss: 2.066469428359821

Epoch: 6| Step: 10
Training loss: 1.2617688179016113
Validation loss: 2.0785550404620428

Epoch: 6| Step: 11
Training loss: 1.4002017974853516
Validation loss: 2.07153090353935

Epoch: 6| Step: 12
Training loss: 2.237997055053711
Validation loss: 2.0598043344354116

Epoch: 6| Step: 13
Training loss: 3.072024345397949
Validation loss: 2.0548678546823482

Epoch: 286| Step: 0
Training loss: 1.2346903085708618
Validation loss: 2.0343004247193694

Epoch: 6| Step: 1
Training loss: 1.699077844619751
Validation loss: 2.044354418272613

Epoch: 6| Step: 2
Training loss: 1.3740849494934082
Validation loss: 2.0374228518496276

Epoch: 6| Step: 3
Training loss: 2.13997483253479
Validation loss: 2.0241967990834224

Epoch: 6| Step: 4
Training loss: 2.448028326034546
Validation loss: 2.0353460170889415

Epoch: 6| Step: 5
Training loss: 1.9769586324691772
Validation loss: 2.038651845788443

Epoch: 6| Step: 6
Training loss: 2.5838065147399902
Validation loss: 2.0566718398883777

Epoch: 6| Step: 7
Training loss: 0.9831756353378296
Validation loss: 2.0558071597929923

Epoch: 6| Step: 8
Training loss: 1.2995917797088623
Validation loss: 2.072222891674247

Epoch: 6| Step: 9
Training loss: 1.2695032358169556
Validation loss: 2.0730376602500997

Epoch: 6| Step: 10
Training loss: 1.618807315826416
Validation loss: 2.0890079980255454

Epoch: 6| Step: 11
Training loss: 2.039013147354126
Validation loss: 2.1252940931627826

Epoch: 6| Step: 12
Training loss: 1.8349746465682983
Validation loss: 2.1317821164284982

Epoch: 6| Step: 13
Training loss: 1.8810114860534668
Validation loss: 2.118344432564192

Epoch: 287| Step: 0
Training loss: 1.7514238357543945
Validation loss: 2.115545875282698

Epoch: 6| Step: 1
Training loss: 1.9166936874389648
Validation loss: 2.0784771314231296

Epoch: 6| Step: 2
Training loss: 1.7392055988311768
Validation loss: 2.1105180696774553

Epoch: 6| Step: 3
Training loss: 1.7102372646331787
Validation loss: 2.0884732456617456

Epoch: 6| Step: 4
Training loss: 1.4198564291000366
Validation loss: 2.0876474739402853

Epoch: 6| Step: 5
Training loss: 1.7801755666732788
Validation loss: 2.06047482644358

Epoch: 6| Step: 6
Training loss: 1.1053876876831055
Validation loss: 2.071150851506059

Epoch: 6| Step: 7
Training loss: 2.2365541458129883
Validation loss: 2.061263257457364

Epoch: 6| Step: 8
Training loss: 1.6460304260253906
Validation loss: 2.0704964950520504

Epoch: 6| Step: 9
Training loss: 1.5378592014312744
Validation loss: 2.072116818479312

Epoch: 6| Step: 10
Training loss: 1.8261394500732422
Validation loss: 2.065930261406847

Epoch: 6| Step: 11
Training loss: 1.6696016788482666
Validation loss: 2.051051342359153

Epoch: 6| Step: 12
Training loss: 1.8060870170593262
Validation loss: 2.0539936160528534

Epoch: 6| Step: 13
Training loss: 1.8265190124511719
Validation loss: 2.0660685057281167

Epoch: 288| Step: 0
Training loss: 2.2033743858337402
Validation loss: 2.076756121009909

Epoch: 6| Step: 1
Training loss: 1.9874217510223389
Validation loss: 2.0842630196643133

Epoch: 6| Step: 2
Training loss: 2.3318052291870117
Validation loss: 2.0746623034118326

Epoch: 6| Step: 3
Training loss: 1.852685809135437
Validation loss: 2.0632949285609747

Epoch: 6| Step: 4
Training loss: 1.2806410789489746
Validation loss: 2.0663101852581067

Epoch: 6| Step: 5
Training loss: 1.948484182357788
Validation loss: 2.060953768350745

Epoch: 6| Step: 6
Training loss: 1.674088478088379
Validation loss: 2.058318817487327

Epoch: 6| Step: 7
Training loss: 1.1421518325805664
Validation loss: 2.0562515592062347

Epoch: 6| Step: 8
Training loss: 1.5893468856811523
Validation loss: 2.0619613970479658

Epoch: 6| Step: 9
Training loss: 1.5380560159683228
Validation loss: 2.07067588708734

Epoch: 6| Step: 10
Training loss: 1.9763736724853516
Validation loss: 2.0712442974890433

Epoch: 6| Step: 11
Training loss: 0.9981685280799866
Validation loss: 2.087275589666059

Epoch: 6| Step: 12
Training loss: 1.4411423206329346
Validation loss: 2.092358563535957

Epoch: 6| Step: 13
Training loss: 2.1167705059051514
Validation loss: 2.097953168294763

Epoch: 289| Step: 0
Training loss: 1.4930170774459839
Validation loss: 2.079493486753074

Epoch: 6| Step: 1
Training loss: 2.1359703540802
Validation loss: 2.0854858057473296

Epoch: 6| Step: 2
Training loss: 1.639763355255127
Validation loss: 2.055702514545892

Epoch: 6| Step: 3
Training loss: 1.472551941871643
Validation loss: 2.0797849573114866

Epoch: 6| Step: 4
Training loss: 1.820670247077942
Validation loss: 2.069559489527056

Epoch: 6| Step: 5
Training loss: 1.9224117994308472
Validation loss: 2.066790485894808

Epoch: 6| Step: 6
Training loss: 1.9284101724624634
Validation loss: 2.06878670056661

Epoch: 6| Step: 7
Training loss: 1.5260711908340454
Validation loss: 2.0650837293235202

Epoch: 6| Step: 8
Training loss: 1.8841038942337036
Validation loss: 2.037542982767987

Epoch: 6| Step: 9
Training loss: 1.1986018419265747
Validation loss: 2.065683287958945

Epoch: 6| Step: 10
Training loss: 1.7455558776855469
Validation loss: 2.0699849949088147

Epoch: 6| Step: 11
Training loss: 1.8516240119934082
Validation loss: 2.0957029968179683

Epoch: 6| Step: 12
Training loss: 1.800861120223999
Validation loss: 2.0928296504482145

Epoch: 6| Step: 13
Training loss: 1.4822479486465454
Validation loss: 2.118183946096769

Epoch: 290| Step: 0
Training loss: 1.4437963962554932
Validation loss: 2.1102707104016374

Epoch: 6| Step: 1
Training loss: 1.5587074756622314
Validation loss: 2.121487509819769

Epoch: 6| Step: 2
Training loss: 1.3480936288833618
Validation loss: 2.109896589350957

Epoch: 6| Step: 3
Training loss: 1.678411602973938
Validation loss: 2.1118418837106354

Epoch: 6| Step: 4
Training loss: 2.5631508827209473
Validation loss: 2.1107962862137826

Epoch: 6| Step: 5
Training loss: 2.0812675952911377
Validation loss: 2.1143619065643637

Epoch: 6| Step: 6
Training loss: 1.9037166833877563
Validation loss: 2.096708487438899

Epoch: 6| Step: 7
Training loss: 1.2599165439605713
Validation loss: 2.1045128324980378

Epoch: 6| Step: 8
Training loss: 2.20648455619812
Validation loss: 2.0810994973746677

Epoch: 6| Step: 9
Training loss: 1.2284226417541504
Validation loss: 2.066940458871985

Epoch: 6| Step: 10
Training loss: 1.688300609588623
Validation loss: 2.057537001948203

Epoch: 6| Step: 11
Training loss: 1.7175228595733643
Validation loss: 2.072809143732953

Epoch: 6| Step: 12
Training loss: 1.6165106296539307
Validation loss: 2.078452733255202

Epoch: 6| Step: 13
Training loss: 1.886270523071289
Validation loss: 2.071596650667088

Epoch: 291| Step: 0
Training loss: 1.3800230026245117
Validation loss: 2.0925472551776516

Epoch: 6| Step: 1
Training loss: 1.7002689838409424
Validation loss: 2.0999199421175065

Epoch: 6| Step: 2
Training loss: 1.0715168714523315
Validation loss: 2.1053043103987172

Epoch: 6| Step: 3
Training loss: 1.6444247961044312
Validation loss: 2.085840294438024

Epoch: 6| Step: 4
Training loss: 1.3029415607452393
Validation loss: 2.087581744758032

Epoch: 6| Step: 5
Training loss: 1.5920920372009277
Validation loss: 2.079141511712023

Epoch: 6| Step: 6
Training loss: 1.9720911979675293
Validation loss: 2.098388893629915

Epoch: 6| Step: 7
Training loss: 1.0347157716751099
Validation loss: 2.057377032054368

Epoch: 6| Step: 8
Training loss: 2.477426052093506
Validation loss: 2.0621409595653577

Epoch: 6| Step: 9
Training loss: 1.9018924236297607
Validation loss: 2.084517449461004

Epoch: 6| Step: 10
Training loss: 2.1164638996124268
Validation loss: 2.0895046059803297

Epoch: 6| Step: 11
Training loss: 1.9151253700256348
Validation loss: 2.077346950448969

Epoch: 6| Step: 12
Training loss: 2.032522201538086
Validation loss: 2.070338664516326

Epoch: 6| Step: 13
Training loss: 1.640731930732727
Validation loss: 2.064102466388415

Epoch: 292| Step: 0
Training loss: 1.7419790029525757
Validation loss: 2.065074351526076

Epoch: 6| Step: 1
Training loss: 2.154663562774658
Validation loss: 2.0738873789387364

Epoch: 6| Step: 2
Training loss: 1.6353435516357422
Validation loss: 2.069984133525561

Epoch: 6| Step: 3
Training loss: 1.1551733016967773
Validation loss: 2.0826225908853675

Epoch: 6| Step: 4
Training loss: 1.0847842693328857
Validation loss: 2.0730419928027737

Epoch: 6| Step: 5
Training loss: 1.7754549980163574
Validation loss: 2.083563253443728

Epoch: 6| Step: 6
Training loss: 1.4330722093582153
Validation loss: 2.0673482494969524

Epoch: 6| Step: 7
Training loss: 1.9489340782165527
Validation loss: 2.0740575021313084

Epoch: 6| Step: 8
Training loss: 1.4646453857421875
Validation loss: 2.0583314536720194

Epoch: 6| Step: 9
Training loss: 1.4979546070098877
Validation loss: 2.0763918302392446

Epoch: 6| Step: 10
Training loss: 1.7440996170043945
Validation loss: 2.0675488877040085

Epoch: 6| Step: 11
Training loss: 1.442502498626709
Validation loss: 2.1053460362137004

Epoch: 6| Step: 12
Training loss: 2.7440104484558105
Validation loss: 2.099659045537313

Epoch: 6| Step: 13
Training loss: 1.8752198219299316
Validation loss: 2.106946029970723

Epoch: 293| Step: 0
Training loss: 1.853419542312622
Validation loss: 2.1132571620325886

Epoch: 6| Step: 1
Training loss: 1.4938006401062012
Validation loss: 2.1230400723795735

Epoch: 6| Step: 2
Training loss: 0.5587419271469116
Validation loss: 2.0997289021809897

Epoch: 6| Step: 3
Training loss: 1.6278454065322876
Validation loss: 2.0810873969908683

Epoch: 6| Step: 4
Training loss: 1.4911317825317383
Validation loss: 2.08189477715441

Epoch: 6| Step: 5
Training loss: 1.9608010053634644
Validation loss: 2.0894519705926218

Epoch: 6| Step: 6
Training loss: 2.0437395572662354
Validation loss: 2.0922601992084133

Epoch: 6| Step: 7
Training loss: 2.0839109420776367
Validation loss: 2.075737158457438

Epoch: 6| Step: 8
Training loss: 1.6396665573120117
Validation loss: 2.1099319714371876

Epoch: 6| Step: 9
Training loss: 1.1774370670318604
Validation loss: 2.10358614049932

Epoch: 6| Step: 10
Training loss: 2.2149758338928223
Validation loss: 2.102672774304626

Epoch: 6| Step: 11
Training loss: 1.0441734790802002
Validation loss: 2.0946796530036518

Epoch: 6| Step: 12
Training loss: 2.5258240699768066
Validation loss: 2.0629906436448455

Epoch: 6| Step: 13
Training loss: 2.2075235843658447
Validation loss: 2.076023333816118

Epoch: 294| Step: 0
Training loss: 2.1692628860473633
Validation loss: 2.073750090855424

Epoch: 6| Step: 1
Training loss: 2.0560622215270996
Validation loss: 2.0565504976498183

Epoch: 6| Step: 2
Training loss: 1.475985050201416
Validation loss: 2.0654208096124793

Epoch: 6| Step: 3
Training loss: 1.8957061767578125
Validation loss: 2.063880656355171

Epoch: 6| Step: 4
Training loss: 1.4960854053497314
Validation loss: 2.048849880054433

Epoch: 6| Step: 5
Training loss: 1.4842994213104248
Validation loss: 2.05956333427019

Epoch: 6| Step: 6
Training loss: 2.034822940826416
Validation loss: 2.06087322901654

Epoch: 6| Step: 7
Training loss: 1.2115976810455322
Validation loss: 2.0440680980682373

Epoch: 6| Step: 8
Training loss: 1.3930648565292358
Validation loss: 2.049178349074497

Epoch: 6| Step: 9
Training loss: 1.3668437004089355
Validation loss: 2.062882213182347

Epoch: 6| Step: 10
Training loss: 1.763047695159912
Validation loss: 2.0553888492686774

Epoch: 6| Step: 11
Training loss: 1.3567830324172974
Validation loss: 2.0789787000225437

Epoch: 6| Step: 12
Training loss: 1.8745050430297852
Validation loss: 2.1067776756901897

Epoch: 6| Step: 13
Training loss: 2.0983128547668457
Validation loss: 2.103126971952377

Epoch: 295| Step: 0
Training loss: 1.4994148015975952
Validation loss: 2.1100053518049178

Epoch: 6| Step: 1
Training loss: 2.380974292755127
Validation loss: 2.098505953306793

Epoch: 6| Step: 2
Training loss: 1.2787251472473145
Validation loss: 2.0987631351717058

Epoch: 6| Step: 3
Training loss: 1.1393041610717773
Validation loss: 2.0932848491976337

Epoch: 6| Step: 4
Training loss: 1.4655790328979492
Validation loss: 2.0945350252172

Epoch: 6| Step: 5
Training loss: 2.049579381942749
Validation loss: 2.1136662267869517

Epoch: 6| Step: 6
Training loss: 1.8503491878509521
Validation loss: 2.1303963968830724

Epoch: 6| Step: 7
Training loss: 2.3117594718933105
Validation loss: 2.140016358385804

Epoch: 6| Step: 8
Training loss: 1.4379713535308838
Validation loss: 2.1444546458541707

Epoch: 6| Step: 9
Training loss: 1.4021846055984497
Validation loss: 2.1033622039261686

Epoch: 6| Step: 10
Training loss: 1.5020647048950195
Validation loss: 2.0898338107652563

Epoch: 6| Step: 11
Training loss: 2.1514477729797363
Validation loss: 2.0835793172159502

Epoch: 6| Step: 12
Training loss: 1.1207294464111328
Validation loss: 2.0639415248747794

Epoch: 6| Step: 13
Training loss: 1.6887803077697754
Validation loss: 2.0670030847672494

Epoch: 296| Step: 0
Training loss: 1.5471521615982056
Validation loss: 2.077865146821545

Epoch: 6| Step: 1
Training loss: 1.2894490957260132
Validation loss: 2.0510949806500505

Epoch: 6| Step: 2
Training loss: 2.4931013584136963
Validation loss: 2.0642955405737764

Epoch: 6| Step: 3
Training loss: 1.7555670738220215
Validation loss: 2.046451203284725

Epoch: 6| Step: 4
Training loss: 0.9202466011047363
Validation loss: 2.0766363528466996

Epoch: 6| Step: 5
Training loss: 1.5690553188323975
Validation loss: 2.075842841978996

Epoch: 6| Step: 6
Training loss: 2.473665714263916
Validation loss: 2.079463046084168

Epoch: 6| Step: 7
Training loss: 2.1415934562683105
Validation loss: 2.083183160392187

Epoch: 6| Step: 8
Training loss: 1.501939058303833
Validation loss: 2.0928733310391827

Epoch: 6| Step: 9
Training loss: 1.5865967273712158
Validation loss: 2.0832229250220844

Epoch: 6| Step: 10
Training loss: 0.9603275656700134
Validation loss: 2.0738126154868834

Epoch: 6| Step: 11
Training loss: 1.788002371788025
Validation loss: 2.071223762727553

Epoch: 6| Step: 12
Training loss: 1.1304643154144287
Validation loss: 2.073557779353152

Epoch: 6| Step: 13
Training loss: 2.2026989459991455
Validation loss: 2.0740088032137964

Epoch: 297| Step: 0
Training loss: 1.6255074739456177
Validation loss: 2.0662890788047545

Epoch: 6| Step: 1
Training loss: 1.978060245513916
Validation loss: 2.074922823136853

Epoch: 6| Step: 2
Training loss: 1.8943949937820435
Validation loss: 2.053106810456963

Epoch: 6| Step: 3
Training loss: 1.210815668106079
Validation loss: 2.060896861937738

Epoch: 6| Step: 4
Training loss: 2.1433539390563965
Validation loss: 2.048005493738318

Epoch: 6| Step: 5
Training loss: 1.9015095233917236
Validation loss: 2.0248206635957122

Epoch: 6| Step: 6
Training loss: 1.5388970375061035
Validation loss: 2.0241778922337357

Epoch: 6| Step: 7
Training loss: 1.9918946027755737
Validation loss: 2.0312735073028074

Epoch: 6| Step: 8
Training loss: 1.064272403717041
Validation loss: 2.0263586928767543

Epoch: 6| Step: 9
Training loss: 1.6403958797454834
Validation loss: 2.0211391910429923

Epoch: 6| Step: 10
Training loss: 1.3103697299957275
Validation loss: 2.0377906804443686

Epoch: 6| Step: 11
Training loss: 1.414368748664856
Validation loss: 2.069875709472164

Epoch: 6| Step: 12
Training loss: 1.3290886878967285
Validation loss: 2.078196648628481

Epoch: 6| Step: 13
Training loss: 2.46026611328125
Validation loss: 2.078981457218047

Epoch: 298| Step: 0
Training loss: 1.4713250398635864
Validation loss: 2.102473497390747

Epoch: 6| Step: 1
Training loss: 1.2568538188934326
Validation loss: 2.1114683535791214

Epoch: 6| Step: 2
Training loss: 1.8667967319488525
Validation loss: 2.122932231554421

Epoch: 6| Step: 3
Training loss: 1.7574938535690308
Validation loss: 2.13963439900388

Epoch: 6| Step: 4
Training loss: 1.776924729347229
Validation loss: 2.1412566733616654

Epoch: 6| Step: 5
Training loss: 1.877104640007019
Validation loss: 2.1246538521141134

Epoch: 6| Step: 6
Training loss: 1.0738976001739502
Validation loss: 2.116941249498757

Epoch: 6| Step: 7
Training loss: 1.6887612342834473
Validation loss: 2.104416214009767

Epoch: 6| Step: 8
Training loss: 2.2056353092193604
Validation loss: 2.082970275673815

Epoch: 6| Step: 9
Training loss: 1.6524646282196045
Validation loss: 2.078375699699566

Epoch: 6| Step: 10
Training loss: 1.7046482563018799
Validation loss: 2.072159477459487

Epoch: 6| Step: 11
Training loss: 1.6583770513534546
Validation loss: 2.073089794446063

Epoch: 6| Step: 12
Training loss: 1.7330241203308105
Validation loss: 2.0612370250045613

Epoch: 6| Step: 13
Training loss: 1.089760422706604
Validation loss: 2.0575679450906734

Epoch: 299| Step: 0
Training loss: 1.3311527967453003
Validation loss: 2.0516959979969966

Epoch: 6| Step: 1
Training loss: 1.8986828327178955
Validation loss: 2.062935140825087

Epoch: 6| Step: 2
Training loss: 1.399946689605713
Validation loss: 2.0503729287014214

Epoch: 6| Step: 3
Training loss: 1.302621841430664
Validation loss: 2.063807246505573

Epoch: 6| Step: 4
Training loss: 2.0832977294921875
Validation loss: 2.0751092433929443

Epoch: 6| Step: 5
Training loss: 1.899245262145996
Validation loss: 2.0624822519158803

Epoch: 6| Step: 6
Training loss: 1.3334126472473145
Validation loss: 2.0692845493234615

Epoch: 6| Step: 7
Training loss: 1.2606480121612549
Validation loss: 2.0881288025968816

Epoch: 6| Step: 8
Training loss: 1.797147512435913
Validation loss: 2.0853671899405857

Epoch: 6| Step: 9
Training loss: 1.855886459350586
Validation loss: 2.088859014613654

Epoch: 6| Step: 10
Training loss: 2.3589072227478027
Validation loss: 2.095440141616329

Epoch: 6| Step: 11
Training loss: 1.515825629234314
Validation loss: 2.0927359865557764

Epoch: 6| Step: 12
Training loss: 1.4567791223526
Validation loss: 2.1028815956525904

Epoch: 6| Step: 13
Training loss: 1.2595759630203247
Validation loss: 2.099578986885727

Epoch: 300| Step: 0
Training loss: 1.6930153369903564
Validation loss: 2.1183483921071535

Epoch: 6| Step: 1
Training loss: 1.060250997543335
Validation loss: 2.0898055953364216

Epoch: 6| Step: 2
Training loss: 1.6472835540771484
Validation loss: 2.0697399775187173

Epoch: 6| Step: 3
Training loss: 2.0514421463012695
Validation loss: 2.055188391798286

Epoch: 6| Step: 4
Training loss: 1.077412724494934
Validation loss: 2.050565896495696

Epoch: 6| Step: 5
Training loss: 1.9806544780731201
Validation loss: 2.0619045970260457

Epoch: 6| Step: 6
Training loss: 1.4597145318984985
Validation loss: 2.062301778024243

Epoch: 6| Step: 7
Training loss: 2.1232032775878906
Validation loss: 2.04922406647795

Epoch: 6| Step: 8
Training loss: 1.850296974182129
Validation loss: 2.056789311029578

Epoch: 6| Step: 9
Training loss: 1.358634352684021
Validation loss: 2.054180952810472

Epoch: 6| Step: 10
Training loss: 1.122701644897461
Validation loss: 2.0667206625784598

Epoch: 6| Step: 11
Training loss: 1.9035038948059082
Validation loss: 2.05696492169493

Epoch: 6| Step: 12
Training loss: 1.8595763444900513
Validation loss: 2.0723220994395595

Epoch: 6| Step: 13
Training loss: 1.8047093152999878
Validation loss: 2.0747786926966842

Epoch: 301| Step: 0
Training loss: 1.8484723567962646
Validation loss: 2.0810113235186507

Epoch: 6| Step: 1
Training loss: 1.3338838815689087
Validation loss: 2.0987872949210544

Epoch: 6| Step: 2
Training loss: 1.7396656274795532
Validation loss: 2.082358806363998

Epoch: 6| Step: 3
Training loss: 1.4511886835098267
Validation loss: 2.1040044330781504

Epoch: 6| Step: 4
Training loss: 1.7573397159576416
Validation loss: 2.1041309256707468

Epoch: 6| Step: 5
Training loss: 1.6666648387908936
Validation loss: 2.0899533123098393

Epoch: 6| Step: 6
Training loss: 1.6218883991241455
Validation loss: 2.0929252075892624

Epoch: 6| Step: 7
Training loss: 1.5164073705673218
Validation loss: 2.0699038018462477

Epoch: 6| Step: 8
Training loss: 1.0750244855880737
Validation loss: 2.0740561805745608

Epoch: 6| Step: 9
Training loss: 1.6532025337219238
Validation loss: 2.085221008587909

Epoch: 6| Step: 10
Training loss: 1.007891297340393
Validation loss: 2.10118120203736

Epoch: 6| Step: 11
Training loss: 2.201263904571533
Validation loss: 2.1063642142921366

Epoch: 6| Step: 12
Training loss: 2.1885621547698975
Validation loss: 2.1116726629195677

Epoch: 6| Step: 13
Training loss: 1.6216861009597778
Validation loss: 2.104992672961245

Epoch: 302| Step: 0
Training loss: 1.6374953985214233
Validation loss: 2.1089877492638043

Epoch: 6| Step: 1
Training loss: 1.38495934009552
Validation loss: 2.143322438322088

Epoch: 6| Step: 2
Training loss: 1.0894451141357422
Validation loss: 2.130725778559203

Epoch: 6| Step: 3
Training loss: 2.291304349899292
Validation loss: 2.1251963953818045

Epoch: 6| Step: 4
Training loss: 1.7861813306808472
Validation loss: 2.1258995584262315

Epoch: 6| Step: 5
Training loss: 1.6447737216949463
Validation loss: 2.123998906022759

Epoch: 6| Step: 6
Training loss: 1.3864600658416748
Validation loss: 2.101525004192065

Epoch: 6| Step: 7
Training loss: 1.372077226638794
Validation loss: 2.0967678293105094

Epoch: 6| Step: 8
Training loss: 1.6488384008407593
Validation loss: 2.0843269760890673

Epoch: 6| Step: 9
Training loss: 1.8052219152450562
Validation loss: 2.0846176096188125

Epoch: 6| Step: 10
Training loss: 1.5321953296661377
Validation loss: 2.0782358864302277

Epoch: 6| Step: 11
Training loss: 1.8025908470153809
Validation loss: 2.060152816516097

Epoch: 6| Step: 12
Training loss: 1.5572763681411743
Validation loss: 2.068772776152498

Epoch: 6| Step: 13
Training loss: 1.5617196559906006
Validation loss: 2.0733751609761226

Epoch: 303| Step: 0
Training loss: 1.4196736812591553
Validation loss: 2.07898792400155

Epoch: 6| Step: 1
Training loss: 1.5913220643997192
Validation loss: 2.078562149437525

Epoch: 6| Step: 2
Training loss: 1.63949716091156
Validation loss: 2.0856798566797727

Epoch: 6| Step: 3
Training loss: 1.5333476066589355
Validation loss: 2.08350710715017

Epoch: 6| Step: 4
Training loss: 1.2482647895812988
Validation loss: 2.0628680439405542

Epoch: 6| Step: 5
Training loss: 1.8271911144256592
Validation loss: 2.070826376638105

Epoch: 6| Step: 6
Training loss: 1.796413540840149
Validation loss: 2.0925940416192494

Epoch: 6| Step: 7
Training loss: 1.2780474424362183
Validation loss: 2.0913121777196086

Epoch: 6| Step: 8
Training loss: 1.4613990783691406
Validation loss: 2.094930345012296

Epoch: 6| Step: 9
Training loss: 1.9222595691680908
Validation loss: 2.0927864864308345

Epoch: 6| Step: 10
Training loss: 1.7759144306182861
Validation loss: 2.09273237182248

Epoch: 6| Step: 11
Training loss: 1.768757939338684
Validation loss: 2.1049526583763862

Epoch: 6| Step: 12
Training loss: 1.5800371170043945
Validation loss: 2.089343476039107

Epoch: 6| Step: 13
Training loss: 1.659087061882019
Validation loss: 2.093946856837119

Epoch: 304| Step: 0
Training loss: 1.423454761505127
Validation loss: 2.075167752081348

Epoch: 6| Step: 1
Training loss: 1.2653264999389648
Validation loss: 2.0735618837418093

Epoch: 6| Step: 2
Training loss: 1.610639214515686
Validation loss: 2.0568852962986117

Epoch: 6| Step: 3
Training loss: 1.5028700828552246
Validation loss: 2.064532685023482

Epoch: 6| Step: 4
Training loss: 1.7465717792510986
Validation loss: 2.0644388301398164

Epoch: 6| Step: 5
Training loss: 1.7860852479934692
Validation loss: 2.0713601573821037

Epoch: 6| Step: 6
Training loss: 1.206702470779419
Validation loss: 2.0702088750818723

Epoch: 6| Step: 7
Training loss: 2.3808116912841797
Validation loss: 2.0718645818771853

Epoch: 6| Step: 8
Training loss: 1.7446134090423584
Validation loss: 2.063811820040467

Epoch: 6| Step: 9
Training loss: 1.3083689212799072
Validation loss: 2.0545653553419214

Epoch: 6| Step: 10
Training loss: 2.189439296722412
Validation loss: 2.0591000741527927

Epoch: 6| Step: 11
Training loss: 1.7394081354141235
Validation loss: 2.077857909664031

Epoch: 6| Step: 12
Training loss: 1.440320372581482
Validation loss: 2.059745786010578

Epoch: 6| Step: 13
Training loss: 1.2232776880264282
Validation loss: 2.0639625736462173

Epoch: 305| Step: 0
Training loss: 1.994554042816162
Validation loss: 2.0779810131237073

Epoch: 6| Step: 1
Training loss: 1.6157476902008057
Validation loss: 2.0655609946097098

Epoch: 6| Step: 2
Training loss: 1.3658647537231445
Validation loss: 2.06591603320132

Epoch: 6| Step: 3
Training loss: 1.8770453929901123
Validation loss: 2.0905200768542547

Epoch: 6| Step: 4
Training loss: 2.1697115898132324
Validation loss: 2.0982450951812086

Epoch: 6| Step: 5
Training loss: 0.7832369208335876
Validation loss: 2.1160712280581073

Epoch: 6| Step: 6
Training loss: 1.415192723274231
Validation loss: 2.1285361730924217

Epoch: 6| Step: 7
Training loss: 1.062809944152832
Validation loss: 2.1134250266577608

Epoch: 6| Step: 8
Training loss: 1.509007453918457
Validation loss: 2.123248584808842

Epoch: 6| Step: 9
Training loss: 1.7805140018463135
Validation loss: 2.1229402454950477

Epoch: 6| Step: 10
Training loss: 1.451654076576233
Validation loss: 2.12525350047696

Epoch: 6| Step: 11
Training loss: 2.0291237831115723
Validation loss: 2.1029617042951685

Epoch: 6| Step: 12
Training loss: 2.125687599182129
Validation loss: 2.0860429527939006

Epoch: 6| Step: 13
Training loss: 0.9951252341270447
Validation loss: 2.085286259651184

Epoch: 306| Step: 0
Training loss: 1.1199705600738525
Validation loss: 2.086359644448885

Epoch: 6| Step: 1
Training loss: 1.8717658519744873
Validation loss: 2.0736685978469027

Epoch: 6| Step: 2
Training loss: 1.4048171043395996
Validation loss: 2.0820630647802867

Epoch: 6| Step: 3
Training loss: 1.3150378465652466
Validation loss: 2.0889934967922907

Epoch: 6| Step: 4
Training loss: 1.5053856372833252
Validation loss: 2.0893813140930666

Epoch: 6| Step: 5
Training loss: 1.9051644802093506
Validation loss: 2.0797564727003857

Epoch: 6| Step: 6
Training loss: 1.6702263355255127
Validation loss: 2.09909753389256

Epoch: 6| Step: 7
Training loss: 1.5866341590881348
Validation loss: 2.091676481308476

Epoch: 6| Step: 8
Training loss: 1.60260808467865
Validation loss: 2.098119507553757

Epoch: 6| Step: 9
Training loss: 1.248732566833496
Validation loss: 2.0933773953427552

Epoch: 6| Step: 10
Training loss: 1.4997773170471191
Validation loss: 2.0923382261747956

Epoch: 6| Step: 11
Training loss: 1.5569519996643066
Validation loss: 2.073609208547941

Epoch: 6| Step: 12
Training loss: 2.2609364986419678
Validation loss: 2.0818797747294107

Epoch: 6| Step: 13
Training loss: 1.5466210842132568
Validation loss: 2.0807807522435344

Epoch: 307| Step: 0
Training loss: 1.4081693887710571
Validation loss: 2.062033933977927

Epoch: 6| Step: 1
Training loss: 1.4259744882583618
Validation loss: 2.052337351665702

Epoch: 6| Step: 2
Training loss: 1.7250146865844727
Validation loss: 2.0777381568826656

Epoch: 6| Step: 3
Training loss: 1.2522286176681519
Validation loss: 2.0548388727249636

Epoch: 6| Step: 4
Training loss: 1.1386165618896484
Validation loss: 2.0713810702805877

Epoch: 6| Step: 5
Training loss: 1.2860819101333618
Validation loss: 2.0657448896797757

Epoch: 6| Step: 6
Training loss: 1.2630085945129395
Validation loss: 2.0909181922994633

Epoch: 6| Step: 7
Training loss: 1.5923405885696411
Validation loss: 2.108002411421909

Epoch: 6| Step: 8
Training loss: 1.9980026483535767
Validation loss: 2.1094019887267903

Epoch: 6| Step: 9
Training loss: 2.0223450660705566
Validation loss: 2.1234301777296167

Epoch: 6| Step: 10
Training loss: 1.9650222063064575
Validation loss: 2.120034074270597

Epoch: 6| Step: 11
Training loss: 2.147913694381714
Validation loss: 2.1192970045151247

Epoch: 6| Step: 12
Training loss: 1.3730823993682861
Validation loss: 2.088869215339743

Epoch: 6| Step: 13
Training loss: 1.6264220476150513
Validation loss: 2.0915498964248167

Epoch: 308| Step: 0
Training loss: 1.9668159484863281
Validation loss: 2.102548130096928

Epoch: 6| Step: 1
Training loss: 1.7752448320388794
Validation loss: 2.091093945246871

Epoch: 6| Step: 2
Training loss: 1.659642219543457
Validation loss: 2.0970891316731772

Epoch: 6| Step: 3
Training loss: 2.235781669616699
Validation loss: 2.0743551510636524

Epoch: 6| Step: 4
Training loss: 1.2952302694320679
Validation loss: 2.0742753039124193

Epoch: 6| Step: 5
Training loss: 1.1411068439483643
Validation loss: 2.06260189958798

Epoch: 6| Step: 6
Training loss: 1.0485388040542603
Validation loss: 2.0722122474383284

Epoch: 6| Step: 7
Training loss: 1.744065284729004
Validation loss: 2.1001047254890524

Epoch: 6| Step: 8
Training loss: 1.4374933242797852
Validation loss: 2.0895658308459866

Epoch: 6| Step: 9
Training loss: 1.211370825767517
Validation loss: 2.0925271177804596

Epoch: 6| Step: 10
Training loss: 1.6254606246948242
Validation loss: 2.140500601901803

Epoch: 6| Step: 11
Training loss: 2.1388890743255615
Validation loss: 2.129934558304407

Epoch: 6| Step: 12
Training loss: 1.1721580028533936
Validation loss: 2.115316499945938

Epoch: 6| Step: 13
Training loss: 1.4168338775634766
Validation loss: 2.1324999870792514

Epoch: 309| Step: 0
Training loss: 1.8345117568969727
Validation loss: 2.1276754025490052

Epoch: 6| Step: 1
Training loss: 1.786805272102356
Validation loss: 2.1215357190819195

Epoch: 6| Step: 2
Training loss: 1.0213754177093506
Validation loss: 2.1275550344938874

Epoch: 6| Step: 3
Training loss: 1.7083110809326172
Validation loss: 2.1068380699362805

Epoch: 6| Step: 4
Training loss: 1.535775899887085
Validation loss: 2.1048092662647204

Epoch: 6| Step: 5
Training loss: 1.4075567722320557
Validation loss: 2.09028442957068

Epoch: 6| Step: 6
Training loss: 1.6192798614501953
Validation loss: 2.0712653924060125

Epoch: 6| Step: 7
Training loss: 1.178990364074707
Validation loss: 2.057726449863885

Epoch: 6| Step: 8
Training loss: 2.28245210647583
Validation loss: 2.0704212957812893

Epoch: 6| Step: 9
Training loss: 1.3256492614746094
Validation loss: 2.0613267831904913

Epoch: 6| Step: 10
Training loss: 1.436051845550537
Validation loss: 2.0529886881510415

Epoch: 6| Step: 11
Training loss: 1.2944893836975098
Validation loss: 2.080413661977296

Epoch: 6| Step: 12
Training loss: 1.8146660327911377
Validation loss: 2.068066159884135

Epoch: 6| Step: 13
Training loss: 1.60767662525177
Validation loss: 2.059854935574275

Epoch: 310| Step: 0
Training loss: 1.6702156066894531
Validation loss: 2.0833295647815993

Epoch: 6| Step: 1
Training loss: 1.8998236656188965
Validation loss: 2.0673543035343127

Epoch: 6| Step: 2
Training loss: 1.2257434129714966
Validation loss: 2.089736734667132

Epoch: 6| Step: 3
Training loss: 1.6756105422973633
Validation loss: 2.0675642567296184

Epoch: 6| Step: 4
Training loss: 1.3407235145568848
Validation loss: 2.0785143067759853

Epoch: 6| Step: 5
Training loss: 1.7580446004867554
Validation loss: 2.0974051375542917

Epoch: 6| Step: 6
Training loss: 1.5340365171432495
Validation loss: 2.1185445682976836

Epoch: 6| Step: 7
Training loss: 1.8597846031188965
Validation loss: 2.095881772297685

Epoch: 6| Step: 8
Training loss: 1.4527273178100586
Validation loss: 2.0970102920327136

Epoch: 6| Step: 9
Training loss: 1.203488826751709
Validation loss: 2.10850876890203

Epoch: 6| Step: 10
Training loss: 1.752305030822754
Validation loss: 2.10682967657684

Epoch: 6| Step: 11
Training loss: 1.409119725227356
Validation loss: 2.1027696299296554

Epoch: 6| Step: 12
Training loss: 1.5987858772277832
Validation loss: 2.123208368978193

Epoch: 6| Step: 13
Training loss: 1.307119369506836
Validation loss: 2.1268128989845194

Epoch: 311| Step: 0
Training loss: 2.2720680236816406
Validation loss: 2.1093255601903445

Epoch: 6| Step: 1
Training loss: 1.1909945011138916
Validation loss: 2.0955360448488625

Epoch: 6| Step: 2
Training loss: 1.1105607748031616
Validation loss: 2.1193422079086304

Epoch: 6| Step: 3
Training loss: 1.5044786930084229
Validation loss: 2.112317018611457

Epoch: 6| Step: 4
Training loss: 1.215402364730835
Validation loss: 2.129671678748182

Epoch: 6| Step: 5
Training loss: 2.094479560852051
Validation loss: 2.125827532942577

Epoch: 6| Step: 6
Training loss: 1.2028238773345947
Validation loss: 2.12239178534477

Epoch: 6| Step: 7
Training loss: 1.2818493843078613
Validation loss: 2.11671713090712

Epoch: 6| Step: 8
Training loss: 1.3399970531463623
Validation loss: 2.0956076947591638

Epoch: 6| Step: 9
Training loss: 2.2508392333984375
Validation loss: 2.0984848737716675

Epoch: 6| Step: 10
Training loss: 2.0655932426452637
Validation loss: 2.072735917183661

Epoch: 6| Step: 11
Training loss: 1.3906042575836182
Validation loss: 2.057036171677292

Epoch: 6| Step: 12
Training loss: 1.642371654510498
Validation loss: 2.050256303561631

Epoch: 6| Step: 13
Training loss: 1.3302223682403564
Validation loss: 2.0729920095013035

Epoch: 312| Step: 0
Training loss: 1.6800280809402466
Validation loss: 2.0974994039022796

Epoch: 6| Step: 1
Training loss: 1.4059417247772217
Validation loss: 2.105087903238112

Epoch: 6| Step: 2
Training loss: 1.3749642372131348
Validation loss: 2.081608194176869

Epoch: 6| Step: 3
Training loss: 1.4048614501953125
Validation loss: 2.081665228771907

Epoch: 6| Step: 4
Training loss: 1.3708679676055908
Validation loss: 2.093825283870902

Epoch: 6| Step: 5
Training loss: 1.6422209739685059
Validation loss: 2.0978270166663715

Epoch: 6| Step: 6
Training loss: 1.2686519622802734
Validation loss: 2.1154756405020274

Epoch: 6| Step: 7
Training loss: 1.7878170013427734
Validation loss: 2.0858713324351976

Epoch: 6| Step: 8
Training loss: 1.5105485916137695
Validation loss: 2.0874517630505305

Epoch: 6| Step: 9
Training loss: 1.4625306129455566
Validation loss: 2.0833154147671116

Epoch: 6| Step: 10
Training loss: 1.6503429412841797
Validation loss: 2.0741764576204362

Epoch: 6| Step: 11
Training loss: 2.1087722778320312
Validation loss: 2.0829108850930327

Epoch: 6| Step: 12
Training loss: 1.455787181854248
Validation loss: 2.0787523331180697

Epoch: 6| Step: 13
Training loss: 2.142817497253418
Validation loss: 2.109043453329353

Epoch: 313| Step: 0
Training loss: 1.676134467124939
Validation loss: 2.095873253319853

Epoch: 6| Step: 1
Training loss: 1.5527050495147705
Validation loss: 2.1192131875663676

Epoch: 6| Step: 2
Training loss: 1.9403221607208252
Validation loss: 2.1163980640390867

Epoch: 6| Step: 3
Training loss: 1.2286696434020996
Validation loss: 2.126000181321175

Epoch: 6| Step: 4
Training loss: 1.7765437364578247
Validation loss: 2.112159913586032

Epoch: 6| Step: 5
Training loss: 1.0074706077575684
Validation loss: 2.1049377456788094

Epoch: 6| Step: 6
Training loss: 1.810654640197754
Validation loss: 2.1014456851508028

Epoch: 6| Step: 7
Training loss: 1.3901267051696777
Validation loss: 2.0957656855224283

Epoch: 6| Step: 8
Training loss: 1.1099764108657837
Validation loss: 2.0988639529033373

Epoch: 6| Step: 9
Training loss: 1.4216747283935547
Validation loss: 2.0868791111053957

Epoch: 6| Step: 10
Training loss: 1.3302175998687744
Validation loss: 2.1050149484347274

Epoch: 6| Step: 11
Training loss: 2.299321174621582
Validation loss: 2.0935872049741846

Epoch: 6| Step: 12
Training loss: 1.6162724494934082
Validation loss: 2.104796437806981

Epoch: 6| Step: 13
Training loss: 1.6009409427642822
Validation loss: 2.098360143682008

Epoch: 314| Step: 0
Training loss: 0.8755592107772827
Validation loss: 2.0865891825768257

Epoch: 6| Step: 1
Training loss: 1.2530059814453125
Validation loss: 2.0709122765448784

Epoch: 6| Step: 2
Training loss: 2.1439476013183594
Validation loss: 2.0805594049474245

Epoch: 6| Step: 3
Training loss: 1.9647235870361328
Validation loss: 2.0695920862177366

Epoch: 6| Step: 4
Training loss: 1.6543577909469604
Validation loss: 2.075992147127787

Epoch: 6| Step: 5
Training loss: 1.406524896621704
Validation loss: 2.095225400822137

Epoch: 6| Step: 6
Training loss: 1.198275089263916
Validation loss: 2.0889112308461177

Epoch: 6| Step: 7
Training loss: 1.982898473739624
Validation loss: 2.0888884375172276

Epoch: 6| Step: 8
Training loss: 1.7086548805236816
Validation loss: 2.0780469679063365

Epoch: 6| Step: 9
Training loss: 1.1715264320373535
Validation loss: 2.078838609880017

Epoch: 6| Step: 10
Training loss: 0.973318338394165
Validation loss: 2.087420149516034

Epoch: 6| Step: 11
Training loss: 1.4823169708251953
Validation loss: 2.0824762800688386

Epoch: 6| Step: 12
Training loss: 1.59651517868042
Validation loss: 2.0996341859140704

Epoch: 6| Step: 13
Training loss: 2.3150689601898193
Validation loss: 2.079281673636488

Epoch: 315| Step: 0
Training loss: 1.0483022928237915
Validation loss: 2.0693775633329987

Epoch: 6| Step: 1
Training loss: 1.3220857381820679
Validation loss: 2.0604724678941952

Epoch: 6| Step: 2
Training loss: 1.8257113695144653
Validation loss: 2.088926886999479

Epoch: 6| Step: 3
Training loss: 1.9889967441558838
Validation loss: 2.076608545036726

Epoch: 6| Step: 4
Training loss: 1.3203697204589844
Validation loss: 2.1021081965456725

Epoch: 6| Step: 5
Training loss: 1.586338758468628
Validation loss: 2.090916795115317

Epoch: 6| Step: 6
Training loss: 1.5709309577941895
Validation loss: 2.0777760756913053

Epoch: 6| Step: 7
Training loss: 1.25596284866333
Validation loss: 2.092293780337098

Epoch: 6| Step: 8
Training loss: 1.4384814500808716
Validation loss: 2.078405726340509

Epoch: 6| Step: 9
Training loss: 2.0405654907226562
Validation loss: 2.0871151467805267

Epoch: 6| Step: 10
Training loss: 1.434241771697998
Validation loss: 2.076658656520228

Epoch: 6| Step: 11
Training loss: 1.9704492092132568
Validation loss: 2.0657769172422347

Epoch: 6| Step: 12
Training loss: 1.274111270904541
Validation loss: 2.0822676381757184

Epoch: 6| Step: 13
Training loss: 1.648362636566162
Validation loss: 2.0642801638572448

Epoch: 316| Step: 0
Training loss: 2.126047134399414
Validation loss: 2.0750690942169516

Epoch: 6| Step: 1
Training loss: 1.8007137775421143
Validation loss: 2.0732728512056413

Epoch: 6| Step: 2
Training loss: 1.405548095703125
Validation loss: 2.107695566710605

Epoch: 6| Step: 3
Training loss: 1.812662124633789
Validation loss: 2.100685554165994

Epoch: 6| Step: 4
Training loss: 1.2801003456115723
Validation loss: 2.1127497829416746

Epoch: 6| Step: 5
Training loss: 1.7849385738372803
Validation loss: 2.1066344630333687

Epoch: 6| Step: 6
Training loss: 1.0448634624481201
Validation loss: 2.1085138090195192

Epoch: 6| Step: 7
Training loss: 1.1223270893096924
Validation loss: 2.12117124372913

Epoch: 6| Step: 8
Training loss: 1.7326009273529053
Validation loss: 2.1070665813261464

Epoch: 6| Step: 9
Training loss: 1.552968144416809
Validation loss: 2.1025645271424325

Epoch: 6| Step: 10
Training loss: 0.8416628241539001
Validation loss: 2.09943030341979

Epoch: 6| Step: 11
Training loss: 1.5713495016098022
Validation loss: 2.086839001665833

Epoch: 6| Step: 12
Training loss: 1.7822296619415283
Validation loss: 2.0865723317669285

Epoch: 6| Step: 13
Training loss: 1.6510366201400757
Validation loss: 2.0817041781640824

Epoch: 317| Step: 0
Training loss: 1.5206809043884277
Validation loss: 2.090520674182523

Epoch: 6| Step: 1
Training loss: 1.2315025329589844
Validation loss: 2.0665166070384364

Epoch: 6| Step: 2
Training loss: 1.6696674823760986
Validation loss: 2.0663016662802747

Epoch: 6| Step: 3
Training loss: 1.7393529415130615
Validation loss: 2.0834698664244784

Epoch: 6| Step: 4
Training loss: 1.897855281829834
Validation loss: 2.0896717412497408

Epoch: 6| Step: 5
Training loss: 1.3059293031692505
Validation loss: 2.084695716058054

Epoch: 6| Step: 6
Training loss: 1.4388132095336914
Validation loss: 2.085277171545131

Epoch: 6| Step: 7
Training loss: 1.3109899759292603
Validation loss: 2.111556867117523

Epoch: 6| Step: 8
Training loss: 1.6461155414581299
Validation loss: 2.113048912376486

Epoch: 6| Step: 9
Training loss: 1.2716028690338135
Validation loss: 2.1156461033769833

Epoch: 6| Step: 10
Training loss: 1.4909310340881348
Validation loss: 2.1080896764673214

Epoch: 6| Step: 11
Training loss: 1.5445688962936401
Validation loss: 2.116154284887416

Epoch: 6| Step: 12
Training loss: 1.4182400703430176
Validation loss: 2.1185659490605837

Epoch: 6| Step: 13
Training loss: 1.8317031860351562
Validation loss: 2.1287204552722234

Epoch: 318| Step: 0
Training loss: 1.363229513168335
Validation loss: 2.0872657222132527

Epoch: 6| Step: 1
Training loss: 1.4094703197479248
Validation loss: 2.070415494262531

Epoch: 6| Step: 2
Training loss: 1.4939112663269043
Validation loss: 2.057275718258273

Epoch: 6| Step: 3
Training loss: 1.652616262435913
Validation loss: 2.0551865690497944

Epoch: 6| Step: 4
Training loss: 1.2925169467926025
Validation loss: 2.0448725915724233

Epoch: 6| Step: 5
Training loss: 2.083038806915283
Validation loss: 2.0434767020645963

Epoch: 6| Step: 6
Training loss: 1.7025538682937622
Validation loss: 2.014868954176544

Epoch: 6| Step: 7
Training loss: 1.4510903358459473
Validation loss: 2.025362809499105

Epoch: 6| Step: 8
Training loss: 1.670093059539795
Validation loss: 2.041986124489897

Epoch: 6| Step: 9
Training loss: 1.123311996459961
Validation loss: 2.0518962952398483

Epoch: 6| Step: 10
Training loss: 1.42341947555542
Validation loss: 2.055443407386862

Epoch: 6| Step: 11
Training loss: 1.1738604307174683
Validation loss: 2.0937686235673967

Epoch: 6| Step: 12
Training loss: 1.5660206079483032
Validation loss: 2.0847349346324964

Epoch: 6| Step: 13
Training loss: 1.7786892652511597
Validation loss: 2.1169637851817633

Epoch: 319| Step: 0
Training loss: 1.1919595003128052
Validation loss: 2.125457840581094

Epoch: 6| Step: 1
Training loss: 1.1156083345413208
Validation loss: 2.148000435162616

Epoch: 6| Step: 2
Training loss: 1.6767750978469849
Validation loss: 2.148941929622363

Epoch: 6| Step: 3
Training loss: 1.6575467586517334
Validation loss: 2.1445346109328733

Epoch: 6| Step: 4
Training loss: 1.841080904006958
Validation loss: 2.1365332231726697

Epoch: 6| Step: 5
Training loss: 1.1532340049743652
Validation loss: 2.103788636064017

Epoch: 6| Step: 6
Training loss: 1.556241750717163
Validation loss: 2.072773261736798

Epoch: 6| Step: 7
Training loss: 1.3052908182144165
Validation loss: 2.0662719511216685

Epoch: 6| Step: 8
Training loss: 1.4233152866363525
Validation loss: 2.0718943739450104

Epoch: 6| Step: 9
Training loss: 1.954817771911621
Validation loss: 2.0819418558510403

Epoch: 6| Step: 10
Training loss: 1.8027008771896362
Validation loss: 2.063750943829936

Epoch: 6| Step: 11
Training loss: 1.5782339572906494
Validation loss: 2.0654502863525064

Epoch: 6| Step: 12
Training loss: 1.2172504663467407
Validation loss: 2.08190389474233

Epoch: 6| Step: 13
Training loss: 1.6561838388442993
Validation loss: 2.069650137296287

Epoch: 320| Step: 0
Training loss: 0.9669713377952576
Validation loss: 2.101311129908408

Epoch: 6| Step: 1
Training loss: 1.8579859733581543
Validation loss: 2.07917284452787

Epoch: 6| Step: 2
Training loss: 1.9891564846038818
Validation loss: 2.0841112713659964

Epoch: 6| Step: 3
Training loss: 2.0541341304779053
Validation loss: 2.0749439526629705

Epoch: 6| Step: 4
Training loss: 1.8033028841018677
Validation loss: 2.0931460306208622

Epoch: 6| Step: 5
Training loss: 1.3978188037872314
Validation loss: 2.0782376258603987

Epoch: 6| Step: 6
Training loss: 1.2946518659591675
Validation loss: 2.084427243919783

Epoch: 6| Step: 7
Training loss: 0.9308737516403198
Validation loss: 2.1146385310798563

Epoch: 6| Step: 8
Training loss: 2.310626745223999
Validation loss: 2.097711947656447

Epoch: 6| Step: 9
Training loss: 1.3684923648834229
Validation loss: 2.0961118257173927

Epoch: 6| Step: 10
Training loss: 1.478071689605713
Validation loss: 2.117116847345906

Epoch: 6| Step: 11
Training loss: 1.4630615711212158
Validation loss: 2.1460274034930813

Epoch: 6| Step: 12
Training loss: 0.550746738910675
Validation loss: 2.1339560054963633

Epoch: 6| Step: 13
Training loss: 1.4079008102416992
Validation loss: 2.1303781873436383

Epoch: 321| Step: 0
Training loss: 1.1130295991897583
Validation loss: 2.138479644252408

Epoch: 6| Step: 1
Training loss: 1.747375726699829
Validation loss: 2.1463902714431926

Epoch: 6| Step: 2
Training loss: 1.803558588027954
Validation loss: 2.1372303475615797

Epoch: 6| Step: 3
Training loss: 1.3139257431030273
Validation loss: 2.1093304734076224

Epoch: 6| Step: 4
Training loss: 1.5158355236053467
Validation loss: 2.087990217311408

Epoch: 6| Step: 5
Training loss: 1.9809134006500244
Validation loss: 2.0701914089982227

Epoch: 6| Step: 6
Training loss: 1.428119421005249
Validation loss: 2.0914485377650105

Epoch: 6| Step: 7
Training loss: 1.6422297954559326
Validation loss: 2.062519265759376

Epoch: 6| Step: 8
Training loss: 1.999513030052185
Validation loss: 2.070033199043684

Epoch: 6| Step: 9
Training loss: 1.3277326822280884
Validation loss: 2.0547190327798166

Epoch: 6| Step: 10
Training loss: 1.5302294492721558
Validation loss: 2.0550148397363643

Epoch: 6| Step: 11
Training loss: 1.1247284412384033
Validation loss: 2.054758930719027

Epoch: 6| Step: 12
Training loss: 1.4364819526672363
Validation loss: 2.0608422217830533

Epoch: 6| Step: 13
Training loss: 0.6577841639518738
Validation loss: 2.0802397830511934

Epoch: 322| Step: 0
Training loss: 1.614935040473938
Validation loss: 2.090886377519177

Epoch: 6| Step: 1
Training loss: 1.3391809463500977
Validation loss: 2.1064594189325967

Epoch: 6| Step: 2
Training loss: 1.95021653175354
Validation loss: 2.1499237834766345

Epoch: 6| Step: 3
Training loss: 1.0816872119903564
Validation loss: 2.156360650575289

Epoch: 6| Step: 4
Training loss: 1.8083460330963135
Validation loss: 2.1605816861634612

Epoch: 6| Step: 5
Training loss: 1.3572049140930176
Validation loss: 2.155219656164928

Epoch: 6| Step: 6
Training loss: 1.170299768447876
Validation loss: 2.1574753074235815

Epoch: 6| Step: 7
Training loss: 1.0879086256027222
Validation loss: 2.120987470431994

Epoch: 6| Step: 8
Training loss: 1.6156014204025269
Validation loss: 2.1285497603877896

Epoch: 6| Step: 9
Training loss: 1.6998556852340698
Validation loss: 2.1072323322296143

Epoch: 6| Step: 10
Training loss: 1.471580982208252
Validation loss: 2.0885769474890923

Epoch: 6| Step: 11
Training loss: 1.8935999870300293
Validation loss: 2.1012974041764454

Epoch: 6| Step: 12
Training loss: 1.3349370956420898
Validation loss: 2.0656722771224154

Epoch: 6| Step: 13
Training loss: 1.508548378944397
Validation loss: 2.0516737891781713

Epoch: 323| Step: 0
Training loss: 1.5378987789154053
Validation loss: 2.0540242682221117

Epoch: 6| Step: 1
Training loss: 0.7989379167556763
Validation loss: 2.054559689696117

Epoch: 6| Step: 2
Training loss: 1.588545799255371
Validation loss: 2.032406596727269

Epoch: 6| Step: 3
Training loss: 1.6379177570343018
Validation loss: 2.0446397437844226

Epoch: 6| Step: 4
Training loss: 1.6102076768875122
Validation loss: 2.0413650043549074

Epoch: 6| Step: 5
Training loss: 1.3726741075515747
Validation loss: 2.0338639982285036

Epoch: 6| Step: 6
Training loss: 1.1301511526107788
Validation loss: 2.047569303102391

Epoch: 6| Step: 7
Training loss: 0.9760935306549072
Validation loss: 2.0511308626462053

Epoch: 6| Step: 8
Training loss: 1.847163438796997
Validation loss: 2.052294567067136

Epoch: 6| Step: 9
Training loss: 1.2023097276687622
Validation loss: 2.076361592097949

Epoch: 6| Step: 10
Training loss: 1.5333576202392578
Validation loss: 2.0826679147699827

Epoch: 6| Step: 11
Training loss: 1.6360602378845215
Validation loss: 2.0763707519859396

Epoch: 6| Step: 12
Training loss: 2.054469585418701
Validation loss: 2.076308329900106

Epoch: 6| Step: 13
Training loss: 2.12137508392334
Validation loss: 2.0916809138431343

Epoch: 324| Step: 0
Training loss: 1.262464165687561
Validation loss: 2.0811435189298404

Epoch: 6| Step: 1
Training loss: 1.1632187366485596
Validation loss: 2.076625959847563

Epoch: 6| Step: 2
Training loss: 1.9766401052474976
Validation loss: 2.0842296064540906

Epoch: 6| Step: 3
Training loss: 2.042498826980591
Validation loss: 2.080383808382096

Epoch: 6| Step: 4
Training loss: 1.4300943613052368
Validation loss: 2.0852673105014268

Epoch: 6| Step: 5
Training loss: 1.8629944324493408
Validation loss: 2.066847059034532

Epoch: 6| Step: 6
Training loss: 1.8855042457580566
Validation loss: 2.08632892306133

Epoch: 6| Step: 7
Training loss: 0.7299957275390625
Validation loss: 2.095709172628259

Epoch: 6| Step: 8
Training loss: 0.9766527414321899
Validation loss: 2.093784757839736

Epoch: 6| Step: 9
Training loss: 1.4890693426132202
Validation loss: 2.1032624526690413

Epoch: 6| Step: 10
Training loss: 1.4197946786880493
Validation loss: 2.1075027437620264

Epoch: 6| Step: 11
Training loss: 1.2904728651046753
Validation loss: 2.0921614836621028

Epoch: 6| Step: 12
Training loss: 1.2632148265838623
Validation loss: 2.1033641728021766

Epoch: 6| Step: 13
Training loss: 1.726491093635559
Validation loss: 2.0997792623376332

Epoch: 325| Step: 0
Training loss: 2.152693271636963
Validation loss: 2.091262544355085

Epoch: 6| Step: 1
Training loss: 1.3065065145492554
Validation loss: 2.067643819316741

Epoch: 6| Step: 2
Training loss: 1.0813558101654053
Validation loss: 2.0586584998715307

Epoch: 6| Step: 3
Training loss: 1.768036127090454
Validation loss: 2.0515039556769916

Epoch: 6| Step: 4
Training loss: 1.1973305940628052
Validation loss: 2.0452617778572986

Epoch: 6| Step: 5
Training loss: 1.2901430130004883
Validation loss: 2.052627965968142

Epoch: 6| Step: 6
Training loss: 1.1331026554107666
Validation loss: 2.0527097819953837

Epoch: 6| Step: 7
Training loss: 1.9682632684707642
Validation loss: 2.0512226448264173

Epoch: 6| Step: 8
Training loss: 1.0530239343643188
Validation loss: 2.064441978290517

Epoch: 6| Step: 9
Training loss: 1.4935072660446167
Validation loss: 2.06607194741567

Epoch: 6| Step: 10
Training loss: 1.586939811706543
Validation loss: 2.0912140928288943

Epoch: 6| Step: 11
Training loss: 1.7391043901443481
Validation loss: 2.079660556649649

Epoch: 6| Step: 12
Training loss: 1.1008927822113037
Validation loss: 2.091138626939507

Epoch: 6| Step: 13
Training loss: 1.628114104270935
Validation loss: 2.093986318957421

Epoch: 326| Step: 0
Training loss: 1.4190818071365356
Validation loss: 2.0897176034988894

Epoch: 6| Step: 1
Training loss: 1.099790334701538
Validation loss: 2.0718424422766573

Epoch: 6| Step: 2
Training loss: 1.713032841682434
Validation loss: 2.0768521344789894

Epoch: 6| Step: 3
Training loss: 1.7888810634613037
Validation loss: 2.0751498104423605

Epoch: 6| Step: 4
Training loss: 1.5233056545257568
Validation loss: 2.0838983789567025

Epoch: 6| Step: 5
Training loss: 1.8100614547729492
Validation loss: 2.0904789893857894

Epoch: 6| Step: 6
Training loss: 1.5982247591018677
Validation loss: 2.0819295375577864

Epoch: 6| Step: 7
Training loss: 1.0278908014297485
Validation loss: 2.073206842586558

Epoch: 6| Step: 8
Training loss: 1.272526502609253
Validation loss: 2.0845500961426766

Epoch: 6| Step: 9
Training loss: 0.7194358110427856
Validation loss: 2.084742269208354

Epoch: 6| Step: 10
Training loss: 1.8111767768859863
Validation loss: 2.0850273973198346

Epoch: 6| Step: 11
Training loss: 2.0044898986816406
Validation loss: 2.092340641124274

Epoch: 6| Step: 12
Training loss: 0.9215736389160156
Validation loss: 2.0927916983122468

Epoch: 6| Step: 13
Training loss: 1.7789567708969116
Validation loss: 2.0817837997149398

Epoch: 327| Step: 0
Training loss: 1.60880446434021
Validation loss: 2.0834515556212394

Epoch: 6| Step: 1
Training loss: 1.114870309829712
Validation loss: 2.0358707674088015

Epoch: 6| Step: 2
Training loss: 0.9663432836532593
Validation loss: 2.071173570489371

Epoch: 6| Step: 3
Training loss: 1.4239397048950195
Validation loss: 2.060401278157388

Epoch: 6| Step: 4
Training loss: 1.566307544708252
Validation loss: 2.077070515642884

Epoch: 6| Step: 5
Training loss: 1.3015565872192383
Validation loss: 2.1129049908730293

Epoch: 6| Step: 6
Training loss: 1.2874808311462402
Validation loss: 2.1224306988459762

Epoch: 6| Step: 7
Training loss: 2.0614304542541504
Validation loss: 2.1060219413490704

Epoch: 6| Step: 8
Training loss: 1.1370770931243896
Validation loss: 2.0956886891395814

Epoch: 6| Step: 9
Training loss: 1.6000962257385254
Validation loss: 2.0953138951332337

Epoch: 6| Step: 10
Training loss: 1.1681654453277588
Validation loss: 2.1034488113977576

Epoch: 6| Step: 11
Training loss: 1.7009303569793701
Validation loss: 2.0826404145968858

Epoch: 6| Step: 12
Training loss: 1.790226697921753
Validation loss: 2.0925397514015116

Epoch: 6| Step: 13
Training loss: 2.1345787048339844
Validation loss: 2.076820474798961

Epoch: 328| Step: 0
Training loss: 1.3978660106658936
Validation loss: 2.059849190455611

Epoch: 6| Step: 1
Training loss: 2.1440086364746094
Validation loss: 2.0609059154346423

Epoch: 6| Step: 2
Training loss: 1.4283020496368408
Validation loss: 2.0506666603908745

Epoch: 6| Step: 3
Training loss: 1.6576482057571411
Validation loss: 2.036413400403915

Epoch: 6| Step: 4
Training loss: 1.4051328897476196
Validation loss: 2.0511119083691667

Epoch: 6| Step: 5
Training loss: 1.430896282196045
Validation loss: 2.0227824205993326

Epoch: 6| Step: 6
Training loss: 1.0872817039489746
Validation loss: 2.0363766518972253

Epoch: 6| Step: 7
Training loss: 2.3349802494049072
Validation loss: 2.0594405230655464

Epoch: 6| Step: 8
Training loss: 0.862050473690033
Validation loss: 2.055119796465802

Epoch: 6| Step: 9
Training loss: 1.2756109237670898
Validation loss: 2.0767966214046685

Epoch: 6| Step: 10
Training loss: 1.3677659034729004
Validation loss: 2.083624743646191

Epoch: 6| Step: 11
Training loss: 1.3434116840362549
Validation loss: 2.101320364141977

Epoch: 6| Step: 12
Training loss: 1.0439965724945068
Validation loss: 2.1174928988179853

Epoch: 6| Step: 13
Training loss: 1.4219692945480347
Validation loss: 2.0958257503406976

Epoch: 329| Step: 0
Training loss: 1.6994879245758057
Validation loss: 2.095521903807117

Epoch: 6| Step: 1
Training loss: 1.8045532703399658
Validation loss: 2.1090698934370473

Epoch: 6| Step: 2
Training loss: 1.4903674125671387
Validation loss: 2.121322995872908

Epoch: 6| Step: 3
Training loss: 1.1223889589309692
Validation loss: 2.1108758975100774

Epoch: 6| Step: 4
Training loss: 1.6431924104690552
Validation loss: 2.109644200212212

Epoch: 6| Step: 5
Training loss: 1.5872002840042114
Validation loss: 2.087485582597794

Epoch: 6| Step: 6
Training loss: 1.3207365274429321
Validation loss: 2.0864871060976418

Epoch: 6| Step: 7
Training loss: 1.5086827278137207
Validation loss: 2.07278597611253

Epoch: 6| Step: 8
Training loss: 1.1856563091278076
Validation loss: 2.0360298900194067

Epoch: 6| Step: 9
Training loss: 1.5642540454864502
Validation loss: 2.0498007369297806

Epoch: 6| Step: 10
Training loss: 1.7065269947052002
Validation loss: 2.0443824978284937

Epoch: 6| Step: 11
Training loss: 1.2519644498825073
Validation loss: 2.023428217057259

Epoch: 6| Step: 12
Training loss: 1.1069337129592896
Validation loss: 2.0549482196889897

Epoch: 6| Step: 13
Training loss: 1.1496014595031738
Validation loss: 2.0458546902543757

Epoch: 330| Step: 0
Training loss: 1.5675086975097656
Validation loss: 2.039863573607578

Epoch: 6| Step: 1
Training loss: 1.753686547279358
Validation loss: 2.0812344640813847

Epoch: 6| Step: 2
Training loss: 2.1393587589263916
Validation loss: 2.106287464018791

Epoch: 6| Step: 3
Training loss: 1.2753963470458984
Validation loss: 2.110251654860794

Epoch: 6| Step: 4
Training loss: 0.820160984992981
Validation loss: 2.1203901229366178

Epoch: 6| Step: 5
Training loss: 1.2274696826934814
Validation loss: 2.12077699681764

Epoch: 6| Step: 6
Training loss: 1.5381677150726318
Validation loss: 2.135050263456119

Epoch: 6| Step: 7
Training loss: 1.4347379207611084
Validation loss: 2.147166106008714

Epoch: 6| Step: 8
Training loss: 1.8930795192718506
Validation loss: 2.1280081477216495

Epoch: 6| Step: 9
Training loss: 1.438256025314331
Validation loss: 2.1373551404604347

Epoch: 6| Step: 10
Training loss: 1.1805167198181152
Validation loss: 2.0970937154626332

Epoch: 6| Step: 11
Training loss: 1.7781399488449097
Validation loss: 2.0988731076640468

Epoch: 6| Step: 12
Training loss: 1.2796556949615479
Validation loss: 2.0547749483457176

Epoch: 6| Step: 13
Training loss: 0.4911183714866638
Validation loss: 2.065773897273566

Epoch: 331| Step: 0
Training loss: 1.2179515361785889
Validation loss: 2.0537759847538446

Epoch: 6| Step: 1
Training loss: 1.0939583778381348
Validation loss: 2.046270952429823

Epoch: 6| Step: 2
Training loss: 0.9485846757888794
Validation loss: 2.0438963059456117

Epoch: 6| Step: 3
Training loss: 0.8834455013275146
Validation loss: 2.043383757273356

Epoch: 6| Step: 4
Training loss: 1.446125864982605
Validation loss: 2.0503731632745392

Epoch: 6| Step: 5
Training loss: 2.037590980529785
Validation loss: 2.0755485847432125

Epoch: 6| Step: 6
Training loss: 2.1837921142578125
Validation loss: 2.0936244623635405

Epoch: 6| Step: 7
Training loss: 1.7121548652648926
Validation loss: 2.0888522401932748

Epoch: 6| Step: 8
Training loss: 2.2832837104797363
Validation loss: 2.1134022538379957

Epoch: 6| Step: 9
Training loss: 1.1656466722488403
Validation loss: 2.1181292508238103

Epoch: 6| Step: 10
Training loss: 1.4029611349105835
Validation loss: 2.1342052823753765

Epoch: 6| Step: 11
Training loss: 1.6865999698638916
Validation loss: 2.1172901353528424

Epoch: 6| Step: 12
Training loss: 1.026313066482544
Validation loss: 2.119306433585382

Epoch: 6| Step: 13
Training loss: 0.8488374948501587
Validation loss: 2.125615886462632

Epoch: 332| Step: 0
Training loss: 1.2671986818313599
Validation loss: 2.093780084322858

Epoch: 6| Step: 1
Training loss: 1.2273650169372559
Validation loss: 2.1016877748632945

Epoch: 6| Step: 2
Training loss: 1.6998977661132812
Validation loss: 2.079210494154243

Epoch: 6| Step: 3
Training loss: 1.4180349111557007
Validation loss: 2.077201489479311

Epoch: 6| Step: 4
Training loss: 0.9523434638977051
Validation loss: 2.071673398376793

Epoch: 6| Step: 5
Training loss: 0.845138430595398
Validation loss: 2.050471482738372

Epoch: 6| Step: 6
Training loss: 1.5377119779586792
Validation loss: 2.0767936809088594

Epoch: 6| Step: 7
Training loss: 1.3348355293273926
Validation loss: 2.111944321663149

Epoch: 6| Step: 8
Training loss: 1.9259240627288818
Validation loss: 2.0988456536364812

Epoch: 6| Step: 9
Training loss: 1.7605574131011963
Validation loss: 2.1196390095577446

Epoch: 6| Step: 10
Training loss: 1.5912325382232666
Validation loss: 2.1257427430921987

Epoch: 6| Step: 11
Training loss: 1.299089789390564
Validation loss: 2.1121661406691357

Epoch: 6| Step: 12
Training loss: 1.9834353923797607
Validation loss: 2.0864598430613035

Epoch: 6| Step: 13
Training loss: 0.8307729363441467
Validation loss: 2.066027982260591

Epoch: 333| Step: 0
Training loss: 1.7607803344726562
Validation loss: 2.0656942680317867

Epoch: 6| Step: 1
Training loss: 1.8130133152008057
Validation loss: 2.047141539153232

Epoch: 6| Step: 2
Training loss: 1.8348524570465088
Validation loss: 2.044002764968462

Epoch: 6| Step: 3
Training loss: 0.7811239957809448
Validation loss: 2.0060590736327635

Epoch: 6| Step: 4
Training loss: 1.5013415813446045
Validation loss: 2.014853510805356

Epoch: 6| Step: 5
Training loss: 1.9096148014068604
Validation loss: 2.010729517987979

Epoch: 6| Step: 6
Training loss: 1.4941480159759521
Validation loss: 2.0007068200777938

Epoch: 6| Step: 7
Training loss: 0.9973481297492981
Validation loss: 2.0062278560412827

Epoch: 6| Step: 8
Training loss: 0.8907272815704346
Validation loss: 2.0299674285355436

Epoch: 6| Step: 9
Training loss: 0.7892849445343018
Validation loss: 2.0610333386287896

Epoch: 6| Step: 10
Training loss: 1.4706382751464844
Validation loss: 2.0743723966742076

Epoch: 6| Step: 11
Training loss: 1.2302794456481934
Validation loss: 2.084587517605033

Epoch: 6| Step: 12
Training loss: 1.6313235759735107
Validation loss: 2.095685612770819

Epoch: 6| Step: 13
Training loss: 2.1123106479644775
Validation loss: 2.1154087487087456

Epoch: 334| Step: 0
Training loss: 1.2703055143356323
Validation loss: 2.1319980954611175

Epoch: 6| Step: 1
Training loss: 2.3428220748901367
Validation loss: 2.123037358765961

Epoch: 6| Step: 2
Training loss: 1.0296024084091187
Validation loss: 2.1169075863335722

Epoch: 6| Step: 3
Training loss: 1.0433943271636963
Validation loss: 2.110933542251587

Epoch: 6| Step: 4
Training loss: 1.0053898096084595
Validation loss: 2.124851449843376

Epoch: 6| Step: 5
Training loss: 1.1867420673370361
Validation loss: 2.10460832811171

Epoch: 6| Step: 6
Training loss: 0.8878778219223022
Validation loss: 2.0846571076300835

Epoch: 6| Step: 7
Training loss: 1.5146492719650269
Validation loss: 2.0661286756556523

Epoch: 6| Step: 8
Training loss: 1.2151010036468506
Validation loss: 2.075259993153234

Epoch: 6| Step: 9
Training loss: 1.8865450620651245
Validation loss: 2.056241559725936

Epoch: 6| Step: 10
Training loss: 1.8836721181869507
Validation loss: 2.0351873059426584

Epoch: 6| Step: 11
Training loss: 1.531489372253418
Validation loss: 2.0637809025344027

Epoch: 6| Step: 12
Training loss: 1.5032854080200195
Validation loss: 2.0446506572026077

Epoch: 6| Step: 13
Training loss: 1.0793986320495605
Validation loss: 2.0529682790079424

Epoch: 335| Step: 0
Training loss: 1.3710826635360718
Validation loss: 2.053380581640428

Epoch: 6| Step: 1
Training loss: 1.6054627895355225
Validation loss: 2.0476590689792427

Epoch: 6| Step: 2
Training loss: 0.9436519145965576
Validation loss: 2.0590360574824835

Epoch: 6| Step: 3
Training loss: 1.8614325523376465
Validation loss: 2.0641425040460404

Epoch: 6| Step: 4
Training loss: 1.349685549736023
Validation loss: 2.071468842926846

Epoch: 6| Step: 5
Training loss: 1.7249711751937866
Validation loss: 2.05277096327915

Epoch: 6| Step: 6
Training loss: 1.7893376350402832
Validation loss: 2.0809649754596014

Epoch: 6| Step: 7
Training loss: 1.2630176544189453
Validation loss: 2.109414346756474

Epoch: 6| Step: 8
Training loss: 0.8782433271408081
Validation loss: 2.1071912152792818

Epoch: 6| Step: 9
Training loss: 1.9729423522949219
Validation loss: 2.1173863923677834

Epoch: 6| Step: 10
Training loss: 1.1180164813995361
Validation loss: 2.121984394647742

Epoch: 6| Step: 11
Training loss: 0.980018675327301
Validation loss: 2.121419788688742

Epoch: 6| Step: 12
Training loss: 1.7617149353027344
Validation loss: 2.1133547444497385

Epoch: 6| Step: 13
Training loss: 0.428049236536026
Validation loss: 2.1144028427780315

Epoch: 336| Step: 0
Training loss: 0.7067481279373169
Validation loss: 2.0876118982991865

Epoch: 6| Step: 1
Training loss: 1.2770392894744873
Validation loss: 2.0845233548072075

Epoch: 6| Step: 2
Training loss: 1.6991297006607056
Validation loss: 2.094932799698204

Epoch: 6| Step: 3
Training loss: 1.0826070308685303
Validation loss: 2.081936154314267

Epoch: 6| Step: 4
Training loss: 1.2676684856414795
Validation loss: 2.0574221649477558

Epoch: 6| Step: 5
Training loss: 1.2026790380477905
Validation loss: 2.0443592738079768

Epoch: 6| Step: 6
Training loss: 1.0606122016906738
Validation loss: 2.0169504368177025

Epoch: 6| Step: 7
Training loss: 1.708420753479004
Validation loss: 2.0178937886350896

Epoch: 6| Step: 8
Training loss: 1.6011962890625
Validation loss: 2.0258224113013155

Epoch: 6| Step: 9
Training loss: 1.2257975339889526
Validation loss: 2.0410649289367018

Epoch: 6| Step: 10
Training loss: 1.9745585918426514
Validation loss: 2.0657369757211335

Epoch: 6| Step: 11
Training loss: 1.8350956439971924
Validation loss: 2.0428722827665267

Epoch: 6| Step: 12
Training loss: 1.6572102308273315
Validation loss: 2.052830596123972

Epoch: 6| Step: 13
Training loss: 0.7605218887329102
Validation loss: 2.0853095874991467

Epoch: 337| Step: 0
Training loss: 1.6726409196853638
Validation loss: 2.0918071885262766

Epoch: 6| Step: 1
Training loss: 0.8569188117980957
Validation loss: 2.1087883672406598

Epoch: 6| Step: 2
Training loss: 1.7279269695281982
Validation loss: 2.1384472282983924

Epoch: 6| Step: 3
Training loss: 1.1209557056427002
Validation loss: 2.1088567831182994

Epoch: 6| Step: 4
Training loss: 1.2502107620239258
Validation loss: 2.1281255906628025

Epoch: 6| Step: 5
Training loss: 1.9206905364990234
Validation loss: 2.1209910967016734

Epoch: 6| Step: 6
Training loss: 1.1075053215026855
Validation loss: 2.1402750797169183

Epoch: 6| Step: 7
Training loss: 0.8436940312385559
Validation loss: 2.1135947653042373

Epoch: 6| Step: 8
Training loss: 1.2615108489990234
Validation loss: 2.125382564401114

Epoch: 6| Step: 9
Training loss: 1.564610481262207
Validation loss: 2.1017410652611845

Epoch: 6| Step: 10
Training loss: 2.020890474319458
Validation loss: 2.078901461375657

Epoch: 6| Step: 11
Training loss: 0.8494182229042053
Validation loss: 2.0949993107908513

Epoch: 6| Step: 12
Training loss: 1.2862061262130737
Validation loss: 2.0736874688056206

Epoch: 6| Step: 13
Training loss: 2.1981494426727295
Validation loss: 2.067884906645744

Epoch: 338| Step: 0
Training loss: 0.8273634910583496
Validation loss: 2.0607685324966267

Epoch: 6| Step: 1
Training loss: 1.1700921058654785
Validation loss: 2.073780003414359

Epoch: 6| Step: 2
Training loss: 1.6667194366455078
Validation loss: 2.0802521231353923

Epoch: 6| Step: 3
Training loss: 1.8471506834030151
Validation loss: 2.0779817360703663

Epoch: 6| Step: 4
Training loss: 1.452567219734192
Validation loss: 2.093300563032909

Epoch: 6| Step: 5
Training loss: 1.7070780992507935
Validation loss: 2.1314577569243727

Epoch: 6| Step: 6
Training loss: 1.2986788749694824
Validation loss: 2.1625547434694026

Epoch: 6| Step: 7
Training loss: 1.4385782480239868
Validation loss: 2.144660142160231

Epoch: 6| Step: 8
Training loss: 1.7228221893310547
Validation loss: 2.130204683990889

Epoch: 6| Step: 9
Training loss: 1.2519159317016602
Validation loss: 2.126220226287842

Epoch: 6| Step: 10
Training loss: 1.3629176616668701
Validation loss: 2.104930108593356

Epoch: 6| Step: 11
Training loss: 1.2987356185913086
Validation loss: 2.1021402138535694

Epoch: 6| Step: 12
Training loss: 1.19773530960083
Validation loss: 2.0532770054314726

Epoch: 6| Step: 13
Training loss: 0.998694121837616
Validation loss: 2.045920788600881

Epoch: 339| Step: 0
Training loss: 1.1374406814575195
Validation loss: 2.0473657602904947

Epoch: 6| Step: 1
Training loss: 2.183906078338623
Validation loss: 2.013874328264626

Epoch: 6| Step: 2
Training loss: 1.164520025253296
Validation loss: 2.0139935503723803

Epoch: 6| Step: 3
Training loss: 1.0241780281066895
Validation loss: 1.9944350155450965

Epoch: 6| Step: 4
Training loss: 1.1766138076782227
Validation loss: 2.002848694401403

Epoch: 6| Step: 5
Training loss: 1.189427137374878
Validation loss: 2.0292918989735265

Epoch: 6| Step: 6
Training loss: 1.2530901432037354
Validation loss: 2.0289053481112242

Epoch: 6| Step: 7
Training loss: 1.4783610105514526
Validation loss: 2.0491860143599974

Epoch: 6| Step: 8
Training loss: 1.6716887950897217
Validation loss: 2.071949323018392

Epoch: 6| Step: 9
Training loss: 0.7942912578582764
Validation loss: 2.085258590277805

Epoch: 6| Step: 10
Training loss: 1.6482771635055542
Validation loss: 2.114241329572534

Epoch: 6| Step: 11
Training loss: 1.0425420999526978
Validation loss: 2.0964820628525107

Epoch: 6| Step: 12
Training loss: 1.8514907360076904
Validation loss: 2.122304677963257

Epoch: 6| Step: 13
Training loss: 1.7743333578109741
Validation loss: 2.122108949128018

Epoch: 340| Step: 0
Training loss: 0.9077492356300354
Validation loss: 2.1297096206295874

Epoch: 6| Step: 1
Training loss: 1.1445326805114746
Validation loss: 2.1189719912826375

Epoch: 6| Step: 2
Training loss: 1.725605845451355
Validation loss: 2.1218231493426907

Epoch: 6| Step: 3
Training loss: 2.021024703979492
Validation loss: 2.10295174583312

Epoch: 6| Step: 4
Training loss: 0.694839358329773
Validation loss: 2.0877892266037645

Epoch: 6| Step: 5
Training loss: 0.9714123010635376
Validation loss: 2.108944046881891

Epoch: 6| Step: 6
Training loss: 1.7320640087127686
Validation loss: 2.100077943135333

Epoch: 6| Step: 7
Training loss: 1.7882630825042725
Validation loss: 2.0751345670351418

Epoch: 6| Step: 8
Training loss: 1.7178179025650024
Validation loss: 2.0664349499569146

Epoch: 6| Step: 9
Training loss: 0.9183642864227295
Validation loss: 2.0749999374471684

Epoch: 6| Step: 10
Training loss: 1.9433878660202026
Validation loss: 2.084558936857408

Epoch: 6| Step: 11
Training loss: 1.0629949569702148
Validation loss: 2.0724824525976695

Epoch: 6| Step: 12
Training loss: 1.2902806997299194
Validation loss: 2.0470078029940204

Epoch: 6| Step: 13
Training loss: 1.0824799537658691
Validation loss: 2.0792178082209762

Epoch: 341| Step: 0
Training loss: 1.8820407390594482
Validation loss: 2.0628885223019506

Epoch: 6| Step: 1
Training loss: 1.241137981414795
Validation loss: 2.0628539900625906

Epoch: 6| Step: 2
Training loss: 1.5271918773651123
Validation loss: 2.0327584538408505

Epoch: 6| Step: 3
Training loss: 1.492842435836792
Validation loss: 2.057108329188439

Epoch: 6| Step: 4
Training loss: 1.0343347787857056
Validation loss: 2.061236471258184

Epoch: 6| Step: 5
Training loss: 0.861910879611969
Validation loss: 2.0707997070845736

Epoch: 6| Step: 6
Training loss: 1.2990529537200928
Validation loss: 2.105949581310313

Epoch: 6| Step: 7
Training loss: 1.1555966138839722
Validation loss: 2.118422128820932

Epoch: 6| Step: 8
Training loss: 0.8218284845352173
Validation loss: 2.1151022423980055

Epoch: 6| Step: 9
Training loss: 2.2814524173736572
Validation loss: 2.083708634940527

Epoch: 6| Step: 10
Training loss: 1.767241358757019
Validation loss: 2.101540688545473

Epoch: 6| Step: 11
Training loss: 1.2898473739624023
Validation loss: 2.097900234242921

Epoch: 6| Step: 12
Training loss: 0.6923025846481323
Validation loss: 2.0975380392484766

Epoch: 6| Step: 13
Training loss: 1.5375268459320068
Validation loss: 2.0570543222529913

Epoch: 342| Step: 0
Training loss: 1.1131081581115723
Validation loss: 2.0573304571131223

Epoch: 6| Step: 1
Training loss: 1.8049421310424805
Validation loss: 2.07523533093032

Epoch: 6| Step: 2
Training loss: 1.5606706142425537
Validation loss: 2.062884344849535

Epoch: 6| Step: 3
Training loss: 1.2370916604995728
Validation loss: 2.0643721421559653

Epoch: 6| Step: 4
Training loss: 0.5549486875534058
Validation loss: 2.0434400394398677

Epoch: 6| Step: 5
Training loss: 1.5355943441390991
Validation loss: 2.045210282007853

Epoch: 6| Step: 6
Training loss: 1.4813015460968018
Validation loss: 2.064898360160089

Epoch: 6| Step: 7
Training loss: 1.740801453590393
Validation loss: 2.0668979101283576

Epoch: 6| Step: 8
Training loss: 1.2410064935684204
Validation loss: 2.1005041009636334

Epoch: 6| Step: 9
Training loss: 1.251782774925232
Validation loss: 2.088937400489725

Epoch: 6| Step: 10
Training loss: 0.9276742935180664
Validation loss: 2.1068991768744683

Epoch: 6| Step: 11
Training loss: 0.9740568399429321
Validation loss: 2.1279386166603333

Epoch: 6| Step: 12
Training loss: 1.7855192422866821
Validation loss: 2.137525381580476

Epoch: 6| Step: 13
Training loss: 1.475150465965271
Validation loss: 2.116091512864636

Epoch: 343| Step: 0
Training loss: 1.350303292274475
Validation loss: 2.121013308084139

Epoch: 6| Step: 1
Training loss: 1.3279513120651245
Validation loss: 2.122719185326689

Epoch: 6| Step: 2
Training loss: 1.0357767343521118
Validation loss: 2.0939737776274323

Epoch: 6| Step: 3
Training loss: 0.7555729150772095
Validation loss: 2.130249540011088

Epoch: 6| Step: 4
Training loss: 1.0558372735977173
Validation loss: 2.0971491465004544

Epoch: 6| Step: 5
Training loss: 1.539222240447998
Validation loss: 2.0869256783557195

Epoch: 6| Step: 6
Training loss: 1.3046624660491943
Validation loss: 2.084571728142359

Epoch: 6| Step: 7
Training loss: 1.3052215576171875
Validation loss: 2.0826834119776243

Epoch: 6| Step: 8
Training loss: 1.5375062227249146
Validation loss: 2.0826481632007066

Epoch: 6| Step: 9
Training loss: 1.340824842453003
Validation loss: 2.0525694534342778

Epoch: 6| Step: 10
Training loss: 1.6146910190582275
Validation loss: 2.0574340653675858

Epoch: 6| Step: 11
Training loss: 1.5564031600952148
Validation loss: 2.056448995426137

Epoch: 6| Step: 12
Training loss: 1.3808989524841309
Validation loss: 2.064089849431028

Epoch: 6| Step: 13
Training loss: 1.8487499952316284
Validation loss: 2.0474466687889508

Epoch: 344| Step: 0
Training loss: 1.748833417892456
Validation loss: 2.050144085320093

Epoch: 6| Step: 1
Training loss: 0.8894999623298645
Validation loss: 2.0339709558794574

Epoch: 6| Step: 2
Training loss: 1.5166304111480713
Validation loss: 2.0288062531461

Epoch: 6| Step: 3
Training loss: 0.5788853168487549
Validation loss: 2.0216749022083897

Epoch: 6| Step: 4
Training loss: 1.1516730785369873
Validation loss: 2.047504184066608

Epoch: 6| Step: 5
Training loss: 1.0787450075149536
Validation loss: 2.0694922426695466

Epoch: 6| Step: 6
Training loss: 1.9238181114196777
Validation loss: 2.068236558668075

Epoch: 6| Step: 7
Training loss: 1.3701562881469727
Validation loss: 2.091948236188581

Epoch: 6| Step: 8
Training loss: 1.2626914978027344
Validation loss: 2.094563497010098

Epoch: 6| Step: 9
Training loss: 1.498767614364624
Validation loss: 2.0992525815963745

Epoch: 6| Step: 10
Training loss: 1.6342732906341553
Validation loss: 2.1408361132426927

Epoch: 6| Step: 11
Training loss: 1.250497817993164
Validation loss: 2.1299956665244153

Epoch: 6| Step: 12
Training loss: 1.2923080921173096
Validation loss: 2.1138580153065343

Epoch: 6| Step: 13
Training loss: 1.3992400169372559
Validation loss: 2.102652959926154

Epoch: 345| Step: 0
Training loss: 1.333298921585083
Validation loss: 2.063251213360858

Epoch: 6| Step: 1
Training loss: 0.6662493348121643
Validation loss: 2.0551238803453344

Epoch: 6| Step: 2
Training loss: 1.862573504447937
Validation loss: 2.0504170348567348

Epoch: 6| Step: 3
Training loss: 1.591971755027771
Validation loss: 2.0400464470668505

Epoch: 6| Step: 4
Training loss: 0.99771648645401
Validation loss: 2.0353246658079085

Epoch: 6| Step: 5
Training loss: 0.9249504804611206
Validation loss: 2.0116972615641933

Epoch: 6| Step: 6
Training loss: 1.8154380321502686
Validation loss: 2.043093324989401

Epoch: 6| Step: 7
Training loss: 1.3218122720718384
Validation loss: 2.0491098332148727

Epoch: 6| Step: 8
Training loss: 1.1771197319030762
Validation loss: 2.0447254411635862

Epoch: 6| Step: 9
Training loss: 1.5216631889343262
Validation loss: 2.040508508682251

Epoch: 6| Step: 10
Training loss: 0.9826258420944214
Validation loss: 2.051643935582971

Epoch: 6| Step: 11
Training loss: 1.4958221912384033
Validation loss: 2.0042758795522873

Epoch: 6| Step: 12
Training loss: 1.4262986183166504
Validation loss: 2.018713471710041

Epoch: 6| Step: 13
Training loss: 1.5590773820877075
Validation loss: 2.024756243152003

Epoch: 346| Step: 0
Training loss: 1.2802774906158447
Validation loss: 2.0273913452702184

Epoch: 6| Step: 1
Training loss: 1.5644205808639526
Validation loss: 2.061004593808164

Epoch: 6| Step: 2
Training loss: 0.8996114730834961
Validation loss: 2.0415362696493826

Epoch: 6| Step: 3
Training loss: 1.516048789024353
Validation loss: 2.0754313827842794

Epoch: 6| Step: 4
Training loss: 2.107003927230835
Validation loss: 2.074899181242912

Epoch: 6| Step: 5
Training loss: 0.9786649942398071
Validation loss: 2.0737949622574674

Epoch: 6| Step: 6
Training loss: 1.5698778629302979
Validation loss: 2.059129920057071

Epoch: 6| Step: 7
Training loss: 1.6493523120880127
Validation loss: 2.043269039482199

Epoch: 6| Step: 8
Training loss: 1.2356555461883545
Validation loss: 2.0461440406819826

Epoch: 6| Step: 9
Training loss: 1.080625057220459
Validation loss: 2.041776357158538

Epoch: 6| Step: 10
Training loss: 0.7457254528999329
Validation loss: 2.0358142083691013

Epoch: 6| Step: 11
Training loss: 0.9427664279937744
Validation loss: 2.043385713331161

Epoch: 6| Step: 12
Training loss: 1.6266109943389893
Validation loss: 2.0222962825529036

Epoch: 6| Step: 13
Training loss: 1.2174582481384277
Validation loss: 2.0638504848685315

Epoch: 347| Step: 0
Training loss: 0.806222677230835
Validation loss: 2.085580993724126

Epoch: 6| Step: 1
Training loss: 1.285426378250122
Validation loss: 2.091438788880584

Epoch: 6| Step: 2
Training loss: 1.1517517566680908
Validation loss: 2.1171143618963097

Epoch: 6| Step: 3
Training loss: 0.9145806431770325
Validation loss: 2.13250127402685

Epoch: 6| Step: 4
Training loss: 1.702275276184082
Validation loss: 2.104942931923815

Epoch: 6| Step: 5
Training loss: 1.735451340675354
Validation loss: 2.1109386156964045

Epoch: 6| Step: 6
Training loss: 1.548628568649292
Validation loss: 2.1379217281136462

Epoch: 6| Step: 7
Training loss: 1.0608736276626587
Validation loss: 2.10456944024691

Epoch: 6| Step: 8
Training loss: 0.7874873876571655
Validation loss: 2.1090593056012223

Epoch: 6| Step: 9
Training loss: 0.9202909469604492
Validation loss: 2.093733156881025

Epoch: 6| Step: 10
Training loss: 1.6790754795074463
Validation loss: 2.107206331786289

Epoch: 6| Step: 11
Training loss: 1.5858315229415894
Validation loss: 2.0782196573031846

Epoch: 6| Step: 12
Training loss: 1.4680439233779907
Validation loss: 2.0409652827888407

Epoch: 6| Step: 13
Training loss: 1.9283338785171509
Validation loss: 2.0232544086312734

Epoch: 348| Step: 0
Training loss: 1.6759412288665771
Validation loss: 1.9932544949234172

Epoch: 6| Step: 1
Training loss: 1.4065728187561035
Validation loss: 1.993207179090028

Epoch: 6| Step: 2
Training loss: 1.3382959365844727
Validation loss: 1.9747140407562256

Epoch: 6| Step: 3
Training loss: 1.186701774597168
Validation loss: 1.975076070395849

Epoch: 6| Step: 4
Training loss: 1.1738295555114746
Validation loss: 2.0001653907119588

Epoch: 6| Step: 5
Training loss: 1.0477440357208252
Validation loss: 2.026534249705653

Epoch: 6| Step: 6
Training loss: 1.568617343902588
Validation loss: 2.028413713619273

Epoch: 6| Step: 7
Training loss: 1.2499051094055176
Validation loss: 2.075013837506694

Epoch: 6| Step: 8
Training loss: 1.9507668018341064
Validation loss: 2.084463712989643

Epoch: 6| Step: 9
Training loss: 1.1405917406082153
Validation loss: 2.0687014710518623

Epoch: 6| Step: 10
Training loss: 0.6990481615066528
Validation loss: 2.1065762235272314

Epoch: 6| Step: 11
Training loss: 1.597536325454712
Validation loss: 2.0979056768519904

Epoch: 6| Step: 12
Training loss: 1.360160231590271
Validation loss: 2.0994623232913274

Epoch: 6| Step: 13
Training loss: 0.6660053730010986
Validation loss: 2.084895028862902

Epoch: 349| Step: 0
Training loss: 1.218648910522461
Validation loss: 2.0705036501730643

Epoch: 6| Step: 1
Training loss: 0.578497052192688
Validation loss: 2.0574530196446243

Epoch: 6| Step: 2
Training loss: 1.1331771612167358
Validation loss: 2.0650049512104323

Epoch: 6| Step: 3
Training loss: 1.0667035579681396
Validation loss: 2.041095966933876

Epoch: 6| Step: 4
Training loss: 1.3603278398513794
Validation loss: 2.0762216891011884

Epoch: 6| Step: 5
Training loss: 2.1490182876586914
Validation loss: 2.065112749735514

Epoch: 6| Step: 6
Training loss: 1.0688647031784058
Validation loss: 2.0160701031325967

Epoch: 6| Step: 7
Training loss: 1.4494704008102417
Validation loss: 2.0188724340931063

Epoch: 6| Step: 8
Training loss: 0.8972504138946533
Validation loss: 2.0120499262245755

Epoch: 6| Step: 9
Training loss: 1.678544521331787
Validation loss: 2.0065826831325406

Epoch: 6| Step: 10
Training loss: 0.6316244602203369
Validation loss: 2.0291695492241972

Epoch: 6| Step: 11
Training loss: 1.5326778888702393
Validation loss: 2.024294986519762

Epoch: 6| Step: 12
Training loss: 1.9094321727752686
Validation loss: 2.060644790690432

Epoch: 6| Step: 13
Training loss: 1.3460074663162231
Validation loss: 2.0397790170484975

Epoch: 350| Step: 0
Training loss: 1.1315503120422363
Validation loss: 2.088376074708918

Epoch: 6| Step: 1
Training loss: 0.9535452127456665
Validation loss: 2.1032841692688646

Epoch: 6| Step: 2
Training loss: 1.5846550464630127
Validation loss: 2.096953877838709

Epoch: 6| Step: 3
Training loss: 2.5482935905456543
Validation loss: 2.1194389943153626

Epoch: 6| Step: 4
Training loss: 0.9039090275764465
Validation loss: 2.104204176574625

Epoch: 6| Step: 5
Training loss: 1.1616895198822021
Validation loss: 2.1026166433929117

Epoch: 6| Step: 6
Training loss: 1.4916834831237793
Validation loss: 2.0786781182853122

Epoch: 6| Step: 7
Training loss: 0.5910497307777405
Validation loss: 2.062830707078339

Epoch: 6| Step: 8
Training loss: 1.367398738861084
Validation loss: 2.0520688667092273

Epoch: 6| Step: 9
Training loss: 1.4198529720306396
Validation loss: 2.03854307564356

Epoch: 6| Step: 10
Training loss: 1.2630773782730103
Validation loss: 2.002597834474297

Epoch: 6| Step: 11
Training loss: 0.6815257668495178
Validation loss: 1.999695179282978

Epoch: 6| Step: 12
Training loss: 1.8021718263626099
Validation loss: 1.997429568280456

Epoch: 6| Step: 13
Training loss: 0.8649195432662964
Validation loss: 2.0283675168150213

Epoch: 351| Step: 0
Training loss: 1.5767630338668823
Validation loss: 2.010102838598272

Epoch: 6| Step: 1
Training loss: 1.1328380107879639
Validation loss: 2.0103411764226933

Epoch: 6| Step: 2
Training loss: 1.7794994115829468
Validation loss: 1.9915321616716282

Epoch: 6| Step: 3
Training loss: 1.5841999053955078
Validation loss: 2.014773658526841

Epoch: 6| Step: 4
Training loss: 0.8942911028862
Validation loss: 1.9981267926513508

Epoch: 6| Step: 5
Training loss: 1.0621756315231323
Validation loss: 2.0399813299537986

Epoch: 6| Step: 6
Training loss: 1.0947343111038208
Validation loss: 2.021716971551218

Epoch: 6| Step: 7
Training loss: 0.833781898021698
Validation loss: 2.038265871745284

Epoch: 6| Step: 8
Training loss: 0.9383788704872131
Validation loss: 2.0572087431466706

Epoch: 6| Step: 9
Training loss: 1.2792115211486816
Validation loss: 2.0775251298822384

Epoch: 6| Step: 10
Training loss: 1.0519769191741943
Validation loss: 2.109357956917055

Epoch: 6| Step: 11
Training loss: 1.4049913883209229
Validation loss: 2.1143293534555743

Epoch: 6| Step: 12
Training loss: 1.5605217218399048
Validation loss: 2.1187769764213154

Epoch: 6| Step: 13
Training loss: 1.9433577060699463
Validation loss: 2.0709834137270526

Epoch: 352| Step: 0
Training loss: 1.053947925567627
Validation loss: 2.0588394236821

Epoch: 6| Step: 1
Training loss: 2.260951519012451
Validation loss: 2.0625257594611055

Epoch: 6| Step: 2
Training loss: 1.0391206741333008
Validation loss: 2.0521563227458666

Epoch: 6| Step: 3
Training loss: 0.942255437374115
Validation loss: 2.05445118616986

Epoch: 6| Step: 4
Training loss: 1.321660041809082
Validation loss: 2.0427350382651053

Epoch: 6| Step: 5
Training loss: 1.5447962284088135
Validation loss: 2.02798242081878

Epoch: 6| Step: 6
Training loss: 0.697666347026825
Validation loss: 2.0164720114841255

Epoch: 6| Step: 7
Training loss: 1.5814471244812012
Validation loss: 2.0255704438814552

Epoch: 6| Step: 8
Training loss: 0.6466599106788635
Validation loss: 2.019091909931552

Epoch: 6| Step: 9
Training loss: 1.2585232257843018
Validation loss: 2.0063792121025825

Epoch: 6| Step: 10
Training loss: 0.931601881980896
Validation loss: 2.015489862811181

Epoch: 6| Step: 11
Training loss: 1.7386038303375244
Validation loss: 2.05429248655996

Epoch: 6| Step: 12
Training loss: 1.4009497165679932
Validation loss: 2.0516023751228087

Epoch: 6| Step: 13
Training loss: 0.9518066048622131
Validation loss: 2.0473483121523293

Epoch: 353| Step: 0
Training loss: 1.499262809753418
Validation loss: 2.0543137596499537

Epoch: 6| Step: 1
Training loss: 1.1999680995941162
Validation loss: 2.0464344024658203

Epoch: 6| Step: 2
Training loss: 1.6025490760803223
Validation loss: 2.058147709856751

Epoch: 6| Step: 3
Training loss: 1.5469834804534912
Validation loss: 2.0747920954099266

Epoch: 6| Step: 4
Training loss: 0.8502170443534851
Validation loss: 2.0175356852110995

Epoch: 6| Step: 5
Training loss: 1.7437357902526855
Validation loss: 2.018291119606264

Epoch: 6| Step: 6
Training loss: 1.7228515148162842
Validation loss: 2.088746419516943

Epoch: 6| Step: 7
Training loss: 0.6048548221588135
Validation loss: 2.034457475908341

Epoch: 6| Step: 8
Training loss: 0.8350314497947693
Validation loss: 2.07564938581118

Epoch: 6| Step: 9
Training loss: 1.2492940425872803
Validation loss: 2.034934946285781

Epoch: 6| Step: 10
Training loss: 1.3593776226043701
Validation loss: 2.0443049387265275

Epoch: 6| Step: 11
Training loss: 1.3714991807937622
Validation loss: 2.0267968549523303

Epoch: 6| Step: 12
Training loss: 0.8124197721481323
Validation loss: 2.060318975038426

Epoch: 6| Step: 13
Training loss: 1.1600146293640137
Validation loss: 2.032569800653765

Epoch: 354| Step: 0
Training loss: 1.2980260848999023
Validation loss: 2.0559955386705298

Epoch: 6| Step: 1
Training loss: 0.9123640060424805
Validation loss: 2.029825475908095

Epoch: 6| Step: 2
Training loss: 1.0899808406829834
Validation loss: 2.043570210856776

Epoch: 6| Step: 3
Training loss: 1.1134295463562012
Validation loss: 2.042757188120196

Epoch: 6| Step: 4
Training loss: 1.0555217266082764
Validation loss: 2.040397410751671

Epoch: 6| Step: 5
Training loss: 1.0080024003982544
Validation loss: 2.0276120965198805

Epoch: 6| Step: 6
Training loss: 1.6166625022888184
Validation loss: 2.047855713034189

Epoch: 6| Step: 7
Training loss: 1.6178892850875854
Validation loss: 2.0572495306691816

Epoch: 6| Step: 8
Training loss: 1.223656177520752
Validation loss: 2.050296914192938

Epoch: 6| Step: 9
Training loss: 1.6104148626327515
Validation loss: 2.0489305962798414

Epoch: 6| Step: 10
Training loss: 1.1971049308776855
Validation loss: 2.070977358407872

Epoch: 6| Step: 11
Training loss: 1.0649094581604004
Validation loss: 2.062926451365153

Epoch: 6| Step: 12
Training loss: 1.3627381324768066
Validation loss: 2.0629707023661625

Epoch: 6| Step: 13
Training loss: 1.1354568004608154
Validation loss: 2.0479284576190415

Epoch: 355| Step: 0
Training loss: 0.9195061922073364
Validation loss: 2.0478866638675814

Epoch: 6| Step: 1
Training loss: 1.28607177734375
Validation loss: 2.039852507652775

Epoch: 6| Step: 2
Training loss: 0.8886899948120117
Validation loss: 2.0420883009510655

Epoch: 6| Step: 3
Training loss: 1.0781357288360596
Validation loss: 2.039042038302268

Epoch: 6| Step: 4
Training loss: 1.2543330192565918
Validation loss: 2.0510032100062214

Epoch: 6| Step: 5
Training loss: 1.0504069328308105
Validation loss: 2.0365739458350727

Epoch: 6| Step: 6
Training loss: 1.501636028289795
Validation loss: 2.066103719895886

Epoch: 6| Step: 7
Training loss: 1.848454236984253
Validation loss: 2.0299847587462394

Epoch: 6| Step: 8
Training loss: 1.1570289134979248
Validation loss: 2.0700983501249746

Epoch: 6| Step: 9
Training loss: 0.7101182341575623
Validation loss: 2.054583834063622

Epoch: 6| Step: 10
Training loss: 1.6664625406265259
Validation loss: 2.0514872022854385

Epoch: 6| Step: 11
Training loss: 1.1606749296188354
Validation loss: 2.047057520958685

Epoch: 6| Step: 12
Training loss: 1.3705071210861206
Validation loss: 2.050350953173894

Epoch: 6| Step: 13
Training loss: 1.4756944179534912
Validation loss: 2.0462388236035585

Epoch: 356| Step: 0
Training loss: 1.5889103412628174
Validation loss: 2.0258013458662134

Epoch: 6| Step: 1
Training loss: 0.7939350605010986
Validation loss: 2.027445140705314

Epoch: 6| Step: 2
Training loss: 1.0138977766036987
Validation loss: 2.0375704252591698

Epoch: 6| Step: 3
Training loss: 1.0079008340835571
Validation loss: 2.0205014085256927

Epoch: 6| Step: 4
Training loss: 1.5161018371582031
Validation loss: 2.0338034142730055

Epoch: 6| Step: 5
Training loss: 1.2054738998413086
Validation loss: 2.0331227958843274

Epoch: 6| Step: 6
Training loss: 1.9547357559204102
Validation loss: 2.021717640661424

Epoch: 6| Step: 7
Training loss: 0.9018558859825134
Validation loss: 2.0309172548273557

Epoch: 6| Step: 8
Training loss: 1.2570090293884277
Validation loss: 2.023778405240787

Epoch: 6| Step: 9
Training loss: 1.5694692134857178
Validation loss: 2.027855657762097

Epoch: 6| Step: 10
Training loss: 1.1336004734039307
Validation loss: 2.020939468055643

Epoch: 6| Step: 11
Training loss: 1.1236379146575928
Validation loss: 1.9971752346202891

Epoch: 6| Step: 12
Training loss: 0.2576165795326233
Validation loss: 2.035921142947289

Epoch: 6| Step: 13
Training loss: 2.2693753242492676
Validation loss: 2.023577674742668

Epoch: 357| Step: 0
Training loss: 0.9984073638916016
Validation loss: 2.024833251071233

Epoch: 6| Step: 1
Training loss: 1.0107636451721191
Validation loss: 2.0613220481462378

Epoch: 6| Step: 2
Training loss: 1.698432445526123
Validation loss: 2.080297512392844

Epoch: 6| Step: 3
Training loss: 0.9504473209381104
Validation loss: 2.0849835424013037

Epoch: 6| Step: 4
Training loss: 1.5124707221984863
Validation loss: 2.065998120974469

Epoch: 6| Step: 5
Training loss: 1.3949381113052368
Validation loss: 2.0760790455725884

Epoch: 6| Step: 6
Training loss: 1.3588554859161377
Validation loss: 2.034325139496916

Epoch: 6| Step: 7
Training loss: 1.0350326299667358
Validation loss: 2.0212206712333103

Epoch: 6| Step: 8
Training loss: 0.8491379618644714
Validation loss: 2.0322663502026628

Epoch: 6| Step: 9
Training loss: 1.505773901939392
Validation loss: 1.99067045539938

Epoch: 6| Step: 10
Training loss: 0.8629665374755859
Validation loss: 1.9901087027724071

Epoch: 6| Step: 11
Training loss: 1.561566948890686
Validation loss: 1.9886989016686716

Epoch: 6| Step: 12
Training loss: 1.5497825145721436
Validation loss: 1.9666518165219216

Epoch: 6| Step: 13
Training loss: 0.689062774181366
Validation loss: 1.989725584624916

Epoch: 358| Step: 0
Training loss: 0.9059370160102844
Validation loss: 1.9897383695007653

Epoch: 6| Step: 1
Training loss: 0.7289277911186218
Validation loss: 1.9946380328106623

Epoch: 6| Step: 2
Training loss: 1.4848278760910034
Validation loss: 2.0046766650292183

Epoch: 6| Step: 3
Training loss: 1.1728190183639526
Validation loss: 2.0035452688893964

Epoch: 6| Step: 4
Training loss: 1.1478954553604126
Validation loss: 2.004712620089131

Epoch: 6| Step: 5
Training loss: 1.145636796951294
Validation loss: 2.009374722357719

Epoch: 6| Step: 6
Training loss: 1.5056555271148682
Validation loss: 2.0408057589684763

Epoch: 6| Step: 7
Training loss: 1.6501591205596924
Validation loss: 2.074926366088211

Epoch: 6| Step: 8
Training loss: 1.5755558013916016
Validation loss: 2.0712274518064273

Epoch: 6| Step: 9
Training loss: 1.380751371383667
Validation loss: 2.0750146168534473

Epoch: 6| Step: 10
Training loss: 0.8218779563903809
Validation loss: 2.0834155851794827

Epoch: 6| Step: 11
Training loss: 1.6470766067504883
Validation loss: 2.0820734103520713

Epoch: 6| Step: 12
Training loss: 1.189257264137268
Validation loss: 2.0827252223927486

Epoch: 6| Step: 13
Training loss: 0.29867905378341675
Validation loss: 2.0529940282144854

Epoch: 359| Step: 0
Training loss: 0.9353169798851013
Validation loss: 2.085922605247908

Epoch: 6| Step: 1
Training loss: 1.4273946285247803
Validation loss: 2.023103542225335

Epoch: 6| Step: 2
Training loss: 1.3242781162261963
Validation loss: 1.9851292999841834

Epoch: 6| Step: 3
Training loss: 1.8027905225753784
Validation loss: 1.9925235432963218

Epoch: 6| Step: 4
Training loss: 1.104652762413025
Validation loss: 1.952091222168297

Epoch: 6| Step: 5
Training loss: 1.2876383066177368
Validation loss: 1.9625152157198997

Epoch: 6| Step: 6
Training loss: 1.4455277919769287
Validation loss: 1.9481168588002522

Epoch: 6| Step: 7
Training loss: 0.7742156982421875
Validation loss: 1.9740654576209284

Epoch: 6| Step: 8
Training loss: 0.843712329864502
Validation loss: 1.9721046032444123

Epoch: 6| Step: 9
Training loss: 1.2944656610488892
Validation loss: 2.010586548877019

Epoch: 6| Step: 10
Training loss: 1.0852372646331787
Validation loss: 2.015278184285728

Epoch: 6| Step: 11
Training loss: 1.1444650888442993
Validation loss: 2.077381600615799

Epoch: 6| Step: 12
Training loss: 1.8400321006774902
Validation loss: 2.1009387200878513

Epoch: 6| Step: 13
Training loss: 0.5182356834411621
Validation loss: 2.0935215386011268

Epoch: 360| Step: 0
Training loss: 1.4123213291168213
Validation loss: 2.092342544627446

Epoch: 6| Step: 1
Training loss: 1.787971019744873
Validation loss: 2.05749402764023

Epoch: 6| Step: 2
Training loss: 1.3128266334533691
Validation loss: 2.045156148172194

Epoch: 6| Step: 3
Training loss: 1.6113457679748535
Validation loss: 2.040933606445148

Epoch: 6| Step: 4
Training loss: 0.8800848126411438
Validation loss: 2.038151225736064

Epoch: 6| Step: 5
Training loss: 0.8210946917533875
Validation loss: 2.0499560602249636

Epoch: 6| Step: 6
Training loss: 1.1120086908340454
Validation loss: 2.0736360588381366

Epoch: 6| Step: 7
Training loss: 1.4166983366012573
Validation loss: 2.0783550111196374

Epoch: 6| Step: 8
Training loss: 1.2467180490493774
Validation loss: 2.0248298837292578

Epoch: 6| Step: 9
Training loss: 1.2342371940612793
Validation loss: 2.073957432982742

Epoch: 6| Step: 10
Training loss: 0.8171316385269165
Validation loss: 2.035464317567887

Epoch: 6| Step: 11
Training loss: 0.7501598596572876
Validation loss: 2.017194694088351

Epoch: 6| Step: 12
Training loss: 1.1106404066085815
Validation loss: 2.0132703024853944

Epoch: 6| Step: 13
Training loss: 1.6867280006408691
Validation loss: 2.027449233557588

Epoch: 361| Step: 0
Training loss: 0.7399599552154541
Validation loss: 2.0143895251776582

Epoch: 6| Step: 1
Training loss: 1.489288091659546
Validation loss: 1.9986165287674114

Epoch: 6| Step: 2
Training loss: 0.5278109908103943
Validation loss: 1.978922264550322

Epoch: 6| Step: 3
Training loss: 1.4179916381835938
Validation loss: 1.9735918186044181

Epoch: 6| Step: 4
Training loss: 1.3386589288711548
Validation loss: 1.9559791241922686

Epoch: 6| Step: 5
Training loss: 1.4219553470611572
Validation loss: 1.9693991522635184

Epoch: 6| Step: 6
Training loss: 1.6940407752990723
Validation loss: 1.9806992776932255

Epoch: 6| Step: 7
Training loss: 0.9654160737991333
Validation loss: 1.9766037207777782

Epoch: 6| Step: 8
Training loss: 1.745957612991333
Validation loss: 1.9933201305327877

Epoch: 6| Step: 9
Training loss: 1.1242737770080566
Validation loss: 2.0321119523817495

Epoch: 6| Step: 10
Training loss: 1.1177037954330444
Validation loss: 2.028304451255388

Epoch: 6| Step: 11
Training loss: 1.2624945640563965
Validation loss: 2.044989316694198

Epoch: 6| Step: 12
Training loss: 0.8887543678283691
Validation loss: 2.093861545285871

Epoch: 6| Step: 13
Training loss: 1.029778242111206
Validation loss: 2.1101390674550045

Epoch: 362| Step: 0
Training loss: 1.4594831466674805
Validation loss: 2.078122613250568

Epoch: 6| Step: 1
Training loss: 1.0313045978546143
Validation loss: 2.0760003776960474

Epoch: 6| Step: 2
Training loss: 1.2436619997024536
Validation loss: 2.108850356071226

Epoch: 6| Step: 3
Training loss: 1.3877179622650146
Validation loss: 2.0649951863032516

Epoch: 6| Step: 4
Training loss: 1.3592629432678223
Validation loss: 2.0486832241858206

Epoch: 6| Step: 5
Training loss: 0.9253016710281372
Validation loss: 2.040980674887216

Epoch: 6| Step: 6
Training loss: 0.9180676937103271
Validation loss: 2.034110676857733

Epoch: 6| Step: 7
Training loss: 0.5709223747253418
Validation loss: 2.0063685947848904

Epoch: 6| Step: 8
Training loss: 1.4020798206329346
Validation loss: 1.991083409196587

Epoch: 6| Step: 9
Training loss: 1.4686779975891113
Validation loss: 2.0018201361420336

Epoch: 6| Step: 10
Training loss: 1.1273179054260254
Validation loss: 1.9780968414839877

Epoch: 6| Step: 11
Training loss: 1.4714322090148926
Validation loss: 1.9951814784798572

Epoch: 6| Step: 12
Training loss: 1.3291493654251099
Validation loss: 1.9701485838941348

Epoch: 6| Step: 13
Training loss: 0.9274823665618896
Validation loss: 1.9687859691599363

Epoch: 363| Step: 0
Training loss: 1.3111004829406738
Validation loss: 1.9718930900737803

Epoch: 6| Step: 1
Training loss: 1.321683406829834
Validation loss: 1.9823265152592813

Epoch: 6| Step: 2
Training loss: 1.2716774940490723
Validation loss: 1.9988599605457757

Epoch: 6| Step: 3
Training loss: 0.5312202572822571
Validation loss: 2.0146979683188984

Epoch: 6| Step: 4
Training loss: 1.187787413597107
Validation loss: 2.0249433889183948

Epoch: 6| Step: 5
Training loss: 1.2799131870269775
Validation loss: 2.027429906270837

Epoch: 6| Step: 6
Training loss: 1.5318529605865479
Validation loss: 2.0332986052318285

Epoch: 6| Step: 7
Training loss: 1.2120729684829712
Validation loss: 2.050782372874598

Epoch: 6| Step: 8
Training loss: 1.2903897762298584
Validation loss: 2.0554546438237673

Epoch: 6| Step: 9
Training loss: 0.8250167965888977
Validation loss: 2.0770566335288425

Epoch: 6| Step: 10
Training loss: 1.5491489171981812
Validation loss: 2.0574286727495092

Epoch: 6| Step: 11
Training loss: 0.7590888738632202
Validation loss: 2.0402738586548836

Epoch: 6| Step: 12
Training loss: 1.733079195022583
Validation loss: 2.0480509906686764

Epoch: 6| Step: 13
Training loss: 0.558908998966217
Validation loss: 2.0544023872703634

Epoch: 364| Step: 0
Training loss: 0.7061076164245605
Validation loss: 2.031586987997896

Epoch: 6| Step: 1
Training loss: 1.1484789848327637
Validation loss: 2.033272353551721

Epoch: 6| Step: 2
Training loss: 1.6223171949386597
Validation loss: 2.02884699708672

Epoch: 6| Step: 3
Training loss: 1.1314072608947754
Validation loss: 2.0339922994695683

Epoch: 6| Step: 4
Training loss: 0.7149375081062317
Validation loss: 2.0522860198892574

Epoch: 6| Step: 5
Training loss: 1.1338014602661133
Validation loss: 2.0094876238094863

Epoch: 6| Step: 6
Training loss: 1.514095664024353
Validation loss: 1.9919185074426795

Epoch: 6| Step: 7
Training loss: 1.1480956077575684
Validation loss: 1.9753679793368104

Epoch: 6| Step: 8
Training loss: 1.187719464302063
Validation loss: 1.969444364629766

Epoch: 6| Step: 9
Training loss: 1.1276049613952637
Validation loss: 1.980984616023238

Epoch: 6| Step: 10
Training loss: 1.3275251388549805
Validation loss: 1.9726077266918716

Epoch: 6| Step: 11
Training loss: 0.990044355392456
Validation loss: 1.9571033652110765

Epoch: 6| Step: 12
Training loss: 1.1561329364776611
Validation loss: 1.9841453247172858

Epoch: 6| Step: 13
Training loss: 1.6662440299987793
Validation loss: 2.007703632436773

Epoch: 365| Step: 0
Training loss: 1.358149766921997
Validation loss: 2.014229478374604

Epoch: 6| Step: 1
Training loss: 1.1619913578033447
Validation loss: 2.0045599963075373

Epoch: 6| Step: 2
Training loss: 1.1617486476898193
Validation loss: 2.0191551498187486

Epoch: 6| Step: 3
Training loss: 2.2082200050354004
Validation loss: 2.0098579058083157

Epoch: 6| Step: 4
Training loss: 1.285757064819336
Validation loss: 1.9660181358296385

Epoch: 6| Step: 5
Training loss: 1.0324140787124634
Validation loss: 1.9495495032238703

Epoch: 6| Step: 6
Training loss: 1.4256808757781982
Validation loss: 1.9688856781169932

Epoch: 6| Step: 7
Training loss: 1.483393669128418
Validation loss: 1.9856334668333813

Epoch: 6| Step: 8
Training loss: 0.6951022148132324
Validation loss: 1.989361827091504

Epoch: 6| Step: 9
Training loss: 1.0105929374694824
Validation loss: 1.971125380967253

Epoch: 6| Step: 10
Training loss: 0.7353006601333618
Validation loss: 2.0090779681359567

Epoch: 6| Step: 11
Training loss: 1.3928592205047607
Validation loss: 2.0388101070157942

Epoch: 6| Step: 12
Training loss: 0.680859386920929
Validation loss: 2.034739940397201

Epoch: 6| Step: 13
Training loss: 0.8267822861671448
Validation loss: 2.0339758165421022

Epoch: 366| Step: 0
Training loss: 1.2538480758666992
Validation loss: 2.0836963269018356

Epoch: 6| Step: 1
Training loss: 1.0631482601165771
Validation loss: 2.085216397880226

Epoch: 6| Step: 2
Training loss: 1.6037836074829102
Validation loss: 2.048882243453815

Epoch: 6| Step: 3
Training loss: 1.144989013671875
Validation loss: 2.059587956756674

Epoch: 6| Step: 4
Training loss: 1.4520535469055176
Validation loss: 2.029864686791615

Epoch: 6| Step: 5
Training loss: 0.9809274673461914
Validation loss: 2.0144128837893085

Epoch: 6| Step: 6
Training loss: 1.283671498298645
Validation loss: 2.012011779251919

Epoch: 6| Step: 7
Training loss: 1.905615210533142
Validation loss: 1.9986401450249456

Epoch: 6| Step: 8
Training loss: 1.081470012664795
Validation loss: 1.9826394281079691

Epoch: 6| Step: 9
Training loss: 1.1164662837982178
Validation loss: 2.006650012026551

Epoch: 6| Step: 10
Training loss: 0.5114739537239075
Validation loss: 2.0116540462740007

Epoch: 6| Step: 11
Training loss: 1.0177576541900635
Validation loss: 2.0005381453421807

Epoch: 6| Step: 12
Training loss: 0.7160959243774414
Validation loss: 2.027119492971769

Epoch: 6| Step: 13
Training loss: 1.4233118295669556
Validation loss: 2.049881145518313

Epoch: 367| Step: 0
Training loss: 1.2014415264129639
Validation loss: 2.0666390644606722

Epoch: 6| Step: 1
Training loss: 1.2791550159454346
Validation loss: 2.056152279658984

Epoch: 6| Step: 2
Training loss: 1.06795072555542
Validation loss: 2.0457162857055664

Epoch: 6| Step: 3
Training loss: 1.1825602054595947
Validation loss: 2.0368135641979914

Epoch: 6| Step: 4
Training loss: 1.1394139528274536
Validation loss: 2.0167757952085106

Epoch: 6| Step: 5
Training loss: 1.286128282546997
Validation loss: 2.025654920967676

Epoch: 6| Step: 6
Training loss: 0.7189521193504333
Validation loss: 2.006985454149144

Epoch: 6| Step: 7
Training loss: 1.2427263259887695
Validation loss: 2.0162259865832586

Epoch: 6| Step: 8
Training loss: 1.3817158937454224
Validation loss: 2.0226871787860827

Epoch: 6| Step: 9
Training loss: 1.5568214654922485
Validation loss: 2.013782702466493

Epoch: 6| Step: 10
Training loss: 0.6328922510147095
Validation loss: 2.020764150927144

Epoch: 6| Step: 11
Training loss: 1.0338218212127686
Validation loss: 1.9983698578291043

Epoch: 6| Step: 12
Training loss: 1.4846575260162354
Validation loss: 2.0168636255366827

Epoch: 6| Step: 13
Training loss: 1.3726677894592285
Validation loss: 1.9923742458384524

Epoch: 368| Step: 0
Training loss: 1.3133413791656494
Validation loss: 1.9779274156016688

Epoch: 6| Step: 1
Training loss: 1.2406688928604126
Validation loss: 1.9583091120566092

Epoch: 6| Step: 2
Training loss: 0.8681408762931824
Validation loss: 1.9496034947774743

Epoch: 6| Step: 3
Training loss: 1.790642261505127
Validation loss: 1.9255429570392897

Epoch: 6| Step: 4
Training loss: 1.650396466255188
Validation loss: 1.9430692285619757

Epoch: 6| Step: 5
Training loss: 1.2894129753112793
Validation loss: 1.9140763744231193

Epoch: 6| Step: 6
Training loss: 0.7980457544326782
Validation loss: 1.9176481270021009

Epoch: 6| Step: 7
Training loss: 1.0408341884613037
Validation loss: 1.9549413163174865

Epoch: 6| Step: 8
Training loss: 1.1532907485961914
Validation loss: 1.9753431235590289

Epoch: 6| Step: 9
Training loss: 0.8622819185256958
Validation loss: 2.0098163671390985

Epoch: 6| Step: 10
Training loss: 0.6408861875534058
Validation loss: 2.027239635426511

Epoch: 6| Step: 11
Training loss: 1.1180751323699951
Validation loss: 2.0456840543336767

Epoch: 6| Step: 12
Training loss: 1.3063294887542725
Validation loss: 2.045082761395362

Epoch: 6| Step: 13
Training loss: 1.2555421590805054
Validation loss: 2.0480438791295534

Epoch: 369| Step: 0
Training loss: 1.3220152854919434
Validation loss: 2.048377295976044

Epoch: 6| Step: 1
Training loss: 1.0191786289215088
Validation loss: 2.0127080550757785

Epoch: 6| Step: 2
Training loss: 0.41370970010757446
Validation loss: 2.009566076340214

Epoch: 6| Step: 3
Training loss: 0.599689245223999
Validation loss: 2.0185624027764923

Epoch: 6| Step: 4
Training loss: 1.3460339307785034
Validation loss: 2.011970491819484

Epoch: 6| Step: 5
Training loss: 1.236424446105957
Validation loss: 1.993969722460675

Epoch: 6| Step: 6
Training loss: 1.7949066162109375
Validation loss: 1.9631018305337558

Epoch: 6| Step: 7
Training loss: 1.3463664054870605
Validation loss: 1.9779280744573122

Epoch: 6| Step: 8
Training loss: 0.8722905516624451
Validation loss: 1.9685330121747908

Epoch: 6| Step: 9
Training loss: 1.6438764333724976
Validation loss: 1.9605813231519473

Epoch: 6| Step: 10
Training loss: 1.0124597549438477
Validation loss: 1.9966574817575433

Epoch: 6| Step: 11
Training loss: 0.8873493075370789
Validation loss: 1.9739647872986332

Epoch: 6| Step: 12
Training loss: 1.4975392818450928
Validation loss: 1.9435501765179377

Epoch: 6| Step: 13
Training loss: 1.1994587182998657
Validation loss: 1.9486232675531858

Epoch: 370| Step: 0
Training loss: 0.7530224323272705
Validation loss: 1.9633453071758311

Epoch: 6| Step: 1
Training loss: 1.3031435012817383
Validation loss: 1.9288248785080448

Epoch: 6| Step: 2
Training loss: 1.5237581729888916
Validation loss: 1.9468638845669326

Epoch: 6| Step: 3
Training loss: 1.304999589920044
Validation loss: 1.9301968851397115

Epoch: 6| Step: 4
Training loss: 0.7995905876159668
Validation loss: 1.959672115182364

Epoch: 6| Step: 5
Training loss: 1.6749377250671387
Validation loss: 1.9800892645312893

Epoch: 6| Step: 6
Training loss: 1.0150548219680786
Validation loss: 1.948383722254025

Epoch: 6| Step: 7
Training loss: 0.9327881336212158
Validation loss: 1.995678936281512

Epoch: 6| Step: 8
Training loss: 1.1691311597824097
Validation loss: 1.9939978302166026

Epoch: 6| Step: 9
Training loss: 0.9249093532562256
Validation loss: 2.0236434269976873

Epoch: 6| Step: 10
Training loss: 0.9629384875297546
Validation loss: 2.0472332610878894

Epoch: 6| Step: 11
Training loss: 1.3526554107666016
Validation loss: 2.0616311360430974

Epoch: 6| Step: 12
Training loss: 1.2070281505584717
Validation loss: 2.0827661714246197

Epoch: 6| Step: 13
Training loss: 1.1263965368270874
Validation loss: 2.069329930889991

Epoch: 371| Step: 0
Training loss: 1.0461722612380981
Validation loss: 2.0812632781203075

Epoch: 6| Step: 1
Training loss: 1.0692291259765625
Validation loss: 2.0717065923957416

Epoch: 6| Step: 2
Training loss: 1.0979278087615967
Validation loss: 2.0427336872264905

Epoch: 6| Step: 3
Training loss: 1.2028199434280396
Validation loss: 2.015771483862272

Epoch: 6| Step: 4
Training loss: 0.9922116994857788
Validation loss: 1.9997350297948366

Epoch: 6| Step: 5
Training loss: 0.9469725489616394
Validation loss: 1.989237872503137

Epoch: 6| Step: 6
Training loss: 0.9049230813980103
Validation loss: 1.9612502974848594

Epoch: 6| Step: 7
Training loss: 1.8475196361541748
Validation loss: 1.9455283944324782

Epoch: 6| Step: 8
Training loss: 1.2795050144195557
Validation loss: 1.9508757488701933

Epoch: 6| Step: 9
Training loss: 0.8901201486587524
Validation loss: 1.926723535342883

Epoch: 6| Step: 10
Training loss: 0.7595414519309998
Validation loss: 1.9769168899905296

Epoch: 6| Step: 11
Training loss: 1.4811511039733887
Validation loss: 1.9738127698180497

Epoch: 6| Step: 12
Training loss: 1.4066776037216187
Validation loss: 1.9683498323604625

Epoch: 6| Step: 13
Training loss: 1.0477818250656128
Validation loss: 1.9858130729326637

Epoch: 372| Step: 0
Training loss: 1.3712273836135864
Validation loss: 1.999427290372951

Epoch: 6| Step: 1
Training loss: 1.9601994752883911
Validation loss: 1.9550702007867957

Epoch: 6| Step: 2
Training loss: 1.1884806156158447
Validation loss: 1.9478619355027393

Epoch: 6| Step: 3
Training loss: 0.4593319296836853
Validation loss: 1.9373804061643538

Epoch: 6| Step: 4
Training loss: 0.9360817074775696
Validation loss: 1.9451161597364692

Epoch: 6| Step: 5
Training loss: 1.379526138305664
Validation loss: 1.9219526129384195

Epoch: 6| Step: 6
Training loss: 0.6997599005699158
Validation loss: 1.949046855331749

Epoch: 6| Step: 7
Training loss: 1.5044429302215576
Validation loss: 1.9701953011174356

Epoch: 6| Step: 8
Training loss: 1.481270432472229
Validation loss: 1.9792363336009364

Epoch: 6| Step: 9
Training loss: 0.8313577771186829
Validation loss: 2.0125955074064192

Epoch: 6| Step: 10
Training loss: 1.0877480506896973
Validation loss: 2.049372805062161

Epoch: 6| Step: 11
Training loss: 0.9063774943351746
Validation loss: 2.0979623410009567

Epoch: 6| Step: 12
Training loss: 1.1428337097167969
Validation loss: 2.067592279885405

Epoch: 6| Step: 13
Training loss: 0.9809491634368896
Validation loss: 2.0583248907519924

Epoch: 373| Step: 0
Training loss: 1.5884501934051514
Validation loss: 2.0462442662126277

Epoch: 6| Step: 1
Training loss: 1.2842626571655273
Validation loss: 2.027498382394032

Epoch: 6| Step: 2
Training loss: 0.832560658454895
Validation loss: 2.0217817432136944

Epoch: 6| Step: 3
Training loss: 1.394320011138916
Validation loss: 1.9868653256406066

Epoch: 6| Step: 4
Training loss: 1.0833349227905273
Validation loss: 1.9518109957377117

Epoch: 6| Step: 5
Training loss: 0.976535439491272
Validation loss: 1.9606316935631536

Epoch: 6| Step: 6
Training loss: 1.3672945499420166
Validation loss: 1.9706657830105032

Epoch: 6| Step: 7
Training loss: 1.1384485960006714
Validation loss: 1.951830869079918

Epoch: 6| Step: 8
Training loss: 1.106560230255127
Validation loss: 1.9417839806566957

Epoch: 6| Step: 9
Training loss: 1.2877851724624634
Validation loss: 1.9801179414154382

Epoch: 6| Step: 10
Training loss: 0.7177984118461609
Validation loss: 1.9895929059674662

Epoch: 6| Step: 11
Training loss: 0.7322909832000732
Validation loss: 1.992783458002152

Epoch: 6| Step: 12
Training loss: 1.305546522140503
Validation loss: 1.9861573057789956

Epoch: 6| Step: 13
Training loss: 1.1570366621017456
Validation loss: 1.988606365778113

Epoch: 374| Step: 0
Training loss: 1.2939945459365845
Validation loss: 1.9721782284398233

Epoch: 6| Step: 1
Training loss: 1.3392956256866455
Validation loss: 2.0068680060807096

Epoch: 6| Step: 2
Training loss: 1.0497722625732422
Validation loss: 1.979602889348102

Epoch: 6| Step: 3
Training loss: 1.6099737882614136
Validation loss: 2.0145638117226223

Epoch: 6| Step: 4
Training loss: 0.8739959001541138
Validation loss: 2.0205253426746657

Epoch: 6| Step: 5
Training loss: 0.8897295594215393
Validation loss: 1.9839823797184934

Epoch: 6| Step: 6
Training loss: 0.8730212450027466
Validation loss: 2.001266425655734

Epoch: 6| Step: 7
Training loss: 1.2406713962554932
Validation loss: 2.027335630950107

Epoch: 6| Step: 8
Training loss: 0.8293737173080444
Validation loss: 2.01682629892903

Epoch: 6| Step: 9
Training loss: 1.1237117052078247
Validation loss: 2.029496487750802

Epoch: 6| Step: 10
Training loss: 1.2298038005828857
Validation loss: 2.0333237442919003

Epoch: 6| Step: 11
Training loss: 1.0303207635879517
Validation loss: 2.0379870527534076

Epoch: 6| Step: 12
Training loss: 1.6067837476730347
Validation loss: 2.0145895224745556

Epoch: 6| Step: 13
Training loss: 0.7283483147621155
Validation loss: 2.03168132100054

Epoch: 375| Step: 0
Training loss: 1.0126514434814453
Validation loss: 2.0030190483216317

Epoch: 6| Step: 1
Training loss: 1.150700330734253
Validation loss: 1.9518993785304408

Epoch: 6| Step: 2
Training loss: 0.965287446975708
Validation loss: 1.9523809686783822

Epoch: 6| Step: 3
Training loss: 1.0206289291381836
Validation loss: 1.913382936549443

Epoch: 6| Step: 4
Training loss: 0.8679522275924683
Validation loss: 1.905429147904919

Epoch: 6| Step: 5
Training loss: 0.8787285685539246
Validation loss: 1.9254256832984187

Epoch: 6| Step: 6
Training loss: 0.9644297957420349
Validation loss: 1.935930061083968

Epoch: 6| Step: 7
Training loss: 1.221980333328247
Validation loss: 1.967607867333197

Epoch: 6| Step: 8
Training loss: 1.7793021202087402
Validation loss: 1.9779211577548776

Epoch: 6| Step: 9
Training loss: 1.32013738155365
Validation loss: 1.9491428970008768

Epoch: 6| Step: 10
Training loss: 1.3778870105743408
Validation loss: 2.0024641483060774

Epoch: 6| Step: 11
Training loss: 0.9233063459396362
Validation loss: 2.007790378344956

Epoch: 6| Step: 12
Training loss: 1.2421562671661377
Validation loss: 2.028078930352324

Epoch: 6| Step: 13
Training loss: 1.1552538871765137
Validation loss: 2.053394076644733

Epoch: 376| Step: 0
Training loss: 0.6546553373336792
Validation loss: 2.0032317523033387

Epoch: 6| Step: 1
Training loss: 1.0101792812347412
Validation loss: 1.963401391942014

Epoch: 6| Step: 2
Training loss: 1.2000492811203003
Validation loss: 1.933518486638223

Epoch: 6| Step: 3
Training loss: 1.4871660470962524
Validation loss: 1.9405344660564134

Epoch: 6| Step: 4
Training loss: 0.8420078754425049
Validation loss: 1.9405776954466296

Epoch: 6| Step: 5
Training loss: 1.4861955642700195
Validation loss: 1.9085305275455597

Epoch: 6| Step: 6
Training loss: 1.3425114154815674
Validation loss: 1.9380125653359197

Epoch: 6| Step: 7
Training loss: 0.9939437508583069
Validation loss: 1.9327360417253228

Epoch: 6| Step: 8
Training loss: 0.47657230496406555
Validation loss: 1.9275395716390302

Epoch: 6| Step: 9
Training loss: 1.5794532299041748
Validation loss: 1.9362002482978247

Epoch: 6| Step: 10
Training loss: 1.0569862127304077
Validation loss: 1.9506180119770828

Epoch: 6| Step: 11
Training loss: 0.8705790042877197
Validation loss: 1.9904407749893844

Epoch: 6| Step: 12
Training loss: 1.609376072883606
Validation loss: 1.9868012564156645

Epoch: 6| Step: 13
Training loss: 1.152222990989685
Validation loss: 1.9883865156481344

Epoch: 377| Step: 0
Training loss: 0.6059896945953369
Validation loss: 1.9910510355426418

Epoch: 6| Step: 1
Training loss: 1.99871826171875
Validation loss: 1.976495704343242

Epoch: 6| Step: 2
Training loss: 1.1599756479263306
Validation loss: 1.988628723288095

Epoch: 6| Step: 3
Training loss: 1.0027995109558105
Validation loss: 1.9626474906039495

Epoch: 6| Step: 4
Training loss: 1.2849563360214233
Validation loss: 1.9634830849145049

Epoch: 6| Step: 5
Training loss: 0.7650303244590759
Validation loss: 1.9805814258513912

Epoch: 6| Step: 6
Training loss: 0.9408162236213684
Validation loss: 1.988256936432213

Epoch: 6| Step: 7
Training loss: 1.0699516534805298
Validation loss: 1.9545942493664321

Epoch: 6| Step: 8
Training loss: 0.6537880301475525
Validation loss: 1.9943763235563874

Epoch: 6| Step: 9
Training loss: 1.0574893951416016
Validation loss: 1.9946220228748937

Epoch: 6| Step: 10
Training loss: 1.5387505292892456
Validation loss: 1.972729165066955

Epoch: 6| Step: 11
Training loss: 0.9343251585960388
Validation loss: 1.9384683024498723

Epoch: 6| Step: 12
Training loss: 1.2687382698059082
Validation loss: 1.9474134599008868

Epoch: 6| Step: 13
Training loss: 1.081148624420166
Validation loss: 1.9664089051626061

Epoch: 378| Step: 0
Training loss: 0.5793864130973816
Validation loss: 1.970773676390289

Epoch: 6| Step: 1
Training loss: 0.960928201675415
Validation loss: 2.003421319428311

Epoch: 6| Step: 2
Training loss: 0.7214100360870361
Validation loss: 1.968193700236659

Epoch: 6| Step: 3
Training loss: 1.283969521522522
Validation loss: 1.9988276843101747

Epoch: 6| Step: 4
Training loss: 1.0306262969970703
Validation loss: 1.9927537838617961

Epoch: 6| Step: 5
Training loss: 0.9255286455154419
Validation loss: 2.012510625264978

Epoch: 6| Step: 6
Training loss: 1.2241934537887573
Validation loss: 1.9964220754561885

Epoch: 6| Step: 7
Training loss: 0.8398867249488831
Validation loss: 1.9880477202835904

Epoch: 6| Step: 8
Training loss: 1.2042012214660645
Validation loss: 2.016457688423895

Epoch: 6| Step: 9
Training loss: 1.5814696550369263
Validation loss: 1.9868541994402487

Epoch: 6| Step: 10
Training loss: 1.1026270389556885
Validation loss: 1.960514655677221

Epoch: 6| Step: 11
Training loss: 1.1900954246520996
Validation loss: 1.9631882713687034

Epoch: 6| Step: 12
Training loss: 1.4654936790466309
Validation loss: 1.9595092112018215

Epoch: 6| Step: 13
Training loss: 1.3244283199310303
Validation loss: 1.944985028236143

Epoch: 379| Step: 0
Training loss: 1.2799855470657349
Validation loss: 1.9355393263601488

Epoch: 6| Step: 1
Training loss: 1.5844502449035645
Validation loss: 1.996366536745461

Epoch: 6| Step: 2
Training loss: 0.8986303806304932
Validation loss: 1.9795975633846816

Epoch: 6| Step: 3
Training loss: 0.9746356010437012
Validation loss: 1.9728583033366869

Epoch: 6| Step: 4
Training loss: 0.9709831476211548
Validation loss: 1.98589886132107

Epoch: 6| Step: 5
Training loss: 1.3309991359710693
Validation loss: 1.9672024737122238

Epoch: 6| Step: 6
Training loss: 1.3777494430541992
Validation loss: 1.985787110943948

Epoch: 6| Step: 7
Training loss: 0.7861381769180298
Validation loss: 1.9360228943568405

Epoch: 6| Step: 8
Training loss: 1.244160771369934
Validation loss: 1.9343592774483465

Epoch: 6| Step: 9
Training loss: 0.7144320011138916
Validation loss: 1.9463943127662904

Epoch: 6| Step: 10
Training loss: 0.817147970199585
Validation loss: 1.9189603021067958

Epoch: 6| Step: 11
Training loss: 0.8394359350204468
Validation loss: 1.9405386217178837

Epoch: 6| Step: 12
Training loss: 1.2493319511413574
Validation loss: 1.9559891275180283

Epoch: 6| Step: 13
Training loss: 1.2260183095932007
Validation loss: 1.9581942237833494

Epoch: 380| Step: 0
Training loss: 0.990713357925415
Validation loss: 1.96757286466578

Epoch: 6| Step: 1
Training loss: 1.0108108520507812
Validation loss: 1.9745874725362307

Epoch: 6| Step: 2
Training loss: 1.0494803190231323
Validation loss: 1.9942734036394345

Epoch: 6| Step: 3
Training loss: 1.4754290580749512
Validation loss: 1.9878669708005843

Epoch: 6| Step: 4
Training loss: 0.9732367396354675
Validation loss: 1.9702195544396677

Epoch: 6| Step: 5
Training loss: 1.3309762477874756
Validation loss: 1.9831709028572164

Epoch: 6| Step: 6
Training loss: 1.2667624950408936
Validation loss: 1.9759901915827105

Epoch: 6| Step: 7
Training loss: 1.3795477151870728
Validation loss: 1.9358582086460565

Epoch: 6| Step: 8
Training loss: 0.7966296672821045
Validation loss: 1.9132339569830126

Epoch: 6| Step: 9
Training loss: 1.226132869720459
Validation loss: 1.9091276943042714

Epoch: 6| Step: 10
Training loss: 0.9357469081878662
Validation loss: 1.9239663565030662

Epoch: 6| Step: 11
Training loss: 0.9021008610725403
Validation loss: 1.9300509140055666

Epoch: 6| Step: 12
Training loss: 0.8842321634292603
Validation loss: 1.9661848545074463

Epoch: 6| Step: 13
Training loss: 1.1159626245498657
Validation loss: 1.9551396190479238

Epoch: 381| Step: 0
Training loss: 1.371645450592041
Validation loss: 1.9102209460350774

Epoch: 6| Step: 1
Training loss: 1.2346444129943848
Validation loss: 1.9374399518453946

Epoch: 6| Step: 2
Training loss: 0.6903724670410156
Validation loss: 1.9490364725871752

Epoch: 6| Step: 3
Training loss: 0.8086578845977783
Validation loss: 1.9442571158050208

Epoch: 6| Step: 4
Training loss: 1.323059320449829
Validation loss: 1.9527065369390673

Epoch: 6| Step: 5
Training loss: 1.1718136072158813
Validation loss: 1.9524354165600193

Epoch: 6| Step: 6
Training loss: 1.1046509742736816
Validation loss: 1.9816906170178485

Epoch: 6| Step: 7
Training loss: 0.8791608810424805
Validation loss: 1.9719821394130748

Epoch: 6| Step: 8
Training loss: 1.182772159576416
Validation loss: 1.9976995427121398

Epoch: 6| Step: 9
Training loss: 0.9372044205665588
Validation loss: 2.011078658924308

Epoch: 6| Step: 10
Training loss: 1.3192296028137207
Validation loss: 2.02645246828756

Epoch: 6| Step: 11
Training loss: 1.1047754287719727
Validation loss: 2.0454394330260572

Epoch: 6| Step: 12
Training loss: 0.9013590812683105
Validation loss: 2.014179793737268

Epoch: 6| Step: 13
Training loss: 1.2515522241592407
Validation loss: 2.006135473969162

Epoch: 382| Step: 0
Training loss: 0.8144895434379578
Validation loss: 1.9876631408609369

Epoch: 6| Step: 1
Training loss: 1.326884150505066
Validation loss: 1.9841504853258851

Epoch: 6| Step: 2
Training loss: 1.2378417253494263
Validation loss: 1.9802076124375867

Epoch: 6| Step: 3
Training loss: 1.554728388786316
Validation loss: 1.9705792139935236

Epoch: 6| Step: 4
Training loss: 0.3640667498111725
Validation loss: 1.9675743631137315

Epoch: 6| Step: 5
Training loss: 1.0348786115646362
Validation loss: 1.970036647653067

Epoch: 6| Step: 6
Training loss: 1.574405550956726
Validation loss: 1.9830124211567703

Epoch: 6| Step: 7
Training loss: 1.4269413948059082
Validation loss: 1.989842196946503

Epoch: 6| Step: 8
Training loss: 0.7965673208236694
Validation loss: 1.9835558834896292

Epoch: 6| Step: 9
Training loss: 1.3200304508209229
Validation loss: 1.9791457114681121

Epoch: 6| Step: 10
Training loss: 0.7324700355529785
Validation loss: 2.0043555152031685

Epoch: 6| Step: 11
Training loss: 0.531286358833313
Validation loss: 1.9863127226470618

Epoch: 6| Step: 12
Training loss: 1.1284875869750977
Validation loss: 1.9729817951879194

Epoch: 6| Step: 13
Training loss: 1.5644476413726807
Validation loss: 1.9956236654712307

Epoch: 383| Step: 0
Training loss: 1.1403706073760986
Validation loss: 1.9582725583866079

Epoch: 6| Step: 1
Training loss: 1.2538259029388428
Validation loss: 1.9958162000102382

Epoch: 6| Step: 2
Training loss: 0.8878942131996155
Validation loss: 1.9345146276617562

Epoch: 6| Step: 3
Training loss: 1.3604909181594849
Validation loss: 1.942623717810518

Epoch: 6| Step: 4
Training loss: 1.1228280067443848
Validation loss: 1.9659126484265892

Epoch: 6| Step: 5
Training loss: 1.2543084621429443
Validation loss: 1.9652027827437206

Epoch: 6| Step: 6
Training loss: 1.0903551578521729
Validation loss: 1.956644873465261

Epoch: 6| Step: 7
Training loss: 1.0848863124847412
Validation loss: 1.9675420074052707

Epoch: 6| Step: 8
Training loss: 1.1911616325378418
Validation loss: 1.9829121353805705

Epoch: 6| Step: 9
Training loss: 1.298105001449585
Validation loss: 1.9749113590486589

Epoch: 6| Step: 10
Training loss: 0.826992392539978
Validation loss: 1.9681091949503908

Epoch: 6| Step: 11
Training loss: 0.4035605490207672
Validation loss: 1.9591036932442778

Epoch: 6| Step: 12
Training loss: 0.7830009460449219
Validation loss: 1.972573939190116

Epoch: 6| Step: 13
Training loss: 1.3746979236602783
Validation loss: 1.9620750206772999

Epoch: 384| Step: 0
Training loss: 1.5086276531219482
Validation loss: 1.9663671524293962

Epoch: 6| Step: 1
Training loss: 0.9238694906234741
Validation loss: 1.9574206157397198

Epoch: 6| Step: 2
Training loss: 0.9039396047592163
Validation loss: 2.011055974550145

Epoch: 6| Step: 3
Training loss: 1.2841577529907227
Validation loss: 1.9870505230401152

Epoch: 6| Step: 4
Training loss: 1.057003378868103
Validation loss: 1.9972826306537916

Epoch: 6| Step: 5
Training loss: 1.178755283355713
Validation loss: 2.025863548760773

Epoch: 6| Step: 6
Training loss: 0.9916539788246155
Validation loss: 1.9967886786307059

Epoch: 6| Step: 7
Training loss: 0.9582760334014893
Validation loss: 2.031735151044784

Epoch: 6| Step: 8
Training loss: 1.019020915031433
Validation loss: 2.045019893236058

Epoch: 6| Step: 9
Training loss: 0.49571001529693604
Validation loss: 2.041974893180273

Epoch: 6| Step: 10
Training loss: 1.4956917762756348
Validation loss: 2.039711747118222

Epoch: 6| Step: 11
Training loss: 1.1616699695587158
Validation loss: 1.9992597013391473

Epoch: 6| Step: 12
Training loss: 0.7214698195457458
Validation loss: 2.001315926992765

Epoch: 6| Step: 13
Training loss: 1.452386736869812
Validation loss: 1.9631689607456166

Epoch: 385| Step: 0
Training loss: 0.83099365234375
Validation loss: 1.9263243393231464

Epoch: 6| Step: 1
Training loss: 0.9852929711341858
Validation loss: 1.9530181346401092

Epoch: 6| Step: 2
Training loss: 1.2160627841949463
Validation loss: 1.9050312221691172

Epoch: 6| Step: 3
Training loss: 1.2832372188568115
Validation loss: 1.919587468588224

Epoch: 6| Step: 4
Training loss: 0.7684128284454346
Validation loss: 1.9210627591738136

Epoch: 6| Step: 5
Training loss: 0.9120585918426514
Validation loss: 1.9341740608215332

Epoch: 6| Step: 6
Training loss: 1.3253436088562012
Validation loss: 1.97284867430246

Epoch: 6| Step: 7
Training loss: 1.5627000331878662
Validation loss: 1.9902600575518865

Epoch: 6| Step: 8
Training loss: 0.8777525424957275
Validation loss: 1.987174444301154

Epoch: 6| Step: 9
Training loss: 1.302978277206421
Validation loss: 1.9865805654115574

Epoch: 6| Step: 10
Training loss: 1.081327199935913
Validation loss: 2.0117258269299745

Epoch: 6| Step: 11
Training loss: 0.8269145488739014
Validation loss: 1.9927063436918362

Epoch: 6| Step: 12
Training loss: 0.8154447674751282
Validation loss: 2.0171830859235538

Epoch: 6| Step: 13
Training loss: 1.5578974485397339
Validation loss: 2.0397066659824823

Epoch: 386| Step: 0
Training loss: 0.513636589050293
Validation loss: 2.0161439244465162

Epoch: 6| Step: 1
Training loss: 0.9836106300354004
Validation loss: 2.0277809994195097

Epoch: 6| Step: 2
Training loss: 1.246934413909912
Validation loss: 2.0233073644740607

Epoch: 6| Step: 3
Training loss: 1.082242488861084
Validation loss: 2.0156614985517276

Epoch: 6| Step: 4
Training loss: 1.077085018157959
Validation loss: 2.018950762287263

Epoch: 6| Step: 5
Training loss: 0.8675627708435059
Validation loss: 1.9945912438054239

Epoch: 6| Step: 6
Training loss: 0.9826962351799011
Validation loss: 2.0097648046349965

Epoch: 6| Step: 7
Training loss: 1.1480739116668701
Validation loss: 2.031701967280398

Epoch: 6| Step: 8
Training loss: 1.432219386100769
Validation loss: 1.9987175272357078

Epoch: 6| Step: 9
Training loss: 0.8612000942230225
Validation loss: 1.9832129696364045

Epoch: 6| Step: 10
Training loss: 1.3566362857818604
Validation loss: 1.9507562421983289

Epoch: 6| Step: 11
Training loss: 1.065952181816101
Validation loss: 1.935039568972844

Epoch: 6| Step: 12
Training loss: 1.661705732345581
Validation loss: 1.9324135190697127

Epoch: 6| Step: 13
Training loss: 1.0388033390045166
Validation loss: 1.8902040296985256

Epoch: 387| Step: 0
Training loss: 1.4916329383850098
Validation loss: 1.9038487954806256

Epoch: 6| Step: 1
Training loss: 1.0313057899475098
Validation loss: 1.914236117434758

Epoch: 6| Step: 2
Training loss: 1.1025738716125488
Validation loss: 1.8908861888352262

Epoch: 6| Step: 3
Training loss: 1.4158916473388672
Validation loss: 1.891699242335494

Epoch: 6| Step: 4
Training loss: 0.8846265077590942
Validation loss: 1.8772044028005292

Epoch: 6| Step: 5
Training loss: 0.9302641153335571
Validation loss: 1.907744433290215

Epoch: 6| Step: 6
Training loss: 0.9921034574508667
Validation loss: 1.9145221082113122

Epoch: 6| Step: 7
Training loss: 1.0282741785049438
Validation loss: 1.9100383968763455

Epoch: 6| Step: 8
Training loss: 0.7592799663543701
Validation loss: 1.966412636541551

Epoch: 6| Step: 9
Training loss: 1.3242664337158203
Validation loss: 1.9836240481304865

Epoch: 6| Step: 10
Training loss: 0.8337012529373169
Validation loss: 2.0045675680201542

Epoch: 6| Step: 11
Training loss: 1.2824373245239258
Validation loss: 2.0417147810741136

Epoch: 6| Step: 12
Training loss: 0.9903653860092163
Validation loss: 2.0180270646208074

Epoch: 6| Step: 13
Training loss: 1.0170077085494995
Validation loss: 2.031302129068682

Epoch: 388| Step: 0
Training loss: 0.9982430934906006
Validation loss: 1.9939935309912569

Epoch: 6| Step: 1
Training loss: 0.8787938356399536
Validation loss: 1.9768333588877032

Epoch: 6| Step: 2
Training loss: 0.5600864887237549
Validation loss: 1.9689118926243117

Epoch: 6| Step: 3
Training loss: 1.1646194458007812
Validation loss: 1.983613960204586

Epoch: 6| Step: 4
Training loss: 0.9251224994659424
Validation loss: 1.9757897033486316

Epoch: 6| Step: 5
Training loss: 0.9032100439071655
Validation loss: 1.9672043156880203

Epoch: 6| Step: 6
Training loss: 1.0892643928527832
Validation loss: 1.9821022043945968

Epoch: 6| Step: 7
Training loss: 1.342447280883789
Validation loss: 1.992601038307272

Epoch: 6| Step: 8
Training loss: 0.9151625037193298
Validation loss: 1.9520086101306382

Epoch: 6| Step: 9
Training loss: 1.0715463161468506
Validation loss: 1.9573526138900428

Epoch: 6| Step: 10
Training loss: 1.3293535709381104
Validation loss: 1.9580253106291576

Epoch: 6| Step: 11
Training loss: 1.2626018524169922
Validation loss: 1.9296820266272432

Epoch: 6| Step: 12
Training loss: 0.9531970024108887
Validation loss: 1.9286132794554516

Epoch: 6| Step: 13
Training loss: 1.388861060142517
Validation loss: 1.9110462704012472

Epoch: 389| Step: 0
Training loss: 1.4199014902114868
Validation loss: 1.944159060396174

Epoch: 6| Step: 1
Training loss: 0.7120782136917114
Validation loss: 1.9284929972822948

Epoch: 6| Step: 2
Training loss: 1.4392225742340088
Validation loss: 1.9823941107719176

Epoch: 6| Step: 3
Training loss: 1.1828564405441284
Validation loss: 1.9637590915926042

Epoch: 6| Step: 4
Training loss: 0.7730613946914673
Validation loss: 2.0127320238339004

Epoch: 6| Step: 5
Training loss: 1.309525966644287
Validation loss: 2.007434360442623

Epoch: 6| Step: 6
Training loss: 0.7890779972076416
Validation loss: 1.9886852387459046

Epoch: 6| Step: 7
Training loss: 0.5130363702774048
Validation loss: 2.0231533973447737

Epoch: 6| Step: 8
Training loss: 0.9053676128387451
Validation loss: 1.9751268855987056

Epoch: 6| Step: 9
Training loss: 1.644650936126709
Validation loss: 1.9935620484813568

Epoch: 6| Step: 10
Training loss: 0.7076727151870728
Validation loss: 1.9642477958433089

Epoch: 6| Step: 11
Training loss: 1.0282883644104004
Validation loss: 1.9708905040576894

Epoch: 6| Step: 12
Training loss: 0.8909202814102173
Validation loss: 1.9741476197396555

Epoch: 6| Step: 13
Training loss: 1.3427263498306274
Validation loss: 1.9403965652629893

Epoch: 390| Step: 0
Training loss: 0.9766781330108643
Validation loss: 1.9365637020398212

Epoch: 6| Step: 1
Training loss: 1.127753734588623
Validation loss: 1.9403390781853789

Epoch: 6| Step: 2
Training loss: 1.031848430633545
Validation loss: 1.9401023631454797

Epoch: 6| Step: 3
Training loss: 1.2505724430084229
Validation loss: 1.941050883262388

Epoch: 6| Step: 4
Training loss: 1.2305504083633423
Validation loss: 1.9523513445290186

Epoch: 6| Step: 5
Training loss: 0.8623571395874023
Validation loss: 1.9970977050001903

Epoch: 6| Step: 6
Training loss: 1.0077604055404663
Validation loss: 1.9795113699410551

Epoch: 6| Step: 7
Training loss: 1.1848983764648438
Validation loss: 2.0255697273438975

Epoch: 6| Step: 8
Training loss: 0.9005115032196045
Validation loss: 2.06396343118401

Epoch: 6| Step: 9
Training loss: 1.2647027969360352
Validation loss: 2.0496149524565666

Epoch: 6| Step: 10
Training loss: 0.7627390027046204
Validation loss: 1.9980359500454319

Epoch: 6| Step: 11
Training loss: 0.8590306043624878
Validation loss: 2.025732783861058

Epoch: 6| Step: 12
Training loss: 0.8647220134735107
Validation loss: 1.9932492548419583

Epoch: 6| Step: 13
Training loss: 1.2354732751846313
Validation loss: 1.9807390653958885

Epoch: 391| Step: 0
Training loss: 0.5566394329071045
Validation loss: 1.9479570901522072

Epoch: 6| Step: 1
Training loss: 0.5464012622833252
Validation loss: 1.9748961374323855

Epoch: 6| Step: 2
Training loss: 0.8054215908050537
Validation loss: 1.975304477958269

Epoch: 6| Step: 3
Training loss: 0.9505636096000671
Validation loss: 1.9802138574661747

Epoch: 6| Step: 4
Training loss: 0.9842347502708435
Validation loss: 1.970729338225498

Epoch: 6| Step: 5
Training loss: 1.2915890216827393
Validation loss: 1.9641252025481193

Epoch: 6| Step: 6
Training loss: 1.071040391921997
Validation loss: 1.979723561194635

Epoch: 6| Step: 7
Training loss: 1.0224895477294922
Validation loss: 1.9529373697055283

Epoch: 6| Step: 8
Training loss: 0.9139820337295532
Validation loss: 1.9755112906937957

Epoch: 6| Step: 9
Training loss: 1.1801049709320068
Validation loss: 1.971203120805884

Epoch: 6| Step: 10
Training loss: 1.1631548404693604
Validation loss: 1.954982337131295

Epoch: 6| Step: 11
Training loss: 1.3530025482177734
Validation loss: 1.9654643779159875

Epoch: 6| Step: 12
Training loss: 1.3075300455093384
Validation loss: 1.921824396297496

Epoch: 6| Step: 13
Training loss: 1.480097770690918
Validation loss: 1.9607517232177079

Epoch: 392| Step: 0
Training loss: 1.365447759628296
Validation loss: 1.9823015684722571

Epoch: 6| Step: 1
Training loss: 1.0306906700134277
Validation loss: 1.982223133887014

Epoch: 6| Step: 2
Training loss: 1.0404303073883057
Validation loss: 1.9961203041897024

Epoch: 6| Step: 3
Training loss: 1.0211966037750244
Validation loss: 1.9911660660979569

Epoch: 6| Step: 4
Training loss: 0.5033646821975708
Validation loss: 1.9995325175664758

Epoch: 6| Step: 5
Training loss: 0.6597827672958374
Validation loss: 1.9745578304413827

Epoch: 6| Step: 6
Training loss: 0.8939022421836853
Validation loss: 2.0109825108640935

Epoch: 6| Step: 7
Training loss: 1.0635571479797363
Validation loss: 2.0069233730275142

Epoch: 6| Step: 8
Training loss: 1.591042160987854
Validation loss: 2.008930031971265

Epoch: 6| Step: 9
Training loss: 1.5071907043457031
Validation loss: 1.9684738959035566

Epoch: 6| Step: 10
Training loss: 0.5444443821907043
Validation loss: 1.9593716000997892

Epoch: 6| Step: 11
Training loss: 1.1468236446380615
Validation loss: 1.9639646853170087

Epoch: 6| Step: 12
Training loss: 1.0849230289459229
Validation loss: 1.9840605489669307

Epoch: 6| Step: 13
Training loss: 0.812749981880188
Validation loss: 1.9846396548773653

Epoch: 393| Step: 0
Training loss: 0.9373493194580078
Validation loss: 1.9924742380777996

Epoch: 6| Step: 1
Training loss: 1.2980842590332031
Validation loss: 1.9721734728864444

Epoch: 6| Step: 2
Training loss: 1.25541090965271
Validation loss: 1.9518792603605537

Epoch: 6| Step: 3
Training loss: 1.1432595252990723
Validation loss: 1.947753551185772

Epoch: 6| Step: 4
Training loss: 0.8093101978302002
Validation loss: 1.916295701457608

Epoch: 6| Step: 5
Training loss: 0.306723952293396
Validation loss: 1.9523207551689559

Epoch: 6| Step: 6
Training loss: 1.3718043565750122
Validation loss: 1.95939770308874

Epoch: 6| Step: 7
Training loss: 1.0936840772628784
Validation loss: 1.940986757637352

Epoch: 6| Step: 8
Training loss: 1.0035836696624756
Validation loss: 1.9619269114668652

Epoch: 6| Step: 9
Training loss: 0.5730452537536621
Validation loss: 1.9683921080763622

Epoch: 6| Step: 10
Training loss: 1.1974101066589355
Validation loss: 1.9804522773270965

Epoch: 6| Step: 11
Training loss: 1.3961405754089355
Validation loss: 1.9367567659706197

Epoch: 6| Step: 12
Training loss: 0.5536155104637146
Validation loss: 1.9559146909303562

Epoch: 6| Step: 13
Training loss: 1.4205689430236816
Validation loss: 1.9484625375399025

Epoch: 394| Step: 0
Training loss: 0.8973222970962524
Validation loss: 1.950447049192203

Epoch: 6| Step: 1
Training loss: 0.770850658416748
Validation loss: 1.9518466252152638

Epoch: 6| Step: 2
Training loss: 1.115701675415039
Validation loss: 1.9718399214488205

Epoch: 6| Step: 3
Training loss: 1.6083753108978271
Validation loss: 1.9891882711841213

Epoch: 6| Step: 4
Training loss: 1.3115684986114502
Validation loss: 1.9522985694228963

Epoch: 6| Step: 5
Training loss: 0.984301745891571
Validation loss: 1.9439250769153718

Epoch: 6| Step: 6
Training loss: 1.1116454601287842
Validation loss: 1.9287413653507028

Epoch: 6| Step: 7
Training loss: 0.8093158602714539
Validation loss: 1.9196518826228317

Epoch: 6| Step: 8
Training loss: 1.0269607305526733
Validation loss: 1.9347210417511642

Epoch: 6| Step: 9
Training loss: 1.1668692827224731
Validation loss: 1.9107082505379953

Epoch: 6| Step: 10
Training loss: 0.8347407579421997
Validation loss: 1.939824724710116

Epoch: 6| Step: 11
Training loss: 1.2145031690597534
Validation loss: 1.960708854019001

Epoch: 6| Step: 12
Training loss: 0.6489394307136536
Validation loss: 1.9879289519402288

Epoch: 6| Step: 13
Training loss: 0.6042135953903198
Validation loss: 1.9451961004605858

Epoch: 395| Step: 0
Training loss: 0.3149188458919525
Validation loss: 1.964778754018968

Epoch: 6| Step: 1
Training loss: 1.3118267059326172
Validation loss: 1.972911496316233

Epoch: 6| Step: 2
Training loss: 0.8937715291976929
Validation loss: 1.961170752843221

Epoch: 6| Step: 3
Training loss: 1.1478828191757202
Validation loss: 1.9491539821829846

Epoch: 6| Step: 4
Training loss: 0.8419862389564514
Validation loss: 1.9397139728710215

Epoch: 6| Step: 5
Training loss: 1.0815560817718506
Validation loss: 1.9340290305435017

Epoch: 6| Step: 6
Training loss: 0.9461945295333862
Validation loss: 1.93741746358974

Epoch: 6| Step: 7
Training loss: 1.1794407367706299
Validation loss: 1.9103752284921625

Epoch: 6| Step: 8
Training loss: 1.442862868309021
Validation loss: 1.9155241289446432

Epoch: 6| Step: 9
Training loss: 1.154146671295166
Validation loss: 1.9225194851557414

Epoch: 6| Step: 10
Training loss: 1.0761382579803467
Validation loss: 1.9456185217826598

Epoch: 6| Step: 11
Training loss: 0.6498783826828003
Validation loss: 1.903128013815931

Epoch: 6| Step: 12
Training loss: 1.0550665855407715
Validation loss: 1.9407319048399567

Epoch: 6| Step: 13
Training loss: 0.8611899614334106
Validation loss: 1.9277438156066402

Epoch: 396| Step: 0
Training loss: 1.1344679594039917
Validation loss: 1.966733209548458

Epoch: 6| Step: 1
Training loss: 0.5926892161369324
Validation loss: 1.963273848256757

Epoch: 6| Step: 2
Training loss: 0.7307925820350647
Validation loss: 1.977746073917676

Epoch: 6| Step: 3
Training loss: 1.112473964691162
Validation loss: 1.9998962597180439

Epoch: 6| Step: 4
Training loss: 0.8122034072875977
Validation loss: 2.004799453161096

Epoch: 6| Step: 5
Training loss: 0.6976960897445679
Validation loss: 2.0237602187741186

Epoch: 6| Step: 6
Training loss: 0.9826332330703735
Validation loss: 1.976878737890592

Epoch: 6| Step: 7
Training loss: 1.5318554639816284
Validation loss: 1.9806671680942658

Epoch: 6| Step: 8
Training loss: 1.6736115217208862
Validation loss: 1.9598124052888604

Epoch: 6| Step: 9
Training loss: 0.9039312601089478
Validation loss: 1.9795657979544772

Epoch: 6| Step: 10
Training loss: 0.7909164428710938
Validation loss: 1.9578855858054212

Epoch: 6| Step: 11
Training loss: 0.8206875324249268
Validation loss: 1.968491082550377

Epoch: 6| Step: 12
Training loss: 0.8788570165634155
Validation loss: 1.9343331603593723

Epoch: 6| Step: 13
Training loss: 1.4370485544204712
Validation loss: 1.9446738689176497

Epoch: 397| Step: 0
Training loss: 1.0700700283050537
Validation loss: 1.936376219154686

Epoch: 6| Step: 1
Training loss: 0.9354387521743774
Validation loss: 1.936812464908887

Epoch: 6| Step: 2
Training loss: 0.8941572308540344
Validation loss: 1.956503237447431

Epoch: 6| Step: 3
Training loss: 1.1828787326812744
Validation loss: 1.9611753161235521

Epoch: 6| Step: 4
Training loss: 0.5314986109733582
Validation loss: 1.9538010794629332

Epoch: 6| Step: 5
Training loss: 1.1283458471298218
Validation loss: 1.9570351044336955

Epoch: 6| Step: 6
Training loss: 0.6580685973167419
Validation loss: 1.978658688965664

Epoch: 6| Step: 7
Training loss: 0.6753798127174377
Validation loss: 1.9686080691634968

Epoch: 6| Step: 8
Training loss: 1.563683271408081
Validation loss: 2.015716806534798

Epoch: 6| Step: 9
Training loss: 0.8777008056640625
Validation loss: 2.0071667932694957

Epoch: 6| Step: 10
Training loss: 0.5894874930381775
Validation loss: 2.005507020540135

Epoch: 6| Step: 11
Training loss: 1.6148688793182373
Validation loss: 1.991568068022369

Epoch: 6| Step: 12
Training loss: 1.3408772945404053
Validation loss: 1.9574628876101585

Epoch: 6| Step: 13
Training loss: 0.8563442230224609
Validation loss: 1.9818664699472406

Epoch: 398| Step: 0
Training loss: 0.722991943359375
Validation loss: 1.9363999494942286

Epoch: 6| Step: 1
Training loss: 1.343822956085205
Validation loss: 1.957126150849045

Epoch: 6| Step: 2
Training loss: 1.3130152225494385
Validation loss: 1.9312560789046749

Epoch: 6| Step: 3
Training loss: 0.7338360548019409
Validation loss: 1.9177665402812343

Epoch: 6| Step: 4
Training loss: 1.2890832424163818
Validation loss: 1.9186635145577051

Epoch: 6| Step: 5
Training loss: 1.478769063949585
Validation loss: 1.9033991841859714

Epoch: 6| Step: 6
Training loss: 0.5940757393836975
Validation loss: 1.9156129308926162

Epoch: 6| Step: 7
Training loss: 1.3956488370895386
Validation loss: 1.9330059918024207

Epoch: 6| Step: 8
Training loss: 0.861474871635437
Validation loss: 1.9446963546096638

Epoch: 6| Step: 9
Training loss: 0.9187146425247192
Validation loss: 1.9713510800433416

Epoch: 6| Step: 10
Training loss: 0.8884386420249939
Validation loss: 1.947684149588308

Epoch: 6| Step: 11
Training loss: 0.977504551410675
Validation loss: 1.9582967206995974

Epoch: 6| Step: 12
Training loss: 0.9653027653694153
Validation loss: 1.943533112925868

Epoch: 6| Step: 13
Training loss: 0.32804954051971436
Validation loss: 1.94857205114057

Epoch: 399| Step: 0
Training loss: 0.6359696984291077
Validation loss: 1.9628310716280373

Epoch: 6| Step: 1
Training loss: 1.3936936855316162
Validation loss: 1.9689638755654777

Epoch: 6| Step: 2
Training loss: 1.1373040676116943
Validation loss: 1.9401028874099895

Epoch: 6| Step: 3
Training loss: 0.8914605379104614
Validation loss: 1.9475655107087986

Epoch: 6| Step: 4
Training loss: 0.6967625021934509
Validation loss: 1.956814947948661

Epoch: 6| Step: 5
Training loss: 1.4404683113098145
Validation loss: 1.9468717549436836

Epoch: 6| Step: 6
Training loss: 0.7397181391716003
Validation loss: 1.9462446935715214

Epoch: 6| Step: 7
Training loss: 0.9820518493652344
Validation loss: 1.9473284470137728

Epoch: 6| Step: 8
Training loss: 0.9425835609436035
Validation loss: 1.928071968017086

Epoch: 6| Step: 9
Training loss: 1.4523193836212158
Validation loss: 1.9198866544231292

Epoch: 6| Step: 10
Training loss: 1.070322036743164
Validation loss: 1.9239783876685685

Epoch: 6| Step: 11
Training loss: 1.3651586771011353
Validation loss: 1.9398499496521489

Epoch: 6| Step: 12
Training loss: 0.4277404248714447
Validation loss: 1.932283620680532

Epoch: 6| Step: 13
Training loss: 0.40150853991508484
Validation loss: 1.9245890327679214

Epoch: 400| Step: 0
Training loss: 1.0146993398666382
Validation loss: 1.9439400652403473

Epoch: 6| Step: 1
Training loss: 0.8822644948959351
Validation loss: 1.9199559842386553

Epoch: 6| Step: 2
Training loss: 0.9778838157653809
Validation loss: 1.9538686749755696

Epoch: 6| Step: 3
Training loss: 0.8354319334030151
Validation loss: 1.9367617701971402

Epoch: 6| Step: 4
Training loss: 0.7748190760612488
Validation loss: 1.936985759324925

Epoch: 6| Step: 5
Training loss: 1.1462395191192627
Validation loss: 1.9593026702122023

Epoch: 6| Step: 6
Training loss: 1.211400032043457
Validation loss: 1.9564450838232552

Epoch: 6| Step: 7
Training loss: 0.7854804992675781
Validation loss: 1.9199328909638107

Epoch: 6| Step: 8
Training loss: 0.7554530501365662
Validation loss: 1.93435804049174

Epoch: 6| Step: 9
Training loss: 1.0866811275482178
Validation loss: 1.9569160604989657

Epoch: 6| Step: 10
Training loss: 1.291831374168396
Validation loss: 1.9041471096777147

Epoch: 6| Step: 11
Training loss: 1.173721194267273
Validation loss: 1.905940378865888

Epoch: 6| Step: 12
Training loss: 0.7778931856155396
Validation loss: 1.913566368882374

Epoch: 6| Step: 13
Training loss: 1.036133050918579
Validation loss: 1.9011755656170588

Epoch: 401| Step: 0
Training loss: 0.8346126079559326
Validation loss: 1.9123381337811869

Epoch: 6| Step: 1
Training loss: 0.8292320370674133
Validation loss: 1.9134980734958444

Epoch: 6| Step: 2
Training loss: 1.2131679058074951
Validation loss: 1.8843112607156076

Epoch: 6| Step: 3
Training loss: 1.3945428133010864
Validation loss: 1.9362471462577902

Epoch: 6| Step: 4
Training loss: 1.3276994228363037
Validation loss: 1.9055675973174393

Epoch: 6| Step: 5
Training loss: 0.6266154646873474
Validation loss: 1.9133638745994979

Epoch: 6| Step: 6
Training loss: 1.1388014554977417
Validation loss: 1.9309837305417625

Epoch: 6| Step: 7
Training loss: 0.8103731870651245
Validation loss: 1.9155271207132647

Epoch: 6| Step: 8
Training loss: 1.069132685661316
Validation loss: 1.9291742142810617

Epoch: 6| Step: 9
Training loss: 0.9944108724594116
Validation loss: 1.9632651934059717

Epoch: 6| Step: 10
Training loss: 0.5833591222763062
Validation loss: 1.9685638104715655

Epoch: 6| Step: 11
Training loss: 0.6122365593910217
Validation loss: 1.9784018275558308

Epoch: 6| Step: 12
Training loss: 1.447195053100586
Validation loss: 1.9645243819041918

Epoch: 6| Step: 13
Training loss: 0.5673289895057678
Validation loss: 1.9630185352858676

Epoch: 402| Step: 0
Training loss: 0.8998181819915771
Validation loss: 1.9788328755286433

Epoch: 6| Step: 1
Training loss: 1.0641844272613525
Validation loss: 1.9629017986277097

Epoch: 6| Step: 2
Training loss: 0.8111217021942139
Validation loss: 2.002879088924777

Epoch: 6| Step: 3
Training loss: 0.7182637453079224
Validation loss: 1.9471405603552376

Epoch: 6| Step: 4
Training loss: 0.8565264344215393
Validation loss: 1.9428376984852616

Epoch: 6| Step: 5
Training loss: 0.9561220407485962
Validation loss: 1.9035919430435344

Epoch: 6| Step: 6
Training loss: 1.2420873641967773
Validation loss: 1.9045399158231673

Epoch: 6| Step: 7
Training loss: 1.3617719411849976
Validation loss: 1.9003078809348486

Epoch: 6| Step: 8
Training loss: 1.4557949304580688
Validation loss: 1.9000400240703295

Epoch: 6| Step: 9
Training loss: 0.9764226675033569
Validation loss: 1.9088329858677362

Epoch: 6| Step: 10
Training loss: 0.5790932178497314
Validation loss: 1.8955289394624772

Epoch: 6| Step: 11
Training loss: 0.8930699825286865
Validation loss: 1.9009848640811058

Epoch: 6| Step: 12
Training loss: 0.832577645778656
Validation loss: 1.9427950100232196

Epoch: 6| Step: 13
Training loss: 0.652487576007843
Validation loss: 1.950925128434294

Epoch: 403| Step: 0
Training loss: 0.6355744004249573
Validation loss: 1.9689907976376113

Epoch: 6| Step: 1
Training loss: 1.129943609237671
Validation loss: 1.963883146162956

Epoch: 6| Step: 2
Training loss: 1.0803773403167725
Validation loss: 1.958894507859343

Epoch: 6| Step: 3
Training loss: 0.9398027658462524
Validation loss: 1.9229015227287047

Epoch: 6| Step: 4
Training loss: 1.2094694375991821
Validation loss: 1.9345629779241418

Epoch: 6| Step: 5
Training loss: 1.3690848350524902
Validation loss: 1.9242770684662687

Epoch: 6| Step: 6
Training loss: 0.9384195804595947
Validation loss: 1.9292740027109783

Epoch: 6| Step: 7
Training loss: 1.138993740081787
Validation loss: 1.940457909337936

Epoch: 6| Step: 8
Training loss: 0.7430087327957153
Validation loss: 1.936697188244071

Epoch: 6| Step: 9
Training loss: 1.0263597965240479
Validation loss: 1.9490406256850048

Epoch: 6| Step: 10
Training loss: 0.913796067237854
Validation loss: 1.9617837013736847

Epoch: 6| Step: 11
Training loss: 0.8798860311508179
Validation loss: 1.9565876145516672

Epoch: 6| Step: 12
Training loss: 0.8729788064956665
Validation loss: 1.9581453108018445

Epoch: 6| Step: 13
Training loss: 0.5151781439781189
Validation loss: 1.9681175319097375

Epoch: 404| Step: 0
Training loss: 1.1902976036071777
Validation loss: 1.92973800628416

Epoch: 6| Step: 1
Training loss: 1.0268242359161377
Validation loss: 1.927489798556092

Epoch: 6| Step: 2
Training loss: 0.9505214691162109
Validation loss: 1.9272510749037548

Epoch: 6| Step: 3
Training loss: 1.4556342363357544
Validation loss: 1.8950729523935625

Epoch: 6| Step: 4
Training loss: 0.7844436168670654
Validation loss: 1.8764410390648791

Epoch: 6| Step: 5
Training loss: 0.9650978446006775
Validation loss: 1.8905740937879008

Epoch: 6| Step: 6
Training loss: 1.0795106887817383
Validation loss: 1.8697978732406453

Epoch: 6| Step: 7
Training loss: 1.0636439323425293
Validation loss: 1.8782857976933962

Epoch: 6| Step: 8
Training loss: 0.7531627416610718
Validation loss: 1.8904088671489427

Epoch: 6| Step: 9
Training loss: 0.6983940005302429
Validation loss: 1.887447686605556

Epoch: 6| Step: 10
Training loss: 0.8150383830070496
Validation loss: 1.9003574963538878

Epoch: 6| Step: 11
Training loss: 0.6553213596343994
Validation loss: 1.9167320971847863

Epoch: 6| Step: 12
Training loss: 0.9305846691131592
Validation loss: 1.9219211275859545

Epoch: 6| Step: 13
Training loss: 1.314075231552124
Validation loss: 1.9898626650533369

Epoch: 405| Step: 0
Training loss: 0.7919198274612427
Validation loss: 2.0109191351039435

Epoch: 6| Step: 1
Training loss: 0.8037347197532654
Validation loss: 2.009304278640337

Epoch: 6| Step: 2
Training loss: 1.0717658996582031
Validation loss: 2.035546259213519

Epoch: 6| Step: 3
Training loss: 1.1962378025054932
Validation loss: 2.0106660307094617

Epoch: 6| Step: 4
Training loss: 1.2536139488220215
Validation loss: 1.9831053979935185

Epoch: 6| Step: 5
Training loss: 0.9690723419189453
Validation loss: 1.9780981309952275

Epoch: 6| Step: 6
Training loss: 0.8392355442047119
Validation loss: 1.9536362181427658

Epoch: 6| Step: 7
Training loss: 1.4856048822402954
Validation loss: 1.9201366465578797

Epoch: 6| Step: 8
Training loss: 0.8807104825973511
Validation loss: 1.9135678596394037

Epoch: 6| Step: 9
Training loss: 0.8309237957000732
Validation loss: 1.8806846295633624

Epoch: 6| Step: 10
Training loss: 0.8477662801742554
Validation loss: 1.8797448296700754

Epoch: 6| Step: 11
Training loss: 1.107783555984497
Validation loss: 1.8861985155331191

Epoch: 6| Step: 12
Training loss: 0.8392741680145264
Validation loss: 1.8921040129917923

Epoch: 6| Step: 13
Training loss: 0.7700628638267517
Validation loss: 1.9026579344144432

Epoch: 406| Step: 0
Training loss: 0.8723208904266357
Validation loss: 1.9061452310572389

Epoch: 6| Step: 1
Training loss: 0.9430429339408875
Validation loss: 1.9238697187874907

Epoch: 6| Step: 2
Training loss: 0.977302074432373
Validation loss: 1.912784367479304

Epoch: 6| Step: 3
Training loss: 1.422836422920227
Validation loss: 1.9493677141845867

Epoch: 6| Step: 4
Training loss: 0.7922494411468506
Validation loss: 1.9179803620102585

Epoch: 6| Step: 5
Training loss: 1.0816655158996582
Validation loss: 1.9119920820318244

Epoch: 6| Step: 6
Training loss: 1.0071840286254883
Validation loss: 1.91901978113318

Epoch: 6| Step: 7
Training loss: 0.850438117980957
Validation loss: 1.929040947268086

Epoch: 6| Step: 8
Training loss: 0.9304012656211853
Validation loss: 1.9100103327023086

Epoch: 6| Step: 9
Training loss: 1.1953247785568237
Validation loss: 1.938523502760036

Epoch: 6| Step: 10
Training loss: 0.7467247247695923
Validation loss: 1.9315224924395162

Epoch: 6| Step: 11
Training loss: 0.8290791511535645
Validation loss: 1.9304462863552956

Epoch: 6| Step: 12
Training loss: 0.6259899139404297
Validation loss: 1.9414121527825632

Epoch: 6| Step: 13
Training loss: 1.3790068626403809
Validation loss: 1.9476056445029475

Epoch: 407| Step: 0
Training loss: 0.6898825764656067
Validation loss: 1.9424709261104625

Epoch: 6| Step: 1
Training loss: 1.1307293176651
Validation loss: 1.9495927108231412

Epoch: 6| Step: 2
Training loss: 0.9372148513793945
Validation loss: 1.9398466374284478

Epoch: 6| Step: 3
Training loss: 0.6756860613822937
Validation loss: 1.9335596881886965

Epoch: 6| Step: 4
Training loss: 0.7216441631317139
Validation loss: 1.9302249070136779

Epoch: 6| Step: 5
Training loss: 0.8834885358810425
Validation loss: 1.900193856608483

Epoch: 6| Step: 6
Training loss: 0.9798967838287354
Validation loss: 1.8919494164887296

Epoch: 6| Step: 7
Training loss: 0.836927056312561
Validation loss: 1.8913249956664218

Epoch: 6| Step: 8
Training loss: 0.7411839365959167
Validation loss: 1.8887496443204983

Epoch: 6| Step: 9
Training loss: 1.1728777885437012
Validation loss: 1.8759915700522802

Epoch: 6| Step: 10
Training loss: 0.9541443586349487
Validation loss: 1.866688907787364

Epoch: 6| Step: 11
Training loss: 0.9302873015403748
Validation loss: 1.893747091293335

Epoch: 6| Step: 12
Training loss: 1.3079371452331543
Validation loss: 1.9076775222696283

Epoch: 6| Step: 13
Training loss: 1.637787103652954
Validation loss: 1.9167121635970248

Epoch: 408| Step: 0
Training loss: 1.048387050628662
Validation loss: 1.9325037694746448

Epoch: 6| Step: 1
Training loss: 0.6447880864143372
Validation loss: 1.8992020109648347

Epoch: 6| Step: 2
Training loss: 0.6832823753356934
Validation loss: 1.909316994810617

Epoch: 6| Step: 3
Training loss: 0.9952079057693481
Validation loss: 1.9127439401483024

Epoch: 6| Step: 4
Training loss: 0.99299156665802
Validation loss: 1.9139259361451673

Epoch: 6| Step: 5
Training loss: 1.1394773721694946
Validation loss: 1.9233030926796697

Epoch: 6| Step: 6
Training loss: 0.8389211893081665
Validation loss: 1.9419115128055695

Epoch: 6| Step: 7
Training loss: 0.8066816329956055
Validation loss: 1.9086303249482186

Epoch: 6| Step: 8
Training loss: 1.08124577999115
Validation loss: 1.929500276042569

Epoch: 6| Step: 9
Training loss: 1.1437857151031494
Validation loss: 1.9429987374172415

Epoch: 6| Step: 10
Training loss: 0.7063422799110413
Validation loss: 1.906667346595436

Epoch: 6| Step: 11
Training loss: 1.3334918022155762
Validation loss: 1.9021167485944686

Epoch: 6| Step: 12
Training loss: 0.7667537927627563
Validation loss: 1.8969861845816336

Epoch: 6| Step: 13
Training loss: 0.9990647435188293
Validation loss: 1.8847037656332857

Epoch: 409| Step: 0
Training loss: 1.1044464111328125
Validation loss: 1.8997618177885651

Epoch: 6| Step: 1
Training loss: 0.7588626146316528
Validation loss: 1.9328950669175835

Epoch: 6| Step: 2
Training loss: 0.7847214341163635
Validation loss: 1.9101267322417228

Epoch: 6| Step: 3
Training loss: 0.8872416019439697
Validation loss: 1.9321138910067979

Epoch: 6| Step: 4
Training loss: 0.6171679496765137
Validation loss: 1.9336121082305908

Epoch: 6| Step: 5
Training loss: 1.1453750133514404
Validation loss: 1.971039548996956

Epoch: 6| Step: 6
Training loss: 1.0334641933441162
Validation loss: 1.9342568561594973

Epoch: 6| Step: 7
Training loss: 0.7489173412322998
Validation loss: 1.9326431930706065

Epoch: 6| Step: 8
Training loss: 1.2138144969940186
Validation loss: 1.8868538807797175

Epoch: 6| Step: 9
Training loss: 0.7209437489509583
Validation loss: 1.901081810715378

Epoch: 6| Step: 10
Training loss: 1.3632984161376953
Validation loss: 1.8866380594109977

Epoch: 6| Step: 11
Training loss: 0.8700546026229858
Validation loss: 1.8985301422816452

Epoch: 6| Step: 12
Training loss: 0.6667937636375427
Validation loss: 1.898169675180989

Epoch: 6| Step: 13
Training loss: 1.7819453477859497
Validation loss: 1.8963168910754624

Epoch: 410| Step: 0
Training loss: 0.8805833458900452
Validation loss: 1.9072414700702955

Epoch: 6| Step: 1
Training loss: 0.9392967820167542
Validation loss: 1.89130526204263

Epoch: 6| Step: 2
Training loss: 1.0462095737457275
Validation loss: 1.9248004587747718

Epoch: 6| Step: 3
Training loss: 1.255555272102356
Validation loss: 1.908652268430238

Epoch: 6| Step: 4
Training loss: 0.6676710247993469
Validation loss: 1.9051994072493685

Epoch: 6| Step: 5
Training loss: 0.5993958711624146
Validation loss: 1.9183890268366823

Epoch: 6| Step: 6
Training loss: 1.010351300239563
Validation loss: 1.8873341660345755

Epoch: 6| Step: 7
Training loss: 1.5168616771697998
Validation loss: 1.8800119764061385

Epoch: 6| Step: 8
Training loss: 0.7755234837532043
Validation loss: 1.8943780647811068

Epoch: 6| Step: 9
Training loss: 1.1828157901763916
Validation loss: 1.9063138987428399

Epoch: 6| Step: 10
Training loss: 0.6610150337219238
Validation loss: 1.8849049281048518

Epoch: 6| Step: 11
Training loss: 0.5911270380020142
Validation loss: 1.877415334024737

Epoch: 6| Step: 12
Training loss: 0.6088056564331055
Validation loss: 1.937913130688411

Epoch: 6| Step: 13
Training loss: 1.3896970748901367
Validation loss: 1.9449637910371185

Epoch: 411| Step: 0
Training loss: 0.6007564663887024
Validation loss: 1.9682706120193645

Epoch: 6| Step: 1
Training loss: 1.4464328289031982
Validation loss: 2.0049382960924538

Epoch: 6| Step: 2
Training loss: 1.5275933742523193
Validation loss: 1.9870262427996563

Epoch: 6| Step: 3
Training loss: 0.6716721653938293
Validation loss: 1.9901423108193181

Epoch: 6| Step: 4
Training loss: 1.0819025039672852
Validation loss: 1.9475010748832458

Epoch: 6| Step: 5
Training loss: 0.8828408718109131
Validation loss: 1.9583640765118342

Epoch: 6| Step: 6
Training loss: 0.8619164228439331
Validation loss: 1.9108305118417228

Epoch: 6| Step: 7
Training loss: 0.8869379758834839
Validation loss: 1.8924454207061439

Epoch: 6| Step: 8
Training loss: 1.0375003814697266
Validation loss: 1.8798350928932108

Epoch: 6| Step: 9
Training loss: 0.6754186153411865
Validation loss: 1.8949763659507997

Epoch: 6| Step: 10
Training loss: 0.4729587435722351
Validation loss: 1.877103832460219

Epoch: 6| Step: 11
Training loss: 1.1022417545318604
Validation loss: 1.8919985960888606

Epoch: 6| Step: 12
Training loss: 1.1662768125534058
Validation loss: 1.8906088054821055

Epoch: 6| Step: 13
Training loss: 0.46197810769081116
Validation loss: 1.8778898357063212

Epoch: 412| Step: 0
Training loss: 1.0375406742095947
Validation loss: 1.922122843803898

Epoch: 6| Step: 1
Training loss: 0.8905339241027832
Validation loss: 1.9484817481810046

Epoch: 6| Step: 2
Training loss: 1.388258457183838
Validation loss: 1.9462189007830877

Epoch: 6| Step: 3
Training loss: 0.7714619636535645
Validation loss: 1.9319629105188514

Epoch: 6| Step: 4
Training loss: 0.9940111637115479
Validation loss: 1.918812697292656

Epoch: 6| Step: 5
Training loss: 1.256438970565796
Validation loss: 1.9065311160138858

Epoch: 6| Step: 6
Training loss: 0.8465152978897095
Validation loss: 1.9216250758017264

Epoch: 6| Step: 7
Training loss: 0.5443373322486877
Validation loss: 1.9003793629266883

Epoch: 6| Step: 8
Training loss: 1.1211025714874268
Validation loss: 1.881502636017338

Epoch: 6| Step: 9
Training loss: 0.8378623127937317
Validation loss: 1.9148384986385223

Epoch: 6| Step: 10
Training loss: 1.0534147024154663
Validation loss: 1.9111541958265408

Epoch: 6| Step: 11
Training loss: 0.720147430896759
Validation loss: 1.8776656491782076

Epoch: 6| Step: 12
Training loss: 0.33937743306159973
Validation loss: 1.906211463353967

Epoch: 6| Step: 13
Training loss: 1.27487051486969
Validation loss: 1.8775660889123076

Epoch: 413| Step: 0
Training loss: 0.9035139083862305
Validation loss: 1.935065859107561

Epoch: 6| Step: 1
Training loss: 1.013359785079956
Validation loss: 1.9582656109204857

Epoch: 6| Step: 2
Training loss: 1.0119612216949463
Validation loss: 1.9828480571828864

Epoch: 6| Step: 3
Training loss: 1.132272720336914
Validation loss: 1.965017322571047

Epoch: 6| Step: 4
Training loss: 1.3739652633666992
Validation loss: 1.9713689024730394

Epoch: 6| Step: 5
Training loss: 0.8154324293136597
Validation loss: 1.9634345013608214

Epoch: 6| Step: 6
Training loss: 0.7499811053276062
Validation loss: 1.920654640402845

Epoch: 6| Step: 7
Training loss: 1.0205130577087402
Validation loss: 1.9037743832475396

Epoch: 6| Step: 8
Training loss: 1.0950382947921753
Validation loss: 1.881153005425648

Epoch: 6| Step: 9
Training loss: 0.5935912728309631
Validation loss: 1.8601442139635804

Epoch: 6| Step: 10
Training loss: 0.5516816973686218
Validation loss: 1.8538346867407522

Epoch: 6| Step: 11
Training loss: 0.7120789289474487
Validation loss: 1.8801379126887168

Epoch: 6| Step: 12
Training loss: 0.855392336845398
Validation loss: 1.8678459582790252

Epoch: 6| Step: 13
Training loss: 1.2675741910934448
Validation loss: 1.8527285847612607

Epoch: 414| Step: 0
Training loss: 0.7779654264450073
Validation loss: 1.8571655570819814

Epoch: 6| Step: 1
Training loss: 0.7928175926208496
Validation loss: 1.840314890748711

Epoch: 6| Step: 2
Training loss: 0.35907360911369324
Validation loss: 1.8708148605080062

Epoch: 6| Step: 3
Training loss: 0.8312625288963318
Validation loss: 1.8612744987651866

Epoch: 6| Step: 4
Training loss: 1.0108370780944824
Validation loss: 1.8440132166749688

Epoch: 6| Step: 5
Training loss: 1.4257279634475708
Validation loss: 1.893569472015545

Epoch: 6| Step: 6
Training loss: 0.5991643667221069
Validation loss: 1.9224127954052341

Epoch: 6| Step: 7
Training loss: 0.6788660883903503
Validation loss: 1.9212279499218028

Epoch: 6| Step: 8
Training loss: 0.9704343676567078
Validation loss: 1.9152108187316566

Epoch: 6| Step: 9
Training loss: 1.2990217208862305
Validation loss: 1.9687955456395303

Epoch: 6| Step: 10
Training loss: 1.2224045991897583
Validation loss: 1.973482935659347

Epoch: 6| Step: 11
Training loss: 0.6392257809638977
Validation loss: 1.9690702576791086

Epoch: 6| Step: 12
Training loss: 0.9359347224235535
Validation loss: 1.9416389183331562

Epoch: 6| Step: 13
Training loss: 1.5726056098937988
Validation loss: 1.9566866505530573

Epoch: 415| Step: 0
Training loss: 0.3916942775249481
Validation loss: 1.900487506261436

Epoch: 6| Step: 1
Training loss: 0.6749175786972046
Validation loss: 1.8952193490920528

Epoch: 6| Step: 2
Training loss: 0.8743833303451538
Validation loss: 1.884396280011823

Epoch: 6| Step: 3
Training loss: 0.911052942276001
Validation loss: 1.882765136739259

Epoch: 6| Step: 4
Training loss: 0.6686660051345825
Validation loss: 1.8921423535193167

Epoch: 6| Step: 5
Training loss: 0.9876142740249634
Validation loss: 1.8994004136772566

Epoch: 6| Step: 6
Training loss: 1.0490516424179077
Validation loss: 1.9131689738201838

Epoch: 6| Step: 7
Training loss: 1.1749567985534668
Validation loss: 1.870841964598625

Epoch: 6| Step: 8
Training loss: 0.6890293955802917
Validation loss: 1.8971550874812628

Epoch: 6| Step: 9
Training loss: 1.2465046644210815
Validation loss: 1.8855493043058662

Epoch: 6| Step: 10
Training loss: 0.8376015424728394
Validation loss: 1.8850372452889719

Epoch: 6| Step: 11
Training loss: 1.1190950870513916
Validation loss: 1.8905126305036648

Epoch: 6| Step: 12
Training loss: 0.8351925611495972
Validation loss: 1.909669699207429

Epoch: 6| Step: 13
Training loss: 1.7015671730041504
Validation loss: 1.8957828565310406

Epoch: 416| Step: 0
Training loss: 0.812503457069397
Validation loss: 1.8907595039695821

Epoch: 6| Step: 1
Training loss: 0.6200833320617676
Validation loss: 1.9218839496694586

Epoch: 6| Step: 2
Training loss: 0.9743058681488037
Validation loss: 1.9410106033407233

Epoch: 6| Step: 3
Training loss: 1.0838887691497803
Validation loss: 1.962843087411696

Epoch: 6| Step: 4
Training loss: 1.2893303632736206
Validation loss: 1.9677274944961711

Epoch: 6| Step: 5
Training loss: 0.9740390181541443
Validation loss: 1.9832041084125478

Epoch: 6| Step: 6
Training loss: 0.9124261736869812
Validation loss: 1.967787088886384

Epoch: 6| Step: 7
Training loss: 0.6644235253334045
Validation loss: 1.9691347973321074

Epoch: 6| Step: 8
Training loss: 0.9963806867599487
Validation loss: 1.9843238143510715

Epoch: 6| Step: 9
Training loss: 1.2317290306091309
Validation loss: 1.9543255554732455

Epoch: 6| Step: 10
Training loss: 0.5000640153884888
Validation loss: 1.9324045053092382

Epoch: 6| Step: 11
Training loss: 0.8140096664428711
Validation loss: 1.9154424205903084

Epoch: 6| Step: 12
Training loss: 1.0909723043441772
Validation loss: 1.8778529987540296

Epoch: 6| Step: 13
Training loss: 0.9724233150482178
Validation loss: 1.8776707174957439

Epoch: 417| Step: 0
Training loss: 0.7650596499443054
Validation loss: 1.867758024123407

Epoch: 6| Step: 1
Training loss: 1.221999168395996
Validation loss: 1.838222849753595

Epoch: 6| Step: 2
Training loss: 0.9518719911575317
Validation loss: 1.8522488186436314

Epoch: 6| Step: 3
Training loss: 0.5970504879951477
Validation loss: 1.8407717853464105

Epoch: 6| Step: 4
Training loss: 0.3352007269859314
Validation loss: 1.8657018548698836

Epoch: 6| Step: 5
Training loss: 1.139055609703064
Validation loss: 1.8742861132467947

Epoch: 6| Step: 6
Training loss: 0.7379112839698792
Validation loss: 1.9375480554437126

Epoch: 6| Step: 7
Training loss: 0.9277148246765137
Validation loss: 1.9578810802070044

Epoch: 6| Step: 8
Training loss: 0.7842739820480347
Validation loss: 1.9822041091098581

Epoch: 6| Step: 9
Training loss: 1.5347106456756592
Validation loss: 1.961901303260557

Epoch: 6| Step: 10
Training loss: 1.1381100416183472
Validation loss: 1.9376184978792745

Epoch: 6| Step: 11
Training loss: 0.9023705720901489
Validation loss: 1.9563320503439954

Epoch: 6| Step: 12
Training loss: 0.8641282320022583
Validation loss: 1.955009396358203

Epoch: 6| Step: 13
Training loss: 1.1270726919174194
Validation loss: 1.942171492884236

Epoch: 418| Step: 0
Training loss: 0.6780524253845215
Validation loss: 1.9150317471514466

Epoch: 6| Step: 1
Training loss: 0.8008391857147217
Validation loss: 1.928423450839135

Epoch: 6| Step: 2
Training loss: 0.8395941257476807
Validation loss: 1.9027414039898944

Epoch: 6| Step: 3
Training loss: 0.7457307577133179
Validation loss: 1.8794722300703808

Epoch: 6| Step: 4
Training loss: 1.3929946422576904
Validation loss: 1.8610426123424242

Epoch: 6| Step: 5
Training loss: 1.1782810688018799
Validation loss: 1.881480937362999

Epoch: 6| Step: 6
Training loss: 1.0687339305877686
Validation loss: 1.8726355503964167

Epoch: 6| Step: 7
Training loss: 1.2178843021392822
Validation loss: 1.8417476351543138

Epoch: 6| Step: 8
Training loss: 0.6810566186904907
Validation loss: 1.8399976709837556

Epoch: 6| Step: 9
Training loss: 0.7696972489356995
Validation loss: 1.8470771569077686

Epoch: 6| Step: 10
Training loss: 0.576859712600708
Validation loss: 1.8716430715335313

Epoch: 6| Step: 11
Training loss: 0.584766685962677
Validation loss: 1.897844878576135

Epoch: 6| Step: 12
Training loss: 1.1453473567962646
Validation loss: 1.9004564028914257

Epoch: 6| Step: 13
Training loss: 1.1779513359069824
Validation loss: 1.9393917642613894

Epoch: 419| Step: 0
Training loss: 0.48463210463523865
Validation loss: 1.9570093500998713

Epoch: 6| Step: 1
Training loss: 0.6584576368331909
Validation loss: 2.000302776213615

Epoch: 6| Step: 2
Training loss: 1.1311196088790894
Validation loss: 2.0111933369790354

Epoch: 6| Step: 3
Training loss: 1.3472274541854858
Validation loss: 1.9867629222972418

Epoch: 6| Step: 4
Training loss: 1.3641712665557861
Validation loss: 1.9809357940509755

Epoch: 6| Step: 5
Training loss: 1.222460389137268
Validation loss: 1.954938164321325

Epoch: 6| Step: 6
Training loss: 1.1197335720062256
Validation loss: 1.940041265180034

Epoch: 6| Step: 7
Training loss: 0.48389407992362976
Validation loss: 1.91400711254407

Epoch: 6| Step: 8
Training loss: 0.5616709589958191
Validation loss: 1.8731141782576037

Epoch: 6| Step: 9
Training loss: 0.6759741306304932
Validation loss: 1.8806608274418821

Epoch: 6| Step: 10
Training loss: 1.0193063020706177
Validation loss: 1.848789785497932

Epoch: 6| Step: 11
Training loss: 0.5720318555831909
Validation loss: 1.8722376861879904

Epoch: 6| Step: 12
Training loss: 0.9735442996025085
Validation loss: 1.8726671485490696

Epoch: 6| Step: 13
Training loss: 1.231445074081421
Validation loss: 1.8688811896949686

Epoch: 420| Step: 0
Training loss: 0.8214881420135498
Validation loss: 1.8825685311389226

Epoch: 6| Step: 1
Training loss: 0.6953095197677612
Validation loss: 1.8944690201872139

Epoch: 6| Step: 2
Training loss: 1.1093592643737793
Validation loss: 1.918256728879867

Epoch: 6| Step: 3
Training loss: 0.5023610591888428
Validation loss: 1.8979073339892971

Epoch: 6| Step: 4
Training loss: 0.6602622866630554
Validation loss: 1.8912232716878254

Epoch: 6| Step: 5
Training loss: 0.7633941173553467
Validation loss: 1.9223238550206667

Epoch: 6| Step: 6
Training loss: 1.0997090339660645
Validation loss: 1.9520482658058085

Epoch: 6| Step: 7
Training loss: 0.7381836175918579
Validation loss: 1.9442702083177463

Epoch: 6| Step: 8
Training loss: 1.1585803031921387
Validation loss: 1.9334603445504301

Epoch: 6| Step: 9
Training loss: 1.1376385688781738
Validation loss: 1.9676419047899143

Epoch: 6| Step: 10
Training loss: 0.8439884185791016
Validation loss: 1.9711663607628114

Epoch: 6| Step: 11
Training loss: 0.905996561050415
Validation loss: 1.9360595364724436

Epoch: 6| Step: 12
Training loss: 1.0591518878936768
Validation loss: 1.917093797396588

Epoch: 6| Step: 13
Training loss: 1.1834540367126465
Validation loss: 1.9292057252699328

Epoch: 421| Step: 0
Training loss: 0.8940001130104065
Validation loss: 1.8954924434743903

Epoch: 6| Step: 1
Training loss: 0.5636196136474609
Validation loss: 1.8910990017716602

Epoch: 6| Step: 2
Training loss: 1.0211129188537598
Validation loss: 1.8599388330213484

Epoch: 6| Step: 3
Training loss: 0.5096583366394043
Validation loss: 1.8386627166501937

Epoch: 6| Step: 4
Training loss: 0.9094237089157104
Validation loss: 1.8428096399512341

Epoch: 6| Step: 5
Training loss: 0.8990225791931152
Validation loss: 1.8664041129491662

Epoch: 6| Step: 6
Training loss: 1.0757296085357666
Validation loss: 1.8590317951735629

Epoch: 6| Step: 7
Training loss: 1.2785098552703857
Validation loss: 1.8760642236278904

Epoch: 6| Step: 8
Training loss: 1.2098058462142944
Validation loss: 1.8721144673644856

Epoch: 6| Step: 9
Training loss: 1.025791883468628
Validation loss: 1.8710474544955837

Epoch: 6| Step: 10
Training loss: 0.7000908851623535
Validation loss: 1.8774956464767456

Epoch: 6| Step: 11
Training loss: 0.9596138000488281
Validation loss: 1.900636717837344

Epoch: 6| Step: 12
Training loss: 0.9183078408241272
Validation loss: 1.895860795051821

Epoch: 6| Step: 13
Training loss: 0.7978554368019104
Validation loss: 1.9406287054861746

Epoch: 422| Step: 0
Training loss: 0.7290422916412354
Validation loss: 1.9328776674885904

Epoch: 6| Step: 1
Training loss: 0.535737931728363
Validation loss: 1.9269154815263645

Epoch: 6| Step: 2
Training loss: 1.1775180101394653
Validation loss: 1.9222459626454178

Epoch: 6| Step: 3
Training loss: 1.1643184423446655
Validation loss: 1.8952985937877367

Epoch: 6| Step: 4
Training loss: 0.8131177425384521
Validation loss: 1.88871766162175

Epoch: 6| Step: 5
Training loss: 1.0362428426742554
Validation loss: 1.8916199630306614

Epoch: 6| Step: 6
Training loss: 0.6637666821479797
Validation loss: 1.89776062709029

Epoch: 6| Step: 7
Training loss: 0.8382517099380493
Validation loss: 1.9263678263592463

Epoch: 6| Step: 8
Training loss: 0.5755575895309448
Validation loss: 1.9135482413794405

Epoch: 6| Step: 9
Training loss: 1.060575008392334
Validation loss: 1.9228429845584336

Epoch: 6| Step: 10
Training loss: 0.7830182313919067
Validation loss: 1.9056190777850408

Epoch: 6| Step: 11
Training loss: 1.1583213806152344
Validation loss: 1.8999436093914894

Epoch: 6| Step: 12
Training loss: 0.9013400673866272
Validation loss: 1.8850288647477345

Epoch: 6| Step: 13
Training loss: 1.0905601978302002
Validation loss: 1.8791128307260492

Epoch: 423| Step: 0
Training loss: 1.246957778930664
Validation loss: 1.8700439827416533

Epoch: 6| Step: 1
Training loss: 0.7561285495758057
Validation loss: 1.8685328524599794

Epoch: 6| Step: 2
Training loss: 0.8088415861129761
Validation loss: 1.8493200630270026

Epoch: 6| Step: 3
Training loss: 0.3896116018295288
Validation loss: 1.848023501775598

Epoch: 6| Step: 4
Training loss: 0.8479030132293701
Validation loss: 1.8739438954220022

Epoch: 6| Step: 5
Training loss: 1.2876811027526855
Validation loss: 1.8547269080274849

Epoch: 6| Step: 6
Training loss: 0.7946774959564209
Validation loss: 1.8760281250041018

Epoch: 6| Step: 7
Training loss: 0.867804765701294
Validation loss: 1.8858443998521375

Epoch: 6| Step: 8
Training loss: 0.6581027507781982
Validation loss: 1.9210987347428516

Epoch: 6| Step: 9
Training loss: 1.1531096696853638
Validation loss: 1.9167872833949264

Epoch: 6| Step: 10
Training loss: 0.7973771691322327
Validation loss: 1.9018877142219133

Epoch: 6| Step: 11
Training loss: 0.6382797360420227
Validation loss: 1.936747145909135

Epoch: 6| Step: 12
Training loss: 1.1105124950408936
Validation loss: 1.9146451065617223

Epoch: 6| Step: 13
Training loss: 1.2434744834899902
Validation loss: 1.8875108867563226

Epoch: 424| Step: 0
Training loss: 1.372520923614502
Validation loss: 1.9233540488827614

Epoch: 6| Step: 1
Training loss: 0.7179442644119263
Validation loss: 1.9080846514753116

Epoch: 6| Step: 2
Training loss: 0.8880517482757568
Validation loss: 1.903444282470211

Epoch: 6| Step: 3
Training loss: 0.6110616326332092
Validation loss: 1.9278513616131199

Epoch: 6| Step: 4
Training loss: 0.8595613241195679
Validation loss: 1.9143650198495517

Epoch: 6| Step: 5
Training loss: 1.0599913597106934
Validation loss: 1.8910490646157214

Epoch: 6| Step: 6
Training loss: 0.9730574488639832
Validation loss: 1.8811919407177997

Epoch: 6| Step: 7
Training loss: 1.611799716949463
Validation loss: 1.9140806685211837

Epoch: 6| Step: 8
Training loss: 0.422702819108963
Validation loss: 1.901847352263748

Epoch: 6| Step: 9
Training loss: 0.5014700889587402
Validation loss: 1.9120615733567106

Epoch: 6| Step: 10
Training loss: 0.7271997928619385
Validation loss: 1.9161684538728447

Epoch: 6| Step: 11
Training loss: 0.9680328369140625
Validation loss: 1.8844260015795309

Epoch: 6| Step: 12
Training loss: 0.9206789135932922
Validation loss: 1.8906464576721191

Epoch: 6| Step: 13
Training loss: 1.3229424953460693
Validation loss: 1.9022191634742163

Epoch: 425| Step: 0
Training loss: 0.5410482287406921
Validation loss: 1.873082644195967

Epoch: 6| Step: 1
Training loss: 1.0117037296295166
Validation loss: 1.8750872381271855

Epoch: 6| Step: 2
Training loss: 1.3344457149505615
Validation loss: 1.8750677595856369

Epoch: 6| Step: 3
Training loss: 0.936003565788269
Validation loss: 1.8845756848653157

Epoch: 6| Step: 4
Training loss: 0.4824634790420532
Validation loss: 1.9110740384747904

Epoch: 6| Step: 5
Training loss: 0.9279323816299438
Validation loss: 1.9671275436237294

Epoch: 6| Step: 6
Training loss: 0.47882217168807983
Validation loss: 1.9341143267129057

Epoch: 6| Step: 7
Training loss: 1.0997068881988525
Validation loss: 1.9519612366153347

Epoch: 6| Step: 8
Training loss: 1.0402218103408813
Validation loss: 1.9537171240775817

Epoch: 6| Step: 9
Training loss: 0.9596153497695923
Validation loss: 1.9394391941767868

Epoch: 6| Step: 10
Training loss: 0.621936023235321
Validation loss: 1.914980342311244

Epoch: 6| Step: 11
Training loss: 0.7494730949401855
Validation loss: 1.8728326161702473

Epoch: 6| Step: 12
Training loss: 1.1183334589004517
Validation loss: 1.8556448336570495

Epoch: 6| Step: 13
Training loss: 1.1515501737594604
Validation loss: 1.867620882167611

Epoch: 426| Step: 0
Training loss: 0.2706502079963684
Validation loss: 1.8745276645947528

Epoch: 6| Step: 1
Training loss: 0.7933449149131775
Validation loss: 1.8939774984954505

Epoch: 6| Step: 2
Training loss: 0.9606561064720154
Validation loss: 1.9106374402200021

Epoch: 6| Step: 3
Training loss: 1.287248134613037
Validation loss: 1.8797487661402712

Epoch: 6| Step: 4
Training loss: 0.8647325038909912
Validation loss: 1.901576457485076

Epoch: 6| Step: 5
Training loss: 1.1481224298477173
Validation loss: 1.8884615987859747

Epoch: 6| Step: 6
Training loss: 0.8894809484481812
Validation loss: 1.9284663431106075

Epoch: 6| Step: 7
Training loss: 0.7305279970169067
Validation loss: 1.9304875122603549

Epoch: 6| Step: 8
Training loss: 1.5986268520355225
Validation loss: 1.9795860744291736

Epoch: 6| Step: 9
Training loss: 0.8712528944015503
Validation loss: 2.00529218745488

Epoch: 6| Step: 10
Training loss: 0.5636937618255615
Validation loss: 1.9986155122838996

Epoch: 6| Step: 11
Training loss: 0.9000967741012573
Validation loss: 1.9961810932364514

Epoch: 6| Step: 12
Training loss: 0.7891221642494202
Validation loss: 1.9998791179349344

Epoch: 6| Step: 13
Training loss: 1.3228611946105957
Validation loss: 1.9048929855387697

Epoch: 427| Step: 0
Training loss: 1.1055597066879272
Validation loss: 1.8709522703642487

Epoch: 6| Step: 1
Training loss: 0.8326040506362915
Validation loss: 1.8492352283129128

Epoch: 6| Step: 2
Training loss: 0.89897620677948
Validation loss: 1.8661903822293846

Epoch: 6| Step: 3
Training loss: 0.915069580078125
Validation loss: 1.8806540120032527

Epoch: 6| Step: 4
Training loss: 0.7827243208885193
Validation loss: 1.8681411743164062

Epoch: 6| Step: 5
Training loss: 0.883926510810852
Validation loss: 1.9027825273493284

Epoch: 6| Step: 6
Training loss: 0.9368941783905029
Validation loss: 1.914705802035588

Epoch: 6| Step: 7
Training loss: 0.5471275448799133
Validation loss: 1.9681444462909494

Epoch: 6| Step: 8
Training loss: 1.02335786819458
Validation loss: 1.988442769614599

Epoch: 6| Step: 9
Training loss: 0.4664995074272156
Validation loss: 2.0089475749641337

Epoch: 6| Step: 10
Training loss: 1.1338529586791992
Validation loss: 2.038640614478819

Epoch: 6| Step: 11
Training loss: 1.2281547784805298
Validation loss: 2.0217715988877

Epoch: 6| Step: 12
Training loss: 0.940104603767395
Validation loss: 1.9870480234904955

Epoch: 6| Step: 13
Training loss: 1.0282641649246216
Validation loss: 1.9839012020377702

Epoch: 428| Step: 0
Training loss: 0.7823240756988525
Validation loss: 1.9235018196926321

Epoch: 6| Step: 1
Training loss: 0.8973152041435242
Validation loss: 1.898069179186257

Epoch: 6| Step: 2
Training loss: 0.7527061700820923
Validation loss: 1.8800684457184167

Epoch: 6| Step: 3
Training loss: 0.47486260533332825
Validation loss: 1.8653027306320846

Epoch: 6| Step: 4
Training loss: 1.6836808919906616
Validation loss: 1.8723057367468392

Epoch: 6| Step: 5
Training loss: 0.6541454792022705
Validation loss: 1.8235188017609298

Epoch: 6| Step: 6
Training loss: 1.0851283073425293
Validation loss: 1.8418342208349576

Epoch: 6| Step: 7
Training loss: 0.7101345062255859
Validation loss: 1.8146208499067573

Epoch: 6| Step: 8
Training loss: 0.8348890542984009
Validation loss: 1.8637639335406724

Epoch: 6| Step: 9
Training loss: 0.9134567975997925
Validation loss: 1.841807254540023

Epoch: 6| Step: 10
Training loss: 1.1670427322387695
Validation loss: 1.854786124280704

Epoch: 6| Step: 11
Training loss: 0.48426926136016846
Validation loss: 1.9090378899728098

Epoch: 6| Step: 12
Training loss: 1.510330319404602
Validation loss: 1.9340946623074111

Epoch: 6| Step: 13
Training loss: 0.6273064017295837
Validation loss: 1.917489928583945

Epoch: 429| Step: 0
Training loss: 1.0391322374343872
Validation loss: 1.9083523352940877

Epoch: 6| Step: 1
Training loss: 1.4516472816467285
Validation loss: 1.8632462152870752

Epoch: 6| Step: 2
Training loss: 0.9332162141799927
Validation loss: 1.8343146488230715

Epoch: 6| Step: 3
Training loss: 0.6601462364196777
Validation loss: 1.8074686757979854

Epoch: 6| Step: 4
Training loss: 1.0584557056427002
Validation loss: 1.8142754993131083

Epoch: 6| Step: 5
Training loss: 1.0959981679916382
Validation loss: 1.8097502826362528

Epoch: 6| Step: 6
Training loss: 0.769125759601593
Validation loss: 1.8285218182430472

Epoch: 6| Step: 7
Training loss: 1.279710292816162
Validation loss: 1.827301900873902

Epoch: 6| Step: 8
Training loss: 0.6276378035545349
Validation loss: 1.835701124642485

Epoch: 6| Step: 9
Training loss: 0.8306499719619751
Validation loss: 1.8364783474194106

Epoch: 6| Step: 10
Training loss: 0.39030593633651733
Validation loss: 1.8322574118132233

Epoch: 6| Step: 11
Training loss: 0.817074179649353
Validation loss: 1.8686931812635033

Epoch: 6| Step: 12
Training loss: 0.723674476146698
Validation loss: 1.9081413694607314

Epoch: 6| Step: 13
Training loss: 0.27962809801101685
Validation loss: 1.9192277974979852

Epoch: 430| Step: 0
Training loss: 1.08893620967865
Validation loss: 1.9599897707662275

Epoch: 6| Step: 1
Training loss: 0.7933388352394104
Validation loss: 1.966589666181995

Epoch: 6| Step: 2
Training loss: 1.0305505990982056
Validation loss: 1.977363237770655

Epoch: 6| Step: 3
Training loss: 0.7610363364219666
Validation loss: 1.9431421064561414

Epoch: 6| Step: 4
Training loss: 1.0470960140228271
Validation loss: 1.9520508012463968

Epoch: 6| Step: 5
Training loss: 1.096763014793396
Validation loss: 1.9376870919299383

Epoch: 6| Step: 6
Training loss: 0.8900349736213684
Validation loss: 1.91834669984797

Epoch: 6| Step: 7
Training loss: 0.7111023664474487
Validation loss: 1.9375240623310048

Epoch: 6| Step: 8
Training loss: 0.9091817736625671
Validation loss: 1.8968359693404166

Epoch: 6| Step: 9
Training loss: 0.7960941791534424
Validation loss: 1.897058110083303

Epoch: 6| Step: 10
Training loss: 0.44998329877853394
Validation loss: 1.8552489895974436

Epoch: 6| Step: 11
Training loss: 0.8303350210189819
Validation loss: 1.8551360868638562

Epoch: 6| Step: 12
Training loss: 0.7252503633499146
Validation loss: 1.8625622385291642

Epoch: 6| Step: 13
Training loss: 0.672159731388092
Validation loss: 1.877353488758046

Epoch: 431| Step: 0
Training loss: 1.279228925704956
Validation loss: 1.8805181211040867

Epoch: 6| Step: 1
Training loss: 0.3816169500350952
Validation loss: 1.933850472973239

Epoch: 6| Step: 2
Training loss: 1.0924038887023926
Validation loss: 1.9103838577065417

Epoch: 6| Step: 3
Training loss: 0.5987595915794373
Validation loss: 1.9183741923301452

Epoch: 6| Step: 4
Training loss: 0.836647629737854
Validation loss: 1.9050123127557899

Epoch: 6| Step: 5
Training loss: 1.0038089752197266
Validation loss: 1.8809759450215164

Epoch: 6| Step: 6
Training loss: 0.8182885646820068
Validation loss: 1.8979091900651173

Epoch: 6| Step: 7
Training loss: 1.0023107528686523
Validation loss: 1.8667430262411795

Epoch: 6| Step: 8
Training loss: 0.9861284494400024
Validation loss: 1.8822358833846224

Epoch: 6| Step: 9
Training loss: 0.9720181822776794
Validation loss: 1.858793786776963

Epoch: 6| Step: 10
Training loss: 0.7705520391464233
Validation loss: 1.8651571248167305

Epoch: 6| Step: 11
Training loss: 0.7831017374992371
Validation loss: 1.868747176662568

Epoch: 6| Step: 12
Training loss: 1.004338026046753
Validation loss: 1.8706667884703605

Epoch: 6| Step: 13
Training loss: 0.39809083938598633
Validation loss: 1.8795850276947021

Epoch: 432| Step: 0
Training loss: 1.2536299228668213
Validation loss: 1.85836963499746

Epoch: 6| Step: 1
Training loss: 1.270484447479248
Validation loss: 1.894112633120629

Epoch: 6| Step: 2
Training loss: 0.6298327445983887
Validation loss: 1.8998911188494774

Epoch: 6| Step: 3
Training loss: 0.9780998229980469
Validation loss: 1.9310895627544773

Epoch: 6| Step: 4
Training loss: 0.7283596992492676
Validation loss: 1.9117878739551832

Epoch: 6| Step: 5
Training loss: 0.7032262086868286
Validation loss: 1.9209350360337125

Epoch: 6| Step: 6
Training loss: 0.5140112638473511
Validation loss: 1.9085352420806885

Epoch: 6| Step: 7
Training loss: 1.000917911529541
Validation loss: 1.9163920956273233

Epoch: 6| Step: 8
Training loss: 0.6701688766479492
Validation loss: 1.8966683610793083

Epoch: 6| Step: 9
Training loss: 0.8248871564865112
Validation loss: 1.8615194905188777

Epoch: 6| Step: 10
Training loss: 0.9032429456710815
Validation loss: 1.8794311631110407

Epoch: 6| Step: 11
Training loss: 0.9628852009773254
Validation loss: 1.8915933101407942

Epoch: 6| Step: 12
Training loss: 0.6768003702163696
Validation loss: 1.8617375358458488

Epoch: 6| Step: 13
Training loss: 0.7169148921966553
Validation loss: 1.8756768088186941

Epoch: 433| Step: 0
Training loss: 1.2985856533050537
Validation loss: 1.8512175301069855

Epoch: 6| Step: 1
Training loss: 1.1052355766296387
Validation loss: 1.8942492559391966

Epoch: 6| Step: 2
Training loss: 0.5518050789833069
Validation loss: 1.8946771967795588

Epoch: 6| Step: 3
Training loss: 0.8916465640068054
Validation loss: 1.904251867725003

Epoch: 6| Step: 4
Training loss: 1.088653564453125
Validation loss: 1.925678142937281

Epoch: 6| Step: 5
Training loss: 0.7736853361129761
Validation loss: 1.9248510842682214

Epoch: 6| Step: 6
Training loss: 0.9687519073486328
Validation loss: 1.9102876686280774

Epoch: 6| Step: 7
Training loss: 1.2258845567703247
Validation loss: 1.9297531215093469

Epoch: 6| Step: 8
Training loss: 0.7262383103370667
Validation loss: 1.8678401170238372

Epoch: 6| Step: 9
Training loss: 0.5045115947723389
Validation loss: 1.8562531804525724

Epoch: 6| Step: 10
Training loss: 0.6505310535430908
Validation loss: 1.8697417448925715

Epoch: 6| Step: 11
Training loss: 0.5274195075035095
Validation loss: 1.8553663197384085

Epoch: 6| Step: 12
Training loss: 0.7001773118972778
Validation loss: 1.8866454862779187

Epoch: 6| Step: 13
Training loss: 0.7580049633979797
Validation loss: 1.8622989603268203

Epoch: 434| Step: 0
Training loss: 1.100319266319275
Validation loss: 1.8581408890344764

Epoch: 6| Step: 1
Training loss: 1.0311176776885986
Validation loss: 1.862634979268556

Epoch: 6| Step: 2
Training loss: 0.8372892141342163
Validation loss: 1.860906090787662

Epoch: 6| Step: 3
Training loss: 0.6442980766296387
Validation loss: 1.825563802514025

Epoch: 6| Step: 4
Training loss: 1.0938851833343506
Validation loss: 1.8352270382706837

Epoch: 6| Step: 5
Training loss: 0.6022616624832153
Validation loss: 1.83239742120107

Epoch: 6| Step: 6
Training loss: 0.5807328224182129
Validation loss: 1.848765080974948

Epoch: 6| Step: 7
Training loss: 0.7259682416915894
Validation loss: 1.8495493063362696

Epoch: 6| Step: 8
Training loss: 0.9673605561256409
Validation loss: 1.8508381587202831

Epoch: 6| Step: 9
Training loss: 0.4569471478462219
Validation loss: 1.844714536461779

Epoch: 6| Step: 10
Training loss: 1.3086957931518555
Validation loss: 1.8485823318522463

Epoch: 6| Step: 11
Training loss: 0.9580003619194031
Validation loss: 1.8744728603670675

Epoch: 6| Step: 12
Training loss: 0.7196853160858154
Validation loss: 1.8788893812446184

Epoch: 6| Step: 13
Training loss: 0.9273560643196106
Validation loss: 1.91264767800608

Epoch: 435| Step: 0
Training loss: 1.2968261241912842
Validation loss: 1.9024981234663276

Epoch: 6| Step: 1
Training loss: 1.1706416606903076
Validation loss: 1.9154276130019978

Epoch: 6| Step: 2
Training loss: 0.9108123779296875
Validation loss: 1.9188974377929524

Epoch: 6| Step: 3
Training loss: 0.6477206945419312
Validation loss: 1.913062249460528

Epoch: 6| Step: 4
Training loss: 0.9820385575294495
Validation loss: 1.9153110391350203

Epoch: 6| Step: 5
Training loss: 0.5974187254905701
Validation loss: 1.9036453065051828

Epoch: 6| Step: 6
Training loss: 0.37866008281707764
Validation loss: 1.9224153590458695

Epoch: 6| Step: 7
Training loss: 0.478242427110672
Validation loss: 1.8920152443711475

Epoch: 6| Step: 8
Training loss: 0.5089004635810852
Validation loss: 1.8874989658273675

Epoch: 6| Step: 9
Training loss: 0.7736258506774902
Validation loss: 1.8791775523975331

Epoch: 6| Step: 10
Training loss: 0.8895653486251831
Validation loss: 1.8797463281180269

Epoch: 6| Step: 11
Training loss: 1.0726425647735596
Validation loss: 1.904520752609417

Epoch: 6| Step: 12
Training loss: 0.999445378780365
Validation loss: 1.8543976301788

Epoch: 6| Step: 13
Training loss: 0.7461785078048706
Validation loss: 1.9131313908484675

Epoch: 436| Step: 0
Training loss: 0.7401469945907593
Validation loss: 1.8983205133868801

Epoch: 6| Step: 1
Training loss: 0.928184449672699
Validation loss: 1.9093863015533776

Epoch: 6| Step: 2
Training loss: 0.9812238812446594
Validation loss: 1.8858996257987073

Epoch: 6| Step: 3
Training loss: 0.5882733464241028
Validation loss: 1.8661533863313737

Epoch: 6| Step: 4
Training loss: 1.0432490110397339
Validation loss: 1.870548197018203

Epoch: 6| Step: 5
Training loss: 1.2433381080627441
Validation loss: 1.8612435825409428

Epoch: 6| Step: 6
Training loss: 0.5530135631561279
Validation loss: 1.8659358870598577

Epoch: 6| Step: 7
Training loss: 0.9112758636474609
Validation loss: 1.8394703954778693

Epoch: 6| Step: 8
Training loss: 0.8441861867904663
Validation loss: 1.838005967037652

Epoch: 6| Step: 9
Training loss: 0.8621209263801575
Validation loss: 1.8101433707821755

Epoch: 6| Step: 10
Training loss: 0.8143998384475708
Validation loss: 1.8252252737681072

Epoch: 6| Step: 11
Training loss: 0.6570490598678589
Validation loss: 1.855421450830275

Epoch: 6| Step: 12
Training loss: 0.9435752630233765
Validation loss: 1.8717957491515784

Epoch: 6| Step: 13
Training loss: 0.44441163539886475
Validation loss: 1.901228250995759

Epoch: 437| Step: 0
Training loss: 1.0825953483581543
Validation loss: 1.890025564419326

Epoch: 6| Step: 1
Training loss: 0.7435522079467773
Validation loss: 1.9122719123799314

Epoch: 6| Step: 2
Training loss: 0.709346354007721
Validation loss: 1.9188812291750343

Epoch: 6| Step: 3
Training loss: 0.6979151964187622
Validation loss: 1.9537906377546248

Epoch: 6| Step: 4
Training loss: 1.0217645168304443
Validation loss: 1.9539313829073341

Epoch: 6| Step: 5
Training loss: 0.6518864631652832
Validation loss: 1.936341154959894

Epoch: 6| Step: 6
Training loss: 0.9548782706260681
Validation loss: 1.9144288583468365

Epoch: 6| Step: 7
Training loss: 0.6091649532318115
Validation loss: 1.8723784300588793

Epoch: 6| Step: 8
Training loss: 0.45066577196121216
Validation loss: 1.8934849487837924

Epoch: 6| Step: 9
Training loss: 0.8956378102302551
Validation loss: 1.8767183467906008

Epoch: 6| Step: 10
Training loss: 0.9764372110366821
Validation loss: 1.8356300553967875

Epoch: 6| Step: 11
Training loss: 1.0540670156478882
Validation loss: 1.8340194763675812

Epoch: 6| Step: 12
Training loss: 0.661687970161438
Validation loss: 1.823181862472206

Epoch: 6| Step: 13
Training loss: 1.178117275238037
Validation loss: 1.7775602789335354

Epoch: 438| Step: 0
Training loss: 1.1052312850952148
Validation loss: 1.8037933598282516

Epoch: 6| Step: 1
Training loss: 0.7941856384277344
Validation loss: 1.8066198325926257

Epoch: 6| Step: 2
Training loss: 0.6252991557121277
Validation loss: 1.8072351255724508

Epoch: 6| Step: 3
Training loss: 0.33508825302124023
Validation loss: 1.8121158256325671

Epoch: 6| Step: 4
Training loss: 1.2378184795379639
Validation loss: 1.8356020194227978

Epoch: 6| Step: 5
Training loss: 0.7044445276260376
Validation loss: 1.858642170506139

Epoch: 6| Step: 6
Training loss: 0.9039045572280884
Validation loss: 1.8998339970906575

Epoch: 6| Step: 7
Training loss: 0.6061515808105469
Validation loss: 1.9059856219958233

Epoch: 6| Step: 8
Training loss: 0.800666093826294
Validation loss: 1.9342307634251092

Epoch: 6| Step: 9
Training loss: 1.15974760055542
Validation loss: 1.9341284767273934

Epoch: 6| Step: 10
Training loss: 0.9450162053108215
Validation loss: 1.9545035221243416

Epoch: 6| Step: 11
Training loss: 1.070734977722168
Validation loss: 1.9547879285709833

Epoch: 6| Step: 12
Training loss: 0.5411917567253113
Validation loss: 1.9527112002013831

Epoch: 6| Step: 13
Training loss: 0.44522979855537415
Validation loss: 1.9234618986806562

Epoch: 439| Step: 0
Training loss: 1.0117213726043701
Validation loss: 1.8911749470618464

Epoch: 6| Step: 1
Training loss: 0.8147414326667786
Validation loss: 1.8830302658901419

Epoch: 6| Step: 2
Training loss: 1.393183708190918
Validation loss: 1.885899325852753

Epoch: 6| Step: 3
Training loss: 0.6452748775482178
Validation loss: 1.864840562625598

Epoch: 6| Step: 4
Training loss: 1.2077314853668213
Validation loss: 1.8587455711057108

Epoch: 6| Step: 5
Training loss: 1.1378368139266968
Validation loss: 1.8472213501571326

Epoch: 6| Step: 6
Training loss: 0.8780484199523926
Validation loss: 1.8593038089813725

Epoch: 6| Step: 7
Training loss: 0.7197448015213013
Validation loss: 1.8711787808325984

Epoch: 6| Step: 8
Training loss: 0.6123194098472595
Validation loss: 1.88080656913019

Epoch: 6| Step: 9
Training loss: 0.346265971660614
Validation loss: 1.8671896931945637

Epoch: 6| Step: 10
Training loss: 0.5612038373947144
Validation loss: 1.89249788817539

Epoch: 6| Step: 11
Training loss: 0.2065407782793045
Validation loss: 1.898904218468615

Epoch: 6| Step: 12
Training loss: 0.9092327356338501
Validation loss: 1.905107823751306

Epoch: 6| Step: 13
Training loss: 0.7516916990280151
Validation loss: 1.9191884943234023

Epoch: 440| Step: 0
Training loss: 0.5669000148773193
Validation loss: 1.9181806477167274

Epoch: 6| Step: 1
Training loss: 0.975470244884491
Validation loss: 1.9222988441426268

Epoch: 6| Step: 2
Training loss: 0.8003084659576416
Validation loss: 1.9149127109076387

Epoch: 6| Step: 3
Training loss: 0.8167239427566528
Validation loss: 1.9090161451729395

Epoch: 6| Step: 4
Training loss: 0.918262243270874
Validation loss: 1.9065432625432168

Epoch: 6| Step: 5
Training loss: 0.42085030674934387
Validation loss: 1.9216261281762073

Epoch: 6| Step: 6
Training loss: 1.1968413591384888
Validation loss: 1.8750155125894854

Epoch: 6| Step: 7
Training loss: 1.0663998126983643
Validation loss: 1.9029306378415836

Epoch: 6| Step: 8
Training loss: 0.6144862174987793
Validation loss: 1.9036148158452844

Epoch: 6| Step: 9
Training loss: 1.0090566873550415
Validation loss: 1.898481289545695

Epoch: 6| Step: 10
Training loss: 0.6707996726036072
Validation loss: 1.874974581503099

Epoch: 6| Step: 11
Training loss: 1.1405178308486938
Validation loss: 1.8717920626363447

Epoch: 6| Step: 12
Training loss: 0.3507046103477478
Validation loss: 1.820082958026599

Epoch: 6| Step: 13
Training loss: 0.845896303653717
Validation loss: 1.8448056405590427

Epoch: 441| Step: 0
Training loss: 0.7638602256774902
Validation loss: 1.8229936925313805

Epoch: 6| Step: 1
Training loss: 0.7613734006881714
Validation loss: 1.824115651910023

Epoch: 6| Step: 2
Training loss: 0.789104700088501
Validation loss: 1.829453678541286

Epoch: 6| Step: 3
Training loss: 0.976362407207489
Validation loss: 1.8263104500309113

Epoch: 6| Step: 4
Training loss: 0.7549804449081421
Validation loss: 1.8456600430191203

Epoch: 6| Step: 5
Training loss: 0.8230655193328857
Validation loss: 1.8464501045083488

Epoch: 6| Step: 6
Training loss: 0.38007012009620667
Validation loss: 1.882113374689574

Epoch: 6| Step: 7
Training loss: 0.8348605036735535
Validation loss: 1.8884923599099601

Epoch: 6| Step: 8
Training loss: 0.9463634490966797
Validation loss: 1.912394759475544

Epoch: 6| Step: 9
Training loss: 0.6520648002624512
Validation loss: 1.921674979630337

Epoch: 6| Step: 10
Training loss: 0.5591421723365784
Validation loss: 1.9256424096322828

Epoch: 6| Step: 11
Training loss: 1.163447380065918
Validation loss: 1.9175557859482304

Epoch: 6| Step: 12
Training loss: 1.1115150451660156
Validation loss: 1.9083760989609586

Epoch: 6| Step: 13
Training loss: 0.7524542212486267
Validation loss: 1.9042354629885765

Epoch: 442| Step: 0
Training loss: 0.8318359851837158
Validation loss: 1.8890431414368332

Epoch: 6| Step: 1
Training loss: 0.6295157670974731
Validation loss: 1.875426169364683

Epoch: 6| Step: 2
Training loss: 0.9051692485809326
Validation loss: 1.8559834893031786

Epoch: 6| Step: 3
Training loss: 0.7202073335647583
Validation loss: 1.8447660182112007

Epoch: 6| Step: 4
Training loss: 0.8029563426971436
Validation loss: 1.804860193242309

Epoch: 6| Step: 5
Training loss: 0.805575430393219
Validation loss: 1.8152395756013933

Epoch: 6| Step: 6
Training loss: 0.8382818102836609
Validation loss: 1.7822259805535758

Epoch: 6| Step: 7
Training loss: 0.8347722887992859
Validation loss: 1.8476335079439226

Epoch: 6| Step: 8
Training loss: 1.226504921913147
Validation loss: 1.8186614333942372

Epoch: 6| Step: 9
Training loss: 0.6476731896400452
Validation loss: 1.8025511131491712

Epoch: 6| Step: 10
Training loss: 0.5898741483688354
Validation loss: 1.8060753153216453

Epoch: 6| Step: 11
Training loss: 0.5857006311416626
Validation loss: 1.8530153330936228

Epoch: 6| Step: 12
Training loss: 1.0141111612319946
Validation loss: 1.870782571454202

Epoch: 6| Step: 13
Training loss: 1.1441750526428223
Validation loss: 1.9171793704391809

Epoch: 443| Step: 0
Training loss: 0.6533982753753662
Validation loss: 1.928003582903134

Epoch: 6| Step: 1
Training loss: 0.7829844355583191
Validation loss: 1.9496577529497043

Epoch: 6| Step: 2
Training loss: 0.8504953384399414
Validation loss: 1.9253546986528622

Epoch: 6| Step: 3
Training loss: 1.127573013305664
Validation loss: 1.9410303228644914

Epoch: 6| Step: 4
Training loss: 0.47535941004753113
Validation loss: 1.9620977063332834

Epoch: 6| Step: 5
Training loss: 0.8096373081207275
Validation loss: 1.940737578176683

Epoch: 6| Step: 6
Training loss: 1.025986909866333
Validation loss: 1.9281281886562225

Epoch: 6| Step: 7
Training loss: 0.7223228216171265
Validation loss: 1.9339820531106764

Epoch: 6| Step: 8
Training loss: 0.6832973957061768
Validation loss: 1.864392521560833

Epoch: 6| Step: 9
Training loss: 0.5038844347000122
Validation loss: 1.84921553058009

Epoch: 6| Step: 10
Training loss: 0.6746860146522522
Validation loss: 1.8322603433362898

Epoch: 6| Step: 11
Training loss: 1.2183396816253662
Validation loss: 1.8354574813637683

Epoch: 6| Step: 12
Training loss: 0.8888621926307678
Validation loss: 1.8128166173094062

Epoch: 6| Step: 13
Training loss: 0.8905671238899231
Validation loss: 1.8102818548038442

Epoch: 444| Step: 0
Training loss: 1.1784725189208984
Validation loss: 1.797106533922175

Epoch: 6| Step: 1
Training loss: 0.9300867915153503
Validation loss: 1.8194452767731042

Epoch: 6| Step: 2
Training loss: 0.733147144317627
Validation loss: 1.823530795753643

Epoch: 6| Step: 3
Training loss: 0.7604312896728516
Validation loss: 1.8252471429045483

Epoch: 6| Step: 4
Training loss: 0.482311487197876
Validation loss: 1.8151344560807752

Epoch: 6| Step: 5
Training loss: 0.4961707592010498
Validation loss: 1.7951242013644146

Epoch: 6| Step: 6
Training loss: 1.0720134973526
Validation loss: 1.8053569165609216

Epoch: 6| Step: 7
Training loss: 0.5628663897514343
Validation loss: 1.826798016025174

Epoch: 6| Step: 8
Training loss: 0.8959635496139526
Validation loss: 1.8399382329756213

Epoch: 6| Step: 9
Training loss: 0.6539875864982605
Validation loss: 1.9051941299951205

Epoch: 6| Step: 10
Training loss: 1.281470537185669
Validation loss: 1.8924531411099177

Epoch: 6| Step: 11
Training loss: 0.5107986927032471
Validation loss: 1.9224750918726767

Epoch: 6| Step: 12
Training loss: 0.6227171421051025
Validation loss: 1.891812780851959

Epoch: 6| Step: 13
Training loss: 1.354572057723999
Validation loss: 1.9080680275476107

Epoch: 445| Step: 0
Training loss: 1.1273547410964966
Validation loss: 1.8572087172539002

Epoch: 6| Step: 1
Training loss: 0.6810189485549927
Validation loss: 1.8665673117483816

Epoch: 6| Step: 2
Training loss: 0.7811236381530762
Validation loss: 1.8120133620436474

Epoch: 6| Step: 3
Training loss: 0.9752187132835388
Validation loss: 1.8220348755518596

Epoch: 6| Step: 4
Training loss: 0.4470561146736145
Validation loss: 1.8075289982621388

Epoch: 6| Step: 5
Training loss: 0.9636754989624023
Validation loss: 1.7981570061816965

Epoch: 6| Step: 6
Training loss: 1.012431025505066
Validation loss: 1.7664915592439714

Epoch: 6| Step: 7
Training loss: 0.5463106632232666
Validation loss: 1.8312007675888717

Epoch: 6| Step: 8
Training loss: 0.29515737295150757
Validation loss: 1.7884282078794254

Epoch: 6| Step: 9
Training loss: 1.171164870262146
Validation loss: 1.8262326230284989

Epoch: 6| Step: 10
Training loss: 0.9137731790542603
Validation loss: 1.8548521072633806

Epoch: 6| Step: 11
Training loss: 0.7678276300430298
Validation loss: 1.8051178096443095

Epoch: 6| Step: 12
Training loss: 0.8187375068664551
Validation loss: 1.82443122325405

Epoch: 6| Step: 13
Training loss: 1.0056308507919312
Validation loss: 1.8509105161953998

Epoch: 446| Step: 0
Training loss: 0.6277211904525757
Validation loss: 1.8923312502522622

Epoch: 6| Step: 1
Training loss: 0.4937666654586792
Validation loss: 1.9180671297093874

Epoch: 6| Step: 2
Training loss: 0.9831063747406006
Validation loss: 1.8690201300446705

Epoch: 6| Step: 3
Training loss: 0.9306304454803467
Validation loss: 1.8958074713266024

Epoch: 6| Step: 4
Training loss: 0.6168162226676941
Validation loss: 1.887189479284389

Epoch: 6| Step: 5
Training loss: 1.023020625114441
Validation loss: 1.9069049871096047

Epoch: 6| Step: 6
Training loss: 1.0884274244308472
Validation loss: 1.8763129070240965

Epoch: 6| Step: 7
Training loss: 0.8000536561012268
Validation loss: 1.869214565523209

Epoch: 6| Step: 8
Training loss: 0.8822669982910156
Validation loss: 1.8642673107885546

Epoch: 6| Step: 9
Training loss: 0.9122970104217529
Validation loss: 1.874090007556382

Epoch: 6| Step: 10
Training loss: 0.7248305082321167
Validation loss: 1.8830508955063359

Epoch: 6| Step: 11
Training loss: 0.7113243341445923
Validation loss: 1.9536430579359814

Epoch: 6| Step: 12
Training loss: 0.8464979529380798
Validation loss: 1.9208473236330095

Epoch: 6| Step: 13
Training loss: 0.19259412586688995
Validation loss: 1.8724867605393933

Epoch: 447| Step: 0
Training loss: 0.8048438429832458
Validation loss: 1.8652741037389284

Epoch: 6| Step: 1
Training loss: 0.8576939105987549
Validation loss: 1.8355571992935673

Epoch: 6| Step: 2
Training loss: 1.2164192199707031
Validation loss: 1.82157600438723

Epoch: 6| Step: 3
Training loss: 0.7164719700813293
Validation loss: 1.8336079953819193

Epoch: 6| Step: 4
Training loss: 0.6176873445510864
Validation loss: 1.8097143737218713

Epoch: 6| Step: 5
Training loss: 0.8874143362045288
Validation loss: 1.8191013720727736

Epoch: 6| Step: 6
Training loss: 0.7630658149719238
Validation loss: 1.8518451439437045

Epoch: 6| Step: 7
Training loss: 0.5535221695899963
Validation loss: 1.8126694066550142

Epoch: 6| Step: 8
Training loss: 0.7952392101287842
Validation loss: 1.8430675332264235

Epoch: 6| Step: 9
Training loss: 0.8094460964202881
Validation loss: 1.861843023248898

Epoch: 6| Step: 10
Training loss: 0.7751787900924683
Validation loss: 1.8980652939888738

Epoch: 6| Step: 11
Training loss: 1.0401297807693481
Validation loss: 1.890496064257878

Epoch: 6| Step: 12
Training loss: 0.6354840993881226
Validation loss: 1.891910481196578

Epoch: 6| Step: 13
Training loss: 0.6271072030067444
Validation loss: 1.8579553660526071

Epoch: 448| Step: 0
Training loss: 0.5663778781890869
Validation loss: 1.8754969822463168

Epoch: 6| Step: 1
Training loss: 1.1294739246368408
Validation loss: 1.844440060277139

Epoch: 6| Step: 2
Training loss: 0.48692944645881653
Validation loss: 1.8315764742512857

Epoch: 6| Step: 3
Training loss: 0.9128700494766235
Validation loss: 1.814756478032758

Epoch: 6| Step: 4
Training loss: 0.4553513824939728
Validation loss: 1.8201671979760612

Epoch: 6| Step: 5
Training loss: 0.6489133238792419
Validation loss: 1.817435847815647

Epoch: 6| Step: 6
Training loss: 1.1235328912734985
Validation loss: 1.835287033870656

Epoch: 6| Step: 7
Training loss: 0.40764087438583374
Validation loss: 1.8269131222078878

Epoch: 6| Step: 8
Training loss: 0.9191556572914124
Validation loss: 1.8630718928511425

Epoch: 6| Step: 9
Training loss: 0.7896324396133423
Validation loss: 1.8904284187542495

Epoch: 6| Step: 10
Training loss: 0.884329080581665
Validation loss: 1.8675335350856985

Epoch: 6| Step: 11
Training loss: 1.0172587633132935
Validation loss: 1.8551291163249681

Epoch: 6| Step: 12
Training loss: 0.7216448783874512
Validation loss: 1.8657475543278519

Epoch: 6| Step: 13
Training loss: 0.7943302989006042
Validation loss: 1.8796335266482445

Epoch: 449| Step: 0
Training loss: 0.8367485404014587
Validation loss: 1.8796481816999373

Epoch: 6| Step: 1
Training loss: 0.8223358392715454
Validation loss: 1.887208754016507

Epoch: 6| Step: 2
Training loss: 0.7414308786392212
Validation loss: 1.8576416610389628

Epoch: 6| Step: 3
Training loss: 0.5624292492866516
Validation loss: 1.8223271575025333

Epoch: 6| Step: 4
Training loss: 0.69582200050354
Validation loss: 1.8406700664950955

Epoch: 6| Step: 5
Training loss: 1.1714065074920654
Validation loss: 1.8410865081253873

Epoch: 6| Step: 6
Training loss: 0.47525954246520996
Validation loss: 1.8370006558715657

Epoch: 6| Step: 7
Training loss: 1.076798915863037
Validation loss: 1.8348899477271623

Epoch: 6| Step: 8
Training loss: 0.6198001503944397
Validation loss: 1.8348546348592287

Epoch: 6| Step: 9
Training loss: 0.7131388187408447
Validation loss: 1.845262009610412

Epoch: 6| Step: 10
Training loss: 0.7499285936355591
Validation loss: 1.8400650203868907

Epoch: 6| Step: 11
Training loss: 1.0688245296478271
Validation loss: 1.8151822115785332

Epoch: 6| Step: 12
Training loss: 0.5137770771980286
Validation loss: 1.84942300217126

Epoch: 6| Step: 13
Training loss: 0.5753329396247864
Validation loss: 1.8399101124014905

Epoch: 450| Step: 0
Training loss: 0.9625398516654968
Validation loss: 1.8467499466352566

Epoch: 6| Step: 1
Training loss: 1.0136603116989136
Validation loss: 1.8431046996065366

Epoch: 6| Step: 2
Training loss: 0.9147381782531738
Validation loss: 1.8483758934082524

Epoch: 6| Step: 3
Training loss: 0.29428043961524963
Validation loss: 1.8351122281884635

Epoch: 6| Step: 4
Training loss: 0.5969528555870056
Validation loss: 1.866709041339095

Epoch: 6| Step: 5
Training loss: 0.8673323392868042
Validation loss: 1.8622635705496675

Epoch: 6| Step: 6
Training loss: 0.7102270126342773
Validation loss: 1.8381318507655975

Epoch: 6| Step: 7
Training loss: 0.8976598978042603
Validation loss: 1.825253495606043

Epoch: 6| Step: 8
Training loss: 0.7069911956787109
Validation loss: 1.8474347911855227

Epoch: 6| Step: 9
Training loss: 0.7899786233901978
Validation loss: 1.871752054460587

Epoch: 6| Step: 10
Training loss: 1.1421260833740234
Validation loss: 1.8790798520529142

Epoch: 6| Step: 11
Training loss: 0.6037085056304932
Validation loss: 1.8388743528755762

Epoch: 6| Step: 12
Training loss: 0.5175498723983765
Validation loss: 1.8522878949360182

Epoch: 6| Step: 13
Training loss: 0.3457784354686737
Validation loss: 1.8393458012611634

Testing loss: 2.131975015004476
