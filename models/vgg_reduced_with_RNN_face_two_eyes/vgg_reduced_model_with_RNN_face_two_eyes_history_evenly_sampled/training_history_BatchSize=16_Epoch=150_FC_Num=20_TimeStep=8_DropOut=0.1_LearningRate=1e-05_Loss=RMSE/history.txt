Epoch: 1| Step: 0
Training loss: 6.6901493707012945
Validation loss: 5.837176428464631

Epoch: 6| Step: 1
Training loss: 5.229362615837605
Validation loss: 5.825991310277249

Epoch: 6| Step: 2
Training loss: 6.6054751025619955
Validation loss: 5.816358584228906

Epoch: 6| Step: 3
Training loss: 6.04869726357881
Validation loss: 5.806426310911392

Epoch: 6| Step: 4
Training loss: 5.187040745272321
Validation loss: 5.7977922043042645

Epoch: 6| Step: 5
Training loss: 4.884993458238827
Validation loss: 5.789150763073193

Epoch: 6| Step: 6
Training loss: 4.990711166985173
Validation loss: 5.780566259391732

Epoch: 6| Step: 7
Training loss: 5.680139494781425
Validation loss: 5.771725604687046

Epoch: 6| Step: 8
Training loss: 6.004675632835333
Validation loss: 5.762321168758667

Epoch: 6| Step: 9
Training loss: 6.69896592088508
Validation loss: 5.7520026722700335

Epoch: 6| Step: 10
Training loss: 5.530371644705666
Validation loss: 5.741431117849434

Epoch: 6| Step: 11
Training loss: 6.017447851863973
Validation loss: 5.729463313711252

Epoch: 6| Step: 12
Training loss: 5.393128629146765
Validation loss: 5.717256064543431

Epoch: 6| Step: 13
Training loss: 6.07038728135244
Validation loss: 5.70350987620099

Epoch: 2| Step: 0
Training loss: 4.141806840475374
Validation loss: 5.689122614587836

Epoch: 6| Step: 1
Training loss: 5.958679331445853
Validation loss: 5.672627046313612

Epoch: 6| Step: 2
Training loss: 6.341671457510236
Validation loss: 5.656908911424842

Epoch: 6| Step: 3
Training loss: 6.052613367014008
Validation loss: 5.6385694861528295

Epoch: 6| Step: 4
Training loss: 5.868820836753837
Validation loss: 5.619380492896409

Epoch: 6| Step: 5
Training loss: 6.093144000316565
Validation loss: 5.599356866051945

Epoch: 6| Step: 6
Training loss: 6.033851497310947
Validation loss: 5.57742749998968

Epoch: 6| Step: 7
Training loss: 4.9614722737109735
Validation loss: 5.555286637364023

Epoch: 6| Step: 8
Training loss: 4.667299205054979
Validation loss: 5.531207845128751

Epoch: 6| Step: 9
Training loss: 6.711008837568307
Validation loss: 5.507052746318917

Epoch: 6| Step: 10
Training loss: 4.433868856759346
Validation loss: 5.4811302823506

Epoch: 6| Step: 11
Training loss: 5.754588079616512
Validation loss: 5.454186876737844

Epoch: 6| Step: 12
Training loss: 5.19703881974115
Validation loss: 5.425918887192743

Epoch: 6| Step: 13
Training loss: 5.466383067582506
Validation loss: 5.397510168081402

Epoch: 3| Step: 0
Training loss: 5.221766896159026
Validation loss: 5.369477991940649

Epoch: 6| Step: 1
Training loss: 4.791801428627493
Validation loss: 5.3379902402154125

Epoch: 6| Step: 2
Training loss: 5.240335378906855
Validation loss: 5.306012850967768

Epoch: 6| Step: 3
Training loss: 6.028582838043801
Validation loss: 5.2743569695257735

Epoch: 6| Step: 4
Training loss: 6.043286897733742
Validation loss: 5.239737281779407

Epoch: 6| Step: 5
Training loss: 5.321387004598516
Validation loss: 5.203183514114099

Epoch: 6| Step: 6
Training loss: 4.172508620246956
Validation loss: 5.166325423251278

Epoch: 6| Step: 7
Training loss: 5.381979735337363
Validation loss: 5.127011742416444

Epoch: 6| Step: 8
Training loss: 5.342797980917169
Validation loss: 5.087262369901894

Epoch: 6| Step: 9
Training loss: 4.211638383447088
Validation loss: 5.04901312435989

Epoch: 6| Step: 10
Training loss: 5.543208412113157
Validation loss: 5.004759946982241

Epoch: 6| Step: 11
Training loss: 5.031749250389851
Validation loss: 4.962305172836269

Epoch: 6| Step: 12
Training loss: 4.765390659261419
Validation loss: 4.920403494201078

Epoch: 6| Step: 13
Training loss: 5.438018247965886
Validation loss: 4.87984832322865

Epoch: 4| Step: 0
Training loss: 3.7584300336781844
Validation loss: 4.842449446308555

Epoch: 6| Step: 1
Training loss: 5.15262175555421
Validation loss: 4.806255227205074

Epoch: 6| Step: 2
Training loss: 5.651968162517144
Validation loss: 4.7673747771496

Epoch: 6| Step: 3
Training loss: 4.531081834500717
Validation loss: 4.7316888102087

Epoch: 6| Step: 4
Training loss: 5.308905608481434
Validation loss: 4.691549397069247

Epoch: 6| Step: 5
Training loss: 4.212107536529901
Validation loss: 4.654223127354333

Epoch: 6| Step: 6
Training loss: 3.5140477690296787
Validation loss: 4.618322508017352

Epoch: 6| Step: 7
Training loss: 4.873588161946557
Validation loss: 4.586813243091646

Epoch: 6| Step: 8
Training loss: 4.870336404887998
Validation loss: 4.556042121652951

Epoch: 6| Step: 9
Training loss: 4.748081422128533
Validation loss: 4.524369393059771

Epoch: 6| Step: 10
Training loss: 4.7429512326465755
Validation loss: 4.491957545375865

Epoch: 6| Step: 11
Training loss: 4.944414922123662
Validation loss: 4.461770492400404

Epoch: 6| Step: 12
Training loss: 4.774013653087231
Validation loss: 4.432035658734488

Epoch: 6| Step: 13
Training loss: 3.943744974994632
Validation loss: 4.404376472168792

Epoch: 5| Step: 0
Training loss: 4.985557870210884
Validation loss: 4.384146855550252

Epoch: 6| Step: 1
Training loss: 4.7221360342101475
Validation loss: 4.35910785038931

Epoch: 6| Step: 2
Training loss: 4.50684344951297
Validation loss: 4.33776750393682

Epoch: 6| Step: 3
Training loss: 3.8541580337565198
Validation loss: 4.322589155062345

Epoch: 6| Step: 4
Training loss: 4.909744476071285
Validation loss: 4.310125190776873

Epoch: 6| Step: 5
Training loss: 4.363995253730801
Validation loss: 4.28810868570721

Epoch: 6| Step: 6
Training loss: 4.161195723642889
Validation loss: 4.286411089219328

Epoch: 6| Step: 7
Training loss: 4.998730307538105
Validation loss: 4.274068153679549

Epoch: 6| Step: 8
Training loss: 4.0942084368787794
Validation loss: 4.250472421948671

Epoch: 6| Step: 9
Training loss: 5.594331679122642
Validation loss: 4.233342531649791

Epoch: 6| Step: 10
Training loss: 3.841277529080647
Validation loss: 4.2261707495188165

Epoch: 6| Step: 11
Training loss: 3.2179976389552074
Validation loss: 4.221006814793053

Epoch: 6| Step: 12
Training loss: 4.033965859324942
Validation loss: 4.192442754936468

Epoch: 6| Step: 13
Training loss: 3.314318319803907
Validation loss: 4.180055112852726

Epoch: 6| Step: 0
Training loss: 3.4084977599186006
Validation loss: 4.167445917581801

Epoch: 6| Step: 1
Training loss: 4.165712527065963
Validation loss: 4.1538514957540285

Epoch: 6| Step: 2
Training loss: 4.352781060098626
Validation loss: 4.137155149388176

Epoch: 6| Step: 3
Training loss: 4.448029182434405
Validation loss: 4.122804782882305

Epoch: 6| Step: 4
Training loss: 5.290632051664859
Validation loss: 4.106030897112895

Epoch: 6| Step: 5
Training loss: 3.470147615970182
Validation loss: 4.092049945900862

Epoch: 6| Step: 6
Training loss: 4.466393763237968
Validation loss: 4.099863155481348

Epoch: 6| Step: 7
Training loss: 1.9803468565137476
Validation loss: 4.070100057395508

Epoch: 6| Step: 8
Training loss: 4.535679408348048
Validation loss: 4.066682034595756

Epoch: 6| Step: 9
Training loss: 4.544248261345564
Validation loss: 4.038946255938511

Epoch: 6| Step: 10
Training loss: 5.200204390397006
Validation loss: 4.0307764447867065

Epoch: 6| Step: 11
Training loss: 3.1955737914159137
Validation loss: 4.026695968888304

Epoch: 6| Step: 12
Training loss: 4.631267733932498
Validation loss: 4.00525297672927

Epoch: 6| Step: 13
Training loss: 4.180898444616805
Validation loss: 3.9868000594415736

Epoch: 7| Step: 0
Training loss: 3.5827689206866364
Validation loss: 3.977061211968345

Epoch: 6| Step: 1
Training loss: 3.745349161655346
Validation loss: 3.968844065683081

Epoch: 6| Step: 2
Training loss: 3.161199937260369
Validation loss: 3.96260910875129

Epoch: 6| Step: 3
Training loss: 4.384096552516506
Validation loss: 3.9478324621194156

Epoch: 6| Step: 4
Training loss: 4.474458476285802
Validation loss: 3.943357181508338

Epoch: 6| Step: 5
Training loss: 3.4390475864251684
Validation loss: 3.939167186060594

Epoch: 6| Step: 6
Training loss: 4.715193260657675
Validation loss: 3.9392331266541563

Epoch: 6| Step: 7
Training loss: 3.70973921854085
Validation loss: 3.914148147134236

Epoch: 6| Step: 8
Training loss: 3.903244449201793
Validation loss: 3.9155631455877136

Epoch: 6| Step: 9
Training loss: 3.577691197647597
Validation loss: 3.9159277247470294

Epoch: 6| Step: 10
Training loss: 5.053983329766591
Validation loss: 3.9036805816292293

Epoch: 6| Step: 11
Training loss: 4.321041549232133
Validation loss: 3.8881115689298458

Epoch: 6| Step: 12
Training loss: 4.121058575086852
Validation loss: 3.8717669079928854

Epoch: 6| Step: 13
Training loss: 4.6463928341918
Validation loss: 3.8570436514928197

Epoch: 8| Step: 0
Training loss: 2.6245744451079718
Validation loss: 3.8619597575453026

Epoch: 6| Step: 1
Training loss: 4.123565886921088
Validation loss: 3.894717508720627

Epoch: 6| Step: 2
Training loss: 4.652850862501574
Validation loss: 3.837131348632924

Epoch: 6| Step: 3
Training loss: 4.329116872893353
Validation loss: 3.815089726871338

Epoch: 6| Step: 4
Training loss: 4.62590801501488
Validation loss: 3.814922712844124

Epoch: 6| Step: 5
Training loss: 3.7738390722689528
Validation loss: 3.8147102241883393

Epoch: 6| Step: 6
Training loss: 4.384277534081255
Validation loss: 3.8059359560629162

Epoch: 6| Step: 7
Training loss: 4.499085863300086
Validation loss: 3.7946845323937355

Epoch: 6| Step: 8
Training loss: 3.6075081889799128
Validation loss: 3.7723652110935633

Epoch: 6| Step: 9
Training loss: 3.1062756911506733
Validation loss: 3.753960618720661

Epoch: 6| Step: 10
Training loss: 4.228835871244915
Validation loss: 3.748206274985798

Epoch: 6| Step: 11
Training loss: 3.3699104645830933
Validation loss: 3.7571995442288206

Epoch: 6| Step: 12
Training loss: 3.9999058235526044
Validation loss: 3.752585384644717

Epoch: 6| Step: 13
Training loss: 3.3847064559528275
Validation loss: 3.7204211726506076

Epoch: 9| Step: 0
Training loss: 3.8913095630335612
Validation loss: 3.718699729898842

Epoch: 6| Step: 1
Training loss: 3.1711292611648023
Validation loss: 3.723791953627589

Epoch: 6| Step: 2
Training loss: 3.279765201863986
Validation loss: 3.733214396532029

Epoch: 6| Step: 3
Training loss: 4.961891863479913
Validation loss: 3.734343916618234

Epoch: 6| Step: 4
Training loss: 3.6898330807859723
Validation loss: 3.7133178164827556

Epoch: 6| Step: 5
Training loss: 3.8610976849390384
Validation loss: 3.7037120329741566

Epoch: 6| Step: 6
Training loss: 4.218355287524642
Validation loss: 3.6961693931286743

Epoch: 6| Step: 7
Training loss: 3.3057957587780407
Validation loss: 3.6887596346876115

Epoch: 6| Step: 8
Training loss: 4.2921231715294565
Validation loss: 3.6711528066989776

Epoch: 6| Step: 9
Training loss: 3.4474609319673815
Validation loss: 3.660223699666519

Epoch: 6| Step: 10
Training loss: 4.486429096259808
Validation loss: 3.652584220108014

Epoch: 6| Step: 11
Training loss: 4.000686824960326
Validation loss: 3.6465497645788623

Epoch: 6| Step: 12
Training loss: 3.8539480748778883
Validation loss: 3.6446243255079587

Epoch: 6| Step: 13
Training loss: 2.8561391395740743
Validation loss: 3.635931331470416

Epoch: 10| Step: 0
Training loss: 3.7851730047116927
Validation loss: 3.628199571585402

Epoch: 6| Step: 1
Training loss: 3.684290895804405
Validation loss: 3.622236606599872

Epoch: 6| Step: 2
Training loss: 3.9653233430689974
Validation loss: 3.620917709373632

Epoch: 6| Step: 3
Training loss: 3.8087059278351436
Validation loss: 3.6084123611653354

Epoch: 6| Step: 4
Training loss: 3.8742355084773155
Validation loss: 3.6058644375238926

Epoch: 6| Step: 5
Training loss: 4.055825722345459
Validation loss: 3.5992880588965495

Epoch: 6| Step: 6
Training loss: 3.953183501643765
Validation loss: 3.590930827730992

Epoch: 6| Step: 7
Training loss: 4.114459355413967
Validation loss: 3.583065900579182

Epoch: 6| Step: 8
Training loss: 4.098903993329583
Validation loss: 3.5800587906498405

Epoch: 6| Step: 9
Training loss: 3.391237405766949
Validation loss: 3.5734502304925577

Epoch: 6| Step: 10
Training loss: 2.7547184605408375
Validation loss: 3.576375317583473

Epoch: 6| Step: 11
Training loss: 4.482258686095343
Validation loss: 3.5685104260106546

Epoch: 6| Step: 12
Training loss: 3.40717436120982
Validation loss: 3.5588957338059832

Epoch: 6| Step: 13
Training loss: 3.044268623048857
Validation loss: 3.552685583197058

Epoch: 11| Step: 0
Training loss: 2.693118764463312
Validation loss: 3.547891845196241

Epoch: 6| Step: 1
Training loss: 3.1797948720737943
Validation loss: 3.5458101249097154

Epoch: 6| Step: 2
Training loss: 4.129515979104535
Validation loss: 3.5438282493408626

Epoch: 6| Step: 3
Training loss: 4.004026532110974
Validation loss: 3.536360819949189

Epoch: 6| Step: 4
Training loss: 4.045334688540563
Validation loss: 3.5371074891112686

Epoch: 6| Step: 5
Training loss: 3.362859294088282
Validation loss: 3.538011323395341

Epoch: 6| Step: 6
Training loss: 3.901554550999987
Validation loss: 3.532025270174605

Epoch: 6| Step: 7
Training loss: 3.492397771389095
Validation loss: 3.52449132698875

Epoch: 6| Step: 8
Training loss: 3.7388633665435864
Validation loss: 3.5173159774110374

Epoch: 6| Step: 9
Training loss: 3.048365927539874
Validation loss: 3.512417684720426

Epoch: 6| Step: 10
Training loss: 3.81196140174498
Validation loss: 3.5087923883444536

Epoch: 6| Step: 11
Training loss: 3.9789597755425654
Validation loss: 3.5069146097812713

Epoch: 6| Step: 12
Training loss: 4.169800660562579
Validation loss: 3.5017149249954023

Epoch: 6| Step: 13
Training loss: 4.608291964261906
Validation loss: 3.501150935217233

Epoch: 12| Step: 0
Training loss: 3.5972774277177697
Validation loss: 3.4924613612358635

Epoch: 6| Step: 1
Training loss: 3.1848723108395633
Validation loss: 3.493346665793819

Epoch: 6| Step: 2
Training loss: 4.184864182541455
Validation loss: 3.4839852437571404

Epoch: 6| Step: 3
Training loss: 3.345455412148375
Validation loss: 3.488129222119927

Epoch: 6| Step: 4
Training loss: 3.443829067866412
Validation loss: 3.4855001178051186

Epoch: 6| Step: 5
Training loss: 3.3388079191416287
Validation loss: 3.4843167646344098

Epoch: 6| Step: 6
Training loss: 3.75009002577485
Validation loss: 3.4767760552830707

Epoch: 6| Step: 7
Training loss: 4.4987910024136974
Validation loss: 3.473712443405648

Epoch: 6| Step: 8
Training loss: 3.3511937078566683
Validation loss: 3.469699187645375

Epoch: 6| Step: 9
Training loss: 4.329123041094078
Validation loss: 3.464179520304829

Epoch: 6| Step: 10
Training loss: 3.893753448533786
Validation loss: 3.4628674307560012

Epoch: 6| Step: 11
Training loss: 4.226438397120938
Validation loss: 3.4588620349673422

Epoch: 6| Step: 12
Training loss: 2.964785689638602
Validation loss: 3.458115203260497

Epoch: 6| Step: 13
Training loss: 2.562811483665091
Validation loss: 3.4540834972592664

Epoch: 13| Step: 0
Training loss: 3.194505361077537
Validation loss: 3.452433331107025

Epoch: 6| Step: 1
Training loss: 2.975224552174887
Validation loss: 3.4486432818153

Epoch: 6| Step: 2
Training loss: 3.861166966596123
Validation loss: 3.443672990121211

Epoch: 6| Step: 3
Training loss: 4.1614058789260335
Validation loss: 3.4438141489978356

Epoch: 6| Step: 4
Training loss: 3.922150013312687
Validation loss: 3.4371434508782994

Epoch: 6| Step: 5
Training loss: 3.6279876498986847
Validation loss: 3.4357127729567445

Epoch: 6| Step: 6
Training loss: 3.4775071135941125
Validation loss: 3.437456465190954

Epoch: 6| Step: 7
Training loss: 3.3001692526213358
Validation loss: 3.446546982858546

Epoch: 6| Step: 8
Training loss: 3.840676171851937
Validation loss: 3.431094184970431

Epoch: 6| Step: 9
Training loss: 3.6345132107748452
Validation loss: 3.4289379475759243

Epoch: 6| Step: 10
Training loss: 4.091166838801038
Validation loss: 3.4255114876506205

Epoch: 6| Step: 11
Training loss: 3.7365596238887955
Validation loss: 3.4247583009836142

Epoch: 6| Step: 12
Training loss: 3.4234357784237313
Validation loss: 3.4219643204754857

Epoch: 6| Step: 13
Training loss: 3.7927718735111227
Validation loss: 3.418770904216148

Epoch: 14| Step: 0
Training loss: 2.904173406504651
Validation loss: 3.4149311053571574

Epoch: 6| Step: 1
Training loss: 2.5243210323465046
Validation loss: 3.4141626183550007

Epoch: 6| Step: 2
Training loss: 4.400697713499597
Validation loss: 3.410296229024078

Epoch: 6| Step: 3
Training loss: 3.733839307852934
Validation loss: 3.4084550415551984

Epoch: 6| Step: 4
Training loss: 3.094818547218877
Validation loss: 3.405722238628866

Epoch: 6| Step: 5
Training loss: 2.8597121743442595
Validation loss: 3.414728185518138

Epoch: 6| Step: 6
Training loss: 4.127692990796376
Validation loss: 3.4201754184508113

Epoch: 6| Step: 7
Training loss: 3.6539414119272458
Validation loss: 3.399752344682411

Epoch: 6| Step: 8
Training loss: 4.335024625890847
Validation loss: 3.398600666870748

Epoch: 6| Step: 9
Training loss: 3.0959089048325508
Validation loss: 3.401478626053861

Epoch: 6| Step: 10
Training loss: 3.2772561608341797
Validation loss: 3.4048209525410997

Epoch: 6| Step: 11
Training loss: 3.7033418358522927
Validation loss: 3.403758001178282

Epoch: 6| Step: 12
Training loss: 4.896845265233091
Validation loss: 3.400498080279924

Epoch: 6| Step: 13
Training loss: 3.1917482377294917
Validation loss: 3.3953905846823096

Epoch: 15| Step: 0
Training loss: 3.1048194830322737
Validation loss: 3.3944902122434906

Epoch: 6| Step: 1
Training loss: 3.1830413151827224
Validation loss: 3.3917522013180834

Epoch: 6| Step: 2
Training loss: 3.368089736467897
Validation loss: 3.3889768165313896

Epoch: 6| Step: 3
Training loss: 4.333603239212389
Validation loss: 3.3870564820685742

Epoch: 6| Step: 4
Training loss: 3.7805376879434673
Validation loss: 3.3826517364687123

Epoch: 6| Step: 5
Training loss: 4.230979994212426
Validation loss: 3.3791773370392986

Epoch: 6| Step: 6
Training loss: 3.320947061375783
Validation loss: 3.3766657760651824

Epoch: 6| Step: 7
Training loss: 2.961512044356259
Validation loss: 3.3734485291529834

Epoch: 6| Step: 8
Training loss: 3.818680428278579
Validation loss: 3.374800575529369

Epoch: 6| Step: 9
Training loss: 2.5133513607151006
Validation loss: 3.3718508753738985

Epoch: 6| Step: 10
Training loss: 3.824549410340867
Validation loss: 3.374963180602454

Epoch: 6| Step: 11
Training loss: 3.8830728424415413
Validation loss: 3.372821735388252

Epoch: 6| Step: 12
Training loss: 3.835907790307873
Validation loss: 3.3697460834806665

Epoch: 6| Step: 13
Training loss: 4.10929609447772
Validation loss: 3.3647461390837674

Epoch: 16| Step: 0
Training loss: 3.314389391743236
Validation loss: 3.362342715241542

Epoch: 6| Step: 1
Training loss: 3.964930701594269
Validation loss: 3.3607077501599734

Epoch: 6| Step: 2
Training loss: 4.252761168267187
Validation loss: 3.356987202116551

Epoch: 6| Step: 3
Training loss: 2.950078129137867
Validation loss: 3.3578510526125105

Epoch: 6| Step: 4
Training loss: 3.454674144565504
Validation loss: 3.356840434695264

Epoch: 6| Step: 5
Training loss: 3.5499157747834866
Validation loss: 3.3561423313700907

Epoch: 6| Step: 6
Training loss: 3.32037497068989
Validation loss: 3.3510165781635877

Epoch: 6| Step: 7
Training loss: 3.922754804554171
Validation loss: 3.350875694244886

Epoch: 6| Step: 8
Training loss: 3.532051873099422
Validation loss: 3.349472737958359

Epoch: 6| Step: 9
Training loss: 3.339712682461113
Validation loss: 3.348253868076102

Epoch: 6| Step: 10
Training loss: 4.49031274568678
Validation loss: 3.348007791162719

Epoch: 6| Step: 11
Training loss: 3.198310620689619
Validation loss: 3.345338030489129

Epoch: 6| Step: 12
Training loss: 3.5182455510968107
Validation loss: 3.3435432815633477

Epoch: 6| Step: 13
Training loss: 2.6039692511435075
Validation loss: 3.342343547990548

Epoch: 17| Step: 0
Training loss: 3.5980501404555802
Validation loss: 3.3413714295458825

Epoch: 6| Step: 1
Training loss: 4.263888386337356
Validation loss: 3.338770289061876

Epoch: 6| Step: 2
Training loss: 3.8402402407279608
Validation loss: 3.3365256356452844

Epoch: 6| Step: 3
Training loss: 3.64388172048983
Validation loss: 3.336339905685748

Epoch: 6| Step: 4
Training loss: 4.0202972898110305
Validation loss: 3.335497913704722

Epoch: 6| Step: 5
Training loss: 3.7000986601588974
Validation loss: 3.3347706223788736

Epoch: 6| Step: 6
Training loss: 3.784952919993508
Validation loss: 3.3317546218247114

Epoch: 6| Step: 7
Training loss: 4.213429126093182
Validation loss: 3.331200720910023

Epoch: 6| Step: 8
Training loss: 3.3648684984107002
Validation loss: 3.33198134989115

Epoch: 6| Step: 9
Training loss: 3.4315894898722883
Validation loss: 3.3283126048708587

Epoch: 6| Step: 10
Training loss: 2.6098954829485574
Validation loss: 3.327324789871887

Epoch: 6| Step: 11
Training loss: 2.8293112274526377
Validation loss: 3.3250055085922305

Epoch: 6| Step: 12
Training loss: 2.8014763005575203
Validation loss: 3.3232453796657397

Epoch: 6| Step: 13
Training loss: 3.2835855074118085
Validation loss: 3.3219039124077883

Epoch: 18| Step: 0
Training loss: 3.9647968458586456
Validation loss: 3.3212695878798613

Epoch: 6| Step: 1
Training loss: 3.1008170743080465
Validation loss: 3.320562184239446

Epoch: 6| Step: 2
Training loss: 2.4309171159455785
Validation loss: 3.3196357878080778

Epoch: 6| Step: 3
Training loss: 3.867531007865581
Validation loss: 3.319602323824967

Epoch: 6| Step: 4
Training loss: 3.3399505419695563
Validation loss: 3.3190985826232415

Epoch: 6| Step: 5
Training loss: 3.0856828415494704
Validation loss: 3.3167440399735293

Epoch: 6| Step: 6
Training loss: 3.4748271597272327
Validation loss: 3.316398741670862

Epoch: 6| Step: 7
Training loss: 4.216735358803258
Validation loss: 3.3147712872082846

Epoch: 6| Step: 8
Training loss: 3.398798079380329
Validation loss: 3.3133259186874557

Epoch: 6| Step: 9
Training loss: 3.39056297983852
Validation loss: 3.3134968720930127

Epoch: 6| Step: 10
Training loss: 3.6848207212235704
Validation loss: 3.3136190604878815

Epoch: 6| Step: 11
Training loss: 3.827389144238927
Validation loss: 3.313829235401879

Epoch: 6| Step: 12
Training loss: 3.198117393796224
Validation loss: 3.3158225053503436

Epoch: 6| Step: 13
Training loss: 4.872035959458714
Validation loss: 3.3103887757085424

Epoch: 19| Step: 0
Training loss: 3.0670656697917216
Validation loss: 3.3080513867470738

Epoch: 6| Step: 1
Training loss: 3.3740297971629643
Validation loss: 3.306973074264377

Epoch: 6| Step: 2
Training loss: 3.2043948749947435
Validation loss: 3.310644980488921

Epoch: 6| Step: 3
Training loss: 2.944926674258674
Validation loss: 3.313358855705566

Epoch: 6| Step: 4
Training loss: 3.611251541406732
Validation loss: 3.320017384027582

Epoch: 6| Step: 5
Training loss: 3.8683197521764052
Validation loss: 3.3149167990270296

Epoch: 6| Step: 6
Training loss: 3.6299943391109495
Validation loss: 3.3107909508717586

Epoch: 6| Step: 7
Training loss: 3.869253881916017
Validation loss: 3.3049163300829956

Epoch: 6| Step: 8
Training loss: 3.560723648244823
Validation loss: 3.3037307926498807

Epoch: 6| Step: 9
Training loss: 3.8355722661376945
Validation loss: 3.3047100217547243

Epoch: 6| Step: 10
Training loss: 3.7263887312899295
Validation loss: 3.3005693362182447

Epoch: 6| Step: 11
Training loss: 3.9995633125353827
Validation loss: 3.300449464902427

Epoch: 6| Step: 12
Training loss: 2.668123254728517
Validation loss: 3.298992936049268

Epoch: 6| Step: 13
Training loss: 4.335834123908435
Validation loss: 3.2978396672102908

Epoch: 20| Step: 0
Training loss: 3.2822357150367036
Validation loss: 3.297129578591392

Epoch: 6| Step: 1
Training loss: 3.3365132105317272
Validation loss: 3.2971700273793174

Epoch: 6| Step: 2
Training loss: 3.887488636846586
Validation loss: 3.295761488779157

Epoch: 6| Step: 3
Training loss: 4.413771682206328
Validation loss: 3.294319731393899

Epoch: 6| Step: 4
Training loss: 2.6648730166529986
Validation loss: 3.2942485898880216

Epoch: 6| Step: 5
Training loss: 3.5457214630684897
Validation loss: 3.292619341219011

Epoch: 6| Step: 6
Training loss: 3.654203836794982
Validation loss: 3.290761526970492

Epoch: 6| Step: 7
Training loss: 3.6231521632275383
Validation loss: 3.28932789471386

Epoch: 6| Step: 8
Training loss: 4.092510472530698
Validation loss: 3.2917683841248517

Epoch: 6| Step: 9
Training loss: 3.486070160711811
Validation loss: 3.292002456088372

Epoch: 6| Step: 10
Training loss: 3.5430669970701287
Validation loss: 3.2907674523567465

Epoch: 6| Step: 11
Training loss: 2.6887087210763445
Validation loss: 3.2874448771233866

Epoch: 6| Step: 12
Training loss: 3.361714954272128
Validation loss: 3.2891341714501343

Epoch: 6| Step: 13
Training loss: 3.4770087823633458
Validation loss: 3.2838055231506034

Epoch: 21| Step: 0
Training loss: 3.9231540980163175
Validation loss: 3.2843718928836423

Epoch: 6| Step: 1
Training loss: 3.9562579017789252
Validation loss: 3.280260592205

Epoch: 6| Step: 2
Training loss: 3.321916834369544
Validation loss: 3.2811063853222278

Epoch: 6| Step: 3
Training loss: 2.944200219716189
Validation loss: 3.2810990118630894

Epoch: 6| Step: 4
Training loss: 3.2668720401380495
Validation loss: 3.2809882931272822

Epoch: 6| Step: 5
Training loss: 4.0484027114604295
Validation loss: 3.2781958300966125

Epoch: 6| Step: 6
Training loss: 3.719996395724612
Validation loss: 3.2771556430220685

Epoch: 6| Step: 7
Training loss: 3.308727923738614
Validation loss: 3.2780513316149236

Epoch: 6| Step: 8
Training loss: 3.160809839511503
Validation loss: 3.2766314354106396

Epoch: 6| Step: 9
Training loss: 3.0611818551967698
Validation loss: 3.2768252930656097

Epoch: 6| Step: 10
Training loss: 3.8831281015631474
Validation loss: 3.276531557235154

Epoch: 6| Step: 11
Training loss: 3.9791687704084073
Validation loss: 3.2801341748125106

Epoch: 6| Step: 12
Training loss: 3.457275657850446
Validation loss: 3.2785577670426083

Epoch: 6| Step: 13
Training loss: 2.5661399854146016
Validation loss: 3.2756764098931246

Epoch: 22| Step: 0
Training loss: 3.7920565701622957
Validation loss: 3.2779895825158354

Epoch: 6| Step: 1
Training loss: 3.4639607952709737
Validation loss: 3.2983715115573684

Epoch: 6| Step: 2
Training loss: 2.936028781708218
Validation loss: 3.2714167656460713

Epoch: 6| Step: 3
Training loss: 3.35794164552134
Validation loss: 3.2696285569750665

Epoch: 6| Step: 4
Training loss: 3.5068850236313316
Validation loss: 3.2707822121760417

Epoch: 6| Step: 5
Training loss: 4.077638092789928
Validation loss: 3.2724325971570627

Epoch: 6| Step: 6
Training loss: 3.6619351521057193
Validation loss: 3.272294071738434

Epoch: 6| Step: 7
Training loss: 2.989277433015076
Validation loss: 3.273373945569175

Epoch: 6| Step: 8
Training loss: 2.926659893934658
Validation loss: 3.27223286191189

Epoch: 6| Step: 9
Training loss: 3.794062447918275
Validation loss: 3.2713941729836167

Epoch: 6| Step: 10
Training loss: 2.7314232289004936
Validation loss: 3.2704337786319133

Epoch: 6| Step: 11
Training loss: 4.656093927622358
Validation loss: 3.2688019239552095

Epoch: 6| Step: 12
Training loss: 3.7625504601222053
Validation loss: 3.2687947101829673

Epoch: 6| Step: 13
Training loss: 2.7618846708578597
Validation loss: 3.2660567346650975

Epoch: 23| Step: 0
Training loss: 3.2488844497529734
Validation loss: 3.2635215975600076

Epoch: 6| Step: 1
Training loss: 3.751914870599815
Validation loss: 3.262487605675678

Epoch: 6| Step: 2
Training loss: 3.985425623584393
Validation loss: 3.2619339940991394

Epoch: 6| Step: 3
Training loss: 3.962146582020225
Validation loss: 3.263176535288979

Epoch: 6| Step: 4
Training loss: 3.655255043743795
Validation loss: 3.2621001630395074

Epoch: 6| Step: 5
Training loss: 3.3960651404397932
Validation loss: 3.26087073879093

Epoch: 6| Step: 6
Training loss: 2.8872307722075874
Validation loss: 3.259572541241554

Epoch: 6| Step: 7
Training loss: 3.451287933107986
Validation loss: 3.2588565562315805

Epoch: 6| Step: 8
Training loss: 2.363713097327133
Validation loss: 3.256282919175924

Epoch: 6| Step: 9
Training loss: 2.8849583524610143
Validation loss: 3.2572501004927155

Epoch: 6| Step: 10
Training loss: 4.212535661042722
Validation loss: 3.2553967298892967

Epoch: 6| Step: 11
Training loss: 3.9142817818439926
Validation loss: 3.257119364596816

Epoch: 6| Step: 12
Training loss: 3.356964524005234
Validation loss: 3.2517417235183186

Epoch: 6| Step: 13
Training loss: 3.635976287411961
Validation loss: 3.2544703333243663

Epoch: 24| Step: 0
Training loss: 3.545440652682244
Validation loss: 3.252260491633111

Epoch: 6| Step: 1
Training loss: 2.7210571321646126
Validation loss: 3.2526836264210806

Epoch: 6| Step: 2
Training loss: 3.3395007933381384
Validation loss: 3.252333209772556

Epoch: 6| Step: 3
Training loss: 3.380464439309997
Validation loss: 3.25281896515516

Epoch: 6| Step: 4
Training loss: 3.5126251307018075
Validation loss: 3.2511639699638626

Epoch: 6| Step: 5
Training loss: 3.999721040535153
Validation loss: 3.252640778516554

Epoch: 6| Step: 6
Training loss: 3.5525279433395043
Validation loss: 3.249896313675348

Epoch: 6| Step: 7
Training loss: 3.5454636509207087
Validation loss: 3.2516592363806547

Epoch: 6| Step: 8
Training loss: 3.987206982217373
Validation loss: 3.248638481582699

Epoch: 6| Step: 9
Training loss: 3.5134700698109724
Validation loss: 3.2466847759916817

Epoch: 6| Step: 10
Training loss: 3.3579442015709935
Validation loss: 3.24766124918247

Epoch: 6| Step: 11
Training loss: 3.494126432335625
Validation loss: 3.247114280805779

Epoch: 6| Step: 12
Training loss: 3.2584008433445084
Validation loss: 3.2453748221477694

Epoch: 6| Step: 13
Training loss: 3.714547355051148
Validation loss: 3.2471611286212587

Epoch: 25| Step: 0
Training loss: 3.4638260268117618
Validation loss: 3.250768127414131

Epoch: 6| Step: 1
Training loss: 2.735293512024592
Validation loss: 3.2476122614345955

Epoch: 6| Step: 2
Training loss: 4.024750904407538
Validation loss: 3.2482292677520075

Epoch: 6| Step: 3
Training loss: 3.6519922750334914
Validation loss: 3.2440989934561912

Epoch: 6| Step: 4
Training loss: 3.88536261281449
Validation loss: 3.239863045148982

Epoch: 6| Step: 5
Training loss: 2.901253948743139
Validation loss: 3.2413115465505413

Epoch: 6| Step: 6
Training loss: 3.475606654063364
Validation loss: 3.243373036847634

Epoch: 6| Step: 7
Training loss: 3.0180622588979147
Validation loss: 3.2412855012216384

Epoch: 6| Step: 8
Training loss: 3.3105483153573565
Validation loss: 3.240833313676637

Epoch: 6| Step: 9
Training loss: 3.8053902793567254
Validation loss: 3.2410410034442334

Epoch: 6| Step: 10
Training loss: 3.8452284535969463
Validation loss: 3.2402892767827995

Epoch: 6| Step: 11
Training loss: 3.4346801289043825
Validation loss: 3.238124561045632

Epoch: 6| Step: 12
Training loss: 3.6741392256387675
Validation loss: 3.237622337042806

Epoch: 6| Step: 13
Training loss: 3.3577779122865983
Validation loss: 3.2365235348962504

Epoch: 26| Step: 0
Training loss: 3.527149892150082
Validation loss: 3.236365076761697

Epoch: 6| Step: 1
Training loss: 3.0188199052950258
Validation loss: 3.244600243397335

Epoch: 6| Step: 2
Training loss: 4.303530889025077
Validation loss: 3.260606564364612

Epoch: 6| Step: 3
Training loss: 3.9842674091248633
Validation loss: 3.234355900895183

Epoch: 6| Step: 4
Training loss: 2.9714189277743954
Validation loss: 3.233637229377917

Epoch: 6| Step: 5
Training loss: 3.0340670051191574
Validation loss: 3.2318808547691797

Epoch: 6| Step: 6
Training loss: 3.207379451160337
Validation loss: 3.2328546133078695

Epoch: 6| Step: 7
Training loss: 3.317855392542411
Validation loss: 3.2351236077951335

Epoch: 6| Step: 8
Training loss: 3.482800594153747
Validation loss: 3.232220069418244

Epoch: 6| Step: 9
Training loss: 3.1571080014179413
Validation loss: 3.232427458434089

Epoch: 6| Step: 10
Training loss: 3.6863305775297817
Validation loss: 3.2313128502650574

Epoch: 6| Step: 11
Training loss: 3.6083942088101066
Validation loss: 3.2311180345015442

Epoch: 6| Step: 12
Training loss: 3.545631224224855
Validation loss: 3.230489468762588

Epoch: 6| Step: 13
Training loss: 3.913619756879867
Validation loss: 3.230575735728601

Epoch: 27| Step: 0
Training loss: 2.916075801036828
Validation loss: 3.231440738087953

Epoch: 6| Step: 1
Training loss: 3.4312654310758433
Validation loss: 3.2349873116216448

Epoch: 6| Step: 2
Training loss: 3.4749694603325856
Validation loss: 3.2425720469128594

Epoch: 6| Step: 3
Training loss: 3.1934946573982326
Validation loss: 3.2746314345416163

Epoch: 6| Step: 4
Training loss: 3.450082534687364
Validation loss: 3.2857681536999124

Epoch: 6| Step: 5
Training loss: 3.721614727973824
Validation loss: 3.277362428064106

Epoch: 6| Step: 6
Training loss: 3.909312276237923
Validation loss: 3.241537446396017

Epoch: 6| Step: 7
Training loss: 3.682605792958373
Validation loss: 3.2270989717297263

Epoch: 6| Step: 8
Training loss: 3.456426086906892
Validation loss: 3.230398158556147

Epoch: 6| Step: 9
Training loss: 3.3620448658869524
Validation loss: 3.239568730803363

Epoch: 6| Step: 10
Training loss: 3.981400639964308
Validation loss: 3.2391381352347683

Epoch: 6| Step: 11
Training loss: 3.793152542454251
Validation loss: 3.2360552259327107

Epoch: 6| Step: 12
Training loss: 2.9037799798515587
Validation loss: 3.231395154662213

Epoch: 6| Step: 13
Training loss: 3.482846870098747
Validation loss: 3.2313007457303846

Epoch: 28| Step: 0
Training loss: 3.5684411551589346
Validation loss: 3.224096814333237

Epoch: 6| Step: 1
Training loss: 2.9017095065327845
Validation loss: 3.2225839218321224

Epoch: 6| Step: 2
Training loss: 3.011306754306222
Validation loss: 3.220037678846072

Epoch: 6| Step: 3
Training loss: 3.5155495868647733
Validation loss: 3.223315123682336

Epoch: 6| Step: 4
Training loss: 4.830319199212841
Validation loss: 3.221736439647158

Epoch: 6| Step: 5
Training loss: 3.5549738841968694
Validation loss: 3.22109732023925

Epoch: 6| Step: 6
Training loss: 3.342087519551558
Validation loss: 3.222011554030239

Epoch: 6| Step: 7
Training loss: 3.993220902857255
Validation loss: 3.2230561520332337

Epoch: 6| Step: 8
Training loss: 3.1965235721143244
Validation loss: 3.22248503835836

Epoch: 6| Step: 9
Training loss: 3.495048289913621
Validation loss: 3.2183133036248366

Epoch: 6| Step: 10
Training loss: 2.5311292454679557
Validation loss: 3.2161501531666183

Epoch: 6| Step: 11
Training loss: 2.885539597372625
Validation loss: 3.2144058115253245

Epoch: 6| Step: 12
Training loss: 3.489441613503205
Validation loss: 3.2116500965569665

Epoch: 6| Step: 13
Training loss: 3.9632976655716
Validation loss: 3.2123166290154557

Epoch: 29| Step: 0
Training loss: 3.4038763612735576
Validation loss: 3.2125933528612354

Epoch: 6| Step: 1
Training loss: 3.4679152025461613
Validation loss: 3.2117175176842134

Epoch: 6| Step: 2
Training loss: 3.2281965870042213
Validation loss: 3.2096510792434345

Epoch: 6| Step: 3
Training loss: 2.8787772202788777
Validation loss: 3.209250522126284

Epoch: 6| Step: 4
Training loss: 3.845795126105594
Validation loss: 3.2095961022718513

Epoch: 6| Step: 5
Training loss: 4.1707556433719235
Validation loss: 3.2081456975853233

Epoch: 6| Step: 6
Training loss: 3.693345560565452
Validation loss: 3.20799873907542

Epoch: 6| Step: 7
Training loss: 3.5949211534281575
Validation loss: 3.208499739259738

Epoch: 6| Step: 8
Training loss: 3.8996883365615838
Validation loss: 3.2088880667977375

Epoch: 6| Step: 9
Training loss: 3.3621930744526645
Validation loss: 3.206949605755992

Epoch: 6| Step: 10
Training loss: 2.9522752296105574
Validation loss: 3.2062621642148663

Epoch: 6| Step: 11
Training loss: 2.157768488828075
Validation loss: 3.2066499976259855

Epoch: 6| Step: 12
Training loss: 3.7597151477942727
Validation loss: 3.2063410747016596

Epoch: 6| Step: 13
Training loss: 3.6686761435981845
Validation loss: 3.206575651865208

Epoch: 30| Step: 0
Training loss: 3.2169774183738293
Validation loss: 3.2052253677874405

Epoch: 6| Step: 1
Training loss: 4.185896153546618
Validation loss: 3.2048341510602656

Epoch: 6| Step: 2
Training loss: 4.131448502612169
Validation loss: 3.205661265582435

Epoch: 6| Step: 3
Training loss: 3.0408983348848526
Validation loss: 3.2040581593215682

Epoch: 6| Step: 4
Training loss: 3.604354206711172
Validation loss: 3.2090646725002676

Epoch: 6| Step: 5
Training loss: 2.9642909241990023
Validation loss: 3.2071771465488186

Epoch: 6| Step: 6
Training loss: 3.414621128496085
Validation loss: 3.2054219075878265

Epoch: 6| Step: 7
Training loss: 4.029338057987549
Validation loss: 3.208037375671358

Epoch: 6| Step: 8
Training loss: 3.5048195489640808
Validation loss: 3.20327547301685

Epoch: 6| Step: 9
Training loss: 2.691120813567338
Validation loss: 3.1991874994499083

Epoch: 6| Step: 10
Training loss: 3.4970465869412997
Validation loss: 3.201924980590019

Epoch: 6| Step: 11
Training loss: 3.437869520266717
Validation loss: 3.202824797970262

Epoch: 6| Step: 12
Training loss: 3.626735140443904
Validation loss: 3.2012666359160478

Epoch: 6| Step: 13
Training loss: 1.7445805967589019
Validation loss: 3.202466495354631

Epoch: 31| Step: 0
Training loss: 2.48490199611531
Validation loss: 3.1995610901329354

Epoch: 6| Step: 1
Training loss: 3.4076336491459864
Validation loss: 3.1991670972388104

Epoch: 6| Step: 2
Training loss: 3.349644679114243
Validation loss: 3.1966583051808155

Epoch: 6| Step: 3
Training loss: 2.8289898134967126
Validation loss: 3.197131550993778

Epoch: 6| Step: 4
Training loss: 4.044593668782643
Validation loss: 3.1981332640177076

Epoch: 6| Step: 5
Training loss: 3.4903000887857525
Validation loss: 3.20047137021471

Epoch: 6| Step: 6
Training loss: 4.1393412201332636
Validation loss: 3.1996486492722847

Epoch: 6| Step: 7
Training loss: 2.7758190836369376
Validation loss: 3.197485543011604

Epoch: 6| Step: 8
Training loss: 3.2676796905912817
Validation loss: 3.1988828246474887

Epoch: 6| Step: 9
Training loss: 3.9516625394334373
Validation loss: 3.199287147877122

Epoch: 6| Step: 10
Training loss: 3.9339789738910147
Validation loss: 3.1989711628759516

Epoch: 6| Step: 11
Training loss: 3.110851761437794
Validation loss: 3.198305370461628

Epoch: 6| Step: 12
Training loss: 3.256825249467095
Validation loss: 3.195998901291636

Epoch: 6| Step: 13
Training loss: 4.016715647503008
Validation loss: 3.1957421819089515

Epoch: 32| Step: 0
Training loss: 3.5395070990394117
Validation loss: 3.1945918919610765

Epoch: 6| Step: 1
Training loss: 2.9990215295296765
Validation loss: 3.1932368856832007

Epoch: 6| Step: 2
Training loss: 3.776913765356893
Validation loss: 3.1929156923893496

Epoch: 6| Step: 3
Training loss: 3.7144767507743883
Validation loss: 3.189291020372876

Epoch: 6| Step: 4
Training loss: 3.8553529855340622
Validation loss: 3.1905815450743074

Epoch: 6| Step: 5
Training loss: 3.211253352536552
Validation loss: 3.187857200687715

Epoch: 6| Step: 6
Training loss: 3.2122396163208515
Validation loss: 3.1885340808997764

Epoch: 6| Step: 7
Training loss: 3.969096251274323
Validation loss: 3.188450815648715

Epoch: 6| Step: 8
Training loss: 2.315584857299287
Validation loss: 3.188462152586553

Epoch: 6| Step: 9
Training loss: 3.513504134580026
Validation loss: 3.1858928810368425

Epoch: 6| Step: 10
Training loss: 2.945066406330308
Validation loss: 3.1873045701967

Epoch: 6| Step: 11
Training loss: 3.9720013133927523
Validation loss: 3.192056259910686

Epoch: 6| Step: 12
Training loss: 3.116622682420841
Validation loss: 3.1945982043721757

Epoch: 6| Step: 13
Training loss: 3.828195874862079
Validation loss: 3.196189955858181

Epoch: 33| Step: 0
Training loss: 3.0786792236816587
Validation loss: 3.1835765124237514

Epoch: 6| Step: 1
Training loss: 3.5991774996957857
Validation loss: 3.1846624456287063

Epoch: 6| Step: 2
Training loss: 2.4832764121920388
Validation loss: 3.186112801939914

Epoch: 6| Step: 3
Training loss: 2.882679509762724
Validation loss: 3.183583614902707

Epoch: 6| Step: 4
Training loss: 3.891968031874467
Validation loss: 3.1834367932944883

Epoch: 6| Step: 5
Training loss: 3.9966736314048457
Validation loss: 3.1844396068804928

Epoch: 6| Step: 6
Training loss: 3.789560438649352
Validation loss: 3.18529438370602

Epoch: 6| Step: 7
Training loss: 3.4590818368803937
Validation loss: 3.1857396379427607

Epoch: 6| Step: 8
Training loss: 4.12173587081282
Validation loss: 3.1883628653709426

Epoch: 6| Step: 9
Training loss: 4.224031434404566
Validation loss: 3.187242150458766

Epoch: 6| Step: 10
Training loss: 3.3199956765204166
Validation loss: 3.1872685215878453

Epoch: 6| Step: 11
Training loss: 2.223189305106592
Validation loss: 3.186615675059441

Epoch: 6| Step: 12
Training loss: 3.3993318630538765
Validation loss: 3.1856404509664764

Epoch: 6| Step: 13
Training loss: 2.797595480072716
Validation loss: 3.183350722640126

Epoch: 34| Step: 0
Training loss: 2.9274343549370703
Validation loss: 3.18228547109227

Epoch: 6| Step: 1
Training loss: 3.6353585458097246
Validation loss: 3.1823261406073127

Epoch: 6| Step: 2
Training loss: 2.0486522850022575
Validation loss: 3.181767989027625

Epoch: 6| Step: 3
Training loss: 3.1396473743680158
Validation loss: 3.182098471960113

Epoch: 6| Step: 4
Training loss: 3.95057505514025
Validation loss: 3.1827404447661922

Epoch: 6| Step: 5
Training loss: 3.9615480452771314
Validation loss: 3.182674489592906

Epoch: 6| Step: 6
Training loss: 3.6126905133655343
Validation loss: 3.1832793456425343

Epoch: 6| Step: 7
Training loss: 3.602589756564236
Validation loss: 3.1805955317387054

Epoch: 6| Step: 8
Training loss: 3.3475451456548373
Validation loss: 3.178579571539575

Epoch: 6| Step: 9
Training loss: 3.6197682478259225
Validation loss: 3.180906566550232

Epoch: 6| Step: 10
Training loss: 3.5951437196401708
Validation loss: 3.1766758332475713

Epoch: 6| Step: 11
Training loss: 3.728060567191924
Validation loss: 3.175684406301515

Epoch: 6| Step: 12
Training loss: 3.2066479173880107
Validation loss: 3.174987492768039

Epoch: 6| Step: 13
Training loss: 3.14107377371247
Validation loss: 3.1737513528504238

Epoch: 35| Step: 0
Training loss: 4.5081016936996114
Validation loss: 3.174939101977691

Epoch: 6| Step: 1
Training loss: 3.4709501420080446
Validation loss: 3.1725546565692686

Epoch: 6| Step: 2
Training loss: 2.642368801761307
Validation loss: 3.1736139614144814

Epoch: 6| Step: 3
Training loss: 3.6523835695105418
Validation loss: 3.171610224428431

Epoch: 6| Step: 4
Training loss: 3.4590483389766256
Validation loss: 3.1721712712893235

Epoch: 6| Step: 5
Training loss: 3.9951084745764804
Validation loss: 3.1709639714296984

Epoch: 6| Step: 6
Training loss: 3.3304715905746742
Validation loss: 3.169489050191829

Epoch: 6| Step: 7
Training loss: 3.6681819443500165
Validation loss: 3.1684819271630116

Epoch: 6| Step: 8
Training loss: 3.262497860261062
Validation loss: 3.1671361677714

Epoch: 6| Step: 9
Training loss: 2.895923603947014
Validation loss: 3.165942069237535

Epoch: 6| Step: 10
Training loss: 3.4734256608617957
Validation loss: 3.165689431475728

Epoch: 6| Step: 11
Training loss: 2.562620020591052
Validation loss: 3.163671959469536

Epoch: 6| Step: 12
Training loss: 3.149221620816262
Validation loss: 3.170494684886214

Epoch: 6| Step: 13
Training loss: 3.43444077738562
Validation loss: 3.169806504611227

Epoch: 36| Step: 0
Training loss: 3.3880673091827345
Validation loss: 3.1812526759682704

Epoch: 6| Step: 1
Training loss: 3.3770127122960005
Validation loss: 3.1630846553090044

Epoch: 6| Step: 2
Training loss: 3.2614111475463874
Validation loss: 3.159290104924703

Epoch: 6| Step: 3
Training loss: 4.384427186270629
Validation loss: 3.160183905813058

Epoch: 6| Step: 4
Training loss: 2.866418387137019
Validation loss: 3.1606628789838567

Epoch: 6| Step: 5
Training loss: 3.050651830841661
Validation loss: 3.1611144906070208

Epoch: 6| Step: 6
Training loss: 3.8348466677892223
Validation loss: 3.1611600583339245

Epoch: 6| Step: 7
Training loss: 2.884474360613409
Validation loss: 3.163875666786174

Epoch: 6| Step: 8
Training loss: 3.6664750020189265
Validation loss: 3.1598212848219385

Epoch: 6| Step: 9
Training loss: 3.807676922901198
Validation loss: 3.1581493711023234

Epoch: 6| Step: 10
Training loss: 3.2362279329693173
Validation loss: 3.1580076673193895

Epoch: 6| Step: 11
Training loss: 3.2108840381042016
Validation loss: 3.1592727639560314

Epoch: 6| Step: 12
Training loss: 3.037476741246471
Validation loss: 3.1584432822136117

Epoch: 6| Step: 13
Training loss: 3.604266097327138
Validation loss: 3.157496680976827

Epoch: 37| Step: 0
Training loss: 3.1853290719628786
Validation loss: 3.159654595415645

Epoch: 6| Step: 1
Training loss: 3.176953539255552
Validation loss: 3.1601966145397133

Epoch: 6| Step: 2
Training loss: 4.284909431630997
Validation loss: 3.159405929118511

Epoch: 6| Step: 3
Training loss: 3.7019136274371505
Validation loss: 3.155799264156403

Epoch: 6| Step: 4
Training loss: 3.364744074301473
Validation loss: 3.1528902596790043

Epoch: 6| Step: 5
Training loss: 2.4330964047123214
Validation loss: 3.150734116750904

Epoch: 6| Step: 6
Training loss: 3.6910207718704195
Validation loss: 3.151908325891843

Epoch: 6| Step: 7
Training loss: 3.8934872068628765
Validation loss: 3.1506321482876705

Epoch: 6| Step: 8
Training loss: 2.9238835739147677
Validation loss: 3.149727748350478

Epoch: 6| Step: 9
Training loss: 3.5055020546059006
Validation loss: 3.1511919414769687

Epoch: 6| Step: 10
Training loss: 3.561947428363012
Validation loss: 3.1494613477294475

Epoch: 6| Step: 11
Training loss: 3.4622433784218263
Validation loss: 3.1481138402096365

Epoch: 6| Step: 12
Training loss: 2.8308146632577067
Validation loss: 3.147709847017111

Epoch: 6| Step: 13
Training loss: 3.16813281066016
Validation loss: 3.147852709058249

Epoch: 38| Step: 0
Training loss: 3.7997089374902857
Validation loss: 3.1461355749652262

Epoch: 6| Step: 1
Training loss: 4.05178923467118
Validation loss: 3.1480853136877567

Epoch: 6| Step: 2
Training loss: 2.21773645596093
Validation loss: 3.1447833978765525

Epoch: 6| Step: 3
Training loss: 3.102519236096944
Validation loss: 3.1448946598688403

Epoch: 6| Step: 4
Training loss: 3.7780458099673586
Validation loss: 3.1476290007814454

Epoch: 6| Step: 5
Training loss: 3.3904112295802795
Validation loss: 3.1435203440147066

Epoch: 6| Step: 6
Training loss: 3.6781090592627965
Validation loss: 3.144871280552623

Epoch: 6| Step: 7
Training loss: 3.726061133480578
Validation loss: 3.1430923597030507

Epoch: 6| Step: 8
Training loss: 3.540169986803095
Validation loss: 3.1419280039914783

Epoch: 6| Step: 9
Training loss: 3.76800436611692
Validation loss: 3.142286464109948

Epoch: 6| Step: 10
Training loss: 3.216020630575784
Validation loss: 3.1412778006647604

Epoch: 6| Step: 11
Training loss: 2.484930588119313
Validation loss: 3.141676189175014

Epoch: 6| Step: 12
Training loss: 3.192935721849838
Validation loss: 3.14108878870016

Epoch: 6| Step: 13
Training loss: 2.9106849548573797
Validation loss: 3.1394525742601505

Epoch: 39| Step: 0
Training loss: 3.25065562164312
Validation loss: 3.139557245269442

Epoch: 6| Step: 1
Training loss: 3.105587593539661
Validation loss: 3.13953313539084

Epoch: 6| Step: 2
Training loss: 3.583901086821743
Validation loss: 3.138978996463307

Epoch: 6| Step: 3
Training loss: 3.5522036415526026
Validation loss: 3.1387364874465393

Epoch: 6| Step: 4
Training loss: 3.0169933950056658
Validation loss: 3.13894893888148

Epoch: 6| Step: 5
Training loss: 3.0282118211076474
Validation loss: 3.13709335839427

Epoch: 6| Step: 6
Training loss: 2.8558477940753084
Validation loss: 3.138035523346996

Epoch: 6| Step: 7
Training loss: 3.7097469307270896
Validation loss: 3.1361383412882793

Epoch: 6| Step: 8
Training loss: 3.9403893904770357
Validation loss: 3.1360501288685496

Epoch: 6| Step: 9
Training loss: 3.476553173266984
Validation loss: 3.1371341479762704

Epoch: 6| Step: 10
Training loss: 4.11921887890936
Validation loss: 3.136395679140879

Epoch: 6| Step: 11
Training loss: 2.8230967634307826
Validation loss: 3.1367094818028574

Epoch: 6| Step: 12
Training loss: 2.8854340003051857
Validation loss: 3.1381258023518357

Epoch: 6| Step: 13
Training loss: 4.139767655196807
Validation loss: 3.137867114543823

Epoch: 40| Step: 0
Training loss: 2.997438608897825
Validation loss: 3.1354821747170494

Epoch: 6| Step: 1
Training loss: 3.400379126111373
Validation loss: 3.1343260429170083

Epoch: 6| Step: 2
Training loss: 3.967390293078041
Validation loss: 3.1341171217945174

Epoch: 6| Step: 3
Training loss: 2.893138885233982
Validation loss: 3.1342564580743772

Epoch: 6| Step: 4
Training loss: 2.447163037024516
Validation loss: 3.132904037485634

Epoch: 6| Step: 5
Training loss: 3.1025273818437658
Validation loss: 3.1336889445680662

Epoch: 6| Step: 6
Training loss: 3.1376757082429116
Validation loss: 3.1321428763884946

Epoch: 6| Step: 7
Training loss: 3.157796650751913
Validation loss: 3.131580513871512

Epoch: 6| Step: 8
Training loss: 4.046640278846974
Validation loss: 3.131087451704827

Epoch: 6| Step: 9
Training loss: 3.47923220879195
Validation loss: 3.1303299715804327

Epoch: 6| Step: 10
Training loss: 3.519006755669525
Validation loss: 3.1304052141965273

Epoch: 6| Step: 11
Training loss: 3.7939062246619013
Validation loss: 3.1311596778531543

Epoch: 6| Step: 12
Training loss: 3.320792273471402
Validation loss: 3.1323183787176374

Epoch: 6| Step: 13
Training loss: 4.174444771583519
Validation loss: 3.130076618435602

Epoch: 41| Step: 0
Training loss: 3.016447281280518
Validation loss: 3.129139527301662

Epoch: 6| Step: 1
Training loss: 2.9849557361483834
Validation loss: 3.1274439453458975

Epoch: 6| Step: 2
Training loss: 3.850897493656879
Validation loss: 3.1285752138780185

Epoch: 6| Step: 3
Training loss: 2.5926028552937104
Validation loss: 3.126618628566332

Epoch: 6| Step: 4
Training loss: 3.5396648509110156
Validation loss: 3.126391849451519

Epoch: 6| Step: 5
Training loss: 3.958743599494118
Validation loss: 3.1255100957827864

Epoch: 6| Step: 6
Training loss: 3.0760221317720338
Validation loss: 3.1244858850043826

Epoch: 6| Step: 7
Training loss: 3.7858640404665813
Validation loss: 3.124225513919568

Epoch: 6| Step: 8
Training loss: 3.9958148758309138
Validation loss: 3.123819814987931

Epoch: 6| Step: 9
Training loss: 4.073641947424972
Validation loss: 3.123229542934305

Epoch: 6| Step: 10
Training loss: 3.535656905155895
Validation loss: 3.121872458723336

Epoch: 6| Step: 11
Training loss: 3.1756690874738833
Validation loss: 3.122317699123339

Epoch: 6| Step: 12
Training loss: 2.6424503676157287
Validation loss: 3.1232925672706644

Epoch: 6| Step: 13
Training loss: 1.7407023167859754
Validation loss: 3.1269277193045637

Epoch: 42| Step: 0
Training loss: 3.8190474024465564
Validation loss: 3.125290669694881

Epoch: 6| Step: 1
Training loss: 3.6843911983531883
Validation loss: 3.122142044371319

Epoch: 6| Step: 2
Training loss: 3.0586108990379715
Validation loss: 3.1215496310143482

Epoch: 6| Step: 3
Training loss: 2.736685163905474
Validation loss: 3.120234694216312

Epoch: 6| Step: 4
Training loss: 2.836963142325019
Validation loss: 3.1194301435953724

Epoch: 6| Step: 5
Training loss: 3.883807724449129
Validation loss: 3.1195415168028413

Epoch: 6| Step: 6
Training loss: 3.4866971202660664
Validation loss: 3.1191379628450795

Epoch: 6| Step: 7
Training loss: 3.076034998194856
Validation loss: 3.1179619106109047

Epoch: 6| Step: 8
Training loss: 3.4016048009973128
Validation loss: 3.1174251558221098

Epoch: 6| Step: 9
Training loss: 3.6300295435015864
Validation loss: 3.1166127227261406

Epoch: 6| Step: 10
Training loss: 3.4825779681436018
Validation loss: 3.1151733733983646

Epoch: 6| Step: 11
Training loss: 2.9060975721850872
Validation loss: 3.1158104021088606

Epoch: 6| Step: 12
Training loss: 3.638293129359096
Validation loss: 3.116302506885097

Epoch: 6| Step: 13
Training loss: 3.4041223442961805
Validation loss: 3.1161901154303244

Epoch: 43| Step: 0
Training loss: 4.546632111344418
Validation loss: 3.1177855598553474

Epoch: 6| Step: 1
Training loss: 3.5665268475468483
Validation loss: 3.1113042594451095

Epoch: 6| Step: 2
Training loss: 3.1072326640913754
Validation loss: 3.114347941140984

Epoch: 6| Step: 3
Training loss: 3.352334953870859
Validation loss: 3.1133067719961804

Epoch: 6| Step: 4
Training loss: 3.433683183739995
Validation loss: 3.111822418220831

Epoch: 6| Step: 5
Training loss: 3.842123540382395
Validation loss: 3.110750071268258

Epoch: 6| Step: 6
Training loss: 3.214669168397217
Validation loss: 3.110423844857658

Epoch: 6| Step: 7
Training loss: 2.1320079361873447
Validation loss: 3.1108885455714157

Epoch: 6| Step: 8
Training loss: 3.4592658627876873
Validation loss: 3.109207622895651

Epoch: 6| Step: 9
Training loss: 3.614976112212931
Validation loss: 3.1099773468093637

Epoch: 6| Step: 10
Training loss: 2.634021334365494
Validation loss: 3.1080793374338676

Epoch: 6| Step: 11
Training loss: 3.5919750308419993
Validation loss: 3.1074421882229717

Epoch: 6| Step: 12
Training loss: 3.221325334786386
Validation loss: 3.109090497592896

Epoch: 6| Step: 13
Training loss: 2.4732668154461144
Validation loss: 3.109317724803457

Epoch: 44| Step: 0
Training loss: 3.0138531949868788
Validation loss: 3.1077210719987916

Epoch: 6| Step: 1
Training loss: 3.769920336946635
Validation loss: 3.1096262161217965

Epoch: 6| Step: 2
Training loss: 2.567555534557075
Validation loss: 3.1123284440678187

Epoch: 6| Step: 3
Training loss: 3.231230160561903
Validation loss: 3.1081552151990914

Epoch: 6| Step: 4
Training loss: 2.7718270797629896
Validation loss: 3.1066959238221705

Epoch: 6| Step: 5
Training loss: 3.5646599362092632
Validation loss: 3.1048032662976626

Epoch: 6| Step: 6
Training loss: 3.853600015310739
Validation loss: 3.1053212533312875

Epoch: 6| Step: 7
Training loss: 3.4176657231744194
Validation loss: 3.115012653155067

Epoch: 6| Step: 8
Training loss: 3.494065703457175
Validation loss: 3.1082605186862544

Epoch: 6| Step: 9
Training loss: 3.96779975628885
Validation loss: 3.105872557138788

Epoch: 6| Step: 10
Training loss: 3.1163425304203547
Validation loss: 3.105286627343751

Epoch: 6| Step: 11
Training loss: 3.1710624969588883
Validation loss: 3.105755669260158

Epoch: 6| Step: 12
Training loss: 3.80116889443093
Validation loss: 3.1063392410272934

Epoch: 6| Step: 13
Training loss: 2.8710239946883362
Validation loss: 3.104265869784206

Epoch: 45| Step: 0
Training loss: 3.230786087704792
Validation loss: 3.103351941705912

Epoch: 6| Step: 1
Training loss: 3.5518018474896045
Validation loss: 3.101678238324134

Epoch: 6| Step: 2
Training loss: 3.138762116099269
Validation loss: 3.103602754903985

Epoch: 6| Step: 3
Training loss: 3.2549620675075595
Validation loss: 3.102368569803217

Epoch: 6| Step: 4
Training loss: 4.152367176409693
Validation loss: 3.100586980952432

Epoch: 6| Step: 5
Training loss: 3.564593854242461
Validation loss: 3.099214823693797

Epoch: 6| Step: 6
Training loss: 3.4355452094580956
Validation loss: 3.099987579582809

Epoch: 6| Step: 7
Training loss: 3.8675375423569616
Validation loss: 3.0998354686537004

Epoch: 6| Step: 8
Training loss: 3.551592005125874
Validation loss: 3.099149604837773

Epoch: 6| Step: 9
Training loss: 3.1343384638869445
Validation loss: 3.101265235897809

Epoch: 6| Step: 10
Training loss: 3.235035557028209
Validation loss: 3.1013344756080135

Epoch: 6| Step: 11
Training loss: 2.9922314832358103
Validation loss: 3.0985764548508468

Epoch: 6| Step: 12
Training loss: 3.0495792223735907
Validation loss: 3.099236251158891

Epoch: 6| Step: 13
Training loss: 2.051338396230819
Validation loss: 3.0995681015260668

Epoch: 46| Step: 0
Training loss: 3.435477199140671
Validation loss: 3.0969301834670815

Epoch: 6| Step: 1
Training loss: 3.165600664171405
Validation loss: 3.0962539323100056

Epoch: 6| Step: 2
Training loss: 2.8155393496408854
Validation loss: 3.097038002617178

Epoch: 6| Step: 3
Training loss: 3.29161063681773
Validation loss: 3.096027307165727

Epoch: 6| Step: 4
Training loss: 3.5248724136529734
Validation loss: 3.098082631693746

Epoch: 6| Step: 5
Training loss: 3.730661628889709
Validation loss: 3.096943751916842

Epoch: 6| Step: 6
Training loss: 3.7882189883423707
Validation loss: 3.0953590531814688

Epoch: 6| Step: 7
Training loss: 2.541169779834686
Validation loss: 3.0937317629836283

Epoch: 6| Step: 8
Training loss: 3.5101559294057973
Validation loss: 3.0937929354518503

Epoch: 6| Step: 9
Training loss: 3.6374883277941756
Validation loss: 3.0915792437315823

Epoch: 6| Step: 10
Training loss: 2.741688653071249
Validation loss: 3.0921301903533096

Epoch: 6| Step: 11
Training loss: 3.0596189376322775
Validation loss: 3.0916667498308916

Epoch: 6| Step: 12
Training loss: 3.5603052707043914
Validation loss: 3.090107189811855

Epoch: 6| Step: 13
Training loss: 4.297924010800133
Validation loss: 3.090170046796729

Epoch: 47| Step: 0
Training loss: 2.673407934706479
Validation loss: 3.0904577327213367

Epoch: 6| Step: 1
Training loss: 3.2667327900117407
Validation loss: 3.0908822442792188

Epoch: 6| Step: 2
Training loss: 3.6052470857171866
Validation loss: 3.0895888492790364

Epoch: 6| Step: 3
Training loss: 3.5223082363110234
Validation loss: 3.08867891829085

Epoch: 6| Step: 4
Training loss: 2.7703026476070045
Validation loss: 3.0883885083318208

Epoch: 6| Step: 5
Training loss: 4.097772849345008
Validation loss: 3.0888357741300094

Epoch: 6| Step: 6
Training loss: 2.6737057843861507
Validation loss: 3.0896077314121873

Epoch: 6| Step: 7
Training loss: 3.0483482515927016
Validation loss: 3.088017216607714

Epoch: 6| Step: 8
Training loss: 3.15301105758417
Validation loss: 3.0884475968981637

Epoch: 6| Step: 9
Training loss: 4.073363348750915
Validation loss: 3.087239046341939

Epoch: 6| Step: 10
Training loss: 3.4385894436171602
Validation loss: 3.0883200832492865

Epoch: 6| Step: 11
Training loss: 3.193552889778789
Validation loss: 3.0884050270800527

Epoch: 6| Step: 12
Training loss: 3.164574701742355
Validation loss: 3.08761081358031

Epoch: 6| Step: 13
Training loss: 4.231316957831431
Validation loss: 3.0862366101069396

Epoch: 48| Step: 0
Training loss: 3.2593811795842664
Validation loss: 3.086166015737462

Epoch: 6| Step: 1
Training loss: 3.1743642876450506
Validation loss: 3.085962565268211

Epoch: 6| Step: 2
Training loss: 2.808509708680467
Validation loss: 3.085061280609245

Epoch: 6| Step: 3
Training loss: 2.922076050068309
Validation loss: 3.0849174145832285

Epoch: 6| Step: 4
Training loss: 3.383596140108253
Validation loss: 3.084665535031215

Epoch: 6| Step: 5
Training loss: 2.8927528591298475
Validation loss: 3.085098661426413

Epoch: 6| Step: 6
Training loss: 3.2012447141747438
Validation loss: 3.085473546429617

Epoch: 6| Step: 7
Training loss: 4.372734137014027
Validation loss: 3.084496335033274

Epoch: 6| Step: 8
Training loss: 3.2327416760230756
Validation loss: 3.083883755772759

Epoch: 6| Step: 9
Training loss: 3.7335842684018545
Validation loss: 3.0827401052523102

Epoch: 6| Step: 10
Training loss: 2.800439023613188
Validation loss: 3.0841002260270853

Epoch: 6| Step: 11
Training loss: 4.061748259023168
Validation loss: 3.082477659265548

Epoch: 6| Step: 12
Training loss: 2.7462027081813547
Validation loss: 3.0826805496856275

Epoch: 6| Step: 13
Training loss: 4.162077754601849
Validation loss: 3.080960439614686

Epoch: 49| Step: 0
Training loss: 2.814676586971513
Validation loss: 3.081128990091655

Epoch: 6| Step: 1
Training loss: 3.1685501487053727
Validation loss: 3.0803859517672914

Epoch: 6| Step: 2
Training loss: 3.4919665648617406
Validation loss: 3.0784860693502787

Epoch: 6| Step: 3
Training loss: 3.6446804003845474
Validation loss: 3.079221874938097

Epoch: 6| Step: 4
Training loss: 3.598991088423702
Validation loss: 3.07871241690664

Epoch: 6| Step: 5
Training loss: 3.530960341194915
Validation loss: 3.078408007086122

Epoch: 6| Step: 6
Training loss: 3.1316582510691133
Validation loss: 3.0786080205004116

Epoch: 6| Step: 7
Training loss: 2.968134444818754
Validation loss: 3.077826299354358

Epoch: 6| Step: 8
Training loss: 3.3596903808172645
Validation loss: 3.0759746485553996

Epoch: 6| Step: 9
Training loss: 3.6171024716231317
Validation loss: 3.0762555617176814

Epoch: 6| Step: 10
Training loss: 2.5486663883969753
Validation loss: 3.075376861393045

Epoch: 6| Step: 11
Training loss: 3.8567790208000257
Validation loss: 3.0763846179262115

Epoch: 6| Step: 12
Training loss: 3.7917933739810765
Validation loss: 3.075482596167631

Epoch: 6| Step: 13
Training loss: 2.7512623750511453
Validation loss: 3.0753670998968645

Epoch: 50| Step: 0
Training loss: 3.0922539686988184
Validation loss: 3.0748661076471877

Epoch: 6| Step: 1
Training loss: 2.696894526935843
Validation loss: 3.0734401690086255

Epoch: 6| Step: 2
Training loss: 2.4555539297536737
Validation loss: 3.072834365991237

Epoch: 6| Step: 3
Training loss: 4.382221474465837
Validation loss: 3.071547663633119

Epoch: 6| Step: 4
Training loss: 3.6129444522087653
Validation loss: 3.0709373199274137

Epoch: 6| Step: 5
Training loss: 3.226445452250457
Validation loss: 3.0711454102808413

Epoch: 6| Step: 6
Training loss: 3.3186407211329634
Validation loss: 3.071169163853552

Epoch: 6| Step: 7
Training loss: 3.5411261800602234
Validation loss: 3.068683266207018

Epoch: 6| Step: 8
Training loss: 2.8408214874632325
Validation loss: 3.070084018383964

Epoch: 6| Step: 9
Training loss: 3.399364546689434
Validation loss: 3.0693852498367233

Epoch: 6| Step: 10
Training loss: 3.8791251836266616
Validation loss: 3.069201360235366

Epoch: 6| Step: 11
Training loss: 2.964881705743542
Validation loss: 3.0679671989645128

Epoch: 6| Step: 12
Training loss: 2.858930376014334
Validation loss: 3.068952567197437

Epoch: 6| Step: 13
Training loss: 4.357699602100121
Validation loss: 3.067095113690639

Epoch: 51| Step: 0
Training loss: 3.509190753777703
Validation loss: 3.067920348993829

Epoch: 6| Step: 1
Training loss: 3.9666995060520374
Validation loss: 3.0675447249289203

Epoch: 6| Step: 2
Training loss: 3.68698840714265
Validation loss: 3.06737117849554

Epoch: 6| Step: 3
Training loss: 2.884592390702376
Validation loss: 3.0662981530396567

Epoch: 6| Step: 4
Training loss: 3.1144502711285997
Validation loss: 3.0655066184254873

Epoch: 6| Step: 5
Training loss: 3.6910696047718345
Validation loss: 3.0652723648966624

Epoch: 6| Step: 6
Training loss: 3.476702946601313
Validation loss: 3.064254134484976

Epoch: 6| Step: 7
Training loss: 2.458603493883615
Validation loss: 3.065178040725321

Epoch: 6| Step: 8
Training loss: 3.721353212769771
Validation loss: 3.066536074350516

Epoch: 6| Step: 9
Training loss: 3.0116627016307045
Validation loss: 3.065530492628673

Epoch: 6| Step: 10
Training loss: 3.8305963752113996
Validation loss: 3.0679250552480153

Epoch: 6| Step: 11
Training loss: 3.032187090876344
Validation loss: 3.070456606986227

Epoch: 6| Step: 12
Training loss: 2.850050099250416
Validation loss: 3.0704345478472903

Epoch: 6| Step: 13
Training loss: 2.925963779353042
Validation loss: 3.064448206779758

Epoch: 52| Step: 0
Training loss: 3.537256853893288
Validation loss: 3.06316837888553

Epoch: 6| Step: 1
Training loss: 3.115338305231469
Validation loss: 3.059391157343552

Epoch: 6| Step: 2
Training loss: 2.9354723161377345
Validation loss: 3.060112775112791

Epoch: 6| Step: 3
Training loss: 2.9584857382044585
Validation loss: 3.0610704934288546

Epoch: 6| Step: 4
Training loss: 3.5581772662085953
Validation loss: 3.060896951371589

Epoch: 6| Step: 5
Training loss: 2.7500832284990713
Validation loss: 3.06141776743035

Epoch: 6| Step: 6
Training loss: 3.6364116600506797
Validation loss: 3.059558645436778

Epoch: 6| Step: 7
Training loss: 3.1639600195595223
Validation loss: 3.0600797252951377

Epoch: 6| Step: 8
Training loss: 3.127418650202632
Validation loss: 3.0597530189058495

Epoch: 6| Step: 9
Training loss: 2.9981842904175586
Validation loss: 3.0583182240279703

Epoch: 6| Step: 10
Training loss: 3.771167016764832
Validation loss: 3.057840968385938

Epoch: 6| Step: 11
Training loss: 4.045237795485141
Validation loss: 3.0575410524875832

Epoch: 6| Step: 12
Training loss: 3.2673484233556254
Validation loss: 3.05821965744461

Epoch: 6| Step: 13
Training loss: 3.638432575246415
Validation loss: 3.0573492560270163

Epoch: 53| Step: 0
Training loss: 3.4840079486287627
Validation loss: 3.0577584519811567

Epoch: 6| Step: 1
Training loss: 3.5470750391002177
Validation loss: 3.0583665572425556

Epoch: 6| Step: 2
Training loss: 3.314321916598583
Validation loss: 3.0553773259983905

Epoch: 6| Step: 3
Training loss: 3.0932357823128305
Validation loss: 3.055809497877264

Epoch: 6| Step: 4
Training loss: 4.4021232163872765
Validation loss: 3.055381600159933

Epoch: 6| Step: 5
Training loss: 3.2154768810505856
Validation loss: 3.0550705843373978

Epoch: 6| Step: 6
Training loss: 2.8706220382053904
Validation loss: 3.0546548195047434

Epoch: 6| Step: 7
Training loss: 3.6499571810784377
Validation loss: 3.0540533352461705

Epoch: 6| Step: 8
Training loss: 2.911259753029498
Validation loss: 3.0531302743798316

Epoch: 6| Step: 9
Training loss: 3.151372937320444
Validation loss: 3.0521195173752282

Epoch: 6| Step: 10
Training loss: 3.1372317682025717
Validation loss: 3.054579003437734

Epoch: 6| Step: 11
Training loss: 2.674321175836193
Validation loss: 3.0542953160144197

Epoch: 6| Step: 12
Training loss: 3.1031365616228634
Validation loss: 3.052105692537589

Epoch: 6| Step: 13
Training loss: 3.9241723858514925
Validation loss: 3.0533124383627976

Epoch: 54| Step: 0
Training loss: 3.0008899640226523
Validation loss: 3.051037072148648

Epoch: 6| Step: 1
Training loss: 3.4045583741630128
Validation loss: 3.052689328598517

Epoch: 6| Step: 2
Training loss: 2.7648276348781557
Validation loss: 3.0517193781181904

Epoch: 6| Step: 3
Training loss: 3.538602213790271
Validation loss: 3.0540782592729605

Epoch: 6| Step: 4
Training loss: 3.40124395838898
Validation loss: 3.0504534233544733

Epoch: 6| Step: 5
Training loss: 3.5969216324660924
Validation loss: 3.0554323845279376

Epoch: 6| Step: 6
Training loss: 3.319240118643115
Validation loss: 3.0488769298629532

Epoch: 6| Step: 7
Training loss: 3.535061290161079
Validation loss: 3.0474974933215453

Epoch: 6| Step: 8
Training loss: 3.7002370655304624
Validation loss: 3.045805716063578

Epoch: 6| Step: 9
Training loss: 2.7212397257760297
Validation loss: 3.046056996382515

Epoch: 6| Step: 10
Training loss: 2.9064511465379756
Validation loss: 3.0453445903210916

Epoch: 6| Step: 11
Training loss: 3.767128545299011
Validation loss: 3.0442443395688614

Epoch: 6| Step: 12
Training loss: 3.5793492251028174
Validation loss: 3.0489301685003385

Epoch: 6| Step: 13
Training loss: 2.895660633087752
Validation loss: 3.0473420118887264

Epoch: 55| Step: 0
Training loss: 3.3435021424455655
Validation loss: 3.0489971535541383

Epoch: 6| Step: 1
Training loss: 3.818969989939384
Validation loss: 3.0454558393866598

Epoch: 6| Step: 2
Training loss: 2.978438139360964
Validation loss: 3.046089163998376

Epoch: 6| Step: 3
Training loss: 2.8689385246213694
Validation loss: 3.0450772459575455

Epoch: 6| Step: 4
Training loss: 3.0804078597480338
Validation loss: 3.0448300744039387

Epoch: 6| Step: 5
Training loss: 3.89063799139711
Validation loss: 3.0458250446952255

Epoch: 6| Step: 6
Training loss: 3.622801015074416
Validation loss: 3.0485901453250603

Epoch: 6| Step: 7
Training loss: 3.21311917405193
Validation loss: 3.050398548095713

Epoch: 6| Step: 8
Training loss: 3.001882280495381
Validation loss: 3.0510715214544257

Epoch: 6| Step: 9
Training loss: 3.5649765508236326
Validation loss: 3.0501861359464097

Epoch: 6| Step: 10
Training loss: 2.8816133812000073
Validation loss: 3.0489726790310865

Epoch: 6| Step: 11
Training loss: 3.168255022804567
Validation loss: 3.049825184420164

Epoch: 6| Step: 12
Training loss: 3.2720723002497247
Validation loss: 3.0421906926044233

Epoch: 6| Step: 13
Training loss: 3.7162546713524134
Validation loss: 3.043007016048299

Epoch: 56| Step: 0
Training loss: 3.153822163388616
Validation loss: 3.0401261370555135

Epoch: 6| Step: 1
Training loss: 3.4504602429330387
Validation loss: 3.0398540959510125

Epoch: 6| Step: 2
Training loss: 3.8449388851869615
Validation loss: 3.0403312803370106

Epoch: 6| Step: 3
Training loss: 3.2932563194608684
Validation loss: 3.0380099610993274

Epoch: 6| Step: 4
Training loss: 2.964902935015327
Validation loss: 3.0391876965088302

Epoch: 6| Step: 5
Training loss: 3.6613563027778535
Validation loss: 3.038177030561304

Epoch: 6| Step: 6
Training loss: 2.737865552489439
Validation loss: 3.03986807011765

Epoch: 6| Step: 7
Training loss: 3.659272338573827
Validation loss: 3.0385494084275604

Epoch: 6| Step: 8
Training loss: 3.641878493467573
Validation loss: 3.038472394019906

Epoch: 6| Step: 9
Training loss: 3.4537880377481742
Validation loss: 3.0382447783739

Epoch: 6| Step: 10
Training loss: 2.5982825879355
Validation loss: 3.0355929678168496

Epoch: 6| Step: 11
Training loss: 3.289449854714263
Validation loss: 3.038202784341752

Epoch: 6| Step: 12
Training loss: 2.818069199859676
Validation loss: 3.036718302769132

Epoch: 6| Step: 13
Training loss: 3.694928978016748
Validation loss: 3.0372134480448487

Epoch: 57| Step: 0
Training loss: 3.2253241206091827
Validation loss: 3.0356045834208563

Epoch: 6| Step: 1
Training loss: 3.1626389303336713
Validation loss: 3.036702558133959

Epoch: 6| Step: 2
Training loss: 2.635224728637458
Validation loss: 3.037278787307426

Epoch: 6| Step: 3
Training loss: 4.313269283953131
Validation loss: 3.0359771678804837

Epoch: 6| Step: 4
Training loss: 3.334305017625341
Validation loss: 3.0360136145290624

Epoch: 6| Step: 5
Training loss: 3.4466566720469594
Validation loss: 3.0350395274476716

Epoch: 6| Step: 6
Training loss: 3.024327346795272
Validation loss: 3.035473054418465

Epoch: 6| Step: 7
Training loss: 3.8595847872037035
Validation loss: 3.034510981331942

Epoch: 6| Step: 8
Training loss: 3.285017629776421
Validation loss: 3.035045166533696

Epoch: 6| Step: 9
Training loss: 2.360615991277778
Validation loss: 3.032082897728391

Epoch: 6| Step: 10
Training loss: 3.623424055922531
Validation loss: 3.0331328075468673

Epoch: 6| Step: 11
Training loss: 3.062131587075804
Validation loss: 3.032248933414438

Epoch: 6| Step: 12
Training loss: 3.5430544808139928
Validation loss: 3.0302618437612825

Epoch: 6| Step: 13
Training loss: 2.667988767311437
Validation loss: 3.031842610962984

Epoch: 58| Step: 0
Training loss: 3.3290942576096887
Validation loss: 3.029851091883811

Epoch: 6| Step: 1
Training loss: 2.707978582379209
Validation loss: 3.0473647412653793

Epoch: 6| Step: 2
Training loss: 3.9456146426694114
Validation loss: 3.087478710989782

Epoch: 6| Step: 3
Training loss: 3.3729964066414757
Validation loss: 3.042411363819374

Epoch: 6| Step: 4
Training loss: 2.4887897923965583
Validation loss: 3.0294594956465297

Epoch: 6| Step: 5
Training loss: 2.7438416450506056
Validation loss: 3.029457815019434

Epoch: 6| Step: 6
Training loss: 3.407806600769338
Validation loss: 3.0286784680250523

Epoch: 6| Step: 7
Training loss: 2.978486968355998
Validation loss: 3.030899137491491

Epoch: 6| Step: 8
Training loss: 3.3063413841728213
Validation loss: 3.0321521826729

Epoch: 6| Step: 9
Training loss: 4.24677333639929
Validation loss: 3.0303392859473335

Epoch: 6| Step: 10
Training loss: 3.2121140303839546
Validation loss: 3.0337835713594608

Epoch: 6| Step: 11
Training loss: 3.4028048109853493
Validation loss: 3.0325491036703682

Epoch: 6| Step: 12
Training loss: 3.0173142203572563
Validation loss: 3.033598098324365

Epoch: 6| Step: 13
Training loss: 4.007596908035403
Validation loss: 3.0323608582177917

Epoch: 59| Step: 0
Training loss: 3.5764444060887834
Validation loss: 3.030958626176381

Epoch: 6| Step: 1
Training loss: 3.109613304015902
Validation loss: 3.02991417511651

Epoch: 6| Step: 2
Training loss: 2.9360740934372416
Validation loss: 3.026084947176824

Epoch: 6| Step: 3
Training loss: 3.598655470798749
Validation loss: 3.027229266798866

Epoch: 6| Step: 4
Training loss: 2.9716028259346063
Validation loss: 3.024926680379143

Epoch: 6| Step: 5
Training loss: 3.1903990483396405
Validation loss: 3.0233957073077558

Epoch: 6| Step: 6
Training loss: 3.5643228251012964
Validation loss: 3.0237918141742934

Epoch: 6| Step: 7
Training loss: 3.6965652503734536
Validation loss: 3.0236979960027655

Epoch: 6| Step: 8
Training loss: 3.361403309825185
Validation loss: 3.022730389019233

Epoch: 6| Step: 9
Training loss: 3.36120612340331
Validation loss: 3.020293092775389

Epoch: 6| Step: 10
Training loss: 3.253583399771707
Validation loss: 3.0231215848862334

Epoch: 6| Step: 11
Training loss: 3.1973294558762726
Validation loss: 3.0217830558244554

Epoch: 6| Step: 12
Training loss: 2.7369749950567095
Validation loss: 3.023168285344355

Epoch: 6| Step: 13
Training loss: 3.5923688805423586
Validation loss: 3.022019093244749

Epoch: 60| Step: 0
Training loss: 3.088425495263715
Validation loss: 3.022012608676175

Epoch: 6| Step: 1
Training loss: 3.791288936929457
Validation loss: 3.0265896705702424

Epoch: 6| Step: 2
Training loss: 2.7626989370668165
Validation loss: 3.0240433680937238

Epoch: 6| Step: 3
Training loss: 3.464834942209775
Validation loss: 3.0206282368173865

Epoch: 6| Step: 4
Training loss: 3.431231939549677
Validation loss: 3.0209708386541063

Epoch: 6| Step: 5
Training loss: 3.5099603071440924
Validation loss: 3.0161252451415494

Epoch: 6| Step: 6
Training loss: 3.7098672387565594
Validation loss: 3.0158045143230017

Epoch: 6| Step: 7
Training loss: 4.0032278388673825
Validation loss: 3.0155626703182232

Epoch: 6| Step: 8
Training loss: 2.1134844275091043
Validation loss: 3.0151188543756238

Epoch: 6| Step: 9
Training loss: 3.0475874630250726
Validation loss: 3.016118594904966

Epoch: 6| Step: 10
Training loss: 3.1724531276357575
Validation loss: 3.0151099308639533

Epoch: 6| Step: 11
Training loss: 3.6776034209790853
Validation loss: 3.0155936363902

Epoch: 6| Step: 12
Training loss: 3.0649920853330594
Validation loss: 3.012337323831314

Epoch: 6| Step: 13
Training loss: 2.4200134013727044
Validation loss: 3.0155712651884756

Epoch: 61| Step: 0
Training loss: 2.409941875500784
Validation loss: 3.01333464453904

Epoch: 6| Step: 1
Training loss: 2.445831731203281
Validation loss: 3.014593154543466

Epoch: 6| Step: 2
Training loss: 3.724636387839577
Validation loss: 3.012676979666385

Epoch: 6| Step: 3
Training loss: 3.983458888630235
Validation loss: 3.016253548318276

Epoch: 6| Step: 4
Training loss: 3.3200890320019916
Validation loss: 3.0222710322237383

Epoch: 6| Step: 5
Training loss: 3.6299696432898796
Validation loss: 3.0312882744373226

Epoch: 6| Step: 6
Training loss: 3.562478851790984
Validation loss: 3.0314852309603895

Epoch: 6| Step: 7
Training loss: 3.7149436126988826
Validation loss: 3.0378718872105943

Epoch: 6| Step: 8
Training loss: 3.0499491515376667
Validation loss: 3.029704730273059

Epoch: 6| Step: 9
Training loss: 2.81884304662764
Validation loss: 3.014714136567118

Epoch: 6| Step: 10
Training loss: 3.2540286110978283
Validation loss: 3.0115296502493374

Epoch: 6| Step: 11
Training loss: 3.404838059393333
Validation loss: 3.0096246615905615

Epoch: 6| Step: 12
Training loss: 3.6201531465286507
Validation loss: 3.0091213899057823

Epoch: 6| Step: 13
Training loss: 1.9993888398025659
Validation loss: 3.0099867613020272

Epoch: 62| Step: 0
Training loss: 3.0829689910348788
Validation loss: 3.009390807395394

Epoch: 6| Step: 1
Training loss: 3.6514062341202553
Validation loss: 3.0073503292336907

Epoch: 6| Step: 2
Training loss: 3.3400364870374113
Validation loss: 3.007311173865892

Epoch: 6| Step: 3
Training loss: 2.9465007459379655
Validation loss: 3.009673637093906

Epoch: 6| Step: 4
Training loss: 3.4545682764896557
Validation loss: 3.0129387633828197

Epoch: 6| Step: 5
Training loss: 3.459105409284884
Validation loss: 3.024351871571075

Epoch: 6| Step: 6
Training loss: 3.4009565466393283
Validation loss: 3.0373689043964367

Epoch: 6| Step: 7
Training loss: 4.019601003859041
Validation loss: 3.046242788904314

Epoch: 6| Step: 8
Training loss: 3.6924867693561363
Validation loss: 3.008260512922892

Epoch: 6| Step: 9
Training loss: 3.027248612416389
Validation loss: 3.005633593542615

Epoch: 6| Step: 10
Training loss: 2.2640788096807305
Validation loss: 3.0118717396120185

Epoch: 6| Step: 11
Training loss: 3.008521216981011
Validation loss: 3.037121996038759

Epoch: 6| Step: 12
Training loss: 3.1329440044095307
Validation loss: 3.0120515763552507

Epoch: 6| Step: 13
Training loss: 3.3760594718359225
Validation loss: 3.0360657386742136

Epoch: 63| Step: 0
Training loss: 2.4580371053205874
Validation loss: 3.0735901798228134

Epoch: 6| Step: 1
Training loss: 2.98830566396277
Validation loss: 3.096058701390846

Epoch: 6| Step: 2
Training loss: 3.9067400815616558
Validation loss: 3.1015846452299285

Epoch: 6| Step: 3
Training loss: 3.400201168840812
Validation loss: 3.0846538963978594

Epoch: 6| Step: 4
Training loss: 3.469073168847534
Validation loss: 3.0777896998102867

Epoch: 6| Step: 5
Training loss: 3.0919285816664615
Validation loss: 3.068602508394925

Epoch: 6| Step: 6
Training loss: 3.4799955069852744
Validation loss: 3.068568291825341

Epoch: 6| Step: 7
Training loss: 3.242631040820792
Validation loss: 3.0681952257548097

Epoch: 6| Step: 8
Training loss: 4.155060332556857
Validation loss: 3.068358297193721

Epoch: 6| Step: 9
Training loss: 2.882520045717782
Validation loss: 3.0687261931491703

Epoch: 6| Step: 10
Training loss: 4.037995129155797
Validation loss: 3.07693555991971

Epoch: 6| Step: 11
Training loss: 3.523244509941235
Validation loss: 3.083698688956441

Epoch: 6| Step: 12
Training loss: 2.738817366551077
Validation loss: 3.078697263413627

Epoch: 6| Step: 13
Training loss: 2.7265680963409618
Validation loss: 3.0691464250889022

Epoch: 64| Step: 0
Training loss: 2.721750029225339
Validation loss: 3.0673581787805984

Epoch: 6| Step: 1
Training loss: 3.1376132473511795
Validation loss: 3.0632561676589196

Epoch: 6| Step: 2
Training loss: 3.44852109530317
Validation loss: 3.0660685294551504

Epoch: 6| Step: 3
Training loss: 3.3922289732897695
Validation loss: 3.066451884109705

Epoch: 6| Step: 4
Training loss: 3.5873641623057457
Validation loss: 3.0684786532309074

Epoch: 6| Step: 5
Training loss: 3.5051944877876315
Validation loss: 3.0721116224094973

Epoch: 6| Step: 6
Training loss: 3.8946053240589076
Validation loss: 3.0590081791236745

Epoch: 6| Step: 7
Training loss: 3.2166550123830446
Validation loss: 3.058080384313798

Epoch: 6| Step: 8
Training loss: 2.9642444351657526
Validation loss: 3.0575622798279705

Epoch: 6| Step: 9
Training loss: 2.74807654651492
Validation loss: 3.0566706406714017

Epoch: 6| Step: 10
Training loss: 3.555575685311662
Validation loss: 3.0544529127600235

Epoch: 6| Step: 11
Training loss: 3.4159568576545185
Validation loss: 3.055035439993575

Epoch: 6| Step: 12
Training loss: 3.7443660375710373
Validation loss: 3.0550078443388884

Epoch: 6| Step: 13
Training loss: 2.8361476683702063
Validation loss: 3.05432203763031

Epoch: 65| Step: 0
Training loss: 3.7902765904858784
Validation loss: 3.05128889374558

Epoch: 6| Step: 1
Training loss: 3.0087150507673317
Validation loss: 3.0530872977732972

Epoch: 6| Step: 2
Training loss: 3.1921085626119434
Validation loss: 3.050744924315499

Epoch: 6| Step: 3
Training loss: 3.423300250325968
Validation loss: 3.051706704041124

Epoch: 6| Step: 4
Training loss: 3.1850118462598265
Validation loss: 3.050900445761102

Epoch: 6| Step: 5
Training loss: 3.166833638925616
Validation loss: 3.0479558625685277

Epoch: 6| Step: 6
Training loss: 3.61472099694322
Validation loss: 3.048217215283059

Epoch: 6| Step: 7
Training loss: 2.908310354701282
Validation loss: 3.0510641147058544

Epoch: 6| Step: 8
Training loss: 3.2939696323776086
Validation loss: 3.04650703355912

Epoch: 6| Step: 9
Training loss: 3.2279122325872835
Validation loss: 3.0466978717366517

Epoch: 6| Step: 10
Training loss: 3.1401310622446528
Validation loss: 3.0460075361483288

Epoch: 6| Step: 11
Training loss: 4.115044805345381
Validation loss: 3.045743163986522

Epoch: 6| Step: 12
Training loss: 3.1144075546078955
Validation loss: 3.0441543434846974

Epoch: 6| Step: 13
Training loss: 3.0619386430967808
Validation loss: 3.04293287867061

Epoch: 66| Step: 0
Training loss: 2.8865975030567252
Validation loss: 3.0459700088896318

Epoch: 6| Step: 1
Training loss: 2.93247247187059
Validation loss: 3.0413499404003823

Epoch: 6| Step: 2
Training loss: 3.4408472583575516
Validation loss: 3.042872269333692

Epoch: 6| Step: 3
Training loss: 3.297599242873755
Validation loss: 3.041626000452087

Epoch: 6| Step: 4
Training loss: 3.6721275729705267
Validation loss: 3.0436958852111755

Epoch: 6| Step: 5
Training loss: 3.3256477126629385
Validation loss: 3.0389839649584336

Epoch: 6| Step: 6
Training loss: 3.4610778917895892
Validation loss: 3.038804773831269

Epoch: 6| Step: 7
Training loss: 3.3877556961233513
Validation loss: 3.03810110453698

Epoch: 6| Step: 8
Training loss: 3.0165995075765903
Validation loss: 3.044175782914539

Epoch: 6| Step: 9
Training loss: 3.0416952854708774
Validation loss: 3.0544530034057766

Epoch: 6| Step: 10
Training loss: 3.267870847150668
Validation loss: 3.060394713665116

Epoch: 6| Step: 11
Training loss: 3.247289848076681
Validation loss: 3.0602872487765356

Epoch: 6| Step: 12
Training loss: 3.741113432925762
Validation loss: 3.0369646918762556

Epoch: 6| Step: 13
Training loss: 3.786709461865801
Validation loss: 3.0367217589799957

Epoch: 67| Step: 0
Training loss: 2.826984829031061
Validation loss: 3.0364658680177192

Epoch: 6| Step: 1
Training loss: 2.6897185284010527
Validation loss: 3.0338616241626783

Epoch: 6| Step: 2
Training loss: 2.8547738165038568
Validation loss: 3.0318159956279596

Epoch: 6| Step: 3
Training loss: 2.6760489002771988
Validation loss: 3.03244422465731

Epoch: 6| Step: 4
Training loss: 3.234789688136935
Validation loss: 3.013419620334084

Epoch: 6| Step: 5
Training loss: 4.3607420606566585
Validation loss: 2.9813637308269443

Epoch: 6| Step: 6
Training loss: 2.9906513464075086
Validation loss: 2.9734987060657945

Epoch: 6| Step: 7
Training loss: 3.7233332751850976
Validation loss: 2.974442904008385

Epoch: 6| Step: 8
Training loss: 3.7838047949380647
Validation loss: 2.97634834990038

Epoch: 6| Step: 9
Training loss: 3.388295863504629
Validation loss: 2.978389535081197

Epoch: 6| Step: 10
Training loss: 3.0030894266456922
Validation loss: 2.982240103652875

Epoch: 6| Step: 11
Training loss: 3.7287653843878514
Validation loss: 2.9836173469982046

Epoch: 6| Step: 12
Training loss: 3.4811450716433323
Validation loss: 2.9770760601715547

Epoch: 6| Step: 13
Training loss: 1.8944167898937068
Validation loss: 2.973951915802071

Epoch: 68| Step: 0
Training loss: 2.9606608158366714
Validation loss: 2.973277639248826

Epoch: 6| Step: 1
Training loss: 3.2723786091274047
Validation loss: 2.9709875805240884

Epoch: 6| Step: 2
Training loss: 3.9238908306027427
Validation loss: 2.9710509730521677

Epoch: 6| Step: 3
Training loss: 3.4679154775454686
Validation loss: 2.9718292570615263

Epoch: 6| Step: 4
Training loss: 2.745726298984578
Validation loss: 2.969186649043271

Epoch: 6| Step: 5
Training loss: 3.4942743607372146
Validation loss: 2.969634283950447

Epoch: 6| Step: 6
Training loss: 3.4687989377530433
Validation loss: 2.965633259274667

Epoch: 6| Step: 7
Training loss: 3.239144020508459
Validation loss: 2.9667320694534527

Epoch: 6| Step: 8
Training loss: 3.8404358012541606
Validation loss: 2.9649717561703657

Epoch: 6| Step: 9
Training loss: 2.27922135124181
Validation loss: 2.96692221850799

Epoch: 6| Step: 10
Training loss: 2.659144630719386
Validation loss: 2.9640092190931844

Epoch: 6| Step: 11
Training loss: 3.4214719770154414
Validation loss: 2.9668435089544913

Epoch: 6| Step: 12
Training loss: 3.3267036949140634
Validation loss: 2.964226698673168

Epoch: 6| Step: 13
Training loss: 3.017038755143298
Validation loss: 2.967943590847018

Epoch: 69| Step: 0
Training loss: 2.9828522477216803
Validation loss: 2.969974149289918

Epoch: 6| Step: 1
Training loss: 3.42908488130127
Validation loss: 2.9700461528185307

Epoch: 6| Step: 2
Training loss: 3.7530989240237593
Validation loss: 2.9708377994522825

Epoch: 6| Step: 3
Training loss: 3.926213634459792
Validation loss: 2.9684922214889844

Epoch: 6| Step: 4
Training loss: 3.3189450309042576
Validation loss: 2.9671108416155265

Epoch: 6| Step: 5
Training loss: 3.484733665720854
Validation loss: 2.9630534017113104

Epoch: 6| Step: 6
Training loss: 3.15402808210393
Validation loss: 2.964038659206268

Epoch: 6| Step: 7
Training loss: 3.5278961999462535
Validation loss: 2.9653314463903477

Epoch: 6| Step: 8
Training loss: 2.8098609410695388
Validation loss: 2.9657378610243965

Epoch: 6| Step: 9
Training loss: 2.893991849939223
Validation loss: 2.963142045552806

Epoch: 6| Step: 10
Training loss: 2.610083478126105
Validation loss: 2.965168668505778

Epoch: 6| Step: 11
Training loss: 2.8278734295482395
Validation loss: 2.965534554770954

Epoch: 6| Step: 12
Training loss: 3.027778446613514
Validation loss: 2.965264739645208

Epoch: 6| Step: 13
Training loss: 3.651437183820263
Validation loss: 2.9650535899965043

Epoch: 70| Step: 0
Training loss: 3.4797755791659704
Validation loss: 2.9642124656405704

Epoch: 6| Step: 1
Training loss: 3.2321368596022073
Validation loss: 2.961532248619294

Epoch: 6| Step: 2
Training loss: 3.298358890639398
Validation loss: 2.961461732199104

Epoch: 6| Step: 3
Training loss: 3.8306042175177337
Validation loss: 2.963914671954369

Epoch: 6| Step: 4
Training loss: 2.60963210249801
Validation loss: 2.964404093415932

Epoch: 6| Step: 5
Training loss: 2.3403919832289533
Validation loss: 2.9658770327016795

Epoch: 6| Step: 6
Training loss: 2.792993590771307
Validation loss: 2.973604714017227

Epoch: 6| Step: 7
Training loss: 2.8511992758821707
Validation loss: 2.97137856038234

Epoch: 6| Step: 8
Training loss: 3.746325409123575
Validation loss: 2.9784139802031024

Epoch: 6| Step: 9
Training loss: 3.797376560316968
Validation loss: 2.974551157063538

Epoch: 6| Step: 10
Training loss: 3.34763431430605
Validation loss: 2.9645538778518428

Epoch: 6| Step: 11
Training loss: 3.1012088756609923
Validation loss: 2.960291189636315

Epoch: 6| Step: 12
Training loss: 3.1592230061268873
Validation loss: 2.961605976562795

Epoch: 6| Step: 13
Training loss: 3.6939435362742254
Validation loss: 2.96159575264643

Epoch: 71| Step: 0
Training loss: 3.5804891313958693
Validation loss: 2.964767032882202

Epoch: 6| Step: 1
Training loss: 2.74900531119135
Validation loss: 2.959450152311225

Epoch: 6| Step: 2
Training loss: 2.3973718319744703
Validation loss: 2.9593399867877865

Epoch: 6| Step: 3
Training loss: 3.4809263123403458
Validation loss: 2.9606739532650517

Epoch: 6| Step: 4
Training loss: 3.803010230107557
Validation loss: 2.958187424352941

Epoch: 6| Step: 5
Training loss: 3.7226834051016398
Validation loss: 2.9566383243266934

Epoch: 6| Step: 6
Training loss: 2.433231822818504
Validation loss: 2.9566633420671806

Epoch: 6| Step: 7
Training loss: 3.1943754953508288
Validation loss: 2.9564307572715562

Epoch: 6| Step: 8
Training loss: 3.7811646254808573
Validation loss: 2.954216291829807

Epoch: 6| Step: 9
Training loss: 2.7380697519683985
Validation loss: 2.9564031560628554

Epoch: 6| Step: 10
Training loss: 3.7287688371653753
Validation loss: 2.954567314768118

Epoch: 6| Step: 11
Training loss: 3.3325680013073105
Validation loss: 2.9531518080176524

Epoch: 6| Step: 12
Training loss: 3.126762808465073
Validation loss: 2.951861635035413

Epoch: 6| Step: 13
Training loss: 2.5780502770894853
Validation loss: 2.955054409903935

Epoch: 72| Step: 0
Training loss: 2.767656000800954
Validation loss: 2.9546548770055754

Epoch: 6| Step: 1
Training loss: 3.3170274707575538
Validation loss: 2.95495402811718

Epoch: 6| Step: 2
Training loss: 3.1231146656573068
Validation loss: 2.9563789339038844

Epoch: 6| Step: 3
Training loss: 2.904374204323161
Validation loss: 2.95665540054209

Epoch: 6| Step: 4
Training loss: 2.911518858324282
Validation loss: 2.9604429530652756

Epoch: 6| Step: 5
Training loss: 3.061911390142436
Validation loss: 2.960674010414296

Epoch: 6| Step: 6
Training loss: 3.4360501092669695
Validation loss: 2.9541205712587124

Epoch: 6| Step: 7
Training loss: 3.0685289167334875
Validation loss: 2.9565035606184376

Epoch: 6| Step: 8
Training loss: 3.978177625093791
Validation loss: 2.9516085101231155

Epoch: 6| Step: 9
Training loss: 3.1555661508743476
Validation loss: 2.954087045502187

Epoch: 6| Step: 10
Training loss: 3.533777463338685
Validation loss: 2.9536478118372265

Epoch: 6| Step: 11
Training loss: 2.6909787927909674
Validation loss: 2.9491564024699812

Epoch: 6| Step: 12
Training loss: 3.74063224568697
Validation loss: 2.9477303561768053

Epoch: 6| Step: 13
Training loss: 3.477888698725164
Validation loss: 2.9502923195963042

Epoch: 73| Step: 0
Training loss: 3.721333864270998
Validation loss: 2.9484938415910316

Epoch: 6| Step: 1
Training loss: 2.5302459232390575
Validation loss: 2.948342484776874

Epoch: 6| Step: 2
Training loss: 3.00211672811754
Validation loss: 2.948659179731672

Epoch: 6| Step: 3
Training loss: 3.2605966796581054
Validation loss: 2.9490453151750753

Epoch: 6| Step: 4
Training loss: 3.4092340959476046
Validation loss: 2.9500931160067436

Epoch: 6| Step: 5
Training loss: 2.825582467855753
Validation loss: 2.9500368996480293

Epoch: 6| Step: 6
Training loss: 3.4544815919987197
Validation loss: 2.9536520405229165

Epoch: 6| Step: 7
Training loss: 3.4728363985893704
Validation loss: 2.9526953405530993

Epoch: 6| Step: 8
Training loss: 3.7171360648895195
Validation loss: 2.9582225675411897

Epoch: 6| Step: 9
Training loss: 3.5747323422837867
Validation loss: 2.966500957663835

Epoch: 6| Step: 10
Training loss: 3.5759195919000155
Validation loss: 2.959065560889147

Epoch: 6| Step: 11
Training loss: 2.2801673096622737
Validation loss: 2.9470858659661454

Epoch: 6| Step: 12
Training loss: 2.384505774035255
Validation loss: 2.9445285671592596

Epoch: 6| Step: 13
Training loss: 3.8505764021962205
Validation loss: 2.9424433223054067

Epoch: 74| Step: 0
Training loss: 3.425585820573078
Validation loss: 2.9406594378319517

Epoch: 6| Step: 1
Training loss: 3.344715727628436
Validation loss: 2.9412342581178152

Epoch: 6| Step: 2
Training loss: 3.3093948205168817
Validation loss: 2.9431979619360256

Epoch: 6| Step: 3
Training loss: 2.6332882414550536
Validation loss: 2.940163822946352

Epoch: 6| Step: 4
Training loss: 3.392428854390979
Validation loss: 2.941867753542997

Epoch: 6| Step: 5
Training loss: 3.3354966455258883
Validation loss: 2.9387672534166644

Epoch: 6| Step: 6
Training loss: 2.784926652473232
Validation loss: 2.941003431698671

Epoch: 6| Step: 7
Training loss: 3.0615801305556234
Validation loss: 2.9425506929990104

Epoch: 6| Step: 8
Training loss: 2.2080499239267066
Validation loss: 2.9412496596150954

Epoch: 6| Step: 9
Training loss: 3.4441544366252215
Validation loss: 2.948813629196265

Epoch: 6| Step: 10
Training loss: 3.2785629169057993
Validation loss: 2.9527437435252586

Epoch: 6| Step: 11
Training loss: 3.2389770790977974
Validation loss: 2.9536435024253223

Epoch: 6| Step: 12
Training loss: 3.8879900362805455
Validation loss: 2.9716903313596488

Epoch: 6| Step: 13
Training loss: 3.8799625737066403
Validation loss: 2.9563086856588887

Epoch: 75| Step: 0
Training loss: 3.663849716677654
Validation loss: 2.9420298338728594

Epoch: 6| Step: 1
Training loss: 2.925349001156008
Validation loss: 2.941793620675264

Epoch: 6| Step: 2
Training loss: 2.7996347972577347
Validation loss: 2.943509530083351

Epoch: 6| Step: 3
Training loss: 3.6701055930431914
Validation loss: 2.9438328357045527

Epoch: 6| Step: 4
Training loss: 2.5767796560816163
Validation loss: 2.9483415665643706

Epoch: 6| Step: 5
Training loss: 2.441337499031973
Validation loss: 2.9548594801492

Epoch: 6| Step: 6
Training loss: 3.1534376550828824
Validation loss: 2.981522441397722

Epoch: 6| Step: 7
Training loss: 3.4099831378777155
Validation loss: 2.9538908576993355

Epoch: 6| Step: 8
Training loss: 3.41987976710585
Validation loss: 2.9444302974997503

Epoch: 6| Step: 9
Training loss: 3.277218912904749
Validation loss: 2.940132696337989

Epoch: 6| Step: 10
Training loss: 3.1901056447966387
Validation loss: 2.9419780844773684

Epoch: 6| Step: 11
Training loss: 4.351367007783391
Validation loss: 2.9371823793901286

Epoch: 6| Step: 12
Training loss: 2.68970221845966
Validation loss: 2.9377809807753517

Epoch: 6| Step: 13
Training loss: 3.147214135966435
Validation loss: 2.9341945373544385

Epoch: 76| Step: 0
Training loss: 3.3366452612048967
Validation loss: 2.9358914312231774

Epoch: 6| Step: 1
Training loss: 3.7626472824520176
Validation loss: 2.9374620709646555

Epoch: 6| Step: 2
Training loss: 2.594762213953419
Validation loss: 2.937357873561255

Epoch: 6| Step: 3
Training loss: 2.4250119474450975
Validation loss: 2.93936071763352

Epoch: 6| Step: 4
Training loss: 3.3032509136471515
Validation loss: 2.9424205177913803

Epoch: 6| Step: 5
Training loss: 4.065259964291399
Validation loss: 2.946777664338023

Epoch: 6| Step: 6
Training loss: 1.9275886766590733
Validation loss: 2.94074901823063

Epoch: 6| Step: 7
Training loss: 3.993953187457088
Validation loss: 2.937707856556074

Epoch: 6| Step: 8
Training loss: 3.0383051931389766
Validation loss: 2.9341821393566203

Epoch: 6| Step: 9
Training loss: 3.2380328295941943
Validation loss: 2.934650438872031

Epoch: 6| Step: 10
Training loss: 3.908867165249283
Validation loss: 2.9338161520255865

Epoch: 6| Step: 11
Training loss: 3.1058602716048576
Validation loss: 2.934273325886851

Epoch: 6| Step: 12
Training loss: 3.0795879469854035
Validation loss: 2.9348132872933546

Epoch: 6| Step: 13
Training loss: 1.9342199063099252
Validation loss: 2.9323679546653585

Epoch: 77| Step: 0
Training loss: 3.820198915505359
Validation loss: 2.9322736856095086

Epoch: 6| Step: 1
Training loss: 3.1185208100711272
Validation loss: 2.9326874997235692

Epoch: 6| Step: 2
Training loss: 2.6237159494895703
Validation loss: 2.9325849894583853

Epoch: 6| Step: 3
Training loss: 3.0652050605617656
Validation loss: 2.9328276007610863

Epoch: 6| Step: 4
Training loss: 3.3370595291310514
Validation loss: 2.931252788050244

Epoch: 6| Step: 5
Training loss: 3.4890611552036424
Validation loss: 2.9315680585816115

Epoch: 6| Step: 6
Training loss: 3.2237783616982734
Validation loss: 2.9314717900044345

Epoch: 6| Step: 7
Training loss: 3.0340487743825135
Validation loss: 2.930049770038494

Epoch: 6| Step: 8
Training loss: 3.1930254747071634
Validation loss: 2.929000519743672

Epoch: 6| Step: 9
Training loss: 3.0429693768051345
Validation loss: 2.928463905687078

Epoch: 6| Step: 10
Training loss: 3.416409521583301
Validation loss: 2.928651427251492

Epoch: 6| Step: 11
Training loss: 3.336202785119259
Validation loss: 2.9301248597223895

Epoch: 6| Step: 12
Training loss: 2.8455107551228007
Validation loss: 2.92848848742318

Epoch: 6| Step: 13
Training loss: 3.525971239627207
Validation loss: 2.9272565773254464

Epoch: 78| Step: 0
Training loss: 3.322130849751938
Validation loss: 2.9278305151649526

Epoch: 6| Step: 1
Training loss: 3.6093436896217033
Validation loss: 2.9282468981338576

Epoch: 6| Step: 2
Training loss: 3.5531375398305545
Validation loss: 2.9271176635097627

Epoch: 6| Step: 3
Training loss: 3.4748920670906727
Validation loss: 2.9284463149120823

Epoch: 6| Step: 4
Training loss: 3.2761481449227032
Validation loss: 2.9297878847049077

Epoch: 6| Step: 5
Training loss: 2.8333154752579928
Validation loss: 2.92690596037434

Epoch: 6| Step: 6
Training loss: 2.977610005765622
Validation loss: 2.9254500710434286

Epoch: 6| Step: 7
Training loss: 2.4991163599493333
Validation loss: 2.9264117875434215

Epoch: 6| Step: 8
Training loss: 3.25602632951518
Validation loss: 2.925060603451156

Epoch: 6| Step: 9
Training loss: 3.3492486253442153
Validation loss: 2.926325282138672

Epoch: 6| Step: 10
Training loss: 3.434706784189791
Validation loss: 2.9279260445189355

Epoch: 6| Step: 11
Training loss: 3.084648384570453
Validation loss: 2.923569658156844

Epoch: 6| Step: 12
Training loss: 2.8414471702786197
Validation loss: 2.9234916018829726

Epoch: 6| Step: 13
Training loss: 3.3739988466904167
Validation loss: 2.922833511673242

Epoch: 79| Step: 0
Training loss: 3.2802410209305517
Validation loss: 2.926164690420434

Epoch: 6| Step: 1
Training loss: 3.7005723613647628
Validation loss: 2.9280628169332235

Epoch: 6| Step: 2
Training loss: 3.903750420972525
Validation loss: 2.9246792342096835

Epoch: 6| Step: 3
Training loss: 3.771713968930801
Validation loss: 2.92667700228367

Epoch: 6| Step: 4
Training loss: 2.977458828914492
Validation loss: 2.92205115206213

Epoch: 6| Step: 5
Training loss: 1.994404953672192
Validation loss: 2.922938669767267

Epoch: 6| Step: 6
Training loss: 3.228789588487623
Validation loss: 2.9218790974351654

Epoch: 6| Step: 7
Training loss: 2.5240063100031644
Validation loss: 2.9233040992403287

Epoch: 6| Step: 8
Training loss: 2.8204902740835593
Validation loss: 2.9209949922341747

Epoch: 6| Step: 9
Training loss: 2.5529263926921018
Validation loss: 2.9215767667466483

Epoch: 6| Step: 10
Training loss: 2.9381401500786013
Validation loss: 2.9202624535662576

Epoch: 6| Step: 11
Training loss: 4.138145539325396
Validation loss: 2.918326084826536

Epoch: 6| Step: 12
Training loss: 2.8421535831753437
Validation loss: 2.923632011182656

Epoch: 6| Step: 13
Training loss: 3.8248690713651805
Validation loss: 2.9220285595195015

Epoch: 80| Step: 0
Training loss: 3.1131216508456374
Validation loss: 2.9203859792347697

Epoch: 6| Step: 1
Training loss: 3.413118210013732
Validation loss: 2.9187292239276292

Epoch: 6| Step: 2
Training loss: 2.669580824304883
Validation loss: 2.918853367813907

Epoch: 6| Step: 3
Training loss: 3.7428199695500837
Validation loss: 2.9184495721090764

Epoch: 6| Step: 4
Training loss: 2.9928510044788004
Validation loss: 2.9171003534902646

Epoch: 6| Step: 5
Training loss: 3.206274354481546
Validation loss: 2.917576004408966

Epoch: 6| Step: 6
Training loss: 3.8070642461663917
Validation loss: 2.918262829555244

Epoch: 6| Step: 7
Training loss: 2.4527992955616775
Validation loss: 2.9167702394252224

Epoch: 6| Step: 8
Training loss: 2.4598682805594767
Validation loss: 2.9165160642729897

Epoch: 6| Step: 9
Training loss: 2.99304473788457
Validation loss: 2.9176230648309076

Epoch: 6| Step: 10
Training loss: 3.3223304988889435
Validation loss: 2.9181724815796524

Epoch: 6| Step: 11
Training loss: 3.6915439479112737
Validation loss: 2.916522533763894

Epoch: 6| Step: 12
Training loss: 3.616998193784162
Validation loss: 2.9158394679164963

Epoch: 6| Step: 13
Training loss: 2.917138161469317
Validation loss: 2.9159893134183914

Epoch: 81| Step: 0
Training loss: 3.3719400733699936
Validation loss: 2.9164924083166825

Epoch: 6| Step: 1
Training loss: 3.7483216662555394
Validation loss: 2.9154181191510924

Epoch: 6| Step: 2
Training loss: 3.4511001657182887
Validation loss: 2.919187608349456

Epoch: 6| Step: 3
Training loss: 3.4265770504386404
Validation loss: 2.915391341399166

Epoch: 6| Step: 4
Training loss: 3.1533378536791457
Validation loss: 2.91496207414409

Epoch: 6| Step: 5
Training loss: 2.4784783976038436
Validation loss: 2.9151535087841194

Epoch: 6| Step: 6
Training loss: 3.2126625049619784
Validation loss: 2.915175606734548

Epoch: 6| Step: 7
Training loss: 3.5378640947908737
Validation loss: 2.9179249371281197

Epoch: 6| Step: 8
Training loss: 3.0706507372733522
Validation loss: 2.913770597312436

Epoch: 6| Step: 9
Training loss: 3.122705151039263
Validation loss: 2.9132170847031342

Epoch: 6| Step: 10
Training loss: 3.1155703372426293
Validation loss: 2.913039322133948

Epoch: 6| Step: 11
Training loss: 2.9647948571396765
Validation loss: 2.915105965260318

Epoch: 6| Step: 12
Training loss: 2.6710472386280752
Validation loss: 2.9128096859711823

Epoch: 6| Step: 13
Training loss: 3.3419281461651535
Validation loss: 2.91349453565022

Epoch: 82| Step: 0
Training loss: 2.5522763133882687
Validation loss: 2.911195454798611

Epoch: 6| Step: 1
Training loss: 3.534533299308538
Validation loss: 2.9116327777713336

Epoch: 6| Step: 2
Training loss: 3.4246066960519777
Validation loss: 2.9114936772021576

Epoch: 6| Step: 3
Training loss: 3.00656490461037
Validation loss: 2.9093065687348396

Epoch: 6| Step: 4
Training loss: 3.0810789853934932
Validation loss: 2.907908851520841

Epoch: 6| Step: 5
Training loss: 4.026307380596627
Validation loss: 2.908650025075772

Epoch: 6| Step: 6
Training loss: 2.40402773009951
Validation loss: 2.9073395770048505

Epoch: 6| Step: 7
Training loss: 2.3246398031492936
Validation loss: 2.9091112349320762

Epoch: 6| Step: 8
Training loss: 3.1709310696176605
Validation loss: 2.9073939352904374

Epoch: 6| Step: 9
Training loss: 3.3598865208309237
Validation loss: 2.906954386766563

Epoch: 6| Step: 10
Training loss: 2.9553901825277564
Validation loss: 2.9082041281701416

Epoch: 6| Step: 11
Training loss: 3.102539984655198
Validation loss: 2.907348825563997

Epoch: 6| Step: 12
Training loss: 3.9899738542278538
Validation loss: 2.907870379582479

Epoch: 6| Step: 13
Training loss: 3.4016342386821092
Validation loss: 2.9052983478110033

Epoch: 83| Step: 0
Training loss: 2.9528269137958145
Validation loss: 2.9060800206931487

Epoch: 6| Step: 1
Training loss: 3.55124559713035
Validation loss: 2.9053034498540176

Epoch: 6| Step: 2
Training loss: 3.7488363367857076
Validation loss: 2.90594870665802

Epoch: 6| Step: 3
Training loss: 2.9974701068777945
Validation loss: 2.90374166509938

Epoch: 6| Step: 4
Training loss: 3.1290543767605907
Validation loss: 2.9042398913471863

Epoch: 6| Step: 5
Training loss: 3.4703436962169967
Validation loss: 2.9045782451320963

Epoch: 6| Step: 6
Training loss: 2.8788784237970013
Validation loss: 2.9048729813324194

Epoch: 6| Step: 7
Training loss: 2.5829192003940347
Validation loss: 2.9079441421427843

Epoch: 6| Step: 8
Training loss: 2.5847249948399145
Validation loss: 2.918712902542592

Epoch: 6| Step: 9
Training loss: 3.757947510893268
Validation loss: 2.9343387399573357

Epoch: 6| Step: 10
Training loss: 2.2891441565000403
Validation loss: 2.910228330230599

Epoch: 6| Step: 11
Training loss: 3.8253611026428334
Validation loss: 2.9019406120844335

Epoch: 6| Step: 12
Training loss: 2.994126291856593
Validation loss: 2.899281223656699

Epoch: 6| Step: 13
Training loss: 3.6810925953604694
Validation loss: 2.8995844325783757

Epoch: 84| Step: 0
Training loss: 2.6605543379286205
Validation loss: 2.9004480334090528

Epoch: 6| Step: 1
Training loss: 3.4089135071806203
Validation loss: 2.901265451840841

Epoch: 6| Step: 2
Training loss: 2.4865805953967315
Validation loss: 2.900361196452134

Epoch: 6| Step: 3
Training loss: 2.9823054782460114
Validation loss: 2.9011668708111373

Epoch: 6| Step: 4
Training loss: 3.634841188427342
Validation loss: 2.9011743686434417

Epoch: 6| Step: 5
Training loss: 3.086194764048936
Validation loss: 2.901975233219262

Epoch: 6| Step: 6
Training loss: 2.9595480202647377
Validation loss: 2.9016719154203523

Epoch: 6| Step: 7
Training loss: 3.1961764261298597
Validation loss: 2.9002440273172008

Epoch: 6| Step: 8
Training loss: 3.7015208701308384
Validation loss: 2.9029314781526354

Epoch: 6| Step: 9
Training loss: 3.145467640082264
Validation loss: 2.8995007191593456

Epoch: 6| Step: 10
Training loss: 3.3295932450328167
Validation loss: 2.8997927392566676

Epoch: 6| Step: 11
Training loss: 2.7053954010685843
Validation loss: 2.8988330083531597

Epoch: 6| Step: 12
Training loss: 3.485978788082612
Validation loss: 2.8984342999113526

Epoch: 6| Step: 13
Training loss: 3.9219258217729283
Validation loss: 2.898801801424792

Epoch: 85| Step: 0
Training loss: 2.6239432069575406
Validation loss: 2.897681890006567

Epoch: 6| Step: 1
Training loss: 3.6276611557331853
Validation loss: 2.8973283108351433

Epoch: 6| Step: 2
Training loss: 3.257014115019241
Validation loss: 2.9014719661275206

Epoch: 6| Step: 3
Training loss: 3.1023323391253252
Validation loss: 2.9011843866361615

Epoch: 6| Step: 4
Training loss: 3.465876445815501
Validation loss: 2.904624808292007

Epoch: 6| Step: 5
Training loss: 3.1843136587776693
Validation loss: 2.908691814766128

Epoch: 6| Step: 6
Training loss: 2.878850597325042
Validation loss: 2.905577651631674

Epoch: 6| Step: 7
Training loss: 2.303652980539503
Validation loss: 2.912470603708963

Epoch: 6| Step: 8
Training loss: 3.5607820350552033
Validation loss: 2.921352328978277

Epoch: 6| Step: 9
Training loss: 2.7422600978359712
Validation loss: 2.9281162726341528

Epoch: 6| Step: 10
Training loss: 3.7479293192546876
Validation loss: 2.9088929907505485

Epoch: 6| Step: 11
Training loss: 3.6366630246720812
Validation loss: 2.895644310936108

Epoch: 6| Step: 12
Training loss: 2.8165486335476544
Validation loss: 2.8952598337347077

Epoch: 6| Step: 13
Training loss: 3.4585524493436326
Validation loss: 2.8967502022193785

Epoch: 86| Step: 0
Training loss: 2.860982474323076
Validation loss: 2.9066562586960507

Epoch: 6| Step: 1
Training loss: 2.370060351444352
Validation loss: 2.896629851325

Epoch: 6| Step: 2
Training loss: 3.857108002459765
Validation loss: 2.894628322904858

Epoch: 6| Step: 3
Training loss: 2.590287712789465
Validation loss: 2.893253628946802

Epoch: 6| Step: 4
Training loss: 3.71532917561536
Validation loss: 2.8961177399138798

Epoch: 6| Step: 5
Training loss: 2.6096671848833393
Validation loss: 2.8950407587704112

Epoch: 6| Step: 6
Training loss: 3.340548256973027
Validation loss: 2.8959733187455923

Epoch: 6| Step: 7
Training loss: 3.238374016218772
Validation loss: 2.894095469419425

Epoch: 6| Step: 8
Training loss: 3.5517477434470277
Validation loss: 2.8956070961571605

Epoch: 6| Step: 9
Training loss: 3.3065582823936013
Validation loss: 2.8956126933669664

Epoch: 6| Step: 10
Training loss: 3.1659692364352954
Validation loss: 2.8959382142144463

Epoch: 6| Step: 11
Training loss: 3.3475358867929557
Validation loss: 2.8978008569106026

Epoch: 6| Step: 12
Training loss: 2.9869290752029864
Validation loss: 2.897042904858842

Epoch: 6| Step: 13
Training loss: 3.4060107505839237
Validation loss: 2.8968962129860762

Epoch: 87| Step: 0
Training loss: 3.2005199725173443
Validation loss: 2.900607072190886

Epoch: 6| Step: 1
Training loss: 3.376953972220108
Validation loss: 2.9043626023196154

Epoch: 6| Step: 2
Training loss: 3.5892803758745546
Validation loss: 2.9172386054007884

Epoch: 6| Step: 3
Training loss: 3.2478218115331106
Validation loss: 2.9054782057423765

Epoch: 6| Step: 4
Training loss: 2.966008576970422
Validation loss: 2.897507084170865

Epoch: 6| Step: 5
Training loss: 3.1522109371224283
Validation loss: 2.8926710342482287

Epoch: 6| Step: 6
Training loss: 3.1721320588377235
Validation loss: 2.887939692250743

Epoch: 6| Step: 7
Training loss: 2.773471370006653
Validation loss: 2.8876322278783904

Epoch: 6| Step: 8
Training loss: 2.587918816178997
Validation loss: 2.8850192820377267

Epoch: 6| Step: 9
Training loss: 2.832848918867956
Validation loss: 2.8854940731377434

Epoch: 6| Step: 10
Training loss: 3.264689334267471
Validation loss: 2.8857331499785137

Epoch: 6| Step: 11
Training loss: 3.6466977793071247
Validation loss: 2.8863505316048723

Epoch: 6| Step: 12
Training loss: 3.3830429597721006
Validation loss: 2.8839195552003463

Epoch: 6| Step: 13
Training loss: 3.13895945249329
Validation loss: 2.8832541915878975

Epoch: 88| Step: 0
Training loss: 2.783143673981272
Validation loss: 2.8857692990062658

Epoch: 6| Step: 1
Training loss: 2.789844221736256
Validation loss: 2.88403075629315

Epoch: 6| Step: 2
Training loss: 3.8378635395831773
Validation loss: 2.8848967648910424

Epoch: 6| Step: 3
Training loss: 3.314911162738106
Validation loss: 2.8853103190441094

Epoch: 6| Step: 4
Training loss: 3.1318345672062016
Validation loss: 2.8837800499721027

Epoch: 6| Step: 5
Training loss: 3.1297117189488213
Validation loss: 2.8849830045377374

Epoch: 6| Step: 6
Training loss: 3.1316500288308355
Validation loss: 2.884886861846807

Epoch: 6| Step: 7
Training loss: 2.850945058367502
Validation loss: 2.8830120787816735

Epoch: 6| Step: 8
Training loss: 3.510597126262477
Validation loss: 2.8834848594457725

Epoch: 6| Step: 9
Training loss: 3.0235579907757657
Validation loss: 2.88369711347998

Epoch: 6| Step: 10
Training loss: 3.4828227738254145
Validation loss: 2.883355093930843

Epoch: 6| Step: 11
Training loss: 2.648700172204073
Validation loss: 2.883509212056431

Epoch: 6| Step: 12
Training loss: 3.0764806392661237
Validation loss: 2.883842857940332

Epoch: 6| Step: 13
Training loss: 3.874852085366831
Validation loss: 2.882126144952278

Epoch: 89| Step: 0
Training loss: 2.5528903437791524
Validation loss: 2.8838212595214188

Epoch: 6| Step: 1
Training loss: 3.2643070755665358
Validation loss: 2.886117795725348

Epoch: 6| Step: 2
Training loss: 3.260050272641722
Validation loss: 2.882300616156016

Epoch: 6| Step: 3
Training loss: 2.8280030113592667
Validation loss: 2.8811581018518084

Epoch: 6| Step: 4
Training loss: 3.2045712067229086
Validation loss: 2.8812517975419496

Epoch: 6| Step: 5
Training loss: 4.249025569731998
Validation loss: 2.8795918216483143

Epoch: 6| Step: 6
Training loss: 3.2332064226812802
Validation loss: 2.8828847223405716

Epoch: 6| Step: 7
Training loss: 2.5692494521742257
Validation loss: 2.8777070678492733

Epoch: 6| Step: 8
Training loss: 3.2892008047858834
Validation loss: 2.875837295970749

Epoch: 6| Step: 9
Training loss: 2.949187383421776
Validation loss: 2.8785646016899213

Epoch: 6| Step: 10
Training loss: 3.118038204817911
Validation loss: 2.8750726263531083

Epoch: 6| Step: 11
Training loss: 3.3136126970634536
Validation loss: 2.880995079641619

Epoch: 6| Step: 12
Training loss: 2.664086484381588
Validation loss: 2.880857693112207

Epoch: 6| Step: 13
Training loss: 3.9190043243672466
Validation loss: 2.8915022388347227

Epoch: 90| Step: 0
Training loss: 3.8583711252908937
Validation loss: 2.8955053528980335

Epoch: 6| Step: 1
Training loss: 3.5064832042039993
Validation loss: 2.8857190495050937

Epoch: 6| Step: 2
Training loss: 3.088784288179777
Validation loss: 2.8738019586248855

Epoch: 6| Step: 3
Training loss: 2.697938297926349
Validation loss: 2.8724581809919423

Epoch: 6| Step: 4
Training loss: 3.07767138551642
Validation loss: 2.873661530441996

Epoch: 6| Step: 5
Training loss: 3.0345125239879547
Validation loss: 2.8744347468301705

Epoch: 6| Step: 6
Training loss: 2.936220417937387
Validation loss: 2.87515963859757

Epoch: 6| Step: 7
Training loss: 2.552961787373024
Validation loss: 2.8770551554336525

Epoch: 6| Step: 8
Training loss: 3.068203655640439
Validation loss: 2.8764192770498203

Epoch: 6| Step: 9
Training loss: 3.5330475139775506
Validation loss: 2.8788214668669214

Epoch: 6| Step: 10
Training loss: 3.1972824776682454
Validation loss: 2.87115043431827

Epoch: 6| Step: 11
Training loss: 3.5646579296898437
Validation loss: 2.8720311284090587

Epoch: 6| Step: 12
Training loss: 3.12526915344809
Validation loss: 2.8678728855716455

Epoch: 6| Step: 13
Training loss: 3.078360146772516
Validation loss: 2.871328671496029

Epoch: 91| Step: 0
Training loss: 3.510451787363531
Validation loss: 2.8676901630938523

Epoch: 6| Step: 1
Training loss: 3.3706436298746056
Validation loss: 2.8660029880280344

Epoch: 6| Step: 2
Training loss: 2.53223230587109
Validation loss: 2.8663952380465694

Epoch: 6| Step: 3
Training loss: 3.3967996794238235
Validation loss: 2.8661140237818374

Epoch: 6| Step: 4
Training loss: 3.311780167586304
Validation loss: 2.8672898564779934

Epoch: 6| Step: 5
Training loss: 3.458932265541281
Validation loss: 2.8821122385330673

Epoch: 6| Step: 6
Training loss: 2.8790271583540226
Validation loss: 2.9059728930722577

Epoch: 6| Step: 7
Training loss: 2.7819293617588348
Validation loss: 2.915336008843326

Epoch: 6| Step: 8
Training loss: 3.2013005713147886
Validation loss: 2.887696756031322

Epoch: 6| Step: 9
Training loss: 2.4463836956184415
Validation loss: 2.8708405529887355

Epoch: 6| Step: 10
Training loss: 2.963672351246337
Validation loss: 2.869610579150756

Epoch: 6| Step: 11
Training loss: 3.7885745648702156
Validation loss: 2.8669647204460227

Epoch: 6| Step: 12
Training loss: 2.627988295112451
Validation loss: 2.8697766957851822

Epoch: 6| Step: 13
Training loss: 4.128369660097681
Validation loss: 2.8713589582966503

Epoch: 92| Step: 0
Training loss: 3.188121061967647
Validation loss: 2.864215403147274

Epoch: 6| Step: 1
Training loss: 4.027164725349294
Validation loss: 2.867666822229971

Epoch: 6| Step: 2
Training loss: 2.9616943036365786
Validation loss: 2.867883748431767

Epoch: 6| Step: 3
Training loss: 2.5178127845327465
Validation loss: 2.8671089513220727

Epoch: 6| Step: 4
Training loss: 3.216819999347667
Validation loss: 2.8673986894922

Epoch: 6| Step: 5
Training loss: 2.702771025837951
Validation loss: 2.8647723457572694

Epoch: 6| Step: 6
Training loss: 3.7847281608573837
Validation loss: 2.8651129472222125

Epoch: 6| Step: 7
Training loss: 2.1450088052635596
Validation loss: 2.865394049481919

Epoch: 6| Step: 8
Training loss: 3.162304198947294
Validation loss: 2.8652197817487077

Epoch: 6| Step: 9
Training loss: 3.112680336503943
Validation loss: 2.8729709100925653

Epoch: 6| Step: 10
Training loss: 3.835915497446763
Validation loss: 2.8724332670213344

Epoch: 6| Step: 11
Training loss: 3.302960605193536
Validation loss: 2.863752088712275

Epoch: 6| Step: 12
Training loss: 2.883466940928276
Validation loss: 2.8625801932814414

Epoch: 6| Step: 13
Training loss: 2.6988870552178557
Validation loss: 2.8654761737290393

Epoch: 93| Step: 0
Training loss: 3.0622608324977807
Validation loss: 2.864868994347686

Epoch: 6| Step: 1
Training loss: 2.666973235469096
Validation loss: 2.865380027859186

Epoch: 6| Step: 2
Training loss: 2.859074477782423
Validation loss: 2.868266861414754

Epoch: 6| Step: 3
Training loss: 2.780649527546387
Validation loss: 2.8706625364506966

Epoch: 6| Step: 4
Training loss: 2.7682316452020057
Validation loss: 2.8686366217432644

Epoch: 6| Step: 5
Training loss: 3.9077087120113863
Validation loss: 2.8662027256764797

Epoch: 6| Step: 6
Training loss: 3.1464658863322414
Validation loss: 2.8664358326789143

Epoch: 6| Step: 7
Training loss: 3.4829730989883294
Validation loss: 2.862191657051847

Epoch: 6| Step: 8
Training loss: 2.672957797686696
Validation loss: 2.8643887161564052

Epoch: 6| Step: 9
Training loss: 3.4346673565068153
Validation loss: 2.864153571831633

Epoch: 6| Step: 10
Training loss: 2.8531073579106976
Validation loss: 2.8645528597436716

Epoch: 6| Step: 11
Training loss: 3.246292346888192
Validation loss: 2.8615716361534953

Epoch: 6| Step: 12
Training loss: 3.5459351491748015
Validation loss: 2.8620393281251615

Epoch: 6| Step: 13
Training loss: 3.8174025485547634
Validation loss: 2.863188586874477

Epoch: 94| Step: 0
Training loss: 3.34150891649106
Validation loss: 2.861544936848232

Epoch: 6| Step: 1
Training loss: 2.772302185651726
Validation loss: 2.8631786642606185

Epoch: 6| Step: 2
Training loss: 3.3082613907557894
Validation loss: 2.8628552364490902

Epoch: 6| Step: 3
Training loss: 3.7504401902287947
Validation loss: 2.864636475786999

Epoch: 6| Step: 4
Training loss: 3.259496605745091
Validation loss: 2.866081101888859

Epoch: 6| Step: 5
Training loss: 2.749303903044177
Validation loss: 2.864760023169918

Epoch: 6| Step: 6
Training loss: 2.6080284070416173
Validation loss: 2.864444944258833

Epoch: 6| Step: 7
Training loss: 3.4236154528305107
Validation loss: 2.864753066298718

Epoch: 6| Step: 8
Training loss: 2.39974959577161
Validation loss: 2.8633464853982042

Epoch: 6| Step: 9
Training loss: 3.540856990637918
Validation loss: 2.860859870499254

Epoch: 6| Step: 10
Training loss: 2.6717191059521244
Validation loss: 2.859323390058074

Epoch: 6| Step: 11
Training loss: 3.877532131669434
Validation loss: 2.8594974245280507

Epoch: 6| Step: 12
Training loss: 3.31614168187924
Validation loss: 2.8576949897748016

Epoch: 6| Step: 13
Training loss: 2.459515454402915
Validation loss: 2.8565763686505328

Epoch: 95| Step: 0
Training loss: 1.9635465977722364
Validation loss: 2.8568214289903495

Epoch: 6| Step: 1
Training loss: 4.000859168287814
Validation loss: 2.856517674676203

Epoch: 6| Step: 2
Training loss: 2.212771352733662
Validation loss: 2.856660778163884

Epoch: 6| Step: 3
Training loss: 3.2549740801129325
Validation loss: 2.856261936160201

Epoch: 6| Step: 4
Training loss: 3.058480563937811
Validation loss: 2.8558484430986817

Epoch: 6| Step: 5
Training loss: 3.064537460499016
Validation loss: 2.857059516035494

Epoch: 6| Step: 6
Training loss: 2.819215429073941
Validation loss: 2.8540791224979043

Epoch: 6| Step: 7
Training loss: 3.6697454242606304
Validation loss: 2.855049581174589

Epoch: 6| Step: 8
Training loss: 3.065278797257997
Validation loss: 2.8566439603578306

Epoch: 6| Step: 9
Training loss: 2.9072920049004045
Validation loss: 2.855130593254191

Epoch: 6| Step: 10
Training loss: 3.200437432431875
Validation loss: 2.8541220336710498

Epoch: 6| Step: 11
Training loss: 3.795656487497458
Validation loss: 2.8580849634117023

Epoch: 6| Step: 12
Training loss: 3.4825174486499515
Validation loss: 2.8560732934410935

Epoch: 6| Step: 13
Training loss: 2.867089709035663
Validation loss: 2.856038499163404

Epoch: 96| Step: 0
Training loss: 3.2913158245871412
Validation loss: 2.8536553664049413

Epoch: 6| Step: 1
Training loss: 2.9319387509244397
Validation loss: 2.8590293786122642

Epoch: 6| Step: 2
Training loss: 3.0332282778255233
Validation loss: 2.868183731975369

Epoch: 6| Step: 3
Training loss: 3.284749662478681
Validation loss: 2.871985723003198

Epoch: 6| Step: 4
Training loss: 2.661722895442958
Validation loss: 2.8682941470380414

Epoch: 6| Step: 5
Training loss: 3.0684087932645165
Validation loss: 2.8754232950142478

Epoch: 6| Step: 6
Training loss: 3.2989798963199584
Validation loss: 2.8631700220137803

Epoch: 6| Step: 7
Training loss: 3.1287259586887366
Validation loss: 2.8497872961001813

Epoch: 6| Step: 8
Training loss: 3.084476946196261
Validation loss: 2.846759677001582

Epoch: 6| Step: 9
Training loss: 3.410591648267988
Validation loss: 2.8460071327659064

Epoch: 6| Step: 10
Training loss: 3.185357963531722
Validation loss: 2.849053830617805

Epoch: 6| Step: 11
Training loss: 3.5348476211964392
Validation loss: 2.8498494517054964

Epoch: 6| Step: 12
Training loss: 2.9280327357979274
Validation loss: 2.849651107488685

Epoch: 6| Step: 13
Training loss: 3.1578013318452776
Validation loss: 2.8498860729872453

Epoch: 97| Step: 0
Training loss: 2.954969042310871
Validation loss: 2.8506583944538493

Epoch: 6| Step: 1
Training loss: 2.8713250929861314
Validation loss: 2.851235664034815

Epoch: 6| Step: 2
Training loss: 2.74280951854539
Validation loss: 2.8504299448312813

Epoch: 6| Step: 3
Training loss: 3.5984307365668635
Validation loss: 2.850739443191444

Epoch: 6| Step: 4
Training loss: 3.867539884907787
Validation loss: 2.8542947452252236

Epoch: 6| Step: 5
Training loss: 3.7779601106087757
Validation loss: 2.8499177354886647

Epoch: 6| Step: 6
Training loss: 2.6509845380242236
Validation loss: 2.8487842690584713

Epoch: 6| Step: 7
Training loss: 3.1986092346630555
Validation loss: 2.847093894468288

Epoch: 6| Step: 8
Training loss: 3.160192010816281
Validation loss: 2.8463776105453737

Epoch: 6| Step: 9
Training loss: 3.001426675434983
Validation loss: 2.8470399440227827

Epoch: 6| Step: 10
Training loss: 2.5564683778934545
Validation loss: 2.8462482969318317

Epoch: 6| Step: 11
Training loss: 3.7999262852796987
Validation loss: 2.8440200585479642

Epoch: 6| Step: 12
Training loss: 2.8085797432880484
Validation loss: 2.8433422637867682

Epoch: 6| Step: 13
Training loss: 2.3375129617749852
Validation loss: 2.844092386218329

Epoch: 98| Step: 0
Training loss: 3.3758560790349788
Validation loss: 2.8422982649224973

Epoch: 6| Step: 1
Training loss: 3.2717710636976896
Validation loss: 2.8476026082016452

Epoch: 6| Step: 2
Training loss: 3.257049983595906
Validation loss: 2.8473844042978893

Epoch: 6| Step: 3
Training loss: 2.640607574224816
Validation loss: 2.844921571644032

Epoch: 6| Step: 4
Training loss: 2.844869539993875
Validation loss: 2.8456951377754818

Epoch: 6| Step: 5
Training loss: 3.0815813052821523
Validation loss: 2.84547162513341

Epoch: 6| Step: 6
Training loss: 3.0187004890883538
Validation loss: 2.844146632341455

Epoch: 6| Step: 7
Training loss: 2.5450269863294217
Validation loss: 2.8503747192148223

Epoch: 6| Step: 8
Training loss: 3.094126668791906
Validation loss: 2.8548391789539718

Epoch: 6| Step: 9
Training loss: 2.9160035242339344
Validation loss: 2.843243214478726

Epoch: 6| Step: 10
Training loss: 3.3424464742045403
Validation loss: 2.842862161563711

Epoch: 6| Step: 11
Training loss: 3.5850626890269197
Validation loss: 2.8407258436853544

Epoch: 6| Step: 12
Training loss: 3.1572475556543784
Validation loss: 2.8369516432707256

Epoch: 6| Step: 13
Training loss: 4.033605789145915
Validation loss: 2.8388727051336287

Epoch: 99| Step: 0
Training loss: 3.4643207486478094
Validation loss: 2.8402313339410705

Epoch: 6| Step: 1
Training loss: 3.3820577224326334
Validation loss: 2.847402031282476

Epoch: 6| Step: 2
Training loss: 2.8200610780526993
Validation loss: 2.858870633665914

Epoch: 6| Step: 3
Training loss: 3.507685533702348
Validation loss: 2.846094363451904

Epoch: 6| Step: 4
Training loss: 2.40262260989499
Validation loss: 2.8399169829380386

Epoch: 6| Step: 5
Training loss: 3.199985361065759
Validation loss: 2.841442403790269

Epoch: 6| Step: 6
Training loss: 2.8567387669773843
Validation loss: 2.8458044669326923

Epoch: 6| Step: 7
Training loss: 3.2557665211527054
Validation loss: 2.838831014675859

Epoch: 6| Step: 8
Training loss: 3.9830671969029026
Validation loss: 2.8351087967071145

Epoch: 6| Step: 9
Training loss: 3.124756460236704
Validation loss: 2.837208622687068

Epoch: 6| Step: 10
Training loss: 2.4234770367642002
Validation loss: 2.8375807063612744

Epoch: 6| Step: 11
Training loss: 4.087821103237067
Validation loss: 2.8367447851704415

Epoch: 6| Step: 12
Training loss: 2.065127923803948
Validation loss: 2.8381924599084796

Epoch: 6| Step: 13
Training loss: 2.228270187034827
Validation loss: 2.841314994027818

Epoch: 100| Step: 0
Training loss: 2.6671460336725663
Validation loss: 2.842710320040839

Epoch: 6| Step: 1
Training loss: 3.392937219004639
Validation loss: 2.8455028862830045

Epoch: 6| Step: 2
Training loss: 3.036792368152302
Validation loss: 2.8411257486817867

Epoch: 6| Step: 3
Training loss: 2.877062513831789
Validation loss: 2.84314013205515

Epoch: 6| Step: 4
Training loss: 2.5966899709508673
Validation loss: 2.8409276905812004

Epoch: 6| Step: 5
Training loss: 3.0708409599578714
Validation loss: 2.838111255200381

Epoch: 6| Step: 6
Training loss: 3.0311770086250633
Validation loss: 2.843621938139487

Epoch: 6| Step: 7
Training loss: 3.515108875959758
Validation loss: 2.838964978968138

Epoch: 6| Step: 8
Training loss: 3.174039656412395
Validation loss: 2.837318000560083

Epoch: 6| Step: 9
Training loss: 3.1403498742598206
Validation loss: 2.8355826534382675

Epoch: 6| Step: 10
Training loss: 3.787064046918006
Validation loss: 2.836454222310501

Epoch: 6| Step: 11
Training loss: 2.9436853097987563
Validation loss: 2.834857035732484

Epoch: 6| Step: 12
Training loss: 3.5231576203627224
Validation loss: 2.8354334518756636

Epoch: 6| Step: 13
Training loss: 2.946224162620056
Validation loss: 2.8343731138291814

Epoch: 101| Step: 0
Training loss: 3.544223550578751
Validation loss: 2.8354781940012375

Epoch: 6| Step: 1
Training loss: 3.487651840787556
Validation loss: 2.833969495993525

Epoch: 6| Step: 2
Training loss: 3.0744451999268936
Validation loss: 2.8358709425316575

Epoch: 6| Step: 3
Training loss: 2.9667059034974597
Validation loss: 2.8347144449396318

Epoch: 6| Step: 4
Training loss: 2.8022902931068403
Validation loss: 2.833037426701756

Epoch: 6| Step: 5
Training loss: 3.1424659912891166
Validation loss: 2.8328849110689367

Epoch: 6| Step: 6
Training loss: 3.0117341077044393
Validation loss: 2.8311384181642776

Epoch: 6| Step: 7
Training loss: 3.36205436845034
Validation loss: 2.8301146162306283

Epoch: 6| Step: 8
Training loss: 3.190390678566618
Validation loss: 2.83000716123534

Epoch: 6| Step: 9
Training loss: 2.52637464288497
Validation loss: 2.8297642279023587

Epoch: 6| Step: 10
Training loss: 3.3190615462860382
Validation loss: 2.829763403482679

Epoch: 6| Step: 11
Training loss: 3.220602891055114
Validation loss: 2.828572294707458

Epoch: 6| Step: 12
Training loss: 3.152051039936031
Validation loss: 2.8273972081504986

Epoch: 6| Step: 13
Training loss: 2.8435320089439244
Validation loss: 2.826865478288322

Epoch: 102| Step: 0
Training loss: 2.808631440441644
Validation loss: 2.8255592373447325

Epoch: 6| Step: 1
Training loss: 2.8119822555405385
Validation loss: 2.826221770893892

Epoch: 6| Step: 2
Training loss: 3.744081404192257
Validation loss: 2.823844709592741

Epoch: 6| Step: 3
Training loss: 2.638669345044124
Validation loss: 2.8296390410999575

Epoch: 6| Step: 4
Training loss: 2.894079175645052
Validation loss: 2.8448290512502603

Epoch: 6| Step: 5
Training loss: 2.853813390842326
Validation loss: 2.8537299284099484

Epoch: 6| Step: 6
Training loss: 2.8967059533630652
Validation loss: 2.8717681577094116

Epoch: 6| Step: 7
Training loss: 3.645977620493997
Validation loss: 2.88216126027457

Epoch: 6| Step: 8
Training loss: 3.4068225064499766
Validation loss: 2.852588143103233

Epoch: 6| Step: 9
Training loss: 3.1308392710287167
Validation loss: 2.8275790419830127

Epoch: 6| Step: 10
Training loss: 3.365898717660897
Validation loss: 2.8216474546791876

Epoch: 6| Step: 11
Training loss: 3.068244995083267
Validation loss: 2.822056100655981

Epoch: 6| Step: 12
Training loss: 3.5519087106211535
Validation loss: 2.823181236815361

Epoch: 6| Step: 13
Training loss: 2.501019937361815
Validation loss: 2.8237119663164005

Epoch: 103| Step: 0
Training loss: 3.4759494883968367
Validation loss: 2.8245513134269453

Epoch: 6| Step: 1
Training loss: 3.46033067743775
Validation loss: 2.8258560026481274

Epoch: 6| Step: 2
Training loss: 2.906586330190217
Validation loss: 2.826204078933561

Epoch: 6| Step: 3
Training loss: 2.7763616056651155
Validation loss: 2.825899764233757

Epoch: 6| Step: 4
Training loss: 3.2696805894806547
Validation loss: 2.8256713170822603

Epoch: 6| Step: 5
Training loss: 3.189315428509205
Validation loss: 2.825602651498077

Epoch: 6| Step: 6
Training loss: 3.1648587202265666
Validation loss: 2.8241699815459547

Epoch: 6| Step: 7
Training loss: 2.453720312108972
Validation loss: 2.826732211182611

Epoch: 6| Step: 8
Training loss: 2.779940007337743
Validation loss: 2.8252119962872557

Epoch: 6| Step: 9
Training loss: 3.506581249671377
Validation loss: 2.8238982253033256

Epoch: 6| Step: 10
Training loss: 3.1573463273275038
Validation loss: 2.822574938681909

Epoch: 6| Step: 11
Training loss: 2.6292572013957303
Validation loss: 2.8243093876452408

Epoch: 6| Step: 12
Training loss: 3.816579043674931
Validation loss: 2.823312471389719

Epoch: 6| Step: 13
Training loss: 2.9122036893680945
Validation loss: 2.822412378068334

Epoch: 104| Step: 0
Training loss: 3.76054730104781
Validation loss: 2.82082721684519

Epoch: 6| Step: 1
Training loss: 3.4448355346753368
Validation loss: 2.8212234643408123

Epoch: 6| Step: 2
Training loss: 2.851692426674044
Validation loss: 2.8202819758937525

Epoch: 6| Step: 3
Training loss: 2.5633165872702315
Validation loss: 2.820564697559285

Epoch: 6| Step: 4
Training loss: 3.5003539315152152
Validation loss: 2.819203697584282

Epoch: 6| Step: 5
Training loss: 2.7211498323718386
Validation loss: 2.820600137571616

Epoch: 6| Step: 6
Training loss: 2.9097585521565437
Validation loss: 2.8216387233883298

Epoch: 6| Step: 7
Training loss: 2.3978594850758994
Validation loss: 2.820125279674688

Epoch: 6| Step: 8
Training loss: 3.188008286583827
Validation loss: 2.8270810446893653

Epoch: 6| Step: 9
Training loss: 3.057439242716099
Validation loss: 2.8281515833270947

Epoch: 6| Step: 10
Training loss: 3.52357066509721
Validation loss: 2.8280252309780254

Epoch: 6| Step: 11
Training loss: 2.843172790300113
Validation loss: 2.8338250421813056

Epoch: 6| Step: 12
Training loss: 3.145678198486008
Validation loss: 2.8415562983896323

Epoch: 6| Step: 13
Training loss: 3.876566662492097
Validation loss: 2.8361123358624982

Epoch: 105| Step: 0
Training loss: 2.837934647262651
Validation loss: 2.8333380187597266

Epoch: 6| Step: 1
Training loss: 4.119650869298527
Validation loss: 2.829007279610178

Epoch: 6| Step: 2
Training loss: 3.4117388816188874
Validation loss: 2.8269296559658588

Epoch: 6| Step: 3
Training loss: 3.162217645517473
Validation loss: 2.813477338842533

Epoch: 6| Step: 4
Training loss: 3.173160687032338
Validation loss: 2.813955188053003

Epoch: 6| Step: 5
Training loss: 2.3699395325749397
Validation loss: 2.8136642716969935

Epoch: 6| Step: 6
Training loss: 3.470744891068336
Validation loss: 2.813446852657959

Epoch: 6| Step: 7
Training loss: 3.0939384942479005
Validation loss: 2.814362193613698

Epoch: 6| Step: 8
Training loss: 3.082042698905383
Validation loss: 2.815178317579654

Epoch: 6| Step: 9
Training loss: 2.6933997402250807
Validation loss: 2.8138654832813

Epoch: 6| Step: 10
Training loss: 2.8245933780209262
Validation loss: 2.8146290749840173

Epoch: 6| Step: 11
Training loss: 2.9569086933816697
Validation loss: 2.8135542157387503

Epoch: 6| Step: 12
Training loss: 3.346108006231669
Validation loss: 2.8112992361123204

Epoch: 6| Step: 13
Training loss: 2.674773311813972
Validation loss: 2.812926383381568

Epoch: 106| Step: 0
Training loss: 2.5775379784169785
Validation loss: 2.8113562460734527

Epoch: 6| Step: 1
Training loss: 3.5113621616612947
Validation loss: 2.8114565929431814

Epoch: 6| Step: 2
Training loss: 2.5506958180443555
Validation loss: 2.808422082863278

Epoch: 6| Step: 3
Training loss: 2.2749756528788185
Validation loss: 2.8090964283408493

Epoch: 6| Step: 4
Training loss: 3.1635102720255133
Validation loss: 2.80890172301043

Epoch: 6| Step: 5
Training loss: 3.062718442016164
Validation loss: 2.807696642678309

Epoch: 6| Step: 6
Training loss: 3.547790678023206
Validation loss: 2.8084371008704436

Epoch: 6| Step: 7
Training loss: 3.0417953011124252
Validation loss: 2.822752018544228

Epoch: 6| Step: 8
Training loss: 3.0410231514839423
Validation loss: 2.821438134301882

Epoch: 6| Step: 9
Training loss: 2.941055418777137
Validation loss: 2.819128487036518

Epoch: 6| Step: 10
Training loss: 3.3152904632954963
Validation loss: 2.812789778097681

Epoch: 6| Step: 11
Training loss: 3.547804656008736
Validation loss: 2.8066883160604266

Epoch: 6| Step: 12
Training loss: 3.6219524859087624
Validation loss: 2.8093567916340456

Epoch: 6| Step: 13
Training loss: 3.1389038531941638
Validation loss: 2.8090313084210194

Epoch: 107| Step: 0
Training loss: 2.7971135895474126
Validation loss: 2.8103278592255205

Epoch: 6| Step: 1
Training loss: 3.686642433923842
Validation loss: 2.8100386501569696

Epoch: 6| Step: 2
Training loss: 3.12462674772877
Validation loss: 2.809776372876401

Epoch: 6| Step: 3
Training loss: 3.2983288203576895
Validation loss: 2.8124953384998848

Epoch: 6| Step: 4
Training loss: 3.0460444956865205
Validation loss: 2.8187165771493548

Epoch: 6| Step: 5
Training loss: 2.8505094909349373
Validation loss: 2.8107960825161986

Epoch: 6| Step: 6
Training loss: 2.9191954050292934
Validation loss: 2.810310196743258

Epoch: 6| Step: 7
Training loss: 2.9780085698011485
Validation loss: 2.812238758127607

Epoch: 6| Step: 8
Training loss: 2.8307422308925956
Validation loss: 2.8093995865327

Epoch: 6| Step: 9
Training loss: 3.0198484898133917
Validation loss: 2.809111639867939

Epoch: 6| Step: 10
Training loss: 3.5317135396897954
Validation loss: 2.8097237907585892

Epoch: 6| Step: 11
Training loss: 3.0766829002616123
Validation loss: 2.8098973855638505

Epoch: 6| Step: 12
Training loss: 3.1536839695752734
Validation loss: 2.8091101157985636

Epoch: 6| Step: 13
Training loss: 3.326700828188275
Validation loss: 2.807602062839112

Epoch: 108| Step: 0
Training loss: 3.353943874628816
Validation loss: 2.805443614653015

Epoch: 6| Step: 1
Training loss: 2.505690202480767
Validation loss: 2.8046154074992895

Epoch: 6| Step: 2
Training loss: 3.6170293060710144
Validation loss: 2.821537671040662

Epoch: 6| Step: 3
Training loss: 3.1817738579474306
Validation loss: 2.8181313745749152

Epoch: 6| Step: 4
Training loss: 2.744526357453652
Validation loss: 2.815699960295944

Epoch: 6| Step: 5
Training loss: 3.693469630410761
Validation loss: 2.813027033311339

Epoch: 6| Step: 6
Training loss: 3.3843967877335674
Validation loss: 2.815275961186075

Epoch: 6| Step: 7
Training loss: 2.999367329324753
Validation loss: 2.810424833963089

Epoch: 6| Step: 8
Training loss: 2.8031332230633375
Validation loss: 2.803217453922153

Epoch: 6| Step: 9
Training loss: 3.0298128162138904
Validation loss: 2.802129637523208

Epoch: 6| Step: 10
Training loss: 2.9208444011948345
Validation loss: 2.802413275691365

Epoch: 6| Step: 11
Training loss: 3.287585726588429
Validation loss: 2.800536300495419

Epoch: 6| Step: 12
Training loss: 2.7004036848849715
Validation loss: 2.803796336910596

Epoch: 6| Step: 13
Training loss: 3.2522182230535095
Validation loss: 2.801381527180455

Epoch: 109| Step: 0
Training loss: 3.142145955756255
Validation loss: 2.800754588124904

Epoch: 6| Step: 1
Training loss: 3.655982113667147
Validation loss: 2.800884711562179

Epoch: 6| Step: 2
Training loss: 3.0051163913319
Validation loss: 2.7988892469639146

Epoch: 6| Step: 3
Training loss: 3.3415728459937855
Validation loss: 2.7978096428800914

Epoch: 6| Step: 4
Training loss: 2.6361388070255343
Validation loss: 2.79798141962997

Epoch: 6| Step: 5
Training loss: 3.4370767506211792
Validation loss: 2.797894202600398

Epoch: 6| Step: 6
Training loss: 2.7167863441115094
Validation loss: 2.795433004977024

Epoch: 6| Step: 7
Training loss: 3.360086055289387
Validation loss: 2.7956886417524798

Epoch: 6| Step: 8
Training loss: 3.1608710877423007
Validation loss: 2.796315566944888

Epoch: 6| Step: 9
Training loss: 3.2660688618807283
Validation loss: 2.7965322094130407

Epoch: 6| Step: 10
Training loss: 3.4354705368330904
Validation loss: 2.797791433136524

Epoch: 6| Step: 11
Training loss: 2.901117201711507
Validation loss: 2.805850868097821

Epoch: 6| Step: 12
Training loss: 2.6689888161646103
Validation loss: 2.8059088000862693

Epoch: 6| Step: 13
Training loss: 1.9257473275251389
Validation loss: 2.7992752728207653

Epoch: 110| Step: 0
Training loss: 3.239068647674159
Validation loss: 2.7976603484406724

Epoch: 6| Step: 1
Training loss: 3.3675922053230463
Validation loss: 2.7964505943584252

Epoch: 6| Step: 2
Training loss: 2.8250116736246813
Validation loss: 2.798057183025901

Epoch: 6| Step: 3
Training loss: 3.6244157780752526
Validation loss: 2.8079807410570563

Epoch: 6| Step: 4
Training loss: 3.208472872255128
Validation loss: 2.805658310516162

Epoch: 6| Step: 5
Training loss: 2.83208799108029
Validation loss: 2.8037234022198794

Epoch: 6| Step: 6
Training loss: 2.931028501686354
Validation loss: 2.804230215491097

Epoch: 6| Step: 7
Training loss: 3.6822050193221574
Validation loss: 2.8187293593226643

Epoch: 6| Step: 8
Training loss: 3.216701262951797
Validation loss: 2.820538514455374

Epoch: 6| Step: 9
Training loss: 2.4443199410183722
Validation loss: 2.8137918037348677

Epoch: 6| Step: 10
Training loss: 2.486538790447997
Validation loss: 2.8030367121900728

Epoch: 6| Step: 11
Training loss: 3.4316295087327067
Validation loss: 2.8049299793585996

Epoch: 6| Step: 12
Training loss: 3.120069658039786
Validation loss: 2.799698700859508

Epoch: 6| Step: 13
Training loss: 2.627399710094142
Validation loss: 2.800691196502313

Epoch: 111| Step: 0
Training loss: 3.3764008334609503
Validation loss: 2.798083426240234

Epoch: 6| Step: 1
Training loss: 3.283777044945074
Validation loss: 2.7940530937085826

Epoch: 6| Step: 2
Training loss: 3.5160343186197593
Validation loss: 2.7949029227269944

Epoch: 6| Step: 3
Training loss: 3.5045555984499592
Validation loss: 2.79366987099305

Epoch: 6| Step: 4
Training loss: 2.488544348396867
Validation loss: 2.7911869583397717

Epoch: 6| Step: 5
Training loss: 3.0679560735609166
Validation loss: 2.793136247218632

Epoch: 6| Step: 6
Training loss: 3.2718940683299267
Validation loss: 2.791281406472835

Epoch: 6| Step: 7
Training loss: 3.108655069862816
Validation loss: 2.7928498815151612

Epoch: 6| Step: 8
Training loss: 2.6826707788092086
Validation loss: 2.7973885306792305

Epoch: 6| Step: 9
Training loss: 2.851468521032703
Validation loss: 2.7913737491581236

Epoch: 6| Step: 10
Training loss: 3.0897564013609515
Validation loss: 2.7908480482754245

Epoch: 6| Step: 11
Training loss: 3.4550993785560267
Validation loss: 2.791548228854617

Epoch: 6| Step: 12
Training loss: 2.966923041106416
Validation loss: 2.791501340775028

Epoch: 6| Step: 13
Training loss: 2.2353261777037234
Validation loss: 2.7915618297033964

Epoch: 112| Step: 0
Training loss: 2.9856622126869277
Validation loss: 2.7923166831159807

Epoch: 6| Step: 1
Training loss: 3.615605776776091
Validation loss: 2.790852167222758

Epoch: 6| Step: 2
Training loss: 2.306075166521035
Validation loss: 2.7904067455650456

Epoch: 6| Step: 3
Training loss: 3.2144132861298114
Validation loss: 2.7917054996596575

Epoch: 6| Step: 4
Training loss: 2.872191674639619
Validation loss: 2.7920948830286534

Epoch: 6| Step: 5
Training loss: 2.774966911599782
Validation loss: 2.790642234630427

Epoch: 6| Step: 6
Training loss: 2.9055992136151767
Validation loss: 2.7905957079834858

Epoch: 6| Step: 7
Training loss: 3.3140236571255484
Validation loss: 2.7891319438372855

Epoch: 6| Step: 8
Training loss: 2.7505724917901677
Validation loss: 2.7905594882074207

Epoch: 6| Step: 9
Training loss: 3.1311395987351918
Validation loss: 2.7888501290586634

Epoch: 6| Step: 10
Training loss: 3.035433684130957
Validation loss: 2.7908361203795975

Epoch: 6| Step: 11
Training loss: 3.491140187220177
Validation loss: 2.7894694853255118

Epoch: 6| Step: 12
Training loss: 3.8825398585428363
Validation loss: 2.790996844606112

Epoch: 6| Step: 13
Training loss: 2.7017408586779657
Validation loss: 2.7892484597465383

Epoch: 113| Step: 0
Training loss: 3.3063882550067647
Validation loss: 2.787539442576008

Epoch: 6| Step: 1
Training loss: 3.2260168320748233
Validation loss: 2.789109085313019

Epoch: 6| Step: 2
Training loss: 3.0030457612221197
Validation loss: 2.788495841834916

Epoch: 6| Step: 3
Training loss: 2.6282363196711542
Validation loss: 2.789297205513949

Epoch: 6| Step: 4
Training loss: 3.05061150346024
Validation loss: 2.788132154785899

Epoch: 6| Step: 5
Training loss: 3.6523761278645073
Validation loss: 2.7863487911380487

Epoch: 6| Step: 6
Training loss: 3.2664484327430507
Validation loss: 2.786082769152768

Epoch: 6| Step: 7
Training loss: 2.5412681975982037
Validation loss: 2.7860144639527498

Epoch: 6| Step: 8
Training loss: 3.081446370953184
Validation loss: 2.786147541650317

Epoch: 6| Step: 9
Training loss: 3.435775879323961
Validation loss: 2.783716102796459

Epoch: 6| Step: 10
Training loss: 2.3026989650187746
Validation loss: 2.7837711432624537

Epoch: 6| Step: 11
Training loss: 3.200017696570101
Validation loss: 2.783784868213988

Epoch: 6| Step: 12
Training loss: 3.3760300936329397
Validation loss: 2.78865318090229

Epoch: 6| Step: 13
Training loss: 3.006485445632865
Validation loss: 2.7872806900021283

Epoch: 114| Step: 0
Training loss: 2.626305754921723
Validation loss: 2.7875616803181402

Epoch: 6| Step: 1
Training loss: 3.7018550192019837
Validation loss: 2.7872108146497605

Epoch: 6| Step: 2
Training loss: 3.352642747768548
Validation loss: 2.791746774465991

Epoch: 6| Step: 3
Training loss: 2.9387188269918254
Validation loss: 2.793050226316359

Epoch: 6| Step: 4
Training loss: 3.2478225456206498
Validation loss: 2.7918187061600306

Epoch: 6| Step: 5
Training loss: 3.2807403168602605
Validation loss: 2.7910549452941247

Epoch: 6| Step: 6
Training loss: 3.0544040089840205
Validation loss: 2.786561454832894

Epoch: 6| Step: 7
Training loss: 3.096178277070117
Validation loss: 2.7869731903924295

Epoch: 6| Step: 8
Training loss: 3.2277664266077757
Validation loss: 2.78067644212089

Epoch: 6| Step: 9
Training loss: 2.257686519077995
Validation loss: 2.7861007434912155

Epoch: 6| Step: 10
Training loss: 2.636751121039716
Validation loss: 2.7810629670821103

Epoch: 6| Step: 11
Training loss: 3.6918160993127787
Validation loss: 2.7835032051343673

Epoch: 6| Step: 12
Training loss: 2.8614297790176546
Validation loss: 2.7850916813481645

Epoch: 6| Step: 13
Training loss: 2.8883227278538
Validation loss: 2.784529468475068

Epoch: 115| Step: 0
Training loss: 3.281138681612472
Validation loss: 2.7815456936035674

Epoch: 6| Step: 1
Training loss: 2.7433392749535086
Validation loss: 2.778537650378637

Epoch: 6| Step: 2
Training loss: 3.1504994495986485
Validation loss: 2.7766106793924266

Epoch: 6| Step: 3
Training loss: 3.3275297823632846
Validation loss: 2.7772253638454503

Epoch: 6| Step: 4
Training loss: 2.5465638140268805
Validation loss: 2.7767448609762027

Epoch: 6| Step: 5
Training loss: 2.6363823570136877
Validation loss: 2.776297260934169

Epoch: 6| Step: 6
Training loss: 3.786861952617385
Validation loss: 2.7777885862023965

Epoch: 6| Step: 7
Training loss: 3.0812869799021723
Validation loss: 2.776661826891536

Epoch: 6| Step: 8
Training loss: 2.8964501325521432
Validation loss: 2.774955130697227

Epoch: 6| Step: 9
Training loss: 2.6540191258055397
Validation loss: 2.776409899015117

Epoch: 6| Step: 10
Training loss: 3.2950742603784655
Validation loss: 2.774232887650681

Epoch: 6| Step: 11
Training loss: 3.006170602491512
Validation loss: 2.7779121496316477

Epoch: 6| Step: 12
Training loss: 3.0228794578472367
Validation loss: 2.7808518031924123

Epoch: 6| Step: 13
Training loss: 3.9127413105511404
Validation loss: 2.788515389268096

Epoch: 116| Step: 0
Training loss: 3.1023792181242635
Validation loss: 2.8000837783028696

Epoch: 6| Step: 1
Training loss: 2.870228664313911
Validation loss: 2.821615863814163

Epoch: 6| Step: 2
Training loss: 3.872237174249865
Validation loss: 2.8270929212257454

Epoch: 6| Step: 3
Training loss: 2.420066699850662
Validation loss: 2.773573187363266

Epoch: 6| Step: 4
Training loss: 3.504343335161862
Validation loss: 2.7758597884039005

Epoch: 6| Step: 5
Training loss: 3.250147302663938
Validation loss: 2.7771168039991516

Epoch: 6| Step: 6
Training loss: 2.814661509352669
Validation loss: 2.777470966198919

Epoch: 6| Step: 7
Training loss: 3.3069111442429127
Validation loss: 2.7792087524502045

Epoch: 6| Step: 8
Training loss: 2.8014245564700224
Validation loss: 2.7883571211778673

Epoch: 6| Step: 9
Training loss: 3.430719242146261
Validation loss: 2.790639011982812

Epoch: 6| Step: 10
Training loss: 2.990811741339021
Validation loss: 2.783205234344725

Epoch: 6| Step: 11
Training loss: 2.9043390698115954
Validation loss: 2.7770060446184783

Epoch: 6| Step: 12
Training loss: 2.756107657080803
Validation loss: 2.772631108632003

Epoch: 6| Step: 13
Training loss: 3.178867993671868
Validation loss: 2.7741678309578095

Epoch: 117| Step: 0
Training loss: 2.481588084059341
Validation loss: 2.7878465873024827

Epoch: 6| Step: 1
Training loss: 2.880449189548279
Validation loss: 2.8395624603300496

Epoch: 6| Step: 2
Training loss: 3.0470548136544164
Validation loss: 2.8654689913511144

Epoch: 6| Step: 3
Training loss: 3.663350570911213
Validation loss: 2.776398443721233

Epoch: 6| Step: 4
Training loss: 3.3551998719033
Validation loss: 2.772481849071211

Epoch: 6| Step: 5
Training loss: 2.8531498083767923
Validation loss: 2.7695008086214172

Epoch: 6| Step: 6
Training loss: 3.7637946401309694
Validation loss: 2.7688600161315304

Epoch: 6| Step: 7
Training loss: 2.840517995096801
Validation loss: 2.772840209961089

Epoch: 6| Step: 8
Training loss: 2.661460881440398
Validation loss: 2.7772308599429003

Epoch: 6| Step: 9
Training loss: 2.787252228677392
Validation loss: 2.789311725404216

Epoch: 6| Step: 10
Training loss: 3.7685345690947183
Validation loss: 2.788834889749053

Epoch: 6| Step: 11
Training loss: 2.7541454454798093
Validation loss: 2.798964907932863

Epoch: 6| Step: 12
Training loss: 3.1447841755812638
Validation loss: 2.820426577968362

Epoch: 6| Step: 13
Training loss: 2.9999663033182427
Validation loss: 2.81380494902893

Epoch: 118| Step: 0
Training loss: 2.8319317399004458
Validation loss: 2.7939760729501697

Epoch: 6| Step: 1
Training loss: 2.3968426002192613
Validation loss: 2.7800948262856857

Epoch: 6| Step: 2
Training loss: 3.2110031381102857
Validation loss: 2.7749087530697403

Epoch: 6| Step: 3
Training loss: 2.6297248824075345
Validation loss: 2.766953649906063

Epoch: 6| Step: 4
Training loss: 3.3483250772220288
Validation loss: 2.7646422172079386

Epoch: 6| Step: 5
Training loss: 2.7282765419590986
Validation loss: 2.7650096336852172

Epoch: 6| Step: 6
Training loss: 3.5123750711942865
Validation loss: 2.7647126759409413

Epoch: 6| Step: 7
Training loss: 2.936580595241035
Validation loss: 2.7657661751885563

Epoch: 6| Step: 8
Training loss: 3.3422394665088344
Validation loss: 2.7663173940865295

Epoch: 6| Step: 9
Training loss: 3.2313468874308713
Validation loss: 2.7680855788474137

Epoch: 6| Step: 10
Training loss: 3.065397021170325
Validation loss: 2.766167581610642

Epoch: 6| Step: 11
Training loss: 3.160400984709895
Validation loss: 2.7669627427681203

Epoch: 6| Step: 12
Training loss: 3.5199218262314806
Validation loss: 2.7674356156509266

Epoch: 6| Step: 13
Training loss: 2.9652274666259597
Validation loss: 2.7649032534399303

Epoch: 119| Step: 0
Training loss: 3.054765861267126
Validation loss: 2.7701221182137723

Epoch: 6| Step: 1
Training loss: 3.1542209864129576
Validation loss: 2.7697820014357517

Epoch: 6| Step: 2
Training loss: 2.9141050443023695
Validation loss: 2.771526664117502

Epoch: 6| Step: 3
Training loss: 3.0818350648507065
Validation loss: 2.7734644189337323

Epoch: 6| Step: 4
Training loss: 3.407565361621929
Validation loss: 2.7800100931064207

Epoch: 6| Step: 5
Training loss: 2.776663609747637
Validation loss: 2.780302826870486

Epoch: 6| Step: 6
Training loss: 3.612009647445215
Validation loss: 2.778953100625036

Epoch: 6| Step: 7
Training loss: 2.1743465055707754
Validation loss: 2.778394679884666

Epoch: 6| Step: 8
Training loss: 3.1020830231703345
Validation loss: 2.7744557858175116

Epoch: 6| Step: 9
Training loss: 3.337975480288439
Validation loss: 2.7728828916701356

Epoch: 6| Step: 10
Training loss: 3.2715514218875863
Validation loss: 2.768487572205984

Epoch: 6| Step: 11
Training loss: 2.9264651875526417
Validation loss: 2.7680544621497023

Epoch: 6| Step: 12
Training loss: 2.9613983681362095
Validation loss: 2.7706585802078303

Epoch: 6| Step: 13
Training loss: 3.081593684282496
Validation loss: 2.76427090124918

Epoch: 120| Step: 0
Training loss: 3.2803785347576624
Validation loss: 2.7632100174079066

Epoch: 6| Step: 1
Training loss: 3.889640101280924
Validation loss: 2.7630444693320118

Epoch: 6| Step: 2
Training loss: 2.8511892414099824
Validation loss: 2.7610035794570487

Epoch: 6| Step: 3
Training loss: 2.816505462126512
Validation loss: 2.7601147437605973

Epoch: 6| Step: 4
Training loss: 2.7025328412032263
Validation loss: 2.761009107845775

Epoch: 6| Step: 5
Training loss: 2.138388920708414
Validation loss: 2.7596847433730427

Epoch: 6| Step: 6
Training loss: 3.199106514886822
Validation loss: 2.7600386647303767

Epoch: 6| Step: 7
Training loss: 2.7757229696608734
Validation loss: 2.757429937961743

Epoch: 6| Step: 8
Training loss: 2.88430127414368
Validation loss: 2.7594366307795086

Epoch: 6| Step: 9
Training loss: 3.4886146377551186
Validation loss: 2.758950129743953

Epoch: 6| Step: 10
Training loss: 3.35144384214123
Validation loss: 2.758647034002229

Epoch: 6| Step: 11
Training loss: 2.7379659560980136
Validation loss: 2.757729008353826

Epoch: 6| Step: 12
Training loss: 2.8938204861783645
Validation loss: 2.755701589699388

Epoch: 6| Step: 13
Training loss: 3.9576487836022216
Validation loss: 2.756755263781441

Epoch: 121| Step: 0
Training loss: 3.320393783471975
Validation loss: 2.7579848038037924

Epoch: 6| Step: 1
Training loss: 2.9931729837754486
Validation loss: 2.756695713881112

Epoch: 6| Step: 2
Training loss: 3.2692357594033385
Validation loss: 2.7573351447640806

Epoch: 6| Step: 3
Training loss: 3.0991158239699366
Validation loss: 2.757755597223055

Epoch: 6| Step: 4
Training loss: 3.46493801947752
Validation loss: 2.763886609111468

Epoch: 6| Step: 5
Training loss: 2.9186762471652457
Validation loss: 2.761190578442056

Epoch: 6| Step: 6
Training loss: 2.9709527125901514
Validation loss: 2.7537150063863836

Epoch: 6| Step: 7
Training loss: 2.982573759537072
Validation loss: 2.7518449804855725

Epoch: 6| Step: 8
Training loss: 3.2159459019755903
Validation loss: 2.7530709922254952

Epoch: 6| Step: 9
Training loss: 2.651010349490909
Validation loss: 2.7543198914208533

Epoch: 6| Step: 10
Training loss: 2.8042193263769555
Validation loss: 2.7552605260422967

Epoch: 6| Step: 11
Training loss: 2.8552626758531545
Validation loss: 2.7621918839379997

Epoch: 6| Step: 12
Training loss: 3.1920501544998903
Validation loss: 2.750887663201598

Epoch: 6| Step: 13
Training loss: 3.2387267980771406
Validation loss: 2.749079717168824

Epoch: 122| Step: 0
Training loss: 2.6588546548681653
Validation loss: 2.7503942354332147

Epoch: 6| Step: 1
Training loss: 2.8998019972982907
Validation loss: 2.7482869013351094

Epoch: 6| Step: 2
Training loss: 2.807208445111082
Validation loss: 2.7499589711892036

Epoch: 6| Step: 3
Training loss: 3.4304910122612298
Validation loss: 2.749584665378525

Epoch: 6| Step: 4
Training loss: 3.1715219987145096
Validation loss: 2.748992885596941

Epoch: 6| Step: 5
Training loss: 3.2555951593078327
Validation loss: 2.748940987336735

Epoch: 6| Step: 6
Training loss: 2.8119279915555455
Validation loss: 2.7496850680801552

Epoch: 6| Step: 7
Training loss: 2.7176233346810372
Validation loss: 2.7476687100402333

Epoch: 6| Step: 8
Training loss: 2.854596256495418
Validation loss: 2.74890429612106

Epoch: 6| Step: 9
Training loss: 3.543134422592524
Validation loss: 2.7494375654949903

Epoch: 6| Step: 10
Training loss: 3.0744445795389206
Validation loss: 2.7491834123557113

Epoch: 6| Step: 11
Training loss: 3.536443351672672
Validation loss: 2.7485045229009666

Epoch: 6| Step: 12
Training loss: 2.9947826794475656
Validation loss: 2.7481061859917117

Epoch: 6| Step: 13
Training loss: 2.979577167390626
Validation loss: 2.7482133796795116

Epoch: 123| Step: 0
Training loss: 2.4051388243264102
Validation loss: 2.7485221665578017

Epoch: 6| Step: 1
Training loss: 2.8483686563330197
Validation loss: 2.755447419813301

Epoch: 6| Step: 2
Training loss: 2.520087034448185
Validation loss: 2.7492774338519905

Epoch: 6| Step: 3
Training loss: 3.1170134149188673
Validation loss: 2.750446283367561

Epoch: 6| Step: 4
Training loss: 3.5645890385046823
Validation loss: 2.7498451927665424

Epoch: 6| Step: 5
Training loss: 3.8388302960657414
Validation loss: 2.7474592717765525

Epoch: 6| Step: 6
Training loss: 3.1473583710115016
Validation loss: 2.746306353305757

Epoch: 6| Step: 7
Training loss: 3.3731633593088826
Validation loss: 2.7514328528520213

Epoch: 6| Step: 8
Training loss: 3.018127509910186
Validation loss: 2.745590565990709

Epoch: 6| Step: 9
Training loss: 2.911811183959687
Validation loss: 2.7463983524864903

Epoch: 6| Step: 10
Training loss: 2.7927119637199764
Validation loss: 2.7475426220265122

Epoch: 6| Step: 11
Training loss: 3.1260070703954908
Validation loss: 2.7476738463321215

Epoch: 6| Step: 12
Training loss: 3.027037534916435
Validation loss: 2.7485188413583526

Epoch: 6| Step: 13
Training loss: 2.812132069575218
Validation loss: 2.7493333595817906

Epoch: 124| Step: 0
Training loss: 3.2737598488081647
Validation loss: 2.7483683674427524

Epoch: 6| Step: 1
Training loss: 3.647169525884026
Validation loss: 2.751604236873378

Epoch: 6| Step: 2
Training loss: 3.081021103471877
Validation loss: 2.7510067876443087

Epoch: 6| Step: 3
Training loss: 3.315313619792705
Validation loss: 2.7517947458636782

Epoch: 6| Step: 4
Training loss: 2.806571391505382
Validation loss: 2.750398366494361

Epoch: 6| Step: 5
Training loss: 3.1684788153362904
Validation loss: 2.7478082196994844

Epoch: 6| Step: 6
Training loss: 2.884106353449507
Validation loss: 2.7516917574566455

Epoch: 6| Step: 7
Training loss: 3.02906453110424
Validation loss: 2.7471992478719804

Epoch: 6| Step: 8
Training loss: 3.1702127846142196
Validation loss: 2.7514697982551746

Epoch: 6| Step: 9
Training loss: 2.4625027961521444
Validation loss: 2.754553970340069

Epoch: 6| Step: 10
Training loss: 2.8994076485593423
Validation loss: 2.747004750642961

Epoch: 6| Step: 11
Training loss: 2.5331907014681865
Validation loss: 2.7472298019917716

Epoch: 6| Step: 12
Training loss: 3.0241668373486985
Validation loss: 2.7449992102319576

Epoch: 6| Step: 13
Training loss: 3.595497303655741
Validation loss: 2.7469101063206898

Epoch: 125| Step: 0
Training loss: 2.758581383914288
Validation loss: 2.7441754460912673

Epoch: 6| Step: 1
Training loss: 3.240346804295703
Validation loss: 2.7448597847594196

Epoch: 6| Step: 2
Training loss: 3.6824006851798976
Validation loss: 2.746374436319102

Epoch: 6| Step: 3
Training loss: 2.6694551630650674
Validation loss: 2.7436424349959725

Epoch: 6| Step: 4
Training loss: 2.4788901765231923
Validation loss: 2.746671444650483

Epoch: 6| Step: 5
Training loss: 3.00760227806349
Validation loss: 2.7444264124399878

Epoch: 6| Step: 6
Training loss: 3.240160793506001
Validation loss: 2.744002919804913

Epoch: 6| Step: 7
Training loss: 2.4787221451279695
Validation loss: 2.744727759955939

Epoch: 6| Step: 8
Training loss: 3.062868679976543
Validation loss: 2.741781054979066

Epoch: 6| Step: 9
Training loss: 2.9462999059814545
Validation loss: 2.7442677119524865

Epoch: 6| Step: 10
Training loss: 2.871451800590641
Validation loss: 2.7473917969790325

Epoch: 6| Step: 11
Training loss: 3.198274242444324
Validation loss: 2.749993046465572

Epoch: 6| Step: 12
Training loss: 3.557455004195072
Validation loss: 2.7603655008011425

Epoch: 6| Step: 13
Training loss: 3.5389576742719155
Validation loss: 2.764936182111582

Epoch: 126| Step: 0
Training loss: 2.48858008394305
Validation loss: 2.757958390039278

Epoch: 6| Step: 1
Training loss: 3.623117418450699
Validation loss: 2.749156334001078

Epoch: 6| Step: 2
Training loss: 3.2395149706203004
Validation loss: 2.73722673304207

Epoch: 6| Step: 3
Training loss: 2.814367479640021
Validation loss: 2.735560418460524

Epoch: 6| Step: 4
Training loss: 3.451942068619487
Validation loss: 2.7374843281366474

Epoch: 6| Step: 5
Training loss: 3.345129566277747
Validation loss: 2.7416083340673563

Epoch: 6| Step: 6
Training loss: 2.6665022521196344
Validation loss: 2.7415056288003035

Epoch: 6| Step: 7
Training loss: 3.815815218996127
Validation loss: 2.740367911030506

Epoch: 6| Step: 8
Training loss: 2.1615427268837513
Validation loss: 2.747515896065913

Epoch: 6| Step: 9
Training loss: 3.48918579266389
Validation loss: 2.745478028661646

Epoch: 6| Step: 10
Training loss: 2.8936265362957907
Validation loss: 2.7432854427610747

Epoch: 6| Step: 11
Training loss: 2.985429188146817
Validation loss: 2.74199621693079

Epoch: 6| Step: 12
Training loss: 2.4639385030119474
Validation loss: 2.7382363952105866

Epoch: 6| Step: 13
Training loss: 2.980737996470182
Validation loss: 2.737076087446166

Epoch: 127| Step: 0
Training loss: 2.40928567406587
Validation loss: 2.7407572799067674

Epoch: 6| Step: 1
Training loss: 3.18899740314348
Validation loss: 2.741008782756849

Epoch: 6| Step: 2
Training loss: 3.2505300529767718
Validation loss: 2.7442047811140835

Epoch: 6| Step: 3
Training loss: 3.2782849675541037
Validation loss: 2.751763399300532

Epoch: 6| Step: 4
Training loss: 2.651598189321128
Validation loss: 2.757309866523521

Epoch: 6| Step: 5
Training loss: 2.695223334122941
Validation loss: 2.763098866649519

Epoch: 6| Step: 6
Training loss: 3.3765218623733153
Validation loss: 2.7896086414114913

Epoch: 6| Step: 7
Training loss: 2.984849822133998
Validation loss: 2.805028836991882

Epoch: 6| Step: 8
Training loss: 2.97640486172142
Validation loss: 2.7758432457571556

Epoch: 6| Step: 9
Training loss: 3.8379338618747716
Validation loss: 2.750492512366996

Epoch: 6| Step: 10
Training loss: 2.563408295221948
Validation loss: 2.739359523003656

Epoch: 6| Step: 11
Training loss: 2.671197816573785
Validation loss: 2.735608686605857

Epoch: 6| Step: 12
Training loss: 3.2114756335100703
Validation loss: 2.7347534386587147

Epoch: 6| Step: 13
Training loss: 3.597874936095769
Validation loss: 2.737180620915263

Epoch: 128| Step: 0
Training loss: 3.1060343677120192
Validation loss: 2.7347203715437

Epoch: 6| Step: 1
Training loss: 3.78827135144162
Validation loss: 2.737090992543017

Epoch: 6| Step: 2
Training loss: 2.948418636292001
Validation loss: 2.740249869622121

Epoch: 6| Step: 3
Training loss: 3.150596767995999
Validation loss: 2.74394516727396

Epoch: 6| Step: 4
Training loss: 3.1505961626031302
Validation loss: 2.7510094323519336

Epoch: 6| Step: 5
Training loss: 2.979970827919949
Validation loss: 2.7429909623007536

Epoch: 6| Step: 6
Training loss: 2.2454270409958874
Validation loss: 2.738288251063227

Epoch: 6| Step: 7
Training loss: 2.582308617264754
Validation loss: 2.7388552009974445

Epoch: 6| Step: 8
Training loss: 3.459945915549171
Validation loss: 2.7390101660719077

Epoch: 6| Step: 9
Training loss: 3.222214547144493
Validation loss: 2.7367029156122187

Epoch: 6| Step: 10
Training loss: 2.4369482736463106
Validation loss: 2.7352087040805535

Epoch: 6| Step: 11
Training loss: 2.88066670436222
Validation loss: 2.73505896386239

Epoch: 6| Step: 12
Training loss: 3.1896743837828567
Validation loss: 2.7333613810186943

Epoch: 6| Step: 13
Training loss: 3.7797229299978152
Validation loss: 2.732160039005722

Epoch: 129| Step: 0
Training loss: 3.2854564044285217
Validation loss: 2.732520017742441

Epoch: 6| Step: 1
Training loss: 3.4028887481933
Validation loss: 2.7306786821362414

Epoch: 6| Step: 2
Training loss: 3.080220704778949
Validation loss: 2.7316935405617935

Epoch: 6| Step: 3
Training loss: 3.3524675192173343
Validation loss: 2.7294759687036168

Epoch: 6| Step: 4
Training loss: 3.216894411184483
Validation loss: 2.7286790194342054

Epoch: 6| Step: 5
Training loss: 3.3537940219146827
Validation loss: 2.733489861972372

Epoch: 6| Step: 6
Training loss: 3.040430540666836
Validation loss: 2.7283116021677363

Epoch: 6| Step: 7
Training loss: 2.87283293279533
Validation loss: 2.7293913049843295

Epoch: 6| Step: 8
Training loss: 2.8514723672078093
Validation loss: 2.7302976805813888

Epoch: 6| Step: 9
Training loss: 2.765761808470691
Validation loss: 2.7319318178314744

Epoch: 6| Step: 10
Training loss: 3.176728242302047
Validation loss: 2.7311135957625052

Epoch: 6| Step: 11
Training loss: 3.1541916584618868
Validation loss: 2.7308595246770047

Epoch: 6| Step: 12
Training loss: 2.7953814562527803
Validation loss: 2.730441726409304

Epoch: 6| Step: 13
Training loss: 1.2010124783086054
Validation loss: 2.732999024504731

Epoch: 130| Step: 0
Training loss: 2.5836706454008898
Validation loss: 2.7338740157955166

Epoch: 6| Step: 1
Training loss: 2.505184519780811
Validation loss: 2.7371683252159595

Epoch: 6| Step: 2
Training loss: 3.1184143864346288
Validation loss: 2.739743474195069

Epoch: 6| Step: 3
Training loss: 3.5828125745304997
Validation loss: 2.739654568786661

Epoch: 6| Step: 4
Training loss: 3.343851105774647
Validation loss: 2.749213088389287

Epoch: 6| Step: 5
Training loss: 2.520621508901663
Validation loss: 2.737367301208613

Epoch: 6| Step: 6
Training loss: 3.197318121514657
Validation loss: 2.741791744192401

Epoch: 6| Step: 7
Training loss: 3.0156452395693862
Validation loss: 2.7315306999874074

Epoch: 6| Step: 8
Training loss: 2.7441126486007184
Validation loss: 2.72849492799919

Epoch: 6| Step: 9
Training loss: 3.1697031487423963
Validation loss: 2.732569357987547

Epoch: 6| Step: 10
Training loss: 3.0433564043232515
Validation loss: 2.727789565149874

Epoch: 6| Step: 11
Training loss: 3.403046948086933
Validation loss: 2.730375057310459

Epoch: 6| Step: 12
Training loss: 3.1937571426580478
Validation loss: 2.726649840911986

Epoch: 6| Step: 13
Training loss: 3.033824653099918
Validation loss: 2.726460780364132

Epoch: 131| Step: 0
Training loss: 2.9661289892257043
Validation loss: 2.723639122684997

Epoch: 6| Step: 1
Training loss: 3.0771743158325515
Validation loss: 2.7350683258539163

Epoch: 6| Step: 2
Training loss: 3.0959769816762748
Validation loss: 2.759364985619929

Epoch: 6| Step: 3
Training loss: 3.775593080731435
Validation loss: 2.8079562419456803

Epoch: 6| Step: 4
Training loss: 3.2016912461435636
Validation loss: 2.7947365422668797

Epoch: 6| Step: 5
Training loss: 2.8176742429427963
Validation loss: 2.751927527163915

Epoch: 6| Step: 6
Training loss: 2.7216100447730063
Validation loss: 2.739897577336144

Epoch: 6| Step: 7
Training loss: 3.455865247395259
Validation loss: 2.74289211376274

Epoch: 6| Step: 8
Training loss: 2.530605092722873
Validation loss: 2.7305305459059155

Epoch: 6| Step: 9
Training loss: 2.796984111000186
Validation loss: 2.719673008074003

Epoch: 6| Step: 10
Training loss: 3.1711671537374624
Validation loss: 2.7194779830773297

Epoch: 6| Step: 11
Training loss: 3.3849359415549025
Validation loss: 2.7220283679178183

Epoch: 6| Step: 12
Training loss: 2.6555634452812575
Validation loss: 2.7237169012914775

Epoch: 6| Step: 13
Training loss: 2.684721197645695
Validation loss: 2.7209572851744532

Epoch: 132| Step: 0
Training loss: 3.1326643987261686
Validation loss: 2.7195763780057445

Epoch: 6| Step: 1
Training loss: 3.266900940363878
Validation loss: 2.7199837904078557

Epoch: 6| Step: 2
Training loss: 3.0813275248154888
Validation loss: 2.7211550140086245

Epoch: 6| Step: 3
Training loss: 3.076534266848457
Validation loss: 2.7209878023218512

Epoch: 6| Step: 4
Training loss: 3.2027346489472683
Validation loss: 2.7244938406940378

Epoch: 6| Step: 5
Training loss: 3.5030790137097885
Validation loss: 2.7273341883107074

Epoch: 6| Step: 6
Training loss: 2.4124465027248836
Validation loss: 2.7205479755967357

Epoch: 6| Step: 7
Training loss: 3.265515339301498
Validation loss: 2.7237037409993983

Epoch: 6| Step: 8
Training loss: 2.6976876671025245
Validation loss: 2.7207677386067637

Epoch: 6| Step: 9
Training loss: 3.339938549458681
Validation loss: 2.7238730090172076

Epoch: 6| Step: 10
Training loss: 2.909938317657823
Validation loss: 2.734898042828019

Epoch: 6| Step: 11
Training loss: 2.410472187621621
Validation loss: 2.73177345099246

Epoch: 6| Step: 12
Training loss: 3.1739981925589036
Validation loss: 2.729998041495798

Epoch: 6| Step: 13
Training loss: 2.721555555761617
Validation loss: 2.748206602595782

Epoch: 133| Step: 0
Training loss: 2.9417082490944826
Validation loss: 2.737654856708317

Epoch: 6| Step: 1
Training loss: 3.359817262857449
Validation loss: 2.7236360993702626

Epoch: 6| Step: 2
Training loss: 3.185838602952909
Validation loss: 2.719704943660638

Epoch: 6| Step: 3
Training loss: 2.8801617931908017
Validation loss: 2.7122094482410066

Epoch: 6| Step: 4
Training loss: 2.6796217484929357
Validation loss: 2.717879113786321

Epoch: 6| Step: 5
Training loss: 3.2138002725391104
Validation loss: 2.7135624978743254

Epoch: 6| Step: 6
Training loss: 3.445383499348159
Validation loss: 2.7120701198523096

Epoch: 6| Step: 7
Training loss: 2.2866336578603947
Validation loss: 2.7126153463864835

Epoch: 6| Step: 8
Training loss: 3.309156349746913
Validation loss: 2.714731157231014

Epoch: 6| Step: 9
Training loss: 2.4242944261182586
Validation loss: 2.712285446823601

Epoch: 6| Step: 10
Training loss: 3.178750839803317
Validation loss: 2.712781319231264

Epoch: 6| Step: 11
Training loss: 2.726336450688413
Validation loss: 2.7120334147395693

Epoch: 6| Step: 12
Training loss: 3.408370451659002
Validation loss: 2.711244637660887

Epoch: 6| Step: 13
Training loss: 3.3498851073191704
Validation loss: 2.7110979368969113

Epoch: 134| Step: 0
Training loss: 3.14787859250936
Validation loss: 2.7128983559103292

Epoch: 6| Step: 1
Training loss: 2.8981823256209234
Validation loss: 2.713457059734969

Epoch: 6| Step: 2
Training loss: 3.492625642126221
Validation loss: 2.7123595226921653

Epoch: 6| Step: 3
Training loss: 3.1451533679531076
Validation loss: 2.7142047173956882

Epoch: 6| Step: 4
Training loss: 3.241078970884204
Validation loss: 2.7131527993330584

Epoch: 6| Step: 5
Training loss: 2.5893895828385203
Validation loss: 2.713772237696828

Epoch: 6| Step: 6
Training loss: 3.001215688437022
Validation loss: 2.7114219817740257

Epoch: 6| Step: 7
Training loss: 2.7549960097268453
Validation loss: 2.7165198367650314

Epoch: 6| Step: 8
Training loss: 3.152793729259079
Validation loss: 2.7148924530398797

Epoch: 6| Step: 9
Training loss: 3.267731639587219
Validation loss: 2.7151193871472024

Epoch: 6| Step: 10
Training loss: 3.4496964915466206
Validation loss: 2.7187280933373077

Epoch: 6| Step: 11
Training loss: 2.651297046724162
Validation loss: 2.716644527944768

Epoch: 6| Step: 12
Training loss: 2.6480617200337138
Validation loss: 2.7178934681334184

Epoch: 6| Step: 13
Training loss: 2.787023659278904
Validation loss: 2.7195805502234625

Epoch: 135| Step: 0
Training loss: 2.540393938018481
Validation loss: 2.722388582697021

Epoch: 6| Step: 1
Training loss: 3.3028739841039356
Validation loss: 2.7232523954174006

Epoch: 6| Step: 2
Training loss: 3.07360461449304
Validation loss: 2.7240719886904414

Epoch: 6| Step: 3
Training loss: 3.266402886568467
Validation loss: 2.722115240268321

Epoch: 6| Step: 4
Training loss: 2.9492937697412196
Validation loss: 2.7183733471652536

Epoch: 6| Step: 5
Training loss: 3.1154504970094465
Validation loss: 2.7137173815865947

Epoch: 6| Step: 6
Training loss: 2.926734188520356
Validation loss: 2.7233558723741633

Epoch: 6| Step: 7
Training loss: 3.0030710078535354
Validation loss: 2.7172370409522038

Epoch: 6| Step: 8
Training loss: 3.1938622501601484
Validation loss: 2.7276927277806604

Epoch: 6| Step: 9
Training loss: 3.424199677679032
Validation loss: 2.7184102797715357

Epoch: 6| Step: 10
Training loss: 2.5782589039563266
Validation loss: 2.715684025951594

Epoch: 6| Step: 11
Training loss: 3.1718458352838677
Validation loss: 2.711738196064629

Epoch: 6| Step: 12
Training loss: 2.846288700636428
Validation loss: 2.7122881973417936

Epoch: 6| Step: 13
Training loss: 2.8990520638050543
Validation loss: 2.7083064668772665

Epoch: 136| Step: 0
Training loss: 3.4623163718547554
Validation loss: 2.7098520726704507

Epoch: 6| Step: 1
Training loss: 2.726538540535399
Validation loss: 2.7089221642389854

Epoch: 6| Step: 2
Training loss: 3.112799211084427
Validation loss: 2.715588192795519

Epoch: 6| Step: 3
Training loss: 3.071817043995659
Validation loss: 2.7186734616966777

Epoch: 6| Step: 4
Training loss: 3.418050222243281
Validation loss: 2.725006500105431

Epoch: 6| Step: 5
Training loss: 3.0383428589432118
Validation loss: 2.7373347685945566

Epoch: 6| Step: 6
Training loss: 3.400080001114246
Validation loss: 2.7632073027332575

Epoch: 6| Step: 7
Training loss: 3.1578612794274896
Validation loss: 2.756783848392614

Epoch: 6| Step: 8
Training loss: 3.2823109682597713
Validation loss: 2.7314510593311834

Epoch: 6| Step: 9
Training loss: 1.9692567445630547
Validation loss: 2.7060150273723305

Epoch: 6| Step: 10
Training loss: 2.8763613587547887
Validation loss: 2.7158593876701

Epoch: 6| Step: 11
Training loss: 2.904320517304577
Validation loss: 2.7108055225179677

Epoch: 6| Step: 12
Training loss: 2.933521579713123
Validation loss: 2.7133161202159592

Epoch: 6| Step: 13
Training loss: 2.6541498296454153
Validation loss: 2.711074290876446

Epoch: 137| Step: 0
Training loss: 3.4391076230144035
Validation loss: 2.7197595998266713

Epoch: 6| Step: 1
Training loss: 2.679532060480126
Validation loss: 2.7176219074084456

Epoch: 6| Step: 2
Training loss: 2.5134796092760205
Validation loss: 2.718672165105982

Epoch: 6| Step: 3
Training loss: 2.5976666213667485
Validation loss: 2.713909166247382

Epoch: 6| Step: 4
Training loss: 2.887633223990108
Validation loss: 2.7145356803863447

Epoch: 6| Step: 5
Training loss: 3.7233249508027124
Validation loss: 2.7108736705958068

Epoch: 6| Step: 6
Training loss: 3.0552136682688587
Validation loss: 2.7116780442371287

Epoch: 6| Step: 7
Training loss: 3.2577135542153424
Validation loss: 2.7171687647045832

Epoch: 6| Step: 8
Training loss: 2.603364612409346
Validation loss: 2.7125561515508454

Epoch: 6| Step: 9
Training loss: 2.931477643183613
Validation loss: 2.710431671069519

Epoch: 6| Step: 10
Training loss: 3.1892053866488403
Validation loss: 2.7111371567231126

Epoch: 6| Step: 11
Training loss: 3.1775091334105894
Validation loss: 2.7139580107476835

Epoch: 6| Step: 12
Training loss: 3.3480111894318014
Validation loss: 2.714215353697529

Epoch: 6| Step: 13
Training loss: 2.8083311761985517
Validation loss: 2.7193495980684737

Epoch: 138| Step: 0
Training loss: 2.91114051098655
Validation loss: 2.71899644062195

Epoch: 6| Step: 1
Training loss: 2.4956136370103312
Validation loss: 2.7260386205246308

Epoch: 6| Step: 2
Training loss: 2.9989669928647085
Validation loss: 2.721570404092387

Epoch: 6| Step: 3
Training loss: 3.106153803665615
Validation loss: 2.7253563747140377

Epoch: 6| Step: 4
Training loss: 3.454319259776362
Validation loss: 2.7180231848678362

Epoch: 6| Step: 5
Training loss: 3.2984450520438475
Validation loss: 2.7174679500084062

Epoch: 6| Step: 6
Training loss: 3.0668752129451473
Validation loss: 2.7121537164210965

Epoch: 6| Step: 7
Training loss: 2.4155360789051428
Validation loss: 2.7095105120531353

Epoch: 6| Step: 8
Training loss: 2.733352906071746
Validation loss: 2.7109196164567724

Epoch: 6| Step: 9
Training loss: 3.3206669158271716
Validation loss: 2.7087002419698036

Epoch: 6| Step: 10
Training loss: 2.948802388086868
Validation loss: 2.705805824150281

Epoch: 6| Step: 11
Training loss: 2.756341039144515
Validation loss: 2.7103963407958234

Epoch: 6| Step: 12
Training loss: 3.6274852783409166
Validation loss: 2.7073466192387854

Epoch: 6| Step: 13
Training loss: 3.096333975548304
Validation loss: 2.712551376894335

Epoch: 139| Step: 0
Training loss: 2.996836583882753
Validation loss: 2.7351479521020208

Epoch: 6| Step: 1
Training loss: 2.601838151687788
Validation loss: 2.793695498381737

Epoch: 6| Step: 2
Training loss: 3.520743615325944
Validation loss: 2.851097978242345

Epoch: 6| Step: 3
Training loss: 3.1366473008090745
Validation loss: 2.7685149031864893

Epoch: 6| Step: 4
Training loss: 3.0947673935753093
Validation loss: 2.7167761878046677

Epoch: 6| Step: 5
Training loss: 3.5423832486336364
Validation loss: 2.7044125222695468

Epoch: 6| Step: 6
Training loss: 2.241090619217282
Validation loss: 2.70454284672042

Epoch: 6| Step: 7
Training loss: 3.348251307691525
Validation loss: 2.703268917590782

Epoch: 6| Step: 8
Training loss: 3.4568115164542204
Validation loss: 2.705012337679222

Epoch: 6| Step: 9
Training loss: 2.8690252832712724
Validation loss: 2.707471465867129

Epoch: 6| Step: 10
Training loss: 2.631004187910806
Validation loss: 2.715804144211064

Epoch: 6| Step: 11
Training loss: 2.688633169759907
Validation loss: 2.7159018472387144

Epoch: 6| Step: 12
Training loss: 3.039150521148591
Validation loss: 2.718390307443874

Epoch: 6| Step: 13
Training loss: 3.273518636421746
Validation loss: 2.7059623000932103

Epoch: 140| Step: 0
Training loss: 2.770004167519199
Validation loss: 2.7056589369839394

Epoch: 6| Step: 1
Training loss: 2.8744950887731324
Validation loss: 2.705530696433312

Epoch: 6| Step: 2
Training loss: 3.1389848212452085
Validation loss: 2.7072313652596494

Epoch: 6| Step: 3
Training loss: 2.8518353893397537
Validation loss: 2.7158660019330254

Epoch: 6| Step: 4
Training loss: 2.6877542419825904
Validation loss: 2.726977155691865

Epoch: 6| Step: 5
Training loss: 3.0090587857843776
Validation loss: 2.7327930586780305

Epoch: 6| Step: 6
Training loss: 3.25403168838349
Validation loss: 2.7331097522531813

Epoch: 6| Step: 7
Training loss: 2.647753601895867
Validation loss: 2.7239975838298043

Epoch: 6| Step: 8
Training loss: 3.540828441084704
Validation loss: 2.712198134852661

Epoch: 6| Step: 9
Training loss: 2.9822165787642336
Validation loss: 2.7116327853138027

Epoch: 6| Step: 10
Training loss: 3.300278917720958
Validation loss: 2.7114659054146544

Epoch: 6| Step: 11
Training loss: 2.9644472764284613
Validation loss: 2.7265068763347764

Epoch: 6| Step: 12
Training loss: 3.2858607277311522
Validation loss: 2.716047928910446

Epoch: 6| Step: 13
Training loss: 2.7704834585695983
Validation loss: 2.7329374795299692

Epoch: 141| Step: 0
Training loss: 2.851830038819372
Validation loss: 2.7518635976756842

Epoch: 6| Step: 1
Training loss: 3.643518435937655
Validation loss: 2.7444730968683775

Epoch: 6| Step: 2
Training loss: 3.2728646808253683
Validation loss: 2.7534318198632057

Epoch: 6| Step: 3
Training loss: 3.0980738470192204
Validation loss: 2.7406822102176562

Epoch: 6| Step: 4
Training loss: 3.1157441968700814
Validation loss: 2.7218893038503817

Epoch: 6| Step: 5
Training loss: 3.134924122258677
Validation loss: 2.7201769889502896

Epoch: 6| Step: 6
Training loss: 2.9526788283673473
Validation loss: 2.7165332526896226

Epoch: 6| Step: 7
Training loss: 2.593874273425351
Validation loss: 2.7113264650657816

Epoch: 6| Step: 8
Training loss: 2.6536738750160365
Validation loss: 2.715796650958105

Epoch: 6| Step: 9
Training loss: 3.0982697734363382
Validation loss: 2.7116670472353266

Epoch: 6| Step: 10
Training loss: 2.7412295502240385
Validation loss: 2.714552663697953

Epoch: 6| Step: 11
Training loss: 3.030215686637495
Validation loss: 2.7204356236247675

Epoch: 6| Step: 12
Training loss: 3.039567998507964
Validation loss: 2.722257448544282

Epoch: 6| Step: 13
Training loss: 3.100341710361666
Validation loss: 2.7119319149071677

Epoch: 142| Step: 0
Training loss: 2.208778864224511
Validation loss: 2.7122942229517983

Epoch: 6| Step: 1
Training loss: 3.7203750265443354
Validation loss: 2.7086237263452078

Epoch: 6| Step: 2
Training loss: 2.439748069702223
Validation loss: 2.7001776283989205

Epoch: 6| Step: 3
Training loss: 3.4182770508277733
Validation loss: 2.703491302771558

Epoch: 6| Step: 4
Training loss: 3.1563690465250303
Validation loss: 2.6980819648342886

Epoch: 6| Step: 5
Training loss: 3.0796766678664618
Validation loss: 2.6993430123737916

Epoch: 6| Step: 6
Training loss: 2.878266344938353
Validation loss: 2.69732845721779

Epoch: 6| Step: 7
Training loss: 2.9604027901918655
Validation loss: 2.7002012540129607

Epoch: 6| Step: 8
Training loss: 3.4956609532652196
Validation loss: 2.6996183481139906

Epoch: 6| Step: 9
Training loss: 3.0956039268412554
Validation loss: 2.6969200900776507

Epoch: 6| Step: 10
Training loss: 2.414841806984215
Validation loss: 2.701833421746281

Epoch: 6| Step: 11
Training loss: 2.6567288135485363
Validation loss: 2.7072120528823347

Epoch: 6| Step: 12
Training loss: 3.168203248777061
Validation loss: 2.7190773775898656

Epoch: 6| Step: 13
Training loss: 3.285152766422053
Validation loss: 2.7179263607895603

Epoch: 143| Step: 0
Training loss: 2.7382267444535207
Validation loss: 2.71023076012058

Epoch: 6| Step: 1
Training loss: 2.604456303066442
Validation loss: 2.7100975771247104

Epoch: 6| Step: 2
Training loss: 3.185256317939597
Validation loss: 2.7063611222778716

Epoch: 6| Step: 3
Training loss: 3.5535030865036568
Validation loss: 2.7058898918470495

Epoch: 6| Step: 4
Training loss: 2.4491495369070626
Validation loss: 2.6990442495177085

Epoch: 6| Step: 5
Training loss: 3.016502134216454
Validation loss: 2.69574678764587

Epoch: 6| Step: 6
Training loss: 2.9881204000827384
Validation loss: 2.694001084552524

Epoch: 6| Step: 7
Training loss: 3.251017337908901
Validation loss: 2.694980020036733

Epoch: 6| Step: 8
Training loss: 3.035408235397272
Validation loss: 2.6931153165974218

Epoch: 6| Step: 9
Training loss: 3.101416596408806
Validation loss: 2.6924562533586025

Epoch: 6| Step: 10
Training loss: 3.2257365723701263
Validation loss: 2.694944116196137

Epoch: 6| Step: 11
Training loss: 2.688624745479215
Validation loss: 2.6946008347587793

Epoch: 6| Step: 12
Training loss: 3.120203533380744
Validation loss: 2.6927047510175433

Epoch: 6| Step: 13
Training loss: 3.1461188247852254
Validation loss: 2.6941851159968317

Epoch: 144| Step: 0
Training loss: 2.024883563614834
Validation loss: 2.6893036340178296

Epoch: 6| Step: 1
Training loss: 3.0839727786850535
Validation loss: 2.6932801124157866

Epoch: 6| Step: 2
Training loss: 3.161393459771009
Validation loss: 2.691754271816555

Epoch: 6| Step: 3
Training loss: 2.7775494248518995
Validation loss: 2.6930449113909756

Epoch: 6| Step: 4
Training loss: 3.714671743684774
Validation loss: 2.6946937891225513

Epoch: 6| Step: 5
Training loss: 2.9890237920381493
Validation loss: 2.7022523872203337

Epoch: 6| Step: 6
Training loss: 2.9834855436854193
Validation loss: 2.702024714967801

Epoch: 6| Step: 7
Training loss: 3.214200851288973
Validation loss: 2.7093953122748875

Epoch: 6| Step: 8
Training loss: 3.045746736213033
Validation loss: 2.6922591325382634

Epoch: 6| Step: 9
Training loss: 3.3895076193830085
Validation loss: 2.696540557269431

Epoch: 6| Step: 10
Training loss: 3.0377866130974156
Validation loss: 2.6957350162090217

Epoch: 6| Step: 11
Training loss: 2.5134927942230765
Validation loss: 2.6911934429531437

Epoch: 6| Step: 12
Training loss: 3.1623553156267796
Validation loss: 2.6879288936188

Epoch: 6| Step: 13
Training loss: 2.747802463228135
Validation loss: 2.68772929559155

Epoch: 145| Step: 0
Training loss: 2.847865218670107
Validation loss: 2.687684598679817

Epoch: 6| Step: 1
Training loss: 3.085458761817118
Validation loss: 2.6845353877022564

Epoch: 6| Step: 2
Training loss: 3.1403948191845763
Validation loss: 2.685226085129604

Epoch: 6| Step: 3
Training loss: 3.02799277946992
Validation loss: 2.6866394004343035

Epoch: 6| Step: 4
Training loss: 3.122986259134621
Validation loss: 2.6854261575156264

Epoch: 6| Step: 5
Training loss: 2.8065126054060365
Validation loss: 2.683475326325574

Epoch: 6| Step: 6
Training loss: 3.1794175541892447
Validation loss: 2.685100411839959

Epoch: 6| Step: 7
Training loss: 2.6556243159579864
Validation loss: 2.682986891184298

Epoch: 6| Step: 8
Training loss: 2.9902509592943107
Validation loss: 2.6854206310442064

Epoch: 6| Step: 9
Training loss: 3.286471036875375
Validation loss: 2.6849934592906073

Epoch: 6| Step: 10
Training loss: 3.179058340751067
Validation loss: 2.686752950019269

Epoch: 6| Step: 11
Training loss: 3.121658522362242
Validation loss: 2.6845622946958776

Epoch: 6| Step: 12
Training loss: 2.8529988890872024
Validation loss: 2.6891635249704064

Epoch: 6| Step: 13
Training loss: 2.690337346702547
Validation loss: 2.688672823119135

Epoch: 146| Step: 0
Training loss: 2.877259900427303
Validation loss: 2.6895157117468638

Epoch: 6| Step: 1
Training loss: 2.7852397119715406
Validation loss: 2.6862902616948334

Epoch: 6| Step: 2
Training loss: 2.7922813156411572
Validation loss: 2.684948269979395

Epoch: 6| Step: 3
Training loss: 2.9776955197804407
Validation loss: 2.685581139428896

Epoch: 6| Step: 4
Training loss: 2.921618771665503
Validation loss: 2.6812012203854616

Epoch: 6| Step: 5
Training loss: 2.9170773534918273
Validation loss: 2.681969117984521

Epoch: 6| Step: 6
Training loss: 2.86132912489317
Validation loss: 2.678709957488139

Epoch: 6| Step: 7
Training loss: 2.81351528915663
Validation loss: 2.6804644772697737

Epoch: 6| Step: 8
Training loss: 2.6932435871820917
Validation loss: 2.6803245345701465

Epoch: 6| Step: 9
Training loss: 3.206792899229285
Validation loss: 2.6851943395275724

Epoch: 6| Step: 10
Training loss: 3.388363413554463
Validation loss: 2.6813606791436584

Epoch: 6| Step: 11
Training loss: 3.2054693807312624
Validation loss: 2.684678182869597

Epoch: 6| Step: 12
Training loss: 3.281805663516037
Validation loss: 2.687746842216973

Epoch: 6| Step: 13
Training loss: 3.421382363448509
Validation loss: 2.679477243920487

Epoch: 147| Step: 0
Training loss: 2.0025149268881037
Validation loss: 2.6859985835594884

Epoch: 6| Step: 1
Training loss: 2.278362170773861
Validation loss: 2.6846548159872063

Epoch: 6| Step: 2
Training loss: 3.551648662443337
Validation loss: 2.6897115438847288

Epoch: 6| Step: 3
Training loss: 2.9727848942474497
Validation loss: 2.687291594406876

Epoch: 6| Step: 4
Training loss: 3.1322606996799096
Validation loss: 2.691706466367861

Epoch: 6| Step: 5
Training loss: 2.0608562508416983
Validation loss: 2.6942577978937847

Epoch: 6| Step: 6
Training loss: 3.2113601146571438
Validation loss: 2.68919553735617

Epoch: 6| Step: 7
Training loss: 3.701247628677263
Validation loss: 2.6960067228305435

Epoch: 6| Step: 8
Training loss: 3.1737222037613737
Validation loss: 2.6871081946854303

Epoch: 6| Step: 9
Training loss: 3.3321518870581652
Validation loss: 2.6854284649023836

Epoch: 6| Step: 10
Training loss: 2.9208829286929463
Validation loss: 2.6811377138127446

Epoch: 6| Step: 11
Training loss: 3.049142785852382
Validation loss: 2.680524071880049

Epoch: 6| Step: 12
Training loss: 2.842833654302544
Validation loss: 2.6829691720112803

Epoch: 6| Step: 13
Training loss: 3.3297264293756057
Validation loss: 2.684523668331115

Epoch: 148| Step: 0
Training loss: 3.152660027843102
Validation loss: 2.681589743484134

Epoch: 6| Step: 1
Training loss: 3.1899431626568906
Validation loss: 2.6846990085395497

Epoch: 6| Step: 2
Training loss: 3.602112171652622
Validation loss: 2.6781129803717283

Epoch: 6| Step: 3
Training loss: 2.299583654452624
Validation loss: 2.681113413913416

Epoch: 6| Step: 4
Training loss: 2.4780975301790664
Validation loss: 2.681245011870176

Epoch: 6| Step: 5
Training loss: 3.0045298709079633
Validation loss: 2.6848998878908064

Epoch: 6| Step: 6
Training loss: 2.7684969887616324
Validation loss: 2.6763993060453535

Epoch: 6| Step: 7
Training loss: 2.814218547080379
Validation loss: 2.6764573067955357

Epoch: 6| Step: 8
Training loss: 3.0686215313593443
Validation loss: 2.678674338024644

Epoch: 6| Step: 9
Training loss: 2.416267844428781
Validation loss: 2.6779463762102664

Epoch: 6| Step: 10
Training loss: 2.952905232966404
Validation loss: 2.675168456994199

Epoch: 6| Step: 11
Training loss: 3.210261438484095
Validation loss: 2.6861733216692847

Epoch: 6| Step: 12
Training loss: 4.017287804365102
Validation loss: 2.705808466612714

Epoch: 6| Step: 13
Training loss: 2.1628125709034314
Validation loss: 2.717508443914051

Epoch: 149| Step: 0
Training loss: 3.037147369637743
Validation loss: 2.7498349282846903

Epoch: 6| Step: 1
Training loss: 3.076808899815106
Validation loss: 2.7482675948148994

Epoch: 6| Step: 2
Training loss: 2.8820005684613124
Validation loss: 2.6902963428123323

Epoch: 6| Step: 3
Training loss: 3.223327936630176
Validation loss: 2.6861460166064384

Epoch: 6| Step: 4
Training loss: 2.367467076879301
Validation loss: 2.694026190784334

Epoch: 6| Step: 5
Training loss: 3.1528570993297405
Validation loss: 2.688894289348543

Epoch: 6| Step: 6
Training loss: 2.675817603539544
Validation loss: 2.6974450771124108

Epoch: 6| Step: 7
Training loss: 3.0304805132880257
Validation loss: 2.6950422767694264

Epoch: 6| Step: 8
Training loss: 3.3592885560734893
Validation loss: 2.70056323155237

Epoch: 6| Step: 9
Training loss: 3.2838088457739887
Validation loss: 2.691650804341922

Epoch: 6| Step: 10
Training loss: 3.443725497233043
Validation loss: 2.6875144813111196

Epoch: 6| Step: 11
Training loss: 2.7807098892914595
Validation loss: 2.683792655468248

Epoch: 6| Step: 12
Training loss: 2.6542907669861657
Validation loss: 2.687342574976434

Epoch: 6| Step: 13
Training loss: 2.9729433660415445
Validation loss: 2.6839342999975138

Epoch: 150| Step: 0
Training loss: 2.584197320330875
Validation loss: 2.6840353188990727

Epoch: 6| Step: 1
Training loss: 2.9415628459933862
Validation loss: 2.6857371585737027

Epoch: 6| Step: 2
Training loss: 2.6821602403361524
Validation loss: 2.6786404197546783

Epoch: 6| Step: 3
Training loss: 2.933534258405594
Validation loss: 2.681079825311735

Epoch: 6| Step: 4
Training loss: 3.173714240745247
Validation loss: 2.679143011241675

Epoch: 6| Step: 5
Training loss: 3.0132819842574294
Validation loss: 2.6824250760439354

Epoch: 6| Step: 6
Training loss: 3.1983291078360354
Validation loss: 2.683389678416499

Epoch: 6| Step: 7
Training loss: 2.7111636020793712
Validation loss: 2.6908337891417085

Epoch: 6| Step: 8
Training loss: 3.243575568828808
Validation loss: 2.697003449978421

Epoch: 6| Step: 9
Training loss: 3.324975327708554
Validation loss: 2.696656294788208

Epoch: 6| Step: 10
Training loss: 3.142016050573349
Validation loss: 2.6853165252428886

Epoch: 6| Step: 11
Training loss: 2.7037959506450573
Validation loss: 2.6761705455940508

Epoch: 6| Step: 12
Training loss: 3.0863012171930126
Validation loss: 2.67440463910224

Epoch: 6| Step: 13
Training loss: 3.4099301397601143
Validation loss: 2.670857052629485

Testing loss: 2.887723592236199
