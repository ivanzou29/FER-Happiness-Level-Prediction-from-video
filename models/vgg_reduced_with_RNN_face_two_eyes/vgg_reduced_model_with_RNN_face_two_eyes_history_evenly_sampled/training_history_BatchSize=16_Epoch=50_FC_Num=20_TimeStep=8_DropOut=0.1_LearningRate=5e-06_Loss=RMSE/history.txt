Epoch: 1| Step: 0
Training loss: 5.746758252068277
Validation loss: 5.80440917075344

Epoch: 6| Step: 1
Training loss: 4.926188198767657
Validation loss: 5.799073430223372

Epoch: 6| Step: 2
Training loss: 5.348410375572561
Validation loss: 5.794043910546812

Epoch: 6| Step: 3
Training loss: 5.017494114832902
Validation loss: 5.789243864029684

Epoch: 6| Step: 4
Training loss: 5.269595135187707
Validation loss: 5.7845734422078445

Epoch: 6| Step: 5
Training loss: 6.507228353416365
Validation loss: 5.780132695025464

Epoch: 6| Step: 6
Training loss: 6.506304397868625
Validation loss: 5.775823574172107

Epoch: 6| Step: 7
Training loss: 6.850441922599746
Validation loss: 5.771364165039532

Epoch: 6| Step: 8
Training loss: 5.88291625074514
Validation loss: 5.766986447743814

Epoch: 6| Step: 9
Training loss: 5.907126386905811
Validation loss: 5.762317673645092

Epoch: 6| Step: 10
Training loss: 6.047279994916232
Validation loss: 5.757669934158394

Epoch: 6| Step: 11
Training loss: 4.891563447364731
Validation loss: 5.753159438365246

Epoch: 6| Step: 12
Training loss: 5.701613134366832
Validation loss: 5.748225419331946

Epoch: 6| Step: 13
Training loss: 6.627631474546721
Validation loss: 5.743417486280696

Epoch: 2| Step: 0
Training loss: 6.810741512579367
Validation loss: 5.738203194950153

Epoch: 6| Step: 1
Training loss: 6.944716540622076
Validation loss: 5.733359391178764

Epoch: 6| Step: 2
Training loss: 5.101291246198362
Validation loss: 5.728417648917984

Epoch: 6| Step: 3
Training loss: 4.018214240780903
Validation loss: 5.722553303065685

Epoch: 6| Step: 4
Training loss: 6.551797331939427
Validation loss: 5.716621930481198

Epoch: 6| Step: 5
Training loss: 5.252530351030917
Validation loss: 5.711285351101692

Epoch: 6| Step: 6
Training loss: 6.211966183483784
Validation loss: 5.705219447340588

Epoch: 6| Step: 7
Training loss: 4.969011407849441
Validation loss: 5.699098883460149

Epoch: 6| Step: 8
Training loss: 4.796576375705751
Validation loss: 5.692567327880712

Epoch: 6| Step: 9
Training loss: 5.960880224270213
Validation loss: 5.686277770025863

Epoch: 6| Step: 10
Training loss: 5.42038374298948
Validation loss: 5.679846387245006

Epoch: 6| Step: 11
Training loss: 5.362068945003569
Validation loss: 5.6721161125793875

Epoch: 6| Step: 12
Training loss: 6.1966198844162905
Validation loss: 5.665353287437104

Epoch: 6| Step: 13
Training loss: 6.086254028394192
Validation loss: 5.657745924956064

Epoch: 3| Step: 0
Training loss: 6.047566061427852
Validation loss: 5.649563178243261

Epoch: 6| Step: 1
Training loss: 4.847465615900629
Validation loss: 5.641667660725998

Epoch: 6| Step: 2
Training loss: 5.21802154756471
Validation loss: 5.6335481452846015

Epoch: 6| Step: 3
Training loss: 6.061506996236966
Validation loss: 5.624262826394543

Epoch: 6| Step: 4
Training loss: 4.6028543158330795
Validation loss: 5.616013724624176

Epoch: 6| Step: 5
Training loss: 6.504537026000192
Validation loss: 5.605796785786712

Epoch: 6| Step: 6
Training loss: 5.331096816014388
Validation loss: 5.596458110871766

Epoch: 6| Step: 7
Training loss: 6.05945565778415
Validation loss: 5.586943193942375

Epoch: 6| Step: 8
Training loss: 6.088526281680555
Validation loss: 5.576349427319622

Epoch: 6| Step: 9
Training loss: 6.197062799529193
Validation loss: 5.566213944370809

Epoch: 6| Step: 10
Training loss: 5.473170297837521
Validation loss: 5.55495281655149

Epoch: 6| Step: 11
Training loss: 5.462820795272326
Validation loss: 5.543280318531085

Epoch: 6| Step: 12
Training loss: 5.546263239262039
Validation loss: 5.531963475020596

Epoch: 6| Step: 13
Training loss: 4.366774537790061
Validation loss: 5.519656883203169

Epoch: 4| Step: 0
Training loss: 4.339627731811567
Validation loss: 5.507895778636453

Epoch: 6| Step: 1
Training loss: 6.516030132039034
Validation loss: 5.49575429241922

Epoch: 6| Step: 2
Training loss: 6.03908334508854
Validation loss: 5.483373219933169

Epoch: 6| Step: 3
Training loss: 5.533848728551249
Validation loss: 5.470611894730508

Epoch: 6| Step: 4
Training loss: 4.614793805675014
Validation loss: 5.457270247804173

Epoch: 6| Step: 5
Training loss: 6.579171068102681
Validation loss: 5.443627811826261

Epoch: 6| Step: 6
Training loss: 5.2205001728813025
Validation loss: 5.429540643471413

Epoch: 6| Step: 7
Training loss: 4.636133145741605
Validation loss: 5.415254634449577

Epoch: 6| Step: 8
Training loss: 4.61650811117049
Validation loss: 5.4015353161915485

Epoch: 6| Step: 9
Training loss: 5.377697112701859
Validation loss: 5.386896538901564

Epoch: 6| Step: 10
Training loss: 5.984581527931015
Validation loss: 5.3713236487027505

Epoch: 6| Step: 11
Training loss: 6.216272215137103
Validation loss: 5.355273074711898

Epoch: 6| Step: 12
Training loss: 5.006222095959414
Validation loss: 5.339987419844554

Epoch: 6| Step: 13
Training loss: 4.971726971238272
Validation loss: 5.323405949039286

Epoch: 5| Step: 0
Training loss: 4.011330530981482
Validation loss: 5.307431718433835

Epoch: 6| Step: 1
Training loss: 4.027163304486901
Validation loss: 5.290661390859362

Epoch: 6| Step: 2
Training loss: 6.31779092062243
Validation loss: 5.273738331784176

Epoch: 6| Step: 3
Training loss: 5.763496481573944
Validation loss: 5.257501238697176

Epoch: 6| Step: 4
Training loss: 4.6951926623902125
Validation loss: 5.238564813325842

Epoch: 6| Step: 5
Training loss: 5.540543674274481
Validation loss: 5.2219398225524305

Epoch: 6| Step: 6
Training loss: 6.674791471388708
Validation loss: 5.205317708178169

Epoch: 6| Step: 7
Training loss: 4.156158675717776
Validation loss: 5.185818768041908

Epoch: 6| Step: 8
Training loss: 6.013853927091718
Validation loss: 5.168029535278836

Epoch: 6| Step: 9
Training loss: 6.04517587057253
Validation loss: 5.151053819003641

Epoch: 6| Step: 10
Training loss: 4.666529017643603
Validation loss: 5.131790276857948

Epoch: 6| Step: 11
Training loss: 4.842296751500247
Validation loss: 5.114426068113926

Epoch: 6| Step: 12
Training loss: 3.743097182785319
Validation loss: 5.096187944005107

Epoch: 6| Step: 13
Training loss: 6.243163069592639
Validation loss: 5.078819294330789

Epoch: 6| Step: 0
Training loss: 5.315504055004064
Validation loss: 5.061305654792419

Epoch: 6| Step: 1
Training loss: 5.204104769450363
Validation loss: 5.043973991553061

Epoch: 6| Step: 2
Training loss: 4.50277709040531
Validation loss: 5.023919725933648

Epoch: 6| Step: 3
Training loss: 5.4193617742687445
Validation loss: 5.00452979614078

Epoch: 6| Step: 4
Training loss: 4.579749330215826
Validation loss: 4.986447733746943

Epoch: 6| Step: 5
Training loss: 4.751174580759013
Validation loss: 4.967089225256394

Epoch: 6| Step: 6
Training loss: 5.824685071036701
Validation loss: 4.946867111969136

Epoch: 6| Step: 7
Training loss: 4.275680148802443
Validation loss: 4.928471277292346

Epoch: 6| Step: 8
Training loss: 4.602028789113566
Validation loss: 4.907680288623574

Epoch: 6| Step: 9
Training loss: 4.9634916683959815
Validation loss: 4.888280748125918

Epoch: 6| Step: 10
Training loss: 4.795942880731001
Validation loss: 4.868302335534324

Epoch: 6| Step: 11
Training loss: 4.818966966783766
Validation loss: 4.847799872696971

Epoch: 6| Step: 12
Training loss: 5.423574395678911
Validation loss: 4.828978191299416

Epoch: 6| Step: 13
Training loss: 5.6552254607758154
Validation loss: 4.809329382670692

Epoch: 7| Step: 0
Training loss: 4.540093782439381
Validation loss: 4.7907009819144335

Epoch: 6| Step: 1
Training loss: 4.944475100037675
Validation loss: 4.771507037571374

Epoch: 6| Step: 2
Training loss: 3.6438422006552873
Validation loss: 4.755905101217964

Epoch: 6| Step: 3
Training loss: 5.565597700323014
Validation loss: 4.741548788640974

Epoch: 6| Step: 4
Training loss: 5.006454497886134
Validation loss: 4.726972451021756

Epoch: 6| Step: 5
Training loss: 4.303756474720796
Validation loss: 4.708938423991732

Epoch: 6| Step: 6
Training loss: 5.200778007993394
Validation loss: 4.69532059826505

Epoch: 6| Step: 7
Training loss: 4.506294510577893
Validation loss: 4.680947694738348

Epoch: 6| Step: 8
Training loss: 4.443284898070886
Validation loss: 4.664973317981926

Epoch: 6| Step: 9
Training loss: 5.454513067091532
Validation loss: 4.6481470127741025

Epoch: 6| Step: 10
Training loss: 5.370390934131368
Validation loss: 4.636442462186789

Epoch: 6| Step: 11
Training loss: 4.269131403537941
Validation loss: 4.6228825700567

Epoch: 6| Step: 12
Training loss: 4.6825957010390775
Validation loss: 4.608271287271462

Epoch: 6| Step: 13
Training loss: 4.394891478291248
Validation loss: 4.594007283815303

Epoch: 8| Step: 0
Training loss: 5.334707540059142
Validation loss: 4.579642120373959

Epoch: 6| Step: 1
Training loss: 3.6945353491234663
Validation loss: 4.566081092614024

Epoch: 6| Step: 2
Training loss: 4.7386863893804385
Validation loss: 4.5534202793949685

Epoch: 6| Step: 3
Training loss: 4.552538304175631
Validation loss: 4.544772670049621

Epoch: 6| Step: 4
Training loss: 4.869473968859309
Validation loss: 4.532592487437628

Epoch: 6| Step: 5
Training loss: 4.4858055889914095
Validation loss: 4.522377653547259

Epoch: 6| Step: 6
Training loss: 4.574946944132355
Validation loss: 4.512386204712935

Epoch: 6| Step: 7
Training loss: 4.716720043370106
Validation loss: 4.504540512414414

Epoch: 6| Step: 8
Training loss: 4.104722090315093
Validation loss: 4.4957154601477995

Epoch: 6| Step: 9
Training loss: 3.9590366474872978
Validation loss: 4.485075426105701

Epoch: 6| Step: 10
Training loss: 5.149180241497071
Validation loss: 4.478084593572424

Epoch: 6| Step: 11
Training loss: 4.593022087710156
Validation loss: 4.469384935763462

Epoch: 6| Step: 12
Training loss: 4.636981805604043
Validation loss: 4.460926974029332

Epoch: 6| Step: 13
Training loss: 5.117089842818148
Validation loss: 4.454134898152681

Epoch: 9| Step: 0
Training loss: 4.386644615844527
Validation loss: 4.445841494089317

Epoch: 6| Step: 1
Training loss: 5.584065669222861
Validation loss: 4.438909648462531

Epoch: 6| Step: 2
Training loss: 3.4880412020218388
Validation loss: 4.434129136302275

Epoch: 6| Step: 3
Training loss: 4.2171030856570955
Validation loss: 4.427264061652392

Epoch: 6| Step: 4
Training loss: 3.5886398471787038
Validation loss: 4.42118390066255

Epoch: 6| Step: 5
Training loss: 4.799486077135161
Validation loss: 4.41731587052189

Epoch: 6| Step: 6
Training loss: 5.616926375515259
Validation loss: 4.411032645831031

Epoch: 6| Step: 7
Training loss: 4.281878125968151
Validation loss: 4.404539987951853

Epoch: 6| Step: 8
Training loss: 3.6299562444230347
Validation loss: 4.39993886783974

Epoch: 6| Step: 9
Training loss: 4.200739641003016
Validation loss: 4.393625123594931

Epoch: 6| Step: 10
Training loss: 4.902654606055713
Validation loss: 4.389062111598479

Epoch: 6| Step: 11
Training loss: 4.87409651771625
Validation loss: 4.386854328598946

Epoch: 6| Step: 12
Training loss: 4.776285224231578
Validation loss: 4.379559121127803

Epoch: 6| Step: 13
Training loss: 4.126227456314089
Validation loss: 4.375439838854091

Epoch: 10| Step: 0
Training loss: 4.074955318650626
Validation loss: 4.369094639137223

Epoch: 6| Step: 1
Training loss: 3.751151353199358
Validation loss: 4.365264317082067

Epoch: 6| Step: 2
Training loss: 4.861919950980395
Validation loss: 4.359965942662237

Epoch: 6| Step: 3
Training loss: 5.236704931250882
Validation loss: 4.3548615074852295

Epoch: 6| Step: 4
Training loss: 4.379551509034696
Validation loss: 4.3497012914517095

Epoch: 6| Step: 5
Training loss: 3.3790707939523834
Validation loss: 4.3443485891319975

Epoch: 6| Step: 6
Training loss: 3.4449396256027263
Validation loss: 4.3388136616307715

Epoch: 6| Step: 7
Training loss: 3.471781874814647
Validation loss: 4.334572086490071

Epoch: 6| Step: 8
Training loss: 4.294419575419488
Validation loss: 4.328635117321707

Epoch: 6| Step: 9
Training loss: 4.970382901951981
Validation loss: 4.324659231706186

Epoch: 6| Step: 10
Training loss: 5.034461471411705
Validation loss: 4.317235877784421

Epoch: 6| Step: 11
Training loss: 5.360933038436737
Validation loss: 4.312315042960317

Epoch: 6| Step: 12
Training loss: 5.247464612284463
Validation loss: 4.305191166904367

Epoch: 6| Step: 13
Training loss: 3.797087361240724
Validation loss: 4.298241273420863

Epoch: 11| Step: 0
Training loss: 4.823243077261257
Validation loss: 4.294069360494086

Epoch: 6| Step: 1
Training loss: 4.9724211176488495
Validation loss: 4.290247770530475

Epoch: 6| Step: 2
Training loss: 4.823855787206093
Validation loss: 4.284041588391789

Epoch: 6| Step: 3
Training loss: 3.8502926851463517
Validation loss: 4.278593140310606

Epoch: 6| Step: 4
Training loss: 4.271165093662877
Validation loss: 4.271467217145903

Epoch: 6| Step: 5
Training loss: 4.789757832117615
Validation loss: 4.269636877480172

Epoch: 6| Step: 6
Training loss: 4.152652876105084
Validation loss: 4.265852503686069

Epoch: 6| Step: 7
Training loss: 3.6116487021381594
Validation loss: 4.258387719750171

Epoch: 6| Step: 8
Training loss: 3.6765028339542636
Validation loss: 4.256323509273593

Epoch: 6| Step: 9
Training loss: 5.010553666090353
Validation loss: 4.252205162599935

Epoch: 6| Step: 10
Training loss: 4.432605676999541
Validation loss: 4.246727008259195

Epoch: 6| Step: 11
Training loss: 4.956059401937413
Validation loss: 4.244012805299875

Epoch: 6| Step: 12
Training loss: 3.9669889612989073
Validation loss: 4.238781594425683

Epoch: 6| Step: 13
Training loss: 3.0196263149047167
Validation loss: 4.234775658210261

Epoch: 12| Step: 0
Training loss: 4.386969622863125
Validation loss: 4.231520208795358

Epoch: 6| Step: 1
Training loss: 4.805036628258037
Validation loss: 4.22837420307615

Epoch: 6| Step: 2
Training loss: 3.9631884196497644
Validation loss: 4.223559640998271

Epoch: 6| Step: 3
Training loss: 5.177410194726982
Validation loss: 4.221180305221294

Epoch: 6| Step: 4
Training loss: 4.280389184102634
Validation loss: 4.216641266176554

Epoch: 6| Step: 5
Training loss: 4.258478347090848
Validation loss: 4.214213884013565

Epoch: 6| Step: 6
Training loss: 2.7364135118949138
Validation loss: 4.210368457602686

Epoch: 6| Step: 7
Training loss: 4.035159558777685
Validation loss: 4.206628914623317

Epoch: 6| Step: 8
Training loss: 3.957398889904317
Validation loss: 4.20396508447713

Epoch: 6| Step: 9
Training loss: 4.464079009584014
Validation loss: 4.203045490325751

Epoch: 6| Step: 10
Training loss: 4.525336254124175
Validation loss: 4.196613799773959

Epoch: 6| Step: 11
Training loss: 4.4045614700176525
Validation loss: 4.194071160625903

Epoch: 6| Step: 12
Training loss: 5.1009717426904615
Validation loss: 4.1915662647589365

Epoch: 6| Step: 13
Training loss: 3.9392191449091345
Validation loss: 4.18817898922714

Epoch: 13| Step: 0
Training loss: 4.8018834313126595
Validation loss: 4.186554052713429

Epoch: 6| Step: 1
Training loss: 3.737949464238995
Validation loss: 4.181662724908077

Epoch: 6| Step: 2
Training loss: 5.070833105976953
Validation loss: 4.179261403699048

Epoch: 6| Step: 3
Training loss: 5.281141652457384
Validation loss: 4.1754578506669935

Epoch: 6| Step: 4
Training loss: 4.2679336504511545
Validation loss: 4.172045187547313

Epoch: 6| Step: 5
Training loss: 4.199959055383103
Validation loss: 4.167504843217602

Epoch: 6| Step: 6
Training loss: 4.0309258855594265
Validation loss: 4.166376801939633

Epoch: 6| Step: 7
Training loss: 4.490774234211318
Validation loss: 4.162788975637645

Epoch: 6| Step: 8
Training loss: 4.54081652789344
Validation loss: 4.159993730438563

Epoch: 6| Step: 9
Training loss: 4.376158206764783
Validation loss: 4.1553878661034185

Epoch: 6| Step: 10
Training loss: 3.8427112695495413
Validation loss: 4.154645784301113

Epoch: 6| Step: 11
Training loss: 3.036912800109471
Validation loss: 4.149616148560569

Epoch: 6| Step: 12
Training loss: 4.097238699382402
Validation loss: 4.147156910019516

Epoch: 6| Step: 13
Training loss: 3.6944346766394522
Validation loss: 4.143106587987428

Epoch: 14| Step: 0
Training loss: 4.3613926310024755
Validation loss: 4.137689660671124

Epoch: 6| Step: 1
Training loss: 4.5837688354737685
Validation loss: 4.134721065105995

Epoch: 6| Step: 2
Training loss: 3.9674483439995396
Validation loss: 4.134058011609165

Epoch: 6| Step: 3
Training loss: 4.585439833715838
Validation loss: 4.128511546933981

Epoch: 6| Step: 4
Training loss: 4.099333239047631
Validation loss: 4.1249910256942925

Epoch: 6| Step: 5
Training loss: 4.655345854567066
Validation loss: 4.124051118849561

Epoch: 6| Step: 6
Training loss: 4.131991847573996
Validation loss: 4.121699300666596

Epoch: 6| Step: 7
Training loss: 4.308763516246909
Validation loss: 4.116939135176581

Epoch: 6| Step: 8
Training loss: 4.7793194232840595
Validation loss: 4.114549025733551

Epoch: 6| Step: 9
Training loss: 4.493878757717268
Validation loss: 4.113319198834876

Epoch: 6| Step: 10
Training loss: 4.293758857640177
Validation loss: 4.108479972275269

Epoch: 6| Step: 11
Training loss: 3.8169452204662355
Validation loss: 4.106827855015858

Epoch: 6| Step: 12
Training loss: 3.4495713949029545
Validation loss: 4.103689390949995

Epoch: 6| Step: 13
Training loss: 3.6009728865509794
Validation loss: 4.099718014744144

Epoch: 15| Step: 0
Training loss: 4.269518071299995
Validation loss: 4.09679895913026

Epoch: 6| Step: 1
Training loss: 4.656571549955344
Validation loss: 4.092044402687068

Epoch: 6| Step: 2
Training loss: 3.0940551607310565
Validation loss: 4.089201295603723

Epoch: 6| Step: 3
Training loss: 4.389468437807009
Validation loss: 4.088042228463526

Epoch: 6| Step: 4
Training loss: 3.992628577066334
Validation loss: 4.0839845181225005

Epoch: 6| Step: 5
Training loss: 4.060708223029945
Validation loss: 4.0829021953695435

Epoch: 6| Step: 6
Training loss: 3.3574809567954573
Validation loss: 4.0789402745696695

Epoch: 6| Step: 7
Training loss: 3.2843513001549622
Validation loss: 4.07378551635458

Epoch: 6| Step: 8
Training loss: 5.025978881232949
Validation loss: 4.073223213992647

Epoch: 6| Step: 9
Training loss: 5.008227636117969
Validation loss: 4.069735412142517

Epoch: 6| Step: 10
Training loss: 4.160617913791238
Validation loss: 4.066235544930102

Epoch: 6| Step: 11
Training loss: 3.8441103634507114
Validation loss: 4.062090270123844

Epoch: 6| Step: 12
Training loss: 5.229760165432011
Validation loss: 4.0600668373690425

Epoch: 6| Step: 13
Training loss: 3.9405617087936267
Validation loss: 4.056475199388614

Epoch: 16| Step: 0
Training loss: 4.14941762491757
Validation loss: 4.055304380201765

Epoch: 6| Step: 1
Training loss: 4.967730339557744
Validation loss: 4.053377653313037

Epoch: 6| Step: 2
Training loss: 4.017348339016913
Validation loss: 4.048838909322724

Epoch: 6| Step: 3
Training loss: 4.017287804365102
Validation loss: 4.047345604953446

Epoch: 6| Step: 4
Training loss: 3.8867153148540097
Validation loss: 4.045198391696157

Epoch: 6| Step: 5
Training loss: 3.9395241756963486
Validation loss: 4.042030011560641

Epoch: 6| Step: 6
Training loss: 4.449503821667445
Validation loss: 4.036688199625037

Epoch: 6| Step: 7
Training loss: 4.440831397975949
Validation loss: 4.034911445021753

Epoch: 6| Step: 8
Training loss: 3.791372448471633
Validation loss: 4.031600121666606

Epoch: 6| Step: 9
Training loss: 4.419662515175437
Validation loss: 4.028390689298486

Epoch: 6| Step: 10
Training loss: 3.8821311061128303
Validation loss: 4.028815059784017

Epoch: 6| Step: 11
Training loss: 4.457279663117321
Validation loss: 4.025875530941601

Epoch: 6| Step: 12
Training loss: 4.312778187500498
Validation loss: 4.021847911826073

Epoch: 6| Step: 13
Training loss: 3.23825945691551
Validation loss: 4.018156881173141

Epoch: 17| Step: 0
Training loss: 4.59455044578119
Validation loss: 4.017465007636304

Epoch: 6| Step: 1
Training loss: 4.211429376130712
Validation loss: 4.016987358780903

Epoch: 6| Step: 2
Training loss: 4.140542544137719
Validation loss: 4.013366574872099

Epoch: 6| Step: 3
Training loss: 4.752383387066538
Validation loss: 4.009569857874941

Epoch: 6| Step: 4
Training loss: 3.9656180692090612
Validation loss: 4.007457234544395

Epoch: 6| Step: 5
Training loss: 4.541415472987581
Validation loss: 4.005196419780879

Epoch: 6| Step: 6
Training loss: 4.513283303874273
Validation loss: 4.006071832622324

Epoch: 6| Step: 7
Training loss: 4.064167795426853
Validation loss: 4.003227349606805

Epoch: 6| Step: 8
Training loss: 3.4833512106502096
Validation loss: 3.997928695807245

Epoch: 6| Step: 9
Training loss: 3.8915943332351297
Validation loss: 3.9948645743099296

Epoch: 6| Step: 10
Training loss: 3.7796237695752963
Validation loss: 3.992660269388783

Epoch: 6| Step: 11
Training loss: 4.242880973547158
Validation loss: 3.9894511397113783

Epoch: 6| Step: 12
Training loss: 4.444664128490238
Validation loss: 3.987799478145616

Epoch: 6| Step: 13
Training loss: 2.3215900847033315
Validation loss: 3.9856642108985456

Epoch: 18| Step: 0
Training loss: 3.803305874412525
Validation loss: 3.9833082411378156

Epoch: 6| Step: 1
Training loss: 4.159727778331094
Validation loss: 3.9833724586136374

Epoch: 6| Step: 2
Training loss: 3.7092192516714637
Validation loss: 3.9799476007120616

Epoch: 6| Step: 3
Training loss: 3.762896677188764
Validation loss: 3.9776119645458055

Epoch: 6| Step: 4
Training loss: 4.035742570317397
Validation loss: 3.9739414683993863

Epoch: 6| Step: 5
Training loss: 5.029781530045836
Validation loss: 3.9739082526910696

Epoch: 6| Step: 6
Training loss: 2.9497014945347186
Validation loss: 3.97217535567871

Epoch: 6| Step: 7
Training loss: 4.441437170077068
Validation loss: 3.9696217868840677

Epoch: 6| Step: 8
Training loss: 4.261271396447845
Validation loss: 3.966823634561798

Epoch: 6| Step: 9
Training loss: 4.218196578284004
Validation loss: 3.963518695517599

Epoch: 6| Step: 10
Training loss: 4.747194565946106
Validation loss: 3.9635777746360454

Epoch: 6| Step: 11
Training loss: 4.88202102960404
Validation loss: 3.9606029504080746

Epoch: 6| Step: 12
Training loss: 2.8987500621142592
Validation loss: 3.9572682828737897

Epoch: 6| Step: 13
Training loss: 4.314326908308286
Validation loss: 3.9557746937999974

Epoch: 19| Step: 0
Training loss: 3.9362094520183617
Validation loss: 3.9534592823353703

Epoch: 6| Step: 1
Training loss: 3.873864407420905
Validation loss: 3.953296571239793

Epoch: 6| Step: 2
Training loss: 3.607002171925313
Validation loss: 3.95118947902862

Epoch: 6| Step: 3
Training loss: 3.9886745815624693
Validation loss: 3.9479523123391886

Epoch: 6| Step: 4
Training loss: 1.9740863714908
Validation loss: 3.9468921528271377

Epoch: 6| Step: 5
Training loss: 3.7787901388314857
Validation loss: 3.9440064004782363

Epoch: 6| Step: 6
Training loss: 4.280698643286373
Validation loss: 3.9416338043899986

Epoch: 6| Step: 7
Training loss: 5.2449294535908235
Validation loss: 3.9411709040764413

Epoch: 6| Step: 8
Training loss: 4.52711329560679
Validation loss: 3.9387016487656203

Epoch: 6| Step: 9
Training loss: 4.422711081031002
Validation loss: 3.9373491384966592

Epoch: 6| Step: 10
Training loss: 3.7664700268305196
Validation loss: 3.934618882695173

Epoch: 6| Step: 11
Training loss: 4.18112562875567
Validation loss: 3.9338291386703883

Epoch: 6| Step: 12
Training loss: 4.159806644274349
Validation loss: 3.9336573739645733

Epoch: 6| Step: 13
Training loss: 5.236442134972004
Validation loss: 3.9303692669269417

Epoch: 20| Step: 0
Training loss: 3.377616009756407
Validation loss: 3.9272063739705327

Epoch: 6| Step: 1
Training loss: 3.7153298173312006
Validation loss: 3.927832307819119

Epoch: 6| Step: 2
Training loss: 4.4279557868107915
Validation loss: 3.9290355587727586

Epoch: 6| Step: 3
Training loss: 4.367106046241173
Validation loss: 3.9253159433929774

Epoch: 6| Step: 4
Training loss: 4.322984417610401
Validation loss: 3.9243329950425805

Epoch: 6| Step: 5
Training loss: 4.313609105000381
Validation loss: 3.9214176227820334

Epoch: 6| Step: 6
Training loss: 3.1838702309967264
Validation loss: 3.921260521352988

Epoch: 6| Step: 7
Training loss: 3.666911825018226
Validation loss: 3.9182325888227454

Epoch: 6| Step: 8
Training loss: 4.582693899228208
Validation loss: 3.914290453310767

Epoch: 6| Step: 9
Training loss: 4.215523170954988
Validation loss: 3.9108242942577447

Epoch: 6| Step: 10
Training loss: 4.212639119825224
Validation loss: 3.9093606159519414

Epoch: 6| Step: 11
Training loss: 3.798385633571937
Validation loss: 3.906044982124062

Epoch: 6| Step: 12
Training loss: 4.247437995157208
Validation loss: 3.905763181479295

Epoch: 6| Step: 13
Training loss: 4.608370810569605
Validation loss: 3.90356200306046

Epoch: 21| Step: 0
Training loss: 3.0428521619995204
Validation loss: 3.903074965532361

Epoch: 6| Step: 1
Training loss: 5.218521935510691
Validation loss: 3.902977888087852

Epoch: 6| Step: 2
Training loss: 4.315025806195124
Validation loss: 3.897306140943623

Epoch: 6| Step: 3
Training loss: 3.548063507595469
Validation loss: 3.89601808831214

Epoch: 6| Step: 4
Training loss: 4.083490459507129
Validation loss: 3.8961007710415774

Epoch: 6| Step: 5
Training loss: 3.381255815821809
Validation loss: 3.895872964219284

Epoch: 6| Step: 6
Training loss: 3.9281179884769863
Validation loss: 3.8927557340463586

Epoch: 6| Step: 7
Training loss: 3.6292473475659457
Validation loss: 3.891269491258658

Epoch: 6| Step: 8
Training loss: 4.7668719552034
Validation loss: 3.891026877706714

Epoch: 6| Step: 9
Training loss: 4.434088886861854
Validation loss: 3.8872653823514667

Epoch: 6| Step: 10
Training loss: 4.936625729188703
Validation loss: 3.886292056306529

Epoch: 6| Step: 11
Training loss: 3.6525129472841193
Validation loss: 3.884182008555985

Epoch: 6| Step: 12
Training loss: 3.3710213274375858
Validation loss: 3.883238300560393

Epoch: 6| Step: 13
Training loss: 3.6241859311202673
Validation loss: 3.882672477510446

Epoch: 22| Step: 0
Training loss: 3.8556681139881075
Validation loss: 3.880761415493835

Epoch: 6| Step: 1
Training loss: 4.06003742407477
Validation loss: 3.8808468370610645

Epoch: 6| Step: 2
Training loss: 3.3771276478543633
Validation loss: 3.8792326096886414

Epoch: 6| Step: 3
Training loss: 4.170226039111688
Validation loss: 3.87908898303296

Epoch: 6| Step: 4
Training loss: 5.136096757137821
Validation loss: 3.8768174563239395

Epoch: 6| Step: 5
Training loss: 3.746350101613877
Validation loss: 3.876406990752525

Epoch: 6| Step: 6
Training loss: 3.8609205849993695
Validation loss: 3.87381422177608

Epoch: 6| Step: 7
Training loss: 3.6344035284442975
Validation loss: 3.8716557706530597

Epoch: 6| Step: 8
Training loss: 4.807425461626191
Validation loss: 3.870615640558944

Epoch: 6| Step: 9
Training loss: 3.3513034106860684
Validation loss: 3.868148796597632

Epoch: 6| Step: 10
Training loss: 3.328274002679777
Validation loss: 3.869993387286435

Epoch: 6| Step: 11
Training loss: 4.07588689783049
Validation loss: 3.87115929652606

Epoch: 6| Step: 12
Training loss: 4.4337419527129756
Validation loss: 3.8702156919830184

Epoch: 6| Step: 13
Training loss: 4.411693051822179
Validation loss: 3.8682815311857364

Epoch: 23| Step: 0
Training loss: 3.9900174747170425
Validation loss: 3.865639550236897

Epoch: 6| Step: 1
Training loss: 2.952907816656225
Validation loss: 3.8643715999495085

Epoch: 6| Step: 2
Training loss: 4.0493413413124255
Validation loss: 3.862956453427159

Epoch: 6| Step: 3
Training loss: 3.2911092229828136
Validation loss: 3.864941334652699

Epoch: 6| Step: 4
Training loss: 3.9299117340969594
Validation loss: 3.8638371430830625

Epoch: 6| Step: 5
Training loss: 4.679672827084676
Validation loss: 3.862049780916375

Epoch: 6| Step: 6
Training loss: 3.8587694194911792
Validation loss: 3.8632221527425386

Epoch: 6| Step: 7
Training loss: 4.372284836881538
Validation loss: 3.8622122632224314

Epoch: 6| Step: 8
Training loss: 4.022653566301421
Validation loss: 3.8597837021393016

Epoch: 6| Step: 9
Training loss: 4.265055747701999
Validation loss: 3.859717648926192

Epoch: 6| Step: 10
Training loss: 4.868223517847816
Validation loss: 3.8583718202908757

Epoch: 6| Step: 11
Training loss: 4.283981899533114
Validation loss: 3.856460171361062

Epoch: 6| Step: 12
Training loss: 3.4253720046677163
Validation loss: 3.8537830588691016

Epoch: 6| Step: 13
Training loss: 3.9417499433972183
Validation loss: 3.855529157648204

Epoch: 24| Step: 0
Training loss: 3.9635411720760136
Validation loss: 3.8513038403795914

Epoch: 6| Step: 1
Training loss: 4.149238580919588
Validation loss: 3.8510528974804714

Epoch: 6| Step: 2
Training loss: 4.13224618417288
Validation loss: 3.8493523556791227

Epoch: 6| Step: 3
Training loss: 4.131818742024311
Validation loss: 3.8475371108352623

Epoch: 6| Step: 4
Training loss: 4.869113400257323
Validation loss: 3.848190907606331

Epoch: 6| Step: 5
Training loss: 4.124968557526946
Validation loss: 3.8448251493973182

Epoch: 6| Step: 6
Training loss: 3.9596500147665723
Validation loss: 3.845218930342704

Epoch: 6| Step: 7
Training loss: 3.378057719503743
Validation loss: 3.846449665520852

Epoch: 6| Step: 8
Training loss: 2.9713861907829133
Validation loss: 3.846416573886709

Epoch: 6| Step: 9
Training loss: 4.634165985888467
Validation loss: 3.8437916876553757

Epoch: 6| Step: 10
Training loss: 4.143893121747685
Validation loss: 3.842919463448717

Epoch: 6| Step: 11
Training loss: 2.895579283477117
Validation loss: 3.842570678450332

Epoch: 6| Step: 12
Training loss: 4.129140913979565
Validation loss: 3.844364432290772

Epoch: 6| Step: 13
Training loss: 4.415178924080045
Validation loss: 3.8429244293942024

Epoch: 25| Step: 0
Training loss: 4.333118629027211
Validation loss: 3.8403563072183564

Epoch: 6| Step: 1
Training loss: 2.906063607094064
Validation loss: 3.839493411622771

Epoch: 6| Step: 2
Training loss: 4.387342209980943
Validation loss: 3.8393698939593555

Epoch: 6| Step: 3
Training loss: 4.225668877919839
Validation loss: 3.8372328912424347

Epoch: 6| Step: 4
Training loss: 4.240910627715527
Validation loss: 3.8366974710058352

Epoch: 6| Step: 5
Training loss: 3.4147910730841122
Validation loss: 3.8354521259846113

Epoch: 6| Step: 6
Training loss: 4.022589081132874
Validation loss: 3.8349746375501947

Epoch: 6| Step: 7
Training loss: 3.7790578998249673
Validation loss: 3.834156122402536

Epoch: 6| Step: 8
Training loss: 4.766000401454049
Validation loss: 3.834872579222961

Epoch: 6| Step: 9
Training loss: 3.7156251231996404
Validation loss: 3.8336483815665185

Epoch: 6| Step: 10
Training loss: 3.441382417801986
Validation loss: 3.8341956076112007

Epoch: 6| Step: 11
Training loss: 4.66488093315182
Validation loss: 3.8334352181918154

Epoch: 6| Step: 12
Training loss: 3.6135829160389923
Validation loss: 3.8326473228601112

Epoch: 6| Step: 13
Training loss: 4.23353664080207
Validation loss: 3.828842197025255

Epoch: 26| Step: 0
Training loss: 3.842490137071429
Validation loss: 3.8285895917221846

Epoch: 6| Step: 1
Training loss: 4.501844028301221
Validation loss: 3.8281382691298003

Epoch: 6| Step: 2
Training loss: 2.979392801163191
Validation loss: 3.8270014426847485

Epoch: 6| Step: 3
Training loss: 3.2239456464099794
Validation loss: 3.82787166960161

Epoch: 6| Step: 4
Training loss: 4.122483613008834
Validation loss: 3.8278984493332007

Epoch: 6| Step: 5
Training loss: 3.485743232624724
Validation loss: 3.827371864326193

Epoch: 6| Step: 6
Training loss: 4.108324504066456
Validation loss: 3.8284522386539677

Epoch: 6| Step: 7
Training loss: 4.403889774699757
Validation loss: 3.8265264800384737

Epoch: 6| Step: 8
Training loss: 3.460186534550101
Validation loss: 3.8264931919890306

Epoch: 6| Step: 9
Training loss: 3.6378881293277705
Validation loss: 3.8240213451417056

Epoch: 6| Step: 10
Training loss: 4.493150372350639
Validation loss: 3.8225701484555095

Epoch: 6| Step: 11
Training loss: 4.127950364605476
Validation loss: 3.8218282633522986

Epoch: 6| Step: 12
Training loss: 4.847985169642965
Validation loss: 3.822968941666122

Epoch: 6| Step: 13
Training loss: 4.455192219946834
Validation loss: 3.8221788244505563

Epoch: 27| Step: 0
Training loss: 3.656182704208412
Validation loss: 3.8208505061376012

Epoch: 6| Step: 1
Training loss: 4.499953799540396
Validation loss: 3.821240122560734

Epoch: 6| Step: 2
Training loss: 3.363374963533609
Validation loss: 3.8194029347440925

Epoch: 6| Step: 3
Training loss: 3.5547627535389412
Validation loss: 3.818909659858755

Epoch: 6| Step: 4
Training loss: 3.756672073491247
Validation loss: 3.8186599079832364

Epoch: 6| Step: 5
Training loss: 4.126500174800306
Validation loss: 3.8195217191623456

Epoch: 6| Step: 6
Training loss: 2.4069605187037517
Validation loss: 3.818653859154334

Epoch: 6| Step: 7
Training loss: 4.598144920132788
Validation loss: 3.81934531184197

Epoch: 6| Step: 8
Training loss: 4.97237048410526
Validation loss: 3.8176608955721885

Epoch: 6| Step: 9
Training loss: 4.193094189187089
Validation loss: 3.816415788725478

Epoch: 6| Step: 10
Training loss: 3.847000236548904
Validation loss: 3.8150599032101518

Epoch: 6| Step: 11
Training loss: 2.8546553887125614
Validation loss: 3.8152306331594246

Epoch: 6| Step: 12
Training loss: 4.462114863512119
Validation loss: 3.815614718723111

Epoch: 6| Step: 13
Training loss: 5.20732556575153
Validation loss: 3.8146750762963517

Epoch: 28| Step: 0
Training loss: 3.915490291680362
Validation loss: 3.8150716198202748

Epoch: 6| Step: 1
Training loss: 4.016306066089076
Validation loss: 3.813539803987249

Epoch: 6| Step: 2
Training loss: 3.7978408903568877
Validation loss: 3.81353113736927

Epoch: 6| Step: 3
Training loss: 4.64242981002574
Validation loss: 3.812813587091794

Epoch: 6| Step: 4
Training loss: 4.774954846553117
Validation loss: 3.811844151874099

Epoch: 6| Step: 5
Training loss: 4.057139924737189
Validation loss: 3.8105938270045114

Epoch: 6| Step: 6
Training loss: 3.961803815556927
Validation loss: 3.8105678655218727

Epoch: 6| Step: 7
Training loss: 2.9049272706058864
Validation loss: 3.8097656022286257

Epoch: 6| Step: 8
Training loss: 4.266974714205595
Validation loss: 3.810303399371529

Epoch: 6| Step: 9
Training loss: 2.9188585673690515
Validation loss: 3.809429689459092

Epoch: 6| Step: 10
Training loss: 4.1101741811407955
Validation loss: 3.809011403446565

Epoch: 6| Step: 11
Training loss: 3.5612659659384285
Validation loss: 3.809294904183639

Epoch: 6| Step: 12
Training loss: 4.4744239478984715
Validation loss: 3.808275472101317

Epoch: 6| Step: 13
Training loss: 3.84847508736212
Validation loss: 3.8082607914451643

Epoch: 29| Step: 0
Training loss: 4.344605944711136
Validation loss: 3.806830890375116

Epoch: 6| Step: 1
Training loss: 3.9252596532378483
Validation loss: 3.8063737496045373

Epoch: 6| Step: 2
Training loss: 4.139840451174615
Validation loss: 3.8060057460893346

Epoch: 6| Step: 3
Training loss: 3.5683044529589045
Validation loss: 3.8055716975001763

Epoch: 6| Step: 4
Training loss: 3.644515811278259
Validation loss: 3.8058492532569477

Epoch: 6| Step: 5
Training loss: 4.7947197958944985
Validation loss: 3.8054688236728524

Epoch: 6| Step: 6
Training loss: 3.6397987050161316
Validation loss: 3.8045605882595668

Epoch: 6| Step: 7
Training loss: 4.549201710855948
Validation loss: 3.8042391991984044

Epoch: 6| Step: 8
Training loss: 3.6601072652138344
Validation loss: 3.8039900388975307

Epoch: 6| Step: 9
Training loss: 2.737900036711156
Validation loss: 3.803449599281115

Epoch: 6| Step: 10
Training loss: 4.018964158398796
Validation loss: 3.8029140093727123

Epoch: 6| Step: 11
Training loss: 3.956017201400712
Validation loss: 3.8020540949626755

Epoch: 6| Step: 12
Training loss: 4.557252138965483
Validation loss: 3.8023450832420695

Epoch: 6| Step: 13
Training loss: 3.5371196205332014
Validation loss: 3.8026190546229515

Epoch: 30| Step: 0
Training loss: 4.122824123912378
Validation loss: 3.801533839218281

Epoch: 6| Step: 1
Training loss: 4.29564213492213
Validation loss: 3.8006568344256713

Epoch: 6| Step: 2
Training loss: 4.038883758662932
Validation loss: 3.8006254715502537

Epoch: 6| Step: 3
Training loss: 3.658002645250702
Validation loss: 3.8011463695902803

Epoch: 6| Step: 4
Training loss: 3.4246374676260216
Validation loss: 3.799810493765392

Epoch: 6| Step: 5
Training loss: 4.122134745224625
Validation loss: 3.799547926463832

Epoch: 6| Step: 6
Training loss: 4.996821155937914
Validation loss: 3.8005123159001624

Epoch: 6| Step: 7
Training loss: 3.085051976883573
Validation loss: 3.799421404434543

Epoch: 6| Step: 8
Training loss: 4.309043494206218
Validation loss: 3.7983486783294356

Epoch: 6| Step: 9
Training loss: 4.2275743665871115
Validation loss: 3.7974015851509413

Epoch: 6| Step: 10
Training loss: 3.870923020248081
Validation loss: 3.7977488649979168

Epoch: 6| Step: 11
Training loss: 3.272159153823986
Validation loss: 3.7976501988776055

Epoch: 6| Step: 12
Training loss: 3.757768595036524
Validation loss: 3.7968414047228887

Epoch: 6| Step: 13
Training loss: 4.152900206349939
Validation loss: 3.7961112950394296

Epoch: 31| Step: 0
Training loss: 3.203402623496631
Validation loss: 3.7960682044738285

Epoch: 6| Step: 1
Training loss: 3.0233106956209213
Validation loss: 3.7962950204395285

Epoch: 6| Step: 2
Training loss: 4.244550914216828
Validation loss: 3.7957210498004508

Epoch: 6| Step: 3
Training loss: 4.34132504183878
Validation loss: 3.7952371698455987

Epoch: 6| Step: 4
Training loss: 3.990288628103397
Validation loss: 3.7956140178846565

Epoch: 6| Step: 5
Training loss: 4.059401988820021
Validation loss: 3.7944793523381866

Epoch: 6| Step: 6
Training loss: 4.666090021382622
Validation loss: 3.795339972462128

Epoch: 6| Step: 7
Training loss: 3.9551480510793815
Validation loss: 3.7936011032356296

Epoch: 6| Step: 8
Training loss: 4.853698555091395
Validation loss: 3.793377935116804

Epoch: 6| Step: 9
Training loss: 3.5461451918154094
Validation loss: 3.793614190373038

Epoch: 6| Step: 10
Training loss: 3.9341675719588927
Validation loss: 3.7925644579867726

Epoch: 6| Step: 11
Training loss: 4.118398296523613
Validation loss: 3.7924291787649014

Epoch: 6| Step: 12
Training loss: 3.2042791008703366
Validation loss: 3.7919775019450297

Epoch: 6| Step: 13
Training loss: 3.983865383692795
Validation loss: 3.7915467562551086

Epoch: 32| Step: 0
Training loss: 5.347957627669979
Validation loss: 3.7904988225432272

Epoch: 6| Step: 1
Training loss: 3.903763857281581
Validation loss: 3.790716674065141

Epoch: 6| Step: 2
Training loss: 4.243265538379518
Validation loss: 3.7905077981520288

Epoch: 6| Step: 3
Training loss: 4.074797577306204
Validation loss: 3.7908600538917696

Epoch: 6| Step: 4
Training loss: 3.540874227992561
Validation loss: 3.789684026563649

Epoch: 6| Step: 5
Training loss: 3.093203101321572
Validation loss: 3.7903120065618827

Epoch: 6| Step: 6
Training loss: 4.202849538632661
Validation loss: 3.789543203399498

Epoch: 6| Step: 7
Training loss: 3.770518941400955
Validation loss: 3.788437726163317

Epoch: 6| Step: 8
Training loss: 3.632356610969712
Validation loss: 3.78823169479783

Epoch: 6| Step: 9
Training loss: 4.624033234051132
Validation loss: 3.787507069103004

Epoch: 6| Step: 10
Training loss: 3.764948993960479
Validation loss: 3.7875529184796832

Epoch: 6| Step: 11
Training loss: 3.1193807816418415
Validation loss: 3.7866378930954387

Epoch: 6| Step: 12
Training loss: 3.5500780338790947
Validation loss: 3.787655633201884

Epoch: 6| Step: 13
Training loss: 4.186928325745694
Validation loss: 3.7875553998452753

Epoch: 33| Step: 0
Training loss: 3.5036723081131833
Validation loss: 3.78725162150471

Epoch: 6| Step: 1
Training loss: 4.748627112902998
Validation loss: 3.7866049070411583

Epoch: 6| Step: 2
Training loss: 4.3919382540977985
Validation loss: 3.7854592280473573

Epoch: 6| Step: 3
Training loss: 4.34581197195146
Validation loss: 3.7861538313906866

Epoch: 6| Step: 4
Training loss: 4.264514149656112
Validation loss: 3.784284360816029

Epoch: 6| Step: 5
Training loss: 3.157929681701724
Validation loss: 3.7851269504108154

Epoch: 6| Step: 6
Training loss: 2.5102908048828416
Validation loss: 3.784754021192299

Epoch: 6| Step: 7
Training loss: 4.225637733136737
Validation loss: 3.7845475698087747

Epoch: 6| Step: 8
Training loss: 4.106928688294018
Validation loss: 3.7839340559371353

Epoch: 6| Step: 9
Training loss: 4.053644946651794
Validation loss: 3.7836466914031845

Epoch: 6| Step: 10
Training loss: 3.7796771348587983
Validation loss: 3.782945237160908

Epoch: 6| Step: 11
Training loss: 3.8381806009250505
Validation loss: 3.782701322772073

Epoch: 6| Step: 12
Training loss: 3.8072025203400712
Validation loss: 3.782251831267499

Epoch: 6| Step: 13
Training loss: 4.397948974799108
Validation loss: 3.7815701972772064

Epoch: 34| Step: 0
Training loss: 3.3568267383561476
Validation loss: 3.7812309525682206

Epoch: 6| Step: 1
Training loss: 4.512021431946412
Validation loss: 3.78123281704307

Epoch: 6| Step: 2
Training loss: 3.6252124329507915
Validation loss: 3.7805669173144976

Epoch: 6| Step: 3
Training loss: 4.450214277959094
Validation loss: 3.7807131299445422

Epoch: 6| Step: 4
Training loss: 3.9477536344793505
Validation loss: 3.780980677459805

Epoch: 6| Step: 5
Training loss: 3.888825640088379
Validation loss: 3.779959601946929

Epoch: 6| Step: 6
Training loss: 3.333823899092622
Validation loss: 3.7798216686642956

Epoch: 6| Step: 7
Training loss: 4.09180340094945
Validation loss: 3.779580686383981

Epoch: 6| Step: 8
Training loss: 3.562924811482874
Validation loss: 3.779278329193924

Epoch: 6| Step: 9
Training loss: 4.231700094561005
Validation loss: 3.77949007835714

Epoch: 6| Step: 10
Training loss: 3.7726414316612713
Validation loss: 3.7789042556424572

Epoch: 6| Step: 11
Training loss: 4.02007240382036
Validation loss: 3.778780079073588

Epoch: 6| Step: 12
Training loss: 4.347732365054184
Validation loss: 3.7772716196303837

Epoch: 6| Step: 13
Training loss: 4.100972799869981
Validation loss: 3.777660893359838

Epoch: 35| Step: 0
Training loss: 2.6850988617780858
Validation loss: 3.776467371597704

Epoch: 6| Step: 1
Training loss: 4.121174280907479
Validation loss: 3.776224613814413

Epoch: 6| Step: 2
Training loss: 4.689114305361941
Validation loss: 3.7756528773735942

Epoch: 6| Step: 3
Training loss: 4.002788048886256
Validation loss: 3.775662459306022

Epoch: 6| Step: 4
Training loss: 4.860148769974452
Validation loss: 3.77534382256816

Epoch: 6| Step: 5
Training loss: 3.7855209316631786
Validation loss: 3.7760035825286202

Epoch: 6| Step: 6
Training loss: 3.361351673635554
Validation loss: 3.7748455692684844

Epoch: 6| Step: 7
Training loss: 4.2668361411609865
Validation loss: 3.7743005706713637

Epoch: 6| Step: 8
Training loss: 4.3891546971003566
Validation loss: 3.7738698561638113

Epoch: 6| Step: 9
Training loss: 4.233909665823021
Validation loss: 3.7740338660446513

Epoch: 6| Step: 10
Training loss: 3.5516524216646546
Validation loss: 3.772812459864697

Epoch: 6| Step: 11
Training loss: 3.730656899705508
Validation loss: 3.773348357372434

Epoch: 6| Step: 12
Training loss: 2.42757095437505
Validation loss: 3.772806580792706

Epoch: 6| Step: 13
Training loss: 4.768597385669221
Validation loss: 3.771978176065249

Epoch: 36| Step: 0
Training loss: 3.3350671709379363
Validation loss: 3.7719800954080913

Epoch: 6| Step: 1
Training loss: 4.229623077770038
Validation loss: 3.7711479197652134

Epoch: 6| Step: 2
Training loss: 4.206726119824869
Validation loss: 3.771299651637126

Epoch: 6| Step: 3
Training loss: 3.9422927025944796
Validation loss: 3.7710078299969068

Epoch: 6| Step: 4
Training loss: 3.876924344587759
Validation loss: 3.770446876289529

Epoch: 6| Step: 5
Training loss: 4.028829158202955
Validation loss: 3.7702204636194314

Epoch: 6| Step: 6
Training loss: 4.12189065902778
Validation loss: 3.7700132075172217

Epoch: 6| Step: 7
Training loss: 3.607940653048552
Validation loss: 3.7698891508643513

Epoch: 6| Step: 8
Training loss: 4.991767208931528
Validation loss: 3.769294444246098

Epoch: 6| Step: 9
Training loss: 3.2381270755009424
Validation loss: 3.768649599155607

Epoch: 6| Step: 10
Training loss: 3.6669062333884255
Validation loss: 3.768631394142221

Epoch: 6| Step: 11
Training loss: 4.368185785667257
Validation loss: 3.768691029144502

Epoch: 6| Step: 12
Training loss: 3.543623858432047
Validation loss: 3.768861587688119

Epoch: 6| Step: 13
Training loss: 3.6753772671700347
Validation loss: 3.768374975872871

Epoch: 37| Step: 0
Training loss: 4.63015398037236
Validation loss: 3.767836426417693

Epoch: 6| Step: 1
Training loss: 3.663510409082531
Validation loss: 3.767091548832816

Epoch: 6| Step: 2
Training loss: 4.319711157008125
Validation loss: 3.767024401128718

Epoch: 6| Step: 3
Training loss: 4.374951607572765
Validation loss: 3.7664044335640816

Epoch: 6| Step: 4
Training loss: 4.312665853213603
Validation loss: 3.7662492671267302

Epoch: 6| Step: 5
Training loss: 4.224677097238052
Validation loss: 3.7656049571701464

Epoch: 6| Step: 6
Training loss: 3.65743086566368
Validation loss: 3.7651641200116823

Epoch: 6| Step: 7
Training loss: 4.007809406599074
Validation loss: 3.7649468367955685

Epoch: 6| Step: 8
Training loss: 4.64337467201674
Validation loss: 3.7645515699375824

Epoch: 6| Step: 9
Training loss: 3.504295710222329
Validation loss: 3.764096156296041

Epoch: 6| Step: 10
Training loss: 2.72182317217986
Validation loss: 3.763802349174042

Epoch: 6| Step: 11
Training loss: 2.537427170182808
Validation loss: 3.764040053493386

Epoch: 6| Step: 12
Training loss: 3.8442150547949585
Validation loss: 3.7637755152605856

Epoch: 6| Step: 13
Training loss: 4.267924488947687
Validation loss: 3.763404576541245

Epoch: 38| Step: 0
Training loss: 3.759147930184544
Validation loss: 3.7627204957689604

Epoch: 6| Step: 1
Training loss: 4.4470209415423945
Validation loss: 3.762261771652382

Epoch: 6| Step: 2
Training loss: 2.7303968864883656
Validation loss: 3.762264009400273

Epoch: 6| Step: 3
Training loss: 3.381587346254223
Validation loss: 3.762122422206854

Epoch: 6| Step: 4
Training loss: 4.490363505374636
Validation loss: 3.761826846486643

Epoch: 6| Step: 5
Training loss: 4.344772547836266
Validation loss: 3.7618936181086484

Epoch: 6| Step: 6
Training loss: 3.79516060510681
Validation loss: 3.7614763039685335

Epoch: 6| Step: 7
Training loss: 4.14406687357788
Validation loss: 3.760996230559255

Epoch: 6| Step: 8
Training loss: 2.727774014786531
Validation loss: 3.7606487805308233

Epoch: 6| Step: 9
Training loss: 4.153388393480042
Validation loss: 3.7603718685621956

Epoch: 6| Step: 10
Training loss: 4.705591511854852
Validation loss: 3.760010699970605

Epoch: 6| Step: 11
Training loss: 4.488279550151985
Validation loss: 3.760042389345146

Epoch: 6| Step: 12
Training loss: 3.2615263556655756
Validation loss: 3.7601174983279084

Epoch: 6| Step: 13
Training loss: 4.173376377562171
Validation loss: 3.7595801090049092

Epoch: 39| Step: 0
Training loss: 4.135193223786148
Validation loss: 3.7589776374537496

Epoch: 6| Step: 1
Training loss: 4.394480468456594
Validation loss: 3.7589526296200817

Epoch: 6| Step: 2
Training loss: 3.5375490973741988
Validation loss: 3.758409893817782

Epoch: 6| Step: 3
Training loss: 4.320388876048452
Validation loss: 3.7579094798774237

Epoch: 6| Step: 4
Training loss: 3.0260602432880117
Validation loss: 3.7580160009523578

Epoch: 6| Step: 5
Training loss: 3.674811045661188
Validation loss: 3.757721287948972

Epoch: 6| Step: 6
Training loss: 4.481884414265057
Validation loss: 3.7576420607856518

Epoch: 6| Step: 7
Training loss: 3.3330932212815365
Validation loss: 3.756942366185861

Epoch: 6| Step: 8
Training loss: 3.663749632664548
Validation loss: 3.756555852272058

Epoch: 6| Step: 9
Training loss: 4.027452439655436
Validation loss: 3.7564473311203046

Epoch: 6| Step: 10
Training loss: 4.22053252814938
Validation loss: 3.7556444368024366

Epoch: 6| Step: 11
Training loss: 4.473871457459534
Validation loss: 3.755648914721693

Epoch: 6| Step: 12
Training loss: 3.6107764227548165
Validation loss: 3.7555752795763477

Epoch: 6| Step: 13
Training loss: 3.8903944567660282
Validation loss: 3.755112084738587

Epoch: 40| Step: 0
Training loss: 3.9912115348589596
Validation loss: 3.7547588369793767

Epoch: 6| Step: 1
Training loss: 4.750763881898137
Validation loss: 3.7543636979463986

Epoch: 6| Step: 2
Training loss: 4.172006212092719
Validation loss: 3.7541945607759515

Epoch: 6| Step: 3
Training loss: 3.5512278730219395
Validation loss: 3.753791737933082

Epoch: 6| Step: 4
Training loss: 2.9940164021442155
Validation loss: 3.7542910017863087

Epoch: 6| Step: 5
Training loss: 3.9777818170689176
Validation loss: 3.75378267248426

Epoch: 6| Step: 6
Training loss: 3.7040458210362273
Validation loss: 3.753443828631943

Epoch: 6| Step: 7
Training loss: 3.7765722423801855
Validation loss: 3.7529068977208966

Epoch: 6| Step: 8
Training loss: 4.165863163085735
Validation loss: 3.752258313992066

Epoch: 6| Step: 9
Training loss: 3.8616684496901117
Validation loss: 3.7519343743387394

Epoch: 6| Step: 10
Training loss: 4.9882606021988485
Validation loss: 3.7519263757955152

Epoch: 6| Step: 11
Training loss: 3.194698209404125
Validation loss: 3.7513458872087133

Epoch: 6| Step: 12
Training loss: 3.4521215025027714
Validation loss: 3.7516126521821156

Epoch: 6| Step: 13
Training loss: 4.113322519528246
Validation loss: 3.7508293752379678

Epoch: 41| Step: 0
Training loss: 4.38605867278954
Validation loss: 3.750843814542559

Epoch: 6| Step: 1
Training loss: 4.50034267392376
Validation loss: 3.7502973267738233

Epoch: 6| Step: 2
Training loss: 3.415121721636901
Validation loss: 3.7503417334494746

Epoch: 6| Step: 3
Training loss: 3.092399996202178
Validation loss: 3.7502556334292203

Epoch: 6| Step: 4
Training loss: 4.527002066619988
Validation loss: 3.7504305725657576

Epoch: 6| Step: 5
Training loss: 4.190449145877976
Validation loss: 3.7491459109727434

Epoch: 6| Step: 6
Training loss: 3.5224895005512993
Validation loss: 3.749657744509389

Epoch: 6| Step: 7
Training loss: 3.4776381982236364
Validation loss: 3.748392791612053

Epoch: 6| Step: 8
Training loss: 4.763608211828591
Validation loss: 3.7487777796455486

Epoch: 6| Step: 9
Training loss: 3.644180591718609
Validation loss: 3.7488821749514187

Epoch: 6| Step: 10
Training loss: 4.296351175457095
Validation loss: 3.748552468230459

Epoch: 6| Step: 11
Training loss: 3.214075935420995
Validation loss: 3.7480274727830816

Epoch: 6| Step: 12
Training loss: 4.075552761290006
Validation loss: 3.7471791558446004

Epoch: 6| Step: 13
Training loss: 2.991167895748114
Validation loss: 3.74735861696805

Epoch: 42| Step: 0
Training loss: 3.1916828012349114
Validation loss: 3.746763613002068

Epoch: 6| Step: 1
Training loss: 3.882830921029618
Validation loss: 3.747177040445589

Epoch: 6| Step: 2
Training loss: 4.215838522625426
Validation loss: 3.7466805755382753

Epoch: 6| Step: 3
Training loss: 4.114908068755199
Validation loss: 3.745753193564845

Epoch: 6| Step: 4
Training loss: 4.1467603608694965
Validation loss: 3.7457645096254746

Epoch: 6| Step: 5
Training loss: 3.4317812426724688
Validation loss: 3.745336194722178

Epoch: 6| Step: 6
Training loss: 5.319808062195808
Validation loss: 3.7460863028918956

Epoch: 6| Step: 7
Training loss: 3.775505810128552
Validation loss: 3.745525269025777

Epoch: 6| Step: 8
Training loss: 3.1982811006697593
Validation loss: 3.7450389573607503

Epoch: 6| Step: 9
Training loss: 3.4546444687046116
Validation loss: 3.745057643972097

Epoch: 6| Step: 10
Training loss: 4.755722413646446
Validation loss: 3.7455133814057455

Epoch: 6| Step: 11
Training loss: 3.2674489745378574
Validation loss: 3.7452525807453396

Epoch: 6| Step: 12
Training loss: 3.8753159917153246
Validation loss: 3.7455074991827555

Epoch: 6| Step: 13
Training loss: 3.6489331972630548
Validation loss: 3.7453930561432065

Epoch: 43| Step: 0
Training loss: 4.527757443081388
Validation loss: 3.7448824223532817

Epoch: 6| Step: 1
Training loss: 3.9595757124201696
Validation loss: 3.7444367683924074

Epoch: 6| Step: 2
Training loss: 4.026529786728652
Validation loss: 3.7432473615169184

Epoch: 6| Step: 3
Training loss: 4.11924920768751
Validation loss: 3.742479779669878

Epoch: 6| Step: 4
Training loss: 3.938052789546427
Validation loss: 3.742683122466063

Epoch: 6| Step: 5
Training loss: 3.2908397231366378
Validation loss: 3.742025823973616

Epoch: 6| Step: 6
Training loss: 3.3211462073713807
Validation loss: 3.7415575655929962

Epoch: 6| Step: 7
Training loss: 4.230539985261283
Validation loss: 3.7414436238956044

Epoch: 6| Step: 8
Training loss: 4.567648921683116
Validation loss: 3.7414816592056717

Epoch: 6| Step: 9
Training loss: 3.9107166845186145
Validation loss: 3.741436792436136

Epoch: 6| Step: 10
Training loss: 4.081074200008689
Validation loss: 3.7409405347377254

Epoch: 6| Step: 11
Training loss: 3.8087277119869856
Validation loss: 3.740915110278316

Epoch: 6| Step: 12
Training loss: 3.238128400814448
Validation loss: 3.7410751458047997

Epoch: 6| Step: 13
Training loss: 3.429371326097648
Validation loss: 3.7400447987941043

Epoch: 44| Step: 0
Training loss: 4.230921614510233
Validation loss: 3.739871238374869

Epoch: 6| Step: 1
Training loss: 4.144763188609023
Validation loss: 3.73940353836546

Epoch: 6| Step: 2
Training loss: 4.76553955001517
Validation loss: 3.7396406807491145

Epoch: 6| Step: 3
Training loss: 3.2697663399277643
Validation loss: 3.7389618266328415

Epoch: 6| Step: 4
Training loss: 3.3694198536916797
Validation loss: 3.738898485219113

Epoch: 6| Step: 5
Training loss: 3.6297679982514546
Validation loss: 3.73856090496966

Epoch: 6| Step: 6
Training loss: 3.7074218801446763
Validation loss: 3.737871859103013

Epoch: 6| Step: 7
Training loss: 3.008409475558777
Validation loss: 3.737663318866985

Epoch: 6| Step: 8
Training loss: 4.095174527018144
Validation loss: 3.73748479835864

Epoch: 6| Step: 9
Training loss: 3.0907815891630355
Validation loss: 3.737620488660142

Epoch: 6| Step: 10
Training loss: 3.854188716241122
Validation loss: 3.7368559111665296

Epoch: 6| Step: 11
Training loss: 4.337986037756407
Validation loss: 3.7374319679103767

Epoch: 6| Step: 12
Training loss: 4.990659763547129
Validation loss: 3.7362060753366717

Epoch: 6| Step: 13
Training loss: 3.7603179129668796
Validation loss: 3.7365605514912046

Epoch: 45| Step: 0
Training loss: 4.261679141300241
Validation loss: 3.7357289101405367

Epoch: 6| Step: 1
Training loss: 3.8140898344505194
Validation loss: 3.7354872026399755

Epoch: 6| Step: 2
Training loss: 2.9528215847870785
Validation loss: 3.7353043297667354

Epoch: 6| Step: 3
Training loss: 2.871834048372503
Validation loss: 3.7351134298654713

Epoch: 6| Step: 4
Training loss: 4.431778779110331
Validation loss: 3.734326420345862

Epoch: 6| Step: 5
Training loss: 3.875781195866823
Validation loss: 3.734755222225289

Epoch: 6| Step: 6
Training loss: 3.7156466830738224
Validation loss: 3.7341784628333143

Epoch: 6| Step: 7
Training loss: 4.6954315221239336
Validation loss: 3.733769923895434

Epoch: 6| Step: 8
Training loss: 4.896633174843161
Validation loss: 3.7334502442098

Epoch: 6| Step: 9
Training loss: 4.449941681897645
Validation loss: 3.7331708175764664

Epoch: 6| Step: 10
Training loss: 3.805909510825217
Validation loss: 3.7329770697921676

Epoch: 6| Step: 11
Training loss: 3.5425758690742213
Validation loss: 3.732386479709739

Epoch: 6| Step: 12
Training loss: 3.456713852617036
Validation loss: 3.732439604114537

Epoch: 6| Step: 13
Training loss: 3.080329841192659
Validation loss: 3.732605363002564

Epoch: 46| Step: 0
Training loss: 3.3337277814813415
Validation loss: 3.732467668858689

Epoch: 6| Step: 1
Training loss: 2.6043837088102175
Validation loss: 3.731578915426802

Epoch: 6| Step: 2
Training loss: 4.236673892355419
Validation loss: 3.7311731590130472

Epoch: 6| Step: 3
Training loss: 3.5593235511176173
Validation loss: 3.7310735506786177

Epoch: 6| Step: 4
Training loss: 4.1050773165411
Validation loss: 3.730878088819584

Epoch: 6| Step: 5
Training loss: 4.575831545109985
Validation loss: 3.730827721018073

Epoch: 6| Step: 6
Training loss: 4.642151860755465
Validation loss: 3.730126805507621

Epoch: 6| Step: 7
Training loss: 3.463333987938749
Validation loss: 3.7303221830286097

Epoch: 6| Step: 8
Training loss: 4.481104705029933
Validation loss: 3.729897509562886

Epoch: 6| Step: 9
Training loss: 4.124257338744929
Validation loss: 3.7291873104761253

Epoch: 6| Step: 10
Training loss: 3.5316496766350656
Validation loss: 3.7292758863556026

Epoch: 6| Step: 11
Training loss: 3.841453796800011
Validation loss: 3.7289076840245627

Epoch: 6| Step: 12
Training loss: 4.598765016714278
Validation loss: 3.728794134060328

Epoch: 6| Step: 13
Training loss: 2.1662578808464485
Validation loss: 3.728410770822394

Epoch: 47| Step: 0
Training loss: 3.8524624467587643
Validation loss: 3.728378019101998

Epoch: 6| Step: 1
Training loss: 3.0530467590489754
Validation loss: 3.728053762095701

Epoch: 6| Step: 2
Training loss: 2.702479379100627
Validation loss: 3.727710521848832

Epoch: 6| Step: 3
Training loss: 4.881492790406739
Validation loss: 3.7276146462147963

Epoch: 6| Step: 4
Training loss: 4.523627242620217
Validation loss: 3.727950128627502

Epoch: 6| Step: 5
Training loss: 3.79176746835267
Validation loss: 3.7268407381597846

Epoch: 6| Step: 6
Training loss: 3.5357527930294457
Validation loss: 3.7267370475709316

Epoch: 6| Step: 7
Training loss: 3.7084438578961887
Validation loss: 3.72658082109607

Epoch: 6| Step: 8
Training loss: 3.6648515774804493
Validation loss: 3.7262827742727014

Epoch: 6| Step: 9
Training loss: 4.423223175386625
Validation loss: 3.726079700603162

Epoch: 6| Step: 10
Training loss: 4.34781505915031
Validation loss: 3.725616348037764

Epoch: 6| Step: 11
Training loss: 4.301774106985314
Validation loss: 3.7258199189810166

Epoch: 6| Step: 12
Training loss: 3.5016701664302667
Validation loss: 3.724996109485762

Epoch: 6| Step: 13
Training loss: 3.902776654033265
Validation loss: 3.725043887231996

Epoch: 48| Step: 0
Training loss: 4.5595128980442245
Validation loss: 3.7251624968882084

Epoch: 6| Step: 1
Training loss: 3.4423787954320533
Validation loss: 3.7244716770926134

Epoch: 6| Step: 2
Training loss: 3.3350983397298717
Validation loss: 3.724534671908289

Epoch: 6| Step: 3
Training loss: 4.140269829254272
Validation loss: 3.724324856215489

Epoch: 6| Step: 4
Training loss: 3.193952126274989
Validation loss: 3.7240518601944936

Epoch: 6| Step: 5
Training loss: 4.923183303609808
Validation loss: 3.72374273195663

Epoch: 6| Step: 6
Training loss: 4.179673353509939
Validation loss: 3.7237083970187945

Epoch: 6| Step: 7
Training loss: 3.453901799028036
Validation loss: 3.7236306479233874

Epoch: 6| Step: 8
Training loss: 3.3559535856436007
Validation loss: 3.722880929228764

Epoch: 6| Step: 9
Training loss: 4.387718243075236
Validation loss: 3.7227084637572725

Epoch: 6| Step: 10
Training loss: 3.6283440785795764
Validation loss: 3.722760534922446

Epoch: 6| Step: 11
Training loss: 3.775299686889781
Validation loss: 3.7225574398989867

Epoch: 6| Step: 12
Training loss: 3.998590936433572
Validation loss: 3.721739848893491

Epoch: 6| Step: 13
Training loss: 3.9135812551110325
Validation loss: 3.7212394887798124

Epoch: 49| Step: 0
Training loss: 3.995616656896914
Validation loss: 3.721010531188387

Epoch: 6| Step: 1
Training loss: 3.3197026668828022
Validation loss: 3.7207937190652483

Epoch: 6| Step: 2
Training loss: 3.391315302039054
Validation loss: 3.720819684768046

Epoch: 6| Step: 3
Training loss: 4.19448338561406
Validation loss: 3.7202203824748143

Epoch: 6| Step: 4
Training loss: 3.1718094541795927
Validation loss: 3.7199834231164868

Epoch: 6| Step: 5
Training loss: 3.6676676568712936
Validation loss: 3.719543623282338

Epoch: 6| Step: 6
Training loss: 3.54862307857346
Validation loss: 3.7194566890224157

Epoch: 6| Step: 7
Training loss: 4.605706465186099
Validation loss: 3.7192112329948053

Epoch: 6| Step: 8
Training loss: 3.8724231150353847
Validation loss: 3.71880502333504

Epoch: 6| Step: 9
Training loss: 4.637959238022116
Validation loss: 3.718761962143398

Epoch: 6| Step: 10
Training loss: 4.264315561380425
Validation loss: 3.718283840766453

Epoch: 6| Step: 11
Training loss: 3.3408110350006375
Validation loss: 3.718059809062413

Epoch: 6| Step: 12
Training loss: 3.3644522689628684
Validation loss: 3.71780532829313

Epoch: 6| Step: 13
Training loss: 5.39456589982536
Validation loss: 3.717641991972768

Epoch: 50| Step: 0
Training loss: 4.062341070734409
Validation loss: 3.7171108983199255

Epoch: 6| Step: 1
Training loss: 2.649002960065179
Validation loss: 3.7170406737927624

Epoch: 6| Step: 2
Training loss: 4.1094513512542274
Validation loss: 3.7168025005528356

Epoch: 6| Step: 3
Training loss: 4.563207493104173
Validation loss: 3.7163797037007673

Epoch: 6| Step: 4
Training loss: 3.513123839017971
Validation loss: 3.7160827372432736

Epoch: 6| Step: 5
Training loss: 3.9158753481733353
Validation loss: 3.7159389764784416

Epoch: 6| Step: 6
Training loss: 3.583288074178015
Validation loss: 3.71564604003279

Epoch: 6| Step: 7
Training loss: 4.439721854149415
Validation loss: 3.7154725018212367

Epoch: 6| Step: 8
Training loss: 2.0458683712737056
Validation loss: 3.7149651861894104

Epoch: 6| Step: 9
Training loss: 4.318921160032013
Validation loss: 3.7149821939779906

Epoch: 6| Step: 10
Training loss: 4.056090007618463
Validation loss: 3.714463884501504

Epoch: 6| Step: 11
Training loss: 3.6489329359060227
Validation loss: 3.714304880689779

Epoch: 6| Step: 12
Training loss: 4.367178983458266
Validation loss: 3.7139161465952064

Epoch: 6| Step: 13
Training loss: 4.885307370436142
Validation loss: 3.713495764602344

Testing loss: 3.869385653418325
