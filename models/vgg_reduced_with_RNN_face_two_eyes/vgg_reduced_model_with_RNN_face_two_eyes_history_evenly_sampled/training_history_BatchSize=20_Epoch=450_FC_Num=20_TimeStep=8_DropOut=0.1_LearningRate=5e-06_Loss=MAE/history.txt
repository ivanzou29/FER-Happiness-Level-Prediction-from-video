Epoch: 1| Step: 0
Training loss: 5.137851715087891
Validation loss: 5.186905537882159

Epoch: 5| Step: 1
Training loss: 4.979395389556885
Validation loss: 5.181708623004216

Epoch: 5| Step: 2
Training loss: 4.429691314697266
Validation loss: 5.176814340776013

Epoch: 5| Step: 3
Training loss: 4.076529502868652
Validation loss: 5.1720579619048745

Epoch: 5| Step: 4
Training loss: 5.982346534729004
Validation loss: 5.166987531928606

Epoch: 5| Step: 5
Training loss: 4.854027271270752
Validation loss: 5.161620324657809

Epoch: 5| Step: 6
Training loss: 5.558889865875244
Validation loss: 5.156494591825751

Epoch: 5| Step: 7
Training loss: 5.226962089538574
Validation loss: 5.150693601177585

Epoch: 5| Step: 8
Training loss: 4.9865570068359375
Validation loss: 5.14442108010733

Epoch: 5| Step: 9
Training loss: 4.016427040100098
Validation loss: 5.1380342565557005

Epoch: 5| Step: 10
Training loss: 5.326443672180176
Validation loss: 5.131230954200991

Epoch: 2| Step: 0
Training loss: 4.4256911277771
Validation loss: 5.12444386430966

Epoch: 5| Step: 1
Training loss: 5.7582831382751465
Validation loss: 5.117222104021298

Epoch: 5| Step: 2
Training loss: 5.130152702331543
Validation loss: 5.110088917516893

Epoch: 5| Step: 3
Training loss: 4.3883490562438965
Validation loss: 5.102213423739197

Epoch: 5| Step: 4
Training loss: 4.874545097351074
Validation loss: 5.094401482612856

Epoch: 5| Step: 5
Training loss: 6.180875778198242
Validation loss: 5.085807764401999

Epoch: 5| Step: 6
Training loss: 5.366858005523682
Validation loss: 5.0766923248126945

Epoch: 5| Step: 7
Training loss: 5.629008769989014
Validation loss: 5.067352207758093

Epoch: 5| Step: 8
Training loss: 4.5806379318237305
Validation loss: 5.058342046635126

Epoch: 5| Step: 9
Training loss: 2.4762682914733887
Validation loss: 5.047824618636921

Epoch: 5| Step: 10
Training loss: 4.849178314208984
Validation loss: 5.037586289067423

Epoch: 3| Step: 0
Training loss: 3.745492458343506
Validation loss: 5.026958634776454

Epoch: 5| Step: 1
Training loss: 5.260815620422363
Validation loss: 5.015777823745563

Epoch: 5| Step: 2
Training loss: 5.448077201843262
Validation loss: 5.003685479523034

Epoch: 5| Step: 3
Training loss: 4.348900318145752
Validation loss: 4.990684232404155

Epoch: 5| Step: 4
Training loss: 5.352898597717285
Validation loss: 4.976763099752446

Epoch: 5| Step: 5
Training loss: 3.921330213546753
Validation loss: 4.964230491269019

Epoch: 5| Step: 6
Training loss: 5.431462287902832
Validation loss: 4.949310851353471

Epoch: 5| Step: 7
Training loss: 5.442649841308594
Validation loss: 4.934895556460145

Epoch: 5| Step: 8
Training loss: 4.079791069030762
Validation loss: 4.918793098900908

Epoch: 5| Step: 9
Training loss: 4.8845415115356445
Validation loss: 4.902190121271277

Epoch: 5| Step: 10
Training loss: 4.314023971557617
Validation loss: 4.885009017041934

Epoch: 4| Step: 0
Training loss: 4.8399786949157715
Validation loss: 4.867509688100507

Epoch: 5| Step: 1
Training loss: 4.580050468444824
Validation loss: 4.848779724490258

Epoch: 5| Step: 2
Training loss: 5.325926780700684
Validation loss: 4.829738750252672

Epoch: 5| Step: 3
Training loss: 4.776813507080078
Validation loss: 4.809367015797605

Epoch: 5| Step: 4
Training loss: 4.071366786956787
Validation loss: 4.787466351703931

Epoch: 5| Step: 5
Training loss: 5.4352264404296875
Validation loss: 4.764993524038664

Epoch: 5| Step: 6
Training loss: 3.958130359649658
Validation loss: 4.743042668988628

Epoch: 5| Step: 7
Training loss: 4.3892412185668945
Validation loss: 4.720407880762572

Epoch: 5| Step: 8
Training loss: 3.7345986366271973
Validation loss: 4.6974797197567515

Epoch: 5| Step: 9
Training loss: 4.899350166320801
Validation loss: 4.6710033673112115

Epoch: 5| Step: 10
Training loss: 3.92242431640625
Validation loss: 4.645348115633893

Epoch: 5| Step: 0
Training loss: 4.407825469970703
Validation loss: 4.619522253672282

Epoch: 5| Step: 1
Training loss: 4.862135410308838
Validation loss: 4.5945345637618855

Epoch: 5| Step: 2
Training loss: 5.098208427429199
Validation loss: 4.566175891507056

Epoch: 5| Step: 3
Training loss: 4.130852699279785
Validation loss: 4.535542682934833

Epoch: 5| Step: 4
Training loss: 4.000274658203125
Validation loss: 4.507455251550161

Epoch: 5| Step: 5
Training loss: 4.505381107330322
Validation loss: 4.47947887707782

Epoch: 5| Step: 6
Training loss: 3.6110634803771973
Validation loss: 4.449218078326154

Epoch: 5| Step: 7
Training loss: 3.9404799938201904
Validation loss: 4.421795455358362

Epoch: 5| Step: 8
Training loss: 3.936176300048828
Validation loss: 4.391887208466889

Epoch: 5| Step: 9
Training loss: 4.266658782958984
Validation loss: 4.360369190093009

Epoch: 5| Step: 10
Training loss: 4.122594833374023
Validation loss: 4.332250754038493

Epoch: 6| Step: 0
Training loss: 3.7637343406677246
Validation loss: 4.303370891078826

Epoch: 5| Step: 1
Training loss: 4.483762264251709
Validation loss: 4.273908087002334

Epoch: 5| Step: 2
Training loss: 4.11970853805542
Validation loss: 4.2476101024176485

Epoch: 5| Step: 3
Training loss: 4.127692222595215
Validation loss: 4.218890856671077

Epoch: 5| Step: 4
Training loss: 4.260167121887207
Validation loss: 4.19201131533551

Epoch: 5| Step: 5
Training loss: 4.025029182434082
Validation loss: 4.165670410279305

Epoch: 5| Step: 6
Training loss: 3.7906546592712402
Validation loss: 4.140718962556573

Epoch: 5| Step: 7
Training loss: 4.033552169799805
Validation loss: 4.112789395034954

Epoch: 5| Step: 8
Training loss: 3.9238102436065674
Validation loss: 4.090525150299072

Epoch: 5| Step: 9
Training loss: 3.5796806812286377
Validation loss: 4.0669271151224775

Epoch: 5| Step: 10
Training loss: 3.6579654216766357
Validation loss: 4.044678657285629

Epoch: 7| Step: 0
Training loss: 3.6445212364196777
Validation loss: 4.018918191232989

Epoch: 5| Step: 1
Training loss: 4.637363433837891
Validation loss: 3.999132643463791

Epoch: 5| Step: 2
Training loss: 3.1967105865478516
Validation loss: 3.978437751852056

Epoch: 5| Step: 3
Training loss: 3.9030582904815674
Validation loss: 3.9584235683564217

Epoch: 5| Step: 4
Training loss: 3.6454806327819824
Validation loss: 3.9386968971580587

Epoch: 5| Step: 5
Training loss: 4.073359489440918
Validation loss: 3.9181438133280766

Epoch: 5| Step: 6
Training loss: 3.2862114906311035
Validation loss: 3.901980648758591

Epoch: 5| Step: 7
Training loss: 4.320420265197754
Validation loss: 3.8866058882846626

Epoch: 5| Step: 8
Training loss: 3.066943645477295
Validation loss: 3.870182750045612

Epoch: 5| Step: 9
Training loss: 3.632115602493286
Validation loss: 3.8582037802665465

Epoch: 5| Step: 10
Training loss: 4.323756217956543
Validation loss: 3.843112048282418

Epoch: 8| Step: 0
Training loss: 3.407991409301758
Validation loss: 3.833397739677019

Epoch: 5| Step: 1
Training loss: 3.753690242767334
Validation loss: 3.82053054019969

Epoch: 5| Step: 2
Training loss: 3.743389129638672
Validation loss: 3.808431609984367

Epoch: 5| Step: 3
Training loss: 3.046243667602539
Validation loss: 3.7975664548976447

Epoch: 5| Step: 4
Training loss: 3.4673049449920654
Validation loss: 3.7848348668826524

Epoch: 5| Step: 5
Training loss: 3.6741490364074707
Validation loss: 3.7746049845090477

Epoch: 5| Step: 6
Training loss: 4.7408671379089355
Validation loss: 3.7641752253296556

Epoch: 5| Step: 7
Training loss: 3.3316638469696045
Validation loss: 3.7535280668607323

Epoch: 5| Step: 8
Training loss: 3.787740707397461
Validation loss: 3.7416795863900134

Epoch: 5| Step: 9
Training loss: 4.1873779296875
Validation loss: 3.7318707537907425

Epoch: 5| Step: 10
Training loss: 3.065462112426758
Validation loss: 3.7228683143533687

Epoch: 9| Step: 0
Training loss: 2.575188398361206
Validation loss: 3.712165117263794

Epoch: 5| Step: 1
Training loss: 3.618748426437378
Validation loss: 3.703835377129175

Epoch: 5| Step: 2
Training loss: 2.485442876815796
Validation loss: 3.6949319557477067

Epoch: 5| Step: 3
Training loss: 4.3377814292907715
Validation loss: 3.684741473967029

Epoch: 5| Step: 4
Training loss: 4.209782600402832
Validation loss: 3.6747781974013134

Epoch: 5| Step: 5
Training loss: 4.294548988342285
Validation loss: 3.665657486966861

Epoch: 5| Step: 6
Training loss: 3.239255905151367
Validation loss: 3.6540852592837427

Epoch: 5| Step: 7
Training loss: 2.8864333629608154
Validation loss: 3.6441515312399915

Epoch: 5| Step: 8
Training loss: 3.4564766883850098
Validation loss: 3.6352975009590067

Epoch: 5| Step: 9
Training loss: 3.3495376110076904
Validation loss: 3.626427096705283

Epoch: 5| Step: 10
Training loss: 4.999420642852783
Validation loss: 3.6148887218967563

Epoch: 10| Step: 0
Training loss: 3.7210144996643066
Validation loss: 3.6051713343589538

Epoch: 5| Step: 1
Training loss: 3.235363721847534
Validation loss: 3.5963064957690496

Epoch: 5| Step: 2
Training loss: 2.9742071628570557
Validation loss: 3.5855594706791702

Epoch: 5| Step: 3
Training loss: 3.162949562072754
Validation loss: 3.575182294332853

Epoch: 5| Step: 4
Training loss: 3.4689602851867676
Validation loss: 3.5677789795783257

Epoch: 5| Step: 5
Training loss: 3.970917224884033
Validation loss: 3.5576223250358336

Epoch: 5| Step: 6
Training loss: 4.001132965087891
Validation loss: 3.545374483190557

Epoch: 5| Step: 7
Training loss: 3.64277720451355
Validation loss: 3.5381547609965005

Epoch: 5| Step: 8
Training loss: 3.1233129501342773
Validation loss: 3.527937586589526

Epoch: 5| Step: 9
Training loss: 3.489899158477783
Validation loss: 3.5206592852069485

Epoch: 5| Step: 10
Training loss: 3.515491485595703
Validation loss: 3.509373664855957

Epoch: 11| Step: 0
Training loss: 3.8958792686462402
Validation loss: 3.497950948694701

Epoch: 5| Step: 1
Training loss: 3.385713577270508
Validation loss: 3.4871017932891846

Epoch: 5| Step: 2
Training loss: 3.2744719982147217
Validation loss: 3.476223755908269

Epoch: 5| Step: 3
Training loss: 4.0147857666015625
Validation loss: 3.46612802884912

Epoch: 5| Step: 4
Training loss: 3.110384702682495
Validation loss: 3.454225878561697

Epoch: 5| Step: 5
Training loss: 3.31620454788208
Validation loss: 3.443194289361277

Epoch: 5| Step: 6
Training loss: 3.4767918586730957
Validation loss: 3.4327616665952947

Epoch: 5| Step: 7
Training loss: 3.257354259490967
Validation loss: 3.420184322582778

Epoch: 5| Step: 8
Training loss: 3.707104444503784
Validation loss: 3.409514086220854

Epoch: 5| Step: 9
Training loss: 3.049535036087036
Validation loss: 3.3944099000705186

Epoch: 5| Step: 10
Training loss: 2.656681776046753
Validation loss: 3.383155774044734

Epoch: 12| Step: 0
Training loss: 3.982567548751831
Validation loss: 3.3722237412647535

Epoch: 5| Step: 1
Training loss: 2.640207052230835
Validation loss: 3.361435256978517

Epoch: 5| Step: 2
Training loss: 3.102839708328247
Validation loss: 3.349909092790337

Epoch: 5| Step: 3
Training loss: 2.8729450702667236
Validation loss: 3.343466179345244

Epoch: 5| Step: 4
Training loss: 3.053527355194092
Validation loss: 3.3342928117321384

Epoch: 5| Step: 5
Training loss: 3.070276975631714
Validation loss: 3.3291929101431244

Epoch: 5| Step: 6
Training loss: 3.554741621017456
Validation loss: 3.320416804282896

Epoch: 5| Step: 7
Training loss: 3.8996188640594482
Validation loss: 3.3095316297264508

Epoch: 5| Step: 8
Training loss: 3.0374209880828857
Validation loss: 3.303106056746616

Epoch: 5| Step: 9
Training loss: 3.832806348800659
Validation loss: 3.2938355809898785

Epoch: 5| Step: 10
Training loss: 3.093930721282959
Validation loss: 3.2880141965804563

Epoch: 13| Step: 0
Training loss: 3.834735870361328
Validation loss: 3.2768219312032065

Epoch: 5| Step: 1
Training loss: 2.643364667892456
Validation loss: 3.272326664258075

Epoch: 5| Step: 2
Training loss: 3.503288984298706
Validation loss: 3.265907149161062

Epoch: 5| Step: 3
Training loss: 3.3172690868377686
Validation loss: 3.2552478236536824

Epoch: 5| Step: 4
Training loss: 3.4411520957946777
Validation loss: 3.253464016863095

Epoch: 5| Step: 5
Training loss: 2.989985466003418
Validation loss: 3.2433871761445077

Epoch: 5| Step: 6
Training loss: 3.691542387008667
Validation loss: 3.2400961537514963

Epoch: 5| Step: 7
Training loss: 2.6881134510040283
Validation loss: 3.231045730652348

Epoch: 5| Step: 8
Training loss: 3.5080223083496094
Validation loss: 3.225105462535735

Epoch: 5| Step: 9
Training loss: 2.589787721633911
Validation loss: 3.2189771462512273

Epoch: 5| Step: 10
Training loss: 3.2856760025024414
Validation loss: 3.2110919414028043

Epoch: 14| Step: 0
Training loss: 3.655884265899658
Validation loss: 3.2072680457945792

Epoch: 5| Step: 1
Training loss: 2.444185495376587
Validation loss: 3.200633066956715

Epoch: 5| Step: 2
Training loss: 2.555194139480591
Validation loss: 3.195352026211318

Epoch: 5| Step: 3
Training loss: 3.614388942718506
Validation loss: 3.1932223073897825

Epoch: 5| Step: 4
Training loss: 2.8983378410339355
Validation loss: 3.1818472416170183

Epoch: 5| Step: 5
Training loss: 3.163801670074463
Validation loss: 3.1757981418281473

Epoch: 5| Step: 6
Training loss: 3.4264767169952393
Validation loss: 3.17547341315977

Epoch: 5| Step: 7
Training loss: 4.164753437042236
Validation loss: 3.1709160317656813

Epoch: 5| Step: 8
Training loss: 2.3205573558807373
Validation loss: 3.163932631092687

Epoch: 5| Step: 9
Training loss: 2.68217134475708
Validation loss: 3.155720285190049

Epoch: 5| Step: 10
Training loss: 4.224088191986084
Validation loss: 3.152591556631109

Epoch: 15| Step: 0
Training loss: 3.2056972980499268
Validation loss: 3.1469022535508677

Epoch: 5| Step: 1
Training loss: 2.9033138751983643
Validation loss: 3.1402622294682327

Epoch: 5| Step: 2
Training loss: 3.526460647583008
Validation loss: 3.1371412328494492

Epoch: 5| Step: 3
Training loss: 2.9173545837402344
Validation loss: 3.132335098840857

Epoch: 5| Step: 4
Training loss: 2.4522573947906494
Validation loss: 3.1261317396676667

Epoch: 5| Step: 5
Training loss: 3.008035659790039
Validation loss: 3.120629564408333

Epoch: 5| Step: 6
Training loss: 3.220503330230713
Validation loss: 3.1209375268669537

Epoch: 5| Step: 7
Training loss: 4.620225429534912
Validation loss: 3.113723352391233

Epoch: 5| Step: 8
Training loss: 2.9053683280944824
Validation loss: 3.105442862356863

Epoch: 5| Step: 9
Training loss: 2.3282828330993652
Validation loss: 3.101345326310845

Epoch: 5| Step: 10
Training loss: 3.4920430183410645
Validation loss: 3.100352377019903

Epoch: 16| Step: 0
Training loss: 4.444512367248535
Validation loss: 3.0934760698708157

Epoch: 5| Step: 1
Training loss: 3.353785753250122
Validation loss: 3.089034508633357

Epoch: 5| Step: 2
Training loss: 1.9758507013320923
Validation loss: 3.085232503952519

Epoch: 5| Step: 3
Training loss: 2.9469542503356934
Validation loss: 3.084987868544876

Epoch: 5| Step: 4
Training loss: 3.3240394592285156
Validation loss: 3.08369969296199

Epoch: 5| Step: 5
Training loss: 3.140803575515747
Validation loss: 3.0827205104212605

Epoch: 5| Step: 6
Training loss: 3.004584550857544
Validation loss: 3.07242888276295

Epoch: 5| Step: 7
Training loss: 2.798520088195801
Validation loss: 3.06786681759742

Epoch: 5| Step: 8
Training loss: 2.725292921066284
Validation loss: 3.0649945761567805

Epoch: 5| Step: 9
Training loss: 3.0232856273651123
Validation loss: 3.07758193631326

Epoch: 5| Step: 10
Training loss: 3.5124943256378174
Validation loss: 3.063271409721785

Epoch: 17| Step: 0
Training loss: 2.5754737854003906
Validation loss: 3.0559163683204242

Epoch: 5| Step: 1
Training loss: 3.105825424194336
Validation loss: 3.0491129634200886

Epoch: 5| Step: 2
Training loss: 3.0563271045684814
Validation loss: 3.0467222839273433

Epoch: 5| Step: 3
Training loss: 2.563056468963623
Validation loss: 3.04696661426175

Epoch: 5| Step: 4
Training loss: 3.3175511360168457
Validation loss: 3.041324800060641

Epoch: 5| Step: 5
Training loss: 3.6248421669006348
Validation loss: 3.0416729501498643

Epoch: 5| Step: 6
Training loss: 3.3277745246887207
Validation loss: 3.0393715878968597

Epoch: 5| Step: 7
Training loss: 3.694361925125122
Validation loss: 3.0305255920656267

Epoch: 5| Step: 8
Training loss: 2.390324354171753
Validation loss: 3.0305139428825787

Epoch: 5| Step: 9
Training loss: 3.3794264793395996
Validation loss: 3.029257127033767

Epoch: 5| Step: 10
Training loss: 2.8823087215423584
Validation loss: 3.0209204509694088

Epoch: 18| Step: 0
Training loss: 2.7565834522247314
Validation loss: 3.0199833070078204

Epoch: 5| Step: 1
Training loss: 3.8482468128204346
Validation loss: 3.018085100317514

Epoch: 5| Step: 2
Training loss: 3.401960849761963
Validation loss: 3.0121575350402505

Epoch: 5| Step: 3
Training loss: 3.3954644203186035
Validation loss: 3.0079404179767897

Epoch: 5| Step: 4
Training loss: 3.25300669670105
Validation loss: 3.0074333862591813

Epoch: 5| Step: 5
Training loss: 2.5777366161346436
Validation loss: 3.0041940289158977

Epoch: 5| Step: 6
Training loss: 3.159379482269287
Validation loss: 2.9999923090780936

Epoch: 5| Step: 7
Training loss: 2.600297451019287
Validation loss: 2.994168625083021

Epoch: 5| Step: 8
Training loss: 2.504124879837036
Validation loss: 2.9963666110910396

Epoch: 5| Step: 9
Training loss: 2.0768749713897705
Validation loss: 2.991237043052591

Epoch: 5| Step: 10
Training loss: 4.313950061798096
Validation loss: 2.9924308792237313

Epoch: 19| Step: 0
Training loss: 3.0382773876190186
Validation loss: 2.989377303790021

Epoch: 5| Step: 1
Training loss: 3.4435107707977295
Validation loss: 2.9844898280277046

Epoch: 5| Step: 2
Training loss: 2.8066043853759766
Validation loss: 2.9804105656121367

Epoch: 5| Step: 3
Training loss: 3.0152087211608887
Validation loss: 2.981025118981638

Epoch: 5| Step: 4
Training loss: 2.809788465499878
Validation loss: 2.9832509256178334

Epoch: 5| Step: 5
Training loss: 2.882812976837158
Validation loss: 2.97425667701229

Epoch: 5| Step: 6
Training loss: 3.524543285369873
Validation loss: 2.9719145554368214

Epoch: 5| Step: 7
Training loss: 2.8790485858917236
Validation loss: 2.96799498732372

Epoch: 5| Step: 8
Training loss: 2.8357903957366943
Validation loss: 2.964288252656178

Epoch: 5| Step: 9
Training loss: 2.8623621463775635
Validation loss: 2.9642252511875604

Epoch: 5| Step: 10
Training loss: 3.4694557189941406
Validation loss: 2.960234490774011

Epoch: 20| Step: 0
Training loss: 4.213954925537109
Validation loss: 2.9595179455254668

Epoch: 5| Step: 1
Training loss: 2.4772121906280518
Validation loss: 2.955627559333719

Epoch: 5| Step: 2
Training loss: 3.0021767616271973
Validation loss: 2.953962743923228

Epoch: 5| Step: 3
Training loss: 2.3234708309173584
Validation loss: 2.9527224366382887

Epoch: 5| Step: 4
Training loss: 3.0621426105499268
Validation loss: 2.946938309618222

Epoch: 5| Step: 5
Training loss: 3.1236164569854736
Validation loss: 2.9411369190421155

Epoch: 5| Step: 6
Training loss: 3.0743207931518555
Validation loss: 2.941807564868722

Epoch: 5| Step: 7
Training loss: 3.4588356018066406
Validation loss: 2.9398034029109503

Epoch: 5| Step: 8
Training loss: 2.8441948890686035
Validation loss: 2.9363294134857836

Epoch: 5| Step: 9
Training loss: 3.2931504249572754
Validation loss: 2.9421403920778664

Epoch: 5| Step: 10
Training loss: 2.3495352268218994
Validation loss: 2.936792109602241

Epoch: 21| Step: 0
Training loss: 2.2763848304748535
Validation loss: 2.934967497343658

Epoch: 5| Step: 1
Training loss: 2.8060407638549805
Validation loss: 2.9286600261606197

Epoch: 5| Step: 2
Training loss: 3.3547561168670654
Validation loss: 2.930204668352681

Epoch: 5| Step: 3
Training loss: 3.456564426422119
Validation loss: 2.9288439058488414

Epoch: 5| Step: 4
Training loss: 3.3754801750183105
Validation loss: 2.9253389220083914

Epoch: 5| Step: 5
Training loss: 2.6649882793426514
Validation loss: 2.924698437413862

Epoch: 5| Step: 6
Training loss: 2.930875778198242
Validation loss: 2.9223768941817747

Epoch: 5| Step: 7
Training loss: 3.3288960456848145
Validation loss: 2.921282914377028

Epoch: 5| Step: 8
Training loss: 2.811264991760254
Validation loss: 2.9154287871494087

Epoch: 5| Step: 9
Training loss: 2.71504807472229
Validation loss: 2.9159128999197357

Epoch: 5| Step: 10
Training loss: 3.4667956829071045
Validation loss: 2.914043523932016

Epoch: 22| Step: 0
Training loss: 2.639948844909668
Validation loss: 2.9094320163931897

Epoch: 5| Step: 1
Training loss: 2.9386751651763916
Validation loss: 2.9118069448778705

Epoch: 5| Step: 2
Training loss: 3.3165156841278076
Validation loss: 2.9081238956861597

Epoch: 5| Step: 3
Training loss: 3.4498016834259033
Validation loss: 2.907369080410209

Epoch: 5| Step: 4
Training loss: 2.4758141040802
Validation loss: 2.9055821075234363

Epoch: 5| Step: 5
Training loss: 3.1904196739196777
Validation loss: 2.8998530167405323

Epoch: 5| Step: 6
Training loss: 3.2438552379608154
Validation loss: 2.8955299854278564

Epoch: 5| Step: 7
Training loss: 2.5889294147491455
Validation loss: 2.900994793061287

Epoch: 5| Step: 8
Training loss: 2.591869831085205
Validation loss: 2.8959601361264466

Epoch: 5| Step: 9
Training loss: 2.797685146331787
Validation loss: 2.8952093483299337

Epoch: 5| Step: 10
Training loss: 3.8901195526123047
Validation loss: 2.899932487036592

Epoch: 23| Step: 0
Training loss: 3.4760658740997314
Validation loss: 2.902399411765478

Epoch: 5| Step: 1
Training loss: 2.564619302749634
Validation loss: 2.8954991166309645

Epoch: 5| Step: 2
Training loss: 2.7664029598236084
Validation loss: 2.8911595139452206

Epoch: 5| Step: 3
Training loss: 2.250537157058716
Validation loss: 2.8871723041739514

Epoch: 5| Step: 4
Training loss: 2.804408311843872
Validation loss: 2.8848055511392574

Epoch: 5| Step: 5
Training loss: 3.171649932861328
Validation loss: 2.8788011561157885

Epoch: 5| Step: 6
Training loss: 2.875429630279541
Validation loss: 2.8794035065558647

Epoch: 5| Step: 7
Training loss: 3.715914249420166
Validation loss: 2.8737392169173046

Epoch: 5| Step: 8
Training loss: 3.14284086227417
Validation loss: 2.8717537977362193

Epoch: 5| Step: 9
Training loss: 3.0636701583862305
Validation loss: 2.868716388620356

Epoch: 5| Step: 10
Training loss: 2.999757766723633
Validation loss: 2.868651772058138

Epoch: 24| Step: 0
Training loss: 2.433685779571533
Validation loss: 2.8656842708587646

Epoch: 5| Step: 1
Training loss: 3.1340596675872803
Validation loss: 2.865889335191378

Epoch: 5| Step: 2
Training loss: 2.5362496376037598
Validation loss: 2.865431111346009

Epoch: 5| Step: 3
Training loss: 2.8042454719543457
Validation loss: 2.8653335853289534

Epoch: 5| Step: 4
Training loss: 3.3113903999328613
Validation loss: 2.8626431880458707

Epoch: 5| Step: 5
Training loss: 3.2311553955078125
Validation loss: 2.860412464346937

Epoch: 5| Step: 6
Training loss: 2.610344886779785
Validation loss: 2.858347228778306

Epoch: 5| Step: 7
Training loss: 2.9946770668029785
Validation loss: 2.857793605455788

Epoch: 5| Step: 8
Training loss: 3.8162612915039062
Validation loss: 2.8539879014415126

Epoch: 5| Step: 9
Training loss: 2.8492162227630615
Validation loss: 2.850417765237952

Epoch: 5| Step: 10
Training loss: 2.8970947265625
Validation loss: 2.8507171241186

Epoch: 25| Step: 0
Training loss: 2.4748024940490723
Validation loss: 2.8500011556891987

Epoch: 5| Step: 1
Training loss: 2.681405544281006
Validation loss: 2.848909954870901

Epoch: 5| Step: 2
Training loss: 3.354574680328369
Validation loss: 2.8521276930327057

Epoch: 5| Step: 3
Training loss: 2.9636662006378174
Validation loss: 2.846355656141876

Epoch: 5| Step: 4
Training loss: 4.017516613006592
Validation loss: 2.842729086517006

Epoch: 5| Step: 5
Training loss: 3.222324848175049
Validation loss: 2.8421956236644457

Epoch: 5| Step: 6
Training loss: 2.653050661087036
Validation loss: 2.8507127069657847

Epoch: 5| Step: 7
Training loss: 2.2753801345825195
Validation loss: 2.8353706175281155

Epoch: 5| Step: 8
Training loss: 2.555762767791748
Validation loss: 2.8385193271021687

Epoch: 5| Step: 9
Training loss: 3.3655738830566406
Validation loss: 2.8422315812879995

Epoch: 5| Step: 10
Training loss: 2.9714772701263428
Validation loss: 2.8470803486403597

Epoch: 26| Step: 0
Training loss: 2.690950393676758
Validation loss: 2.8463160684031825

Epoch: 5| Step: 1
Training loss: 2.9907631874084473
Validation loss: 2.8494423179216284

Epoch: 5| Step: 2
Training loss: 2.9821255207061768
Validation loss: 2.8445040948929323

Epoch: 5| Step: 3
Training loss: 3.4974265098571777
Validation loss: 2.833769513714698

Epoch: 5| Step: 4
Training loss: 2.9969615936279297
Validation loss: 2.827662919157295

Epoch: 5| Step: 5
Training loss: 3.234135389328003
Validation loss: 2.8230759046411

Epoch: 5| Step: 6
Training loss: 2.827606201171875
Validation loss: 2.8251116096332507

Epoch: 5| Step: 7
Training loss: 2.2014312744140625
Validation loss: 2.818763040727185

Epoch: 5| Step: 8
Training loss: 3.523853302001953
Validation loss: 2.815481253849563

Epoch: 5| Step: 9
Training loss: 2.412325859069824
Validation loss: 2.8173733475387737

Epoch: 5| Step: 10
Training loss: 3.1314494609832764
Validation loss: 2.8118132570738434

Epoch: 27| Step: 0
Training loss: 2.696345806121826
Validation loss: 2.811404869120608

Epoch: 5| Step: 1
Training loss: 3.0983195304870605
Validation loss: 2.810300801389961

Epoch: 5| Step: 2
Training loss: 3.554706573486328
Validation loss: 2.809998309740456

Epoch: 5| Step: 3
Training loss: 3.1331119537353516
Validation loss: 2.8061089720777286

Epoch: 5| Step: 4
Training loss: 2.4872045516967773
Validation loss: 2.8054406309640534

Epoch: 5| Step: 5
Training loss: 3.0397274494171143
Validation loss: 2.8086806163992932

Epoch: 5| Step: 6
Training loss: 2.5918235778808594
Validation loss: 2.8036763104059363

Epoch: 5| Step: 7
Training loss: 2.885101556777954
Validation loss: 2.8063440117784726

Epoch: 5| Step: 8
Training loss: 2.438286542892456
Validation loss: 2.804916856109455

Epoch: 5| Step: 9
Training loss: 2.993238687515259
Validation loss: 2.7991132018386677

Epoch: 5| Step: 10
Training loss: 3.429414749145508
Validation loss: 2.7988920878338557

Epoch: 28| Step: 0
Training loss: 2.6359260082244873
Validation loss: 2.7961037005147626

Epoch: 5| Step: 1
Training loss: 2.8619704246520996
Validation loss: 2.79454981383457

Epoch: 5| Step: 2
Training loss: 2.987277030944824
Validation loss: 2.7996416681556293

Epoch: 5| Step: 3
Training loss: 3.235607862472534
Validation loss: 2.7928902308146157

Epoch: 5| Step: 4
Training loss: 3.3348937034606934
Validation loss: 2.795056358460457

Epoch: 5| Step: 5
Training loss: 3.3369109630584717
Validation loss: 2.7911881631420505

Epoch: 5| Step: 6
Training loss: 3.1903483867645264
Validation loss: 2.7882865090523996

Epoch: 5| Step: 7
Training loss: 2.3061015605926514
Validation loss: 2.784058899007818

Epoch: 5| Step: 8
Training loss: 1.7873929738998413
Validation loss: 2.7838437018855924

Epoch: 5| Step: 9
Training loss: 3.219728946685791
Validation loss: 2.784914706342964

Epoch: 5| Step: 10
Training loss: 3.3349173069000244
Validation loss: 2.7876136610584874

Epoch: 29| Step: 0
Training loss: 3.0663464069366455
Validation loss: 2.7841208724565405

Epoch: 5| Step: 1
Training loss: 2.480546236038208
Validation loss: 2.7800914805422545

Epoch: 5| Step: 2
Training loss: 2.9002525806427
Validation loss: 2.779765293162356

Epoch: 5| Step: 3
Training loss: 2.869702100753784
Validation loss: 2.7763225340074107

Epoch: 5| Step: 4
Training loss: 2.8926587104797363
Validation loss: 2.77604034895538

Epoch: 5| Step: 5
Training loss: 2.557107448577881
Validation loss: 2.7767421994158017

Epoch: 5| Step: 6
Training loss: 3.328784465789795
Validation loss: 2.7726656954775573

Epoch: 5| Step: 7
Training loss: 2.821321964263916
Validation loss: 2.7717362501287974

Epoch: 5| Step: 8
Training loss: 3.4006924629211426
Validation loss: 2.7734771364478656

Epoch: 5| Step: 9
Training loss: 2.9493935108184814
Validation loss: 2.769709938315935

Epoch: 5| Step: 10
Training loss: 2.7614805698394775
Validation loss: 2.7673638097701536

Epoch: 30| Step: 0
Training loss: 3.614870548248291
Validation loss: 2.768208944669334

Epoch: 5| Step: 1
Training loss: 2.101914644241333
Validation loss: 2.773501729452482

Epoch: 5| Step: 2
Training loss: 3.106426954269409
Validation loss: 2.7679895226673414

Epoch: 5| Step: 3
Training loss: 2.6798274517059326
Validation loss: 2.763088660855447

Epoch: 5| Step: 4
Training loss: 3.2407708168029785
Validation loss: 2.7631557321035736

Epoch: 5| Step: 5
Training loss: 2.1604506969451904
Validation loss: 2.7570847311327533

Epoch: 5| Step: 6
Training loss: 3.1876158714294434
Validation loss: 2.7584210877777426

Epoch: 5| Step: 7
Training loss: 3.2023372650146484
Validation loss: 2.7563717698538177

Epoch: 5| Step: 8
Training loss: 3.2284045219421387
Validation loss: 2.754141381991807

Epoch: 5| Step: 9
Training loss: 2.7291338443756104
Validation loss: 2.753449696366505

Epoch: 5| Step: 10
Training loss: 2.6222994327545166
Validation loss: 2.7607556337951333

Epoch: 31| Step: 0
Training loss: 2.524653434753418
Validation loss: 2.7754882766354467

Epoch: 5| Step: 1
Training loss: 2.478003740310669
Validation loss: 2.7507062958132837

Epoch: 5| Step: 2
Training loss: 3.1290533542633057
Validation loss: 2.7560461285293743

Epoch: 5| Step: 3
Training loss: 3.234919309616089
Validation loss: 2.751833774710214

Epoch: 5| Step: 4
Training loss: 3.582312822341919
Validation loss: 2.757242907759964

Epoch: 5| Step: 5
Training loss: 3.5282928943634033
Validation loss: 2.754854594507525

Epoch: 5| Step: 6
Training loss: 3.453113555908203
Validation loss: 2.7565520527542278

Epoch: 5| Step: 7
Training loss: 2.779249668121338
Validation loss: 2.7593177979992283

Epoch: 5| Step: 8
Training loss: 2.639160633087158
Validation loss: 2.7551323213884906

Epoch: 5| Step: 9
Training loss: 2.228982448577881
Validation loss: 2.747796312455208

Epoch: 5| Step: 10
Training loss: 2.2550134658813477
Validation loss: 2.743270743277765

Epoch: 32| Step: 0
Training loss: 3.2451064586639404
Validation loss: 2.741240534731137

Epoch: 5| Step: 1
Training loss: 2.9413466453552246
Validation loss: 2.7365090103559595

Epoch: 5| Step: 2
Training loss: 2.9820713996887207
Validation loss: 2.7527014632378854

Epoch: 5| Step: 3
Training loss: 2.933927297592163
Validation loss: 2.757704793765981

Epoch: 5| Step: 4
Training loss: 3.6423420906066895
Validation loss: 2.7531966675994215

Epoch: 5| Step: 5
Training loss: 2.377681016921997
Validation loss: 2.7331701811923774

Epoch: 5| Step: 6
Training loss: 2.5171666145324707
Validation loss: 2.7377846164088093

Epoch: 5| Step: 7
Training loss: 2.436938524246216
Validation loss: 2.743310046452348

Epoch: 5| Step: 8
Training loss: 2.2059080600738525
Validation loss: 2.7438611471524803

Epoch: 5| Step: 9
Training loss: 3.3370964527130127
Validation loss: 2.756799385111819

Epoch: 5| Step: 10
Training loss: 3.249876022338867
Validation loss: 2.745759182078864

Epoch: 33| Step: 0
Training loss: 2.995774030685425
Validation loss: 2.74708314095774

Epoch: 5| Step: 1
Training loss: 2.0019423961639404
Validation loss: 2.735720565242152

Epoch: 5| Step: 2
Training loss: 3.452338695526123
Validation loss: 2.7323765062516734

Epoch: 5| Step: 3
Training loss: 2.855856418609619
Validation loss: 2.7246743376537035

Epoch: 5| Step: 4
Training loss: 2.6207103729248047
Validation loss: 2.725566966559297

Epoch: 5| Step: 5
Training loss: 2.523564577102661
Validation loss: 2.7473797695611113

Epoch: 5| Step: 6
Training loss: 2.7131330966949463
Validation loss: 2.753791711663687

Epoch: 5| Step: 7
Training loss: 2.8944034576416016
Validation loss: 2.745767144746678

Epoch: 5| Step: 8
Training loss: 3.2367260456085205
Validation loss: 2.7449627127698673

Epoch: 5| Step: 9
Training loss: 3.068981647491455
Validation loss: 2.7366112688536286

Epoch: 5| Step: 10
Training loss: 3.4760677814483643
Validation loss: 2.714852533032817

Epoch: 34| Step: 0
Training loss: 4.177432537078857
Validation loss: 2.712846791872414

Epoch: 5| Step: 1
Training loss: 2.692146062850952
Validation loss: 2.7122568391984507

Epoch: 5| Step: 2
Training loss: 2.678029775619507
Validation loss: 2.714502134630757

Epoch: 5| Step: 3
Training loss: 2.599623918533325
Validation loss: 2.7121644225171817

Epoch: 5| Step: 4
Training loss: 3.136157512664795
Validation loss: 2.710551102956136

Epoch: 5| Step: 5
Training loss: 3.083221435546875
Validation loss: 2.711651855899442

Epoch: 5| Step: 6
Training loss: 2.55261492729187
Validation loss: 2.7082090608535276

Epoch: 5| Step: 7
Training loss: 2.942629337310791
Validation loss: 2.7066427456435336

Epoch: 5| Step: 8
Training loss: 2.1236958503723145
Validation loss: 2.7041944765275523

Epoch: 5| Step: 9
Training loss: 2.18791127204895
Validation loss: 2.704606533050537

Epoch: 5| Step: 10
Training loss: 3.51253342628479
Validation loss: 2.6979010105133057

Epoch: 35| Step: 0
Training loss: 2.5018107891082764
Validation loss: 2.697511755010133

Epoch: 5| Step: 1
Training loss: 2.9788336753845215
Validation loss: 2.6958618112789687

Epoch: 5| Step: 2
Training loss: 3.661881923675537
Validation loss: 2.691848308809342

Epoch: 5| Step: 3
Training loss: 3.015410900115967
Validation loss: 2.6936530605439217

Epoch: 5| Step: 4
Training loss: 2.3673160076141357
Validation loss: 2.694402784429571

Epoch: 5| Step: 5
Training loss: 3.3064262866973877
Validation loss: 2.69434287471156

Epoch: 5| Step: 6
Training loss: 2.9743263721466064
Validation loss: 2.6935126191826275

Epoch: 5| Step: 7
Training loss: 2.070990800857544
Validation loss: 2.696066548747401

Epoch: 5| Step: 8
Training loss: 2.980482578277588
Validation loss: 2.6923034832041752

Epoch: 5| Step: 9
Training loss: 2.776670217514038
Validation loss: 2.6826530528324906

Epoch: 5| Step: 10
Training loss: 2.8012452125549316
Validation loss: 2.6862242862742436

Epoch: 36| Step: 0
Training loss: 3.1558048725128174
Validation loss: 2.687723091853562

Epoch: 5| Step: 1
Training loss: 2.4430813789367676
Validation loss: 2.6859104351330827

Epoch: 5| Step: 2
Training loss: 2.7267813682556152
Validation loss: 2.6851595729909916

Epoch: 5| Step: 3
Training loss: 2.0811142921447754
Validation loss: 2.6789478178947204

Epoch: 5| Step: 4
Training loss: 3.1431641578674316
Validation loss: 2.6795034844388246

Epoch: 5| Step: 5
Training loss: 3.2422356605529785
Validation loss: 2.6790693575336086

Epoch: 5| Step: 6
Training loss: 2.976224899291992
Validation loss: 2.6754828242845434

Epoch: 5| Step: 7
Training loss: 2.5254838466644287
Validation loss: 2.683203992023263

Epoch: 5| Step: 8
Training loss: 2.8694965839385986
Validation loss: 2.683611577556979

Epoch: 5| Step: 9
Training loss: 3.0117688179016113
Validation loss: 2.7017094986413115

Epoch: 5| Step: 10
Training loss: 3.236948251724243
Validation loss: 2.72474306373186

Epoch: 37| Step: 0
Training loss: 2.7639546394348145
Validation loss: 2.680885999433456

Epoch: 5| Step: 1
Training loss: 3.486783504486084
Validation loss: 2.6712858805092434

Epoch: 5| Step: 2
Training loss: 2.017991542816162
Validation loss: 2.667596209433771

Epoch: 5| Step: 3
Training loss: 2.4370193481445312
Validation loss: 2.671735978895618

Epoch: 5| Step: 4
Training loss: 2.744307041168213
Validation loss: 2.6758975931393203

Epoch: 5| Step: 5
Training loss: 2.410614013671875
Validation loss: 2.6765543260881977

Epoch: 5| Step: 6
Training loss: 3.4476304054260254
Validation loss: 2.678879596853769

Epoch: 5| Step: 7
Training loss: 3.5269293785095215
Validation loss: 2.6729868253072104

Epoch: 5| Step: 8
Training loss: 2.339515209197998
Validation loss: 2.67089678395179

Epoch: 5| Step: 9
Training loss: 3.134646415710449
Validation loss: 2.668502958871985

Epoch: 5| Step: 10
Training loss: 3.027477502822876
Validation loss: 2.659411955905217

Epoch: 38| Step: 0
Training loss: 2.2859320640563965
Validation loss: 2.665920562641595

Epoch: 5| Step: 1
Training loss: 3.2951531410217285
Validation loss: 2.664487502908194

Epoch: 5| Step: 2
Training loss: 3.5370254516601562
Validation loss: 2.6580680262657905

Epoch: 5| Step: 3
Training loss: 2.5425267219543457
Validation loss: 2.6609391345772693

Epoch: 5| Step: 4
Training loss: 3.128736972808838
Validation loss: 2.662687296508461

Epoch: 5| Step: 5
Training loss: 2.5373785495758057
Validation loss: 2.6655742019735356

Epoch: 5| Step: 6
Training loss: 2.662057638168335
Validation loss: 2.667312998925486

Epoch: 5| Step: 7
Training loss: 2.874619722366333
Validation loss: 2.66324266054297

Epoch: 5| Step: 8
Training loss: 2.5572972297668457
Validation loss: 2.649123171324371

Epoch: 5| Step: 9
Training loss: 2.78442120552063
Validation loss: 2.6567518095816336

Epoch: 5| Step: 10
Training loss: 2.9607198238372803
Validation loss: 2.6547446789280063

Epoch: 39| Step: 0
Training loss: 2.1594061851501465
Validation loss: 2.660693899277718

Epoch: 5| Step: 1
Training loss: 3.148130416870117
Validation loss: 2.662050529192853

Epoch: 5| Step: 2
Training loss: 2.8233590126037598
Validation loss: 2.6605024491586993

Epoch: 5| Step: 3
Training loss: 2.654710292816162
Validation loss: 2.6567368712476505

Epoch: 5| Step: 4
Training loss: 2.416080951690674
Validation loss: 2.658947765186269

Epoch: 5| Step: 5
Training loss: 3.207324266433716
Validation loss: 2.6487268837549354

Epoch: 5| Step: 6
Training loss: 3.2180557250976562
Validation loss: 2.6546158713679158

Epoch: 5| Step: 7
Training loss: 2.3344101905822754
Validation loss: 2.6413673816188687

Epoch: 5| Step: 8
Training loss: 2.4085288047790527
Validation loss: 2.6398097058778167

Epoch: 5| Step: 9
Training loss: 3.2149670124053955
Validation loss: 2.636158897030738

Epoch: 5| Step: 10
Training loss: 3.6003642082214355
Validation loss: 2.6327886607057307

Epoch: 40| Step: 0
Training loss: 2.3810200691223145
Validation loss: 2.633300809450047

Epoch: 5| Step: 1
Training loss: 2.8415472507476807
Validation loss: 2.632349139900618

Epoch: 5| Step: 2
Training loss: 2.3560781478881836
Validation loss: 2.6471638884595645

Epoch: 5| Step: 3
Training loss: 2.095090866088867
Validation loss: 2.656401562434371

Epoch: 5| Step: 4
Training loss: 3.0532615184783936
Validation loss: 2.669751944080476

Epoch: 5| Step: 5
Training loss: 2.9621803760528564
Validation loss: 2.6682303567086496

Epoch: 5| Step: 6
Training loss: 2.909388780593872
Validation loss: 2.6488617799615346

Epoch: 5| Step: 7
Training loss: 3.2510554790496826
Validation loss: 2.632321419254426

Epoch: 5| Step: 8
Training loss: 2.980067491531372
Validation loss: 2.63167328475624

Epoch: 5| Step: 9
Training loss: 2.726580858230591
Validation loss: 2.6377059644268406

Epoch: 5| Step: 10
Training loss: 3.597527027130127
Validation loss: 2.640482202652962

Epoch: 41| Step: 0
Training loss: 3.812819004058838
Validation loss: 2.6457318003459642

Epoch: 5| Step: 1
Training loss: 3.164201259613037
Validation loss: 2.6481306834887435

Epoch: 5| Step: 2
Training loss: 2.2867608070373535
Validation loss: 2.6420645483078493

Epoch: 5| Step: 3
Training loss: 2.558021068572998
Validation loss: 2.638485731617097

Epoch: 5| Step: 4
Training loss: 3.4107723236083984
Validation loss: 2.635019661277853

Epoch: 5| Step: 5
Training loss: 1.9231414794921875
Validation loss: 2.632584548765613

Epoch: 5| Step: 6
Training loss: 2.959444284439087
Validation loss: 2.624964678159324

Epoch: 5| Step: 7
Training loss: 2.878012180328369
Validation loss: 2.6229155243083997

Epoch: 5| Step: 8
Training loss: 3.1082818508148193
Validation loss: 2.625589996255854

Epoch: 5| Step: 9
Training loss: 2.37255597114563
Validation loss: 2.628069411041916

Epoch: 5| Step: 10
Training loss: 2.4177887439727783
Validation loss: 2.619920781863633

Epoch: 42| Step: 0
Training loss: 2.203838348388672
Validation loss: 2.6179987948427916

Epoch: 5| Step: 1
Training loss: 2.920403242111206
Validation loss: 2.6247617198574926

Epoch: 5| Step: 2
Training loss: 2.456780433654785
Validation loss: 2.617671371788107

Epoch: 5| Step: 3
Training loss: 3.1051859855651855
Validation loss: 2.6228002014980523

Epoch: 5| Step: 4
Training loss: 2.738647222518921
Validation loss: 2.620708921904205

Epoch: 5| Step: 5
Training loss: 2.6278610229492188
Validation loss: 2.6157471697817565

Epoch: 5| Step: 6
Training loss: 2.6245481967926025
Validation loss: 2.611715970500823

Epoch: 5| Step: 7
Training loss: 3.1201412677764893
Validation loss: 2.611315947706981

Epoch: 5| Step: 8
Training loss: 3.22015380859375
Validation loss: 2.608307715385191

Epoch: 5| Step: 9
Training loss: 2.5244839191436768
Validation loss: 2.6109245515638784

Epoch: 5| Step: 10
Training loss: 3.326956272125244
Validation loss: 2.612049982111941

Epoch: 43| Step: 0
Training loss: 2.604388952255249
Validation loss: 2.6097301513917985

Epoch: 5| Step: 1
Training loss: 3.1352574825286865
Validation loss: 2.6156703720810595

Epoch: 5| Step: 2
Training loss: 2.301119327545166
Validation loss: 2.614518565516318

Epoch: 5| Step: 3
Training loss: 2.5250391960144043
Validation loss: 2.611106703358312

Epoch: 5| Step: 4
Training loss: 2.7454657554626465
Validation loss: 2.610221985847719

Epoch: 5| Step: 5
Training loss: 2.9925596714019775
Validation loss: 2.607363911085231

Epoch: 5| Step: 6
Training loss: 2.9568018913269043
Validation loss: 2.5989510756666943

Epoch: 5| Step: 7
Training loss: 2.644181728363037
Validation loss: 2.601169163180936

Epoch: 5| Step: 8
Training loss: 2.7772202491760254
Validation loss: 2.6147839151402956

Epoch: 5| Step: 9
Training loss: 2.97855806350708
Validation loss: 2.5976524609391407

Epoch: 5| Step: 10
Training loss: 3.0719165802001953
Validation loss: 2.5913415467867287

Epoch: 44| Step: 0
Training loss: 3.009188652038574
Validation loss: 2.5923295008238925

Epoch: 5| Step: 1
Training loss: 2.5847299098968506
Validation loss: 2.5930405944906254

Epoch: 5| Step: 2
Training loss: 2.3883843421936035
Validation loss: 2.5974692503611245

Epoch: 5| Step: 3
Training loss: 3.09793758392334
Validation loss: 2.5991986336246615

Epoch: 5| Step: 4
Training loss: 2.80104398727417
Validation loss: 2.598374077068862

Epoch: 5| Step: 5
Training loss: 2.673046112060547
Validation loss: 2.598887712724747

Epoch: 5| Step: 6
Training loss: 2.4549694061279297
Validation loss: 2.5928676461660736

Epoch: 5| Step: 7
Training loss: 3.1107635498046875
Validation loss: 2.595327831083728

Epoch: 5| Step: 8
Training loss: 3.100956439971924
Validation loss: 2.593862638678602

Epoch: 5| Step: 9
Training loss: 2.635500907897949
Validation loss: 2.5972939511781097

Epoch: 5| Step: 10
Training loss: 2.7788453102111816
Validation loss: 2.596105649907102

Epoch: 45| Step: 0
Training loss: 2.939079999923706
Validation loss: 2.605597572941934

Epoch: 5| Step: 1
Training loss: 2.771239995956421
Validation loss: 2.615137674475229

Epoch: 5| Step: 2
Training loss: 2.2067019939422607
Validation loss: 2.6147037654794674

Epoch: 5| Step: 3
Training loss: 3.6144752502441406
Validation loss: 2.601351225247947

Epoch: 5| Step: 4
Training loss: 2.507476806640625
Validation loss: 2.5968851812424196

Epoch: 5| Step: 5
Training loss: 1.9455969333648682
Validation loss: 2.5860815484036683

Epoch: 5| Step: 6
Training loss: 2.968867778778076
Validation loss: 2.5847526186256

Epoch: 5| Step: 7
Training loss: 3.224234104156494
Validation loss: 2.5869411447996735

Epoch: 5| Step: 8
Training loss: 2.686685085296631
Validation loss: 2.5875759996393675

Epoch: 5| Step: 9
Training loss: 2.4373016357421875
Validation loss: 2.5859411378060617

Epoch: 5| Step: 10
Training loss: 3.4080233573913574
Validation loss: 2.582987267483947

Epoch: 46| Step: 0
Training loss: 2.5171661376953125
Validation loss: 2.5807298511587162

Epoch: 5| Step: 1
Training loss: 2.7064993381500244
Validation loss: 2.5775354267448507

Epoch: 5| Step: 2
Training loss: 2.589040756225586
Validation loss: 2.5754054387410483

Epoch: 5| Step: 3
Training loss: 2.7565879821777344
Validation loss: 2.5760975217306488

Epoch: 5| Step: 4
Training loss: 2.134094715118408
Validation loss: 2.5840959779677855

Epoch: 5| Step: 5
Training loss: 2.789320468902588
Validation loss: 2.5943770536812405

Epoch: 5| Step: 6
Training loss: 3.783966064453125
Validation loss: 2.5996431919836227

Epoch: 5| Step: 7
Training loss: 3.206754684448242
Validation loss: 2.5894465677199827

Epoch: 5| Step: 8
Training loss: 2.506321430206299
Validation loss: 2.573963160155922

Epoch: 5| Step: 9
Training loss: 2.6810522079467773
Validation loss: 2.5800524475753948

Epoch: 5| Step: 10
Training loss: 2.818704605102539
Validation loss: 2.5858913698504047

Epoch: 47| Step: 0
Training loss: 2.0324254035949707
Validation loss: 2.578615650053947

Epoch: 5| Step: 1
Training loss: 1.8353402614593506
Validation loss: 2.5781860889927035

Epoch: 5| Step: 2
Training loss: 3.0445847511291504
Validation loss: 2.5855007761268207

Epoch: 5| Step: 3
Training loss: 3.387876510620117
Validation loss: 2.573282277712258

Epoch: 5| Step: 4
Training loss: 3.5517914295196533
Validation loss: 2.5717173186681603

Epoch: 5| Step: 5
Training loss: 2.6874496936798096
Validation loss: 2.569708901066934

Epoch: 5| Step: 6
Training loss: 2.747235059738159
Validation loss: 2.5661017894744873

Epoch: 5| Step: 7
Training loss: 2.2021374702453613
Validation loss: 2.5614750154556765

Epoch: 5| Step: 8
Training loss: 2.5212268829345703
Validation loss: 2.564791997273763

Epoch: 5| Step: 9
Training loss: 3.2222137451171875
Validation loss: 2.5624850949933453

Epoch: 5| Step: 10
Training loss: 3.266808032989502
Validation loss: 2.565359159182477

Epoch: 48| Step: 0
Training loss: 2.3926494121551514
Validation loss: 2.5601542944549234

Epoch: 5| Step: 1
Training loss: 2.7335214614868164
Validation loss: 2.559181895307315

Epoch: 5| Step: 2
Training loss: 2.422701358795166
Validation loss: 2.561309294034076

Epoch: 5| Step: 3
Training loss: 3.0930886268615723
Validation loss: 2.565177861080375

Epoch: 5| Step: 4
Training loss: 2.763613224029541
Validation loss: 2.571646503222886

Epoch: 5| Step: 5
Training loss: 3.316671848297119
Validation loss: 2.558569887632965

Epoch: 5| Step: 6
Training loss: 3.1772522926330566
Validation loss: 2.555428471616519

Epoch: 5| Step: 7
Training loss: 2.836055278778076
Validation loss: 2.5558119538009807

Epoch: 5| Step: 8
Training loss: 3.077223300933838
Validation loss: 2.5502987830869612

Epoch: 5| Step: 9
Training loss: 2.3450632095336914
Validation loss: 2.552851894850372

Epoch: 5| Step: 10
Training loss: 2.08471941947937
Validation loss: 2.5592970822447088

Epoch: 49| Step: 0
Training loss: 2.9614312648773193
Validation loss: 2.559967005124656

Epoch: 5| Step: 1
Training loss: 3.3167176246643066
Validation loss: 2.5727909944390737

Epoch: 5| Step: 2
Training loss: 3.4760727882385254
Validation loss: 2.5610857727707073

Epoch: 5| Step: 3
Training loss: 1.8234933614730835
Validation loss: 2.5534196412691506

Epoch: 5| Step: 4
Training loss: 3.267493724822998
Validation loss: 2.548501553074006

Epoch: 5| Step: 5
Training loss: 2.478149890899658
Validation loss: 2.545659185737692

Epoch: 5| Step: 6
Training loss: 2.4132468700408936
Validation loss: 2.555065744666643

Epoch: 5| Step: 7
Training loss: 2.259119749069214
Validation loss: 2.551929373894968

Epoch: 5| Step: 8
Training loss: 2.1327931880950928
Validation loss: 2.555903171980253

Epoch: 5| Step: 9
Training loss: 3.37554931640625
Validation loss: 2.550545600152785

Epoch: 5| Step: 10
Training loss: 2.83616304397583
Validation loss: 2.55091844835589

Epoch: 50| Step: 0
Training loss: 2.8611748218536377
Validation loss: 2.548283415455972

Epoch: 5| Step: 1
Training loss: 2.20212459564209
Validation loss: 2.5448953977195163

Epoch: 5| Step: 2
Training loss: 2.1191959381103516
Validation loss: 2.5439849284387406

Epoch: 5| Step: 3
Training loss: 3.049014091491699
Validation loss: 2.5449081723408034

Epoch: 5| Step: 4
Training loss: 3.206911087036133
Validation loss: 2.542411493998702

Epoch: 5| Step: 5
Training loss: 2.856778621673584
Validation loss: 2.5480255567899315

Epoch: 5| Step: 6
Training loss: 2.766136646270752
Validation loss: 2.544109247064078

Epoch: 5| Step: 7
Training loss: 3.2876956462860107
Validation loss: 2.5497602544805056

Epoch: 5| Step: 8
Training loss: 2.7274794578552246
Validation loss: 2.549975461857293

Epoch: 5| Step: 9
Training loss: 2.6928083896636963
Validation loss: 2.555099082249467

Epoch: 5| Step: 10
Training loss: 2.3664798736572266
Validation loss: 2.556624925264748

Epoch: 51| Step: 0
Training loss: 3.008472442626953
Validation loss: 2.5514153921475975

Epoch: 5| Step: 1
Training loss: 2.3568434715270996
Validation loss: 2.550197419299874

Epoch: 5| Step: 2
Training loss: 3.247917652130127
Validation loss: 2.5479205872422908

Epoch: 5| Step: 3
Training loss: 2.852569103240967
Validation loss: 2.5444947032518286

Epoch: 5| Step: 4
Training loss: 2.025618076324463
Validation loss: 2.5420237612980667

Epoch: 5| Step: 5
Training loss: 2.3098509311676025
Validation loss: 2.5415473804678967

Epoch: 5| Step: 6
Training loss: 2.1514899730682373
Validation loss: 2.543110009162657

Epoch: 5| Step: 7
Training loss: 2.780971050262451
Validation loss: 2.554642661925285

Epoch: 5| Step: 8
Training loss: 3.2616565227508545
Validation loss: 2.558759799567602

Epoch: 5| Step: 9
Training loss: 2.9535090923309326
Validation loss: 2.5643479721520537

Epoch: 5| Step: 10
Training loss: 3.3188703060150146
Validation loss: 2.545138471870012

Epoch: 52| Step: 0
Training loss: 2.426621198654175
Validation loss: 2.535649972577249

Epoch: 5| Step: 1
Training loss: 2.882351875305176
Validation loss: 2.538724145581645

Epoch: 5| Step: 2
Training loss: 3.0123653411865234
Validation loss: 2.5417556890877346

Epoch: 5| Step: 3
Training loss: 3.5141491889953613
Validation loss: 2.544165039575228

Epoch: 5| Step: 4
Training loss: 2.422058582305908
Validation loss: 2.5512770657898276

Epoch: 5| Step: 5
Training loss: 2.7256886959075928
Validation loss: 2.550569729138446

Epoch: 5| Step: 6
Training loss: 2.906419038772583
Validation loss: 2.554339257619714

Epoch: 5| Step: 7
Training loss: 2.4629478454589844
Validation loss: 2.5526957486265447

Epoch: 5| Step: 8
Training loss: 2.2195847034454346
Validation loss: 2.5504608718297814

Epoch: 5| Step: 9
Training loss: 3.0478827953338623
Validation loss: 2.551956594631236

Epoch: 5| Step: 10
Training loss: 2.567338466644287
Validation loss: 2.546240391269807

Epoch: 53| Step: 0
Training loss: 2.664999008178711
Validation loss: 2.542608235471992

Epoch: 5| Step: 1
Training loss: 2.700669765472412
Validation loss: 2.5430258525315153

Epoch: 5| Step: 2
Training loss: 2.4957995414733887
Validation loss: 2.5399390446242465

Epoch: 5| Step: 3
Training loss: 2.8708388805389404
Validation loss: 2.5361317408982145

Epoch: 5| Step: 4
Training loss: 2.7479248046875
Validation loss: 2.536091726313355

Epoch: 5| Step: 5
Training loss: 3.0684638023376465
Validation loss: 2.5333706973701395

Epoch: 5| Step: 6
Training loss: 2.7822251319885254
Validation loss: 2.5290145207476873

Epoch: 5| Step: 7
Training loss: 2.567840099334717
Validation loss: 2.526865977112965

Epoch: 5| Step: 8
Training loss: 3.030803918838501
Validation loss: 2.52487370275682

Epoch: 5| Step: 9
Training loss: 2.379629135131836
Validation loss: 2.5227632625128633

Epoch: 5| Step: 10
Training loss: 2.8563082218170166
Validation loss: 2.5193379335505988

Epoch: 54| Step: 0
Training loss: 3.01308536529541
Validation loss: 2.529813766479492

Epoch: 5| Step: 1
Training loss: 3.1895251274108887
Validation loss: 2.5186616528418755

Epoch: 5| Step: 2
Training loss: 2.8037257194519043
Validation loss: 2.5182352104494647

Epoch: 5| Step: 3
Training loss: 2.6206533908843994
Validation loss: 2.5180064068045667

Epoch: 5| Step: 4
Training loss: 2.535393714904785
Validation loss: 2.521287343835318

Epoch: 5| Step: 5
Training loss: 2.7289552688598633
Validation loss: 2.5229007633783485

Epoch: 5| Step: 6
Training loss: 2.1946871280670166
Validation loss: 2.526893574704406

Epoch: 5| Step: 7
Training loss: 2.970858335494995
Validation loss: 2.528049417721328

Epoch: 5| Step: 8
Training loss: 2.3925681114196777
Validation loss: 2.5241413911183677

Epoch: 5| Step: 9
Training loss: 2.776925563812256
Validation loss: 2.5285294799394507

Epoch: 5| Step: 10
Training loss: 2.827735424041748
Validation loss: 2.518501684229861

Epoch: 55| Step: 0
Training loss: 3.0562682151794434
Validation loss: 2.5168384352037982

Epoch: 5| Step: 1
Training loss: 2.3937296867370605
Validation loss: 2.518485156438684

Epoch: 5| Step: 2
Training loss: 3.0023932456970215
Validation loss: 2.5194116856462214

Epoch: 5| Step: 3
Training loss: 3.160611152648926
Validation loss: 2.5254299499655284

Epoch: 5| Step: 4
Training loss: 2.6964375972747803
Validation loss: 2.5188421228880524

Epoch: 5| Step: 5
Training loss: 3.2695281505584717
Validation loss: 2.517021571436236

Epoch: 5| Step: 6
Training loss: 2.7968947887420654
Validation loss: 2.5195389768128753

Epoch: 5| Step: 7
Training loss: 2.5222039222717285
Validation loss: 2.514150813061704

Epoch: 5| Step: 8
Training loss: 2.659702777862549
Validation loss: 2.516669868141092

Epoch: 5| Step: 9
Training loss: 2.1842598915100098
Validation loss: 2.5201211796011975

Epoch: 5| Step: 10
Training loss: 2.0981764793395996
Validation loss: 2.5228285353670836

Epoch: 56| Step: 0
Training loss: 2.9097952842712402
Validation loss: 2.5321434582433393

Epoch: 5| Step: 1
Training loss: 2.1825623512268066
Validation loss: 2.523464495135892

Epoch: 5| Step: 2
Training loss: 2.5900540351867676
Validation loss: 2.5255472454973447

Epoch: 5| Step: 3
Training loss: 2.9182662963867188
Validation loss: 2.5384687300651305

Epoch: 5| Step: 4
Training loss: 2.9261131286621094
Validation loss: 2.5368073806967786

Epoch: 5| Step: 5
Training loss: 2.8919901847839355
Validation loss: 2.5217285643341723

Epoch: 5| Step: 6
Training loss: 2.8732876777648926
Validation loss: 2.517236263521256

Epoch: 5| Step: 7
Training loss: 2.3345305919647217
Validation loss: 2.5132060845692954

Epoch: 5| Step: 8
Training loss: 3.0193068981170654
Validation loss: 2.510238544915312

Epoch: 5| Step: 9
Training loss: 2.588956356048584
Validation loss: 2.5107074065874984

Epoch: 5| Step: 10
Training loss: 2.8023273944854736
Validation loss: 2.5109471838961364

Epoch: 57| Step: 0
Training loss: 2.1250085830688477
Validation loss: 2.513454862820205

Epoch: 5| Step: 1
Training loss: 2.700160026550293
Validation loss: 2.5114577765105874

Epoch: 5| Step: 2
Training loss: 2.4020307064056396
Validation loss: 2.524620615026002

Epoch: 5| Step: 3
Training loss: 2.4912009239196777
Validation loss: 2.5228609526029198

Epoch: 5| Step: 4
Training loss: 2.7072315216064453
Validation loss: 2.51623006789915

Epoch: 5| Step: 5
Training loss: 2.278071880340576
Validation loss: 2.51802078113761

Epoch: 5| Step: 6
Training loss: 3.491342544555664
Validation loss: 2.5223924421495005

Epoch: 5| Step: 7
Training loss: 2.3018264770507812
Validation loss: 2.5214759303677465

Epoch: 5| Step: 8
Training loss: 2.7689192295074463
Validation loss: 2.5275720306622085

Epoch: 5| Step: 9
Training loss: 4.053977966308594
Validation loss: 2.5122913698996268

Epoch: 5| Step: 10
Training loss: 2.6827311515808105
Validation loss: 2.5112724816927345

Epoch: 58| Step: 0
Training loss: 2.2901084423065186
Validation loss: 2.505464753796977

Epoch: 5| Step: 1
Training loss: 2.526376485824585
Validation loss: 2.5105896944640786

Epoch: 5| Step: 2
Training loss: 3.222865343093872
Validation loss: 2.5145192453938146

Epoch: 5| Step: 3
Training loss: 2.6769580841064453
Validation loss: 2.5170283240656697

Epoch: 5| Step: 4
Training loss: 2.561021327972412
Validation loss: 2.5158849275240334

Epoch: 5| Step: 5
Training loss: 3.1780362129211426
Validation loss: 2.5178533907859557

Epoch: 5| Step: 6
Training loss: 2.8877086639404297
Validation loss: 2.514110388294343

Epoch: 5| Step: 7
Training loss: 2.470198631286621
Validation loss: 2.5176854159242366

Epoch: 5| Step: 8
Training loss: 3.201251268386841
Validation loss: 2.5152470245156238

Epoch: 5| Step: 9
Training loss: 2.0988314151763916
Validation loss: 2.5161116533381964

Epoch: 5| Step: 10
Training loss: 2.9601430892944336
Validation loss: 2.5173543781362553

Epoch: 59| Step: 0
Training loss: 2.2949700355529785
Validation loss: 2.52143338418776

Epoch: 5| Step: 1
Training loss: 2.6319706439971924
Validation loss: 2.534358807789382

Epoch: 5| Step: 2
Training loss: 2.7307381629943848
Validation loss: 2.536792516708374

Epoch: 5| Step: 3
Training loss: 2.4711835384368896
Validation loss: 2.54999678878374

Epoch: 5| Step: 4
Training loss: 2.9816620349884033
Validation loss: 2.5583625249965216

Epoch: 5| Step: 5
Training loss: 2.576587438583374
Validation loss: 2.5346111072007047

Epoch: 5| Step: 6
Training loss: 2.9209036827087402
Validation loss: 2.5384185083450808

Epoch: 5| Step: 7
Training loss: 3.290301561355591
Validation loss: 2.5195215978930072

Epoch: 5| Step: 8
Training loss: 2.613499402999878
Validation loss: 2.501681843111592

Epoch: 5| Step: 9
Training loss: 2.5856971740722656
Validation loss: 2.49575702862073

Epoch: 5| Step: 10
Training loss: 2.92157244682312
Validation loss: 2.4961142104159117

Epoch: 60| Step: 0
Training loss: 4.0434160232543945
Validation loss: 2.5011222875246437

Epoch: 5| Step: 1
Training loss: 2.663236618041992
Validation loss: 2.4974897702534995

Epoch: 5| Step: 2
Training loss: 3.1027634143829346
Validation loss: 2.4965272744496665

Epoch: 5| Step: 3
Training loss: 2.8681282997131348
Validation loss: 2.491164889386905

Epoch: 5| Step: 4
Training loss: 2.1591901779174805
Validation loss: 2.5017623773185154

Epoch: 5| Step: 5
Training loss: 3.066706418991089
Validation loss: 2.496042659205775

Epoch: 5| Step: 6
Training loss: 2.146557569503784
Validation loss: 2.4929049861046577

Epoch: 5| Step: 7
Training loss: 1.762332558631897
Validation loss: 2.4887236728463122

Epoch: 5| Step: 8
Training loss: 2.5249810218811035
Validation loss: 2.488342341556344

Epoch: 5| Step: 9
Training loss: 2.7320187091827393
Validation loss: 2.4873261092811503

Epoch: 5| Step: 10
Training loss: 2.8080179691314697
Validation loss: 2.4883760354852162

Epoch: 61| Step: 0
Training loss: 2.0365428924560547
Validation loss: 2.4906801395518805

Epoch: 5| Step: 1
Training loss: 2.3273987770080566
Validation loss: 2.498236119106252

Epoch: 5| Step: 2
Training loss: 3.410778522491455
Validation loss: 2.4953253781923683

Epoch: 5| Step: 3
Training loss: 2.739647388458252
Validation loss: 2.4938909751112743

Epoch: 5| Step: 4
Training loss: 2.450265407562256
Validation loss: 2.499136678634151

Epoch: 5| Step: 5
Training loss: 2.7848546504974365
Validation loss: 2.500284151364398

Epoch: 5| Step: 6
Training loss: 2.477064847946167
Validation loss: 2.499206442986765

Epoch: 5| Step: 7
Training loss: 2.450784206390381
Validation loss: 2.5002698283041678

Epoch: 5| Step: 8
Training loss: 3.1910455226898193
Validation loss: 2.497941775988507

Epoch: 5| Step: 9
Training loss: 2.8574581146240234
Validation loss: 2.509797819199101

Epoch: 5| Step: 10
Training loss: 3.116395950317383
Validation loss: 2.5127603802629697

Epoch: 62| Step: 0
Training loss: 2.75213360786438
Validation loss: 2.509057047546551

Epoch: 5| Step: 1
Training loss: 2.4842846393585205
Validation loss: 2.509902468291662

Epoch: 5| Step: 2
Training loss: 2.2449772357940674
Validation loss: 2.506388518118089

Epoch: 5| Step: 3
Training loss: 2.393911600112915
Validation loss: 2.4981048671148156

Epoch: 5| Step: 4
Training loss: 2.0418949127197266
Validation loss: 2.5039687925769436

Epoch: 5| Step: 5
Training loss: 3.4337315559387207
Validation loss: 2.4929223316971973

Epoch: 5| Step: 6
Training loss: 3.3500943183898926
Validation loss: 2.4971709405222247

Epoch: 5| Step: 7
Training loss: 3.006436586380005
Validation loss: 2.495707306810605

Epoch: 5| Step: 8
Training loss: 3.0153870582580566
Validation loss: 2.4880179692340154

Epoch: 5| Step: 9
Training loss: 2.385451316833496
Validation loss: 2.486472406694966

Epoch: 5| Step: 10
Training loss: 2.585909605026245
Validation loss: 2.4848608483550367

Epoch: 63| Step: 0
Training loss: 2.9425511360168457
Validation loss: 2.485442638397217

Epoch: 5| Step: 1
Training loss: 2.4982497692108154
Validation loss: 2.4792492466588176

Epoch: 5| Step: 2
Training loss: 2.9021058082580566
Validation loss: 2.4849036842264156

Epoch: 5| Step: 3
Training loss: 1.7838531732559204
Validation loss: 2.4862902715641964

Epoch: 5| Step: 4
Training loss: 3.0719635486602783
Validation loss: 2.4966712715805217

Epoch: 5| Step: 5
Training loss: 2.2291507720947266
Validation loss: 2.4940295962877173

Epoch: 5| Step: 6
Training loss: 2.307751178741455
Validation loss: 2.4930404078575874

Epoch: 5| Step: 7
Training loss: 2.965444564819336
Validation loss: 2.499770647736006

Epoch: 5| Step: 8
Training loss: 2.3687832355499268
Validation loss: 2.4873166417562835

Epoch: 5| Step: 9
Training loss: 3.529970645904541
Validation loss: 2.4874604978869037

Epoch: 5| Step: 10
Training loss: 3.245014190673828
Validation loss: 2.490644929229572

Epoch: 64| Step: 0
Training loss: 3.0320277214050293
Validation loss: 2.484025707808874

Epoch: 5| Step: 1
Training loss: 3.0509886741638184
Validation loss: 2.474155569589266

Epoch: 5| Step: 2
Training loss: 3.1749274730682373
Validation loss: 2.482414481460407

Epoch: 5| Step: 3
Training loss: 2.884706497192383
Validation loss: 2.4840554409129645

Epoch: 5| Step: 4
Training loss: 2.0088393688201904
Validation loss: 2.4886785425165647

Epoch: 5| Step: 5
Training loss: 2.3211071491241455
Validation loss: 2.4785112616836384

Epoch: 5| Step: 6
Training loss: 2.5619349479675293
Validation loss: 2.474664850901532

Epoch: 5| Step: 7
Training loss: 2.5613467693328857
Validation loss: 2.4778742098039195

Epoch: 5| Step: 8
Training loss: 2.7996554374694824
Validation loss: 2.4877199434464976

Epoch: 5| Step: 9
Training loss: 2.8620963096618652
Validation loss: 2.5048428530334146

Epoch: 5| Step: 10
Training loss: 2.4174938201904297
Validation loss: 2.5129816198861725

Epoch: 65| Step: 0
Training loss: 2.165362596511841
Validation loss: 2.5113512674967446

Epoch: 5| Step: 1
Training loss: 2.6640028953552246
Validation loss: 2.501041973790815

Epoch: 5| Step: 2
Training loss: 2.4618825912475586
Validation loss: 2.5002873225878646

Epoch: 5| Step: 3
Training loss: 2.5612504482269287
Validation loss: 2.499734363248271

Epoch: 5| Step: 4
Training loss: 3.1467342376708984
Validation loss: 2.489447516779746

Epoch: 5| Step: 5
Training loss: 2.7053205966949463
Validation loss: 2.478374058200467

Epoch: 5| Step: 6
Training loss: 2.743659496307373
Validation loss: 2.482222617313426

Epoch: 5| Step: 7
Training loss: 2.875011920928955
Validation loss: 2.4784553717541438

Epoch: 5| Step: 8
Training loss: 2.508845329284668
Validation loss: 2.4787718096087055

Epoch: 5| Step: 9
Training loss: 3.0855095386505127
Validation loss: 2.4834453239235827

Epoch: 5| Step: 10
Training loss: 2.69935941696167
Validation loss: 2.4798982245947725

Epoch: 66| Step: 0
Training loss: 2.7432849407196045
Validation loss: 2.479964916424085

Epoch: 5| Step: 1
Training loss: 2.6330699920654297
Validation loss: 2.4864744063346618

Epoch: 5| Step: 2
Training loss: 2.3223681449890137
Validation loss: 2.4806167541011686

Epoch: 5| Step: 3
Training loss: 3.270771026611328
Validation loss: 2.480856292991228

Epoch: 5| Step: 4
Training loss: 2.5718417167663574
Validation loss: 2.478709707977951

Epoch: 5| Step: 5
Training loss: 2.5890204906463623
Validation loss: 2.477539659828268

Epoch: 5| Step: 6
Training loss: 3.7102646827697754
Validation loss: 2.472831776065211

Epoch: 5| Step: 7
Training loss: 2.4786105155944824
Validation loss: 2.478468810358355

Epoch: 5| Step: 8
Training loss: 2.0293993949890137
Validation loss: 2.481383926124983

Epoch: 5| Step: 9
Training loss: 2.7731502056121826
Validation loss: 2.4837505099593953

Epoch: 5| Step: 10
Training loss: 2.4843924045562744
Validation loss: 2.4817688644573255

Epoch: 67| Step: 0
Training loss: 3.1759393215179443
Validation loss: 2.491991212291102

Epoch: 5| Step: 1
Training loss: 2.6275362968444824
Validation loss: 2.4839492702996857

Epoch: 5| Step: 2
Training loss: 1.7027614116668701
Validation loss: 2.4825458193338044

Epoch: 5| Step: 3
Training loss: 2.9449658393859863
Validation loss: 2.4842774227101314

Epoch: 5| Step: 4
Training loss: 2.566586494445801
Validation loss: 2.4801671992066088

Epoch: 5| Step: 5
Training loss: 3.078263521194458
Validation loss: 2.4767547166475685

Epoch: 5| Step: 6
Training loss: 2.7674052715301514
Validation loss: 2.472878345879175

Epoch: 5| Step: 7
Training loss: 2.842433452606201
Validation loss: 2.473590302210982

Epoch: 5| Step: 8
Training loss: 2.388610363006592
Validation loss: 2.4786699087389055

Epoch: 5| Step: 9
Training loss: 3.095559597015381
Validation loss: 2.4704397198974446

Epoch: 5| Step: 10
Training loss: 2.220917224884033
Validation loss: 2.465461584829515

Epoch: 68| Step: 0
Training loss: 3.0553250312805176
Validation loss: 2.475685883593816

Epoch: 5| Step: 1
Training loss: 2.9346983432769775
Validation loss: 2.4791943360400457

Epoch: 5| Step: 2
Training loss: 2.6162502765655518
Validation loss: 2.4711455504099527

Epoch: 5| Step: 3
Training loss: 2.8110766410827637
Validation loss: 2.4657448337924097

Epoch: 5| Step: 4
Training loss: 2.757683038711548
Validation loss: 2.467887842527

Epoch: 5| Step: 5
Training loss: 3.0961315631866455
Validation loss: 2.4662988211518977

Epoch: 5| Step: 6
Training loss: 2.663290500640869
Validation loss: 2.4639304427690405

Epoch: 5| Step: 7
Training loss: 2.5013175010681152
Validation loss: 2.47134578868907

Epoch: 5| Step: 8
Training loss: 2.187028169631958
Validation loss: 2.4663675164663665

Epoch: 5| Step: 9
Training loss: 2.4705073833465576
Validation loss: 2.4753467729014735

Epoch: 5| Step: 10
Training loss: 2.3683230876922607
Validation loss: 2.4779301817699144

Epoch: 69| Step: 0
Training loss: 2.286264181137085
Validation loss: 2.473623611593759

Epoch: 5| Step: 1
Training loss: 2.5513949394226074
Validation loss: 2.4632551272710166

Epoch: 5| Step: 2
Training loss: 3.146183490753174
Validation loss: 2.461853499053627

Epoch: 5| Step: 3
Training loss: 2.0253586769104004
Validation loss: 2.4616435907220326

Epoch: 5| Step: 4
Training loss: 2.6777682304382324
Validation loss: 2.4559297279645036

Epoch: 5| Step: 5
Training loss: 2.6811296939849854
Validation loss: 2.4528806747928744

Epoch: 5| Step: 6
Training loss: 3.218778133392334
Validation loss: 2.453810025286931

Epoch: 5| Step: 7
Training loss: 2.1778671741485596
Validation loss: 2.45519075598768

Epoch: 5| Step: 8
Training loss: 3.013421058654785
Validation loss: 2.4548105244995444

Epoch: 5| Step: 9
Training loss: 3.189619541168213
Validation loss: 2.4597736456060924

Epoch: 5| Step: 10
Training loss: 2.4041452407836914
Validation loss: 2.458661622898553

Epoch: 70| Step: 0
Training loss: 3.0160272121429443
Validation loss: 2.46087142216262

Epoch: 5| Step: 1
Training loss: 2.2722558975219727
Validation loss: 2.4683533791572816

Epoch: 5| Step: 2
Training loss: 2.2495100498199463
Validation loss: 2.4626505092907975

Epoch: 5| Step: 3
Training loss: 2.426293134689331
Validation loss: 2.468516859956967

Epoch: 5| Step: 4
Training loss: 2.4202136993408203
Validation loss: 2.4705232330547866

Epoch: 5| Step: 5
Training loss: 2.9110677242279053
Validation loss: 2.4735925761602258

Epoch: 5| Step: 6
Training loss: 2.5975141525268555
Validation loss: 2.4656535835676294

Epoch: 5| Step: 7
Training loss: 2.857541561126709
Validation loss: 2.456036839433896

Epoch: 5| Step: 8
Training loss: 2.7670576572418213
Validation loss: 2.4592794679826304

Epoch: 5| Step: 9
Training loss: 3.161890983581543
Validation loss: 2.459773414878435

Epoch: 5| Step: 10
Training loss: 2.5920987129211426
Validation loss: 2.467102642982237

Epoch: 71| Step: 0
Training loss: 2.209000587463379
Validation loss: 2.462479809279083

Epoch: 5| Step: 1
Training loss: 3.0480220317840576
Validation loss: 2.46305267272457

Epoch: 5| Step: 2
Training loss: 2.348766326904297
Validation loss: 2.4707781371249946

Epoch: 5| Step: 3
Training loss: 3.3582942485809326
Validation loss: 2.45820120329498

Epoch: 5| Step: 4
Training loss: 2.202249526977539
Validation loss: 2.448775786225514

Epoch: 5| Step: 5
Training loss: 2.9555068016052246
Validation loss: 2.4490775754374843

Epoch: 5| Step: 6
Training loss: 3.1463513374328613
Validation loss: 2.4516500016694427

Epoch: 5| Step: 7
Training loss: 3.156393527984619
Validation loss: 2.449077098600326

Epoch: 5| Step: 8
Training loss: 2.085972309112549
Validation loss: 2.4517603279441915

Epoch: 5| Step: 9
Training loss: 2.426604986190796
Validation loss: 2.461541057914816

Epoch: 5| Step: 10
Training loss: 2.3061492443084717
Validation loss: 2.461913611299248

Epoch: 72| Step: 0
Training loss: 2.900500535964966
Validation loss: 2.478722228798815

Epoch: 5| Step: 1
Training loss: 2.473906993865967
Validation loss: 2.4845980726262575

Epoch: 5| Step: 2
Training loss: 2.570085048675537
Validation loss: 2.494876584699077

Epoch: 5| Step: 3
Training loss: 3.9912619590759277
Validation loss: 2.508127902143745

Epoch: 5| Step: 4
Training loss: 2.4452908039093018
Validation loss: 2.4968991561602523

Epoch: 5| Step: 5
Training loss: 2.387942314147949
Validation loss: 2.4787835075009252

Epoch: 5| Step: 6
Training loss: 2.4968600273132324
Validation loss: 2.4563199730329615

Epoch: 5| Step: 7
Training loss: 2.7953896522521973
Validation loss: 2.4489949672452864

Epoch: 5| Step: 8
Training loss: 2.317047595977783
Validation loss: 2.4550070711361465

Epoch: 5| Step: 9
Training loss: 2.7083547115325928
Validation loss: 2.4704579614823863

Epoch: 5| Step: 10
Training loss: 2.356362819671631
Validation loss: 2.477505773626348

Epoch: 73| Step: 0
Training loss: 2.2432126998901367
Validation loss: 2.478170802516322

Epoch: 5| Step: 1
Training loss: 2.7849080562591553
Validation loss: 2.4672087418135775

Epoch: 5| Step: 2
Training loss: 2.5445101261138916
Validation loss: 2.472383699109477

Epoch: 5| Step: 3
Training loss: 2.241934299468994
Validation loss: 2.465790794741723

Epoch: 5| Step: 4
Training loss: 2.501249313354492
Validation loss: 2.455617884153961

Epoch: 5| Step: 5
Training loss: 2.4511046409606934
Validation loss: 2.45859036907073

Epoch: 5| Step: 6
Training loss: 3.7292640209198
Validation loss: 2.4518275055834042

Epoch: 5| Step: 7
Training loss: 2.9023499488830566
Validation loss: 2.4463522972599154

Epoch: 5| Step: 8
Training loss: 2.5852818489074707
Validation loss: 2.444576132682062

Epoch: 5| Step: 9
Training loss: 2.458256721496582
Validation loss: 2.4377420128032727

Epoch: 5| Step: 10
Training loss: 3.0268001556396484
Validation loss: 2.4466296959948797

Epoch: 74| Step: 0
Training loss: 3.1725597381591797
Validation loss: 2.4485803342634633

Epoch: 5| Step: 1
Training loss: 2.6134867668151855
Validation loss: 2.4657903127772833

Epoch: 5| Step: 2
Training loss: 2.568488121032715
Validation loss: 2.4731540295385543

Epoch: 5| Step: 3
Training loss: 3.1440834999084473
Validation loss: 2.485390199128018

Epoch: 5| Step: 4
Training loss: 2.3187787532806396
Validation loss: 2.4916795351172007

Epoch: 5| Step: 5
Training loss: 1.8184735774993896
Validation loss: 2.4993267520781486

Epoch: 5| Step: 6
Training loss: 2.3884525299072266
Validation loss: 2.5168403592160953

Epoch: 5| Step: 7
Training loss: 3.1338908672332764
Validation loss: 2.516648994979038

Epoch: 5| Step: 8
Training loss: 3.069840908050537
Validation loss: 2.515277834348781

Epoch: 5| Step: 9
Training loss: 2.437028169631958
Validation loss: 2.495128082972701

Epoch: 5| Step: 10
Training loss: 3.0080673694610596
Validation loss: 2.475596774008966

Epoch: 75| Step: 0
Training loss: 2.7101492881774902
Validation loss: 2.459740105495658

Epoch: 5| Step: 1
Training loss: 2.8413174152374268
Validation loss: 2.4382375722290366

Epoch: 5| Step: 2
Training loss: 2.122938871383667
Validation loss: 2.432823616971252

Epoch: 5| Step: 3
Training loss: 2.276538372039795
Validation loss: 2.4393953636128414

Epoch: 5| Step: 4
Training loss: 2.605778217315674
Validation loss: 2.4477181588449786

Epoch: 5| Step: 5
Training loss: 1.8942283391952515
Validation loss: 2.4465824250252015

Epoch: 5| Step: 6
Training loss: 3.356837511062622
Validation loss: 2.4476799593176892

Epoch: 5| Step: 7
Training loss: 2.014721393585205
Validation loss: 2.44314145529142

Epoch: 5| Step: 8
Training loss: 3.2715296745300293
Validation loss: 2.44905581525577

Epoch: 5| Step: 9
Training loss: 3.083193778991699
Validation loss: 2.442193546602803

Epoch: 5| Step: 10
Training loss: 3.242293119430542
Validation loss: 2.444599377211704

Epoch: 76| Step: 0
Training loss: 2.671342372894287
Validation loss: 2.4452557256144862

Epoch: 5| Step: 1
Training loss: 3.073143482208252
Validation loss: 2.45580598744013

Epoch: 5| Step: 2
Training loss: 3.0814056396484375
Validation loss: 2.448079486047068

Epoch: 5| Step: 3
Training loss: 2.4825973510742188
Validation loss: 2.4534364464462444

Epoch: 5| Step: 4
Training loss: 2.496415615081787
Validation loss: 2.441607177898448

Epoch: 5| Step: 5
Training loss: 2.8055124282836914
Validation loss: 2.437505237517818

Epoch: 5| Step: 6
Training loss: 2.2350964546203613
Validation loss: 2.4424374001000517

Epoch: 5| Step: 7
Training loss: 2.6183178424835205
Validation loss: 2.4371745073667137

Epoch: 5| Step: 8
Training loss: 2.1998331546783447
Validation loss: 2.4402764151173253

Epoch: 5| Step: 9
Training loss: 3.07944917678833
Validation loss: 2.4421229772670294

Epoch: 5| Step: 10
Training loss: 2.5156702995300293
Validation loss: 2.4416112053778862

Epoch: 77| Step: 0
Training loss: 2.366563320159912
Validation loss: 2.444778347528109

Epoch: 5| Step: 1
Training loss: 3.2938461303710938
Validation loss: 2.4445624325865056

Epoch: 5| Step: 2
Training loss: 2.4776463508605957
Validation loss: 2.443438814532372

Epoch: 5| Step: 3
Training loss: 2.7417941093444824
Validation loss: 2.435911282416313

Epoch: 5| Step: 4
Training loss: 2.558201313018799
Validation loss: 2.4424369847902687

Epoch: 5| Step: 5
Training loss: 2.647088050842285
Validation loss: 2.435833566932268

Epoch: 5| Step: 6
Training loss: 2.5584042072296143
Validation loss: 2.440619276415917

Epoch: 5| Step: 7
Training loss: 2.3780670166015625
Validation loss: 2.437840328421644

Epoch: 5| Step: 8
Training loss: 2.289825439453125
Validation loss: 2.444122927163237

Epoch: 5| Step: 9
Training loss: 2.950881242752075
Validation loss: 2.445927486624769

Epoch: 5| Step: 10
Training loss: 2.922839403152466
Validation loss: 2.4491689640988588

Epoch: 78| Step: 0
Training loss: 2.786139965057373
Validation loss: 2.466746276424777

Epoch: 5| Step: 1
Training loss: 2.5549890995025635
Validation loss: 2.47017091320407

Epoch: 5| Step: 2
Training loss: 2.8034777641296387
Validation loss: 2.47607175765499

Epoch: 5| Step: 3
Training loss: 2.5646164417266846
Validation loss: 2.4507620155170398

Epoch: 5| Step: 4
Training loss: 2.3536124229431152
Validation loss: 2.4446742201364167

Epoch: 5| Step: 5
Training loss: 3.1133477687835693
Validation loss: 2.435927237233808

Epoch: 5| Step: 6
Training loss: 2.755998134613037
Validation loss: 2.434253054280435

Epoch: 5| Step: 7
Training loss: 2.9297726154327393
Validation loss: 2.434498635671472

Epoch: 5| Step: 8
Training loss: 2.773879289627075
Validation loss: 2.4321403452145156

Epoch: 5| Step: 9
Training loss: 1.9957733154296875
Validation loss: 2.434985142882152

Epoch: 5| Step: 10
Training loss: 2.5546493530273438
Validation loss: 2.4374607788619174

Epoch: 79| Step: 0
Training loss: 2.903862953186035
Validation loss: 2.43650887602119

Epoch: 5| Step: 1
Training loss: 2.793677568435669
Validation loss: 2.4339091059982136

Epoch: 5| Step: 2
Training loss: 2.1329269409179688
Validation loss: 2.4290281444467525

Epoch: 5| Step: 3
Training loss: 2.4709129333496094
Validation loss: 2.432205820596346

Epoch: 5| Step: 4
Training loss: 2.6546688079833984
Validation loss: 2.4257123342124363

Epoch: 5| Step: 5
Training loss: 2.297086000442505
Validation loss: 2.424469840142035

Epoch: 5| Step: 6
Training loss: 2.891592264175415
Validation loss: 2.4293697239250265

Epoch: 5| Step: 7
Training loss: 2.475069761276245
Validation loss: 2.4309486419923845

Epoch: 5| Step: 8
Training loss: 2.918898820877075
Validation loss: 2.432492922711116

Epoch: 5| Step: 9
Training loss: 2.7923924922943115
Validation loss: 2.443333028465189

Epoch: 5| Step: 10
Training loss: 2.936436414718628
Validation loss: 2.450854483471122

Epoch: 80| Step: 0
Training loss: 2.752854585647583
Validation loss: 2.456799853232599

Epoch: 5| Step: 1
Training loss: 3.1074273586273193
Validation loss: 2.470000923320811

Epoch: 5| Step: 2
Training loss: 2.8497912883758545
Validation loss: 2.4646516153889317

Epoch: 5| Step: 3
Training loss: 2.824608325958252
Validation loss: 2.464447667521815

Epoch: 5| Step: 4
Training loss: 2.9879133701324463
Validation loss: 2.4629822674617974

Epoch: 5| Step: 5
Training loss: 2.5969204902648926
Validation loss: 2.4515674319318546

Epoch: 5| Step: 6
Training loss: 2.2011122703552246
Validation loss: 2.446472147459625

Epoch: 5| Step: 7
Training loss: 2.5579161643981934
Validation loss: 2.4383819026331746

Epoch: 5| Step: 8
Training loss: 2.253990650177002
Validation loss: 2.4324244376151793

Epoch: 5| Step: 9
Training loss: 2.9368743896484375
Validation loss: 2.4326676758386756

Epoch: 5| Step: 10
Training loss: 2.005497455596924
Validation loss: 2.428695842783938

Epoch: 81| Step: 0
Training loss: 2.7568423748016357
Validation loss: 2.4349503824787755

Epoch: 5| Step: 1
Training loss: 2.5003364086151123
Validation loss: 2.4305789214308544

Epoch: 5| Step: 2
Training loss: 2.7208199501037598
Validation loss: 2.430894651720601

Epoch: 5| Step: 3
Training loss: 2.528043270111084
Validation loss: 2.4238565506473666

Epoch: 5| Step: 4
Training loss: 3.3248367309570312
Validation loss: 2.4326893411656862

Epoch: 5| Step: 5
Training loss: 2.4244165420532227
Validation loss: 2.431031357857489

Epoch: 5| Step: 6
Training loss: 2.46509051322937
Validation loss: 2.4302422205607095

Epoch: 5| Step: 7
Training loss: 2.0994369983673096
Validation loss: 2.4297717719949703

Epoch: 5| Step: 8
Training loss: 2.30631160736084
Validation loss: 2.437974804191179

Epoch: 5| Step: 9
Training loss: 2.5833027362823486
Validation loss: 2.430861819174982

Epoch: 5| Step: 10
Training loss: 3.5605111122131348
Validation loss: 2.441288822440691

Epoch: 82| Step: 0
Training loss: 2.4829161167144775
Validation loss: 2.435321956552485

Epoch: 5| Step: 1
Training loss: 2.6977739334106445
Validation loss: 2.4266162072458575

Epoch: 5| Step: 2
Training loss: 2.3106555938720703
Validation loss: 2.4240044650211128

Epoch: 5| Step: 3
Training loss: 2.2229690551757812
Validation loss: 2.4253224531809487

Epoch: 5| Step: 4
Training loss: 3.163257122039795
Validation loss: 2.4263411824421217

Epoch: 5| Step: 5
Training loss: 3.0541913509368896
Validation loss: 2.4315132761514313

Epoch: 5| Step: 6
Training loss: 2.7904140949249268
Validation loss: 2.431062485582085

Epoch: 5| Step: 7
Training loss: 2.8255650997161865
Validation loss: 2.425049538253456

Epoch: 5| Step: 8
Training loss: 1.988323450088501
Validation loss: 2.4187322278176584

Epoch: 5| Step: 9
Training loss: 2.4892449378967285
Validation loss: 2.4133585447906167

Epoch: 5| Step: 10
Training loss: 3.2138593196868896
Validation loss: 2.412035374231236

Epoch: 83| Step: 0
Training loss: 2.6667094230651855
Validation loss: 2.4110042689948954

Epoch: 5| Step: 1
Training loss: 2.2062277793884277
Validation loss: 2.410208414959651

Epoch: 5| Step: 2
Training loss: 2.496432065963745
Validation loss: 2.4105484536899033

Epoch: 5| Step: 3
Training loss: 3.155592679977417
Validation loss: 2.4144569725118656

Epoch: 5| Step: 4
Training loss: 2.0669872760772705
Validation loss: 2.4107162978059504

Epoch: 5| Step: 5
Training loss: 2.6790943145751953
Validation loss: 2.410407584200623

Epoch: 5| Step: 6
Training loss: 2.6340765953063965
Validation loss: 2.410064528065343

Epoch: 5| Step: 7
Training loss: 2.6048970222473145
Validation loss: 2.412052044304468

Epoch: 5| Step: 8
Training loss: 2.853257417678833
Validation loss: 2.4120226521645822

Epoch: 5| Step: 9
Training loss: 2.860978603363037
Validation loss: 2.416718413752894

Epoch: 5| Step: 10
Training loss: 2.943208694458008
Validation loss: 2.422069646978891

Epoch: 84| Step: 0
Training loss: 2.4509644508361816
Validation loss: 2.420064769765382

Epoch: 5| Step: 1
Training loss: 3.03075909614563
Validation loss: 2.4344989894538798

Epoch: 5| Step: 2
Training loss: 2.469759464263916
Validation loss: 2.4525721662787983

Epoch: 5| Step: 3
Training loss: 2.669335126876831
Validation loss: 2.4561237878696893

Epoch: 5| Step: 4
Training loss: 2.373469829559326
Validation loss: 2.4709786574045816

Epoch: 5| Step: 5
Training loss: 2.8459935188293457
Validation loss: 2.4688942201675905

Epoch: 5| Step: 6
Training loss: 2.3139662742614746
Validation loss: 2.478560560493059

Epoch: 5| Step: 7
Training loss: 2.814885377883911
Validation loss: 2.4619848010360554

Epoch: 5| Step: 8
Training loss: 3.0632710456848145
Validation loss: 2.4500372768730245

Epoch: 5| Step: 9
Training loss: 2.839920997619629
Validation loss: 2.4210201758210377

Epoch: 5| Step: 10
Training loss: 2.302177667617798
Validation loss: 2.4138897875303864

Epoch: 85| Step: 0
Training loss: 3.2823739051818848
Validation loss: 2.4066059307385514

Epoch: 5| Step: 1
Training loss: 2.353855609893799
Validation loss: 2.4123934468915387

Epoch: 5| Step: 2
Training loss: 1.738764762878418
Validation loss: 2.4182723414513374

Epoch: 5| Step: 3
Training loss: 2.7089130878448486
Validation loss: 2.43304951729313

Epoch: 5| Step: 4
Training loss: 2.2412798404693604
Validation loss: 2.4428114480869745

Epoch: 5| Step: 5
Training loss: 2.7163267135620117
Validation loss: 2.4555839287337435

Epoch: 5| Step: 6
Training loss: 3.1391284465789795
Validation loss: 2.482057022792037

Epoch: 5| Step: 7
Training loss: 2.306671619415283
Validation loss: 2.468540842815112

Epoch: 5| Step: 8
Training loss: 3.6150946617126465
Validation loss: 2.4622215301759782

Epoch: 5| Step: 9
Training loss: 2.5863564014434814
Validation loss: 2.441115968970842

Epoch: 5| Step: 10
Training loss: 2.665414810180664
Validation loss: 2.424022500232984

Epoch: 86| Step: 0
Training loss: 2.984923839569092
Validation loss: 2.40930203981297

Epoch: 5| Step: 1
Training loss: 2.682277202606201
Validation loss: 2.40576530784689

Epoch: 5| Step: 2
Training loss: 2.3750319480895996
Validation loss: 2.4106594362566547

Epoch: 5| Step: 3
Training loss: 2.829246997833252
Validation loss: 2.416427545650031

Epoch: 5| Step: 4
Training loss: 1.83291757106781
Validation loss: 2.428232382702571

Epoch: 5| Step: 5
Training loss: 3.071227550506592
Validation loss: 2.433287351362167

Epoch: 5| Step: 6
Training loss: 2.772700071334839
Validation loss: 2.4174295369014946

Epoch: 5| Step: 7
Training loss: 2.3238372802734375
Validation loss: 2.4315432528013825

Epoch: 5| Step: 8
Training loss: 2.6018166542053223
Validation loss: 2.4254368248806206

Epoch: 5| Step: 9
Training loss: 2.424328565597534
Validation loss: 2.4289522042838474

Epoch: 5| Step: 10
Training loss: 3.2559447288513184
Validation loss: 2.4310031757559827

Epoch: 87| Step: 0
Training loss: 2.890392780303955
Validation loss: 2.425754339464249

Epoch: 5| Step: 1
Training loss: 2.7166907787323
Validation loss: 2.427470120050574

Epoch: 5| Step: 2
Training loss: 2.99141788482666
Validation loss: 2.421283268159436

Epoch: 5| Step: 3
Training loss: 2.287242889404297
Validation loss: 2.4124371364552486

Epoch: 5| Step: 4
Training loss: 2.25810170173645
Validation loss: 2.416471417232226

Epoch: 5| Step: 5
Training loss: 2.8165297508239746
Validation loss: 2.4122662903160177

Epoch: 5| Step: 6
Training loss: 2.318432331085205
Validation loss: 2.4051209367731565

Epoch: 5| Step: 7
Training loss: 2.549975872039795
Validation loss: 2.403610155146609

Epoch: 5| Step: 8
Training loss: 2.764906406402588
Validation loss: 2.4091112485495945

Epoch: 5| Step: 9
Training loss: 2.415179967880249
Validation loss: 2.4017298426679385

Epoch: 5| Step: 10
Training loss: 3.136533737182617
Validation loss: 2.403595329612814

Epoch: 88| Step: 0
Training loss: 2.6065187454223633
Validation loss: 2.4066720572851037

Epoch: 5| Step: 1
Training loss: 2.1308748722076416
Validation loss: 2.413652950717557

Epoch: 5| Step: 2
Training loss: 2.2000317573547363
Validation loss: 2.423673629760742

Epoch: 5| Step: 3
Training loss: 2.2128348350524902
Validation loss: 2.429976438963285

Epoch: 5| Step: 4
Training loss: 3.38885235786438
Validation loss: 2.423828935110441

Epoch: 5| Step: 5
Training loss: 2.2452635765075684
Validation loss: 2.4141093223325667

Epoch: 5| Step: 6
Training loss: 2.5792014598846436
Validation loss: 2.4144796658587713

Epoch: 5| Step: 7
Training loss: 1.9509875774383545
Validation loss: 2.4066116220207623

Epoch: 5| Step: 8
Training loss: 3.532458543777466
Validation loss: 2.4049970462758052

Epoch: 5| Step: 9
Training loss: 2.6044604778289795
Validation loss: 2.401903206302274

Epoch: 5| Step: 10
Training loss: 3.730677366256714
Validation loss: 2.401986619477631

Epoch: 89| Step: 0
Training loss: 2.7776834964752197
Validation loss: 2.399965311891289

Epoch: 5| Step: 1
Training loss: 3.3140342235565186
Validation loss: 2.4082773449600383

Epoch: 5| Step: 2
Training loss: 2.3645622730255127
Validation loss: 2.394827490211815

Epoch: 5| Step: 3
Training loss: 2.366356611251831
Validation loss: 2.403432716605484

Epoch: 5| Step: 4
Training loss: 3.0677731037139893
Validation loss: 2.404925941139139

Epoch: 5| Step: 5
Training loss: 2.551499128341675
Validation loss: 2.404457979304816

Epoch: 5| Step: 6
Training loss: 2.743879795074463
Validation loss: 2.4074285927639214

Epoch: 5| Step: 7
Training loss: 3.0832061767578125
Validation loss: 2.4082574818723943

Epoch: 5| Step: 8
Training loss: 2.2380213737487793
Validation loss: 2.4077998079279417

Epoch: 5| Step: 9
Training loss: 2.200150966644287
Validation loss: 2.4095754802867932

Epoch: 5| Step: 10
Training loss: 2.2278270721435547
Validation loss: 2.412784637943391

Epoch: 90| Step: 0
Training loss: 3.0268678665161133
Validation loss: 2.419394957121982

Epoch: 5| Step: 1
Training loss: 2.0687758922576904
Validation loss: 2.417429821465605

Epoch: 5| Step: 2
Training loss: 2.6812026500701904
Validation loss: 2.418066217053321

Epoch: 5| Step: 3
Training loss: 2.580730676651001
Validation loss: 2.411424490713304

Epoch: 5| Step: 4
Training loss: 3.2809925079345703
Validation loss: 2.411237560292726

Epoch: 5| Step: 5
Training loss: 2.5026659965515137
Validation loss: 2.4186922298964633

Epoch: 5| Step: 6
Training loss: 2.8655238151550293
Validation loss: 2.411783622157189

Epoch: 5| Step: 7
Training loss: 2.4351096153259277
Validation loss: 2.4058537765215804

Epoch: 5| Step: 8
Training loss: 2.2689146995544434
Validation loss: 2.405948326151858

Epoch: 5| Step: 9
Training loss: 2.817383050918579
Validation loss: 2.40834984215357

Epoch: 5| Step: 10
Training loss: 2.340787649154663
Validation loss: 2.404240583860746

Epoch: 91| Step: 0
Training loss: 2.8471429347991943
Validation loss: 2.4086621653649116

Epoch: 5| Step: 1
Training loss: 2.877361297607422
Validation loss: 2.403200303354571

Epoch: 5| Step: 2
Training loss: 2.730637788772583
Validation loss: 2.40491234999831

Epoch: 5| Step: 3
Training loss: 2.7546095848083496
Validation loss: 2.3983691482133764

Epoch: 5| Step: 4
Training loss: 2.3248088359832764
Validation loss: 2.3898080830932944

Epoch: 5| Step: 5
Training loss: 2.5540359020233154
Validation loss: 2.3929766096094602

Epoch: 5| Step: 6
Training loss: 2.9375271797180176
Validation loss: 2.388109491717431

Epoch: 5| Step: 7
Training loss: 2.0569357872009277
Validation loss: 2.389599041272235

Epoch: 5| Step: 8
Training loss: 2.852788209915161
Validation loss: 2.390562936823855

Epoch: 5| Step: 9
Training loss: 2.3525912761688232
Validation loss: 2.396465318177336

Epoch: 5| Step: 10
Training loss: 2.641293525695801
Validation loss: 2.4007221293705765

Epoch: 92| Step: 0
Training loss: 2.3419926166534424
Validation loss: 2.3968562720924296

Epoch: 5| Step: 1
Training loss: 2.517082691192627
Validation loss: 2.403343972339425

Epoch: 5| Step: 2
Training loss: 1.8179117441177368
Validation loss: 2.3990699860357467

Epoch: 5| Step: 3
Training loss: 2.7390456199645996
Validation loss: 2.4073519142725135

Epoch: 5| Step: 4
Training loss: 2.7048823833465576
Validation loss: 2.4066219688743673

Epoch: 5| Step: 5
Training loss: 3.0727627277374268
Validation loss: 2.4143655800050303

Epoch: 5| Step: 6
Training loss: 2.6578590869903564
Validation loss: 2.416723143669867

Epoch: 5| Step: 7
Training loss: 2.577528476715088
Validation loss: 2.4279088973999023

Epoch: 5| Step: 8
Training loss: 2.6270384788513184
Validation loss: 2.4434644509387273

Epoch: 5| Step: 9
Training loss: 2.8533401489257812
Validation loss: 2.448065362950807

Epoch: 5| Step: 10
Training loss: 3.0814502239227295
Validation loss: 2.4520857154682116

Epoch: 93| Step: 0
Training loss: 2.7434356212615967
Validation loss: 2.447782354970132

Epoch: 5| Step: 1
Training loss: 2.8542418479919434
Validation loss: 2.4398754950492614

Epoch: 5| Step: 2
Training loss: 2.618257999420166
Validation loss: 2.441897633255169

Epoch: 5| Step: 3
Training loss: 2.635472536087036
Validation loss: 2.441226522127787

Epoch: 5| Step: 4
Training loss: 2.7220499515533447
Validation loss: 2.4347056368345856

Epoch: 5| Step: 5
Training loss: 3.2116825580596924
Validation loss: 2.429390227922829

Epoch: 5| Step: 6
Training loss: 2.323168992996216
Validation loss: 2.420649607976278

Epoch: 5| Step: 7
Training loss: 2.9459052085876465
Validation loss: 2.4120250491685766

Epoch: 5| Step: 8
Training loss: 2.201896905899048
Validation loss: 2.3978963398164317

Epoch: 5| Step: 9
Training loss: 1.876652717590332
Validation loss: 2.3911752726442073

Epoch: 5| Step: 10
Training loss: 2.7763099670410156
Validation loss: 2.3942718505859375

Epoch: 94| Step: 0
Training loss: 2.794945478439331
Validation loss: 2.3876846926186674

Epoch: 5| Step: 1
Training loss: 2.942854404449463
Validation loss: 2.3928612201444563

Epoch: 5| Step: 2
Training loss: 2.693948268890381
Validation loss: 2.3935735764042025

Epoch: 5| Step: 3
Training loss: 2.255647659301758
Validation loss: 2.3954529916086504

Epoch: 5| Step: 4
Training loss: 2.6644959449768066
Validation loss: 2.3894255212558213

Epoch: 5| Step: 5
Training loss: 2.7266244888305664
Validation loss: 2.400891432198145

Epoch: 5| Step: 6
Training loss: 2.025442600250244
Validation loss: 2.4015998686513593

Epoch: 5| Step: 7
Training loss: 2.648052930831909
Validation loss: 2.396726154511975

Epoch: 5| Step: 8
Training loss: 2.356994867324829
Validation loss: 2.3977582762318272

Epoch: 5| Step: 9
Training loss: 2.918729782104492
Validation loss: 2.4072423775990806

Epoch: 5| Step: 10
Training loss: 2.946767807006836
Validation loss: 2.40750765544112

Epoch: 95| Step: 0
Training loss: 2.368283748626709
Validation loss: 2.403517484664917

Epoch: 5| Step: 1
Training loss: 3.01985502243042
Validation loss: 2.4041719385372695

Epoch: 5| Step: 2
Training loss: 2.113219738006592
Validation loss: 2.4003501322961625

Epoch: 5| Step: 3
Training loss: 2.8222262859344482
Validation loss: 2.4003905583453435

Epoch: 5| Step: 4
Training loss: 2.760448455810547
Validation loss: 2.3967669830527356

Epoch: 5| Step: 5
Training loss: 2.7829129695892334
Validation loss: 2.402664963917066

Epoch: 5| Step: 6
Training loss: 2.5635507106781006
Validation loss: 2.4033892923785793

Epoch: 5| Step: 7
Training loss: 2.060147762298584
Validation loss: 2.4059866987248903

Epoch: 5| Step: 8
Training loss: 2.5993902683258057
Validation loss: 2.401822784895538

Epoch: 5| Step: 9
Training loss: 2.4777991771698
Validation loss: 2.4001647554418093

Epoch: 5| Step: 10
Training loss: 3.4475443363189697
Validation loss: 2.395266366261308

Epoch: 96| Step: 0
Training loss: 2.2946343421936035
Validation loss: 2.391638284088463

Epoch: 5| Step: 1
Training loss: 2.594202756881714
Validation loss: 2.386319988517351

Epoch: 5| Step: 2
Training loss: 2.97190523147583
Validation loss: 2.3878805098995084

Epoch: 5| Step: 3
Training loss: 2.1087586879730225
Validation loss: 2.3965325765712286

Epoch: 5| Step: 4
Training loss: 2.5663864612579346
Validation loss: 2.3816824907897622

Epoch: 5| Step: 5
Training loss: 2.794180393218994
Validation loss: 2.394776557081489

Epoch: 5| Step: 6
Training loss: 2.4231579303741455
Validation loss: 2.39654775076015

Epoch: 5| Step: 7
Training loss: 2.062068223953247
Validation loss: 2.4059828173729683

Epoch: 5| Step: 8
Training loss: 3.037154197692871
Validation loss: 2.4068406756206224

Epoch: 5| Step: 9
Training loss: 3.4774272441864014
Validation loss: 2.4050667824283725

Epoch: 5| Step: 10
Training loss: 2.512235403060913
Validation loss: 2.4185643965198147

Epoch: 97| Step: 0
Training loss: 2.3732433319091797
Validation loss: 2.420134293135776

Epoch: 5| Step: 1
Training loss: 2.5460095405578613
Validation loss: 2.4047082201127084

Epoch: 5| Step: 2
Training loss: 2.176997661590576
Validation loss: 2.4059142604950936

Epoch: 5| Step: 3
Training loss: 3.0218043327331543
Validation loss: 2.3979434172312417

Epoch: 5| Step: 4
Training loss: 2.536221504211426
Validation loss: 2.3917494743101058

Epoch: 5| Step: 5
Training loss: 2.4877781867980957
Validation loss: 2.3964055430504585

Epoch: 5| Step: 6
Training loss: 2.8412997722625732
Validation loss: 2.392124265752813

Epoch: 5| Step: 7
Training loss: 2.74424409866333
Validation loss: 2.3855565542815835

Epoch: 5| Step: 8
Training loss: 2.6579346656799316
Validation loss: 2.3898402106377388

Epoch: 5| Step: 9
Training loss: 2.979966640472412
Validation loss: 2.389261309818555

Epoch: 5| Step: 10
Training loss: 2.4710397720336914
Validation loss: 2.3837671433725665

Epoch: 98| Step: 0
Training loss: 2.866046190261841
Validation loss: 2.390211843675183

Epoch: 5| Step: 1
Training loss: 2.057129144668579
Validation loss: 2.3893176637670046

Epoch: 5| Step: 2
Training loss: 2.434842348098755
Validation loss: 2.404272658850557

Epoch: 5| Step: 3
Training loss: 2.6345231533050537
Validation loss: 2.4132842863759687

Epoch: 5| Step: 4
Training loss: 2.5300233364105225
Validation loss: 2.4276074978613083

Epoch: 5| Step: 5
Training loss: 3.0955817699432373
Validation loss: 2.4302788139671407

Epoch: 5| Step: 6
Training loss: 2.493366241455078
Validation loss: 2.423683717686643

Epoch: 5| Step: 7
Training loss: 3.0851664543151855
Validation loss: 2.4101747210307787

Epoch: 5| Step: 8
Training loss: 2.3012306690216064
Validation loss: 2.393656522996964

Epoch: 5| Step: 9
Training loss: 3.042116641998291
Validation loss: 2.3920863033622823

Epoch: 5| Step: 10
Training loss: 2.244598865509033
Validation loss: 2.3872618162503807

Epoch: 99| Step: 0
Training loss: 2.626443386077881
Validation loss: 2.386910856411021

Epoch: 5| Step: 1
Training loss: 2.3925976753234863
Validation loss: 2.383630278289959

Epoch: 5| Step: 2
Training loss: 2.907766580581665
Validation loss: 2.384502880034908

Epoch: 5| Step: 3
Training loss: 2.4043986797332764
Validation loss: 2.383220447007046

Epoch: 5| Step: 4
Training loss: 1.807800054550171
Validation loss: 2.386779882574594

Epoch: 5| Step: 5
Training loss: 2.5919952392578125
Validation loss: 2.387447562268985

Epoch: 5| Step: 6
Training loss: 3.102750301361084
Validation loss: 2.3866692537902505

Epoch: 5| Step: 7
Training loss: 2.7843375205993652
Validation loss: 2.383127209960773

Epoch: 5| Step: 8
Training loss: 2.9320857524871826
Validation loss: 2.3870062584518106

Epoch: 5| Step: 9
Training loss: 2.7846004962921143
Validation loss: 2.381543092830207

Epoch: 5| Step: 10
Training loss: 2.413715362548828
Validation loss: 2.384675964232414

Epoch: 100| Step: 0
Training loss: 2.4039270877838135
Validation loss: 2.3907820665708153

Epoch: 5| Step: 1
Training loss: 2.5433335304260254
Validation loss: 2.3926929325185795

Epoch: 5| Step: 2
Training loss: 2.5952773094177246
Validation loss: 2.402422983159301

Epoch: 5| Step: 3
Training loss: 2.0314440727233887
Validation loss: 2.4104272832152662

Epoch: 5| Step: 4
Training loss: 2.60846209526062
Validation loss: 2.415295811109645

Epoch: 5| Step: 5
Training loss: 2.677945613861084
Validation loss: 2.4324901283428235

Epoch: 5| Step: 6
Training loss: 2.713809013366699
Validation loss: 2.422109865373181

Epoch: 5| Step: 7
Training loss: 2.867201328277588
Validation loss: 2.4169673278767574

Epoch: 5| Step: 8
Training loss: 3.0175540447235107
Validation loss: 2.3961328178323726

Epoch: 5| Step: 9
Training loss: 2.1033568382263184
Validation loss: 2.3869377233648814

Epoch: 5| Step: 10
Training loss: 3.3221771717071533
Validation loss: 2.39178361943973

Epoch: 101| Step: 0
Training loss: 2.719971179962158
Validation loss: 2.3837287836177374

Epoch: 5| Step: 1
Training loss: 2.1192855834960938
Validation loss: 2.3847632100505214

Epoch: 5| Step: 2
Training loss: 2.75062894821167
Validation loss: 2.3886435160072903

Epoch: 5| Step: 3
Training loss: 2.5340871810913086
Validation loss: 2.3822274566978536

Epoch: 5| Step: 4
Training loss: 2.8947196006774902
Validation loss: 2.376760510988133

Epoch: 5| Step: 5
Training loss: 2.691884756088257
Validation loss: 2.3769696092092865

Epoch: 5| Step: 6
Training loss: 2.332347869873047
Validation loss: 2.3745953382984286

Epoch: 5| Step: 7
Training loss: 2.3794708251953125
Validation loss: 2.376001368286789

Epoch: 5| Step: 8
Training loss: 3.1686272621154785
Validation loss: 2.3741023489224014

Epoch: 5| Step: 9
Training loss: 2.37559175491333
Validation loss: 2.388369083404541

Epoch: 5| Step: 10
Training loss: 2.7294013500213623
Validation loss: 2.3855768660063386

Epoch: 102| Step: 0
Training loss: 2.915642261505127
Validation loss: 2.4025601674151678

Epoch: 5| Step: 1
Training loss: 2.60414457321167
Validation loss: 2.416247837005123

Epoch: 5| Step: 2
Training loss: 3.0940468311309814
Validation loss: 2.4347709353252123

Epoch: 5| Step: 3
Training loss: 3.156202554702759
Validation loss: 2.4323226226273404

Epoch: 5| Step: 4
Training loss: 2.713202476501465
Validation loss: 2.4210036108570714

Epoch: 5| Step: 5
Training loss: 2.5217673778533936
Validation loss: 2.3996616794217016

Epoch: 5| Step: 6
Training loss: 2.636096954345703
Validation loss: 2.3962447797098467

Epoch: 5| Step: 7
Training loss: 2.1348459720611572
Validation loss: 2.390007422816369

Epoch: 5| Step: 8
Training loss: 1.9384281635284424
Validation loss: 2.3768628617768646

Epoch: 5| Step: 9
Training loss: 2.1914830207824707
Validation loss: 2.378730197106638

Epoch: 5| Step: 10
Training loss: 2.891768455505371
Validation loss: 2.3747909940699095

Epoch: 103| Step: 0
Training loss: 2.990591526031494
Validation loss: 2.3664896411280476

Epoch: 5| Step: 1
Training loss: 2.282763719558716
Validation loss: 2.367047853367303

Epoch: 5| Step: 2
Training loss: 2.068624496459961
Validation loss: 2.3775479383366083

Epoch: 5| Step: 3
Training loss: 3.1663308143615723
Validation loss: 2.367396159838605

Epoch: 5| Step: 4
Training loss: 2.77923321723938
Validation loss: 2.378123450022872

Epoch: 5| Step: 5
Training loss: 2.50895357131958
Validation loss: 2.377554214128884

Epoch: 5| Step: 6
Training loss: 2.5609610080718994
Validation loss: 2.385580224375571

Epoch: 5| Step: 7
Training loss: 3.2408084869384766
Validation loss: 2.3857429604376517

Epoch: 5| Step: 8
Training loss: 2.331099271774292
Validation loss: 2.3798021167837162

Epoch: 5| Step: 9
Training loss: 2.1143016815185547
Validation loss: 2.3961109627959547

Epoch: 5| Step: 10
Training loss: 2.69283390045166
Validation loss: 2.3979627983544463

Epoch: 104| Step: 0
Training loss: 2.5842323303222656
Validation loss: 2.389550229554535

Epoch: 5| Step: 1
Training loss: 2.862596035003662
Validation loss: 2.385658097523515

Epoch: 5| Step: 2
Training loss: 2.134655475616455
Validation loss: 2.3928812806324293

Epoch: 5| Step: 3
Training loss: 2.8070685863494873
Validation loss: 2.3904818821978826

Epoch: 5| Step: 4
Training loss: 3.1533775329589844
Validation loss: 2.3937816568600234

Epoch: 5| Step: 5
Training loss: 2.3215203285217285
Validation loss: 2.4047827220732167

Epoch: 5| Step: 6
Training loss: 3.1287014484405518
Validation loss: 2.390973050107238

Epoch: 5| Step: 7
Training loss: 2.4710774421691895
Validation loss: 2.3890601973379813

Epoch: 5| Step: 8
Training loss: 2.7394187450408936
Validation loss: 2.374394298881613

Epoch: 5| Step: 9
Training loss: 2.787187099456787
Validation loss: 2.376703267456383

Epoch: 5| Step: 10
Training loss: 1.4202600717544556
Validation loss: 2.3789721791462233

Epoch: 105| Step: 0
Training loss: 2.8818328380584717
Validation loss: 2.3730491694583686

Epoch: 5| Step: 1
Training loss: 2.0396881103515625
Validation loss: 2.3882113605417232

Epoch: 5| Step: 2
Training loss: 2.9507014751434326
Validation loss: 2.376967945406514

Epoch: 5| Step: 3
Training loss: 2.919316053390503
Validation loss: 2.370767219092256

Epoch: 5| Step: 4
Training loss: 2.320344924926758
Validation loss: 2.370651593772314

Epoch: 5| Step: 5
Training loss: 2.0998783111572266
Validation loss: 2.3675882970133135

Epoch: 5| Step: 6
Training loss: 2.4914772510528564
Validation loss: 2.360993767297396

Epoch: 5| Step: 7
Training loss: 2.874565362930298
Validation loss: 2.364112513039702

Epoch: 5| Step: 8
Training loss: 3.035757541656494
Validation loss: 2.3662979128540202

Epoch: 5| Step: 9
Training loss: 2.296511173248291
Validation loss: 2.369216949709

Epoch: 5| Step: 10
Training loss: 2.83609676361084
Validation loss: 2.367535093779205

Epoch: 106| Step: 0
Training loss: 2.553316354751587
Validation loss: 2.3669116702131046

Epoch: 5| Step: 1
Training loss: 3.3526597023010254
Validation loss: 2.3676940215531217

Epoch: 5| Step: 2
Training loss: 2.367990255355835
Validation loss: 2.3729266581996793

Epoch: 5| Step: 3
Training loss: 3.228984832763672
Validation loss: 2.3733647100387083

Epoch: 5| Step: 4
Training loss: 2.892374038696289
Validation loss: 2.3822314687954482

Epoch: 5| Step: 5
Training loss: 2.6971890926361084
Validation loss: 2.3809882287056214

Epoch: 5| Step: 6
Training loss: 2.4461734294891357
Validation loss: 2.38481726184968

Epoch: 5| Step: 7
Training loss: 2.0501697063446045
Validation loss: 2.3844695809066936

Epoch: 5| Step: 8
Training loss: 1.7557861804962158
Validation loss: 2.3839959790629726

Epoch: 5| Step: 9
Training loss: 2.612741470336914
Validation loss: 2.3880068435463855

Epoch: 5| Step: 10
Training loss: 2.72009015083313
Validation loss: 2.376699956514502

Epoch: 107| Step: 0
Training loss: 2.6353378295898438
Validation loss: 2.37427645216706

Epoch: 5| Step: 1
Training loss: 2.339998483657837
Validation loss: 2.375246799120339

Epoch: 5| Step: 2
Training loss: 2.061964511871338
Validation loss: 2.3713253749314176

Epoch: 5| Step: 3
Training loss: 2.3845818042755127
Validation loss: 2.3743416211938344

Epoch: 5| Step: 4
Training loss: 2.6297030448913574
Validation loss: 2.3748168406947965

Epoch: 5| Step: 5
Training loss: 2.463510513305664
Validation loss: 2.3733174083053425

Epoch: 5| Step: 6
Training loss: 2.546309232711792
Validation loss: 2.3772934149670344

Epoch: 5| Step: 7
Training loss: 2.9136829376220703
Validation loss: 2.398500447632164

Epoch: 5| Step: 8
Training loss: 2.5903549194335938
Validation loss: 2.41048607262232

Epoch: 5| Step: 9
Training loss: 3.094813823699951
Validation loss: 2.419291978241295

Epoch: 5| Step: 10
Training loss: 3.0812580585479736
Validation loss: 2.4206762442024807

Epoch: 108| Step: 0
Training loss: 2.2198703289031982
Validation loss: 2.398802570117417

Epoch: 5| Step: 1
Training loss: 2.278621196746826
Validation loss: 2.3861696848305325

Epoch: 5| Step: 2
Training loss: 2.61157488822937
Validation loss: 2.372281559052006

Epoch: 5| Step: 3
Training loss: 2.7235872745513916
Validation loss: 2.3700633305375294

Epoch: 5| Step: 4
Training loss: 2.8585925102233887
Validation loss: 2.3719387951717583

Epoch: 5| Step: 5
Training loss: 2.9600319862365723
Validation loss: 2.370580421980991

Epoch: 5| Step: 6
Training loss: 3.299044370651245
Validation loss: 2.380528921722084

Epoch: 5| Step: 7
Training loss: 2.4342684745788574
Validation loss: 2.378937454633815

Epoch: 5| Step: 8
Training loss: 1.8912006616592407
Validation loss: 2.376442288839689

Epoch: 5| Step: 9
Training loss: 2.4168701171875
Validation loss: 2.3741707135272283

Epoch: 5| Step: 10
Training loss: 2.991851329803467
Validation loss: 2.381088077381093

Epoch: 109| Step: 0
Training loss: 2.7404227256774902
Validation loss: 2.3882895336356214

Epoch: 5| Step: 1
Training loss: 2.0266754627227783
Validation loss: 2.379985373507264

Epoch: 5| Step: 2
Training loss: 3.1775336265563965
Validation loss: 2.3626853830070904

Epoch: 5| Step: 3
Training loss: 2.0636000633239746
Validation loss: 2.35410475730896

Epoch: 5| Step: 4
Training loss: 3.081965684890747
Validation loss: 2.3565923167813208

Epoch: 5| Step: 5
Training loss: 2.647125720977783
Validation loss: 2.348716853767313

Epoch: 5| Step: 6
Training loss: 3.031313419342041
Validation loss: 2.348788192195277

Epoch: 5| Step: 7
Training loss: 2.5766654014587402
Validation loss: 2.3540416635492796

Epoch: 5| Step: 8
Training loss: 2.5578014850616455
Validation loss: 2.3514760412195677

Epoch: 5| Step: 9
Training loss: 2.5207602977752686
Validation loss: 2.3490454330239245

Epoch: 5| Step: 10
Training loss: 2.19809627532959
Validation loss: 2.3535241824324413

Epoch: 110| Step: 0
Training loss: 3.3620216846466064
Validation loss: 2.353761024372552

Epoch: 5| Step: 1
Training loss: 2.231271266937256
Validation loss: 2.353382820724159

Epoch: 5| Step: 2
Training loss: 2.4498867988586426
Validation loss: 2.3494969196217035

Epoch: 5| Step: 3
Training loss: 2.029747724533081
Validation loss: 2.3575589015919673

Epoch: 5| Step: 4
Training loss: 1.9736063480377197
Validation loss: 2.3641250992334015

Epoch: 5| Step: 5
Training loss: 2.971935272216797
Validation loss: 2.3719896065291537

Epoch: 5| Step: 6
Training loss: 3.151050329208374
Validation loss: 2.3721942824702107

Epoch: 5| Step: 7
Training loss: 2.3292431831359863
Validation loss: 2.3769148472816712

Epoch: 5| Step: 8
Training loss: 2.0694992542266846
Validation loss: 2.386571443209084

Epoch: 5| Step: 9
Training loss: 3.2893428802490234
Validation loss: 2.3986436654162664

Epoch: 5| Step: 10
Training loss: 2.8570399284362793
Validation loss: 2.3993071894491873

Epoch: 111| Step: 0
Training loss: 2.724104404449463
Validation loss: 2.375117487804864

Epoch: 5| Step: 1
Training loss: 2.9379959106445312
Validation loss: 2.370356482844199

Epoch: 5| Step: 2
Training loss: 2.540452003479004
Validation loss: 2.3621043594934608

Epoch: 5| Step: 3
Training loss: 2.668023109436035
Validation loss: 2.3597122161619124

Epoch: 5| Step: 4
Training loss: 2.8719699382781982
Validation loss: 2.362893383990052

Epoch: 5| Step: 5
Training loss: 2.093301773071289
Validation loss: 2.3642121899512505

Epoch: 5| Step: 6
Training loss: 2.4418792724609375
Validation loss: 2.361059893843948

Epoch: 5| Step: 7
Training loss: 2.951704502105713
Validation loss: 2.36752833602249

Epoch: 5| Step: 8
Training loss: 2.357182264328003
Validation loss: 2.3665364583333335

Epoch: 5| Step: 9
Training loss: 2.213245153427124
Validation loss: 2.3668837957484747

Epoch: 5| Step: 10
Training loss: 2.848146915435791
Validation loss: 2.3645913421466784

Epoch: 112| Step: 0
Training loss: 2.3320558071136475
Validation loss: 2.3650670410484396

Epoch: 5| Step: 1
Training loss: 2.7514026165008545
Validation loss: 2.366604934456528

Epoch: 5| Step: 2
Training loss: 2.2525744438171387
Validation loss: 2.365551607583159

Epoch: 5| Step: 3
Training loss: 3.031245470046997
Validation loss: 2.363770064487252

Epoch: 5| Step: 4
Training loss: 2.464168071746826
Validation loss: 2.3633718208600114

Epoch: 5| Step: 5
Training loss: 2.763719081878662
Validation loss: 2.3661813018142537

Epoch: 5| Step: 6
Training loss: 2.4353058338165283
Validation loss: 2.3566246314715316

Epoch: 5| Step: 7
Training loss: 3.0589568614959717
Validation loss: 2.355555852254232

Epoch: 5| Step: 8
Training loss: 2.9642558097839355
Validation loss: 2.345161748188798

Epoch: 5| Step: 9
Training loss: 1.7925513982772827
Validation loss: 2.348839183007517

Epoch: 5| Step: 10
Training loss: 2.789090633392334
Validation loss: 2.3557145159731627

Epoch: 113| Step: 0
Training loss: 2.479147434234619
Validation loss: 2.3612244513727005

Epoch: 5| Step: 1
Training loss: 2.3722705841064453
Validation loss: 2.3670013463625343

Epoch: 5| Step: 2
Training loss: 2.2420260906219482
Validation loss: 2.3667579158659904

Epoch: 5| Step: 3
Training loss: 2.398638963699341
Validation loss: 2.373646664363082

Epoch: 5| Step: 4
Training loss: 2.8810172080993652
Validation loss: 2.380161775055752

Epoch: 5| Step: 5
Training loss: 3.106311321258545
Validation loss: 2.388363525431643

Epoch: 5| Step: 6
Training loss: 2.069836378097534
Validation loss: 2.3974898912573375

Epoch: 5| Step: 7
Training loss: 2.894353151321411
Validation loss: 2.397434247437344

Epoch: 5| Step: 8
Training loss: 3.3605663776397705
Validation loss: 2.3849765152059574

Epoch: 5| Step: 9
Training loss: 2.2325072288513184
Validation loss: 2.391081307523994

Epoch: 5| Step: 10
Training loss: 2.5280563831329346
Validation loss: 2.388125237598214

Epoch: 114| Step: 0
Training loss: 2.641634464263916
Validation loss: 2.38628674322559

Epoch: 5| Step: 1
Training loss: 2.7722644805908203
Validation loss: 2.3954902900162565

Epoch: 5| Step: 2
Training loss: 2.837280750274658
Validation loss: 2.38153217428474

Epoch: 5| Step: 3
Training loss: 2.374878168106079
Validation loss: 2.386441566610849

Epoch: 5| Step: 4
Training loss: 2.2888450622558594
Validation loss: 2.373957949299966

Epoch: 5| Step: 5
Training loss: 2.428083896636963
Validation loss: 2.367995021163776

Epoch: 5| Step: 6
Training loss: 2.305361747741699
Validation loss: 2.3559134032136653

Epoch: 5| Step: 7
Training loss: 2.8993730545043945
Validation loss: 2.356820216742895

Epoch: 5| Step: 8
Training loss: 3.0142557621002197
Validation loss: 2.345910954219039

Epoch: 5| Step: 9
Training loss: 2.7338521480560303
Validation loss: 2.3427108885139547

Epoch: 5| Step: 10
Training loss: 2.089916944503784
Validation loss: 2.3459426613264185

Epoch: 115| Step: 0
Training loss: 3.0417566299438477
Validation loss: 2.3461287970184

Epoch: 5| Step: 1
Training loss: 2.6192469596862793
Validation loss: 2.344904033086633

Epoch: 5| Step: 2
Training loss: 2.3705010414123535
Validation loss: 2.344065304725401

Epoch: 5| Step: 3
Training loss: 2.8841552734375
Validation loss: 2.3457846308267243

Epoch: 5| Step: 4
Training loss: 3.1961779594421387
Validation loss: 2.345256564437702

Epoch: 5| Step: 5
Training loss: 2.344817876815796
Validation loss: 2.3491852283477783

Epoch: 5| Step: 6
Training loss: 2.1672332286834717
Validation loss: 2.3461087544759116

Epoch: 5| Step: 7
Training loss: 2.8123226165771484
Validation loss: 2.349242953843968

Epoch: 5| Step: 8
Training loss: 1.7447715997695923
Validation loss: 2.353381262030653

Epoch: 5| Step: 9
Training loss: 2.6360368728637695
Validation loss: 2.3529436357559694

Epoch: 5| Step: 10
Training loss: 2.7402963638305664
Validation loss: 2.3611082441063336

Epoch: 116| Step: 0
Training loss: 3.1794586181640625
Validation loss: 2.363322191340949

Epoch: 5| Step: 1
Training loss: 2.826150417327881
Validation loss: 2.3659821171914377

Epoch: 5| Step: 2
Training loss: 2.074582576751709
Validation loss: 2.3735123142119376

Epoch: 5| Step: 3
Training loss: 2.9009101390838623
Validation loss: 2.370311070513982

Epoch: 5| Step: 4
Training loss: 2.587510585784912
Validation loss: 2.368827353241623

Epoch: 5| Step: 5
Training loss: 2.7857038974761963
Validation loss: 2.3778601179840746

Epoch: 5| Step: 6
Training loss: 2.277641773223877
Validation loss: 2.3640101161054385

Epoch: 5| Step: 7
Training loss: 2.2102622985839844
Validation loss: 2.3704936940182924

Epoch: 5| Step: 8
Training loss: 3.1033997535705566
Validation loss: 2.3611004685842865

Epoch: 5| Step: 9
Training loss: 2.078925371170044
Validation loss: 2.358609612270068

Epoch: 5| Step: 10
Training loss: 2.336033821105957
Validation loss: 2.346208687751524

Epoch: 117| Step: 0
Training loss: 3.4035656452178955
Validation loss: 2.348147928073842

Epoch: 5| Step: 1
Training loss: 2.298973321914673
Validation loss: 2.34322476643388

Epoch: 5| Step: 2
Training loss: 2.121644973754883
Validation loss: 2.3448888153158207

Epoch: 5| Step: 3
Training loss: 3.1032886505126953
Validation loss: 2.3409934556612404

Epoch: 5| Step: 4
Training loss: 2.727567195892334
Validation loss: 2.342909515544932

Epoch: 5| Step: 5
Training loss: 2.554567813873291
Validation loss: 2.3444483075090634

Epoch: 5| Step: 6
Training loss: 2.468752861022949
Validation loss: 2.343410345815843

Epoch: 5| Step: 7
Training loss: 2.8617258071899414
Validation loss: 2.34467984784034

Epoch: 5| Step: 8
Training loss: 1.9732471704483032
Validation loss: 2.3411064173585627

Epoch: 5| Step: 9
Training loss: 2.1606688499450684
Validation loss: 2.34734441644402

Epoch: 5| Step: 10
Training loss: 2.86612606048584
Validation loss: 2.353594828677434

Epoch: 118| Step: 0
Training loss: 2.88264799118042
Validation loss: 2.3511876995845506

Epoch: 5| Step: 1
Training loss: 2.72560715675354
Validation loss: 2.368865338704919

Epoch: 5| Step: 2
Training loss: 1.7642581462860107
Validation loss: 2.376681209892355

Epoch: 5| Step: 3
Training loss: 2.1339762210845947
Validation loss: 2.396819814558952

Epoch: 5| Step: 4
Training loss: 1.8138141632080078
Validation loss: 2.3795172783636276

Epoch: 5| Step: 5
Training loss: 2.4318554401397705
Validation loss: 2.36368239566844

Epoch: 5| Step: 6
Training loss: 2.9256176948547363
Validation loss: 2.353699448288128

Epoch: 5| Step: 7
Training loss: 2.7725696563720703
Validation loss: 2.356697554229408

Epoch: 5| Step: 8
Training loss: 3.4713664054870605
Validation loss: 2.348039593747867

Epoch: 5| Step: 9
Training loss: 2.5669262409210205
Validation loss: 2.3453341735306608

Epoch: 5| Step: 10
Training loss: 2.921957015991211
Validation loss: 2.3467615035272416

Epoch: 119| Step: 0
Training loss: 2.2294235229492188
Validation loss: 2.343279251488306

Epoch: 5| Step: 1
Training loss: 2.742913007736206
Validation loss: 2.3416737574403004

Epoch: 5| Step: 2
Training loss: 2.5826480388641357
Validation loss: 2.348025946206944

Epoch: 5| Step: 3
Training loss: 2.6946167945861816
Validation loss: 2.349902868270874

Epoch: 5| Step: 4
Training loss: 2.7903666496276855
Validation loss: 2.3502569788245746

Epoch: 5| Step: 5
Training loss: 2.888762950897217
Validation loss: 2.3459353113687165

Epoch: 5| Step: 6
Training loss: 2.8595645427703857
Validation loss: 2.3468849684602473

Epoch: 5| Step: 7
Training loss: 2.299757719039917
Validation loss: 2.3510002859177126

Epoch: 5| Step: 8
Training loss: 2.818877696990967
Validation loss: 2.343851318923376

Epoch: 5| Step: 9
Training loss: 2.738255023956299
Validation loss: 2.342404703940115

Epoch: 5| Step: 10
Training loss: 1.7882946729660034
Validation loss: 2.3467939053812334

Epoch: 120| Step: 0
Training loss: 2.037208080291748
Validation loss: 2.3441768641112954

Epoch: 5| Step: 1
Training loss: 2.207775592803955
Validation loss: 2.3398019472757974

Epoch: 5| Step: 2
Training loss: 2.7305896282196045
Validation loss: 2.3385343192726054

Epoch: 5| Step: 3
Training loss: 2.8066325187683105
Validation loss: 2.3482628483926096

Epoch: 5| Step: 4
Training loss: 2.776219606399536
Validation loss: 2.344027001370666

Epoch: 5| Step: 5
Training loss: 2.8683435916900635
Validation loss: 2.3668327677634453

Epoch: 5| Step: 6
Training loss: 2.226931095123291
Validation loss: 2.364685978940738

Epoch: 5| Step: 7
Training loss: 2.241987705230713
Validation loss: 2.3785086037010275

Epoch: 5| Step: 8
Training loss: 2.595899820327759
Validation loss: 2.3775092453084965

Epoch: 5| Step: 9
Training loss: 2.9257657527923584
Validation loss: 2.377083865545129

Epoch: 5| Step: 10
Training loss: 2.9971187114715576
Validation loss: 2.3813986650077243

Epoch: 121| Step: 0
Training loss: 2.6900179386138916
Validation loss: 2.374656287572717

Epoch: 5| Step: 1
Training loss: 2.2931060791015625
Validation loss: 2.369290018594393

Epoch: 5| Step: 2
Training loss: 2.2793736457824707
Validation loss: 2.3580204004882486

Epoch: 5| Step: 3
Training loss: 2.164576292037964
Validation loss: 2.346683907252486

Epoch: 5| Step: 4
Training loss: 2.062591075897217
Validation loss: 2.3440705473705004

Epoch: 5| Step: 5
Training loss: 3.149977207183838
Validation loss: 2.3453412722515803

Epoch: 5| Step: 6
Training loss: 2.7245235443115234
Validation loss: 2.3440590545695317

Epoch: 5| Step: 7
Training loss: 2.938506841659546
Validation loss: 2.353185986959806

Epoch: 5| Step: 8
Training loss: 2.5831778049468994
Validation loss: 2.3470651334331882

Epoch: 5| Step: 9
Training loss: 2.5828521251678467
Validation loss: 2.359745838308847

Epoch: 5| Step: 10
Training loss: 2.9651260375976562
Validation loss: 2.3593082902252034

Epoch: 122| Step: 0
Training loss: 2.5499768257141113
Validation loss: 2.372283217727497

Epoch: 5| Step: 1
Training loss: 2.565964937210083
Validation loss: 2.375809374675956

Epoch: 5| Step: 2
Training loss: 2.782261371612549
Validation loss: 2.3705507042587444

Epoch: 5| Step: 3
Training loss: 2.4045522212982178
Validation loss: 2.3750069807934504

Epoch: 5| Step: 4
Training loss: 2.7361626625061035
Validation loss: 2.37190640869961

Epoch: 5| Step: 5
Training loss: 2.4311797618865967
Validation loss: 2.3808885620486353

Epoch: 5| Step: 6
Training loss: 2.8349766731262207
Validation loss: 2.3755502495714413

Epoch: 5| Step: 7
Training loss: 3.070161819458008
Validation loss: 2.3664819694334462

Epoch: 5| Step: 8
Training loss: 2.3148670196533203
Validation loss: 2.3610682384942168

Epoch: 5| Step: 9
Training loss: 2.2320995330810547
Validation loss: 2.346051380198489

Epoch: 5| Step: 10
Training loss: 2.5025510787963867
Validation loss: 2.342249588299823

Epoch: 123| Step: 0
Training loss: 2.9919049739837646
Validation loss: 2.3447199201071136

Epoch: 5| Step: 1
Training loss: 2.83793568611145
Validation loss: 2.3401973811529015

Epoch: 5| Step: 2
Training loss: 2.7985777854919434
Validation loss: 2.340129171648333

Epoch: 5| Step: 3
Training loss: 2.5747170448303223
Validation loss: 2.341493568112773

Epoch: 5| Step: 4
Training loss: 1.9765918254852295
Validation loss: 2.343460775190784

Epoch: 5| Step: 5
Training loss: 3.098527193069458
Validation loss: 2.3490668983869654

Epoch: 5| Step: 6
Training loss: 2.3640315532684326
Validation loss: 2.3454095240562194

Epoch: 5| Step: 7
Training loss: 2.7722327709198
Validation loss: 2.344696798632222

Epoch: 5| Step: 8
Training loss: 2.4966540336608887
Validation loss: 2.3455947035102436

Epoch: 5| Step: 9
Training loss: 2.564915418624878
Validation loss: 2.346355515141641

Epoch: 5| Step: 10
Training loss: 1.7674856185913086
Validation loss: 2.342926848319269

Epoch: 124| Step: 0
Training loss: 2.4759960174560547
Validation loss: 2.340228537077545

Epoch: 5| Step: 1
Training loss: 2.292133331298828
Validation loss: 2.3437935306179907

Epoch: 5| Step: 2
Training loss: 2.744105815887451
Validation loss: 2.3563861154740855

Epoch: 5| Step: 3
Training loss: 2.4651780128479004
Validation loss: 2.3641048964633735

Epoch: 5| Step: 4
Training loss: 3.1879563331604004
Validation loss: 2.3831234132089922

Epoch: 5| Step: 5
Training loss: 1.9890785217285156
Validation loss: 2.3826321799268007

Epoch: 5| Step: 6
Training loss: 2.765742540359497
Validation loss: 2.3842559604234594

Epoch: 5| Step: 7
Training loss: 2.081897735595703
Validation loss: 2.3866584788086596

Epoch: 5| Step: 8
Training loss: 2.918799877166748
Validation loss: 2.3821802985283638

Epoch: 5| Step: 9
Training loss: 2.5612170696258545
Validation loss: 2.3777573877765286

Epoch: 5| Step: 10
Training loss: 2.9142985343933105
Validation loss: 2.3767386456971527

Epoch: 125| Step: 0
Training loss: 2.7704296112060547
Validation loss: 2.3755819310424147

Epoch: 5| Step: 1
Training loss: 2.685704469680786
Validation loss: 2.3675723421958184

Epoch: 5| Step: 2
Training loss: 2.7976202964782715
Validation loss: 2.3768973555616153

Epoch: 5| Step: 3
Training loss: 2.280311107635498
Validation loss: 2.3658939766627487

Epoch: 5| Step: 4
Training loss: 2.835359573364258
Validation loss: 2.3581411889804307

Epoch: 5| Step: 5
Training loss: 3.1803736686706543
Validation loss: 2.3489133183674147

Epoch: 5| Step: 6
Training loss: 2.0732903480529785
Validation loss: 2.3543204710047734

Epoch: 5| Step: 7
Training loss: 2.553898572921753
Validation loss: 2.3508505052135837

Epoch: 5| Step: 8
Training loss: 2.376990795135498
Validation loss: 2.3429941182495444

Epoch: 5| Step: 9
Training loss: 2.830859661102295
Validation loss: 2.339171408325113

Epoch: 5| Step: 10
Training loss: 1.9739173650741577
Validation loss: 2.334633083753688

Epoch: 126| Step: 0
Training loss: 2.434582471847534
Validation loss: 2.3348681772908857

Epoch: 5| Step: 1
Training loss: 2.162691116333008
Validation loss: 2.3411617330325547

Epoch: 5| Step: 2
Training loss: 1.800115942955017
Validation loss: 2.347373511201592

Epoch: 5| Step: 3
Training loss: 2.731226682662964
Validation loss: 2.3577586630339264

Epoch: 5| Step: 4
Training loss: 2.8441715240478516
Validation loss: 2.365794304878481

Epoch: 5| Step: 5
Training loss: 3.10048246383667
Validation loss: 2.357561126832039

Epoch: 5| Step: 6
Training loss: 2.5973541736602783
Validation loss: 2.342769131865553

Epoch: 5| Step: 7
Training loss: 2.578572988510132
Validation loss: 2.337104005198325

Epoch: 5| Step: 8
Training loss: 2.7820231914520264
Validation loss: 2.329972308169129

Epoch: 5| Step: 9
Training loss: 2.440633773803711
Validation loss: 2.333118771993986

Epoch: 5| Step: 10
Training loss: 2.9700427055358887
Validation loss: 2.326455363663294

Epoch: 127| Step: 0
Training loss: 2.8310208320617676
Validation loss: 2.3309738610380437

Epoch: 5| Step: 1
Training loss: 2.4222092628479004
Validation loss: 2.3350184040684856

Epoch: 5| Step: 2
Training loss: 2.9857006072998047
Validation loss: 2.3382107493697957

Epoch: 5| Step: 3
Training loss: 2.093851089477539
Validation loss: 2.338685699688491

Epoch: 5| Step: 4
Training loss: 2.585190773010254
Validation loss: 2.339562467349473

Epoch: 5| Step: 5
Training loss: 2.41938853263855
Validation loss: 2.340183978439659

Epoch: 5| Step: 6
Training loss: 3.2176899909973145
Validation loss: 2.337275425593058

Epoch: 5| Step: 7
Training loss: 2.915639877319336
Validation loss: 2.3459786240772535

Epoch: 5| Step: 8
Training loss: 1.8472328186035156
Validation loss: 2.341554903214978

Epoch: 5| Step: 9
Training loss: 3.0088748931884766
Validation loss: 2.3375857209646576

Epoch: 5| Step: 10
Training loss: 1.7000397443771362
Validation loss: 2.3451118007782967

Epoch: 128| Step: 0
Training loss: 2.9330620765686035
Validation loss: 2.3511239918329383

Epoch: 5| Step: 1
Training loss: 2.3409945964813232
Validation loss: 2.354619469693912

Epoch: 5| Step: 2
Training loss: 2.0009570121765137
Validation loss: 2.3565641628798617

Epoch: 5| Step: 3
Training loss: 2.5819530487060547
Validation loss: 2.3730035392186974

Epoch: 5| Step: 4
Training loss: 2.7713537216186523
Validation loss: 2.358392271944272

Epoch: 5| Step: 5
Training loss: 2.511359691619873
Validation loss: 2.3617803588990243

Epoch: 5| Step: 6
Training loss: 2.9697303771972656
Validation loss: 2.343428957846857

Epoch: 5| Step: 7
Training loss: 2.2519583702087402
Validation loss: 2.3482387117160264

Epoch: 5| Step: 8
Training loss: 3.1924068927764893
Validation loss: 2.3516687718770837

Epoch: 5| Step: 9
Training loss: 2.1892621517181396
Validation loss: 2.344346293839075

Epoch: 5| Step: 10
Training loss: 2.450427293777466
Validation loss: 2.3405407987615114

Epoch: 129| Step: 0
Training loss: 2.3761050701141357
Validation loss: 2.3375577183179956

Epoch: 5| Step: 1
Training loss: 3.067927837371826
Validation loss: 2.3324583499662337

Epoch: 5| Step: 2
Training loss: 2.5595390796661377
Validation loss: 2.326734121127795

Epoch: 5| Step: 3
Training loss: 2.972888469696045
Validation loss: 2.3278200318736415

Epoch: 5| Step: 4
Training loss: 2.632455587387085
Validation loss: 2.3356537024180093

Epoch: 5| Step: 5
Training loss: 1.7964073419570923
Validation loss: 2.32926102863845

Epoch: 5| Step: 6
Training loss: 2.574280261993408
Validation loss: 2.3239715842790503

Epoch: 5| Step: 7
Training loss: 1.8469903469085693
Validation loss: 2.3321586193576938

Epoch: 5| Step: 8
Training loss: 2.9764046669006348
Validation loss: 2.3294219739975466

Epoch: 5| Step: 9
Training loss: 2.564697504043579
Validation loss: 2.334704127362979

Epoch: 5| Step: 10
Training loss: 2.92103910446167
Validation loss: 2.334729740696569

Epoch: 130| Step: 0
Training loss: 2.8725409507751465
Validation loss: 2.334348181242584

Epoch: 5| Step: 1
Training loss: 2.5574026107788086
Validation loss: 2.3295576546781804

Epoch: 5| Step: 2
Training loss: 2.633338451385498
Validation loss: 2.3276038118588027

Epoch: 5| Step: 3
Training loss: 2.335608720779419
Validation loss: 2.336098483813706

Epoch: 5| Step: 4
Training loss: 2.3743903636932373
Validation loss: 2.3313984845274236

Epoch: 5| Step: 5
Training loss: 3.1543707847595215
Validation loss: 2.340330313610774

Epoch: 5| Step: 6
Training loss: 2.78410005569458
Validation loss: 2.345967984968616

Epoch: 5| Step: 7
Training loss: 2.0568554401397705
Validation loss: 2.350030606792819

Epoch: 5| Step: 8
Training loss: 2.1755199432373047
Validation loss: 2.351931946251982

Epoch: 5| Step: 9
Training loss: 2.937670946121216
Validation loss: 2.3437875470807477

Epoch: 5| Step: 10
Training loss: 2.2356765270233154
Validation loss: 2.3461316067685365

Epoch: 131| Step: 0
Training loss: 2.8425815105438232
Validation loss: 2.3478363534455657

Epoch: 5| Step: 1
Training loss: 2.79801344871521
Validation loss: 2.341416928075975

Epoch: 5| Step: 2
Training loss: 2.492506265640259
Validation loss: 2.341033891964984

Epoch: 5| Step: 3
Training loss: 2.802530288696289
Validation loss: 2.321488998269522

Epoch: 5| Step: 4
Training loss: 2.614943265914917
Validation loss: 2.320857301835091

Epoch: 5| Step: 5
Training loss: 2.3068313598632812
Validation loss: 2.309823510467365

Epoch: 5| Step: 6
Training loss: 3.0626437664031982
Validation loss: 2.316828691831199

Epoch: 5| Step: 7
Training loss: 2.248722553253174
Validation loss: 2.3172280403875534

Epoch: 5| Step: 8
Training loss: 2.4015822410583496
Validation loss: 2.3152574287947787

Epoch: 5| Step: 9
Training loss: 2.345275402069092
Validation loss: 2.3134023194671958

Epoch: 5| Step: 10
Training loss: 2.3375773429870605
Validation loss: 2.3199548721313477

Epoch: 132| Step: 0
Training loss: 1.645728349685669
Validation loss: 2.317714075888357

Epoch: 5| Step: 1
Training loss: 2.186844825744629
Validation loss: 2.3184924317944433

Epoch: 5| Step: 2
Training loss: 2.867938995361328
Validation loss: 2.320531174700747

Epoch: 5| Step: 3
Training loss: 2.632228136062622
Validation loss: 2.3268411210788194

Epoch: 5| Step: 4
Training loss: 3.080894947052002
Validation loss: 2.3353031219974643

Epoch: 5| Step: 5
Training loss: 1.8146543502807617
Validation loss: 2.3450423056079495

Epoch: 5| Step: 6
Training loss: 2.5520036220550537
Validation loss: 2.355046010786487

Epoch: 5| Step: 7
Training loss: 3.1235241889953613
Validation loss: 2.3697195822192776

Epoch: 5| Step: 8
Training loss: 3.026186466217041
Validation loss: 2.367096156202337

Epoch: 5| Step: 9
Training loss: 2.3271288871765137
Validation loss: 2.3365581894433625

Epoch: 5| Step: 10
Training loss: 2.9646856784820557
Validation loss: 2.3462558818119827

Epoch: 133| Step: 0
Training loss: 1.9615967273712158
Validation loss: 2.338205063214866

Epoch: 5| Step: 1
Training loss: 2.1053664684295654
Validation loss: 2.344752473215903

Epoch: 5| Step: 2
Training loss: 2.8568408489227295
Validation loss: 2.3429807847545994

Epoch: 5| Step: 3
Training loss: 2.8332016468048096
Validation loss: 2.3343072232379707

Epoch: 5| Step: 4
Training loss: 2.5497264862060547
Validation loss: 2.3316609910739365

Epoch: 5| Step: 5
Training loss: 3.408020496368408
Validation loss: 2.3232832365138556

Epoch: 5| Step: 6
Training loss: 2.166724681854248
Validation loss: 2.3283229976572017

Epoch: 5| Step: 7
Training loss: 2.225564479827881
Validation loss: 2.320562211416101

Epoch: 5| Step: 8
Training loss: 3.0748651027679443
Validation loss: 2.325108592228223

Epoch: 5| Step: 9
Training loss: 2.6921589374542236
Validation loss: 2.321885501184771

Epoch: 5| Step: 10
Training loss: 2.16756272315979
Validation loss: 2.3216716422829577

Epoch: 134| Step: 0
Training loss: 2.033346652984619
Validation loss: 2.3201444290017568

Epoch: 5| Step: 1
Training loss: 1.9962890148162842
Validation loss: 2.3230896662640315

Epoch: 5| Step: 2
Training loss: 2.5542354583740234
Validation loss: 2.3240854560687976

Epoch: 5| Step: 3
Training loss: 2.8177084922790527
Validation loss: 2.3233833774443595

Epoch: 5| Step: 4
Training loss: 2.3771862983703613
Validation loss: 2.340826678019698

Epoch: 5| Step: 5
Training loss: 2.4120872020721436
Validation loss: 2.3384973028654694

Epoch: 5| Step: 6
Training loss: 2.8153343200683594
Validation loss: 2.3423996330589376

Epoch: 5| Step: 7
Training loss: 2.7043039798736572
Validation loss: 2.344624883385115

Epoch: 5| Step: 8
Training loss: 2.537628650665283
Validation loss: 2.3397183854092836

Epoch: 5| Step: 9
Training loss: 2.879349708557129
Validation loss: 2.330961355599024

Epoch: 5| Step: 10
Training loss: 3.118741989135742
Validation loss: 2.3231096472791446

Epoch: 135| Step: 0
Training loss: 2.6304526329040527
Validation loss: 2.328433267531856

Epoch: 5| Step: 1
Training loss: 2.6278300285339355
Validation loss: 2.3222776766746276

Epoch: 5| Step: 2
Training loss: 2.5106663703918457
Validation loss: 2.3234828364464546

Epoch: 5| Step: 3
Training loss: 2.293307304382324
Validation loss: 2.319552790734076

Epoch: 5| Step: 4
Training loss: 2.864999294281006
Validation loss: 2.323144330773302

Epoch: 5| Step: 5
Training loss: 2.2342143058776855
Validation loss: 2.315392768511208

Epoch: 5| Step: 6
Training loss: 2.8845462799072266
Validation loss: 2.316071189859862

Epoch: 5| Step: 7
Training loss: 2.5112814903259277
Validation loss: 2.3173664128908547

Epoch: 5| Step: 8
Training loss: 2.976909637451172
Validation loss: 2.309074837674377

Epoch: 5| Step: 9
Training loss: 1.8511230945587158
Validation loss: 2.3195380626186246

Epoch: 5| Step: 10
Training loss: 2.6509451866149902
Validation loss: 2.315536155495592

Epoch: 136| Step: 0
Training loss: 2.4343879222869873
Validation loss: 2.323909067338513

Epoch: 5| Step: 1
Training loss: 2.7338812351226807
Validation loss: 2.3293723752421718

Epoch: 5| Step: 2
Training loss: 2.6865882873535156
Validation loss: 2.337049827780775

Epoch: 5| Step: 3
Training loss: 2.4531514644622803
Validation loss: 2.3353107757465814

Epoch: 5| Step: 4
Training loss: 2.501671314239502
Validation loss: 2.3294521070295766

Epoch: 5| Step: 5
Training loss: 2.6370418071746826
Validation loss: 2.3246290273563837

Epoch: 5| Step: 6
Training loss: 2.5020480155944824
Validation loss: 2.3276290034735077

Epoch: 5| Step: 7
Training loss: 2.3812975883483887
Validation loss: 2.344261351452079

Epoch: 5| Step: 8
Training loss: 2.036182165145874
Validation loss: 2.348190869054487

Epoch: 5| Step: 9
Training loss: 2.5085906982421875
Validation loss: 2.345432468639907

Epoch: 5| Step: 10
Training loss: 3.4350929260253906
Validation loss: 2.3308178840144986

Epoch: 137| Step: 0
Training loss: 2.1556472778320312
Validation loss: 2.324163188216507

Epoch: 5| Step: 1
Training loss: 2.086257219314575
Validation loss: 2.312640191406332

Epoch: 5| Step: 2
Training loss: 2.596334934234619
Validation loss: 2.318321394663985

Epoch: 5| Step: 3
Training loss: 2.941884756088257
Validation loss: 2.320314279166601

Epoch: 5| Step: 4
Training loss: 2.899085521697998
Validation loss: 2.3221052256963586

Epoch: 5| Step: 5
Training loss: 2.061765193939209
Validation loss: 2.331937746335101

Epoch: 5| Step: 6
Training loss: 3.261735439300537
Validation loss: 2.3311200680271273

Epoch: 5| Step: 7
Training loss: 2.751906156539917
Validation loss: 2.3425647622795513

Epoch: 5| Step: 8
Training loss: 2.6051278114318848
Validation loss: 2.3383752581893757

Epoch: 5| Step: 9
Training loss: 2.577008008956909
Validation loss: 2.3112464438202562

Epoch: 5| Step: 10
Training loss: 2.112139940261841
Validation loss: 2.3172591194029777

Epoch: 138| Step: 0
Training loss: 2.328239917755127
Validation loss: 2.3105456675252607

Epoch: 5| Step: 1
Training loss: 2.640390396118164
Validation loss: 2.3086762505192913

Epoch: 5| Step: 2
Training loss: 2.618696928024292
Validation loss: 2.3111228968507502

Epoch: 5| Step: 3
Training loss: 2.7910304069519043
Validation loss: 2.3097784749923216

Epoch: 5| Step: 4
Training loss: 2.707559108734131
Validation loss: 2.315499013470065

Epoch: 5| Step: 5
Training loss: 2.6945300102233887
Validation loss: 2.3102851196001937

Epoch: 5| Step: 6
Training loss: 2.2859671115875244
Validation loss: 2.3136806949492423

Epoch: 5| Step: 7
Training loss: 2.456484079360962
Validation loss: 2.317688721482472

Epoch: 5| Step: 8
Training loss: 1.777191162109375
Validation loss: 2.3146920306708223

Epoch: 5| Step: 9
Training loss: 3.2455062866210938
Validation loss: 2.320248378220425

Epoch: 5| Step: 10
Training loss: 2.491090774536133
Validation loss: 2.315465109322661

Epoch: 139| Step: 0
Training loss: 2.842350482940674
Validation loss: 2.3249772646093882

Epoch: 5| Step: 1
Training loss: 2.4530482292175293
Validation loss: 2.3220213203019995

Epoch: 5| Step: 2
Training loss: 2.1551706790924072
Validation loss: 2.3233311842846613

Epoch: 5| Step: 3
Training loss: 3.1220333576202393
Validation loss: 2.321144908987066

Epoch: 5| Step: 4
Training loss: 2.7150917053222656
Validation loss: 2.3223928136210286

Epoch: 5| Step: 5
Training loss: 2.394134759902954
Validation loss: 2.319120637832149

Epoch: 5| Step: 6
Training loss: 2.3552346229553223
Validation loss: 2.31587484318723

Epoch: 5| Step: 7
Training loss: 2.7800800800323486
Validation loss: 2.31034948748927

Epoch: 5| Step: 8
Training loss: 2.921316146850586
Validation loss: 2.31459479947244

Epoch: 5| Step: 9
Training loss: 2.3110616207122803
Validation loss: 2.3245992532340427

Epoch: 5| Step: 10
Training loss: 1.8110216856002808
Validation loss: 2.3442796840462634

Epoch: 140| Step: 0
Training loss: 2.4853084087371826
Validation loss: 2.3692452881925847

Epoch: 5| Step: 1
Training loss: 2.953899621963501
Validation loss: 2.362772654461604

Epoch: 5| Step: 2
Training loss: 2.826019763946533
Validation loss: 2.3534429022060928

Epoch: 5| Step: 3
Training loss: 2.4270131587982178
Validation loss: 2.33372663938871

Epoch: 5| Step: 4
Training loss: 2.8218395709991455
Validation loss: 2.332436782057567

Epoch: 5| Step: 5
Training loss: 2.0893208980560303
Validation loss: 2.319516476764474

Epoch: 5| Step: 6
Training loss: 2.6474609375
Validation loss: 2.3211212158203125

Epoch: 5| Step: 7
Training loss: 2.5318188667297363
Validation loss: 2.3248086642193537

Epoch: 5| Step: 8
Training loss: 2.3619132041931152
Validation loss: 2.3305719103864444

Epoch: 5| Step: 9
Training loss: 2.2711904048919678
Validation loss: 2.323884117987848

Epoch: 5| Step: 10
Training loss: 2.8103978633880615
Validation loss: 2.327467485140729

Epoch: 141| Step: 0
Training loss: 2.2932934761047363
Validation loss: 2.32502850409477

Epoch: 5| Step: 1
Training loss: 2.157707691192627
Validation loss: 2.3291013599723898

Epoch: 5| Step: 2
Training loss: 2.20115327835083
Validation loss: 2.3307518420680875

Epoch: 5| Step: 3
Training loss: 3.431835889816284
Validation loss: 2.329312119432675

Epoch: 5| Step: 4
Training loss: 2.4075839519500732
Validation loss: 2.328767937998618

Epoch: 5| Step: 5
Training loss: 2.897351026535034
Validation loss: 2.3263799657103834

Epoch: 5| Step: 6
Training loss: 2.4805490970611572
Validation loss: 2.3197282668082946

Epoch: 5| Step: 7
Training loss: 2.878058671951294
Validation loss: 2.311034507648919

Epoch: 5| Step: 8
Training loss: 2.0535218715667725
Validation loss: 2.3073759617344027

Epoch: 5| Step: 9
Training loss: 3.000864028930664
Validation loss: 2.316553295299571

Epoch: 5| Step: 10
Training loss: 2.112100124359131
Validation loss: 2.31509062551683

Epoch: 142| Step: 0
Training loss: 2.282111406326294
Validation loss: 2.3197411721752537

Epoch: 5| Step: 1
Training loss: 3.441554546356201
Validation loss: 2.309407244446457

Epoch: 5| Step: 2
Training loss: 1.8437315225601196
Validation loss: 2.305887158199023

Epoch: 5| Step: 3
Training loss: 2.560537576675415
Validation loss: 2.3032833145510767

Epoch: 5| Step: 4
Training loss: 2.3950915336608887
Validation loss: 2.3101080181778118

Epoch: 5| Step: 5
Training loss: 2.2865257263183594
Validation loss: 2.307944256772277

Epoch: 5| Step: 6
Training loss: 2.703626871109009
Validation loss: 2.310779474114859

Epoch: 5| Step: 7
Training loss: 2.4629569053649902
Validation loss: 2.3131212906170915

Epoch: 5| Step: 8
Training loss: 2.999732494354248
Validation loss: 2.3136125687629945

Epoch: 5| Step: 9
Training loss: 2.2485432624816895
Validation loss: 2.3067155012520413

Epoch: 5| Step: 10
Training loss: 2.7538163661956787
Validation loss: 2.3136806026581795

Epoch: 143| Step: 0
Training loss: 2.655672550201416
Validation loss: 2.322613105979017

Epoch: 5| Step: 1
Training loss: 2.788872003555298
Validation loss: 2.3171390487301733

Epoch: 5| Step: 2
Training loss: 2.3365914821624756
Validation loss: 2.3228011464559906

Epoch: 5| Step: 3
Training loss: 2.173065423965454
Validation loss: 2.314121905193534

Epoch: 5| Step: 4
Training loss: 3.4830009937286377
Validation loss: 2.3272598071764876

Epoch: 5| Step: 5
Training loss: 2.099048137664795
Validation loss: 2.320481600299958

Epoch: 5| Step: 6
Training loss: 2.237717866897583
Validation loss: 2.3421905040740967

Epoch: 5| Step: 7
Training loss: 1.8038957118988037
Validation loss: 2.3327651408410843

Epoch: 5| Step: 8
Training loss: 2.339395046234131
Validation loss: 2.3298784725127684

Epoch: 5| Step: 9
Training loss: 2.9547336101531982
Validation loss: 2.3203572509109334

Epoch: 5| Step: 10
Training loss: 3.165395736694336
Validation loss: 2.3139424913672992

Epoch: 144| Step: 0
Training loss: 2.2886509895324707
Validation loss: 2.3071889954228557

Epoch: 5| Step: 1
Training loss: 2.4613914489746094
Validation loss: 2.303107238584949

Epoch: 5| Step: 2
Training loss: 2.043240547180176
Validation loss: 2.3042256088667017

Epoch: 5| Step: 3
Training loss: 2.351593017578125
Validation loss: 2.3026078054981847

Epoch: 5| Step: 4
Training loss: 3.2218737602233887
Validation loss: 2.30954308407281

Epoch: 5| Step: 5
Training loss: 2.7844951152801514
Validation loss: 2.297822653606374

Epoch: 5| Step: 6
Training loss: 2.788501262664795
Validation loss: 2.2946406666950514

Epoch: 5| Step: 7
Training loss: 2.1236391067504883
Validation loss: 2.2922480362717823

Epoch: 5| Step: 8
Training loss: 2.4124953746795654
Validation loss: 2.2915765085527973

Epoch: 5| Step: 9
Training loss: 2.3833088874816895
Validation loss: 2.289676207368092

Epoch: 5| Step: 10
Training loss: 3.2662267684936523
Validation loss: 2.2968620369511266

Epoch: 145| Step: 0
Training loss: 2.389425754547119
Validation loss: 2.3130397104447886

Epoch: 5| Step: 1
Training loss: 1.9846044778823853
Validation loss: 2.307474079952445

Epoch: 5| Step: 2
Training loss: 2.2700679302215576
Validation loss: 2.309677349623813

Epoch: 5| Step: 3
Training loss: 2.6814677715301514
Validation loss: 2.302298774001419

Epoch: 5| Step: 4
Training loss: 2.3825950622558594
Validation loss: 2.296592853402579

Epoch: 5| Step: 5
Training loss: 3.587608814239502
Validation loss: 2.299742511523667

Epoch: 5| Step: 6
Training loss: 2.450784206390381
Validation loss: 2.3049810637709913

Epoch: 5| Step: 7
Training loss: 2.89422607421875
Validation loss: 2.29998597791118

Epoch: 5| Step: 8
Training loss: 2.3500075340270996
Validation loss: 2.3038126973695654

Epoch: 5| Step: 9
Training loss: 3.02933931350708
Validation loss: 2.3054386056879514

Epoch: 5| Step: 10
Training loss: 1.8633527755737305
Validation loss: 2.30461948533212

Epoch: 146| Step: 0
Training loss: 3.115652561187744
Validation loss: 2.304947445469518

Epoch: 5| Step: 1
Training loss: 2.660114288330078
Validation loss: 2.3052240981850574

Epoch: 5| Step: 2
Training loss: 2.610983371734619
Validation loss: 2.3053695745365594

Epoch: 5| Step: 3
Training loss: 2.585444927215576
Validation loss: 2.2970176512195217

Epoch: 5| Step: 4
Training loss: 2.679239273071289
Validation loss: 2.2964983986270044

Epoch: 5| Step: 5
Training loss: 2.560546875
Validation loss: 2.301850926491522

Epoch: 5| Step: 6
Training loss: 2.635042428970337
Validation loss: 2.305437385395009

Epoch: 5| Step: 7
Training loss: 2.005946636199951
Validation loss: 2.3077622946872505

Epoch: 5| Step: 8
Training loss: 2.1882011890411377
Validation loss: 2.3046169550188127

Epoch: 5| Step: 9
Training loss: 2.676367998123169
Validation loss: 2.30100521990048

Epoch: 5| Step: 10
Training loss: 2.172725200653076
Validation loss: 2.3062716094396447

Epoch: 147| Step: 0
Training loss: 2.25114107131958
Validation loss: 2.2969539806406987

Epoch: 5| Step: 1
Training loss: 2.424288749694824
Validation loss: 2.307709555472097

Epoch: 5| Step: 2
Training loss: 2.3268136978149414
Validation loss: 2.3157968085299254

Epoch: 5| Step: 3
Training loss: 2.359973907470703
Validation loss: 2.3179306419946815

Epoch: 5| Step: 4
Training loss: 2.1632912158966064
Validation loss: 2.321948923090453

Epoch: 5| Step: 5
Training loss: 2.5842838287353516
Validation loss: 2.3246637159778225

Epoch: 5| Step: 6
Training loss: 2.2684550285339355
Validation loss: 2.3283767674558904

Epoch: 5| Step: 7
Training loss: 2.762730836868286
Validation loss: 2.334571966560938

Epoch: 5| Step: 8
Training loss: 3.20208477973938
Validation loss: 2.3320750010910856

Epoch: 5| Step: 9
Training loss: 2.8416709899902344
Validation loss: 2.3245648491767144

Epoch: 5| Step: 10
Training loss: 2.754213333129883
Validation loss: 2.311327511264432

Epoch: 148| Step: 0
Training loss: 2.2440555095672607
Validation loss: 2.3041744873087895

Epoch: 5| Step: 1
Training loss: 2.5336403846740723
Validation loss: 2.314657659940822

Epoch: 5| Step: 2
Training loss: 3.2113075256347656
Validation loss: 2.307557794355577

Epoch: 5| Step: 3
Training loss: 2.3605234622955322
Validation loss: 2.2954333213067826

Epoch: 5| Step: 4
Training loss: 2.2748990058898926
Validation loss: 2.293472379766485

Epoch: 5| Step: 5
Training loss: 2.92958402633667
Validation loss: 2.3032420527550483

Epoch: 5| Step: 6
Training loss: 2.8352341651916504
Validation loss: 2.299038871642082

Epoch: 5| Step: 7
Training loss: 2.028526782989502
Validation loss: 2.3073990601365284

Epoch: 5| Step: 8
Training loss: 2.541247606277466
Validation loss: 2.301358945908085

Epoch: 5| Step: 9
Training loss: 2.4917311668395996
Validation loss: 2.296931025802448

Epoch: 5| Step: 10
Training loss: 2.425290107727051
Validation loss: 2.3055009393281836

Epoch: 149| Step: 0
Training loss: 2.847820281982422
Validation loss: 2.3058384772269958

Epoch: 5| Step: 1
Training loss: 2.8513505458831787
Validation loss: 2.3026875142128236

Epoch: 5| Step: 2
Training loss: 1.9379253387451172
Validation loss: 2.302379018516951

Epoch: 5| Step: 3
Training loss: 2.061065912246704
Validation loss: 2.3015197246305403

Epoch: 5| Step: 4
Training loss: 2.4879071712493896
Validation loss: 2.3076669246919694

Epoch: 5| Step: 5
Training loss: 2.5351831912994385
Validation loss: 2.3045501068074215

Epoch: 5| Step: 6
Training loss: 2.6419730186462402
Validation loss: 2.3059053805566605

Epoch: 5| Step: 7
Training loss: 2.4363512992858887
Validation loss: 2.2985904216766357

Epoch: 5| Step: 8
Training loss: 2.870208263397217
Validation loss: 2.2951812180139686

Epoch: 5| Step: 9
Training loss: 2.5252292156219482
Validation loss: 2.284017757702899

Epoch: 5| Step: 10
Training loss: 2.5910987854003906
Validation loss: 2.2949273868273665

Epoch: 150| Step: 0
Training loss: 2.49122953414917
Validation loss: 2.289415610733853

Epoch: 5| Step: 1
Training loss: 1.9410526752471924
Validation loss: 2.285473600510628

Epoch: 5| Step: 2
Training loss: 2.4339072704315186
Validation loss: 2.2840305989788425

Epoch: 5| Step: 3
Training loss: 2.0782134532928467
Validation loss: 2.3014806419290523

Epoch: 5| Step: 4
Training loss: 2.29266357421875
Validation loss: 2.2887845065004084

Epoch: 5| Step: 5
Training loss: 2.625523090362549
Validation loss: 2.2974185302693355

Epoch: 5| Step: 6
Training loss: 3.0446295738220215
Validation loss: 2.3061778904289327

Epoch: 5| Step: 7
Training loss: 2.406233310699463
Validation loss: 2.3041438902578046

Epoch: 5| Step: 8
Training loss: 2.5343616008758545
Validation loss: 2.3153543292835193

Epoch: 5| Step: 9
Training loss: 3.437007188796997
Validation loss: 2.3140760570444088

Epoch: 5| Step: 10
Training loss: 2.5716941356658936
Validation loss: 2.305046964717168

Epoch: 151| Step: 0
Training loss: 1.867272973060608
Validation loss: 2.291065590355986

Epoch: 5| Step: 1
Training loss: 2.278794765472412
Validation loss: 2.2878732001909645

Epoch: 5| Step: 2
Training loss: 2.2551021575927734
Validation loss: 2.289369821548462

Epoch: 5| Step: 3
Training loss: 3.2626547813415527
Validation loss: 2.2965155519464964

Epoch: 5| Step: 4
Training loss: 2.557283401489258
Validation loss: 2.289137706961683

Epoch: 5| Step: 5
Training loss: 2.4386589527130127
Validation loss: 2.2925845166688323

Epoch: 5| Step: 6
Training loss: 2.1614432334899902
Validation loss: 2.2934469715241463

Epoch: 5| Step: 7
Training loss: 2.4768850803375244
Validation loss: 2.2870988999643633

Epoch: 5| Step: 8
Training loss: 2.5160813331604004
Validation loss: 2.2989175217126006

Epoch: 5| Step: 9
Training loss: 2.98968505859375
Validation loss: 2.297214359365484

Epoch: 5| Step: 10
Training loss: 3.046005964279175
Validation loss: 2.3006147530771073

Epoch: 152| Step: 0
Training loss: 2.6867458820343018
Validation loss: 2.3039343228904148

Epoch: 5| Step: 1
Training loss: 2.561603546142578
Validation loss: 2.3148432303500432

Epoch: 5| Step: 2
Training loss: 1.8056659698486328
Validation loss: 2.3130556844895884

Epoch: 5| Step: 3
Training loss: 2.315782308578491
Validation loss: 2.3120827649229314

Epoch: 5| Step: 4
Training loss: 2.36043119430542
Validation loss: 2.316262165705363

Epoch: 5| Step: 5
Training loss: 2.3561813831329346
Validation loss: 2.3095554100569857

Epoch: 5| Step: 6
Training loss: 3.216444492340088
Validation loss: 2.324675461297394

Epoch: 5| Step: 7
Training loss: 2.2280707359313965
Validation loss: 2.3082480174238964

Epoch: 5| Step: 8
Training loss: 3.0378036499023438
Validation loss: 2.2935893509977605

Epoch: 5| Step: 9
Training loss: 2.295459508895874
Validation loss: 2.288481097067556

Epoch: 5| Step: 10
Training loss: 2.9520792961120605
Validation loss: 2.286175166406939

Epoch: 153| Step: 0
Training loss: 2.9360175132751465
Validation loss: 2.283025800540883

Epoch: 5| Step: 1
Training loss: 2.281338691711426
Validation loss: 2.287744681040446

Epoch: 5| Step: 2
Training loss: 1.949886679649353
Validation loss: 2.284800139806604

Epoch: 5| Step: 3
Training loss: 2.473224639892578
Validation loss: 2.292251963769236

Epoch: 5| Step: 4
Training loss: 2.1983585357666016
Validation loss: 2.294988311747069

Epoch: 5| Step: 5
Training loss: 2.535724639892578
Validation loss: 2.2866628554559525

Epoch: 5| Step: 6
Training loss: 2.4156651496887207
Validation loss: 2.2864293898305585

Epoch: 5| Step: 7
Training loss: 2.5526819229125977
Validation loss: 2.2854650430781867

Epoch: 5| Step: 8
Training loss: 2.764916181564331
Validation loss: 2.2841489673942648

Epoch: 5| Step: 9
Training loss: 2.83854603767395
Validation loss: 2.2880583681086057

Epoch: 5| Step: 10
Training loss: 2.9478955268859863
Validation loss: 2.288439352025268

Epoch: 154| Step: 0
Training loss: 2.59591007232666
Validation loss: 2.29631450868422

Epoch: 5| Step: 1
Training loss: 2.512087345123291
Validation loss: 2.278744552725105

Epoch: 5| Step: 2
Training loss: 2.525496006011963
Validation loss: 2.2912000968892086

Epoch: 5| Step: 3
Training loss: 2.607290267944336
Validation loss: 2.2825758175183366

Epoch: 5| Step: 4
Training loss: 2.8017172813415527
Validation loss: 2.2708833320166475

Epoch: 5| Step: 5
Training loss: 2.6509451866149902
Validation loss: 2.2624487005254275

Epoch: 5| Step: 6
Training loss: 2.611823320388794
Validation loss: 2.2539180350560013

Epoch: 5| Step: 7
Training loss: 2.1086747646331787
Validation loss: 2.2643703914457753

Epoch: 5| Step: 8
Training loss: 2.648205518722534
Validation loss: 2.2590307702300367

Epoch: 5| Step: 9
Training loss: 2.7800629138946533
Validation loss: 2.255060798378401

Epoch: 5| Step: 10
Training loss: 1.9912679195404053
Validation loss: 2.260720109426847

Epoch: 155| Step: 0
Training loss: 2.408066987991333
Validation loss: 2.2709569841302852

Epoch: 5| Step: 1
Training loss: 2.8275809288024902
Validation loss: 2.2718349887478735

Epoch: 5| Step: 2
Training loss: 2.5976767539978027
Validation loss: 2.278286933898926

Epoch: 5| Step: 3
Training loss: 2.9513654708862305
Validation loss: 2.2920362193097352

Epoch: 5| Step: 4
Training loss: 2.315412998199463
Validation loss: 2.2843552763744066

Epoch: 5| Step: 5
Training loss: 2.4238123893737793
Validation loss: 2.2876890654204995

Epoch: 5| Step: 6
Training loss: 2.3278815746307373
Validation loss: 2.2742385120802027

Epoch: 5| Step: 7
Training loss: 2.3497931957244873
Validation loss: 2.266748812890822

Epoch: 5| Step: 8
Training loss: 2.739340305328369
Validation loss: 2.261255351446008

Epoch: 5| Step: 9
Training loss: 2.296337366104126
Validation loss: 2.2545309579500588

Epoch: 5| Step: 10
Training loss: 2.545180559158325
Validation loss: 2.2499142128934144

Epoch: 156| Step: 0
Training loss: 2.8334760665893555
Validation loss: 2.2517838836998068

Epoch: 5| Step: 1
Training loss: 2.6598992347717285
Validation loss: 2.2503669056841122

Epoch: 5| Step: 2
Training loss: 2.652364492416382
Validation loss: 2.25176574337867

Epoch: 5| Step: 3
Training loss: 2.387411594390869
Validation loss: 2.2530135236760622

Epoch: 5| Step: 4
Training loss: 3.112996816635132
Validation loss: 2.260112964978782

Epoch: 5| Step: 5
Training loss: 2.4590837955474854
Validation loss: 2.2546664155939573

Epoch: 5| Step: 6
Training loss: 2.9979355335235596
Validation loss: 2.2561029567513415

Epoch: 5| Step: 7
Training loss: 1.9110186100006104
Validation loss: 2.25680193080697

Epoch: 5| Step: 8
Training loss: 2.295142412185669
Validation loss: 2.259938975816132

Epoch: 5| Step: 9
Training loss: 2.17881441116333
Validation loss: 2.2632527556470645

Epoch: 5| Step: 10
Training loss: 2.0883610248565674
Validation loss: 2.262165954036097

Epoch: 157| Step: 0
Training loss: 2.841053009033203
Validation loss: 2.2655546652373446

Epoch: 5| Step: 1
Training loss: 1.9975439310073853
Validation loss: 2.2751398214729885

Epoch: 5| Step: 2
Training loss: 2.580082654953003
Validation loss: 2.2790060504790275

Epoch: 5| Step: 3
Training loss: 2.4239134788513184
Validation loss: 2.2728589465541225

Epoch: 5| Step: 4
Training loss: 2.530273914337158
Validation loss: 2.2802052074863064

Epoch: 5| Step: 5
Training loss: 2.1788113117218018
Validation loss: 2.2832336759054535

Epoch: 5| Step: 6
Training loss: 2.7323288917541504
Validation loss: 2.2747150518560924

Epoch: 5| Step: 7
Training loss: 2.1986372470855713
Validation loss: 2.2751862874595066

Epoch: 5| Step: 8
Training loss: 2.768749713897705
Validation loss: 2.2760333373982418

Epoch: 5| Step: 9
Training loss: 2.72086501121521
Validation loss: 2.2804396306314776

Epoch: 5| Step: 10
Training loss: 2.750288963317871
Validation loss: 2.2836605425803893

Epoch: 158| Step: 0
Training loss: 2.634453058242798
Validation loss: 2.282409515432132

Epoch: 5| Step: 1
Training loss: 1.9155086278915405
Validation loss: 2.2659814896122104

Epoch: 5| Step: 2
Training loss: 2.325075387954712
Validation loss: 2.248755088416479

Epoch: 5| Step: 3
Training loss: 2.0111255645751953
Validation loss: 2.238525095806327

Epoch: 5| Step: 4
Training loss: 2.3732731342315674
Validation loss: 2.2430492601087018

Epoch: 5| Step: 5
Training loss: 2.9279723167419434
Validation loss: 2.2449457158324537

Epoch: 5| Step: 6
Training loss: 2.200273036956787
Validation loss: 2.2489678936619915

Epoch: 5| Step: 7
Training loss: 2.6559646129608154
Validation loss: 2.2507054895483036

Epoch: 5| Step: 8
Training loss: 3.293940782546997
Validation loss: 2.2546571813603884

Epoch: 5| Step: 9
Training loss: 2.753934383392334
Validation loss: 2.2558688079157183

Epoch: 5| Step: 10
Training loss: 2.5209336280822754
Validation loss: 2.262397430276358

Epoch: 159| Step: 0
Training loss: 2.743706464767456
Validation loss: 2.2651095108319352

Epoch: 5| Step: 1
Training loss: 1.9992866516113281
Validation loss: 2.259537435347034

Epoch: 5| Step: 2
Training loss: 1.785133719444275
Validation loss: 2.269145281084122

Epoch: 5| Step: 3
Training loss: 2.926692008972168
Validation loss: 2.2608000386145806

Epoch: 5| Step: 4
Training loss: 2.126108407974243
Validation loss: 2.267633097146147

Epoch: 5| Step: 5
Training loss: 3.0181853771209717
Validation loss: 2.2681280207890335

Epoch: 5| Step: 6
Training loss: 2.7236123085021973
Validation loss: 2.263918161392212

Epoch: 5| Step: 7
Training loss: 2.681180238723755
Validation loss: 2.257853320849839

Epoch: 5| Step: 8
Training loss: 2.440084457397461
Validation loss: 2.2565839470073743

Epoch: 5| Step: 9
Training loss: 2.568469285964966
Validation loss: 2.2546557585398355

Epoch: 5| Step: 10
Training loss: 2.4406652450561523
Validation loss: 2.246440815669234

Epoch: 160| Step: 0
Training loss: 2.337171792984009
Validation loss: 2.243131158172443

Epoch: 5| Step: 1
Training loss: 3.139519453048706
Validation loss: 2.247611617529264

Epoch: 5| Step: 2
Training loss: 2.2108981609344482
Validation loss: 2.2461569616871495

Epoch: 5| Step: 3
Training loss: 2.2409467697143555
Validation loss: 2.248827072881883

Epoch: 5| Step: 4
Training loss: 2.550877332687378
Validation loss: 2.253998576953847

Epoch: 5| Step: 5
Training loss: 2.1114323139190674
Validation loss: 2.247300153137535

Epoch: 5| Step: 6
Training loss: 2.4567322731018066
Validation loss: 2.249946487847195

Epoch: 5| Step: 7
Training loss: 2.9241223335266113
Validation loss: 2.2412994907748316

Epoch: 5| Step: 8
Training loss: 2.544456958770752
Validation loss: 2.2424991489738546

Epoch: 5| Step: 9
Training loss: 2.6862738132476807
Validation loss: 2.243388488728513

Epoch: 5| Step: 10
Training loss: 2.221593141555786
Validation loss: 2.2412806531434417

Epoch: 161| Step: 0
Training loss: 2.1304125785827637
Validation loss: 2.255512615685822

Epoch: 5| Step: 1
Training loss: 2.4400460720062256
Validation loss: 2.2613810980191795

Epoch: 5| Step: 2
Training loss: 2.740889310836792
Validation loss: 2.2680161922208724

Epoch: 5| Step: 3
Training loss: 2.85202956199646
Validation loss: 2.2636356507578204

Epoch: 5| Step: 4
Training loss: 2.5500543117523193
Validation loss: 2.266314850058607

Epoch: 5| Step: 5
Training loss: 1.544163465499878
Validation loss: 2.2621563480746363

Epoch: 5| Step: 6
Training loss: 3.202035427093506
Validation loss: 2.257756126824246

Epoch: 5| Step: 7
Training loss: 2.0957329273223877
Validation loss: 2.276709992398498

Epoch: 5| Step: 8
Training loss: 2.6566531658172607
Validation loss: 2.2620027219095538

Epoch: 5| Step: 9
Training loss: 2.729266405105591
Validation loss: 2.2779459748216855

Epoch: 5| Step: 10
Training loss: 2.512693405151367
Validation loss: 2.268460435252036

Epoch: 162| Step: 0
Training loss: 2.148413896560669
Validation loss: 2.262222220820765

Epoch: 5| Step: 1
Training loss: 2.355644941329956
Validation loss: 2.2574326453670377

Epoch: 5| Step: 2
Training loss: 2.434103488922119
Validation loss: 2.258101322317636

Epoch: 5| Step: 3
Training loss: 3.1350324153900146
Validation loss: 2.2554950585929294

Epoch: 5| Step: 4
Training loss: 2.362562656402588
Validation loss: 2.2487913639314714

Epoch: 5| Step: 5
Training loss: 2.1223368644714355
Validation loss: 2.249125554997434

Epoch: 5| Step: 6
Training loss: 2.124135732650757
Validation loss: 2.2435370491396998

Epoch: 5| Step: 7
Training loss: 2.427974224090576
Validation loss: 2.2537916462908507

Epoch: 5| Step: 8
Training loss: 2.3857579231262207
Validation loss: 2.270250379398305

Epoch: 5| Step: 9
Training loss: 2.9467337131500244
Validation loss: 2.272528863722278

Epoch: 5| Step: 10
Training loss: 3.120208978652954
Validation loss: 2.2862496799038303

Epoch: 163| Step: 0
Training loss: 2.396869659423828
Validation loss: 2.30447881965227

Epoch: 5| Step: 1
Training loss: 2.2494239807128906
Validation loss: 2.296081601932485

Epoch: 5| Step: 2
Training loss: 2.700869083404541
Validation loss: 2.303211840250159

Epoch: 5| Step: 3
Training loss: 2.3194022178649902
Validation loss: 2.30997218367874

Epoch: 5| Step: 4
Training loss: 2.7706596851348877
Validation loss: 2.289943748904813

Epoch: 5| Step: 5
Training loss: 2.1236071586608887
Validation loss: 2.281790553882558

Epoch: 5| Step: 6
Training loss: 2.213792085647583
Validation loss: 2.2860740474475327

Epoch: 5| Step: 7
Training loss: 3.072909116744995
Validation loss: 2.2781506943446335

Epoch: 5| Step: 8
Training loss: 2.7719132900238037
Validation loss: 2.268985932873141

Epoch: 5| Step: 9
Training loss: 2.5460004806518555
Validation loss: 2.2574904887906966

Epoch: 5| Step: 10
Training loss: 2.424490451812744
Validation loss: 2.2666962274941067

Epoch: 164| Step: 0
Training loss: 2.7154674530029297
Validation loss: 2.264700514014049

Epoch: 5| Step: 1
Training loss: 2.179399013519287
Validation loss: 2.2604146439542054

Epoch: 5| Step: 2
Training loss: 2.9296298027038574
Validation loss: 2.254899501800537

Epoch: 5| Step: 3
Training loss: 3.3024401664733887
Validation loss: 2.2532310050020934

Epoch: 5| Step: 4
Training loss: 2.525540590286255
Validation loss: 2.2499407414467103

Epoch: 5| Step: 5
Training loss: 2.123465061187744
Validation loss: 2.254400343023321

Epoch: 5| Step: 6
Training loss: 2.287506341934204
Validation loss: 2.2567816524095434

Epoch: 5| Step: 7
Training loss: 2.4994938373565674
Validation loss: 2.251659095928233

Epoch: 5| Step: 8
Training loss: 2.0461137294769287
Validation loss: 2.273654296833982

Epoch: 5| Step: 9
Training loss: 2.3332841396331787
Validation loss: 2.2760404438100834

Epoch: 5| Step: 10
Training loss: 2.6357028484344482
Validation loss: 2.2784339920167

Epoch: 165| Step: 0
Training loss: 2.3539958000183105
Validation loss: 2.28492711692728

Epoch: 5| Step: 1
Training loss: 2.4864373207092285
Validation loss: 2.2868293536606656

Epoch: 5| Step: 2
Training loss: 2.9893834590911865
Validation loss: 2.284205480288434

Epoch: 5| Step: 3
Training loss: 2.141866445541382
Validation loss: 2.2731910585075297

Epoch: 5| Step: 4
Training loss: 2.683901309967041
Validation loss: 2.2667787100679133

Epoch: 5| Step: 5
Training loss: 2.0144193172454834
Validation loss: 2.2591298703224427

Epoch: 5| Step: 6
Training loss: 2.1581368446350098
Validation loss: 2.263198926884641

Epoch: 5| Step: 7
Training loss: 2.415372133255005
Validation loss: 2.2531667922132756

Epoch: 5| Step: 8
Training loss: 2.5339417457580566
Validation loss: 2.2600965884424027

Epoch: 5| Step: 9
Training loss: 2.5331673622131348
Validation loss: 2.2675566391278337

Epoch: 5| Step: 10
Training loss: 3.232600450515747
Validation loss: 2.268304568465038

Epoch: 166| Step: 0
Training loss: 2.57645845413208
Validation loss: 2.2641669960432154

Epoch: 5| Step: 1
Training loss: 2.7126855850219727
Validation loss: 2.258509084742556

Epoch: 5| Step: 2
Training loss: 2.839648962020874
Validation loss: 2.2557818069252917

Epoch: 5| Step: 3
Training loss: 2.622776508331299
Validation loss: 2.259675173349278

Epoch: 5| Step: 4
Training loss: 2.187004327774048
Validation loss: 2.2368500309605754

Epoch: 5| Step: 5
Training loss: 2.824453830718994
Validation loss: 2.2287513850837626

Epoch: 5| Step: 6
Training loss: 2.0234439373016357
Validation loss: 2.226355162999963

Epoch: 5| Step: 7
Training loss: 2.8697681427001953
Validation loss: 2.2242673340664116

Epoch: 5| Step: 8
Training loss: 2.481269359588623
Validation loss: 2.2348161051350255

Epoch: 5| Step: 9
Training loss: 2.417052745819092
Validation loss: 2.23508164446841

Epoch: 5| Step: 10
Training loss: 1.8273954391479492
Validation loss: 2.244488516161519

Epoch: 167| Step: 0
Training loss: 2.4905142784118652
Validation loss: 2.2457170845359884

Epoch: 5| Step: 1
Training loss: 3.192209243774414
Validation loss: 2.247450392733338

Epoch: 5| Step: 2
Training loss: 2.6488194465637207
Validation loss: 2.2532184021447295

Epoch: 5| Step: 3
Training loss: 2.087691068649292
Validation loss: 2.245796136958625

Epoch: 5| Step: 4
Training loss: 2.601763963699341
Validation loss: 2.243024851686211

Epoch: 5| Step: 5
Training loss: 2.445214033126831
Validation loss: 2.2453501762882357

Epoch: 5| Step: 6
Training loss: 2.2696621417999268
Validation loss: 2.2435981124959965

Epoch: 5| Step: 7
Training loss: 2.7682454586029053
Validation loss: 2.2446331554843533

Epoch: 5| Step: 8
Training loss: 2.770346164703369
Validation loss: 2.2381058790350474

Epoch: 5| Step: 9
Training loss: 2.1485726833343506
Validation loss: 2.251838631527398

Epoch: 5| Step: 10
Training loss: 1.9468073844909668
Validation loss: 2.2567312653346727

Epoch: 168| Step: 0
Training loss: 2.5217952728271484
Validation loss: 2.2487989856350805

Epoch: 5| Step: 1
Training loss: 2.9380054473876953
Validation loss: 2.2510400715694634

Epoch: 5| Step: 2
Training loss: 2.1826581954956055
Validation loss: 2.244109181947606

Epoch: 5| Step: 3
Training loss: 2.952350378036499
Validation loss: 2.243881451186313

Epoch: 5| Step: 4
Training loss: 2.0584981441497803
Validation loss: 2.2459819009227138

Epoch: 5| Step: 5
Training loss: 2.410827398300171
Validation loss: 2.2502558385172198

Epoch: 5| Step: 6
Training loss: 2.7847132682800293
Validation loss: 2.255551843233006

Epoch: 5| Step: 7
Training loss: 2.382960796356201
Validation loss: 2.2564837599313385

Epoch: 5| Step: 8
Training loss: 2.4221901893615723
Validation loss: 2.2631686656705794

Epoch: 5| Step: 9
Training loss: 2.7407584190368652
Validation loss: 2.2570742535334762

Epoch: 5| Step: 10
Training loss: 1.9147781133651733
Validation loss: 2.2670797891514276

Epoch: 169| Step: 0
Training loss: 2.1723484992980957
Validation loss: 2.2644939268788984

Epoch: 5| Step: 1
Training loss: 1.761707067489624
Validation loss: 2.2482818813734156

Epoch: 5| Step: 2
Training loss: 2.9740395545959473
Validation loss: 2.2393300866567962

Epoch: 5| Step: 3
Training loss: 2.137840747833252
Validation loss: 2.2299784306556947

Epoch: 5| Step: 4
Training loss: 2.657240390777588
Validation loss: 2.2324026784589215

Epoch: 5| Step: 5
Training loss: 2.3460965156555176
Validation loss: 2.2307955795718777

Epoch: 5| Step: 6
Training loss: 2.9184305667877197
Validation loss: 2.2249751398640294

Epoch: 5| Step: 7
Training loss: 2.5772864818573
Validation loss: 2.2281755042332474

Epoch: 5| Step: 8
Training loss: 2.718299150466919
Validation loss: 2.22586682791351

Epoch: 5| Step: 9
Training loss: 2.8812217712402344
Validation loss: 2.2323264229682183

Epoch: 5| Step: 10
Training loss: 2.164978265762329
Validation loss: 2.2279553105754237

Epoch: 170| Step: 0
Training loss: 2.0000483989715576
Validation loss: 2.227930575288752

Epoch: 5| Step: 1
Training loss: 2.5328469276428223
Validation loss: 2.233924432467389

Epoch: 5| Step: 2
Training loss: 2.6263251304626465
Validation loss: 2.2229338025534027

Epoch: 5| Step: 3
Training loss: 2.533339023590088
Validation loss: 2.2314963904760217

Epoch: 5| Step: 4
Training loss: 2.504624605178833
Validation loss: 2.2271966254839333

Epoch: 5| Step: 5
Training loss: 2.2395784854888916
Validation loss: 2.233740493815432

Epoch: 5| Step: 6
Training loss: 2.7640161514282227
Validation loss: 2.235974642538255

Epoch: 5| Step: 7
Training loss: 2.4234955310821533
Validation loss: 2.2431891169599307

Epoch: 5| Step: 8
Training loss: 2.3814988136291504
Validation loss: 2.255018344489477

Epoch: 5| Step: 9
Training loss: 2.323746919631958
Validation loss: 2.2471906715823757

Epoch: 5| Step: 10
Training loss: 3.0008962154388428
Validation loss: 2.2531920607371996

Epoch: 171| Step: 0
Training loss: 2.2454142570495605
Validation loss: 2.258052231163107

Epoch: 5| Step: 1
Training loss: 2.805846691131592
Validation loss: 2.2539447687005483

Epoch: 5| Step: 2
Training loss: 2.6344099044799805
Validation loss: 2.259256560315368

Epoch: 5| Step: 3
Training loss: 2.778916597366333
Validation loss: 2.2612017175202728

Epoch: 5| Step: 4
Training loss: 2.290806293487549
Validation loss: 2.2553158421670236

Epoch: 5| Step: 5
Training loss: 2.7476227283477783
Validation loss: 2.244705246340844

Epoch: 5| Step: 6
Training loss: 2.191068172454834
Validation loss: 2.249103899924986

Epoch: 5| Step: 7
Training loss: 1.8066184520721436
Validation loss: 2.2647314558746996

Epoch: 5| Step: 8
Training loss: 2.4719157218933105
Validation loss: 2.248583770567371

Epoch: 5| Step: 9
Training loss: 2.819472551345825
Validation loss: 2.2511064211527505

Epoch: 5| Step: 10
Training loss: 2.51954984664917
Validation loss: 2.2596624589735463

Epoch: 172| Step: 0
Training loss: 2.2447032928466797
Validation loss: 2.254258685214545

Epoch: 5| Step: 1
Training loss: 2.6190505027770996
Validation loss: 2.2705342231258268

Epoch: 5| Step: 2
Training loss: 2.212390899658203
Validation loss: 2.2710709494929158

Epoch: 5| Step: 3
Training loss: 2.2075209617614746
Validation loss: 2.278565206835347

Epoch: 5| Step: 4
Training loss: 2.4516713619232178
Validation loss: 2.2774619748515468

Epoch: 5| Step: 5
Training loss: 2.542820453643799
Validation loss: 2.282698090358447

Epoch: 5| Step: 6
Training loss: 2.1905112266540527
Validation loss: 2.283152831498013

Epoch: 5| Step: 7
Training loss: 3.320558547973633
Validation loss: 2.2856757487020185

Epoch: 5| Step: 8
Training loss: 3.0925707817077637
Validation loss: 2.273986397251006

Epoch: 5| Step: 9
Training loss: 2.6934313774108887
Validation loss: 2.2521862624793925

Epoch: 5| Step: 10
Training loss: 1.6704704761505127
Validation loss: 2.246734029503279

Epoch: 173| Step: 0
Training loss: 1.8260457515716553
Validation loss: 2.2295577154364636

Epoch: 5| Step: 1
Training loss: 2.0047788619995117
Validation loss: 2.2347014334893998

Epoch: 5| Step: 2
Training loss: 2.1677849292755127
Validation loss: 2.2361686332251436

Epoch: 5| Step: 3
Training loss: 2.665966272354126
Validation loss: 2.2370104020641697

Epoch: 5| Step: 4
Training loss: 2.797048568725586
Validation loss: 2.2285554921755226

Epoch: 5| Step: 5
Training loss: 2.888361692428589
Validation loss: 2.2383020026709444

Epoch: 5| Step: 6
Training loss: 2.477975606918335
Validation loss: 2.238631293337832

Epoch: 5| Step: 7
Training loss: 2.069801092147827
Validation loss: 2.2370540301005044

Epoch: 5| Step: 8
Training loss: 2.862597703933716
Validation loss: 2.2436118433552403

Epoch: 5| Step: 9
Training loss: 2.4805779457092285
Validation loss: 2.249090128047492

Epoch: 5| Step: 10
Training loss: 3.030709743499756
Validation loss: 2.250206532016877

Epoch: 174| Step: 0
Training loss: 3.462233066558838
Validation loss: 2.247196771765268

Epoch: 5| Step: 1
Training loss: 2.4939680099487305
Validation loss: 2.247840381437732

Epoch: 5| Step: 2
Training loss: 2.8120641708374023
Validation loss: 2.2455432979009484

Epoch: 5| Step: 3
Training loss: 2.065319538116455
Validation loss: 2.228078947272352

Epoch: 5| Step: 4
Training loss: 2.1766574382781982
Validation loss: 2.2060026276496147

Epoch: 5| Step: 5
Training loss: 1.8803991079330444
Validation loss: 2.207440690327716

Epoch: 5| Step: 6
Training loss: 2.4688162803649902
Validation loss: 2.205590635217646

Epoch: 5| Step: 7
Training loss: 2.4927663803100586
Validation loss: 2.209890132309288

Epoch: 5| Step: 8
Training loss: 2.331325054168701
Validation loss: 2.213329161367109

Epoch: 5| Step: 9
Training loss: 2.5111560821533203
Validation loss: 2.224261740202545

Epoch: 5| Step: 10
Training loss: 2.844522476196289
Validation loss: 2.2311278363709808

Epoch: 175| Step: 0
Training loss: 2.4694206714630127
Validation loss: 2.234218733285063

Epoch: 5| Step: 1
Training loss: 3.043858051300049
Validation loss: 2.2475707607884563

Epoch: 5| Step: 2
Training loss: 2.4489855766296387
Validation loss: 2.252190725777739

Epoch: 5| Step: 3
Training loss: 2.534071207046509
Validation loss: 2.2581927648154636

Epoch: 5| Step: 4
Training loss: 2.2972588539123535
Validation loss: 2.255161213618453

Epoch: 5| Step: 5
Training loss: 3.249934673309326
Validation loss: 2.2594529146789224

Epoch: 5| Step: 6
Training loss: 2.088164806365967
Validation loss: 2.2504766089941866

Epoch: 5| Step: 7
Training loss: 2.0045337677001953
Validation loss: 2.253824728791432

Epoch: 5| Step: 8
Training loss: 2.451115846633911
Validation loss: 2.249698987571142

Epoch: 5| Step: 9
Training loss: 2.2462735176086426
Validation loss: 2.253459697128624

Epoch: 5| Step: 10
Training loss: 2.476928949356079
Validation loss: 2.247383225348688

Epoch: 176| Step: 0
Training loss: 2.5701587200164795
Validation loss: 2.2459864744576077

Epoch: 5| Step: 1
Training loss: 2.484581708908081
Validation loss: 2.246315038332375

Epoch: 5| Step: 2
Training loss: 2.7051730155944824
Validation loss: 2.248424183937811

Epoch: 5| Step: 3
Training loss: 2.376189708709717
Validation loss: 2.2259821225238103

Epoch: 5| Step: 4
Training loss: 2.7765164375305176
Validation loss: 2.227835750067106

Epoch: 5| Step: 5
Training loss: 2.1788322925567627
Validation loss: 2.2176155787642284

Epoch: 5| Step: 6
Training loss: 2.197417974472046
Validation loss: 2.215047319730123

Epoch: 5| Step: 7
Training loss: 2.720975875854492
Validation loss: 2.20993390903678

Epoch: 5| Step: 8
Training loss: 2.4331090450286865
Validation loss: 2.2079950378787134

Epoch: 5| Step: 9
Training loss: 2.6657795906066895
Validation loss: 2.220649487228804

Epoch: 5| Step: 10
Training loss: 2.145059585571289
Validation loss: 2.2209802622436197

Epoch: 177| Step: 0
Training loss: 2.4339182376861572
Validation loss: 2.2340850009713122

Epoch: 5| Step: 1
Training loss: 2.2232282161712646
Validation loss: 2.235928796952771

Epoch: 5| Step: 2
Training loss: 2.767824649810791
Validation loss: 2.251439312452911

Epoch: 5| Step: 3
Training loss: 2.6282174587249756
Validation loss: 2.263926318896714

Epoch: 5| Step: 4
Training loss: 2.2222273349761963
Validation loss: 2.2623173447065454

Epoch: 5| Step: 5
Training loss: 1.939284086227417
Validation loss: 2.2756384059947026

Epoch: 5| Step: 6
Training loss: 2.325923442840576
Validation loss: 2.287547375566216

Epoch: 5| Step: 7
Training loss: 2.8148560523986816
Validation loss: 2.2850986296130764

Epoch: 5| Step: 8
Training loss: 2.5336458683013916
Validation loss: 2.2953265892562045

Epoch: 5| Step: 9
Training loss: 2.7693209648132324
Validation loss: 2.2873753988614647

Epoch: 5| Step: 10
Training loss: 2.707383155822754
Validation loss: 2.272752151694349

Epoch: 178| Step: 0
Training loss: 2.1679415702819824
Validation loss: 2.25192367646002

Epoch: 5| Step: 1
Training loss: 2.4270694255828857
Validation loss: 2.2313490298486527

Epoch: 5| Step: 2
Training loss: 2.667290210723877
Validation loss: 2.2274707876225954

Epoch: 5| Step: 3
Training loss: 2.6224281787872314
Validation loss: 2.2138780086271224

Epoch: 5| Step: 4
Training loss: 2.8047595024108887
Validation loss: 2.208349491960259

Epoch: 5| Step: 5
Training loss: 2.209995746612549
Validation loss: 2.2082823886666247

Epoch: 5| Step: 6
Training loss: 2.967775821685791
Validation loss: 2.206952198859184

Epoch: 5| Step: 7
Training loss: 2.077669620513916
Validation loss: 2.211592420454948

Epoch: 5| Step: 8
Training loss: 2.696652889251709
Validation loss: 2.2013086324097006

Epoch: 5| Step: 9
Training loss: 2.427767515182495
Validation loss: 2.2167586870090936

Epoch: 5| Step: 10
Training loss: 2.064379930496216
Validation loss: 2.2066616191658923

Epoch: 179| Step: 0
Training loss: 2.5623154640197754
Validation loss: 2.207698204184091

Epoch: 5| Step: 1
Training loss: 1.9850839376449585
Validation loss: 2.223107432806364

Epoch: 5| Step: 2
Training loss: 2.861271858215332
Validation loss: 2.2272048945068033

Epoch: 5| Step: 3
Training loss: 3.2229199409484863
Validation loss: 2.2281876815262662

Epoch: 5| Step: 4
Training loss: 2.146918535232544
Validation loss: 2.235166101045506

Epoch: 5| Step: 5
Training loss: 2.6300997734069824
Validation loss: 2.2386984132951304

Epoch: 5| Step: 6
Training loss: 2.1102240085601807
Validation loss: 2.2307885231510287

Epoch: 5| Step: 7
Training loss: 1.8596365451812744
Validation loss: 2.2337753413825907

Epoch: 5| Step: 8
Training loss: 2.2944161891937256
Validation loss: 2.230410329757198

Epoch: 5| Step: 9
Training loss: 2.789778709411621
Validation loss: 2.234568888141263

Epoch: 5| Step: 10
Training loss: 2.765866756439209
Validation loss: 2.236349968500035

Epoch: 180| Step: 0
Training loss: 2.800577402114868
Validation loss: 2.2445966518053444

Epoch: 5| Step: 1
Training loss: 2.5005478858947754
Validation loss: 2.237651260950232

Epoch: 5| Step: 2
Training loss: 2.504006862640381
Validation loss: 2.2340643431550715

Epoch: 5| Step: 3
Training loss: 2.800680160522461
Validation loss: 2.2443145039261028

Epoch: 5| Step: 4
Training loss: 2.1652960777282715
Validation loss: 2.2227163032818864

Epoch: 5| Step: 5
Training loss: 2.096360445022583
Validation loss: 2.2198603819775324

Epoch: 5| Step: 6
Training loss: 2.4474945068359375
Validation loss: 2.204759749033118

Epoch: 5| Step: 7
Training loss: 2.326388359069824
Validation loss: 2.213897914014837

Epoch: 5| Step: 8
Training loss: 2.3432865142822266
Validation loss: 2.226191101535674

Epoch: 5| Step: 9
Training loss: 2.9244179725646973
Validation loss: 2.231188717708793

Epoch: 5| Step: 10
Training loss: 2.3758161067962646
Validation loss: 2.235495141757432

Epoch: 181| Step: 0
Training loss: 2.429658889770508
Validation loss: 2.2412507405845066

Epoch: 5| Step: 1
Training loss: 1.6683591604232788
Validation loss: 2.226028839747111

Epoch: 5| Step: 2
Training loss: 2.555445671081543
Validation loss: 2.209737104754294

Epoch: 5| Step: 3
Training loss: 2.66086483001709
Validation loss: 2.204669580664686

Epoch: 5| Step: 4
Training loss: 2.1179165840148926
Validation loss: 2.199584250809044

Epoch: 5| Step: 5
Training loss: 2.8958587646484375
Validation loss: 2.198908377719182

Epoch: 5| Step: 6
Training loss: 2.9624509811401367
Validation loss: 2.199859083339732

Epoch: 5| Step: 7
Training loss: 2.161663770675659
Validation loss: 2.1999612700554634

Epoch: 5| Step: 8
Training loss: 2.640831470489502
Validation loss: 2.194721462906048

Epoch: 5| Step: 9
Training loss: 2.3483784198760986
Validation loss: 2.2015717849936536

Epoch: 5| Step: 10
Training loss: 3.0063157081604004
Validation loss: 2.1987167840362876

Epoch: 182| Step: 0
Training loss: 2.550863027572632
Validation loss: 2.196404241746472

Epoch: 5| Step: 1
Training loss: 2.340419292449951
Validation loss: 2.1990105387985066

Epoch: 5| Step: 2
Training loss: 1.917576789855957
Validation loss: 2.199295727155542

Epoch: 5| Step: 3
Training loss: 1.8558744192123413
Validation loss: 2.199882722670032

Epoch: 5| Step: 4
Training loss: 2.7060952186584473
Validation loss: 2.199544281087896

Epoch: 5| Step: 5
Training loss: 2.785043239593506
Validation loss: 2.2177534590485277

Epoch: 5| Step: 6
Training loss: 2.575314521789551
Validation loss: 2.2201042918748755

Epoch: 5| Step: 7
Training loss: 2.592233180999756
Validation loss: 2.236698527489939

Epoch: 5| Step: 8
Training loss: 2.857668399810791
Validation loss: 2.2432012275982927

Epoch: 5| Step: 9
Training loss: 2.4213309288024902
Validation loss: 2.2455211916277484

Epoch: 5| Step: 10
Training loss: 2.5844647884368896
Validation loss: 2.2465086521640902

Epoch: 183| Step: 0
Training loss: 2.8717308044433594
Validation loss: 2.2353932754967802

Epoch: 5| Step: 1
Training loss: 2.808586597442627
Validation loss: 2.2260503717648086

Epoch: 5| Step: 2
Training loss: 2.581234931945801
Validation loss: 2.229409119134308

Epoch: 5| Step: 3
Training loss: 2.9141006469726562
Validation loss: 2.2284560613734747

Epoch: 5| Step: 4
Training loss: 2.510596990585327
Validation loss: 2.2202587512231644

Epoch: 5| Step: 5
Training loss: 2.185741424560547
Validation loss: 2.2130351066589355

Epoch: 5| Step: 6
Training loss: 2.0650293827056885
Validation loss: 2.222111596856066

Epoch: 5| Step: 7
Training loss: 1.9969123601913452
Validation loss: 2.2185671303861882

Epoch: 5| Step: 8
Training loss: 2.1655893325805664
Validation loss: 2.220113746581539

Epoch: 5| Step: 9
Training loss: 2.696141242980957
Validation loss: 2.216076235617361

Epoch: 5| Step: 10
Training loss: 2.5655012130737305
Validation loss: 2.2295326173946424

Epoch: 184| Step: 0
Training loss: 2.688838481903076
Validation loss: 2.2315582895791657

Epoch: 5| Step: 1
Training loss: 2.7789204120635986
Validation loss: 2.2360020222202426

Epoch: 5| Step: 2
Training loss: 2.1751556396484375
Validation loss: 2.2228486486660537

Epoch: 5| Step: 3
Training loss: 2.8362271785736084
Validation loss: 2.206773316988381

Epoch: 5| Step: 4
Training loss: 2.031250238418579
Validation loss: 2.2135766744613647

Epoch: 5| Step: 5
Training loss: 2.891267776489258
Validation loss: 2.2062744927662674

Epoch: 5| Step: 6
Training loss: 2.1914210319519043
Validation loss: 2.208251594215311

Epoch: 5| Step: 7
Training loss: 2.6049180030822754
Validation loss: 2.2079339950315413

Epoch: 5| Step: 8
Training loss: 3.012528657913208
Validation loss: 2.2071597601777766

Epoch: 5| Step: 9
Training loss: 1.8735545873641968
Validation loss: 2.2060962466783423

Epoch: 5| Step: 10
Training loss: 2.079308271408081
Validation loss: 2.2078048336890435

Epoch: 185| Step: 0
Training loss: 2.273155450820923
Validation loss: 2.209519032509096

Epoch: 5| Step: 1
Training loss: 2.7671070098876953
Validation loss: 2.2308679575561197

Epoch: 5| Step: 2
Training loss: 2.563457489013672
Validation loss: 2.2269339330734743

Epoch: 5| Step: 3
Training loss: 2.1932766437530518
Validation loss: 2.220308680688181

Epoch: 5| Step: 4
Training loss: 2.191624879837036
Validation loss: 2.225406608273906

Epoch: 5| Step: 5
Training loss: 2.1663506031036377
Validation loss: 2.2279360781433764

Epoch: 5| Step: 6
Training loss: 2.9144203662872314
Validation loss: 2.2326032346294773

Epoch: 5| Step: 7
Training loss: 3.008181095123291
Validation loss: 2.2395533733470465

Epoch: 5| Step: 8
Training loss: 2.1887168884277344
Validation loss: 2.231779844530167

Epoch: 5| Step: 9
Training loss: 2.4877800941467285
Validation loss: 2.2189541247583207

Epoch: 5| Step: 10
Training loss: 2.3085556030273438
Validation loss: 2.2170189221700034

Epoch: 186| Step: 0
Training loss: 2.635728597640991
Validation loss: 2.2170246954887145

Epoch: 5| Step: 1
Training loss: 2.3981497287750244
Validation loss: 2.2013150620204147

Epoch: 5| Step: 2
Training loss: 2.1069138050079346
Validation loss: 2.200297881198186

Epoch: 5| Step: 3
Training loss: 2.434281826019287
Validation loss: 2.205607580882247

Epoch: 5| Step: 4
Training loss: 2.446502685546875
Validation loss: 2.204530895397227

Epoch: 5| Step: 5
Training loss: 2.948335647583008
Validation loss: 2.211475864533455

Epoch: 5| Step: 6
Training loss: 2.545689105987549
Validation loss: 2.205850073086318

Epoch: 5| Step: 7
Training loss: 2.5902276039123535
Validation loss: 2.203384513496071

Epoch: 5| Step: 8
Training loss: 2.5165536403656006
Validation loss: 2.2023280397538216

Epoch: 5| Step: 9
Training loss: 1.8974323272705078
Validation loss: 2.1958783698338333

Epoch: 5| Step: 10
Training loss: 2.673271894454956
Validation loss: 2.2018758379003054

Epoch: 187| Step: 0
Training loss: 2.5614395141601562
Validation loss: 2.2066199484691826

Epoch: 5| Step: 1
Training loss: 1.9145796298980713
Validation loss: 2.214189285873085

Epoch: 5| Step: 2
Training loss: 2.0737640857696533
Validation loss: 2.2149935691587386

Epoch: 5| Step: 3
Training loss: 2.5127317905426025
Validation loss: 2.2266995496647333

Epoch: 5| Step: 4
Training loss: 2.879398822784424
Validation loss: 2.2396649391420427

Epoch: 5| Step: 5
Training loss: 2.4604883193969727
Validation loss: 2.226353709415723

Epoch: 5| Step: 6
Training loss: 2.5423531532287598
Validation loss: 2.2427975644347486

Epoch: 5| Step: 7
Training loss: 2.6714508533477783
Validation loss: 2.240398701801095

Epoch: 5| Step: 8
Training loss: 2.825254201889038
Validation loss: 2.2534861256999354

Epoch: 5| Step: 9
Training loss: 2.093790054321289
Validation loss: 2.24556028714744

Epoch: 5| Step: 10
Training loss: 2.635514736175537
Validation loss: 2.2407510460063977

Epoch: 188| Step: 0
Training loss: 2.25020170211792
Validation loss: 2.23181313596746

Epoch: 5| Step: 1
Training loss: 2.6440517902374268
Validation loss: 2.2203017793675905

Epoch: 5| Step: 2
Training loss: 2.485400915145874
Validation loss: 2.2173500907036567

Epoch: 5| Step: 3
Training loss: 2.558098316192627
Validation loss: 2.20288097986611

Epoch: 5| Step: 4
Training loss: 1.848850965499878
Validation loss: 2.2032005863804973

Epoch: 5| Step: 5
Training loss: 2.553006410598755
Validation loss: 2.2006506099495837

Epoch: 5| Step: 6
Training loss: 2.5484702587127686
Validation loss: 2.2097040350719164

Epoch: 5| Step: 7
Training loss: 2.3973703384399414
Validation loss: 2.212563891564646

Epoch: 5| Step: 8
Training loss: 1.9362913370132446
Validation loss: 2.201150466037053

Epoch: 5| Step: 9
Training loss: 2.4689061641693115
Validation loss: 2.2016513116898073

Epoch: 5| Step: 10
Training loss: 3.6016759872436523
Validation loss: 2.2005813326886905

Epoch: 189| Step: 0
Training loss: 2.772460460662842
Validation loss: 2.1981422978062786

Epoch: 5| Step: 1
Training loss: 2.2113564014434814
Validation loss: 2.193915908054639

Epoch: 5| Step: 2
Training loss: 2.574042797088623
Validation loss: 2.1974683628287366

Epoch: 5| Step: 3
Training loss: 2.7191996574401855
Validation loss: 2.203782002131144

Epoch: 5| Step: 4
Training loss: 2.3311514854431152
Validation loss: 2.2008056012533044

Epoch: 5| Step: 5
Training loss: 2.950209140777588
Validation loss: 2.2047111424066688

Epoch: 5| Step: 6
Training loss: 2.0275886058807373
Validation loss: 2.2136291765397593

Epoch: 5| Step: 7
Training loss: 2.867048978805542
Validation loss: 2.208418094983665

Epoch: 5| Step: 8
Training loss: 2.016967535018921
Validation loss: 2.2181703326522664

Epoch: 5| Step: 9
Training loss: 2.19783353805542
Validation loss: 2.2263706166257142

Epoch: 5| Step: 10
Training loss: 2.434810161590576
Validation loss: 2.2306916893169446

Epoch: 190| Step: 0
Training loss: 1.936676025390625
Validation loss: 2.2226133064557145

Epoch: 5| Step: 1
Training loss: 2.5383119583129883
Validation loss: 2.2173409615793536

Epoch: 5| Step: 2
Training loss: 2.1519579887390137
Validation loss: 2.2131815418120353

Epoch: 5| Step: 3
Training loss: 2.6415905952453613
Validation loss: 2.2000625107877996

Epoch: 5| Step: 4
Training loss: 2.5553879737854004
Validation loss: 2.1980153745220554

Epoch: 5| Step: 5
Training loss: 2.5397486686706543
Validation loss: 2.1995357800555486

Epoch: 5| Step: 6
Training loss: 2.6780409812927246
Validation loss: 2.198043880924102

Epoch: 5| Step: 7
Training loss: 2.925220012664795
Validation loss: 2.193367214613063

Epoch: 5| Step: 8
Training loss: 2.3918890953063965
Validation loss: 2.1936052230096634

Epoch: 5| Step: 9
Training loss: 2.114896774291992
Validation loss: 2.195216714694936

Epoch: 5| Step: 10
Training loss: 2.5169482231140137
Validation loss: 2.2062143818024667

Epoch: 191| Step: 0
Training loss: 2.918120861053467
Validation loss: 2.207460718770181

Epoch: 5| Step: 1
Training loss: 2.8475000858306885
Validation loss: 2.216989173684069

Epoch: 5| Step: 2
Training loss: 2.061401844024658
Validation loss: 2.234765934687789

Epoch: 5| Step: 3
Training loss: 2.3022029399871826
Validation loss: 2.228729678738502

Epoch: 5| Step: 4
Training loss: 2.1922755241394043
Validation loss: 2.234644055366516

Epoch: 5| Step: 5
Training loss: 2.1823620796203613
Validation loss: 2.2329472623845583

Epoch: 5| Step: 6
Training loss: 2.4086244106292725
Validation loss: 2.231161653354604

Epoch: 5| Step: 7
Training loss: 2.7859272956848145
Validation loss: 2.233002749822473

Epoch: 5| Step: 8
Training loss: 2.2607133388519287
Validation loss: 2.2243053067115044

Epoch: 5| Step: 9
Training loss: 2.0863640308380127
Validation loss: 2.2178431326343166

Epoch: 5| Step: 10
Training loss: 2.9704103469848633
Validation loss: 2.207915752164779

Epoch: 192| Step: 0
Training loss: 2.6009762287139893
Validation loss: 2.208562558697116

Epoch: 5| Step: 1
Training loss: 3.183048963546753
Validation loss: 2.2058128977334626

Epoch: 5| Step: 2
Training loss: 2.600214719772339
Validation loss: 2.215504927019919

Epoch: 5| Step: 3
Training loss: 2.4927146434783936
Validation loss: 2.2160776251105854

Epoch: 5| Step: 4
Training loss: 2.7159039974212646
Validation loss: 2.204917300132013

Epoch: 5| Step: 5
Training loss: 1.8669970035552979
Validation loss: 2.201562637923866

Epoch: 5| Step: 6
Training loss: 2.4919140338897705
Validation loss: 2.1951843077136624

Epoch: 5| Step: 7
Training loss: 2.0553512573242188
Validation loss: 2.1987290869476976

Epoch: 5| Step: 8
Training loss: 1.794618844985962
Validation loss: 2.186317141338061

Epoch: 5| Step: 9
Training loss: 2.68477201461792
Validation loss: 2.1932189426114483

Epoch: 5| Step: 10
Training loss: 2.5221195220947266
Validation loss: 2.1909476121266684

Epoch: 193| Step: 0
Training loss: 2.4468421936035156
Validation loss: 2.198734078356015

Epoch: 5| Step: 1
Training loss: 2.6519217491149902
Validation loss: 2.184141625640213

Epoch: 5| Step: 2
Training loss: 2.717733860015869
Validation loss: 2.192836264128326

Epoch: 5| Step: 3
Training loss: 2.4236466884613037
Validation loss: 2.193476343667635

Epoch: 5| Step: 4
Training loss: 2.7805256843566895
Validation loss: 2.212700081127946

Epoch: 5| Step: 5
Training loss: 2.1818785667419434
Validation loss: 2.225731965034239

Epoch: 5| Step: 6
Training loss: 2.157022714614868
Validation loss: 2.2222008038592596

Epoch: 5| Step: 7
Training loss: 2.502002000808716
Validation loss: 2.225299653186593

Epoch: 5| Step: 8
Training loss: 2.2064990997314453
Validation loss: 2.229012832846693

Epoch: 5| Step: 9
Training loss: 2.5600857734680176
Validation loss: 2.239403872079747

Epoch: 5| Step: 10
Training loss: 2.205014228820801
Validation loss: 2.218167504956645

Epoch: 194| Step: 0
Training loss: 2.565250873565674
Validation loss: 2.2152291395330943

Epoch: 5| Step: 1
Training loss: 2.462460517883301
Validation loss: 2.195289711798391

Epoch: 5| Step: 2
Training loss: 3.2100472450256348
Validation loss: 2.1896848601679646

Epoch: 5| Step: 3
Training loss: 1.9922345876693726
Validation loss: 2.186406541896123

Epoch: 5| Step: 4
Training loss: 1.9329702854156494
Validation loss: 2.184251072586224

Epoch: 5| Step: 5
Training loss: 2.388669967651367
Validation loss: 2.190675855964743

Epoch: 5| Step: 6
Training loss: 2.6314570903778076
Validation loss: 2.190284385476061

Epoch: 5| Step: 7
Training loss: 2.1275665760040283
Validation loss: 2.1893476978425057

Epoch: 5| Step: 8
Training loss: 2.7058117389678955
Validation loss: 2.182744344075521

Epoch: 5| Step: 9
Training loss: 2.5638608932495117
Validation loss: 2.1968704551778813

Epoch: 5| Step: 10
Training loss: 2.4080634117126465
Validation loss: 2.1878152829344555

Epoch: 195| Step: 0
Training loss: 1.7701833248138428
Validation loss: 2.190518504829817

Epoch: 5| Step: 1
Training loss: 2.3197407722473145
Validation loss: 2.195236175291

Epoch: 5| Step: 2
Training loss: 2.0451247692108154
Validation loss: 2.195477178019862

Epoch: 5| Step: 3
Training loss: 2.309924364089966
Validation loss: 2.198709164896319

Epoch: 5| Step: 4
Training loss: 2.6265597343444824
Validation loss: 2.1950594455965105

Epoch: 5| Step: 5
Training loss: 3.0091552734375
Validation loss: 2.194832722345988

Epoch: 5| Step: 6
Training loss: 2.5274627208709717
Validation loss: 2.1897684963800574

Epoch: 5| Step: 7
Training loss: 2.0466341972351074
Validation loss: 2.2021407504235544

Epoch: 5| Step: 8
Training loss: 2.754505157470703
Validation loss: 2.200407710126651

Epoch: 5| Step: 9
Training loss: 2.5247607231140137
Validation loss: 2.2029054139250066

Epoch: 5| Step: 10
Training loss: 3.0581817626953125
Validation loss: 2.19741129618819

Epoch: 196| Step: 0
Training loss: 1.9563109874725342
Validation loss: 2.2074462316369496

Epoch: 5| Step: 1
Training loss: 2.7902445793151855
Validation loss: 2.207931410881781

Epoch: 5| Step: 2
Training loss: 2.098496913909912
Validation loss: 2.208276000074161

Epoch: 5| Step: 3
Training loss: 1.918278455734253
Validation loss: 2.214969624755203

Epoch: 5| Step: 4
Training loss: 2.7235474586486816
Validation loss: 2.203691085179647

Epoch: 5| Step: 5
Training loss: 2.7670555114746094
Validation loss: 2.2063244901677614

Epoch: 5| Step: 6
Training loss: 2.61645245552063
Validation loss: 2.204945288678651

Epoch: 5| Step: 7
Training loss: 1.9507306814193726
Validation loss: 2.2106137967878774

Epoch: 5| Step: 8
Training loss: 2.8248887062072754
Validation loss: 2.2182959279706402

Epoch: 5| Step: 9
Training loss: 2.5209269523620605
Validation loss: 2.225654625123547

Epoch: 5| Step: 10
Training loss: 2.699920415878296
Validation loss: 2.217988834586195

Epoch: 197| Step: 0
Training loss: 2.896793842315674
Validation loss: 2.218636510192707

Epoch: 5| Step: 1
Training loss: 2.0441980361938477
Validation loss: 2.217713963600897

Epoch: 5| Step: 2
Training loss: 2.508945941925049
Validation loss: 2.2095681775000786

Epoch: 5| Step: 3
Training loss: 2.16243839263916
Validation loss: 2.2126709004884124

Epoch: 5| Step: 4
Training loss: 2.3410391807556152
Validation loss: 2.212768539305656

Epoch: 5| Step: 5
Training loss: 1.9633163213729858
Validation loss: 2.2028745118007866

Epoch: 5| Step: 6
Training loss: 2.662156581878662
Validation loss: 2.2031727901069065

Epoch: 5| Step: 7
Training loss: 2.734604835510254
Validation loss: 2.192866322814777

Epoch: 5| Step: 8
Training loss: 2.763167381286621
Validation loss: 2.1991164043385494

Epoch: 5| Step: 9
Training loss: 2.5772736072540283
Validation loss: 2.199155435767225

Epoch: 5| Step: 10
Training loss: 2.302927255630493
Validation loss: 2.197561717802478

Epoch: 198| Step: 0
Training loss: 2.5412631034851074
Validation loss: 2.192159560418898

Epoch: 5| Step: 1
Training loss: 2.5254967212677
Validation loss: 2.197549366181897

Epoch: 5| Step: 2
Training loss: 3.063732385635376
Validation loss: 2.1841355703210317

Epoch: 5| Step: 3
Training loss: 2.1397480964660645
Validation loss: 2.1881558177291707

Epoch: 5| Step: 4
Training loss: 2.1524722576141357
Validation loss: 2.1929826454449723

Epoch: 5| Step: 5
Training loss: 2.8257174491882324
Validation loss: 2.2206680031232935

Epoch: 5| Step: 6
Training loss: 2.4338581562042236
Validation loss: 2.2090030459947485

Epoch: 5| Step: 7
Training loss: 1.9292036294937134
Validation loss: 2.208983216234433

Epoch: 5| Step: 8
Training loss: 2.2059760093688965
Validation loss: 2.2322418305181686

Epoch: 5| Step: 9
Training loss: 2.2575936317443848
Validation loss: 2.2403268339813396

Epoch: 5| Step: 10
Training loss: 2.7686002254486084
Validation loss: 2.2484829297629734

Epoch: 199| Step: 0
Training loss: 2.725829601287842
Validation loss: 2.2498230165050876

Epoch: 5| Step: 1
Training loss: 2.4934380054473877
Validation loss: 2.213322542046988

Epoch: 5| Step: 2
Training loss: 2.7894058227539062
Validation loss: 2.2143901932624077

Epoch: 5| Step: 3
Training loss: 2.8362534046173096
Validation loss: 2.211070442712435

Epoch: 5| Step: 4
Training loss: 1.7922184467315674
Validation loss: 2.2003726459318593

Epoch: 5| Step: 5
Training loss: 2.3424079418182373
Validation loss: 2.1936643661991244

Epoch: 5| Step: 6
Training loss: 2.615668535232544
Validation loss: 2.1948205091620006

Epoch: 5| Step: 7
Training loss: 2.232485294342041
Validation loss: 2.1920519003304104

Epoch: 5| Step: 8
Training loss: 2.151607036590576
Validation loss: 2.18608671106318

Epoch: 5| Step: 9
Training loss: 2.2356936931610107
Validation loss: 2.1994939901495494

Epoch: 5| Step: 10
Training loss: 2.6979517936706543
Validation loss: 2.200575154314759

Epoch: 200| Step: 0
Training loss: 2.236396312713623
Validation loss: 2.193072506176528

Epoch: 5| Step: 1
Training loss: 2.2225584983825684
Validation loss: 2.193355711557532

Epoch: 5| Step: 2
Training loss: 2.3952789306640625
Validation loss: 2.1950560333908244

Epoch: 5| Step: 3
Training loss: 3.140977382659912
Validation loss: 2.2044389119712253

Epoch: 5| Step: 4
Training loss: 2.315579652786255
Validation loss: 2.2033493365010908

Epoch: 5| Step: 5
Training loss: 2.2102487087249756
Validation loss: 2.220428559087938

Epoch: 5| Step: 6
Training loss: 2.7820889949798584
Validation loss: 2.226099691083354

Epoch: 5| Step: 7
Training loss: 2.0753777027130127
Validation loss: 2.236957775649204

Epoch: 5| Step: 8
Training loss: 3.1131582260131836
Validation loss: 2.2470712866834415

Epoch: 5| Step: 9
Training loss: 2.2591605186462402
Validation loss: 2.232872579687385

Epoch: 5| Step: 10
Training loss: 1.9878438711166382
Validation loss: 2.2244509625178512

Epoch: 201| Step: 0
Training loss: 2.7245657444000244
Validation loss: 2.232913073673043

Epoch: 5| Step: 1
Training loss: 1.528713583946228
Validation loss: 2.2088009208761235

Epoch: 5| Step: 2
Training loss: 2.3000435829162598
Validation loss: 2.2178446887641825

Epoch: 5| Step: 3
Training loss: 1.6370713710784912
Validation loss: 2.215860874422135

Epoch: 5| Step: 4
Training loss: 2.5345234870910645
Validation loss: 2.209846588873094

Epoch: 5| Step: 5
Training loss: 2.8186774253845215
Validation loss: 2.203337182280838

Epoch: 5| Step: 6
Training loss: 2.1526286602020264
Validation loss: 2.1964920336200344

Epoch: 5| Step: 7
Training loss: 2.654381275177002
Validation loss: 2.189643391998865

Epoch: 5| Step: 8
Training loss: 2.5057504177093506
Validation loss: 2.2008161749891055

Epoch: 5| Step: 9
Training loss: 2.910609483718872
Validation loss: 2.187221711681735

Epoch: 5| Step: 10
Training loss: 3.107785701751709
Validation loss: 2.1880821028063373

Epoch: 202| Step: 0
Training loss: 2.5476455688476562
Validation loss: 2.1940191253539054

Epoch: 5| Step: 1
Training loss: 2.5588207244873047
Validation loss: 2.1872573911502795

Epoch: 5| Step: 2
Training loss: 2.406623363494873
Validation loss: 2.191607052280057

Epoch: 5| Step: 3
Training loss: 2.3637826442718506
Validation loss: 2.2001003219235327

Epoch: 5| Step: 4
Training loss: 2.155236005783081
Validation loss: 2.190146230882214

Epoch: 5| Step: 5
Training loss: 2.9950108528137207
Validation loss: 2.1970877339763026

Epoch: 5| Step: 6
Training loss: 2.0793707370758057
Validation loss: 2.188432514026601

Epoch: 5| Step: 7
Training loss: 2.463624954223633
Validation loss: 2.19181393038842

Epoch: 5| Step: 8
Training loss: 2.325751781463623
Validation loss: 2.20105073272541

Epoch: 5| Step: 9
Training loss: 2.162982702255249
Validation loss: 2.1999345338472756

Epoch: 5| Step: 10
Training loss: 2.7157492637634277
Validation loss: 2.20934489721893

Epoch: 203| Step: 0
Training loss: 2.5963387489318848
Validation loss: 2.2033324933821157

Epoch: 5| Step: 1
Training loss: 2.405251979827881
Validation loss: 2.2004736726002028

Epoch: 5| Step: 2
Training loss: 2.443448543548584
Validation loss: 2.185129327158774

Epoch: 5| Step: 3
Training loss: 2.603425979614258
Validation loss: 2.185090272657333

Epoch: 5| Step: 4
Training loss: 2.217789649963379
Validation loss: 2.1821030878251597

Epoch: 5| Step: 5
Training loss: 1.7599761486053467
Validation loss: 2.175969969841742

Epoch: 5| Step: 6
Training loss: 2.73629093170166
Validation loss: 2.1756291927829867

Epoch: 5| Step: 7
Training loss: 2.4091341495513916
Validation loss: 2.1791724671599684

Epoch: 5| Step: 8
Training loss: 2.790288209915161
Validation loss: 2.1795018872907086

Epoch: 5| Step: 9
Training loss: 2.0042102336883545
Validation loss: 2.1822997498255905

Epoch: 5| Step: 10
Training loss: 2.85356068611145
Validation loss: 2.1754288852855725

Epoch: 204| Step: 0
Training loss: 2.685718297958374
Validation loss: 2.1866062533470894

Epoch: 5| Step: 1
Training loss: 2.4533233642578125
Validation loss: 2.1928023651082027

Epoch: 5| Step: 2
Training loss: 2.6572341918945312
Validation loss: 2.193252226357819

Epoch: 5| Step: 3
Training loss: 2.2824783325195312
Validation loss: 2.190684308287918

Epoch: 5| Step: 4
Training loss: 2.116098403930664
Validation loss: 2.1932963607131795

Epoch: 5| Step: 5
Training loss: 3.2096199989318848
Validation loss: 2.199535798001033

Epoch: 5| Step: 6
Training loss: 2.6452324390411377
Validation loss: 2.1912389006665958

Epoch: 5| Step: 7
Training loss: 2.0842604637145996
Validation loss: 2.2003591060638428

Epoch: 5| Step: 8
Training loss: 2.7044177055358887
Validation loss: 2.195069148976316

Epoch: 5| Step: 9
Training loss: 2.0806355476379395
Validation loss: 2.20400002438535

Epoch: 5| Step: 10
Training loss: 1.6991550922393799
Validation loss: 2.209217143315141

Epoch: 205| Step: 0
Training loss: 2.272484302520752
Validation loss: 2.2007806301116943

Epoch: 5| Step: 1
Training loss: 2.416482925415039
Validation loss: 2.21452179262715

Epoch: 5| Step: 2
Training loss: 2.5433156490325928
Validation loss: 2.2014368503324446

Epoch: 5| Step: 3
Training loss: 2.122096538543701
Validation loss: 2.2051139570051626

Epoch: 5| Step: 4
Training loss: 2.6472830772399902
Validation loss: 2.2137560382966073

Epoch: 5| Step: 5
Training loss: 2.6164889335632324
Validation loss: 2.205163917233867

Epoch: 5| Step: 6
Training loss: 2.289724111557007
Validation loss: 2.2062985409972486

Epoch: 5| Step: 7
Training loss: 2.6998355388641357
Validation loss: 2.203865817798081

Epoch: 5| Step: 8
Training loss: 2.465489625930786
Validation loss: 2.2017379114704747

Epoch: 5| Step: 9
Training loss: 2.819007396697998
Validation loss: 2.1967699681558917

Epoch: 5| Step: 10
Training loss: 1.5945444107055664
Validation loss: 2.178791361470376

Epoch: 206| Step: 0
Training loss: 2.690105438232422
Validation loss: 2.1822391351064048

Epoch: 5| Step: 1
Training loss: 1.9983608722686768
Validation loss: 2.1744414401310745

Epoch: 5| Step: 2
Training loss: 2.194593906402588
Validation loss: 2.174708627885388

Epoch: 5| Step: 3
Training loss: 2.8432438373565674
Validation loss: 2.184176907744459

Epoch: 5| Step: 4
Training loss: 2.1983494758605957
Validation loss: 2.180012046649892

Epoch: 5| Step: 5
Training loss: 2.0197134017944336
Validation loss: 2.1643151416573474

Epoch: 5| Step: 6
Training loss: 2.5473439693450928
Validation loss: 2.179563860739431

Epoch: 5| Step: 7
Training loss: 3.0773537158966064
Validation loss: 2.1807762089596

Epoch: 5| Step: 8
Training loss: 2.2138125896453857
Validation loss: 2.180492870269283

Epoch: 5| Step: 9
Training loss: 2.6171963214874268
Validation loss: 2.191114333368117

Epoch: 5| Step: 10
Training loss: 2.3147799968719482
Validation loss: 2.193248869270407

Epoch: 207| Step: 0
Training loss: 2.169835329055786
Validation loss: 2.1780237279912478

Epoch: 5| Step: 1
Training loss: 2.3101885318756104
Validation loss: 2.185413657978017

Epoch: 5| Step: 2
Training loss: 2.491584300994873
Validation loss: 2.1949746583097722

Epoch: 5| Step: 3
Training loss: 2.7387893199920654
Validation loss: 2.19005109161459

Epoch: 5| Step: 4
Training loss: 2.4368703365325928
Validation loss: 2.1850248100937053

Epoch: 5| Step: 5
Training loss: 2.434643268585205
Validation loss: 2.185134736440515

Epoch: 5| Step: 6
Training loss: 2.6834747791290283
Validation loss: 2.1799346272663405

Epoch: 5| Step: 7
Training loss: 2.141735553741455
Validation loss: 2.171692717459894

Epoch: 5| Step: 8
Training loss: 2.060853958129883
Validation loss: 2.1858733597622124

Epoch: 5| Step: 9
Training loss: 2.342888355255127
Validation loss: 2.1899396014469925

Epoch: 5| Step: 10
Training loss: 2.9893975257873535
Validation loss: 2.197701031161893

Epoch: 208| Step: 0
Training loss: 2.4511513710021973
Validation loss: 2.1967820198305192

Epoch: 5| Step: 1
Training loss: 2.057713508605957
Validation loss: 2.2233921225352953

Epoch: 5| Step: 2
Training loss: 2.2102010250091553
Validation loss: 2.207301902514632

Epoch: 5| Step: 3
Training loss: 2.4835104942321777
Validation loss: 2.2054365399063274

Epoch: 5| Step: 4
Training loss: 2.794935703277588
Validation loss: 2.2218075003675235

Epoch: 5| Step: 5
Training loss: 2.609825849533081
Validation loss: 2.226250235752393

Epoch: 5| Step: 6
Training loss: 3.009352207183838
Validation loss: 2.2237876128124934

Epoch: 5| Step: 7
Training loss: 2.8668179512023926
Validation loss: 2.212430736070038

Epoch: 5| Step: 8
Training loss: 2.0608248710632324
Validation loss: 2.2075318905615036

Epoch: 5| Step: 9
Training loss: 2.0693962574005127
Validation loss: 2.1943063620598084

Epoch: 5| Step: 10
Training loss: 1.8569436073303223
Validation loss: 2.1709634052809847

Epoch: 209| Step: 0
Training loss: 2.3866913318634033
Validation loss: 2.188838997194844

Epoch: 5| Step: 1
Training loss: 2.0546188354492188
Validation loss: 2.1782762158301567

Epoch: 5| Step: 2
Training loss: 2.227437973022461
Validation loss: 2.1713839013089418

Epoch: 5| Step: 3
Training loss: 2.859583616256714
Validation loss: 2.1721464882614794

Epoch: 5| Step: 4
Training loss: 2.2167630195617676
Validation loss: 2.180888327219153

Epoch: 5| Step: 5
Training loss: 2.7029337882995605
Validation loss: 2.179521527341617

Epoch: 5| Step: 6
Training loss: 2.2536301612854004
Validation loss: 2.180591639652047

Epoch: 5| Step: 7
Training loss: 2.4984591007232666
Validation loss: 2.172292063313146

Epoch: 5| Step: 8
Training loss: 2.591291904449463
Validation loss: 2.1819439190690235

Epoch: 5| Step: 9
Training loss: 2.2496113777160645
Validation loss: 2.1695857637672016

Epoch: 5| Step: 10
Training loss: 2.8758533000946045
Validation loss: 2.169899066289266

Epoch: 210| Step: 0
Training loss: 2.206969976425171
Validation loss: 2.1680557740631925

Epoch: 5| Step: 1
Training loss: 2.3336446285247803
Validation loss: 2.17678879409708

Epoch: 5| Step: 2
Training loss: 2.276766300201416
Validation loss: 2.211678922817271

Epoch: 5| Step: 3
Training loss: 2.3539347648620605
Validation loss: 2.24405679651486

Epoch: 5| Step: 4
Training loss: 3.176469326019287
Validation loss: 2.267188423423357

Epoch: 5| Step: 5
Training loss: 2.730760097503662
Validation loss: 2.254045896632697

Epoch: 5| Step: 6
Training loss: 2.6482670307159424
Validation loss: 2.257620798644199

Epoch: 5| Step: 7
Training loss: 2.356839418411255
Validation loss: 2.226550543180076

Epoch: 5| Step: 8
Training loss: 2.0204856395721436
Validation loss: 2.2051764816366215

Epoch: 5| Step: 9
Training loss: 2.6071815490722656
Validation loss: 2.1840183683620986

Epoch: 5| Step: 10
Training loss: 2.079859972000122
Validation loss: 2.186657562050768

Epoch: 211| Step: 0
Training loss: 2.0229506492614746
Validation loss: 2.1719029859829972

Epoch: 5| Step: 1
Training loss: 2.6851744651794434
Validation loss: 2.1791474485910065

Epoch: 5| Step: 2
Training loss: 2.499720335006714
Validation loss: 2.167286629317909

Epoch: 5| Step: 3
Training loss: 2.0806400775909424
Validation loss: 2.163760542869568

Epoch: 5| Step: 4
Training loss: 2.113412857055664
Validation loss: 2.1723624480667936

Epoch: 5| Step: 5
Training loss: 2.3729984760284424
Validation loss: 2.1662189524660826

Epoch: 5| Step: 6
Training loss: 3.0108377933502197
Validation loss: 2.1766037979433612

Epoch: 5| Step: 7
Training loss: 2.050428867340088
Validation loss: 2.1694424075465046

Epoch: 5| Step: 8
Training loss: 2.869581937789917
Validation loss: 2.1674748851406958

Epoch: 5| Step: 9
Training loss: 2.7444474697113037
Validation loss: 2.1817771516820437

Epoch: 5| Step: 10
Training loss: 2.352274179458618
Validation loss: 2.1967545811847975

Epoch: 212| Step: 0
Training loss: 2.6287624835968018
Validation loss: 2.2112472364979405

Epoch: 5| Step: 1
Training loss: 2.5650622844696045
Validation loss: 2.2358277151661534

Epoch: 5| Step: 2
Training loss: 2.737461566925049
Validation loss: 2.25663318685306

Epoch: 5| Step: 3
Training loss: 2.757411241531372
Validation loss: 2.255144416645009

Epoch: 5| Step: 4
Training loss: 2.280503511428833
Validation loss: 2.23454297742536

Epoch: 5| Step: 5
Training loss: 1.9214595556259155
Validation loss: 2.229231044810305

Epoch: 5| Step: 6
Training loss: 1.693477988243103
Validation loss: 2.2158031386713826

Epoch: 5| Step: 7
Training loss: 2.5829153060913086
Validation loss: 2.201166699009557

Epoch: 5| Step: 8
Training loss: 2.72184419631958
Validation loss: 2.2011052664890083

Epoch: 5| Step: 9
Training loss: 2.606741428375244
Validation loss: 2.204445994028481

Epoch: 5| Step: 10
Training loss: 2.13516902923584
Validation loss: 2.193722974869513

Epoch: 213| Step: 0
Training loss: 2.3906009197235107
Validation loss: 2.1969031672323904

Epoch: 5| Step: 1
Training loss: 2.2390031814575195
Validation loss: 2.1864856930189234

Epoch: 5| Step: 2
Training loss: 2.6703567504882812
Validation loss: 2.1970841743612803

Epoch: 5| Step: 3
Training loss: 1.6801671981811523
Validation loss: 2.194212862240371

Epoch: 5| Step: 4
Training loss: 2.3306703567504883
Validation loss: 2.1903496301302345

Epoch: 5| Step: 5
Training loss: 2.400516986846924
Validation loss: 2.1917548666718187

Epoch: 5| Step: 6
Training loss: 2.693758487701416
Validation loss: 2.179404604819513

Epoch: 5| Step: 7
Training loss: 3.136402130126953
Validation loss: 2.1794233373416367

Epoch: 5| Step: 8
Training loss: 2.622437000274658
Validation loss: 2.1600066205506683

Epoch: 5| Step: 9
Training loss: 2.343388557434082
Validation loss: 2.1557850530070644

Epoch: 5| Step: 10
Training loss: 1.9923441410064697
Validation loss: 2.149189426052955

Epoch: 214| Step: 0
Training loss: 2.5014379024505615
Validation loss: 2.154861227158577

Epoch: 5| Step: 1
Training loss: 2.4751362800598145
Validation loss: 2.147467162019463

Epoch: 5| Step: 2
Training loss: 1.9872878789901733
Validation loss: 2.1579921578848236

Epoch: 5| Step: 3
Training loss: 2.248079776763916
Validation loss: 2.164372141643237

Epoch: 5| Step: 4
Training loss: 2.9726009368896484
Validation loss: 2.1618337554316365

Epoch: 5| Step: 5
Training loss: 2.2928760051727295
Validation loss: 2.1749882864695724

Epoch: 5| Step: 6
Training loss: 2.6771397590637207
Validation loss: 2.168352655185166

Epoch: 5| Step: 7
Training loss: 2.662998676300049
Validation loss: 2.1864413471632105

Epoch: 5| Step: 8
Training loss: 1.740625023841858
Validation loss: 2.1943081707082768

Epoch: 5| Step: 9
Training loss: 2.554771900177002
Validation loss: 2.203240802211146

Epoch: 5| Step: 10
Training loss: 2.236971855163574
Validation loss: 2.19449976054571

Epoch: 215| Step: 0
Training loss: 2.025200605392456
Validation loss: 2.1818317392820954

Epoch: 5| Step: 1
Training loss: 2.8208720684051514
Validation loss: 2.1865349918283443

Epoch: 5| Step: 2
Training loss: 2.2019870281219482
Validation loss: 2.176881810670258

Epoch: 5| Step: 3
Training loss: 2.6013834476470947
Validation loss: 2.1772594759541173

Epoch: 5| Step: 4
Training loss: 2.076488971710205
Validation loss: 2.181220764754921

Epoch: 5| Step: 5
Training loss: 2.442885160446167
Validation loss: 2.1826528169775523

Epoch: 5| Step: 6
Training loss: 2.547795295715332
Validation loss: 2.189512860390448

Epoch: 5| Step: 7
Training loss: 2.3886213302612305
Validation loss: 2.1899734722670687

Epoch: 5| Step: 8
Training loss: 2.9633936882019043
Validation loss: 2.203985937180058

Epoch: 5| Step: 9
Training loss: 2.205073833465576
Validation loss: 2.2025454659615793

Epoch: 5| Step: 10
Training loss: 2.14613938331604
Validation loss: 2.196257386156308

Epoch: 216| Step: 0
Training loss: 2.313734531402588
Validation loss: 2.184380647956684

Epoch: 5| Step: 1
Training loss: 2.44002103805542
Validation loss: 2.199189293769098

Epoch: 5| Step: 2
Training loss: 2.578781843185425
Validation loss: 2.1899972474703224

Epoch: 5| Step: 3
Training loss: 2.265672206878662
Validation loss: 2.1819048197038713

Epoch: 5| Step: 4
Training loss: 2.5356645584106445
Validation loss: 2.1761321431847027

Epoch: 5| Step: 5
Training loss: 2.3574767112731934
Validation loss: 2.1691262824561006

Epoch: 5| Step: 6
Training loss: 2.381319761276245
Validation loss: 2.1710302022195633

Epoch: 5| Step: 7
Training loss: 3.2030727863311768
Validation loss: 2.1613187238734257

Epoch: 5| Step: 8
Training loss: 2.073805570602417
Validation loss: 2.161881160992448

Epoch: 5| Step: 9
Training loss: 2.338693857192993
Validation loss: 2.178151894641179

Epoch: 5| Step: 10
Training loss: 1.9294164180755615
Validation loss: 2.1723423939879223

Epoch: 217| Step: 0
Training loss: 2.481090545654297
Validation loss: 2.203993756283996

Epoch: 5| Step: 1
Training loss: 3.2300705909729004
Validation loss: 2.224405642478697

Epoch: 5| Step: 2
Training loss: 2.627931594848633
Validation loss: 2.226510114567254

Epoch: 5| Step: 3
Training loss: 2.863067150115967
Validation loss: 2.2424059632003948

Epoch: 5| Step: 4
Training loss: 1.8008949756622314
Validation loss: 2.217845437347248

Epoch: 5| Step: 5
Training loss: 2.2230308055877686
Validation loss: 2.203335027540884

Epoch: 5| Step: 6
Training loss: 2.5580227375030518
Validation loss: 2.1873629887898765

Epoch: 5| Step: 7
Training loss: 2.6490893363952637
Validation loss: 2.1811790440672185

Epoch: 5| Step: 8
Training loss: 2.2424211502075195
Validation loss: 2.1816039726298344

Epoch: 5| Step: 9
Training loss: 1.8283135890960693
Validation loss: 2.165619493812643

Epoch: 5| Step: 10
Training loss: 2.019713878631592
Validation loss: 2.1572962166160665

Epoch: 218| Step: 0
Training loss: 2.1008076667785645
Validation loss: 2.1595644412502164

Epoch: 5| Step: 1
Training loss: 2.683516025543213
Validation loss: 2.1600390993138796

Epoch: 5| Step: 2
Training loss: 2.1340584754943848
Validation loss: 2.148870216902866

Epoch: 5| Step: 3
Training loss: 3.1767241954803467
Validation loss: 2.150066949987924

Epoch: 5| Step: 4
Training loss: 2.339479684829712
Validation loss: 2.1513643803135043

Epoch: 5| Step: 5
Training loss: 2.315098285675049
Validation loss: 2.1563104685916694

Epoch: 5| Step: 6
Training loss: 1.8967063426971436
Validation loss: 2.1670120403330815

Epoch: 5| Step: 7
Training loss: 2.951725721359253
Validation loss: 2.166954748092159

Epoch: 5| Step: 8
Training loss: 1.757148027420044
Validation loss: 2.1913142768285607

Epoch: 5| Step: 9
Training loss: 2.473923921585083
Validation loss: 2.1888328393300376

Epoch: 5| Step: 10
Training loss: 2.4756147861480713
Validation loss: 2.1977168385700514

Epoch: 219| Step: 0
Training loss: 2.585636854171753
Validation loss: 2.1882806913827055

Epoch: 5| Step: 1
Training loss: 2.5801875591278076
Validation loss: 2.2017446397453226

Epoch: 5| Step: 2
Training loss: 2.3258578777313232
Validation loss: 2.1708947356029222

Epoch: 5| Step: 3
Training loss: 2.327590227127075
Validation loss: 2.168886125728648

Epoch: 5| Step: 4
Training loss: 1.819209098815918
Validation loss: 2.1590819320371075

Epoch: 5| Step: 5
Training loss: 3.01468563079834
Validation loss: 2.1635007281457224

Epoch: 5| Step: 6
Training loss: 2.0721662044525146
Validation loss: 2.1563630078428533

Epoch: 5| Step: 7
Training loss: 2.187784194946289
Validation loss: 2.162636267241611

Epoch: 5| Step: 8
Training loss: 3.0820956230163574
Validation loss: 2.1527373457467682

Epoch: 5| Step: 9
Training loss: 2.144753932952881
Validation loss: 2.1568359687764156

Epoch: 5| Step: 10
Training loss: 2.2497425079345703
Validation loss: 2.1587636393885457

Epoch: 220| Step: 0
Training loss: 2.3861069679260254
Validation loss: 2.160480877404572

Epoch: 5| Step: 1
Training loss: 2.402330160140991
Validation loss: 2.1673178531790294

Epoch: 5| Step: 2
Training loss: 2.6657376289367676
Validation loss: 2.1694325195845736

Epoch: 5| Step: 3
Training loss: 2.6104793548583984
Validation loss: 2.1812208929369525

Epoch: 5| Step: 4
Training loss: 2.5595221519470215
Validation loss: 2.1861404142072125

Epoch: 5| Step: 5
Training loss: 1.9591047763824463
Validation loss: 2.2037320111387517

Epoch: 5| Step: 6
Training loss: 2.3015341758728027
Validation loss: 2.2093577782313027

Epoch: 5| Step: 7
Training loss: 2.6078200340270996
Validation loss: 2.206952550077951

Epoch: 5| Step: 8
Training loss: 2.4985556602478027
Validation loss: 2.1995933978788313

Epoch: 5| Step: 9
Training loss: 2.499265670776367
Validation loss: 2.1798783527907504

Epoch: 5| Step: 10
Training loss: 1.7017085552215576
Validation loss: 2.172102653852073

Epoch: 221| Step: 0
Training loss: 2.1880180835723877
Validation loss: 2.153831422969859

Epoch: 5| Step: 1
Training loss: 2.230832099914551
Validation loss: 2.1651038354442966

Epoch: 5| Step: 2
Training loss: 2.0913989543914795
Validation loss: 2.163171422096991

Epoch: 5| Step: 3
Training loss: 2.2011892795562744
Validation loss: 2.166770663312686

Epoch: 5| Step: 4
Training loss: 2.8688855171203613
Validation loss: 2.1657419243166522

Epoch: 5| Step: 5
Training loss: 2.3529295921325684
Validation loss: 2.1637243968184277

Epoch: 5| Step: 6
Training loss: 2.4888477325439453
Validation loss: 2.159525448276151

Epoch: 5| Step: 7
Training loss: 2.1592984199523926
Validation loss: 2.1719541498409805

Epoch: 5| Step: 8
Training loss: 2.539548873901367
Validation loss: 2.171540247496738

Epoch: 5| Step: 9
Training loss: 2.4016757011413574
Validation loss: 2.175841813446373

Epoch: 5| Step: 10
Training loss: 2.7531352043151855
Validation loss: 2.190899505410143

Epoch: 222| Step: 0
Training loss: 2.5059242248535156
Validation loss: 2.2051585258976107

Epoch: 5| Step: 1
Training loss: 1.9475167989730835
Validation loss: 2.1851689225883892

Epoch: 5| Step: 2
Training loss: 2.141928195953369
Validation loss: 2.195352952967408

Epoch: 5| Step: 3
Training loss: 3.1211044788360596
Validation loss: 2.191494398219611

Epoch: 5| Step: 4
Training loss: 2.658668279647827
Validation loss: 2.196428270750148

Epoch: 5| Step: 5
Training loss: 1.8063881397247314
Validation loss: 2.1970604183853313

Epoch: 5| Step: 6
Training loss: 2.643033742904663
Validation loss: 2.1880523184294343

Epoch: 5| Step: 7
Training loss: 2.520059823989868
Validation loss: 2.164152470968103

Epoch: 5| Step: 8
Training loss: 1.8385423421859741
Validation loss: 2.156250274309548

Epoch: 5| Step: 9
Training loss: 2.4123787879943848
Validation loss: 2.1576972648661625

Epoch: 5| Step: 10
Training loss: 2.6027355194091797
Validation loss: 2.1512854829911263

Epoch: 223| Step: 0
Training loss: 2.5526556968688965
Validation loss: 2.145996396259595

Epoch: 5| Step: 1
Training loss: 2.5419745445251465
Validation loss: 2.139655106811113

Epoch: 5| Step: 2
Training loss: 2.039736747741699
Validation loss: 2.135153919137934

Epoch: 5| Step: 3
Training loss: 2.2865326404571533
Validation loss: 2.125126623338269

Epoch: 5| Step: 4
Training loss: 2.1198458671569824
Validation loss: 2.1381429651732087

Epoch: 5| Step: 5
Training loss: 2.4056003093719482
Validation loss: 2.1303667791428103

Epoch: 5| Step: 6
Training loss: 2.475613594055176
Validation loss: 2.1344334797192643

Epoch: 5| Step: 7
Training loss: 1.8901554346084595
Validation loss: 2.1431806113130305

Epoch: 5| Step: 8
Training loss: 2.5647571086883545
Validation loss: 2.174490791495128

Epoch: 5| Step: 9
Training loss: 3.135676860809326
Validation loss: 2.2013259164748655

Epoch: 5| Step: 10
Training loss: 2.3250696659088135
Validation loss: 2.2172213805619108

Epoch: 224| Step: 0
Training loss: 2.429288864135742
Validation loss: 2.1855169188591743

Epoch: 5| Step: 1
Training loss: 2.207181215286255
Validation loss: 2.2037217693944133

Epoch: 5| Step: 2
Training loss: 2.503737211227417
Validation loss: 2.2051729861126153

Epoch: 5| Step: 3
Training loss: 2.1403675079345703
Validation loss: 2.1988293406783894

Epoch: 5| Step: 4
Training loss: 2.7125983238220215
Validation loss: 2.184394041697184

Epoch: 5| Step: 5
Training loss: 3.032907009124756
Validation loss: 2.1714507405475905

Epoch: 5| Step: 6
Training loss: 1.9171361923217773
Validation loss: 2.157031633520639

Epoch: 5| Step: 7
Training loss: 2.0909621715545654
Validation loss: 2.1606274010032736

Epoch: 5| Step: 8
Training loss: 2.227177858352661
Validation loss: 2.1545630116616525

Epoch: 5| Step: 9
Training loss: 2.2020764350891113
Validation loss: 2.1425312231945735

Epoch: 5| Step: 10
Training loss: 2.9155113697052
Validation loss: 2.1462680037303636

Epoch: 225| Step: 0
Training loss: 2.364781141281128
Validation loss: 2.151386131522476

Epoch: 5| Step: 1
Training loss: 2.5129692554473877
Validation loss: 2.146841013303367

Epoch: 5| Step: 2
Training loss: 1.961971640586853
Validation loss: 2.14853766400327

Epoch: 5| Step: 3
Training loss: 2.6026928424835205
Validation loss: 2.136715155775829

Epoch: 5| Step: 4
Training loss: 2.1182258129119873
Validation loss: 2.142235420083487

Epoch: 5| Step: 5
Training loss: 2.274245023727417
Validation loss: 2.1398459788291686

Epoch: 5| Step: 6
Training loss: 2.2718799114227295
Validation loss: 2.1440628895195584

Epoch: 5| Step: 7
Training loss: 3.0783708095550537
Validation loss: 2.1457442955304216

Epoch: 5| Step: 8
Training loss: 2.3617491722106934
Validation loss: 2.149829105664325

Epoch: 5| Step: 9
Training loss: 2.3944923877716064
Validation loss: 2.1621408936797932

Epoch: 5| Step: 10
Training loss: 2.3203039169311523
Validation loss: 2.157325642083281

Epoch: 226| Step: 0
Training loss: 2.2845966815948486
Validation loss: 2.1693499319015013

Epoch: 5| Step: 1
Training loss: 2.138256311416626
Validation loss: 2.1650582500683364

Epoch: 5| Step: 2
Training loss: 2.405775785446167
Validation loss: 2.164711985536801

Epoch: 5| Step: 3
Training loss: 3.551555633544922
Validation loss: 2.1535745102872133

Epoch: 5| Step: 4
Training loss: 2.9946446418762207
Validation loss: 2.157261689503988

Epoch: 5| Step: 5
Training loss: 2.5104191303253174
Validation loss: 2.1600747005913847

Epoch: 5| Step: 6
Training loss: 1.6809475421905518
Validation loss: 2.151255117949619

Epoch: 5| Step: 7
Training loss: 2.2246034145355225
Validation loss: 2.1514355828685146

Epoch: 5| Step: 8
Training loss: 2.0453619956970215
Validation loss: 2.1686599933972923

Epoch: 5| Step: 9
Training loss: 2.2182772159576416
Validation loss: 2.1490218895737843

Epoch: 5| Step: 10
Training loss: 2.125012159347534
Validation loss: 2.1574815037429973

Epoch: 227| Step: 0
Training loss: 2.5796608924865723
Validation loss: 2.159244579653586

Epoch: 5| Step: 1
Training loss: 2.0578932762145996
Validation loss: 2.150029613125709

Epoch: 5| Step: 2
Training loss: 2.506779670715332
Validation loss: 2.1381237353048017

Epoch: 5| Step: 3
Training loss: 2.561868667602539
Validation loss: 2.14651249301049

Epoch: 5| Step: 4
Training loss: 2.0652782917022705
Validation loss: 2.152670096325618

Epoch: 5| Step: 5
Training loss: 2.4258787631988525
Validation loss: 2.1577451562368744

Epoch: 5| Step: 6
Training loss: 2.136531352996826
Validation loss: 2.163720579557521

Epoch: 5| Step: 7
Training loss: 2.688387393951416
Validation loss: 2.1772383746280464

Epoch: 5| Step: 8
Training loss: 2.572166919708252
Validation loss: 2.1836463764149654

Epoch: 5| Step: 9
Training loss: 2.6689302921295166
Validation loss: 2.1644278226360196

Epoch: 5| Step: 10
Training loss: 1.679033875465393
Validation loss: 2.161683959345664

Epoch: 228| Step: 0
Training loss: 2.4957966804504395
Validation loss: 2.154804575827814

Epoch: 5| Step: 1
Training loss: 1.9403022527694702
Validation loss: 2.162104901447091

Epoch: 5| Step: 2
Training loss: 1.6305421590805054
Validation loss: 2.146570828653151

Epoch: 5| Step: 3
Training loss: 2.1949236392974854
Validation loss: 2.1515837177153556

Epoch: 5| Step: 4
Training loss: 3.2250118255615234
Validation loss: 2.1602187759132794

Epoch: 5| Step: 5
Training loss: 2.583103895187378
Validation loss: 2.1484804371351838

Epoch: 5| Step: 6
Training loss: 2.5668482780456543
Validation loss: 2.1498911150040163

Epoch: 5| Step: 7
Training loss: 2.4064557552337646
Validation loss: 2.1586316400958645

Epoch: 5| Step: 8
Training loss: 2.1117146015167236
Validation loss: 2.146678559241756

Epoch: 5| Step: 9
Training loss: 2.6868793964385986
Validation loss: 2.142525678039879

Epoch: 5| Step: 10
Training loss: 2.521742820739746
Validation loss: 2.134828248331624

Epoch: 229| Step: 0
Training loss: 2.253910779953003
Validation loss: 2.1355915415671562

Epoch: 5| Step: 1
Training loss: 2.647014617919922
Validation loss: 2.148630419085103

Epoch: 5| Step: 2
Training loss: 1.9864189624786377
Validation loss: 2.162214858557588

Epoch: 5| Step: 3
Training loss: 2.4134373664855957
Validation loss: 2.1966493219457646

Epoch: 5| Step: 4
Training loss: 2.221424102783203
Validation loss: 2.1985595072469404

Epoch: 5| Step: 5
Training loss: 2.816087245941162
Validation loss: 2.239804534501927

Epoch: 5| Step: 6
Training loss: 2.3855669498443604
Validation loss: 2.259490684796405

Epoch: 5| Step: 7
Training loss: 2.6048219203948975
Validation loss: 2.2437489776201147

Epoch: 5| Step: 8
Training loss: 2.6272964477539062
Validation loss: 2.2229905500206897

Epoch: 5| Step: 9
Training loss: 2.2954952716827393
Validation loss: 2.1678394194572204

Epoch: 5| Step: 10
Training loss: 1.962378978729248
Validation loss: 2.15188173068467

Epoch: 230| Step: 0
Training loss: 2.8576881885528564
Validation loss: 2.1494475231375745

Epoch: 5| Step: 1
Training loss: 2.427778959274292
Validation loss: 2.134443013898788

Epoch: 5| Step: 2
Training loss: 1.99700927734375
Validation loss: 2.1448447550496748

Epoch: 5| Step: 3
Training loss: 2.861520290374756
Validation loss: 2.1517783467487623

Epoch: 5| Step: 4
Training loss: 2.316181182861328
Validation loss: 2.1521570003160866

Epoch: 5| Step: 5
Training loss: 2.4576854705810547
Validation loss: 2.1497893692344747

Epoch: 5| Step: 6
Training loss: 2.2901225090026855
Validation loss: 2.1479420405562206

Epoch: 5| Step: 7
Training loss: 2.312156915664673
Validation loss: 2.136530324976931

Epoch: 5| Step: 8
Training loss: 2.500211000442505
Validation loss: 2.136955673976611

Epoch: 5| Step: 9
Training loss: 1.8439733982086182
Validation loss: 2.1403450324971187

Epoch: 5| Step: 10
Training loss: 2.6310184001922607
Validation loss: 2.1364291893538607

Epoch: 231| Step: 0
Training loss: 1.680749535560608
Validation loss: 2.137433828846101

Epoch: 5| Step: 1
Training loss: 2.846111297607422
Validation loss: 2.1526646498710877

Epoch: 5| Step: 2
Training loss: 2.6136467456817627
Validation loss: 2.157374597364856

Epoch: 5| Step: 3
Training loss: 2.945878505706787
Validation loss: 2.1602520122322986

Epoch: 5| Step: 4
Training loss: 2.2614922523498535
Validation loss: 2.1723057454632175

Epoch: 5| Step: 5
Training loss: 2.0592124462127686
Validation loss: 2.16903369785637

Epoch: 5| Step: 6
Training loss: 1.9197990894317627
Validation loss: 2.179565022068639

Epoch: 5| Step: 7
Training loss: 2.4643054008483887
Validation loss: 2.1690909477972213

Epoch: 5| Step: 8
Training loss: 2.4140665531158447
Validation loss: 2.1695001202244915

Epoch: 5| Step: 9
Training loss: 2.1683883666992188
Validation loss: 2.1514109385910856

Epoch: 5| Step: 10
Training loss: 2.590630292892456
Validation loss: 2.1476371801027687

Epoch: 232| Step: 0
Training loss: 2.722872257232666
Validation loss: 2.1547746632688787

Epoch: 5| Step: 1
Training loss: 2.3563742637634277
Validation loss: 2.1434377790779195

Epoch: 5| Step: 2
Training loss: 2.5825319290161133
Validation loss: 2.14099649588267

Epoch: 5| Step: 3
Training loss: 1.943484902381897
Validation loss: 2.140508036459646

Epoch: 5| Step: 4
Training loss: 2.021068572998047
Validation loss: 2.1462316436152302

Epoch: 5| Step: 5
Training loss: 2.872053384780884
Validation loss: 2.144689912437111

Epoch: 5| Step: 6
Training loss: 2.517801523208618
Validation loss: 2.1545827786127725

Epoch: 5| Step: 7
Training loss: 2.4138970375061035
Validation loss: 2.1481740782337804

Epoch: 5| Step: 8
Training loss: 2.3760688304901123
Validation loss: 2.1622496484428324

Epoch: 5| Step: 9
Training loss: 2.4693357944488525
Validation loss: 2.160417964381556

Epoch: 5| Step: 10
Training loss: 1.5115469694137573
Validation loss: 2.1692361344573317

Epoch: 233| Step: 0
Training loss: 2.1870250701904297
Validation loss: 2.179788181858678

Epoch: 5| Step: 1
Training loss: 2.4514031410217285
Validation loss: 2.1978901022224018

Epoch: 5| Step: 2
Training loss: 2.264535427093506
Validation loss: 2.214174670557822

Epoch: 5| Step: 3
Training loss: 1.9888598918914795
Validation loss: 2.2308304822573097

Epoch: 5| Step: 4
Training loss: 1.9488780498504639
Validation loss: 2.2371750441930627

Epoch: 5| Step: 5
Training loss: 2.0116660594940186
Validation loss: 2.2213909087642545

Epoch: 5| Step: 6
Training loss: 2.7437808513641357
Validation loss: 2.179793078412292

Epoch: 5| Step: 7
Training loss: 3.0582752227783203
Validation loss: 2.1622199063659995

Epoch: 5| Step: 8
Training loss: 2.0328378677368164
Validation loss: 2.146776362132001

Epoch: 5| Step: 9
Training loss: 2.7907612323760986
Validation loss: 2.1480886487550634

Epoch: 5| Step: 10
Training loss: 2.631282329559326
Validation loss: 2.1489453725917365

Epoch: 234| Step: 0
Training loss: 2.2736141681671143
Validation loss: 2.1420118924110167

Epoch: 5| Step: 1
Training loss: 2.287334680557251
Validation loss: 2.154856340859526

Epoch: 5| Step: 2
Training loss: 3.1111979484558105
Validation loss: 2.1460464000701904

Epoch: 5| Step: 3
Training loss: 2.341900587081909
Validation loss: 2.1488376996850453

Epoch: 5| Step: 4
Training loss: 2.5518460273742676
Validation loss: 2.143124349655644

Epoch: 5| Step: 5
Training loss: 1.9150079488754272
Validation loss: 2.140532306445542

Epoch: 5| Step: 6
Training loss: 2.1929996013641357
Validation loss: 2.1310223943443707

Epoch: 5| Step: 7
Training loss: 1.8835983276367188
Validation loss: 2.1304644243691557

Epoch: 5| Step: 8
Training loss: 2.1898155212402344
Validation loss: 2.1348008186586442

Epoch: 5| Step: 9
Training loss: 2.3674557209014893
Validation loss: 2.1234818376520628

Epoch: 5| Step: 10
Training loss: 2.7817206382751465
Validation loss: 2.131950878327893

Epoch: 235| Step: 0
Training loss: 2.669093370437622
Validation loss: 2.139762254171474

Epoch: 5| Step: 1
Training loss: 2.4184823036193848
Validation loss: 2.142836527157855

Epoch: 5| Step: 2
Training loss: 2.523726463317871
Validation loss: 2.1456802698873703

Epoch: 5| Step: 3
Training loss: 2.6698031425476074
Validation loss: 2.1522560478538595

Epoch: 5| Step: 4
Training loss: 2.020359754562378
Validation loss: 2.1683641825952837

Epoch: 5| Step: 5
Training loss: 1.9047057628631592
Validation loss: 2.1573680793085406

Epoch: 5| Step: 6
Training loss: 1.9986050128936768
Validation loss: 2.16786685041202

Epoch: 5| Step: 7
Training loss: 2.6373097896575928
Validation loss: 2.178247336418398

Epoch: 5| Step: 8
Training loss: 1.8831077814102173
Validation loss: 2.1771155454779185

Epoch: 5| Step: 9
Training loss: 2.415701389312744
Validation loss: 2.1614769517734485

Epoch: 5| Step: 10
Training loss: 2.8089752197265625
Validation loss: 2.1659142560856317

Epoch: 236| Step: 0
Training loss: 2.0818469524383545
Validation loss: 2.15182856205971

Epoch: 5| Step: 1
Training loss: 2.2470173835754395
Validation loss: 2.1377702502794165

Epoch: 5| Step: 2
Training loss: 2.6943259239196777
Validation loss: 2.1385085787824405

Epoch: 5| Step: 3
Training loss: 2.475179672241211
Validation loss: 2.1323604660649456

Epoch: 5| Step: 4
Training loss: 2.166715145111084
Validation loss: 2.125337154634537

Epoch: 5| Step: 5
Training loss: 1.9931215047836304
Validation loss: 2.1117100228545485

Epoch: 5| Step: 6
Training loss: 2.589195728302002
Validation loss: 2.1189506874289563

Epoch: 5| Step: 7
Training loss: 2.970014810562134
Validation loss: 2.1170233449628277

Epoch: 5| Step: 8
Training loss: 2.075744390487671
Validation loss: 2.1309699666115547

Epoch: 5| Step: 9
Training loss: 2.319373369216919
Validation loss: 2.124646936693499

Epoch: 5| Step: 10
Training loss: 2.2677829265594482
Validation loss: 2.123411370861915

Epoch: 237| Step: 0
Training loss: 2.5077145099639893
Validation loss: 2.1311408319780902

Epoch: 5| Step: 1
Training loss: 2.4901111125946045
Validation loss: 2.1366585403360348

Epoch: 5| Step: 2
Training loss: 2.6102538108825684
Validation loss: 2.1490653407189155

Epoch: 5| Step: 3
Training loss: 1.9828135967254639
Validation loss: 2.1549096774029475

Epoch: 5| Step: 4
Training loss: 2.3385891914367676
Validation loss: 2.1422348765916723

Epoch: 5| Step: 5
Training loss: 2.6043224334716797
Validation loss: 2.1465296437663417

Epoch: 5| Step: 6
Training loss: 1.9001582860946655
Validation loss: 2.1416650638785413

Epoch: 5| Step: 7
Training loss: 2.6394827365875244
Validation loss: 2.1281699249821324

Epoch: 5| Step: 8
Training loss: 2.319145679473877
Validation loss: 2.127843459447225

Epoch: 5| Step: 9
Training loss: 2.548896312713623
Validation loss: 2.1222236861464796

Epoch: 5| Step: 10
Training loss: 1.8391327857971191
Validation loss: 2.118794728350896

Epoch: 238| Step: 0
Training loss: 2.254100799560547
Validation loss: 2.1259933056369906

Epoch: 5| Step: 1
Training loss: 1.8902286291122437
Validation loss: 2.131262763853996

Epoch: 5| Step: 2
Training loss: 2.7741827964782715
Validation loss: 2.1354420236361924

Epoch: 5| Step: 3
Training loss: 2.4433276653289795
Validation loss: 2.132916327445738

Epoch: 5| Step: 4
Training loss: 1.6054681539535522
Validation loss: 2.1390569107506865

Epoch: 5| Step: 5
Training loss: 2.749330759048462
Validation loss: 2.1372204544723674

Epoch: 5| Step: 6
Training loss: 2.5313754081726074
Validation loss: 2.144202216978996

Epoch: 5| Step: 7
Training loss: 2.80999493598938
Validation loss: 2.150445081854379

Epoch: 5| Step: 8
Training loss: 2.8305087089538574
Validation loss: 2.1488758492213424

Epoch: 5| Step: 9
Training loss: 2.0189731121063232
Validation loss: 2.15473723283378

Epoch: 5| Step: 10
Training loss: 1.8257619142532349
Validation loss: 2.1663437043466875

Epoch: 239| Step: 0
Training loss: 2.677126169204712
Validation loss: 2.1761860873109553

Epoch: 5| Step: 1
Training loss: 2.4598259925842285
Validation loss: 2.177107561019159

Epoch: 5| Step: 2
Training loss: 2.339282274246216
Validation loss: 2.1607498866255566

Epoch: 5| Step: 3
Training loss: 2.7316596508026123
Validation loss: 2.1572734617417857

Epoch: 5| Step: 4
Training loss: 2.8456249237060547
Validation loss: 2.150940272115892

Epoch: 5| Step: 5
Training loss: 2.1229827404022217
Validation loss: 2.1453276744452854

Epoch: 5| Step: 6
Training loss: 2.390245199203491
Validation loss: 2.135030517014124

Epoch: 5| Step: 7
Training loss: 2.123696804046631
Validation loss: 2.12071132147184

Epoch: 5| Step: 8
Training loss: 1.5637205839157104
Validation loss: 2.1257245245800225

Epoch: 5| Step: 9
Training loss: 2.819760322570801
Validation loss: 2.1263656846938597

Epoch: 5| Step: 10
Training loss: 1.6856662034988403
Validation loss: 2.13021360417848

Epoch: 240| Step: 0
Training loss: 2.5892603397369385
Validation loss: 2.116041814127276

Epoch: 5| Step: 1
Training loss: 2.1297788619995117
Validation loss: 2.1275181308869393

Epoch: 5| Step: 2
Training loss: 2.67592453956604
Validation loss: 2.12446948277053

Epoch: 5| Step: 3
Training loss: 1.702471375465393
Validation loss: 2.1218163979950773

Epoch: 5| Step: 4
Training loss: 2.6261513233184814
Validation loss: 2.109647386817522

Epoch: 5| Step: 5
Training loss: 2.5930399894714355
Validation loss: 2.1165581864695393

Epoch: 5| Step: 6
Training loss: 2.0148119926452637
Validation loss: 2.128986479133688

Epoch: 5| Step: 7
Training loss: 2.121346950531006
Validation loss: 2.1162791149590605

Epoch: 5| Step: 8
Training loss: 2.416830539703369
Validation loss: 2.125649006136002

Epoch: 5| Step: 9
Training loss: 2.3018481731414795
Validation loss: 2.1172198762175856

Epoch: 5| Step: 10
Training loss: 2.6605796813964844
Validation loss: 2.133155624071757

Epoch: 241| Step: 0
Training loss: 1.8691298961639404
Validation loss: 2.1480191112846456

Epoch: 5| Step: 1
Training loss: 2.230578899383545
Validation loss: 2.144836938509377

Epoch: 5| Step: 2
Training loss: 2.399256467819214
Validation loss: 2.1473809390939693

Epoch: 5| Step: 3
Training loss: 3.2171688079833984
Validation loss: 2.164890076524468

Epoch: 5| Step: 4
Training loss: 2.3964622020721436
Validation loss: 2.161754767100016

Epoch: 5| Step: 5
Training loss: 2.7928435802459717
Validation loss: 2.158712979285948

Epoch: 5| Step: 6
Training loss: 2.1349778175354004
Validation loss: 2.141314612921848

Epoch: 5| Step: 7
Training loss: 2.4627628326416016
Validation loss: 2.1249058759340675

Epoch: 5| Step: 8
Training loss: 1.9885997772216797
Validation loss: 2.0955423065411147

Epoch: 5| Step: 9
Training loss: 2.452080011367798
Validation loss: 2.1093378118289414

Epoch: 5| Step: 10
Training loss: 1.7074005603790283
Validation loss: 2.103548606236776

Epoch: 242| Step: 0
Training loss: 2.7102508544921875
Validation loss: 2.114943192851159

Epoch: 5| Step: 1
Training loss: 2.5998260974884033
Validation loss: 2.0970261660955285

Epoch: 5| Step: 2
Training loss: 2.212400197982788
Validation loss: 2.1115344993529783

Epoch: 5| Step: 3
Training loss: 2.1809937953948975
Validation loss: 2.1225155284327846

Epoch: 5| Step: 4
Training loss: 2.6461944580078125
Validation loss: 2.143262949041141

Epoch: 5| Step: 5
Training loss: 2.6407318115234375
Validation loss: 2.1316721721362044

Epoch: 5| Step: 6
Training loss: 2.2981228828430176
Validation loss: 2.1518229310230543

Epoch: 5| Step: 7
Training loss: 2.1431093215942383
Validation loss: 2.15742019684084

Epoch: 5| Step: 8
Training loss: 2.1071979999542236
Validation loss: 2.1562579524132515

Epoch: 5| Step: 9
Training loss: 2.1577601432800293
Validation loss: 2.1554087695255073

Epoch: 5| Step: 10
Training loss: 2.2016632556915283
Validation loss: 2.1529081688132337

Epoch: 243| Step: 0
Training loss: 2.224594831466675
Validation loss: 2.1439089441812165

Epoch: 5| Step: 1
Training loss: 2.5976903438568115
Validation loss: 2.136153148066613

Epoch: 5| Step: 2
Training loss: 2.601762056350708
Validation loss: 2.1351323409747054

Epoch: 5| Step: 3
Training loss: 2.6932625770568848
Validation loss: 2.130364243702222

Epoch: 5| Step: 4
Training loss: 1.7553459405899048
Validation loss: 2.1378005499480874

Epoch: 5| Step: 5
Training loss: 2.1559276580810547
Validation loss: 2.1249038583488873

Epoch: 5| Step: 6
Training loss: 2.347827196121216
Validation loss: 2.1144689641973025

Epoch: 5| Step: 7
Training loss: 2.0760409832000732
Validation loss: 2.0982882912440965

Epoch: 5| Step: 8
Training loss: 2.2314553260803223
Validation loss: 2.1068373123804727

Epoch: 5| Step: 9
Training loss: 2.6721415519714355
Validation loss: 2.114609359413065

Epoch: 5| Step: 10
Training loss: 2.5438363552093506
Validation loss: 2.100738799700173

Epoch: 244| Step: 0
Training loss: 1.9920154809951782
Validation loss: 2.103070825658819

Epoch: 5| Step: 1
Training loss: 2.819958209991455
Validation loss: 2.112845955356475

Epoch: 5| Step: 2
Training loss: 2.4702975749969482
Validation loss: 2.1260059610489876

Epoch: 5| Step: 3
Training loss: 2.452655076980591
Validation loss: 2.1204473715956493

Epoch: 5| Step: 4
Training loss: 1.9492111206054688
Validation loss: 2.131889904699018

Epoch: 5| Step: 5
Training loss: 2.3001644611358643
Validation loss: 2.124262379061791

Epoch: 5| Step: 6
Training loss: 2.163335084915161
Validation loss: 2.1213446881181452

Epoch: 5| Step: 7
Training loss: 2.304349422454834
Validation loss: 2.1090138035435833

Epoch: 5| Step: 8
Training loss: 2.3114616870880127
Validation loss: 2.124838403476182

Epoch: 5| Step: 9
Training loss: 2.619725465774536
Validation loss: 2.1292264230789675

Epoch: 5| Step: 10
Training loss: 2.2160489559173584
Validation loss: 2.1254172325134277

Epoch: 245| Step: 0
Training loss: 2.12660813331604
Validation loss: 2.119980573654175

Epoch: 5| Step: 1
Training loss: 1.5262491703033447
Validation loss: 2.129138095404512

Epoch: 5| Step: 2
Training loss: 2.061723232269287
Validation loss: 2.1165235119481243

Epoch: 5| Step: 3
Training loss: 2.3868343830108643
Validation loss: 2.121260714787309

Epoch: 5| Step: 4
Training loss: 2.5724873542785645
Validation loss: 2.132336921589349

Epoch: 5| Step: 5
Training loss: 2.708662509918213
Validation loss: 2.1382611695156304

Epoch: 5| Step: 6
Training loss: 2.422849178314209
Validation loss: 2.1381926369923416

Epoch: 5| Step: 7
Training loss: 2.3674302101135254
Validation loss: 2.111774106179514

Epoch: 5| Step: 8
Training loss: 2.314826488494873
Validation loss: 2.120140255138438

Epoch: 5| Step: 9
Training loss: 2.1906158924102783
Validation loss: 2.1103343732895388

Epoch: 5| Step: 10
Training loss: 3.1045382022857666
Validation loss: 2.1023027896881104

Epoch: 246| Step: 0
Training loss: 2.3388214111328125
Validation loss: 2.0945346355438232

Epoch: 5| Step: 1
Training loss: 3.0016512870788574
Validation loss: 2.100611550833589

Epoch: 5| Step: 2
Training loss: 1.7128196954727173
Validation loss: 2.096100407262002

Epoch: 5| Step: 3
Training loss: 2.3738014698028564
Validation loss: 2.090604661613382

Epoch: 5| Step: 4
Training loss: 2.069214344024658
Validation loss: 2.1001224158912577

Epoch: 5| Step: 5
Training loss: 2.6798107624053955
Validation loss: 2.105081859455314

Epoch: 5| Step: 6
Training loss: 2.820709466934204
Validation loss: 2.1078119534318165

Epoch: 5| Step: 7
Training loss: 2.6881189346313477
Validation loss: 2.1158777590720885

Epoch: 5| Step: 8
Training loss: 1.9687353372573853
Validation loss: 2.135530138528475

Epoch: 5| Step: 9
Training loss: 1.988093376159668
Validation loss: 2.1376127786533807

Epoch: 5| Step: 10
Training loss: 2.0763425827026367
Validation loss: 2.130705230979509

Epoch: 247| Step: 0
Training loss: 2.1102161407470703
Validation loss: 2.129417306633406

Epoch: 5| Step: 1
Training loss: 2.2107529640197754
Validation loss: 2.110498615490493

Epoch: 5| Step: 2
Training loss: 2.1024041175842285
Validation loss: 2.1150683382506013

Epoch: 5| Step: 3
Training loss: 1.6014206409454346
Validation loss: 2.1092214507441365

Epoch: 5| Step: 4
Training loss: 2.875822067260742
Validation loss: 2.1343297522555114

Epoch: 5| Step: 5
Training loss: 2.132429838180542
Validation loss: 2.1161054206150833

Epoch: 5| Step: 6
Training loss: 2.543747663497925
Validation loss: 2.0971904775147796

Epoch: 5| Step: 7
Training loss: 2.706697940826416
Validation loss: 2.0986740563505437

Epoch: 5| Step: 8
Training loss: 2.155628204345703
Validation loss: 2.092933693239766

Epoch: 5| Step: 9
Training loss: 2.367210865020752
Validation loss: 2.0901776911110006

Epoch: 5| Step: 10
Training loss: 2.7857937812805176
Validation loss: 2.096752699985299

Epoch: 248| Step: 0
Training loss: 1.9584894180297852
Validation loss: 2.095731540392804

Epoch: 5| Step: 1
Training loss: 1.9905818700790405
Validation loss: 2.1068957979961107

Epoch: 5| Step: 2
Training loss: 2.0806689262390137
Validation loss: 2.1145284380964053

Epoch: 5| Step: 3
Training loss: 2.607124090194702
Validation loss: 2.110510080091415

Epoch: 5| Step: 4
Training loss: 2.197993516921997
Validation loss: 2.124003007847776

Epoch: 5| Step: 5
Training loss: 2.4229419231414795
Validation loss: 2.1157799343908987

Epoch: 5| Step: 6
Training loss: 2.039649486541748
Validation loss: 2.1179734583823913

Epoch: 5| Step: 7
Training loss: 2.5909900665283203
Validation loss: 2.129952851162162

Epoch: 5| Step: 8
Training loss: 2.731658458709717
Validation loss: 2.1106655905323644

Epoch: 5| Step: 9
Training loss: 2.5212254524230957
Validation loss: 2.1152291528640257

Epoch: 5| Step: 10
Training loss: 2.287322759628296
Validation loss: 2.10411766523956

Epoch: 249| Step: 0
Training loss: 2.1514081954956055
Validation loss: 2.10768025664873

Epoch: 5| Step: 1
Training loss: 2.133486270904541
Validation loss: 2.1005429119192143

Epoch: 5| Step: 2
Training loss: 2.4959540367126465
Validation loss: 2.119646110842305

Epoch: 5| Step: 3
Training loss: 1.570400595664978
Validation loss: 2.1309720239331646

Epoch: 5| Step: 4
Training loss: 2.9285058975219727
Validation loss: 2.1299026704603627

Epoch: 5| Step: 5
Training loss: 2.356874942779541
Validation loss: 2.1328799878397295

Epoch: 5| Step: 6
Training loss: 2.9176504611968994
Validation loss: 2.1418744312819613

Epoch: 5| Step: 7
Training loss: 2.188788890838623
Validation loss: 2.134562917934951

Epoch: 5| Step: 8
Training loss: 2.72152042388916
Validation loss: 2.119195081854379

Epoch: 5| Step: 9
Training loss: 2.047175168991089
Validation loss: 2.1045029240269817

Epoch: 5| Step: 10
Training loss: 1.7835969924926758
Validation loss: 2.1113000044258694

Epoch: 250| Step: 0
Training loss: 1.6403274536132812
Validation loss: 2.09178335948657

Epoch: 5| Step: 1
Training loss: 2.4784512519836426
Validation loss: 2.0936805996843564

Epoch: 5| Step: 2
Training loss: 2.1343483924865723
Validation loss: 2.100094004343915

Epoch: 5| Step: 3
Training loss: 2.090343475341797
Validation loss: 2.106608990700014

Epoch: 5| Step: 4
Training loss: 2.597562551498413
Validation loss: 2.099589151720847

Epoch: 5| Step: 5
Training loss: 2.7724177837371826
Validation loss: 2.11411807357624

Epoch: 5| Step: 6
Training loss: 2.007507085800171
Validation loss: 2.1119665151001303

Epoch: 5| Step: 7
Training loss: 2.5339202880859375
Validation loss: 2.1286631604676605

Epoch: 5| Step: 8
Training loss: 2.5306992530822754
Validation loss: 2.1377353975849767

Epoch: 5| Step: 9
Training loss: 2.619424343109131
Validation loss: 2.149134010396978

Epoch: 5| Step: 10
Training loss: 2.023966073989868
Validation loss: 2.1444467011318413

Epoch: 251| Step: 0
Training loss: 2.2122371196746826
Validation loss: 2.1453508536020913

Epoch: 5| Step: 1
Training loss: 1.7441085577011108
Validation loss: 2.1319099677506315

Epoch: 5| Step: 2
Training loss: 2.3674957752227783
Validation loss: 2.102192673631894

Epoch: 5| Step: 3
Training loss: 2.4329419136047363
Validation loss: 2.111368933031636

Epoch: 5| Step: 4
Training loss: 2.3103652000427246
Validation loss: 2.1087789381704023

Epoch: 5| Step: 5
Training loss: 2.1248488426208496
Validation loss: 2.0973546453701553

Epoch: 5| Step: 6
Training loss: 2.280364990234375
Validation loss: 2.1129926596918414

Epoch: 5| Step: 7
Training loss: 2.8389039039611816
Validation loss: 2.10155608705295

Epoch: 5| Step: 8
Training loss: 2.8787572383880615
Validation loss: 2.1102654190473658

Epoch: 5| Step: 9
Training loss: 2.372612237930298
Validation loss: 2.1090245400705645

Epoch: 5| Step: 10
Training loss: 1.8377701044082642
Validation loss: 2.11428383217063

Epoch: 252| Step: 0
Training loss: 2.6226322650909424
Validation loss: 2.117087423160512

Epoch: 5| Step: 1
Training loss: 2.1601510047912598
Validation loss: 2.119981993911087

Epoch: 5| Step: 2
Training loss: 2.2416255474090576
Validation loss: 2.121133230065787

Epoch: 5| Step: 3
Training loss: 2.2078232765197754
Validation loss: 2.140157994403634

Epoch: 5| Step: 4
Training loss: 1.9548025131225586
Validation loss: 2.175283037206178

Epoch: 5| Step: 5
Training loss: 1.9153341054916382
Validation loss: 2.167917738678635

Epoch: 5| Step: 6
Training loss: 2.3038392066955566
Validation loss: 2.1794303309532905

Epoch: 5| Step: 7
Training loss: 1.9197934865951538
Validation loss: 2.1752557626334568

Epoch: 5| Step: 8
Training loss: 3.111699342727661
Validation loss: 2.1531256757756716

Epoch: 5| Step: 9
Training loss: 2.149116039276123
Validation loss: 2.1545501755129908

Epoch: 5| Step: 10
Training loss: 3.008211135864258
Validation loss: 2.124846366143996

Epoch: 253| Step: 0
Training loss: 2.217501401901245
Validation loss: 2.1144012815208844

Epoch: 5| Step: 1
Training loss: 2.64566969871521
Validation loss: 2.1225778466911724

Epoch: 5| Step: 2
Training loss: 2.4296886920928955
Validation loss: 2.1082621210364887

Epoch: 5| Step: 3
Training loss: 1.969935655593872
Validation loss: 2.10334680157323

Epoch: 5| Step: 4
Training loss: 2.471799612045288
Validation loss: 2.1153290707577943

Epoch: 5| Step: 5
Training loss: 2.2272603511810303
Validation loss: 2.1054203100101923

Epoch: 5| Step: 6
Training loss: 2.544574737548828
Validation loss: 2.096148811360841

Epoch: 5| Step: 7
Training loss: 2.418087959289551
Validation loss: 2.1034249695398475

Epoch: 5| Step: 8
Training loss: 2.120007276535034
Validation loss: 2.1085159086411998

Epoch: 5| Step: 9
Training loss: 1.5899015665054321
Validation loss: 2.0920626681338073

Epoch: 5| Step: 10
Training loss: 2.8757615089416504
Validation loss: 2.093687762496292

Epoch: 254| Step: 0
Training loss: 2.473987579345703
Validation loss: 2.110483343883227

Epoch: 5| Step: 1
Training loss: 2.036719799041748
Validation loss: 2.1066433204117643

Epoch: 5| Step: 2
Training loss: 1.8345378637313843
Validation loss: 2.1016770896091255

Epoch: 5| Step: 3
Training loss: 2.3952481746673584
Validation loss: 2.108253868677283

Epoch: 5| Step: 4
Training loss: 2.2972960472106934
Validation loss: 2.0980268191265803

Epoch: 5| Step: 5
Training loss: 2.5577778816223145
Validation loss: 2.102767925108633

Epoch: 5| Step: 6
Training loss: 2.093945026397705
Validation loss: 2.116951434843002

Epoch: 5| Step: 7
Training loss: 2.707982301712036
Validation loss: 2.117891364200141

Epoch: 5| Step: 8
Training loss: 1.9294666051864624
Validation loss: 2.1254952761434738

Epoch: 5| Step: 9
Training loss: 2.4618124961853027
Validation loss: 2.1209012564792427

Epoch: 5| Step: 10
Training loss: 2.37493896484375
Validation loss: 2.114321292087596

Epoch: 255| Step: 0
Training loss: 2.826521873474121
Validation loss: 2.104305403206938

Epoch: 5| Step: 1
Training loss: 2.2060232162475586
Validation loss: 2.115715221692157

Epoch: 5| Step: 2
Training loss: 2.411351442337036
Validation loss: 2.121680035386034

Epoch: 5| Step: 3
Training loss: 2.8631768226623535
Validation loss: 2.1146603002343127

Epoch: 5| Step: 4
Training loss: 2.100283145904541
Validation loss: 2.1005843454791653

Epoch: 5| Step: 5
Training loss: 2.1035959720611572
Validation loss: 2.1054074020795923

Epoch: 5| Step: 6
Training loss: 2.0807433128356934
Validation loss: 2.113949950023364

Epoch: 5| Step: 7
Training loss: 1.844261884689331
Validation loss: 2.109571797873384

Epoch: 5| Step: 8
Training loss: 2.803882598876953
Validation loss: 2.1031631603035876

Epoch: 5| Step: 9
Training loss: 1.714914083480835
Validation loss: 2.107209713228287

Epoch: 5| Step: 10
Training loss: 2.1327154636383057
Validation loss: 2.1038182653406614

Epoch: 256| Step: 0
Training loss: 1.8578178882598877
Validation loss: 2.1217585661078013

Epoch: 5| Step: 1
Training loss: 2.774519443511963
Validation loss: 2.125822397970384

Epoch: 5| Step: 2
Training loss: 2.472012996673584
Validation loss: 2.136198553987729

Epoch: 5| Step: 3
Training loss: 2.0148608684539795
Validation loss: 2.14441579644398

Epoch: 5| Step: 4
Training loss: 2.363171100616455
Validation loss: 2.1693081035408923

Epoch: 5| Step: 5
Training loss: 2.534316062927246
Validation loss: 2.1766875174737748

Epoch: 5| Step: 6
Training loss: 2.559741735458374
Validation loss: 2.1476982101317375

Epoch: 5| Step: 7
Training loss: 1.8245446681976318
Validation loss: 2.1597338799507386

Epoch: 5| Step: 8
Training loss: 2.5042765140533447
Validation loss: 2.129105829423474

Epoch: 5| Step: 9
Training loss: 2.252260684967041
Validation loss: 2.1301873730074976

Epoch: 5| Step: 10
Training loss: 2.2313899993896484
Validation loss: 2.1149233643726637

Epoch: 257| Step: 0
Training loss: 1.843121886253357
Validation loss: 2.098342287924982

Epoch: 5| Step: 1
Training loss: 2.3132529258728027
Validation loss: 2.0925550332633396

Epoch: 5| Step: 2
Training loss: 1.7983207702636719
Validation loss: 2.0788426719686037

Epoch: 5| Step: 3
Training loss: 2.2529003620147705
Validation loss: 2.0971685481327835

Epoch: 5| Step: 4
Training loss: 2.2383170127868652
Validation loss: 2.1053798288427372

Epoch: 5| Step: 5
Training loss: 2.3839774131774902
Validation loss: 2.130647038900724

Epoch: 5| Step: 6
Training loss: 2.2342519760131836
Validation loss: 2.1062671330667313

Epoch: 5| Step: 7
Training loss: 3.415076494216919
Validation loss: 2.1283038303416264

Epoch: 5| Step: 8
Training loss: 2.821720600128174
Validation loss: 2.0912174845254548

Epoch: 5| Step: 9
Training loss: 2.097783327102661
Validation loss: 2.099276663154684

Epoch: 5| Step: 10
Training loss: 1.8302409648895264
Validation loss: 2.1043171087900796

Epoch: 258| Step: 0
Training loss: 2.4754505157470703
Validation loss: 2.0961691128310336

Epoch: 5| Step: 1
Training loss: 2.8383536338806152
Validation loss: 2.1029558181762695

Epoch: 5| Step: 2
Training loss: 2.4743998050689697
Validation loss: 2.112340288777505

Epoch: 5| Step: 3
Training loss: 2.370676279067993
Validation loss: 2.0958995652455155

Epoch: 5| Step: 4
Training loss: 1.743949294090271
Validation loss: 2.095814959977263

Epoch: 5| Step: 5
Training loss: 1.903752088546753
Validation loss: 2.0960603221770255

Epoch: 5| Step: 6
Training loss: 2.278031349182129
Validation loss: 2.0901708833632933

Epoch: 5| Step: 7
Training loss: 2.2338054180145264
Validation loss: 2.102048276573099

Epoch: 5| Step: 8
Training loss: 2.6979122161865234
Validation loss: 2.1018347342809043

Epoch: 5| Step: 9
Training loss: 2.271498203277588
Validation loss: 2.113334414779499

Epoch: 5| Step: 10
Training loss: 1.9108045101165771
Validation loss: 2.0840567645206245

Epoch: 259| Step: 0
Training loss: 2.6301074028015137
Validation loss: 2.088179011498728

Epoch: 5| Step: 1
Training loss: 2.4757273197174072
Validation loss: 2.096286386571905

Epoch: 5| Step: 2
Training loss: 1.950653076171875
Validation loss: 2.0787371012472335

Epoch: 5| Step: 3
Training loss: 2.6695306301116943
Validation loss: 2.0864514407291206

Epoch: 5| Step: 4
Training loss: 2.07379150390625
Validation loss: 2.0768611149121354

Epoch: 5| Step: 5
Training loss: 2.4667716026306152
Validation loss: 2.0846094008414977

Epoch: 5| Step: 6
Training loss: 2.399859666824341
Validation loss: 2.0685455773466375

Epoch: 5| Step: 7
Training loss: 2.2087032794952393
Validation loss: 2.0752619094746088

Epoch: 5| Step: 8
Training loss: 2.3517379760742188
Validation loss: 2.0952135798751668

Epoch: 5| Step: 9
Training loss: 2.189195156097412
Validation loss: 2.0914801884722967

Epoch: 5| Step: 10
Training loss: 1.533689260482788
Validation loss: 2.099358299727081

Epoch: 260| Step: 0
Training loss: 2.076585054397583
Validation loss: 2.098822298870292

Epoch: 5| Step: 1
Training loss: 2.7885921001434326
Validation loss: 2.0994399926995717

Epoch: 5| Step: 2
Training loss: 2.1088414192199707
Validation loss: 2.1089805838882283

Epoch: 5| Step: 3
Training loss: 1.9073419570922852
Validation loss: 2.1079760084870043

Epoch: 5| Step: 4
Training loss: 2.3052926063537598
Validation loss: 2.108060823973789

Epoch: 5| Step: 5
Training loss: 2.478782892227173
Validation loss: 2.1001299401765228

Epoch: 5| Step: 6
Training loss: 1.4621089696884155
Validation loss: 2.1122185581473896

Epoch: 5| Step: 7
Training loss: 2.4753355979919434
Validation loss: 2.0961244080656316

Epoch: 5| Step: 8
Training loss: 2.6397104263305664
Validation loss: 2.102686092417727

Epoch: 5| Step: 9
Training loss: 2.564265489578247
Validation loss: 2.111096715414396

Epoch: 5| Step: 10
Training loss: 2.3754477500915527
Validation loss: 2.112622864784733

Epoch: 261| Step: 0
Training loss: 2.4765360355377197
Validation loss: 2.112181213594252

Epoch: 5| Step: 1
Training loss: 1.7826223373413086
Validation loss: 2.103064948512662

Epoch: 5| Step: 2
Training loss: 1.8743959665298462
Validation loss: 2.101972956811228

Epoch: 5| Step: 3
Training loss: 2.2161474227905273
Validation loss: 2.1043924400883336

Epoch: 5| Step: 4
Training loss: 2.430161952972412
Validation loss: 2.1154465521535566

Epoch: 5| Step: 5
Training loss: 2.327627182006836
Validation loss: 2.1171306628052906

Epoch: 5| Step: 6
Training loss: 2.6289026737213135
Validation loss: 2.133653574092414

Epoch: 5| Step: 7
Training loss: 2.95402193069458
Validation loss: 2.1208953652330624

Epoch: 5| Step: 8
Training loss: 1.9539382457733154
Validation loss: 2.13823849667785

Epoch: 5| Step: 9
Training loss: 1.9253933429718018
Validation loss: 2.1175135784251715

Epoch: 5| Step: 10
Training loss: 2.676737070083618
Validation loss: 2.1210793423396286

Epoch: 262| Step: 0
Training loss: 2.4427943229675293
Validation loss: 2.1195675019294984

Epoch: 5| Step: 1
Training loss: 1.2506277561187744
Validation loss: 2.1219049269153225

Epoch: 5| Step: 2
Training loss: 1.798365831375122
Validation loss: 2.115624209885956

Epoch: 5| Step: 3
Training loss: 2.452157497406006
Validation loss: 2.1051004355953586

Epoch: 5| Step: 4
Training loss: 2.9653515815734863
Validation loss: 2.0912374604132866

Epoch: 5| Step: 5
Training loss: 2.371367931365967
Validation loss: 2.0867590955508653

Epoch: 5| Step: 6
Training loss: 2.3445773124694824
Validation loss: 2.0817347495786604

Epoch: 5| Step: 7
Training loss: 2.4651005268096924
Validation loss: 2.09734437798941

Epoch: 5| Step: 8
Training loss: 1.9721218347549438
Validation loss: 2.0974261581256823

Epoch: 5| Step: 9
Training loss: 2.2591235637664795
Validation loss: 2.107235013797719

Epoch: 5| Step: 10
Training loss: 2.83196759223938
Validation loss: 2.116625178244806

Epoch: 263| Step: 0
Training loss: 2.1279842853546143
Validation loss: 2.122254935644006

Epoch: 5| Step: 1
Training loss: 2.67073655128479
Validation loss: 2.1480477163868565

Epoch: 5| Step: 2
Training loss: 2.744661808013916
Validation loss: 2.1385365391290314

Epoch: 5| Step: 3
Training loss: 2.041149854660034
Validation loss: 2.1398837169011435

Epoch: 5| Step: 4
Training loss: 2.576845169067383
Validation loss: 2.137144507900361

Epoch: 5| Step: 5
Training loss: 2.1169040203094482
Validation loss: 2.132587586679766

Epoch: 5| Step: 6
Training loss: 2.3735203742980957
Validation loss: 2.141258855019846

Epoch: 5| Step: 7
Training loss: 2.0396735668182373
Validation loss: 2.1333609960412465

Epoch: 5| Step: 8
Training loss: 1.721666693687439
Validation loss: 2.1425318512865292

Epoch: 5| Step: 9
Training loss: 2.5276145935058594
Validation loss: 2.1309802814196517

Epoch: 5| Step: 10
Training loss: 2.3713996410369873
Validation loss: 2.1194236714352845

Epoch: 264| Step: 0
Training loss: 2.4199280738830566
Validation loss: 2.1101390956550516

Epoch: 5| Step: 1
Training loss: 1.9443466663360596
Validation loss: 2.0948287030701995

Epoch: 5| Step: 2
Training loss: 1.8893365859985352
Validation loss: 2.0912172768705632

Epoch: 5| Step: 3
Training loss: 2.4689927101135254
Validation loss: 2.0836117677791144

Epoch: 5| Step: 4
Training loss: 2.189511775970459
Validation loss: 2.078234358500409

Epoch: 5| Step: 5
Training loss: 1.9204576015472412
Validation loss: 2.0732719257313716

Epoch: 5| Step: 6
Training loss: 1.9474611282348633
Validation loss: 2.082664171854655

Epoch: 5| Step: 7
Training loss: 2.254181146621704
Validation loss: 2.072903517753847

Epoch: 5| Step: 8
Training loss: 2.5842692852020264
Validation loss: 2.089779684620519

Epoch: 5| Step: 9
Training loss: 2.4822051525115967
Validation loss: 2.090099109116421

Epoch: 5| Step: 10
Training loss: 3.05957293510437
Validation loss: 2.1018440146600046

Epoch: 265| Step: 0
Training loss: 2.2274246215820312
Validation loss: 2.097609099521432

Epoch: 5| Step: 1
Training loss: 2.488276720046997
Validation loss: 2.1141349577134654

Epoch: 5| Step: 2
Training loss: 1.646744966506958
Validation loss: 2.125393698292394

Epoch: 5| Step: 3
Training loss: 2.717607021331787
Validation loss: 2.136202612230855

Epoch: 5| Step: 4
Training loss: 2.685272693634033
Validation loss: 2.147603847647226

Epoch: 5| Step: 5
Training loss: 2.697371244430542
Validation loss: 2.134832038674303

Epoch: 5| Step: 6
Training loss: 1.6594346761703491
Validation loss: 2.1127727288071827

Epoch: 5| Step: 7
Training loss: 2.5015578269958496
Validation loss: 2.105106379396172

Epoch: 5| Step: 8
Training loss: 1.8048045635223389
Validation loss: 2.0839627327457553

Epoch: 5| Step: 9
Training loss: 1.8723570108413696
Validation loss: 2.0767600972165345

Epoch: 5| Step: 10
Training loss: 2.91171932220459
Validation loss: 2.072782554934102

Epoch: 266| Step: 0
Training loss: 2.2314038276672363
Validation loss: 2.0645738776012132

Epoch: 5| Step: 1
Training loss: 2.4850590229034424
Validation loss: 2.0756308878621748

Epoch: 5| Step: 2
Training loss: 2.2144672870635986
Validation loss: 2.06786520506746

Epoch: 5| Step: 3
Training loss: 2.208097219467163
Validation loss: 2.067738902184271

Epoch: 5| Step: 4
Training loss: 2.397254467010498
Validation loss: 2.0808875432578464

Epoch: 5| Step: 5
Training loss: 2.1666274070739746
Validation loss: 2.0773240417562504

Epoch: 5| Step: 6
Training loss: 2.1617374420166016
Validation loss: 2.074976687790245

Epoch: 5| Step: 7
Training loss: 2.236266613006592
Validation loss: 2.081020485970282

Epoch: 5| Step: 8
Training loss: 2.7040817737579346
Validation loss: 2.0929979021831224

Epoch: 5| Step: 9
Training loss: 2.8681349754333496
Validation loss: 2.08856172971828

Epoch: 5| Step: 10
Training loss: 1.53193998336792
Validation loss: 2.1119094074413343

Epoch: 267| Step: 0
Training loss: 2.9438624382019043
Validation loss: 2.1241562340849187

Epoch: 5| Step: 1
Training loss: 2.4221205711364746
Validation loss: 2.1294575686095865

Epoch: 5| Step: 2
Training loss: 2.3240158557891846
Validation loss: 2.1278270906017673

Epoch: 5| Step: 3
Training loss: 1.788205862045288
Validation loss: 2.109629196505393

Epoch: 5| Step: 4
Training loss: 2.036273717880249
Validation loss: 2.109253143751493

Epoch: 5| Step: 5
Training loss: 2.2468020915985107
Validation loss: 2.1093587695911364

Epoch: 5| Step: 6
Training loss: 1.796142578125
Validation loss: 2.1037425764145388

Epoch: 5| Step: 7
Training loss: 2.5879669189453125
Validation loss: 2.1045706297761653

Epoch: 5| Step: 8
Training loss: 2.40702486038208
Validation loss: 2.1003491417054208

Epoch: 5| Step: 9
Training loss: 2.7322001457214355
Validation loss: 2.0975641627465524

Epoch: 5| Step: 10
Training loss: 1.5930994749069214
Validation loss: 2.09794512871773

Epoch: 268| Step: 0
Training loss: 2.2149007320404053
Validation loss: 2.0916319329251527

Epoch: 5| Step: 1
Training loss: 2.1074118614196777
Validation loss: 2.0834966321145334

Epoch: 5| Step: 2
Training loss: 2.1008687019348145
Validation loss: 2.0962490189460015

Epoch: 5| Step: 3
Training loss: 2.2449822425842285
Validation loss: 2.1032252132251696

Epoch: 5| Step: 4
Training loss: 1.8728954792022705
Validation loss: 2.089151511910141

Epoch: 5| Step: 5
Training loss: 2.56071138381958
Validation loss: 2.1094664630069526

Epoch: 5| Step: 6
Training loss: 2.554654121398926
Validation loss: 2.1020481612092707

Epoch: 5| Step: 7
Training loss: 2.5493903160095215
Validation loss: 2.1119950714931695

Epoch: 5| Step: 8
Training loss: 1.5849475860595703
Validation loss: 2.107166131337484

Epoch: 5| Step: 9
Training loss: 2.9312920570373535
Validation loss: 2.112655373029811

Epoch: 5| Step: 10
Training loss: 2.2257237434387207
Validation loss: 2.1143733942380516

Epoch: 269| Step: 0
Training loss: 2.0140318870544434
Validation loss: 2.112457299745211

Epoch: 5| Step: 1
Training loss: 1.7828080654144287
Validation loss: 2.1069084444353656

Epoch: 5| Step: 2
Training loss: 2.753296375274658
Validation loss: 2.102629534659847

Epoch: 5| Step: 3
Training loss: 2.735393762588501
Validation loss: 2.088549901080388

Epoch: 5| Step: 4
Training loss: 1.7395532131195068
Validation loss: 2.0834946068384315

Epoch: 5| Step: 5
Training loss: 2.5653035640716553
Validation loss: 2.072672151750134

Epoch: 5| Step: 6
Training loss: 2.157125949859619
Validation loss: 2.0560438222782587

Epoch: 5| Step: 7
Training loss: 2.4359612464904785
Validation loss: 2.0635050612111248

Epoch: 5| Step: 8
Training loss: 2.4286820888519287
Validation loss: 2.0649091043779926

Epoch: 5| Step: 9
Training loss: 1.8993780612945557
Validation loss: 2.06707178649082

Epoch: 5| Step: 10
Training loss: 2.4215402603149414
Validation loss: 2.075720058974399

Epoch: 270| Step: 0
Training loss: 2.427582263946533
Validation loss: 2.0641287860049995

Epoch: 5| Step: 1
Training loss: 2.509399175643921
Validation loss: 2.089532111280708

Epoch: 5| Step: 2
Training loss: 2.1447761058807373
Validation loss: 2.1005414275712866

Epoch: 5| Step: 3
Training loss: 2.447814464569092
Validation loss: 2.100677171061116

Epoch: 5| Step: 4
Training loss: 2.414207696914673
Validation loss: 2.1096996902137675

Epoch: 5| Step: 5
Training loss: 2.591538667678833
Validation loss: 2.0992878919006674

Epoch: 5| Step: 6
Training loss: 1.9861772060394287
Validation loss: 2.11264988171157

Epoch: 5| Step: 7
Training loss: 1.9250507354736328
Validation loss: 2.0995688822961625

Epoch: 5| Step: 8
Training loss: 2.1996066570281982
Validation loss: 2.0914670716049852

Epoch: 5| Step: 9
Training loss: 2.264324188232422
Validation loss: 2.0925344536381383

Epoch: 5| Step: 10
Training loss: 2.019127130508423
Validation loss: 2.0900710551969466

Epoch: 271| Step: 0
Training loss: 2.401480197906494
Validation loss: 2.089643577093719

Epoch: 5| Step: 1
Training loss: 2.0168538093566895
Validation loss: 2.098012605021077

Epoch: 5| Step: 2
Training loss: 2.418294906616211
Validation loss: 2.100734482529343

Epoch: 5| Step: 3
Training loss: 2.897333860397339
Validation loss: 2.0942504739248626

Epoch: 5| Step: 4
Training loss: 2.3320298194885254
Validation loss: 2.090661379598802

Epoch: 5| Step: 5
Training loss: 2.8099582195281982
Validation loss: 2.094240644926666

Epoch: 5| Step: 6
Training loss: 1.8634166717529297
Validation loss: 2.109626352146108

Epoch: 5| Step: 7
Training loss: 1.9491955041885376
Validation loss: 2.1133806551656416

Epoch: 5| Step: 8
Training loss: 2.3921608924865723
Validation loss: 2.090073703437723

Epoch: 5| Step: 9
Training loss: 1.9609572887420654
Validation loss: 2.090250092168008

Epoch: 5| Step: 10
Training loss: 1.830693244934082
Validation loss: 2.0679839554653374

Epoch: 272| Step: 0
Training loss: 2.398242473602295
Validation loss: 2.0653674371780886

Epoch: 5| Step: 1
Training loss: 1.931945562362671
Validation loss: 2.0675964304195937

Epoch: 5| Step: 2
Training loss: 2.385693073272705
Validation loss: 2.0921165917509343

Epoch: 5| Step: 3
Training loss: 1.8205207586288452
Validation loss: 2.0891602834065757

Epoch: 5| Step: 4
Training loss: 2.3245341777801514
Validation loss: 2.1082271773328065

Epoch: 5| Step: 5
Training loss: 3.4057681560516357
Validation loss: 2.113702327974381

Epoch: 5| Step: 6
Training loss: 2.166093111038208
Validation loss: 2.112324783878942

Epoch: 5| Step: 7
Training loss: 2.339974880218506
Validation loss: 2.1048427089568107

Epoch: 5| Step: 8
Training loss: 1.7698371410369873
Validation loss: 2.1107169607634186

Epoch: 5| Step: 9
Training loss: 2.317595958709717
Validation loss: 2.099001540932604

Epoch: 5| Step: 10
Training loss: 2.1096184253692627
Validation loss: 2.089304465119557

Epoch: 273| Step: 0
Training loss: 2.3990674018859863
Validation loss: 2.076034294661655

Epoch: 5| Step: 1
Training loss: 2.65335750579834
Validation loss: 2.0919409080218245

Epoch: 5| Step: 2
Training loss: 1.9256559610366821
Validation loss: 2.0859496490929716

Epoch: 5| Step: 3
Training loss: 2.4250056743621826
Validation loss: 2.068774902692405

Epoch: 5| Step: 4
Training loss: 2.728553295135498
Validation loss: 2.07867943856024

Epoch: 5| Step: 5
Training loss: 2.3977770805358887
Validation loss: 2.0717119452773884

Epoch: 5| Step: 6
Training loss: 1.9393517971038818
Validation loss: 2.0896755315924205

Epoch: 5| Step: 7
Training loss: 2.2508292198181152
Validation loss: 2.1131595206517044

Epoch: 5| Step: 8
Training loss: 2.113102912902832
Validation loss: 2.121844158377699

Epoch: 5| Step: 9
Training loss: 2.1890177726745605
Validation loss: 2.1418283421506166

Epoch: 5| Step: 10
Training loss: 1.905925989151001
Validation loss: 2.1359619402116343

Epoch: 274| Step: 0
Training loss: 2.329958915710449
Validation loss: 2.11118051826313

Epoch: 5| Step: 1
Training loss: 1.890333890914917
Validation loss: 2.1172316100007746

Epoch: 5| Step: 2
Training loss: 2.3662009239196777
Validation loss: 2.1234737032203266

Epoch: 5| Step: 3
Training loss: 1.8933677673339844
Validation loss: 2.122940008358289

Epoch: 5| Step: 4
Training loss: 2.6784439086914062
Validation loss: 2.122795033198531

Epoch: 5| Step: 5
Training loss: 2.4179439544677734
Validation loss: 2.1245861643104145

Epoch: 5| Step: 6
Training loss: 2.5315186977386475
Validation loss: 2.1165793749593917

Epoch: 5| Step: 7
Training loss: 1.9387840032577515
Validation loss: 2.1074166810640724

Epoch: 5| Step: 8
Training loss: 1.9048306941986084
Validation loss: 2.0950667601759716

Epoch: 5| Step: 9
Training loss: 2.1796629428863525
Validation loss: 2.107659201468191

Epoch: 5| Step: 10
Training loss: 2.9075350761413574
Validation loss: 2.082917631313365

Epoch: 275| Step: 0
Training loss: 2.4560182094573975
Validation loss: 2.0779198779854724

Epoch: 5| Step: 1
Training loss: 2.2193827629089355
Validation loss: 2.0775478988565426

Epoch: 5| Step: 2
Training loss: 2.8538119792938232
Validation loss: 2.085518043528321

Epoch: 5| Step: 3
Training loss: 2.3610949516296387
Validation loss: 2.0700670673001196

Epoch: 5| Step: 4
Training loss: 2.1026220321655273
Validation loss: 2.069451658956466

Epoch: 5| Step: 5
Training loss: 2.4501938819885254
Validation loss: 2.055400950934297

Epoch: 5| Step: 6
Training loss: 1.7840166091918945
Validation loss: 2.0562653028836815

Epoch: 5| Step: 7
Training loss: 2.338160753250122
Validation loss: 2.060412069802643

Epoch: 5| Step: 8
Training loss: 2.3340041637420654
Validation loss: 2.0600583732769056

Epoch: 5| Step: 9
Training loss: 1.8744075298309326
Validation loss: 2.0804429464442755

Epoch: 5| Step: 10
Training loss: 2.122546434402466
Validation loss: 2.0883527366063928

Epoch: 276| Step: 0
Training loss: 2.355515956878662
Validation loss: 2.1028916681966474

Epoch: 5| Step: 1
Training loss: 2.1423144340515137
Validation loss: 2.0974582959246892

Epoch: 5| Step: 2
Training loss: 2.3874621391296387
Validation loss: 2.097157234786659

Epoch: 5| Step: 3
Training loss: 1.7066959142684937
Validation loss: 2.1102609634399414

Epoch: 5| Step: 4
Training loss: 1.8389641046524048
Validation loss: 2.0860655948679936

Epoch: 5| Step: 5
Training loss: 1.8133903741836548
Validation loss: 2.0869375710846274

Epoch: 5| Step: 6
Training loss: 2.5368847846984863
Validation loss: 2.0895203210974254

Epoch: 5| Step: 7
Training loss: 2.1727001667022705
Validation loss: 2.0782939028996292

Epoch: 5| Step: 8
Training loss: 3.090421438217163
Validation loss: 2.0898322597626717

Epoch: 5| Step: 9
Training loss: 2.3140645027160645
Validation loss: 2.0712825290618406

Epoch: 5| Step: 10
Training loss: 2.422952651977539
Validation loss: 2.0767150284141622

Epoch: 277| Step: 0
Training loss: 2.2466864585876465
Validation loss: 2.087601346354331

Epoch: 5| Step: 1
Training loss: 2.3718016147613525
Validation loss: 2.0853706380372405

Epoch: 5| Step: 2
Training loss: 1.8441680669784546
Validation loss: 2.072375383428348

Epoch: 5| Step: 3
Training loss: 1.847208023071289
Validation loss: 2.0854187434719456

Epoch: 5| Step: 4
Training loss: 2.6617722511291504
Validation loss: 2.0817580466629355

Epoch: 5| Step: 5
Training loss: 2.471449613571167
Validation loss: 2.0704122884299165

Epoch: 5| Step: 6
Training loss: 2.435917377471924
Validation loss: 2.075398665602489

Epoch: 5| Step: 7
Training loss: 2.071516752243042
Validation loss: 2.072651083751391

Epoch: 5| Step: 8
Training loss: 2.382582187652588
Validation loss: 2.0714220564852477

Epoch: 5| Step: 9
Training loss: 2.24731183052063
Validation loss: 2.072266209510065

Epoch: 5| Step: 10
Training loss: 2.2809085845947266
Validation loss: 2.0660850322374733

Epoch: 278| Step: 0
Training loss: 2.2657909393310547
Validation loss: 2.0649237517387635

Epoch: 5| Step: 1
Training loss: 2.6968860626220703
Validation loss: 2.0715223409796275

Epoch: 5| Step: 2
Training loss: 2.098588466644287
Validation loss: 2.069286759181689

Epoch: 5| Step: 3
Training loss: 2.2509896755218506
Validation loss: 2.0792478181982554

Epoch: 5| Step: 4
Training loss: 2.3871688842773438
Validation loss: 2.08897763939314

Epoch: 5| Step: 5
Training loss: 2.405526876449585
Validation loss: 2.1038175782849713

Epoch: 5| Step: 6
Training loss: 2.0621390342712402
Validation loss: 2.1184174194130847

Epoch: 5| Step: 7
Training loss: 1.702399492263794
Validation loss: 2.1208555211303053

Epoch: 5| Step: 8
Training loss: 2.4309186935424805
Validation loss: 2.1159464877138854

Epoch: 5| Step: 9
Training loss: 2.5869386196136475
Validation loss: 2.0972784385886243

Epoch: 5| Step: 10
Training loss: 1.85759699344635
Validation loss: 2.073464109051612

Epoch: 279| Step: 0
Training loss: 2.2967262268066406
Validation loss: 2.0980204100249917

Epoch: 5| Step: 1
Training loss: 2.0875160694122314
Validation loss: 2.0859117559207383

Epoch: 5| Step: 2
Training loss: 1.896421194076538
Validation loss: 2.0841983877202517

Epoch: 5| Step: 3
Training loss: 2.289459705352783
Validation loss: 2.0918659394787205

Epoch: 5| Step: 4
Training loss: 2.3308568000793457
Validation loss: 2.086053409884053

Epoch: 5| Step: 5
Training loss: 2.6143441200256348
Validation loss: 2.0791104070601927

Epoch: 5| Step: 6
Training loss: 2.37514328956604
Validation loss: 2.08294334719258

Epoch: 5| Step: 7
Training loss: 2.4222607612609863
Validation loss: 2.0849984204897316

Epoch: 5| Step: 8
Training loss: 2.3893847465515137
Validation loss: 2.0782773212719987

Epoch: 5| Step: 9
Training loss: 1.960193395614624
Validation loss: 2.0763210840122674

Epoch: 5| Step: 10
Training loss: 2.059957504272461
Validation loss: 2.0838307885713476

Epoch: 280| Step: 0
Training loss: 2.2577693462371826
Validation loss: 2.0857888754977973

Epoch: 5| Step: 1
Training loss: 2.076568603515625
Validation loss: 2.093507766723633

Epoch: 5| Step: 2
Training loss: 2.2696385383605957
Validation loss: 2.101005619572055

Epoch: 5| Step: 3
Training loss: 2.2056326866149902
Validation loss: 2.0996592711376887

Epoch: 5| Step: 4
Training loss: 2.3828306198120117
Validation loss: 2.10401048198823

Epoch: 5| Step: 5
Training loss: 2.2109668254852295
Validation loss: 2.0819960589049966

Epoch: 5| Step: 6
Training loss: 1.709619164466858
Validation loss: 2.0829451417410247

Epoch: 5| Step: 7
Training loss: 2.2881312370300293
Validation loss: 2.085820667205318

Epoch: 5| Step: 8
Training loss: 2.4281420707702637
Validation loss: 2.0864547144982124

Epoch: 5| Step: 9
Training loss: 2.6426327228546143
Validation loss: 2.08311898990344

Epoch: 5| Step: 10
Training loss: 2.1007323265075684
Validation loss: 2.089499583808325

Epoch: 281| Step: 0
Training loss: 1.913511037826538
Validation loss: 2.092625723090223

Epoch: 5| Step: 1
Training loss: 2.2341055870056152
Validation loss: 2.093689674972206

Epoch: 5| Step: 2
Training loss: 1.6999107599258423
Validation loss: 2.09493415458228

Epoch: 5| Step: 3
Training loss: 2.166780471801758
Validation loss: 2.0815141354837725

Epoch: 5| Step: 4
Training loss: 2.3083629608154297
Validation loss: 2.0793367867828696

Epoch: 5| Step: 5
Training loss: 1.9011814594268799
Validation loss: 2.107523318259947

Epoch: 5| Step: 6
Training loss: 2.034095048904419
Validation loss: 2.109570002043119

Epoch: 5| Step: 7
Training loss: 2.5300590991973877
Validation loss: 2.1085227227980092

Epoch: 5| Step: 8
Training loss: 2.65834641456604
Validation loss: 2.126513606758528

Epoch: 5| Step: 9
Training loss: 2.814134120941162
Validation loss: 2.1127039104379635

Epoch: 5| Step: 10
Training loss: 2.542595386505127
Validation loss: 2.09117986566277

Epoch: 282| Step: 0
Training loss: 2.3120779991149902
Validation loss: 2.090387803252025

Epoch: 5| Step: 1
Training loss: 2.955174207687378
Validation loss: 2.090837763201806

Epoch: 5| Step: 2
Training loss: 2.0022387504577637
Validation loss: 2.0939517046815608

Epoch: 5| Step: 3
Training loss: 1.96964430809021
Validation loss: 2.076520694199429

Epoch: 5| Step: 4
Training loss: 2.603569984436035
Validation loss: 2.069312157169465

Epoch: 5| Step: 5
Training loss: 2.2585041522979736
Validation loss: 2.0700362369578373

Epoch: 5| Step: 6
Training loss: 1.9112536907196045
Validation loss: 2.0654506196257887

Epoch: 5| Step: 7
Training loss: 2.589709997177124
Validation loss: 2.054368990723805

Epoch: 5| Step: 8
Training loss: 2.7888236045837402
Validation loss: 2.0672019245803996

Epoch: 5| Step: 9
Training loss: 1.7090728282928467
Validation loss: 2.062929803325284

Epoch: 5| Step: 10
Training loss: 1.521932601928711
Validation loss: 2.0684648867576354

Epoch: 283| Step: 0
Training loss: 2.623988389968872
Validation loss: 2.075312324749526

Epoch: 5| Step: 1
Training loss: 2.1337785720825195
Validation loss: 2.0756026890970047

Epoch: 5| Step: 2
Training loss: 2.0875182151794434
Validation loss: 2.0728427671617076

Epoch: 5| Step: 3
Training loss: 1.9053274393081665
Validation loss: 2.084043813008134

Epoch: 5| Step: 4
Training loss: 2.1190989017486572
Validation loss: 2.0922419230143228

Epoch: 5| Step: 5
Training loss: 1.9131063222885132
Validation loss: 2.104052374439855

Epoch: 5| Step: 6
Training loss: 2.480191469192505
Validation loss: 2.101935237966558

Epoch: 5| Step: 7
Training loss: 1.937809944152832
Validation loss: 2.109104610258533

Epoch: 5| Step: 8
Training loss: 2.175327777862549
Validation loss: 2.1051016802428872

Epoch: 5| Step: 9
Training loss: 2.5677595138549805
Validation loss: 2.102526859570575

Epoch: 5| Step: 10
Training loss: 2.8153746128082275
Validation loss: 2.0961691717947684

Epoch: 284| Step: 0
Training loss: 1.9822056293487549
Validation loss: 2.077379736849057

Epoch: 5| Step: 1
Training loss: 1.666067361831665
Validation loss: 2.082138248669204

Epoch: 5| Step: 2
Training loss: 2.151970386505127
Validation loss: 2.0713460906859367

Epoch: 5| Step: 3
Training loss: 2.2870051860809326
Validation loss: 2.0753938100671254

Epoch: 5| Step: 4
Training loss: 2.701625347137451
Validation loss: 2.0757714445872972

Epoch: 5| Step: 5
Training loss: 1.8476356267929077
Validation loss: 2.0767620840380268

Epoch: 5| Step: 6
Training loss: 2.5242371559143066
Validation loss: 2.0801533370889644

Epoch: 5| Step: 7
Training loss: 2.675110340118408
Validation loss: 2.0863020022710166

Epoch: 5| Step: 8
Training loss: 1.905430555343628
Validation loss: 2.085084888242906

Epoch: 5| Step: 9
Training loss: 2.3889472484588623
Validation loss: 2.102401020706341

Epoch: 5| Step: 10
Training loss: 2.435925006866455
Validation loss: 2.1047014395395913

Epoch: 285| Step: 0
Training loss: 1.8841367959976196
Validation loss: 2.1080912672063357

Epoch: 5| Step: 1
Training loss: 2.5120255947113037
Validation loss: 2.115558442249093

Epoch: 5| Step: 2
Training loss: 2.215773105621338
Validation loss: 2.1220624216141237

Epoch: 5| Step: 3
Training loss: 2.1626782417297363
Validation loss: 2.107645211681243

Epoch: 5| Step: 4
Training loss: 2.766414165496826
Validation loss: 2.0977140152326195

Epoch: 5| Step: 5
Training loss: 2.224160671234131
Validation loss: 2.0820242204973773

Epoch: 5| Step: 6
Training loss: 2.7465415000915527
Validation loss: 2.080545053687147

Epoch: 5| Step: 7
Training loss: 1.9193077087402344
Validation loss: 2.0762540589096727

Epoch: 5| Step: 8
Training loss: 1.9916330575942993
Validation loss: 2.0688681781932874

Epoch: 5| Step: 9
Training loss: 2.1383140087127686
Validation loss: 2.0769189814085602

Epoch: 5| Step: 10
Training loss: 2.0850212574005127
Validation loss: 2.0579961935679116

Epoch: 286| Step: 0
Training loss: 2.6801841259002686
Validation loss: 2.086135466893514

Epoch: 5| Step: 1
Training loss: 2.1886181831359863
Validation loss: 2.0736552976792857

Epoch: 5| Step: 2
Training loss: 2.0028908252716064
Validation loss: 2.0914977660743137

Epoch: 5| Step: 3
Training loss: 1.9444637298583984
Validation loss: 2.1068829285201205

Epoch: 5| Step: 4
Training loss: 1.95291006565094
Validation loss: 2.0900555887529926

Epoch: 5| Step: 5
Training loss: 2.067164182662964
Validation loss: 2.089982327594552

Epoch: 5| Step: 6
Training loss: 2.081861734390259
Validation loss: 2.0958162661521667

Epoch: 5| Step: 7
Training loss: 2.4930977821350098
Validation loss: 2.075768196454612

Epoch: 5| Step: 8
Training loss: 2.439366102218628
Validation loss: 2.0819314731064664

Epoch: 5| Step: 9
Training loss: 2.1884613037109375
Validation loss: 2.079888338683754

Epoch: 5| Step: 10
Training loss: 2.474501609802246
Validation loss: 2.081610389935073

Epoch: 287| Step: 0
Training loss: 2.2262587547302246
Validation loss: 2.075519113130467

Epoch: 5| Step: 1
Training loss: 2.1682753562927246
Validation loss: 2.0667213470705095

Epoch: 5| Step: 2
Training loss: 2.1716957092285156
Validation loss: 2.06898622487181

Epoch: 5| Step: 3
Training loss: 2.213895320892334
Validation loss: 2.0849738005668885

Epoch: 5| Step: 4
Training loss: 2.065317153930664
Validation loss: 2.064593017742198

Epoch: 5| Step: 5
Training loss: 2.1794722080230713
Validation loss: 2.0788512845193186

Epoch: 5| Step: 6
Training loss: 2.5542335510253906
Validation loss: 2.0787906877456175

Epoch: 5| Step: 7
Training loss: 1.7395766973495483
Validation loss: 2.0751582627655356

Epoch: 5| Step: 8
Training loss: 2.949169397354126
Validation loss: 2.068093776702881

Epoch: 5| Step: 9
Training loss: 2.2275032997131348
Validation loss: 2.079070229684153

Epoch: 5| Step: 10
Training loss: 1.934051275253296
Validation loss: 2.0795494817918345

Epoch: 288| Step: 0
Training loss: 2.1167690753936768
Validation loss: 2.0884908399274273

Epoch: 5| Step: 1
Training loss: 2.8494772911071777
Validation loss: 2.078416719231554

Epoch: 5| Step: 2
Training loss: 2.0319156646728516
Validation loss: 2.080260490858427

Epoch: 5| Step: 3
Training loss: 2.3298847675323486
Validation loss: 2.0829612055132465

Epoch: 5| Step: 4
Training loss: 1.6893593072891235
Validation loss: 2.081301135401572

Epoch: 5| Step: 5
Training loss: 2.4714035987854004
Validation loss: 2.0853986817021526

Epoch: 5| Step: 6
Training loss: 2.143465042114258
Validation loss: 2.088141210617558

Epoch: 5| Step: 7
Training loss: 2.1621780395507812
Validation loss: 2.086050869316183

Epoch: 5| Step: 8
Training loss: 2.370927333831787
Validation loss: 2.084157086187793

Epoch: 5| Step: 9
Training loss: 2.2444229125976562
Validation loss: 2.0929931056114937

Epoch: 5| Step: 10
Training loss: 2.005462169647217
Validation loss: 2.0820685227711997

Epoch: 289| Step: 0
Training loss: 2.413588762283325
Validation loss: 2.08992350229653

Epoch: 5| Step: 1
Training loss: 1.9431304931640625
Validation loss: 2.089738133133099

Epoch: 5| Step: 2
Training loss: 2.077373743057251
Validation loss: 2.0884268770935717

Epoch: 5| Step: 3
Training loss: 2.5822434425354004
Validation loss: 2.0851073316348496

Epoch: 5| Step: 4
Training loss: 2.256530284881592
Validation loss: 2.0772075422348513

Epoch: 5| Step: 5
Training loss: 2.2443900108337402
Validation loss: 2.0760687435826948

Epoch: 5| Step: 6
Training loss: 2.2158193588256836
Validation loss: 2.078865049987711

Epoch: 5| Step: 7
Training loss: 1.927880048751831
Validation loss: 2.085540799684422

Epoch: 5| Step: 8
Training loss: 1.9961450099945068
Validation loss: 2.0886973668170232

Epoch: 5| Step: 9
Training loss: 2.37742280960083
Validation loss: 2.1000497418065227

Epoch: 5| Step: 10
Training loss: 2.318357467651367
Validation loss: 2.09394843347611

Epoch: 290| Step: 0
Training loss: 1.950720191001892
Validation loss: 2.082727029759397

Epoch: 5| Step: 1
Training loss: 2.0482583045959473
Validation loss: 2.0818697073126353

Epoch: 5| Step: 2
Training loss: 2.45691180229187
Validation loss: 2.0940840987749

Epoch: 5| Step: 3
Training loss: 1.7575385570526123
Validation loss: 2.0735426692552466

Epoch: 5| Step: 4
Training loss: 2.108931303024292
Validation loss: 2.0857993928335046

Epoch: 5| Step: 5
Training loss: 1.9450578689575195
Validation loss: 2.0848589879210278

Epoch: 5| Step: 6
Training loss: 2.445621967315674
Validation loss: 2.086919839664172

Epoch: 5| Step: 7
Training loss: 2.7833123207092285
Validation loss: 2.089435374864968

Epoch: 5| Step: 8
Training loss: 2.318136692047119
Validation loss: 2.0756039901446273

Epoch: 5| Step: 9
Training loss: 1.9696975946426392
Validation loss: 2.076880607553708

Epoch: 5| Step: 10
Training loss: 2.6982388496398926
Validation loss: 2.0690715543685423

Epoch: 291| Step: 0
Training loss: 2.732250928878784
Validation loss: 2.092184470545861

Epoch: 5| Step: 1
Training loss: 2.805751323699951
Validation loss: 2.093133326499693

Epoch: 5| Step: 2
Training loss: 1.5734049081802368
Validation loss: 2.078742145210184

Epoch: 5| Step: 3
Training loss: 1.6628509759902954
Validation loss: 2.0750428322822816

Epoch: 5| Step: 4
Training loss: 1.9535808563232422
Validation loss: 2.075848234597073

Epoch: 5| Step: 5
Training loss: 2.989652633666992
Validation loss: 2.0784903008450746

Epoch: 5| Step: 6
Training loss: 2.1663641929626465
Validation loss: 2.0749263686518513

Epoch: 5| Step: 7
Training loss: 2.386866807937622
Validation loss: 2.068081776301066

Epoch: 5| Step: 8
Training loss: 2.03096342086792
Validation loss: 2.067789908378355

Epoch: 5| Step: 9
Training loss: 1.8673985004425049
Validation loss: 2.0849683592396397

Epoch: 5| Step: 10
Training loss: 2.2535181045532227
Validation loss: 2.0911482790464997

Epoch: 292| Step: 0
Training loss: 2.038623332977295
Validation loss: 2.093585414271201

Epoch: 5| Step: 1
Training loss: 2.0013396739959717
Validation loss: 2.094375151459889

Epoch: 5| Step: 2
Training loss: 1.793927788734436
Validation loss: 2.1230566783617904

Epoch: 5| Step: 3
Training loss: 2.322277545928955
Validation loss: 2.129126020657119

Epoch: 5| Step: 4
Training loss: 1.476615309715271
Validation loss: 2.1365049756983274

Epoch: 5| Step: 5
Training loss: 2.612426280975342
Validation loss: 2.150551626759191

Epoch: 5| Step: 6
Training loss: 2.927976131439209
Validation loss: 2.1217939135848836

Epoch: 5| Step: 7
Training loss: 2.130375623703003
Validation loss: 2.1183642905245543

Epoch: 5| Step: 8
Training loss: 2.540433406829834
Validation loss: 2.07890232147709

Epoch: 5| Step: 9
Training loss: 2.667214870452881
Validation loss: 2.086776005324497

Epoch: 5| Step: 10
Training loss: 1.931193232536316
Validation loss: 2.078099719939693

Epoch: 293| Step: 0
Training loss: 2.8383736610412598
Validation loss: 2.0654665577796196

Epoch: 5| Step: 1
Training loss: 2.238434314727783
Validation loss: 2.079252632715369

Epoch: 5| Step: 2
Training loss: 2.0393729209899902
Validation loss: 2.061289615528558

Epoch: 5| Step: 3
Training loss: 1.8850104808807373
Validation loss: 2.072974302435434

Epoch: 5| Step: 4
Training loss: 1.8018829822540283
Validation loss: 2.067739919949603

Epoch: 5| Step: 5
Training loss: 2.118013620376587
Validation loss: 2.0834411933857906

Epoch: 5| Step: 6
Training loss: 2.4838833808898926
Validation loss: 2.090859672074677

Epoch: 5| Step: 7
Training loss: 2.0383706092834473
Validation loss: 2.0882546106974282

Epoch: 5| Step: 8
Training loss: 2.7886695861816406
Validation loss: 2.096044736523782

Epoch: 5| Step: 9
Training loss: 2.1661789417266846
Validation loss: 2.0835155851097515

Epoch: 5| Step: 10
Training loss: 1.8857520818710327
Validation loss: 2.096440342164809

Epoch: 294| Step: 0
Training loss: 2.67221736907959
Validation loss: 2.0834574981402327

Epoch: 5| Step: 1
Training loss: 2.744553804397583
Validation loss: 2.0732664703040995

Epoch: 5| Step: 2
Training loss: 1.8487999439239502
Validation loss: 2.0820177062865226

Epoch: 5| Step: 3
Training loss: 2.1811490058898926
Validation loss: 2.0732838851149364

Epoch: 5| Step: 4
Training loss: 2.3675074577331543
Validation loss: 2.054634263438563

Epoch: 5| Step: 5
Training loss: 1.7072229385375977
Validation loss: 2.06826969885057

Epoch: 5| Step: 6
Training loss: 1.5625829696655273
Validation loss: 2.0584887945523827

Epoch: 5| Step: 7
Training loss: 2.653061628341675
Validation loss: 2.0508859747199604

Epoch: 5| Step: 8
Training loss: 2.1267268657684326
Validation loss: 2.0627447148805023

Epoch: 5| Step: 9
Training loss: 2.573570966720581
Validation loss: 2.0670916854694323

Epoch: 5| Step: 10
Training loss: 1.7632583379745483
Validation loss: 2.0828030916952316

Epoch: 295| Step: 0
Training loss: 1.7351726293563843
Validation loss: 2.0963564201067855

Epoch: 5| Step: 1
Training loss: 1.8575680255889893
Validation loss: 2.102454939196187

Epoch: 5| Step: 2
Training loss: 1.9042469263076782
Validation loss: 2.112239591536983

Epoch: 5| Step: 3
Training loss: 2.4063563346862793
Validation loss: 2.0990675931335776

Epoch: 5| Step: 4
Training loss: 2.8538355827331543
Validation loss: 2.109532040934409

Epoch: 5| Step: 5
Training loss: 2.2237939834594727
Validation loss: 2.0933555633791032

Epoch: 5| Step: 6
Training loss: 2.5614452362060547
Validation loss: 2.1036283713515087

Epoch: 5| Step: 7
Training loss: 2.3397936820983887
Validation loss: 2.084480066453257

Epoch: 5| Step: 8
Training loss: 2.696810245513916
Validation loss: 2.073141631259713

Epoch: 5| Step: 9
Training loss: 1.8092845678329468
Validation loss: 2.0951085359819475

Epoch: 5| Step: 10
Training loss: 1.8819334506988525
Validation loss: 2.0792479079256774

Epoch: 296| Step: 0
Training loss: 2.7482943534851074
Validation loss: 2.081420165236278

Epoch: 5| Step: 1
Training loss: 2.0100104808807373
Validation loss: 2.0806971121859807

Epoch: 5| Step: 2
Training loss: 2.36989164352417
Validation loss: 2.0756522968251216

Epoch: 5| Step: 3
Training loss: 2.4003703594207764
Validation loss: 2.0872500276052826

Epoch: 5| Step: 4
Training loss: 2.441588878631592
Validation loss: 2.0753216974196897

Epoch: 5| Step: 5
Training loss: 2.271876096725464
Validation loss: 2.0851792699547222

Epoch: 5| Step: 6
Training loss: 1.5876266956329346
Validation loss: 2.077670108887457

Epoch: 5| Step: 7
Training loss: 2.1883883476257324
Validation loss: 2.0841182765140327

Epoch: 5| Step: 8
Training loss: 1.805314064025879
Validation loss: 2.0825691761509066

Epoch: 5| Step: 9
Training loss: 2.3347764015197754
Validation loss: 2.08660481309378

Epoch: 5| Step: 10
Training loss: 2.020967721939087
Validation loss: 2.0926915791726883

Epoch: 297| Step: 0
Training loss: 2.318190097808838
Validation loss: 2.0910156529436827

Epoch: 5| Step: 1
Training loss: 1.7901885509490967
Validation loss: 2.0953214604367494

Epoch: 5| Step: 2
Training loss: 2.4917149543762207
Validation loss: 2.0911619432510866

Epoch: 5| Step: 3
Training loss: 1.8807882070541382
Validation loss: 2.0942651379492974

Epoch: 5| Step: 4
Training loss: 2.487006425857544
Validation loss: 2.089252466796547

Epoch: 5| Step: 5
Training loss: 2.1137001514434814
Validation loss: 2.0881482888293523

Epoch: 5| Step: 6
Training loss: 2.680067300796509
Validation loss: 2.1006569708547285

Epoch: 5| Step: 7
Training loss: 1.9755992889404297
Validation loss: 2.092433491060811

Epoch: 5| Step: 8
Training loss: 2.567739248275757
Validation loss: 2.0959582892797326

Epoch: 5| Step: 9
Training loss: 1.7592252492904663
Validation loss: 2.090846647498428

Epoch: 5| Step: 10
Training loss: 2.2365942001342773
Validation loss: 2.0890332806494927

Epoch: 298| Step: 0
Training loss: 2.0439321994781494
Validation loss: 2.0905339294864285

Epoch: 5| Step: 1
Training loss: 2.362722396850586
Validation loss: 2.0748338109703472

Epoch: 5| Step: 2
Training loss: 2.1361448764801025
Validation loss: 2.078680897271761

Epoch: 5| Step: 3
Training loss: 2.1637065410614014
Validation loss: 2.0764272802619526

Epoch: 5| Step: 4
Training loss: 2.0542073249816895
Validation loss: 2.078377860848622

Epoch: 5| Step: 5
Training loss: 1.3018348217010498
Validation loss: 2.071312450593518

Epoch: 5| Step: 6
Training loss: 2.3666629791259766
Validation loss: 2.0837175846099854

Epoch: 5| Step: 7
Training loss: 2.475167751312256
Validation loss: 2.0632202086910123

Epoch: 5| Step: 8
Training loss: 2.5557589530944824
Validation loss: 2.072182014424314

Epoch: 5| Step: 9
Training loss: 2.3468925952911377
Validation loss: 2.0699118004050305

Epoch: 5| Step: 10
Training loss: 2.389331102371216
Validation loss: 2.062742421703954

Epoch: 299| Step: 0
Training loss: 1.5265793800354004
Validation loss: 2.077549239640595

Epoch: 5| Step: 1
Training loss: 2.2306227684020996
Validation loss: 2.0681801111467424

Epoch: 5| Step: 2
Training loss: 2.690049886703491
Validation loss: 2.069946624899423

Epoch: 5| Step: 3
Training loss: 1.560390830039978
Validation loss: 2.058280065495481

Epoch: 5| Step: 4
Training loss: 2.2982940673828125
Validation loss: 2.079879747923984

Epoch: 5| Step: 5
Training loss: 1.8650716543197632
Validation loss: 2.0783161681185485

Epoch: 5| Step: 6
Training loss: 2.285818576812744
Validation loss: 2.081067059629707

Epoch: 5| Step: 7
Training loss: 2.1664576530456543
Validation loss: 2.0930803052840696

Epoch: 5| Step: 8
Training loss: 2.6970479488372803
Validation loss: 2.0923974296098113

Epoch: 5| Step: 9
Training loss: 2.7644906044006348
Validation loss: 2.1113999300105597

Epoch: 5| Step: 10
Training loss: 2.0666632652282715
Validation loss: 2.1069567921341106

Epoch: 300| Step: 0
Training loss: 2.612109899520874
Validation loss: 2.09826252793753

Epoch: 5| Step: 1
Training loss: 1.9055545330047607
Validation loss: 2.1015413063828663

Epoch: 5| Step: 2
Training loss: 2.834688663482666
Validation loss: 2.086567037849016

Epoch: 5| Step: 3
Training loss: 2.0130951404571533
Validation loss: 2.0779717558173725

Epoch: 5| Step: 4
Training loss: 2.141786575317383
Validation loss: 2.0758645380696943

Epoch: 5| Step: 5
Training loss: 1.7568706274032593
Validation loss: 2.074453823028072

Epoch: 5| Step: 6
Training loss: 2.5107579231262207
Validation loss: 2.0745391332975

Epoch: 5| Step: 7
Training loss: 2.228689670562744
Validation loss: 2.0739671286716255

Epoch: 5| Step: 8
Training loss: 2.2333762645721436
Validation loss: 2.0745626188093618

Epoch: 5| Step: 9
Training loss: 1.898159384727478
Validation loss: 2.09362155519506

Epoch: 5| Step: 10
Training loss: 2.1969571113586426
Validation loss: 2.0813255361331406

Epoch: 301| Step: 0
Training loss: 1.9655593633651733
Validation loss: 2.088759877348459

Epoch: 5| Step: 1
Training loss: 1.9814374446868896
Validation loss: 2.086982430950288

Epoch: 5| Step: 2
Training loss: 1.9662803411483765
Validation loss: 2.079123391900011

Epoch: 5| Step: 3
Training loss: 2.620222568511963
Validation loss: 2.0890227415228404

Epoch: 5| Step: 4
Training loss: 2.968334674835205
Validation loss: 2.0933163601865052

Epoch: 5| Step: 5
Training loss: 2.206651449203491
Validation loss: 2.0810873380271335

Epoch: 5| Step: 6
Training loss: 2.2584924697875977
Validation loss: 2.090994493935698

Epoch: 5| Step: 7
Training loss: 2.7525131702423096
Validation loss: 2.0991700849225445

Epoch: 5| Step: 8
Training loss: 1.9137065410614014
Validation loss: 2.0942037951561714

Epoch: 5| Step: 9
Training loss: 1.5017926692962646
Validation loss: 2.0971600317185923

Epoch: 5| Step: 10
Training loss: 2.098461866378784
Validation loss: 2.0994065089892318

Epoch: 302| Step: 0
Training loss: 2.329298734664917
Validation loss: 2.1043250945306595

Epoch: 5| Step: 1
Training loss: 2.8457467555999756
Validation loss: 2.0981015671965895

Epoch: 5| Step: 2
Training loss: 2.0510027408599854
Validation loss: 2.102590359667296

Epoch: 5| Step: 3
Training loss: 2.2901368141174316
Validation loss: 2.0892671590210288

Epoch: 5| Step: 4
Training loss: 1.8059816360473633
Validation loss: 2.094003008257958

Epoch: 5| Step: 5
Training loss: 1.4487056732177734
Validation loss: 2.076074242591858

Epoch: 5| Step: 6
Training loss: 2.3727164268493652
Validation loss: 2.077588447960474

Epoch: 5| Step: 7
Training loss: 2.012345790863037
Validation loss: 2.0713147860701366

Epoch: 5| Step: 8
Training loss: 2.295933485031128
Validation loss: 2.0616439824463217

Epoch: 5| Step: 9
Training loss: 2.0020861625671387
Validation loss: 2.0709841097554853

Epoch: 5| Step: 10
Training loss: 2.714801788330078
Validation loss: 2.06584103902181

Epoch: 303| Step: 0
Training loss: 2.1315178871154785
Validation loss: 2.0607404426861833

Epoch: 5| Step: 1
Training loss: 2.411567449569702
Validation loss: 2.0758174901367514

Epoch: 5| Step: 2
Training loss: 2.627939462661743
Validation loss: 2.0798535590530722

Epoch: 5| Step: 3
Training loss: 2.177321195602417
Validation loss: 2.0699519829083513

Epoch: 5| Step: 4
Training loss: 1.9279594421386719
Validation loss: 2.0848645010302143

Epoch: 5| Step: 5
Training loss: 2.333052158355713
Validation loss: 2.0814587890460925

Epoch: 5| Step: 6
Training loss: 2.085092067718506
Validation loss: 2.081725864000218

Epoch: 5| Step: 7
Training loss: 2.1312918663024902
Validation loss: 2.095606198874853

Epoch: 5| Step: 8
Training loss: 1.5217201709747314
Validation loss: 2.0817850264169837

Epoch: 5| Step: 9
Training loss: 2.4279446601867676
Validation loss: 2.0956112236104985

Epoch: 5| Step: 10
Training loss: 2.4023804664611816
Validation loss: 2.0817499135130193

Epoch: 304| Step: 0
Training loss: 1.854430913925171
Validation loss: 2.065752496001541

Epoch: 5| Step: 1
Training loss: 1.44419264793396
Validation loss: 2.0802820805580384

Epoch: 5| Step: 2
Training loss: 1.9552866220474243
Validation loss: 2.0692338302571285

Epoch: 5| Step: 3
Training loss: 2.5752737522125244
Validation loss: 2.092385274107738

Epoch: 5| Step: 4
Training loss: 2.294191837310791
Validation loss: 2.0820838136057698

Epoch: 5| Step: 5
Training loss: 2.775109052658081
Validation loss: 2.099153087985131

Epoch: 5| Step: 6
Training loss: 2.1922483444213867
Validation loss: 2.094333069298857

Epoch: 5| Step: 7
Training loss: 1.7782299518585205
Validation loss: 2.0885393440082507

Epoch: 5| Step: 8
Training loss: 2.6713740825653076
Validation loss: 2.080242549219439

Epoch: 5| Step: 9
Training loss: 2.184230327606201
Validation loss: 2.0781659285227456

Epoch: 5| Step: 10
Training loss: 2.454554557800293
Validation loss: 2.0744288608592045

Epoch: 305| Step: 0
Training loss: 2.6890602111816406
Validation loss: 2.0584590819574173

Epoch: 5| Step: 1
Training loss: 2.084299325942993
Validation loss: 2.075328673085859

Epoch: 5| Step: 2
Training loss: 1.8675591945648193
Validation loss: 2.0644717818947247

Epoch: 5| Step: 3
Training loss: 2.4971799850463867
Validation loss: 2.0778829589966805

Epoch: 5| Step: 4
Training loss: 1.9147075414657593
Validation loss: 2.079026060719644

Epoch: 5| Step: 5
Training loss: 2.4575042724609375
Validation loss: 2.0726986174942343

Epoch: 5| Step: 6
Training loss: 1.879055380821228
Validation loss: 2.0900798561752483

Epoch: 5| Step: 7
Training loss: 2.1554641723632812
Validation loss: 2.0871325282640356

Epoch: 5| Step: 8
Training loss: 1.9869725704193115
Validation loss: 2.0689101578086935

Epoch: 5| Step: 9
Training loss: 2.354280471801758
Validation loss: 2.0637725066113215

Epoch: 5| Step: 10
Training loss: 2.2347397804260254
Validation loss: 2.0750993810674196

Epoch: 306| Step: 0
Training loss: 2.1480865478515625
Validation loss: 2.063182270655068

Epoch: 5| Step: 1
Training loss: 2.5951592922210693
Validation loss: 2.0616392256111227

Epoch: 5| Step: 2
Training loss: 1.7680460214614868
Validation loss: 2.0536467682930732

Epoch: 5| Step: 3
Training loss: 2.80877685546875
Validation loss: 2.0525998402667303

Epoch: 5| Step: 4
Training loss: 2.106232166290283
Validation loss: 2.059250141984673

Epoch: 5| Step: 5
Training loss: 2.2539615631103516
Validation loss: 2.0629914627280286

Epoch: 5| Step: 6
Training loss: 2.310241222381592
Validation loss: 2.060487795901555

Epoch: 5| Step: 7
Training loss: 1.7211589813232422
Validation loss: 2.0715379317601523

Epoch: 5| Step: 8
Training loss: 2.1774144172668457
Validation loss: 2.0653241629241617

Epoch: 5| Step: 9
Training loss: 1.938871145248413
Validation loss: 2.067424548569546

Epoch: 5| Step: 10
Training loss: 2.2043514251708984
Validation loss: 2.084504545375865

Epoch: 307| Step: 0
Training loss: 2.306222438812256
Validation loss: 2.0966222722043275

Epoch: 5| Step: 1
Training loss: 2.2692458629608154
Validation loss: 2.0839153720486547

Epoch: 5| Step: 2
Training loss: 1.933786153793335
Validation loss: 2.123074559755223

Epoch: 5| Step: 3
Training loss: 2.2044601440429688
Validation loss: 2.1182376697499263

Epoch: 5| Step: 4
Training loss: 1.5706244707107544
Validation loss: 2.1101214834438857

Epoch: 5| Step: 5
Training loss: 2.3911075592041016
Validation loss: 2.0994604838791715

Epoch: 5| Step: 6
Training loss: 1.9180223941802979
Validation loss: 2.1059757201902327

Epoch: 5| Step: 7
Training loss: 2.544304370880127
Validation loss: 2.1027950522720174

Epoch: 5| Step: 8
Training loss: 1.9906995296478271
Validation loss: 2.1014628846158265

Epoch: 5| Step: 9
Training loss: 2.517514705657959
Validation loss: 2.0897722474990355

Epoch: 5| Step: 10
Training loss: 2.3731672763824463
Validation loss: 2.0880947856492895

Epoch: 308| Step: 0
Training loss: 2.9572532176971436
Validation loss: 2.0765190227057344

Epoch: 5| Step: 1
Training loss: 2.08850359916687
Validation loss: 2.0706929981067614

Epoch: 5| Step: 2
Training loss: 1.9418413639068604
Validation loss: 2.0620412595810427

Epoch: 5| Step: 3
Training loss: 1.7400970458984375
Validation loss: 2.06774043011409

Epoch: 5| Step: 4
Training loss: 2.466139793395996
Validation loss: 2.0578630919097574

Epoch: 5| Step: 5
Training loss: 2.4765284061431885
Validation loss: 2.0659238676871023

Epoch: 5| Step: 6
Training loss: 1.8945887088775635
Validation loss: 2.065021759720259

Epoch: 5| Step: 7
Training loss: 2.036909818649292
Validation loss: 2.0577510505594234

Epoch: 5| Step: 8
Training loss: 1.9129211902618408
Validation loss: 2.0697285590633268

Epoch: 5| Step: 9
Training loss: 2.61624813079834
Validation loss: 2.0751029342733402

Epoch: 5| Step: 10
Training loss: 1.6564147472381592
Validation loss: 2.090775041170018

Epoch: 309| Step: 0
Training loss: 2.2728707790374756
Validation loss: 2.0837518348488757

Epoch: 5| Step: 1
Training loss: 2.2936370372772217
Validation loss: 2.0909402857544603

Epoch: 5| Step: 2
Training loss: 2.3556461334228516
Validation loss: 2.077956735446889

Epoch: 5| Step: 3
Training loss: 2.4854023456573486
Validation loss: 2.070655422825967

Epoch: 5| Step: 4
Training loss: 2.1668238639831543
Validation loss: 2.061783557297081

Epoch: 5| Step: 5
Training loss: 2.5385537147521973
Validation loss: 2.0680190363237934

Epoch: 5| Step: 6
Training loss: 1.9495757818222046
Validation loss: 2.066950246851931

Epoch: 5| Step: 7
Training loss: 1.396874189376831
Validation loss: 2.0565430528374127

Epoch: 5| Step: 8
Training loss: 2.1960208415985107
Validation loss: 2.0628995126293552

Epoch: 5| Step: 9
Training loss: 2.5332283973693848
Validation loss: 2.0554221214786654

Epoch: 5| Step: 10
Training loss: 1.719425916671753
Validation loss: 2.061007325367261

Epoch: 310| Step: 0
Training loss: 2.191455364227295
Validation loss: 2.0584984799867034

Epoch: 5| Step: 1
Training loss: 2.6354384422302246
Validation loss: 2.094256875335529

Epoch: 5| Step: 2
Training loss: 2.265721082687378
Validation loss: 2.075228315527721

Epoch: 5| Step: 3
Training loss: 1.9784568548202515
Validation loss: 2.082032926620976

Epoch: 5| Step: 4
Training loss: 2.0774083137512207
Validation loss: 2.0738321696558306

Epoch: 5| Step: 5
Training loss: 1.7285856008529663
Validation loss: 2.0732206683005057

Epoch: 5| Step: 6
Training loss: 1.9570930004119873
Validation loss: 2.0656254317170832

Epoch: 5| Step: 7
Training loss: 2.03509783744812
Validation loss: 2.0643175827559603

Epoch: 5| Step: 8
Training loss: 1.9205372333526611
Validation loss: 2.0708494904220744

Epoch: 5| Step: 9
Training loss: 2.582899808883667
Validation loss: 2.073280385745469

Epoch: 5| Step: 10
Training loss: 2.567948818206787
Validation loss: 2.0727744012750606

Epoch: 311| Step: 0
Training loss: 2.5460751056671143
Validation loss: 2.071367158684679

Epoch: 5| Step: 1
Training loss: 1.769669532775879
Validation loss: 2.0716741302961945

Epoch: 5| Step: 2
Training loss: 1.9694175720214844
Validation loss: 2.096608510581396

Epoch: 5| Step: 3
Training loss: 2.313408613204956
Validation loss: 2.096562518868395

Epoch: 5| Step: 4
Training loss: 2.0599842071533203
Validation loss: 2.095160604805075

Epoch: 5| Step: 5
Training loss: 2.51517915725708
Validation loss: 2.1008373729644285

Epoch: 5| Step: 6
Training loss: 2.673497200012207
Validation loss: 2.079391441037578

Epoch: 5| Step: 7
Training loss: 2.270207405090332
Validation loss: 2.0652721056374173

Epoch: 5| Step: 8
Training loss: 2.1576945781707764
Validation loss: 2.0556824130396687

Epoch: 5| Step: 9
Training loss: 1.5986454486846924
Validation loss: 2.0400644015240412

Epoch: 5| Step: 10
Training loss: 1.9777560234069824
Validation loss: 2.041902692087235

Epoch: 312| Step: 0
Training loss: 2.0624217987060547
Validation loss: 2.042241579742842

Epoch: 5| Step: 1
Training loss: 1.9924099445343018
Validation loss: 2.041041115278839

Epoch: 5| Step: 2
Training loss: 2.0798892974853516
Validation loss: 2.038543562735281

Epoch: 5| Step: 3
Training loss: 2.6238887310028076
Validation loss: 2.0469317692582325

Epoch: 5| Step: 4
Training loss: 1.9296373128890991
Validation loss: 2.054557010691653

Epoch: 5| Step: 5
Training loss: 2.2345664501190186
Validation loss: 2.05672957563913

Epoch: 5| Step: 6
Training loss: 1.343404769897461
Validation loss: 2.058147276601484

Epoch: 5| Step: 7
Training loss: 2.752086639404297
Validation loss: 2.0755976861523044

Epoch: 5| Step: 8
Training loss: 2.1938679218292236
Validation loss: 2.080653981495929

Epoch: 5| Step: 9
Training loss: 2.5887928009033203
Validation loss: 2.0734530802695983

Epoch: 5| Step: 10
Training loss: 2.0918283462524414
Validation loss: 2.076303110327772

Epoch: 313| Step: 0
Training loss: 2.3632419109344482
Validation loss: 2.095497062129359

Epoch: 5| Step: 1
Training loss: 1.8284485340118408
Validation loss: 2.083875471545804

Epoch: 5| Step: 2
Training loss: 2.703500986099243
Validation loss: 2.0905127781693653

Epoch: 5| Step: 3
Training loss: 2.4360814094543457
Validation loss: 2.0906459951913483

Epoch: 5| Step: 4
Training loss: 1.8926903009414673
Validation loss: 2.0973015510907738

Epoch: 5| Step: 5
Training loss: 1.4961175918579102
Validation loss: 2.100107010974679

Epoch: 5| Step: 6
Training loss: 2.5161635875701904
Validation loss: 2.1202946106592813

Epoch: 5| Step: 7
Training loss: 1.7646057605743408
Validation loss: 2.1199508174773185

Epoch: 5| Step: 8
Training loss: 2.4115288257598877
Validation loss: 2.1108549782024917

Epoch: 5| Step: 9
Training loss: 1.898667573928833
Validation loss: 2.0947467460427234

Epoch: 5| Step: 10
Training loss: 2.5857434272766113
Validation loss: 2.0912804911213536

Epoch: 314| Step: 0
Training loss: 2.2663767337799072
Validation loss: 2.07575878789348

Epoch: 5| Step: 1
Training loss: 2.7061493396759033
Validation loss: 2.081479072570801

Epoch: 5| Step: 2
Training loss: 2.057189464569092
Validation loss: 2.084484907888597

Epoch: 5| Step: 3
Training loss: 1.714193344116211
Validation loss: 2.0893739602899037

Epoch: 5| Step: 4
Training loss: 2.205477476119995
Validation loss: 2.081616950291459

Epoch: 5| Step: 5
Training loss: 1.8488296270370483
Validation loss: 2.0811521314805552

Epoch: 5| Step: 6
Training loss: 1.9596506357192993
Validation loss: 2.0610608798201366

Epoch: 5| Step: 7
Training loss: 2.229250431060791
Validation loss: 2.081423697933074

Epoch: 5| Step: 8
Training loss: 2.306434392929077
Validation loss: 2.0653804809816423

Epoch: 5| Step: 9
Training loss: 2.082400321960449
Validation loss: 2.052916988249748

Epoch: 5| Step: 10
Training loss: 2.436422348022461
Validation loss: 2.077597843703403

Epoch: 315| Step: 0
Training loss: 2.683929920196533
Validation loss: 2.06970335847588

Epoch: 5| Step: 1
Training loss: 1.7003581523895264
Validation loss: 2.081263457575152

Epoch: 5| Step: 2
Training loss: 2.47194504737854
Validation loss: 2.083987380868645

Epoch: 5| Step: 3
Training loss: 2.072640895843506
Validation loss: 2.094537276093678

Epoch: 5| Step: 4
Training loss: 2.07588529586792
Validation loss: 2.091989758194134

Epoch: 5| Step: 5
Training loss: 2.133741855621338
Validation loss: 2.0862019779861614

Epoch: 5| Step: 6
Training loss: 2.3060059547424316
Validation loss: 2.0804479352889524

Epoch: 5| Step: 7
Training loss: 2.4064533710479736
Validation loss: 2.0657365757931947

Epoch: 5| Step: 8
Training loss: 1.8661115169525146
Validation loss: 2.079183973291869

Epoch: 5| Step: 9
Training loss: 2.3902535438537598
Validation loss: 2.058793875478929

Epoch: 5| Step: 10
Training loss: 1.581174612045288
Validation loss: 2.061940722568061

Epoch: 316| Step: 0
Training loss: 2.128993511199951
Validation loss: 2.0565206132909304

Epoch: 5| Step: 1
Training loss: 1.8408520221710205
Validation loss: 2.0639879447157665

Epoch: 5| Step: 2
Training loss: 2.101855754852295
Validation loss: 2.066383679707845

Epoch: 5| Step: 3
Training loss: 2.0611090660095215
Validation loss: 2.06343408297467

Epoch: 5| Step: 4
Training loss: 2.4756085872650146
Validation loss: 2.0642063643342707

Epoch: 5| Step: 5
Training loss: 1.9668411016464233
Validation loss: 2.0707711019823627

Epoch: 5| Step: 6
Training loss: 1.1976600885391235
Validation loss: 2.062963354972101

Epoch: 5| Step: 7
Training loss: 2.649580478668213
Validation loss: 2.0673876552171606

Epoch: 5| Step: 8
Training loss: 2.174934148788452
Validation loss: 2.0707412535144436

Epoch: 5| Step: 9
Training loss: 2.729094982147217
Validation loss: 2.0701337604112524

Epoch: 5| Step: 10
Training loss: 2.584878444671631
Validation loss: 2.0619515090860348

Epoch: 317| Step: 0
Training loss: 2.592334032058716
Validation loss: 2.0696021664527153

Epoch: 5| Step: 1
Training loss: 1.8413845300674438
Validation loss: 2.064697660425658

Epoch: 5| Step: 2
Training loss: 2.6195056438446045
Validation loss: 2.0728721054651404

Epoch: 5| Step: 3
Training loss: 2.0137791633605957
Validation loss: 2.0660185108902636

Epoch: 5| Step: 4
Training loss: 2.3673653602600098
Validation loss: 2.0762251935979372

Epoch: 5| Step: 5
Training loss: 1.799359679222107
Validation loss: 2.091349196690385

Epoch: 5| Step: 6
Training loss: 1.9900672435760498
Validation loss: 2.097905174378426

Epoch: 5| Step: 7
Training loss: 1.741794228553772
Validation loss: 2.1089337589920207

Epoch: 5| Step: 8
Training loss: 2.0647292137145996
Validation loss: 2.086124925203221

Epoch: 5| Step: 9
Training loss: 2.247807741165161
Validation loss: 2.086136947395981

Epoch: 5| Step: 10
Training loss: 2.5733699798583984
Validation loss: 2.04796887341366

Epoch: 318| Step: 0
Training loss: 2.307044267654419
Validation loss: 2.057436438016994

Epoch: 5| Step: 1
Training loss: 2.0619754791259766
Validation loss: 2.038125930293914

Epoch: 5| Step: 2
Training loss: 2.1818459033966064
Validation loss: 2.034534858119103

Epoch: 5| Step: 3
Training loss: 2.2914531230926514
Validation loss: 2.0328567515137377

Epoch: 5| Step: 4
Training loss: 2.2635514736175537
Validation loss: 2.028044605767855

Epoch: 5| Step: 5
Training loss: 1.9867836236953735
Validation loss: 2.036338818970547

Epoch: 5| Step: 6
Training loss: 2.0599212646484375
Validation loss: 2.0316237198409213

Epoch: 5| Step: 7
Training loss: 1.4304996728897095
Validation loss: 2.03581852041265

Epoch: 5| Step: 8
Training loss: 2.630000591278076
Validation loss: 2.041243653143606

Epoch: 5| Step: 9
Training loss: 2.4823760986328125
Validation loss: 2.0605384124222623

Epoch: 5| Step: 10
Training loss: 2.071640729904175
Validation loss: 2.053821797012001

Epoch: 319| Step: 0
Training loss: 1.8645662069320679
Validation loss: 2.0697292781645253

Epoch: 5| Step: 1
Training loss: 2.2855148315429688
Validation loss: 2.076153468060237

Epoch: 5| Step: 2
Training loss: 2.2257723808288574
Validation loss: 2.0682472503313454

Epoch: 5| Step: 3
Training loss: 2.2213282585144043
Validation loss: 2.094729511968551

Epoch: 5| Step: 4
Training loss: 1.7279434204101562
Validation loss: 2.0976506843361804

Epoch: 5| Step: 5
Training loss: 2.6834311485290527
Validation loss: 2.1012552322879916

Epoch: 5| Step: 6
Training loss: 1.9017009735107422
Validation loss: 2.090503592644968

Epoch: 5| Step: 7
Training loss: 2.349919557571411
Validation loss: 2.083117104345752

Epoch: 5| Step: 8
Training loss: 2.1951355934143066
Validation loss: 2.0790518317171323

Epoch: 5| Step: 9
Training loss: 2.787651538848877
Validation loss: 2.090018915873702

Epoch: 5| Step: 10
Training loss: 1.3766781091690063
Validation loss: 2.0830481744581655

Epoch: 320| Step: 0
Training loss: 2.284243583679199
Validation loss: 2.0722481909618584

Epoch: 5| Step: 1
Training loss: 2.316298007965088
Validation loss: 2.0599381846766316

Epoch: 5| Step: 2
Training loss: 3.0164268016815186
Validation loss: 2.070115827745007

Epoch: 5| Step: 3
Training loss: 2.0957274436950684
Validation loss: 2.0645166186876196

Epoch: 5| Step: 4
Training loss: 2.0037343502044678
Validation loss: 2.066706026754072

Epoch: 5| Step: 5
Training loss: 2.0667083263397217
Validation loss: 2.05158398484671

Epoch: 5| Step: 6
Training loss: 1.7276833057403564
Validation loss: 2.063325748648695

Epoch: 5| Step: 7
Training loss: 2.0436253547668457
Validation loss: 2.057849960942422

Epoch: 5| Step: 8
Training loss: 2.2073066234588623
Validation loss: 2.0446496061099473

Epoch: 5| Step: 9
Training loss: 1.484786033630371
Validation loss: 2.056179646522768

Epoch: 5| Step: 10
Training loss: 2.4065487384796143
Validation loss: 2.054840046872375

Epoch: 321| Step: 0
Training loss: 2.1572813987731934
Validation loss: 2.0535071793422905

Epoch: 5| Step: 1
Training loss: 2.04826283454895
Validation loss: 2.0347244521623016

Epoch: 5| Step: 2
Training loss: 1.7292743921279907
Validation loss: 2.039312134506882

Epoch: 5| Step: 3
Training loss: 1.7868459224700928
Validation loss: 2.0498512752594484

Epoch: 5| Step: 4
Training loss: 2.761446714401245
Validation loss: 2.0380926234747774

Epoch: 5| Step: 5
Training loss: 1.8617231845855713
Validation loss: 2.047672176873812

Epoch: 5| Step: 6
Training loss: 2.010124683380127
Validation loss: 2.047064527388542

Epoch: 5| Step: 7
Training loss: 2.5598363876342773
Validation loss: 2.064116547184606

Epoch: 5| Step: 8
Training loss: 2.064119338989258
Validation loss: 2.054575945741387

Epoch: 5| Step: 9
Training loss: 2.5471620559692383
Validation loss: 2.052951075697458

Epoch: 5| Step: 10
Training loss: 2.1359450817108154
Validation loss: 2.0611490588034354

Epoch: 322| Step: 0
Training loss: 2.38763689994812
Validation loss: 2.0613613846481487

Epoch: 5| Step: 1
Training loss: 2.25423526763916
Validation loss: 2.0751513076084915

Epoch: 5| Step: 2
Training loss: 1.9736158847808838
Validation loss: 2.082458561466586

Epoch: 5| Step: 3
Training loss: 1.2540966272354126
Validation loss: 2.077885394455284

Epoch: 5| Step: 4
Training loss: 1.66890549659729
Validation loss: 2.0703850253935783

Epoch: 5| Step: 5
Training loss: 2.349592685699463
Validation loss: 2.0610350870317027

Epoch: 5| Step: 6
Training loss: 2.599092721939087
Validation loss: 2.0661471889865015

Epoch: 5| Step: 7
Training loss: 1.6384464502334595
Validation loss: 2.053874459317935

Epoch: 5| Step: 8
Training loss: 2.8673388957977295
Validation loss: 2.0573956825399913

Epoch: 5| Step: 9
Training loss: 2.4925713539123535
Validation loss: 2.059985629973873

Epoch: 5| Step: 10
Training loss: 2.0277984142303467
Validation loss: 2.042379568981868

Epoch: 323| Step: 0
Training loss: 2.611832857131958
Validation loss: 2.0354953171104513

Epoch: 5| Step: 1
Training loss: 1.8635635375976562
Validation loss: 2.043502870426383

Epoch: 5| Step: 2
Training loss: 1.7099730968475342
Validation loss: 2.0191995610472975

Epoch: 5| Step: 3
Training loss: 1.881291389465332
Validation loss: 2.040695531393892

Epoch: 5| Step: 4
Training loss: 1.9814422130584717
Validation loss: 2.0489327138470066

Epoch: 5| Step: 5
Training loss: 2.3170578479766846
Validation loss: 2.045597187934383

Epoch: 5| Step: 6
Training loss: 2.0519144535064697
Validation loss: 2.0382940564104306

Epoch: 5| Step: 7
Training loss: 2.2423152923583984
Validation loss: 2.043598036612234

Epoch: 5| Step: 8
Training loss: 2.2182719707489014
Validation loss: 2.059077929424983

Epoch: 5| Step: 9
Training loss: 2.2893269062042236
Validation loss: 2.0681945457253406

Epoch: 5| Step: 10
Training loss: 2.421239137649536
Validation loss: 2.0733700003675235

Epoch: 324| Step: 0
Training loss: 2.4605965614318848
Validation loss: 2.071182781650174

Epoch: 5| Step: 1
Training loss: 1.425891399383545
Validation loss: 2.0656534984547603

Epoch: 5| Step: 2
Training loss: 1.9978229999542236
Validation loss: 2.066774852814213

Epoch: 5| Step: 3
Training loss: 2.034672498703003
Validation loss: 2.054104874210973

Epoch: 5| Step: 4
Training loss: 1.6309688091278076
Validation loss: 2.0660686249374063

Epoch: 5| Step: 5
Training loss: 2.872150182723999
Validation loss: 2.054722229639689

Epoch: 5| Step: 6
Training loss: 1.9369497299194336
Validation loss: 2.064846993774496

Epoch: 5| Step: 7
Training loss: 2.6153464317321777
Validation loss: 2.0702176478601273

Epoch: 5| Step: 8
Training loss: 2.08980655670166
Validation loss: 2.0750100792095227

Epoch: 5| Step: 9
Training loss: 2.114696979522705
Validation loss: 2.060615321641327

Epoch: 5| Step: 10
Training loss: 2.3596980571746826
Validation loss: 2.0706535411137406

Epoch: 325| Step: 0
Training loss: 2.304995059967041
Validation loss: 2.069722129452613

Epoch: 5| Step: 1
Training loss: 1.557058572769165
Validation loss: 2.0700908950580064

Epoch: 5| Step: 2
Training loss: 2.179182529449463
Validation loss: 2.065275824198159

Epoch: 5| Step: 3
Training loss: 1.7928693294525146
Validation loss: 2.077278342298282

Epoch: 5| Step: 4
Training loss: 1.5900686979293823
Validation loss: 2.089930780472294

Epoch: 5| Step: 5
Training loss: 2.2579283714294434
Validation loss: 2.0716928089818647

Epoch: 5| Step: 6
Training loss: 2.744662284851074
Validation loss: 2.0652713980726016

Epoch: 5| Step: 7
Training loss: 2.4595444202423096
Validation loss: 2.0638019833513486

Epoch: 5| Step: 8
Training loss: 2.5649116039276123
Validation loss: 2.061939865030268

Epoch: 5| Step: 9
Training loss: 1.4883453845977783
Validation loss: 2.049585860262635

Epoch: 5| Step: 10
Training loss: 2.5251448154449463
Validation loss: 2.049881224991173

Epoch: 326| Step: 0
Training loss: 2.3932597637176514
Validation loss: 2.038339186740178

Epoch: 5| Step: 1
Training loss: 2.180678367614746
Validation loss: 2.032333723960384

Epoch: 5| Step: 2
Training loss: 2.3792238235473633
Validation loss: 2.0390744632290256

Epoch: 5| Step: 3
Training loss: 2.157083749771118
Validation loss: 2.032258924617562

Epoch: 5| Step: 4
Training loss: 2.1658127307891846
Validation loss: 2.0502960284550986

Epoch: 5| Step: 5
Training loss: 2.1256303787231445
Validation loss: 2.0432888512970298

Epoch: 5| Step: 6
Training loss: 2.2773540019989014
Validation loss: 2.051012776231253

Epoch: 5| Step: 7
Training loss: 1.9077707529067993
Validation loss: 2.057469456426559

Epoch: 5| Step: 8
Training loss: 1.8550078868865967
Validation loss: 2.073279647416966

Epoch: 5| Step: 9
Training loss: 2.5741584300994873
Validation loss: 2.092397459091679

Epoch: 5| Step: 10
Training loss: 1.4349445104599
Validation loss: 2.0962867711179998

Epoch: 327| Step: 0
Training loss: 2.2041523456573486
Validation loss: 2.1020896383511123

Epoch: 5| Step: 1
Training loss: 2.2973973751068115
Validation loss: 2.104753055880147

Epoch: 5| Step: 2
Training loss: 2.013615846633911
Validation loss: 2.109204364079301

Epoch: 5| Step: 3
Training loss: 2.6393938064575195
Validation loss: 2.0971258186524913

Epoch: 5| Step: 4
Training loss: 2.4308180809020996
Validation loss: 2.094554529395155

Epoch: 5| Step: 5
Training loss: 1.7435619831085205
Validation loss: 2.0835281059306157

Epoch: 5| Step: 6
Training loss: 2.1666858196258545
Validation loss: 2.0884980488848943

Epoch: 5| Step: 7
Training loss: 1.5073702335357666
Validation loss: 2.071583802982043

Epoch: 5| Step: 8
Training loss: 2.2761340141296387
Validation loss: 2.0831241171847106

Epoch: 5| Step: 9
Training loss: 2.1491496562957764
Validation loss: 2.0875242217894523

Epoch: 5| Step: 10
Training loss: 2.031033515930176
Validation loss: 2.080950265289635

Epoch: 328| Step: 0
Training loss: 2.2249538898468018
Validation loss: 2.066896851344775

Epoch: 5| Step: 1
Training loss: 2.1092967987060547
Validation loss: 2.080940943892284

Epoch: 5| Step: 2
Training loss: 1.5099389553070068
Validation loss: 2.091774982790793

Epoch: 5| Step: 3
Training loss: 2.2109594345092773
Validation loss: 2.09070667400155

Epoch: 5| Step: 4
Training loss: 1.7787754535675049
Validation loss: 2.09184540471723

Epoch: 5| Step: 5
Training loss: 2.654326915740967
Validation loss: 2.083853737000496

Epoch: 5| Step: 6
Training loss: 2.346428632736206
Validation loss: 2.0784272045217533

Epoch: 5| Step: 7
Training loss: 1.7601597309112549
Validation loss: 2.064290934993375

Epoch: 5| Step: 8
Training loss: 2.0691967010498047
Validation loss: 2.057935708312578

Epoch: 5| Step: 9
Training loss: 2.626422882080078
Validation loss: 2.0639755238768873

Epoch: 5| Step: 10
Training loss: 2.1706597805023193
Validation loss: 2.0367021637578167

Epoch: 329| Step: 0
Training loss: 1.760420560836792
Validation loss: 2.0612774741265083

Epoch: 5| Step: 1
Training loss: 1.9687011241912842
Validation loss: 2.065360939630898

Epoch: 5| Step: 2
Training loss: 1.9537338018417358
Validation loss: 2.054021781490695

Epoch: 5| Step: 3
Training loss: 2.1984496116638184
Validation loss: 2.050645325773506

Epoch: 5| Step: 4
Training loss: 2.3887338638305664
Validation loss: 2.0442747890308337

Epoch: 5| Step: 5
Training loss: 2.2494776248931885
Validation loss: 2.026051849447271

Epoch: 5| Step: 6
Training loss: 1.977125883102417
Validation loss: 2.023783245394307

Epoch: 5| Step: 7
Training loss: 2.4733071327209473
Validation loss: 2.0504445260570896

Epoch: 5| Step: 8
Training loss: 2.3397216796875
Validation loss: 2.0693091936008905

Epoch: 5| Step: 9
Training loss: 2.117159128189087
Validation loss: 2.094143577801284

Epoch: 5| Step: 10
Training loss: 2.211987018585205
Validation loss: 2.0854358493640857

Epoch: 330| Step: 0
Training loss: 1.8512426614761353
Validation loss: 2.1054012775421143

Epoch: 5| Step: 1
Training loss: 1.8484846353530884
Validation loss: 2.127735202030469

Epoch: 5| Step: 2
Training loss: 2.366417407989502
Validation loss: 2.1375107970289005

Epoch: 5| Step: 3
Training loss: 2.2545552253723145
Validation loss: 2.1303441024595693

Epoch: 5| Step: 4
Training loss: 1.7299302816390991
Validation loss: 2.1057479637925343

Epoch: 5| Step: 5
Training loss: 2.3029191493988037
Validation loss: 2.092918147322952

Epoch: 5| Step: 6
Training loss: 2.673187732696533
Validation loss: 2.074767674169233

Epoch: 5| Step: 7
Training loss: 2.2731330394744873
Validation loss: 2.068410708058265

Epoch: 5| Step: 8
Training loss: 2.0712873935699463
Validation loss: 2.0727383449513423

Epoch: 5| Step: 9
Training loss: 2.043881416320801
Validation loss: 2.074945238328749

Epoch: 5| Step: 10
Training loss: 2.257138729095459
Validation loss: 2.0580669372312483

Epoch: 331| Step: 0
Training loss: 1.6477890014648438
Validation loss: 2.0438322162115448

Epoch: 5| Step: 1
Training loss: 2.44628643989563
Validation loss: 2.0424226176354194

Epoch: 5| Step: 2
Training loss: 1.6880477666854858
Validation loss: 2.051588202035555

Epoch: 5| Step: 3
Training loss: 2.124229907989502
Validation loss: 2.072596273114604

Epoch: 5| Step: 4
Training loss: 2.6026713848114014
Validation loss: 2.0723194819624706

Epoch: 5| Step: 5
Training loss: 2.0713672637939453
Validation loss: 2.0593990561782674

Epoch: 5| Step: 6
Training loss: 1.9419384002685547
Validation loss: 2.058841828377016

Epoch: 5| Step: 7
Training loss: 2.3502697944641113
Validation loss: 2.063412171538158

Epoch: 5| Step: 8
Training loss: 2.6534790992736816
Validation loss: 2.0554788215186006

Epoch: 5| Step: 9
Training loss: 2.0597922801971436
Validation loss: 2.050718758695869

Epoch: 5| Step: 10
Training loss: 1.8585232496261597
Validation loss: 2.0469833702169438

Epoch: 332| Step: 0
Training loss: 1.9605448246002197
Validation loss: 2.0482669799558577

Epoch: 5| Step: 1
Training loss: 1.4038166999816895
Validation loss: 2.042162291465267

Epoch: 5| Step: 2
Training loss: 2.4168524742126465
Validation loss: 2.0659444537214053

Epoch: 5| Step: 3
Training loss: 1.4697043895721436
Validation loss: 2.0722474052060034

Epoch: 5| Step: 4
Training loss: 2.6329751014709473
Validation loss: 2.0663449225887174

Epoch: 5| Step: 5
Training loss: 2.278240203857422
Validation loss: 2.090667131126568

Epoch: 5| Step: 6
Training loss: 1.9340794086456299
Validation loss: 2.098705650657736

Epoch: 5| Step: 7
Training loss: 2.338613986968994
Validation loss: 2.0910664707101803

Epoch: 5| Step: 8
Training loss: 2.582782030105591
Validation loss: 2.096767223009499

Epoch: 5| Step: 9
Training loss: 2.140903949737549
Validation loss: 2.112719060272299

Epoch: 5| Step: 10
Training loss: 2.2482645511627197
Validation loss: 2.1020865055822555

Epoch: 333| Step: 0
Training loss: 2.024646520614624
Validation loss: 2.086046163753797

Epoch: 5| Step: 1
Training loss: 2.1592788696289062
Validation loss: 2.074399253373505

Epoch: 5| Step: 2
Training loss: 2.49182391166687
Validation loss: 2.060240739135332

Epoch: 5| Step: 3
Training loss: 2.649881362915039
Validation loss: 2.0445274076154156

Epoch: 5| Step: 4
Training loss: 1.7463150024414062
Validation loss: 2.0386362921807075

Epoch: 5| Step: 5
Training loss: 1.9741218090057373
Validation loss: 2.0208629920918453

Epoch: 5| Step: 6
Training loss: 1.462418556213379
Validation loss: 2.0210531847451323

Epoch: 5| Step: 7
Training loss: 1.9171425104141235
Validation loss: 2.028445795018186

Epoch: 5| Step: 8
Training loss: 2.609069585800171
Validation loss: 2.0235848426818848

Epoch: 5| Step: 9
Training loss: 2.4454283714294434
Validation loss: 2.0191563406298236

Epoch: 5| Step: 10
Training loss: 1.8635129928588867
Validation loss: 2.0350784076157438

Epoch: 334| Step: 0
Training loss: 2.561487913131714
Validation loss: 2.0285643659612185

Epoch: 5| Step: 1
Training loss: 2.002192497253418
Validation loss: 2.033917970554803

Epoch: 5| Step: 2
Training loss: 1.59699547290802
Validation loss: 2.0364581154238794

Epoch: 5| Step: 3
Training loss: 1.9009811878204346
Validation loss: 2.0587846963636336

Epoch: 5| Step: 4
Training loss: 2.06477952003479
Validation loss: 2.056059524577151

Epoch: 5| Step: 5
Training loss: 3.066422700881958
Validation loss: 2.0685774882634482

Epoch: 5| Step: 6
Training loss: 1.8995304107666016
Validation loss: 2.0596653120492094

Epoch: 5| Step: 7
Training loss: 1.8526700735092163
Validation loss: 2.050939339463429

Epoch: 5| Step: 8
Training loss: 2.6807169914245605
Validation loss: 2.050510880767658

Epoch: 5| Step: 9
Training loss: 2.1426477432250977
Validation loss: 2.046079533074492

Epoch: 5| Step: 10
Training loss: 1.401612401008606
Validation loss: 2.0575720725520963

Epoch: 335| Step: 0
Training loss: 2.418537139892578
Validation loss: 2.0530786104099725

Epoch: 5| Step: 1
Training loss: 1.7079750299453735
Validation loss: 2.0449010723380634

Epoch: 5| Step: 2
Training loss: 1.5922935009002686
Validation loss: 2.059849072528142

Epoch: 5| Step: 3
Training loss: 2.591899871826172
Validation loss: 2.066467474865657

Epoch: 5| Step: 4
Training loss: 2.3475093841552734
Validation loss: 2.071880809722408

Epoch: 5| Step: 5
Training loss: 2.2501251697540283
Validation loss: 2.0635885910321305

Epoch: 5| Step: 6
Training loss: 1.2576017379760742
Validation loss: 2.047622929337204

Epoch: 5| Step: 7
Training loss: 2.7377076148986816
Validation loss: 2.054743471965995

Epoch: 5| Step: 8
Training loss: 1.8288390636444092
Validation loss: 2.0406913898324452

Epoch: 5| Step: 9
Training loss: 2.4981865882873535
Validation loss: 2.0379678062213364

Epoch: 5| Step: 10
Training loss: 1.9463567733764648
Validation loss: 2.04360447647751

Epoch: 336| Step: 0
Training loss: 1.7900136709213257
Validation loss: 2.0391198819683445

Epoch: 5| Step: 1
Training loss: 2.537188768386841
Validation loss: 2.0581907264647947

Epoch: 5| Step: 2
Training loss: 1.9463622570037842
Validation loss: 2.0539420099668604

Epoch: 5| Step: 3
Training loss: 2.019157886505127
Validation loss: 2.0614254167003017

Epoch: 5| Step: 4
Training loss: 2.0077602863311768
Validation loss: 2.0684514584079867

Epoch: 5| Step: 5
Training loss: 2.3102469444274902
Validation loss: 2.0624939062262095

Epoch: 5| Step: 6
Training loss: 2.297771692276001
Validation loss: 2.061898584006935

Epoch: 5| Step: 7
Training loss: 1.9563583135604858
Validation loss: 2.0746164796172932

Epoch: 5| Step: 8
Training loss: 2.086987257003784
Validation loss: 2.0718526737664336

Epoch: 5| Step: 9
Training loss: 2.3022847175598145
Validation loss: 2.057797690873505

Epoch: 5| Step: 10
Training loss: 2.0120105743408203
Validation loss: 2.061645677012782

Epoch: 337| Step: 0
Training loss: 2.0997226238250732
Validation loss: 2.0606894057284117

Epoch: 5| Step: 1
Training loss: 1.8073631525039673
Validation loss: 2.0646060564184703

Epoch: 5| Step: 2
Training loss: 2.1767373085021973
Validation loss: 2.047817304570188

Epoch: 5| Step: 3
Training loss: 2.3228235244750977
Validation loss: 2.0589902221515612

Epoch: 5| Step: 4
Training loss: 1.7183523178100586
Validation loss: 2.0756388454027075

Epoch: 5| Step: 5
Training loss: 2.3833370208740234
Validation loss: 2.0719337732561174

Epoch: 5| Step: 6
Training loss: 1.6806930303573608
Validation loss: 2.066803059270305

Epoch: 5| Step: 7
Training loss: 2.0007667541503906
Validation loss: 2.0579951552934546

Epoch: 5| Step: 8
Training loss: 2.178311824798584
Validation loss: 2.0484374453944545

Epoch: 5| Step: 9
Training loss: 2.1934797763824463
Validation loss: 2.0555001856178365

Epoch: 5| Step: 10
Training loss: 2.579585075378418
Validation loss: 2.0524470037029636

Epoch: 338| Step: 0
Training loss: 2.042031764984131
Validation loss: 2.045153561458793

Epoch: 5| Step: 1
Training loss: 2.2490992546081543
Validation loss: 2.034801648509118

Epoch: 5| Step: 2
Training loss: 2.046409845352173
Validation loss: 2.0443412796143563

Epoch: 5| Step: 3
Training loss: 2.019312620162964
Validation loss: 2.0480432894922074

Epoch: 5| Step: 4
Training loss: 2.5065464973449707
Validation loss: 2.0446823591827066

Epoch: 5| Step: 5
Training loss: 1.7551987171173096
Validation loss: 2.035548767735881

Epoch: 5| Step: 6
Training loss: 2.331683397293091
Validation loss: 2.0331809110538934

Epoch: 5| Step: 7
Training loss: 2.2044034004211426
Validation loss: 2.02323793467655

Epoch: 5| Step: 8
Training loss: 2.397892713546753
Validation loss: 2.0168162853487077

Epoch: 5| Step: 9
Training loss: 2.1307220458984375
Validation loss: 2.03474417296789

Epoch: 5| Step: 10
Training loss: 1.3852603435516357
Validation loss: 2.0333168186167234

Epoch: 339| Step: 0
Training loss: 2.3804359436035156
Validation loss: 2.0410180912222913

Epoch: 5| Step: 1
Training loss: 2.306352376937866
Validation loss: 2.061577796936035

Epoch: 5| Step: 2
Training loss: 1.762933373451233
Validation loss: 2.038506725782989

Epoch: 5| Step: 3
Training loss: 2.5184106826782227
Validation loss: 2.0333273436433528

Epoch: 5| Step: 4
Training loss: 2.2931056022644043
Validation loss: 2.0461406797491093

Epoch: 5| Step: 5
Training loss: 1.854060173034668
Validation loss: 2.040891385847522

Epoch: 5| Step: 6
Training loss: 1.6713920831680298
Validation loss: 2.0518165557615218

Epoch: 5| Step: 7
Training loss: 2.3132593631744385
Validation loss: 2.0632774086408716

Epoch: 5| Step: 8
Training loss: 1.9085195064544678
Validation loss: 2.053204873556732

Epoch: 5| Step: 9
Training loss: 2.1098930835723877
Validation loss: 2.0636414507383942

Epoch: 5| Step: 10
Training loss: 2.036062479019165
Validation loss: 2.0653613331497356

Epoch: 340| Step: 0
Training loss: 2.2703499794006348
Validation loss: 2.058760086695353

Epoch: 5| Step: 1
Training loss: 2.1065385341644287
Validation loss: 2.062006283831853

Epoch: 5| Step: 2
Training loss: 2.4626994132995605
Validation loss: 2.062632650457403

Epoch: 5| Step: 3
Training loss: 1.6660915613174438
Validation loss: 2.060790661842592

Epoch: 5| Step: 4
Training loss: 2.2011115550994873
Validation loss: 2.0554603286968764

Epoch: 5| Step: 5
Training loss: 1.771598219871521
Validation loss: 2.063482863928682

Epoch: 5| Step: 6
Training loss: 2.2822604179382324
Validation loss: 2.053708243113692

Epoch: 5| Step: 7
Training loss: 2.4250638484954834
Validation loss: 2.070815533720037

Epoch: 5| Step: 8
Training loss: 1.9749021530151367
Validation loss: 2.038813752512778

Epoch: 5| Step: 9
Training loss: 1.9477142095565796
Validation loss: 2.0439954380835257

Epoch: 5| Step: 10
Training loss: 1.9048293828964233
Validation loss: 2.042729728965349

Epoch: 341| Step: 0
Training loss: 2.3264384269714355
Validation loss: 2.048784617454775

Epoch: 5| Step: 1
Training loss: 2.6492419242858887
Validation loss: 2.045523184601979

Epoch: 5| Step: 2
Training loss: 2.872378349304199
Validation loss: 2.043334294390935

Epoch: 5| Step: 3
Training loss: 2.1756067276000977
Validation loss: 2.0507954653873237

Epoch: 5| Step: 4
Training loss: 2.258793592453003
Validation loss: 2.055261109464912

Epoch: 5| Step: 5
Training loss: 1.945738434791565
Validation loss: 2.0505173590875443

Epoch: 5| Step: 6
Training loss: 2.12544584274292
Validation loss: 2.0362299719164447

Epoch: 5| Step: 7
Training loss: 1.4911950826644897
Validation loss: 2.036922465088547

Epoch: 5| Step: 8
Training loss: 1.3751057386398315
Validation loss: 2.051742346056046

Epoch: 5| Step: 9
Training loss: 1.484872817993164
Validation loss: 2.044136498564033

Epoch: 5| Step: 10
Training loss: 2.316774606704712
Validation loss: 2.0605846886993735

Epoch: 342| Step: 0
Training loss: 2.3719992637634277
Validation loss: 2.0634433607901297

Epoch: 5| Step: 1
Training loss: 2.0712881088256836
Validation loss: 2.064298686160836

Epoch: 5| Step: 2
Training loss: 2.45784330368042
Validation loss: 2.054858317939184

Epoch: 5| Step: 3
Training loss: 1.5176867246627808
Validation loss: 2.042057398826845

Epoch: 5| Step: 4
Training loss: 1.834231972694397
Validation loss: 2.045433934016894

Epoch: 5| Step: 5
Training loss: 2.3140053749084473
Validation loss: 2.0405885865611415

Epoch: 5| Step: 6
Training loss: 2.325186252593994
Validation loss: 2.030960423972017

Epoch: 5| Step: 7
Training loss: 1.7936108112335205
Validation loss: 2.0354344408999205

Epoch: 5| Step: 8
Training loss: 2.3396172523498535
Validation loss: 2.0174899947258735

Epoch: 5| Step: 9
Training loss: 1.5909936428070068
Validation loss: 2.038419479964882

Epoch: 5| Step: 10
Training loss: 2.3578033447265625
Validation loss: 2.033763111278575

Epoch: 343| Step: 0
Training loss: 1.6729816198349
Validation loss: 2.046537491583055

Epoch: 5| Step: 1
Training loss: 2.4889588356018066
Validation loss: 2.0355326770454325

Epoch: 5| Step: 2
Training loss: 2.4080231189727783
Validation loss: 2.0419099715448197

Epoch: 5| Step: 3
Training loss: 1.9675582647323608
Validation loss: 2.0600316473232803

Epoch: 5| Step: 4
Training loss: 2.4461300373077393
Validation loss: 2.068057552460701

Epoch: 5| Step: 5
Training loss: 2.078953742980957
Validation loss: 2.0612757526418215

Epoch: 5| Step: 6
Training loss: 2.285210371017456
Validation loss: 2.067647400722709

Epoch: 5| Step: 7
Training loss: 1.9237617254257202
Validation loss: 2.0695864667174635

Epoch: 5| Step: 8
Training loss: 1.6355899572372437
Validation loss: 2.0766939706699823

Epoch: 5| Step: 9
Training loss: 2.2402985095977783
Validation loss: 2.0660416644106627

Epoch: 5| Step: 10
Training loss: 1.9016367197036743
Validation loss: 2.0587001487772953

Epoch: 344| Step: 0
Training loss: 1.6855051517486572
Validation loss: 2.0610531222435737

Epoch: 5| Step: 1
Training loss: 1.8796937465667725
Validation loss: 2.046257741989628

Epoch: 5| Step: 2
Training loss: 2.1606879234313965
Validation loss: 2.035829423576273

Epoch: 5| Step: 3
Training loss: 1.5541250705718994
Validation loss: 2.023815493429861

Epoch: 5| Step: 4
Training loss: 2.4089529514312744
Validation loss: 2.0324578926127446

Epoch: 5| Step: 5
Training loss: 1.584702730178833
Validation loss: 2.037783697087278

Epoch: 5| Step: 6
Training loss: 1.889059066772461
Validation loss: 2.043784228704309

Epoch: 5| Step: 7
Training loss: 2.893458843231201
Validation loss: 2.0392756244187713

Epoch: 5| Step: 8
Training loss: 2.6495494842529297
Validation loss: 2.0273231511474936

Epoch: 5| Step: 9
Training loss: 2.526442289352417
Validation loss: 2.036393263006723

Epoch: 5| Step: 10
Training loss: 1.8044794797897339
Validation loss: 2.034949538528278

Epoch: 345| Step: 0
Training loss: 2.0235908031463623
Validation loss: 2.030708496288587

Epoch: 5| Step: 1
Training loss: 2.2206239700317383
Validation loss: 2.0337273074734594

Epoch: 5| Step: 2
Training loss: 2.4388997554779053
Validation loss: 2.027975143924836

Epoch: 5| Step: 3
Training loss: 2.2007460594177246
Validation loss: 2.04829458139276

Epoch: 5| Step: 4
Training loss: 2.341810703277588
Validation loss: 2.051201007699454

Epoch: 5| Step: 5
Training loss: 2.1429150104522705
Validation loss: 2.0555870866262786

Epoch: 5| Step: 6
Training loss: 1.1776288747787476
Validation loss: 2.0677969776174074

Epoch: 5| Step: 7
Training loss: 1.8233743906021118
Validation loss: 2.0706111807977

Epoch: 5| Step: 8
Training loss: 2.1456685066223145
Validation loss: 2.0659702644553235

Epoch: 5| Step: 9
Training loss: 1.9915916919708252
Validation loss: 2.086121823198052

Epoch: 5| Step: 10
Training loss: 2.6632673740386963
Validation loss: 2.0751831044432936

Epoch: 346| Step: 0
Training loss: 2.538811206817627
Validation loss: 2.053733725701609

Epoch: 5| Step: 1
Training loss: 1.9738070964813232
Validation loss: 2.0655918736611643

Epoch: 5| Step: 2
Training loss: 1.4912853240966797
Validation loss: 2.058954518328431

Epoch: 5| Step: 3
Training loss: 2.1576015949249268
Validation loss: 2.060212994134554

Epoch: 5| Step: 4
Training loss: 1.7273178100585938
Validation loss: 2.0661876868176203

Epoch: 5| Step: 5
Training loss: 2.1429104804992676
Validation loss: 2.0447975230473343

Epoch: 5| Step: 6
Training loss: 2.213132381439209
Validation loss: 2.0396179255618843

Epoch: 5| Step: 7
Training loss: 1.830536127090454
Validation loss: 2.0536915204858266

Epoch: 5| Step: 8
Training loss: 2.186126470565796
Validation loss: 2.040358915123888

Epoch: 5| Step: 9
Training loss: 2.066838026046753
Validation loss: 2.043444407883511

Epoch: 5| Step: 10
Training loss: 2.6865806579589844
Validation loss: 2.053661390017438

Epoch: 347| Step: 0
Training loss: 2.1874442100524902
Validation loss: 2.052041745954944

Epoch: 5| Step: 1
Training loss: 2.395711898803711
Validation loss: 2.05587504243338

Epoch: 5| Step: 2
Training loss: 2.2026264667510986
Validation loss: 2.0502955759725263

Epoch: 5| Step: 3
Training loss: 1.9908441305160522
Validation loss: 2.0508951576807166

Epoch: 5| Step: 4
Training loss: 2.2144174575805664
Validation loss: 2.0560125945716776

Epoch: 5| Step: 5
Training loss: 2.077014207839966
Validation loss: 2.0691988468170166

Epoch: 5| Step: 6
Training loss: 2.021090030670166
Validation loss: 2.0561350519939134

Epoch: 5| Step: 7
Training loss: 2.1517200469970703
Validation loss: 2.0423613696969967

Epoch: 5| Step: 8
Training loss: 2.1392064094543457
Validation loss: 2.058691079898547

Epoch: 5| Step: 9
Training loss: 1.9131832122802734
Validation loss: 2.0585921246518373

Epoch: 5| Step: 10
Training loss: 1.5484108924865723
Validation loss: 2.030893289914695

Epoch: 348| Step: 0
Training loss: 2.3056540489196777
Validation loss: 2.054643577144992

Epoch: 5| Step: 1
Training loss: 2.2238335609436035
Validation loss: 2.0597736784206924

Epoch: 5| Step: 2
Training loss: 2.0507991313934326
Validation loss: 2.042294261276081

Epoch: 5| Step: 3
Training loss: 2.0009703636169434
Validation loss: 2.0557958951560398

Epoch: 5| Step: 4
Training loss: 2.0145645141601562
Validation loss: 2.0700761348970476

Epoch: 5| Step: 5
Training loss: 1.6625906229019165
Validation loss: 2.05711543175482

Epoch: 5| Step: 6
Training loss: 1.5643179416656494
Validation loss: 2.0539292571365193

Epoch: 5| Step: 7
Training loss: 2.0135657787323
Validation loss: 2.0550188710612636

Epoch: 5| Step: 8
Training loss: 2.4812510013580322
Validation loss: 2.048121299794925

Epoch: 5| Step: 9
Training loss: 2.021946668624878
Validation loss: 2.043012706182336

Epoch: 5| Step: 10
Training loss: 2.6661136150360107
Validation loss: 2.0445233057903986

Epoch: 349| Step: 0
Training loss: 2.61285138130188
Validation loss: 2.030452787235219

Epoch: 5| Step: 1
Training loss: 1.7977664470672607
Validation loss: 2.054868908338649

Epoch: 5| Step: 2
Training loss: 2.5114898681640625
Validation loss: 2.054154775475943

Epoch: 5| Step: 3
Training loss: 1.7881698608398438
Validation loss: 2.0490137018183225

Epoch: 5| Step: 4
Training loss: 2.136943817138672
Validation loss: 2.0521732889195925

Epoch: 5| Step: 5
Training loss: 1.9405434131622314
Validation loss: 2.0583103574732298

Epoch: 5| Step: 6
Training loss: 2.2105660438537598
Validation loss: 2.0631342831478325

Epoch: 5| Step: 7
Training loss: 1.5831773281097412
Validation loss: 2.0679751083415043

Epoch: 5| Step: 8
Training loss: 2.476806402206421
Validation loss: 2.086683432261149

Epoch: 5| Step: 9
Training loss: 2.061467170715332
Validation loss: 2.0784189521625476

Epoch: 5| Step: 10
Training loss: 1.740508794784546
Validation loss: 2.06544231343013

Epoch: 350| Step: 0
Training loss: 2.1108880043029785
Validation loss: 2.0753270477376957

Epoch: 5| Step: 1
Training loss: 2.4209342002868652
Validation loss: 2.067193159493067

Epoch: 5| Step: 2
Training loss: 1.8951069116592407
Validation loss: 2.05645340552894

Epoch: 5| Step: 3
Training loss: 2.2047133445739746
Validation loss: 2.0507934644658077

Epoch: 5| Step: 4
Training loss: 2.315248727798462
Validation loss: 2.0336425150594404

Epoch: 5| Step: 5
Training loss: 2.309641122817993
Validation loss: 2.0259514239526566

Epoch: 5| Step: 6
Training loss: 2.0662732124328613
Validation loss: 2.0236820046619703

Epoch: 5| Step: 7
Training loss: 2.0835258960723877
Validation loss: 2.034689312340111

Epoch: 5| Step: 8
Training loss: 2.051924228668213
Validation loss: 2.0316381736468245

Epoch: 5| Step: 9
Training loss: 1.7244746685028076
Validation loss: 2.037121847111692

Epoch: 5| Step: 10
Training loss: 1.6622965335845947
Validation loss: 2.0332696002016784

Epoch: 351| Step: 0
Training loss: 2.089386463165283
Validation loss: 2.040375263460221

Epoch: 5| Step: 1
Training loss: 1.926361322402954
Validation loss: 2.055110857050906

Epoch: 5| Step: 2
Training loss: 2.1524128913879395
Validation loss: 2.0686231633668304

Epoch: 5| Step: 3
Training loss: 2.222557783126831
Validation loss: 2.0620095601645847

Epoch: 5| Step: 4
Training loss: 2.055203914642334
Validation loss: 2.0663829388157016

Epoch: 5| Step: 5
Training loss: 1.9948015213012695
Validation loss: 2.092857624894829

Epoch: 5| Step: 6
Training loss: 2.1739606857299805
Validation loss: 2.081693233982209

Epoch: 5| Step: 7
Training loss: 1.5945188999176025
Validation loss: 2.0807878817281416

Epoch: 5| Step: 8
Training loss: 2.1715033054351807
Validation loss: 2.078885591158303

Epoch: 5| Step: 9
Training loss: 1.8367493152618408
Validation loss: 2.071763248853786

Epoch: 5| Step: 10
Training loss: 2.7232842445373535
Validation loss: 2.0534067974295667

Epoch: 352| Step: 0
Training loss: 2.6106910705566406
Validation loss: 2.0731707337082073

Epoch: 5| Step: 1
Training loss: 2.2390785217285156
Validation loss: 2.0785245780021913

Epoch: 5| Step: 2
Training loss: 2.4493203163146973
Validation loss: 2.060642021958546

Epoch: 5| Step: 3
Training loss: 2.259368896484375
Validation loss: 2.047576847896781

Epoch: 5| Step: 4
Training loss: 1.421584129333496
Validation loss: 2.045794302417386

Epoch: 5| Step: 5
Training loss: 2.5647454261779785
Validation loss: 2.037761039631341

Epoch: 5| Step: 6
Training loss: 1.4670650959014893
Validation loss: 2.0348066245355914

Epoch: 5| Step: 7
Training loss: 2.1708619594573975
Validation loss: 2.0339775354631486

Epoch: 5| Step: 8
Training loss: 1.655901312828064
Validation loss: 2.038487216477753

Epoch: 5| Step: 9
Training loss: 2.0333638191223145
Validation loss: 2.046391510194348

Epoch: 5| Step: 10
Training loss: 2.048092842102051
Validation loss: 2.0500719649817354

Epoch: 353| Step: 0
Training loss: 2.0556814670562744
Validation loss: 2.06189703172253

Epoch: 5| Step: 1
Training loss: 1.863835334777832
Validation loss: 2.0550876868668424

Epoch: 5| Step: 2
Training loss: 2.4551658630371094
Validation loss: 2.066567361995738

Epoch: 5| Step: 3
Training loss: 2.1526401042938232
Validation loss: 2.0529724141602874

Epoch: 5| Step: 4
Training loss: 2.2503163814544678
Validation loss: 2.0460992243982132

Epoch: 5| Step: 5
Training loss: 3.075230121612549
Validation loss: 2.03434907749135

Epoch: 5| Step: 6
Training loss: 1.8637053966522217
Validation loss: 2.0235569400172078

Epoch: 5| Step: 7
Training loss: 2.0685477256774902
Validation loss: 2.01238670656758

Epoch: 5| Step: 8
Training loss: 2.017228603363037
Validation loss: 2.0190726505812777

Epoch: 5| Step: 9
Training loss: 1.439940094947815
Validation loss: 2.021509421769009

Epoch: 5| Step: 10
Training loss: 1.7487694025039673
Validation loss: 2.030742620909086

Epoch: 354| Step: 0
Training loss: 1.521289587020874
Validation loss: 2.038175244485178

Epoch: 5| Step: 1
Training loss: 1.8476760387420654
Validation loss: 2.0413086106700282

Epoch: 5| Step: 2
Training loss: 2.147610902786255
Validation loss: 2.0524495775981615

Epoch: 5| Step: 3
Training loss: 2.7413511276245117
Validation loss: 2.034144837369201

Epoch: 5| Step: 4
Training loss: 1.9516674280166626
Validation loss: 2.058483878771464

Epoch: 5| Step: 5
Training loss: 2.103980541229248
Validation loss: 2.0645654509144444

Epoch: 5| Step: 6
Training loss: 2.3547205924987793
Validation loss: 2.067646834158128

Epoch: 5| Step: 7
Training loss: 2.470184803009033
Validation loss: 2.0656808294275755

Epoch: 5| Step: 8
Training loss: 2.018974781036377
Validation loss: 2.0582443027086157

Epoch: 5| Step: 9
Training loss: 1.5623632669448853
Validation loss: 2.0567772157730593

Epoch: 5| Step: 10
Training loss: 2.1242809295654297
Validation loss: 2.0502764460861043

Epoch: 355| Step: 0
Training loss: 2.220982074737549
Validation loss: 2.0522753807806198

Epoch: 5| Step: 1
Training loss: 1.6633220911026
Validation loss: 2.045825171214278

Epoch: 5| Step: 2
Training loss: 2.1642422676086426
Validation loss: 2.0463191386192077

Epoch: 5| Step: 3
Training loss: 3.126295804977417
Validation loss: 2.040463762898599

Epoch: 5| Step: 4
Training loss: 1.7746508121490479
Validation loss: 2.0454604112973778

Epoch: 5| Step: 5
Training loss: 2.0578513145446777
Validation loss: 2.028692981248261

Epoch: 5| Step: 6
Training loss: 1.5183799266815186
Validation loss: 2.0264964436972015

Epoch: 5| Step: 7
Training loss: 1.79103684425354
Validation loss: 2.0287093052300076

Epoch: 5| Step: 8
Training loss: 2.0040714740753174
Validation loss: 2.0241344872341362

Epoch: 5| Step: 9
Training loss: 2.05249285697937
Validation loss: 2.041839973900908

Epoch: 5| Step: 10
Training loss: 2.357464551925659
Validation loss: 2.045780933031472

Epoch: 356| Step: 0
Training loss: 1.798235297203064
Validation loss: 2.0385429602797314

Epoch: 5| Step: 1
Training loss: 1.7190673351287842
Validation loss: 2.051946360577819

Epoch: 5| Step: 2
Training loss: 2.5472207069396973
Validation loss: 2.069955254113802

Epoch: 5| Step: 3
Training loss: 2.578230619430542
Validation loss: 2.06496242297593

Epoch: 5| Step: 4
Training loss: 1.8714332580566406
Validation loss: 2.0751662113333262

Epoch: 5| Step: 5
Training loss: 2.1311283111572266
Validation loss: 2.053339030153008

Epoch: 5| Step: 6
Training loss: 1.7906367778778076
Validation loss: 2.05252008540656

Epoch: 5| Step: 7
Training loss: 2.2167744636535645
Validation loss: 2.053415036970569

Epoch: 5| Step: 8
Training loss: 2.5136215686798096
Validation loss: 2.0362335366587483

Epoch: 5| Step: 9
Training loss: 1.7821285724639893
Validation loss: 2.036490435241371

Epoch: 5| Step: 10
Training loss: 1.7749755382537842
Validation loss: 2.028452677111472

Epoch: 357| Step: 0
Training loss: 1.7830114364624023
Validation loss: 2.038484124727147

Epoch: 5| Step: 1
Training loss: 1.95688796043396
Validation loss: 2.03509162574686

Epoch: 5| Step: 2
Training loss: 2.3003451824188232
Validation loss: 2.0314515021539505

Epoch: 5| Step: 3
Training loss: 1.5611881017684937
Validation loss: 2.0262592710474485

Epoch: 5| Step: 4
Training loss: 2.2802646160125732
Validation loss: 2.04252343152159

Epoch: 5| Step: 5
Training loss: 1.9752180576324463
Validation loss: 2.057982372981246

Epoch: 5| Step: 6
Training loss: 1.721832513809204
Validation loss: 2.0503048742971113

Epoch: 5| Step: 7
Training loss: 2.425771474838257
Validation loss: 2.0550125170779485

Epoch: 5| Step: 8
Training loss: 2.562636613845825
Validation loss: 2.064848538367979

Epoch: 5| Step: 9
Training loss: 1.8229385614395142
Validation loss: 2.0691867720696235

Epoch: 5| Step: 10
Training loss: 2.3627243041992188
Validation loss: 2.064572239434847

Epoch: 358| Step: 0
Training loss: 2.507190227508545
Validation loss: 2.0650028874797206

Epoch: 5| Step: 1
Training loss: 2.281235694885254
Validation loss: 2.066783905029297

Epoch: 5| Step: 2
Training loss: 1.6666721105575562
Validation loss: 2.0531734189679547

Epoch: 5| Step: 3
Training loss: 2.6188857555389404
Validation loss: 2.0485999097106276

Epoch: 5| Step: 4
Training loss: 2.087827205657959
Validation loss: 2.047355135281881

Epoch: 5| Step: 5
Training loss: 1.6941282749176025
Validation loss: 2.0594080776296635

Epoch: 5| Step: 6
Training loss: 1.504555583000183
Validation loss: 2.0551280398522653

Epoch: 5| Step: 7
Training loss: 2.1539180278778076
Validation loss: 2.052385522473243

Epoch: 5| Step: 8
Training loss: 2.020528793334961
Validation loss: 2.0385091509870303

Epoch: 5| Step: 9
Training loss: 1.8951339721679688
Validation loss: 2.0392270959833616

Epoch: 5| Step: 10
Training loss: 2.284799575805664
Validation loss: 2.0445601683790966

Epoch: 359| Step: 0
Training loss: 2.525188684463501
Validation loss: 2.0336086429575437

Epoch: 5| Step: 1
Training loss: 2.278684139251709
Validation loss: 2.023262941709129

Epoch: 5| Step: 2
Training loss: 1.644506812095642
Validation loss: 2.0356771279406805

Epoch: 5| Step: 3
Training loss: 2.174765110015869
Validation loss: 2.0275095483308196

Epoch: 5| Step: 4
Training loss: 1.5012835264205933
Validation loss: 2.0210319065278575

Epoch: 5| Step: 5
Training loss: 2.0323026180267334
Validation loss: 2.028679509316721

Epoch: 5| Step: 6
Training loss: 1.949872374534607
Validation loss: 2.021986460173002

Epoch: 5| Step: 7
Training loss: 2.0593459606170654
Validation loss: 2.029978170189806

Epoch: 5| Step: 8
Training loss: 2.7156801223754883
Validation loss: 2.035171657480219

Epoch: 5| Step: 9
Training loss: 1.8477624654769897
Validation loss: 2.0301689511986187

Epoch: 5| Step: 10
Training loss: 1.8480511903762817
Validation loss: 2.034050453093744

Epoch: 360| Step: 0
Training loss: 2.1843442916870117
Validation loss: 2.051466143259438

Epoch: 5| Step: 1
Training loss: 2.0623016357421875
Validation loss: 2.0583283183395222

Epoch: 5| Step: 2
Training loss: 2.5428059101104736
Validation loss: 2.0455771005281838

Epoch: 5| Step: 3
Training loss: 1.9140701293945312
Validation loss: 2.04786729556258

Epoch: 5| Step: 4
Training loss: 1.7849842309951782
Validation loss: 2.0419880062021236

Epoch: 5| Step: 5
Training loss: 1.9207664728164673
Validation loss: 2.037973392394281

Epoch: 5| Step: 6
Training loss: 2.1078548431396484
Validation loss: 2.0329488528672086

Epoch: 5| Step: 7
Training loss: 2.3692612648010254
Validation loss: 2.0480019507869596

Epoch: 5| Step: 8
Training loss: 2.243140459060669
Validation loss: 2.042521543400262

Epoch: 5| Step: 9
Training loss: 1.664544701576233
Validation loss: 2.0342013528270106

Epoch: 5| Step: 10
Training loss: 1.7985213994979858
Validation loss: 2.0554621706726732

Epoch: 361| Step: 0
Training loss: 2.117023468017578
Validation loss: 2.0574083815338793

Epoch: 5| Step: 1
Training loss: 1.5063875913619995
Validation loss: 2.054246399992256

Epoch: 5| Step: 2
Training loss: 2.297950029373169
Validation loss: 2.0516279384654057

Epoch: 5| Step: 3
Training loss: 2.0386176109313965
Validation loss: 2.0467199561416463

Epoch: 5| Step: 4
Training loss: 2.5192711353302
Validation loss: 2.046981192404224

Epoch: 5| Step: 5
Training loss: 2.7742908000946045
Validation loss: 2.0340306707607803

Epoch: 5| Step: 6
Training loss: 1.5553534030914307
Validation loss: 2.0325303487880255

Epoch: 5| Step: 7
Training loss: 1.8289268016815186
Validation loss: 2.0261872865820445

Epoch: 5| Step: 8
Training loss: 2.0927340984344482
Validation loss: 2.0219475069353656

Epoch: 5| Step: 9
Training loss: 2.3235621452331543
Validation loss: 2.028076507711923

Epoch: 5| Step: 10
Training loss: 1.4091929197311401
Validation loss: 2.0368182877058625

Epoch: 362| Step: 0
Training loss: 2.39021635055542
Validation loss: 2.046360687542987

Epoch: 5| Step: 1
Training loss: 1.7717926502227783
Validation loss: 2.065891259460039

Epoch: 5| Step: 2
Training loss: 1.861867904663086
Validation loss: 2.0535205359100015

Epoch: 5| Step: 3
Training loss: 2.0785071849823
Validation loss: 2.06136820649588

Epoch: 5| Step: 4
Training loss: 2.3771984577178955
Validation loss: 2.053853431055623

Epoch: 5| Step: 5
Training loss: 1.6672195196151733
Validation loss: 2.061314013696486

Epoch: 5| Step: 6
Training loss: 2.3070693016052246
Validation loss: 2.06280110215628

Epoch: 5| Step: 7
Training loss: 2.387648344039917
Validation loss: 2.0624724857268797

Epoch: 5| Step: 8
Training loss: 1.7611840963363647
Validation loss: 2.0403912195595364

Epoch: 5| Step: 9
Training loss: 1.7847020626068115
Validation loss: 2.0524407740562194

Epoch: 5| Step: 10
Training loss: 2.250929355621338
Validation loss: 2.0375085543560725

Epoch: 363| Step: 0
Training loss: 2.148686647415161
Validation loss: 2.0337295506590154

Epoch: 5| Step: 1
Training loss: 1.3088243007659912
Validation loss: 2.0402851091918124

Epoch: 5| Step: 2
Training loss: 1.6257375478744507
Validation loss: 2.0326791347995883

Epoch: 5| Step: 3
Training loss: 2.708118438720703
Validation loss: 2.036691132412162

Epoch: 5| Step: 4
Training loss: 2.2009692192077637
Validation loss: 2.0345260276589343

Epoch: 5| Step: 5
Training loss: 2.0815625190734863
Validation loss: 2.0436562415092223

Epoch: 5| Step: 6
Training loss: 2.2350313663482666
Validation loss: 2.0478881020699777

Epoch: 5| Step: 7
Training loss: 2.6736416816711426
Validation loss: 2.033450448384849

Epoch: 5| Step: 8
Training loss: 1.5433610677719116
Validation loss: 2.0387372739853395

Epoch: 5| Step: 9
Training loss: 2.2112975120544434
Validation loss: 2.040976466671113

Epoch: 5| Step: 10
Training loss: 1.8049843311309814
Validation loss: 2.0335574278267483

Epoch: 364| Step: 0
Training loss: 1.9589049816131592
Validation loss: 2.057807824944937

Epoch: 5| Step: 1
Training loss: 1.9340463876724243
Validation loss: 2.0481261822485153

Epoch: 5| Step: 2
Training loss: 2.1590962409973145
Validation loss: 2.0597110538072485

Epoch: 5| Step: 3
Training loss: 2.7547059059143066
Validation loss: 2.05242411551937

Epoch: 5| Step: 4
Training loss: 2.001258611679077
Validation loss: 2.0370449199471423

Epoch: 5| Step: 5
Training loss: 1.4547312259674072
Validation loss: 2.0399349261355657

Epoch: 5| Step: 6
Training loss: 2.5761947631835938
Validation loss: 2.0369646626134075

Epoch: 5| Step: 7
Training loss: 1.3882921934127808
Validation loss: 2.0315868495613016

Epoch: 5| Step: 8
Training loss: 2.085111618041992
Validation loss: 2.0561826126549834

Epoch: 5| Step: 9
Training loss: 2.0730385780334473
Validation loss: 2.040806375524049

Epoch: 5| Step: 10
Training loss: 2.0558853149414062
Validation loss: 2.0522944042759557

Epoch: 365| Step: 0
Training loss: 1.6561861038208008
Validation loss: 2.0603734780383367

Epoch: 5| Step: 1
Training loss: 2.722555160522461
Validation loss: 2.0384300319097375

Epoch: 5| Step: 2
Training loss: 1.5943055152893066
Validation loss: 2.029896366980768

Epoch: 5| Step: 3
Training loss: 1.7663829326629639
Validation loss: 2.038422897297849

Epoch: 5| Step: 4
Training loss: 1.9783546924591064
Validation loss: 2.0458190133494716

Epoch: 5| Step: 5
Training loss: 2.5409886837005615
Validation loss: 2.063183884466848

Epoch: 5| Step: 6
Training loss: 1.9941608905792236
Validation loss: 2.0748988082331996

Epoch: 5| Step: 7
Training loss: 1.753700613975525
Validation loss: 2.0728375129802252

Epoch: 5| Step: 8
Training loss: 2.0333714485168457
Validation loss: 2.0868669709851666

Epoch: 5| Step: 9
Training loss: 2.1098740100860596
Validation loss: 2.0630304480111725

Epoch: 5| Step: 10
Training loss: 2.5103156566619873
Validation loss: 2.0547520191438737

Epoch: 366| Step: 0
Training loss: 1.5585576295852661
Validation loss: 2.056123996293673

Epoch: 5| Step: 1
Training loss: 2.623713970184326
Validation loss: 2.0430888001636793

Epoch: 5| Step: 2
Training loss: 2.304417848587036
Validation loss: 2.0405648780125443

Epoch: 5| Step: 3
Training loss: 1.6090247631072998
Validation loss: 2.0487437709685294

Epoch: 5| Step: 4
Training loss: 2.165461778640747
Validation loss: 2.067893171823153

Epoch: 5| Step: 5
Training loss: 2.2624526023864746
Validation loss: 2.0654079093728015

Epoch: 5| Step: 6
Training loss: 2.0328471660614014
Validation loss: 2.0392856213354293

Epoch: 5| Step: 7
Training loss: 1.8411438465118408
Validation loss: 2.0326003720683437

Epoch: 5| Step: 8
Training loss: 2.058307647705078
Validation loss: 2.028326460110244

Epoch: 5| Step: 9
Training loss: 2.078707695007324
Validation loss: 2.0353603965492657

Epoch: 5| Step: 10
Training loss: 2.1657238006591797
Validation loss: 2.0448276535157235

Epoch: 367| Step: 0
Training loss: 1.8641847372055054
Validation loss: 2.0529242100254184

Epoch: 5| Step: 1
Training loss: 2.3021297454833984
Validation loss: 2.050937714115266

Epoch: 5| Step: 2
Training loss: 2.4913558959960938
Validation loss: 2.059340638499106

Epoch: 5| Step: 3
Training loss: 2.1267459392547607
Validation loss: 2.047320160814511

Epoch: 5| Step: 4
Training loss: 1.7656383514404297
Validation loss: 2.0425782524129397

Epoch: 5| Step: 5
Training loss: 2.1208701133728027
Validation loss: 2.035850565920594

Epoch: 5| Step: 6
Training loss: 1.7783458232879639
Validation loss: 2.031145412434814

Epoch: 5| Step: 7
Training loss: 2.1540017127990723
Validation loss: 2.0290745330113236

Epoch: 5| Step: 8
Training loss: 1.4911770820617676
Validation loss: 2.0281051410141813

Epoch: 5| Step: 9
Training loss: 2.154837131500244
Validation loss: 2.029731550524312

Epoch: 5| Step: 10
Training loss: 2.327554225921631
Validation loss: 2.022284858970232

Epoch: 368| Step: 0
Training loss: 2.134800434112549
Validation loss: 2.0375563739448466

Epoch: 5| Step: 1
Training loss: 2.019940137863159
Validation loss: 2.0470377796439716

Epoch: 5| Step: 2
Training loss: 2.181614637374878
Validation loss: 2.048110536349717

Epoch: 5| Step: 3
Training loss: 2.114954710006714
Validation loss: 2.054730523017145

Epoch: 5| Step: 4
Training loss: 1.9080814123153687
Validation loss: 2.032825331534109

Epoch: 5| Step: 5
Training loss: 2.2262778282165527
Validation loss: 2.0468065777132587

Epoch: 5| Step: 6
Training loss: 2.2232837677001953
Validation loss: 2.0577844817151307

Epoch: 5| Step: 7
Training loss: 1.8684800863265991
Validation loss: 2.062425228857225

Epoch: 5| Step: 8
Training loss: 2.0966057777404785
Validation loss: 2.0702365931644233

Epoch: 5| Step: 9
Training loss: 2.1864724159240723
Validation loss: 2.0496551952054425

Epoch: 5| Step: 10
Training loss: 1.343480110168457
Validation loss: 2.055485058856267

Epoch: 369| Step: 0
Training loss: 1.580091118812561
Validation loss: 2.0442359832025345

Epoch: 5| Step: 1
Training loss: 1.7891457080841064
Validation loss: 2.0334934931929394

Epoch: 5| Step: 2
Training loss: 2.343215227127075
Validation loss: 2.052903349681567

Epoch: 5| Step: 3
Training loss: 1.7919785976409912
Validation loss: 2.036412336493051

Epoch: 5| Step: 4
Training loss: 2.1963438987731934
Validation loss: 2.053103922515787

Epoch: 5| Step: 5
Training loss: 1.5010906457901
Validation loss: 2.0491962817407425

Epoch: 5| Step: 6
Training loss: 2.042588710784912
Validation loss: 2.039277148503129

Epoch: 5| Step: 7
Training loss: 2.2359185218811035
Validation loss: 2.0420661408414125

Epoch: 5| Step: 8
Training loss: 1.7123124599456787
Validation loss: 2.039894732095862

Epoch: 5| Step: 9
Training loss: 3.251692295074463
Validation loss: 2.0189750066367527

Epoch: 5| Step: 10
Training loss: 1.8973970413208008
Validation loss: 2.0422101033631193

Epoch: 370| Step: 0
Training loss: 1.4565534591674805
Validation loss: 2.0440211629354827

Epoch: 5| Step: 1
Training loss: 1.6598917245864868
Validation loss: 2.0472048303132415

Epoch: 5| Step: 2
Training loss: 1.7902438640594482
Validation loss: 2.062046673990065

Epoch: 5| Step: 3
Training loss: 2.2063615322113037
Validation loss: 2.0601296027501426

Epoch: 5| Step: 4
Training loss: 2.665844678878784
Validation loss: 2.05064437466283

Epoch: 5| Step: 5
Training loss: 2.0312225818634033
Validation loss: 2.0376069763655305

Epoch: 5| Step: 6
Training loss: 2.2578625679016113
Validation loss: 2.030646642049154

Epoch: 5| Step: 7
Training loss: 2.1490349769592285
Validation loss: 2.0140799988982496

Epoch: 5| Step: 8
Training loss: 1.8436542749404907
Validation loss: 2.0107113443395144

Epoch: 5| Step: 9
Training loss: 1.886731505393982
Validation loss: 2.0157449578726165

Epoch: 5| Step: 10
Training loss: 2.50795841217041
Validation loss: 2.0193423942853044

Epoch: 371| Step: 0
Training loss: 2.1086959838867188
Validation loss: 2.0226910857744116

Epoch: 5| Step: 1
Training loss: 1.8349977731704712
Validation loss: 2.0191908959419496

Epoch: 5| Step: 2
Training loss: 2.35502290725708
Validation loss: 2.0102323088594662

Epoch: 5| Step: 3
Training loss: 2.6124672889709473
Validation loss: 2.005281130472819

Epoch: 5| Step: 4
Training loss: 1.7957732677459717
Validation loss: 2.024177029568662

Epoch: 5| Step: 5
Training loss: 1.7169063091278076
Validation loss: 2.0132121885976484

Epoch: 5| Step: 6
Training loss: 2.0423169136047363
Validation loss: 2.0282623844762004

Epoch: 5| Step: 7
Training loss: 1.9727907180786133
Validation loss: 2.0304375079370316

Epoch: 5| Step: 8
Training loss: 1.9149792194366455
Validation loss: 2.0401577898251113

Epoch: 5| Step: 9
Training loss: 1.5185599327087402
Validation loss: 2.0492729653594313

Epoch: 5| Step: 10
Training loss: 2.595191240310669
Validation loss: 2.0553106210565053

Epoch: 372| Step: 0
Training loss: 2.25752592086792
Validation loss: 2.0476923334983086

Epoch: 5| Step: 1
Training loss: 2.3298089504241943
Validation loss: 2.052007626461726

Epoch: 5| Step: 2
Training loss: 2.1341311931610107
Validation loss: 2.0509930887529926

Epoch: 5| Step: 3
Training loss: 1.2443523406982422
Validation loss: 2.0422949919136624

Epoch: 5| Step: 4
Training loss: 1.9496219158172607
Validation loss: 2.032228139138991

Epoch: 5| Step: 5
Training loss: 2.022169828414917
Validation loss: 2.040695674957768

Epoch: 5| Step: 6
Training loss: 1.8306163549423218
Validation loss: 2.027881903033103

Epoch: 5| Step: 7
Training loss: 2.448150157928467
Validation loss: 2.0418378563337427

Epoch: 5| Step: 8
Training loss: 2.188211679458618
Validation loss: 2.0445885017354

Epoch: 5| Step: 9
Training loss: 1.9246333837509155
Validation loss: 2.046095203327876

Epoch: 5| Step: 10
Training loss: 2.0521340370178223
Validation loss: 2.0511509115977953

Epoch: 373| Step: 0
Training loss: 2.06709361076355
Validation loss: 2.0397834649649997

Epoch: 5| Step: 1
Training loss: 2.792741060256958
Validation loss: 2.0477969518271824

Epoch: 5| Step: 2
Training loss: 1.807647943496704
Validation loss: 2.050042288277739

Epoch: 5| Step: 3
Training loss: 2.411907911300659
Validation loss: 2.0613004212738364

Epoch: 5| Step: 4
Training loss: 2.577875852584839
Validation loss: 2.056056364890068

Epoch: 5| Step: 5
Training loss: 1.9808250665664673
Validation loss: 2.050786349081224

Epoch: 5| Step: 6
Training loss: 1.1417465209960938
Validation loss: 2.043656251763785

Epoch: 5| Step: 7
Training loss: 2.0450034141540527
Validation loss: 2.0310447369852374

Epoch: 5| Step: 8
Training loss: 2.0228896141052246
Validation loss: 2.0240360972701863

Epoch: 5| Step: 9
Training loss: 1.7535836696624756
Validation loss: 2.020327970545779

Epoch: 5| Step: 10
Training loss: 1.8063772916793823
Validation loss: 2.0367019227755967

Epoch: 374| Step: 0
Training loss: 1.448481559753418
Validation loss: 2.016343137269379

Epoch: 5| Step: 1
Training loss: 1.7824490070343018
Validation loss: 2.029999684262019

Epoch: 5| Step: 2
Training loss: 2.3364806175231934
Validation loss: 2.025254682828021

Epoch: 5| Step: 3
Training loss: 2.208566188812256
Validation loss: 2.0292307023079164

Epoch: 5| Step: 4
Training loss: 1.7388598918914795
Validation loss: 2.0207528670628867

Epoch: 5| Step: 5
Training loss: 1.7884190082550049
Validation loss: 2.0101102167560208

Epoch: 5| Step: 6
Training loss: 1.9933325052261353
Validation loss: 2.034805190178656

Epoch: 5| Step: 7
Training loss: 2.4617831707000732
Validation loss: 2.043901321708515

Epoch: 5| Step: 8
Training loss: 2.404027223587036
Validation loss: 2.0490727193893923

Epoch: 5| Step: 9
Training loss: 2.3975868225097656
Validation loss: 2.062510282762589

Epoch: 5| Step: 10
Training loss: 1.9119387865066528
Validation loss: 2.051933773102299

Epoch: 375| Step: 0
Training loss: 2.0041868686676025
Validation loss: 2.0362012847777335

Epoch: 5| Step: 1
Training loss: 1.867431402206421
Validation loss: 2.0316156636002245

Epoch: 5| Step: 2
Training loss: 2.724193572998047
Validation loss: 2.027192279856692

Epoch: 5| Step: 3
Training loss: 1.9089834690093994
Validation loss: 2.0505702098210654

Epoch: 5| Step: 4
Training loss: 1.8505666255950928
Validation loss: 2.0453536664285967

Epoch: 5| Step: 5
Training loss: 2.118295907974243
Validation loss: 2.0535258144460697

Epoch: 5| Step: 6
Training loss: 2.1070332527160645
Validation loss: 2.052453637123108

Epoch: 5| Step: 7
Training loss: 2.1839802265167236
Validation loss: 2.0488478291419243

Epoch: 5| Step: 8
Training loss: 2.6967732906341553
Validation loss: 2.0213178639770835

Epoch: 5| Step: 9
Training loss: 1.385634183883667
Validation loss: 2.034030258014638

Epoch: 5| Step: 10
Training loss: 1.6972090005874634
Validation loss: 2.029653879903978

Epoch: 376| Step: 0
Training loss: 2.215090036392212
Validation loss: 2.059142804914905

Epoch: 5| Step: 1
Training loss: 1.700018286705017
Validation loss: 2.0643592111526

Epoch: 5| Step: 2
Training loss: 2.1764426231384277
Validation loss: 2.079142919150732

Epoch: 5| Step: 3
Training loss: 1.636423110961914
Validation loss: 2.0554091135660806

Epoch: 5| Step: 4
Training loss: 2.0172791481018066
Validation loss: 2.0443254593879945

Epoch: 5| Step: 5
Training loss: 1.7878621816635132
Validation loss: 2.0393924456770702

Epoch: 5| Step: 6
Training loss: 1.898336410522461
Validation loss: 2.005221248954855

Epoch: 5| Step: 7
Training loss: 2.4344687461853027
Validation loss: 2.00881274284855

Epoch: 5| Step: 8
Training loss: 2.172729015350342
Validation loss: 2.0062023721715456

Epoch: 5| Step: 9
Training loss: 2.3782386779785156
Validation loss: 2.020633897473735

Epoch: 5| Step: 10
Training loss: 2.086878776550293
Validation loss: 2.0147700848117953

Epoch: 377| Step: 0
Training loss: 1.840919852256775
Validation loss: 2.023888526424285

Epoch: 5| Step: 1
Training loss: 1.8597068786621094
Validation loss: 2.0186069293688704

Epoch: 5| Step: 2
Training loss: 1.8688628673553467
Validation loss: 2.0172046897231892

Epoch: 5| Step: 3
Training loss: 2.5725817680358887
Validation loss: 2.039770108397289

Epoch: 5| Step: 4
Training loss: 1.6279754638671875
Validation loss: 2.040517951852532

Epoch: 5| Step: 5
Training loss: 2.21345853805542
Validation loss: 2.05167696937438

Epoch: 5| Step: 6
Training loss: 2.2161364555358887
Validation loss: 2.0429247643357966

Epoch: 5| Step: 7
Training loss: 1.9525549411773682
Validation loss: 2.027673585440523

Epoch: 5| Step: 8
Training loss: 1.871403455734253
Validation loss: 2.040558143328595

Epoch: 5| Step: 9
Training loss: 1.8196041584014893
Validation loss: 2.0325053814918763

Epoch: 5| Step: 10
Training loss: 2.363787889480591
Validation loss: 2.0488157131338633

Epoch: 378| Step: 0
Training loss: 1.910103440284729
Validation loss: 2.0369674787726453

Epoch: 5| Step: 1
Training loss: 2.444800853729248
Validation loss: 2.041463498146303

Epoch: 5| Step: 2
Training loss: 1.7256767749786377
Validation loss: 2.033536021427442

Epoch: 5| Step: 3
Training loss: 1.736555814743042
Validation loss: 2.052295841196532

Epoch: 5| Step: 4
Training loss: 2.0748677253723145
Validation loss: 2.0415113074805147

Epoch: 5| Step: 5
Training loss: 1.6416162252426147
Validation loss: 2.0395331293024044

Epoch: 5| Step: 6
Training loss: 2.4367947578430176
Validation loss: 2.031100603841966

Epoch: 5| Step: 7
Training loss: 2.1036226749420166
Validation loss: 2.025219880124574

Epoch: 5| Step: 8
Training loss: 1.8937543630599976
Validation loss: 2.0199905762108425

Epoch: 5| Step: 9
Training loss: 2.37752103805542
Validation loss: 2.0283695049183343

Epoch: 5| Step: 10
Training loss: 1.9137423038482666
Validation loss: 2.0277891389785276

Epoch: 379| Step: 0
Training loss: 1.6480538845062256
Validation loss: 2.0184042120492585

Epoch: 5| Step: 1
Training loss: 2.198490858078003
Validation loss: 2.0234521819699194

Epoch: 5| Step: 2
Training loss: 2.0752272605895996
Validation loss: 2.0036448791462886

Epoch: 5| Step: 3
Training loss: 2.44295072555542
Validation loss: 2.0094046028711463

Epoch: 5| Step: 4
Training loss: 1.7978038787841797
Validation loss: 2.000201124016957

Epoch: 5| Step: 5
Training loss: 2.0806984901428223
Validation loss: 2.031859049233057

Epoch: 5| Step: 6
Training loss: 2.3193249702453613
Validation loss: 2.003768313315607

Epoch: 5| Step: 7
Training loss: 1.416764736175537
Validation loss: 2.0083371054741646

Epoch: 5| Step: 8
Training loss: 2.082660436630249
Validation loss: 2.019807228478052

Epoch: 5| Step: 9
Training loss: 1.9105726480484009
Validation loss: 2.0295754119914067

Epoch: 5| Step: 10
Training loss: 2.1931934356689453
Validation loss: 2.0275574191924064

Epoch: 380| Step: 0
Training loss: 2.652885913848877
Validation loss: 2.028103202901861

Epoch: 5| Step: 1
Training loss: 1.966095209121704
Validation loss: 2.0454830790078766

Epoch: 5| Step: 2
Training loss: 2.306579113006592
Validation loss: 2.0335322656939105

Epoch: 5| Step: 3
Training loss: 2.4564132690429688
Validation loss: 2.0396049125220186

Epoch: 5| Step: 4
Training loss: 1.1483925580978394
Validation loss: 2.057422045738466

Epoch: 5| Step: 5
Training loss: 2.102968215942383
Validation loss: 2.0605688659093713

Epoch: 5| Step: 6
Training loss: 1.8542534112930298
Validation loss: 2.0535949327612437

Epoch: 5| Step: 7
Training loss: 2.353663921356201
Validation loss: 2.0377242026790494

Epoch: 5| Step: 8
Training loss: 1.628095030784607
Validation loss: 2.040678931820777

Epoch: 5| Step: 9
Training loss: 1.9363203048706055
Validation loss: 2.0448140021293395

Epoch: 5| Step: 10
Training loss: 1.7266607284545898
Validation loss: 2.0249184690495974

Epoch: 381| Step: 0
Training loss: 2.7150585651397705
Validation loss: 2.0255173688293784

Epoch: 5| Step: 1
Training loss: 2.0169148445129395
Validation loss: 2.0243619693222867

Epoch: 5| Step: 2
Training loss: 1.4552061557769775
Validation loss: 2.025456843837615

Epoch: 5| Step: 3
Training loss: 2.173492431640625
Validation loss: 2.004180133983653

Epoch: 5| Step: 4
Training loss: 1.6516568660736084
Validation loss: 2.009080768913351

Epoch: 5| Step: 5
Training loss: 1.9724916219711304
Validation loss: 1.993035711267943

Epoch: 5| Step: 6
Training loss: 1.7027876377105713
Validation loss: 2.0117524170106456

Epoch: 5| Step: 7
Training loss: 1.7009445428848267
Validation loss: 2.015488733527481

Epoch: 5| Step: 8
Training loss: 2.3525915145874023
Validation loss: 2.008632036947435

Epoch: 5| Step: 9
Training loss: 2.2047934532165527
Validation loss: 2.00965380155912

Epoch: 5| Step: 10
Training loss: 2.017174243927002
Validation loss: 2.005635861427553

Epoch: 382| Step: 0
Training loss: 2.3014042377471924
Validation loss: 2.0093320915775914

Epoch: 5| Step: 1
Training loss: 2.0546348094940186
Validation loss: 2.007910633599886

Epoch: 5| Step: 2
Training loss: 2.507392406463623
Validation loss: 2.0112546695175992

Epoch: 5| Step: 3
Training loss: 2.06742525100708
Validation loss: 2.0235128748801445

Epoch: 5| Step: 4
Training loss: 1.9671173095703125
Validation loss: 2.012139335755379

Epoch: 5| Step: 5
Training loss: 1.8261501789093018
Validation loss: 2.0219127247410436

Epoch: 5| Step: 6
Training loss: 1.7280709743499756
Validation loss: 2.0127642231602825

Epoch: 5| Step: 7
Training loss: 1.609837532043457
Validation loss: 2.015920562128867

Epoch: 5| Step: 8
Training loss: 2.1267285346984863
Validation loss: 2.00403158895431

Epoch: 5| Step: 9
Training loss: 2.4268555641174316
Validation loss: 2.0200543108806817

Epoch: 5| Step: 10
Training loss: 1.2725526094436646
Validation loss: 2.0259720843325377

Epoch: 383| Step: 0
Training loss: 1.799144983291626
Validation loss: 2.018763869039474

Epoch: 5| Step: 1
Training loss: 2.2107994556427
Validation loss: 2.0287422313485095

Epoch: 5| Step: 2
Training loss: 1.773023247718811
Validation loss: 2.0308272992410967

Epoch: 5| Step: 3
Training loss: 2.038184881210327
Validation loss: 2.042159302260286

Epoch: 5| Step: 4
Training loss: 1.2419682741165161
Validation loss: 2.034932590300037

Epoch: 5| Step: 5
Training loss: 1.6610877513885498
Validation loss: 2.036927351387598

Epoch: 5| Step: 6
Training loss: 2.1833078861236572
Validation loss: 2.047256544072141

Epoch: 5| Step: 7
Training loss: 1.4705489873886108
Validation loss: 2.043232610148768

Epoch: 5| Step: 8
Training loss: 2.6131813526153564
Validation loss: 2.0336220713071924

Epoch: 5| Step: 9
Training loss: 2.3516054153442383
Validation loss: 2.01794760457931

Epoch: 5| Step: 10
Training loss: 2.7170801162719727
Validation loss: 2.027913708840647

Epoch: 384| Step: 0
Training loss: 1.61935555934906
Validation loss: 2.0282532553518973

Epoch: 5| Step: 1
Training loss: 2.22529935836792
Validation loss: 1.999559478093219

Epoch: 5| Step: 2
Training loss: 1.5458223819732666
Validation loss: 2.0115099260883946

Epoch: 5| Step: 3
Training loss: 1.6838512420654297
Validation loss: 2.0145499398631435

Epoch: 5| Step: 4
Training loss: 1.777766466140747
Validation loss: 2.008692979812622

Epoch: 5| Step: 5
Training loss: 1.9216969013214111
Validation loss: 2.0186237404423375

Epoch: 5| Step: 6
Training loss: 2.295290231704712
Validation loss: 2.0174594361294984

Epoch: 5| Step: 7
Training loss: 2.5169496536254883
Validation loss: 2.024172008678477

Epoch: 5| Step: 8
Training loss: 2.6037590503692627
Validation loss: 2.01951870354273

Epoch: 5| Step: 9
Training loss: 2.1005523204803467
Validation loss: 2.025572165366142

Epoch: 5| Step: 10
Training loss: 1.7429388761520386
Validation loss: 2.02262124963986

Epoch: 385| Step: 0
Training loss: 1.6999320983886719
Validation loss: 2.035806671265633

Epoch: 5| Step: 1
Training loss: 2.7557125091552734
Validation loss: 2.048103682456478

Epoch: 5| Step: 2
Training loss: 1.7192602157592773
Validation loss: 2.0563653528049426

Epoch: 5| Step: 3
Training loss: 1.515312671661377
Validation loss: 2.058375040690104

Epoch: 5| Step: 4
Training loss: 1.888250708580017
Validation loss: 2.0440772553925872

Epoch: 5| Step: 5
Training loss: 2.4834401607513428
Validation loss: 2.0552237469662904

Epoch: 5| Step: 6
Training loss: 1.9379714727401733
Validation loss: 2.039948772358638

Epoch: 5| Step: 7
Training loss: 1.647032380104065
Validation loss: 2.0547355310891264

Epoch: 5| Step: 8
Training loss: 1.7572519779205322
Validation loss: 2.0450145557362545

Epoch: 5| Step: 9
Training loss: 2.248682737350464
Validation loss: 2.031440178553263

Epoch: 5| Step: 10
Training loss: 2.445359230041504
Validation loss: 2.0306633428860734

Epoch: 386| Step: 0
Training loss: 2.012500047683716
Validation loss: 2.028935158124534

Epoch: 5| Step: 1
Training loss: 2.351635456085205
Validation loss: 2.0148412168666883

Epoch: 5| Step: 2
Training loss: 1.9457709789276123
Validation loss: 2.0219634245800715

Epoch: 5| Step: 3
Training loss: 1.4164313077926636
Validation loss: 2.0005995458172214

Epoch: 5| Step: 4
Training loss: 1.649877905845642
Validation loss: 2.0123525691288773

Epoch: 5| Step: 5
Training loss: 2.4354662895202637
Validation loss: 2.001696240517401

Epoch: 5| Step: 6
Training loss: 1.9289610385894775
Validation loss: 2.0076296406407512

Epoch: 5| Step: 7
Training loss: 2.5396201610565186
Validation loss: 2.006856215897427

Epoch: 5| Step: 8
Training loss: 2.1831889152526855
Validation loss: 2.023388349881736

Epoch: 5| Step: 9
Training loss: 1.7876487970352173
Validation loss: 2.0091271656815723

Epoch: 5| Step: 10
Training loss: 1.6667572259902954
Validation loss: 2.024913864751016

Epoch: 387| Step: 0
Training loss: 2.2628986835479736
Validation loss: 2.037190818017529

Epoch: 5| Step: 1
Training loss: 1.7792953252792358
Validation loss: 2.0384966096570416

Epoch: 5| Step: 2
Training loss: 2.3686277866363525
Validation loss: 2.0347570680802867

Epoch: 5| Step: 3
Training loss: 1.6088041067123413
Validation loss: 2.0312885840733848

Epoch: 5| Step: 4
Training loss: 1.7893269062042236
Validation loss: 2.0391934840909895

Epoch: 5| Step: 5
Training loss: 2.010023832321167
Validation loss: 2.032257754315612

Epoch: 5| Step: 6
Training loss: 1.8578612804412842
Validation loss: 2.020477937113854

Epoch: 5| Step: 7
Training loss: 2.00095796585083
Validation loss: 2.0221690516318045

Epoch: 5| Step: 8
Training loss: 2.3549633026123047
Validation loss: 2.032702310110933

Epoch: 5| Step: 9
Training loss: 1.91982901096344
Validation loss: 2.0274713244489444

Epoch: 5| Step: 10
Training loss: 2.1615712642669678
Validation loss: 2.038769639948363

Epoch: 388| Step: 0
Training loss: 1.3204551935195923
Validation loss: 2.0274150858643236

Epoch: 5| Step: 1
Training loss: 2.373997449874878
Validation loss: 2.032362940490887

Epoch: 5| Step: 2
Training loss: 2.2109804153442383
Validation loss: 2.0332030711635465

Epoch: 5| Step: 3
Training loss: 2.1866719722747803
Validation loss: 2.0232296348899923

Epoch: 5| Step: 4
Training loss: 2.3860490322113037
Validation loss: 2.004295072247905

Epoch: 5| Step: 5
Training loss: 1.6904351711273193
Validation loss: 2.0092046927380305

Epoch: 5| Step: 6
Training loss: 2.098313570022583
Validation loss: 2.008908406380684

Epoch: 5| Step: 7
Training loss: 2.577117443084717
Validation loss: 2.0156856172828266

Epoch: 5| Step: 8
Training loss: 1.2447357177734375
Validation loss: 2.0184837630999986

Epoch: 5| Step: 9
Training loss: 1.9777629375457764
Validation loss: 2.0239382559253323

Epoch: 5| Step: 10
Training loss: 1.925092339515686
Validation loss: 2.0211251897196614

Epoch: 389| Step: 0
Training loss: 2.3122401237487793
Validation loss: 2.030270393176745

Epoch: 5| Step: 1
Training loss: 1.9001222848892212
Validation loss: 2.0226699588119343

Epoch: 5| Step: 2
Training loss: 0.9792949557304382
Validation loss: 2.0361760995721303

Epoch: 5| Step: 3
Training loss: 1.840332269668579
Validation loss: 2.0169981833427184

Epoch: 5| Step: 4
Training loss: 1.910945177078247
Validation loss: 2.0283421701000584

Epoch: 5| Step: 5
Training loss: 2.3757853507995605
Validation loss: 2.0424903490210093

Epoch: 5| Step: 6
Training loss: 1.860630750656128
Validation loss: 2.0516023148772535

Epoch: 5| Step: 7
Training loss: 2.256898880004883
Validation loss: 2.0341377886392737

Epoch: 5| Step: 8
Training loss: 2.107112407684326
Validation loss: 2.033591349919637

Epoch: 5| Step: 9
Training loss: 1.8320945501327515
Validation loss: 2.0212384782811648

Epoch: 5| Step: 10
Training loss: 2.5633294582366943
Validation loss: 2.0159953768535326

Epoch: 390| Step: 0
Training loss: 2.309561252593994
Validation loss: 2.017757369625953

Epoch: 5| Step: 1
Training loss: 2.684856653213501
Validation loss: 2.0046853967892226

Epoch: 5| Step: 2
Training loss: 2.130253314971924
Validation loss: 2.000182690158967

Epoch: 5| Step: 3
Training loss: 1.3362557888031006
Validation loss: 2.0024131087846655

Epoch: 5| Step: 4
Training loss: 1.5537817478179932
Validation loss: 1.9988188435954433

Epoch: 5| Step: 5
Training loss: 1.7463823556900024
Validation loss: 1.9794887458124468

Epoch: 5| Step: 6
Training loss: 2.1664414405822754
Validation loss: 1.999792475854197

Epoch: 5| Step: 7
Training loss: 2.0248634815216064
Validation loss: 1.9996112943977438

Epoch: 5| Step: 8
Training loss: 2.2584404945373535
Validation loss: 2.017676632891419

Epoch: 5| Step: 9
Training loss: 1.7222131490707397
Validation loss: 2.016505415721606

Epoch: 5| Step: 10
Training loss: 2.015852689743042
Validation loss: 2.0236695889503724

Epoch: 391| Step: 0
Training loss: 1.7601743936538696
Validation loss: 2.041471242904663

Epoch: 5| Step: 1
Training loss: 2.342210054397583
Validation loss: 2.047565180768249

Epoch: 5| Step: 2
Training loss: 1.7910842895507812
Validation loss: 2.0468442747669835

Epoch: 5| Step: 3
Training loss: 1.408614158630371
Validation loss: 2.0424380840793734

Epoch: 5| Step: 4
Training loss: 2.0460307598114014
Validation loss: 2.0530004552615586

Epoch: 5| Step: 5
Training loss: 2.092559576034546
Validation loss: 2.042480745623189

Epoch: 5| Step: 6
Training loss: 2.4950904846191406
Validation loss: 2.0521920637417863

Epoch: 5| Step: 7
Training loss: 1.9883754253387451
Validation loss: 2.0339046242416545

Epoch: 5| Step: 8
Training loss: 2.702902317047119
Validation loss: 2.03517379812015

Epoch: 5| Step: 9
Training loss: 1.7180595397949219
Validation loss: 2.0507307526885823

Epoch: 5| Step: 10
Training loss: 1.5333058834075928
Validation loss: 2.0444437508941977

Epoch: 392| Step: 0
Training loss: 2.412973165512085
Validation loss: 2.042100953799422

Epoch: 5| Step: 1
Training loss: 1.894202470779419
Validation loss: 2.0402025150996383

Epoch: 5| Step: 2
Training loss: 2.1083130836486816
Validation loss: 2.0264141739055677

Epoch: 5| Step: 3
Training loss: 2.1557037830352783
Validation loss: 2.027533153051971

Epoch: 5| Step: 4
Training loss: 1.6345927715301514
Validation loss: 2.0236078103383384

Epoch: 5| Step: 5
Training loss: 1.7986838817596436
Validation loss: 2.0261956953233287

Epoch: 5| Step: 6
Training loss: 1.7540327310562134
Validation loss: 2.022036060210197

Epoch: 5| Step: 7
Training loss: 1.633469820022583
Validation loss: 2.0349415079239876

Epoch: 5| Step: 8
Training loss: 2.5919272899627686
Validation loss: 2.052978733534454

Epoch: 5| Step: 9
Training loss: 2.2099993228912354
Validation loss: 2.051360007255308

Epoch: 5| Step: 10
Training loss: 1.624603033065796
Validation loss: 2.0647701883828766

Epoch: 393| Step: 0
Training loss: 1.8728611469268799
Validation loss: 2.0615522835844304

Epoch: 5| Step: 1
Training loss: 1.9438482522964478
Validation loss: 2.038954222074119

Epoch: 5| Step: 2
Training loss: 2.2279975414276123
Validation loss: 2.033173285504823

Epoch: 5| Step: 3
Training loss: 1.5571995973587036
Validation loss: 2.021402356445148

Epoch: 5| Step: 4
Training loss: 2.1730594635009766
Validation loss: 2.010673543458344

Epoch: 5| Step: 5
Training loss: 2.400546073913574
Validation loss: 2.0111096725668958

Epoch: 5| Step: 6
Training loss: 2.441211700439453
Validation loss: 2.0067427812084073

Epoch: 5| Step: 7
Training loss: 1.9189293384552002
Validation loss: 2.0253757969025643

Epoch: 5| Step: 8
Training loss: 1.6974141597747803
Validation loss: 2.026070528132941

Epoch: 5| Step: 9
Training loss: 1.7827879190444946
Validation loss: 2.0320000622862127

Epoch: 5| Step: 10
Training loss: 2.040663242340088
Validation loss: 2.027217412507662

Epoch: 394| Step: 0
Training loss: 1.7890431880950928
Validation loss: 2.0171024389164423

Epoch: 5| Step: 1
Training loss: 1.97821843624115
Validation loss: 2.0221524853860178

Epoch: 5| Step: 2
Training loss: 2.755789279937744
Validation loss: 2.0181108508058774

Epoch: 5| Step: 3
Training loss: 1.9510505199432373
Validation loss: 2.0317750951295257

Epoch: 5| Step: 4
Training loss: 1.511853814125061
Validation loss: 2.017860430543141

Epoch: 5| Step: 5
Training loss: 1.7612154483795166
Validation loss: 2.0151754604872836

Epoch: 5| Step: 6
Training loss: 1.4592430591583252
Validation loss: 2.003435013114765

Epoch: 5| Step: 7
Training loss: 2.023634672164917
Validation loss: 2.0007627548709994

Epoch: 5| Step: 8
Training loss: 2.2847321033477783
Validation loss: 1.993905944208945

Epoch: 5| Step: 9
Training loss: 2.259120464324951
Validation loss: 1.993828623525558

Epoch: 5| Step: 10
Training loss: 1.9940060377120972
Validation loss: 2.009060985298567

Epoch: 395| Step: 0
Training loss: 2.1054306030273438
Validation loss: 2.011664039345198

Epoch: 5| Step: 1
Training loss: 2.133086681365967
Validation loss: 2.015438160588664

Epoch: 5| Step: 2
Training loss: 1.7684437036514282
Validation loss: 2.0442673929276003

Epoch: 5| Step: 3
Training loss: 1.5761795043945312
Validation loss: 2.0256911349552933

Epoch: 5| Step: 4
Training loss: 2.2596888542175293
Validation loss: 2.045497146985864

Epoch: 5| Step: 5
Training loss: 1.9665464162826538
Validation loss: 2.0382547711813324

Epoch: 5| Step: 6
Training loss: 2.357844829559326
Validation loss: 2.027515304985867

Epoch: 5| Step: 7
Training loss: 2.3178765773773193
Validation loss: 2.033701192948126

Epoch: 5| Step: 8
Training loss: 1.7570960521697998
Validation loss: 2.0274387046854985

Epoch: 5| Step: 9
Training loss: 1.7168700695037842
Validation loss: 2.0355005623191915

Epoch: 5| Step: 10
Training loss: 1.8072805404663086
Validation loss: 2.029940107817291

Epoch: 396| Step: 0
Training loss: 1.6150691509246826
Validation loss: 2.035780288839853

Epoch: 5| Step: 1
Training loss: 2.016470432281494
Validation loss: 2.0205885953800653

Epoch: 5| Step: 2
Training loss: 1.684059739112854
Validation loss: 2.0174283673686366

Epoch: 5| Step: 3
Training loss: 2.1749558448791504
Validation loss: 2.012129642630136

Epoch: 5| Step: 4
Training loss: 2.1948771476745605
Validation loss: 2.0058589571265766

Epoch: 5| Step: 5
Training loss: 1.9049174785614014
Validation loss: 2.0176156464443413

Epoch: 5| Step: 6
Training loss: 1.8191192150115967
Validation loss: 2.0186088136447373

Epoch: 5| Step: 7
Training loss: 1.906433343887329
Validation loss: 2.016962011655172

Epoch: 5| Step: 8
Training loss: 2.1861183643341064
Validation loss: 2.021918122486402

Epoch: 5| Step: 9
Training loss: 2.305680274963379
Validation loss: 2.012880681663431

Epoch: 5| Step: 10
Training loss: 1.8760985136032104
Validation loss: 2.0167444290653354

Epoch: 397| Step: 0
Training loss: 2.3124799728393555
Validation loss: 2.003798556584184

Epoch: 5| Step: 1
Training loss: 1.8618608713150024
Validation loss: 2.0028652978199784

Epoch: 5| Step: 2
Training loss: 2.4605350494384766
Validation loss: 1.99574456291814

Epoch: 5| Step: 3
Training loss: 2.091665267944336
Validation loss: 2.0071792743539296

Epoch: 5| Step: 4
Training loss: 1.5114911794662476
Validation loss: 2.020107981979206

Epoch: 5| Step: 5
Training loss: 1.9893887042999268
Validation loss: 2.0371683605255617

Epoch: 5| Step: 6
Training loss: 1.5105680227279663
Validation loss: 2.0300212021796935

Epoch: 5| Step: 7
Training loss: 2.0756399631500244
Validation loss: 2.0499710549590406

Epoch: 5| Step: 8
Training loss: 1.86598801612854
Validation loss: 2.04420651671707

Epoch: 5| Step: 9
Training loss: 2.0470924377441406
Validation loss: 2.048320375463014

Epoch: 5| Step: 10
Training loss: 2.0851540565490723
Validation loss: 2.056569814682007

Epoch: 398| Step: 0
Training loss: 1.8318357467651367
Validation loss: 2.08939097004552

Epoch: 5| Step: 1
Training loss: 1.8331005573272705
Validation loss: 2.0911662399127917

Epoch: 5| Step: 2
Training loss: 1.3261748552322388
Validation loss: 2.0976710806610765

Epoch: 5| Step: 3
Training loss: 1.5537153482437134
Validation loss: 2.0986190983044204

Epoch: 5| Step: 4
Training loss: 2.248950958251953
Validation loss: 2.079888674520677

Epoch: 5| Step: 5
Training loss: 1.48517906665802
Validation loss: 2.0691110818616805

Epoch: 5| Step: 6
Training loss: 2.4180047512054443
Validation loss: 2.082515437115905

Epoch: 5| Step: 7
Training loss: 2.064939022064209
Validation loss: 2.0597503044271983

Epoch: 5| Step: 8
Training loss: 2.777459144592285
Validation loss: 2.0573237326837357

Epoch: 5| Step: 9
Training loss: 2.5971603393554688
Validation loss: 2.059388993888773

Epoch: 5| Step: 10
Training loss: 1.8900774717330933
Validation loss: 2.0414909701193533

Epoch: 399| Step: 0
Training loss: 1.681907296180725
Validation loss: 2.039574266761862

Epoch: 5| Step: 1
Training loss: 1.8828151226043701
Validation loss: 2.0211453719805648

Epoch: 5| Step: 2
Training loss: 2.518976926803589
Validation loss: 2.0128864267820954

Epoch: 5| Step: 3
Training loss: 1.8475415706634521
Validation loss: 2.020994558129259

Epoch: 5| Step: 4
Training loss: 1.6756423711776733
Validation loss: 2.0141544098495157

Epoch: 5| Step: 5
Training loss: 2.0603396892547607
Validation loss: 2.020498905130612

Epoch: 5| Step: 6
Training loss: 2.6928017139434814
Validation loss: 2.015821382563601

Epoch: 5| Step: 7
Training loss: 1.943041205406189
Validation loss: 2.0233900457300167

Epoch: 5| Step: 8
Training loss: 2.0003418922424316
Validation loss: 2.009524868380639

Epoch: 5| Step: 9
Training loss: 1.7438476085662842
Validation loss: 2.0052370486720914

Epoch: 5| Step: 10
Training loss: 1.7147338390350342
Validation loss: 2.0198046353555497

Epoch: 400| Step: 0
Training loss: 2.4044482707977295
Validation loss: 2.0059370815113025

Epoch: 5| Step: 1
Training loss: 1.6101064682006836
Validation loss: 2.0194030295136156

Epoch: 5| Step: 2
Training loss: 2.492218017578125
Validation loss: 2.0213943296863186

Epoch: 5| Step: 3
Training loss: 1.740179419517517
Validation loss: 2.0056308443828295

Epoch: 5| Step: 4
Training loss: 1.5772520303726196
Validation loss: 2.0148166200166107

Epoch: 5| Step: 5
Training loss: 1.9297726154327393
Validation loss: 2.0187036196390786

Epoch: 5| Step: 6
Training loss: 1.7357009649276733
Validation loss: 2.0085366900249193

Epoch: 5| Step: 7
Training loss: 2.1935315132141113
Validation loss: 2.007872308454206

Epoch: 5| Step: 8
Training loss: 1.4983199834823608
Validation loss: 2.0158724400304977

Epoch: 5| Step: 9
Training loss: 2.165590763092041
Validation loss: 2.022940763863184

Epoch: 5| Step: 10
Training loss: 2.2509684562683105
Validation loss: 2.0193920571316957

Epoch: 401| Step: 0
Training loss: 2.5365424156188965
Validation loss: 2.0357183794821463

Epoch: 5| Step: 1
Training loss: 1.4788787364959717
Validation loss: 2.0343396356028896

Epoch: 5| Step: 2
Training loss: 1.69564688205719
Validation loss: 2.0446395438204528

Epoch: 5| Step: 3
Training loss: 1.8944523334503174
Validation loss: 2.051865344406456

Epoch: 5| Step: 4
Training loss: 1.8675267696380615
Validation loss: 2.044435898462931

Epoch: 5| Step: 5
Training loss: 1.9944827556610107
Validation loss: 2.0482699653153777

Epoch: 5| Step: 6
Training loss: 2.371826648712158
Validation loss: 2.0360535447315504

Epoch: 5| Step: 7
Training loss: 2.0193142890930176
Validation loss: 2.0333551181259977

Epoch: 5| Step: 8
Training loss: 1.169095754623413
Validation loss: 2.0402510294350247

Epoch: 5| Step: 9
Training loss: 2.5462894439697266
Validation loss: 2.0378742641018284

Epoch: 5| Step: 10
Training loss: 1.9519236087799072
Validation loss: 2.0424015547639582

Epoch: 402| Step: 0
Training loss: 1.7109521627426147
Validation loss: 2.0240457545044603

Epoch: 5| Step: 1
Training loss: 1.2795524597167969
Validation loss: 2.0341363273641115

Epoch: 5| Step: 2
Training loss: 1.7899043560028076
Validation loss: 2.0345796590210288

Epoch: 5| Step: 3
Training loss: 2.3568708896636963
Validation loss: 2.0027142186318674

Epoch: 5| Step: 4
Training loss: 1.7517105340957642
Validation loss: 2.0015933180368073

Epoch: 5| Step: 5
Training loss: 1.9644778966903687
Validation loss: 2.0113349037785686

Epoch: 5| Step: 6
Training loss: 1.7583529949188232
Validation loss: 1.9879865402816443

Epoch: 5| Step: 7
Training loss: 2.6274638175964355
Validation loss: 2.00629755502106

Epoch: 5| Step: 8
Training loss: 2.1842498779296875
Validation loss: 2.0169885491812103

Epoch: 5| Step: 9
Training loss: 2.0690932273864746
Validation loss: 2.0032975007128972

Epoch: 5| Step: 10
Training loss: 2.058861017227173
Validation loss: 2.0003140421323877

Epoch: 403| Step: 0
Training loss: 1.1150861978530884
Validation loss: 2.017489460206801

Epoch: 5| Step: 1
Training loss: 2.0968544483184814
Validation loss: 2.0110782256690403

Epoch: 5| Step: 2
Training loss: 2.2454094886779785
Validation loss: 2.0050635850557716

Epoch: 5| Step: 3
Training loss: 1.8153584003448486
Validation loss: 2.017482844732141

Epoch: 5| Step: 4
Training loss: 2.3608927726745605
Validation loss: 2.014266910091523

Epoch: 5| Step: 5
Training loss: 1.9753379821777344
Validation loss: 2.024589036100654

Epoch: 5| Step: 6
Training loss: 1.7061522006988525
Validation loss: 2.019282639667552

Epoch: 5| Step: 7
Training loss: 1.7090919017791748
Validation loss: 2.0330062040718655

Epoch: 5| Step: 8
Training loss: 1.995418906211853
Validation loss: 2.0328054940828713

Epoch: 5| Step: 9
Training loss: 2.4332642555236816
Validation loss: 2.043882231558523

Epoch: 5| Step: 10
Training loss: 2.1389427185058594
Validation loss: 2.0383398468776415

Epoch: 404| Step: 0
Training loss: 1.6344373226165771
Validation loss: 2.0378531179120465

Epoch: 5| Step: 1
Training loss: 2.1848137378692627
Validation loss: 2.031918348804597

Epoch: 5| Step: 2
Training loss: 2.7068920135498047
Validation loss: 2.0189048372289187

Epoch: 5| Step: 3
Training loss: 1.8023020029067993
Validation loss: 2.0281441609064736

Epoch: 5| Step: 4
Training loss: 1.9741119146347046
Validation loss: 2.041395192505211

Epoch: 5| Step: 5
Training loss: 1.566652774810791
Validation loss: 2.0286194842348815

Epoch: 5| Step: 6
Training loss: 1.8912887573242188
Validation loss: 2.0311524227101314

Epoch: 5| Step: 7
Training loss: 1.7835346460342407
Validation loss: 2.017733362413222

Epoch: 5| Step: 8
Training loss: 2.16397762298584
Validation loss: 2.0165469364453386

Epoch: 5| Step: 9
Training loss: 1.6400117874145508
Validation loss: 2.0013359259533625

Epoch: 5| Step: 10
Training loss: 2.243790626525879
Validation loss: 1.9986964464187622

Epoch: 405| Step: 0
Training loss: 2.1628475189208984
Validation loss: 2.002681601432062

Epoch: 5| Step: 1
Training loss: 2.1600356101989746
Validation loss: 1.9978751033864997

Epoch: 5| Step: 2
Training loss: 2.326134443283081
Validation loss: 2.0130771693362983

Epoch: 5| Step: 3
Training loss: 2.0947813987731934
Validation loss: 2.006704854708846

Epoch: 5| Step: 4
Training loss: 1.6803287267684937
Validation loss: 2.0113174018039497

Epoch: 5| Step: 5
Training loss: 1.6002975702285767
Validation loss: 2.003233951907004

Epoch: 5| Step: 6
Training loss: 2.054535388946533
Validation loss: 2.020767128595742

Epoch: 5| Step: 7
Training loss: 1.3454093933105469
Validation loss: 2.0286418648176294

Epoch: 5| Step: 8
Training loss: 1.819963812828064
Validation loss: 2.028889174102455

Epoch: 5| Step: 9
Training loss: 2.3115322589874268
Validation loss: 2.0387924255863314

Epoch: 5| Step: 10
Training loss: 2.0095067024230957
Validation loss: 2.0281827808708273

Epoch: 406| Step: 0
Training loss: 2.1090455055236816
Validation loss: 2.0361448449473225

Epoch: 5| Step: 1
Training loss: 2.4792356491088867
Validation loss: 2.040511146668465

Epoch: 5| Step: 2
Training loss: 1.8086601495742798
Validation loss: 2.038762120790379

Epoch: 5| Step: 3
Training loss: 1.6409885883331299
Validation loss: 2.0305793541733936

Epoch: 5| Step: 4
Training loss: 1.5076100826263428
Validation loss: 2.0488828612912084

Epoch: 5| Step: 5
Training loss: 1.8831040859222412
Validation loss: 2.0258696092072355

Epoch: 5| Step: 6
Training loss: 1.7810596227645874
Validation loss: 2.0371619603967153

Epoch: 5| Step: 7
Training loss: 2.703617572784424
Validation loss: 2.0331943701672297

Epoch: 5| Step: 8
Training loss: 1.5761123895645142
Validation loss: 2.047357666877008

Epoch: 5| Step: 9
Training loss: 2.3252882957458496
Validation loss: 2.046840465196999

Epoch: 5| Step: 10
Training loss: 1.7055115699768066
Validation loss: 2.0243528427616244

Epoch: 407| Step: 0
Training loss: 1.875872254371643
Validation loss: 2.035964289019185

Epoch: 5| Step: 1
Training loss: 1.6177256107330322
Validation loss: 2.012686930676942

Epoch: 5| Step: 2
Training loss: 2.426131010055542
Validation loss: 2.023620710578016

Epoch: 5| Step: 3
Training loss: 2.0331196784973145
Validation loss: 2.016675497895928

Epoch: 5| Step: 4
Training loss: 1.8596442937850952
Validation loss: 2.0191394039379653

Epoch: 5| Step: 5
Training loss: 2.0166141986846924
Validation loss: 2.004305790829402

Epoch: 5| Step: 6
Training loss: 2.2469613552093506
Validation loss: 2.0204787895243657

Epoch: 5| Step: 7
Training loss: 1.7153184413909912
Validation loss: 2.003450021948866

Epoch: 5| Step: 8
Training loss: 1.9681437015533447
Validation loss: 2.011174735202584

Epoch: 5| Step: 9
Training loss: 2.2377853393554688
Validation loss: 2.0000821390459613

Epoch: 5| Step: 10
Training loss: 1.2376741170883179
Validation loss: 2.019200608294497

Epoch: 408| Step: 0
Training loss: 1.696601152420044
Validation loss: 2.013445235067798

Epoch: 5| Step: 1
Training loss: 1.6979411840438843
Validation loss: 2.0177799194089827

Epoch: 5| Step: 2
Training loss: 1.5992845296859741
Validation loss: 2.018541800078525

Epoch: 5| Step: 3
Training loss: 2.0110602378845215
Validation loss: 2.0166541722513016

Epoch: 5| Step: 4
Training loss: 2.4841678142547607
Validation loss: 2.02214402280828

Epoch: 5| Step: 5
Training loss: 2.2474615573883057
Validation loss: 2.051446933900156

Epoch: 5| Step: 6
Training loss: 1.4460408687591553
Validation loss: 2.031617195375504

Epoch: 5| Step: 7
Training loss: 2.0694477558135986
Validation loss: 2.038998455129644

Epoch: 5| Step: 8
Training loss: 2.493964433670044
Validation loss: 2.03896346399861

Epoch: 5| Step: 9
Training loss: 1.9380710124969482
Validation loss: 2.046014439675116

Epoch: 5| Step: 10
Training loss: 1.616945505142212
Validation loss: 2.029479826650312

Epoch: 409| Step: 0
Training loss: 2.0295233726501465
Validation loss: 2.0356465693443053

Epoch: 5| Step: 1
Training loss: 2.5927751064300537
Validation loss: 2.037637787480508

Epoch: 5| Step: 2
Training loss: 1.871681571006775
Validation loss: 2.036749409091088

Epoch: 5| Step: 3
Training loss: 1.853499174118042
Validation loss: 2.0214532754754506

Epoch: 5| Step: 4
Training loss: 1.5203548669815063
Validation loss: 2.028800359336279

Epoch: 5| Step: 5
Training loss: 2.369884967803955
Validation loss: 2.0268592783199844

Epoch: 5| Step: 6
Training loss: 2.1606638431549072
Validation loss: 2.0171076238796277

Epoch: 5| Step: 7
Training loss: 1.6426780223846436
Validation loss: 2.0146357731152604

Epoch: 5| Step: 8
Training loss: 1.939784288406372
Validation loss: 1.9995404545978834

Epoch: 5| Step: 9
Training loss: 1.6705840826034546
Validation loss: 2.0299605554149998

Epoch: 5| Step: 10
Training loss: 1.5793956518173218
Validation loss: 2.0132568138901905

Epoch: 410| Step: 0
Training loss: 1.7584174871444702
Validation loss: 2.026703111587032

Epoch: 5| Step: 1
Training loss: 1.9056732654571533
Validation loss: 2.0215588615786646

Epoch: 5| Step: 2
Training loss: 1.9402472972869873
Validation loss: 2.0308382895685013

Epoch: 5| Step: 3
Training loss: 2.1973838806152344
Validation loss: 2.0202277783424623

Epoch: 5| Step: 4
Training loss: 2.671299457550049
Validation loss: 2.010754577575191

Epoch: 5| Step: 5
Training loss: 1.4425256252288818
Validation loss: 2.0195250306078183

Epoch: 5| Step: 6
Training loss: 2.458719253540039
Validation loss: 2.0217632785920174

Epoch: 5| Step: 7
Training loss: 2.347170352935791
Validation loss: 2.0222138422791676

Epoch: 5| Step: 8
Training loss: 1.496569037437439
Validation loss: 2.0281301698377057

Epoch: 5| Step: 9
Training loss: 1.4962800741195679
Validation loss: 2.0227192230122064

Epoch: 5| Step: 10
Training loss: 1.7376530170440674
Validation loss: 2.023779421724299

Epoch: 411| Step: 0
Training loss: 1.8849397897720337
Validation loss: 2.014232220188264

Epoch: 5| Step: 1
Training loss: 1.751471757888794
Validation loss: 2.0261302686506704

Epoch: 5| Step: 2
Training loss: 2.032344341278076
Validation loss: 2.0114106285956597

Epoch: 5| Step: 3
Training loss: 2.2257063388824463
Validation loss: 2.0420202491103963

Epoch: 5| Step: 4
Training loss: 1.7704880237579346
Validation loss: 2.032363475009959

Epoch: 5| Step: 5
Training loss: 2.0308804512023926
Validation loss: 2.0379363003597466

Epoch: 5| Step: 6
Training loss: 2.139984369277954
Validation loss: 2.0503795505851827

Epoch: 5| Step: 7
Training loss: 1.4279335737228394
Validation loss: 2.019837866547287

Epoch: 5| Step: 8
Training loss: 2.1436362266540527
Validation loss: 2.019761739238616

Epoch: 5| Step: 9
Training loss: 1.8405437469482422
Validation loss: 2.009139439111115

Epoch: 5| Step: 10
Training loss: 2.031393051147461
Validation loss: 2.0026511748631797

Epoch: 412| Step: 0
Training loss: 2.059645175933838
Validation loss: 2.007245682900952

Epoch: 5| Step: 1
Training loss: 1.5264770984649658
Validation loss: 2.0116758295284805

Epoch: 5| Step: 2
Training loss: 1.5562328100204468
Validation loss: 2.035462669146958

Epoch: 5| Step: 3
Training loss: 1.8967504501342773
Validation loss: 2.0102215915597896

Epoch: 5| Step: 4
Training loss: 1.7603060007095337
Validation loss: 2.00203416937141

Epoch: 5| Step: 5
Training loss: 2.516657829284668
Validation loss: 2.0110402453330254

Epoch: 5| Step: 6
Training loss: 1.693399429321289
Validation loss: 2.0204008753581713

Epoch: 5| Step: 7
Training loss: 2.298039436340332
Validation loss: 2.0221607146724576

Epoch: 5| Step: 8
Training loss: 2.0811355113983154
Validation loss: 2.0063101732602684

Epoch: 5| Step: 9
Training loss: 2.022650957107544
Validation loss: 2.0139806244962957

Epoch: 5| Step: 10
Training loss: 1.9098483324050903
Validation loss: 2.019994492171913

Epoch: 413| Step: 0
Training loss: 1.6619691848754883
Validation loss: 2.0102253267841954

Epoch: 5| Step: 1
Training loss: 2.611457347869873
Validation loss: 2.007360425046695

Epoch: 5| Step: 2
Training loss: 1.5153429508209229
Validation loss: 1.9905859911313621

Epoch: 5| Step: 3
Training loss: 2.1313138008117676
Validation loss: 2.0147125208249657

Epoch: 5| Step: 4
Training loss: 2.125253915786743
Validation loss: 2.0024262525702037

Epoch: 5| Step: 5
Training loss: 2.302356243133545
Validation loss: 2.003093486191124

Epoch: 5| Step: 6
Training loss: 1.457675814628601
Validation loss: 1.9956451692888815

Epoch: 5| Step: 7
Training loss: 2.0472869873046875
Validation loss: 2.019038483660708

Epoch: 5| Step: 8
Training loss: 1.5201619863510132
Validation loss: 2.000241894875803

Epoch: 5| Step: 9
Training loss: 2.1901843547821045
Validation loss: 2.0085217081090456

Epoch: 5| Step: 10
Training loss: 1.5713160037994385
Validation loss: 2.028422103133253

Epoch: 414| Step: 0
Training loss: 1.8712151050567627
Validation loss: 2.0490471278467486

Epoch: 5| Step: 1
Training loss: 1.821969985961914
Validation loss: 2.063262293415685

Epoch: 5| Step: 2
Training loss: 1.93732488155365
Validation loss: 2.048767230843985

Epoch: 5| Step: 3
Training loss: 2.296628475189209
Validation loss: 2.0640605239457983

Epoch: 5| Step: 4
Training loss: 1.7103561162948608
Validation loss: 2.0533479516224196

Epoch: 5| Step: 5
Training loss: 2.2016963958740234
Validation loss: 2.0471432849925053

Epoch: 5| Step: 6
Training loss: 1.5442249774932861
Validation loss: 2.041750684861214

Epoch: 5| Step: 7
Training loss: 1.661442756652832
Validation loss: 2.065244843882899

Epoch: 5| Step: 8
Training loss: 2.364448070526123
Validation loss: 2.0561943233654065

Epoch: 5| Step: 9
Training loss: 1.5340449810028076
Validation loss: 2.0610661609198457

Epoch: 5| Step: 10
Training loss: 2.367734909057617
Validation loss: 2.0240100096630793

Epoch: 415| Step: 0
Training loss: 2.06071138381958
Validation loss: 2.0219461456421883

Epoch: 5| Step: 1
Training loss: 2.0483665466308594
Validation loss: 2.012074908902568

Epoch: 5| Step: 2
Training loss: 2.48783540725708
Validation loss: 2.0043295070689213

Epoch: 5| Step: 3
Training loss: 1.8495323657989502
Validation loss: 2.022064762730752

Epoch: 5| Step: 4
Training loss: 1.7864208221435547
Validation loss: 2.0151357420029177

Epoch: 5| Step: 5
Training loss: 2.0868823528289795
Validation loss: 2.004371517448015

Epoch: 5| Step: 6
Training loss: 2.0426557064056396
Validation loss: 2.01537077401274

Epoch: 5| Step: 7
Training loss: 2.124938488006592
Validation loss: 2.011157510101154

Epoch: 5| Step: 8
Training loss: 1.4357649087905884
Validation loss: 2.020471134493428

Epoch: 5| Step: 9
Training loss: 1.5688083171844482
Validation loss: 2.006732856073687

Epoch: 5| Step: 10
Training loss: 1.5595252513885498
Validation loss: 2.015996548437303

Epoch: 416| Step: 0
Training loss: 2.1380021572113037
Validation loss: 2.0040568946510233

Epoch: 5| Step: 1
Training loss: 1.9768390655517578
Validation loss: 2.0134934802209177

Epoch: 5| Step: 2
Training loss: 1.6571842432022095
Validation loss: 2.0017909298660936

Epoch: 5| Step: 3
Training loss: 1.6085668802261353
Validation loss: 2.0145734792114585

Epoch: 5| Step: 4
Training loss: 2.231403350830078
Validation loss: 2.0065789338081115

Epoch: 5| Step: 5
Training loss: 1.829368233680725
Validation loss: 2.010544461588706

Epoch: 5| Step: 6
Training loss: 1.9138946533203125
Validation loss: 2.027335810404952

Epoch: 5| Step: 7
Training loss: 2.3632516860961914
Validation loss: 2.0247722518059517

Epoch: 5| Step: 8
Training loss: 1.4297455549240112
Validation loss: 2.0209569623393397

Epoch: 5| Step: 9
Training loss: 1.8849589824676514
Validation loss: 2.024217700445524

Epoch: 5| Step: 10
Training loss: 1.9424656629562378
Validation loss: 2.025703945467549

Epoch: 417| Step: 0
Training loss: 2.1637511253356934
Validation loss: 2.0302954630185197

Epoch: 5| Step: 1
Training loss: 1.7909828424453735
Validation loss: 2.016291026146181

Epoch: 5| Step: 2
Training loss: 2.1778790950775146
Validation loss: 2.031871409826381

Epoch: 5| Step: 3
Training loss: 1.8865333795547485
Validation loss: 2.024629713386618

Epoch: 5| Step: 4
Training loss: 1.7886149883270264
Validation loss: 2.0060608130629345

Epoch: 5| Step: 5
Training loss: 2.0920844078063965
Validation loss: 2.003383862074985

Epoch: 5| Step: 6
Training loss: 1.8764848709106445
Validation loss: 2.0212057277720463

Epoch: 5| Step: 7
Training loss: 1.3584245443344116
Validation loss: 2.0144439102500997

Epoch: 5| Step: 8
Training loss: 2.0408589839935303
Validation loss: 2.0023321067133257

Epoch: 5| Step: 9
Training loss: 1.766007661819458
Validation loss: 2.012146729294972

Epoch: 5| Step: 10
Training loss: 2.0153777599334717
Validation loss: 2.0124497464908067

Epoch: 418| Step: 0
Training loss: 2.4204933643341064
Validation loss: 2.0042749117779475

Epoch: 5| Step: 1
Training loss: 1.7404505014419556
Validation loss: 2.01131341021548

Epoch: 5| Step: 2
Training loss: 1.780609369277954
Validation loss: 2.0093053284511773

Epoch: 5| Step: 3
Training loss: 1.6990115642547607
Validation loss: 2.0059963054554437

Epoch: 5| Step: 4
Training loss: 2.131898880004883
Validation loss: 2.019313245691279

Epoch: 5| Step: 5
Training loss: 2.0213851928710938
Validation loss: 2.0142975648244223

Epoch: 5| Step: 6
Training loss: 2.056896686553955
Validation loss: 2.02265525633289

Epoch: 5| Step: 7
Training loss: 1.4458506107330322
Validation loss: 2.0236594907699095

Epoch: 5| Step: 8
Training loss: 2.089372158050537
Validation loss: 2.035949073812013

Epoch: 5| Step: 9
Training loss: 1.8610674142837524
Validation loss: 2.0574242043238815

Epoch: 5| Step: 10
Training loss: 1.8471627235412598
Validation loss: 2.0570188030119865

Epoch: 419| Step: 0
Training loss: 2.5258278846740723
Validation loss: 2.0599308783008206

Epoch: 5| Step: 1
Training loss: 1.082381010055542
Validation loss: 2.0747087181255384

Epoch: 5| Step: 2
Training loss: 1.1551411151885986
Validation loss: 2.0569722857526553

Epoch: 5| Step: 3
Training loss: 2.1558926105499268
Validation loss: 2.059214292034026

Epoch: 5| Step: 4
Training loss: 1.4629846811294556
Validation loss: 2.0621619609094437

Epoch: 5| Step: 5
Training loss: 2.1535778045654297
Validation loss: 2.0540440659369192

Epoch: 5| Step: 6
Training loss: 2.4855144023895264
Validation loss: 2.0469915661760556

Epoch: 5| Step: 7
Training loss: 2.505077362060547
Validation loss: 2.059343248285273

Epoch: 5| Step: 8
Training loss: 1.991864800453186
Validation loss: 2.045422269452003

Epoch: 5| Step: 9
Training loss: 1.7555713653564453
Validation loss: 2.0451208494042836

Epoch: 5| Step: 10
Training loss: 1.5690875053405762
Validation loss: 2.0568799863579454

Epoch: 420| Step: 0
Training loss: 2.1716418266296387
Validation loss: 2.0498979604372414

Epoch: 5| Step: 1
Training loss: 1.6957582235336304
Validation loss: 2.048250536764822

Epoch: 5| Step: 2
Training loss: 1.827108383178711
Validation loss: 2.0533117504530054

Epoch: 5| Step: 3
Training loss: 1.6464283466339111
Validation loss: 2.019587855185232

Epoch: 5| Step: 4
Training loss: 1.653658151626587
Validation loss: 2.0322730246410576

Epoch: 5| Step: 5
Training loss: 1.8742961883544922
Validation loss: 2.0267815833450644

Epoch: 5| Step: 6
Training loss: 1.7734953165054321
Validation loss: 2.013761751113399

Epoch: 5| Step: 7
Training loss: 2.0734550952911377
Validation loss: 2.0186489500025266

Epoch: 5| Step: 8
Training loss: 2.0697734355926514
Validation loss: 2.0196781927539456

Epoch: 5| Step: 9
Training loss: 2.350598096847534
Validation loss: 2.0084453346908733

Epoch: 5| Step: 10
Training loss: 1.803796410560608
Validation loss: 2.0198975147739535

Epoch: 421| Step: 0
Training loss: 1.6371742486953735
Validation loss: 2.0273592702804075

Epoch: 5| Step: 1
Training loss: 2.38798451423645
Validation loss: 2.028669200917726

Epoch: 5| Step: 2
Training loss: 2.2663588523864746
Validation loss: 2.0196061441975255

Epoch: 5| Step: 3
Training loss: 2.5873517990112305
Validation loss: 2.02864061632464

Epoch: 5| Step: 4
Training loss: 1.6445140838623047
Validation loss: 2.0329427167933476

Epoch: 5| Step: 5
Training loss: 1.6846344470977783
Validation loss: 2.034977779593519

Epoch: 5| Step: 6
Training loss: 1.6402031183242798
Validation loss: 2.0245770433897614

Epoch: 5| Step: 7
Training loss: 2.1902382373809814
Validation loss: 2.0187938021075342

Epoch: 5| Step: 8
Training loss: 1.5162668228149414
Validation loss: 2.0240453097128097

Epoch: 5| Step: 9
Training loss: 1.4718897342681885
Validation loss: 2.021182849843015

Epoch: 5| Step: 10
Training loss: 1.970263123512268
Validation loss: 2.0165340131328953

Epoch: 422| Step: 0
Training loss: 1.6478255987167358
Validation loss: 2.006170485609321

Epoch: 5| Step: 1
Training loss: 2.3223352432250977
Validation loss: 2.0169470361483994

Epoch: 5| Step: 2
Training loss: 1.4392204284667969
Validation loss: 2.000280036721178

Epoch: 5| Step: 3
Training loss: 1.993250846862793
Validation loss: 2.0129317186212026

Epoch: 5| Step: 4
Training loss: 1.589742660522461
Validation loss: 2.0064028719420075

Epoch: 5| Step: 5
Training loss: 1.4654579162597656
Validation loss: 1.9980213129392235

Epoch: 5| Step: 6
Training loss: 1.9396165609359741
Validation loss: 2.021621915601915

Epoch: 5| Step: 7
Training loss: 1.7425702810287476
Validation loss: 2.0147832080882084

Epoch: 5| Step: 8
Training loss: 2.645439863204956
Validation loss: 1.9974587053380988

Epoch: 5| Step: 9
Training loss: 2.033172845840454
Validation loss: 2.0009269855355702

Epoch: 5| Step: 10
Training loss: 2.1146016120910645
Validation loss: 2.0067341712213334

Epoch: 423| Step: 0
Training loss: 1.5308793783187866
Validation loss: 2.015659393802766

Epoch: 5| Step: 1
Training loss: 1.951395034790039
Validation loss: 2.003642287305606

Epoch: 5| Step: 2
Training loss: 1.8677709102630615
Validation loss: 2.0286641146547053

Epoch: 5| Step: 3
Training loss: 1.9258716106414795
Validation loss: 2.039508318388334

Epoch: 5| Step: 4
Training loss: 2.7660088539123535
Validation loss: 2.050071402262616

Epoch: 5| Step: 5
Training loss: 2.231776475906372
Validation loss: 2.0455994682927288

Epoch: 5| Step: 6
Training loss: 1.3039580583572388
Validation loss: 2.035586605789841

Epoch: 5| Step: 7
Training loss: 2.183143377304077
Validation loss: 2.047657064212266

Epoch: 5| Step: 8
Training loss: 1.3692915439605713
Validation loss: 2.041473788599814

Epoch: 5| Step: 9
Training loss: 1.1764953136444092
Validation loss: 2.0281825962887017

Epoch: 5| Step: 10
Training loss: 2.530505895614624
Validation loss: 2.033517743951531

Epoch: 424| Step: 0
Training loss: 1.402641773223877
Validation loss: 2.029592566592719

Epoch: 5| Step: 1
Training loss: 1.4625871181488037
Validation loss: 2.0315574638305174

Epoch: 5| Step: 2
Training loss: 1.951080083847046
Validation loss: 1.9994249241326445

Epoch: 5| Step: 3
Training loss: 2.4416041374206543
Validation loss: 2.0117153429215953

Epoch: 5| Step: 4
Training loss: 1.7332885265350342
Validation loss: 2.0166976759510655

Epoch: 5| Step: 5
Training loss: 1.4112008810043335
Validation loss: 2.0029469100377892

Epoch: 5| Step: 6
Training loss: 2.4304757118225098
Validation loss: 1.9962174354061004

Epoch: 5| Step: 7
Training loss: 1.878033995628357
Validation loss: 2.0009916854161087

Epoch: 5| Step: 8
Training loss: 2.298469066619873
Validation loss: 1.9988416599970993

Epoch: 5| Step: 9
Training loss: 1.8938848972320557
Validation loss: 2.029651685427594

Epoch: 5| Step: 10
Training loss: 1.8548709154129028
Validation loss: 2.0344611085871214

Epoch: 425| Step: 0
Training loss: 1.6788921356201172
Validation loss: 2.0233250741035707

Epoch: 5| Step: 1
Training loss: 1.5772496461868286
Validation loss: 2.0386922795285463

Epoch: 5| Step: 2
Training loss: 1.3923771381378174
Validation loss: 2.0221984001897995

Epoch: 5| Step: 3
Training loss: 2.0774643421173096
Validation loss: 2.0240783819588284

Epoch: 5| Step: 4
Training loss: 1.8619197607040405
Validation loss: 2.0254638925675423

Epoch: 5| Step: 5
Training loss: 1.5672922134399414
Validation loss: 2.0402709976319344

Epoch: 5| Step: 6
Training loss: 2.4031474590301514
Validation loss: 2.032226042080951

Epoch: 5| Step: 7
Training loss: 1.8344604969024658
Validation loss: 2.027160603513

Epoch: 5| Step: 8
Training loss: 1.7801669836044312
Validation loss: 2.0411072610526957

Epoch: 5| Step: 9
Training loss: 2.035627841949463
Validation loss: 2.043518127933625

Epoch: 5| Step: 10
Training loss: 2.6442723274230957
Validation loss: 2.0417294079257595

Epoch: 426| Step: 0
Training loss: 1.701493263244629
Validation loss: 2.050216382549655

Epoch: 5| Step: 1
Training loss: 1.7445628643035889
Validation loss: 2.0478012625889113

Epoch: 5| Step: 2
Training loss: 1.7897924184799194
Validation loss: 2.04129276480726

Epoch: 5| Step: 3
Training loss: 1.302555799484253
Validation loss: 2.0626498550497074

Epoch: 5| Step: 4
Training loss: 1.7862160205841064
Validation loss: 2.0382549865271455

Epoch: 5| Step: 5
Training loss: 1.661026954650879
Validation loss: 2.044297102958925

Epoch: 5| Step: 6
Training loss: 2.3844337463378906
Validation loss: 2.0208044500761133

Epoch: 5| Step: 7
Training loss: 2.231269359588623
Validation loss: 2.0263422471220776

Epoch: 5| Step: 8
Training loss: 1.8065983057022095
Validation loss: 2.0121733680848153

Epoch: 5| Step: 9
Training loss: 1.9166921377182007
Validation loss: 2.0181051595236665

Epoch: 5| Step: 10
Training loss: 2.4316844940185547
Validation loss: 1.9985645432626047

Epoch: 427| Step: 0
Training loss: 1.2400356531143188
Validation loss: 2.0151693128770396

Epoch: 5| Step: 1
Training loss: 1.3843567371368408
Validation loss: 2.0258142781513993

Epoch: 5| Step: 2
Training loss: 2.471052646636963
Validation loss: 2.0279102774076563

Epoch: 5| Step: 3
Training loss: 2.072230577468872
Validation loss: 2.038508689531716

Epoch: 5| Step: 4
Training loss: 1.6554008722305298
Validation loss: 2.030918498193064

Epoch: 5| Step: 5
Training loss: 2.084777355194092
Validation loss: 2.0434585937889675

Epoch: 5| Step: 6
Training loss: 2.0237154960632324
Validation loss: 2.0446884132200673

Epoch: 5| Step: 7
Training loss: 1.650756597518921
Validation loss: 2.036135196685791

Epoch: 5| Step: 8
Training loss: 2.1441445350646973
Validation loss: 2.032287332319444

Epoch: 5| Step: 9
Training loss: 1.7005994319915771
Validation loss: 2.037892928687475

Epoch: 5| Step: 10
Training loss: 2.5013844966888428
Validation loss: 2.0196857234483123

Epoch: 428| Step: 0
Training loss: 1.59917414188385
Validation loss: 1.998824324659122

Epoch: 5| Step: 1
Training loss: 2.0128350257873535
Validation loss: 2.00045742142585

Epoch: 5| Step: 2
Training loss: 1.096653938293457
Validation loss: 2.003500220596149

Epoch: 5| Step: 3
Training loss: 1.6254602670669556
Validation loss: 1.999003541085028

Epoch: 5| Step: 4
Training loss: 2.1878931522369385
Validation loss: 1.9993770955711283

Epoch: 5| Step: 5
Training loss: 1.8018624782562256
Validation loss: 1.9980031597998835

Epoch: 5| Step: 6
Training loss: 2.641937255859375
Validation loss: 2.000024475077147

Epoch: 5| Step: 7
Training loss: 2.005208969116211
Validation loss: 2.000052580269434

Epoch: 5| Step: 8
Training loss: 1.8272850513458252
Validation loss: 2.0070881869203303

Epoch: 5| Step: 9
Training loss: 2.1355767250061035
Validation loss: 2.0049038920351254

Epoch: 5| Step: 10
Training loss: 1.7783066034317017
Validation loss: 1.9826578453022947

Epoch: 429| Step: 0
Training loss: 2.038114309310913
Validation loss: 1.9924472429419076

Epoch: 5| Step: 1
Training loss: 1.6409584283828735
Validation loss: 1.9988404589314615

Epoch: 5| Step: 2
Training loss: 1.9438968896865845
Validation loss: 1.9857829078551261

Epoch: 5| Step: 3
Training loss: 1.8514751195907593
Validation loss: 1.9965408950723627

Epoch: 5| Step: 4
Training loss: 1.7639873027801514
Validation loss: 1.9968944249614593

Epoch: 5| Step: 5
Training loss: 2.2009072303771973
Validation loss: 2.007366203492688

Epoch: 5| Step: 6
Training loss: 1.8815186023712158
Validation loss: 2.000608600595946

Epoch: 5| Step: 7
Training loss: 1.9445432424545288
Validation loss: 2.015830810352038

Epoch: 5| Step: 8
Training loss: 1.773855209350586
Validation loss: 2.0223468401098765

Epoch: 5| Step: 9
Training loss: 1.9559414386749268
Validation loss: 2.0330771835901404

Epoch: 5| Step: 10
Training loss: 1.7970372438430786
Validation loss: 2.0276168443823375

Epoch: 430| Step: 0
Training loss: 1.8572990894317627
Validation loss: 2.031240855493853

Epoch: 5| Step: 1
Training loss: 1.4501121044158936
Validation loss: 2.060005371288587

Epoch: 5| Step: 2
Training loss: 1.8509759902954102
Validation loss: 2.0623097881194083

Epoch: 5| Step: 3
Training loss: 1.2772618532180786
Validation loss: 2.056059862977715

Epoch: 5| Step: 4
Training loss: 2.0830187797546387
Validation loss: 2.0848343039071686

Epoch: 5| Step: 5
Training loss: 1.7634378671646118
Validation loss: 2.0786353823959187

Epoch: 5| Step: 6
Training loss: 2.2643985748291016
Validation loss: 2.072985949054841

Epoch: 5| Step: 7
Training loss: 2.005977153778076
Validation loss: 2.0677665895031345

Epoch: 5| Step: 8
Training loss: 2.280449390411377
Validation loss: 2.0231348801684637

Epoch: 5| Step: 9
Training loss: 2.1807861328125
Validation loss: 2.03126073011788

Epoch: 5| Step: 10
Training loss: 1.6473222970962524
Validation loss: 2.0312692529411724

Epoch: 431| Step: 0
Training loss: 2.502497434616089
Validation loss: 2.02159724825172

Epoch: 5| Step: 1
Training loss: 2.1206588745117188
Validation loss: 2.008876621082265

Epoch: 5| Step: 2
Training loss: 2.234797954559326
Validation loss: 1.9975063262447235

Epoch: 5| Step: 3
Training loss: 1.7346479892730713
Validation loss: 2.0195508913327287

Epoch: 5| Step: 4
Training loss: 1.3810838460922241
Validation loss: 1.9968835512797039

Epoch: 5| Step: 5
Training loss: 2.2856814861297607
Validation loss: 1.9952803593809887

Epoch: 5| Step: 6
Training loss: 2.208141803741455
Validation loss: 1.998156366809722

Epoch: 5| Step: 7
Training loss: 1.2576323747634888
Validation loss: 2.0234781862587057

Epoch: 5| Step: 8
Training loss: 1.8049099445343018
Validation loss: 2.007445366151871

Epoch: 5| Step: 9
Training loss: 1.6651207208633423
Validation loss: 2.0096896899643766

Epoch: 5| Step: 10
Training loss: 1.3889087438583374
Validation loss: 2.013243588068152

Epoch: 432| Step: 0
Training loss: 1.657546043395996
Validation loss: 2.02032958820302

Epoch: 5| Step: 1
Training loss: 1.8836959600448608
Validation loss: 2.0276172814830655

Epoch: 5| Step: 2
Training loss: 1.8475618362426758
Validation loss: 1.9951996726374472

Epoch: 5| Step: 3
Training loss: 1.4735615253448486
Validation loss: 2.004274202931312

Epoch: 5| Step: 4
Training loss: 2.7917141914367676
Validation loss: 2.0147588791385775

Epoch: 5| Step: 5
Training loss: 1.951279640197754
Validation loss: 2.021600777103055

Epoch: 5| Step: 6
Training loss: 2.245654582977295
Validation loss: 2.0180500374045423

Epoch: 5| Step: 7
Training loss: 1.8586194515228271
Validation loss: 2.018674450535928

Epoch: 5| Step: 8
Training loss: 1.5719332695007324
Validation loss: 2.019727408245046

Epoch: 5| Step: 9
Training loss: 2.0407681465148926
Validation loss: 2.011097402982814

Epoch: 5| Step: 10
Training loss: 1.353272795677185
Validation loss: 2.014486361575383

Epoch: 433| Step: 0
Training loss: 1.8957840204238892
Validation loss: 2.021124388581963

Epoch: 5| Step: 1
Training loss: 1.4901158809661865
Validation loss: 2.012258255353538

Epoch: 5| Step: 2
Training loss: 1.472739577293396
Validation loss: 2.0316684656245734

Epoch: 5| Step: 3
Training loss: 2.0193533897399902
Validation loss: 2.023296703574478

Epoch: 5| Step: 4
Training loss: 1.668902039527893
Validation loss: 2.032530774352371

Epoch: 5| Step: 5
Training loss: 1.8478056192398071
Validation loss: 2.058491099265314

Epoch: 5| Step: 6
Training loss: 1.9767169952392578
Validation loss: 2.0397311384959886

Epoch: 5| Step: 7
Training loss: 1.2788841724395752
Validation loss: 2.03264880693087

Epoch: 5| Step: 8
Training loss: 2.2734854221343994
Validation loss: 2.0362105856659594

Epoch: 5| Step: 9
Training loss: 1.99396550655365
Validation loss: 2.0335091570372223

Epoch: 5| Step: 10
Training loss: 2.732799530029297
Validation loss: 2.0325603305652575

Epoch: 434| Step: 0
Training loss: 2.1038129329681396
Validation loss: 2.021184467500256

Epoch: 5| Step: 1
Training loss: 1.7040656805038452
Validation loss: 2.033667941247263

Epoch: 5| Step: 2
Training loss: 2.0244407653808594
Validation loss: 2.034949134754878

Epoch: 5| Step: 3
Training loss: 1.8539047241210938
Validation loss: 2.038082886767644

Epoch: 5| Step: 4
Training loss: 1.6733566522598267
Validation loss: 2.0178783247547765

Epoch: 5| Step: 5
Training loss: 2.1719915866851807
Validation loss: 2.0045849200217956

Epoch: 5| Step: 6
Training loss: 1.7766163349151611
Validation loss: 2.010962857994982

Epoch: 5| Step: 7
Training loss: 1.7894665002822876
Validation loss: 1.9934718852402062

Epoch: 5| Step: 8
Training loss: 1.4454180002212524
Validation loss: 1.9785499034389373

Epoch: 5| Step: 9
Training loss: 1.773428201675415
Validation loss: 2.017148301165591

Epoch: 5| Step: 10
Training loss: 2.2491166591644287
Validation loss: 1.991752580929828

Epoch: 435| Step: 0
Training loss: 2.003122091293335
Validation loss: 2.007631801789807

Epoch: 5| Step: 1
Training loss: 1.5604467391967773
Validation loss: 2.0004822054216937

Epoch: 5| Step: 2
Training loss: 1.7487272024154663
Validation loss: 1.98552200102037

Epoch: 5| Step: 3
Training loss: 1.3277114629745483
Validation loss: 1.9869010256182762

Epoch: 5| Step: 4
Training loss: 2.1439592838287354
Validation loss: 1.9896749578496462

Epoch: 5| Step: 5
Training loss: 1.7466354370117188
Validation loss: 2.0046201123986194

Epoch: 5| Step: 6
Training loss: 2.1609554290771484
Validation loss: 1.9994614278116534

Epoch: 5| Step: 7
Training loss: 2.1646461486816406
Validation loss: 2.0139588386781755

Epoch: 5| Step: 8
Training loss: 1.8751323223114014
Validation loss: 2.0044619549987135

Epoch: 5| Step: 9
Training loss: 1.8796741962432861
Validation loss: 2.0148981514797417

Epoch: 5| Step: 10
Training loss: 1.772775411605835
Validation loss: 2.016044356489694

Epoch: 436| Step: 0
Training loss: 1.8342773914337158
Validation loss: 2.033744460792952

Epoch: 5| Step: 1
Training loss: 1.9174076318740845
Validation loss: 2.016852839018709

Epoch: 5| Step: 2
Training loss: 1.8842490911483765
Validation loss: 2.0006712585367183

Epoch: 5| Step: 3
Training loss: 2.359093189239502
Validation loss: 2.0144758750033636

Epoch: 5| Step: 4
Training loss: 2.101392984390259
Validation loss: 1.996726159126528

Epoch: 5| Step: 5
Training loss: 2.151754140853882
Validation loss: 1.987193940788187

Epoch: 5| Step: 6
Training loss: 1.4830207824707031
Validation loss: 1.9965612913972588

Epoch: 5| Step: 7
Training loss: 1.0457494258880615
Validation loss: 2.009193362728242

Epoch: 5| Step: 8
Training loss: 1.9361846446990967
Validation loss: 2.0166201770946546

Epoch: 5| Step: 9
Training loss: 1.483660340309143
Validation loss: 2.017388479683989

Epoch: 5| Step: 10
Training loss: 2.4079220294952393
Validation loss: 2.0377332907851025

Epoch: 437| Step: 0
Training loss: 1.837817907333374
Validation loss: 2.0323529576742523

Epoch: 5| Step: 1
Training loss: 1.8474647998809814
Validation loss: 2.037635974986579

Epoch: 5| Step: 2
Training loss: 2.204246759414673
Validation loss: 2.0376919623344176

Epoch: 5| Step: 3
Training loss: 1.8770242929458618
Validation loss: 2.0226073508621543

Epoch: 5| Step: 4
Training loss: 1.4039380550384521
Validation loss: 2.012484158239057

Epoch: 5| Step: 5
Training loss: 0.9184924960136414
Validation loss: 2.022454789889756

Epoch: 5| Step: 6
Training loss: 2.2573070526123047
Validation loss: 2.032123624637563

Epoch: 5| Step: 7
Training loss: 2.2607104778289795
Validation loss: 2.04185531216283

Epoch: 5| Step: 8
Training loss: 2.062238931655884
Validation loss: 2.0535107376754924

Epoch: 5| Step: 9
Training loss: 1.7648460865020752
Validation loss: 2.03149982934357

Epoch: 5| Step: 10
Training loss: 2.0143492221832275
Validation loss: 2.0288218246993197

Epoch: 438| Step: 0
Training loss: 2.388059616088867
Validation loss: 2.030996532850368

Epoch: 5| Step: 1
Training loss: 1.3711755275726318
Validation loss: 2.0090303280020274

Epoch: 5| Step: 2
Training loss: 1.4707660675048828
Validation loss: 2.009242102664004

Epoch: 5| Step: 3
Training loss: 1.5654503107070923
Validation loss: 1.9980013524332354

Epoch: 5| Step: 4
Training loss: 2.138803482055664
Validation loss: 2.0110535929279942

Epoch: 5| Step: 5
Training loss: 2.1124439239501953
Validation loss: 2.016239858442737

Epoch: 5| Step: 6
Training loss: 1.284437894821167
Validation loss: 2.030635045420739

Epoch: 5| Step: 7
Training loss: 1.8691962957382202
Validation loss: 2.027176841612785

Epoch: 5| Step: 8
Training loss: 1.9003616571426392
Validation loss: 2.023933636244907

Epoch: 5| Step: 9
Training loss: 2.029437780380249
Validation loss: 2.0006637406605545

Epoch: 5| Step: 10
Training loss: 2.508824110031128
Validation loss: 1.9907552401224773

Epoch: 439| Step: 0
Training loss: 2.1021487712860107
Validation loss: 2.001008609289764

Epoch: 5| Step: 1
Training loss: 2.1872200965881348
Validation loss: 1.9842395987561954

Epoch: 5| Step: 2
Training loss: 2.49540376663208
Validation loss: 1.999342494113471

Epoch: 5| Step: 3
Training loss: 1.949062705039978
Validation loss: 1.9861033642163841

Epoch: 5| Step: 4
Training loss: 1.3796865940093994
Validation loss: 2.000097228634742

Epoch: 5| Step: 5
Training loss: 1.6843681335449219
Validation loss: 1.9788811488818097

Epoch: 5| Step: 6
Training loss: 1.5500586032867432
Validation loss: 1.9838026274916947

Epoch: 5| Step: 7
Training loss: 1.9585880041122437
Validation loss: 1.9820008995712444

Epoch: 5| Step: 8
Training loss: 1.6976735591888428
Validation loss: 1.9794033163337297

Epoch: 5| Step: 9
Training loss: 1.4377717971801758
Validation loss: 2.0071236061793503

Epoch: 5| Step: 10
Training loss: 2.2711830139160156
Validation loss: 2.039721453061668

Epoch: 440| Step: 0
Training loss: 2.0839781761169434
Validation loss: 2.0444602902217577

Epoch: 5| Step: 1
Training loss: 2.101618528366089
Validation loss: 2.066991654775476

Epoch: 5| Step: 2
Training loss: 1.4525401592254639
Validation loss: 2.0702367303191975

Epoch: 5| Step: 3
Training loss: 2.098982334136963
Validation loss: 2.0424282114992858

Epoch: 5| Step: 4
Training loss: 2.3825602531433105
Validation loss: 2.0686107015097015

Epoch: 5| Step: 5
Training loss: 1.587233304977417
Validation loss: 2.0554944058900237

Epoch: 5| Step: 6
Training loss: 1.7270551919937134
Validation loss: 2.0635229233772523

Epoch: 5| Step: 7
Training loss: 1.244106650352478
Validation loss: 2.073538091874892

Epoch: 5| Step: 8
Training loss: 1.9007444381713867
Validation loss: 2.078916606082711

Epoch: 5| Step: 9
Training loss: 1.9245868921279907
Validation loss: 2.0654313589936946

Epoch: 5| Step: 10
Training loss: 2.013432502746582
Validation loss: 2.0398941129766484

Epoch: 441| Step: 0
Training loss: 2.191906690597534
Validation loss: 2.033106888494184

Epoch: 5| Step: 1
Training loss: 1.6195141077041626
Validation loss: 2.0289184995876846

Epoch: 5| Step: 2
Training loss: 1.9609715938568115
Validation loss: 2.0439374844233194

Epoch: 5| Step: 3
Training loss: 1.9322456121444702
Validation loss: 2.0303863120335404

Epoch: 5| Step: 4
Training loss: 2.029611349105835
Validation loss: 2.0559316783822994

Epoch: 5| Step: 5
Training loss: 1.6147912740707397
Validation loss: 2.0309058299628635

Epoch: 5| Step: 6
Training loss: 2.085261583328247
Validation loss: 2.0305075030173025

Epoch: 5| Step: 7
Training loss: 2.0537850856781006
Validation loss: 2.02509835714935

Epoch: 5| Step: 8
Training loss: 2.117138385772705
Validation loss: 1.9987146546763759

Epoch: 5| Step: 9
Training loss: 1.002883791923523
Validation loss: 2.015462433138201

Epoch: 5| Step: 10
Training loss: 2.027440309524536
Validation loss: 1.9943218897747736

Epoch: 442| Step: 0
Training loss: 1.7460148334503174
Validation loss: 2.0079024120043685

Epoch: 5| Step: 1
Training loss: 1.8587749004364014
Validation loss: 1.9912656404638802

Epoch: 5| Step: 2
Training loss: 1.820680022239685
Validation loss: 1.9884133544019473

Epoch: 5| Step: 3
Training loss: 2.010340452194214
Validation loss: 2.001780197184573

Epoch: 5| Step: 4
Training loss: 1.1318488121032715
Validation loss: 1.975681125476796

Epoch: 5| Step: 5
Training loss: 1.8774497509002686
Validation loss: 1.9841781995629753

Epoch: 5| Step: 6
Training loss: 2.005561113357544
Validation loss: 1.9941878382877638

Epoch: 5| Step: 7
Training loss: 1.5476033687591553
Validation loss: 2.005334864380539

Epoch: 5| Step: 8
Training loss: 2.286799192428589
Validation loss: 1.9868458496626986

Epoch: 5| Step: 9
Training loss: 2.0195281505584717
Validation loss: 2.0013016834053943

Epoch: 5| Step: 10
Training loss: 1.930139422416687
Validation loss: 2.017981431817496

Epoch: 443| Step: 0
Training loss: 2.438535213470459
Validation loss: 2.006987107697354

Epoch: 5| Step: 1
Training loss: 1.1723984479904175
Validation loss: 2.0344537509384977

Epoch: 5| Step: 2
Training loss: 2.074486017227173
Validation loss: 2.053933960135265

Epoch: 5| Step: 3
Training loss: 2.1838510036468506
Validation loss: 2.0476351540575743

Epoch: 5| Step: 4
Training loss: 2.0684256553649902
Validation loss: 2.039599496831176

Epoch: 5| Step: 5
Training loss: 1.5388891696929932
Validation loss: 2.042540023403783

Epoch: 5| Step: 6
Training loss: 1.666277527809143
Validation loss: 2.035839560211346

Epoch: 5| Step: 7
Training loss: 1.838460922241211
Validation loss: 2.0547255674997964

Epoch: 5| Step: 8
Training loss: 1.9516868591308594
Validation loss: 2.0551265772952827

Epoch: 5| Step: 9
Training loss: 2.078949451446533
Validation loss: 2.0422860653169694

Epoch: 5| Step: 10
Training loss: 1.1718051433563232
Validation loss: 2.031794507016418

Epoch: 444| Step: 0
Training loss: 1.550217628479004
Validation loss: 2.0001744211360974

Epoch: 5| Step: 1
Training loss: 1.624098777770996
Validation loss: 2.0136381682529243

Epoch: 5| Step: 2
Training loss: 1.7631661891937256
Validation loss: 2.0014663511706936

Epoch: 5| Step: 3
Training loss: 2.112459182739258
Validation loss: 2.018665612384837

Epoch: 5| Step: 4
Training loss: 2.043410539627075
Validation loss: 2.0131323299100323

Epoch: 5| Step: 5
Training loss: 2.277092456817627
Validation loss: 2.002861169076735

Epoch: 5| Step: 6
Training loss: 2.1081199645996094
Validation loss: 2.0226755988213325

Epoch: 5| Step: 7
Training loss: 1.963213324546814
Validation loss: 2.012539650804253

Epoch: 5| Step: 8
Training loss: 1.6494194269180298
Validation loss: 2.019691931304111

Epoch: 5| Step: 9
Training loss: 1.8237247467041016
Validation loss: 2.0362530857004146

Epoch: 5| Step: 10
Training loss: 1.3334895372390747
Validation loss: 2.022061832489506

Epoch: 445| Step: 0
Training loss: 2.0971310138702393
Validation loss: 2.017101721097064

Epoch: 5| Step: 1
Training loss: 1.7574180364608765
Validation loss: 2.014978490849977

Epoch: 5| Step: 2
Training loss: 1.932025671005249
Validation loss: 2.014313495287331

Epoch: 5| Step: 3
Training loss: 1.5679032802581787
Validation loss: 2.0190814310504543

Epoch: 5| Step: 4
Training loss: 1.7330669164657593
Validation loss: 2.0192884950227636

Epoch: 5| Step: 5
Training loss: 1.8785070180892944
Validation loss: 2.032437209160097

Epoch: 5| Step: 6
Training loss: 1.217164397239685
Validation loss: 2.0263969731587235

Epoch: 5| Step: 7
Training loss: 2.113124370574951
Validation loss: 2.0250425569472776

Epoch: 5| Step: 8
Training loss: 1.8690242767333984
Validation loss: 2.029110336816439

Epoch: 5| Step: 9
Training loss: 1.6789172887802124
Validation loss: 2.0111841412000757

Epoch: 5| Step: 10
Training loss: 2.3329355716705322
Validation loss: 2.0213149670631654

Epoch: 446| Step: 0
Training loss: 2.1964633464813232
Validation loss: 2.025830002241237

Epoch: 5| Step: 1
Training loss: 1.968971848487854
Validation loss: 2.0476700477702643

Epoch: 5| Step: 2
Training loss: 1.870819091796875
Validation loss: 2.0521441121255197

Epoch: 5| Step: 3
Training loss: 1.3750536441802979
Validation loss: 2.077110803255471

Epoch: 5| Step: 4
Training loss: 1.65683913230896
Validation loss: 2.071265402660575

Epoch: 5| Step: 5
Training loss: 1.9306118488311768
Validation loss: 2.057329986685066

Epoch: 5| Step: 6
Training loss: 2.3442935943603516
Validation loss: 2.0393740720646356

Epoch: 5| Step: 7
Training loss: 2.1130053997039795
Validation loss: 2.0284672872994536

Epoch: 5| Step: 8
Training loss: 1.8690874576568604
Validation loss: 2.0283608692948536

Epoch: 5| Step: 9
Training loss: 1.863677978515625
Validation loss: 2.01987668647561

Epoch: 5| Step: 10
Training loss: 0.9770169854164124
Validation loss: 2.0186484526562434

Epoch: 447| Step: 0
Training loss: 1.6189178228378296
Validation loss: 2.027441402917267

Epoch: 5| Step: 1
Training loss: 1.64883553981781
Validation loss: 2.0106284977287374

Epoch: 5| Step: 2
Training loss: 1.3698954582214355
Validation loss: 2.017164607201853

Epoch: 5| Step: 3
Training loss: 2.3654284477233887
Validation loss: 1.9923411876924577

Epoch: 5| Step: 4
Training loss: 1.686140775680542
Validation loss: 2.0004319273015505

Epoch: 5| Step: 5
Training loss: 2.1602795124053955
Validation loss: 2.0040886799494424

Epoch: 5| Step: 6
Training loss: 2.3330912590026855
Validation loss: 2.004024592779016

Epoch: 5| Step: 7
Training loss: 1.8457624912261963
Validation loss: 2.0518114759076025

Epoch: 5| Step: 8
Training loss: 1.849632978439331
Validation loss: 2.038709097011115

Epoch: 5| Step: 9
Training loss: 1.7932132482528687
Validation loss: 2.097758893043764

Epoch: 5| Step: 10
Training loss: 1.6890021562576294
Validation loss: 2.0635278289036085

Epoch: 448| Step: 0
Training loss: 2.246579647064209
Validation loss: 2.055958585072589

Epoch: 5| Step: 1
Training loss: 1.6974258422851562
Validation loss: 2.029698330868957

Epoch: 5| Step: 2
Training loss: 1.7094299793243408
Validation loss: 2.007327596346537

Epoch: 5| Step: 3
Training loss: 1.4835498332977295
Validation loss: 2.0073826697564896

Epoch: 5| Step: 4
Training loss: 2.157421588897705
Validation loss: 1.9907375356202484

Epoch: 5| Step: 5
Training loss: 1.948756217956543
Validation loss: 1.9929898362005911

Epoch: 5| Step: 6
Training loss: 1.105150818824768
Validation loss: 1.9980851014455159

Epoch: 5| Step: 7
Training loss: 2.065849781036377
Validation loss: 1.9992574107262395

Epoch: 5| Step: 8
Training loss: 2.2408249378204346
Validation loss: 1.9775914146054177

Epoch: 5| Step: 9
Training loss: 1.5487836599349976
Validation loss: 1.9808602307432441

Epoch: 5| Step: 10
Training loss: 2.1234326362609863
Validation loss: 1.9792839609166628

Epoch: 449| Step: 0
Training loss: 1.7047879695892334
Validation loss: 2.007051323049812

Epoch: 5| Step: 1
Training loss: 1.5625667572021484
Validation loss: 2.0277523302262828

Epoch: 5| Step: 2
Training loss: 1.9697530269622803
Validation loss: 2.0380401534418904

Epoch: 5| Step: 3
Training loss: 2.042569637298584
Validation loss: 2.0576797505860687

Epoch: 5| Step: 4
Training loss: 1.6818395853042603
Validation loss: 2.063457267258757

Epoch: 5| Step: 5
Training loss: 2.154233694076538
Validation loss: 2.0366613736716648

Epoch: 5| Step: 6
Training loss: 1.6403290033340454
Validation loss: 2.0328658037288214

Epoch: 5| Step: 7
Training loss: 1.9504448175430298
Validation loss: 2.018886839189837

Epoch: 5| Step: 8
Training loss: 1.860997200012207
Validation loss: 2.0242817581340833

Epoch: 5| Step: 9
Training loss: 1.199393630027771
Validation loss: 2.0168916858652586

Epoch: 5| Step: 10
Training loss: 2.3207244873046875
Validation loss: 2.0304445400032947

Epoch: 450| Step: 0
Training loss: 1.3469582796096802
Validation loss: 2.046973805273733

Epoch: 5| Step: 1
Training loss: 1.123612880706787
Validation loss: 2.054127420148542

Epoch: 5| Step: 2
Training loss: 2.0524020195007324
Validation loss: 2.059089893935829

Epoch: 5| Step: 3
Training loss: 1.765723466873169
Validation loss: 2.048194703235421

Epoch: 5| Step: 4
Training loss: 1.8526275157928467
Validation loss: 2.0334726738673385

Epoch: 5| Step: 5
Training loss: 1.9519679546356201
Validation loss: 2.01676131063892

Epoch: 5| Step: 6
Training loss: 2.275059938430786
Validation loss: 2.01975820526

Epoch: 5| Step: 7
Training loss: 1.7382055521011353
Validation loss: 2.0383658383482244

Epoch: 5| Step: 8
Training loss: 1.750739336013794
Validation loss: 2.0630043988586753

Epoch: 5| Step: 9
Training loss: 2.4321792125701904
Validation loss: 2.0530467315386702

Epoch: 5| Step: 10
Training loss: 1.7808544635772705
Validation loss: 2.056418062538229

Testing loss: 2.207449714342753
