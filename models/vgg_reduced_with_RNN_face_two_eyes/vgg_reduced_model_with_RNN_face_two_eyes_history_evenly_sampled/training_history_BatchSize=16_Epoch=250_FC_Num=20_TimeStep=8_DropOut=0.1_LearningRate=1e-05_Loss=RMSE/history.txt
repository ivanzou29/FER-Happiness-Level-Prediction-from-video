Epoch: 1| Step: 0
Training loss: 5.203953032719266
Validation loss: 5.841869452413798

Epoch: 6| Step: 1
Training loss: 6.469938159865245
Validation loss: 5.834285336114079

Epoch: 6| Step: 2
Training loss: 5.119339212453886
Validation loss: 5.8263808251222935

Epoch: 6| Step: 3
Training loss: 5.266469282161548
Validation loss: 5.818451123854527

Epoch: 6| Step: 4
Training loss: 7.8146100666101095
Validation loss: 5.809969794706158

Epoch: 6| Step: 5
Training loss: 6.038721704181825
Validation loss: 5.801015716075684

Epoch: 6| Step: 6
Training loss: 6.123239692438529
Validation loss: 5.791943965826645

Epoch: 6| Step: 7
Training loss: 5.592974220056866
Validation loss: 5.781735405115123

Epoch: 6| Step: 8
Training loss: 6.628450466799937
Validation loss: 5.770733451697075

Epoch: 6| Step: 9
Training loss: 5.17538600348169
Validation loss: 5.7589608982614156

Epoch: 6| Step: 10
Training loss: 5.549171853354034
Validation loss: 5.746042324316855

Epoch: 6| Step: 11
Training loss: 5.642427531576873
Validation loss: 5.7323125739474365

Epoch: 6| Step: 12
Training loss: 4.2145118052355395
Validation loss: 5.716706709140175

Epoch: 6| Step: 13
Training loss: 5.7672090499504245
Validation loss: 5.700522022993632

Epoch: 2| Step: 0
Training loss: 6.394229385437603
Validation loss: 5.68341020178416

Epoch: 6| Step: 1
Training loss: 5.493521950147104
Validation loss: 5.663901631040748

Epoch: 6| Step: 2
Training loss: 5.437256730875073
Validation loss: 5.643213218173036

Epoch: 6| Step: 3
Training loss: 5.383729455189933
Validation loss: 5.6213217847258745

Epoch: 6| Step: 4
Training loss: 5.715096395752581
Validation loss: 5.5977704390639245

Epoch: 6| Step: 5
Training loss: 4.4551834435162
Validation loss: 5.572351830691605

Epoch: 6| Step: 6
Training loss: 6.290391333798257
Validation loss: 5.546361948192656

Epoch: 6| Step: 7
Training loss: 6.350609889741275
Validation loss: 5.518727901273603

Epoch: 6| Step: 8
Training loss: 4.323219576721141
Validation loss: 5.489440597929795

Epoch: 6| Step: 9
Training loss: 5.555745341979925
Validation loss: 5.460189606396929

Epoch: 6| Step: 10
Training loss: 5.743433312453416
Validation loss: 5.42952222521652

Epoch: 6| Step: 11
Training loss: 5.100110535265273
Validation loss: 5.398668464255188

Epoch: 6| Step: 12
Training loss: 5.400191953567575
Validation loss: 5.365767847219745

Epoch: 6| Step: 13
Training loss: 6.142559804722282
Validation loss: 5.334193323130618

Epoch: 3| Step: 0
Training loss: 5.087744794575153
Validation loss: 5.302237408858387

Epoch: 6| Step: 1
Training loss: 6.118092904738831
Validation loss: 5.270786596315797

Epoch: 6| Step: 2
Training loss: 5.535349905089771
Validation loss: 5.238767051910477

Epoch: 6| Step: 3
Training loss: 4.762082043027134
Validation loss: 5.206122750358796

Epoch: 6| Step: 4
Training loss: 6.493074101802929
Validation loss: 5.1739729006433635

Epoch: 6| Step: 5
Training loss: 4.492826041573806
Validation loss: 5.143073176153327

Epoch: 6| Step: 6
Training loss: 4.736714304488265
Validation loss: 5.112353777655378

Epoch: 6| Step: 7
Training loss: 4.292059179831265
Validation loss: 5.081132729517913

Epoch: 6| Step: 8
Training loss: 4.662036551588759
Validation loss: 5.049629008870988

Epoch: 6| Step: 9
Training loss: 5.509670079595177
Validation loss: 5.0175272911076725

Epoch: 6| Step: 10
Training loss: 5.20995315794288
Validation loss: 4.986531606844238

Epoch: 6| Step: 11
Training loss: 4.118631706796624
Validation loss: 4.953200437810367

Epoch: 6| Step: 12
Training loss: 5.443612707708313
Validation loss: 4.919389655146187

Epoch: 6| Step: 13
Training loss: 5.384135444966637
Validation loss: 4.883862013384693

Epoch: 4| Step: 0
Training loss: 4.535499842308462
Validation loss: 4.849121210852952

Epoch: 6| Step: 1
Training loss: 5.259802250499106
Validation loss: 4.81396349615114

Epoch: 6| Step: 2
Training loss: 4.882585932243506
Validation loss: 4.778972574750724

Epoch: 6| Step: 3
Training loss: 5.472681517886439
Validation loss: 4.747183806320986

Epoch: 6| Step: 4
Training loss: 5.209371031065712
Validation loss: 4.721539737637858

Epoch: 6| Step: 5
Training loss: 4.068373439726049
Validation loss: 4.698868559615199

Epoch: 6| Step: 6
Training loss: 5.544925486800954
Validation loss: 4.678001257640916

Epoch: 6| Step: 7
Training loss: 4.821178191611822
Validation loss: 4.655153004225737

Epoch: 6| Step: 8
Training loss: 3.908283162286393
Validation loss: 4.633052227416255

Epoch: 6| Step: 9
Training loss: 5.628844240311634
Validation loss: 4.612431788791227

Epoch: 6| Step: 10
Training loss: 4.862578387964719
Validation loss: 4.593564828167148

Epoch: 6| Step: 11
Training loss: 3.2131105666549673
Validation loss: 4.575356182881223

Epoch: 6| Step: 12
Training loss: 4.650135095746295
Validation loss: 4.557020273967155

Epoch: 6| Step: 13
Training loss: 3.6925282221434252
Validation loss: 4.5395326134245755

Epoch: 5| Step: 0
Training loss: 4.326861806582424
Validation loss: 4.523380237876952

Epoch: 6| Step: 1
Training loss: 4.257041931418972
Validation loss: 4.507428730280132

Epoch: 6| Step: 2
Training loss: 4.008177980411579
Validation loss: 4.49021302647551

Epoch: 6| Step: 3
Training loss: 5.224671071481513
Validation loss: 4.472344775006789

Epoch: 6| Step: 4
Training loss: 5.430989544311416
Validation loss: 4.456136633641343

Epoch: 6| Step: 5
Training loss: 4.589445627680275
Validation loss: 4.435786257044879

Epoch: 6| Step: 6
Training loss: 5.172959136276444
Validation loss: 4.416650842106974

Epoch: 6| Step: 7
Training loss: 4.836553531290144
Validation loss: 4.401839115801157

Epoch: 6| Step: 8
Training loss: 3.4217161376865115
Validation loss: 4.385076382429507

Epoch: 6| Step: 9
Training loss: 4.082497076441132
Validation loss: 4.370882638227576

Epoch: 6| Step: 10
Training loss: 4.536215120519408
Validation loss: 4.355377859378199

Epoch: 6| Step: 11
Training loss: 4.325755879054076
Validation loss: 4.3425063929727195

Epoch: 6| Step: 12
Training loss: 4.4043193943437595
Validation loss: 4.330503646549756

Epoch: 6| Step: 13
Training loss: 4.397053963408785
Validation loss: 4.316887631456106

Epoch: 6| Step: 0
Training loss: 4.626391433495749
Validation loss: 4.300333059680671

Epoch: 6| Step: 1
Training loss: 3.7642406910752504
Validation loss: 4.285825859615646

Epoch: 6| Step: 2
Training loss: 4.157946477005163
Validation loss: 4.26920923926406

Epoch: 6| Step: 3
Training loss: 4.4495211825849825
Validation loss: 4.252298685325553

Epoch: 6| Step: 4
Training loss: 4.649477340693895
Validation loss: 4.2350752904200295

Epoch: 6| Step: 5
Training loss: 4.48894074245337
Validation loss: 4.218809586031623

Epoch: 6| Step: 6
Training loss: 4.675574837497006
Validation loss: 4.201749616325282

Epoch: 6| Step: 7
Training loss: 3.9409041448791897
Validation loss: 4.184690590639681

Epoch: 6| Step: 8
Training loss: 3.9689838010150313
Validation loss: 4.170731710491

Epoch: 6| Step: 9
Training loss: 4.294563698329411
Validation loss: 4.158527232454966

Epoch: 6| Step: 10
Training loss: 4.184595495657887
Validation loss: 4.148291986016541

Epoch: 6| Step: 11
Training loss: 4.720899685928996
Validation loss: 4.137716773518113

Epoch: 6| Step: 12
Training loss: 4.680024760580178
Validation loss: 4.120932133525615

Epoch: 6| Step: 13
Training loss: 3.5239814964267624
Validation loss: 4.1047689094800335

Epoch: 7| Step: 0
Training loss: 4.68401156002348
Validation loss: 4.092263411556925

Epoch: 6| Step: 1
Training loss: 4.111445960306603
Validation loss: 4.078298435932278

Epoch: 6| Step: 2
Training loss: 3.6191920087926794
Validation loss: 4.061883118193692

Epoch: 6| Step: 3
Training loss: 4.230355582656485
Validation loss: 4.048920329019116

Epoch: 6| Step: 4
Training loss: 5.268549166615504
Validation loss: 4.039944721604408

Epoch: 6| Step: 5
Training loss: 4.106966770733385
Validation loss: 4.0277384377834275

Epoch: 6| Step: 6
Training loss: 5.1219694900408355
Validation loss: 4.01614837791731

Epoch: 6| Step: 7
Training loss: 4.223329220483509
Validation loss: 4.004252777671001

Epoch: 6| Step: 8
Training loss: 3.009971576949352
Validation loss: 3.9923483615065156

Epoch: 6| Step: 9
Training loss: 4.4134464880582955
Validation loss: 3.9846014734994695

Epoch: 6| Step: 10
Training loss: 4.287023507824586
Validation loss: 3.972302314089877

Epoch: 6| Step: 11
Training loss: 3.7591179941406563
Validation loss: 3.958695041643317

Epoch: 6| Step: 12
Training loss: 2.796350014287336
Validation loss: 3.9461753074777928

Epoch: 6| Step: 13
Training loss: 3.855386255805963
Validation loss: 3.934902422308413

Epoch: 8| Step: 0
Training loss: 3.428554756260253
Validation loss: 3.9228342809227565

Epoch: 6| Step: 1
Training loss: 3.386144534384092
Validation loss: 3.9106026905877376

Epoch: 6| Step: 2
Training loss: 3.654318927186602
Validation loss: 3.9026458927761714

Epoch: 6| Step: 3
Training loss: 3.8811506863724823
Validation loss: 3.8921948632151846

Epoch: 6| Step: 4
Training loss: 4.008000479113766
Validation loss: 3.882705658945847

Epoch: 6| Step: 5
Training loss: 4.007173305052892
Validation loss: 3.8701165820486376

Epoch: 6| Step: 6
Training loss: 5.260135131956718
Validation loss: 3.8647252989803764

Epoch: 6| Step: 7
Training loss: 2.8294920594218063
Validation loss: 3.852068419982685

Epoch: 6| Step: 8
Training loss: 4.774601521267471
Validation loss: 3.8487155500320274

Epoch: 6| Step: 9
Training loss: 4.354830872222156
Validation loss: 3.8376659467925394

Epoch: 6| Step: 10
Training loss: 4.658713284433024
Validation loss: 3.82766068677034

Epoch: 6| Step: 11
Training loss: 4.191450845813546
Validation loss: 3.821912510848065

Epoch: 6| Step: 12
Training loss: 4.112539255250527
Validation loss: 3.814905602929846

Epoch: 6| Step: 13
Training loss: 2.1882246724461476
Validation loss: 3.806983551589002

Epoch: 9| Step: 0
Training loss: 3.7335402062410754
Validation loss: 3.798454636336765

Epoch: 6| Step: 1
Training loss: 3.8136362352535498
Validation loss: 3.793730126409771

Epoch: 6| Step: 2
Training loss: 3.810660121531257
Validation loss: 3.7919627649516974

Epoch: 6| Step: 3
Training loss: 5.107726598223251
Validation loss: 3.7854094794858444

Epoch: 6| Step: 4
Training loss: 3.566018358175848
Validation loss: 3.776383753108817

Epoch: 6| Step: 5
Training loss: 4.260481083887371
Validation loss: 3.773200231431815

Epoch: 6| Step: 6
Training loss: 3.7384992354564286
Validation loss: 3.7670937632956365

Epoch: 6| Step: 7
Training loss: 4.322122646471589
Validation loss: 3.7647060300450295

Epoch: 6| Step: 8
Training loss: 3.904635774865921
Validation loss: 3.7553670370423338

Epoch: 6| Step: 9
Training loss: 3.729574653570782
Validation loss: 3.747855309446984

Epoch: 6| Step: 10
Training loss: 3.4186539491763055
Validation loss: 3.746810813490255

Epoch: 6| Step: 11
Training loss: 3.446012879890553
Validation loss: 3.744279275672792

Epoch: 6| Step: 12
Training loss: 4.004505719224015
Validation loss: 3.7392803824321232

Epoch: 6| Step: 13
Training loss: 4.234249324270819
Validation loss: 3.7357968728890705

Epoch: 10| Step: 0
Training loss: 3.6327508080279247
Validation loss: 3.726126162725999

Epoch: 6| Step: 1
Training loss: 4.245299938016242
Validation loss: 3.7196405064433318

Epoch: 6| Step: 2
Training loss: 2.3383442909417202
Validation loss: 3.71647469788008

Epoch: 6| Step: 3
Training loss: 4.046771780929069
Validation loss: 3.709719014748265

Epoch: 6| Step: 4
Training loss: 4.649233863638054
Validation loss: 3.7068012986204093

Epoch: 6| Step: 5
Training loss: 3.7647025217013224
Validation loss: 3.7049403765387656

Epoch: 6| Step: 6
Training loss: 4.076749723206474
Validation loss: 3.6991513945613033

Epoch: 6| Step: 7
Training loss: 4.984075363862992
Validation loss: 3.697570786454214

Epoch: 6| Step: 8
Training loss: 2.8047506596246294
Validation loss: 3.6917050736970918

Epoch: 6| Step: 9
Training loss: 3.472648011273973
Validation loss: 3.686454863996743

Epoch: 6| Step: 10
Training loss: 4.143088245053299
Validation loss: 3.683555964646702

Epoch: 6| Step: 11
Training loss: 3.753235501990041
Validation loss: 3.6775699895232283

Epoch: 6| Step: 12
Training loss: 4.117418431097715
Validation loss: 3.673910848262534

Epoch: 6| Step: 13
Training loss: 3.361500905731456
Validation loss: 3.671643438916272

Epoch: 11| Step: 0
Training loss: 3.6945780695664805
Validation loss: 3.6672954360476293

Epoch: 6| Step: 1
Training loss: 3.8346765625003183
Validation loss: 3.661915184423463

Epoch: 6| Step: 2
Training loss: 3.5005280232631177
Validation loss: 3.655278046795562

Epoch: 6| Step: 3
Training loss: 4.054001590286191
Validation loss: 3.651198892027128

Epoch: 6| Step: 4
Training loss: 3.6885502499589413
Validation loss: 3.645486975652838

Epoch: 6| Step: 5
Training loss: 3.2330876981366856
Validation loss: 3.642320327193918

Epoch: 6| Step: 6
Training loss: 3.7798754503025367
Validation loss: 3.6402951187513035

Epoch: 6| Step: 7
Training loss: 3.977714446668876
Validation loss: 3.634760106641562

Epoch: 6| Step: 8
Training loss: 4.3405945658045955
Validation loss: 3.6320328176467753

Epoch: 6| Step: 9
Training loss: 3.6103564492714426
Validation loss: 3.627881111320314

Epoch: 6| Step: 10
Training loss: 4.011604166298134
Validation loss: 3.62275954285929

Epoch: 6| Step: 11
Training loss: 3.6752799621651913
Validation loss: 3.620140447816015

Epoch: 6| Step: 12
Training loss: 4.555946974233924
Validation loss: 3.61818030662057

Epoch: 6| Step: 13
Training loss: 3.2291372154287425
Validation loss: 3.611806808066522

Epoch: 12| Step: 0
Training loss: 3.6715470837204407
Validation loss: 3.6104331200173774

Epoch: 6| Step: 1
Training loss: 3.8310348973090043
Validation loss: 3.6189239833614693

Epoch: 6| Step: 2
Training loss: 3.6134235086015933
Validation loss: 3.6039876832371323

Epoch: 6| Step: 3
Training loss: 4.640222808158094
Validation loss: 3.604454735098135

Epoch: 6| Step: 4
Training loss: 3.9885844415240816
Validation loss: 3.6052742675871596

Epoch: 6| Step: 5
Training loss: 3.9303880677560556
Validation loss: 3.599717707487156

Epoch: 6| Step: 6
Training loss: 4.321495073655743
Validation loss: 3.5952054180189563

Epoch: 6| Step: 7
Training loss: 3.0638732945112688
Validation loss: 3.589906424982068

Epoch: 6| Step: 8
Training loss: 3.680172639197362
Validation loss: 3.585226472241937

Epoch: 6| Step: 9
Training loss: 3.697367381102706
Validation loss: 3.5817576409331715

Epoch: 6| Step: 10
Training loss: 3.776848998307725
Validation loss: 3.576308837041434

Epoch: 6| Step: 11
Training loss: 3.8623077739794875
Validation loss: 3.5741317224691636

Epoch: 6| Step: 12
Training loss: 3.342509387166459
Validation loss: 3.5706135975211155

Epoch: 6| Step: 13
Training loss: 3.150432550916387
Validation loss: 3.5683881956936605

Epoch: 13| Step: 0
Training loss: 3.7904649164498165
Validation loss: 3.564192143538073

Epoch: 6| Step: 1
Training loss: 4.0118908571285585
Validation loss: 3.5575413198399586

Epoch: 6| Step: 2
Training loss: 3.1791279368376695
Validation loss: 3.5558257954156414

Epoch: 6| Step: 3
Training loss: 4.031969819379809
Validation loss: 3.557949240264137

Epoch: 6| Step: 4
Training loss: 3.860223962482921
Validation loss: 3.551553610855849

Epoch: 6| Step: 5
Training loss: 4.5412310936783875
Validation loss: 3.55139006639427

Epoch: 6| Step: 6
Training loss: 3.4547345997167396
Validation loss: 3.550010302614049

Epoch: 6| Step: 7
Training loss: 3.208356948039023
Validation loss: 3.549191064452972

Epoch: 6| Step: 8
Training loss: 3.2568240781736852
Validation loss: 3.546269769074723

Epoch: 6| Step: 9
Training loss: 3.812943229550808
Validation loss: 3.5430921683733256

Epoch: 6| Step: 10
Training loss: 2.9361887501011754
Validation loss: 3.538973412672237

Epoch: 6| Step: 11
Training loss: 4.054652689819264
Validation loss: 3.5346104238299825

Epoch: 6| Step: 12
Training loss: 4.301623574629423
Validation loss: 3.5287662519006804

Epoch: 6| Step: 13
Training loss: 3.7606785366919424
Validation loss: 3.5278900856816104

Epoch: 14| Step: 0
Training loss: 3.6660304529035503
Validation loss: 3.5214634900739834

Epoch: 6| Step: 1
Training loss: 3.393984207305402
Validation loss: 3.522040479412937

Epoch: 6| Step: 2
Training loss: 3.9328863574228574
Validation loss: 3.516145557070456

Epoch: 6| Step: 3
Training loss: 3.848643096004087
Validation loss: 3.515783945954695

Epoch: 6| Step: 4
Training loss: 3.733529861136646
Validation loss: 3.5106789521463426

Epoch: 6| Step: 5
Training loss: 3.2730865654574473
Validation loss: 3.5088180437090957

Epoch: 6| Step: 6
Training loss: 3.443681187989347
Validation loss: 3.5074325462814975

Epoch: 6| Step: 7
Training loss: 3.255054504828873
Validation loss: 3.508076909936443

Epoch: 6| Step: 8
Training loss: 3.925024705553964
Validation loss: 3.5018514403567615

Epoch: 6| Step: 9
Training loss: 3.8733088587011206
Validation loss: 3.4997543360080763

Epoch: 6| Step: 10
Training loss: 3.1477446823214565
Validation loss: 3.495799032403804

Epoch: 6| Step: 11
Training loss: 3.8873294216400844
Validation loss: 3.491733499949964

Epoch: 6| Step: 12
Training loss: 4.522058464499066
Validation loss: 3.489685780480442

Epoch: 6| Step: 13
Training loss: 4.072177101106169
Validation loss: 3.485608020725457

Epoch: 15| Step: 0
Training loss: 3.706581530610976
Validation loss: 3.48853059824235

Epoch: 6| Step: 1
Training loss: 3.84876637201646
Validation loss: 3.4894313087952806

Epoch: 6| Step: 2
Training loss: 3.8147023828090676
Validation loss: 3.4840484235070543

Epoch: 6| Step: 3
Training loss: 3.9282206837025035
Validation loss: 3.4779836392007253

Epoch: 6| Step: 4
Training loss: 3.556998572648743
Validation loss: 3.4759104651061112

Epoch: 6| Step: 5
Training loss: 4.249856834244215
Validation loss: 3.4699415935227464

Epoch: 6| Step: 6
Training loss: 4.071592045611725
Validation loss: 3.470317004388239

Epoch: 6| Step: 7
Training loss: 2.989261481386592
Validation loss: 3.464099335754344

Epoch: 6| Step: 8
Training loss: 3.3117309253322134
Validation loss: 3.460343300286128

Epoch: 6| Step: 9
Training loss: 3.3408136041568866
Validation loss: 3.4591199827995065

Epoch: 6| Step: 10
Training loss: 3.680038921316233
Validation loss: 3.45998228405859

Epoch: 6| Step: 11
Training loss: 3.6708873962739648
Validation loss: 3.454907069329378

Epoch: 6| Step: 12
Training loss: 3.795023023010298
Validation loss: 3.4527412379111935

Epoch: 6| Step: 13
Training loss: 3.330362203792144
Validation loss: 3.446314973383652

Epoch: 16| Step: 0
Training loss: 3.4778751252687163
Validation loss: 3.4481284491607016

Epoch: 6| Step: 1
Training loss: 4.0847542035826985
Validation loss: 3.448968670640371

Epoch: 6| Step: 2
Training loss: 4.243060786106502
Validation loss: 3.441118371600255

Epoch: 6| Step: 3
Training loss: 3.9153918903981384
Validation loss: 3.4396090767181264

Epoch: 6| Step: 4
Training loss: 3.679598732300781
Validation loss: 3.4382125071321132

Epoch: 6| Step: 5
Training loss: 2.7189470417046526
Validation loss: 3.439577853250994

Epoch: 6| Step: 6
Training loss: 3.275046014826503
Validation loss: 3.4352453950293893

Epoch: 6| Step: 7
Training loss: 4.072208014430619
Validation loss: 3.43217039739772

Epoch: 6| Step: 8
Training loss: 2.8967215916116418
Validation loss: 3.426589959231163

Epoch: 6| Step: 9
Training loss: 3.8802979461084854
Validation loss: 3.428120418995004

Epoch: 6| Step: 10
Training loss: 3.3032415306302045
Validation loss: 3.4188821069280566

Epoch: 6| Step: 11
Training loss: 4.037078192912959
Validation loss: 3.41573121995957

Epoch: 6| Step: 12
Training loss: 3.8647243477455953
Validation loss: 3.4155067893169186

Epoch: 6| Step: 13
Training loss: 3.1034971876418984
Validation loss: 3.4180650068051306

Epoch: 17| Step: 0
Training loss: 3.6523908805866174
Validation loss: 3.4174520643815964

Epoch: 6| Step: 1
Training loss: 3.773647263029692
Validation loss: 3.415871183671328

Epoch: 6| Step: 2
Training loss: 3.840159902819625
Validation loss: 3.4098819284552433

Epoch: 6| Step: 3
Training loss: 3.8618077321328332
Validation loss: 3.408402519106553

Epoch: 6| Step: 4
Training loss: 3.1857556824862847
Validation loss: 3.4056593221090123

Epoch: 6| Step: 5
Training loss: 2.7757595603604384
Validation loss: 3.40438982621613

Epoch: 6| Step: 6
Training loss: 3.6297992638185486
Validation loss: 3.40427624259291

Epoch: 6| Step: 7
Training loss: 4.51678916417821
Validation loss: 3.4000592262483003

Epoch: 6| Step: 8
Training loss: 3.3863460419286797
Validation loss: 3.395644712591746

Epoch: 6| Step: 9
Training loss: 3.6868523497725585
Validation loss: 3.393474459906366

Epoch: 6| Step: 10
Training loss: 3.3870217298875525
Validation loss: 3.3932928692055717

Epoch: 6| Step: 11
Training loss: 3.8730248370291442
Validation loss: 3.392878431231353

Epoch: 6| Step: 12
Training loss: 2.9877121726313023
Validation loss: 3.3900418873411327

Epoch: 6| Step: 13
Training loss: 4.154170613237583
Validation loss: 3.388383078325408

Epoch: 18| Step: 0
Training loss: 3.808193463540096
Validation loss: 3.3834420815951907

Epoch: 6| Step: 1
Training loss: 3.2031422684366837
Validation loss: 3.381328329271922

Epoch: 6| Step: 2
Training loss: 4.844246918815061
Validation loss: 3.379776836272308

Epoch: 6| Step: 3
Training loss: 2.6317187111531863
Validation loss: 3.3870032826425382

Epoch: 6| Step: 4
Training loss: 2.0108372803370154
Validation loss: 3.378802598279466

Epoch: 6| Step: 5
Training loss: 3.7160221641544746
Validation loss: 3.378226219048771

Epoch: 6| Step: 6
Training loss: 3.982886900418268
Validation loss: 3.3751426250381913

Epoch: 6| Step: 7
Training loss: 3.2369644193346603
Validation loss: 3.3766948739013825

Epoch: 6| Step: 8
Training loss: 3.9825713020642066
Validation loss: 3.374686735161747

Epoch: 6| Step: 9
Training loss: 3.3769649860621658
Validation loss: 3.3764150380801556

Epoch: 6| Step: 10
Training loss: 3.488117209888721
Validation loss: 3.370810041964827

Epoch: 6| Step: 11
Training loss: 3.379448114065973
Validation loss: 3.366669820166538

Epoch: 6| Step: 12
Training loss: 3.898076776545989
Validation loss: 3.366510181167112

Epoch: 6| Step: 13
Training loss: 4.434496870778943
Validation loss: 3.365420711061875

Epoch: 19| Step: 0
Training loss: 4.099946435718013
Validation loss: 3.3644409230823578

Epoch: 6| Step: 1
Training loss: 4.372877205423328
Validation loss: 3.362087548671694

Epoch: 6| Step: 2
Training loss: 2.911380464243821
Validation loss: 3.3634866151055824

Epoch: 6| Step: 3
Training loss: 3.8680844278283413
Validation loss: 3.3601220977395205

Epoch: 6| Step: 4
Training loss: 3.1154419258838204
Validation loss: 3.356474976691056

Epoch: 6| Step: 5
Training loss: 3.518317111610544
Validation loss: 3.35490294344505

Epoch: 6| Step: 6
Training loss: 3.074534534488069
Validation loss: 3.3519506122901737

Epoch: 6| Step: 7
Training loss: 3.8130997983296324
Validation loss: 3.3537821706339006

Epoch: 6| Step: 8
Training loss: 3.523727100591554
Validation loss: 3.349625784173262

Epoch: 6| Step: 9
Training loss: 3.117362187206611
Validation loss: 3.348777087217193

Epoch: 6| Step: 10
Training loss: 3.175713682687591
Validation loss: 3.34785995010115

Epoch: 6| Step: 11
Training loss: 3.9122082244984733
Validation loss: 3.346442519258049

Epoch: 6| Step: 12
Training loss: 3.493045846476037
Validation loss: 3.344532830987285

Epoch: 6| Step: 13
Training loss: 4.127655561670695
Validation loss: 3.3437797124150355

Epoch: 20| Step: 0
Training loss: 3.8633575277637844
Validation loss: 3.340358381447456

Epoch: 6| Step: 1
Training loss: 3.6187424417525507
Validation loss: 3.3385886654436376

Epoch: 6| Step: 2
Training loss: 3.4001973824147154
Validation loss: 3.3363050340148073

Epoch: 6| Step: 3
Training loss: 3.4971500782843083
Validation loss: 3.3343225416201494

Epoch: 6| Step: 4
Training loss: 4.424912342992125
Validation loss: 3.332117894805671

Epoch: 6| Step: 5
Training loss: 3.795408365947812
Validation loss: 3.330260847077429

Epoch: 6| Step: 6
Training loss: 3.9266837377992103
Validation loss: 3.338926866349161

Epoch: 6| Step: 7
Training loss: 3.4685237226484693
Validation loss: 3.3337916748710428

Epoch: 6| Step: 8
Training loss: 3.6238138297052847
Validation loss: 3.337089328772135

Epoch: 6| Step: 9
Training loss: 3.0581023112534593
Validation loss: 3.3484236032712866

Epoch: 6| Step: 10
Training loss: 2.4954516043016386
Validation loss: 3.339124861714877

Epoch: 6| Step: 11
Training loss: 4.080887951061167
Validation loss: 3.343869867745693

Epoch: 6| Step: 12
Training loss: 3.1820683294281116
Validation loss: 3.343866068133055

Epoch: 6| Step: 13
Training loss: 2.891490085131635
Validation loss: 3.343591662738678

Epoch: 21| Step: 0
Training loss: 3.0975474161701486
Validation loss: 3.3414007518735476

Epoch: 6| Step: 1
Training loss: 3.0525450547101114
Validation loss: 3.3386558881891855

Epoch: 6| Step: 2
Training loss: 4.2571839594845535
Validation loss: 3.3316673196722206

Epoch: 6| Step: 3
Training loss: 3.278011213133313
Validation loss: 3.326380781252213

Epoch: 6| Step: 4
Training loss: 3.8308905129476596
Validation loss: 3.323540585429016

Epoch: 6| Step: 5
Training loss: 3.78225795458022
Validation loss: 3.3217994390013907

Epoch: 6| Step: 6
Training loss: 4.01063839518275
Validation loss: 3.319894734593136

Epoch: 6| Step: 7
Training loss: 3.3331092441257257
Validation loss: 3.320514085936866

Epoch: 6| Step: 8
Training loss: 3.3262457041406255
Validation loss: 3.318771554858246

Epoch: 6| Step: 9
Training loss: 3.8301319077687395
Validation loss: 3.315806763902437

Epoch: 6| Step: 10
Training loss: 4.175234238683618
Validation loss: 3.312835073521432

Epoch: 6| Step: 11
Training loss: 3.706968992331528
Validation loss: 3.307049411114219

Epoch: 6| Step: 12
Training loss: 2.2237022901695216
Validation loss: 3.305691371889802

Epoch: 6| Step: 13
Training loss: 3.345576135259643
Validation loss: 3.3043453803875513

Epoch: 22| Step: 0
Training loss: 2.903128968267942
Validation loss: 3.3034482535060743

Epoch: 6| Step: 1
Training loss: 4.207844520104218
Validation loss: 3.3026650099121015

Epoch: 6| Step: 2
Training loss: 3.18309869017964
Validation loss: 3.300083184397952

Epoch: 6| Step: 3
Training loss: 2.627697875233117
Validation loss: 3.300173467649154

Epoch: 6| Step: 4
Training loss: 3.240641691924526
Validation loss: 3.2963461261932268

Epoch: 6| Step: 5
Training loss: 4.218781421685646
Validation loss: 3.297279642950637

Epoch: 6| Step: 6
Training loss: 3.155794922909121
Validation loss: 3.2944506181948676

Epoch: 6| Step: 7
Training loss: 3.534511444129392
Validation loss: 3.29238249437142

Epoch: 6| Step: 8
Training loss: 3.6325096742484115
Validation loss: 3.2917902731023645

Epoch: 6| Step: 9
Training loss: 3.244505859981094
Validation loss: 3.290963365825088

Epoch: 6| Step: 10
Training loss: 3.894950943565683
Validation loss: 3.290569381618569

Epoch: 6| Step: 11
Training loss: 3.9659133746160538
Validation loss: 3.2896148005139896

Epoch: 6| Step: 12
Training loss: 3.591786785433083
Validation loss: 3.28913727902491

Epoch: 6| Step: 13
Training loss: 3.9279825140725073
Validation loss: 3.285558019725987

Epoch: 23| Step: 0
Training loss: 2.81518003142143
Validation loss: 3.2870925055615636

Epoch: 6| Step: 1
Training loss: 3.2451333508474987
Validation loss: 3.285969309224027

Epoch: 6| Step: 2
Training loss: 3.5483907410107913
Validation loss: 3.2845841523528483

Epoch: 6| Step: 3
Training loss: 4.221323768212893
Validation loss: 3.2857315577916277

Epoch: 6| Step: 4
Training loss: 3.6064059113065645
Validation loss: 3.2849721818593527

Epoch: 6| Step: 5
Training loss: 3.4637481092532507
Validation loss: 3.2832221304742544

Epoch: 6| Step: 6
Training loss: 3.216348585566706
Validation loss: 3.2786730763755454

Epoch: 6| Step: 7
Training loss: 3.33693478259407
Validation loss: 3.2780620974680073

Epoch: 6| Step: 8
Training loss: 4.319725727982071
Validation loss: 3.276404845729488

Epoch: 6| Step: 9
Training loss: 3.9468920878737377
Validation loss: 3.2729358304832545

Epoch: 6| Step: 10
Training loss: 3.083409454505798
Validation loss: 3.2724943602383068

Epoch: 6| Step: 11
Training loss: 3.510528804146351
Validation loss: 3.2712132850011764

Epoch: 6| Step: 12
Training loss: 2.3931221479716207
Validation loss: 3.26777143866248

Epoch: 6| Step: 13
Training loss: 4.515296369691844
Validation loss: 3.2685055485659795

Epoch: 24| Step: 0
Training loss: 3.0715092081276256
Validation loss: 3.266863888263161

Epoch: 6| Step: 1
Training loss: 3.856421448591966
Validation loss: 3.264150570936603

Epoch: 6| Step: 2
Training loss: 3.1680149587701916
Validation loss: 3.263566952998919

Epoch: 6| Step: 3
Training loss: 3.3796225080797324
Validation loss: 3.263272474686936

Epoch: 6| Step: 4
Training loss: 4.24457517980672
Validation loss: 3.2607361949726075

Epoch: 6| Step: 5
Training loss: 3.917484941970913
Validation loss: 3.2581196553590073

Epoch: 6| Step: 6
Training loss: 3.4737446884658247
Validation loss: 3.256259997919385

Epoch: 6| Step: 7
Training loss: 3.171782393583471
Validation loss: 3.258080976893997

Epoch: 6| Step: 8
Training loss: 3.3396822706302776
Validation loss: 3.2554823588878823

Epoch: 6| Step: 9
Training loss: 3.1677808976363386
Validation loss: 3.2552222487941815

Epoch: 6| Step: 10
Training loss: 2.627378748338206
Validation loss: 3.252647990283056

Epoch: 6| Step: 11
Training loss: 3.785260304377945
Validation loss: 3.252060379870477

Epoch: 6| Step: 12
Training loss: 4.399196742169911
Validation loss: 3.2503671509726924

Epoch: 6| Step: 13
Training loss: 2.7141810644382995
Validation loss: 3.2490646208936775

Epoch: 25| Step: 0
Training loss: 3.746175214182001
Validation loss: 3.2481084419467168

Epoch: 6| Step: 1
Training loss: 3.0001026771776327
Validation loss: 3.2472678628183784

Epoch: 6| Step: 2
Training loss: 3.122698432230885
Validation loss: 3.2443666518361423

Epoch: 6| Step: 3
Training loss: 3.865143576813773
Validation loss: 3.243293218826737

Epoch: 6| Step: 4
Training loss: 2.4524854081368197
Validation loss: 3.243911538207672

Epoch: 6| Step: 5
Training loss: 3.7064652327364915
Validation loss: 3.244270438620397

Epoch: 6| Step: 6
Training loss: 3.6235230166405765
Validation loss: 3.2424675095197175

Epoch: 6| Step: 7
Training loss: 4.768688780465394
Validation loss: 3.240341281977271

Epoch: 6| Step: 8
Training loss: 2.9625424989637708
Validation loss: 3.241012382028383

Epoch: 6| Step: 9
Training loss: 2.728166518272321
Validation loss: 3.2414724123534815

Epoch: 6| Step: 10
Training loss: 3.605972866470393
Validation loss: 3.2405785227378714

Epoch: 6| Step: 11
Training loss: 3.482437895407976
Validation loss: 3.239314375394078

Epoch: 6| Step: 12
Training loss: 4.1414996680830996
Validation loss: 3.236619594244307

Epoch: 6| Step: 13
Training loss: 2.651816044533521
Validation loss: 3.2351917458043764

Epoch: 26| Step: 0
Training loss: 3.662054947512207
Validation loss: 3.2352598284949248

Epoch: 6| Step: 1
Training loss: 3.552348480322134
Validation loss: 3.2346182786131537

Epoch: 6| Step: 2
Training loss: 3.1632718075502746
Validation loss: 3.2360789589221586

Epoch: 6| Step: 3
Training loss: 4.136783300369836
Validation loss: 3.231577674108206

Epoch: 6| Step: 4
Training loss: 2.9710989242616987
Validation loss: 3.2331953758448955

Epoch: 6| Step: 5
Training loss: 3.7085824661292155
Validation loss: 3.2327633968681497

Epoch: 6| Step: 6
Training loss: 3.600364105037541
Validation loss: 3.235669898974714

Epoch: 6| Step: 7
Training loss: 3.8305630141097953
Validation loss: 3.2354427693608137

Epoch: 6| Step: 8
Training loss: 2.957652985331549
Validation loss: 3.236562589796105

Epoch: 6| Step: 9
Training loss: 3.3223195909785095
Validation loss: 3.234492006504389

Epoch: 6| Step: 10
Training loss: 2.9607634078004637
Validation loss: 3.2337415797322

Epoch: 6| Step: 11
Training loss: 3.7032115298434714
Validation loss: 3.230908007244113

Epoch: 6| Step: 12
Training loss: 3.782155582659237
Validation loss: 3.22835060364253

Epoch: 6| Step: 13
Training loss: 3.026629042398577
Validation loss: 3.230742754178461

Epoch: 27| Step: 0
Training loss: 3.417090567987495
Validation loss: 3.2316889814197367

Epoch: 6| Step: 1
Training loss: 3.3639719184129784
Validation loss: 3.2343006368225447

Epoch: 6| Step: 2
Training loss: 3.3248171419041395
Validation loss: 3.232914813828373

Epoch: 6| Step: 3
Training loss: 3.697403749524727
Validation loss: 3.2325639688109367

Epoch: 6| Step: 4
Training loss: 3.6871068712580226
Validation loss: 3.231734779643799

Epoch: 6| Step: 5
Training loss: 3.9303334730931927
Validation loss: 3.230038565199695

Epoch: 6| Step: 6
Training loss: 3.5051268766025494
Validation loss: 3.2290814428499024

Epoch: 6| Step: 7
Training loss: 3.0533425572796
Validation loss: 3.2257630325287083

Epoch: 6| Step: 8
Training loss: 3.428041241160706
Validation loss: 3.2265579313781028

Epoch: 6| Step: 9
Training loss: 3.146870187492441
Validation loss: 3.224336134473942

Epoch: 6| Step: 10
Training loss: 3.813572216910133
Validation loss: 3.2257069727212535

Epoch: 6| Step: 11
Training loss: 3.105142751413022
Validation loss: 3.222884715842126

Epoch: 6| Step: 12
Training loss: 3.8052990557011825
Validation loss: 3.222523959500128

Epoch: 6| Step: 13
Training loss: 3.258362355472913
Validation loss: 3.220269444791452

Epoch: 28| Step: 0
Training loss: 3.0931846024942353
Validation loss: 3.2194185137182583

Epoch: 6| Step: 1
Training loss: 3.4242615063709243
Validation loss: 3.2169110510461585

Epoch: 6| Step: 2
Training loss: 3.486528629125805
Validation loss: 3.216567026714315

Epoch: 6| Step: 3
Training loss: 4.025321445305593
Validation loss: 3.217266323433201

Epoch: 6| Step: 4
Training loss: 3.3450964952814353
Validation loss: 3.21531889103138

Epoch: 6| Step: 5
Training loss: 3.4339970166343923
Validation loss: 3.2143444428659325

Epoch: 6| Step: 6
Training loss: 3.9744184968370515
Validation loss: 3.2134216518065766

Epoch: 6| Step: 7
Training loss: 2.8490341892406983
Validation loss: 3.213732226621484

Epoch: 6| Step: 8
Training loss: 3.4832010387017833
Validation loss: 3.2113218629096276

Epoch: 6| Step: 9
Training loss: 3.927062475552133
Validation loss: 3.2102304088300118

Epoch: 6| Step: 10
Training loss: 2.4013838672407704
Validation loss: 3.2098175092357053

Epoch: 6| Step: 11
Training loss: 3.4219917730325053
Validation loss: 3.211074860095884

Epoch: 6| Step: 12
Training loss: 3.792081467851882
Validation loss: 3.2141857431494096

Epoch: 6| Step: 13
Training loss: 3.690119184931433
Validation loss: 3.2094896952345655

Epoch: 29| Step: 0
Training loss: 3.681212415001388
Validation loss: 3.210649358914133

Epoch: 6| Step: 1
Training loss: 2.9816799277672965
Validation loss: 3.208117800758889

Epoch: 6| Step: 2
Training loss: 3.7892927906016016
Validation loss: 3.208176598771017

Epoch: 6| Step: 3
Training loss: 3.6277405475174955
Validation loss: 3.2088416652650067

Epoch: 6| Step: 4
Training loss: 3.756973014216794
Validation loss: 3.207538193506705

Epoch: 6| Step: 5
Training loss: 2.4788649773490556
Validation loss: 3.207510352140498

Epoch: 6| Step: 6
Training loss: 3.026359782128323
Validation loss: 3.205484805872512

Epoch: 6| Step: 7
Training loss: 3.85731482248604
Validation loss: 3.2052544383360906

Epoch: 6| Step: 8
Training loss: 3.5514510292050763
Validation loss: 3.2048367540290457

Epoch: 6| Step: 9
Training loss: 4.149030107890474
Validation loss: 3.205135638219703

Epoch: 6| Step: 10
Training loss: 2.5396064997162218
Validation loss: 3.203310015377572

Epoch: 6| Step: 11
Training loss: 3.2453497850078934
Validation loss: 3.2023308506579786

Epoch: 6| Step: 12
Training loss: 3.4523570039541776
Validation loss: 3.2003597894286973

Epoch: 6| Step: 13
Training loss: 4.153866651000833
Validation loss: 3.201031732167209

Epoch: 30| Step: 0
Training loss: 3.808225768481058
Validation loss: 3.2002381896899053

Epoch: 6| Step: 1
Training loss: 3.1505170064835535
Validation loss: 3.198936402163505

Epoch: 6| Step: 2
Training loss: 3.8289790232400853
Validation loss: 3.2001002923441098

Epoch: 6| Step: 3
Training loss: 2.8027251027448976
Validation loss: 3.1974219253186598

Epoch: 6| Step: 4
Training loss: 3.5378674643163723
Validation loss: 3.1977231797314007

Epoch: 6| Step: 5
Training loss: 3.2778154108793025
Validation loss: 3.195932632556954

Epoch: 6| Step: 6
Training loss: 3.39420056241315
Validation loss: 3.196644333138609

Epoch: 6| Step: 7
Training loss: 3.925937691223728
Validation loss: 3.1976528667512034

Epoch: 6| Step: 8
Training loss: 3.7969238529280624
Validation loss: 3.193530621276708

Epoch: 6| Step: 9
Training loss: 4.000001192092718
Validation loss: 3.1954822151721882

Epoch: 6| Step: 10
Training loss: 3.181366648156103
Validation loss: 3.1946574919571944

Epoch: 6| Step: 11
Training loss: 3.10708196232698
Validation loss: 3.1925703173881113

Epoch: 6| Step: 12
Training loss: 2.9423303051861622
Validation loss: 3.19161487495449

Epoch: 6| Step: 13
Training loss: 3.2606162760674335
Validation loss: 3.192754726310056

Epoch: 31| Step: 0
Training loss: 2.9436496725621732
Validation loss: 3.190500649011837

Epoch: 6| Step: 1
Training loss: 2.696999196257169
Validation loss: 3.1908685272341026

Epoch: 6| Step: 2
Training loss: 3.403150635790007
Validation loss: 3.18787004356489

Epoch: 6| Step: 3
Training loss: 4.101857783269664
Validation loss: 3.187691946762934

Epoch: 6| Step: 4
Training loss: 2.7944195587216347
Validation loss: 3.1848342641770206

Epoch: 6| Step: 5
Training loss: 2.905846680578704
Validation loss: 3.1853483732790258

Epoch: 6| Step: 6
Training loss: 3.5925346641487472
Validation loss: 3.1843574534471797

Epoch: 6| Step: 7
Training loss: 3.53689987430026
Validation loss: 3.183101723282592

Epoch: 6| Step: 8
Training loss: 3.1787746909409296
Validation loss: 3.18072177779022

Epoch: 6| Step: 9
Training loss: 3.802576376243871
Validation loss: 3.1795600236076087

Epoch: 6| Step: 10
Training loss: 4.170279094037708
Validation loss: 3.1777010358367757

Epoch: 6| Step: 11
Training loss: 3.6553007018335983
Validation loss: 3.177222212982513

Epoch: 6| Step: 12
Training loss: 3.1576491172536683
Validation loss: 3.1731811053747156

Epoch: 6| Step: 13
Training loss: 4.1252473699206345
Validation loss: 3.1738743292361593

Epoch: 32| Step: 0
Training loss: 3.696186115640369
Validation loss: 3.171579262006529

Epoch: 6| Step: 1
Training loss: 3.1272587052045027
Validation loss: 3.184856564505899

Epoch: 6| Step: 2
Training loss: 2.9653844126800526
Validation loss: 3.180733231741247

Epoch: 6| Step: 3
Training loss: 3.0079976606968652
Validation loss: 3.176386204810339

Epoch: 6| Step: 4
Training loss: 3.1478398136744046
Validation loss: 3.1722942701376566

Epoch: 6| Step: 5
Training loss: 3.169187713427441
Validation loss: 3.1699658786083345

Epoch: 6| Step: 6
Training loss: 3.069635292284202
Validation loss: 3.167423825397638

Epoch: 6| Step: 7
Training loss: 3.909514261108725
Validation loss: 3.1685495661608836

Epoch: 6| Step: 8
Training loss: 4.229970520493972
Validation loss: 3.1669972354601197

Epoch: 6| Step: 9
Training loss: 2.948483487868783
Validation loss: 3.169832888157555

Epoch: 6| Step: 10
Training loss: 3.7274271283871565
Validation loss: 3.1714964634245972

Epoch: 6| Step: 11
Training loss: 3.3510546888660286
Validation loss: 3.170037048717009

Epoch: 6| Step: 12
Training loss: 4.129804645194577
Validation loss: 3.1691054736338957

Epoch: 6| Step: 13
Training loss: 3.0108587518993915
Validation loss: 3.161753160660332

Epoch: 33| Step: 0
Training loss: 3.3922624281906417
Validation loss: 3.1648746972810677

Epoch: 6| Step: 1
Training loss: 3.2539340930493936
Validation loss: 3.1695871718618895

Epoch: 6| Step: 2
Training loss: 2.644702629723105
Validation loss: 3.1713259173359547

Epoch: 6| Step: 3
Training loss: 3.882691041823612
Validation loss: 3.1674567879220787

Epoch: 6| Step: 4
Training loss: 3.090508506438567
Validation loss: 3.159510662057018

Epoch: 6| Step: 5
Training loss: 3.7425166166518924
Validation loss: 3.162775410025864

Epoch: 6| Step: 6
Training loss: 3.42126347899787
Validation loss: 3.1615389186391525

Epoch: 6| Step: 7
Training loss: 3.4873980763626022
Validation loss: 3.1583459344826204

Epoch: 6| Step: 8
Training loss: 3.8007988140331577
Validation loss: 3.1577130523676407

Epoch: 6| Step: 9
Training loss: 3.5228161316792606
Validation loss: 3.158359095416705

Epoch: 6| Step: 10
Training loss: 4.198286142804613
Validation loss: 3.158455095361007

Epoch: 6| Step: 11
Training loss: 3.2011901966662233
Validation loss: 3.1588014361669576

Epoch: 6| Step: 12
Training loss: 3.048967943522838
Validation loss: 3.1580970401302717

Epoch: 6| Step: 13
Training loss: 2.464747504094821
Validation loss: 3.154122227408959

Epoch: 34| Step: 0
Training loss: 2.889424502612731
Validation loss: 3.1550239123609356

Epoch: 6| Step: 1
Training loss: 3.044425879914546
Validation loss: 3.1537323272060207

Epoch: 6| Step: 2
Training loss: 3.0385817120493535
Validation loss: 3.1527364760444345

Epoch: 6| Step: 3
Training loss: 3.0080975286012834
Validation loss: 3.154076076825777

Epoch: 6| Step: 4
Training loss: 3.27807478088954
Validation loss: 3.1591868269751346

Epoch: 6| Step: 5
Training loss: 3.240730859246907
Validation loss: 3.149024248545414

Epoch: 6| Step: 6
Training loss: 3.8976937542042087
Validation loss: 3.1497682554853568

Epoch: 6| Step: 7
Training loss: 4.232402947581121
Validation loss: 3.1536386612621197

Epoch: 6| Step: 8
Training loss: 3.399450111800741
Validation loss: 3.1514582739004453

Epoch: 6| Step: 9
Training loss: 3.650845829404546
Validation loss: 3.15415321895911

Epoch: 6| Step: 10
Training loss: 3.7523033697468122
Validation loss: 3.152701495859601

Epoch: 6| Step: 11
Training loss: 3.8953820985527963
Validation loss: 3.15132470293281

Epoch: 6| Step: 12
Training loss: 3.057258948043267
Validation loss: 3.1509763915134124

Epoch: 6| Step: 13
Training loss: 2.8991958160850198
Validation loss: 3.15363302775512

Epoch: 35| Step: 0
Training loss: 2.867149914071593
Validation loss: 3.157593047325924

Epoch: 6| Step: 1
Training loss: 2.894003548441348
Validation loss: 3.16500980806272

Epoch: 6| Step: 2
Training loss: 2.85209621503627
Validation loss: 3.162173609079361

Epoch: 6| Step: 3
Training loss: 3.309930344508483
Validation loss: 3.1716349561581034

Epoch: 6| Step: 4
Training loss: 3.4987144834208785
Validation loss: 3.159807011967922

Epoch: 6| Step: 5
Training loss: 3.6547037098995205
Validation loss: 3.1593522102916127

Epoch: 6| Step: 6
Training loss: 3.6508462212346764
Validation loss: 3.145506451422221

Epoch: 6| Step: 7
Training loss: 3.0839724694493915
Validation loss: 3.146799154541028

Epoch: 6| Step: 8
Training loss: 3.5944534276751434
Validation loss: 3.160616579758496

Epoch: 6| Step: 9
Training loss: 4.255678982738944
Validation loss: 3.171351634266659

Epoch: 6| Step: 10
Training loss: 3.346836839987288
Validation loss: 3.142839466005839

Epoch: 6| Step: 11
Training loss: 3.815386570534785
Validation loss: 3.143210995971108

Epoch: 6| Step: 12
Training loss: 3.7664416682016757
Validation loss: 3.144184380952883

Epoch: 6| Step: 13
Training loss: 2.4764861567430163
Validation loss: 3.1461207348122016

Epoch: 36| Step: 0
Training loss: 4.303221963691721
Validation loss: 3.142171112760427

Epoch: 6| Step: 1
Training loss: 3.3818823260155875
Validation loss: 3.141852483288774

Epoch: 6| Step: 2
Training loss: 3.404172071050294
Validation loss: 3.1412198919495227

Epoch: 6| Step: 3
Training loss: 3.0492489687423796
Validation loss: 3.1405396792481373

Epoch: 6| Step: 4
Training loss: 3.154396192563744
Validation loss: 3.1405841447408136

Epoch: 6| Step: 5
Training loss: 2.417319067226815
Validation loss: 3.146014260446903

Epoch: 6| Step: 6
Training loss: 3.3354524710975397
Validation loss: 3.1532005541099535

Epoch: 6| Step: 7
Training loss: 2.8725037725969975
Validation loss: 3.1409315060600274

Epoch: 6| Step: 8
Training loss: 2.6727479991982066
Validation loss: 3.135719374371804

Epoch: 6| Step: 9
Training loss: 3.829047142601364
Validation loss: 3.134565958666708

Epoch: 6| Step: 10
Training loss: 3.399262707372784
Validation loss: 3.1327091118456036

Epoch: 6| Step: 11
Training loss: 4.277450769209134
Validation loss: 3.1338606193945457

Epoch: 6| Step: 12
Training loss: 3.260141249328957
Validation loss: 3.1314649539935955

Epoch: 6| Step: 13
Training loss: 3.9871341501615265
Validation loss: 3.1313040997718233

Epoch: 37| Step: 0
Training loss: 3.083857122384521
Validation loss: 3.129781938896035

Epoch: 6| Step: 1
Training loss: 3.8108481909315373
Validation loss: 3.130503936880774

Epoch: 6| Step: 2
Training loss: 3.406163485767009
Validation loss: 3.1303860212607866

Epoch: 6| Step: 3
Training loss: 3.316683736274794
Validation loss: 3.130005132290987

Epoch: 6| Step: 4
Training loss: 2.960419380532152
Validation loss: 3.1298150013413006

Epoch: 6| Step: 5
Training loss: 3.1342091479402305
Validation loss: 3.12669372763694

Epoch: 6| Step: 6
Training loss: 3.6302713674201876
Validation loss: 3.1293243677385107

Epoch: 6| Step: 7
Training loss: 3.6649096064850024
Validation loss: 3.129508618914768

Epoch: 6| Step: 8
Training loss: 2.813558930154936
Validation loss: 3.129225254740634

Epoch: 6| Step: 9
Training loss: 2.9877800016188827
Validation loss: 3.1276155809900112

Epoch: 6| Step: 10
Training loss: 4.096779903236385
Validation loss: 3.1259522379807434

Epoch: 6| Step: 11
Training loss: 3.811624270060054
Validation loss: 3.1231034822374544

Epoch: 6| Step: 12
Training loss: 3.4165638853911373
Validation loss: 3.1244237159221857

Epoch: 6| Step: 13
Training loss: 2.89794769672717
Validation loss: 3.1219222780901252

Epoch: 38| Step: 0
Training loss: 3.607438926470597
Validation loss: 3.1223433155736156

Epoch: 6| Step: 1
Training loss: 3.7798886961923928
Validation loss: 3.120906355347597

Epoch: 6| Step: 2
Training loss: 2.938273226649176
Validation loss: 3.1222684263384193

Epoch: 6| Step: 3
Training loss: 3.566115034232341
Validation loss: 3.1213976534348293

Epoch: 6| Step: 4
Training loss: 4.135918702881586
Validation loss: 3.123277894374463

Epoch: 6| Step: 5
Training loss: 3.3909664421614725
Validation loss: 3.1208718020594244

Epoch: 6| Step: 6
Training loss: 3.6440212142276573
Validation loss: 3.1186850469984644

Epoch: 6| Step: 7
Training loss: 2.8539677757149495
Validation loss: 3.1176659560755593

Epoch: 6| Step: 8
Training loss: 2.957125744135
Validation loss: 3.119289562332044

Epoch: 6| Step: 9
Training loss: 2.4630904211188476
Validation loss: 3.116824717185813

Epoch: 6| Step: 10
Training loss: 3.525223577456773
Validation loss: 3.1179799187510495

Epoch: 6| Step: 11
Training loss: 3.476868622407305
Validation loss: 3.116988327929839

Epoch: 6| Step: 12
Training loss: 3.333300653933233
Validation loss: 3.1165415446950275

Epoch: 6| Step: 13
Training loss: 3.4255823406033343
Validation loss: 3.1204692950979305

Epoch: 39| Step: 0
Training loss: 2.975362220319074
Validation loss: 3.1192401003501127

Epoch: 6| Step: 1
Training loss: 3.209811642073081
Validation loss: 3.125260500971286

Epoch: 6| Step: 2
Training loss: 3.8946490332145394
Validation loss: 3.118715785692512

Epoch: 6| Step: 3
Training loss: 3.7198014255560534
Validation loss: 3.1144671455321316

Epoch: 6| Step: 4
Training loss: 3.4115307671620037
Validation loss: 3.112000762717608

Epoch: 6| Step: 5
Training loss: 2.9004974859312593
Validation loss: 3.1103065609427243

Epoch: 6| Step: 6
Training loss: 3.7864768733113348
Validation loss: 3.1097157353938405

Epoch: 6| Step: 7
Training loss: 2.8077972938155558
Validation loss: 3.1084785473912184

Epoch: 6| Step: 8
Training loss: 3.0890610736849418
Validation loss: 3.1086994636325285

Epoch: 6| Step: 9
Training loss: 3.879758067109566
Validation loss: 3.1090224671122044

Epoch: 6| Step: 10
Training loss: 3.152253292634152
Validation loss: 3.107650587852335

Epoch: 6| Step: 11
Training loss: 3.6053073966806974
Validation loss: 3.1108475964535907

Epoch: 6| Step: 12
Training loss: 2.883099301345845
Validation loss: 3.1052178117737355

Epoch: 6| Step: 13
Training loss: 3.960446058254888
Validation loss: 3.1043383384375463

Epoch: 40| Step: 0
Training loss: 3.9363275629217123
Validation loss: 3.105762716929467

Epoch: 6| Step: 1
Training loss: 2.541675713528234
Validation loss: 3.104125111322323

Epoch: 6| Step: 2
Training loss: 3.6039755592321887
Validation loss: 3.1026634105066653

Epoch: 6| Step: 3
Training loss: 3.394884097743158
Validation loss: 3.102737208844934

Epoch: 6| Step: 4
Training loss: 3.665575443072673
Validation loss: 3.1016791756128588

Epoch: 6| Step: 5
Training loss: 2.842042179597332
Validation loss: 3.0995865291720155

Epoch: 6| Step: 6
Training loss: 3.217964150503511
Validation loss: 3.101798232120914

Epoch: 6| Step: 7
Training loss: 2.823531831011016
Validation loss: 3.1040724080495927

Epoch: 6| Step: 8
Training loss: 3.117973668288842
Validation loss: 3.1007576840503823

Epoch: 6| Step: 9
Training loss: 3.9984511714700086
Validation loss: 3.0998894183163923

Epoch: 6| Step: 10
Training loss: 3.5838927046774347
Validation loss: 3.1011228077450057

Epoch: 6| Step: 11
Training loss: 3.0110464174359888
Validation loss: 3.098869014840888

Epoch: 6| Step: 12
Training loss: 3.624405910875203
Validation loss: 3.1007796961303216

Epoch: 6| Step: 13
Training loss: 3.5549819321314082
Validation loss: 3.1011809443982674

Epoch: 41| Step: 0
Training loss: 3.931550147602133
Validation loss: 3.097806072958125

Epoch: 6| Step: 1
Training loss: 3.2874322688446695
Validation loss: 3.0988058122821567

Epoch: 6| Step: 2
Training loss: 3.298837086929064
Validation loss: 3.102105781193356

Epoch: 6| Step: 3
Training loss: 3.611594570433747
Validation loss: 3.096438025187434

Epoch: 6| Step: 4
Training loss: 2.753549192832522
Validation loss: 3.10024275489172

Epoch: 6| Step: 5
Training loss: 3.8182737062800167
Validation loss: 3.101139949763748

Epoch: 6| Step: 6
Training loss: 2.9092342682757537
Validation loss: 3.0959306748126805

Epoch: 6| Step: 7
Training loss: 3.635754384674343
Validation loss: 3.0944353299377267

Epoch: 6| Step: 8
Training loss: 3.4316931488759295
Validation loss: 3.0999961024698823

Epoch: 6| Step: 9
Training loss: 2.966697224091733
Validation loss: 3.102033621537501

Epoch: 6| Step: 10
Training loss: 3.7614691503949036
Validation loss: 3.1025305432934056

Epoch: 6| Step: 11
Training loss: 3.6799261902580422
Validation loss: 3.097423903158308

Epoch: 6| Step: 12
Training loss: 2.8182602281373836
Validation loss: 3.0973382953799713

Epoch: 6| Step: 13
Training loss: 2.6622789962812927
Validation loss: 3.091379106758159

Epoch: 42| Step: 0
Training loss: 2.9986858668591125
Validation loss: 3.094366427972832

Epoch: 6| Step: 1
Training loss: 3.2123947363799763
Validation loss: 3.0930345241814803

Epoch: 6| Step: 2
Training loss: 3.07948559738386
Validation loss: 3.090281503922537

Epoch: 6| Step: 3
Training loss: 3.0259387490678575
Validation loss: 3.0954855381285094

Epoch: 6| Step: 4
Training loss: 3.736056791065861
Validation loss: 3.1001687962877575

Epoch: 6| Step: 5
Training loss: 3.6730814798167826
Validation loss: 3.0931083782020137

Epoch: 6| Step: 6
Training loss: 3.676148869518787
Validation loss: 3.094609222969426

Epoch: 6| Step: 7
Training loss: 3.8024080878090074
Validation loss: 3.0918575716716585

Epoch: 6| Step: 8
Training loss: 3.199633523698319
Validation loss: 3.0916663086912

Epoch: 6| Step: 9
Training loss: 2.8668314117584286
Validation loss: 3.090685061548418

Epoch: 6| Step: 10
Training loss: 3.7404291724730077
Validation loss: 3.0929187773781237

Epoch: 6| Step: 11
Training loss: 3.4558293726444353
Validation loss: 3.088770721236297

Epoch: 6| Step: 12
Training loss: 3.0699628868717648
Validation loss: 3.1381325216240956

Epoch: 6| Step: 13
Training loss: 3.4188024931788212
Validation loss: 3.1000120284462085

Epoch: 43| Step: 0
Training loss: 2.8668601865283843
Validation loss: 3.090964790407965

Epoch: 6| Step: 1
Training loss: 3.6149354849264825
Validation loss: 3.087690964638184

Epoch: 6| Step: 2
Training loss: 2.7095857707652105
Validation loss: 3.085012386707536

Epoch: 6| Step: 3
Training loss: 3.822610674815815
Validation loss: 3.0882175739443243

Epoch: 6| Step: 4
Training loss: 3.966967805816893
Validation loss: 3.086829957980507

Epoch: 6| Step: 5
Training loss: 3.12678964867803
Validation loss: 3.087034787970265

Epoch: 6| Step: 6
Training loss: 2.9416351431939733
Validation loss: 3.0837885651662114

Epoch: 6| Step: 7
Training loss: 2.6588531304835965
Validation loss: 3.084586391624624

Epoch: 6| Step: 8
Training loss: 3.5021818717120943
Validation loss: 3.082863236110174

Epoch: 6| Step: 9
Training loss: 3.6635991761299223
Validation loss: 3.082143975447768

Epoch: 6| Step: 10
Training loss: 3.76626758711868
Validation loss: 3.0822403014419506

Epoch: 6| Step: 11
Training loss: 3.864784557659589
Validation loss: 3.083006052963384

Epoch: 6| Step: 12
Training loss: 3.205840657596602
Validation loss: 3.082926215843324

Epoch: 6| Step: 13
Training loss: 2.4592376166510155
Validation loss: 3.080996909132099

Epoch: 44| Step: 0
Training loss: 3.3538834509528925
Validation loss: 3.0805567722969185

Epoch: 6| Step: 1
Training loss: 3.565257694940921
Validation loss: 3.080105197238259

Epoch: 6| Step: 2
Training loss: 3.0835254368779004
Validation loss: 3.0796485346550893

Epoch: 6| Step: 3
Training loss: 2.729575604578415
Validation loss: 3.0793069032386975

Epoch: 6| Step: 4
Training loss: 3.478028132074265
Validation loss: 3.078413035831921

Epoch: 6| Step: 5
Training loss: 3.2525344649767844
Validation loss: 3.0774071427225915

Epoch: 6| Step: 6
Training loss: 3.9519849497859885
Validation loss: 3.0783209210805427

Epoch: 6| Step: 7
Training loss: 2.592469048457843
Validation loss: 3.0812753551314964

Epoch: 6| Step: 8
Training loss: 3.8826586195850123
Validation loss: 3.076785083130376

Epoch: 6| Step: 9
Training loss: 4.264361631106069
Validation loss: 3.077740450497063

Epoch: 6| Step: 10
Training loss: 3.216505731170449
Validation loss: 3.07905385117961

Epoch: 6| Step: 11
Training loss: 2.616796572511971
Validation loss: 3.077900702370276

Epoch: 6| Step: 12
Training loss: 2.5692123331157894
Validation loss: 3.075656822254299

Epoch: 6| Step: 13
Training loss: 4.067698043569265
Validation loss: 3.073998356410072

Epoch: 45| Step: 0
Training loss: 3.625119437519169
Validation loss: 3.07527228089598

Epoch: 6| Step: 1
Training loss: 3.0045668491970594
Validation loss: 3.0747113615026485

Epoch: 6| Step: 2
Training loss: 2.8566714987904986
Validation loss: 3.073055510445837

Epoch: 6| Step: 3
Training loss: 2.5758282227611002
Validation loss: 3.071284872244864

Epoch: 6| Step: 4
Training loss: 3.5854261777590217
Validation loss: 3.072585965579007

Epoch: 6| Step: 5
Training loss: 3.5959924750328893
Validation loss: 3.072348843200882

Epoch: 6| Step: 6
Training loss: 3.317350902297218
Validation loss: 3.073654847551159

Epoch: 6| Step: 7
Training loss: 3.3098692614041254
Validation loss: 3.071959786882859

Epoch: 6| Step: 8
Training loss: 2.9983946955708225
Validation loss: 3.0726901786240917

Epoch: 6| Step: 9
Training loss: 3.9505854353864565
Validation loss: 3.0705657848666092

Epoch: 6| Step: 10
Training loss: 3.0982236017909255
Validation loss: 3.0715821758583357

Epoch: 6| Step: 11
Training loss: 3.544954426933876
Validation loss: 3.071937267860066

Epoch: 6| Step: 12
Training loss: 3.519402809636119
Validation loss: 3.0720112593880406

Epoch: 6| Step: 13
Training loss: 3.7876301053806123
Validation loss: 3.071086341921871

Epoch: 46| Step: 0
Training loss: 2.5056911539891917
Validation loss: 3.071697604958042

Epoch: 6| Step: 1
Training loss: 4.2836190233558185
Validation loss: 3.0693902495155174

Epoch: 6| Step: 2
Training loss: 2.656062220499557
Validation loss: 3.0673255430184057

Epoch: 6| Step: 3
Training loss: 2.9185071496998463
Validation loss: 3.0712825984864964

Epoch: 6| Step: 4
Training loss: 3.951213389549577
Validation loss: 3.0860894951461275

Epoch: 6| Step: 5
Training loss: 4.184315623630605
Validation loss: 3.1159422604151112

Epoch: 6| Step: 6
Training loss: 3.0583720510528365
Validation loss: 3.087642328254033

Epoch: 6| Step: 7
Training loss: 3.4421147668247736
Validation loss: 3.0671005266698557

Epoch: 6| Step: 8
Training loss: 3.1118408853408157
Validation loss: 3.0660488301017845

Epoch: 6| Step: 9
Training loss: 2.5342175078463955
Validation loss: 3.075633523440874

Epoch: 6| Step: 10
Training loss: 3.4158115402336757
Validation loss: 3.1209871052452436

Epoch: 6| Step: 11
Training loss: 3.5095542202956933
Validation loss: 3.096986756498335

Epoch: 6| Step: 12
Training loss: 3.698055225337501
Validation loss: 3.0669942897735436

Epoch: 6| Step: 13
Training loss: 2.789797816863844
Validation loss: 3.0643468950408463

Epoch: 47| Step: 0
Training loss: 4.049932672388382
Validation loss: 3.073190843222652

Epoch: 6| Step: 1
Training loss: 3.4633309589435366
Validation loss: 3.062286120026682

Epoch: 6| Step: 2
Training loss: 3.5185729827532266
Validation loss: 3.0663954483342555

Epoch: 6| Step: 3
Training loss: 2.39925556955807
Validation loss: 3.0689570012166554

Epoch: 6| Step: 4
Training loss: 3.206453408375523
Validation loss: 3.079131584018132

Epoch: 6| Step: 5
Training loss: 3.245751758834996
Validation loss: 3.0820943249218287

Epoch: 6| Step: 6
Training loss: 3.888046329292904
Validation loss: 3.078875932990389

Epoch: 6| Step: 7
Training loss: 2.8246429251449703
Validation loss: 3.0727813880027424

Epoch: 6| Step: 8
Training loss: 2.8355737878531504
Validation loss: 3.067707194571786

Epoch: 6| Step: 9
Training loss: 3.0755077408079354
Validation loss: 3.0668473601999486

Epoch: 6| Step: 10
Training loss: 4.135121729764519
Validation loss: 3.0670012141995597

Epoch: 6| Step: 11
Training loss: 3.1550196903055645
Validation loss: 3.0626192971642845

Epoch: 6| Step: 12
Training loss: 2.9510020542325064
Validation loss: 3.060340159073271

Epoch: 6| Step: 13
Training loss: 3.65725120464829
Validation loss: 3.059182847353922

Epoch: 48| Step: 0
Training loss: 2.795016475758589
Validation loss: 3.0599420163926783

Epoch: 6| Step: 1
Training loss: 3.2287748201592557
Validation loss: 3.058783845818539

Epoch: 6| Step: 2
Training loss: 2.80177108745548
Validation loss: 3.059800515070247

Epoch: 6| Step: 3
Training loss: 3.061517518933673
Validation loss: 3.061444070147771

Epoch: 6| Step: 4
Training loss: 3.3507403452380573
Validation loss: 3.061034263047865

Epoch: 6| Step: 5
Training loss: 3.8403141203194053
Validation loss: 3.059326959048213

Epoch: 6| Step: 6
Training loss: 3.3067545457155347
Validation loss: 3.059284887367584

Epoch: 6| Step: 7
Training loss: 3.415862353175948
Validation loss: 3.058899213109508

Epoch: 6| Step: 8
Training loss: 4.093605097179061
Validation loss: 3.0578921327706867

Epoch: 6| Step: 9
Training loss: 2.913133897683895
Validation loss: 3.0560352046546018

Epoch: 6| Step: 10
Training loss: 3.478503013557992
Validation loss: 3.0542285713868105

Epoch: 6| Step: 11
Training loss: 3.3838023087763816
Validation loss: 3.053708736287015

Epoch: 6| Step: 12
Training loss: 3.37755629192571
Validation loss: 3.05431989057608

Epoch: 6| Step: 13
Training loss: 3.4620187418059603
Validation loss: 3.0564432479285477

Epoch: 49| Step: 0
Training loss: 3.84144399056894
Validation loss: 3.0552481401264333

Epoch: 6| Step: 1
Training loss: 3.494015754869442
Validation loss: 3.0534827996112615

Epoch: 6| Step: 2
Training loss: 2.828610541883815
Validation loss: 3.057426438905012

Epoch: 6| Step: 3
Training loss: 3.924397785614543
Validation loss: 3.053728019933411

Epoch: 6| Step: 4
Training loss: 3.2172566625526255
Validation loss: 3.05101609602043

Epoch: 6| Step: 5
Training loss: 3.7028646256860682
Validation loss: 3.0506293595775267

Epoch: 6| Step: 6
Training loss: 3.5366446549440385
Validation loss: 3.0485934266190027

Epoch: 6| Step: 7
Training loss: 3.378061248431819
Validation loss: 3.0528388004827063

Epoch: 6| Step: 8
Training loss: 3.4653240159151526
Validation loss: 3.055877348908416

Epoch: 6| Step: 9
Training loss: 2.8217228879095027
Validation loss: 3.0493839574431916

Epoch: 6| Step: 10
Training loss: 3.1869180185422374
Validation loss: 3.049212027867524

Epoch: 6| Step: 11
Training loss: 2.9248046875
Validation loss: 3.0484051240790673

Epoch: 6| Step: 12
Training loss: 2.9733420745082486
Validation loss: 3.048906221486798

Epoch: 6| Step: 13
Training loss: 2.8254254349924706
Validation loss: 3.0475952374160684

Epoch: 50| Step: 0
Training loss: 3.288300994647005
Validation loss: 3.0478054412883773

Epoch: 6| Step: 1
Training loss: 3.712022096847667
Validation loss: 3.046614387079635

Epoch: 6| Step: 2
Training loss: 1.9840538185495682
Validation loss: 3.0464233383403134

Epoch: 6| Step: 3
Training loss: 3.3409680353649116
Validation loss: 3.045246981082015

Epoch: 6| Step: 4
Training loss: 2.7320456037834258
Validation loss: 3.0440779803952953

Epoch: 6| Step: 5
Training loss: 3.0893458605454547
Validation loss: 3.042787249097832

Epoch: 6| Step: 6
Training loss: 2.5347230420626587
Validation loss: 3.041911513289643

Epoch: 6| Step: 7
Training loss: 3.616987647185511
Validation loss: 3.043250752093613

Epoch: 6| Step: 8
Training loss: 4.155321978454727
Validation loss: 3.0467359857685556

Epoch: 6| Step: 9
Training loss: 3.41926440286528
Validation loss: 3.0415123085460887

Epoch: 6| Step: 10
Training loss: 3.4094377352836887
Validation loss: 3.0446524895256184

Epoch: 6| Step: 11
Training loss: 3.67604419120485
Validation loss: 3.042018019380647

Epoch: 6| Step: 12
Training loss: 3.795306474375427
Validation loss: 3.040687967159433

Epoch: 6| Step: 13
Training loss: 3.0180374536636068
Validation loss: 3.0417470029391187

Epoch: 51| Step: 0
Training loss: 2.8641882236687985
Validation loss: 3.039600147080849

Epoch: 6| Step: 1
Training loss: 2.9910402015731514
Validation loss: 3.0397034592955294

Epoch: 6| Step: 2
Training loss: 2.963164526211701
Validation loss: 3.0402814099026223

Epoch: 6| Step: 3
Training loss: 3.0291533150219063
Validation loss: 3.0389777882243587

Epoch: 6| Step: 4
Training loss: 3.7399566945715437
Validation loss: 3.039060190323668

Epoch: 6| Step: 5
Training loss: 2.4812879276019313
Validation loss: 3.0402743352384523

Epoch: 6| Step: 6
Training loss: 3.907907363246575
Validation loss: 3.0381109511724502

Epoch: 6| Step: 7
Training loss: 3.189133767691851
Validation loss: 3.0384594917220578

Epoch: 6| Step: 8
Training loss: 3.714814483816106
Validation loss: 3.0380739297164525

Epoch: 6| Step: 9
Training loss: 2.9603209646291813
Validation loss: 3.037322720228758

Epoch: 6| Step: 10
Training loss: 2.985485569295664
Validation loss: 3.03854773367182

Epoch: 6| Step: 11
Training loss: 3.93370721193116
Validation loss: 3.0367307245110915

Epoch: 6| Step: 12
Training loss: 4.186528107320407
Validation loss: 3.03910221974717

Epoch: 6| Step: 13
Training loss: 2.742519173846337
Validation loss: 3.0336245154879893

Epoch: 52| Step: 0
Training loss: 2.480287464155353
Validation loss: 3.0338035376821018

Epoch: 6| Step: 1
Training loss: 3.3018125469158153
Validation loss: 3.034746689400308

Epoch: 6| Step: 2
Training loss: 3.3774104517452574
Validation loss: 3.0336308476293388

Epoch: 6| Step: 3
Training loss: 2.6661547725820993
Validation loss: 3.0339692789451203

Epoch: 6| Step: 4
Training loss: 3.6078572570747247
Validation loss: 3.0327684011847515

Epoch: 6| Step: 5
Training loss: 3.6966733463136423
Validation loss: 3.0363987323162576

Epoch: 6| Step: 6
Training loss: 3.1198316941959967
Validation loss: 3.030997739105199

Epoch: 6| Step: 7
Training loss: 3.6889071608350035
Validation loss: 3.045791730420839

Epoch: 6| Step: 8
Training loss: 3.599713229307573
Validation loss: 3.049790888314743

Epoch: 6| Step: 9
Training loss: 3.2817824158824593
Validation loss: 3.043826187169772

Epoch: 6| Step: 10
Training loss: 2.929966620818211
Validation loss: 3.035271093015238

Epoch: 6| Step: 11
Training loss: 3.7002201839606843
Validation loss: 3.0325413836977373

Epoch: 6| Step: 12
Training loss: 3.208581956089841
Validation loss: 3.028116196056877

Epoch: 6| Step: 13
Training loss: 3.457301449318876
Validation loss: 3.029860120051862

Epoch: 53| Step: 0
Training loss: 2.903388470703913
Validation loss: 3.0309801386457256

Epoch: 6| Step: 1
Training loss: 3.0488692579604377
Validation loss: 3.0290698639339833

Epoch: 6| Step: 2
Training loss: 2.9355897576708156
Validation loss: 3.027144975067572

Epoch: 6| Step: 3
Training loss: 3.962296171992932
Validation loss: 3.0263336505598883

Epoch: 6| Step: 4
Training loss: 3.393546537759998
Validation loss: 3.026012668248639

Epoch: 6| Step: 5
Training loss: 3.688058584546465
Validation loss: 3.0285359495493567

Epoch: 6| Step: 6
Training loss: 3.728345144699639
Validation loss: 3.025741651796088

Epoch: 6| Step: 7
Training loss: 3.3479658982922644
Validation loss: 3.02340424938487

Epoch: 6| Step: 8
Training loss: 3.366289837839111
Validation loss: 3.0268050506211863

Epoch: 6| Step: 9
Training loss: 2.635171348603165
Validation loss: 3.024017916757987

Epoch: 6| Step: 10
Training loss: 2.5961327695941976
Validation loss: 3.0246086780742627

Epoch: 6| Step: 11
Training loss: 3.6168643815336425
Validation loss: 3.024892610484294

Epoch: 6| Step: 12
Training loss: 3.123772036568961
Validation loss: 3.0224685780439584

Epoch: 6| Step: 13
Training loss: 3.8588842164854125
Validation loss: 3.0225125778032753

Epoch: 54| Step: 0
Training loss: 2.952487452881693
Validation loss: 3.0203207305967004

Epoch: 6| Step: 1
Training loss: 3.429439179417992
Validation loss: 3.0220101807768254

Epoch: 6| Step: 2
Training loss: 2.8803422470187354
Validation loss: 3.020744630206457

Epoch: 6| Step: 3
Training loss: 3.955830127196978
Validation loss: 3.019823415706389

Epoch: 6| Step: 4
Training loss: 3.502808397807812
Validation loss: 3.020118087829103

Epoch: 6| Step: 5
Training loss: 2.917811051158253
Validation loss: 3.0190900995523204

Epoch: 6| Step: 6
Training loss: 3.8719662511631587
Validation loss: 3.0199331914869108

Epoch: 6| Step: 7
Training loss: 3.5942074691846835
Validation loss: 3.018421442207622

Epoch: 6| Step: 8
Training loss: 3.1439014254251876
Validation loss: 3.0179155549152394

Epoch: 6| Step: 9
Training loss: 3.5768387660714707
Validation loss: 3.0203118538595737

Epoch: 6| Step: 10
Training loss: 2.9026146578751746
Validation loss: 3.016409425356952

Epoch: 6| Step: 11
Training loss: 3.0188309621122573
Validation loss: 3.0155367070302352

Epoch: 6| Step: 12
Training loss: 3.6335867108063806
Validation loss: 3.0174493513896317

Epoch: 6| Step: 13
Training loss: 1.5163036282231361
Validation loss: 3.0146122972153044

Epoch: 55| Step: 0
Training loss: 2.973114018527222
Validation loss: 3.014545558412105

Epoch: 6| Step: 1
Training loss: 3.1678978551041594
Validation loss: 3.0145182596914806

Epoch: 6| Step: 2
Training loss: 3.484885687246259
Validation loss: 3.0165030180831818

Epoch: 6| Step: 3
Training loss: 3.1663955940539763
Validation loss: 3.011746586526444

Epoch: 6| Step: 4
Training loss: 3.996690215252713
Validation loss: 3.0150443577603983

Epoch: 6| Step: 5
Training loss: 3.074633326804892
Validation loss: 3.0133000113850668

Epoch: 6| Step: 6
Training loss: 3.6773272353304547
Validation loss: 3.015833884049138

Epoch: 6| Step: 7
Training loss: 2.844976642693775
Validation loss: 3.011339511921401

Epoch: 6| Step: 8
Training loss: 3.257833284087628
Validation loss: 3.016550256983482

Epoch: 6| Step: 9
Training loss: 3.696905780577031
Validation loss: 3.020192797979345

Epoch: 6| Step: 10
Training loss: 3.278244822215065
Validation loss: 3.020558774109547

Epoch: 6| Step: 11
Training loss: 3.767443965502755
Validation loss: 3.0126351159877234

Epoch: 6| Step: 12
Training loss: 2.702422298757682
Validation loss: 3.010590047378566

Epoch: 6| Step: 13
Training loss: 2.2706295120274227
Validation loss: 3.013627364207591

Epoch: 56| Step: 0
Training loss: 3.0739147224982357
Validation loss: 3.0112802647999284

Epoch: 6| Step: 1
Training loss: 3.591621631124597
Validation loss: 3.0092305227070995

Epoch: 6| Step: 2
Training loss: 3.290037758097471
Validation loss: 3.009771624891316

Epoch: 6| Step: 3
Training loss: 3.386077221714829
Validation loss: 3.0150681664376484

Epoch: 6| Step: 4
Training loss: 3.495918891838801
Validation loss: 3.0204259414562933

Epoch: 6| Step: 5
Training loss: 3.855940182202092
Validation loss: 3.0233502559968595

Epoch: 6| Step: 6
Training loss: 3.562774112261399
Validation loss: 3.011444189515074

Epoch: 6| Step: 7
Training loss: 3.2662874124912116
Validation loss: 3.0083478468505462

Epoch: 6| Step: 8
Training loss: 3.034083349824398
Validation loss: 3.0138769169547555

Epoch: 6| Step: 9
Training loss: 3.1133085127609634
Validation loss: 3.0268300152273806

Epoch: 6| Step: 10
Training loss: 3.1243160262229983
Validation loss: 3.0103852422650754

Epoch: 6| Step: 11
Training loss: 3.397954516236081
Validation loss: 3.015978186832172

Epoch: 6| Step: 12
Training loss: 2.9884229439446037
Validation loss: 3.018688368524311

Epoch: 6| Step: 13
Training loss: 2.4726699418928777
Validation loss: 3.0201919270761124

Epoch: 57| Step: 0
Training loss: 3.394642080729897
Validation loss: 3.0147093531981612

Epoch: 6| Step: 1
Training loss: 3.2515671692887547
Validation loss: 3.0138106977645958

Epoch: 6| Step: 2
Training loss: 3.420914606638208
Validation loss: 3.018907427981584

Epoch: 6| Step: 3
Training loss: 3.5321791785165018
Validation loss: 3.0207297706602905

Epoch: 6| Step: 4
Training loss: 3.2366563795131187
Validation loss: 3.0219150653091953

Epoch: 6| Step: 5
Training loss: 2.73002112216254
Validation loss: 3.0212807233162167

Epoch: 6| Step: 6
Training loss: 2.8860923077049616
Validation loss: 3.021116851186512

Epoch: 6| Step: 7
Training loss: 4.00238419050121
Validation loss: 3.0195000882798584

Epoch: 6| Step: 8
Training loss: 3.0716189645453245
Validation loss: 3.0139857134019317

Epoch: 6| Step: 9
Training loss: 2.8140169079617623
Validation loss: 3.0123363093831212

Epoch: 6| Step: 10
Training loss: 3.5921487972900787
Validation loss: 3.009572114425414

Epoch: 6| Step: 11
Training loss: 2.8357219351397305
Validation loss: 3.005593329143551

Epoch: 6| Step: 12
Training loss: 3.981607111510337
Validation loss: 3.0072194842735147

Epoch: 6| Step: 13
Training loss: 2.9694919662867916
Validation loss: 3.010418098472927

Epoch: 58| Step: 0
Training loss: 3.126746338220326
Validation loss: 3.014221740539945

Epoch: 6| Step: 1
Training loss: 3.1143498327871653
Validation loss: 3.01663052164398

Epoch: 6| Step: 2
Training loss: 3.415425951463688
Validation loss: 3.0137475071319133

Epoch: 6| Step: 3
Training loss: 3.2365564923011068
Validation loss: 3.0128153955880594

Epoch: 6| Step: 4
Training loss: 3.284805696451457
Validation loss: 3.0103274181472446

Epoch: 6| Step: 5
Training loss: 3.83400713485826
Validation loss: 3.011988871420071

Epoch: 6| Step: 6
Training loss: 2.689654617684743
Validation loss: 3.0081836460266684

Epoch: 6| Step: 7
Training loss: 3.4469879989570043
Validation loss: 3.0035367715774215

Epoch: 6| Step: 8
Training loss: 3.2100822999095184
Validation loss: 3.005357424505336

Epoch: 6| Step: 9
Training loss: 3.5981834596911155
Validation loss: 3.002534522064172

Epoch: 6| Step: 10
Training loss: 3.4768813769227007
Validation loss: 3.001082127764027

Epoch: 6| Step: 11
Training loss: 3.549859089808371
Validation loss: 3.002000890038728

Epoch: 6| Step: 12
Training loss: 2.776783389019113
Validation loss: 3.0004702459284394

Epoch: 6| Step: 13
Training loss: 3.0141234143055655
Validation loss: 2.998804507080488

Epoch: 59| Step: 0
Training loss: 3.140054679443111
Validation loss: 2.999970890573904

Epoch: 6| Step: 1
Training loss: 3.51098081921081
Validation loss: 2.9988206763800016

Epoch: 6| Step: 2
Training loss: 3.2754328434406417
Validation loss: 2.997212861977238

Epoch: 6| Step: 3
Training loss: 3.631854187277689
Validation loss: 2.9977957650257965

Epoch: 6| Step: 4
Training loss: 3.601585404660424
Validation loss: 2.996605331717781

Epoch: 6| Step: 5
Training loss: 3.936494486954757
Validation loss: 2.9976465674452117

Epoch: 6| Step: 6
Training loss: 3.815463555846929
Validation loss: 2.9977289118131614

Epoch: 6| Step: 7
Training loss: 3.341202380365131
Validation loss: 2.995229848484955

Epoch: 6| Step: 8
Training loss: 2.964360736810197
Validation loss: 2.996346948221674

Epoch: 6| Step: 9
Training loss: 2.5844021298738484
Validation loss: 2.994999459197263

Epoch: 6| Step: 10
Training loss: 2.231626086769444
Validation loss: 3.0035833352714185

Epoch: 6| Step: 11
Training loss: 3.064025032090605
Validation loss: 3.0266496039421846

Epoch: 6| Step: 12
Training loss: 3.382563416647079
Validation loss: 3.0510704350203945

Epoch: 6| Step: 13
Training loss: 2.9961679143566884
Validation loss: 3.053746950865296

Epoch: 60| Step: 0
Training loss: 3.0948661563262685
Validation loss: 3.001887119318085

Epoch: 6| Step: 1
Training loss: 3.855801429811667
Validation loss: 2.9926288812215978

Epoch: 6| Step: 2
Training loss: 2.988798847126381
Validation loss: 2.993897592733873

Epoch: 6| Step: 3
Training loss: 3.682757544643605
Validation loss: 2.9956321178309

Epoch: 6| Step: 4
Training loss: 3.6386079234852455
Validation loss: 2.999406615745362

Epoch: 6| Step: 5
Training loss: 3.1194139526845626
Validation loss: 3.002039918255912

Epoch: 6| Step: 6
Training loss: 3.3699237654125622
Validation loss: 3.0054658486659167

Epoch: 6| Step: 7
Training loss: 3.205237905923574
Validation loss: 3.0019170214638264

Epoch: 6| Step: 8
Training loss: 3.4280697563400744
Validation loss: 3.002829321594563

Epoch: 6| Step: 9
Training loss: 3.2250341901519315
Validation loss: 2.9965171867169524

Epoch: 6| Step: 10
Training loss: 2.8271384019953576
Validation loss: 2.992610978860706

Epoch: 6| Step: 11
Training loss: 3.4199627275276296
Validation loss: 2.9913431391708984

Epoch: 6| Step: 12
Training loss: 2.783315170442021
Validation loss: 2.9912248800836334

Epoch: 6| Step: 13
Training loss: 3.1873881002493762
Validation loss: 2.9892969522038007

Epoch: 61| Step: 0
Training loss: 2.9008356337377
Validation loss: 2.9886201125244316

Epoch: 6| Step: 1
Training loss: 3.314890161135887
Validation loss: 2.9901360967654207

Epoch: 6| Step: 2
Training loss: 3.3784041015058115
Validation loss: 2.9888986489000042

Epoch: 6| Step: 3
Training loss: 3.595678591502059
Validation loss: 2.9896248280790956

Epoch: 6| Step: 4
Training loss: 2.99122624108475
Validation loss: 2.9955565816037564

Epoch: 6| Step: 5
Training loss: 3.633625423577955
Validation loss: 2.997397693444473

Epoch: 6| Step: 6
Training loss: 3.318382941168527
Validation loss: 2.997159185394213

Epoch: 6| Step: 7
Training loss: 3.2778917838778576
Validation loss: 3.005450469166947

Epoch: 6| Step: 8
Training loss: 3.12711110332509
Validation loss: 3.000733979653693

Epoch: 6| Step: 9
Training loss: 2.7916089996151285
Validation loss: 2.993499217307612

Epoch: 6| Step: 10
Training loss: 3.4584635208321566
Validation loss: 2.992305776731882

Epoch: 6| Step: 11
Training loss: 3.2876884145374823
Validation loss: 2.988957615767807

Epoch: 6| Step: 12
Training loss: 3.254603719892048
Validation loss: 2.9864689587666526

Epoch: 6| Step: 13
Training loss: 3.5193583692626174
Validation loss: 2.983601295509703

Epoch: 62| Step: 0
Training loss: 3.769976369242385
Validation loss: 2.9827417346558676

Epoch: 6| Step: 1
Training loss: 3.442985458108427
Validation loss: 2.9842126835781735

Epoch: 6| Step: 2
Training loss: 2.9443531042202706
Validation loss: 2.9826254861893053

Epoch: 6| Step: 3
Training loss: 2.977120574938914
Validation loss: 2.983434034737717

Epoch: 6| Step: 4
Training loss: 3.268277054191413
Validation loss: 2.980633000825938

Epoch: 6| Step: 5
Training loss: 3.3760552346108845
Validation loss: 2.982793607084547

Epoch: 6| Step: 6
Training loss: 3.7966047277134467
Validation loss: 2.982969776489881

Epoch: 6| Step: 7
Training loss: 2.661154941851796
Validation loss: 2.9809153761431757

Epoch: 6| Step: 8
Training loss: 3.6924016670042286
Validation loss: 2.9808050071405248

Epoch: 6| Step: 9
Training loss: 2.666672488047286
Validation loss: 2.9793686325372204

Epoch: 6| Step: 10
Training loss: 3.6210171095752797
Validation loss: 2.9829337422750375

Epoch: 6| Step: 11
Training loss: 2.9763979728664145
Validation loss: 2.9797592835768096

Epoch: 6| Step: 12
Training loss: 2.9937717636050003
Validation loss: 2.9874557557058243

Epoch: 6| Step: 13
Training loss: 3.278241913113423
Validation loss: 2.9803503811290875

Epoch: 63| Step: 0
Training loss: 3.180242616527171
Validation loss: 2.979591455228104

Epoch: 6| Step: 1
Training loss: 3.0904702420729877
Validation loss: 2.9801108145455677

Epoch: 6| Step: 2
Training loss: 4.011857101892571
Validation loss: 2.978525898426668

Epoch: 6| Step: 3
Training loss: 3.740484116784548
Validation loss: 2.9759868349058016

Epoch: 6| Step: 4
Training loss: 3.3326883327784342
Validation loss: 2.9776015535855884

Epoch: 6| Step: 5
Training loss: 3.011981561774042
Validation loss: 2.976575665429616

Epoch: 6| Step: 6
Training loss: 2.351959904646847
Validation loss: 2.975791889320339

Epoch: 6| Step: 7
Training loss: 3.3561310475330566
Validation loss: 2.9773206876960474

Epoch: 6| Step: 8
Training loss: 2.559119343826795
Validation loss: 2.9754619790852934

Epoch: 6| Step: 9
Training loss: 3.710494936603545
Validation loss: 2.9770516850103443

Epoch: 6| Step: 10
Training loss: 3.111034621327782
Validation loss: 2.9763672027972583

Epoch: 6| Step: 11
Training loss: 3.073136368133701
Validation loss: 2.973987551976395

Epoch: 6| Step: 12
Training loss: 3.0758401358822125
Validation loss: 2.97429015174757

Epoch: 6| Step: 13
Training loss: 3.999609212859529
Validation loss: 2.973671715597405

Epoch: 64| Step: 0
Training loss: 3.8268738239541333
Validation loss: 2.9735619519482746

Epoch: 6| Step: 1
Training loss: 2.847820680159264
Validation loss: 2.9753618351735516

Epoch: 6| Step: 2
Training loss: 3.200687876915994
Validation loss: 2.9738166996179047

Epoch: 6| Step: 3
Training loss: 3.2015159473227546
Validation loss: 2.9717193882640047

Epoch: 6| Step: 4
Training loss: 3.941377698267497
Validation loss: 2.973737488046654

Epoch: 6| Step: 5
Training loss: 2.6551886738263484
Validation loss: 2.9712343970018287

Epoch: 6| Step: 6
Training loss: 3.7623456549432706
Validation loss: 2.971201865056257

Epoch: 6| Step: 7
Training loss: 2.9456985989576188
Validation loss: 2.969645986618404

Epoch: 6| Step: 8
Training loss: 3.104828697798927
Validation loss: 2.9706203283598973

Epoch: 6| Step: 9
Training loss: 3.0932433358890425
Validation loss: 2.9699773819203963

Epoch: 6| Step: 10
Training loss: 3.153298385888849
Validation loss: 2.97295807984081

Epoch: 6| Step: 11
Training loss: 2.7977189650080168
Validation loss: 2.9706197691368716

Epoch: 6| Step: 12
Training loss: 3.1834188027084185
Validation loss: 2.969955817748476

Epoch: 6| Step: 13
Training loss: 3.814638632361893
Validation loss: 2.974427414954702

Epoch: 65| Step: 0
Training loss: 3.1848050861213584
Validation loss: 2.9717418583853235

Epoch: 6| Step: 1
Training loss: 3.1898077296368164
Validation loss: 2.971137223755039

Epoch: 6| Step: 2
Training loss: 3.066021821045784
Validation loss: 2.9673096526771694

Epoch: 6| Step: 3
Training loss: 3.09698455955492
Validation loss: 2.96951868525353

Epoch: 6| Step: 4
Training loss: 3.3092649965671956
Validation loss: 2.967245014710247

Epoch: 6| Step: 5
Training loss: 2.8216481942482647
Validation loss: 2.9680601750949864

Epoch: 6| Step: 6
Training loss: 3.3973841646165517
Validation loss: 2.964982090359693

Epoch: 6| Step: 7
Training loss: 3.5765182685700125
Validation loss: 2.9646413474798194

Epoch: 6| Step: 8
Training loss: 3.342745621186851
Validation loss: 2.9628111974611775

Epoch: 6| Step: 9
Training loss: 3.040075138317909
Validation loss: 2.9625984174508426

Epoch: 6| Step: 10
Training loss: 3.4250640640393044
Validation loss: 2.9645402612404346

Epoch: 6| Step: 11
Training loss: 3.134022923602976
Validation loss: 2.9640160874411534

Epoch: 6| Step: 12
Training loss: 3.2228403119784996
Validation loss: 2.9682736077705236

Epoch: 6| Step: 13
Training loss: 3.943648246020718
Validation loss: 2.963159589548373

Epoch: 66| Step: 0
Training loss: 2.57718729247898
Validation loss: 2.9610159267214926

Epoch: 6| Step: 1
Training loss: 2.763389934271493
Validation loss: 2.962362103160252

Epoch: 6| Step: 2
Training loss: 3.2943548179244195
Validation loss: 2.9616419915440537

Epoch: 6| Step: 3
Training loss: 3.8988290104713577
Validation loss: 2.9614225864642556

Epoch: 6| Step: 4
Training loss: 3.582807384009853
Validation loss: 2.9604556576137697

Epoch: 6| Step: 5
Training loss: 2.826596263137687
Validation loss: 2.958616561769428

Epoch: 6| Step: 6
Training loss: 2.930202591437608
Validation loss: 2.958978188087669

Epoch: 6| Step: 7
Training loss: 3.185050771359492
Validation loss: 2.959447522357677

Epoch: 6| Step: 8
Training loss: 3.2042597551717433
Validation loss: 2.958209237236183

Epoch: 6| Step: 9
Training loss: 3.5264932107604503
Validation loss: 2.958538887708461

Epoch: 6| Step: 10
Training loss: 3.308389668661633
Validation loss: 2.9573531918184015

Epoch: 6| Step: 11
Training loss: 3.992737972880335
Validation loss: 2.957516262032029

Epoch: 6| Step: 12
Training loss: 2.6952208572509138
Validation loss: 2.959754257415157

Epoch: 6| Step: 13
Training loss: 3.3831352802305763
Validation loss: 2.958982209885393

Epoch: 67| Step: 0
Training loss: 2.643552522971962
Validation loss: 2.962142934032724

Epoch: 6| Step: 1
Training loss: 2.7431824881456652
Validation loss: 2.9665950257224796

Epoch: 6| Step: 2
Training loss: 3.4694380893925647
Validation loss: 2.959841216677833

Epoch: 6| Step: 3
Training loss: 3.2977643734310216
Validation loss: 2.9555209141192624

Epoch: 6| Step: 4
Training loss: 3.032679427232924
Validation loss: 2.9556415628180406

Epoch: 6| Step: 5
Training loss: 3.8062570455952596
Validation loss: 2.9559419097960644

Epoch: 6| Step: 6
Training loss: 3.1704071106008205
Validation loss: 2.956797281748069

Epoch: 6| Step: 7
Training loss: 3.1640739534900724
Validation loss: 2.957218846462127

Epoch: 6| Step: 8
Training loss: 2.7982261420284016
Validation loss: 2.9558303455018846

Epoch: 6| Step: 9
Training loss: 4.230123377233943
Validation loss: 2.9584599897790564

Epoch: 6| Step: 10
Training loss: 2.4575918555725766
Validation loss: 2.9589929791272644

Epoch: 6| Step: 11
Training loss: 3.1021591112365954
Validation loss: 2.9646444847508127

Epoch: 6| Step: 12
Training loss: 3.9715871206864075
Validation loss: 2.9623957005573742

Epoch: 6| Step: 13
Training loss: 2.8629486598595686
Validation loss: 2.9616809958824226

Epoch: 68| Step: 0
Training loss: 3.728801062934755
Validation loss: 2.9567135338505155

Epoch: 6| Step: 1
Training loss: 3.2135935840503707
Validation loss: 2.956832512554598

Epoch: 6| Step: 2
Training loss: 3.669859507519551
Validation loss: 2.956776287337964

Epoch: 6| Step: 3
Training loss: 2.9468798931643496
Validation loss: 2.9554964461907693

Epoch: 6| Step: 4
Training loss: 3.7033853560077667
Validation loss: 2.9540852994309295

Epoch: 6| Step: 5
Training loss: 3.5312155662815767
Validation loss: 2.953272094292574

Epoch: 6| Step: 6
Training loss: 3.9148021615856234
Validation loss: 2.954157717130456

Epoch: 6| Step: 7
Training loss: 3.5324696822866595
Validation loss: 2.9529777230131518

Epoch: 6| Step: 8
Training loss: 2.680584548854889
Validation loss: 2.953492458122605

Epoch: 6| Step: 9
Training loss: 2.667466123271077
Validation loss: 2.9537313706553205

Epoch: 6| Step: 10
Training loss: 3.04918407094999
Validation loss: 2.9520133689515173

Epoch: 6| Step: 11
Training loss: 2.289102182923149
Validation loss: 2.9530775990164972

Epoch: 6| Step: 12
Training loss: 2.97369150188389
Validation loss: 2.9591793449165076

Epoch: 6| Step: 13
Training loss: 2.9151792457394516
Validation loss: 2.9612267911577024

Epoch: 69| Step: 0
Training loss: 3.3648120971636364
Validation loss: 2.964990272432003

Epoch: 6| Step: 1
Training loss: 3.3964981333282296
Validation loss: 2.9706319356659043

Epoch: 6| Step: 2
Training loss: 3.375320843175143
Validation loss: 2.9597694958470244

Epoch: 6| Step: 3
Training loss: 3.016246356100323
Validation loss: 2.949846751975916

Epoch: 6| Step: 4
Training loss: 3.0388359240329774
Validation loss: 2.9482052853544993

Epoch: 6| Step: 5
Training loss: 3.3765964264513495
Validation loss: 2.945898947321751

Epoch: 6| Step: 6
Training loss: 3.121129194495234
Validation loss: 2.9483024396639865

Epoch: 6| Step: 7
Training loss: 3.699503741620643
Validation loss: 2.945061838883945

Epoch: 6| Step: 8
Training loss: 3.2815768124542806
Validation loss: 2.9456071795169176

Epoch: 6| Step: 9
Training loss: 3.120196809185561
Validation loss: 2.949766119752734

Epoch: 6| Step: 10
Training loss: 3.3882048095355546
Validation loss: 2.9504384776745325

Epoch: 6| Step: 11
Training loss: 2.6306030782963044
Validation loss: 2.9490337220067575

Epoch: 6| Step: 12
Training loss: 3.1428170975697673
Validation loss: 2.9550075881666524

Epoch: 6| Step: 13
Training loss: 3.2837620882843526
Validation loss: 2.963482758395234

Epoch: 70| Step: 0
Training loss: 3.3499336463847555
Validation loss: 2.9489609472335694

Epoch: 6| Step: 1
Training loss: 3.2642772759116534
Validation loss: 2.9475090510042996

Epoch: 6| Step: 2
Training loss: 3.4662945278649144
Validation loss: 2.9472505576452885

Epoch: 6| Step: 3
Training loss: 3.3012200961045908
Validation loss: 2.9449300014141713

Epoch: 6| Step: 4
Training loss: 3.229473435791871
Validation loss: 2.9443273040367917

Epoch: 6| Step: 5
Training loss: 3.5334106856702063
Validation loss: 2.9440581929435203

Epoch: 6| Step: 6
Training loss: 2.7449492108314035
Validation loss: 2.9453644153733607

Epoch: 6| Step: 7
Training loss: 3.614967934029637
Validation loss: 2.945290504561228

Epoch: 6| Step: 8
Training loss: 2.835327419097542
Validation loss: 2.9430418048638654

Epoch: 6| Step: 9
Training loss: 3.085748053421461
Validation loss: 2.945643992366493

Epoch: 6| Step: 10
Training loss: 3.3241709830127872
Validation loss: 2.9467455609935636

Epoch: 6| Step: 11
Training loss: 3.3721451164143614
Validation loss: 2.9434943337618122

Epoch: 6| Step: 12
Training loss: 3.2488057803465393
Validation loss: 2.9444222916360316

Epoch: 6| Step: 13
Training loss: 2.369048441503144
Validation loss: 2.942317064071005

Epoch: 71| Step: 0
Training loss: 4.24269980468692
Validation loss: 2.9429947920113895

Epoch: 6| Step: 1
Training loss: 2.801052958185644
Validation loss: 2.9426082982120803

Epoch: 6| Step: 2
Training loss: 4.043159576187973
Validation loss: 2.940958588182712

Epoch: 6| Step: 3
Training loss: 3.040244688927963
Validation loss: 2.94115732002478

Epoch: 6| Step: 4
Training loss: 3.3322400366426486
Validation loss: 2.940026733654148

Epoch: 6| Step: 5
Training loss: 3.4826023399503336
Validation loss: 2.939858566011876

Epoch: 6| Step: 6
Training loss: 3.1675587117113824
Validation loss: 2.94161636052492

Epoch: 6| Step: 7
Training loss: 3.1895201022514366
Validation loss: 2.9376748110897832

Epoch: 6| Step: 8
Training loss: 2.8513344033344583
Validation loss: 2.935738804662296

Epoch: 6| Step: 9
Training loss: 2.0347975050445792
Validation loss: 2.9365217613031196

Epoch: 6| Step: 10
Training loss: 3.1031258051968207
Validation loss: 2.936648892882693

Epoch: 6| Step: 11
Training loss: 2.8179810416109805
Validation loss: 2.9347483362976803

Epoch: 6| Step: 12
Training loss: 3.0017510707863164
Validation loss: 2.932904357029345

Epoch: 6| Step: 13
Training loss: 3.678909899923864
Validation loss: 2.934843705116517

Epoch: 72| Step: 0
Training loss: 3.1438239208350782
Validation loss: 2.9364724623535436

Epoch: 6| Step: 1
Training loss: 3.3830828481571533
Validation loss: 2.935333042648951

Epoch: 6| Step: 2
Training loss: 3.2403856533025364
Validation loss: 2.9424854858825573

Epoch: 6| Step: 3
Training loss: 2.9087333323972864
Validation loss: 2.9594039735907867

Epoch: 6| Step: 4
Training loss: 3.5197060189161715
Validation loss: 2.957142945841637

Epoch: 6| Step: 5
Training loss: 3.333677146982368
Validation loss: 2.948954821879249

Epoch: 6| Step: 6
Training loss: 3.499510322103199
Validation loss: 2.9436833433173293

Epoch: 6| Step: 7
Training loss: 3.1901657326914186
Validation loss: 2.9425943552751432

Epoch: 6| Step: 8
Training loss: 3.4680161258274196
Validation loss: 2.932694142464444

Epoch: 6| Step: 9
Training loss: 3.4987371073625333
Validation loss: 2.9311541738890465

Epoch: 6| Step: 10
Training loss: 2.939644213577043
Validation loss: 2.9295244042723936

Epoch: 6| Step: 11
Training loss: 3.378750024612771
Validation loss: 2.9303625261906188

Epoch: 6| Step: 12
Training loss: 2.6752501468813477
Validation loss: 2.9297399915142393

Epoch: 6| Step: 13
Training loss: 2.5887007686809396
Validation loss: 2.9314919634404872

Epoch: 73| Step: 0
Training loss: 3.4028845443757088
Validation loss: 2.9335519182961773

Epoch: 6| Step: 1
Training loss: 2.9837514815149038
Validation loss: 2.929545355954694

Epoch: 6| Step: 2
Training loss: 2.232443448126844
Validation loss: 2.929951511751671

Epoch: 6| Step: 3
Training loss: 2.577284242348316
Validation loss: 2.92921861447204

Epoch: 6| Step: 4
Training loss: 3.725319965112831
Validation loss: 2.9285889990148974

Epoch: 6| Step: 5
Training loss: 3.6540775202653935
Validation loss: 2.9275875055124727

Epoch: 6| Step: 6
Training loss: 3.695669144886592
Validation loss: 2.9270808576400342

Epoch: 6| Step: 7
Training loss: 3.3370698172970754
Validation loss: 2.9293580281388283

Epoch: 6| Step: 8
Training loss: 3.401219283991823
Validation loss: 2.9272126783890133

Epoch: 6| Step: 9
Training loss: 2.741215286278613
Validation loss: 2.927608379985903

Epoch: 6| Step: 10
Training loss: 2.7418174385270326
Validation loss: 2.9269281342608147

Epoch: 6| Step: 11
Training loss: 2.671828598601103
Validation loss: 2.9369084660002946

Epoch: 6| Step: 12
Training loss: 3.7595209691096674
Validation loss: 2.938454967818257

Epoch: 6| Step: 13
Training loss: 3.969562477389902
Validation loss: 2.9334583637107516

Epoch: 74| Step: 0
Training loss: 3.568873008839437
Validation loss: 2.9253459610831887

Epoch: 6| Step: 1
Training loss: 3.220596080363696
Validation loss: 2.9257505083850623

Epoch: 6| Step: 2
Training loss: 3.5682157206733245
Validation loss: 2.9280630699647188

Epoch: 6| Step: 3
Training loss: 2.953398030894929
Validation loss: 2.925285953833446

Epoch: 6| Step: 4
Training loss: 3.331608198707835
Validation loss: 2.9262806123028002

Epoch: 6| Step: 5
Training loss: 2.756262670647871
Validation loss: 2.9256459543345628

Epoch: 6| Step: 6
Training loss: 3.7620362715242606
Validation loss: 2.924897139284709

Epoch: 6| Step: 7
Training loss: 2.89720666462017
Validation loss: 2.923218505150783

Epoch: 6| Step: 8
Training loss: 3.448973494695814
Validation loss: 2.9227837809811783

Epoch: 6| Step: 9
Training loss: 2.8771622860788666
Validation loss: 2.924031091491628

Epoch: 6| Step: 10
Training loss: 3.032164760088775
Validation loss: 2.9213619188584854

Epoch: 6| Step: 11
Training loss: 3.0547104466349606
Validation loss: 2.918555147286467

Epoch: 6| Step: 12
Training loss: 3.3603742665790692
Validation loss: 2.9189813242430445

Epoch: 6| Step: 13
Training loss: 2.8321201494667605
Validation loss: 2.9202988809786503

Epoch: 75| Step: 0
Training loss: 2.1901714905783267
Validation loss: 2.917637246600923

Epoch: 6| Step: 1
Training loss: 3.5904932275136363
Validation loss: 2.9193736831921613

Epoch: 6| Step: 2
Training loss: 3.2543654833310716
Validation loss: 2.91765454756406

Epoch: 6| Step: 3
Training loss: 3.583492866927369
Validation loss: 2.916812102622246

Epoch: 6| Step: 4
Training loss: 3.6650350292660328
Validation loss: 2.9175444575620086

Epoch: 6| Step: 5
Training loss: 2.204984056410812
Validation loss: 2.9181599083325085

Epoch: 6| Step: 6
Training loss: 3.4389892126625767
Validation loss: 2.919503985953937

Epoch: 6| Step: 7
Training loss: 2.459303734412092
Validation loss: 2.9166260111446634

Epoch: 6| Step: 8
Training loss: 4.068870596556071
Validation loss: 2.920745579560156

Epoch: 6| Step: 9
Training loss: 3.4045167765501647
Validation loss: 2.9169924608268207

Epoch: 6| Step: 10
Training loss: 2.556785631839595
Validation loss: 2.9169344578407084

Epoch: 6| Step: 11
Training loss: 3.160781930441295
Validation loss: 2.917091277779861

Epoch: 6| Step: 12
Training loss: 3.215645783916069
Validation loss: 2.9178172541931073

Epoch: 6| Step: 13
Training loss: 3.708800397169867
Validation loss: 2.917649363436556

Epoch: 76| Step: 0
Training loss: 3.0993463011588163
Validation loss: 2.919033477818196

Epoch: 6| Step: 1
Training loss: 3.777425550109637
Validation loss: 2.9232021737512697

Epoch: 6| Step: 2
Training loss: 3.457863159084397
Validation loss: 2.922363938748146

Epoch: 6| Step: 3
Training loss: 2.972053376469374
Validation loss: 2.9200497450997216

Epoch: 6| Step: 4
Training loss: 3.825831010092532
Validation loss: 2.9207109834300438

Epoch: 6| Step: 5
Training loss: 3.2819605466713377
Validation loss: 2.9200838881486915

Epoch: 6| Step: 6
Training loss: 3.1491348592325004
Validation loss: 2.917971174852978

Epoch: 6| Step: 7
Training loss: 3.0399727132476104
Validation loss: 2.9191674043309157

Epoch: 6| Step: 8
Training loss: 2.47866241284943
Validation loss: 2.918447786269411

Epoch: 6| Step: 9
Training loss: 3.03874428463347
Validation loss: 2.9207028870952367

Epoch: 6| Step: 10
Training loss: 2.6725345266054914
Validation loss: 2.9241213820687086

Epoch: 6| Step: 11
Training loss: 3.1671179065106236
Validation loss: 2.920152745448468

Epoch: 6| Step: 12
Training loss: 3.2247511834259903
Validation loss: 2.924411610764221

Epoch: 6| Step: 13
Training loss: 3.681380415000429
Validation loss: 2.927956947162557

Epoch: 77| Step: 0
Training loss: 3.8717735147915495
Validation loss: 2.926915985766634

Epoch: 6| Step: 1
Training loss: 2.640217044173497
Validation loss: 2.92941790384223

Epoch: 6| Step: 2
Training loss: 2.3526185158075266
Validation loss: 2.9217119016209008

Epoch: 6| Step: 3
Training loss: 3.5929429184594093
Validation loss: 2.9202290210625903

Epoch: 6| Step: 4
Training loss: 3.4999035413256725
Validation loss: 2.913415516048302

Epoch: 6| Step: 5
Training loss: 2.847692586198644
Validation loss: 2.910799248225319

Epoch: 6| Step: 6
Training loss: 2.587060413706545
Validation loss: 2.9124275012241685

Epoch: 6| Step: 7
Training loss: 2.896792868033213
Validation loss: 2.9082263265266715

Epoch: 6| Step: 8
Training loss: 3.622315695466041
Validation loss: 2.909308822808121

Epoch: 6| Step: 9
Training loss: 3.121469410619477
Validation loss: 2.910679871055147

Epoch: 6| Step: 10
Training loss: 3.498778538780032
Validation loss: 2.909156779095736

Epoch: 6| Step: 11
Training loss: 3.145568600730147
Validation loss: 2.9089278217322727

Epoch: 6| Step: 12
Training loss: 3.6725138656323297
Validation loss: 2.907105565926764

Epoch: 6| Step: 13
Training loss: 3.0599585127667197
Validation loss: 2.9071960409037114

Epoch: 78| Step: 0
Training loss: 3.830873335825229
Validation loss: 2.905979656868962

Epoch: 6| Step: 1
Training loss: 2.916541796236484
Validation loss: 2.9061320097109

Epoch: 6| Step: 2
Training loss: 3.6131211693846863
Validation loss: 2.9068977691709503

Epoch: 6| Step: 3
Training loss: 2.798258348754981
Validation loss: 2.9044793581656196

Epoch: 6| Step: 4
Training loss: 2.920832646941695
Validation loss: 2.9066930568338503

Epoch: 6| Step: 5
Training loss: 3.2150955935871206
Validation loss: 2.907546855917277

Epoch: 6| Step: 6
Training loss: 3.2114248532408003
Validation loss: 2.912751567126192

Epoch: 6| Step: 7
Training loss: 3.5426750692263838
Validation loss: 2.9121928923518015

Epoch: 6| Step: 8
Training loss: 3.075232836584336
Validation loss: 2.9133715458267875

Epoch: 6| Step: 9
Training loss: 3.2967430919998053
Validation loss: 2.9106047562258013

Epoch: 6| Step: 10
Training loss: 2.597608889958307
Validation loss: 2.910190426315476

Epoch: 6| Step: 11
Training loss: 2.8838910822095642
Validation loss: 2.9091467171768985

Epoch: 6| Step: 12
Training loss: 3.551432634791268
Validation loss: 2.910474903284713

Epoch: 6| Step: 13
Training loss: 3.117907448139469
Validation loss: 2.9056604012026725

Epoch: 79| Step: 0
Training loss: 3.092296682842582
Validation loss: 2.9004320378345847

Epoch: 6| Step: 1
Training loss: 3.382627838944414
Validation loss: 2.9020195748778304

Epoch: 6| Step: 2
Training loss: 3.0899847989495446
Validation loss: 2.900810570214049

Epoch: 6| Step: 3
Training loss: 3.1223062730956896
Validation loss: 2.9040977844024924

Epoch: 6| Step: 4
Training loss: 2.693372476060414
Validation loss: 2.9021130546341922

Epoch: 6| Step: 5
Training loss: 3.240249385419572
Validation loss: 2.9017811428116547

Epoch: 6| Step: 6
Training loss: 3.5517007541557204
Validation loss: 2.9013640136162393

Epoch: 6| Step: 7
Training loss: 2.743856851152534
Validation loss: 2.9016965845323774

Epoch: 6| Step: 8
Training loss: 2.6593264547325846
Validation loss: 2.90153912870091

Epoch: 6| Step: 9
Training loss: 2.6924460386006563
Validation loss: 2.900141747510813

Epoch: 6| Step: 10
Training loss: 3.778739663380307
Validation loss: 2.901894188725955

Epoch: 6| Step: 11
Training loss: 3.708296757778428
Validation loss: 2.9001885560391094

Epoch: 6| Step: 12
Training loss: 3.4244525555445766
Validation loss: 2.901420872616919

Epoch: 6| Step: 13
Training loss: 3.4528275443681604
Validation loss: 2.900027517669781

Epoch: 80| Step: 0
Training loss: 1.8386326912310544
Validation loss: 2.9005076706596795

Epoch: 6| Step: 1
Training loss: 3.4523152916713604
Validation loss: 2.899549504389303

Epoch: 6| Step: 2
Training loss: 2.478862669014953
Validation loss: 2.9021403312157887

Epoch: 6| Step: 3
Training loss: 3.532584014347063
Validation loss: 2.9011282900264503

Epoch: 6| Step: 4
Training loss: 3.4627923063982595
Validation loss: 2.900359882086705

Epoch: 6| Step: 5
Training loss: 2.618482582440811
Validation loss: 2.9012477456403363

Epoch: 6| Step: 6
Training loss: 3.0242880874131264
Validation loss: 2.901288024924894

Epoch: 6| Step: 7
Training loss: 3.522208327163367
Validation loss: 2.9096977203551693

Epoch: 6| Step: 8
Training loss: 3.453007898891152
Validation loss: 2.9187297878227367

Epoch: 6| Step: 9
Training loss: 3.353270195681974
Validation loss: 2.920582036273088

Epoch: 6| Step: 10
Training loss: 3.6716342278939473
Validation loss: 2.8992421181809007

Epoch: 6| Step: 11
Training loss: 3.1790101925667615
Validation loss: 2.8964056551785315

Epoch: 6| Step: 12
Training loss: 3.564515865244067
Validation loss: 2.898893654268516

Epoch: 6| Step: 13
Training loss: 2.8608496360266145
Validation loss: 2.895849428968006

Epoch: 81| Step: 0
Training loss: 3.272652543303284
Validation loss: 2.8943332254923786

Epoch: 6| Step: 1
Training loss: 3.4791296920791326
Validation loss: 2.8987275453250625

Epoch: 6| Step: 2
Training loss: 3.1661425876281806
Validation loss: 2.9024016364972915

Epoch: 6| Step: 3
Training loss: 3.346212175773223
Validation loss: 2.9056962837926763

Epoch: 6| Step: 4
Training loss: 3.114010982594512
Validation loss: 2.9063518769624426

Epoch: 6| Step: 5
Training loss: 3.7348153720555297
Validation loss: 2.9024986413791383

Epoch: 6| Step: 6
Training loss: 2.460098753396872
Validation loss: 2.89867220422179

Epoch: 6| Step: 7
Training loss: 3.164312658899478
Validation loss: 2.8914259040787997

Epoch: 6| Step: 8
Training loss: 2.7104564756675282
Validation loss: 2.8894394296608694

Epoch: 6| Step: 9
Training loss: 2.982904841021312
Validation loss: 2.8900051393536663

Epoch: 6| Step: 10
Training loss: 3.2932673236342342
Validation loss: 2.8903790068559383

Epoch: 6| Step: 11
Training loss: 3.6581986931867174
Validation loss: 2.890464124163324

Epoch: 6| Step: 12
Training loss: 2.476361383882159
Validation loss: 2.891289761550694

Epoch: 6| Step: 13
Training loss: 3.6453733462844746
Validation loss: 2.887725102720964

Epoch: 82| Step: 0
Training loss: 3.3306445403553977
Validation loss: 2.889119739382837

Epoch: 6| Step: 1
Training loss: 2.8392393788740877
Validation loss: 2.888480534916626

Epoch: 6| Step: 2
Training loss: 3.417072985299734
Validation loss: 2.8906210161274224

Epoch: 6| Step: 3
Training loss: 3.40588642944833
Validation loss: 2.887373900184863

Epoch: 6| Step: 4
Training loss: 2.1461543488114083
Validation loss: 2.8862809997940864

Epoch: 6| Step: 5
Training loss: 3.314232571063053
Validation loss: 2.8882881188145855

Epoch: 6| Step: 6
Training loss: 3.18224454970788
Validation loss: 2.8858766933545943

Epoch: 6| Step: 7
Training loss: 2.3616383792831566
Validation loss: 2.885415381329155

Epoch: 6| Step: 8
Training loss: 3.3121651534215557
Validation loss: 2.885578276415801

Epoch: 6| Step: 9
Training loss: 3.7695135402757565
Validation loss: 2.8860699391034834

Epoch: 6| Step: 10
Training loss: 3.5558806376726144
Validation loss: 2.887674694603642

Epoch: 6| Step: 11
Training loss: 3.314828881727791
Validation loss: 2.8868913043473263

Epoch: 6| Step: 12
Training loss: 3.22790794861493
Validation loss: 2.884966053258524

Epoch: 6| Step: 13
Training loss: 2.8502833175378153
Validation loss: 2.8839374122357673

Epoch: 83| Step: 0
Training loss: 3.0495609280087677
Validation loss: 2.8854006875706557

Epoch: 6| Step: 1
Training loss: 3.1538040201260573
Validation loss: 2.8840363084128566

Epoch: 6| Step: 2
Training loss: 3.0714700860801263
Validation loss: 2.8864300079299383

Epoch: 6| Step: 3
Training loss: 2.6263965343209628
Validation loss: 2.889342440622322

Epoch: 6| Step: 4
Training loss: 2.7557572873765044
Validation loss: 2.8907423036071815

Epoch: 6| Step: 5
Training loss: 2.713819395607434
Validation loss: 2.902320536779537

Epoch: 6| Step: 6
Training loss: 3.3392329142616686
Validation loss: 2.9098280678753152

Epoch: 6| Step: 7
Training loss: 2.9171847473687302
Validation loss: 2.9076798390949827

Epoch: 6| Step: 8
Training loss: 3.753344379654976
Validation loss: 2.928927140422934

Epoch: 6| Step: 9
Training loss: 3.4601136339964986
Validation loss: 2.9175149349154417

Epoch: 6| Step: 10
Training loss: 3.0486262057275133
Validation loss: 2.9192452671058913

Epoch: 6| Step: 11
Training loss: 3.707685792657295
Validation loss: 2.9194508028413066

Epoch: 6| Step: 12
Training loss: 3.220665223018339
Validation loss: 2.885350418322437

Epoch: 6| Step: 13
Training loss: 3.7780180430832124
Validation loss: 2.881964866749336

Epoch: 84| Step: 0
Training loss: 3.0311279272294773
Validation loss: 2.88401981735936

Epoch: 6| Step: 1
Training loss: 3.293373743676771
Validation loss: 2.896183396152652

Epoch: 6| Step: 2
Training loss: 3.1810188973952886
Validation loss: 2.9061811538006235

Epoch: 6| Step: 3
Training loss: 2.827106692939865
Validation loss: 2.9143109144094628

Epoch: 6| Step: 4
Training loss: 3.6447063048292265
Validation loss: 2.9078226341041913

Epoch: 6| Step: 5
Training loss: 2.853440760910482
Validation loss: 2.8959695679678013

Epoch: 6| Step: 6
Training loss: 3.30332886383442
Validation loss: 2.8854525267601008

Epoch: 6| Step: 7
Training loss: 3.455291620691515
Validation loss: 2.881384106306002

Epoch: 6| Step: 8
Training loss: 3.077711513263469
Validation loss: 2.879746566707158

Epoch: 6| Step: 9
Training loss: 3.2456664023282857
Validation loss: 2.8787600516786664

Epoch: 6| Step: 10
Training loss: 2.991122780950768
Validation loss: 2.879037679936742

Epoch: 6| Step: 11
Training loss: 3.5905952206697274
Validation loss: 2.8794058220768126

Epoch: 6| Step: 12
Training loss: 2.767477503463711
Validation loss: 2.8850106892210277

Epoch: 6| Step: 13
Training loss: 3.4314195434707466
Validation loss: 2.8898554413065094

Epoch: 85| Step: 0
Training loss: 2.2254137790272894
Validation loss: 2.892737280959632

Epoch: 6| Step: 1
Training loss: 3.5189768093046347
Validation loss: 2.89929636699447

Epoch: 6| Step: 2
Training loss: 3.4341017137948135
Validation loss: 2.9000984617893706

Epoch: 6| Step: 3
Training loss: 3.9026962594553645
Validation loss: 2.891153110728768

Epoch: 6| Step: 4
Training loss: 2.68304873155719
Validation loss: 2.8833266669352855

Epoch: 6| Step: 5
Training loss: 2.4870414579622606
Validation loss: 2.884375683880361

Epoch: 6| Step: 6
Training loss: 3.695329403989812
Validation loss: 2.8784548620325117

Epoch: 6| Step: 7
Training loss: 3.403785584004945
Validation loss: 2.878934606661613

Epoch: 6| Step: 8
Training loss: 2.7139353597725804
Validation loss: 2.8773027572426346

Epoch: 6| Step: 9
Training loss: 3.1362951997469968
Validation loss: 2.8798996797559515

Epoch: 6| Step: 10
Training loss: 3.849598227010114
Validation loss: 2.8774136260204766

Epoch: 6| Step: 11
Training loss: 2.5809411591507256
Validation loss: 2.875524381206959

Epoch: 6| Step: 12
Training loss: 3.2089952223740124
Validation loss: 2.873759106695113

Epoch: 6| Step: 13
Training loss: 2.973523448317311
Validation loss: 2.8751925465941195

Epoch: 86| Step: 0
Training loss: 3.0342889084079485
Validation loss: 2.8741668075239764

Epoch: 6| Step: 1
Training loss: 3.0326440496109375
Validation loss: 2.879193835792685

Epoch: 6| Step: 2
Training loss: 3.2668554004981107
Validation loss: 2.8766706667593644

Epoch: 6| Step: 3
Training loss: 3.1663210496185967
Validation loss: 2.874973608201686

Epoch: 6| Step: 4
Training loss: 3.7370422287071663
Validation loss: 2.8773006562934698

Epoch: 6| Step: 5
Training loss: 2.5930493798841034
Validation loss: 2.875634660619169

Epoch: 6| Step: 6
Training loss: 3.3687185537254174
Validation loss: 2.8815270798516757

Epoch: 6| Step: 7
Training loss: 3.568333183572461
Validation loss: 2.881699587442469

Epoch: 6| Step: 8
Training loss: 2.8874276288363623
Validation loss: 2.8855318128149055

Epoch: 6| Step: 9
Training loss: 2.980555141891762
Validation loss: 2.8811328796068065

Epoch: 6| Step: 10
Training loss: 2.970000957142069
Validation loss: 2.8804964809537528

Epoch: 6| Step: 11
Training loss: 3.317646419280798
Validation loss: 2.8715341747659884

Epoch: 6| Step: 12
Training loss: 3.0955464705532982
Validation loss: 2.8719278447314567

Epoch: 6| Step: 13
Training loss: 3.191884484755969
Validation loss: 2.8693815656343187

Epoch: 87| Step: 0
Training loss: 2.6392427697956666
Validation loss: 2.869315519477762

Epoch: 6| Step: 1
Training loss: 3.265273079777932
Validation loss: 2.868222140961005

Epoch: 6| Step: 2
Training loss: 3.1263096925938654
Validation loss: 2.864660094604011

Epoch: 6| Step: 3
Training loss: 2.986578322733195
Validation loss: 2.865915597590859

Epoch: 6| Step: 4
Training loss: 3.456323307632659
Validation loss: 2.8670826540943977

Epoch: 6| Step: 5
Training loss: 3.210386354244309
Validation loss: 2.8660283666792

Epoch: 6| Step: 6
Training loss: 2.911718003232229
Validation loss: 2.8674118626147576

Epoch: 6| Step: 7
Training loss: 2.8077401467640284
Validation loss: 2.8694483375197963

Epoch: 6| Step: 8
Training loss: 3.676362497423694
Validation loss: 2.865025902770443

Epoch: 6| Step: 9
Training loss: 3.654967645588044
Validation loss: 2.8638604653576043

Epoch: 6| Step: 10
Training loss: 3.4402605936128343
Validation loss: 2.865201056467359

Epoch: 6| Step: 11
Training loss: 2.8303633625775317
Validation loss: 2.866103437760939

Epoch: 6| Step: 12
Training loss: 3.061513625133797
Validation loss: 2.866712015465315

Epoch: 6| Step: 13
Training loss: 2.934556013380304
Validation loss: 2.8677102801217016

Epoch: 88| Step: 0
Training loss: 3.0343395101434156
Validation loss: 2.8700408860088

Epoch: 6| Step: 1
Training loss: 3.2887925424582654
Validation loss: 2.8727607352840003

Epoch: 6| Step: 2
Training loss: 3.108150682034487
Validation loss: 2.8706950128657427

Epoch: 6| Step: 3
Training loss: 3.7020493888837267
Validation loss: 2.8674550293349257

Epoch: 6| Step: 4
Training loss: 3.6044981405311853
Validation loss: 2.866969575949393

Epoch: 6| Step: 5
Training loss: 3.4015030287527686
Validation loss: 2.861892240396431

Epoch: 6| Step: 6
Training loss: 3.0751945372041734
Validation loss: 2.8621494428018424

Epoch: 6| Step: 7
Training loss: 2.350399299949194
Validation loss: 2.8626104418903076

Epoch: 6| Step: 8
Training loss: 2.637153374914141
Validation loss: 2.860600368132354

Epoch: 6| Step: 9
Training loss: 2.353215748530266
Validation loss: 2.860732796813945

Epoch: 6| Step: 10
Training loss: 3.708595452349449
Validation loss: 2.859028881850305

Epoch: 6| Step: 11
Training loss: 3.649505262942582
Validation loss: 2.862556414906471

Epoch: 6| Step: 12
Training loss: 2.785854685392797
Validation loss: 2.8620718952233846

Epoch: 6| Step: 13
Training loss: 3.172361439954926
Validation loss: 2.8604624089453137

Epoch: 89| Step: 0
Training loss: 3.2286012872407546
Validation loss: 2.8597093567437475

Epoch: 6| Step: 1
Training loss: 3.367373857408268
Validation loss: 2.865885950108867

Epoch: 6| Step: 2
Training loss: 3.021936324877036
Validation loss: 2.880890332238672

Epoch: 6| Step: 3
Training loss: 2.539635132993346
Validation loss: 2.8725559284200997

Epoch: 6| Step: 4
Training loss: 3.794495013266019
Validation loss: 2.864762011611347

Epoch: 6| Step: 5
Training loss: 3.3231384458443833
Validation loss: 2.8590739738549544

Epoch: 6| Step: 6
Training loss: 3.329748053427496
Validation loss: 2.855482750263202

Epoch: 6| Step: 7
Training loss: 2.182086676997542
Validation loss: 2.858988224191701

Epoch: 6| Step: 8
Training loss: 3.4844250867861697
Validation loss: 2.8569107666766

Epoch: 6| Step: 9
Training loss: 3.4370108516500717
Validation loss: 2.8553712795471373

Epoch: 6| Step: 10
Training loss: 2.1973759737915888
Validation loss: 2.8567924184983293

Epoch: 6| Step: 11
Training loss: 2.9173411724722156
Validation loss: 2.85738536465498

Epoch: 6| Step: 12
Training loss: 3.3540371382129504
Validation loss: 2.8543754203688643

Epoch: 6| Step: 13
Training loss: 3.81353020428822
Validation loss: 2.8559220205668328

Epoch: 90| Step: 0
Training loss: 2.9138181855002303
Validation loss: 2.860711315164043

Epoch: 6| Step: 1
Training loss: 3.6347841224425217
Validation loss: 2.8577221529626717

Epoch: 6| Step: 2
Training loss: 3.2240823075836973
Validation loss: 2.857700484512292

Epoch: 6| Step: 3
Training loss: 2.798142556175249
Validation loss: 2.8587758538049055

Epoch: 6| Step: 4
Training loss: 2.797610223557181
Validation loss: 2.8579123320034894

Epoch: 6| Step: 5
Training loss: 3.509859503083318
Validation loss: 2.8578801696143477

Epoch: 6| Step: 6
Training loss: 2.935168375777621
Validation loss: 2.854459047143545

Epoch: 6| Step: 7
Training loss: 3.0941201961475264
Validation loss: 2.860686948606896

Epoch: 6| Step: 8
Training loss: 3.672048102011842
Validation loss: 2.855193388560396

Epoch: 6| Step: 9
Training loss: 3.4491114702314323
Validation loss: 2.8525372668521616

Epoch: 6| Step: 10
Training loss: 3.077204067898046
Validation loss: 2.8554513541688387

Epoch: 6| Step: 11
Training loss: 2.8823704988052476
Validation loss: 2.852140989692861

Epoch: 6| Step: 12
Training loss: 3.267542226061766
Validation loss: 2.8507733300247353

Epoch: 6| Step: 13
Training loss: 2.09306984856961
Validation loss: 2.846447465482082

Epoch: 91| Step: 0
Training loss: 3.4139613784724006
Validation loss: 2.8505602972545097

Epoch: 6| Step: 1
Training loss: 2.7015644486057893
Validation loss: 2.8503403176739517

Epoch: 6| Step: 2
Training loss: 3.2840352181185226
Validation loss: 2.850700347202681

Epoch: 6| Step: 3
Training loss: 3.2803238787893885
Validation loss: 2.8507005648337667

Epoch: 6| Step: 4
Training loss: 3.4020691858306207
Validation loss: 2.858762905433694

Epoch: 6| Step: 5
Training loss: 3.103713512413585
Validation loss: 2.8631333145586155

Epoch: 6| Step: 6
Training loss: 3.788046033923948
Validation loss: 2.858529551186416

Epoch: 6| Step: 7
Training loss: 3.567101568522922
Validation loss: 2.8555937874981976

Epoch: 6| Step: 8
Training loss: 1.943385813164227
Validation loss: 2.8541946343893825

Epoch: 6| Step: 9
Training loss: 3.179603669282286
Validation loss: 2.8501361304202977

Epoch: 6| Step: 10
Training loss: 3.0781538134160633
Validation loss: 2.84971738089379

Epoch: 6| Step: 11
Training loss: 2.505305382850628
Validation loss: 2.849168843513849

Epoch: 6| Step: 12
Training loss: 3.4767490294061436
Validation loss: 2.8494884491707793

Epoch: 6| Step: 13
Training loss: 2.712858195759873
Validation loss: 2.8480436051859197

Epoch: 92| Step: 0
Training loss: 3.2814360066326147
Validation loss: 2.8465661996299563

Epoch: 6| Step: 1
Training loss: 3.144453609289945
Validation loss: 2.845174131504437

Epoch: 6| Step: 2
Training loss: 3.1772712693624716
Validation loss: 2.8464857516727884

Epoch: 6| Step: 3
Training loss: 3.208417585843739
Validation loss: 2.8449261782105006

Epoch: 6| Step: 4
Training loss: 3.1507269247617993
Validation loss: 2.843656757227465

Epoch: 6| Step: 5
Training loss: 2.5670527510474255
Validation loss: 2.8459819764310454

Epoch: 6| Step: 6
Training loss: 2.7057443617735824
Validation loss: 2.847242456186348

Epoch: 6| Step: 7
Training loss: 3.365786940451761
Validation loss: 2.8477724212177487

Epoch: 6| Step: 8
Training loss: 3.7133763059347404
Validation loss: 2.848375869230126

Epoch: 6| Step: 9
Training loss: 2.3338276702754763
Validation loss: 2.846081840193846

Epoch: 6| Step: 10
Training loss: 3.5579727585743033
Validation loss: 2.8488327520303405

Epoch: 6| Step: 11
Training loss: 3.0963943431783356
Validation loss: 2.851414114810684

Epoch: 6| Step: 12
Training loss: 3.002703719902548
Validation loss: 2.845218723157299

Epoch: 6| Step: 13
Training loss: 3.710578724433002
Validation loss: 2.844449530251611

Epoch: 93| Step: 0
Training loss: 2.629940379377139
Validation loss: 2.8439078086059992

Epoch: 6| Step: 1
Training loss: 3.19660308069256
Validation loss: 2.846708617334877

Epoch: 6| Step: 2
Training loss: 3.496632727308875
Validation loss: 2.853253117686285

Epoch: 6| Step: 3
Training loss: 3.4045174768508835
Validation loss: 2.860188931003833

Epoch: 6| Step: 4
Training loss: 2.689313853085342
Validation loss: 2.8549763808122797

Epoch: 6| Step: 5
Training loss: 3.2410498404055996
Validation loss: 2.8520305373620056

Epoch: 6| Step: 6
Training loss: 2.7919137949710775
Validation loss: 2.8485954857321643

Epoch: 6| Step: 7
Training loss: 3.634547321829658
Validation loss: 2.8467580271991615

Epoch: 6| Step: 8
Training loss: 3.286589719117907
Validation loss: 2.8466317694502092

Epoch: 6| Step: 9
Training loss: 3.807365712473398
Validation loss: 2.8453473005986574

Epoch: 6| Step: 10
Training loss: 2.9001078355405463
Validation loss: 2.8448547413483043

Epoch: 6| Step: 11
Training loss: 3.1069915684541716
Validation loss: 2.842189331266969

Epoch: 6| Step: 12
Training loss: 3.2826235848003202
Validation loss: 2.841225608085515

Epoch: 6| Step: 13
Training loss: 1.6325719190706762
Validation loss: 2.8414725878058973

Epoch: 94| Step: 0
Training loss: 2.3701477677518343
Validation loss: 2.839314063928055

Epoch: 6| Step: 1
Training loss: 3.499348171027043
Validation loss: 2.8411849266525264

Epoch: 6| Step: 2
Training loss: 3.3635480644202245
Validation loss: 2.838842189144021

Epoch: 6| Step: 3
Training loss: 3.4944417961230516
Validation loss: 2.8435195438220253

Epoch: 6| Step: 4
Training loss: 2.594307437422269
Validation loss: 2.8426830945732235

Epoch: 6| Step: 5
Training loss: 2.8882116192242346
Validation loss: 2.8417977753152095

Epoch: 6| Step: 6
Training loss: 2.8827390583886996
Validation loss: 2.851368937635446

Epoch: 6| Step: 7
Training loss: 2.788010684733119
Validation loss: 2.8572665713667025

Epoch: 6| Step: 8
Training loss: 3.7305325327907877
Validation loss: 2.8687480533214433

Epoch: 6| Step: 9
Training loss: 3.8632795220073235
Validation loss: 2.905199584187698

Epoch: 6| Step: 10
Training loss: 3.044232127017265
Validation loss: 2.9099206959457264

Epoch: 6| Step: 11
Training loss: 3.5646813390127954
Validation loss: 2.9008310311153154

Epoch: 6| Step: 12
Training loss: 2.7995176989838497
Validation loss: 2.856336839395664

Epoch: 6| Step: 13
Training loss: 2.7282837951518952
Validation loss: 2.843779635756699

Epoch: 95| Step: 0
Training loss: 3.2578691436453826
Validation loss: 2.8381559876296767

Epoch: 6| Step: 1
Training loss: 2.8485142967932675
Validation loss: 2.837109097194103

Epoch: 6| Step: 2
Training loss: 3.3368607612530425
Validation loss: 2.8396621237305175

Epoch: 6| Step: 3
Training loss: 3.063547227826995
Validation loss: 2.8411337631894233

Epoch: 6| Step: 4
Training loss: 2.5516584912083387
Validation loss: 2.8456137327514024

Epoch: 6| Step: 5
Training loss: 3.838329307586065
Validation loss: 2.844615947322693

Epoch: 6| Step: 6
Training loss: 3.1020292224011783
Validation loss: 2.8432921507898237

Epoch: 6| Step: 7
Training loss: 2.8448589803543913
Validation loss: 2.8389595734884763

Epoch: 6| Step: 8
Training loss: 3.2018024970860837
Validation loss: 2.8377753618844186

Epoch: 6| Step: 9
Training loss: 2.949733017300388
Validation loss: 2.8380875378385335

Epoch: 6| Step: 10
Training loss: 3.3325994796385316
Validation loss: 2.8376473081983615

Epoch: 6| Step: 11
Training loss: 2.794029109248878
Validation loss: 2.8340895073198973

Epoch: 6| Step: 12
Training loss: 3.452741368590185
Validation loss: 2.8320456232110005

Epoch: 6| Step: 13
Training loss: 3.4195876467444273
Validation loss: 2.8344485828370534

Epoch: 96| Step: 0
Training loss: 2.9120155488217416
Validation loss: 2.832215535324619

Epoch: 6| Step: 1
Training loss: 2.604000472805607
Validation loss: 2.8306199384307114

Epoch: 6| Step: 2
Training loss: 3.411916376866809
Validation loss: 2.836797588498178

Epoch: 6| Step: 3
Training loss: 3.524495103537992
Validation loss: 2.8434904282723465

Epoch: 6| Step: 4
Training loss: 2.996841357283955
Validation loss: 2.8519635579113287

Epoch: 6| Step: 5
Training loss: 3.1203681188219523
Validation loss: 2.855718806953531

Epoch: 6| Step: 6
Training loss: 3.69748693127286
Validation loss: 2.8533441268380173

Epoch: 6| Step: 7
Training loss: 2.7308609534799113
Validation loss: 2.8373954440357037

Epoch: 6| Step: 8
Training loss: 2.6525807787417603
Validation loss: 2.8335162178555073

Epoch: 6| Step: 9
Training loss: 3.620085706591943
Validation loss: 2.833062307966194

Epoch: 6| Step: 10
Training loss: 2.751653694231619
Validation loss: 2.83070109268611

Epoch: 6| Step: 11
Training loss: 3.194871643544633
Validation loss: 2.831265192974221

Epoch: 6| Step: 12
Training loss: 3.2555037626356933
Validation loss: 2.8296662063428464

Epoch: 6| Step: 13
Training loss: 3.316314084914492
Validation loss: 2.8323007378313765

Epoch: 97| Step: 0
Training loss: 2.996382121267311
Validation loss: 2.828450817520507

Epoch: 6| Step: 1
Training loss: 2.9970806540531094
Validation loss: 2.830079329786995

Epoch: 6| Step: 2
Training loss: 3.7898619132942533
Validation loss: 2.830211153938238

Epoch: 6| Step: 3
Training loss: 3.179545031455863
Validation loss: 2.8300042470249864

Epoch: 6| Step: 4
Training loss: 3.180690897616686
Validation loss: 2.8282220742550597

Epoch: 6| Step: 5
Training loss: 2.3980122043149525
Validation loss: 2.828836960013105

Epoch: 6| Step: 6
Training loss: 1.7092933593446038
Validation loss: 2.8290479349834854

Epoch: 6| Step: 7
Training loss: 3.1794820433276194
Validation loss: 2.826687215439946

Epoch: 6| Step: 8
Training loss: 3.1209333280697997
Validation loss: 2.828668588689706

Epoch: 6| Step: 9
Training loss: 3.385294719358133
Validation loss: 2.829846091580481

Epoch: 6| Step: 10
Training loss: 2.956250509701578
Validation loss: 2.8269174395749954

Epoch: 6| Step: 11
Training loss: 3.743442651426823
Validation loss: 2.8280096244132467

Epoch: 6| Step: 12
Training loss: 3.5329856995445135
Validation loss: 2.82832863898915

Epoch: 6| Step: 13
Training loss: 3.2032446862166792
Validation loss: 2.827687145008075

Epoch: 98| Step: 0
Training loss: 3.2941416035309974
Validation loss: 2.8284848571819925

Epoch: 6| Step: 1
Training loss: 3.5680812817112155
Validation loss: 2.829224258579224

Epoch: 6| Step: 2
Training loss: 3.2621904774431254
Validation loss: 2.8293436511711603

Epoch: 6| Step: 3
Training loss: 2.917999798508677
Validation loss: 2.829429505542081

Epoch: 6| Step: 4
Training loss: 2.956639534769501
Validation loss: 2.8322252115908624

Epoch: 6| Step: 5
Training loss: 3.1949325372919346
Validation loss: 2.829158879748922

Epoch: 6| Step: 6
Training loss: 3.9408126701662405
Validation loss: 2.8385207236492884

Epoch: 6| Step: 7
Training loss: 2.8216247042040354
Validation loss: 2.841900577167603

Epoch: 6| Step: 8
Training loss: 2.763760212810803
Validation loss: 2.838701362704893

Epoch: 6| Step: 9
Training loss: 3.2231214152921455
Validation loss: 2.8395158757535803

Epoch: 6| Step: 10
Training loss: 2.4490162645565463
Validation loss: 2.8252058467269685

Epoch: 6| Step: 11
Training loss: 3.3650208337374106
Validation loss: 2.822643300546183

Epoch: 6| Step: 12
Training loss: 2.773450910508951
Validation loss: 2.8221900436750333

Epoch: 6| Step: 13
Training loss: 2.9428616554130422
Validation loss: 2.820606734352821

Epoch: 99| Step: 0
Training loss: 3.015269362277175
Validation loss: 2.8202544948255617

Epoch: 6| Step: 1
Training loss: 3.166747510446937
Validation loss: 2.822106395438912

Epoch: 6| Step: 2
Training loss: 3.2388513521084428
Validation loss: 2.822622212925722

Epoch: 6| Step: 3
Training loss: 2.6092673639266324
Validation loss: 2.821864937782847

Epoch: 6| Step: 4
Training loss: 2.767281160325815
Validation loss: 2.8214368822107816

Epoch: 6| Step: 5
Training loss: 3.154809150787582
Validation loss: 2.820942042834026

Epoch: 6| Step: 6
Training loss: 3.118359032475241
Validation loss: 2.8197030806680443

Epoch: 6| Step: 7
Training loss: 3.0798740742690263
Validation loss: 2.8219354512955466

Epoch: 6| Step: 8
Training loss: 3.6391899980851625
Validation loss: 2.8211076747335153

Epoch: 6| Step: 9
Training loss: 2.9194485794297815
Validation loss: 2.820906509875539

Epoch: 6| Step: 10
Training loss: 2.9731374343634505
Validation loss: 2.8202683699260085

Epoch: 6| Step: 11
Training loss: 3.472314051791338
Validation loss: 2.8189400117218653

Epoch: 6| Step: 12
Training loss: 3.407536534920265
Validation loss: 2.820423190291313

Epoch: 6| Step: 13
Training loss: 3.1290173457278443
Validation loss: 2.816903662669845

Epoch: 100| Step: 0
Training loss: 2.6286497628641334
Validation loss: 2.8183016116156057

Epoch: 6| Step: 1
Training loss: 2.630306692770763
Validation loss: 2.8172123561400486

Epoch: 6| Step: 2
Training loss: 3.6657939797142154
Validation loss: 2.8170769952218606

Epoch: 6| Step: 3
Training loss: 3.2297653299595757
Validation loss: 2.8169642959665264

Epoch: 6| Step: 4
Training loss: 3.6883404307434313
Validation loss: 2.815545850836831

Epoch: 6| Step: 5
Training loss: 2.851595609289806
Validation loss: 2.8205732031301434

Epoch: 6| Step: 6
Training loss: 3.7630752225154973
Validation loss: 2.819850414395762

Epoch: 6| Step: 7
Training loss: 2.7149926892598395
Validation loss: 2.8183489125126453

Epoch: 6| Step: 8
Training loss: 3.632992975817777
Validation loss: 2.8188470746476733

Epoch: 6| Step: 9
Training loss: 2.693204370454715
Validation loss: 2.825204123541008

Epoch: 6| Step: 10
Training loss: 2.3686897370817985
Validation loss: 2.8381904275609284

Epoch: 6| Step: 11
Training loss: 3.216724536223666
Validation loss: 2.8373203082096023

Epoch: 6| Step: 12
Training loss: 3.3140879729432693
Validation loss: 2.828599668681102

Epoch: 6| Step: 13
Training loss: 2.742185065548243
Validation loss: 2.821720829163116

Epoch: 101| Step: 0
Training loss: 2.9878088883201683
Validation loss: 2.820505188748698

Epoch: 6| Step: 1
Training loss: 3.2751524445674662
Validation loss: 2.8154938708970008

Epoch: 6| Step: 2
Training loss: 3.8147168827620592
Validation loss: 2.813030770738366

Epoch: 6| Step: 3
Training loss: 3.1674596563237354
Validation loss: 2.8122909285886917

Epoch: 6| Step: 4
Training loss: 2.6705365314109795
Validation loss: 2.8115576565710607

Epoch: 6| Step: 5
Training loss: 3.8544052187664573
Validation loss: 2.81391374794156

Epoch: 6| Step: 6
Training loss: 3.3120257919892104
Validation loss: 2.8132421136560084

Epoch: 6| Step: 7
Training loss: 2.426873248480578
Validation loss: 2.8112692543070446

Epoch: 6| Step: 8
Training loss: 2.3595216212913908
Validation loss: 2.8125832576118657

Epoch: 6| Step: 9
Training loss: 2.8009360894426587
Validation loss: 2.811900911137875

Epoch: 6| Step: 10
Training loss: 3.5379945604747234
Validation loss: 2.811824781337664

Epoch: 6| Step: 11
Training loss: 3.3202194380340613
Validation loss: 2.8101359961391092

Epoch: 6| Step: 12
Training loss: 2.9258930505800476
Validation loss: 2.8091430428139605

Epoch: 6| Step: 13
Training loss: 2.556828619425113
Validation loss: 2.8099516011776453

Epoch: 102| Step: 0
Training loss: 2.768056371875555
Validation loss: 2.809704317880786

Epoch: 6| Step: 1
Training loss: 3.536435261549525
Validation loss: 2.8092098758025674

Epoch: 6| Step: 2
Training loss: 2.828320575506255
Validation loss: 2.808551053271122

Epoch: 6| Step: 3
Training loss: 3.126553263881754
Validation loss: 2.810818306819411

Epoch: 6| Step: 4
Training loss: 2.7596465758005384
Validation loss: 2.8092749286162935

Epoch: 6| Step: 5
Training loss: 3.288007335895977
Validation loss: 2.8104526848015468

Epoch: 6| Step: 6
Training loss: 3.0034906424739716
Validation loss: 2.8115839916959664

Epoch: 6| Step: 7
Training loss: 3.203902880488505
Validation loss: 2.8196203960667314

Epoch: 6| Step: 8
Training loss: 3.018455955448161
Validation loss: 2.81979762555901

Epoch: 6| Step: 9
Training loss: 3.2961633284757417
Validation loss: 2.8210571658546764

Epoch: 6| Step: 10
Training loss: 3.454921617515904
Validation loss: 2.818493875721104

Epoch: 6| Step: 11
Training loss: 3.7922664349627544
Validation loss: 2.808549275139465

Epoch: 6| Step: 12
Training loss: 2.5901374017508667
Validation loss: 2.805469067783478

Epoch: 6| Step: 13
Training loss: 2.372583464911958
Validation loss: 2.803351929418704

Epoch: 103| Step: 0
Training loss: 3.4512579518039703
Validation loss: 2.806877552397497

Epoch: 6| Step: 1
Training loss: 2.4419835255010134
Validation loss: 2.8053156473544774

Epoch: 6| Step: 2
Training loss: 2.7199950601028013
Validation loss: 2.8068913730625837

Epoch: 6| Step: 3
Training loss: 3.257635390775554
Validation loss: 2.804204577415364

Epoch: 6| Step: 4
Training loss: 3.007523322137856
Validation loss: 2.8027052638393695

Epoch: 6| Step: 5
Training loss: 2.79435198483239
Validation loss: 2.80151083451877

Epoch: 6| Step: 6
Training loss: 3.8189979585101237
Validation loss: 2.8019577024431284

Epoch: 6| Step: 7
Training loss: 3.1292259633981185
Validation loss: 2.810190066660559

Epoch: 6| Step: 8
Training loss: 3.1999764203156515
Validation loss: 2.813197105363531

Epoch: 6| Step: 9
Training loss: 3.1097269290375245
Validation loss: 2.8026493941876067

Epoch: 6| Step: 10
Training loss: 2.3437823484095763
Validation loss: 2.800783944731836

Epoch: 6| Step: 11
Training loss: 3.168132509639206
Validation loss: 2.800926457935217

Epoch: 6| Step: 12
Training loss: 3.7835937046300714
Validation loss: 2.8003152713745236

Epoch: 6| Step: 13
Training loss: 2.905767585339503
Validation loss: 2.801811958697671

Epoch: 104| Step: 0
Training loss: 3.4100600466097917
Validation loss: 2.8011048702171504

Epoch: 6| Step: 1
Training loss: 3.398627615686217
Validation loss: 2.8008207682022705

Epoch: 6| Step: 2
Training loss: 3.433226269531015
Validation loss: 2.8038579083102744

Epoch: 6| Step: 3
Training loss: 3.3446927746924797
Validation loss: 2.804333759154185

Epoch: 6| Step: 4
Training loss: 2.5252754438882272
Validation loss: 2.800480090058382

Epoch: 6| Step: 5
Training loss: 3.575674758935641
Validation loss: 2.8021332998258437

Epoch: 6| Step: 6
Training loss: 2.9295914697803123
Validation loss: 2.8013922086089433

Epoch: 6| Step: 7
Training loss: 2.7609256970812286
Validation loss: 2.8048179107811744

Epoch: 6| Step: 8
Training loss: 3.159132594799699
Validation loss: 2.798328747113959

Epoch: 6| Step: 9
Training loss: 3.2954190913000256
Validation loss: 2.799339677331272

Epoch: 6| Step: 10
Training loss: 2.3308630082613715
Validation loss: 2.797379149060301

Epoch: 6| Step: 11
Training loss: 2.808814282838236
Validation loss: 2.7990436790823345

Epoch: 6| Step: 12
Training loss: 3.0932061844487055
Validation loss: 2.8018680069986903

Epoch: 6| Step: 13
Training loss: 3.2140357298749183
Validation loss: 2.8047601280985655

Epoch: 105| Step: 0
Training loss: 3.593695731375236
Validation loss: 2.8224783382538057

Epoch: 6| Step: 1
Training loss: 2.895366512150933
Validation loss: 2.835874356051317

Epoch: 6| Step: 2
Training loss: 3.433278074714874
Validation loss: 2.824124861919767

Epoch: 6| Step: 3
Training loss: 3.290231093896767
Validation loss: 2.8095700916829394

Epoch: 6| Step: 4
Training loss: 2.6023162574655734
Validation loss: 2.8007690696699163

Epoch: 6| Step: 5
Training loss: 3.338748935369381
Validation loss: 2.7933810664540166

Epoch: 6| Step: 6
Training loss: 2.95984542958598
Validation loss: 2.7938097877819317

Epoch: 6| Step: 7
Training loss: 2.5340731853824807
Validation loss: 2.7958499480349026

Epoch: 6| Step: 8
Training loss: 2.6562772861649995
Validation loss: 2.796353259690285

Epoch: 6| Step: 9
Training loss: 3.3650211171455444
Validation loss: 2.797074831942775

Epoch: 6| Step: 10
Training loss: 3.6806828474829074
Validation loss: 2.7954496637176574

Epoch: 6| Step: 11
Training loss: 3.4311265989254904
Validation loss: 2.7975915360010477

Epoch: 6| Step: 12
Training loss: 2.593576080741932
Validation loss: 2.799407360685123

Epoch: 6| Step: 13
Training loss: 2.6337160999232845
Validation loss: 2.805173560023411

Epoch: 106| Step: 0
Training loss: 3.5717522120292364
Validation loss: 2.825993668187409

Epoch: 6| Step: 1
Training loss: 3.0585379370107195
Validation loss: 2.846973846017352

Epoch: 6| Step: 2
Training loss: 3.053444065379353
Validation loss: 2.8426585013349985

Epoch: 6| Step: 3
Training loss: 3.5173219103489104
Validation loss: 2.8077817966880807

Epoch: 6| Step: 4
Training loss: 3.369748444945758
Validation loss: 2.7907254213790575

Epoch: 6| Step: 5
Training loss: 2.3609259352031553
Validation loss: 2.7962222597666004

Epoch: 6| Step: 6
Training loss: 2.931688606942035
Validation loss: 2.8148534073302716

Epoch: 6| Step: 7
Training loss: 3.3376157590528788
Validation loss: 2.8490736212288827

Epoch: 6| Step: 8
Training loss: 2.8493761015511483
Validation loss: 2.876881453277948

Epoch: 6| Step: 9
Training loss: 3.0151596105532814
Validation loss: 2.8965593497485265

Epoch: 6| Step: 10
Training loss: 3.094456447514879
Validation loss: 2.8744775583643363

Epoch: 6| Step: 11
Training loss: 3.3098606174775558
Validation loss: 2.8578358392127914

Epoch: 6| Step: 12
Training loss: 3.4728652324807583
Validation loss: 2.840339357972999

Epoch: 6| Step: 13
Training loss: 2.353806448415065
Validation loss: 2.8026598119191264

Epoch: 107| Step: 0
Training loss: 3.480439157071162
Validation loss: 2.791582068304929

Epoch: 6| Step: 1
Training loss: 2.8375669899985607
Validation loss: 2.7938259322464605

Epoch: 6| Step: 2
Training loss: 2.844960720012332
Validation loss: 2.794575472612459

Epoch: 6| Step: 3
Training loss: 3.434449663122957
Validation loss: 2.7938077047960257

Epoch: 6| Step: 4
Training loss: 2.9534501799925867
Validation loss: 2.794092186835577

Epoch: 6| Step: 5
Training loss: 3.544334274647279
Validation loss: 2.795102253627532

Epoch: 6| Step: 6
Training loss: 3.091485475918485
Validation loss: 2.7938346843901782

Epoch: 6| Step: 7
Training loss: 2.6644455083456595
Validation loss: 2.7946291451818346

Epoch: 6| Step: 8
Training loss: 2.9247031167150714
Validation loss: 2.7944975470282425

Epoch: 6| Step: 9
Training loss: 2.4835969678312555
Validation loss: 2.793286559907912

Epoch: 6| Step: 10
Training loss: 3.0440613886975374
Validation loss: 2.7905053496704073

Epoch: 6| Step: 11
Training loss: 3.732684019934688
Validation loss: 2.7949767058015587

Epoch: 6| Step: 12
Training loss: 3.3350687436821222
Validation loss: 2.7940771128284227

Epoch: 6| Step: 13
Training loss: 2.6424270891219845
Validation loss: 2.7939877681452243

Epoch: 108| Step: 0
Training loss: 3.2648180096833177
Validation loss: 2.792614877881436

Epoch: 6| Step: 1
Training loss: 2.5300448339055706
Validation loss: 2.7972905742860847

Epoch: 6| Step: 2
Training loss: 3.048691428209565
Validation loss: 2.7953825017450766

Epoch: 6| Step: 3
Training loss: 2.4890413425884965
Validation loss: 2.7915179384885187

Epoch: 6| Step: 4
Training loss: 2.1818318637505607
Validation loss: 2.7929291922930854

Epoch: 6| Step: 5
Training loss: 3.42220371008761
Validation loss: 2.7926668173292315

Epoch: 6| Step: 6
Training loss: 3.3190049412970155
Validation loss: 2.7983702952583993

Epoch: 6| Step: 7
Training loss: 3.1293624945334124
Validation loss: 2.804150545070575

Epoch: 6| Step: 8
Training loss: 3.5870338376323323
Validation loss: 2.81024851310594

Epoch: 6| Step: 9
Training loss: 3.263478426904504
Validation loss: 2.8168003617277186

Epoch: 6| Step: 10
Training loss: 3.126375124691227
Validation loss: 2.850033578852972

Epoch: 6| Step: 11
Training loss: 3.3516475782288717
Validation loss: 2.862768094693703

Epoch: 6| Step: 12
Training loss: 2.9878807048755114
Validation loss: 2.8680656058368856

Epoch: 6| Step: 13
Training loss: 3.978653213900952
Validation loss: 2.875896886432953

Epoch: 109| Step: 0
Training loss: 3.571676114903952
Validation loss: 2.884584705793348

Epoch: 6| Step: 1
Training loss: 3.0925460168102377
Validation loss: 2.891413895463666

Epoch: 6| Step: 2
Training loss: 3.806390338183436
Validation loss: 2.8921811691685306

Epoch: 6| Step: 3
Training loss: 2.682136773140088
Validation loss: 2.882805486648814

Epoch: 6| Step: 4
Training loss: 3.180269605136102
Validation loss: 2.8789588775479547

Epoch: 6| Step: 5
Training loss: 2.8566541390012627
Validation loss: 2.876156646061632

Epoch: 6| Step: 6
Training loss: 2.540472490113298
Validation loss: 2.8702115062092557

Epoch: 6| Step: 7
Training loss: 2.87727266131128
Validation loss: 2.8645773509271675

Epoch: 6| Step: 8
Training loss: 2.6907405389840777
Validation loss: 2.864289391315949

Epoch: 6| Step: 9
Training loss: 3.508207235237265
Validation loss: 2.8623789059756355

Epoch: 6| Step: 10
Training loss: 3.40653738506883
Validation loss: 2.861374096429551

Epoch: 6| Step: 11
Training loss: 3.3071643394330406
Validation loss: 2.8604655054284467

Epoch: 6| Step: 12
Training loss: 3.161109280785908
Validation loss: 2.8567295344995034

Epoch: 6| Step: 13
Training loss: 3.373057618866792
Validation loss: 2.855890833969783

Epoch: 110| Step: 0
Training loss: 3.2883813293120028
Validation loss: 2.8575745666976307

Epoch: 6| Step: 1
Training loss: 3.4722843893631805
Validation loss: 2.8558494314451948

Epoch: 6| Step: 2
Training loss: 2.125714911085028
Validation loss: 2.8562793997557923

Epoch: 6| Step: 3
Training loss: 3.3173622577649193
Validation loss: 2.8547490643036078

Epoch: 6| Step: 4
Training loss: 3.7738448845179557
Validation loss: 2.8531350293174316

Epoch: 6| Step: 5
Training loss: 2.6960474753685104
Validation loss: 2.848959896675646

Epoch: 6| Step: 6
Training loss: 2.8736134378276206
Validation loss: 2.850053278107151

Epoch: 6| Step: 7
Training loss: 3.2454780518020767
Validation loss: 2.8515691869783457

Epoch: 6| Step: 8
Training loss: 3.110817119543532
Validation loss: 2.8517481823368986

Epoch: 6| Step: 9
Training loss: 3.056195835499472
Validation loss: 2.850113771057105

Epoch: 6| Step: 10
Training loss: 3.120595039943554
Validation loss: 2.8521947546657254

Epoch: 6| Step: 11
Training loss: 3.782181806272438
Validation loss: 2.853854352191501

Epoch: 6| Step: 12
Training loss: 3.006717789829265
Validation loss: 2.854711272399469

Epoch: 6| Step: 13
Training loss: 2.604456028438769
Validation loss: 2.8542863015207667

Epoch: 111| Step: 0
Training loss: 2.6605862397409936
Validation loss: 2.854584734173948

Epoch: 6| Step: 1
Training loss: 3.1840289795481667
Validation loss: 2.850611833823917

Epoch: 6| Step: 2
Training loss: 3.1914158124091747
Validation loss: 2.8481323162941

Epoch: 6| Step: 3
Training loss: 2.743347096677101
Validation loss: 2.8507516051594837

Epoch: 6| Step: 4
Training loss: 3.3121513327149867
Validation loss: 2.8527089339423015

Epoch: 6| Step: 5
Training loss: 3.2921661448680015
Validation loss: 2.8530067534267243

Epoch: 6| Step: 6
Training loss: 3.5759790640437887
Validation loss: 2.8524733417716908

Epoch: 6| Step: 7
Training loss: 3.4378084911291507
Validation loss: 2.8527332967505883

Epoch: 6| Step: 8
Training loss: 3.411687867496763
Validation loss: 2.855735204690343

Epoch: 6| Step: 9
Training loss: 3.068533423214544
Validation loss: 2.851725351063697

Epoch: 6| Step: 10
Training loss: 3.0511536902043397
Validation loss: 2.8458374504336192

Epoch: 6| Step: 11
Training loss: 3.106677548248924
Validation loss: 2.8463534311151504

Epoch: 6| Step: 12
Training loss: 3.2264395406353117
Validation loss: 2.8462462523223224

Epoch: 6| Step: 13
Training loss: 1.9732967734279399
Validation loss: 2.8418903556051336

Epoch: 112| Step: 0
Training loss: 3.4715147255551275
Validation loss: 2.8378909935713965

Epoch: 6| Step: 1
Training loss: 3.068385949071351
Validation loss: 2.840829178858012

Epoch: 6| Step: 2
Training loss: 2.782379006962389
Validation loss: 2.8392741704441384

Epoch: 6| Step: 3
Training loss: 3.0671514881136206
Validation loss: 2.8399449634086515

Epoch: 6| Step: 4
Training loss: 2.617037731838837
Validation loss: 2.837003869838307

Epoch: 6| Step: 5
Training loss: 3.235735031417511
Validation loss: 2.8192959113601423

Epoch: 6| Step: 6
Training loss: 3.366373693982024
Validation loss: 2.801847048491052

Epoch: 6| Step: 7
Training loss: 3.0315620812287105
Validation loss: 2.842994324496807

Epoch: 6| Step: 8
Training loss: 3.4798414904570087
Validation loss: 2.8479980657917645

Epoch: 6| Step: 9
Training loss: 3.016870429251089
Validation loss: 2.8503934321691635

Epoch: 6| Step: 10
Training loss: 3.9277971396417892
Validation loss: 2.8462320066674613

Epoch: 6| Step: 11
Training loss: 2.3332247595276585
Validation loss: 2.845085118207733

Epoch: 6| Step: 12
Training loss: 3.413696269419503
Validation loss: 2.8471885328669946

Epoch: 6| Step: 13
Training loss: 2.5184763037918843
Validation loss: 2.839126008056362

Epoch: 113| Step: 0
Training loss: 3.3836663206003394
Validation loss: 2.844035101311694

Epoch: 6| Step: 1
Training loss: 3.5572989795585443
Validation loss: 2.849207352270782

Epoch: 6| Step: 2
Training loss: 2.401698079994642
Validation loss: 2.8368599663534346

Epoch: 6| Step: 3
Training loss: 3.2435746867703275
Validation loss: 2.8410642847235237

Epoch: 6| Step: 4
Training loss: 3.136028209033912
Validation loss: 2.842976153483557

Epoch: 6| Step: 5
Training loss: 3.640559249087723
Validation loss: 2.8437077941611255

Epoch: 6| Step: 6
Training loss: 2.538135253615006
Validation loss: 2.8430109426077834

Epoch: 6| Step: 7
Training loss: 3.0959646601865507
Validation loss: 2.8438014661694937

Epoch: 6| Step: 8
Training loss: 3.248364990951743
Validation loss: 2.8462620200966735

Epoch: 6| Step: 9
Training loss: 3.041758305114158
Validation loss: 2.8413838266675944

Epoch: 6| Step: 10
Training loss: 2.9617843020949772
Validation loss: 2.8517460275011515

Epoch: 6| Step: 11
Training loss: 3.0388170942449615
Validation loss: 2.84581763641646

Epoch: 6| Step: 12
Training loss: 2.685974397788663
Validation loss: 2.844376464484006

Epoch: 6| Step: 13
Training loss: 4.002193326429789
Validation loss: 2.8449175715306736

Epoch: 114| Step: 0
Training loss: 3.575143963242621
Validation loss: 2.865673082683467

Epoch: 6| Step: 1
Training loss: 3.61159377825644
Validation loss: 2.850341015620396

Epoch: 6| Step: 2
Training loss: 2.747470038739191
Validation loss: 2.839164385753427

Epoch: 6| Step: 3
Training loss: 3.106171918229206
Validation loss: 2.8390772365164785

Epoch: 6| Step: 4
Training loss: 3.1804747110796816
Validation loss: 2.8437207038034757

Epoch: 6| Step: 5
Training loss: 2.8344613429064704
Validation loss: 2.843832116449734

Epoch: 6| Step: 6
Training loss: 2.9024237599902865
Validation loss: 2.847847040027422

Epoch: 6| Step: 7
Training loss: 2.7393560762511133
Validation loss: 2.850710241306547

Epoch: 6| Step: 8
Training loss: 2.6878140288234302
Validation loss: 2.854459850060794

Epoch: 6| Step: 9
Training loss: 3.7287836712842872
Validation loss: 2.86417802167587

Epoch: 6| Step: 10
Training loss: 3.0119606643276455
Validation loss: 2.8566981485180714

Epoch: 6| Step: 11
Training loss: 3.511099517846048
Validation loss: 2.858148763880144

Epoch: 6| Step: 12
Training loss: 2.723044938264759
Validation loss: 2.8452517368750727

Epoch: 6| Step: 13
Training loss: 3.3477522525798293
Validation loss: 2.840582582715318

Epoch: 115| Step: 0
Training loss: 3.4228309445705705
Validation loss: 2.8368230720849756

Epoch: 6| Step: 1
Training loss: 3.02994186647754
Validation loss: 2.8341265574801557

Epoch: 6| Step: 2
Training loss: 2.6655527013385574
Validation loss: 2.8323853087187336

Epoch: 6| Step: 3
Training loss: 2.7250442431296706
Validation loss: 2.8363761520801014

Epoch: 6| Step: 4
Training loss: 3.3528676015105754
Validation loss: 2.8332676370183645

Epoch: 6| Step: 5
Training loss: 3.923817430921216
Validation loss: 2.8339613780007076

Epoch: 6| Step: 6
Training loss: 2.426700239822603
Validation loss: 2.8340816311924946

Epoch: 6| Step: 7
Training loss: 3.317647425373425
Validation loss: 2.8320995822989463

Epoch: 6| Step: 8
Training loss: 3.421947182368673
Validation loss: 2.8340797153010673

Epoch: 6| Step: 9
Training loss: 2.844919823453709
Validation loss: 2.8298919384817305

Epoch: 6| Step: 10
Training loss: 3.1026162152037458
Validation loss: 2.83300158122568

Epoch: 6| Step: 11
Training loss: 3.8135484598296046
Validation loss: 2.8328874196102007

Epoch: 6| Step: 12
Training loss: 2.574584749683098
Validation loss: 2.8303771383054315

Epoch: 6| Step: 13
Training loss: 2.5261425719147637
Validation loss: 2.828254667273839

Epoch: 116| Step: 0
Training loss: 2.954787981976476
Validation loss: 2.8307938393689676

Epoch: 6| Step: 1
Training loss: 2.894477380413448
Validation loss: 2.833416554521473

Epoch: 6| Step: 2
Training loss: 2.485618903690005
Validation loss: 2.8322899530174896

Epoch: 6| Step: 3
Training loss: 3.5755766076805817
Validation loss: 2.8348090607253495

Epoch: 6| Step: 4
Training loss: 3.1843368692707545
Validation loss: 2.8316900798145914

Epoch: 6| Step: 5
Training loss: 3.0269989407968825
Validation loss: 2.8326233517780364

Epoch: 6| Step: 6
Training loss: 3.0212015563338603
Validation loss: 2.833052267168002

Epoch: 6| Step: 7
Training loss: 3.643234954603977
Validation loss: 2.832845603964334

Epoch: 6| Step: 8
Training loss: 3.4094529797721007
Validation loss: 2.830353881026337

Epoch: 6| Step: 9
Training loss: 3.1001934421850654
Validation loss: 2.832434940385076

Epoch: 6| Step: 10
Training loss: 2.58172383981651
Validation loss: 2.8252921779964018

Epoch: 6| Step: 11
Training loss: 3.660271804597674
Validation loss: 2.8308302634142546

Epoch: 6| Step: 12
Training loss: 2.5775904245730326
Validation loss: 2.82882106067414

Epoch: 6| Step: 13
Training loss: 3.4656386984854524
Validation loss: 2.8271721201341182

Epoch: 117| Step: 0
Training loss: 3.455773628061914
Validation loss: 2.824926160521998

Epoch: 6| Step: 1
Training loss: 3.6325939481890117
Validation loss: 2.8246340333921

Epoch: 6| Step: 2
Training loss: 3.3652899190134677
Validation loss: 2.8221012519948063

Epoch: 6| Step: 3
Training loss: 2.428934747302371
Validation loss: 2.822230827229713

Epoch: 6| Step: 4
Training loss: 2.9973627260414117
Validation loss: 2.8256962967765364

Epoch: 6| Step: 5
Training loss: 2.169395293610965
Validation loss: 2.8241223451412334

Epoch: 6| Step: 6
Training loss: 3.8995590889948075
Validation loss: 2.823960435088928

Epoch: 6| Step: 7
Training loss: 3.140864576624769
Validation loss: 2.8223629089613484

Epoch: 6| Step: 8
Training loss: 2.9811326233731448
Validation loss: 2.8223181860059836

Epoch: 6| Step: 9
Training loss: 3.026143285168937
Validation loss: 2.8232793019195204

Epoch: 6| Step: 10
Training loss: 2.8400956033008242
Validation loss: 2.8211712609646225

Epoch: 6| Step: 11
Training loss: 2.8876239766510086
Validation loss: 2.82211672771953

Epoch: 6| Step: 12
Training loss: 3.6310008135862706
Validation loss: 2.8172879736383396

Epoch: 6| Step: 13
Training loss: 2.573109875630629
Validation loss: 2.8170631189633304

Epoch: 118| Step: 0
Training loss: 3.154822753908933
Validation loss: 2.7714353529301206

Epoch: 6| Step: 1
Training loss: 3.169042666310827
Validation loss: 2.758038973724496

Epoch: 6| Step: 2
Training loss: 3.1230148113386877
Validation loss: 2.753747918959238

Epoch: 6| Step: 3
Training loss: 2.6725960812546288
Validation loss: 2.752196527303675

Epoch: 6| Step: 4
Training loss: 3.0377316735852635
Validation loss: 2.755700926392447

Epoch: 6| Step: 5
Training loss: 3.0506899694250778
Validation loss: 2.7532741654697444

Epoch: 6| Step: 6
Training loss: 3.4770433414841944
Validation loss: 2.7553779857959753

Epoch: 6| Step: 7
Training loss: 2.736541848613883
Validation loss: 2.7499075806004676

Epoch: 6| Step: 8
Training loss: 3.357107843488937
Validation loss: 2.7510149715058225

Epoch: 6| Step: 9
Training loss: 2.5059356796766092
Validation loss: 2.7490715433994586

Epoch: 6| Step: 10
Training loss: 2.6662143283895365
Validation loss: 2.747821634936563

Epoch: 6| Step: 11
Training loss: 3.2858108067996024
Validation loss: 2.749495519676731

Epoch: 6| Step: 12
Training loss: 3.2607299036718307
Validation loss: 2.7476680914453033

Epoch: 6| Step: 13
Training loss: 3.5848454825967377
Validation loss: 2.745535370780477

Epoch: 119| Step: 0
Training loss: 2.453266115442577
Validation loss: 2.7448616433764483

Epoch: 6| Step: 1
Training loss: 3.4424006814695796
Validation loss: 2.749500383091722

Epoch: 6| Step: 2
Training loss: 3.5504553113348214
Validation loss: 2.7453607000222573

Epoch: 6| Step: 3
Training loss: 3.89142732122476
Validation loss: 2.7491199934937574

Epoch: 6| Step: 4
Training loss: 3.2177199409911896
Validation loss: 2.748723480535851

Epoch: 6| Step: 5
Training loss: 2.0562096820809277
Validation loss: 2.7424941002396457

Epoch: 6| Step: 6
Training loss: 3.114558973610494
Validation loss: 2.7455000318921337

Epoch: 6| Step: 7
Training loss: 2.668845081645658
Validation loss: 2.7476082746171064

Epoch: 6| Step: 8
Training loss: 2.7142123359427393
Validation loss: 2.7475081123364338

Epoch: 6| Step: 9
Training loss: 3.6877186597229787
Validation loss: 2.747359547299856

Epoch: 6| Step: 10
Training loss: 2.262805104627511
Validation loss: 2.744822953061382

Epoch: 6| Step: 11
Training loss: 3.205059081677125
Validation loss: 2.74900974182915

Epoch: 6| Step: 12
Training loss: 2.8233156567425155
Validation loss: 2.750844359701801

Epoch: 6| Step: 13
Training loss: 3.146414056864787
Validation loss: 2.7420257613215324

Epoch: 120| Step: 0
Training loss: 2.7953180849329775
Validation loss: 2.740797379214675

Epoch: 6| Step: 1
Training loss: 3.5626529861528264
Validation loss: 2.7409440523783006

Epoch: 6| Step: 2
Training loss: 2.46347438298311
Validation loss: 2.74136018924854

Epoch: 6| Step: 3
Training loss: 2.501576117550576
Validation loss: 2.7372378774231527

Epoch: 6| Step: 4
Training loss: 3.212248226051574
Validation loss: 2.7399239298940086

Epoch: 6| Step: 5
Training loss: 2.540906688281462
Validation loss: 2.7417354243232177

Epoch: 6| Step: 6
Training loss: 3.4677396110360896
Validation loss: 2.744597575454558

Epoch: 6| Step: 7
Training loss: 3.1442011120855082
Validation loss: 2.742972958751962

Epoch: 6| Step: 8
Training loss: 3.1347948304714284
Validation loss: 2.743417431379852

Epoch: 6| Step: 9
Training loss: 3.289102223353501
Validation loss: 2.7454231430738125

Epoch: 6| Step: 10
Training loss: 4.045427571675322
Validation loss: 2.7436669271993104

Epoch: 6| Step: 11
Training loss: 2.7228627283950813
Validation loss: 2.7413759524461248

Epoch: 6| Step: 12
Training loss: 2.569676468370991
Validation loss: 2.741601826793457

Epoch: 6| Step: 13
Training loss: 2.847798075761352
Validation loss: 2.740733420212787

Epoch: 121| Step: 0
Training loss: 2.5759123583983627
Validation loss: 2.7378995020535988

Epoch: 6| Step: 1
Training loss: 2.5541187084812953
Validation loss: 2.7387397659233432

Epoch: 6| Step: 2
Training loss: 3.3286864474250195
Validation loss: 2.7559746213730008

Epoch: 6| Step: 3
Training loss: 3.3200284230497785
Validation loss: 2.775898096923745

Epoch: 6| Step: 4
Training loss: 3.0732342744476298
Validation loss: 2.790966103677896

Epoch: 6| Step: 5
Training loss: 3.56947553912191
Validation loss: 2.793181345637822

Epoch: 6| Step: 6
Training loss: 2.733693762795152
Validation loss: 2.7716684414505544

Epoch: 6| Step: 7
Training loss: 3.7141798130071204
Validation loss: 2.739708472321689

Epoch: 6| Step: 8
Training loss: 3.1956375068704808
Validation loss: 2.738948268516134

Epoch: 6| Step: 9
Training loss: 2.502562258895802
Validation loss: 2.7364491564345887

Epoch: 6| Step: 10
Training loss: 3.113291665015515
Validation loss: 2.740541345290054

Epoch: 6| Step: 11
Training loss: 2.854450759299951
Validation loss: 2.7397911189180504

Epoch: 6| Step: 12
Training loss: 3.222948909533304
Validation loss: 2.7418474878768193

Epoch: 6| Step: 13
Training loss: 2.6684599350252958
Validation loss: 2.7399202686491106

Epoch: 122| Step: 0
Training loss: 2.7055645997585787
Validation loss: 2.745606697065044

Epoch: 6| Step: 1
Training loss: 2.7876028307093113
Validation loss: 2.7447292179664666

Epoch: 6| Step: 2
Training loss: 3.182033264024651
Validation loss: 2.7379527697258714

Epoch: 6| Step: 3
Training loss: 3.2116529127168607
Validation loss: 2.739389294230123

Epoch: 6| Step: 4
Training loss: 3.071268413334798
Validation loss: 2.7404286361603294

Epoch: 6| Step: 5
Training loss: 2.8402957267992055
Validation loss: 2.738716407237707

Epoch: 6| Step: 6
Training loss: 3.416314331744263
Validation loss: 2.73826434738604

Epoch: 6| Step: 7
Training loss: 3.3547605537665293
Validation loss: 2.738314440760444

Epoch: 6| Step: 8
Training loss: 2.9505006139095555
Validation loss: 2.7401047357856676

Epoch: 6| Step: 9
Training loss: 2.6522953888609293
Validation loss: 2.737638748075833

Epoch: 6| Step: 10
Training loss: 2.4461946206507834
Validation loss: 2.739922970841065

Epoch: 6| Step: 11
Training loss: 3.209385257693411
Validation loss: 2.7439198357512233

Epoch: 6| Step: 12
Training loss: 3.6305257839962684
Validation loss: 2.751770523508437

Epoch: 6| Step: 13
Training loss: 3.1803163848490383
Validation loss: 2.7502586638363815

Epoch: 123| Step: 0
Training loss: 3.252654825288965
Validation loss: 2.7475775903461788

Epoch: 6| Step: 1
Training loss: 2.8154084320271613
Validation loss: 2.7362431533068152

Epoch: 6| Step: 2
Training loss: 3.653335061409349
Validation loss: 2.74029180111795

Epoch: 6| Step: 3
Training loss: 3.450974152734882
Validation loss: 2.736748776309145

Epoch: 6| Step: 4
Training loss: 2.503137527034431
Validation loss: 2.7347911071595536

Epoch: 6| Step: 5
Training loss: 2.460176089737702
Validation loss: 2.738173387548877

Epoch: 6| Step: 6
Training loss: 2.531622211734843
Validation loss: 2.742038452222525

Epoch: 6| Step: 7
Training loss: 3.3700281892497412
Validation loss: 2.74226689615959

Epoch: 6| Step: 8
Training loss: 2.8514303934510288
Validation loss: 2.7462075699596102

Epoch: 6| Step: 9
Training loss: 3.1915682094384334
Validation loss: 2.7444221761743686

Epoch: 6| Step: 10
Training loss: 2.9564740602131754
Validation loss: 2.741278154818241

Epoch: 6| Step: 11
Training loss: 2.7271446327992153
Validation loss: 2.74509095624017

Epoch: 6| Step: 12
Training loss: 3.4271931886699676
Validation loss: 2.7371102224192385

Epoch: 6| Step: 13
Training loss: 3.5275405710592116
Validation loss: 2.733324350296774

Epoch: 124| Step: 0
Training loss: 2.499700719085699
Validation loss: 2.7361963279923285

Epoch: 6| Step: 1
Training loss: 2.8873637179626552
Validation loss: 2.7432973961128537

Epoch: 6| Step: 2
Training loss: 3.1401653807513448
Validation loss: 2.748440969913247

Epoch: 6| Step: 3
Training loss: 3.220970498964589
Validation loss: 2.7457073582062024

Epoch: 6| Step: 4
Training loss: 2.785599982183764
Validation loss: 2.744817780612937

Epoch: 6| Step: 5
Training loss: 2.7848671526359765
Validation loss: 2.7366923760771575

Epoch: 6| Step: 6
Training loss: 2.8355709290893225
Validation loss: 2.734903553683589

Epoch: 6| Step: 7
Training loss: 3.6723027406279076
Validation loss: 2.734607375623673

Epoch: 6| Step: 8
Training loss: 3.37720502241539
Validation loss: 2.7321167304990257

Epoch: 6| Step: 9
Training loss: 3.571525250897416
Validation loss: 2.7318184794669644

Epoch: 6| Step: 10
Training loss: 3.038426192875717
Validation loss: 2.7304447647222627

Epoch: 6| Step: 11
Training loss: 2.623964196158585
Validation loss: 2.7342850283867026

Epoch: 6| Step: 12
Training loss: 2.8364736507327666
Validation loss: 2.736178256781014

Epoch: 6| Step: 13
Training loss: 3.5442698317766235
Validation loss: 2.749823179554622

Epoch: 125| Step: 0
Training loss: 2.9673696420859734
Validation loss: 2.7514404726723867

Epoch: 6| Step: 1
Training loss: 3.464498302695483
Validation loss: 2.7627468670152044

Epoch: 6| Step: 2
Training loss: 2.4115463032066717
Validation loss: 2.763376246717977

Epoch: 6| Step: 3
Training loss: 2.9841885333701277
Validation loss: 2.761987637473836

Epoch: 6| Step: 4
Training loss: 2.6687288555942503
Validation loss: 2.7583178970692637

Epoch: 6| Step: 5
Training loss: 3.2009237029145012
Validation loss: 2.7526260825101865

Epoch: 6| Step: 6
Training loss: 3.564968926721007
Validation loss: 2.7672221556323877

Epoch: 6| Step: 7
Training loss: 2.9818588754685305
Validation loss: 2.7506276558250047

Epoch: 6| Step: 8
Training loss: 3.132274857427219
Validation loss: 2.729670475198911

Epoch: 6| Step: 9
Training loss: 2.229577095062458
Validation loss: 2.726052915919724

Epoch: 6| Step: 10
Training loss: 3.248313906595052
Validation loss: 2.724271091221724

Epoch: 6| Step: 11
Training loss: 3.167857515049681
Validation loss: 2.722991230208915

Epoch: 6| Step: 12
Training loss: 3.4714965943719904
Validation loss: 2.7227718095526208

Epoch: 6| Step: 13
Training loss: 2.885997470465997
Validation loss: 2.7364238688798754

Epoch: 126| Step: 0
Training loss: 3.3986137256751694
Validation loss: 2.743341097220854

Epoch: 6| Step: 1
Training loss: 3.1671859583124022
Validation loss: 2.733954083791553

Epoch: 6| Step: 2
Training loss: 2.2844155700671314
Validation loss: 2.726314555147278

Epoch: 6| Step: 3
Training loss: 2.7346552242013002
Validation loss: 2.7229966785457846

Epoch: 6| Step: 4
Training loss: 2.992947394788487
Validation loss: 2.722469753108396

Epoch: 6| Step: 5
Training loss: 3.1162820901760093
Validation loss: 2.724984174285239

Epoch: 6| Step: 6
Training loss: 2.785869747756496
Validation loss: 2.7224117839068813

Epoch: 6| Step: 7
Training loss: 2.6618709555400604
Validation loss: 2.719871950504367

Epoch: 6| Step: 8
Training loss: 3.3057089234862174
Validation loss: 2.7199267852247297

Epoch: 6| Step: 9
Training loss: 3.157271720263584
Validation loss: 2.7229781916270164

Epoch: 6| Step: 10
Training loss: 2.905766600737896
Validation loss: 2.72407634412577

Epoch: 6| Step: 11
Training loss: 3.489976152923345
Validation loss: 2.728240449544482

Epoch: 6| Step: 12
Training loss: 3.3096005687979617
Validation loss: 2.739754365987663

Epoch: 6| Step: 13
Training loss: 3.1991096450031145
Validation loss: 2.7422047056412038

Epoch: 127| Step: 0
Training loss: 3.640388186369819
Validation loss: 2.765759916625808

Epoch: 6| Step: 1
Training loss: 2.988183751728504
Validation loss: 2.7622073055074186

Epoch: 6| Step: 2
Training loss: 2.381397565139163
Validation loss: 2.755951598530097

Epoch: 6| Step: 3
Training loss: 2.832533293323855
Validation loss: 2.7372227150970945

Epoch: 6| Step: 4
Training loss: 3.0705370638892755
Validation loss: 2.725496420716636

Epoch: 6| Step: 5
Training loss: 3.6318591764095847
Validation loss: 2.7185443040816004

Epoch: 6| Step: 6
Training loss: 2.733531276777236
Validation loss: 2.7208802747289793

Epoch: 6| Step: 7
Training loss: 3.3557205549799933
Validation loss: 2.720028687946528

Epoch: 6| Step: 8
Training loss: 2.800030851194172
Validation loss: 2.7175542181686088

Epoch: 6| Step: 9
Training loss: 2.939720937498771
Validation loss: 2.718730737384303

Epoch: 6| Step: 10
Training loss: 3.3707630264878166
Validation loss: 2.7217939990624616

Epoch: 6| Step: 11
Training loss: 3.006201374509293
Validation loss: 2.7178019981968684

Epoch: 6| Step: 12
Training loss: 2.4926491432373186
Validation loss: 2.721161281891717

Epoch: 6| Step: 13
Training loss: 3.206661598005935
Validation loss: 2.721952723303529

Epoch: 128| Step: 0
Training loss: 2.622426269920322
Validation loss: 2.7137818110456946

Epoch: 6| Step: 1
Training loss: 3.2772192039058385
Validation loss: 2.717009841192716

Epoch: 6| Step: 2
Training loss: 2.8700897745054426
Validation loss: 2.712406044501875

Epoch: 6| Step: 3
Training loss: 2.8753655242757152
Validation loss: 2.7136300202711774

Epoch: 6| Step: 4
Training loss: 3.741093804246674
Validation loss: 2.7140309556346467

Epoch: 6| Step: 5
Training loss: 3.1038573108792917
Validation loss: 2.7153631162524947

Epoch: 6| Step: 6
Training loss: 2.79444831125722
Validation loss: 2.713144851821598

Epoch: 6| Step: 7
Training loss: 2.3463144133174816
Validation loss: 2.714346767760951

Epoch: 6| Step: 8
Training loss: 3.70862553906121
Validation loss: 2.7147406422076354

Epoch: 6| Step: 9
Training loss: 3.2784845233206945
Validation loss: 2.718009702727459

Epoch: 6| Step: 10
Training loss: 2.9460985667721165
Validation loss: 2.710358884697939

Epoch: 6| Step: 11
Training loss: 3.1943899748945093
Validation loss: 2.711128951773614

Epoch: 6| Step: 12
Training loss: 2.8321952404028825
Validation loss: 2.711669654678405

Epoch: 6| Step: 13
Training loss: 2.387761114731063
Validation loss: 2.710870607510721

Epoch: 129| Step: 0
Training loss: 3.3968979428524597
Validation loss: 2.709199750401401

Epoch: 6| Step: 1
Training loss: 3.044275671588239
Validation loss: 2.708494512591016

Epoch: 6| Step: 2
Training loss: 3.1344566692084004
Validation loss: 2.7122098962763017

Epoch: 6| Step: 3
Training loss: 2.2214512030517986
Validation loss: 2.720910455432688

Epoch: 6| Step: 4
Training loss: 2.954805733480193
Validation loss: 2.733537865161248

Epoch: 6| Step: 5
Training loss: 3.04977044664376
Validation loss: 2.7633737938240377

Epoch: 6| Step: 6
Training loss: 3.0137414930390487
Validation loss: 2.743466623296061

Epoch: 6| Step: 7
Training loss: 3.0920315988956735
Validation loss: 2.715491288503259

Epoch: 6| Step: 8
Training loss: 3.4801602039512516
Validation loss: 2.7087530134355884

Epoch: 6| Step: 9
Training loss: 3.1873961787051845
Validation loss: 2.7106748068711157

Epoch: 6| Step: 10
Training loss: 3.2681043056431776
Validation loss: 2.7071480693499255

Epoch: 6| Step: 11
Training loss: 3.225975445043171
Validation loss: 2.708062861893524

Epoch: 6| Step: 12
Training loss: 2.26801095490274
Validation loss: 2.7073836189376754

Epoch: 6| Step: 13
Training loss: 2.828312820183347
Validation loss: 2.706523707819508

Epoch: 130| Step: 0
Training loss: 3.1376570156976586
Validation loss: 2.705772576181313

Epoch: 6| Step: 1
Training loss: 3.3577456759215583
Validation loss: 2.702791866706206

Epoch: 6| Step: 2
Training loss: 3.394146896393389
Validation loss: 2.7037617198296457

Epoch: 6| Step: 3
Training loss: 3.010369499567417
Validation loss: 2.7019167220961053

Epoch: 6| Step: 4
Training loss: 3.6896314764660314
Validation loss: 2.7086727172645553

Epoch: 6| Step: 5
Training loss: 2.994231399981595
Validation loss: 2.713018128814252

Epoch: 6| Step: 6
Training loss: 2.5888303497237666
Validation loss: 2.726374132987244

Epoch: 6| Step: 7
Training loss: 2.625556523502297
Validation loss: 2.7251611595519485

Epoch: 6| Step: 8
Training loss: 2.526169564591297
Validation loss: 2.732842404312448

Epoch: 6| Step: 9
Training loss: 2.8513494542632176
Validation loss: 2.7414177428103392

Epoch: 6| Step: 10
Training loss: 2.86189717437691
Validation loss: 2.7248915283148145

Epoch: 6| Step: 11
Training loss: 3.3952287631147677
Validation loss: 2.723282708925171

Epoch: 6| Step: 12
Training loss: 2.872446335838236
Validation loss: 2.726346128489766

Epoch: 6| Step: 13
Training loss: 2.7767499887238554
Validation loss: 2.7072734577913926

Epoch: 131| Step: 0
Training loss: 3.520540725617646
Validation loss: 2.7053047395334238

Epoch: 6| Step: 1
Training loss: 2.689676335088782
Validation loss: 2.703617384701669

Epoch: 6| Step: 2
Training loss: 3.5420643452292944
Validation loss: 2.7010249299285474

Epoch: 6| Step: 3
Training loss: 2.4687432397677416
Validation loss: 2.701085468955787

Epoch: 6| Step: 4
Training loss: 3.360719065925577
Validation loss: 2.6992427696105636

Epoch: 6| Step: 5
Training loss: 2.9105578254285853
Validation loss: 2.69620076755492

Epoch: 6| Step: 6
Training loss: 3.3740009665948536
Validation loss: 2.6946126591957493

Epoch: 6| Step: 7
Training loss: 3.4535356510454602
Validation loss: 2.697547982112541

Epoch: 6| Step: 8
Training loss: 3.0230042297454833
Validation loss: 2.6960562244797295

Epoch: 6| Step: 9
Training loss: 2.6283697569973468
Validation loss: 2.698888946444355

Epoch: 6| Step: 10
Training loss: 2.573825279346583
Validation loss: 2.6988284132403164

Epoch: 6| Step: 11
Training loss: 2.598440960980999
Validation loss: 2.696934000842172

Epoch: 6| Step: 12
Training loss: 3.1649870852045696
Validation loss: 2.705778685940174

Epoch: 6| Step: 13
Training loss: 2.516352009418145
Validation loss: 2.7033565928712595

Epoch: 132| Step: 0
Training loss: 3.1490340129218315
Validation loss: 2.7206392363670764

Epoch: 6| Step: 1
Training loss: 2.9459639013581733
Validation loss: 2.723538688858428

Epoch: 6| Step: 2
Training loss: 3.759306232080278
Validation loss: 2.75161191957385

Epoch: 6| Step: 3
Training loss: 3.2353637953002212
Validation loss: 2.783785083248588

Epoch: 6| Step: 4
Training loss: 2.5913114919694786
Validation loss: 2.7641758390454605

Epoch: 6| Step: 5
Training loss: 2.479538342052704
Validation loss: 2.7553680098853035

Epoch: 6| Step: 6
Training loss: 2.874882571268605
Validation loss: 2.736501145459001

Epoch: 6| Step: 7
Training loss: 2.955127824061587
Validation loss: 2.7133642989009705

Epoch: 6| Step: 8
Training loss: 2.878123038391704
Validation loss: 2.7055847577277183

Epoch: 6| Step: 9
Training loss: 2.8703931303956365
Validation loss: 2.6976994347704935

Epoch: 6| Step: 10
Training loss: 3.560919695579941
Validation loss: 2.6971091235684637

Epoch: 6| Step: 11
Training loss: 2.974352399079284
Validation loss: 2.694339203020534

Epoch: 6| Step: 12
Training loss: 2.9374250037176814
Validation loss: 2.6949780271354586

Epoch: 6| Step: 13
Training loss: 2.949711517194176
Validation loss: 2.695431770823367

Epoch: 133| Step: 0
Training loss: 3.252056498216218
Validation loss: 2.6964022066738593

Epoch: 6| Step: 1
Training loss: 3.2827392105135558
Validation loss: 2.6957071850868854

Epoch: 6| Step: 2
Training loss: 3.1793461646873418
Validation loss: 2.693521128274554

Epoch: 6| Step: 3
Training loss: 2.4376780127055193
Validation loss: 2.6953699325475227

Epoch: 6| Step: 4
Training loss: 3.395984404466313
Validation loss: 2.696353176308288

Epoch: 6| Step: 5
Training loss: 2.8042992453293456
Validation loss: 2.69605628058197

Epoch: 6| Step: 6
Training loss: 3.0613513271498562
Validation loss: 2.6926962118974225

Epoch: 6| Step: 7
Training loss: 2.905149518103015
Validation loss: 2.69417475744892

Epoch: 6| Step: 8
Training loss: 3.1212083320448776
Validation loss: 2.6979368146292195

Epoch: 6| Step: 9
Training loss: 2.635547157243482
Validation loss: 2.710792966273979

Epoch: 6| Step: 10
Training loss: 3.233620375905872
Validation loss: 2.7122787803498913

Epoch: 6| Step: 11
Training loss: 2.4336072697883884
Validation loss: 2.720278992562298

Epoch: 6| Step: 12
Training loss: 3.6209736529437078
Validation loss: 2.727943726615047

Epoch: 6| Step: 13
Training loss: 2.528286836062897
Validation loss: 2.7047847650480925

Epoch: 134| Step: 0
Training loss: 2.738265577589779
Validation loss: 2.6977943705950933

Epoch: 6| Step: 1
Training loss: 3.3078445252826474
Validation loss: 2.6991603156349653

Epoch: 6| Step: 2
Training loss: 3.256504152890109
Validation loss: 2.7006395673633876

Epoch: 6| Step: 3
Training loss: 3.21602863710853
Validation loss: 2.691842650706534

Epoch: 6| Step: 4
Training loss: 2.3070501081947032
Validation loss: 2.6913172652396984

Epoch: 6| Step: 5
Training loss: 2.715787654873765
Validation loss: 2.6912055381342195

Epoch: 6| Step: 6
Training loss: 3.19936511178863
Validation loss: 2.6920318883641734

Epoch: 6| Step: 7
Training loss: 3.668263968875348
Validation loss: 2.694538755732309

Epoch: 6| Step: 8
Training loss: 3.2242216250252205
Validation loss: 2.6939800643386693

Epoch: 6| Step: 9
Training loss: 3.025134967914106
Validation loss: 2.6886597201357025

Epoch: 6| Step: 10
Training loss: 2.7358087758838563
Validation loss: 2.6897931352094675

Epoch: 6| Step: 11
Training loss: 2.8191122528547097
Validation loss: 2.688595885323963

Epoch: 6| Step: 12
Training loss: 3.0164996049963873
Validation loss: 2.691290416255255

Epoch: 6| Step: 13
Training loss: 2.6021890888046633
Validation loss: 2.688524883084206

Epoch: 135| Step: 0
Training loss: 2.6960329723775582
Validation loss: 2.6893318631440377

Epoch: 6| Step: 1
Training loss: 2.7754504997994753
Validation loss: 2.690032326828509

Epoch: 6| Step: 2
Training loss: 3.600256561038095
Validation loss: 2.6937102813263105

Epoch: 6| Step: 3
Training loss: 2.4718436643058643
Validation loss: 2.7040855203910534

Epoch: 6| Step: 4
Training loss: 2.6712161138488937
Validation loss: 2.694461033985029

Epoch: 6| Step: 5
Training loss: 2.885256178669883
Validation loss: 2.696624998423293

Epoch: 6| Step: 6
Training loss: 3.4220567071475587
Validation loss: 2.7062226513555885

Epoch: 6| Step: 7
Training loss: 3.376369057356528
Validation loss: 2.690861943146761

Epoch: 6| Step: 8
Training loss: 3.3956624243541786
Validation loss: 2.685644474109329

Epoch: 6| Step: 9
Training loss: 2.9861280475303733
Validation loss: 2.684174765367548

Epoch: 6| Step: 10
Training loss: 3.1029784384054273
Validation loss: 2.6837166466999784

Epoch: 6| Step: 11
Training loss: 2.438470109435294
Validation loss: 2.684110399820357

Epoch: 6| Step: 12
Training loss: 2.9719320811216066
Validation loss: 2.6830547435273107

Epoch: 6| Step: 13
Training loss: 3.390814147454939
Validation loss: 2.686746534118538

Epoch: 136| Step: 0
Training loss: 2.747361477942904
Validation loss: 2.6886206534718875

Epoch: 6| Step: 1
Training loss: 3.2390206554634
Validation loss: 2.6834262517933705

Epoch: 6| Step: 2
Training loss: 3.6023263514306856
Validation loss: 2.6867665432050902

Epoch: 6| Step: 3
Training loss: 3.121243928010448
Validation loss: 2.686593520269712

Epoch: 6| Step: 4
Training loss: 2.873926376896983
Validation loss: 2.6852245022023973

Epoch: 6| Step: 5
Training loss: 2.5858464066517843
Validation loss: 2.686944123282057

Epoch: 6| Step: 6
Training loss: 3.2107768146191504
Validation loss: 2.6868089348776807

Epoch: 6| Step: 7
Training loss: 2.441741383248033
Validation loss: 2.6838767650626334

Epoch: 6| Step: 8
Training loss: 3.499846455067052
Validation loss: 2.6858135463732067

Epoch: 6| Step: 9
Training loss: 2.295098480571686
Validation loss: 2.684180999262305

Epoch: 6| Step: 10
Training loss: 3.832783009928463
Validation loss: 2.683826638533832

Epoch: 6| Step: 11
Training loss: 2.4569471190199437
Validation loss: 2.6841248602593435

Epoch: 6| Step: 12
Training loss: 2.775236164388076
Validation loss: 2.68246107385842

Epoch: 6| Step: 13
Training loss: 3.17211146483296
Validation loss: 2.6876449355096885

Epoch: 137| Step: 0
Training loss: 2.884872734132075
Validation loss: 2.700415496728958

Epoch: 6| Step: 1
Training loss: 3.3068035736762367
Validation loss: 2.715970200642971

Epoch: 6| Step: 2
Training loss: 3.0639920395331894
Validation loss: 2.7422323322303677

Epoch: 6| Step: 3
Training loss: 2.6511716879466194
Validation loss: 2.742654818616786

Epoch: 6| Step: 4
Training loss: 3.58571968165053
Validation loss: 2.7544978062435734

Epoch: 6| Step: 5
Training loss: 2.8474980063092334
Validation loss: 2.7421034886623

Epoch: 6| Step: 6
Training loss: 2.1291579911365672
Validation loss: 2.710368628062506

Epoch: 6| Step: 7
Training loss: 2.7003791401598316
Validation loss: 2.695937123446446

Epoch: 6| Step: 8
Training loss: 3.658646279217977
Validation loss: 2.687770347228288

Epoch: 6| Step: 9
Training loss: 3.6059088639830543
Validation loss: 2.685876520503308

Epoch: 6| Step: 10
Training loss: 2.7266940109759634
Validation loss: 2.679119594168548

Epoch: 6| Step: 11
Training loss: 2.4739030584217043
Validation loss: 2.679354890470106

Epoch: 6| Step: 12
Training loss: 3.3211401771704874
Validation loss: 2.6795294858663095

Epoch: 6| Step: 13
Training loss: 2.5369131527757434
Validation loss: 2.680651645283098

Epoch: 138| Step: 0
Training loss: 2.4946076412194307
Validation loss: 2.6844169215276596

Epoch: 6| Step: 1
Training loss: 3.4111539204990353
Validation loss: 2.685178644644356

Epoch: 6| Step: 2
Training loss: 3.343596552955447
Validation loss: 2.6885264621611458

Epoch: 6| Step: 3
Training loss: 2.721423358433082
Validation loss: 2.688526834045073

Epoch: 6| Step: 4
Training loss: 2.436915205227351
Validation loss: 2.6842044199337938

Epoch: 6| Step: 5
Training loss: 2.895303929373361
Validation loss: 2.682780806833661

Epoch: 6| Step: 6
Training loss: 3.6398406268432084
Validation loss: 2.6794119168536046

Epoch: 6| Step: 7
Training loss: 2.777649509859295
Validation loss: 2.6808663735518428

Epoch: 6| Step: 8
Training loss: 2.530398472855017
Validation loss: 2.6883552260793833

Epoch: 6| Step: 9
Training loss: 3.283861846471161
Validation loss: 2.7135858198950342

Epoch: 6| Step: 10
Training loss: 2.8009960140103214
Validation loss: 2.7025912320550103

Epoch: 6| Step: 11
Training loss: 3.152182800646467
Validation loss: 2.72266713858758

Epoch: 6| Step: 12
Training loss: 2.9747041122368603
Validation loss: 2.714332991570803

Epoch: 6| Step: 13
Training loss: 4.023585877876896
Validation loss: 2.7023950440362783

Epoch: 139| Step: 0
Training loss: 3.0168351823586734
Validation loss: 2.6934995598923988

Epoch: 6| Step: 1
Training loss: 3.1843314784616377
Validation loss: 2.6832015414908508

Epoch: 6| Step: 2
Training loss: 2.877215319752038
Validation loss: 2.6765223875000204

Epoch: 6| Step: 3
Training loss: 2.43211003564063
Validation loss: 2.6772519114377333

Epoch: 6| Step: 4
Training loss: 3.6010649165663753
Validation loss: 2.678066575053982

Epoch: 6| Step: 5
Training loss: 2.736017747330689
Validation loss: 2.679809112166652

Epoch: 6| Step: 6
Training loss: 2.781119611448305
Validation loss: 2.676604900954892

Epoch: 6| Step: 7
Training loss: 3.5015299041878643
Validation loss: 2.677432222368771

Epoch: 6| Step: 8
Training loss: 3.0520448302529934
Validation loss: 2.6792610656931517

Epoch: 6| Step: 9
Training loss: 3.2469556194499694
Validation loss: 2.6788496266176196

Epoch: 6| Step: 10
Training loss: 2.959015798873984
Validation loss: 2.681962514757365

Epoch: 6| Step: 11
Training loss: 2.760718438309814
Validation loss: 2.6911689132979495

Epoch: 6| Step: 12
Training loss: 2.833738709415917
Validation loss: 2.6873998139183075

Epoch: 6| Step: 13
Training loss: 3.0215134129179964
Validation loss: 2.677643057423639

Epoch: 140| Step: 0
Training loss: 2.2423887793816504
Validation loss: 2.6794340846822253

Epoch: 6| Step: 1
Training loss: 2.244432979760092
Validation loss: 2.6759873809830843

Epoch: 6| Step: 2
Training loss: 2.3305328002271435
Validation loss: 2.678919461322574

Epoch: 6| Step: 3
Training loss: 3.283915862739892
Validation loss: 2.67742378582534

Epoch: 6| Step: 4
Training loss: 2.5343558013226466
Validation loss: 2.673356178238658

Epoch: 6| Step: 5
Training loss: 2.7580609520365797
Validation loss: 2.6774220082208964

Epoch: 6| Step: 6
Training loss: 3.1068457663432096
Validation loss: 2.6898168920640186

Epoch: 6| Step: 7
Training loss: 3.4974051802286135
Validation loss: 2.6824251754385555

Epoch: 6| Step: 8
Training loss: 3.111757985106415
Validation loss: 2.682419189773285

Epoch: 6| Step: 9
Training loss: 3.5541520941652838
Validation loss: 2.680663748818704

Epoch: 6| Step: 10
Training loss: 3.214087507403777
Validation loss: 2.6751862537096756

Epoch: 6| Step: 11
Training loss: 3.0077960125359806
Validation loss: 2.6789513693220055

Epoch: 6| Step: 12
Training loss: 3.201201070451063
Validation loss: 2.673593745135055

Epoch: 6| Step: 13
Training loss: 3.939007667241572
Validation loss: 2.6733850859202306

Epoch: 141| Step: 0
Training loss: 2.584207007634428
Validation loss: 2.67654542980207

Epoch: 6| Step: 1
Training loss: 2.9746427177218617
Validation loss: 2.678443391477287

Epoch: 6| Step: 2
Training loss: 3.4084213755334534
Validation loss: 2.6790209075967226

Epoch: 6| Step: 3
Training loss: 3.2920279646620845
Validation loss: 2.6802904764945117

Epoch: 6| Step: 4
Training loss: 3.562099501199442
Validation loss: 2.685266862845871

Epoch: 6| Step: 5
Training loss: 2.2968326486848043
Validation loss: 2.6868217129332046

Epoch: 6| Step: 6
Training loss: 2.8687294288180265
Validation loss: 2.685218661212024

Epoch: 6| Step: 7
Training loss: 3.282061086045502
Validation loss: 2.687717802852266

Epoch: 6| Step: 8
Training loss: 3.1685657996938845
Validation loss: 2.677713896313468

Epoch: 6| Step: 9
Training loss: 2.673128781979347
Validation loss: 2.6761098184661307

Epoch: 6| Step: 10
Training loss: 3.0164550271446338
Validation loss: 2.6722729193576296

Epoch: 6| Step: 11
Training loss: 2.7043697600273147
Validation loss: 2.675233698900516

Epoch: 6| Step: 12
Training loss: 2.659485226777497
Validation loss: 2.6767998569985734

Epoch: 6| Step: 13
Training loss: 3.5427854379086545
Validation loss: 2.674507057014242

Epoch: 142| Step: 0
Training loss: 3.3485868177706637
Validation loss: 2.676200876071294

Epoch: 6| Step: 1
Training loss: 4.02004630863979
Validation loss: 2.6726123526635504

Epoch: 6| Step: 2
Training loss: 1.946015625392052
Validation loss: 2.6733883012751476

Epoch: 6| Step: 3
Training loss: 3.3476915747115252
Validation loss: 2.675631339126296

Epoch: 6| Step: 4
Training loss: 3.31011056190996
Validation loss: 2.6736820540924056

Epoch: 6| Step: 5
Training loss: 2.741022367823846
Validation loss: 2.673477836280573

Epoch: 6| Step: 6
Training loss: 2.6263894536406487
Validation loss: 2.6734795963702855

Epoch: 6| Step: 7
Training loss: 3.0135793121620207
Validation loss: 2.6737461855201583

Epoch: 6| Step: 8
Training loss: 2.3090497646065766
Validation loss: 2.6783364119123

Epoch: 6| Step: 9
Training loss: 3.1601440278560777
Validation loss: 2.6766184585185346

Epoch: 6| Step: 10
Training loss: 2.931160437022914
Validation loss: 2.6826102915274066

Epoch: 6| Step: 11
Training loss: 2.428735086392307
Validation loss: 2.688607850116177

Epoch: 6| Step: 12
Training loss: 3.037641570634282
Validation loss: 2.7060519685407884

Epoch: 6| Step: 13
Training loss: 3.4984394409119783
Validation loss: 2.689919557081856

Epoch: 143| Step: 0
Training loss: 2.838785722139081
Validation loss: 2.6740866397773364

Epoch: 6| Step: 1
Training loss: 3.203869691206242
Validation loss: 2.672235978434451

Epoch: 6| Step: 2
Training loss: 3.357298027093307
Validation loss: 2.6696979572147574

Epoch: 6| Step: 3
Training loss: 2.930983111954669
Validation loss: 2.6680179358936593

Epoch: 6| Step: 4
Training loss: 2.9896712517299306
Validation loss: 2.6714489116198465

Epoch: 6| Step: 5
Training loss: 2.2994198357663445
Validation loss: 2.6689246069232913

Epoch: 6| Step: 6
Training loss: 3.3246298332960893
Validation loss: 2.6664707431678276

Epoch: 6| Step: 7
Training loss: 2.789726114263287
Validation loss: 2.6710165146591476

Epoch: 6| Step: 8
Training loss: 2.6220432159330826
Validation loss: 2.6635720141854473

Epoch: 6| Step: 9
Training loss: 3.294595373197702
Validation loss: 2.666901936330255

Epoch: 6| Step: 10
Training loss: 3.04636038322334
Validation loss: 2.6688780677773694

Epoch: 6| Step: 11
Training loss: 2.9427508235778252
Validation loss: 2.6683208173404864

Epoch: 6| Step: 12
Training loss: 3.3262779590760534
Validation loss: 2.67170006558883

Epoch: 6| Step: 13
Training loss: 2.774770582871157
Validation loss: 2.675289248282072

Epoch: 144| Step: 0
Training loss: 2.609049337017827
Validation loss: 2.683821884407555

Epoch: 6| Step: 1
Training loss: 2.2370051129708584
Validation loss: 2.7072669101282596

Epoch: 6| Step: 2
Training loss: 3.0131012629151805
Validation loss: 2.723855913464486

Epoch: 6| Step: 3
Training loss: 3.243054377473721
Validation loss: 2.7427147023494407

Epoch: 6| Step: 4
Training loss: 2.9782476185776554
Validation loss: 2.7271156707768904

Epoch: 6| Step: 5
Training loss: 3.197214320755147
Validation loss: 2.7248406453091647

Epoch: 6| Step: 6
Training loss: 3.3388710434772264
Validation loss: 2.68752031158838

Epoch: 6| Step: 7
Training loss: 2.7750330673859454
Validation loss: 2.6602769799321897

Epoch: 6| Step: 8
Training loss: 2.8211221563049476
Validation loss: 2.668564332414784

Epoch: 6| Step: 9
Training loss: 3.146944435058196
Validation loss: 2.6754479478750155

Epoch: 6| Step: 10
Training loss: 3.2750013162158913
Validation loss: 2.6822839931366724

Epoch: 6| Step: 11
Training loss: 3.172642206322033
Validation loss: 2.6960191292322517

Epoch: 6| Step: 12
Training loss: 3.1733464177714064
Validation loss: 2.736307359673603

Epoch: 6| Step: 13
Training loss: 3.308654280179776
Validation loss: 2.808830591142482

Epoch: 145| Step: 0
Training loss: 3.3581938330466423
Validation loss: 2.8425177124492094

Epoch: 6| Step: 1
Training loss: 3.337717193508577
Validation loss: 2.7916601028206043

Epoch: 6| Step: 2
Training loss: 2.931772370145179
Validation loss: 2.7350815917447826

Epoch: 6| Step: 3
Training loss: 3.380791675015412
Validation loss: 2.6770382789551155

Epoch: 6| Step: 4
Training loss: 3.12139226562496
Validation loss: 2.668588830643652

Epoch: 6| Step: 5
Training loss: 2.74848011671275
Validation loss: 2.673668940926891

Epoch: 6| Step: 6
Training loss: 2.5440973218140317
Validation loss: 2.686205354420317

Epoch: 6| Step: 7
Training loss: 3.089650684599189
Validation loss: 2.7599035682792223

Epoch: 6| Step: 8
Training loss: 3.3996024404229517
Validation loss: 2.835057594574582

Epoch: 6| Step: 9
Training loss: 3.310209381995182
Validation loss: 2.842734435766936

Epoch: 6| Step: 10
Training loss: 3.764983063111325
Validation loss: 2.848537957489817

Epoch: 6| Step: 11
Training loss: 2.1827101446577926
Validation loss: 2.7709413023668845

Epoch: 6| Step: 12
Training loss: 2.7976233477496617
Validation loss: 2.696597207859437

Epoch: 6| Step: 13
Training loss: 2.221042684262543
Validation loss: 2.669362910153495

Epoch: 146| Step: 0
Training loss: 3.133621225590871
Validation loss: 2.665870737751986

Epoch: 6| Step: 1
Training loss: 3.273592487753921
Validation loss: 2.6691152485370035

Epoch: 6| Step: 2
Training loss: 2.847998830023536
Validation loss: 2.6674233626855184

Epoch: 6| Step: 3
Training loss: 2.7130510956971987
Validation loss: 2.66713689848386

Epoch: 6| Step: 4
Training loss: 2.811340856105891
Validation loss: 2.6675883435305203

Epoch: 6| Step: 5
Training loss: 2.895840285770843
Validation loss: 2.6672226251933644

Epoch: 6| Step: 6
Training loss: 3.3653959035160104
Validation loss: 2.670148392233362

Epoch: 6| Step: 7
Training loss: 2.857659163827353
Validation loss: 2.6666619909025036

Epoch: 6| Step: 8
Training loss: 2.433378011040763
Validation loss: 2.6686814715146174

Epoch: 6| Step: 9
Training loss: 3.1090127551828486
Validation loss: 2.6701142312415747

Epoch: 6| Step: 10
Training loss: 3.3884917549392113
Validation loss: 2.668643905445483

Epoch: 6| Step: 11
Training loss: 3.1457003297962713
Validation loss: 2.667820550729614

Epoch: 6| Step: 12
Training loss: 2.2972892335801753
Validation loss: 2.6676214249670243

Epoch: 6| Step: 13
Training loss: 3.9514750177210822
Validation loss: 2.6641583861927614

Epoch: 147| Step: 0
Training loss: 3.0706552406404337
Validation loss: 2.660726406422294

Epoch: 6| Step: 1
Training loss: 3.152024868668564
Validation loss: 2.6645726084921275

Epoch: 6| Step: 2
Training loss: 3.3262776723668943
Validation loss: 2.663110223322001

Epoch: 6| Step: 3
Training loss: 3.578469738740506
Validation loss: 2.6625930331965812

Epoch: 6| Step: 4
Training loss: 3.461469691155843
Validation loss: 2.6621300599146074

Epoch: 6| Step: 5
Training loss: 2.879223582196995
Validation loss: 2.6623466368574413

Epoch: 6| Step: 6
Training loss: 2.1634743232023257
Validation loss: 2.6630729704669256

Epoch: 6| Step: 7
Training loss: 2.4671270129934917
Validation loss: 2.663291293385648

Epoch: 6| Step: 8
Training loss: 2.566375407087307
Validation loss: 2.659968524589043

Epoch: 6| Step: 9
Training loss: 2.5693042018065704
Validation loss: 2.665364474966601

Epoch: 6| Step: 10
Training loss: 2.7513544041860696
Validation loss: 2.6735089534026883

Epoch: 6| Step: 11
Training loss: 2.5203067975769047
Validation loss: 2.6696941324420194

Epoch: 6| Step: 12
Training loss: 3.3764083184553626
Validation loss: 2.6837666959982736

Epoch: 6| Step: 13
Training loss: 4.069932681939894
Validation loss: 2.682592611915802

Epoch: 148| Step: 0
Training loss: 3.107559057213134
Validation loss: 2.6746496926682486

Epoch: 6| Step: 1
Training loss: 2.2459951362523234
Validation loss: 2.669791116538737

Epoch: 6| Step: 2
Training loss: 3.169445592010971
Validation loss: 2.658915919748752

Epoch: 6| Step: 3
Training loss: 3.113075393131415
Validation loss: 2.6624033207710487

Epoch: 6| Step: 4
Training loss: 3.12490981925543
Validation loss: 2.6636774385486737

Epoch: 6| Step: 5
Training loss: 2.780957495920463
Validation loss: 2.662182788169006

Epoch: 6| Step: 6
Training loss: 3.1503718565389476
Validation loss: 2.6632360097080845

Epoch: 6| Step: 7
Training loss: 3.0315314093461163
Validation loss: 2.6647190546420623

Epoch: 6| Step: 8
Training loss: 2.827462050152053
Validation loss: 2.6671409864462263

Epoch: 6| Step: 9
Training loss: 3.0656794956352655
Validation loss: 2.671933037075316

Epoch: 6| Step: 10
Training loss: 3.087246310665031
Validation loss: 2.667663648058544

Epoch: 6| Step: 11
Training loss: 3.0929542828303673
Validation loss: 2.664788277413757

Epoch: 6| Step: 12
Training loss: 3.2628883686055588
Validation loss: 2.6549910590662402

Epoch: 6| Step: 13
Training loss: 2.385696217066312
Validation loss: 2.6555342499530794

Epoch: 149| Step: 0
Training loss: 3.3000230268195194
Validation loss: 2.655925854974426

Epoch: 6| Step: 1
Training loss: 3.4724306391578517
Validation loss: 2.656389825121784

Epoch: 6| Step: 2
Training loss: 2.8404854281709255
Validation loss: 2.6556302036985113

Epoch: 6| Step: 3
Training loss: 2.534566519729188
Validation loss: 2.647482920648931

Epoch: 6| Step: 4
Training loss: 3.1542302080319424
Validation loss: 2.6509588655631013

Epoch: 6| Step: 5
Training loss: 3.0851422407846973
Validation loss: 2.649812188229253

Epoch: 6| Step: 6
Training loss: 2.6387434356044
Validation loss: 2.648131408242975

Epoch: 6| Step: 7
Training loss: 3.2226059418421737
Validation loss: 2.65144643834903

Epoch: 6| Step: 8
Training loss: 3.1625998801641284
Validation loss: 2.6593330939216115

Epoch: 6| Step: 9
Training loss: 2.7648629900631243
Validation loss: 2.655774672732792

Epoch: 6| Step: 10
Training loss: 3.0777311896123574
Validation loss: 2.666694898289268

Epoch: 6| Step: 11
Training loss: 2.7538650401393596
Validation loss: 2.6530077348407595

Epoch: 6| Step: 12
Training loss: 2.945317033111565
Validation loss: 2.6586768744951326

Epoch: 6| Step: 13
Training loss: 2.499216147561848
Validation loss: 2.6536868850788524

Epoch: 150| Step: 0
Training loss: 3.019352324046678
Validation loss: 2.6569728150163403

Epoch: 6| Step: 1
Training loss: 3.7324810252949727
Validation loss: 2.659475451228754

Epoch: 6| Step: 2
Training loss: 3.1082384342164664
Validation loss: 2.6592515002523687

Epoch: 6| Step: 3
Training loss: 3.4850397545012455
Validation loss: 2.6594839292853725

Epoch: 6| Step: 4
Training loss: 2.740213493327422
Validation loss: 2.6551072540474263

Epoch: 6| Step: 5
Training loss: 2.6112696912871267
Validation loss: 2.644812984930157

Epoch: 6| Step: 6
Training loss: 2.665188280221636
Validation loss: 2.647335245035408

Epoch: 6| Step: 7
Training loss: 2.8183773090429054
Validation loss: 2.6446849012343874

Epoch: 6| Step: 8
Training loss: 2.8840431956576076
Validation loss: 2.644942684967302

Epoch: 6| Step: 9
Training loss: 3.150162368707167
Validation loss: 2.6444716072163916

Epoch: 6| Step: 10
Training loss: 2.623902591013795
Validation loss: 2.64605110980116

Epoch: 6| Step: 11
Training loss: 2.8632366182145628
Validation loss: 2.6401045120582745

Epoch: 6| Step: 12
Training loss: 2.65441112819774
Validation loss: 2.645903502032762

Epoch: 6| Step: 13
Training loss: 3.332872756291687
Validation loss: 2.647979493449245

Epoch: 151| Step: 0
Training loss: 3.2496375835527376
Validation loss: 2.6493103706887635

Epoch: 6| Step: 1
Training loss: 3.269939292320863
Validation loss: 2.6604165394426342

Epoch: 6| Step: 2
Training loss: 2.021473996048235
Validation loss: 2.668520904449974

Epoch: 6| Step: 3
Training loss: 3.0512332361644545
Validation loss: 2.6840215112997123

Epoch: 6| Step: 4
Training loss: 2.4719859294861273
Validation loss: 2.6951364824443473

Epoch: 6| Step: 5
Training loss: 3.6288100641518084
Validation loss: 2.7024752004024224

Epoch: 6| Step: 6
Training loss: 2.7811521877276855
Validation loss: 2.6863236863743234

Epoch: 6| Step: 7
Training loss: 2.749008693621652
Validation loss: 2.670737989322765

Epoch: 6| Step: 8
Training loss: 2.5375146461402385
Validation loss: 2.668504499533685

Epoch: 6| Step: 9
Training loss: 3.377746877054896
Validation loss: 2.6610502152439417

Epoch: 6| Step: 10
Training loss: 3.313933440217441
Validation loss: 2.654538130304724

Epoch: 6| Step: 11
Training loss: 3.481189451940985
Validation loss: 2.641276947566244

Epoch: 6| Step: 12
Training loss: 2.5888240872496766
Validation loss: 2.645965980445462

Epoch: 6| Step: 13
Training loss: 2.685739517238328
Validation loss: 2.6527909013662323

Epoch: 152| Step: 0
Training loss: 3.6204660935433535
Validation loss: 2.6512927012999206

Epoch: 6| Step: 1
Training loss: 2.6514794088819733
Validation loss: 2.6603912904526017

Epoch: 6| Step: 2
Training loss: 2.585922010669245
Validation loss: 2.6688012788138162

Epoch: 6| Step: 3
Training loss: 3.199787764663713
Validation loss: 2.681529677330521

Epoch: 6| Step: 4
Training loss: 3.0899835644133655
Validation loss: 2.6955129326855203

Epoch: 6| Step: 5
Training loss: 3.006580447238652
Validation loss: 2.6923325505850646

Epoch: 6| Step: 6
Training loss: 2.823092202972977
Validation loss: 2.6932967766749365

Epoch: 6| Step: 7
Training loss: 2.6513544184199884
Validation loss: 2.6687975545793603

Epoch: 6| Step: 8
Training loss: 3.667517621102676
Validation loss: 2.6634877790587117

Epoch: 6| Step: 9
Training loss: 3.0905060377841163
Validation loss: 2.6566481984889068

Epoch: 6| Step: 10
Training loss: 2.804170608706677
Validation loss: 2.6522528089868054

Epoch: 6| Step: 11
Training loss: 3.250145542113749
Validation loss: 2.649203948803107

Epoch: 6| Step: 12
Training loss: 2.692672719418639
Validation loss: 2.6460075211267275

Epoch: 6| Step: 13
Training loss: 2.7806885399035486
Validation loss: 2.645543925998898

Epoch: 153| Step: 0
Training loss: 2.9906652178795556
Validation loss: 2.6486345225657537

Epoch: 6| Step: 1
Training loss: 2.4509169244589595
Validation loss: 2.6528301569576547

Epoch: 6| Step: 2
Training loss: 2.741182235388122
Validation loss: 2.6534354743919497

Epoch: 6| Step: 3
Training loss: 3.0804693134490195
Validation loss: 2.6566289198360242

Epoch: 6| Step: 4
Training loss: 2.8525049611749727
Validation loss: 2.658287505163294

Epoch: 6| Step: 5
Training loss: 3.043947975566288
Validation loss: 2.659566407460914

Epoch: 6| Step: 6
Training loss: 2.4994387950420256
Validation loss: 2.6560597302732782

Epoch: 6| Step: 7
Training loss: 2.964513385847358
Validation loss: 2.662155377638429

Epoch: 6| Step: 8
Training loss: 2.9326895426367945
Validation loss: 2.656633187052157

Epoch: 6| Step: 9
Training loss: 3.2498424198388727
Validation loss: 2.6753895826750944

Epoch: 6| Step: 10
Training loss: 3.588084922185298
Validation loss: 2.6696032850365587

Epoch: 6| Step: 11
Training loss: 2.8388065506187523
Validation loss: 2.666837744134545

Epoch: 6| Step: 12
Training loss: 3.117205244506199
Validation loss: 2.660970347693709

Epoch: 6| Step: 13
Training loss: 3.551315552785551
Validation loss: 2.6543082724350997

Epoch: 154| Step: 0
Training loss: 2.922458202888766
Validation loss: 2.6475966574345504

Epoch: 6| Step: 1
Training loss: 3.5913705660972646
Validation loss: 2.641915784671447

Epoch: 6| Step: 2
Training loss: 3.6495639279253176
Validation loss: 2.6410213104376186

Epoch: 6| Step: 3
Training loss: 2.4021641113603613
Validation loss: 2.64308400058831

Epoch: 6| Step: 4
Training loss: 3.078493667444851
Validation loss: 2.642308165164807

Epoch: 6| Step: 5
Training loss: 3.016822695692621
Validation loss: 2.6409097163535753

Epoch: 6| Step: 6
Training loss: 2.9367924913635117
Validation loss: 2.6435574978926306

Epoch: 6| Step: 7
Training loss: 2.8784928044369527
Validation loss: 2.641267068714574

Epoch: 6| Step: 8
Training loss: 3.0003714331524756
Validation loss: 2.64448807397071

Epoch: 6| Step: 9
Training loss: 3.0400163188295553
Validation loss: 2.637421377884471

Epoch: 6| Step: 10
Training loss: 2.342214055639254
Validation loss: 2.638974808994466

Epoch: 6| Step: 11
Training loss: 2.4669225182026753
Validation loss: 2.6381233803669284

Epoch: 6| Step: 12
Training loss: 3.3389672986508807
Validation loss: 2.641707167841105

Epoch: 6| Step: 13
Training loss: 2.7204608138406137
Validation loss: 2.642731299987209

Epoch: 155| Step: 0
Training loss: 2.7170195937308375
Validation loss: 2.645181078584198

Epoch: 6| Step: 1
Training loss: 2.953875088167918
Validation loss: 2.6647015786215533

Epoch: 6| Step: 2
Training loss: 3.0446572081695487
Validation loss: 2.679818146758422

Epoch: 6| Step: 3
Training loss: 2.9586733412229673
Validation loss: 2.6799291853731346

Epoch: 6| Step: 4
Training loss: 3.12817831537045
Validation loss: 2.6840728357439723

Epoch: 6| Step: 5
Training loss: 2.9155305738787374
Validation loss: 2.6704930356796437

Epoch: 6| Step: 6
Training loss: 3.1098465298384017
Validation loss: 2.6700113807826806

Epoch: 6| Step: 7
Training loss: 2.89036567143322
Validation loss: 2.671458289247175

Epoch: 6| Step: 8
Training loss: 3.4152849396312557
Validation loss: 2.664676383703333

Epoch: 6| Step: 9
Training loss: 2.00182211842692
Validation loss: 2.6510493916248836

Epoch: 6| Step: 10
Training loss: 3.6158092666133337
Validation loss: 2.653553390514967

Epoch: 6| Step: 11
Training loss: 2.967888154865759
Validation loss: 2.647765263260353

Epoch: 6| Step: 12
Training loss: 2.5761572524343346
Validation loss: 2.6330422632573924

Epoch: 6| Step: 13
Training loss: 3.2736395361559136
Validation loss: 2.6311239014603087

Epoch: 156| Step: 0
Training loss: 2.8292365655892726
Validation loss: 2.633346073648899

Epoch: 6| Step: 1
Training loss: 3.2164167817716813
Validation loss: 2.6343858974414687

Epoch: 6| Step: 2
Training loss: 2.7874770159265614
Validation loss: 2.635091176317063

Epoch: 6| Step: 3
Training loss: 2.9658638828808956
Validation loss: 2.6351544636710167

Epoch: 6| Step: 4
Training loss: 2.931638673175566
Validation loss: 2.639782886770817

Epoch: 6| Step: 5
Training loss: 3.4861508620901582
Validation loss: 2.637279913286432

Epoch: 6| Step: 6
Training loss: 2.4449468467255047
Validation loss: 2.640137044529106

Epoch: 6| Step: 7
Training loss: 3.2314014864151823
Validation loss: 2.6411647547166197

Epoch: 6| Step: 8
Training loss: 3.1971573482162134
Validation loss: 2.645715437796133

Epoch: 6| Step: 9
Training loss: 2.9613152819064266
Validation loss: 2.643412050816362

Epoch: 6| Step: 10
Training loss: 2.770195584054233
Validation loss: 2.65078553537248

Epoch: 6| Step: 11
Training loss: 2.701849311178805
Validation loss: 2.64762660743459

Epoch: 6| Step: 12
Training loss: 3.4401492920350503
Validation loss: 2.6480651384620577

Epoch: 6| Step: 13
Training loss: 2.517120674899079
Validation loss: 2.648233495680106

Epoch: 157| Step: 0
Training loss: 2.770042727309564
Validation loss: 2.651799559477521

Epoch: 6| Step: 1
Training loss: 2.830842625023752
Validation loss: 2.657295481673132

Epoch: 6| Step: 2
Training loss: 2.8877398965107473
Validation loss: 2.658475521892254

Epoch: 6| Step: 3
Training loss: 3.7354201127288347
Validation loss: 2.669419301023637

Epoch: 6| Step: 4
Training loss: 2.7387718381581254
Validation loss: 2.680012884361581

Epoch: 6| Step: 5
Training loss: 2.2899341160654405
Validation loss: 2.6763194444196383

Epoch: 6| Step: 6
Training loss: 2.3859188656182315
Validation loss: 2.6858471650217677

Epoch: 6| Step: 7
Training loss: 2.9455384994941
Validation loss: 2.686128930997416

Epoch: 6| Step: 8
Training loss: 2.9786995652731902
Validation loss: 2.6913427108493413

Epoch: 6| Step: 9
Training loss: 2.957190404763761
Validation loss: 2.6973267293228593

Epoch: 6| Step: 10
Training loss: 2.8392397147648434
Validation loss: 2.6745747017770056

Epoch: 6| Step: 11
Training loss: 3.538228793607141
Validation loss: 2.6660370859025098

Epoch: 6| Step: 12
Training loss: 3.026730816227126
Validation loss: 2.6477712004281866

Epoch: 6| Step: 13
Training loss: 3.954209250625148
Validation loss: 2.6422275501390877

Epoch: 158| Step: 0
Training loss: 2.2766590692254676
Validation loss: 2.635666143096078

Epoch: 6| Step: 1
Training loss: 3.0588285275673055
Validation loss: 2.6335558132455046

Epoch: 6| Step: 2
Training loss: 2.5551642576745452
Validation loss: 2.635810449738131

Epoch: 6| Step: 3
Training loss: 2.7778470083722406
Validation loss: 2.6341939107452874

Epoch: 6| Step: 4
Training loss: 2.516288527654716
Validation loss: 2.6314356122788096

Epoch: 6| Step: 5
Training loss: 3.3347866387010696
Validation loss: 2.6379301083120934

Epoch: 6| Step: 6
Training loss: 3.298116007451587
Validation loss: 2.6375551805943216

Epoch: 6| Step: 7
Training loss: 3.443142785126625
Validation loss: 2.6361107269586737

Epoch: 6| Step: 8
Training loss: 2.497433871290146
Validation loss: 2.6388466265118162

Epoch: 6| Step: 9
Training loss: 2.6350607851606953
Validation loss: 2.637529524188026

Epoch: 6| Step: 10
Training loss: 3.067811369447402
Validation loss: 2.6369168241263017

Epoch: 6| Step: 11
Training loss: 2.8938267477251656
Validation loss: 2.635081513605691

Epoch: 6| Step: 12
Training loss: 3.433228213975628
Validation loss: 2.6359466839483305

Epoch: 6| Step: 13
Training loss: 3.902589593576126
Validation loss: 2.636385037942582

Epoch: 159| Step: 0
Training loss: 3.3749473002522543
Validation loss: 2.6385518713916523

Epoch: 6| Step: 1
Training loss: 3.2762871404156013
Validation loss: 2.635063996689108

Epoch: 6| Step: 2
Training loss: 2.4421090785228676
Validation loss: 2.6336763842188318

Epoch: 6| Step: 3
Training loss: 3.037586942456693
Validation loss: 2.636408104320448

Epoch: 6| Step: 4
Training loss: 2.946858210429869
Validation loss: 2.632598960797442

Epoch: 6| Step: 5
Training loss: 2.8047175923807828
Validation loss: 2.6381914109377753

Epoch: 6| Step: 6
Training loss: 2.678896951422875
Validation loss: 2.6428957754909645

Epoch: 6| Step: 7
Training loss: 2.99639198778431
Validation loss: 2.6458422216825346

Epoch: 6| Step: 8
Training loss: 2.973874778486834
Validation loss: 2.637411055926286

Epoch: 6| Step: 9
Training loss: 2.9570812387411083
Validation loss: 2.6517268024272944

Epoch: 6| Step: 10
Training loss: 2.731523258323183
Validation loss: 2.648479132591706

Epoch: 6| Step: 11
Training loss: 2.9468897636100384
Validation loss: 2.6468803757001567

Epoch: 6| Step: 12
Training loss: 3.58444042994172
Validation loss: 2.6492293886055447

Epoch: 6| Step: 13
Training loss: 2.2832444760744335
Validation loss: 2.6456640310641855

Epoch: 160| Step: 0
Training loss: 2.1033505912512056
Validation loss: 2.6481752441532556

Epoch: 6| Step: 1
Training loss: 3.152139687817028
Validation loss: 2.642375780439956

Epoch: 6| Step: 2
Training loss: 2.9975028771521064
Validation loss: 2.6446170793865442

Epoch: 6| Step: 3
Training loss: 2.6122944655173836
Validation loss: 2.638354969432541

Epoch: 6| Step: 4
Training loss: 3.226664617737469
Validation loss: 2.6351573569598807

Epoch: 6| Step: 5
Training loss: 2.9143799309767555
Validation loss: 2.6314000153846004

Epoch: 6| Step: 6
Training loss: 3.1804980995137764
Validation loss: 2.631945408138654

Epoch: 6| Step: 7
Training loss: 3.0975387955053355
Validation loss: 2.6330612531032243

Epoch: 6| Step: 8
Training loss: 2.651627051894528
Validation loss: 2.631065352976133

Epoch: 6| Step: 9
Training loss: 3.0030930786341656
Validation loss: 2.63160380981026

Epoch: 6| Step: 10
Training loss: 2.9863994981558393
Validation loss: 2.628925815327782

Epoch: 6| Step: 11
Training loss: 3.0966224051584645
Validation loss: 2.6339434347915467

Epoch: 6| Step: 12
Training loss: 3.3544471260164817
Validation loss: 2.640284951373781

Epoch: 6| Step: 13
Training loss: 2.959091698239321
Validation loss: 2.640425882625076

Epoch: 161| Step: 0
Training loss: 3.22848076867905
Validation loss: 2.6463762178052526

Epoch: 6| Step: 1
Training loss: 3.2238944709299004
Validation loss: 2.657204229182444

Epoch: 6| Step: 2
Training loss: 3.1148475526394677
Validation loss: 2.6863902672797653

Epoch: 6| Step: 3
Training loss: 2.6942607209621587
Validation loss: 2.727240656778825

Epoch: 6| Step: 4
Training loss: 2.921663164425753
Validation loss: 2.7658352158728845

Epoch: 6| Step: 5
Training loss: 3.9920546776461374
Validation loss: 2.7488222853845925

Epoch: 6| Step: 6
Training loss: 3.0261164977143986
Validation loss: 2.6712898055393355

Epoch: 6| Step: 7
Training loss: 2.5659270281863145
Validation loss: 2.638073049170504

Epoch: 6| Step: 8
Training loss: 2.6660978982268615
Validation loss: 2.6318743416257346

Epoch: 6| Step: 9
Training loss: 2.330340054955181
Validation loss: 2.6334650869134406

Epoch: 6| Step: 10
Training loss: 2.9214607801936965
Validation loss: 2.636482237034052

Epoch: 6| Step: 11
Training loss: 2.334311337094422
Validation loss: 2.643328668037066

Epoch: 6| Step: 12
Training loss: 3.191473186262547
Validation loss: 2.6404571839091253

Epoch: 6| Step: 13
Training loss: 3.5146464024289052
Validation loss: 2.657641391566173

Epoch: 162| Step: 0
Training loss: 3.40635191038776
Validation loss: 2.651406689457637

Epoch: 6| Step: 1
Training loss: 2.6139986111346105
Validation loss: 2.6447005737324463

Epoch: 6| Step: 2
Training loss: 1.4801220651498748
Validation loss: 2.641050170175702

Epoch: 6| Step: 3
Training loss: 2.9083078953487624
Validation loss: 2.6392119135647003

Epoch: 6| Step: 4
Training loss: 3.039226302020397
Validation loss: 2.632340566225725

Epoch: 6| Step: 5
Training loss: 3.1056284353598427
Validation loss: 2.6334419382949514

Epoch: 6| Step: 6
Training loss: 3.522656136295116
Validation loss: 2.633739569295689

Epoch: 6| Step: 7
Training loss: 3.265724874182977
Validation loss: 2.6310950585365656

Epoch: 6| Step: 8
Training loss: 3.214240609715389
Validation loss: 2.626251065163891

Epoch: 6| Step: 9
Training loss: 2.8361574198044983
Validation loss: 2.625004998362012

Epoch: 6| Step: 10
Training loss: 2.4791350376024233
Validation loss: 2.6232597512635216

Epoch: 6| Step: 11
Training loss: 2.4528478964026617
Validation loss: 2.621607788475979

Epoch: 6| Step: 12
Training loss: 3.5302664138069826
Validation loss: 2.620022387181531

Epoch: 6| Step: 13
Training loss: 3.6507635441454203
Validation loss: 2.620019151344746

Epoch: 163| Step: 0
Training loss: 2.5870507370876723
Validation loss: 2.6201092601263887

Epoch: 6| Step: 1
Training loss: 2.6457441019545604
Validation loss: 2.617736379768284

Epoch: 6| Step: 2
Training loss: 3.064020052104703
Validation loss: 2.624290916470647

Epoch: 6| Step: 3
Training loss: 2.604303056324223
Validation loss: 2.6333452208367363

Epoch: 6| Step: 4
Training loss: 2.819538126382452
Validation loss: 2.641794802249904

Epoch: 6| Step: 5
Training loss: 2.8175261621352172
Validation loss: 2.657557654574548

Epoch: 6| Step: 6
Training loss: 2.8689651175898367
Validation loss: 2.667718197081507

Epoch: 6| Step: 7
Training loss: 3.4091371671832755
Validation loss: 2.701484010891245

Epoch: 6| Step: 8
Training loss: 3.0377178600658885
Validation loss: 2.6816125864147478

Epoch: 6| Step: 9
Training loss: 2.826036303681852
Validation loss: 2.6705644395748434

Epoch: 6| Step: 10
Training loss: 3.7675715437021315
Validation loss: 2.6635554748400794

Epoch: 6| Step: 11
Training loss: 3.0651663247511824
Validation loss: 2.653656994782291

Epoch: 6| Step: 12
Training loss: 3.021635874110726
Validation loss: 2.6314190385151837

Epoch: 6| Step: 13
Training loss: 2.6770094231720045
Validation loss: 2.6240522467777647

Epoch: 164| Step: 0
Training loss: 2.5293140307695205
Validation loss: 2.6191813764521594

Epoch: 6| Step: 1
Training loss: 2.922488877378889
Validation loss: 2.6213549901024082

Epoch: 6| Step: 2
Training loss: 2.995956397855951
Validation loss: 2.624978411127197

Epoch: 6| Step: 3
Training loss: 2.6173095674658438
Validation loss: 2.623424553875399

Epoch: 6| Step: 4
Training loss: 3.3786079054522116
Validation loss: 2.627604281631591

Epoch: 6| Step: 5
Training loss: 2.430505253104768
Validation loss: 2.628296802968726

Epoch: 6| Step: 6
Training loss: 2.947236826296509
Validation loss: 2.6288483045310813

Epoch: 6| Step: 7
Training loss: 3.1231546675620545
Validation loss: 2.6355341889530277

Epoch: 6| Step: 8
Training loss: 3.176950087124301
Validation loss: 2.6317746461754

Epoch: 6| Step: 9
Training loss: 2.5305592100598826
Validation loss: 2.6262288545067265

Epoch: 6| Step: 10
Training loss: 3.847475309038657
Validation loss: 2.626487312534734

Epoch: 6| Step: 11
Training loss: 3.2137633277619675
Validation loss: 2.624025414923912

Epoch: 6| Step: 12
Training loss: 2.8557891874646044
Validation loss: 2.622948434239158

Epoch: 6| Step: 13
Training loss: 2.9524314106234604
Validation loss: 2.6234452418498244

Epoch: 165| Step: 0
Training loss: 2.7521424184420287
Validation loss: 2.624918460311993

Epoch: 6| Step: 1
Training loss: 3.3001584159512003
Validation loss: 2.6183452770304636

Epoch: 6| Step: 2
Training loss: 2.9932037301103125
Validation loss: 2.620768096457263

Epoch: 6| Step: 3
Training loss: 2.841708613857046
Validation loss: 2.6216657737010336

Epoch: 6| Step: 4
Training loss: 3.138264238512286
Validation loss: 2.619711342078863

Epoch: 6| Step: 5
Training loss: 2.8989783756624665
Validation loss: 2.6181909975056645

Epoch: 6| Step: 6
Training loss: 3.4475505592229445
Validation loss: 2.6186331059899843

Epoch: 6| Step: 7
Training loss: 3.4035395766437437
Validation loss: 2.61678724489887

Epoch: 6| Step: 8
Training loss: 2.8597156759463727
Validation loss: 2.6173094675573907

Epoch: 6| Step: 9
Training loss: 2.4775132721854347
Validation loss: 2.617300140792662

Epoch: 6| Step: 10
Training loss: 2.9395478597690916
Validation loss: 2.619463052524302

Epoch: 6| Step: 11
Training loss: 2.57223948680484
Validation loss: 2.6264040815594147

Epoch: 6| Step: 12
Training loss: 2.657085780879937
Validation loss: 2.6245346125572184

Epoch: 6| Step: 13
Training loss: 3.236326356932227
Validation loss: 2.6249964138305355

Epoch: 166| Step: 0
Training loss: 2.6366022833074005
Validation loss: 2.628227950533452

Epoch: 6| Step: 1
Training loss: 2.2909898162975115
Validation loss: 2.6295554942156603

Epoch: 6| Step: 2
Training loss: 3.164565811627726
Validation loss: 2.6382376197666746

Epoch: 6| Step: 3
Training loss: 2.6695260771002705
Validation loss: 2.6416481474182008

Epoch: 6| Step: 4
Training loss: 2.938280204888391
Validation loss: 2.643541415191324

Epoch: 6| Step: 5
Training loss: 3.2813694523457864
Validation loss: 2.6397953845460718

Epoch: 6| Step: 6
Training loss: 3.050850333824885
Validation loss: 2.630628472862968

Epoch: 6| Step: 7
Training loss: 3.023046660481805
Validation loss: 2.6269181075626813

Epoch: 6| Step: 8
Training loss: 2.703165219399129
Validation loss: 2.6190633076689447

Epoch: 6| Step: 9
Training loss: 2.5171829043629974
Validation loss: 2.6194535983679605

Epoch: 6| Step: 10
Training loss: 2.788254735750582
Validation loss: 2.6162998399156208

Epoch: 6| Step: 11
Training loss: 3.2201665335293
Validation loss: 2.6129996836002376

Epoch: 6| Step: 12
Training loss: 3.5180632549539146
Validation loss: 2.620000702986959

Epoch: 6| Step: 13
Training loss: 3.6895093454143604
Validation loss: 2.6204924471315554

Epoch: 167| Step: 0
Training loss: 3.14601121277457
Validation loss: 2.619178392105668

Epoch: 6| Step: 1
Training loss: 3.233395782994984
Validation loss: 2.6097218871968924

Epoch: 6| Step: 2
Training loss: 2.736538450774247
Validation loss: 2.6118101974184467

Epoch: 6| Step: 3
Training loss: 3.115341366452288
Validation loss: 2.6103050593901873

Epoch: 6| Step: 4
Training loss: 3.045364396664491
Validation loss: 2.609339037308367

Epoch: 6| Step: 5
Training loss: 2.4336136377786386
Validation loss: 2.6062637368085593

Epoch: 6| Step: 6
Training loss: 2.618722949195572
Validation loss: 2.6075208567033923

Epoch: 6| Step: 7
Training loss: 3.1015718781836332
Validation loss: 2.608363619146329

Epoch: 6| Step: 8
Training loss: 3.293776660789573
Validation loss: 2.609757588716121

Epoch: 6| Step: 9
Training loss: 2.9949192893436405
Validation loss: 2.610697794582939

Epoch: 6| Step: 10
Training loss: 3.109504428642617
Validation loss: 2.616386711042186

Epoch: 6| Step: 11
Training loss: 2.96475464859114
Validation loss: 2.612795626295857

Epoch: 6| Step: 12
Training loss: 2.9898393545723994
Validation loss: 2.610530244588207

Epoch: 6| Step: 13
Training loss: 1.8009691119725104
Validation loss: 2.614245758469525

Epoch: 168| Step: 0
Training loss: 2.9389472804992116
Validation loss: 2.618375113193277

Epoch: 6| Step: 1
Training loss: 3.314485926288782
Validation loss: 2.614420995381882

Epoch: 6| Step: 2
Training loss: 3.3036604202832933
Validation loss: 2.613597724467133

Epoch: 6| Step: 3
Training loss: 3.531816555249103
Validation loss: 2.616292469303228

Epoch: 6| Step: 4
Training loss: 2.7618263148142903
Validation loss: 2.6173477831488716

Epoch: 6| Step: 5
Training loss: 2.7278901723361004
Validation loss: 2.615458680987884

Epoch: 6| Step: 6
Training loss: 2.517741195807254
Validation loss: 2.621178406388904

Epoch: 6| Step: 7
Training loss: 3.1702539971576633
Validation loss: 2.615401684407873

Epoch: 6| Step: 8
Training loss: 3.12971187130699
Validation loss: 2.621414303122763

Epoch: 6| Step: 9
Training loss: 3.194513421534837
Validation loss: 2.617534676992326

Epoch: 6| Step: 10
Training loss: 2.6475191127530273
Validation loss: 2.6274754619860525

Epoch: 6| Step: 11
Training loss: 2.7056528961230994
Validation loss: 2.637205354855379

Epoch: 6| Step: 12
Training loss: 2.83292685192185
Validation loss: 2.634574130619123

Epoch: 6| Step: 13
Training loss: 1.531842798200402
Validation loss: 2.650707508523259

Epoch: 169| Step: 0
Training loss: 3.1496083091744445
Validation loss: 2.6774658428457765

Epoch: 6| Step: 1
Training loss: 2.548792766457331
Validation loss: 2.68351093747255

Epoch: 6| Step: 2
Training loss: 3.0826546893013624
Validation loss: 2.689917516590843

Epoch: 6| Step: 3
Training loss: 2.9537391629466216
Validation loss: 2.6935354877472775

Epoch: 6| Step: 4
Training loss: 3.0060084890320606
Validation loss: 2.6954880761707845

Epoch: 6| Step: 5
Training loss: 3.451250905468914
Validation loss: 2.74245197292341

Epoch: 6| Step: 6
Training loss: 3.42835795498619
Validation loss: 2.6911738945031094

Epoch: 6| Step: 7
Training loss: 3.1076115347133713
Validation loss: 2.67868891394382

Epoch: 6| Step: 8
Training loss: 2.957455321205835
Validation loss: 2.6751703017402786

Epoch: 6| Step: 9
Training loss: 2.8824384906753613
Validation loss: 2.6750299268245876

Epoch: 6| Step: 10
Training loss: 3.26537734557346
Validation loss: 2.6751293423280242

Epoch: 6| Step: 11
Training loss: 2.4808042764889473
Validation loss: 2.6836212052193194

Epoch: 6| Step: 12
Training loss: 2.5330989348573882
Validation loss: 2.687877276554062

Epoch: 6| Step: 13
Training loss: 3.294205873273596
Validation loss: 2.7079933248093697

Epoch: 170| Step: 0
Training loss: 2.574584194055
Validation loss: 2.69294113651045

Epoch: 6| Step: 1
Training loss: 2.869765450599592
Validation loss: 2.678426637676863

Epoch: 6| Step: 2
Training loss: 2.516858669139927
Validation loss: 2.6660799956503527

Epoch: 6| Step: 3
Training loss: 3.1393913009496788
Validation loss: 2.662049247765611

Epoch: 6| Step: 4
Training loss: 2.9471090084298477
Validation loss: 2.6573129764931736

Epoch: 6| Step: 5
Training loss: 3.380948511245529
Validation loss: 2.655189531208929

Epoch: 6| Step: 6
Training loss: 3.375873876394272
Validation loss: 2.656639181601099

Epoch: 6| Step: 7
Training loss: 2.425368613316629
Validation loss: 2.654152122688623

Epoch: 6| Step: 8
Training loss: 2.6645185242486966
Validation loss: 2.6635100132483616

Epoch: 6| Step: 9
Training loss: 2.521985560455249
Validation loss: 2.679572399600559

Epoch: 6| Step: 10
Training loss: 3.678448186918333
Validation loss: 2.687775537894552

Epoch: 6| Step: 11
Training loss: 3.565255956249051
Validation loss: 2.698781521539041

Epoch: 6| Step: 12
Training loss: 3.2845422123266528
Validation loss: 2.726713860428773

Epoch: 6| Step: 13
Training loss: 2.6390155650290925
Validation loss: 2.7200538734485082

Epoch: 171| Step: 0
Training loss: 2.2073116698235564
Validation loss: 2.726095074720214

Epoch: 6| Step: 1
Training loss: 2.9245854010554053
Validation loss: 2.720633874711847

Epoch: 6| Step: 2
Training loss: 3.1785364715466375
Validation loss: 2.7096872998214705

Epoch: 6| Step: 3
Training loss: 3.150897936524838
Validation loss: 2.695356440769274

Epoch: 6| Step: 4
Training loss: 3.7163233172193064
Validation loss: 2.6746526697547077

Epoch: 6| Step: 5
Training loss: 2.6340655053407045
Validation loss: 2.654273746763406

Epoch: 6| Step: 6
Training loss: 2.9033298383210697
Validation loss: 2.645341542758089

Epoch: 6| Step: 7
Training loss: 2.252913178580606
Validation loss: 2.637074797915901

Epoch: 6| Step: 8
Training loss: 3.4050789316134185
Validation loss: 2.612734414238973

Epoch: 6| Step: 9
Training loss: 2.395001164637145
Validation loss: 2.5964777085575688

Epoch: 6| Step: 10
Training loss: 3.0238071580383408
Validation loss: 2.60008910040666

Epoch: 6| Step: 11
Training loss: 3.6528275602854103
Validation loss: 2.5971750881327136

Epoch: 6| Step: 12
Training loss: 2.8197087621790873
Validation loss: 2.598622603822084

Epoch: 6| Step: 13
Training loss: 2.985825750235034
Validation loss: 2.595856347129593

Epoch: 172| Step: 0
Training loss: 2.2224350535941086
Validation loss: 2.6027807381351478

Epoch: 6| Step: 1
Training loss: 2.6133943769890022
Validation loss: 2.5995629903722874

Epoch: 6| Step: 2
Training loss: 3.0263203915489
Validation loss: 2.600135497340145

Epoch: 6| Step: 3
Training loss: 3.363366598891658
Validation loss: 2.5980529112216613

Epoch: 6| Step: 4
Training loss: 3.5204536338584225
Validation loss: 2.6008113619379722

Epoch: 6| Step: 5
Training loss: 3.1533821598436984
Validation loss: 2.6043011544889105

Epoch: 6| Step: 6
Training loss: 2.7672798679817
Validation loss: 2.6032298185162546

Epoch: 6| Step: 7
Training loss: 2.550173069185755
Validation loss: 2.619715173281785

Epoch: 6| Step: 8
Training loss: 3.193545573461094
Validation loss: 2.6293435634969056

Epoch: 6| Step: 9
Training loss: 3.603425113192547
Validation loss: 2.6381522834676305

Epoch: 6| Step: 10
Training loss: 2.6806283083339633
Validation loss: 2.6249670885076726

Epoch: 6| Step: 11
Training loss: 2.5777548784393507
Validation loss: 2.6228484454507903

Epoch: 6| Step: 12
Training loss: 3.0405291864681465
Validation loss: 2.615560325465648

Epoch: 6| Step: 13
Training loss: 2.4976438863887966
Validation loss: 2.6125513376234832

Epoch: 173| Step: 0
Training loss: 3.0154415727083768
Validation loss: 2.60792993611063

Epoch: 6| Step: 1
Training loss: 3.3401900976300234
Validation loss: 2.6139383177770235

Epoch: 6| Step: 2
Training loss: 2.497887099989596
Validation loss: 2.6013806406480877

Epoch: 6| Step: 3
Training loss: 2.997686606763723
Validation loss: 2.601314663071756

Epoch: 6| Step: 4
Training loss: 2.8063513620672498
Validation loss: 2.6041301844512783

Epoch: 6| Step: 5
Training loss: 3.173923976917986
Validation loss: 2.5985120746569317

Epoch: 6| Step: 6
Training loss: 2.860527765089623
Validation loss: 2.595446099635178

Epoch: 6| Step: 7
Training loss: 2.64913571136747
Validation loss: 2.593509798853872

Epoch: 6| Step: 8
Training loss: 2.790054444086057
Validation loss: 2.5901233271813635

Epoch: 6| Step: 9
Training loss: 2.7828672186276604
Validation loss: 2.5974601129377355

Epoch: 6| Step: 10
Training loss: 2.616041883564971
Validation loss: 2.6019622309395394

Epoch: 6| Step: 11
Training loss: 3.181107037822523
Validation loss: 2.6046464841434007

Epoch: 6| Step: 12
Training loss: 3.207586242753218
Validation loss: 2.6152902459774827

Epoch: 6| Step: 13
Training loss: 3.3669752155838566
Validation loss: 2.6187095941078415

Epoch: 174| Step: 0
Training loss: 3.0834031140103573
Validation loss: 2.6116231776081835

Epoch: 6| Step: 1
Training loss: 2.5475062424692743
Validation loss: 2.5940683532483804

Epoch: 6| Step: 2
Training loss: 2.6231505827239077
Validation loss: 2.600203847427181

Epoch: 6| Step: 3
Training loss: 3.4901137371166366
Validation loss: 2.60420344041681

Epoch: 6| Step: 4
Training loss: 3.0736066313045045
Validation loss: 2.616811043423284

Epoch: 6| Step: 5
Training loss: 2.9269578755237204
Validation loss: 2.6163243101606657

Epoch: 6| Step: 6
Training loss: 2.9630380391393425
Validation loss: 2.603403496598407

Epoch: 6| Step: 7
Training loss: 2.0696395068080986
Validation loss: 2.605868206387076

Epoch: 6| Step: 8
Training loss: 3.249266908568029
Validation loss: 2.610156196726611

Epoch: 6| Step: 9
Training loss: 3.224050952934699
Validation loss: 2.6062141005802073

Epoch: 6| Step: 10
Training loss: 3.103183582133256
Validation loss: 2.6128309546697057

Epoch: 6| Step: 11
Training loss: 2.9296953124895833
Validation loss: 2.6048930730543662

Epoch: 6| Step: 12
Training loss: 2.6554026430211524
Validation loss: 2.599372600097312

Epoch: 6| Step: 13
Training loss: 2.988654139571691
Validation loss: 2.5971014680842592

Epoch: 175| Step: 0
Training loss: 2.688010233859608
Validation loss: 2.595057823329945

Epoch: 6| Step: 1
Training loss: 3.018105865057638
Validation loss: 2.5949487170954075

Epoch: 6| Step: 2
Training loss: 2.121743343353167
Validation loss: 2.5975138909357938

Epoch: 6| Step: 3
Training loss: 2.998778730400322
Validation loss: 2.590625693460679

Epoch: 6| Step: 4
Training loss: 3.399012725204705
Validation loss: 2.588763155081499

Epoch: 6| Step: 5
Training loss: 2.67337217267838
Validation loss: 2.584569048657753

Epoch: 6| Step: 6
Training loss: 3.5900459108100042
Validation loss: 2.590840478619805

Epoch: 6| Step: 7
Training loss: 3.1183156049242453
Validation loss: 2.5900004654129796

Epoch: 6| Step: 8
Training loss: 2.637117482872016
Validation loss: 2.5881162230962715

Epoch: 6| Step: 9
Training loss: 2.58186522165006
Validation loss: 2.5870586438739904

Epoch: 6| Step: 10
Training loss: 3.1513199780512515
Validation loss: 2.5888618104056578

Epoch: 6| Step: 11
Training loss: 2.4847685304291005
Validation loss: 2.5893072712464273

Epoch: 6| Step: 12
Training loss: 3.115606150670555
Validation loss: 2.592957522972894

Epoch: 6| Step: 13
Training loss: 3.4121236293169632
Validation loss: 2.591270288372618

Epoch: 176| Step: 0
Training loss: 2.8060008934601433
Validation loss: 2.599968252706001

Epoch: 6| Step: 1
Training loss: 2.3101342962290676
Validation loss: 2.602164897446438

Epoch: 6| Step: 2
Training loss: 3.218371322726336
Validation loss: 2.6068470158546155

Epoch: 6| Step: 3
Training loss: 2.987997841952973
Validation loss: 2.594658417895081

Epoch: 6| Step: 4
Training loss: 2.789804055501178
Validation loss: 2.6011580527578855

Epoch: 6| Step: 5
Training loss: 2.6512438104351332
Validation loss: 2.591544455870343

Epoch: 6| Step: 6
Training loss: 2.7861767968290305
Validation loss: 2.5979433742192803

Epoch: 6| Step: 7
Training loss: 3.25629900348129
Validation loss: 2.6066860722693157

Epoch: 6| Step: 8
Training loss: 2.7632794104891656
Validation loss: 2.604339489196216

Epoch: 6| Step: 9
Training loss: 3.3745813463303103
Validation loss: 2.606353430983713

Epoch: 6| Step: 10
Training loss: 3.413472349370862
Validation loss: 2.600246567784022

Epoch: 6| Step: 11
Training loss: 3.185124278615679
Validation loss: 2.599866338832835

Epoch: 6| Step: 12
Training loss: 2.4543440395779514
Validation loss: 2.5950430947846477

Epoch: 6| Step: 13
Training loss: 2.7493408453524526
Validation loss: 2.5897438253876466

Epoch: 177| Step: 0
Training loss: 2.95968947869582
Validation loss: 2.5902345052884588

Epoch: 6| Step: 1
Training loss: 3.093306384407691
Validation loss: 2.5952495317918487

Epoch: 6| Step: 2
Training loss: 3.607497746816501
Validation loss: 2.5985658752795593

Epoch: 6| Step: 3
Training loss: 1.8500292260206965
Validation loss: 2.5904202626091357

Epoch: 6| Step: 4
Training loss: 2.999033295327335
Validation loss: 2.589623833347867

Epoch: 6| Step: 5
Training loss: 2.9406821688244364
Validation loss: 2.591567846667651

Epoch: 6| Step: 6
Training loss: 2.783750802747853
Validation loss: 2.5919305295992774

Epoch: 6| Step: 7
Training loss: 2.8994545193371444
Validation loss: 2.5893414349786235

Epoch: 6| Step: 8
Training loss: 3.19294005274448
Validation loss: 2.5881623146368185

Epoch: 6| Step: 9
Training loss: 3.389907972048793
Validation loss: 2.5888597793860857

Epoch: 6| Step: 10
Training loss: 2.9774971042878415
Validation loss: 2.5817178351646137

Epoch: 6| Step: 11
Training loss: 2.6473368380288096
Validation loss: 2.5918780679789273

Epoch: 6| Step: 12
Training loss: 2.5986251056819203
Validation loss: 2.59557200353367

Epoch: 6| Step: 13
Training loss: 2.5955766427458697
Validation loss: 2.583350422339891

Epoch: 178| Step: 0
Training loss: 2.7123872689584467
Validation loss: 2.5987384681852435

Epoch: 6| Step: 1
Training loss: 3.0283757376619356
Validation loss: 2.5962016101696275

Epoch: 6| Step: 2
Training loss: 3.3511797635303178
Validation loss: 2.596901076281313

Epoch: 6| Step: 3
Training loss: 3.134598144620659
Validation loss: 2.593087441973175

Epoch: 6| Step: 4
Training loss: 2.514840139840916
Validation loss: 2.5967449821799056

Epoch: 6| Step: 5
Training loss: 3.333771978762836
Validation loss: 2.5933291690217355

Epoch: 6| Step: 6
Training loss: 3.108303786504662
Validation loss: 2.598553044051095

Epoch: 6| Step: 7
Training loss: 2.8820581457134824
Validation loss: 2.597686464915937

Epoch: 6| Step: 8
Training loss: 2.867167210312236
Validation loss: 2.6146819187572725

Epoch: 6| Step: 9
Training loss: 2.9624644345752147
Validation loss: 2.60906220505926

Epoch: 6| Step: 10
Training loss: 2.772390076476436
Validation loss: 2.606938435481672

Epoch: 6| Step: 11
Training loss: 2.6033447392694526
Validation loss: 2.610716613088923

Epoch: 6| Step: 12
Training loss: 1.9759481930447165
Validation loss: 2.6275070629257353

Epoch: 6| Step: 13
Training loss: 3.6876349990185213
Validation loss: 2.6314400440769417

Epoch: 179| Step: 0
Training loss: 2.193164575610524
Validation loss: 2.6282279134672817

Epoch: 6| Step: 1
Training loss: 2.8133523285331488
Validation loss: 2.6357076282350524

Epoch: 6| Step: 2
Training loss: 3.3927858560286652
Validation loss: 2.63019227362406

Epoch: 6| Step: 3
Training loss: 2.830518184170165
Validation loss: 2.6082068256311

Epoch: 6| Step: 4
Training loss: 2.4129626290075064
Validation loss: 2.6018919692564384

Epoch: 6| Step: 5
Training loss: 3.256942083868072
Validation loss: 2.589877850232819

Epoch: 6| Step: 6
Training loss: 3.234184812399693
Validation loss: 2.584461608499684

Epoch: 6| Step: 7
Training loss: 3.7449968659371273
Validation loss: 2.5831647044495476

Epoch: 6| Step: 8
Training loss: 2.9395378024555883
Validation loss: 2.585653407112525

Epoch: 6| Step: 9
Training loss: 3.0310382572429067
Validation loss: 2.586740607305471

Epoch: 6| Step: 10
Training loss: 2.4183335529785617
Validation loss: 2.586889269458091

Epoch: 6| Step: 11
Training loss: 2.788754999215276
Validation loss: 2.592110198647025

Epoch: 6| Step: 12
Training loss: 2.8115998417078054
Validation loss: 2.5896156453226626

Epoch: 6| Step: 13
Training loss: 2.930662760850261
Validation loss: 2.589492360489977

Epoch: 180| Step: 0
Training loss: 2.615018304355956
Validation loss: 2.5933540023166475

Epoch: 6| Step: 1
Training loss: 2.1726266123023477
Validation loss: 2.591468288775854

Epoch: 6| Step: 2
Training loss: 2.9713072353783474
Validation loss: 2.5913897085395963

Epoch: 6| Step: 3
Training loss: 2.6498337387614743
Validation loss: 2.588978786918387

Epoch: 6| Step: 4
Training loss: 2.5354202203613387
Validation loss: 2.5879938128488185

Epoch: 6| Step: 5
Training loss: 3.504381298578629
Validation loss: 2.5886878023963424

Epoch: 6| Step: 6
Training loss: 3.4956698197932927
Validation loss: 2.5869301979670634

Epoch: 6| Step: 7
Training loss: 3.0914415166123983
Validation loss: 2.5843898869928736

Epoch: 6| Step: 8
Training loss: 2.7968140494242526
Validation loss: 2.5893063564054613

Epoch: 6| Step: 9
Training loss: 2.911612372966669
Validation loss: 2.584478393126002

Epoch: 6| Step: 10
Training loss: 3.217263183889248
Validation loss: 2.5855878650534136

Epoch: 6| Step: 11
Training loss: 3.1826943466885664
Validation loss: 2.5838432266950258

Epoch: 6| Step: 12
Training loss: 3.116536390332323
Validation loss: 2.5866935855688773

Epoch: 6| Step: 13
Training loss: 2.5915949497746578
Validation loss: 2.5826188950994577

Epoch: 181| Step: 0
Training loss: 3.181292304636445
Validation loss: 2.5843310991281814

Epoch: 6| Step: 1
Training loss: 3.1403161651441134
Validation loss: 2.587262190462755

Epoch: 6| Step: 2
Training loss: 3.0224762406215984
Validation loss: 2.5863410910612616

Epoch: 6| Step: 3
Training loss: 2.918748131042797
Validation loss: 2.5863775410458034

Epoch: 6| Step: 4
Training loss: 2.694250986903805
Validation loss: 2.5882786839029404

Epoch: 6| Step: 5
Training loss: 2.4066807745240886
Validation loss: 2.58843111541745

Epoch: 6| Step: 6
Training loss: 3.7246721059380423
Validation loss: 2.5916067837083916

Epoch: 6| Step: 7
Training loss: 3.120674496637681
Validation loss: 2.589871874384819

Epoch: 6| Step: 8
Training loss: 2.8325565245628814
Validation loss: 2.5927518487403103

Epoch: 6| Step: 9
Training loss: 2.95688466523856
Validation loss: 2.6068371245390627

Epoch: 6| Step: 10
Training loss: 3.0845944342971054
Validation loss: 2.601734860614557

Epoch: 6| Step: 11
Training loss: 2.1607982929927747
Validation loss: 2.5989579440298316

Epoch: 6| Step: 12
Training loss: 2.662335414903651
Validation loss: 2.6021617556567196

Epoch: 6| Step: 13
Training loss: 2.6882660239824188
Validation loss: 2.5893721221524246

Epoch: 182| Step: 0
Training loss: 2.451158160289072
Validation loss: 2.6005543465705814

Epoch: 6| Step: 1
Training loss: 3.208585225575327
Validation loss: 2.6018966065603855

Epoch: 6| Step: 2
Training loss: 3.027863803617467
Validation loss: 2.6028013789211153

Epoch: 6| Step: 3
Training loss: 2.6299372064324715
Validation loss: 2.601409001976881

Epoch: 6| Step: 4
Training loss: 2.8424595849914156
Validation loss: 2.6023715861680734

Epoch: 6| Step: 5
Training loss: 3.1906135162834324
Validation loss: 2.599571629306883

Epoch: 6| Step: 6
Training loss: 2.512718844016319
Validation loss: 2.5937398116396833

Epoch: 6| Step: 7
Training loss: 2.7651035657805276
Validation loss: 2.5848028473688824

Epoch: 6| Step: 8
Training loss: 3.0763910512196615
Validation loss: 2.588396953536228

Epoch: 6| Step: 9
Training loss: 3.3214936433151587
Validation loss: 2.578993383627903

Epoch: 6| Step: 10
Training loss: 2.7256681620524654
Validation loss: 2.578363061915901

Epoch: 6| Step: 11
Training loss: 2.858073954773919
Validation loss: 2.5783549365651335

Epoch: 6| Step: 12
Training loss: 3.3546324854667504
Validation loss: 2.5724062799287712

Epoch: 6| Step: 13
Training loss: 2.59587579960833
Validation loss: 2.5686069753001775

Epoch: 183| Step: 0
Training loss: 3.3159410849147317
Validation loss: 2.579748270731113

Epoch: 6| Step: 1
Training loss: 2.8578794143042674
Validation loss: 2.580604846668932

Epoch: 6| Step: 2
Training loss: 3.2546435707999146
Validation loss: 2.5769858380786

Epoch: 6| Step: 3
Training loss: 3.0044767039007354
Validation loss: 2.5690472286296604

Epoch: 6| Step: 4
Training loss: 2.2127668273720382
Validation loss: 2.5777102089799744

Epoch: 6| Step: 5
Training loss: 2.4440025257653204
Validation loss: 2.5798163729329557

Epoch: 6| Step: 6
Training loss: 3.821134077166248
Validation loss: 2.5838773798261623

Epoch: 6| Step: 7
Training loss: 3.0734572285347204
Validation loss: 2.57968464371704

Epoch: 6| Step: 8
Training loss: 2.865979348075661
Validation loss: 2.581682033366641

Epoch: 6| Step: 9
Training loss: 2.649264406279347
Validation loss: 2.583831774418314

Epoch: 6| Step: 10
Training loss: 3.074434963509333
Validation loss: 2.5890522339409063

Epoch: 6| Step: 11
Training loss: 2.1403995590115406
Validation loss: 2.604946968241554

Epoch: 6| Step: 12
Training loss: 3.256060744513291
Validation loss: 2.5938553554597226

Epoch: 6| Step: 13
Training loss: 2.1391138464907122
Validation loss: 2.5835717005585566

Epoch: 184| Step: 0
Training loss: 2.907600007243779
Validation loss: 2.598643456197732

Epoch: 6| Step: 1
Training loss: 2.6365955917417616
Validation loss: 2.5882650370209355

Epoch: 6| Step: 2
Training loss: 2.5347548344806152
Validation loss: 2.595692113690658

Epoch: 6| Step: 3
Training loss: 2.6096824419193907
Validation loss: 2.5793708383960987

Epoch: 6| Step: 4
Training loss: 3.1018241560560416
Validation loss: 2.581784974858076

Epoch: 6| Step: 5
Training loss: 3.4040413791817574
Validation loss: 2.584596813844856

Epoch: 6| Step: 6
Training loss: 3.1299248607744943
Validation loss: 2.5720190387438953

Epoch: 6| Step: 7
Training loss: 3.372297264435874
Validation loss: 2.5744976181645627

Epoch: 6| Step: 8
Training loss: 2.484311085004782
Validation loss: 2.5821001458408306

Epoch: 6| Step: 9
Training loss: 2.686669775895559
Validation loss: 2.581612448122361

Epoch: 6| Step: 10
Training loss: 2.6300914977660175
Validation loss: 2.584991460476525

Epoch: 6| Step: 11
Training loss: 2.632081425529088
Validation loss: 2.5920154431678197

Epoch: 6| Step: 12
Training loss: 3.4282650441693874
Validation loss: 2.6220991324821936

Epoch: 6| Step: 13
Training loss: 3.291851827186096
Validation loss: 2.6033469451058537

Epoch: 185| Step: 0
Training loss: 2.6316859158308614
Validation loss: 2.595860149346626

Epoch: 6| Step: 1
Training loss: 2.9248263706938324
Validation loss: 2.5917747588048283

Epoch: 6| Step: 2
Training loss: 3.1274084347037334
Validation loss: 2.5876456614556584

Epoch: 6| Step: 3
Training loss: 2.3740125912442482
Validation loss: 2.589520536211467

Epoch: 6| Step: 4
Training loss: 3.000085193695938
Validation loss: 2.6007632549985207

Epoch: 6| Step: 5
Training loss: 2.7486712973838854
Validation loss: 2.5891138078617235

Epoch: 6| Step: 6
Training loss: 2.6965272681471864
Validation loss: 2.57924757575811

Epoch: 6| Step: 7
Training loss: 3.4545677243660236
Validation loss: 2.5750554679840496

Epoch: 6| Step: 8
Training loss: 3.197966501715387
Validation loss: 2.567676380666454

Epoch: 6| Step: 9
Training loss: 3.2197277472889843
Validation loss: 2.5703010597476847

Epoch: 6| Step: 10
Training loss: 2.3494437675427995
Validation loss: 2.57139257758075

Epoch: 6| Step: 11
Training loss: 3.0013831446934596
Validation loss: 2.5727288746106662

Epoch: 6| Step: 12
Training loss: 2.8278964461396234
Validation loss: 2.569763553857887

Epoch: 6| Step: 13
Training loss: 3.3602745093879434
Validation loss: 2.5687497667049493

Epoch: 186| Step: 0
Training loss: 3.128966598785989
Validation loss: 2.5658494062386255

Epoch: 6| Step: 1
Training loss: 3.369768397129537
Validation loss: 2.565549560043683

Epoch: 6| Step: 2
Training loss: 2.764444303909508
Validation loss: 2.567826916769162

Epoch: 6| Step: 3
Training loss: 3.0492688287546326
Validation loss: 2.5721984959668087

Epoch: 6| Step: 4
Training loss: 2.898321678952752
Validation loss: 2.5707200439746423

Epoch: 6| Step: 5
Training loss: 3.3926004728592525
Validation loss: 2.5805152420378494

Epoch: 6| Step: 6
Training loss: 2.3681273152754603
Validation loss: 2.588579103100885

Epoch: 6| Step: 7
Training loss: 2.686832522517702
Validation loss: 2.611984006733911

Epoch: 6| Step: 8
Training loss: 2.851822013019977
Validation loss: 2.603735358832548

Epoch: 6| Step: 9
Training loss: 2.640827419490659
Validation loss: 2.61498849753817

Epoch: 6| Step: 10
Training loss: 3.531720695520385
Validation loss: 2.603324847267482

Epoch: 6| Step: 11
Training loss: 2.9821606155010345
Validation loss: 2.5891429847842407

Epoch: 6| Step: 12
Training loss: 2.1704487680233915
Validation loss: 2.588093436542768

Epoch: 6| Step: 13
Training loss: 2.546582070571648
Validation loss: 2.583812578532534

Epoch: 187| Step: 0
Training loss: 2.5136078512934805
Validation loss: 2.575837798221331

Epoch: 6| Step: 1
Training loss: 3.3331860668711966
Validation loss: 2.584986990202509

Epoch: 6| Step: 2
Training loss: 2.756447256905624
Validation loss: 2.5808883450186513

Epoch: 6| Step: 3
Training loss: 3.09952707067201
Validation loss: 2.58153282307885

Epoch: 6| Step: 4
Training loss: 2.8489128448555614
Validation loss: 2.57340410894531

Epoch: 6| Step: 5
Training loss: 2.251197496275333
Validation loss: 2.5801454782612065

Epoch: 6| Step: 6
Training loss: 2.3771963504422406
Validation loss: 2.576793364785917

Epoch: 6| Step: 7
Training loss: 3.2438947112451175
Validation loss: 2.575025193604595

Epoch: 6| Step: 8
Training loss: 3.4252425393316415
Validation loss: 2.5809888776819307

Epoch: 6| Step: 9
Training loss: 2.286987718429915
Validation loss: 2.583178702803243

Epoch: 6| Step: 10
Training loss: 2.8324396930681797
Validation loss: 2.6034931110836763

Epoch: 6| Step: 11
Training loss: 2.9814219619131452
Validation loss: 2.579825025324582

Epoch: 6| Step: 12
Training loss: 3.239773138604619
Validation loss: 2.593539037031016

Epoch: 6| Step: 13
Training loss: 3.401600034872003
Validation loss: 2.598023486033151

Epoch: 188| Step: 0
Training loss: 3.1582745394774383
Validation loss: 2.604955130711799

Epoch: 6| Step: 1
Training loss: 2.6415697924383434
Validation loss: 2.599512857358066

Epoch: 6| Step: 2
Training loss: 3.3686132399731585
Validation loss: 2.5824872820334877

Epoch: 6| Step: 3
Training loss: 2.795180931854498
Validation loss: 2.574609619394328

Epoch: 6| Step: 4
Training loss: 3.0395300341284903
Validation loss: 2.571398717008982

Epoch: 6| Step: 5
Training loss: 2.715159884920885
Validation loss: 2.5599927974719456

Epoch: 6| Step: 6
Training loss: 2.703930685114236
Validation loss: 2.5680616137790584

Epoch: 6| Step: 7
Training loss: 2.8397285616468713
Validation loss: 2.562736909461093

Epoch: 6| Step: 8
Training loss: 3.021733555447063
Validation loss: 2.563663601647466

Epoch: 6| Step: 9
Training loss: 3.7414330854905216
Validation loss: 2.560928974636572

Epoch: 6| Step: 10
Training loss: 2.635944529706607
Validation loss: 2.5686267229685114

Epoch: 6| Step: 11
Training loss: 3.0431799760209843
Validation loss: 2.563434033425375

Epoch: 6| Step: 12
Training loss: 2.250267436769973
Validation loss: 2.561893440368365

Epoch: 6| Step: 13
Training loss: 2.4274165589186985
Validation loss: 2.563530636390449

Epoch: 189| Step: 0
Training loss: 3.0381893678653022
Validation loss: 2.564481865730153

Epoch: 6| Step: 1
Training loss: 3.3917293595901863
Validation loss: 2.561048467243672

Epoch: 6| Step: 2
Training loss: 3.1333024172238404
Validation loss: 2.558177911638191

Epoch: 6| Step: 3
Training loss: 3.0036762283416283
Validation loss: 2.5574741644681027

Epoch: 6| Step: 4
Training loss: 3.2502703921004996
Validation loss: 2.568821067616399

Epoch: 6| Step: 5
Training loss: 2.6668815128880734
Validation loss: 2.5626063070948724

Epoch: 6| Step: 6
Training loss: 1.978026379481683
Validation loss: 2.561210541998732

Epoch: 6| Step: 7
Training loss: 3.2762692387091326
Validation loss: 2.5629404273762826

Epoch: 6| Step: 8
Training loss: 3.019109106719863
Validation loss: 2.568270926276464

Epoch: 6| Step: 9
Training loss: 2.5096838318079886
Validation loss: 2.579332141543463

Epoch: 6| Step: 10
Training loss: 2.8322171275207477
Validation loss: 2.583344459178941

Epoch: 6| Step: 11
Training loss: 2.9492691945189202
Validation loss: 2.593307383222111

Epoch: 6| Step: 12
Training loss: 2.673766509545046
Validation loss: 2.5946136294049236

Epoch: 6| Step: 13
Training loss: 2.5216942780322027
Validation loss: 2.6081987676971248

Epoch: 190| Step: 0
Training loss: 3.5012744218219023
Validation loss: 2.6163442757826925

Epoch: 6| Step: 1
Training loss: 3.0155105173784293
Validation loss: 2.6156646328758186

Epoch: 6| Step: 2
Training loss: 2.8581044860811042
Validation loss: 2.582671070322915

Epoch: 6| Step: 3
Training loss: 2.372549700362139
Validation loss: 2.5554558201119586

Epoch: 6| Step: 4
Training loss: 3.144331685243491
Validation loss: 2.5577891106804365

Epoch: 6| Step: 5
Training loss: 3.2114863239907603
Validation loss: 2.5634842679815706

Epoch: 6| Step: 6
Training loss: 2.765803789297266
Validation loss: 2.5633035695917257

Epoch: 6| Step: 7
Training loss: 2.9725248731337683
Validation loss: 2.569157793070439

Epoch: 6| Step: 8
Training loss: 2.552129649046935
Validation loss: 2.5721764713939024

Epoch: 6| Step: 9
Training loss: 3.2686550556930767
Validation loss: 2.5734243786691353

Epoch: 6| Step: 10
Training loss: 2.9859848074606377
Validation loss: 2.5730885592775614

Epoch: 6| Step: 11
Training loss: 2.612531659970253
Validation loss: 2.5704961245416755

Epoch: 6| Step: 12
Training loss: 3.015787545206437
Validation loss: 2.567570236064459

Epoch: 6| Step: 13
Training loss: 2.7974324443388525
Validation loss: 2.5668548348272675

Epoch: 191| Step: 0
Training loss: 3.0231065987970767
Validation loss: 2.567469949823718

Epoch: 6| Step: 1
Training loss: 2.9249191338209832
Validation loss: 2.56362769371767

Epoch: 6| Step: 2
Training loss: 3.0013173707695437
Validation loss: 2.5633382899216186

Epoch: 6| Step: 3
Training loss: 2.858169718546232
Validation loss: 2.560532469575291

Epoch: 6| Step: 4
Training loss: 3.3029709995716328
Validation loss: 2.562848847477295

Epoch: 6| Step: 5
Training loss: 2.530696855553235
Validation loss: 2.562930689448064

Epoch: 6| Step: 6
Training loss: 2.6293081625351977
Validation loss: 2.5638163867259944

Epoch: 6| Step: 7
Training loss: 2.629652623054656
Validation loss: 2.561096930788427

Epoch: 6| Step: 8
Training loss: 2.7293104954062066
Validation loss: 2.57088323613081

Epoch: 6| Step: 9
Training loss: 2.9617181317593655
Validation loss: 2.570795808633496

Epoch: 6| Step: 10
Training loss: 3.429593234841375
Validation loss: 2.580116564247973

Epoch: 6| Step: 11
Training loss: 2.7469307504319174
Validation loss: 2.5657416308298715

Epoch: 6| Step: 12
Training loss: 2.9654968105383266
Validation loss: 2.5657311958604656

Epoch: 6| Step: 13
Training loss: 3.0676812698042655
Validation loss: 2.573134398932375

Epoch: 192| Step: 0
Training loss: 3.1747648857951867
Validation loss: 2.566281591948338

Epoch: 6| Step: 1
Training loss: 2.3948803098074074
Validation loss: 2.571239797006488

Epoch: 6| Step: 2
Training loss: 2.9700841214889357
Validation loss: 2.5760321949597405

Epoch: 6| Step: 3
Training loss: 3.4324445135712125
Validation loss: 2.5744734723082208

Epoch: 6| Step: 4
Training loss: 2.5278326443131136
Validation loss: 2.5698706528289956

Epoch: 6| Step: 5
Training loss: 2.6282880263050985
Validation loss: 2.5514321684130494

Epoch: 6| Step: 6
Training loss: 2.409667622451216
Validation loss: 2.555451119098944

Epoch: 6| Step: 7
Training loss: 3.100872280085057
Validation loss: 2.5551572274201924

Epoch: 6| Step: 8
Training loss: 2.2569524585548986
Validation loss: 2.5479424104087696

Epoch: 6| Step: 9
Training loss: 3.4086172294988373
Validation loss: 2.550069989605754

Epoch: 6| Step: 10
Training loss: 3.3219227196180747
Validation loss: 2.547692785700979

Epoch: 6| Step: 11
Training loss: 3.276210147829235
Validation loss: 2.5513106448179608

Epoch: 6| Step: 12
Training loss: 2.815543498935325
Validation loss: 2.553811569300065

Epoch: 6| Step: 13
Training loss: 2.4212310919468947
Validation loss: 2.5520988365105937

Epoch: 193| Step: 0
Training loss: 2.8242686413675417
Validation loss: 2.562465420381346

Epoch: 6| Step: 1
Training loss: 3.158140919107538
Validation loss: 2.569749032499115

Epoch: 6| Step: 2
Training loss: 3.2996328669845627
Validation loss: 2.586328077262463

Epoch: 6| Step: 3
Training loss: 2.125577735902582
Validation loss: 2.5885307084157363

Epoch: 6| Step: 4
Training loss: 3.0888691943460915
Validation loss: 2.6252295652015607

Epoch: 6| Step: 5
Training loss: 3.047269981409525
Validation loss: 2.631906449834498

Epoch: 6| Step: 6
Training loss: 2.7535372439501886
Validation loss: 2.6333941889416423

Epoch: 6| Step: 7
Training loss: 3.1787263884513117
Validation loss: 2.6481975495483563

Epoch: 6| Step: 8
Training loss: 2.5948302995176156
Validation loss: 2.6565737122299558

Epoch: 6| Step: 9
Training loss: 2.0640455292921636
Validation loss: 2.665422342655665

Epoch: 6| Step: 10
Training loss: 2.915678910618702
Validation loss: 2.668576811639506

Epoch: 6| Step: 11
Training loss: 3.3771220000067643
Validation loss: 2.684626164302219

Epoch: 6| Step: 12
Training loss: 3.1471459553354957
Validation loss: 2.600396814032267

Epoch: 6| Step: 13
Training loss: 2.8073965606248787
Validation loss: 2.5558746691357275

Epoch: 194| Step: 0
Training loss: 2.9394372274279403
Validation loss: 2.5544284843414125

Epoch: 6| Step: 1
Training loss: 3.0786085959148526
Validation loss: 2.568439119977924

Epoch: 6| Step: 2
Training loss: 3.4353100823562457
Validation loss: 2.5771243244381288

Epoch: 6| Step: 3
Training loss: 3.1216120856449523
Validation loss: 2.587579372306815

Epoch: 6| Step: 4
Training loss: 2.964953755987854
Validation loss: 2.6006199294082823

Epoch: 6| Step: 5
Training loss: 2.898102856671357
Validation loss: 2.6099674838510403

Epoch: 6| Step: 6
Training loss: 3.134189674017788
Validation loss: 2.587781342396757

Epoch: 6| Step: 7
Training loss: 3.2004946445586553
Validation loss: 2.5706253761487954

Epoch: 6| Step: 8
Training loss: 2.8374154099278615
Validation loss: 2.569508361649615

Epoch: 6| Step: 9
Training loss: 2.6798888372739014
Validation loss: 2.568404559433534

Epoch: 6| Step: 10
Training loss: 3.0175607427695157
Validation loss: 2.562389527467433

Epoch: 6| Step: 11
Training loss: 1.8952032097033675
Validation loss: 2.5588140622489903

Epoch: 6| Step: 12
Training loss: 2.712534936776602
Validation loss: 2.5598877889032567

Epoch: 6| Step: 13
Training loss: 3.255384825944582
Validation loss: 2.5587463699107396

Epoch: 195| Step: 0
Training loss: 3.0414377065384564
Validation loss: 2.553095291006414

Epoch: 6| Step: 1
Training loss: 1.8251347008729428
Validation loss: 2.559344681333563

Epoch: 6| Step: 2
Training loss: 2.8488850604484703
Validation loss: 2.5609584686638733

Epoch: 6| Step: 3
Training loss: 2.527467232330451
Validation loss: 2.565512144630718

Epoch: 6| Step: 4
Training loss: 3.024774457862116
Validation loss: 2.5738025316161783

Epoch: 6| Step: 5
Training loss: 2.7402041835304436
Validation loss: 2.5865873229091694

Epoch: 6| Step: 6
Training loss: 3.268882623319703
Validation loss: 2.5829229561480322

Epoch: 6| Step: 7
Training loss: 2.7578192432526447
Validation loss: 2.5871338765445646

Epoch: 6| Step: 8
Training loss: 3.238415244796364
Validation loss: 2.5953859284349736

Epoch: 6| Step: 9
Training loss: 3.4068773724315546
Validation loss: 2.5840275609347874

Epoch: 6| Step: 10
Training loss: 2.627591987836204
Validation loss: 2.577146836435496

Epoch: 6| Step: 11
Training loss: 3.121102305604669
Validation loss: 2.565434732974021

Epoch: 6| Step: 12
Training loss: 3.1442011120855082
Validation loss: 2.557987961847356

Epoch: 6| Step: 13
Training loss: 2.8760621140713534
Validation loss: 2.557768745115022

Epoch: 196| Step: 0
Training loss: 2.274342989107952
Validation loss: 2.559915115760686

Epoch: 6| Step: 1
Training loss: 2.8956743009154917
Validation loss: 2.57142699029255

Epoch: 6| Step: 2
Training loss: 2.445386794061586
Validation loss: 2.5818934160646143

Epoch: 6| Step: 3
Training loss: 2.4674728566757116
Validation loss: 2.5937191155447277

Epoch: 6| Step: 4
Training loss: 3.166881068818425
Validation loss: 2.587478391257795

Epoch: 6| Step: 5
Training loss: 2.840196506256712
Validation loss: 2.577888343168936

Epoch: 6| Step: 6
Training loss: 3.112700098185676
Validation loss: 2.552942787157193

Epoch: 6| Step: 7
Training loss: 3.291603828184484
Validation loss: 2.55692459264535

Epoch: 6| Step: 8
Training loss: 2.604046709476756
Validation loss: 2.551150585003595

Epoch: 6| Step: 9
Training loss: 3.489444073227933
Validation loss: 2.547689002161613

Epoch: 6| Step: 10
Training loss: 3.2950350431625073
Validation loss: 2.5436666182663563

Epoch: 6| Step: 11
Training loss: 2.1811967772190863
Validation loss: 2.5506775155626826

Epoch: 6| Step: 12
Training loss: 2.7253130916651243
Validation loss: 2.543685502327632

Epoch: 6| Step: 13
Training loss: 3.9170687584060935
Validation loss: 2.545568383044473

Epoch: 197| Step: 0
Training loss: 3.0511647861307036
Validation loss: 2.54634889339725

Epoch: 6| Step: 1
Training loss: 3.0209168170486493
Validation loss: 2.5487790751245103

Epoch: 6| Step: 2
Training loss: 2.660901652804176
Validation loss: 2.549285861902845

Epoch: 6| Step: 3
Training loss: 1.911403256765339
Validation loss: 2.5467579639388944

Epoch: 6| Step: 4
Training loss: 3.3175617626796847
Validation loss: 2.5528468952150987

Epoch: 6| Step: 5
Training loss: 2.6248300588184756
Validation loss: 2.5435471446310443

Epoch: 6| Step: 6
Training loss: 3.208017028145058
Validation loss: 2.548369093657818

Epoch: 6| Step: 7
Training loss: 3.266244345892572
Validation loss: 2.5494942573158483

Epoch: 6| Step: 8
Training loss: 2.9821059303836437
Validation loss: 2.546514650066436

Epoch: 6| Step: 9
Training loss: 2.909471592595487
Validation loss: 2.5426952429896894

Epoch: 6| Step: 10
Training loss: 2.4221018038962567
Validation loss: 2.541313756780297

Epoch: 6| Step: 11
Training loss: 3.105919225876761
Validation loss: 2.5457552263781578

Epoch: 6| Step: 12
Training loss: 3.252527867754184
Validation loss: 2.5467526408787373

Epoch: 6| Step: 13
Training loss: 2.3456074792831165
Validation loss: 2.544264540109965

Epoch: 198| Step: 0
Training loss: 3.0265943817996024
Validation loss: 2.54384168024437

Epoch: 6| Step: 1
Training loss: 2.9239468496269487
Validation loss: 2.5450953779837397

Epoch: 6| Step: 2
Training loss: 2.272419180361408
Validation loss: 2.544905218324977

Epoch: 6| Step: 3
Training loss: 2.736683508634918
Validation loss: 2.5448844031202666

Epoch: 6| Step: 4
Training loss: 2.7388450488368425
Validation loss: 2.543513021954735

Epoch: 6| Step: 5
Training loss: 3.1132852322159286
Validation loss: 2.5449376189078783

Epoch: 6| Step: 6
Training loss: 2.8822727266623844
Validation loss: 2.5467642392568703

Epoch: 6| Step: 7
Training loss: 3.036297871890323
Validation loss: 2.5526651294799727

Epoch: 6| Step: 8
Training loss: 2.2090627317419025
Validation loss: 2.5556220805325522

Epoch: 6| Step: 9
Training loss: 2.701074340559919
Validation loss: 2.5572191393570005

Epoch: 6| Step: 10
Training loss: 3.3872500732115545
Validation loss: 2.5652013156988316

Epoch: 6| Step: 11
Training loss: 3.7487850764288115
Validation loss: 2.553807967488092

Epoch: 6| Step: 12
Training loss: 2.4734885214714115
Validation loss: 2.5601540658704987

Epoch: 6| Step: 13
Training loss: 3.092445638019994
Validation loss: 2.549586155771891

Epoch: 199| Step: 0
Training loss: 2.7230497538335627
Validation loss: 2.5642743504252774

Epoch: 6| Step: 1
Training loss: 3.3794371083166177
Validation loss: 2.5685937269309704

Epoch: 6| Step: 2
Training loss: 2.819052544235716
Validation loss: 2.5558505740318567

Epoch: 6| Step: 3
Training loss: 2.5900360542350658
Validation loss: 2.5793541666378723

Epoch: 6| Step: 4
Training loss: 2.7055594005814143
Validation loss: 2.5772473732990058

Epoch: 6| Step: 5
Training loss: 2.7771770357510217
Validation loss: 2.5685543487093803

Epoch: 6| Step: 6
Training loss: 3.012261446929566
Validation loss: 2.5698119478185117

Epoch: 6| Step: 7
Training loss: 3.0655583272327434
Validation loss: 2.57344422983334

Epoch: 6| Step: 8
Training loss: 2.7097324474338835
Validation loss: 2.5645083678967753

Epoch: 6| Step: 9
Training loss: 2.5471840887382653
Validation loss: 2.5758202596056967

Epoch: 6| Step: 10
Training loss: 2.917490234358656
Validation loss: 2.5973811040039485

Epoch: 6| Step: 11
Training loss: 3.4248248758583046
Validation loss: 2.601121044091464

Epoch: 6| Step: 12
Training loss: 3.208915426450396
Validation loss: 2.5727928769202357

Epoch: 6| Step: 13
Training loss: 2.3352590743112063
Validation loss: 2.5538656229734285

Epoch: 200| Step: 0
Training loss: 3.1114058260365898
Validation loss: 2.545577768187375

Epoch: 6| Step: 1
Training loss: 2.870141111354017
Validation loss: 2.552942009913706

Epoch: 6| Step: 2
Training loss: 2.1122546849216333
Validation loss: 2.545207559041877

Epoch: 6| Step: 3
Training loss: 3.3847783039469688
Validation loss: 2.5466214301698074

Epoch: 6| Step: 4
Training loss: 3.1856395303336065
Validation loss: 2.5484185055268767

Epoch: 6| Step: 5
Training loss: 2.2085852089478246
Validation loss: 2.5418394047865918

Epoch: 6| Step: 6
Training loss: 2.5355874093165127
Validation loss: 2.5471199834313643

Epoch: 6| Step: 7
Training loss: 3.0217643267810357
Validation loss: 2.546553323123827

Epoch: 6| Step: 8
Training loss: 3.2807991808049617
Validation loss: 2.5553783516114272

Epoch: 6| Step: 9
Training loss: 2.4111795834176246
Validation loss: 2.558875106450298

Epoch: 6| Step: 10
Training loss: 2.8063726861383573
Validation loss: 2.565703693640057

Epoch: 6| Step: 11
Training loss: 3.372175801093989
Validation loss: 2.578583651627151

Epoch: 6| Step: 12
Training loss: 2.9782830019303743
Validation loss: 2.5626416691181753

Epoch: 6| Step: 13
Training loss: 2.785865297521152
Validation loss: 2.5590093544877672

Epoch: 201| Step: 0
Training loss: 2.8329034553986947
Validation loss: 2.552228997706691

Epoch: 6| Step: 1
Training loss: 2.979944745517999
Validation loss: 2.554420703369567

Epoch: 6| Step: 2
Training loss: 2.7562339522744455
Validation loss: 2.547595907210508

Epoch: 6| Step: 3
Training loss: 3.1794003068724033
Validation loss: 2.5604817105323643

Epoch: 6| Step: 4
Training loss: 3.1621244546814617
Validation loss: 2.558777001206179

Epoch: 6| Step: 5
Training loss: 2.35915783015296
Validation loss: 2.556145515295263

Epoch: 6| Step: 6
Training loss: 2.999755849440084
Validation loss: 2.5510454134507694

Epoch: 6| Step: 7
Training loss: 2.675682879122432
Validation loss: 2.549178877625946

Epoch: 6| Step: 8
Training loss: 3.1668003622910827
Validation loss: 2.5406929186950133

Epoch: 6| Step: 9
Training loss: 3.3079062223784104
Validation loss: 2.5476052094121253

Epoch: 6| Step: 10
Training loss: 2.53502401938712
Validation loss: 2.5501735899212807

Epoch: 6| Step: 11
Training loss: 2.8464684540518115
Validation loss: 2.551125758930827

Epoch: 6| Step: 12
Training loss: 2.623665788452224
Validation loss: 2.5498267967279897

Epoch: 6| Step: 13
Training loss: 2.87006319195764
Validation loss: 2.549002106346685

Epoch: 202| Step: 0
Training loss: 2.937299031626894
Validation loss: 2.5519846729916154

Epoch: 6| Step: 1
Training loss: 2.6418570629383633
Validation loss: 2.5619932164270045

Epoch: 6| Step: 2
Training loss: 2.9425827854797655
Validation loss: 2.5687584463923314

Epoch: 6| Step: 3
Training loss: 3.2708556706987975
Validation loss: 2.5813248223218506

Epoch: 6| Step: 4
Training loss: 3.02613587924934
Validation loss: 2.609298951547235

Epoch: 6| Step: 5
Training loss: 2.714807919053117
Validation loss: 2.6525312263783434

Epoch: 6| Step: 6
Training loss: 3.1496564526394493
Validation loss: 2.645814188399525

Epoch: 6| Step: 7
Training loss: 2.653643237790581
Validation loss: 2.623570571105564

Epoch: 6| Step: 8
Training loss: 3.1370308270677136
Validation loss: 2.6112184841369044

Epoch: 6| Step: 9
Training loss: 2.964048175847538
Validation loss: 2.5718984619732326

Epoch: 6| Step: 10
Training loss: 3.1099202813728426
Validation loss: 2.55699653410303

Epoch: 6| Step: 11
Training loss: 3.2367008710547416
Validation loss: 2.549726863302176

Epoch: 6| Step: 12
Training loss: 2.095776161137046
Validation loss: 2.547458187583197

Epoch: 6| Step: 13
Training loss: 2.3814395138277225
Validation loss: 2.5472064723254872

Epoch: 203| Step: 0
Training loss: 3.3003436458719215
Validation loss: 2.5487318569634914

Epoch: 6| Step: 1
Training loss: 3.024304957973121
Validation loss: 2.5480664992525934

Epoch: 6| Step: 2
Training loss: 2.6822745510900887
Validation loss: 2.547236995813943

Epoch: 6| Step: 3
Training loss: 3.1950076081330123
Validation loss: 2.5491843756348787

Epoch: 6| Step: 4
Training loss: 3.337848625119759
Validation loss: 2.5526889262486963

Epoch: 6| Step: 5
Training loss: 2.6928920326560135
Validation loss: 2.5457963731108655

Epoch: 6| Step: 6
Training loss: 2.417940845236043
Validation loss: 2.5419716298199724

Epoch: 6| Step: 7
Training loss: 2.7067102899778672
Validation loss: 2.5446531346713126

Epoch: 6| Step: 8
Training loss: 2.349701509389552
Validation loss: 2.537402766537097

Epoch: 6| Step: 9
Training loss: 2.9405897407971824
Validation loss: 2.54047600790186

Epoch: 6| Step: 10
Training loss: 2.607297332875375
Validation loss: 2.5501919060723153

Epoch: 6| Step: 11
Training loss: 2.7784059534801577
Validation loss: 2.5522252866849833

Epoch: 6| Step: 12
Training loss: 3.1768309112497435
Validation loss: 2.556914215438882

Epoch: 6| Step: 13
Training loss: 3.3678843049409055
Validation loss: 2.5589014973723123

Epoch: 204| Step: 0
Training loss: 2.873752986977756
Validation loss: 2.58803975204014

Epoch: 6| Step: 1
Training loss: 3.238229417558643
Validation loss: 2.610900384911345

Epoch: 6| Step: 2
Training loss: 2.6547879851724168
Validation loss: 2.6590992171221197

Epoch: 6| Step: 3
Training loss: 2.8292235880440804
Validation loss: 2.6841500884767475

Epoch: 6| Step: 4
Training loss: 1.9874204559722985
Validation loss: 2.698204977885922

Epoch: 6| Step: 5
Training loss: 2.6184708366816865
Validation loss: 2.6728028492198037

Epoch: 6| Step: 6
Training loss: 2.6024721863476064
Validation loss: 2.6194374929481063

Epoch: 6| Step: 7
Training loss: 2.879288004974212
Validation loss: 2.5907934748914214

Epoch: 6| Step: 8
Training loss: 2.977468758138106
Validation loss: 2.548762374254283

Epoch: 6| Step: 9
Training loss: 2.958090346838824
Validation loss: 2.5502961116114697

Epoch: 6| Step: 10
Training loss: 2.986527869740351
Validation loss: 2.5351766718237467

Epoch: 6| Step: 11
Training loss: 3.274962441032468
Validation loss: 2.5321895274158277

Epoch: 6| Step: 12
Training loss: 3.054338127898765
Validation loss: 2.5411945014053163

Epoch: 6| Step: 13
Training loss: 3.486719822183624
Validation loss: 2.540996497118507

Epoch: 205| Step: 0
Training loss: 2.78708944333601
Validation loss: 2.544349769862988

Epoch: 6| Step: 1
Training loss: 2.920663674325229
Validation loss: 2.538945600596795

Epoch: 6| Step: 2
Training loss: 2.9493322489542746
Validation loss: 2.545164423526205

Epoch: 6| Step: 3
Training loss: 2.5282461922434987
Validation loss: 2.5391614608474087

Epoch: 6| Step: 4
Training loss: 2.569486444719958
Validation loss: 2.539970010861885

Epoch: 6| Step: 5
Training loss: 2.7311840512063115
Validation loss: 2.539784735480978

Epoch: 6| Step: 6
Training loss: 2.5253494625173984
Validation loss: 2.5397976324610942

Epoch: 6| Step: 7
Training loss: 3.1518569438053285
Validation loss: 2.541704435452858

Epoch: 6| Step: 8
Training loss: 2.5595995607709856
Validation loss: 2.5416656916425002

Epoch: 6| Step: 9
Training loss: 3.1770122249129122
Validation loss: 2.547027238082741

Epoch: 6| Step: 10
Training loss: 3.381227751991848
Validation loss: 2.547146328066501

Epoch: 6| Step: 11
Training loss: 3.4627771590265772
Validation loss: 2.5546108973320596

Epoch: 6| Step: 12
Training loss: 2.8291172373465487
Validation loss: 2.5531713271478145

Epoch: 6| Step: 13
Training loss: 2.940949220853892
Validation loss: 2.545844870217046

Epoch: 206| Step: 0
Training loss: 3.5641518494252904
Validation loss: 2.545921543304307

Epoch: 6| Step: 1
Training loss: 2.5707565897940876
Validation loss: 2.5413973423688825

Epoch: 6| Step: 2
Training loss: 2.537431868216336
Validation loss: 2.5419737114136627

Epoch: 6| Step: 3
Training loss: 3.1966609581136267
Validation loss: 2.538498762352231

Epoch: 6| Step: 4
Training loss: 2.4957397400932577
Validation loss: 2.543872829621266

Epoch: 6| Step: 5
Training loss: 2.9642503870895993
Validation loss: 2.545326761358504

Epoch: 6| Step: 6
Training loss: 2.6946909312169205
Validation loss: 2.541015472655503

Epoch: 6| Step: 7
Training loss: 2.776521671061522
Validation loss: 2.5446480399322713

Epoch: 6| Step: 8
Training loss: 3.134005426466674
Validation loss: 2.550259216294707

Epoch: 6| Step: 9
Training loss: 3.0122953226670712
Validation loss: 2.5474207962857345

Epoch: 6| Step: 10
Training loss: 2.8223968158576374
Validation loss: 2.5701416848550327

Epoch: 6| Step: 11
Training loss: 2.805284611887469
Validation loss: 2.5623117913520717

Epoch: 6| Step: 12
Training loss: 2.6221547828863607
Validation loss: 2.5525173174029487

Epoch: 6| Step: 13
Training loss: 2.979379517391966
Validation loss: 2.558257145248403

Epoch: 207| Step: 0
Training loss: 2.8798182374499803
Validation loss: 2.5608120052451286

Epoch: 6| Step: 1
Training loss: 2.9454204832969593
Validation loss: 2.5648637159922267

Epoch: 6| Step: 2
Training loss: 3.260436247907995
Validation loss: 2.5721990780237394

Epoch: 6| Step: 3
Training loss: 2.8490529343951896
Validation loss: 2.551793372076856

Epoch: 6| Step: 4
Training loss: 2.877063673994079
Validation loss: 2.557687794423452

Epoch: 6| Step: 5
Training loss: 3.384855785368727
Validation loss: 2.5612555762915155

Epoch: 6| Step: 6
Training loss: 2.1356026421175667
Validation loss: 2.5696954196819966

Epoch: 6| Step: 7
Training loss: 2.643753906679987
Validation loss: 2.58266230636461

Epoch: 6| Step: 8
Training loss: 3.2907753876522077
Validation loss: 2.589919545172835

Epoch: 6| Step: 9
Training loss: 3.0970835595293567
Validation loss: 2.5681838580552183

Epoch: 6| Step: 10
Training loss: 2.3381845134960653
Validation loss: 2.546993402592199

Epoch: 6| Step: 11
Training loss: 2.955288210786467
Validation loss: 2.541182898791568

Epoch: 6| Step: 12
Training loss: 2.7883949656343523
Validation loss: 2.5397119178439453

Epoch: 6| Step: 13
Training loss: 2.418283864134684
Validation loss: 2.536038072187379

Epoch: 208| Step: 0
Training loss: 2.5693745394525136
Validation loss: 2.532214233393227

Epoch: 6| Step: 1
Training loss: 2.974500527647802
Validation loss: 2.539600915356759

Epoch: 6| Step: 2
Training loss: 2.827249296560157
Validation loss: 2.537746693425725

Epoch: 6| Step: 3
Training loss: 3.0196424219508695
Validation loss: 2.540159808274924

Epoch: 6| Step: 4
Training loss: 2.825399107296
Validation loss: 2.537688404013358

Epoch: 6| Step: 5
Training loss: 2.9893441099006086
Validation loss: 2.542979474454075

Epoch: 6| Step: 6
Training loss: 3.1626503889791797
Validation loss: 2.538661420395316

Epoch: 6| Step: 7
Training loss: 3.7122959581811266
Validation loss: 2.5437348429152284

Epoch: 6| Step: 8
Training loss: 2.32393181576398
Validation loss: 2.538479343839443

Epoch: 6| Step: 9
Training loss: 2.8654963107733473
Validation loss: 2.5510486895441944

Epoch: 6| Step: 10
Training loss: 2.890950942349977
Validation loss: 2.550169538636298

Epoch: 6| Step: 11
Training loss: 2.2348541599626786
Validation loss: 2.5549829126645585

Epoch: 6| Step: 12
Training loss: 2.7167382525352135
Validation loss: 2.563152096201174

Epoch: 6| Step: 13
Training loss: 2.9161068697001995
Validation loss: 2.5707404994060408

Epoch: 209| Step: 0
Training loss: 2.8996691284847484
Validation loss: 2.5773908925412945

Epoch: 6| Step: 1
Training loss: 2.292217697017458
Validation loss: 2.5988283145581943

Epoch: 6| Step: 2
Training loss: 3.4228590852271115
Validation loss: 2.6013822598114613

Epoch: 6| Step: 3
Training loss: 2.93803952720649
Validation loss: 2.619213209596081

Epoch: 6| Step: 4
Training loss: 2.210228256934995
Validation loss: 2.630793786883511

Epoch: 6| Step: 5
Training loss: 3.0395821173711015
Validation loss: 2.6123661863662764

Epoch: 6| Step: 6
Training loss: 3.300454749939239
Validation loss: 2.6125439387726033

Epoch: 6| Step: 7
Training loss: 2.9902056711963287
Validation loss: 2.574962833772304

Epoch: 6| Step: 8
Training loss: 2.914806281273017
Validation loss: 2.5420913469257407

Epoch: 6| Step: 9
Training loss: 2.504062403720905
Validation loss: 2.53401128673438

Epoch: 6| Step: 10
Training loss: 2.4260999682114535
Validation loss: 2.529239719682809

Epoch: 6| Step: 11
Training loss: 3.1274465520669024
Validation loss: 2.533646165332664

Epoch: 6| Step: 12
Training loss: 2.667305502267323
Validation loss: 2.5299128063208705

Epoch: 6| Step: 13
Training loss: 3.5731450370265465
Validation loss: 2.5296939699201624

Epoch: 210| Step: 0
Training loss: 3.572834484760407
Validation loss: 2.533260758622797

Epoch: 6| Step: 1
Training loss: 2.6175941265273477
Validation loss: 2.538546947455392

Epoch: 6| Step: 2
Training loss: 2.456581838774545
Validation loss: 2.5406430044152906

Epoch: 6| Step: 3
Training loss: 2.9386185484660428
Validation loss: 2.537189926870311

Epoch: 6| Step: 4
Training loss: 2.674380906382237
Validation loss: 2.5376254438826256

Epoch: 6| Step: 5
Training loss: 2.8766207894755387
Validation loss: 2.542550721651487

Epoch: 6| Step: 6
Training loss: 2.9621626199079256
Validation loss: 2.540146960568368

Epoch: 6| Step: 7
Training loss: 2.848364136337527
Validation loss: 2.536737695525048

Epoch: 6| Step: 8
Training loss: 3.3923865458015325
Validation loss: 2.5375035116447293

Epoch: 6| Step: 9
Training loss: 3.153147768632177
Validation loss: 2.528201672198946

Epoch: 6| Step: 10
Training loss: 2.111499310098834
Validation loss: 2.5258169311241394

Epoch: 6| Step: 11
Training loss: 3.030972497566723
Validation loss: 2.525626406056096

Epoch: 6| Step: 12
Training loss: 2.9584383520550426
Validation loss: 2.5257991223128147

Epoch: 6| Step: 13
Training loss: 2.5843112591744157
Validation loss: 2.5249196050210174

Epoch: 211| Step: 0
Training loss: 2.5760582240141123
Validation loss: 2.5562824519893783

Epoch: 6| Step: 1
Training loss: 2.327026107844903
Validation loss: 2.5786205363670645

Epoch: 6| Step: 2
Training loss: 2.730517472908906
Validation loss: 2.614448907352173

Epoch: 6| Step: 3
Training loss: 2.622020119980493
Validation loss: 2.64467185561192

Epoch: 6| Step: 4
Training loss: 3.3220665461094825
Validation loss: 2.6987185132134766

Epoch: 6| Step: 5
Training loss: 3.3382831697572293
Validation loss: 2.706222076336371

Epoch: 6| Step: 6
Training loss: 2.3022545338027953
Validation loss: 2.6388437158949194

Epoch: 6| Step: 7
Training loss: 3.5274773083449698
Validation loss: 2.5918835941049974

Epoch: 6| Step: 8
Training loss: 3.358637387226694
Validation loss: 2.5509754819218475

Epoch: 6| Step: 9
Training loss: 2.6323354951153157
Validation loss: 2.527678911419069

Epoch: 6| Step: 10
Training loss: 2.876316266811359
Validation loss: 2.519940651372012

Epoch: 6| Step: 11
Training loss: 3.0274842457318085
Validation loss: 2.5252532557439507

Epoch: 6| Step: 12
Training loss: 2.866264672888536
Validation loss: 2.5306408897601282

Epoch: 6| Step: 13
Training loss: 2.832650120958053
Validation loss: 2.5322853886629955

Epoch: 212| Step: 0
Training loss: 3.021596264139118
Validation loss: 2.5388341001102748

Epoch: 6| Step: 1
Training loss: 2.937133441536757
Validation loss: 2.5388870529505407

Epoch: 6| Step: 2
Training loss: 2.908836936159707
Validation loss: 2.5408645028407646

Epoch: 6| Step: 3
Training loss: 2.2092958428043796
Validation loss: 2.541235075332082

Epoch: 6| Step: 4
Training loss: 2.450942216426266
Validation loss: 2.5426512481667904

Epoch: 6| Step: 5
Training loss: 2.977609365201937
Validation loss: 2.534073331568496

Epoch: 6| Step: 6
Training loss: 2.8784232284329594
Validation loss: 2.53619664462298

Epoch: 6| Step: 7
Training loss: 2.7835939795456244
Validation loss: 2.529935292049531

Epoch: 6| Step: 8
Training loss: 2.7580239536387667
Validation loss: 2.527132707299867

Epoch: 6| Step: 9
Training loss: 3.104679875971625
Validation loss: 2.529145443883653

Epoch: 6| Step: 10
Training loss: 3.075577819623582
Validation loss: 2.528980964446179

Epoch: 6| Step: 11
Training loss: 2.8909717248769637
Validation loss: 2.5345807773848765

Epoch: 6| Step: 12
Training loss: 3.258771210993958
Validation loss: 2.5384739498939632

Epoch: 6| Step: 13
Training loss: 3.491358989430708
Validation loss: 2.5534425087472195

Epoch: 213| Step: 0
Training loss: 2.6601799111007187
Validation loss: 2.550562928589632

Epoch: 6| Step: 1
Training loss: 2.567169308264202
Validation loss: 2.5446894876605124

Epoch: 6| Step: 2
Training loss: 3.115907640559892
Validation loss: 2.544386007285992

Epoch: 6| Step: 3
Training loss: 2.9405328231455914
Validation loss: 2.5622477513575515

Epoch: 6| Step: 4
Training loss: 3.0379547218328877
Validation loss: 2.5632669335130602

Epoch: 6| Step: 5
Training loss: 2.497616967258334
Validation loss: 2.550080844040787

Epoch: 6| Step: 6
Training loss: 3.096616399690322
Validation loss: 2.5407623663961623

Epoch: 6| Step: 7
Training loss: 2.699269626872182
Validation loss: 2.5491946515597848

Epoch: 6| Step: 8
Training loss: 2.28782823636151
Validation loss: 2.54172983667664

Epoch: 6| Step: 9
Training loss: 2.9219177569356565
Validation loss: 2.5426690569111083

Epoch: 6| Step: 10
Training loss: 2.7377262178777437
Validation loss: 2.5394051743857267

Epoch: 6| Step: 11
Training loss: 3.5554734922581535
Validation loss: 2.5341683511999897

Epoch: 6| Step: 12
Training loss: 2.980076435312144
Validation loss: 2.5257318879955397

Epoch: 6| Step: 13
Training loss: 2.9576407324745477
Validation loss: 2.5281190000318587

Epoch: 214| Step: 0
Training loss: 2.684150027350135
Validation loss: 2.5253347385543483

Epoch: 6| Step: 1
Training loss: 2.910655302742294
Validation loss: 2.5282015099561472

Epoch: 6| Step: 2
Training loss: 3.1073480641669873
Validation loss: 2.5259388520342383

Epoch: 6| Step: 3
Training loss: 2.712986416426616
Validation loss: 2.520263157547494

Epoch: 6| Step: 4
Training loss: 3.522927257868575
Validation loss: 2.5244704131081037

Epoch: 6| Step: 5
Training loss: 2.223190270281596
Validation loss: 2.524410121190521

Epoch: 6| Step: 6
Training loss: 3.150523211910851
Validation loss: 2.53155322317848

Epoch: 6| Step: 7
Training loss: 2.5062625646870793
Validation loss: 2.536308290369112

Epoch: 6| Step: 8
Training loss: 3.169259030840715
Validation loss: 2.5422140937648168

Epoch: 6| Step: 9
Training loss: 2.7399695139950135
Validation loss: 2.536598154377393

Epoch: 6| Step: 10
Training loss: 3.0965066053608634
Validation loss: 2.5506939516193716

Epoch: 6| Step: 11
Training loss: 2.648910345217122
Validation loss: 2.5544170833478876

Epoch: 6| Step: 12
Training loss: 2.6288112946319337
Validation loss: 2.588575356543737

Epoch: 6| Step: 13
Training loss: 2.8889955619125636
Validation loss: 2.5926418929760424

Epoch: 215| Step: 0
Training loss: 3.172558940944147
Validation loss: 2.5952216227497913

Epoch: 6| Step: 1
Training loss: 3.173694257994159
Validation loss: 2.606353105899911

Epoch: 6| Step: 2
Training loss: 3.353241186626527
Validation loss: 2.564361301457001

Epoch: 6| Step: 3
Training loss: 2.7275348667395227
Validation loss: 2.550973472996366

Epoch: 6| Step: 4
Training loss: 2.968088015986401
Validation loss: 2.5498907998011506

Epoch: 6| Step: 5
Training loss: 2.351474899738792
Validation loss: 2.535878197844966

Epoch: 6| Step: 6
Training loss: 2.482135459049879
Validation loss: 2.5248265457722914

Epoch: 6| Step: 7
Training loss: 2.365668586924039
Validation loss: 2.5344062056024494

Epoch: 6| Step: 8
Training loss: 2.7663861967500294
Validation loss: 2.5277959525535136

Epoch: 6| Step: 9
Training loss: 2.783946669456893
Validation loss: 2.5378967032041833

Epoch: 6| Step: 10
Training loss: 2.805090235110417
Validation loss: 2.5303557809226755

Epoch: 6| Step: 11
Training loss: 3.3023826551706383
Validation loss: 2.531708846287637

Epoch: 6| Step: 12
Training loss: 2.7714952142031697
Validation loss: 2.531177971940703

Epoch: 6| Step: 13
Training loss: 3.0297464003992847
Validation loss: 2.522952752334426

Epoch: 216| Step: 0
Training loss: 3.2302827608566855
Validation loss: 2.53677922297935

Epoch: 6| Step: 1
Training loss: 3.252257956574336
Validation loss: 2.526010864056477

Epoch: 6| Step: 2
Training loss: 2.705173487996415
Validation loss: 2.523717233533027

Epoch: 6| Step: 3
Training loss: 2.931157508806148
Validation loss: 2.5254540322644243

Epoch: 6| Step: 4
Training loss: 2.5155658596503256
Validation loss: 2.528572531010322

Epoch: 6| Step: 5
Training loss: 2.440290174583636
Validation loss: 2.525770694537085

Epoch: 6| Step: 6
Training loss: 2.9268260765833625
Validation loss: 2.5393792269595687

Epoch: 6| Step: 7
Training loss: 3.256834326976738
Validation loss: 2.549216890780194

Epoch: 6| Step: 8
Training loss: 2.8873972424474883
Validation loss: 2.5619401017447934

Epoch: 6| Step: 9
Training loss: 2.407160599058194
Validation loss: 2.566376020432945

Epoch: 6| Step: 10
Training loss: 2.3459210322391404
Validation loss: 2.564577416595532

Epoch: 6| Step: 11
Training loss: 3.4675920632922246
Validation loss: 2.5523471996387856

Epoch: 6| Step: 12
Training loss: 2.6369413606838243
Validation loss: 2.5399404780088317

Epoch: 6| Step: 13
Training loss: 2.966456119338188
Validation loss: 2.523748299127198

Epoch: 217| Step: 0
Training loss: 2.615318883850934
Validation loss: 2.514170057840123

Epoch: 6| Step: 1
Training loss: 2.68757629286241
Validation loss: 2.517397584765263

Epoch: 6| Step: 2
Training loss: 2.406938924879097
Validation loss: 2.517442644152271

Epoch: 6| Step: 3
Training loss: 2.5756348577290846
Validation loss: 2.5108100999128116

Epoch: 6| Step: 4
Training loss: 3.2461241572639454
Validation loss: 2.516143919570997

Epoch: 6| Step: 5
Training loss: 3.658205731946482
Validation loss: 2.5195732696353983

Epoch: 6| Step: 6
Training loss: 2.8968224974383636
Validation loss: 2.520372624418819

Epoch: 6| Step: 7
Training loss: 3.16231776982772
Validation loss: 2.524273042863039

Epoch: 6| Step: 8
Training loss: 3.124078691094681
Validation loss: 2.521472802679758

Epoch: 6| Step: 9
Training loss: 3.003943235965817
Validation loss: 2.5184524148223177

Epoch: 6| Step: 10
Training loss: 2.8087655599831156
Validation loss: 2.5186266836631033

Epoch: 6| Step: 11
Training loss: 2.847125052264551
Validation loss: 2.5254579120527145

Epoch: 6| Step: 12
Training loss: 2.5120262800166206
Validation loss: 2.53453585983356

Epoch: 6| Step: 13
Training loss: 1.6311517327771188
Validation loss: 2.542232031624123

Epoch: 218| Step: 0
Training loss: 3.1708597898110575
Validation loss: 2.5520318761731335

Epoch: 6| Step: 1
Training loss: 2.7553406787567964
Validation loss: 2.566651633540496

Epoch: 6| Step: 2
Training loss: 2.610031045458666
Validation loss: 2.5734088170105993

Epoch: 6| Step: 3
Training loss: 2.1266245522509544
Validation loss: 2.5814674544667566

Epoch: 6| Step: 4
Training loss: 2.8311746077783693
Validation loss: 2.5717483391432965

Epoch: 6| Step: 5
Training loss: 2.3187202102104782
Validation loss: 2.5639714214097244

Epoch: 6| Step: 6
Training loss: 2.8905068863115435
Validation loss: 2.541839890920635

Epoch: 6| Step: 7
Training loss: 2.455709274605167
Validation loss: 2.5383237934442975

Epoch: 6| Step: 8
Training loss: 2.779764528799389
Validation loss: 2.5315279983314762

Epoch: 6| Step: 9
Training loss: 3.3468422539940716
Validation loss: 2.538071400552633

Epoch: 6| Step: 10
Training loss: 3.1937129486980576
Validation loss: 2.5317022045519533

Epoch: 6| Step: 11
Training loss: 3.4020045710313735
Validation loss: 2.5207469884379647

Epoch: 6| Step: 12
Training loss: 2.953892199450847
Validation loss: 2.522495024817137

Epoch: 6| Step: 13
Training loss: 2.9505723688933894
Validation loss: 2.5248422657277185

Epoch: 219| Step: 0
Training loss: 2.4733303410733916
Validation loss: 2.5235080829129743

Epoch: 6| Step: 1
Training loss: 2.3355955556187955
Validation loss: 2.535601364991707

Epoch: 6| Step: 2
Training loss: 2.937498701379367
Validation loss: 2.5299328843938618

Epoch: 6| Step: 3
Training loss: 3.0445929955889115
Validation loss: 2.5396979575017564

Epoch: 6| Step: 4
Training loss: 2.933260841629851
Validation loss: 2.5287831777989087

Epoch: 6| Step: 5
Training loss: 2.79992909682283
Validation loss: 2.5400059151219265

Epoch: 6| Step: 6
Training loss: 2.6593134549076076
Validation loss: 2.5382115182289753

Epoch: 6| Step: 7
Training loss: 3.0766979336897697
Validation loss: 2.539240964260791

Epoch: 6| Step: 8
Training loss: 3.2254551056289302
Validation loss: 2.545827765425379

Epoch: 6| Step: 9
Training loss: 2.791727796046606
Validation loss: 2.5444460596151504

Epoch: 6| Step: 10
Training loss: 2.3491558547333296
Validation loss: 2.537377303809491

Epoch: 6| Step: 11
Training loss: 3.323781792760137
Validation loss: 2.550136088649282

Epoch: 6| Step: 12
Training loss: 3.164914466220408
Validation loss: 2.5472206733213336

Epoch: 6| Step: 13
Training loss: 2.4616694255065266
Validation loss: 2.5334491522187315

Epoch: 220| Step: 0
Training loss: 2.8682634792950448
Validation loss: 2.5350519358524224

Epoch: 6| Step: 1
Training loss: 3.0720893047782973
Validation loss: 2.539476906504116

Epoch: 6| Step: 2
Training loss: 2.580921482859096
Validation loss: 2.544488495995004

Epoch: 6| Step: 3
Training loss: 2.842844389197447
Validation loss: 2.5447102772587353

Epoch: 6| Step: 4
Training loss: 3.3344197092392673
Validation loss: 2.545193071835099

Epoch: 6| Step: 5
Training loss: 3.1728180484052553
Validation loss: 2.5493440661492546

Epoch: 6| Step: 6
Training loss: 2.4724566483047954
Validation loss: 2.545059862822708

Epoch: 6| Step: 7
Training loss: 2.815348729541885
Validation loss: 2.5573067703604706

Epoch: 6| Step: 8
Training loss: 3.383274672301932
Validation loss: 2.560946632252899

Epoch: 6| Step: 9
Training loss: 2.8877446851228172
Validation loss: 2.541226039343944

Epoch: 6| Step: 10
Training loss: 2.752500004573479
Validation loss: 2.540819284710899

Epoch: 6| Step: 11
Training loss: 2.299110103610562
Validation loss: 2.5476110761012185

Epoch: 6| Step: 12
Training loss: 2.5684325233167127
Validation loss: 2.527204946008801

Epoch: 6| Step: 13
Training loss: 2.5572164075127266
Validation loss: 2.535469045359291

Epoch: 221| Step: 0
Training loss: 2.408978389251928
Validation loss: 2.5300572982166196

Epoch: 6| Step: 1
Training loss: 2.647594216375032
Validation loss: 2.523064832727287

Epoch: 6| Step: 2
Training loss: 3.0621647553971973
Validation loss: 2.5215467519619144

Epoch: 6| Step: 3
Training loss: 2.4757189351909945
Validation loss: 2.528979398271477

Epoch: 6| Step: 4
Training loss: 2.9757341649062723
Validation loss: 2.528688432814048

Epoch: 6| Step: 5
Training loss: 3.2504550908648917
Validation loss: 2.5350294550569745

Epoch: 6| Step: 6
Training loss: 2.4831458355912583
Validation loss: 2.538863607967094

Epoch: 6| Step: 7
Training loss: 3.2486848370958312
Validation loss: 2.5310591683108172

Epoch: 6| Step: 8
Training loss: 2.729702690619402
Validation loss: 2.5269223865670063

Epoch: 6| Step: 9
Training loss: 2.805598374051552
Validation loss: 2.521786722951695

Epoch: 6| Step: 10
Training loss: 2.774399367618819
Validation loss: 2.520875888391708

Epoch: 6| Step: 11
Training loss: 2.8744526217622477
Validation loss: 2.526812418164287

Epoch: 6| Step: 12
Training loss: 3.0787055537941415
Validation loss: 2.526064597202186

Epoch: 6| Step: 13
Training loss: 2.9457939422290287
Validation loss: 2.534045690121654

Epoch: 222| Step: 0
Training loss: 2.333978654543199
Validation loss: 2.561338422027668

Epoch: 6| Step: 1
Training loss: 2.942705452616584
Validation loss: 2.5702609656000965

Epoch: 6| Step: 2
Training loss: 2.7813879257463436
Validation loss: 2.592019567515525

Epoch: 6| Step: 3
Training loss: 2.723428493535201
Validation loss: 2.5916860332193408

Epoch: 6| Step: 4
Training loss: 3.0056334690126185
Validation loss: 2.5829240548837005

Epoch: 6| Step: 5
Training loss: 2.6613877816500935
Validation loss: 2.5661414959415105

Epoch: 6| Step: 6
Training loss: 2.3695329685626287
Validation loss: 2.579849207546966

Epoch: 6| Step: 7
Training loss: 2.844141168205294
Validation loss: 2.5427153118774615

Epoch: 6| Step: 8
Training loss: 3.0859174124148425
Validation loss: 2.5338996166723686

Epoch: 6| Step: 9
Training loss: 2.9134386637463487
Validation loss: 2.513285243891696

Epoch: 6| Step: 10
Training loss: 2.914033864062132
Validation loss: 2.514583722962501

Epoch: 6| Step: 11
Training loss: 3.201639268139979
Validation loss: 2.504780745116402

Epoch: 6| Step: 12
Training loss: 2.9496507340912417
Validation loss: 2.5060735165394012

Epoch: 6| Step: 13
Training loss: 3.2911037172928044
Validation loss: 2.5050405448219717

Epoch: 223| Step: 0
Training loss: 2.2876609703918325
Validation loss: 2.503658657999856

Epoch: 6| Step: 1
Training loss: 3.5555212363600126
Validation loss: 2.508095792580581

Epoch: 6| Step: 2
Training loss: 2.8831571874304114
Validation loss: 2.507341655224005

Epoch: 6| Step: 3
Training loss: 2.811386905387999
Validation loss: 2.507046727992714

Epoch: 6| Step: 4
Training loss: 2.1754806557463597
Validation loss: 2.5129861924384573

Epoch: 6| Step: 5
Training loss: 3.4132463191037776
Validation loss: 2.5278168242961123

Epoch: 6| Step: 6
Training loss: 2.5019639883765916
Validation loss: 2.5743126866767234

Epoch: 6| Step: 7
Training loss: 1.7581568401883059
Validation loss: 2.5985566114665057

Epoch: 6| Step: 8
Training loss: 2.44344016840343
Validation loss: 2.6031360104371615

Epoch: 6| Step: 9
Training loss: 3.393894148938894
Validation loss: 2.629899114226172

Epoch: 6| Step: 10
Training loss: 3.2699967466565667
Validation loss: 2.5568095526907513

Epoch: 6| Step: 11
Training loss: 3.1173646345935615
Validation loss: 2.538807948930441

Epoch: 6| Step: 12
Training loss: 2.9871516068472386
Validation loss: 2.519781106800407

Epoch: 6| Step: 13
Training loss: 2.7269265879984754
Validation loss: 2.517100868413008

Epoch: 224| Step: 0
Training loss: 2.6827274795595137
Validation loss: 2.5171247803943286

Epoch: 6| Step: 1
Training loss: 3.2804689476847106
Validation loss: 2.5244615791171046

Epoch: 6| Step: 2
Training loss: 2.6000121483152188
Validation loss: 2.5290327186251305

Epoch: 6| Step: 3
Training loss: 2.891876939352856
Validation loss: 2.522378211336881

Epoch: 6| Step: 4
Training loss: 2.910439373811592
Validation loss: 2.52110400399766

Epoch: 6| Step: 5
Training loss: 3.0343547533579645
Validation loss: 2.521677521811709

Epoch: 6| Step: 6
Training loss: 3.0999782561493285
Validation loss: 2.521305616276425

Epoch: 6| Step: 7
Training loss: 3.252997703150382
Validation loss: 2.525197340877513

Epoch: 6| Step: 8
Training loss: 2.8149207823263347
Validation loss: 2.52969264234056

Epoch: 6| Step: 9
Training loss: 2.491948609576894
Validation loss: 2.534284831643504

Epoch: 6| Step: 10
Training loss: 2.9346180840537617
Validation loss: 2.5493895931338226

Epoch: 6| Step: 11
Training loss: 2.586476802772787
Validation loss: 2.550306359936614

Epoch: 6| Step: 12
Training loss: 2.9827993337701333
Validation loss: 2.5519780418335207

Epoch: 6| Step: 13
Training loss: 1.9750881803117866
Validation loss: 2.576137883925207

Epoch: 225| Step: 0
Training loss: 3.004847901060601
Validation loss: 2.566698685845733

Epoch: 6| Step: 1
Training loss: 2.7923455243256843
Validation loss: 2.5729432835538364

Epoch: 6| Step: 2
Training loss: 2.1374247219817293
Validation loss: 2.57897401057316

Epoch: 6| Step: 3
Training loss: 3.0495578007559336
Validation loss: 2.5736152028159256

Epoch: 6| Step: 4
Training loss: 3.215441735089879
Validation loss: 2.572816062044101

Epoch: 6| Step: 5
Training loss: 2.7035291072011574
Validation loss: 2.5842834284225864

Epoch: 6| Step: 6
Training loss: 2.7018683715428393
Validation loss: 2.588814119150088

Epoch: 6| Step: 7
Training loss: 2.6200413872456534
Validation loss: 2.5690645999355692

Epoch: 6| Step: 8
Training loss: 3.2508473392104347
Validation loss: 2.53379063606241

Epoch: 6| Step: 9
Training loss: 3.16926083632402
Validation loss: 2.511361068866209

Epoch: 6| Step: 10
Training loss: 3.0781071851185775
Validation loss: 2.505290181910481

Epoch: 6| Step: 11
Training loss: 2.6523214572424716
Validation loss: 2.508066326998394

Epoch: 6| Step: 12
Training loss: 2.8782436483076683
Validation loss: 2.516237172578728

Epoch: 6| Step: 13
Training loss: 2.6960022859139188
Validation loss: 2.5187206132141875

Epoch: 226| Step: 0
Training loss: 2.2236739847143534
Validation loss: 2.5193356572161343

Epoch: 6| Step: 1
Training loss: 2.7000121787467664
Validation loss: 2.5205386298108516

Epoch: 6| Step: 2
Training loss: 3.210940767086994
Validation loss: 2.5166995281553324

Epoch: 6| Step: 3
Training loss: 3.1275439779359364
Validation loss: 2.50699082274113

Epoch: 6| Step: 4
Training loss: 3.409390742670317
Validation loss: 2.511287740452808

Epoch: 6| Step: 5
Training loss: 2.9120399471938456
Validation loss: 2.5106532344903947

Epoch: 6| Step: 6
Training loss: 3.099747210624665
Validation loss: 2.5112974548143723

Epoch: 6| Step: 7
Training loss: 2.6589744508282647
Validation loss: 2.50384968129056

Epoch: 6| Step: 8
Training loss: 2.5710225617328706
Validation loss: 2.5015300970019645

Epoch: 6| Step: 9
Training loss: 3.399319098115172
Validation loss: 2.5123309039812143

Epoch: 6| Step: 10
Training loss: 2.850123379362355
Validation loss: 2.5126769617637943

Epoch: 6| Step: 11
Training loss: 2.2293209723665304
Validation loss: 2.545106713962623

Epoch: 6| Step: 12
Training loss: 2.8137168794883185
Validation loss: 2.582336281668153

Epoch: 6| Step: 13
Training loss: 2.1252063202272704
Validation loss: 2.654758371868966

Epoch: 227| Step: 0
Training loss: 2.199950941579204
Validation loss: 2.7035483273557306

Epoch: 6| Step: 1
Training loss: 2.9501954741290093
Validation loss: 2.7347875984041576

Epoch: 6| Step: 2
Training loss: 2.5245905742508894
Validation loss: 2.7582588177432905

Epoch: 6| Step: 3
Training loss: 2.5218342982225557
Validation loss: 2.7397313724644223

Epoch: 6| Step: 4
Training loss: 3.4364386567316303
Validation loss: 2.725545201473127

Epoch: 6| Step: 5
Training loss: 3.12157985449097
Validation loss: 2.6785726680645316

Epoch: 6| Step: 6
Training loss: 3.1196576038186428
Validation loss: 2.620357138198925

Epoch: 6| Step: 7
Training loss: 2.4330091922459363
Validation loss: 2.5702073235637597

Epoch: 6| Step: 8
Training loss: 3.0985646401163702
Validation loss: 2.53665127112746

Epoch: 6| Step: 9
Training loss: 2.999129486941729
Validation loss: 2.5163243337668155

Epoch: 6| Step: 10
Training loss: 2.188526348754594
Validation loss: 2.5137216190958793

Epoch: 6| Step: 11
Training loss: 3.141146792057081
Validation loss: 2.501522988777789

Epoch: 6| Step: 12
Training loss: 3.00802667028697
Validation loss: 2.500693123623787

Epoch: 6| Step: 13
Training loss: 3.4894857516333335
Validation loss: 2.5033464676145796

Epoch: 228| Step: 0
Training loss: 3.102906826989418
Validation loss: 2.50406794038533

Epoch: 6| Step: 1
Training loss: 2.602830365967299
Validation loss: 2.5017902916572545

Epoch: 6| Step: 2
Training loss: 3.318568015990905
Validation loss: 2.5049741436539605

Epoch: 6| Step: 3
Training loss: 2.519687570853163
Validation loss: 2.5054720939150066

Epoch: 6| Step: 4
Training loss: 3.030758218101027
Validation loss: 2.507429460983843

Epoch: 6| Step: 5
Training loss: 3.0475777622531606
Validation loss: 2.5131587736253196

Epoch: 6| Step: 6
Training loss: 2.518701224410931
Validation loss: 2.5121618988745142

Epoch: 6| Step: 7
Training loss: 2.1775958782683977
Validation loss: 2.5177723860478007

Epoch: 6| Step: 8
Training loss: 2.9320255969648907
Validation loss: 2.5171226507522553

Epoch: 6| Step: 9
Training loss: 2.7362384658925882
Validation loss: 2.530398450566

Epoch: 6| Step: 10
Training loss: 2.978689640152373
Validation loss: 2.560651515142501

Epoch: 6| Step: 11
Training loss: 1.8250315650404967
Validation loss: 2.5447913949623002

Epoch: 6| Step: 12
Training loss: 4.032830926379349
Validation loss: 2.579720683913684

Epoch: 6| Step: 13
Training loss: 2.281355345919497
Validation loss: 2.5670962987171437

Epoch: 229| Step: 0
Training loss: 2.4719878584492596
Validation loss: 2.542872141175589

Epoch: 6| Step: 1
Training loss: 2.82074647560295
Validation loss: 2.5520699603442125

Epoch: 6| Step: 2
Training loss: 2.7943667454300067
Validation loss: 2.540617136229245

Epoch: 6| Step: 3
Training loss: 2.6930474093032384
Validation loss: 2.5396189867517927

Epoch: 6| Step: 4
Training loss: 2.71208742581452
Validation loss: 2.542687772947253

Epoch: 6| Step: 5
Training loss: 2.885557444382548
Validation loss: 2.520537594402518

Epoch: 6| Step: 6
Training loss: 3.101798175918817
Validation loss: 2.515743985779595

Epoch: 6| Step: 7
Training loss: 2.783270798245249
Validation loss: 2.512419800653568

Epoch: 6| Step: 8
Training loss: 2.4173013138808
Validation loss: 2.5126972000083545

Epoch: 6| Step: 9
Training loss: 2.7439954400261004
Validation loss: 2.508611427676844

Epoch: 6| Step: 10
Training loss: 2.836012489861666
Validation loss: 2.515782053722588

Epoch: 6| Step: 11
Training loss: 3.0726415133807876
Validation loss: 2.5173133193983803

Epoch: 6| Step: 12
Training loss: 3.3565369438957924
Validation loss: 2.5181798641985673

Epoch: 6| Step: 13
Training loss: 2.951821983324915
Validation loss: 2.508411896933098

Epoch: 230| Step: 0
Training loss: 3.106670948265738
Validation loss: 2.5137616166124777

Epoch: 6| Step: 1
Training loss: 2.7754763563795275
Validation loss: 2.5174582615372096

Epoch: 6| Step: 2
Training loss: 2.70733411891913
Validation loss: 2.5257617382192667

Epoch: 6| Step: 3
Training loss: 2.6758452247712596
Validation loss: 2.527592395346408

Epoch: 6| Step: 4
Training loss: 2.3096894376651407
Validation loss: 2.5415112375443645

Epoch: 6| Step: 5
Training loss: 3.0026649718181013
Validation loss: 2.5358909357560013

Epoch: 6| Step: 6
Training loss: 3.0914242412052295
Validation loss: 2.5486076385655303

Epoch: 6| Step: 7
Training loss: 1.8975232595593783
Validation loss: 2.5340766503428553

Epoch: 6| Step: 8
Training loss: 2.6601132292776795
Validation loss: 2.5203379174141625

Epoch: 6| Step: 9
Training loss: 3.4348547727932637
Validation loss: 2.51557537201366

Epoch: 6| Step: 10
Training loss: 2.9546412859227096
Validation loss: 2.5102843413677625

Epoch: 6| Step: 11
Training loss: 3.2353971036543507
Validation loss: 2.5077175382694965

Epoch: 6| Step: 12
Training loss: 2.6118430155712424
Validation loss: 2.5177472033594714

Epoch: 6| Step: 13
Training loss: 2.816168786988859
Validation loss: 2.5142862330408406

Epoch: 231| Step: 0
Training loss: 2.850055620420371
Validation loss: 2.503272522434228

Epoch: 6| Step: 1
Training loss: 3.0200193338848966
Validation loss: 2.5093530658571463

Epoch: 6| Step: 2
Training loss: 2.8744070022039065
Validation loss: 2.4956578426392646

Epoch: 6| Step: 3
Training loss: 2.6053525335423697
Validation loss: 2.5017814052485297

Epoch: 6| Step: 4
Training loss: 3.0213174015555504
Validation loss: 2.501298195116213

Epoch: 6| Step: 5
Training loss: 2.67943622979191
Validation loss: 2.498892029972834

Epoch: 6| Step: 6
Training loss: 3.1015236032963216
Validation loss: 2.4980528272894147

Epoch: 6| Step: 7
Training loss: 2.313171392355391
Validation loss: 2.5156295135320996

Epoch: 6| Step: 8
Training loss: 2.7940088856200123
Validation loss: 2.5231139232330553

Epoch: 6| Step: 9
Training loss: 3.15516719562508
Validation loss: 2.5479826917515225

Epoch: 6| Step: 10
Training loss: 2.7464439635436317
Validation loss: 2.5667417171544957

Epoch: 6| Step: 11
Training loss: 2.4446976836357046
Validation loss: 2.5938511836250044

Epoch: 6| Step: 12
Training loss: 3.046962951955737
Validation loss: 2.5863434035833603

Epoch: 6| Step: 13
Training loss: 2.942903621348878
Validation loss: 2.5474835616259894

Epoch: 232| Step: 0
Training loss: 2.602425921702287
Validation loss: 2.5281914336439306

Epoch: 6| Step: 1
Training loss: 3.1717838969559793
Validation loss: 2.516584224310843

Epoch: 6| Step: 2
Training loss: 3.0120860468312696
Validation loss: 2.5050326278422097

Epoch: 6| Step: 3
Training loss: 2.6052989990206683
Validation loss: 2.5028586973615825

Epoch: 6| Step: 4
Training loss: 2.4536383024999076
Validation loss: 2.498040970930644

Epoch: 6| Step: 5
Training loss: 2.7473947148373514
Validation loss: 2.5003434129930535

Epoch: 6| Step: 6
Training loss: 2.2017318974471176
Validation loss: 2.507620554844646

Epoch: 6| Step: 7
Training loss: 2.9273405312774203
Validation loss: 2.513702659852828

Epoch: 6| Step: 8
Training loss: 2.6471123995376797
Validation loss: 2.5117755497464924

Epoch: 6| Step: 9
Training loss: 3.1310929980482465
Validation loss: 2.5102949266543475

Epoch: 6| Step: 10
Training loss: 3.228478257827841
Validation loss: 2.513980779345293

Epoch: 6| Step: 11
Training loss: 3.2640743680877913
Validation loss: 2.5223459102393093

Epoch: 6| Step: 12
Training loss: 2.813953278501416
Validation loss: 2.528673516403062

Epoch: 6| Step: 13
Training loss: 2.5674464238565484
Validation loss: 2.533034398193366

Epoch: 233| Step: 0
Training loss: 2.816962199159609
Validation loss: 2.5374678174830176

Epoch: 6| Step: 1
Training loss: 2.4964085531143536
Validation loss: 2.54278446741619

Epoch: 6| Step: 2
Training loss: 2.792045985020788
Validation loss: 2.5381543666977393

Epoch: 6| Step: 3
Training loss: 2.9535793378799506
Validation loss: 2.534116404480601

Epoch: 6| Step: 4
Training loss: 3.5399675369929406
Validation loss: 2.52916562941154

Epoch: 6| Step: 5
Training loss: 3.302248656810424
Validation loss: 2.5380283558722976

Epoch: 6| Step: 6
Training loss: 2.365573849244717
Validation loss: 2.53710049205451

Epoch: 6| Step: 7
Training loss: 2.838796136398019
Validation loss: 2.546956195715978

Epoch: 6| Step: 8
Training loss: 2.38150398722108
Validation loss: 2.5500881144858356

Epoch: 6| Step: 9
Training loss: 2.1951491542877704
Validation loss: 2.546048870186451

Epoch: 6| Step: 10
Training loss: 2.8575303428020113
Validation loss: 2.5480124543597924

Epoch: 6| Step: 11
Training loss: 3.4551548580017997
Validation loss: 2.5445905302296397

Epoch: 6| Step: 12
Training loss: 2.292634539967087
Validation loss: 2.5214039116049287

Epoch: 6| Step: 13
Training loss: 2.810434557888656
Validation loss: 2.514594158634558

Epoch: 234| Step: 0
Training loss: 2.8483539244694516
Validation loss: 2.5064361314935133

Epoch: 6| Step: 1
Training loss: 2.413928969557381
Validation loss: 2.5005685077835715

Epoch: 6| Step: 2
Training loss: 3.219398507276977
Validation loss: 2.5082408350240004

Epoch: 6| Step: 3
Training loss: 3.0302548692228397
Validation loss: 2.499363510570322

Epoch: 6| Step: 4
Training loss: 2.4917007018691697
Validation loss: 2.5004214126463653

Epoch: 6| Step: 5
Training loss: 2.656571043472185
Validation loss: 2.4950391175836053

Epoch: 6| Step: 6
Training loss: 2.89642148711652
Validation loss: 2.4869428992251037

Epoch: 6| Step: 7
Training loss: 3.0407267821037984
Validation loss: 2.49668243099724

Epoch: 6| Step: 8
Training loss: 2.245483315486756
Validation loss: 2.5035417039361003

Epoch: 6| Step: 9
Training loss: 2.1659633399699993
Validation loss: 2.52868988156565

Epoch: 6| Step: 10
Training loss: 2.776209947210403
Validation loss: 2.532861129758384

Epoch: 6| Step: 11
Training loss: 3.0995301475086414
Validation loss: 2.5603356914487962

Epoch: 6| Step: 12
Training loss: 3.158588109941941
Validation loss: 2.5570469683155927

Epoch: 6| Step: 13
Training loss: 3.5049077094493963
Validation loss: 2.57722143085942

Epoch: 235| Step: 0
Training loss: 2.6952140458411034
Validation loss: 2.6055439961861637

Epoch: 6| Step: 1
Training loss: 3.7616523269382256
Validation loss: 2.6217618630258577

Epoch: 6| Step: 2
Training loss: 2.434726996186528
Validation loss: 2.6382950461274577

Epoch: 6| Step: 3
Training loss: 3.023944979717132
Validation loss: 2.5973021360964923

Epoch: 6| Step: 4
Training loss: 2.56755999174669
Validation loss: 2.561983009847845

Epoch: 6| Step: 5
Training loss: 2.885093551520538
Validation loss: 2.5256710658930217

Epoch: 6| Step: 6
Training loss: 2.3429417551691794
Validation loss: 2.513688272557735

Epoch: 6| Step: 7
Training loss: 2.6708125628905055
Validation loss: 2.505252310651463

Epoch: 6| Step: 8
Training loss: 2.776193716001657
Validation loss: 2.5020843200184375

Epoch: 6| Step: 9
Training loss: 2.9489493745977446
Validation loss: 2.502737880541277

Epoch: 6| Step: 10
Training loss: 2.5243325550490026
Validation loss: 2.501434279802591

Epoch: 6| Step: 11
Training loss: 3.0716133759116073
Validation loss: 2.4974119521277034

Epoch: 6| Step: 12
Training loss: 3.203834120248481
Validation loss: 2.4977042742649957

Epoch: 6| Step: 13
Training loss: 2.1749445677961172
Validation loss: 2.5035016568061876

Epoch: 236| Step: 0
Training loss: 2.820872834988841
Validation loss: 2.504343404698219

Epoch: 6| Step: 1
Training loss: 2.480299768173686
Validation loss: 2.50934664079213

Epoch: 6| Step: 2
Training loss: 2.912920607946719
Validation loss: 2.5095846034334697

Epoch: 6| Step: 3
Training loss: 2.08099923670845
Validation loss: 2.5181826872580313

Epoch: 6| Step: 4
Training loss: 2.835555121754952
Validation loss: 2.5273676117313606

Epoch: 6| Step: 5
Training loss: 2.946787983164824
Validation loss: 2.529310292715038

Epoch: 6| Step: 6
Training loss: 2.9658965200531817
Validation loss: 2.548698872933625

Epoch: 6| Step: 7
Training loss: 2.8138383012471038
Validation loss: 2.5517638791123955

Epoch: 6| Step: 8
Training loss: 3.518067456681401
Validation loss: 2.5451944457210027

Epoch: 6| Step: 9
Training loss: 3.0120129076717856
Validation loss: 2.5415444515330314

Epoch: 6| Step: 10
Training loss: 2.9047979193307816
Validation loss: 2.5542958764001855

Epoch: 6| Step: 11
Training loss: 2.533233242399995
Validation loss: 2.5447180587064584

Epoch: 6| Step: 12
Training loss: 2.757235804444559
Validation loss: 2.5433723143722307

Epoch: 6| Step: 13
Training loss: 2.7335344166951843
Validation loss: 2.5458510138563653

Epoch: 237| Step: 0
Training loss: 2.576295145482315
Validation loss: 2.5370070055287366

Epoch: 6| Step: 1
Training loss: 2.6583640269198616
Validation loss: 2.535052703411824

Epoch: 6| Step: 2
Training loss: 2.7200428311397715
Validation loss: 2.5366727961470925

Epoch: 6| Step: 3
Training loss: 2.798537798968572
Validation loss: 2.535347944736416

Epoch: 6| Step: 4
Training loss: 2.9632288941500917
Validation loss: 2.5519652516159597

Epoch: 6| Step: 5
Training loss: 3.4888967417434897
Validation loss: 2.539441719606696

Epoch: 6| Step: 6
Training loss: 2.7418631772129243
Validation loss: 2.5408521187873028

Epoch: 6| Step: 7
Training loss: 2.7476126104712177
Validation loss: 2.5393432401401723

Epoch: 6| Step: 8
Training loss: 2.7113121279557975
Validation loss: 2.5384290749741787

Epoch: 6| Step: 9
Training loss: 2.861576421074136
Validation loss: 2.5250027494802403

Epoch: 6| Step: 10
Training loss: 2.739724816753172
Validation loss: 2.523414976689421

Epoch: 6| Step: 11
Training loss: 2.3709370845715374
Validation loss: 2.5176394226396255

Epoch: 6| Step: 12
Training loss: 2.991009751845073
Validation loss: 2.5183203912994236

Epoch: 6| Step: 13
Training loss: 2.863665587481162
Validation loss: 2.513769458168324

Epoch: 238| Step: 0
Training loss: 2.6500403131261696
Validation loss: 2.5086612792694463

Epoch: 6| Step: 1
Training loss: 2.540151509249282
Validation loss: 2.5054617798704566

Epoch: 6| Step: 2
Training loss: 2.1104810287537514
Validation loss: 2.501565598876921

Epoch: 6| Step: 3
Training loss: 2.786134010525943
Validation loss: 2.500309542494338

Epoch: 6| Step: 4
Training loss: 2.5626906347308407
Validation loss: 2.49852034250151

Epoch: 6| Step: 5
Training loss: 3.160914835751978
Validation loss: 2.5109737960751004

Epoch: 6| Step: 6
Training loss: 2.8280872321373196
Validation loss: 2.5156806354183177

Epoch: 6| Step: 7
Training loss: 2.414059734651531
Validation loss: 2.536227015566613

Epoch: 6| Step: 8
Training loss: 3.558458277513617
Validation loss: 2.537300331103603

Epoch: 6| Step: 9
Training loss: 2.79601534626669
Validation loss: 2.5398491864175514

Epoch: 6| Step: 10
Training loss: 3.070558183852702
Validation loss: 2.531119176759575

Epoch: 6| Step: 11
Training loss: 3.0542275943550963
Validation loss: 2.551758623257845

Epoch: 6| Step: 12
Training loss: 2.1493013621919146
Validation loss: 2.559426441036519

Epoch: 6| Step: 13
Training loss: 3.705740861836268
Validation loss: 2.5578249111452367

Epoch: 239| Step: 0
Training loss: 2.9161706411827297
Validation loss: 2.539705136539081

Epoch: 6| Step: 1
Training loss: 2.9018815546662156
Validation loss: 2.5318977127840347

Epoch: 6| Step: 2
Training loss: 3.0467033142234086
Validation loss: 2.5541576528334105

Epoch: 6| Step: 3
Training loss: 2.633835953014648
Validation loss: 2.5341596865745437

Epoch: 6| Step: 4
Training loss: 2.921696132142119
Validation loss: 2.5171938598729273

Epoch: 6| Step: 5
Training loss: 2.6241698087607026
Validation loss: 2.5032780915690873

Epoch: 6| Step: 6
Training loss: 3.192317837123643
Validation loss: 2.503036670796528

Epoch: 6| Step: 7
Training loss: 2.7426150605399027
Validation loss: 2.500284718123397

Epoch: 6| Step: 8
Training loss: 2.950249134470568
Validation loss: 2.4981679910352046

Epoch: 6| Step: 9
Training loss: 2.477472084111397
Validation loss: 2.4908632364369376

Epoch: 6| Step: 10
Training loss: 2.2278250343889434
Validation loss: 2.489179484658047

Epoch: 6| Step: 11
Training loss: 2.6857890515805303
Validation loss: 2.4917257784358475

Epoch: 6| Step: 12
Training loss: 3.1417354309759298
Validation loss: 2.4920410397127437

Epoch: 6| Step: 13
Training loss: 2.6425019765682283
Validation loss: 2.4964165693289453

Epoch: 240| Step: 0
Training loss: 2.6420336696030047
Validation loss: 2.492047886938915

Epoch: 6| Step: 1
Training loss: 2.7383024946795347
Validation loss: 2.498796351688232

Epoch: 6| Step: 2
Training loss: 2.738899542078738
Validation loss: 2.5083660672096384

Epoch: 6| Step: 3
Training loss: 2.853379765278345
Validation loss: 2.509831686432491

Epoch: 6| Step: 4
Training loss: 3.214949058022337
Validation loss: 2.51747141088064

Epoch: 6| Step: 5
Training loss: 2.4816806025612284
Validation loss: 2.5081502918028065

Epoch: 6| Step: 6
Training loss: 2.7580793646056714
Validation loss: 2.5094094308201167

Epoch: 6| Step: 7
Training loss: 2.8546914687857265
Validation loss: 2.5232407713434837

Epoch: 6| Step: 8
Training loss: 2.8681434472148126
Validation loss: 2.529862655028719

Epoch: 6| Step: 9
Training loss: 2.7732168190426694
Validation loss: 2.53659064515561

Epoch: 6| Step: 10
Training loss: 2.2802111206688247
Validation loss: 2.5460821745051794

Epoch: 6| Step: 11
Training loss: 3.2051669427535923
Validation loss: 2.549616702051785

Epoch: 6| Step: 12
Training loss: 2.965116827530295
Validation loss: 2.535805603672964

Epoch: 6| Step: 13
Training loss: 2.790233633315516
Validation loss: 2.5239105182566206

Epoch: 241| Step: 0
Training loss: 2.5719281252522634
Validation loss: 2.5141740692450725

Epoch: 6| Step: 1
Training loss: 2.1950787728671144
Validation loss: 2.5221857087328368

Epoch: 6| Step: 2
Training loss: 3.0049688198610984
Validation loss: 2.509992874587085

Epoch: 6| Step: 3
Training loss: 2.766010236041257
Validation loss: 2.509460122653

Epoch: 6| Step: 4
Training loss: 2.30981722715538
Validation loss: 2.499734814227984

Epoch: 6| Step: 5
Training loss: 2.6975382142988336
Validation loss: 2.517896031816425

Epoch: 6| Step: 6
Training loss: 3.0221326116603384
Validation loss: 2.512937752873522

Epoch: 6| Step: 7
Training loss: 2.5244872564038348
Validation loss: 2.5273196669104063

Epoch: 6| Step: 8
Training loss: 2.6536277842757956
Validation loss: 2.5226779847365433

Epoch: 6| Step: 9
Training loss: 3.3743833755640753
Validation loss: 2.546838004792697

Epoch: 6| Step: 10
Training loss: 3.0991542893118376
Validation loss: 2.5423307309484104

Epoch: 6| Step: 11
Training loss: 3.271084397190773
Validation loss: 2.530319675901334

Epoch: 6| Step: 12
Training loss: 2.7296955285393705
Validation loss: 2.5329716330987218

Epoch: 6| Step: 13
Training loss: 2.611196282082136
Validation loss: 2.5251305433390243

Epoch: 242| Step: 0
Training loss: 2.84999053685809
Validation loss: 2.537240535027287

Epoch: 6| Step: 1
Training loss: 2.4088864436006197
Validation loss: 2.544155030090037

Epoch: 6| Step: 2
Training loss: 3.1620406107408883
Validation loss: 2.550871953369332

Epoch: 6| Step: 3
Training loss: 2.4158850644606082
Validation loss: 2.5509151019154594

Epoch: 6| Step: 4
Training loss: 2.4621071594121795
Validation loss: 2.5433480312733563

Epoch: 6| Step: 5
Training loss: 1.9622160250526415
Validation loss: 2.5509344770173894

Epoch: 6| Step: 6
Training loss: 2.987460633341735
Validation loss: 2.5488328623677545

Epoch: 6| Step: 7
Training loss: 2.9972677504513188
Validation loss: 2.553217304998298

Epoch: 6| Step: 8
Training loss: 2.9618237459956576
Validation loss: 2.5385774745823673

Epoch: 6| Step: 9
Training loss: 3.235833912457311
Validation loss: 2.517677089241327

Epoch: 6| Step: 10
Training loss: 3.0973040271061745
Validation loss: 2.5012698527313355

Epoch: 6| Step: 11
Training loss: 2.741703610234128
Validation loss: 2.4981241695055982

Epoch: 6| Step: 12
Training loss: 2.940601253920379
Validation loss: 2.4908522505425346

Epoch: 6| Step: 13
Training loss: 2.541689221224743
Validation loss: 2.487615894221771

Epoch: 243| Step: 0
Training loss: 3.234581834749419
Validation loss: 2.491110505047608

Epoch: 6| Step: 1
Training loss: 2.6634474237264527
Validation loss: 2.4881416433990697

Epoch: 6| Step: 2
Training loss: 2.8712432199613165
Validation loss: 2.4958491126139686

Epoch: 6| Step: 3
Training loss: 2.5931103388697565
Validation loss: 2.4983611600889826

Epoch: 6| Step: 4
Training loss: 2.6040199747095882
Validation loss: 2.5057913417118653

Epoch: 6| Step: 5
Training loss: 2.403966439392121
Validation loss: 2.5240780450354774

Epoch: 6| Step: 6
Training loss: 3.1488609313202325
Validation loss: 2.516893727656945

Epoch: 6| Step: 7
Training loss: 3.0604959275533763
Validation loss: 2.538970613418254

Epoch: 6| Step: 8
Training loss: 2.4003648003848825
Validation loss: 2.549660093047187

Epoch: 6| Step: 9
Training loss: 2.4936219873293024
Validation loss: 2.575782040894445

Epoch: 6| Step: 10
Training loss: 3.3541349484541327
Validation loss: 2.6014190666807173

Epoch: 6| Step: 11
Training loss: 2.780487727598598
Validation loss: 2.5767116517116655

Epoch: 6| Step: 12
Training loss: 3.039790912013082
Validation loss: 2.5574819441692576

Epoch: 6| Step: 13
Training loss: 2.2000559539615177
Validation loss: 2.5515047329500113

Epoch: 244| Step: 0
Training loss: 2.905132119724788
Validation loss: 2.5409981941071154

Epoch: 6| Step: 1
Training loss: 3.001357724990371
Validation loss: 2.5123646011891823

Epoch: 6| Step: 2
Training loss: 2.6644709209702944
Validation loss: 2.506193308700149

Epoch: 6| Step: 3
Training loss: 2.234335412161591
Validation loss: 2.5185116645070402

Epoch: 6| Step: 4
Training loss: 3.134180849856845
Validation loss: 2.5165266284745944

Epoch: 6| Step: 5
Training loss: 3.131750673632771
Validation loss: 2.5112484242633144

Epoch: 6| Step: 6
Training loss: 2.766106342734568
Validation loss: 2.5067148639138024

Epoch: 6| Step: 7
Training loss: 2.2580830237074028
Validation loss: 2.514572735690438

Epoch: 6| Step: 8
Training loss: 2.7330738568618607
Validation loss: 2.524360787783624

Epoch: 6| Step: 9
Training loss: 2.97443512113745
Validation loss: 2.511912628832492

Epoch: 6| Step: 10
Training loss: 2.609207787552668
Validation loss: 2.523408543743059

Epoch: 6| Step: 11
Training loss: 2.9314120900575955
Validation loss: 2.5164281752327278

Epoch: 6| Step: 12
Training loss: 2.8353553363595982
Validation loss: 2.5049298696018356

Epoch: 6| Step: 13
Training loss: 2.7737544348785717
Validation loss: 2.5049746517819385

Epoch: 245| Step: 0
Training loss: 2.074365183228622
Validation loss: 2.5191623563637573

Epoch: 6| Step: 1
Training loss: 3.0184379463736533
Validation loss: 2.5316151404082143

Epoch: 6| Step: 2
Training loss: 3.4939548875923916
Validation loss: 2.541867145544238

Epoch: 6| Step: 3
Training loss: 2.9471203342874395
Validation loss: 2.5364634751805575

Epoch: 6| Step: 4
Training loss: 2.3537457745352572
Validation loss: 2.5276404156264807

Epoch: 6| Step: 5
Training loss: 2.3013335052540267
Validation loss: 2.519382020041804

Epoch: 6| Step: 6
Training loss: 2.8414199841355936
Validation loss: 2.5118073121355162

Epoch: 6| Step: 7
Training loss: 2.6761966132336212
Validation loss: 2.524079340019592

Epoch: 6| Step: 8
Training loss: 2.301864912853569
Validation loss: 2.5197741416287096

Epoch: 6| Step: 9
Training loss: 2.9659519863448116
Validation loss: 2.529566151211446

Epoch: 6| Step: 10
Training loss: 2.4073141147871455
Validation loss: 2.5423460562923834

Epoch: 6| Step: 11
Training loss: 3.2931734973972993
Validation loss: 2.5479580571725853

Epoch: 6| Step: 12
Training loss: 3.405682157728853
Validation loss: 2.5506742631145256

Epoch: 6| Step: 13
Training loss: 2.4111417118988254
Validation loss: 2.5248833826654544

Epoch: 246| Step: 0
Training loss: 2.831738266094876
Validation loss: 2.5288225336122285

Epoch: 6| Step: 1
Training loss: 2.5746264214487455
Validation loss: 2.527471700371371

Epoch: 6| Step: 2
Training loss: 2.4578894737107335
Validation loss: 2.53962875223707

Epoch: 6| Step: 3
Training loss: 3.303998149280168
Validation loss: 2.535231255279837

Epoch: 6| Step: 4
Training loss: 2.2721583382544273
Validation loss: 2.513755279303926

Epoch: 6| Step: 5
Training loss: 2.90476935621701
Validation loss: 2.5251730860473733

Epoch: 6| Step: 6
Training loss: 2.5753274246485103
Validation loss: 2.512466460479438

Epoch: 6| Step: 7
Training loss: 2.8586176301762007
Validation loss: 2.5199524433517415

Epoch: 6| Step: 8
Training loss: 3.09549394255797
Validation loss: 2.514223858466367

Epoch: 6| Step: 9
Training loss: 3.1344737074457103
Validation loss: 2.5133315979658994

Epoch: 6| Step: 10
Training loss: 2.8915788056348695
Validation loss: 2.517007738053393

Epoch: 6| Step: 11
Training loss: 2.5565642483160524
Validation loss: 2.5272232145854776

Epoch: 6| Step: 12
Training loss: 2.7089924719372505
Validation loss: 2.514557682529818

Epoch: 6| Step: 13
Training loss: 2.564309946379071
Validation loss: 2.519409731807118

Epoch: 247| Step: 0
Training loss: 3.1610379303512226
Validation loss: 2.528247348202782

Epoch: 6| Step: 1
Training loss: 2.6775986785228922
Validation loss: 2.534247507985076

Epoch: 6| Step: 2
Training loss: 2.857582739619193
Validation loss: 2.5191540075002665

Epoch: 6| Step: 3
Training loss: 2.578795374786835
Validation loss: 2.514969472506387

Epoch: 6| Step: 4
Training loss: 3.0929471910558313
Validation loss: 2.5195650162516507

Epoch: 6| Step: 5
Training loss: 2.6015361979303395
Validation loss: 2.510971557076657

Epoch: 6| Step: 6
Training loss: 2.7036288458865454
Validation loss: 2.5333259483104547

Epoch: 6| Step: 7
Training loss: 2.250332489878427
Validation loss: 2.515269859813094

Epoch: 6| Step: 8
Training loss: 2.722314361604559
Validation loss: 2.526926340190511

Epoch: 6| Step: 9
Training loss: 2.9668753075544263
Validation loss: 2.5408746842753875

Epoch: 6| Step: 10
Training loss: 2.619238024556888
Validation loss: 2.518137875269417

Epoch: 6| Step: 11
Training loss: 3.1756638321044206
Validation loss: 2.5439513004961465

Epoch: 6| Step: 12
Training loss: 2.474331690406108
Validation loss: 2.535728075731887

Epoch: 6| Step: 13
Training loss: 2.780650556450746
Validation loss: 2.5540256892999755

Epoch: 248| Step: 0
Training loss: 2.4229194603923285
Validation loss: 2.5630549878565683

Epoch: 6| Step: 1
Training loss: 2.1915526859635395
Validation loss: 2.5377812997316576

Epoch: 6| Step: 2
Training loss: 2.3403132354535496
Validation loss: 2.5345455892725206

Epoch: 6| Step: 3
Training loss: 2.509222377064463
Validation loss: 2.524441887604256

Epoch: 6| Step: 4
Training loss: 2.6673808532247327
Validation loss: 2.520340978110879

Epoch: 6| Step: 5
Training loss: 2.9919160963829534
Validation loss: 2.5270718235523097

Epoch: 6| Step: 6
Training loss: 2.9568822462871602
Validation loss: 2.5236889519498495

Epoch: 6| Step: 7
Training loss: 2.8332190397060946
Validation loss: 2.5223948206134534

Epoch: 6| Step: 8
Training loss: 3.417913643528985
Validation loss: 2.500214988939663

Epoch: 6| Step: 9
Training loss: 3.000983236040416
Validation loss: 2.5178165997307005

Epoch: 6| Step: 10
Training loss: 3.2357802724470672
Validation loss: 2.5039534063376343

Epoch: 6| Step: 11
Training loss: 2.817182076904358
Validation loss: 2.504272282652564

Epoch: 6| Step: 12
Training loss: 2.8217380967837573
Validation loss: 2.4990191401814177

Epoch: 6| Step: 13
Training loss: 2.1204383357355003
Validation loss: 2.501803697040213

Epoch: 249| Step: 0
Training loss: 3.0225541749047897
Validation loss: 2.5078161842284117

Epoch: 6| Step: 1
Training loss: 2.779980830668492
Validation loss: 2.5155704874287528

Epoch: 6| Step: 2
Training loss: 3.456908763719921
Validation loss: 2.5273017931170174

Epoch: 6| Step: 3
Training loss: 2.5586461185599645
Validation loss: 2.526192597139638

Epoch: 6| Step: 4
Training loss: 2.971315098917182
Validation loss: 2.530713053653961

Epoch: 6| Step: 5
Training loss: 2.1180923611582023
Validation loss: 2.525939777646444

Epoch: 6| Step: 6
Training loss: 2.881440784815632
Validation loss: 2.523663847601673

Epoch: 6| Step: 7
Training loss: 2.1632495000237553
Validation loss: 2.511859734508551

Epoch: 6| Step: 8
Training loss: 2.6569263270411203
Validation loss: 2.5150563463494526

Epoch: 6| Step: 9
Training loss: 3.1447508172567056
Validation loss: 2.5116784433450414

Epoch: 6| Step: 10
Training loss: 2.9464564037247003
Validation loss: 2.5079480221701393

Epoch: 6| Step: 11
Training loss: 2.6922175675283384
Validation loss: 2.5240511955484815

Epoch: 6| Step: 12
Training loss: 2.6071814722683957
Validation loss: 2.5281573683739578

Epoch: 6| Step: 13
Training loss: 2.444838992943301
Validation loss: 2.5124398062824738

Epoch: 250| Step: 0
Training loss: 2.888993911382875
Validation loss: 2.5046718670183914

Epoch: 6| Step: 1
Training loss: 2.6924871259149548
Validation loss: 2.5134220024753966

Epoch: 6| Step: 2
Training loss: 3.112464175343686
Validation loss: 2.508411067054822

Epoch: 6| Step: 3
Training loss: 2.5727399592909355
Validation loss: 2.4990356636335753

Epoch: 6| Step: 4
Training loss: 2.992518951942389
Validation loss: 2.4912635581334586

Epoch: 6| Step: 5
Training loss: 3.3031137745936268
Validation loss: 2.4921049189932547

Epoch: 6| Step: 6
Training loss: 2.262994857539505
Validation loss: 2.5016289889979184

Epoch: 6| Step: 7
Training loss: 3.1560442262555597
Validation loss: 2.503118407738891

Epoch: 6| Step: 8
Training loss: 2.3663846407558875
Validation loss: 2.5205045679082354

Epoch: 6| Step: 9
Training loss: 2.4492351038628652
Validation loss: 2.5221320027261944

Epoch: 6| Step: 10
Training loss: 2.3129839004239967
Validation loss: 2.5335890863762374

Epoch: 6| Step: 11
Training loss: 3.1306188803940644
Validation loss: 2.5409335523670404

Epoch: 6| Step: 12
Training loss: 2.5759308697208967
Validation loss: 2.524759663284092

Epoch: 6| Step: 13
Training loss: 2.9227698276765093
Validation loss: 2.5072088186164008

Testing loss: 2.682594605162454
