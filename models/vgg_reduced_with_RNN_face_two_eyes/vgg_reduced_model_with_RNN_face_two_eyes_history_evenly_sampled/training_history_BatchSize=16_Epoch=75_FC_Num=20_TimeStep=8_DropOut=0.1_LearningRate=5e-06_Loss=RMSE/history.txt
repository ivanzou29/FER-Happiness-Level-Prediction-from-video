Epoch: 1| Step: 0
Training loss: 5.415958925618286
Validation loss: 5.758223507565474

Epoch: 6| Step: 1
Training loss: 6.015633877834358
Validation loss: 5.752446015054704

Epoch: 6| Step: 2
Training loss: 5.181078509724185
Validation loss: 5.747683325455931

Epoch: 6| Step: 3
Training loss: 5.674565961599095
Validation loss: 5.742341254210492

Epoch: 6| Step: 4
Training loss: 5.624382663335411
Validation loss: 5.737761743440938

Epoch: 6| Step: 5
Training loss: 4.9665760586728185
Validation loss: 5.73328068693066

Epoch: 6| Step: 6
Training loss: 6.422852676110782
Validation loss: 5.728777645323864

Epoch: 6| Step: 7
Training loss: 5.238683766169582
Validation loss: 5.724073505747973

Epoch: 6| Step: 8
Training loss: 5.610157011558227
Validation loss: 5.719120244293159

Epoch: 6| Step: 9
Training loss: 6.365432740848927
Validation loss: 5.71452432828631

Epoch: 6| Step: 10
Training loss: 5.533271549446764
Validation loss: 5.7091686097849665

Epoch: 6| Step: 11
Training loss: 6.001606090479714
Validation loss: 5.704008174788037

Epoch: 6| Step: 12
Training loss: 6.0215271370724555
Validation loss: 5.697985924848776

Epoch: 6| Step: 13
Training loss: 6.812754215081973
Validation loss: 5.691889617136945

Epoch: 2| Step: 0
Training loss: 5.823866037169509
Validation loss: 5.685763983341499

Epoch: 6| Step: 1
Training loss: 5.179531181358694
Validation loss: 5.679374908634792

Epoch: 6| Step: 2
Training loss: 5.79343001419243
Validation loss: 5.672445135418212

Epoch: 6| Step: 3
Training loss: 5.960989335660925
Validation loss: 5.66556882749717

Epoch: 6| Step: 4
Training loss: 6.19637702176044
Validation loss: 5.6581165599437115

Epoch: 6| Step: 5
Training loss: 4.555023128647608
Validation loss: 5.650110234128891

Epoch: 6| Step: 6
Training loss: 5.504935737532749
Validation loss: 5.642151953906357

Epoch: 6| Step: 7
Training loss: 5.445137010151918
Validation loss: 5.633893945381363

Epoch: 6| Step: 8
Training loss: 6.146943314312813
Validation loss: 5.625271734786242

Epoch: 6| Step: 9
Training loss: 5.906345911609638
Validation loss: 5.616535626385974

Epoch: 6| Step: 10
Training loss: 5.295918155994316
Validation loss: 5.607359686244579

Epoch: 6| Step: 11
Training loss: 5.350815056721754
Validation loss: 5.597262715604445

Epoch: 6| Step: 12
Training loss: 6.365979563333616
Validation loss: 5.586558594908132

Epoch: 6| Step: 13
Training loss: 5.638329881709695
Validation loss: 5.5766973693362205

Epoch: 3| Step: 0
Training loss: 5.712566096551593
Validation loss: 5.565152741276147

Epoch: 6| Step: 1
Training loss: 6.568596033965087
Validation loss: 5.553021976268404

Epoch: 6| Step: 2
Training loss: 5.561450473484283
Validation loss: 5.542239332652739

Epoch: 6| Step: 3
Training loss: 4.691280823872369
Validation loss: 5.529424383809837

Epoch: 6| Step: 4
Training loss: 6.065576775431364
Validation loss: 5.516602368313595

Epoch: 6| Step: 5
Training loss: 5.463241156746385
Validation loss: 5.503010245792823

Epoch: 6| Step: 6
Training loss: 6.170046146659221
Validation loss: 5.489968312304639

Epoch: 6| Step: 7
Training loss: 5.5085658214328
Validation loss: 5.475491437190874

Epoch: 6| Step: 8
Training loss: 4.4568801840908625
Validation loss: 5.460503800516015

Epoch: 6| Step: 9
Training loss: 4.939307932079188
Validation loss: 5.446592207542629

Epoch: 6| Step: 10
Training loss: 5.032692649098787
Validation loss: 5.43206952332718

Epoch: 6| Step: 11
Training loss: 5.13979047593135
Validation loss: 5.417541122213445

Epoch: 6| Step: 12
Training loss: 5.705319168029255
Validation loss: 5.401960059433134

Epoch: 6| Step: 13
Training loss: 6.232080022844124
Validation loss: 5.38677508135637

Epoch: 4| Step: 0
Training loss: 5.248904159255232
Validation loss: 5.371034543066269

Epoch: 6| Step: 1
Training loss: 5.304973341778677
Validation loss: 5.354577183282864

Epoch: 6| Step: 2
Training loss: 6.254322540895748
Validation loss: 5.337543325009885

Epoch: 6| Step: 3
Training loss: 6.0212445850122265
Validation loss: 5.3207621499207445

Epoch: 6| Step: 4
Training loss: 5.693265905643551
Validation loss: 5.303226085330796

Epoch: 6| Step: 5
Training loss: 5.154140341384915
Validation loss: 5.287876525907185

Epoch: 6| Step: 6
Training loss: 5.005057447410557
Validation loss: 5.269690431245315

Epoch: 6| Step: 7
Training loss: 4.352597235174694
Validation loss: 5.253444633450033

Epoch: 6| Step: 8
Training loss: 5.246287895467509
Validation loss: 5.23608982756463

Epoch: 6| Step: 9
Training loss: 4.904493272526113
Validation loss: 5.21858450175418

Epoch: 6| Step: 10
Training loss: 5.335898537444682
Validation loss: 5.20194316571374

Epoch: 6| Step: 11
Training loss: 6.4389261684411885
Validation loss: 5.18506184387459

Epoch: 6| Step: 12
Training loss: 3.931931205885029
Validation loss: 5.166019327031445

Epoch: 6| Step: 13
Training loss: 4.690979136924564
Validation loss: 5.147665618841194

Epoch: 5| Step: 0
Training loss: 5.477973875843498
Validation loss: 5.129695323202609

Epoch: 6| Step: 1
Training loss: 5.863563607042063
Validation loss: 5.112832779840756

Epoch: 6| Step: 2
Training loss: 5.6321298129986985
Validation loss: 5.094255617696181

Epoch: 6| Step: 3
Training loss: 5.9101346274596205
Validation loss: 5.075287765862445

Epoch: 6| Step: 4
Training loss: 5.345238015537664
Validation loss: 5.055099101065197

Epoch: 6| Step: 5
Training loss: 5.373792468318228
Validation loss: 5.036595872477444

Epoch: 6| Step: 6
Training loss: 4.438717957028897
Validation loss: 5.016889554123572

Epoch: 6| Step: 7
Training loss: 3.156649422630359
Validation loss: 4.998347007120209

Epoch: 6| Step: 8
Training loss: 4.157526035468173
Validation loss: 4.982142782289276

Epoch: 6| Step: 9
Training loss: 4.210530050803084
Validation loss: 4.961715311446195

Epoch: 6| Step: 10
Training loss: 5.800560615016994
Validation loss: 4.944049740794215

Epoch: 6| Step: 11
Training loss: 4.026819914707918
Validation loss: 4.92615601438838

Epoch: 6| Step: 12
Training loss: 5.757914196757086
Validation loss: 4.907839988048068

Epoch: 6| Step: 13
Training loss: 4.996636021990684
Validation loss: 4.890465151494625

Epoch: 6| Step: 0
Training loss: 4.200164319411634
Validation loss: 4.8706440529086725

Epoch: 6| Step: 1
Training loss: 4.265948719973707
Validation loss: 4.852969975605667

Epoch: 6| Step: 2
Training loss: 4.640453399670834
Validation loss: 4.83455168771742

Epoch: 6| Step: 3
Training loss: 4.088148405109842
Validation loss: 4.8148443581802125

Epoch: 6| Step: 4
Training loss: 4.314833742123556
Validation loss: 4.797823090055935

Epoch: 6| Step: 5
Training loss: 4.829825191454126
Validation loss: 4.781563212605843

Epoch: 6| Step: 6
Training loss: 5.342417054378117
Validation loss: 4.764211875572754

Epoch: 6| Step: 7
Training loss: 5.5958011212514185
Validation loss: 4.744264828729628

Epoch: 6| Step: 8
Training loss: 4.3646746180539475
Validation loss: 4.727670473081104

Epoch: 6| Step: 9
Training loss: 4.6710147129383275
Validation loss: 4.711531790974612

Epoch: 6| Step: 10
Training loss: 5.796916786721863
Validation loss: 4.6932483825017455

Epoch: 6| Step: 11
Training loss: 4.607268702413637
Validation loss: 4.677230466862517

Epoch: 6| Step: 12
Training loss: 5.471756637225516
Validation loss: 4.659324552044018

Epoch: 6| Step: 13
Training loss: 5.100281442094565
Validation loss: 4.643975197739557

Epoch: 7| Step: 0
Training loss: 4.424392899930903
Validation loss: 4.627155920048305

Epoch: 6| Step: 1
Training loss: 4.513731879739617
Validation loss: 4.611953624200353

Epoch: 6| Step: 2
Training loss: 4.121586167263725
Validation loss: 4.596626647311228

Epoch: 6| Step: 3
Training loss: 5.434627782855381
Validation loss: 4.5815206162977455

Epoch: 6| Step: 4
Training loss: 4.704821917318618
Validation loss: 4.568250732830396

Epoch: 6| Step: 5
Training loss: 3.55328650061381
Validation loss: 4.554645670479902

Epoch: 6| Step: 6
Training loss: 4.57126058542321
Validation loss: 4.538904320704887

Epoch: 6| Step: 7
Training loss: 4.369457985372728
Validation loss: 4.5267719957926404

Epoch: 6| Step: 8
Training loss: 4.078511303841931
Validation loss: 4.513560210262863

Epoch: 6| Step: 9
Training loss: 5.210088978188812
Validation loss: 4.499910912036367

Epoch: 6| Step: 10
Training loss: 5.556056373063028
Validation loss: 4.486811374460894

Epoch: 6| Step: 11
Training loss: 4.657734679013811
Validation loss: 4.4758256719845955

Epoch: 6| Step: 12
Training loss: 5.032360262420708
Validation loss: 4.4629213066174644

Epoch: 6| Step: 13
Training loss: 3.8036368484039236
Validation loss: 4.451159169583377

Epoch: 8| Step: 0
Training loss: 3.5451860481801147
Validation loss: 4.440172397415378

Epoch: 6| Step: 1
Training loss: 3.369057545397772
Validation loss: 4.430064396977309

Epoch: 6| Step: 2
Training loss: 4.098392562241724
Validation loss: 4.418600469738048

Epoch: 6| Step: 3
Training loss: 4.500314277694666
Validation loss: 4.409112695494311

Epoch: 6| Step: 4
Training loss: 4.8338581107247185
Validation loss: 4.3993532234464805

Epoch: 6| Step: 5
Training loss: 4.629736047722595
Validation loss: 4.389474460459746

Epoch: 6| Step: 6
Training loss: 4.52777092327907
Validation loss: 4.3793690255713535

Epoch: 6| Step: 7
Training loss: 4.1537261413017585
Validation loss: 4.367905569998774

Epoch: 6| Step: 8
Training loss: 5.417361092681205
Validation loss: 4.3601968141839915

Epoch: 6| Step: 9
Training loss: 4.722116242260447
Validation loss: 4.3487915211424975

Epoch: 6| Step: 10
Training loss: 5.063940714472513
Validation loss: 4.339392088906435

Epoch: 6| Step: 11
Training loss: 3.9699258339053367
Validation loss: 4.32881006487905

Epoch: 6| Step: 12
Training loss: 4.341344373068805
Validation loss: 4.319364005280211

Epoch: 6| Step: 13
Training loss: 5.566599503224286
Validation loss: 4.310219193522595

Epoch: 9| Step: 0
Training loss: 4.333764763898543
Validation loss: 4.303195693458979

Epoch: 6| Step: 1
Training loss: 3.7432337435221137
Validation loss: 4.293490957076034

Epoch: 6| Step: 2
Training loss: 4.03815761442583
Validation loss: 4.284990928231457

Epoch: 6| Step: 3
Training loss: 5.325917611734378
Validation loss: 4.277096854813296

Epoch: 6| Step: 4
Training loss: 3.882537893489871
Validation loss: 4.270264305466329

Epoch: 6| Step: 5
Training loss: 5.144918486576877
Validation loss: 4.263231903964207

Epoch: 6| Step: 6
Training loss: 4.623639705731619
Validation loss: 4.257352001361285

Epoch: 6| Step: 7
Training loss: 4.027770677465268
Validation loss: 4.247895952315336

Epoch: 6| Step: 8
Training loss: 3.6986690704990637
Validation loss: 4.24205100357118

Epoch: 6| Step: 9
Training loss: 5.296524441351792
Validation loss: 4.234658348829877

Epoch: 6| Step: 10
Training loss: 4.2076269381545215
Validation loss: 4.2270281578026685

Epoch: 6| Step: 11
Training loss: 4.6651252289836345
Validation loss: 4.220747838869649

Epoch: 6| Step: 12
Training loss: 4.122604136727666
Validation loss: 4.2130428393982156

Epoch: 6| Step: 13
Training loss: 3.0342722505091664
Validation loss: 4.207097858540698

Epoch: 10| Step: 0
Training loss: 5.39123885488121
Validation loss: 4.199877647223307

Epoch: 6| Step: 1
Training loss: 3.4718880420511957
Validation loss: 4.192670900879264

Epoch: 6| Step: 2
Training loss: 3.8605341232445856
Validation loss: 4.188104239715623

Epoch: 6| Step: 3
Training loss: 4.0154283527361105
Validation loss: 4.181143422215984

Epoch: 6| Step: 4
Training loss: 5.063229166901062
Validation loss: 4.174314314160382

Epoch: 6| Step: 5
Training loss: 4.7605085078867475
Validation loss: 4.167817456877987

Epoch: 6| Step: 6
Training loss: 3.563753677093311
Validation loss: 4.160781513102376

Epoch: 6| Step: 7
Training loss: 3.3537171025036514
Validation loss: 4.154553019075387

Epoch: 6| Step: 8
Training loss: 3.1776677495704546
Validation loss: 4.14636670199809

Epoch: 6| Step: 9
Training loss: 4.895239265057246
Validation loss: 4.143457492654389

Epoch: 6| Step: 10
Training loss: 4.77779448060263
Validation loss: 4.13514243166386

Epoch: 6| Step: 11
Training loss: 4.8839588498093285
Validation loss: 4.128881076126705

Epoch: 6| Step: 12
Training loss: 3.917215931031833
Validation loss: 4.1200165139701745

Epoch: 6| Step: 13
Training loss: 4.092110108834104
Validation loss: 4.112454583046004

Epoch: 11| Step: 0
Training loss: 4.766418591070526
Validation loss: 4.101293924018337

Epoch: 6| Step: 1
Training loss: 3.7250210755027218
Validation loss: 4.089768748989359

Epoch: 6| Step: 2
Training loss: 4.2120285177832235
Validation loss: 4.0851981170231975

Epoch: 6| Step: 3
Training loss: 4.525979600955643
Validation loss: 4.08027753738936

Epoch: 6| Step: 4
Training loss: 2.9823264236014846
Validation loss: 4.071144318653493

Epoch: 6| Step: 5
Training loss: 4.293378815577858
Validation loss: 4.064317075693082

Epoch: 6| Step: 6
Training loss: 3.9226723882407395
Validation loss: 4.058470526937191

Epoch: 6| Step: 7
Training loss: 3.5197350107498773
Validation loss: 4.053885849221167

Epoch: 6| Step: 8
Training loss: 4.415904189217607
Validation loss: 4.0504468259912425

Epoch: 6| Step: 9
Training loss: 4.538484467618831
Validation loss: 4.0469433944243285

Epoch: 6| Step: 10
Training loss: 4.163076201643847
Validation loss: 4.040493382022854

Epoch: 6| Step: 11
Training loss: 5.0729892524471545
Validation loss: 4.035046315462391

Epoch: 6| Step: 12
Training loss: 4.071517326706937
Validation loss: 4.029162374568978

Epoch: 6| Step: 13
Training loss: 4.209119868033763
Validation loss: 4.023628651018465

Epoch: 12| Step: 0
Training loss: 3.9252428890810376
Validation loss: 4.018194092533599

Epoch: 6| Step: 1
Training loss: 4.996134408124731
Validation loss: 4.01471099404473

Epoch: 6| Step: 2
Training loss: 3.8751503699875505
Validation loss: 4.011550030201483

Epoch: 6| Step: 3
Training loss: 3.4992506042379654
Validation loss: 4.007695465947345

Epoch: 6| Step: 4
Training loss: 5.026064647035655
Validation loss: 4.0020807863319305

Epoch: 6| Step: 5
Training loss: 3.5132378505734776
Validation loss: 3.9975858037627114

Epoch: 6| Step: 6
Training loss: 3.8838883872372802
Validation loss: 3.9951048913506884

Epoch: 6| Step: 7
Training loss: 3.0798763966219878
Validation loss: 3.9906860492335734

Epoch: 6| Step: 8
Training loss: 3.941664899915712
Validation loss: 3.9864806853724217

Epoch: 6| Step: 9
Training loss: 4.394123679016573
Validation loss: 3.9834336142098756

Epoch: 6| Step: 10
Training loss: 4.304943596340814
Validation loss: 3.9806988873697566

Epoch: 6| Step: 11
Training loss: 4.191380993997184
Validation loss: 3.9768783353977106

Epoch: 6| Step: 12
Training loss: 4.7408777278958985
Validation loss: 3.973419472033294

Epoch: 6| Step: 13
Training loss: 4.148582326656291
Validation loss: 3.969403585887235

Epoch: 13| Step: 0
Training loss: 4.516574640967064
Validation loss: 3.963062541958472

Epoch: 6| Step: 1
Training loss: 2.3153598731435
Validation loss: 3.960745159055996

Epoch: 6| Step: 2
Training loss: 4.018235601130352
Validation loss: 3.9591402631363444

Epoch: 6| Step: 3
Training loss: 4.296166045917197
Validation loss: 3.9532080745402687

Epoch: 6| Step: 4
Training loss: 4.038943025161168
Validation loss: 3.950937588354147

Epoch: 6| Step: 5
Training loss: 4.545151426438707
Validation loss: 3.947569488516664

Epoch: 6| Step: 6
Training loss: 2.58171423554437
Validation loss: 3.944637246402488

Epoch: 6| Step: 7
Training loss: 3.7971434949595304
Validation loss: 3.9447028187021798

Epoch: 6| Step: 8
Training loss: 3.2997036771958483
Validation loss: 3.937086339819116

Epoch: 6| Step: 9
Training loss: 5.019167210777709
Validation loss: 3.935745775631831

Epoch: 6| Step: 10
Training loss: 3.6691292094001593
Validation loss: 3.9373683904192918

Epoch: 6| Step: 11
Training loss: 4.424752421376649
Validation loss: 3.9361756769238005

Epoch: 6| Step: 12
Training loss: 5.080372098976856
Validation loss: 3.9332333581425982

Epoch: 6| Step: 13
Training loss: 5.120555159750061
Validation loss: 3.925086639620612

Epoch: 14| Step: 0
Training loss: 3.7849511562405866
Validation loss: 3.9180481009848336

Epoch: 6| Step: 1
Training loss: 4.849850461561853
Validation loss: 3.914328843313856

Epoch: 6| Step: 2
Training loss: 4.726696876318145
Validation loss: 3.9132242611653694

Epoch: 6| Step: 3
Training loss: 4.0260006341985815
Validation loss: 3.908425238601172

Epoch: 6| Step: 4
Training loss: 4.141040939456631
Validation loss: 3.9047122177852205

Epoch: 6| Step: 5
Training loss: 3.6920075103501526
Validation loss: 3.903132801249591

Epoch: 6| Step: 6
Training loss: 3.7688392438807763
Validation loss: 3.9005696449931815

Epoch: 6| Step: 7
Training loss: 3.8127651435081575
Validation loss: 3.8972598395748226

Epoch: 6| Step: 8
Training loss: 4.236649131308422
Validation loss: 3.8937519302670194

Epoch: 6| Step: 9
Training loss: 4.39930903471331
Validation loss: 3.8889308600985717

Epoch: 6| Step: 10
Training loss: 4.198950073163402
Validation loss: 3.886607821217177

Epoch: 6| Step: 11
Training loss: 2.699901003258949
Validation loss: 3.882924274030744

Epoch: 6| Step: 12
Training loss: 4.613196699254297
Validation loss: 3.879891971834511

Epoch: 6| Step: 13
Training loss: 2.7729004245877555
Validation loss: 3.878532187820911

Epoch: 15| Step: 0
Training loss: 4.415902893436156
Validation loss: 3.876385593551911

Epoch: 6| Step: 1
Training loss: 3.972136366893728
Validation loss: 3.8719779915565096

Epoch: 6| Step: 2
Training loss: 4.8834620661687325
Validation loss: 3.871129567086243

Epoch: 6| Step: 3
Training loss: 4.03948748066451
Validation loss: 3.869027737153184

Epoch: 6| Step: 4
Training loss: 3.4100371140057235
Validation loss: 3.8666890306713584

Epoch: 6| Step: 5
Training loss: 3.5821635680475383
Validation loss: 3.8604196329778753

Epoch: 6| Step: 6
Training loss: 4.084431766503709
Validation loss: 3.8585392239343737

Epoch: 6| Step: 7
Training loss: 3.6258353224579154
Validation loss: 3.855694965288548

Epoch: 6| Step: 8
Training loss: 4.207721225047454
Validation loss: 3.855167157732679

Epoch: 6| Step: 9
Training loss: 3.808485825794593
Validation loss: 3.851059352088973

Epoch: 6| Step: 10
Training loss: 4.011608207687698
Validation loss: 3.847586238664084

Epoch: 6| Step: 11
Training loss: 3.4979713555325143
Validation loss: 3.8448489305890705

Epoch: 6| Step: 12
Training loss: 4.328722530391292
Validation loss: 3.840611717780349

Epoch: 6| Step: 13
Training loss: 4.390988589399468
Validation loss: 3.8388011169754046

Epoch: 16| Step: 0
Training loss: 4.8492675857457135
Validation loss: 3.8362407042786484

Epoch: 6| Step: 1
Training loss: 3.41546937076649
Validation loss: 3.832544097512909

Epoch: 6| Step: 2
Training loss: 2.826370959859016
Validation loss: 3.8310311967581243

Epoch: 6| Step: 3
Training loss: 4.693239893922353
Validation loss: 3.8306164942620247

Epoch: 6| Step: 4
Training loss: 4.215549413457254
Validation loss: 3.8251947750006656

Epoch: 6| Step: 5
Training loss: 4.144442889020376
Validation loss: 3.824430393286619

Epoch: 6| Step: 6
Training loss: 4.2697418803116545
Validation loss: 3.8238348340964974

Epoch: 6| Step: 7
Training loss: 3.7817308104449285
Validation loss: 3.8212072446704597

Epoch: 6| Step: 8
Training loss: 4.3401885217601945
Validation loss: 3.8151145481616684

Epoch: 6| Step: 9
Training loss: 4.371651376127165
Validation loss: 3.8124749276802503

Epoch: 6| Step: 10
Training loss: 3.511648277110244
Validation loss: 3.814616494860623

Epoch: 6| Step: 11
Training loss: 3.3943612744231735
Validation loss: 3.8103060906424973

Epoch: 6| Step: 12
Training loss: 4.026189422199077
Validation loss: 3.805428873321916

Epoch: 6| Step: 13
Training loss: 3.1277981247210933
Validation loss: 3.8031212473776397

Epoch: 17| Step: 0
Training loss: 4.057465235760412
Validation loss: 3.8006604255986947

Epoch: 6| Step: 1
Training loss: 3.6109982758198087
Validation loss: 3.800011328684096

Epoch: 6| Step: 2
Training loss: 4.34075824706051
Validation loss: 3.794928135946231

Epoch: 6| Step: 3
Training loss: 4.296534077384352
Validation loss: 3.792322842843016

Epoch: 6| Step: 4
Training loss: 3.9202529774993824
Validation loss: 3.791491655333465

Epoch: 6| Step: 5
Training loss: 4.349502377163976
Validation loss: 3.7895444677850167

Epoch: 6| Step: 6
Training loss: 3.412195878223398
Validation loss: 3.784822668286979

Epoch: 6| Step: 7
Training loss: 2.8647840025002664
Validation loss: 3.783118758179754

Epoch: 6| Step: 8
Training loss: 3.6255232334699863
Validation loss: 3.7787853423357474

Epoch: 6| Step: 9
Training loss: 4.178561106984638
Validation loss: 3.7764676458515707

Epoch: 6| Step: 10
Training loss: 4.540406965257217
Validation loss: 3.775523032730248

Epoch: 6| Step: 11
Training loss: 4.629280171803994
Validation loss: 3.7720133982976667

Epoch: 6| Step: 12
Training loss: 3.8528807823336524
Validation loss: 3.7677045582643607

Epoch: 6| Step: 13
Training loss: 2.7447677601612233
Validation loss: 3.765505258845758

Epoch: 18| Step: 0
Training loss: 4.542475403806767
Validation loss: 3.7598945083123656

Epoch: 6| Step: 1
Training loss: 4.071120286326871
Validation loss: 3.7595361524023243

Epoch: 6| Step: 2
Training loss: 3.503599904084773
Validation loss: 3.7562476504520554

Epoch: 6| Step: 3
Training loss: 4.460604840650379
Validation loss: 3.7502352733024935

Epoch: 6| Step: 4
Training loss: 3.7549654828756935
Validation loss: 3.7468921430304163

Epoch: 6| Step: 5
Training loss: 3.326161839844668
Validation loss: 3.7457673389774953

Epoch: 6| Step: 6
Training loss: 3.723543939897994
Validation loss: 3.739336723024822

Epoch: 6| Step: 7
Training loss: 3.1731957002118953
Validation loss: 3.7364504561011356

Epoch: 6| Step: 8
Training loss: 4.3409654213302105
Validation loss: 3.732909003510906

Epoch: 6| Step: 9
Training loss: 3.7825001313082818
Validation loss: 3.725771600719815

Epoch: 6| Step: 10
Training loss: 3.717697122730993
Validation loss: 3.7234408226041564

Epoch: 6| Step: 11
Training loss: 4.159499654757732
Validation loss: 3.719334579244468

Epoch: 6| Step: 12
Training loss: 3.917333519081473
Validation loss: 3.7147177094325556

Epoch: 6| Step: 13
Training loss: 4.270158196406647
Validation loss: 3.7103244422333357

Epoch: 19| Step: 0
Training loss: 3.8603506978480566
Validation loss: 3.7053841942167236

Epoch: 6| Step: 1
Training loss: 3.9291257665345363
Validation loss: 3.7003065101470183

Epoch: 6| Step: 2
Training loss: 4.924974222648277
Validation loss: 3.6942327932575623

Epoch: 6| Step: 3
Training loss: 4.419010380218462
Validation loss: 3.6895973813462275

Epoch: 6| Step: 4
Training loss: 4.082921740489872
Validation loss: 3.684661481863756

Epoch: 6| Step: 5
Training loss: 3.6051407455079856
Validation loss: 3.681356764458208

Epoch: 6| Step: 6
Training loss: 3.9644288094910296
Validation loss: 3.677592518389985

Epoch: 6| Step: 7
Training loss: 3.5181441712107007
Validation loss: 3.675529656279187

Epoch: 6| Step: 8
Training loss: 4.543440842638073
Validation loss: 3.6735044153809415

Epoch: 6| Step: 9
Training loss: 3.6565417311916186
Validation loss: 3.664969263003712

Epoch: 6| Step: 10
Training loss: 3.0564106717615696
Validation loss: 3.662903656302986

Epoch: 6| Step: 11
Training loss: 2.8837854247775905
Validation loss: 3.6652126902031505

Epoch: 6| Step: 12
Training loss: 3.622695716641282
Validation loss: 3.675126707487594

Epoch: 6| Step: 13
Training loss: 3.327623499664224
Validation loss: 3.6604209033148427

Epoch: 20| Step: 0
Training loss: 4.213803478479867
Validation loss: 3.655997164580315

Epoch: 6| Step: 1
Training loss: 3.9397045200912517
Validation loss: 3.651060089607389

Epoch: 6| Step: 2
Training loss: 4.3445807012560556
Validation loss: 3.647404147680408

Epoch: 6| Step: 3
Training loss: 3.979904239595176
Validation loss: 3.6456772778186095

Epoch: 6| Step: 4
Training loss: 2.9255279716597937
Validation loss: 3.6447456338223247

Epoch: 6| Step: 5
Training loss: 4.00533725380568
Validation loss: 3.6417501950856423

Epoch: 6| Step: 6
Training loss: 3.7605727877486386
Validation loss: 3.6405885488526835

Epoch: 6| Step: 7
Training loss: 4.479723282169832
Validation loss: 3.635670262967075

Epoch: 6| Step: 8
Training loss: 3.416972231963378
Validation loss: 3.6313531356707727

Epoch: 6| Step: 9
Training loss: 3.4783360447223393
Validation loss: 3.6291758608463476

Epoch: 6| Step: 10
Training loss: 3.9113599389810223
Validation loss: 3.621562877064625

Epoch: 6| Step: 11
Training loss: 3.8646434083503816
Validation loss: 3.619814622649394

Epoch: 6| Step: 12
Training loss: 3.493830283783098
Validation loss: 3.617392478423453

Epoch: 6| Step: 13
Training loss: 3.23585631131929
Validation loss: 3.614105924081186

Epoch: 21| Step: 0
Training loss: 3.620352824599415
Validation loss: 3.6136669510259605

Epoch: 6| Step: 1
Training loss: 4.12740787396359
Validation loss: 3.6105861072879932

Epoch: 6| Step: 2
Training loss: 3.774697166573872
Validation loss: 3.6069562350866997

Epoch: 6| Step: 3
Training loss: 4.081285443232392
Validation loss: 3.605713111299791

Epoch: 6| Step: 4
Training loss: 3.428209964113113
Validation loss: 3.6027035526689253

Epoch: 6| Step: 5
Training loss: 3.8903853867369524
Validation loss: 3.599584427983254

Epoch: 6| Step: 6
Training loss: 3.874728039457833
Validation loss: 3.595998353733567

Epoch: 6| Step: 7
Training loss: 3.305708779239649
Validation loss: 3.5938990294099824

Epoch: 6| Step: 8
Training loss: 4.33092069708886
Validation loss: 3.591145701503828

Epoch: 6| Step: 9
Training loss: 4.387303300670606
Validation loss: 3.5892828214629806

Epoch: 6| Step: 10
Training loss: 3.607047779821205
Validation loss: 3.5840690288731887

Epoch: 6| Step: 11
Training loss: 3.107722164200932
Validation loss: 3.5838590500061382

Epoch: 6| Step: 12
Training loss: 4.116458256397137
Validation loss: 3.581710900765387

Epoch: 6| Step: 13
Training loss: 2.5793187007763425
Validation loss: 3.583029367575935

Epoch: 22| Step: 0
Training loss: 2.8639110169253184
Validation loss: 3.582331843458393

Epoch: 6| Step: 1
Training loss: 3.6439319702565007
Validation loss: 3.577609329404188

Epoch: 6| Step: 2
Training loss: 3.340103870992421
Validation loss: 3.578276892550879

Epoch: 6| Step: 3
Training loss: 2.414751170669052
Validation loss: 3.578549675969348

Epoch: 6| Step: 4
Training loss: 4.036869361213211
Validation loss: 3.5730012766284167

Epoch: 6| Step: 5
Training loss: 3.690456304481944
Validation loss: 3.5738371478308

Epoch: 6| Step: 6
Training loss: 4.218536823679421
Validation loss: 3.569957016172268

Epoch: 6| Step: 7
Training loss: 4.113173900916975
Validation loss: 3.5657729862891405

Epoch: 6| Step: 8
Training loss: 4.1858781549078055
Validation loss: 3.5628464607140558

Epoch: 6| Step: 9
Training loss: 3.061135591461764
Validation loss: 3.559220674804611

Epoch: 6| Step: 10
Training loss: 4.5640264596531495
Validation loss: 3.558135363549216

Epoch: 6| Step: 11
Training loss: 4.062666200025795
Validation loss: 3.5566935114347156

Epoch: 6| Step: 12
Training loss: 3.9419189361644658
Validation loss: 3.555688701934431

Epoch: 6| Step: 13
Training loss: 4.14638179556935
Validation loss: 3.553269069508926

Epoch: 23| Step: 0
Training loss: 3.427952077532855
Validation loss: 3.551093226971592

Epoch: 6| Step: 1
Training loss: 4.117774414849823
Validation loss: 3.551223167657674

Epoch: 6| Step: 2
Training loss: 3.2530712874464487
Validation loss: 3.550693116615596

Epoch: 6| Step: 3
Training loss: 3.994790499544864
Validation loss: 3.552815553677059

Epoch: 6| Step: 4
Training loss: 3.8542091298556436
Validation loss: 3.5494168564184254

Epoch: 6| Step: 5
Training loss: 3.2827355791146586
Validation loss: 3.545262013922669

Epoch: 6| Step: 6
Training loss: 4.106124694863227
Validation loss: 3.5401500072413823

Epoch: 6| Step: 7
Training loss: 4.014659721045017
Validation loss: 3.538956450026298

Epoch: 6| Step: 8
Training loss: 3.984579163350728
Validation loss: 3.5387140859661543

Epoch: 6| Step: 9
Training loss: 3.733709683068104
Validation loss: 3.537571830952197

Epoch: 6| Step: 10
Training loss: 3.960341188586798
Validation loss: 3.5326965139702566

Epoch: 6| Step: 11
Training loss: 3.280572585161199
Validation loss: 3.5301879641900755

Epoch: 6| Step: 12
Training loss: 3.6518256651264944
Validation loss: 3.528458953232777

Epoch: 6| Step: 13
Training loss: 3.5392368433705705
Validation loss: 3.530781242815843

Epoch: 24| Step: 0
Training loss: 2.6619324880761797
Validation loss: 3.5282209804988267

Epoch: 6| Step: 1
Training loss: 3.347194288109962
Validation loss: 3.528500815975648

Epoch: 6| Step: 2
Training loss: 4.258977496153759
Validation loss: 3.5299320082676084

Epoch: 6| Step: 3
Training loss: 3.8328715889407996
Validation loss: 3.53217645097502

Epoch: 6| Step: 4
Training loss: 4.369009221453811
Validation loss: 3.5327549343917197

Epoch: 6| Step: 5
Training loss: 4.178303427014156
Validation loss: 3.525056428907822

Epoch: 6| Step: 6
Training loss: 3.4485959001535904
Validation loss: 3.521672903026205

Epoch: 6| Step: 7
Training loss: 3.917462545385039
Validation loss: 3.5216104405040087

Epoch: 6| Step: 8
Training loss: 3.9392262867729904
Validation loss: 3.517017775352649

Epoch: 6| Step: 9
Training loss: 3.2791875260952716
Validation loss: 3.51530142148416

Epoch: 6| Step: 10
Training loss: 3.8631253572644964
Validation loss: 3.5156044886274405

Epoch: 6| Step: 11
Training loss: 2.399599172976288
Validation loss: 3.5147981017137564

Epoch: 6| Step: 12
Training loss: 3.1197196599752255
Validation loss: 3.5132024580581662

Epoch: 6| Step: 13
Training loss: 5.4972463129967934
Validation loss: 3.5108620464630436

Epoch: 25| Step: 0
Training loss: 4.25491116566609
Validation loss: 3.5061939443768115

Epoch: 6| Step: 1
Training loss: 2.514019566389249
Validation loss: 3.5041504289426126

Epoch: 6| Step: 2
Training loss: 2.9279350227275285
Validation loss: 3.502999633221368

Epoch: 6| Step: 3
Training loss: 3.818171800459894
Validation loss: 3.5036133281235573

Epoch: 6| Step: 4
Training loss: 4.277501156492986
Validation loss: 3.500777919884039

Epoch: 6| Step: 5
Training loss: 3.8843409026560574
Validation loss: 3.4964664893218074

Epoch: 6| Step: 6
Training loss: 3.8563160994195713
Validation loss: 3.4978323932241047

Epoch: 6| Step: 7
Training loss: 3.56676107858023
Validation loss: 3.494648928554833

Epoch: 6| Step: 8
Training loss: 3.586292656491571
Validation loss: 3.493389191474074

Epoch: 6| Step: 9
Training loss: 3.9743316328403457
Validation loss: 3.4930189024443417

Epoch: 6| Step: 10
Training loss: 3.6279649119252304
Validation loss: 3.4900205795875907

Epoch: 6| Step: 11
Training loss: 3.2632342626738247
Validation loss: 3.490695294393709

Epoch: 6| Step: 12
Training loss: 3.9625900402729664
Validation loss: 3.4888210344984723

Epoch: 6| Step: 13
Training loss: 4.223125985667526
Validation loss: 3.4868143869176853

Epoch: 26| Step: 0
Training loss: 3.4460179997094165
Validation loss: 3.4857621457802064

Epoch: 6| Step: 1
Training loss: 3.927723448750964
Validation loss: 3.4825803679364187

Epoch: 6| Step: 2
Training loss: 3.3523372297150233
Validation loss: 3.482516448963795

Epoch: 6| Step: 3
Training loss: 4.266702927991639
Validation loss: 3.482258542432857

Epoch: 6| Step: 4
Training loss: 3.889312277558927
Validation loss: 3.478652148745262

Epoch: 6| Step: 5
Training loss: 3.91931822823122
Validation loss: 3.4763000381834885

Epoch: 6| Step: 6
Training loss: 3.1549722332344654
Validation loss: 3.475243610239442

Epoch: 6| Step: 7
Training loss: 3.804539859734883
Validation loss: 3.472870507595352

Epoch: 6| Step: 8
Training loss: 3.0869049487270557
Validation loss: 3.471103935613303

Epoch: 6| Step: 9
Training loss: 3.89444946080742
Validation loss: 3.468746592896826

Epoch: 6| Step: 10
Training loss: 4.5316105140124305
Validation loss: 3.466822867763284

Epoch: 6| Step: 11
Training loss: 2.7715903565007665
Validation loss: 3.466568139153534

Epoch: 6| Step: 12
Training loss: 3.0845550144463294
Validation loss: 3.462759426300818

Epoch: 6| Step: 13
Training loss: 4.343042549320129
Validation loss: 3.462041608510991

Epoch: 27| Step: 0
Training loss: 3.9407422477105283
Validation loss: 3.4631871852160425

Epoch: 6| Step: 1
Training loss: 2.971011775909886
Validation loss: 3.4627438390177363

Epoch: 6| Step: 2
Training loss: 3.8720685884296286
Validation loss: 3.463398289062517

Epoch: 6| Step: 3
Training loss: 3.1715389881771645
Validation loss: 3.460489548015089

Epoch: 6| Step: 4
Training loss: 4.274785639870811
Validation loss: 3.458265955259117

Epoch: 6| Step: 5
Training loss: 3.870000875507423
Validation loss: 3.4545262554732483

Epoch: 6| Step: 6
Training loss: 3.797361115156657
Validation loss: 3.4528665701566905

Epoch: 6| Step: 7
Training loss: 3.7315101008916804
Validation loss: 3.4527818818091154

Epoch: 6| Step: 8
Training loss: 2.949526577478155
Validation loss: 3.4499751197853494

Epoch: 6| Step: 9
Training loss: 4.165538762338191
Validation loss: 3.451032307430815

Epoch: 6| Step: 10
Training loss: 3.737757726860722
Validation loss: 3.443590501150857

Epoch: 6| Step: 11
Training loss: 3.896963570941123
Validation loss: 3.4510915189642257

Epoch: 6| Step: 12
Training loss: 3.3092448236872087
Validation loss: 3.4471796195559947

Epoch: 6| Step: 13
Training loss: 3.1784170551071944
Validation loss: 3.4415563461458714

Epoch: 28| Step: 0
Training loss: 3.979385423222739
Validation loss: 3.4390006227066467

Epoch: 6| Step: 1
Training loss: 2.8563878867090824
Validation loss: 3.4384877282064177

Epoch: 6| Step: 2
Training loss: 3.292601360130898
Validation loss: 3.4363848416493936

Epoch: 6| Step: 3
Training loss: 4.118468228370313
Validation loss: 3.4349374207981564

Epoch: 6| Step: 4
Training loss: 4.103984589902861
Validation loss: 3.4309322421113064

Epoch: 6| Step: 5
Training loss: 2.735662102904134
Validation loss: 3.427909167841472

Epoch: 6| Step: 6
Training loss: 4.012994164195263
Validation loss: 3.427410520171832

Epoch: 6| Step: 7
Training loss: 4.122132431679234
Validation loss: 3.4260675130603047

Epoch: 6| Step: 8
Training loss: 2.8014034500546376
Validation loss: 3.423633007908701

Epoch: 6| Step: 9
Training loss: 4.562819796289155
Validation loss: 3.42105382922861

Epoch: 6| Step: 10
Training loss: 3.136545140840831
Validation loss: 3.4200867101395493

Epoch: 6| Step: 11
Training loss: 3.7627300356884716
Validation loss: 3.4169224408983183

Epoch: 6| Step: 12
Training loss: 3.556331715374058
Validation loss: 3.416543840311011

Epoch: 6| Step: 13
Training loss: 3.339428685146049
Validation loss: 3.4138762101119804

Epoch: 29| Step: 0
Training loss: 3.194684477555305
Validation loss: 3.4156291240692047

Epoch: 6| Step: 1
Training loss: 4.043942364652692
Validation loss: 3.416991740343602

Epoch: 6| Step: 2
Training loss: 4.656587934071914
Validation loss: 3.408721587087506

Epoch: 6| Step: 3
Training loss: 3.5340953604974845
Validation loss: 3.4071066468684017

Epoch: 6| Step: 4
Training loss: 3.4281306806602463
Validation loss: 3.408762567077024

Epoch: 6| Step: 5
Training loss: 3.5171486498645663
Validation loss: 3.412239950191678

Epoch: 6| Step: 6
Training loss: 3.1121709320273925
Validation loss: 3.42752768502779

Epoch: 6| Step: 7
Training loss: 3.419384054075403
Validation loss: 3.407526122459462

Epoch: 6| Step: 8
Training loss: 3.9223746783122886
Validation loss: 3.4028439810359923

Epoch: 6| Step: 9
Training loss: 3.0037146458825212
Validation loss: 3.4005643204369833

Epoch: 6| Step: 10
Training loss: 2.8745969406877085
Validation loss: 3.4039688261517784

Epoch: 6| Step: 11
Training loss: 4.007581678142371
Validation loss: 3.402991161529972

Epoch: 6| Step: 12
Training loss: 4.081138929459257
Validation loss: 3.397883526293953

Epoch: 6| Step: 13
Training loss: 3.638370323278537
Validation loss: 3.3971345468092364

Epoch: 30| Step: 0
Training loss: 3.107592507885865
Validation loss: 3.400525692564501

Epoch: 6| Step: 1
Training loss: 3.3244631685261186
Validation loss: 3.395610960330376

Epoch: 6| Step: 2
Training loss: 3.461751114597776
Validation loss: 3.3915555503171273

Epoch: 6| Step: 3
Training loss: 4.009185972091277
Validation loss: 3.391668451091096

Epoch: 6| Step: 4
Training loss: 3.8992541113419237
Validation loss: 3.391537274375787

Epoch: 6| Step: 5
Training loss: 3.6870282404795534
Validation loss: 3.389273663648849

Epoch: 6| Step: 6
Training loss: 3.8543896309909087
Validation loss: 3.3858381096440247

Epoch: 6| Step: 7
Training loss: 3.631523313758173
Validation loss: 3.387182396511146

Epoch: 6| Step: 8
Training loss: 4.132846190345902
Validation loss: 3.3850948668598946

Epoch: 6| Step: 9
Training loss: 4.260730884160173
Validation loss: 3.3808236309723165

Epoch: 6| Step: 10
Training loss: 3.565330050519955
Validation loss: 3.379749227416015

Epoch: 6| Step: 11
Training loss: 2.9733699788913035
Validation loss: 3.3788484123496536

Epoch: 6| Step: 12
Training loss: 3.532323083463176
Validation loss: 3.3788985747890874

Epoch: 6| Step: 13
Training loss: 2.0853192845592465
Validation loss: 3.380453580960137

Epoch: 31| Step: 0
Training loss: 4.217436409353834
Validation loss: 3.381181524334467

Epoch: 6| Step: 1
Training loss: 3.260456576524574
Validation loss: 3.3785744822778074

Epoch: 6| Step: 2
Training loss: 3.3252235624258866
Validation loss: 3.374516449822877

Epoch: 6| Step: 3
Training loss: 2.8229096941609626
Validation loss: 3.3758836437906146

Epoch: 6| Step: 4
Training loss: 4.198935310201601
Validation loss: 3.371871041687116

Epoch: 6| Step: 5
Training loss: 3.71229351766747
Validation loss: 3.3730088288502005

Epoch: 6| Step: 6
Training loss: 3.6048023934774163
Validation loss: 3.36681322678126

Epoch: 6| Step: 7
Training loss: 3.821727529629759
Validation loss: 3.3657469522007886

Epoch: 6| Step: 8
Training loss: 3.7676319140227843
Validation loss: 3.364625317472787

Epoch: 6| Step: 9
Training loss: 3.9139314123195614
Validation loss: 3.367339552267126

Epoch: 6| Step: 10
Training loss: 3.7261248637484146
Validation loss: 3.366523449740204

Epoch: 6| Step: 11
Training loss: 3.564378209829181
Validation loss: 3.3640075061824533

Epoch: 6| Step: 12
Training loss: 2.7952617062793594
Validation loss: 3.364202056365112

Epoch: 6| Step: 13
Training loss: 3.1220371696805898
Validation loss: 3.3708656264363146

Epoch: 32| Step: 0
Training loss: 3.2711170502737743
Validation loss: 3.3729576409084006

Epoch: 6| Step: 1
Training loss: 3.6539977872327127
Validation loss: 3.3687912008224195

Epoch: 6| Step: 2
Training loss: 4.061183305253185
Validation loss: 3.3595422892449545

Epoch: 6| Step: 3
Training loss: 3.4916143779132156
Validation loss: 3.357451380903585

Epoch: 6| Step: 4
Training loss: 4.375826948213662
Validation loss: 3.358511368970306

Epoch: 6| Step: 5
Training loss: 3.5994996888809294
Validation loss: 3.361845437013131

Epoch: 6| Step: 6
Training loss: 2.748476907123376
Validation loss: 3.358404722935642

Epoch: 6| Step: 7
Training loss: 2.440329352335433
Validation loss: 3.3544870227550003

Epoch: 6| Step: 8
Training loss: 2.889510151092922
Validation loss: 3.3544729178707895

Epoch: 6| Step: 9
Training loss: 3.7156357748197824
Validation loss: 3.353053562068594

Epoch: 6| Step: 10
Training loss: 3.9664138766822727
Validation loss: 3.3526422828536337

Epoch: 6| Step: 11
Training loss: 3.750840919304458
Validation loss: 3.3513188522991677

Epoch: 6| Step: 12
Training loss: 4.522036742380415
Validation loss: 3.3505104272989037

Epoch: 6| Step: 13
Training loss: 2.739992050799791
Validation loss: 3.3522817754567282

Epoch: 33| Step: 0
Training loss: 3.6352583332431907
Validation loss: 3.3519846206272286

Epoch: 6| Step: 1
Training loss: 3.406397265129371
Validation loss: 3.354723111798462

Epoch: 6| Step: 2
Training loss: 4.2404127254782
Validation loss: 3.35339646135433

Epoch: 6| Step: 3
Training loss: 2.799696452853219
Validation loss: 3.35327420482012

Epoch: 6| Step: 4
Training loss: 2.76272551707817
Validation loss: 3.3526372850142376

Epoch: 6| Step: 5
Training loss: 3.595330993525204
Validation loss: 3.3485355367075567

Epoch: 6| Step: 6
Training loss: 3.0243905706728107
Validation loss: 3.3466030917739276

Epoch: 6| Step: 7
Training loss: 3.8547174558492237
Validation loss: 3.3468831605613474

Epoch: 6| Step: 8
Training loss: 3.540198945742944
Validation loss: 3.345703195494879

Epoch: 6| Step: 9
Training loss: 3.966261436429083
Validation loss: 3.345521430242065

Epoch: 6| Step: 10
Training loss: 3.048649823621977
Validation loss: 3.3401612512820957

Epoch: 6| Step: 11
Training loss: 4.497109226385653
Validation loss: 3.341233003938472

Epoch: 6| Step: 12
Training loss: 3.3406694428901758
Validation loss: 3.3400422405774477

Epoch: 6| Step: 13
Training loss: 4.203040593657596
Validation loss: 3.3406530265592096

Epoch: 34| Step: 0
Training loss: 3.119645987258078
Validation loss: 3.3369560357300503

Epoch: 6| Step: 1
Training loss: 3.7557861194022784
Validation loss: 3.336922345943477

Epoch: 6| Step: 2
Training loss: 3.6900490178106327
Validation loss: 3.3392044711535633

Epoch: 6| Step: 3
Training loss: 2.9950917146169806
Validation loss: 3.340983109620677

Epoch: 6| Step: 4
Training loss: 3.795711134874357
Validation loss: 3.352718366697652

Epoch: 6| Step: 5
Training loss: 3.832273640874947
Validation loss: 3.341889251713147

Epoch: 6| Step: 6
Training loss: 3.769102651314047
Validation loss: 3.3379827933917063

Epoch: 6| Step: 7
Training loss: 3.861831933179764
Validation loss: 3.3351635082219135

Epoch: 6| Step: 8
Training loss: 4.303044665105462
Validation loss: 3.3323819038309064

Epoch: 6| Step: 9
Training loss: 3.1289580646848947
Validation loss: 3.3335807344445034

Epoch: 6| Step: 10
Training loss: 3.259923310577218
Validation loss: 3.329973115084203

Epoch: 6| Step: 11
Training loss: 3.0535883572395197
Validation loss: 3.330100256401524

Epoch: 6| Step: 12
Training loss: 2.6997967113682546
Validation loss: 3.330717643821705

Epoch: 6| Step: 13
Training loss: 4.771166771754221
Validation loss: 3.3285287337464893

Epoch: 35| Step: 0
Training loss: 3.5521459191738614
Validation loss: 3.328624927548556

Epoch: 6| Step: 1
Training loss: 3.288933903225724
Validation loss: 3.32796961076757

Epoch: 6| Step: 2
Training loss: 3.894608752245705
Validation loss: 3.3275654147249205

Epoch: 6| Step: 3
Training loss: 3.4801762347704512
Validation loss: 3.331565407070044

Epoch: 6| Step: 4
Training loss: 3.2167002252860724
Validation loss: 3.336863290427131

Epoch: 6| Step: 5
Training loss: 4.473774253009927
Validation loss: 3.3347387786206544

Epoch: 6| Step: 6
Training loss: 3.4566261183427516
Validation loss: 3.3249643575401953

Epoch: 6| Step: 7
Training loss: 2.843391311996505
Validation loss: 3.324186587680276

Epoch: 6| Step: 8
Training loss: 3.9034855940973054
Validation loss: 3.3249905369220163

Epoch: 6| Step: 9
Training loss: 2.869287870094203
Validation loss: 3.32425263639673

Epoch: 6| Step: 10
Training loss: 3.597240842347986
Validation loss: 3.3243517879837725

Epoch: 6| Step: 11
Training loss: 3.0877825279545523
Validation loss: 3.3240701362562493

Epoch: 6| Step: 12
Training loss: 4.478058623243238
Validation loss: 3.3227545477862206

Epoch: 6| Step: 13
Training loss: 3.003189140214425
Validation loss: 3.322433430884671

Epoch: 36| Step: 0
Training loss: 3.633634084683948
Validation loss: 3.322228519022953

Epoch: 6| Step: 1
Training loss: 3.212105123393453
Validation loss: 3.320719607716142

Epoch: 6| Step: 2
Training loss: 4.0102170159651855
Validation loss: 3.3185923547313756

Epoch: 6| Step: 3
Training loss: 3.874815905720252
Validation loss: 3.31934954602178

Epoch: 6| Step: 4
Training loss: 3.245958896961975
Validation loss: 3.319925209539304

Epoch: 6| Step: 5
Training loss: 3.047981569890249
Validation loss: 3.318077369910723

Epoch: 6| Step: 6
Training loss: 3.481434629191182
Validation loss: 3.317497593029661

Epoch: 6| Step: 7
Training loss: 3.6801644763264236
Validation loss: 3.318821829702592

Epoch: 6| Step: 8
Training loss: 3.1866347690672403
Validation loss: 3.3181958179032707

Epoch: 6| Step: 9
Training loss: 3.910352459995027
Validation loss: 3.3173861177216626

Epoch: 6| Step: 10
Training loss: 4.136069501695005
Validation loss: 3.315356243841863

Epoch: 6| Step: 11
Training loss: 3.3745041942222755
Validation loss: 3.3147681951578374

Epoch: 6| Step: 12
Training loss: 3.426444429867386
Validation loss: 3.31361243246852

Epoch: 6| Step: 13
Training loss: 3.231030047547044
Validation loss: 3.3136657223902186

Epoch: 37| Step: 0
Training loss: 2.734434639416567
Validation loss: 3.3140017216048747

Epoch: 6| Step: 1
Training loss: 3.291846033030066
Validation loss: 3.3132519447998754

Epoch: 6| Step: 2
Training loss: 3.795745807284849
Validation loss: 3.312189593391878

Epoch: 6| Step: 3
Training loss: 3.0198123302632176
Validation loss: 3.3131044981271387

Epoch: 6| Step: 4
Training loss: 3.1863658607701724
Validation loss: 3.31267624995813

Epoch: 6| Step: 5
Training loss: 4.447465479150167
Validation loss: 3.3102679310160097

Epoch: 6| Step: 6
Training loss: 2.6261782953495074
Validation loss: 3.3119083308756365

Epoch: 6| Step: 7
Training loss: 3.760127823462827
Validation loss: 3.312019666230528

Epoch: 6| Step: 8
Training loss: 4.402720234705799
Validation loss: 3.3103934872936716

Epoch: 6| Step: 9
Training loss: 4.329934082939099
Validation loss: 3.310336109890805

Epoch: 6| Step: 10
Training loss: 3.382223240933938
Validation loss: 3.3104004555330206

Epoch: 6| Step: 11
Training loss: 3.370350213120594
Validation loss: 3.3092658332277654

Epoch: 6| Step: 12
Training loss: 3.3100686417114975
Validation loss: 3.3085587827012937

Epoch: 6| Step: 13
Training loss: 3.378036263541695
Validation loss: 3.308389254869933

Epoch: 38| Step: 0
Training loss: 3.1850281649172145
Validation loss: 3.309436242632284

Epoch: 6| Step: 1
Training loss: 3.4066202504926926
Validation loss: 3.3088689100947164

Epoch: 6| Step: 2
Training loss: 3.2282054495965227
Validation loss: 3.3091391697057477

Epoch: 6| Step: 3
Training loss: 3.7593328687632948
Validation loss: 3.3088045734085316

Epoch: 6| Step: 4
Training loss: 2.953666516261141
Validation loss: 3.3077681959319833

Epoch: 6| Step: 5
Training loss: 3.9158636582109527
Validation loss: 3.3075612469986035

Epoch: 6| Step: 6
Training loss: 3.461581133718015
Validation loss: 3.3082249010828964

Epoch: 6| Step: 7
Training loss: 4.335824885924967
Validation loss: 3.3056040545698115

Epoch: 6| Step: 8
Training loss: 3.3669150257723293
Validation loss: 3.3051365237215573

Epoch: 6| Step: 9
Training loss: 4.277102055100637
Validation loss: 3.3044454357493858

Epoch: 6| Step: 10
Training loss: 2.885031737577778
Validation loss: 3.305245049822947

Epoch: 6| Step: 11
Training loss: 3.8345862842600824
Validation loss: 3.3040569775138837

Epoch: 6| Step: 12
Training loss: 3.5179605143783377
Validation loss: 3.304235913871687

Epoch: 6| Step: 13
Training loss: 2.8350756467922804
Validation loss: 3.303562945479613

Epoch: 39| Step: 0
Training loss: 4.079550775218748
Validation loss: 3.3024432759044213

Epoch: 6| Step: 1
Training loss: 3.53614872441877
Validation loss: 3.3029186144293186

Epoch: 6| Step: 2
Training loss: 3.2820512065902725
Validation loss: 3.3034239351173844

Epoch: 6| Step: 3
Training loss: 2.531885703051753
Validation loss: 3.300928720567098

Epoch: 6| Step: 4
Training loss: 3.523523841358267
Validation loss: 3.3003592109510254

Epoch: 6| Step: 5
Training loss: 3.500059127308183
Validation loss: 3.2980515527270655

Epoch: 6| Step: 6
Training loss: 4.287816490303264
Validation loss: 3.297748604866295

Epoch: 6| Step: 7
Training loss: 3.466037824033638
Validation loss: 3.2964853152573403

Epoch: 6| Step: 8
Training loss: 4.175883335617798
Validation loss: 3.2953567939978496

Epoch: 6| Step: 9
Training loss: 3.3301968282087797
Validation loss: 3.2998719078975878

Epoch: 6| Step: 10
Training loss: 2.185657924527376
Validation loss: 3.2950545818064234

Epoch: 6| Step: 11
Training loss: 3.6089149611282436
Validation loss: 3.2911813787637465

Epoch: 6| Step: 12
Training loss: 3.3987398561169853
Validation loss: 3.293216526331807

Epoch: 6| Step: 13
Training loss: 4.338702225967488
Validation loss: 3.2907989394590675

Epoch: 40| Step: 0
Training loss: 2.9824888650281816
Validation loss: 3.288391766655766

Epoch: 6| Step: 1
Training loss: 2.984849822133998
Validation loss: 3.2829385783010148

Epoch: 6| Step: 2
Training loss: 3.872662485258875
Validation loss: 3.2808680517642235

Epoch: 6| Step: 3
Training loss: 4.142770117987273
Validation loss: 3.2814070516055356

Epoch: 6| Step: 4
Training loss: 4.080998486279985
Validation loss: 3.280865566940031

Epoch: 6| Step: 5
Training loss: 3.4069663878076883
Validation loss: 3.2780447951310108

Epoch: 6| Step: 6
Training loss: 2.503592580111617
Validation loss: 3.279889460563591

Epoch: 6| Step: 7
Training loss: 3.8024664002187425
Validation loss: 3.2765813363087517

Epoch: 6| Step: 8
Training loss: 3.05297491354808
Validation loss: 3.2776290736304876

Epoch: 6| Step: 9
Training loss: 4.287296675151105
Validation loss: 3.2771476106009167

Epoch: 6| Step: 10
Training loss: 3.780212259943165
Validation loss: 3.274621664195396

Epoch: 6| Step: 11
Training loss: 3.444670809892491
Validation loss: 3.2753749350047747

Epoch: 6| Step: 12
Training loss: 3.029446881611939
Validation loss: 3.2774503710758136

Epoch: 6| Step: 13
Training loss: 3.4135771172857274
Validation loss: 3.2709884925493626

Epoch: 41| Step: 0
Training loss: 3.3453763055039483
Validation loss: 3.2737083181083344

Epoch: 6| Step: 1
Training loss: 2.874741252368012
Validation loss: 3.272495464035181

Epoch: 6| Step: 2
Training loss: 3.687708961902405
Validation loss: 3.2737989418722813

Epoch: 6| Step: 3
Training loss: 3.8298688381036805
Validation loss: 3.272344564733319

Epoch: 6| Step: 4
Training loss: 3.3185958912731746
Validation loss: 3.273838239633622

Epoch: 6| Step: 5
Training loss: 3.2178989507482303
Validation loss: 3.2722678287991287

Epoch: 6| Step: 6
Training loss: 3.620742402217105
Validation loss: 3.2713396850777188

Epoch: 6| Step: 7
Training loss: 3.0837159477861866
Validation loss: 3.272996613596632

Epoch: 6| Step: 8
Training loss: 3.6935760095608323
Validation loss: 3.2708572617776306

Epoch: 6| Step: 9
Training loss: 3.7761536610097868
Validation loss: 3.2784226478812806

Epoch: 6| Step: 10
Training loss: 3.2897522264303904
Validation loss: 3.269028957498386

Epoch: 6| Step: 11
Training loss: 4.089087706952063
Validation loss: 3.2694289828950365

Epoch: 6| Step: 12
Training loss: 3.6285243824074804
Validation loss: 3.2654170995446834

Epoch: 6| Step: 13
Training loss: 3.652118141427699
Validation loss: 3.2635977410472607

Epoch: 42| Step: 0
Training loss: 3.5273740308777772
Validation loss: 3.2649299410620065

Epoch: 6| Step: 1
Training loss: 3.283272256299251
Validation loss: 3.262895227730572

Epoch: 6| Step: 2
Training loss: 3.247018473505372
Validation loss: 3.2630829673049644

Epoch: 6| Step: 3
Training loss: 3.1530600564731657
Validation loss: 3.2635566263613476

Epoch: 6| Step: 4
Training loss: 4.2136081585001355
Validation loss: 3.2635153179132073

Epoch: 6| Step: 5
Training loss: 3.074351519925203
Validation loss: 3.261831358332062

Epoch: 6| Step: 6
Training loss: 3.953253099378918
Validation loss: 3.262304828196303

Epoch: 6| Step: 7
Training loss: 3.3629863401482076
Validation loss: 3.259051099901645

Epoch: 6| Step: 8
Training loss: 3.58948894486596
Validation loss: 3.259090464578541

Epoch: 6| Step: 9
Training loss: 3.2131607266784448
Validation loss: 3.2592800184706467

Epoch: 6| Step: 10
Training loss: 3.5879990712380456
Validation loss: 3.258640761126828

Epoch: 6| Step: 11
Training loss: 3.912585560408499
Validation loss: 3.2611302049714723

Epoch: 6| Step: 12
Training loss: 3.5966343458654353
Validation loss: 3.260504429339193

Epoch: 6| Step: 13
Training loss: 2.981123985970151
Validation loss: 3.258389387825356

Epoch: 43| Step: 0
Training loss: 3.154480088525881
Validation loss: 3.257266123354357

Epoch: 6| Step: 1
Training loss: 3.5663529023340943
Validation loss: 3.2590427569801785

Epoch: 6| Step: 2
Training loss: 2.9220793137540158
Validation loss: 3.257320410660405

Epoch: 6| Step: 3
Training loss: 3.1644252239523434
Validation loss: 3.2565126786559104

Epoch: 6| Step: 4
Training loss: 3.6073269668924297
Validation loss: 3.2551521658040667

Epoch: 6| Step: 5
Training loss: 3.482658476609107
Validation loss: 3.2553327082674235

Epoch: 6| Step: 6
Training loss: 3.7708005675407996
Validation loss: 3.256582680410843

Epoch: 6| Step: 7
Training loss: 3.8765787169652732
Validation loss: 3.2569578752553365

Epoch: 6| Step: 8
Training loss: 3.6240675154369453
Validation loss: 3.2571832692454565

Epoch: 6| Step: 9
Training loss: 3.2821061243616523
Validation loss: 3.2565619072349437

Epoch: 6| Step: 10
Training loss: 2.9987440659216635
Validation loss: 3.2576395538105998

Epoch: 6| Step: 11
Training loss: 4.0061848032581375
Validation loss: 3.259159872148692

Epoch: 6| Step: 12
Training loss: 3.277128992330489
Validation loss: 3.2594140112607572

Epoch: 6| Step: 13
Training loss: 4.484564694104153
Validation loss: 3.2568658209845975

Epoch: 44| Step: 0
Training loss: 3.7495179184351826
Validation loss: 3.25410121094396

Epoch: 6| Step: 1
Training loss: 3.62660076707918
Validation loss: 3.252539400667905

Epoch: 6| Step: 2
Training loss: 2.866390606059535
Validation loss: 3.2535996770725366

Epoch: 6| Step: 3
Training loss: 3.6421430967186197
Validation loss: 3.252013061842203

Epoch: 6| Step: 4
Training loss: 3.523872703859748
Validation loss: 3.2527244245671203

Epoch: 6| Step: 5
Training loss: 4.0245554139441575
Validation loss: 3.252402814356612

Epoch: 6| Step: 6
Training loss: 4.192718442663796
Validation loss: 3.2525992557701993

Epoch: 6| Step: 7
Training loss: 3.781522126297135
Validation loss: 3.2553712004577426

Epoch: 6| Step: 8
Training loss: 2.723905213946144
Validation loss: 3.252444204037073

Epoch: 6| Step: 9
Training loss: 3.506383660092708
Validation loss: 3.249066741831419

Epoch: 6| Step: 10
Training loss: 4.099214590254822
Validation loss: 3.24966991568899

Epoch: 6| Step: 11
Training loss: 2.0895651373129605
Validation loss: 3.251720779082306

Epoch: 6| Step: 12
Training loss: 3.361389975280757
Validation loss: 3.248999251461717

Epoch: 6| Step: 13
Training loss: 2.9915273550709336
Validation loss: 3.2499916622411456

Epoch: 45| Step: 0
Training loss: 3.503052606438642
Validation loss: 3.24757745693449

Epoch: 6| Step: 1
Training loss: 3.176185122401195
Validation loss: 3.248678208381632

Epoch: 6| Step: 2
Training loss: 2.4341911941889327
Validation loss: 3.2471374166276354

Epoch: 6| Step: 3
Training loss: 3.225020143904355
Validation loss: 3.2472868275598525

Epoch: 6| Step: 4
Training loss: 2.9331750075643286
Validation loss: 3.2471406867677017

Epoch: 6| Step: 5
Training loss: 3.3258179024344985
Validation loss: 3.2468630526211117

Epoch: 6| Step: 6
Training loss: 3.842951001496421
Validation loss: 3.2460102174059142

Epoch: 6| Step: 7
Training loss: 4.1596028277726775
Validation loss: 3.245625660798651

Epoch: 6| Step: 8
Training loss: 3.342843619169051
Validation loss: 3.2439702295779065

Epoch: 6| Step: 9
Training loss: 3.6429849596867547
Validation loss: 3.2461498099629975

Epoch: 6| Step: 10
Training loss: 4.0796889306208
Validation loss: 3.2452593574180058

Epoch: 6| Step: 11
Training loss: 2.924990049165933
Validation loss: 3.2449038063863003

Epoch: 6| Step: 12
Training loss: 3.6983056235482294
Validation loss: 3.243717064975691

Epoch: 6| Step: 13
Training loss: 4.642928967601525
Validation loss: 3.243844983788823

Epoch: 46| Step: 0
Training loss: 3.217496164789411
Validation loss: 3.244145388546403

Epoch: 6| Step: 1
Training loss: 3.632809481055533
Validation loss: 3.2446378278583796

Epoch: 6| Step: 2
Training loss: 4.093560367297995
Validation loss: 3.243358647933032

Epoch: 6| Step: 3
Training loss: 3.3198069468061693
Validation loss: 3.2422509651876403

Epoch: 6| Step: 4
Training loss: 3.3240012827295797
Validation loss: 3.240756901913798

Epoch: 6| Step: 5
Training loss: 3.538764856887401
Validation loss: 3.2439469937198124

Epoch: 6| Step: 6
Training loss: 2.653754823871672
Validation loss: 3.2436970266233507

Epoch: 6| Step: 7
Training loss: 3.3420853794042333
Validation loss: 3.242237048876873

Epoch: 6| Step: 8
Training loss: 3.49295806917261
Validation loss: 3.2405613287976545

Epoch: 6| Step: 9
Training loss: 3.9937623980453587
Validation loss: 3.241115314799468

Epoch: 6| Step: 10
Training loss: 3.4789959224140845
Validation loss: 3.2405228347361996

Epoch: 6| Step: 11
Training loss: 3.617410541685808
Validation loss: 3.2396135131286936

Epoch: 6| Step: 12
Training loss: 3.2801946486890947
Validation loss: 3.2410724848113763

Epoch: 6| Step: 13
Training loss: 3.8419073386667417
Validation loss: 3.2407921126969206

Epoch: 47| Step: 0
Training loss: 3.2412802288559774
Validation loss: 3.2399359719094907

Epoch: 6| Step: 1
Training loss: 3.567407273261677
Validation loss: 3.2397887319744707

Epoch: 6| Step: 2
Training loss: 4.451698262054812
Validation loss: 3.241943345437629

Epoch: 6| Step: 3
Training loss: 3.3632669304555067
Validation loss: 3.2405366365766937

Epoch: 6| Step: 4
Training loss: 4.311639672307782
Validation loss: 3.240197820239122

Epoch: 6| Step: 5
Training loss: 3.0050143615074805
Validation loss: 3.2394351746636216

Epoch: 6| Step: 6
Training loss: 2.6421024320094912
Validation loss: 3.2415583395805525

Epoch: 6| Step: 7
Training loss: 2.53805061717921
Validation loss: 3.2396598284332674

Epoch: 6| Step: 8
Training loss: 3.978927898067214
Validation loss: 3.2365177240673217

Epoch: 6| Step: 9
Training loss: 3.1464395170607498
Validation loss: 3.235357606799089

Epoch: 6| Step: 10
Training loss: 3.270174936170721
Validation loss: 3.2364020629550727

Epoch: 6| Step: 11
Training loss: 3.8221273967404676
Validation loss: 3.235973795057544

Epoch: 6| Step: 12
Training loss: 3.68292392049116
Validation loss: 3.2359774678410687

Epoch: 6| Step: 13
Training loss: 3.0332215180241593
Validation loss: 3.2359936451511535

Epoch: 48| Step: 0
Training loss: 3.727636410464165
Validation loss: 3.2351722933439153

Epoch: 6| Step: 1
Training loss: 2.285434073489401
Validation loss: 3.2360186810031513

Epoch: 6| Step: 2
Training loss: 3.123245967700248
Validation loss: 3.2357362341135674

Epoch: 6| Step: 3
Training loss: 3.22048370187583
Validation loss: 3.2349700911339223

Epoch: 6| Step: 4
Training loss: 4.098550326226498
Validation loss: 3.236557767564066

Epoch: 6| Step: 5
Training loss: 3.5257271307543228
Validation loss: 3.235895136596804

Epoch: 6| Step: 6
Training loss: 3.3364267459501202
Validation loss: 3.2346442619131257

Epoch: 6| Step: 7
Training loss: 3.902931329520372
Validation loss: 3.235560947936345

Epoch: 6| Step: 8
Training loss: 4.368066579821323
Validation loss: 3.2365802770607206

Epoch: 6| Step: 9
Training loss: 3.7811122900737137
Validation loss: 3.238642002090403

Epoch: 6| Step: 10
Training loss: 3.1900078874448647
Validation loss: 3.2370744342591955

Epoch: 6| Step: 11
Training loss: 3.314353855964077
Validation loss: 3.2358601490261223

Epoch: 6| Step: 12
Training loss: 2.779838889825713
Validation loss: 3.236204243849843

Epoch: 6| Step: 13
Training loss: 3.743327371372311
Validation loss: 3.233564163732793

Epoch: 49| Step: 0
Training loss: 3.555472553463207
Validation loss: 3.232234987772935

Epoch: 6| Step: 1
Training loss: 3.7189360499924042
Validation loss: 3.2320737764267036

Epoch: 6| Step: 2
Training loss: 2.691199307174684
Validation loss: 3.2295046123716853

Epoch: 6| Step: 3
Training loss: 3.9023548695021133
Validation loss: 3.230346909115649

Epoch: 6| Step: 4
Training loss: 2.334525916188752
Validation loss: 3.2311033022053754

Epoch: 6| Step: 5
Training loss: 3.4719885751738433
Validation loss: 3.2299799191116016

Epoch: 6| Step: 6
Training loss: 3.241024829179711
Validation loss: 3.2303794367087098

Epoch: 6| Step: 7
Training loss: 3.8172531515777126
Validation loss: 3.2296316176654303

Epoch: 6| Step: 8
Training loss: 2.9934544682223434
Validation loss: 3.230007415997143

Epoch: 6| Step: 9
Training loss: 3.3086110444500774
Validation loss: 3.2305324692144692

Epoch: 6| Step: 10
Training loss: 3.9920641139124258
Validation loss: 3.230289974920927

Epoch: 6| Step: 11
Training loss: 4.438361500674426
Validation loss: 3.231212017162724

Epoch: 6| Step: 12
Training loss: 3.377622080304189
Validation loss: 3.2297295711231966

Epoch: 6| Step: 13
Training loss: 3.298531211197662
Validation loss: 3.227899779348221

Epoch: 50| Step: 0
Training loss: 3.4015097575902153
Validation loss: 3.226269011301889

Epoch: 6| Step: 1
Training loss: 3.3510764598769462
Validation loss: 3.2270307311641573

Epoch: 6| Step: 2
Training loss: 4.400791764547288
Validation loss: 3.2259247118284

Epoch: 6| Step: 3
Training loss: 3.6420675538620273
Validation loss: 3.22688757699374

Epoch: 6| Step: 4
Training loss: 2.7905786491209903
Validation loss: 3.2274902967564483

Epoch: 6| Step: 5
Training loss: 4.424428680952156
Validation loss: 3.2278920214642928

Epoch: 6| Step: 6
Training loss: 3.630966275238445
Validation loss: 3.2271782640244466

Epoch: 6| Step: 7
Training loss: 2.5950816768956466
Validation loss: 3.2242290116744625

Epoch: 6| Step: 8
Training loss: 3.336245949129209
Validation loss: 3.2253164089900555

Epoch: 6| Step: 9
Training loss: 3.676666380212749
Validation loss: 3.2243628867897742

Epoch: 6| Step: 10
Training loss: 2.9080719517932567
Validation loss: 3.224042279303272

Epoch: 6| Step: 11
Training loss: 3.382554253638601
Validation loss: 3.2240387789917913

Epoch: 6| Step: 12
Training loss: 3.389056708830849
Validation loss: 3.224177678485543

Epoch: 6| Step: 13
Training loss: 3.0730392345402824
Validation loss: 3.2253566344748714

Epoch: 51| Step: 0
Training loss: 3.408558614384936
Validation loss: 3.2251332561933945

Epoch: 6| Step: 1
Training loss: 3.318964570143992
Validation loss: 3.2253989721141867

Epoch: 6| Step: 2
Training loss: 3.6660532149194975
Validation loss: 3.2246866026701815

Epoch: 6| Step: 3
Training loss: 3.8997526530544064
Validation loss: 3.2229470267423177

Epoch: 6| Step: 4
Training loss: 4.175864837066829
Validation loss: 3.2275342792099924

Epoch: 6| Step: 5
Training loss: 3.652005070777874
Validation loss: 3.2210038447316895

Epoch: 6| Step: 6
Training loss: 3.0985061614815708
Validation loss: 3.220973147791249

Epoch: 6| Step: 7
Training loss: 3.5126202437158645
Validation loss: 3.222254922736488

Epoch: 6| Step: 8
Training loss: 2.742260532547763
Validation loss: 3.2242032370453324

Epoch: 6| Step: 9
Training loss: 2.9542421518715307
Validation loss: 3.2252934170959486

Epoch: 6| Step: 10
Training loss: 2.9427315410047714
Validation loss: 3.2266386210289646

Epoch: 6| Step: 11
Training loss: 3.6599930082577488
Validation loss: 3.2233814776579623

Epoch: 6| Step: 12
Training loss: 3.876240070407799
Validation loss: 3.2202926269965064

Epoch: 6| Step: 13
Training loss: 3.4580755175965128
Validation loss: 3.2193346377684326

Epoch: 52| Step: 0
Training loss: 3.801582839980394
Validation loss: 3.220153144346662

Epoch: 6| Step: 1
Training loss: 3.665783703580721
Validation loss: 3.2195181076979527

Epoch: 6| Step: 2
Training loss: 3.7049557309202243
Validation loss: 3.219781715238961

Epoch: 6| Step: 3
Training loss: 4.225462595878695
Validation loss: 3.2199524336832543

Epoch: 6| Step: 4
Training loss: 2.737748337720865
Validation loss: 3.2191714018817628

Epoch: 6| Step: 5
Training loss: 2.9096061442631522
Validation loss: 3.2183979812430845

Epoch: 6| Step: 6
Training loss: 3.559858447057402
Validation loss: 3.2192554222414804

Epoch: 6| Step: 7
Training loss: 3.257146021595233
Validation loss: 3.220946218482659

Epoch: 6| Step: 8
Training loss: 4.085134277751558
Validation loss: 3.222217599915907

Epoch: 6| Step: 9
Training loss: 2.8575712257512844
Validation loss: 3.217790142926393

Epoch: 6| Step: 10
Training loss: 2.7738810439783785
Validation loss: 3.217195478958142

Epoch: 6| Step: 11
Training loss: 2.792315298612905
Validation loss: 3.2175275147919806

Epoch: 6| Step: 12
Training loss: 3.7885032005059913
Validation loss: 3.2170835889064002

Epoch: 6| Step: 13
Training loss: 4.23254580243694
Validation loss: 3.2168146374720963

Epoch: 53| Step: 0
Training loss: 3.7458524019620896
Validation loss: 3.2154897076917988

Epoch: 6| Step: 1
Training loss: 3.360847186050475
Validation loss: 3.2149009274370735

Epoch: 6| Step: 2
Training loss: 3.9004475948049007
Validation loss: 3.2140750699932576

Epoch: 6| Step: 3
Training loss: 3.2187027418500556
Validation loss: 3.2138848736333885

Epoch: 6| Step: 4
Training loss: 3.8756741583342103
Validation loss: 3.215257965577068

Epoch: 6| Step: 5
Training loss: 2.6492717857980588
Validation loss: 3.2127872523595817

Epoch: 6| Step: 6
Training loss: 3.6647148283671944
Validation loss: 3.2113662999081916

Epoch: 6| Step: 7
Training loss: 3.519748829203401
Validation loss: 3.2127600038788127

Epoch: 6| Step: 8
Training loss: 1.8642224507802287
Validation loss: 3.2122527767175004

Epoch: 6| Step: 9
Training loss: 3.6045566120038433
Validation loss: 3.2131393336853646

Epoch: 6| Step: 10
Training loss: 3.540824266366594
Validation loss: 3.213606250681892

Epoch: 6| Step: 11
Training loss: 3.5744000498331965
Validation loss: 3.212389415000968

Epoch: 6| Step: 12
Training loss: 3.3920791250213007
Validation loss: 3.211277417312911

Epoch: 6| Step: 13
Training loss: 4.473093336312281
Validation loss: 3.2164596371976875

Epoch: 54| Step: 0
Training loss: 3.488569121747757
Validation loss: 3.2123481381021524

Epoch: 6| Step: 1
Training loss: 2.9095661563540163
Validation loss: 3.211458749949939

Epoch: 6| Step: 2
Training loss: 4.058833418994247
Validation loss: 3.214307926258794

Epoch: 6| Step: 3
Training loss: 3.6864544954232343
Validation loss: 3.2189509146587723

Epoch: 6| Step: 4
Training loss: 3.2361825508523783
Validation loss: 3.217896331258318

Epoch: 6| Step: 5
Training loss: 3.291868919886965
Validation loss: 3.2179517224995706

Epoch: 6| Step: 6
Training loss: 3.593799623893121
Validation loss: 3.213376150241253

Epoch: 6| Step: 7
Training loss: 3.542344211768308
Validation loss: 3.212648358340234

Epoch: 6| Step: 8
Training loss: 3.3963613899168577
Validation loss: 3.210336200383156

Epoch: 6| Step: 9
Training loss: 4.51887010174667
Validation loss: 3.2100761169761665

Epoch: 6| Step: 10
Training loss: 2.953206379087054
Validation loss: 3.2081082481776915

Epoch: 6| Step: 11
Training loss: 3.399530344669842
Validation loss: 3.2076218264496914

Epoch: 6| Step: 12
Training loss: 3.145196879763743
Validation loss: 3.2085468688357315

Epoch: 6| Step: 13
Training loss: 2.504790770269231
Validation loss: 3.2065281023575123

Epoch: 55| Step: 0
Training loss: 2.875555565270816
Validation loss: 3.2086787320892665

Epoch: 6| Step: 1
Training loss: 3.692358404813868
Validation loss: 3.211446946572394

Epoch: 6| Step: 2
Training loss: 3.081122163979818
Validation loss: 3.212308159928056

Epoch: 6| Step: 3
Training loss: 3.0747119551557565
Validation loss: 3.212166530844679

Epoch: 6| Step: 4
Training loss: 3.376235876918886
Validation loss: 3.2105786399187743

Epoch: 6| Step: 5
Training loss: 3.386517687046346
Validation loss: 3.2084054756337177

Epoch: 6| Step: 6
Training loss: 2.965913401208268
Validation loss: 3.2057570805473112

Epoch: 6| Step: 7
Training loss: 3.957559985189985
Validation loss: 3.203597066465232

Epoch: 6| Step: 8
Training loss: 3.444313094666598
Validation loss: 3.2051308678867585

Epoch: 6| Step: 9
Training loss: 3.1719381391883874
Validation loss: 3.2026295956874837

Epoch: 6| Step: 10
Training loss: 3.6309938534133313
Validation loss: 3.20417972290378

Epoch: 6| Step: 11
Training loss: 3.8225233549573425
Validation loss: 3.204713570653781

Epoch: 6| Step: 12
Training loss: 4.229337842261407
Validation loss: 3.201907361304312

Epoch: 6| Step: 13
Training loss: 3.4286398710503914
Validation loss: 3.1985647983655965

Epoch: 56| Step: 0
Training loss: 3.236329303711312
Validation loss: 3.2019707217439395

Epoch: 6| Step: 1
Training loss: 2.9402590841200524
Validation loss: 3.20219944653399

Epoch: 6| Step: 2
Training loss: 3.9950936744984564
Validation loss: 3.201649248392094

Epoch: 6| Step: 3
Training loss: 4.271505808416733
Validation loss: 3.1977454815700854

Epoch: 6| Step: 4
Training loss: 3.5416412053408464
Validation loss: 3.195312148586903

Epoch: 6| Step: 5
Training loss: 2.7759389852365017
Validation loss: 3.193378870224887

Epoch: 6| Step: 6
Training loss: 3.5712184299225873
Validation loss: 3.1930012723709136

Epoch: 6| Step: 7
Training loss: 3.136993890193964
Validation loss: 3.1911978596409956

Epoch: 6| Step: 8
Training loss: 2.9584240071186545
Validation loss: 3.192382472007098

Epoch: 6| Step: 9
Training loss: 3.8133655253520935
Validation loss: 3.191272304176717

Epoch: 6| Step: 10
Training loss: 3.5962640344520262
Validation loss: 3.192844310018784

Epoch: 6| Step: 11
Training loss: 3.914239144669758
Validation loss: 3.1913419777210605

Epoch: 6| Step: 12
Training loss: 2.7742277497059917
Validation loss: 3.191323149658483

Epoch: 6| Step: 13
Training loss: 3.315999611591091
Validation loss: 3.1897083669619777

Epoch: 57| Step: 0
Training loss: 3.6810598223902344
Validation loss: 3.192096136742229

Epoch: 6| Step: 1
Training loss: 3.099048431539958
Validation loss: 3.193884712201919

Epoch: 6| Step: 2
Training loss: 3.894158776931939
Validation loss: 3.1953128080881625

Epoch: 6| Step: 3
Training loss: 3.1367597945438845
Validation loss: 3.188842085540503

Epoch: 6| Step: 4
Training loss: 2.8457138490703904
Validation loss: 3.1880878016694876

Epoch: 6| Step: 5
Training loss: 3.628760130602355
Validation loss: 3.1883246255727666

Epoch: 6| Step: 6
Training loss: 3.3265070317966825
Validation loss: 3.1875352578059992

Epoch: 6| Step: 7
Training loss: 3.361712826620101
Validation loss: 3.1863758647242113

Epoch: 6| Step: 8
Training loss: 2.7049636320817716
Validation loss: 3.185857632414298

Epoch: 6| Step: 9
Training loss: 3.4887148255529863
Validation loss: 3.1848631441356194

Epoch: 6| Step: 10
Training loss: 3.790615243419598
Validation loss: 3.185913883249578

Epoch: 6| Step: 11
Training loss: 3.6101324434368434
Validation loss: 3.1842662888807847

Epoch: 6| Step: 12
Training loss: 4.017081267511281
Validation loss: 3.1838005388809427

Epoch: 6| Step: 13
Training loss: 3.297626572407398
Validation loss: 3.18466060379725

Epoch: 58| Step: 0
Training loss: 3.326870534099453
Validation loss: 3.1820039684384116

Epoch: 6| Step: 1
Training loss: 3.4720742732423124
Validation loss: 3.182868813479629

Epoch: 6| Step: 2
Training loss: 3.1385105283863544
Validation loss: 3.18229741324448

Epoch: 6| Step: 3
Training loss: 3.7052495471348443
Validation loss: 3.1821978821242465

Epoch: 6| Step: 4
Training loss: 3.7494529325077304
Validation loss: 3.1824703245283597

Epoch: 6| Step: 5
Training loss: 3.2632880358982743
Validation loss: 3.1807546162082043

Epoch: 6| Step: 6
Training loss: 4.1400256604859855
Validation loss: 3.181751637534706

Epoch: 6| Step: 7
Training loss: 3.431046549006258
Validation loss: 3.179729402436388

Epoch: 6| Step: 8
Training loss: 3.5280746091448902
Validation loss: 3.1810046471199165

Epoch: 6| Step: 9
Training loss: 3.068624173010691
Validation loss: 3.1799106814362337

Epoch: 6| Step: 10
Training loss: 2.963453527300821
Validation loss: 3.180750112360614

Epoch: 6| Step: 11
Training loss: 3.0398230691920523
Validation loss: 3.1808492261610075

Epoch: 6| Step: 12
Training loss: 3.6877368915566167
Validation loss: 3.1813228203730337

Epoch: 6| Step: 13
Training loss: 3.4418663730516688
Validation loss: 3.180111800751674

Epoch: 59| Step: 0
Training loss: 4.364167453857335
Validation loss: 3.1791885450916664

Epoch: 6| Step: 1
Training loss: 3.6357855987621184
Validation loss: 3.1822843545341932

Epoch: 6| Step: 2
Training loss: 3.170622780451495
Validation loss: 3.179488629241532

Epoch: 6| Step: 3
Training loss: 3.4232691881459276
Validation loss: 3.180751440625563

Epoch: 6| Step: 4
Training loss: 3.4791640930775394
Validation loss: 3.1762584675902987

Epoch: 6| Step: 5
Training loss: 3.4983970513673994
Validation loss: 3.178790839996676

Epoch: 6| Step: 6
Training loss: 2.855872672301402
Validation loss: 3.1776578198544714

Epoch: 6| Step: 7
Training loss: 3.3387088029577043
Validation loss: 3.1774750923738693

Epoch: 6| Step: 8
Training loss: 3.6021452657752535
Validation loss: 3.177844179992222

Epoch: 6| Step: 9
Training loss: 3.5152119711806202
Validation loss: 3.176455342914839

Epoch: 6| Step: 10
Training loss: 4.319372257612106
Validation loss: 3.175460772822206

Epoch: 6| Step: 11
Training loss: 1.7905320707643153
Validation loss: 3.175973162388192

Epoch: 6| Step: 12
Training loss: 3.0018949881528934
Validation loss: 3.1760767282975912

Epoch: 6| Step: 13
Training loss: 3.306348739332254
Validation loss: 3.1765241308652947

Epoch: 60| Step: 0
Training loss: 3.6698593775861936
Validation loss: 3.1779713630071904

Epoch: 6| Step: 1
Training loss: 3.867158153692314
Validation loss: 3.177833894254738

Epoch: 6| Step: 2
Training loss: 2.4719899803069665
Validation loss: 3.177993334771764

Epoch: 6| Step: 3
Training loss: 3.4911038554382148
Validation loss: 3.180457932174303

Epoch: 6| Step: 4
Training loss: 3.7159554375480304
Validation loss: 3.1820206046455395

Epoch: 6| Step: 5
Training loss: 2.9325617411196165
Validation loss: 3.185830472265431

Epoch: 6| Step: 6
Training loss: 2.3299118455901793
Validation loss: 3.179027787149104

Epoch: 6| Step: 7
Training loss: 4.12412183257146
Validation loss: 3.1784110186732075

Epoch: 6| Step: 8
Training loss: 3.131782038825259
Validation loss: 3.177442177300729

Epoch: 6| Step: 9
Training loss: 3.593480771802183
Validation loss: 3.1735360587932484

Epoch: 6| Step: 10
Training loss: 3.563208526290744
Validation loss: 3.1727734286519396

Epoch: 6| Step: 11
Training loss: 3.2919801651274834
Validation loss: 3.173202997201361

Epoch: 6| Step: 12
Training loss: 3.5689742837900207
Validation loss: 3.1727742237361545

Epoch: 6| Step: 13
Training loss: 4.019135006131266
Validation loss: 3.1724241072279242

Epoch: 61| Step: 0
Training loss: 2.78337418950717
Validation loss: 3.1717736158136334

Epoch: 6| Step: 1
Training loss: 3.2829146749218725
Validation loss: 3.1730638813118226

Epoch: 6| Step: 2
Training loss: 3.676225917079662
Validation loss: 3.1742072945421445

Epoch: 6| Step: 3
Training loss: 3.7915565698310507
Validation loss: 3.172938507778192

Epoch: 6| Step: 4
Training loss: 4.023871478036162
Validation loss: 3.168970130555123

Epoch: 6| Step: 5
Training loss: 3.058153454499877
Validation loss: 3.170248571888976

Epoch: 6| Step: 6
Training loss: 3.663142822930403
Validation loss: 3.169902636649372

Epoch: 6| Step: 7
Training loss: 3.901364620814237
Validation loss: 3.1676285904017996

Epoch: 6| Step: 8
Training loss: 4.036879755806679
Validation loss: 3.173572210881565

Epoch: 6| Step: 9
Training loss: 3.1894779426277258
Validation loss: 3.170726132216271

Epoch: 6| Step: 10
Training loss: 2.6592619929077745
Validation loss: 3.171036466428095

Epoch: 6| Step: 11
Training loss: 3.3210531687674427
Validation loss: 3.1694927708987994

Epoch: 6| Step: 12
Training loss: 2.9222792075547366
Validation loss: 3.1686830226868663

Epoch: 6| Step: 13
Training loss: 3.233943154811514
Validation loss: 3.1687791532109957

Epoch: 62| Step: 0
Training loss: 2.8224649853895443
Validation loss: 3.1677158902645157

Epoch: 6| Step: 1
Training loss: 2.492543736172627
Validation loss: 3.1666220390357305

Epoch: 6| Step: 2
Training loss: 3.0259119598026247
Validation loss: 3.1695808905224516

Epoch: 6| Step: 3
Training loss: 3.438424696960438
Validation loss: 3.1708333501287167

Epoch: 6| Step: 4
Training loss: 3.879340786138485
Validation loss: 3.1719042016267327

Epoch: 6| Step: 5
Training loss: 3.1470700458286673
Validation loss: 3.1727569160652274

Epoch: 6| Step: 6
Training loss: 3.4949439177154296
Validation loss: 3.1699587096295567

Epoch: 6| Step: 7
Training loss: 3.6990358333620645
Validation loss: 3.1711474589045894

Epoch: 6| Step: 8
Training loss: 3.5685186575013934
Validation loss: 3.1746736912554696

Epoch: 6| Step: 9
Training loss: 3.204946604743644
Validation loss: 3.168204681021946

Epoch: 6| Step: 10
Training loss: 3.964202919270941
Validation loss: 3.169085641409629

Epoch: 6| Step: 11
Training loss: 4.222752008049298
Validation loss: 3.1691212788149636

Epoch: 6| Step: 12
Training loss: 3.14081204744614
Validation loss: 3.1679596695275998

Epoch: 6| Step: 13
Training loss: 3.450950524788226
Validation loss: 3.167144275219384

Epoch: 63| Step: 0
Training loss: 3.1003467858065075
Validation loss: 3.16735539990983

Epoch: 6| Step: 1
Training loss: 3.6744470556610223
Validation loss: 3.167387704305876

Epoch: 6| Step: 2
Training loss: 3.9767326513434655
Validation loss: 3.168427617823257

Epoch: 6| Step: 3
Training loss: 2.909167722208106
Validation loss: 3.1668986433602386

Epoch: 6| Step: 4
Training loss: 3.2975071305551427
Validation loss: 3.165195826750249

Epoch: 6| Step: 5
Training loss: 3.1965722023614087
Validation loss: 3.166892531543078

Epoch: 6| Step: 6
Training loss: 3.6422965342313804
Validation loss: 3.1645682824566963

Epoch: 6| Step: 7
Training loss: 3.7124940197829046
Validation loss: 3.165386399905341

Epoch: 6| Step: 8
Training loss: 3.5860184803713633
Validation loss: 3.1666321992752424

Epoch: 6| Step: 9
Training loss: 3.433268630396456
Validation loss: 3.1655914902526834

Epoch: 6| Step: 10
Training loss: 3.5516588660347987
Validation loss: 3.1655775301018383

Epoch: 6| Step: 11
Training loss: 3.2560828577882086
Validation loss: 3.1642140998208172

Epoch: 6| Step: 12
Training loss: 3.2731318729453034
Validation loss: 3.1626622293738045

Epoch: 6| Step: 13
Training loss: 2.886466999974772
Validation loss: 3.1609662149642586

Epoch: 64| Step: 0
Training loss: 3.672729003289516
Validation loss: 3.163566832696052

Epoch: 6| Step: 1
Training loss: 3.9784620503342376
Validation loss: 3.1620531133709773

Epoch: 6| Step: 2
Training loss: 3.175165433403428
Validation loss: 3.161211884458656

Epoch: 6| Step: 3
Training loss: 3.8393191719498345
Validation loss: 3.1609119841204065

Epoch: 6| Step: 4
Training loss: 3.4132213123635644
Validation loss: 3.162107975666773

Epoch: 6| Step: 5
Training loss: 3.6759553355262873
Validation loss: 3.160250452863566

Epoch: 6| Step: 6
Training loss: 2.9728110394674254
Validation loss: 3.163181918799811

Epoch: 6| Step: 7
Training loss: 3.4409428781403797
Validation loss: 3.162768110863714

Epoch: 6| Step: 8
Training loss: 2.170628910604876
Validation loss: 3.1647864936021977

Epoch: 6| Step: 9
Training loss: 3.9255621246370267
Validation loss: 3.1605885343345577

Epoch: 6| Step: 10
Training loss: 3.5624856781253373
Validation loss: 3.1624285154391387

Epoch: 6| Step: 11
Training loss: 3.2457511711903
Validation loss: 3.1625300970708032

Epoch: 6| Step: 12
Training loss: 3.2141524877640153
Validation loss: 3.1603245191140648

Epoch: 6| Step: 13
Training loss: 2.9792929313596557
Validation loss: 3.1608821253719683

Epoch: 65| Step: 0
Training loss: 3.571211753803312
Validation loss: 3.1633653163063533

Epoch: 6| Step: 1
Training loss: 3.6442916807732644
Validation loss: 3.1602158884519236

Epoch: 6| Step: 2
Training loss: 3.5379527796326853
Validation loss: 3.160711915792125

Epoch: 6| Step: 3
Training loss: 2.6192791679544536
Validation loss: 3.1608020297009074

Epoch: 6| Step: 4
Training loss: 2.9479858246543995
Validation loss: 3.1587054004868698

Epoch: 6| Step: 5
Training loss: 3.820027783477566
Validation loss: 3.1581024562385913

Epoch: 6| Step: 6
Training loss: 3.5352665836546024
Validation loss: 3.158764172764114

Epoch: 6| Step: 7
Training loss: 3.4361441972915046
Validation loss: 3.1592098487917637

Epoch: 6| Step: 8
Training loss: 3.17479537544774
Validation loss: 3.157101315223064

Epoch: 6| Step: 9
Training loss: 2.8651767925152827
Validation loss: 3.161952902845644

Epoch: 6| Step: 10
Training loss: 3.5618750040697242
Validation loss: 3.161366227301618

Epoch: 6| Step: 11
Training loss: 3.5080721276935836
Validation loss: 3.1591020002359342

Epoch: 6| Step: 12
Training loss: 3.969766201370363
Validation loss: 3.1575856744797584

Epoch: 6| Step: 13
Training loss: 3.363460735356685
Validation loss: 3.1583302977865526

Epoch: 66| Step: 0
Training loss: 3.514374506334857
Validation loss: 3.1592714932009107

Epoch: 6| Step: 1
Training loss: 3.359743036026333
Validation loss: 3.1575524635767183

Epoch: 6| Step: 2
Training loss: 3.9977480986843914
Validation loss: 3.154437392318541

Epoch: 6| Step: 3
Training loss: 3.2123423378102287
Validation loss: 3.1560737205686444

Epoch: 6| Step: 4
Training loss: 3.9315778004326063
Validation loss: 3.156675895028327

Epoch: 6| Step: 5
Training loss: 3.251484165228765
Validation loss: 3.155677991311439

Epoch: 6| Step: 6
Training loss: 3.3050343577204897
Validation loss: 3.1532846981428335

Epoch: 6| Step: 7
Training loss: 3.130388268468425
Validation loss: 3.155998860848437

Epoch: 6| Step: 8
Training loss: 3.661145706540711
Validation loss: 3.1543776779368082

Epoch: 6| Step: 9
Training loss: 3.5844452190089573
Validation loss: 3.1550463713903847

Epoch: 6| Step: 10
Training loss: 2.40456836943222
Validation loss: 3.1544648568973894

Epoch: 6| Step: 11
Training loss: 3.5772645407123975
Validation loss: 3.155956690450097

Epoch: 6| Step: 12
Training loss: 3.763188503802185
Validation loss: 3.157906609961579

Epoch: 6| Step: 13
Training loss: 2.076724735119646
Validation loss: 3.157766914362364

Epoch: 67| Step: 0
Training loss: 3.1487023784069597
Validation loss: 3.156332340829484

Epoch: 6| Step: 1
Training loss: 3.577636152298389
Validation loss: 3.153749327149754

Epoch: 6| Step: 2
Training loss: 3.3883739681281027
Validation loss: 3.1624863519503377

Epoch: 6| Step: 3
Training loss: 2.1825695604423316
Validation loss: 3.160321658837876

Epoch: 6| Step: 4
Training loss: 4.514423989425321
Validation loss: 3.1766532430660126

Epoch: 6| Step: 5
Training loss: 3.5525495534577627
Validation loss: 3.1697370516375294

Epoch: 6| Step: 6
Training loss: 3.4669700385890447
Validation loss: 3.1561258397819754

Epoch: 6| Step: 7
Training loss: 2.7097196014442027
Validation loss: 3.1537478289993546

Epoch: 6| Step: 8
Training loss: 3.5419190859133454
Validation loss: 3.152333545334103

Epoch: 6| Step: 9
Training loss: 2.6695830570381758
Validation loss: 3.151375570617561

Epoch: 6| Step: 10
Training loss: 3.5747728929208797
Validation loss: 3.1524309543052698

Epoch: 6| Step: 11
Training loss: 3.5798263835897837
Validation loss: 3.1540826962816553

Epoch: 6| Step: 12
Training loss: 3.7508635480322434
Validation loss: 3.153967141540029

Epoch: 6| Step: 13
Training loss: 3.6022321033074247
Validation loss: 3.15272693130146

Epoch: 68| Step: 0
Training loss: 3.2647965397905008
Validation loss: 3.151014510162877

Epoch: 6| Step: 1
Training loss: 3.379082083123656
Validation loss: 3.1518295622411374

Epoch: 6| Step: 2
Training loss: 3.498242618232135
Validation loss: 3.1526400612653736

Epoch: 6| Step: 3
Training loss: 4.388683609380173
Validation loss: 3.1547070962527357

Epoch: 6| Step: 4
Training loss: 3.6210581953654972
Validation loss: 3.151454525393549

Epoch: 6| Step: 5
Training loss: 3.3616549539685088
Validation loss: 3.151385787333985

Epoch: 6| Step: 6
Training loss: 3.3045069868418233
Validation loss: 3.1486812110353695

Epoch: 6| Step: 7
Training loss: 4.039591358026669
Validation loss: 3.1501657590470575

Epoch: 6| Step: 8
Training loss: 2.5539592673235707
Validation loss: 3.1521367566762595

Epoch: 6| Step: 9
Training loss: 3.6844477548445047
Validation loss: 3.1541243179054756

Epoch: 6| Step: 10
Training loss: 3.0298535778056825
Validation loss: 3.1559658517599494

Epoch: 6| Step: 11
Training loss: 2.8857235154324004
Validation loss: 3.1574603034194446

Epoch: 6| Step: 12
Training loss: 3.205718985860831
Validation loss: 3.1585689900494023

Epoch: 6| Step: 13
Training loss: 2.7862124801033117
Validation loss: 3.1539483260838823

Epoch: 69| Step: 0
Training loss: 2.9211971700296036
Validation loss: 3.155890260004132

Epoch: 6| Step: 1
Training loss: 3.6907315076532554
Validation loss: 3.1565397006362628

Epoch: 6| Step: 2
Training loss: 3.6707057958148472
Validation loss: 3.1503996788057402

Epoch: 6| Step: 3
Training loss: 3.321315048551311
Validation loss: 3.149525654990611

Epoch: 6| Step: 4
Training loss: 3.3609121664840207
Validation loss: 3.1433729250395652

Epoch: 6| Step: 5
Training loss: 3.1421225853601995
Validation loss: 3.1464772816609363

Epoch: 6| Step: 6
Training loss: 3.9978288480182433
Validation loss: 3.141848919153059

Epoch: 6| Step: 7
Training loss: 4.007805361378876
Validation loss: 3.144489139414279

Epoch: 6| Step: 8
Training loss: 2.6196294068178694
Validation loss: 3.1447586204624742

Epoch: 6| Step: 9
Training loss: 3.2424222194780916
Validation loss: 3.1428133305991857

Epoch: 6| Step: 10
Training loss: 2.5563388352009295
Validation loss: 3.1450757874329907

Epoch: 6| Step: 11
Training loss: 3.4430389168628674
Validation loss: 3.1445686005381903

Epoch: 6| Step: 12
Training loss: 3.4177250192117272
Validation loss: 3.144774747732885

Epoch: 6| Step: 13
Training loss: 4.257933896635225
Validation loss: 3.1433531180443035

Epoch: 70| Step: 0
Training loss: 3.277744273285689
Validation loss: 3.142942290896594

Epoch: 6| Step: 1
Training loss: 3.723954733822379
Validation loss: 3.1440546309322763

Epoch: 6| Step: 2
Training loss: 2.834119650243181
Validation loss: 3.1445610528531174

Epoch: 6| Step: 3
Training loss: 3.989515870057595
Validation loss: 3.1424856472422644

Epoch: 6| Step: 4
Training loss: 3.652902358476608
Validation loss: 3.143127998197265

Epoch: 6| Step: 5
Training loss: 2.6826190538819956
Validation loss: 3.1419588816486783

Epoch: 6| Step: 6
Training loss: 3.240834001884545
Validation loss: 3.1424867714148337

Epoch: 6| Step: 7
Training loss: 3.2094140812798195
Validation loss: 3.1410651337571402

Epoch: 6| Step: 8
Training loss: 3.0475051619475835
Validation loss: 3.1411763707532105

Epoch: 6| Step: 9
Training loss: 4.10872189513628
Validation loss: 3.141820912640977

Epoch: 6| Step: 10
Training loss: 3.6100377386767595
Validation loss: 3.141078101842881

Epoch: 6| Step: 11
Training loss: 4.0285881776471175
Validation loss: 3.141279271301755

Epoch: 6| Step: 12
Training loss: 3.0857310551989996
Validation loss: 3.137904147347562

Epoch: 6| Step: 13
Training loss: 1.9740175894211571
Validation loss: 3.139442725371698

Epoch: 71| Step: 0
Training loss: 3.05957701408658
Validation loss: 3.14032512554109

Epoch: 6| Step: 1
Training loss: 3.205133915333674
Validation loss: 3.1405812207736123

Epoch: 6| Step: 2
Training loss: 2.9490467147671477
Validation loss: 3.1432009345652605

Epoch: 6| Step: 3
Training loss: 3.1306674681905644
Validation loss: 3.1429896115008056

Epoch: 6| Step: 4
Training loss: 4.329137580389586
Validation loss: 3.138956285264292

Epoch: 6| Step: 5
Training loss: 3.885891528254533
Validation loss: 3.1400117560619156

Epoch: 6| Step: 6
Training loss: 2.968352763051509
Validation loss: 3.1390208885898327

Epoch: 6| Step: 7
Training loss: 2.7504377883618685
Validation loss: 3.139506648280021

Epoch: 6| Step: 8
Training loss: 3.358449409189013
Validation loss: 3.137342028172238

Epoch: 6| Step: 9
Training loss: 3.5141476388050825
Validation loss: 3.139350958801702

Epoch: 6| Step: 10
Training loss: 3.130774389149885
Validation loss: 3.1384226571060414

Epoch: 6| Step: 11
Training loss: 3.523120535996069
Validation loss: 3.138210442074316

Epoch: 6| Step: 12
Training loss: 3.1764101576406953
Validation loss: 3.1377347052967486

Epoch: 6| Step: 13
Training loss: 4.708647568380731
Validation loss: 3.1413865492307247

Epoch: 72| Step: 0
Training loss: 2.9694778353276106
Validation loss: 3.140324461022731

Epoch: 6| Step: 1
Training loss: 3.124423317151231
Validation loss: 3.1404908572536456

Epoch: 6| Step: 2
Training loss: 4.387847347584363
Validation loss: 3.1357699449929357

Epoch: 6| Step: 3
Training loss: 3.556073197459996
Validation loss: 3.136355324617609

Epoch: 6| Step: 4
Training loss: 2.974891974787944
Validation loss: 3.1370870544876044

Epoch: 6| Step: 5
Training loss: 3.292169910704377
Validation loss: 3.137762137960688

Epoch: 6| Step: 6
Training loss: 3.299760324270815
Validation loss: 3.137269480208879

Epoch: 6| Step: 7
Training loss: 3.8501377526942693
Validation loss: 3.1400194453127273

Epoch: 6| Step: 8
Training loss: 3.0477642620066825
Validation loss: 3.1410870837350666

Epoch: 6| Step: 9
Training loss: 2.9958040776281085
Validation loss: 3.1397324989086317

Epoch: 6| Step: 10
Training loss: 2.6489732588631156
Validation loss: 3.140561833708371

Epoch: 6| Step: 11
Training loss: 3.172604932560225
Validation loss: 3.1421074904592095

Epoch: 6| Step: 12
Training loss: 4.246300377332161
Validation loss: 3.140206285543999

Epoch: 6| Step: 13
Training loss: 3.6353417564624233
Validation loss: 3.141994015701262

Epoch: 73| Step: 0
Training loss: 3.73618212273546
Validation loss: 3.1384129708078947

Epoch: 6| Step: 1
Training loss: 3.6699793041175814
Validation loss: 3.1360218449449215

Epoch: 6| Step: 2
Training loss: 3.153583571147269
Validation loss: 3.1361223159303533

Epoch: 6| Step: 3
Training loss: 3.824383709693912
Validation loss: 3.136066551885846

Epoch: 6| Step: 4
Training loss: 4.249294222403269
Validation loss: 3.1335007290535155

Epoch: 6| Step: 5
Training loss: 3.3616373650240416
Validation loss: 3.1359625458928737

Epoch: 6| Step: 6
Training loss: 2.6522077432855258
Validation loss: 3.134094646934797

Epoch: 6| Step: 7
Training loss: 3.2271175322784065
Validation loss: 3.1342217542304143

Epoch: 6| Step: 8
Training loss: 2.9505768939239676
Validation loss: 3.1354589157247843

Epoch: 6| Step: 9
Training loss: 2.481955927977786
Validation loss: 3.1345867649927435

Epoch: 6| Step: 10
Training loss: 2.719479167103072
Validation loss: 3.1345389822088183

Epoch: 6| Step: 11
Training loss: 3.7408430834228374
Validation loss: 3.1349503430622323

Epoch: 6| Step: 12
Training loss: 3.8872592569366464
Validation loss: 3.1341964499880626

Epoch: 6| Step: 13
Training loss: 3.3479308613300387
Validation loss: 3.1332552841439307

Epoch: 74| Step: 0
Training loss: 3.4127071667062903
Validation loss: 3.129545085458089

Epoch: 6| Step: 1
Training loss: 2.2460774031334494
Validation loss: 3.1314657677528097

Epoch: 6| Step: 2
Training loss: 3.3626807692481875
Validation loss: 3.131237759540741

Epoch: 6| Step: 3
Training loss: 3.4313112903116947
Validation loss: 3.131694378234618

Epoch: 6| Step: 4
Training loss: 3.2462826523517574
Validation loss: 3.1315346106891964

Epoch: 6| Step: 5
Training loss: 3.1745356783427856
Validation loss: 3.1300999231555755

Epoch: 6| Step: 6
Training loss: 3.5192843910548164
Validation loss: 3.129018795909282

Epoch: 6| Step: 7
Training loss: 3.1022547182417224
Validation loss: 3.1298913637376264

Epoch: 6| Step: 8
Training loss: 3.3602427226906553
Validation loss: 3.1302288044444784

Epoch: 6| Step: 9
Training loss: 3.855381432252739
Validation loss: 3.1327114081242335

Epoch: 6| Step: 10
Training loss: 3.834110236567585
Validation loss: 3.130052653395349

Epoch: 6| Step: 11
Training loss: 3.118361173254367
Validation loss: 3.1321625725699005

Epoch: 6| Step: 12
Training loss: 3.9287115443620584
Validation loss: 3.1318110028067956

Epoch: 6| Step: 13
Training loss: 3.7261184651763717
Validation loss: 3.1304347256853458

Epoch: 75| Step: 0
Training loss: 3.1034876616306297
Validation loss: 3.130639563096149

Epoch: 6| Step: 1
Training loss: 3.4265734323169768
Validation loss: 3.1305516518653005

Epoch: 6| Step: 2
Training loss: 3.0304057725192783
Validation loss: 3.1304631133196037

Epoch: 6| Step: 3
Training loss: 2.6257939727393254
Validation loss: 3.1302391532437337

Epoch: 6| Step: 4
Training loss: 3.293502601438346
Validation loss: 3.130281156601527

Epoch: 6| Step: 5
Training loss: 4.030703721995309
Validation loss: 3.131371041157683

Epoch: 6| Step: 6
Training loss: 2.5616099975247884
Validation loss: 3.1325104151757066

Epoch: 6| Step: 7
Training loss: 3.3392329142616686
Validation loss: 3.1323661929205247

Epoch: 6| Step: 8
Training loss: 3.589664558529283
Validation loss: 3.1359207101940365

Epoch: 6| Step: 9
Training loss: 3.797590023578456
Validation loss: 3.132819887777075

Epoch: 6| Step: 10
Training loss: 3.8741169815558982
Validation loss: 3.1329148856075864

Epoch: 6| Step: 11
Training loss: 3.859107992843326
Validation loss: 3.131791612202664

Epoch: 6| Step: 12
Training loss: 3.117775615387168
Validation loss: 3.1319783449200833

Epoch: 6| Step: 13
Training loss: 3.4606394757847663
Validation loss: 3.130769392511451

Testing loss: 3.3153830211952613
