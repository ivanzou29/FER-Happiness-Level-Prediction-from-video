Epoch: 1| Step: 0
Training loss: 5.160751504806287
Validation loss: 5.7744987500742715

Epoch: 5| Step: 1
Training loss: 5.429762849353526
Validation loss: 5.770474091720757

Epoch: 5| Step: 2
Training loss: 6.492183680711121
Validation loss: 5.76647207024386

Epoch: 5| Step: 3
Training loss: 6.112984530039476
Validation loss: 5.762905844370538

Epoch: 5| Step: 4
Training loss: 4.65399955283287
Validation loss: 5.759044950375399

Epoch: 5| Step: 5
Training loss: 6.020214995033465
Validation loss: 5.755400651591513

Epoch: 5| Step: 6
Training loss: 5.699585200157764
Validation loss: 5.7518345464094915

Epoch: 5| Step: 7
Training loss: 5.35741546663853
Validation loss: 5.748086476276769

Epoch: 5| Step: 8
Training loss: 6.342269649570359
Validation loss: 5.744861077307966

Epoch: 5| Step: 9
Training loss: 6.424205496383629
Validation loss: 5.741221224720012

Epoch: 5| Step: 10
Training loss: 5.720041264738612
Validation loss: 5.7381164392638295

Epoch: 2| Step: 0
Training loss: 6.340629524240623
Validation loss: 5.734660220629981

Epoch: 5| Step: 1
Training loss: 6.453292290317969
Validation loss: 5.731083038600244

Epoch: 5| Step: 2
Training loss: 6.359341108152163
Validation loss: 5.727572663656778

Epoch: 5| Step: 3
Training loss: 4.871443404777199
Validation loss: 5.7239806257198245

Epoch: 5| Step: 4
Training loss: 5.9583268954724655
Validation loss: 5.720194524263658

Epoch: 5| Step: 5
Training loss: 6.546987455217058
Validation loss: 5.716440931675722

Epoch: 5| Step: 6
Training loss: 4.130511214642458
Validation loss: 5.712165662863163

Epoch: 5| Step: 7
Training loss: 4.747435429572369
Validation loss: 5.707878880936043

Epoch: 5| Step: 8
Training loss: 5.88243055180232
Validation loss: 5.703672580163226

Epoch: 5| Step: 9
Training loss: 5.1941766630203325
Validation loss: 5.698860085705611

Epoch: 5| Step: 10
Training loss: 6.290736384383986
Validation loss: 5.694103577252204

Epoch: 3| Step: 0
Training loss: 6.715414381385612
Validation loss: 5.689172687422097

Epoch: 5| Step: 1
Training loss: 5.826635748274162
Validation loss: 5.683025761558328

Epoch: 5| Step: 2
Training loss: 5.587131954078948
Validation loss: 5.677657723550097

Epoch: 5| Step: 3
Training loss: 5.427089678955273
Validation loss: 5.671180730743554

Epoch: 5| Step: 4
Training loss: 5.313452063126987
Validation loss: 5.664566745172652

Epoch: 5| Step: 5
Training loss: 5.783557987888388
Validation loss: 5.657701355848604

Epoch: 5| Step: 6
Training loss: 5.787382595115524
Validation loss: 5.6497520769169896

Epoch: 5| Step: 7
Training loss: 5.803411782552664
Validation loss: 5.641730240161175

Epoch: 5| Step: 8
Training loss: 5.370498546566406
Validation loss: 5.633611987152083

Epoch: 5| Step: 9
Training loss: 4.949394481884091
Validation loss: 5.624838775912966

Epoch: 5| Step: 10
Training loss: 5.936398695149563
Validation loss: 5.615057564639777

Epoch: 4| Step: 0
Training loss: 5.303544338463555
Validation loss: 5.605386829524373

Epoch: 5| Step: 1
Training loss: 5.651427684438378
Validation loss: 5.594371063407996

Epoch: 5| Step: 2
Training loss: 5.727006798717686
Validation loss: 5.584432337958388

Epoch: 5| Step: 3
Training loss: 6.029060875685749
Validation loss: 5.572376383353779

Epoch: 5| Step: 4
Training loss: 5.834195572842732
Validation loss: 5.559594064847686

Epoch: 5| Step: 5
Training loss: 5.789137290234664
Validation loss: 5.546929414659314

Epoch: 5| Step: 6
Training loss: 4.8580491198227245
Validation loss: 5.5327026302529765

Epoch: 5| Step: 7
Training loss: 5.312602322658897
Validation loss: 5.517867103361232

Epoch: 5| Step: 8
Training loss: 4.84262780756911
Validation loss: 5.504085403156358

Epoch: 5| Step: 9
Training loss: 6.436569887392135
Validation loss: 5.488408983023113

Epoch: 5| Step: 10
Training loss: 5.394202949539017
Validation loss: 5.471742454096579

Epoch: 5| Step: 0
Training loss: 6.2371630254628725
Validation loss: 5.455001345109695

Epoch: 5| Step: 1
Training loss: 3.807093304199397
Validation loss: 5.437664408090637

Epoch: 5| Step: 2
Training loss: 5.900712904451607
Validation loss: 5.419656415293868

Epoch: 5| Step: 3
Training loss: 5.05142205488824
Validation loss: 5.402316949682516

Epoch: 5| Step: 4
Training loss: 5.064384015689768
Validation loss: 5.383668697701203

Epoch: 5| Step: 5
Training loss: 6.637444953187318
Validation loss: 5.3636937354106715

Epoch: 5| Step: 6
Training loss: 5.003322451124529
Validation loss: 5.344789438573399

Epoch: 5| Step: 7
Training loss: 5.4891517464679325
Validation loss: 5.3246409172891624

Epoch: 5| Step: 8
Training loss: 4.63481500842844
Validation loss: 5.3051633744474405

Epoch: 5| Step: 9
Training loss: 5.955348122876482
Validation loss: 5.285411022914594

Epoch: 5| Step: 10
Training loss: 5.071553741077069
Validation loss: 5.265272481496344

Epoch: 6| Step: 0
Training loss: 5.872562633324929
Validation loss: 5.244549411766988

Epoch: 5| Step: 1
Training loss: 4.852205243127659
Validation loss: 5.223299019256071

Epoch: 5| Step: 2
Training loss: 4.899430705105529
Validation loss: 5.203004185685165

Epoch: 5| Step: 3
Training loss: 5.186013801659322
Validation loss: 5.182612700919226

Epoch: 5| Step: 4
Training loss: 5.28181951036647
Validation loss: 5.16088052098206

Epoch: 5| Step: 5
Training loss: 6.42977056067249
Validation loss: 5.140274639840414

Epoch: 5| Step: 6
Training loss: 4.6668760161898755
Validation loss: 5.1186703768169295

Epoch: 5| Step: 7
Training loss: 4.966440491785567
Validation loss: 5.099118612873872

Epoch: 5| Step: 8
Training loss: 4.637646679473633
Validation loss: 5.078354957491692

Epoch: 5| Step: 9
Training loss: 4.446117147284575
Validation loss: 5.0581147345024915

Epoch: 5| Step: 10
Training loss: 5.683938724496256
Validation loss: 5.03690756587428

Epoch: 7| Step: 0
Training loss: 5.008937096448871
Validation loss: 5.015940431414403

Epoch: 5| Step: 1
Training loss: 4.343741657056961
Validation loss: 4.995510456573201

Epoch: 5| Step: 2
Training loss: 3.9890968019450326
Validation loss: 4.974816605383643

Epoch: 5| Step: 3
Training loss: 5.179901440835296
Validation loss: 4.955110442295997

Epoch: 5| Step: 4
Training loss: 4.469530370905896
Validation loss: 4.933359260596268

Epoch: 5| Step: 5
Training loss: 5.494910920161292
Validation loss: 4.911883544819243

Epoch: 5| Step: 6
Training loss: 4.622269726676221
Validation loss: 4.890717116948936

Epoch: 5| Step: 7
Training loss: 5.628522321114762
Validation loss: 4.869224280056525

Epoch: 5| Step: 8
Training loss: 5.191735985519195
Validation loss: 4.846924511160531

Epoch: 5| Step: 9
Training loss: 4.940611426318522
Validation loss: 4.823021407890221

Epoch: 5| Step: 10
Training loss: 5.675271102546763
Validation loss: 4.800491282998937

Epoch: 8| Step: 0
Training loss: 5.497264355114701
Validation loss: 4.776748894541444

Epoch: 5| Step: 1
Training loss: 4.8578145259976875
Validation loss: 4.753306946981449

Epoch: 5| Step: 2
Training loss: 5.400025240521251
Validation loss: 4.730190864227208

Epoch: 5| Step: 3
Training loss: 4.521917585213262
Validation loss: 4.7071548730935735

Epoch: 5| Step: 4
Training loss: 5.70062217662981
Validation loss: 4.685743506791452

Epoch: 5| Step: 5
Training loss: 4.136735118224817
Validation loss: 4.6611649139097

Epoch: 5| Step: 6
Training loss: 4.940583437238701
Validation loss: 4.636936592912949

Epoch: 5| Step: 7
Training loss: 3.444647969279761
Validation loss: 4.613261412267329

Epoch: 5| Step: 8
Training loss: 4.028709853324683
Validation loss: 4.588519509122444

Epoch: 5| Step: 9
Training loss: 4.202025315743635
Validation loss: 4.565909116273994

Epoch: 5| Step: 10
Training loss: 5.089088225775474
Validation loss: 4.543304646225786

Epoch: 9| Step: 0
Training loss: 4.024646644008746
Validation loss: 4.519449943935467

Epoch: 5| Step: 1
Training loss: 4.595277285838172
Validation loss: 4.50029166448855

Epoch: 5| Step: 2
Training loss: 4.274556294219456
Validation loss: 4.475234875244268

Epoch: 5| Step: 3
Training loss: 4.6909415263424945
Validation loss: 4.4582645632147715

Epoch: 5| Step: 4
Training loss: 4.347119019691353
Validation loss: 4.435743858794619

Epoch: 5| Step: 5
Training loss: 4.134199115359522
Validation loss: 4.420813321392292

Epoch: 5| Step: 6
Training loss: 4.98485196979475
Validation loss: 4.402164920481994

Epoch: 5| Step: 7
Training loss: 4.664624562094773
Validation loss: 4.382239692789849

Epoch: 5| Step: 8
Training loss: 4.13635955490231
Validation loss: 4.367937343749931

Epoch: 5| Step: 9
Training loss: 5.282600546158439
Validation loss: 4.352133759389596

Epoch: 5| Step: 10
Training loss: 4.47582170838048
Validation loss: 4.3376298473205095

Epoch: 10| Step: 0
Training loss: 4.298092867182127
Validation loss: 4.31936696814457

Epoch: 5| Step: 1
Training loss: 4.726203942688651
Validation loss: 4.303958332370132

Epoch: 5| Step: 2
Training loss: 5.086581562941851
Validation loss: 4.288788254418824

Epoch: 5| Step: 3
Training loss: 4.587519150363958
Validation loss: 4.274738962824492

Epoch: 5| Step: 4
Training loss: 4.759271106850907
Validation loss: 4.262531384595609

Epoch: 5| Step: 5
Training loss: 4.469565790580025
Validation loss: 4.248873805718836

Epoch: 5| Step: 6
Training loss: 3.177796347400084
Validation loss: 4.234125503608069

Epoch: 5| Step: 7
Training loss: 4.71674450831438
Validation loss: 4.2204313269313545

Epoch: 5| Step: 8
Training loss: 4.136615467313111
Validation loss: 4.211482003299043

Epoch: 5| Step: 9
Training loss: 3.509699732226132
Validation loss: 4.19781044454356

Epoch: 5| Step: 10
Training loss: 4.266619108848963
Validation loss: 4.18544933104807

Epoch: 11| Step: 0
Training loss: 4.235251698406192
Validation loss: 4.177565075846923

Epoch: 5| Step: 1
Training loss: 3.416589705057884
Validation loss: 4.166800039474316

Epoch: 5| Step: 2
Training loss: 4.058477904912516
Validation loss: 4.156163717677788

Epoch: 5| Step: 3
Training loss: 4.977425157644379
Validation loss: 4.147097122830282

Epoch: 5| Step: 4
Training loss: 3.9881320368757462
Validation loss: 4.134723406329054

Epoch: 5| Step: 5
Training loss: 4.285480942504509
Validation loss: 4.126511688024579

Epoch: 5| Step: 6
Training loss: 4.35206368263718
Validation loss: 4.116610846693816

Epoch: 5| Step: 7
Training loss: 3.8308760742122265
Validation loss: 4.1063330898724075

Epoch: 5| Step: 8
Training loss: 3.7269109087245194
Validation loss: 4.0963621869392774

Epoch: 5| Step: 9
Training loss: 5.043264697999393
Validation loss: 4.087287296047947

Epoch: 5| Step: 10
Training loss: 4.722086352219987
Validation loss: 4.078119011645395

Epoch: 12| Step: 0
Training loss: 3.5397924213649223
Validation loss: 4.069621462855938

Epoch: 5| Step: 1
Training loss: 4.89758118075843
Validation loss: 4.059851375726526

Epoch: 5| Step: 2
Training loss: 4.5972689689930695
Validation loss: 4.048948723903544

Epoch: 5| Step: 3
Training loss: 5.042840531992214
Validation loss: 4.042232081033144

Epoch: 5| Step: 4
Training loss: 4.271906772096322
Validation loss: 4.032767763471464

Epoch: 5| Step: 5
Training loss: 4.488978133452778
Validation loss: 4.025041186086888

Epoch: 5| Step: 6
Training loss: 3.6424428960739617
Validation loss: 4.016591128193562

Epoch: 5| Step: 7
Training loss: 3.2066392926206273
Validation loss: 4.00667438691908

Epoch: 5| Step: 8
Training loss: 4.668766888813893
Validation loss: 4.0012024910105115

Epoch: 5| Step: 9
Training loss: 3.3415243281794957
Validation loss: 3.992316290411866

Epoch: 5| Step: 10
Training loss: 3.5877401769967565
Validation loss: 3.9870367763426255

Epoch: 13| Step: 0
Training loss: 3.8164578515335053
Validation loss: 3.9784434625107044

Epoch: 5| Step: 1
Training loss: 4.926742423631814
Validation loss: 3.970692715995046

Epoch: 5| Step: 2
Training loss: 4.486503919811656
Validation loss: 3.9640747999329746

Epoch: 5| Step: 3
Training loss: 3.462802771816354
Validation loss: 3.9583465930002055

Epoch: 5| Step: 4
Training loss: 4.297209903496909
Validation loss: 3.950172370606635

Epoch: 5| Step: 5
Training loss: 4.905020201288556
Validation loss: 3.9424898830460386

Epoch: 5| Step: 6
Training loss: 3.4649282485997217
Validation loss: 3.938351113532249

Epoch: 5| Step: 7
Training loss: 2.8082224211784013
Validation loss: 3.9325684296074273

Epoch: 5| Step: 8
Training loss: 4.419202448492456
Validation loss: 3.9256402641917414

Epoch: 5| Step: 9
Training loss: 4.460882771117871
Validation loss: 3.92060656287609

Epoch: 5| Step: 10
Training loss: 3.374196133424073
Validation loss: 3.9153755213725967

Epoch: 14| Step: 0
Training loss: 3.719807834994258
Validation loss: 3.9085670119715523

Epoch: 5| Step: 1
Training loss: 4.150906907227121
Validation loss: 3.904094102755357

Epoch: 5| Step: 2
Training loss: 4.440442036799685
Validation loss: 3.896780459016548

Epoch: 5| Step: 3
Training loss: 3.9974630178299906
Validation loss: 3.892683277825897

Epoch: 5| Step: 4
Training loss: 4.873077796119333
Validation loss: 3.8860657855259313

Epoch: 5| Step: 5
Training loss: 4.273644813655685
Validation loss: 3.88286253236918

Epoch: 5| Step: 6
Training loss: 3.5048545141132603
Validation loss: 3.877073431210932

Epoch: 5| Step: 7
Training loss: 4.12012864513843
Validation loss: 3.874355904369032

Epoch: 5| Step: 8
Training loss: 4.090427826980847
Validation loss: 3.8691714113001465

Epoch: 5| Step: 9
Training loss: 3.0049185169616663
Validation loss: 3.8633408785456678

Epoch: 5| Step: 10
Training loss: 4.040559413817215
Validation loss: 3.861441952306854

Epoch: 15| Step: 0
Training loss: 4.184946220900117
Validation loss: 3.85405085998576

Epoch: 5| Step: 1
Training loss: 3.425480167116017
Validation loss: 3.851515821780468

Epoch: 5| Step: 2
Training loss: 4.642517320542079
Validation loss: 3.847877877090962

Epoch: 5| Step: 3
Training loss: 4.232432690629928
Validation loss: 3.8412740626413266

Epoch: 5| Step: 4
Training loss: 4.146040459192097
Validation loss: 3.8363377958490834

Epoch: 5| Step: 5
Training loss: 3.080924063693014
Validation loss: 3.833673421068558

Epoch: 5| Step: 6
Training loss: 3.6362219121798245
Validation loss: 3.828796771108468

Epoch: 5| Step: 7
Training loss: 3.6426286545590463
Validation loss: 3.826087201339279

Epoch: 5| Step: 8
Training loss: 4.6678083703489595
Validation loss: 3.8221081358204776

Epoch: 5| Step: 9
Training loss: 3.3928010347932775
Validation loss: 3.8174105777984213

Epoch: 5| Step: 10
Training loss: 4.686080717751897
Validation loss: 3.8161632059799557

Epoch: 16| Step: 0
Training loss: 3.9396272998106783
Validation loss: 3.8124072787990664

Epoch: 5| Step: 1
Training loss: 3.7397577923358774
Validation loss: 3.8060517579045947

Epoch: 5| Step: 2
Training loss: 3.181102990611502
Validation loss: 3.8063766430135164

Epoch: 5| Step: 3
Training loss: 3.4700349369543937
Validation loss: 3.800101106050981

Epoch: 5| Step: 4
Training loss: 3.86428557668665
Validation loss: 3.794646431781715

Epoch: 5| Step: 5
Training loss: 3.3527791409268928
Validation loss: 3.7916531112376304

Epoch: 5| Step: 6
Training loss: 4.480930826693088
Validation loss: 3.786124981000228

Epoch: 5| Step: 7
Training loss: 4.850154457385666
Validation loss: 3.781340984842093

Epoch: 5| Step: 8
Training loss: 3.688162016845247
Validation loss: 3.7796439958104617

Epoch: 5| Step: 9
Training loss: 4.36006667689864
Validation loss: 3.775958717235667

Epoch: 5| Step: 10
Training loss: 4.390098241519252
Validation loss: 3.7719611316598702

Epoch: 17| Step: 0
Training loss: 3.6821594358422223
Validation loss: 3.7655637818915126

Epoch: 5| Step: 1
Training loss: 3.223547166150584
Validation loss: 3.765849035358341

Epoch: 5| Step: 2
Training loss: 3.7342322414037477
Validation loss: 3.7606327550533103

Epoch: 5| Step: 3
Training loss: 3.9831464481539474
Validation loss: 3.7574791557348393

Epoch: 5| Step: 4
Training loss: 2.826827621046053
Validation loss: 3.755634634509331

Epoch: 5| Step: 5
Training loss: 4.174274340399886
Validation loss: 3.7516055235345185

Epoch: 5| Step: 6
Training loss: 3.7416539458898996
Validation loss: 3.750939342476876

Epoch: 5| Step: 7
Training loss: 5.163472428998185
Validation loss: 3.7431405927532175

Epoch: 5| Step: 8
Training loss: 3.965140435905472
Validation loss: 3.745141465604837

Epoch: 5| Step: 9
Training loss: 4.305086259321096
Validation loss: 3.749509031361912

Epoch: 5| Step: 10
Training loss: 3.989719172755598
Validation loss: 3.7449152474238354

Epoch: 18| Step: 0
Training loss: 3.9959126093017545
Validation loss: 3.7418171439059553

Epoch: 5| Step: 1
Training loss: 3.934445361901234
Validation loss: 3.7358517933748976

Epoch: 5| Step: 2
Training loss: 4.321653961465041
Validation loss: 3.7311337873450765

Epoch: 5| Step: 3
Training loss: 3.6074411735576106
Validation loss: 3.7259901061240623

Epoch: 5| Step: 4
Training loss: 4.559767440420375
Validation loss: 3.7185656545888945

Epoch: 5| Step: 5
Training loss: 3.177244255284642
Validation loss: 3.716416069561244

Epoch: 5| Step: 6
Training loss: 4.1239821594325985
Validation loss: 3.713796093984033

Epoch: 5| Step: 7
Training loss: 3.4683234150084954
Validation loss: 3.7110173291189037

Epoch: 5| Step: 8
Training loss: 3.8063875821809385
Validation loss: 3.705114509068764

Epoch: 5| Step: 9
Training loss: 4.217646249565581
Validation loss: 3.702792361319668

Epoch: 5| Step: 10
Training loss: 3.4146085603599423
Validation loss: 3.700507894520808

Epoch: 19| Step: 0
Training loss: 4.657596265501349
Validation loss: 3.697258954598773

Epoch: 5| Step: 1
Training loss: 4.0478677010760915
Validation loss: 3.693173256865667

Epoch: 5| Step: 2
Training loss: 3.2464189607513054
Validation loss: 3.6899824718196093

Epoch: 5| Step: 3
Training loss: 3.7397579198406987
Validation loss: 3.6870229338428433

Epoch: 5| Step: 4
Training loss: 3.1646523008350638
Validation loss: 3.6826566963798926

Epoch: 5| Step: 5
Training loss: 4.316535278048892
Validation loss: 3.6801250605089586

Epoch: 5| Step: 6
Training loss: 3.982605664706738
Validation loss: 3.677194961702876

Epoch: 5| Step: 7
Training loss: 3.9620196126484206
Validation loss: 3.673436570304057

Epoch: 5| Step: 8
Training loss: 4.285500970708826
Validation loss: 3.6706509999174193

Epoch: 5| Step: 9
Training loss: 3.0991210552844843
Validation loss: 3.6670623371908104

Epoch: 5| Step: 10
Training loss: 3.711901473275152
Validation loss: 3.668245550801978

Epoch: 20| Step: 0
Training loss: 4.752094409377277
Validation loss: 3.6686681200624967

Epoch: 5| Step: 1
Training loss: 3.1830600408175944
Validation loss: 3.6590981795743187

Epoch: 5| Step: 2
Training loss: 2.885234032828938
Validation loss: 3.6580474420761653

Epoch: 5| Step: 3
Training loss: 3.3311404326493426
Validation loss: 3.6566076251907775

Epoch: 5| Step: 4
Training loss: 3.7944953902625356
Validation loss: 3.656011912507807

Epoch: 5| Step: 5
Training loss: 4.09849960041591
Validation loss: 3.652406660135552

Epoch: 5| Step: 6
Training loss: 3.263026321459288
Validation loss: 3.6500408864256313

Epoch: 5| Step: 7
Training loss: 4.1378108988236555
Validation loss: 3.6440824114836388

Epoch: 5| Step: 8
Training loss: 3.9744086587449137
Validation loss: 3.6427933584888534

Epoch: 5| Step: 9
Training loss: 4.623554106824678
Validation loss: 3.638865847622793

Epoch: 5| Step: 10
Training loss: 3.7403955170900813
Validation loss: 3.635612142403477

Epoch: 21| Step: 0
Training loss: 3.853344240162163
Validation loss: 3.6372458883923793

Epoch: 5| Step: 1
Training loss: 3.6996422981357635
Validation loss: 3.6281076843640476

Epoch: 5| Step: 2
Training loss: 3.676432277255438
Validation loss: 3.627553040075762

Epoch: 5| Step: 3
Training loss: 4.273376575991109
Validation loss: 3.6261658312547222

Epoch: 5| Step: 4
Training loss: 4.000405529446286
Validation loss: 3.6220428121858728

Epoch: 5| Step: 5
Training loss: 3.1767479057638335
Validation loss: 3.6200318823437962

Epoch: 5| Step: 6
Training loss: 3.436046778670215
Validation loss: 3.6152838798553195

Epoch: 5| Step: 7
Training loss: 3.5232610214256983
Validation loss: 3.6147173401913397

Epoch: 5| Step: 8
Training loss: 3.331162476955451
Validation loss: 3.609717178976179

Epoch: 5| Step: 9
Training loss: 4.776205356112713
Validation loss: 3.6078522148556553

Epoch: 5| Step: 10
Training loss: 3.978876605954268
Validation loss: 3.604245077533668

Epoch: 22| Step: 0
Training loss: 3.134266047614108
Validation loss: 3.6015333753230396

Epoch: 5| Step: 1
Training loss: 4.1651683147808205
Validation loss: 3.5958479084426793

Epoch: 5| Step: 2
Training loss: 3.594512062543877
Validation loss: 3.5926831160285824

Epoch: 5| Step: 3
Training loss: 3.6894025905171355
Validation loss: 3.592198033656753

Epoch: 5| Step: 4
Training loss: 3.7023578605696894
Validation loss: 3.58787908110163

Epoch: 5| Step: 5
Training loss: 3.9274073027823637
Validation loss: 3.5852550329276287

Epoch: 5| Step: 6
Training loss: 4.192488247167393
Validation loss: 3.5831448595332853

Epoch: 5| Step: 7
Training loss: 3.1148640858005754
Validation loss: 3.5797663036168377

Epoch: 5| Step: 8
Training loss: 4.111671879186111
Validation loss: 3.5790307961527086

Epoch: 5| Step: 9
Training loss: 4.166947444356398
Validation loss: 3.574144749620926

Epoch: 5| Step: 10
Training loss: 3.604140147440521
Validation loss: 3.5686431132010803

Epoch: 23| Step: 0
Training loss: 3.7749922493356123
Validation loss: 3.5673791589656445

Epoch: 5| Step: 1
Training loss: 3.4929737682302218
Validation loss: 3.5650688211641595

Epoch: 5| Step: 2
Training loss: 3.8807736115177525
Validation loss: 3.562640007648633

Epoch: 5| Step: 3
Training loss: 4.003493214214277
Validation loss: 3.5560729653240792

Epoch: 5| Step: 4
Training loss: 3.6481610669249585
Validation loss: 3.5553174902662135

Epoch: 5| Step: 5
Training loss: 3.5626761409648773
Validation loss: 3.5518213630842377

Epoch: 5| Step: 6
Training loss: 3.1489567860860217
Validation loss: 3.5493297928119967

Epoch: 5| Step: 7
Training loss: 4.339491039264674
Validation loss: 3.544348253244494

Epoch: 5| Step: 8
Training loss: 3.5547965567491326
Validation loss: 3.5400197470042194

Epoch: 5| Step: 9
Training loss: 3.5314433627231083
Validation loss: 3.5375659696598674

Epoch: 5| Step: 10
Training loss: 4.297866762321168
Validation loss: 3.5426689674428355

Epoch: 24| Step: 0
Training loss: 3.906813680033022
Validation loss: 3.532481029877495

Epoch: 5| Step: 1
Training loss: 3.280482756513695
Validation loss: 3.532230413518488

Epoch: 5| Step: 2
Training loss: 3.2410023189113835
Validation loss: 3.5292915462099983

Epoch: 5| Step: 3
Training loss: 4.398585152730955
Validation loss: 3.5255172110921515

Epoch: 5| Step: 4
Training loss: 3.1517707086419717
Validation loss: 3.525431509027726

Epoch: 5| Step: 5
Training loss: 3.663629372054609
Validation loss: 3.5231153870565968

Epoch: 5| Step: 6
Training loss: 3.739825879291959
Validation loss: 3.5186272981839277

Epoch: 5| Step: 7
Training loss: 3.4273195194999135
Validation loss: 3.517949847223785

Epoch: 5| Step: 8
Training loss: 4.439151295489169
Validation loss: 3.515116908685541

Epoch: 5| Step: 9
Training loss: 4.323927624007628
Validation loss: 3.510525341195164

Epoch: 5| Step: 10
Training loss: 2.997636817946692
Validation loss: 3.5098530024177603

Epoch: 25| Step: 0
Training loss: 4.619723841682864
Validation loss: 3.505858003184916

Epoch: 5| Step: 1
Training loss: 4.204145683384916
Validation loss: 3.5020876926555715

Epoch: 5| Step: 2
Training loss: 2.932038119496349
Validation loss: 3.5014419881302357

Epoch: 5| Step: 3
Training loss: 3.870994220150865
Validation loss: 3.497887587728603

Epoch: 5| Step: 4
Training loss: 2.906958052819065
Validation loss: 3.4956721093926704

Epoch: 5| Step: 5
Training loss: 3.6526839643517777
Validation loss: 3.4972710349589415

Epoch: 5| Step: 6
Training loss: 2.6106935927074364
Validation loss: 3.4931977058806063

Epoch: 5| Step: 7
Training loss: 3.5732328462231
Validation loss: 3.4936662209732665

Epoch: 5| Step: 8
Training loss: 4.251153677141056
Validation loss: 3.4931581854065934

Epoch: 5| Step: 9
Training loss: 3.8860363231773465
Validation loss: 3.486152537282138

Epoch: 5| Step: 10
Training loss: 3.7670629771097195
Validation loss: 3.4847384284946337

Epoch: 26| Step: 0
Training loss: 4.237390999531452
Validation loss: 3.4827075163119194

Epoch: 5| Step: 1
Training loss: 3.9233051747165324
Validation loss: 3.4804013641427574

Epoch: 5| Step: 2
Training loss: 4.0510675224302375
Validation loss: 3.476806965337677

Epoch: 5| Step: 3
Training loss: 3.7182048750682037
Validation loss: 3.479028680010478

Epoch: 5| Step: 4
Training loss: 3.7257437456338676
Validation loss: 3.475054403230212

Epoch: 5| Step: 5
Training loss: 3.0451517562758674
Validation loss: 3.4736834556587732

Epoch: 5| Step: 6
Training loss: 3.9228744145307757
Validation loss: 3.470461584887803

Epoch: 5| Step: 7
Training loss: 3.408183257911293
Validation loss: 3.4686285513344353

Epoch: 5| Step: 8
Training loss: 2.6708882612351843
Validation loss: 3.4680523520479025

Epoch: 5| Step: 9
Training loss: 3.7728078881599463
Validation loss: 3.4655315201518095

Epoch: 5| Step: 10
Training loss: 3.8587681837676033
Validation loss: 3.462028571249422

Epoch: 27| Step: 0
Training loss: 3.5304868430484184
Validation loss: 3.4596595879871206

Epoch: 5| Step: 1
Training loss: 3.876401217210307
Validation loss: 3.4572512276310614

Epoch: 5| Step: 2
Training loss: 4.032687381900759
Validation loss: 3.4552455818784935

Epoch: 5| Step: 3
Training loss: 3.5998345654940564
Validation loss: 3.4536054881332303

Epoch: 5| Step: 4
Training loss: 3.9585538836154934
Validation loss: 3.4524968610290103

Epoch: 5| Step: 5
Training loss: 3.7314243550674226
Validation loss: 3.4499735340317765

Epoch: 5| Step: 6
Training loss: 3.3123088277676964
Validation loss: 3.4482267189731974

Epoch: 5| Step: 7
Training loss: 3.2684060260392687
Validation loss: 3.4466474681909918

Epoch: 5| Step: 8
Training loss: 3.862214931597728
Validation loss: 3.4452238324701048

Epoch: 5| Step: 9
Training loss: 3.612058888467535
Validation loss: 3.4418622168405224

Epoch: 5| Step: 10
Training loss: 3.4804654619092212
Validation loss: 3.44131405873474

Epoch: 28| Step: 0
Training loss: 3.740834160663946
Validation loss: 3.437087811977153

Epoch: 5| Step: 1
Training loss: 2.3983469396138513
Validation loss: 3.43477699814167

Epoch: 5| Step: 2
Training loss: 3.936470987192439
Validation loss: 3.4355918532806187

Epoch: 5| Step: 3
Training loss: 4.306145893493936
Validation loss: 3.4332624506560165

Epoch: 5| Step: 4
Training loss: 3.7248529955639875
Validation loss: 3.43505756047476

Epoch: 5| Step: 5
Training loss: 3.728085764369122
Validation loss: 3.429460710725463

Epoch: 5| Step: 6
Training loss: 2.704769450179717
Validation loss: 3.425259848063172

Epoch: 5| Step: 7
Training loss: 3.8353055911303806
Validation loss: 3.4254175641053486

Epoch: 5| Step: 8
Training loss: 3.511650313918812
Validation loss: 3.422595284079549

Epoch: 5| Step: 9
Training loss: 3.841748965051417
Validation loss: 3.4214897798627066

Epoch: 5| Step: 10
Training loss: 4.061638843522999
Validation loss: 3.420154534032696

Epoch: 29| Step: 0
Training loss: 3.19333219837442
Validation loss: 3.4171097080762403

Epoch: 5| Step: 1
Training loss: 2.8821372298342562
Validation loss: 3.4158525484924263

Epoch: 5| Step: 2
Training loss: 3.661268393020039
Validation loss: 3.4137939128210495

Epoch: 5| Step: 3
Training loss: 3.8826930067990677
Validation loss: 3.4103959618139115

Epoch: 5| Step: 4
Training loss: 3.522637591520917
Validation loss: 3.4074316098662627

Epoch: 5| Step: 5
Training loss: 4.239734143973212
Validation loss: 3.4083360145819657

Epoch: 5| Step: 6
Training loss: 3.5264334449258645
Validation loss: 3.4037939909156414

Epoch: 5| Step: 7
Training loss: 4.13424917247289
Validation loss: 3.40421189259686

Epoch: 5| Step: 8
Training loss: 3.789188091910195
Validation loss: 3.400256191424261

Epoch: 5| Step: 9
Training loss: 3.3173110859831225
Validation loss: 3.397660586262912

Epoch: 5| Step: 10
Training loss: 3.5975744712390374
Validation loss: 3.392452256664918

Epoch: 30| Step: 0
Training loss: 3.869080236388275
Validation loss: 3.391266718754441

Epoch: 5| Step: 1
Training loss: 4.195061077632644
Validation loss: 3.387780896890632

Epoch: 5| Step: 2
Training loss: 3.1966166551302266
Validation loss: 3.3861727830779755

Epoch: 5| Step: 3
Training loss: 3.7550503101864363
Validation loss: 3.3828503176679625

Epoch: 5| Step: 4
Training loss: 3.6477919340276963
Validation loss: 3.3819087970669144

Epoch: 5| Step: 5
Training loss: 3.3969490387120094
Validation loss: 3.3795673740971344

Epoch: 5| Step: 6
Training loss: 3.7019521409150453
Validation loss: 3.376719882382449

Epoch: 5| Step: 7
Training loss: 4.148757261319887
Validation loss: 3.373909826217813

Epoch: 5| Step: 8
Training loss: 2.9713996707642627
Validation loss: 3.3682464760878124

Epoch: 5| Step: 9
Training loss: 3.516624206961597
Validation loss: 3.3670577892293143

Epoch: 5| Step: 10
Training loss: 2.952204808167976
Validation loss: 3.3652996577091674

Epoch: 31| Step: 0
Training loss: 4.415154084122983
Validation loss: 3.367098572020694

Epoch: 5| Step: 1
Training loss: 4.195417747385026
Validation loss: 3.363110978695228

Epoch: 5| Step: 2
Training loss: 2.9871803399974017
Validation loss: 3.35973550169536

Epoch: 5| Step: 3
Training loss: 3.7358566600903216
Validation loss: 3.359386547666879

Epoch: 5| Step: 4
Training loss: 3.2152538385637497
Validation loss: 3.36003307737407

Epoch: 5| Step: 5
Training loss: 3.8963037434635566
Validation loss: 3.3589394365489014

Epoch: 5| Step: 6
Training loss: 3.5843272198499845
Validation loss: 3.356050036841224

Epoch: 5| Step: 7
Training loss: 2.9188533397081784
Validation loss: 3.355303997562214

Epoch: 5| Step: 8
Training loss: 3.6505263432418396
Validation loss: 3.353882829512088

Epoch: 5| Step: 9
Training loss: 3.6188436387354748
Validation loss: 3.349040125914946

Epoch: 5| Step: 10
Training loss: 2.80154310688853
Validation loss: 3.345543933047467

Epoch: 32| Step: 0
Training loss: 3.2924991150596314
Validation loss: 3.3441762053585204

Epoch: 5| Step: 1
Training loss: 4.10706615494845
Validation loss: 3.3413564744305506

Epoch: 5| Step: 2
Training loss: 3.524975088045005
Validation loss: 3.339832865513728

Epoch: 5| Step: 3
Training loss: 3.6943871789252976
Validation loss: 3.3384018177408343

Epoch: 5| Step: 4
Training loss: 3.3808547206694564
Validation loss: 3.336015978997134

Epoch: 5| Step: 5
Training loss: 3.7531061659569844
Validation loss: 3.3363815180803913

Epoch: 5| Step: 6
Training loss: 3.705593011016382
Validation loss: 3.332531727008214

Epoch: 5| Step: 7
Training loss: 3.014626609493376
Validation loss: 3.3317598679757867

Epoch: 5| Step: 8
Training loss: 3.9239495250554772
Validation loss: 3.3303808924178573

Epoch: 5| Step: 9
Training loss: 3.547352897277042
Validation loss: 3.329024131079278

Epoch: 5| Step: 10
Training loss: 3.113358289658085
Validation loss: 3.3252648089528605

Epoch: 33| Step: 0
Training loss: 3.611176804817152
Validation loss: 3.324241821167357

Epoch: 5| Step: 1
Training loss: 3.343057721213943
Validation loss: 3.325202568903629

Epoch: 5| Step: 2
Training loss: 3.4534996140213208
Validation loss: 3.3224868308674638

Epoch: 5| Step: 3
Training loss: 3.6492602709182504
Validation loss: 3.319931089052029

Epoch: 5| Step: 4
Training loss: 3.740480037420245
Validation loss: 3.3196138368571293

Epoch: 5| Step: 5
Training loss: 3.8589249939283152
Validation loss: 3.317517009425394

Epoch: 5| Step: 6
Training loss: 3.454943700130197
Validation loss: 3.3165175162970586

Epoch: 5| Step: 7
Training loss: 3.435817098481278
Validation loss: 3.314704532925884

Epoch: 5| Step: 8
Training loss: 3.034962376670857
Validation loss: 3.3128367520037605

Epoch: 5| Step: 9
Training loss: 3.3416571796945305
Validation loss: 3.3120252826708136

Epoch: 5| Step: 10
Training loss: 4.186808970355353
Validation loss: 3.3118685853667724

Epoch: 34| Step: 0
Training loss: 2.5974192575750226
Validation loss: 3.3097512528168282

Epoch: 5| Step: 1
Training loss: 4.460595005870459
Validation loss: 3.309145959303383

Epoch: 5| Step: 2
Training loss: 4.0517341574463135
Validation loss: 3.306548603285053

Epoch: 5| Step: 3
Training loss: 2.8459460823061202
Validation loss: 3.3036431759652833

Epoch: 5| Step: 4
Training loss: 3.5302002283211324
Validation loss: 3.304059769225762

Epoch: 5| Step: 5
Training loss: 3.50871581275302
Validation loss: 3.301974935716971

Epoch: 5| Step: 6
Training loss: 3.8833013645105967
Validation loss: 3.303143295284142

Epoch: 5| Step: 7
Training loss: 3.5064640299432894
Validation loss: 3.298842338800911

Epoch: 5| Step: 8
Training loss: 3.3345424048775807
Validation loss: 3.298667185374597

Epoch: 5| Step: 9
Training loss: 3.8016997400763106
Validation loss: 3.2964772910516364

Epoch: 5| Step: 10
Training loss: 2.9670104702673816
Validation loss: 3.295875839976296

Epoch: 35| Step: 0
Training loss: 3.8934313599338823
Validation loss: 3.295853898793052

Epoch: 5| Step: 1
Training loss: 4.019248900584973
Validation loss: 3.293581495333257

Epoch: 5| Step: 2
Training loss: 3.6063895160522663
Validation loss: 3.2946937669246927

Epoch: 5| Step: 3
Training loss: 3.4123975242347306
Validation loss: 3.292458837808435

Epoch: 5| Step: 4
Training loss: 3.1453163446364045
Validation loss: 3.2903780462519068

Epoch: 5| Step: 5
Training loss: 3.079355681265671
Validation loss: 3.2893543678517894

Epoch: 5| Step: 6
Training loss: 4.142663763259085
Validation loss: 3.2896890012157125

Epoch: 5| Step: 7
Training loss: 2.5734890958689522
Validation loss: 3.2899565771130863

Epoch: 5| Step: 8
Training loss: 3.0609650171044915
Validation loss: 3.2885231614668564

Epoch: 5| Step: 9
Training loss: 4.04466629141831
Validation loss: 3.2848942331126048

Epoch: 5| Step: 10
Training loss: 3.562859098840553
Validation loss: 3.2833934496301436

Epoch: 36| Step: 0
Training loss: 3.840920500099675
Validation loss: 3.2801027940146383

Epoch: 5| Step: 1
Training loss: 3.0361263732743713
Validation loss: 3.280219928652432

Epoch: 5| Step: 2
Training loss: 3.4788531011723007
Validation loss: 3.282724383447528

Epoch: 5| Step: 3
Training loss: 3.9283658605520166
Validation loss: 3.282053053132077

Epoch: 5| Step: 4
Training loss: 3.44614765312744
Validation loss: 3.278832950449194

Epoch: 5| Step: 5
Training loss: 2.8651534929151468
Validation loss: 3.2765270332499186

Epoch: 5| Step: 6
Training loss: 4.1356106319469035
Validation loss: 3.275400663865029

Epoch: 5| Step: 7
Training loss: 3.602377180855638
Validation loss: 3.275860202119083

Epoch: 5| Step: 8
Training loss: 3.2079217489882503
Validation loss: 3.2725534853105414

Epoch: 5| Step: 9
Training loss: 3.407885237682292
Validation loss: 3.2716722375997644

Epoch: 5| Step: 10
Training loss: 3.62094231117056
Validation loss: 3.2728924910525836

Epoch: 37| Step: 0
Training loss: 2.3962234068953534
Validation loss: 3.2686300549144613

Epoch: 5| Step: 1
Training loss: 3.6823591183856323
Validation loss: 3.2686428753275836

Epoch: 5| Step: 2
Training loss: 4.045925662358619
Validation loss: 3.26985235469406

Epoch: 5| Step: 3
Training loss: 4.088519766520101
Validation loss: 3.2681672800981154

Epoch: 5| Step: 4
Training loss: 3.309500289721029
Validation loss: 3.2638986260251355

Epoch: 5| Step: 5
Training loss: 2.9884036369443545
Validation loss: 3.2652699989542597

Epoch: 5| Step: 6
Training loss: 3.433606387517628
Validation loss: 3.2631642951923805

Epoch: 5| Step: 7
Training loss: 3.157548391857808
Validation loss: 3.264269890355289

Epoch: 5| Step: 8
Training loss: 3.2037278515202328
Validation loss: 3.2621733392587595

Epoch: 5| Step: 9
Training loss: 3.2788069576620082
Validation loss: 3.2633417642437488

Epoch: 5| Step: 10
Training loss: 4.726251160006821
Validation loss: 3.261086117475133

Epoch: 38| Step: 0
Training loss: 3.6078679625294474
Validation loss: 3.2594193644082177

Epoch: 5| Step: 1
Training loss: 3.9363698397068347
Validation loss: 3.256201778430588

Epoch: 5| Step: 2
Training loss: 3.5178280857537607
Validation loss: 3.254743999350989

Epoch: 5| Step: 3
Training loss: 3.93676169603485
Validation loss: 3.253636170299098

Epoch: 5| Step: 4
Training loss: 2.91772312831067
Validation loss: 3.2547800725300813

Epoch: 5| Step: 5
Training loss: 3.4046695787536745
Validation loss: 3.2537899053900725

Epoch: 5| Step: 6
Training loss: 3.5560698451851938
Validation loss: 3.2550736715048014

Epoch: 5| Step: 7
Training loss: 3.327578647523833
Validation loss: 3.2507378251030983

Epoch: 5| Step: 8
Training loss: 3.7814037197172823
Validation loss: 3.2516389142611732

Epoch: 5| Step: 9
Training loss: 2.771005515195988
Validation loss: 3.251766409492084

Epoch: 5| Step: 10
Training loss: 3.624818731577069
Validation loss: 3.250632474583172

Epoch: 39| Step: 0
Training loss: 3.374442866929356
Validation loss: 3.248727483867814

Epoch: 5| Step: 1
Training loss: 3.8093796765218166
Validation loss: 3.249159638808588

Epoch: 5| Step: 2
Training loss: 2.7783631333200565
Validation loss: 3.2473798796618456

Epoch: 5| Step: 3
Training loss: 3.3598981583011223
Validation loss: 3.2454609027767707

Epoch: 5| Step: 4
Training loss: 3.779224326055921
Validation loss: 3.2468302172052588

Epoch: 5| Step: 5
Training loss: 3.0808539517116587
Validation loss: 3.2442369376814484

Epoch: 5| Step: 6
Training loss: 3.0562217352248577
Validation loss: 3.2449525766797334

Epoch: 5| Step: 7
Training loss: 3.4099016127278343
Validation loss: 3.243821479907134

Epoch: 5| Step: 8
Training loss: 3.9084801983165174
Validation loss: 3.2447110707955744

Epoch: 5| Step: 9
Training loss: 3.8952303061017126
Validation loss: 3.243824016817156

Epoch: 5| Step: 10
Training loss: 3.849119204547694
Validation loss: 3.242895642389192

Epoch: 40| Step: 0
Training loss: 3.5058112266018235
Validation loss: 3.242534022636494

Epoch: 5| Step: 1
Training loss: 3.7650701976782353
Validation loss: 3.2400740664711294

Epoch: 5| Step: 2
Training loss: 3.3947138589044425
Validation loss: 3.2469106667794003

Epoch: 5| Step: 3
Training loss: 3.020609792572012
Validation loss: 3.2392851277447114

Epoch: 5| Step: 4
Training loss: 2.0698809479833526
Validation loss: 3.2406291831784757

Epoch: 5| Step: 5
Training loss: 3.5611343443204078
Validation loss: 3.243886969485329

Epoch: 5| Step: 6
Training loss: 3.2078010480837045
Validation loss: 3.2409285096363307

Epoch: 5| Step: 7
Training loss: 3.667257969312872
Validation loss: 3.237659519497448

Epoch: 5| Step: 8
Training loss: 3.8238626222713474
Validation loss: 3.2345306737894566

Epoch: 5| Step: 9
Training loss: 4.019378926140741
Validation loss: 3.235696882427228

Epoch: 5| Step: 10
Training loss: 3.9979211650516286
Validation loss: 3.234770689753823

Epoch: 41| Step: 0
Training loss: 3.90321561831856
Validation loss: 3.2339123729965986

Epoch: 5| Step: 1
Training loss: 3.8101686947939832
Validation loss: 3.232479680524107

Epoch: 5| Step: 2
Training loss: 3.463223565583077
Validation loss: 3.2327398314495164

Epoch: 5| Step: 3
Training loss: 2.614614833525514
Validation loss: 3.2304322577365086

Epoch: 5| Step: 4
Training loss: 4.092681512366913
Validation loss: 3.231885122370039

Epoch: 5| Step: 5
Training loss: 2.7728923423000187
Validation loss: 3.2315872096719716

Epoch: 5| Step: 6
Training loss: 3.7062159004379627
Validation loss: 3.2294409236822426

Epoch: 5| Step: 7
Training loss: 2.9722723694212316
Validation loss: 3.2356519413096687

Epoch: 5| Step: 8
Training loss: 3.710449829181832
Validation loss: 3.251593085744147

Epoch: 5| Step: 9
Training loss: 3.256506934984561
Validation loss: 3.231456520813489

Epoch: 5| Step: 10
Training loss: 3.7410514875232344
Validation loss: 3.224399656848423

Epoch: 42| Step: 0
Training loss: 3.3045583568977968
Validation loss: 3.2283548695572604

Epoch: 5| Step: 1
Training loss: 3.3916128099619147
Validation loss: 3.2264810695024866

Epoch: 5| Step: 2
Training loss: 3.857126051750105
Validation loss: 3.2284765680445235

Epoch: 5| Step: 3
Training loss: 3.6804777620999167
Validation loss: 3.2261730116826093

Epoch: 5| Step: 4
Training loss: 3.5924895356622506
Validation loss: 3.227271286637669

Epoch: 5| Step: 5
Training loss: 3.208108439964778
Validation loss: 3.226008826491111

Epoch: 5| Step: 6
Training loss: 3.53350528502565
Validation loss: 3.2252501123093595

Epoch: 5| Step: 7
Training loss: 3.9136164671865696
Validation loss: 3.2249009558122523

Epoch: 5| Step: 8
Training loss: 3.123064586214632
Validation loss: 3.2246046414258607

Epoch: 5| Step: 9
Training loss: 3.567864110659736
Validation loss: 3.2231415990620667

Epoch: 5| Step: 10
Training loss: 2.9059774619670486
Validation loss: 3.2232680119996946

Epoch: 43| Step: 0
Training loss: 2.963732685889644
Validation loss: 3.2206898112792897

Epoch: 5| Step: 1
Training loss: 3.6156183056452043
Validation loss: 3.2198230624528965

Epoch: 5| Step: 2
Training loss: 3.58546128778142
Validation loss: 3.222642035877133

Epoch: 5| Step: 3
Training loss: 3.866232274308072
Validation loss: 3.2230116001975553

Epoch: 5| Step: 4
Training loss: 2.9679066313377964
Validation loss: 3.2179396864100034

Epoch: 5| Step: 5
Training loss: 2.8252167475098537
Validation loss: 3.216022974186596

Epoch: 5| Step: 6
Training loss: 3.9633519264685533
Validation loss: 3.2172554465736845

Epoch: 5| Step: 7
Training loss: 3.270086280081124
Validation loss: 3.21676102619446

Epoch: 5| Step: 8
Training loss: 3.7313660825630675
Validation loss: 3.216776290397238

Epoch: 5| Step: 9
Training loss: 3.6692057545803833
Validation loss: 3.2191505680673065

Epoch: 5| Step: 10
Training loss: 3.5672992703826596
Validation loss: 3.219343605982014

Epoch: 44| Step: 0
Training loss: 3.60268531889173
Validation loss: 3.21801520439945

Epoch: 5| Step: 1
Training loss: 4.191370755033769
Validation loss: 3.2165695213590753

Epoch: 5| Step: 2
Training loss: 3.643610438296335
Validation loss: 3.215783175684715

Epoch: 5| Step: 3
Training loss: 2.994223437374025
Validation loss: 3.2149123800267665

Epoch: 5| Step: 4
Training loss: 3.320195310431912
Validation loss: 3.2129817369861695

Epoch: 5| Step: 5
Training loss: 2.988294334632301
Validation loss: 3.2109762497370573

Epoch: 5| Step: 6
Training loss: 4.132531659512135
Validation loss: 3.208726344004344

Epoch: 5| Step: 7
Training loss: 2.9256401078898193
Validation loss: 3.2071628734148576

Epoch: 5| Step: 8
Training loss: 3.686389173879555
Validation loss: 3.2080774853806022

Epoch: 5| Step: 9
Training loss: 3.3090063421073905
Validation loss: 3.2050217641789263

Epoch: 5| Step: 10
Training loss: 3.010250381752296
Validation loss: 3.203234765357787

Epoch: 45| Step: 0
Training loss: 3.3041216859646108
Validation loss: 3.2014750251063715

Epoch: 5| Step: 1
Training loss: 3.942308910434098
Validation loss: 3.198170618607423

Epoch: 5| Step: 2
Training loss: 3.4346665235227154
Validation loss: 3.197042075388833

Epoch: 5| Step: 3
Training loss: 2.2025730172046885
Validation loss: 3.1962456943981645

Epoch: 5| Step: 4
Training loss: 3.610246033038106
Validation loss: 3.196429358730084

Epoch: 5| Step: 5
Training loss: 3.572389361708484
Validation loss: 3.1941995671027756

Epoch: 5| Step: 6
Training loss: 3.873166912025063
Validation loss: 3.1924204576209623

Epoch: 5| Step: 7
Training loss: 3.4050108729341533
Validation loss: 3.1950829885300505

Epoch: 5| Step: 8
Training loss: 3.278090199884918
Validation loss: 3.191046668481035

Epoch: 5| Step: 9
Training loss: 3.5760836046076374
Validation loss: 3.1925884700017377

Epoch: 5| Step: 10
Training loss: 3.5135326347306615
Validation loss: 3.198350899671136

Epoch: 46| Step: 0
Training loss: 3.375313920857
Validation loss: 3.1930480421927374

Epoch: 5| Step: 1
Training loss: 3.8135967240591766
Validation loss: 3.1917416369518117

Epoch: 5| Step: 2
Training loss: 3.5532489255096866
Validation loss: 3.190068560617757

Epoch: 5| Step: 3
Training loss: 3.9779995043693375
Validation loss: 3.1910896935016386

Epoch: 5| Step: 4
Training loss: 3.1605346604015607
Validation loss: 3.185566360897804

Epoch: 5| Step: 5
Training loss: 2.8785381935902827
Validation loss: 3.1862701771638524

Epoch: 5| Step: 6
Training loss: 3.786775193562083
Validation loss: 3.18781857041667

Epoch: 5| Step: 7
Training loss: 3.1657219196933815
Validation loss: 3.1855361763359475

Epoch: 5| Step: 8
Training loss: 3.805325495749486
Validation loss: 3.184189019642192

Epoch: 5| Step: 9
Training loss: 3.2661834677319113
Validation loss: 3.180924269922625

Epoch: 5| Step: 10
Training loss: 2.8128633052567733
Validation loss: 3.181556247854942

Epoch: 47| Step: 0
Training loss: 3.4064000647849904
Validation loss: 3.1811299654739265

Epoch: 5| Step: 1
Training loss: 2.774940191088347
Validation loss: 3.1802556030100573

Epoch: 5| Step: 2
Training loss: 3.458616421308332
Validation loss: 3.1800310769074667

Epoch: 5| Step: 3
Training loss: 3.192530981285426
Validation loss: 3.178706821104853

Epoch: 5| Step: 4
Training loss: 3.0731967259606208
Validation loss: 3.1787855752715743

Epoch: 5| Step: 5
Training loss: 4.575707953036817
Validation loss: 3.1817460699184026

Epoch: 5| Step: 6
Training loss: 3.550434762900909
Validation loss: 3.1805376666522553

Epoch: 5| Step: 7
Training loss: 3.3289444322059274
Validation loss: 3.1761623366277134

Epoch: 5| Step: 8
Training loss: 2.5574357768447573
Validation loss: 3.178238039802174

Epoch: 5| Step: 9
Training loss: 3.6969004922795654
Validation loss: 3.1751780983141713

Epoch: 5| Step: 10
Training loss: 3.866632595131379
Validation loss: 3.175335928286325

Epoch: 48| Step: 0
Training loss: 3.4746085515913863
Validation loss: 3.1783962344429617

Epoch: 5| Step: 1
Training loss: 3.207458541970872
Validation loss: 3.173965008808927

Epoch: 5| Step: 2
Training loss: 3.5511520074673175
Validation loss: 3.172458650145988

Epoch: 5| Step: 3
Training loss: 3.237009790489987
Validation loss: 3.1742252727249296

Epoch: 5| Step: 4
Training loss: 2.937102595292415
Validation loss: 3.172599602622147

Epoch: 5| Step: 5
Training loss: 3.7226627826133
Validation loss: 3.170561439217292

Epoch: 5| Step: 6
Training loss: 3.48691004750371
Validation loss: 3.1725177745045934

Epoch: 5| Step: 7
Training loss: 3.9981946447334566
Validation loss: 3.172167419568328

Epoch: 5| Step: 8
Training loss: 3.906303954705503
Validation loss: 3.172568815509252

Epoch: 5| Step: 9
Training loss: 2.3352161939628604
Validation loss: 3.1723351889590865

Epoch: 5| Step: 10
Training loss: 3.6267576231723524
Validation loss: 3.1697987517439308

Epoch: 49| Step: 0
Training loss: 3.979456000602341
Validation loss: 3.1719164382650065

Epoch: 5| Step: 1
Training loss: 3.4410674570306594
Validation loss: 3.1684159810267842

Epoch: 5| Step: 2
Training loss: 3.2333261751967437
Validation loss: 3.1685908165187007

Epoch: 5| Step: 3
Training loss: 3.6625667683110468
Validation loss: 3.167913010815982

Epoch: 5| Step: 4
Training loss: 3.7939635365955486
Validation loss: 3.163862015076954

Epoch: 5| Step: 5
Training loss: 2.9218152697980746
Validation loss: 3.166269286879888

Epoch: 5| Step: 6
Training loss: 3.533084089257245
Validation loss: 3.166191106383377

Epoch: 5| Step: 7
Training loss: 3.92346694066264
Validation loss: 3.164845341689965

Epoch: 5| Step: 8
Training loss: 2.6385854033469553
Validation loss: 3.1645731090737557

Epoch: 5| Step: 9
Training loss: 3.216285873432446
Validation loss: 3.1642125539622334

Epoch: 5| Step: 10
Training loss: 3.072480113599096
Validation loss: 3.164238579055187

Epoch: 50| Step: 0
Training loss: 3.6646967422318064
Validation loss: 3.162970179980293

Epoch: 5| Step: 1
Training loss: 3.6868240254110507
Validation loss: 3.161989870034935

Epoch: 5| Step: 2
Training loss: 3.7090102160187883
Validation loss: 3.163210004445993

Epoch: 5| Step: 3
Training loss: 3.2768877369169127
Validation loss: 3.1617009071750246

Epoch: 5| Step: 4
Training loss: 3.399252747716605
Validation loss: 3.1608934354756943

Epoch: 5| Step: 5
Training loss: 3.973372883333167
Validation loss: 3.160150959908861

Epoch: 5| Step: 6
Training loss: 3.619588429991296
Validation loss: 3.160003754561761

Epoch: 5| Step: 7
Training loss: 2.781376353619048
Validation loss: 3.161379669216846

Epoch: 5| Step: 8
Training loss: 2.974026297857691
Validation loss: 3.160044767629377

Epoch: 5| Step: 9
Training loss: 3.1131081718475544
Validation loss: 3.1569272596721345

Epoch: 5| Step: 10
Training loss: 3.2906032405760572
Validation loss: 3.1593139731477224

Epoch: 51| Step: 0
Training loss: 2.9891061080726766
Validation loss: 3.1564805774985314

Epoch: 5| Step: 1
Training loss: 3.7839676099846686
Validation loss: 3.1563740594931606

Epoch: 5| Step: 2
Training loss: 3.2224635950936826
Validation loss: 3.15622663494353

Epoch: 5| Step: 3
Training loss: 3.1785693252825933
Validation loss: 3.1592162108010338

Epoch: 5| Step: 4
Training loss: 3.124053659200489
Validation loss: 3.1575383404135717

Epoch: 5| Step: 5
Training loss: 3.389477795015095
Validation loss: 3.157198873473799

Epoch: 5| Step: 6
Training loss: 3.7131568456060133
Validation loss: 3.157150305848115

Epoch: 5| Step: 7
Training loss: 3.6261447545913
Validation loss: 3.153842246037733

Epoch: 5| Step: 8
Training loss: 4.336834129210181
Validation loss: 3.154344839624586

Epoch: 5| Step: 9
Training loss: 3.2639872993801826
Validation loss: 3.1547104166973297

Epoch: 5| Step: 10
Training loss: 2.6203286522473808
Validation loss: 3.1562497173395703

Epoch: 52| Step: 0
Training loss: 3.7332484888472104
Validation loss: 3.161324726973954

Epoch: 5| Step: 1
Training loss: 3.80470617395475
Validation loss: 3.1592415743167614

Epoch: 5| Step: 2
Training loss: 2.8597378526601873
Validation loss: 3.1591202080175043

Epoch: 5| Step: 3
Training loss: 4.034007940281707
Validation loss: 3.1582520189845273

Epoch: 5| Step: 4
Training loss: 3.5025222409486343
Validation loss: 3.1580172155848616

Epoch: 5| Step: 5
Training loss: 3.234829783140237
Validation loss: 3.151699096362217

Epoch: 5| Step: 6
Training loss: 3.3695353312725254
Validation loss: 3.1521744286219318

Epoch: 5| Step: 7
Training loss: 2.876303170121786
Validation loss: 3.1504555178989797

Epoch: 5| Step: 8
Training loss: 3.6261177970406777
Validation loss: 3.1509578803867573

Epoch: 5| Step: 9
Training loss: 3.3253126126520485
Validation loss: 3.1538569685720867

Epoch: 5| Step: 10
Training loss: 2.9604445074724386
Validation loss: 3.147093592911477

Epoch: 53| Step: 0
Training loss: 3.012608101199214
Validation loss: 3.1448630439487717

Epoch: 5| Step: 1
Training loss: 3.2989268494237822
Validation loss: 3.144105565684118

Epoch: 5| Step: 2
Training loss: 3.3295414019449625
Validation loss: 3.142338005136127

Epoch: 5| Step: 3
Training loss: 3.9032869621495574
Validation loss: 3.142719761777444

Epoch: 5| Step: 4
Training loss: 2.971656902024049
Validation loss: 3.1413574115718226

Epoch: 5| Step: 5
Training loss: 3.655639597484853
Validation loss: 3.1406170346946722

Epoch: 5| Step: 6
Training loss: 3.025189820946578
Validation loss: 3.138526575856869

Epoch: 5| Step: 7
Training loss: 4.119147107628849
Validation loss: 3.139259542337104

Epoch: 5| Step: 8
Training loss: 3.737475779783432
Validation loss: 3.138067263606629

Epoch: 5| Step: 9
Training loss: 3.4785881399042515
Validation loss: 3.1381224120752647

Epoch: 5| Step: 10
Training loss: 2.5457629250770824
Validation loss: 3.133775331262357

Epoch: 54| Step: 0
Training loss: 2.7403295586083645
Validation loss: 3.1351203281019973

Epoch: 5| Step: 1
Training loss: 3.1676540006732044
Validation loss: 3.137839365798461

Epoch: 5| Step: 2
Training loss: 3.9131449158738545
Validation loss: 3.133200777403107

Epoch: 5| Step: 3
Training loss: 3.966643247348241
Validation loss: 3.1327174393255905

Epoch: 5| Step: 4
Training loss: 3.226570332589237
Validation loss: 3.1328115278366333

Epoch: 5| Step: 5
Training loss: 3.7027836251949973
Validation loss: 3.130893339871627

Epoch: 5| Step: 6
Training loss: 2.7486441477629464
Validation loss: 3.132020189896847

Epoch: 5| Step: 7
Training loss: 3.5389668365416482
Validation loss: 3.1311888039716487

Epoch: 5| Step: 8
Training loss: 3.0781164798521834
Validation loss: 3.1306645955585886

Epoch: 5| Step: 9
Training loss: 3.3078941136933673
Validation loss: 3.135690597741512

Epoch: 5| Step: 10
Training loss: 3.8367145939895533
Validation loss: 3.1418827684876294

Epoch: 55| Step: 0
Training loss: 2.4621857883192266
Validation loss: 3.1282501423832625

Epoch: 5| Step: 1
Training loss: 2.914813152102536
Validation loss: 3.128474834854523

Epoch: 5| Step: 2
Training loss: 3.885892878062625
Validation loss: 3.128439972636669

Epoch: 5| Step: 3
Training loss: 3.9723592851610583
Validation loss: 3.127932417575188

Epoch: 5| Step: 4
Training loss: 3.17915193513496
Validation loss: 3.1310408813554793

Epoch: 5| Step: 5
Training loss: 3.398148307334472
Validation loss: 3.1277936724817583

Epoch: 5| Step: 6
Training loss: 3.1531329484731643
Validation loss: 3.131595730736014

Epoch: 5| Step: 7
Training loss: 3.456030266452642
Validation loss: 3.132391305703989

Epoch: 5| Step: 8
Training loss: 3.2337753550888744
Validation loss: 3.130251122788046

Epoch: 5| Step: 9
Training loss: 3.6295072224218408
Validation loss: 3.128856899074093

Epoch: 5| Step: 10
Training loss: 3.8788901460280636
Validation loss: 3.1285089903224974

Epoch: 56| Step: 0
Training loss: 3.8284535792499406
Validation loss: 3.1259825870128473

Epoch: 5| Step: 1
Training loss: 3.2368501047730094
Validation loss: 3.1240853002559343

Epoch: 5| Step: 2
Training loss: 3.220733623927
Validation loss: 3.1254642330436506

Epoch: 5| Step: 3
Training loss: 2.977819142441793
Validation loss: 3.1266378265897203

Epoch: 5| Step: 4
Training loss: 3.2305455043028095
Validation loss: 3.1257489601026553

Epoch: 5| Step: 5
Training loss: 3.428928021778824
Validation loss: 3.1249999376522593

Epoch: 5| Step: 6
Training loss: 3.1620109029119865
Validation loss: 3.126578107673768

Epoch: 5| Step: 7
Training loss: 3.830097795637274
Validation loss: 3.126268696178639

Epoch: 5| Step: 8
Training loss: 3.3650070884142465
Validation loss: 3.1250309456554355

Epoch: 5| Step: 9
Training loss: 3.2992156339247214
Validation loss: 3.124243021517242

Epoch: 5| Step: 10
Training loss: 3.722805088266068
Validation loss: 3.1219031791725436

Epoch: 57| Step: 0
Training loss: 3.7274665295782303
Validation loss: 3.1228136351347358

Epoch: 5| Step: 1
Training loss: 3.503877127195723
Validation loss: 3.121688284892865

Epoch: 5| Step: 2
Training loss: 3.7393931107590164
Validation loss: 3.1209662148267165

Epoch: 5| Step: 3
Training loss: 2.837243654208205
Validation loss: 3.120624585057284

Epoch: 5| Step: 4
Training loss: 2.9438785533008103
Validation loss: 3.1192683046739598

Epoch: 5| Step: 5
Training loss: 3.252258396426093
Validation loss: 3.1215772133053665

Epoch: 5| Step: 6
Training loss: 3.5882267179359055
Validation loss: 3.1255022773300047

Epoch: 5| Step: 7
Training loss: 3.6134261478548275
Validation loss: 3.122933641849603

Epoch: 5| Step: 8
Training loss: 2.934953762905485
Validation loss: 3.1309563262104123

Epoch: 5| Step: 9
Training loss: 3.231180428617423
Validation loss: 3.135321310730978

Epoch: 5| Step: 10
Training loss: 3.8525514396981153
Validation loss: 3.129622353870838

Epoch: 58| Step: 0
Training loss: 3.645788762864653
Validation loss: 3.1175833307949317

Epoch: 5| Step: 1
Training loss: 3.3079690715077366
Validation loss: 3.119290034083571

Epoch: 5| Step: 2
Training loss: 2.9633264089130846
Validation loss: 3.1268182301031167

Epoch: 5| Step: 3
Training loss: 2.96299989884808
Validation loss: 3.1366932860938577

Epoch: 5| Step: 4
Training loss: 2.8718614447173123
Validation loss: 3.1494994195969293

Epoch: 5| Step: 5
Training loss: 3.944134043328853
Validation loss: 3.148162495126458

Epoch: 5| Step: 6
Training loss: 3.124488788752496
Validation loss: 3.1334110727748623

Epoch: 5| Step: 7
Training loss: 3.240717322451634
Validation loss: 3.1227048916134015

Epoch: 5| Step: 8
Training loss: 4.00051185194028
Validation loss: 3.121101586067392

Epoch: 5| Step: 9
Training loss: 3.7172291955778105
Validation loss: 3.1257268195773156

Epoch: 5| Step: 10
Training loss: 3.4115099410407446
Validation loss: 3.1207796118108755

Epoch: 59| Step: 0
Training loss: 3.4015216732072044
Validation loss: 3.1229875791318698

Epoch: 5| Step: 1
Training loss: 2.9154550124616057
Validation loss: 3.1208325545669817

Epoch: 5| Step: 2
Training loss: 3.4402332883287143
Validation loss: 3.1273198366806496

Epoch: 5| Step: 3
Training loss: 3.0419885822109456
Validation loss: 3.1232970833831564

Epoch: 5| Step: 4
Training loss: 3.4263560596905744
Validation loss: 3.123931152331419

Epoch: 5| Step: 5
Training loss: 3.5723593289207005
Validation loss: 3.1243454672244346

Epoch: 5| Step: 6
Training loss: 2.8893655868664094
Validation loss: 3.124176361487593

Epoch: 5| Step: 7
Training loss: 3.5708773977854027
Validation loss: 3.1238747915183116

Epoch: 5| Step: 8
Training loss: 3.9227199176239975
Validation loss: 3.1225144557226967

Epoch: 5| Step: 9
Training loss: 3.9892341454316314
Validation loss: 3.1220445796710488

Epoch: 5| Step: 10
Training loss: 2.8544028154307965
Validation loss: 3.120175913475789

Epoch: 60| Step: 0
Training loss: 3.2022508870657496
Validation loss: 3.1206333703288274

Epoch: 5| Step: 1
Training loss: 3.3774789254119058
Validation loss: 3.118295541757055

Epoch: 5| Step: 2
Training loss: 3.7308790370745375
Validation loss: 3.118072951477867

Epoch: 5| Step: 3
Training loss: 3.5469980092501476
Validation loss: 3.1166164473332367

Epoch: 5| Step: 4
Training loss: 3.5372379812518613
Validation loss: 3.118741372543062

Epoch: 5| Step: 5
Training loss: 3.316529036945896
Validation loss: 3.1168733703187503

Epoch: 5| Step: 6
Training loss: 3.0781302669886728
Validation loss: 3.117274744494396

Epoch: 5| Step: 7
Training loss: 3.75649322382421
Validation loss: 3.1183826829059202

Epoch: 5| Step: 8
Training loss: 3.7471839503797244
Validation loss: 3.1166542673075437

Epoch: 5| Step: 9
Training loss: 3.275254939981772
Validation loss: 3.1174986639244544

Epoch: 5| Step: 10
Training loss: 2.3767925324177925
Validation loss: 3.1138238615034535

Epoch: 61| Step: 0
Training loss: 3.640490091468332
Validation loss: 3.1130750983157505

Epoch: 5| Step: 1
Training loss: 3.4405237943505327
Validation loss: 3.1130650053916895

Epoch: 5| Step: 2
Training loss: 3.1792132799590176
Validation loss: 3.112041755973975

Epoch: 5| Step: 3
Training loss: 3.4698095679453616
Validation loss: 3.1124358459389674

Epoch: 5| Step: 4
Training loss: 3.141331531515506
Validation loss: 3.11194669679369

Epoch: 5| Step: 5
Training loss: 2.931530344881981
Validation loss: 3.1091422945528437

Epoch: 5| Step: 6
Training loss: 3.660206276339021
Validation loss: 3.108963842153719

Epoch: 5| Step: 7
Training loss: 3.2988313050421323
Validation loss: 3.111300337315964

Epoch: 5| Step: 8
Training loss: 3.0216297196073763
Validation loss: 3.110552539199497

Epoch: 5| Step: 9
Training loss: 3.761976318414631
Validation loss: 3.1105206714733167

Epoch: 5| Step: 10
Training loss: 3.6047452487957896
Validation loss: 3.109245221319538

Epoch: 62| Step: 0
Training loss: 3.4678925150281943
Validation loss: 3.1083273831300944

Epoch: 5| Step: 1
Training loss: 3.3290895309074164
Validation loss: 3.1078754696063373

Epoch: 5| Step: 2
Training loss: 3.4256629357954376
Validation loss: 3.107219141395784

Epoch: 5| Step: 3
Training loss: 3.710111698823773
Validation loss: 3.106534253338425

Epoch: 5| Step: 4
Training loss: 3.301797816370716
Validation loss: 3.1074513671623873

Epoch: 5| Step: 5
Training loss: 3.435969202607481
Validation loss: 3.10985726301869

Epoch: 5| Step: 6
Training loss: 3.0947834176991806
Validation loss: 3.1066991099117205

Epoch: 5| Step: 7
Training loss: 3.3161977605806734
Validation loss: 3.1083758970972775

Epoch: 5| Step: 8
Training loss: 3.0453044266884874
Validation loss: 3.1058171232756506

Epoch: 5| Step: 9
Training loss: 3.4811899998423588
Validation loss: 3.1057103683288725

Epoch: 5| Step: 10
Training loss: 3.573105668980992
Validation loss: 3.1080320453804324

Epoch: 63| Step: 0
Training loss: 3.481509685589993
Validation loss: 3.103473040484653

Epoch: 5| Step: 1
Training loss: 3.088559043968338
Validation loss: 3.1029344981616784

Epoch: 5| Step: 2
Training loss: 2.77009703717531
Validation loss: 3.1037331841621665

Epoch: 5| Step: 3
Training loss: 3.7666852416084073
Validation loss: 3.1022576122224343

Epoch: 5| Step: 4
Training loss: 3.224669115701907
Validation loss: 3.1035545677766616

Epoch: 5| Step: 5
Training loss: 3.53582521294866
Validation loss: 3.103313596133626

Epoch: 5| Step: 6
Training loss: 3.37456735734274
Validation loss: 3.1023375154345625

Epoch: 5| Step: 7
Training loss: 3.2741648883253243
Validation loss: 3.1031771002913344

Epoch: 5| Step: 8
Training loss: 3.2600151684179983
Validation loss: 3.1029883724627436

Epoch: 5| Step: 9
Training loss: 3.728102008144343
Validation loss: 3.1001151442272947

Epoch: 5| Step: 10
Training loss: 3.5632261908052962
Validation loss: 3.101910255753132

Epoch: 64| Step: 0
Training loss: 3.6790833189794934
Validation loss: 3.101433037501287

Epoch: 5| Step: 1
Training loss: 2.578061097248993
Validation loss: 3.1006689346931733

Epoch: 5| Step: 2
Training loss: 3.2439580655850677
Validation loss: 3.1014893498556995

Epoch: 5| Step: 3
Training loss: 3.691476132977733
Validation loss: 3.1000679928259496

Epoch: 5| Step: 4
Training loss: 3.1460140925805358
Validation loss: 3.1017992685535183

Epoch: 5| Step: 5
Training loss: 3.8355529965372144
Validation loss: 3.101111847583246

Epoch: 5| Step: 6
Training loss: 3.4004507831859043
Validation loss: 3.1031228294109274

Epoch: 5| Step: 7
Training loss: 3.4656059519155717
Validation loss: 3.109344945638568

Epoch: 5| Step: 8
Training loss: 3.803638603492262
Validation loss: 3.1073777748345077

Epoch: 5| Step: 9
Training loss: 3.5161874278848018
Validation loss: 3.1084656181471484

Epoch: 5| Step: 10
Training loss: 2.2377853509955163
Validation loss: 3.1016544109279844

Epoch: 65| Step: 0
Training loss: 3.4207042624826816
Validation loss: 3.098066975493073

Epoch: 5| Step: 1
Training loss: 3.9002506420095115
Validation loss: 3.098394243138025

Epoch: 5| Step: 2
Training loss: 3.3245492271098294
Validation loss: 3.0965312704713774

Epoch: 5| Step: 3
Training loss: 2.795048975370421
Validation loss: 3.096843513188056

Epoch: 5| Step: 4
Training loss: 3.37441220286493
Validation loss: 3.0987196230170397

Epoch: 5| Step: 5
Training loss: 3.9178273260087533
Validation loss: 3.0971179262615816

Epoch: 5| Step: 6
Training loss: 2.8428385185568197
Validation loss: 3.0966508990998936

Epoch: 5| Step: 7
Training loss: 2.8211071976473483
Validation loss: 3.0986799576105963

Epoch: 5| Step: 8
Training loss: 3.8663900150336685
Validation loss: 3.099853816143352

Epoch: 5| Step: 9
Training loss: 3.5744029847070293
Validation loss: 3.0992769657468267

Epoch: 5| Step: 10
Training loss: 2.8875339786792718
Validation loss: 3.0967153253373567

Epoch: 66| Step: 0
Training loss: 3.424184359587314
Validation loss: 3.095802997367664

Epoch: 5| Step: 1
Training loss: 3.1705057731062096
Validation loss: 3.096384384653764

Epoch: 5| Step: 2
Training loss: 3.627392866996301
Validation loss: 3.0960179237795926

Epoch: 5| Step: 3
Training loss: 3.859989750507563
Validation loss: 3.0941987618004196

Epoch: 5| Step: 4
Training loss: 3.3907480525175937
Validation loss: 3.0954498256743013

Epoch: 5| Step: 5
Training loss: 4.007216857312357
Validation loss: 3.097209258067495

Epoch: 5| Step: 6
Training loss: 3.4705275371488407
Validation loss: 3.0954134717765363

Epoch: 5| Step: 7
Training loss: 2.8946750620587425
Validation loss: 3.094339738166964

Epoch: 5| Step: 8
Training loss: 3.0572569204475624
Validation loss: 3.0947346889955423

Epoch: 5| Step: 9
Training loss: 3.1595530836134698
Validation loss: 3.09384000847591

Epoch: 5| Step: 10
Training loss: 2.6445691149661807
Validation loss: 3.0924307657056587

Epoch: 67| Step: 0
Training loss: 2.7404777217600467
Validation loss: 3.0933991406528505

Epoch: 5| Step: 1
Training loss: 3.8792197109465065
Validation loss: 3.093884969472521

Epoch: 5| Step: 2
Training loss: 3.6328358639201648
Validation loss: 3.094537879320862

Epoch: 5| Step: 3
Training loss: 3.7333387908441527
Validation loss: 3.093890600737444

Epoch: 5| Step: 4
Training loss: 3.3110483695563846
Validation loss: 3.0927962988407467

Epoch: 5| Step: 5
Training loss: 3.4493937636976346
Validation loss: 3.0910670535144447

Epoch: 5| Step: 6
Training loss: 3.1518705596680747
Validation loss: 3.0925951795590585

Epoch: 5| Step: 7
Training loss: 3.313154479814773
Validation loss: 3.090969254225858

Epoch: 5| Step: 8
Training loss: 3.1512028592497887
Validation loss: 3.091376691873349

Epoch: 5| Step: 9
Training loss: 3.4496793515012127
Validation loss: 3.0903907305110865

Epoch: 5| Step: 10
Training loss: 2.9719168386312136
Validation loss: 3.0917697724675657

Epoch: 68| Step: 0
Training loss: 3.930158886403384
Validation loss: 3.090590322636674

Epoch: 5| Step: 1
Training loss: 2.834841345598006
Validation loss: 3.092098292778232

Epoch: 5| Step: 2
Training loss: 3.278838661266176
Validation loss: 3.094852107433144

Epoch: 5| Step: 3
Training loss: 4.024317732141501
Validation loss: 3.0955391230148495

Epoch: 5| Step: 4
Training loss: 3.502390726196921
Validation loss: 3.0972006629487674

Epoch: 5| Step: 5
Training loss: 3.209971930122644
Validation loss: 3.091626551132664

Epoch: 5| Step: 6
Training loss: 3.048933536874865
Validation loss: 3.08663366089297

Epoch: 5| Step: 7
Training loss: 2.833650365557839
Validation loss: 3.086590690638087

Epoch: 5| Step: 8
Training loss: 2.768524202047766
Validation loss: 3.088455265114006

Epoch: 5| Step: 9
Training loss: 3.710142030285053
Validation loss: 3.0876533760820006

Epoch: 5| Step: 10
Training loss: 3.564783401864617
Validation loss: 3.0905868155142073

Epoch: 69| Step: 0
Training loss: 3.578583667126154
Validation loss: 3.089796994441525

Epoch: 5| Step: 1
Training loss: 2.6877898126519955
Validation loss: 3.0895486218852977

Epoch: 5| Step: 2
Training loss: 3.5053380041902673
Validation loss: 3.0895026584596392

Epoch: 5| Step: 3
Training loss: 3.3254254635384335
Validation loss: 3.0875056328136115

Epoch: 5| Step: 4
Training loss: 3.1673279289349914
Validation loss: 3.085619771854103

Epoch: 5| Step: 5
Training loss: 2.3961120664470483
Validation loss: 3.084887076238207

Epoch: 5| Step: 6
Training loss: 4.241726395361958
Validation loss: 3.087127255986313

Epoch: 5| Step: 7
Training loss: 3.2962614094113962
Validation loss: 3.0863774185566335

Epoch: 5| Step: 8
Training loss: 3.51671613926612
Validation loss: 3.0854649626554096

Epoch: 5| Step: 9
Training loss: 3.7780909938244194
Validation loss: 3.0865800858565833

Epoch: 5| Step: 10
Training loss: 3.026299908244977
Validation loss: 3.0846412886599333

Epoch: 70| Step: 0
Training loss: 3.6500326912866052
Validation loss: 3.086323774281834

Epoch: 5| Step: 1
Training loss: 3.097362528437438
Validation loss: 3.0864250731481215

Epoch: 5| Step: 2
Training loss: 2.7489335853433086
Validation loss: 3.085612035109692

Epoch: 5| Step: 3
Training loss: 3.9518107163200606
Validation loss: 3.093930085593181

Epoch: 5| Step: 4
Training loss: 2.5939104880813106
Validation loss: 3.0898703367641676

Epoch: 5| Step: 5
Training loss: 3.63316504295774
Validation loss: 3.0917186728595687

Epoch: 5| Step: 6
Training loss: 3.3356932074906878
Validation loss: 3.093988915867164

Epoch: 5| Step: 7
Training loss: 3.7441731005291508
Validation loss: 3.088693845190991

Epoch: 5| Step: 8
Training loss: 2.8094225683205645
Validation loss: 3.0790356020535214

Epoch: 5| Step: 9
Training loss: 3.236952045272836
Validation loss: 3.079300940594315

Epoch: 5| Step: 10
Training loss: 3.869989663043744
Validation loss: 3.0769999648794193

Epoch: 71| Step: 0
Training loss: 2.4590683393255146
Validation loss: 3.076691296059501

Epoch: 5| Step: 1
Training loss: 3.0892069434054705
Validation loss: 3.0752797952317343

Epoch: 5| Step: 2
Training loss: 3.352082894568042
Validation loss: 3.0756691617518537

Epoch: 5| Step: 3
Training loss: 2.8185479305266434
Validation loss: 3.076710618972959

Epoch: 5| Step: 4
Training loss: 3.180955188933265
Validation loss: 3.0749778993874335

Epoch: 5| Step: 5
Training loss: 3.593352586084806
Validation loss: 3.073853022661132

Epoch: 5| Step: 6
Training loss: 3.892116643688703
Validation loss: 3.072842090689669

Epoch: 5| Step: 7
Training loss: 3.8351261811467667
Validation loss: 3.0697479351047683

Epoch: 5| Step: 8
Training loss: 3.7695079743452387
Validation loss: 3.071638170805784

Epoch: 5| Step: 9
Training loss: 3.3456208886474568
Validation loss: 3.0711598948400085

Epoch: 5| Step: 10
Training loss: 3.1521357546874476
Validation loss: 3.07047268617848

Epoch: 72| Step: 0
Training loss: 3.0575220561694074
Validation loss: 3.069229288509934

Epoch: 5| Step: 1
Training loss: 3.7112054025418693
Validation loss: 3.0678555202762428

Epoch: 5| Step: 2
Training loss: 3.519688135983778
Validation loss: 3.0679207776710453

Epoch: 5| Step: 3
Training loss: 3.401903511585276
Validation loss: 3.065313843395781

Epoch: 5| Step: 4
Training loss: 3.3659920749945003
Validation loss: 3.0655890249521236

Epoch: 5| Step: 5
Training loss: 3.387073819424008
Validation loss: 3.0658072334927273

Epoch: 5| Step: 6
Training loss: 2.4190269213121036
Validation loss: 3.065942618639878

Epoch: 5| Step: 7
Training loss: 2.9222157325559754
Validation loss: 3.066979692758119

Epoch: 5| Step: 8
Training loss: 3.3225858198783285
Validation loss: 3.064798401309109

Epoch: 5| Step: 9
Training loss: 4.125024506467214
Validation loss: 3.0642383221760428

Epoch: 5| Step: 10
Training loss: 3.223360185902519
Validation loss: 3.063953201369224

Epoch: 73| Step: 0
Training loss: 2.7357199712578253
Validation loss: 3.063761843137153

Epoch: 5| Step: 1
Training loss: 3.4085355317842216
Validation loss: 3.064830922617985

Epoch: 5| Step: 2
Training loss: 3.4388551295083087
Validation loss: 3.0637638095281026

Epoch: 5| Step: 3
Training loss: 2.65593376521171
Validation loss: 3.063387713877281

Epoch: 5| Step: 4
Training loss: 3.620928352142259
Validation loss: 3.0627549956597937

Epoch: 5| Step: 5
Training loss: 3.707040897272418
Validation loss: 3.0618577810732432

Epoch: 5| Step: 6
Training loss: 2.759976669848702
Validation loss: 3.060865319625175

Epoch: 5| Step: 7
Training loss: 3.768131166074399
Validation loss: 3.0611619686264357

Epoch: 5| Step: 8
Training loss: 3.3426767213221567
Validation loss: 3.060607719825674

Epoch: 5| Step: 9
Training loss: 3.714561989224241
Validation loss: 3.0606308490692316

Epoch: 5| Step: 10
Training loss: 3.301742937290878
Validation loss: 3.0607104167547936

Epoch: 74| Step: 0
Training loss: 4.3492385987147
Validation loss: 3.0630073788378684

Epoch: 5| Step: 1
Training loss: 3.1076172120506254
Validation loss: 3.0591801640292156

Epoch: 5| Step: 2
Training loss: 3.3216165293118727
Validation loss: 3.0578557708331457

Epoch: 5| Step: 3
Training loss: 3.0135286782955406
Validation loss: 3.0572833327531135

Epoch: 5| Step: 4
Training loss: 3.204807788482892
Validation loss: 3.056360681205924

Epoch: 5| Step: 5
Training loss: 2.7907809565282182
Validation loss: 3.057505845146712

Epoch: 5| Step: 6
Training loss: 3.462802771816354
Validation loss: 3.0579760942296708

Epoch: 5| Step: 7
Training loss: 3.3678040260873083
Validation loss: 3.0590031901323895

Epoch: 5| Step: 8
Training loss: 3.4225821265209637
Validation loss: 3.0605329315902203

Epoch: 5| Step: 9
Training loss: 3.355575328906187
Validation loss: 3.059571296204676

Epoch: 5| Step: 10
Training loss: 2.981280415057934
Validation loss: 3.060890479650245

Epoch: 75| Step: 0
Training loss: 3.3090281015622565
Validation loss: 3.0627723658117265

Epoch: 5| Step: 1
Training loss: 3.773954683800973
Validation loss: 3.062331304870097

Epoch: 5| Step: 2
Training loss: 3.874918290784195
Validation loss: 3.0578658946563637

Epoch: 5| Step: 3
Training loss: 3.1973603268942896
Validation loss: 3.0578726909418883

Epoch: 5| Step: 4
Training loss: 2.93634140216667
Validation loss: 3.0554892401026135

Epoch: 5| Step: 5
Training loss: 3.4350353768871593
Validation loss: 3.057985460211757

Epoch: 5| Step: 6
Training loss: 3.0358810443115125
Validation loss: 3.059168166974667

Epoch: 5| Step: 7
Training loss: 3.043657844291982
Validation loss: 3.0571853457930263

Epoch: 5| Step: 8
Training loss: 3.4965389032238456
Validation loss: 3.058645897528941

Epoch: 5| Step: 9
Training loss: 2.7972107584504893
Validation loss: 3.058681064926219

Epoch: 5| Step: 10
Training loss: 3.5950713009189967
Validation loss: 3.0585711795066985

Epoch: 76| Step: 0
Training loss: 3.1594466838005544
Validation loss: 3.0577269386819133

Epoch: 5| Step: 1
Training loss: 3.9063410633916797
Validation loss: 3.0518547464443992

Epoch: 5| Step: 2
Training loss: 3.5788963852342355
Validation loss: 3.057409361203981

Epoch: 5| Step: 3
Training loss: 3.578953676173908
Validation loss: 3.0554267109106257

Epoch: 5| Step: 4
Training loss: 3.4815587179110175
Validation loss: 3.054632785570316

Epoch: 5| Step: 5
Training loss: 3.3639052960721685
Validation loss: 3.0545571754202547

Epoch: 5| Step: 6
Training loss: 3.477844824735423
Validation loss: 3.0558184745214323

Epoch: 5| Step: 7
Training loss: 3.4865100289554363
Validation loss: 3.056628879657043

Epoch: 5| Step: 8
Training loss: 2.688075336706192
Validation loss: 3.0555365659422598

Epoch: 5| Step: 9
Training loss: 2.2995550388651322
Validation loss: 3.05321807973026

Epoch: 5| Step: 10
Training loss: 3.318754373608597
Validation loss: 3.0525735998003842

Epoch: 77| Step: 0
Training loss: 3.063281056978842
Validation loss: 3.0540436953046597

Epoch: 5| Step: 1
Training loss: 3.370920187857142
Validation loss: 3.0531447050198244

Epoch: 5| Step: 2
Training loss: 4.016053410695455
Validation loss: 3.053106795265401

Epoch: 5| Step: 3
Training loss: 3.676674680542592
Validation loss: 3.050788127192953

Epoch: 5| Step: 4
Training loss: 2.975671189191454
Validation loss: 3.0530667874863675

Epoch: 5| Step: 5
Training loss: 3.660048899506309
Validation loss: 3.0543331354760785

Epoch: 5| Step: 6
Training loss: 3.0941362236231478
Validation loss: 3.054615998583306

Epoch: 5| Step: 7
Training loss: 3.370846771351765
Validation loss: 3.057365397444901

Epoch: 5| Step: 8
Training loss: 2.8802169238624056
Validation loss: 3.0534787603930758

Epoch: 5| Step: 9
Training loss: 3.491038976315686
Validation loss: 3.054932589214093

Epoch: 5| Step: 10
Training loss: 2.694206298275475
Validation loss: 3.0561615370669966

Epoch: 78| Step: 0
Training loss: 3.187519746607033
Validation loss: 3.057648365717803

Epoch: 5| Step: 1
Training loss: 2.9989773278773812
Validation loss: 3.0551770202015045

Epoch: 5| Step: 2
Training loss: 2.7536725749985367
Validation loss: 3.054314162852486

Epoch: 5| Step: 3
Training loss: 3.630984266738193
Validation loss: 3.0496205259414495

Epoch: 5| Step: 4
Training loss: 3.6672454868408244
Validation loss: 3.049574800530925

Epoch: 5| Step: 5
Training loss: 2.8510111236515825
Validation loss: 3.0486341086522537

Epoch: 5| Step: 6
Training loss: 3.3774398179413825
Validation loss: 3.0513355857107034

Epoch: 5| Step: 7
Training loss: 2.7862168442134068
Validation loss: 3.0509028725171836

Epoch: 5| Step: 8
Training loss: 3.383845570190151
Validation loss: 3.0445088233570043

Epoch: 5| Step: 9
Training loss: 4.159042911470514
Validation loss: 3.0498692274510657

Epoch: 5| Step: 10
Training loss: 3.5195152629527304
Validation loss: 3.0483545237147207

Epoch: 79| Step: 0
Training loss: 3.1718811636427953
Validation loss: 3.045264528549193

Epoch: 5| Step: 1
Training loss: 2.954214228223436
Validation loss: 3.048311151785902

Epoch: 5| Step: 2
Training loss: 3.585853193368302
Validation loss: 3.047359066087874

Epoch: 5| Step: 3
Training loss: 3.610289090487704
Validation loss: 3.045362477320291

Epoch: 5| Step: 4
Training loss: 3.7713382165167015
Validation loss: 3.045005232625651

Epoch: 5| Step: 5
Training loss: 3.5064683815577546
Validation loss: 3.046953134768067

Epoch: 5| Step: 6
Training loss: 3.347034730492288
Validation loss: 3.0456221653855757

Epoch: 5| Step: 7
Training loss: 2.894063687881903
Validation loss: 3.047301543117086

Epoch: 5| Step: 8
Training loss: 3.523026875930735
Validation loss: 3.0500490461360235

Epoch: 5| Step: 9
Training loss: 2.8033239083541783
Validation loss: 3.047482982101652

Epoch: 5| Step: 10
Training loss: 3.1674921733274766
Validation loss: 3.0468130689647386

Epoch: 80| Step: 0
Training loss: 3.499271044433001
Validation loss: 3.047294668992237

Epoch: 5| Step: 1
Training loss: 3.3747055490404803
Validation loss: 3.046282022860718

Epoch: 5| Step: 2
Training loss: 4.163808961632333
Validation loss: 3.0453255970549193

Epoch: 5| Step: 3
Training loss: 2.944075347350829
Validation loss: 3.043701280002356

Epoch: 5| Step: 4
Training loss: 2.8780517966438754
Validation loss: 3.0522486172867227

Epoch: 5| Step: 5
Training loss: 3.273233994597122
Validation loss: 3.0610618889615724

Epoch: 5| Step: 6
Training loss: 2.9565730880097743
Validation loss: 3.0502470437226616

Epoch: 5| Step: 7
Training loss: 3.3343908221969674
Validation loss: 3.0512456895565796

Epoch: 5| Step: 8
Training loss: 3.2711144263773626
Validation loss: 3.0512904127958165

Epoch: 5| Step: 9
Training loss: 3.5111834464958234
Validation loss: 3.047933480772052

Epoch: 5| Step: 10
Training loss: 3.0447839065820026
Validation loss: 3.0518702129838307

Epoch: 81| Step: 0
Training loss: 3.4897511152479788
Validation loss: 3.044124086497665

Epoch: 5| Step: 1
Training loss: 3.362041887466034
Validation loss: 3.041361218763206

Epoch: 5| Step: 2
Training loss: 3.7118091081666296
Validation loss: 3.0408786680642126

Epoch: 5| Step: 3
Training loss: 3.374370657558936
Validation loss: 3.0439129529422697

Epoch: 5| Step: 4
Training loss: 3.311312048601782
Validation loss: 3.0437474836177496

Epoch: 5| Step: 5
Training loss: 3.442230576199346
Validation loss: 3.045302040930156

Epoch: 5| Step: 6
Training loss: 3.1339611506680303
Validation loss: 3.046230062586238

Epoch: 5| Step: 7
Training loss: 3.0444963609332563
Validation loss: 3.0422296602836405

Epoch: 5| Step: 8
Training loss: 3.142022576312295
Validation loss: 3.044116257764895

Epoch: 5| Step: 9
Training loss: 3.3857885224962563
Validation loss: 3.042283698650667

Epoch: 5| Step: 10
Training loss: 2.9758573883403328
Validation loss: 3.044431531929294

Epoch: 82| Step: 0
Training loss: 2.788253111094748
Validation loss: 3.0420907101876278

Epoch: 5| Step: 1
Training loss: 3.3744497910343716
Validation loss: 3.044433793742745

Epoch: 5| Step: 2
Training loss: 3.8349575803318
Validation loss: 3.0427017386475583

Epoch: 5| Step: 3
Training loss: 3.2676178176758337
Validation loss: 3.042456713225019

Epoch: 5| Step: 4
Training loss: 2.859063136702882
Validation loss: 3.043749947240591

Epoch: 5| Step: 5
Training loss: 2.9327723017169713
Validation loss: 3.044182589131371

Epoch: 5| Step: 6
Training loss: 3.5159811560046625
Validation loss: 3.0438154990901043

Epoch: 5| Step: 7
Training loss: 3.3507968410379148
Validation loss: 3.041813529246814

Epoch: 5| Step: 8
Training loss: 3.0932777121355484
Validation loss: 3.0427798651528

Epoch: 5| Step: 9
Training loss: 3.6833268166969155
Validation loss: 3.0410531392119244

Epoch: 5| Step: 10
Training loss: 3.6358726820272613
Validation loss: 3.040939396381824

Epoch: 83| Step: 0
Training loss: 3.645325994160019
Validation loss: 3.040043430749446

Epoch: 5| Step: 1
Training loss: 2.665396974208692
Validation loss: 3.0418047118597706

Epoch: 5| Step: 2
Training loss: 3.0799199017104564
Validation loss: 3.0444854613229912

Epoch: 5| Step: 3
Training loss: 3.406878072247041
Validation loss: 3.04042857773519

Epoch: 5| Step: 4
Training loss: 3.59654989223274
Validation loss: 3.041197286427113

Epoch: 5| Step: 5
Training loss: 2.7894062076218633
Validation loss: 3.039810363225403

Epoch: 5| Step: 6
Training loss: 3.0370580343831803
Validation loss: 3.0384597077170317

Epoch: 5| Step: 7
Training loss: 2.955844978830824
Validation loss: 3.0364911939099852

Epoch: 5| Step: 8
Training loss: 3.808057103618451
Validation loss: 3.0387386861581343

Epoch: 5| Step: 9
Training loss: 3.955325754207789
Validation loss: 3.038636405023881

Epoch: 5| Step: 10
Training loss: 3.2059263307670784
Validation loss: 3.036609647084118

Epoch: 84| Step: 0
Training loss: 3.22779493832545
Validation loss: 3.0374342690114564

Epoch: 5| Step: 1
Training loss: 3.1344250265219626
Validation loss: 3.0388659080361364

Epoch: 5| Step: 2
Training loss: 2.894522354174083
Validation loss: 3.036562232260948

Epoch: 5| Step: 3
Training loss: 3.8014624241059716
Validation loss: 3.0395524288851226

Epoch: 5| Step: 4
Training loss: 3.0296823439571425
Validation loss: 3.0376747666804325

Epoch: 5| Step: 5
Training loss: 3.295968604577173
Validation loss: 3.0361327407279566

Epoch: 5| Step: 6
Training loss: 2.8829034723747298
Validation loss: 3.0376240939103947

Epoch: 5| Step: 7
Training loss: 3.2781435839596265
Validation loss: 3.0388813394493215

Epoch: 5| Step: 8
Training loss: 3.5106661261753582
Validation loss: 3.0370603202585733

Epoch: 5| Step: 9
Training loss: 4.2091880660544305
Validation loss: 3.0378524767519477

Epoch: 5| Step: 10
Training loss: 2.8083671722486394
Validation loss: 3.0369532747844263

Epoch: 85| Step: 0
Training loss: 3.5226522107671174
Validation loss: 3.0360568142437065

Epoch: 5| Step: 1
Training loss: 3.800171351333978
Validation loss: 3.036186232383655

Epoch: 5| Step: 2
Training loss: 4.157907944034997
Validation loss: 3.0353962626283706

Epoch: 5| Step: 3
Training loss: 3.21947108219227
Validation loss: 3.0349095417522216

Epoch: 5| Step: 4
Training loss: 2.601755312627825
Validation loss: 3.0337024278793527

Epoch: 5| Step: 5
Training loss: 2.8549201323499696
Validation loss: 3.034510008089629

Epoch: 5| Step: 6
Training loss: 3.5374331734212165
Validation loss: 3.034010075106841

Epoch: 5| Step: 7
Training loss: 3.190453152414093
Validation loss: 3.033885730486088

Epoch: 5| Step: 8
Training loss: 2.868230063666462
Validation loss: 3.0356190923068636

Epoch: 5| Step: 9
Training loss: 3.387377893703473
Validation loss: 3.0348767361333207

Epoch: 5| Step: 10
Training loss: 2.829378809065769
Validation loss: 3.0346784402589093

Epoch: 86| Step: 0
Training loss: 3.4363456868725386
Validation loss: 3.033795771889986

Epoch: 5| Step: 1
Training loss: 2.6113944091601464
Validation loss: 3.03350418285348

Epoch: 5| Step: 2
Training loss: 3.0774490466265267
Validation loss: 3.033628490718802

Epoch: 5| Step: 3
Training loss: 3.289552194561909
Validation loss: 3.0319996397279207

Epoch: 5| Step: 4
Training loss: 3.1481507883081608
Validation loss: 3.0340014471289827

Epoch: 5| Step: 5
Training loss: 3.0024316787251957
Validation loss: 3.032309416912318

Epoch: 5| Step: 6
Training loss: 3.007779524981583
Validation loss: 3.033687946164196

Epoch: 5| Step: 7
Training loss: 3.685532513758784
Validation loss: 3.0352002491186694

Epoch: 5| Step: 8
Training loss: 3.6662769254989183
Validation loss: 3.0376573644154163

Epoch: 5| Step: 9
Training loss: 3.6501834457492777
Validation loss: 3.0382713289547962

Epoch: 5| Step: 10
Training loss: 3.690576724545016
Validation loss: 3.034045067554056

Epoch: 87| Step: 0
Training loss: 3.4365960059562277
Validation loss: 3.0316915525610497

Epoch: 5| Step: 1
Training loss: 3.2649512074959253
Validation loss: 3.030244884539065

Epoch: 5| Step: 2
Training loss: 2.7558116192265505
Validation loss: 3.032562905228181

Epoch: 5| Step: 3
Training loss: 3.5543346858735885
Validation loss: 3.031808441213706

Epoch: 5| Step: 4
Training loss: 3.6100306060000826
Validation loss: 3.03381380218662

Epoch: 5| Step: 5
Training loss: 3.4194044138877944
Validation loss: 3.0336303262190265

Epoch: 5| Step: 6
Training loss: 2.7743341420313135
Validation loss: 3.02993484720513

Epoch: 5| Step: 7
Training loss: 2.7470772557013214
Validation loss: 3.0296443555507078

Epoch: 5| Step: 8
Training loss: 3.133065154049862
Validation loss: 3.0272687437866046

Epoch: 5| Step: 9
Training loss: 3.6070469866453343
Validation loss: 3.028393658856784

Epoch: 5| Step: 10
Training loss: 3.890994134879416
Validation loss: 3.026752816122033

Epoch: 88| Step: 0
Training loss: 3.3207909811486953
Validation loss: 3.0275575107311217

Epoch: 5| Step: 1
Training loss: 3.5472497952102473
Validation loss: 3.027356921540133

Epoch: 5| Step: 2
Training loss: 3.4269961700640676
Validation loss: 3.0278388585418528

Epoch: 5| Step: 3
Training loss: 3.2252580347258983
Validation loss: 3.027283323957137

Epoch: 5| Step: 4
Training loss: 3.791231710337648
Validation loss: 3.025869172736623

Epoch: 5| Step: 5
Training loss: 3.606351833128809
Validation loss: 3.025067596846424

Epoch: 5| Step: 6
Training loss: 3.65435859469024
Validation loss: 3.026010479080739

Epoch: 5| Step: 7
Training loss: 2.3186589266841806
Validation loss: 3.025294847220296

Epoch: 5| Step: 8
Training loss: 2.971391646973207
Validation loss: 3.0237511590863355

Epoch: 5| Step: 9
Training loss: 2.475052237681894
Validation loss: 3.023746417144104

Epoch: 5| Step: 10
Training loss: 3.6375304073360586
Validation loss: 3.031115668597246

Epoch: 89| Step: 0
Training loss: 3.239932091554658
Validation loss: 3.0308379711605884

Epoch: 5| Step: 1
Training loss: 4.062811736837479
Validation loss: 3.032572941455693

Epoch: 5| Step: 2
Training loss: 3.5720683315016513
Validation loss: 3.0289707323643142

Epoch: 5| Step: 3
Training loss: 3.1921925130646973
Validation loss: 3.0259786732746425

Epoch: 5| Step: 4
Training loss: 3.5966025268331987
Validation loss: 3.024314250219063

Epoch: 5| Step: 5
Training loss: 2.9533276362252954
Validation loss: 3.024036578435508

Epoch: 5| Step: 6
Training loss: 3.2746965631752176
Validation loss: 3.023473682331739

Epoch: 5| Step: 7
Training loss: 3.767449407914953
Validation loss: 3.0245613124468402

Epoch: 5| Step: 8
Training loss: 3.1420321372541826
Validation loss: 3.0230072377560977

Epoch: 5| Step: 9
Training loss: 2.6403646848679636
Validation loss: 3.0207162078340595

Epoch: 5| Step: 10
Training loss: 2.3370210819950277
Validation loss: 3.021117547016956

Epoch: 90| Step: 0
Training loss: 3.0346123049626397
Validation loss: 3.0217879713731515

Epoch: 5| Step: 1
Training loss: 3.246479034511234
Validation loss: 3.0226807056921356

Epoch: 5| Step: 2
Training loss: 3.3488835652233195
Validation loss: 3.021878075340681

Epoch: 5| Step: 3
Training loss: 3.272264657413758
Validation loss: 3.020326450637526

Epoch: 5| Step: 4
Training loss: 3.2086222299742704
Validation loss: 3.0216157467850375

Epoch: 5| Step: 5
Training loss: 3.6669340614151493
Validation loss: 3.0221120694338386

Epoch: 5| Step: 6
Training loss: 3.403705311347706
Validation loss: 3.0209091810662674

Epoch: 5| Step: 7
Training loss: 3.7795560210731978
Validation loss: 3.019814877083292

Epoch: 5| Step: 8
Training loss: 2.7748753218951996
Validation loss: 3.0208931299952515

Epoch: 5| Step: 9
Training loss: 3.6220193644890135
Validation loss: 3.022742084582985

Epoch: 5| Step: 10
Training loss: 2.58683516949821
Validation loss: 3.019922812739342

Epoch: 91| Step: 0
Training loss: 3.2851100922924097
Validation loss: 3.021788469375309

Epoch: 5| Step: 1
Training loss: 3.6539027839009646
Validation loss: 3.0216263326738

Epoch: 5| Step: 2
Training loss: 2.483019284951226
Validation loss: 3.0261687897906473

Epoch: 5| Step: 3
Training loss: 3.15261949280957
Validation loss: 3.034770857963298

Epoch: 5| Step: 4
Training loss: 3.5541710111554967
Validation loss: 3.037736711858405

Epoch: 5| Step: 5
Training loss: 2.7797813395399102
Validation loss: 3.0426799762414922

Epoch: 5| Step: 6
Training loss: 3.435030240698996
Validation loss: 3.0646988402444104

Epoch: 5| Step: 7
Training loss: 2.5956732731717893
Validation loss: 3.0481980077905604

Epoch: 5| Step: 8
Training loss: 4.064793804799588
Validation loss: 3.0364652491572217

Epoch: 5| Step: 9
Training loss: 3.5220430240981773
Validation loss: 3.0200863303199803

Epoch: 5| Step: 10
Training loss: 3.4827455550990947
Validation loss: 3.0199522850294613

Epoch: 92| Step: 0
Training loss: 3.6492265587283987
Validation loss: 3.0212525350917523

Epoch: 5| Step: 1
Training loss: 3.3110505297649473
Validation loss: 3.0230109284377127

Epoch: 5| Step: 2
Training loss: 3.5249175961649684
Validation loss: 3.0269970597761975

Epoch: 5| Step: 3
Training loss: 2.8858441381631317
Validation loss: 3.0232613779786126

Epoch: 5| Step: 4
Training loss: 3.4030556355562873
Validation loss: 3.0240381510197074

Epoch: 5| Step: 5
Training loss: 3.3233387518570425
Validation loss: 3.0238068808015717

Epoch: 5| Step: 6
Training loss: 2.765100289262611
Validation loss: 3.020838378856775

Epoch: 5| Step: 7
Training loss: 3.256851310636506
Validation loss: 3.019852619007147

Epoch: 5| Step: 8
Training loss: 3.2340574246830345
Validation loss: 3.0191298154293476

Epoch: 5| Step: 9
Training loss: 3.0988243950287964
Validation loss: 3.019475803429443

Epoch: 5| Step: 10
Training loss: 3.771929263757285
Validation loss: 3.0170453846578273

Epoch: 93| Step: 0
Training loss: 2.296064999540888
Validation loss: 3.017822279535566

Epoch: 5| Step: 1
Training loss: 3.4465988422068445
Validation loss: 3.018472997892552

Epoch: 5| Step: 2
Training loss: 3.1659412222326293
Validation loss: 3.0164536333325014

Epoch: 5| Step: 3
Training loss: 3.9053077476846787
Validation loss: 3.0171480068689576

Epoch: 5| Step: 4
Training loss: 3.246285149432092
Validation loss: 3.0166977004165507

Epoch: 5| Step: 5
Training loss: 3.5060193208639743
Validation loss: 3.0142775048869455

Epoch: 5| Step: 6
Training loss: 3.238051678994992
Validation loss: 3.015356168432706

Epoch: 5| Step: 7
Training loss: 2.9907714042583224
Validation loss: 3.0162841171780856

Epoch: 5| Step: 8
Training loss: 3.683424685857149
Validation loss: 3.0163732143812085

Epoch: 5| Step: 9
Training loss: 3.236301603881978
Validation loss: 3.020730683842573

Epoch: 5| Step: 10
Training loss: 3.248212175871142
Validation loss: 3.0226142671721155

Epoch: 94| Step: 0
Training loss: 2.5999725340346145
Validation loss: 3.022523945964676

Epoch: 5| Step: 1
Training loss: 3.661250680576312
Validation loss: 3.028362402937418

Epoch: 5| Step: 2
Training loss: 3.1450619457069497
Validation loss: 3.0304713871455884

Epoch: 5| Step: 3
Training loss: 2.821135847210181
Validation loss: 3.028691473781261

Epoch: 5| Step: 4
Training loss: 3.6936583738371347
Validation loss: 3.025688498267867

Epoch: 5| Step: 5
Training loss: 3.553499060864027
Validation loss: 3.0156700066734836

Epoch: 5| Step: 6
Training loss: 3.3527137184151177
Validation loss: 3.012114113167497

Epoch: 5| Step: 7
Training loss: 3.270022411211308
Validation loss: 3.012363074701305

Epoch: 5| Step: 8
Training loss: 3.2776057760365127
Validation loss: 3.0113130635674152

Epoch: 5| Step: 9
Training loss: 3.39459811409262
Validation loss: 3.0125544657528076

Epoch: 5| Step: 10
Training loss: 3.258924555169484
Validation loss: 3.011408553059982

Epoch: 95| Step: 0
Training loss: 3.2958948205998673
Validation loss: 3.0131789666272684

Epoch: 5| Step: 1
Training loss: 3.5351501802002447
Validation loss: 3.0122276576210476

Epoch: 5| Step: 2
Training loss: 2.8063717516207074
Validation loss: 3.010729217456124

Epoch: 5| Step: 3
Training loss: 3.2832918626002607
Validation loss: 3.012360926676279

Epoch: 5| Step: 4
Training loss: 2.8150636644769853
Validation loss: 3.011838456644258

Epoch: 5| Step: 5
Training loss: 3.1017907969052514
Validation loss: 3.013293677357748

Epoch: 5| Step: 6
Training loss: 3.2675832325404643
Validation loss: 3.0129043860495943

Epoch: 5| Step: 7
Training loss: 3.226168333643549
Validation loss: 3.0119778737495815

Epoch: 5| Step: 8
Training loss: 3.9233430949057
Validation loss: 3.0118695435705454

Epoch: 5| Step: 9
Training loss: 3.029736485117227
Validation loss: 3.012832558433288

Epoch: 5| Step: 10
Training loss: 3.7666085252803807
Validation loss: 3.0121925061931427

Epoch: 96| Step: 0
Training loss: 3.456697161204931
Validation loss: 3.0153412712797105

Epoch: 5| Step: 1
Training loss: 2.8896944764940926
Validation loss: 3.0186459529610565

Epoch: 5| Step: 2
Training loss: 2.763384585056738
Validation loss: 3.019271783615021

Epoch: 5| Step: 3
Training loss: 4.141235997446638
Validation loss: 3.0134881280537016

Epoch: 5| Step: 4
Training loss: 3.071985308353738
Validation loss: 3.011329447493222

Epoch: 5| Step: 5
Training loss: 3.2945260452906036
Validation loss: 3.009637463477009

Epoch: 5| Step: 6
Training loss: 2.6393023908682984
Validation loss: 3.009633390116691

Epoch: 5| Step: 7
Training loss: 3.6239572537997966
Validation loss: 3.0080709886754815

Epoch: 5| Step: 8
Training loss: 3.362327520208199
Validation loss: 3.009749057946679

Epoch: 5| Step: 9
Training loss: 3.1977717628743494
Validation loss: 3.008746633487349

Epoch: 5| Step: 10
Training loss: 3.4582564257300983
Validation loss: 3.008695843308103

Epoch: 97| Step: 0
Training loss: 3.2221862820195786
Validation loss: 3.009913775546867

Epoch: 5| Step: 1
Training loss: 3.482969402545739
Validation loss: 3.00924829126769

Epoch: 5| Step: 2
Training loss: 2.776017313570674
Validation loss: 3.0091547012219566

Epoch: 5| Step: 3
Training loss: 3.0236366856928876
Validation loss: 3.0076425786438103

Epoch: 5| Step: 4
Training loss: 3.897473294385009
Validation loss: 3.008642286381425

Epoch: 5| Step: 5
Training loss: 2.2253172487546533
Validation loss: 3.008036894911883

Epoch: 5| Step: 6
Training loss: 3.507481072960031
Validation loss: 3.0055063211942983

Epoch: 5| Step: 7
Training loss: 3.6847567942058657
Validation loss: 3.0047724885782547

Epoch: 5| Step: 8
Training loss: 3.1720923739208042
Validation loss: 3.00446134664334

Epoch: 5| Step: 9
Training loss: 3.6484403753167203
Validation loss: 3.003965110879007

Epoch: 5| Step: 10
Training loss: 3.1029332588632905
Validation loss: 3.005117718742698

Epoch: 98| Step: 0
Training loss: 3.577571909439685
Validation loss: 3.0038356051812443

Epoch: 5| Step: 1
Training loss: 2.0972354402890474
Validation loss: 3.004218345439832

Epoch: 5| Step: 2
Training loss: 3.606500975868498
Validation loss: 3.003243263880494

Epoch: 5| Step: 3
Training loss: 2.807603175916124
Validation loss: 3.002383835153064

Epoch: 5| Step: 4
Training loss: 3.248365724916531
Validation loss: 3.0032531744391977

Epoch: 5| Step: 5
Training loss: 3.698612344699994
Validation loss: 3.0020720801588343

Epoch: 5| Step: 6
Training loss: 3.017098496723006
Validation loss: 3.002163503409177

Epoch: 5| Step: 7
Training loss: 3.8780391219449357
Validation loss: 3.001986160602003

Epoch: 5| Step: 8
Training loss: 3.353267209467265
Validation loss: 3.001963007366369

Epoch: 5| Step: 9
Training loss: 3.0622893280436294
Validation loss: 3.005224522204936

Epoch: 5| Step: 10
Training loss: 3.346991848085732
Validation loss: 3.002527955284825

Epoch: 99| Step: 0
Training loss: 3.708838196294951
Validation loss: 3.002108339810414

Epoch: 5| Step: 1
Training loss: 3.2070154893606335
Validation loss: 3.0034110526556095

Epoch: 5| Step: 2
Training loss: 2.984779689971851
Validation loss: 3.005411104797433

Epoch: 5| Step: 3
Training loss: 3.2588367635855553
Validation loss: 3.0070209554225134

Epoch: 5| Step: 4
Training loss: 2.9523480720417723
Validation loss: 3.009642692736805

Epoch: 5| Step: 5
Training loss: 3.483500144164563
Validation loss: 3.011918232328213

Epoch: 5| Step: 6
Training loss: 3.088771166109486
Validation loss: 3.0065196900100437

Epoch: 5| Step: 7
Training loss: 3.1519362175582906
Validation loss: 3.002841415675252

Epoch: 5| Step: 8
Training loss: 3.107729836002728
Validation loss: 3.0031292004707573

Epoch: 5| Step: 9
Training loss: 3.9459039528048248
Validation loss: 3.0032263748814567

Epoch: 5| Step: 10
Training loss: 3.084213354634653
Validation loss: 3.0024116096554123

Epoch: 100| Step: 0
Training loss: 3.0316517357216513
Validation loss: 3.0015814135516496

Epoch: 5| Step: 1
Training loss: 2.8022161875337215
Validation loss: 3.0014835008768004

Epoch: 5| Step: 2
Training loss: 2.9181383688778353
Validation loss: 3.001645570044197

Epoch: 5| Step: 3
Training loss: 3.4548342517892845
Validation loss: 3.0013648034084874

Epoch: 5| Step: 4
Training loss: 3.7502970259971575
Validation loss: 3.0042763076205716

Epoch: 5| Step: 5
Training loss: 3.69957579165612
Validation loss: 3.0061056002161903

Epoch: 5| Step: 6
Training loss: 3.452997403786548
Validation loss: 3.0052618468157837

Epoch: 5| Step: 7
Training loss: 3.1890077204020204
Validation loss: 3.009603726483323

Epoch: 5| Step: 8
Training loss: 3.4677844379049687
Validation loss: 3.0107053804269963

Epoch: 5| Step: 9
Training loss: 2.9182168020194914
Validation loss: 3.0083551960039556

Epoch: 5| Step: 10
Training loss: 3.262522122245998
Validation loss: 3.0022118201470964

Epoch: 101| Step: 0
Training loss: 3.571130571194304
Validation loss: 3.001786933771604

Epoch: 5| Step: 1
Training loss: 2.73160757347305
Validation loss: 2.9995668228408587

Epoch: 5| Step: 2
Training loss: 3.2894446361664604
Validation loss: 2.9967285353138666

Epoch: 5| Step: 3
Training loss: 2.991238515778434
Validation loss: 2.9964522462414123

Epoch: 5| Step: 4
Training loss: 3.2064685769337085
Validation loss: 2.9982133727267026

Epoch: 5| Step: 5
Training loss: 3.2875250985815625
Validation loss: 2.997824001068042

Epoch: 5| Step: 6
Training loss: 3.2679287755948474
Validation loss: 2.9963094783352

Epoch: 5| Step: 7
Training loss: 3.174467784098663
Validation loss: 2.9974177845383756

Epoch: 5| Step: 8
Training loss: 3.702274015485913
Validation loss: 2.9964015873300207

Epoch: 5| Step: 9
Training loss: 3.690214806483921
Validation loss: 2.996221660035563

Epoch: 5| Step: 10
Training loss: 2.9080416171468566
Validation loss: 2.9953959875668934

Epoch: 102| Step: 0
Training loss: 3.487390556122181
Validation loss: 2.9960396939830503

Epoch: 5| Step: 1
Training loss: 3.6519100156062114
Validation loss: 2.996201657179421

Epoch: 5| Step: 2
Training loss: 3.220319642971063
Validation loss: 2.994296624927171

Epoch: 5| Step: 3
Training loss: 3.662044660886543
Validation loss: 2.9961969820123384

Epoch: 5| Step: 4
Training loss: 2.9945156512014637
Validation loss: 2.9945484991807385

Epoch: 5| Step: 5
Training loss: 3.0148624384988594
Validation loss: 2.9938279242757875

Epoch: 5| Step: 6
Training loss: 3.3881820104770943
Validation loss: 2.9929125993839847

Epoch: 5| Step: 7
Training loss: 3.6745589166751293
Validation loss: 2.9927749950227573

Epoch: 5| Step: 8
Training loss: 3.3834215281098867
Validation loss: 2.992661370417829

Epoch: 5| Step: 9
Training loss: 2.5959321000692923
Validation loss: 2.993752802803981

Epoch: 5| Step: 10
Training loss: 2.597466621074314
Validation loss: 2.993914090802528

Epoch: 103| Step: 0
Training loss: 3.101320656060341
Validation loss: 2.9938362852614038

Epoch: 5| Step: 1
Training loss: 3.0202220605215175
Validation loss: 2.9945023882857527

Epoch: 5| Step: 2
Training loss: 3.5194720433681943
Validation loss: 2.9974917998199984

Epoch: 5| Step: 3
Training loss: 2.9431301298520043
Validation loss: 3.0010064890952504

Epoch: 5| Step: 4
Training loss: 3.7806615450393926
Validation loss: 3.000871072972168

Epoch: 5| Step: 5
Training loss: 2.6389385910261405
Validation loss: 2.9991700689105616

Epoch: 5| Step: 6
Training loss: 3.358832594974333
Validation loss: 2.993795105212025

Epoch: 5| Step: 7
Training loss: 3.3753623767858736
Validation loss: 2.9933157205665295

Epoch: 5| Step: 8
Training loss: 3.764694162133149
Validation loss: 2.991526338707735

Epoch: 5| Step: 9
Training loss: 3.1276734170015206
Validation loss: 2.989700746126108

Epoch: 5| Step: 10
Training loss: 3.1630787014620845
Validation loss: 2.991333124876458

Epoch: 104| Step: 0
Training loss: 3.929421144714796
Validation loss: 2.9904745879433

Epoch: 5| Step: 1
Training loss: 3.686732713430791
Validation loss: 2.9894039812999704

Epoch: 5| Step: 2
Training loss: 2.497819140017506
Validation loss: 2.9916010242008273

Epoch: 5| Step: 3
Training loss: 3.1850010669173487
Validation loss: 2.990051980274144

Epoch: 5| Step: 4
Training loss: 3.193470916199918
Validation loss: 2.9879053572047525

Epoch: 5| Step: 5
Training loss: 3.6391112491786957
Validation loss: 2.989754179325138

Epoch: 5| Step: 6
Training loss: 3.0628261781715382
Validation loss: 2.9885256920442838

Epoch: 5| Step: 7
Training loss: 3.432542173344641
Validation loss: 2.9872640653448284

Epoch: 5| Step: 8
Training loss: 3.0856007838945727
Validation loss: 2.9886819859113323

Epoch: 5| Step: 9
Training loss: 3.058176842894634
Validation loss: 2.9889172227869065

Epoch: 5| Step: 10
Training loss: 2.8638042893377675
Validation loss: 2.9892932833607433

Epoch: 105| Step: 0
Training loss: 2.9936357384779435
Validation loss: 2.988352705189464

Epoch: 5| Step: 1
Training loss: 3.386735645502839
Validation loss: 2.9877757543081174

Epoch: 5| Step: 2
Training loss: 3.1101068756776202
Validation loss: 2.988763248595759

Epoch: 5| Step: 3
Training loss: 3.5311919351040584
Validation loss: 2.9887302555449646

Epoch: 5| Step: 4
Training loss: 3.1001160753730064
Validation loss: 2.9910636450640906

Epoch: 5| Step: 5
Training loss: 3.554107283304458
Validation loss: 2.9920540572669165

Epoch: 5| Step: 6
Training loss: 3.3776417036281954
Validation loss: 2.98861503605516

Epoch: 5| Step: 7
Training loss: 3.180456719859494
Validation loss: 2.9873724862643103

Epoch: 5| Step: 8
Training loss: 3.49590320600686
Validation loss: 2.9857475707810655

Epoch: 5| Step: 9
Training loss: 3.1721618221996026
Validation loss: 2.984806614787923

Epoch: 5| Step: 10
Training loss: 2.8917565682660538
Validation loss: 2.987540483331302

Epoch: 106| Step: 0
Training loss: 3.6526685600890865
Validation loss: 2.9869566346524987

Epoch: 5| Step: 1
Training loss: 2.9483930834086545
Validation loss: 2.988849683789794

Epoch: 5| Step: 2
Training loss: 3.8998842173286805
Validation loss: 2.9864149070891446

Epoch: 5| Step: 3
Training loss: 3.336937354734702
Validation loss: 2.9860543601374823

Epoch: 5| Step: 4
Training loss: 2.4924041749522847
Validation loss: 2.9874500336555156

Epoch: 5| Step: 5
Training loss: 3.5534796035415264
Validation loss: 2.9874307375304423

Epoch: 5| Step: 6
Training loss: 3.3799536344068013
Validation loss: 2.987836067271185

Epoch: 5| Step: 7
Training loss: 3.389733403843627
Validation loss: 2.985604122691764

Epoch: 5| Step: 8
Training loss: 3.4996025677238043
Validation loss: 2.986975223190234

Epoch: 5| Step: 9
Training loss: 2.914620435549918
Validation loss: 2.9871974905010736

Epoch: 5| Step: 10
Training loss: 2.4260937770446236
Validation loss: 2.985756374260952

Epoch: 107| Step: 0
Training loss: 3.3119273140528516
Validation loss: 2.986165226220793

Epoch: 5| Step: 1
Training loss: 2.793283724864041
Validation loss: 2.9859387351749493

Epoch: 5| Step: 2
Training loss: 3.3804335477515544
Validation loss: 2.984935684420906

Epoch: 5| Step: 3
Training loss: 3.505182788561188
Validation loss: 2.9855217976878814

Epoch: 5| Step: 4
Training loss: 3.7236859557658684
Validation loss: 2.984115325569199

Epoch: 5| Step: 5
Training loss: 2.7665701075636413
Validation loss: 2.983155844067285

Epoch: 5| Step: 6
Training loss: 2.72114098305551
Validation loss: 2.9852365741481397

Epoch: 5| Step: 7
Training loss: 3.606645485068953
Validation loss: 2.9819444344232804

Epoch: 5| Step: 8
Training loss: 3.4411772046632594
Validation loss: 2.982481685939398

Epoch: 5| Step: 9
Training loss: 3.3999309196186194
Validation loss: 2.983274293256787

Epoch: 5| Step: 10
Training loss: 3.030234255154753
Validation loss: 2.9842980754009383

Epoch: 108| Step: 0
Training loss: 3.5945944415919753
Validation loss: 2.983135606647164

Epoch: 5| Step: 1
Training loss: 3.094972003076781
Validation loss: 2.9832735645381674

Epoch: 5| Step: 2
Training loss: 2.567575777564346
Validation loss: 2.9829887877833343

Epoch: 5| Step: 3
Training loss: 4.047389406480482
Validation loss: 2.981715485336358

Epoch: 5| Step: 4
Training loss: 2.930281515300387
Validation loss: 2.980654654609607

Epoch: 5| Step: 5
Training loss: 3.329664850180325
Validation loss: 2.9820946634674357

Epoch: 5| Step: 6
Training loss: 2.9565476056038165
Validation loss: 2.981519268576063

Epoch: 5| Step: 7
Training loss: 2.402599687046319
Validation loss: 2.9806628358043725

Epoch: 5| Step: 8
Training loss: 3.420953217115997
Validation loss: 2.9819855597596137

Epoch: 5| Step: 9
Training loss: 3.6604401143509384
Validation loss: 2.9801587851462283

Epoch: 5| Step: 10
Training loss: 3.51969545173983
Validation loss: 2.9821474884821675

Epoch: 109| Step: 0
Training loss: 4.381179804654551
Validation loss: 2.9800639821619694

Epoch: 5| Step: 1
Training loss: 3.141563920449809
Validation loss: 2.9804225279333973

Epoch: 5| Step: 2
Training loss: 3.154365808070308
Validation loss: 2.983668139625059

Epoch: 5| Step: 3
Training loss: 2.772361181170279
Validation loss: 2.980068221538084

Epoch: 5| Step: 4
Training loss: 2.926237063177649
Validation loss: 2.979170398177731

Epoch: 5| Step: 5
Training loss: 3.3460044034847964
Validation loss: 2.9790239329315327

Epoch: 5| Step: 6
Training loss: 3.177874373884822
Validation loss: 2.9780728949519513

Epoch: 5| Step: 7
Training loss: 3.369346687539007
Validation loss: 2.980102141491408

Epoch: 5| Step: 8
Training loss: 2.955050209251406
Validation loss: 2.9773968721187374

Epoch: 5| Step: 9
Training loss: 2.7726650827997514
Validation loss: 2.978386663626949

Epoch: 5| Step: 10
Training loss: 3.584055953389451
Validation loss: 2.978104440221946

Epoch: 110| Step: 0
Training loss: 3.13468500431765
Validation loss: 2.9762827962218754

Epoch: 5| Step: 1
Training loss: 2.775821230917431
Validation loss: 2.9770070951542453

Epoch: 5| Step: 2
Training loss: 3.2263443621404138
Validation loss: 2.9758532764950356

Epoch: 5| Step: 3
Training loss: 3.3936224138925253
Validation loss: 2.9771740496470036

Epoch: 5| Step: 4
Training loss: 3.070161849735179
Validation loss: 2.9848720671543494

Epoch: 5| Step: 5
Training loss: 3.330525137244776
Validation loss: 2.993553915244565

Epoch: 5| Step: 6
Training loss: 3.1859357398880928
Validation loss: 2.9852077707620106

Epoch: 5| Step: 7
Training loss: 3.070931175740155
Validation loss: 2.98139313027266

Epoch: 5| Step: 8
Training loss: 3.6382082010496006
Validation loss: 2.9752915560513484

Epoch: 5| Step: 9
Training loss: 3.616053228315674
Validation loss: 2.974891705057291

Epoch: 5| Step: 10
Training loss: 3.329611719308271
Validation loss: 2.975480286181479

Epoch: 111| Step: 0
Training loss: 2.478427124848256
Validation loss: 2.976148268240674

Epoch: 5| Step: 1
Training loss: 3.308733544216877
Validation loss: 2.975750917886446

Epoch: 5| Step: 2
Training loss: 2.4903413158716523
Validation loss: 2.9755161470164597

Epoch: 5| Step: 3
Training loss: 3.538921968141462
Validation loss: 2.975406034389586

Epoch: 5| Step: 4
Training loss: 4.003655432311666
Validation loss: 2.975597242845979

Epoch: 5| Step: 5
Training loss: 3.5783987148822445
Validation loss: 2.9747544451759778

Epoch: 5| Step: 6
Training loss: 3.4661800727710323
Validation loss: 2.9748774920269696

Epoch: 5| Step: 7
Training loss: 3.3112561751668452
Validation loss: 2.9751709579827113

Epoch: 5| Step: 8
Training loss: 3.469258451570939
Validation loss: 2.9746149476593753

Epoch: 5| Step: 9
Training loss: 2.92802589598914
Validation loss: 2.9739613067598873

Epoch: 5| Step: 10
Training loss: 2.8498349325998524
Validation loss: 2.9739736147832523

Epoch: 112| Step: 0
Training loss: 2.8829304327270626
Validation loss: 2.9740856794149892

Epoch: 5| Step: 1
Training loss: 3.514966572457434
Validation loss: 2.9732444027940113

Epoch: 5| Step: 2
Training loss: 3.500947823931907
Validation loss: 2.9751147777421054

Epoch: 5| Step: 3
Training loss: 3.1160548549715705
Validation loss: 2.9744450164984104

Epoch: 5| Step: 4
Training loss: 2.824939430060103
Validation loss: 2.9754790265383146

Epoch: 5| Step: 5
Training loss: 3.4092781535658463
Validation loss: 2.9742278048505977

Epoch: 5| Step: 6
Training loss: 3.4741273731166897
Validation loss: 2.972813612755887

Epoch: 5| Step: 7
Training loss: 3.1093150377482313
Validation loss: 2.9732768951467228

Epoch: 5| Step: 8
Training loss: 2.8188774705978945
Validation loss: 2.9729803784850555

Epoch: 5| Step: 9
Training loss: 3.707391011957
Validation loss: 2.973246761010629

Epoch: 5| Step: 10
Training loss: 3.2969975019358135
Validation loss: 2.972423811779564

Epoch: 113| Step: 0
Training loss: 3.4497024352521577
Validation loss: 2.9714927201375283

Epoch: 5| Step: 1
Training loss: 4.085254269253997
Validation loss: 2.971159158140134

Epoch: 5| Step: 2
Training loss: 3.8313998169722665
Validation loss: 2.970965335091813

Epoch: 5| Step: 3
Training loss: 2.9299941245791534
Validation loss: 2.9720054613615647

Epoch: 5| Step: 4
Training loss: 3.4510379888344342
Validation loss: 2.9710591064850074

Epoch: 5| Step: 5
Training loss: 2.972209159925364
Validation loss: 2.9703795998690636

Epoch: 5| Step: 6
Training loss: 2.8515867467398093
Validation loss: 2.969077547631582

Epoch: 5| Step: 7
Training loss: 2.892316828329326
Validation loss: 2.971522374262421

Epoch: 5| Step: 8
Training loss: 3.151671610935421
Validation loss: 2.9705543393161413

Epoch: 5| Step: 9
Training loss: 3.1112226814367254
Validation loss: 2.9692374381396807

Epoch: 5| Step: 10
Training loss: 2.6504423492039697
Validation loss: 2.9704725879873526

Epoch: 114| Step: 0
Training loss: 3.201449221035399
Validation loss: 2.9718696631887473

Epoch: 5| Step: 1
Training loss: 3.2266556031323805
Validation loss: 2.9711380098097155

Epoch: 5| Step: 2
Training loss: 3.659320943613935
Validation loss: 2.971799838915966

Epoch: 5| Step: 3
Training loss: 3.3855568411735306
Validation loss: 2.9709390208947153

Epoch: 5| Step: 4
Training loss: 3.0761583891073436
Validation loss: 2.970022070410369

Epoch: 5| Step: 5
Training loss: 3.5841807464935633
Validation loss: 2.970064042727661

Epoch: 5| Step: 6
Training loss: 2.6232892774431478
Validation loss: 2.9712787180120195

Epoch: 5| Step: 7
Training loss: 3.2439004440553325
Validation loss: 2.9766189784725348

Epoch: 5| Step: 8
Training loss: 2.7138974962604503
Validation loss: 2.9738387392391172

Epoch: 5| Step: 9
Training loss: 3.3577446818437084
Validation loss: 2.978579277328078

Epoch: 5| Step: 10
Training loss: 3.565684718736043
Validation loss: 2.9775829926276898

Epoch: 115| Step: 0
Training loss: 3.21453151368563
Validation loss: 2.969528973403149

Epoch: 5| Step: 1
Training loss: 3.437710564839964
Validation loss: 2.968108522704995

Epoch: 5| Step: 2
Training loss: 3.160717814076373
Validation loss: 2.970567705702444

Epoch: 5| Step: 3
Training loss: 2.9521492451102933
Validation loss: 2.9668937384890754

Epoch: 5| Step: 4
Training loss: 3.2921070496406926
Validation loss: 2.966305536453992

Epoch: 5| Step: 5
Training loss: 3.0910996923990672
Validation loss: 2.965182308168869

Epoch: 5| Step: 6
Training loss: 3.43027333185354
Validation loss: 2.966948225296166

Epoch: 5| Step: 7
Training loss: 3.3444618109177897
Validation loss: 2.96698582232048

Epoch: 5| Step: 8
Training loss: 3.4229263711065423
Validation loss: 2.965233779694419

Epoch: 5| Step: 9
Training loss: 3.1066579017460945
Validation loss: 2.9647693762242926

Epoch: 5| Step: 10
Training loss: 3.2107496369066206
Validation loss: 2.9626423000035036

Epoch: 116| Step: 0
Training loss: 3.768611499272151
Validation loss: 2.963258999523944

Epoch: 5| Step: 1
Training loss: 3.2220785467044113
Validation loss: 2.962369623513291

Epoch: 5| Step: 2
Training loss: 3.7013304663829345
Validation loss: 2.965142787902593

Epoch: 5| Step: 3
Training loss: 3.5310506848824734
Validation loss: 2.9637437492701864

Epoch: 5| Step: 4
Training loss: 2.41589680828997
Validation loss: 2.9652328658478995

Epoch: 5| Step: 5
Training loss: 2.758076857737296
Validation loss: 2.9634872792839433

Epoch: 5| Step: 6
Training loss: 3.7585240441857835
Validation loss: 2.964577399350027

Epoch: 5| Step: 7
Training loss: 3.2150812072939354
Validation loss: 2.9629690770294945

Epoch: 5| Step: 8
Training loss: 3.4652371876661876
Validation loss: 2.9626227678827424

Epoch: 5| Step: 9
Training loss: 2.5604433319549065
Validation loss: 2.9631198831106764

Epoch: 5| Step: 10
Training loss: 2.8781324819328815
Validation loss: 2.9663611930080562

Epoch: 117| Step: 0
Training loss: 3.011494391924915
Validation loss: 2.978981088586079

Epoch: 5| Step: 1
Training loss: 3.995228066743856
Validation loss: 2.9785769259154318

Epoch: 5| Step: 2
Training loss: 3.822530839594799
Validation loss: 2.969100082645221

Epoch: 5| Step: 3
Training loss: 2.8623400047932024
Validation loss: 2.96210469393712

Epoch: 5| Step: 4
Training loss: 2.674016261813833
Validation loss: 2.9613292994516636

Epoch: 5| Step: 5
Training loss: 2.602968311517011
Validation loss: 2.961969348905171

Epoch: 5| Step: 6
Training loss: 3.4577122938803013
Validation loss: 2.963419392561115

Epoch: 5| Step: 7
Training loss: 3.374100459278259
Validation loss: 2.9669290861609614

Epoch: 5| Step: 8
Training loss: 3.313750696689413
Validation loss: 2.9649680874899063

Epoch: 5| Step: 9
Training loss: 3.1759316947183547
Validation loss: 2.9667100012327574

Epoch: 5| Step: 10
Training loss: 3.1451341134057533
Validation loss: 2.966949960341236

Epoch: 118| Step: 0
Training loss: 3.4860957391475127
Validation loss: 2.9668422853928584

Epoch: 5| Step: 1
Training loss: 2.9304790597325976
Validation loss: 2.9644984615020444

Epoch: 5| Step: 2
Training loss: 3.6997106078101525
Validation loss: 2.964035739252771

Epoch: 5| Step: 3
Training loss: 3.500796908526825
Validation loss: 2.9625285217731516

Epoch: 5| Step: 4
Training loss: 3.1357113181192324
Validation loss: 2.961471625028692

Epoch: 5| Step: 5
Training loss: 3.1532986883259015
Validation loss: 2.962615327782673

Epoch: 5| Step: 6
Training loss: 2.8101702047366888
Validation loss: 2.9616807275454096

Epoch: 5| Step: 7
Training loss: 2.8124866909136053
Validation loss: 2.959554757771286

Epoch: 5| Step: 8
Training loss: 3.2216135268574138
Validation loss: 2.9611787857074194

Epoch: 5| Step: 9
Training loss: 3.100954702480108
Validation loss: 2.9611343706660627

Epoch: 5| Step: 10
Training loss: 3.7665415554592605
Validation loss: 2.961907699078982

Epoch: 119| Step: 0
Training loss: 3.0454108999843768
Validation loss: 2.9614889434605676

Epoch: 5| Step: 1
Training loss: 3.3531979569802153
Validation loss: 2.9627795179154734

Epoch: 5| Step: 2
Training loss: 3.9960920794381893
Validation loss: 2.9630164036993207

Epoch: 5| Step: 3
Training loss: 2.9357307462790994
Validation loss: 2.9641411870174132

Epoch: 5| Step: 4
Training loss: 3.4114751373731336
Validation loss: 2.9636361533308917

Epoch: 5| Step: 5
Training loss: 2.2859811712175437
Validation loss: 2.9632105425088606

Epoch: 5| Step: 6
Training loss: 3.6868888219175613
Validation loss: 2.9673337216767566

Epoch: 5| Step: 7
Training loss: 3.49968227579221
Validation loss: 2.965060351306647

Epoch: 5| Step: 8
Training loss: 3.0781377027220445
Validation loss: 2.9595997387667974

Epoch: 5| Step: 9
Training loss: 2.913184803363385
Validation loss: 2.9605845921442984

Epoch: 5| Step: 10
Training loss: 3.123030843210493
Validation loss: 2.958930107167868

Epoch: 120| Step: 0
Training loss: 2.967682656609665
Validation loss: 2.958354955649372

Epoch: 5| Step: 1
Training loss: 3.370462546370937
Validation loss: 2.9568876043918983

Epoch: 5| Step: 2
Training loss: 2.986547508190144
Validation loss: 2.957450636798647

Epoch: 5| Step: 3
Training loss: 3.2726494835268882
Validation loss: 2.9588179675918065

Epoch: 5| Step: 4
Training loss: 3.5964055077241732
Validation loss: 2.956147247723086

Epoch: 5| Step: 5
Training loss: 2.7283571124880557
Validation loss: 2.9582300186892767

Epoch: 5| Step: 6
Training loss: 3.2607905911819937
Validation loss: 2.9574471859010405

Epoch: 5| Step: 7
Training loss: 3.0063745801970647
Validation loss: 2.9579494480865764

Epoch: 5| Step: 8
Training loss: 3.5374757691756535
Validation loss: 2.9570226930496184

Epoch: 5| Step: 9
Training loss: 3.2439296959292054
Validation loss: 2.9565704780415816

Epoch: 5| Step: 10
Training loss: 3.6224368011037438
Validation loss: 2.9571862175484176

Epoch: 121| Step: 0
Training loss: 2.91909510922715
Validation loss: 2.955100948084379

Epoch: 5| Step: 1
Training loss: 3.49145554759334
Validation loss: 2.9546412147741288

Epoch: 5| Step: 2
Training loss: 3.285179618906553
Validation loss: 2.9567630823030644

Epoch: 5| Step: 3
Training loss: 3.3192202937066857
Validation loss: 2.954530097688601

Epoch: 5| Step: 4
Training loss: 2.669486601257709
Validation loss: 2.955580421135699

Epoch: 5| Step: 5
Training loss: 2.7049887521901264
Validation loss: 2.955876681526429

Epoch: 5| Step: 6
Training loss: 3.4266899060847886
Validation loss: 2.9552489346968134

Epoch: 5| Step: 7
Training loss: 3.3975007969600592
Validation loss: 2.954646887566582

Epoch: 5| Step: 8
Training loss: 3.0897383448855273
Validation loss: 2.953929480111338

Epoch: 5| Step: 9
Training loss: 3.635690381841158
Validation loss: 2.95626449402766

Epoch: 5| Step: 10
Training loss: 3.5433096422017676
Validation loss: 2.9594286205806113

Epoch: 122| Step: 0
Training loss: 3.2485230831378877
Validation loss: 2.954788037504318

Epoch: 5| Step: 1
Training loss: 2.7670869573144246
Validation loss: 2.9553866025770033

Epoch: 5| Step: 2
Training loss: 3.2727256856779623
Validation loss: 2.9543272393567026

Epoch: 5| Step: 3
Training loss: 2.7681000405187794
Validation loss: 2.9561382910242564

Epoch: 5| Step: 4
Training loss: 2.8523942962238533
Validation loss: 2.95706652656843

Epoch: 5| Step: 5
Training loss: 3.2503606156040172
Validation loss: 2.955676750154535

Epoch: 5| Step: 6
Training loss: 3.200734805141888
Validation loss: 2.955112592057773

Epoch: 5| Step: 7
Training loss: 3.5677926083748916
Validation loss: 2.954945411361835

Epoch: 5| Step: 8
Training loss: 3.3095295380990035
Validation loss: 2.954894496339877

Epoch: 5| Step: 9
Training loss: 3.608713328826278
Validation loss: 2.953372741575552

Epoch: 5| Step: 10
Training loss: 3.656455531415999
Validation loss: 2.952686771037158

Epoch: 123| Step: 0
Training loss: 3.1285131924329566
Validation loss: 2.9524467988627197

Epoch: 5| Step: 1
Training loss: 3.8576317684192944
Validation loss: 2.9526180776974047

Epoch: 5| Step: 2
Training loss: 2.879085126311965
Validation loss: 2.9509976202025077

Epoch: 5| Step: 3
Training loss: 3.3665443744417582
Validation loss: 2.9511154029434614

Epoch: 5| Step: 4
Training loss: 2.982243920433799
Validation loss: 2.9516047371085032

Epoch: 5| Step: 5
Training loss: 3.29414855167173
Validation loss: 2.9500553123832316

Epoch: 5| Step: 6
Training loss: 2.6828079961206828
Validation loss: 2.9507867511015102

Epoch: 5| Step: 7
Training loss: 3.120303172029278
Validation loss: 2.951273021285501

Epoch: 5| Step: 8
Training loss: 3.0089370805038698
Validation loss: 2.94976360457734

Epoch: 5| Step: 9
Training loss: 3.440838666304926
Validation loss: 2.9504888074999966

Epoch: 5| Step: 10
Training loss: 3.712205401204904
Validation loss: 2.9488912899206015

Epoch: 124| Step: 0
Training loss: 2.7803477849154463
Validation loss: 2.950401144213329

Epoch: 5| Step: 1
Training loss: 3.566126800987
Validation loss: 2.950000331065926

Epoch: 5| Step: 2
Training loss: 3.3974116739296285
Validation loss: 2.951346592046108

Epoch: 5| Step: 3
Training loss: 3.3965497967570837
Validation loss: 2.948629450432875

Epoch: 5| Step: 4
Training loss: 3.7491566027486227
Validation loss: 2.955227571012221

Epoch: 5| Step: 5
Training loss: 3.5539638579188666
Validation loss: 2.953702482235395

Epoch: 5| Step: 6
Training loss: 3.0599058413510978
Validation loss: 2.961216670686575

Epoch: 5| Step: 7
Training loss: 2.7708153592628566
Validation loss: 2.961504967637704

Epoch: 5| Step: 8
Training loss: 2.9325828791595385
Validation loss: 2.9487197172350506

Epoch: 5| Step: 9
Training loss: 3.238399784141277
Validation loss: 2.9475871200897785

Epoch: 5| Step: 10
Training loss: 2.8976401494438444
Validation loss: 2.9470518113141866

Epoch: 125| Step: 0
Training loss: 2.902628621513388
Validation loss: 2.946207233910935

Epoch: 5| Step: 1
Training loss: 3.164765004478111
Validation loss: 2.946192785043711

Epoch: 5| Step: 2
Training loss: 3.4373909672871523
Validation loss: 2.952687199947665

Epoch: 5| Step: 3
Training loss: 4.086797270023255
Validation loss: 2.947155776459503

Epoch: 5| Step: 4
Training loss: 2.5641746631291418
Validation loss: 2.958879111687972

Epoch: 5| Step: 5
Training loss: 3.438062171049906
Validation loss: 2.9660311832716983

Epoch: 5| Step: 6
Training loss: 3.08111194974522
Validation loss: 2.95494655482719

Epoch: 5| Step: 7
Training loss: 3.712749095227984
Validation loss: 2.9503919528418656

Epoch: 5| Step: 8
Training loss: 3.1729862164601648
Validation loss: 2.948525172073923

Epoch: 5| Step: 9
Training loss: 2.8885280942179574
Validation loss: 2.9469524513907612

Epoch: 5| Step: 10
Training loss: 2.7923460366230812
Validation loss: 2.9457885465405287

Epoch: 126| Step: 0
Training loss: 3.6991045409540977
Validation loss: 2.9448023550369333

Epoch: 5| Step: 1
Training loss: 3.014478238129567
Validation loss: 2.945616755706254

Epoch: 5| Step: 2
Training loss: 2.697958711470817
Validation loss: 2.945261557721586

Epoch: 5| Step: 3
Training loss: 3.7115953364296397
Validation loss: 2.945025656832968

Epoch: 5| Step: 4
Training loss: 2.708806060224988
Validation loss: 2.9441415641670288

Epoch: 5| Step: 5
Training loss: 2.313632378538133
Validation loss: 2.943229007349485

Epoch: 5| Step: 6
Training loss: 2.9752817677650656
Validation loss: 2.9453552021913088

Epoch: 5| Step: 7
Training loss: 3.133262088317368
Validation loss: 2.945051961441411

Epoch: 5| Step: 8
Training loss: 3.8396015886413357
Validation loss: 2.946385778819455

Epoch: 5| Step: 9
Training loss: 3.4410098104073787
Validation loss: 2.945442885100753

Epoch: 5| Step: 10
Training loss: 3.670010486972388
Validation loss: 2.9436168183404448

Epoch: 127| Step: 0
Training loss: 3.191148352970909
Validation loss: 2.9445644096762984

Epoch: 5| Step: 1
Training loss: 3.17324138206274
Validation loss: 2.9463109947965176

Epoch: 5| Step: 2
Training loss: 3.6559168998072016
Validation loss: 2.9454607973692677

Epoch: 5| Step: 3
Training loss: 2.7256568781915775
Validation loss: 2.961154778361648

Epoch: 5| Step: 4
Training loss: 3.456790411367186
Validation loss: 2.9599913324762968

Epoch: 5| Step: 5
Training loss: 3.1972909785379917
Validation loss: 2.9559137402828797

Epoch: 5| Step: 6
Training loss: 4.056828222221071
Validation loss: 2.960436932002972

Epoch: 5| Step: 7
Training loss: 2.376943997292715
Validation loss: 2.946436644235309

Epoch: 5| Step: 8
Training loss: 2.7833335872657643
Validation loss: 2.9423533944396576

Epoch: 5| Step: 9
Training loss: 3.4583574929982936
Validation loss: 2.9398948474083157

Epoch: 5| Step: 10
Training loss: 3.109287433253853
Validation loss: 2.93957758149343

Epoch: 128| Step: 0
Training loss: 2.8267793773576306
Validation loss: 2.9421612802334574

Epoch: 5| Step: 1
Training loss: 2.853752904448533
Validation loss: 2.941513112965887

Epoch: 5| Step: 2
Training loss: 3.5423580766352556
Validation loss: 2.9407153766456497

Epoch: 5| Step: 3
Training loss: 3.478997293030995
Validation loss: 2.940021280294415

Epoch: 5| Step: 4
Training loss: 3.2026560370305646
Validation loss: 2.941733532370796

Epoch: 5| Step: 5
Training loss: 4.077431806208087
Validation loss: 2.9396464461320932

Epoch: 5| Step: 6
Training loss: 3.134062481985835
Validation loss: 2.9407037332025663

Epoch: 5| Step: 7
Training loss: 3.7650860285967402
Validation loss: 2.9398688960440635

Epoch: 5| Step: 8
Training loss: 2.831662489461559
Validation loss: 2.9396068267489284

Epoch: 5| Step: 9
Training loss: 2.2859567658348467
Validation loss: 2.9397953467495626

Epoch: 5| Step: 10
Training loss: 3.117259701153177
Validation loss: 2.939914521808075

Epoch: 129| Step: 0
Training loss: 3.1451144039044845
Validation loss: 2.9393580627277873

Epoch: 5| Step: 1
Training loss: 2.661360099955382
Validation loss: 2.9380244535476177

Epoch: 5| Step: 2
Training loss: 3.277699029554838
Validation loss: 2.9386200699252036

Epoch: 5| Step: 3
Training loss: 3.381383439849015
Validation loss: 2.938607589400352

Epoch: 5| Step: 4
Training loss: 3.8336509213674965
Validation loss: 2.939195323940582

Epoch: 5| Step: 5
Training loss: 2.769908626440252
Validation loss: 2.9394863728700766

Epoch: 5| Step: 6
Training loss: 3.522048168782286
Validation loss: 2.937819583729908

Epoch: 5| Step: 7
Training loss: 3.5132876616036253
Validation loss: 2.9389895221447357

Epoch: 5| Step: 8
Training loss: 3.11939774936214
Validation loss: 2.936766552740176

Epoch: 5| Step: 9
Training loss: 2.6822193518708146
Validation loss: 2.9383506494509444

Epoch: 5| Step: 10
Training loss: 3.354961956507742
Validation loss: 2.9392584810987645

Epoch: 130| Step: 0
Training loss: 2.928752129326444
Validation loss: 2.9398635418026355

Epoch: 5| Step: 1
Training loss: 3.8941862054867036
Validation loss: 2.943136744668288

Epoch: 5| Step: 2
Training loss: 3.9463736438442587
Validation loss: 2.9435627357514154

Epoch: 5| Step: 3
Training loss: 3.2412187346904555
Validation loss: 2.94444181301933

Epoch: 5| Step: 4
Training loss: 3.0469652993930807
Validation loss: 2.9433515883267884

Epoch: 5| Step: 5
Training loss: 3.367251650028786
Validation loss: 2.9432939083825556

Epoch: 5| Step: 6
Training loss: 2.835192537850749
Validation loss: 2.9440521618829694

Epoch: 5| Step: 7
Training loss: 3.224843599533949
Validation loss: 2.93745067121271

Epoch: 5| Step: 8
Training loss: 2.8458128772482585
Validation loss: 2.936427291221038

Epoch: 5| Step: 9
Training loss: 3.143423475292429
Validation loss: 2.9353426462427863

Epoch: 5| Step: 10
Training loss: 2.631993559751197
Validation loss: 2.9334294381950032

Epoch: 131| Step: 0
Training loss: 2.817279484538274
Validation loss: 2.9344569082923266

Epoch: 5| Step: 1
Training loss: 3.3320570091691883
Validation loss: 2.9348563877060183

Epoch: 5| Step: 2
Training loss: 3.1994700350603416
Validation loss: 2.9342406305365207

Epoch: 5| Step: 3
Training loss: 3.0459937753094035
Validation loss: 2.9332540786874546

Epoch: 5| Step: 4
Training loss: 3.4400167788606457
Validation loss: 2.9343748676932067

Epoch: 5| Step: 5
Training loss: 3.4388372421152456
Validation loss: 2.933239094056125

Epoch: 5| Step: 6
Training loss: 3.400697154208759
Validation loss: 2.9343873994195238

Epoch: 5| Step: 7
Training loss: 2.970728004446689
Validation loss: 2.934245081151565

Epoch: 5| Step: 8
Training loss: 3.432485217057726
Validation loss: 2.9335954881683177

Epoch: 5| Step: 9
Training loss: 3.0457346811943387
Validation loss: 2.934052764565476

Epoch: 5| Step: 10
Training loss: 3.2568557029478935
Validation loss: 2.93279105623601

Epoch: 132| Step: 0
Training loss: 3.082050434628187
Validation loss: 2.9354583873395383

Epoch: 5| Step: 1
Training loss: 3.4629250496209116
Validation loss: 2.9349660021639496

Epoch: 5| Step: 2
Training loss: 3.006455152336022
Validation loss: 2.93383858345344

Epoch: 5| Step: 3
Training loss: 3.1888779298488443
Validation loss: 2.9326486648701064

Epoch: 5| Step: 4
Training loss: 3.0407129821907684
Validation loss: 2.932377715718711

Epoch: 5| Step: 5
Training loss: 3.4302376064824243
Validation loss: 2.9312952752625367

Epoch: 5| Step: 6
Training loss: 3.2868472361403023
Validation loss: 2.933364593769514

Epoch: 5| Step: 7
Training loss: 2.875556228568175
Validation loss: 2.9361511394089836

Epoch: 5| Step: 8
Training loss: 2.9648638537382475
Validation loss: 2.935553223952362

Epoch: 5| Step: 9
Training loss: 3.473503910447425
Validation loss: 2.9356680302040483

Epoch: 5| Step: 10
Training loss: 3.5999948395586117
Validation loss: 2.943152515988823

Epoch: 133| Step: 0
Training loss: 3.015003832155136
Validation loss: 2.932775706473104

Epoch: 5| Step: 1
Training loss: 2.776155585169687
Validation loss: 2.9291642371599527

Epoch: 5| Step: 2
Training loss: 3.0552253737409596
Validation loss: 2.9297567511136546

Epoch: 5| Step: 3
Training loss: 3.080441295666873
Validation loss: 2.9288675820492913

Epoch: 5| Step: 4
Training loss: 3.361133204055631
Validation loss: 2.9284044814641534

Epoch: 5| Step: 5
Training loss: 2.983653835222018
Validation loss: 2.929216407226706

Epoch: 5| Step: 6
Training loss: 2.9103740021826345
Validation loss: 2.928255248512213

Epoch: 5| Step: 7
Training loss: 3.722159481626901
Validation loss: 2.9295962022344795

Epoch: 5| Step: 8
Training loss: 3.5882806706111414
Validation loss: 2.927611530671666

Epoch: 5| Step: 9
Training loss: 3.7079774635807
Validation loss: 2.9287239608954065

Epoch: 5| Step: 10
Training loss: 2.951113384078707
Validation loss: 2.9286201275127977

Epoch: 134| Step: 0
Training loss: 3.4121782703136834
Validation loss: 2.927959767382478

Epoch: 5| Step: 1
Training loss: 3.4239044442078703
Validation loss: 2.9286007160094205

Epoch: 5| Step: 2
Training loss: 3.0468307100647154
Validation loss: 2.9263978594217424

Epoch: 5| Step: 3
Training loss: 2.888770751086272
Validation loss: 2.928704566711883

Epoch: 5| Step: 4
Training loss: 2.790892185180312
Validation loss: 2.9283142660452897

Epoch: 5| Step: 5
Training loss: 2.777932063162522
Validation loss: 2.9273673135729656

Epoch: 5| Step: 6
Training loss: 3.4241297709214162
Validation loss: 2.924531811564577

Epoch: 5| Step: 7
Training loss: 2.76163708081817
Validation loss: 2.9261553011400356

Epoch: 5| Step: 8
Training loss: 3.889593393605317
Validation loss: 2.92707927588112

Epoch: 5| Step: 9
Training loss: 3.3084336279232707
Validation loss: 2.9273088129178473

Epoch: 5| Step: 10
Training loss: 3.4751420794744754
Validation loss: 2.9270476037378383

Epoch: 135| Step: 0
Training loss: 2.9200654163610165
Validation loss: 2.927255311819188

Epoch: 5| Step: 1
Training loss: 3.1567950391866737
Validation loss: 2.9272656766934384

Epoch: 5| Step: 2
Training loss: 3.3548522311782962
Validation loss: 2.9262304644767845

Epoch: 5| Step: 3
Training loss: 2.7005803473501575
Validation loss: 2.9268768982795064

Epoch: 5| Step: 4
Training loss: 3.6585442281658698
Validation loss: 2.928608555033375

Epoch: 5| Step: 5
Training loss: 3.136995562242914
Validation loss: 2.9289819886540154

Epoch: 5| Step: 6
Training loss: 2.7829764504733343
Validation loss: 2.9280473093003554

Epoch: 5| Step: 7
Training loss: 3.2289075850053193
Validation loss: 2.930899231728063

Epoch: 5| Step: 8
Training loss: 3.4440202776569997
Validation loss: 2.927567537229145

Epoch: 5| Step: 9
Training loss: 3.115226415546258
Validation loss: 2.9270593312817628

Epoch: 5| Step: 10
Training loss: 3.761798861750789
Validation loss: 2.9265841985169594

Epoch: 136| Step: 0
Training loss: 2.9303173151146518
Validation loss: 2.926036523309431

Epoch: 5| Step: 1
Training loss: 2.9198763126148406
Validation loss: 2.926224922327519

Epoch: 5| Step: 2
Training loss: 3.063872049453894
Validation loss: 2.9270486547519066

Epoch: 5| Step: 3
Training loss: 3.342322784724725
Validation loss: 2.928330195987872

Epoch: 5| Step: 4
Training loss: 3.232101157144474
Validation loss: 2.933984842504254

Epoch: 5| Step: 5
Training loss: 3.1733931492796508
Validation loss: 2.9285522418379615

Epoch: 5| Step: 6
Training loss: 3.308103991293489
Validation loss: 2.930323248462927

Epoch: 5| Step: 7
Training loss: 4.19728607414167
Validation loss: 2.926685647957818

Epoch: 5| Step: 8
Training loss: 2.794986449534644
Validation loss: 2.925519175345544

Epoch: 5| Step: 9
Training loss: 3.4220433302632536
Validation loss: 2.924929923301503

Epoch: 5| Step: 10
Training loss: 2.645950815390993
Validation loss: 2.9243949660541912

Epoch: 137| Step: 0
Training loss: 3.4165799354771975
Validation loss: 2.9226821811907175

Epoch: 5| Step: 1
Training loss: 3.2914380988104246
Validation loss: 2.925819584562105

Epoch: 5| Step: 2
Training loss: 3.245888970958802
Validation loss: 2.9272007762995873

Epoch: 5| Step: 3
Training loss: 2.6423397478289092
Validation loss: 2.9255245873866107

Epoch: 5| Step: 4
Training loss: 3.1799491755904494
Validation loss: 2.9253862779407847

Epoch: 5| Step: 5
Training loss: 3.4304835062702157
Validation loss: 2.9249011316901066

Epoch: 5| Step: 6
Training loss: 2.6700511753164196
Validation loss: 2.9230716569650976

Epoch: 5| Step: 7
Training loss: 3.3604975754295334
Validation loss: 2.9232842262281693

Epoch: 5| Step: 8
Training loss: 3.330277011335394
Validation loss: 2.922385761111027

Epoch: 5| Step: 9
Training loss: 3.4713889041811874
Validation loss: 2.9222985996402273

Epoch: 5| Step: 10
Training loss: 3.1716858755770505
Validation loss: 2.922753030644196

Epoch: 138| Step: 0
Training loss: 3.640989359030488
Validation loss: 2.9247536869215534

Epoch: 5| Step: 1
Training loss: 2.822154788048501
Validation loss: 2.9259863739285175

Epoch: 5| Step: 2
Training loss: 3.248249756423071
Validation loss: 2.92440166883342

Epoch: 5| Step: 3
Training loss: 3.1375902991199847
Validation loss: 2.9209910901549487

Epoch: 5| Step: 4
Training loss: 3.4604659954109516
Validation loss: 2.9235806700848066

Epoch: 5| Step: 5
Training loss: 2.7828250668395627
Validation loss: 2.9233608165177816

Epoch: 5| Step: 6
Training loss: 2.9261647114470617
Validation loss: 2.9238121266878525

Epoch: 5| Step: 7
Training loss: 3.220776854920927
Validation loss: 2.9236513232693557

Epoch: 5| Step: 8
Training loss: 3.4591310492617646
Validation loss: 2.9210533279604203

Epoch: 5| Step: 9
Training loss: 3.3747035708761413
Validation loss: 2.922179454493262

Epoch: 5| Step: 10
Training loss: 3.107730603181866
Validation loss: 2.919914866934379

Epoch: 139| Step: 0
Training loss: 2.883149910386506
Validation loss: 2.919421733270401

Epoch: 5| Step: 1
Training loss: 2.347049882369267
Validation loss: 2.9179193229743037

Epoch: 5| Step: 2
Training loss: 3.984149043838047
Validation loss: 2.9193110073776127

Epoch: 5| Step: 3
Training loss: 3.6026109340299555
Validation loss: 2.918490542467015

Epoch: 5| Step: 4
Training loss: 3.102120375726978
Validation loss: 2.9208658890971506

Epoch: 5| Step: 5
Training loss: 3.516360600125816
Validation loss: 2.9214074212175536

Epoch: 5| Step: 6
Training loss: 3.3429082363541736
Validation loss: 2.918858511157694

Epoch: 5| Step: 7
Training loss: 2.7884914123391975
Validation loss: 2.919544720234956

Epoch: 5| Step: 8
Training loss: 2.953957092283461
Validation loss: 2.9206711896934228

Epoch: 5| Step: 9
Training loss: 2.951064263735422
Validation loss: 2.9220560423669886

Epoch: 5| Step: 10
Training loss: 3.5143696217815474
Validation loss: 2.92107418593834

Epoch: 140| Step: 0
Training loss: 2.785855626792914
Validation loss: 2.922262965652011

Epoch: 5| Step: 1
Training loss: 3.265949433925157
Validation loss: 2.920400689214287

Epoch: 5| Step: 2
Training loss: 3.3134364118091266
Validation loss: 2.9209969191361975

Epoch: 5| Step: 3
Training loss: 3.292347769147089
Validation loss: 2.91653067246855

Epoch: 5| Step: 4
Training loss: 3.1926259729778117
Validation loss: 2.9171421425231827

Epoch: 5| Step: 5
Training loss: 2.402414708523942
Validation loss: 2.914865995030174

Epoch: 5| Step: 6
Training loss: 2.514776051070181
Validation loss: 2.918381266696759

Epoch: 5| Step: 7
Training loss: 3.0991044381371604
Validation loss: 2.9156513034739446

Epoch: 5| Step: 8
Training loss: 3.7527614598484575
Validation loss: 2.9145605531565586

Epoch: 5| Step: 9
Training loss: 3.2548272888959855
Validation loss: 2.913756326335518

Epoch: 5| Step: 10
Training loss: 4.143965845254488
Validation loss: 2.916158977101247

Epoch: 141| Step: 0
Training loss: 2.8656748593650967
Validation loss: 2.9142526592419036

Epoch: 5| Step: 1
Training loss: 3.676136157813153
Validation loss: 2.9141615931290796

Epoch: 5| Step: 2
Training loss: 3.950591711801164
Validation loss: 2.9119140672189285

Epoch: 5| Step: 3
Training loss: 3.605883209774573
Validation loss: 2.9147410920209342

Epoch: 5| Step: 4
Training loss: 2.5166210785161978
Validation loss: 2.914599318526723

Epoch: 5| Step: 5
Training loss: 2.9373086095916032
Validation loss: 2.913926954074317

Epoch: 5| Step: 6
Training loss: 2.6824639619964454
Validation loss: 2.9145451847857666

Epoch: 5| Step: 7
Training loss: 3.284716128737264
Validation loss: 2.9148734461911334

Epoch: 5| Step: 8
Training loss: 2.894287758082619
Validation loss: 2.9176093829600678

Epoch: 5| Step: 9
Training loss: 3.360094428097946
Validation loss: 2.9187347135560513

Epoch: 5| Step: 10
Training loss: 3.111186511019173
Validation loss: 2.9121832238604344

Epoch: 142| Step: 0
Training loss: 3.115589315349728
Validation loss: 2.912550949009474

Epoch: 5| Step: 1
Training loss: 2.929213177748974
Validation loss: 2.9118858362693834

Epoch: 5| Step: 2
Training loss: 3.5382824305429
Validation loss: 2.912487959129389

Epoch: 5| Step: 3
Training loss: 2.432656488824686
Validation loss: 2.912999128773588

Epoch: 5| Step: 4
Training loss: 2.7370596649111336
Validation loss: 2.9125397219786335

Epoch: 5| Step: 5
Training loss: 3.069323975129807
Validation loss: 2.9132315792013586

Epoch: 5| Step: 6
Training loss: 3.0714559585516223
Validation loss: 2.912715503885213

Epoch: 5| Step: 7
Training loss: 3.5228406311769054
Validation loss: 2.911023314251448

Epoch: 5| Step: 8
Training loss: 3.962151756988891
Validation loss: 2.9128433365287005

Epoch: 5| Step: 9
Training loss: 2.899532306710213
Validation loss: 2.9127602875792786

Epoch: 5| Step: 10
Training loss: 3.7250566619045427
Validation loss: 2.9100345013225954

Epoch: 143| Step: 0
Training loss: 3.1795235856380146
Validation loss: 2.910763860107448

Epoch: 5| Step: 1
Training loss: 3.282819390777662
Validation loss: 2.9085400957741476

Epoch: 5| Step: 2
Training loss: 2.6295296778609876
Validation loss: 2.9105987544953145

Epoch: 5| Step: 3
Training loss: 3.1073156850570496
Validation loss: 2.909164958675158

Epoch: 5| Step: 4
Training loss: 3.5461970954420567
Validation loss: 2.9100799050605595

Epoch: 5| Step: 5
Training loss: 3.242777207759583
Validation loss: 2.910636712986238

Epoch: 5| Step: 6
Training loss: 3.410452673614581
Validation loss: 2.9111006110828948

Epoch: 5| Step: 7
Training loss: 3.5905354594062855
Validation loss: 2.909922177787639

Epoch: 5| Step: 8
Training loss: 2.8920350630706873
Validation loss: 2.911683554292889

Epoch: 5| Step: 9
Training loss: 3.0555635644827026
Validation loss: 2.9203008228248217

Epoch: 5| Step: 10
Training loss: 3.1748907475935724
Validation loss: 2.9186156785296826

Epoch: 144| Step: 0
Training loss: 2.819706056439298
Validation loss: 2.9129518572363624

Epoch: 5| Step: 1
Training loss: 3.780555472154793
Validation loss: 2.9132025250122244

Epoch: 5| Step: 2
Training loss: 4.0142154817396
Validation loss: 2.9140543922312183

Epoch: 5| Step: 3
Training loss: 3.431973818396803
Validation loss: 2.9156943117009715

Epoch: 5| Step: 4
Training loss: 2.9788497187114826
Validation loss: 2.9181254897576903

Epoch: 5| Step: 5
Training loss: 2.7716747430931075
Validation loss: 2.9152369257349573

Epoch: 5| Step: 6
Training loss: 2.949187383421776
Validation loss: 2.914615334863437

Epoch: 5| Step: 7
Training loss: 2.9169083268096925
Validation loss: 2.9139325442477255

Epoch: 5| Step: 8
Training loss: 3.0374472279929075
Validation loss: 2.9146092279252875

Epoch: 5| Step: 9
Training loss: 2.5986662084475656
Validation loss: 2.9145940119798044

Epoch: 5| Step: 10
Training loss: 3.65619444193566
Validation loss: 2.909953144763165

Epoch: 145| Step: 0
Training loss: 2.950986703633958
Validation loss: 2.91151451033015

Epoch: 5| Step: 1
Training loss: 3.100084697427731
Validation loss: 2.9090726907693107

Epoch: 5| Step: 2
Training loss: 3.175006091494987
Validation loss: 2.9091382238257837

Epoch: 5| Step: 3
Training loss: 3.0033991947495857
Validation loss: 2.9080442160124202

Epoch: 5| Step: 4
Training loss: 3.534669958568044
Validation loss: 2.907350470964105

Epoch: 5| Step: 5
Training loss: 2.440566652506575
Validation loss: 2.9076956175819113

Epoch: 5| Step: 6
Training loss: 3.5459312494178654
Validation loss: 2.9079860865573006

Epoch: 5| Step: 7
Training loss: 3.675591069651752
Validation loss: 2.9075445563920237

Epoch: 5| Step: 8
Training loss: 3.474794636977132
Validation loss: 2.905889204893197

Epoch: 5| Step: 9
Training loss: 2.845588006261517
Validation loss: 2.9064929625516744

Epoch: 5| Step: 10
Training loss: 3.2781622027239843
Validation loss: 2.9065632734535347

Epoch: 146| Step: 0
Training loss: 2.132823678570751
Validation loss: 2.9061232446679903

Epoch: 5| Step: 1
Training loss: 3.2031430127637583
Validation loss: 2.905875714798708

Epoch: 5| Step: 2
Training loss: 3.6287437049424787
Validation loss: 2.9100704039780148

Epoch: 5| Step: 3
Training loss: 2.970800073409834
Validation loss: 2.906746585377028

Epoch: 5| Step: 4
Training loss: 3.567711214310348
Validation loss: 2.909814046277453

Epoch: 5| Step: 5
Training loss: 3.2239129592751
Validation loss: 2.905247028630989

Epoch: 5| Step: 6
Training loss: 3.195555735985838
Validation loss: 2.905127250348698

Epoch: 5| Step: 7
Training loss: 3.449610237550849
Validation loss: 2.9076179375076

Epoch: 5| Step: 8
Training loss: 3.192032228522263
Validation loss: 2.9048383647278078

Epoch: 5| Step: 9
Training loss: 3.2545122953772534
Validation loss: 2.905543346943152

Epoch: 5| Step: 10
Training loss: 3.071785997903979
Validation loss: 2.9071324341089344

Epoch: 147| Step: 0
Training loss: 3.0808539517116587
Validation loss: 2.904779666294363

Epoch: 5| Step: 1
Training loss: 3.2542507543376145
Validation loss: 2.9070771736392844

Epoch: 5| Step: 2
Training loss: 3.5724695813837393
Validation loss: 2.9108854232745616

Epoch: 5| Step: 3
Training loss: 3.252633128509386
Validation loss: 2.9137667330696067

Epoch: 5| Step: 4
Training loss: 2.9826049348800456
Validation loss: 2.9069682528340053

Epoch: 5| Step: 5
Training loss: 3.454306421953688
Validation loss: 2.906013044227991

Epoch: 5| Step: 6
Training loss: 2.9642978411900818
Validation loss: 2.904825103627781

Epoch: 5| Step: 7
Training loss: 3.043876385267888
Validation loss: 2.900734045588265

Epoch: 5| Step: 8
Training loss: 3.180286397932736
Validation loss: 2.898837180807309

Epoch: 5| Step: 9
Training loss: 3.014150624744467
Validation loss: 2.8990057064989636

Epoch: 5| Step: 10
Training loss: 3.2790720659801917
Validation loss: 2.900237289921507

Epoch: 148| Step: 0
Training loss: 3.0734984973154758
Validation loss: 2.8999312319467987

Epoch: 5| Step: 1
Training loss: 3.3841830465982925
Validation loss: 2.901509758630101

Epoch: 5| Step: 2
Training loss: 3.046799565873097
Validation loss: 2.9031935599460694

Epoch: 5| Step: 3
Training loss: 2.8183365343084343
Validation loss: 2.903878422732626

Epoch: 5| Step: 4
Training loss: 3.488593998437981
Validation loss: 2.900008250703203

Epoch: 5| Step: 5
Training loss: 2.9918886837268843
Validation loss: 2.901664156472126

Epoch: 5| Step: 6
Training loss: 3.4928046242334263
Validation loss: 2.899448918049383

Epoch: 5| Step: 7
Training loss: 2.9738938591287636
Validation loss: 2.8996855977300395

Epoch: 5| Step: 8
Training loss: 2.7588480877258688
Validation loss: 2.898676569710454

Epoch: 5| Step: 9
Training loss: 3.6709157137046913
Validation loss: 2.897952845327768

Epoch: 5| Step: 10
Training loss: 3.304758346195014
Validation loss: 2.899829536084276

Epoch: 149| Step: 0
Training loss: 3.710111184729072
Validation loss: 2.900753584358589

Epoch: 5| Step: 1
Training loss: 2.7942798018274546
Validation loss: 2.901410810377946

Epoch: 5| Step: 2
Training loss: 2.7880842272324
Validation loss: 2.8988638399767557

Epoch: 5| Step: 3
Training loss: 2.720748429972083
Validation loss: 2.9048475413806454

Epoch: 5| Step: 4
Training loss: 2.8432843172857933
Validation loss: 2.91143836302711

Epoch: 5| Step: 5
Training loss: 3.9861425929463774
Validation loss: 2.9087426545249797

Epoch: 5| Step: 6
Training loss: 3.8091208068806552
Validation loss: 2.925507771118718

Epoch: 5| Step: 7
Training loss: 3.094643820140721
Validation loss: 2.9047698107366853

Epoch: 5| Step: 8
Training loss: 2.541506673644627
Validation loss: 2.8968200380676716

Epoch: 5| Step: 9
Training loss: 3.8052429169800135
Validation loss: 2.897105975700279

Epoch: 5| Step: 10
Training loss: 2.3593775262882275
Validation loss: 2.8945894300113193

Epoch: 150| Step: 0
Training loss: 3.934541468776132
Validation loss: 2.8964261445416355

Epoch: 5| Step: 1
Training loss: 3.3182028856475645
Validation loss: 2.8950454591510204

Epoch: 5| Step: 2
Training loss: 3.3456600830017402
Validation loss: 2.894351847331378

Epoch: 5| Step: 3
Training loss: 2.934637419937772
Validation loss: 2.8941604664400664

Epoch: 5| Step: 4
Training loss: 2.859590282569774
Validation loss: 2.895266738553959

Epoch: 5| Step: 5
Training loss: 3.1429360460309907
Validation loss: 2.8972454958340736

Epoch: 5| Step: 6
Training loss: 3.1912474201698497
Validation loss: 2.898267191644208

Epoch: 5| Step: 7
Training loss: 3.4969429561771985
Validation loss: 2.8960787537154684

Epoch: 5| Step: 8
Training loss: 3.017001613617776
Validation loss: 2.8972113933419914

Epoch: 5| Step: 9
Training loss: 3.1367032441436487
Validation loss: 2.897093634899235

Epoch: 5| Step: 10
Training loss: 2.35780929251744
Validation loss: 2.8968576133779638

Epoch: 151| Step: 0
Training loss: 3.305176466531636
Validation loss: 2.8991266431979437

Epoch: 5| Step: 1
Training loss: 3.0289804673369534
Validation loss: 2.8999596305472988

Epoch: 5| Step: 2
Training loss: 2.778444654099184
Validation loss: 2.9028301302656456

Epoch: 5| Step: 3
Training loss: 3.3112229098647945
Validation loss: 2.915743328031756

Epoch: 5| Step: 4
Training loss: 2.6373453031614784
Validation loss: 2.9058218790729726

Epoch: 5| Step: 5
Training loss: 3.3389718685604532
Validation loss: 2.8989070362428775

Epoch: 5| Step: 6
Training loss: 3.467967727018181
Validation loss: 2.8956449235939283

Epoch: 5| Step: 7
Training loss: 3.6996299249277484
Validation loss: 2.89599117316029

Epoch: 5| Step: 8
Training loss: 3.4808076806950066
Validation loss: 2.8943665523347626

Epoch: 5| Step: 9
Training loss: 3.112179971810904
Validation loss: 2.8948182665387314

Epoch: 5| Step: 10
Training loss: 2.626498566620394
Validation loss: 2.8941419275209816

Epoch: 152| Step: 0
Training loss: 2.837640928558212
Validation loss: 2.8928028668112638

Epoch: 5| Step: 1
Training loss: 3.499499148908725
Validation loss: 2.8931569884140913

Epoch: 5| Step: 2
Training loss: 3.2631039173765437
Validation loss: 2.893794126051708

Epoch: 5| Step: 3
Training loss: 2.921570787555766
Validation loss: 2.894055635700504

Epoch: 5| Step: 4
Training loss: 3.451098784021929
Validation loss: 2.893684024856475

Epoch: 5| Step: 5
Training loss: 2.552142727738122
Validation loss: 2.8925451347278517

Epoch: 5| Step: 6
Training loss: 2.476814521938699
Validation loss: 2.892944293262873

Epoch: 5| Step: 7
Training loss: 3.960003925283009
Validation loss: 2.893292796755133

Epoch: 5| Step: 8
Training loss: 3.200109634905504
Validation loss: 2.889416128739194

Epoch: 5| Step: 9
Training loss: 3.710458439472768
Validation loss: 2.897995748207783

Epoch: 5| Step: 10
Training loss: 2.779783826834721
Validation loss: 2.9070212895127594

Epoch: 153| Step: 0
Training loss: 3.516857287286219
Validation loss: 2.8961990690890875

Epoch: 5| Step: 1
Training loss: 2.815563229170113
Validation loss: 2.8938995093073845

Epoch: 5| Step: 2
Training loss: 3.740914082331579
Validation loss: 2.892909830789905

Epoch: 5| Step: 3
Training loss: 3.10530137864615
Validation loss: 2.8909247112462513

Epoch: 5| Step: 4
Training loss: 3.286493525893478
Validation loss: 2.89189692447532

Epoch: 5| Step: 5
Training loss: 3.2607399939626496
Validation loss: 2.892313437105126

Epoch: 5| Step: 6
Training loss: 3.030077678075012
Validation loss: 2.89274871955258

Epoch: 5| Step: 7
Training loss: 2.6960108640095317
Validation loss: 2.893216675825665

Epoch: 5| Step: 8
Training loss: 3.093980876900498
Validation loss: 2.8914210524056836

Epoch: 5| Step: 9
Training loss: 2.8336910882117414
Validation loss: 2.890905859821271

Epoch: 5| Step: 10
Training loss: 3.523773650989547
Validation loss: 2.8895717547837596

Epoch: 154| Step: 0
Training loss: 2.735156399929257
Validation loss: 2.8910133958941753

Epoch: 5| Step: 1
Training loss: 3.234153555693013
Validation loss: 2.892029132723004

Epoch: 5| Step: 2
Training loss: 3.5211141500650167
Validation loss: 2.8886898402166308

Epoch: 5| Step: 3
Training loss: 3.2747591760048
Validation loss: 2.8872943184317776

Epoch: 5| Step: 4
Training loss: 2.6492687260001118
Validation loss: 2.8881985613851233

Epoch: 5| Step: 5
Training loss: 2.702130437914391
Validation loss: 2.8878585556942413

Epoch: 5| Step: 6
Training loss: 3.0767216460611624
Validation loss: 2.887938990963125

Epoch: 5| Step: 7
Training loss: 3.773537328438161
Validation loss: 2.8886367798049295

Epoch: 5| Step: 8
Training loss: 3.697918801463769
Validation loss: 2.8872849421486273

Epoch: 5| Step: 9
Training loss: 3.103060651190734
Validation loss: 2.8866378357883695

Epoch: 5| Step: 10
Training loss: 2.9714949917443767
Validation loss: 2.887781367367896

Epoch: 155| Step: 0
Training loss: 3.389866757320301
Validation loss: 2.887797439228958

Epoch: 5| Step: 1
Training loss: 2.252007436635018
Validation loss: 2.887738793903729

Epoch: 5| Step: 2
Training loss: 2.81924917195247
Validation loss: 2.8864545603979077

Epoch: 5| Step: 3
Training loss: 3.5311757307766456
Validation loss: 2.8894126098950754

Epoch: 5| Step: 4
Training loss: 3.169556470342336
Validation loss: 2.883893901963809

Epoch: 5| Step: 5
Training loss: 3.5789081099662954
Validation loss: 2.887332863869866

Epoch: 5| Step: 6
Training loss: 2.8105070046359804
Validation loss: 2.885990529256858

Epoch: 5| Step: 7
Training loss: 2.998655335751649
Validation loss: 2.8859235555911966

Epoch: 5| Step: 8
Training loss: 3.030845693780341
Validation loss: 2.8847115268361843

Epoch: 5| Step: 9
Training loss: 3.757557437988177
Validation loss: 2.8839556834029847

Epoch: 5| Step: 10
Training loss: 3.3977350320144626
Validation loss: 2.886341276603459

Epoch: 156| Step: 0
Training loss: 2.6385379647159826
Validation loss: 2.8857511032852643

Epoch: 5| Step: 1
Training loss: 3.2297278296061602
Validation loss: 2.8865790070416524

Epoch: 5| Step: 2
Training loss: 3.7420847964279518
Validation loss: 2.8851891097652227

Epoch: 5| Step: 3
Training loss: 3.0681004600141857
Validation loss: 2.884119450260349

Epoch: 5| Step: 4
Training loss: 2.8471319189456947
Validation loss: 2.8846572428049324

Epoch: 5| Step: 5
Training loss: 2.974346146737187
Validation loss: 2.8850269435741147

Epoch: 5| Step: 6
Training loss: 3.473844344267348
Validation loss: 2.884630423013104

Epoch: 5| Step: 7
Training loss: 3.433013207285472
Validation loss: 2.88671490194162

Epoch: 5| Step: 8
Training loss: 3.113279105727775
Validation loss: 2.8841863431563137

Epoch: 5| Step: 9
Training loss: 3.238635367069365
Validation loss: 2.883636355998472

Epoch: 5| Step: 10
Training loss: 3.046029780602351
Validation loss: 2.8824540675839114

Epoch: 157| Step: 0
Training loss: 2.4422487804024384
Validation loss: 2.8841037125691504

Epoch: 5| Step: 1
Training loss: 4.015502927832046
Validation loss: 2.8838268716055695

Epoch: 5| Step: 2
Training loss: 3.006166319763036
Validation loss: 2.88235853784783

Epoch: 5| Step: 3
Training loss: 2.969386303622619
Validation loss: 2.88271520173471

Epoch: 5| Step: 4
Training loss: 3.0668246815924305
Validation loss: 2.88350331485116

Epoch: 5| Step: 5
Training loss: 2.9422356600068786
Validation loss: 2.8827557292934953

Epoch: 5| Step: 6
Training loss: 3.253143404304853
Validation loss: 2.8805517921161186

Epoch: 5| Step: 7
Training loss: 3.1149120008551265
Validation loss: 2.8823499308729708

Epoch: 5| Step: 8
Training loss: 3.1787512898264376
Validation loss: 2.8825259431559243

Epoch: 5| Step: 9
Training loss: 3.2300276726166204
Validation loss: 2.8828694776770325

Epoch: 5| Step: 10
Training loss: 3.5484740564032995
Validation loss: 2.884059495463922

Epoch: 158| Step: 0
Training loss: 2.9923677315477297
Validation loss: 2.882346000491177

Epoch: 5| Step: 1
Training loss: 3.144516389231189
Validation loss: 2.884384364802388

Epoch: 5| Step: 2
Training loss: 3.689135431249785
Validation loss: 2.886746333670113

Epoch: 5| Step: 3
Training loss: 3.3139058134960107
Validation loss: 2.8872031239069766

Epoch: 5| Step: 4
Training loss: 2.7801218209230263
Validation loss: 2.8874461309575947

Epoch: 5| Step: 5
Training loss: 2.5019087180753705
Validation loss: 2.887961041494827

Epoch: 5| Step: 6
Training loss: 3.2306671266176297
Validation loss: 2.8926866269551907

Epoch: 5| Step: 7
Training loss: 3.168342916309273
Validation loss: 2.9009735693862746

Epoch: 5| Step: 8
Training loss: 3.563700557326959
Validation loss: 2.881192716456558

Epoch: 5| Step: 9
Training loss: 3.2825086813446553
Validation loss: 2.8804476320230354

Epoch: 5| Step: 10
Training loss: 3.1073655579532953
Validation loss: 2.879164206615354

Epoch: 159| Step: 0
Training loss: 3.388091797883255
Validation loss: 2.8788303470928343

Epoch: 5| Step: 1
Training loss: 3.2972761877311263
Validation loss: 2.8790531603776324

Epoch: 5| Step: 2
Training loss: 3.2448423982739487
Validation loss: 2.87877116466105

Epoch: 5| Step: 3
Training loss: 3.555801518860174
Validation loss: 2.879684218680557

Epoch: 5| Step: 4
Training loss: 2.57549359673941
Validation loss: 2.8801856336107257

Epoch: 5| Step: 5
Training loss: 3.1742827198475028
Validation loss: 2.880197628514409

Epoch: 5| Step: 6
Training loss: 2.944757788757548
Validation loss: 2.88086684025624

Epoch: 5| Step: 7
Training loss: 2.9856935154889253
Validation loss: 2.8799925084284395

Epoch: 5| Step: 8
Training loss: 3.5218724329481272
Validation loss: 2.8795947702514373

Epoch: 5| Step: 9
Training loss: 3.1749382073103813
Validation loss: 2.8798031376822606

Epoch: 5| Step: 10
Training loss: 2.9099401201727026
Validation loss: 2.877031825498133

Epoch: 160| Step: 0
Training loss: 3.3809425877071724
Validation loss: 2.8783650886077

Epoch: 5| Step: 1
Training loss: 3.1018190830285914
Validation loss: 2.877978124871737

Epoch: 5| Step: 2
Training loss: 3.147948574979091
Validation loss: 2.879978677161959

Epoch: 5| Step: 3
Training loss: 2.951057154144319
Validation loss: 2.878375261692313

Epoch: 5| Step: 4
Training loss: 2.9863800184033593
Validation loss: 2.880495770734006

Epoch: 5| Step: 5
Training loss: 3.3311568943202956
Validation loss: 2.8813353186902115

Epoch: 5| Step: 6
Training loss: 3.0144733344736903
Validation loss: 2.888122264469676

Epoch: 5| Step: 7
Training loss: 3.639224196330815
Validation loss: 2.8910870706840868

Epoch: 5| Step: 8
Training loss: 3.097843121235189
Validation loss: 2.893661469532276

Epoch: 5| Step: 9
Training loss: 2.9758581895163165
Validation loss: 2.899349409611787

Epoch: 5| Step: 10
Training loss: 3.260767778660059
Validation loss: 2.895476315624875

Epoch: 161| Step: 0
Training loss: 3.3488468292009443
Validation loss: 2.8876308100610313

Epoch: 5| Step: 1
Training loss: 3.6141789161545494
Validation loss: 2.8882690478070265

Epoch: 5| Step: 2
Training loss: 2.8110142492193035
Validation loss: 2.8776146732588233

Epoch: 5| Step: 3
Training loss: 2.649276105506791
Validation loss: 2.875901577988385

Epoch: 5| Step: 4
Training loss: 3.0831542779292884
Validation loss: 2.8768179265618103

Epoch: 5| Step: 5
Training loss: 2.5688381430546383
Validation loss: 2.8771900825460075

Epoch: 5| Step: 6
Training loss: 3.2703022292805604
Validation loss: 2.8753606704679884

Epoch: 5| Step: 7
Training loss: 2.914073463398864
Validation loss: 2.8781693668501442

Epoch: 5| Step: 8
Training loss: 3.6937541619550105
Validation loss: 2.878374912555352

Epoch: 5| Step: 9
Training loss: 3.032189921527813
Validation loss: 2.877913754725988

Epoch: 5| Step: 10
Training loss: 3.82264360635874
Validation loss: 2.8777101493401966

Epoch: 162| Step: 0
Training loss: 3.3366875620469396
Validation loss: 2.87769370666601

Epoch: 5| Step: 1
Training loss: 3.419321718827537
Validation loss: 2.8779152779906516

Epoch: 5| Step: 2
Training loss: 3.32293468378777
Validation loss: 2.876502655100682

Epoch: 5| Step: 3
Training loss: 2.43020477185654
Validation loss: 2.8752766217966834

Epoch: 5| Step: 4
Training loss: 3.288140754480692
Validation loss: 2.875336597457731

Epoch: 5| Step: 5
Training loss: 3.193189591960151
Validation loss: 2.876189609500817

Epoch: 5| Step: 6
Training loss: 3.7666918244548544
Validation loss: 2.8760739247233236

Epoch: 5| Step: 7
Training loss: 3.3414098804267747
Validation loss: 2.8751609635915134

Epoch: 5| Step: 8
Training loss: 2.9265639273033592
Validation loss: 2.8769397335822533

Epoch: 5| Step: 9
Training loss: 2.7585488003785295
Validation loss: 2.878427922105176

Epoch: 5| Step: 10
Training loss: 2.884027323324897
Validation loss: 2.876932476455722

Epoch: 163| Step: 0
Training loss: 3.0673064835994226
Validation loss: 2.877723805320827

Epoch: 5| Step: 1
Training loss: 3.0617899168814944
Validation loss: 2.878132879198696

Epoch: 5| Step: 2
Training loss: 3.2912245505827156
Validation loss: 2.881856876497003

Epoch: 5| Step: 3
Training loss: 3.3150551495919984
Validation loss: 2.878609788439445

Epoch: 5| Step: 4
Training loss: 2.807436475162484
Validation loss: 2.881851900185301

Epoch: 5| Step: 5
Training loss: 3.2167673763921445
Validation loss: 2.878586120211158

Epoch: 5| Step: 6
Training loss: 2.7618246746118187
Validation loss: 2.8765405234382637

Epoch: 5| Step: 7
Training loss: 3.0559603875673615
Validation loss: 2.879566069317704

Epoch: 5| Step: 8
Training loss: 3.4344221727986124
Validation loss: 2.8797612545965254

Epoch: 5| Step: 9
Training loss: 3.910957734455309
Validation loss: 2.8727568149850145

Epoch: 5| Step: 10
Training loss: 2.7018794017846783
Validation loss: 2.8738402996591956

Epoch: 164| Step: 0
Training loss: 2.976898414700736
Validation loss: 2.8743021788263023

Epoch: 5| Step: 1
Training loss: 2.8920210482832553
Validation loss: 2.870089763786723

Epoch: 5| Step: 2
Training loss: 2.8918213714052623
Validation loss: 2.871204562096529

Epoch: 5| Step: 3
Training loss: 2.7640326274596725
Validation loss: 2.8701953966117006

Epoch: 5| Step: 4
Training loss: 3.805845613091587
Validation loss: 2.8692084032139396

Epoch: 5| Step: 5
Training loss: 3.2126148604109095
Validation loss: 2.8718891746582442

Epoch: 5| Step: 6
Training loss: 3.347717640691107
Validation loss: 2.870018006420814

Epoch: 5| Step: 7
Training loss: 3.021561230185685
Validation loss: 2.873040924196603

Epoch: 5| Step: 8
Training loss: 3.3777825929233742
Validation loss: 2.8703545003802104

Epoch: 5| Step: 9
Training loss: 3.585613826197701
Validation loss: 2.8764012022177354

Epoch: 5| Step: 10
Training loss: 2.7262195273073253
Validation loss: 2.875276768913204

Epoch: 165| Step: 0
Training loss: 2.8084193826806056
Validation loss: 2.8730932299891165

Epoch: 5| Step: 1
Training loss: 3.5498992529529234
Validation loss: 2.8797305558520585

Epoch: 5| Step: 2
Training loss: 3.3291763292792265
Validation loss: 2.8726053881153777

Epoch: 5| Step: 3
Training loss: 2.1551725487544577
Validation loss: 2.877087461673197

Epoch: 5| Step: 4
Training loss: 2.838754479133032
Validation loss: 2.874114563192282

Epoch: 5| Step: 5
Training loss: 3.6636714116559976
Validation loss: 2.8752146681315316

Epoch: 5| Step: 6
Training loss: 3.7839793293733135
Validation loss: 2.870312584814218

Epoch: 5| Step: 7
Training loss: 3.1496254168422086
Validation loss: 2.8680078942702587

Epoch: 5| Step: 8
Training loss: 2.993828306189404
Validation loss: 2.866890761081681

Epoch: 5| Step: 9
Training loss: 3.0452222204943244
Validation loss: 2.866696380741209

Epoch: 5| Step: 10
Training loss: 3.187209770602834
Validation loss: 2.8681226422875303

Epoch: 166| Step: 0
Training loss: 2.9047168256193463
Validation loss: 2.867233261248847

Epoch: 5| Step: 1
Training loss: 3.016069606756902
Validation loss: 2.8662619288107445

Epoch: 5| Step: 2
Training loss: 3.6012937234477205
Validation loss: 2.865019452111086

Epoch: 5| Step: 3
Training loss: 3.7165469528100146
Validation loss: 2.8667343723555874

Epoch: 5| Step: 4
Training loss: 2.943209517118636
Validation loss: 2.8650830731063555

Epoch: 5| Step: 5
Training loss: 3.051242925314572
Validation loss: 2.865240287437736

Epoch: 5| Step: 6
Training loss: 2.9039024798410082
Validation loss: 2.863864080049898

Epoch: 5| Step: 7
Training loss: 3.05146748619003
Validation loss: 2.8644513031335372

Epoch: 5| Step: 8
Training loss: 3.213547585521587
Validation loss: 2.8646701852528564

Epoch: 5| Step: 9
Training loss: 2.963346201121738
Validation loss: 2.8646466528791943

Epoch: 5| Step: 10
Training loss: 3.3550186654721466
Validation loss: 2.8646763087125096

Epoch: 167| Step: 0
Training loss: 3.845556811430746
Validation loss: 2.8664394146095518

Epoch: 5| Step: 1
Training loss: 3.371566155884511
Validation loss: 2.8631589926351793

Epoch: 5| Step: 2
Training loss: 2.401661448776362
Validation loss: 2.8643096047259475

Epoch: 5| Step: 3
Training loss: 3.312437092885498
Validation loss: 2.864053611364962

Epoch: 5| Step: 4
Training loss: 3.2486707463271793
Validation loss: 2.8639725115361996

Epoch: 5| Step: 5
Training loss: 2.7810063630449298
Validation loss: 2.865549940575361

Epoch: 5| Step: 6
Training loss: 2.663802416682685
Validation loss: 2.864230953853216

Epoch: 5| Step: 7
Training loss: 2.861683898263668
Validation loss: 2.8643105140754352

Epoch: 5| Step: 8
Training loss: 3.226696390325082
Validation loss: 2.8634339954272106

Epoch: 5| Step: 9
Training loss: 3.704042988884035
Validation loss: 2.8643165420886088

Epoch: 5| Step: 10
Training loss: 3.019309051747333
Validation loss: 2.863654730105669

Epoch: 168| Step: 0
Training loss: 2.913481544489858
Validation loss: 2.8629004266850284

Epoch: 5| Step: 1
Training loss: 3.4239239415429052
Validation loss: 2.8613173375998535

Epoch: 5| Step: 2
Training loss: 3.8008310563684855
Validation loss: 2.8631543957051373

Epoch: 5| Step: 3
Training loss: 2.79536857740639
Validation loss: 2.861359820368326

Epoch: 5| Step: 4
Training loss: 3.329684612929884
Validation loss: 2.86239422842177

Epoch: 5| Step: 5
Training loss: 2.8067198803886706
Validation loss: 2.862056511933164

Epoch: 5| Step: 6
Training loss: 3.224244696122432
Validation loss: 2.8598847105546823

Epoch: 5| Step: 7
Training loss: 2.966562690055742
Validation loss: 2.8606485585361137

Epoch: 5| Step: 8
Training loss: 2.5439013574357645
Validation loss: 2.8608285871830628

Epoch: 5| Step: 9
Training loss: 3.6723784405953737
Validation loss: 2.8612089255540716

Epoch: 5| Step: 10
Training loss: 2.998459738469512
Validation loss: 2.86023207318327

Epoch: 169| Step: 0
Training loss: 2.9090428212916355
Validation loss: 2.8608215248666147

Epoch: 5| Step: 1
Training loss: 3.637321446811387
Validation loss: 2.860286792087091

Epoch: 5| Step: 2
Training loss: 3.400655509364567
Validation loss: 2.858774826115836

Epoch: 5| Step: 3
Training loss: 3.4348654621546717
Validation loss: 2.8590228310316426

Epoch: 5| Step: 4
Training loss: 3.0459324087857893
Validation loss: 2.8572172355565937

Epoch: 5| Step: 5
Training loss: 2.7193799220860133
Validation loss: 2.859480720231894

Epoch: 5| Step: 6
Training loss: 2.7486874308974163
Validation loss: 2.8586778853965895

Epoch: 5| Step: 7
Training loss: 3.25845045251596
Validation loss: 2.857871676401139

Epoch: 5| Step: 8
Training loss: 2.9815794948616894
Validation loss: 2.860051735390629

Epoch: 5| Step: 9
Training loss: 2.615228540415448
Validation loss: 2.858006933293729

Epoch: 5| Step: 10
Training loss: 3.833313209370298
Validation loss: 2.860967527836027

Epoch: 170| Step: 0
Training loss: 3.136455140016658
Validation loss: 2.8627471701046248

Epoch: 5| Step: 1
Training loss: 3.6898388961317456
Validation loss: 2.867437562278204

Epoch: 5| Step: 2
Training loss: 3.007789195577333
Validation loss: 2.871057838548521

Epoch: 5| Step: 3
Training loss: 3.0527403105948374
Validation loss: 2.894022847411693

Epoch: 5| Step: 4
Training loss: 2.8316672045112385
Validation loss: 2.890694716881344

Epoch: 5| Step: 5
Training loss: 2.9218030298518523
Validation loss: 2.8913138187756986

Epoch: 5| Step: 6
Training loss: 2.2171824115805006
Validation loss: 2.87057011338215

Epoch: 5| Step: 7
Training loss: 3.102703048123359
Validation loss: 2.8581029935187603

Epoch: 5| Step: 8
Training loss: 3.4352889839782597
Validation loss: 2.857184885890782

Epoch: 5| Step: 9
Training loss: 3.667101285203001
Validation loss: 2.8570670856516083

Epoch: 5| Step: 10
Training loss: 3.4270918980330065
Validation loss: 2.8564484232102125

Epoch: 171| Step: 0
Training loss: 3.5073225533047174
Validation loss: 2.855124600619179

Epoch: 5| Step: 1
Training loss: 3.0930510993433997
Validation loss: 2.857832207925178

Epoch: 5| Step: 2
Training loss: 3.163379736808866
Validation loss: 2.8584028878155205

Epoch: 5| Step: 3
Training loss: 2.5060683034735516
Validation loss: 2.856588953594466

Epoch: 5| Step: 4
Training loss: 3.665046218226761
Validation loss: 2.8566881925908816

Epoch: 5| Step: 5
Training loss: 2.2414236861169363
Validation loss: 2.8583847169955194

Epoch: 5| Step: 6
Training loss: 3.524850092737212
Validation loss: 2.8591945624210915

Epoch: 5| Step: 7
Training loss: 3.239769017498495
Validation loss: 2.857260933134061

Epoch: 5| Step: 8
Training loss: 3.285947797308372
Validation loss: 2.855887377049811

Epoch: 5| Step: 9
Training loss: 3.2668843008711406
Validation loss: 2.856085874318514

Epoch: 5| Step: 10
Training loss: 2.901485023429644
Validation loss: 2.856394469049963

Epoch: 172| Step: 0
Training loss: 3.0128926761224055
Validation loss: 2.8551546777016408

Epoch: 5| Step: 1
Training loss: 3.168487543978233
Validation loss: 2.8561769143803444

Epoch: 5| Step: 2
Training loss: 2.955776255676435
Validation loss: 2.8573231361136036

Epoch: 5| Step: 3
Training loss: 2.5885818652300814
Validation loss: 2.858611522884623

Epoch: 5| Step: 4
Training loss: 3.335624161953005
Validation loss: 2.859380469094792

Epoch: 5| Step: 5
Training loss: 2.9661921675325496
Validation loss: 2.858823774553886

Epoch: 5| Step: 6
Training loss: 3.4518528316683175
Validation loss: 2.8548744808435824

Epoch: 5| Step: 7
Training loss: 3.370675884352929
Validation loss: 2.856164131050483

Epoch: 5| Step: 8
Training loss: 3.2371762441525433
Validation loss: 2.8552991235553646

Epoch: 5| Step: 9
Training loss: 3.430906596136236
Validation loss: 2.853243919753117

Epoch: 5| Step: 10
Training loss: 3.0501108055623973
Validation loss: 2.8535404660607644

Epoch: 173| Step: 0
Training loss: 3.4940329503654866
Validation loss: 2.852679861857111

Epoch: 5| Step: 1
Training loss: 2.6459665840616635
Validation loss: 2.853841815375364

Epoch: 5| Step: 2
Training loss: 2.9710945909786313
Validation loss: 2.855607341861085

Epoch: 5| Step: 3
Training loss: 3.031117229896751
Validation loss: 2.849996808346579

Epoch: 5| Step: 4
Training loss: 3.41817298496957
Validation loss: 2.8534833896953278

Epoch: 5| Step: 5
Training loss: 3.227997763121254
Validation loss: 2.8515977058029804

Epoch: 5| Step: 6
Training loss: 3.504910838561673
Validation loss: 2.8535451000401375

Epoch: 5| Step: 7
Training loss: 2.9506025895017305
Validation loss: 2.8533486281630878

Epoch: 5| Step: 8
Training loss: 3.439945252892189
Validation loss: 2.850868410108818

Epoch: 5| Step: 9
Training loss: 2.60957262581408
Validation loss: 2.851129139037731

Epoch: 5| Step: 10
Training loss: 3.2023930899696786
Validation loss: 2.8571292040208616

Epoch: 174| Step: 0
Training loss: 3.2905961400403037
Validation loss: 2.8549753427759814

Epoch: 5| Step: 1
Training loss: 3.329830395385947
Validation loss: 2.8583180651518094

Epoch: 5| Step: 2
Training loss: 2.6465847320109326
Validation loss: 2.8694176445882427

Epoch: 5| Step: 3
Training loss: 3.21024747613517
Validation loss: 2.883283396405877

Epoch: 5| Step: 4
Training loss: 2.8291062818177757
Validation loss: 2.86825171334858

Epoch: 5| Step: 5
Training loss: 3.2353595211945576
Validation loss: 2.8546018802335595

Epoch: 5| Step: 6
Training loss: 3.255168619549411
Validation loss: 2.8527180805791166

Epoch: 5| Step: 7
Training loss: 3.042661443233882
Validation loss: 2.848922264640324

Epoch: 5| Step: 8
Training loss: 3.600479856935088
Validation loss: 2.845440974494205

Epoch: 5| Step: 9
Training loss: 2.8357836468790665
Validation loss: 2.8502419864645545

Epoch: 5| Step: 10
Training loss: 3.2977006068315786
Validation loss: 2.8507928973696934

Epoch: 175| Step: 0
Training loss: 3.136428990644375
Validation loss: 2.8508959171045127

Epoch: 5| Step: 1
Training loss: 2.726762037435843
Validation loss: 2.849287733282391

Epoch: 5| Step: 2
Training loss: 2.5493745298541834
Validation loss: 2.8485542525665455

Epoch: 5| Step: 3
Training loss: 3.4966838658300454
Validation loss: 2.8534694766528297

Epoch: 5| Step: 4
Training loss: 3.3335790225719033
Validation loss: 2.8518218548050664

Epoch: 5| Step: 5
Training loss: 3.228560376419653
Validation loss: 2.858724619557538

Epoch: 5| Step: 6
Training loss: 3.2481622635284033
Validation loss: 2.8525622422529047

Epoch: 5| Step: 7
Training loss: 3.516189868899692
Validation loss: 2.8511882415574137

Epoch: 5| Step: 8
Training loss: 3.012792650625672
Validation loss: 2.84935087958906

Epoch: 5| Step: 9
Training loss: 2.660732660568443
Validation loss: 2.8491578454152147

Epoch: 5| Step: 10
Training loss: 3.6142687628599988
Validation loss: 2.847977533174698

Epoch: 176| Step: 0
Training loss: 3.7014248965295025
Validation loss: 2.846319246674138

Epoch: 5| Step: 1
Training loss: 2.6278405034395322
Validation loss: 2.845346756398274

Epoch: 5| Step: 2
Training loss: 3.433241963945391
Validation loss: 2.8469858385736306

Epoch: 5| Step: 3
Training loss: 2.649324791736909
Validation loss: 2.8489043474055014

Epoch: 5| Step: 4
Training loss: 3.203244537356003
Validation loss: 2.848027125357991

Epoch: 5| Step: 5
Training loss: 3.074528175690181
Validation loss: 2.8472725363973796

Epoch: 5| Step: 6
Training loss: 3.132445049854258
Validation loss: 2.846634158707515

Epoch: 5| Step: 7
Training loss: 3.6401416637814332
Validation loss: 2.8467753212595457

Epoch: 5| Step: 8
Training loss: 2.9913698677885163
Validation loss: 2.8466367929221597

Epoch: 5| Step: 9
Training loss: 2.744018465085641
Validation loss: 2.8472291888466823

Epoch: 5| Step: 10
Training loss: 3.2545401332418433
Validation loss: 2.84834316443664

Epoch: 177| Step: 0
Training loss: 3.2293569365199795
Validation loss: 2.8521672062659653

Epoch: 5| Step: 1
Training loss: 2.8109467349873487
Validation loss: 2.8529259038911996

Epoch: 5| Step: 2
Training loss: 3.133865902328052
Validation loss: 2.8525514936005836

Epoch: 5| Step: 3
Training loss: 3.2836046761896642
Validation loss: 2.854423729338539

Epoch: 5| Step: 4
Training loss: 3.28928242217725
Validation loss: 2.866898067771291

Epoch: 5| Step: 5
Training loss: 3.1887841723266037
Validation loss: 2.8492959065805317

Epoch: 5| Step: 6
Training loss: 3.067808882528649
Validation loss: 2.846062097237214

Epoch: 5| Step: 7
Training loss: 3.340842721122961
Validation loss: 2.846799770868843

Epoch: 5| Step: 8
Training loss: 3.0917891636629986
Validation loss: 2.849458960958511

Epoch: 5| Step: 9
Training loss: 2.9820304568786606
Validation loss: 2.853738071018448

Epoch: 5| Step: 10
Training loss: 3.2376132547607264
Validation loss: 2.8553828947621827

Epoch: 178| Step: 0
Training loss: 2.8306805776984065
Validation loss: 2.8524951577774376

Epoch: 5| Step: 1
Training loss: 3.3256990429299984
Validation loss: 2.8540925645890725

Epoch: 5| Step: 2
Training loss: 3.141343978647913
Validation loss: 2.8535301361587595

Epoch: 5| Step: 3
Training loss: 3.592418258044971
Validation loss: 2.8511395306893843

Epoch: 5| Step: 4
Training loss: 3.022185152502788
Validation loss: 2.84993989309338

Epoch: 5| Step: 5
Training loss: 3.014431573984289
Validation loss: 2.8463286264053886

Epoch: 5| Step: 6
Training loss: 3.303658255242458
Validation loss: 2.848335473530896

Epoch: 5| Step: 7
Training loss: 3.138303439551174
Validation loss: 2.8465663518327244

Epoch: 5| Step: 8
Training loss: 3.308567952277303
Validation loss: 2.845740019452223

Epoch: 5| Step: 9
Training loss: 3.0665981354174057
Validation loss: 2.8467601813078076

Epoch: 5| Step: 10
Training loss: 2.833877361651154
Validation loss: 2.8473595401422815

Epoch: 179| Step: 0
Training loss: 2.221711881634871
Validation loss: 2.8457680895092388

Epoch: 5| Step: 1
Training loss: 2.949192557313324
Validation loss: 2.847003606698249

Epoch: 5| Step: 2
Training loss: 3.1799695688866914
Validation loss: 2.848403611802649

Epoch: 5| Step: 3
Training loss: 3.663620651705366
Validation loss: 2.846962282040412

Epoch: 5| Step: 4
Training loss: 3.2399850741384055
Validation loss: 2.850616582282167

Epoch: 5| Step: 5
Training loss: 3.659251879959056
Validation loss: 2.8563828175603074

Epoch: 5| Step: 6
Training loss: 3.1121844150846996
Validation loss: 2.8551093271548122

Epoch: 5| Step: 7
Training loss: 2.522366039397641
Validation loss: 2.8559524501059794

Epoch: 5| Step: 8
Training loss: 3.6716011107542306
Validation loss: 2.8562067990727042

Epoch: 5| Step: 9
Training loss: 2.236306162897072
Validation loss: 2.8581001752288433

Epoch: 5| Step: 10
Training loss: 3.7588196354547105
Validation loss: 2.856341208555805

Epoch: 180| Step: 0
Training loss: 2.8918569877794016
Validation loss: 2.8500384883875967

Epoch: 5| Step: 1
Training loss: 3.014144929556651
Validation loss: 2.8423462046183383

Epoch: 5| Step: 2
Training loss: 3.2362851017432974
Validation loss: 2.8434470528171447

Epoch: 5| Step: 3
Training loss: 3.2775807528000724
Validation loss: 2.8418970653420166

Epoch: 5| Step: 4
Training loss: 3.6718930507784373
Validation loss: 2.8425067111636766

Epoch: 5| Step: 5
Training loss: 2.738568387506384
Validation loss: 2.8425243548673502

Epoch: 5| Step: 6
Training loss: 3.4718613975388912
Validation loss: 2.8410745715200925

Epoch: 5| Step: 7
Training loss: 2.961210615702111
Validation loss: 2.845998480712491

Epoch: 5| Step: 8
Training loss: 3.5279977050739184
Validation loss: 2.8497683866520918

Epoch: 5| Step: 9
Training loss: 2.7445220139215323
Validation loss: 2.8456820713269186

Epoch: 5| Step: 10
Training loss: 2.8752670164089826
Validation loss: 2.852105856212762

Epoch: 181| Step: 0
Training loss: 2.9665773171103353
Validation loss: 2.849188408381236

Epoch: 5| Step: 1
Training loss: 2.539776323186762
Validation loss: 2.843931828540713

Epoch: 5| Step: 2
Training loss: 3.7116343918007924
Validation loss: 2.838465175104177

Epoch: 5| Step: 3
Training loss: 3.1466068217949945
Validation loss: 2.836705978901218

Epoch: 5| Step: 4
Training loss: 3.225576624220206
Validation loss: 2.840352397552633

Epoch: 5| Step: 5
Training loss: 3.21857074127277
Validation loss: 2.8441461780487796

Epoch: 5| Step: 6
Training loss: 2.781487272621233
Validation loss: 2.8455756005975825

Epoch: 5| Step: 7
Training loss: 2.9870060213051928
Validation loss: 2.844639205155962

Epoch: 5| Step: 8
Training loss: 3.5049926026357388
Validation loss: 2.839094957517446

Epoch: 5| Step: 9
Training loss: 3.853724246364366
Validation loss: 2.8381521974774313

Epoch: 5| Step: 10
Training loss: 2.2447765966442077
Validation loss: 2.8404526857776418

Epoch: 182| Step: 0
Training loss: 2.6657478617252006
Validation loss: 2.8406712903742166

Epoch: 5| Step: 1
Training loss: 3.3296323416342144
Validation loss: 2.8389353760297067

Epoch: 5| Step: 2
Training loss: 3.343422419108183
Validation loss: 2.8444089571170377

Epoch: 5| Step: 3
Training loss: 3.4001839195322225
Validation loss: 2.839129721962334

Epoch: 5| Step: 4
Training loss: 3.7811652560235154
Validation loss: 2.8433385382521466

Epoch: 5| Step: 5
Training loss: 3.3248413793832454
Validation loss: 2.848015540453553

Epoch: 5| Step: 6
Training loss: 3.3999728538327063
Validation loss: 2.849259054573711

Epoch: 5| Step: 7
Training loss: 2.760860671316707
Validation loss: 2.8551013716318976

Epoch: 5| Step: 8
Training loss: 2.6613949483849746
Validation loss: 2.8647090194439904

Epoch: 5| Step: 9
Training loss: 3.0131360787277206
Validation loss: 2.8741397212595996

Epoch: 5| Step: 10
Training loss: 2.5366090159270933
Validation loss: 2.8610395982168466

Epoch: 183| Step: 0
Training loss: 2.833424024439425
Validation loss: 2.845690074804049

Epoch: 5| Step: 1
Training loss: 3.218585260119756
Validation loss: 2.8502592755758207

Epoch: 5| Step: 2
Training loss: 3.3144309695598637
Validation loss: 2.8413947303467606

Epoch: 5| Step: 3
Training loss: 2.9967554348989975
Validation loss: 2.8414544864572795

Epoch: 5| Step: 4
Training loss: 2.774358634032506
Validation loss: 2.844055690334584

Epoch: 5| Step: 5
Training loss: 3.4317396971416683
Validation loss: 2.841308578862469

Epoch: 5| Step: 6
Training loss: 3.4306486342789295
Validation loss: 2.8411171620709466

Epoch: 5| Step: 7
Training loss: 2.715785021177118
Validation loss: 2.8395832804038403

Epoch: 5| Step: 8
Training loss: 3.542526739069373
Validation loss: 2.8389155237733776

Epoch: 5| Step: 9
Training loss: 2.768060764610475
Validation loss: 2.8391486164853217

Epoch: 5| Step: 10
Training loss: 3.4661111502723743
Validation loss: 2.838746553635498

Epoch: 184| Step: 0
Training loss: 3.805281261821179
Validation loss: 2.837636453812323

Epoch: 5| Step: 1
Training loss: 3.2393480483267374
Validation loss: 2.8363648368386056

Epoch: 5| Step: 2
Training loss: 2.8701678593157953
Validation loss: 2.8371201691079198

Epoch: 5| Step: 3
Training loss: 2.8151937512245215
Validation loss: 2.836308456996638

Epoch: 5| Step: 4
Training loss: 3.1252389435016794
Validation loss: 2.8384197900231953

Epoch: 5| Step: 5
Training loss: 3.1876872886536627
Validation loss: 2.8492957212329912

Epoch: 5| Step: 6
Training loss: 3.0507798432995314
Validation loss: 2.855949449266401

Epoch: 5| Step: 7
Training loss: 2.8449667538810495
Validation loss: 2.8458853683455296

Epoch: 5| Step: 8
Training loss: 3.5217104991009043
Validation loss: 2.84307793346714

Epoch: 5| Step: 9
Training loss: 2.450475245722985
Validation loss: 2.833898315764874

Epoch: 5| Step: 10
Training loss: 3.4224224610667457
Validation loss: 2.836966968404734

Epoch: 185| Step: 0
Training loss: 3.325047032303274
Validation loss: 2.8344955184090974

Epoch: 5| Step: 1
Training loss: 2.8231992873340377
Validation loss: 2.8356624569221562

Epoch: 5| Step: 2
Training loss: 2.7374178277489865
Validation loss: 2.834967454745645

Epoch: 5| Step: 3
Training loss: 3.301677081190999
Validation loss: 2.8342891078756245

Epoch: 5| Step: 4
Training loss: 2.88165127489941
Validation loss: 2.8333197116222757

Epoch: 5| Step: 5
Training loss: 3.2658205110714014
Validation loss: 2.835635979266594

Epoch: 5| Step: 6
Training loss: 2.9345007661268254
Validation loss: 2.8363701586863823

Epoch: 5| Step: 7
Training loss: 3.5763302762229476
Validation loss: 2.833509024131879

Epoch: 5| Step: 8
Training loss: 2.7453872835485202
Validation loss: 2.8335256245874243

Epoch: 5| Step: 9
Training loss: 3.380651475319958
Validation loss: 2.8329780622495067

Epoch: 5| Step: 10
Training loss: 3.4073546132161057
Validation loss: 2.832390958454607

Epoch: 186| Step: 0
Training loss: 2.64752874846875
Validation loss: 2.835343629154137

Epoch: 5| Step: 1
Training loss: 3.637077207344191
Validation loss: 2.8351031704722836

Epoch: 5| Step: 2
Training loss: 3.066057124581786
Validation loss: 2.8468121775018753

Epoch: 5| Step: 3
Training loss: 2.5932397915102205
Validation loss: 2.839208405422166

Epoch: 5| Step: 4
Training loss: 3.7378836393415624
Validation loss: 2.834619887495217

Epoch: 5| Step: 5
Training loss: 3.172200303708091
Validation loss: 2.829486046009992

Epoch: 5| Step: 6
Training loss: 3.514026600614899
Validation loss: 2.8303517542850436

Epoch: 5| Step: 7
Training loss: 2.893644498215989
Validation loss: 2.8292166389346987

Epoch: 5| Step: 8
Training loss: 2.7177328201970696
Validation loss: 2.8293808459305594

Epoch: 5| Step: 9
Training loss: 3.1707904633987978
Validation loss: 2.8283794467416468

Epoch: 5| Step: 10
Training loss: 3.096477500741392
Validation loss: 2.8293224105242936

Epoch: 187| Step: 0
Training loss: 2.8352658656088185
Validation loss: 2.829397118144265

Epoch: 5| Step: 1
Training loss: 2.679315480024292
Validation loss: 2.8274592965234406

Epoch: 5| Step: 2
Training loss: 2.9546052966693277
Validation loss: 2.8300297247494073

Epoch: 5| Step: 3
Training loss: 3.3529273324174755
Validation loss: 2.827518588255127

Epoch: 5| Step: 4
Training loss: 3.2622213193468905
Validation loss: 2.828988700678524

Epoch: 5| Step: 5
Training loss: 3.5082232738154553
Validation loss: 2.828092116316159

Epoch: 5| Step: 6
Training loss: 3.9403834608502866
Validation loss: 2.827644979562775

Epoch: 5| Step: 7
Training loss: 3.2174660797820915
Validation loss: 2.8288831205150564

Epoch: 5| Step: 8
Training loss: 2.8869754331288062
Validation loss: 2.827139990249866

Epoch: 5| Step: 9
Training loss: 2.848419547639104
Validation loss: 2.8292365184707973

Epoch: 5| Step: 10
Training loss: 2.6753100349228656
Validation loss: 2.8270658418882646

Epoch: 188| Step: 0
Training loss: 3.304814185201046
Validation loss: 2.82700273011967

Epoch: 5| Step: 1
Training loss: 2.8653338934446806
Validation loss: 2.828273477635639

Epoch: 5| Step: 2
Training loss: 3.570201112441198
Validation loss: 2.8259205262101004

Epoch: 5| Step: 3
Training loss: 3.014522370673506
Validation loss: 2.826068250625293

Epoch: 5| Step: 4
Training loss: 3.6241314603864865
Validation loss: 2.827945084152778

Epoch: 5| Step: 5
Training loss: 2.902624186012059
Validation loss: 2.8252246047949323

Epoch: 5| Step: 6
Training loss: 3.0107849494206183
Validation loss: 2.827070375986024

Epoch: 5| Step: 7
Training loss: 2.790964199524047
Validation loss: 2.8296168667697716

Epoch: 5| Step: 8
Training loss: 3.1852108084052984
Validation loss: 2.8256032466801626

Epoch: 5| Step: 9
Training loss: 3.626797197694959
Validation loss: 2.8253182653259072

Epoch: 5| Step: 10
Training loss: 2.089888926935762
Validation loss: 2.8269701217600662

Epoch: 189| Step: 0
Training loss: 2.9408705832793216
Validation loss: 2.824385719184304

Epoch: 5| Step: 1
Training loss: 2.6778616954937893
Validation loss: 2.825304988493213

Epoch: 5| Step: 2
Training loss: 3.361346141139618
Validation loss: 2.8252124309391586

Epoch: 5| Step: 3
Training loss: 3.3657702231356033
Validation loss: 2.8243337666893074

Epoch: 5| Step: 4
Training loss: 2.8984213774610557
Validation loss: 2.8260447673846287

Epoch: 5| Step: 5
Training loss: 2.957520619543819
Validation loss: 2.824581706987745

Epoch: 5| Step: 6
Training loss: 2.853582633378613
Validation loss: 2.8257902582964833

Epoch: 5| Step: 7
Training loss: 2.8336109885508343
Validation loss: 2.824449677278694

Epoch: 5| Step: 8
Training loss: 3.460489696181442
Validation loss: 2.830054673220765

Epoch: 5| Step: 9
Training loss: 3.835389511838339
Validation loss: 2.828749653922676

Epoch: 5| Step: 10
Training loss: 3.0252336396084765
Validation loss: 2.826784463316537

Epoch: 190| Step: 0
Training loss: 3.6247284886196565
Validation loss: 2.821562917203683

Epoch: 5| Step: 1
Training loss: 3.0462880669658405
Validation loss: 2.8260434964701058

Epoch: 5| Step: 2
Training loss: 2.9075068555572323
Validation loss: 2.8244262649937624

Epoch: 5| Step: 3
Training loss: 2.6570610154640186
Validation loss: 2.8209423663628335

Epoch: 5| Step: 4
Training loss: 2.448417374285355
Validation loss: 2.8217910928011523

Epoch: 5| Step: 5
Training loss: 3.310714672416045
Validation loss: 2.8200560436034023

Epoch: 5| Step: 6
Training loss: 3.1771247902755406
Validation loss: 2.821821605125563

Epoch: 5| Step: 7
Training loss: 3.314790905188016
Validation loss: 2.822318865448498

Epoch: 5| Step: 8
Training loss: 3.4226510896624247
Validation loss: 2.820084138406469

Epoch: 5| Step: 9
Training loss: 3.1265695826322983
Validation loss: 2.8191245849122866

Epoch: 5| Step: 10
Training loss: 3.175493253104578
Validation loss: 2.820047622835058

Epoch: 191| Step: 0
Training loss: 3.332219287356149
Validation loss: 2.8205140380733407

Epoch: 5| Step: 1
Training loss: 3.1316631234964247
Validation loss: 2.824763455235402

Epoch: 5| Step: 2
Training loss: 3.4088410488232768
Validation loss: 2.830959096808846

Epoch: 5| Step: 3
Training loss: 2.997393906650979
Validation loss: 2.839231797845284

Epoch: 5| Step: 4
Training loss: 2.990351100963104
Validation loss: 2.8453246170851556

Epoch: 5| Step: 5
Training loss: 3.461121151703595
Validation loss: 2.8576176164693945

Epoch: 5| Step: 6
Training loss: 2.8047729309161986
Validation loss: 2.8254220297179997

Epoch: 5| Step: 7
Training loss: 3.1411713841320004
Validation loss: 2.8182589105037983

Epoch: 5| Step: 8
Training loss: 2.795631515867169
Validation loss: 2.816511839123184

Epoch: 5| Step: 9
Training loss: 2.7666639542470604
Validation loss: 2.818323261880484

Epoch: 5| Step: 10
Training loss: 3.520320350851557
Validation loss: 2.8198151249715173

Epoch: 192| Step: 0
Training loss: 3.9324188144498
Validation loss: 2.8195870031365002

Epoch: 5| Step: 1
Training loss: 2.8182214820844935
Validation loss: 2.8203326822703576

Epoch: 5| Step: 2
Training loss: 3.2929997380474045
Validation loss: 2.8197204661103066

Epoch: 5| Step: 3
Training loss: 3.1833738660645214
Validation loss: 2.8196922867656338

Epoch: 5| Step: 4
Training loss: 2.7775174930272293
Validation loss: 2.8198509616983793

Epoch: 5| Step: 5
Training loss: 2.7761016514770307
Validation loss: 2.819028042219974

Epoch: 5| Step: 6
Training loss: 2.929915355722622
Validation loss: 2.81965591341055

Epoch: 5| Step: 7
Training loss: 3.038298287690883
Validation loss: 2.8179075351769036

Epoch: 5| Step: 8
Training loss: 3.1646506433986015
Validation loss: 2.81780752630228

Epoch: 5| Step: 9
Training loss: 3.31765576155774
Validation loss: 2.818067298554081

Epoch: 5| Step: 10
Training loss: 2.9784493460863404
Validation loss: 2.8190657932234755

Epoch: 193| Step: 0
Training loss: 2.90544921343257
Validation loss: 2.817352207515443

Epoch: 5| Step: 1
Training loss: 2.999916870236994
Validation loss: 2.820445747762635

Epoch: 5| Step: 2
Training loss: 2.920943657446269
Validation loss: 2.8200402474831296

Epoch: 5| Step: 3
Training loss: 2.9074578185232025
Validation loss: 2.820019360396348

Epoch: 5| Step: 4
Training loss: 3.6252117752828474
Validation loss: 2.8215571494757024

Epoch: 5| Step: 5
Training loss: 3.538131759898553
Validation loss: 2.8178427125886447

Epoch: 5| Step: 6
Training loss: 3.070777760748603
Validation loss: 2.8189869222244774

Epoch: 5| Step: 7
Training loss: 3.2746543352420914
Validation loss: 2.8188140263420927

Epoch: 5| Step: 8
Training loss: 3.597579640454007
Validation loss: 2.816181968524603

Epoch: 5| Step: 9
Training loss: 2.5281692406705405
Validation loss: 2.8163221159316536

Epoch: 5| Step: 10
Training loss: 2.7638699410032395
Validation loss: 2.817591180349177

Epoch: 194| Step: 0
Training loss: 3.2392545739733585
Validation loss: 2.8161921705175432

Epoch: 5| Step: 1
Training loss: 2.7310307569695946
Validation loss: 2.81560220756391

Epoch: 5| Step: 2
Training loss: 3.0347851461312234
Validation loss: 2.816637885154219

Epoch: 5| Step: 3
Training loss: 2.560658328077105
Validation loss: 2.814286052964373

Epoch: 5| Step: 4
Training loss: 3.1074255578230847
Validation loss: 2.8148952197625388

Epoch: 5| Step: 5
Training loss: 3.1961838856148534
Validation loss: 2.8182547538365457

Epoch: 5| Step: 6
Training loss: 3.6791113141145253
Validation loss: 2.8174964003656355

Epoch: 5| Step: 7
Training loss: 3.1674316553030195
Validation loss: 2.818185062455898

Epoch: 5| Step: 8
Training loss: 3.26192692075223
Validation loss: 2.819225523699364

Epoch: 5| Step: 9
Training loss: 3.0856326181967906
Validation loss: 2.819639558613047

Epoch: 5| Step: 10
Training loss: 3.16865052437625
Validation loss: 2.818291370866854

Epoch: 195| Step: 0
Training loss: 3.981351295991079
Validation loss: 2.821349181750742

Epoch: 5| Step: 1
Training loss: 2.7481305964336795
Validation loss: 2.8193402103282423

Epoch: 5| Step: 2
Training loss: 3.661085403717453
Validation loss: 2.821389816630098

Epoch: 5| Step: 3
Training loss: 2.7745083313193173
Validation loss: 2.8200180476755947

Epoch: 5| Step: 4
Training loss: 2.8943248268478965
Validation loss: 2.8179792439567604

Epoch: 5| Step: 5
Training loss: 2.635736036487821
Validation loss: 2.8220189592479485

Epoch: 5| Step: 6
Training loss: 3.590862407754006
Validation loss: 2.817325707920007

Epoch: 5| Step: 7
Training loss: 2.8757719579171903
Validation loss: 2.815497679714216

Epoch: 5| Step: 8
Training loss: 2.6857680129123866
Validation loss: 2.8116530853492394

Epoch: 5| Step: 9
Training loss: 2.715888260173464
Validation loss: 2.8116388932828684

Epoch: 5| Step: 10
Training loss: 3.46661256112156
Validation loss: 2.811398734238841

Epoch: 196| Step: 0
Training loss: 2.6640897061477387
Validation loss: 2.8139905026801917

Epoch: 5| Step: 1
Training loss: 3.3017308060027575
Validation loss: 2.8110051921481154

Epoch: 5| Step: 2
Training loss: 2.643423730363619
Validation loss: 2.812080416720664

Epoch: 5| Step: 3
Training loss: 3.653568947658967
Validation loss: 2.81251895948284

Epoch: 5| Step: 4
Training loss: 3.164536579549313
Validation loss: 2.8108316958580426

Epoch: 5| Step: 5
Training loss: 3.3492919059649466
Validation loss: 2.812282203800536

Epoch: 5| Step: 6
Training loss: 3.040289702163841
Validation loss: 2.808271598946788

Epoch: 5| Step: 7
Training loss: 3.2554604069067556
Validation loss: 2.8103822298194054

Epoch: 5| Step: 8
Training loss: 2.619959578748287
Validation loss: 2.811064999650868

Epoch: 5| Step: 9
Training loss: 3.006591390469547
Validation loss: 2.809207696550578

Epoch: 5| Step: 10
Training loss: 3.46945540670172
Validation loss: 2.810731989768184

Epoch: 197| Step: 0
Training loss: 3.2359544518734515
Validation loss: 2.809399020768627

Epoch: 5| Step: 1
Training loss: 3.3156156462484403
Validation loss: 2.8080837967655463

Epoch: 5| Step: 2
Training loss: 3.018392923217291
Validation loss: 2.809691699945963

Epoch: 5| Step: 3
Training loss: 3.617828905487362
Validation loss: 2.8138414982360263

Epoch: 5| Step: 4
Training loss: 3.1242020160353765
Validation loss: 2.812365305602334

Epoch: 5| Step: 5
Training loss: 3.161024353976202
Validation loss: 2.810347975455297

Epoch: 5| Step: 6
Training loss: 2.843164572349168
Validation loss: 2.812379136673154

Epoch: 5| Step: 7
Training loss: 2.810983715345397
Validation loss: 2.8114523245468797

Epoch: 5| Step: 8
Training loss: 3.4222609768224057
Validation loss: 2.81257207087668

Epoch: 5| Step: 9
Training loss: 2.903924483313083
Validation loss: 2.8141563815697923

Epoch: 5| Step: 10
Training loss: 2.6091859486331512
Validation loss: 2.812552422658191

Epoch: 198| Step: 0
Training loss: 3.1489767743898924
Validation loss: 2.8143964018529726

Epoch: 5| Step: 1
Training loss: 3.4312313836709665
Validation loss: 2.813883493341199

Epoch: 5| Step: 2
Training loss: 2.355127515478994
Validation loss: 2.8102675406884123

Epoch: 5| Step: 3
Training loss: 3.532896215163171
Validation loss: 2.8124093782872155

Epoch: 5| Step: 4
Training loss: 2.7555162417605086
Validation loss: 2.813844617779425

Epoch: 5| Step: 5
Training loss: 3.1931910852540284
Validation loss: 2.8127077561443636

Epoch: 5| Step: 6
Training loss: 2.8999766250194465
Validation loss: 2.8095503585973525

Epoch: 5| Step: 7
Training loss: 2.6447548257596405
Validation loss: 2.809631925256739

Epoch: 5| Step: 8
Training loss: 3.4641858565443107
Validation loss: 2.806204942999787

Epoch: 5| Step: 9
Training loss: 3.3594889776722106
Validation loss: 2.807830489136253

Epoch: 5| Step: 10
Training loss: 3.2985124182855494
Validation loss: 2.8066132131431023

Epoch: 199| Step: 0
Training loss: 2.6809901860764307
Validation loss: 2.8077921533768135

Epoch: 5| Step: 1
Training loss: 3.6431866584935624
Validation loss: 2.8051925041372625

Epoch: 5| Step: 2
Training loss: 2.7660368704279583
Validation loss: 2.806676712150661

Epoch: 5| Step: 3
Training loss: 3.2212323736523447
Validation loss: 2.803417181263499

Epoch: 5| Step: 4
Training loss: 2.380481618027043
Validation loss: 2.806083858781013

Epoch: 5| Step: 5
Training loss: 3.557024043205965
Validation loss: 2.8039907412113476

Epoch: 5| Step: 6
Training loss: 3.1573608256616557
Validation loss: 2.8024952659615616

Epoch: 5| Step: 7
Training loss: 2.728364452851827
Validation loss: 2.807169224139192

Epoch: 5| Step: 8
Training loss: 2.9833386604076826
Validation loss: 2.803279623325971

Epoch: 5| Step: 9
Training loss: 3.0864816692876427
Validation loss: 2.804751197077235

Epoch: 5| Step: 10
Training loss: 3.858147676970706
Validation loss: 2.802201611917104

Epoch: 200| Step: 0
Training loss: 3.471238626826182
Validation loss: 2.802624758828939

Epoch: 5| Step: 1
Training loss: 2.858298677580989
Validation loss: 2.805864010393073

Epoch: 5| Step: 2
Training loss: 3.711571055087111
Validation loss: 2.809354841542852

Epoch: 5| Step: 3
Training loss: 2.3644963947283983
Validation loss: 2.811344327678487

Epoch: 5| Step: 4
Training loss: 3.341716968287796
Validation loss: 2.8131438508478084

Epoch: 5| Step: 5
Training loss: 2.8292156666560695
Validation loss: 2.819767267711878

Epoch: 5| Step: 6
Training loss: 3.205702623783714
Validation loss: 2.839996828015058

Epoch: 5| Step: 7
Training loss: 3.106555369543264
Validation loss: 2.82928988145389

Epoch: 5| Step: 8
Training loss: 2.837908603640143
Validation loss: 2.8261944473634797

Epoch: 5| Step: 9
Training loss: 3.365100328783426
Validation loss: 2.817690751992121

Epoch: 5| Step: 10
Training loss: 2.900163244717149
Validation loss: 2.822093632194962

Epoch: 201| Step: 0
Training loss: 3.049289314143559
Validation loss: 2.8090742077547417

Epoch: 5| Step: 1
Training loss: 3.5247141350159934
Validation loss: 2.805952061452538

Epoch: 5| Step: 2
Training loss: 3.4161471150186427
Validation loss: 2.801917402431683

Epoch: 5| Step: 3
Training loss: 3.2387334234121905
Validation loss: 2.8054106780288914

Epoch: 5| Step: 4
Training loss: 2.583964168270623
Validation loss: 2.804737472808801

Epoch: 5| Step: 5
Training loss: 2.7306377920670557
Validation loss: 2.8009442290154007

Epoch: 5| Step: 6
Training loss: 2.7730073837088427
Validation loss: 2.803965068945787

Epoch: 5| Step: 7
Training loss: 3.7289666631900995
Validation loss: 2.8013990858093827

Epoch: 5| Step: 8
Training loss: 3.303846175503878
Validation loss: 2.8020495377510137

Epoch: 5| Step: 9
Training loss: 3.1900344944825862
Validation loss: 2.801936563445698

Epoch: 5| Step: 10
Training loss: 2.2563598606066013
Validation loss: 2.8022328818827065

Epoch: 202| Step: 0
Training loss: 3.4348969747538063
Validation loss: 2.799141944135441

Epoch: 5| Step: 1
Training loss: 3.468241748862418
Validation loss: 2.80264718696636

Epoch: 5| Step: 2
Training loss: 2.5418444607778157
Validation loss: 2.8010825496258764

Epoch: 5| Step: 3
Training loss: 3.0660967822541765
Validation loss: 2.8031072978391793

Epoch: 5| Step: 4
Training loss: 2.359213210868131
Validation loss: 2.8009741511006467

Epoch: 5| Step: 5
Training loss: 3.4718564531739085
Validation loss: 2.8008245814129333

Epoch: 5| Step: 6
Training loss: 2.9242288012972626
Validation loss: 2.801018100986379

Epoch: 5| Step: 7
Training loss: 3.47799934098521
Validation loss: 2.8010812005734516

Epoch: 5| Step: 8
Training loss: 3.0795126948106577
Validation loss: 2.803763914005494

Epoch: 5| Step: 9
Training loss: 2.880788863014192
Validation loss: 2.804057032334057

Epoch: 5| Step: 10
Training loss: 3.296150597992822
Validation loss: 2.8021514722050194

Epoch: 203| Step: 0
Training loss: 3.1037775772965133
Validation loss: 2.807504716657961

Epoch: 5| Step: 1
Training loss: 2.6427002827109853
Validation loss: 2.802446416778935

Epoch: 5| Step: 2
Training loss: 2.6486079968511547
Validation loss: 2.802366435838748

Epoch: 5| Step: 3
Training loss: 3.677547537200124
Validation loss: 2.8002845897138484

Epoch: 5| Step: 4
Training loss: 2.839359121410484
Validation loss: 2.7992208943870476

Epoch: 5| Step: 5
Training loss: 3.5072211295953215
Validation loss: 2.8013323529163907

Epoch: 5| Step: 6
Training loss: 3.195421286971862
Validation loss: 2.7988852424307273

Epoch: 5| Step: 7
Training loss: 2.75938841664216
Validation loss: 2.8002500351369632

Epoch: 5| Step: 8
Training loss: 3.3533987425940053
Validation loss: 2.798623669520824

Epoch: 5| Step: 9
Training loss: 3.083655641223167
Validation loss: 2.7995393837101714

Epoch: 5| Step: 10
Training loss: 3.2336624023935783
Validation loss: 2.7991534244998197

Epoch: 204| Step: 0
Training loss: 3.3411755499802958
Validation loss: 2.8003284213394593

Epoch: 5| Step: 1
Training loss: 2.654859919615259
Validation loss: 2.7999456610585467

Epoch: 5| Step: 2
Training loss: 2.9111821152211346
Validation loss: 2.7970882739368137

Epoch: 5| Step: 3
Training loss: 3.084768339389951
Validation loss: 2.799352847447622

Epoch: 5| Step: 4
Training loss: 3.6409469265693404
Validation loss: 2.797992821377975

Epoch: 5| Step: 5
Training loss: 3.389670804674475
Validation loss: 2.7992240897536904

Epoch: 5| Step: 6
Training loss: 3.6409050174803346
Validation loss: 2.7987581495666247

Epoch: 5| Step: 7
Training loss: 2.5671547272924284
Validation loss: 2.8001820810140585

Epoch: 5| Step: 8
Training loss: 2.7770193261918816
Validation loss: 2.8019113929719697

Epoch: 5| Step: 9
Training loss: 3.09167133204133
Validation loss: 2.8021057121303308

Epoch: 5| Step: 10
Training loss: 2.814702930257793
Validation loss: 2.8061531106991016

Epoch: 205| Step: 0
Training loss: 3.0353669200234035
Validation loss: 2.8063674371231637

Epoch: 5| Step: 1
Training loss: 3.164107861605778
Validation loss: 2.8141580094908707

Epoch: 5| Step: 2
Training loss: 2.68055021673098
Validation loss: 2.820596097512682

Epoch: 5| Step: 3
Training loss: 3.188875686878105
Validation loss: 2.82816521391591

Epoch: 5| Step: 4
Training loss: 3.570654120263907
Validation loss: 2.8228841848691415

Epoch: 5| Step: 5
Training loss: 3.570745996915393
Validation loss: 2.823276329006478

Epoch: 5| Step: 6
Training loss: 3.2488517199887905
Validation loss: 2.819192412538086

Epoch: 5| Step: 7
Training loss: 3.027882071593532
Validation loss: 2.816521900658369

Epoch: 5| Step: 8
Training loss: 3.1909998211216557
Validation loss: 2.79757118417297

Epoch: 5| Step: 9
Training loss: 3.044303239052199
Validation loss: 2.7985738550280725

Epoch: 5| Step: 10
Training loss: 2.088368231848889
Validation loss: 2.796407898325449

Epoch: 206| Step: 0
Training loss: 3.2625908148392195
Validation loss: 2.795323313426176

Epoch: 5| Step: 1
Training loss: 2.6326561946485136
Validation loss: 2.7944283741423304

Epoch: 5| Step: 2
Training loss: 3.40247632895034
Validation loss: 2.7953450710430667

Epoch: 5| Step: 3
Training loss: 3.2134210119776907
Validation loss: 2.795282919600017

Epoch: 5| Step: 4
Training loss: 2.8184146994634864
Validation loss: 2.7956668134490648

Epoch: 5| Step: 5
Training loss: 3.1363955434550794
Validation loss: 2.795368292187373

Epoch: 5| Step: 6
Training loss: 2.8536536505162102
Validation loss: 2.794015598401942

Epoch: 5| Step: 7
Training loss: 3.383611219172103
Validation loss: 2.795177078843907

Epoch: 5| Step: 8
Training loss: 2.9755333750895776
Validation loss: 2.796145581147808

Epoch: 5| Step: 9
Training loss: 3.265919649255858
Validation loss: 2.8012756660920743

Epoch: 5| Step: 10
Training loss: 3.1490726256295294
Validation loss: 2.7941693924801205

Epoch: 207| Step: 0
Training loss: 2.8117387377131067
Validation loss: 2.7958881376164575

Epoch: 5| Step: 1
Training loss: 2.6489890995456586
Validation loss: 2.7966495344439095

Epoch: 5| Step: 2
Training loss: 3.23524279171219
Validation loss: 2.7979986944878346

Epoch: 5| Step: 3
Training loss: 3.7109687241696254
Validation loss: 2.795384862355192

Epoch: 5| Step: 4
Training loss: 2.7243400194478187
Validation loss: 2.7970896432458225

Epoch: 5| Step: 5
Training loss: 2.9593106835857674
Validation loss: 2.797718134810706

Epoch: 5| Step: 6
Training loss: 3.3546253783146947
Validation loss: 2.795326642561636

Epoch: 5| Step: 7
Training loss: 3.279271573848941
Validation loss: 2.796794846899132

Epoch: 5| Step: 8
Training loss: 3.1143527418700434
Validation loss: 2.8043388410262455

Epoch: 5| Step: 9
Training loss: 2.497000038730558
Validation loss: 2.80788444062442

Epoch: 5| Step: 10
Training loss: 3.637305190909727
Validation loss: 2.796558583360404

Epoch: 208| Step: 0
Training loss: 2.9340137328364118
Validation loss: 2.7946238181510963

Epoch: 5| Step: 1
Training loss: 2.941401062412424
Validation loss: 2.7965364895815035

Epoch: 5| Step: 2
Training loss: 2.763482939930976
Validation loss: 2.7930108900539063

Epoch: 5| Step: 3
Training loss: 3.0279507330007025
Validation loss: 2.7928909090121903

Epoch: 5| Step: 4
Training loss: 3.202268904746393
Validation loss: 2.7930369044045045

Epoch: 5| Step: 5
Training loss: 3.4896110571523864
Validation loss: 2.791676866723645

Epoch: 5| Step: 6
Training loss: 3.2591378788630503
Validation loss: 2.79592531531349

Epoch: 5| Step: 7
Training loss: 3.5108018129933205
Validation loss: 2.79398057174314

Epoch: 5| Step: 8
Training loss: 3.0867095367827098
Validation loss: 2.791161844313983

Epoch: 5| Step: 9
Training loss: 2.5841465767189487
Validation loss: 2.790345869607904

Epoch: 5| Step: 10
Training loss: 3.1890718660866564
Validation loss: 2.7908081086847165

Epoch: 209| Step: 0
Training loss: 2.903925632743609
Validation loss: 2.7918949287945654

Epoch: 5| Step: 1
Training loss: 2.938851228347294
Validation loss: 2.7885605302418464

Epoch: 5| Step: 2
Training loss: 3.4159202845918455
Validation loss: 2.7890907489075274

Epoch: 5| Step: 3
Training loss: 3.2487723159170367
Validation loss: 2.7909870134613364

Epoch: 5| Step: 4
Training loss: 3.078080075318581
Validation loss: 2.7894127228533816

Epoch: 5| Step: 5
Training loss: 3.050571175545706
Validation loss: 2.790020894844802

Epoch: 5| Step: 6
Training loss: 2.3870873299306274
Validation loss: 2.789922821277673

Epoch: 5| Step: 7
Training loss: 3.2520949140917197
Validation loss: 2.7971528131226733

Epoch: 5| Step: 8
Training loss: 3.2457701226781324
Validation loss: 2.7957958220814163

Epoch: 5| Step: 9
Training loss: 3.2775365252172706
Validation loss: 2.801089536498936

Epoch: 5| Step: 10
Training loss: 3.211460934041014
Validation loss: 2.8063377954413387

Epoch: 210| Step: 0
Training loss: 2.9557018844532923
Validation loss: 2.8027055565440544

Epoch: 5| Step: 1
Training loss: 3.076053910188544
Validation loss: 2.794995349386551

Epoch: 5| Step: 2
Training loss: 2.790163309110043
Validation loss: 2.802977976346248

Epoch: 5| Step: 3
Training loss: 2.9466925102354895
Validation loss: 2.806764911256897

Epoch: 5| Step: 4
Training loss: 3.4620570316035644
Validation loss: 2.8061089808650928

Epoch: 5| Step: 5
Training loss: 3.0831428331516295
Validation loss: 2.7965395642583393

Epoch: 5| Step: 6
Training loss: 3.538477969370684
Validation loss: 2.788800573879704

Epoch: 5| Step: 7
Training loss: 3.1460904822606106
Validation loss: 2.7905827510111227

Epoch: 5| Step: 8
Training loss: 3.2863529307314434
Validation loss: 2.7925257177603835

Epoch: 5| Step: 9
Training loss: 2.982445217758192
Validation loss: 2.7894656207496857

Epoch: 5| Step: 10
Training loss: 2.640546537960375
Validation loss: 2.7880065763002273

Epoch: 211| Step: 0
Training loss: 3.0697399896613358
Validation loss: 2.7881634722073145

Epoch: 5| Step: 1
Training loss: 2.9269583642602917
Validation loss: 2.790390474744278

Epoch: 5| Step: 2
Training loss: 3.2948182547058598
Validation loss: 2.7898442033578776

Epoch: 5| Step: 3
Training loss: 2.719871289770209
Validation loss: 2.7900157767858427

Epoch: 5| Step: 4
Training loss: 3.290952017421287
Validation loss: 2.789366736334726

Epoch: 5| Step: 5
Training loss: 2.906185190442106
Validation loss: 2.7893773539425464

Epoch: 5| Step: 6
Training loss: 3.412830680503236
Validation loss: 2.790985837726484

Epoch: 5| Step: 7
Training loss: 3.5208336794399715
Validation loss: 2.7904987506318277

Epoch: 5| Step: 8
Training loss: 2.646712109666459
Validation loss: 2.791925296793416

Epoch: 5| Step: 9
Training loss: 3.097707817735569
Validation loss: 2.7977221281857987

Epoch: 5| Step: 10
Training loss: 3.093898731085963
Validation loss: 2.7960194731889545

Epoch: 212| Step: 0
Training loss: 2.248122385515056
Validation loss: 2.7969148190422204

Epoch: 5| Step: 1
Training loss: 3.2451408447358414
Validation loss: 2.802857866768417

Epoch: 5| Step: 2
Training loss: 3.0822725963013324
Validation loss: 2.7994798876720206

Epoch: 5| Step: 3
Training loss: 2.6966710301927015
Validation loss: 2.802309843118991

Epoch: 5| Step: 4
Training loss: 3.464950267440351
Validation loss: 2.8000415963717677

Epoch: 5| Step: 5
Training loss: 2.9681625588105685
Validation loss: 2.7940560610141905

Epoch: 5| Step: 6
Training loss: 3.391420613829436
Validation loss: 2.790571861007815

Epoch: 5| Step: 7
Training loss: 3.146996861875974
Validation loss: 2.7898541570699136

Epoch: 5| Step: 8
Training loss: 2.740705562438342
Validation loss: 2.7886985715328247

Epoch: 5| Step: 9
Training loss: 3.6555752906021826
Validation loss: 2.7861570544823073

Epoch: 5| Step: 10
Training loss: 3.1889917211607552
Validation loss: 2.787074188880237

Epoch: 213| Step: 0
Training loss: 2.80956988820274
Validation loss: 2.784628016471962

Epoch: 5| Step: 1
Training loss: 3.3000296735874386
Validation loss: 2.786291705625469

Epoch: 5| Step: 2
Training loss: 3.4314930536176766
Validation loss: 2.785428894226222

Epoch: 5| Step: 3
Training loss: 2.5249403502717485
Validation loss: 2.786310454247291

Epoch: 5| Step: 4
Training loss: 2.848269047362294
Validation loss: 2.788316216371374

Epoch: 5| Step: 5
Training loss: 3.1887922472456167
Validation loss: 2.7898125115019963

Epoch: 5| Step: 6
Training loss: 3.0478509366989104
Validation loss: 2.7934083392589257

Epoch: 5| Step: 7
Training loss: 3.1238266840296163
Validation loss: 2.7921836841386702

Epoch: 5| Step: 8
Training loss: 3.360782488126109
Validation loss: 2.793430765221584

Epoch: 5| Step: 9
Training loss: 3.037411748914903
Validation loss: 2.7899756111828276

Epoch: 5| Step: 10
Training loss: 3.2920796742861715
Validation loss: 2.7897552413983746

Epoch: 214| Step: 0
Training loss: 3.5582681249380568
Validation loss: 2.7847503631909927

Epoch: 5| Step: 1
Training loss: 2.424925034140976
Validation loss: 2.7850333909000553

Epoch: 5| Step: 2
Training loss: 3.63456529560283
Validation loss: 2.7817425883285325

Epoch: 5| Step: 3
Training loss: 3.4104356159731624
Validation loss: 2.7844100795072895

Epoch: 5| Step: 4
Training loss: 3.666499582009452
Validation loss: 2.783734222268231

Epoch: 5| Step: 5
Training loss: 2.387609037935186
Validation loss: 2.7829289721105805

Epoch: 5| Step: 6
Training loss: 3.2413081803637205
Validation loss: 2.7830667013466286

Epoch: 5| Step: 7
Training loss: 3.047309570621544
Validation loss: 2.7817300066823187

Epoch: 5| Step: 8
Training loss: 2.7674818109674444
Validation loss: 2.7796937709570844

Epoch: 5| Step: 9
Training loss: 2.5260808463187936
Validation loss: 2.7847187422494337

Epoch: 5| Step: 10
Training loss: 2.9803404374206655
Validation loss: 2.7829812037921706

Epoch: 215| Step: 0
Training loss: 2.9339363720943314
Validation loss: 2.7839366716014515

Epoch: 5| Step: 1
Training loss: 2.9025819662712116
Validation loss: 2.7845170034576765

Epoch: 5| Step: 2
Training loss: 3.374968634565625
Validation loss: 2.780359692341004

Epoch: 5| Step: 3
Training loss: 2.744391965385789
Validation loss: 2.7796673273773274

Epoch: 5| Step: 4
Training loss: 2.864673478991166
Validation loss: 2.779138210149899

Epoch: 5| Step: 5
Training loss: 3.4778690926044025
Validation loss: 2.7789645204803093

Epoch: 5| Step: 6
Training loss: 3.387765830332284
Validation loss: 2.778315704380521

Epoch: 5| Step: 7
Training loss: 2.192495908135279
Validation loss: 2.7812047053436437

Epoch: 5| Step: 8
Training loss: 3.125780542169065
Validation loss: 2.7809287504773685

Epoch: 5| Step: 9
Training loss: 3.3755109894655124
Validation loss: 2.7806306522468036

Epoch: 5| Step: 10
Training loss: 3.45194524574395
Validation loss: 2.7808381029451397

Epoch: 216| Step: 0
Training loss: 2.667565333416303
Validation loss: 2.781588590114783

Epoch: 5| Step: 1
Training loss: 3.033234251590934
Validation loss: 2.7777796136856847

Epoch: 5| Step: 2
Training loss: 3.4056661962970747
Validation loss: 2.782434303298191

Epoch: 5| Step: 3
Training loss: 3.2380687611696866
Validation loss: 2.7828071035867925

Epoch: 5| Step: 4
Training loss: 3.197351975343947
Validation loss: 2.7815168823489134

Epoch: 5| Step: 5
Training loss: 2.9216990698413676
Validation loss: 2.7873964472648924

Epoch: 5| Step: 6
Training loss: 2.8016927132501093
Validation loss: 2.786578998285706

Epoch: 5| Step: 7
Training loss: 3.0981449545040096
Validation loss: 2.788329475331562

Epoch: 5| Step: 8
Training loss: 2.9429185280237458
Validation loss: 2.787063967685878

Epoch: 5| Step: 9
Training loss: 3.5467205266041826
Validation loss: 2.7918714308329253

Epoch: 5| Step: 10
Training loss: 3.030121426053487
Validation loss: 2.7929385493899046

Epoch: 217| Step: 0
Training loss: 3.453080535188126
Validation loss: 2.80390568875965

Epoch: 5| Step: 1
Training loss: 3.393488505424793
Validation loss: 2.7830012109380124

Epoch: 5| Step: 2
Training loss: 2.63507019499598
Validation loss: 2.7821407313586306

Epoch: 5| Step: 3
Training loss: 2.8363052003682943
Validation loss: 2.7759620417902098

Epoch: 5| Step: 4
Training loss: 2.528008351505343
Validation loss: 2.776529721548046

Epoch: 5| Step: 5
Training loss: 3.057384968275713
Validation loss: 2.7770255307614002

Epoch: 5| Step: 6
Training loss: 3.231649236161545
Validation loss: 2.777971441292768

Epoch: 5| Step: 7
Training loss: 3.311542300567406
Validation loss: 2.7759614138004167

Epoch: 5| Step: 8
Training loss: 2.753711103735189
Validation loss: 2.775252553615932

Epoch: 5| Step: 9
Training loss: 3.1285205084183545
Validation loss: 2.77743345102236

Epoch: 5| Step: 10
Training loss: 3.593822445346564
Validation loss: 2.7759584326939883

Epoch: 218| Step: 0
Training loss: 3.0837385237858697
Validation loss: 2.7771074619049223

Epoch: 5| Step: 1
Training loss: 3.2921377561166882
Validation loss: 2.7754893690951734

Epoch: 5| Step: 2
Training loss: 3.037431215362995
Validation loss: 2.7774036519219574

Epoch: 5| Step: 3
Training loss: 3.366691251860135
Validation loss: 2.7756706281808854

Epoch: 5| Step: 4
Training loss: 2.708346841240478
Validation loss: 2.775255575201821

Epoch: 5| Step: 5
Training loss: 3.669911610425041
Validation loss: 2.7756031723367305

Epoch: 5| Step: 6
Training loss: 3.214997706197392
Validation loss: 2.775221557922175

Epoch: 5| Step: 7
Training loss: 2.6971463806178977
Validation loss: 2.7725652284055236

Epoch: 5| Step: 8
Training loss: 2.7302797003748633
Validation loss: 2.774322121882362

Epoch: 5| Step: 9
Training loss: 3.1925284421605244
Validation loss: 2.771880406671786

Epoch: 5| Step: 10
Training loss: 2.78083223784321
Validation loss: 2.7742289020480113

Epoch: 219| Step: 0
Training loss: 3.3780069025306805
Validation loss: 2.7799007917348786

Epoch: 5| Step: 1
Training loss: 2.8837136614973318
Validation loss: 2.7811959051586657

Epoch: 5| Step: 2
Training loss: 2.7160968331110613
Validation loss: 2.791010328732291

Epoch: 5| Step: 3
Training loss: 3.1351945530148373
Validation loss: 2.7905107957258535

Epoch: 5| Step: 4
Training loss: 3.3677714609274054
Validation loss: 2.800093006202259

Epoch: 5| Step: 5
Training loss: 2.8839886341479453
Validation loss: 2.792832364602422

Epoch: 5| Step: 6
Training loss: 2.907438465887518
Validation loss: 2.7878322997922584

Epoch: 5| Step: 7
Training loss: 3.9209136392529094
Validation loss: 2.7928825587133477

Epoch: 5| Step: 8
Training loss: 2.9857171520811288
Validation loss: 2.7848974950882455

Epoch: 5| Step: 9
Training loss: 3.073334194632828
Validation loss: 2.7849224538801587

Epoch: 5| Step: 10
Training loss: 2.355146851061198
Validation loss: 2.7813226225551

Epoch: 220| Step: 0
Training loss: 3.052817940864787
Validation loss: 2.7797088565598673

Epoch: 5| Step: 1
Training loss: 3.478586769126128
Validation loss: 2.782137557837146

Epoch: 5| Step: 2
Training loss: 2.6061355675473883
Validation loss: 2.790649979809632

Epoch: 5| Step: 3
Training loss: 2.1978922717531955
Validation loss: 2.797660880840922

Epoch: 5| Step: 4
Training loss: 3.4411776203673345
Validation loss: 2.796394886691412

Epoch: 5| Step: 5
Training loss: 3.4475054692590827
Validation loss: 2.785826498456009

Epoch: 5| Step: 6
Training loss: 3.3136827768409316
Validation loss: 2.778485144170533

Epoch: 5| Step: 7
Training loss: 3.4424304628794253
Validation loss: 2.7718635137932983

Epoch: 5| Step: 8
Training loss: 3.07116718383968
Validation loss: 2.7714585209520304

Epoch: 5| Step: 9
Training loss: 2.9471344106497814
Validation loss: 2.7734352935638964

Epoch: 5| Step: 10
Training loss: 2.5570852244246187
Validation loss: 2.7719570406875103

Epoch: 221| Step: 0
Training loss: 2.6051356432958923
Validation loss: 2.77173341251978

Epoch: 5| Step: 1
Training loss: 2.88731285248372
Validation loss: 2.7752432477388767

Epoch: 5| Step: 2
Training loss: 3.405795145725297
Validation loss: 2.7712287904366417

Epoch: 5| Step: 3
Training loss: 2.677531183882201
Validation loss: 2.770586716320584

Epoch: 5| Step: 4
Training loss: 3.0402653919624276
Validation loss: 2.7709089298623684

Epoch: 5| Step: 5
Training loss: 3.1195548874675776
Validation loss: 2.769518786903517

Epoch: 5| Step: 6
Training loss: 3.230486610298648
Validation loss: 2.769232190560978

Epoch: 5| Step: 7
Training loss: 3.3393982707288563
Validation loss: 2.7694763375315206

Epoch: 5| Step: 8
Training loss: 3.1780976390879907
Validation loss: 2.769597193139159

Epoch: 5| Step: 9
Training loss: 2.95726425482468
Validation loss: 2.770871250899481

Epoch: 5| Step: 10
Training loss: 3.454761790387336
Validation loss: 2.7736472152645337

Epoch: 222| Step: 0
Training loss: 2.9019257564078247
Validation loss: 2.774615721852903

Epoch: 5| Step: 1
Training loss: 3.1907324762578244
Validation loss: 2.7824447939528003

Epoch: 5| Step: 2
Training loss: 3.2997254979954898
Validation loss: 2.7891201023564656

Epoch: 5| Step: 3
Training loss: 3.6633520027173185
Validation loss: 2.7930954105666124

Epoch: 5| Step: 4
Training loss: 2.879920563397027
Validation loss: 2.792133415947005

Epoch: 5| Step: 5
Training loss: 3.4994296562885108
Validation loss: 2.7993350268852883

Epoch: 5| Step: 6
Training loss: 2.691736652263583
Validation loss: 2.781596017651828

Epoch: 5| Step: 7
Training loss: 3.015628794929607
Validation loss: 2.7855320839005135

Epoch: 5| Step: 8
Training loss: 3.0635937664362536
Validation loss: 2.774576910540329

Epoch: 5| Step: 9
Training loss: 2.9027179872073066
Validation loss: 2.769428424073895

Epoch: 5| Step: 10
Training loss: 2.5574163858387706
Validation loss: 2.771576337605209

Epoch: 223| Step: 0
Training loss: 2.824921706473487
Validation loss: 2.7708165398556894

Epoch: 5| Step: 1
Training loss: 3.1773935802295696
Validation loss: 2.7677206399789966

Epoch: 5| Step: 2
Training loss: 3.12238079933872
Validation loss: 2.767929786245645

Epoch: 5| Step: 3
Training loss: 2.824589748470008
Validation loss: 2.767995615644917

Epoch: 5| Step: 4
Training loss: 2.8463647579869757
Validation loss: 2.7676838040578553

Epoch: 5| Step: 5
Training loss: 3.1685012388679934
Validation loss: 2.7661205784196627

Epoch: 5| Step: 6
Training loss: 2.7496051504864374
Validation loss: 2.7674183325053243

Epoch: 5| Step: 7
Training loss: 3.4604187311805172
Validation loss: 2.7654932675633366

Epoch: 5| Step: 8
Training loss: 3.1951783392239315
Validation loss: 2.768698796676336

Epoch: 5| Step: 9
Training loss: 3.4177308789995577
Validation loss: 2.770982091739202

Epoch: 5| Step: 10
Training loss: 3.0062356357667483
Validation loss: 2.7699718349655704

Epoch: 224| Step: 0
Training loss: 2.7843510345215385
Validation loss: 2.7757770723371413

Epoch: 5| Step: 1
Training loss: 3.3477706266469536
Validation loss: 2.7695473212393376

Epoch: 5| Step: 2
Training loss: 3.736961841432327
Validation loss: 2.76844207707695

Epoch: 5| Step: 3
Training loss: 3.058382029409894
Validation loss: 2.7707062475528703

Epoch: 5| Step: 4
Training loss: 2.8764666257978058
Validation loss: 2.76960703634168

Epoch: 5| Step: 5
Training loss: 2.7031862108653915
Validation loss: 2.770101725600407

Epoch: 5| Step: 6
Training loss: 3.111992429228843
Validation loss: 2.7739457691453

Epoch: 5| Step: 7
Training loss: 2.859079814745465
Validation loss: 2.7743855782182285

Epoch: 5| Step: 8
Training loss: 3.2273961945970338
Validation loss: 2.788485515527628

Epoch: 5| Step: 9
Training loss: 3.3787330891774854
Validation loss: 2.788733255452068

Epoch: 5| Step: 10
Training loss: 2.554512321228908
Validation loss: 2.791123703958579

Epoch: 225| Step: 0
Training loss: 3.5391235346299488
Validation loss: 2.7895549053293767

Epoch: 5| Step: 1
Training loss: 3.2661167486363154
Validation loss: 2.781765287125862

Epoch: 5| Step: 2
Training loss: 3.1023323391253252
Validation loss: 2.7741134002513843

Epoch: 5| Step: 3
Training loss: 2.945463060330329
Validation loss: 2.7695925603239093

Epoch: 5| Step: 4
Training loss: 2.7091489492975427
Validation loss: 2.7635927867396477

Epoch: 5| Step: 5
Training loss: 3.357523563214272
Validation loss: 2.762744098993299

Epoch: 5| Step: 6
Training loss: 2.6420759920833303
Validation loss: 2.7637843273032754

Epoch: 5| Step: 7
Training loss: 3.602391344135347
Validation loss: 2.7612271834582116

Epoch: 5| Step: 8
Training loss: 2.891726722057012
Validation loss: 2.76176834276582

Epoch: 5| Step: 9
Training loss: 2.9484495258743055
Validation loss: 2.7637631022569886

Epoch: 5| Step: 10
Training loss: 2.6163961096516135
Validation loss: 2.7637689803922814

Epoch: 226| Step: 0
Training loss: 3.1090010988485677
Validation loss: 2.7667316447175336

Epoch: 5| Step: 1
Training loss: 2.96305686770972
Validation loss: 2.775343830662425

Epoch: 5| Step: 2
Training loss: 2.876789696966271
Validation loss: 2.775251434953981

Epoch: 5| Step: 3
Training loss: 3.258161713616314
Validation loss: 2.771683442166619

Epoch: 5| Step: 4
Training loss: 3.167679440685315
Validation loss: 2.777092388941968

Epoch: 5| Step: 5
Training loss: 2.799146358609007
Validation loss: 2.773497196047851

Epoch: 5| Step: 6
Training loss: 3.3236739074099693
Validation loss: 2.766518568695133

Epoch: 5| Step: 7
Training loss: 3.181162349190424
Validation loss: 2.763793587353467

Epoch: 5| Step: 8
Training loss: 2.9442424904843416
Validation loss: 2.762704257914865

Epoch: 5| Step: 9
Training loss: 3.178062979994193
Validation loss: 2.7622327820930375

Epoch: 5| Step: 10
Training loss: 3.0026946681406965
Validation loss: 2.762300341704769

Epoch: 227| Step: 0
Training loss: 3.347950658683021
Validation loss: 2.760870351597588

Epoch: 5| Step: 1
Training loss: 3.247525667084715
Validation loss: 2.7598129853741833

Epoch: 5| Step: 2
Training loss: 2.97372918434763
Validation loss: 2.7596370798093153

Epoch: 5| Step: 3
Training loss: 3.096547720944397
Validation loss: 2.7601768855415885

Epoch: 5| Step: 4
Training loss: 3.123352837381224
Validation loss: 2.758188674678173

Epoch: 5| Step: 5
Training loss: 3.445371735424738
Validation loss: 2.7590999206346316

Epoch: 5| Step: 6
Training loss: 3.0196634241467035
Validation loss: 2.7584663477511304

Epoch: 5| Step: 7
Training loss: 3.0427119057301453
Validation loss: 2.7583486691221992

Epoch: 5| Step: 8
Training loss: 2.518758776628145
Validation loss: 2.7601188593442747

Epoch: 5| Step: 9
Training loss: 2.838836449298243
Validation loss: 2.7598895754785766

Epoch: 5| Step: 10
Training loss: 3.087118111286354
Validation loss: 2.7614544623961113

Epoch: 228| Step: 0
Training loss: 3.3596043708032517
Validation loss: 2.7651303229377215

Epoch: 5| Step: 1
Training loss: 3.16633897056229
Validation loss: 2.7708340321855376

Epoch: 5| Step: 2
Training loss: 3.4203563089645264
Validation loss: 2.7741986475977782

Epoch: 5| Step: 3
Training loss: 3.3641913375598733
Validation loss: 2.768874826517643

Epoch: 5| Step: 4
Training loss: 2.9228345957785202
Validation loss: 2.7669230282178936

Epoch: 5| Step: 5
Training loss: 2.9217055980513456
Validation loss: 2.7640583970033004

Epoch: 5| Step: 6
Training loss: 2.9821681306288514
Validation loss: 2.762132805796675

Epoch: 5| Step: 7
Training loss: 2.638843183512042
Validation loss: 2.7622674243038388

Epoch: 5| Step: 8
Training loss: 3.214060060966579
Validation loss: 2.765333652184391

Epoch: 5| Step: 9
Training loss: 2.6683607581415223
Validation loss: 2.761841255742267

Epoch: 5| Step: 10
Training loss: 3.055054625477004
Validation loss: 2.7580952358088227

Epoch: 229| Step: 0
Training loss: 2.4658052289142622
Validation loss: 2.7601687641393653

Epoch: 5| Step: 1
Training loss: 3.0242882450823467
Validation loss: 2.7577093970160242

Epoch: 5| Step: 2
Training loss: 3.1456959338634745
Validation loss: 2.7557322495628243

Epoch: 5| Step: 3
Training loss: 2.8107798932406376
Validation loss: 2.757871917025976

Epoch: 5| Step: 4
Training loss: 3.033378090021738
Validation loss: 2.7602926017818508

Epoch: 5| Step: 5
Training loss: 3.176251328553241
Validation loss: 2.761079648148536

Epoch: 5| Step: 6
Training loss: 3.0011918561419972
Validation loss: 2.7677959729501014

Epoch: 5| Step: 7
Training loss: 3.3241131739991476
Validation loss: 2.763212730224338

Epoch: 5| Step: 8
Training loss: 3.0694145462014584
Validation loss: 2.7675094353390066

Epoch: 5| Step: 9
Training loss: 3.1887932939928803
Validation loss: 2.7657337013250367

Epoch: 5| Step: 10
Training loss: 3.494455168774484
Validation loss: 2.7630970861746964

Epoch: 230| Step: 0
Training loss: 3.3673924076192976
Validation loss: 2.774994091924505

Epoch: 5| Step: 1
Training loss: 3.006931403770292
Validation loss: 2.7674209457809296

Epoch: 5| Step: 2
Training loss: 2.888040738027148
Validation loss: 2.7781241054052

Epoch: 5| Step: 3
Training loss: 2.7242577548088636
Validation loss: 2.776587180421397

Epoch: 5| Step: 4
Training loss: 3.416955485968587
Validation loss: 2.795740789103157

Epoch: 5| Step: 5
Training loss: 2.7662716556740845
Validation loss: 2.781592319092927

Epoch: 5| Step: 6
Training loss: 3.5327613769503547
Validation loss: 2.78290101532204

Epoch: 5| Step: 7
Training loss: 2.8705966233624776
Validation loss: 2.7774164950005304

Epoch: 5| Step: 8
Training loss: 2.5689743872138244
Validation loss: 2.7810101278336075

Epoch: 5| Step: 9
Training loss: 3.0185126675334755
Validation loss: 2.7715677695424823

Epoch: 5| Step: 10
Training loss: 3.4999978201723123
Validation loss: 2.7626795447438552

Epoch: 231| Step: 0
Training loss: 3.2157481000376116
Validation loss: 2.754947965403125

Epoch: 5| Step: 1
Training loss: 3.394766532724532
Validation loss: 2.7513265374784415

Epoch: 5| Step: 2
Training loss: 2.367166248389806
Validation loss: 2.7595344073108445

Epoch: 5| Step: 3
Training loss: 2.9012172972263035
Validation loss: 2.757230419115877

Epoch: 5| Step: 4
Training loss: 3.0168935054688033
Validation loss: 2.7617060938392255

Epoch: 5| Step: 5
Training loss: 2.9343424932367297
Validation loss: 2.76733041995733

Epoch: 5| Step: 6
Training loss: 3.4154281852676545
Validation loss: 2.770023515968047

Epoch: 5| Step: 7
Training loss: 3.4445139679677452
Validation loss: 2.769849563875464

Epoch: 5| Step: 8
Training loss: 3.2952955177705197
Validation loss: 2.765018092266142

Epoch: 5| Step: 9
Training loss: 3.339307311405664
Validation loss: 2.761004355697719

Epoch: 5| Step: 10
Training loss: 2.3066821760784446
Validation loss: 2.756297998970984

Epoch: 232| Step: 0
Training loss: 2.8640460441020874
Validation loss: 2.7597158095257206

Epoch: 5| Step: 1
Training loss: 3.475905727113337
Validation loss: 2.76748245570291

Epoch: 5| Step: 2
Training loss: 3.1897583983001545
Validation loss: 2.7731797917367556

Epoch: 5| Step: 3
Training loss: 3.1793359660562133
Validation loss: 2.769656233317214

Epoch: 5| Step: 4
Training loss: 2.937236855266035
Validation loss: 2.7833870289838627

Epoch: 5| Step: 5
Training loss: 3.1823146754721767
Validation loss: 2.785672397464619

Epoch: 5| Step: 6
Training loss: 2.598457751995173
Validation loss: 2.7866172256839192

Epoch: 5| Step: 7
Training loss: 2.927351119167316
Validation loss: 2.7842875327642553

Epoch: 5| Step: 8
Training loss: 3.0663020608294724
Validation loss: 2.80160080493646

Epoch: 5| Step: 9
Training loss: 3.303177581051011
Validation loss: 2.8155211325542973

Epoch: 5| Step: 10
Training loss: 3.057342702167772
Validation loss: 2.803604145716276

Epoch: 233| Step: 0
Training loss: 2.9894691649290386
Validation loss: 2.777032236592112

Epoch: 5| Step: 1
Training loss: 2.7975123867275444
Validation loss: 2.75531246344356

Epoch: 5| Step: 2
Training loss: 3.2110862975901613
Validation loss: 2.7531486321467074

Epoch: 5| Step: 3
Training loss: 2.658762024501194
Validation loss: 2.756355533602948

Epoch: 5| Step: 4
Training loss: 3.613536994749986
Validation loss: 2.754505348712919

Epoch: 5| Step: 5
Training loss: 3.251678326884183
Validation loss: 2.753353333179958

Epoch: 5| Step: 6
Training loss: 3.055397829165658
Validation loss: 2.7549999161411267

Epoch: 5| Step: 7
Training loss: 3.057841592142523
Validation loss: 2.7568258571339843

Epoch: 5| Step: 8
Training loss: 3.1598902190731626
Validation loss: 2.7526304784483835

Epoch: 5| Step: 9
Training loss: 2.9701234551661693
Validation loss: 2.755826763001599

Epoch: 5| Step: 10
Training loss: 3.0193974908217314
Validation loss: 2.756490013877143

Epoch: 234| Step: 0
Training loss: 2.7813321219332217
Validation loss: 2.7546897511960498

Epoch: 5| Step: 1
Training loss: 3.4706838904573933
Validation loss: 2.7568966588365145

Epoch: 5| Step: 2
Training loss: 2.4952578391129814
Validation loss: 2.754573899170268

Epoch: 5| Step: 3
Training loss: 3.4857585537889024
Validation loss: 2.7538765519285637

Epoch: 5| Step: 4
Training loss: 3.1348669303140073
Validation loss: 2.7574730999233172

Epoch: 5| Step: 5
Training loss: 3.191429259498601
Validation loss: 2.755801061606029

Epoch: 5| Step: 6
Training loss: 3.0226390484172274
Validation loss: 2.759244532903456

Epoch: 5| Step: 7
Training loss: 3.100149913977668
Validation loss: 2.7599068361044172

Epoch: 5| Step: 8
Training loss: 2.639635792376297
Validation loss: 2.7627434327375284

Epoch: 5| Step: 9
Training loss: 3.2998452930599464
Validation loss: 2.7653312992955468

Epoch: 5| Step: 10
Training loss: 3.047457282351362
Validation loss: 2.7622961319225783

Epoch: 235| Step: 0
Training loss: 3.6746949101660524
Validation loss: 2.7607881679516266

Epoch: 5| Step: 1
Training loss: 2.8223356561650834
Validation loss: 2.7630211147780517

Epoch: 5| Step: 2
Training loss: 3.03916887817916
Validation loss: 2.7609400198332943

Epoch: 5| Step: 3
Training loss: 3.2859057139674572
Validation loss: 2.7624987213439165

Epoch: 5| Step: 4
Training loss: 2.76705731732416
Validation loss: 2.7634450446818932

Epoch: 5| Step: 5
Training loss: 2.7643580578969003
Validation loss: 2.7592481610741313

Epoch: 5| Step: 6
Training loss: 3.220489476360106
Validation loss: 2.7544048750719843

Epoch: 5| Step: 7
Training loss: 3.456327308493792
Validation loss: 2.755006431782161

Epoch: 5| Step: 8
Training loss: 2.9395021149364426
Validation loss: 2.7509710857063343

Epoch: 5| Step: 9
Training loss: 3.1040319801826435
Validation loss: 2.753293305595487

Epoch: 5| Step: 10
Training loss: 2.3753921787311456
Validation loss: 2.749568155786518

Epoch: 236| Step: 0
Training loss: 3.519282765142675
Validation loss: 2.754427100173425

Epoch: 5| Step: 1
Training loss: 2.3205658745418924
Validation loss: 2.7521120148087244

Epoch: 5| Step: 2
Training loss: 3.3669735161215866
Validation loss: 2.7519018266149677

Epoch: 5| Step: 3
Training loss: 3.353109647319306
Validation loss: 2.7507835905066496

Epoch: 5| Step: 4
Training loss: 3.1677446203757387
Validation loss: 2.750693275790997

Epoch: 5| Step: 5
Training loss: 2.938506258417994
Validation loss: 2.7488653540099177

Epoch: 5| Step: 6
Training loss: 2.8990770647136026
Validation loss: 2.749169473163005

Epoch: 5| Step: 7
Training loss: 3.552952873469299
Validation loss: 2.744037386691103

Epoch: 5| Step: 8
Training loss: 2.3450535518818856
Validation loss: 2.7468012144659704

Epoch: 5| Step: 9
Training loss: 2.767816569650601
Validation loss: 2.747303877197847

Epoch: 5| Step: 10
Training loss: 3.2085306841771284
Validation loss: 2.7485688588354518

Epoch: 237| Step: 0
Training loss: 2.671539731769234
Validation loss: 2.752962802226148

Epoch: 5| Step: 1
Training loss: 3.023926845644593
Validation loss: 2.7478320795382083

Epoch: 5| Step: 2
Training loss: 2.9532155825331317
Validation loss: 2.746294294497242

Epoch: 5| Step: 3
Training loss: 3.851839067228679
Validation loss: 2.754520065031209

Epoch: 5| Step: 4
Training loss: 3.0050900511490726
Validation loss: 2.750148215452833

Epoch: 5| Step: 5
Training loss: 3.237515311775673
Validation loss: 2.750219382953716

Epoch: 5| Step: 6
Training loss: 2.944367193812122
Validation loss: 2.7479736995664514

Epoch: 5| Step: 7
Training loss: 3.12362625444819
Validation loss: 2.748897670890401

Epoch: 5| Step: 8
Training loss: 2.7658939554072917
Validation loss: 2.752835482493052

Epoch: 5| Step: 9
Training loss: 3.089637257539906
Validation loss: 2.755547973595863

Epoch: 5| Step: 10
Training loss: 2.821388018421852
Validation loss: 2.745972386510541

Epoch: 238| Step: 0
Training loss: 3.162843068931262
Validation loss: 2.7422304484593996

Epoch: 5| Step: 1
Training loss: 2.4949784391461582
Validation loss: 2.7424740359544084

Epoch: 5| Step: 2
Training loss: 2.9586725353935157
Validation loss: 2.7436345860824747

Epoch: 5| Step: 3
Training loss: 3.0761821056377494
Validation loss: 2.741472821739241

Epoch: 5| Step: 4
Training loss: 2.9593791635357127
Validation loss: 2.742922385933462

Epoch: 5| Step: 5
Training loss: 3.6831322357608984
Validation loss: 2.7406414287094045

Epoch: 5| Step: 6
Training loss: 3.3135223250597594
Validation loss: 2.738521399276113

Epoch: 5| Step: 7
Training loss: 2.8460958677164094
Validation loss: 2.736601355559246

Epoch: 5| Step: 8
Training loss: 3.4490437274217025
Validation loss: 2.738238997950654

Epoch: 5| Step: 9
Training loss: 2.844783050363893
Validation loss: 2.739634406037433

Epoch: 5| Step: 10
Training loss: 2.637824565569269
Validation loss: 2.738735169836399

Epoch: 239| Step: 0
Training loss: 2.9719617636417093
Validation loss: 2.7409863871241953

Epoch: 5| Step: 1
Training loss: 3.5076132125148005
Validation loss: 2.7391291023083912

Epoch: 5| Step: 2
Training loss: 3.3783671219096942
Validation loss: 2.7408041203679896

Epoch: 5| Step: 3
Training loss: 2.5826900870870086
Validation loss: 2.7451501219075825

Epoch: 5| Step: 4
Training loss: 3.5600021707335294
Validation loss: 2.7472471262936184

Epoch: 5| Step: 5
Training loss: 3.04103491157781
Validation loss: 2.7453794134770098

Epoch: 5| Step: 6
Training loss: 2.501352516525064
Validation loss: 2.744420618049008

Epoch: 5| Step: 7
Training loss: 3.416212997710702
Validation loss: 2.7451475630753497

Epoch: 5| Step: 8
Training loss: 2.9094112799622676
Validation loss: 2.74312337069219

Epoch: 5| Step: 9
Training loss: 2.6965193106145353
Validation loss: 2.743663215820429

Epoch: 5| Step: 10
Training loss: 2.8180827363906595
Validation loss: 2.7446168461428164

Epoch: 240| Step: 0
Training loss: 2.89168203461564
Validation loss: 2.740091390361824

Epoch: 5| Step: 1
Training loss: 3.4236577933333305
Validation loss: 2.7400573304198588

Epoch: 5| Step: 2
Training loss: 3.412476754022029
Validation loss: 2.73558148044083

Epoch: 5| Step: 3
Training loss: 3.4590356565580302
Validation loss: 2.7385231395606433

Epoch: 5| Step: 4
Training loss: 2.7038836875311447
Validation loss: 2.7382571515257013

Epoch: 5| Step: 5
Training loss: 2.737465207649595
Validation loss: 2.735495576494398

Epoch: 5| Step: 6
Training loss: 3.600010469209495
Validation loss: 2.7366756922221165

Epoch: 5| Step: 7
Training loss: 2.7725144260536827
Validation loss: 2.7365489393773004

Epoch: 5| Step: 8
Training loss: 2.7810394550310598
Validation loss: 2.736038216423795

Epoch: 5| Step: 9
Training loss: 2.697895084329145
Validation loss: 2.7357553202804925

Epoch: 5| Step: 10
Training loss: 2.9621603662427454
Validation loss: 2.7382845117973975

Epoch: 241| Step: 0
Training loss: 3.3719670832012687
Validation loss: 2.737698938177313

Epoch: 5| Step: 1
Training loss: 3.1163411533139134
Validation loss: 2.740610070102027

Epoch: 5| Step: 2
Training loss: 3.028053407245947
Validation loss: 2.7413983495720458

Epoch: 5| Step: 3
Training loss: 3.667960169968
Validation loss: 2.7470281844363575

Epoch: 5| Step: 4
Training loss: 3.0649071400252144
Validation loss: 2.7519584051412385

Epoch: 5| Step: 5
Training loss: 3.3668333075296313
Validation loss: 2.7496991295920172

Epoch: 5| Step: 6
Training loss: 3.0800533547672337
Validation loss: 2.7540339307438084

Epoch: 5| Step: 7
Training loss: 2.9256865584121843
Validation loss: 2.748767705331324

Epoch: 5| Step: 8
Training loss: 2.5098965265595403
Validation loss: 2.7575236903675644

Epoch: 5| Step: 9
Training loss: 2.359980726486644
Validation loss: 2.746876105728607

Epoch: 5| Step: 10
Training loss: 2.9205706127677513
Validation loss: 2.7474427102226655

Epoch: 242| Step: 0
Training loss: 2.450722848563001
Validation loss: 2.741057536233232

Epoch: 5| Step: 1
Training loss: 2.76681234443473
Validation loss: 2.7464144013399365

Epoch: 5| Step: 2
Training loss: 2.7556457653028965
Validation loss: 2.74163263966011

Epoch: 5| Step: 3
Training loss: 3.4955969771884043
Validation loss: 2.7451673836901507

Epoch: 5| Step: 4
Training loss: 3.3532838469153483
Validation loss: 2.7439389299465753

Epoch: 5| Step: 5
Training loss: 3.162456340262256
Validation loss: 2.749224715704617

Epoch: 5| Step: 6
Training loss: 3.1846842577265226
Validation loss: 2.7431077156665054

Epoch: 5| Step: 7
Training loss: 2.9179112276793457
Validation loss: 2.7451561678396663

Epoch: 5| Step: 8
Training loss: 3.2411459111434304
Validation loss: 2.7419899686253473

Epoch: 5| Step: 9
Training loss: 2.865097905961014
Validation loss: 2.739121898424535

Epoch: 5| Step: 10
Training loss: 3.298993049505566
Validation loss: 2.7370549704654668

Epoch: 243| Step: 0
Training loss: 3.396921525652371
Validation loss: 2.7380351528458284

Epoch: 5| Step: 1
Training loss: 3.3151377126590145
Validation loss: 2.740942066708058

Epoch: 5| Step: 2
Training loss: 2.7431722323770296
Validation loss: 2.73643956776461

Epoch: 5| Step: 3
Training loss: 3.259333486466363
Validation loss: 2.735117116795664

Epoch: 5| Step: 4
Training loss: 3.087435819754165
Validation loss: 2.7347861529043658

Epoch: 5| Step: 5
Training loss: 3.3432989083594076
Validation loss: 2.7357189545051477

Epoch: 5| Step: 6
Training loss: 3.1749870179879616
Validation loss: 2.734040979472673

Epoch: 5| Step: 7
Training loss: 2.7275134507782037
Validation loss: 2.732312454530435

Epoch: 5| Step: 8
Training loss: 2.828107464983623
Validation loss: 2.734256424215303

Epoch: 5| Step: 9
Training loss: 3.1118165211757587
Validation loss: 2.7350260335430807

Epoch: 5| Step: 10
Training loss: 2.32637962099067
Validation loss: 2.7320677602354073

Epoch: 244| Step: 0
Training loss: 3.3538662477778387
Validation loss: 2.729920187822487

Epoch: 5| Step: 1
Training loss: 3.631467508705629
Validation loss: 2.736693829000988

Epoch: 5| Step: 2
Training loss: 2.3187142464485246
Validation loss: 2.7346864265727597

Epoch: 5| Step: 3
Training loss: 2.661318711253395
Validation loss: 2.7358934593412347

Epoch: 5| Step: 4
Training loss: 3.05938562346534
Validation loss: 2.742085206288948

Epoch: 5| Step: 5
Training loss: 3.0167898191601417
Validation loss: 2.73631396666966

Epoch: 5| Step: 6
Training loss: 2.7477759123975516
Validation loss: 2.738986110514128

Epoch: 5| Step: 7
Training loss: 3.35069352557884
Validation loss: 2.7437556325194215

Epoch: 5| Step: 8
Training loss: 3.4724524731057897
Validation loss: 2.7357394619119106

Epoch: 5| Step: 9
Training loss: 2.9925367983130653
Validation loss: 2.7393225499691787

Epoch: 5| Step: 10
Training loss: 2.66405220812826
Validation loss: 2.730245171548679

Epoch: 245| Step: 0
Training loss: 3.3948822717943052
Validation loss: 2.727724524831542

Epoch: 5| Step: 1
Training loss: 3.1558003624650235
Validation loss: 2.7257681600186023

Epoch: 5| Step: 2
Training loss: 3.072050500554003
Validation loss: 2.7272937350149227

Epoch: 5| Step: 3
Training loss: 3.4440259542517344
Validation loss: 2.7262424438989927

Epoch: 5| Step: 4
Training loss: 3.070132340054614
Validation loss: 2.7274239944379057

Epoch: 5| Step: 5
Training loss: 3.112464788153453
Validation loss: 2.7274624456182446

Epoch: 5| Step: 6
Training loss: 2.7565771691563725
Validation loss: 2.72807051654465

Epoch: 5| Step: 7
Training loss: 2.8818195566185576
Validation loss: 2.7309079646214185

Epoch: 5| Step: 8
Training loss: 2.7510091490570874
Validation loss: 2.7327489055781404

Epoch: 5| Step: 9
Training loss: 2.602215201032407
Validation loss: 2.7378860531812585

Epoch: 5| Step: 10
Training loss: 3.2128481783860248
Validation loss: 2.7378993653460455

Epoch: 246| Step: 0
Training loss: 2.7721979514337707
Validation loss: 2.740437593452136

Epoch: 5| Step: 1
Training loss: 3.2891103419360475
Validation loss: 2.743329195456982

Epoch: 5| Step: 2
Training loss: 2.578303475415633
Validation loss: 2.736869459421138

Epoch: 5| Step: 3
Training loss: 2.6884898647169098
Validation loss: 2.7397026885386135

Epoch: 5| Step: 4
Training loss: 2.5012089667131003
Validation loss: 2.7404625212306337

Epoch: 5| Step: 5
Training loss: 3.164523922276949
Validation loss: 2.7346234758635313

Epoch: 5| Step: 6
Training loss: 3.3994809708206457
Validation loss: 2.735680572518005

Epoch: 5| Step: 7
Training loss: 3.5410437690639
Validation loss: 2.7310719631272753

Epoch: 5| Step: 8
Training loss: 3.314895915012742
Validation loss: 2.7352222373496993

Epoch: 5| Step: 9
Training loss: 3.02864450381975
Validation loss: 2.735970435128143

Epoch: 5| Step: 10
Training loss: 3.0722901476095372
Validation loss: 2.732419576335121

Epoch: 247| Step: 0
Training loss: 3.293048681191825
Validation loss: 2.7336098702396687

Epoch: 5| Step: 1
Training loss: 3.070387977662436
Validation loss: 2.7340719713161286

Epoch: 5| Step: 2
Training loss: 3.5462242571407683
Validation loss: 2.728285261950167

Epoch: 5| Step: 3
Training loss: 3.352419159075972
Validation loss: 2.731841768568689

Epoch: 5| Step: 4
Training loss: 2.780103382822903
Validation loss: 2.7296725085139055

Epoch: 5| Step: 5
Training loss: 2.8086806749413618
Validation loss: 2.7272262632676036

Epoch: 5| Step: 6
Training loss: 2.7606180849306097
Validation loss: 2.726408512435321

Epoch: 5| Step: 7
Training loss: 3.104094195106638
Validation loss: 2.7264703439505076

Epoch: 5| Step: 8
Training loss: 2.433457176331757
Validation loss: 2.727340634688557

Epoch: 5| Step: 9
Training loss: 3.291937289802939
Validation loss: 2.728163136312934

Epoch: 5| Step: 10
Training loss: 2.8705117394785855
Validation loss: 2.7313210154281578

Epoch: 248| Step: 0
Training loss: 2.682218996316606
Validation loss: 2.738570821428692

Epoch: 5| Step: 1
Training loss: 3.023909026841301
Validation loss: 2.7407092553729457

Epoch: 5| Step: 2
Training loss: 3.236266978761905
Validation loss: 2.7469553197085674

Epoch: 5| Step: 3
Training loss: 2.753532654872903
Validation loss: 2.7605862358577893

Epoch: 5| Step: 4
Training loss: 2.663871601681996
Validation loss: 2.761530816664933

Epoch: 5| Step: 5
Training loss: 3.3269897817231766
Validation loss: 2.776400713361644

Epoch: 5| Step: 6
Training loss: 3.324479232964188
Validation loss: 2.766180734501899

Epoch: 5| Step: 7
Training loss: 3.123038630089961
Validation loss: 2.749895619623627

Epoch: 5| Step: 8
Training loss: 2.656529580156751
Validation loss: 2.734592782297117

Epoch: 5| Step: 9
Training loss: 3.4898668468181575
Validation loss: 2.728577569429914

Epoch: 5| Step: 10
Training loss: 3.175393093735585
Validation loss: 2.7253094822832655

Epoch: 249| Step: 0
Training loss: 2.9852881507515447
Validation loss: 2.72476754101595

Epoch: 5| Step: 1
Training loss: 2.8219113031800163
Validation loss: 2.7215801704311073

Epoch: 5| Step: 2
Training loss: 2.9490535058218588
Validation loss: 2.7240819079301732

Epoch: 5| Step: 3
Training loss: 3.384321831931024
Validation loss: 2.722465331069845

Epoch: 5| Step: 4
Training loss: 3.2036861765469244
Validation loss: 2.7203429970888875

Epoch: 5| Step: 5
Training loss: 3.327506854181374
Validation loss: 2.720021035737678

Epoch: 5| Step: 6
Training loss: 2.845693238711808
Validation loss: 2.7237050060166474

Epoch: 5| Step: 7
Training loss: 2.633088683179655
Validation loss: 2.7201024681222155

Epoch: 5| Step: 8
Training loss: 2.7548327896136398
Validation loss: 2.725742231628134

Epoch: 5| Step: 9
Training loss: 3.1798641521299267
Validation loss: 2.7274539203837573

Epoch: 5| Step: 10
Training loss: 3.354102677076476
Validation loss: 2.724384899774237

Epoch: 250| Step: 0
Training loss: 3.0350392047794603
Validation loss: 2.7289072674496966

Epoch: 5| Step: 1
Training loss: 2.989094143673573
Validation loss: 2.7274694340347985

Epoch: 5| Step: 2
Training loss: 2.636761157789753
Validation loss: 2.7292413728720772

Epoch: 5| Step: 3
Training loss: 3.249725330190182
Validation loss: 2.7324622964713554

Epoch: 5| Step: 4
Training loss: 2.877751899252669
Validation loss: 2.75489216016676

Epoch: 5| Step: 5
Training loss: 3.1776348865130593
Validation loss: 2.762165697886203

Epoch: 5| Step: 6
Training loss: 2.7750270532887376
Validation loss: 2.763832825579086

Epoch: 5| Step: 7
Training loss: 3.0222679853091146
Validation loss: 2.7630273906785403

Epoch: 5| Step: 8
Training loss: 2.8484841648951975
Validation loss: 2.740652120964442

Epoch: 5| Step: 9
Training loss: 3.3398056295795993
Validation loss: 2.7307605740326832

Epoch: 5| Step: 10
Training loss: 3.5102617510714436
Validation loss: 2.7243780888224824

Epoch: 251| Step: 0
Training loss: 3.0333927092836745
Validation loss: 2.724790484873137

Epoch: 5| Step: 1
Training loss: 2.382311158516799
Validation loss: 2.72501361900344

Epoch: 5| Step: 2
Training loss: 2.586228276526112
Validation loss: 2.727877170327047

Epoch: 5| Step: 3
Training loss: 3.6907321536459476
Validation loss: 2.73422568199195

Epoch: 5| Step: 4
Training loss: 2.6679451579758524
Validation loss: 2.7284634030120505

Epoch: 5| Step: 5
Training loss: 2.82777739859801
Validation loss: 2.722550069864431

Epoch: 5| Step: 6
Training loss: 3.698954362293297
Validation loss: 2.723780242425689

Epoch: 5| Step: 7
Training loss: 3.4689790117426673
Validation loss: 2.7233949067301393

Epoch: 5| Step: 8
Training loss: 2.707888424838533
Validation loss: 2.7241804734715527

Epoch: 5| Step: 9
Training loss: 2.8889151800214554
Validation loss: 2.726788236299469

Epoch: 5| Step: 10
Training loss: 3.191508147948686
Validation loss: 2.7239140815758347

Epoch: 252| Step: 0
Training loss: 2.813014682724676
Validation loss: 2.7233497088550194

Epoch: 5| Step: 1
Training loss: 2.861742550779318
Validation loss: 2.722422887232715

Epoch: 5| Step: 2
Training loss: 3.5373318042466644
Validation loss: 2.7301668070612686

Epoch: 5| Step: 3
Training loss: 3.5188623061476085
Validation loss: 2.730387590166183

Epoch: 5| Step: 4
Training loss: 3.004791565837134
Validation loss: 2.736332504024077

Epoch: 5| Step: 5
Training loss: 2.67577937884857
Validation loss: 2.72950904112052

Epoch: 5| Step: 6
Training loss: 3.1864370930015626
Validation loss: 2.7287952239525533

Epoch: 5| Step: 7
Training loss: 3.1647143787392604
Validation loss: 2.738136299253181

Epoch: 5| Step: 8
Training loss: 2.9949111693491814
Validation loss: 2.740977473714375

Epoch: 5| Step: 9
Training loss: 2.874842597964927
Validation loss: 2.745626749662269

Epoch: 5| Step: 10
Training loss: 2.6118611809555965
Validation loss: 2.739356174515908

Epoch: 253| Step: 0
Training loss: 3.321041251597458
Validation loss: 2.7370123192031417

Epoch: 5| Step: 1
Training loss: 3.4764719747694532
Validation loss: 2.723709164380221

Epoch: 5| Step: 2
Training loss: 2.9651999680501993
Validation loss: 2.719182756187719

Epoch: 5| Step: 3
Training loss: 3.407715228553944
Validation loss: 2.7161218889520695

Epoch: 5| Step: 4
Training loss: 1.9184413723829639
Validation loss: 2.7193482999146794

Epoch: 5| Step: 5
Training loss: 2.5120077723303904
Validation loss: 2.716822541510641

Epoch: 5| Step: 6
Training loss: 3.3419377059290105
Validation loss: 2.716744590057943

Epoch: 5| Step: 7
Training loss: 3.2082554365997993
Validation loss: 2.7165341010917428

Epoch: 5| Step: 8
Training loss: 3.1494924893335834
Validation loss: 2.717241011085008

Epoch: 5| Step: 9
Training loss: 2.975930935396683
Validation loss: 2.716665488863846

Epoch: 5| Step: 10
Training loss: 2.8737591263210076
Validation loss: 2.7162121866017306

Epoch: 254| Step: 0
Training loss: 3.1658672695712435
Validation loss: 2.715176189232769

Epoch: 5| Step: 1
Training loss: 2.7585162164578954
Validation loss: 2.7171380565335106

Epoch: 5| Step: 2
Training loss: 3.021498736179106
Validation loss: 2.719961077452657

Epoch: 5| Step: 3
Training loss: 3.00149276469698
Validation loss: 2.7344688406456523

Epoch: 5| Step: 4
Training loss: 2.686919659786685
Validation loss: 2.735842950564063

Epoch: 5| Step: 5
Training loss: 3.1781924620363426
Validation loss: 2.734834359254107

Epoch: 5| Step: 6
Training loss: 3.0693197805214263
Validation loss: 2.7215084066170854

Epoch: 5| Step: 7
Training loss: 3.1907323268134027
Validation loss: 2.7152529243111108

Epoch: 5| Step: 8
Training loss: 3.1637775057317046
Validation loss: 2.7160665743779093

Epoch: 5| Step: 9
Training loss: 3.0657788843696276
Validation loss: 2.715082941372661

Epoch: 5| Step: 10
Training loss: 3.1335116626503594
Validation loss: 2.716538899890739

Epoch: 255| Step: 0
Training loss: 3.048001281717987
Validation loss: 2.7198047404821915

Epoch: 5| Step: 1
Training loss: 2.8108395231261545
Validation loss: 2.720162071753576

Epoch: 5| Step: 2
Training loss: 3.2970667778752305
Validation loss: 2.721143604973483

Epoch: 5| Step: 3
Training loss: 2.7570783378144967
Validation loss: 2.731616736129425

Epoch: 5| Step: 4
Training loss: 2.4781905638210255
Validation loss: 2.7322875424700643

Epoch: 5| Step: 5
Training loss: 2.880037786712714
Validation loss: 2.7435987835393814

Epoch: 5| Step: 6
Training loss: 3.211847106848107
Validation loss: 2.7379386422689884

Epoch: 5| Step: 7
Training loss: 2.9079932450290813
Validation loss: 2.74110991670452

Epoch: 5| Step: 8
Training loss: 3.3757857361728174
Validation loss: 2.734037640411574

Epoch: 5| Step: 9
Training loss: 3.185945917392479
Validation loss: 2.729666891301449

Epoch: 5| Step: 10
Training loss: 3.4124513224389204
Validation loss: 2.7240556115136894

Epoch: 256| Step: 0
Training loss: 2.97970135209975
Validation loss: 2.7187605949462266

Epoch: 5| Step: 1
Training loss: 2.7645144199347818
Validation loss: 2.7148734633397806

Epoch: 5| Step: 2
Training loss: 3.4622805639478744
Validation loss: 2.7141186969807305

Epoch: 5| Step: 3
Training loss: 3.008795560231137
Validation loss: 2.7116521910016522

Epoch: 5| Step: 4
Training loss: 3.1016904098309843
Validation loss: 2.7108986678508327

Epoch: 5| Step: 5
Training loss: 3.287053670428183
Validation loss: 2.7086184544825653

Epoch: 5| Step: 6
Training loss: 2.8492602944385172
Validation loss: 2.711231805455001

Epoch: 5| Step: 7
Training loss: 2.978107682104685
Validation loss: 2.7119255850440784

Epoch: 5| Step: 8
Training loss: 3.569545271093058
Validation loss: 2.7121495015853347

Epoch: 5| Step: 9
Training loss: 2.482922975400167
Validation loss: 2.711637574823673

Epoch: 5| Step: 10
Training loss: 2.7021855833245976
Validation loss: 2.710910801834211

Epoch: 257| Step: 0
Training loss: 3.0921998427088337
Validation loss: 2.7117813299252425

Epoch: 5| Step: 1
Training loss: 3.4129157682900515
Validation loss: 2.7188077530828263

Epoch: 5| Step: 2
Training loss: 2.9495842915538044
Validation loss: 2.724534264050124

Epoch: 5| Step: 3
Training loss: 3.2965016809057377
Validation loss: 2.7226154324744885

Epoch: 5| Step: 4
Training loss: 2.799258106582104
Validation loss: 2.7287858441970223

Epoch: 5| Step: 5
Training loss: 2.8724061626249755
Validation loss: 2.7376009895267948

Epoch: 5| Step: 6
Training loss: 3.388488659041971
Validation loss: 2.758525166131319

Epoch: 5| Step: 7
Training loss: 2.883478516762075
Validation loss: 2.77731468377354

Epoch: 5| Step: 8
Training loss: 3.2354398439604344
Validation loss: 2.780931623928812

Epoch: 5| Step: 9
Training loss: 2.636253756741578
Validation loss: 2.7762352703660196

Epoch: 5| Step: 10
Training loss: 2.7777345706970205
Validation loss: 2.7484858092707936

Epoch: 258| Step: 0
Training loss: 3.295293202531364
Validation loss: 2.7197395365489467

Epoch: 5| Step: 1
Training loss: 3.2554130957734535
Validation loss: 2.7085750885272217

Epoch: 5| Step: 2
Training loss: 3.074059139310755
Validation loss: 2.7057125319188127

Epoch: 5| Step: 3
Training loss: 3.4390215194042177
Validation loss: 2.710656462899389

Epoch: 5| Step: 4
Training loss: 3.228429517388087
Validation loss: 2.71418221960509

Epoch: 5| Step: 5
Training loss: 2.7878824082892613
Validation loss: 2.713900004263332

Epoch: 5| Step: 6
Training loss: 2.650191994675589
Validation loss: 2.717386952839453

Epoch: 5| Step: 7
Training loss: 2.9044485764432335
Validation loss: 2.715526324968996

Epoch: 5| Step: 8
Training loss: 2.8808623543416796
Validation loss: 2.7187435870011862

Epoch: 5| Step: 9
Training loss: 3.465636634635142
Validation loss: 2.716334292716099

Epoch: 5| Step: 10
Training loss: 2.1647816919292713
Validation loss: 2.7176395176169126

Epoch: 259| Step: 0
Training loss: 2.591818400496992
Validation loss: 2.7159378331880495

Epoch: 5| Step: 1
Training loss: 2.8801313301448315
Validation loss: 2.711105157563327

Epoch: 5| Step: 2
Training loss: 2.7619542476060572
Validation loss: 2.7124477424727327

Epoch: 5| Step: 3
Training loss: 3.0167749613788795
Validation loss: 2.712210002141171

Epoch: 5| Step: 4
Training loss: 3.1728990527186136
Validation loss: 2.712263755439948

Epoch: 5| Step: 5
Training loss: 3.5575819367163133
Validation loss: 2.707941380639486

Epoch: 5| Step: 6
Training loss: 3.31046909477213
Validation loss: 2.7073615265591573

Epoch: 5| Step: 7
Training loss: 3.058923930035072
Validation loss: 2.708762299774606

Epoch: 5| Step: 8
Training loss: 3.15873590149958
Validation loss: 2.711621631187555

Epoch: 5| Step: 9
Training loss: 2.2937352525616364
Validation loss: 2.7194308610738256

Epoch: 5| Step: 10
Training loss: 3.5134678983403926
Validation loss: 2.7192975130499253

Epoch: 260| Step: 0
Training loss: 2.8482409218457896
Validation loss: 2.719327325736117

Epoch: 5| Step: 1
Training loss: 3.286971562489141
Validation loss: 2.713086898820443

Epoch: 5| Step: 2
Training loss: 3.037675634259222
Validation loss: 2.7204421617384438

Epoch: 5| Step: 3
Training loss: 3.0232807286349943
Validation loss: 2.7202018432234665

Epoch: 5| Step: 4
Training loss: 3.2996100339801933
Validation loss: 2.7294748331588425

Epoch: 5| Step: 5
Training loss: 3.224851288434791
Validation loss: 2.7383249637540588

Epoch: 5| Step: 6
Training loss: 2.993171868617472
Validation loss: 2.7312374742554444

Epoch: 5| Step: 7
Training loss: 2.791806449996479
Validation loss: 2.7316964460953277

Epoch: 5| Step: 8
Training loss: 2.5654431630605825
Validation loss: 2.728784912232372

Epoch: 5| Step: 9
Training loss: 2.7655041339562665
Validation loss: 2.72101534943008

Epoch: 5| Step: 10
Training loss: 3.4824980055124852
Validation loss: 2.714609839341993

Epoch: 261| Step: 0
Training loss: 2.6458401617327505
Validation loss: 2.710796791693029

Epoch: 5| Step: 1
Training loss: 3.331642834831164
Validation loss: 2.7057851599861102

Epoch: 5| Step: 2
Training loss: 3.110024082544434
Validation loss: 2.7059682838928922

Epoch: 5| Step: 3
Training loss: 2.5629478621461637
Validation loss: 2.703642727822525

Epoch: 5| Step: 4
Training loss: 3.54296969210813
Validation loss: 2.7079479479727566

Epoch: 5| Step: 5
Training loss: 2.967964469984904
Validation loss: 2.7047647461338555

Epoch: 5| Step: 6
Training loss: 3.1954873930208327
Validation loss: 2.707406508425033

Epoch: 5| Step: 7
Training loss: 3.21851977663837
Validation loss: 2.7040325857811087

Epoch: 5| Step: 8
Training loss: 2.7418132646165647
Validation loss: 2.7031795399707237

Epoch: 5| Step: 9
Training loss: 3.303237488706998
Validation loss: 2.704748135469228

Epoch: 5| Step: 10
Training loss: 2.4923777731844576
Validation loss: 2.7047355245655638

Epoch: 262| Step: 0
Training loss: 2.472314024469707
Validation loss: 2.7059374088224777

Epoch: 5| Step: 1
Training loss: 2.509161375461026
Validation loss: 2.706452966567477

Epoch: 5| Step: 2
Training loss: 3.195225348368323
Validation loss: 2.7159564421265694

Epoch: 5| Step: 3
Training loss: 3.149826765595098
Validation loss: 2.7156441175148354

Epoch: 5| Step: 4
Training loss: 2.966074169299076
Validation loss: 2.712835476066545

Epoch: 5| Step: 5
Training loss: 3.3728147425732895
Validation loss: 2.712848321476804

Epoch: 5| Step: 6
Training loss: 3.1285188318398784
Validation loss: 2.719697013410645

Epoch: 5| Step: 7
Training loss: 3.7209599443846266
Validation loss: 2.720995391512991

Epoch: 5| Step: 8
Training loss: 2.5511855641834345
Validation loss: 2.711046130226296

Epoch: 5| Step: 9
Training loss: 2.968535566114645
Validation loss: 2.71181475049064

Epoch: 5| Step: 10
Training loss: 3.09453118220028
Validation loss: 2.7073294647818864

Epoch: 263| Step: 0
Training loss: 3.216062887051377
Validation loss: 2.705744825565359

Epoch: 5| Step: 1
Training loss: 3.5395593694392464
Validation loss: 2.7083952460457597

Epoch: 5| Step: 2
Training loss: 3.5311700592444835
Validation loss: 2.708563393665148

Epoch: 5| Step: 3
Training loss: 2.598920150405001
Validation loss: 2.7117397483887893

Epoch: 5| Step: 4
Training loss: 2.5348596149524907
Validation loss: 2.713572427188209

Epoch: 5| Step: 5
Training loss: 2.976339657268997
Validation loss: 2.719985939353875

Epoch: 5| Step: 6
Training loss: 2.891948664946955
Validation loss: 2.7186003895953714

Epoch: 5| Step: 7
Training loss: 2.5522383869843708
Validation loss: 2.7127207142317857

Epoch: 5| Step: 8
Training loss: 3.1125321964912005
Validation loss: 2.7149548376607195

Epoch: 5| Step: 9
Training loss: 3.2998835861017475
Validation loss: 2.710937181310637

Epoch: 5| Step: 10
Training loss: 2.8197243201324897
Validation loss: 2.7171372460602887

Epoch: 264| Step: 0
Training loss: 2.7800789414319267
Validation loss: 2.7095090275217997

Epoch: 5| Step: 1
Training loss: 3.649789433088406
Validation loss: 2.7167566328202244

Epoch: 5| Step: 2
Training loss: 3.238971779229561
Validation loss: 2.710100821761431

Epoch: 5| Step: 3
Training loss: 3.205335198785342
Validation loss: 2.709147686946351

Epoch: 5| Step: 4
Training loss: 2.1050271896454755
Validation loss: 2.709786486396104

Epoch: 5| Step: 5
Training loss: 3.1165619416075248
Validation loss: 2.710605220934794

Epoch: 5| Step: 6
Training loss: 2.8428326479040686
Validation loss: 2.703708395809734

Epoch: 5| Step: 7
Training loss: 2.9678757835984504
Validation loss: 2.702068529505853

Epoch: 5| Step: 8
Training loss: 3.128049811832474
Validation loss: 2.700344721726312

Epoch: 5| Step: 9
Training loss: 2.769928165289316
Validation loss: 2.7021229143329024

Epoch: 5| Step: 10
Training loss: 3.313250042912969
Validation loss: 2.7038214542266354

Epoch: 265| Step: 0
Training loss: 3.0218337583834196
Validation loss: 2.7049024225799134

Epoch: 5| Step: 1
Training loss: 2.6868074988692854
Validation loss: 2.703279732533807

Epoch: 5| Step: 2
Training loss: 3.220924013612374
Validation loss: 2.714736777961901

Epoch: 5| Step: 3
Training loss: 3.2394653658633885
Validation loss: 2.7290240681610043

Epoch: 5| Step: 4
Training loss: 3.0722311688508075
Validation loss: 2.727573919771304

Epoch: 5| Step: 5
Training loss: 3.504421030459672
Validation loss: 2.7167033336144626

Epoch: 5| Step: 6
Training loss: 2.85942035910061
Validation loss: 2.703363484286473

Epoch: 5| Step: 7
Training loss: 3.0998984227920143
Validation loss: 2.704817439889576

Epoch: 5| Step: 8
Training loss: 2.446156901370107
Validation loss: 2.699078372993558

Epoch: 5| Step: 9
Training loss: 2.873371990176891
Validation loss: 2.70048382726095

Epoch: 5| Step: 10
Training loss: 3.2183853979918755
Validation loss: 2.6976638151564476

Epoch: 266| Step: 0
Training loss: 2.4037602412203527
Validation loss: 2.6993031415637962

Epoch: 5| Step: 1
Training loss: 2.885156686319524
Validation loss: 2.6996309325915484

Epoch: 5| Step: 2
Training loss: 3.0443896990244808
Validation loss: 2.7006864904037293

Epoch: 5| Step: 3
Training loss: 2.3934011857589677
Validation loss: 2.7010780734418693

Epoch: 5| Step: 4
Training loss: 3.315541005126802
Validation loss: 2.7060305142462475

Epoch: 5| Step: 5
Training loss: 2.804756865002267
Validation loss: 2.7125628249036717

Epoch: 5| Step: 6
Training loss: 2.4560928372099244
Validation loss: 2.713636738219408

Epoch: 5| Step: 7
Training loss: 2.9032799095321935
Validation loss: 2.723038963746641

Epoch: 5| Step: 8
Training loss: 3.5073951523894316
Validation loss: 2.7212981853250837

Epoch: 5| Step: 9
Training loss: 3.8722571232915093
Validation loss: 2.716342556501348

Epoch: 5| Step: 10
Training loss: 3.3977785370468756
Validation loss: 2.7070386017862895

Epoch: 267| Step: 0
Training loss: 2.9204976308401904
Validation loss: 2.7010456789161084

Epoch: 5| Step: 1
Training loss: 2.5116075933133555
Validation loss: 2.696842194554211

Epoch: 5| Step: 2
Training loss: 3.167356683609545
Validation loss: 2.698237237395808

Epoch: 5| Step: 3
Training loss: 3.3076872501436987
Validation loss: 2.6988897785455994

Epoch: 5| Step: 4
Training loss: 3.0669440897250655
Validation loss: 2.69364964697217

Epoch: 5| Step: 5
Training loss: 2.711413251043103
Validation loss: 2.696945301265547

Epoch: 5| Step: 6
Training loss: 3.246431004968307
Validation loss: 2.6936673130192315

Epoch: 5| Step: 7
Training loss: 3.169671406607742
Validation loss: 2.695155999299411

Epoch: 5| Step: 8
Training loss: 2.876026136298125
Validation loss: 2.692907966278994

Epoch: 5| Step: 9
Training loss: 3.0828616494593186
Validation loss: 2.695140113210276

Epoch: 5| Step: 10
Training loss: 3.1367263508819803
Validation loss: 2.6960858073146547

Epoch: 268| Step: 0
Training loss: 3.0309909041270444
Validation loss: 2.694100300526566

Epoch: 5| Step: 1
Training loss: 3.1410242842227674
Validation loss: 2.6955526655408817

Epoch: 5| Step: 2
Training loss: 2.9202585900128684
Validation loss: 2.6976001268897325

Epoch: 5| Step: 3
Training loss: 3.7981233781538366
Validation loss: 2.7009105926592696

Epoch: 5| Step: 4
Training loss: 3.00243755494803
Validation loss: 2.703575197792239

Epoch: 5| Step: 5
Training loss: 2.8233496039536123
Validation loss: 2.7097355203203124

Epoch: 5| Step: 6
Training loss: 3.1720765900090275
Validation loss: 2.7154663099234395

Epoch: 5| Step: 7
Training loss: 3.0076057660284627
Validation loss: 2.7150688289962273

Epoch: 5| Step: 8
Training loss: 2.77454820340208
Validation loss: 2.720373973001192

Epoch: 5| Step: 9
Training loss: 2.8221086610222326
Validation loss: 2.7331618742085353

Epoch: 5| Step: 10
Training loss: 2.5309214437615775
Validation loss: 2.7318230890675923

Epoch: 269| Step: 0
Training loss: 2.756115442568339
Validation loss: 2.732266638532496

Epoch: 5| Step: 1
Training loss: 3.2783693293457232
Validation loss: 2.731853511110551

Epoch: 5| Step: 2
Training loss: 2.9741582497089025
Validation loss: 2.720985752153115

Epoch: 5| Step: 3
Training loss: 2.274153449203123
Validation loss: 2.715041874021191

Epoch: 5| Step: 4
Training loss: 3.2763328402633314
Validation loss: 2.7077273253266694

Epoch: 5| Step: 5
Training loss: 2.9708501514816588
Validation loss: 2.7101896712702462

Epoch: 5| Step: 6
Training loss: 3.1677667480488436
Validation loss: 2.7080337289282626

Epoch: 5| Step: 7
Training loss: 2.798832639809033
Validation loss: 2.7067724275023815

Epoch: 5| Step: 8
Training loss: 3.16399423031094
Validation loss: 2.7004505787971746

Epoch: 5| Step: 9
Training loss: 3.234707580274114
Validation loss: 2.699228243897716

Epoch: 5| Step: 10
Training loss: 3.2069811427933175
Validation loss: 2.69815952432017

Epoch: 270| Step: 0
Training loss: 2.9539312644611644
Validation loss: 2.6977801345205754

Epoch: 5| Step: 1
Training loss: 3.1905097963044935
Validation loss: 2.6963629255962465

Epoch: 5| Step: 2
Training loss: 3.158388074603462
Validation loss: 2.6939518173056127

Epoch: 5| Step: 3
Training loss: 2.3015779887064753
Validation loss: 2.6954434927006012

Epoch: 5| Step: 4
Training loss: 3.2368411185345107
Validation loss: 2.6912589431814604

Epoch: 5| Step: 5
Training loss: 3.499374333725825
Validation loss: 2.691354076661413

Epoch: 5| Step: 6
Training loss: 2.788269785149097
Validation loss: 2.6935135406704633

Epoch: 5| Step: 7
Training loss: 3.0013513700309598
Validation loss: 2.6922744557243594

Epoch: 5| Step: 8
Training loss: 2.7856237760099924
Validation loss: 2.692527827941161

Epoch: 5| Step: 9
Training loss: 3.207144694581144
Validation loss: 2.6987737682382433

Epoch: 5| Step: 10
Training loss: 2.905632199487528
Validation loss: 2.697779179491193

Epoch: 271| Step: 0
Training loss: 2.805303564389941
Validation loss: 2.698726516508456

Epoch: 5| Step: 1
Training loss: 2.873731416208279
Validation loss: 2.704393203033913

Epoch: 5| Step: 2
Training loss: 3.3513940444262333
Validation loss: 2.704553846148836

Epoch: 5| Step: 3
Training loss: 3.0932903526323674
Validation loss: 2.704744829437186

Epoch: 5| Step: 4
Training loss: 2.7223755788964943
Validation loss: 2.7029547285921045

Epoch: 5| Step: 5
Training loss: 3.1419646029940065
Validation loss: 2.7068346317916157

Epoch: 5| Step: 6
Training loss: 2.645444906563376
Validation loss: 2.7063079716751206

Epoch: 5| Step: 7
Training loss: 3.3817678340583464
Validation loss: 2.708525968063464

Epoch: 5| Step: 8
Training loss: 2.931652661221961
Validation loss: 2.709530899912985

Epoch: 5| Step: 9
Training loss: 2.937270135205131
Validation loss: 2.7013943474037108

Epoch: 5| Step: 10
Training loss: 3.2390074059548053
Validation loss: 2.699236672125871

Epoch: 272| Step: 0
Training loss: 3.270869811678718
Validation loss: 2.7027853456526065

Epoch: 5| Step: 1
Training loss: 3.0372451800927402
Validation loss: 2.7048886561036527

Epoch: 5| Step: 2
Training loss: 2.8686518035238855
Validation loss: 2.708417322893205

Epoch: 5| Step: 3
Training loss: 2.5689489579941633
Validation loss: 2.7195388004206777

Epoch: 5| Step: 4
Training loss: 3.2434547245822687
Validation loss: 2.724206416726488

Epoch: 5| Step: 5
Training loss: 3.0472906367147483
Validation loss: 2.711566756151271

Epoch: 5| Step: 6
Training loss: 3.2890533664603736
Validation loss: 2.7137164142167074

Epoch: 5| Step: 7
Training loss: 2.975515266483138
Validation loss: 2.69988272566819

Epoch: 5| Step: 8
Training loss: 3.1004704395319
Validation loss: 2.6896151599011495

Epoch: 5| Step: 9
Training loss: 2.8471093090794177
Validation loss: 2.6909323559279112

Epoch: 5| Step: 10
Training loss: 2.8270757425347344
Validation loss: 2.690884048088214

Epoch: 273| Step: 0
Training loss: 2.8961690987066384
Validation loss: 2.688356390436127

Epoch: 5| Step: 1
Training loss: 3.138106973608073
Validation loss: 2.688371568986466

Epoch: 5| Step: 2
Training loss: 2.2755517730623507
Validation loss: 2.6861953974331203

Epoch: 5| Step: 3
Training loss: 3.148036732499327
Validation loss: 2.6884903643831297

Epoch: 5| Step: 4
Training loss: 3.05373576525924
Validation loss: 2.6896349608285526

Epoch: 5| Step: 5
Training loss: 2.6878934173059448
Validation loss: 2.690645638208162

Epoch: 5| Step: 6
Training loss: 3.251859426437293
Validation loss: 2.692644735729214

Epoch: 5| Step: 7
Training loss: 3.628892190205877
Validation loss: 2.6917335950212977

Epoch: 5| Step: 8
Training loss: 2.748794031141815
Validation loss: 2.6964357218275654

Epoch: 5| Step: 9
Training loss: 2.9196288915510964
Validation loss: 2.6973646058945695

Epoch: 5| Step: 10
Training loss: 3.284103896315467
Validation loss: 2.700816095748119

Epoch: 274| Step: 0
Training loss: 3.255391124425119
Validation loss: 2.701299901580702

Epoch: 5| Step: 1
Training loss: 3.280584649339122
Validation loss: 2.697723714035637

Epoch: 5| Step: 2
Training loss: 3.097575433165099
Validation loss: 2.699444027313092

Epoch: 5| Step: 3
Training loss: 3.148433865149887
Validation loss: 2.699656793641734

Epoch: 5| Step: 4
Training loss: 2.601514661194449
Validation loss: 2.7098580620715293

Epoch: 5| Step: 5
Training loss: 2.968279831447143
Validation loss: 2.7138241037961457

Epoch: 5| Step: 6
Training loss: 2.8032159796912524
Validation loss: 2.6980819572329167

Epoch: 5| Step: 7
Training loss: 3.1978038225342327
Validation loss: 2.6902206588338258

Epoch: 5| Step: 8
Training loss: 2.287044950990059
Validation loss: 2.689595591401353

Epoch: 5| Step: 9
Training loss: 3.285169023087535
Validation loss: 2.687236136675563

Epoch: 5| Step: 10
Training loss: 3.086163090053441
Validation loss: 2.685562390175429

Epoch: 275| Step: 0
Training loss: 3.7937541427463994
Validation loss: 2.6874268262611847

Epoch: 5| Step: 1
Training loss: 3.4242784951402934
Validation loss: 2.6856975716440363

Epoch: 5| Step: 2
Training loss: 2.581113158655944
Validation loss: 2.690618961649453

Epoch: 5| Step: 3
Training loss: 3.054681412088323
Validation loss: 2.6895648496011466

Epoch: 5| Step: 4
Training loss: 2.5546615552605534
Validation loss: 2.6935475257747874

Epoch: 5| Step: 5
Training loss: 3.0777710067209374
Validation loss: 2.6919316523839676

Epoch: 5| Step: 6
Training loss: 2.8028652041002537
Validation loss: 2.6880951880779373

Epoch: 5| Step: 7
Training loss: 2.7350361923807904
Validation loss: 2.6882552182548

Epoch: 5| Step: 8
Training loss: 2.898222964179543
Validation loss: 2.6882816550662163

Epoch: 5| Step: 9
Training loss: 3.117609669485507
Validation loss: 2.685357784650774

Epoch: 5| Step: 10
Training loss: 2.9874485027391775
Validation loss: 2.6864369210279673

Epoch: 276| Step: 0
Training loss: 2.9625627792724276
Validation loss: 2.689091203031143

Epoch: 5| Step: 1
Training loss: 2.858303181866433
Validation loss: 2.690110139361989

Epoch: 5| Step: 2
Training loss: 3.5989419335940718
Validation loss: 2.697791309764638

Epoch: 5| Step: 3
Training loss: 2.1855100026910863
Validation loss: 2.7185073798973485

Epoch: 5| Step: 4
Training loss: 2.771329094459657
Validation loss: 2.7201482439631666

Epoch: 5| Step: 5
Training loss: 2.796372352484596
Validation loss: 2.716304614232105

Epoch: 5| Step: 6
Training loss: 3.3299980802788225
Validation loss: 2.7247092001247286

Epoch: 5| Step: 7
Training loss: 2.8718631050934467
Validation loss: 2.716005792551906

Epoch: 5| Step: 8
Training loss: 3.681848106305483
Validation loss: 2.7158825398797246

Epoch: 5| Step: 9
Training loss: 2.7486289681455385
Validation loss: 2.718566403185226

Epoch: 5| Step: 10
Training loss: 3.081050973155447
Validation loss: 2.695267000508367

Epoch: 277| Step: 0
Training loss: 2.490817754889693
Validation loss: 2.692060092690908

Epoch: 5| Step: 1
Training loss: 2.78453350193983
Validation loss: 2.6906057576173676

Epoch: 5| Step: 2
Training loss: 2.790331725358604
Validation loss: 2.6909312736649773

Epoch: 5| Step: 3
Training loss: 2.9031143500355485
Validation loss: 2.6856508220046824

Epoch: 5| Step: 4
Training loss: 3.1306691436183733
Validation loss: 2.684028885040361

Epoch: 5| Step: 5
Training loss: 3.3515704672836537
Validation loss: 2.6882959185535222

Epoch: 5| Step: 6
Training loss: 3.749380187628595
Validation loss: 2.686488059048649

Epoch: 5| Step: 7
Training loss: 2.827646794644563
Validation loss: 2.6900572766404207

Epoch: 5| Step: 8
Training loss: 3.2251360605799144
Validation loss: 2.692837826025538

Epoch: 5| Step: 9
Training loss: 2.6665588496187786
Validation loss: 2.6918665228044123

Epoch: 5| Step: 10
Training loss: 3.036258139098791
Validation loss: 2.6937153358723527

Epoch: 278| Step: 0
Training loss: 3.4756439710050273
Validation loss: 2.691713597142429

Epoch: 5| Step: 1
Training loss: 3.3583025972712566
Validation loss: 2.690556856971125

Epoch: 5| Step: 2
Training loss: 2.789118149146113
Validation loss: 2.694447880178813

Epoch: 5| Step: 3
Training loss: 2.685200705672191
Validation loss: 2.6955095382891967

Epoch: 5| Step: 4
Training loss: 3.1690682456413315
Validation loss: 2.691864827593402

Epoch: 5| Step: 5
Training loss: 2.949955930219022
Validation loss: 2.6931770138815474

Epoch: 5| Step: 6
Training loss: 3.285691370795293
Validation loss: 2.6972581962015107

Epoch: 5| Step: 7
Training loss: 2.4497244037622736
Validation loss: 2.6934248625321624

Epoch: 5| Step: 8
Training loss: 2.8227647597390155
Validation loss: 2.7024464540089888

Epoch: 5| Step: 9
Training loss: 2.8346628734758226
Validation loss: 2.7177758664632075

Epoch: 5| Step: 10
Training loss: 3.1487511414710956
Validation loss: 2.7286279768710733

Epoch: 279| Step: 0
Training loss: 2.4421904014135736
Validation loss: 2.7216407806683818

Epoch: 5| Step: 1
Training loss: 3.219821936618209
Validation loss: 2.7189368104951264

Epoch: 5| Step: 2
Training loss: 3.3965857360702065
Validation loss: 2.698356346164439

Epoch: 5| Step: 3
Training loss: 2.7828031339493124
Validation loss: 2.695309488664288

Epoch: 5| Step: 4
Training loss: 3.227801586099064
Validation loss: 2.684700425622689

Epoch: 5| Step: 5
Training loss: 2.329372609359624
Validation loss: 2.6816802221071465

Epoch: 5| Step: 6
Training loss: 2.5319862707769234
Validation loss: 2.682641596577641

Epoch: 5| Step: 7
Training loss: 3.283076767813158
Validation loss: 2.679149263542615

Epoch: 5| Step: 8
Training loss: 2.8130724854092373
Validation loss: 2.676816988745207

Epoch: 5| Step: 9
Training loss: 3.43575450623289
Validation loss: 2.6801455526692353

Epoch: 5| Step: 10
Training loss: 3.450895254105747
Validation loss: 2.681805791354905

Epoch: 280| Step: 0
Training loss: 2.7001123122415227
Validation loss: 2.6778245406312084

Epoch: 5| Step: 1
Training loss: 2.7735628341508525
Validation loss: 2.6823663217103473

Epoch: 5| Step: 2
Training loss: 2.71711883721401
Validation loss: 2.6812882805967244

Epoch: 5| Step: 3
Training loss: 2.9272905233414113
Validation loss: 2.679573926549146

Epoch: 5| Step: 4
Training loss: 3.0603172152784888
Validation loss: 2.678707228000089

Epoch: 5| Step: 5
Training loss: 2.9752525991703007
Validation loss: 2.679117858357415

Epoch: 5| Step: 6
Training loss: 3.044439819623245
Validation loss: 2.684402395811013

Epoch: 5| Step: 7
Training loss: 3.1639927232371687
Validation loss: 2.68257037175458

Epoch: 5| Step: 8
Training loss: 3.2800671579882454
Validation loss: 2.6802404923667793

Epoch: 5| Step: 9
Training loss: 3.4248454817840583
Validation loss: 2.683482923206111

Epoch: 5| Step: 10
Training loss: 2.997968462685903
Validation loss: 2.681418822590189

Epoch: 281| Step: 0
Training loss: 3.179654507852487
Validation loss: 2.68527883483359

Epoch: 5| Step: 1
Training loss: 2.9441545471696333
Validation loss: 2.6806429443985964

Epoch: 5| Step: 2
Training loss: 3.2564539283551976
Validation loss: 2.6913188760178377

Epoch: 5| Step: 3
Training loss: 3.298484951529091
Validation loss: 2.6826456580461824

Epoch: 5| Step: 4
Training loss: 2.4617145583087727
Validation loss: 2.6831898697987944

Epoch: 5| Step: 5
Training loss: 2.8178922037336336
Validation loss: 2.681821418031343

Epoch: 5| Step: 6
Training loss: 2.8229404368695996
Validation loss: 2.6895316005551497

Epoch: 5| Step: 7
Training loss: 2.9882946537689588
Validation loss: 2.6906188339733093

Epoch: 5| Step: 8
Training loss: 2.9460279976834514
Validation loss: 2.688441433841748

Epoch: 5| Step: 9
Training loss: 3.051775624948016
Validation loss: 2.6836516110215136

Epoch: 5| Step: 10
Training loss: 3.2771855931091434
Validation loss: 2.6813541078816066

Epoch: 282| Step: 0
Training loss: 3.120423131518281
Validation loss: 2.686281563804322

Epoch: 5| Step: 1
Training loss: 2.4315070793524165
Validation loss: 2.6883151856325043

Epoch: 5| Step: 2
Training loss: 2.9453490884870943
Validation loss: 2.695281041553087

Epoch: 5| Step: 3
Training loss: 3.390878975492996
Validation loss: 2.6957603915892836

Epoch: 5| Step: 4
Training loss: 2.907263794321972
Validation loss: 2.6861417237404805

Epoch: 5| Step: 5
Training loss: 2.792902677594784
Validation loss: 2.692408942173913

Epoch: 5| Step: 6
Training loss: 3.3078895008493108
Validation loss: 2.6915357297732307

Epoch: 5| Step: 7
Training loss: 2.7253163285343907
Validation loss: 2.691346939218993

Epoch: 5| Step: 8
Training loss: 3.0589251771064525
Validation loss: 2.685715952453429

Epoch: 5| Step: 9
Training loss: 3.0329533146787795
Validation loss: 2.68675910446051

Epoch: 5| Step: 10
Training loss: 3.282385202856923
Validation loss: 2.6859621750151685

Epoch: 283| Step: 0
Training loss: 3.3163910091485778
Validation loss: 2.6850865509992903

Epoch: 5| Step: 1
Training loss: 3.254245625871818
Validation loss: 2.6841933141943213

Epoch: 5| Step: 2
Training loss: 3.078937868557516
Validation loss: 2.6850687301542844

Epoch: 5| Step: 3
Training loss: 3.0026276524935693
Validation loss: 2.6829654053342034

Epoch: 5| Step: 4
Training loss: 2.713357158887453
Validation loss: 2.681381804977558

Epoch: 5| Step: 5
Training loss: 2.8644810513818357
Validation loss: 2.6771773601950475

Epoch: 5| Step: 6
Training loss: 3.0548532738546172
Validation loss: 2.6809121939463796

Epoch: 5| Step: 7
Training loss: 2.9403226561182905
Validation loss: 2.6784781449418813

Epoch: 5| Step: 8
Training loss: 2.8832936286030035
Validation loss: 2.677871954395686

Epoch: 5| Step: 9
Training loss: 3.00419656965282
Validation loss: 2.6809841895575

Epoch: 5| Step: 10
Training loss: 2.9023541004925635
Validation loss: 2.679922577119662

Epoch: 284| Step: 0
Training loss: 3.430240942719602
Validation loss: 2.681617085380322

Epoch: 5| Step: 1
Training loss: 3.4760175299251825
Validation loss: 2.692036193740382

Epoch: 5| Step: 2
Training loss: 2.3129917343658253
Validation loss: 2.6888740672734093

Epoch: 5| Step: 3
Training loss: 2.31044389200179
Validation loss: 2.696835288375903

Epoch: 5| Step: 4
Training loss: 3.2487411995592796
Validation loss: 2.70361733539391

Epoch: 5| Step: 5
Training loss: 2.906567463917231
Validation loss: 2.692108831760282

Epoch: 5| Step: 6
Training loss: 2.483944261745618
Validation loss: 2.701646609058577

Epoch: 5| Step: 7
Training loss: 2.7214241469053695
Validation loss: 2.7012092079339376

Epoch: 5| Step: 8
Training loss: 3.25703300097211
Validation loss: 2.6928116262548647

Epoch: 5| Step: 9
Training loss: 3.413822540998677
Validation loss: 2.682589847196274

Epoch: 5| Step: 10
Training loss: 3.173301639024618
Validation loss: 2.684825345628479

Epoch: 285| Step: 0
Training loss: 3.372551206252315
Validation loss: 2.6854244295995446

Epoch: 5| Step: 1
Training loss: 2.9336961507385864
Validation loss: 2.6941289456604403

Epoch: 5| Step: 2
Training loss: 3.6558535108204384
Validation loss: 2.7023790022322083

Epoch: 5| Step: 3
Training loss: 3.353605203648527
Validation loss: 2.707060763091603

Epoch: 5| Step: 4
Training loss: 3.088159461385981
Validation loss: 2.7024092206997725

Epoch: 5| Step: 5
Training loss: 3.4028255502543567
Validation loss: 2.701422149353343

Epoch: 5| Step: 6
Training loss: 2.6889703853419156
Validation loss: 2.7056095243265275

Epoch: 5| Step: 7
Training loss: 2.690178534386705
Validation loss: 2.714992347440146

Epoch: 5| Step: 8
Training loss: 2.950074088249254
Validation loss: 2.7394153395766154

Epoch: 5| Step: 9
Training loss: 2.233858595707538
Validation loss: 2.7920856635861924

Epoch: 5| Step: 10
Training loss: 2.1615602645432297
Validation loss: 2.7854334602055566

Epoch: 286| Step: 0
Training loss: 3.07529966553455
Validation loss: 2.7981455979367436

Epoch: 5| Step: 1
Training loss: 3.360588670661571
Validation loss: 2.750767627722677

Epoch: 5| Step: 2
Training loss: 2.7290458846604753
Validation loss: 2.7305344460108274

Epoch: 5| Step: 3
Training loss: 2.703581490311668
Validation loss: 2.7176136173265153

Epoch: 5| Step: 4
Training loss: 3.2796209742035796
Validation loss: 2.713325791547133

Epoch: 5| Step: 5
Training loss: 3.3816403655459357
Validation loss: 2.71355582697996

Epoch: 5| Step: 6
Training loss: 3.2152160206505944
Validation loss: 2.7017406423322394

Epoch: 5| Step: 7
Training loss: 2.4766403811751183
Validation loss: 2.7069057835703294

Epoch: 5| Step: 8
Training loss: 3.0437313196756564
Validation loss: 2.7099825555540913

Epoch: 5| Step: 9
Training loss: 2.9409769461777864
Validation loss: 2.7127555795187557

Epoch: 5| Step: 10
Training loss: 3.090602776704969
Validation loss: 2.698219675378999

Epoch: 287| Step: 0
Training loss: 3.5532008824763155
Validation loss: 2.7013594522114945

Epoch: 5| Step: 1
Training loss: 3.1664547765680755
Validation loss: 2.6946765664848913

Epoch: 5| Step: 2
Training loss: 2.8686833858027896
Validation loss: 2.6951522515567463

Epoch: 5| Step: 3
Training loss: 3.454669865736173
Validation loss: 2.689482466859442

Epoch: 5| Step: 4
Training loss: 3.106487678015889
Validation loss: 2.6954798074175046

Epoch: 5| Step: 5
Training loss: 3.012766377555276
Validation loss: 2.696254822903666

Epoch: 5| Step: 6
Training loss: 2.6922709677360857
Validation loss: 2.7020777278120343

Epoch: 5| Step: 7
Training loss: 2.7132182352583936
Validation loss: 2.7045746713832814

Epoch: 5| Step: 8
Training loss: 2.8359637298632028
Validation loss: 2.726259445497022

Epoch: 5| Step: 9
Training loss: 2.985299331762181
Validation loss: 2.734114028032355

Epoch: 5| Step: 10
Training loss: 2.6447783542061134
Validation loss: 2.7436400074415537

Epoch: 288| Step: 0
Training loss: 2.9067516919337244
Validation loss: 2.7459544501230564

Epoch: 5| Step: 1
Training loss: 3.2526765219238163
Validation loss: 2.752182415210001

Epoch: 5| Step: 2
Training loss: 2.896483881121418
Validation loss: 2.7489364521376345

Epoch: 5| Step: 3
Training loss: 3.223730881432015
Validation loss: 2.757806684465867

Epoch: 5| Step: 4
Training loss: 3.2365806540922684
Validation loss: 2.751437290295831

Epoch: 5| Step: 5
Training loss: 2.994560396414378
Validation loss: 2.7511116197455387

Epoch: 5| Step: 6
Training loss: 3.3092475614424193
Validation loss: 2.719178370286908

Epoch: 5| Step: 7
Training loss: 2.9429434803322634
Validation loss: 2.6958923847911183

Epoch: 5| Step: 8
Training loss: 3.208944848641992
Validation loss: 2.680120546935472

Epoch: 5| Step: 9
Training loss: 2.8961180585855155
Validation loss: 2.680239940468245

Epoch: 5| Step: 10
Training loss: 2.2849015574879563
Validation loss: 2.6772188829289614

Epoch: 289| Step: 0
Training loss: 2.9699555208105832
Validation loss: 2.672244454380915

Epoch: 5| Step: 1
Training loss: 3.482638486585576
Validation loss: 2.678755546800927

Epoch: 5| Step: 2
Training loss: 2.47258643945192
Validation loss: 2.6768339977948448

Epoch: 5| Step: 3
Training loss: 3.1101744884348115
Validation loss: 2.672267561391682

Epoch: 5| Step: 4
Training loss: 3.2408497451938207
Validation loss: 2.6722659391298653

Epoch: 5| Step: 5
Training loss: 3.1661876182269233
Validation loss: 2.6700969604760205

Epoch: 5| Step: 6
Training loss: 2.6659864710516756
Validation loss: 2.677019408579908

Epoch: 5| Step: 7
Training loss: 2.702138378922822
Validation loss: 2.6747958583332867

Epoch: 5| Step: 8
Training loss: 3.2164367956008735
Validation loss: 2.6852334899322994

Epoch: 5| Step: 9
Training loss: 3.274351297443111
Validation loss: 2.7031250445747457

Epoch: 5| Step: 10
Training loss: 2.646922350463331
Validation loss: 2.714856634067391

Epoch: 290| Step: 0
Training loss: 2.8394222655110464
Validation loss: 2.707166181409375

Epoch: 5| Step: 1
Training loss: 3.186549923991592
Validation loss: 2.703115754992222

Epoch: 5| Step: 2
Training loss: 2.8272678488382925
Validation loss: 2.6828144462854024

Epoch: 5| Step: 3
Training loss: 2.83054749655416
Validation loss: 2.6785641977863994

Epoch: 5| Step: 4
Training loss: 2.9227084842716016
Validation loss: 2.671330386205893

Epoch: 5| Step: 5
Training loss: 2.8315062148012333
Validation loss: 2.6773310682712634

Epoch: 5| Step: 6
Training loss: 2.9970394467292993
Validation loss: 2.6797260525727085

Epoch: 5| Step: 7
Training loss: 2.7068982552670273
Validation loss: 2.686558720060764

Epoch: 5| Step: 8
Training loss: 3.471650706410329
Validation loss: 2.682994571622097

Epoch: 5| Step: 9
Training loss: 3.033827796570393
Validation loss: 2.6892568746157144

Epoch: 5| Step: 10
Training loss: 3.3052102254931666
Validation loss: 2.6819643137273474

Epoch: 291| Step: 0
Training loss: 2.3921465052325575
Validation loss: 2.6853899245055235

Epoch: 5| Step: 1
Training loss: 3.0217400253432984
Validation loss: 2.7040592475702105

Epoch: 5| Step: 2
Training loss: 3.1116257385711537
Validation loss: 2.7121662200487306

Epoch: 5| Step: 3
Training loss: 3.0155171587542347
Validation loss: 2.720188549061762

Epoch: 5| Step: 4
Training loss: 2.6364091253392132
Validation loss: 2.7221080149029997

Epoch: 5| Step: 5
Training loss: 3.152329833651129
Validation loss: 2.696001402523518

Epoch: 5| Step: 6
Training loss: 3.0457633313555212
Validation loss: 2.6801804447571964

Epoch: 5| Step: 7
Training loss: 2.94300553613026
Validation loss: 2.669535672755249

Epoch: 5| Step: 8
Training loss: 3.2727220431680992
Validation loss: 2.66664894896692

Epoch: 5| Step: 9
Training loss: 2.793830706563527
Validation loss: 2.664559856512999

Epoch: 5| Step: 10
Training loss: 3.6310805263136507
Validation loss: 2.6710304902648505

Epoch: 292| Step: 0
Training loss: 3.699323545943339
Validation loss: 2.6712678369236595

Epoch: 5| Step: 1
Training loss: 2.973367573351355
Validation loss: 2.6734831759989084

Epoch: 5| Step: 2
Training loss: 2.39875498108697
Validation loss: 2.669209551924379

Epoch: 5| Step: 3
Training loss: 3.1650145052175205
Validation loss: 2.670308688626597

Epoch: 5| Step: 4
Training loss: 3.2777038303661863
Validation loss: 2.670256032983749

Epoch: 5| Step: 5
Training loss: 2.85916720609809
Validation loss: 2.6714954520421594

Epoch: 5| Step: 6
Training loss: 2.937217374151109
Validation loss: 2.6647998055488613

Epoch: 5| Step: 7
Training loss: 3.0964831984926646
Validation loss: 2.6666727264653334

Epoch: 5| Step: 8
Training loss: 2.7184101637744007
Validation loss: 2.6667966798139253

Epoch: 5| Step: 9
Training loss: 2.792038214331836
Validation loss: 2.6666572811617835

Epoch: 5| Step: 10
Training loss: 2.971975722345973
Validation loss: 2.66823426407653

Epoch: 293| Step: 0
Training loss: 3.0714519221029715
Validation loss: 2.669953627437725

Epoch: 5| Step: 1
Training loss: 3.488647851764085
Validation loss: 2.6772488864906565

Epoch: 5| Step: 2
Training loss: 3.07899656398045
Validation loss: 2.6829042892563337

Epoch: 5| Step: 3
Training loss: 2.863600646727897
Validation loss: 2.701973178370346

Epoch: 5| Step: 4
Training loss: 3.0506432339639744
Validation loss: 2.7070064452685574

Epoch: 5| Step: 5
Training loss: 2.495198980435294
Validation loss: 2.7268441870382265

Epoch: 5| Step: 6
Training loss: 2.739677649978818
Validation loss: 2.720527621298494

Epoch: 5| Step: 7
Training loss: 2.4806461781400033
Validation loss: 2.738027774739158

Epoch: 5| Step: 8
Training loss: 3.3165166721899744
Validation loss: 2.73866636802028

Epoch: 5| Step: 9
Training loss: 3.4220285598927545
Validation loss: 2.7398091190468055

Epoch: 5| Step: 10
Training loss: 2.8479643394723624
Validation loss: 2.716822396193579

Epoch: 294| Step: 0
Training loss: 2.825503488420025
Validation loss: 2.7162591803996756

Epoch: 5| Step: 1
Training loss: 2.925461307241724
Validation loss: 2.6984132626512727

Epoch: 5| Step: 2
Training loss: 2.868230229914334
Validation loss: 2.683688711957549

Epoch: 5| Step: 3
Training loss: 2.79581955756154
Validation loss: 2.663785651640306

Epoch: 5| Step: 4
Training loss: 2.8334745110138946
Validation loss: 2.661119515147859

Epoch: 5| Step: 5
Training loss: 3.3138790498899935
Validation loss: 2.6632066944159654

Epoch: 5| Step: 6
Training loss: 3.225014968955616
Validation loss: 2.664636675343634

Epoch: 5| Step: 7
Training loss: 3.0659935157144935
Validation loss: 2.6622514288159

Epoch: 5| Step: 8
Training loss: 2.615271296678552
Validation loss: 2.6628896462515415

Epoch: 5| Step: 9
Training loss: 3.2655587075545514
Validation loss: 2.6651100901924045

Epoch: 5| Step: 10
Training loss: 3.275421633769809
Validation loss: 2.6625207020422077

Epoch: 295| Step: 0
Training loss: 3.1423861751411555
Validation loss: 2.664214477303542

Epoch: 5| Step: 1
Training loss: 3.1355676118291647
Validation loss: 2.6625417819016843

Epoch: 5| Step: 2
Training loss: 2.724314640196514
Validation loss: 2.6634278747269398

Epoch: 5| Step: 3
Training loss: 2.4963261312566853
Validation loss: 2.6653321157578436

Epoch: 5| Step: 4
Training loss: 2.9421687258761073
Validation loss: 2.6695362902486783

Epoch: 5| Step: 5
Training loss: 3.1616572527493085
Validation loss: 2.6716258430515767

Epoch: 5| Step: 6
Training loss: 3.3013457588656294
Validation loss: 2.67289987973362

Epoch: 5| Step: 7
Training loss: 2.766509006404919
Validation loss: 2.6869652796370267

Epoch: 5| Step: 8
Training loss: 3.2583753799366253
Validation loss: 2.6899185897311018

Epoch: 5| Step: 9
Training loss: 3.394227535589577
Validation loss: 2.695610879008228

Epoch: 5| Step: 10
Training loss: 2.3597711899932827
Validation loss: 2.718043672047155

Epoch: 296| Step: 0
Training loss: 3.253865217703473
Validation loss: 2.7221873431272963

Epoch: 5| Step: 1
Training loss: 2.814139587600401
Validation loss: 2.7282001459404848

Epoch: 5| Step: 2
Training loss: 2.551069865467446
Validation loss: 2.737000199776645

Epoch: 5| Step: 3
Training loss: 3.2050006120178303
Validation loss: 2.7361981835932974

Epoch: 5| Step: 4
Training loss: 2.875478953396422
Validation loss: 2.722412962889943

Epoch: 5| Step: 5
Training loss: 3.251982304439283
Validation loss: 2.7031102447704543

Epoch: 5| Step: 6
Training loss: 3.240170064866252
Validation loss: 2.701493058403202

Epoch: 5| Step: 7
Training loss: 3.2058515156077507
Validation loss: 2.6957041542208686

Epoch: 5| Step: 8
Training loss: 2.6392674314026783
Validation loss: 2.6950723568139847

Epoch: 5| Step: 9
Training loss: 2.3269944486203467
Validation loss: 2.6840340007998207

Epoch: 5| Step: 10
Training loss: 3.435032600570187
Validation loss: 2.68213502016518

Epoch: 297| Step: 0
Training loss: 2.5963783275789902
Validation loss: 2.6751412533104277

Epoch: 5| Step: 1
Training loss: 2.9106605451271643
Validation loss: 2.6677869643746965

Epoch: 5| Step: 2
Training loss: 2.205685689798666
Validation loss: 2.6671550986631747

Epoch: 5| Step: 3
Training loss: 2.8040718104136606
Validation loss: 2.6665208633104536

Epoch: 5| Step: 4
Training loss: 3.137278429695804
Validation loss: 2.664757473584184

Epoch: 5| Step: 5
Training loss: 2.941655243445272
Validation loss: 2.661480335078591

Epoch: 5| Step: 6
Training loss: 3.619779181516051
Validation loss: 2.658777993921662

Epoch: 5| Step: 7
Training loss: 2.933457697775141
Validation loss: 2.658546908158331

Epoch: 5| Step: 8
Training loss: 3.405550543688235
Validation loss: 2.6569639651888464

Epoch: 5| Step: 9
Training loss: 2.884646114283497
Validation loss: 2.6575518675704957

Epoch: 5| Step: 10
Training loss: 3.2786463989225005
Validation loss: 2.6590372613317084

Epoch: 298| Step: 0
Training loss: 2.600132454652701
Validation loss: 2.6601985588140638

Epoch: 5| Step: 1
Training loss: 2.526776729223075
Validation loss: 2.657303725496749

Epoch: 5| Step: 2
Training loss: 2.8324188177691747
Validation loss: 2.661205566712258

Epoch: 5| Step: 3
Training loss: 2.8398304851070013
Validation loss: 2.6630711751006513

Epoch: 5| Step: 4
Training loss: 3.3607350989438958
Validation loss: 2.6626318881630375

Epoch: 5| Step: 5
Training loss: 2.677828218803698
Validation loss: 2.6616650682016725

Epoch: 5| Step: 6
Training loss: 3.244065074282074
Validation loss: 2.6652419757412558

Epoch: 5| Step: 7
Training loss: 2.5687817128398076
Validation loss: 2.676920579460832

Epoch: 5| Step: 8
Training loss: 3.514269079884538
Validation loss: 2.6865166212154166

Epoch: 5| Step: 9
Training loss: 3.3752110733150764
Validation loss: 2.690640635539851

Epoch: 5| Step: 10
Training loss: 3.13847649564962
Validation loss: 2.7066306189579468

Epoch: 299| Step: 0
Training loss: 3.341256754048118
Validation loss: 2.7117079567639863

Epoch: 5| Step: 1
Training loss: 3.127835475087574
Validation loss: 2.7287834823424415

Epoch: 5| Step: 2
Training loss: 2.995423004388483
Validation loss: 2.7303774440783974

Epoch: 5| Step: 3
Training loss: 3.478473540988059
Validation loss: 2.7228178436925146

Epoch: 5| Step: 4
Training loss: 3.2463275995039043
Validation loss: 2.722744084369691

Epoch: 5| Step: 5
Training loss: 3.013007099952271
Validation loss: 2.6802656681927726

Epoch: 5| Step: 6
Training loss: 3.011485683264626
Validation loss: 2.667820178842159

Epoch: 5| Step: 7
Training loss: 2.2833394971704006
Validation loss: 2.660979011744672

Epoch: 5| Step: 8
Training loss: 2.620301355691958
Validation loss: 2.6588689190543477

Epoch: 5| Step: 9
Training loss: 2.9041085506044446
Validation loss: 2.6563672005495977

Epoch: 5| Step: 10
Training loss: 2.580850536111321
Validation loss: 2.6556334830262767

Epoch: 300| Step: 0
Training loss: 2.5824698163730835
Validation loss: 2.6599547212089996

Epoch: 5| Step: 1
Training loss: 2.3992196960347982
Validation loss: 2.6556567712533288

Epoch: 5| Step: 2
Training loss: 2.9499900365111635
Validation loss: 2.6597681304940224

Epoch: 5| Step: 3
Training loss: 3.5771256429709855
Validation loss: 2.6589207839699482

Epoch: 5| Step: 4
Training loss: 2.800877440435467
Validation loss: 2.6591846090829208

Epoch: 5| Step: 5
Training loss: 3.236715013933247
Validation loss: 2.662743134147535

Epoch: 5| Step: 6
Training loss: 3.119667997546693
Validation loss: 2.662567749963947

Epoch: 5| Step: 7
Training loss: 2.3150870827100665
Validation loss: 2.6681559826737544

Epoch: 5| Step: 8
Training loss: 3.319935496749249
Validation loss: 2.6692166986185817

Epoch: 5| Step: 9
Training loss: 3.272112958501861
Validation loss: 2.6710579220133908

Epoch: 5| Step: 10
Training loss: 3.052058578928961
Validation loss: 2.669503257510805

Epoch: 301| Step: 0
Training loss: 2.8038402754748275
Validation loss: 2.678626636027995

Epoch: 5| Step: 1
Training loss: 3.264342864008202
Validation loss: 2.679467104063944

Epoch: 5| Step: 2
Training loss: 3.347687016705177
Validation loss: 2.687980235014552

Epoch: 5| Step: 3
Training loss: 2.9974739247922693
Validation loss: 2.700370704105082

Epoch: 5| Step: 4
Training loss: 3.2899109387155416
Validation loss: 2.6943633869694326

Epoch: 5| Step: 5
Training loss: 3.549236973172662
Validation loss: 2.6732188842996676

Epoch: 5| Step: 6
Training loss: 2.946175284459955
Validation loss: 2.66837671335021

Epoch: 5| Step: 7
Training loss: 2.5577256921428377
Validation loss: 2.6659181996770736

Epoch: 5| Step: 8
Training loss: 2.7521064666846167
Validation loss: 2.6573081662491824

Epoch: 5| Step: 9
Training loss: 2.7816872413777927
Validation loss: 2.6514723352385405

Epoch: 5| Step: 10
Training loss: 2.29351041202581
Validation loss: 2.6547734672979524

Epoch: 302| Step: 0
Training loss: 2.9218994792381996
Validation loss: 2.6519886268246013

Epoch: 5| Step: 1
Training loss: 3.5404328983511397
Validation loss: 2.6544241549288583

Epoch: 5| Step: 2
Training loss: 3.205079463979382
Validation loss: 2.6525593220470576

Epoch: 5| Step: 3
Training loss: 2.93949108416105
Validation loss: 2.653315567482838

Epoch: 5| Step: 4
Training loss: 3.0641481285443937
Validation loss: 2.656733620016697

Epoch: 5| Step: 5
Training loss: 2.759887433451717
Validation loss: 2.6545644799069956

Epoch: 5| Step: 6
Training loss: 3.1741015507221686
Validation loss: 2.6609752529585413

Epoch: 5| Step: 7
Training loss: 2.9766288209269964
Validation loss: 2.663291631252485

Epoch: 5| Step: 8
Training loss: 2.438441363757772
Validation loss: 2.6674023531203415

Epoch: 5| Step: 9
Training loss: 2.493683273455261
Validation loss: 2.6651369518609846

Epoch: 5| Step: 10
Training loss: 3.210636319702463
Validation loss: 2.6714947975760905

Epoch: 303| Step: 0
Training loss: 3.12499069212481
Validation loss: 2.6794563250424552

Epoch: 5| Step: 1
Training loss: 3.0604488744181375
Validation loss: 2.6851089202172345

Epoch: 5| Step: 2
Training loss: 3.1754755339859506
Validation loss: 2.703304711814177

Epoch: 5| Step: 3
Training loss: 2.7655334457502025
Validation loss: 2.70639684150335

Epoch: 5| Step: 4
Training loss: 2.482433976354749
Validation loss: 2.7089758711078695

Epoch: 5| Step: 5
Training loss: 2.923634534808932
Validation loss: 2.7161869843549535

Epoch: 5| Step: 6
Training loss: 2.8524593249404018
Validation loss: 2.701572685450483

Epoch: 5| Step: 7
Training loss: 3.3596959160397826
Validation loss: 2.679494233212913

Epoch: 5| Step: 8
Training loss: 3.1038448670446144
Validation loss: 2.670636718942694

Epoch: 5| Step: 9
Training loss: 2.9924558514212167
Validation loss: 2.6687034508541605

Epoch: 5| Step: 10
Training loss: 2.9620991946758166
Validation loss: 2.6637785664052585

Epoch: 304| Step: 0
Training loss: 3.069961488960598
Validation loss: 2.6640650125771423

Epoch: 5| Step: 1
Training loss: 2.785980231128011
Validation loss: 2.6599392831586677

Epoch: 5| Step: 2
Training loss: 3.0365006109645662
Validation loss: 2.6538737932350545

Epoch: 5| Step: 3
Training loss: 3.442714689232542
Validation loss: 2.658497308850631

Epoch: 5| Step: 4
Training loss: 2.879248920890604
Validation loss: 2.6559394592166194

Epoch: 5| Step: 5
Training loss: 2.8902326987805993
Validation loss: 2.6549831431234767

Epoch: 5| Step: 6
Training loss: 3.1283822638848435
Validation loss: 2.655558954307283

Epoch: 5| Step: 7
Training loss: 3.3019498844236876
Validation loss: 2.6633463660767887

Epoch: 5| Step: 8
Training loss: 2.9799941898775746
Validation loss: 2.6570603468293226

Epoch: 5| Step: 9
Training loss: 2.472176985975679
Validation loss: 2.6602355049930804

Epoch: 5| Step: 10
Training loss: 2.6762002658632618
Validation loss: 2.652146641466116

Epoch: 305| Step: 0
Training loss: 2.8161789462442344
Validation loss: 2.6563402945935133

Epoch: 5| Step: 1
Training loss: 3.5620434117100173
Validation loss: 2.6601062402720586

Epoch: 5| Step: 2
Training loss: 3.1593384692516655
Validation loss: 2.663558466251633

Epoch: 5| Step: 3
Training loss: 3.0294898517071616
Validation loss: 2.6631508699070254

Epoch: 5| Step: 4
Training loss: 2.295058278027431
Validation loss: 2.6635677041866965

Epoch: 5| Step: 5
Training loss: 3.327634103596276
Validation loss: 2.663778135246636

Epoch: 5| Step: 6
Training loss: 2.4415623973503173
Validation loss: 2.6660007730465702

Epoch: 5| Step: 7
Training loss: 3.0980569164251435
Validation loss: 2.665999025809057

Epoch: 5| Step: 8
Training loss: 3.322229312292363
Validation loss: 2.663538980629234

Epoch: 5| Step: 9
Training loss: 2.781449128641131
Validation loss: 2.665433843522253

Epoch: 5| Step: 10
Training loss: 2.6416218698676457
Validation loss: 2.6655701727406935

Epoch: 306| Step: 0
Training loss: 3.0227543653002793
Validation loss: 2.6623030930243563

Epoch: 5| Step: 1
Training loss: 3.1853564665656804
Validation loss: 2.669716374239808

Epoch: 5| Step: 2
Training loss: 2.80064555628187
Validation loss: 2.676776218302765

Epoch: 5| Step: 3
Training loss: 3.586462576659868
Validation loss: 2.6853481949356484

Epoch: 5| Step: 4
Training loss: 2.6015921009659353
Validation loss: 2.6882339394939496

Epoch: 5| Step: 5
Training loss: 2.9123587447199526
Validation loss: 2.695776466121947

Epoch: 5| Step: 6
Training loss: 2.7003776392161636
Validation loss: 2.6822968950149964

Epoch: 5| Step: 7
Training loss: 3.110807156095432
Validation loss: 2.6865603041103396

Epoch: 5| Step: 8
Training loss: 2.344471527935516
Validation loss: 2.684697165566423

Epoch: 5| Step: 9
Training loss: 3.3991107843744492
Validation loss: 2.707499599310372

Epoch: 5| Step: 10
Training loss: 2.9052378214728662
Validation loss: 2.7250918833202165

Epoch: 307| Step: 0
Training loss: 3.198638900729612
Validation loss: 2.7276807633769975

Epoch: 5| Step: 1
Training loss: 2.9364373740298158
Validation loss: 2.7158601871972436

Epoch: 5| Step: 2
Training loss: 2.9674728055509743
Validation loss: 2.7151169879106294

Epoch: 5| Step: 3
Training loss: 3.0587566619788027
Validation loss: 2.7068209537518984

Epoch: 5| Step: 4
Training loss: 2.577028908510786
Validation loss: 2.692970789740302

Epoch: 5| Step: 5
Training loss: 2.844389455813457
Validation loss: 2.682498322190194

Epoch: 5| Step: 6
Training loss: 3.3959719077701833
Validation loss: 2.6633337810074535

Epoch: 5| Step: 7
Training loss: 3.0300797238578676
Validation loss: 2.6518816589131267

Epoch: 5| Step: 8
Training loss: 2.9210603771767225
Validation loss: 2.6581377225997254

Epoch: 5| Step: 9
Training loss: 3.0579987747459376
Validation loss: 2.6554491383624224

Epoch: 5| Step: 10
Training loss: 2.584456927512714
Validation loss: 2.664338157248804

Epoch: 308| Step: 0
Training loss: 2.750259820628432
Validation loss: 2.658143929791973

Epoch: 5| Step: 1
Training loss: 3.3733452873118694
Validation loss: 2.658389389671688

Epoch: 5| Step: 2
Training loss: 2.6139864803918997
Validation loss: 2.6638247134481277

Epoch: 5| Step: 3
Training loss: 2.857817679140332
Validation loss: 2.6653375953922955

Epoch: 5| Step: 4
Training loss: 3.237345487817931
Validation loss: 2.67084696451416

Epoch: 5| Step: 5
Training loss: 2.236883822368012
Validation loss: 2.671282795870923

Epoch: 5| Step: 6
Training loss: 3.3753530529585642
Validation loss: 2.6678871705998395

Epoch: 5| Step: 7
Training loss: 3.2855855727011574
Validation loss: 2.670085480174956

Epoch: 5| Step: 8
Training loss: 2.779809471572141
Validation loss: 2.672579840442264

Epoch: 5| Step: 9
Training loss: 3.1731190614192046
Validation loss: 2.6736215811143853

Epoch: 5| Step: 10
Training loss: 2.907295777224445
Validation loss: 2.6709333745623316

Epoch: 309| Step: 0
Training loss: 3.3172908182895133
Validation loss: 2.6864645781264307

Epoch: 5| Step: 1
Training loss: 2.443571500771427
Validation loss: 2.6785992387225437

Epoch: 5| Step: 2
Training loss: 2.4889919158448692
Validation loss: 2.6888192800357134

Epoch: 5| Step: 3
Training loss: 2.656758069085815
Validation loss: 2.6971340649468645

Epoch: 5| Step: 4
Training loss: 2.7412235489389714
Validation loss: 2.692896790761582

Epoch: 5| Step: 5
Training loss: 3.7979703351510015
Validation loss: 2.6933726521495016

Epoch: 5| Step: 6
Training loss: 2.734819561377803
Validation loss: 2.689020965128223

Epoch: 5| Step: 7
Training loss: 3.4754518942348525
Validation loss: 2.700752083139998

Epoch: 5| Step: 8
Training loss: 3.3580259941326402
Validation loss: 2.701615428387694

Epoch: 5| Step: 9
Training loss: 2.9472407092841797
Validation loss: 2.699892482151198

Epoch: 5| Step: 10
Training loss: 2.386077944675917
Validation loss: 2.6767462525414776

Epoch: 310| Step: 0
Training loss: 3.0235095742479214
Validation loss: 2.6617011059923783

Epoch: 5| Step: 1
Training loss: 3.375099745795283
Validation loss: 2.660133985610217

Epoch: 5| Step: 2
Training loss: 2.637818329028136
Validation loss: 2.6582750904704144

Epoch: 5| Step: 3
Training loss: 2.8144244921231754
Validation loss: 2.6572493948995692

Epoch: 5| Step: 4
Training loss: 2.998625917463414
Validation loss: 2.6525591190866376

Epoch: 5| Step: 5
Training loss: 3.296941819801978
Validation loss: 2.6515537767163275

Epoch: 5| Step: 6
Training loss: 2.673516377233537
Validation loss: 2.648255687322871

Epoch: 5| Step: 7
Training loss: 3.353803121321661
Validation loss: 2.646309607629523

Epoch: 5| Step: 8
Training loss: 2.3694378822815176
Validation loss: 2.6485689080816908

Epoch: 5| Step: 9
Training loss: 2.8801296745352754
Validation loss: 2.652186300971948

Epoch: 5| Step: 10
Training loss: 3.2323793898265394
Validation loss: 2.6556080379624047

Epoch: 311| Step: 0
Training loss: 2.722292379093717
Validation loss: 2.6566521414377204

Epoch: 5| Step: 1
Training loss: 3.2359506206163564
Validation loss: 2.6786600481873593

Epoch: 5| Step: 2
Training loss: 2.6608344514507745
Validation loss: 2.6845075254629744

Epoch: 5| Step: 3
Training loss: 2.990841874218219
Validation loss: 2.6765860380601243

Epoch: 5| Step: 4
Training loss: 3.1362761948952302
Validation loss: 2.681156493051682

Epoch: 5| Step: 5
Training loss: 3.071590710792847
Validation loss: 2.6800145210655733

Epoch: 5| Step: 6
Training loss: 3.0829674443528354
Validation loss: 2.6717641591927865

Epoch: 5| Step: 7
Training loss: 3.36804245010046
Validation loss: 2.67233877877014

Epoch: 5| Step: 8
Training loss: 2.4925187706886196
Validation loss: 2.689006290767241

Epoch: 5| Step: 9
Training loss: 2.8692034460659968
Validation loss: 2.6944794606231546

Epoch: 5| Step: 10
Training loss: 2.945706530858494
Validation loss: 2.6908704071066625

Epoch: 312| Step: 0
Training loss: 3.342254304151341
Validation loss: 2.711260179762755

Epoch: 5| Step: 1
Training loss: 3.2617750334309354
Validation loss: 2.6953559842257198

Epoch: 5| Step: 2
Training loss: 2.251137869593122
Validation loss: 2.6840788654779413

Epoch: 5| Step: 3
Training loss: 2.7196218912196546
Validation loss: 2.6859520300518374

Epoch: 5| Step: 4
Training loss: 3.6938775726337285
Validation loss: 2.6929845133756913

Epoch: 5| Step: 5
Training loss: 2.856520264775184
Validation loss: 2.68447673399069

Epoch: 5| Step: 6
Training loss: 2.9618672141757436
Validation loss: 2.6848553940470237

Epoch: 5| Step: 7
Training loss: 3.074785153706691
Validation loss: 2.661841137881749

Epoch: 5| Step: 8
Training loss: 2.6374258491976357
Validation loss: 2.652807202446485

Epoch: 5| Step: 9
Training loss: 3.045730140980124
Validation loss: 2.6505610194297127

Epoch: 5| Step: 10
Training loss: 2.509855394947315
Validation loss: 2.6499675435690455

Epoch: 313| Step: 0
Training loss: 2.725595384702366
Validation loss: 2.651587119111973

Epoch: 5| Step: 1
Training loss: 2.363546964982137
Validation loss: 2.6536791468669536

Epoch: 5| Step: 2
Training loss: 2.6722195051853097
Validation loss: 2.669488923382254

Epoch: 5| Step: 3
Training loss: 3.3880302943166725
Validation loss: 2.668707703566483

Epoch: 5| Step: 4
Training loss: 3.4846232372862005
Validation loss: 2.6736152391775185

Epoch: 5| Step: 5
Training loss: 2.868938192207704
Validation loss: 2.6770153548554596

Epoch: 5| Step: 6
Training loss: 3.0174349556449185
Validation loss: 2.6833366718346627

Epoch: 5| Step: 7
Training loss: 2.733026488068651
Validation loss: 2.6753400656415134

Epoch: 5| Step: 8
Training loss: 2.8001090164760356
Validation loss: 2.6858445859620157

Epoch: 5| Step: 9
Training loss: 2.985327603559403
Validation loss: 2.6721506140334443

Epoch: 5| Step: 10
Training loss: 3.517750008814117
Validation loss: 2.6861995728252284

Epoch: 314| Step: 0
Training loss: 2.8612374665672005
Validation loss: 2.695766336219969

Epoch: 5| Step: 1
Training loss: 2.496275129578567
Validation loss: 2.712201293796657

Epoch: 5| Step: 2
Training loss: 2.9446526959587094
Validation loss: 2.74365943342309

Epoch: 5| Step: 3
Training loss: 3.270785402242399
Validation loss: 2.7718822434713113

Epoch: 5| Step: 4
Training loss: 3.148391912617775
Validation loss: 2.7782798670863644

Epoch: 5| Step: 5
Training loss: 3.228397761857211
Validation loss: 2.7579365986790214

Epoch: 5| Step: 6
Training loss: 3.0056804283966194
Validation loss: 2.7057925994823773

Epoch: 5| Step: 7
Training loss: 3.2610141746963937
Validation loss: 2.668663052150708

Epoch: 5| Step: 8
Training loss: 2.579849129043303
Validation loss: 2.6520928059931332

Epoch: 5| Step: 9
Training loss: 2.407874215614307
Validation loss: 2.6477448384105586

Epoch: 5| Step: 10
Training loss: 3.5071723200892615
Validation loss: 2.6467856670779675

Epoch: 315| Step: 0
Training loss: 2.807896385574365
Validation loss: 2.6472136256323746

Epoch: 5| Step: 1
Training loss: 3.6475630371837977
Validation loss: 2.651458103776541

Epoch: 5| Step: 2
Training loss: 2.579591183912083
Validation loss: 2.649000598691473

Epoch: 5| Step: 3
Training loss: 3.0335525733890187
Validation loss: 2.6507572990441766

Epoch: 5| Step: 4
Training loss: 3.08220081322216
Validation loss: 2.656327053354333

Epoch: 5| Step: 5
Training loss: 2.867116818089521
Validation loss: 2.6573525357406997

Epoch: 5| Step: 6
Training loss: 2.906561393872928
Validation loss: 2.659402022126803

Epoch: 5| Step: 7
Training loss: 3.5275375971963485
Validation loss: 2.6560475262003442

Epoch: 5| Step: 8
Training loss: 2.6518019289931085
Validation loss: 2.6508629458187274

Epoch: 5| Step: 9
Training loss: 2.833356875901492
Validation loss: 2.6529146249107436

Epoch: 5| Step: 10
Training loss: 2.8609161392822857
Validation loss: 2.6523021626051766

Epoch: 316| Step: 0
Training loss: 2.7573077466664215
Validation loss: 2.6521710308419757

Epoch: 5| Step: 1
Training loss: 2.63473422496231
Validation loss: 2.651779579475479

Epoch: 5| Step: 2
Training loss: 2.8730027268659355
Validation loss: 2.6491514823704034

Epoch: 5| Step: 3
Training loss: 3.209851900528689
Validation loss: 2.6573465823551894

Epoch: 5| Step: 4
Training loss: 2.895780183226598
Validation loss: 2.6499843689435654

Epoch: 5| Step: 5
Training loss: 3.148455068383056
Validation loss: 2.6627206396184753

Epoch: 5| Step: 6
Training loss: 3.0979280869650343
Validation loss: 2.664675788173707

Epoch: 5| Step: 7
Training loss: 3.165673418041928
Validation loss: 2.6625464324854007

Epoch: 5| Step: 8
Training loss: 3.1788631935981897
Validation loss: 2.6781814510853392

Epoch: 5| Step: 9
Training loss: 3.198400968148265
Validation loss: 2.696428429552766

Epoch: 5| Step: 10
Training loss: 2.2868789830450718
Validation loss: 2.696463157527538

Epoch: 317| Step: 0
Training loss: 2.921893277850585
Validation loss: 2.743066311800399

Epoch: 5| Step: 1
Training loss: 3.0444810118726036
Validation loss: 2.7607075800098566

Epoch: 5| Step: 2
Training loss: 3.008809665013851
Validation loss: 2.7385994264065747

Epoch: 5| Step: 3
Training loss: 2.8517059708128616
Validation loss: 2.7459129155276267

Epoch: 5| Step: 4
Training loss: 2.6102989525422307
Validation loss: 2.7209086515910315

Epoch: 5| Step: 5
Training loss: 3.284772308448056
Validation loss: 2.6966646892252824

Epoch: 5| Step: 6
Training loss: 2.5286620297029465
Validation loss: 2.6802743540417784

Epoch: 5| Step: 7
Training loss: 3.2994806921437787
Validation loss: 2.658382810809267

Epoch: 5| Step: 8
Training loss: 2.7315780721948713
Validation loss: 2.6465139588313447

Epoch: 5| Step: 9
Training loss: 3.007976260000251
Validation loss: 2.639354581027924

Epoch: 5| Step: 10
Training loss: 3.3827407512147896
Validation loss: 2.6360722766014923

Epoch: 318| Step: 0
Training loss: 3.400042836536505
Validation loss: 2.6383200586297106

Epoch: 5| Step: 1
Training loss: 2.545071952417251
Validation loss: 2.639596207502958

Epoch: 5| Step: 2
Training loss: 2.693837168405019
Validation loss: 2.642184603775207

Epoch: 5| Step: 3
Training loss: 2.6326238638202217
Validation loss: 2.638158170359657

Epoch: 5| Step: 4
Training loss: 2.627898477959418
Validation loss: 2.640714010529791

Epoch: 5| Step: 5
Training loss: 3.3258090132095965
Validation loss: 2.6422511821059484

Epoch: 5| Step: 6
Training loss: 2.8641923857277707
Validation loss: 2.651558430135639

Epoch: 5| Step: 7
Training loss: 2.72458111054448
Validation loss: 2.6558340751944245

Epoch: 5| Step: 8
Training loss: 3.7795746930348515
Validation loss: 2.656649648869437

Epoch: 5| Step: 9
Training loss: 2.5136477833077233
Validation loss: 2.670485368246373

Epoch: 5| Step: 10
Training loss: 3.336676701071098
Validation loss: 2.67644455540691

Epoch: 319| Step: 0
Training loss: 2.378260933679177
Validation loss: 2.6973162307691387

Epoch: 5| Step: 1
Training loss: 3.199748571770349
Validation loss: 2.7341958217248643

Epoch: 5| Step: 2
Training loss: 3.7115700273019123
Validation loss: 2.764235307560674

Epoch: 5| Step: 3
Training loss: 3.244294513724774
Validation loss: 2.774657722094392

Epoch: 5| Step: 4
Training loss: 2.8295264380973015
Validation loss: 2.763318259871015

Epoch: 5| Step: 5
Training loss: 3.673581250427328
Validation loss: 2.7245475802906616

Epoch: 5| Step: 6
Training loss: 2.386713755301136
Validation loss: 2.70242526801633

Epoch: 5| Step: 7
Training loss: 2.1918357387449565
Validation loss: 2.687174329702221

Epoch: 5| Step: 8
Training loss: 3.3794938298719495
Validation loss: 2.664760417467854

Epoch: 5| Step: 9
Training loss: 2.622809358865581
Validation loss: 2.6541762458853912

Epoch: 5| Step: 10
Training loss: 2.997196158821295
Validation loss: 2.6447494566343988

Epoch: 320| Step: 0
Training loss: 2.6487318567408016
Validation loss: 2.6346355777004926

Epoch: 5| Step: 1
Training loss: 2.6541248571754883
Validation loss: 2.633636874280976

Epoch: 5| Step: 2
Training loss: 2.818827906714008
Validation loss: 2.632810408433558

Epoch: 5| Step: 3
Training loss: 3.073813269895957
Validation loss: 2.635199481485001

Epoch: 5| Step: 4
Training loss: 2.2795478009305477
Validation loss: 2.6366779740195083

Epoch: 5| Step: 5
Training loss: 3.016014271649256
Validation loss: 2.638611446865583

Epoch: 5| Step: 6
Training loss: 2.818370626087426
Validation loss: 2.6374074516394415

Epoch: 5| Step: 7
Training loss: 3.48911910124334
Validation loss: 2.6360958912965966

Epoch: 5| Step: 8
Training loss: 3.055204772080068
Validation loss: 2.634684142339162

Epoch: 5| Step: 9
Training loss: 3.407163025167114
Validation loss: 2.6354044850288507

Epoch: 5| Step: 10
Training loss: 3.3923061439714237
Validation loss: 2.6373206925970702

Epoch: 321| Step: 0
Training loss: 2.924908863180211
Validation loss: 2.6407465772364165

Epoch: 5| Step: 1
Training loss: 2.8748150641627728
Validation loss: 2.640687367391515

Epoch: 5| Step: 2
Training loss: 2.6969571168493784
Validation loss: 2.654444565084169

Epoch: 5| Step: 3
Training loss: 3.313323728239182
Validation loss: 2.666298973270214

Epoch: 5| Step: 4
Training loss: 3.3756097313447846
Validation loss: 2.6732171475340305

Epoch: 5| Step: 5
Training loss: 3.1271589832105455
Validation loss: 2.6763200258635687

Epoch: 5| Step: 6
Training loss: 3.216430865590392
Validation loss: 2.671568328043194

Epoch: 5| Step: 7
Training loss: 2.4304496330311336
Validation loss: 2.6678680817478155

Epoch: 5| Step: 8
Training loss: 2.711877577429446
Validation loss: 2.676888265134776

Epoch: 5| Step: 9
Training loss: 2.876490994154705
Validation loss: 2.6672602968224752

Epoch: 5| Step: 10
Training loss: 2.935366078670275
Validation loss: 2.6666953405125593

Epoch: 322| Step: 0
Training loss: 2.7742157180069147
Validation loss: 2.6566023600732382

Epoch: 5| Step: 1
Training loss: 3.2392623758729537
Validation loss: 2.6502493187114866

Epoch: 5| Step: 2
Training loss: 2.978889737007159
Validation loss: 2.6494931385795404

Epoch: 5| Step: 3
Training loss: 2.6922957634923574
Validation loss: 2.6454291105560532

Epoch: 5| Step: 4
Training loss: 3.28865799036073
Validation loss: 2.640346119423118

Epoch: 5| Step: 5
Training loss: 3.001069514048186
Validation loss: 2.6352127432746495

Epoch: 5| Step: 6
Training loss: 3.2922624620214362
Validation loss: 2.6406122547008817

Epoch: 5| Step: 7
Training loss: 2.8395159714550715
Validation loss: 2.636283473855276

Epoch: 5| Step: 8
Training loss: 2.3198442082877717
Validation loss: 2.63695494620472

Epoch: 5| Step: 9
Training loss: 2.93511638923975
Validation loss: 2.6361159998956114

Epoch: 5| Step: 10
Training loss: 3.1547509589952183
Validation loss: 2.6415115308045682

Epoch: 323| Step: 0
Training loss: 2.9260910542440492
Validation loss: 2.6358378978900574

Epoch: 5| Step: 1
Training loss: 3.0269460109184534
Validation loss: 2.647501967657511

Epoch: 5| Step: 2
Training loss: 2.74612205349701
Validation loss: 2.6549426785565204

Epoch: 5| Step: 3
Training loss: 2.95047152355411
Validation loss: 2.6572018427765025

Epoch: 5| Step: 4
Training loss: 2.644066187931866
Validation loss: 2.66989812883826

Epoch: 5| Step: 5
Training loss: 2.585932613494958
Validation loss: 2.6796350363073533

Epoch: 5| Step: 6
Training loss: 3.1959793402298877
Validation loss: 2.6948757536491734

Epoch: 5| Step: 7
Training loss: 3.1256025114968615
Validation loss: 2.678102272480878

Epoch: 5| Step: 8
Training loss: 2.691091045641187
Validation loss: 2.683368411707775

Epoch: 5| Step: 9
Training loss: 3.633650619465336
Validation loss: 2.687984229284623

Epoch: 5| Step: 10
Training loss: 2.9316791732663003
Validation loss: 2.6877577768466785

Epoch: 324| Step: 0
Training loss: 3.209494607659698
Validation loss: 2.691848893510093

Epoch: 5| Step: 1
Training loss: 3.106951511924306
Validation loss: 2.681308718598026

Epoch: 5| Step: 2
Training loss: 2.7292849003076096
Validation loss: 2.6748633664059382

Epoch: 5| Step: 3
Training loss: 3.151529237631238
Validation loss: 2.695044876515834

Epoch: 5| Step: 4
Training loss: 3.323350804269285
Validation loss: 2.6807405250463434

Epoch: 5| Step: 5
Training loss: 2.8192013059948637
Validation loss: 2.6571883530544294

Epoch: 5| Step: 6
Training loss: 2.9210398087235903
Validation loss: 2.645264533807042

Epoch: 5| Step: 7
Training loss: 2.791582950836125
Validation loss: 2.6368426589077822

Epoch: 5| Step: 8
Training loss: 2.707444108578092
Validation loss: 2.6341025620996943

Epoch: 5| Step: 9
Training loss: 3.0269233264015085
Validation loss: 2.6321008528108236

Epoch: 5| Step: 10
Training loss: 2.698848273858695
Validation loss: 2.633818088113173

Epoch: 325| Step: 0
Training loss: 2.6713448160183506
Validation loss: 2.6362430830435293

Epoch: 5| Step: 1
Training loss: 2.822239267826752
Validation loss: 2.6322523419248913

Epoch: 5| Step: 2
Training loss: 2.5122083124541192
Validation loss: 2.6365455571168206

Epoch: 5| Step: 3
Training loss: 3.0248165484831535
Validation loss: 2.6409682431656525

Epoch: 5| Step: 4
Training loss: 3.5566108614384775
Validation loss: 2.643476900115678

Epoch: 5| Step: 5
Training loss: 2.858613960421945
Validation loss: 2.6440002826403024

Epoch: 5| Step: 6
Training loss: 3.0682089396604186
Validation loss: 2.651319413846363

Epoch: 5| Step: 7
Training loss: 2.628696291561241
Validation loss: 2.6502205020755603

Epoch: 5| Step: 8
Training loss: 3.02511447658358
Validation loss: 2.6522569653198884

Epoch: 5| Step: 9
Training loss: 3.0016484499951686
Validation loss: 2.6477284780842085

Epoch: 5| Step: 10
Training loss: 3.38244147611684
Validation loss: 2.653022846994857

Epoch: 326| Step: 0
Training loss: 3.124067854140718
Validation loss: 2.6492839320578963

Epoch: 5| Step: 1
Training loss: 2.535259885388952
Validation loss: 2.6514356188971164

Epoch: 5| Step: 2
Training loss: 3.06058006049534
Validation loss: 2.6633451975241536

Epoch: 5| Step: 3
Training loss: 2.3730964058938397
Validation loss: 2.6805276975721957

Epoch: 5| Step: 4
Training loss: 3.1458517583513785
Validation loss: 2.6904098638352085

Epoch: 5| Step: 5
Training loss: 3.184536322792774
Validation loss: 2.6872798536660167

Epoch: 5| Step: 6
Training loss: 2.8163561346962864
Validation loss: 2.6792247560062616

Epoch: 5| Step: 7
Training loss: 3.5855847021015728
Validation loss: 2.6804451059386123

Epoch: 5| Step: 8
Training loss: 2.524025957684409
Validation loss: 2.6716427661634596

Epoch: 5| Step: 9
Training loss: 3.2895211740378505
Validation loss: 2.6718726242986532

Epoch: 5| Step: 10
Training loss: 2.6313204286985514
Validation loss: 2.677169304928411

Epoch: 327| Step: 0
Training loss: 2.7455424681967004
Validation loss: 2.689662433968792

Epoch: 5| Step: 1
Training loss: 2.830259918839773
Validation loss: 2.706869484814003

Epoch: 5| Step: 2
Training loss: 2.742217843520909
Validation loss: 2.7319562217130637

Epoch: 5| Step: 3
Training loss: 3.219994017553992
Validation loss: 2.7314530617559654

Epoch: 5| Step: 4
Training loss: 3.004106889430701
Validation loss: 2.7444904198895417

Epoch: 5| Step: 5
Training loss: 3.12442377499936
Validation loss: 2.7423322805510146

Epoch: 5| Step: 6
Training loss: 3.0387968520927116
Validation loss: 2.7439404294850855

Epoch: 5| Step: 7
Training loss: 2.5759864954446354
Validation loss: 2.731694146820015

Epoch: 5| Step: 8
Training loss: 4.023274420238678
Validation loss: 2.7116676409535505

Epoch: 5| Step: 9
Training loss: 2.3821399177243907
Validation loss: 2.702430974580779

Epoch: 5| Step: 10
Training loss: 2.8339611554656985
Validation loss: 2.6793986489822155

Epoch: 328| Step: 0
Training loss: 2.4567998100891835
Validation loss: 2.6582347579898684

Epoch: 5| Step: 1
Training loss: 2.8908377904152913
Validation loss: 2.6324608520093733

Epoch: 5| Step: 2
Training loss: 3.426363018054879
Validation loss: 2.6302643787736564

Epoch: 5| Step: 3
Training loss: 3.451310315294186
Validation loss: 2.6288864480451744

Epoch: 5| Step: 4
Training loss: 2.8007500938055254
Validation loss: 2.6288747029365904

Epoch: 5| Step: 5
Training loss: 3.210921907039009
Validation loss: 2.6362981888516774

Epoch: 5| Step: 6
Training loss: 2.6717300821902046
Validation loss: 2.635116335975509

Epoch: 5| Step: 7
Training loss: 2.8495128215200793
Validation loss: 2.634327367445073

Epoch: 5| Step: 8
Training loss: 3.026001466537695
Validation loss: 2.6455762297537584

Epoch: 5| Step: 9
Training loss: 2.570319920676978
Validation loss: 2.6394204294313504

Epoch: 5| Step: 10
Training loss: 3.138879547180258
Validation loss: 2.6422660443329304

Epoch: 329| Step: 0
Training loss: 3.433592639007215
Validation loss: 2.6505833028134544

Epoch: 5| Step: 1
Training loss: 3.0789816966440453
Validation loss: 2.65778793411673

Epoch: 5| Step: 2
Training loss: 3.225537892514196
Validation loss: 2.6614061974226604

Epoch: 5| Step: 3
Training loss: 2.79964578295358
Validation loss: 2.6688969486482104

Epoch: 5| Step: 4
Training loss: 2.6983244500613845
Validation loss: 2.675332322982337

Epoch: 5| Step: 5
Training loss: 2.729880339127448
Validation loss: 2.6659432616944296

Epoch: 5| Step: 6
Training loss: 2.9958677442870814
Validation loss: 2.6676409384303024

Epoch: 5| Step: 7
Training loss: 3.2344240931226635
Validation loss: 2.6615898077856293

Epoch: 5| Step: 8
Training loss: 2.4459022079032966
Validation loss: 2.6566781207500476

Epoch: 5| Step: 9
Training loss: 3.20482832117046
Validation loss: 2.6501649892660146

Epoch: 5| Step: 10
Training loss: 2.5628248799628204
Validation loss: 2.6451362703847336

Epoch: 330| Step: 0
Training loss: 3.0035509710455965
Validation loss: 2.6350352348367108

Epoch: 5| Step: 1
Training loss: 2.417547580601854
Validation loss: 2.629822558696223

Epoch: 5| Step: 2
Training loss: 3.003368711556027
Validation loss: 2.6266429630951933

Epoch: 5| Step: 3
Training loss: 3.0185665351292084
Validation loss: 2.6291061510891978

Epoch: 5| Step: 4
Training loss: 2.763322809503791
Validation loss: 2.6381857787168066

Epoch: 5| Step: 5
Training loss: 2.819347438385791
Validation loss: 2.6548990132887913

Epoch: 5| Step: 6
Training loss: 3.0742632657891176
Validation loss: 2.671531869659461

Epoch: 5| Step: 7
Training loss: 3.226383675337358
Validation loss: 2.6827163839513304

Epoch: 5| Step: 8
Training loss: 2.6878181978858753
Validation loss: 2.722183302042409

Epoch: 5| Step: 9
Training loss: 3.510549314503784
Validation loss: 2.7625353758427087

Epoch: 5| Step: 10
Training loss: 3.0322111513295966
Validation loss: 2.7258157160786536

Epoch: 331| Step: 0
Training loss: 3.197982903373399
Validation loss: 2.6731918132600665

Epoch: 5| Step: 1
Training loss: 3.389717226641024
Validation loss: 2.650390135561851

Epoch: 5| Step: 2
Training loss: 2.3053980879520797
Validation loss: 2.632084081618834

Epoch: 5| Step: 3
Training loss: 3.293691245899565
Validation loss: 2.6302973253482906

Epoch: 5| Step: 4
Training loss: 2.719420602460373
Validation loss: 2.6250972905565804

Epoch: 5| Step: 5
Training loss: 3.0529246206914484
Validation loss: 2.624832252459333

Epoch: 5| Step: 6
Training loss: 3.3379229102629675
Validation loss: 2.625650233547007

Epoch: 5| Step: 7
Training loss: 2.480179705261666
Validation loss: 2.620493082051367

Epoch: 5| Step: 8
Training loss: 3.225128668059169
Validation loss: 2.6204584155958734

Epoch: 5| Step: 9
Training loss: 2.784635733267852
Validation loss: 2.622923515591266

Epoch: 5| Step: 10
Training loss: 2.5223063009124327
Validation loss: 2.6215608308178853

Epoch: 332| Step: 0
Training loss: 2.7048382043310624
Validation loss: 2.621528407158835

Epoch: 5| Step: 1
Training loss: 2.7659962722797333
Validation loss: 2.6261436600127857

Epoch: 5| Step: 2
Training loss: 2.855222594874904
Validation loss: 2.630894527070586

Epoch: 5| Step: 3
Training loss: 3.5883972109365248
Validation loss: 2.6402908165187724

Epoch: 5| Step: 4
Training loss: 3.1800145536365605
Validation loss: 2.653819684156025

Epoch: 5| Step: 5
Training loss: 2.8229782735898623
Validation loss: 2.675788348483209

Epoch: 5| Step: 6
Training loss: 3.3362793937065724
Validation loss: 2.692173063213196

Epoch: 5| Step: 7
Training loss: 3.066186204535098
Validation loss: 2.710963803564113

Epoch: 5| Step: 8
Training loss: 3.2044688313397325
Validation loss: 2.7003639892297016

Epoch: 5| Step: 9
Training loss: 2.616793383630023
Validation loss: 2.7049391258904856

Epoch: 5| Step: 10
Training loss: 2.025319170817988
Validation loss: 2.713232435684214

Epoch: 333| Step: 0
Training loss: 3.0727779206241213
Validation loss: 2.6990843825027317

Epoch: 5| Step: 1
Training loss: 3.4555901061276617
Validation loss: 2.706155709582569

Epoch: 5| Step: 2
Training loss: 3.0534589008959085
Validation loss: 2.6786345337809156

Epoch: 5| Step: 3
Training loss: 2.9386467825718228
Validation loss: 2.664263716148179

Epoch: 5| Step: 4
Training loss: 3.3949724444028107
Validation loss: 2.6452341122211265

Epoch: 5| Step: 5
Training loss: 2.821220442009037
Validation loss: 2.637762384155363

Epoch: 5| Step: 6
Training loss: 2.7548793507378107
Validation loss: 2.6333865614646954

Epoch: 5| Step: 7
Training loss: 2.7545528004603
Validation loss: 2.6291834032035557

Epoch: 5| Step: 8
Training loss: 2.5621020310429414
Validation loss: 2.629941716789228

Epoch: 5| Step: 9
Training loss: 2.5163549465953006
Validation loss: 2.627138990078885

Epoch: 5| Step: 10
Training loss: 3.027901914270244
Validation loss: 2.623606577143656

Epoch: 334| Step: 0
Training loss: 3.2129093250785585
Validation loss: 2.6227626387385286

Epoch: 5| Step: 1
Training loss: 3.044025673415886
Validation loss: 2.6200702256315624

Epoch: 5| Step: 2
Training loss: 2.835535446545453
Validation loss: 2.619717942704674

Epoch: 5| Step: 3
Training loss: 2.658477656912133
Validation loss: 2.621007773359472

Epoch: 5| Step: 4
Training loss: 3.120102057621767
Validation loss: 2.6202424479736734

Epoch: 5| Step: 5
Training loss: 3.1165359313254637
Validation loss: 2.622934281609977

Epoch: 5| Step: 6
Training loss: 2.6767239657199746
Validation loss: 2.622717107366672

Epoch: 5| Step: 7
Training loss: 3.1551685557854876
Validation loss: 2.6264334718532316

Epoch: 5| Step: 8
Training loss: 2.7100330789947207
Validation loss: 2.6265371190627835

Epoch: 5| Step: 9
Training loss: 2.9790989439053757
Validation loss: 2.633261122076268

Epoch: 5| Step: 10
Training loss: 3.0153473246916995
Validation loss: 2.633836004602125

Epoch: 335| Step: 0
Training loss: 3.0368517211348447
Validation loss: 2.6356957403890062

Epoch: 5| Step: 1
Training loss: 2.8089898139223
Validation loss: 2.6480541086659386

Epoch: 5| Step: 2
Training loss: 3.0969011076626405
Validation loss: 2.6509548580566245

Epoch: 5| Step: 3
Training loss: 2.731271432054874
Validation loss: 2.65822717767964

Epoch: 5| Step: 4
Training loss: 3.163121212947789
Validation loss: 2.66886786267639

Epoch: 5| Step: 5
Training loss: 2.8722383254792856
Validation loss: 2.681740473213249

Epoch: 5| Step: 6
Training loss: 2.586908440531594
Validation loss: 2.658934286114323

Epoch: 5| Step: 7
Training loss: 3.353344139197997
Validation loss: 2.67792998212536

Epoch: 5| Step: 8
Training loss: 2.668554730384981
Validation loss: 2.671429424052616

Epoch: 5| Step: 9
Training loss: 3.404320266476937
Validation loss: 2.6561318802553706

Epoch: 5| Step: 10
Training loss: 2.6453801966036035
Validation loss: 2.658319811253452

Epoch: 336| Step: 0
Training loss: 2.6212056302384314
Validation loss: 2.6723861641942888

Epoch: 5| Step: 1
Training loss: 2.8031308415414764
Validation loss: 2.6805874409274795

Epoch: 5| Step: 2
Training loss: 2.718090985985065
Validation loss: 2.704140292220325

Epoch: 5| Step: 3
Training loss: 3.7042604146335862
Validation loss: 2.7369828799280813

Epoch: 5| Step: 4
Training loss: 3.2451934484061384
Validation loss: 2.7234061594855765

Epoch: 5| Step: 5
Training loss: 2.4095359263626115
Validation loss: 2.6647881917919376

Epoch: 5| Step: 6
Training loss: 2.6892498440956554
Validation loss: 2.649905195299124

Epoch: 5| Step: 7
Training loss: 2.9899120792488505
Validation loss: 2.629218936502837

Epoch: 5| Step: 8
Training loss: 2.8309332461987857
Validation loss: 2.621857132369789

Epoch: 5| Step: 9
Training loss: 3.203947678032801
Validation loss: 2.6198114682132614

Epoch: 5| Step: 10
Training loss: 3.196674233972253
Validation loss: 2.622811437881142

Epoch: 337| Step: 0
Training loss: 2.6240363395779758
Validation loss: 2.6283737540724568

Epoch: 5| Step: 1
Training loss: 3.7630408826599684
Validation loss: 2.6264475158270244

Epoch: 5| Step: 2
Training loss: 3.073386480764182
Validation loss: 2.62717734576681

Epoch: 5| Step: 3
Training loss: 2.836506599933673
Validation loss: 2.6290465411057364

Epoch: 5| Step: 4
Training loss: 3.0570841019641466
Validation loss: 2.6293362450491924

Epoch: 5| Step: 5
Training loss: 3.1921061725311435
Validation loss: 2.628490870161591

Epoch: 5| Step: 6
Training loss: 2.9450916642591403
Validation loss: 2.628059019448352

Epoch: 5| Step: 7
Training loss: 2.3924443919895415
Validation loss: 2.6267685901891884

Epoch: 5| Step: 8
Training loss: 2.6379182926796196
Validation loss: 2.627780163782869

Epoch: 5| Step: 9
Training loss: 2.8519788464247244
Validation loss: 2.6239738333727005

Epoch: 5| Step: 10
Training loss: 3.3081661159685263
Validation loss: 2.622807305261851

Epoch: 338| Step: 0
Training loss: 2.580231701700537
Validation loss: 2.6217943297552644

Epoch: 5| Step: 1
Training loss: 2.7464417064848
Validation loss: 2.6241367344526374

Epoch: 5| Step: 2
Training loss: 2.938609623835951
Validation loss: 2.6181452387733097

Epoch: 5| Step: 3
Training loss: 2.7253021562675475
Validation loss: 2.618849843605209

Epoch: 5| Step: 4
Training loss: 3.142636390463589
Validation loss: 2.6201293466081528

Epoch: 5| Step: 5
Training loss: 3.123901326642087
Validation loss: 2.6246374908324874

Epoch: 5| Step: 6
Training loss: 2.992833478634413
Validation loss: 2.6379876764496273

Epoch: 5| Step: 7
Training loss: 2.9299417207409566
Validation loss: 2.6323352681958005

Epoch: 5| Step: 8
Training loss: 3.215808301915394
Validation loss: 2.6502278711934104

Epoch: 5| Step: 9
Training loss: 3.1366544458014056
Validation loss: 2.669818942232942

Epoch: 5| Step: 10
Training loss: 2.9038952547839663
Validation loss: 2.675063556410247

Epoch: 339| Step: 0
Training loss: 3.010520132502137
Validation loss: 2.6921692027605637

Epoch: 5| Step: 1
Training loss: 2.694770205579033
Validation loss: 2.711932502895492

Epoch: 5| Step: 2
Training loss: 3.0053383696050453
Validation loss: 2.701835188508534

Epoch: 5| Step: 3
Training loss: 3.2095567096502498
Validation loss: 2.7032427202888396

Epoch: 5| Step: 4
Training loss: 2.2425096659202173
Validation loss: 2.673074020165886

Epoch: 5| Step: 5
Training loss: 3.0360187890698977
Validation loss: 2.6518321930604434

Epoch: 5| Step: 6
Training loss: 3.0829948205103195
Validation loss: 2.6350619360966534

Epoch: 5| Step: 7
Training loss: 2.598152377140592
Validation loss: 2.6362940375039523

Epoch: 5| Step: 8
Training loss: 3.121119875076439
Validation loss: 2.6229976971083206

Epoch: 5| Step: 9
Training loss: 3.1161283065470475
Validation loss: 2.6166775026078106

Epoch: 5| Step: 10
Training loss: 3.249747046383536
Validation loss: 2.6129916708609695

Epoch: 340| Step: 0
Training loss: 3.1006977403563187
Validation loss: 2.609354238296744

Epoch: 5| Step: 1
Training loss: 3.1742190264082764
Validation loss: 2.614291261849268

Epoch: 5| Step: 2
Training loss: 2.7347812023898856
Validation loss: 2.6139665556057388

Epoch: 5| Step: 3
Training loss: 2.8412244711860595
Validation loss: 2.6168797573618856

Epoch: 5| Step: 4
Training loss: 2.995170839051178
Validation loss: 2.617980257078668

Epoch: 5| Step: 5
Training loss: 2.6830333585481703
Validation loss: 2.611923418548269

Epoch: 5| Step: 6
Training loss: 2.8277091041908085
Validation loss: 2.618037156393931

Epoch: 5| Step: 7
Training loss: 2.867566325344372
Validation loss: 2.6171403523414853

Epoch: 5| Step: 8
Training loss: 3.0038849788949418
Validation loss: 2.6155182541622555

Epoch: 5| Step: 9
Training loss: 2.758439551975329
Validation loss: 2.619506638092627

Epoch: 5| Step: 10
Training loss: 3.443896082498829
Validation loss: 2.6297895213619804

Epoch: 341| Step: 0
Training loss: 3.0293615692136866
Validation loss: 2.636983080474018

Epoch: 5| Step: 1
Training loss: 2.923049445930481
Validation loss: 2.6475165079760994

Epoch: 5| Step: 2
Training loss: 3.3397516605999287
Validation loss: 2.6444710914774636

Epoch: 5| Step: 3
Training loss: 2.569912679353988
Validation loss: 2.643519364353174

Epoch: 5| Step: 4
Training loss: 3.0561402907699895
Validation loss: 2.6555847917845754

Epoch: 5| Step: 5
Training loss: 2.908373641324104
Validation loss: 2.6549562820429675

Epoch: 5| Step: 6
Training loss: 2.5206326701688138
Validation loss: 2.6437363783761496

Epoch: 5| Step: 7
Training loss: 3.315966537674874
Validation loss: 2.642860152529942

Epoch: 5| Step: 8
Training loss: 2.7199245853347565
Validation loss: 2.640159619806566

Epoch: 5| Step: 9
Training loss: 3.060075539797202
Validation loss: 2.6275750907862414

Epoch: 5| Step: 10
Training loss: 2.732421700489183
Validation loss: 2.6370256871966995

Epoch: 342| Step: 0
Training loss: 2.582212779348284
Validation loss: 2.6373855721128687

Epoch: 5| Step: 1
Training loss: 2.541030918928561
Validation loss: 2.6495213748339745

Epoch: 5| Step: 2
Training loss: 3.2739743905437813
Validation loss: 2.652032653212483

Epoch: 5| Step: 3
Training loss: 2.9430504164011535
Validation loss: 2.6642956813138303

Epoch: 5| Step: 4
Training loss: 2.7385877146621462
Validation loss: 2.6723286415666565

Epoch: 5| Step: 5
Training loss: 3.396246543660685
Validation loss: 2.6846930823737885

Epoch: 5| Step: 6
Training loss: 2.8696722339256056
Validation loss: 2.697638049039815

Epoch: 5| Step: 7
Training loss: 3.425557563116565
Validation loss: 2.7122161186660096

Epoch: 5| Step: 8
Training loss: 2.510964762474996
Validation loss: 2.696767650621726

Epoch: 5| Step: 9
Training loss: 3.078544162152818
Validation loss: 2.7048932727383708

Epoch: 5| Step: 10
Training loss: 2.7348082280964623
Validation loss: 2.6743201913398504

Epoch: 343| Step: 0
Training loss: 3.051077424153827
Validation loss: 2.658518516079164

Epoch: 5| Step: 1
Training loss: 3.0419768258039093
Validation loss: 2.629549644610677

Epoch: 5| Step: 2
Training loss: 3.0115233678314897
Validation loss: 2.6175346436923723

Epoch: 5| Step: 3
Training loss: 2.809422992640074
Validation loss: 2.6243073261988843

Epoch: 5| Step: 4
Training loss: 3.441898514248387
Validation loss: 2.627538872281174

Epoch: 5| Step: 5
Training loss: 2.762283375389529
Validation loss: 2.6236261043106675

Epoch: 5| Step: 6
Training loss: 2.9241782509447574
Validation loss: 2.6305769291794014

Epoch: 5| Step: 7
Training loss: 3.1380537904562558
Validation loss: 2.633716082402212

Epoch: 5| Step: 8
Training loss: 2.792699243307112
Validation loss: 2.634407579519322

Epoch: 5| Step: 9
Training loss: 2.2732452625916246
Validation loss: 2.6408250949766985

Epoch: 5| Step: 10
Training loss: 2.974412837708642
Validation loss: 2.6531330870666436

Epoch: 344| Step: 0
Training loss: 2.854692972112212
Validation loss: 2.6468860339734666

Epoch: 5| Step: 1
Training loss: 3.2313120616508875
Validation loss: 2.645593141197424

Epoch: 5| Step: 2
Training loss: 2.643190841522237
Validation loss: 2.6412754926266646

Epoch: 5| Step: 3
Training loss: 3.305395893618464
Validation loss: 2.644745701439044

Epoch: 5| Step: 4
Training loss: 2.8098464315677716
Validation loss: 2.6511071071327996

Epoch: 5| Step: 5
Training loss: 2.8971253584212104
Validation loss: 2.6469044324793463

Epoch: 5| Step: 6
Training loss: 3.15261752654469
Validation loss: 2.649133164308304

Epoch: 5| Step: 7
Training loss: 3.16607963407881
Validation loss: 2.6476930653821853

Epoch: 5| Step: 8
Training loss: 2.712259723199699
Validation loss: 2.6594234935022136

Epoch: 5| Step: 9
Training loss: 2.716147657170084
Validation loss: 2.653453492230466

Epoch: 5| Step: 10
Training loss: 2.5654888865041148
Validation loss: 2.6883894318285666

Epoch: 345| Step: 0
Training loss: 2.931271544420009
Validation loss: 2.6971952539918016

Epoch: 5| Step: 1
Training loss: 2.8289657101917864
Validation loss: 2.709941461048388

Epoch: 5| Step: 2
Training loss: 3.021609677932669
Validation loss: 2.701193971497339

Epoch: 5| Step: 3
Training loss: 2.6484105831792673
Validation loss: 2.7094184478096945

Epoch: 5| Step: 4
Training loss: 3.297485584288257
Validation loss: 2.7251132844451362

Epoch: 5| Step: 5
Training loss: 2.935829011984496
Validation loss: 2.723369932864712

Epoch: 5| Step: 6
Training loss: 3.1110930177374394
Validation loss: 2.7285470695209635

Epoch: 5| Step: 7
Training loss: 3.0306480832596563
Validation loss: 2.714545467312413

Epoch: 5| Step: 8
Training loss: 2.841584942967242
Validation loss: 2.693450930699471

Epoch: 5| Step: 9
Training loss: 2.7890205273288275
Validation loss: 2.6724183276694387

Epoch: 5| Step: 10
Training loss: 2.7485784844720613
Validation loss: 2.6467800938258788

Epoch: 346| Step: 0
Training loss: 2.781397183413515
Validation loss: 2.645655635660443

Epoch: 5| Step: 1
Training loss: 2.8719403115235704
Validation loss: 2.6254268256258992

Epoch: 5| Step: 2
Training loss: 2.6425855231904016
Validation loss: 2.6248905947222068

Epoch: 5| Step: 3
Training loss: 2.808457924393018
Validation loss: 2.6172553548157538

Epoch: 5| Step: 4
Training loss: 3.3929071437048233
Validation loss: 2.62477488219012

Epoch: 5| Step: 5
Training loss: 3.5264554853854704
Validation loss: 2.629883037681502

Epoch: 5| Step: 6
Training loss: 2.750631780011455
Validation loss: 2.6248106802756848

Epoch: 5| Step: 7
Training loss: 2.656674519443114
Validation loss: 2.6421259064522755

Epoch: 5| Step: 8
Training loss: 2.9190738735175468
Validation loss: 2.656078402087474

Epoch: 5| Step: 9
Training loss: 2.816902191051186
Validation loss: 2.694195485923424

Epoch: 5| Step: 10
Training loss: 2.965814202948926
Validation loss: 2.698676158526326

Epoch: 347| Step: 0
Training loss: 3.015176215897678
Validation loss: 2.737640538552862

Epoch: 5| Step: 1
Training loss: 2.906425552808562
Validation loss: 2.789789285465652

Epoch: 5| Step: 2
Training loss: 3.379491854510401
Validation loss: 2.76137574882839

Epoch: 5| Step: 3
Training loss: 2.6078643994798156
Validation loss: 2.780164317995794

Epoch: 5| Step: 4
Training loss: 2.8240293911547227
Validation loss: 2.747823555925231

Epoch: 5| Step: 5
Training loss: 3.307475904404344
Validation loss: 2.715702014057006

Epoch: 5| Step: 6
Training loss: 2.814835574699089
Validation loss: 2.655548408404747

Epoch: 5| Step: 7
Training loss: 2.528838150667802
Validation loss: 2.630830820539836

Epoch: 5| Step: 8
Training loss: 2.8236772326735307
Validation loss: 2.621664024296257

Epoch: 5| Step: 9
Training loss: 3.0093463900306374
Validation loss: 2.6167460662393354

Epoch: 5| Step: 10
Training loss: 3.0719089385881118
Validation loss: 2.610623736886625

Epoch: 348| Step: 0
Training loss: 2.5015578184733287
Validation loss: 2.6115941605436888

Epoch: 5| Step: 1
Training loss: 2.8288242887619326
Validation loss: 2.612494725086955

Epoch: 5| Step: 2
Training loss: 2.798146390443337
Validation loss: 2.6154158601540365

Epoch: 5| Step: 3
Training loss: 2.4656429778435998
Validation loss: 2.6290355363454587

Epoch: 5| Step: 4
Training loss: 2.6324738870541013
Validation loss: 2.6500083627179953

Epoch: 5| Step: 5
Training loss: 3.1564098355452446
Validation loss: 2.6612430441526524

Epoch: 5| Step: 6
Training loss: 3.3143752925728083
Validation loss: 2.6793368525774346

Epoch: 5| Step: 7
Training loss: 2.608689817822884
Validation loss: 2.681780318348369

Epoch: 5| Step: 8
Training loss: 3.3832798870606986
Validation loss: 2.6725154814997953

Epoch: 5| Step: 9
Training loss: 3.2508323777259402
Validation loss: 2.6578764634320553

Epoch: 5| Step: 10
Training loss: 3.2997431279401406
Validation loss: 2.6219520716801634

Epoch: 349| Step: 0
Training loss: 3.4543167750402133
Validation loss: 2.6198090609565035

Epoch: 5| Step: 1
Training loss: 2.6877675477743868
Validation loss: 2.6283250104092346

Epoch: 5| Step: 2
Training loss: 2.5136422820227735
Validation loss: 2.6365758533716206

Epoch: 5| Step: 3
Training loss: 2.278170139613825
Validation loss: 2.6419294038048755

Epoch: 5| Step: 4
Training loss: 2.4659095551610606
Validation loss: 2.6591387430476465

Epoch: 5| Step: 5
Training loss: 2.883601217743395
Validation loss: 2.6975388101763977

Epoch: 5| Step: 6
Training loss: 3.33119869228451
Validation loss: 2.701512427796457

Epoch: 5| Step: 7
Training loss: 2.9534290298503523
Validation loss: 2.68321911581417

Epoch: 5| Step: 8
Training loss: 3.6493403687869814
Validation loss: 2.6650481481246233

Epoch: 5| Step: 9
Training loss: 2.7123977290267898
Validation loss: 2.6469273597288345

Epoch: 5| Step: 10
Training loss: 3.1294903346941094
Validation loss: 2.6398854466072077

Epoch: 350| Step: 0
Training loss: 2.718599600304113
Validation loss: 2.637584363043735

Epoch: 5| Step: 1
Training loss: 3.4246987314751043
Validation loss: 2.618085786085265

Epoch: 5| Step: 2
Training loss: 2.8649417907233996
Validation loss: 2.612408969849754

Epoch: 5| Step: 3
Training loss: 3.196747026464324
Validation loss: 2.611153714361815

Epoch: 5| Step: 4
Training loss: 2.5590742519051526
Validation loss: 2.610917132128013

Epoch: 5| Step: 5
Training loss: 2.931898091781715
Validation loss: 2.6106519712874388

Epoch: 5| Step: 6
Training loss: 3.0287739187343883
Validation loss: 2.6059297341801537

Epoch: 5| Step: 7
Training loss: 2.979378397071203
Validation loss: 2.6062075887122047

Epoch: 5| Step: 8
Training loss: 3.2482223050470806
Validation loss: 2.6028429062366802

Epoch: 5| Step: 9
Training loss: 2.5980850210043527
Validation loss: 2.608097216723251

Epoch: 5| Step: 10
Training loss: 2.7870287920310157
Validation loss: 2.603469726496649

Epoch: 351| Step: 0
Training loss: 2.7004635448258867
Validation loss: 2.6063017475598387

Epoch: 5| Step: 1
Training loss: 2.9630336940676485
Validation loss: 2.6107504662223686

Epoch: 5| Step: 2
Training loss: 2.9604908951096025
Validation loss: 2.613249114057381

Epoch: 5| Step: 3
Training loss: 2.767296065317652
Validation loss: 2.6198126679265754

Epoch: 5| Step: 4
Training loss: 3.350474218709103
Validation loss: 2.6196750828663817

Epoch: 5| Step: 5
Training loss: 2.4417911805919643
Validation loss: 2.6223028910931334

Epoch: 5| Step: 6
Training loss: 3.5436623429586684
Validation loss: 2.6411289725154523

Epoch: 5| Step: 7
Training loss: 2.943462893988741
Validation loss: 2.6386688621759258

Epoch: 5| Step: 8
Training loss: 2.8505513109728895
Validation loss: 2.6543400836774826

Epoch: 5| Step: 9
Training loss: 2.9583322945892947
Validation loss: 2.6458993124654273

Epoch: 5| Step: 10
Training loss: 2.692244134928269
Validation loss: 2.651777480633605

Epoch: 352| Step: 0
Training loss: 2.826921322780606
Validation loss: 2.649937089872556

Epoch: 5| Step: 1
Training loss: 3.002458677491896
Validation loss: 2.6501827372014963

Epoch: 5| Step: 2
Training loss: 2.5444871438935297
Validation loss: 2.650903661241489

Epoch: 5| Step: 3
Training loss: 3.2077350471462616
Validation loss: 2.634740049434371

Epoch: 5| Step: 4
Training loss: 3.0211840371193905
Validation loss: 2.6424895740576204

Epoch: 5| Step: 5
Training loss: 3.027350995455039
Validation loss: 2.6551936423931766

Epoch: 5| Step: 6
Training loss: 2.9862505227204634
Validation loss: 2.649652306347191

Epoch: 5| Step: 7
Training loss: 2.964219179572161
Validation loss: 2.6540459683586572

Epoch: 5| Step: 8
Training loss: 2.6977197484404285
Validation loss: 2.64778134547966

Epoch: 5| Step: 9
Training loss: 3.582391186250899
Validation loss: 2.655080868312672

Epoch: 5| Step: 10
Training loss: 1.867639718299706
Validation loss: 2.6635981358240994

Epoch: 353| Step: 0
Training loss: 3.175337531703769
Validation loss: 2.6755237910278042

Epoch: 5| Step: 1
Training loss: 2.169308360226657
Validation loss: 2.6715699229001997

Epoch: 5| Step: 2
Training loss: 2.5989851915173197
Validation loss: 2.6820253021105556

Epoch: 5| Step: 3
Training loss: 3.34312818217915
Validation loss: 2.693412717352723

Epoch: 5| Step: 4
Training loss: 3.230783431053394
Validation loss: 2.6968873889470135

Epoch: 5| Step: 5
Training loss: 2.409349501260885
Validation loss: 2.68570256299696

Epoch: 5| Step: 6
Training loss: 3.5831967852694517
Validation loss: 2.667506580466337

Epoch: 5| Step: 7
Training loss: 2.117807445342781
Validation loss: 2.6644094210785267

Epoch: 5| Step: 8
Training loss: 2.853799689616815
Validation loss: 2.644281155052911

Epoch: 5| Step: 9
Training loss: 3.05355806276078
Validation loss: 2.6397823672023772

Epoch: 5| Step: 10
Training loss: 3.354865307442178
Validation loss: 2.630061463103722

Epoch: 354| Step: 0
Training loss: 2.72275668907167
Validation loss: 2.6230076398798237

Epoch: 5| Step: 1
Training loss: 2.882861790843005
Validation loss: 2.632349196927375

Epoch: 5| Step: 2
Training loss: 2.986351437225065
Validation loss: 2.6398313324366525

Epoch: 5| Step: 3
Training loss: 2.5379795993018086
Validation loss: 2.639606315017485

Epoch: 5| Step: 4
Training loss: 2.6896011655311396
Validation loss: 2.6487206438883

Epoch: 5| Step: 5
Training loss: 3.1424743369669854
Validation loss: 2.6382834497919276

Epoch: 5| Step: 6
Training loss: 2.940903173539594
Validation loss: 2.640055251834488

Epoch: 5| Step: 7
Training loss: 3.036657327943994
Validation loss: 2.6417956159438134

Epoch: 5| Step: 8
Training loss: 3.212845803733714
Validation loss: 2.632933521748208

Epoch: 5| Step: 9
Training loss: 2.744561626679941
Validation loss: 2.634666194642198

Epoch: 5| Step: 10
Training loss: 3.1886889166460115
Validation loss: 2.620526848019715

Epoch: 355| Step: 0
Training loss: 2.7665081446017736
Validation loss: 2.636770130843341

Epoch: 5| Step: 1
Training loss: 2.7241222752870935
Validation loss: 2.643464223845615

Epoch: 5| Step: 2
Training loss: 3.148625294880068
Validation loss: 2.642291160899013

Epoch: 5| Step: 3
Training loss: 2.6259398821350426
Validation loss: 2.649434526732894

Epoch: 5| Step: 4
Training loss: 3.256389206383682
Validation loss: 2.6547064304609354

Epoch: 5| Step: 5
Training loss: 2.596156187681354
Validation loss: 2.648950758698547

Epoch: 5| Step: 6
Training loss: 2.684793484522583
Validation loss: 2.654190915772679

Epoch: 5| Step: 7
Training loss: 3.267766952759016
Validation loss: 2.6718752350753414

Epoch: 5| Step: 8
Training loss: 3.151362345537805
Validation loss: 2.668750841267848

Epoch: 5| Step: 9
Training loss: 3.107742724587111
Validation loss: 2.6570454708698765

Epoch: 5| Step: 10
Training loss: 2.519034024640668
Validation loss: 2.6623688630038522

Epoch: 356| Step: 0
Training loss: 2.716289766374285
Validation loss: 2.6883249449980657

Epoch: 5| Step: 1
Training loss: 2.6780646834820057
Validation loss: 2.6996863911496503

Epoch: 5| Step: 2
Training loss: 2.944103205198712
Validation loss: 2.728642220179772

Epoch: 5| Step: 3
Training loss: 3.7082912285518237
Validation loss: 2.69530323199961

Epoch: 5| Step: 4
Training loss: 2.469421198902016
Validation loss: 2.6787722487791816

Epoch: 5| Step: 5
Training loss: 2.755655195971011
Validation loss: 2.6710146670442403

Epoch: 5| Step: 6
Training loss: 3.1116603714631172
Validation loss: 2.6448063005678737

Epoch: 5| Step: 7
Training loss: 2.4834376072166555
Validation loss: 2.639489265744002

Epoch: 5| Step: 8
Training loss: 3.455367244960568
Validation loss: 2.6335455579068685

Epoch: 5| Step: 9
Training loss: 2.5677497865581898
Validation loss: 2.63748385505068

Epoch: 5| Step: 10
Training loss: 3.0048501227097386
Validation loss: 2.6423195362092575

Epoch: 357| Step: 0
Training loss: 2.6221379617669913
Validation loss: 2.6441824528761555

Epoch: 5| Step: 1
Training loss: 2.879832808356998
Validation loss: 2.6727684516688983

Epoch: 5| Step: 2
Training loss: 3.157888912312674
Validation loss: 2.68894174245829

Epoch: 5| Step: 3
Training loss: 3.014646223071749
Validation loss: 2.703865340152343

Epoch: 5| Step: 4
Training loss: 3.3638831828333493
Validation loss: 2.716653132397082

Epoch: 5| Step: 5
Training loss: 2.6233636206106854
Validation loss: 2.746548421893379

Epoch: 5| Step: 6
Training loss: 2.702488995299399
Validation loss: 2.7515624148795594

Epoch: 5| Step: 7
Training loss: 2.1077431477193356
Validation loss: 2.7417529067672635

Epoch: 5| Step: 8
Training loss: 3.1490614204219396
Validation loss: 2.7400598762289743

Epoch: 5| Step: 9
Training loss: 3.058995012292353
Validation loss: 2.705770032694628

Epoch: 5| Step: 10
Training loss: 3.238071706363112
Validation loss: 2.6849060790440746

Epoch: 358| Step: 0
Training loss: 2.6187378803418833
Validation loss: 2.6763468018423437

Epoch: 5| Step: 1
Training loss: 2.9852689832073103
Validation loss: 2.6600866040748468

Epoch: 5| Step: 2
Training loss: 3.5118144768046373
Validation loss: 2.64486168449709

Epoch: 5| Step: 3
Training loss: 2.7913684021385494
Validation loss: 2.636371339602266

Epoch: 5| Step: 4
Training loss: 3.0396370234376553
Validation loss: 2.6260837499542444

Epoch: 5| Step: 5
Training loss: 3.0129999782639487
Validation loss: 2.6173430307060603

Epoch: 5| Step: 6
Training loss: 2.6333579565257104
Validation loss: 2.6119094525415063

Epoch: 5| Step: 7
Training loss: 2.2426201273405577
Validation loss: 2.6248378781728325

Epoch: 5| Step: 8
Training loss: 2.8705928028110814
Validation loss: 2.6283944747811847

Epoch: 5| Step: 9
Training loss: 3.3752263311154236
Validation loss: 2.643967210115346

Epoch: 5| Step: 10
Training loss: 2.8486595950275078
Validation loss: 2.66839176536455

Epoch: 359| Step: 0
Training loss: 2.971067467692884
Validation loss: 2.6940775768007468

Epoch: 5| Step: 1
Training loss: 2.7694249314318276
Validation loss: 2.7098768125671056

Epoch: 5| Step: 2
Training loss: 2.767000276682033
Validation loss: 2.7719394953288696

Epoch: 5| Step: 3
Training loss: 2.7429383382955677
Validation loss: 2.7875439140502345

Epoch: 5| Step: 4
Training loss: 2.848499565682923
Validation loss: 2.7779163680488677

Epoch: 5| Step: 5
Training loss: 3.1963248666074398
Validation loss: 2.777959289226256

Epoch: 5| Step: 6
Training loss: 2.8246849593319814
Validation loss: 2.70278645352144

Epoch: 5| Step: 7
Training loss: 3.460092411240447
Validation loss: 2.6695700255319106

Epoch: 5| Step: 8
Training loss: 2.8458241035754845
Validation loss: 2.6273555587800734

Epoch: 5| Step: 9
Training loss: 2.9434552800400593
Validation loss: 2.6031072099744974

Epoch: 5| Step: 10
Training loss: 2.75485009867363
Validation loss: 2.601095329903752

Epoch: 360| Step: 0
Training loss: 3.2813055124582453
Validation loss: 2.6004325030922173

Epoch: 5| Step: 1
Training loss: 3.3775454211904523
Validation loss: 2.602038991366656

Epoch: 5| Step: 2
Training loss: 2.8333972661902176
Validation loss: 2.601897768717808

Epoch: 5| Step: 3
Training loss: 2.7386023405271924
Validation loss: 2.6036900854968774

Epoch: 5| Step: 4
Training loss: 3.3015784390051692
Validation loss: 2.6057155965906023

Epoch: 5| Step: 5
Training loss: 2.8238221202622387
Validation loss: 2.602770437380103

Epoch: 5| Step: 6
Training loss: 2.7104698459374315
Validation loss: 2.6082328333818454

Epoch: 5| Step: 7
Training loss: 2.8392209048213406
Validation loss: 2.6070671110273516

Epoch: 5| Step: 8
Training loss: 3.4172546687107173
Validation loss: 2.6079641498085495

Epoch: 5| Step: 9
Training loss: 2.490676469641977
Validation loss: 2.6104599454133095

Epoch: 5| Step: 10
Training loss: 2.6814242148543608
Validation loss: 2.603999911640072

Epoch: 361| Step: 0
Training loss: 3.068200391976493
Validation loss: 2.603618434829483

Epoch: 5| Step: 1
Training loss: 3.308118405475166
Validation loss: 2.604906516692832

Epoch: 5| Step: 2
Training loss: 2.6834268976172906
Validation loss: 2.601075673014808

Epoch: 5| Step: 3
Training loss: 2.537594226910445
Validation loss: 2.6137069575396623

Epoch: 5| Step: 4
Training loss: 2.2185520567375896
Validation loss: 2.6271705999449133

Epoch: 5| Step: 5
Training loss: 3.1832627200405255
Validation loss: 2.6441172379034237

Epoch: 5| Step: 6
Training loss: 3.1409155867782568
Validation loss: 2.641658270372788

Epoch: 5| Step: 7
Training loss: 2.230617431388364
Validation loss: 2.652231497528249

Epoch: 5| Step: 8
Training loss: 2.880098217772886
Validation loss: 2.675738712359204

Epoch: 5| Step: 9
Training loss: 3.659784939393612
Validation loss: 2.683042072701706

Epoch: 5| Step: 10
Training loss: 3.20294605778753
Validation loss: 2.662969618934629

Epoch: 362| Step: 0
Training loss: 3.023530549581553
Validation loss: 2.6358617344927002

Epoch: 5| Step: 1
Training loss: 2.9256321215853593
Validation loss: 2.6138994686874533

Epoch: 5| Step: 2
Training loss: 3.20275772594282
Validation loss: 2.5988261285615257

Epoch: 5| Step: 3
Training loss: 2.9424369394291343
Validation loss: 2.5996195127440007

Epoch: 5| Step: 4
Training loss: 3.295148930982628
Validation loss: 2.6001698274025986

Epoch: 5| Step: 5
Training loss: 2.949997795233468
Validation loss: 2.595388538118212

Epoch: 5| Step: 6
Training loss: 2.6470036859317334
Validation loss: 2.5956834213504174

Epoch: 5| Step: 7
Training loss: 2.6234764037164378
Validation loss: 2.5964100641070718

Epoch: 5| Step: 8
Training loss: 2.907874524963154
Validation loss: 2.599214463326717

Epoch: 5| Step: 9
Training loss: 2.874789852257224
Validation loss: 2.6024259069258395

Epoch: 5| Step: 10
Training loss: 2.9081665610633802
Validation loss: 2.623767409089719

Epoch: 363| Step: 0
Training loss: 2.4044604892669375
Validation loss: 2.6325034686240425

Epoch: 5| Step: 1
Training loss: 3.4196883230235375
Validation loss: 2.6414151476429737

Epoch: 5| Step: 2
Training loss: 2.846570638723922
Validation loss: 2.657854318358211

Epoch: 5| Step: 3
Training loss: 3.2872580609661917
Validation loss: 2.662832577963128

Epoch: 5| Step: 4
Training loss: 2.732773229928638
Validation loss: 2.669037575042908

Epoch: 5| Step: 5
Training loss: 2.7931083164156423
Validation loss: 2.681623133064185

Epoch: 5| Step: 6
Training loss: 2.2724477179863665
Validation loss: 2.6975474137974373

Epoch: 5| Step: 7
Training loss: 2.9261348902807205
Validation loss: 2.7225208207299314

Epoch: 5| Step: 8
Training loss: 3.023461945506391
Validation loss: 2.7201924649370706

Epoch: 5| Step: 9
Training loss: 3.245839463612975
Validation loss: 2.688032621664875

Epoch: 5| Step: 10
Training loss: 2.959979141264957
Validation loss: 2.656430950914144

Epoch: 364| Step: 0
Training loss: 3.1569556023536243
Validation loss: 2.637005758582345

Epoch: 5| Step: 1
Training loss: 2.948562892719811
Validation loss: 2.627720575914656

Epoch: 5| Step: 2
Training loss: 2.865936089356133
Validation loss: 2.6255052512927732

Epoch: 5| Step: 3
Training loss: 2.5855554027563703
Validation loss: 2.6226754099029006

Epoch: 5| Step: 4
Training loss: 2.653602447504497
Validation loss: 2.6148420907787777

Epoch: 5| Step: 5
Training loss: 2.9433898316689
Validation loss: 2.6213168836955507

Epoch: 5| Step: 6
Training loss: 3.4182374336359316
Validation loss: 2.6218005310768167

Epoch: 5| Step: 7
Training loss: 3.1299896079186444
Validation loss: 2.6351455678093654

Epoch: 5| Step: 8
Training loss: 2.8860455503616373
Validation loss: 2.6399529802119517

Epoch: 5| Step: 9
Training loss: 2.5847981412127043
Validation loss: 2.638667582623351

Epoch: 5| Step: 10
Training loss: 2.7809354625676868
Validation loss: 2.6379339869145713

Epoch: 365| Step: 0
Training loss: 2.716396848077003
Validation loss: 2.628809386147078

Epoch: 5| Step: 1
Training loss: 3.0404848040950814
Validation loss: 2.6340563235538967

Epoch: 5| Step: 2
Training loss: 3.236619106326989
Validation loss: 2.637841701646267

Epoch: 5| Step: 3
Training loss: 2.627554059692947
Validation loss: 2.633793695717924

Epoch: 5| Step: 4
Training loss: 3.599095887988746
Validation loss: 2.625095067839511

Epoch: 5| Step: 5
Training loss: 2.421714925090433
Validation loss: 2.633670945784898

Epoch: 5| Step: 6
Training loss: 2.633046035143946
Validation loss: 2.6318797263018614

Epoch: 5| Step: 7
Training loss: 3.320528198416555
Validation loss: 2.6379414156226138

Epoch: 5| Step: 8
Training loss: 2.722329512793557
Validation loss: 2.627965082642881

Epoch: 5| Step: 9
Training loss: 2.835003659684983
Validation loss: 2.6225108989354315

Epoch: 5| Step: 10
Training loss: 2.6586310990204547
Validation loss: 2.627901550933259

Epoch: 366| Step: 0
Training loss: 3.0429673396879755
Validation loss: 2.6436348979183397

Epoch: 5| Step: 1
Training loss: 3.348307845488766
Validation loss: 2.668369657599189

Epoch: 5| Step: 2
Training loss: 2.691346188610042
Validation loss: 2.6975942347676423

Epoch: 5| Step: 3
Training loss: 3.2774112589888493
Validation loss: 2.6995101450162573

Epoch: 5| Step: 4
Training loss: 2.6473682687062237
Validation loss: 2.72361215840173

Epoch: 5| Step: 5
Training loss: 2.8725185466064698
Validation loss: 2.707589743286813

Epoch: 5| Step: 6
Training loss: 2.656455895914878
Validation loss: 2.6913898874190245

Epoch: 5| Step: 7
Training loss: 2.8746327704706
Validation loss: 2.672743293467613

Epoch: 5| Step: 8
Training loss: 3.1420890470205864
Validation loss: 2.6468817064899346

Epoch: 5| Step: 9
Training loss: 2.6401132843969903
Validation loss: 2.6407395660989574

Epoch: 5| Step: 10
Training loss: 2.5098974764733373
Validation loss: 2.624277156954586

Epoch: 367| Step: 0
Training loss: 2.95590982879292
Validation loss: 2.627760113344831

Epoch: 5| Step: 1
Training loss: 3.530789505631999
Validation loss: 2.615246638172075

Epoch: 5| Step: 2
Training loss: 3.1697545974039807
Validation loss: 2.606052182876423

Epoch: 5| Step: 3
Training loss: 2.942006165218571
Validation loss: 2.602895640303917

Epoch: 5| Step: 4
Training loss: 2.4558913068483847
Validation loss: 2.601810077826618

Epoch: 5| Step: 5
Training loss: 3.342575294713655
Validation loss: 2.6059636731084366

Epoch: 5| Step: 6
Training loss: 2.9907124122911295
Validation loss: 2.6135543169717534

Epoch: 5| Step: 7
Training loss: 2.9852453430665933
Validation loss: 2.6140104838888343

Epoch: 5| Step: 8
Training loss: 2.153455941909167
Validation loss: 2.620132087218525

Epoch: 5| Step: 9
Training loss: 2.719397018438165
Validation loss: 2.6297796364017247

Epoch: 5| Step: 10
Training loss: 2.461394930515476
Validation loss: 2.643870832116409

Epoch: 368| Step: 0
Training loss: 2.7193726451445377
Validation loss: 2.6622784493258336

Epoch: 5| Step: 1
Training loss: 2.769979723088384
Validation loss: 2.7161011144991973

Epoch: 5| Step: 2
Training loss: 2.940235406442874
Validation loss: 2.7273930022491357

Epoch: 5| Step: 3
Training loss: 3.0953759438696165
Validation loss: 2.7512672241612237

Epoch: 5| Step: 4
Training loss: 3.246232122784062
Validation loss: 2.754662773501517

Epoch: 5| Step: 5
Training loss: 2.7116342138479324
Validation loss: 2.8083323948794305

Epoch: 5| Step: 6
Training loss: 2.818996301957784
Validation loss: 2.779305255969987

Epoch: 5| Step: 7
Training loss: 2.8897670813025202
Validation loss: 2.708442752669257

Epoch: 5| Step: 8
Training loss: 2.780895853533437
Validation loss: 2.6880800003373264

Epoch: 5| Step: 9
Training loss: 3.1881805890099213
Validation loss: 2.6415151673417316

Epoch: 5| Step: 10
Training loss: 2.929086852489818
Validation loss: 2.6317587759111176

Epoch: 369| Step: 0
Training loss: 2.9573276225116008
Validation loss: 2.619369705426645

Epoch: 5| Step: 1
Training loss: 2.9314317724156784
Validation loss: 2.6144442369104524

Epoch: 5| Step: 2
Training loss: 3.204415559134389
Validation loss: 2.619433963757437

Epoch: 5| Step: 3
Training loss: 2.83415733771811
Validation loss: 2.6224421868864654

Epoch: 5| Step: 4
Training loss: 2.6831399903233
Validation loss: 2.6207782041992034

Epoch: 5| Step: 5
Training loss: 2.9677120602817415
Validation loss: 2.621433959084773

Epoch: 5| Step: 6
Training loss: 2.8600196320186733
Validation loss: 2.6216038123775043

Epoch: 5| Step: 7
Training loss: 3.4150096007361554
Validation loss: 2.6202540703407533

Epoch: 5| Step: 8
Training loss: 2.533691735597517
Validation loss: 2.621693941010745

Epoch: 5| Step: 9
Training loss: 2.8511927534792654
Validation loss: 2.617590862224651

Epoch: 5| Step: 10
Training loss: 2.7867000201691763
Validation loss: 2.618319691855989

Epoch: 370| Step: 0
Training loss: 2.6358688227961515
Validation loss: 2.618472339538694

Epoch: 5| Step: 1
Training loss: 2.985385903312873
Validation loss: 2.6209484403797187

Epoch: 5| Step: 2
Training loss: 3.2543522962961773
Validation loss: 2.6106340292409596

Epoch: 5| Step: 3
Training loss: 2.725630811419608
Validation loss: 2.624089768316612

Epoch: 5| Step: 4
Training loss: 2.8237927380654675
Validation loss: 2.6197959012471306

Epoch: 5| Step: 5
Training loss: 2.6147240731303136
Validation loss: 2.627307918358976

Epoch: 5| Step: 6
Training loss: 2.893734800492446
Validation loss: 2.63501265749176

Epoch: 5| Step: 7
Training loss: 3.235878120588554
Validation loss: 2.6406798134051694

Epoch: 5| Step: 8
Training loss: 3.1848812939906446
Validation loss: 2.6461562522489572

Epoch: 5| Step: 9
Training loss: 2.765290062229527
Validation loss: 2.6475225367235597

Epoch: 5| Step: 10
Training loss: 2.6921531847750027
Validation loss: 2.6481482201133444

Epoch: 371| Step: 0
Training loss: 2.808278115141886
Validation loss: 2.6568773150207856

Epoch: 5| Step: 1
Training loss: 3.0596814322603825
Validation loss: 2.641605161064271

Epoch: 5| Step: 2
Training loss: 3.715178882712675
Validation loss: 2.640013569911637

Epoch: 5| Step: 3
Training loss: 3.296385380695644
Validation loss: 2.619012783441064

Epoch: 5| Step: 4
Training loss: 2.407615373328695
Validation loss: 2.624824283654593

Epoch: 5| Step: 5
Training loss: 2.6457503198131263
Validation loss: 2.627956313651134

Epoch: 5| Step: 6
Training loss: 2.822916366370679
Validation loss: 2.632208810600973

Epoch: 5| Step: 7
Training loss: 2.4257889162393957
Validation loss: 2.6525544046016547

Epoch: 5| Step: 8
Training loss: 2.3956861588981213
Validation loss: 2.6684665322757364

Epoch: 5| Step: 9
Training loss: 2.9583816166192594
Validation loss: 2.678890174108825

Epoch: 5| Step: 10
Training loss: 3.046490610769038
Validation loss: 2.706777625296683

Epoch: 372| Step: 0
Training loss: 3.1584359332675507
Validation loss: 2.7015516548762504

Epoch: 5| Step: 1
Training loss: 2.6741471472963236
Validation loss: 2.702004001013344

Epoch: 5| Step: 2
Training loss: 2.9032521526959707
Validation loss: 2.662914395969306

Epoch: 5| Step: 3
Training loss: 3.13085709046431
Validation loss: 2.6448321936539023

Epoch: 5| Step: 4
Training loss: 3.0248777128360587
Validation loss: 2.6455075140312685

Epoch: 5| Step: 5
Training loss: 2.8511047832028633
Validation loss: 2.650590944639101

Epoch: 5| Step: 6
Training loss: 3.1362574940086767
Validation loss: 2.662565002002266

Epoch: 5| Step: 7
Training loss: 2.576464493959747
Validation loss: 2.668986584855266

Epoch: 5| Step: 8
Training loss: 2.832880058682309
Validation loss: 2.668586062943954

Epoch: 5| Step: 9
Training loss: 2.659324661657055
Validation loss: 2.6738113259812977

Epoch: 5| Step: 10
Training loss: 3.08812595462379
Validation loss: 2.6549581340738495

Epoch: 373| Step: 0
Training loss: 2.71492972477962
Validation loss: 2.6584889964040648

Epoch: 5| Step: 1
Training loss: 2.602412546027801
Validation loss: 2.6413150785388835

Epoch: 5| Step: 2
Training loss: 3.1282994971446465
Validation loss: 2.6316292580408276

Epoch: 5| Step: 3
Training loss: 3.125013122531042
Validation loss: 2.6270616866286676

Epoch: 5| Step: 4
Training loss: 3.036680096772104
Validation loss: 2.6245036508026467

Epoch: 5| Step: 5
Training loss: 2.700071782464801
Validation loss: 2.6233093425075222

Epoch: 5| Step: 6
Training loss: 3.020158433610947
Validation loss: 2.6290028089664026

Epoch: 5| Step: 7
Training loss: 2.9874954287442144
Validation loss: 2.642473184104889

Epoch: 5| Step: 8
Training loss: 3.15275712830386
Validation loss: 2.6515456745456163

Epoch: 5| Step: 9
Training loss: 2.405501013772038
Validation loss: 2.6513900838941367

Epoch: 5| Step: 10
Training loss: 2.9295190381253318
Validation loss: 2.658210735275944

Epoch: 374| Step: 0
Training loss: 2.576276544233352
Validation loss: 2.6647031525744773

Epoch: 5| Step: 1
Training loss: 2.989769020472379
Validation loss: 2.6593135744465175

Epoch: 5| Step: 2
Training loss: 2.9061243173638722
Validation loss: 2.670261805896266

Epoch: 5| Step: 3
Training loss: 3.3800449106517005
Validation loss: 2.6768408693819383

Epoch: 5| Step: 4
Training loss: 2.5302131318797665
Validation loss: 2.6936138110559944

Epoch: 5| Step: 5
Training loss: 3.1367950620192575
Validation loss: 2.690346723288693

Epoch: 5| Step: 6
Training loss: 3.187085741836556
Validation loss: 2.6565022705270014

Epoch: 5| Step: 7
Training loss: 2.7414868103522676
Validation loss: 2.6355839529125453

Epoch: 5| Step: 8
Training loss: 2.5184028405174708
Validation loss: 2.6230135402366788

Epoch: 5| Step: 9
Training loss: 2.7342224078516626
Validation loss: 2.6114097699830485

Epoch: 5| Step: 10
Training loss: 3.1232717694295085
Validation loss: 2.604380887644498

Epoch: 375| Step: 0
Training loss: 3.2390524540629007
Validation loss: 2.600237081223979

Epoch: 5| Step: 1
Training loss: 3.184558333789952
Validation loss: 2.598625656169684

Epoch: 5| Step: 2
Training loss: 2.484611931785043
Validation loss: 2.6084050126972507

Epoch: 5| Step: 3
Training loss: 2.5299053623758585
Validation loss: 2.6282999213205955

Epoch: 5| Step: 4
Training loss: 1.7003979329382215
Validation loss: 2.6323888810396965

Epoch: 5| Step: 5
Training loss: 2.5727853677172225
Validation loss: 2.663482243883435

Epoch: 5| Step: 6
Training loss: 2.8731708512828855
Validation loss: 2.689530948571582

Epoch: 5| Step: 7
Training loss: 3.183356789973519
Validation loss: 2.7099665870448715

Epoch: 5| Step: 8
Training loss: 3.3157453653561606
Validation loss: 2.705233380752023

Epoch: 5| Step: 9
Training loss: 3.2783142035242454
Validation loss: 2.677937798646098

Epoch: 5| Step: 10
Training loss: 3.0720494140286685
Validation loss: 2.6635723221797316

Epoch: 376| Step: 0
Training loss: 2.91514407788226
Validation loss: 2.6575733283305403

Epoch: 5| Step: 1
Training loss: 2.2627700180872643
Validation loss: 2.628298533327712

Epoch: 5| Step: 2
Training loss: 2.620291255894381
Validation loss: 2.632892180822682

Epoch: 5| Step: 3
Training loss: 3.1913151068495345
Validation loss: 2.6324123768530967

Epoch: 5| Step: 4
Training loss: 2.6915600293966513
Validation loss: 2.649059312559621

Epoch: 5| Step: 5
Training loss: 2.5711105638230705
Validation loss: 2.665931857746057

Epoch: 5| Step: 6
Training loss: 3.529602071362369
Validation loss: 2.686345307599194

Epoch: 5| Step: 7
Training loss: 2.438894997514023
Validation loss: 2.6876024749900016

Epoch: 5| Step: 8
Training loss: 2.9306614591999436
Validation loss: 2.7237662447613746

Epoch: 5| Step: 9
Training loss: 2.9342721289334674
Validation loss: 2.7043844515074653

Epoch: 5| Step: 10
Training loss: 3.4840469548053705
Validation loss: 2.7029440527211124

Epoch: 377| Step: 0
Training loss: 2.9551975304279843
Validation loss: 2.6936077217675973

Epoch: 5| Step: 1
Training loss: 2.761575266174114
Validation loss: 2.6851757393766977

Epoch: 5| Step: 2
Training loss: 2.799535583400763
Validation loss: 2.64944043016396

Epoch: 5| Step: 3
Training loss: 2.609174161023229
Validation loss: 2.6287724566435577

Epoch: 5| Step: 4
Training loss: 3.0385514248828693
Validation loss: 2.6428796955530074

Epoch: 5| Step: 5
Training loss: 3.3848232433876144
Validation loss: 2.6363904027094094

Epoch: 5| Step: 6
Training loss: 2.7066817505264287
Validation loss: 2.629515565528242

Epoch: 5| Step: 7
Training loss: 2.669565820288715
Validation loss: 2.6226116200436853

Epoch: 5| Step: 8
Training loss: 2.6598837736737906
Validation loss: 2.6296228631783216

Epoch: 5| Step: 9
Training loss: 3.1741571343892137
Validation loss: 2.6474526717423013

Epoch: 5| Step: 10
Training loss: 2.865257507522076
Validation loss: 2.652810234969809

Epoch: 378| Step: 0
Training loss: 2.740841701035114
Validation loss: 2.6561253633640467

Epoch: 5| Step: 1
Training loss: 2.5881550203971426
Validation loss: 2.6663360608674713

Epoch: 5| Step: 2
Training loss: 3.4164132900414117
Validation loss: 2.6712208165114717

Epoch: 5| Step: 3
Training loss: 2.6735770175185745
Validation loss: 2.65951191005429

Epoch: 5| Step: 4
Training loss: 2.943880658985786
Validation loss: 2.6597604735895395

Epoch: 5| Step: 5
Training loss: 3.1404622353656495
Validation loss: 2.649946672294222

Epoch: 5| Step: 6
Training loss: 2.767546939606851
Validation loss: 2.6483793236245186

Epoch: 5| Step: 7
Training loss: 3.063986281361757
Validation loss: 2.6617307797840355

Epoch: 5| Step: 8
Training loss: 2.5581136238447266
Validation loss: 2.6790269070747117

Epoch: 5| Step: 9
Training loss: 3.253531957670765
Validation loss: 2.6933478244263527

Epoch: 5| Step: 10
Training loss: 2.3680280445796607
Validation loss: 2.70609795742606

Epoch: 379| Step: 0
Training loss: 2.758586569587396
Validation loss: 2.706765117613696

Epoch: 5| Step: 1
Training loss: 3.186230874316587
Validation loss: 2.6913343407725008

Epoch: 5| Step: 2
Training loss: 2.755145201413454
Validation loss: 2.6663097554849045

Epoch: 5| Step: 3
Training loss: 2.6318152828503054
Validation loss: 2.638061309977842

Epoch: 5| Step: 4
Training loss: 3.213876831448232
Validation loss: 2.6360794363053044

Epoch: 5| Step: 5
Training loss: 2.698763818674546
Validation loss: 2.626959369769567

Epoch: 5| Step: 6
Training loss: 2.359356709592546
Validation loss: 2.6344071454999898

Epoch: 5| Step: 7
Training loss: 2.85840043933565
Validation loss: 2.6499234006386385

Epoch: 5| Step: 8
Training loss: 3.2450027193078634
Validation loss: 2.6392892079083916

Epoch: 5| Step: 9
Training loss: 3.157146666412916
Validation loss: 2.6513326665576544

Epoch: 5| Step: 10
Training loss: 2.6785105798258506
Validation loss: 2.6627797552271466

Epoch: 380| Step: 0
Training loss: 3.085228792730162
Validation loss: 2.6580793765988036

Epoch: 5| Step: 1
Training loss: 2.633039425089322
Validation loss: 2.654888648234542

Epoch: 5| Step: 2
Training loss: 3.0674498124746528
Validation loss: 2.6342153525610836

Epoch: 5| Step: 3
Training loss: 2.98144371315057
Validation loss: 2.6073278568946447

Epoch: 5| Step: 4
Training loss: 2.915096150770555
Validation loss: 2.6075105982700073

Epoch: 5| Step: 5
Training loss: 3.1911579161528807
Validation loss: 2.5954164157326858

Epoch: 5| Step: 6
Training loss: 2.7275878377419227
Validation loss: 2.59774731015296

Epoch: 5| Step: 7
Training loss: 2.3655209355916536
Validation loss: 2.5965478531324973

Epoch: 5| Step: 8
Training loss: 2.740902765480402
Validation loss: 2.6030972650546382

Epoch: 5| Step: 9
Training loss: 3.3113208327416164
Validation loss: 2.616063300705535

Epoch: 5| Step: 10
Training loss: 2.6132140101063226
Validation loss: 2.644688311425876

Epoch: 381| Step: 0
Training loss: 2.804595945771309
Validation loss: 2.669585961029136

Epoch: 5| Step: 1
Training loss: 2.6217580485034424
Validation loss: 2.673813561893535

Epoch: 5| Step: 2
Training loss: 2.8592370839028605
Validation loss: 2.6711917932734255

Epoch: 5| Step: 3
Training loss: 2.636060121009832
Validation loss: 2.694022410067047

Epoch: 5| Step: 4
Training loss: 2.9048793390792285
Validation loss: 2.692908655524823

Epoch: 5| Step: 5
Training loss: 2.9905827853134226
Validation loss: 2.7164050946842266

Epoch: 5| Step: 6
Training loss: 2.3760153958948877
Validation loss: 2.7000583996338174

Epoch: 5| Step: 7
Training loss: 2.638842008966227
Validation loss: 2.7046483082021595

Epoch: 5| Step: 8
Training loss: 3.2912145537522415
Validation loss: 2.716291970151853

Epoch: 5| Step: 9
Training loss: 3.4887403845987697
Validation loss: 2.69914538201543

Epoch: 5| Step: 10
Training loss: 2.8373258360797142
Validation loss: 2.6716994524337174

Epoch: 382| Step: 0
Training loss: 3.0722220115209335
Validation loss: 2.672138730015006

Epoch: 5| Step: 1
Training loss: 2.7289608788011863
Validation loss: 2.6712828592113826

Epoch: 5| Step: 2
Training loss: 3.2276443995197144
Validation loss: 2.670403598842023

Epoch: 5| Step: 3
Training loss: 2.7494758626652214
Validation loss: 2.6379583478286053

Epoch: 5| Step: 4
Training loss: 3.1526471716389026
Validation loss: 2.630882066916788

Epoch: 5| Step: 5
Training loss: 2.108954493676069
Validation loss: 2.61497276460905

Epoch: 5| Step: 6
Training loss: 2.864870554078487
Validation loss: 2.618600366082325

Epoch: 5| Step: 7
Training loss: 2.9676283474220373
Validation loss: 2.6191993754445497

Epoch: 5| Step: 8
Training loss: 3.0392310088445185
Validation loss: 2.631750806648894

Epoch: 5| Step: 9
Training loss: 3.234429990144325
Validation loss: 2.6443564655206244

Epoch: 5| Step: 10
Training loss: 2.202517486572128
Validation loss: 2.663354253312385

Epoch: 383| Step: 0
Training loss: 2.52203509686437
Validation loss: 2.697622750618299

Epoch: 5| Step: 1
Training loss: 2.5533753738063165
Validation loss: 2.699335945441263

Epoch: 5| Step: 2
Training loss: 2.53698185107604
Validation loss: 2.7411838757841056

Epoch: 5| Step: 3
Training loss: 3.383670830140421
Validation loss: 2.736797704030195

Epoch: 5| Step: 4
Training loss: 2.6751422202548576
Validation loss: 2.716566750688165

Epoch: 5| Step: 5
Training loss: 2.5490994714579034
Validation loss: 2.6512121646213926

Epoch: 5| Step: 6
Training loss: 3.642786653087791
Validation loss: 2.6390353686947456

Epoch: 5| Step: 7
Training loss: 2.6596939200502097
Validation loss: 2.621331601534457

Epoch: 5| Step: 8
Training loss: 3.226365792325959
Validation loss: 2.6175826030211606

Epoch: 5| Step: 9
Training loss: 2.995239135926258
Validation loss: 2.622532293550076

Epoch: 5| Step: 10
Training loss: 2.4629259583421574
Validation loss: 2.6179590093629557

Epoch: 384| Step: 0
Training loss: 3.192348756605592
Validation loss: 2.6232369728881317

Epoch: 5| Step: 1
Training loss: 3.1851311651556213
Validation loss: 2.63026800844344

Epoch: 5| Step: 2
Training loss: 3.0390639121241096
Validation loss: 2.6473409168622557

Epoch: 5| Step: 3
Training loss: 2.9475440518854295
Validation loss: 2.6742050228975858

Epoch: 5| Step: 4
Training loss: 3.304200337171471
Validation loss: 2.6669389280671454

Epoch: 5| Step: 5
Training loss: 2.1179519905938493
Validation loss: 2.6856031456027427

Epoch: 5| Step: 6
Training loss: 2.468660666865469
Validation loss: 2.675451228783605

Epoch: 5| Step: 7
Training loss: 3.1129294164334627
Validation loss: 2.6680173074791536

Epoch: 5| Step: 8
Training loss: 2.6715981858730653
Validation loss: 2.6851996602430592

Epoch: 5| Step: 9
Training loss: 2.409084384673822
Validation loss: 2.7020903947629313

Epoch: 5| Step: 10
Training loss: 2.7373770664429737
Validation loss: 2.702783405932536

Epoch: 385| Step: 0
Training loss: 3.0901445129082132
Validation loss: 2.709473214021268

Epoch: 5| Step: 1
Training loss: 2.4902490233944166
Validation loss: 2.6904768896078015

Epoch: 5| Step: 2
Training loss: 2.829807013142136
Validation loss: 2.6891192084461593

Epoch: 5| Step: 3
Training loss: 3.3582554570737795
Validation loss: 2.6638002580209763

Epoch: 5| Step: 4
Training loss: 2.768029498521918
Validation loss: 2.644351111582936

Epoch: 5| Step: 5
Training loss: 2.7130389684514187
Validation loss: 2.6193098175842384

Epoch: 5| Step: 6
Training loss: 2.8967638967662515
Validation loss: 2.6162214175730276

Epoch: 5| Step: 7
Training loss: 2.8518725082985155
Validation loss: 2.6058240188509867

Epoch: 5| Step: 8
Training loss: 2.590861907176472
Validation loss: 2.5936495675881224

Epoch: 5| Step: 9
Training loss: 3.2186421496646154
Validation loss: 2.596580124687587

Epoch: 5| Step: 10
Training loss: 2.836854896650669
Validation loss: 2.5909800549364075

Epoch: 386| Step: 0
Training loss: 2.7037788438250487
Validation loss: 2.588694603440069

Epoch: 5| Step: 1
Training loss: 2.8371873523700777
Validation loss: 2.5982382634993777

Epoch: 5| Step: 2
Training loss: 2.6143969789840074
Validation loss: 2.599697426101356

Epoch: 5| Step: 3
Training loss: 3.0758511427538835
Validation loss: 2.609813517511201

Epoch: 5| Step: 4
Training loss: 2.9912429792909214
Validation loss: 2.632472413615224

Epoch: 5| Step: 5
Training loss: 2.919699608754107
Validation loss: 2.6510398750791504

Epoch: 5| Step: 6
Training loss: 3.0559613237779626
Validation loss: 2.669408782987919

Epoch: 5| Step: 7
Training loss: 3.0748885902133303
Validation loss: 2.6676819090310846

Epoch: 5| Step: 8
Training loss: 2.635846209796622
Validation loss: 2.67571355621648

Epoch: 5| Step: 9
Training loss: 2.7464851979458036
Validation loss: 2.6800811458354876

Epoch: 5| Step: 10
Training loss: 3.0424573906929457
Validation loss: 2.687943792271617

Epoch: 387| Step: 0
Training loss: 2.5158511231955822
Validation loss: 2.670380086890782

Epoch: 5| Step: 1
Training loss: 2.7455463759229692
Validation loss: 2.654990809943248

Epoch: 5| Step: 2
Training loss: 3.035438553926046
Validation loss: 2.6571584625887583

Epoch: 5| Step: 3
Training loss: 2.6334222376177334
Validation loss: 2.6395599038508997

Epoch: 5| Step: 4
Training loss: 2.757435716171966
Validation loss: 2.6334946320390684

Epoch: 5| Step: 5
Training loss: 3.2854093801110804
Validation loss: 2.631984762297711

Epoch: 5| Step: 6
Training loss: 3.0337256321126835
Validation loss: 2.6385905800086205

Epoch: 5| Step: 7
Training loss: 3.097564811367168
Validation loss: 2.640866947078645

Epoch: 5| Step: 8
Training loss: 3.0349738460212
Validation loss: 2.634783273309085

Epoch: 5| Step: 9
Training loss: 2.525349651337658
Validation loss: 2.6419068504429686

Epoch: 5| Step: 10
Training loss: 2.6390066209820615
Validation loss: 2.642532947664851

Epoch: 388| Step: 0
Training loss: 3.1148002489437925
Validation loss: 2.643546428923827

Epoch: 5| Step: 1
Training loss: 2.0316484500651435
Validation loss: 2.6411167407037484

Epoch: 5| Step: 2
Training loss: 2.8230828286754632
Validation loss: 2.6580666571240235

Epoch: 5| Step: 3
Training loss: 3.4848639311969585
Validation loss: 2.667429338752099

Epoch: 5| Step: 4
Training loss: 2.5070089318413435
Validation loss: 2.672313422738323

Epoch: 5| Step: 5
Training loss: 3.475591013755425
Validation loss: 2.66106106400515

Epoch: 5| Step: 6
Training loss: 2.8425349060438356
Validation loss: 2.62120135522764

Epoch: 5| Step: 7
Training loss: 2.5898424611728506
Validation loss: 2.6174067511175925

Epoch: 5| Step: 8
Training loss: 2.8226843500203587
Validation loss: 2.612265459835104

Epoch: 5| Step: 9
Training loss: 2.8021769643878836
Validation loss: 2.6026338357424206

Epoch: 5| Step: 10
Training loss: 2.7095856827744242
Validation loss: 2.6212128100109426

Epoch: 389| Step: 0
Training loss: 3.0665385806936007
Validation loss: 2.6247916307385992

Epoch: 5| Step: 1
Training loss: 2.9226768331814963
Validation loss: 2.643748147642325

Epoch: 5| Step: 2
Training loss: 2.4874355250298286
Validation loss: 2.6599488170182863

Epoch: 5| Step: 3
Training loss: 3.075845096730658
Validation loss: 2.6801328824379147

Epoch: 5| Step: 4
Training loss: 2.832730584451496
Validation loss: 2.6752947065637036

Epoch: 5| Step: 5
Training loss: 2.7113804524028198
Validation loss: 2.6611240872942563

Epoch: 5| Step: 6
Training loss: 2.230634212202319
Validation loss: 2.6568209590052216

Epoch: 5| Step: 7
Training loss: 2.73208976074257
Validation loss: 2.6551678648344947

Epoch: 5| Step: 8
Training loss: 2.7137592152808487
Validation loss: 2.6627468909194802

Epoch: 5| Step: 9
Training loss: 3.2092940308219706
Validation loss: 2.679378611664157

Epoch: 5| Step: 10
Training loss: 3.304947935262727
Validation loss: 2.6856867727643996

Epoch: 390| Step: 0
Training loss: 2.4517167051988835
Validation loss: 2.693838984188371

Epoch: 5| Step: 1
Training loss: 2.799440709522674
Validation loss: 2.6862077995216596

Epoch: 5| Step: 2
Training loss: 2.8515180192378384
Validation loss: 2.660244775668513

Epoch: 5| Step: 3
Training loss: 2.4898558803965467
Validation loss: 2.6491031423089697

Epoch: 5| Step: 4
Training loss: 3.2008311920701775
Validation loss: 2.624197432400314

Epoch: 5| Step: 5
Training loss: 2.831356331215908
Validation loss: 2.6265742937477317

Epoch: 5| Step: 6
Training loss: 3.0600541916580153
Validation loss: 2.6399829314725136

Epoch: 5| Step: 7
Training loss: 2.666647811664044
Validation loss: 2.64156905485906

Epoch: 5| Step: 8
Training loss: 3.1028604169917124
Validation loss: 2.6533827438068003

Epoch: 5| Step: 9
Training loss: 2.7947503229856454
Validation loss: 2.6491166615894084

Epoch: 5| Step: 10
Training loss: 3.0261404488614456
Validation loss: 2.6188521029481984

Epoch: 391| Step: 0
Training loss: 3.072164738787778
Validation loss: 2.6193797157990875

Epoch: 5| Step: 1
Training loss: 3.02708936053151
Validation loss: 2.6246202597546473

Epoch: 5| Step: 2
Training loss: 2.946683124594088
Validation loss: 2.6241181724075617

Epoch: 5| Step: 3
Training loss: 3.2574345577572683
Validation loss: 2.6279535333995607

Epoch: 5| Step: 4
Training loss: 2.886906061560779
Validation loss: 2.644498636836488

Epoch: 5| Step: 5
Training loss: 2.6403991783236744
Validation loss: 2.6250133269909743

Epoch: 5| Step: 6
Training loss: 2.8021465894704036
Validation loss: 2.6141867976517603

Epoch: 5| Step: 7
Training loss: 2.819533560168725
Validation loss: 2.618643953282545

Epoch: 5| Step: 8
Training loss: 2.6898821541877944
Validation loss: 2.6013484729944754

Epoch: 5| Step: 9
Training loss: 2.8450485450612057
Validation loss: 2.6026895861673482

Epoch: 5| Step: 10
Training loss: 2.387051872818052
Validation loss: 2.602916099940023

Epoch: 392| Step: 0
Training loss: 3.3729838247762394
Validation loss: 2.632488950557709

Epoch: 5| Step: 1
Training loss: 2.8987786845391414
Validation loss: 2.669032080912865

Epoch: 5| Step: 2
Training loss: 2.830945036844718
Validation loss: 2.6832810597521277

Epoch: 5| Step: 3
Training loss: 2.9832071146202206
Validation loss: 2.7276077934764746

Epoch: 5| Step: 4
Training loss: 2.8615817533709547
Validation loss: 2.7387502161420194

Epoch: 5| Step: 5
Training loss: 2.883024213093128
Validation loss: 2.7042136318139787

Epoch: 5| Step: 6
Training loss: 3.4257393533195613
Validation loss: 2.671294532064677

Epoch: 5| Step: 7
Training loss: 2.60143767736165
Validation loss: 2.6203290240264594

Epoch: 5| Step: 8
Training loss: 2.5915947657809455
Validation loss: 2.599949135531273

Epoch: 5| Step: 9
Training loss: 2.595598963591518
Validation loss: 2.5943587599774776

Epoch: 5| Step: 10
Training loss: 2.3515376599796336
Validation loss: 2.576674640152182

Epoch: 393| Step: 0
Training loss: 3.502106032939978
Validation loss: 2.5831932747061623

Epoch: 5| Step: 1
Training loss: 3.4121777113309344
Validation loss: 2.5854823035877685

Epoch: 5| Step: 2
Training loss: 2.556037755982835
Validation loss: 2.5923998506605757

Epoch: 5| Step: 3
Training loss: 2.6189168653835746
Validation loss: 2.6039900380603678

Epoch: 5| Step: 4
Training loss: 1.8903554298595122
Validation loss: 2.608777350179613

Epoch: 5| Step: 5
Training loss: 2.9080744113453125
Validation loss: 2.620026564311162

Epoch: 5| Step: 6
Training loss: 2.6366630491801772
Validation loss: 2.6547206947252087

Epoch: 5| Step: 7
Training loss: 2.961699777681748
Validation loss: 2.6693319689544848

Epoch: 5| Step: 8
Training loss: 2.675769399352179
Validation loss: 2.681289743464082

Epoch: 5| Step: 9
Training loss: 2.956119855471789
Validation loss: 2.673656196855114

Epoch: 5| Step: 10
Training loss: 3.1687432223215546
Validation loss: 2.651081116743002

Epoch: 394| Step: 0
Training loss: 2.820473452384452
Validation loss: 2.633413581227705

Epoch: 5| Step: 1
Training loss: 2.737666127637922
Validation loss: 2.619883311088125

Epoch: 5| Step: 2
Training loss: 3.287085294493644
Validation loss: 2.6279949159208877

Epoch: 5| Step: 3
Training loss: 2.5027574590812462
Validation loss: 2.6107052340168795

Epoch: 5| Step: 4
Training loss: 3.4273444233761734
Validation loss: 2.6010208785541225

Epoch: 5| Step: 5
Training loss: 3.0562722858638356
Validation loss: 2.6246863117681745

Epoch: 5| Step: 6
Training loss: 3.056761990901247
Validation loss: 2.650486905205458

Epoch: 5| Step: 7
Training loss: 1.88441190414604
Validation loss: 2.6323047283514427

Epoch: 5| Step: 8
Training loss: 2.961437656161785
Validation loss: 2.643359070818774

Epoch: 5| Step: 9
Training loss: 2.632313032910174
Validation loss: 2.6595410935274333

Epoch: 5| Step: 10
Training loss: 2.8184716300788493
Validation loss: 2.698770225004661

Epoch: 395| Step: 0
Training loss: 3.201560629327022
Validation loss: 2.6736229187299316

Epoch: 5| Step: 1
Training loss: 2.94442889571333
Validation loss: 2.641087721046212

Epoch: 5| Step: 2
Training loss: 3.3231002772833773
Validation loss: 2.6118312723442063

Epoch: 5| Step: 3
Training loss: 2.5343972878940115
Validation loss: 2.5960202117061817

Epoch: 5| Step: 4
Training loss: 2.9004882796060105
Validation loss: 2.576314022234373

Epoch: 5| Step: 5
Training loss: 2.851076518412435
Validation loss: 2.587943508221588

Epoch: 5| Step: 6
Training loss: 2.2457788926735045
Validation loss: 2.5941973776180225

Epoch: 5| Step: 7
Training loss: 2.683626266349129
Validation loss: 2.6159534996241067

Epoch: 5| Step: 8
Training loss: 2.662261264467333
Validation loss: 2.6150964255466036

Epoch: 5| Step: 9
Training loss: 3.252595598603023
Validation loss: 2.6304375554199426

Epoch: 5| Step: 10
Training loss: 2.770939693465117
Validation loss: 2.652675955999355

Epoch: 396| Step: 0
Training loss: 2.407267962055262
Validation loss: 2.6672571423221245

Epoch: 5| Step: 1
Training loss: 2.8763893750841816
Validation loss: 2.672420365213702

Epoch: 5| Step: 2
Training loss: 3.2645714625516233
Validation loss: 2.6783371757390273

Epoch: 5| Step: 3
Training loss: 3.087481689398829
Validation loss: 2.657900095636499

Epoch: 5| Step: 4
Training loss: 2.864384832729482
Validation loss: 2.6240962475323424

Epoch: 5| Step: 5
Training loss: 2.8831206366379667
Validation loss: 2.602418252714829

Epoch: 5| Step: 6
Training loss: 2.5942433818678685
Validation loss: 2.5868876313132496

Epoch: 5| Step: 7
Training loss: 2.3807886753115444
Validation loss: 2.571123806203262

Epoch: 5| Step: 8
Training loss: 2.8601923540426477
Validation loss: 2.5785234841270097

Epoch: 5| Step: 9
Training loss: 2.737407201996933
Validation loss: 2.578991818003403

Epoch: 5| Step: 10
Training loss: 3.6718647408849368
Validation loss: 2.5994315389316753

Epoch: 397| Step: 0
Training loss: 2.189847830619916
Validation loss: 2.5879111567042856

Epoch: 5| Step: 1
Training loss: 2.6976048548332323
Validation loss: 2.608724075604375

Epoch: 5| Step: 2
Training loss: 2.692074010474964
Validation loss: 2.6478536164700026

Epoch: 5| Step: 3
Training loss: 2.7142580127736577
Validation loss: 2.7021071460525423

Epoch: 5| Step: 4
Training loss: 3.0227373283359773
Validation loss: 2.721777120274923

Epoch: 5| Step: 5
Training loss: 2.9283268324624774
Validation loss: 2.7408488573728507

Epoch: 5| Step: 6
Training loss: 2.8343324769519866
Validation loss: 2.739166936192621

Epoch: 5| Step: 7
Training loss: 2.9471185545127003
Validation loss: 2.696508213762772

Epoch: 5| Step: 8
Training loss: 3.7062929662365747
Validation loss: 2.67817734360024

Epoch: 5| Step: 9
Training loss: 3.1611881716750556
Validation loss: 2.6392443268766494

Epoch: 5| Step: 10
Training loss: 2.769536415170607
Validation loss: 2.6173141941045834

Epoch: 398| Step: 0
Training loss: 2.7823580131394396
Validation loss: 2.583631707332648

Epoch: 5| Step: 1
Training loss: 3.0401830495133577
Validation loss: 2.5730948670235234

Epoch: 5| Step: 2
Training loss: 2.604142201626617
Validation loss: 2.5632631314560146

Epoch: 5| Step: 3
Training loss: 3.300230804232646
Validation loss: 2.5656764724014924

Epoch: 5| Step: 4
Training loss: 3.7639320968518963
Validation loss: 2.562939833964135

Epoch: 5| Step: 5
Training loss: 2.4021925963944106
Validation loss: 2.564458804193814

Epoch: 5| Step: 6
Training loss: 2.679225781759039
Validation loss: 2.557316233723686

Epoch: 5| Step: 7
Training loss: 2.286372664692488
Validation loss: 2.563833483496911

Epoch: 5| Step: 8
Training loss: 2.48123190846802
Validation loss: 2.562518534179378

Epoch: 5| Step: 9
Training loss: 2.931428681806213
Validation loss: 2.5772874741467593

Epoch: 5| Step: 10
Training loss: 3.287901467297155
Validation loss: 2.5839964174093213

Epoch: 399| Step: 0
Training loss: 2.3026653146782143
Validation loss: 2.5982550124096435

Epoch: 5| Step: 1
Training loss: 2.90435351769958
Validation loss: 2.610774382619638

Epoch: 5| Step: 2
Training loss: 2.978649619168386
Validation loss: 2.6098325074199145

Epoch: 5| Step: 3
Training loss: 3.055819952728906
Validation loss: 2.6245567418267153

Epoch: 5| Step: 4
Training loss: 2.9940864772093363
Validation loss: 2.6205724223378053

Epoch: 5| Step: 5
Training loss: 2.3097046117467426
Validation loss: 2.628854287347729

Epoch: 5| Step: 6
Training loss: 3.0710858252012354
Validation loss: 2.6172724541516277

Epoch: 5| Step: 7
Training loss: 2.686307864482316
Validation loss: 2.6101159526135094

Epoch: 5| Step: 8
Training loss: 2.7621284407598417
Validation loss: 2.6009811475607476

Epoch: 5| Step: 9
Training loss: 3.22211021652527
Validation loss: 2.596302735771946

Epoch: 5| Step: 10
Training loss: 3.1022155228001718
Validation loss: 2.5941804483467936

Epoch: 400| Step: 0
Training loss: 2.969105588798843
Validation loss: 2.601175529929876

Epoch: 5| Step: 1
Training loss: 3.1095211435602965
Validation loss: 2.608507777239915

Epoch: 5| Step: 2
Training loss: 2.8993017342568277
Validation loss: 2.6226784987714686

Epoch: 5| Step: 3
Training loss: 2.623996815406216
Validation loss: 2.623683640403974

Epoch: 5| Step: 4
Training loss: 2.4333803625221635
Validation loss: 2.6265616930457174

Epoch: 5| Step: 5
Training loss: 2.759510587339832
Validation loss: 2.6216157210971223

Epoch: 5| Step: 6
Training loss: 3.1560285131716013
Validation loss: 2.617834414743919

Epoch: 5| Step: 7
Training loss: 3.146693804618494
Validation loss: 2.617185809312892

Epoch: 5| Step: 8
Training loss: 2.5548370037604533
Validation loss: 2.6202111791573075

Epoch: 5| Step: 9
Training loss: 2.724435583334959
Validation loss: 2.6329763916549846

Epoch: 5| Step: 10
Training loss: 2.958675597544264
Validation loss: 2.6440137872892304

Epoch: 401| Step: 0
Training loss: 2.8464888912796957
Validation loss: 2.6698819345079223

Epoch: 5| Step: 1
Training loss: 3.108302405836725
Validation loss: 2.6711840462680363

Epoch: 5| Step: 2
Training loss: 2.7028575610566916
Validation loss: 2.6787667219786298

Epoch: 5| Step: 3
Training loss: 2.636105524031955
Validation loss: 2.653739804762375

Epoch: 5| Step: 4
Training loss: 2.5070536288234107
Validation loss: 2.6606679755495195

Epoch: 5| Step: 5
Training loss: 3.06385010523462
Validation loss: 2.6485278905810863

Epoch: 5| Step: 6
Training loss: 3.0736905605158436
Validation loss: 2.6479726902523426

Epoch: 5| Step: 7
Training loss: 2.881355558435296
Validation loss: 2.6269086392483865

Epoch: 5| Step: 8
Training loss: 3.08514007695495
Validation loss: 2.6223931315856683

Epoch: 5| Step: 9
Training loss: 2.547702116730298
Validation loss: 2.61737307810582

Epoch: 5| Step: 10
Training loss: 2.7298178053762703
Validation loss: 2.6129778430148556

Epoch: 402| Step: 0
Training loss: 2.641607699854238
Validation loss: 2.6155272966630148

Epoch: 5| Step: 1
Training loss: 2.4839355271982377
Validation loss: 2.610030417324994

Epoch: 5| Step: 2
Training loss: 2.9887296053558714
Validation loss: 2.607723021406375

Epoch: 5| Step: 3
Training loss: 3.1839187549787864
Validation loss: 2.6081418601641158

Epoch: 5| Step: 4
Training loss: 2.7716188297360467
Validation loss: 2.610374922756979

Epoch: 5| Step: 5
Training loss: 2.6925373330534295
Validation loss: 2.6157922940668175

Epoch: 5| Step: 6
Training loss: 2.7212924688667406
Validation loss: 2.644522467111642

Epoch: 5| Step: 7
Training loss: 2.925607673579045
Validation loss: 2.6641879431250226

Epoch: 5| Step: 8
Training loss: 3.171840874248766
Validation loss: 2.6739725964226593

Epoch: 5| Step: 9
Training loss: 2.7692833104814207
Validation loss: 2.7050763167609246

Epoch: 5| Step: 10
Training loss: 2.804084479236158
Validation loss: 2.7093681674390497

Epoch: 403| Step: 0
Training loss: 2.7653303258775908
Validation loss: 2.696387291055771

Epoch: 5| Step: 1
Training loss: 2.5371604955396405
Validation loss: 2.6795522449457567

Epoch: 5| Step: 2
Training loss: 2.8802460615688905
Validation loss: 2.6797819814221033

Epoch: 5| Step: 3
Training loss: 2.6739394037289723
Validation loss: 2.641882057242717

Epoch: 5| Step: 4
Training loss: 2.823412261664316
Validation loss: 2.6363270176370754

Epoch: 5| Step: 5
Training loss: 3.15738483838115
Validation loss: 2.6327932464254915

Epoch: 5| Step: 6
Training loss: 2.8360017291065103
Validation loss: 2.6306689079760397

Epoch: 5| Step: 7
Training loss: 2.727439761104113
Validation loss: 2.6200603196578203

Epoch: 5| Step: 8
Training loss: 2.942056247176089
Validation loss: 2.613473967111771

Epoch: 5| Step: 9
Training loss: 3.060758757423162
Validation loss: 2.5950369964765816

Epoch: 5| Step: 10
Training loss: 2.8170144195620925
Validation loss: 2.601153822659471

Epoch: 404| Step: 0
Training loss: 2.6883449556872425
Validation loss: 2.5974423413188497

Epoch: 5| Step: 1
Training loss: 2.9671077000401747
Validation loss: 2.58929654659695

Epoch: 5| Step: 2
Training loss: 3.010438243608246
Validation loss: 2.6020512349522944

Epoch: 5| Step: 3
Training loss: 2.8913847053836275
Validation loss: 2.619543699690736

Epoch: 5| Step: 4
Training loss: 2.7579581678785163
Validation loss: 2.6566325105898123

Epoch: 5| Step: 5
Training loss: 3.014755835317685
Validation loss: 2.6643518926958762

Epoch: 5| Step: 6
Training loss: 3.024329711802018
Validation loss: 2.6706372344283373

Epoch: 5| Step: 7
Training loss: 3.125223228111058
Validation loss: 2.656183192494528

Epoch: 5| Step: 8
Training loss: 2.151442323429778
Validation loss: 2.6432836170044807

Epoch: 5| Step: 9
Training loss: 3.0705883106079503
Validation loss: 2.6393858124562

Epoch: 5| Step: 10
Training loss: 2.3836152272364917
Validation loss: 2.631585904426856

Epoch: 405| Step: 0
Training loss: 2.928671373263522
Validation loss: 2.610890178050658

Epoch: 5| Step: 1
Training loss: 2.8905126601375626
Validation loss: 2.6172807956327855

Epoch: 5| Step: 2
Training loss: 2.0887092148949806
Validation loss: 2.6350856337854833

Epoch: 5| Step: 3
Training loss: 2.1830652242187725
Validation loss: 2.624502694505772

Epoch: 5| Step: 4
Training loss: 2.1808293677548933
Validation loss: 2.6350687969487563

Epoch: 5| Step: 5
Training loss: 2.6942826667101514
Validation loss: 2.6570761450881104

Epoch: 5| Step: 6
Training loss: 3.307806036090977
Validation loss: 2.672257968831007

Epoch: 5| Step: 7
Training loss: 3.071011917394223
Validation loss: 2.6695828515307594

Epoch: 5| Step: 8
Training loss: 2.827670234662036
Validation loss: 2.6535717853016294

Epoch: 5| Step: 9
Training loss: 3.346419080211023
Validation loss: 2.662107474978601

Epoch: 5| Step: 10
Training loss: 3.4063164940739568
Validation loss: 2.6531431613696066

Epoch: 406| Step: 0
Training loss: 2.696293395307321
Validation loss: 2.645691878439287

Epoch: 5| Step: 1
Training loss: 2.7360095560899684
Validation loss: 2.614207244430186

Epoch: 5| Step: 2
Training loss: 2.8805137504536815
Validation loss: 2.6028857585956677

Epoch: 5| Step: 3
Training loss: 2.887505740205418
Validation loss: 2.595991493268105

Epoch: 5| Step: 4
Training loss: 2.4437404856777105
Validation loss: 2.633878271926719

Epoch: 5| Step: 5
Training loss: 2.8007562229203473
Validation loss: 2.649626802876957

Epoch: 5| Step: 6
Training loss: 2.9653627044483284
Validation loss: 2.6630259449484766

Epoch: 5| Step: 7
Training loss: 2.7854912811838544
Validation loss: 2.6949879221849415

Epoch: 5| Step: 8
Training loss: 2.856441973822835
Validation loss: 2.676242827779412

Epoch: 5| Step: 9
Training loss: 2.9997604592375664
Validation loss: 2.6575029346145524

Epoch: 5| Step: 10
Training loss: 3.1882834874065598
Validation loss: 2.6237871988704113

Epoch: 407| Step: 0
Training loss: 2.8289963870896875
Validation loss: 2.6076188559391427

Epoch: 5| Step: 1
Training loss: 2.8049214300075547
Validation loss: 2.6031134824044124

Epoch: 5| Step: 2
Training loss: 2.6853765926128186
Validation loss: 2.597616508007785

Epoch: 5| Step: 3
Training loss: 2.3202105669950113
Validation loss: 2.5993945540101744

Epoch: 5| Step: 4
Training loss: 2.723919918647677
Validation loss: 2.616680083218565

Epoch: 5| Step: 5
Training loss: 2.9206026132167677
Validation loss: 2.6157405531013973

Epoch: 5| Step: 6
Training loss: 2.9896851277493988
Validation loss: 2.626414227153341

Epoch: 5| Step: 7
Training loss: 2.7740538865832662
Validation loss: 2.6404628617721895

Epoch: 5| Step: 8
Training loss: 2.9577766396131584
Validation loss: 2.6436728038449298

Epoch: 5| Step: 9
Training loss: 3.024062454335586
Validation loss: 2.6614356606598593

Epoch: 5| Step: 10
Training loss: 3.083082979365591
Validation loss: 2.6700945831926735

Epoch: 408| Step: 0
Training loss: 2.9320690190204943
Validation loss: 2.674299511081202

Epoch: 5| Step: 1
Training loss: 2.840637012284231
Validation loss: 2.682831945743074

Epoch: 5| Step: 2
Training loss: 2.627598702330842
Validation loss: 2.663924805032152

Epoch: 5| Step: 3
Training loss: 2.8242356338101824
Validation loss: 2.691831649813342

Epoch: 5| Step: 4
Training loss: 2.483945701503227
Validation loss: 2.729373380799257

Epoch: 5| Step: 5
Training loss: 3.2978346453982
Validation loss: 2.763912985700381

Epoch: 5| Step: 6
Training loss: 2.7287094276756614
Validation loss: 2.7083937878799076

Epoch: 5| Step: 7
Training loss: 2.581539505432588
Validation loss: 2.672267777245487

Epoch: 5| Step: 8
Training loss: 3.1546965449195494
Validation loss: 2.6149113495946965

Epoch: 5| Step: 9
Training loss: 2.8825561078608377
Validation loss: 2.5979447646147467

Epoch: 5| Step: 10
Training loss: 3.0565109859189867
Validation loss: 2.5758851405412497

Epoch: 409| Step: 0
Training loss: 3.1199506019692085
Validation loss: 2.589591682008858

Epoch: 5| Step: 1
Training loss: 2.3997895347183267
Validation loss: 2.5809818830055975

Epoch: 5| Step: 2
Training loss: 2.7500755993248536
Validation loss: 2.583997643672273

Epoch: 5| Step: 3
Training loss: 2.9829753369684293
Validation loss: 2.6011216709270553

Epoch: 5| Step: 4
Training loss: 3.0702752263958866
Validation loss: 2.6078422288358847

Epoch: 5| Step: 5
Training loss: 2.395580665422966
Validation loss: 2.617575157669176

Epoch: 5| Step: 6
Training loss: 3.1076100002961167
Validation loss: 2.629275667683269

Epoch: 5| Step: 7
Training loss: 2.869698155443693
Validation loss: 2.596199715236601

Epoch: 5| Step: 8
Training loss: 2.63728491462076
Validation loss: 2.6331851832142807

Epoch: 5| Step: 9
Training loss: 2.842877096830446
Validation loss: 2.648278151283106

Epoch: 5| Step: 10
Training loss: 2.791606095828851
Validation loss: 2.6716773854728864

Epoch: 410| Step: 0
Training loss: 2.4263862187206433
Validation loss: 2.673789003190662

Epoch: 5| Step: 1
Training loss: 2.2371365214652923
Validation loss: 2.7017038187087676

Epoch: 5| Step: 2
Training loss: 3.3085444603213134
Validation loss: 2.733757086577544

Epoch: 5| Step: 3
Training loss: 2.7707618379093053
Validation loss: 2.704664732751671

Epoch: 5| Step: 4
Training loss: 2.6727117823161906
Validation loss: 2.6913624866837145

Epoch: 5| Step: 5
Training loss: 2.9246191510434145
Validation loss: 2.6740839122810693

Epoch: 5| Step: 6
Training loss: 2.769617593169902
Validation loss: 2.674298034803899

Epoch: 5| Step: 7
Training loss: 2.82972528694659
Validation loss: 2.6135350794510877

Epoch: 5| Step: 8
Training loss: 3.143187431220608
Validation loss: 2.590765204165374

Epoch: 5| Step: 9
Training loss: 3.124898679998106
Validation loss: 2.5638558287186255

Epoch: 5| Step: 10
Training loss: 2.831087194481793
Validation loss: 2.554506431249787

Epoch: 411| Step: 0
Training loss: 2.4592467297618263
Validation loss: 2.55037744066371

Epoch: 5| Step: 1
Training loss: 3.3389807227424515
Validation loss: 2.5569508513014236

Epoch: 5| Step: 2
Training loss: 2.8931553668416377
Validation loss: 2.557910369586861

Epoch: 5| Step: 3
Training loss: 3.2458428424766104
Validation loss: 2.558967769025304

Epoch: 5| Step: 4
Training loss: 2.4260298990040945
Validation loss: 2.561859184793338

Epoch: 5| Step: 5
Training loss: 2.690593978933398
Validation loss: 2.579398798682536

Epoch: 5| Step: 6
Training loss: 3.007967541154275
Validation loss: 2.6031868772793914

Epoch: 5| Step: 7
Training loss: 2.884438818393988
Validation loss: 2.6384012706199997

Epoch: 5| Step: 8
Training loss: 3.0301299237889956
Validation loss: 2.6724566810139345

Epoch: 5| Step: 9
Training loss: 3.087927531553244
Validation loss: 2.705721708362045

Epoch: 5| Step: 10
Training loss: 2.721486085070153
Validation loss: 2.688471539108064

Epoch: 412| Step: 0
Training loss: 3.0408732455028185
Validation loss: 2.6522194904255167

Epoch: 5| Step: 1
Training loss: 2.7297421690647474
Validation loss: 2.62942349276299

Epoch: 5| Step: 2
Training loss: 2.859417357417655
Validation loss: 2.614019434022941

Epoch: 5| Step: 3
Training loss: 2.721349854290966
Validation loss: 2.606274031626202

Epoch: 5| Step: 4
Training loss: 2.6521265674152588
Validation loss: 2.6025101431338986

Epoch: 5| Step: 5
Training loss: 2.9869321083856226
Validation loss: 2.5848146935542173

Epoch: 5| Step: 6
Training loss: 2.9806117752175356
Validation loss: 2.578083730835306

Epoch: 5| Step: 7
Training loss: 2.2327628555278007
Validation loss: 2.569870271755032

Epoch: 5| Step: 8
Training loss: 3.1836130715000337
Validation loss: 2.576604185388593

Epoch: 5| Step: 9
Training loss: 2.576492254943281
Validation loss: 2.5854353065615685

Epoch: 5| Step: 10
Training loss: 3.3455095741774654
Validation loss: 2.582860391958662

Epoch: 413| Step: 0
Training loss: 3.1149540981382535
Validation loss: 2.597208563035882

Epoch: 5| Step: 1
Training loss: 2.879799030232632
Validation loss: 2.5929761004600116

Epoch: 5| Step: 2
Training loss: 2.7798812584251875
Validation loss: 2.600563156698922

Epoch: 5| Step: 3
Training loss: 2.674808520300056
Validation loss: 2.6185528111317575

Epoch: 5| Step: 4
Training loss: 3.326464171454755
Validation loss: 2.62191336870869

Epoch: 5| Step: 5
Training loss: 2.9810790390802544
Validation loss: 2.624677983078272

Epoch: 5| Step: 6
Training loss: 2.250309604960231
Validation loss: 2.615440187719678

Epoch: 5| Step: 7
Training loss: 2.2451181432482197
Validation loss: 2.6220655099536025

Epoch: 5| Step: 8
Training loss: 2.4133130734297534
Validation loss: 2.642165664946772

Epoch: 5| Step: 9
Training loss: 2.7390785090603713
Validation loss: 2.6738508798748333

Epoch: 5| Step: 10
Training loss: 3.6747112601895893
Validation loss: 2.6814059681152846

Epoch: 414| Step: 0
Training loss: 2.7444744083589496
Validation loss: 2.6677444520589693

Epoch: 5| Step: 1
Training loss: 2.880120071981083
Validation loss: 2.6509842387215268

Epoch: 5| Step: 2
Training loss: 3.081407220322964
Validation loss: 2.6438818590017457

Epoch: 5| Step: 3
Training loss: 3.0452316156002595
Validation loss: 2.6024848977756645

Epoch: 5| Step: 4
Training loss: 3.186079269629951
Validation loss: 2.596620622028905

Epoch: 5| Step: 5
Training loss: 2.229919365934687
Validation loss: 2.6110413238804036

Epoch: 5| Step: 6
Training loss: 2.774066520602918
Validation loss: 2.607952572938224

Epoch: 5| Step: 7
Training loss: 3.19424562434428
Validation loss: 2.5989165341672695

Epoch: 5| Step: 8
Training loss: 2.670967974271908
Validation loss: 2.6037408066246015

Epoch: 5| Step: 9
Training loss: 2.2259366410690378
Validation loss: 2.6073446142758963

Epoch: 5| Step: 10
Training loss: 3.0092473558587165
Validation loss: 2.6207150778608077

Epoch: 415| Step: 0
Training loss: 2.835261661086788
Validation loss: 2.640674674818122

Epoch: 5| Step: 1
Training loss: 3.051707030827493
Validation loss: 2.6691619199337215

Epoch: 5| Step: 2
Training loss: 2.582355703955303
Validation loss: 2.6464125083546985

Epoch: 5| Step: 3
Training loss: 2.685533824542154
Validation loss: 2.6563723869527887

Epoch: 5| Step: 4
Training loss: 2.6391270468696733
Validation loss: 2.644408443960523

Epoch: 5| Step: 5
Training loss: 2.838306624920978
Validation loss: 2.6237673748917856

Epoch: 5| Step: 6
Training loss: 2.5460201771334425
Validation loss: 2.6262578641078878

Epoch: 5| Step: 7
Training loss: 2.905060719628594
Validation loss: 2.625244496937885

Epoch: 5| Step: 8
Training loss: 2.987876715112167
Validation loss: 2.6219297502953367

Epoch: 5| Step: 9
Training loss: 2.888923762999441
Validation loss: 2.6321922689766186

Epoch: 5| Step: 10
Training loss: 3.0292043173722565
Validation loss: 2.628853483788469

Epoch: 416| Step: 0
Training loss: 2.8213414563324686
Validation loss: 2.6390342632060926

Epoch: 5| Step: 1
Training loss: 2.569151642300005
Validation loss: 2.6451250752429263

Epoch: 5| Step: 2
Training loss: 3.1835690362825266
Validation loss: 2.6655615596788285

Epoch: 5| Step: 3
Training loss: 2.9818551974737426
Validation loss: 2.651134066199708

Epoch: 5| Step: 4
Training loss: 2.8580342469028825
Validation loss: 2.6343774159786926

Epoch: 5| Step: 5
Training loss: 2.5647652080965138
Validation loss: 2.612641784428574

Epoch: 5| Step: 6
Training loss: 3.057662412832255
Validation loss: 2.5922328358120312

Epoch: 5| Step: 7
Training loss: 2.6957443996973742
Validation loss: 2.594948623241582

Epoch: 5| Step: 8
Training loss: 2.5771438118682437
Validation loss: 2.5760298930850007

Epoch: 5| Step: 9
Training loss: 3.10625941929454
Validation loss: 2.5853983346102862

Epoch: 5| Step: 10
Training loss: 2.5718124326416545
Validation loss: 2.5871576733597488

Epoch: 417| Step: 0
Training loss: 2.7725222514629486
Validation loss: 2.5967496449650205

Epoch: 5| Step: 1
Training loss: 2.0437694023681225
Validation loss: 2.618807173177839

Epoch: 5| Step: 2
Training loss: 3.0955684981570393
Validation loss: 2.6114593526145633

Epoch: 5| Step: 3
Training loss: 3.345198700709571
Validation loss: 2.656092391625391

Epoch: 5| Step: 4
Training loss: 3.3180458140736984
Validation loss: 2.64609618492553

Epoch: 5| Step: 5
Training loss: 2.8049499898930073
Validation loss: 2.633890672159927

Epoch: 5| Step: 6
Training loss: 3.026997995628598
Validation loss: 2.651220406087491

Epoch: 5| Step: 7
Training loss: 2.0671282770578743
Validation loss: 2.676413614658182

Epoch: 5| Step: 8
Training loss: 2.6474501308106624
Validation loss: 2.662761373023545

Epoch: 5| Step: 9
Training loss: 2.8145169972909296
Validation loss: 2.650467163889201

Epoch: 5| Step: 10
Training loss: 2.7147643592258697
Validation loss: 2.623948243482248

Epoch: 418| Step: 0
Training loss: 2.921780997819438
Validation loss: 2.61911965097861

Epoch: 5| Step: 1
Training loss: 2.477831109456116
Validation loss: 2.6063430292655516

Epoch: 5| Step: 2
Training loss: 2.7480392401724076
Validation loss: 2.605141449805335

Epoch: 5| Step: 3
Training loss: 2.8864344558820365
Validation loss: 2.594837012833545

Epoch: 5| Step: 4
Training loss: 2.88462776572676
Validation loss: 2.586934064835327

Epoch: 5| Step: 5
Training loss: 2.7053152923728208
Validation loss: 2.5991125988048784

Epoch: 5| Step: 6
Training loss: 2.449256908843492
Validation loss: 2.6077236938435755

Epoch: 5| Step: 7
Training loss: 3.2146491435630944
Validation loss: 2.6145294655205307

Epoch: 5| Step: 8
Training loss: 3.1767303437465197
Validation loss: 2.621864635963269

Epoch: 5| Step: 9
Training loss: 2.532293599069272
Validation loss: 2.6190179958527353

Epoch: 5| Step: 10
Training loss: 2.8351190400066626
Validation loss: 2.6247270210708233

Epoch: 419| Step: 0
Training loss: 2.66486138589884
Validation loss: 2.625995974418108

Epoch: 5| Step: 1
Training loss: 2.3561899273649223
Validation loss: 2.645666309175264

Epoch: 5| Step: 2
Training loss: 2.3329263627407846
Validation loss: 2.6510767071415957

Epoch: 5| Step: 3
Training loss: 3.1541629349465174
Validation loss: 2.654351207115476

Epoch: 5| Step: 4
Training loss: 2.9471454128172145
Validation loss: 2.6682509214216377

Epoch: 5| Step: 5
Training loss: 3.1195979920624515
Validation loss: 2.6685473052398967

Epoch: 5| Step: 6
Training loss: 2.9266300778140244
Validation loss: 2.6438599128171525

Epoch: 5| Step: 7
Training loss: 2.475423749618101
Validation loss: 2.609852183813646

Epoch: 5| Step: 8
Training loss: 3.015520953819556
Validation loss: 2.6293155278621354

Epoch: 5| Step: 9
Training loss: 3.133551227487447
Validation loss: 2.606358218219153

Epoch: 5| Step: 10
Training loss: 2.601379846341159
Validation loss: 2.5967570907925346

Epoch: 420| Step: 0
Training loss: 2.1793573601208207
Validation loss: 2.610278771753605

Epoch: 5| Step: 1
Training loss: 2.459601145408464
Validation loss: 2.6003133360382673

Epoch: 5| Step: 2
Training loss: 3.3685781346574095
Validation loss: 2.593683172996653

Epoch: 5| Step: 3
Training loss: 2.673734854164402
Validation loss: 2.5927232038549497

Epoch: 5| Step: 4
Training loss: 2.440575444576829
Validation loss: 2.593609669310621

Epoch: 5| Step: 5
Training loss: 3.0220224780414995
Validation loss: 2.599352636274881

Epoch: 5| Step: 6
Training loss: 3.5804182807749734
Validation loss: 2.6325707884394296

Epoch: 5| Step: 7
Training loss: 2.6008285082725773
Validation loss: 2.6325797085826372

Epoch: 5| Step: 8
Training loss: 2.863782144113849
Validation loss: 2.651828735984648

Epoch: 5| Step: 9
Training loss: 2.7504325873250255
Validation loss: 2.644491665698802

Epoch: 5| Step: 10
Training loss: 2.7719668505394326
Validation loss: 2.6297241882998024

Epoch: 421| Step: 0
Training loss: 2.7131026798253757
Validation loss: 2.625451722467327

Epoch: 5| Step: 1
Training loss: 2.6262336738438465
Validation loss: 2.6388174832809534

Epoch: 5| Step: 2
Training loss: 2.9299619012119784
Validation loss: 2.619857812367442

Epoch: 5| Step: 3
Training loss: 3.2015187772015214
Validation loss: 2.6017453369212604

Epoch: 5| Step: 4
Training loss: 2.505063175006312
Validation loss: 2.594257850116353

Epoch: 5| Step: 5
Training loss: 2.9841676010844806
Validation loss: 2.601589683748648

Epoch: 5| Step: 6
Training loss: 3.363148543766898
Validation loss: 2.607946028056639

Epoch: 5| Step: 7
Training loss: 1.9090297630351851
Validation loss: 2.6163075446428574

Epoch: 5| Step: 8
Training loss: 2.891869189584475
Validation loss: 2.6232278870874546

Epoch: 5| Step: 9
Training loss: 2.7986984702065048
Validation loss: 2.643103661258345

Epoch: 5| Step: 10
Training loss: 2.759271684140254
Validation loss: 2.657779250982006

Epoch: 422| Step: 0
Training loss: 3.004009587329748
Validation loss: 2.6639780140561116

Epoch: 5| Step: 1
Training loss: 2.9266036829619524
Validation loss: 2.6732545879616625

Epoch: 5| Step: 2
Training loss: 2.6006485533616046
Validation loss: 2.6715630454324133

Epoch: 5| Step: 3
Training loss: 2.7854827218698466
Validation loss: 2.6571424631738765

Epoch: 5| Step: 4
Training loss: 2.793630668259215
Validation loss: 2.629932117040726

Epoch: 5| Step: 5
Training loss: 2.357360080519065
Validation loss: 2.6019535723544442

Epoch: 5| Step: 6
Training loss: 3.0111805475759996
Validation loss: 2.597620480359222

Epoch: 5| Step: 7
Training loss: 2.8838806654516613
Validation loss: 2.59287523071724

Epoch: 5| Step: 8
Training loss: 2.8300907616501005
Validation loss: 2.6077894768288776

Epoch: 5| Step: 9
Training loss: 2.484426629831542
Validation loss: 2.61141701890139

Epoch: 5| Step: 10
Training loss: 3.373319843426094
Validation loss: 2.617949120861289

Epoch: 423| Step: 0
Training loss: 2.6234855824665613
Validation loss: 2.6401863935305094

Epoch: 5| Step: 1
Training loss: 2.6434558389119784
Validation loss: 2.6638765569408553

Epoch: 5| Step: 2
Training loss: 3.1002132834619784
Validation loss: 2.694157501043526

Epoch: 5| Step: 3
Training loss: 2.790751311891954
Validation loss: 2.6867158475045887

Epoch: 5| Step: 4
Training loss: 2.8780479859890735
Validation loss: 2.6672891244768873

Epoch: 5| Step: 5
Training loss: 2.6881273114164093
Validation loss: 2.6522179622273314

Epoch: 5| Step: 6
Training loss: 2.9177329339639684
Validation loss: 2.6224326202950095

Epoch: 5| Step: 7
Training loss: 2.447869764379187
Validation loss: 2.6092390644343397

Epoch: 5| Step: 8
Training loss: 3.1896558464739284
Validation loss: 2.580528157988877

Epoch: 5| Step: 9
Training loss: 2.6960176734062045
Validation loss: 2.5797879590577923

Epoch: 5| Step: 10
Training loss: 2.938800767259665
Validation loss: 2.577670370807205

Epoch: 424| Step: 0
Training loss: 2.7087025512989746
Validation loss: 2.5790742093169645

Epoch: 5| Step: 1
Training loss: 2.5664710932281096
Validation loss: 2.5781899651290785

Epoch: 5| Step: 2
Training loss: 2.8084042714683997
Validation loss: 2.5924701945694393

Epoch: 5| Step: 3
Training loss: 3.2213772911942
Validation loss: 2.6067576405849864

Epoch: 5| Step: 4
Training loss: 2.7855132785001993
Validation loss: 2.6103854026899835

Epoch: 5| Step: 5
Training loss: 2.948092739566791
Validation loss: 2.611841429394546

Epoch: 5| Step: 6
Training loss: 2.6808396245447614
Validation loss: 2.6434663147409543

Epoch: 5| Step: 7
Training loss: 2.793754669799998
Validation loss: 2.649169421929354

Epoch: 5| Step: 8
Training loss: 2.9204576287862225
Validation loss: 2.6588142212599233

Epoch: 5| Step: 9
Training loss: 2.4871125882827325
Validation loss: 2.6509791022177978

Epoch: 5| Step: 10
Training loss: 2.9322609140376925
Validation loss: 2.638086394664408

Epoch: 425| Step: 0
Training loss: 2.414683240568567
Validation loss: 2.6624863391929976

Epoch: 5| Step: 1
Training loss: 2.9140525183621775
Validation loss: 2.6326954174350488

Epoch: 5| Step: 2
Training loss: 2.423578463106465
Validation loss: 2.6318394568787316

Epoch: 5| Step: 3
Training loss: 2.7477535262037933
Validation loss: 2.6575747367260476

Epoch: 5| Step: 4
Training loss: 2.7310829617817403
Validation loss: 2.668727256157527

Epoch: 5| Step: 5
Training loss: 2.864271463699143
Validation loss: 2.657792325831366

Epoch: 5| Step: 6
Training loss: 2.576146979569578
Validation loss: 2.6289646213084312

Epoch: 5| Step: 7
Training loss: 3.3856406426310452
Validation loss: 2.6104403619871177

Epoch: 5| Step: 8
Training loss: 2.5239803332667403
Validation loss: 2.6095686736213017

Epoch: 5| Step: 9
Training loss: 2.8277289181701564
Validation loss: 2.5897765559139243

Epoch: 5| Step: 10
Training loss: 3.3849773571885526
Validation loss: 2.6022967792441234

Epoch: 426| Step: 0
Training loss: 2.8165014835504776
Validation loss: 2.5877915522347505

Epoch: 5| Step: 1
Training loss: 2.403455622714696
Validation loss: 2.604492422751266

Epoch: 5| Step: 2
Training loss: 2.969242898278457
Validation loss: 2.599724708241559

Epoch: 5| Step: 3
Training loss: 3.326449836769003
Validation loss: 2.6162904301817216

Epoch: 5| Step: 4
Training loss: 2.295531522248172
Validation loss: 2.6470776100425004

Epoch: 5| Step: 5
Training loss: 2.932682551094749
Validation loss: 2.66666949243806

Epoch: 5| Step: 6
Training loss: 2.211712596888794
Validation loss: 2.69535865215102

Epoch: 5| Step: 7
Training loss: 3.1819318119417908
Validation loss: 2.711230300118196

Epoch: 5| Step: 8
Training loss: 2.4031864828075
Validation loss: 2.7042886189231146

Epoch: 5| Step: 9
Training loss: 2.702110585291213
Validation loss: 2.689641547125712

Epoch: 5| Step: 10
Training loss: 3.4697392058417265
Validation loss: 2.6744118255944187

Epoch: 427| Step: 0
Training loss: 2.426959600828315
Validation loss: 2.634356319006201

Epoch: 5| Step: 1
Training loss: 2.6754386292677825
Validation loss: 2.596887516666662

Epoch: 5| Step: 2
Training loss: 2.9150555838623107
Validation loss: 2.584225809728866

Epoch: 5| Step: 3
Training loss: 2.7475635832908534
Validation loss: 2.5666903230576823

Epoch: 5| Step: 4
Training loss: 2.9046982755250808
Validation loss: 2.580038081437616

Epoch: 5| Step: 5
Training loss: 3.417171503002537
Validation loss: 2.5829171557687913

Epoch: 5| Step: 6
Training loss: 2.6197180513286216
Validation loss: 2.592240717891341

Epoch: 5| Step: 7
Training loss: 2.8029190481134307
Validation loss: 2.5963822119723425

Epoch: 5| Step: 8
Training loss: 2.831159954870702
Validation loss: 2.623603136618436

Epoch: 5| Step: 9
Training loss: 2.607091395547684
Validation loss: 2.6360923532876335

Epoch: 5| Step: 10
Training loss: 2.8644440958111477
Validation loss: 2.6469181005222104

Epoch: 428| Step: 0
Training loss: 2.4144790438186767
Validation loss: 2.659593539110909

Epoch: 5| Step: 1
Training loss: 2.723231163240613
Validation loss: 2.6507200573082166

Epoch: 5| Step: 2
Training loss: 2.2915586850706666
Validation loss: 2.69272153022877

Epoch: 5| Step: 3
Training loss: 2.913442428111698
Validation loss: 2.699322920811056

Epoch: 5| Step: 4
Training loss: 2.929236618950372
Validation loss: 2.6851195677047413

Epoch: 5| Step: 5
Training loss: 2.078993422247833
Validation loss: 2.6673575097355045

Epoch: 5| Step: 6
Training loss: 2.953031023740328
Validation loss: 2.664361457913549

Epoch: 5| Step: 7
Training loss: 2.9843256282217645
Validation loss: 2.673480372132695

Epoch: 5| Step: 8
Training loss: 3.35858925790036
Validation loss: 2.6387585361828974

Epoch: 5| Step: 9
Training loss: 3.1693496046513876
Validation loss: 2.5998139061996395

Epoch: 5| Step: 10
Training loss: 2.8193849850686874
Validation loss: 2.5721784288755716

Epoch: 429| Step: 0
Training loss: 2.5718268945025957
Validation loss: 2.5701809619526936

Epoch: 5| Step: 1
Training loss: 3.0999230344508626
Validation loss: 2.5574085347651687

Epoch: 5| Step: 2
Training loss: 2.818531943131588
Validation loss: 2.5473707929330143

Epoch: 5| Step: 3
Training loss: 2.623238653811558
Validation loss: 2.550210469387321

Epoch: 5| Step: 4
Training loss: 2.8573768179333796
Validation loss: 2.5579954593679757

Epoch: 5| Step: 5
Training loss: 3.300828633165821
Validation loss: 2.562708734374079

Epoch: 5| Step: 6
Training loss: 2.7362609462946037
Validation loss: 2.5793727834606694

Epoch: 5| Step: 7
Training loss: 2.9787285400334755
Validation loss: 2.594106209653169

Epoch: 5| Step: 8
Training loss: 2.552570550823454
Validation loss: 2.616488451741418

Epoch: 5| Step: 9
Training loss: 2.751721450226427
Validation loss: 2.6245547374529825

Epoch: 5| Step: 10
Training loss: 2.4492409445017107
Validation loss: 2.648846376107041

Epoch: 430| Step: 0
Training loss: 2.632106607139083
Validation loss: 2.659672407964681

Epoch: 5| Step: 1
Training loss: 3.0278507324979835
Validation loss: 2.654578417547163

Epoch: 5| Step: 2
Training loss: 3.0029803412902623
Validation loss: 2.623986977991096

Epoch: 5| Step: 3
Training loss: 2.582130788018513
Validation loss: 2.6112136724314086

Epoch: 5| Step: 4
Training loss: 2.5333469323579627
Validation loss: 2.6093958666618438

Epoch: 5| Step: 5
Training loss: 3.2341106509480597
Validation loss: 2.602600596104753

Epoch: 5| Step: 6
Training loss: 2.5427662289748234
Validation loss: 2.599985141333063

Epoch: 5| Step: 7
Training loss: 3.066301283285041
Validation loss: 2.5985122709863897

Epoch: 5| Step: 8
Training loss: 2.5526292074381867
Validation loss: 2.603734498291066

Epoch: 5| Step: 9
Training loss: 2.8745848314471494
Validation loss: 2.5886353017977615

Epoch: 5| Step: 10
Training loss: 2.641940359223564
Validation loss: 2.583234991199092

Epoch: 431| Step: 0
Training loss: 3.1999439353799928
Validation loss: 2.6060164453505115

Epoch: 5| Step: 1
Training loss: 2.5262564866002992
Validation loss: 2.601400545545758

Epoch: 5| Step: 2
Training loss: 2.6538390943078225
Validation loss: 2.6314150977007467

Epoch: 5| Step: 3
Training loss: 2.5068682737980654
Validation loss: 2.61921202233237

Epoch: 5| Step: 4
Training loss: 2.645261317218178
Validation loss: 2.6394679852661906

Epoch: 5| Step: 5
Training loss: 2.7583932238143745
Validation loss: 2.6573453947636465

Epoch: 5| Step: 6
Training loss: 2.840488785603227
Validation loss: 2.666952191597538

Epoch: 5| Step: 7
Training loss: 2.85869019025879
Validation loss: 2.688045614212544

Epoch: 5| Step: 8
Training loss: 3.1443072695366827
Validation loss: 2.662297737141476

Epoch: 5| Step: 9
Training loss: 2.6797905282102645
Validation loss: 2.6234692643406303

Epoch: 5| Step: 10
Training loss: 2.9761916202361314
Validation loss: 2.582672284310943

Epoch: 432| Step: 0
Training loss: 2.823977807030723
Validation loss: 2.5612365345054493

Epoch: 5| Step: 1
Training loss: 2.8647936564597103
Validation loss: 2.5451350929725023

Epoch: 5| Step: 2
Training loss: 2.8984602030150275
Validation loss: 2.554613765432572

Epoch: 5| Step: 3
Training loss: 2.909042165629631
Validation loss: 2.549001788531925

Epoch: 5| Step: 4
Training loss: 2.273113424268002
Validation loss: 2.5387735141468943

Epoch: 5| Step: 5
Training loss: 2.7619438888960355
Validation loss: 2.549016842448284

Epoch: 5| Step: 6
Training loss: 3.270542658303841
Validation loss: 2.5484385404097214

Epoch: 5| Step: 7
Training loss: 2.699575132920903
Validation loss: 2.584718438751307

Epoch: 5| Step: 8
Training loss: 3.23895852952103
Validation loss: 2.608417506509198

Epoch: 5| Step: 9
Training loss: 2.685882081352724
Validation loss: 2.6369888397034393

Epoch: 5| Step: 10
Training loss: 2.3477939558978735
Validation loss: 2.659048657248501

Epoch: 433| Step: 0
Training loss: 2.826610264920192
Validation loss: 2.694111419666786

Epoch: 5| Step: 1
Training loss: 3.146228403374226
Validation loss: 2.7228230240380857

Epoch: 5| Step: 2
Training loss: 2.614953023805863
Validation loss: 2.7456684417140225

Epoch: 5| Step: 3
Training loss: 2.8638495782850497
Validation loss: 2.7048847645142526

Epoch: 5| Step: 4
Training loss: 2.7252668127624915
Validation loss: 2.6815735007361834

Epoch: 5| Step: 5
Training loss: 2.74964044127681
Validation loss: 2.650412736676638

Epoch: 5| Step: 6
Training loss: 2.8305326719381245
Validation loss: 2.6370862391617895

Epoch: 5| Step: 7
Training loss: 3.1239581087847346
Validation loss: 2.6113364520903386

Epoch: 5| Step: 8
Training loss: 2.058876206421338
Validation loss: 2.585715669736691

Epoch: 5| Step: 9
Training loss: 2.8860315064886786
Validation loss: 2.572139245071486

Epoch: 5| Step: 10
Training loss: 3.056049482324448
Validation loss: 2.5531655098848742

Epoch: 434| Step: 0
Training loss: 2.7938463232857327
Validation loss: 2.565773863211653

Epoch: 5| Step: 1
Training loss: 2.20152441009428
Validation loss: 2.562985981163679

Epoch: 5| Step: 2
Training loss: 3.008417717621057
Validation loss: 2.5800886653956754

Epoch: 5| Step: 3
Training loss: 2.5140208940874382
Validation loss: 2.581121872253508

Epoch: 5| Step: 4
Training loss: 2.9846298348638927
Validation loss: 2.6118516668917864

Epoch: 5| Step: 5
Training loss: 2.8087537611158218
Validation loss: 2.6329759564260695

Epoch: 5| Step: 6
Training loss: 2.6548122329551926
Validation loss: 2.6693299415380753

Epoch: 5| Step: 7
Training loss: 3.1297347249483245
Validation loss: 2.6626689969910657

Epoch: 5| Step: 8
Training loss: 3.124828486504237
Validation loss: 2.66845611616383

Epoch: 5| Step: 9
Training loss: 2.9526893253980067
Validation loss: 2.6314185056044046

Epoch: 5| Step: 10
Training loss: 2.5931528162297557
Validation loss: 2.601921427548608

Epoch: 435| Step: 0
Training loss: 2.6110710068817578
Validation loss: 2.5981391551016424

Epoch: 5| Step: 1
Training loss: 2.2850292724804486
Validation loss: 2.5817421913045604

Epoch: 5| Step: 2
Training loss: 3.229983827296534
Validation loss: 2.5740747182588906

Epoch: 5| Step: 3
Training loss: 3.2644265636072394
Validation loss: 2.578566192334882

Epoch: 5| Step: 4
Training loss: 2.513841269119943
Validation loss: 2.5899304127503773

Epoch: 5| Step: 5
Training loss: 3.1691356537115882
Validation loss: 2.5932231258733416

Epoch: 5| Step: 6
Training loss: 2.8532499154395947
Validation loss: 2.609563566117965

Epoch: 5| Step: 7
Training loss: 2.3430503309496014
Validation loss: 2.614380794364762

Epoch: 5| Step: 8
Training loss: 2.499315740403171
Validation loss: 2.6096976811839165

Epoch: 5| Step: 9
Training loss: 2.942584567997891
Validation loss: 2.6050081054471335

Epoch: 5| Step: 10
Training loss: 2.8168472600823247
Validation loss: 2.623920535149022

Epoch: 436| Step: 0
Training loss: 3.125843086956295
Validation loss: 2.6100355194947533

Epoch: 5| Step: 1
Training loss: 3.0677345849011184
Validation loss: 2.602594516490191

Epoch: 5| Step: 2
Training loss: 2.2090047739235517
Validation loss: 2.621186787276459

Epoch: 5| Step: 3
Training loss: 2.614000982551419
Validation loss: 2.6062978897540328

Epoch: 5| Step: 4
Training loss: 3.0927974891510317
Validation loss: 2.6030398087131874

Epoch: 5| Step: 5
Training loss: 2.829310553313702
Validation loss: 2.597503654173188

Epoch: 5| Step: 6
Training loss: 2.30650862817579
Validation loss: 2.606174055285363

Epoch: 5| Step: 7
Training loss: 2.9723942925704474
Validation loss: 2.644713821806409

Epoch: 5| Step: 8
Training loss: 2.8412452817878533
Validation loss: 2.6391780835853083

Epoch: 5| Step: 9
Training loss: 2.529822146983347
Validation loss: 2.657568361318783

Epoch: 5| Step: 10
Training loss: 2.895100361298334
Validation loss: 2.656466167998901

Epoch: 437| Step: 0
Training loss: 2.7076866160262916
Validation loss: 2.6447053952752038

Epoch: 5| Step: 1
Training loss: 3.0496544313870886
Validation loss: 2.62348527660646

Epoch: 5| Step: 2
Training loss: 2.6262029888551788
Validation loss: 2.602668205741311

Epoch: 5| Step: 3
Training loss: 2.2906087919028697
Validation loss: 2.6212450527272577

Epoch: 5| Step: 4
Training loss: 2.597470292627337
Validation loss: 2.5785500095005265

Epoch: 5| Step: 5
Training loss: 2.66015625
Validation loss: 2.597460160312765

Epoch: 5| Step: 6
Training loss: 2.922039986098562
Validation loss: 2.576202061269863

Epoch: 5| Step: 7
Training loss: 3.144900472063784
Validation loss: 2.575860567788294

Epoch: 5| Step: 8
Training loss: 3.039826677049444
Validation loss: 2.5900241606644903

Epoch: 5| Step: 9
Training loss: 2.8223528046656225
Validation loss: 2.6059710296490555

Epoch: 5| Step: 10
Training loss: 2.5570257376224763
Validation loss: 2.6239083535508327

Epoch: 438| Step: 0
Training loss: 2.812749300610041
Validation loss: 2.6287683528999315

Epoch: 5| Step: 1
Training loss: 2.7246817411704662
Validation loss: 2.6360774620884553

Epoch: 5| Step: 2
Training loss: 2.8377639311662834
Validation loss: 2.6261136163191705

Epoch: 5| Step: 3
Training loss: 2.792908823930975
Validation loss: 2.6288419803816465

Epoch: 5| Step: 4
Training loss: 2.845215472222451
Validation loss: 2.622726205689011

Epoch: 5| Step: 5
Training loss: 2.8082298923839915
Validation loss: 2.613997253796643

Epoch: 5| Step: 6
Training loss: 2.471671198992733
Validation loss: 2.6322900358311787

Epoch: 5| Step: 7
Training loss: 2.455210388553899
Validation loss: 2.6417644780233176

Epoch: 5| Step: 8
Training loss: 3.098408899834121
Validation loss: 2.652126927970409

Epoch: 5| Step: 9
Training loss: 2.7261616321988407
Validation loss: 2.6876541097325273

Epoch: 5| Step: 10
Training loss: 2.988474162737583
Validation loss: 2.649292981720707

Epoch: 439| Step: 0
Training loss: 2.9288493267153695
Validation loss: 2.648295669370961

Epoch: 5| Step: 1
Training loss: 2.3315396453673958
Validation loss: 2.6099227115284687

Epoch: 5| Step: 2
Training loss: 2.331411001255442
Validation loss: 2.5922537465104143

Epoch: 5| Step: 3
Training loss: 3.0171214131526263
Validation loss: 2.5882658096000064

Epoch: 5| Step: 4
Training loss: 2.3367424538040464
Validation loss: 2.5746561583468752

Epoch: 5| Step: 5
Training loss: 2.500204745491589
Validation loss: 2.5682356048285744

Epoch: 5| Step: 6
Training loss: 3.0459112746202717
Validation loss: 2.5619956519909635

Epoch: 5| Step: 7
Training loss: 3.024587644104584
Validation loss: 2.5759024100003924

Epoch: 5| Step: 8
Training loss: 2.954639510678337
Validation loss: 2.5711124333748945

Epoch: 5| Step: 9
Training loss: 2.832953614614287
Validation loss: 2.56918765562992

Epoch: 5| Step: 10
Training loss: 3.2106479040824856
Validation loss: 2.587563385538051

Epoch: 440| Step: 0
Training loss: 2.535114117523546
Validation loss: 2.586777629445994

Epoch: 5| Step: 1
Training loss: 2.6106161489375466
Validation loss: 2.6004204155372244

Epoch: 5| Step: 2
Training loss: 3.2127086645852243
Validation loss: 2.6216946108424075

Epoch: 5| Step: 3
Training loss: 3.163351096722084
Validation loss: 2.629222762627164

Epoch: 5| Step: 4
Training loss: 2.800799126348547
Validation loss: 2.63460407588718

Epoch: 5| Step: 5
Training loss: 2.7688482435031605
Validation loss: 2.640066037327843

Epoch: 5| Step: 6
Training loss: 2.6647767482667337
Validation loss: 2.624444608829563

Epoch: 5| Step: 7
Training loss: 2.4199488702212
Validation loss: 2.613389900855457

Epoch: 5| Step: 8
Training loss: 3.1578283612486677
Validation loss: 2.611734370056327

Epoch: 5| Step: 9
Training loss: 2.6867279008208698
Validation loss: 2.6115363306144026

Epoch: 5| Step: 10
Training loss: 2.4084006272608343
Validation loss: 2.6161953451902336

Epoch: 441| Step: 0
Training loss: 2.374724723523172
Validation loss: 2.622925429336178

Epoch: 5| Step: 1
Training loss: 2.8119468144939592
Validation loss: 2.6341171004698714

Epoch: 5| Step: 2
Training loss: 3.115738687382849
Validation loss: 2.691628317097981

Epoch: 5| Step: 3
Training loss: 2.618658307275165
Validation loss: 2.6784810593884685

Epoch: 5| Step: 4
Training loss: 2.5492700654037277
Validation loss: 2.6402058767229386

Epoch: 5| Step: 5
Training loss: 3.0594794500053246
Validation loss: 2.613714257956623

Epoch: 5| Step: 6
Training loss: 2.650607050335928
Validation loss: 2.603116134567202

Epoch: 5| Step: 7
Training loss: 2.7619781588133465
Validation loss: 2.583401658910785

Epoch: 5| Step: 8
Training loss: 3.006742847038598
Validation loss: 2.5606411415262187

Epoch: 5| Step: 9
Training loss: 2.7863345870351255
Validation loss: 2.5886420282086084

Epoch: 5| Step: 10
Training loss: 2.875483099112859
Validation loss: 2.5873941095573345

Epoch: 442| Step: 0
Training loss: 2.5283688761208425
Validation loss: 2.5979028530911292

Epoch: 5| Step: 1
Training loss: 3.1552007460773197
Validation loss: 2.6106755458747575

Epoch: 5| Step: 2
Training loss: 3.1410572266999224
Validation loss: 2.615398789848681

Epoch: 5| Step: 3
Training loss: 2.7386907905226816
Validation loss: 2.6256797738529176

Epoch: 5| Step: 4
Training loss: 2.681464404090204
Validation loss: 2.6281496422054875

Epoch: 5| Step: 5
Training loss: 3.0277060015120023
Validation loss: 2.6317771048304186

Epoch: 5| Step: 6
Training loss: 2.3597283509266984
Validation loss: 2.6507424447733388

Epoch: 5| Step: 7
Training loss: 2.5997959130223425
Validation loss: 2.63617197484554

Epoch: 5| Step: 8
Training loss: 2.5471123894830794
Validation loss: 2.6184351193421698

Epoch: 5| Step: 9
Training loss: 2.9060803435653386
Validation loss: 2.6047096687172355

Epoch: 5| Step: 10
Training loss: 2.7272458682038123
Validation loss: 2.612102873471056

Epoch: 443| Step: 0
Training loss: 3.2516745141536068
Validation loss: 2.6370679072851995

Epoch: 5| Step: 1
Training loss: 2.380340694918073
Validation loss: 2.620996296161508

Epoch: 5| Step: 2
Training loss: 2.738520591386792
Validation loss: 2.654349825984353

Epoch: 5| Step: 3
Training loss: 2.5223397622002794
Validation loss: 2.6612230560574557

Epoch: 5| Step: 4
Training loss: 2.884059067902965
Validation loss: 2.658379998731181

Epoch: 5| Step: 5
Training loss: 2.5376818850119536
Validation loss: 2.658725293120173

Epoch: 5| Step: 6
Training loss: 2.512083700431746
Validation loss: 2.646792529503808

Epoch: 5| Step: 7
Training loss: 2.6532125721420083
Validation loss: 2.6344006585567907

Epoch: 5| Step: 8
Training loss: 3.202740008780415
Validation loss: 2.6295561756937946

Epoch: 5| Step: 9
Training loss: 2.683675662016356
Validation loss: 2.607444420867939

Epoch: 5| Step: 10
Training loss: 3.022905169797488
Validation loss: 2.606652195855721

Epoch: 444| Step: 0
Training loss: 2.6275010682602007
Validation loss: 2.5947000626916585

Epoch: 5| Step: 1
Training loss: 2.83307496931131
Validation loss: 2.56881065363911

Epoch: 5| Step: 2
Training loss: 2.7958707231806206
Validation loss: 2.571624173818483

Epoch: 5| Step: 3
Training loss: 2.537408284000258
Validation loss: 2.56748734178632

Epoch: 5| Step: 4
Training loss: 2.61829355126683
Validation loss: 2.55764163783112

Epoch: 5| Step: 5
Training loss: 2.4097128387571405
Validation loss: 2.5573497612154674

Epoch: 5| Step: 6
Training loss: 2.958753923059787
Validation loss: 2.5654301731610327

Epoch: 5| Step: 7
Training loss: 3.2392173306842618
Validation loss: 2.575366085116726

Epoch: 5| Step: 8
Training loss: 2.9168507835767574
Validation loss: 2.5823145520418773

Epoch: 5| Step: 9
Training loss: 2.865745909624626
Validation loss: 2.602182356033842

Epoch: 5| Step: 10
Training loss: 2.7831519834939518
Validation loss: 2.6281657156970937

Epoch: 445| Step: 0
Training loss: 2.8074148194731414
Validation loss: 2.632673859045865

Epoch: 5| Step: 1
Training loss: 2.6310938084290463
Validation loss: 2.6784931392332694

Epoch: 5| Step: 2
Training loss: 3.096102350046408
Validation loss: 2.691063870498922

Epoch: 5| Step: 3
Training loss: 3.0599678626274
Validation loss: 2.719974725230038

Epoch: 5| Step: 4
Training loss: 2.4569166487271654
Validation loss: 2.6925405198245187

Epoch: 5| Step: 5
Training loss: 3.1105896384061285
Validation loss: 2.644451214124554

Epoch: 5| Step: 6
Training loss: 3.05367143127827
Validation loss: 2.6394516202580847

Epoch: 5| Step: 7
Training loss: 2.78436764631574
Validation loss: 2.6330622919715814

Epoch: 5| Step: 8
Training loss: 2.418862518137985
Validation loss: 2.6175423056086675

Epoch: 5| Step: 9
Training loss: 2.2337152534092137
Validation loss: 2.57466199376644

Epoch: 5| Step: 10
Training loss: 2.749394783699813
Validation loss: 2.578587450481474

Epoch: 446| Step: 0
Training loss: 2.717142002279781
Validation loss: 2.5760466679624856

Epoch: 5| Step: 1
Training loss: 2.6931851602467005
Validation loss: 2.571484667465154

Epoch: 5| Step: 2
Training loss: 2.7245356067802686
Validation loss: 2.580921494282096

Epoch: 5| Step: 3
Training loss: 2.2931625570245675
Validation loss: 2.6071040126709093

Epoch: 5| Step: 4
Training loss: 2.776246960881754
Validation loss: 2.60330248237029

Epoch: 5| Step: 5
Training loss: 2.5432782197266173
Validation loss: 2.624803709591038

Epoch: 5| Step: 6
Training loss: 2.925029174137527
Validation loss: 2.627906932043241

Epoch: 5| Step: 7
Training loss: 2.825106195124868
Validation loss: 2.6482207468244363

Epoch: 5| Step: 8
Training loss: 2.752976107603487
Validation loss: 2.6374435778797185

Epoch: 5| Step: 9
Training loss: 3.403477931922147
Validation loss: 2.6551969270877116

Epoch: 5| Step: 10
Training loss: 2.6721011060556608
Validation loss: 2.6525457719887373

Epoch: 447| Step: 0
Training loss: 2.347775981471312
Validation loss: 2.6779706890517185

Epoch: 5| Step: 1
Training loss: 3.1315670439212586
Validation loss: 2.6654850324767567

Epoch: 5| Step: 2
Training loss: 3.011262732986
Validation loss: 2.6696868545075834

Epoch: 5| Step: 3
Training loss: 2.7660539369875305
Validation loss: 2.6430477108944577

Epoch: 5| Step: 4
Training loss: 2.683957359856447
Validation loss: 2.631938072574447

Epoch: 5| Step: 5
Training loss: 3.0617027023373775
Validation loss: 2.598367625430817

Epoch: 5| Step: 6
Training loss: 2.358768410421308
Validation loss: 2.57667859205695

Epoch: 5| Step: 7
Training loss: 2.7939148480895484
Validation loss: 2.5739550983243307

Epoch: 5| Step: 8
Training loss: 2.5090184624708387
Validation loss: 2.570313960199421

Epoch: 5| Step: 9
Training loss: 2.7142431678879233
Validation loss: 2.5566776528369557

Epoch: 5| Step: 10
Training loss: 3.098388123611788
Validation loss: 2.5753203001169918

Epoch: 448| Step: 0
Training loss: 2.7751344459200764
Validation loss: 2.576275641681773

Epoch: 5| Step: 1
Training loss: 2.8281034184259424
Validation loss: 2.5840842038655536

Epoch: 5| Step: 2
Training loss: 2.753044783671726
Validation loss: 2.5832428054614036

Epoch: 5| Step: 3
Training loss: 2.8551265652422915
Validation loss: 2.605346870674216

Epoch: 5| Step: 4
Training loss: 2.7718778281213554
Validation loss: 2.6396366373288482

Epoch: 5| Step: 5
Training loss: 3.0914661955980356
Validation loss: 2.680188021324965

Epoch: 5| Step: 6
Training loss: 2.5061343273381413
Validation loss: 2.673088187375184

Epoch: 5| Step: 7
Training loss: 2.396942766368054
Validation loss: 2.667603374045509

Epoch: 5| Step: 8
Training loss: 2.6730945324805924
Validation loss: 2.6509352556150168

Epoch: 5| Step: 9
Training loss: 2.847403558265074
Validation loss: 2.6207780907282046

Epoch: 5| Step: 10
Training loss: 2.9105373465863695
Validation loss: 2.6045625699905575

Epoch: 449| Step: 0
Training loss: 3.2243525069462073
Validation loss: 2.588804075750847

Epoch: 5| Step: 1
Training loss: 2.6057535041639857
Validation loss: 2.5902106080743046

Epoch: 5| Step: 2
Training loss: 3.0010336049024686
Validation loss: 2.5935763555331994

Epoch: 5| Step: 3
Training loss: 2.999043153122267
Validation loss: 2.5934170409053814

Epoch: 5| Step: 4
Training loss: 2.8252385199124292
Validation loss: 2.583777335598444

Epoch: 5| Step: 5
Training loss: 2.31678087058205
Validation loss: 2.5916635122426066

Epoch: 5| Step: 6
Training loss: 2.933950186662163
Validation loss: 2.5834948449218995

Epoch: 5| Step: 7
Training loss: 2.277974324417437
Validation loss: 2.592474400270551

Epoch: 5| Step: 8
Training loss: 2.56738959159551
Validation loss: 2.600294623156441

Epoch: 5| Step: 9
Training loss: 2.6049589147274883
Validation loss: 2.610186322929601

Epoch: 5| Step: 10
Training loss: 2.972954753871457
Validation loss: 2.6259251129985284

Epoch: 450| Step: 0
Training loss: 2.442065047832563
Validation loss: 2.630111489492406

Epoch: 5| Step: 1
Training loss: 2.4088756553447497
Validation loss: 2.634775698503506

Epoch: 5| Step: 2
Training loss: 2.8459598213410358
Validation loss: 2.6355756829779624

Epoch: 5| Step: 3
Training loss: 2.859123677533061
Validation loss: 2.648829490272839

Epoch: 5| Step: 4
Training loss: 2.2813869069443804
Validation loss: 2.656892535426833

Epoch: 5| Step: 5
Training loss: 2.9403643339528243
Validation loss: 2.6308822101596823

Epoch: 5| Step: 6
Training loss: 2.9457730608596493
Validation loss: 2.644086393956566

Epoch: 5| Step: 7
Training loss: 2.7564136966872654
Validation loss: 2.615728838153178

Epoch: 5| Step: 8
Training loss: 2.683930799260161
Validation loss: 2.586541429283987

Epoch: 5| Step: 9
Training loss: 3.250188968740053
Validation loss: 2.5837510717592265

Epoch: 5| Step: 10
Training loss: 2.821267766664175
Validation loss: 2.5631124933483793

Epoch: 451| Step: 0
Training loss: 2.5988085034029766
Validation loss: 2.573679609912881

Epoch: 5| Step: 1
Training loss: 2.7169307014857824
Validation loss: 2.5808511182036282

Epoch: 5| Step: 2
Training loss: 2.836274098159008
Validation loss: 2.572539161135234

Epoch: 5| Step: 3
Training loss: 2.7709103528172125
Validation loss: 2.585722700189128

Epoch: 5| Step: 4
Training loss: 2.9105171952649767
Validation loss: 2.584769978482604

Epoch: 5| Step: 5
Training loss: 3.0551927543803936
Validation loss: 2.5814505926634306

Epoch: 5| Step: 6
Training loss: 2.8233741774263743
Validation loss: 2.600968227711274

Epoch: 5| Step: 7
Training loss: 2.5814522282999213
Validation loss: 2.5934942311866274

Epoch: 5| Step: 8
Training loss: 2.7974846031712968
Validation loss: 2.608251351214111

Epoch: 5| Step: 9
Training loss: 2.583413543276317
Validation loss: 2.593080996005543

Epoch: 5| Step: 10
Training loss: 2.6049275215009247
Validation loss: 2.633975574229256

Epoch: 452| Step: 0
Training loss: 3.024603724729967
Validation loss: 2.655068421245883

Epoch: 5| Step: 1
Training loss: 2.7738791530499483
Validation loss: 2.670410332413216

Epoch: 5| Step: 2
Training loss: 2.49842451043298
Validation loss: 2.6422282715253105

Epoch: 5| Step: 3
Training loss: 2.776930809172801
Validation loss: 2.6597870268765855

Epoch: 5| Step: 4
Training loss: 2.712073536058754
Validation loss: 2.655331553584579

Epoch: 5| Step: 5
Training loss: 3.030430161814855
Validation loss: 2.6136867383286617

Epoch: 5| Step: 6
Training loss: 2.4809844674881543
Validation loss: 2.591701433449557

Epoch: 5| Step: 7
Training loss: 2.3435372828274352
Validation loss: 2.571851514766546

Epoch: 5| Step: 8
Training loss: 2.779214950286984
Validation loss: 2.582027422454545

Epoch: 5| Step: 9
Training loss: 2.8050900651204587
Validation loss: 2.5956850282651853

Epoch: 5| Step: 10
Training loss: 3.0534371941683145
Validation loss: 2.589236106742872

Epoch: 453| Step: 0
Training loss: 2.8994832992638466
Validation loss: 2.6035653323673253

Epoch: 5| Step: 1
Training loss: 2.6150649844204064
Validation loss: 2.6051182409112847

Epoch: 5| Step: 2
Training loss: 2.429146660470996
Validation loss: 2.629558339068847

Epoch: 5| Step: 3
Training loss: 2.9711618364002077
Validation loss: 2.6432414738911962

Epoch: 5| Step: 4
Training loss: 2.5898920805551184
Validation loss: 2.6542665511421384

Epoch: 5| Step: 5
Training loss: 2.911692292032076
Validation loss: 2.6691488037708266

Epoch: 5| Step: 6
Training loss: 2.7131519782204214
Validation loss: 2.6495356031525987

Epoch: 5| Step: 7
Training loss: 2.4431468404641223
Validation loss: 2.6200668851582334

Epoch: 5| Step: 8
Training loss: 3.1860475409840707
Validation loss: 2.6144570097594095

Epoch: 5| Step: 9
Training loss: 2.803648179646365
Validation loss: 2.6065038563349634

Epoch: 5| Step: 10
Training loss: 2.6529314741134105
Validation loss: 2.6125150025879944

Epoch: 454| Step: 0
Training loss: 2.670627057168223
Validation loss: 2.587806105097407

Epoch: 5| Step: 1
Training loss: 3.1856682694048466
Validation loss: 2.598804659135524

Epoch: 5| Step: 2
Training loss: 2.7137773134463923
Validation loss: 2.607617356166695

Epoch: 5| Step: 3
Training loss: 2.450219249646425
Validation loss: 2.590418998810385

Epoch: 5| Step: 4
Training loss: 3.035245484129048
Validation loss: 2.5918724003986955

Epoch: 5| Step: 5
Training loss: 2.5812389641403484
Validation loss: 2.5989338291288866

Epoch: 5| Step: 6
Training loss: 2.8886030393991615
Validation loss: 2.603411419696456

Epoch: 5| Step: 7
Training loss: 2.0210780228281964
Validation loss: 2.61958670015664

Epoch: 5| Step: 8
Training loss: 3.280096232700554
Validation loss: 2.6439752133378134

Epoch: 5| Step: 9
Training loss: 2.7870158745868268
Validation loss: 2.6365534117348264

Epoch: 5| Step: 10
Training loss: 2.4239525528661123
Validation loss: 2.6300758776010107

Epoch: 455| Step: 0
Training loss: 2.6258742375296693
Validation loss: 2.623724227981387

Epoch: 5| Step: 1
Training loss: 2.778554403033649
Validation loss: 2.6370974800962146

Epoch: 5| Step: 2
Training loss: 2.4270100944067066
Validation loss: 2.6206507496944798

Epoch: 5| Step: 3
Training loss: 3.0633770990687115
Validation loss: 2.5832723816446808

Epoch: 5| Step: 4
Training loss: 2.68218024062528
Validation loss: 2.5833748265988636

Epoch: 5| Step: 5
Training loss: 2.362869201552947
Validation loss: 2.578026319636941

Epoch: 5| Step: 6
Training loss: 3.179871349971279
Validation loss: 2.559412442987863

Epoch: 5| Step: 7
Training loss: 2.8267398202924863
Validation loss: 2.5684373502897206

Epoch: 5| Step: 8
Training loss: 2.807446666017315
Validation loss: 2.5713379820853914

Epoch: 5| Step: 9
Training loss: 2.8594935658371337
Validation loss: 2.5647110217933506

Epoch: 5| Step: 10
Training loss: 2.6075118488689917
Validation loss: 2.583278001106032

Epoch: 456| Step: 0
Training loss: 3.143812696920004
Validation loss: 2.6124176349973367

Epoch: 5| Step: 1
Training loss: 2.8194583856982325
Validation loss: 2.661098383560085

Epoch: 5| Step: 2
Training loss: 2.630125128811705
Validation loss: 2.7002079749895715

Epoch: 5| Step: 3
Training loss: 2.1825756777372676
Validation loss: 2.7073664429362143

Epoch: 5| Step: 4
Training loss: 3.134381060912946
Validation loss: 2.7205514612550368

Epoch: 5| Step: 5
Training loss: 2.767641011602481
Validation loss: 2.72144566636429

Epoch: 5| Step: 6
Training loss: 3.114916899477322
Validation loss: 2.689749966124987

Epoch: 5| Step: 7
Training loss: 2.549185331022088
Validation loss: 2.6562227550559463

Epoch: 5| Step: 8
Training loss: 3.078561354947196
Validation loss: 2.6186739044994587

Epoch: 5| Step: 9
Training loss: 2.7291238990131155
Validation loss: 2.573979799822178

Epoch: 5| Step: 10
Training loss: 2.417833956164339
Validation loss: 2.559670489595111

Epoch: 457| Step: 0
Training loss: 2.701655964423257
Validation loss: 2.5560645252314913

Epoch: 5| Step: 1
Training loss: 2.167607017787872
Validation loss: 2.553606718713072

Epoch: 5| Step: 2
Training loss: 3.1716876796788736
Validation loss: 2.5427208117635387

Epoch: 5| Step: 3
Training loss: 2.8353738355986953
Validation loss: 2.5711479376508986

Epoch: 5| Step: 4
Training loss: 3.2043527622690102
Validation loss: 2.5845560308958757

Epoch: 5| Step: 5
Training loss: 2.766931774659013
Validation loss: 2.5827268188836645

Epoch: 5| Step: 6
Training loss: 2.945834085841175
Validation loss: 2.6045016447810103

Epoch: 5| Step: 7
Training loss: 2.518163975394835
Validation loss: 2.604110636118606

Epoch: 5| Step: 8
Training loss: 2.633628560268728
Validation loss: 2.61938772367801

Epoch: 5| Step: 9
Training loss: 2.81452902612782
Validation loss: 2.631246205117366

Epoch: 5| Step: 10
Training loss: 2.8849507493917494
Validation loss: 2.6702126968584534

Epoch: 458| Step: 0
Training loss: 2.474736163015784
Validation loss: 2.634576975891565

Epoch: 5| Step: 1
Training loss: 2.962454455061787
Validation loss: 2.6036330991105285

Epoch: 5| Step: 2
Training loss: 3.0313492591573232
Validation loss: 2.5925702642770725

Epoch: 5| Step: 3
Training loss: 2.9544200177008024
Validation loss: 2.5697926960898627

Epoch: 5| Step: 4
Training loss: 2.2752730572496978
Validation loss: 2.5827302940091643

Epoch: 5| Step: 5
Training loss: 2.404868583974801
Validation loss: 2.562476995661513

Epoch: 5| Step: 6
Training loss: 2.881375086255747
Validation loss: 2.5770937689651814

Epoch: 5| Step: 7
Training loss: 2.8057877871475503
Validation loss: 2.575516238953421

Epoch: 5| Step: 8
Training loss: 3.137554432674143
Validation loss: 2.586043973750121

Epoch: 5| Step: 9
Training loss: 2.8008954864146345
Validation loss: 2.583717547520365

Epoch: 5| Step: 10
Training loss: 2.376728934354669
Validation loss: 2.5936592413329578

Epoch: 459| Step: 0
Training loss: 1.858868377651177
Validation loss: 2.576952909280182

Epoch: 5| Step: 1
Training loss: 2.338495595318176
Validation loss: 2.5818852253681994

Epoch: 5| Step: 2
Training loss: 3.0899051703558786
Validation loss: 2.610589307630468

Epoch: 5| Step: 3
Training loss: 2.591570478496278
Validation loss: 2.616925640104436

Epoch: 5| Step: 4
Training loss: 3.193137475566345
Validation loss: 2.5890631754618196

Epoch: 5| Step: 5
Training loss: 2.8269609616434406
Validation loss: 2.617123814412382

Epoch: 5| Step: 6
Training loss: 2.5978256743973613
Validation loss: 2.6048348601181464

Epoch: 5| Step: 7
Training loss: 2.871263979062771
Validation loss: 2.6049963919322296

Epoch: 5| Step: 8
Training loss: 3.107345148526361
Validation loss: 2.60454691680564

Epoch: 5| Step: 9
Training loss: 2.7010874042005035
Validation loss: 2.576069110260935

Epoch: 5| Step: 10
Training loss: 2.744334714277181
Validation loss: 2.607339191711986

Epoch: 460| Step: 0
Training loss: 3.4557595537924697
Validation loss: 2.6054850952601964

Epoch: 5| Step: 1
Training loss: 2.9815999655373266
Validation loss: 2.6021773020109364

Epoch: 5| Step: 2
Training loss: 2.833730464105696
Validation loss: 2.6039315135161445

Epoch: 5| Step: 3
Training loss: 2.5410061483477686
Validation loss: 2.619328796391225

Epoch: 5| Step: 4
Training loss: 2.8571727172108656
Validation loss: 2.623375609292393

Epoch: 5| Step: 5
Training loss: 2.302204410826927
Validation loss: 2.6394681795205295

Epoch: 5| Step: 6
Training loss: 2.6262862369410436
Validation loss: 2.6262112570667733

Epoch: 5| Step: 7
Training loss: 2.477917033028104
Validation loss: 2.641473076568257

Epoch: 5| Step: 8
Training loss: 2.674985892713193
Validation loss: 2.618352484228426

Epoch: 5| Step: 9
Training loss: 2.3804373488375457
Validation loss: 2.615050549922939

Epoch: 5| Step: 10
Training loss: 2.957470799460763
Validation loss: 2.5988435829439402

Epoch: 461| Step: 0
Training loss: 3.0137617452575336
Validation loss: 2.584033391561072

Epoch: 5| Step: 1
Training loss: 2.4910034428239243
Validation loss: 2.5967047651873445

Epoch: 5| Step: 2
Training loss: 2.8191855760151228
Validation loss: 2.5857243004050776

Epoch: 5| Step: 3
Training loss: 2.8340957588164875
Validation loss: 2.5875028507073696

Epoch: 5| Step: 4
Training loss: 2.8699983959658724
Validation loss: 2.5895097916550327

Epoch: 5| Step: 5
Training loss: 3.050270262454006
Validation loss: 2.575974380757352

Epoch: 5| Step: 6
Training loss: 2.910496552303273
Validation loss: 2.5668378480683702

Epoch: 5| Step: 7
Training loss: 2.9597054285959032
Validation loss: 2.5666244093707546

Epoch: 5| Step: 8
Training loss: 2.6022813508366758
Validation loss: 2.5804146491948012

Epoch: 5| Step: 9
Training loss: 2.007130310298644
Validation loss: 2.5858115899907075

Epoch: 5| Step: 10
Training loss: 2.3132144752148482
Validation loss: 2.6132132870873113

Epoch: 462| Step: 0
Training loss: 2.790920205216987
Validation loss: 2.603701555288982

Epoch: 5| Step: 1
Training loss: 2.7755065936692467
Validation loss: 2.6259967690892276

Epoch: 5| Step: 2
Training loss: 2.889529788825977
Validation loss: 2.6052061333765333

Epoch: 5| Step: 3
Training loss: 3.3639179118932945
Validation loss: 2.603008644469766

Epoch: 5| Step: 4
Training loss: 2.2537874557420894
Validation loss: 2.5855378130580315

Epoch: 5| Step: 5
Training loss: 2.6732028985329293
Validation loss: 2.6049908675437847

Epoch: 5| Step: 6
Training loss: 2.716822587747886
Validation loss: 2.585097511059603

Epoch: 5| Step: 7
Training loss: 2.794223658201108
Validation loss: 2.5829208867123747

Epoch: 5| Step: 8
Training loss: 2.6063005072001553
Validation loss: 2.601574679805052

Epoch: 5| Step: 9
Training loss: 2.857598591970116
Validation loss: 2.5838547324985246

Epoch: 5| Step: 10
Training loss: 2.168938387293368
Validation loss: 2.6189324963079637

Epoch: 463| Step: 0
Training loss: 3.1028684081666174
Validation loss: 2.632451206911195

Epoch: 5| Step: 1
Training loss: 2.3901455466990953
Validation loss: 2.6152914516858203

Epoch: 5| Step: 2
Training loss: 2.637267014757684
Validation loss: 2.612871889890913

Epoch: 5| Step: 3
Training loss: 2.887927637181662
Validation loss: 2.60401683712704

Epoch: 5| Step: 4
Training loss: 2.903702963137298
Validation loss: 2.602640050212254

Epoch: 5| Step: 5
Training loss: 2.9024842178217938
Validation loss: 2.6100983771721067

Epoch: 5| Step: 6
Training loss: 3.071503153557628
Validation loss: 2.5808078423619736

Epoch: 5| Step: 7
Training loss: 2.7879234573934535
Validation loss: 2.589985914981926

Epoch: 5| Step: 8
Training loss: 2.1392338819931953
Validation loss: 2.5731591257439366

Epoch: 5| Step: 9
Training loss: 2.572940584346991
Validation loss: 2.59143152259951

Epoch: 5| Step: 10
Training loss: 2.5865193890726643
Validation loss: 2.5987197079557953

Epoch: 464| Step: 0
Training loss: 2.8959520896510353
Validation loss: 2.595440186982888

Epoch: 5| Step: 1
Training loss: 2.1551565078937647
Validation loss: 2.599198858812039

Epoch: 5| Step: 2
Training loss: 2.185389672455989
Validation loss: 2.5832496213366354

Epoch: 5| Step: 3
Training loss: 3.034995370575392
Validation loss: 2.583610087828711

Epoch: 5| Step: 4
Training loss: 2.6688727750387917
Validation loss: 2.572888437984538

Epoch: 5| Step: 5
Training loss: 2.8285407503674502
Validation loss: 2.579668798829983

Epoch: 5| Step: 6
Training loss: 2.931254626435165
Validation loss: 2.59010447188928

Epoch: 5| Step: 7
Training loss: 3.073893470471945
Validation loss: 2.593825233298455

Epoch: 5| Step: 8
Training loss: 2.924475344040847
Validation loss: 2.605658684018902

Epoch: 5| Step: 9
Training loss: 2.3968601072164546
Validation loss: 2.584159709638266

Epoch: 5| Step: 10
Training loss: 2.808151698440862
Validation loss: 2.6228701510632986

Epoch: 465| Step: 0
Training loss: 2.788276369235405
Validation loss: 2.6242052028398293

Epoch: 5| Step: 1
Training loss: 3.1529236440949795
Validation loss: 2.632895889633994

Epoch: 5| Step: 2
Training loss: 2.355459032940156
Validation loss: 2.6304401352011735

Epoch: 5| Step: 3
Training loss: 3.1416414807943402
Validation loss: 2.6655125443783554

Epoch: 5| Step: 4
Training loss: 2.8548013765686404
Validation loss: 2.6661763179418094

Epoch: 5| Step: 5
Training loss: 2.8299938792240016
Validation loss: 2.6183280789565333

Epoch: 5| Step: 6
Training loss: 3.1225810034501764
Validation loss: 2.599491233838027

Epoch: 5| Step: 7
Training loss: 1.9504989059159634
Validation loss: 2.5785369225767925

Epoch: 5| Step: 8
Training loss: 2.2959854583279737
Validation loss: 2.556930407873073

Epoch: 5| Step: 9
Training loss: 3.2312854993629943
Validation loss: 2.5392393024437654

Epoch: 5| Step: 10
Training loss: 2.102108682329008
Validation loss: 2.536628046519424

Epoch: 466| Step: 0
Training loss: 2.973928332247063
Validation loss: 2.5527924162625713

Epoch: 5| Step: 1
Training loss: 2.5968699247491958
Validation loss: 2.5617770183798956

Epoch: 5| Step: 2
Training loss: 2.670665891241887
Validation loss: 2.5574773310829864

Epoch: 5| Step: 3
Training loss: 3.057224010821541
Validation loss: 2.556100756045333

Epoch: 5| Step: 4
Training loss: 3.354209299389185
Validation loss: 2.5565135859727888

Epoch: 5| Step: 5
Training loss: 2.279533472014969
Validation loss: 2.584131941738841

Epoch: 5| Step: 6
Training loss: 2.156971465224896
Validation loss: 2.6194079213934316

Epoch: 5| Step: 7
Training loss: 2.2090301374017556
Validation loss: 2.6329485319909876

Epoch: 5| Step: 8
Training loss: 2.506762608643373
Validation loss: 2.6388340892689692

Epoch: 5| Step: 9
Training loss: 2.9439046312931767
Validation loss: 2.665835345828715

Epoch: 5| Step: 10
Training loss: 3.2552919585612643
Validation loss: 2.62161356583606

Epoch: 467| Step: 0
Training loss: 2.750896481129404
Validation loss: 2.6027806061502097

Epoch: 5| Step: 1
Training loss: 2.8440987509364235
Validation loss: 2.576845385367121

Epoch: 5| Step: 2
Training loss: 2.5508298533367193
Validation loss: 2.5544383959384493

Epoch: 5| Step: 3
Training loss: 2.623913767275778
Validation loss: 2.535946648706146

Epoch: 5| Step: 4
Training loss: 2.659158527963924
Validation loss: 2.5331810660037513

Epoch: 5| Step: 5
Training loss: 2.891951467980031
Validation loss: 2.5237576648483393

Epoch: 5| Step: 6
Training loss: 2.6869295091372893
Validation loss: 2.521795872307449

Epoch: 5| Step: 7
Training loss: 2.4911669133213166
Validation loss: 2.539908276108817

Epoch: 5| Step: 8
Training loss: 3.333705897173609
Validation loss: 2.5396227338599484

Epoch: 5| Step: 9
Training loss: 2.62910603505233
Validation loss: 2.5454855467560273

Epoch: 5| Step: 10
Training loss: 2.8423122921768758
Validation loss: 2.5570695613251133

Epoch: 468| Step: 0
Training loss: 2.7263696815495164
Validation loss: 2.551082528529289

Epoch: 5| Step: 1
Training loss: 2.927628508238533
Validation loss: 2.541768859901434

Epoch: 5| Step: 2
Training loss: 2.108793390412168
Validation loss: 2.5630988244959845

Epoch: 5| Step: 3
Training loss: 2.5398822106811414
Validation loss: 2.5500499393914273

Epoch: 5| Step: 4
Training loss: 2.8144605796657
Validation loss: 2.5755306810125047

Epoch: 5| Step: 5
Training loss: 2.7016175758126724
Validation loss: 2.564419453450331

Epoch: 5| Step: 6
Training loss: 2.774499824055075
Validation loss: 2.569278097343354

Epoch: 5| Step: 7
Training loss: 2.7172042135434253
Validation loss: 2.574707290630327

Epoch: 5| Step: 8
Training loss: 2.7229600077426532
Validation loss: 2.6027967988791882

Epoch: 5| Step: 9
Training loss: 3.0100214785699846
Validation loss: 2.6201363492973644

Epoch: 5| Step: 10
Training loss: 3.0411859071424354
Validation loss: 2.6503994832345126

Epoch: 469| Step: 0
Training loss: 2.701184143788795
Validation loss: 2.6758026095846867

Epoch: 5| Step: 1
Training loss: 3.180067334931716
Validation loss: 2.678891353106232

Epoch: 5| Step: 2
Training loss: 2.743471719798027
Validation loss: 2.6512628516979215

Epoch: 5| Step: 3
Training loss: 2.9271207831940824
Validation loss: 2.6064052530528743

Epoch: 5| Step: 4
Training loss: 3.0241537502500377
Validation loss: 2.5822070875756777

Epoch: 5| Step: 5
Training loss: 2.13648687077333
Validation loss: 2.5630970201140033

Epoch: 5| Step: 6
Training loss: 3.179693048645727
Validation loss: 2.543355208071556

Epoch: 5| Step: 7
Training loss: 1.922952179530883
Validation loss: 2.549926460817495

Epoch: 5| Step: 8
Training loss: 2.5648101070078786
Validation loss: 2.542198468120295

Epoch: 5| Step: 9
Training loss: 2.7322154209106952
Validation loss: 2.5259965661482604

Epoch: 5| Step: 10
Training loss: 3.0004488291369893
Validation loss: 2.5366259342621045

Epoch: 470| Step: 0
Training loss: 2.6319315990267618
Validation loss: 2.5448811896073935

Epoch: 5| Step: 1
Training loss: 2.961326392409383
Validation loss: 2.5361955579902538

Epoch: 5| Step: 2
Training loss: 2.8077845568319924
Validation loss: 2.5417857580124745

Epoch: 5| Step: 3
Training loss: 2.2904630679234366
Validation loss: 2.552456493775252

Epoch: 5| Step: 4
Training loss: 3.265879059906467
Validation loss: 2.5610356882906684

Epoch: 5| Step: 5
Training loss: 2.650348345335672
Validation loss: 2.556248265639482

Epoch: 5| Step: 6
Training loss: 2.4953608384583035
Validation loss: 2.5927974396312603

Epoch: 5| Step: 7
Training loss: 2.924898103422626
Validation loss: 2.6236123276280225

Epoch: 5| Step: 8
Training loss: 3.030712591295182
Validation loss: 2.6443163827084346

Epoch: 5| Step: 9
Training loss: 2.3593577201159954
Validation loss: 2.6219712836218467

Epoch: 5| Step: 10
Training loss: 2.643515364964283
Validation loss: 2.614200929972132

Epoch: 471| Step: 0
Training loss: 2.7973805402215666
Validation loss: 2.5890821819124317

Epoch: 5| Step: 1
Training loss: 2.537983826612039
Validation loss: 2.594651196260298

Epoch: 5| Step: 2
Training loss: 2.644528905960464
Validation loss: 2.5658620892798507

Epoch: 5| Step: 3
Training loss: 3.13807020135354
Validation loss: 2.551020793373576

Epoch: 5| Step: 4
Training loss: 2.73686776023686
Validation loss: 2.515756459802149

Epoch: 5| Step: 5
Training loss: 2.407325405234916
Validation loss: 2.5232667038775785

Epoch: 5| Step: 6
Training loss: 2.844040237539142
Validation loss: 2.5235515439053686

Epoch: 5| Step: 7
Training loss: 3.110333932200818
Validation loss: 2.522048558295725

Epoch: 5| Step: 8
Training loss: 3.049368439620604
Validation loss: 2.5415678652302796

Epoch: 5| Step: 9
Training loss: 2.261972679944582
Validation loss: 2.5779767284347406

Epoch: 5| Step: 10
Training loss: 2.802922195361825
Validation loss: 2.59228928362991

Epoch: 472| Step: 0
Training loss: 2.971588063151659
Validation loss: 2.6194119380160488

Epoch: 5| Step: 1
Training loss: 2.854008709697091
Validation loss: 2.629297110605991

Epoch: 5| Step: 2
Training loss: 2.678113558554496
Validation loss: 2.6365043370047405

Epoch: 5| Step: 3
Training loss: 2.7669722729152944
Validation loss: 2.6256712891651275

Epoch: 5| Step: 4
Training loss: 2.233866386946409
Validation loss: 2.619057163490949

Epoch: 5| Step: 5
Training loss: 2.4723004270416435
Validation loss: 2.600054996057128

Epoch: 5| Step: 6
Training loss: 2.7972464714358742
Validation loss: 2.5933528427560417

Epoch: 5| Step: 7
Training loss: 2.8630199443243702
Validation loss: 2.600078012031243

Epoch: 5| Step: 8
Training loss: 1.9475248082041359
Validation loss: 2.596750510782974

Epoch: 5| Step: 9
Training loss: 3.1120923307691135
Validation loss: 2.6005125668143956

Epoch: 5| Step: 10
Training loss: 3.2134904573998355
Validation loss: 2.5907031163330903

Epoch: 473| Step: 0
Training loss: 3.1812016211767586
Validation loss: 2.5819552560264563

Epoch: 5| Step: 1
Training loss: 2.679948443728211
Validation loss: 2.574655381186084

Epoch: 5| Step: 2
Training loss: 2.8005817081550637
Validation loss: 2.588119983195102

Epoch: 5| Step: 3
Training loss: 2.659059273147015
Validation loss: 2.5729223872946463

Epoch: 5| Step: 4
Training loss: 2.498595987891113
Validation loss: 2.562862149551169

Epoch: 5| Step: 5
Training loss: 3.039147696980201
Validation loss: 2.570041675514612

Epoch: 5| Step: 6
Training loss: 2.3636702288355695
Validation loss: 2.559811331839644

Epoch: 5| Step: 7
Training loss: 2.5988789599165867
Validation loss: 2.5719860204405633

Epoch: 5| Step: 8
Training loss: 2.443105951304719
Validation loss: 2.56751921176777

Epoch: 5| Step: 9
Training loss: 2.746135597398518
Validation loss: 2.5749543910453085

Epoch: 5| Step: 10
Training loss: 2.932856521723175
Validation loss: 2.588560210810839

Epoch: 474| Step: 0
Training loss: 3.202392792169148
Validation loss: 2.612525109878265

Epoch: 5| Step: 1
Training loss: 2.4187968720224253
Validation loss: 2.6359269446093387

Epoch: 5| Step: 2
Training loss: 2.889819058624494
Validation loss: 2.634486202012047

Epoch: 5| Step: 3
Training loss: 2.7418879592620558
Validation loss: 2.6099198757224493

Epoch: 5| Step: 4
Training loss: 2.8817881183024303
Validation loss: 2.5841080247965778

Epoch: 5| Step: 5
Training loss: 2.6207246023001107
Validation loss: 2.559295889106941

Epoch: 5| Step: 6
Training loss: 3.0687593603671206
Validation loss: 2.5413577485292644

Epoch: 5| Step: 7
Training loss: 2.872000414877519
Validation loss: 2.531174917258295

Epoch: 5| Step: 8
Training loss: 2.114783692537642
Validation loss: 2.530047136073815

Epoch: 5| Step: 9
Training loss: 3.426297191363073
Validation loss: 2.5258442789656637

Epoch: 5| Step: 10
Training loss: 1.8098316281866231
Validation loss: 2.5164521363937387

Epoch: 475| Step: 0
Training loss: 3.0341224824628332
Validation loss: 2.524232985422925

Epoch: 5| Step: 1
Training loss: 2.526410598293443
Validation loss: 2.531289154402147

Epoch: 5| Step: 2
Training loss: 2.876431481953557
Validation loss: 2.540374005193208

Epoch: 5| Step: 3
Training loss: 2.6891925716029164
Validation loss: 2.5342551576803665

Epoch: 5| Step: 4
Training loss: 2.6943431050840236
Validation loss: 2.563874753060259

Epoch: 5| Step: 5
Training loss: 3.1782440733382122
Validation loss: 2.5791052114908934

Epoch: 5| Step: 6
Training loss: 2.4525420838769016
Validation loss: 2.6065270514159735

Epoch: 5| Step: 7
Training loss: 2.46117252256969
Validation loss: 2.6130450752503727

Epoch: 5| Step: 8
Training loss: 2.7721330180709494
Validation loss: 2.603270574810627

Epoch: 5| Step: 9
Training loss: 2.50359610364068
Validation loss: 2.617569133402156

Epoch: 5| Step: 10
Training loss: 2.746014828585646
Validation loss: 2.6004898415628808

Epoch: 476| Step: 0
Training loss: 2.503551059233457
Validation loss: 2.6255234539693952

Epoch: 5| Step: 1
Training loss: 2.3024251922814445
Validation loss: 2.586672539732346

Epoch: 5| Step: 2
Training loss: 2.356469797259347
Validation loss: 2.6159167571171293

Epoch: 5| Step: 3
Training loss: 2.917481571979394
Validation loss: 2.597258090058045

Epoch: 5| Step: 4
Training loss: 2.790218167269268
Validation loss: 2.5798471783755628

Epoch: 5| Step: 5
Training loss: 3.265785760892371
Validation loss: 2.5705354849848727

Epoch: 5| Step: 6
Training loss: 2.8830746580599946
Validation loss: 2.5778232247445323

Epoch: 5| Step: 7
Training loss: 2.4801186622410603
Validation loss: 2.5707180065999755

Epoch: 5| Step: 8
Training loss: 2.9280631890383555
Validation loss: 2.569925526889813

Epoch: 5| Step: 9
Training loss: 2.782013691838987
Validation loss: 2.559407226378843

Epoch: 5| Step: 10
Training loss: 2.531267425100372
Validation loss: 2.5577365892619857

Epoch: 477| Step: 0
Training loss: 2.8938598677868295
Validation loss: 2.552974776446118

Epoch: 5| Step: 1
Training loss: 2.2719336710703963
Validation loss: 2.564044747899766

Epoch: 5| Step: 2
Training loss: 2.395422217437352
Validation loss: 2.5599960631165946

Epoch: 5| Step: 3
Training loss: 2.461624776147596
Validation loss: 2.561310032375857

Epoch: 5| Step: 4
Training loss: 2.834404649337586
Validation loss: 2.583242444223484

Epoch: 5| Step: 5
Training loss: 2.809047359926938
Validation loss: 2.622441426331013

Epoch: 5| Step: 6
Training loss: 2.385336617760541
Validation loss: 2.612371634805335

Epoch: 5| Step: 7
Training loss: 3.332105664834339
Validation loss: 2.640316697571646

Epoch: 5| Step: 8
Training loss: 2.605848110325019
Validation loss: 2.6591259505487574

Epoch: 5| Step: 9
Training loss: 3.087245383941637
Validation loss: 2.6496382615210057

Epoch: 5| Step: 10
Training loss: 2.8155778785683063
Validation loss: 2.616845911025288

Epoch: 478| Step: 0
Training loss: 2.7850788635374486
Validation loss: 2.570685394424068

Epoch: 5| Step: 1
Training loss: 2.264332685546393
Validation loss: 2.5453384599026774

Epoch: 5| Step: 2
Training loss: 2.279392269854631
Validation loss: 2.533754054864678

Epoch: 5| Step: 3
Training loss: 2.5036460991268017
Validation loss: 2.5222256706184343

Epoch: 5| Step: 4
Training loss: 3.1831310474241685
Validation loss: 2.517557903589714

Epoch: 5| Step: 5
Training loss: 2.5637925772476975
Validation loss: 2.5212774154227833

Epoch: 5| Step: 6
Training loss: 2.722943196438643
Validation loss: 2.51607763974408

Epoch: 5| Step: 7
Training loss: 3.1029171231531043
Validation loss: 2.5195276887230498

Epoch: 5| Step: 8
Training loss: 3.135029377046775
Validation loss: 2.5255790088009844

Epoch: 5| Step: 9
Training loss: 3.069112994756785
Validation loss: 2.549979810656916

Epoch: 5| Step: 10
Training loss: 2.4909508007432892
Validation loss: 2.554784237014558

Epoch: 479| Step: 0
Training loss: 2.783622672599619
Validation loss: 2.565850404378458

Epoch: 5| Step: 1
Training loss: 2.749903417105001
Validation loss: 2.5988404460171184

Epoch: 5| Step: 2
Training loss: 2.764721394138482
Validation loss: 2.6110121137967397

Epoch: 5| Step: 3
Training loss: 2.8982652474190442
Validation loss: 2.6143106458013596

Epoch: 5| Step: 4
Training loss: 2.1109589457746094
Validation loss: 2.6200797881287676

Epoch: 5| Step: 5
Training loss: 2.647193458972826
Validation loss: 2.6085621235310548

Epoch: 5| Step: 6
Training loss: 2.3401268993105284
Validation loss: 2.586498834426536

Epoch: 5| Step: 7
Training loss: 2.831978212057235
Validation loss: 2.5829479083496136

Epoch: 5| Step: 8
Training loss: 2.807016579780497
Validation loss: 2.577975158215059

Epoch: 5| Step: 9
Training loss: 2.6682262826953984
Validation loss: 2.5888087043149515

Epoch: 5| Step: 10
Training loss: 3.332480146573589
Validation loss: 2.579787180958603

Epoch: 480| Step: 0
Training loss: 2.179966734361133
Validation loss: 2.5690683879184317

Epoch: 5| Step: 1
Training loss: 2.6527980140149423
Validation loss: 2.58583283913515

Epoch: 5| Step: 2
Training loss: 3.326375295407299
Validation loss: 2.5479658015355384

Epoch: 5| Step: 3
Training loss: 2.6457111200256618
Validation loss: 2.5623941081988293

Epoch: 5| Step: 4
Training loss: 3.088886329671164
Validation loss: 2.583191089372559

Epoch: 5| Step: 5
Training loss: 2.688639554460321
Validation loss: 2.5582316936752987

Epoch: 5| Step: 6
Training loss: 3.2186800754692375
Validation loss: 2.563103434466131

Epoch: 5| Step: 7
Training loss: 2.468296443947744
Validation loss: 2.574712263160221

Epoch: 5| Step: 8
Training loss: 2.493180128106287
Validation loss: 2.5801989901903233

Epoch: 5| Step: 9
Training loss: 2.6668428025091164
Validation loss: 2.5898822066440474

Epoch: 5| Step: 10
Training loss: 1.9737943784183187
Validation loss: 2.5809588199076887

Epoch: 481| Step: 0
Training loss: 2.897493522314248
Validation loss: 2.570273912134354

Epoch: 5| Step: 1
Training loss: 2.9046880975469227
Validation loss: 2.579644865352996

Epoch: 5| Step: 2
Training loss: 2.7370242119060726
Validation loss: 2.5639305333594336

Epoch: 5| Step: 3
Training loss: 2.6105079247267255
Validation loss: 2.563927895656349

Epoch: 5| Step: 4
Training loss: 2.1730485119660043
Validation loss: 2.5753678017646338

Epoch: 5| Step: 5
Training loss: 2.653715023577529
Validation loss: 2.5760235218671474

Epoch: 5| Step: 6
Training loss: 2.789742437663333
Validation loss: 2.572788695843343

Epoch: 5| Step: 7
Training loss: 3.162067603906856
Validation loss: 2.573702842829701

Epoch: 5| Step: 8
Training loss: 2.412381472665429
Validation loss: 2.581549993187549

Epoch: 5| Step: 9
Training loss: 2.6485241000890367
Validation loss: 2.5831318707925055

Epoch: 5| Step: 10
Training loss: 2.876147165727251
Validation loss: 2.583565725008601

Epoch: 482| Step: 0
Training loss: 2.7855244910732075
Validation loss: 2.581739686986027

Epoch: 5| Step: 1
Training loss: 2.533562533985878
Validation loss: 2.587158087560132

Epoch: 5| Step: 2
Training loss: 2.5459449801856615
Validation loss: 2.5707585578306094

Epoch: 5| Step: 3
Training loss: 2.858316527855704
Validation loss: 2.576945969308136

Epoch: 5| Step: 4
Training loss: 3.0206672535109034
Validation loss: 2.5596647406856974

Epoch: 5| Step: 5
Training loss: 2.5390462552064466
Validation loss: 2.5676360703070804

Epoch: 5| Step: 6
Training loss: 2.5099527608370042
Validation loss: 2.5693603052495777

Epoch: 5| Step: 7
Training loss: 3.1672002610493877
Validation loss: 2.5848780435404852

Epoch: 5| Step: 8
Training loss: 2.468810744685082
Validation loss: 2.5808621570726484

Epoch: 5| Step: 9
Training loss: 2.701225539506689
Validation loss: 2.5837343925447884

Epoch: 5| Step: 10
Training loss: 2.5010518722188264
Validation loss: 2.602733428000904

Epoch: 483| Step: 0
Training loss: 2.034235711317452
Validation loss: 2.6325694163317497

Epoch: 5| Step: 1
Training loss: 2.9918582426342586
Validation loss: 2.6211387863069113

Epoch: 5| Step: 2
Training loss: 2.952882787065953
Validation loss: 2.6256059805607554

Epoch: 5| Step: 3
Training loss: 2.403954637280372
Validation loss: 2.606414384709564

Epoch: 5| Step: 4
Training loss: 3.1058651845035907
Validation loss: 2.5804984962089317

Epoch: 5| Step: 5
Training loss: 3.5062483462841465
Validation loss: 2.5798966044428004

Epoch: 5| Step: 6
Training loss: 2.1953502936860225
Validation loss: 2.569572843251546

Epoch: 5| Step: 7
Training loss: 2.3514510727143323
Validation loss: 2.5560999857798024

Epoch: 5| Step: 8
Training loss: 2.823490370744647
Validation loss: 2.579547056088326

Epoch: 5| Step: 9
Training loss: 2.3571477823907827
Validation loss: 2.5784282189055783

Epoch: 5| Step: 10
Training loss: 2.5404192776692907
Validation loss: 2.5815438739288243

Epoch: 484| Step: 0
Training loss: 2.6410865154662644
Validation loss: 2.5743642863557183

Epoch: 5| Step: 1
Training loss: 2.9294039576332027
Validation loss: 2.54898556081741

Epoch: 5| Step: 2
Training loss: 2.454470611644995
Validation loss: 2.580644585400435

Epoch: 5| Step: 3
Training loss: 2.9053000261388364
Validation loss: 2.575817316586027

Epoch: 5| Step: 4
Training loss: 2.227950456585494
Validation loss: 2.566975731400914

Epoch: 5| Step: 5
Training loss: 2.8542456140296544
Validation loss: 2.5946173870041926

Epoch: 5| Step: 6
Training loss: 2.0579818018710165
Validation loss: 2.5836789256926753

Epoch: 5| Step: 7
Training loss: 2.78457425792752
Validation loss: 2.5910556447103814

Epoch: 5| Step: 8
Training loss: 3.1052890941547404
Validation loss: 2.588753364010869

Epoch: 5| Step: 9
Training loss: 2.4132316665767095
Validation loss: 2.5953193480285774

Epoch: 5| Step: 10
Training loss: 3.2285586040979983
Validation loss: 2.5865702942728825

Epoch: 485| Step: 0
Training loss: 3.167982146097216
Validation loss: 2.5644526701441164

Epoch: 5| Step: 1
Training loss: 3.00522428846614
Validation loss: 2.555780864259

Epoch: 5| Step: 2
Training loss: 2.3114116272599143
Validation loss: 2.564610790183245

Epoch: 5| Step: 3
Training loss: 2.1737593565394544
Validation loss: 2.5452660801521394

Epoch: 5| Step: 4
Training loss: 2.5919592317094793
Validation loss: 2.557017449222727

Epoch: 5| Step: 5
Training loss: 2.680768476165507
Validation loss: 2.5632192951261947

Epoch: 5| Step: 6
Training loss: 3.0908747711928237
Validation loss: 2.5689092359356698

Epoch: 5| Step: 7
Training loss: 2.7438873499943885
Validation loss: 2.566734016457999

Epoch: 5| Step: 8
Training loss: 2.383159274523334
Validation loss: 2.5664800193574324

Epoch: 5| Step: 9
Training loss: 2.8949094620483438
Validation loss: 2.55358216951161

Epoch: 5| Step: 10
Training loss: 2.5220724375983266
Validation loss: 2.554034387909393

Epoch: 486| Step: 0
Training loss: 3.0304595860585857
Validation loss: 2.5553412798659223

Epoch: 5| Step: 1
Training loss: 2.480943433142104
Validation loss: 2.5549623702079076

Epoch: 5| Step: 2
Training loss: 2.6747229495029763
Validation loss: 2.576577986733347

Epoch: 5| Step: 3
Training loss: 2.4817205679500813
Validation loss: 2.575604618029877

Epoch: 5| Step: 4
Training loss: 2.3271446468115897
Validation loss: 2.61711532451622

Epoch: 5| Step: 5
Training loss: 3.0181587919775374
Validation loss: 2.619900631053891

Epoch: 5| Step: 6
Training loss: 2.479252939299241
Validation loss: 2.6076506763749285

Epoch: 5| Step: 7
Training loss: 2.015941624575848
Validation loss: 2.6200089486968228

Epoch: 5| Step: 8
Training loss: 2.955603634133314
Validation loss: 2.6278894794909053

Epoch: 5| Step: 9
Training loss: 2.8855531478902474
Validation loss: 2.608649323090541

Epoch: 5| Step: 10
Training loss: 3.2980149454272083
Validation loss: 2.5808479971542617

Epoch: 487| Step: 0
Training loss: 2.477393170468011
Validation loss: 2.5379662355005737

Epoch: 5| Step: 1
Training loss: 2.77601319108187
Validation loss: 2.5207880664063933

Epoch: 5| Step: 2
Training loss: 3.123917353964316
Validation loss: 2.525050463152391

Epoch: 5| Step: 3
Training loss: 2.666502967419378
Validation loss: 2.5157289100749862

Epoch: 5| Step: 4
Training loss: 3.2485552290756856
Validation loss: 2.501501307339493

Epoch: 5| Step: 5
Training loss: 2.4492896159504562
Validation loss: 2.5141852907442432

Epoch: 5| Step: 6
Training loss: 2.8055029403570497
Validation loss: 2.513108885774622

Epoch: 5| Step: 7
Training loss: 3.048794811587297
Validation loss: 2.517769559473628

Epoch: 5| Step: 8
Training loss: 2.0627306028976773
Validation loss: 2.5313508704760843

Epoch: 5| Step: 9
Training loss: 2.6108798867060883
Validation loss: 2.5458051592518873

Epoch: 5| Step: 10
Training loss: 2.5451279715569437
Validation loss: 2.5523161235530187

Epoch: 488| Step: 0
Training loss: 2.9125886109588173
Validation loss: 2.580440849630312

Epoch: 5| Step: 1
Training loss: 2.7257014010611256
Validation loss: 2.5832368757941087

Epoch: 5| Step: 2
Training loss: 3.280627382335354
Validation loss: 2.5958350427601165

Epoch: 5| Step: 3
Training loss: 2.794835460507873
Validation loss: 2.5944554515733746

Epoch: 5| Step: 4
Training loss: 2.308226373813308
Validation loss: 2.6317280637750686

Epoch: 5| Step: 5
Training loss: 2.811366721817603
Validation loss: 2.6292700173387167

Epoch: 5| Step: 6
Training loss: 2.572488252336761
Validation loss: 2.615805655228406

Epoch: 5| Step: 7
Training loss: 2.8273843880921716
Validation loss: 2.5941382190626427

Epoch: 5| Step: 8
Training loss: 2.4378032984692566
Validation loss: 2.5894549356089103

Epoch: 5| Step: 9
Training loss: 2.4694296951435146
Validation loss: 2.622243288256343

Epoch: 5| Step: 10
Training loss: 2.4783422771703787
Validation loss: 2.5599016141043296

Epoch: 489| Step: 0
Training loss: 2.3063923365391212
Validation loss: 2.548162837699245

Epoch: 5| Step: 1
Training loss: 3.2520900754758912
Validation loss: 2.54236045888537

Epoch: 5| Step: 2
Training loss: 2.529559100487452
Validation loss: 2.538065225961065

Epoch: 5| Step: 3
Training loss: 2.7223073552458734
Validation loss: 2.5298802356063677

Epoch: 5| Step: 4
Training loss: 2.616571883491503
Validation loss: 2.5308319054396953

Epoch: 5| Step: 5
Training loss: 2.7478354344907054
Validation loss: 2.5180667386592686

Epoch: 5| Step: 6
Training loss: 2.776389171232873
Validation loss: 2.5186849124174846

Epoch: 5| Step: 7
Training loss: 2.831478596399789
Validation loss: 2.5330025214318117

Epoch: 5| Step: 8
Training loss: 2.62025895447862
Validation loss: 2.549427516163966

Epoch: 5| Step: 9
Training loss: 2.791701919181255
Validation loss: 2.580667889723108

Epoch: 5| Step: 10
Training loss: 2.6829747981289387
Validation loss: 2.603902053350895

Epoch: 490| Step: 0
Training loss: 2.9132016626045565
Validation loss: 2.5990183994688434

Epoch: 5| Step: 1
Training loss: 2.86045258442295
Validation loss: 2.5975065084693245

Epoch: 5| Step: 2
Training loss: 2.9126650652954886
Validation loss: 2.570130957036897

Epoch: 5| Step: 3
Training loss: 2.4099456348856187
Validation loss: 2.5694830464666625

Epoch: 5| Step: 4
Training loss: 2.593220484353143
Validation loss: 2.565676321521305

Epoch: 5| Step: 5
Training loss: 2.6556990108110803
Validation loss: 2.5674295468553243

Epoch: 5| Step: 6
Training loss: 2.8802169238624056
Validation loss: 2.5478838088978595

Epoch: 5| Step: 7
Training loss: 2.562161772201344
Validation loss: 2.5600493933782897

Epoch: 5| Step: 8
Training loss: 2.753080290172621
Validation loss: 2.545115392691076

Epoch: 5| Step: 9
Training loss: 2.7339126632012603
Validation loss: 2.570319783035584

Epoch: 5| Step: 10
Training loss: 2.193962686776048
Validation loss: 2.5831421967638506

Epoch: 491| Step: 0
Training loss: 3.237298353830531
Validation loss: 2.5809724080793806

Epoch: 5| Step: 1
Training loss: 2.8303982360799846
Validation loss: 2.5895591610039945

Epoch: 5| Step: 2
Training loss: 1.9518288545897802
Validation loss: 2.580598326804115

Epoch: 5| Step: 3
Training loss: 2.553220741970142
Validation loss: 2.603723308272095

Epoch: 5| Step: 4
Training loss: 2.7409753973440214
Validation loss: 2.5777473021398256

Epoch: 5| Step: 5
Training loss: 2.4864422336712906
Validation loss: 2.592687095720203

Epoch: 5| Step: 6
Training loss: 2.8763979954383263
Validation loss: 2.581122484081435

Epoch: 5| Step: 7
Training loss: 2.7001516052350953
Validation loss: 2.556525745748738

Epoch: 5| Step: 8
Training loss: 2.722777879753838
Validation loss: 2.5930045082354884

Epoch: 5| Step: 9
Training loss: 2.7435713099379875
Validation loss: 2.5745113380244335

Epoch: 5| Step: 10
Training loss: 2.6122648945567324
Validation loss: 2.57377399258188

Epoch: 492| Step: 0
Training loss: 2.692162129376158
Validation loss: 2.5716526499815444

Epoch: 5| Step: 1
Training loss: 3.0993709172019828
Validation loss: 2.580105866974571

Epoch: 5| Step: 2
Training loss: 3.0366681627869365
Validation loss: 2.5933330965357024

Epoch: 5| Step: 3
Training loss: 1.8755450410206673
Validation loss: 2.593033241959144

Epoch: 5| Step: 4
Training loss: 2.422575916876201
Validation loss: 2.6105685496923883

Epoch: 5| Step: 5
Training loss: 2.584022573590958
Validation loss: 2.621999151393528

Epoch: 5| Step: 6
Training loss: 2.669223562923032
Validation loss: 2.6682472127525423

Epoch: 5| Step: 7
Training loss: 2.9149286450507335
Validation loss: 2.6219532361924185

Epoch: 5| Step: 8
Training loss: 2.6594500843749143
Validation loss: 2.5954630739889364

Epoch: 5| Step: 9
Training loss: 2.755727179456932
Validation loss: 2.576530217355319

Epoch: 5| Step: 10
Training loss: 2.8753151098968566
Validation loss: 2.5291898003403896

Epoch: 493| Step: 0
Training loss: 2.990310598207966
Validation loss: 2.53640822891954

Epoch: 5| Step: 1
Training loss: 2.5144110173114202
Validation loss: 2.519256685709889

Epoch: 5| Step: 2
Training loss: 2.631354497071387
Validation loss: 2.5193699557355944

Epoch: 5| Step: 3
Training loss: 2.990418391729287
Validation loss: 2.5150016532616397

Epoch: 5| Step: 4
Training loss: 2.502549302170917
Validation loss: 2.5240521035706007

Epoch: 5| Step: 5
Training loss: 2.841387427547981
Validation loss: 2.5200772807239504

Epoch: 5| Step: 6
Training loss: 2.4441292431898463
Validation loss: 2.527499231646508

Epoch: 5| Step: 7
Training loss: 2.8080696816071846
Validation loss: 2.531817747407963

Epoch: 5| Step: 8
Training loss: 2.7166318863902674
Validation loss: 2.5154644254954945

Epoch: 5| Step: 9
Training loss: 2.5035877233472115
Validation loss: 2.543913037340989

Epoch: 5| Step: 10
Training loss: 2.8012641267024514
Validation loss: 2.5571177423690776

Epoch: 494| Step: 0
Training loss: 2.9970615619271896
Validation loss: 2.5879841040586067

Epoch: 5| Step: 1
Training loss: 2.6844287445052757
Validation loss: 2.6007712166973334

Epoch: 5| Step: 2
Training loss: 2.873188111278224
Validation loss: 2.6639023291426254

Epoch: 5| Step: 3
Training loss: 2.6570890111345613
Validation loss: 2.655295469896273

Epoch: 5| Step: 4
Training loss: 2.1046951939499543
Validation loss: 2.640627191198869

Epoch: 5| Step: 5
Training loss: 2.769591681893131
Validation loss: 2.595190991902216

Epoch: 5| Step: 6
Training loss: 2.8366856284428588
Validation loss: 2.574729383166666

Epoch: 5| Step: 7
Training loss: 2.5096272114981817
Validation loss: 2.5707283978919664

Epoch: 5| Step: 8
Training loss: 2.610306990243291
Validation loss: 2.535764010735312

Epoch: 5| Step: 9
Training loss: 2.871184263294765
Validation loss: 2.5318152595242505

Epoch: 5| Step: 10
Training loss: 2.7407391410208186
Validation loss: 2.541707550101958

Epoch: 495| Step: 0
Training loss: 2.964906151558398
Validation loss: 2.5299121658952073

Epoch: 5| Step: 1
Training loss: 2.535944882121832
Validation loss: 2.5372783279361006

Epoch: 5| Step: 2
Training loss: 3.006933465300836
Validation loss: 2.55295178167475

Epoch: 5| Step: 3
Training loss: 2.691374802094257
Validation loss: 2.531841062718684

Epoch: 5| Step: 4
Training loss: 2.3741108083084397
Validation loss: 2.5518814516026262

Epoch: 5| Step: 5
Training loss: 2.597056567733849
Validation loss: 2.5624047858684307

Epoch: 5| Step: 6
Training loss: 2.296177557070923
Validation loss: 2.555478570645574

Epoch: 5| Step: 7
Training loss: 2.9590973382418397
Validation loss: 2.5731064941185853

Epoch: 5| Step: 8
Training loss: 2.4132595269981256
Validation loss: 2.59059455899515

Epoch: 5| Step: 9
Training loss: 2.974861359771793
Validation loss: 2.627016809437741

Epoch: 5| Step: 10
Training loss: 2.6104279181219407
Validation loss: 2.590741708651705

Epoch: 496| Step: 0
Training loss: 2.686638006320922
Validation loss: 2.557201521165804

Epoch: 5| Step: 1
Training loss: 2.4063631501780165
Validation loss: 2.5432469572250453

Epoch: 5| Step: 2
Training loss: 2.4501426694162904
Validation loss: 2.533963036628366

Epoch: 5| Step: 3
Training loss: 2.6416304440426686
Validation loss: 2.5320921296763355

Epoch: 5| Step: 4
Training loss: 2.64840959292312
Validation loss: 2.534543171835617

Epoch: 5| Step: 5
Training loss: 2.4492177765523384
Validation loss: 2.5304239632567067

Epoch: 5| Step: 6
Training loss: 2.31108947212938
Validation loss: 2.5726434101620024

Epoch: 5| Step: 7
Training loss: 2.642140241546568
Validation loss: 2.5533042199063223

Epoch: 5| Step: 8
Training loss: 2.9784403807094124
Validation loss: 2.555345507548849

Epoch: 5| Step: 9
Training loss: 2.8254304979828975
Validation loss: 2.5719546533575137

Epoch: 5| Step: 10
Training loss: 3.4774452717448994
Validation loss: 2.593849495517507

Epoch: 497| Step: 0
Training loss: 3.0254142666724753
Validation loss: 2.580688397432452

Epoch: 5| Step: 1
Training loss: 2.361080437504606
Validation loss: 2.5668240422489528

Epoch: 5| Step: 2
Training loss: 2.9382454758129475
Validation loss: 2.5834754530297808

Epoch: 5| Step: 3
Training loss: 2.1571840115413563
Validation loss: 2.5785666586201197

Epoch: 5| Step: 4
Training loss: 2.198870616074664
Validation loss: 2.5879766953980483

Epoch: 5| Step: 5
Training loss: 2.6970166996830294
Validation loss: 2.5995049485118784

Epoch: 5| Step: 6
Training loss: 2.8596826606703707
Validation loss: 2.6013981734828193

Epoch: 5| Step: 7
Training loss: 2.8627549503514476
Validation loss: 2.5528149937011166

Epoch: 5| Step: 8
Training loss: 2.2107479162451176
Validation loss: 2.530986825379316

Epoch: 5| Step: 9
Training loss: 3.0743983602828635
Validation loss: 2.5298182890886913

Epoch: 5| Step: 10
Training loss: 3.049465388987121
Validation loss: 2.511253751120872

Epoch: 498| Step: 0
Training loss: 2.721205205658197
Validation loss: 2.510971684698601

Epoch: 5| Step: 1
Training loss: 2.827828238919069
Validation loss: 2.5088413445928737

Epoch: 5| Step: 2
Training loss: 2.5734186853903434
Validation loss: 2.5115450042068392

Epoch: 5| Step: 3
Training loss: 2.8325125870589116
Validation loss: 2.5072941270379214

Epoch: 5| Step: 4
Training loss: 2.7281257061340187
Validation loss: 2.5150833943002415

Epoch: 5| Step: 5
Training loss: 2.1714317912422056
Validation loss: 2.534752252385579

Epoch: 5| Step: 6
Training loss: 2.6416557151334774
Validation loss: 2.5370277135807906

Epoch: 5| Step: 7
Training loss: 2.939801227830765
Validation loss: 2.550381756990932

Epoch: 5| Step: 8
Training loss: 2.653668484327523
Validation loss: 2.5710773733186096

Epoch: 5| Step: 9
Training loss: 2.8723307948330548
Validation loss: 2.5640279944859024

Epoch: 5| Step: 10
Training loss: 2.7889255522116057
Validation loss: 2.587269945000204

Epoch: 499| Step: 0
Training loss: 1.8634227003232402
Validation loss: 2.574757801090533

Epoch: 5| Step: 1
Training loss: 3.04724353615528
Validation loss: 2.5841887093638967

Epoch: 5| Step: 2
Training loss: 2.5161479145837125
Validation loss: 2.584521231569091

Epoch: 5| Step: 3
Training loss: 3.1264306417605456
Validation loss: 2.5672001086845455

Epoch: 5| Step: 4
Training loss: 3.055269073773893
Validation loss: 2.551652866412557

Epoch: 5| Step: 5
Training loss: 2.559311068787862
Validation loss: 2.5577013759240783

Epoch: 5| Step: 6
Training loss: 2.921370682057877
Validation loss: 2.5455456738566435

Epoch: 5| Step: 7
Training loss: 2.7888746866199776
Validation loss: 2.542644274057931

Epoch: 5| Step: 8
Training loss: 2.6886868185071156
Validation loss: 2.536060988827022

Epoch: 5| Step: 9
Training loss: 2.0746077982674413
Validation loss: 2.5331465952116807

Epoch: 5| Step: 10
Training loss: 2.5377720766825567
Validation loss: 2.544766763742228

Epoch: 500| Step: 0
Training loss: 2.826862875528457
Validation loss: 2.5385324853552

Epoch: 5| Step: 1
Training loss: 2.679552436294184
Validation loss: 2.527705990125304

Epoch: 5| Step: 2
Training loss: 2.6948567322989896
Validation loss: 2.5320706816442535

Epoch: 5| Step: 3
Training loss: 2.7889612858035404
Validation loss: 2.5489504790320336

Epoch: 5| Step: 4
Training loss: 2.531327611416262
Validation loss: 2.536624845791976

Epoch: 5| Step: 5
Training loss: 2.901174728291481
Validation loss: 2.547832938731393

Epoch: 5| Step: 6
Training loss: 2.62731350266817
Validation loss: 2.547424921381389

Epoch: 5| Step: 7
Training loss: 2.3840068887956667
Validation loss: 2.557039657501803

Epoch: 5| Step: 8
Training loss: 2.6128494065544206
Validation loss: 2.5407052914161317

Epoch: 5| Step: 9
Training loss: 2.7607970257586385
Validation loss: 2.547520714508889

Epoch: 5| Step: 10
Training loss: 2.667313368184447
Validation loss: 2.5735387227424336

Testing loss: 2.79999305444189
