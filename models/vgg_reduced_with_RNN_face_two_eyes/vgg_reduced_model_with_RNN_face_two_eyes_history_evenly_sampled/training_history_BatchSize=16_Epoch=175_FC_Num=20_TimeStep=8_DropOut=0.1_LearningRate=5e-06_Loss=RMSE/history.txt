Epoch: 1| Step: 0
Training loss: 5.931902043445032
Validation loss: 5.772710998544749

Epoch: 6| Step: 1
Training loss: 5.904109829467773
Validation loss: 5.767463437887933

Epoch: 6| Step: 2
Training loss: 5.994398681415661
Validation loss: 5.762035192410577

Epoch: 6| Step: 3
Training loss: 5.432792291831305
Validation loss: 5.756716104792236

Epoch: 6| Step: 4
Training loss: 6.3019532581703634
Validation loss: 5.751288021401917

Epoch: 6| Step: 5
Training loss: 6.649092717052525
Validation loss: 5.746288562360903

Epoch: 6| Step: 6
Training loss: 5.32320017597736
Validation loss: 5.740981056772157

Epoch: 6| Step: 7
Training loss: 6.268162087648281
Validation loss: 5.735875800639745

Epoch: 6| Step: 8
Training loss: 4.9943052286376
Validation loss: 5.730349619460532

Epoch: 6| Step: 9
Training loss: 4.997409340139653
Validation loss: 5.72499779354013

Epoch: 6| Step: 10
Training loss: 6.046237803555897
Validation loss: 5.719578166196376

Epoch: 6| Step: 11
Training loss: 5.751878846082362
Validation loss: 5.713602597998916

Epoch: 6| Step: 12
Training loss: 5.480533482556052
Validation loss: 5.707637457322001

Epoch: 6| Step: 13
Training loss: 5.31744262549578
Validation loss: 5.701568900974718

Epoch: 2| Step: 0
Training loss: 5.5531760948118905
Validation loss: 5.694576660003285

Epoch: 6| Step: 1
Training loss: 6.31295412148625
Validation loss: 5.687929871243549

Epoch: 6| Step: 2
Training loss: 5.686621629567183
Validation loss: 5.681024596697102

Epoch: 6| Step: 3
Training loss: 5.309530707417353
Validation loss: 5.673770708986692

Epoch: 6| Step: 4
Training loss: 5.3270547188994986
Validation loss: 5.665716650201588

Epoch: 6| Step: 5
Training loss: 5.971507129686972
Validation loss: 5.657952107336839

Epoch: 6| Step: 6
Training loss: 5.179184833145914
Validation loss: 5.6496550164734805

Epoch: 6| Step: 7
Training loss: 5.584211517656345
Validation loss: 5.639971649833506

Epoch: 6| Step: 8
Training loss: 6.3967211311145995
Validation loss: 5.631151532321131

Epoch: 6| Step: 9
Training loss: 6.413539702544398
Validation loss: 5.621720827343022

Epoch: 6| Step: 10
Training loss: 5.2964763660146685
Validation loss: 5.610943548921883

Epoch: 6| Step: 11
Training loss: 5.297178726715623
Validation loss: 5.600724854999267

Epoch: 6| Step: 12
Training loss: 5.456703389175685
Validation loss: 5.5892565107130014

Epoch: 6| Step: 13
Training loss: 5.423466781321758
Validation loss: 5.576371146977597

Epoch: 3| Step: 0
Training loss: 6.24705924468009
Validation loss: 5.564775953250296

Epoch: 6| Step: 1
Training loss: 6.27410330273721
Validation loss: 5.551893180858985

Epoch: 6| Step: 2
Training loss: 5.847043990889455
Validation loss: 5.538304566953149

Epoch: 6| Step: 3
Training loss: 5.797954777509978
Validation loss: 5.5239410247463185

Epoch: 6| Step: 4
Training loss: 4.839309330361294
Validation loss: 5.508670300871432

Epoch: 6| Step: 5
Training loss: 5.940620325238166
Validation loss: 5.4936442787780955

Epoch: 6| Step: 6
Training loss: 5.500756125060235
Validation loss: 5.476682664717543

Epoch: 6| Step: 7
Training loss: 5.031380408830103
Validation loss: 5.461032760094171

Epoch: 6| Step: 8
Training loss: 4.971364419112933
Validation loss: 5.443270534897166

Epoch: 6| Step: 9
Training loss: 4.676232388689354
Validation loss: 5.426858435291552

Epoch: 6| Step: 10
Training loss: 5.899137543826752
Validation loss: 5.409287164289353

Epoch: 6| Step: 11
Training loss: 5.110010323411402
Validation loss: 5.3896186658530345

Epoch: 6| Step: 12
Training loss: 4.832531347276716
Validation loss: 5.37217575817918

Epoch: 6| Step: 13
Training loss: 6.14335404727705
Validation loss: 5.352141389135276

Epoch: 4| Step: 0
Training loss: 5.353011821879861
Validation loss: 5.331064462022087

Epoch: 6| Step: 1
Training loss: 4.9737926302432545
Validation loss: 5.310113352179114

Epoch: 6| Step: 2
Training loss: 5.6168876642203465
Validation loss: 5.290548566743141

Epoch: 6| Step: 3
Training loss: 4.858174166463102
Validation loss: 5.269624217880088

Epoch: 6| Step: 4
Training loss: 6.1899156575165035
Validation loss: 5.247810713988143

Epoch: 6| Step: 5
Training loss: 5.805429732050789
Validation loss: 5.225452240118585

Epoch: 6| Step: 6
Training loss: 4.182441046847112
Validation loss: 5.201959925633544

Epoch: 6| Step: 7
Training loss: 5.320631199728599
Validation loss: 5.180528954400574

Epoch: 6| Step: 8
Training loss: 5.17245526242349
Validation loss: 5.156034783439514

Epoch: 6| Step: 9
Training loss: 5.792999041137932
Validation loss: 5.133306159682813

Epoch: 6| Step: 10
Training loss: 5.028278681822955
Validation loss: 5.108429563035144

Epoch: 6| Step: 11
Training loss: 4.452915119779945
Validation loss: 5.085958479121978

Epoch: 6| Step: 12
Training loss: 5.488468913606508
Validation loss: 5.0623583057890365

Epoch: 6| Step: 13
Training loss: 4.525022238998139
Validation loss: 5.039048204006639

Epoch: 5| Step: 0
Training loss: 4.469595022268342
Validation loss: 5.015666642679188

Epoch: 6| Step: 1
Training loss: 3.896074637761424
Validation loss: 4.993265261624272

Epoch: 6| Step: 2
Training loss: 4.83217631116888
Validation loss: 4.968922808172792

Epoch: 6| Step: 3
Training loss: 4.984401786516973
Validation loss: 4.946716898181147

Epoch: 6| Step: 4
Training loss: 5.241867669663148
Validation loss: 4.921835358761667

Epoch: 6| Step: 5
Training loss: 5.657417303366757
Validation loss: 4.898953278584513

Epoch: 6| Step: 6
Training loss: 5.052646796931388
Validation loss: 4.871020179479321

Epoch: 6| Step: 7
Training loss: 4.374779831932215
Validation loss: 4.84177865657506

Epoch: 6| Step: 8
Training loss: 5.548888794601888
Validation loss: 4.816488704693007

Epoch: 6| Step: 9
Training loss: 4.9004622416548385
Validation loss: 4.787726475701316

Epoch: 6| Step: 10
Training loss: 4.7153419161919405
Validation loss: 4.757369414374067

Epoch: 6| Step: 11
Training loss: 4.3326614788271085
Validation loss: 4.728648419118779

Epoch: 6| Step: 12
Training loss: 5.059599999460532
Validation loss: 4.70361672669659

Epoch: 6| Step: 13
Training loss: 5.848595227197023
Validation loss: 4.677570619743295

Epoch: 6| Step: 0
Training loss: 4.726116972803889
Validation loss: 4.654251406383245

Epoch: 6| Step: 1
Training loss: 4.385141226604966
Validation loss: 4.627217624448605

Epoch: 6| Step: 2
Training loss: 4.63535860289594
Validation loss: 4.602753178320655

Epoch: 6| Step: 3
Training loss: 4.3805585154994615
Validation loss: 4.580599266765752

Epoch: 6| Step: 4
Training loss: 4.80850529531255
Validation loss: 4.558994085164705

Epoch: 6| Step: 5
Training loss: 4.520381758443133
Validation loss: 4.537761863710267

Epoch: 6| Step: 6
Training loss: 4.026818020062394
Validation loss: 4.518332639467289

Epoch: 6| Step: 7
Training loss: 4.053880203231028
Validation loss: 4.49879168167606

Epoch: 6| Step: 8
Training loss: 5.18661748893848
Validation loss: 4.480577204516949

Epoch: 6| Step: 9
Training loss: 4.109976952852475
Validation loss: 4.465569197470838

Epoch: 6| Step: 10
Training loss: 4.77108741761083
Validation loss: 4.447903468568802

Epoch: 6| Step: 11
Training loss: 4.868873463388655
Validation loss: 4.429082231256335

Epoch: 6| Step: 12
Training loss: 4.862981212506723
Validation loss: 4.414851565430892

Epoch: 6| Step: 13
Training loss: 5.282637374398751
Validation loss: 4.400920541456539

Epoch: 7| Step: 0
Training loss: 4.716942042926553
Validation loss: 4.385282162156752

Epoch: 6| Step: 1
Training loss: 4.708704480871951
Validation loss: 4.369835718187508

Epoch: 6| Step: 2
Training loss: 4.133679131430147
Validation loss: 4.355650306602611

Epoch: 6| Step: 3
Training loss: 4.470034114698932
Validation loss: 4.340026298123066

Epoch: 6| Step: 4
Training loss: 3.9484232205976957
Validation loss: 4.326424554560306

Epoch: 6| Step: 5
Training loss: 4.778766460784493
Validation loss: 4.3107808618759

Epoch: 6| Step: 6
Training loss: 4.455114943951318
Validation loss: 4.296217605254968

Epoch: 6| Step: 7
Training loss: 3.4581366027273357
Validation loss: 4.282212175238058

Epoch: 6| Step: 8
Training loss: 5.103814975793001
Validation loss: 4.2684957081977775

Epoch: 6| Step: 9
Training loss: 4.642484863782457
Validation loss: 4.256655703464242

Epoch: 6| Step: 10
Training loss: 4.046737609652011
Validation loss: 4.242077700806138

Epoch: 6| Step: 11
Training loss: 4.4517198989372355
Validation loss: 4.228476512847125

Epoch: 6| Step: 12
Training loss: 4.551979581696585
Validation loss: 4.218265741736772

Epoch: 6| Step: 13
Training loss: 3.7248939601474915
Validation loss: 4.206996291489286

Epoch: 8| Step: 0
Training loss: 4.748069169977993
Validation loss: 4.1911523105152675

Epoch: 6| Step: 1
Training loss: 4.716212923221152
Validation loss: 4.179785797892263

Epoch: 6| Step: 2
Training loss: 4.146721263988084
Validation loss: 4.163984535966696

Epoch: 6| Step: 3
Training loss: 4.374845665525582
Validation loss: 4.154525515041112

Epoch: 6| Step: 4
Training loss: 4.381500863853194
Validation loss: 4.14231694163534

Epoch: 6| Step: 5
Training loss: 4.165538533394375
Validation loss: 4.129109738969506

Epoch: 6| Step: 6
Training loss: 4.013215169423856
Validation loss: 4.117335901510254

Epoch: 6| Step: 7
Training loss: 4.174838381625726
Validation loss: 4.10360369900386

Epoch: 6| Step: 8
Training loss: 4.49021419804351
Validation loss: 4.088868800093932

Epoch: 6| Step: 9
Training loss: 4.293420575205241
Validation loss: 4.077980904899039

Epoch: 6| Step: 10
Training loss: 4.339668387124191
Validation loss: 4.066251306656387

Epoch: 6| Step: 11
Training loss: 4.090453706306612
Validation loss: 4.050396567409903

Epoch: 6| Step: 12
Training loss: 3.1129822629330763
Validation loss: 4.040189441153121

Epoch: 6| Step: 13
Training loss: 4.237142074007227
Validation loss: 4.033486406910993

Epoch: 9| Step: 0
Training loss: 3.5039243495648056
Validation loss: 4.016998912733946

Epoch: 6| Step: 1
Training loss: 4.106378311173078
Validation loss: 4.00630069954182

Epoch: 6| Step: 2
Training loss: 4.375729309329519
Validation loss: 3.997299077191532

Epoch: 6| Step: 3
Training loss: 3.645588646806723
Validation loss: 3.9869620263060295

Epoch: 6| Step: 4
Training loss: 4.14632797485303
Validation loss: 3.9747622742280915

Epoch: 6| Step: 5
Training loss: 4.561512461350795
Validation loss: 3.9656166030219664

Epoch: 6| Step: 6
Training loss: 4.679800602178202
Validation loss: 3.9547450867016987

Epoch: 6| Step: 7
Training loss: 3.818153067476432
Validation loss: 3.9432881372565003

Epoch: 6| Step: 8
Training loss: 3.640604829527681
Validation loss: 3.934274459472086

Epoch: 6| Step: 9
Training loss: 4.47854501121519
Validation loss: 3.9202440994946017

Epoch: 6| Step: 10
Training loss: 3.8019944829444245
Validation loss: 3.911678212938559

Epoch: 6| Step: 11
Training loss: 3.751815610685967
Validation loss: 3.8961263514287445

Epoch: 6| Step: 12
Training loss: 4.354487697806891
Validation loss: 3.890132436168424

Epoch: 6| Step: 13
Training loss: 4.4294642370295785
Validation loss: 3.8793281203740317

Epoch: 10| Step: 0
Training loss: 4.215755728129054
Validation loss: 3.8656643347698183

Epoch: 6| Step: 1
Training loss: 3.638191949110071
Validation loss: 3.856245471476154

Epoch: 6| Step: 2
Training loss: 4.114771095852678
Validation loss: 3.843763643379452

Epoch: 6| Step: 3
Training loss: 3.3707208703467297
Validation loss: 3.8319894036300597

Epoch: 6| Step: 4
Training loss: 3.9590550751811815
Validation loss: 3.8248280568530664

Epoch: 6| Step: 5
Training loss: 4.316140669855701
Validation loss: 3.813407616427101

Epoch: 6| Step: 6
Training loss: 4.260731331817766
Validation loss: 3.8038282695796872

Epoch: 6| Step: 7
Training loss: 4.559248091962369
Validation loss: 3.7957331786646047

Epoch: 6| Step: 8
Training loss: 4.126830879563701
Validation loss: 3.786826953795751

Epoch: 6| Step: 9
Training loss: 4.115941360352496
Validation loss: 3.773577438426625

Epoch: 6| Step: 10
Training loss: 3.982293037549354
Validation loss: 3.7656497374978017

Epoch: 6| Step: 11
Training loss: 3.4796800672420054
Validation loss: 3.7585314038980133

Epoch: 6| Step: 12
Training loss: 3.399505798101495
Validation loss: 3.747432896545386

Epoch: 6| Step: 13
Training loss: 3.7453664763837775
Validation loss: 3.741961835617075

Epoch: 11| Step: 0
Training loss: 3.6128127335606974
Validation loss: 3.733996109446868

Epoch: 6| Step: 1
Training loss: 4.256113927965541
Validation loss: 3.726146430295361

Epoch: 6| Step: 2
Training loss: 3.662741872462758
Validation loss: 3.719635657107156

Epoch: 6| Step: 3
Training loss: 3.949894365274364
Validation loss: 3.712841383094862

Epoch: 6| Step: 4
Training loss: 3.8286349209968256
Validation loss: 3.7013835793945344

Epoch: 6| Step: 5
Training loss: 3.603370593287396
Validation loss: 3.695817327505772

Epoch: 6| Step: 6
Training loss: 2.586771574088766
Validation loss: 3.6884019894596207

Epoch: 6| Step: 7
Training loss: 4.0976716105825055
Validation loss: 3.682362357084143

Epoch: 6| Step: 8
Training loss: 3.7405533378193243
Validation loss: 3.677511114622885

Epoch: 6| Step: 9
Training loss: 3.905295049288475
Validation loss: 3.6701975771405504

Epoch: 6| Step: 10
Training loss: 4.016193750381148
Validation loss: 3.6652108562393413

Epoch: 6| Step: 11
Training loss: 4.989218340792434
Validation loss: 3.658920551051518

Epoch: 6| Step: 12
Training loss: 4.256074491178801
Validation loss: 3.6515656318903686

Epoch: 6| Step: 13
Training loss: 2.5208686531892295
Validation loss: 3.646354610369155

Epoch: 12| Step: 0
Training loss: 3.8326571047757567
Validation loss: 3.6389315389562333

Epoch: 6| Step: 1
Training loss: 4.003845750305115
Validation loss: 3.6345741618415306

Epoch: 6| Step: 2
Training loss: 3.3717034806262385
Validation loss: 3.6301894731282234

Epoch: 6| Step: 3
Training loss: 3.2124536651950937
Validation loss: 3.6230133434535396

Epoch: 6| Step: 4
Training loss: 3.923583490655206
Validation loss: 3.618139963306549

Epoch: 6| Step: 5
Training loss: 4.094992878480339
Validation loss: 3.613217135733305

Epoch: 6| Step: 6
Training loss: 4.708319244813799
Validation loss: 3.6101653759836956

Epoch: 6| Step: 7
Training loss: 3.477418944060696
Validation loss: 3.6025280722162916

Epoch: 6| Step: 8
Training loss: 4.005173437051666
Validation loss: 3.59981162975303

Epoch: 6| Step: 9
Training loss: 3.7716091615409244
Validation loss: 3.5931133303740674

Epoch: 6| Step: 10
Training loss: 3.480236383938013
Validation loss: 3.5891239490341804

Epoch: 6| Step: 11
Training loss: 3.975249367815297
Validation loss: 3.5830257271340518

Epoch: 6| Step: 12
Training loss: 2.961751297611156
Validation loss: 3.57846338707074

Epoch: 6| Step: 13
Training loss: 4.279528640745718
Validation loss: 3.5752238457610326

Epoch: 13| Step: 0
Training loss: 4.441614097489293
Validation loss: 3.5703687080236044

Epoch: 6| Step: 1
Training loss: 3.628852244325335
Validation loss: 3.565208076454813

Epoch: 6| Step: 2
Training loss: 3.681363187905351
Validation loss: 3.5628462793878426

Epoch: 6| Step: 3
Training loss: 3.864827246907357
Validation loss: 3.5572152121507927

Epoch: 6| Step: 4
Training loss: 2.396134653354869
Validation loss: 3.5523096121442284

Epoch: 6| Step: 5
Training loss: 4.220367347674419
Validation loss: 3.5461969248313467

Epoch: 6| Step: 6
Training loss: 3.5115677543316344
Validation loss: 3.544944869372274

Epoch: 6| Step: 7
Training loss: 4.255547213124287
Validation loss: 3.5390327827415486

Epoch: 6| Step: 8
Training loss: 3.3813852730872402
Validation loss: 3.534796361757273

Epoch: 6| Step: 9
Training loss: 3.888499464488474
Validation loss: 3.530924738609831

Epoch: 6| Step: 10
Training loss: 3.767201960064015
Validation loss: 3.527678651611782

Epoch: 6| Step: 11
Training loss: 3.4703670547230066
Validation loss: 3.5205559040843584

Epoch: 6| Step: 12
Training loss: 3.609499049841696
Validation loss: 3.5186778678736115

Epoch: 6| Step: 13
Training loss: 4.033407654090664
Validation loss: 3.5140957841479783

Epoch: 14| Step: 0
Training loss: 3.4529637087614224
Validation loss: 3.5081801372687527

Epoch: 6| Step: 1
Training loss: 4.59658933331503
Validation loss: 3.503772131199231

Epoch: 6| Step: 2
Training loss: 3.713296690462717
Validation loss: 3.504937852090817

Epoch: 6| Step: 3
Training loss: 3.600623018608217
Validation loss: 3.5002627325402527

Epoch: 6| Step: 4
Training loss: 3.683331218275841
Validation loss: 3.495186661708547

Epoch: 6| Step: 5
Training loss: 2.848055755262352
Validation loss: 3.490941429919655

Epoch: 6| Step: 6
Training loss: 4.796326248640561
Validation loss: 3.488778694158194

Epoch: 6| Step: 7
Training loss: 3.0207835927792472
Validation loss: 3.4838180019540848

Epoch: 6| Step: 8
Training loss: 3.8156828804843554
Validation loss: 3.483177476275157

Epoch: 6| Step: 9
Training loss: 3.681699425508557
Validation loss: 3.4781482987597885

Epoch: 6| Step: 10
Training loss: 3.441796825124489
Validation loss: 3.472982855446585

Epoch: 6| Step: 11
Training loss: 4.3949201216832785
Validation loss: 3.469052383707234

Epoch: 6| Step: 12
Training loss: 2.8713827182386553
Validation loss: 3.4681671726064205

Epoch: 6| Step: 13
Training loss: 2.853531332840921
Validation loss: 3.466290894991453

Epoch: 15| Step: 0
Training loss: 2.631778502678028
Validation loss: 3.462887263954159

Epoch: 6| Step: 1
Training loss: 4.281281185732676
Validation loss: 3.4597406460671944

Epoch: 6| Step: 2
Training loss: 3.674814419374903
Validation loss: 3.4567029630854327

Epoch: 6| Step: 3
Training loss: 3.9101057630513103
Validation loss: 3.4532471260610125

Epoch: 6| Step: 4
Training loss: 4.068213567808453
Validation loss: 3.452999282157217

Epoch: 6| Step: 5
Training loss: 4.086475227522644
Validation loss: 3.4517153444979

Epoch: 6| Step: 6
Training loss: 3.016000200559979
Validation loss: 3.4465306661930906

Epoch: 6| Step: 7
Training loss: 3.3140450958701417
Validation loss: 3.4436417111889672

Epoch: 6| Step: 8
Training loss: 3.6956743059202948
Validation loss: 3.4417193295057595

Epoch: 6| Step: 9
Training loss: 4.160754981856414
Validation loss: 3.437231618299039

Epoch: 6| Step: 10
Training loss: 2.389678568273978
Validation loss: 3.436190392801571

Epoch: 6| Step: 11
Training loss: 4.294093115811051
Validation loss: 3.43479566499489

Epoch: 6| Step: 12
Training loss: 3.3960550309969317
Validation loss: 3.432539064150271

Epoch: 6| Step: 13
Training loss: 3.8366170308481458
Validation loss: 3.4305306583283977

Epoch: 16| Step: 0
Training loss: 3.1856723108159466
Validation loss: 3.425214349398484

Epoch: 6| Step: 1
Training loss: 1.9994194857199699
Validation loss: 3.4219790132096866

Epoch: 6| Step: 2
Training loss: 2.952493913015992
Validation loss: 3.422296924794089

Epoch: 6| Step: 3
Training loss: 3.800720277083515
Validation loss: 3.4200765517685974

Epoch: 6| Step: 4
Training loss: 3.77538582554338
Validation loss: 3.4188490534848714

Epoch: 6| Step: 5
Training loss: 3.5702801792676833
Validation loss: 3.4141005767383215

Epoch: 6| Step: 6
Training loss: 4.257933000731776
Validation loss: 3.4106198763796884

Epoch: 6| Step: 7
Training loss: 4.625538150305502
Validation loss: 3.4101082749426697

Epoch: 6| Step: 8
Training loss: 3.004849964020569
Validation loss: 3.411260817288728

Epoch: 6| Step: 9
Training loss: 4.032605320405906
Validation loss: 3.40957393170204

Epoch: 6| Step: 10
Training loss: 4.173915635415669
Validation loss: 3.404264524884329

Epoch: 6| Step: 11
Training loss: 3.9607623360630817
Validation loss: 3.401533649076213

Epoch: 6| Step: 12
Training loss: 3.3246157775537575
Validation loss: 3.3995466169485486

Epoch: 6| Step: 13
Training loss: 3.32285446698721
Validation loss: 3.3997794789166558

Epoch: 17| Step: 0
Training loss: 3.2903928263631723
Validation loss: 3.4005276677698433

Epoch: 6| Step: 1
Training loss: 3.0915050646009177
Validation loss: 3.398132459891721

Epoch: 6| Step: 2
Training loss: 3.7789360090956614
Validation loss: 3.396456637775167

Epoch: 6| Step: 3
Training loss: 2.9316165524078284
Validation loss: 3.387915341201128

Epoch: 6| Step: 4
Training loss: 3.6683907068096793
Validation loss: 3.380994911936937

Epoch: 6| Step: 5
Training loss: 3.764137575787198
Validation loss: 3.379304704248794

Epoch: 6| Step: 6
Training loss: 4.119599014323889
Validation loss: 3.3788293772259714

Epoch: 6| Step: 7
Training loss: 3.2172314663551127
Validation loss: 3.379033727574825

Epoch: 6| Step: 8
Training loss: 3.692914188531521
Validation loss: 3.376449117381511

Epoch: 6| Step: 9
Training loss: 3.7030137443730378
Validation loss: 3.373672020515875

Epoch: 6| Step: 10
Training loss: 3.786728980017322
Validation loss: 3.368193025232287

Epoch: 6| Step: 11
Training loss: 4.288328903636777
Validation loss: 3.3693018658091423

Epoch: 6| Step: 12
Training loss: 4.038857312773544
Validation loss: 3.365961685819235

Epoch: 6| Step: 13
Training loss: 1.8560815702633306
Validation loss: 3.3605876621675956

Epoch: 18| Step: 0
Training loss: 3.3469010951345415
Validation loss: 3.360688380385673

Epoch: 6| Step: 1
Training loss: 3.4078015634675207
Validation loss: 3.357284259314855

Epoch: 6| Step: 2
Training loss: 3.8268059151154885
Validation loss: 3.356124547011287

Epoch: 6| Step: 3
Training loss: 2.8778443571397148
Validation loss: 3.356250867234162

Epoch: 6| Step: 4
Training loss: 3.8014054761035423
Validation loss: 3.35220749495455

Epoch: 6| Step: 5
Training loss: 4.383777858883823
Validation loss: 3.3492416139289913

Epoch: 6| Step: 6
Training loss: 2.462130593413151
Validation loss: 3.345218613858525

Epoch: 6| Step: 7
Training loss: 3.745100508233719
Validation loss: 3.3456661762841606

Epoch: 6| Step: 8
Training loss: 3.9552684898245682
Validation loss: 3.3419597173692637

Epoch: 6| Step: 9
Training loss: 3.6092930904193454
Validation loss: 3.3395133447487275

Epoch: 6| Step: 10
Training loss: 3.646112849101935
Validation loss: 3.336814177088327

Epoch: 6| Step: 11
Training loss: 3.1165083907902003
Validation loss: 3.335327521488429

Epoch: 6| Step: 12
Training loss: 3.584033069747536
Validation loss: 3.335322805156986

Epoch: 6| Step: 13
Training loss: 4.192486654862039
Validation loss: 3.331615093334981

Epoch: 19| Step: 0
Training loss: 3.45592678552359
Validation loss: 3.328862451854835

Epoch: 6| Step: 1
Training loss: 3.0151513869202926
Validation loss: 3.3279369208091123

Epoch: 6| Step: 2
Training loss: 3.6375454824429094
Validation loss: 3.3362803957170435

Epoch: 6| Step: 3
Training loss: 4.0263718062140015
Validation loss: 3.334941908629039

Epoch: 6| Step: 4
Training loss: 2.634911309039898
Validation loss: 3.331579901346478

Epoch: 6| Step: 5
Training loss: 3.600640632000843
Validation loss: 3.3332843643611323

Epoch: 6| Step: 6
Training loss: 2.9194632792044235
Validation loss: 3.3252102123188867

Epoch: 6| Step: 7
Training loss: 3.503400376970206
Validation loss: 3.3252465017257355

Epoch: 6| Step: 8
Training loss: 3.644928839973988
Validation loss: 3.3181884287413035

Epoch: 6| Step: 9
Training loss: 3.61042856139997
Validation loss: 3.3122978837584403

Epoch: 6| Step: 10
Training loss: 4.0069757670047474
Validation loss: 3.308856518263484

Epoch: 6| Step: 11
Training loss: 4.425744617980571
Validation loss: 3.3056821602113753

Epoch: 6| Step: 12
Training loss: 3.299417392279886
Validation loss: 3.3060664898323227

Epoch: 6| Step: 13
Training loss: 3.7574343421666545
Validation loss: 3.304867466502618

Epoch: 20| Step: 0
Training loss: 4.088023133005283
Validation loss: 3.3012939031717012

Epoch: 6| Step: 1
Training loss: 3.270495565351061
Validation loss: 3.2997252322869834

Epoch: 6| Step: 2
Training loss: 4.174381488966921
Validation loss: 3.295851149912167

Epoch: 6| Step: 3
Training loss: 3.1472203479060576
Validation loss: 3.287521580082877

Epoch: 6| Step: 4
Training loss: 4.009357950080661
Validation loss: 3.2861168898227615

Epoch: 6| Step: 5
Training loss: 4.021004365172503
Validation loss: 3.2862928447742648

Epoch: 6| Step: 6
Training loss: 2.978656022561959
Validation loss: 3.285331085907213

Epoch: 6| Step: 7
Training loss: 3.3725753834572845
Validation loss: 3.2854054317357306

Epoch: 6| Step: 8
Training loss: 2.652709755904755
Validation loss: 3.284459764513447

Epoch: 6| Step: 9
Training loss: 2.968871425353951
Validation loss: 3.2853183727550364

Epoch: 6| Step: 10
Training loss: 3.8912616499920345
Validation loss: 3.2859872673098605

Epoch: 6| Step: 11
Training loss: 3.7481473796940303
Validation loss: 3.276016175518339

Epoch: 6| Step: 12
Training loss: 3.362896727801118
Validation loss: 3.27208097505544

Epoch: 6| Step: 13
Training loss: 3.148275290728779
Validation loss: 3.2703724689236617

Epoch: 21| Step: 0
Training loss: 3.192055084126089
Validation loss: 3.2670485230852617

Epoch: 6| Step: 1
Training loss: 3.1648608295523153
Validation loss: 3.2646593920415223

Epoch: 6| Step: 2
Training loss: 3.4147465280322065
Validation loss: 3.258583111286293

Epoch: 6| Step: 3
Training loss: 3.393287140982146
Validation loss: 3.259131316245526

Epoch: 6| Step: 4
Training loss: 2.8916424584451845
Validation loss: 3.2588068195065625

Epoch: 6| Step: 5
Training loss: 3.5224732561903394
Validation loss: 3.2610110458247976

Epoch: 6| Step: 6
Training loss: 2.622046216573408
Validation loss: 3.2521137127317212

Epoch: 6| Step: 7
Training loss: 4.236270494363647
Validation loss: 3.2519087688181774

Epoch: 6| Step: 8
Training loss: 4.26771913203831
Validation loss: 3.251805453187307

Epoch: 6| Step: 9
Training loss: 4.011760588876277
Validation loss: 3.251457162197348

Epoch: 6| Step: 10
Training loss: 3.5713677046902483
Validation loss: 3.2462719548441816

Epoch: 6| Step: 11
Training loss: 2.9916982225827664
Validation loss: 3.2445578355168316

Epoch: 6| Step: 12
Training loss: 3.2145070378233456
Validation loss: 3.248222625480213

Epoch: 6| Step: 13
Training loss: 4.4836257149088175
Validation loss: 3.24650731082016

Epoch: 22| Step: 0
Training loss: 2.765551549938314
Validation loss: 3.23872688831477

Epoch: 6| Step: 1
Training loss: 3.905359883936317
Validation loss: 3.237020954193041

Epoch: 6| Step: 2
Training loss: 4.137474617779371
Validation loss: 3.2354748693550412

Epoch: 6| Step: 3
Training loss: 3.8047743519107042
Validation loss: 3.2328892147082544

Epoch: 6| Step: 4
Training loss: 3.7243585687138197
Validation loss: 3.2337107975840564

Epoch: 6| Step: 5
Training loss: 3.519308644155086
Validation loss: 3.2301276585468104

Epoch: 6| Step: 6
Training loss: 3.9856795026723435
Validation loss: 3.2287133943044166

Epoch: 6| Step: 7
Training loss: 4.095571098328041
Validation loss: 3.2273903276176474

Epoch: 6| Step: 8
Training loss: 3.7692776135119272
Validation loss: 3.222225752559713

Epoch: 6| Step: 9
Training loss: 2.770269513428697
Validation loss: 3.218552091610989

Epoch: 6| Step: 10
Training loss: 2.6948957480399787
Validation loss: 3.2201546729040413

Epoch: 6| Step: 11
Training loss: 2.6816905906784436
Validation loss: 3.2154673583047457

Epoch: 6| Step: 12
Training loss: 3.324686055671184
Validation loss: 3.2148731976793172

Epoch: 6| Step: 13
Training loss: 2.6301384542014214
Validation loss: 3.212473668601461

Epoch: 23| Step: 0
Training loss: 2.9835734464319636
Validation loss: 3.2136658465211285

Epoch: 6| Step: 1
Training loss: 3.3835547075681287
Validation loss: 3.2112209034419767

Epoch: 6| Step: 2
Training loss: 3.2131001783865463
Validation loss: 3.2108603328658516

Epoch: 6| Step: 3
Training loss: 3.043745575887923
Validation loss: 3.207436541058552

Epoch: 6| Step: 4
Training loss: 3.1428014700776545
Validation loss: 3.2044193064903403

Epoch: 6| Step: 5
Training loss: 3.572093561115497
Validation loss: 3.2037909847112194

Epoch: 6| Step: 6
Training loss: 3.239793008149863
Validation loss: 3.202765479071613

Epoch: 6| Step: 7
Training loss: 4.019732916011268
Validation loss: 3.2002984814618936

Epoch: 6| Step: 8
Training loss: 4.180579316728952
Validation loss: 3.200979310972361

Epoch: 6| Step: 9
Training loss: 3.130328404074946
Validation loss: 3.199415278977721

Epoch: 6| Step: 10
Training loss: 3.5471363391468467
Validation loss: 3.196534991097901

Epoch: 6| Step: 11
Training loss: 3.878874041989268
Validation loss: 3.197005541576653

Epoch: 6| Step: 12
Training loss: 3.3405967889634787
Validation loss: 3.192394059988035

Epoch: 6| Step: 13
Training loss: 3.6089277774796167
Validation loss: 3.19240994581288

Epoch: 24| Step: 0
Training loss: 3.397431182950333
Validation loss: 3.192538942336304

Epoch: 6| Step: 1
Training loss: 3.6940363480907474
Validation loss: 3.189854216771365

Epoch: 6| Step: 2
Training loss: 3.8385429779147113
Validation loss: 3.1890185079066358

Epoch: 6| Step: 3
Training loss: 3.8813096636180706
Validation loss: 3.1886575468181717

Epoch: 6| Step: 4
Training loss: 3.3151925138381624
Validation loss: 3.185525006036055

Epoch: 6| Step: 5
Training loss: 2.7745075579327367
Validation loss: 3.185632582122054

Epoch: 6| Step: 6
Training loss: 2.984840236969874
Validation loss: 3.184831658544374

Epoch: 6| Step: 7
Training loss: 3.7604906210491387
Validation loss: 3.18217496377846

Epoch: 6| Step: 8
Training loss: 3.6495388419011134
Validation loss: 3.18271099781331

Epoch: 6| Step: 9
Training loss: 3.2493308919094694
Validation loss: 3.1807637818568693

Epoch: 6| Step: 10
Training loss: 3.4328584719163717
Validation loss: 3.17901266023337

Epoch: 6| Step: 11
Training loss: 3.2472642975419816
Validation loss: 3.1771809197656924

Epoch: 6| Step: 12
Training loss: 3.40210997241481
Validation loss: 3.1788874180895585

Epoch: 6| Step: 13
Training loss: 3.423873805314208
Validation loss: 3.1760425839255504

Epoch: 25| Step: 0
Training loss: 4.049190138859825
Validation loss: 3.1761798323711528

Epoch: 6| Step: 1
Training loss: 3.412779542980234
Validation loss: 3.1732332223293347

Epoch: 6| Step: 2
Training loss: 3.183865438464544
Validation loss: 3.1724221928349263

Epoch: 6| Step: 3
Training loss: 3.4967125030752237
Validation loss: 3.1733046168615915

Epoch: 6| Step: 4
Training loss: 3.119751757502892
Validation loss: 3.170583482546018

Epoch: 6| Step: 5
Training loss: 3.529565595098085
Validation loss: 3.1690004931320566

Epoch: 6| Step: 6
Training loss: 3.55236552768506
Validation loss: 3.1701120055425314

Epoch: 6| Step: 7
Training loss: 2.17558115068151
Validation loss: 3.171954801517287

Epoch: 6| Step: 8
Training loss: 3.7083715944066538
Validation loss: 3.173773974995568

Epoch: 6| Step: 9
Training loss: 3.517652139091538
Validation loss: 3.1707988396324875

Epoch: 6| Step: 10
Training loss: 3.874909553702827
Validation loss: 3.170353833706014

Epoch: 6| Step: 11
Training loss: 3.2694460767729114
Validation loss: 3.168537518793205

Epoch: 6| Step: 12
Training loss: 3.6523445333388196
Validation loss: 3.167510581351868

Epoch: 6| Step: 13
Training loss: 2.9798056888594893
Validation loss: 3.164121562488044

Epoch: 26| Step: 0
Training loss: 4.019735525740396
Validation loss: 3.1644658175857243

Epoch: 6| Step: 1
Training loss: 3.517257514843094
Validation loss: 3.1611271372011958

Epoch: 6| Step: 2
Training loss: 3.094147011300378
Validation loss: 3.1601862494599056

Epoch: 6| Step: 3
Training loss: 3.7733010214061284
Validation loss: 3.1618171035974227

Epoch: 6| Step: 4
Training loss: 3.7455284161450306
Validation loss: 3.1587582270056007

Epoch: 6| Step: 5
Training loss: 3.8216814892017394
Validation loss: 3.1584257969860796

Epoch: 6| Step: 6
Training loss: 3.382712699704223
Validation loss: 3.159225304232347

Epoch: 6| Step: 7
Training loss: 2.567131323266497
Validation loss: 3.157453661814978

Epoch: 6| Step: 8
Training loss: 2.43431097884215
Validation loss: 3.157169954828064

Epoch: 6| Step: 9
Training loss: 2.3408516828832457
Validation loss: 3.154808515323729

Epoch: 6| Step: 10
Training loss: 3.7003621929328374
Validation loss: 3.1549187363212243

Epoch: 6| Step: 11
Training loss: 3.951496738838434
Validation loss: 3.1550670930347278

Epoch: 6| Step: 12
Training loss: 3.520291905654016
Validation loss: 3.1528449659795865

Epoch: 6| Step: 13
Training loss: 3.5599189911958606
Validation loss: 3.1538893299436923

Epoch: 27| Step: 0
Training loss: 2.512621869979449
Validation loss: 3.151132651289837

Epoch: 6| Step: 1
Training loss: 3.3530537593273766
Validation loss: 3.1511118451958655

Epoch: 6| Step: 2
Training loss: 2.7796976279062964
Validation loss: 3.150222419338631

Epoch: 6| Step: 3
Training loss: 3.6472160696336253
Validation loss: 3.1514328200843194

Epoch: 6| Step: 4
Training loss: 3.118990192834541
Validation loss: 3.150880111638397

Epoch: 6| Step: 5
Training loss: 3.722480377493968
Validation loss: 3.148683139048642

Epoch: 6| Step: 6
Training loss: 4.294408915905857
Validation loss: 3.147899379253707

Epoch: 6| Step: 7
Training loss: 2.872817496473104
Validation loss: 3.148580697867142

Epoch: 6| Step: 8
Training loss: 3.4514306515973407
Validation loss: 3.149496531582063

Epoch: 6| Step: 9
Training loss: 3.71064246360058
Validation loss: 3.146705041883491

Epoch: 6| Step: 10
Training loss: 3.56765093606411
Validation loss: 3.1457063385391177

Epoch: 6| Step: 11
Training loss: 3.923917322203573
Validation loss: 3.1469510629979887

Epoch: 6| Step: 12
Training loss: 3.245081480910614
Validation loss: 3.144899449835606

Epoch: 6| Step: 13
Training loss: 3.040095999356391
Validation loss: 3.1450963620219663

Epoch: 28| Step: 0
Training loss: 3.7907399033556204
Validation loss: 3.146248263972891

Epoch: 6| Step: 1
Training loss: 3.673296064982792
Validation loss: 3.142977870732686

Epoch: 6| Step: 2
Training loss: 3.6982984032398925
Validation loss: 3.141854116849626

Epoch: 6| Step: 3
Training loss: 3.303960048249259
Validation loss: 3.142626147750059

Epoch: 6| Step: 4
Training loss: 2.701944964612876
Validation loss: 3.1407441473897557

Epoch: 6| Step: 5
Training loss: 3.2566609714527237
Validation loss: 3.1423056047549704

Epoch: 6| Step: 6
Training loss: 3.816125240541964
Validation loss: 3.1407060526490036

Epoch: 6| Step: 7
Training loss: 3.3486782370151054
Validation loss: 3.1424902222468414

Epoch: 6| Step: 8
Training loss: 2.838058645232564
Validation loss: 3.1418276794967226

Epoch: 6| Step: 9
Training loss: 3.6922385594424942
Validation loss: 3.141011468541086

Epoch: 6| Step: 10
Training loss: 3.037920347413909
Validation loss: 3.1394782648434996

Epoch: 6| Step: 11
Training loss: 2.991381663681935
Validation loss: 3.139341615080599

Epoch: 6| Step: 12
Training loss: 4.053607304332078
Validation loss: 3.1380846678379783

Epoch: 6| Step: 13
Training loss: 3.091396476955742
Validation loss: 3.1373022602768574

Epoch: 29| Step: 0
Training loss: 2.8467855495967846
Validation loss: 3.1385315144032577

Epoch: 6| Step: 1
Training loss: 2.7607874399368715
Validation loss: 3.1378902731692966

Epoch: 6| Step: 2
Training loss: 2.9851346472143447
Validation loss: 3.1362440228927086

Epoch: 6| Step: 3
Training loss: 3.7107976947349206
Validation loss: 3.1357986669374376

Epoch: 6| Step: 4
Training loss: 3.7156881341471193
Validation loss: 3.133821847069301

Epoch: 6| Step: 5
Training loss: 4.172021527520997
Validation loss: 3.1338842559126223

Epoch: 6| Step: 6
Training loss: 3.241543846124506
Validation loss: 3.132010781742386

Epoch: 6| Step: 7
Training loss: 3.875144709684542
Validation loss: 3.1327407063968415

Epoch: 6| Step: 8
Training loss: 2.8890894754985563
Validation loss: 3.1332442432856067

Epoch: 6| Step: 9
Training loss: 4.21886845175144
Validation loss: 3.132675281230522

Epoch: 6| Step: 10
Training loss: 3.465039167086479
Validation loss: 3.1310494867448924

Epoch: 6| Step: 11
Training loss: 2.8805322907539455
Validation loss: 3.1318233150577486

Epoch: 6| Step: 12
Training loss: 3.525826940191849
Validation loss: 3.1300377287994383

Epoch: 6| Step: 13
Training loss: 2.4389804354638014
Validation loss: 3.133815139005877

Epoch: 30| Step: 0
Training loss: 2.688390539908285
Validation loss: 3.136825866794978

Epoch: 6| Step: 1
Training loss: 3.5084460393662917
Validation loss: 3.143355196129054

Epoch: 6| Step: 2
Training loss: 3.427377257260488
Validation loss: 3.137295352916217

Epoch: 6| Step: 3
Training loss: 3.14454050003492
Validation loss: 3.129926147539765

Epoch: 6| Step: 4
Training loss: 3.9745693045430985
Validation loss: 3.1276488171552224

Epoch: 6| Step: 5
Training loss: 3.727309689898877
Validation loss: 3.126511004629202

Epoch: 6| Step: 6
Training loss: 2.6251427747862963
Validation loss: 3.1238765854816406

Epoch: 6| Step: 7
Training loss: 3.10765910127248
Validation loss: 3.124754190929427

Epoch: 6| Step: 8
Training loss: 4.137552524936263
Validation loss: 3.1255817241049635

Epoch: 6| Step: 9
Training loss: 3.638273470204534
Validation loss: 3.125187387078031

Epoch: 6| Step: 10
Training loss: 3.445084544834441
Validation loss: 3.124839829472738

Epoch: 6| Step: 11
Training loss: 3.312462140712673
Validation loss: 3.12423272178381

Epoch: 6| Step: 12
Training loss: 3.5641474344517903
Validation loss: 3.124644325278642

Epoch: 6| Step: 13
Training loss: 2.5508280774618703
Validation loss: 3.124004164325231

Epoch: 31| Step: 0
Training loss: 3.468857222265972
Validation loss: 3.1237610984269293

Epoch: 6| Step: 1
Training loss: 3.446966418716645
Validation loss: 3.122369481921392

Epoch: 6| Step: 2
Training loss: 3.112818359271447
Validation loss: 3.123259819924463

Epoch: 6| Step: 3
Training loss: 3.8249432478540384
Validation loss: 3.123896136824884

Epoch: 6| Step: 4
Training loss: 3.390770834322354
Validation loss: 3.1226903583944354

Epoch: 6| Step: 5
Training loss: 3.5584964676089466
Validation loss: 3.123161434639818

Epoch: 6| Step: 6
Training loss: 4.13112209197084
Validation loss: 3.120324089891487

Epoch: 6| Step: 7
Training loss: 3.823786429574301
Validation loss: 3.1206609253935693

Epoch: 6| Step: 8
Training loss: 2.5924228811979146
Validation loss: 3.1181249881133404

Epoch: 6| Step: 9
Training loss: 3.567736073778254
Validation loss: 3.116519040155066

Epoch: 6| Step: 10
Training loss: 3.355602896765535
Validation loss: 3.1168503993439964

Epoch: 6| Step: 11
Training loss: 3.0894733501123923
Validation loss: 3.1187458681195963

Epoch: 6| Step: 12
Training loss: 2.7484872298434104
Validation loss: 3.1183434205277303

Epoch: 6| Step: 13
Training loss: 2.834980616696682
Validation loss: 3.1163064358810564

Epoch: 32| Step: 0
Training loss: 3.1730120645576836
Validation loss: 3.122418074929878

Epoch: 6| Step: 1
Training loss: 3.152003386887798
Validation loss: 3.123792776914384

Epoch: 6| Step: 2
Training loss: 3.1733818796862896
Validation loss: 3.130037378248311

Epoch: 6| Step: 3
Training loss: 3.1072555296063973
Validation loss: 3.1197077445263215

Epoch: 6| Step: 4
Training loss: 3.7946145192859295
Validation loss: 3.114198790936179

Epoch: 6| Step: 5
Training loss: 3.1093874217029676
Validation loss: 3.1099564335439753

Epoch: 6| Step: 6
Training loss: 3.839554023872289
Validation loss: 3.1103726445470388

Epoch: 6| Step: 7
Training loss: 3.0072967483447623
Validation loss: 3.110179023595313

Epoch: 6| Step: 8
Training loss: 3.6606205306857107
Validation loss: 3.1106401593404343

Epoch: 6| Step: 9
Training loss: 3.118255967513037
Validation loss: 3.106882039280236

Epoch: 6| Step: 10
Training loss: 3.3414241509340465
Validation loss: 3.106070911765177

Epoch: 6| Step: 11
Training loss: 3.4176202389285706
Validation loss: 3.105645081986951

Epoch: 6| Step: 12
Training loss: 3.96484832011744
Validation loss: 3.107009861308955

Epoch: 6| Step: 13
Training loss: 3.359292672501383
Validation loss: 3.1044345191497045

Epoch: 33| Step: 0
Training loss: 2.9616830335117244
Validation loss: 3.1033702626231827

Epoch: 6| Step: 1
Training loss: 3.8673406397235333
Validation loss: 3.1047536990424756

Epoch: 6| Step: 2
Training loss: 3.644310260708623
Validation loss: 3.101906222569254

Epoch: 6| Step: 3
Training loss: 4.116548608072903
Validation loss: 3.1016393496842443

Epoch: 6| Step: 4
Training loss: 2.806649629476248
Validation loss: 3.102899695169924

Epoch: 6| Step: 5
Training loss: 3.3182412542433237
Validation loss: 3.102813236252592

Epoch: 6| Step: 6
Training loss: 3.2233288242291454
Validation loss: 3.101079266128443

Epoch: 6| Step: 7
Training loss: 3.248819870529522
Validation loss: 3.0988271068992526

Epoch: 6| Step: 8
Training loss: 3.4303058596888447
Validation loss: 3.0977680675594725

Epoch: 6| Step: 9
Training loss: 2.8283011871591124
Validation loss: 3.0974273487409483

Epoch: 6| Step: 10
Training loss: 3.4760099850633
Validation loss: 3.0972963394127593

Epoch: 6| Step: 11
Training loss: 3.944777771621675
Validation loss: 3.094172152573601

Epoch: 6| Step: 12
Training loss: 3.4123280743896927
Validation loss: 3.0982783622794208

Epoch: 6| Step: 13
Training loss: 1.9099594045988455
Validation loss: 3.0941759920184504

Epoch: 34| Step: 0
Training loss: 3.827816573193859
Validation loss: 3.093931166091677

Epoch: 6| Step: 1
Training loss: 3.5110828133608343
Validation loss: 3.093599670675672

Epoch: 6| Step: 2
Training loss: 3.538220842333895
Validation loss: 3.092326410450723

Epoch: 6| Step: 3
Training loss: 3.4933322335986476
Validation loss: 3.091361804464892

Epoch: 6| Step: 4
Training loss: 2.5199977235935163
Validation loss: 3.09111380147328

Epoch: 6| Step: 5
Training loss: 3.7584900433559563
Validation loss: 3.0908030070786072

Epoch: 6| Step: 6
Training loss: 3.865333806436472
Validation loss: 3.0888191655582267

Epoch: 6| Step: 7
Training loss: 2.9848999839908723
Validation loss: 3.0872664228192597

Epoch: 6| Step: 8
Training loss: 3.2235520476098882
Validation loss: 3.0900198295377272

Epoch: 6| Step: 9
Training loss: 3.345333259300737
Validation loss: 3.0881917524555744

Epoch: 6| Step: 10
Training loss: 2.6545555544479362
Validation loss: 3.0926868679125517

Epoch: 6| Step: 11
Training loss: 3.30594490244439
Validation loss: 3.0927227357814253

Epoch: 6| Step: 12
Training loss: 2.6643741906361935
Validation loss: 3.08720556529764

Epoch: 6| Step: 13
Training loss: 4.481712055725965
Validation loss: 3.0866734320982516

Epoch: 35| Step: 0
Training loss: 3.6859727703378216
Validation loss: 3.0821828580417723

Epoch: 6| Step: 1
Training loss: 3.646810229983955
Validation loss: 3.0872196365315276

Epoch: 6| Step: 2
Training loss: 3.259736807794658
Validation loss: 3.081295813267513

Epoch: 6| Step: 3
Training loss: 3.184999869210377
Validation loss: 3.0790921258682755

Epoch: 6| Step: 4
Training loss: 3.217840269838959
Validation loss: 3.0812130713392842

Epoch: 6| Step: 5
Training loss: 2.568536950996429
Validation loss: 3.079723790170031

Epoch: 6| Step: 6
Training loss: 3.730741129413139
Validation loss: 3.0855578175343195

Epoch: 6| Step: 7
Training loss: 3.1033604404837623
Validation loss: 3.0794300082020114

Epoch: 6| Step: 8
Training loss: 3.080119150259834
Validation loss: 3.0774774248637953

Epoch: 6| Step: 9
Training loss: 3.188271821766873
Validation loss: 3.0768204614725834

Epoch: 6| Step: 10
Training loss: 3.9295812027435035
Validation loss: 3.0738852121494245

Epoch: 6| Step: 11
Training loss: 3.5541707428300984
Validation loss: 3.07658198974421

Epoch: 6| Step: 12
Training loss: 3.3191882575084133
Validation loss: 3.0757235694769958

Epoch: 6| Step: 13
Training loss: 3.281095955275403
Validation loss: 3.0731390142462134

Epoch: 36| Step: 0
Training loss: 3.564481485332382
Validation loss: 3.0744940434128742

Epoch: 6| Step: 1
Training loss: 3.8806683090626772
Validation loss: 3.0735332545477774

Epoch: 6| Step: 2
Training loss: 3.522336665225361
Validation loss: 3.0717489808715572

Epoch: 6| Step: 3
Training loss: 3.1512129976127037
Validation loss: 3.072636806841532

Epoch: 6| Step: 4
Training loss: 3.5342142272593775
Validation loss: 3.0696412803849626

Epoch: 6| Step: 5
Training loss: 2.996446889583923
Validation loss: 3.0676954782285804

Epoch: 6| Step: 6
Training loss: 3.4052335289907636
Validation loss: 3.0683257589629775

Epoch: 6| Step: 7
Training loss: 3.394109807339377
Validation loss: 3.069217933804245

Epoch: 6| Step: 8
Training loss: 3.8211693924128376
Validation loss: 3.067629620181719

Epoch: 6| Step: 9
Training loss: 3.265368729898617
Validation loss: 3.07081332350825

Epoch: 6| Step: 10
Training loss: 2.708204491313841
Validation loss: 3.0685678540486125

Epoch: 6| Step: 11
Training loss: 3.2774231893121186
Validation loss: 3.067939974494017

Epoch: 6| Step: 12
Training loss: 2.7872941424389728
Validation loss: 3.0696358409851348

Epoch: 6| Step: 13
Training loss: 3.4191302434989628
Validation loss: 3.0746367320573054

Epoch: 37| Step: 0
Training loss: 3.4605731987654402
Validation loss: 3.0648065854123367

Epoch: 6| Step: 1
Training loss: 3.2273004533111544
Validation loss: 3.0656817208663325

Epoch: 6| Step: 2
Training loss: 2.909490276146698
Validation loss: 3.0658890892573445

Epoch: 6| Step: 3
Training loss: 3.3325352349103445
Validation loss: 3.06403614834042

Epoch: 6| Step: 4
Training loss: 3.2722366788926545
Validation loss: 3.061705763596549

Epoch: 6| Step: 5
Training loss: 2.6497513204528644
Validation loss: 3.063827573463645

Epoch: 6| Step: 6
Training loss: 2.9226210350641786
Validation loss: 3.0633530959419644

Epoch: 6| Step: 7
Training loss: 4.036748403975897
Validation loss: 3.062503070507473

Epoch: 6| Step: 8
Training loss: 3.748904004471335
Validation loss: 3.062257780165231

Epoch: 6| Step: 9
Training loss: 3.603682219006484
Validation loss: 3.0652759770903155

Epoch: 6| Step: 10
Training loss: 3.393751118415662
Validation loss: 3.062168350326702

Epoch: 6| Step: 11
Training loss: 2.5351438360395213
Validation loss: 3.0600917992014627

Epoch: 6| Step: 12
Training loss: 3.674089259226785
Validation loss: 3.0590063177858653

Epoch: 6| Step: 13
Training loss: 3.935916037082645
Validation loss: 3.0603668605785037

Epoch: 38| Step: 0
Training loss: 3.472029227085416
Validation loss: 3.0599173931478503

Epoch: 6| Step: 1
Training loss: 3.5485824978631433
Validation loss: 3.059917832999998

Epoch: 6| Step: 2
Training loss: 3.646869461329944
Validation loss: 3.060179954364388

Epoch: 6| Step: 3
Training loss: 3.4859518409068104
Validation loss: 3.0626906770266826

Epoch: 6| Step: 4
Training loss: 3.5234827009122562
Validation loss: 3.05987673545573

Epoch: 6| Step: 5
Training loss: 3.453294568623642
Validation loss: 3.0614727273752753

Epoch: 6| Step: 6
Training loss: 3.4204246199395296
Validation loss: 3.0609548172657726

Epoch: 6| Step: 7
Training loss: 3.2217041088703824
Validation loss: 3.058717634969695

Epoch: 6| Step: 8
Training loss: 2.9787451883870273
Validation loss: 3.0581712598747193

Epoch: 6| Step: 9
Training loss: 3.0962848489807637
Validation loss: 3.061005613440666

Epoch: 6| Step: 10
Training loss: 3.6105404248005106
Validation loss: 3.0595684774793592

Epoch: 6| Step: 11
Training loss: 2.943665871359559
Validation loss: 3.0571719363125163

Epoch: 6| Step: 12
Training loss: 3.2212372586194826
Validation loss: 3.0579988351063685

Epoch: 6| Step: 13
Training loss: 2.8660144537104055
Validation loss: 3.057727420769843

Epoch: 39| Step: 0
Training loss: 2.77952273450359
Validation loss: 3.057705739314058

Epoch: 6| Step: 1
Training loss: 3.391144884043257
Validation loss: 3.055259670935558

Epoch: 6| Step: 2
Training loss: 3.2788622206266957
Validation loss: 3.06169627167357

Epoch: 6| Step: 3
Training loss: 3.1159445213305332
Validation loss: 3.0634224787078965

Epoch: 6| Step: 4
Training loss: 4.097443057788162
Validation loss: 3.053660448561937

Epoch: 6| Step: 5
Training loss: 3.552379353439008
Validation loss: 3.057538999924993

Epoch: 6| Step: 6
Training loss: 2.615023045338019
Validation loss: 3.05678662279026

Epoch: 6| Step: 7
Training loss: 2.927775417699311
Validation loss: 3.0523921938089122

Epoch: 6| Step: 8
Training loss: 2.869476651846668
Validation loss: 3.05334883089705

Epoch: 6| Step: 9
Training loss: 3.9539371907595697
Validation loss: 3.0527752134729553

Epoch: 6| Step: 10
Training loss: 2.4798444788375726
Validation loss: 3.0522305598215653

Epoch: 6| Step: 11
Training loss: 4.278503873779854
Validation loss: 3.0521182011666985

Epoch: 6| Step: 12
Training loss: 3.3402286419302336
Validation loss: 3.051111031932045

Epoch: 6| Step: 13
Training loss: 3.5706015037913366
Validation loss: 3.0525448313134302

Epoch: 40| Step: 0
Training loss: 3.1295608807231
Validation loss: 3.052125651554654

Epoch: 6| Step: 1
Training loss: 3.5295581647017373
Validation loss: 3.0501775192654117

Epoch: 6| Step: 2
Training loss: 3.2923687697133337
Validation loss: 3.0497141317289875

Epoch: 6| Step: 3
Training loss: 3.8559310311287063
Validation loss: 3.0553999570032593

Epoch: 6| Step: 4
Training loss: 3.773583577173827
Validation loss: 3.058841456254387

Epoch: 6| Step: 5
Training loss: 4.178566584508601
Validation loss: 3.0629042006474556

Epoch: 6| Step: 6
Training loss: 2.765009062546956
Validation loss: 3.0606977991736195

Epoch: 6| Step: 7
Training loss: 3.1137805188986984
Validation loss: 3.0582932976720403

Epoch: 6| Step: 8
Training loss: 2.981143660018329
Validation loss: 3.0552297555197683

Epoch: 6| Step: 9
Training loss: 2.361675429380641
Validation loss: 3.0550973570727007

Epoch: 6| Step: 10
Training loss: 3.5732722128674967
Validation loss: 3.0523177476908074

Epoch: 6| Step: 11
Training loss: 3.250272592703554
Validation loss: 3.057912882322241

Epoch: 6| Step: 12
Training loss: 3.5712699691433136
Validation loss: 3.0481614881582297

Epoch: 6| Step: 13
Training loss: 2.4552396176437865
Validation loss: 3.047850050147147

Epoch: 41| Step: 0
Training loss: 3.5550137212947224
Validation loss: 3.049614020202171

Epoch: 6| Step: 1
Training loss: 4.167175617923395
Validation loss: 3.0515703453844933

Epoch: 6| Step: 2
Training loss: 3.9391670936458887
Validation loss: 3.0478006391984147

Epoch: 6| Step: 3
Training loss: 3.5394443196523016
Validation loss: 3.0471630043406464

Epoch: 6| Step: 4
Training loss: 2.6191049412651215
Validation loss: 3.0479660516566085

Epoch: 6| Step: 5
Training loss: 3.680916680107823
Validation loss: 3.044741386403216

Epoch: 6| Step: 6
Training loss: 3.2584435745933353
Validation loss: 3.046543615098363

Epoch: 6| Step: 7
Training loss: 3.4629507990136332
Validation loss: 3.047261836019731

Epoch: 6| Step: 8
Training loss: 2.9345844490612083
Validation loss: 3.045965422735369

Epoch: 6| Step: 9
Training loss: 2.612092938263767
Validation loss: 3.047645490358784

Epoch: 6| Step: 10
Training loss: 3.210842307505841
Validation loss: 3.045557250916631

Epoch: 6| Step: 11
Training loss: 2.297898979038241
Validation loss: 3.043515574923894

Epoch: 6| Step: 12
Training loss: 3.0752857106533105
Validation loss: 3.0471314294195144

Epoch: 6| Step: 13
Training loss: 4.05434902887919
Validation loss: 3.0452259145591483

Epoch: 42| Step: 0
Training loss: 2.8561753678535906
Validation loss: 3.0438496376452138

Epoch: 6| Step: 1
Training loss: 3.2426619217089185
Validation loss: 3.044012694435319

Epoch: 6| Step: 2
Training loss: 3.716679357213363
Validation loss: 3.0446134029754823

Epoch: 6| Step: 3
Training loss: 3.417947823596654
Validation loss: 3.042908207092331

Epoch: 6| Step: 4
Training loss: 3.2982221264730853
Validation loss: 3.0445374008493356

Epoch: 6| Step: 5
Training loss: 3.1633993325083165
Validation loss: 3.0429802228724574

Epoch: 6| Step: 6
Training loss: 3.8601374934716843
Validation loss: 3.043732458423176

Epoch: 6| Step: 7
Training loss: 2.6863734523404323
Validation loss: 3.044517676699207

Epoch: 6| Step: 8
Training loss: 3.753193576259293
Validation loss: 3.042316844887195

Epoch: 6| Step: 9
Training loss: 2.7633796672211335
Validation loss: 3.0429856972826226

Epoch: 6| Step: 10
Training loss: 3.0561326454894218
Validation loss: 3.0414572938833255

Epoch: 6| Step: 11
Training loss: 3.177304886560792
Validation loss: 3.043297537900764

Epoch: 6| Step: 12
Training loss: 3.9052582969667746
Validation loss: 3.045367150247851

Epoch: 6| Step: 13
Training loss: 3.4722051509861376
Validation loss: 3.0421430597068277

Epoch: 43| Step: 0
Training loss: 3.5060527780045354
Validation loss: 3.042103391460986

Epoch: 6| Step: 1
Training loss: 3.2230592787756716
Validation loss: 3.0414231647203285

Epoch: 6| Step: 2
Training loss: 2.434092952661682
Validation loss: 3.040274476057316

Epoch: 6| Step: 3
Training loss: 3.35947875816328
Validation loss: 3.0419340422118006

Epoch: 6| Step: 4
Training loss: 3.418179122990149
Validation loss: 3.0412985398701102

Epoch: 6| Step: 5
Training loss: 3.037757416794668
Validation loss: 3.0421346747430125

Epoch: 6| Step: 6
Training loss: 2.808997707470576
Validation loss: 3.0420502634153275

Epoch: 6| Step: 7
Training loss: 3.406114488058456
Validation loss: 3.0403124690856718

Epoch: 6| Step: 8
Training loss: 3.6774810201335346
Validation loss: 3.0398463591095797

Epoch: 6| Step: 9
Training loss: 3.213608273764404
Validation loss: 3.0402711638610054

Epoch: 6| Step: 10
Training loss: 3.2257716061648196
Validation loss: 3.036575731909401

Epoch: 6| Step: 11
Training loss: 4.17767844713324
Validation loss: 3.0399109941054094

Epoch: 6| Step: 12
Training loss: 3.7878290115322613
Validation loss: 3.0382997794850066

Epoch: 6| Step: 13
Training loss: 2.5305773936377505
Validation loss: 3.0374588660462947

Epoch: 44| Step: 0
Training loss: 2.921823103336748
Validation loss: 3.037166402230138

Epoch: 6| Step: 1
Training loss: 3.345021514139141
Validation loss: 3.035991490903181

Epoch: 6| Step: 2
Training loss: 3.7405500233975033
Validation loss: 3.0385694159922587

Epoch: 6| Step: 3
Training loss: 3.099492456049445
Validation loss: 3.038865878509522

Epoch: 6| Step: 4
Training loss: 3.656785974587579
Validation loss: 3.0374410278775095

Epoch: 6| Step: 5
Training loss: 3.002257927911999
Validation loss: 3.0348371410123844

Epoch: 6| Step: 6
Training loss: 4.013372004461012
Validation loss: 3.0334670544677884

Epoch: 6| Step: 7
Training loss: 2.853203121256435
Validation loss: 3.0317872043640466

Epoch: 6| Step: 8
Training loss: 2.930936257300788
Validation loss: 3.0318878588638825

Epoch: 6| Step: 9
Training loss: 3.4735461919460646
Validation loss: 3.028005619689258

Epoch: 6| Step: 10
Training loss: 3.3875102138013395
Validation loss: 3.0256279637568353

Epoch: 6| Step: 11
Training loss: 3.3492977431111255
Validation loss: 3.0246041434421365

Epoch: 6| Step: 12
Training loss: 3.307520740815957
Validation loss: 3.018435025536927

Epoch: 6| Step: 13
Training loss: 2.9083015010224798
Validation loss: 3.018881573284518

Epoch: 45| Step: 0
Training loss: 2.9186607265502005
Validation loss: 3.012487043106849

Epoch: 6| Step: 1
Training loss: 3.4580556612493716
Validation loss: 3.0133842046148684

Epoch: 6| Step: 2
Training loss: 3.2881498905552937
Validation loss: 3.015005599066217

Epoch: 6| Step: 3
Training loss: 3.082086946977724
Validation loss: 3.0215554166074736

Epoch: 6| Step: 4
Training loss: 2.8941183889726503
Validation loss: 3.027379352149852

Epoch: 6| Step: 5
Training loss: 3.4198028003435086
Validation loss: 3.044480422429407

Epoch: 6| Step: 6
Training loss: 3.6698049351046915
Validation loss: 3.024792564816988

Epoch: 6| Step: 7
Training loss: 3.422418699225391
Validation loss: 3.01585109177056

Epoch: 6| Step: 8
Training loss: 3.389215413676194
Validation loss: 3.0110222389448684

Epoch: 6| Step: 9
Training loss: 3.4380947638872246
Validation loss: 3.013742993586115

Epoch: 6| Step: 10
Training loss: 3.666846155339587
Validation loss: 3.0087262333341775

Epoch: 6| Step: 11
Training loss: 2.3985581755955616
Validation loss: 3.012271618882327

Epoch: 6| Step: 12
Training loss: 3.8461464955186293
Validation loss: 3.014213279605405

Epoch: 6| Step: 13
Training loss: 2.831405507379117
Validation loss: 3.013688204419511

Epoch: 46| Step: 0
Training loss: 3.331965992546785
Validation loss: 3.0185154532555614

Epoch: 6| Step: 1
Training loss: 3.243265510495529
Validation loss: 3.0180909330598125

Epoch: 6| Step: 2
Training loss: 3.199936037616444
Validation loss: 3.015543174919349

Epoch: 6| Step: 3
Training loss: 3.4626669943300996
Validation loss: 3.0178164961326504

Epoch: 6| Step: 4
Training loss: 3.6843693261592234
Validation loss: 3.014107589066739

Epoch: 6| Step: 5
Training loss: 3.676924978562064
Validation loss: 3.0099035598529116

Epoch: 6| Step: 6
Training loss: 2.7077567929603643
Validation loss: 3.009344400860204

Epoch: 6| Step: 7
Training loss: 2.699771631261043
Validation loss: 3.005313259739959

Epoch: 6| Step: 8
Training loss: 2.590694052002579
Validation loss: 3.005567537331534

Epoch: 6| Step: 9
Training loss: 3.7124675608030095
Validation loss: 3.0060645404859603

Epoch: 6| Step: 10
Training loss: 3.034452025263858
Validation loss: 3.0083916619921927

Epoch: 6| Step: 11
Training loss: 3.3040052210140773
Validation loss: 3.0067798194273436

Epoch: 6| Step: 12
Training loss: 4.0678848964194625
Validation loss: 3.0108313686627297

Epoch: 6| Step: 13
Training loss: 2.9202675707255574
Validation loss: 3.009671503333624

Epoch: 47| Step: 0
Training loss: 3.194756718359311
Validation loss: 3.00623482221991

Epoch: 6| Step: 1
Training loss: 3.2291475521055153
Validation loss: 3.0066293751261837

Epoch: 6| Step: 2
Training loss: 2.713925959831623
Validation loss: 3.0052055176459613

Epoch: 6| Step: 3
Training loss: 3.0213549634939763
Validation loss: 3.002328842109978

Epoch: 6| Step: 4
Training loss: 3.547271168635892
Validation loss: 3.0029400788787775

Epoch: 6| Step: 5
Training loss: 3.3006288391680387
Validation loss: 2.9991687320291054

Epoch: 6| Step: 6
Training loss: 3.290490644561355
Validation loss: 2.9984872449479765

Epoch: 6| Step: 7
Training loss: 2.7340322225160594
Validation loss: 2.999297840913425

Epoch: 6| Step: 8
Training loss: 2.782863191960039
Validation loss: 2.998445219064726

Epoch: 6| Step: 9
Training loss: 3.451964999104351
Validation loss: 2.9989014181318088

Epoch: 6| Step: 10
Training loss: 3.9497107436103365
Validation loss: 2.998759736285334

Epoch: 6| Step: 11
Training loss: 3.2870616490055053
Validation loss: 2.9967668537187016

Epoch: 6| Step: 12
Training loss: 3.2113644207043706
Validation loss: 2.999537747671472

Epoch: 6| Step: 13
Training loss: 4.511787024307548
Validation loss: 2.9986987949522317

Epoch: 48| Step: 0
Training loss: 3.264839187330429
Validation loss: 3.0050029910902634

Epoch: 6| Step: 1
Training loss: 3.3762895451715145
Validation loss: 2.9969356808696452

Epoch: 6| Step: 2
Training loss: 3.2985131410918416
Validation loss: 2.997787548491078

Epoch: 6| Step: 3
Training loss: 3.1335048148393807
Validation loss: 2.997749145641675

Epoch: 6| Step: 4
Training loss: 3.1049853446479445
Validation loss: 3.0012607437705956

Epoch: 6| Step: 5
Training loss: 4.080449987167876
Validation loss: 2.9978262775221562

Epoch: 6| Step: 6
Training loss: 3.1906831592187235
Validation loss: 2.9986959933856654

Epoch: 6| Step: 7
Training loss: 3.6628581265804634
Validation loss: 3.003104434087482

Epoch: 6| Step: 8
Training loss: 3.1670058888560386
Validation loss: 2.9976999428219537

Epoch: 6| Step: 9
Training loss: 3.051599527145111
Validation loss: 2.995002111002474

Epoch: 6| Step: 10
Training loss: 3.13363157300394
Validation loss: 2.996231696494043

Epoch: 6| Step: 11
Training loss: 2.7277060135644287
Validation loss: 2.995453222680475

Epoch: 6| Step: 12
Training loss: 3.289592636768472
Validation loss: 2.994358314238239

Epoch: 6| Step: 13
Training loss: 3.381802943457301
Validation loss: 2.9973847413507526

Epoch: 49| Step: 0
Training loss: 3.0072233341400643
Validation loss: 2.9951906142696534

Epoch: 6| Step: 1
Training loss: 3.6427136107091918
Validation loss: 2.996858271145439

Epoch: 6| Step: 2
Training loss: 3.217457632217137
Validation loss: 2.993100810271335

Epoch: 6| Step: 3
Training loss: 3.2593527978742562
Validation loss: 2.9974483949625608

Epoch: 6| Step: 4
Training loss: 3.61398021638962
Validation loss: 2.9955287516719933

Epoch: 6| Step: 5
Training loss: 2.533683643046138
Validation loss: 2.9951610626635525

Epoch: 6| Step: 6
Training loss: 3.04079954424591
Validation loss: 2.9950742395461347

Epoch: 6| Step: 7
Training loss: 2.979066451372291
Validation loss: 2.9966866199339632

Epoch: 6| Step: 8
Training loss: 3.0940608629430986
Validation loss: 2.9943698038422584

Epoch: 6| Step: 9
Training loss: 3.8862055300686342
Validation loss: 2.9952419407261583

Epoch: 6| Step: 10
Training loss: 2.8905098557092224
Validation loss: 2.9956766110280673

Epoch: 6| Step: 11
Training loss: 3.0098229761124125
Validation loss: 2.993739688936115

Epoch: 6| Step: 12
Training loss: 3.8485049478410613
Validation loss: 2.9929173345019517

Epoch: 6| Step: 13
Training loss: 3.8686820176765684
Validation loss: 2.9904547386750564

Epoch: 50| Step: 0
Training loss: 2.946912416966939
Validation loss: 2.9900223564458734

Epoch: 6| Step: 1
Training loss: 3.1960608018861323
Validation loss: 2.9901256043034965

Epoch: 6| Step: 2
Training loss: 3.163061365053906
Validation loss: 2.9903752425526537

Epoch: 6| Step: 3
Training loss: 3.592415736092198
Validation loss: 2.9898386240240895

Epoch: 6| Step: 4
Training loss: 3.3071092610357935
Validation loss: 2.988046597093347

Epoch: 6| Step: 5
Training loss: 3.179737737385309
Validation loss: 2.988828331261331

Epoch: 6| Step: 6
Training loss: 3.638106756303843
Validation loss: 2.9889895925139514

Epoch: 6| Step: 7
Training loss: 3.48841439021882
Validation loss: 2.987535084951632

Epoch: 6| Step: 8
Training loss: 3.451589665925518
Validation loss: 2.988379926377367

Epoch: 6| Step: 9
Training loss: 3.2195614282702034
Validation loss: 2.986313951806178

Epoch: 6| Step: 10
Training loss: 3.8455079563382446
Validation loss: 2.9873429276889034

Epoch: 6| Step: 11
Training loss: 2.51224769729902
Validation loss: 2.987475698698919

Epoch: 6| Step: 12
Training loss: 3.221206320369161
Validation loss: 2.988140017770949

Epoch: 6| Step: 13
Training loss: 2.643366276734977
Validation loss: 2.9899844832001774

Epoch: 51| Step: 0
Training loss: 4.043863597376827
Validation loss: 2.9868713737668187

Epoch: 6| Step: 1
Training loss: 3.179215079789282
Validation loss: 2.9886605352545748

Epoch: 6| Step: 2
Training loss: 2.9361965452925474
Validation loss: 2.9875200447793016

Epoch: 6| Step: 3
Training loss: 3.295518207234095
Validation loss: 2.989157416362032

Epoch: 6| Step: 4
Training loss: 3.037393224275868
Validation loss: 2.988445906124505

Epoch: 6| Step: 5
Training loss: 2.6682595224395538
Validation loss: 2.9867750457270663

Epoch: 6| Step: 6
Training loss: 3.7114974392524034
Validation loss: 2.986332788146338

Epoch: 6| Step: 7
Training loss: 3.882928919438032
Validation loss: 2.984505910202916

Epoch: 6| Step: 8
Training loss: 3.7337089167998387
Validation loss: 2.987418889994581

Epoch: 6| Step: 9
Training loss: 2.7468142696953772
Validation loss: 2.9854829202006727

Epoch: 6| Step: 10
Training loss: 2.8294859925533586
Validation loss: 2.984139338915502

Epoch: 6| Step: 11
Training loss: 2.5610931069915135
Validation loss: 2.984655072355593

Epoch: 6| Step: 12
Training loss: 3.5933894764389684
Validation loss: 2.982873408398428

Epoch: 6| Step: 13
Training loss: 3.014332548693214
Validation loss: 2.9811806076296836

Epoch: 52| Step: 0
Training loss: 3.4056212518636038
Validation loss: 2.9846156441568468

Epoch: 6| Step: 1
Training loss: 3.1671681927175754
Validation loss: 2.981733828838609

Epoch: 6| Step: 2
Training loss: 3.254175877934573
Validation loss: 2.9852004685356133

Epoch: 6| Step: 3
Training loss: 3.5156141492888104
Validation loss: 2.9849515277617003

Epoch: 6| Step: 4
Training loss: 3.9183827692047872
Validation loss: 2.9796106197171746

Epoch: 6| Step: 5
Training loss: 3.138113507475984
Validation loss: 2.979132814657472

Epoch: 6| Step: 6
Training loss: 3.1316868764710084
Validation loss: 2.9813787908775593

Epoch: 6| Step: 7
Training loss: 3.864154898174684
Validation loss: 2.9814122986583227

Epoch: 6| Step: 8
Training loss: 2.8386572204774305
Validation loss: 2.977213892416188

Epoch: 6| Step: 9
Training loss: 3.0397887159006456
Validation loss: 2.981104452826129

Epoch: 6| Step: 10
Training loss: 2.466672385269272
Validation loss: 2.9789303589001768

Epoch: 6| Step: 11
Training loss: 3.424186448422038
Validation loss: 2.9770882175379976

Epoch: 6| Step: 12
Training loss: 3.2149345227540334
Validation loss: 2.977308717267767

Epoch: 6| Step: 13
Training loss: 3.0407430910111803
Validation loss: 2.9783325324090826

Epoch: 53| Step: 0
Training loss: 2.9496917951544304
Validation loss: 2.97910623785292

Epoch: 6| Step: 1
Training loss: 3.338735224706476
Validation loss: 2.9786713596663996

Epoch: 6| Step: 2
Training loss: 2.703694366291863
Validation loss: 2.9823144027768644

Epoch: 6| Step: 3
Training loss: 3.4043886190933037
Validation loss: 2.995346290767991

Epoch: 6| Step: 4
Training loss: 3.3138898416926197
Validation loss: 3.013036651800953

Epoch: 6| Step: 5
Training loss: 3.56116755145399
Validation loss: 3.0057534760062503

Epoch: 6| Step: 6
Training loss: 3.37712312957704
Validation loss: 2.9804075946559316

Epoch: 6| Step: 7
Training loss: 3.177591818886758
Validation loss: 2.972117871048125

Epoch: 6| Step: 8
Training loss: 2.9535888630505154
Validation loss: 2.9771089808755034

Epoch: 6| Step: 9
Training loss: 3.6687153959185768
Validation loss: 2.980677314537466

Epoch: 6| Step: 10
Training loss: 3.5261969407723535
Validation loss: 2.991191387090862

Epoch: 6| Step: 11
Training loss: 2.9617057347194073
Validation loss: 3.0002686745985314

Epoch: 6| Step: 12
Training loss: 3.5313377707047033
Validation loss: 2.9914660984327477

Epoch: 6| Step: 13
Training loss: 3.258901875903535
Validation loss: 2.982541139826049

Epoch: 54| Step: 0
Training loss: 3.5287161319200573
Validation loss: 2.979886788395772

Epoch: 6| Step: 1
Training loss: 3.0709453056828617
Validation loss: 2.979592527286373

Epoch: 6| Step: 2
Training loss: 3.2007601312001603
Validation loss: 2.984622417842145

Epoch: 6| Step: 3
Training loss: 2.4584479439953495
Validation loss: 2.9879824360349114

Epoch: 6| Step: 4
Training loss: 4.052952977914563
Validation loss: 2.9954607113060194

Epoch: 6| Step: 5
Training loss: 2.820468126901012
Validation loss: 2.994409864715844

Epoch: 6| Step: 6
Training loss: 2.67458380197629
Validation loss: 2.999753244568074

Epoch: 6| Step: 7
Training loss: 3.6092489641651415
Validation loss: 3.000444412641674

Epoch: 6| Step: 8
Training loss: 3.7695239131243365
Validation loss: 2.995488731437122

Epoch: 6| Step: 9
Training loss: 3.836794879758471
Validation loss: 2.988571718444341

Epoch: 6| Step: 10
Training loss: 3.431895455553196
Validation loss: 2.97662500900371

Epoch: 6| Step: 11
Training loss: 2.578122503106035
Validation loss: 2.9759991362749423

Epoch: 6| Step: 12
Training loss: 3.3617119755589133
Validation loss: 2.9767902039447605

Epoch: 6| Step: 13
Training loss: 2.7880871346866956
Validation loss: 2.9751564938134516

Epoch: 55| Step: 0
Training loss: 3.211640886547415
Validation loss: 2.9767955692764336

Epoch: 6| Step: 1
Training loss: 3.0548785606009825
Validation loss: 2.9819577626501554

Epoch: 6| Step: 2
Training loss: 3.21356286897677
Validation loss: 3.0015405199794896

Epoch: 6| Step: 3
Training loss: 3.292015218187386
Validation loss: 2.995916479173395

Epoch: 6| Step: 4
Training loss: 4.152840729019772
Validation loss: 3.0038517260628064

Epoch: 6| Step: 5
Training loss: 3.3011208624752646
Validation loss: 2.971089246414905

Epoch: 6| Step: 6
Training loss: 3.7793946561559273
Validation loss: 2.973498823319964

Epoch: 6| Step: 7
Training loss: 3.2361968433409762
Validation loss: 2.9697039036138375

Epoch: 6| Step: 8
Training loss: 3.038827921387327
Validation loss: 2.9710300862670147

Epoch: 6| Step: 9
Training loss: 3.1790244421053795
Validation loss: 2.9712311614248486

Epoch: 6| Step: 10
Training loss: 2.886532747834552
Validation loss: 2.9694324600591457

Epoch: 6| Step: 11
Training loss: 2.9535709427889003
Validation loss: 2.972473629631544

Epoch: 6| Step: 12
Training loss: 3.388143730231429
Validation loss: 2.9688018569778087

Epoch: 6| Step: 13
Training loss: 2.6410885014696523
Validation loss: 2.970580031238579

Epoch: 56| Step: 0
Training loss: 3.4891125413626236
Validation loss: 2.9680561785543147

Epoch: 6| Step: 1
Training loss: 2.4094798222362077
Validation loss: 2.9703928065116756

Epoch: 6| Step: 2
Training loss: 2.92843853585845
Validation loss: 2.9732886084820964

Epoch: 6| Step: 3
Training loss: 2.840059673595779
Validation loss: 2.971090022990793

Epoch: 6| Step: 4
Training loss: 3.094439651223775
Validation loss: 2.976841516960797

Epoch: 6| Step: 5
Training loss: 3.9926025413764594
Validation loss: 2.9788015411339392

Epoch: 6| Step: 6
Training loss: 2.8735074024918212
Validation loss: 2.9774261256131314

Epoch: 6| Step: 7
Training loss: 2.8939256124578345
Validation loss: 2.9761095689361943

Epoch: 6| Step: 8
Training loss: 4.179485337546667
Validation loss: 2.9721095386722483

Epoch: 6| Step: 9
Training loss: 3.3531469054630905
Validation loss: 2.9720464309485837

Epoch: 6| Step: 10
Training loss: 3.450586827444768
Validation loss: 2.969608875638594

Epoch: 6| Step: 11
Training loss: 3.4199999544913307
Validation loss: 2.9675398617806006

Epoch: 6| Step: 12
Training loss: 2.727360649570109
Validation loss: 2.967937694701143

Epoch: 6| Step: 13
Training loss: 3.8466620850384254
Validation loss: 2.9665219178189792

Epoch: 57| Step: 0
Training loss: 2.739506728886561
Validation loss: 2.961062076839864

Epoch: 6| Step: 1
Training loss: 2.7438638024853486
Validation loss: 2.9618286277585537

Epoch: 6| Step: 2
Training loss: 3.277085049663724
Validation loss: 2.9634132572978267

Epoch: 6| Step: 3
Training loss: 2.487570189439425
Validation loss: 2.9612991190542046

Epoch: 6| Step: 4
Training loss: 3.5014125153516447
Validation loss: 2.964367599154798

Epoch: 6| Step: 5
Training loss: 3.912717302521756
Validation loss: 2.96150466638986

Epoch: 6| Step: 6
Training loss: 3.6261606660271255
Validation loss: 2.9644018898841056

Epoch: 6| Step: 7
Training loss: 3.059256568307474
Validation loss: 2.962230654863841

Epoch: 6| Step: 8
Training loss: 3.9672783954269315
Validation loss: 2.9613327380340237

Epoch: 6| Step: 9
Training loss: 3.806071881415787
Validation loss: 2.962737136085952

Epoch: 6| Step: 10
Training loss: 2.9162765968702495
Validation loss: 2.9611555627374346

Epoch: 6| Step: 11
Training loss: 2.9275164481726295
Validation loss: 2.962166980104739

Epoch: 6| Step: 12
Training loss: 2.981752531614594
Validation loss: 2.9612084461550507

Epoch: 6| Step: 13
Training loss: 3.312293424102997
Validation loss: 2.959732236776732

Epoch: 58| Step: 0
Training loss: 3.1812851100100845
Validation loss: 2.9598198800768407

Epoch: 6| Step: 1
Training loss: 3.5107974667501205
Validation loss: 2.961568900739665

Epoch: 6| Step: 2
Training loss: 2.8484592221384437
Validation loss: 2.9607726431714156

Epoch: 6| Step: 3
Training loss: 2.902507710606784
Validation loss: 2.9603406574242683

Epoch: 6| Step: 4
Training loss: 3.0814835094312096
Validation loss: 2.9584783327605155

Epoch: 6| Step: 5
Training loss: 3.091047860156697
Validation loss: 2.9579097046437575

Epoch: 6| Step: 6
Training loss: 3.278410054950924
Validation loss: 2.9580974533925444

Epoch: 6| Step: 7
Training loss: 3.4854595053244894
Validation loss: 2.959243862779576

Epoch: 6| Step: 8
Training loss: 3.3186933092350848
Validation loss: 2.9595578787786994

Epoch: 6| Step: 9
Training loss: 3.3156608040302937
Validation loss: 2.9572738513481363

Epoch: 6| Step: 10
Training loss: 2.9025251247163
Validation loss: 2.957055661881019

Epoch: 6| Step: 11
Training loss: 3.4863627285134955
Validation loss: 2.957412526738014

Epoch: 6| Step: 12
Training loss: 4.292845233948776
Validation loss: 2.9584948099780073

Epoch: 6| Step: 13
Training loss: 1.821417804493857
Validation loss: 2.958337632736093

Epoch: 59| Step: 0
Training loss: 3.227865108578685
Validation loss: 2.9576032775613394

Epoch: 6| Step: 1
Training loss: 3.257091268570673
Validation loss: 2.9601094848502405

Epoch: 6| Step: 2
Training loss: 3.4432909650925647
Validation loss: 2.961482476112397

Epoch: 6| Step: 3
Training loss: 2.555450792054183
Validation loss: 2.9608333139761362

Epoch: 6| Step: 4
Training loss: 3.4298227757081143
Validation loss: 2.9687936828197365

Epoch: 6| Step: 5
Training loss: 3.247911956242116
Validation loss: 2.9692028121302525

Epoch: 6| Step: 6
Training loss: 2.4863361799015244
Validation loss: 2.968250267571448

Epoch: 6| Step: 7
Training loss: 3.310021822992858
Validation loss: 2.9627156697781545

Epoch: 6| Step: 8
Training loss: 3.7854381727924418
Validation loss: 2.9584415357653335

Epoch: 6| Step: 9
Training loss: 3.3869403559814257
Validation loss: 2.9569558890317187

Epoch: 6| Step: 10
Training loss: 3.7989384573871603
Validation loss: 2.9547115955012457

Epoch: 6| Step: 11
Training loss: 2.4976087578203905
Validation loss: 2.9542071609247587

Epoch: 6| Step: 12
Training loss: 3.3509903710664375
Validation loss: 2.9534060115598817

Epoch: 6| Step: 13
Training loss: 3.5417495867428106
Validation loss: 2.9539202754180214

Epoch: 60| Step: 0
Training loss: 3.449384225265185
Validation loss: 2.954894480723234

Epoch: 6| Step: 1
Training loss: 3.8326671823167366
Validation loss: 2.9537082627193905

Epoch: 6| Step: 2
Training loss: 3.3422667163593767
Validation loss: 2.9536514885027145

Epoch: 6| Step: 3
Training loss: 2.7890055674664556
Validation loss: 2.953404943884615

Epoch: 6| Step: 4
Training loss: 3.57640267444575
Validation loss: 2.953477133487962

Epoch: 6| Step: 5
Training loss: 2.904978648384666
Validation loss: 2.9545180245102936

Epoch: 6| Step: 6
Training loss: 2.9949576600000327
Validation loss: 2.952178864282255

Epoch: 6| Step: 7
Training loss: 2.832065934593639
Validation loss: 2.9511604482869407

Epoch: 6| Step: 8
Training loss: 3.6946167885744936
Validation loss: 2.9547324943915805

Epoch: 6| Step: 9
Training loss: 3.480463269846976
Validation loss: 2.952393289609918

Epoch: 6| Step: 10
Training loss: 2.416304352884595
Validation loss: 2.953932554989769

Epoch: 6| Step: 11
Training loss: 3.373625298732804
Validation loss: 2.9564768471603804

Epoch: 6| Step: 12
Training loss: 3.233453149312485
Validation loss: 2.9555867201145136

Epoch: 6| Step: 13
Training loss: 3.2451246814256685
Validation loss: 2.9534289447842195

Epoch: 61| Step: 0
Training loss: 3.008429922171805
Validation loss: 2.954403980260445

Epoch: 6| Step: 1
Training loss: 3.3829342862026786
Validation loss: 2.960390200591919

Epoch: 6| Step: 2
Training loss: 3.5486789770701725
Validation loss: 2.9623766150879036

Epoch: 6| Step: 3
Training loss: 2.862310018440106
Validation loss: 2.968520320001876

Epoch: 6| Step: 4
Training loss: 2.602391474620318
Validation loss: 2.9679674085312424

Epoch: 6| Step: 5
Training loss: 3.7836955335444165
Validation loss: 2.961009949248473

Epoch: 6| Step: 6
Training loss: 2.060589685944487
Validation loss: 2.9487089226450443

Epoch: 6| Step: 7
Training loss: 3.2230378266049056
Validation loss: 2.949799260073561

Epoch: 6| Step: 8
Training loss: 3.72651617953065
Validation loss: 2.951999717942769

Epoch: 6| Step: 9
Training loss: 3.3409934401848798
Validation loss: 2.954615363431212

Epoch: 6| Step: 10
Training loss: 3.278578915366331
Validation loss: 2.9664001335665566

Epoch: 6| Step: 11
Training loss: 3.839716461959105
Validation loss: 2.9576881452712525

Epoch: 6| Step: 12
Training loss: 2.7199953230649343
Validation loss: 2.9527481775378357

Epoch: 6| Step: 13
Training loss: 3.9942075989571317
Validation loss: 2.9532771412348953

Epoch: 62| Step: 0
Training loss: 2.742886967581995
Validation loss: 2.9536077318939267

Epoch: 6| Step: 1
Training loss: 3.616182850999827
Validation loss: 2.9550260662278913

Epoch: 6| Step: 2
Training loss: 3.447542675437449
Validation loss: 2.955271444169058

Epoch: 6| Step: 3
Training loss: 4.024674605017098
Validation loss: 2.9528618516432195

Epoch: 6| Step: 4
Training loss: 3.096081866372207
Validation loss: 2.9539502864659095

Epoch: 6| Step: 5
Training loss: 2.7272524247714274
Validation loss: 2.956055629334161

Epoch: 6| Step: 6
Training loss: 3.512284247128839
Validation loss: 2.958010610135633

Epoch: 6| Step: 7
Training loss: 2.923075383490956
Validation loss: 2.962647109461293

Epoch: 6| Step: 8
Training loss: 2.3026587916322194
Validation loss: 2.961868971239302

Epoch: 6| Step: 9
Training loss: 3.518298543965565
Validation loss: 2.9610989849884772

Epoch: 6| Step: 10
Training loss: 3.4693938336542374
Validation loss: 2.9626012401728556

Epoch: 6| Step: 11
Training loss: 3.405663676064166
Validation loss: 2.9682579621533596

Epoch: 6| Step: 12
Training loss: 2.7415050733381237
Validation loss: 2.961186286556217

Epoch: 6| Step: 13
Training loss: 3.725292957230008
Validation loss: 2.96034114238151

Epoch: 63| Step: 0
Training loss: 3.605545059669499
Validation loss: 2.9546758639302917

Epoch: 6| Step: 1
Training loss: 3.219672061735423
Validation loss: 2.955302163232288

Epoch: 6| Step: 2
Training loss: 3.5783035700187575
Validation loss: 2.950665090666819

Epoch: 6| Step: 3
Training loss: 3.2876042918788855
Validation loss: 2.9504886971513775

Epoch: 6| Step: 4
Training loss: 3.5226202649283374
Validation loss: 2.9517127924620787

Epoch: 6| Step: 5
Training loss: 3.456860761156209
Validation loss: 2.9544613977475596

Epoch: 6| Step: 6
Training loss: 3.385328806201642
Validation loss: 2.9548358795578586

Epoch: 6| Step: 7
Training loss: 2.898880999172488
Validation loss: 2.9543368879404137

Epoch: 6| Step: 8
Training loss: 3.4641212991792374
Validation loss: 2.95338091848496

Epoch: 6| Step: 9
Training loss: 3.157046982259428
Validation loss: 2.9547154721364013

Epoch: 6| Step: 10
Training loss: 2.920520652182035
Validation loss: 2.952281434911657

Epoch: 6| Step: 11
Training loss: 3.2976945337578
Validation loss: 2.9513493212935553

Epoch: 6| Step: 12
Training loss: 2.4765388174759813
Validation loss: 2.9506920921924684

Epoch: 6| Step: 13
Training loss: 2.9792948519643714
Validation loss: 2.948695825805271

Epoch: 64| Step: 0
Training loss: 3.024257499428837
Validation loss: 2.9481716784179386

Epoch: 6| Step: 1
Training loss: 3.0093692070418996
Validation loss: 2.9479321057216716

Epoch: 6| Step: 2
Training loss: 3.3778135087259398
Validation loss: 2.9476708385367143

Epoch: 6| Step: 3
Training loss: 3.357170765769461
Validation loss: 2.9470890097470654

Epoch: 6| Step: 4
Training loss: 3.1781794090452324
Validation loss: 2.947933478013786

Epoch: 6| Step: 5
Training loss: 3.025929609227551
Validation loss: 2.946817325635798

Epoch: 6| Step: 6
Training loss: 3.0688726334628944
Validation loss: 2.9452767605926717

Epoch: 6| Step: 7
Training loss: 3.0322872628787496
Validation loss: 2.943211131147392

Epoch: 6| Step: 8
Training loss: 3.732154601072763
Validation loss: 2.941851538744522

Epoch: 6| Step: 9
Training loss: 3.596968296143561
Validation loss: 2.943012191296915

Epoch: 6| Step: 10
Training loss: 2.953941918465225
Validation loss: 2.9426801759485484

Epoch: 6| Step: 11
Training loss: 3.57962604338409
Validation loss: 2.9421731644983495

Epoch: 6| Step: 12
Training loss: 3.4023942034864167
Validation loss: 2.9456836767610004

Epoch: 6| Step: 13
Training loss: 2.7399809129426056
Validation loss: 2.942928666122385

Epoch: 65| Step: 0
Training loss: 3.412902774725856
Validation loss: 2.947991185884435

Epoch: 6| Step: 1
Training loss: 3.502652661674429
Validation loss: 2.946445150141834

Epoch: 6| Step: 2
Training loss: 2.747529393907505
Validation loss: 2.9523682660775923

Epoch: 6| Step: 3
Training loss: 2.815023858086151
Validation loss: 2.9546746908598815

Epoch: 6| Step: 4
Training loss: 2.9866314890470145
Validation loss: 2.951811500579821

Epoch: 6| Step: 5
Training loss: 2.8419230534702558
Validation loss: 2.95324255553115

Epoch: 6| Step: 6
Training loss: 3.0921910529287318
Validation loss: 2.9532601843772937

Epoch: 6| Step: 7
Training loss: 3.1121560699533624
Validation loss: 2.9521049964246515

Epoch: 6| Step: 8
Training loss: 3.3671920316094797
Validation loss: 2.9499096723979332

Epoch: 6| Step: 9
Training loss: 3.0543521784863987
Validation loss: 2.9507655280027447

Epoch: 6| Step: 10
Training loss: 4.007687810255766
Validation loss: 2.949509214882932

Epoch: 6| Step: 11
Training loss: 3.493109050229035
Validation loss: 2.9471555041903668

Epoch: 6| Step: 12
Training loss: 3.679228476627612
Validation loss: 2.9436560615178524

Epoch: 6| Step: 13
Training loss: 2.6731751608094543
Validation loss: 2.9384447497234913

Epoch: 66| Step: 0
Training loss: 2.743864584509188
Validation loss: 2.938066559253127

Epoch: 6| Step: 1
Training loss: 2.635870450924631
Validation loss: 2.9362714088096813

Epoch: 6| Step: 2
Training loss: 2.3503826641438015
Validation loss: 2.937372933185473

Epoch: 6| Step: 3
Training loss: 2.9971218608103616
Validation loss: 2.9389282451298153

Epoch: 6| Step: 4
Training loss: 2.779638530778038
Validation loss: 2.9383085800984996

Epoch: 6| Step: 5
Training loss: 2.6507946766210577
Validation loss: 2.9387180183077235

Epoch: 6| Step: 6
Training loss: 3.453392191082161
Validation loss: 2.937691809039197

Epoch: 6| Step: 7
Training loss: 3.7690129531552747
Validation loss: 2.938237365846374

Epoch: 6| Step: 8
Training loss: 3.441702475988815
Validation loss: 2.9374085016952525

Epoch: 6| Step: 9
Training loss: 3.4413123058438826
Validation loss: 2.9366329818757912

Epoch: 6| Step: 10
Training loss: 2.8494458847784356
Validation loss: 2.933954663931291

Epoch: 6| Step: 11
Training loss: 4.4356242769006125
Validation loss: 2.9351411545813173

Epoch: 6| Step: 12
Training loss: 3.956409522240869
Validation loss: 2.937774657581023

Epoch: 6| Step: 13
Training loss: 2.979826171720739
Validation loss: 2.9371893078517406

Epoch: 67| Step: 0
Training loss: 3.179585523165102
Validation loss: 2.9360414993441006

Epoch: 6| Step: 1
Training loss: 3.1072171645526208
Validation loss: 2.9384232856761328

Epoch: 6| Step: 2
Training loss: 3.550899692486206
Validation loss: 2.934090011592626

Epoch: 6| Step: 3
Training loss: 2.6355751100539866
Validation loss: 2.9358297201702577

Epoch: 6| Step: 4
Training loss: 3.447763414616987
Validation loss: 2.9354214511199666

Epoch: 6| Step: 5
Training loss: 3.4537212150553267
Validation loss: 2.938903920815305

Epoch: 6| Step: 6
Training loss: 3.620191871236981
Validation loss: 2.935802776681594

Epoch: 6| Step: 7
Training loss: 3.161180629610156
Validation loss: 2.9377914158487877

Epoch: 6| Step: 8
Training loss: 3.334827247274593
Validation loss: 2.9356917569449026

Epoch: 6| Step: 9
Training loss: 3.0727507638058977
Validation loss: 2.935316477336453

Epoch: 6| Step: 10
Training loss: 3.4398145339560298
Validation loss: 2.9348924243398864

Epoch: 6| Step: 11
Training loss: 3.4231037041581702
Validation loss: 2.9376439452221095

Epoch: 6| Step: 12
Training loss: 2.384879394616775
Validation loss: 2.938933031461273

Epoch: 6| Step: 13
Training loss: 3.0927722040769563
Validation loss: 2.936054658743054

Epoch: 68| Step: 0
Training loss: 3.1881656325711822
Validation loss: 2.9492339429034136

Epoch: 6| Step: 1
Training loss: 3.337635903323899
Validation loss: 2.9429033756912615

Epoch: 6| Step: 2
Training loss: 3.026724672083767
Validation loss: 2.9366379456722287

Epoch: 6| Step: 3
Training loss: 3.3219876002034927
Validation loss: 2.933185341906261

Epoch: 6| Step: 4
Training loss: 2.7695631878172153
Validation loss: 2.9337485591688575

Epoch: 6| Step: 5
Training loss: 3.541493505096835
Validation loss: 2.9321263650163183

Epoch: 6| Step: 6
Training loss: 3.097857744126453
Validation loss: 2.932131589996718

Epoch: 6| Step: 7
Training loss: 3.482317535155204
Validation loss: 2.932009076794441

Epoch: 6| Step: 8
Training loss: 2.964302506128441
Validation loss: 2.9309379725539952

Epoch: 6| Step: 9
Training loss: 3.1400340269152416
Validation loss: 2.93213188377044

Epoch: 6| Step: 10
Training loss: 3.055108160923106
Validation loss: 2.9323020367613952

Epoch: 6| Step: 11
Training loss: 3.416877616014695
Validation loss: 2.9318697682022528

Epoch: 6| Step: 12
Training loss: 3.4953158232358055
Validation loss: 2.933662185339334

Epoch: 6| Step: 13
Training loss: 3.450191166322162
Validation loss: 2.9344891801461306

Epoch: 69| Step: 0
Training loss: 3.1830700777125385
Validation loss: 2.9376468940264986

Epoch: 6| Step: 1
Training loss: 3.3958324752213658
Validation loss: 2.939341140700009

Epoch: 6| Step: 2
Training loss: 3.093863745245661
Validation loss: 2.933448497885431

Epoch: 6| Step: 3
Training loss: 3.646843703004096
Validation loss: 2.934746224060249

Epoch: 6| Step: 4
Training loss: 2.9296035144211894
Validation loss: 2.9397855030630033

Epoch: 6| Step: 5
Training loss: 2.959080418202033
Validation loss: 2.935777171624224

Epoch: 6| Step: 6
Training loss: 3.1547388670595127
Validation loss: 2.9321286347713302

Epoch: 6| Step: 7
Training loss: 3.190020892035972
Validation loss: 2.9342764536897397

Epoch: 6| Step: 8
Training loss: 3.0733843086577397
Validation loss: 2.9312716406241517

Epoch: 6| Step: 9
Training loss: 3.7268622895580124
Validation loss: 2.93365260595604

Epoch: 6| Step: 10
Training loss: 3.758259641569122
Validation loss: 2.9352051675753943

Epoch: 6| Step: 11
Training loss: 3.0074004448373532
Validation loss: 2.932294503991643

Epoch: 6| Step: 12
Training loss: 2.9872445097015725
Validation loss: 2.930210948491316

Epoch: 6| Step: 13
Training loss: 2.6060744558077897
Validation loss: 2.9309543281995047

Epoch: 70| Step: 0
Training loss: 3.553417205202411
Validation loss: 2.928758831762505

Epoch: 6| Step: 1
Training loss: 4.075134115995999
Validation loss: 2.932514850493634

Epoch: 6| Step: 2
Training loss: 2.9074991474494767
Validation loss: 2.929037471289741

Epoch: 6| Step: 3
Training loss: 2.5987687790317393
Validation loss: 2.9286612252019637

Epoch: 6| Step: 4
Training loss: 2.9290881548398713
Validation loss: 2.931360313263361

Epoch: 6| Step: 5
Training loss: 2.5235372706669725
Validation loss: 2.9283743364290116

Epoch: 6| Step: 6
Training loss: 3.5529959541982756
Validation loss: 2.9405754866408143

Epoch: 6| Step: 7
Training loss: 2.6692232949590506
Validation loss: 2.9388503246159035

Epoch: 6| Step: 8
Training loss: 3.167178430530151
Validation loss: 2.932972269149517

Epoch: 6| Step: 9
Training loss: 3.835036535176067
Validation loss: 2.932508012396829

Epoch: 6| Step: 10
Training loss: 3.3326362516761905
Validation loss: 2.927477525456111

Epoch: 6| Step: 11
Training loss: 3.331744594251006
Validation loss: 2.9307141738258773

Epoch: 6| Step: 12
Training loss: 2.9950386984845325
Validation loss: 2.9268309641654833

Epoch: 6| Step: 13
Training loss: 3.255780581211388
Validation loss: 2.925842551762457

Epoch: 71| Step: 0
Training loss: 2.405236166860041
Validation loss: 2.927127242383923

Epoch: 6| Step: 1
Training loss: 2.972161029966128
Validation loss: 2.9257087152531005

Epoch: 6| Step: 2
Training loss: 3.271894797016576
Validation loss: 2.9243521436461046

Epoch: 6| Step: 3
Training loss: 3.444708185113918
Validation loss: 2.9275322020622343

Epoch: 6| Step: 4
Training loss: 2.900853551019577
Validation loss: 2.9249805027336717

Epoch: 6| Step: 5
Training loss: 3.3910297204990134
Validation loss: 2.9287471311566184

Epoch: 6| Step: 6
Training loss: 3.572628547165651
Validation loss: 2.9263284307016644

Epoch: 6| Step: 7
Training loss: 3.4439899561754395
Validation loss: 2.9253206947921795

Epoch: 6| Step: 8
Training loss: 3.607664421284097
Validation loss: 2.927526089668217

Epoch: 6| Step: 9
Training loss: 3.330793144003339
Validation loss: 2.9263922562666043

Epoch: 6| Step: 10
Training loss: 2.854668751755793
Validation loss: 2.9291452826253535

Epoch: 6| Step: 11
Training loss: 3.3131061215340485
Validation loss: 2.9260300047620986

Epoch: 6| Step: 12
Training loss: 3.335182122286332
Validation loss: 2.924893794600164

Epoch: 6| Step: 13
Training loss: 2.916225745161153
Validation loss: 2.924403960363365

Epoch: 72| Step: 0
Training loss: 4.126845438283868
Validation loss: 2.923877995752413

Epoch: 6| Step: 1
Training loss: 3.085834279325915
Validation loss: 2.9263380428212615

Epoch: 6| Step: 2
Training loss: 2.6575863337735544
Validation loss: 2.924509298671417

Epoch: 6| Step: 3
Training loss: 3.5132799253319162
Validation loss: 2.9228715708954858

Epoch: 6| Step: 4
Training loss: 3.6722089899632344
Validation loss: 2.922791794365162

Epoch: 6| Step: 5
Training loss: 3.1609124220844667
Validation loss: 2.9210919211581237

Epoch: 6| Step: 6
Training loss: 2.811679466081244
Validation loss: 2.923222702433761

Epoch: 6| Step: 7
Training loss: 3.5965390205064356
Validation loss: 2.924353591875686

Epoch: 6| Step: 8
Training loss: 3.1532862883829478
Validation loss: 2.9232897862301788

Epoch: 6| Step: 9
Training loss: 2.5147976669919596
Validation loss: 2.919737910775981

Epoch: 6| Step: 10
Training loss: 3.1749813109320923
Validation loss: 2.922229870982538

Epoch: 6| Step: 11
Training loss: 3.4226577769234496
Validation loss: 2.9206965479934937

Epoch: 6| Step: 12
Training loss: 2.557405944466956
Validation loss: 2.9211073867295285

Epoch: 6| Step: 13
Training loss: 3.156550024899397
Validation loss: 2.9234115037758497

Epoch: 73| Step: 0
Training loss: 2.7990820503978835
Validation loss: 2.9253352274713262

Epoch: 6| Step: 1
Training loss: 3.5920076873629068
Validation loss: 2.9249759223282847

Epoch: 6| Step: 2
Training loss: 2.7116466111479203
Validation loss: 2.927323164953259

Epoch: 6| Step: 3
Training loss: 2.85434969201509
Validation loss: 2.925520917434985

Epoch: 6| Step: 4
Training loss: 3.304179411803812
Validation loss: 2.9273124648642135

Epoch: 6| Step: 5
Training loss: 3.3035837769737846
Validation loss: 2.926592307488674

Epoch: 6| Step: 6
Training loss: 3.485980976676576
Validation loss: 2.925238085967061

Epoch: 6| Step: 7
Training loss: 3.345319433084829
Validation loss: 2.926062147017523

Epoch: 6| Step: 8
Training loss: 2.605781593585782
Validation loss: 2.9217781584741433

Epoch: 6| Step: 9
Training loss: 3.511318434323039
Validation loss: 2.9242181810615824

Epoch: 6| Step: 10
Training loss: 2.388233060291343
Validation loss: 2.923255742014158

Epoch: 6| Step: 11
Training loss: 3.725186843794442
Validation loss: 2.920205692791342

Epoch: 6| Step: 12
Training loss: 3.8909203597256443
Validation loss: 2.9226838539217876

Epoch: 6| Step: 13
Training loss: 3.170723992833957
Validation loss: 2.9215396076407756

Epoch: 74| Step: 0
Training loss: 3.759388678344297
Validation loss: 2.9195682899935194

Epoch: 6| Step: 1
Training loss: 2.6781670619372324
Validation loss: 2.9181156063561398

Epoch: 6| Step: 2
Training loss: 3.3906528454177742
Validation loss: 2.9196351855552147

Epoch: 6| Step: 3
Training loss: 3.017534827258141
Validation loss: 2.9202643647108637

Epoch: 6| Step: 4
Training loss: 3.598479235825732
Validation loss: 2.9180990056803013

Epoch: 6| Step: 5
Training loss: 3.2496895275005095
Validation loss: 2.917802525038968

Epoch: 6| Step: 6
Training loss: 2.834593399196705
Validation loss: 2.9185868325342557

Epoch: 6| Step: 7
Training loss: 3.0404404210741514
Validation loss: 2.918003737094697

Epoch: 6| Step: 8
Training loss: 2.6835362679490107
Validation loss: 2.918537919298765

Epoch: 6| Step: 9
Training loss: 4.0844906055810775
Validation loss: 2.916858117167729

Epoch: 6| Step: 10
Training loss: 2.999924022984042
Validation loss: 2.919650016099995

Epoch: 6| Step: 11
Training loss: 3.783129012406492
Validation loss: 2.916918976296544

Epoch: 6| Step: 12
Training loss: 2.8892281121196204
Validation loss: 2.925405413257183

Epoch: 6| Step: 13
Training loss: 1.9026020979084666
Validation loss: 2.919479002788252

Epoch: 75| Step: 0
Training loss: 3.773125487512845
Validation loss: 2.924564498868934

Epoch: 6| Step: 1
Training loss: 3.89152105958924
Validation loss: 2.9199401562967244

Epoch: 6| Step: 2
Training loss: 3.7204953753926198
Validation loss: 2.918116744925704

Epoch: 6| Step: 3
Training loss: 2.7188515479755786
Validation loss: 2.9159629576406347

Epoch: 6| Step: 4
Training loss: 3.003316000303775
Validation loss: 2.9143110965017684

Epoch: 6| Step: 5
Training loss: 2.5385315325230393
Validation loss: 2.913990507572954

Epoch: 6| Step: 6
Training loss: 2.7742126241330034
Validation loss: 2.9131744473514396

Epoch: 6| Step: 7
Training loss: 3.168225373246991
Validation loss: 2.916177494731911

Epoch: 6| Step: 8
Training loss: 3.00747052515162
Validation loss: 2.9141169875622785

Epoch: 6| Step: 9
Training loss: 3.538361806325201
Validation loss: 2.9134571740289794

Epoch: 6| Step: 10
Training loss: 3.633197591736594
Validation loss: 2.9179551716646572

Epoch: 6| Step: 11
Training loss: 2.7275549713665117
Validation loss: 2.9150450814719653

Epoch: 6| Step: 12
Training loss: 3.002444225241094
Validation loss: 2.9134582369851643

Epoch: 6| Step: 13
Training loss: 2.9868987432072167
Validation loss: 2.915678078838365

Epoch: 76| Step: 0
Training loss: 3.4854700394895377
Validation loss: 2.9139304204405834

Epoch: 6| Step: 1
Training loss: 2.897701694423234
Validation loss: 2.916812121958457

Epoch: 6| Step: 2
Training loss: 3.2361090245783624
Validation loss: 2.9173796372699523

Epoch: 6| Step: 3
Training loss: 3.2939259143736557
Validation loss: 2.9255568035456507

Epoch: 6| Step: 4
Training loss: 3.3483276406127884
Validation loss: 2.930747498966514

Epoch: 6| Step: 5
Training loss: 2.518329469773337
Validation loss: 2.9264610036804126

Epoch: 6| Step: 6
Training loss: 3.234921026902043
Validation loss: 2.9218868781591882

Epoch: 6| Step: 7
Training loss: 2.597607329632164
Validation loss: 2.9231737080318463

Epoch: 6| Step: 8
Training loss: 3.616375364417691
Validation loss: 2.927022558836791

Epoch: 6| Step: 9
Training loss: 3.123441383775412
Validation loss: 2.9206620996240473

Epoch: 6| Step: 10
Training loss: 3.7450966885439647
Validation loss: 2.9180122002485014

Epoch: 6| Step: 11
Training loss: 2.6887862210425473
Validation loss: 2.916944394461526

Epoch: 6| Step: 12
Training loss: 3.079700512135198
Validation loss: 2.914728635903869

Epoch: 6| Step: 13
Training loss: 4.16172510214282
Validation loss: 2.912347697402703

Epoch: 77| Step: 0
Training loss: 2.963393991519624
Validation loss: 2.91188332094946

Epoch: 6| Step: 1
Training loss: 2.951569000931664
Validation loss: 2.9114604935781223

Epoch: 6| Step: 2
Training loss: 3.106510395518318
Validation loss: 2.908897273039625

Epoch: 6| Step: 3
Training loss: 3.189908482784426
Validation loss: 2.908649917546794

Epoch: 6| Step: 4
Training loss: 3.751868354757163
Validation loss: 2.9115012162405813

Epoch: 6| Step: 5
Training loss: 3.153354638681625
Validation loss: 2.910257429968402

Epoch: 6| Step: 6
Training loss: 2.959154221094878
Validation loss: 2.9097773651406946

Epoch: 6| Step: 7
Training loss: 4.04885309251226
Validation loss: 2.911460895101705

Epoch: 6| Step: 8
Training loss: 3.422553286977029
Validation loss: 2.910106273595567

Epoch: 6| Step: 9
Training loss: 3.7540304776693687
Validation loss: 2.909579660176611

Epoch: 6| Step: 10
Training loss: 2.800788741055184
Validation loss: 2.9099306679695935

Epoch: 6| Step: 11
Training loss: 2.729495070017485
Validation loss: 2.9105101469378827

Epoch: 6| Step: 12
Training loss: 2.988089122704443
Validation loss: 2.9102790303938786

Epoch: 6| Step: 13
Training loss: 2.373173864914923
Validation loss: 2.907854217654814

Epoch: 78| Step: 0
Training loss: 2.7754069468094134
Validation loss: 2.907041921877468

Epoch: 6| Step: 1
Training loss: 2.8558980512080683
Validation loss: 2.909602803147417

Epoch: 6| Step: 2
Training loss: 3.4710537245540056
Validation loss: 2.9081317597518153

Epoch: 6| Step: 3
Training loss: 2.713748145469619
Validation loss: 2.9078244837755847

Epoch: 6| Step: 4
Training loss: 3.1875510118179906
Validation loss: 2.9173011042888133

Epoch: 6| Step: 5
Training loss: 3.4209264546651013
Validation loss: 2.9163186165948805

Epoch: 6| Step: 6
Training loss: 2.554347211006648
Validation loss: 2.922972474728913

Epoch: 6| Step: 7
Training loss: 3.1798199150388435
Validation loss: 2.9240852433773923

Epoch: 6| Step: 8
Training loss: 3.4472916296823692
Validation loss: 2.9326049646642964

Epoch: 6| Step: 9
Training loss: 3.386721284330799
Validation loss: 2.928017056396922

Epoch: 6| Step: 10
Training loss: 3.3540768028842147
Validation loss: 2.925110900167654

Epoch: 6| Step: 11
Training loss: 3.780848836504775
Validation loss: 2.9300626159941108

Epoch: 6| Step: 12
Training loss: 3.1848597343854816
Validation loss: 2.9286016062714886

Epoch: 6| Step: 13
Training loss: 3.4388475031117913
Validation loss: 2.9311726938698257

Epoch: 79| Step: 0
Training loss: 2.4718531167548257
Validation loss: 2.950323775223823

Epoch: 6| Step: 1
Training loss: 3.454462819274652
Validation loss: 2.9613861602093237

Epoch: 6| Step: 2
Training loss: 3.1858354597976803
Validation loss: 2.9493252316724887

Epoch: 6| Step: 3
Training loss: 3.6755517610266137
Validation loss: 2.9560174544564513

Epoch: 6| Step: 4
Training loss: 3.225850541674881
Validation loss: 2.961354016987116

Epoch: 6| Step: 5
Training loss: 2.995178799140105
Validation loss: 2.972834818154746

Epoch: 6| Step: 6
Training loss: 3.3601236618083035
Validation loss: 2.960312417187906

Epoch: 6| Step: 7
Training loss: 3.1974660616006374
Validation loss: 2.9416196461062514

Epoch: 6| Step: 8
Training loss: 3.7683846266533054
Validation loss: 2.924967562587906

Epoch: 6| Step: 9
Training loss: 3.034026142970833
Validation loss: 2.915061243985981

Epoch: 6| Step: 10
Training loss: 2.924583118433459
Validation loss: 2.9093254216512934

Epoch: 6| Step: 11
Training loss: 3.307793350416567
Validation loss: 2.899564537575893

Epoch: 6| Step: 12
Training loss: 2.714718690914545
Validation loss: 2.9057374913170686

Epoch: 6| Step: 13
Training loss: 3.5626869821835343
Validation loss: 2.905401808468091

Epoch: 80| Step: 0
Training loss: 3.249822465008996
Validation loss: 2.903077365243326

Epoch: 6| Step: 1
Training loss: 3.338850906658171
Validation loss: 2.9073852428298603

Epoch: 6| Step: 2
Training loss: 3.8613818429732705
Validation loss: 2.908396897904047

Epoch: 6| Step: 3
Training loss: 3.458916825550898
Validation loss: 2.9074786664617287

Epoch: 6| Step: 4
Training loss: 3.2050999949265275
Validation loss: 2.906406367948383

Epoch: 6| Step: 5
Training loss: 2.4653786926628705
Validation loss: 2.906204181812335

Epoch: 6| Step: 6
Training loss: 2.639543481138047
Validation loss: 2.906676567317986

Epoch: 6| Step: 7
Training loss: 3.1335860745648176
Validation loss: 2.9033949888719497

Epoch: 6| Step: 8
Training loss: 2.7557045983013793
Validation loss: 2.9048789684169702

Epoch: 6| Step: 9
Training loss: 2.962314416408251
Validation loss: 2.904417770562542

Epoch: 6| Step: 10
Training loss: 3.663113924721463
Validation loss: 2.9009630372239417

Epoch: 6| Step: 11
Training loss: 3.480104986119888
Validation loss: 2.9032781788216524

Epoch: 6| Step: 12
Training loss: 3.0534734240159804
Validation loss: 2.9036252133305767

Epoch: 6| Step: 13
Training loss: 3.3623945992552797
Validation loss: 2.907809732216762

Epoch: 81| Step: 0
Training loss: 2.6944937969114418
Validation loss: 2.9075496941708248

Epoch: 6| Step: 1
Training loss: 3.558309131215417
Validation loss: 2.9108260682215876

Epoch: 6| Step: 2
Training loss: 2.746231878721781
Validation loss: 2.916535544780817

Epoch: 6| Step: 3
Training loss: 3.6324435138970617
Validation loss: 2.912253208118277

Epoch: 6| Step: 4
Training loss: 2.7629295187819825
Validation loss: 2.914383627272837

Epoch: 6| Step: 5
Training loss: 3.2141171789641247
Validation loss: 2.9087825629765214

Epoch: 6| Step: 6
Training loss: 3.6189527385626628
Validation loss: 2.9123667727042846

Epoch: 6| Step: 7
Training loss: 3.3614183465884233
Validation loss: 2.90627101802823

Epoch: 6| Step: 8
Training loss: 3.4581422561499013
Validation loss: 2.902287619266639

Epoch: 6| Step: 9
Training loss: 3.633164780466403
Validation loss: 2.9034109513462893

Epoch: 6| Step: 10
Training loss: 3.171782393583471
Validation loss: 2.9003732175205554

Epoch: 6| Step: 11
Training loss: 2.70498734194461
Validation loss: 2.900865618653964

Epoch: 6| Step: 12
Training loss: 2.6174257084633656
Validation loss: 2.8990483780275222

Epoch: 6| Step: 13
Training loss: 3.4205028273603255
Validation loss: 2.8985321345235833

Epoch: 82| Step: 0
Training loss: 3.2424594259554405
Validation loss: 2.8988119337420186

Epoch: 6| Step: 1
Training loss: 3.6195291474284983
Validation loss: 2.8984116533013298

Epoch: 6| Step: 2
Training loss: 3.285611550875214
Validation loss: 2.9009366297664303

Epoch: 6| Step: 3
Training loss: 3.602066898400383
Validation loss: 2.8993436445413523

Epoch: 6| Step: 4
Training loss: 2.15838163854482
Validation loss: 2.900666935078695

Epoch: 6| Step: 5
Training loss: 2.4753693314693375
Validation loss: 2.898414126357961

Epoch: 6| Step: 6
Training loss: 3.2505265322900505
Validation loss: 2.8967405078499815

Epoch: 6| Step: 7
Training loss: 3.679791945090819
Validation loss: 2.898362083814919

Epoch: 6| Step: 8
Training loss: 3.840508683804584
Validation loss: 2.8990175174155484

Epoch: 6| Step: 9
Training loss: 3.131724484978986
Validation loss: 2.898598159721351

Epoch: 6| Step: 10
Training loss: 2.22902738427189
Validation loss: 2.892842949965199

Epoch: 6| Step: 11
Training loss: 2.925080035818231
Validation loss: 2.8981117645061722

Epoch: 6| Step: 12
Training loss: 3.2451452528973714
Validation loss: 2.8939247708816214

Epoch: 6| Step: 13
Training loss: 3.76108235871447
Validation loss: 2.8972363871278133

Epoch: 83| Step: 0
Training loss: 3.593377798957755
Validation loss: 2.8936749908762125

Epoch: 6| Step: 1
Training loss: 2.3150274537932387
Validation loss: 2.8967249307694574

Epoch: 6| Step: 2
Training loss: 2.9478493043641554
Validation loss: 2.894642351638337

Epoch: 6| Step: 3
Training loss: 2.6700154576229167
Validation loss: 2.8967130618292507

Epoch: 6| Step: 4
Training loss: 2.6725350618694206
Validation loss: 2.9017273318369625

Epoch: 6| Step: 5
Training loss: 3.3255922234663386
Validation loss: 2.9014169477470344

Epoch: 6| Step: 6
Training loss: 3.194088727154591
Validation loss: 2.908854074421505

Epoch: 6| Step: 7
Training loss: 3.2013437668348192
Validation loss: 2.9212166105449424

Epoch: 6| Step: 8
Training loss: 3.414666652690863
Validation loss: 2.9166845986185663

Epoch: 6| Step: 9
Training loss: 3.8018341958275186
Validation loss: 2.917131743436601

Epoch: 6| Step: 10
Training loss: 3.5289763836566332
Validation loss: 2.9147380734271935

Epoch: 6| Step: 11
Training loss: 3.694607237923551
Validation loss: 2.909676384341876

Epoch: 6| Step: 12
Training loss: 3.0707299334553584
Validation loss: 2.9001516258677364

Epoch: 6| Step: 13
Training loss: 2.8218082255323678
Validation loss: 2.8936723808772524

Epoch: 84| Step: 0
Training loss: 3.7411052755651406
Validation loss: 2.8934271943769674

Epoch: 6| Step: 1
Training loss: 3.100561792474886
Validation loss: 2.8928324342837057

Epoch: 6| Step: 2
Training loss: 3.2757027374400542
Validation loss: 2.896038147033923

Epoch: 6| Step: 3
Training loss: 2.470720108637279
Validation loss: 2.898180374262275

Epoch: 6| Step: 4
Training loss: 3.605463724349829
Validation loss: 2.8940653868981743

Epoch: 6| Step: 5
Training loss: 2.5482664461341487
Validation loss: 2.8950924908737905

Epoch: 6| Step: 6
Training loss: 2.4031340996975494
Validation loss: 2.8919425571267006

Epoch: 6| Step: 7
Training loss: 3.3686222993500934
Validation loss: 2.894967891268449

Epoch: 6| Step: 8
Training loss: 3.6588671845807488
Validation loss: 2.888901765961367

Epoch: 6| Step: 9
Training loss: 3.82405552890794
Validation loss: 2.891934236641371

Epoch: 6| Step: 10
Training loss: 1.8839244803743875
Validation loss: 2.891041049432887

Epoch: 6| Step: 11
Training loss: 2.494293949011854
Validation loss: 2.8943654557951053

Epoch: 6| Step: 12
Training loss: 3.821826720537121
Validation loss: 2.893536969555144

Epoch: 6| Step: 13
Training loss: 3.977336455986425
Validation loss: 2.8923215987273636

Epoch: 85| Step: 0
Training loss: 3.1581131374393774
Validation loss: 2.895043167406492

Epoch: 6| Step: 1
Training loss: 2.9040729202909468
Validation loss: 2.8986889285359414

Epoch: 6| Step: 2
Training loss: 3.441237342664316
Validation loss: 2.8937426161385584

Epoch: 6| Step: 3
Training loss: 3.795302705214242
Validation loss: 2.8963377982305207

Epoch: 6| Step: 4
Training loss: 2.5838405254803365
Validation loss: 2.8911109256473444

Epoch: 6| Step: 5
Training loss: 2.738665544260173
Validation loss: 2.892364858131582

Epoch: 6| Step: 6
Training loss: 2.9620525102616537
Validation loss: 2.8899860876604144

Epoch: 6| Step: 7
Training loss: 3.18853922339845
Validation loss: 2.888999319082542

Epoch: 6| Step: 8
Training loss: 3.7394118557490432
Validation loss: 2.8892322292345076

Epoch: 6| Step: 9
Training loss: 3.1455199399215146
Validation loss: 2.8907254801067572

Epoch: 6| Step: 10
Training loss: 3.2467642595426383
Validation loss: 2.892931356037151

Epoch: 6| Step: 11
Training loss: 3.245912181857973
Validation loss: 2.88893588312902

Epoch: 6| Step: 12
Training loss: 3.3712377418009494
Validation loss: 2.888938323476973

Epoch: 6| Step: 13
Training loss: 2.658647868603004
Validation loss: 2.8905673663450373

Epoch: 86| Step: 0
Training loss: 2.5956498507277534
Validation loss: 2.88910451963289

Epoch: 6| Step: 1
Training loss: 2.6881179986156116
Validation loss: 2.8880252533885336

Epoch: 6| Step: 2
Training loss: 3.196079749629413
Validation loss: 2.8900086690082403

Epoch: 6| Step: 3
Training loss: 3.1312586862287515
Validation loss: 2.888319333715238

Epoch: 6| Step: 4
Training loss: 3.0741151358412395
Validation loss: 2.8930708612785274

Epoch: 6| Step: 5
Training loss: 3.090858418258389
Validation loss: 2.888706822892414

Epoch: 6| Step: 6
Training loss: 2.226482403301655
Validation loss: 2.8874417706862356

Epoch: 6| Step: 7
Training loss: 3.4903890258476653
Validation loss: 2.8896380450453276

Epoch: 6| Step: 8
Training loss: 4.010167550941119
Validation loss: 2.890397286085986

Epoch: 6| Step: 9
Training loss: 2.4658179919543537
Validation loss: 2.889889072613187

Epoch: 6| Step: 10
Training loss: 3.3279851606478337
Validation loss: 2.886901928696112

Epoch: 6| Step: 11
Training loss: 3.7564451144760906
Validation loss: 2.8889805260847004

Epoch: 6| Step: 12
Training loss: 3.6122646901932036
Validation loss: 2.8881489075940037

Epoch: 6| Step: 13
Training loss: 3.6313515627605213
Validation loss: 2.88972164939437

Epoch: 87| Step: 0
Training loss: 3.0654236209222385
Validation loss: 2.8869986702777606

Epoch: 6| Step: 1
Training loss: 3.2633191596695243
Validation loss: 2.8845677166237786

Epoch: 6| Step: 2
Training loss: 3.2648656226833728
Validation loss: 2.8863917382058553

Epoch: 6| Step: 3
Training loss: 2.9726203184424995
Validation loss: 2.884779739020431

Epoch: 6| Step: 4
Training loss: 2.9238101854200815
Validation loss: 2.885114261614256

Epoch: 6| Step: 5
Training loss: 2.977545628426263
Validation loss: 2.884803919850736

Epoch: 6| Step: 6
Training loss: 2.7021840833843287
Validation loss: 2.8853960709891684

Epoch: 6| Step: 7
Training loss: 3.2208496948721477
Validation loss: 2.882393077556418

Epoch: 6| Step: 8
Training loss: 2.9005839582028967
Validation loss: 2.8837482116449875

Epoch: 6| Step: 9
Training loss: 3.2254794984141415
Validation loss: 2.889878751105575

Epoch: 6| Step: 10
Training loss: 3.377126235893349
Validation loss: 2.88958301338505

Epoch: 6| Step: 11
Training loss: 4.108546880674861
Validation loss: 2.8885368860263316

Epoch: 6| Step: 12
Training loss: 3.427733679442593
Validation loss: 2.886579257492662

Epoch: 6| Step: 13
Training loss: 2.724056546037457
Validation loss: 2.883660957145184

Epoch: 88| Step: 0
Training loss: 3.180582656263659
Validation loss: 2.8843263033622684

Epoch: 6| Step: 1
Training loss: 2.99680794331587
Validation loss: 2.8865788152068212

Epoch: 6| Step: 2
Training loss: 3.1531637985216716
Validation loss: 2.8826933929909684

Epoch: 6| Step: 3
Training loss: 2.901268411994571
Validation loss: 2.8825205508826137

Epoch: 6| Step: 4
Training loss: 3.113207578086526
Validation loss: 2.883503007232403

Epoch: 6| Step: 5
Training loss: 2.997068721488662
Validation loss: 2.8849329723850063

Epoch: 6| Step: 6
Training loss: 2.9760184203777595
Validation loss: 2.8836522233709583

Epoch: 6| Step: 7
Training loss: 3.540802988694589
Validation loss: 2.884961748776505

Epoch: 6| Step: 8
Training loss: 3.158160849284148
Validation loss: 2.884323523138767

Epoch: 6| Step: 9
Training loss: 3.2746882632451517
Validation loss: 2.882624440417967

Epoch: 6| Step: 10
Training loss: 2.5871764381560176
Validation loss: 2.882710776502004

Epoch: 6| Step: 11
Training loss: 3.6257447102601548
Validation loss: 2.8846125489382164

Epoch: 6| Step: 12
Training loss: 3.432196948182502
Validation loss: 2.8830078371848664

Epoch: 6| Step: 13
Training loss: 3.73987432992903
Validation loss: 2.8801825716801437

Epoch: 89| Step: 0
Training loss: 3.6760805111558033
Validation loss: 2.8807028537817505

Epoch: 6| Step: 1
Training loss: 2.9821088085727174
Validation loss: 2.88184185146104

Epoch: 6| Step: 2
Training loss: 2.481199910693649
Validation loss: 2.8825726232965967

Epoch: 6| Step: 3
Training loss: 3.1324072977705146
Validation loss: 2.8819281362668563

Epoch: 6| Step: 4
Training loss: 3.6363951378238135
Validation loss: 2.8797875517760163

Epoch: 6| Step: 5
Training loss: 3.1896631717137183
Validation loss: 2.881304926775014

Epoch: 6| Step: 6
Training loss: 3.603055632056673
Validation loss: 2.8797252473681905

Epoch: 6| Step: 7
Training loss: 2.78288058369545
Validation loss: 2.879516809309001

Epoch: 6| Step: 8
Training loss: 3.6689547999860697
Validation loss: 2.8804656245033176

Epoch: 6| Step: 9
Training loss: 3.0792982315085653
Validation loss: 2.8807304523389723

Epoch: 6| Step: 10
Training loss: 2.87261100693992
Validation loss: 2.8845306566730056

Epoch: 6| Step: 11
Training loss: 3.5906768927878874
Validation loss: 2.882480315293741

Epoch: 6| Step: 12
Training loss: 2.779997640101028
Validation loss: 2.8933232665403095

Epoch: 6| Step: 13
Training loss: 2.13231342890346
Validation loss: 2.897934660641868

Epoch: 90| Step: 0
Training loss: 3.0147289466796585
Validation loss: 2.9134118642810733

Epoch: 6| Step: 1
Training loss: 3.4541570579723406
Validation loss: 2.937513998535426

Epoch: 6| Step: 2
Training loss: 3.071216867444401
Validation loss: 2.8992192612392222

Epoch: 6| Step: 3
Training loss: 3.0173935522031186
Validation loss: 2.881573453224383

Epoch: 6| Step: 4
Training loss: 3.298268968115723
Validation loss: 2.8798184101505564

Epoch: 6| Step: 5
Training loss: 3.0906172795676605
Validation loss: 2.877341857070057

Epoch: 6| Step: 6
Training loss: 3.746675670879943
Validation loss: 2.8774236518984218

Epoch: 6| Step: 7
Training loss: 3.4437279896110646
Validation loss: 2.8820096844024996

Epoch: 6| Step: 8
Training loss: 3.1686983785242955
Validation loss: 2.8831869569642192

Epoch: 6| Step: 9
Training loss: 2.414191381476975
Validation loss: 2.8898025171805037

Epoch: 6| Step: 10
Training loss: 2.541234516447514
Validation loss: 2.8898082622513708

Epoch: 6| Step: 11
Training loss: 3.5772309498144716
Validation loss: 2.8878472149125534

Epoch: 6| Step: 12
Training loss: 3.294051131610743
Validation loss: 2.8813354539307596

Epoch: 6| Step: 13
Training loss: 3.604851865224817
Validation loss: 2.880467565612524

Epoch: 91| Step: 0
Training loss: 2.9932743021093904
Validation loss: 2.8809348560454056

Epoch: 6| Step: 1
Training loss: 2.149110778736691
Validation loss: 2.877707913277438

Epoch: 6| Step: 2
Training loss: 3.244202798687411
Validation loss: 2.8781793411061503

Epoch: 6| Step: 3
Training loss: 2.674551353978525
Validation loss: 2.8794060544546785

Epoch: 6| Step: 4
Training loss: 3.054665802002941
Validation loss: 2.879666794642883

Epoch: 6| Step: 5
Training loss: 3.438310562282744
Validation loss: 2.878714622386436

Epoch: 6| Step: 6
Training loss: 3.5919636142646505
Validation loss: 2.880414355962515

Epoch: 6| Step: 7
Training loss: 3.3848095784797643
Validation loss: 2.878239162758188

Epoch: 6| Step: 8
Training loss: 3.2105120077628966
Validation loss: 2.8771696344017

Epoch: 6| Step: 9
Training loss: 3.797052826661361
Validation loss: 2.878428702304977

Epoch: 6| Step: 10
Training loss: 2.3966043530862438
Validation loss: 2.8789730040072037

Epoch: 6| Step: 11
Training loss: 3.466879950589128
Validation loss: 2.8769706376510147

Epoch: 6| Step: 12
Training loss: 3.6048260712166327
Validation loss: 2.8783833078624697

Epoch: 6| Step: 13
Training loss: 3.014376208807165
Validation loss: 2.8808845142110946

Epoch: 92| Step: 0
Training loss: 3.3819093974388714
Validation loss: 2.8826945642268824

Epoch: 6| Step: 1
Training loss: 3.304597749686253
Validation loss: 2.8838827811641967

Epoch: 6| Step: 2
Training loss: 3.571524049300103
Validation loss: 2.879406261012765

Epoch: 6| Step: 3
Training loss: 2.931940865184439
Validation loss: 2.878349528759808

Epoch: 6| Step: 4
Training loss: 2.748237218276902
Validation loss: 2.8793252071938187

Epoch: 6| Step: 5
Training loss: 2.3160634808446523
Validation loss: 2.8813820474806837

Epoch: 6| Step: 6
Training loss: 3.3952520766238194
Validation loss: 2.877622072988863

Epoch: 6| Step: 7
Training loss: 3.244178840646375
Validation loss: 2.878131612579697

Epoch: 6| Step: 8
Training loss: 3.6428184614077925
Validation loss: 2.8761850868772845

Epoch: 6| Step: 9
Training loss: 3.5799892849468797
Validation loss: 2.8793281409338385

Epoch: 6| Step: 10
Training loss: 2.781284717814606
Validation loss: 2.881608479198924

Epoch: 6| Step: 11
Training loss: 3.485604381503717
Validation loss: 2.880732139640614

Epoch: 6| Step: 12
Training loss: 2.4862288749645063
Validation loss: 2.8845266857135647

Epoch: 6| Step: 13
Training loss: 3.273126919745654
Validation loss: 2.8887498764035433

Epoch: 93| Step: 0
Training loss: 3.8659365085177777
Validation loss: 2.8979056884046233

Epoch: 6| Step: 1
Training loss: 3.4444022500793317
Validation loss: 2.8917024271253506

Epoch: 6| Step: 2
Training loss: 3.6626741751959675
Validation loss: 2.892782840091752

Epoch: 6| Step: 3
Training loss: 3.6630386841710254
Validation loss: 2.8848314773966233

Epoch: 6| Step: 4
Training loss: 2.4667743551958505
Validation loss: 2.878606560965228

Epoch: 6| Step: 5
Training loss: 2.4027965584120814
Validation loss: 2.87524572448559

Epoch: 6| Step: 6
Training loss: 3.231067680365507
Validation loss: 2.8703873277096323

Epoch: 6| Step: 7
Training loss: 3.2025072944313853
Validation loss: 2.8706844812455823

Epoch: 6| Step: 8
Training loss: 2.902659834108852
Validation loss: 2.86817857462802

Epoch: 6| Step: 9
Training loss: 2.508682812987078
Validation loss: 2.871722174127476

Epoch: 6| Step: 10
Training loss: 3.559117635610856
Validation loss: 2.870099255197303

Epoch: 6| Step: 11
Training loss: 2.8123758076692438
Validation loss: 2.8716105812051334

Epoch: 6| Step: 12
Training loss: 3.213946860481217
Validation loss: 2.8707899912775066

Epoch: 6| Step: 13
Training loss: 2.964100941925038
Validation loss: 2.869008621939506

Epoch: 94| Step: 0
Training loss: 2.6549599600321243
Validation loss: 2.871719543283698

Epoch: 6| Step: 1
Training loss: 2.7276500729848574
Validation loss: 2.8690156408701593

Epoch: 6| Step: 2
Training loss: 2.6057457269089865
Validation loss: 2.8691078003833557

Epoch: 6| Step: 3
Training loss: 3.347705676004367
Validation loss: 2.8698993412011053

Epoch: 6| Step: 4
Training loss: 3.591489130457495
Validation loss: 2.871196527952596

Epoch: 6| Step: 5
Training loss: 3.789227731779088
Validation loss: 2.8686600583823

Epoch: 6| Step: 6
Training loss: 3.246949157749134
Validation loss: 2.8695510439701257

Epoch: 6| Step: 7
Training loss: 2.4361644900930903
Validation loss: 2.8686119846916434

Epoch: 6| Step: 8
Training loss: 3.1690474812594025
Validation loss: 2.8686791301690655

Epoch: 6| Step: 9
Training loss: 3.1934674819239146
Validation loss: 2.8699464955901655

Epoch: 6| Step: 10
Training loss: 3.149542148558173
Validation loss: 2.871667391910185

Epoch: 6| Step: 11
Training loss: 3.4798266913568963
Validation loss: 2.8696721856843483

Epoch: 6| Step: 12
Training loss: 3.4995840370409756
Validation loss: 2.8695013877901707

Epoch: 6| Step: 13
Training loss: 3.212753487764745
Validation loss: 2.876232416306231

Epoch: 95| Step: 0
Training loss: 3.387648159038727
Validation loss: 2.8708854166085636

Epoch: 6| Step: 1
Training loss: 2.672511510155124
Validation loss: 2.870424996283813

Epoch: 6| Step: 2
Training loss: 3.6967128173130415
Validation loss: 2.8670844316908672

Epoch: 6| Step: 3
Training loss: 3.3747188309710117
Validation loss: 2.8681945695251505

Epoch: 6| Step: 4
Training loss: 2.414978446153452
Validation loss: 2.8666004072612887

Epoch: 6| Step: 5
Training loss: 3.204170168183145
Validation loss: 2.8680710378009793

Epoch: 6| Step: 6
Training loss: 2.7615179396251586
Validation loss: 2.8661447342020385

Epoch: 6| Step: 7
Training loss: 3.2042000803964164
Validation loss: 2.8664631160557628

Epoch: 6| Step: 8
Training loss: 2.8499006889842238
Validation loss: 2.8659792121104855

Epoch: 6| Step: 9
Training loss: 3.6009285259192936
Validation loss: 2.863886940769336

Epoch: 6| Step: 10
Training loss: 3.647204303011455
Validation loss: 2.8670330079192055

Epoch: 6| Step: 11
Training loss: 2.8204112365853726
Validation loss: 2.8683273867400763

Epoch: 6| Step: 12
Training loss: 3.529742163732592
Validation loss: 2.866236214134025

Epoch: 6| Step: 13
Training loss: 2.6335212817500953
Validation loss: 2.865004483733631

Epoch: 96| Step: 0
Training loss: 3.5908199141198445
Validation loss: 2.867434550212675

Epoch: 6| Step: 1
Training loss: 3.3093319984646468
Validation loss: 2.866318081707375

Epoch: 6| Step: 2
Training loss: 2.79866149789673
Validation loss: 2.86238056826976

Epoch: 6| Step: 3
Training loss: 2.4318069094750725
Validation loss: 2.8627822419432696

Epoch: 6| Step: 4
Training loss: 2.9347469333808465
Validation loss: 2.862026074738216

Epoch: 6| Step: 5
Training loss: 2.782363840012303
Validation loss: 2.86330184925756

Epoch: 6| Step: 6
Training loss: 3.0265334096917664
Validation loss: 2.8642272519085434

Epoch: 6| Step: 7
Training loss: 3.662922175425
Validation loss: 2.8694589996495528

Epoch: 6| Step: 8
Training loss: 3.630176925340877
Validation loss: 2.8632309192133762

Epoch: 6| Step: 9
Training loss: 3.140967355164408
Validation loss: 2.864629344999487

Epoch: 6| Step: 10
Training loss: 3.2294558651948937
Validation loss: 2.8670164968568943

Epoch: 6| Step: 11
Training loss: 3.2005825466148052
Validation loss: 2.8650199514135775

Epoch: 6| Step: 12
Training loss: 2.8844181541115974
Validation loss: 2.866202887569753

Epoch: 6| Step: 13
Training loss: 3.6578503880092703
Validation loss: 2.866726688759203

Epoch: 97| Step: 0
Training loss: 3.1594506078289224
Validation loss: 2.860581791851576

Epoch: 6| Step: 1
Training loss: 2.663021835266279
Validation loss: 2.8620678214452497

Epoch: 6| Step: 2
Training loss: 3.8727879517035095
Validation loss: 2.862213717847586

Epoch: 6| Step: 3
Training loss: 3.347405405339017
Validation loss: 2.862822754379047

Epoch: 6| Step: 4
Training loss: 3.5583040389583056
Validation loss: 2.8635646448878007

Epoch: 6| Step: 5
Training loss: 2.168954765920979
Validation loss: 2.860869508129142

Epoch: 6| Step: 6
Training loss: 3.1566998756001903
Validation loss: 2.861927127433136

Epoch: 6| Step: 7
Training loss: 3.2144816717330515
Validation loss: 2.863925115561898

Epoch: 6| Step: 8
Training loss: 3.0220283161707457
Validation loss: 2.861916382600798

Epoch: 6| Step: 9
Training loss: 3.675835214800466
Validation loss: 2.8633214939367413

Epoch: 6| Step: 10
Training loss: 3.493725192778655
Validation loss: 2.8614853431576703

Epoch: 6| Step: 11
Training loss: 2.823743091589999
Validation loss: 2.861229094422831

Epoch: 6| Step: 12
Training loss: 2.8522423338799174
Validation loss: 2.8622205554953526

Epoch: 6| Step: 13
Training loss: 2.7032609144671533
Validation loss: 2.862412805479039

Epoch: 98| Step: 0
Training loss: 3.1387077286766742
Validation loss: 2.863693836338713

Epoch: 6| Step: 1
Training loss: 3.0423345137440205
Validation loss: 2.862640943620459

Epoch: 6| Step: 2
Training loss: 3.7459147771539323
Validation loss: 2.8641196589184443

Epoch: 6| Step: 3
Training loss: 3.3662090959978284
Validation loss: 2.862052654901002

Epoch: 6| Step: 4
Training loss: 2.730787790675547
Validation loss: 2.8635119492811247

Epoch: 6| Step: 5
Training loss: 3.111264675377044
Validation loss: 2.869963795521931

Epoch: 6| Step: 6
Training loss: 3.3393327288600103
Validation loss: 2.872541245634254

Epoch: 6| Step: 7
Training loss: 2.7516706767092467
Validation loss: 2.8754767824651073

Epoch: 6| Step: 8
Training loss: 3.063447766690054
Validation loss: 2.871359320786345

Epoch: 6| Step: 9
Training loss: 3.001982034160573
Validation loss: 2.867185439921911

Epoch: 6| Step: 10
Training loss: 3.459167441160709
Validation loss: 2.869924887277771

Epoch: 6| Step: 11
Training loss: 3.088166872970912
Validation loss: 2.8607204218762563

Epoch: 6| Step: 12
Training loss: 2.7247077295195736
Validation loss: 2.8622961805457803

Epoch: 6| Step: 13
Training loss: 3.8293989280574463
Validation loss: 2.8586178759024907

Epoch: 99| Step: 0
Training loss: 3.035534848592024
Validation loss: 2.859687770586505

Epoch: 6| Step: 1
Training loss: 2.7169536048991185
Validation loss: 2.862670071264862

Epoch: 6| Step: 2
Training loss: 3.8040415001981107
Validation loss: 2.8632543804018917

Epoch: 6| Step: 3
Training loss: 2.380005029945508
Validation loss: 2.8635015801469548

Epoch: 6| Step: 4
Training loss: 3.75296157874981
Validation loss: 2.864756776512808

Epoch: 6| Step: 5
Training loss: 3.2016032255904743
Validation loss: 2.8657552937595363

Epoch: 6| Step: 6
Training loss: 3.2456471564030474
Validation loss: 2.864215193703554

Epoch: 6| Step: 7
Training loss: 2.940187563979032
Validation loss: 2.865360098463018

Epoch: 6| Step: 8
Training loss: 3.0879780264156635
Validation loss: 2.8639730369801097

Epoch: 6| Step: 9
Training loss: 3.347506400708325
Validation loss: 2.863244139267108

Epoch: 6| Step: 10
Training loss: 3.8275078723709406
Validation loss: 2.8619338842503526

Epoch: 6| Step: 11
Training loss: 2.9724364832323307
Validation loss: 2.862898428891392

Epoch: 6| Step: 12
Training loss: 2.870216038245409
Validation loss: 2.863222825985443

Epoch: 6| Step: 13
Training loss: 2.5593566223155437
Validation loss: 2.863118142913692

Epoch: 100| Step: 0
Training loss: 2.747828753503672
Validation loss: 2.8598103529448053

Epoch: 6| Step: 1
Training loss: 3.1233435245973253
Validation loss: 2.8605902071152918

Epoch: 6| Step: 2
Training loss: 3.1638890348379896
Validation loss: 2.8631262874752816

Epoch: 6| Step: 3
Training loss: 3.210907799056673
Validation loss: 2.861739492407137

Epoch: 6| Step: 4
Training loss: 2.877411535843708
Validation loss: 2.8624407093502673

Epoch: 6| Step: 5
Training loss: 3.6233623357019775
Validation loss: 2.8631342207001143

Epoch: 6| Step: 6
Training loss: 3.660779185500693
Validation loss: 2.859773916122698

Epoch: 6| Step: 7
Training loss: 3.6041999477253746
Validation loss: 2.860856322803796

Epoch: 6| Step: 8
Training loss: 3.8597862858485206
Validation loss: 2.8607584722416943

Epoch: 6| Step: 9
Training loss: 3.4723823018790476
Validation loss: 2.8601681645701746

Epoch: 6| Step: 10
Training loss: 2.66267372245153
Validation loss: 2.8599246553790816

Epoch: 6| Step: 11
Training loss: 2.4877037923326464
Validation loss: 2.8575695086253536

Epoch: 6| Step: 12
Training loss: 2.3443675944110405
Validation loss: 2.858405490556292

Epoch: 6| Step: 13
Training loss: 2.8741234811524903
Validation loss: 2.860241806143947

Epoch: 101| Step: 0
Training loss: 3.0014233391596146
Validation loss: 2.854829512884261

Epoch: 6| Step: 1
Training loss: 3.3186010639802106
Validation loss: 2.8553667383147103

Epoch: 6| Step: 2
Training loss: 3.0267457826779878
Validation loss: 2.8603436923627465

Epoch: 6| Step: 3
Training loss: 3.1225283194022038
Validation loss: 2.8600749170011577

Epoch: 6| Step: 4
Training loss: 4.152275307379255
Validation loss: 2.856877233515445

Epoch: 6| Step: 5
Training loss: 3.15132345825912
Validation loss: 2.858256647107392

Epoch: 6| Step: 6
Training loss: 2.6768186465576704
Validation loss: 2.8567856934925464

Epoch: 6| Step: 7
Training loss: 3.038759348834151
Validation loss: 2.8562270571170334

Epoch: 6| Step: 8
Training loss: 3.3912066123428186
Validation loss: 2.858957222585087

Epoch: 6| Step: 9
Training loss: 3.0760356182620665
Validation loss: 2.854870430918605

Epoch: 6| Step: 10
Training loss: 2.419834483295126
Validation loss: 2.853219000635837

Epoch: 6| Step: 11
Training loss: 2.6579744014956854
Validation loss: 2.8538537377486572

Epoch: 6| Step: 12
Training loss: 3.172498068662376
Validation loss: 2.855845309292898

Epoch: 6| Step: 13
Training loss: 3.906264770479887
Validation loss: 2.8550598301530608

Epoch: 102| Step: 0
Training loss: 3.4627548509585417
Validation loss: 2.8518303552482758

Epoch: 6| Step: 1
Training loss: 3.02398313975806
Validation loss: 2.8540134668758075

Epoch: 6| Step: 2
Training loss: 2.9145939319373353
Validation loss: 2.85119433777536

Epoch: 6| Step: 3
Training loss: 3.265755682707784
Validation loss: 2.8508681502258386

Epoch: 6| Step: 4
Training loss: 3.3324206215289665
Validation loss: 2.8505578078630784

Epoch: 6| Step: 5
Training loss: 2.8677434148465926
Validation loss: 2.8497176147929624

Epoch: 6| Step: 6
Training loss: 3.7090666542348143
Validation loss: 2.8522273290085454

Epoch: 6| Step: 7
Training loss: 3.1839546981924225
Validation loss: 2.851672593105789

Epoch: 6| Step: 8
Training loss: 2.9789329561626614
Validation loss: 2.851080976560174

Epoch: 6| Step: 9
Training loss: 3.318166672183917
Validation loss: 2.8567346066226547

Epoch: 6| Step: 10
Training loss: 3.0797390651401924
Validation loss: 2.852569556885368

Epoch: 6| Step: 11
Training loss: 2.9017379354379114
Validation loss: 2.853999251906411

Epoch: 6| Step: 12
Training loss: 2.9904042002008047
Validation loss: 2.850956099028802

Epoch: 6| Step: 13
Training loss: 2.966908415756265
Validation loss: 2.848811167148886

Epoch: 103| Step: 0
Training loss: 3.0680878711535673
Validation loss: 2.847206938114223

Epoch: 6| Step: 1
Training loss: 2.699458110260334
Validation loss: 2.849653977317026

Epoch: 6| Step: 2
Training loss: 3.1675298083317105
Validation loss: 2.8484626007724656

Epoch: 6| Step: 3
Training loss: 2.7908828735814573
Validation loss: 2.849312879325552

Epoch: 6| Step: 4
Training loss: 3.092261370469964
Validation loss: 2.8524727611836114

Epoch: 6| Step: 5
Training loss: 3.517549657627035
Validation loss: 2.847678623257584

Epoch: 6| Step: 6
Training loss: 3.248675736814733
Validation loss: 2.84727089769675

Epoch: 6| Step: 7
Training loss: 3.7870328205903516
Validation loss: 2.8441071320432676

Epoch: 6| Step: 8
Training loss: 3.237270662292911
Validation loss: 2.844666897654142

Epoch: 6| Step: 9
Training loss: 2.8585787639032225
Validation loss: 2.8424028146477145

Epoch: 6| Step: 10
Training loss: 3.535001129625024
Validation loss: 2.8419005843842964

Epoch: 6| Step: 11
Training loss: 2.664507607782562
Validation loss: 2.8444884940481865

Epoch: 6| Step: 12
Training loss: 3.146609549515874
Validation loss: 2.844944245755422

Epoch: 6| Step: 13
Training loss: 3.03216759076109
Validation loss: 2.8432468463656617

Epoch: 104| Step: 0
Training loss: 2.5269793051629694
Validation loss: 2.8450080904036494

Epoch: 6| Step: 1
Training loss: 3.3120900026338167
Validation loss: 2.842988713867325

Epoch: 6| Step: 2
Training loss: 3.762343120155866
Validation loss: 2.844433931785313

Epoch: 6| Step: 3
Training loss: 3.1085707041194617
Validation loss: 2.843735752658252

Epoch: 6| Step: 4
Training loss: 2.947518653195854
Validation loss: 2.8445598409713684

Epoch: 6| Step: 5
Training loss: 2.598046111486882
Validation loss: 2.8426602004126442

Epoch: 6| Step: 6
Training loss: 3.292114871128745
Validation loss: 2.8468865261139698

Epoch: 6| Step: 7
Training loss: 2.700344000200972
Validation loss: 2.8450598789302677

Epoch: 6| Step: 8
Training loss: 3.0918511622681875
Validation loss: 2.8435095120008156

Epoch: 6| Step: 9
Training loss: 3.114083104273594
Validation loss: 2.8455526900680597

Epoch: 6| Step: 10
Training loss: 3.0035406517705696
Validation loss: 2.847925927330248

Epoch: 6| Step: 11
Training loss: 3.355919626694376
Validation loss: 2.8499915893033356

Epoch: 6| Step: 12
Training loss: 3.818282697839451
Validation loss: 2.851435037153057

Epoch: 6| Step: 13
Training loss: 3.204615994924627
Validation loss: 2.845477638097789

Epoch: 105| Step: 0
Training loss: 3.203533165210029
Validation loss: 2.8442780613932968

Epoch: 6| Step: 1
Training loss: 2.9561630849179057
Validation loss: 2.844366705175149

Epoch: 6| Step: 2
Training loss: 3.4732746479057997
Validation loss: 2.843858450185498

Epoch: 6| Step: 3
Training loss: 3.2877081395390033
Validation loss: 2.8417227703220878

Epoch: 6| Step: 4
Training loss: 2.6856644150414115
Validation loss: 2.8420457128925793

Epoch: 6| Step: 5
Training loss: 3.2094122983850784
Validation loss: 2.841729520148867

Epoch: 6| Step: 6
Training loss: 3.432927923124255
Validation loss: 2.8393130120395265

Epoch: 6| Step: 7
Training loss: 3.5379727266768852
Validation loss: 2.841497577456118

Epoch: 6| Step: 8
Training loss: 3.1313934536964574
Validation loss: 2.841304364334565

Epoch: 6| Step: 9
Training loss: 2.7926631306783487
Validation loss: 2.841014540317765

Epoch: 6| Step: 10
Training loss: 3.5695583623840386
Validation loss: 2.8387224555077557

Epoch: 6| Step: 11
Training loss: 2.4801520197944082
Validation loss: 2.8398567331774505

Epoch: 6| Step: 12
Training loss: 2.862245213526178
Validation loss: 2.840800083563718

Epoch: 6| Step: 13
Training loss: 3.273720667570363
Validation loss: 2.8411137566550466

Epoch: 106| Step: 0
Training loss: 3.352922639313309
Validation loss: 2.8440558471787205

Epoch: 6| Step: 1
Training loss: 3.240686423033188
Validation loss: 2.840327104486371

Epoch: 6| Step: 2
Training loss: 2.8115015588871723
Validation loss: 2.8402452269855147

Epoch: 6| Step: 3
Training loss: 2.931800019609194
Validation loss: 2.842984187121871

Epoch: 6| Step: 4
Training loss: 2.498131435176987
Validation loss: 2.8415890686648195

Epoch: 6| Step: 5
Training loss: 2.9430849267577037
Validation loss: 2.843403698338895

Epoch: 6| Step: 6
Training loss: 2.5975002155909666
Validation loss: 2.8421281753463554

Epoch: 6| Step: 7
Training loss: 3.401760397303017
Validation loss: 2.8454226033230587

Epoch: 6| Step: 8
Training loss: 4.009139586723077
Validation loss: 2.848436379803293

Epoch: 6| Step: 9
Training loss: 3.4590330373570923
Validation loss: 2.8421072701829653

Epoch: 6| Step: 10
Training loss: 3.103474140790239
Validation loss: 2.8474867685750946

Epoch: 6| Step: 11
Training loss: 3.1572055692060323
Validation loss: 2.840475299892774

Epoch: 6| Step: 12
Training loss: 3.1413236381864733
Validation loss: 2.8398116664380564

Epoch: 6| Step: 13
Training loss: 3.0240971439541715
Validation loss: 2.8392830028048706

Epoch: 107| Step: 0
Training loss: 3.0444000364655186
Validation loss: 2.844364325730158

Epoch: 6| Step: 1
Training loss: 3.1502777098293815
Validation loss: 2.8457791385442843

Epoch: 6| Step: 2
Training loss: 3.180390151459869
Validation loss: 2.840147393847523

Epoch: 6| Step: 3
Training loss: 3.7615256888817967
Validation loss: 2.8429706005300326

Epoch: 6| Step: 4
Training loss: 2.2931007984097604
Validation loss: 2.839886223600844

Epoch: 6| Step: 5
Training loss: 3.2518806884762794
Validation loss: 2.8413752904606033

Epoch: 6| Step: 6
Training loss: 2.844432539302363
Validation loss: 2.8384231968648144

Epoch: 6| Step: 7
Training loss: 3.60447035963487
Validation loss: 2.837691583129198

Epoch: 6| Step: 8
Training loss: 3.019007549790719
Validation loss: 2.843546568346282

Epoch: 6| Step: 9
Training loss: 3.2155175134546377
Validation loss: 2.8396337829614673

Epoch: 6| Step: 10
Training loss: 3.3911135273240554
Validation loss: 2.8411010571428017

Epoch: 6| Step: 11
Training loss: 3.205518172773545
Validation loss: 2.8354839876597615

Epoch: 6| Step: 12
Training loss: 2.8786915837538065
Validation loss: 2.8386238952509633

Epoch: 6| Step: 13
Training loss: 2.742367904249815
Validation loss: 2.8419544637061938

Epoch: 108| Step: 0
Training loss: 3.0787146918393655
Validation loss: 2.8388545835951975

Epoch: 6| Step: 1
Training loss: 2.9107524491532195
Validation loss: 2.8406640506941265

Epoch: 6| Step: 2
Training loss: 3.089930633210752
Validation loss: 2.8387797220925646

Epoch: 6| Step: 3
Training loss: 3.3717712216674265
Validation loss: 2.835774490822926

Epoch: 6| Step: 4
Training loss: 3.335317656846243
Validation loss: 2.8358152462557014

Epoch: 6| Step: 5
Training loss: 3.293893632163881
Validation loss: 2.8364752649416176

Epoch: 6| Step: 6
Training loss: 3.298800949969478
Validation loss: 2.836351004326143

Epoch: 6| Step: 7
Training loss: 3.6785969991231724
Validation loss: 2.83662452738851

Epoch: 6| Step: 8
Training loss: 3.5294488685190952
Validation loss: 2.8337660977143804

Epoch: 6| Step: 9
Training loss: 2.3527365760343244
Validation loss: 2.834473730284943

Epoch: 6| Step: 10
Training loss: 2.9094294722197342
Validation loss: 2.8334857201780808

Epoch: 6| Step: 11
Training loss: 3.2079131276456794
Validation loss: 2.8314878822390948

Epoch: 6| Step: 12
Training loss: 2.5802196894121017
Validation loss: 2.835042994741923

Epoch: 6| Step: 13
Training loss: 3.000323754960874
Validation loss: 2.835001219933137

Epoch: 109| Step: 0
Training loss: 2.152323921790757
Validation loss: 2.835150965081199

Epoch: 6| Step: 1
Training loss: 3.687436119431453
Validation loss: 2.834218994880594

Epoch: 6| Step: 2
Training loss: 3.0379625698192134
Validation loss: 2.840617657462008

Epoch: 6| Step: 3
Training loss: 2.759420471853577
Validation loss: 2.834012567825385

Epoch: 6| Step: 4
Training loss: 3.928511396172341
Validation loss: 2.831846717307608

Epoch: 6| Step: 5
Training loss: 3.113953253422722
Validation loss: 2.8327591354643005

Epoch: 6| Step: 6
Training loss: 2.363188232609011
Validation loss: 2.833151911646242

Epoch: 6| Step: 7
Training loss: 2.52031767644191
Validation loss: 2.8356782419606055

Epoch: 6| Step: 8
Training loss: 3.4177165085496046
Validation loss: 2.8374554786226867

Epoch: 6| Step: 9
Training loss: 3.047766452372223
Validation loss: 2.832550234371655

Epoch: 6| Step: 10
Training loss: 3.5830267102254436
Validation loss: 2.833149273942312

Epoch: 6| Step: 11
Training loss: 3.4703153909931395
Validation loss: 2.8330818971931775

Epoch: 6| Step: 12
Training loss: 2.9860406990522557
Validation loss: 2.833634033629708

Epoch: 6| Step: 13
Training loss: 3.4282411206172925
Validation loss: 2.833960902173797

Epoch: 110| Step: 0
Training loss: 3.0286939403401147
Validation loss: 2.834780130634946

Epoch: 6| Step: 1
Training loss: 3.3405077179464304
Validation loss: 2.833390751666464

Epoch: 6| Step: 2
Training loss: 3.819308845347852
Validation loss: 2.8361104538843036

Epoch: 6| Step: 3
Training loss: 3.2834331697366634
Validation loss: 2.8342591693667702

Epoch: 6| Step: 4
Training loss: 3.3579004644531687
Validation loss: 2.8345919304310363

Epoch: 6| Step: 5
Training loss: 2.5171256949889846
Validation loss: 2.8324162526962398

Epoch: 6| Step: 6
Training loss: 2.598139530055913
Validation loss: 2.8342209685678528

Epoch: 6| Step: 7
Training loss: 2.7145064988366787
Validation loss: 2.8333265104217706

Epoch: 6| Step: 8
Training loss: 3.184376251849377
Validation loss: 2.8336865095207924

Epoch: 6| Step: 9
Training loss: 3.566495963197683
Validation loss: 2.8318048899154955

Epoch: 6| Step: 10
Training loss: 3.0203886209004045
Validation loss: 2.8311923103310823

Epoch: 6| Step: 11
Training loss: 2.5011145968106687
Validation loss: 2.831240328513928

Epoch: 6| Step: 12
Training loss: 3.619659436049668
Validation loss: 2.8325481554377565

Epoch: 6| Step: 13
Training loss: 2.8691499319113856
Validation loss: 2.8280973703343135

Epoch: 111| Step: 0
Training loss: 2.853072427722793
Validation loss: 2.828883434073296

Epoch: 6| Step: 1
Training loss: 2.6258443655131147
Validation loss: 2.8273962733282088

Epoch: 6| Step: 2
Training loss: 2.791390694789214
Validation loss: 2.829947283891673

Epoch: 6| Step: 3
Training loss: 3.271138041369297
Validation loss: 2.8279507364136647

Epoch: 6| Step: 4
Training loss: 3.2861402128909987
Validation loss: 2.827197396686173

Epoch: 6| Step: 5
Training loss: 3.1731399494305124
Validation loss: 2.829569775073475

Epoch: 6| Step: 6
Training loss: 3.2088188365511794
Validation loss: 2.8306407400512197

Epoch: 6| Step: 7
Training loss: 3.223257371729974
Validation loss: 2.8286829735493773

Epoch: 6| Step: 8
Training loss: 3.227975900609698
Validation loss: 2.82967117839482

Epoch: 6| Step: 9
Training loss: 3.211900552713683
Validation loss: 2.8284084749308342

Epoch: 6| Step: 10
Training loss: 3.296407368114575
Validation loss: 2.8315363571577326

Epoch: 6| Step: 11
Training loss: 3.1955793124774705
Validation loss: 2.8307626621149757

Epoch: 6| Step: 12
Training loss: 2.916429310177884
Validation loss: 2.829040670995674

Epoch: 6| Step: 13
Training loss: 3.72891998895895
Validation loss: 2.8333971512813867

Epoch: 112| Step: 0
Training loss: 2.859084317800282
Validation loss: 2.8358717868719134

Epoch: 6| Step: 1
Training loss: 2.7514245938299355
Validation loss: 2.836383597030654

Epoch: 6| Step: 2
Training loss: 3.658101452638099
Validation loss: 2.8414269385872224

Epoch: 6| Step: 3
Training loss: 3.51988172744243
Validation loss: 2.8462903777317474

Epoch: 6| Step: 4
Training loss: 2.555979084311383
Validation loss: 2.8374064434544373

Epoch: 6| Step: 5
Training loss: 3.243588946686358
Validation loss: 2.8392643051107593

Epoch: 6| Step: 6
Training loss: 3.4276876332283153
Validation loss: 2.8311011577539906

Epoch: 6| Step: 7
Training loss: 2.820313176289739
Validation loss: 2.831071045174353

Epoch: 6| Step: 8
Training loss: 3.4597520024941395
Validation loss: 2.8272975684999353

Epoch: 6| Step: 9
Training loss: 2.9389252147420626
Validation loss: 2.828620304800576

Epoch: 6| Step: 10
Training loss: 3.4483688534332595
Validation loss: 2.827078160108098

Epoch: 6| Step: 11
Training loss: 2.85959545182029
Validation loss: 2.8273381940538544

Epoch: 6| Step: 12
Training loss: 2.938304060604259
Validation loss: 2.8270211742889084

Epoch: 6| Step: 13
Training loss: 3.19477821117578
Validation loss: 2.828119395224484

Epoch: 113| Step: 0
Training loss: 2.8393843120444924
Validation loss: 2.8271988366494023

Epoch: 6| Step: 1
Training loss: 3.004826477931061
Validation loss: 2.8283020917703174

Epoch: 6| Step: 2
Training loss: 3.5104516515299697
Validation loss: 2.8272798868985114

Epoch: 6| Step: 3
Training loss: 3.3743746142767828
Validation loss: 2.8274085048776714

Epoch: 6| Step: 4
Training loss: 3.674889937848187
Validation loss: 2.8255010522602038

Epoch: 6| Step: 5
Training loss: 3.001569655180013
Validation loss: 2.826366651400405

Epoch: 6| Step: 6
Training loss: 3.168132509639206
Validation loss: 2.8263308591934853

Epoch: 6| Step: 7
Training loss: 3.248942716723441
Validation loss: 2.8277291139973992

Epoch: 6| Step: 8
Training loss: 2.6910986648441155
Validation loss: 2.828804130824922

Epoch: 6| Step: 9
Training loss: 3.4571540077957423
Validation loss: 2.828348190301759

Epoch: 6| Step: 10
Training loss: 3.152624937844377
Validation loss: 2.8257412729155442

Epoch: 6| Step: 11
Training loss: 2.607050974322298
Validation loss: 2.8319601559369905

Epoch: 6| Step: 12
Training loss: 3.074729324461126
Validation loss: 2.8337182507976206

Epoch: 6| Step: 13
Training loss: 2.7027457086904656
Validation loss: 2.837595439045079

Epoch: 114| Step: 0
Training loss: 3.5995532076464345
Validation loss: 2.8327544873920583

Epoch: 6| Step: 1
Training loss: 3.2061720334811055
Validation loss: 2.8304542028871804

Epoch: 6| Step: 2
Training loss: 3.7783930050030987
Validation loss: 2.8312760894427393

Epoch: 6| Step: 3
Training loss: 2.999450792267947
Validation loss: 2.832014229807842

Epoch: 6| Step: 4
Training loss: 2.676236168274644
Validation loss: 2.84442480627785

Epoch: 6| Step: 5
Training loss: 2.7930128827643013
Validation loss: 2.8314632442765144

Epoch: 6| Step: 6
Training loss: 3.0429640489573764
Validation loss: 2.8321761664292353

Epoch: 6| Step: 7
Training loss: 2.5687915510914823
Validation loss: 2.8364859958822555

Epoch: 6| Step: 8
Training loss: 2.9890103915389017
Validation loss: 2.8357429967654664

Epoch: 6| Step: 9
Training loss: 3.336752155541338
Validation loss: 2.842559269470716

Epoch: 6| Step: 10
Training loss: 3.3056189124039945
Validation loss: 2.828109609729365

Epoch: 6| Step: 11
Training loss: 3.2056251259021136
Validation loss: 2.825437383816787

Epoch: 6| Step: 12
Training loss: 2.923553637384904
Validation loss: 2.819618102571429

Epoch: 6| Step: 13
Training loss: 3.2771119682546748
Validation loss: 2.8213828573124857

Epoch: 115| Step: 0
Training loss: 3.7264788156386075
Validation loss: 2.82152463446093

Epoch: 6| Step: 1
Training loss: 3.2712616528663174
Validation loss: 2.8197933488780933

Epoch: 6| Step: 2
Training loss: 2.668581801391704
Validation loss: 2.823140300811601

Epoch: 6| Step: 3
Training loss: 3.4887774243809417
Validation loss: 2.822338390267442

Epoch: 6| Step: 4
Training loss: 2.674594855599921
Validation loss: 2.8213495706562073

Epoch: 6| Step: 5
Training loss: 2.9595551094586585
Validation loss: 2.8181194220640973

Epoch: 6| Step: 6
Training loss: 2.7274532229488417
Validation loss: 2.8215574583965295

Epoch: 6| Step: 7
Training loss: 3.4787782615969323
Validation loss: 2.8225458727509793

Epoch: 6| Step: 8
Training loss: 2.973667609351005
Validation loss: 2.8220274549850366

Epoch: 6| Step: 9
Training loss: 3.2998658124055305
Validation loss: 2.8194261047142906

Epoch: 6| Step: 10
Training loss: 2.9047430910369263
Validation loss: 2.8204543591299416

Epoch: 6| Step: 11
Training loss: 3.168797545668863
Validation loss: 2.8212120619729717

Epoch: 6| Step: 12
Training loss: 3.47535063806447
Validation loss: 2.819812222956755

Epoch: 6| Step: 13
Training loss: 2.456769143878247
Validation loss: 2.820160012521105

Epoch: 116| Step: 0
Training loss: 2.6881026545972593
Validation loss: 2.819012571364945

Epoch: 6| Step: 1
Training loss: 2.5437992925343464
Validation loss: 2.8189245299251544

Epoch: 6| Step: 2
Training loss: 3.116224556094889
Validation loss: 2.817550154029021

Epoch: 6| Step: 3
Training loss: 3.1036966125837537
Validation loss: 2.8162087401430322

Epoch: 6| Step: 4
Training loss: 2.787424755363844
Validation loss: 2.823886318081895

Epoch: 6| Step: 5
Training loss: 3.9656172275091284
Validation loss: 2.82250387301246

Epoch: 6| Step: 6
Training loss: 3.130612635512866
Validation loss: 2.821018838080514

Epoch: 6| Step: 7
Training loss: 3.6315634928650167
Validation loss: 2.8228515180357965

Epoch: 6| Step: 8
Training loss: 3.5341933145547593
Validation loss: 2.8227659313193687

Epoch: 6| Step: 9
Training loss: 2.2482178305707587
Validation loss: 2.8215448889259194

Epoch: 6| Step: 10
Training loss: 2.697139750864489
Validation loss: 2.819338891835434

Epoch: 6| Step: 11
Training loss: 3.149624357077879
Validation loss: 2.817750759683715

Epoch: 6| Step: 12
Training loss: 3.942368540195865
Validation loss: 2.8235866855043943

Epoch: 6| Step: 13
Training loss: 2.1852694446975995
Validation loss: 2.81425695744827

Epoch: 117| Step: 0
Training loss: 2.8734713927319047
Validation loss: 2.823243834699371

Epoch: 6| Step: 1
Training loss: 2.967770706080102
Validation loss: 2.8209352868897297

Epoch: 6| Step: 2
Training loss: 3.043783801006653
Validation loss: 2.817844917005095

Epoch: 6| Step: 3
Training loss: 3.0483368325634856
Validation loss: 2.8276127847866004

Epoch: 6| Step: 4
Training loss: 3.26982088070875
Validation loss: 2.8160476505202636

Epoch: 6| Step: 5
Training loss: 3.4107746555460867
Validation loss: 2.8182179771387066

Epoch: 6| Step: 6
Training loss: 3.3183967359212274
Validation loss: 2.819778691377832

Epoch: 6| Step: 7
Training loss: 2.9476480709865323
Validation loss: 2.817952279005846

Epoch: 6| Step: 8
Training loss: 2.462401714396732
Validation loss: 2.8215430944508837

Epoch: 6| Step: 9
Training loss: 3.1006417625387828
Validation loss: 2.8156227422744813

Epoch: 6| Step: 10
Training loss: 3.6304735098722025
Validation loss: 2.8165187549533837

Epoch: 6| Step: 11
Training loss: 3.1480708133531925
Validation loss: 2.816657051608349

Epoch: 6| Step: 12
Training loss: 2.9445702707848294
Validation loss: 2.8191009301577785

Epoch: 6| Step: 13
Training loss: 3.5664986371778835
Validation loss: 2.8150685730732468

Epoch: 118| Step: 0
Training loss: 1.6368156167729362
Validation loss: 2.8189480224621994

Epoch: 6| Step: 1
Training loss: 3.3217285009110316
Validation loss: 2.8170883770153687

Epoch: 6| Step: 2
Training loss: 3.8504302738079845
Validation loss: 2.8199126289314655

Epoch: 6| Step: 3
Training loss: 2.967553309128092
Validation loss: 2.820271847780502

Epoch: 6| Step: 4
Training loss: 3.359622963913624
Validation loss: 2.8202048642396442

Epoch: 6| Step: 5
Training loss: 3.3626738209094973
Validation loss: 2.82119084007002

Epoch: 6| Step: 6
Training loss: 2.7177899298816874
Validation loss: 2.816693469150176

Epoch: 6| Step: 7
Training loss: 3.1350966044117587
Validation loss: 2.8202626704531504

Epoch: 6| Step: 8
Training loss: 2.9417674132935825
Validation loss: 2.8168948775409923

Epoch: 6| Step: 9
Training loss: 3.692768277577119
Validation loss: 2.8140998902119825

Epoch: 6| Step: 10
Training loss: 2.7737672421717576
Validation loss: 2.816744930924857

Epoch: 6| Step: 11
Training loss: 3.3203479720072115
Validation loss: 2.820320679095398

Epoch: 6| Step: 12
Training loss: 3.13384460038626
Validation loss: 2.815540862035288

Epoch: 6| Step: 13
Training loss: 2.7127922814754655
Validation loss: 2.8161408861714694

Epoch: 119| Step: 0
Training loss: 3.5711747678764314
Validation loss: 2.814075842483173

Epoch: 6| Step: 1
Training loss: 3.0080588499967793
Validation loss: 2.818482658780206

Epoch: 6| Step: 2
Training loss: 2.9575818858092653
Validation loss: 2.819507919404711

Epoch: 6| Step: 3
Training loss: 3.306271869897172
Validation loss: 2.8163245299921806

Epoch: 6| Step: 4
Training loss: 2.602344292371791
Validation loss: 2.811475215695326

Epoch: 6| Step: 5
Training loss: 3.391586237773109
Validation loss: 2.8115372480929266

Epoch: 6| Step: 6
Training loss: 3.2385964970667445
Validation loss: 2.8088696994721927

Epoch: 6| Step: 7
Training loss: 3.3303400110091195
Validation loss: 2.810334983664016

Epoch: 6| Step: 8
Training loss: 2.774300626310877
Validation loss: 2.812954070012846

Epoch: 6| Step: 9
Training loss: 2.62627597859537
Validation loss: 2.810372911644736

Epoch: 6| Step: 10
Training loss: 3.421571064867851
Validation loss: 2.8088345997507878

Epoch: 6| Step: 11
Training loss: 3.3489907808447468
Validation loss: 2.811201169854693

Epoch: 6| Step: 12
Training loss: 3.0225789430719674
Validation loss: 2.8095529436339786

Epoch: 6| Step: 13
Training loss: 2.7932696413807294
Validation loss: 2.8083447496263627

Epoch: 120| Step: 0
Training loss: 3.0124784666692634
Validation loss: 2.8072412474026796

Epoch: 6| Step: 1
Training loss: 2.453138800904153
Validation loss: 2.809778362820619

Epoch: 6| Step: 2
Training loss: 3.1943716142248735
Validation loss: 2.807843675121399

Epoch: 6| Step: 3
Training loss: 3.664949549682941
Validation loss: 2.811604155470512

Epoch: 6| Step: 4
Training loss: 3.2744823600001496
Validation loss: 2.8106773349777976

Epoch: 6| Step: 5
Training loss: 2.8521212931731497
Validation loss: 2.8118194558852276

Epoch: 6| Step: 6
Training loss: 2.698005370421045
Validation loss: 2.810304748918768

Epoch: 6| Step: 7
Training loss: 2.7685645908938836
Validation loss: 2.8160858930139767

Epoch: 6| Step: 8
Training loss: 3.0451927823080265
Validation loss: 2.8167192429321535

Epoch: 6| Step: 9
Training loss: 3.1604196936119906
Validation loss: 2.8145395629313437

Epoch: 6| Step: 10
Training loss: 2.9115057562080513
Validation loss: 2.8162180508424495

Epoch: 6| Step: 11
Training loss: 3.4606728204995676
Validation loss: 2.812690320064395

Epoch: 6| Step: 12
Training loss: 3.639948704326669
Validation loss: 2.810599025786434

Epoch: 6| Step: 13
Training loss: 3.3507093219503656
Validation loss: 2.8191251432683107

Epoch: 121| Step: 0
Training loss: 2.922780268978909
Validation loss: 2.8091443651796606

Epoch: 6| Step: 1
Training loss: 3.1213281039792067
Validation loss: 2.8093565771879585

Epoch: 6| Step: 2
Training loss: 2.9463461926326344
Validation loss: 2.809612915268559

Epoch: 6| Step: 3
Training loss: 3.060086291723318
Validation loss: 2.8116232030563415

Epoch: 6| Step: 4
Training loss: 3.3861490406237853
Validation loss: 2.806051517124079

Epoch: 6| Step: 5
Training loss: 2.7970698624397374
Validation loss: 2.80709773055147

Epoch: 6| Step: 6
Training loss: 3.3453858554143565
Validation loss: 2.8055950616733885

Epoch: 6| Step: 7
Training loss: 3.0054027862489203
Validation loss: 2.8096424074300153

Epoch: 6| Step: 8
Training loss: 2.9125994161902686
Validation loss: 2.8044829730336223

Epoch: 6| Step: 9
Training loss: 3.138705905618252
Validation loss: 2.804041541048959

Epoch: 6| Step: 10
Training loss: 3.0809280877318286
Validation loss: 2.807218904370547

Epoch: 6| Step: 11
Training loss: 3.058736551782924
Validation loss: 2.805192678690469

Epoch: 6| Step: 12
Training loss: 3.7355395939193654
Validation loss: 2.804552708277287

Epoch: 6| Step: 13
Training loss: 2.9132854663166725
Validation loss: 2.80702452454238

Epoch: 122| Step: 0
Training loss: 3.5790845092533705
Validation loss: 2.8087302663721694

Epoch: 6| Step: 1
Training loss: 3.4467652733112244
Validation loss: 2.8066576912804413

Epoch: 6| Step: 2
Training loss: 2.855527864149564
Validation loss: 2.809604515210728

Epoch: 6| Step: 3
Training loss: 3.3239562382577392
Validation loss: 2.8072708174464585

Epoch: 6| Step: 4
Training loss: 2.665395632464996
Validation loss: 2.8042368224411773

Epoch: 6| Step: 5
Training loss: 3.226792740631355
Validation loss: 2.808757909481636

Epoch: 6| Step: 6
Training loss: 3.4346654128769347
Validation loss: 2.8080987471980574

Epoch: 6| Step: 7
Training loss: 3.316968962217385
Validation loss: 2.805941115978759

Epoch: 6| Step: 8
Training loss: 2.801701478335273
Validation loss: 2.804248576319562

Epoch: 6| Step: 9
Training loss: 2.8744212687617763
Validation loss: 2.801841542121776

Epoch: 6| Step: 10
Training loss: 2.910827968827998
Validation loss: 2.8030149575721177

Epoch: 6| Step: 11
Training loss: 2.72458111054448
Validation loss: 2.8053948908286133

Epoch: 6| Step: 12
Training loss: 3.3303826782930686
Validation loss: 2.8043541039562974

Epoch: 6| Step: 13
Training loss: 2.7017150023943306
Validation loss: 2.802813674075341

Epoch: 123| Step: 0
Training loss: 2.7019363171169246
Validation loss: 2.8026892876054297

Epoch: 6| Step: 1
Training loss: 2.942414413672403
Validation loss: 2.8033238763466666

Epoch: 6| Step: 2
Training loss: 3.033065881221762
Validation loss: 2.8066970609777253

Epoch: 6| Step: 3
Training loss: 3.272359374589662
Validation loss: 2.8033379340106324

Epoch: 6| Step: 4
Training loss: 2.961645197778906
Validation loss: 2.8064697555230906

Epoch: 6| Step: 5
Training loss: 3.718171659745285
Validation loss: 2.8092780450175487

Epoch: 6| Step: 6
Training loss: 3.5949202249347647
Validation loss: 2.8054407452901557

Epoch: 6| Step: 7
Training loss: 3.396388767118639
Validation loss: 2.8044209029804286

Epoch: 6| Step: 8
Training loss: 3.076453825124401
Validation loss: 2.8033727523057137

Epoch: 6| Step: 9
Training loss: 2.4949688831904053
Validation loss: 2.805582362207711

Epoch: 6| Step: 10
Training loss: 3.188546700750392
Validation loss: 2.8019288082922156

Epoch: 6| Step: 11
Training loss: 3.2342555811853693
Validation loss: 2.803406754458284

Epoch: 6| Step: 12
Training loss: 2.7311066194867593
Validation loss: 2.8042045737585117

Epoch: 6| Step: 13
Training loss: 2.8887245323019206
Validation loss: 2.810673075431285

Epoch: 124| Step: 0
Training loss: 3.074737388748123
Validation loss: 2.8140968729835016

Epoch: 6| Step: 1
Training loss: 3.5448129180052965
Validation loss: 2.8182729705365697

Epoch: 6| Step: 2
Training loss: 2.4710728787057255
Validation loss: 2.819683314848323

Epoch: 6| Step: 3
Training loss: 2.844516022182273
Validation loss: 2.820786731090424

Epoch: 6| Step: 4
Training loss: 3.1727618401152955
Validation loss: 2.809902662654604

Epoch: 6| Step: 5
Training loss: 2.5686655072426507
Validation loss: 2.81964561029923

Epoch: 6| Step: 6
Training loss: 3.4631063928742787
Validation loss: 2.807656080806755

Epoch: 6| Step: 7
Training loss: 2.9180674504307937
Validation loss: 2.8046666539679155

Epoch: 6| Step: 8
Training loss: 3.3269195522698456
Validation loss: 2.8012525213725827

Epoch: 6| Step: 9
Training loss: 3.8723652403836653
Validation loss: 2.799666844015373

Epoch: 6| Step: 10
Training loss: 2.8991834806426366
Validation loss: 2.7962189243628566

Epoch: 6| Step: 11
Training loss: 2.819188028544621
Validation loss: 2.7990226591268605

Epoch: 6| Step: 12
Training loss: 3.1581321618689513
Validation loss: 2.7991560337918657

Epoch: 6| Step: 13
Training loss: 3.228814103763578
Validation loss: 2.797338634621648

Epoch: 125| Step: 0
Training loss: 2.9335193040445717
Validation loss: 2.7978011817278166

Epoch: 6| Step: 1
Training loss: 3.0611223508701952
Validation loss: 2.7986049319373048

Epoch: 6| Step: 2
Training loss: 2.7995086715681126
Validation loss: 2.79761809881315

Epoch: 6| Step: 3
Training loss: 2.973679154759992
Validation loss: 2.799408201370828

Epoch: 6| Step: 4
Training loss: 2.9230189404547695
Validation loss: 2.79703202170338

Epoch: 6| Step: 5
Training loss: 2.8256886140901702
Validation loss: 2.7976479849970897

Epoch: 6| Step: 6
Training loss: 3.05266002288693
Validation loss: 2.7959802795596804

Epoch: 6| Step: 7
Training loss: 3.7244928718833603
Validation loss: 2.795977754409718

Epoch: 6| Step: 8
Training loss: 3.6915338726285136
Validation loss: 2.7956674681906066

Epoch: 6| Step: 9
Training loss: 2.9485703317612715
Validation loss: 2.797797054684761

Epoch: 6| Step: 10
Training loss: 3.479559748633658
Validation loss: 2.7969051269404575

Epoch: 6| Step: 11
Training loss: 2.9517310349352797
Validation loss: 2.7948149363408334

Epoch: 6| Step: 12
Training loss: 2.807831768294566
Validation loss: 2.7943282965203466

Epoch: 6| Step: 13
Training loss: 3.210503838948389
Validation loss: 2.7934514840226634

Epoch: 126| Step: 0
Training loss: 2.745174509140052
Validation loss: 2.797990065318427

Epoch: 6| Step: 1
Training loss: 3.160956772930771
Validation loss: 2.796114064318322

Epoch: 6| Step: 2
Training loss: 2.9630908232051376
Validation loss: 2.798026437206273

Epoch: 6| Step: 3
Training loss: 2.885723350192325
Validation loss: 2.795266676245579

Epoch: 6| Step: 4
Training loss: 3.4659239107773057
Validation loss: 2.8005752454535053

Epoch: 6| Step: 5
Training loss: 2.828199016803786
Validation loss: 2.8006413135160124

Epoch: 6| Step: 6
Training loss: 3.0061709197304154
Validation loss: 2.795408233571702

Epoch: 6| Step: 7
Training loss: 3.074991402962925
Validation loss: 2.800453529675971

Epoch: 6| Step: 8
Training loss: 3.7063132938429124
Validation loss: 2.8024947802182627

Epoch: 6| Step: 9
Training loss: 3.687928643609972
Validation loss: 2.8001754507639802

Epoch: 6| Step: 10
Training loss: 2.5156206403422043
Validation loss: 2.7957696408382886

Epoch: 6| Step: 11
Training loss: 2.7566714425220504
Validation loss: 2.7952423289212516

Epoch: 6| Step: 12
Training loss: 3.221375810966258
Validation loss: 2.7958997963885945

Epoch: 6| Step: 13
Training loss: 3.335577130116255
Validation loss: 2.792987219739879

Epoch: 127| Step: 0
Training loss: 3.0235046852394722
Validation loss: 2.789387389739073

Epoch: 6| Step: 1
Training loss: 3.230931019487347
Validation loss: 2.79071166212356

Epoch: 6| Step: 2
Training loss: 2.8941803383570655
Validation loss: 2.7920277992057763

Epoch: 6| Step: 3
Training loss: 3.5895463324241446
Validation loss: 2.7934977832331533

Epoch: 6| Step: 4
Training loss: 2.9213777006718784
Validation loss: 2.7930081731364753

Epoch: 6| Step: 5
Training loss: 2.8680912433299466
Validation loss: 2.7942372341001662

Epoch: 6| Step: 6
Training loss: 3.1244930619095475
Validation loss: 2.796919835567042

Epoch: 6| Step: 7
Training loss: 3.4258970547701537
Validation loss: 2.793377833199773

Epoch: 6| Step: 8
Training loss: 3.0915445500717156
Validation loss: 2.7934286250531843

Epoch: 6| Step: 9
Training loss: 2.2480016947431047
Validation loss: 2.7920743359614386

Epoch: 6| Step: 10
Training loss: 3.205524717991014
Validation loss: 2.797639512359597

Epoch: 6| Step: 11
Training loss: 3.2792278053048514
Validation loss: 2.79424744465214

Epoch: 6| Step: 12
Training loss: 2.9663572607247417
Validation loss: 2.795951608795933

Epoch: 6| Step: 13
Training loss: 3.614360322403002
Validation loss: 2.793760249001232

Epoch: 128| Step: 0
Training loss: 2.901136925238858
Validation loss: 2.795893661212243

Epoch: 6| Step: 1
Training loss: 2.9381132094538804
Validation loss: 2.791926362862846

Epoch: 6| Step: 2
Training loss: 2.6309133862542264
Validation loss: 2.7915621098012062

Epoch: 6| Step: 3
Training loss: 3.2597694282669543
Validation loss: 2.7946409073618397

Epoch: 6| Step: 4
Training loss: 3.512859833772329
Validation loss: 2.793036815371257

Epoch: 6| Step: 5
Training loss: 2.630650116231176
Validation loss: 2.790403880951986

Epoch: 6| Step: 6
Training loss: 3.154192263164662
Validation loss: 2.7932721497052415

Epoch: 6| Step: 7
Training loss: 2.733806878062038
Validation loss: 2.807213252375314

Epoch: 6| Step: 8
Training loss: 3.1917710953669167
Validation loss: 2.7961126826123888

Epoch: 6| Step: 9
Training loss: 2.881770082482045
Validation loss: 2.7929801198915944

Epoch: 6| Step: 10
Training loss: 3.4523646005077255
Validation loss: 2.789495902154192

Epoch: 6| Step: 11
Training loss: 3.146584696860487
Validation loss: 2.787130652209051

Epoch: 6| Step: 12
Training loss: 3.5160553393299936
Validation loss: 2.7920627989437015

Epoch: 6| Step: 13
Training loss: 3.452345954391905
Validation loss: 2.7901017864953532

Epoch: 129| Step: 0
Training loss: 3.046225767168374
Validation loss: 2.7931038547673026

Epoch: 6| Step: 1
Training loss: 3.2257404157585894
Validation loss: 2.791461284712518

Epoch: 6| Step: 2
Training loss: 3.263853331748685
Validation loss: 2.791887724243215

Epoch: 6| Step: 3
Training loss: 3.2638333164831876
Validation loss: 2.791908024759107

Epoch: 6| Step: 4
Training loss: 2.9893666010504756
Validation loss: 2.793728513475128

Epoch: 6| Step: 5
Training loss: 2.5373555710754028
Validation loss: 2.793342996781701

Epoch: 6| Step: 6
Training loss: 3.4728602895449514
Validation loss: 2.792449783172005

Epoch: 6| Step: 7
Training loss: 2.934089791409379
Validation loss: 2.793764679319538

Epoch: 6| Step: 8
Training loss: 2.2015502929349076
Validation loss: 2.790175766360137

Epoch: 6| Step: 9
Training loss: 3.3765676177982096
Validation loss: 2.7937330447841404

Epoch: 6| Step: 10
Training loss: 3.5559323991973093
Validation loss: 2.7888827529250544

Epoch: 6| Step: 11
Training loss: 3.0389360337801166
Validation loss: 2.789242568211931

Epoch: 6| Step: 12
Training loss: 3.1433536954714443
Validation loss: 2.7972944628773364

Epoch: 6| Step: 13
Training loss: 3.2465943318898614
Validation loss: 2.7971457091833725

Epoch: 130| Step: 0
Training loss: 3.2908404476281747
Validation loss: 2.797659689583769

Epoch: 6| Step: 1
Training loss: 2.9246881171991217
Validation loss: 2.7977748927992585

Epoch: 6| Step: 2
Training loss: 2.836569975636873
Validation loss: 2.794178900480164

Epoch: 6| Step: 3
Training loss: 3.646894565716112
Validation loss: 2.795262979266566

Epoch: 6| Step: 4
Training loss: 3.8124114479662325
Validation loss: 2.7898398623814997

Epoch: 6| Step: 5
Training loss: 3.0365599696498315
Validation loss: 2.78825042723847

Epoch: 6| Step: 6
Training loss: 3.1678356890597814
Validation loss: 2.7915227286916897

Epoch: 6| Step: 7
Training loss: 2.552358609878163
Validation loss: 2.7867764407632976

Epoch: 6| Step: 8
Training loss: 2.573544959654444
Validation loss: 2.787469489097401

Epoch: 6| Step: 9
Training loss: 2.6680979662499884
Validation loss: 2.7907092635710087

Epoch: 6| Step: 10
Training loss: 3.195970537472397
Validation loss: 2.7871315343101393

Epoch: 6| Step: 11
Training loss: 3.0378515974090736
Validation loss: 2.785044125823223

Epoch: 6| Step: 12
Training loss: 3.214240609715389
Validation loss: 2.788070799756292

Epoch: 6| Step: 13
Training loss: 3.300091372294216
Validation loss: 2.790348773786888

Epoch: 131| Step: 0
Training loss: 3.3363735798386855
Validation loss: 2.7876062895400824

Epoch: 6| Step: 1
Training loss: 2.691316334588613
Validation loss: 2.7881900871416248

Epoch: 6| Step: 2
Training loss: 2.258339473908394
Validation loss: 2.7886094856895345

Epoch: 6| Step: 3
Training loss: 3.0128687779274843
Validation loss: 2.7884147601712277

Epoch: 6| Step: 4
Training loss: 2.791386338768022
Validation loss: 2.7962212750986195

Epoch: 6| Step: 5
Training loss: 3.7475188630324703
Validation loss: 2.819582876158561

Epoch: 6| Step: 6
Training loss: 3.1929200409752707
Validation loss: 2.816792186062321

Epoch: 6| Step: 7
Training loss: 3.1460894213055335
Validation loss: 2.8206044811965776

Epoch: 6| Step: 8
Training loss: 2.510229069413091
Validation loss: 2.8041262968237453

Epoch: 6| Step: 9
Training loss: 2.93405907568456
Validation loss: 2.79347705559823

Epoch: 6| Step: 10
Training loss: 3.112497420099254
Validation loss: 2.784857680965728

Epoch: 6| Step: 11
Training loss: 3.287345818794949
Validation loss: 2.7828269194459887

Epoch: 6| Step: 12
Training loss: 3.789019334684863
Validation loss: 2.7827011061506255

Epoch: 6| Step: 13
Training loss: 3.4006322328995027
Validation loss: 2.7821973436461085

Epoch: 132| Step: 0
Training loss: 3.235956809567871
Validation loss: 2.7829143783851054

Epoch: 6| Step: 1
Training loss: 2.78766902872974
Validation loss: 2.7824337873331286

Epoch: 6| Step: 2
Training loss: 3.0622539810701657
Validation loss: 2.7816252465087272

Epoch: 6| Step: 3
Training loss: 3.2578643136055034
Validation loss: 2.7833330926519855

Epoch: 6| Step: 4
Training loss: 3.0584983372330647
Validation loss: 2.7823158997071986

Epoch: 6| Step: 5
Training loss: 2.958114365188435
Validation loss: 2.784018161779151

Epoch: 6| Step: 6
Training loss: 2.431708669667932
Validation loss: 2.7829750355303458

Epoch: 6| Step: 7
Training loss: 3.086993613782381
Validation loss: 2.780243477965966

Epoch: 6| Step: 8
Training loss: 3.3523409279584953
Validation loss: 2.7803603405446022

Epoch: 6| Step: 9
Training loss: 2.9849955128391605
Validation loss: 2.780387763198791

Epoch: 6| Step: 10
Training loss: 3.8355538667793234
Validation loss: 2.782156081052274

Epoch: 6| Step: 11
Training loss: 2.181187158242274
Validation loss: 2.7814278605067537

Epoch: 6| Step: 12
Training loss: 3.6726424044323944
Validation loss: 2.7804634002284727

Epoch: 6| Step: 13
Training loss: 3.1243808896001046
Validation loss: 2.7850948192865173

Epoch: 133| Step: 0
Training loss: 3.583128516679386
Validation loss: 2.7843362558156444

Epoch: 6| Step: 1
Training loss: 3.884757278302999
Validation loss: 2.780140417506597

Epoch: 6| Step: 2
Training loss: 3.0817580108006193
Validation loss: 2.78249172224093

Epoch: 6| Step: 3
Training loss: 3.2746457439752406
Validation loss: 2.785832233411867

Epoch: 6| Step: 4
Training loss: 3.0079034964928426
Validation loss: 2.787342147959821

Epoch: 6| Step: 5
Training loss: 2.9459543515337776
Validation loss: 2.794018502436694

Epoch: 6| Step: 6
Training loss: 3.448401210578411
Validation loss: 2.7933900861397984

Epoch: 6| Step: 7
Training loss: 2.271382769922322
Validation loss: 2.7857303257571724

Epoch: 6| Step: 8
Training loss: 2.7809329763029105
Validation loss: 2.7911312062375133

Epoch: 6| Step: 9
Training loss: 2.848863468764284
Validation loss: 2.7841821855980773

Epoch: 6| Step: 10
Training loss: 2.5195762925964096
Validation loss: 2.7884609223608248

Epoch: 6| Step: 11
Training loss: 3.045028518267602
Validation loss: 2.7847435396968936

Epoch: 6| Step: 12
Training loss: 3.290394855214592
Validation loss: 2.7777564476247028

Epoch: 6| Step: 13
Training loss: 2.816005895256244
Validation loss: 2.778141625546771

Epoch: 134| Step: 0
Training loss: 3.1527418525729067
Validation loss: 2.7809296870919606

Epoch: 6| Step: 1
Training loss: 2.8842103458577415
Validation loss: 2.778644041907772

Epoch: 6| Step: 2
Training loss: 3.319546384500831
Validation loss: 2.7778434118768276

Epoch: 6| Step: 3
Training loss: 2.8877214024861306
Validation loss: 2.77978221382844

Epoch: 6| Step: 4
Training loss: 3.45077476094944
Validation loss: 2.778598035858419

Epoch: 6| Step: 5
Training loss: 3.0097840028235154
Validation loss: 2.779795426803151

Epoch: 6| Step: 6
Training loss: 3.1919999615088437
Validation loss: 2.775839718702873

Epoch: 6| Step: 7
Training loss: 2.899079860854443
Validation loss: 2.776801896249142

Epoch: 6| Step: 8
Training loss: 2.354027049107743
Validation loss: 2.7783681362827157

Epoch: 6| Step: 9
Training loss: 3.5822854986615598
Validation loss: 2.776253232740048

Epoch: 6| Step: 10
Training loss: 3.042680092514779
Validation loss: 2.7816882754279963

Epoch: 6| Step: 11
Training loss: 2.9613146378180204
Validation loss: 2.7840251251770582

Epoch: 6| Step: 12
Training loss: 3.3457635538909383
Validation loss: 2.7805300853893464

Epoch: 6| Step: 13
Training loss: 2.989293225043426
Validation loss: 2.780256886075323

Epoch: 135| Step: 0
Training loss: 3.4468069144170865
Validation loss: 2.777288006157825

Epoch: 6| Step: 1
Training loss: 3.2703265791734384
Validation loss: 2.7813643159747685

Epoch: 6| Step: 2
Training loss: 2.631947723449257
Validation loss: 2.783951910097917

Epoch: 6| Step: 3
Training loss: 3.1643146178971517
Validation loss: 2.7843234464969115

Epoch: 6| Step: 4
Training loss: 2.7253160660856746
Validation loss: 2.782988930681511

Epoch: 6| Step: 5
Training loss: 2.69411621082688
Validation loss: 2.7817773903106198

Epoch: 6| Step: 6
Training loss: 3.2583562090786975
Validation loss: 2.7856824360253953

Epoch: 6| Step: 7
Training loss: 2.2709202414397907
Validation loss: 2.7794493196570915

Epoch: 6| Step: 8
Training loss: 2.9872287068426586
Validation loss: 2.7895775221777344

Epoch: 6| Step: 9
Training loss: 3.254274491702596
Validation loss: 2.7818221798383185

Epoch: 6| Step: 10
Training loss: 3.2562591728330195
Validation loss: 2.782352291293207

Epoch: 6| Step: 11
Training loss: 3.014599877878664
Validation loss: 2.784407503353055

Epoch: 6| Step: 12
Training loss: 3.836873051129766
Validation loss: 2.777532956877862

Epoch: 6| Step: 13
Training loss: 3.1597761342872115
Validation loss: 2.7755339460510555

Epoch: 136| Step: 0
Training loss: 3.3534587484256577
Validation loss: 2.775001352345511

Epoch: 6| Step: 1
Training loss: 3.49019940000663
Validation loss: 2.7760941815355067

Epoch: 6| Step: 2
Training loss: 2.9969299820519293
Validation loss: 2.776836617976317

Epoch: 6| Step: 3
Training loss: 2.9889370067871943
Validation loss: 2.7808805457433725

Epoch: 6| Step: 4
Training loss: 3.828221160303734
Validation loss: 2.78084506416528

Epoch: 6| Step: 5
Training loss: 3.3890337748033454
Validation loss: 2.7801593035114855

Epoch: 6| Step: 6
Training loss: 3.0047776008859843
Validation loss: 2.7780253036171003

Epoch: 6| Step: 7
Training loss: 3.1091173534901246
Validation loss: 2.77373939730146

Epoch: 6| Step: 8
Training loss: 2.8905197536794542
Validation loss: 2.776841642153695

Epoch: 6| Step: 9
Training loss: 2.1542789461940943
Validation loss: 2.781643900320036

Epoch: 6| Step: 10
Training loss: 2.93541399971647
Validation loss: 2.7788797159341456

Epoch: 6| Step: 11
Training loss: 2.6748349932109385
Validation loss: 2.7815996811833945

Epoch: 6| Step: 12
Training loss: 2.7561521205693182
Validation loss: 2.789301389250052

Epoch: 6| Step: 13
Training loss: 3.5147402858153542
Validation loss: 2.7936598069916503

Epoch: 137| Step: 0
Training loss: 2.579922136418165
Validation loss: 2.792718048053715

Epoch: 6| Step: 1
Training loss: 3.3848092967285064
Validation loss: 2.796603284662193

Epoch: 6| Step: 2
Training loss: 2.7747702391763007
Validation loss: 2.7875465461651934

Epoch: 6| Step: 3
Training loss: 3.09780125320688
Validation loss: 2.7949401355429884

Epoch: 6| Step: 4
Training loss: 2.986759052408814
Validation loss: 2.7892684485921246

Epoch: 6| Step: 5
Training loss: 2.640493716977371
Validation loss: 2.7879706318518553

Epoch: 6| Step: 6
Training loss: 3.165641334243011
Validation loss: 2.7808529998059193

Epoch: 6| Step: 7
Training loss: 3.2114839483314603
Validation loss: 2.778218275097756

Epoch: 6| Step: 8
Training loss: 2.939738942188196
Validation loss: 2.7724422237523756

Epoch: 6| Step: 9
Training loss: 3.6590312584571083
Validation loss: 2.7719491803879697

Epoch: 6| Step: 10
Training loss: 3.4207488693484116
Validation loss: 2.768151626810595

Epoch: 6| Step: 11
Training loss: 3.2898258582874025
Validation loss: 2.7688646548018676

Epoch: 6| Step: 12
Training loss: 2.6414119292781764
Validation loss: 2.7691782895909234

Epoch: 6| Step: 13
Training loss: 3.3110964698666923
Validation loss: 2.7676178838750896

Epoch: 138| Step: 0
Training loss: 2.8279388535079195
Validation loss: 2.7695776713936557

Epoch: 6| Step: 1
Training loss: 3.4056773973096597
Validation loss: 2.7706927395597716

Epoch: 6| Step: 2
Training loss: 3.7095307263640325
Validation loss: 2.7713887202930354

Epoch: 6| Step: 3
Training loss: 3.053759031340977
Validation loss: 2.7729314046234657

Epoch: 6| Step: 4
Training loss: 3.2757273383222447
Validation loss: 2.772806304507815

Epoch: 6| Step: 5
Training loss: 3.360753260146591
Validation loss: 2.7692765118271025

Epoch: 6| Step: 6
Training loss: 3.3260408421599124
Validation loss: 2.7716658571532524

Epoch: 6| Step: 7
Training loss: 2.7803931470101344
Validation loss: 2.768866323239877

Epoch: 6| Step: 8
Training loss: 3.0949892586812866
Validation loss: 2.7687674059054888

Epoch: 6| Step: 9
Training loss: 3.583161919212476
Validation loss: 2.769661003942643

Epoch: 6| Step: 10
Training loss: 2.3160176715143703
Validation loss: 2.7688690045898663

Epoch: 6| Step: 11
Training loss: 3.0476093678803218
Validation loss: 2.768408890996998

Epoch: 6| Step: 12
Training loss: 2.409023123649568
Validation loss: 2.768139201956544

Epoch: 6| Step: 13
Training loss: 2.2497182245775442
Validation loss: 2.773441593964978

Epoch: 139| Step: 0
Training loss: 2.988551866831524
Validation loss: 2.773701985082568

Epoch: 6| Step: 1
Training loss: 3.4967275034433842
Validation loss: 2.7802998494969553

Epoch: 6| Step: 2
Training loss: 2.6617701895815076
Validation loss: 2.779457303555669

Epoch: 6| Step: 3
Training loss: 2.5501758739183145
Validation loss: 2.7841475057559677

Epoch: 6| Step: 4
Training loss: 2.9478593333210203
Validation loss: 2.8000162532147157

Epoch: 6| Step: 5
Training loss: 2.891189107752571
Validation loss: 2.8200256949017546

Epoch: 6| Step: 6
Training loss: 3.7762817025897912
Validation loss: 2.838691542342365

Epoch: 6| Step: 7
Training loss: 2.7716332812964253
Validation loss: 2.8453906083441196

Epoch: 6| Step: 8
Training loss: 3.3772544395467863
Validation loss: 2.850223914724966

Epoch: 6| Step: 9
Training loss: 3.4686372755825228
Validation loss: 2.843939119397221

Epoch: 6| Step: 10
Training loss: 2.743455121089887
Validation loss: 2.8325392522978343

Epoch: 6| Step: 11
Training loss: 2.7676603941713296
Validation loss: 2.8014485325207317

Epoch: 6| Step: 12
Training loss: 3.612158424569982
Validation loss: 2.7864491673110723

Epoch: 6| Step: 13
Training loss: 2.7733988154762486
Validation loss: 2.7726455734085693

Epoch: 140| Step: 0
Training loss: 2.9799885894249707
Validation loss: 2.7688799568035867

Epoch: 6| Step: 1
Training loss: 3.094006152096965
Validation loss: 2.7629499847445356

Epoch: 6| Step: 2
Training loss: 3.8826158807659152
Validation loss: 2.7673575706042586

Epoch: 6| Step: 3
Training loss: 2.934125544758156
Validation loss: 2.7684352652444497

Epoch: 6| Step: 4
Training loss: 3.0279086859476148
Validation loss: 2.774034134664734

Epoch: 6| Step: 5
Training loss: 2.2624618021232745
Validation loss: 2.7768035820756984

Epoch: 6| Step: 6
Training loss: 2.841592158648695
Validation loss: 2.7799815453573182

Epoch: 6| Step: 7
Training loss: 2.6712154890659567
Validation loss: 2.777769649931252

Epoch: 6| Step: 8
Training loss: 3.3192122487711715
Validation loss: 2.775966794190718

Epoch: 6| Step: 9
Training loss: 3.4275507429444403
Validation loss: 2.772133487864182

Epoch: 6| Step: 10
Training loss: 3.2940202982125992
Validation loss: 2.7707661014467906

Epoch: 6| Step: 11
Training loss: 3.6768448331750543
Validation loss: 2.766082914863623

Epoch: 6| Step: 12
Training loss: 3.2938742337331837
Validation loss: 2.765685718394282

Epoch: 6| Step: 13
Training loss: 0.8736251179155649
Validation loss: 2.7650432814942816

Epoch: 141| Step: 0
Training loss: 3.3969432834475572
Validation loss: 2.7629941729658207

Epoch: 6| Step: 1
Training loss: 3.0473353893957698
Validation loss: 2.7682559726386415

Epoch: 6| Step: 2
Training loss: 3.0249420286566484
Validation loss: 2.767010810101619

Epoch: 6| Step: 3
Training loss: 2.2723776322961298
Validation loss: 2.774915292177384

Epoch: 6| Step: 4
Training loss: 3.175629296603015
Validation loss: 2.7889942043517792

Epoch: 6| Step: 5
Training loss: 2.9411476700438546
Validation loss: 2.8164519297375494

Epoch: 6| Step: 6
Training loss: 3.4184819648181004
Validation loss: 2.839791711976862

Epoch: 6| Step: 7
Training loss: 3.118881797681296
Validation loss: 2.8309176973225787

Epoch: 6| Step: 8
Training loss: 3.382491098689669
Validation loss: 2.8180113359149623

Epoch: 6| Step: 9
Training loss: 3.3851299144883447
Validation loss: 2.8096799724878028

Epoch: 6| Step: 10
Training loss: 3.028427855283695
Validation loss: 2.8129048401340246

Epoch: 6| Step: 11
Training loss: 2.8390010543665416
Validation loss: 2.794191843529257

Epoch: 6| Step: 12
Training loss: 3.3290068841498055
Validation loss: 2.7888471010591482

Epoch: 6| Step: 13
Training loss: 2.173933412207672
Validation loss: 2.7750175600421043

Epoch: 142| Step: 0
Training loss: 2.502345510738824
Validation loss: 2.7700276640298447

Epoch: 6| Step: 1
Training loss: 3.2869496570210086
Validation loss: 2.780232528100338

Epoch: 6| Step: 2
Training loss: 2.92285743557295
Validation loss: 2.7801919546685965

Epoch: 6| Step: 3
Training loss: 3.4180731010856444
Validation loss: 2.782215964135672

Epoch: 6| Step: 4
Training loss: 2.7424057224311906
Validation loss: 2.7758460284234228

Epoch: 6| Step: 5
Training loss: 3.1036237886280436
Validation loss: 2.7723987270703523

Epoch: 6| Step: 6
Training loss: 2.6767772296700882
Validation loss: 2.7694776473642104

Epoch: 6| Step: 7
Training loss: 3.7143328422658577
Validation loss: 2.7748396046202473

Epoch: 6| Step: 8
Training loss: 3.5264162722023498
Validation loss: 2.7625061788635095

Epoch: 6| Step: 9
Training loss: 3.2691374510828184
Validation loss: 2.762753428413074

Epoch: 6| Step: 10
Training loss: 3.1488804659405125
Validation loss: 2.7588505697331556

Epoch: 6| Step: 11
Training loss: 3.0533825362570814
Validation loss: 2.7563475609161734

Epoch: 6| Step: 12
Training loss: 2.4079779823665355
Validation loss: 2.756481549587728

Epoch: 6| Step: 13
Training loss: 3.0457249745212325
Validation loss: 2.7605526414483568

Epoch: 143| Step: 0
Training loss: 3.197438919879832
Validation loss: 2.756939320499109

Epoch: 6| Step: 1
Training loss: 2.4049882429315357
Validation loss: 2.7676462451410195

Epoch: 6| Step: 2
Training loss: 3.2703162268459267
Validation loss: 2.7649396016121397

Epoch: 6| Step: 3
Training loss: 2.3021942618270623
Validation loss: 2.7629216745541254

Epoch: 6| Step: 4
Training loss: 3.1002566569739556
Validation loss: 2.7637652041764573

Epoch: 6| Step: 5
Training loss: 3.281655422777165
Validation loss: 2.763792242361626

Epoch: 6| Step: 6
Training loss: 3.2735103335050666
Validation loss: 2.778618658590493

Epoch: 6| Step: 7
Training loss: 3.612828307759401
Validation loss: 2.7792236930967915

Epoch: 6| Step: 8
Training loss: 2.676997934208822
Validation loss: 2.7812079748721223

Epoch: 6| Step: 9
Training loss: 2.7030400610130902
Validation loss: 2.789351422644716

Epoch: 6| Step: 10
Training loss: 3.2255736676178226
Validation loss: 2.79287244506085

Epoch: 6| Step: 11
Training loss: 3.3771818667107407
Validation loss: 2.783490844201101

Epoch: 6| Step: 12
Training loss: 3.2319609990552274
Validation loss: 2.7727773488189493

Epoch: 6| Step: 13
Training loss: 3.207307643340558
Validation loss: 2.7653280082144116

Epoch: 144| Step: 0
Training loss: 3.1555313954152275
Validation loss: 2.755777513566381

Epoch: 6| Step: 1
Training loss: 3.7030832795315964
Validation loss: 2.755612233466991

Epoch: 6| Step: 2
Training loss: 2.9387103894483646
Validation loss: 2.760970433033976

Epoch: 6| Step: 3
Training loss: 3.1822683746600973
Validation loss: 2.757045288327294

Epoch: 6| Step: 4
Training loss: 2.8327524674330524
Validation loss: 2.756787665789298

Epoch: 6| Step: 5
Training loss: 2.8856111499965436
Validation loss: 2.7594866380283016

Epoch: 6| Step: 6
Training loss: 3.2941376951953947
Validation loss: 2.7587273847658653

Epoch: 6| Step: 7
Training loss: 2.796710814020338
Validation loss: 2.758016009942559

Epoch: 6| Step: 8
Training loss: 3.358826490467527
Validation loss: 2.7665324955339288

Epoch: 6| Step: 9
Training loss: 3.0073791984466327
Validation loss: 2.768374531219891

Epoch: 6| Step: 10
Training loss: 2.563511532499571
Validation loss: 2.7722251135936067

Epoch: 6| Step: 11
Training loss: 3.3355373884120425
Validation loss: 2.7728334043104033

Epoch: 6| Step: 12
Training loss: 3.088511955199803
Validation loss: 2.7758822637847516

Epoch: 6| Step: 13
Training loss: 2.5030398007869814
Validation loss: 2.781147017398009

Epoch: 145| Step: 0
Training loss: 2.856692196862866
Validation loss: 2.7760513681969736

Epoch: 6| Step: 1
Training loss: 2.4688174081605196
Validation loss: 2.78697840234578

Epoch: 6| Step: 2
Training loss: 3.229193476083687
Validation loss: 2.7866477763138255

Epoch: 6| Step: 3
Training loss: 3.010553235890841
Validation loss: 2.7869521171128

Epoch: 6| Step: 4
Training loss: 3.7880218649920967
Validation loss: 2.7824932959013053

Epoch: 6| Step: 5
Training loss: 2.347978058909071
Validation loss: 2.7663466898494895

Epoch: 6| Step: 6
Training loss: 2.7944204119168607
Validation loss: 2.7561369534677236

Epoch: 6| Step: 7
Training loss: 3.4759595026569756
Validation loss: 2.7530844721434087

Epoch: 6| Step: 8
Training loss: 3.6513329723925154
Validation loss: 2.7547665191040416

Epoch: 6| Step: 9
Training loss: 2.588228161949898
Validation loss: 2.7534909524812328

Epoch: 6| Step: 10
Training loss: 3.3180984116044234
Validation loss: 2.7546572798396767

Epoch: 6| Step: 11
Training loss: 2.770677423512588
Validation loss: 2.7542714257568734

Epoch: 6| Step: 12
Training loss: 3.354037422549181
Validation loss: 2.7575488736799243

Epoch: 6| Step: 13
Training loss: 3.1340557875253734
Validation loss: 2.7535677947761568

Epoch: 146| Step: 0
Training loss: 3.91178477517083
Validation loss: 2.7561980287731798

Epoch: 6| Step: 1
Training loss: 2.9511860936123395
Validation loss: 2.7588831562095137

Epoch: 6| Step: 2
Training loss: 2.733765278003004
Validation loss: 2.755688350509173

Epoch: 6| Step: 3
Training loss: 2.9643005758100105
Validation loss: 2.7566389898587316

Epoch: 6| Step: 4
Training loss: 2.9465886192284794
Validation loss: 2.7570995576024875

Epoch: 6| Step: 5
Training loss: 2.7402731796855946
Validation loss: 2.75284558585244

Epoch: 6| Step: 6
Training loss: 3.745113240504765
Validation loss: 2.7577537900581874

Epoch: 6| Step: 7
Training loss: 2.7493972117677306
Validation loss: 2.752288898717613

Epoch: 6| Step: 8
Training loss: 2.615941357366534
Validation loss: 2.750788065810472

Epoch: 6| Step: 9
Training loss: 2.9142313644940376
Validation loss: 2.7515334666961153

Epoch: 6| Step: 10
Training loss: 2.6017841783076365
Validation loss: 2.751139467197624

Epoch: 6| Step: 11
Training loss: 2.751755760809974
Validation loss: 2.7541184894479125

Epoch: 6| Step: 12
Training loss: 3.5602991098483443
Validation loss: 2.7498234116955453

Epoch: 6| Step: 13
Training loss: 3.7879654702180763
Validation loss: 2.75182564023676

Epoch: 147| Step: 0
Training loss: 3.138668532687237
Validation loss: 2.7482123946013455

Epoch: 6| Step: 1
Training loss: 2.930706365801813
Validation loss: 2.7491278528569145

Epoch: 6| Step: 2
Training loss: 3.095467447160552
Validation loss: 2.7536184001785564

Epoch: 6| Step: 3
Training loss: 3.2451304120630327
Validation loss: 2.7585547128583965

Epoch: 6| Step: 4
Training loss: 3.317041414901078
Validation loss: 2.755398529247548

Epoch: 6| Step: 5
Training loss: 3.175237968117477
Validation loss: 2.757417664686952

Epoch: 6| Step: 6
Training loss: 3.4260587851696993
Validation loss: 2.757628146434431

Epoch: 6| Step: 7
Training loss: 3.190660592682994
Validation loss: 2.754377368712739

Epoch: 6| Step: 8
Training loss: 2.0972847778332477
Validation loss: 2.751553331686072

Epoch: 6| Step: 9
Training loss: 2.5323905729883287
Validation loss: 2.746080536373606

Epoch: 6| Step: 10
Training loss: 3.1001289956111036
Validation loss: 2.7477379096870695

Epoch: 6| Step: 11
Training loss: 3.140864272990423
Validation loss: 2.750008662295006

Epoch: 6| Step: 12
Training loss: 3.192095267764784
Validation loss: 2.7484561197879933

Epoch: 6| Step: 13
Training loss: 3.256285970712505
Validation loss: 2.7503696745060955

Epoch: 148| Step: 0
Training loss: 3.511014636507657
Validation loss: 2.7525157859367235

Epoch: 6| Step: 1
Training loss: 2.7839670518207966
Validation loss: 2.7485531779296704

Epoch: 6| Step: 2
Training loss: 2.836909356170795
Validation loss: 2.75401665751261

Epoch: 6| Step: 3
Training loss: 3.141996928562579
Validation loss: 2.7551755799495825

Epoch: 6| Step: 4
Training loss: 2.7320213433321423
Validation loss: 2.7562555273571374

Epoch: 6| Step: 5
Training loss: 2.9598749111137987
Validation loss: 2.7615100431135664

Epoch: 6| Step: 6
Training loss: 2.412151580317755
Validation loss: 2.759513795244165

Epoch: 6| Step: 7
Training loss: 3.109998324231251
Validation loss: 2.7631407710318454

Epoch: 6| Step: 8
Training loss: 3.232250013133251
Validation loss: 2.765447096504859

Epoch: 6| Step: 9
Training loss: 3.13894471725583
Validation loss: 2.7594087602196447

Epoch: 6| Step: 10
Training loss: 3.621065701372963
Validation loss: 2.749000331261578

Epoch: 6| Step: 11
Training loss: 3.002904122096459
Validation loss: 2.7502576757622057

Epoch: 6| Step: 12
Training loss: 2.7386772098034977
Validation loss: 2.7492820892443053

Epoch: 6| Step: 13
Training loss: 3.8075103627375086
Validation loss: 2.744463247591518

Epoch: 149| Step: 0
Training loss: 3.8370507639016584
Validation loss: 2.7438613517688135

Epoch: 6| Step: 1
Training loss: 2.789499884324209
Validation loss: 2.744670493434638

Epoch: 6| Step: 2
Training loss: 3.5523640511450507
Validation loss: 2.7451636659349634

Epoch: 6| Step: 3
Training loss: 3.362061176240433
Validation loss: 2.746630520125298

Epoch: 6| Step: 4
Training loss: 2.7763819578397118
Validation loss: 2.750491224251441

Epoch: 6| Step: 5
Training loss: 3.504093092888014
Validation loss: 2.749481885099153

Epoch: 6| Step: 6
Training loss: 2.7338606868430437
Validation loss: 2.7507283671559106

Epoch: 6| Step: 7
Training loss: 3.137414002474778
Validation loss: 2.757278238179332

Epoch: 6| Step: 8
Training loss: 2.8181941564910713
Validation loss: 2.7559685498726574

Epoch: 6| Step: 9
Training loss: 2.937915042207152
Validation loss: 2.762580712120757

Epoch: 6| Step: 10
Training loss: 2.7277976137861373
Validation loss: 2.7586563958639028

Epoch: 6| Step: 11
Training loss: 2.858959397093375
Validation loss: 2.7502327053320856

Epoch: 6| Step: 12
Training loss: 2.8907777488146666
Validation loss: 2.7503396194625607

Epoch: 6| Step: 13
Training loss: 2.5991878268045174
Validation loss: 2.750767538253286

Epoch: 150| Step: 0
Training loss: 2.1718909173834997
Validation loss: 2.7517381434762362

Epoch: 6| Step: 1
Training loss: 2.8527623826696638
Validation loss: 2.7485603766816076

Epoch: 6| Step: 2
Training loss: 2.9975410556606383
Validation loss: 2.745947975555073

Epoch: 6| Step: 3
Training loss: 2.9098337698843513
Validation loss: 2.746215166004144

Epoch: 6| Step: 4
Training loss: 2.7526263786774297
Validation loss: 2.7429525381376907

Epoch: 6| Step: 5
Training loss: 3.1801394579555624
Validation loss: 2.74516744345809

Epoch: 6| Step: 6
Training loss: 2.8315966463403504
Validation loss: 2.7427572878368456

Epoch: 6| Step: 7
Training loss: 3.1287012687908535
Validation loss: 2.7432044714724384

Epoch: 6| Step: 8
Training loss: 3.0204244578096096
Validation loss: 2.7407494292784658

Epoch: 6| Step: 9
Training loss: 4.076563276683402
Validation loss: 2.744105358770813

Epoch: 6| Step: 10
Training loss: 2.6285284034394585
Validation loss: 2.7425977097827055

Epoch: 6| Step: 11
Training loss: 2.8646581651565763
Validation loss: 2.7435635729514125

Epoch: 6| Step: 12
Training loss: 3.9269973920867396
Validation loss: 2.7424863835837674

Epoch: 6| Step: 13
Training loss: 3.117671154619218
Validation loss: 2.7464731632582855

Epoch: 151| Step: 0
Training loss: 3.198673038727028
Validation loss: 2.7451740683525996

Epoch: 6| Step: 1
Training loss: 3.2310101241127582
Validation loss: 2.7434060280216404

Epoch: 6| Step: 2
Training loss: 3.443711235257448
Validation loss: 2.7419054388635655

Epoch: 6| Step: 3
Training loss: 2.96974310075344
Validation loss: 2.7404802344371375

Epoch: 6| Step: 4
Training loss: 3.2969532455632695
Validation loss: 2.742617416091624

Epoch: 6| Step: 5
Training loss: 2.7815886730629424
Validation loss: 2.7419608838523306

Epoch: 6| Step: 6
Training loss: 2.490520242476667
Validation loss: 2.743084667074352

Epoch: 6| Step: 7
Training loss: 3.6222256534328734
Validation loss: 2.742546846810377

Epoch: 6| Step: 8
Training loss: 3.240559438044083
Validation loss: 2.742152791095307

Epoch: 6| Step: 9
Training loss: 2.9111939084393157
Validation loss: 2.744340875972604

Epoch: 6| Step: 10
Training loss: 3.194783733612218
Validation loss: 2.7468750044424772

Epoch: 6| Step: 11
Training loss: 2.6662684282326827
Validation loss: 2.7451820454738844

Epoch: 6| Step: 12
Training loss: 2.8341718068833823
Validation loss: 2.7446692455527244

Epoch: 6| Step: 13
Training loss: 2.6559718266854278
Validation loss: 2.7486285176523864

Epoch: 152| Step: 0
Training loss: 3.4195501364033216
Validation loss: 2.7440994179608524

Epoch: 6| Step: 1
Training loss: 2.828619644998128
Validation loss: 2.7514333755623097

Epoch: 6| Step: 2
Training loss: 3.056011878724504
Validation loss: 2.74265235653792

Epoch: 6| Step: 3
Training loss: 3.1505876870907517
Validation loss: 2.743502089296243

Epoch: 6| Step: 4
Training loss: 3.4075342959429396
Validation loss: 2.737453889067467

Epoch: 6| Step: 5
Training loss: 2.6697381827754367
Validation loss: 2.7429066615316704

Epoch: 6| Step: 6
Training loss: 3.0383144526924695
Validation loss: 2.736446653171959

Epoch: 6| Step: 7
Training loss: 2.845842032095785
Validation loss: 2.738133677690033

Epoch: 6| Step: 8
Training loss: 3.1729385772636522
Validation loss: 2.7357045147021326

Epoch: 6| Step: 9
Training loss: 2.8992645646558612
Validation loss: 2.7375418582985707

Epoch: 6| Step: 10
Training loss: 2.8367074809143418
Validation loss: 2.739147242496899

Epoch: 6| Step: 11
Training loss: 3.7055697197923814
Validation loss: 2.737395258512484

Epoch: 6| Step: 12
Training loss: 2.93519079468792
Validation loss: 2.740659835301626

Epoch: 6| Step: 13
Training loss: 2.4928465542781146
Validation loss: 2.7401933552733673

Epoch: 153| Step: 0
Training loss: 2.7327323120985345
Validation loss: 2.7403887045246904

Epoch: 6| Step: 1
Training loss: 3.2261921298288074
Validation loss: 2.741965984087984

Epoch: 6| Step: 2
Training loss: 2.697103154332415
Validation loss: 2.744080232392068

Epoch: 6| Step: 3
Training loss: 3.548139842359991
Validation loss: 2.7399203285315097

Epoch: 6| Step: 4
Training loss: 3.4524081077196733
Validation loss: 2.7397245874994973

Epoch: 6| Step: 5
Training loss: 3.3465206752966563
Validation loss: 2.7384223538261456

Epoch: 6| Step: 6
Training loss: 3.0602240376953893
Validation loss: 2.738492470511351

Epoch: 6| Step: 7
Training loss: 3.3600999626548615
Validation loss: 2.7388950248849824

Epoch: 6| Step: 8
Training loss: 1.7255799963200638
Validation loss: 2.746478049760352

Epoch: 6| Step: 9
Training loss: 2.5223183999604033
Validation loss: 2.7443061279770964

Epoch: 6| Step: 10
Training loss: 2.6740984672043564
Validation loss: 2.748830419792065

Epoch: 6| Step: 11
Training loss: 3.7605669549865763
Validation loss: 2.7545972425127663

Epoch: 6| Step: 12
Training loss: 3.139284673473943
Validation loss: 2.745169764134121

Epoch: 6| Step: 13
Training loss: 3.0494843093911235
Validation loss: 2.74897221593826

Epoch: 154| Step: 0
Training loss: 3.186692079365593
Validation loss: 2.744515520094668

Epoch: 6| Step: 1
Training loss: 3.1274782653590045
Validation loss: 2.745267711683561

Epoch: 6| Step: 2
Training loss: 3.0369847115693
Validation loss: 2.739349681545051

Epoch: 6| Step: 3
Training loss: 3.02947851899397
Validation loss: 2.739749751016912

Epoch: 6| Step: 4
Training loss: 2.9811460592836148
Validation loss: 2.735317139873304

Epoch: 6| Step: 5
Training loss: 3.0903222717815755
Validation loss: 2.7411177747176607

Epoch: 6| Step: 6
Training loss: 3.1678805450690763
Validation loss: 2.736968791488463

Epoch: 6| Step: 7
Training loss: 1.9240011224564988
Validation loss: 2.733793820263563

Epoch: 6| Step: 8
Training loss: 3.635206389516937
Validation loss: 2.7341832153754835

Epoch: 6| Step: 9
Training loss: 2.5513558317491105
Validation loss: 2.7355714998122984

Epoch: 6| Step: 10
Training loss: 2.6839665982631082
Validation loss: 2.735184877528543

Epoch: 6| Step: 11
Training loss: 3.4213607610711647
Validation loss: 2.7385084074882298

Epoch: 6| Step: 12
Training loss: 3.343689677327153
Validation loss: 2.7375440515231033

Epoch: 6| Step: 13
Training loss: 3.421182780164692
Validation loss: 2.7359851265199393

Epoch: 155| Step: 0
Training loss: 3.2307226226574732
Validation loss: 2.735157251927693

Epoch: 6| Step: 1
Training loss: 2.805760935283752
Validation loss: 2.734503243950443

Epoch: 6| Step: 2
Training loss: 3.236652549086902
Validation loss: 2.735607122523441

Epoch: 6| Step: 3
Training loss: 2.6070527118991764
Validation loss: 2.7406274315720163

Epoch: 6| Step: 4
Training loss: 2.750801836503927
Validation loss: 2.739331763560916

Epoch: 6| Step: 5
Training loss: 2.7992396241840916
Validation loss: 2.752578531421548

Epoch: 6| Step: 6
Training loss: 2.6028850504363255
Validation loss: 2.7481859662029375

Epoch: 6| Step: 7
Training loss: 3.453518668126911
Validation loss: 2.7526771457424686

Epoch: 6| Step: 8
Training loss: 3.6005480614023555
Validation loss: 2.7637580051420185

Epoch: 6| Step: 9
Training loss: 2.9785857445639747
Validation loss: 2.7453844279888737

Epoch: 6| Step: 10
Training loss: 2.977818501923095
Validation loss: 2.7459106365589996

Epoch: 6| Step: 11
Training loss: 3.5734475559748646
Validation loss: 2.7534121676765753

Epoch: 6| Step: 12
Training loss: 2.5714401971463383
Validation loss: 2.7381526680494583

Epoch: 6| Step: 13
Training loss: 3.479664445243141
Validation loss: 2.7374283148556877

Epoch: 156| Step: 0
Training loss: 3.0481060964386533
Validation loss: 2.7384983944642447

Epoch: 6| Step: 1
Training loss: 3.2193167474534983
Validation loss: 2.7346779566696706

Epoch: 6| Step: 2
Training loss: 3.905460979883561
Validation loss: 2.7352867985291933

Epoch: 6| Step: 3
Training loss: 3.166396949391103
Validation loss: 2.737068425294694

Epoch: 6| Step: 4
Training loss: 2.9842701838596044
Validation loss: 2.7377675114780406

Epoch: 6| Step: 5
Training loss: 2.5136400056254793
Validation loss: 2.7372701283451315

Epoch: 6| Step: 6
Training loss: 2.664933406291242
Validation loss: 2.7349518498255225

Epoch: 6| Step: 7
Training loss: 2.8490760309338015
Validation loss: 2.7419067197928055

Epoch: 6| Step: 8
Training loss: 2.9122465882957163
Validation loss: 2.7363333734572066

Epoch: 6| Step: 9
Training loss: 3.1133222972121533
Validation loss: 2.743425330441382

Epoch: 6| Step: 10
Training loss: 3.0673845224943497
Validation loss: 2.7419967105865166

Epoch: 6| Step: 11
Training loss: 3.0817877186143985
Validation loss: 2.7459083557212365

Epoch: 6| Step: 12
Training loss: 3.4775589447181563
Validation loss: 2.749394140317402

Epoch: 6| Step: 13
Training loss: 1.9073470664056067
Validation loss: 2.736424197717019

Epoch: 157| Step: 0
Training loss: 3.058123673018326
Validation loss: 2.734333669229988

Epoch: 6| Step: 1
Training loss: 3.062113679147297
Validation loss: 2.7363825053490074

Epoch: 6| Step: 2
Training loss: 3.124015347803296
Validation loss: 2.7321477497999522

Epoch: 6| Step: 3
Training loss: 3.1519628434096987
Validation loss: 2.7335471179453505

Epoch: 6| Step: 4
Training loss: 3.1259001389146768
Validation loss: 2.7285838991846996

Epoch: 6| Step: 5
Training loss: 3.440902967597586
Validation loss: 2.7319468453032276

Epoch: 6| Step: 6
Training loss: 2.976536868327961
Validation loss: 2.733673333822077

Epoch: 6| Step: 7
Training loss: 3.36739084997192
Validation loss: 2.7329693065502703

Epoch: 6| Step: 8
Training loss: 2.83144760957993
Validation loss: 2.726337225515593

Epoch: 6| Step: 9
Training loss: 3.3613214575852672
Validation loss: 2.7322766509371097

Epoch: 6| Step: 10
Training loss: 2.468265920573204
Validation loss: 2.7319359843175

Epoch: 6| Step: 11
Training loss: 2.7235018540360842
Validation loss: 2.7354450191339934

Epoch: 6| Step: 12
Training loss: 2.7226982824947754
Validation loss: 2.728737232233117

Epoch: 6| Step: 13
Training loss: 3.280587701714456
Validation loss: 2.7392730033365122

Epoch: 158| Step: 0
Training loss: 2.4850365099920873
Validation loss: 2.7376828747527107

Epoch: 6| Step: 1
Training loss: 3.074486145256317
Validation loss: 2.748429943714368

Epoch: 6| Step: 2
Training loss: 3.039543055022811
Validation loss: 2.754744986335859

Epoch: 6| Step: 3
Training loss: 2.472071863333538
Validation loss: 2.7621000562504183

Epoch: 6| Step: 4
Training loss: 2.912546208223839
Validation loss: 2.78024718016341

Epoch: 6| Step: 5
Training loss: 3.082934190501222
Validation loss: 2.7557010101198394

Epoch: 6| Step: 6
Training loss: 3.742667977660244
Validation loss: 2.73612201063096

Epoch: 6| Step: 7
Training loss: 2.8693536792279586
Validation loss: 2.7316560179838256

Epoch: 6| Step: 8
Training loss: 3.1143949998201554
Validation loss: 2.727883874804073

Epoch: 6| Step: 9
Training loss: 3.4001645665452496
Validation loss: 2.7279160981665664

Epoch: 6| Step: 10
Training loss: 3.087781910246276
Validation loss: 2.7304431497973782

Epoch: 6| Step: 11
Training loss: 3.121873283194833
Validation loss: 2.7315043382534387

Epoch: 6| Step: 12
Training loss: 3.293946615355138
Validation loss: 2.7320843089572127

Epoch: 6| Step: 13
Training loss: 2.5946591174312177
Validation loss: 2.7318563751832716

Epoch: 159| Step: 0
Training loss: 3.257581816997632
Validation loss: 2.7378116510617048

Epoch: 6| Step: 1
Training loss: 2.7945446343617313
Validation loss: 2.738518678850635

Epoch: 6| Step: 2
Training loss: 2.804551995279473
Validation loss: 2.7385079319265877

Epoch: 6| Step: 3
Training loss: 3.2285941980381287
Validation loss: 2.739010968200987

Epoch: 6| Step: 4
Training loss: 3.0601342853676243
Validation loss: 2.7408514557614083

Epoch: 6| Step: 5
Training loss: 3.158874025253599
Validation loss: 2.7397089635824297

Epoch: 6| Step: 6
Training loss: 2.6586536975775124
Validation loss: 2.7348116777685423

Epoch: 6| Step: 7
Training loss: 3.5469184234246494
Validation loss: 2.741148055260571

Epoch: 6| Step: 8
Training loss: 3.1828906072621868
Validation loss: 2.737691446793634

Epoch: 6| Step: 9
Training loss: 3.2226041662457843
Validation loss: 2.7375956901217853

Epoch: 6| Step: 10
Training loss: 3.6148323317776767
Validation loss: 2.735214577971854

Epoch: 6| Step: 11
Training loss: 2.9464381164131956
Validation loss: 2.7358530632639164

Epoch: 6| Step: 12
Training loss: 2.810868616622508
Validation loss: 2.7318666490341066

Epoch: 6| Step: 13
Training loss: 1.940668038645008
Validation loss: 2.730929361472887

Epoch: 160| Step: 0
Training loss: 2.9302955098253047
Validation loss: 2.7337695879864428

Epoch: 6| Step: 1
Training loss: 3.114912919347375
Validation loss: 2.730313579946793

Epoch: 6| Step: 2
Training loss: 2.8321147616997266
Validation loss: 2.7277714847661723

Epoch: 6| Step: 3
Training loss: 3.6023755924469643
Validation loss: 2.732572023354291

Epoch: 6| Step: 4
Training loss: 2.8843979856292288
Validation loss: 2.7282861865682753

Epoch: 6| Step: 5
Training loss: 3.483990019327402
Validation loss: 2.7325264678355614

Epoch: 6| Step: 6
Training loss: 2.5818033507357057
Validation loss: 2.729710915812181

Epoch: 6| Step: 7
Training loss: 3.319585743073258
Validation loss: 2.729660307662037

Epoch: 6| Step: 8
Training loss: 3.8458057891641837
Validation loss: 2.7319234998547817

Epoch: 6| Step: 9
Training loss: 2.612533393901967
Validation loss: 2.734225176619464

Epoch: 6| Step: 10
Training loss: 3.111304676377035
Validation loss: 2.733026461804018

Epoch: 6| Step: 11
Training loss: 2.8010340620405576
Validation loss: 2.7336113276153275

Epoch: 6| Step: 12
Training loss: 2.5430761921066902
Validation loss: 2.735908140838998

Epoch: 6| Step: 13
Training loss: 2.488000204123093
Validation loss: 2.7402136411462723

Epoch: 161| Step: 0
Training loss: 2.581981110194197
Validation loss: 2.746888146117063

Epoch: 6| Step: 1
Training loss: 3.4762061461501714
Validation loss: 2.7399987574446447

Epoch: 6| Step: 2
Training loss: 3.3144446368943314
Validation loss: 2.751993646191428

Epoch: 6| Step: 3
Training loss: 3.4357310511942196
Validation loss: 2.7547921277843477

Epoch: 6| Step: 4
Training loss: 2.853396977876456
Validation loss: 2.7577251216089653

Epoch: 6| Step: 5
Training loss: 2.931813844243417
Validation loss: 2.7672798346308762

Epoch: 6| Step: 6
Training loss: 3.1986198190701316
Validation loss: 2.7626750571527388

Epoch: 6| Step: 7
Training loss: 1.955969120616597
Validation loss: 2.77802867009305

Epoch: 6| Step: 8
Training loss: 2.8842683749675393
Validation loss: 2.7580911627509335

Epoch: 6| Step: 9
Training loss: 3.391780814484606
Validation loss: 2.749999043528818

Epoch: 6| Step: 10
Training loss: 3.182733899411462
Validation loss: 2.7430888437231498

Epoch: 6| Step: 11
Training loss: 3.3785470760600345
Validation loss: 2.733715294452423

Epoch: 6| Step: 12
Training loss: 2.8282005342123018
Validation loss: 2.7255569692613597

Epoch: 6| Step: 13
Training loss: 2.8817932477353176
Validation loss: 2.7258648588516556

Epoch: 162| Step: 0
Training loss: 2.703262854792939
Validation loss: 2.72718826655226

Epoch: 6| Step: 1
Training loss: 3.299770584223743
Validation loss: 2.728568232145714

Epoch: 6| Step: 2
Training loss: 3.4985280347646466
Validation loss: 2.722589439219355

Epoch: 6| Step: 3
Training loss: 2.5247236346088147
Validation loss: 2.72648368364474

Epoch: 6| Step: 4
Training loss: 2.9514961392731047
Validation loss: 2.7263086348109997

Epoch: 6| Step: 5
Training loss: 3.745164933080593
Validation loss: 2.72445151408749

Epoch: 6| Step: 6
Training loss: 3.234695050165613
Validation loss: 2.7221024103343914

Epoch: 6| Step: 7
Training loss: 3.6494744275178768
Validation loss: 2.725247985658786

Epoch: 6| Step: 8
Training loss: 2.783346179163484
Validation loss: 2.7205112227850416

Epoch: 6| Step: 9
Training loss: 3.1025576592435256
Validation loss: 2.7222653562677643

Epoch: 6| Step: 10
Training loss: 3.094588503251372
Validation loss: 2.723570683128875

Epoch: 6| Step: 11
Training loss: 2.7432300292163943
Validation loss: 2.719648612273902

Epoch: 6| Step: 12
Training loss: 2.6890027480106067
Validation loss: 2.7193499629089706

Epoch: 6| Step: 13
Training loss: 1.6928087723106282
Validation loss: 2.719082656516498

Epoch: 163| Step: 0
Training loss: 2.854597926913845
Validation loss: 2.7206092599614955

Epoch: 6| Step: 1
Training loss: 2.5445281841855762
Validation loss: 2.720765861646141

Epoch: 6| Step: 2
Training loss: 2.462282328013565
Validation loss: 2.7193159401436295

Epoch: 6| Step: 3
Training loss: 3.3408843979073364
Validation loss: 2.7209160181732073

Epoch: 6| Step: 4
Training loss: 2.5725907545327953
Validation loss: 2.717863661413894

Epoch: 6| Step: 5
Training loss: 2.9539680690395542
Validation loss: 2.7197247545739973

Epoch: 6| Step: 6
Training loss: 3.061926651826753
Validation loss: 2.7189219920977794

Epoch: 6| Step: 7
Training loss: 3.361655237660407
Validation loss: 2.7331635287979523

Epoch: 6| Step: 8
Training loss: 3.4731491648732797
Validation loss: 2.7323431357133185

Epoch: 6| Step: 9
Training loss: 2.7337231540277505
Validation loss: 2.7364567467775607

Epoch: 6| Step: 10
Training loss: 3.0283516467360694
Validation loss: 2.738373908249842

Epoch: 6| Step: 11
Training loss: 3.602473807732735
Validation loss: 2.7387705042796533

Epoch: 6| Step: 12
Training loss: 3.209146784586516
Validation loss: 2.745892063967833

Epoch: 6| Step: 13
Training loss: 3.271276958210187
Validation loss: 2.7407699691983756

Epoch: 164| Step: 0
Training loss: 3.585244903499119
Validation loss: 2.728349379338962

Epoch: 6| Step: 1
Training loss: 3.022107366486226
Validation loss: 2.7283093799096307

Epoch: 6| Step: 2
Training loss: 3.323351808634999
Validation loss: 2.726440272747465

Epoch: 6| Step: 3
Training loss: 2.9482171182997603
Validation loss: 2.7219067574155345

Epoch: 6| Step: 4
Training loss: 3.0418829296691383
Validation loss: 2.7196486339545465

Epoch: 6| Step: 5
Training loss: 2.6243110842642468
Validation loss: 2.717327468534234

Epoch: 6| Step: 6
Training loss: 2.2761977176433263
Validation loss: 2.717189851781181

Epoch: 6| Step: 7
Training loss: 3.069707679872493
Validation loss: 2.7198652545547697

Epoch: 6| Step: 8
Training loss: 3.075003808492147
Validation loss: 2.716332056884088

Epoch: 6| Step: 9
Training loss: 3.210358282041471
Validation loss: 2.7162171652967033

Epoch: 6| Step: 10
Training loss: 3.616066810564594
Validation loss: 2.718733511556382

Epoch: 6| Step: 11
Training loss: 2.5558872030738025
Validation loss: 2.7150079275758157

Epoch: 6| Step: 12
Training loss: 2.933275472185921
Validation loss: 2.719196924522308

Epoch: 6| Step: 13
Training loss: 3.084031069053568
Validation loss: 2.718785183058563

Epoch: 165| Step: 0
Training loss: 2.9464568892269987
Validation loss: 2.7182613410313503

Epoch: 6| Step: 1
Training loss: 3.3055930914648783
Validation loss: 2.7203566834730424

Epoch: 6| Step: 2
Training loss: 2.6166756656111327
Validation loss: 2.724713539487327

Epoch: 6| Step: 3
Training loss: 2.956055171425877
Validation loss: 2.7241946854520966

Epoch: 6| Step: 4
Training loss: 3.3444458424624046
Validation loss: 2.723810088872741

Epoch: 6| Step: 5
Training loss: 3.284852874573346
Validation loss: 2.726270908350897

Epoch: 6| Step: 6
Training loss: 3.0146966799974577
Validation loss: 2.7230075648306067

Epoch: 6| Step: 7
Training loss: 3.6620348950759474
Validation loss: 2.728656267053415

Epoch: 6| Step: 8
Training loss: 2.6218830858726534
Validation loss: 2.727891733324853

Epoch: 6| Step: 9
Training loss: 2.7940820142522953
Validation loss: 2.7346041881886802

Epoch: 6| Step: 10
Training loss: 2.932196842013254
Validation loss: 2.72771543274742

Epoch: 6| Step: 11
Training loss: 2.4397822723802824
Validation loss: 2.731848550589554

Epoch: 6| Step: 12
Training loss: 3.4288629396579795
Validation loss: 2.7328006957617035

Epoch: 6| Step: 13
Training loss: 2.927010332783302
Validation loss: 2.7241195574216306

Epoch: 166| Step: 0
Training loss: 3.089054744789835
Validation loss: 2.7288355009177296

Epoch: 6| Step: 1
Training loss: 2.976246093593631
Validation loss: 2.7237132097898455

Epoch: 6| Step: 2
Training loss: 2.8653022742465994
Validation loss: 2.7207822068014336

Epoch: 6| Step: 3
Training loss: 2.856144815924727
Validation loss: 2.7199672510068464

Epoch: 6| Step: 4
Training loss: 2.4560808002153105
Validation loss: 2.7232408859676354

Epoch: 6| Step: 5
Training loss: 3.3540401237421658
Validation loss: 2.721624998305149

Epoch: 6| Step: 6
Training loss: 3.0618377280862425
Validation loss: 2.7203017235961173

Epoch: 6| Step: 7
Training loss: 2.5428485519668187
Validation loss: 2.7192821036198382

Epoch: 6| Step: 8
Training loss: 3.1434735337750093
Validation loss: 2.7175404469177646

Epoch: 6| Step: 9
Training loss: 3.336599958694898
Validation loss: 2.7198634599168288

Epoch: 6| Step: 10
Training loss: 3.330758212720708
Validation loss: 2.714426219860095

Epoch: 6| Step: 11
Training loss: 3.486035143939354
Validation loss: 2.7193491323546928

Epoch: 6| Step: 12
Training loss: 2.9777624560036293
Validation loss: 2.7225661623100623

Epoch: 6| Step: 13
Training loss: 2.708357404944233
Validation loss: 2.7200155569351883

Epoch: 167| Step: 0
Training loss: 3.3117552585843706
Validation loss: 2.7224092263028927

Epoch: 6| Step: 1
Training loss: 3.0210994384017593
Validation loss: 2.714079954741895

Epoch: 6| Step: 2
Training loss: 3.6315973690214607
Validation loss: 2.7119355969219856

Epoch: 6| Step: 3
Training loss: 3.190956784444959
Validation loss: 2.712595053536006

Epoch: 6| Step: 4
Training loss: 3.0546715777438296
Validation loss: 2.7142245807335357

Epoch: 6| Step: 5
Training loss: 3.1312853356231174
Validation loss: 2.7174574622865766

Epoch: 6| Step: 6
Training loss: 2.931220139471357
Validation loss: 2.709862609693549

Epoch: 6| Step: 7
Training loss: 2.8653923048350483
Validation loss: 2.716499792027181

Epoch: 6| Step: 8
Training loss: 3.2556519879961616
Validation loss: 2.717267384771496

Epoch: 6| Step: 9
Training loss: 3.3029242246125956
Validation loss: 2.719949674719847

Epoch: 6| Step: 10
Training loss: 2.7066393812179186
Validation loss: 2.717916335136561

Epoch: 6| Step: 11
Training loss: 2.687887917844199
Validation loss: 2.722565538011575

Epoch: 6| Step: 12
Training loss: 2.535233647791711
Validation loss: 2.7254680610509587

Epoch: 6| Step: 13
Training loss: 2.363869938946903
Validation loss: 2.731200692577053

Epoch: 168| Step: 0
Training loss: 3.1489569375130433
Validation loss: 2.7475595263446264

Epoch: 6| Step: 1
Training loss: 3.208842464195145
Validation loss: 2.74796851718892

Epoch: 6| Step: 2
Training loss: 2.952793163244724
Validation loss: 2.738876912978587

Epoch: 6| Step: 3
Training loss: 3.1891280859520834
Validation loss: 2.7484102958716106

Epoch: 6| Step: 4
Training loss: 2.689025800632959
Validation loss: 2.7323457403140803

Epoch: 6| Step: 5
Training loss: 2.9572492592191724
Validation loss: 2.732783874636848

Epoch: 6| Step: 6
Training loss: 3.373446919585766
Validation loss: 2.7284351127091715

Epoch: 6| Step: 7
Training loss: 3.575944660996009
Validation loss: 2.7140395324786732

Epoch: 6| Step: 8
Training loss: 3.206640630948121
Validation loss: 2.7262288538285673

Epoch: 6| Step: 9
Training loss: 2.2480784794286897
Validation loss: 2.7182622728315695

Epoch: 6| Step: 10
Training loss: 2.8926084569645325
Validation loss: 2.7095289735373935

Epoch: 6| Step: 11
Training loss: 2.8798505251559865
Validation loss: 2.719550603625962

Epoch: 6| Step: 12
Training loss: 2.631557539049706
Validation loss: 2.7261637725135333

Epoch: 6| Step: 13
Training loss: 3.5706356912322983
Validation loss: 2.7195814287827265

Epoch: 169| Step: 0
Training loss: 3.173771333626513
Validation loss: 2.719305253085564

Epoch: 6| Step: 1
Training loss: 2.56254019356816
Validation loss: 2.710306660007358

Epoch: 6| Step: 2
Training loss: 3.449919027953914
Validation loss: 2.708431859902286

Epoch: 6| Step: 3
Training loss: 2.3698608611907597
Validation loss: 2.7059490610315

Epoch: 6| Step: 4
Training loss: 2.9352338450138094
Validation loss: 2.7074658376283947

Epoch: 6| Step: 5
Training loss: 2.869572699766996
Validation loss: 2.705299229032052

Epoch: 6| Step: 6
Training loss: 3.2525722887947395
Validation loss: 2.7057181543297473

Epoch: 6| Step: 7
Training loss: 3.4070338475970376
Validation loss: 2.7074857257870524

Epoch: 6| Step: 8
Training loss: 3.173022734350493
Validation loss: 2.7077815841908444

Epoch: 6| Step: 9
Training loss: 3.094547515726233
Validation loss: 2.7053128853890103

Epoch: 6| Step: 10
Training loss: 2.875509963210517
Validation loss: 2.707533862404291

Epoch: 6| Step: 11
Training loss: 2.638370341388618
Validation loss: 2.708759632747356

Epoch: 6| Step: 12
Training loss: 3.431309344780805
Validation loss: 2.7052696417594997

Epoch: 6| Step: 13
Training loss: 3.035100791552131
Validation loss: 2.7062404162630758

Epoch: 170| Step: 0
Training loss: 2.732022565086639
Validation loss: 2.7056285534633506

Epoch: 6| Step: 1
Training loss: 2.9870033074722393
Validation loss: 2.7077688009007264

Epoch: 6| Step: 2
Training loss: 2.1581109903269167
Validation loss: 2.7093280495836427

Epoch: 6| Step: 3
Training loss: 3.412887126496862
Validation loss: 2.705634423351325

Epoch: 6| Step: 4
Training loss: 2.639716358842207
Validation loss: 2.7064390024276177

Epoch: 6| Step: 5
Training loss: 2.9910130997361026
Validation loss: 2.7120420981005666

Epoch: 6| Step: 6
Training loss: 3.434961664910439
Validation loss: 2.7057684617860303

Epoch: 6| Step: 7
Training loss: 3.2648682516017984
Validation loss: 2.707471090904078

Epoch: 6| Step: 8
Training loss: 2.994061473340208
Validation loss: 2.7087318550008392

Epoch: 6| Step: 9
Training loss: 3.084510338006432
Validation loss: 2.7053696507837497

Epoch: 6| Step: 10
Training loss: 3.5187885885341763
Validation loss: 2.7060381595963623

Epoch: 6| Step: 11
Training loss: 3.0406436680439266
Validation loss: 2.71968975805529

Epoch: 6| Step: 12
Training loss: 3.531251890468935
Validation loss: 2.7148571562655497

Epoch: 6| Step: 13
Training loss: 1.5059029935266333
Validation loss: 2.714596313806161

Epoch: 171| Step: 0
Training loss: 3.1787874414756794
Validation loss: 2.72247224473939

Epoch: 6| Step: 1
Training loss: 2.9717047192299333
Validation loss: 2.735098207526791

Epoch: 6| Step: 2
Training loss: 3.526806221155627
Validation loss: 2.727497023771291

Epoch: 6| Step: 3
Training loss: 2.940540606821094
Validation loss: 2.728983465184599

Epoch: 6| Step: 4
Training loss: 3.122116895130666
Validation loss: 2.7343858934879854

Epoch: 6| Step: 5
Training loss: 2.5067654619463853
Validation loss: 2.7292498385122452

Epoch: 6| Step: 6
Training loss: 3.2118034587314854
Validation loss: 2.728199314321767

Epoch: 6| Step: 7
Training loss: 2.554489828039089
Validation loss: 2.719559673988185

Epoch: 6| Step: 8
Training loss: 2.842962302640652
Validation loss: 2.721999493673747

Epoch: 6| Step: 9
Training loss: 2.98495174247545
Validation loss: 2.7226515382524776

Epoch: 6| Step: 10
Training loss: 2.9980837742028945
Validation loss: 2.718117278800393

Epoch: 6| Step: 11
Training loss: 3.1256984693057817
Validation loss: 2.710681320294194

Epoch: 6| Step: 12
Training loss: 3.566985134511931
Validation loss: 2.7077383146593825

Epoch: 6| Step: 13
Training loss: 2.489225151652887
Validation loss: 2.7089785521174727

Epoch: 172| Step: 0
Training loss: 3.671740330600584
Validation loss: 2.709405482292759

Epoch: 6| Step: 1
Training loss: 2.9614070630720275
Validation loss: 2.7064917223141656

Epoch: 6| Step: 2
Training loss: 2.8431744674300403
Validation loss: 2.706638967305725

Epoch: 6| Step: 3
Training loss: 2.8610121412556273
Validation loss: 2.7011975200933085

Epoch: 6| Step: 4
Training loss: 2.780589164490966
Validation loss: 2.703841928598638

Epoch: 6| Step: 5
Training loss: 3.173837890609976
Validation loss: 2.704610446429895

Epoch: 6| Step: 6
Training loss: 2.456420143194433
Validation loss: 2.705361375275852

Epoch: 6| Step: 7
Training loss: 2.4312113310183006
Validation loss: 2.7039591246598658

Epoch: 6| Step: 8
Training loss: 3.0461235489112934
Validation loss: 2.7013755143052394

Epoch: 6| Step: 9
Training loss: 3.1991987775055746
Validation loss: 2.704591684068454

Epoch: 6| Step: 10
Training loss: 3.2648784751533295
Validation loss: 2.703475345705203

Epoch: 6| Step: 11
Training loss: 2.76822656372369
Validation loss: 2.7035586092146753

Epoch: 6| Step: 12
Training loss: 2.778397372338623
Validation loss: 2.7014217431827356

Epoch: 6| Step: 13
Training loss: 4.414036573485806
Validation loss: 2.7053652112180777

Epoch: 173| Step: 0
Training loss: 2.6720130393972146
Validation loss: 2.701308235084762

Epoch: 6| Step: 1
Training loss: 2.9485907081700304
Validation loss: 2.7034225655733595

Epoch: 6| Step: 2
Training loss: 3.384849023424376
Validation loss: 2.7039325799239085

Epoch: 6| Step: 3
Training loss: 2.8988862628501666
Validation loss: 2.7124009520089065

Epoch: 6| Step: 4
Training loss: 3.082272905707538
Validation loss: 2.7108161456772444

Epoch: 6| Step: 5
Training loss: 3.4056509348581363
Validation loss: 2.7070728233642107

Epoch: 6| Step: 6
Training loss: 2.7251058365453504
Validation loss: 2.714188634880562

Epoch: 6| Step: 7
Training loss: 3.0254300276848234
Validation loss: 2.7187904172916895

Epoch: 6| Step: 8
Training loss: 3.776767311966062
Validation loss: 2.725292316723923

Epoch: 6| Step: 9
Training loss: 2.683458794055864
Validation loss: 2.728383861685775

Epoch: 6| Step: 10
Training loss: 3.2090069612717005
Validation loss: 2.724421718893654

Epoch: 6| Step: 11
Training loss: 2.9768490791033226
Validation loss: 2.720780921580351

Epoch: 6| Step: 12
Training loss: 2.5562082599692384
Validation loss: 2.721107212563876

Epoch: 6| Step: 13
Training loss: 2.7576303394878576
Validation loss: 2.7124086115381365

Epoch: 174| Step: 0
Training loss: 2.7667192783485546
Validation loss: 2.7118135404298327

Epoch: 6| Step: 1
Training loss: 2.987344752152468
Validation loss: 2.7082129237920016

Epoch: 6| Step: 2
Training loss: 3.6140736303887864
Validation loss: 2.702242503592472

Epoch: 6| Step: 3
Training loss: 3.1493512287821193
Validation loss: 2.706804624684601

Epoch: 6| Step: 4
Training loss: 2.9681839252662536
Validation loss: 2.703157201742673

Epoch: 6| Step: 5
Training loss: 2.318948775251668
Validation loss: 2.7061968246306067

Epoch: 6| Step: 6
Training loss: 3.170863850096243
Validation loss: 2.7040168675083884

Epoch: 6| Step: 7
Training loss: 3.0301728841981745
Validation loss: 2.6981168786608114

Epoch: 6| Step: 8
Training loss: 2.9088198876929603
Validation loss: 2.702993600887969

Epoch: 6| Step: 9
Training loss: 3.2261324173296897
Validation loss: 2.700986669975896

Epoch: 6| Step: 10
Training loss: 3.259381472177928
Validation loss: 2.700346669843767

Epoch: 6| Step: 11
Training loss: 3.0730725954656446
Validation loss: 2.7062691583537637

Epoch: 6| Step: 12
Training loss: 3.107767274123779
Validation loss: 2.6994458478722114

Epoch: 6| Step: 13
Training loss: 2.2040016107709093
Validation loss: 2.7028966272912323

Epoch: 175| Step: 0
Training loss: 2.395066666601032
Validation loss: 2.6999467721809824

Epoch: 6| Step: 1
Training loss: 3.1671787316417843
Validation loss: 2.699723190062721

Epoch: 6| Step: 2
Training loss: 2.670115733835141
Validation loss: 2.700273008759867

Epoch: 6| Step: 3
Training loss: 3.2495061058953216
Validation loss: 2.694171885671007

Epoch: 6| Step: 4
Training loss: 2.9508664814479504
Validation loss: 2.6972661468019905

Epoch: 6| Step: 5
Training loss: 3.404247009997677
Validation loss: 2.7036894280663044

Epoch: 6| Step: 6
Training loss: 2.7548532142928788
Validation loss: 2.712772013574204

Epoch: 6| Step: 7
Training loss: 2.990885877242473
Validation loss: 2.7062091502131533

Epoch: 6| Step: 8
Training loss: 2.9220636480293796
Validation loss: 2.716259305926797

Epoch: 6| Step: 9
Training loss: 3.5066065425093997
Validation loss: 2.7052035283593177

Epoch: 6| Step: 10
Training loss: 2.9625378312540294
Validation loss: 2.7043212845915927

Epoch: 6| Step: 11
Training loss: 2.8628535556254064
Validation loss: 2.7058992041182264

Epoch: 6| Step: 12
Training loss: 3.202943973543129
Validation loss: 2.6992021593430753

Epoch: 6| Step: 13
Training loss: 3.2030065002851837
Validation loss: 2.7003059983280915

Testing loss: 2.926096082475403
