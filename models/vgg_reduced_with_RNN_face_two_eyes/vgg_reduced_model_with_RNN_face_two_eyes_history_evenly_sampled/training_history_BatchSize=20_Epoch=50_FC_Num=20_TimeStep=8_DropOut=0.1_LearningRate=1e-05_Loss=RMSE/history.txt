Epoch: 1| Step: 0
Training loss: 7.214582024387906
Validation loss: 5.8409009771540505

Epoch: 5| Step: 1
Training loss: 5.134042531519787
Validation loss: 5.834822185505822

Epoch: 5| Step: 2
Training loss: 6.059826133424456
Validation loss: 5.829183685832149

Epoch: 5| Step: 3
Training loss: 5.278988145049323
Validation loss: 5.824082514335546

Epoch: 5| Step: 4
Training loss: 6.2257445598664765
Validation loss: 5.818242593947276

Epoch: 5| Step: 5
Training loss: 4.693829954560986
Validation loss: 5.811895844756466

Epoch: 5| Step: 6
Training loss: 6.981891096521873
Validation loss: 5.805369270506123

Epoch: 5| Step: 7
Training loss: 5.611901184625925
Validation loss: 5.798330412812435

Epoch: 5| Step: 8
Training loss: 5.715143452710404
Validation loss: 5.79092501393893

Epoch: 5| Step: 9
Training loss: 5.848975145605104
Validation loss: 5.78311863670613

Epoch: 5| Step: 10
Training loss: 4.824359301786041
Validation loss: 5.7738826282106785

Epoch: 2| Step: 0
Training loss: 7.110485082461685
Validation loss: 5.76462694781593

Epoch: 5| Step: 1
Training loss: 5.49413246672208
Validation loss: 5.755014534466099

Epoch: 5| Step: 2
Training loss: 5.342977189069772
Validation loss: 5.744482875657945

Epoch: 5| Step: 3
Training loss: 5.202994863354729
Validation loss: 5.733623265697764

Epoch: 5| Step: 4
Training loss: 5.574082905558287
Validation loss: 5.720929616319777

Epoch: 5| Step: 5
Training loss: 6.184883874714316
Validation loss: 5.708216049873328

Epoch: 5| Step: 6
Training loss: 5.854894119986287
Validation loss: 5.693591074908574

Epoch: 5| Step: 7
Training loss: 5.564081203018973
Validation loss: 5.677890994318725

Epoch: 5| Step: 8
Training loss: 5.465576122800411
Validation loss: 5.661391632661938

Epoch: 5| Step: 9
Training loss: 4.8074341901300786
Validation loss: 5.643603452090487

Epoch: 5| Step: 10
Training loss: 6.292593813997451
Validation loss: 5.624964625749826

Epoch: 3| Step: 0
Training loss: 5.474042674635936
Validation loss: 5.603089359826825

Epoch: 5| Step: 1
Training loss: 4.705316685590284
Validation loss: 5.580932888480885

Epoch: 5| Step: 2
Training loss: 5.7471522037761575
Validation loss: 5.558155156226499

Epoch: 5| Step: 3
Training loss: 4.971947942422878
Validation loss: 5.5333213035570346

Epoch: 5| Step: 4
Training loss: 5.751469300003845
Validation loss: 5.50632435745633

Epoch: 5| Step: 5
Training loss: 6.6720699665965855
Validation loss: 5.478581711451284

Epoch: 5| Step: 6
Training loss: 5.120080214706533
Validation loss: 5.4498616618248

Epoch: 5| Step: 7
Training loss: 5.741576617696986
Validation loss: 5.420463185046567

Epoch: 5| Step: 8
Training loss: 5.497419272016985
Validation loss: 5.3903244174916765

Epoch: 5| Step: 9
Training loss: 5.191868792294012
Validation loss: 5.359961845991911

Epoch: 5| Step: 10
Training loss: 5.569587392814327
Validation loss: 5.328600630730033

Epoch: 4| Step: 0
Training loss: 5.373056814558236
Validation loss: 5.298227079354463

Epoch: 5| Step: 1
Training loss: 5.004837366409521
Validation loss: 5.269235117278648

Epoch: 5| Step: 2
Training loss: 4.474749186216029
Validation loss: 5.239210725630873

Epoch: 5| Step: 3
Training loss: 5.88014742400455
Validation loss: 5.210488671399722

Epoch: 5| Step: 4
Training loss: 4.967566199204742
Validation loss: 5.183986267984945

Epoch: 5| Step: 5
Training loss: 5.297383061802006
Validation loss: 5.156890266568632

Epoch: 5| Step: 6
Training loss: 5.247388280921467
Validation loss: 5.132532626284804

Epoch: 5| Step: 7
Training loss: 5.663716988384193
Validation loss: 5.109514320663959

Epoch: 5| Step: 8
Training loss: 4.743201560582422
Validation loss: 5.088531913634201

Epoch: 5| Step: 9
Training loss: 5.063264953841331
Validation loss: 5.070491131648816

Epoch: 5| Step: 10
Training loss: 5.63485871077791
Validation loss: 5.053000302493846

Epoch: 5| Step: 0
Training loss: 5.410709900878971
Validation loss: 5.03809758307582

Epoch: 5| Step: 1
Training loss: 4.76726406239732
Validation loss: 5.022846673848239

Epoch: 5| Step: 2
Training loss: 4.743204576501104
Validation loss: 5.007070562729925

Epoch: 5| Step: 3
Training loss: 5.532037194050436
Validation loss: 4.993009787726125

Epoch: 5| Step: 4
Training loss: 5.417966813772635
Validation loss: 4.977077105230964

Epoch: 5| Step: 5
Training loss: 5.145375569892739
Validation loss: 4.962886705326105

Epoch: 5| Step: 6
Training loss: 4.611687962453348
Validation loss: 4.951186816170379

Epoch: 5| Step: 7
Training loss: 4.919162741652021
Validation loss: 4.937812218971944

Epoch: 5| Step: 8
Training loss: 5.605138342287516
Validation loss: 4.925866539117471

Epoch: 5| Step: 9
Training loss: 4.4284754580105945
Validation loss: 4.913373539170823

Epoch: 5| Step: 10
Training loss: 4.659760860479373
Validation loss: 4.900490710993291

Epoch: 6| Step: 0
Training loss: 5.132209359183834
Validation loss: 4.883970895437591

Epoch: 5| Step: 1
Training loss: 3.5132301141920825
Validation loss: 4.869500631423219

Epoch: 5| Step: 2
Training loss: 5.394763541002523
Validation loss: 4.853333338784028

Epoch: 5| Step: 3
Training loss: 4.137734840389727
Validation loss: 4.83946116802159

Epoch: 5| Step: 4
Training loss: 5.848400529830718
Validation loss: 4.825708488821014

Epoch: 5| Step: 5
Training loss: 5.599395460467592
Validation loss: 4.808495879925612

Epoch: 5| Step: 6
Training loss: 5.0299584288803665
Validation loss: 4.792920574608664

Epoch: 5| Step: 7
Training loss: 4.201977427781933
Validation loss: 4.774530856079593

Epoch: 5| Step: 8
Training loss: 5.3891873861449096
Validation loss: 4.7577273817221215

Epoch: 5| Step: 9
Training loss: 4.3836682142161605
Validation loss: 4.738523291666847

Epoch: 5| Step: 10
Training loss: 4.584671287609362
Validation loss: 4.716207370001105

Epoch: 7| Step: 0
Training loss: 4.49655973536829
Validation loss: 4.6957359104627345

Epoch: 5| Step: 1
Training loss: 5.051550432657447
Validation loss: 4.66776304213506

Epoch: 5| Step: 2
Training loss: 5.183372602078923
Validation loss: 4.642576574416701

Epoch: 5| Step: 3
Training loss: 4.820107924016839
Validation loss: 4.6158096075605215

Epoch: 5| Step: 4
Training loss: 4.052413390903189
Validation loss: 4.591536512589138

Epoch: 5| Step: 5
Training loss: 5.449908075519826
Validation loss: 4.571075687049611

Epoch: 5| Step: 6
Training loss: 4.650602051512075
Validation loss: 4.545426292163825

Epoch: 5| Step: 7
Training loss: 4.126204806002026
Validation loss: 4.528211202250826

Epoch: 5| Step: 8
Training loss: 4.496703105766616
Validation loss: 4.507867145930437

Epoch: 5| Step: 9
Training loss: 3.495587701242124
Validation loss: 4.493296197627201

Epoch: 5| Step: 10
Training loss: 5.372745484663195
Validation loss: 4.477935023388106

Epoch: 8| Step: 0
Training loss: 5.887376127134525
Validation loss: 4.4578865206120355

Epoch: 5| Step: 1
Training loss: 3.5381504930023557
Validation loss: 4.441265950216597

Epoch: 5| Step: 2
Training loss: 4.034336771292662
Validation loss: 4.425201487810362

Epoch: 5| Step: 3
Training loss: 5.16309674303177
Validation loss: 4.407736071586214

Epoch: 5| Step: 4
Training loss: 3.43596184736215
Validation loss: 4.3901617338349235

Epoch: 5| Step: 5
Training loss: 4.784800688320583
Validation loss: 4.374595839060523

Epoch: 5| Step: 6
Training loss: 4.655622811288123
Validation loss: 4.361269209389485

Epoch: 5| Step: 7
Training loss: 4.009212851571863
Validation loss: 4.3459993730763395

Epoch: 5| Step: 8
Training loss: 3.7178444921959626
Validation loss: 4.332895279664956

Epoch: 5| Step: 9
Training loss: 4.894587754686811
Validation loss: 4.317481788690758

Epoch: 5| Step: 10
Training loss: 4.701437409734535
Validation loss: 4.302492435669351

Epoch: 9| Step: 0
Training loss: 4.956611441172262
Validation loss: 4.288590099148878

Epoch: 5| Step: 1
Training loss: 5.0515128636185525
Validation loss: 4.276329171253324

Epoch: 5| Step: 2
Training loss: 3.731144868784962
Validation loss: 4.261811111120237

Epoch: 5| Step: 3
Training loss: 4.91147252954216
Validation loss: 4.2490727898893095

Epoch: 5| Step: 4
Training loss: 4.289683257105245
Validation loss: 4.2396899471930265

Epoch: 5| Step: 5
Training loss: 4.422400561261176
Validation loss: 4.225840167697246

Epoch: 5| Step: 6
Training loss: 4.356564070163151
Validation loss: 4.212441154490834

Epoch: 5| Step: 7
Training loss: 3.417202760150397
Validation loss: 4.203230034685006

Epoch: 5| Step: 8
Training loss: 4.679356125449237
Validation loss: 4.188080481877502

Epoch: 5| Step: 9
Training loss: 4.323224870962892
Validation loss: 4.174085372481602

Epoch: 5| Step: 10
Training loss: 3.278393328424296
Validation loss: 4.163179458444817

Epoch: 10| Step: 0
Training loss: 4.483469801932846
Validation loss: 4.149690840752791

Epoch: 5| Step: 1
Training loss: 4.211808434835095
Validation loss: 4.1348714388735806

Epoch: 5| Step: 2
Training loss: 4.281589244015331
Validation loss: 4.12160514081196

Epoch: 5| Step: 3
Training loss: 4.556322906706216
Validation loss: 4.118460556989871

Epoch: 5| Step: 4
Training loss: 4.407501043102122
Validation loss: 4.102509071361215

Epoch: 5| Step: 5
Training loss: 4.64065027711708
Validation loss: 4.094796025872361

Epoch: 5| Step: 6
Training loss: 4.422542238610608
Validation loss: 4.094743653291034

Epoch: 5| Step: 7
Training loss: 3.7010789844461423
Validation loss: 4.073381615458939

Epoch: 5| Step: 8
Training loss: 3.203471839548808
Validation loss: 4.058448713824161

Epoch: 5| Step: 9
Training loss: 4.018231803743194
Validation loss: 4.046829841030176

Epoch: 5| Step: 10
Training loss: 4.505784026244723
Validation loss: 4.034990456941854

Epoch: 11| Step: 0
Training loss: 4.294878575625872
Validation loss: 4.026281888692583

Epoch: 5| Step: 1
Training loss: 3.211656030605292
Validation loss: 4.010540821128389

Epoch: 5| Step: 2
Training loss: 4.192018263362092
Validation loss: 4.002226831364422

Epoch: 5| Step: 3
Training loss: 4.201377079774568
Validation loss: 3.9925217158768835

Epoch: 5| Step: 4
Training loss: 4.021517575142217
Validation loss: 3.9849604518123654

Epoch: 5| Step: 5
Training loss: 4.039313007901921
Validation loss: 3.976114989402177

Epoch: 5| Step: 6
Training loss: 3.1737076299242277
Validation loss: 3.968244258614814

Epoch: 5| Step: 7
Training loss: 4.940250451538442
Validation loss: 3.956477718062225

Epoch: 5| Step: 8
Training loss: 4.678038343137876
Validation loss: 3.9478008099472466

Epoch: 5| Step: 9
Training loss: 4.292499547835044
Validation loss: 3.937825033429207

Epoch: 5| Step: 10
Training loss: 4.005295585935311
Validation loss: 3.9281083529118437

Epoch: 12| Step: 0
Training loss: 5.104549077039737
Validation loss: 3.9227031295425268

Epoch: 5| Step: 1
Training loss: 3.793678350887523
Validation loss: 3.90803479051161

Epoch: 5| Step: 2
Training loss: 4.606198008022596
Validation loss: 3.9032643527381343

Epoch: 5| Step: 3
Training loss: 4.514200058343454
Validation loss: 3.8887379611642316

Epoch: 5| Step: 4
Training loss: 3.28079496589094
Validation loss: 3.878828408889737

Epoch: 5| Step: 5
Training loss: 4.065707774276276
Validation loss: 3.868738693683846

Epoch: 5| Step: 6
Training loss: 3.395065704518911
Validation loss: 3.860716075071206

Epoch: 5| Step: 7
Training loss: 3.3746243020509223
Validation loss: 3.8504981055537373

Epoch: 5| Step: 8
Training loss: 4.444145277338912
Validation loss: 3.8410238594167834

Epoch: 5| Step: 9
Training loss: 3.6827260812841494
Validation loss: 3.8276438996946167

Epoch: 5| Step: 10
Training loss: 3.6460517745200036
Validation loss: 3.816524133538772

Epoch: 13| Step: 0
Training loss: 3.4809349424293026
Validation loss: 3.802692412529734

Epoch: 5| Step: 1
Training loss: 4.11154894745453
Validation loss: 3.794054578730508

Epoch: 5| Step: 2
Training loss: 4.696723916269115
Validation loss: 3.7834645431278813

Epoch: 5| Step: 3
Training loss: 4.055707917044079
Validation loss: 3.7861300674819516

Epoch: 5| Step: 4
Training loss: 3.5302384539673968
Validation loss: 3.768316172656021

Epoch: 5| Step: 5
Training loss: 3.6641565892353745
Validation loss: 3.768391063667936

Epoch: 5| Step: 6
Training loss: 3.0924712341500302
Validation loss: 3.7631018148074586

Epoch: 5| Step: 7
Training loss: 3.9817278277326573
Validation loss: 3.7547257907151095

Epoch: 5| Step: 8
Training loss: 3.7467366324257743
Validation loss: 3.7561398766280854

Epoch: 5| Step: 9
Training loss: 4.6499779977585565
Validation loss: 3.746752304064343

Epoch: 5| Step: 10
Training loss: 4.151239343369339
Validation loss: 3.739838012574926

Epoch: 14| Step: 0
Training loss: 2.9562269601065214
Validation loss: 3.7340884955824625

Epoch: 5| Step: 1
Training loss: 4.315924570126259
Validation loss: 3.7273172020342065

Epoch: 5| Step: 2
Training loss: 3.941277281633173
Validation loss: 3.7263205130166006

Epoch: 5| Step: 3
Training loss: 4.650230254348384
Validation loss: 3.720685662424096

Epoch: 5| Step: 4
Training loss: 3.795137235348919
Validation loss: 3.715854418139918

Epoch: 5| Step: 5
Training loss: 3.4895594050407843
Validation loss: 3.7081507607554456

Epoch: 5| Step: 6
Training loss: 3.3454120818937483
Validation loss: 3.7053742423589706

Epoch: 5| Step: 7
Training loss: 4.262924065848057
Validation loss: 3.7002100020491375

Epoch: 5| Step: 8
Training loss: 4.198886932747657
Validation loss: 3.695547298001489

Epoch: 5| Step: 9
Training loss: 3.3281238537996853
Validation loss: 3.690181148869273

Epoch: 5| Step: 10
Training loss: 4.27982211839608
Validation loss: 3.6886535809001977

Epoch: 15| Step: 0
Training loss: 4.596688297507605
Validation loss: 3.6805945258858106

Epoch: 5| Step: 1
Training loss: 3.8813024151836393
Validation loss: 3.675743091408683

Epoch: 5| Step: 2
Training loss: 3.975323617105628
Validation loss: 3.677437229667158

Epoch: 5| Step: 3
Training loss: 4.188423396542672
Validation loss: 3.6896992738875354

Epoch: 5| Step: 4
Training loss: 3.196136890568737
Validation loss: 3.666799354576199

Epoch: 5| Step: 5
Training loss: 2.8596309693211612
Validation loss: 3.6583122759793776

Epoch: 5| Step: 6
Training loss: 3.5038945464722326
Validation loss: 3.6600482761156323

Epoch: 5| Step: 7
Training loss: 4.635644571366642
Validation loss: 3.6553927428814097

Epoch: 5| Step: 8
Training loss: 3.8686700618539898
Validation loss: 3.6522112804967946

Epoch: 5| Step: 9
Training loss: 3.7488543985806935
Validation loss: 3.650140239433663

Epoch: 5| Step: 10
Training loss: 3.5112912742114566
Validation loss: 3.643511896517623

Epoch: 16| Step: 0
Training loss: 4.11557270500541
Validation loss: 3.6389970036666983

Epoch: 5| Step: 1
Training loss: 3.9793680482938165
Validation loss: 3.6372039662619735

Epoch: 5| Step: 2
Training loss: 4.1364151192127885
Validation loss: 3.632326660413041

Epoch: 5| Step: 3
Training loss: 3.7335448040560655
Validation loss: 3.6286572983889096

Epoch: 5| Step: 4
Training loss: 3.0921915155493602
Validation loss: 3.6238421131540064

Epoch: 5| Step: 5
Training loss: 3.3984612124262537
Validation loss: 3.6218250105896725

Epoch: 5| Step: 6
Training loss: 3.513146641625072
Validation loss: 3.6201549523312577

Epoch: 5| Step: 7
Training loss: 3.899872968512209
Validation loss: 3.6135749773335886

Epoch: 5| Step: 8
Training loss: 3.6479431732335965
Validation loss: 3.604651474993264

Epoch: 5| Step: 9
Training loss: 4.464957595401702
Validation loss: 3.6020371728401406

Epoch: 5| Step: 10
Training loss: 3.8050850223862134
Validation loss: 3.5987854366028613

Epoch: 17| Step: 0
Training loss: 3.2185042204118797
Validation loss: 3.5921836703243035

Epoch: 5| Step: 1
Training loss: 3.3989773727072357
Validation loss: 3.5908056723572295

Epoch: 5| Step: 2
Training loss: 4.232596048345705
Validation loss: 3.590578093493186

Epoch: 5| Step: 3
Training loss: 4.157402624479767
Validation loss: 3.5882877350679045

Epoch: 5| Step: 4
Training loss: 3.197552257406089
Validation loss: 3.5796577870082342

Epoch: 5| Step: 5
Training loss: 3.5068140456797194
Validation loss: 3.5792755198835513

Epoch: 5| Step: 6
Training loss: 4.039926344322841
Validation loss: 3.577438108725589

Epoch: 5| Step: 7
Training loss: 3.821362060660731
Validation loss: 3.578441469210107

Epoch: 5| Step: 8
Training loss: 3.996275121128424
Validation loss: 3.5682839196604887

Epoch: 5| Step: 9
Training loss: 4.246935019725117
Validation loss: 3.5641459728627467

Epoch: 5| Step: 10
Training loss: 3.513490020134116
Validation loss: 3.5638818354671598

Epoch: 18| Step: 0
Training loss: 3.6655461737831416
Validation loss: 3.5630272383576194

Epoch: 5| Step: 1
Training loss: 4.015140726893978
Validation loss: 3.5573176520836585

Epoch: 5| Step: 2
Training loss: 4.141581874621621
Validation loss: 3.554612458347605

Epoch: 5| Step: 3
Training loss: 3.7964341649466826
Validation loss: 3.5531289206066052

Epoch: 5| Step: 4
Training loss: 3.6738455172202618
Validation loss: 3.548073536525801

Epoch: 5| Step: 5
Training loss: 2.9372013021340253
Validation loss: 3.5531531807897783

Epoch: 5| Step: 6
Training loss: 3.727451178514349
Validation loss: 3.5496642414829553

Epoch: 5| Step: 7
Training loss: 3.405558804719117
Validation loss: 3.5447838159553373

Epoch: 5| Step: 8
Training loss: 3.3576442784648894
Validation loss: 3.5394981684939912

Epoch: 5| Step: 9
Training loss: 3.9139046094651038
Validation loss: 3.5375174310030744

Epoch: 5| Step: 10
Training loss: 4.585014289326174
Validation loss: 3.539325001995139

Epoch: 19| Step: 0
Training loss: 3.8782819570152904
Validation loss: 3.5369009513930645

Epoch: 5| Step: 1
Training loss: 3.3948571297833174
Validation loss: 3.5382325540445247

Epoch: 5| Step: 2
Training loss: 3.6558015988562884
Validation loss: 3.5353554743331888

Epoch: 5| Step: 3
Training loss: 3.9785071154256686
Validation loss: 3.533114528459559

Epoch: 5| Step: 4
Training loss: 3.982349314643653
Validation loss: 3.5275267119066456

Epoch: 5| Step: 5
Training loss: 3.948225641699501
Validation loss: 3.5243055349723416

Epoch: 5| Step: 6
Training loss: 3.878682386501747
Validation loss: 3.5230612965415395

Epoch: 5| Step: 7
Training loss: 3.0583628522260837
Validation loss: 3.522524175315624

Epoch: 5| Step: 8
Training loss: 2.7935273152127658
Validation loss: 3.522583397603123

Epoch: 5| Step: 9
Training loss: 4.318837250243611
Validation loss: 3.5190418829130294

Epoch: 5| Step: 10
Training loss: 3.95980138492534
Validation loss: 3.5164307204934144

Epoch: 20| Step: 0
Training loss: 3.909634885985062
Validation loss: 3.514709284122591

Epoch: 5| Step: 1
Training loss: 4.040445175948887
Validation loss: 3.515612442923923

Epoch: 5| Step: 2
Training loss: 3.0398765591605987
Validation loss: 3.512635237457617

Epoch: 5| Step: 3
Training loss: 4.147127853538368
Validation loss: 3.5130140724002437

Epoch: 5| Step: 4
Training loss: 4.172275023980613
Validation loss: 3.511081754633462

Epoch: 5| Step: 5
Training loss: 2.7229044950213677
Validation loss: 3.5109530460539897

Epoch: 5| Step: 6
Training loss: 3.964362655541044
Validation loss: 3.508740121369916

Epoch: 5| Step: 7
Training loss: 3.9895225633154556
Validation loss: 3.5065029179193528

Epoch: 5| Step: 8
Training loss: 3.4948848403054815
Validation loss: 3.5074495853676497

Epoch: 5| Step: 9
Training loss: 3.3082739305007616
Validation loss: 3.5058160133912595

Epoch: 5| Step: 10
Training loss: 3.8736738581404504
Validation loss: 3.503819049145178

Epoch: 21| Step: 0
Training loss: 3.339628156875596
Validation loss: 3.5068488505833657

Epoch: 5| Step: 1
Training loss: 3.460101506723266
Validation loss: 3.50348974102293

Epoch: 5| Step: 2
Training loss: 4.102506169344153
Validation loss: 3.5033881112240928

Epoch: 5| Step: 3
Training loss: 3.839798299339987
Validation loss: 3.501584643591153

Epoch: 5| Step: 4
Training loss: 3.0507903153874594
Validation loss: 3.497587440426978

Epoch: 5| Step: 5
Training loss: 3.3580055461790033
Validation loss: 3.498006371545161

Epoch: 5| Step: 6
Training loss: 3.8640697511573316
Validation loss: 3.4997051762343117

Epoch: 5| Step: 7
Training loss: 3.353410118189597
Validation loss: 3.5016440355274048

Epoch: 5| Step: 8
Training loss: 4.0307879515821865
Validation loss: 3.4986836262271757

Epoch: 5| Step: 9
Training loss: 3.917444895811395
Validation loss: 3.497372578626437

Epoch: 5| Step: 10
Training loss: 4.42454378179287
Validation loss: 3.4930044762342938

Epoch: 22| Step: 0
Training loss: 4.054364318316099
Validation loss: 3.492219580345399

Epoch: 5| Step: 1
Training loss: 3.368245040614695
Validation loss: 3.4952721547957153

Epoch: 5| Step: 2
Training loss: 3.3445755839556073
Validation loss: 3.49535697689302

Epoch: 5| Step: 3
Training loss: 3.699739220166904
Validation loss: 3.49192414960064

Epoch: 5| Step: 4
Training loss: 3.5862515712985896
Validation loss: 3.4914184069915

Epoch: 5| Step: 5
Training loss: 3.9243333870032795
Validation loss: 3.489251173529748

Epoch: 5| Step: 6
Training loss: 3.217501648233343
Validation loss: 3.488685880159453

Epoch: 5| Step: 7
Training loss: 4.29880283457463
Validation loss: 3.4857054986754363

Epoch: 5| Step: 8
Training loss: 3.1597877542223305
Validation loss: 3.487919625385934

Epoch: 5| Step: 9
Training loss: 4.384546599833145
Validation loss: 3.486277727292653

Epoch: 5| Step: 10
Training loss: 3.4371348794016243
Validation loss: 3.487819483838415

Epoch: 23| Step: 0
Training loss: 2.8320812562934234
Validation loss: 3.48545676843699

Epoch: 5| Step: 1
Training loss: 4.1237950732637545
Validation loss: 3.4901154397882372

Epoch: 5| Step: 2
Training loss: 4.3023755187535775
Validation loss: 3.4921828839297087

Epoch: 5| Step: 3
Training loss: 3.0168647391976755
Validation loss: 3.481615781508865

Epoch: 5| Step: 4
Training loss: 3.854289546073084
Validation loss: 3.4821628055979987

Epoch: 5| Step: 5
Training loss: 3.5803586160067638
Validation loss: 3.4837028171058346

Epoch: 5| Step: 6
Training loss: 3.5064944911311366
Validation loss: 3.4878893400816007

Epoch: 5| Step: 7
Training loss: 3.1019200808315825
Validation loss: 3.4883825071105776

Epoch: 5| Step: 8
Training loss: 4.103454037421577
Validation loss: 3.4881639966492837

Epoch: 5| Step: 9
Training loss: 3.080706757791537
Validation loss: 3.4879743152576634

Epoch: 5| Step: 10
Training loss: 4.8789338110335425
Validation loss: 3.483341191145515

Epoch: 24| Step: 0
Training loss: 4.619327468803017
Validation loss: 3.4826105094878304

Epoch: 5| Step: 1
Training loss: 3.881361753663935
Validation loss: 3.480101797870741

Epoch: 5| Step: 2
Training loss: 3.710172875584591
Validation loss: 3.478915134646651

Epoch: 5| Step: 3
Training loss: 3.5501907243671185
Validation loss: 3.4776359336100833

Epoch: 5| Step: 4
Training loss: 3.420045964785432
Validation loss: 3.4786629938873377

Epoch: 5| Step: 5
Training loss: 2.5831698909452006
Validation loss: 3.4778774988214556

Epoch: 5| Step: 6
Training loss: 3.8532996912304927
Validation loss: 3.475172335704839

Epoch: 5| Step: 7
Training loss: 3.864425258368267
Validation loss: 3.4762516544123927

Epoch: 5| Step: 8
Training loss: 3.1785466727430105
Validation loss: 3.4746892100312827

Epoch: 5| Step: 9
Training loss: 3.661842177752289
Validation loss: 3.4722846359604764

Epoch: 5| Step: 10
Training loss: 4.025437296930429
Validation loss: 3.472067855411574

Epoch: 25| Step: 0
Training loss: 4.531960056839326
Validation loss: 3.4716767529227615

Epoch: 5| Step: 1
Training loss: 3.8650809050823285
Validation loss: 3.4694963203116056

Epoch: 5| Step: 2
Training loss: 3.80245273136853
Validation loss: 3.469342026855833

Epoch: 5| Step: 3
Training loss: 4.132455503913054
Validation loss: 3.4695304458981178

Epoch: 5| Step: 4
Training loss: 2.9131717087398146
Validation loss: 3.4682352973293655

Epoch: 5| Step: 5
Training loss: 2.3689889631292034
Validation loss: 3.4673929143766657

Epoch: 5| Step: 6
Training loss: 3.704952255950415
Validation loss: 3.4670197098468045

Epoch: 5| Step: 7
Training loss: 3.6169980619518687
Validation loss: 3.4680334842411527

Epoch: 5| Step: 8
Training loss: 3.9765421149250337
Validation loss: 3.4676288454655904

Epoch: 5| Step: 9
Training loss: 3.7799628723178054
Validation loss: 3.4673189793840673

Epoch: 5| Step: 10
Training loss: 3.348341027177092
Validation loss: 3.4667325895855186

Epoch: 26| Step: 0
Training loss: 3.870072338798299
Validation loss: 3.4637220519682352

Epoch: 5| Step: 1
Training loss: 3.4323436557535154
Validation loss: 3.46342934219612

Epoch: 5| Step: 2
Training loss: 4.113411780855624
Validation loss: 3.463098756220086

Epoch: 5| Step: 3
Training loss: 4.5049326670840415
Validation loss: 3.462929060622224

Epoch: 5| Step: 4
Training loss: 3.606048768774255
Validation loss: 3.461050943324508

Epoch: 5| Step: 5
Training loss: 3.633539073846857
Validation loss: 3.4619599319159864

Epoch: 5| Step: 6
Training loss: 3.4956572702392554
Validation loss: 3.4600213854850392

Epoch: 5| Step: 7
Training loss: 3.4096182871868295
Validation loss: 3.4581829670432143

Epoch: 5| Step: 8
Training loss: 3.4806261637119422
Validation loss: 3.4584428246298464

Epoch: 5| Step: 9
Training loss: 3.5982004224205224
Validation loss: 3.4581731837513394

Epoch: 5| Step: 10
Training loss: 3.0706543089098552
Validation loss: 3.45770445105849

Epoch: 27| Step: 0
Training loss: 3.4474306407477022
Validation loss: 3.4561516341364014

Epoch: 5| Step: 1
Training loss: 3.489619529118871
Validation loss: 3.4558703704217195

Epoch: 5| Step: 2
Training loss: 3.36536827418793
Validation loss: 3.4573104705777213

Epoch: 5| Step: 3
Training loss: 3.84311875533116
Validation loss: 3.4548879264166996

Epoch: 5| Step: 4
Training loss: 3.77926533215196
Validation loss: 3.4566273361479287

Epoch: 5| Step: 5
Training loss: 3.4325513418293445
Validation loss: 3.4550069509017547

Epoch: 5| Step: 6
Training loss: 3.6646575769852188
Validation loss: 3.455116631206877

Epoch: 5| Step: 7
Training loss: 3.6804881267648892
Validation loss: 3.4520600584352805

Epoch: 5| Step: 8
Training loss: 4.226144822895557
Validation loss: 3.453526968819014

Epoch: 5| Step: 9
Training loss: 3.8486403702586918
Validation loss: 3.4534321933557366

Epoch: 5| Step: 10
Training loss: 3.5594922134350684
Validation loss: 3.4523567232600896

Epoch: 28| Step: 0
Training loss: 3.75584134689186
Validation loss: 3.4537248180980678

Epoch: 5| Step: 1
Training loss: 3.3391563734354945
Validation loss: 3.452851725232912

Epoch: 5| Step: 2
Training loss: 3.728328134609572
Validation loss: 3.4517206578766584

Epoch: 5| Step: 3
Training loss: 4.212853952813267
Validation loss: 3.450645244241594

Epoch: 5| Step: 4
Training loss: 4.279051501622765
Validation loss: 3.450214636000738

Epoch: 5| Step: 5
Training loss: 4.145498265411563
Validation loss: 3.4506186036065056

Epoch: 5| Step: 6
Training loss: 3.3601587135431856
Validation loss: 3.4504122130683226

Epoch: 5| Step: 7
Training loss: 3.2460358725849594
Validation loss: 3.449714496528618

Epoch: 5| Step: 8
Training loss: 2.903262664191795
Validation loss: 3.447459455114853

Epoch: 5| Step: 9
Training loss: 3.849853879459385
Validation loss: 3.447331647715067

Epoch: 5| Step: 10
Training loss: 3.2303308828841417
Validation loss: 3.4467241895451854

Epoch: 29| Step: 0
Training loss: 2.99989270972087
Validation loss: 3.4461623915382025

Epoch: 5| Step: 1
Training loss: 4.378901240867451
Validation loss: 3.445371186291848

Epoch: 5| Step: 2
Training loss: 2.9205087333539477
Validation loss: 3.4458875989300797

Epoch: 5| Step: 3
Training loss: 3.2670362425662955
Validation loss: 3.444971404738688

Epoch: 5| Step: 4
Training loss: 4.14784480744288
Validation loss: 3.443874563279534

Epoch: 5| Step: 5
Training loss: 3.534126393068394
Validation loss: 3.44316578761423

Epoch: 5| Step: 6
Training loss: 3.6360481537168154
Validation loss: 3.443376443761386

Epoch: 5| Step: 7
Training loss: 3.8792386407181274
Validation loss: 3.4418282712822426

Epoch: 5| Step: 8
Training loss: 3.775972324480048
Validation loss: 3.441462641484181

Epoch: 5| Step: 9
Training loss: 3.842508999597438
Validation loss: 3.4406713531865685

Epoch: 5| Step: 10
Training loss: 3.677778198175576
Validation loss: 3.4403710957547893

Epoch: 30| Step: 0
Training loss: 3.865501329051944
Validation loss: 3.439462219905655

Epoch: 5| Step: 1
Training loss: 4.2646836580080425
Validation loss: 3.4389214896265403

Epoch: 5| Step: 2
Training loss: 3.4783136993521837
Validation loss: 3.4387310400463202

Epoch: 5| Step: 3
Training loss: 3.0594632409747917
Validation loss: 3.4372041024899844

Epoch: 5| Step: 4
Training loss: 3.306148846238089
Validation loss: 3.4363608075148773

Epoch: 5| Step: 5
Training loss: 3.4857790730997227
Validation loss: 3.4342919169660107

Epoch: 5| Step: 6
Training loss: 3.5437346012379694
Validation loss: 3.4332718516825547

Epoch: 5| Step: 7
Training loss: 4.530362588211242
Validation loss: 3.433583758518364

Epoch: 5| Step: 8
Training loss: 3.0584724567863772
Validation loss: 3.4287970121719553

Epoch: 5| Step: 9
Training loss: 3.6680411594706515
Validation loss: 3.4287287341638653

Epoch: 5| Step: 10
Training loss: 3.7189836188271244
Validation loss: 3.4235005473642603

Epoch: 31| Step: 0
Training loss: 3.3346256294191265
Validation loss: 3.414701983900738

Epoch: 5| Step: 1
Training loss: 4.18671034014655
Validation loss: 3.415911290614451

Epoch: 5| Step: 2
Training loss: 3.305930190312217
Validation loss: 3.4173340026908234

Epoch: 5| Step: 3
Training loss: 4.3117792384125675
Validation loss: 3.4112303684508594

Epoch: 5| Step: 4
Training loss: 3.7462016896597246
Validation loss: 3.408079657125394

Epoch: 5| Step: 5
Training loss: 3.993325744923136
Validation loss: 3.407277757782275

Epoch: 5| Step: 6
Training loss: 3.6262408796404153
Validation loss: 3.4071166317220944

Epoch: 5| Step: 7
Training loss: 3.3641174907238365
Validation loss: 3.4067570456750125

Epoch: 5| Step: 8
Training loss: 3.462260318544332
Validation loss: 3.4012004705482046

Epoch: 5| Step: 9
Training loss: 3.1145820915364286
Validation loss: 3.401466425392444

Epoch: 5| Step: 10
Training loss: 3.310230701393447
Validation loss: 3.403832679609525

Epoch: 32| Step: 0
Training loss: 3.348983661719968
Validation loss: 3.4015109981427987

Epoch: 5| Step: 1
Training loss: 4.193551772047622
Validation loss: 3.402047610022657

Epoch: 5| Step: 2
Training loss: 2.750863373214981
Validation loss: 3.3970300989081275

Epoch: 5| Step: 3
Training loss: 3.16542728330067
Validation loss: 3.3959348884725826

Epoch: 5| Step: 4
Training loss: 3.511324681118986
Validation loss: 3.401034707250706

Epoch: 5| Step: 5
Training loss: 3.8185826541176406
Validation loss: 3.3975533264626177

Epoch: 5| Step: 6
Training loss: 4.208986640805654
Validation loss: 3.392028522641733

Epoch: 5| Step: 7
Training loss: 3.3531140557472257
Validation loss: 3.391838693127441

Epoch: 5| Step: 8
Training loss: 3.380708176500628
Validation loss: 3.393528284628375

Epoch: 5| Step: 9
Training loss: 3.942508116274107
Validation loss: 3.3974076082156865

Epoch: 5| Step: 10
Training loss: 3.9957501961999737
Validation loss: 3.3913623500852843

Epoch: 33| Step: 0
Training loss: 2.6189401707757716
Validation loss: 3.3904674227455716

Epoch: 5| Step: 1
Training loss: 3.2562774774193817
Validation loss: 3.3889174153928137

Epoch: 5| Step: 2
Training loss: 3.405387279203689
Validation loss: 3.3893644642593204

Epoch: 5| Step: 3
Training loss: 2.929683593747396
Validation loss: 3.3928939269301113

Epoch: 5| Step: 4
Training loss: 4.256368689765699
Validation loss: 3.389378089624804

Epoch: 5| Step: 5
Training loss: 2.960483647089208
Validation loss: 3.390692891518217

Epoch: 5| Step: 6
Training loss: 3.6135736790449866
Validation loss: 3.389564759331341

Epoch: 5| Step: 7
Training loss: 3.9248687139045453
Validation loss: 3.386078263501162

Epoch: 5| Step: 8
Training loss: 4.053310388282616
Validation loss: 3.384094448568115

Epoch: 5| Step: 9
Training loss: 3.944081210633135
Validation loss: 3.387228142651388

Epoch: 5| Step: 10
Training loss: 4.508016651099119
Validation loss: 3.3866082731346046

Epoch: 34| Step: 0
Training loss: 3.449393210745749
Validation loss: 3.38256767451966

Epoch: 5| Step: 1
Training loss: 3.460354241334968
Validation loss: 3.380324022790946

Epoch: 5| Step: 2
Training loss: 4.378041763113439
Validation loss: 3.3782364774622833

Epoch: 5| Step: 3
Training loss: 3.671402531521423
Validation loss: 3.3802127119813012

Epoch: 5| Step: 4
Training loss: 3.589560280650382
Validation loss: 3.379982866252421

Epoch: 5| Step: 5
Training loss: 4.094820072007944
Validation loss: 3.3777047412861685

Epoch: 5| Step: 6
Training loss: 4.211914402134521
Validation loss: 3.3781368667828042

Epoch: 5| Step: 7
Training loss: 3.2099918355867656
Validation loss: 3.375051454723809

Epoch: 5| Step: 8
Training loss: 3.427231032755143
Validation loss: 3.3748142855223517

Epoch: 5| Step: 9
Training loss: 2.8771276479333414
Validation loss: 3.3748718428805033

Epoch: 5| Step: 10
Training loss: 2.9334370536962346
Validation loss: 3.3749930982925536

Epoch: 35| Step: 0
Training loss: 4.050667771282971
Validation loss: 3.3739249668087936

Epoch: 5| Step: 1
Training loss: 3.8103681763903654
Validation loss: 3.375899899433614

Epoch: 5| Step: 2
Training loss: 2.993037728012895
Validation loss: 3.3758911997962318

Epoch: 5| Step: 3
Training loss: 3.2870974798321613
Validation loss: 3.373564587716485

Epoch: 5| Step: 4
Training loss: 3.7816129147736177
Validation loss: 3.373208163168925

Epoch: 5| Step: 5
Training loss: 3.9705310339536894
Validation loss: 3.3710540710972685

Epoch: 5| Step: 6
Training loss: 2.815884312957253
Validation loss: 3.3725278270358534

Epoch: 5| Step: 7
Training loss: 2.9863271669594607
Validation loss: 3.369348670370146

Epoch: 5| Step: 8
Training loss: 4.431842905255694
Validation loss: 3.369347147105499

Epoch: 5| Step: 9
Training loss: 3.6652758445861533
Validation loss: 3.3699893224286623

Epoch: 5| Step: 10
Training loss: 3.4846805729325516
Validation loss: 3.3687328478135488

Epoch: 36| Step: 0
Training loss: 3.48287794856875
Validation loss: 3.369558955695032

Epoch: 5| Step: 1
Training loss: 3.3919786133271894
Validation loss: 3.3671129666352906

Epoch: 5| Step: 2
Training loss: 3.864978629542954
Validation loss: 3.3678642746090466

Epoch: 5| Step: 3
Training loss: 2.4617002243754094
Validation loss: 3.364255695600427

Epoch: 5| Step: 4
Training loss: 3.401918930002747
Validation loss: 3.3662508516977816

Epoch: 5| Step: 5
Training loss: 3.81473425763314
Validation loss: 3.3661894852318976

Epoch: 5| Step: 6
Training loss: 3.574008889629663
Validation loss: 3.365703471865105

Epoch: 5| Step: 7
Training loss: 3.525033796432484
Validation loss: 3.366322679306961

Epoch: 5| Step: 8
Training loss: 3.8198963398874257
Validation loss: 3.3659349507344754

Epoch: 5| Step: 9
Training loss: 3.8887596714410835
Validation loss: 3.3662528074127684

Epoch: 5| Step: 10
Training loss: 4.186992329811157
Validation loss: 3.363658230134939

Epoch: 37| Step: 0
Training loss: 3.4893254578612907
Validation loss: 3.3622775421009883

Epoch: 5| Step: 1
Training loss: 3.6480976738820456
Validation loss: 3.362624003477449

Epoch: 5| Step: 2
Training loss: 4.315651888974207
Validation loss: 3.361031222317076

Epoch: 5| Step: 3
Training loss: 3.4345835017606436
Validation loss: 3.3661558488847736

Epoch: 5| Step: 4
Training loss: 3.493029328676072
Validation loss: 3.3791187908779294

Epoch: 5| Step: 5
Training loss: 3.96668640313461
Validation loss: 3.387924686451818

Epoch: 5| Step: 6
Training loss: 3.5718813064265875
Validation loss: 3.360137559862643

Epoch: 5| Step: 7
Training loss: 3.505346846240921
Validation loss: 3.3648748235685964

Epoch: 5| Step: 8
Training loss: 2.920188539506004
Validation loss: 3.3669041222024254

Epoch: 5| Step: 9
Training loss: 3.242191912176968
Validation loss: 3.370972208309693

Epoch: 5| Step: 10
Training loss: 3.861707715993618
Validation loss: 3.3649046801037676

Epoch: 38| Step: 0
Training loss: 3.3513032684019746
Validation loss: 3.363744159357054

Epoch: 5| Step: 1
Training loss: 3.535160161643209
Validation loss: 3.3630794749366246

Epoch: 5| Step: 2
Training loss: 3.848287493825252
Validation loss: 3.3613090043872123

Epoch: 5| Step: 3
Training loss: 4.296024196663169
Validation loss: 3.360859732494908

Epoch: 5| Step: 4
Training loss: 3.8785069501174516
Validation loss: 3.3606139942885402

Epoch: 5| Step: 5
Training loss: 3.447122595740319
Validation loss: 3.3614516390973965

Epoch: 5| Step: 6
Training loss: 3.855605288235801
Validation loss: 3.3602694282972485

Epoch: 5| Step: 7
Training loss: 3.5161628820297657
Validation loss: 3.3583026629214134

Epoch: 5| Step: 8
Training loss: 3.133987624932099
Validation loss: 3.357983615488193

Epoch: 5| Step: 9
Training loss: 3.331757045612169
Validation loss: 3.3629881056594386

Epoch: 5| Step: 10
Training loss: 3.1424181928888815
Validation loss: 3.3594934631965554

Epoch: 39| Step: 0
Training loss: 3.471896694606569
Validation loss: 3.3574857794416118

Epoch: 5| Step: 1
Training loss: 3.759303822085361
Validation loss: 3.354954987598055

Epoch: 5| Step: 2
Training loss: 3.3284807328498442
Validation loss: 3.3544511490330047

Epoch: 5| Step: 3
Training loss: 3.1770761625281954
Validation loss: 3.3538834188489424

Epoch: 5| Step: 4
Training loss: 3.617892565302998
Validation loss: 3.353183612724642

Epoch: 5| Step: 5
Training loss: 3.8842040241449833
Validation loss: 3.35151078103747

Epoch: 5| Step: 6
Training loss: 4.396108440932557
Validation loss: 3.3519680669788063

Epoch: 5| Step: 7
Training loss: 3.339209780838757
Validation loss: 3.351900649252027

Epoch: 5| Step: 8
Training loss: 3.6042683463922573
Validation loss: 3.350643312729767

Epoch: 5| Step: 9
Training loss: 3.2586561981268187
Validation loss: 3.349390604875406

Epoch: 5| Step: 10
Training loss: 3.453855273326384
Validation loss: 3.3493155698426027

Epoch: 40| Step: 0
Training loss: 3.7536854753464826
Validation loss: 3.3490924112075993

Epoch: 5| Step: 1
Training loss: 3.8581439692013775
Validation loss: 3.347510167087248

Epoch: 5| Step: 2
Training loss: 3.173631604492739
Validation loss: 3.348492094719575

Epoch: 5| Step: 3
Training loss: 3.0013578838641837
Validation loss: 3.3475352986361

Epoch: 5| Step: 4
Training loss: 3.7192386338227648
Validation loss: 3.348135313478788

Epoch: 5| Step: 5
Training loss: 3.55387758523111
Validation loss: 3.3462267843486404

Epoch: 5| Step: 6
Training loss: 3.6878202913485003
Validation loss: 3.346513535595896

Epoch: 5| Step: 7
Training loss: 3.4477876176146287
Validation loss: 3.344917764308722

Epoch: 5| Step: 8
Training loss: 3.236113887088951
Validation loss: 3.346872761620701

Epoch: 5| Step: 9
Training loss: 4.480484500980379
Validation loss: 3.3446898712643933

Epoch: 5| Step: 10
Training loss: 3.2275217768542412
Validation loss: 3.34398592251849

Epoch: 41| Step: 0
Training loss: 3.6545973735263164
Validation loss: 3.3441795431269488

Epoch: 5| Step: 1
Training loss: 4.349249343120352
Validation loss: 3.3435767328887027

Epoch: 5| Step: 2
Training loss: 3.365569750545749
Validation loss: 3.343167887326348

Epoch: 5| Step: 3
Training loss: 3.3575113494294926
Validation loss: 3.341855376917064

Epoch: 5| Step: 4
Training loss: 3.0181858080475124
Validation loss: 3.3407738449381026

Epoch: 5| Step: 5
Training loss: 3.254830218925147
Validation loss: 3.3415778833975773

Epoch: 5| Step: 6
Training loss: 3.515083237336674
Validation loss: 3.340629203857667

Epoch: 5| Step: 7
Training loss: 3.5115437193501826
Validation loss: 3.3400848959825815

Epoch: 5| Step: 8
Training loss: 3.0766943690691186
Validation loss: 3.3398396525861296

Epoch: 5| Step: 9
Training loss: 3.8045033874456533
Validation loss: 3.339942178533336

Epoch: 5| Step: 10
Training loss: 4.3212582758437215
Validation loss: 3.3389309034589427

Epoch: 42| Step: 0
Training loss: 2.8381382833479543
Validation loss: 3.3381816319272635

Epoch: 5| Step: 1
Training loss: 3.387938810973695
Validation loss: 3.3376439161412885

Epoch: 5| Step: 2
Training loss: 3.1277664146721342
Validation loss: 3.3371069211138504

Epoch: 5| Step: 3
Training loss: 3.4869204405363727
Validation loss: 3.3376081133231255

Epoch: 5| Step: 4
Training loss: 4.141133288009168
Validation loss: 3.336738590335126

Epoch: 5| Step: 5
Training loss: 3.8572703194119806
Validation loss: 3.336889338042901

Epoch: 5| Step: 6
Training loss: 3.5999168227441407
Validation loss: 3.3362216515764156

Epoch: 5| Step: 7
Training loss: 4.37466058776892
Validation loss: 3.3351062110567273

Epoch: 5| Step: 8
Training loss: 3.7353673917148265
Validation loss: 3.3346266057875384

Epoch: 5| Step: 9
Training loss: 3.2530824275533723
Validation loss: 3.333569701079484

Epoch: 5| Step: 10
Training loss: 3.1834635889323604
Validation loss: 3.333861105165923

Epoch: 43| Step: 0
Training loss: 3.9760744286215868
Validation loss: 3.3336743662306647

Epoch: 5| Step: 1
Training loss: 3.2775659133486874
Validation loss: 3.3325163537374323

Epoch: 5| Step: 2
Training loss: 3.9251596746342066
Validation loss: 3.3330739340806375

Epoch: 5| Step: 3
Training loss: 3.340605924318125
Validation loss: 3.3325256066332867

Epoch: 5| Step: 4
Training loss: 4.062107008485704
Validation loss: 3.33115509654663

Epoch: 5| Step: 5
Training loss: 3.3609028025688916
Validation loss: 3.331707176791975

Epoch: 5| Step: 6
Training loss: 3.7712811929426153
Validation loss: 3.3309708157509657

Epoch: 5| Step: 7
Training loss: 3.7639812506635417
Validation loss: 3.32932671329038

Epoch: 5| Step: 8
Training loss: 3.0560371558841575
Validation loss: 3.3290159974027396

Epoch: 5| Step: 9
Training loss: 3.274973069873772
Validation loss: 3.3285418071354163

Epoch: 5| Step: 10
Training loss: 3.264143904514984
Validation loss: 3.3288182340565737

Epoch: 44| Step: 0
Training loss: 2.7075892282085436
Validation loss: 3.3292117376460917

Epoch: 5| Step: 1
Training loss: 3.3251253319545064
Validation loss: 3.3279882157678546

Epoch: 5| Step: 2
Training loss: 3.436333614482443
Validation loss: 3.3274449334328993

Epoch: 5| Step: 3
Training loss: 3.9805124746509777
Validation loss: 3.32624120923447

Epoch: 5| Step: 4
Training loss: 4.077541733463284
Validation loss: 3.32643798363273

Epoch: 5| Step: 5
Training loss: 3.861782049223276
Validation loss: 3.3257532438041033

Epoch: 5| Step: 6
Training loss: 3.9735105303054428
Validation loss: 3.327256612388869

Epoch: 5| Step: 7
Training loss: 3.2939605124445475
Validation loss: 3.325636080220723

Epoch: 5| Step: 8
Training loss: 3.0931603996947437
Validation loss: 3.3246191997330543

Epoch: 5| Step: 9
Training loss: 3.3725700107600476
Validation loss: 3.3241311203666237

Epoch: 5| Step: 10
Training loss: 3.90048842672825
Validation loss: 3.323896998649729

Epoch: 45| Step: 0
Training loss: 3.4941081455484584
Validation loss: 3.3231904443645437

Epoch: 5| Step: 1
Training loss: 4.167211318976031
Validation loss: 3.3234474472366884

Epoch: 5| Step: 2
Training loss: 3.3544674535114334
Validation loss: 3.3232413435581347

Epoch: 5| Step: 3
Training loss: 3.2267068825992515
Validation loss: 3.3223500220764057

Epoch: 5| Step: 4
Training loss: 3.570670145431469
Validation loss: 3.322213511688146

Epoch: 5| Step: 5
Training loss: 3.8014743404302633
Validation loss: 3.3202965852668482

Epoch: 5| Step: 6
Training loss: 3.5202213334809414
Validation loss: 3.3213516089896418

Epoch: 5| Step: 7
Training loss: 4.089020304595173
Validation loss: 3.3204486554077697

Epoch: 5| Step: 8
Training loss: 3.396288102167542
Validation loss: 3.3208758364294897

Epoch: 5| Step: 9
Training loss: 2.8171830924661343
Validation loss: 3.3214946683101174

Epoch: 5| Step: 10
Training loss: 3.562919591989403
Validation loss: 3.3192188308521584

Epoch: 46| Step: 0
Training loss: 2.9513027482769885
Validation loss: 3.319401832501911

Epoch: 5| Step: 1
Training loss: 3.884367050199591
Validation loss: 3.3172539163330894

Epoch: 5| Step: 2
Training loss: 3.564050838814288
Validation loss: 3.316873917453152

Epoch: 5| Step: 3
Training loss: 3.8074294594575377
Validation loss: 3.3172684978714404

Epoch: 5| Step: 4
Training loss: 3.2087840634757
Validation loss: 3.3164762815695052

Epoch: 5| Step: 5
Training loss: 3.9818514143593
Validation loss: 3.3164823171585365

Epoch: 5| Step: 6
Training loss: 3.379206261518486
Validation loss: 3.3154653029901686

Epoch: 5| Step: 7
Training loss: 3.823803389127586
Validation loss: 3.314963445755628

Epoch: 5| Step: 8
Training loss: 2.813837284478135
Validation loss: 3.31513772503203

Epoch: 5| Step: 9
Training loss: 3.6710427497654488
Validation loss: 3.312930481007552

Epoch: 5| Step: 10
Training loss: 3.894273265378522
Validation loss: 3.3149579510700584

Epoch: 47| Step: 0
Training loss: 3.891410533854423
Validation loss: 3.3134864766917373

Epoch: 5| Step: 1
Training loss: 3.646016463267142
Validation loss: 3.313304050505403

Epoch: 5| Step: 2
Training loss: 3.4591776418515634
Validation loss: 3.3135407852628824

Epoch: 5| Step: 3
Training loss: 3.939830877285695
Validation loss: 3.3119342403619894

Epoch: 5| Step: 4
Training loss: 2.8607437943238985
Validation loss: 3.3117602438057943

Epoch: 5| Step: 5
Training loss: 3.138872559166426
Validation loss: 3.3113361666072936

Epoch: 5| Step: 6
Training loss: 3.8506654387240506
Validation loss: 3.31103938957751

Epoch: 5| Step: 7
Training loss: 3.149205268030401
Validation loss: 3.3111080449931976

Epoch: 5| Step: 8
Training loss: 3.9169723445567572
Validation loss: 3.3098881819201655

Epoch: 5| Step: 9
Training loss: 3.6108987077373222
Validation loss: 3.30911239853669

Epoch: 5| Step: 10
Training loss: 3.4483460373150496
Validation loss: 3.3095731011104625

Epoch: 48| Step: 0
Training loss: 4.181823070809744
Validation loss: 3.3081693645285717

Epoch: 5| Step: 1
Training loss: 3.3367920256803605
Validation loss: 3.308508711439964

Epoch: 5| Step: 2
Training loss: 3.433483204456256
Validation loss: 3.307939612483288

Epoch: 5| Step: 3
Training loss: 2.312472575257038
Validation loss: 3.3069652220242034

Epoch: 5| Step: 4
Training loss: 3.6053351711272272
Validation loss: 3.307030395285372

Epoch: 5| Step: 5
Training loss: 3.9188904367497983
Validation loss: 3.3068865939391814

Epoch: 5| Step: 6
Training loss: 4.255027938374512
Validation loss: 3.306048513642501

Epoch: 5| Step: 7
Training loss: 3.5740642576754498
Validation loss: 3.3065808999501223

Epoch: 5| Step: 8
Training loss: 3.6806875113258766
Validation loss: 3.3035000559817966

Epoch: 5| Step: 9
Training loss: 3.256897868835826
Validation loss: 3.3040999748913613

Epoch: 5| Step: 10
Training loss: 3.005471326580485
Validation loss: 3.303202751091266

Epoch: 49| Step: 0
Training loss: 3.140700913455976
Validation loss: 3.302825053050688

Epoch: 5| Step: 1
Training loss: 3.318356357368772
Validation loss: 3.30337362304987

Epoch: 5| Step: 2
Training loss: 3.7419367250264353
Validation loss: 3.303445239326948

Epoch: 5| Step: 3
Training loss: 2.8279305069787384
Validation loss: 3.3012053256401717

Epoch: 5| Step: 4
Training loss: 3.8799099732799003
Validation loss: 3.303358053548656

Epoch: 5| Step: 5
Training loss: 4.072030025408952
Validation loss: 3.300421058849709

Epoch: 5| Step: 6
Training loss: 2.5283580318980494
Validation loss: 3.299885977362776

Epoch: 5| Step: 7
Training loss: 3.8315026154865754
Validation loss: 3.300812118103422

Epoch: 5| Step: 8
Training loss: 3.688826758718138
Validation loss: 3.3002391875174033

Epoch: 5| Step: 9
Training loss: 3.7806769322974754
Validation loss: 3.3003141716034583

Epoch: 5| Step: 10
Training loss: 3.9400663943433107
Validation loss: 3.301005854218682

Epoch: 50| Step: 0
Training loss: 2.780060331526985
Validation loss: 3.3016913696909747

Epoch: 5| Step: 1
Training loss: 3.934039214745051
Validation loss: 3.3006545575817534

Epoch: 5| Step: 2
Training loss: 3.257454612339616
Validation loss: 3.3013199635222907

Epoch: 5| Step: 3
Training loss: 3.9429970773700096
Validation loss: 3.3009627404279396

Epoch: 5| Step: 4
Training loss: 2.8978093127164546
Validation loss: 3.3003119686352282

Epoch: 5| Step: 5
Training loss: 3.463837728060518
Validation loss: 3.30041192256608

Epoch: 5| Step: 6
Training loss: 3.4896908567953373
Validation loss: 3.301031712592778

Epoch: 5| Step: 7
Training loss: 3.7915031202208618
Validation loss: 3.3032468461242193

Epoch: 5| Step: 8
Training loss: 4.301449535811255
Validation loss: 3.3016983260141695

Epoch: 5| Step: 9
Training loss: 3.2898193358469103
Validation loss: 3.3014695314657114

Epoch: 5| Step: 10
Training loss: 3.549080721610296
Validation loss: 3.300676463745904

Testing loss: 3.4901131526647466
