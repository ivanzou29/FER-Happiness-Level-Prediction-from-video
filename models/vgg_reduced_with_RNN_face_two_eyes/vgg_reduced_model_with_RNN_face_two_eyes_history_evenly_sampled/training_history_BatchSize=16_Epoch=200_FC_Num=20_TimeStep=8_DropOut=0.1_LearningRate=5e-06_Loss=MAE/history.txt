Epoch: 1| Step: 0
Training loss: 5.365131378173828
Validation loss: 5.127659572068081

Epoch: 6| Step: 1
Training loss: 4.656418800354004
Validation loss: 5.1242536114108175

Epoch: 6| Step: 2
Training loss: 4.73371696472168
Validation loss: 5.120789527893066

Epoch: 6| Step: 3
Training loss: 5.168701648712158
Validation loss: 5.117776440035913

Epoch: 6| Step: 4
Training loss: 5.21413516998291
Validation loss: 5.114745340039653

Epoch: 6| Step: 5
Training loss: 3.7482593059539795
Validation loss: 5.111865935787078

Epoch: 6| Step: 6
Training loss: 5.735263824462891
Validation loss: 5.1089939917287515

Epoch: 6| Step: 7
Training loss: 5.817434787750244
Validation loss: 5.106284100522277

Epoch: 6| Step: 8
Training loss: 5.832128524780273
Validation loss: 5.103110369815622

Epoch: 6| Step: 9
Training loss: 4.909900665283203
Validation loss: 5.100171619845975

Epoch: 6| Step: 10
Training loss: 4.334226131439209
Validation loss: 5.096852307678551

Epoch: 6| Step: 11
Training loss: 3.960857391357422
Validation loss: 5.093519308233774

Epoch: 6| Step: 12
Training loss: 5.077674388885498
Validation loss: 5.089917598232146

Epoch: 6| Step: 13
Training loss: 3.508350372314453
Validation loss: 5.08615291759532

Epoch: 2| Step: 0
Training loss: 5.268001556396484
Validation loss: 5.081909723179315

Epoch: 6| Step: 1
Training loss: 5.605556964874268
Validation loss: 5.077749854774885

Epoch: 6| Step: 2
Training loss: 4.351780414581299
Validation loss: 5.073538400793589

Epoch: 6| Step: 3
Training loss: 5.986843109130859
Validation loss: 5.069255636584375

Epoch: 6| Step: 4
Training loss: 4.753636837005615
Validation loss: 5.064374257159489

Epoch: 6| Step: 5
Training loss: 4.8565521240234375
Validation loss: 5.059404339841617

Epoch: 6| Step: 6
Training loss: 4.594660758972168
Validation loss: 5.054673394849224

Epoch: 6| Step: 7
Training loss: 4.616306304931641
Validation loss: 5.049065887287099

Epoch: 6| Step: 8
Training loss: 3.984637975692749
Validation loss: 5.043949665561799

Epoch: 6| Step: 9
Training loss: 4.5930399894714355
Validation loss: 5.038122228396836

Epoch: 6| Step: 10
Training loss: 4.889447212219238
Validation loss: 5.031846261793567

Epoch: 6| Step: 11
Training loss: 4.58711576461792
Validation loss: 5.02572141667848

Epoch: 6| Step: 12
Training loss: 5.722232341766357
Validation loss: 5.019003232320149

Epoch: 6| Step: 13
Training loss: 3.426739454269409
Validation loss: 5.0123326137501705

Epoch: 3| Step: 0
Training loss: 4.447574615478516
Validation loss: 5.0058094198985765

Epoch: 6| Step: 1
Training loss: 4.148221015930176
Validation loss: 4.997938807292651

Epoch: 6| Step: 2
Training loss: 4.578579902648926
Validation loss: 4.989868640899658

Epoch: 6| Step: 3
Training loss: 4.246403217315674
Validation loss: 4.982133855101883

Epoch: 6| Step: 4
Training loss: 5.404565811157227
Validation loss: 4.973546771592991

Epoch: 6| Step: 5
Training loss: 4.300319671630859
Validation loss: 4.964915039718792

Epoch: 6| Step: 6
Training loss: 3.5389866828918457
Validation loss: 4.955277622386974

Epoch: 6| Step: 7
Training loss: 4.006591796875
Validation loss: 4.946268030392226

Epoch: 6| Step: 8
Training loss: 4.561997890472412
Validation loss: 4.935977905027328

Epoch: 6| Step: 9
Training loss: 5.184104919433594
Validation loss: 4.9264180378247335

Epoch: 6| Step: 10
Training loss: 5.843042850494385
Validation loss: 4.915717109557121

Epoch: 6| Step: 11
Training loss: 5.993476867675781
Validation loss: 4.904464942152782

Epoch: 6| Step: 12
Training loss: 5.331206321716309
Validation loss: 4.892941618478426

Epoch: 6| Step: 13
Training loss: 4.874648094177246
Validation loss: 4.881744077128749

Epoch: 4| Step: 0
Training loss: 5.161721229553223
Validation loss: 4.869449746224188

Epoch: 6| Step: 1
Training loss: 4.514016628265381
Validation loss: 4.85691483815511

Epoch: 6| Step: 2
Training loss: 4.948459148406982
Validation loss: 4.843537330627441

Epoch: 6| Step: 3
Training loss: 4.6516337394714355
Validation loss: 4.830526956947901

Epoch: 6| Step: 4
Training loss: 5.812182903289795
Validation loss: 4.8166783599443335

Epoch: 6| Step: 5
Training loss: 3.941845178604126
Validation loss: 4.802019083371726

Epoch: 6| Step: 6
Training loss: 3.613558053970337
Validation loss: 4.788233085345197

Epoch: 6| Step: 7
Training loss: 4.309211730957031
Validation loss: 4.773721843637446

Epoch: 6| Step: 8
Training loss: 5.805054187774658
Validation loss: 4.760321350507839

Epoch: 6| Step: 9
Training loss: 4.547939300537109
Validation loss: 4.745709168013706

Epoch: 6| Step: 10
Training loss: 4.518408298492432
Validation loss: 4.732287960667764

Epoch: 6| Step: 11
Training loss: 4.555619239807129
Validation loss: 4.718094800108222

Epoch: 6| Step: 12
Training loss: 3.3115506172180176
Validation loss: 4.704390469417777

Epoch: 6| Step: 13
Training loss: 4.12299919128418
Validation loss: 4.689564520312894

Epoch: 5| Step: 0
Training loss: 4.644497871398926
Validation loss: 4.675167196540422

Epoch: 6| Step: 1
Training loss: 3.715975046157837
Validation loss: 4.660546902687319

Epoch: 6| Step: 2
Training loss: 5.492677688598633
Validation loss: 4.646554090643442

Epoch: 6| Step: 3
Training loss: 3.821321487426758
Validation loss: 4.632475601729526

Epoch: 6| Step: 4
Training loss: 5.0328369140625
Validation loss: 4.6183294173209894

Epoch: 6| Step: 5
Training loss: 4.409454822540283
Validation loss: 4.60503513069563

Epoch: 6| Step: 6
Training loss: 4.648667812347412
Validation loss: 4.591368126612838

Epoch: 6| Step: 7
Training loss: 4.61400842666626
Validation loss: 4.577915171141266

Epoch: 6| Step: 8
Training loss: 5.192157745361328
Validation loss: 4.565264296788041

Epoch: 6| Step: 9
Training loss: 3.8907978534698486
Validation loss: 4.553633748844105

Epoch: 6| Step: 10
Training loss: 3.266928195953369
Validation loss: 4.5415832150367

Epoch: 6| Step: 11
Training loss: 3.886852979660034
Validation loss: 4.529426872089345

Epoch: 6| Step: 12
Training loss: 4.59598445892334
Validation loss: 4.517674269214753

Epoch: 6| Step: 13
Training loss: 3.9110145568847656
Validation loss: 4.506334291991367

Epoch: 6| Step: 0
Training loss: 4.594990253448486
Validation loss: 4.495238816866311

Epoch: 6| Step: 1
Training loss: 5.2119293212890625
Validation loss: 4.483631733925112

Epoch: 6| Step: 2
Training loss: 3.861217975616455
Validation loss: 4.472927575470299

Epoch: 6| Step: 3
Training loss: 4.017124176025391
Validation loss: 4.462197119189847

Epoch: 6| Step: 4
Training loss: 3.098782777786255
Validation loss: 4.450627444892802

Epoch: 6| Step: 5
Training loss: 4.618893146514893
Validation loss: 4.440192468704716

Epoch: 6| Step: 6
Training loss: 5.300625801086426
Validation loss: 4.4292530244396575

Epoch: 6| Step: 7
Training loss: 4.3884782791137695
Validation loss: 4.4175324132365565

Epoch: 6| Step: 8
Training loss: 4.853640556335449
Validation loss: 4.404298336275162

Epoch: 6| Step: 9
Training loss: 3.1792144775390625
Validation loss: 4.388515390375609

Epoch: 6| Step: 10
Training loss: 3.351459264755249
Validation loss: 4.36726955188218

Epoch: 6| Step: 11
Training loss: 3.6245994567871094
Validation loss: 4.347245359933504

Epoch: 6| Step: 12
Training loss: 4.08370304107666
Validation loss: 4.331527038287091

Epoch: 6| Step: 13
Training loss: 5.450952529907227
Validation loss: 4.3178437448317

Epoch: 7| Step: 0
Training loss: 4.283689498901367
Validation loss: 4.306658993485153

Epoch: 6| Step: 1
Training loss: 3.602306365966797
Validation loss: 4.295300488830895

Epoch: 6| Step: 2
Training loss: 3.9432809352874756
Validation loss: 4.285460067051713

Epoch: 6| Step: 3
Training loss: 4.580694198608398
Validation loss: 4.273378023537257

Epoch: 6| Step: 4
Training loss: 3.4696204662323
Validation loss: 4.259882865413543

Epoch: 6| Step: 5
Training loss: 4.259695053100586
Validation loss: 4.245458843887493

Epoch: 6| Step: 6
Training loss: 3.0097291469573975
Validation loss: 4.231440456964636

Epoch: 6| Step: 7
Training loss: 4.082772731781006
Validation loss: 4.21622101465861

Epoch: 6| Step: 8
Training loss: 4.40252685546875
Validation loss: 4.201470390442879

Epoch: 6| Step: 9
Training loss: 4.593120098114014
Validation loss: 4.1861874723947174

Epoch: 6| Step: 10
Training loss: 5.437664985656738
Validation loss: 4.170347511127431

Epoch: 6| Step: 11
Training loss: 3.732628583908081
Validation loss: 4.157268472897109

Epoch: 6| Step: 12
Training loss: 3.0024139881134033
Validation loss: 4.14567889449417

Epoch: 6| Step: 13
Training loss: 4.199843883514404
Validation loss: 4.135570013394919

Epoch: 8| Step: 0
Training loss: 3.870276689529419
Validation loss: 4.124426021370836

Epoch: 6| Step: 1
Training loss: 3.6742329597473145
Validation loss: 4.11418782254701

Epoch: 6| Step: 2
Training loss: 3.355222702026367
Validation loss: 4.104413324786771

Epoch: 6| Step: 3
Training loss: 3.569340705871582
Validation loss: 4.094463320188625

Epoch: 6| Step: 4
Training loss: 4.3877339363098145
Validation loss: 4.082599747565485

Epoch: 6| Step: 5
Training loss: 4.160884857177734
Validation loss: 4.07408982451244

Epoch: 6| Step: 6
Training loss: 3.066823959350586
Validation loss: 4.061622709356328

Epoch: 6| Step: 7
Training loss: 4.256405830383301
Validation loss: 4.050192253563994

Epoch: 6| Step: 8
Training loss: 3.501278877258301
Validation loss: 4.0394716647363476

Epoch: 6| Step: 9
Training loss: 3.3118743896484375
Validation loss: 4.029870312700989

Epoch: 6| Step: 10
Training loss: 5.092408180236816
Validation loss: 4.019685278656662

Epoch: 6| Step: 11
Training loss: 4.011622905731201
Validation loss: 4.00808548670943

Epoch: 6| Step: 12
Training loss: 4.145654201507568
Validation loss: 3.999187489991547

Epoch: 6| Step: 13
Training loss: 4.305565357208252
Validation loss: 3.989633455071398

Epoch: 9| Step: 0
Training loss: 4.594996929168701
Validation loss: 3.981711992653467

Epoch: 6| Step: 1
Training loss: 4.368419647216797
Validation loss: 3.972976520497312

Epoch: 6| Step: 2
Training loss: 4.567718982696533
Validation loss: 3.9642869580176567

Epoch: 6| Step: 3
Training loss: 4.05612850189209
Validation loss: 3.9553261213405158

Epoch: 6| Step: 4
Training loss: 2.8671979904174805
Validation loss: 3.948297997956635

Epoch: 6| Step: 5
Training loss: 3.365185022354126
Validation loss: 3.9375419642335627

Epoch: 6| Step: 6
Training loss: 3.808429718017578
Validation loss: 3.928266535523117

Epoch: 6| Step: 7
Training loss: 3.5835330486297607
Validation loss: 3.9192679210375716

Epoch: 6| Step: 8
Training loss: 3.92598819732666
Validation loss: 3.910659228601763

Epoch: 6| Step: 9
Training loss: 3.408151388168335
Validation loss: 3.900867500612813

Epoch: 6| Step: 10
Training loss: 3.724102020263672
Validation loss: 3.8880690451591247

Epoch: 6| Step: 11
Training loss: 3.863532066345215
Validation loss: 3.8823513728316112

Epoch: 6| Step: 12
Training loss: 3.602964162826538
Validation loss: 3.872626935282061

Epoch: 6| Step: 13
Training loss: 3.006251335144043
Validation loss: 3.8617876140020226

Epoch: 10| Step: 0
Training loss: 4.321179389953613
Validation loss: 3.854226291820567

Epoch: 6| Step: 1
Training loss: 3.6017799377441406
Validation loss: 3.8448973624936995

Epoch: 6| Step: 2
Training loss: 2.8176698684692383
Validation loss: 3.8368465874784734

Epoch: 6| Step: 3
Training loss: 2.6433827877044678
Validation loss: 3.8275658238318657

Epoch: 6| Step: 4
Training loss: 4.340852737426758
Validation loss: 3.8178017729072162

Epoch: 6| Step: 5
Training loss: 4.095272541046143
Validation loss: 3.808529935857301

Epoch: 6| Step: 6
Training loss: 4.096870422363281
Validation loss: 3.798807421038228

Epoch: 6| Step: 7
Training loss: 3.300769329071045
Validation loss: 3.7910508032768004

Epoch: 6| Step: 8
Training loss: 2.9932782649993896
Validation loss: 3.7817404090717273

Epoch: 6| Step: 9
Training loss: 4.326920509338379
Validation loss: 3.773051672084357

Epoch: 6| Step: 10
Training loss: 3.984240770339966
Validation loss: 3.7660481929779053

Epoch: 6| Step: 11
Training loss: 3.794079303741455
Validation loss: 3.759191833516603

Epoch: 6| Step: 12
Training loss: 3.764012575149536
Validation loss: 3.748540432222428

Epoch: 6| Step: 13
Training loss: 3.320568561553955
Validation loss: 3.744768573391822

Epoch: 11| Step: 0
Training loss: 3.0919501781463623
Validation loss: 3.7367413710522395

Epoch: 6| Step: 1
Training loss: 3.033287525177002
Validation loss: 3.727954843992828

Epoch: 6| Step: 2
Training loss: 4.2536163330078125
Validation loss: 3.72137467322811

Epoch: 6| Step: 3
Training loss: 2.8911941051483154
Validation loss: 3.716671097663141

Epoch: 6| Step: 4
Training loss: 3.152263641357422
Validation loss: 3.710258524904969

Epoch: 6| Step: 5
Training loss: 2.594221830368042
Validation loss: 3.7010788917541504

Epoch: 6| Step: 6
Training loss: 3.3997342586517334
Validation loss: 3.6963944896574943

Epoch: 6| Step: 7
Training loss: 2.9583120346069336
Validation loss: 3.6904015233439784

Epoch: 6| Step: 8
Training loss: 3.6112465858459473
Validation loss: 3.6842048501455658

Epoch: 6| Step: 9
Training loss: 4.17155122756958
Validation loss: 3.6769929752554944

Epoch: 6| Step: 10
Training loss: 4.165394306182861
Validation loss: 3.6727625170061664

Epoch: 6| Step: 11
Training loss: 3.794029474258423
Validation loss: 3.6674173826812417

Epoch: 6| Step: 12
Training loss: 4.716243743896484
Validation loss: 3.6589527258308987

Epoch: 6| Step: 13
Training loss: 5.131533622741699
Validation loss: 3.6514547537731867

Epoch: 12| Step: 0
Training loss: 3.151923418045044
Validation loss: 3.64466348514762

Epoch: 6| Step: 1
Training loss: 3.596937656402588
Validation loss: 3.6413221102888866

Epoch: 6| Step: 2
Training loss: 3.9870047569274902
Validation loss: 3.6314663323022986

Epoch: 6| Step: 3
Training loss: 2.760481357574463
Validation loss: 3.6276036001020864

Epoch: 6| Step: 4
Training loss: 3.658817768096924
Validation loss: 3.6218934264234317

Epoch: 6| Step: 5
Training loss: 3.1785993576049805
Validation loss: 3.6141111004737114

Epoch: 6| Step: 6
Training loss: 2.9291329383850098
Validation loss: 3.608381299562352

Epoch: 6| Step: 7
Training loss: 4.03848934173584
Validation loss: 3.600546177997384

Epoch: 6| Step: 8
Training loss: 3.53513765335083
Validation loss: 3.5949172025085776

Epoch: 6| Step: 9
Training loss: 3.8183836936950684
Validation loss: 3.5857128891893613

Epoch: 6| Step: 10
Training loss: 2.9545602798461914
Validation loss: 3.5796961425453104

Epoch: 6| Step: 11
Training loss: 2.900033712387085
Validation loss: 3.575070842619865

Epoch: 6| Step: 12
Training loss: 4.525984764099121
Validation loss: 3.569758022985151

Epoch: 6| Step: 13
Training loss: 4.795327663421631
Validation loss: 3.5567436525898595

Epoch: 13| Step: 0
Training loss: 3.096083879470825
Validation loss: 3.553824358088996

Epoch: 6| Step: 1
Training loss: 2.445016384124756
Validation loss: 3.546876891966789

Epoch: 6| Step: 2
Training loss: 4.248881816864014
Validation loss: 3.541267325801234

Epoch: 6| Step: 3
Training loss: 3.907834529876709
Validation loss: 3.535620989338044

Epoch: 6| Step: 4
Training loss: 3.8596513271331787
Validation loss: 3.5247815039850052

Epoch: 6| Step: 5
Training loss: 3.425724506378174
Validation loss: 3.5169455979460027

Epoch: 6| Step: 6
Training loss: 3.796450614929199
Validation loss: 3.5100762613358034

Epoch: 6| Step: 7
Training loss: 3.332894802093506
Validation loss: 3.5007657210032144

Epoch: 6| Step: 8
Training loss: 3.9603166580200195
Validation loss: 3.4925198349901425

Epoch: 6| Step: 9
Training loss: 3.3414156436920166
Validation loss: 3.484040388496973

Epoch: 6| Step: 10
Training loss: 2.2867801189422607
Validation loss: 3.4745844666675856

Epoch: 6| Step: 11
Training loss: 3.5155601501464844
Validation loss: 3.469646953767346

Epoch: 6| Step: 12
Training loss: 4.300016403198242
Validation loss: 3.46635833350561

Epoch: 6| Step: 13
Training loss: 1.8740798234939575
Validation loss: 3.459193329657278

Epoch: 14| Step: 0
Training loss: 3.50958251953125
Validation loss: 3.4502502718279437

Epoch: 6| Step: 1
Training loss: 2.804558277130127
Validation loss: 3.4455202958917104

Epoch: 6| Step: 2
Training loss: 3.488665819168091
Validation loss: 3.4440645761387323

Epoch: 6| Step: 3
Training loss: 3.7627525329589844
Validation loss: 3.437488102143811

Epoch: 6| Step: 4
Training loss: 3.755539894104004
Validation loss: 3.4318054619655816

Epoch: 6| Step: 5
Training loss: 3.5020952224731445
Validation loss: 3.426457715290849

Epoch: 6| Step: 6
Training loss: 2.4523062705993652
Validation loss: 3.4219590540855163

Epoch: 6| Step: 7
Training loss: 3.658390998840332
Validation loss: 3.416780025728287

Epoch: 6| Step: 8
Training loss: 3.1542367935180664
Validation loss: 3.413084876152777

Epoch: 6| Step: 9
Training loss: 3.2643439769744873
Validation loss: 3.408280000891737

Epoch: 6| Step: 10
Training loss: 4.188973903656006
Validation loss: 3.413074629281157

Epoch: 6| Step: 11
Training loss: 4.212057113647461
Validation loss: 3.4039317561734106

Epoch: 6| Step: 12
Training loss: 2.430807590484619
Validation loss: 3.397844491466399

Epoch: 6| Step: 13
Training loss: 2.80472993850708
Validation loss: 3.397600579005416

Epoch: 15| Step: 0
Training loss: 3.2599105834960938
Validation loss: 3.394137951635545

Epoch: 6| Step: 1
Training loss: 3.512692928314209
Validation loss: 3.3949354566553587

Epoch: 6| Step: 2
Training loss: 3.8939695358276367
Validation loss: 3.3923334819014355

Epoch: 6| Step: 3
Training loss: 3.1542086601257324
Validation loss: 3.3904138483026975

Epoch: 6| Step: 4
Training loss: 2.740246534347534
Validation loss: 3.3861171096883793

Epoch: 6| Step: 5
Training loss: 2.8419222831726074
Validation loss: 3.3855210119678127

Epoch: 6| Step: 6
Training loss: 3.399658679962158
Validation loss: 3.3806906618097776

Epoch: 6| Step: 7
Training loss: 3.6608381271362305
Validation loss: 3.3783696748877086

Epoch: 6| Step: 8
Training loss: 3.4164540767669678
Validation loss: 3.3738993111477105

Epoch: 6| Step: 9
Training loss: 3.944051742553711
Validation loss: 3.369032403474213

Epoch: 6| Step: 10
Training loss: 3.5609474182128906
Validation loss: 3.36658650828946

Epoch: 6| Step: 11
Training loss: 2.557050943374634
Validation loss: 3.364739271902269

Epoch: 6| Step: 12
Training loss: 3.367419481277466
Validation loss: 3.3639706898761053

Epoch: 6| Step: 13
Training loss: 3.387769937515259
Validation loss: 3.362757885327903

Epoch: 16| Step: 0
Training loss: 3.343996286392212
Validation loss: 3.3609778214526433

Epoch: 6| Step: 1
Training loss: 3.424849271774292
Validation loss: 3.355676358745944

Epoch: 6| Step: 2
Training loss: 3.804503917694092
Validation loss: 3.3532502753760225

Epoch: 6| Step: 3
Training loss: 3.5809226036071777
Validation loss: 3.3505917979824926

Epoch: 6| Step: 4
Training loss: 2.8980023860931396
Validation loss: 3.351058216505153

Epoch: 6| Step: 5
Training loss: 2.7792611122131348
Validation loss: 3.349478393472651

Epoch: 6| Step: 6
Training loss: 3.1095426082611084
Validation loss: 3.3484726400785547

Epoch: 6| Step: 7
Training loss: 3.293718099594116
Validation loss: 3.347235346353182

Epoch: 6| Step: 8
Training loss: 4.2279157638549805
Validation loss: 3.34290450362749

Epoch: 6| Step: 9
Training loss: 2.677755355834961
Validation loss: 3.3393764752213673

Epoch: 6| Step: 10
Training loss: 4.3517584800720215
Validation loss: 3.340073001000189

Epoch: 6| Step: 11
Training loss: 2.592628002166748
Validation loss: 3.3370928610524824

Epoch: 6| Step: 12
Training loss: 2.5802245140075684
Validation loss: 3.3367796892760904

Epoch: 6| Step: 13
Training loss: 3.931823253631592
Validation loss: 3.3363499385054394

Epoch: 17| Step: 0
Training loss: 3.3621280193328857
Validation loss: 3.334641041294221

Epoch: 6| Step: 1
Training loss: 4.071069717407227
Validation loss: 3.3305215656116443

Epoch: 6| Step: 2
Training loss: 2.3965466022491455
Validation loss: 3.3280612140573482

Epoch: 6| Step: 3
Training loss: 2.696507692337036
Validation loss: 3.327515786693942

Epoch: 6| Step: 4
Training loss: 2.898014783859253
Validation loss: 3.32380828549785

Epoch: 6| Step: 5
Training loss: 2.441089153289795
Validation loss: 3.32671848932902

Epoch: 6| Step: 6
Training loss: 4.517377853393555
Validation loss: 3.3195908633611535

Epoch: 6| Step: 7
Training loss: 3.534618854522705
Validation loss: 3.318209586604949

Epoch: 6| Step: 8
Training loss: 3.440490961074829
Validation loss: 3.3182068537640315

Epoch: 6| Step: 9
Training loss: 4.4327521324157715
Validation loss: 3.317922317853538

Epoch: 6| Step: 10
Training loss: 2.3455982208251953
Validation loss: 3.3164523852768766

Epoch: 6| Step: 11
Training loss: 3.6727099418640137
Validation loss: 3.3154528166658137

Epoch: 6| Step: 12
Training loss: 3.017530918121338
Validation loss: 3.316112185037264

Epoch: 6| Step: 13
Training loss: 3.129188299179077
Validation loss: 3.3165681182697253

Epoch: 18| Step: 0
Training loss: 3.365699529647827
Validation loss: 3.3136174166074364

Epoch: 6| Step: 1
Training loss: 3.7592709064483643
Validation loss: 3.31122616798647

Epoch: 6| Step: 2
Training loss: 3.3772504329681396
Validation loss: 3.3051316404855378

Epoch: 6| Step: 3
Training loss: 2.0568952560424805
Validation loss: 3.3073781408289427

Epoch: 6| Step: 4
Training loss: 2.446227788925171
Validation loss: 3.3111550500316005

Epoch: 6| Step: 5
Training loss: 3.884467124938965
Validation loss: 3.3048580872115267

Epoch: 6| Step: 6
Training loss: 3.6042211055755615
Validation loss: 3.3027987685254825

Epoch: 6| Step: 7
Training loss: 2.7097628116607666
Validation loss: 3.29878133086748

Epoch: 6| Step: 8
Training loss: 4.023636817932129
Validation loss: 3.2974015384592037

Epoch: 6| Step: 9
Training loss: 3.2705860137939453
Validation loss: 3.296921226286119

Epoch: 6| Step: 10
Training loss: 2.3546366691589355
Validation loss: 3.2946951363676336

Epoch: 6| Step: 11
Training loss: 3.939913749694824
Validation loss: 3.2961940585926013

Epoch: 6| Step: 12
Training loss: 4.075399398803711
Validation loss: 3.290690706622216

Epoch: 6| Step: 13
Training loss: 2.675614833831787
Validation loss: 3.2904434665556876

Epoch: 19| Step: 0
Training loss: 2.351797580718994
Validation loss: 3.2862713798399894

Epoch: 6| Step: 1
Training loss: 3.537829637527466
Validation loss: 3.288438791869789

Epoch: 6| Step: 2
Training loss: 3.290142059326172
Validation loss: 3.2824940860912366

Epoch: 6| Step: 3
Training loss: 4.164400577545166
Validation loss: 3.2837904935242026

Epoch: 6| Step: 4
Training loss: 3.0799574851989746
Validation loss: 3.281449515332458

Epoch: 6| Step: 5
Training loss: 3.407233476638794
Validation loss: 3.2806912006870395

Epoch: 6| Step: 6
Training loss: 4.175711631774902
Validation loss: 3.2780684578803276

Epoch: 6| Step: 7
Training loss: 2.9636070728302
Validation loss: 3.2769514822190806

Epoch: 6| Step: 8
Training loss: 2.7959725856781006
Validation loss: 3.2762944647060928

Epoch: 6| Step: 9
Training loss: 3.199028968811035
Validation loss: 3.2765577941812496

Epoch: 6| Step: 10
Training loss: 2.6723828315734863
Validation loss: 3.2741209871025494

Epoch: 6| Step: 11
Training loss: 3.582465171813965
Validation loss: 3.27426807085673

Epoch: 6| Step: 12
Training loss: 3.040780782699585
Validation loss: 3.2711237040899133

Epoch: 6| Step: 13
Training loss: 3.3808369636535645
Validation loss: 3.271315333663776

Epoch: 20| Step: 0
Training loss: 4.617705345153809
Validation loss: 3.2698462419612433

Epoch: 6| Step: 1
Training loss: 2.7786004543304443
Validation loss: 3.2683536352649813

Epoch: 6| Step: 2
Training loss: 3.2643916606903076
Validation loss: 3.265079467527328

Epoch: 6| Step: 3
Training loss: 2.7946293354034424
Validation loss: 3.2658347237494683

Epoch: 6| Step: 4
Training loss: 3.491334915161133
Validation loss: 3.2655064982752644

Epoch: 6| Step: 5
Training loss: 2.519805431365967
Validation loss: 3.2645894942745084

Epoch: 6| Step: 6
Training loss: 2.5836923122406006
Validation loss: 3.2639240808384393

Epoch: 6| Step: 7
Training loss: 4.80592679977417
Validation loss: 3.2608379702414236

Epoch: 6| Step: 8
Training loss: 2.2135348320007324
Validation loss: 3.2608947266814527

Epoch: 6| Step: 9
Training loss: 3.4853692054748535
Validation loss: 3.2587161525603263

Epoch: 6| Step: 10
Training loss: 3.5995335578918457
Validation loss: 3.2566297951564995

Epoch: 6| Step: 11
Training loss: 2.5311431884765625
Validation loss: 3.2599762075690815

Epoch: 6| Step: 12
Training loss: 3.243783950805664
Validation loss: 3.2576932035466677

Epoch: 6| Step: 13
Training loss: 3.6611475944519043
Validation loss: 3.2562055151949645

Epoch: 21| Step: 0
Training loss: 3.4549646377563477
Validation loss: 3.255369165892242

Epoch: 6| Step: 1
Training loss: 4.423044681549072
Validation loss: 3.2519701065555697

Epoch: 6| Step: 2
Training loss: 3.9389400482177734
Validation loss: 3.2511287530263266

Epoch: 6| Step: 3
Training loss: 3.0193538665771484
Validation loss: 3.2510027372708885

Epoch: 6| Step: 4
Training loss: 3.6045286655426025
Validation loss: 3.250551108391054

Epoch: 6| Step: 5
Training loss: 2.596924304962158
Validation loss: 3.250318791276665

Epoch: 6| Step: 6
Training loss: 3.952963352203369
Validation loss: 3.2478152551958637

Epoch: 6| Step: 7
Training loss: 2.8320717811584473
Validation loss: 3.2451177617555023

Epoch: 6| Step: 8
Training loss: 2.786616802215576
Validation loss: 3.244180835703368

Epoch: 6| Step: 9
Training loss: 3.400648355484009
Validation loss: 3.2427921577166487

Epoch: 6| Step: 10
Training loss: 2.9041318893432617
Validation loss: 3.2417658836610856

Epoch: 6| Step: 11
Training loss: 2.563314914703369
Validation loss: 3.2420070504629486

Epoch: 6| Step: 12
Training loss: 3.2920737266540527
Validation loss: 3.2414512762459378

Epoch: 6| Step: 13
Training loss: 1.9176459312438965
Validation loss: 3.2419412238623506

Epoch: 22| Step: 0
Training loss: 2.8318369388580322
Validation loss: 3.241389231015277

Epoch: 6| Step: 1
Training loss: 3.331068992614746
Validation loss: 3.238364017137917

Epoch: 6| Step: 2
Training loss: 3.4053328037261963
Validation loss: 3.2356382082867365

Epoch: 6| Step: 3
Training loss: 3.711296319961548
Validation loss: 3.23436305856192

Epoch: 6| Step: 4
Training loss: 3.930396795272827
Validation loss: 3.2342640302514516

Epoch: 6| Step: 5
Training loss: 2.608206272125244
Validation loss: 3.2333989348462833

Epoch: 6| Step: 6
Training loss: 3.7400612831115723
Validation loss: 3.234768811092582

Epoch: 6| Step: 7
Training loss: 2.7334957122802734
Validation loss: 3.2350172765793337

Epoch: 6| Step: 8
Training loss: 3.328463554382324
Validation loss: 3.2299484232420563

Epoch: 6| Step: 9
Training loss: 2.4241490364074707
Validation loss: 3.2288681332783034

Epoch: 6| Step: 10
Training loss: 2.925732374191284
Validation loss: 3.227876724735383

Epoch: 6| Step: 11
Training loss: 3.2886040210723877
Validation loss: 3.2265321900767665

Epoch: 6| Step: 12
Training loss: 3.3933095932006836
Validation loss: 3.226368632367862

Epoch: 6| Step: 13
Training loss: 3.689502239227295
Validation loss: 3.226842805903445

Epoch: 23| Step: 0
Training loss: 3.3410210609436035
Validation loss: 3.2248940519107285

Epoch: 6| Step: 1
Training loss: 1.9980220794677734
Validation loss: 3.2239907403146066

Epoch: 6| Step: 2
Training loss: 2.353850841522217
Validation loss: 3.226353350506034

Epoch: 6| Step: 3
Training loss: 3.8028948307037354
Validation loss: 3.22103520875336

Epoch: 6| Step: 4
Training loss: 4.453802585601807
Validation loss: 3.221753038385863

Epoch: 6| Step: 5
Training loss: 3.4157967567443848
Validation loss: 3.221498868798697

Epoch: 6| Step: 6
Training loss: 3.723212718963623
Validation loss: 3.2194045641089

Epoch: 6| Step: 7
Training loss: 3.479278326034546
Validation loss: 3.2187626361846924

Epoch: 6| Step: 8
Training loss: 4.312741279602051
Validation loss: 3.219608414557672

Epoch: 6| Step: 9
Training loss: 2.617532730102539
Validation loss: 3.219500998015045

Epoch: 6| Step: 10
Training loss: 2.852072238922119
Validation loss: 3.216700038602275

Epoch: 6| Step: 11
Training loss: 3.2329530715942383
Validation loss: 3.2176540000464326

Epoch: 6| Step: 12
Training loss: 2.638357162475586
Validation loss: 3.2178686306040776

Epoch: 6| Step: 13
Training loss: 2.422809362411499
Validation loss: 3.2161980828931256

Epoch: 24| Step: 0
Training loss: 2.6923375129699707
Validation loss: 3.2152548887396373

Epoch: 6| Step: 1
Training loss: 3.4080660343170166
Validation loss: 3.212632550988146

Epoch: 6| Step: 2
Training loss: 3.069460391998291
Validation loss: 3.211863979216545

Epoch: 6| Step: 3
Training loss: 2.686972141265869
Validation loss: 3.211036220673592

Epoch: 6| Step: 4
Training loss: 3.4445033073425293
Validation loss: 3.2098675440716486

Epoch: 6| Step: 5
Training loss: 3.5124130249023438
Validation loss: 3.2066718224556214

Epoch: 6| Step: 6
Training loss: 4.228274345397949
Validation loss: 3.2102153352511826

Epoch: 6| Step: 7
Training loss: 3.3361477851867676
Validation loss: 3.2085370453455115

Epoch: 6| Step: 8
Training loss: 1.7597193717956543
Validation loss: 3.201464145414291

Epoch: 6| Step: 9
Training loss: 3.4742021560668945
Validation loss: 3.202409305880147

Epoch: 6| Step: 10
Training loss: 4.040632247924805
Validation loss: 3.203608851278982

Epoch: 6| Step: 11
Training loss: 2.5731613636016846
Validation loss: 3.2030294582407963

Epoch: 6| Step: 12
Training loss: 3.3430213928222656
Validation loss: 3.200057896234656

Epoch: 6| Step: 13
Training loss: 3.371647834777832
Validation loss: 3.2005049515795965

Epoch: 25| Step: 0
Training loss: 2.728999614715576
Validation loss: 3.2036386330922446

Epoch: 6| Step: 1
Training loss: 3.1867706775665283
Validation loss: 3.2010781021528345

Epoch: 6| Step: 2
Training loss: 4.090664386749268
Validation loss: 3.1994341419589136

Epoch: 6| Step: 3
Training loss: 3.481783866882324
Validation loss: 3.197291769007201

Epoch: 6| Step: 4
Training loss: 2.8496999740600586
Validation loss: 3.195299445941884

Epoch: 6| Step: 5
Training loss: 3.852971076965332
Validation loss: 3.194295670396538

Epoch: 6| Step: 6
Training loss: 2.895270824432373
Validation loss: 3.1927369794537945

Epoch: 6| Step: 7
Training loss: 2.078495502471924
Validation loss: 3.1933641177351757

Epoch: 6| Step: 8
Training loss: 3.5263819694519043
Validation loss: 3.194118297228249

Epoch: 6| Step: 9
Training loss: 2.821617603302002
Validation loss: 3.1963543789361113

Epoch: 6| Step: 10
Training loss: 3.146836042404175
Validation loss: 3.1924600114104567

Epoch: 6| Step: 11
Training loss: 2.9278359413146973
Validation loss: 3.190113836719144

Epoch: 6| Step: 12
Training loss: 3.8373475074768066
Validation loss: 3.1900007570943525

Epoch: 6| Step: 13
Training loss: 3.4094529151916504
Validation loss: 3.187603706954628

Epoch: 26| Step: 0
Training loss: 2.4812588691711426
Validation loss: 3.187845983812886

Epoch: 6| Step: 1
Training loss: 2.786931276321411
Validation loss: 3.1869742126875025

Epoch: 6| Step: 2
Training loss: 3.5005340576171875
Validation loss: 3.1856166470435356

Epoch: 6| Step: 3
Training loss: 3.006758689880371
Validation loss: 3.184548624100224

Epoch: 6| Step: 4
Training loss: 3.6810312271118164
Validation loss: 3.186046528559859

Epoch: 6| Step: 5
Training loss: 3.8342514038085938
Validation loss: 3.184235280559909

Epoch: 6| Step: 6
Training loss: 2.685863971710205
Validation loss: 3.1825854932108233

Epoch: 6| Step: 7
Training loss: 3.6674082279205322
Validation loss: 3.1845027118600826

Epoch: 6| Step: 8
Training loss: 3.375211715698242
Validation loss: 3.182068442785612

Epoch: 6| Step: 9
Training loss: 2.188167095184326
Validation loss: 3.1827092298897366

Epoch: 6| Step: 10
Training loss: 3.2894694805145264
Validation loss: 3.183234635219779

Epoch: 6| Step: 11
Training loss: 3.3565306663513184
Validation loss: 3.1811991609552854

Epoch: 6| Step: 12
Training loss: 2.8513784408569336
Validation loss: 3.185708348469068

Epoch: 6| Step: 13
Training loss: 4.498776435852051
Validation loss: 3.1864395961966565

Epoch: 27| Step: 0
Training loss: 2.3687705993652344
Validation loss: 3.1775735680774977

Epoch: 6| Step: 1
Training loss: 3.5613601207733154
Validation loss: 3.177881145990023

Epoch: 6| Step: 2
Training loss: 3.575981378555298
Validation loss: 3.1807717738613004

Epoch: 6| Step: 3
Training loss: 2.0693678855895996
Validation loss: 3.180170025876773

Epoch: 6| Step: 4
Training loss: 2.5882649421691895
Validation loss: 3.179128493032148

Epoch: 6| Step: 5
Training loss: 3.3222227096557617
Validation loss: 3.1773240976436163

Epoch: 6| Step: 6
Training loss: 2.9553611278533936
Validation loss: 3.179135322570801

Epoch: 6| Step: 7
Training loss: 3.9303040504455566
Validation loss: 3.1762647295510895

Epoch: 6| Step: 8
Training loss: 3.7951934337615967
Validation loss: 3.1759108574159685

Epoch: 6| Step: 9
Training loss: 3.4079136848449707
Validation loss: 3.1757311564619823

Epoch: 6| Step: 10
Training loss: 2.7111778259277344
Validation loss: 3.1739775852490495

Epoch: 6| Step: 11
Training loss: 2.9490084648132324
Validation loss: 3.1742210413820002

Epoch: 6| Step: 12
Training loss: 3.996487855911255
Validation loss: 3.1750025544115292

Epoch: 6| Step: 13
Training loss: 3.4888756275177
Validation loss: 3.172511903188562

Epoch: 28| Step: 0
Training loss: 3.340930461883545
Validation loss: 3.1708404376942623

Epoch: 6| Step: 1
Training loss: 4.122721195220947
Validation loss: 3.1712284318862425

Epoch: 6| Step: 2
Training loss: 3.2331299781799316
Validation loss: 3.1685438412491993

Epoch: 6| Step: 3
Training loss: 2.411923408508301
Validation loss: 3.1716432776502383

Epoch: 6| Step: 4
Training loss: 2.893404245376587
Validation loss: 3.1716247015101935

Epoch: 6| Step: 5
Training loss: 2.7480125427246094
Validation loss: 3.1699964795061337

Epoch: 6| Step: 6
Training loss: 3.1386892795562744
Validation loss: 3.169803532220984

Epoch: 6| Step: 7
Training loss: 3.074110507965088
Validation loss: 3.1680495149345806

Epoch: 6| Step: 8
Training loss: 2.299154758453369
Validation loss: 3.1656048964428645

Epoch: 6| Step: 9
Training loss: 3.4631595611572266
Validation loss: 3.1677900693749868

Epoch: 6| Step: 10
Training loss: 2.3136439323425293
Validation loss: 3.166670040417743

Epoch: 6| Step: 11
Training loss: 3.679258108139038
Validation loss: 3.166813668384347

Epoch: 6| Step: 12
Training loss: 4.004650115966797
Validation loss: 3.163894586665656

Epoch: 6| Step: 13
Training loss: 4.214245319366455
Validation loss: 3.1668076745925413

Epoch: 29| Step: 0
Training loss: 3.133758783340454
Validation loss: 3.163102724218881

Epoch: 6| Step: 1
Training loss: 4.121971607208252
Validation loss: 3.1645200508897022

Epoch: 6| Step: 2
Training loss: 2.9875473976135254
Validation loss: 3.1619111645606255

Epoch: 6| Step: 3
Training loss: 3.043797016143799
Validation loss: 3.1616856564757643

Epoch: 6| Step: 4
Training loss: 2.7835490703582764
Validation loss: 3.1594695609102965

Epoch: 6| Step: 5
Training loss: 3.602362632751465
Validation loss: 3.160509514552291

Epoch: 6| Step: 6
Training loss: 2.536022663116455
Validation loss: 3.1605325001542286

Epoch: 6| Step: 7
Training loss: 2.9147212505340576
Validation loss: 3.1567202255290043

Epoch: 6| Step: 8
Training loss: 3.389312505722046
Validation loss: 3.1596204952527116

Epoch: 6| Step: 9
Training loss: 3.1215357780456543
Validation loss: 3.160363471636208

Epoch: 6| Step: 10
Training loss: 2.409653663635254
Validation loss: 3.1582781037976666

Epoch: 6| Step: 11
Training loss: 3.432713270187378
Validation loss: 3.1578751866535475

Epoch: 6| Step: 12
Training loss: 3.3672008514404297
Validation loss: 3.155879892328734

Epoch: 6| Step: 13
Training loss: 3.8533291816711426
Validation loss: 3.1561420066382295

Epoch: 30| Step: 0
Training loss: 2.6897971630096436
Validation loss: 3.157620806847849

Epoch: 6| Step: 1
Training loss: 3.647784948348999
Validation loss: 3.159147459973571

Epoch: 6| Step: 2
Training loss: 3.1875953674316406
Validation loss: 3.158963305975801

Epoch: 6| Step: 3
Training loss: 4.192159175872803
Validation loss: 3.1573388166325067

Epoch: 6| Step: 4
Training loss: 3.6569600105285645
Validation loss: 3.1556509540927027

Epoch: 6| Step: 5
Training loss: 2.707796573638916
Validation loss: 3.1545857998632614

Epoch: 6| Step: 6
Training loss: 2.8282294273376465
Validation loss: 3.1530916203734694

Epoch: 6| Step: 7
Training loss: 1.8081681728363037
Validation loss: 3.1539017538870535

Epoch: 6| Step: 8
Training loss: 3.0876681804656982
Validation loss: 3.152208402592649

Epoch: 6| Step: 9
Training loss: 3.5378222465515137
Validation loss: 3.153044003312306

Epoch: 6| Step: 10
Training loss: 2.741128444671631
Validation loss: 3.1514275176550752

Epoch: 6| Step: 11
Training loss: 3.86159610748291
Validation loss: 3.1513720430353636

Epoch: 6| Step: 12
Training loss: 3.5478615760803223
Validation loss: 3.1502644477352018

Epoch: 6| Step: 13
Training loss: 2.6039562225341797
Validation loss: 3.1505407133410053

Epoch: 31| Step: 0
Training loss: 2.5689167976379395
Validation loss: 3.1499000851826002

Epoch: 6| Step: 1
Training loss: 3.083246946334839
Validation loss: 3.150455528689969

Epoch: 6| Step: 2
Training loss: 3.4021072387695312
Validation loss: 3.1493526094703266

Epoch: 6| Step: 3
Training loss: 3.150261878967285
Validation loss: 3.151082738753288

Epoch: 6| Step: 4
Training loss: 2.8761658668518066
Validation loss: 3.150206163365354

Epoch: 6| Step: 5
Training loss: 2.6312291622161865
Validation loss: 3.148508528227447

Epoch: 6| Step: 6
Training loss: 3.376162052154541
Validation loss: 3.148853225092734

Epoch: 6| Step: 7
Training loss: 3.69614315032959
Validation loss: 3.1473601402774936

Epoch: 6| Step: 8
Training loss: 3.0402143001556396
Validation loss: 3.146106522570374

Epoch: 6| Step: 9
Training loss: 3.753485679626465
Validation loss: 3.1481311808350267

Epoch: 6| Step: 10
Training loss: 4.3485612869262695
Validation loss: 3.1475808594816472

Epoch: 6| Step: 11
Training loss: 2.7395267486572266
Validation loss: 3.1464794784463863

Epoch: 6| Step: 12
Training loss: 2.766118049621582
Validation loss: 3.1445428658557195

Epoch: 6| Step: 13
Training loss: 2.612713575363159
Validation loss: 3.1460243912153345

Epoch: 32| Step: 0
Training loss: 3.2966957092285156
Validation loss: 3.1457404551967496

Epoch: 6| Step: 1
Training loss: 3.2323756217956543
Validation loss: 3.145545833854265

Epoch: 6| Step: 2
Training loss: 3.740870952606201
Validation loss: 3.1437890683451006

Epoch: 6| Step: 3
Training loss: 3.3818135261535645
Validation loss: 3.1450982862903225

Epoch: 6| Step: 4
Training loss: 3.1412339210510254
Validation loss: 3.142711647095219

Epoch: 6| Step: 5
Training loss: 3.212228536605835
Validation loss: 3.141480392025363

Epoch: 6| Step: 6
Training loss: 3.466531276702881
Validation loss: 3.143981484956639

Epoch: 6| Step: 7
Training loss: 3.397712230682373
Validation loss: 3.1425871797787246

Epoch: 6| Step: 8
Training loss: 3.2677245140075684
Validation loss: 3.144671086342104

Epoch: 6| Step: 9
Training loss: 2.699370861053467
Validation loss: 3.1436754477921354

Epoch: 6| Step: 10
Training loss: 3.0680956840515137
Validation loss: 3.142483316442018

Epoch: 6| Step: 11
Training loss: 2.136565685272217
Validation loss: 3.1414895032041814

Epoch: 6| Step: 12
Training loss: 2.955796718597412
Validation loss: 3.1412386484043573

Epoch: 6| Step: 13
Training loss: 3.3061554431915283
Validation loss: 3.140638223258398

Epoch: 33| Step: 0
Training loss: 2.6845216751098633
Validation loss: 3.1379245481183453

Epoch: 6| Step: 1
Training loss: 3.477334499359131
Validation loss: 3.139441708082794

Epoch: 6| Step: 2
Training loss: 3.1626968383789062
Validation loss: 3.138807063461632

Epoch: 6| Step: 3
Training loss: 2.7424659729003906
Validation loss: 3.1381989858483754

Epoch: 6| Step: 4
Training loss: 2.4309563636779785
Validation loss: 3.1385262140663723

Epoch: 6| Step: 5
Training loss: 3.261089563369751
Validation loss: 3.1398281487085486

Epoch: 6| Step: 6
Training loss: 4.4200358390808105
Validation loss: 3.139958191943425

Epoch: 6| Step: 7
Training loss: 3.3248062133789062
Validation loss: 3.1359649935076312

Epoch: 6| Step: 8
Training loss: 2.8404152393341064
Validation loss: 3.1370048651131253

Epoch: 6| Step: 9
Training loss: 2.1342484951019287
Validation loss: 3.136179285664712

Epoch: 6| Step: 10
Training loss: 3.4534642696380615
Validation loss: 3.136856568756924

Epoch: 6| Step: 11
Training loss: 3.2853875160217285
Validation loss: 3.1347260731522755

Epoch: 6| Step: 12
Training loss: 3.7142810821533203
Validation loss: 3.1364644086489113

Epoch: 6| Step: 13
Training loss: 3.317671775817871
Validation loss: 3.135634296683855

Epoch: 34| Step: 0
Training loss: 2.8319509029388428
Validation loss: 3.1357974083192888

Epoch: 6| Step: 1
Training loss: 3.1974472999572754
Validation loss: 3.1338440654098347

Epoch: 6| Step: 2
Training loss: 2.401874303817749
Validation loss: 3.1340565066183768

Epoch: 6| Step: 3
Training loss: 2.6829514503479004
Validation loss: 3.1339310779366443

Epoch: 6| Step: 4
Training loss: 4.455492973327637
Validation loss: 3.1343366125578522

Epoch: 6| Step: 5
Training loss: 3.0689821243286133
Validation loss: 3.1345989396495204

Epoch: 6| Step: 6
Training loss: 2.5471463203430176
Validation loss: 3.1317027922599547

Epoch: 6| Step: 7
Training loss: 3.359081268310547
Validation loss: 3.1324248621540685

Epoch: 6| Step: 8
Training loss: 2.838326930999756
Validation loss: 3.1327956081718527

Epoch: 6| Step: 9
Training loss: 3.557304859161377
Validation loss: 3.1329481319714616

Epoch: 6| Step: 10
Training loss: 2.1745615005493164
Validation loss: 3.132882364334599

Epoch: 6| Step: 11
Training loss: 3.9917588233947754
Validation loss: 3.133764000349147

Epoch: 6| Step: 12
Training loss: 3.2992453575134277
Validation loss: 3.1342222536763837

Epoch: 6| Step: 13
Training loss: 4.169790744781494
Validation loss: 3.1339670791420886

Epoch: 35| Step: 0
Training loss: 2.618647813796997
Validation loss: 3.1337990812076035

Epoch: 6| Step: 1
Training loss: 2.904416799545288
Validation loss: 3.131032648906913

Epoch: 6| Step: 2
Training loss: 2.9487643241882324
Validation loss: 3.1289011688642603

Epoch: 6| Step: 3
Training loss: 3.6371021270751953
Validation loss: 3.1304563630011772

Epoch: 6| Step: 4
Training loss: 2.7067694664001465
Validation loss: 3.129770166130476

Epoch: 6| Step: 5
Training loss: 2.714374542236328
Validation loss: 3.1277696265969226

Epoch: 6| Step: 6
Training loss: 3.4370174407958984
Validation loss: 3.129152344119164

Epoch: 6| Step: 7
Training loss: 2.7603507041931152
Validation loss: 3.1301666305911158

Epoch: 6| Step: 8
Training loss: 3.9445340633392334
Validation loss: 3.130459362460721

Epoch: 6| Step: 9
Training loss: 2.5984785556793213
Validation loss: 3.127670987959831

Epoch: 6| Step: 10
Training loss: 3.2319886684417725
Validation loss: 3.1283050583254908

Epoch: 6| Step: 11
Training loss: 2.939297676086426
Validation loss: 3.1273903359649

Epoch: 6| Step: 12
Training loss: 3.549172878265381
Validation loss: 3.1266929103482153

Epoch: 6| Step: 13
Training loss: 4.835369110107422
Validation loss: 3.1275207740004345

Epoch: 36| Step: 0
Training loss: 2.5197482109069824
Validation loss: 3.128752218779697

Epoch: 6| Step: 1
Training loss: 3.270394802093506
Validation loss: 3.1253106209539596

Epoch: 6| Step: 2
Training loss: 2.843834400177002
Validation loss: 3.1262711427545034

Epoch: 6| Step: 3
Training loss: 2.4260811805725098
Validation loss: 3.1274240657847416

Epoch: 6| Step: 4
Training loss: 2.965006113052368
Validation loss: 3.130562928415114

Epoch: 6| Step: 5
Training loss: 4.181291103363037
Validation loss: 3.1334288530452277

Epoch: 6| Step: 6
Training loss: 3.252706289291382
Validation loss: 3.1395401980287287

Epoch: 6| Step: 7
Training loss: 2.238210678100586
Validation loss: 3.1364943801715808

Epoch: 6| Step: 8
Training loss: 3.453477144241333
Validation loss: 3.1532626972403577

Epoch: 6| Step: 9
Training loss: 3.70862078666687
Validation loss: 3.133212625339467

Epoch: 6| Step: 10
Training loss: 3.137284994125366
Validation loss: 3.1240080043833744

Epoch: 6| Step: 11
Training loss: 3.508025884628296
Validation loss: 3.1240278777255805

Epoch: 6| Step: 12
Training loss: 2.7849276065826416
Validation loss: 3.1210573924485074

Epoch: 6| Step: 13
Training loss: 4.31621789932251
Validation loss: 3.1254264257287465

Epoch: 37| Step: 0
Training loss: 3.1140804290771484
Validation loss: 3.1246723744177047

Epoch: 6| Step: 1
Training loss: 2.1576499938964844
Validation loss: 3.123162325992379

Epoch: 6| Step: 2
Training loss: 3.849991798400879
Validation loss: 3.122595084610806

Epoch: 6| Step: 3
Training loss: 3.476862668991089
Validation loss: 3.125755258785781

Epoch: 6| Step: 4
Training loss: 2.750943183898926
Validation loss: 3.1237907435304377

Epoch: 6| Step: 5
Training loss: 4.409413814544678
Validation loss: 3.121550234415198

Epoch: 6| Step: 6
Training loss: 2.973294734954834
Validation loss: 3.1201891770926853

Epoch: 6| Step: 7
Training loss: 3.9869887828826904
Validation loss: 3.1201081532304005

Epoch: 6| Step: 8
Training loss: 2.424893617630005
Validation loss: 3.120537639946066

Epoch: 6| Step: 9
Training loss: 2.486191987991333
Validation loss: 3.1232499435383785

Epoch: 6| Step: 10
Training loss: 3.3333868980407715
Validation loss: 3.123579817433511

Epoch: 6| Step: 11
Training loss: 2.5552597045898438
Validation loss: 3.129558922142111

Epoch: 6| Step: 12
Training loss: 2.9448163509368896
Validation loss: 3.131979760303292

Epoch: 6| Step: 13
Training loss: 3.8595199584960938
Validation loss: 3.1610032768659693

Epoch: 38| Step: 0
Training loss: 3.317335844039917
Validation loss: 3.1504131517102643

Epoch: 6| Step: 1
Training loss: 2.7275590896606445
Validation loss: 3.1430507885512484

Epoch: 6| Step: 2
Training loss: 2.969059705734253
Validation loss: 3.1317369066258913

Epoch: 6| Step: 3
Training loss: 2.0724620819091797
Validation loss: 3.1189540073435795

Epoch: 6| Step: 4
Training loss: 2.916677474975586
Validation loss: 3.118817908789522

Epoch: 6| Step: 5
Training loss: 3.6317317485809326
Validation loss: 3.1185517285459783

Epoch: 6| Step: 6
Training loss: 2.5961484909057617
Validation loss: 3.1252131821006857

Epoch: 6| Step: 7
Training loss: 2.96659255027771
Validation loss: 3.129859073187715

Epoch: 6| Step: 8
Training loss: 3.4263086318969727
Validation loss: 3.1306458955170005

Epoch: 6| Step: 9
Training loss: 4.099735260009766
Validation loss: 3.1244773480199997

Epoch: 6| Step: 10
Training loss: 2.550586700439453
Validation loss: 3.1213807700782694

Epoch: 6| Step: 11
Training loss: 3.27209734916687
Validation loss: 3.118012192428753

Epoch: 6| Step: 12
Training loss: 3.904564619064331
Validation loss: 3.1166519605985252

Epoch: 6| Step: 13
Training loss: 3.902515411376953
Validation loss: 3.1212523214278685

Epoch: 39| Step: 0
Training loss: 3.282128095626831
Validation loss: 3.123351389361966

Epoch: 6| Step: 1
Training loss: 2.884676933288574
Validation loss: 3.122334357230894

Epoch: 6| Step: 2
Training loss: 2.813058853149414
Validation loss: 3.1227303217816096

Epoch: 6| Step: 3
Training loss: 4.0612101554870605
Validation loss: 3.1165616127752487

Epoch: 6| Step: 4
Training loss: 3.606872081756592
Validation loss: 3.12412384504913

Epoch: 6| Step: 5
Training loss: 2.8517398834228516
Validation loss: 3.121006437527236

Epoch: 6| Step: 6
Training loss: 3.182405471801758
Validation loss: 3.1274173644281205

Epoch: 6| Step: 7
Training loss: 2.7028982639312744
Validation loss: 3.161307152881417

Epoch: 6| Step: 8
Training loss: 2.6115283966064453
Validation loss: 3.2007902719641246

Epoch: 6| Step: 9
Training loss: 1.7648870944976807
Validation loss: 3.1232375329540623

Epoch: 6| Step: 10
Training loss: 3.151829481124878
Validation loss: 3.1101893712115545

Epoch: 6| Step: 11
Training loss: 3.588942050933838
Validation loss: 3.112072067876016

Epoch: 6| Step: 12
Training loss: 3.699122667312622
Validation loss: 3.1171621353395524

Epoch: 6| Step: 13
Training loss: 4.4127373695373535
Validation loss: 3.1287318788548952

Epoch: 40| Step: 0
Training loss: 1.9670748710632324
Validation loss: 3.1257469859174503

Epoch: 6| Step: 1
Training loss: 2.415576457977295
Validation loss: 3.124039552545035

Epoch: 6| Step: 2
Training loss: 3.1457340717315674
Validation loss: 3.1192789026485976

Epoch: 6| Step: 3
Training loss: 3.1838412284851074
Validation loss: 3.1126346357407106

Epoch: 6| Step: 4
Training loss: 3.202404260635376
Validation loss: 3.1130340894063315

Epoch: 6| Step: 5
Training loss: 3.1615047454833984
Validation loss: 3.109741783911182

Epoch: 6| Step: 6
Training loss: 2.937991142272949
Validation loss: 3.1110241797662552

Epoch: 6| Step: 7
Training loss: 3.915134906768799
Validation loss: 3.1107031247949086

Epoch: 6| Step: 8
Training loss: 3.703268051147461
Validation loss: 3.1085441855974096

Epoch: 6| Step: 9
Training loss: 3.9186911582946777
Validation loss: 3.112702190235097

Epoch: 6| Step: 10
Training loss: 2.6842267513275146
Validation loss: 3.1097751791759203

Epoch: 6| Step: 11
Training loss: 3.5659425258636475
Validation loss: 3.1119735061481433

Epoch: 6| Step: 12
Training loss: 2.996244430541992
Validation loss: 3.1148029117174048

Epoch: 6| Step: 13
Training loss: 3.168879985809326
Validation loss: 3.1154976557659846

Epoch: 41| Step: 0
Training loss: 3.356485366821289
Validation loss: 3.113422132307483

Epoch: 6| Step: 1
Training loss: 3.160524845123291
Validation loss: 3.1109631676827707

Epoch: 6| Step: 2
Training loss: 3.124121904373169
Validation loss: 3.1095362837596605

Epoch: 6| Step: 3
Training loss: 3.012279748916626
Validation loss: 3.10957432305941

Epoch: 6| Step: 4
Training loss: 3.299422264099121
Validation loss: 3.107962134063885

Epoch: 6| Step: 5
Training loss: 3.0955588817596436
Validation loss: 3.111379884904431

Epoch: 6| Step: 6
Training loss: 2.987488031387329
Validation loss: 3.102788422697334

Epoch: 6| Step: 7
Training loss: 2.646388053894043
Validation loss: 3.0987815446751092

Epoch: 6| Step: 8
Training loss: 3.2918643951416016
Validation loss: 3.1016626665669103

Epoch: 6| Step: 9
Training loss: 3.0176045894622803
Validation loss: 3.10103258778972

Epoch: 6| Step: 10
Training loss: 2.810810089111328
Validation loss: 3.0975991577230473

Epoch: 6| Step: 11
Training loss: 3.035928726196289
Validation loss: 3.0970955971748597

Epoch: 6| Step: 12
Training loss: 2.8516249656677246
Validation loss: 3.0980260731071554

Epoch: 6| Step: 13
Training loss: 4.956237316131592
Validation loss: 3.0984744538543043

Epoch: 42| Step: 0
Training loss: 3.551569938659668
Validation loss: 3.0984276827945503

Epoch: 6| Step: 1
Training loss: 2.37988543510437
Validation loss: 3.0970965995583484

Epoch: 6| Step: 2
Training loss: 3.943875312805176
Validation loss: 3.0957073550070486

Epoch: 6| Step: 3
Training loss: 3.6765546798706055
Validation loss: 3.0988202659032678

Epoch: 6| Step: 4
Training loss: 2.707066774368286
Validation loss: 3.099668087497834

Epoch: 6| Step: 5
Training loss: 3.5215444564819336
Validation loss: 3.1000444299431256

Epoch: 6| Step: 6
Training loss: 2.4314146041870117
Validation loss: 3.104080036122312

Epoch: 6| Step: 7
Training loss: 3.61777400970459
Validation loss: 3.099196800621607

Epoch: 6| Step: 8
Training loss: 3.4771554470062256
Validation loss: 3.095822831635834

Epoch: 6| Step: 9
Training loss: 2.5554440021514893
Validation loss: 3.0974647229717625

Epoch: 6| Step: 10
Training loss: 2.4644525051116943
Validation loss: 3.0923826079214773

Epoch: 6| Step: 11
Training loss: 3.0481717586517334
Validation loss: 3.0960232211697485

Epoch: 6| Step: 12
Training loss: 3.466438055038452
Validation loss: 3.096735418483775

Epoch: 6| Step: 13
Training loss: 2.799267292022705
Validation loss: 3.1001061393368627

Epoch: 43| Step: 0
Training loss: 2.5519866943359375
Validation loss: 3.096229919823267

Epoch: 6| Step: 1
Training loss: 3.5173444747924805
Validation loss: 3.106175612377864

Epoch: 6| Step: 2
Training loss: 3.949740409851074
Validation loss: 3.111469522599251

Epoch: 6| Step: 3
Training loss: 4.1060285568237305
Validation loss: 3.1139691132371143

Epoch: 6| Step: 4
Training loss: 3.112335681915283
Validation loss: 3.1078832636597338

Epoch: 6| Step: 5
Training loss: 3.2197675704956055
Validation loss: 3.105611132037255

Epoch: 6| Step: 6
Training loss: 2.8070907592773438
Validation loss: 3.0996151047368206

Epoch: 6| Step: 7
Training loss: 3.322359085083008
Validation loss: 3.095678972941573

Epoch: 6| Step: 8
Training loss: 2.988011360168457
Validation loss: 3.0904681862041516

Epoch: 6| Step: 9
Training loss: 2.8384385108947754
Validation loss: 3.090800900613108

Epoch: 6| Step: 10
Training loss: 2.8354249000549316
Validation loss: 3.0914635119899625

Epoch: 6| Step: 11
Training loss: 2.5718326568603516
Validation loss: 3.093433815945861

Epoch: 6| Step: 12
Training loss: 2.067138671875
Validation loss: 3.0896581321634273

Epoch: 6| Step: 13
Training loss: 4.467889785766602
Validation loss: 3.090167942867484

Epoch: 44| Step: 0
Training loss: 2.842217445373535
Validation loss: 3.091284285309494

Epoch: 6| Step: 1
Training loss: 3.7545595169067383
Validation loss: 3.088857517447523

Epoch: 6| Step: 2
Training loss: 2.5332279205322266
Validation loss: 3.0908591465283464

Epoch: 6| Step: 3
Training loss: 2.7756261825561523
Validation loss: 3.0896697762191936

Epoch: 6| Step: 4
Training loss: 3.648226261138916
Validation loss: 3.089497850787255

Epoch: 6| Step: 5
Training loss: 3.524980068206787
Validation loss: 3.0890341497236684

Epoch: 6| Step: 6
Training loss: 2.411464214324951
Validation loss: 3.087307414700908

Epoch: 6| Step: 7
Training loss: 2.897409677505493
Validation loss: 3.087956351618613

Epoch: 6| Step: 8
Training loss: 4.234382152557373
Validation loss: 3.0903559551444104

Epoch: 6| Step: 9
Training loss: 2.960622787475586
Validation loss: 3.0904060409915064

Epoch: 6| Step: 10
Training loss: 2.3593831062316895
Validation loss: 3.089296535779071

Epoch: 6| Step: 11
Training loss: 3.482419967651367
Validation loss: 3.09229459557482

Epoch: 6| Step: 12
Training loss: 2.758115530014038
Validation loss: 3.0881822750132573

Epoch: 6| Step: 13
Training loss: 3.8611462116241455
Validation loss: 3.091471766912809

Epoch: 45| Step: 0
Training loss: 3.1852364540100098
Validation loss: 3.0869236684614614

Epoch: 6| Step: 1
Training loss: 3.027794599533081
Validation loss: 3.0850021992960284

Epoch: 6| Step: 2
Training loss: 3.230340003967285
Validation loss: 3.089469463594498

Epoch: 6| Step: 3
Training loss: 2.8051254749298096
Validation loss: 3.0862320597453783

Epoch: 6| Step: 4
Training loss: 3.5044822692871094
Validation loss: 3.0885394055356263

Epoch: 6| Step: 5
Training loss: 2.2563629150390625
Validation loss: 3.0850302327063774

Epoch: 6| Step: 6
Training loss: 2.706289768218994
Validation loss: 3.084960045353059

Epoch: 6| Step: 7
Training loss: 4.1709980964660645
Validation loss: 3.086525752980222

Epoch: 6| Step: 8
Training loss: 3.07745361328125
Validation loss: 3.085526317678472

Epoch: 6| Step: 9
Training loss: 3.383261203765869
Validation loss: 3.085937000090076

Epoch: 6| Step: 10
Training loss: 3.077387809753418
Validation loss: 3.089263359705607

Epoch: 6| Step: 11
Training loss: 2.5026392936706543
Validation loss: 3.0863892391163814

Epoch: 6| Step: 12
Training loss: 3.5972089767456055
Validation loss: 3.087091253649804

Epoch: 6| Step: 13
Training loss: 3.1803596019744873
Validation loss: 3.0868504970304427

Epoch: 46| Step: 0
Training loss: 2.1158719062805176
Validation loss: 3.0828735725854033

Epoch: 6| Step: 1
Training loss: 3.1098883152008057
Validation loss: 3.0856722913762575

Epoch: 6| Step: 2
Training loss: 2.7582857608795166
Validation loss: 3.086359564976026

Epoch: 6| Step: 3
Training loss: 2.5208628177642822
Validation loss: 3.0869725878520677

Epoch: 6| Step: 4
Training loss: 4.309023857116699
Validation loss: 3.0896791181256695

Epoch: 6| Step: 5
Training loss: 2.8247032165527344
Validation loss: 3.0920912373450493

Epoch: 6| Step: 6
Training loss: 3.337225914001465
Validation loss: 3.0901620388031006

Epoch: 6| Step: 7
Training loss: 3.083829879760742
Validation loss: 3.092936351735105

Epoch: 6| Step: 8
Training loss: 2.5854239463806152
Validation loss: 3.0886870045815744

Epoch: 6| Step: 9
Training loss: 4.104644775390625
Validation loss: 3.0864163726888676

Epoch: 6| Step: 10
Training loss: 3.028508186340332
Validation loss: 3.087388312944802

Epoch: 6| Step: 11
Training loss: 3.55867862701416
Validation loss: 3.0816175091651177

Epoch: 6| Step: 12
Training loss: 2.946369171142578
Validation loss: 3.083274192707513

Epoch: 6| Step: 13
Training loss: 3.536017656326294
Validation loss: 3.0811878993947017

Epoch: 47| Step: 0
Training loss: 2.65609073638916
Validation loss: 3.081502796501242

Epoch: 6| Step: 1
Training loss: 3.4380087852478027
Validation loss: 3.0791365485037527

Epoch: 6| Step: 2
Training loss: 3.418407917022705
Validation loss: 3.080864978092973

Epoch: 6| Step: 3
Training loss: 3.16385817527771
Validation loss: 3.080530049980328

Epoch: 6| Step: 4
Training loss: 3.1290745735168457
Validation loss: 3.077967946247388

Epoch: 6| Step: 5
Training loss: 3.3540353775024414
Validation loss: 3.0797147161217144

Epoch: 6| Step: 6
Training loss: 2.257028102874756
Validation loss: 3.079594071193408

Epoch: 6| Step: 7
Training loss: 3.378041982650757
Validation loss: 3.0804146541062223

Epoch: 6| Step: 8
Training loss: 3.3722281455993652
Validation loss: 3.0789119812750045

Epoch: 6| Step: 9
Training loss: 4.05562686920166
Validation loss: 3.0806916862405758

Epoch: 6| Step: 10
Training loss: 2.913968086242676
Validation loss: 3.079319671917987

Epoch: 6| Step: 11
Training loss: 2.563105583190918
Validation loss: 3.0789399403397755

Epoch: 6| Step: 12
Training loss: 2.394822120666504
Validation loss: 3.0747676280237015

Epoch: 6| Step: 13
Training loss: 3.8062074184417725
Validation loss: 3.081112959051645

Epoch: 48| Step: 0
Training loss: 3.1417694091796875
Validation loss: 3.0784218106218564

Epoch: 6| Step: 1
Training loss: 4.069883346557617
Validation loss: 3.077080375404768

Epoch: 6| Step: 2
Training loss: 2.334573745727539
Validation loss: 3.076462173974642

Epoch: 6| Step: 3
Training loss: 2.5355472564697266
Validation loss: 3.0801234014572634

Epoch: 6| Step: 4
Training loss: 3.1076512336730957
Validation loss: 3.077145717477286

Epoch: 6| Step: 5
Training loss: 3.740966320037842
Validation loss: 3.0815610065255115

Epoch: 6| Step: 6
Training loss: 3.1063404083251953
Validation loss: 3.0803344070270495

Epoch: 6| Step: 7
Training loss: 2.8060696125030518
Validation loss: 3.081383164210986

Epoch: 6| Step: 8
Training loss: 3.358795166015625
Validation loss: 3.0859679637416715

Epoch: 6| Step: 9
Training loss: 2.80009388923645
Validation loss: 3.0742962873110207

Epoch: 6| Step: 10
Training loss: 3.830078601837158
Validation loss: 3.0811258567276822

Epoch: 6| Step: 11
Training loss: 2.830087900161743
Validation loss: 3.0793618130427536

Epoch: 6| Step: 12
Training loss: 3.1691341400146484
Validation loss: 3.0778143277732273

Epoch: 6| Step: 13
Training loss: 2.4100136756896973
Validation loss: 3.075766086578369

Epoch: 49| Step: 0
Training loss: 2.7242588996887207
Validation loss: 3.076238093837615

Epoch: 6| Step: 1
Training loss: 2.491342544555664
Validation loss: 3.0782772751264673

Epoch: 6| Step: 2
Training loss: 3.623447895050049
Validation loss: 3.0804964547516196

Epoch: 6| Step: 3
Training loss: 3.6348257064819336
Validation loss: 3.0794339179992676

Epoch: 6| Step: 4
Training loss: 3.7705864906311035
Validation loss: 3.079308294480847

Epoch: 6| Step: 5
Training loss: 4.101551055908203
Validation loss: 3.0737363676871023

Epoch: 6| Step: 6
Training loss: 2.305403470993042
Validation loss: 3.075431126420216

Epoch: 6| Step: 7
Training loss: 2.8445775508880615
Validation loss: 3.0744511055689987

Epoch: 6| Step: 8
Training loss: 3.2733945846557617
Validation loss: 3.0706828435262046

Epoch: 6| Step: 9
Training loss: 2.9716415405273438
Validation loss: 3.075420259147562

Epoch: 6| Step: 10
Training loss: 3.440725564956665
Validation loss: 3.07391817210823

Epoch: 6| Step: 11
Training loss: 2.723001003265381
Validation loss: 3.0795740773600917

Epoch: 6| Step: 12
Training loss: 2.5881638526916504
Validation loss: 3.077992662306755

Epoch: 6| Step: 13
Training loss: 3.008298635482788
Validation loss: 3.080146174277029

Epoch: 50| Step: 0
Training loss: 3.9930834770202637
Validation loss: 3.0741349163875786

Epoch: 6| Step: 1
Training loss: 3.838624954223633
Validation loss: 3.0782233284365748

Epoch: 6| Step: 2
Training loss: 3.6536202430725098
Validation loss: 3.0749827687458327

Epoch: 6| Step: 3
Training loss: 2.3970792293548584
Validation loss: 3.075373257360151

Epoch: 6| Step: 4
Training loss: 2.5814995765686035
Validation loss: 3.0759247118426907

Epoch: 6| Step: 5
Training loss: 2.5554752349853516
Validation loss: 3.0698029200236

Epoch: 6| Step: 6
Training loss: 4.280522346496582
Validation loss: 3.0713134273405998

Epoch: 6| Step: 7
Training loss: 1.8551963567733765
Validation loss: 3.0705580480637087

Epoch: 6| Step: 8
Training loss: 3.563502311706543
Validation loss: 3.070337282714023

Epoch: 6| Step: 9
Training loss: 3.646972417831421
Validation loss: 3.06760085269969

Epoch: 6| Step: 10
Training loss: 2.8505024909973145
Validation loss: 3.0692858055073726

Epoch: 6| Step: 11
Training loss: 2.7126948833465576
Validation loss: 3.0704809722080024

Epoch: 6| Step: 12
Training loss: 3.3463010787963867
Validation loss: 3.0704751347982757

Epoch: 6| Step: 13
Training loss: 1.5491642951965332
Validation loss: 3.069402351174303

Epoch: 51| Step: 0
Training loss: 3.8373117446899414
Validation loss: 3.0682061231264504

Epoch: 6| Step: 1
Training loss: 2.847064256668091
Validation loss: 3.067256030216012

Epoch: 6| Step: 2
Training loss: 2.5933315753936768
Validation loss: 3.0671670693223194

Epoch: 6| Step: 3
Training loss: 2.9415926933288574
Validation loss: 3.069069767511019

Epoch: 6| Step: 4
Training loss: 2.5361862182617188
Validation loss: 3.06943678855896

Epoch: 6| Step: 5
Training loss: 2.914915084838867
Validation loss: 3.0656407392153175

Epoch: 6| Step: 6
Training loss: 3.6774814128875732
Validation loss: 3.065635763188844

Epoch: 6| Step: 7
Training loss: 2.6974613666534424
Validation loss: 3.0678483593848442

Epoch: 6| Step: 8
Training loss: 3.162065267562866
Validation loss: 3.0646298470035678

Epoch: 6| Step: 9
Training loss: 2.7064950466156006
Validation loss: 3.0698409823961157

Epoch: 6| Step: 10
Training loss: 3.9579520225524902
Validation loss: 3.0704944902850735

Epoch: 6| Step: 11
Training loss: 3.26633882522583
Validation loss: 3.06881142944418

Epoch: 6| Step: 12
Training loss: 3.3454291820526123
Validation loss: 3.0683742748793734

Epoch: 6| Step: 13
Training loss: 2.9745874404907227
Validation loss: 3.069180157876784

Epoch: 52| Step: 0
Training loss: 2.290405750274658
Validation loss: 3.0636363721662954

Epoch: 6| Step: 1
Training loss: 2.338942766189575
Validation loss: 3.0652680371397283

Epoch: 6| Step: 2
Training loss: 2.4984827041625977
Validation loss: 3.0646457851573987

Epoch: 6| Step: 3
Training loss: 3.451617479324341
Validation loss: 3.0649042796063166

Epoch: 6| Step: 4
Training loss: 4.772763252258301
Validation loss: 3.0622743457876225

Epoch: 6| Step: 5
Training loss: 3.2738492488861084
Validation loss: 3.062627571885304

Epoch: 6| Step: 6
Training loss: 2.742133378982544
Validation loss: 3.0612114091073312

Epoch: 6| Step: 7
Training loss: 2.790130853652954
Validation loss: 3.063212953588014

Epoch: 6| Step: 8
Training loss: 3.8158226013183594
Validation loss: 3.0648223148879183

Epoch: 6| Step: 9
Training loss: 3.1236720085144043
Validation loss: 3.065483844408425

Epoch: 6| Step: 10
Training loss: 3.3868422508239746
Validation loss: 3.0653628662068355

Epoch: 6| Step: 11
Training loss: 3.2760818004608154
Validation loss: 3.0699686004269506

Epoch: 6| Step: 12
Training loss: 3.204130172729492
Validation loss: 3.0703612783903718

Epoch: 6| Step: 13
Training loss: 2.105698585510254
Validation loss: 3.069817086701752

Epoch: 53| Step: 0
Training loss: 2.469679355621338
Validation loss: 3.0664957184945383

Epoch: 6| Step: 1
Training loss: 3.154942512512207
Validation loss: 3.0656431874921246

Epoch: 6| Step: 2
Training loss: 3.500657558441162
Validation loss: 3.06199211459006

Epoch: 6| Step: 3
Training loss: 3.3018200397491455
Validation loss: 3.0611331488496516

Epoch: 6| Step: 4
Training loss: 3.1377739906311035
Validation loss: 3.062267928995112

Epoch: 6| Step: 5
Training loss: 3.1867446899414062
Validation loss: 3.060314098993937

Epoch: 6| Step: 6
Training loss: 3.0911307334899902
Validation loss: 3.0595441454200336

Epoch: 6| Step: 7
Training loss: 2.1136436462402344
Validation loss: 3.059401014799713

Epoch: 6| Step: 8
Training loss: 3.0512757301330566
Validation loss: 3.0630793161289667

Epoch: 6| Step: 9
Training loss: 3.595343589782715
Validation loss: 3.061076802592124

Epoch: 6| Step: 10
Training loss: 3.5473411083221436
Validation loss: 3.061927415991342

Epoch: 6| Step: 11
Training loss: 3.465071678161621
Validation loss: 3.060234741498065

Epoch: 6| Step: 12
Training loss: 2.548536777496338
Validation loss: 3.0588740738489295

Epoch: 6| Step: 13
Training loss: 3.4107344150543213
Validation loss: 3.057700546838904

Epoch: 54| Step: 0
Training loss: 2.9015212059020996
Validation loss: 3.0602013526424283

Epoch: 6| Step: 1
Training loss: 2.848116874694824
Validation loss: 3.0607151985168457

Epoch: 6| Step: 2
Training loss: 3.248594045639038
Validation loss: 3.060238156267392

Epoch: 6| Step: 3
Training loss: 3.1644535064697266
Validation loss: 3.058412705698321

Epoch: 6| Step: 4
Training loss: 3.482919216156006
Validation loss: 3.0641023343609226

Epoch: 6| Step: 5
Training loss: 3.3532958030700684
Validation loss: 3.0560378489955777

Epoch: 6| Step: 6
Training loss: 2.6193668842315674
Validation loss: 3.057838883451236

Epoch: 6| Step: 7
Training loss: 3.4384961128234863
Validation loss: 3.0544973291376585

Epoch: 6| Step: 8
Training loss: 3.5006449222564697
Validation loss: 3.062907054860105

Epoch: 6| Step: 9
Training loss: 2.5841782093048096
Validation loss: 3.058904137662662

Epoch: 6| Step: 10
Training loss: 2.395242691040039
Validation loss: 3.061624373159101

Epoch: 6| Step: 11
Training loss: 3.2774240970611572
Validation loss: 3.058278376056302

Epoch: 6| Step: 12
Training loss: 3.970188856124878
Validation loss: 3.058264083759759

Epoch: 6| Step: 13
Training loss: 2.2293357849121094
Validation loss: 3.0587392391697055

Epoch: 55| Step: 0
Training loss: 2.6389479637145996
Validation loss: 3.056042448166878

Epoch: 6| Step: 1
Training loss: 4.104536056518555
Validation loss: 3.0579080966211136

Epoch: 6| Step: 2
Training loss: 2.9926843643188477
Validation loss: 3.056783168546615

Epoch: 6| Step: 3
Training loss: 2.452657699584961
Validation loss: 3.057877327806206

Epoch: 6| Step: 4
Training loss: 3.143010139465332
Validation loss: 3.056253876737369

Epoch: 6| Step: 5
Training loss: 3.3078036308288574
Validation loss: 3.0570567141297045

Epoch: 6| Step: 6
Training loss: 2.263211250305176
Validation loss: 3.0561470780321347

Epoch: 6| Step: 7
Training loss: 2.775667428970337
Validation loss: 3.059384963845694

Epoch: 6| Step: 8
Training loss: 3.3553216457366943
Validation loss: 3.064294468971991

Epoch: 6| Step: 9
Training loss: 2.516228675842285
Validation loss: 3.0640033752687517

Epoch: 6| Step: 10
Training loss: 3.489654064178467
Validation loss: 3.0586680725056636

Epoch: 6| Step: 11
Training loss: 3.972890615463257
Validation loss: 3.0570172289366364

Epoch: 6| Step: 12
Training loss: 2.601243019104004
Validation loss: 3.060053292141166

Epoch: 6| Step: 13
Training loss: 4.328254699707031
Validation loss: 3.0568372716185865

Epoch: 56| Step: 0
Training loss: 3.5782017707824707
Validation loss: 3.054958376833188

Epoch: 6| Step: 1
Training loss: 2.3725826740264893
Validation loss: 3.0552345347660843

Epoch: 6| Step: 2
Training loss: 3.2937331199645996
Validation loss: 3.050380863169188

Epoch: 6| Step: 3
Training loss: 3.0174801349639893
Validation loss: 3.0558067906287407

Epoch: 6| Step: 4
Training loss: 2.8275065422058105
Validation loss: 3.0549010487012964

Epoch: 6| Step: 5
Training loss: 3.0653958320617676
Validation loss: 3.053038368942917

Epoch: 6| Step: 6
Training loss: 2.539172887802124
Validation loss: 3.0521815182060323

Epoch: 6| Step: 7
Training loss: 3.2794189453125
Validation loss: 3.0525832612027406

Epoch: 6| Step: 8
Training loss: 3.1395318508148193
Validation loss: 3.053933471761724

Epoch: 6| Step: 9
Training loss: 2.4814696311950684
Validation loss: 3.057809434911256

Epoch: 6| Step: 10
Training loss: 3.4871437549591064
Validation loss: 3.053720748552712

Epoch: 6| Step: 11
Training loss: 3.4889886379241943
Validation loss: 3.055048983584168

Epoch: 6| Step: 12
Training loss: 3.941317319869995
Validation loss: 3.058135178781325

Epoch: 6| Step: 13
Training loss: 2.6055290699005127
Validation loss: 3.056082869088778

Epoch: 57| Step: 0
Training loss: 3.4538931846618652
Validation loss: 3.0569472261654433

Epoch: 6| Step: 1
Training loss: 3.2517404556274414
Validation loss: 3.053210976303265

Epoch: 6| Step: 2
Training loss: 2.064175605773926
Validation loss: 3.0515378418789116

Epoch: 6| Step: 3
Training loss: 3.1216607093811035
Validation loss: 3.056905513168663

Epoch: 6| Step: 4
Training loss: 3.037741184234619
Validation loss: 3.054908425577225

Epoch: 6| Step: 5
Training loss: 2.6970407962799072
Validation loss: 3.0512703798150502

Epoch: 6| Step: 6
Training loss: 3.1441802978515625
Validation loss: 3.0526260816922752

Epoch: 6| Step: 7
Training loss: 2.9874281883239746
Validation loss: 3.0555034478505454

Epoch: 6| Step: 8
Training loss: 3.0385806560516357
Validation loss: 3.0537831373112176

Epoch: 6| Step: 9
Training loss: 3.3156352043151855
Validation loss: 3.053439804302749

Epoch: 6| Step: 10
Training loss: 3.383845329284668
Validation loss: 3.0514707744762464

Epoch: 6| Step: 11
Training loss: 3.2360427379608154
Validation loss: 3.054066140164611

Epoch: 6| Step: 12
Training loss: 3.78475284576416
Validation loss: 3.0688924199791363

Epoch: 6| Step: 13
Training loss: 2.4816367626190186
Validation loss: 3.073449501427271

Epoch: 58| Step: 0
Training loss: 3.5744950771331787
Validation loss: 3.062537095879996

Epoch: 6| Step: 1
Training loss: 3.309054374694824
Validation loss: 3.059845616740565

Epoch: 6| Step: 2
Training loss: 3.376882791519165
Validation loss: 3.0495471569799606

Epoch: 6| Step: 3
Training loss: 4.0764923095703125
Validation loss: 3.0472829264979207

Epoch: 6| Step: 4
Training loss: 2.2064168453216553
Validation loss: 3.0515437664524203

Epoch: 6| Step: 5
Training loss: 3.0105948448181152
Validation loss: 3.0511173407236734

Epoch: 6| Step: 6
Training loss: 3.5184521675109863
Validation loss: 3.0495973146089943

Epoch: 6| Step: 7
Training loss: 3.482633113861084
Validation loss: 3.052031163246401

Epoch: 6| Step: 8
Training loss: 1.4464685916900635
Validation loss: 3.0544008516496226

Epoch: 6| Step: 9
Training loss: 3.682651996612549
Validation loss: 3.0549576564501693

Epoch: 6| Step: 10
Training loss: 2.9481863975524902
Validation loss: 3.048472260916105

Epoch: 6| Step: 11
Training loss: 3.4510679244995117
Validation loss: 3.049356363152945

Epoch: 6| Step: 12
Training loss: 2.839979410171509
Validation loss: 3.049006421078918

Epoch: 6| Step: 13
Training loss: 1.671641230583191
Validation loss: 3.0496789204177035

Epoch: 59| Step: 0
Training loss: 2.9689178466796875
Validation loss: 3.0554397388171126

Epoch: 6| Step: 1
Training loss: 3.053659677505493
Validation loss: 3.059724420629522

Epoch: 6| Step: 2
Training loss: 2.3452296257019043
Validation loss: 3.0621472533031175

Epoch: 6| Step: 3
Training loss: 3.817748546600342
Validation loss: 3.0664192168943343

Epoch: 6| Step: 4
Training loss: 2.7696404457092285
Validation loss: 3.0690535832476873

Epoch: 6| Step: 5
Training loss: 3.2869551181793213
Validation loss: 3.067044847755022

Epoch: 6| Step: 6
Training loss: 2.416018486022949
Validation loss: 3.0613776535116215

Epoch: 6| Step: 7
Training loss: 3.4403295516967773
Validation loss: 3.0552451174746276

Epoch: 6| Step: 8
Training loss: 2.951101541519165
Validation loss: 3.056082325596963

Epoch: 6| Step: 9
Training loss: 3.008542537689209
Validation loss: 3.059911217740787

Epoch: 6| Step: 10
Training loss: 2.837488889694214
Validation loss: 3.057562622972714

Epoch: 6| Step: 11
Training loss: 2.5758044719696045
Validation loss: 3.066787406962405

Epoch: 6| Step: 12
Training loss: 4.1778717041015625
Validation loss: 3.054077561183642

Epoch: 6| Step: 13
Training loss: 3.9599647521972656
Validation loss: 3.047872486934867

Epoch: 60| Step: 0
Training loss: 3.9496207237243652
Validation loss: 3.0500777203549623

Epoch: 6| Step: 1
Training loss: 3.6286509037017822
Validation loss: 3.0499125321706138

Epoch: 6| Step: 2
Training loss: 4.062336444854736
Validation loss: 3.0548920477590253

Epoch: 6| Step: 3
Training loss: 2.0346438884735107
Validation loss: 3.0491558608188423

Epoch: 6| Step: 4
Training loss: 2.714627742767334
Validation loss: 3.0481705563042754

Epoch: 6| Step: 5
Training loss: 3.4889817237854004
Validation loss: 3.0479792984583045

Epoch: 6| Step: 6
Training loss: 3.3612678050994873
Validation loss: 3.048235780449324

Epoch: 6| Step: 7
Training loss: 2.715137004852295
Validation loss: 3.047873176554198

Epoch: 6| Step: 8
Training loss: 2.384876012802124
Validation loss: 3.0462999395144883

Epoch: 6| Step: 9
Training loss: 2.948444128036499
Validation loss: 3.046583124386367

Epoch: 6| Step: 10
Training loss: 2.9844093322753906
Validation loss: 3.0475314586393294

Epoch: 6| Step: 11
Training loss: 2.5028014183044434
Validation loss: 3.0425408604324504

Epoch: 6| Step: 12
Training loss: 3.2689571380615234
Validation loss: 3.045843662754182

Epoch: 6| Step: 13
Training loss: 3.2096152305603027
Validation loss: 3.0461405579761793

Epoch: 61| Step: 0
Training loss: 4.111912727355957
Validation loss: 3.051678806222895

Epoch: 6| Step: 1
Training loss: 2.348994731903076
Validation loss: 3.0521609501172136

Epoch: 6| Step: 2
Training loss: 2.057586669921875
Validation loss: 3.0677157884003012

Epoch: 6| Step: 3
Training loss: 3.6179399490356445
Validation loss: 3.083285270198699

Epoch: 6| Step: 4
Training loss: 3.846203088760376
Validation loss: 3.071611209582257

Epoch: 6| Step: 5
Training loss: 3.2886769771575928
Validation loss: 3.0646057872362036

Epoch: 6| Step: 6
Training loss: 1.9792919158935547
Validation loss: 3.063536003071775

Epoch: 6| Step: 7
Training loss: 2.679692268371582
Validation loss: 3.0597503826182377

Epoch: 6| Step: 8
Training loss: 3.614506721496582
Validation loss: 3.0553405105426745

Epoch: 6| Step: 9
Training loss: 2.762622356414795
Validation loss: 3.0503901102209605

Epoch: 6| Step: 10
Training loss: 2.894019842147827
Validation loss: 3.0416753240810928

Epoch: 6| Step: 11
Training loss: 3.1601486206054688
Validation loss: 3.042177782263807

Epoch: 6| Step: 12
Training loss: 3.299971580505371
Validation loss: 3.038412086425289

Epoch: 6| Step: 13
Training loss: 3.882388114929199
Validation loss: 3.0425108709642963

Epoch: 62| Step: 0
Training loss: 3.1808314323425293
Validation loss: 3.0443670672755085

Epoch: 6| Step: 1
Training loss: 2.6553399562835693
Validation loss: 3.0453104921566543

Epoch: 6| Step: 2
Training loss: 2.52305269241333
Validation loss: 3.0445311069488525

Epoch: 6| Step: 3
Training loss: 3.2200803756713867
Validation loss: 3.042191746414349

Epoch: 6| Step: 4
Training loss: 3.023228168487549
Validation loss: 3.038986090690859

Epoch: 6| Step: 5
Training loss: 2.7346911430358887
Validation loss: 3.043592814476259

Epoch: 6| Step: 6
Training loss: 2.8494186401367188
Validation loss: 3.0445941545630015

Epoch: 6| Step: 7
Training loss: 3.009675979614258
Validation loss: 3.0474905249893025

Epoch: 6| Step: 8
Training loss: 2.8251266479492188
Validation loss: 3.0409990997724634

Epoch: 6| Step: 9
Training loss: 2.903134822845459
Validation loss: 3.0447299916257142

Epoch: 6| Step: 10
Training loss: 3.140850067138672
Validation loss: 3.0463089045657905

Epoch: 6| Step: 11
Training loss: 4.22791051864624
Validation loss: 3.0547205171277447

Epoch: 6| Step: 12
Training loss: 3.500593423843384
Validation loss: 3.047287961488129

Epoch: 6| Step: 13
Training loss: 3.431950092315674
Validation loss: 3.047646809649724

Epoch: 63| Step: 0
Training loss: 2.5983994007110596
Validation loss: 3.040819419327603

Epoch: 6| Step: 1
Training loss: 1.8444099426269531
Validation loss: 3.040005971026677

Epoch: 6| Step: 2
Training loss: 2.982670307159424
Validation loss: 3.0368192990620932

Epoch: 6| Step: 3
Training loss: 2.318781852722168
Validation loss: 3.0335101337843042

Epoch: 6| Step: 4
Training loss: 3.2750496864318848
Validation loss: 3.034333536701818

Epoch: 6| Step: 5
Training loss: 2.9125125408172607
Validation loss: 3.033856617507114

Epoch: 6| Step: 6
Training loss: 3.526441812515259
Validation loss: 3.034474406191098

Epoch: 6| Step: 7
Training loss: 3.9997081756591797
Validation loss: 3.034922247291893

Epoch: 6| Step: 8
Training loss: 4.062063217163086
Validation loss: 3.0344456498340895

Epoch: 6| Step: 9
Training loss: 2.6805500984191895
Validation loss: 3.035556572739796

Epoch: 6| Step: 10
Training loss: 3.1358251571655273
Validation loss: 3.0344135069078013

Epoch: 6| Step: 11
Training loss: 3.3873772621154785
Validation loss: 3.0331247827058196

Epoch: 6| Step: 12
Training loss: 2.9812490940093994
Validation loss: 3.0312818993804274

Epoch: 6| Step: 13
Training loss: 3.5645854473114014
Validation loss: 3.0314218664682038

Epoch: 64| Step: 0
Training loss: 3.5324857234954834
Validation loss: 3.0329954598539617

Epoch: 6| Step: 1
Training loss: 4.256572723388672
Validation loss: 3.031707432962233

Epoch: 6| Step: 2
Training loss: 3.1764962673187256
Validation loss: 3.0328567797137844

Epoch: 6| Step: 3
Training loss: 3.186619520187378
Validation loss: 3.0336944082731843

Epoch: 6| Step: 4
Training loss: 3.140819787979126
Validation loss: 3.0342184446191274

Epoch: 6| Step: 5
Training loss: 3.3949246406555176
Validation loss: 3.0329659882412163

Epoch: 6| Step: 6
Training loss: 3.0068912506103516
Validation loss: 3.031193574269613

Epoch: 6| Step: 7
Training loss: 2.054844856262207
Validation loss: 3.0305267328857095

Epoch: 6| Step: 8
Training loss: 2.7347512245178223
Validation loss: 3.028933991668045

Epoch: 6| Step: 9
Training loss: 1.8368680477142334
Validation loss: 3.02684889301177

Epoch: 6| Step: 10
Training loss: 3.8144125938415527
Validation loss: 3.030551697618218

Epoch: 6| Step: 11
Training loss: 2.579066276550293
Validation loss: 3.029768446440338

Epoch: 6| Step: 12
Training loss: 2.7494664192199707
Validation loss: 3.036242510682793

Epoch: 6| Step: 13
Training loss: 3.9202466011047363
Validation loss: 3.0434760919181247

Epoch: 65| Step: 0
Training loss: 2.8445026874542236
Validation loss: 3.039529046704692

Epoch: 6| Step: 1
Training loss: 3.074453115463257
Validation loss: 3.0471448077950427

Epoch: 6| Step: 2
Training loss: 3.5599284172058105
Validation loss: 3.039990302055113

Epoch: 6| Step: 3
Training loss: 3.452777862548828
Validation loss: 3.0300659133541967

Epoch: 6| Step: 4
Training loss: 3.208144187927246
Validation loss: 3.0280171799403366

Epoch: 6| Step: 5
Training loss: 3.7983462810516357
Validation loss: 3.025461366099696

Epoch: 6| Step: 6
Training loss: 2.724947452545166
Validation loss: 3.0254526138305664

Epoch: 6| Step: 7
Training loss: 3.5838866233825684
Validation loss: 3.0259053271303893

Epoch: 6| Step: 8
Training loss: 2.1771087646484375
Validation loss: 3.02314845977291

Epoch: 6| Step: 9
Training loss: 2.972529411315918
Validation loss: 3.0267737732138684

Epoch: 6| Step: 10
Training loss: 2.6050045490264893
Validation loss: 3.0252218425914807

Epoch: 6| Step: 11
Training loss: 2.843479633331299
Validation loss: 3.026794469484719

Epoch: 6| Step: 12
Training loss: 3.353788375854492
Validation loss: 3.030970678534559

Epoch: 6| Step: 13
Training loss: 2.626101016998291
Validation loss: 3.0255723230300413

Epoch: 66| Step: 0
Training loss: 2.395291805267334
Validation loss: 3.0231901753333306

Epoch: 6| Step: 1
Training loss: 3.14459228515625
Validation loss: 3.0278887389808573

Epoch: 6| Step: 2
Training loss: 3.81811785697937
Validation loss: 3.026661665208878

Epoch: 6| Step: 3
Training loss: 3.822021961212158
Validation loss: 3.031963074079124

Epoch: 6| Step: 4
Training loss: 2.832040786743164
Validation loss: 3.0306945052198184

Epoch: 6| Step: 5
Training loss: 3.5886917114257812
Validation loss: 3.0382387304818756

Epoch: 6| Step: 6
Training loss: 2.8991503715515137
Validation loss: 3.034431257555562

Epoch: 6| Step: 7
Training loss: 2.6935439109802246
Validation loss: 3.0319891488680275

Epoch: 6| Step: 8
Training loss: 4.077087879180908
Validation loss: 3.036117099946545

Epoch: 6| Step: 9
Training loss: 2.0451550483703613
Validation loss: 3.033840799844393

Epoch: 6| Step: 10
Training loss: 2.552189826965332
Validation loss: 3.028753193475867

Epoch: 6| Step: 11
Training loss: 3.4358978271484375
Validation loss: 3.03337428903067

Epoch: 6| Step: 12
Training loss: 2.6229162216186523
Validation loss: 3.031079735807193

Epoch: 6| Step: 13
Training loss: 2.9507696628570557
Validation loss: 3.0304517002515894

Epoch: 67| Step: 0
Training loss: 2.3282487392425537
Validation loss: 3.0285356916407102

Epoch: 6| Step: 1
Training loss: 1.9935312271118164
Validation loss: 3.0304730605053645

Epoch: 6| Step: 2
Training loss: 3.2218222618103027
Validation loss: 3.0240622617865123

Epoch: 6| Step: 3
Training loss: 3.2518579959869385
Validation loss: 3.0288488300897742

Epoch: 6| Step: 4
Training loss: 3.3150908946990967
Validation loss: 3.0281375351772515

Epoch: 6| Step: 5
Training loss: 3.4307799339294434
Validation loss: 3.0254932013891076

Epoch: 6| Step: 6
Training loss: 3.131378412246704
Validation loss: 3.0288275441815777

Epoch: 6| Step: 7
Training loss: 2.495137929916382
Validation loss: 3.0245435699339835

Epoch: 6| Step: 8
Training loss: 3.1326498985290527
Validation loss: 3.025863475697015

Epoch: 6| Step: 9
Training loss: 2.8311705589294434
Validation loss: 3.024978058312529

Epoch: 6| Step: 10
Training loss: 3.3698439598083496
Validation loss: 3.027567817318824

Epoch: 6| Step: 11
Training loss: 3.687997341156006
Validation loss: 3.0251493710343555

Epoch: 6| Step: 12
Training loss: 3.639376640319824
Validation loss: 3.0294921449435654

Epoch: 6| Step: 13
Training loss: 2.995455741882324
Validation loss: 3.0265743988816456

Epoch: 68| Step: 0
Training loss: 3.307703971862793
Validation loss: 3.0231950154868503

Epoch: 6| Step: 1
Training loss: 3.7118470668792725
Validation loss: 3.0296638627206125

Epoch: 6| Step: 2
Training loss: 2.279524803161621
Validation loss: 3.0311555657335507

Epoch: 6| Step: 3
Training loss: 3.3600711822509766
Validation loss: 3.026484158731276

Epoch: 6| Step: 4
Training loss: 2.539578914642334
Validation loss: 3.0244618103068364

Epoch: 6| Step: 5
Training loss: 4.148149490356445
Validation loss: 3.024614559706821

Epoch: 6| Step: 6
Training loss: 3.5718464851379395
Validation loss: 3.029467910848638

Epoch: 6| Step: 7
Training loss: 2.5038845539093018
Validation loss: 3.0291541648167435

Epoch: 6| Step: 8
Training loss: 2.846890926361084
Validation loss: 3.0306099999335503

Epoch: 6| Step: 9
Training loss: 3.9586687088012695
Validation loss: 3.040485556407641

Epoch: 6| Step: 10
Training loss: 2.3248329162597656
Validation loss: 3.0351983603610786

Epoch: 6| Step: 11
Training loss: 2.6777873039245605
Validation loss: 3.0359698598102858

Epoch: 6| Step: 12
Training loss: 2.588247299194336
Validation loss: 3.0221231932281167

Epoch: 6| Step: 13
Training loss: 3.114461660385132
Validation loss: 3.019775362424953

Epoch: 69| Step: 0
Training loss: 4.320924758911133
Validation loss: 3.0211747025930755

Epoch: 6| Step: 1
Training loss: 2.7786099910736084
Validation loss: 3.020696496450773

Epoch: 6| Step: 2
Training loss: 2.1035568714141846
Validation loss: 3.0187023557642454

Epoch: 6| Step: 3
Training loss: 3.373211145401001
Validation loss: 3.0205076817543275

Epoch: 6| Step: 4
Training loss: 3.099416494369507
Validation loss: 3.015684914845292

Epoch: 6| Step: 5
Training loss: 3.053457736968994
Validation loss: 3.0200827301189466

Epoch: 6| Step: 6
Training loss: 3.5627219676971436
Validation loss: 3.020816180013841

Epoch: 6| Step: 7
Training loss: 2.2539193630218506
Validation loss: 3.0185292074757237

Epoch: 6| Step: 8
Training loss: 3.065685272216797
Validation loss: 3.020742936800885

Epoch: 6| Step: 9
Training loss: 2.8660733699798584
Validation loss: 3.0217854745926394

Epoch: 6| Step: 10
Training loss: 3.345780372619629
Validation loss: 3.031400485705304

Epoch: 6| Step: 11
Training loss: 3.016085147857666
Validation loss: 3.0266267125324537

Epoch: 6| Step: 12
Training loss: 3.2751617431640625
Validation loss: 3.022296541480608

Epoch: 6| Step: 13
Training loss: 2.5826215744018555
Validation loss: 3.0235902545272664

Epoch: 70| Step: 0
Training loss: 2.9167792797088623
Validation loss: 3.0204937406765517

Epoch: 6| Step: 1
Training loss: 2.7959580421447754
Validation loss: 3.0225674516411236

Epoch: 6| Step: 2
Training loss: 2.6301462650299072
Validation loss: 3.028985554172147

Epoch: 6| Step: 3
Training loss: 2.6839966773986816
Validation loss: 3.0268933849949993

Epoch: 6| Step: 4
Training loss: 2.664252758026123
Validation loss: 3.0333013688364336

Epoch: 6| Step: 5
Training loss: 3.1872286796569824
Validation loss: 3.030947857005622

Epoch: 6| Step: 6
Training loss: 3.2303061485290527
Validation loss: 3.0312903773400093

Epoch: 6| Step: 7
Training loss: 3.1825432777404785
Validation loss: 3.024674556588614

Epoch: 6| Step: 8
Training loss: 2.5543508529663086
Validation loss: 3.0250917250110256

Epoch: 6| Step: 9
Training loss: 3.261012554168701
Validation loss: 3.026006962663384

Epoch: 6| Step: 10
Training loss: 3.0299508571624756
Validation loss: 3.0215147259414836

Epoch: 6| Step: 11
Training loss: 3.5167219638824463
Validation loss: 3.026333949899161

Epoch: 6| Step: 12
Training loss: 4.010693073272705
Validation loss: 3.0218846362124205

Epoch: 6| Step: 13
Training loss: 3.1524176597595215
Validation loss: 3.0183890147875716

Epoch: 71| Step: 0
Training loss: 3.1598775386810303
Validation loss: 3.0254181559367845

Epoch: 6| Step: 1
Training loss: 4.136661052703857
Validation loss: 3.0231712095199095

Epoch: 6| Step: 2
Training loss: 3.1978609561920166
Validation loss: 3.0214829239794003

Epoch: 6| Step: 3
Training loss: 2.7818586826324463
Validation loss: 3.0211577748739593

Epoch: 6| Step: 4
Training loss: 3.114042282104492
Validation loss: 3.021393037611438

Epoch: 6| Step: 5
Training loss: 2.7726383209228516
Validation loss: 3.020769214117399

Epoch: 6| Step: 6
Training loss: 2.190659523010254
Validation loss: 3.0229441863234325

Epoch: 6| Step: 7
Training loss: 3.480300188064575
Validation loss: 3.0199165190419843

Epoch: 6| Step: 8
Training loss: 2.4005684852600098
Validation loss: 3.015970940230995

Epoch: 6| Step: 9
Training loss: 2.429703712463379
Validation loss: 3.0154743707308205

Epoch: 6| Step: 10
Training loss: 4.307806968688965
Validation loss: 3.0189726660328526

Epoch: 6| Step: 11
Training loss: 2.1415975093841553
Validation loss: 3.0155619011130383

Epoch: 6| Step: 12
Training loss: 3.720672607421875
Validation loss: 3.0225426894362255

Epoch: 6| Step: 13
Training loss: 2.767585515975952
Validation loss: 3.0226028196273313

Epoch: 72| Step: 0
Training loss: 3.233858585357666
Validation loss: 3.023997929788405

Epoch: 6| Step: 1
Training loss: 3.035883903503418
Validation loss: 3.0306780953561105

Epoch: 6| Step: 2
Training loss: 2.8037428855895996
Validation loss: 3.0286210865102787

Epoch: 6| Step: 3
Training loss: 3.056985378265381
Validation loss: 3.02438933362243

Epoch: 6| Step: 4
Training loss: 2.68930721282959
Validation loss: 3.0160915364501295

Epoch: 6| Step: 5
Training loss: 3.983388662338257
Validation loss: 3.0137292338955786

Epoch: 6| Step: 6
Training loss: 2.69059419631958
Validation loss: 3.0104548238938853

Epoch: 6| Step: 7
Training loss: 2.906317949295044
Validation loss: 3.0123066312523297

Epoch: 6| Step: 8
Training loss: 2.2720420360565186
Validation loss: 3.0090821302065285

Epoch: 6| Step: 9
Training loss: 3.3972153663635254
Validation loss: 3.0144683930181686

Epoch: 6| Step: 10
Training loss: 3.674786329269409
Validation loss: 3.013575730785247

Epoch: 6| Step: 11
Training loss: 3.495558977127075
Validation loss: 3.0180012179959204

Epoch: 6| Step: 12
Training loss: 2.42789626121521
Validation loss: 3.0164115813470658

Epoch: 6| Step: 13
Training loss: 3.107598066329956
Validation loss: 3.0119766317388064

Epoch: 73| Step: 0
Training loss: 3.0973458290100098
Validation loss: 3.0087309293849493

Epoch: 6| Step: 1
Training loss: 2.5056447982788086
Validation loss: 3.013925854877759

Epoch: 6| Step: 2
Training loss: 3.343987226486206
Validation loss: 3.0082169835285475

Epoch: 6| Step: 3
Training loss: 2.579756736755371
Validation loss: 3.0138943631161927

Epoch: 6| Step: 4
Training loss: 3.0692014694213867
Validation loss: 3.0214398983986146

Epoch: 6| Step: 5
Training loss: 3.4677324295043945
Validation loss: 3.0446581763605916

Epoch: 6| Step: 6
Training loss: 4.156525611877441
Validation loss: 3.0455145989694903

Epoch: 6| Step: 7
Training loss: 2.5669515132904053
Validation loss: 3.0488880526634956

Epoch: 6| Step: 8
Training loss: 2.618708610534668
Validation loss: 3.0532417784455004

Epoch: 6| Step: 9
Training loss: 3.538196325302124
Validation loss: 3.0227549973354546

Epoch: 6| Step: 10
Training loss: 3.3257405757904053
Validation loss: 3.0161537175537436

Epoch: 6| Step: 11
Training loss: 2.8994102478027344
Validation loss: 3.0139882872181554

Epoch: 6| Step: 12
Training loss: 2.619422435760498
Validation loss: 3.0102547266150035

Epoch: 6| Step: 13
Training loss: 3.113776683807373
Validation loss: 3.0086901110987507

Epoch: 74| Step: 0
Training loss: 2.714423179626465
Validation loss: 3.0113022942696848

Epoch: 6| Step: 1
Training loss: 3.5409398078918457
Validation loss: 3.0130457878112793

Epoch: 6| Step: 2
Training loss: 2.9097177982330322
Validation loss: 3.01649223860874

Epoch: 6| Step: 3
Training loss: 3.757079839706421
Validation loss: 3.0163626568291777

Epoch: 6| Step: 4
Training loss: 2.74798846244812
Validation loss: 3.0172770382255636

Epoch: 6| Step: 5
Training loss: 2.58001971244812
Validation loss: 3.0121140531314317

Epoch: 6| Step: 6
Training loss: 3.3615806102752686
Validation loss: 3.011691088317543

Epoch: 6| Step: 7
Training loss: 2.9767796993255615
Validation loss: 3.0082141225055983

Epoch: 6| Step: 8
Training loss: 2.575673818588257
Validation loss: 3.006042483032391

Epoch: 6| Step: 9
Training loss: 2.8743557929992676
Validation loss: 3.0028501992584555

Epoch: 6| Step: 10
Training loss: 2.862196922302246
Validation loss: 3.0058952967325845

Epoch: 6| Step: 11
Training loss: 3.5848336219787598
Validation loss: 3.0084239180370043

Epoch: 6| Step: 12
Training loss: 2.9970459938049316
Validation loss: 3.0115189501034316

Epoch: 6| Step: 13
Training loss: 3.4010658264160156
Validation loss: 3.0138678755811465

Epoch: 75| Step: 0
Training loss: 3.8075926303863525
Validation loss: 3.0194534742704002

Epoch: 6| Step: 1
Training loss: 2.8677549362182617
Validation loss: 3.021453970222063

Epoch: 6| Step: 2
Training loss: 2.1609647274017334
Validation loss: 3.021420673657489

Epoch: 6| Step: 3
Training loss: 3.209610939025879
Validation loss: 3.0201956354161745

Epoch: 6| Step: 4
Training loss: 2.4640884399414062
Validation loss: 3.0143368782535678

Epoch: 6| Step: 5
Training loss: 3.2499959468841553
Validation loss: 3.007209495831561

Epoch: 6| Step: 6
Training loss: 4.070413112640381
Validation loss: 3.0070533188440467

Epoch: 6| Step: 7
Training loss: 2.802931785583496
Validation loss: 3.0098107399479037

Epoch: 6| Step: 8
Training loss: 3.326510429382324
Validation loss: 3.0100833216021137

Epoch: 6| Step: 9
Training loss: 2.8445324897766113
Validation loss: 3.0095630896988737

Epoch: 6| Step: 10
Training loss: 3.087287664413452
Validation loss: 3.004235008711456

Epoch: 6| Step: 11
Training loss: 3.1012494564056396
Validation loss: 3.005489754420455

Epoch: 6| Step: 12
Training loss: 2.567434310913086
Validation loss: 3.0111820723420832

Epoch: 6| Step: 13
Training loss: 3.1817610263824463
Validation loss: 3.0057996575550368

Epoch: 76| Step: 0
Training loss: 3.60762882232666
Validation loss: 3.010955100418419

Epoch: 6| Step: 1
Training loss: 3.0289623737335205
Validation loss: 3.0104662244037916

Epoch: 6| Step: 2
Training loss: 2.550743579864502
Validation loss: 3.0086331111128612

Epoch: 6| Step: 3
Training loss: 2.6121768951416016
Validation loss: 3.0098190666526876

Epoch: 6| Step: 4
Training loss: 2.2342331409454346
Validation loss: 3.0062340100606284

Epoch: 6| Step: 5
Training loss: 3.6889171600341797
Validation loss: 3.003432366155809

Epoch: 6| Step: 6
Training loss: 3.033817768096924
Validation loss: 3.0017750391396145

Epoch: 6| Step: 7
Training loss: 2.6870675086975098
Validation loss: 3.0041200653199227

Epoch: 6| Step: 8
Training loss: 3.3073792457580566
Validation loss: 3.0018603391544794

Epoch: 6| Step: 9
Training loss: 2.4075965881347656
Validation loss: 3.0038086368191625

Epoch: 6| Step: 10
Training loss: 2.839027166366577
Validation loss: 3.007004960890739

Epoch: 6| Step: 11
Training loss: 3.341050863265991
Validation loss: 3.0056940817063853

Epoch: 6| Step: 12
Training loss: 2.8076720237731934
Validation loss: 3.0091404299582205

Epoch: 6| Step: 13
Training loss: 5.557437419891357
Validation loss: 3.007631806917088

Epoch: 77| Step: 0
Training loss: 3.9169716835021973
Validation loss: 3.0254556312355945

Epoch: 6| Step: 1
Training loss: 2.47257399559021
Validation loss: 3.023778251422349

Epoch: 6| Step: 2
Training loss: 3.231532573699951
Validation loss: 3.020695447921753

Epoch: 6| Step: 3
Training loss: 2.616726875305176
Validation loss: 3.013065086897983

Epoch: 6| Step: 4
Training loss: 3.463649034500122
Validation loss: 3.012730262612784

Epoch: 6| Step: 5
Training loss: 2.502711296081543
Validation loss: 3.0170711778825328

Epoch: 6| Step: 6
Training loss: 3.6128478050231934
Validation loss: 3.0116770267486572

Epoch: 6| Step: 7
Training loss: 3.044917106628418
Validation loss: 3.0153254847372732

Epoch: 6| Step: 8
Training loss: 2.514902114868164
Validation loss: 3.015656917325912

Epoch: 6| Step: 9
Training loss: 3.404082775115967
Validation loss: 3.0054985066895843

Epoch: 6| Step: 10
Training loss: 3.5931243896484375
Validation loss: 3.007550565145349

Epoch: 6| Step: 11
Training loss: 2.1925437450408936
Validation loss: 3.005727470562022

Epoch: 6| Step: 12
Training loss: 2.9088330268859863
Validation loss: 3.0036236752745924

Epoch: 6| Step: 13
Training loss: 3.1164820194244385
Validation loss: 3.0005960797750824

Epoch: 78| Step: 0
Training loss: 2.7619287967681885
Validation loss: 2.9976366950619604

Epoch: 6| Step: 1
Training loss: 3.9991631507873535
Validation loss: 2.9971780930795977

Epoch: 6| Step: 2
Training loss: 2.4205145835876465
Validation loss: 3.0006245695134646

Epoch: 6| Step: 3
Training loss: 2.2913782596588135
Validation loss: 3.008626509738225

Epoch: 6| Step: 4
Training loss: 2.298625946044922
Validation loss: 3.0114102773768927

Epoch: 6| Step: 5
Training loss: 3.5161705017089844
Validation loss: 3.0178360041751655

Epoch: 6| Step: 6
Training loss: 1.8637888431549072
Validation loss: 3.0143422670261835

Epoch: 6| Step: 7
Training loss: 3.3473386764526367
Validation loss: 3.007866164689423

Epoch: 6| Step: 8
Training loss: 3.7784483432769775
Validation loss: 3.006458851598924

Epoch: 6| Step: 9
Training loss: 3.767597198486328
Validation loss: 2.996556774262459

Epoch: 6| Step: 10
Training loss: 2.4677953720092773
Validation loss: 2.9947705832860803

Epoch: 6| Step: 11
Training loss: 3.5145692825317383
Validation loss: 2.994599998638194

Epoch: 6| Step: 12
Training loss: 3.8369312286376953
Validation loss: 2.9945773206731325

Epoch: 6| Step: 13
Training loss: 2.902881622314453
Validation loss: 2.99223635273595

Epoch: 79| Step: 0
Training loss: 2.6643190383911133
Validation loss: 2.996295093208231

Epoch: 6| Step: 1
Training loss: 3.4850635528564453
Validation loss: 3.000361140056323

Epoch: 6| Step: 2
Training loss: 2.959477663040161
Validation loss: 3.002100195935977

Epoch: 6| Step: 3
Training loss: 3.298976421356201
Validation loss: 3.0046386616204375

Epoch: 6| Step: 4
Training loss: 2.2508020401000977
Validation loss: 3.0095264450196297

Epoch: 6| Step: 5
Training loss: 3.12229323387146
Validation loss: 3.016208335917483

Epoch: 6| Step: 6
Training loss: 3.0303661823272705
Validation loss: 3.0112826029459634

Epoch: 6| Step: 7
Training loss: 3.6899983882904053
Validation loss: 3.0052867653549358

Epoch: 6| Step: 8
Training loss: 2.903794050216675
Validation loss: 3.0018303830136537

Epoch: 6| Step: 9
Training loss: 2.719372510910034
Validation loss: 3.0016864602283766

Epoch: 6| Step: 10
Training loss: 3.4016482830047607
Validation loss: 2.9968542181035525

Epoch: 6| Step: 11
Training loss: 2.8385539054870605
Validation loss: 2.9961932910385953

Epoch: 6| Step: 12
Training loss: 3.388110399246216
Validation loss: 2.9958678266053558

Epoch: 6| Step: 13
Training loss: 2.5661048889160156
Validation loss: 2.9911707883240073

Epoch: 80| Step: 0
Training loss: 2.6026816368103027
Validation loss: 2.9924186814215874

Epoch: 6| Step: 1
Training loss: 2.968374729156494
Validation loss: 2.9923511525636077

Epoch: 6| Step: 2
Training loss: 3.5732781887054443
Validation loss: 2.990011235719086

Epoch: 6| Step: 3
Training loss: 3.3621773719787598
Validation loss: 2.988656072206395

Epoch: 6| Step: 4
Training loss: 3.297696590423584
Validation loss: 2.9933181808840845

Epoch: 6| Step: 5
Training loss: 2.384443998336792
Validation loss: 2.9886708131400486

Epoch: 6| Step: 6
Training loss: 2.5868372917175293
Validation loss: 2.988299390321137

Epoch: 6| Step: 7
Training loss: 3.202881336212158
Validation loss: 2.9878358610214724

Epoch: 6| Step: 8
Training loss: 3.255244731903076
Validation loss: 2.985983725517027

Epoch: 6| Step: 9
Training loss: 3.066220998764038
Validation loss: 2.9852427026276946

Epoch: 6| Step: 10
Training loss: 3.1923987865448
Validation loss: 2.986251118362591

Epoch: 6| Step: 11
Training loss: 3.0033645629882812
Validation loss: 2.984857346421929

Epoch: 6| Step: 12
Training loss: 3.166965961456299
Validation loss: 2.9834172546222644

Epoch: 6| Step: 13
Training loss: 2.6749541759490967
Validation loss: 2.9873885441851873

Epoch: 81| Step: 0
Training loss: 2.825544834136963
Validation loss: 2.988067452625562

Epoch: 6| Step: 1
Training loss: 2.404543399810791
Validation loss: 2.9949068100221696

Epoch: 6| Step: 2
Training loss: 3.022055149078369
Validation loss: 3.0055518047783965

Epoch: 6| Step: 3
Training loss: 2.848700523376465
Validation loss: 3.0108292384814193

Epoch: 6| Step: 4
Training loss: 2.5382442474365234
Validation loss: 3.0173913817251883

Epoch: 6| Step: 5
Training loss: 2.7510268688201904
Validation loss: 3.0004331783581804

Epoch: 6| Step: 6
Training loss: 2.860930919647217
Validation loss: 2.9999039352581067

Epoch: 6| Step: 7
Training loss: 3.073784112930298
Validation loss: 2.993817908789522

Epoch: 6| Step: 8
Training loss: 3.4129791259765625
Validation loss: 2.992913930646835

Epoch: 6| Step: 9
Training loss: 2.3969192504882812
Validation loss: 2.988155149644421

Epoch: 6| Step: 10
Training loss: 3.8841443061828613
Validation loss: 2.989199061547556

Epoch: 6| Step: 11
Training loss: 3.3554868698120117
Validation loss: 2.9853142358923472

Epoch: 6| Step: 12
Training loss: 3.770564556121826
Validation loss: 2.983405315747825

Epoch: 6| Step: 13
Training loss: 3.4805049896240234
Validation loss: 2.981158346258184

Epoch: 82| Step: 0
Training loss: 2.7182579040527344
Validation loss: 2.9803893002130653

Epoch: 6| Step: 1
Training loss: 2.611286163330078
Validation loss: 2.9785614090581096

Epoch: 6| Step: 2
Training loss: 3.406489849090576
Validation loss: 2.9809749305889173

Epoch: 6| Step: 3
Training loss: 2.9550323486328125
Validation loss: 2.983180756209999

Epoch: 6| Step: 4
Training loss: 3.435389757156372
Validation loss: 2.9748087313867386

Epoch: 6| Step: 5
Training loss: 3.254288673400879
Validation loss: 2.9852318379186813

Epoch: 6| Step: 6
Training loss: 1.6702919006347656
Validation loss: 2.980256998410789

Epoch: 6| Step: 7
Training loss: 3.007951259613037
Validation loss: 2.9790479162687897

Epoch: 6| Step: 8
Training loss: 3.8019819259643555
Validation loss: 2.9809005209194717

Epoch: 6| Step: 9
Training loss: 3.3710503578186035
Validation loss: 2.9831068054322274

Epoch: 6| Step: 10
Training loss: 3.1020193099975586
Validation loss: 2.982017071016373

Epoch: 6| Step: 11
Training loss: 3.349482297897339
Validation loss: 2.9841869005592923

Epoch: 6| Step: 12
Training loss: 3.3241281509399414
Validation loss: 2.9850777938801754

Epoch: 6| Step: 13
Training loss: 1.9344515800476074
Validation loss: 2.9828009528498494

Epoch: 83| Step: 0
Training loss: 2.9620182514190674
Validation loss: 2.985374904447986

Epoch: 6| Step: 1
Training loss: 2.4200286865234375
Validation loss: 2.981448955433343

Epoch: 6| Step: 2
Training loss: 3.552260637283325
Validation loss: 2.9783688591372584

Epoch: 6| Step: 3
Training loss: 2.220987558364868
Validation loss: 2.976633130863149

Epoch: 6| Step: 4
Training loss: 3.323047161102295
Validation loss: 2.9720795410935597

Epoch: 6| Step: 5
Training loss: 3.4916701316833496
Validation loss: 2.9788166194833736

Epoch: 6| Step: 6
Training loss: 3.5656065940856934
Validation loss: 2.9828640568640923

Epoch: 6| Step: 7
Training loss: 3.364763021469116
Validation loss: 2.9839204408789195

Epoch: 6| Step: 8
Training loss: 3.335205554962158
Validation loss: 2.9855286100859284

Epoch: 6| Step: 9
Training loss: 3.495205879211426
Validation loss: 2.975952071528281

Epoch: 6| Step: 10
Training loss: 2.89268159866333
Validation loss: 2.977488225506198

Epoch: 6| Step: 11
Training loss: 2.401960849761963
Validation loss: 2.9746595428835962

Epoch: 6| Step: 12
Training loss: 3.1100664138793945
Validation loss: 2.975711332854404

Epoch: 6| Step: 13
Training loss: 1.8997541666030884
Validation loss: 2.9731100861744215

Epoch: 84| Step: 0
Training loss: 3.154261589050293
Validation loss: 2.9740028894075783

Epoch: 6| Step: 1
Training loss: 3.599976062774658
Validation loss: 2.9892863688930387

Epoch: 6| Step: 2
Training loss: 2.373854637145996
Validation loss: 3.0103904457502466

Epoch: 6| Step: 3
Training loss: 3.278979539871216
Validation loss: 3.0298790829156035

Epoch: 6| Step: 4
Training loss: 2.8107051849365234
Validation loss: 3.0359326485664613

Epoch: 6| Step: 5
Training loss: 3.123476982116699
Validation loss: 3.00412905088035

Epoch: 6| Step: 6
Training loss: 2.9400858879089355
Validation loss: 2.9876108015737226

Epoch: 6| Step: 7
Training loss: 3.167576789855957
Validation loss: 2.9800808096444733

Epoch: 6| Step: 8
Training loss: 3.130168914794922
Validation loss: 2.9739814804446314

Epoch: 6| Step: 9
Training loss: 3.620867967605591
Validation loss: 2.976036887015066

Epoch: 6| Step: 10
Training loss: 3.4862165451049805
Validation loss: 2.9718782286490164

Epoch: 6| Step: 11
Training loss: 2.688697338104248
Validation loss: 2.9726331567251556

Epoch: 6| Step: 12
Training loss: 1.893465280532837
Validation loss: 2.9761821916026454

Epoch: 6| Step: 13
Training loss: 3.3252859115600586
Validation loss: 2.9807389731048257

Epoch: 85| Step: 0
Training loss: 3.3608460426330566
Validation loss: 2.9797596675093456

Epoch: 6| Step: 1
Training loss: 3.258484363555908
Validation loss: 2.9897225274834582

Epoch: 6| Step: 2
Training loss: 3.6125144958496094
Validation loss: 2.9836957377772175

Epoch: 6| Step: 3
Training loss: 2.623823642730713
Validation loss: 2.9833199208782566

Epoch: 6| Step: 4
Training loss: 2.151075601577759
Validation loss: 2.979626729924192

Epoch: 6| Step: 5
Training loss: 3.18843936920166
Validation loss: 2.975928727016654

Epoch: 6| Step: 6
Training loss: 2.767486333847046
Validation loss: 2.971601229841991

Epoch: 6| Step: 7
Training loss: 2.4942431449890137
Validation loss: 2.971477452144828

Epoch: 6| Step: 8
Training loss: 2.8649206161499023
Validation loss: 2.9704223935322096

Epoch: 6| Step: 9
Training loss: 2.12248158454895
Validation loss: 2.969864822203113

Epoch: 6| Step: 10
Training loss: 3.482646942138672
Validation loss: 2.974748760141352

Epoch: 6| Step: 11
Training loss: 3.3902742862701416
Validation loss: 2.9760646948250393

Epoch: 6| Step: 12
Training loss: 3.9457719326019287
Validation loss: 2.9755421684634302

Epoch: 6| Step: 13
Training loss: 3.025794744491577
Validation loss: 2.979727638665066

Epoch: 86| Step: 0
Training loss: 2.2205514907836914
Validation loss: 2.976096191713887

Epoch: 6| Step: 1
Training loss: 3.3074488639831543
Validation loss: 2.9751740424863753

Epoch: 6| Step: 2
Training loss: 3.1310033798217773
Validation loss: 2.9730675323035127

Epoch: 6| Step: 3
Training loss: 2.617516279220581
Validation loss: 2.9765238761901855

Epoch: 6| Step: 4
Training loss: 3.6375889778137207
Validation loss: 2.973704645710607

Epoch: 6| Step: 5
Training loss: 3.063143014907837
Validation loss: 2.9672805750241844

Epoch: 6| Step: 6
Training loss: 3.190079689025879
Validation loss: 2.9748062549098844

Epoch: 6| Step: 7
Training loss: 2.641714096069336
Validation loss: 2.9685113660750853

Epoch: 6| Step: 8
Training loss: 2.9372029304504395
Validation loss: 2.970242190104659

Epoch: 6| Step: 9
Training loss: 3.0018372535705566
Validation loss: 2.9688345796318463

Epoch: 6| Step: 10
Training loss: 2.868420124053955
Validation loss: 2.96740811358216

Epoch: 6| Step: 11
Training loss: 3.1908023357391357
Validation loss: 2.9710933854503017

Epoch: 6| Step: 12
Training loss: 3.119084119796753
Validation loss: 2.96839395389762

Epoch: 6| Step: 13
Training loss: 3.512993812561035
Validation loss: 2.972848963993852

Epoch: 87| Step: 0
Training loss: 3.58367919921875
Validation loss: 2.976625419432117

Epoch: 6| Step: 1
Training loss: 3.506864309310913
Validation loss: 2.9791499696752077

Epoch: 6| Step: 2
Training loss: 2.3538818359375
Validation loss: 2.97786303745803

Epoch: 6| Step: 3
Training loss: 2.3779656887054443
Validation loss: 2.975520964591734

Epoch: 6| Step: 4
Training loss: 2.64749813079834
Validation loss: 2.978135662694131

Epoch: 6| Step: 5
Training loss: 2.8823812007904053
Validation loss: 2.977331171753586

Epoch: 6| Step: 6
Training loss: 2.8188552856445312
Validation loss: 2.9733823037916616

Epoch: 6| Step: 7
Training loss: 3.5286011695861816
Validation loss: 2.970550303818077

Epoch: 6| Step: 8
Training loss: 3.401306390762329
Validation loss: 2.965947440875474

Epoch: 6| Step: 9
Training loss: 2.6298398971557617
Validation loss: 2.965075046785416

Epoch: 6| Step: 10
Training loss: 2.429533004760742
Validation loss: 2.9624653964914303

Epoch: 6| Step: 11
Training loss: 3.3897275924682617
Validation loss: 2.9638591940684984

Epoch: 6| Step: 12
Training loss: 3.7068991661071777
Validation loss: 2.966120817328012

Epoch: 6| Step: 13
Training loss: 2.9340291023254395
Validation loss: 2.9694592927091863

Epoch: 88| Step: 0
Training loss: 3.216574192047119
Validation loss: 2.9721112405100176

Epoch: 6| Step: 1
Training loss: 3.456878185272217
Validation loss: 2.9657444620645173

Epoch: 6| Step: 2
Training loss: 3.2883362770080566
Validation loss: 2.9648836581937728

Epoch: 6| Step: 3
Training loss: 2.6724252700805664
Validation loss: 2.9626339635541363

Epoch: 6| Step: 4
Training loss: 3.169231414794922
Validation loss: 2.96547511828843

Epoch: 6| Step: 5
Training loss: 3.4203109741210938
Validation loss: 2.9624271982459613

Epoch: 6| Step: 6
Training loss: 2.193991184234619
Validation loss: 2.962302577111029

Epoch: 6| Step: 7
Training loss: 2.1457362174987793
Validation loss: 2.965117995456983

Epoch: 6| Step: 8
Training loss: 2.7629542350769043
Validation loss: 2.9594367319537747

Epoch: 6| Step: 9
Training loss: 3.2372565269470215
Validation loss: 2.9660328280541206

Epoch: 6| Step: 10
Training loss: 2.8627495765686035
Validation loss: 2.9635339936902447

Epoch: 6| Step: 11
Training loss: 3.0813751220703125
Validation loss: 2.965546961753599

Epoch: 6| Step: 12
Training loss: 3.2145700454711914
Validation loss: 2.96145962643367

Epoch: 6| Step: 13
Training loss: 3.7485551834106445
Validation loss: 2.961261405739733

Epoch: 89| Step: 0
Training loss: 3.482163667678833
Validation loss: 2.9609523383519982

Epoch: 6| Step: 1
Training loss: 2.466085910797119
Validation loss: 2.9644581015392015

Epoch: 6| Step: 2
Training loss: 2.87568998336792
Validation loss: 2.9650895467368503

Epoch: 6| Step: 3
Training loss: 3.0798287391662598
Validation loss: 2.961874556797807

Epoch: 6| Step: 4
Training loss: 3.3064653873443604
Validation loss: 2.965645772154613

Epoch: 6| Step: 5
Training loss: 2.9108128547668457
Validation loss: 2.9663545470083914

Epoch: 6| Step: 6
Training loss: 3.041792631149292
Validation loss: 2.9608652642978135

Epoch: 6| Step: 7
Training loss: 2.723982334136963
Validation loss: 2.9614842835293023

Epoch: 6| Step: 8
Training loss: 3.2397756576538086
Validation loss: 2.9628426336473033

Epoch: 6| Step: 9
Training loss: 2.210970401763916
Validation loss: 2.9609764750285814

Epoch: 6| Step: 10
Training loss: 4.026266098022461
Validation loss: 2.959198082647016

Epoch: 6| Step: 11
Training loss: 3.0624232292175293
Validation loss: 2.9600040348627235

Epoch: 6| Step: 12
Training loss: 2.929805040359497
Validation loss: 2.959319737649733

Epoch: 6| Step: 13
Training loss: 2.5928220748901367
Validation loss: 2.9573293629512993

Epoch: 90| Step: 0
Training loss: 3.291891098022461
Validation loss: 2.957307912970102

Epoch: 6| Step: 1
Training loss: 3.1921908855438232
Validation loss: 2.9582782765870452

Epoch: 6| Step: 2
Training loss: 3.072544574737549
Validation loss: 2.961545676313421

Epoch: 6| Step: 3
Training loss: 2.974682331085205
Validation loss: 2.9605189907935356

Epoch: 6| Step: 4
Training loss: 2.4239768981933594
Validation loss: 2.9616902259088334

Epoch: 6| Step: 5
Training loss: 2.924077033996582
Validation loss: 2.9648989938920542

Epoch: 6| Step: 6
Training loss: 2.512324571609497
Validation loss: 2.962469300916118

Epoch: 6| Step: 7
Training loss: 2.8713321685791016
Validation loss: 2.9626874974978867

Epoch: 6| Step: 8
Training loss: 2.9742207527160645
Validation loss: 2.9578056489267657

Epoch: 6| Step: 9
Training loss: 3.5412282943725586
Validation loss: 2.9558339785504084

Epoch: 6| Step: 10
Training loss: 2.707070827484131
Validation loss: 2.954323543015347

Epoch: 6| Step: 11
Training loss: 3.5356173515319824
Validation loss: 2.9533010759661273

Epoch: 6| Step: 12
Training loss: 2.9510698318481445
Validation loss: 2.9512808348542903

Epoch: 6| Step: 13
Training loss: 3.4719579219818115
Validation loss: 2.9560118259922152

Epoch: 91| Step: 0
Training loss: 2.800302505493164
Validation loss: 2.9556970339949413

Epoch: 6| Step: 1
Training loss: 3.9743812084198
Validation loss: 2.956847131893199

Epoch: 6| Step: 2
Training loss: 2.38871431350708
Validation loss: 2.957496799448485

Epoch: 6| Step: 3
Training loss: 2.349520444869995
Validation loss: 2.9585042358726583

Epoch: 6| Step: 4
Training loss: 2.8103065490722656
Validation loss: 2.9640336703228694

Epoch: 6| Step: 5
Training loss: 3.580876588821411
Validation loss: 2.9629435949428107

Epoch: 6| Step: 6
Training loss: 2.97839093208313
Validation loss: 2.959924651730445

Epoch: 6| Step: 7
Training loss: 1.9888931512832642
Validation loss: 2.967128348606889

Epoch: 6| Step: 8
Training loss: 3.608308792114258
Validation loss: 2.9720238178007063

Epoch: 6| Step: 9
Training loss: 4.12332820892334
Validation loss: 2.9719978635029127

Epoch: 6| Step: 10
Training loss: 2.652620792388916
Validation loss: 2.972022020688621

Epoch: 6| Step: 11
Training loss: 3.2538554668426514
Validation loss: 2.96462151568423

Epoch: 6| Step: 12
Training loss: 2.8928182125091553
Validation loss: 2.9567642493914534

Epoch: 6| Step: 13
Training loss: 2.4284863471984863
Validation loss: 2.954022774132349

Epoch: 92| Step: 0
Training loss: 3.158740282058716
Validation loss: 2.9544850087934926

Epoch: 6| Step: 1
Training loss: 2.7512829303741455
Validation loss: 2.9475893666667323

Epoch: 6| Step: 2
Training loss: 2.333073616027832
Validation loss: 2.950121315576697

Epoch: 6| Step: 3
Training loss: 3.8372020721435547
Validation loss: 2.949152808035574

Epoch: 6| Step: 4
Training loss: 3.1466212272644043
Validation loss: 2.950120838739539

Epoch: 6| Step: 5
Training loss: 3.111807346343994
Validation loss: 2.948530517598634

Epoch: 6| Step: 6
Training loss: 3.488898277282715
Validation loss: 2.9513793837639595

Epoch: 6| Step: 7
Training loss: 2.8457605838775635
Validation loss: 2.9503512100506852

Epoch: 6| Step: 8
Training loss: 2.4352526664733887
Validation loss: 2.9505656329534387

Epoch: 6| Step: 9
Training loss: 3.0251340866088867
Validation loss: 2.9519599432586343

Epoch: 6| Step: 10
Training loss: 3.278703212738037
Validation loss: 2.947458541521462

Epoch: 6| Step: 11
Training loss: 3.5922324657440186
Validation loss: 2.948208770444316

Epoch: 6| Step: 12
Training loss: 2.3351869583129883
Validation loss: 2.9499233717559488

Epoch: 6| Step: 13
Training loss: 2.434300422668457
Validation loss: 2.951271826221097

Epoch: 93| Step: 0
Training loss: 2.6508820056915283
Validation loss: 2.952505011712351

Epoch: 6| Step: 1
Training loss: 1.8069968223571777
Validation loss: 2.951105933035574

Epoch: 6| Step: 2
Training loss: 2.998202323913574
Validation loss: 2.953971606428905

Epoch: 6| Step: 3
Training loss: 2.8559255599975586
Validation loss: 2.949610710144043

Epoch: 6| Step: 4
Training loss: 3.5983777046203613
Validation loss: 2.9486520290374756

Epoch: 6| Step: 5
Training loss: 3.204848289489746
Validation loss: 2.9473625075432563

Epoch: 6| Step: 6
Training loss: 2.781402111053467
Validation loss: 2.9459236642365814

Epoch: 6| Step: 7
Training loss: 3.2975997924804688
Validation loss: 2.9469668813931045

Epoch: 6| Step: 8
Training loss: 3.404686450958252
Validation loss: 2.9458571839076217

Epoch: 6| Step: 9
Training loss: 2.9813599586486816
Validation loss: 2.9452901706900647

Epoch: 6| Step: 10
Training loss: 2.822368860244751
Validation loss: 2.9487094725331953

Epoch: 6| Step: 11
Training loss: 3.281795024871826
Validation loss: 2.9462289399998163

Epoch: 6| Step: 12
Training loss: 3.81999135017395
Validation loss: 2.9465017959635746

Epoch: 6| Step: 13
Training loss: 2.107335329055786
Validation loss: 2.9471167390064528

Epoch: 94| Step: 0
Training loss: 2.7197048664093018
Validation loss: 2.945072461200017

Epoch: 6| Step: 1
Training loss: 3.14243745803833
Validation loss: 2.9445846824235815

Epoch: 6| Step: 2
Training loss: 3.5996320247650146
Validation loss: 2.9452438508310625

Epoch: 6| Step: 3
Training loss: 3.0290184020996094
Validation loss: 2.9429443574720815

Epoch: 6| Step: 4
Training loss: 2.936389923095703
Validation loss: 2.9442428824722127

Epoch: 6| Step: 5
Training loss: 2.5281736850738525
Validation loss: 2.94686193876369

Epoch: 6| Step: 6
Training loss: 2.4742655754089355
Validation loss: 2.943432838686051

Epoch: 6| Step: 7
Training loss: 3.26609468460083
Validation loss: 2.9505143114315566

Epoch: 6| Step: 8
Training loss: 2.8444252014160156
Validation loss: 2.9443990517688055

Epoch: 6| Step: 9
Training loss: 3.3991708755493164
Validation loss: 2.9433913615442093

Epoch: 6| Step: 10
Training loss: 2.779482364654541
Validation loss: 2.9477199303206576

Epoch: 6| Step: 11
Training loss: 2.246152400970459
Validation loss: 2.9422528692471084

Epoch: 6| Step: 12
Training loss: 3.1904137134552
Validation loss: 2.941582505420972

Epoch: 6| Step: 13
Training loss: 4.491022109985352
Validation loss: 2.9405044612064155

Epoch: 95| Step: 0
Training loss: 3.232975959777832
Validation loss: 2.939473218815301

Epoch: 6| Step: 1
Training loss: 3.4371984004974365
Validation loss: 2.9393588650611138

Epoch: 6| Step: 2
Training loss: 2.5929505825042725
Validation loss: 2.9383127253542662

Epoch: 6| Step: 3
Training loss: 3.137021064758301
Validation loss: 2.9397665069949244

Epoch: 6| Step: 4
Training loss: 2.8317911624908447
Validation loss: 2.938824569025347

Epoch: 6| Step: 5
Training loss: 2.907515048980713
Validation loss: 2.9401855596932034

Epoch: 6| Step: 6
Training loss: 3.4585165977478027
Validation loss: 2.9390227230646278

Epoch: 6| Step: 7
Training loss: 2.92002010345459
Validation loss: 2.9392099431765977

Epoch: 6| Step: 8
Training loss: 3.4315686225891113
Validation loss: 2.9394367125726517

Epoch: 6| Step: 9
Training loss: 3.0685386657714844
Validation loss: 2.9438997058458227

Epoch: 6| Step: 10
Training loss: 2.7531721591949463
Validation loss: 2.9367553213591218

Epoch: 6| Step: 11
Training loss: 3.028773784637451
Validation loss: 2.9408278465270996

Epoch: 6| Step: 12
Training loss: 2.6840744018554688
Validation loss: 2.9403489687109507

Epoch: 6| Step: 13
Training loss: 2.121037721633911
Validation loss: 2.9386770699613836

Epoch: 96| Step: 0
Training loss: 3.618518829345703
Validation loss: 2.9392529661937425

Epoch: 6| Step: 1
Training loss: 3.0319509506225586
Validation loss: 2.9443904353726293

Epoch: 6| Step: 2
Training loss: 2.582200050354004
Validation loss: 2.9388820253392702

Epoch: 6| Step: 3
Training loss: 2.9631686210632324
Validation loss: 2.941470948598718

Epoch: 6| Step: 4
Training loss: 3.1040477752685547
Validation loss: 2.943260718417424

Epoch: 6| Step: 5
Training loss: 3.8858611583709717
Validation loss: 2.9403523655347925

Epoch: 6| Step: 6
Training loss: 2.683993101119995
Validation loss: 2.9359535299321657

Epoch: 6| Step: 7
Training loss: 2.7823171615600586
Validation loss: 2.936346438623244

Epoch: 6| Step: 8
Training loss: 2.060173988342285
Validation loss: 2.9374860230312554

Epoch: 6| Step: 9
Training loss: 3.705963134765625
Validation loss: 2.936633853502171

Epoch: 6| Step: 10
Training loss: 3.5766539573669434
Validation loss: 2.9347304849214453

Epoch: 6| Step: 11
Training loss: 2.551546573638916
Validation loss: 2.9349832073334725

Epoch: 6| Step: 12
Training loss: 2.8707759380340576
Validation loss: 2.93353848303518

Epoch: 6| Step: 13
Training loss: 2.0501370429992676
Validation loss: 2.9341973463694253

Epoch: 97| Step: 0
Training loss: 1.960956335067749
Validation loss: 2.9321009446215887

Epoch: 6| Step: 1
Training loss: 2.249785900115967
Validation loss: 2.9347492648709204

Epoch: 6| Step: 2
Training loss: 3.708080768585205
Validation loss: 2.93471678867135

Epoch: 6| Step: 3
Training loss: 3.143517017364502
Validation loss: 2.9370044713379233

Epoch: 6| Step: 4
Training loss: 2.4848721027374268
Validation loss: 2.938043463614679

Epoch: 6| Step: 5
Training loss: 3.8015639781951904
Validation loss: 2.9434923279669976

Epoch: 6| Step: 6
Training loss: 2.8145623207092285
Validation loss: 2.9493505390741492

Epoch: 6| Step: 7
Training loss: 2.3220560550689697
Validation loss: 2.951122599263345

Epoch: 6| Step: 8
Training loss: 3.058760643005371
Validation loss: 2.954545323566724

Epoch: 6| Step: 9
Training loss: 3.4674439430236816
Validation loss: 2.951691319865565

Epoch: 6| Step: 10
Training loss: 3.7864203453063965
Validation loss: 2.944382729068879

Epoch: 6| Step: 11
Training loss: 2.8408632278442383
Validation loss: 2.934261944986159

Epoch: 6| Step: 12
Training loss: 3.075510263442993
Validation loss: 2.9310619549084733

Epoch: 6| Step: 13
Training loss: 3.3594202995300293
Validation loss: 2.9306241773789927

Epoch: 98| Step: 0
Training loss: 2.231881856918335
Validation loss: 2.9307482396402667

Epoch: 6| Step: 1
Training loss: 2.9424970149993896
Validation loss: 2.9289247656381256

Epoch: 6| Step: 2
Training loss: 3.462724208831787
Validation loss: 2.9313485699315227

Epoch: 6| Step: 3
Training loss: 2.8151683807373047
Validation loss: 2.9323207921879266

Epoch: 6| Step: 4
Training loss: 2.743623733520508
Validation loss: 2.930857096948931

Epoch: 6| Step: 5
Training loss: 3.0619139671325684
Validation loss: 2.932892535322456

Epoch: 6| Step: 6
Training loss: 2.76387619972229
Validation loss: 2.93069794870192

Epoch: 6| Step: 7
Training loss: 2.304783821105957
Validation loss: 2.928605692360991

Epoch: 6| Step: 8
Training loss: 3.2306065559387207
Validation loss: 2.9330877206658803

Epoch: 6| Step: 9
Training loss: 3.4392220973968506
Validation loss: 2.931575523909702

Epoch: 6| Step: 10
Training loss: 3.4083938598632812
Validation loss: 2.930693298257807

Epoch: 6| Step: 11
Training loss: 2.8952746391296387
Validation loss: 2.931546570152365

Epoch: 6| Step: 12
Training loss: 3.5145225524902344
Validation loss: 2.9301414566655315

Epoch: 6| Step: 13
Training loss: 3.090823173522949
Validation loss: 2.9293746409877652

Epoch: 99| Step: 0
Training loss: 3.3599250316619873
Validation loss: 2.926301330648443

Epoch: 6| Step: 1
Training loss: 3.4329094886779785
Validation loss: 2.930319501507667

Epoch: 6| Step: 2
Training loss: 2.751741886138916
Validation loss: 2.9281635156241794

Epoch: 6| Step: 3
Training loss: 2.3760297298431396
Validation loss: 2.931588654877037

Epoch: 6| Step: 4
Training loss: 3.030137062072754
Validation loss: 2.928977809926515

Epoch: 6| Step: 5
Training loss: 3.375676155090332
Validation loss: 2.924391628593527

Epoch: 6| Step: 6
Training loss: 2.4984047412872314
Validation loss: 2.9260196608881794

Epoch: 6| Step: 7
Training loss: 3.304502010345459
Validation loss: 2.9264800728008313

Epoch: 6| Step: 8
Training loss: 2.739469051361084
Validation loss: 2.927103745040073

Epoch: 6| Step: 9
Training loss: 3.5028018951416016
Validation loss: 2.9259353196749123

Epoch: 6| Step: 10
Training loss: 2.6066770553588867
Validation loss: 2.9257581644160773

Epoch: 6| Step: 11
Training loss: 3.24513578414917
Validation loss: 2.925996672722601

Epoch: 6| Step: 12
Training loss: 2.699439764022827
Validation loss: 2.9254361352612896

Epoch: 6| Step: 13
Training loss: 2.700100898742676
Validation loss: 2.9250552333811277

Epoch: 100| Step: 0
Training loss: 3.6155471801757812
Validation loss: 2.924487767680999

Epoch: 6| Step: 1
Training loss: 3.171734094619751
Validation loss: 2.9248957223789667

Epoch: 6| Step: 2
Training loss: 1.983560562133789
Validation loss: 2.9234296275723364

Epoch: 6| Step: 3
Training loss: 2.402297258377075
Validation loss: 2.924812309203609

Epoch: 6| Step: 4
Training loss: 3.0915212631225586
Validation loss: 2.927588567938856

Epoch: 6| Step: 5
Training loss: 2.557755708694458
Validation loss: 2.931385709393409

Epoch: 6| Step: 6
Training loss: 3.9721412658691406
Validation loss: 2.940909493354059

Epoch: 6| Step: 7
Training loss: 2.6157798767089844
Validation loss: 2.9437858443106375

Epoch: 6| Step: 8
Training loss: 2.407820701599121
Validation loss: 2.9464976249202603

Epoch: 6| Step: 9
Training loss: 3.449924945831299
Validation loss: 2.9357729599040043

Epoch: 6| Step: 10
Training loss: 3.1269173622131348
Validation loss: 2.932182886267221

Epoch: 6| Step: 11
Training loss: 3.857182025909424
Validation loss: 2.9348059597835747

Epoch: 6| Step: 12
Training loss: 2.399050235748291
Validation loss: 2.926162850472235

Epoch: 6| Step: 13
Training loss: 3.174229621887207
Validation loss: 2.9204272993149294

Epoch: 101| Step: 0
Training loss: 3.3158700466156006
Validation loss: 2.923887360480524

Epoch: 6| Step: 1
Training loss: 3.890918016433716
Validation loss: 2.923062644979005

Epoch: 6| Step: 2
Training loss: 2.881772518157959
Validation loss: 2.920398532703359

Epoch: 6| Step: 3
Training loss: 2.8828659057617188
Validation loss: 2.921658395439066

Epoch: 6| Step: 4
Training loss: 2.4836044311523438
Validation loss: 2.92284361521403

Epoch: 6| Step: 5
Training loss: 2.626671075820923
Validation loss: 2.9212215946566675

Epoch: 6| Step: 6
Training loss: 1.9247145652770996
Validation loss: 2.923990257324711

Epoch: 6| Step: 7
Training loss: 3.3735597133636475
Validation loss: 2.9227329095204673

Epoch: 6| Step: 8
Training loss: 3.3185296058654785
Validation loss: 2.9237277789782454

Epoch: 6| Step: 9
Training loss: 3.3111395835876465
Validation loss: 2.9202342981933267

Epoch: 6| Step: 10
Training loss: 3.793346881866455
Validation loss: 2.920381207619944

Epoch: 6| Step: 11
Training loss: 2.354823350906372
Validation loss: 2.9220989955368863

Epoch: 6| Step: 12
Training loss: 2.8386178016662598
Validation loss: 2.92519014112411

Epoch: 6| Step: 13
Training loss: 2.6354057788848877
Validation loss: 2.921940818909676

Epoch: 102| Step: 0
Training loss: 2.590672016143799
Validation loss: 2.9208199183146157

Epoch: 6| Step: 1
Training loss: 3.243570566177368
Validation loss: 2.924118936702769

Epoch: 6| Step: 2
Training loss: 3.046140670776367
Validation loss: 2.9199315219797115

Epoch: 6| Step: 3
Training loss: 3.0768485069274902
Validation loss: 2.921113262894333

Epoch: 6| Step: 4
Training loss: 3.5626163482666016
Validation loss: 2.922224836964761

Epoch: 6| Step: 5
Training loss: 3.058310031890869
Validation loss: 2.9227161202379452

Epoch: 6| Step: 6
Training loss: 2.3401007652282715
Validation loss: 2.918882216176679

Epoch: 6| Step: 7
Training loss: 3.549431800842285
Validation loss: 2.9203992787227837

Epoch: 6| Step: 8
Training loss: 2.757965564727783
Validation loss: 2.9189815880149923

Epoch: 6| Step: 9
Training loss: 3.5251641273498535
Validation loss: 2.9186919043141026

Epoch: 6| Step: 10
Training loss: 3.2032222747802734
Validation loss: 2.916419844473562

Epoch: 6| Step: 11
Training loss: 2.7669808864593506
Validation loss: 2.914408637631324

Epoch: 6| Step: 12
Training loss: 2.2115519046783447
Validation loss: 2.920767148335775

Epoch: 6| Step: 13
Training loss: 2.600614547729492
Validation loss: 2.919981884699996

Epoch: 103| Step: 0
Training loss: 2.9995250701904297
Validation loss: 2.921987689951415

Epoch: 6| Step: 1
Training loss: 3.4249634742736816
Validation loss: 2.92113737393451

Epoch: 6| Step: 2
Training loss: 2.67651104927063
Validation loss: 2.921125845242572

Epoch: 6| Step: 3
Training loss: 3.4968345165252686
Validation loss: 2.919397364380539

Epoch: 6| Step: 4
Training loss: 3.1269819736480713
Validation loss: 2.918727518409811

Epoch: 6| Step: 5
Training loss: 2.961808919906616
Validation loss: 2.92139450452661

Epoch: 6| Step: 6
Training loss: 3.2315845489501953
Validation loss: 2.9152878356236283

Epoch: 6| Step: 7
Training loss: 2.6567981243133545
Validation loss: 2.919200684434624

Epoch: 6| Step: 8
Training loss: 2.950814723968506
Validation loss: 2.915777257693711

Epoch: 6| Step: 9
Training loss: 2.587639808654785
Validation loss: 2.915494400967834

Epoch: 6| Step: 10
Training loss: 3.4616191387176514
Validation loss: 2.9145930967023297

Epoch: 6| Step: 11
Training loss: 2.351911783218384
Validation loss: 2.915133576239309

Epoch: 6| Step: 12
Training loss: 3.2017624378204346
Validation loss: 2.915562588681457

Epoch: 6| Step: 13
Training loss: 2.177456855773926
Validation loss: 2.912877864735101

Epoch: 104| Step: 0
Training loss: 2.9683618545532227
Validation loss: 2.9124880477946293

Epoch: 6| Step: 1
Training loss: 3.4771041870117188
Validation loss: 2.9110093911488852

Epoch: 6| Step: 2
Training loss: 3.702507972717285
Validation loss: 2.9106490868394093

Epoch: 6| Step: 3
Training loss: 3.0168280601501465
Validation loss: 2.9135970941153904

Epoch: 6| Step: 4
Training loss: 2.955279588699341
Validation loss: 2.91183570379852

Epoch: 6| Step: 5
Training loss: 3.4651741981506348
Validation loss: 2.9135638283145044

Epoch: 6| Step: 6
Training loss: 2.736407518386841
Validation loss: 2.910451791619742

Epoch: 6| Step: 7
Training loss: 3.3989696502685547
Validation loss: 2.912454374374882

Epoch: 6| Step: 8
Training loss: 3.4462790489196777
Validation loss: 2.915760814502675

Epoch: 6| Step: 9
Training loss: 2.6940550804138184
Validation loss: 2.921644813270979

Epoch: 6| Step: 10
Training loss: 2.239964008331299
Validation loss: 2.9223582770234797

Epoch: 6| Step: 11
Training loss: 3.049060821533203
Validation loss: 2.9225360988288798

Epoch: 6| Step: 12
Training loss: 2.409910202026367
Validation loss: 2.924160921445457

Epoch: 6| Step: 13
Training loss: 1.5110880136489868
Validation loss: 2.9142620178960983

Epoch: 105| Step: 0
Training loss: 1.9335211515426636
Validation loss: 2.9134585216481197

Epoch: 6| Step: 1
Training loss: 2.665602445602417
Validation loss: 2.9125074442996772

Epoch: 6| Step: 2
Training loss: 3.710278272628784
Validation loss: 2.9126422584697766

Epoch: 6| Step: 3
Training loss: 3.106607675552368
Validation loss: 2.91403365647921

Epoch: 6| Step: 4
Training loss: 2.6174440383911133
Validation loss: 2.9161834280977965

Epoch: 6| Step: 5
Training loss: 2.8835506439208984
Validation loss: 2.9106689524906937

Epoch: 6| Step: 6
Training loss: 2.8107962608337402
Validation loss: 2.9100304982995473

Epoch: 6| Step: 7
Training loss: 2.3862361907958984
Validation loss: 2.9088336524143013

Epoch: 6| Step: 8
Training loss: 4.091611862182617
Validation loss: 2.9088572481627106

Epoch: 6| Step: 9
Training loss: 2.342538595199585
Validation loss: 2.909637625499438

Epoch: 6| Step: 10
Training loss: 3.317070245742798
Validation loss: 2.9040362014565417

Epoch: 6| Step: 11
Training loss: 3.1594979763031006
Validation loss: 2.907907949980869

Epoch: 6| Step: 12
Training loss: 3.4864091873168945
Validation loss: 2.909867363591348

Epoch: 6| Step: 13
Training loss: 3.158181667327881
Validation loss: 2.9121457197332896

Epoch: 106| Step: 0
Training loss: 3.353747844696045
Validation loss: 2.9118870971023396

Epoch: 6| Step: 1
Training loss: 2.829407215118408
Validation loss: 2.908505957613709

Epoch: 6| Step: 2
Training loss: 3.585280179977417
Validation loss: 2.9129488237442507

Epoch: 6| Step: 3
Training loss: 3.5707077980041504
Validation loss: 2.9170108226037796

Epoch: 6| Step: 4
Training loss: 2.6055819988250732
Validation loss: 2.9163836330495854

Epoch: 6| Step: 5
Training loss: 3.5446860790252686
Validation loss: 2.9220380142170894

Epoch: 6| Step: 6
Training loss: 2.9403138160705566
Validation loss: 2.922806980789349

Epoch: 6| Step: 7
Training loss: 2.4246487617492676
Validation loss: 2.917980742710893

Epoch: 6| Step: 8
Training loss: 4.1742658615112305
Validation loss: 2.915686550960746

Epoch: 6| Step: 9
Training loss: 3.1893601417541504
Validation loss: 2.908070138705674

Epoch: 6| Step: 10
Training loss: 2.552795886993408
Validation loss: 2.90490295040992

Epoch: 6| Step: 11
Training loss: 1.9728317260742188
Validation loss: 2.90689246244328

Epoch: 6| Step: 12
Training loss: 2.3147192001342773
Validation loss: 2.9044377855075303

Epoch: 6| Step: 13
Training loss: 2.281949281692505
Validation loss: 2.905592836359496

Epoch: 107| Step: 0
Training loss: 3.4116692543029785
Validation loss: 2.9053224850726385

Epoch: 6| Step: 1
Training loss: 3.1140270233154297
Validation loss: 2.90727481021676

Epoch: 6| Step: 2
Training loss: 3.685028553009033
Validation loss: 2.906840980693858

Epoch: 6| Step: 3
Training loss: 2.721954345703125
Validation loss: 2.9068085839671474

Epoch: 6| Step: 4
Training loss: 3.3180887699127197
Validation loss: 2.9037336149523334

Epoch: 6| Step: 5
Training loss: 2.910243034362793
Validation loss: 2.9071105654521654

Epoch: 6| Step: 6
Training loss: 3.754629611968994
Validation loss: 2.904791485878729

Epoch: 6| Step: 7
Training loss: 2.678701877593994
Validation loss: 2.9051278355301067

Epoch: 6| Step: 8
Training loss: 2.994011640548706
Validation loss: 2.9042836850689304

Epoch: 6| Step: 9
Training loss: 2.3448500633239746
Validation loss: 2.9044395364740843

Epoch: 6| Step: 10
Training loss: 2.5541648864746094
Validation loss: 2.9014627036227973

Epoch: 6| Step: 11
Training loss: 2.6786680221557617
Validation loss: 2.901447529433876

Epoch: 6| Step: 12
Training loss: 3.2835841178894043
Validation loss: 2.9016961154117378

Epoch: 6| Step: 13
Training loss: 1.460432529449463
Validation loss: 2.9071255422407583

Epoch: 108| Step: 0
Training loss: 2.367767333984375
Validation loss: 2.9029351229308755

Epoch: 6| Step: 1
Training loss: 2.402487277984619
Validation loss: 2.9061340849886657

Epoch: 6| Step: 2
Training loss: 3.4174423217773438
Validation loss: 2.9083909885857695

Epoch: 6| Step: 3
Training loss: 3.7484798431396484
Validation loss: 2.905488519258397

Epoch: 6| Step: 4
Training loss: 2.8506650924682617
Validation loss: 2.907896957089824

Epoch: 6| Step: 5
Training loss: 2.5365381240844727
Validation loss: 2.905898899160406

Epoch: 6| Step: 6
Training loss: 4.485982418060303
Validation loss: 2.901971822143883

Epoch: 6| Step: 7
Training loss: 2.580256462097168
Validation loss: 2.900533419783397

Epoch: 6| Step: 8
Training loss: 2.5551180839538574
Validation loss: 2.9014650724267446

Epoch: 6| Step: 9
Training loss: 2.366053581237793
Validation loss: 2.897585250998056

Epoch: 6| Step: 10
Training loss: 3.072831630706787
Validation loss: 2.896338193647323

Epoch: 6| Step: 11
Training loss: 3.6305246353149414
Validation loss: 2.8961081427912556

Epoch: 6| Step: 12
Training loss: 3.181694507598877
Validation loss: 2.897272832932011

Epoch: 6| Step: 13
Training loss: 1.8414998054504395
Validation loss: 2.898325571449854

Epoch: 109| Step: 0
Training loss: 2.859145402908325
Validation loss: 2.896193145423807

Epoch: 6| Step: 1
Training loss: 3.1551666259765625
Validation loss: 2.894959718950333

Epoch: 6| Step: 2
Training loss: 1.679416298866272
Validation loss: 2.898443627101119

Epoch: 6| Step: 3
Training loss: 2.73551607131958
Validation loss: 2.8997434646852556

Epoch: 6| Step: 4
Training loss: 3.6056501865386963
Validation loss: 2.898599878434212

Epoch: 6| Step: 5
Training loss: 2.9111366271972656
Validation loss: 2.897402519820839

Epoch: 6| Step: 6
Training loss: 3.1275506019592285
Validation loss: 2.8971703719067317

Epoch: 6| Step: 7
Training loss: 3.5085935592651367
Validation loss: 2.899360054282732

Epoch: 6| Step: 8
Training loss: 2.7540388107299805
Validation loss: 2.896167834599813

Epoch: 6| Step: 9
Training loss: 2.6163439750671387
Validation loss: 2.8955120630161737

Epoch: 6| Step: 10
Training loss: 3.087336540222168
Validation loss: 2.895046918622909

Epoch: 6| Step: 11
Training loss: 3.35547137260437
Validation loss: 2.9016399075908046

Epoch: 6| Step: 12
Training loss: 2.909184455871582
Validation loss: 2.904492055216143

Epoch: 6| Step: 13
Training loss: 3.3958966732025146
Validation loss: 2.9134506743441344

Epoch: 110| Step: 0
Training loss: 2.9700286388397217
Validation loss: 2.9225312612390004

Epoch: 6| Step: 1
Training loss: 2.7834293842315674
Validation loss: 2.9159303890761508

Epoch: 6| Step: 2
Training loss: 3.495853900909424
Validation loss: 2.917251420277421

Epoch: 6| Step: 3
Training loss: 2.605182647705078
Validation loss: 2.914448648370722

Epoch: 6| Step: 4
Training loss: 3.3571033477783203
Validation loss: 2.897884420169297

Epoch: 6| Step: 5
Training loss: 2.3942654132843018
Validation loss: 2.896233130526799

Epoch: 6| Step: 6
Training loss: 3.333977222442627
Validation loss: 2.8933569513341433

Epoch: 6| Step: 7
Training loss: 2.645080804824829
Validation loss: 2.8925300490471626

Epoch: 6| Step: 8
Training loss: 3.2787954807281494
Validation loss: 2.8932455226939213

Epoch: 6| Step: 9
Training loss: 2.9580821990966797
Validation loss: 2.8931582102211575

Epoch: 6| Step: 10
Training loss: 2.5624377727508545
Validation loss: 2.8907473984585015

Epoch: 6| Step: 11
Training loss: 2.838165521621704
Validation loss: 2.8926303848143546

Epoch: 6| Step: 12
Training loss: 3.3253982067108154
Validation loss: 2.893913681789111

Epoch: 6| Step: 13
Training loss: 3.088836908340454
Validation loss: 2.8928076938916276

Epoch: 111| Step: 0
Training loss: 3.04425048828125
Validation loss: 2.893142156703498

Epoch: 6| Step: 1
Training loss: 3.1454102993011475
Validation loss: 2.8929474635790755

Epoch: 6| Step: 2
Training loss: 2.596409320831299
Validation loss: 2.8895880047992994

Epoch: 6| Step: 3
Training loss: 2.758082151412964
Validation loss: 2.8917317031532206

Epoch: 6| Step: 4
Training loss: 3.036255121231079
Validation loss: 2.8938007944373676

Epoch: 6| Step: 5
Training loss: 2.8015260696411133
Validation loss: 2.891299045214089

Epoch: 6| Step: 6
Training loss: 3.588876724243164
Validation loss: 2.8919691680580057

Epoch: 6| Step: 7
Training loss: 2.9170196056365967
Validation loss: 2.892938913837556

Epoch: 6| Step: 8
Training loss: 2.3280510902404785
Validation loss: 2.8917038081794657

Epoch: 6| Step: 9
Training loss: 2.5515294075012207
Validation loss: 2.891481540536368

Epoch: 6| Step: 10
Training loss: 3.026275396347046
Validation loss: 2.8907795285665863

Epoch: 6| Step: 11
Training loss: 2.995260000228882
Validation loss: 2.892294632491245

Epoch: 6| Step: 12
Training loss: 2.828291416168213
Validation loss: 2.8893208221722673

Epoch: 6| Step: 13
Training loss: 4.512231826782227
Validation loss: 2.89324442801937

Epoch: 112| Step: 0
Training loss: 2.990837574005127
Validation loss: 2.8895995386185183

Epoch: 6| Step: 1
Training loss: 2.99749755859375
Validation loss: 2.892201274953863

Epoch: 6| Step: 2
Training loss: 2.5194132328033447
Validation loss: 2.8886315720055693

Epoch: 6| Step: 3
Training loss: 3.100468635559082
Validation loss: 2.8909711914677776

Epoch: 6| Step: 4
Training loss: 2.7737553119659424
Validation loss: 2.890415555687361

Epoch: 6| Step: 5
Training loss: 2.9194576740264893
Validation loss: 2.8884112117111043

Epoch: 6| Step: 6
Training loss: 3.336090087890625
Validation loss: 2.8915759363482074

Epoch: 6| Step: 7
Training loss: 2.1726644039154053
Validation loss: 2.8862684465223745

Epoch: 6| Step: 8
Training loss: 3.3313169479370117
Validation loss: 2.887346952192245

Epoch: 6| Step: 9
Training loss: 4.026921272277832
Validation loss: 2.8873625442545903

Epoch: 6| Step: 10
Training loss: 3.3882672786712646
Validation loss: 2.8890458358231412

Epoch: 6| Step: 11
Training loss: 2.0765819549560547
Validation loss: 2.885801781890213

Epoch: 6| Step: 12
Training loss: 2.4929513931274414
Validation loss: 2.8848043821191274

Epoch: 6| Step: 13
Training loss: 3.5110862255096436
Validation loss: 2.885623508884061

Epoch: 113| Step: 0
Training loss: 2.1337080001831055
Validation loss: 2.886487612160303

Epoch: 6| Step: 1
Training loss: 3.576653003692627
Validation loss: 2.886665677511564

Epoch: 6| Step: 2
Training loss: 2.4802024364471436
Validation loss: 2.8875835198228077

Epoch: 6| Step: 3
Training loss: 3.2007110118865967
Validation loss: 2.8846912948034142

Epoch: 6| Step: 4
Training loss: 3.144066333770752
Validation loss: 2.883917890569215

Epoch: 6| Step: 5
Training loss: 2.4241111278533936
Validation loss: 2.884710755399478

Epoch: 6| Step: 6
Training loss: 3.383427381515503
Validation loss: 2.883743868079237

Epoch: 6| Step: 7
Training loss: 3.3952808380126953
Validation loss: 2.883822669265091

Epoch: 6| Step: 8
Training loss: 2.686774730682373
Validation loss: 2.883112399808822

Epoch: 6| Step: 9
Training loss: 2.7992630004882812
Validation loss: 2.8854514603973715

Epoch: 6| Step: 10
Training loss: 3.0605034828186035
Validation loss: 2.880070896558864

Epoch: 6| Step: 11
Training loss: 2.9614510536193848
Validation loss: 2.882615996945289

Epoch: 6| Step: 12
Training loss: 2.935500383377075
Validation loss: 2.8827741786997807

Epoch: 6| Step: 13
Training loss: 3.355287790298462
Validation loss: 2.8796996198674685

Epoch: 114| Step: 0
Training loss: 3.055168628692627
Validation loss: 2.8813458232469458

Epoch: 6| Step: 1
Training loss: 3.0786142349243164
Validation loss: 2.8801343312827488

Epoch: 6| Step: 2
Training loss: 2.6524815559387207
Validation loss: 2.8798578221310853

Epoch: 6| Step: 3
Training loss: 2.316802740097046
Validation loss: 2.876977446258709

Epoch: 6| Step: 4
Training loss: 2.1113901138305664
Validation loss: 2.881624416638446

Epoch: 6| Step: 5
Training loss: 2.8888039588928223
Validation loss: 2.8795076108747915

Epoch: 6| Step: 6
Training loss: 2.687060594558716
Validation loss: 2.8807892004648843

Epoch: 6| Step: 7
Training loss: 3.7068912982940674
Validation loss: 2.8792277407902542

Epoch: 6| Step: 8
Training loss: 2.867126226425171
Validation loss: 2.879036864926738

Epoch: 6| Step: 9
Training loss: 4.526601791381836
Validation loss: 2.8787016766045683

Epoch: 6| Step: 10
Training loss: 2.1453464031219482
Validation loss: 2.880781283942602

Epoch: 6| Step: 11
Training loss: 2.954763412475586
Validation loss: 2.880288867540257

Epoch: 6| Step: 12
Training loss: 2.7862768173217773
Validation loss: 2.881269972811463

Epoch: 6| Step: 13
Training loss: 3.9688501358032227
Validation loss: 2.8797937721334477

Epoch: 115| Step: 0
Training loss: 2.84250807762146
Validation loss: 2.883685532436576

Epoch: 6| Step: 1
Training loss: 3.4338595867156982
Validation loss: 2.8790416512438046

Epoch: 6| Step: 2
Training loss: 2.3194732666015625
Validation loss: 2.877559144009826

Epoch: 6| Step: 3
Training loss: 2.757817268371582
Validation loss: 2.879189234907909

Epoch: 6| Step: 4
Training loss: 2.802891969680786
Validation loss: 2.8828056602067846

Epoch: 6| Step: 5
Training loss: 1.904439091682434
Validation loss: 2.8807999754464753

Epoch: 6| Step: 6
Training loss: 3.489454984664917
Validation loss: 2.8785860615391887

Epoch: 6| Step: 7
Training loss: 3.444429397583008
Validation loss: 2.8819262930141982

Epoch: 6| Step: 8
Training loss: 3.9009008407592773
Validation loss: 2.879946195951072

Epoch: 6| Step: 9
Training loss: 2.8667640686035156
Validation loss: 2.8797507875709125

Epoch: 6| Step: 10
Training loss: 3.2549781799316406
Validation loss: 2.878874430092432

Epoch: 6| Step: 11
Training loss: 2.864647150039673
Validation loss: 2.8828269922605125

Epoch: 6| Step: 12
Training loss: 2.9046669006347656
Validation loss: 2.8824504831785798

Epoch: 6| Step: 13
Training loss: 1.999266505241394
Validation loss: 2.8824974439477407

Epoch: 116| Step: 0
Training loss: 2.894094467163086
Validation loss: 2.8857902660164783

Epoch: 6| Step: 1
Training loss: 2.2701869010925293
Validation loss: 2.893898758836972

Epoch: 6| Step: 2
Training loss: 2.616154670715332
Validation loss: 2.897158756051012

Epoch: 6| Step: 3
Training loss: 3.107060432434082
Validation loss: 2.8898636961496003

Epoch: 6| Step: 4
Training loss: 2.230454444885254
Validation loss: 2.8942823358761367

Epoch: 6| Step: 5
Training loss: 3.6169321537017822
Validation loss: 2.884073411264727

Epoch: 6| Step: 6
Training loss: 2.1563191413879395
Validation loss: 2.8879193849461053

Epoch: 6| Step: 7
Training loss: 2.9743423461914062
Validation loss: 2.8801355515756915

Epoch: 6| Step: 8
Training loss: 2.8239665031433105
Validation loss: 2.8797143197828725

Epoch: 6| Step: 9
Training loss: 2.529252529144287
Validation loss: 2.8776434185684368

Epoch: 6| Step: 10
Training loss: 3.3318746089935303
Validation loss: 2.8745959958722516

Epoch: 6| Step: 11
Training loss: 3.434446334838867
Validation loss: 2.872754796858757

Epoch: 6| Step: 12
Training loss: 4.10813045501709
Validation loss: 2.8723744141158236

Epoch: 6| Step: 13
Training loss: 3.3108956813812256
Validation loss: 2.874467570294616

Epoch: 117| Step: 0
Training loss: 3.187837600708008
Validation loss: 2.8710694338685725

Epoch: 6| Step: 1
Training loss: 1.9741898775100708
Validation loss: 2.872216596398302

Epoch: 6| Step: 2
Training loss: 2.3500399589538574
Validation loss: 2.87040570218076

Epoch: 6| Step: 3
Training loss: 2.4543986320495605
Validation loss: 2.871936398167764

Epoch: 6| Step: 4
Training loss: 3.902247428894043
Validation loss: 2.8741751486255276

Epoch: 6| Step: 5
Training loss: 2.7228152751922607
Validation loss: 2.874000069915607

Epoch: 6| Step: 6
Training loss: 2.7799253463745117
Validation loss: 2.8692660741908576

Epoch: 6| Step: 7
Training loss: 3.3800556659698486
Validation loss: 2.873924380989485

Epoch: 6| Step: 8
Training loss: 3.4181013107299805
Validation loss: 2.8726983096009944

Epoch: 6| Step: 9
Training loss: 3.141340494155884
Validation loss: 2.87184505052464

Epoch: 6| Step: 10
Training loss: 3.955869197845459
Validation loss: 2.873702674783686

Epoch: 6| Step: 11
Training loss: 2.710724353790283
Validation loss: 2.8735381352004183

Epoch: 6| Step: 12
Training loss: 2.161175489425659
Validation loss: 2.8738106630181752

Epoch: 6| Step: 13
Training loss: 3.113220453262329
Validation loss: 2.874973230464484

Epoch: 118| Step: 0
Training loss: 3.7669262886047363
Validation loss: 2.87044257502402

Epoch: 6| Step: 1
Training loss: 2.1259522438049316
Validation loss: 2.87095199349106

Epoch: 6| Step: 2
Training loss: 3.031999349594116
Validation loss: 2.8740010851172992

Epoch: 6| Step: 3
Training loss: 2.510969638824463
Validation loss: 2.870837370554606

Epoch: 6| Step: 4
Training loss: 2.714461326599121
Validation loss: 2.8694355718551146

Epoch: 6| Step: 5
Training loss: 2.5929009914398193
Validation loss: 2.8700224250875492

Epoch: 6| Step: 6
Training loss: 3.4067258834838867
Validation loss: 2.868794879605693

Epoch: 6| Step: 7
Training loss: 2.73732328414917
Validation loss: 2.868995920304329

Epoch: 6| Step: 8
Training loss: 3.065634250640869
Validation loss: 2.8659010112926526

Epoch: 6| Step: 9
Training loss: 3.5408096313476562
Validation loss: 2.867149955482893

Epoch: 6| Step: 10
Training loss: 3.7209954261779785
Validation loss: 2.866671992886451

Epoch: 6| Step: 11
Training loss: 2.5337586402893066
Validation loss: 2.8677419462511615

Epoch: 6| Step: 12
Training loss: 2.281569242477417
Validation loss: 2.8657941433691208

Epoch: 6| Step: 13
Training loss: 3.267167329788208
Validation loss: 2.868466641313286

Epoch: 119| Step: 0
Training loss: 3.4185969829559326
Validation loss: 2.8652185470827165

Epoch: 6| Step: 1
Training loss: 3.9181249141693115
Validation loss: 2.8671027152769026

Epoch: 6| Step: 2
Training loss: 2.7798655033111572
Validation loss: 2.865210635687715

Epoch: 6| Step: 3
Training loss: 2.1187357902526855
Validation loss: 2.866836832415673

Epoch: 6| Step: 4
Training loss: 2.455610752105713
Validation loss: 2.867227013393115

Epoch: 6| Step: 5
Training loss: 2.6833741664886475
Validation loss: 2.8659245506409676

Epoch: 6| Step: 6
Training loss: 3.8624138832092285
Validation loss: 2.8650940566934566

Epoch: 6| Step: 7
Training loss: 3.522292375564575
Validation loss: 2.8661383300699215

Epoch: 6| Step: 8
Training loss: 2.2773261070251465
Validation loss: 2.8650749678252847

Epoch: 6| Step: 9
Training loss: 2.142468214035034
Validation loss: 2.8663046744561966

Epoch: 6| Step: 10
Training loss: 2.9778103828430176
Validation loss: 2.8690970559273996

Epoch: 6| Step: 11
Training loss: 3.1582233905792236
Validation loss: 2.8728940153634674

Epoch: 6| Step: 12
Training loss: 2.7387475967407227
Validation loss: 2.8735073074217765

Epoch: 6| Step: 13
Training loss: 3.1400539875030518
Validation loss: 2.8740469537755495

Epoch: 120| Step: 0
Training loss: 3.6898040771484375
Validation loss: 2.8672131261517926

Epoch: 6| Step: 1
Training loss: 2.3852546215057373
Validation loss: 2.8670308923208587

Epoch: 6| Step: 2
Training loss: 3.1588540077209473
Validation loss: 2.86227072182522

Epoch: 6| Step: 3
Training loss: 2.9788684844970703
Validation loss: 2.8642281639960503

Epoch: 6| Step: 4
Training loss: 2.275902509689331
Validation loss: 2.8632290722221456

Epoch: 6| Step: 5
Training loss: 3.354124069213867
Validation loss: 2.8623884313849994

Epoch: 6| Step: 6
Training loss: 2.9320778846740723
Validation loss: 2.8648626676169773

Epoch: 6| Step: 7
Training loss: 2.5713937282562256
Validation loss: 2.863760276507306

Epoch: 6| Step: 8
Training loss: 2.3687589168548584
Validation loss: 2.8625919408695673

Epoch: 6| Step: 9
Training loss: 2.7540881633758545
Validation loss: 2.8644019544765515

Epoch: 6| Step: 10
Training loss: 3.0919792652130127
Validation loss: 2.8615847838822233

Epoch: 6| Step: 11
Training loss: 2.994223117828369
Validation loss: 2.8635358041332615

Epoch: 6| Step: 12
Training loss: 3.986111640930176
Validation loss: 2.8614792029062905

Epoch: 6| Step: 13
Training loss: 2.2412140369415283
Validation loss: 2.858370050307243

Epoch: 121| Step: 0
Training loss: 2.58457350730896
Validation loss: 2.8618455753531507

Epoch: 6| Step: 1
Training loss: 3.9484951496124268
Validation loss: 2.862703989910823

Epoch: 6| Step: 2
Training loss: 2.43880033493042
Validation loss: 2.863947206927884

Epoch: 6| Step: 3
Training loss: 3.5869040489196777
Validation loss: 2.862865658216579

Epoch: 6| Step: 4
Training loss: 2.1470117568969727
Validation loss: 2.874480216733871

Epoch: 6| Step: 5
Training loss: 3.3632569313049316
Validation loss: 2.8707707825527398

Epoch: 6| Step: 6
Training loss: 2.8618111610412598
Validation loss: 2.87126906969214

Epoch: 6| Step: 7
Training loss: 2.247894763946533
Validation loss: 2.8693134323243172

Epoch: 6| Step: 8
Training loss: 3.5262598991394043
Validation loss: 2.8679009432433755

Epoch: 6| Step: 9
Training loss: 3.114999771118164
Validation loss: 2.8623530454533075

Epoch: 6| Step: 10
Training loss: 3.0320706367492676
Validation loss: 2.8593179769413446

Epoch: 6| Step: 11
Training loss: 2.479731798171997
Validation loss: 2.856502281722202

Epoch: 6| Step: 12
Training loss: 2.839667320251465
Validation loss: 2.856803601787936

Epoch: 6| Step: 13
Training loss: 2.9901676177978516
Validation loss: 2.858426196600801

Epoch: 122| Step: 0
Training loss: 3.1987688541412354
Validation loss: 2.8588595159592165

Epoch: 6| Step: 1
Training loss: 2.5605287551879883
Validation loss: 2.859380499009163

Epoch: 6| Step: 2
Training loss: 3.0704309940338135
Validation loss: 2.8590658198120775

Epoch: 6| Step: 3
Training loss: 2.643378496170044
Validation loss: 2.8600493015781527

Epoch: 6| Step: 4
Training loss: 2.9503979682922363
Validation loss: 2.8612009812426824

Epoch: 6| Step: 5
Training loss: 3.2765111923217773
Validation loss: 2.860137213942825

Epoch: 6| Step: 6
Training loss: 2.79733943939209
Validation loss: 2.8564583127216627

Epoch: 6| Step: 7
Training loss: 2.959141731262207
Validation loss: 2.8587142626444497

Epoch: 6| Step: 8
Training loss: 3.131756067276001
Validation loss: 2.8565087292784

Epoch: 6| Step: 9
Training loss: 2.0886285305023193
Validation loss: 2.85623864717381

Epoch: 6| Step: 10
Training loss: 2.7980494499206543
Validation loss: 2.856450834581929

Epoch: 6| Step: 11
Training loss: 3.7290310859680176
Validation loss: 2.861360062835037

Epoch: 6| Step: 12
Training loss: 3.1880884170532227
Validation loss: 2.859623065558813

Epoch: 6| Step: 13
Training loss: 2.658940553665161
Validation loss: 2.8619763517892487

Epoch: 123| Step: 0
Training loss: 2.8799400329589844
Validation loss: 2.8623052258645334

Epoch: 6| Step: 1
Training loss: 2.2735209465026855
Validation loss: 2.8627893309439383

Epoch: 6| Step: 2
Training loss: 2.709731101989746
Validation loss: 2.86589825794261

Epoch: 6| Step: 3
Training loss: 2.7795846462249756
Validation loss: 2.862969894562998

Epoch: 6| Step: 4
Training loss: 3.27065110206604
Validation loss: 2.859280035059939

Epoch: 6| Step: 5
Training loss: 3.2409040927886963
Validation loss: 2.853215076590097

Epoch: 6| Step: 6
Training loss: 2.4736714363098145
Validation loss: 2.855737909193962

Epoch: 6| Step: 7
Training loss: 2.9251604080200195
Validation loss: 2.8521689522650933

Epoch: 6| Step: 8
Training loss: 2.635850429534912
Validation loss: 2.856530809915194

Epoch: 6| Step: 9
Training loss: 3.5845279693603516
Validation loss: 2.8533012661882626

Epoch: 6| Step: 10
Training loss: 2.9841644763946533
Validation loss: 2.852752880383563

Epoch: 6| Step: 11
Training loss: 3.409101724624634
Validation loss: 2.852952770007554

Epoch: 6| Step: 12
Training loss: 3.1675539016723633
Validation loss: 2.8541568351048294

Epoch: 6| Step: 13
Training loss: 2.6076314449310303
Validation loss: 2.850009295248216

Epoch: 124| Step: 0
Training loss: 3.4214415550231934
Validation loss: 2.852187959096765

Epoch: 6| Step: 1
Training loss: 2.849949359893799
Validation loss: 2.852368441961145

Epoch: 6| Step: 2
Training loss: 2.460576057434082
Validation loss: 2.8511709936203493

Epoch: 6| Step: 3
Training loss: 2.597832441329956
Validation loss: 2.851028073218561

Epoch: 6| Step: 4
Training loss: 2.527935266494751
Validation loss: 2.851765778756911

Epoch: 6| Step: 5
Training loss: 2.666857957839966
Validation loss: 2.8520508632865003

Epoch: 6| Step: 6
Training loss: 2.167571544647217
Validation loss: 2.8533185681989117

Epoch: 6| Step: 7
Training loss: 2.54827880859375
Validation loss: 2.8544625184869252

Epoch: 6| Step: 8
Training loss: 3.587545871734619
Validation loss: 2.8611355289336173

Epoch: 6| Step: 9
Training loss: 2.9853663444519043
Validation loss: 2.8578520692804807

Epoch: 6| Step: 10
Training loss: 3.5685014724731445
Validation loss: 2.8565900325775146

Epoch: 6| Step: 11
Training loss: 3.1170570850372314
Validation loss: 2.8529266952186503

Epoch: 6| Step: 12
Training loss: 3.4791226387023926
Validation loss: 2.8521290517622426

Epoch: 6| Step: 13
Training loss: 3.1431498527526855
Validation loss: 2.8599840953785884

Epoch: 125| Step: 0
Training loss: 2.8558077812194824
Validation loss: 2.85957682260903

Epoch: 6| Step: 1
Training loss: 3.0906572341918945
Validation loss: 2.8534314914416243

Epoch: 6| Step: 2
Training loss: 2.0879123210906982
Validation loss: 2.8550377866273284

Epoch: 6| Step: 3
Training loss: 3.8795228004455566
Validation loss: 2.8469379486576205

Epoch: 6| Step: 4
Training loss: 2.655261516571045
Validation loss: 2.8497774113890944

Epoch: 6| Step: 5
Training loss: 2.6032748222351074
Validation loss: 2.8491660958977154

Epoch: 6| Step: 6
Training loss: 2.4687836170196533
Validation loss: 2.8460349229074295

Epoch: 6| Step: 7
Training loss: 3.303062677383423
Validation loss: 2.849267557103147

Epoch: 6| Step: 8
Training loss: 2.8249638080596924
Validation loss: 2.8482767458884948

Epoch: 6| Step: 9
Training loss: 1.917628288269043
Validation loss: 2.8478760104025564

Epoch: 6| Step: 10
Training loss: 3.554938316345215
Validation loss: 2.849193614016297

Epoch: 6| Step: 11
Training loss: 3.4297969341278076
Validation loss: 2.8487658423762166

Epoch: 6| Step: 12
Training loss: 3.1977860927581787
Validation loss: 2.846546370496032

Epoch: 6| Step: 13
Training loss: 3.3576364517211914
Validation loss: 2.847818236197195

Epoch: 126| Step: 0
Training loss: 2.1886982917785645
Validation loss: 2.848396760161205

Epoch: 6| Step: 1
Training loss: 3.1208648681640625
Validation loss: 2.8457884070693806

Epoch: 6| Step: 2
Training loss: 2.446587085723877
Validation loss: 2.848864716868247

Epoch: 6| Step: 3
Training loss: 3.3663597106933594
Validation loss: 2.847936584103492

Epoch: 6| Step: 4
Training loss: 2.710275650024414
Validation loss: 2.8503550047515542

Epoch: 6| Step: 5
Training loss: 2.985980987548828
Validation loss: 2.853602268362558

Epoch: 6| Step: 6
Training loss: 3.653172254562378
Validation loss: 2.863311490704936

Epoch: 6| Step: 7
Training loss: 2.380727767944336
Validation loss: 2.8612563648531513

Epoch: 6| Step: 8
Training loss: 3.2416162490844727
Validation loss: 2.858147441699941

Epoch: 6| Step: 9
Training loss: 2.5434844493865967
Validation loss: 2.8632944912038822

Epoch: 6| Step: 10
Training loss: 3.105863094329834
Validation loss: 2.875155738604966

Epoch: 6| Step: 11
Training loss: 3.409055233001709
Validation loss: 2.868457914680563

Epoch: 6| Step: 12
Training loss: 2.9569268226623535
Validation loss: 2.860878029177266

Epoch: 6| Step: 13
Training loss: 2.8551316261291504
Validation loss: 2.85046362620528

Epoch: 127| Step: 0
Training loss: 2.36867618560791
Validation loss: 2.85130133680118

Epoch: 6| Step: 1
Training loss: 2.802051067352295
Validation loss: 2.8497423894943728

Epoch: 6| Step: 2
Training loss: 2.776719808578491
Validation loss: 2.85075899862474

Epoch: 6| Step: 3
Training loss: 2.5525455474853516
Validation loss: 2.848992775845271

Epoch: 6| Step: 4
Training loss: 3.4239466190338135
Validation loss: 2.8462428995358047

Epoch: 6| Step: 5
Training loss: 3.1843795776367188
Validation loss: 2.8486402291123585

Epoch: 6| Step: 6
Training loss: 3.532170295715332
Validation loss: 2.8475960275178314

Epoch: 6| Step: 7
Training loss: 3.029531478881836
Validation loss: 2.8461098312049784

Epoch: 6| Step: 8
Training loss: 2.6669347286224365
Validation loss: 2.8475247788172897

Epoch: 6| Step: 9
Training loss: 2.4395751953125
Validation loss: 2.849451699564534

Epoch: 6| Step: 10
Training loss: 3.7912206649780273
Validation loss: 2.8441015417857836

Epoch: 6| Step: 11
Training loss: 3.1971216201782227
Validation loss: 2.850574121680311

Epoch: 6| Step: 12
Training loss: 2.688192367553711
Validation loss: 2.8553319490084084

Epoch: 6| Step: 13
Training loss: 2.138362407684326
Validation loss: 2.854527024812596

Epoch: 128| Step: 0
Training loss: 2.418998956680298
Validation loss: 2.863709029331002

Epoch: 6| Step: 1
Training loss: 2.4415438175201416
Validation loss: 2.869556103983233

Epoch: 6| Step: 2
Training loss: 3.4571642875671387
Validation loss: 2.8619211104608353

Epoch: 6| Step: 3
Training loss: 2.2133021354675293
Validation loss: 2.8464040064042613

Epoch: 6| Step: 4
Training loss: 4.183662414550781
Validation loss: 2.845450537179106

Epoch: 6| Step: 5
Training loss: 3.592036724090576
Validation loss: 2.8443106502614994

Epoch: 6| Step: 6
Training loss: 2.6598803997039795
Validation loss: 2.844751868196713

Epoch: 6| Step: 7
Training loss: 2.9751765727996826
Validation loss: 2.8444397167492936

Epoch: 6| Step: 8
Training loss: 2.8402295112609863
Validation loss: 2.8424545206049436

Epoch: 6| Step: 9
Training loss: 3.4895682334899902
Validation loss: 2.845263860558951

Epoch: 6| Step: 10
Training loss: 2.4169487953186035
Validation loss: 2.845193588605491

Epoch: 6| Step: 11
Training loss: 2.68023943901062
Validation loss: 2.84575153422612

Epoch: 6| Step: 12
Training loss: 2.536022663116455
Validation loss: 2.84675774523007

Epoch: 6| Step: 13
Training loss: 3.0623185634613037
Validation loss: 2.844207748290031

Epoch: 129| Step: 0
Training loss: 3.1457204818725586
Validation loss: 2.842013171924058

Epoch: 6| Step: 1
Training loss: 3.090745449066162
Validation loss: 2.8458013688364336

Epoch: 6| Step: 2
Training loss: 2.75376558303833
Validation loss: 2.8427243719818773

Epoch: 6| Step: 3
Training loss: 3.0128872394561768
Validation loss: 2.8396763827211116

Epoch: 6| Step: 4
Training loss: 2.0576858520507812
Validation loss: 2.8410561110383723

Epoch: 6| Step: 5
Training loss: 3.386612892150879
Validation loss: 2.837645382009527

Epoch: 6| Step: 6
Training loss: 2.8672778606414795
Validation loss: 2.8402171519494828

Epoch: 6| Step: 7
Training loss: 2.681684970855713
Validation loss: 2.841004192188222

Epoch: 6| Step: 8
Training loss: 4.268865585327148
Validation loss: 2.838750575178413

Epoch: 6| Step: 9
Training loss: 2.803105354309082
Validation loss: 2.839037820857058

Epoch: 6| Step: 10
Training loss: 2.986353635787964
Validation loss: 2.8391014350357877

Epoch: 6| Step: 11
Training loss: 3.2593913078308105
Validation loss: 2.8456012074665358

Epoch: 6| Step: 12
Training loss: 2.0359671115875244
Validation loss: 2.8429097257634646

Epoch: 6| Step: 13
Training loss: 2.2807421684265137
Validation loss: 2.83979038012925

Epoch: 130| Step: 0
Training loss: 3.3992462158203125
Validation loss: 2.842178544690532

Epoch: 6| Step: 1
Training loss: 2.9238202571868896
Validation loss: 2.8387608835774083

Epoch: 6| Step: 2
Training loss: 3.0280261039733887
Validation loss: 2.839939166140813

Epoch: 6| Step: 3
Training loss: 3.1594927310943604
Validation loss: 2.8379272978792907

Epoch: 6| Step: 4
Training loss: 2.5717899799346924
Validation loss: 2.83603976362495

Epoch: 6| Step: 5
Training loss: 2.6677498817443848
Validation loss: 2.836571314001596

Epoch: 6| Step: 6
Training loss: 3.202054977416992
Validation loss: 2.8346459993752102

Epoch: 6| Step: 7
Training loss: 3.0235612392425537
Validation loss: 2.8365531300985687

Epoch: 6| Step: 8
Training loss: 2.97100830078125
Validation loss: 2.832998796175885

Epoch: 6| Step: 9
Training loss: 2.9489293098449707
Validation loss: 2.834139193257978

Epoch: 6| Step: 10
Training loss: 2.4005746841430664
Validation loss: 2.8355307732858965

Epoch: 6| Step: 11
Training loss: 2.4792943000793457
Validation loss: 2.834149714439146

Epoch: 6| Step: 12
Training loss: 3.2541723251342773
Validation loss: 2.834370638734551

Epoch: 6| Step: 13
Training loss: 2.813917875289917
Validation loss: 2.8357855632740963

Epoch: 131| Step: 0
Training loss: 3.5481531620025635
Validation loss: 2.839149039278748

Epoch: 6| Step: 1
Training loss: 3.868657112121582
Validation loss: 2.8393655669304634

Epoch: 6| Step: 2
Training loss: 2.6728572845458984
Validation loss: 2.8451223014503397

Epoch: 6| Step: 3
Training loss: 2.4775266647338867
Validation loss: 2.8408286007501746

Epoch: 6| Step: 4
Training loss: 2.77121639251709
Validation loss: 2.844156329349805

Epoch: 6| Step: 5
Training loss: 3.6436054706573486
Validation loss: 2.833706545573409

Epoch: 6| Step: 6
Training loss: 1.6565525531768799
Validation loss: 2.836295138123215

Epoch: 6| Step: 7
Training loss: 2.3617305755615234
Validation loss: 2.835070909992341

Epoch: 6| Step: 8
Training loss: 3.3514890670776367
Validation loss: 2.840557380389142

Epoch: 6| Step: 9
Training loss: 3.0307722091674805
Validation loss: 2.834784789751935

Epoch: 6| Step: 10
Training loss: 3.633983612060547
Validation loss: 2.833150484228647

Epoch: 6| Step: 11
Training loss: 2.2730321884155273
Validation loss: 2.8353450452127764

Epoch: 6| Step: 12
Training loss: 2.7916369438171387
Validation loss: 2.835084069159723

Epoch: 6| Step: 13
Training loss: 2.6745870113372803
Validation loss: 2.834161030348911

Epoch: 132| Step: 0
Training loss: 2.8499269485473633
Validation loss: 2.834385082285891

Epoch: 6| Step: 1
Training loss: 2.8041601181030273
Validation loss: 2.8305071912786013

Epoch: 6| Step: 2
Training loss: 3.912368059158325
Validation loss: 2.838028371974986

Epoch: 6| Step: 3
Training loss: 2.910269021987915
Validation loss: 2.836225325061429

Epoch: 6| Step: 4
Training loss: 2.7664430141448975
Validation loss: 2.8324534021398073

Epoch: 6| Step: 5
Training loss: 2.7031145095825195
Validation loss: 2.83451219015224

Epoch: 6| Step: 6
Training loss: 2.832735300064087
Validation loss: 2.8363239329348326

Epoch: 6| Step: 7
Training loss: 3.121232271194458
Validation loss: 2.8302072889061383

Epoch: 6| Step: 8
Training loss: 3.1088123321533203
Validation loss: 2.8319036345328055

Epoch: 6| Step: 9
Training loss: 2.109736680984497
Validation loss: 2.831952589814381

Epoch: 6| Step: 10
Training loss: 2.071443557739258
Validation loss: 2.8332210535644204

Epoch: 6| Step: 11
Training loss: 2.787728786468506
Validation loss: 2.8306894276731756

Epoch: 6| Step: 12
Training loss: 3.0556070804595947
Validation loss: 2.8296003418584026

Epoch: 6| Step: 13
Training loss: 4.444463729858398
Validation loss: 2.8300490097333024

Epoch: 133| Step: 0
Training loss: 3.0958287715911865
Validation loss: 2.831490557680848

Epoch: 6| Step: 1
Training loss: 2.2685747146606445
Validation loss: 2.8307441280734156

Epoch: 6| Step: 2
Training loss: 2.082374334335327
Validation loss: 2.830382280452277

Epoch: 6| Step: 3
Training loss: 3.0889739990234375
Validation loss: 2.8283483956449773

Epoch: 6| Step: 4
Training loss: 2.4602184295654297
Validation loss: 2.82794984181722

Epoch: 6| Step: 5
Training loss: 2.943594217300415
Validation loss: 2.829306125640869

Epoch: 6| Step: 6
Training loss: 3.5914182662963867
Validation loss: 2.826256577686597

Epoch: 6| Step: 7
Training loss: 2.926527976989746
Validation loss: 2.829108691984607

Epoch: 6| Step: 8
Training loss: 2.96176815032959
Validation loss: 2.8292589905441448

Epoch: 6| Step: 9
Training loss: 3.734961986541748
Validation loss: 2.8296298826894453

Epoch: 6| Step: 10
Training loss: 3.1757616996765137
Validation loss: 2.8273801983043714

Epoch: 6| Step: 11
Training loss: 3.2632217407226562
Validation loss: 2.8292501382930304

Epoch: 6| Step: 12
Training loss: 2.1602346897125244
Validation loss: 2.8280469525244927

Epoch: 6| Step: 13
Training loss: 3.0401601791381836
Validation loss: 2.8257855753744803

Epoch: 134| Step: 0
Training loss: 3.1241605281829834
Validation loss: 2.829672831361012

Epoch: 6| Step: 1
Training loss: 2.5080928802490234
Validation loss: 2.828072359485011

Epoch: 6| Step: 2
Training loss: 3.3106513023376465
Validation loss: 2.8268899456147225

Epoch: 6| Step: 3
Training loss: 3.708695411682129
Validation loss: 2.825287967599848

Epoch: 6| Step: 4
Training loss: 2.727694034576416
Validation loss: 2.8236361754837858

Epoch: 6| Step: 5
Training loss: 3.059933662414551
Validation loss: 2.825222925473285

Epoch: 6| Step: 6
Training loss: 2.4382851123809814
Validation loss: 2.8236611043253252

Epoch: 6| Step: 7
Training loss: 3.4526944160461426
Validation loss: 2.8256601056744977

Epoch: 6| Step: 8
Training loss: 2.5786471366882324
Validation loss: 2.828933428692561

Epoch: 6| Step: 9
Training loss: 2.7135848999023438
Validation loss: 2.826387277213476

Epoch: 6| Step: 10
Training loss: 2.4526376724243164
Validation loss: 2.828575595732658

Epoch: 6| Step: 11
Training loss: 3.165113687515259
Validation loss: 2.8246658027813

Epoch: 6| Step: 12
Training loss: 2.656169891357422
Validation loss: 2.8231656910270773

Epoch: 6| Step: 13
Training loss: 2.816352128982544
Validation loss: 2.8239055833508893

Epoch: 135| Step: 0
Training loss: 3.199831485748291
Validation loss: 2.8255951173843874

Epoch: 6| Step: 1
Training loss: 2.689990997314453
Validation loss: 2.8292948353675103

Epoch: 6| Step: 2
Training loss: 2.836987018585205
Validation loss: 2.838894098035751

Epoch: 6| Step: 3
Training loss: 3.8037800788879395
Validation loss: 2.834871015241069

Epoch: 6| Step: 4
Training loss: 3.069415807723999
Validation loss: 2.8459466477876068

Epoch: 6| Step: 5
Training loss: 3.2187061309814453
Validation loss: 2.8474095059979345

Epoch: 6| Step: 6
Training loss: 2.6322553157806396
Validation loss: 2.8479921638324694

Epoch: 6| Step: 7
Training loss: 2.1937308311462402
Validation loss: 2.840735771322763

Epoch: 6| Step: 8
Training loss: 3.3278117179870605
Validation loss: 2.8360176573517504

Epoch: 6| Step: 9
Training loss: 3.027387857437134
Validation loss: 2.8270761633432038

Epoch: 6| Step: 10
Training loss: 2.742480516433716
Validation loss: 2.826399664725027

Epoch: 6| Step: 11
Training loss: 3.066094160079956
Validation loss: 2.8298597387088242

Epoch: 6| Step: 12
Training loss: 1.910353183746338
Validation loss: 2.8277267973910094

Epoch: 6| Step: 13
Training loss: 3.2460532188415527
Validation loss: 2.8238813774560088

Epoch: 136| Step: 0
Training loss: 3.32706356048584
Validation loss: 2.8244845636429323

Epoch: 6| Step: 1
Training loss: 2.1744906902313232
Validation loss: 2.8257124834163214

Epoch: 6| Step: 2
Training loss: 1.5136768817901611
Validation loss: 2.8262755717000654

Epoch: 6| Step: 3
Training loss: 3.1195895671844482
Validation loss: 2.828336379861319

Epoch: 6| Step: 4
Training loss: 3.229571580886841
Validation loss: 2.828464754166142

Epoch: 6| Step: 5
Training loss: 2.4928743839263916
Validation loss: 2.8281271816581808

Epoch: 6| Step: 6
Training loss: 3.491539478302002
Validation loss: 2.8309483553773616

Epoch: 6| Step: 7
Training loss: 2.136406898498535
Validation loss: 2.83002540116669

Epoch: 6| Step: 8
Training loss: 3.4804515838623047
Validation loss: 2.825380702172556

Epoch: 6| Step: 9
Training loss: 2.649122714996338
Validation loss: 2.8210925132997575

Epoch: 6| Step: 10
Training loss: 3.2935307025909424
Validation loss: 2.8234574666587253

Epoch: 6| Step: 11
Training loss: 3.354104518890381
Validation loss: 2.8200218369883876

Epoch: 6| Step: 12
Training loss: 3.69665265083313
Validation loss: 2.8188876644257577

Epoch: 6| Step: 13
Training loss: 2.6196699142456055
Validation loss: 2.820235521562638

Epoch: 137| Step: 0
Training loss: 1.9208998680114746
Validation loss: 2.8207257460522395

Epoch: 6| Step: 1
Training loss: 2.399627685546875
Validation loss: 2.8233278002790225

Epoch: 6| Step: 2
Training loss: 3.1318483352661133
Validation loss: 2.81877532569311

Epoch: 6| Step: 3
Training loss: 3.026796340942383
Validation loss: 2.824018737321259

Epoch: 6| Step: 4
Training loss: 2.6915111541748047
Validation loss: 2.8202829130234255

Epoch: 6| Step: 5
Training loss: 3.7353484630584717
Validation loss: 2.8184975295938473

Epoch: 6| Step: 6
Training loss: 2.885843276977539
Validation loss: 2.8196276669861167

Epoch: 6| Step: 7
Training loss: 2.3775134086608887
Validation loss: 2.8206009326442594

Epoch: 6| Step: 8
Training loss: 2.6688132286071777
Validation loss: 2.8186009442934425

Epoch: 6| Step: 9
Training loss: 3.4911789894104004
Validation loss: 2.8180507434311735

Epoch: 6| Step: 10
Training loss: 2.588045835494995
Validation loss: 2.8203100491595525

Epoch: 6| Step: 11
Training loss: 3.3328566551208496
Validation loss: 2.8176634029675554

Epoch: 6| Step: 12
Training loss: 3.3185930252075195
Validation loss: 2.8150569187697543

Epoch: 6| Step: 13
Training loss: 3.2396481037139893
Validation loss: 2.816199548782841

Epoch: 138| Step: 0
Training loss: 3.5267534255981445
Validation loss: 2.81659193705487

Epoch: 6| Step: 1
Training loss: 2.41611385345459
Validation loss: 2.8156701313552035

Epoch: 6| Step: 2
Training loss: 2.838496208190918
Validation loss: 2.816156023292131

Epoch: 6| Step: 3
Training loss: 2.0953149795532227
Validation loss: 2.817729324422857

Epoch: 6| Step: 4
Training loss: 3.2082509994506836
Validation loss: 2.8149005366909887

Epoch: 6| Step: 5
Training loss: 2.828176736831665
Validation loss: 2.8159165613112913

Epoch: 6| Step: 6
Training loss: 2.811697483062744
Validation loss: 2.8153604897119666

Epoch: 6| Step: 7
Training loss: 2.5241448879241943
Validation loss: 2.8161763427078084

Epoch: 6| Step: 8
Training loss: 2.2731494903564453
Validation loss: 2.817491151953256

Epoch: 6| Step: 9
Training loss: 4.070647716522217
Validation loss: 2.8160661523060133

Epoch: 6| Step: 10
Training loss: 3.9391939640045166
Validation loss: 2.814582734979609

Epoch: 6| Step: 11
Training loss: 2.1951332092285156
Validation loss: 2.8157650527133735

Epoch: 6| Step: 12
Training loss: 3.299184560775757
Validation loss: 2.8143634462869294

Epoch: 6| Step: 13
Training loss: 2.359623908996582
Validation loss: 2.814094776748329

Epoch: 139| Step: 0
Training loss: 2.8295609951019287
Validation loss: 2.812365106357041

Epoch: 6| Step: 1
Training loss: 3.250950813293457
Validation loss: 2.8174984301290205

Epoch: 6| Step: 2
Training loss: 2.856215000152588
Validation loss: 2.8151804990665887

Epoch: 6| Step: 3
Training loss: 2.9186112880706787
Validation loss: 2.813763436450753

Epoch: 6| Step: 4
Training loss: 3.3110687732696533
Validation loss: 2.8141653537750244

Epoch: 6| Step: 5
Training loss: 2.966928005218506
Validation loss: 2.8153176128223376

Epoch: 6| Step: 6
Training loss: 2.2697319984436035
Validation loss: 2.814629670112364

Epoch: 6| Step: 7
Training loss: 2.482306957244873
Validation loss: 2.814982639845981

Epoch: 6| Step: 8
Training loss: 3.6612329483032227
Validation loss: 2.8171662797210035

Epoch: 6| Step: 9
Training loss: 3.5310587882995605
Validation loss: 2.8142903492014897

Epoch: 6| Step: 10
Training loss: 2.7038516998291016
Validation loss: 2.812614656263782

Epoch: 6| Step: 11
Training loss: 3.0518765449523926
Validation loss: 2.8133153530859176

Epoch: 6| Step: 12
Training loss: 2.171670436859131
Validation loss: 2.810799632021176

Epoch: 6| Step: 13
Training loss: 2.454503059387207
Validation loss: 2.810563861682851

Epoch: 140| Step: 0
Training loss: 2.837320327758789
Validation loss: 2.811075366953368

Epoch: 6| Step: 1
Training loss: 3.6582868099212646
Validation loss: 2.812250360365837

Epoch: 6| Step: 2
Training loss: 3.1911072731018066
Validation loss: 2.811801761709234

Epoch: 6| Step: 3
Training loss: 1.9411150217056274
Validation loss: 2.810133654584167

Epoch: 6| Step: 4
Training loss: 2.6309187412261963
Validation loss: 2.8136341187261764

Epoch: 6| Step: 5
Training loss: 2.839590311050415
Validation loss: 2.8173870783980175

Epoch: 6| Step: 6
Training loss: 3.5913407802581787
Validation loss: 2.8130818720786803

Epoch: 6| Step: 7
Training loss: 2.859971523284912
Validation loss: 2.810954498988326

Epoch: 6| Step: 8
Training loss: 1.9986107349395752
Validation loss: 2.8124423847403577

Epoch: 6| Step: 9
Training loss: 3.346320390701294
Validation loss: 2.8188762485340075

Epoch: 6| Step: 10
Training loss: 3.7211732864379883
Validation loss: 2.809766661736273

Epoch: 6| Step: 11
Training loss: 2.4293529987335205
Validation loss: 2.8110614438210764

Epoch: 6| Step: 12
Training loss: 3.233699083328247
Validation loss: 2.8090474605560303

Epoch: 6| Step: 13
Training loss: 1.823750615119934
Validation loss: 2.8087059426051315

Epoch: 141| Step: 0
Training loss: 3.4375381469726562
Validation loss: 2.810336682104295

Epoch: 6| Step: 1
Training loss: 2.1550064086914062
Validation loss: 2.810806756378502

Epoch: 6| Step: 2
Training loss: 3.0283970832824707
Validation loss: 2.811986159252864

Epoch: 6| Step: 3
Training loss: 3.5808639526367188
Validation loss: 2.8122999052847586

Epoch: 6| Step: 4
Training loss: 3.3210203647613525
Validation loss: 2.8123657805945284

Epoch: 6| Step: 5
Training loss: 1.7882564067840576
Validation loss: 2.8100901701117076

Epoch: 6| Step: 6
Training loss: 3.1007518768310547
Validation loss: 2.81115226335423

Epoch: 6| Step: 7
Training loss: 3.329272508621216
Validation loss: 2.8139127428813646

Epoch: 6| Step: 8
Training loss: 2.9759366512298584
Validation loss: 2.8119085578508276

Epoch: 6| Step: 9
Training loss: 2.933110475540161
Validation loss: 2.8125704232082573

Epoch: 6| Step: 10
Training loss: 3.7876503467559814
Validation loss: 2.8108646074930825

Epoch: 6| Step: 11
Training loss: 1.7828712463378906
Validation loss: 2.8101538842724216

Epoch: 6| Step: 12
Training loss: 2.6860361099243164
Validation loss: 2.808552316440049

Epoch: 6| Step: 13
Training loss: 2.5252621173858643
Validation loss: 2.8087771349055792

Epoch: 142| Step: 0
Training loss: 2.6837515830993652
Validation loss: 2.804947691579019

Epoch: 6| Step: 1
Training loss: 3.297104835510254
Validation loss: 2.805541382041029

Epoch: 6| Step: 2
Training loss: 2.392181396484375
Validation loss: 2.8031306010420605

Epoch: 6| Step: 3
Training loss: 2.7232353687286377
Validation loss: 2.8065906980986237

Epoch: 6| Step: 4
Training loss: 1.9616224765777588
Validation loss: 2.8045569927461687

Epoch: 6| Step: 5
Training loss: 2.0819082260131836
Validation loss: 2.8032143808180288

Epoch: 6| Step: 6
Training loss: 3.200446605682373
Validation loss: 2.8059724761593725

Epoch: 6| Step: 7
Training loss: 2.617556095123291
Validation loss: 2.805658350708664

Epoch: 6| Step: 8
Training loss: 2.9374732971191406
Validation loss: 2.80392002290295

Epoch: 6| Step: 9
Training loss: 4.2939605712890625
Validation loss: 2.8086243931965162

Epoch: 6| Step: 10
Training loss: 2.6836397647857666
Validation loss: 2.804715676974225

Epoch: 6| Step: 11
Training loss: 3.472303867340088
Validation loss: 2.804896910985311

Epoch: 6| Step: 12
Training loss: 3.4464359283447266
Validation loss: 2.8068186826603387

Epoch: 6| Step: 13
Training loss: 2.6701173782348633
Validation loss: 2.8147676247422413

Epoch: 143| Step: 0
Training loss: 2.967845916748047
Validation loss: 2.8134871580267466

Epoch: 6| Step: 1
Training loss: 2.4687209129333496
Validation loss: 2.8129053474754415

Epoch: 6| Step: 2
Training loss: 2.925673246383667
Validation loss: 2.815986810191985

Epoch: 6| Step: 3
Training loss: 2.4116923809051514
Validation loss: 2.809071053740799

Epoch: 6| Step: 4
Training loss: 3.0464935302734375
Validation loss: 2.8161559720193186

Epoch: 6| Step: 5
Training loss: 3.616665840148926
Validation loss: 2.808900066601333

Epoch: 6| Step: 6
Training loss: 2.906299114227295
Validation loss: 2.808304273954002

Epoch: 6| Step: 7
Training loss: 2.937591791152954
Validation loss: 2.805772581408101

Epoch: 6| Step: 8
Training loss: 2.94012188911438
Validation loss: 2.806406113409227

Epoch: 6| Step: 9
Training loss: 2.8735361099243164
Validation loss: 2.8030438730793614

Epoch: 6| Step: 10
Training loss: 3.068666934967041
Validation loss: 2.8082726847740913

Epoch: 6| Step: 11
Training loss: 1.9209606647491455
Validation loss: 2.8060870580775763

Epoch: 6| Step: 12
Training loss: 3.6922824382781982
Validation loss: 2.807831992385208

Epoch: 6| Step: 13
Training loss: 2.660423755645752
Validation loss: 2.8061190933309574

Epoch: 144| Step: 0
Training loss: 2.3865854740142822
Validation loss: 2.804161794724003

Epoch: 6| Step: 1
Training loss: 1.76498544216156
Validation loss: 2.8059638751450406

Epoch: 6| Step: 2
Training loss: 3.4783706665039062
Validation loss: 2.8041600591392926

Epoch: 6| Step: 3
Training loss: 2.453932523727417
Validation loss: 2.8024510209278395

Epoch: 6| Step: 4
Training loss: 3.315366268157959
Validation loss: 2.803985680303266

Epoch: 6| Step: 5
Training loss: 3.208719253540039
Validation loss: 2.8042076223640033

Epoch: 6| Step: 6
Training loss: 2.921147346496582
Validation loss: 2.8047257443910003

Epoch: 6| Step: 7
Training loss: 2.458188533782959
Validation loss: 2.80355788559042

Epoch: 6| Step: 8
Training loss: 3.8551440238952637
Validation loss: 2.8033742212480113

Epoch: 6| Step: 9
Training loss: 3.511460781097412
Validation loss: 2.8069076050994215

Epoch: 6| Step: 10
Training loss: 3.4609570503234863
Validation loss: 2.8041334690586215

Epoch: 6| Step: 11
Training loss: 2.1787853240966797
Validation loss: 2.8074481359092136

Epoch: 6| Step: 12
Training loss: 2.251039505004883
Validation loss: 2.806483643029326

Epoch: 6| Step: 13
Training loss: 3.532700538635254
Validation loss: 2.8043954141678347

Epoch: 145| Step: 0
Training loss: 3.041079044342041
Validation loss: 2.8015565231282222

Epoch: 6| Step: 1
Training loss: 1.915633201599121
Validation loss: 2.806741335058725

Epoch: 6| Step: 2
Training loss: 3.241936206817627
Validation loss: 2.802320303455476

Epoch: 6| Step: 3
Training loss: 2.386873245239258
Validation loss: 2.8043719312196136

Epoch: 6| Step: 4
Training loss: 3.160383701324463
Validation loss: 2.802002409453033

Epoch: 6| Step: 5
Training loss: 2.9957432746887207
Validation loss: 2.8009292489738873

Epoch: 6| Step: 6
Training loss: 3.219313383102417
Validation loss: 2.8022681615685903

Epoch: 6| Step: 7
Training loss: 2.696469306945801
Validation loss: 2.801516450861449

Epoch: 6| Step: 8
Training loss: 2.9639406204223633
Validation loss: 2.8040518658135527

Epoch: 6| Step: 9
Training loss: 3.7487030029296875
Validation loss: 2.799660223786549

Epoch: 6| Step: 10
Training loss: 2.526216506958008
Validation loss: 2.801338290655485

Epoch: 6| Step: 11
Training loss: 2.8374288082122803
Validation loss: 2.79978439628437

Epoch: 6| Step: 12
Training loss: 2.460866689682007
Validation loss: 2.8027847607930503

Epoch: 6| Step: 13
Training loss: 3.5722224712371826
Validation loss: 2.797989268456736

Epoch: 146| Step: 0
Training loss: 3.8718743324279785
Validation loss: 2.7997088201584353

Epoch: 6| Step: 1
Training loss: 1.9132006168365479
Validation loss: 2.79816678262526

Epoch: 6| Step: 2
Training loss: 2.743955135345459
Validation loss: 2.804483611096618

Epoch: 6| Step: 3
Training loss: 1.8566311597824097
Validation loss: 2.7992164934835126

Epoch: 6| Step: 4
Training loss: 3.033210039138794
Validation loss: 2.799859513518631

Epoch: 6| Step: 5
Training loss: 2.8322958946228027
Validation loss: 2.79840334000126

Epoch: 6| Step: 6
Training loss: 2.7721266746520996
Validation loss: 2.7969534422761653

Epoch: 6| Step: 7
Training loss: 2.483546733856201
Validation loss: 2.801382956966277

Epoch: 6| Step: 8
Training loss: 3.336655855178833
Validation loss: 2.800310222051477

Epoch: 6| Step: 9
Training loss: 2.6430141925811768
Validation loss: 2.7992792437153478

Epoch: 6| Step: 10
Training loss: 3.3918843269348145
Validation loss: 2.803517162158925

Epoch: 6| Step: 11
Training loss: 2.947361946105957
Validation loss: 2.8054099108583186

Epoch: 6| Step: 12
Training loss: 3.598109245300293
Validation loss: 2.802696684355377

Epoch: 6| Step: 13
Training loss: 3.100402355194092
Validation loss: 2.802425589612735

Epoch: 147| Step: 0
Training loss: 3.137728214263916
Validation loss: 2.8016710025008007

Epoch: 6| Step: 1
Training loss: 3.3923306465148926
Validation loss: 2.800439903813024

Epoch: 6| Step: 2
Training loss: 2.719890594482422
Validation loss: 2.7986839945598314

Epoch: 6| Step: 3
Training loss: 3.6771063804626465
Validation loss: 2.7955665229469218

Epoch: 6| Step: 4
Training loss: 2.5306625366210938
Validation loss: 2.7973522755407516

Epoch: 6| Step: 5
Training loss: 1.9165165424346924
Validation loss: 2.796754483253725

Epoch: 6| Step: 6
Training loss: 3.4604170322418213
Validation loss: 2.7955601548635833

Epoch: 6| Step: 7
Training loss: 2.583120822906494
Validation loss: 2.7982666005370436

Epoch: 6| Step: 8
Training loss: 3.285281181335449
Validation loss: 2.7977848129887737

Epoch: 6| Step: 9
Training loss: 4.2316179275512695
Validation loss: 2.797124703725179

Epoch: 6| Step: 10
Training loss: 1.5720160007476807
Validation loss: 2.798241476858816

Epoch: 6| Step: 11
Training loss: 3.0035929679870605
Validation loss: 2.796497109115765

Epoch: 6| Step: 12
Training loss: 2.0908901691436768
Validation loss: 2.7958083742408344

Epoch: 6| Step: 13
Training loss: 2.708131790161133
Validation loss: 2.798226187306066

Epoch: 148| Step: 0
Training loss: 2.7474331855773926
Validation loss: 2.796411665537024

Epoch: 6| Step: 1
Training loss: 3.002077102661133
Validation loss: 2.793945156117921

Epoch: 6| Step: 2
Training loss: 2.7643625736236572
Validation loss: 2.796158221460158

Epoch: 6| Step: 3
Training loss: 2.808022975921631
Validation loss: 2.7929439954860236

Epoch: 6| Step: 4
Training loss: 3.001509666442871
Validation loss: 2.793297965039489

Epoch: 6| Step: 5
Training loss: 3.438948631286621
Validation loss: 2.793532927831014

Epoch: 6| Step: 6
Training loss: 2.4726450443267822
Validation loss: 2.793006573953936

Epoch: 6| Step: 7
Training loss: 3.302260398864746
Validation loss: 2.793033328107608

Epoch: 6| Step: 8
Training loss: 3.1253318786621094
Validation loss: 2.793537314220141

Epoch: 6| Step: 9
Training loss: 1.7769391536712646
Validation loss: 2.7913072237404446

Epoch: 6| Step: 10
Training loss: 3.4464714527130127
Validation loss: 2.792317041786768

Epoch: 6| Step: 11
Training loss: 2.9730100631713867
Validation loss: 2.792653806747929

Epoch: 6| Step: 12
Training loss: 2.6191654205322266
Validation loss: 2.7942365933490056

Epoch: 6| Step: 13
Training loss: 2.939840078353882
Validation loss: 2.799008471991426

Epoch: 149| Step: 0
Training loss: 2.1615381240844727
Validation loss: 2.7959366177999847

Epoch: 6| Step: 1
Training loss: 2.93113374710083
Validation loss: 2.8057280048247306

Epoch: 6| Step: 2
Training loss: 2.9688291549682617
Validation loss: 2.8113929097370436

Epoch: 6| Step: 3
Training loss: 3.366729736328125
Validation loss: 2.806756611793272

Epoch: 6| Step: 4
Training loss: 2.999035358428955
Validation loss: 2.8014287974244807

Epoch: 6| Step: 5
Training loss: 3.710303783416748
Validation loss: 2.790744314911545

Epoch: 6| Step: 6
Training loss: 3.42262601852417
Validation loss: 2.7922293114405807

Epoch: 6| Step: 7
Training loss: 3.8143248558044434
Validation loss: 2.790535398708877

Epoch: 6| Step: 8
Training loss: 1.5695189237594604
Validation loss: 2.789402707930534

Epoch: 6| Step: 9
Training loss: 2.8797454833984375
Validation loss: 2.7895471049893286

Epoch: 6| Step: 10
Training loss: 2.523560047149658
Validation loss: 2.7888495742633777

Epoch: 6| Step: 11
Training loss: 1.4093663692474365
Validation loss: 2.791147303837602

Epoch: 6| Step: 12
Training loss: 3.633312702178955
Validation loss: 2.7886388071121706

Epoch: 6| Step: 13
Training loss: 3.0756397247314453
Validation loss: 2.789333733179236

Epoch: 150| Step: 0
Training loss: 2.3482792377471924
Validation loss: 2.7891446646823677

Epoch: 6| Step: 1
Training loss: 2.9632203578948975
Validation loss: 2.792393672850824

Epoch: 6| Step: 2
Training loss: 2.593165397644043
Validation loss: 2.793952147165934

Epoch: 6| Step: 3
Training loss: 2.115975856781006
Validation loss: 2.789363971320532

Epoch: 6| Step: 4
Training loss: 3.481421947479248
Validation loss: 2.7893582544019146

Epoch: 6| Step: 5
Training loss: 3.259950637817383
Validation loss: 2.7870963183782433

Epoch: 6| Step: 6
Training loss: 2.8205747604370117
Validation loss: 2.7858099501620055

Epoch: 6| Step: 7
Training loss: 3.689757823944092
Validation loss: 2.7865666497138237

Epoch: 6| Step: 8
Training loss: 3.0918126106262207
Validation loss: 2.7862930195305937

Epoch: 6| Step: 9
Training loss: 3.4344210624694824
Validation loss: 2.7862630941534556

Epoch: 6| Step: 10
Training loss: 2.571016311645508
Validation loss: 2.7893761409226285

Epoch: 6| Step: 11
Training loss: 2.737312078475952
Validation loss: 2.7861248421412643

Epoch: 6| Step: 12
Training loss: 2.8512234687805176
Validation loss: 2.7876921161528556

Epoch: 6| Step: 13
Training loss: 1.9448697566986084
Validation loss: 2.785921296765727

Epoch: 151| Step: 0
Training loss: 4.034997940063477
Validation loss: 2.7864073194483274

Epoch: 6| Step: 1
Training loss: 3.3380982875823975
Validation loss: 2.7859345661696566

Epoch: 6| Step: 2
Training loss: 1.466605544090271
Validation loss: 2.784727173466836

Epoch: 6| Step: 3
Training loss: 2.567247152328491
Validation loss: 2.7890659557875765

Epoch: 6| Step: 4
Training loss: 3.0770530700683594
Validation loss: 2.785755249761766

Epoch: 6| Step: 5
Training loss: 2.6050214767456055
Validation loss: 2.7902854642560406

Epoch: 6| Step: 6
Training loss: 2.888129949569702
Validation loss: 2.7850894005067888

Epoch: 6| Step: 7
Training loss: 3.238542079925537
Validation loss: 2.783523726206954

Epoch: 6| Step: 8
Training loss: 2.7818470001220703
Validation loss: 2.785045293069655

Epoch: 6| Step: 9
Training loss: 2.469099998474121
Validation loss: 2.7816164160287506

Epoch: 6| Step: 10
Training loss: 3.387946128845215
Validation loss: 2.7833697052412134

Epoch: 6| Step: 11
Training loss: 2.8107025623321533
Validation loss: 2.7841766444585656

Epoch: 6| Step: 12
Training loss: 2.257500171661377
Validation loss: 2.7834960235062467

Epoch: 6| Step: 13
Training loss: 3.7550435066223145
Validation loss: 2.7823316974024617

Epoch: 152| Step: 0
Training loss: 2.7889909744262695
Validation loss: 2.7853519352533485

Epoch: 6| Step: 1
Training loss: 3.134908437728882
Validation loss: 2.789793893855105

Epoch: 6| Step: 2
Training loss: 2.906723976135254
Validation loss: 2.7873484037255727

Epoch: 6| Step: 3
Training loss: 2.545321226119995
Validation loss: 2.790924759321315

Epoch: 6| Step: 4
Training loss: 2.569059133529663
Validation loss: 2.787021113980201

Epoch: 6| Step: 5
Training loss: 3.7638802528381348
Validation loss: 2.788169741630554

Epoch: 6| Step: 6
Training loss: 3.847517967224121
Validation loss: 2.7887265169492332

Epoch: 6| Step: 7
Training loss: 2.9204137325286865
Validation loss: 2.7819080686056488

Epoch: 6| Step: 8
Training loss: 3.3039333820343018
Validation loss: 2.7837598170003583

Epoch: 6| Step: 9
Training loss: 2.41312313079834
Validation loss: 2.7824243371204664

Epoch: 6| Step: 10
Training loss: 2.314944267272949
Validation loss: 2.784503536839639

Epoch: 6| Step: 11
Training loss: 2.1966216564178467
Validation loss: 2.78267990901906

Epoch: 6| Step: 12
Training loss: 3.355128288269043
Validation loss: 2.7814715036781887

Epoch: 6| Step: 13
Training loss: 1.748033046722412
Validation loss: 2.7809324443981214

Epoch: 153| Step: 0
Training loss: 2.9099924564361572
Validation loss: 2.784758367846089

Epoch: 6| Step: 1
Training loss: 2.7716870307922363
Validation loss: 2.7868539928108134

Epoch: 6| Step: 2
Training loss: 3.544794797897339
Validation loss: 2.7897692111230667

Epoch: 6| Step: 3
Training loss: 3.4446487426757812
Validation loss: 2.7866299601011377

Epoch: 6| Step: 4
Training loss: 2.439727306365967
Validation loss: 2.786065637424428

Epoch: 6| Step: 5
Training loss: 2.253845691680908
Validation loss: 2.78456009844298

Epoch: 6| Step: 6
Training loss: 2.167555809020996
Validation loss: 2.7813241507417414

Epoch: 6| Step: 7
Training loss: 3.360222816467285
Validation loss: 2.78151770048244

Epoch: 6| Step: 8
Training loss: 3.1347858905792236
Validation loss: 2.779377450225174

Epoch: 6| Step: 9
Training loss: 3.1006312370300293
Validation loss: 2.779611118378178

Epoch: 6| Step: 10
Training loss: 3.6282615661621094
Validation loss: 2.77890101299491

Epoch: 6| Step: 11
Training loss: 2.1385841369628906
Validation loss: 2.7841927646308817

Epoch: 6| Step: 12
Training loss: 2.4472696781158447
Validation loss: 2.779525469708186

Epoch: 6| Step: 13
Training loss: 2.9743878841400146
Validation loss: 2.7804796849527667

Epoch: 154| Step: 0
Training loss: 2.5193216800689697
Validation loss: 2.7821879156174196

Epoch: 6| Step: 1
Training loss: 3.3806400299072266
Validation loss: 2.783419347578479

Epoch: 6| Step: 2
Training loss: 2.287332057952881
Validation loss: 2.7785085119226927

Epoch: 6| Step: 3
Training loss: 3.3825478553771973
Validation loss: 2.776245850388722

Epoch: 6| Step: 4
Training loss: 3.4182686805725098
Validation loss: 2.7787288158170638

Epoch: 6| Step: 5
Training loss: 2.2265658378601074
Validation loss: 2.7782971141158894

Epoch: 6| Step: 6
Training loss: 2.7996230125427246
Validation loss: 2.780203791074855

Epoch: 6| Step: 7
Training loss: 2.6805026531219482
Validation loss: 2.778634176459364

Epoch: 6| Step: 8
Training loss: 3.020022392272949
Validation loss: 2.780122931285571

Epoch: 6| Step: 9
Training loss: 2.279675245285034
Validation loss: 2.779916958142352

Epoch: 6| Step: 10
Training loss: 4.028158187866211
Validation loss: 2.778309274745244

Epoch: 6| Step: 11
Training loss: 2.5426056385040283
Validation loss: 2.781148346521521

Epoch: 6| Step: 12
Training loss: 2.344266176223755
Validation loss: 2.776362890838295

Epoch: 6| Step: 13
Training loss: 3.6978161334991455
Validation loss: 2.7765749193006948

Epoch: 155| Step: 0
Training loss: 3.251303195953369
Validation loss: 2.7750064813962547

Epoch: 6| Step: 1
Training loss: 3.08787202835083
Validation loss: 2.779691578239523

Epoch: 6| Step: 2
Training loss: 2.233243942260742
Validation loss: 2.7840896062953497

Epoch: 6| Step: 3
Training loss: 3.044966697692871
Validation loss: 2.7804070313771567

Epoch: 6| Step: 4
Training loss: 2.836970806121826
Validation loss: 2.777027407000142

Epoch: 6| Step: 5
Training loss: 2.450594663619995
Validation loss: 2.77556840578715

Epoch: 6| Step: 6
Training loss: 2.5461905002593994
Validation loss: 2.7766801875124694

Epoch: 6| Step: 7
Training loss: 2.6425492763519287
Validation loss: 2.7750842725076983

Epoch: 6| Step: 8
Training loss: 2.3641786575317383
Validation loss: 2.7767896703494492

Epoch: 6| Step: 9
Training loss: 2.6393778324127197
Validation loss: 2.776732849818404

Epoch: 6| Step: 10
Training loss: 3.0625767707824707
Validation loss: 2.775845419976019

Epoch: 6| Step: 11
Training loss: 3.9004573822021484
Validation loss: 2.776231183800646

Epoch: 6| Step: 12
Training loss: 3.4463448524475098
Validation loss: 2.7725541976190384

Epoch: 6| Step: 13
Training loss: 2.57070255279541
Validation loss: 2.776007088281775

Epoch: 156| Step: 0
Training loss: 3.693446159362793
Validation loss: 2.7743513045772428

Epoch: 6| Step: 1
Training loss: 2.3384311199188232
Validation loss: 2.7747470486548638

Epoch: 6| Step: 2
Training loss: 2.4605722427368164
Validation loss: 2.7750453333700857

Epoch: 6| Step: 3
Training loss: 3.2191004753112793
Validation loss: 2.7746975806451615

Epoch: 6| Step: 4
Training loss: 2.4842755794525146
Validation loss: 2.7758628399141374

Epoch: 6| Step: 5
Training loss: 2.1297495365142822
Validation loss: 2.7760945648275395

Epoch: 6| Step: 6
Training loss: 2.2570676803588867
Validation loss: 2.7731971612540622

Epoch: 6| Step: 7
Training loss: 3.487513303756714
Validation loss: 2.7737960379610778

Epoch: 6| Step: 8
Training loss: 3.278714179992676
Validation loss: 2.773742339944327

Epoch: 6| Step: 9
Training loss: 2.905348539352417
Validation loss: 2.7708347689720894

Epoch: 6| Step: 10
Training loss: 3.64462947845459
Validation loss: 2.776865687421573

Epoch: 6| Step: 11
Training loss: 2.7081947326660156
Validation loss: 2.774587731207571

Epoch: 6| Step: 12
Training loss: 2.628025531768799
Validation loss: 2.774532610370267

Epoch: 6| Step: 13
Training loss: 3.0494606494903564
Validation loss: 2.777760200603034

Epoch: 157| Step: 0
Training loss: 3.3667097091674805
Validation loss: 2.777643708772557

Epoch: 6| Step: 1
Training loss: 3.117178440093994
Validation loss: 2.7786277583850327

Epoch: 6| Step: 2
Training loss: 3.3501248359680176
Validation loss: 2.7776418962786273

Epoch: 6| Step: 3
Training loss: 2.677385091781616
Validation loss: 2.7698089717536845

Epoch: 6| Step: 4
Training loss: 3.0679712295532227
Validation loss: 2.7715240319569907

Epoch: 6| Step: 5
Training loss: 1.857101559638977
Validation loss: 2.7702685838104575

Epoch: 6| Step: 6
Training loss: 2.4453134536743164
Validation loss: 2.769279932463041

Epoch: 6| Step: 7
Training loss: 2.762326717376709
Validation loss: 2.7721598327800794

Epoch: 6| Step: 8
Training loss: 3.1620230674743652
Validation loss: 2.768443645969514

Epoch: 6| Step: 9
Training loss: 2.771498918533325
Validation loss: 2.7681156243047407

Epoch: 6| Step: 10
Training loss: 2.9118542671203613
Validation loss: 2.768205322245116

Epoch: 6| Step: 11
Training loss: 2.924755096435547
Validation loss: 2.7714100858216644

Epoch: 6| Step: 12
Training loss: 3.40588641166687
Validation loss: 2.7691121691016742

Epoch: 6| Step: 13
Training loss: 1.979501485824585
Validation loss: 2.771237534861411

Epoch: 158| Step: 0
Training loss: 2.1939399242401123
Validation loss: 2.7681037713122625

Epoch: 6| Step: 1
Training loss: 2.974820375442505
Validation loss: 2.768876511563537

Epoch: 6| Step: 2
Training loss: 3.3079960346221924
Validation loss: 2.7656806515109156

Epoch: 6| Step: 3
Training loss: 2.3181116580963135
Validation loss: 2.7676864541986936

Epoch: 6| Step: 4
Training loss: 3.099275588989258
Validation loss: 2.769628888817244

Epoch: 6| Step: 5
Training loss: 3.0714540481567383
Validation loss: 2.7686962440449703

Epoch: 6| Step: 6
Training loss: 2.868589401245117
Validation loss: 2.7664124324757564

Epoch: 6| Step: 7
Training loss: 2.6949307918548584
Validation loss: 2.7672755820776826

Epoch: 6| Step: 8
Training loss: 3.6704659461975098
Validation loss: 2.7672370069770404

Epoch: 6| Step: 9
Training loss: 2.5985655784606934
Validation loss: 2.768403794175835

Epoch: 6| Step: 10
Training loss: 3.42124080657959
Validation loss: 2.7655102334996706

Epoch: 6| Step: 11
Training loss: 2.0068531036376953
Validation loss: 2.7642616302736345

Epoch: 6| Step: 12
Training loss: 3.4303529262542725
Validation loss: 2.766217254823254

Epoch: 6| Step: 13
Training loss: 2.1834871768951416
Validation loss: 2.7653539898574993

Epoch: 159| Step: 0
Training loss: 2.987603187561035
Validation loss: 2.7655813129999305

Epoch: 6| Step: 1
Training loss: 3.377732753753662
Validation loss: 2.766581448175574

Epoch: 6| Step: 2
Training loss: 3.3884429931640625
Validation loss: 2.76815487236105

Epoch: 6| Step: 3
Training loss: 3.756732225418091
Validation loss: 2.7683463686256

Epoch: 6| Step: 4
Training loss: 2.7918107509613037
Validation loss: 2.770620266596476

Epoch: 6| Step: 5
Training loss: 2.222902536392212
Validation loss: 2.771289938239641

Epoch: 6| Step: 6
Training loss: 2.6939876079559326
Validation loss: 2.769337033712736

Epoch: 6| Step: 7
Training loss: 2.807724952697754
Validation loss: 2.7656920340753373

Epoch: 6| Step: 8
Training loss: 3.207862377166748
Validation loss: 2.7680485069110827

Epoch: 6| Step: 9
Training loss: 3.858189821243286
Validation loss: 2.765750797845984

Epoch: 6| Step: 10
Training loss: 1.9857187271118164
Validation loss: 2.766036379721857

Epoch: 6| Step: 11
Training loss: 2.6189346313476562
Validation loss: 2.7672120217354066

Epoch: 6| Step: 12
Training loss: 2.2917256355285645
Validation loss: 2.76621994151864

Epoch: 6| Step: 13
Training loss: 1.6004666090011597
Validation loss: 2.7675791043107227

Epoch: 160| Step: 0
Training loss: 3.263939380645752
Validation loss: 2.7647225651689755

Epoch: 6| Step: 1
Training loss: 2.682565689086914
Validation loss: 2.7690337960438063

Epoch: 6| Step: 2
Training loss: 2.6986658573150635
Validation loss: 2.764191222447221

Epoch: 6| Step: 3
Training loss: 2.6160082817077637
Validation loss: 2.7689437430392028

Epoch: 6| Step: 4
Training loss: 2.4174747467041016
Validation loss: 2.765370738121771

Epoch: 6| Step: 5
Training loss: 3.0467278957366943
Validation loss: 2.7638080068813857

Epoch: 6| Step: 6
Training loss: 3.2357735633850098
Validation loss: 2.7668771718138006

Epoch: 6| Step: 7
Training loss: 3.8617355823516846
Validation loss: 2.7675521501930813

Epoch: 6| Step: 8
Training loss: 3.1932108402252197
Validation loss: 2.7678492120517197

Epoch: 6| Step: 9
Training loss: 2.678001880645752
Validation loss: 2.767907570767146

Epoch: 6| Step: 10
Training loss: 2.492525339126587
Validation loss: 2.7659425299654723

Epoch: 6| Step: 11
Training loss: 2.5863518714904785
Validation loss: 2.759310253204838

Epoch: 6| Step: 12
Training loss: 2.5341086387634277
Validation loss: 2.7609610326828493

Epoch: 6| Step: 13
Training loss: 2.686875581741333
Validation loss: 2.759805001238341

Epoch: 161| Step: 0
Training loss: 2.7027857303619385
Validation loss: 2.7663097586683048

Epoch: 6| Step: 1
Training loss: 2.4280378818511963
Validation loss: 2.7645674277377386

Epoch: 6| Step: 2
Training loss: 2.3751368522644043
Validation loss: 2.762432175297891

Epoch: 6| Step: 3
Training loss: 3.257077217102051
Validation loss: 2.7614869148500505

Epoch: 6| Step: 4
Training loss: 2.9839258193969727
Validation loss: 2.7600746308603594

Epoch: 6| Step: 5
Training loss: 2.7721099853515625
Validation loss: 2.761371950949392

Epoch: 6| Step: 6
Training loss: 3.811366558074951
Validation loss: 2.7620353442366405

Epoch: 6| Step: 7
Training loss: 2.607064723968506
Validation loss: 2.7733529844591693

Epoch: 6| Step: 8
Training loss: 4.027876853942871
Validation loss: 2.7760668416177072

Epoch: 6| Step: 9
Training loss: 2.1404075622558594
Validation loss: 2.7783303747894945

Epoch: 6| Step: 10
Training loss: 3.2465105056762695
Validation loss: 2.763503074645996

Epoch: 6| Step: 11
Training loss: 1.8373185396194458
Validation loss: 2.766326783805765

Epoch: 6| Step: 12
Training loss: 2.9483816623687744
Validation loss: 2.761009552145517

Epoch: 6| Step: 13
Training loss: 3.1731812953948975
Validation loss: 2.7602838367544194

Epoch: 162| Step: 0
Training loss: 2.950273036956787
Validation loss: 2.7605674882088937

Epoch: 6| Step: 1
Training loss: 2.9472079277038574
Validation loss: 2.7628235406773065

Epoch: 6| Step: 2
Training loss: 2.4870166778564453
Validation loss: 2.7701036084082817

Epoch: 6| Step: 3
Training loss: 2.3585286140441895
Validation loss: 2.7719311944900022

Epoch: 6| Step: 4
Training loss: 2.956268310546875
Validation loss: 2.7775737931651454

Epoch: 6| Step: 5
Training loss: 2.8050999641418457
Validation loss: 2.779921095858338

Epoch: 6| Step: 6
Training loss: 2.9476609230041504
Validation loss: 2.768583036238147

Epoch: 6| Step: 7
Training loss: 3.283515214920044
Validation loss: 2.7674188024254254

Epoch: 6| Step: 8
Training loss: 2.773184299468994
Validation loss: 2.763559856722432

Epoch: 6| Step: 9
Training loss: 3.776599645614624
Validation loss: 2.7606085833682807

Epoch: 6| Step: 10
Training loss: 2.8156280517578125
Validation loss: 2.760160287221273

Epoch: 6| Step: 11
Training loss: 2.946305274963379
Validation loss: 2.7611517547279276

Epoch: 6| Step: 12
Training loss: 2.6297991275787354
Validation loss: 2.7592856448183776

Epoch: 6| Step: 13
Training loss: 2.2921581268310547
Validation loss: 2.756591332856045

Epoch: 163| Step: 0
Training loss: 2.539794445037842
Validation loss: 2.7583297683346655

Epoch: 6| Step: 1
Training loss: 3.3390746116638184
Validation loss: 2.7568097294017835

Epoch: 6| Step: 2
Training loss: 3.1833336353302
Validation loss: 2.7564209148448002

Epoch: 6| Step: 3
Training loss: 2.3044474124908447
Validation loss: 2.7524861930519022

Epoch: 6| Step: 4
Training loss: 3.375838279724121
Validation loss: 2.756241488200362

Epoch: 6| Step: 5
Training loss: 3.702319860458374
Validation loss: 2.755904472002419

Epoch: 6| Step: 6
Training loss: 2.958173990249634
Validation loss: 2.760191830255652

Epoch: 6| Step: 7
Training loss: 2.5522491931915283
Validation loss: 2.7559685143091346

Epoch: 6| Step: 8
Training loss: 2.809779167175293
Validation loss: 2.757396326270155

Epoch: 6| Step: 9
Training loss: 2.5378482341766357
Validation loss: 2.7574610607598418

Epoch: 6| Step: 10
Training loss: 3.3420634269714355
Validation loss: 2.757553013422156

Epoch: 6| Step: 11
Training loss: 2.6382317543029785
Validation loss: 2.7561165055921

Epoch: 6| Step: 12
Training loss: 2.348257541656494
Validation loss: 2.7570330712103073

Epoch: 6| Step: 13
Training loss: 2.1066150665283203
Validation loss: 2.7566380936612367

Epoch: 164| Step: 0
Training loss: 3.097115993499756
Validation loss: 2.7613004407575055

Epoch: 6| Step: 1
Training loss: 2.7821707725524902
Validation loss: 2.7551696992689565

Epoch: 6| Step: 2
Training loss: 2.605924129486084
Validation loss: 2.756350048126713

Epoch: 6| Step: 3
Training loss: 2.563170909881592
Validation loss: 2.7556142986461682

Epoch: 6| Step: 4
Training loss: 3.156855583190918
Validation loss: 2.7544678693176596

Epoch: 6| Step: 5
Training loss: 3.017444610595703
Validation loss: 2.7524585954604612

Epoch: 6| Step: 6
Training loss: 2.7883737087249756
Validation loss: 2.754913499278407

Epoch: 6| Step: 7
Training loss: 2.505821704864502
Validation loss: 2.75172855008033

Epoch: 6| Step: 8
Training loss: 3.000188112258911
Validation loss: 2.7541028145820863

Epoch: 6| Step: 9
Training loss: 2.927727699279785
Validation loss: 2.753538731605776

Epoch: 6| Step: 10
Training loss: 3.218017101287842
Validation loss: 2.7523526837748866

Epoch: 6| Step: 11
Training loss: 2.859959125518799
Validation loss: 2.75511763429129

Epoch: 6| Step: 12
Training loss: 2.9396212100982666
Validation loss: 2.753814620356406

Epoch: 6| Step: 13
Training loss: 2.325376033782959
Validation loss: 2.753325277759183

Epoch: 165| Step: 0
Training loss: 2.6169209480285645
Validation loss: 2.754322559602799

Epoch: 6| Step: 1
Training loss: 2.390197277069092
Validation loss: 2.752090818138533

Epoch: 6| Step: 2
Training loss: 2.529049873352051
Validation loss: 2.7572113724165064

Epoch: 6| Step: 3
Training loss: 2.4007725715637207
Validation loss: 2.754770214839648

Epoch: 6| Step: 4
Training loss: 2.5461087226867676
Validation loss: 2.754460052777362

Epoch: 6| Step: 5
Training loss: 2.5312340259552
Validation loss: 2.7526110244053665

Epoch: 6| Step: 6
Training loss: 2.8185040950775146
Validation loss: 2.751309899873631

Epoch: 6| Step: 7
Training loss: 3.1321892738342285
Validation loss: 2.7501211192018244

Epoch: 6| Step: 8
Training loss: 3.3744778633117676
Validation loss: 2.751412663408505

Epoch: 6| Step: 9
Training loss: 2.5420098304748535
Validation loss: 2.7531274108476538

Epoch: 6| Step: 10
Training loss: 3.332118511199951
Validation loss: 2.7509764804634997

Epoch: 6| Step: 11
Training loss: 3.1213483810424805
Validation loss: 2.748458541849608

Epoch: 6| Step: 12
Training loss: 3.213651180267334
Validation loss: 2.7492825549135924

Epoch: 6| Step: 13
Training loss: 3.9458630084991455
Validation loss: 2.7510342879961898

Epoch: 166| Step: 0
Training loss: 3.1248817443847656
Validation loss: 2.7502665788896623

Epoch: 6| Step: 1
Training loss: 2.34037446975708
Validation loss: 2.7511439989971858

Epoch: 6| Step: 2
Training loss: 2.749295234680176
Validation loss: 2.74919887768325

Epoch: 6| Step: 3
Training loss: 3.149505615234375
Validation loss: 2.7495516371983353

Epoch: 6| Step: 4
Training loss: 1.9536802768707275
Validation loss: 2.7487750745588735

Epoch: 6| Step: 5
Training loss: 3.1835286617279053
Validation loss: 2.749990160747241

Epoch: 6| Step: 6
Training loss: 2.1613693237304688
Validation loss: 2.7501762297845658

Epoch: 6| Step: 7
Training loss: 3.3794469833374023
Validation loss: 2.749211193412863

Epoch: 6| Step: 8
Training loss: 3.323657512664795
Validation loss: 2.747877428608556

Epoch: 6| Step: 9
Training loss: 3.454153060913086
Validation loss: 2.749505983885898

Epoch: 6| Step: 10
Training loss: 1.8544187545776367
Validation loss: 2.7500237521304878

Epoch: 6| Step: 11
Training loss: 3.2357778549194336
Validation loss: 2.7498907837816464

Epoch: 6| Step: 12
Training loss: 2.830174207687378
Validation loss: 2.7467998073947046

Epoch: 6| Step: 13
Training loss: 3.465404987335205
Validation loss: 2.7452649403643865

Epoch: 167| Step: 0
Training loss: 2.423391819000244
Validation loss: 2.74672870994896

Epoch: 6| Step: 1
Training loss: 1.987686038017273
Validation loss: 2.7479428962994645

Epoch: 6| Step: 2
Training loss: 3.3819193840026855
Validation loss: 2.7453479613027265

Epoch: 6| Step: 3
Training loss: 2.688253164291382
Validation loss: 2.746746188850813

Epoch: 6| Step: 4
Training loss: 2.8057007789611816
Validation loss: 2.7477870961671234

Epoch: 6| Step: 5
Training loss: 2.947470188140869
Validation loss: 2.74940461497153

Epoch: 6| Step: 6
Training loss: 3.690248489379883
Validation loss: 2.744938337674705

Epoch: 6| Step: 7
Training loss: 2.7463998794555664
Validation loss: 2.744476374759469

Epoch: 6| Step: 8
Training loss: 2.938572406768799
Validation loss: 2.7452730132687475

Epoch: 6| Step: 9
Training loss: 2.1770434379577637
Validation loss: 2.744341673389558

Epoch: 6| Step: 10
Training loss: 2.858144998550415
Validation loss: 2.7465834591978338

Epoch: 6| Step: 11
Training loss: 2.8618860244750977
Validation loss: 2.747353951136271

Epoch: 6| Step: 12
Training loss: 3.1460719108581543
Validation loss: 2.7458371680269957

Epoch: 6| Step: 13
Training loss: 3.627269744873047
Validation loss: 2.746020793914795

Epoch: 168| Step: 0
Training loss: 3.3645026683807373
Validation loss: 2.7472914341957337

Epoch: 6| Step: 1
Training loss: 1.9328268766403198
Validation loss: 2.745153952670354

Epoch: 6| Step: 2
Training loss: 2.9785776138305664
Validation loss: 2.7507050524475756

Epoch: 6| Step: 3
Training loss: 2.389376640319824
Validation loss: 2.745129995448615

Epoch: 6| Step: 4
Training loss: 2.6968793869018555
Validation loss: 2.750166534095682

Epoch: 6| Step: 5
Training loss: 3.385770082473755
Validation loss: 2.7492336252684235

Epoch: 6| Step: 6
Training loss: 3.0618176460266113
Validation loss: 2.7514554505707114

Epoch: 6| Step: 7
Training loss: 2.7221481800079346
Validation loss: 2.7459075104805732

Epoch: 6| Step: 8
Training loss: 3.5896692276000977
Validation loss: 2.744836425268522

Epoch: 6| Step: 9
Training loss: 3.2701945304870605
Validation loss: 2.744511842727661

Epoch: 6| Step: 10
Training loss: 2.198411703109741
Validation loss: 2.7456560109251287

Epoch: 6| Step: 11
Training loss: 2.52070951461792
Validation loss: 2.7449050359828497

Epoch: 6| Step: 12
Training loss: 3.098907470703125
Validation loss: 2.746124154777937

Epoch: 6| Step: 13
Training loss: 2.6610255241394043
Validation loss: 2.7466016072098927

Epoch: 169| Step: 0
Training loss: 2.9761040210723877
Validation loss: 2.74746528748543

Epoch: 6| Step: 1
Training loss: 2.575517416000366
Validation loss: 2.744834012882684

Epoch: 6| Step: 2
Training loss: 2.946195363998413
Validation loss: 2.7463118747998307

Epoch: 6| Step: 3
Training loss: 3.3442695140838623
Validation loss: 2.7496734383285686

Epoch: 6| Step: 4
Training loss: 3.186006546020508
Validation loss: 2.7474492083313646

Epoch: 6| Step: 5
Training loss: 2.8749945163726807
Validation loss: 2.7491058636737127

Epoch: 6| Step: 6
Training loss: 2.3470494747161865
Validation loss: 2.747873111437726

Epoch: 6| Step: 7
Training loss: 2.753662109375
Validation loss: 2.746609172513408

Epoch: 6| Step: 8
Training loss: 2.4003493785858154
Validation loss: 2.7464061091023106

Epoch: 6| Step: 9
Training loss: 2.392183303833008
Validation loss: 2.744856380647229

Epoch: 6| Step: 10
Training loss: 2.9512939453125
Validation loss: 2.7486094249192106

Epoch: 6| Step: 11
Training loss: 2.90964412689209
Validation loss: 2.748000573086482

Epoch: 6| Step: 12
Training loss: 2.938453435897827
Validation loss: 2.7464591559543403

Epoch: 6| Step: 13
Training loss: 3.6942758560180664
Validation loss: 2.7532943499985563

Epoch: 170| Step: 0
Training loss: 2.651165008544922
Validation loss: 2.746421903692266

Epoch: 6| Step: 1
Training loss: 2.391777992248535
Validation loss: 2.741778335263652

Epoch: 6| Step: 2
Training loss: 2.579742431640625
Validation loss: 2.750071999847248

Epoch: 6| Step: 3
Training loss: 2.885329008102417
Validation loss: 2.749559674211728

Epoch: 6| Step: 4
Training loss: 2.45182466506958
Validation loss: 2.7491090451517413

Epoch: 6| Step: 5
Training loss: 2.405174732208252
Validation loss: 2.7484821888708297

Epoch: 6| Step: 6
Training loss: 3.1937150955200195
Validation loss: 2.7436303451497066

Epoch: 6| Step: 7
Training loss: 3.2248430252075195
Validation loss: 2.742290340444093

Epoch: 6| Step: 8
Training loss: 2.728682041168213
Validation loss: 2.7425931807487243

Epoch: 6| Step: 9
Training loss: 2.90114688873291
Validation loss: 2.742567959652152

Epoch: 6| Step: 10
Training loss: 4.300252914428711
Validation loss: 2.7406382945276078

Epoch: 6| Step: 11
Training loss: 2.8227784633636475
Validation loss: 2.740142160846341

Epoch: 6| Step: 12
Training loss: 2.8467299938201904
Validation loss: 2.7433819565721738

Epoch: 6| Step: 13
Training loss: 2.2196907997131348
Validation loss: 2.738006422596593

Epoch: 171| Step: 0
Training loss: 2.746098756790161
Validation loss: 2.738251596368769

Epoch: 6| Step: 1
Training loss: 1.9659173488616943
Validation loss: 2.740485309272684

Epoch: 6| Step: 2
Training loss: 3.2451982498168945
Validation loss: 2.738351914190477

Epoch: 6| Step: 3
Training loss: 3.4056873321533203
Validation loss: 2.7402445757260887

Epoch: 6| Step: 4
Training loss: 2.4476585388183594
Validation loss: 2.737274798013831

Epoch: 6| Step: 5
Training loss: 2.848982334136963
Validation loss: 2.738727851580548

Epoch: 6| Step: 6
Training loss: 3.4448089599609375
Validation loss: 2.7381205917686544

Epoch: 6| Step: 7
Training loss: 2.6552610397338867
Validation loss: 2.7445849244312575

Epoch: 6| Step: 8
Training loss: 2.9456663131713867
Validation loss: 2.7420476123850834

Epoch: 6| Step: 9
Training loss: 2.241163730621338
Validation loss: 2.7397883656204387

Epoch: 6| Step: 10
Training loss: 3.7717244625091553
Validation loss: 2.7436156888161936

Epoch: 6| Step: 11
Training loss: 2.516328811645508
Validation loss: 2.7393361240304928

Epoch: 6| Step: 12
Training loss: 2.629443883895874
Validation loss: 2.7356455326080322

Epoch: 6| Step: 13
Training loss: 3.1099441051483154
Validation loss: 2.7393954594930015

Epoch: 172| Step: 0
Training loss: 2.594963788986206
Validation loss: 2.7354512906843618

Epoch: 6| Step: 1
Training loss: 2.0489189624786377
Validation loss: 2.7393281844354447

Epoch: 6| Step: 2
Training loss: 2.0042152404785156
Validation loss: 2.7391579202426377

Epoch: 6| Step: 3
Training loss: 3.800600528717041
Validation loss: 2.738685836074173

Epoch: 6| Step: 4
Training loss: 2.9629464149475098
Validation loss: 2.7379434608644053

Epoch: 6| Step: 5
Training loss: 4.164233684539795
Validation loss: 2.7375401476378083

Epoch: 6| Step: 6
Training loss: 2.4248335361480713
Validation loss: 2.735029541036134

Epoch: 6| Step: 7
Training loss: 2.5742626190185547
Validation loss: 2.735715348233459

Epoch: 6| Step: 8
Training loss: 2.9043731689453125
Validation loss: 2.7364624982239096

Epoch: 6| Step: 9
Training loss: 2.6059069633483887
Validation loss: 2.732962028954619

Epoch: 6| Step: 10
Training loss: 3.439149856567383
Validation loss: 2.73824054707763

Epoch: 6| Step: 11
Training loss: 3.2013280391693115
Validation loss: 2.735680841630505

Epoch: 6| Step: 12
Training loss: 2.5402793884277344
Validation loss: 2.7359548640507523

Epoch: 6| Step: 13
Training loss: 2.4236085414886475
Validation loss: 2.735282349330123

Epoch: 173| Step: 0
Training loss: 3.0741968154907227
Validation loss: 2.7387154640689975

Epoch: 6| Step: 1
Training loss: 2.150681257247925
Validation loss: 2.7388105007909958

Epoch: 6| Step: 2
Training loss: 3.423421859741211
Validation loss: 2.7333977735170754

Epoch: 6| Step: 3
Training loss: 2.5472261905670166
Validation loss: 2.733907053547521

Epoch: 6| Step: 4
Training loss: 3.4343342781066895
Validation loss: 2.7332834300174507

Epoch: 6| Step: 5
Training loss: 2.8803529739379883
Validation loss: 2.7352644653730493

Epoch: 6| Step: 6
Training loss: 2.6364853382110596
Validation loss: 2.7355492730294504

Epoch: 6| Step: 7
Training loss: 2.735225200653076
Validation loss: 2.735285961499778

Epoch: 6| Step: 8
Training loss: 2.8915562629699707
Validation loss: 2.73376710953251

Epoch: 6| Step: 9
Training loss: 2.9020462036132812
Validation loss: 2.7372347103652133

Epoch: 6| Step: 10
Training loss: 2.2098333835601807
Validation loss: 2.734069865237

Epoch: 6| Step: 11
Training loss: 2.5537705421447754
Validation loss: 2.7353265080400693

Epoch: 6| Step: 12
Training loss: 3.5962631702423096
Validation loss: 2.734345879606021

Epoch: 6| Step: 13
Training loss: 2.7397284507751465
Validation loss: 2.736849920724028

Epoch: 174| Step: 0
Training loss: 2.720288038253784
Validation loss: 2.738531445944181

Epoch: 6| Step: 1
Training loss: 3.06595516204834
Validation loss: 2.740567130427207

Epoch: 6| Step: 2
Training loss: 3.188941478729248
Validation loss: 2.740668512159778

Epoch: 6| Step: 3
Training loss: 2.627516746520996
Validation loss: 2.7398228388960644

Epoch: 6| Step: 4
Training loss: 2.4056122303009033
Validation loss: 2.739118693977274

Epoch: 6| Step: 5
Training loss: 3.009601354598999
Validation loss: 2.7391616964852936

Epoch: 6| Step: 6
Training loss: 3.1615536212921143
Validation loss: 2.734875758488973

Epoch: 6| Step: 7
Training loss: 1.9538378715515137
Validation loss: 2.7397995943664224

Epoch: 6| Step: 8
Training loss: 2.429640769958496
Validation loss: 2.7390689285852576

Epoch: 6| Step: 9
Training loss: 3.3916568756103516
Validation loss: 2.7378214072155695

Epoch: 6| Step: 10
Training loss: 2.7837564945220947
Validation loss: 2.734478665936378

Epoch: 6| Step: 11
Training loss: 3.3715665340423584
Validation loss: 2.736295635982226

Epoch: 6| Step: 12
Training loss: 3.5012307167053223
Validation loss: 2.735921621322632

Epoch: 6| Step: 13
Training loss: 1.7152974605560303
Validation loss: 2.7380483509391866

Epoch: 175| Step: 0
Training loss: 2.7591795921325684
Validation loss: 2.734842556779103

Epoch: 6| Step: 1
Training loss: 3.094658851623535
Validation loss: 2.7336722368835122

Epoch: 6| Step: 2
Training loss: 3.0629425048828125
Validation loss: 2.741778519845778

Epoch: 6| Step: 3
Training loss: 2.082754373550415
Validation loss: 2.7528259087634344

Epoch: 6| Step: 4
Training loss: 2.9311370849609375
Validation loss: 2.743081764508319

Epoch: 6| Step: 5
Training loss: 2.2251319885253906
Validation loss: 2.73712936780786

Epoch: 6| Step: 6
Training loss: 2.7279629707336426
Validation loss: 2.738842530917096

Epoch: 6| Step: 7
Training loss: 2.728705883026123
Validation loss: 2.7405847144383255

Epoch: 6| Step: 8
Training loss: 3.673126697540283
Validation loss: 2.73352224339721

Epoch: 6| Step: 9
Training loss: 3.036886215209961
Validation loss: 2.726376277144237

Epoch: 6| Step: 10
Training loss: 2.6579527854919434
Validation loss: 2.734741718538346

Epoch: 6| Step: 11
Training loss: 3.318484306335449
Validation loss: 2.7359097029573176

Epoch: 6| Step: 12
Training loss: 3.046870708465576
Validation loss: 2.735700568845195

Epoch: 6| Step: 13
Training loss: 2.378117322921753
Validation loss: 2.7366223027629237

Epoch: 176| Step: 0
Training loss: 3.3338065147399902
Validation loss: 2.735683923126549

Epoch: 6| Step: 1
Training loss: 2.4100489616394043
Validation loss: 2.7316883661413707

Epoch: 6| Step: 2
Training loss: 2.838449001312256
Validation loss: 2.73323227513221

Epoch: 6| Step: 3
Training loss: 1.8248605728149414
Validation loss: 2.7314146590489212

Epoch: 6| Step: 4
Training loss: 2.7431135177612305
Validation loss: 2.7311236166184947

Epoch: 6| Step: 5
Training loss: 2.832920551300049
Validation loss: 2.730512175508725

Epoch: 6| Step: 6
Training loss: 2.852353572845459
Validation loss: 2.729262795499576

Epoch: 6| Step: 7
Training loss: 2.6218421459198
Validation loss: 2.7295205003471783

Epoch: 6| Step: 8
Training loss: 2.1379661560058594
Validation loss: 2.7291936182206675

Epoch: 6| Step: 9
Training loss: 2.8310868740081787
Validation loss: 2.7359010788702194

Epoch: 6| Step: 10
Training loss: 3.379300594329834
Validation loss: 2.741254004099036

Epoch: 6| Step: 11
Training loss: 3.696857213973999
Validation loss: 2.744068594389064

Epoch: 6| Step: 12
Training loss: 3.596520185470581
Validation loss: 2.7434809925735637

Epoch: 6| Step: 13
Training loss: 2.531834363937378
Validation loss: 2.7438736090096096

Epoch: 177| Step: 0
Training loss: 3.106590747833252
Validation loss: 2.737375005598991

Epoch: 6| Step: 1
Training loss: 2.0089104175567627
Validation loss: 2.733558044638685

Epoch: 6| Step: 2
Training loss: 2.5432794094085693
Validation loss: 2.731330556254233

Epoch: 6| Step: 3
Training loss: 1.7217448949813843
Validation loss: 2.7317371855499926

Epoch: 6| Step: 4
Training loss: 3.050053834915161
Validation loss: 2.7296831428363757

Epoch: 6| Step: 5
Training loss: 4.146753787994385
Validation loss: 2.7272545881168817

Epoch: 6| Step: 6
Training loss: 4.053275108337402
Validation loss: 2.7321686283234627

Epoch: 6| Step: 7
Training loss: 2.5797934532165527
Validation loss: 2.7274233961618073

Epoch: 6| Step: 8
Training loss: 2.862269401550293
Validation loss: 2.729460165064822

Epoch: 6| Step: 9
Training loss: 2.4200732707977295
Validation loss: 2.727930745770854

Epoch: 6| Step: 10
Training loss: 2.7203104496002197
Validation loss: 2.724748170504006

Epoch: 6| Step: 11
Training loss: 2.776675224304199
Validation loss: 2.723099354774721

Epoch: 6| Step: 12
Training loss: 2.8069310188293457
Validation loss: 2.7263075305569555

Epoch: 6| Step: 13
Training loss: 2.982825517654419
Validation loss: 2.7249881093220045

Epoch: 178| Step: 0
Training loss: 3.1220383644104004
Validation loss: 2.7259477248755832

Epoch: 6| Step: 1
Training loss: 2.7077550888061523
Validation loss: 2.7257369590061966

Epoch: 6| Step: 2
Training loss: 2.6589059829711914
Validation loss: 2.729821410230411

Epoch: 6| Step: 3
Training loss: 1.897078514099121
Validation loss: 2.7295050185213805

Epoch: 6| Step: 4
Training loss: 3.070972442626953
Validation loss: 2.7291190316600185

Epoch: 6| Step: 5
Training loss: 2.6814212799072266
Validation loss: 2.7303392553842194

Epoch: 6| Step: 6
Training loss: 3.493772506713867
Validation loss: 2.730016167445849

Epoch: 6| Step: 7
Training loss: 2.2608084678649902
Validation loss: 2.7313117058046403

Epoch: 6| Step: 8
Training loss: 3.32542085647583
Validation loss: 2.7294057312832085

Epoch: 6| Step: 9
Training loss: 2.522193670272827
Validation loss: 2.729862913008659

Epoch: 6| Step: 10
Training loss: 3.1537728309631348
Validation loss: 2.7297059746198755

Epoch: 6| Step: 11
Training loss: 2.7832770347595215
Validation loss: 2.7305103271238265

Epoch: 6| Step: 12
Training loss: 3.2304818630218506
Validation loss: 2.72804021322599

Epoch: 6| Step: 13
Training loss: 2.755620002746582
Validation loss: 2.727379088760704

Epoch: 179| Step: 0
Training loss: 2.374713182449341
Validation loss: 2.729604623650992

Epoch: 6| Step: 1
Training loss: 3.366252899169922
Validation loss: 2.7281568947658745

Epoch: 6| Step: 2
Training loss: 3.1013641357421875
Validation loss: 2.727745843190019

Epoch: 6| Step: 3
Training loss: 2.8484737873077393
Validation loss: 2.7238389266434537

Epoch: 6| Step: 4
Training loss: 3.2068722248077393
Validation loss: 2.725797760871149

Epoch: 6| Step: 5
Training loss: 2.9524741172790527
Validation loss: 2.7274849671189503

Epoch: 6| Step: 6
Training loss: 2.8267059326171875
Validation loss: 2.7278597098524853

Epoch: 6| Step: 7
Training loss: 2.5945334434509277
Validation loss: 2.72501620938701

Epoch: 6| Step: 8
Training loss: 3.476038932800293
Validation loss: 2.725532865011564

Epoch: 6| Step: 9
Training loss: 2.438633680343628
Validation loss: 2.7300202154344126

Epoch: 6| Step: 10
Training loss: 3.271117687225342
Validation loss: 2.722950530308549

Epoch: 6| Step: 11
Training loss: 2.32062029838562
Validation loss: 2.72697268250168

Epoch: 6| Step: 12
Training loss: 2.2701797485351562
Validation loss: 2.726713077996367

Epoch: 6| Step: 13
Training loss: 2.4920361042022705
Validation loss: 2.727031553945234

Epoch: 180| Step: 0
Training loss: 2.9880714416503906
Validation loss: 2.722723553257604

Epoch: 6| Step: 1
Training loss: 2.741400718688965
Validation loss: 2.725964479548957

Epoch: 6| Step: 2
Training loss: 2.8171844482421875
Validation loss: 2.722054914761615

Epoch: 6| Step: 3
Training loss: 1.9176775217056274
Validation loss: 2.719405469074044

Epoch: 6| Step: 4
Training loss: 2.5626277923583984
Validation loss: 2.7166187429940827

Epoch: 6| Step: 5
Training loss: 2.5704121589660645
Validation loss: 2.7142958846143497

Epoch: 6| Step: 6
Training loss: 3.445824146270752
Validation loss: 2.7237520935714885

Epoch: 6| Step: 7
Training loss: 2.9524471759796143
Validation loss: 2.7243008382858767

Epoch: 6| Step: 8
Training loss: 2.4236316680908203
Validation loss: 2.7311253137485956

Epoch: 6| Step: 9
Training loss: 3.2434215545654297
Validation loss: 2.7346347352509857

Epoch: 6| Step: 10
Training loss: 3.223637580871582
Validation loss: 2.723746689417029

Epoch: 6| Step: 11
Training loss: 2.972745180130005
Validation loss: 2.725923389516851

Epoch: 6| Step: 12
Training loss: 3.334704875946045
Validation loss: 2.7212952362593783

Epoch: 6| Step: 13
Training loss: 2.345080852508545
Validation loss: 2.7187288563738585

Epoch: 181| Step: 0
Training loss: 2.862833023071289
Validation loss: 2.7176300325701312

Epoch: 6| Step: 1
Training loss: 2.756885051727295
Validation loss: 2.722189180312618

Epoch: 6| Step: 2
Training loss: 4.024603843688965
Validation loss: 2.72382418827344

Epoch: 6| Step: 3
Training loss: 2.4550974369049072
Validation loss: 2.723969446715488

Epoch: 6| Step: 4
Training loss: 1.7333160638809204
Validation loss: 2.7267481614184637

Epoch: 6| Step: 5
Training loss: 2.357344627380371
Validation loss: 2.7248000329540623

Epoch: 6| Step: 6
Training loss: 2.7326059341430664
Validation loss: 2.7254374257979856

Epoch: 6| Step: 7
Training loss: 2.7547860145568848
Validation loss: 2.7243041582005

Epoch: 6| Step: 8
Training loss: 3.2490546703338623
Validation loss: 2.7233827998561244

Epoch: 6| Step: 9
Training loss: 2.6397221088409424
Validation loss: 2.723085154769241

Epoch: 6| Step: 10
Training loss: 1.9047019481658936
Validation loss: 2.724952825935938

Epoch: 6| Step: 11
Training loss: 3.776172637939453
Validation loss: 2.7174853509472263

Epoch: 6| Step: 12
Training loss: 3.282499313354492
Validation loss: 2.7185243124602945

Epoch: 6| Step: 13
Training loss: 3.461542844772339
Validation loss: 2.7165497592700425

Epoch: 182| Step: 0
Training loss: 2.1434812545776367
Validation loss: 2.718302088399087

Epoch: 6| Step: 1
Training loss: 3.512636661529541
Validation loss: 2.715616585105978

Epoch: 6| Step: 2
Training loss: 3.650399684906006
Validation loss: 2.7157481613979546

Epoch: 6| Step: 3
Training loss: 1.7450224161148071
Validation loss: 2.7190757566882717

Epoch: 6| Step: 4
Training loss: 3.0426883697509766
Validation loss: 2.7169234239926903

Epoch: 6| Step: 5
Training loss: 2.9711334705352783
Validation loss: 2.718217170366677

Epoch: 6| Step: 6
Training loss: 3.3954954147338867
Validation loss: 2.715220356500277

Epoch: 6| Step: 7
Training loss: 3.1457505226135254
Validation loss: 2.719581083584857

Epoch: 6| Step: 8
Training loss: 2.997462749481201
Validation loss: 2.7249686025804087

Epoch: 6| Step: 9
Training loss: 2.749018669128418
Validation loss: 2.720167539452994

Epoch: 6| Step: 10
Training loss: 2.55012583732605
Validation loss: 2.7187675609383533

Epoch: 6| Step: 11
Training loss: 2.831386089324951
Validation loss: 2.7179751729452484

Epoch: 6| Step: 12
Training loss: 2.0997400283813477
Validation loss: 2.713551016264064

Epoch: 6| Step: 13
Training loss: 2.8090505599975586
Validation loss: 2.7124898715685775

Epoch: 183| Step: 0
Training loss: 1.905035138130188
Validation loss: 2.712163463715584

Epoch: 6| Step: 1
Training loss: 2.8838796615600586
Validation loss: 2.717625148834721

Epoch: 6| Step: 2
Training loss: 3.5613343715667725
Validation loss: 2.7220295347193235

Epoch: 6| Step: 3
Training loss: 2.805025100708008
Validation loss: 2.7302803301042124

Epoch: 6| Step: 4
Training loss: 3.3299412727355957
Validation loss: 2.728726666460755

Epoch: 6| Step: 5
Training loss: 1.8627369403839111
Validation loss: 2.734881644607872

Epoch: 6| Step: 6
Training loss: 3.144266128540039
Validation loss: 2.7378245784390356

Epoch: 6| Step: 7
Training loss: 3.207479953765869
Validation loss: 2.7376497176385697

Epoch: 6| Step: 8
Training loss: 3.595277786254883
Validation loss: 2.7299259067863546

Epoch: 6| Step: 9
Training loss: 2.6826720237731934
Validation loss: 2.731138124260851

Epoch: 6| Step: 10
Training loss: 3.0569944381713867
Validation loss: 2.7267981395926526

Epoch: 6| Step: 11
Training loss: 2.8138747215270996
Validation loss: 2.7215791825325257

Epoch: 6| Step: 12
Training loss: 2.7087032794952393
Validation loss: 2.7217110792795816

Epoch: 6| Step: 13
Training loss: 1.7575029134750366
Validation loss: 2.716025214041433

Epoch: 184| Step: 0
Training loss: 3.302363157272339
Validation loss: 2.7150819673333118

Epoch: 6| Step: 1
Training loss: 3.3207898139953613
Validation loss: 2.716640841576361

Epoch: 6| Step: 2
Training loss: 2.3977434635162354
Validation loss: 2.71908539084978

Epoch: 6| Step: 3
Training loss: 2.287104845046997
Validation loss: 2.7152328439938125

Epoch: 6| Step: 4
Training loss: 2.3112759590148926
Validation loss: 2.7162629148011566

Epoch: 6| Step: 5
Training loss: 2.5667450428009033
Validation loss: 2.717499466352565

Epoch: 6| Step: 6
Training loss: 2.74592924118042
Validation loss: 2.715423076383529

Epoch: 6| Step: 7
Training loss: 2.6031417846679688
Validation loss: 2.7186607494149158

Epoch: 6| Step: 8
Training loss: 2.843757390975952
Validation loss: 2.715938696297266

Epoch: 6| Step: 9
Training loss: 2.7080471515655518
Validation loss: 2.7195648403577906

Epoch: 6| Step: 10
Training loss: 3.6876418590545654
Validation loss: 2.721871873383881

Epoch: 6| Step: 11
Training loss: 2.9935944080352783
Validation loss: 2.7154058589730212

Epoch: 6| Step: 12
Training loss: 3.058781623840332
Validation loss: 2.713994636330553

Epoch: 6| Step: 13
Training loss: 2.8039283752441406
Validation loss: 2.7122845393355175

Epoch: 185| Step: 0
Training loss: 3.1818735599517822
Validation loss: 2.7127744587518836

Epoch: 6| Step: 1
Training loss: 2.7085704803466797
Validation loss: 2.7131472069730043

Epoch: 6| Step: 2
Training loss: 3.4587459564208984
Validation loss: 2.7144815511600946

Epoch: 6| Step: 3
Training loss: 2.678133010864258
Validation loss: 2.7136335578016055

Epoch: 6| Step: 4
Training loss: 2.5104947090148926
Validation loss: 2.717933929094704

Epoch: 6| Step: 5
Training loss: 2.942636728286743
Validation loss: 2.7122394987331924

Epoch: 6| Step: 6
Training loss: 3.9654035568237305
Validation loss: 2.7136393900840514

Epoch: 6| Step: 7
Training loss: 3.498486280441284
Validation loss: 2.7133246262868247

Epoch: 6| Step: 8
Training loss: 2.5161476135253906
Validation loss: 2.7119552089321997

Epoch: 6| Step: 9
Training loss: 1.8910963535308838
Validation loss: 2.707210671517157

Epoch: 6| Step: 10
Training loss: 2.5046072006225586
Validation loss: 2.7100375903550016

Epoch: 6| Step: 11
Training loss: 3.2278149127960205
Validation loss: 2.70625396954116

Epoch: 6| Step: 12
Training loss: 2.38299822807312
Validation loss: 2.707805992454611

Epoch: 6| Step: 13
Training loss: 1.6080070734024048
Validation loss: 2.7067628829709944

Epoch: 186| Step: 0
Training loss: 2.8124256134033203
Validation loss: 2.707080266808951

Epoch: 6| Step: 1
Training loss: 3.369539260864258
Validation loss: 2.708230226270614

Epoch: 6| Step: 2
Training loss: 3.615633010864258
Validation loss: 2.7091531138266287

Epoch: 6| Step: 3
Training loss: 3.653491497039795
Validation loss: 2.708316692741968

Epoch: 6| Step: 4
Training loss: 2.0556325912475586
Validation loss: 2.7085902562705417

Epoch: 6| Step: 5
Training loss: 2.6220130920410156
Validation loss: 2.7115838937861945

Epoch: 6| Step: 6
Training loss: 2.5395777225494385
Validation loss: 2.7096300061031053

Epoch: 6| Step: 7
Training loss: 3.46689510345459
Validation loss: 2.7082762205472557

Epoch: 6| Step: 8
Training loss: 3.0725455284118652
Validation loss: 2.705891324627784

Epoch: 6| Step: 9
Training loss: 2.794004440307617
Validation loss: 2.7073945383871756

Epoch: 6| Step: 10
Training loss: 2.0341715812683105
Validation loss: 2.7074504257530294

Epoch: 6| Step: 11
Training loss: 3.025939464569092
Validation loss: 2.704782162943194

Epoch: 6| Step: 12
Training loss: 1.676320195198059
Validation loss: 2.7050321307233585

Epoch: 6| Step: 13
Training loss: 2.782909870147705
Validation loss: 2.7070069543776976

Epoch: 187| Step: 0
Training loss: 2.951028347015381
Validation loss: 2.709489030222739

Epoch: 6| Step: 1
Training loss: 2.5370419025421143
Validation loss: 2.700571834400136

Epoch: 6| Step: 2
Training loss: 2.4132213592529297
Validation loss: 2.714731313849008

Epoch: 6| Step: 3
Training loss: 2.9964146614074707
Validation loss: 2.708923875644643

Epoch: 6| Step: 4
Training loss: 2.9555232524871826
Validation loss: 2.7053506835814445

Epoch: 6| Step: 5
Training loss: 2.2965896129608154
Validation loss: 2.711413057901526

Epoch: 6| Step: 6
Training loss: 2.201071262359619
Validation loss: 2.70951707132401

Epoch: 6| Step: 7
Training loss: 2.952855110168457
Validation loss: 2.7078461313760407

Epoch: 6| Step: 8
Training loss: 2.9617488384246826
Validation loss: 2.7049109833214873

Epoch: 6| Step: 9
Training loss: 2.5721840858459473
Validation loss: 2.7074574219283236

Epoch: 6| Step: 10
Training loss: 3.3895421028137207
Validation loss: 2.7046973013108775

Epoch: 6| Step: 11
Training loss: 2.6213083267211914
Validation loss: 2.706186525283321

Epoch: 6| Step: 12
Training loss: 3.3696370124816895
Validation loss: 2.709306311863725

Epoch: 6| Step: 13
Training loss: 3.6045608520507812
Validation loss: 2.708124432512509

Epoch: 188| Step: 0
Training loss: 2.3294713497161865
Validation loss: 2.7092266954401487

Epoch: 6| Step: 1
Training loss: 2.662501573562622
Validation loss: 2.7060467427776707

Epoch: 6| Step: 2
Training loss: 2.4006381034851074
Validation loss: 2.707763192474201

Epoch: 6| Step: 3
Training loss: 3.4899134635925293
Validation loss: 2.705933270915862

Epoch: 6| Step: 4
Training loss: 2.746487617492676
Validation loss: 2.708305738305533

Epoch: 6| Step: 5
Training loss: 2.476393699645996
Validation loss: 2.711708120120469

Epoch: 6| Step: 6
Training loss: 3.262775421142578
Validation loss: 2.7111714193897862

Epoch: 6| Step: 7
Training loss: 3.3188352584838867
Validation loss: 2.709344571636569

Epoch: 6| Step: 8
Training loss: 2.805846691131592
Validation loss: 2.709893262514504

Epoch: 6| Step: 9
Training loss: 3.0149221420288086
Validation loss: 2.7088344225319485

Epoch: 6| Step: 10
Training loss: 3.0739870071411133
Validation loss: 2.7074241868911253

Epoch: 6| Step: 11
Training loss: 2.501615047454834
Validation loss: 2.7079031441801336

Epoch: 6| Step: 12
Training loss: 2.85427188873291
Validation loss: 2.7066572994314213

Epoch: 6| Step: 13
Training loss: 2.290480613708496
Validation loss: 2.710566879600607

Epoch: 189| Step: 0
Training loss: 2.685603618621826
Validation loss: 2.712996385430777

Epoch: 6| Step: 1
Training loss: 3.3079535961151123
Validation loss: 2.7098956928458264

Epoch: 6| Step: 2
Training loss: 3.013774871826172
Validation loss: 2.7092178842072845

Epoch: 6| Step: 3
Training loss: 1.9791316986083984
Validation loss: 2.7074135170188

Epoch: 6| Step: 4
Training loss: 2.515449047088623
Validation loss: 2.714629578334029

Epoch: 6| Step: 5
Training loss: 3.145094394683838
Validation loss: 2.7128217015215146

Epoch: 6| Step: 6
Training loss: 3.2441704273223877
Validation loss: 2.7219848940449376

Epoch: 6| Step: 7
Training loss: 2.663041353225708
Validation loss: 2.7174648213130173

Epoch: 6| Step: 8
Training loss: 2.9350671768188477
Validation loss: 2.714909674018942

Epoch: 6| Step: 9
Training loss: 2.4888529777526855
Validation loss: 2.7150969659128497

Epoch: 6| Step: 10
Training loss: 2.8119149208068848
Validation loss: 2.7133588637075117

Epoch: 6| Step: 11
Training loss: 2.1134161949157715
Validation loss: 2.7115688452156643

Epoch: 6| Step: 12
Training loss: 3.5678606033325195
Validation loss: 2.70396158259402

Epoch: 6| Step: 13
Training loss: 3.3373239040374756
Validation loss: 2.7013720389335387

Epoch: 190| Step: 0
Training loss: 2.939742088317871
Validation loss: 2.701861035439276

Epoch: 6| Step: 1
Training loss: 2.823686361312866
Validation loss: 2.7044527274306103

Epoch: 6| Step: 2
Training loss: 2.2091023921966553
Validation loss: 2.708102908185733

Epoch: 6| Step: 3
Training loss: 2.9095029830932617
Validation loss: 2.711037938312818

Epoch: 6| Step: 4
Training loss: 2.879542112350464
Validation loss: 2.717075360718594

Epoch: 6| Step: 5
Training loss: 3.009291172027588
Validation loss: 2.7094707463377263

Epoch: 6| Step: 6
Training loss: 3.380819320678711
Validation loss: 2.7046843113437777

Epoch: 6| Step: 7
Training loss: 3.348569869995117
Validation loss: 2.7011157722883326

Epoch: 6| Step: 8
Training loss: 2.8152542114257812
Validation loss: 2.7000219155383367

Epoch: 6| Step: 9
Training loss: 2.3288683891296387
Validation loss: 2.7013321743216565

Epoch: 6| Step: 10
Training loss: 2.288405179977417
Validation loss: 2.695977339180567

Epoch: 6| Step: 11
Training loss: 1.9548691511154175
Validation loss: 2.6993165657084477

Epoch: 6| Step: 12
Training loss: 3.2056422233581543
Validation loss: 2.700705715405044

Epoch: 6| Step: 13
Training loss: 3.9059274196624756
Validation loss: 2.7001242663270686

Epoch: 191| Step: 0
Training loss: 3.114579200744629
Validation loss: 2.7035689687216156

Epoch: 6| Step: 1
Training loss: 2.4670569896698
Validation loss: 2.703598399316111

Epoch: 6| Step: 2
Training loss: 2.4488110542297363
Validation loss: 2.706490091098252

Epoch: 6| Step: 3
Training loss: 3.281536102294922
Validation loss: 2.7095904247735136

Epoch: 6| Step: 4
Training loss: 2.6417922973632812
Validation loss: 2.710778667080787

Epoch: 6| Step: 5
Training loss: 3.377535343170166
Validation loss: 2.713179962609404

Epoch: 6| Step: 6
Training loss: 2.541189193725586
Validation loss: 2.71358855565389

Epoch: 6| Step: 7
Training loss: 2.9063210487365723
Validation loss: 2.715440716794742

Epoch: 6| Step: 8
Training loss: 3.4943666458129883
Validation loss: 2.7154378532081522

Epoch: 6| Step: 9
Training loss: 2.8626537322998047
Validation loss: 2.7093719205548688

Epoch: 6| Step: 10
Training loss: 2.04386043548584
Validation loss: 2.707580448478781

Epoch: 6| Step: 11
Training loss: 1.9669932126998901
Validation loss: 2.7047933711800525

Epoch: 6| Step: 12
Training loss: 3.6594948768615723
Validation loss: 2.6998086232011036

Epoch: 6| Step: 13
Training loss: 2.656738758087158
Validation loss: 2.700721945813907

Epoch: 192| Step: 0
Training loss: 3.0655603408813477
Validation loss: 2.7039363948247765

Epoch: 6| Step: 1
Training loss: 2.4031052589416504
Validation loss: 2.706861108861944

Epoch: 6| Step: 2
Training loss: 2.948329210281372
Validation loss: 2.71301100074604

Epoch: 6| Step: 3
Training loss: 2.413630485534668
Validation loss: 2.720336498752717

Epoch: 6| Step: 4
Training loss: 2.909583568572998
Validation loss: 2.7238703440594416

Epoch: 6| Step: 5
Training loss: 2.5725643634796143
Validation loss: 2.7262188003909205

Epoch: 6| Step: 6
Training loss: 2.6657729148864746
Validation loss: 2.7113976863122757

Epoch: 6| Step: 7
Training loss: 2.8927230834960938
Validation loss: 2.702765844201529

Epoch: 6| Step: 8
Training loss: 2.663060188293457
Validation loss: 2.7011512556383686

Epoch: 6| Step: 9
Training loss: 2.4164540767669678
Validation loss: 2.700744536615187

Epoch: 6| Step: 10
Training loss: 3.742414951324463
Validation loss: 2.6979740050531205

Epoch: 6| Step: 11
Training loss: 2.2644855976104736
Validation loss: 2.6988104466469056

Epoch: 6| Step: 12
Training loss: 3.3953728675842285
Validation loss: 2.7001017396168043

Epoch: 6| Step: 13
Training loss: 3.460184335708618
Validation loss: 2.7025733891353814

Epoch: 193| Step: 0
Training loss: 2.6322288513183594
Validation loss: 2.7014495249717467

Epoch: 6| Step: 1
Training loss: 3.284986734390259
Validation loss: 2.705227259666689

Epoch: 6| Step: 2
Training loss: 2.833242177963257
Validation loss: 2.706718279469398

Epoch: 6| Step: 3
Training loss: 2.7015604972839355
Validation loss: 2.7049593515293573

Epoch: 6| Step: 4
Training loss: 3.1053075790405273
Validation loss: 2.7058885353867725

Epoch: 6| Step: 5
Training loss: 2.1242740154266357
Validation loss: 2.703169761165496

Epoch: 6| Step: 6
Training loss: 3.7271370887756348
Validation loss: 2.7021235650585544

Epoch: 6| Step: 7
Training loss: 2.246858596801758
Validation loss: 2.702226515739195

Epoch: 6| Step: 8
Training loss: 3.263380289077759
Validation loss: 2.7002963917229765

Epoch: 6| Step: 9
Training loss: 2.525190591812134
Validation loss: 2.697190692347865

Epoch: 6| Step: 10
Training loss: 2.783350944519043
Validation loss: 2.6942287260486233

Epoch: 6| Step: 11
Training loss: 2.8348793983459473
Validation loss: 2.6934195128820275

Epoch: 6| Step: 12
Training loss: 2.5789546966552734
Validation loss: 2.6971524312932003

Epoch: 6| Step: 13
Training loss: 2.9659712314605713
Validation loss: 2.6954852150332544

Epoch: 194| Step: 0
Training loss: 2.6401824951171875
Validation loss: 2.694437162850493

Epoch: 6| Step: 1
Training loss: 2.8470709323883057
Validation loss: 2.692626742906468

Epoch: 6| Step: 2
Training loss: 3.3635997772216797
Validation loss: 2.695677698299449

Epoch: 6| Step: 3
Training loss: 3.556199073791504
Validation loss: 2.6943145131552093

Epoch: 6| Step: 4
Training loss: 2.183520793914795
Validation loss: 2.693473680045015

Epoch: 6| Step: 5
Training loss: 3.010948419570923
Validation loss: 2.6910435717592955

Epoch: 6| Step: 6
Training loss: 2.871671676635742
Validation loss: 2.6919775778247463

Epoch: 6| Step: 7
Training loss: 2.1036880016326904
Validation loss: 2.6910801446566017

Epoch: 6| Step: 8
Training loss: 2.610240936279297
Validation loss: 2.694423944719376

Epoch: 6| Step: 9
Training loss: 2.3932437896728516
Validation loss: 2.6931566730622323

Epoch: 6| Step: 10
Training loss: 2.871762752532959
Validation loss: 2.692657216902702

Epoch: 6| Step: 11
Training loss: 2.3061399459838867
Validation loss: 2.693408114935762

Epoch: 6| Step: 12
Training loss: 3.293741226196289
Validation loss: 2.692600950118034

Epoch: 6| Step: 13
Training loss: 3.6996138095855713
Validation loss: 2.6906272262655277

Epoch: 195| Step: 0
Training loss: 2.0659170150756836
Validation loss: 2.6913757196036716

Epoch: 6| Step: 1
Training loss: 3.1607308387756348
Validation loss: 2.689640388693861

Epoch: 6| Step: 2
Training loss: 3.2310636043548584
Validation loss: 2.6906337225308983

Epoch: 6| Step: 3
Training loss: 2.4790244102478027
Validation loss: 2.691548042399909

Epoch: 6| Step: 4
Training loss: 3.5096302032470703
Validation loss: 2.693265481661725

Epoch: 6| Step: 5
Training loss: 2.804682970046997
Validation loss: 2.6938554035720004

Epoch: 6| Step: 6
Training loss: 2.886228084564209
Validation loss: 2.694492963052565

Epoch: 6| Step: 7
Training loss: 2.7819042205810547
Validation loss: 2.6914293073838755

Epoch: 6| Step: 8
Training loss: 2.857546806335449
Validation loss: 2.6942526807067213

Epoch: 6| Step: 9
Training loss: 3.203953504562378
Validation loss: 2.6940479919474614

Epoch: 6| Step: 10
Training loss: 2.4557945728302
Validation loss: 2.6881588428251204

Epoch: 6| Step: 11
Training loss: 2.8703718185424805
Validation loss: 2.690299698101577

Epoch: 6| Step: 12
Training loss: 2.580998659133911
Validation loss: 2.6907085757101736

Epoch: 6| Step: 13
Training loss: 2.210972785949707
Validation loss: 2.7025676337621545

Epoch: 196| Step: 0
Training loss: 3.241802453994751
Validation loss: 2.705191578916324

Epoch: 6| Step: 1
Training loss: 3.346285343170166
Validation loss: 2.6992319040401007

Epoch: 6| Step: 2
Training loss: 2.7169606685638428
Validation loss: 2.6904434939866424

Epoch: 6| Step: 3
Training loss: 2.934305191040039
Validation loss: 2.6876191605803785

Epoch: 6| Step: 4
Training loss: 2.4551796913146973
Validation loss: 2.686576871461766

Epoch: 6| Step: 5
Training loss: 3.0242958068847656
Validation loss: 2.6883745988210044

Epoch: 6| Step: 6
Training loss: 2.2078115940093994
Validation loss: 2.691464957370553

Epoch: 6| Step: 7
Training loss: 2.958122730255127
Validation loss: 2.6906065915220525

Epoch: 6| Step: 8
Training loss: 2.8715686798095703
Validation loss: 2.6891027496707056

Epoch: 6| Step: 9
Training loss: 3.0168585777282715
Validation loss: 2.6904047355856946

Epoch: 6| Step: 10
Training loss: 2.5802459716796875
Validation loss: 2.6896844756218696

Epoch: 6| Step: 11
Training loss: 2.099557876586914
Validation loss: 2.685891418046849

Epoch: 6| Step: 12
Training loss: 3.059530258178711
Validation loss: 2.6870324509118193

Epoch: 6| Step: 13
Training loss: 2.8607797622680664
Validation loss: 2.6927063567664034

Epoch: 197| Step: 0
Training loss: 2.996140480041504
Validation loss: 2.688314176374866

Epoch: 6| Step: 1
Training loss: 3.0776255130767822
Validation loss: 2.6906395368678595

Epoch: 6| Step: 2
Training loss: 2.6473536491394043
Validation loss: 2.6910428565035582

Epoch: 6| Step: 3
Training loss: 2.586028575897217
Validation loss: 2.68956736851764

Epoch: 6| Step: 4
Training loss: 3.799130916595459
Validation loss: 2.689453104490875

Epoch: 6| Step: 5
Training loss: 2.0752148628234863
Validation loss: 2.6925782157528784

Epoch: 6| Step: 6
Training loss: 3.114833354949951
Validation loss: 2.6928646461938017

Epoch: 6| Step: 7
Training loss: 2.7715420722961426
Validation loss: 2.6940968780107397

Epoch: 6| Step: 8
Training loss: 2.423107385635376
Validation loss: 2.6926975993699926

Epoch: 6| Step: 9
Training loss: 2.473898410797119
Validation loss: 2.6922378822039534

Epoch: 6| Step: 10
Training loss: 1.7799994945526123
Validation loss: 2.6895037466479885

Epoch: 6| Step: 11
Training loss: 3.709148406982422
Validation loss: 2.688656945382395

Epoch: 6| Step: 12
Training loss: 2.7794034481048584
Validation loss: 2.683021617192094

Epoch: 6| Step: 13
Training loss: 3.475248098373413
Validation loss: 2.687365403739355

Epoch: 198| Step: 0
Training loss: 2.9730193614959717
Validation loss: 2.6972428906348442

Epoch: 6| Step: 1
Training loss: 3.1240615844726562
Validation loss: 2.728674896301762

Epoch: 6| Step: 2
Training loss: 2.6546149253845215
Validation loss: 2.7225318672836467

Epoch: 6| Step: 3
Training loss: 3.454538345336914
Validation loss: 2.705827238739178

Epoch: 6| Step: 4
Training loss: 2.047889232635498
Validation loss: 2.697195565828713

Epoch: 6| Step: 5
Training loss: 2.354548215866089
Validation loss: 2.6885827408042005

Epoch: 6| Step: 6
Training loss: 2.6346144676208496
Validation loss: 2.681720964370235

Epoch: 6| Step: 7
Training loss: 3.340557813644409
Validation loss: 2.684323905616678

Epoch: 6| Step: 8
Training loss: 2.5116326808929443
Validation loss: 2.68928869821692

Epoch: 6| Step: 9
Training loss: 3.0031063556671143
Validation loss: 2.6949560949879308

Epoch: 6| Step: 10
Training loss: 3.9734320640563965
Validation loss: 2.6976941400958645

Epoch: 6| Step: 11
Training loss: 2.818246603012085
Validation loss: 2.6988379058017524

Epoch: 6| Step: 12
Training loss: 1.7269182205200195
Validation loss: 2.6985596251744095

Epoch: 6| Step: 13
Training loss: 3.09112286567688
Validation loss: 2.6962698992862495

Epoch: 199| Step: 0
Training loss: 3.5339581966400146
Validation loss: 2.6952234955244165

Epoch: 6| Step: 1
Training loss: 2.278390645980835
Validation loss: 2.6924104152187223

Epoch: 6| Step: 2
Training loss: 3.2158186435699463
Validation loss: 2.688941853020781

Epoch: 6| Step: 3
Training loss: 2.7474212646484375
Validation loss: 2.6844175015726397

Epoch: 6| Step: 4
Training loss: 3.213374376296997
Validation loss: 2.6854329391192366

Epoch: 6| Step: 5
Training loss: 2.8459601402282715
Validation loss: 2.6807579814746814

Epoch: 6| Step: 6
Training loss: 2.923326015472412
Validation loss: 2.6802544978357132

Epoch: 6| Step: 7
Training loss: 2.8462798595428467
Validation loss: 2.6797916530280985

Epoch: 6| Step: 8
Training loss: 2.461724281311035
Validation loss: 2.6857694323344896

Epoch: 6| Step: 9
Training loss: 3.441718578338623
Validation loss: 2.6927861757175897

Epoch: 6| Step: 10
Training loss: 2.045563220977783
Validation loss: 2.69955966805899

Epoch: 6| Step: 11
Training loss: 2.568166494369507
Validation loss: 2.7017088884948404

Epoch: 6| Step: 12
Training loss: 2.223115921020508
Validation loss: 2.7119026158445623

Epoch: 6| Step: 13
Training loss: 3.2910585403442383
Validation loss: 2.705153960053639

Epoch: 200| Step: 0
Training loss: 2.844254493713379
Validation loss: 2.7126586719225814

Epoch: 6| Step: 1
Training loss: 2.3248801231384277
Validation loss: 2.7015268905188448

Epoch: 6| Step: 2
Training loss: 2.8436779975891113
Validation loss: 2.688992528505223

Epoch: 6| Step: 3
Training loss: 2.9632840156555176
Validation loss: 2.679886656422769

Epoch: 6| Step: 4
Training loss: 3.2186532020568848
Validation loss: 2.6795719874802457

Epoch: 6| Step: 5
Training loss: 2.743917942047119
Validation loss: 2.683902258514076

Epoch: 6| Step: 6
Training loss: 3.143202781677246
Validation loss: 2.6874861383950837

Epoch: 6| Step: 7
Training loss: 3.4257564544677734
Validation loss: 2.7008918741697907

Epoch: 6| Step: 8
Training loss: 2.832160472869873
Validation loss: 2.705055739289971

Epoch: 6| Step: 9
Training loss: 2.1377720832824707
Validation loss: 2.7189262579846125

Epoch: 6| Step: 10
Training loss: 3.1493966579437256
Validation loss: 2.7222833274513163

Epoch: 6| Step: 11
Training loss: 3.022622585296631
Validation loss: 2.710192395794776

Epoch: 6| Step: 12
Training loss: 2.8647236824035645
Validation loss: 2.704631761838031

Epoch: 6| Step: 13
Training loss: 1.5954307317733765
Validation loss: 2.6929149217503046

Testing loss: 2.74625506401062
