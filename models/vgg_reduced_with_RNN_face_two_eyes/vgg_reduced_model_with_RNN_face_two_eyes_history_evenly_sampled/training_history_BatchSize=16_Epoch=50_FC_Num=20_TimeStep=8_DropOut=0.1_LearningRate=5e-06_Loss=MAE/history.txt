Epoch: 1| Step: 0
Training loss: 5.786126613616943
Validation loss: 5.20991854001117

Epoch: 6| Step: 1
Training loss: 3.889655113220215
Validation loss: 5.203386998945667

Epoch: 6| Step: 2
Training loss: 2.9720840454101562
Validation loss: 5.196552140738374

Epoch: 6| Step: 3
Training loss: 4.646750450134277
Validation loss: 5.189548148903795

Epoch: 6| Step: 4
Training loss: 5.3464250564575195
Validation loss: 5.183327346719722

Epoch: 6| Step: 5
Training loss: 4.815705299377441
Validation loss: 5.177260219409901

Epoch: 6| Step: 6
Training loss: 5.45458984375
Validation loss: 5.171083983554635

Epoch: 6| Step: 7
Training loss: 5.357685089111328
Validation loss: 5.164867631850704

Epoch: 6| Step: 8
Training loss: 5.336319923400879
Validation loss: 5.159183543215516

Epoch: 6| Step: 9
Training loss: 5.78855037689209
Validation loss: 5.1533626330796105

Epoch: 6| Step: 10
Training loss: 5.423574447631836
Validation loss: 5.147530196815409

Epoch: 6| Step: 11
Training loss: 4.528691291809082
Validation loss: 5.14124015069777

Epoch: 6| Step: 12
Training loss: 4.667581081390381
Validation loss: 5.1353558160925425

Epoch: 6| Step: 13
Training loss: 5.8973002433776855
Validation loss: 5.128727436065674

Epoch: 2| Step: 0
Training loss: 5.774762153625488
Validation loss: 5.122244840027184

Epoch: 6| Step: 1
Training loss: 3.931875228881836
Validation loss: 5.115052228332848

Epoch: 6| Step: 2
Training loss: 5.8824357986450195
Validation loss: 5.107981046040853

Epoch: 6| Step: 3
Training loss: 4.174871921539307
Validation loss: 5.1004939797104045

Epoch: 6| Step: 4
Training loss: 4.243926048278809
Validation loss: 5.092335829170802

Epoch: 6| Step: 5
Training loss: 5.041154384613037
Validation loss: 5.084164588682113

Epoch: 6| Step: 6
Training loss: 5.845834732055664
Validation loss: 5.076102995103406

Epoch: 6| Step: 7
Training loss: 6.307512283325195
Validation loss: 5.067582591887443

Epoch: 6| Step: 8
Training loss: 5.306347846984863
Validation loss: 5.058722624214747

Epoch: 6| Step: 9
Training loss: 4.783354759216309
Validation loss: 5.049115939806867

Epoch: 6| Step: 10
Training loss: 4.716226100921631
Validation loss: 5.03915943637971

Epoch: 6| Step: 11
Training loss: 3.548687696456909
Validation loss: 5.029222188457366

Epoch: 6| Step: 12
Training loss: 4.1782732009887695
Validation loss: 5.019211979322536

Epoch: 6| Step: 13
Training loss: 4.0171799659729
Validation loss: 5.0082228260655555

Epoch: 3| Step: 0
Training loss: 4.032955169677734
Validation loss: 4.996704363053845

Epoch: 6| Step: 1
Training loss: 5.056459426879883
Validation loss: 4.98551598928308

Epoch: 6| Step: 2
Training loss: 4.899289131164551
Validation loss: 4.9731433827389955

Epoch: 6| Step: 3
Training loss: 5.077813148498535
Validation loss: 4.9608478597415395

Epoch: 6| Step: 4
Training loss: 4.1121954917907715
Validation loss: 4.947680247727261

Epoch: 6| Step: 5
Training loss: 4.6848530769348145
Validation loss: 4.934565333909886

Epoch: 6| Step: 6
Training loss: 4.944577217102051
Validation loss: 4.92101675464261

Epoch: 6| Step: 7
Training loss: 5.08677339553833
Validation loss: 4.907104579351282

Epoch: 6| Step: 8
Training loss: 6.230396747589111
Validation loss: 4.8921220789673505

Epoch: 6| Step: 9
Training loss: 4.4023356437683105
Validation loss: 4.87714458280994

Epoch: 6| Step: 10
Training loss: 4.737916469573975
Validation loss: 4.861983581255841

Epoch: 6| Step: 11
Training loss: 3.4704113006591797
Validation loss: 4.845555618245115

Epoch: 6| Step: 12
Training loss: 4.132480621337891
Validation loss: 4.8296039437734954

Epoch: 6| Step: 13
Training loss: 5.289603233337402
Validation loss: 4.8127451148084415

Epoch: 4| Step: 0
Training loss: 3.9833269119262695
Validation loss: 4.796536117471675

Epoch: 6| Step: 1
Training loss: 3.5567824840545654
Validation loss: 4.780073909349339

Epoch: 6| Step: 2
Training loss: 4.484888076782227
Validation loss: 4.7624267916525564

Epoch: 6| Step: 3
Training loss: 4.916118621826172
Validation loss: 4.745274307907269

Epoch: 6| Step: 4
Training loss: 5.45883321762085
Validation loss: 4.726488574858634

Epoch: 6| Step: 5
Training loss: 4.390520095825195
Validation loss: 4.707982734967303

Epoch: 6| Step: 6
Training loss: 3.5376665592193604
Validation loss: 4.690260882018714

Epoch: 6| Step: 7
Training loss: 5.617980003356934
Validation loss: 4.670977346358761

Epoch: 6| Step: 8
Training loss: 4.308832168579102
Validation loss: 4.650196429221861

Epoch: 6| Step: 9
Training loss: 4.811298847198486
Validation loss: 4.630196899496099

Epoch: 6| Step: 10
Training loss: 5.127886772155762
Validation loss: 4.610089681481802

Epoch: 6| Step: 11
Training loss: 4.183064937591553
Validation loss: 4.588776798658474

Epoch: 6| Step: 12
Training loss: 3.8712244033813477
Validation loss: 4.566377839734478

Epoch: 6| Step: 13
Training loss: 4.084629535675049
Validation loss: 4.5461668301654115

Epoch: 5| Step: 0
Training loss: 3.886430263519287
Validation loss: 4.523440571241482

Epoch: 6| Step: 1
Training loss: 3.5684962272644043
Validation loss: 4.504014148507067

Epoch: 6| Step: 2
Training loss: 4.93818998336792
Validation loss: 4.482807708042924

Epoch: 6| Step: 3
Training loss: 4.536231994628906
Validation loss: 4.460718529198759

Epoch: 6| Step: 4
Training loss: 3.8880088329315186
Validation loss: 4.441612746125909

Epoch: 6| Step: 5
Training loss: 4.158452033996582
Validation loss: 4.420278231302897

Epoch: 6| Step: 6
Training loss: 4.7834930419921875
Validation loss: 4.399516577361732

Epoch: 6| Step: 7
Training loss: 4.038424015045166
Validation loss: 4.379848031587498

Epoch: 6| Step: 8
Training loss: 4.282891750335693
Validation loss: 4.357880120636315

Epoch: 6| Step: 9
Training loss: 3.693835735321045
Validation loss: 4.338667408112557

Epoch: 6| Step: 10
Training loss: 3.8807101249694824
Validation loss: 4.315947532653809

Epoch: 6| Step: 11
Training loss: 3.746527910232544
Validation loss: 4.295038130975539

Epoch: 6| Step: 12
Training loss: 3.990039825439453
Validation loss: 4.275260417692123

Epoch: 6| Step: 13
Training loss: 5.930330753326416
Validation loss: 4.252605248523015

Epoch: 6| Step: 0
Training loss: 4.335696697235107
Validation loss: 4.233310068807294

Epoch: 6| Step: 1
Training loss: 4.725614547729492
Validation loss: 4.212219469008907

Epoch: 6| Step: 2
Training loss: 3.8934011459350586
Validation loss: 4.193581904134443

Epoch: 6| Step: 3
Training loss: 3.399535894393921
Validation loss: 4.169914061023343

Epoch: 6| Step: 4
Training loss: 5.382080078125
Validation loss: 4.152630434241346

Epoch: 6| Step: 5
Training loss: 3.767904043197632
Validation loss: 4.134545910742975

Epoch: 6| Step: 6
Training loss: 3.777900218963623
Validation loss: 4.118129955824985

Epoch: 6| Step: 7
Training loss: 4.24538516998291
Validation loss: 4.100194649029803

Epoch: 6| Step: 8
Training loss: 3.754056215286255
Validation loss: 4.0828281730733895

Epoch: 6| Step: 9
Training loss: 3.160008668899536
Validation loss: 4.065401323380009

Epoch: 6| Step: 10
Training loss: 3.826219320297241
Validation loss: 4.048266008336057

Epoch: 6| Step: 11
Training loss: 4.663529872894287
Validation loss: 4.033418388776882

Epoch: 6| Step: 12
Training loss: 2.8876090049743652
Validation loss: 4.015657929963963

Epoch: 6| Step: 13
Training loss: 3.0817885398864746
Validation loss: 4.001099540341285

Epoch: 7| Step: 0
Training loss: 3.8006412982940674
Validation loss: 3.987967780841294

Epoch: 6| Step: 1
Training loss: 3.762070894241333
Validation loss: 3.973877306907408

Epoch: 6| Step: 2
Training loss: 3.1545419692993164
Validation loss: 3.9596759990979264

Epoch: 6| Step: 3
Training loss: 3.7324113845825195
Validation loss: 3.9442988108563166

Epoch: 6| Step: 4
Training loss: 2.988563299179077
Validation loss: 3.930146917220085

Epoch: 6| Step: 5
Training loss: 4.717170238494873
Validation loss: 3.9153321327701693

Epoch: 6| Step: 6
Training loss: 4.397006034851074
Validation loss: 3.898213299371863

Epoch: 6| Step: 7
Training loss: 3.966118812561035
Validation loss: 3.885732040610365

Epoch: 6| Step: 8
Training loss: 3.005321979522705
Validation loss: 3.8683719429918515

Epoch: 6| Step: 9
Training loss: 3.5774428844451904
Validation loss: 3.854108933479555

Epoch: 6| Step: 10
Training loss: 4.328394889831543
Validation loss: 3.8401037749423774

Epoch: 6| Step: 11
Training loss: 3.491880416870117
Validation loss: 3.8304741408235286

Epoch: 6| Step: 12
Training loss: 4.567551136016846
Validation loss: 3.8176418555680143

Epoch: 6| Step: 13
Training loss: 2.6947455406188965
Validation loss: 3.8055511751482562

Epoch: 8| Step: 0
Training loss: 3.4297940731048584
Validation loss: 3.7924041184045936

Epoch: 6| Step: 1
Training loss: 4.041073322296143
Validation loss: 3.7850218331941994

Epoch: 6| Step: 2
Training loss: 3.941328287124634
Validation loss: 3.7743547142192884

Epoch: 6| Step: 3
Training loss: 3.142929792404175
Validation loss: 3.7653177297243507

Epoch: 6| Step: 4
Training loss: 4.2026543617248535
Validation loss: 3.752720930243051

Epoch: 6| Step: 5
Training loss: 3.528573989868164
Validation loss: 3.7424706105263

Epoch: 6| Step: 6
Training loss: 3.7784266471862793
Validation loss: 3.732989300963699

Epoch: 6| Step: 7
Training loss: 3.121823787689209
Validation loss: 3.721835018486105

Epoch: 6| Step: 8
Training loss: 3.3899879455566406
Validation loss: 3.714030650354201

Epoch: 6| Step: 9
Training loss: 4.283782958984375
Validation loss: 3.7016710824863885

Epoch: 6| Step: 10
Training loss: 3.22021222114563
Validation loss: 3.694490414793773

Epoch: 6| Step: 11
Training loss: 3.770998954772949
Validation loss: 3.685400701338245

Epoch: 6| Step: 12
Training loss: 2.793051242828369
Validation loss: 3.6741494312081286

Epoch: 6| Step: 13
Training loss: 4.496660232543945
Validation loss: 3.665685417831585

Epoch: 9| Step: 0
Training loss: 3.4662554264068604
Validation loss: 3.658689401483023

Epoch: 6| Step: 1
Training loss: 3.318788528442383
Validation loss: 3.649638124691543

Epoch: 6| Step: 2
Training loss: 3.7527925968170166
Validation loss: 3.6421899539168163

Epoch: 6| Step: 3
Training loss: 3.6577117443084717
Validation loss: 3.6339263762197187

Epoch: 6| Step: 4
Training loss: 3.6324613094329834
Validation loss: 3.6253266590897755

Epoch: 6| Step: 5
Training loss: 2.838564157485962
Validation loss: 3.6192702477978123

Epoch: 6| Step: 6
Training loss: 4.1844892501831055
Validation loss: 3.6090357226710164

Epoch: 6| Step: 7
Training loss: 2.399670124053955
Validation loss: 3.6002848020163913

Epoch: 6| Step: 8
Training loss: 3.0850348472595215
Validation loss: 3.591582239315074

Epoch: 6| Step: 9
Training loss: 3.2861838340759277
Validation loss: 3.585433926633609

Epoch: 6| Step: 10
Training loss: 3.8303632736206055
Validation loss: 3.577277209169121

Epoch: 6| Step: 11
Training loss: 3.8552892208099365
Validation loss: 3.5688844291112756

Epoch: 6| Step: 12
Training loss: 4.115963459014893
Validation loss: 3.561766455250402

Epoch: 6| Step: 13
Training loss: 4.134846210479736
Validation loss: 3.551902691523234

Epoch: 10| Step: 0
Training loss: 4.6859025955200195
Validation loss: 3.539071565033287

Epoch: 6| Step: 1
Training loss: 3.559384822845459
Validation loss: 3.5299580045925674

Epoch: 6| Step: 2
Training loss: 2.7144083976745605
Validation loss: 3.5182693235335813

Epoch: 6| Step: 3
Training loss: 3.169053554534912
Validation loss: 3.5077441738497828

Epoch: 6| Step: 4
Training loss: 4.1114959716796875
Validation loss: 3.4921339404198433

Epoch: 6| Step: 5
Training loss: 2.7231884002685547
Validation loss: 3.4745867175440632

Epoch: 6| Step: 6
Training loss: 3.54732084274292
Validation loss: 3.4565097952401764

Epoch: 6| Step: 7
Training loss: 3.7953624725341797
Validation loss: 3.445642868677775

Epoch: 6| Step: 8
Training loss: 3.2338180541992188
Validation loss: 3.4383797517386814

Epoch: 6| Step: 9
Training loss: 4.191889762878418
Validation loss: 3.434136103558284

Epoch: 6| Step: 10
Training loss: 2.3553261756896973
Validation loss: 3.4293094065881546

Epoch: 6| Step: 11
Training loss: 3.274994373321533
Validation loss: 3.4230998869865172

Epoch: 6| Step: 12
Training loss: 2.5585107803344727
Validation loss: 3.4173075793891825

Epoch: 6| Step: 13
Training loss: 4.216026782989502
Validation loss: 3.41375070746227

Epoch: 11| Step: 0
Training loss: 3.281773805618286
Validation loss: 3.4112118623589955

Epoch: 6| Step: 1
Training loss: 3.6662368774414062
Validation loss: 3.404986745567732

Epoch: 6| Step: 2
Training loss: 2.884150266647339
Validation loss: 3.400425810967722

Epoch: 6| Step: 3
Training loss: 3.4793291091918945
Validation loss: 3.3943532692488803

Epoch: 6| Step: 4
Training loss: 4.253301620483398
Validation loss: 3.386463321665282

Epoch: 6| Step: 5
Training loss: 2.9169373512268066
Validation loss: 3.381432353809316

Epoch: 6| Step: 6
Training loss: 2.26078724861145
Validation loss: 3.3710737382211993

Epoch: 6| Step: 7
Training loss: 3.146458148956299
Validation loss: 3.3682073290630052

Epoch: 6| Step: 8
Training loss: 2.8126187324523926
Validation loss: 3.363382016458819

Epoch: 6| Step: 9
Training loss: 3.7375781536102295
Validation loss: 3.3573486984417005

Epoch: 6| Step: 10
Training loss: 4.249152660369873
Validation loss: 3.3544146476253385

Epoch: 6| Step: 11
Training loss: 3.848254919052124
Validation loss: 3.347628652408559

Epoch: 6| Step: 12
Training loss: 2.89646577835083
Validation loss: 3.345114246491463

Epoch: 6| Step: 13
Training loss: 3.0481038093566895
Validation loss: 3.3373391089900846

Epoch: 12| Step: 0
Training loss: 2.966470241546631
Validation loss: 3.3358773980089413

Epoch: 6| Step: 1
Training loss: 3.767116069793701
Validation loss: 3.332822738155242

Epoch: 6| Step: 2
Training loss: 3.160726547241211
Validation loss: 3.3306120057259836

Epoch: 6| Step: 3
Training loss: 2.710449457168579
Validation loss: 3.323235588689004

Epoch: 6| Step: 4
Training loss: 4.118835926055908
Validation loss: 3.3172853608285227

Epoch: 6| Step: 5
Training loss: 2.843064546585083
Validation loss: 3.31015686322284

Epoch: 6| Step: 6
Training loss: 3.0754051208496094
Validation loss: 3.3079504454007713

Epoch: 6| Step: 7
Training loss: 3.694357395172119
Validation loss: 3.3042817782330256

Epoch: 6| Step: 8
Training loss: 3.5120625495910645
Validation loss: 3.2973278491727767

Epoch: 6| Step: 9
Training loss: 2.646712303161621
Validation loss: 3.29339091239437

Epoch: 6| Step: 10
Training loss: 3.622584581375122
Validation loss: 3.293052893812938

Epoch: 6| Step: 11
Training loss: 3.251781702041626
Validation loss: 3.287356376647949

Epoch: 6| Step: 12
Training loss: 3.1727919578552246
Validation loss: 3.284213742902202

Epoch: 6| Step: 13
Training loss: 3.4606142044067383
Validation loss: 3.2821207738691762

Epoch: 13| Step: 0
Training loss: 3.962291717529297
Validation loss: 3.275998571867584

Epoch: 6| Step: 1
Training loss: 3.3876101970672607
Validation loss: 3.267973156385524

Epoch: 6| Step: 2
Training loss: 3.7783422470092773
Validation loss: 3.260830415192471

Epoch: 6| Step: 3
Training loss: 3.1761624813079834
Validation loss: 3.2562658197136334

Epoch: 6| Step: 4
Training loss: 2.9693970680236816
Validation loss: 3.2513509488874868

Epoch: 6| Step: 5
Training loss: 2.5503411293029785
Validation loss: 3.247070607318673

Epoch: 6| Step: 6
Training loss: 2.500613212585449
Validation loss: 3.2452094042172996

Epoch: 6| Step: 7
Training loss: 3.436809539794922
Validation loss: 3.238642108055853

Epoch: 6| Step: 8
Training loss: 3.6294333934783936
Validation loss: 3.2350734690184235

Epoch: 6| Step: 9
Training loss: 3.384920597076416
Validation loss: 3.234517325637161

Epoch: 6| Step: 10
Training loss: 2.9517810344696045
Validation loss: 3.223886561650102

Epoch: 6| Step: 11
Training loss: 2.909010410308838
Validation loss: 3.2210652289852018

Epoch: 6| Step: 12
Training loss: 3.3708672523498535
Validation loss: 3.2151889339570077

Epoch: 6| Step: 13
Training loss: 3.1149606704711914
Validation loss: 3.2062680259827645

Epoch: 14| Step: 0
Training loss: 2.6691553592681885
Validation loss: 3.205276927640361

Epoch: 6| Step: 1
Training loss: 4.130555152893066
Validation loss: 3.201557436297017

Epoch: 6| Step: 2
Training loss: 3.0750207901000977
Validation loss: 3.195815558074623

Epoch: 6| Step: 3
Training loss: 3.0944623947143555
Validation loss: 3.1924726168314614

Epoch: 6| Step: 4
Training loss: 3.8050262928009033
Validation loss: 3.189828759880476

Epoch: 6| Step: 5
Training loss: 3.150770664215088
Validation loss: 3.1853462239747405

Epoch: 6| Step: 6
Training loss: 3.49716854095459
Validation loss: 3.190603374153055

Epoch: 6| Step: 7
Training loss: 3.326079845428467
Validation loss: 3.1808511390480945

Epoch: 6| Step: 8
Training loss: 3.344449520111084
Validation loss: 3.178629062509024

Epoch: 6| Step: 9
Training loss: 3.337559700012207
Validation loss: 3.1807368134939544

Epoch: 6| Step: 10
Training loss: 3.116504192352295
Validation loss: 3.1812834893503497

Epoch: 6| Step: 11
Training loss: 2.5178675651550293
Validation loss: 3.177880112842847

Epoch: 6| Step: 12
Training loss: 2.6340065002441406
Validation loss: 3.1752950068443053

Epoch: 6| Step: 13
Training loss: 2.6924633979797363
Validation loss: 3.168122927347819

Epoch: 15| Step: 0
Training loss: 3.7673091888427734
Validation loss: 3.168489215194538

Epoch: 6| Step: 1
Training loss: 3.1218161582946777
Validation loss: 3.1610489224874847

Epoch: 6| Step: 2
Training loss: 3.868577480316162
Validation loss: 3.1563221100837953

Epoch: 6| Step: 3
Training loss: 2.3501062393188477
Validation loss: 3.1508076703676613

Epoch: 6| Step: 4
Training loss: 3.5578436851501465
Validation loss: 3.1483380025432957

Epoch: 6| Step: 5
Training loss: 1.6584628820419312
Validation loss: 3.1432673649121354

Epoch: 6| Step: 6
Training loss: 3.1398801803588867
Validation loss: 3.1390713773747927

Epoch: 6| Step: 7
Training loss: 3.4605226516723633
Validation loss: 3.136399740813881

Epoch: 6| Step: 8
Training loss: 2.5939345359802246
Validation loss: 3.140341984328403

Epoch: 6| Step: 9
Training loss: 3.3730380535125732
Validation loss: 3.1325688028848298

Epoch: 6| Step: 10
Training loss: 3.0801072120666504
Validation loss: 3.1238121037842124

Epoch: 6| Step: 11
Training loss: 3.0036654472351074
Validation loss: 3.118681179579868

Epoch: 6| Step: 12
Training loss: 3.699993848800659
Validation loss: 3.117446120067309

Epoch: 6| Step: 13
Training loss: 3.7748472690582275
Validation loss: 3.11511653982183

Epoch: 16| Step: 0
Training loss: 2.9388740062713623
Validation loss: 3.113753749478248

Epoch: 6| Step: 1
Training loss: 3.2657511234283447
Validation loss: 3.108674908197054

Epoch: 6| Step: 2
Training loss: 2.5923991203308105
Validation loss: 3.107161778275685

Epoch: 6| Step: 3
Training loss: 2.7868528366088867
Validation loss: 3.1027507192345074

Epoch: 6| Step: 4
Training loss: 2.6573448181152344
Validation loss: 3.099342620500954

Epoch: 6| Step: 5
Training loss: 2.3393752574920654
Validation loss: 3.0940597390615814

Epoch: 6| Step: 6
Training loss: 3.57736873626709
Validation loss: 3.092029789442657

Epoch: 6| Step: 7
Training loss: 3.241438627243042
Validation loss: 3.090503905409126

Epoch: 6| Step: 8
Training loss: 3.1462271213531494
Validation loss: 3.083267701569424

Epoch: 6| Step: 9
Training loss: 3.2683777809143066
Validation loss: 3.079972884988272

Epoch: 6| Step: 10
Training loss: 2.712498426437378
Validation loss: 3.0776194475030385

Epoch: 6| Step: 11
Training loss: 3.865323543548584
Validation loss: 3.0764934273176294

Epoch: 6| Step: 12
Training loss: 3.0784454345703125
Validation loss: 3.0750335775395876

Epoch: 6| Step: 13
Training loss: 5.073078155517578
Validation loss: 3.0676925848889094

Epoch: 17| Step: 0
Training loss: 2.367623805999756
Validation loss: 3.065376061265187

Epoch: 6| Step: 1
Training loss: 2.609459400177002
Validation loss: 3.0628236852666384

Epoch: 6| Step: 2
Training loss: 3.501288414001465
Validation loss: 3.0605963942825154

Epoch: 6| Step: 3
Training loss: 4.036498069763184
Validation loss: 3.056138518036053

Epoch: 6| Step: 4
Training loss: 3.113020420074463
Validation loss: 3.0540252321509906

Epoch: 6| Step: 5
Training loss: 3.357760429382324
Validation loss: 3.049055455833353

Epoch: 6| Step: 6
Training loss: 2.4838180541992188
Validation loss: 3.0467156364071752

Epoch: 6| Step: 7
Training loss: 3.5709497928619385
Validation loss: 3.049008733482771

Epoch: 6| Step: 8
Training loss: 3.0012850761413574
Validation loss: 3.0476584434509277

Epoch: 6| Step: 9
Training loss: 3.514909505844116
Validation loss: 3.0435357042538222

Epoch: 6| Step: 10
Training loss: 3.5574512481689453
Validation loss: 3.0406883352546283

Epoch: 6| Step: 11
Training loss: 3.185086250305176
Validation loss: 3.0400477096598637

Epoch: 6| Step: 12
Training loss: 2.3679933547973633
Validation loss: 3.0396209711669595

Epoch: 6| Step: 13
Training loss: 2.31239652633667
Validation loss: 3.0428386529286704

Epoch: 18| Step: 0
Training loss: 3.770275115966797
Validation loss: 3.027790654090143

Epoch: 6| Step: 1
Training loss: 3.4693589210510254
Validation loss: 3.024503392557944

Epoch: 6| Step: 2
Training loss: 2.7952563762664795
Validation loss: 3.0244266192118325

Epoch: 6| Step: 3
Training loss: 2.8671412467956543
Validation loss: 3.0251704851786294

Epoch: 6| Step: 4
Training loss: 2.470841646194458
Validation loss: 3.0220692824291926

Epoch: 6| Step: 5
Training loss: 2.927532434463501
Validation loss: 3.022825087270429

Epoch: 6| Step: 6
Training loss: 3.133042097091675
Validation loss: 3.021241372631442

Epoch: 6| Step: 7
Training loss: 3.13749623298645
Validation loss: 3.02015789862602

Epoch: 6| Step: 8
Training loss: 2.2618465423583984
Validation loss: 3.023896994129304

Epoch: 6| Step: 9
Training loss: 2.924348831176758
Validation loss: 3.0198403378968597

Epoch: 6| Step: 10
Training loss: 2.73406720161438
Validation loss: 3.016858216254942

Epoch: 6| Step: 11
Training loss: 3.4714200496673584
Validation loss: 3.005547403007425

Epoch: 6| Step: 12
Training loss: 3.4690754413604736
Validation loss: 3.0036450022010395

Epoch: 6| Step: 13
Training loss: 4.011043071746826
Validation loss: 2.998604077164845

Epoch: 19| Step: 0
Training loss: 3.2510149478912354
Validation loss: 2.9970713302653325

Epoch: 6| Step: 1
Training loss: 2.4538414478302
Validation loss: 2.996469654062743

Epoch: 6| Step: 2
Training loss: 3.171374559402466
Validation loss: 2.9901943027332263

Epoch: 6| Step: 3
Training loss: 2.950894832611084
Validation loss: 2.987875461578369

Epoch: 6| Step: 4
Training loss: 3.244809150695801
Validation loss: 2.9820191885835383

Epoch: 6| Step: 5
Training loss: 3.5674469470977783
Validation loss: 2.980291553722915

Epoch: 6| Step: 6
Training loss: 2.280973434448242
Validation loss: 2.976970416243358

Epoch: 6| Step: 7
Training loss: 3.7798118591308594
Validation loss: 2.9740348708245063

Epoch: 6| Step: 8
Training loss: 3.5661959648132324
Validation loss: 2.966746437934137

Epoch: 6| Step: 9
Training loss: 3.0147016048431396
Validation loss: 2.965969741985362

Epoch: 6| Step: 10
Training loss: 2.0011513233184814
Validation loss: 2.964770363223168

Epoch: 6| Step: 11
Training loss: 2.9596498012542725
Validation loss: 2.961882652774934

Epoch: 6| Step: 12
Training loss: 3.2812304496765137
Validation loss: 2.9600816131919943

Epoch: 6| Step: 13
Training loss: 3.291945457458496
Validation loss: 2.9544935328986055

Epoch: 20| Step: 0
Training loss: 2.4755778312683105
Validation loss: 2.9533220414192445

Epoch: 6| Step: 1
Training loss: 3.734276294708252
Validation loss: 2.9502760030890025

Epoch: 6| Step: 2
Training loss: 3.4244682788848877
Validation loss: 2.9464596035659953

Epoch: 6| Step: 3
Training loss: 4.217859268188477
Validation loss: 2.9461015526966383

Epoch: 6| Step: 4
Training loss: 2.846024513244629
Validation loss: 2.9411894582932994

Epoch: 6| Step: 5
Training loss: 2.2807788848876953
Validation loss: 2.9439695676167807

Epoch: 6| Step: 6
Training loss: 2.254913568496704
Validation loss: 2.9448520598873014

Epoch: 6| Step: 7
Training loss: 2.5947165489196777
Validation loss: 2.9385016169599307

Epoch: 6| Step: 8
Training loss: 3.932683229446411
Validation loss: 2.9389637926573395

Epoch: 6| Step: 9
Training loss: 2.7173235416412354
Validation loss: 2.9381806517160065

Epoch: 6| Step: 10
Training loss: 3.0200438499450684
Validation loss: 2.931004488339988

Epoch: 6| Step: 11
Training loss: 2.580366373062134
Validation loss: 2.928582206849129

Epoch: 6| Step: 12
Training loss: 3.1314239501953125
Validation loss: 2.9227724126590195

Epoch: 6| Step: 13
Training loss: 3.1715891361236572
Validation loss: 2.921621173940679

Epoch: 21| Step: 0
Training loss: 3.387861490249634
Validation loss: 2.91926993349547

Epoch: 6| Step: 1
Training loss: 2.841193437576294
Validation loss: 2.9167901572360786

Epoch: 6| Step: 2
Training loss: 2.825617790222168
Validation loss: 2.9161697562022875

Epoch: 6| Step: 3
Training loss: 2.0284388065338135
Validation loss: 2.913948525664627

Epoch: 6| Step: 4
Training loss: 3.0888476371765137
Validation loss: 2.912075683634768

Epoch: 6| Step: 5
Training loss: 3.653447389602661
Validation loss: 2.9109800323363273

Epoch: 6| Step: 6
Training loss: 3.3885741233825684
Validation loss: 2.9096188852863927

Epoch: 6| Step: 7
Training loss: 2.3961853981018066
Validation loss: 2.9031855624209166

Epoch: 6| Step: 8
Training loss: 2.9213573932647705
Validation loss: 2.9015030758355254

Epoch: 6| Step: 9
Training loss: 3.428010940551758
Validation loss: 2.8980089413222445

Epoch: 6| Step: 10
Training loss: 3.3393661975860596
Validation loss: 2.897657730246103

Epoch: 6| Step: 11
Training loss: 3.3842246532440186
Validation loss: 2.895288008515553

Epoch: 6| Step: 12
Training loss: 2.2264678478240967
Validation loss: 2.8925669270177043

Epoch: 6| Step: 13
Training loss: 3.210129737854004
Validation loss: 2.888680763142083

Epoch: 22| Step: 0
Training loss: 3.078080177307129
Validation loss: 2.8868230286464898

Epoch: 6| Step: 1
Training loss: 2.022454261779785
Validation loss: 2.8806140858639955

Epoch: 6| Step: 2
Training loss: 3.04866361618042
Validation loss: 2.880462069665232

Epoch: 6| Step: 3
Training loss: 2.70601749420166
Validation loss: 2.882418604307277

Epoch: 6| Step: 4
Training loss: 3.702418327331543
Validation loss: 2.8794540384764313

Epoch: 6| Step: 5
Training loss: 3.2647900581359863
Validation loss: 2.8780845288307435

Epoch: 6| Step: 6
Training loss: 3.299877882003784
Validation loss: 2.869608945744012

Epoch: 6| Step: 7
Training loss: 2.5410990715026855
Validation loss: 2.8705478406721547

Epoch: 6| Step: 8
Training loss: 2.770836591720581
Validation loss: 2.8718650699943624

Epoch: 6| Step: 9
Training loss: 3.0101447105407715
Validation loss: 2.870261699922623

Epoch: 6| Step: 10
Training loss: 3.5264902114868164
Validation loss: 2.8736050872392553

Epoch: 6| Step: 11
Training loss: 2.709291696548462
Validation loss: 2.864931857714089

Epoch: 6| Step: 12
Training loss: 2.969987630844116
Validation loss: 2.864956719900972

Epoch: 6| Step: 13
Training loss: 3.1637887954711914
Validation loss: 2.8603822595329693

Epoch: 23| Step: 0
Training loss: 2.843122959136963
Validation loss: 2.8525185021021033

Epoch: 6| Step: 1
Training loss: 3.203901529312134
Validation loss: 2.8519512350841234

Epoch: 6| Step: 2
Training loss: 3.133016347885132
Validation loss: 2.854401244912096

Epoch: 6| Step: 3
Training loss: 2.863161087036133
Validation loss: 2.850460224254157

Epoch: 6| Step: 4
Training loss: 3.395066261291504
Validation loss: 2.848247866476736

Epoch: 6| Step: 5
Training loss: 2.7904114723205566
Validation loss: 2.8466684638812976

Epoch: 6| Step: 6
Training loss: 2.8050055503845215
Validation loss: 2.8467117124988186

Epoch: 6| Step: 7
Training loss: 2.3933568000793457
Validation loss: 2.8455106263519614

Epoch: 6| Step: 8
Training loss: 2.925373077392578
Validation loss: 2.844072526501071

Epoch: 6| Step: 9
Training loss: 2.9246630668640137
Validation loss: 2.8436094560930805

Epoch: 6| Step: 10
Training loss: 2.994570255279541
Validation loss: 2.8421181042989097

Epoch: 6| Step: 11
Training loss: 2.8060569763183594
Validation loss: 2.845394244758032

Epoch: 6| Step: 12
Training loss: 3.0882019996643066
Validation loss: 2.8397096895402476

Epoch: 6| Step: 13
Training loss: 3.586906909942627
Validation loss: 2.8370696908684185

Epoch: 24| Step: 0
Training loss: 2.4855339527130127
Validation loss: 2.8377530459434754

Epoch: 6| Step: 1
Training loss: 2.732395648956299
Validation loss: 2.8351505110340733

Epoch: 6| Step: 2
Training loss: 2.8603529930114746
Validation loss: 2.8291368740861134

Epoch: 6| Step: 3
Training loss: 3.309183120727539
Validation loss: 2.8303934245981197

Epoch: 6| Step: 4
Training loss: 3.557978630065918
Validation loss: 2.830056334054598

Epoch: 6| Step: 5
Training loss: 2.525083541870117
Validation loss: 2.8228681164403118

Epoch: 6| Step: 6
Training loss: 3.5752463340759277
Validation loss: 2.8246475676054597

Epoch: 6| Step: 7
Training loss: 3.343543529510498
Validation loss: 2.8218967581308014

Epoch: 6| Step: 8
Training loss: 2.5158891677856445
Validation loss: 2.8257395477705103

Epoch: 6| Step: 9
Training loss: 2.3048548698425293
Validation loss: 2.8210949667038454

Epoch: 6| Step: 10
Training loss: 2.674048900604248
Validation loss: 2.822571139181814

Epoch: 6| Step: 11
Training loss: 3.3532590866088867
Validation loss: 2.8193766301678074

Epoch: 6| Step: 12
Training loss: 2.930264472961426
Validation loss: 2.8211034087724585

Epoch: 6| Step: 13
Training loss: 3.240712881088257
Validation loss: 2.817865622940884

Epoch: 25| Step: 0
Training loss: 2.202838659286499
Validation loss: 2.8137905623323176

Epoch: 6| Step: 1
Training loss: 2.827393054962158
Validation loss: 2.8155997491651967

Epoch: 6| Step: 2
Training loss: 3.136606216430664
Validation loss: 2.81240386860345

Epoch: 6| Step: 3
Training loss: 2.7147936820983887
Validation loss: 2.8121207119316183

Epoch: 6| Step: 4
Training loss: 3.6377716064453125
Validation loss: 2.8118027128199095

Epoch: 6| Step: 5
Training loss: 2.6102476119995117
Validation loss: 2.8080553367573726

Epoch: 6| Step: 6
Training loss: 3.114783763885498
Validation loss: 2.807811483260124

Epoch: 6| Step: 7
Training loss: 2.7339327335357666
Validation loss: 2.807364304860433

Epoch: 6| Step: 8
Training loss: 3.028426170349121
Validation loss: 2.8069988860878894

Epoch: 6| Step: 9
Training loss: 2.430011749267578
Validation loss: 2.804248415013795

Epoch: 6| Step: 10
Training loss: 3.193345785140991
Validation loss: 2.8018260309773106

Epoch: 6| Step: 11
Training loss: 3.4171695709228516
Validation loss: 2.798529791575606

Epoch: 6| Step: 12
Training loss: 2.850247859954834
Validation loss: 2.8013573590145318

Epoch: 6| Step: 13
Training loss: 3.4222166538238525
Validation loss: 2.796281204428724

Epoch: 26| Step: 0
Training loss: 3.388597249984741
Validation loss: 2.7994503872368925

Epoch: 6| Step: 1
Training loss: 3.264962911605835
Validation loss: 2.7934752048984652

Epoch: 6| Step: 2
Training loss: 2.3470263481140137
Validation loss: 2.7942741404297533

Epoch: 6| Step: 3
Training loss: 2.928339958190918
Validation loss: 2.7896014413525982

Epoch: 6| Step: 4
Training loss: 2.954862594604492
Validation loss: 2.792280735508088

Epoch: 6| Step: 5
Training loss: 2.784785747528076
Validation loss: 2.7911637444649973

Epoch: 6| Step: 6
Training loss: 3.3579814434051514
Validation loss: 2.791753181847193

Epoch: 6| Step: 7
Training loss: 3.6312122344970703
Validation loss: 2.7864487350627942

Epoch: 6| Step: 8
Training loss: 2.8521716594696045
Validation loss: 2.784474839446365

Epoch: 6| Step: 9
Training loss: 3.5736446380615234
Validation loss: 2.782942828311715

Epoch: 6| Step: 10
Training loss: 2.6411356925964355
Validation loss: 2.7814717087694394

Epoch: 6| Step: 11
Training loss: 1.9034533500671387
Validation loss: 2.7803073339564826

Epoch: 6| Step: 12
Training loss: 3.07527494430542
Validation loss: 2.7799789546638407

Epoch: 6| Step: 13
Training loss: 1.6979056596755981
Validation loss: 2.775834301466583

Epoch: 27| Step: 0
Training loss: 3.249223232269287
Validation loss: 2.7848905004480833

Epoch: 6| Step: 1
Training loss: 2.890028953552246
Validation loss: 2.7811266555581042

Epoch: 6| Step: 2
Training loss: 2.5287606716156006
Validation loss: 2.790672307373375

Epoch: 6| Step: 3
Training loss: 2.9236884117126465
Validation loss: 2.783657984067035

Epoch: 6| Step: 4
Training loss: 3.3801779747009277
Validation loss: 2.779495705840408

Epoch: 6| Step: 5
Training loss: 2.805704116821289
Validation loss: 2.7758425256257415

Epoch: 6| Step: 6
Training loss: 3.445965528488159
Validation loss: 2.772605267904138

Epoch: 6| Step: 7
Training loss: 2.1384401321411133
Validation loss: 2.7773774080379035

Epoch: 6| Step: 8
Training loss: 3.0243241786956787
Validation loss: 2.788899544746645

Epoch: 6| Step: 9
Training loss: 2.8404176235198975
Validation loss: 2.780367177019837

Epoch: 6| Step: 10
Training loss: 3.556216239929199
Validation loss: 2.7777185747700353

Epoch: 6| Step: 11
Training loss: 2.652574062347412
Validation loss: 2.7771048674019436

Epoch: 6| Step: 12
Training loss: 2.670945405960083
Validation loss: 2.77175635163502

Epoch: 6| Step: 13
Training loss: 2.614339590072632
Validation loss: 2.7721296638570805

Epoch: 28| Step: 0
Training loss: 2.398068904876709
Validation loss: 2.768914830300116

Epoch: 6| Step: 1
Training loss: 3.15456485748291
Validation loss: 2.7666327722610964

Epoch: 6| Step: 2
Training loss: 2.745260000228882
Validation loss: 2.7683041095733643

Epoch: 6| Step: 3
Training loss: 3.0026865005493164
Validation loss: 2.7650285100424163

Epoch: 6| Step: 4
Training loss: 2.8251988887786865
Validation loss: 2.7665916822289907

Epoch: 6| Step: 5
Training loss: 3.636082172393799
Validation loss: 2.765408949185443

Epoch: 6| Step: 6
Training loss: 2.7272391319274902
Validation loss: 2.7690364442845827

Epoch: 6| Step: 7
Training loss: 3.778836727142334
Validation loss: 2.7611120131707962

Epoch: 6| Step: 8
Training loss: 2.9777705669403076
Validation loss: 2.759396158238893

Epoch: 6| Step: 9
Training loss: 2.581498861312866
Validation loss: 2.757233399216847

Epoch: 6| Step: 10
Training loss: 1.9466516971588135
Validation loss: 2.7588348337399062

Epoch: 6| Step: 11
Training loss: 2.8293862342834473
Validation loss: 2.7557425575871624

Epoch: 6| Step: 12
Training loss: 3.5211739540100098
Validation loss: 2.755658616301834

Epoch: 6| Step: 13
Training loss: 2.4013566970825195
Validation loss: 2.7552473314346804

Epoch: 29| Step: 0
Training loss: 3.3008689880371094
Validation loss: 2.754890829004267

Epoch: 6| Step: 1
Training loss: 2.6203389167785645
Validation loss: 2.751936338281119

Epoch: 6| Step: 2
Training loss: 2.7592391967773438
Validation loss: 2.7542092210503033

Epoch: 6| Step: 3
Training loss: 2.4001142978668213
Validation loss: 2.7518989347642466

Epoch: 6| Step: 4
Training loss: 2.883678436279297
Validation loss: 2.7512997914386053

Epoch: 6| Step: 5
Training loss: 2.7326905727386475
Validation loss: 2.7488663017108874

Epoch: 6| Step: 6
Training loss: 2.308089256286621
Validation loss: 2.7485395554573304

Epoch: 6| Step: 7
Training loss: 3.7545382976531982
Validation loss: 2.74758340210043

Epoch: 6| Step: 8
Training loss: 3.228233814239502
Validation loss: 2.7458883664941274

Epoch: 6| Step: 9
Training loss: 2.4309885501861572
Validation loss: 2.7451612282824773

Epoch: 6| Step: 10
Training loss: 2.8037352561950684
Validation loss: 2.7488437519278577

Epoch: 6| Step: 11
Training loss: 3.7356228828430176
Validation loss: 2.7472183576194187

Epoch: 6| Step: 12
Training loss: 2.515599489212036
Validation loss: 2.747557622130199

Epoch: 6| Step: 13
Training loss: 3.2861287593841553
Validation loss: 2.7500491091000137

Epoch: 30| Step: 0
Training loss: 2.6984505653381348
Validation loss: 2.7449201460807555

Epoch: 6| Step: 1
Training loss: 2.9302897453308105
Validation loss: 2.742462081293906

Epoch: 6| Step: 2
Training loss: 2.554760456085205
Validation loss: 2.7447110119686333

Epoch: 6| Step: 3
Training loss: 2.8790578842163086
Validation loss: 2.73917741416603

Epoch: 6| Step: 4
Training loss: 3.3516082763671875
Validation loss: 2.73747092934065

Epoch: 6| Step: 5
Training loss: 3.070648670196533
Validation loss: 2.733791264154578

Epoch: 6| Step: 6
Training loss: 2.898533582687378
Validation loss: 2.734459461704377

Epoch: 6| Step: 7
Training loss: 2.4704363346099854
Validation loss: 2.733251089690834

Epoch: 6| Step: 8
Training loss: 2.7747554779052734
Validation loss: 2.7359812362219698

Epoch: 6| Step: 9
Training loss: 3.3419647216796875
Validation loss: 2.7440312805996148

Epoch: 6| Step: 10
Training loss: 2.668346881866455
Validation loss: 2.744754839968938

Epoch: 6| Step: 11
Training loss: 2.673196792602539
Validation loss: 2.7393926753792712

Epoch: 6| Step: 12
Training loss: 2.826026439666748
Validation loss: 2.7335213409957064

Epoch: 6| Step: 13
Training loss: 3.7258100509643555
Validation loss: 2.7322291584425074

Epoch: 31| Step: 0
Training loss: 3.1222691535949707
Validation loss: 2.7267474461627264

Epoch: 6| Step: 1
Training loss: 2.9907126426696777
Validation loss: 2.72515961944416

Epoch: 6| Step: 2
Training loss: 3.1085333824157715
Validation loss: 2.727140083107897

Epoch: 6| Step: 3
Training loss: 3.097259044647217
Validation loss: 2.726052371404504

Epoch: 6| Step: 4
Training loss: 4.2690229415893555
Validation loss: 2.7240023100247948

Epoch: 6| Step: 5
Training loss: 2.4860434532165527
Validation loss: 2.7198859748019966

Epoch: 6| Step: 6
Training loss: 2.4324655532836914
Validation loss: 2.7194523580612673

Epoch: 6| Step: 7
Training loss: 3.529993772506714
Validation loss: 2.722283560742614

Epoch: 6| Step: 8
Training loss: 2.5829391479492188
Validation loss: 2.7224662406470186

Epoch: 6| Step: 9
Training loss: 2.7046151161193848
Validation loss: 2.7185827839759087

Epoch: 6| Step: 10
Training loss: 1.610680341720581
Validation loss: 2.721697086928993

Epoch: 6| Step: 11
Training loss: 2.5917062759399414
Validation loss: 2.7205183326557116

Epoch: 6| Step: 12
Training loss: 3.0072731971740723
Validation loss: 2.7163992517737934

Epoch: 6| Step: 13
Training loss: 2.80768084526062
Validation loss: 2.7181772647365445

Epoch: 32| Step: 0
Training loss: 2.294543743133545
Validation loss: 2.716805801596693

Epoch: 6| Step: 1
Training loss: 3.484445571899414
Validation loss: 2.7148739753230924

Epoch: 6| Step: 2
Training loss: 2.8309378623962402
Validation loss: 2.71866895562859

Epoch: 6| Step: 3
Training loss: 2.8866078853607178
Validation loss: 2.714996027690108

Epoch: 6| Step: 4
Training loss: 2.4374208450317383
Validation loss: 2.7131730920525006

Epoch: 6| Step: 5
Training loss: 2.5135624408721924
Validation loss: 2.7132282180170857

Epoch: 6| Step: 6
Training loss: 3.6218643188476562
Validation loss: 2.7131732740709857

Epoch: 6| Step: 7
Training loss: 2.9981889724731445
Validation loss: 2.7102770754086074

Epoch: 6| Step: 8
Training loss: 2.5119082927703857
Validation loss: 2.706991139278617

Epoch: 6| Step: 9
Training loss: 2.3234148025512695
Validation loss: 2.709071420854138

Epoch: 6| Step: 10
Training loss: 2.7170495986938477
Validation loss: 2.7192369558477916

Epoch: 6| Step: 11
Training loss: 3.4727516174316406
Validation loss: 2.724354749084801

Epoch: 6| Step: 12
Training loss: 3.284989595413208
Validation loss: 2.7245498344462407

Epoch: 6| Step: 13
Training loss: 2.9305338859558105
Validation loss: 2.721966443523284

Epoch: 33| Step: 0
Training loss: 3.263637065887451
Validation loss: 2.719198488420056

Epoch: 6| Step: 1
Training loss: 2.899491786956787
Validation loss: 2.7076493078662502

Epoch: 6| Step: 2
Training loss: 2.6736254692077637
Validation loss: 2.70465753668098

Epoch: 6| Step: 3
Training loss: 2.9769973754882812
Validation loss: 2.6977839341727634

Epoch: 6| Step: 4
Training loss: 1.3074238300323486
Validation loss: 2.701969746620424

Epoch: 6| Step: 5
Training loss: 2.8540568351745605
Validation loss: 2.7013545138861543

Epoch: 6| Step: 6
Training loss: 3.4165985584259033
Validation loss: 2.701364896630728

Epoch: 6| Step: 7
Training loss: 3.983745813369751
Validation loss: 2.6993347752478813

Epoch: 6| Step: 8
Training loss: 2.675930976867676
Validation loss: 2.69745453967843

Epoch: 6| Step: 9
Training loss: 2.5596296787261963
Validation loss: 2.7016217785496868

Epoch: 6| Step: 10
Training loss: 2.3830459117889404
Validation loss: 2.7236862054435154

Epoch: 6| Step: 11
Training loss: 3.639904499053955
Validation loss: 2.7023019021557224

Epoch: 6| Step: 12
Training loss: 2.607093572616577
Validation loss: 2.6970611515865532

Epoch: 6| Step: 13
Training loss: 2.9961817264556885
Validation loss: 2.6955024708983717

Epoch: 34| Step: 0
Training loss: 3.4940311908721924
Validation loss: 2.692851492153701

Epoch: 6| Step: 1
Training loss: 2.5329933166503906
Validation loss: 2.6913602326505925

Epoch: 6| Step: 2
Training loss: 2.7119369506835938
Validation loss: 2.692021798062068

Epoch: 6| Step: 3
Training loss: 3.6888551712036133
Validation loss: 2.6909686865345126

Epoch: 6| Step: 4
Training loss: 2.475888729095459
Validation loss: 2.6905100832703295

Epoch: 6| Step: 5
Training loss: 2.930967330932617
Validation loss: 2.6897322516287527

Epoch: 6| Step: 6
Training loss: 2.2071566581726074
Validation loss: 2.6896115810640397

Epoch: 6| Step: 7
Training loss: 2.8847427368164062
Validation loss: 2.690851278202508

Epoch: 6| Step: 8
Training loss: 2.780395746231079
Validation loss: 2.68997508992431

Epoch: 6| Step: 9
Training loss: 3.1950438022613525
Validation loss: 2.6923732142294607

Epoch: 6| Step: 10
Training loss: 3.5291130542755127
Validation loss: 2.6961941103781424

Epoch: 6| Step: 11
Training loss: 2.0945816040039062
Validation loss: 2.6960433298541653

Epoch: 6| Step: 12
Training loss: 2.250159740447998
Validation loss: 2.6892324775777836

Epoch: 6| Step: 13
Training loss: 3.6773312091827393
Validation loss: 2.685990812957928

Epoch: 35| Step: 0
Training loss: 2.4643616676330566
Validation loss: 2.682110132709626

Epoch: 6| Step: 1
Training loss: 2.695293426513672
Validation loss: 2.6862814682786182

Epoch: 6| Step: 2
Training loss: 2.8151497840881348
Validation loss: 2.6874852693209084

Epoch: 6| Step: 3
Training loss: 2.7300662994384766
Validation loss: 2.6843206446657897

Epoch: 6| Step: 4
Training loss: 2.2382187843322754
Validation loss: 2.6878163737635457

Epoch: 6| Step: 5
Training loss: 3.555891513824463
Validation loss: 2.6885954487708306

Epoch: 6| Step: 6
Training loss: 2.5582990646362305
Validation loss: 2.6862992945537774

Epoch: 6| Step: 7
Training loss: 3.2041471004486084
Validation loss: 2.688111105272847

Epoch: 6| Step: 8
Training loss: 2.88120174407959
Validation loss: 2.686164068919356

Epoch: 6| Step: 9
Training loss: 2.4807991981506348
Validation loss: 2.6838611505364858

Epoch: 6| Step: 10
Training loss: 3.0322000980377197
Validation loss: 2.6838404978475263

Epoch: 6| Step: 11
Training loss: 3.3129329681396484
Validation loss: 2.6838469172036774

Epoch: 6| Step: 12
Training loss: 2.9259164333343506
Validation loss: 2.6829498942180345

Epoch: 6| Step: 13
Training loss: 3.4093406200408936
Validation loss: 2.6954502495386268

Epoch: 36| Step: 0
Training loss: 2.7110981941223145
Validation loss: 2.677682686877507

Epoch: 6| Step: 1
Training loss: 2.424567461013794
Validation loss: 2.680247196587183

Epoch: 6| Step: 2
Training loss: 2.4927120208740234
Validation loss: 2.6786590519771782

Epoch: 6| Step: 3
Training loss: 2.997225284576416
Validation loss: 2.6752804325472925

Epoch: 6| Step: 4
Training loss: 2.320279121398926
Validation loss: 2.679161610141877

Epoch: 6| Step: 5
Training loss: 2.617569923400879
Validation loss: 2.6780071591818206

Epoch: 6| Step: 6
Training loss: 2.4455771446228027
Validation loss: 2.6778782260033394

Epoch: 6| Step: 7
Training loss: 3.271920680999756
Validation loss: 2.6774308014941472

Epoch: 6| Step: 8
Training loss: 3.026036500930786
Validation loss: 2.6752817451312976

Epoch: 6| Step: 9
Training loss: 3.008845806121826
Validation loss: 2.679889286718061

Epoch: 6| Step: 10
Training loss: 3.018339157104492
Validation loss: 2.6745477927628385

Epoch: 6| Step: 11
Training loss: 3.1128878593444824
Validation loss: 2.6763106007729807

Epoch: 6| Step: 12
Training loss: 3.515991687774658
Validation loss: 2.672969572005733

Epoch: 6| Step: 13
Training loss: 3.083923816680908
Validation loss: 2.672405699247955

Epoch: 37| Step: 0
Training loss: 2.9600353240966797
Validation loss: 2.6722340763256116

Epoch: 6| Step: 1
Training loss: 2.8205690383911133
Validation loss: 2.6698148942762807

Epoch: 6| Step: 2
Training loss: 3.1708579063415527
Validation loss: 2.677607246624526

Epoch: 6| Step: 3
Training loss: 2.5654706954956055
Validation loss: 2.6852531356196248

Epoch: 6| Step: 4
Training loss: 2.7268123626708984
Validation loss: 2.7040739546539965

Epoch: 6| Step: 5
Training loss: 3.2395384311676025
Validation loss: 2.6722289977535123

Epoch: 6| Step: 6
Training loss: 2.644976854324341
Validation loss: 2.672395080648443

Epoch: 6| Step: 7
Training loss: 2.3530783653259277
Validation loss: 2.673253487515193

Epoch: 6| Step: 8
Training loss: 2.877981424331665
Validation loss: 2.672362260921027

Epoch: 6| Step: 9
Training loss: 3.073086977005005
Validation loss: 2.6777710478792907

Epoch: 6| Step: 10
Training loss: 3.4975719451904297
Validation loss: 2.686001226466189

Epoch: 6| Step: 11
Training loss: 3.0165982246398926
Validation loss: 2.6823420422051543

Epoch: 6| Step: 12
Training loss: 2.5175247192382812
Validation loss: 2.690796326565486

Epoch: 6| Step: 13
Training loss: 2.2120985984802246
Validation loss: 2.6795607920615905

Epoch: 38| Step: 0
Training loss: 2.8912694454193115
Validation loss: 2.6734751065572104

Epoch: 6| Step: 1
Training loss: 2.7620773315429688
Validation loss: 2.675638021961335

Epoch: 6| Step: 2
Training loss: 3.2815423011779785
Validation loss: 2.6776988198680263

Epoch: 6| Step: 3
Training loss: 2.816641092300415
Validation loss: 2.6754707085189

Epoch: 6| Step: 4
Training loss: 2.563969612121582
Validation loss: 2.6762603431619625

Epoch: 6| Step: 5
Training loss: 3.0144424438476562
Validation loss: 2.679139124449863

Epoch: 6| Step: 6
Training loss: 2.6187405586242676
Validation loss: 2.7071244460280224

Epoch: 6| Step: 7
Training loss: 2.1743431091308594
Validation loss: 2.6936452260581394

Epoch: 6| Step: 8
Training loss: 3.4945170879364014
Validation loss: 2.6837616325706564

Epoch: 6| Step: 9
Training loss: 2.703139305114746
Validation loss: 2.679889673827797

Epoch: 6| Step: 10
Training loss: 2.52986216545105
Validation loss: 2.6821214742557977

Epoch: 6| Step: 11
Training loss: 2.5373568534851074
Validation loss: 2.6848685920879407

Epoch: 6| Step: 12
Training loss: 3.4989991188049316
Validation loss: 2.692002204156691

Epoch: 6| Step: 13
Training loss: 3.1778371334075928
Validation loss: 2.6914307096953034

Epoch: 39| Step: 0
Training loss: 3.0141754150390625
Validation loss: 2.695844557977492

Epoch: 6| Step: 1
Training loss: 2.7819440364837646
Validation loss: 2.6898627768280687

Epoch: 6| Step: 2
Training loss: 2.5779576301574707
Validation loss: 2.6949875636767318

Epoch: 6| Step: 3
Training loss: 2.8253560066223145
Validation loss: 2.6791950887249363

Epoch: 6| Step: 4
Training loss: 2.655229091644287
Validation loss: 2.6713437008601364

Epoch: 6| Step: 5
Training loss: 2.885911464691162
Validation loss: 2.6699782443302933

Epoch: 6| Step: 6
Training loss: 3.294153928756714
Validation loss: 2.666524625593616

Epoch: 6| Step: 7
Training loss: 3.070345640182495
Validation loss: 2.6653200477682133

Epoch: 6| Step: 8
Training loss: 2.850837230682373
Validation loss: 2.666428058378158

Epoch: 6| Step: 9
Training loss: 3.0438613891601562
Validation loss: 2.6648829214034544

Epoch: 6| Step: 10
Training loss: 2.9191951751708984
Validation loss: 2.6654328812835035

Epoch: 6| Step: 11
Training loss: 2.1786231994628906
Validation loss: 2.6622417434569328

Epoch: 6| Step: 12
Training loss: 2.567586660385132
Validation loss: 2.6629483545980146

Epoch: 6| Step: 13
Training loss: 3.5315802097320557
Validation loss: 2.664039642580094

Epoch: 40| Step: 0
Training loss: 2.8630270957946777
Validation loss: 2.670588880456904

Epoch: 6| Step: 1
Training loss: 2.979691505432129
Validation loss: 2.674102411475233

Epoch: 6| Step: 2
Training loss: 2.5479559898376465
Validation loss: 2.6697407332799767

Epoch: 6| Step: 3
Training loss: 2.666750431060791
Validation loss: 2.670245990958265

Epoch: 6| Step: 4
Training loss: 2.722522258758545
Validation loss: 2.6652130978081816

Epoch: 6| Step: 5
Training loss: 2.898695707321167
Validation loss: 2.6644356994218725

Epoch: 6| Step: 6
Training loss: 2.9152042865753174
Validation loss: 2.657756608019593

Epoch: 6| Step: 7
Training loss: 3.6869523525238037
Validation loss: 2.6550180604380946

Epoch: 6| Step: 8
Training loss: 2.1392276287078857
Validation loss: 2.6577956855938

Epoch: 6| Step: 9
Training loss: 2.3622477054595947
Validation loss: 2.6560164754108717

Epoch: 6| Step: 10
Training loss: 3.656595230102539
Validation loss: 2.657303479409987

Epoch: 6| Step: 11
Training loss: 2.6051340103149414
Validation loss: 2.6571087221945486

Epoch: 6| Step: 12
Training loss: 2.8780736923217773
Validation loss: 2.6634181904536423

Epoch: 6| Step: 13
Training loss: 2.7856762409210205
Validation loss: 2.666934241530716

Epoch: 41| Step: 0
Training loss: 2.8329782485961914
Validation loss: 2.667584652541786

Epoch: 6| Step: 1
Training loss: 2.2221410274505615
Validation loss: 2.6679223429772163

Epoch: 6| Step: 2
Training loss: 2.7267656326293945
Validation loss: 2.66904818114414

Epoch: 6| Step: 3
Training loss: 2.875206232070923
Validation loss: 2.6584227726023686

Epoch: 6| Step: 4
Training loss: 3.6755218505859375
Validation loss: 2.6527668224867953

Epoch: 6| Step: 5
Training loss: 3.1943578720092773
Validation loss: 2.6515560380874144

Epoch: 6| Step: 6
Training loss: 2.8788270950317383
Validation loss: 2.6491956377542145

Epoch: 6| Step: 7
Training loss: 2.5624375343322754
Validation loss: 2.648882758232855

Epoch: 6| Step: 8
Training loss: 2.3595595359802246
Validation loss: 2.645513585818711

Epoch: 6| Step: 9
Training loss: 2.475846529006958
Validation loss: 2.653990819890012

Epoch: 6| Step: 10
Training loss: 3.544461727142334
Validation loss: 2.655518718945083

Epoch: 6| Step: 11
Training loss: 2.0454699993133545
Validation loss: 2.657447415013467

Epoch: 6| Step: 12
Training loss: 3.4411144256591797
Validation loss: 2.6825021338719193

Epoch: 6| Step: 13
Training loss: 2.9425852298736572
Validation loss: 2.6613955036286385

Epoch: 42| Step: 0
Training loss: 3.16152286529541
Validation loss: 2.6485764352224206

Epoch: 6| Step: 1
Training loss: 3.3694489002227783
Validation loss: 2.649730569572859

Epoch: 6| Step: 2
Training loss: 2.457404136657715
Validation loss: 2.6527435600116687

Epoch: 6| Step: 3
Training loss: 2.949019432067871
Validation loss: 2.652607451203049

Epoch: 6| Step: 4
Training loss: 2.7449402809143066
Validation loss: 2.650437706260271

Epoch: 6| Step: 5
Training loss: 2.8408377170562744
Validation loss: 2.6462862491607666

Epoch: 6| Step: 6
Training loss: 3.845482349395752
Validation loss: 2.6522807126404135

Epoch: 6| Step: 7
Training loss: 2.34951114654541
Validation loss: 2.6528918179132606

Epoch: 6| Step: 8
Training loss: 2.2674202919006348
Validation loss: 2.657445397428287

Epoch: 6| Step: 9
Training loss: 2.249441623687744
Validation loss: 2.6739362234710367

Epoch: 6| Step: 10
Training loss: 2.7222859859466553
Validation loss: 2.6604417024120206

Epoch: 6| Step: 11
Training loss: 2.9820871353149414
Validation loss: 2.657942912911856

Epoch: 6| Step: 12
Training loss: 3.074134588241577
Validation loss: 2.655459306573355

Epoch: 6| Step: 13
Training loss: 2.6147077083587646
Validation loss: 2.6676166570314797

Epoch: 43| Step: 0
Training loss: 2.828573226928711
Validation loss: 2.6717118370917534

Epoch: 6| Step: 1
Training loss: 1.825878620147705
Validation loss: 2.6753085838851107

Epoch: 6| Step: 2
Training loss: 3.0468902587890625
Validation loss: 2.6753655018345004

Epoch: 6| Step: 3
Training loss: 3.2508304119110107
Validation loss: 2.6716880388157342

Epoch: 6| Step: 4
Training loss: 1.9637951850891113
Validation loss: 2.6749176184336343

Epoch: 6| Step: 5
Training loss: 2.527881383895874
Validation loss: 2.67334932409307

Epoch: 6| Step: 6
Training loss: 2.6732993125915527
Validation loss: 2.672380998570432

Epoch: 6| Step: 7
Training loss: 4.224115371704102
Validation loss: 2.6700301683077248

Epoch: 6| Step: 8
Training loss: 2.7052934169769287
Validation loss: 2.6698882810531126

Epoch: 6| Step: 9
Training loss: 2.8900156021118164
Validation loss: 2.6676173492144515

Epoch: 6| Step: 10
Training loss: 2.111449718475342
Validation loss: 2.6672197900792605

Epoch: 6| Step: 11
Training loss: 3.577850341796875
Validation loss: 2.6642789815061834

Epoch: 6| Step: 12
Training loss: 3.3036298751831055
Validation loss: 2.6621414025624595

Epoch: 6| Step: 13
Training loss: 2.8916268348693848
Validation loss: 2.660261610502838

Epoch: 44| Step: 0
Training loss: 2.92152738571167
Validation loss: 2.6524951868159796

Epoch: 6| Step: 1
Training loss: 3.205291748046875
Validation loss: 2.648155176511375

Epoch: 6| Step: 2
Training loss: 2.746614456176758
Validation loss: 2.6480116997995684

Epoch: 6| Step: 3
Training loss: 2.2520742416381836
Validation loss: 2.650089958662628

Epoch: 6| Step: 4
Training loss: 3.9692223072052
Validation loss: 2.6552494110599643

Epoch: 6| Step: 5
Training loss: 2.3024942874908447
Validation loss: 2.650672676742718

Epoch: 6| Step: 6
Training loss: 2.4778213500976562
Validation loss: 2.6440463835193264

Epoch: 6| Step: 7
Training loss: 2.363736152648926
Validation loss: 2.645718697578676

Epoch: 6| Step: 8
Training loss: 2.5747694969177246
Validation loss: 2.6520645438983874

Epoch: 6| Step: 9
Training loss: 2.9409408569335938
Validation loss: 2.653439134679815

Epoch: 6| Step: 10
Training loss: 3.0372557640075684
Validation loss: 2.6535225081187424

Epoch: 6| Step: 11
Training loss: 2.580197811126709
Validation loss: 2.654293232066657

Epoch: 6| Step: 12
Training loss: 2.9929795265197754
Validation loss: 2.654690501510456

Epoch: 6| Step: 13
Training loss: 3.6717753410339355
Validation loss: 2.649991753280804

Epoch: 45| Step: 0
Training loss: 3.367734432220459
Validation loss: 2.6480345802922405

Epoch: 6| Step: 1
Training loss: 2.485799551010132
Validation loss: 2.645939488564768

Epoch: 6| Step: 2
Training loss: 3.051584243774414
Validation loss: 2.64382291096513

Epoch: 6| Step: 3
Training loss: 2.3369975090026855
Validation loss: 2.645015116660826

Epoch: 6| Step: 4
Training loss: 3.343012809753418
Validation loss: 2.641688185353433

Epoch: 6| Step: 5
Training loss: 2.9291043281555176
Validation loss: 2.6415978272755942

Epoch: 6| Step: 6
Training loss: 2.897169351577759
Validation loss: 2.63969761325467

Epoch: 6| Step: 7
Training loss: 3.516815185546875
Validation loss: 2.638398103816535

Epoch: 6| Step: 8
Training loss: 2.441664695739746
Validation loss: 2.637402942103724

Epoch: 6| Step: 9
Training loss: 1.8045942783355713
Validation loss: 2.6401750400502193

Epoch: 6| Step: 10
Training loss: 3.643632411956787
Validation loss: 2.6398939112181306

Epoch: 6| Step: 11
Training loss: 1.8233102560043335
Validation loss: 2.641397612069243

Epoch: 6| Step: 12
Training loss: 3.067373037338257
Validation loss: 2.6367047704676145

Epoch: 6| Step: 13
Training loss: 2.898271083831787
Validation loss: 2.6365775164737495

Epoch: 46| Step: 0
Training loss: 2.2755157947540283
Validation loss: 2.639513005492508

Epoch: 6| Step: 1
Training loss: 3.6147594451904297
Validation loss: 2.6408633493608042

Epoch: 6| Step: 2
Training loss: 2.8023810386657715
Validation loss: 2.636861252528365

Epoch: 6| Step: 3
Training loss: 2.224215030670166
Validation loss: 2.6336526563090663

Epoch: 6| Step: 4
Training loss: 3.30153751373291
Validation loss: 2.629421659695205

Epoch: 6| Step: 5
Training loss: 2.3884613513946533
Validation loss: 2.633566553874682

Epoch: 6| Step: 6
Training loss: 3.2550361156463623
Validation loss: 2.629718836917672

Epoch: 6| Step: 7
Training loss: 2.8489723205566406
Validation loss: 2.6331696612860567

Epoch: 6| Step: 8
Training loss: 2.871049404144287
Validation loss: 2.6297482675121677

Epoch: 6| Step: 9
Training loss: 2.1684482097625732
Validation loss: 2.6270129321723856

Epoch: 6| Step: 10
Training loss: 2.9958596229553223
Validation loss: 2.624065306878859

Epoch: 6| Step: 11
Training loss: 3.204195499420166
Validation loss: 2.6335682151138142

Epoch: 6| Step: 12
Training loss: 2.768559455871582
Validation loss: 2.6340754160317044

Epoch: 6| Step: 13
Training loss: 2.7234935760498047
Validation loss: 2.634241588654057

Epoch: 47| Step: 0
Training loss: 2.6988303661346436
Validation loss: 2.6424157363112255

Epoch: 6| Step: 1
Training loss: 2.646270513534546
Validation loss: 2.653185418857041

Epoch: 6| Step: 2
Training loss: 2.613245964050293
Validation loss: 2.6717000930540022

Epoch: 6| Step: 3
Training loss: 3.399460792541504
Validation loss: 2.680913225297005

Epoch: 6| Step: 4
Training loss: 3.2880239486694336
Validation loss: 2.68109417218034

Epoch: 6| Step: 5
Training loss: 3.2878401279449463
Validation loss: 2.680227515518024

Epoch: 6| Step: 6
Training loss: 3.3524835109710693
Validation loss: 2.6509383698945403

Epoch: 6| Step: 7
Training loss: 2.5282435417175293
Validation loss: 2.63729497437836

Epoch: 6| Step: 8
Training loss: 3.569262981414795
Validation loss: 2.6239708521032847

Epoch: 6| Step: 9
Training loss: 1.8369674682617188
Validation loss: 2.628763347543696

Epoch: 6| Step: 10
Training loss: 2.694892644882202
Validation loss: 2.6247944267847205

Epoch: 6| Step: 11
Training loss: 2.5286169052124023
Validation loss: 2.62550401431258

Epoch: 6| Step: 12
Training loss: 2.3289127349853516
Validation loss: 2.625907467257592

Epoch: 6| Step: 13
Training loss: 2.8009743690490723
Validation loss: 2.627356536926762

Epoch: 48| Step: 0
Training loss: 2.778740406036377
Validation loss: 2.6296695534900953

Epoch: 6| Step: 1
Training loss: 3.359029769897461
Validation loss: 2.6461342867984565

Epoch: 6| Step: 2
Training loss: 2.958138942718506
Validation loss: 2.652255271070747

Epoch: 6| Step: 3
Training loss: 3.060593843460083
Validation loss: 2.6367683308098906

Epoch: 6| Step: 4
Training loss: 2.6033501625061035
Validation loss: 2.627703953814763

Epoch: 6| Step: 5
Training loss: 2.7586288452148438
Validation loss: 2.6223459602684103

Epoch: 6| Step: 6
Training loss: 3.200216293334961
Validation loss: 2.6228014064091507

Epoch: 6| Step: 7
Training loss: 2.3481059074401855
Validation loss: 2.623993686450425

Epoch: 6| Step: 8
Training loss: 2.826805591583252
Validation loss: 2.6233707576669674

Epoch: 6| Step: 9
Training loss: 3.010871648788452
Validation loss: 2.6224075312255533

Epoch: 6| Step: 10
Training loss: 2.6257731914520264
Validation loss: 2.6258953822556363

Epoch: 6| Step: 11
Training loss: 2.6234331130981445
Validation loss: 2.6232699040443666

Epoch: 6| Step: 12
Training loss: 2.726566791534424
Validation loss: 2.6229954599052347

Epoch: 6| Step: 13
Training loss: 2.303602457046509
Validation loss: 2.6259388641644548

Epoch: 49| Step: 0
Training loss: 2.1606833934783936
Validation loss: 2.6251542234933503

Epoch: 6| Step: 1
Training loss: 2.8918206691741943
Validation loss: 2.626046452471005

Epoch: 6| Step: 2
Training loss: 2.5351057052612305
Validation loss: 2.6223710890739196

Epoch: 6| Step: 3
Training loss: 3.3867602348327637
Validation loss: 2.626633885086224

Epoch: 6| Step: 4
Training loss: 2.3579983711242676
Validation loss: 2.631528041696036

Epoch: 6| Step: 5
Training loss: 2.93249773979187
Validation loss: 2.6341915617706957

Epoch: 6| Step: 6
Training loss: 2.1322431564331055
Validation loss: 2.626534487611504

Epoch: 6| Step: 7
Training loss: 3.4868621826171875
Validation loss: 2.6306266169394217

Epoch: 6| Step: 8
Training loss: 2.644595146179199
Validation loss: 2.6295602090897097

Epoch: 6| Step: 9
Training loss: 2.509763240814209
Validation loss: 2.6259726350025465

Epoch: 6| Step: 10
Training loss: 2.813650369644165
Validation loss: 2.626867732694072

Epoch: 6| Step: 11
Training loss: 3.721250534057617
Validation loss: 2.621474435252528

Epoch: 6| Step: 12
Training loss: 3.3698384761810303
Validation loss: 2.61817600393808

Epoch: 6| Step: 13
Training loss: 2.090165138244629
Validation loss: 2.625722333949099

Epoch: 50| Step: 0
Training loss: 2.4863076210021973
Validation loss: 2.6192766927903697

Epoch: 6| Step: 1
Training loss: 3.215772867202759
Validation loss: 2.6189732987393617

Epoch: 6| Step: 2
Training loss: 3.2561097145080566
Validation loss: 2.6241961935515046

Epoch: 6| Step: 3
Training loss: 2.1995744705200195
Validation loss: 2.6282141465012745

Epoch: 6| Step: 4
Training loss: 2.701697587966919
Validation loss: 2.626303421553745

Epoch: 6| Step: 5
Training loss: 2.3817362785339355
Validation loss: 2.6275723749591458

Epoch: 6| Step: 6
Training loss: 2.866760015487671
Validation loss: 2.629021683046895

Epoch: 6| Step: 7
Training loss: 2.659456253051758
Validation loss: 2.630900034340479

Epoch: 6| Step: 8
Training loss: 2.515634298324585
Validation loss: 2.6218281458782893

Epoch: 6| Step: 9
Training loss: 3.1415507793426514
Validation loss: 2.6191507821441977

Epoch: 6| Step: 10
Training loss: 3.4875569343566895
Validation loss: 2.6195752492514988

Epoch: 6| Step: 11
Training loss: 2.6313493251800537
Validation loss: 2.6190568400967504

Epoch: 6| Step: 12
Training loss: 3.223635196685791
Validation loss: 2.61919504339977

Epoch: 6| Step: 13
Training loss: 2.304612159729004
Validation loss: 2.6175681749979653

Testing loss: 2.735736714469062
