Epoch: 1| Step: 0
Training loss: 5.32554281987235
Validation loss: 5.723142018067104

Epoch: 6| Step: 1
Training loss: 6.436642487828051
Validation loss: 5.717605703169085

Epoch: 6| Step: 2
Training loss: 5.9230408338729665
Validation loss: 5.712208141070378

Epoch: 6| Step: 3
Training loss: 6.02683139682794
Validation loss: 5.70707793144147

Epoch: 6| Step: 4
Training loss: 6.325498586913673
Validation loss: 5.70205376431662

Epoch: 6| Step: 5
Training loss: 5.228358759787332
Validation loss: 5.696961237772461

Epoch: 6| Step: 6
Training loss: 5.2585769709726184
Validation loss: 5.6912582224723085

Epoch: 6| Step: 7
Training loss: 4.714923241679206
Validation loss: 5.685277777638078

Epoch: 6| Step: 8
Training loss: 6.068410293075726
Validation loss: 5.678791846272064

Epoch: 6| Step: 9
Training loss: 6.101491226776425
Validation loss: 5.671574059533475

Epoch: 6| Step: 10
Training loss: 5.947625130246644
Validation loss: 5.663116835539077

Epoch: 6| Step: 11
Training loss: 4.756297304015956
Validation loss: 5.654061045662829

Epoch: 6| Step: 12
Training loss: 5.442309477822129
Validation loss: 5.644178923289742

Epoch: 6| Step: 13
Training loss: 6.5856745295215635
Validation loss: 5.633280044500702

Epoch: 2| Step: 0
Training loss: 5.720387708955704
Validation loss: 5.6210360726284625

Epoch: 6| Step: 1
Training loss: 6.870809491703948
Validation loss: 5.607669664903363

Epoch: 6| Step: 2
Training loss: 4.19042024275765
Validation loss: 5.593359716295664

Epoch: 6| Step: 3
Training loss: 4.902306788331778
Validation loss: 5.577113685517809

Epoch: 6| Step: 4
Training loss: 5.27415866018021
Validation loss: 5.5598875250085085

Epoch: 6| Step: 5
Training loss: 5.7856844004779235
Validation loss: 5.541675869550642

Epoch: 6| Step: 6
Training loss: 5.556291179697477
Validation loss: 5.520975252797381

Epoch: 6| Step: 7
Training loss: 4.988693041073648
Validation loss: 5.499396420619181

Epoch: 6| Step: 8
Training loss: 6.570927322415372
Validation loss: 5.475066157655038

Epoch: 6| Step: 9
Training loss: 6.415122833146336
Validation loss: 5.449166321661206

Epoch: 6| Step: 10
Training loss: 4.916145210846691
Validation loss: 5.420582423512265

Epoch: 6| Step: 11
Training loss: 5.260142021437574
Validation loss: 5.390433250894024

Epoch: 6| Step: 12
Training loss: 4.9333944514501
Validation loss: 5.357851422548711

Epoch: 6| Step: 13
Training loss: 5.629038399515734
Validation loss: 5.323930601604654

Epoch: 3| Step: 0
Training loss: 6.225713310584253
Validation loss: 5.288359982425938

Epoch: 6| Step: 1
Training loss: 5.73234102104393
Validation loss: 5.249993439029123

Epoch: 6| Step: 2
Training loss: 5.698818472492511
Validation loss: 5.209387204103601

Epoch: 6| Step: 3
Training loss: 4.994928267291307
Validation loss: 5.167881102774373

Epoch: 6| Step: 4
Training loss: 4.550302164293813
Validation loss: 5.123898687717368

Epoch: 6| Step: 5
Training loss: 5.708419724898935
Validation loss: 5.07935495833219

Epoch: 6| Step: 6
Training loss: 4.98962814321552
Validation loss: 5.033260970046075

Epoch: 6| Step: 7
Training loss: 5.187383811292939
Validation loss: 4.985868939041557

Epoch: 6| Step: 8
Training loss: 4.92611889207591
Validation loss: 4.939245054513705

Epoch: 6| Step: 9
Training loss: 4.635472169465234
Validation loss: 4.892978341431531

Epoch: 6| Step: 10
Training loss: 4.076817094507713
Validation loss: 4.846437830655579

Epoch: 6| Step: 11
Training loss: 4.59334411904038
Validation loss: 4.805371254257252

Epoch: 6| Step: 12
Training loss: 3.9634590023341474
Validation loss: 4.763611438706906

Epoch: 6| Step: 13
Training loss: 5.728660459407564
Validation loss: 4.720841777886532

Epoch: 4| Step: 0
Training loss: 4.553371546870259
Validation loss: 4.6837525885816875

Epoch: 6| Step: 1
Training loss: 4.05557552895933
Validation loss: 4.643477630036254

Epoch: 6| Step: 2
Training loss: 4.800759398470408
Validation loss: 4.604370359162437

Epoch: 6| Step: 3
Training loss: 5.4520775081305555
Validation loss: 4.5662493974473675

Epoch: 6| Step: 4
Training loss: 4.643572657858235
Validation loss: 4.525187316636128

Epoch: 6| Step: 5
Training loss: 4.51988721284836
Validation loss: 4.4832195759921865

Epoch: 6| Step: 6
Training loss: 4.666407623367452
Validation loss: 4.446057484708251

Epoch: 6| Step: 7
Training loss: 4.586744091319345
Validation loss: 4.414659292764854

Epoch: 6| Step: 8
Training loss: 4.70117714932712
Validation loss: 4.388952204081997

Epoch: 6| Step: 9
Training loss: 5.249975476888875
Validation loss: 4.36516775982569

Epoch: 6| Step: 10
Training loss: 4.004294950644597
Validation loss: 4.337471967919045

Epoch: 6| Step: 11
Training loss: 3.629771807935803
Validation loss: 4.315905574101974

Epoch: 6| Step: 12
Training loss: 3.453529713937088
Validation loss: 4.293458099767587

Epoch: 6| Step: 13
Training loss: 5.579294803316933
Validation loss: 4.270391610765579

Epoch: 5| Step: 0
Training loss: 4.471157252560462
Validation loss: 4.249165293153726

Epoch: 6| Step: 1
Training loss: 5.016846695180096
Validation loss: 4.2258595540225645

Epoch: 6| Step: 2
Training loss: 4.012629835458428
Validation loss: 4.205762022588484

Epoch: 6| Step: 3
Training loss: 3.9345356515288885
Validation loss: 4.186049623892443

Epoch: 6| Step: 4
Training loss: 4.5605372557446735
Validation loss: 4.166356272467393

Epoch: 6| Step: 5
Training loss: 2.9451842748116213
Validation loss: 4.153653336863209

Epoch: 6| Step: 6
Training loss: 4.487481400390163
Validation loss: 4.135171495487568

Epoch: 6| Step: 7
Training loss: 4.661727039399472
Validation loss: 4.123242801643281

Epoch: 6| Step: 8
Training loss: 3.7712681696994297
Validation loss: 4.107620202091999

Epoch: 6| Step: 9
Training loss: 3.6573551170663676
Validation loss: 4.0920798270017595

Epoch: 6| Step: 10
Training loss: 3.794769079849888
Validation loss: 4.078194323711046

Epoch: 6| Step: 11
Training loss: 3.1691917758548467
Validation loss: 4.063126154021836

Epoch: 6| Step: 12
Training loss: 5.964183718394145
Validation loss: 4.05279412464862

Epoch: 6| Step: 13
Training loss: 4.572728227745906
Validation loss: 4.042221575896918

Epoch: 6| Step: 0
Training loss: 4.419236545133752
Validation loss: 4.032527798972728

Epoch: 6| Step: 1
Training loss: 2.396476714503598
Validation loss: 4.022403417930463

Epoch: 6| Step: 2
Training loss: 4.170319799514734
Validation loss: 4.009905345950276

Epoch: 6| Step: 3
Training loss: 4.946461331680513
Validation loss: 3.9948085325654374

Epoch: 6| Step: 4
Training loss: 4.204179482618494
Validation loss: 3.9770223742200073

Epoch: 6| Step: 5
Training loss: 4.370496557381215
Validation loss: 3.965697719590186

Epoch: 6| Step: 6
Training loss: 4.217510352085255
Validation loss: 3.952110104801518

Epoch: 6| Step: 7
Training loss: 3.3279900321994575
Validation loss: 3.9413848609367936

Epoch: 6| Step: 8
Training loss: 4.2444014980369245
Validation loss: 3.93353226271437

Epoch: 6| Step: 9
Training loss: 4.817533560667149
Validation loss: 3.918505319323297

Epoch: 6| Step: 10
Training loss: 3.925963075896566
Validation loss: 3.8998466185979366

Epoch: 6| Step: 11
Training loss: 3.684208839817665
Validation loss: 3.8848884450216423

Epoch: 6| Step: 12
Training loss: 4.323574717735748
Validation loss: 3.8765475186313507

Epoch: 6| Step: 13
Training loss: 3.609218313275846
Validation loss: 3.8639713726349236

Epoch: 7| Step: 0
Training loss: 4.3094661932598575
Validation loss: 3.8584511770373107

Epoch: 6| Step: 1
Training loss: 3.4007540820259283
Validation loss: 3.8497052077563647

Epoch: 6| Step: 2
Training loss: 4.045039522899781
Validation loss: 3.8348800197029256

Epoch: 6| Step: 3
Training loss: 4.312728875762417
Validation loss: 3.822151857083579

Epoch: 6| Step: 4
Training loss: 3.7786259649566314
Validation loss: 3.8068952456590632

Epoch: 6| Step: 5
Training loss: 4.872244422907448
Validation loss: 3.7914613701757762

Epoch: 6| Step: 6
Training loss: 4.350995285350759
Validation loss: 3.7775991862277873

Epoch: 6| Step: 7
Training loss: 3.2173527027194715
Validation loss: 3.7654634887931815

Epoch: 6| Step: 8
Training loss: 3.9248580226610588
Validation loss: 3.7497055990950168

Epoch: 6| Step: 9
Training loss: 3.7101535973024315
Validation loss: 3.7417837983572837

Epoch: 6| Step: 10
Training loss: 3.424362045238517
Validation loss: 3.7274343871841737

Epoch: 6| Step: 11
Training loss: 3.7127465265797346
Validation loss: 3.714508185372086

Epoch: 6| Step: 12
Training loss: 4.6636613069442205
Validation loss: 3.7053487606658706

Epoch: 6| Step: 13
Training loss: 2.2073099416132584
Validation loss: 3.6984297072243586

Epoch: 8| Step: 0
Training loss: 4.204438525440583
Validation loss: 3.691913989939781

Epoch: 6| Step: 1
Training loss: 2.770001757514479
Validation loss: 3.6873372874400703

Epoch: 6| Step: 2
Training loss: 3.789838888322098
Validation loss: 3.674201354411102

Epoch: 6| Step: 3
Training loss: 3.849340699456935
Validation loss: 3.6667967061972466

Epoch: 6| Step: 4
Training loss: 3.4694356154842008
Validation loss: 3.6607560013228633

Epoch: 6| Step: 5
Training loss: 4.55779305742607
Validation loss: 3.6500334076947616

Epoch: 6| Step: 6
Training loss: 4.921845160499825
Validation loss: 3.6412726504906057

Epoch: 6| Step: 7
Training loss: 3.8295505905425644
Validation loss: 3.6300130091757548

Epoch: 6| Step: 8
Training loss: 3.900360305966286
Validation loss: 3.6276283495093966

Epoch: 6| Step: 9
Training loss: 3.1959854573860693
Validation loss: 3.6198236836596003

Epoch: 6| Step: 10
Training loss: 3.0729358909565945
Validation loss: 3.6148652101599805

Epoch: 6| Step: 11
Training loss: 4.7392134413812546
Validation loss: 3.604878673160809

Epoch: 6| Step: 12
Training loss: 2.702295429628163
Validation loss: 3.588388667832345

Epoch: 6| Step: 13
Training loss: 3.875660870710106
Validation loss: 3.57967505380588

Epoch: 9| Step: 0
Training loss: 3.3241349780131944
Validation loss: 3.5753855844329463

Epoch: 6| Step: 1
Training loss: 3.5402644055433523
Validation loss: 3.567802853459097

Epoch: 6| Step: 2
Training loss: 4.227253573570972
Validation loss: 3.564439543145983

Epoch: 6| Step: 3
Training loss: 3.6884813457656964
Validation loss: 3.5547253728951995

Epoch: 6| Step: 4
Training loss: 3.603143771040789
Validation loss: 3.544546155217836

Epoch: 6| Step: 5
Training loss: 4.277166716513352
Validation loss: 3.5463887815104957

Epoch: 6| Step: 6
Training loss: 3.8804991064848458
Validation loss: 3.543253210411303

Epoch: 6| Step: 7
Training loss: 2.9091103536866316
Validation loss: 3.5413950160236323

Epoch: 6| Step: 8
Training loss: 3.7481590838629484
Validation loss: 3.544669572188667

Epoch: 6| Step: 9
Training loss: 3.213799085564922
Validation loss: 3.518972427990061

Epoch: 6| Step: 10
Training loss: 3.806391966729428
Validation loss: 3.516193316793882

Epoch: 6| Step: 11
Training loss: 3.678732584096453
Validation loss: 3.511625244300315

Epoch: 6| Step: 12
Training loss: 3.564036121797593
Validation loss: 3.508095452758404

Epoch: 6| Step: 13
Training loss: 5.153972145712875
Validation loss: 3.5040395983883394

Epoch: 10| Step: 0
Training loss: 4.4925237645883
Validation loss: 3.5001067600873172

Epoch: 6| Step: 1
Training loss: 3.6134946358021884
Validation loss: 3.486854895389979

Epoch: 6| Step: 2
Training loss: 3.4503972253311996
Validation loss: 3.4799871883927365

Epoch: 6| Step: 3
Training loss: 2.7292091618692322
Validation loss: 3.4770343389813183

Epoch: 6| Step: 4
Training loss: 3.6736722403049256
Validation loss: 3.471999689224552

Epoch: 6| Step: 5
Training loss: 4.021765381831593
Validation loss: 3.466225152044868

Epoch: 6| Step: 6
Training loss: 3.709482136491193
Validation loss: 3.459813336632792

Epoch: 6| Step: 7
Training loss: 3.351981752578122
Validation loss: 3.4515976756460267

Epoch: 6| Step: 8
Training loss: 3.6514135471532096
Validation loss: 3.446179255975916

Epoch: 6| Step: 9
Training loss: 3.262399202740896
Validation loss: 3.447384116949435

Epoch: 6| Step: 10
Training loss: 3.437844553932297
Validation loss: 3.4422057785327826

Epoch: 6| Step: 11
Training loss: 3.9943892944825077
Validation loss: 3.4297114941908813

Epoch: 6| Step: 12
Training loss: 4.339455656730291
Validation loss: 3.4311083350122615

Epoch: 6| Step: 13
Training loss: 3.1271550186618806
Validation loss: 3.4261399632719334

Epoch: 11| Step: 0
Training loss: 3.0264850407635144
Validation loss: 3.4169792964677494

Epoch: 6| Step: 1
Training loss: 3.7654397372817026
Validation loss: 3.4073759342200174

Epoch: 6| Step: 2
Training loss: 3.1242354411399287
Validation loss: 3.3969651271375425

Epoch: 6| Step: 3
Training loss: 3.655267045354082
Validation loss: 3.390216433612438

Epoch: 6| Step: 4
Training loss: 3.8264270987490425
Validation loss: 3.3772367359995177

Epoch: 6| Step: 5
Training loss: 3.849410688207271
Validation loss: 3.372180533543511

Epoch: 6| Step: 6
Training loss: 4.199719265229318
Validation loss: 3.3793242476291754

Epoch: 6| Step: 7
Training loss: 3.060254577817781
Validation loss: 3.362574380482808

Epoch: 6| Step: 8
Training loss: 3.4246380245750405
Validation loss: 3.3616291493448007

Epoch: 6| Step: 9
Training loss: 3.2989686221191254
Validation loss: 3.355996460484241

Epoch: 6| Step: 10
Training loss: 3.125843849689879
Validation loss: 3.351861798624269

Epoch: 6| Step: 11
Training loss: 3.885049892974148
Validation loss: 3.3487529908259255

Epoch: 6| Step: 12
Training loss: 3.956173411226103
Validation loss: 3.3422285683473176

Epoch: 6| Step: 13
Training loss: 4.2296787697314775
Validation loss: 3.334598799933376

Epoch: 12| Step: 0
Training loss: 3.6928376182805267
Validation loss: 3.3325236126625573

Epoch: 6| Step: 1
Training loss: 3.227526209079928
Validation loss: 3.3250134762874772

Epoch: 6| Step: 2
Training loss: 3.8124255814089985
Validation loss: 3.317986082615702

Epoch: 6| Step: 3
Training loss: 2.943131912038629
Validation loss: 3.3252392238309776

Epoch: 6| Step: 4
Training loss: 3.785453792565617
Validation loss: 3.3179778276170553

Epoch: 6| Step: 5
Training loss: 3.969081113924987
Validation loss: 3.306570174229765

Epoch: 6| Step: 6
Training loss: 3.0451235701319326
Validation loss: 3.300750240251379

Epoch: 6| Step: 7
Training loss: 3.600211264451246
Validation loss: 3.302143575524404

Epoch: 6| Step: 8
Training loss: 3.413753678869153
Validation loss: 3.3016154400703503

Epoch: 6| Step: 9
Training loss: 3.3616775073997394
Validation loss: 3.2920670276894883

Epoch: 6| Step: 10
Training loss: 3.6105342175951995
Validation loss: 3.286434941796617

Epoch: 6| Step: 11
Training loss: 4.190609361134363
Validation loss: 3.2843747325500705

Epoch: 6| Step: 12
Training loss: 3.2522619152380114
Validation loss: 3.277047982848025

Epoch: 6| Step: 13
Training loss: 3.401381627023973
Validation loss: 3.274887052609683

Epoch: 13| Step: 0
Training loss: 3.4933389220544893
Validation loss: 3.267496960324681

Epoch: 6| Step: 1
Training loss: 3.7132435269228403
Validation loss: 3.266372578609068

Epoch: 6| Step: 2
Training loss: 3.9698598916724097
Validation loss: 3.2620661182566058

Epoch: 6| Step: 3
Training loss: 2.85777930255544
Validation loss: 3.2575276064510215

Epoch: 6| Step: 4
Training loss: 3.0847432976608244
Validation loss: 3.2594844823913887

Epoch: 6| Step: 5
Training loss: 3.004452262632492
Validation loss: 3.2522974720512865

Epoch: 6| Step: 6
Training loss: 3.8743563702020487
Validation loss: 3.2482281864895826

Epoch: 6| Step: 7
Training loss: 2.9507066623834506
Validation loss: 3.2480577631936285

Epoch: 6| Step: 8
Training loss: 3.908325864436341
Validation loss: 3.2392126042113265

Epoch: 6| Step: 9
Training loss: 3.6833116700468906
Validation loss: 3.23549593955727

Epoch: 6| Step: 10
Training loss: 3.570031353254508
Validation loss: 3.231730595137944

Epoch: 6| Step: 11
Training loss: 3.2754011068705267
Validation loss: 3.2343723478817137

Epoch: 6| Step: 12
Training loss: 3.272166440092851
Validation loss: 3.223266166776786

Epoch: 6| Step: 13
Training loss: 4.32403900406967
Validation loss: 3.224172435393573

Epoch: 14| Step: 0
Training loss: 3.7558177324784556
Validation loss: 3.2221781396190106

Epoch: 6| Step: 1
Training loss: 4.056243774221195
Validation loss: 3.2191291360388914

Epoch: 6| Step: 2
Training loss: 3.408406825932675
Validation loss: 3.2122531406428028

Epoch: 6| Step: 3
Training loss: 3.064345290436604
Validation loss: 3.207227512874306

Epoch: 6| Step: 4
Training loss: 3.172939028111136
Validation loss: 3.201788474629419

Epoch: 6| Step: 5
Training loss: 3.742923035140432
Validation loss: 3.2004696103739323

Epoch: 6| Step: 6
Training loss: 3.732373455378306
Validation loss: 3.1980840154125265

Epoch: 6| Step: 7
Training loss: 4.143482762345641
Validation loss: 3.1982417963299032

Epoch: 6| Step: 8
Training loss: 3.1240527433956786
Validation loss: 3.2033193813903376

Epoch: 6| Step: 9
Training loss: 3.848967074262564
Validation loss: 3.2002483177039296

Epoch: 6| Step: 10
Training loss: 2.5242618123817366
Validation loss: 3.190771439232892

Epoch: 6| Step: 11
Training loss: 3.4141217189515087
Validation loss: 3.1913462232177325

Epoch: 6| Step: 12
Training loss: 2.6341800929830264
Validation loss: 3.185188907354047

Epoch: 6| Step: 13
Training loss: 3.3053384775498977
Validation loss: 3.1846447179567243

Epoch: 15| Step: 0
Training loss: 3.1676987087241946
Validation loss: 3.1838499271012473

Epoch: 6| Step: 1
Training loss: 4.302562375988009
Validation loss: 3.185242688649183

Epoch: 6| Step: 2
Training loss: 3.8644289601109425
Validation loss: 3.1763779304770767

Epoch: 6| Step: 3
Training loss: 2.1098283068691996
Validation loss: 3.1755084032439633

Epoch: 6| Step: 4
Training loss: 3.08650576996739
Validation loss: 3.1735593157980797

Epoch: 6| Step: 5
Training loss: 3.233012184108308
Validation loss: 3.1768071520406607

Epoch: 6| Step: 6
Training loss: 3.47769660882069
Validation loss: 3.1701597163274466

Epoch: 6| Step: 7
Training loss: 3.2292507693915953
Validation loss: 3.169526572512694

Epoch: 6| Step: 8
Training loss: 3.264782664614594
Validation loss: 3.1601915127213966

Epoch: 6| Step: 9
Training loss: 3.8645711043473687
Validation loss: 3.1583269227046413

Epoch: 6| Step: 10
Training loss: 3.71015051276799
Validation loss: 3.1533556841844907

Epoch: 6| Step: 11
Training loss: 3.0469959724081654
Validation loss: 3.1529692765348436

Epoch: 6| Step: 12
Training loss: 3.8902850021651743
Validation loss: 3.151540100547449

Epoch: 6| Step: 13
Training loss: 3.169277536995829
Validation loss: 3.1499218047672

Epoch: 16| Step: 0
Training loss: 4.47986208226582
Validation loss: 3.1610748895875944

Epoch: 6| Step: 1
Training loss: 4.716776858459081
Validation loss: 3.1446590849309852

Epoch: 6| Step: 2
Training loss: 3.060349624207616
Validation loss: 3.143505281107265

Epoch: 6| Step: 3
Training loss: 3.1937231014186493
Validation loss: 3.145124501575072

Epoch: 6| Step: 4
Training loss: 3.15887734618754
Validation loss: 3.140863203740206

Epoch: 6| Step: 5
Training loss: 2.8312879547202443
Validation loss: 3.141116380603522

Epoch: 6| Step: 6
Training loss: 3.007322752082468
Validation loss: 3.1420277280301168

Epoch: 6| Step: 7
Training loss: 3.4283500270656515
Validation loss: 3.1400197269848618

Epoch: 6| Step: 8
Training loss: 2.977866860697278
Validation loss: 3.133001889345542

Epoch: 6| Step: 9
Training loss: 2.938706819711146
Validation loss: 3.14077418207751

Epoch: 6| Step: 10
Training loss: 2.9744703895324904
Validation loss: 3.156747028955506

Epoch: 6| Step: 11
Training loss: 3.539717792533926
Validation loss: 3.131259012081395

Epoch: 6| Step: 12
Training loss: 3.0952807406048293
Validation loss: 3.125383308447062

Epoch: 6| Step: 13
Training loss: 3.902477792875849
Validation loss: 3.1288757130183504

Epoch: 17| Step: 0
Training loss: 3.9658810315700825
Validation loss: 3.1300958001640495

Epoch: 6| Step: 1
Training loss: 3.063109356727966
Validation loss: 3.1285755990089306

Epoch: 6| Step: 2
Training loss: 3.410444704071422
Validation loss: 3.125212390204024

Epoch: 6| Step: 3
Training loss: 3.2986361604152146
Validation loss: 3.1171007761381064

Epoch: 6| Step: 4
Training loss: 2.994869454520778
Validation loss: 3.114106999572821

Epoch: 6| Step: 5
Training loss: 2.0782284818425762
Validation loss: 3.1307879673230623

Epoch: 6| Step: 6
Training loss: 2.978159558635073
Validation loss: 3.1484825460625827

Epoch: 6| Step: 7
Training loss: 4.036680127685011
Validation loss: 3.123458071715332

Epoch: 6| Step: 8
Training loss: 3.5271840951807985
Validation loss: 3.1127229103602785

Epoch: 6| Step: 9
Training loss: 2.7480126916295227
Validation loss: 3.1039359637466273

Epoch: 6| Step: 10
Training loss: 3.9877693826690916
Validation loss: 3.1031830104495524

Epoch: 6| Step: 11
Training loss: 3.500476804680674
Validation loss: 3.098139134032265

Epoch: 6| Step: 12
Training loss: 3.9826618176551967
Validation loss: 3.097830815443555

Epoch: 6| Step: 13
Training loss: 3.209906716580778
Validation loss: 3.093321063553419

Epoch: 18| Step: 0
Training loss: 2.659183453162501
Validation loss: 3.0915610652244796

Epoch: 6| Step: 1
Training loss: 3.8092477403245866
Validation loss: 3.0914106244808144

Epoch: 6| Step: 2
Training loss: 2.9312808167356637
Validation loss: 3.087334401262875

Epoch: 6| Step: 3
Training loss: 3.95149372202372
Validation loss: 3.087275954041306

Epoch: 6| Step: 4
Training loss: 3.608631668502744
Validation loss: 3.086079647912395

Epoch: 6| Step: 5
Training loss: 3.253926472870081
Validation loss: 3.0861796190518356

Epoch: 6| Step: 6
Training loss: 2.6475124487795845
Validation loss: 3.084618045241632

Epoch: 6| Step: 7
Training loss: 3.245248108299861
Validation loss: 3.0832569131690337

Epoch: 6| Step: 8
Training loss: 3.6291314620811663
Validation loss: 3.0815520730072294

Epoch: 6| Step: 9
Training loss: 3.2832173580335455
Validation loss: 3.079222356158428

Epoch: 6| Step: 10
Training loss: 3.212026146997272
Validation loss: 3.080219760128274

Epoch: 6| Step: 11
Training loss: 3.7042502452116257
Validation loss: 3.0856225401947923

Epoch: 6| Step: 12
Training loss: 3.522604833360069
Validation loss: 3.077443797631929

Epoch: 6| Step: 13
Training loss: 3.2772122198725597
Validation loss: 3.0726816233822207

Epoch: 19| Step: 0
Training loss: 3.852627063514887
Validation loss: 3.069992324695517

Epoch: 6| Step: 1
Training loss: 2.455645196044702
Validation loss: 3.0708938194848905

Epoch: 6| Step: 2
Training loss: 3.489960030488071
Validation loss: 3.06800269904374

Epoch: 6| Step: 3
Training loss: 2.644597242875816
Validation loss: 3.064479866795567

Epoch: 6| Step: 4
Training loss: 2.8917214453471254
Validation loss: 3.0654552114866624

Epoch: 6| Step: 5
Training loss: 3.392299256313447
Validation loss: 3.0622332006567317

Epoch: 6| Step: 6
Training loss: 3.468903684218653
Validation loss: 3.058605441698146

Epoch: 6| Step: 7
Training loss: 3.970986164323484
Validation loss: 3.059176847161757

Epoch: 6| Step: 8
Training loss: 3.2594534494206893
Validation loss: 3.058659914917413

Epoch: 6| Step: 9
Training loss: 3.711050316952878
Validation loss: 3.0586661541600737

Epoch: 6| Step: 10
Training loss: 3.0992032165368855
Validation loss: 3.0572367366568654

Epoch: 6| Step: 11
Training loss: 3.789315567217455
Validation loss: 3.0570180371177735

Epoch: 6| Step: 12
Training loss: 3.3631639980741195
Validation loss: 3.049237413522056

Epoch: 6| Step: 13
Training loss: 2.7935236452985395
Validation loss: 3.0510607537249625

Epoch: 20| Step: 0
Training loss: 3.1698695264855
Validation loss: 3.0509994302980483

Epoch: 6| Step: 1
Training loss: 3.4637357193739526
Validation loss: 3.0502060974383154

Epoch: 6| Step: 2
Training loss: 3.020133803479238
Validation loss: 3.051458336280307

Epoch: 6| Step: 3
Training loss: 3.4377446867814574
Validation loss: 3.053886628132434

Epoch: 6| Step: 4
Training loss: 3.0187545112907865
Validation loss: 3.0501228920345445

Epoch: 6| Step: 5
Training loss: 3.5226186405559137
Validation loss: 3.0571075337605005

Epoch: 6| Step: 6
Training loss: 3.9130789916412647
Validation loss: 3.054984743852793

Epoch: 6| Step: 7
Training loss: 2.7262159416943277
Validation loss: 3.0540859936376035

Epoch: 6| Step: 8
Training loss: 3.9574455202537364
Validation loss: 3.0487202322173044

Epoch: 6| Step: 9
Training loss: 3.435097426985986
Validation loss: 3.047221824694155

Epoch: 6| Step: 10
Training loss: 3.7027986921931397
Validation loss: 3.0444388478708237

Epoch: 6| Step: 11
Training loss: 3.570187622824662
Validation loss: 3.0420635558371805

Epoch: 6| Step: 12
Training loss: 2.5837479740572267
Validation loss: 3.0399657070166497

Epoch: 6| Step: 13
Training loss: 2.3049943105499153
Validation loss: 3.037209249605209

Epoch: 21| Step: 0
Training loss: 3.1204631679263986
Validation loss: 3.0354237283063483

Epoch: 6| Step: 1
Training loss: 3.5691626635866043
Validation loss: 3.0352348029974268

Epoch: 6| Step: 2
Training loss: 4.210601396895123
Validation loss: 3.038099043903598

Epoch: 6| Step: 3
Training loss: 3.776391052218038
Validation loss: 3.036414910807726

Epoch: 6| Step: 4
Training loss: 3.4036524956698058
Validation loss: 3.043518285536568

Epoch: 6| Step: 5
Training loss: 2.7323888922576
Validation loss: 3.0369265818361133

Epoch: 6| Step: 6
Training loss: 3.654477203176952
Validation loss: 3.02766225758204

Epoch: 6| Step: 7
Training loss: 3.300345235163232
Validation loss: 3.0291004871102025

Epoch: 6| Step: 8
Training loss: 2.7650225139342854
Validation loss: 3.0227779376920068

Epoch: 6| Step: 9
Training loss: 2.902448567568068
Validation loss: 3.0227772812567317

Epoch: 6| Step: 10
Training loss: 3.079254407927386
Validation loss: 3.024122950669868

Epoch: 6| Step: 11
Training loss: 3.453797287895105
Validation loss: 3.019091257783787

Epoch: 6| Step: 12
Training loss: 2.8203773385411735
Validation loss: 3.019161039560716

Epoch: 6| Step: 13
Training loss: 3.3046672991773245
Validation loss: 3.02254424111809

Epoch: 22| Step: 0
Training loss: 3.7472880411804774
Validation loss: 3.0180666436660912

Epoch: 6| Step: 1
Training loss: 3.211322102403579
Validation loss: 3.0151893861749257

Epoch: 6| Step: 2
Training loss: 2.353735645187615
Validation loss: 3.018052916823124

Epoch: 6| Step: 3
Training loss: 3.28348661216631
Validation loss: 3.015561522633398

Epoch: 6| Step: 4
Training loss: 3.2987069920218537
Validation loss: 3.016063908392707

Epoch: 6| Step: 5
Training loss: 3.5170133434885296
Validation loss: 3.014716946208208

Epoch: 6| Step: 6
Training loss: 3.2666630167519037
Validation loss: 3.015758538863935

Epoch: 6| Step: 7
Training loss: 2.9353334269330476
Validation loss: 3.0128873546508443

Epoch: 6| Step: 8
Training loss: 3.659740640174482
Validation loss: 3.0130680207558864

Epoch: 6| Step: 9
Training loss: 2.3610943725092346
Validation loss: 3.0081441188529636

Epoch: 6| Step: 10
Training loss: 3.166727182579699
Validation loss: 3.0063613320779075

Epoch: 6| Step: 11
Training loss: 3.8152699648229325
Validation loss: 3.0044069001902143

Epoch: 6| Step: 12
Training loss: 3.250947667386232
Validation loss: 3.0036789680785576

Epoch: 6| Step: 13
Training loss: 4.291136749044363
Validation loss: 3.0077895109408517

Epoch: 23| Step: 0
Training loss: 2.8885573131652467
Validation loss: 3.010831292030188

Epoch: 6| Step: 1
Training loss: 3.380384036034826
Validation loss: 3.0085783566325492

Epoch: 6| Step: 2
Training loss: 3.1918717865398327
Validation loss: 3.0191879048600927

Epoch: 6| Step: 3
Training loss: 3.7750732162145892
Validation loss: 3.0132469472237235

Epoch: 6| Step: 4
Training loss: 3.4811495918847126
Validation loss: 3.0088328013494525

Epoch: 6| Step: 5
Training loss: 2.840213798749563
Validation loss: 3.0028458619408704

Epoch: 6| Step: 6
Training loss: 3.043746202533084
Validation loss: 3.017552230027738

Epoch: 6| Step: 7
Training loss: 3.1932216976246206
Validation loss: 3.026115520077955

Epoch: 6| Step: 8
Training loss: 3.7069351617963604
Validation loss: 3.0168644893653354

Epoch: 6| Step: 9
Training loss: 3.7314265274896825
Validation loss: 3.008301610855813

Epoch: 6| Step: 10
Training loss: 3.426551723506766
Validation loss: 3.0004065504757316

Epoch: 6| Step: 11
Training loss: 2.721326111766025
Validation loss: 2.996898143066072

Epoch: 6| Step: 12
Training loss: 3.476089273884468
Validation loss: 2.993596383174307

Epoch: 6| Step: 13
Training loss: 2.971127491673379
Validation loss: 2.995996920122895

Epoch: 24| Step: 0
Training loss: 3.348897376724396
Validation loss: 2.9953716758993467

Epoch: 6| Step: 1
Training loss: 3.1786231806722594
Validation loss: 2.9938372289107105

Epoch: 6| Step: 2
Training loss: 3.578150320171739
Validation loss: 2.9952612104949274

Epoch: 6| Step: 3
Training loss: 3.2719871931688154
Validation loss: 2.994576330089526

Epoch: 6| Step: 4
Training loss: 3.228723721221894
Validation loss: 2.991598624750967

Epoch: 6| Step: 5
Training loss: 3.182791729401882
Validation loss: 2.9931605979614195

Epoch: 6| Step: 6
Training loss: 2.9996487093926087
Validation loss: 2.9911536957766147

Epoch: 6| Step: 7
Training loss: 3.261660565068602
Validation loss: 2.993669412217475

Epoch: 6| Step: 8
Training loss: 2.9709013522272203
Validation loss: 3.006175444645112

Epoch: 6| Step: 9
Training loss: 3.4895462869224443
Validation loss: 3.0180235678419365

Epoch: 6| Step: 10
Training loss: 3.715586238110276
Validation loss: 3.0437946138508534

Epoch: 6| Step: 11
Training loss: 2.9269332756775572
Validation loss: 3.011489471492382

Epoch: 6| Step: 12
Training loss: 3.6608318084035143
Validation loss: 2.9904282110548066

Epoch: 6| Step: 13
Training loss: 3.069430236630092
Validation loss: 2.9824924270600714

Epoch: 25| Step: 0
Training loss: 3.0910757818000136
Validation loss: 2.9868498817825873

Epoch: 6| Step: 1
Training loss: 3.783358529857023
Validation loss: 2.987773835722931

Epoch: 6| Step: 2
Training loss: 3.6263842077447026
Validation loss: 2.9859726777309845

Epoch: 6| Step: 3
Training loss: 3.397646757188466
Validation loss: 2.9802105193056216

Epoch: 6| Step: 4
Training loss: 3.5428892082529995
Validation loss: 2.978696157066856

Epoch: 6| Step: 5
Training loss: 3.1389922647323165
Validation loss: 2.980229512931906

Epoch: 6| Step: 6
Training loss: 2.9674363291593546
Validation loss: 2.98474855108655

Epoch: 6| Step: 7
Training loss: 3.5216740764991905
Validation loss: 2.9819328350432492

Epoch: 6| Step: 8
Training loss: 3.5029186613378878
Validation loss: 2.983775282991022

Epoch: 6| Step: 9
Training loss: 3.1328239155321165
Validation loss: 2.9790332132388326

Epoch: 6| Step: 10
Training loss: 3.443683126530684
Validation loss: 2.97708342452072

Epoch: 6| Step: 11
Training loss: 3.0249849051106787
Validation loss: 2.9759706621460618

Epoch: 6| Step: 12
Training loss: 2.5119292792430397
Validation loss: 2.9714693767530194

Epoch: 6| Step: 13
Training loss: 2.6909650598793013
Validation loss: 2.9800800036686006

Epoch: 26| Step: 0
Training loss: 2.4827560812107707
Validation loss: 2.984508784359542

Epoch: 6| Step: 1
Training loss: 3.783823950013053
Validation loss: 2.99974003899446

Epoch: 6| Step: 2
Training loss: 3.4970993556372174
Validation loss: 2.9998505172267356

Epoch: 6| Step: 3
Training loss: 3.250558218333264
Validation loss: 2.9959267340042652

Epoch: 6| Step: 4
Training loss: 3.9082470481040055
Validation loss: 2.9673781303217703

Epoch: 6| Step: 5
Training loss: 3.2943582917717724
Validation loss: 2.9688991748784814

Epoch: 6| Step: 6
Training loss: 3.0014133303112582
Validation loss: 2.9653641577204177

Epoch: 6| Step: 7
Training loss: 2.128698048341277
Validation loss: 2.9606529967358193

Epoch: 6| Step: 8
Training loss: 3.300001352483299
Validation loss: 2.9635118871232464

Epoch: 6| Step: 9
Training loss: 2.8215395300294914
Validation loss: 2.9607737765934488

Epoch: 6| Step: 10
Training loss: 3.6833508958584824
Validation loss: 2.962241460760586

Epoch: 6| Step: 11
Training loss: 3.6102230512443865
Validation loss: 2.9609498050165715

Epoch: 6| Step: 12
Training loss: 3.0622139621980633
Validation loss: 2.960786716969331

Epoch: 6| Step: 13
Training loss: 3.4534885681148704
Validation loss: 2.966379165637038

Epoch: 27| Step: 0
Training loss: 3.4307617729555977
Validation loss: 2.958806998430823

Epoch: 6| Step: 1
Training loss: 3.2919175901422695
Validation loss: 2.957546012085764

Epoch: 6| Step: 2
Training loss: 2.838877769426872
Validation loss: 2.955690642653285

Epoch: 6| Step: 3
Training loss: 2.992342872669298
Validation loss: 2.957120327509957

Epoch: 6| Step: 4
Training loss: 2.544179882869469
Validation loss: 2.9532065596491845

Epoch: 6| Step: 5
Training loss: 2.9143629149354706
Validation loss: 2.9564749585573655

Epoch: 6| Step: 6
Training loss: 2.7178857240772776
Validation loss: 2.961827123414746

Epoch: 6| Step: 7
Training loss: 3.67445562054583
Validation loss: 2.977790146779918

Epoch: 6| Step: 8
Training loss: 3.791837639499636
Validation loss: 2.9901245497395905

Epoch: 6| Step: 9
Training loss: 3.4685028263040385
Validation loss: 2.974813603647188

Epoch: 6| Step: 10
Training loss: 3.1514641764882043
Validation loss: 2.9587490344908858

Epoch: 6| Step: 11
Training loss: 3.3089133944805584
Validation loss: 2.958957975049077

Epoch: 6| Step: 12
Training loss: 3.3744993898202105
Validation loss: 2.956682685517968

Epoch: 6| Step: 13
Training loss: 4.204347340558175
Validation loss: 2.95160581933188

Epoch: 28| Step: 0
Training loss: 3.657022769480527
Validation loss: 2.9500073641224014

Epoch: 6| Step: 1
Training loss: 3.2696549222428466
Validation loss: 2.951087755495661

Epoch: 6| Step: 2
Training loss: 3.0680740388891317
Validation loss: 2.9516771044944696

Epoch: 6| Step: 3
Training loss: 2.907151605359268
Validation loss: 2.9521910121556436

Epoch: 6| Step: 4
Training loss: 2.92163672470125
Validation loss: 2.9481706749343837

Epoch: 6| Step: 5
Training loss: 3.770554224858417
Validation loss: 2.95345427789108

Epoch: 6| Step: 6
Training loss: 3.0947407378777587
Validation loss: 2.9536894023297

Epoch: 6| Step: 7
Training loss: 2.513750977594232
Validation loss: 2.9645268425993416

Epoch: 6| Step: 8
Training loss: 3.488529892760431
Validation loss: 2.9889517164744883

Epoch: 6| Step: 9
Training loss: 3.955809273661019
Validation loss: 2.9647353085174175

Epoch: 6| Step: 10
Training loss: 3.466420534150477
Validation loss: 2.9568557625414362

Epoch: 6| Step: 11
Training loss: 3.033336589797511
Validation loss: 2.9649939756704544

Epoch: 6| Step: 12
Training loss: 3.0273484752987314
Validation loss: 2.950329543211068

Epoch: 6| Step: 13
Training loss: 2.926751295559144
Validation loss: 2.9482228678001103

Epoch: 29| Step: 0
Training loss: 3.0175514195319098
Validation loss: 2.9569740982916803

Epoch: 6| Step: 1
Training loss: 3.657618079218733
Validation loss: 2.9639465694416773

Epoch: 6| Step: 2
Training loss: 3.1826829602075217
Validation loss: 2.963941081382257

Epoch: 6| Step: 3
Training loss: 3.5662946067290715
Validation loss: 2.954160007273929

Epoch: 6| Step: 4
Training loss: 2.466240778662664
Validation loss: 2.9529869358533887

Epoch: 6| Step: 5
Training loss: 3.097234439873273
Validation loss: 2.9524939928992846

Epoch: 6| Step: 6
Training loss: 3.3337326446413282
Validation loss: 2.954123550478298

Epoch: 6| Step: 7
Training loss: 2.7623647665349256
Validation loss: 2.9546035491689855

Epoch: 6| Step: 8
Training loss: 3.642449572547272
Validation loss: 2.959583926891781

Epoch: 6| Step: 9
Training loss: 3.603858596483395
Validation loss: 2.9642234848522513

Epoch: 6| Step: 10
Training loss: 3.8738745008552438
Validation loss: 2.9565679651863075

Epoch: 6| Step: 11
Training loss: 2.604230549346657
Validation loss: 2.959047859198846

Epoch: 6| Step: 12
Training loss: 2.799542566808732
Validation loss: 2.9534553247161766

Epoch: 6| Step: 13
Training loss: 3.8210051675066214
Validation loss: 2.9470093990301187

Epoch: 30| Step: 0
Training loss: 2.720683495532203
Validation loss: 2.9411495911517855

Epoch: 6| Step: 1
Training loss: 2.560565404293893
Validation loss: 2.940542296419977

Epoch: 6| Step: 2
Training loss: 3.82222495547155
Validation loss: 2.9381490674093604

Epoch: 6| Step: 3
Training loss: 3.3657818402624127
Validation loss: 2.936852974936574

Epoch: 6| Step: 4
Training loss: 3.246558494671884
Validation loss: 2.932756259536816

Epoch: 6| Step: 5
Training loss: 3.1566503289782473
Validation loss: 2.930495173866059

Epoch: 6| Step: 6
Training loss: 3.027530551192394
Validation loss: 2.9277549016753768

Epoch: 6| Step: 7
Training loss: 2.2829537496138586
Validation loss: 2.9282085533249593

Epoch: 6| Step: 8
Training loss: 3.54437234785949
Validation loss: 2.9248831066596024

Epoch: 6| Step: 9
Training loss: 3.332247048441292
Validation loss: 2.9268683039724275

Epoch: 6| Step: 10
Training loss: 3.895479536396186
Validation loss: 2.9249097396657264

Epoch: 6| Step: 11
Training loss: 3.2308384823276386
Validation loss: 2.9260747721703746

Epoch: 6| Step: 12
Training loss: 3.2846519636544245
Validation loss: 2.925373564372796

Epoch: 6| Step: 13
Training loss: 3.598079296177619
Validation loss: 2.925728507831391

Epoch: 31| Step: 0
Training loss: 2.91919769186408
Validation loss: 2.9238399987318027

Epoch: 6| Step: 1
Training loss: 3.3683488086745728
Validation loss: 2.9249456332749224

Epoch: 6| Step: 2
Training loss: 3.2830379882529552
Validation loss: 2.927506599978233

Epoch: 6| Step: 3
Training loss: 2.9995131097511223
Validation loss: 2.931202040474839

Epoch: 6| Step: 4
Training loss: 3.5595656239252387
Validation loss: 2.933501927107149

Epoch: 6| Step: 5
Training loss: 4.040840038174157
Validation loss: 2.94627059403276

Epoch: 6| Step: 6
Training loss: 3.451613151347876
Validation loss: 2.93897238864502

Epoch: 6| Step: 7
Training loss: 2.317198850947312
Validation loss: 2.9231204364530883

Epoch: 6| Step: 8
Training loss: 3.7706868826455966
Validation loss: 2.917586297348511

Epoch: 6| Step: 9
Training loss: 2.946651245554391
Validation loss: 2.9141739267504323

Epoch: 6| Step: 10
Training loss: 3.363592295158817
Validation loss: 2.9123250586339258

Epoch: 6| Step: 11
Training loss: 2.9384673128904772
Validation loss: 2.913024479054835

Epoch: 6| Step: 12
Training loss: 2.874276609219466
Validation loss: 2.9113467298546003

Epoch: 6| Step: 13
Training loss: 2.8352840290723424
Validation loss: 2.91256319086881

Epoch: 32| Step: 0
Training loss: 3.821715177374245
Validation loss: 2.909692892100248

Epoch: 6| Step: 1
Training loss: 3.0804032158417134
Validation loss: 2.9108336715205074

Epoch: 6| Step: 2
Training loss: 2.9912061551137086
Validation loss: 2.9119195978681187

Epoch: 6| Step: 3
Training loss: 2.624612325469952
Validation loss: 2.909894091380894

Epoch: 6| Step: 4
Training loss: 3.0895614784446925
Validation loss: 2.9089640438540285

Epoch: 6| Step: 5
Training loss: 3.563097451957838
Validation loss: 2.90772915980731

Epoch: 6| Step: 6
Training loss: 3.421727007448282
Validation loss: 2.9046849246440813

Epoch: 6| Step: 7
Training loss: 2.774260406911883
Validation loss: 2.905303712809295

Epoch: 6| Step: 8
Training loss: 3.5818057389652735
Validation loss: 2.9063941301465905

Epoch: 6| Step: 9
Training loss: 3.8763697264534187
Validation loss: 2.9042102149161426

Epoch: 6| Step: 10
Training loss: 3.2853649676376984
Validation loss: 2.9011822481948224

Epoch: 6| Step: 11
Training loss: 2.7867712873078894
Validation loss: 2.9045658328118735

Epoch: 6| Step: 12
Training loss: 2.99195848987976
Validation loss: 2.9066277896958286

Epoch: 6| Step: 13
Training loss: 2.40418372674329
Validation loss: 2.9087986668656947

Epoch: 33| Step: 0
Training loss: 3.5097891287210374
Validation loss: 2.9239316445723484

Epoch: 6| Step: 1
Training loss: 3.4693086191519305
Validation loss: 2.9236849034084043

Epoch: 6| Step: 2
Training loss: 3.4640509591880373
Validation loss: 2.9101362237752597

Epoch: 6| Step: 3
Training loss: 3.0950299322255463
Validation loss: 2.9059012445577572

Epoch: 6| Step: 4
Training loss: 3.0592366172658045
Validation loss: 2.9066620974614397

Epoch: 6| Step: 5
Training loss: 2.4239532413819886
Validation loss: 2.906459790633335

Epoch: 6| Step: 6
Training loss: 3.597854791023401
Validation loss: 2.9085523368865447

Epoch: 6| Step: 7
Training loss: 3.150824236133205
Validation loss: 2.9183770237990228

Epoch: 6| Step: 8
Training loss: 3.2790297489753777
Validation loss: 2.9147108813153824

Epoch: 6| Step: 9
Training loss: 3.1308369864783567
Validation loss: 2.910666436633436

Epoch: 6| Step: 10
Training loss: 3.3543987944149776
Validation loss: 2.9080327573604343

Epoch: 6| Step: 11
Training loss: 2.927647075916605
Validation loss: 2.904306727749036

Epoch: 6| Step: 12
Training loss: 3.1248597685821395
Validation loss: 2.908904445132626

Epoch: 6| Step: 13
Training loss: 3.2218293209889293
Validation loss: 2.9025325651621556

Epoch: 34| Step: 0
Training loss: 2.7582137812803107
Validation loss: 2.901871410980931

Epoch: 6| Step: 1
Training loss: 2.6669001079742536
Validation loss: 2.917198579748723

Epoch: 6| Step: 2
Training loss: 3.6003410601652335
Validation loss: 2.9277428967137755

Epoch: 6| Step: 3
Training loss: 3.4196491405026666
Validation loss: 2.931313936032262

Epoch: 6| Step: 4
Training loss: 2.834917037261284
Validation loss: 2.9083437664299576

Epoch: 6| Step: 5
Training loss: 3.3183287674703053
Validation loss: 2.9007294109881876

Epoch: 6| Step: 6
Training loss: 3.3355638352823
Validation loss: 2.9016305255827306

Epoch: 6| Step: 7
Training loss: 3.346392006666325
Validation loss: 2.901425272847442

Epoch: 6| Step: 8
Training loss: 3.550510106577186
Validation loss: 2.8988874673395824

Epoch: 6| Step: 9
Training loss: 3.37635747665745
Validation loss: 2.8967390528952657

Epoch: 6| Step: 10
Training loss: 2.838999038851993
Validation loss: 2.8956028331690074

Epoch: 6| Step: 11
Training loss: 2.8910442976089636
Validation loss: 2.896162406712858

Epoch: 6| Step: 12
Training loss: 3.843961880434355
Validation loss: 2.892285589207244

Epoch: 6| Step: 13
Training loss: 2.58927292092456
Validation loss: 2.8929350726486414

Epoch: 35| Step: 0
Training loss: 3.9247766224659055
Validation loss: 2.890948308608932

Epoch: 6| Step: 1
Training loss: 3.0208568352848353
Validation loss: 2.8899293638421604

Epoch: 6| Step: 2
Training loss: 2.8915720445027486
Validation loss: 2.888371289161024

Epoch: 6| Step: 3
Training loss: 3.062535966934444
Validation loss: 2.887925428559722

Epoch: 6| Step: 4
Training loss: 2.977791920275657
Validation loss: 2.8894763139738537

Epoch: 6| Step: 5
Training loss: 3.378961851511456
Validation loss: 2.888377537668832

Epoch: 6| Step: 6
Training loss: 3.1879372390351186
Validation loss: 2.885968595139444

Epoch: 6| Step: 7
Training loss: 3.202081575477993
Validation loss: 2.884894122068313

Epoch: 6| Step: 8
Training loss: 3.4006700921289745
Validation loss: 2.884273926185422

Epoch: 6| Step: 9
Training loss: 3.13175478462249
Validation loss: 2.8851648202047335

Epoch: 6| Step: 10
Training loss: 3.2247440857593856
Validation loss: 2.88890428886721

Epoch: 6| Step: 11
Training loss: 2.549159891452704
Validation loss: 2.8865961726549103

Epoch: 6| Step: 12
Training loss: 2.772988726345715
Validation loss: 2.888844262101304

Epoch: 6| Step: 13
Training loss: 4.080277733419128
Validation loss: 2.89287982633078

Epoch: 36| Step: 0
Training loss: 2.7819808685445695
Validation loss: 2.903517662268107

Epoch: 6| Step: 1
Training loss: 3.3206680646014095
Validation loss: 2.897742460484252

Epoch: 6| Step: 2
Training loss: 2.904700573773278
Validation loss: 2.889444804585973

Epoch: 6| Step: 3
Training loss: 3.2783614750636696
Validation loss: 2.8889768948992427

Epoch: 6| Step: 4
Training loss: 3.3001442559819303
Validation loss: 2.88769062856437

Epoch: 6| Step: 5
Training loss: 2.725695453057774
Validation loss: 2.8802431955196792

Epoch: 6| Step: 6
Training loss: 3.0964408500906893
Validation loss: 2.880871698135207

Epoch: 6| Step: 7
Training loss: 3.4322476574744383
Validation loss: 2.882165545812499

Epoch: 6| Step: 8
Training loss: 3.006908409679966
Validation loss: 2.8841206911387594

Epoch: 6| Step: 9
Training loss: 3.807537288370469
Validation loss: 2.8792599064422837

Epoch: 6| Step: 10
Training loss: 2.975597635715026
Validation loss: 2.876668540395409

Epoch: 6| Step: 11
Training loss: 3.1169103054619525
Validation loss: 2.877555276060716

Epoch: 6| Step: 12
Training loss: 3.2959181133671955
Validation loss: 2.874461363867477

Epoch: 6| Step: 13
Training loss: 3.506224682830417
Validation loss: 2.871540217076652

Epoch: 37| Step: 0
Training loss: 3.080152744122282
Validation loss: 2.8741172257388103

Epoch: 6| Step: 1
Training loss: 3.2570770677696013
Validation loss: 2.8741441668246335

Epoch: 6| Step: 2
Training loss: 2.7871526595819867
Validation loss: 2.8729188099899057

Epoch: 6| Step: 3
Training loss: 2.6317695340359006
Validation loss: 2.87215021254104

Epoch: 6| Step: 4
Training loss: 2.7568841944169113
Validation loss: 2.871441627975821

Epoch: 6| Step: 5
Training loss: 4.109683181172166
Validation loss: 2.8747219238340493

Epoch: 6| Step: 6
Training loss: 3.851890441675413
Validation loss: 2.872949904547064

Epoch: 6| Step: 7
Training loss: 2.936616967769727
Validation loss: 2.8731722057465667

Epoch: 6| Step: 8
Training loss: 3.3747126139036534
Validation loss: 2.8754063569208803

Epoch: 6| Step: 9
Training loss: 2.502585218809698
Validation loss: 2.8722485175863324

Epoch: 6| Step: 10
Training loss: 3.382247771947633
Validation loss: 2.871184811526803

Epoch: 6| Step: 11
Training loss: 2.6981213957139736
Validation loss: 2.8698726220019664

Epoch: 6| Step: 12
Training loss: 3.625780744990269
Validation loss: 2.8732843643663606

Epoch: 6| Step: 13
Training loss: 3.033200609705976
Validation loss: 2.8734650564948665

Epoch: 38| Step: 0
Training loss: 3.221747622853368
Validation loss: 2.870489610277146

Epoch: 6| Step: 1
Training loss: 2.913090029696673
Validation loss: 2.872237240127985

Epoch: 6| Step: 2
Training loss: 2.7947748919957633
Validation loss: 2.8700110587218957

Epoch: 6| Step: 3
Training loss: 3.8421332207716623
Validation loss: 2.8725114095038546

Epoch: 6| Step: 4
Training loss: 3.4470436089537375
Validation loss: 2.870788233835712

Epoch: 6| Step: 5
Training loss: 2.5423944296435534
Validation loss: 2.8786686909894037

Epoch: 6| Step: 6
Training loss: 2.666788893123766
Validation loss: 2.8753779922115723

Epoch: 6| Step: 7
Training loss: 2.945207912702913
Validation loss: 2.879205442162466

Epoch: 6| Step: 8
Training loss: 3.632533958995681
Validation loss: 2.8872019784742053

Epoch: 6| Step: 9
Training loss: 2.8790269927296137
Validation loss: 2.884871609101622

Epoch: 6| Step: 10
Training loss: 3.4535074842081124
Validation loss: 2.8825506453840934

Epoch: 6| Step: 11
Training loss: 3.4069591099082643
Validation loss: 2.8767383923223253

Epoch: 6| Step: 12
Training loss: 2.9289890117862427
Validation loss: 2.871462249937343

Epoch: 6| Step: 13
Training loss: 3.675696798686146
Validation loss: 2.868335373506486

Epoch: 39| Step: 0
Training loss: 3.876614634152912
Validation loss: 2.8657495720351767

Epoch: 6| Step: 1
Training loss: 3.1632612556095068
Validation loss: 2.861163463990332

Epoch: 6| Step: 2
Training loss: 2.7306031288184367
Validation loss: 2.8605570137300522

Epoch: 6| Step: 3
Training loss: 3.033144643874417
Validation loss: 2.858827460180231

Epoch: 6| Step: 4
Training loss: 3.3364610462175706
Validation loss: 2.8574015877444343

Epoch: 6| Step: 5
Training loss: 2.302695134081731
Validation loss: 2.857099761469406

Epoch: 6| Step: 6
Training loss: 3.455803708171108
Validation loss: 2.855493103626468

Epoch: 6| Step: 7
Training loss: 3.6743110529965155
Validation loss: 2.8576445031836823

Epoch: 6| Step: 8
Training loss: 3.342254161482015
Validation loss: 2.8582877343441897

Epoch: 6| Step: 9
Training loss: 2.30722268534604
Validation loss: 2.8608638644517206

Epoch: 6| Step: 10
Training loss: 3.2726494835268882
Validation loss: 2.865361300940952

Epoch: 6| Step: 11
Training loss: 2.52868852405805
Validation loss: 2.8713707972221347

Epoch: 6| Step: 12
Training loss: 2.931397450201416
Validation loss: 2.8634056652187763

Epoch: 6| Step: 13
Training loss: 4.31583043741317
Validation loss: 2.8616514306696614

Epoch: 40| Step: 0
Training loss: 3.006440877901865
Validation loss: 2.857728165269168

Epoch: 6| Step: 1
Training loss: 3.5997825080023147
Validation loss: 2.856111631912363

Epoch: 6| Step: 2
Training loss: 3.0927664994889814
Validation loss: 2.8509976085832753

Epoch: 6| Step: 3
Training loss: 3.554266265391879
Validation loss: 2.853503659886767

Epoch: 6| Step: 4
Training loss: 2.994977402386887
Validation loss: 2.852564450394943

Epoch: 6| Step: 5
Training loss: 3.140589168211329
Validation loss: 2.861310927857946

Epoch: 6| Step: 6
Training loss: 3.3900802807599644
Validation loss: 2.869408240266916

Epoch: 6| Step: 7
Training loss: 3.173182326124533
Validation loss: 2.869916842405229

Epoch: 6| Step: 8
Training loss: 2.650827055652536
Validation loss: 2.866831805224817

Epoch: 6| Step: 9
Training loss: 2.5822096400885446
Validation loss: 2.8648679473678422

Epoch: 6| Step: 10
Training loss: 3.269082023723484
Validation loss: 2.8661777322864546

Epoch: 6| Step: 11
Training loss: 2.709658098225188
Validation loss: 2.8578564570883915

Epoch: 6| Step: 12
Training loss: 3.862938351740885
Validation loss: 2.8510294439752237

Epoch: 6| Step: 13
Training loss: 2.762651558425395
Validation loss: 2.8502557146858685

Epoch: 41| Step: 0
Training loss: 2.876292560101699
Validation loss: 2.8513209419466414

Epoch: 6| Step: 1
Training loss: 2.764766581445517
Validation loss: 2.8544615385213867

Epoch: 6| Step: 2
Training loss: 2.6072369799261876
Validation loss: 2.8772972901384715

Epoch: 6| Step: 3
Training loss: 2.9009742021278186
Validation loss: 2.9038252986343585

Epoch: 6| Step: 4
Training loss: 3.274437653695213
Validation loss: 2.919123231813746

Epoch: 6| Step: 5
Training loss: 2.8788592103093897
Validation loss: 2.9230885135586826

Epoch: 6| Step: 6
Training loss: 3.0635716645761923
Validation loss: 2.9210360523937577

Epoch: 6| Step: 7
Training loss: 3.458401752086216
Validation loss: 2.925544921008428

Epoch: 6| Step: 8
Training loss: 2.1924156543336366
Validation loss: 2.921535206992762

Epoch: 6| Step: 9
Training loss: 4.059716782486668
Validation loss: 2.920049142829962

Epoch: 6| Step: 10
Training loss: 3.7180287920004775
Validation loss: 2.9231559679023467

Epoch: 6| Step: 11
Training loss: 3.5194099904974667
Validation loss: 2.920860905518822

Epoch: 6| Step: 12
Training loss: 3.357309247447367
Validation loss: 2.920221803039893

Epoch: 6| Step: 13
Training loss: 4.0261970019590425
Validation loss: 2.918513711401784

Epoch: 42| Step: 0
Training loss: 3.181855233707449
Validation loss: 2.918360936747908

Epoch: 6| Step: 1
Training loss: 3.552880131613542
Validation loss: 2.9186965582291546

Epoch: 6| Step: 2
Training loss: 3.763113110036777
Validation loss: 2.9191570414400627

Epoch: 6| Step: 3
Training loss: 3.4300529963010895
Validation loss: 2.9142272035241814

Epoch: 6| Step: 4
Training loss: 3.0222910203146567
Validation loss: 2.913583362168998

Epoch: 6| Step: 5
Training loss: 2.6879470808178763
Validation loss: 2.91191717149737

Epoch: 6| Step: 6
Training loss: 3.516400874671311
Validation loss: 2.9092617521435784

Epoch: 6| Step: 7
Training loss: 2.9216736096830793
Validation loss: 2.911604617615373

Epoch: 6| Step: 8
Training loss: 3.2842511212681758
Validation loss: 2.9086874466813195

Epoch: 6| Step: 9
Training loss: 3.4768203468285637
Validation loss: 2.906593575018185

Epoch: 6| Step: 10
Training loss: 2.750896134451736
Validation loss: 2.909549004664376

Epoch: 6| Step: 11
Training loss: 3.004072921355487
Validation loss: 2.9018364387594393

Epoch: 6| Step: 12
Training loss: 3.561962957224931
Validation loss: 2.899837542174723

Epoch: 6| Step: 13
Training loss: 1.4147089539576538
Validation loss: 2.8583124684572283

Epoch: 43| Step: 0
Training loss: 3.009199025999472
Validation loss: 2.837819388645265

Epoch: 6| Step: 1
Training loss: 3.415314538637276
Validation loss: 2.8338630094910275

Epoch: 6| Step: 2
Training loss: 3.097518013446884
Validation loss: 2.835657893167288

Epoch: 6| Step: 3
Training loss: 3.3283820254515004
Validation loss: 2.833941755954349

Epoch: 6| Step: 4
Training loss: 2.267020486349553
Validation loss: 2.834942607383704

Epoch: 6| Step: 5
Training loss: 3.516077580460768
Validation loss: 2.840994951645485

Epoch: 6| Step: 6
Training loss: 3.310969160935808
Validation loss: 2.842435312705639

Epoch: 6| Step: 7
Training loss: 3.239678793397149
Validation loss: 2.8484313874056504

Epoch: 6| Step: 8
Training loss: 3.221902285144907
Validation loss: 2.8420094190570784

Epoch: 6| Step: 9
Training loss: 3.5418278077809915
Validation loss: 2.8414881772665224

Epoch: 6| Step: 10
Training loss: 3.1785328711165715
Validation loss: 2.839542439113418

Epoch: 6| Step: 11
Training loss: 3.296735860048939
Validation loss: 2.8392644604137285

Epoch: 6| Step: 12
Training loss: 2.6482688827626504
Validation loss: 2.8301305363835385

Epoch: 6| Step: 13
Training loss: 2.412994543588716
Validation loss: 2.833665989005469

Epoch: 44| Step: 0
Training loss: 2.8496045223035273
Validation loss: 2.8309597433880236

Epoch: 6| Step: 1
Training loss: 2.6105971529450116
Validation loss: 2.8356888249388983

Epoch: 6| Step: 2
Training loss: 2.300106862944227
Validation loss: 2.8344397987241283

Epoch: 6| Step: 3
Training loss: 3.4010817489871448
Validation loss: 2.83007648902526

Epoch: 6| Step: 4
Training loss: 3.1217882054571615
Validation loss: 2.8283972338620056

Epoch: 6| Step: 5
Training loss: 3.2652267870339666
Validation loss: 2.825019851819547

Epoch: 6| Step: 6
Training loss: 3.0509686479636158
Validation loss: 2.8270711032546276

Epoch: 6| Step: 7
Training loss: 3.454488079607582
Validation loss: 2.826873662002682

Epoch: 6| Step: 8
Training loss: 3.7307374228347467
Validation loss: 2.825568523583874

Epoch: 6| Step: 9
Training loss: 3.6453065037422556
Validation loss: 2.8268415282727077

Epoch: 6| Step: 10
Training loss: 2.9511705823954815
Validation loss: 2.8251001878041238

Epoch: 6| Step: 11
Training loss: 2.7115361764651595
Validation loss: 2.828709991185048

Epoch: 6| Step: 12
Training loss: 3.311922850802163
Validation loss: 2.8288129324378883

Epoch: 6| Step: 13
Training loss: 3.2867951540434572
Validation loss: 2.836466854957659

Epoch: 45| Step: 0
Training loss: 3.1463861716518697
Validation loss: 2.831395141992867

Epoch: 6| Step: 1
Training loss: 2.7050668433880274
Validation loss: 2.833962391168008

Epoch: 6| Step: 2
Training loss: 3.43633472458905
Validation loss: 2.829523420104115

Epoch: 6| Step: 3
Training loss: 3.2506584087430705
Validation loss: 2.8265133003824334

Epoch: 6| Step: 4
Training loss: 3.0107056018191476
Validation loss: 2.822492467642636

Epoch: 6| Step: 5
Training loss: 2.7366643422713572
Validation loss: 2.824128409007797

Epoch: 6| Step: 6
Training loss: 3.21666346205583
Validation loss: 2.819587200438445

Epoch: 6| Step: 7
Training loss: 2.9028004509031744
Validation loss: 2.8205697801817577

Epoch: 6| Step: 8
Training loss: 3.490265387689232
Validation loss: 2.8212407668098547

Epoch: 6| Step: 9
Training loss: 3.1767093292392343
Validation loss: 2.823530367386725

Epoch: 6| Step: 10
Training loss: 3.2772331719277457
Validation loss: 2.82080735256909

Epoch: 6| Step: 11
Training loss: 3.0142354184902436
Validation loss: 2.821834942864261

Epoch: 6| Step: 12
Training loss: 3.1913025557855645
Validation loss: 2.8194290053079283

Epoch: 6| Step: 13
Training loss: 3.2456590565687606
Validation loss: 2.819903476799625

Epoch: 46| Step: 0
Training loss: 3.043714243465379
Validation loss: 2.8171223455759047

Epoch: 6| Step: 1
Training loss: 3.826842424053752
Validation loss: 2.8223466824839467

Epoch: 6| Step: 2
Training loss: 3.4085629510985362
Validation loss: 2.8215672675237933

Epoch: 6| Step: 3
Training loss: 2.3042811148596494
Validation loss: 2.8222703748242135

Epoch: 6| Step: 4
Training loss: 2.760680352818307
Validation loss: 2.8237645076635105

Epoch: 6| Step: 5
Training loss: 2.8586334767882113
Validation loss: 2.8221967593718413

Epoch: 6| Step: 6
Training loss: 2.712241439098371
Validation loss: 2.820943769532286

Epoch: 6| Step: 7
Training loss: 2.718537947178863
Validation loss: 2.825540216563831

Epoch: 6| Step: 8
Training loss: 3.510233496047997
Validation loss: 2.8329052616815975

Epoch: 6| Step: 9
Training loss: 3.3681799185079084
Validation loss: 2.8281312347671532

Epoch: 6| Step: 10
Training loss: 3.1219976116613606
Validation loss: 2.8206371240648918

Epoch: 6| Step: 11
Training loss: 2.9440405246702834
Validation loss: 2.820500373235599

Epoch: 6| Step: 12
Training loss: 3.553768768636685
Validation loss: 2.8231585922319806

Epoch: 6| Step: 13
Training loss: 3.4298541956126387
Validation loss: 2.824551747272889

Epoch: 47| Step: 0
Training loss: 3.3388536201373222
Validation loss: 2.8164163173738928

Epoch: 6| Step: 1
Training loss: 2.8318584941920966
Validation loss: 2.8180340791723943

Epoch: 6| Step: 2
Training loss: 2.9820579601567734
Validation loss: 2.8195873277300145

Epoch: 6| Step: 3
Training loss: 3.5568918624368293
Validation loss: 2.83276353284494

Epoch: 6| Step: 4
Training loss: 3.280335798519689
Validation loss: 2.8223910443838456

Epoch: 6| Step: 5
Training loss: 3.270912380032758
Validation loss: 2.8173310156846356

Epoch: 6| Step: 6
Training loss: 2.5593819605321637
Validation loss: 2.817362236931259

Epoch: 6| Step: 7
Training loss: 2.6888915606643953
Validation loss: 2.8151296593368023

Epoch: 6| Step: 8
Training loss: 3.366206546223927
Validation loss: 2.8131366460371434

Epoch: 6| Step: 9
Training loss: 3.30498530351427
Validation loss: 2.818434077595581

Epoch: 6| Step: 10
Training loss: 3.515817594550988
Validation loss: 2.8205993768230533

Epoch: 6| Step: 11
Training loss: 2.8827833882337677
Validation loss: 2.8192732419348663

Epoch: 6| Step: 12
Training loss: 2.8214677890721576
Validation loss: 2.8238979012053282

Epoch: 6| Step: 13
Training loss: 3.36034106181155
Validation loss: 2.8157709550485404

Epoch: 48| Step: 0
Training loss: 3.109996637667589
Validation loss: 2.8113601854247183

Epoch: 6| Step: 1
Training loss: 2.9314164820001922
Validation loss: 2.810756157313909

Epoch: 6| Step: 2
Training loss: 3.2035581714533827
Validation loss: 2.8135345926026645

Epoch: 6| Step: 3
Training loss: 3.4450970017904585
Validation loss: 2.81579981641296

Epoch: 6| Step: 4
Training loss: 2.8954305757510643
Validation loss: 2.8123987555653605

Epoch: 6| Step: 5
Training loss: 3.287805602515398
Validation loss: 2.8112939962955728

Epoch: 6| Step: 6
Training loss: 2.8604205778631897
Validation loss: 2.811403795133458

Epoch: 6| Step: 7
Training loss: 3.3151805756007215
Validation loss: 2.811860881275339

Epoch: 6| Step: 8
Training loss: 2.728809818690341
Validation loss: 2.8128490418271945

Epoch: 6| Step: 9
Training loss: 2.9787656785405874
Validation loss: 2.818726374334768

Epoch: 6| Step: 10
Training loss: 3.412164016224983
Validation loss: 2.822866906095797

Epoch: 6| Step: 11
Training loss: 2.650700055629099
Validation loss: 2.819269239075576

Epoch: 6| Step: 12
Training loss: 3.6151143470924554
Validation loss: 2.828318073791511

Epoch: 6| Step: 13
Training loss: 3.1772598634465146
Validation loss: 2.8161365930132285

Epoch: 49| Step: 0
Training loss: 2.5310035868196907
Validation loss: 2.816725813306609

Epoch: 6| Step: 1
Training loss: 2.8719002972672723
Validation loss: 2.81535833174289

Epoch: 6| Step: 2
Training loss: 3.1322573505260256
Validation loss: 2.8083442548532953

Epoch: 6| Step: 3
Training loss: 3.43099832358746
Validation loss: 2.80716390172697

Epoch: 6| Step: 4
Training loss: 2.4881034080873605
Validation loss: 2.807282842630269

Epoch: 6| Step: 5
Training loss: 3.0639420831450432
Validation loss: 2.8040836143533654

Epoch: 6| Step: 6
Training loss: 3.3008763045669793
Validation loss: 2.804392937390358

Epoch: 6| Step: 7
Training loss: 3.4315068105401876
Validation loss: 2.8073671818476735

Epoch: 6| Step: 8
Training loss: 2.6395815983028674
Validation loss: 2.8103533639021543

Epoch: 6| Step: 9
Training loss: 2.9057452676211546
Validation loss: 2.8110024670866487

Epoch: 6| Step: 10
Training loss: 3.768516854686684
Validation loss: 2.808117120162704

Epoch: 6| Step: 11
Training loss: 2.8529298613250442
Validation loss: 2.8049078491535546

Epoch: 6| Step: 12
Training loss: 2.9500988184008476
Validation loss: 2.805090999151179

Epoch: 6| Step: 13
Training loss: 4.424185105629844
Validation loss: 2.80309396336233

Epoch: 50| Step: 0
Training loss: 3.0266947388992613
Validation loss: 2.8027469519962227

Epoch: 6| Step: 1
Training loss: 2.7948935538615762
Validation loss: 2.801509841643587

Epoch: 6| Step: 2
Training loss: 3.713411875521376
Validation loss: 2.797582455634612

Epoch: 6| Step: 3
Training loss: 3.374641964606353
Validation loss: 2.80417380666111

Epoch: 6| Step: 4
Training loss: 2.8705433012941106
Validation loss: 2.79677703020378

Epoch: 6| Step: 5
Training loss: 3.137976597306637
Validation loss: 2.794978915411334

Epoch: 6| Step: 6
Training loss: 2.904776250787429
Validation loss: 2.7976657604081963

Epoch: 6| Step: 7
Training loss: 2.9332084961538585
Validation loss: 2.797918098951516

Epoch: 6| Step: 8
Training loss: 2.943741842529916
Validation loss: 2.794647837869775

Epoch: 6| Step: 9
Training loss: 3.0120735404774943
Validation loss: 2.794388240772078

Epoch: 6| Step: 10
Training loss: 3.404682743792212
Validation loss: 2.7988128850613125

Epoch: 6| Step: 11
Training loss: 3.4764612761773632
Validation loss: 2.799189772112793

Epoch: 6| Step: 12
Training loss: 2.9168674581531153
Validation loss: 2.803198452562863

Epoch: 6| Step: 13
Training loss: 2.7759370957099114
Validation loss: 2.7992806166427804

Epoch: 51| Step: 0
Training loss: 3.298552027836863
Validation loss: 2.7941953024611252

Epoch: 6| Step: 1
Training loss: 4.0606478650560645
Validation loss: 2.7922045416514223

Epoch: 6| Step: 2
Training loss: 2.5774434431440394
Validation loss: 2.794245800543856

Epoch: 6| Step: 3
Training loss: 3.14208434251898
Validation loss: 2.790345726282321

Epoch: 6| Step: 4
Training loss: 3.563305144762023
Validation loss: 2.7925027860316054

Epoch: 6| Step: 5
Training loss: 3.2448945659325443
Validation loss: 2.790750714788735

Epoch: 6| Step: 6
Training loss: 3.1389173733329345
Validation loss: 2.7896232286051252

Epoch: 6| Step: 7
Training loss: 2.9700364387409004
Validation loss: 2.8002706247504627

Epoch: 6| Step: 8
Training loss: 3.289846730010079
Validation loss: 2.8113424510054177

Epoch: 6| Step: 9
Training loss: 2.333115113362851
Validation loss: 2.7911163440269973

Epoch: 6| Step: 10
Training loss: 2.5153589522614705
Validation loss: 2.7890213821756826

Epoch: 6| Step: 11
Training loss: 3.3484694785096583
Validation loss: 2.7896692467357

Epoch: 6| Step: 12
Training loss: 2.9310597372224443
Validation loss: 2.7931665117746225

Epoch: 6| Step: 13
Training loss: 2.2574200668631366
Validation loss: 2.7952576580294464

Epoch: 52| Step: 0
Training loss: 2.3675882233210954
Validation loss: 2.797216139210466

Epoch: 6| Step: 1
Training loss: 2.4572747963432278
Validation loss: 2.801695413510503

Epoch: 6| Step: 2
Training loss: 3.4515081564552546
Validation loss: 2.79826347555818

Epoch: 6| Step: 3
Training loss: 3.4770471813653074
Validation loss: 2.794700007393168

Epoch: 6| Step: 4
Training loss: 2.901615508401096
Validation loss: 2.7934860740563585

Epoch: 6| Step: 5
Training loss: 3.4879091412495686
Validation loss: 2.7884831040278164

Epoch: 6| Step: 6
Training loss: 3.391472214006971
Validation loss: 2.80032209171353

Epoch: 6| Step: 7
Training loss: 3.4300631445585923
Validation loss: 2.807032306715775

Epoch: 6| Step: 8
Training loss: 2.6451578454438653
Validation loss: 2.817811837840085

Epoch: 6| Step: 9
Training loss: 3.0687916801403503
Validation loss: 2.8235350306436118

Epoch: 6| Step: 10
Training loss: 2.5203183386321766
Validation loss: 2.8273589146387685

Epoch: 6| Step: 11
Training loss: 3.115530697113768
Validation loss: 2.827193229131032

Epoch: 6| Step: 12
Training loss: 3.7689189512425383
Validation loss: 2.8364493398771713

Epoch: 6| Step: 13
Training loss: 3.244313326745302
Validation loss: 2.800761495266452

Epoch: 53| Step: 0
Training loss: 3.682341248404627
Validation loss: 2.787372679607508

Epoch: 6| Step: 1
Training loss: 3.3987089903680334
Validation loss: 2.7870098210377607

Epoch: 6| Step: 2
Training loss: 2.6337352912684024
Validation loss: 2.7897717346324153

Epoch: 6| Step: 3
Training loss: 3.3312612451073687
Validation loss: 2.7984432118965836

Epoch: 6| Step: 4
Training loss: 2.7666564569706185
Validation loss: 2.8024365251731767

Epoch: 6| Step: 5
Training loss: 3.745902047607299
Validation loss: 2.8015882182195755

Epoch: 6| Step: 6
Training loss: 3.0973843891776314
Validation loss: 2.789824716695104

Epoch: 6| Step: 7
Training loss: 3.0910990753536747
Validation loss: 2.7875351908981605

Epoch: 6| Step: 8
Training loss: 3.24366700759001
Validation loss: 2.7925078756633157

Epoch: 6| Step: 9
Training loss: 2.679114455628468
Validation loss: 2.802444623796481

Epoch: 6| Step: 10
Training loss: 2.919860798378782
Validation loss: 2.8231901449487213

Epoch: 6| Step: 11
Training loss: 3.0911356350806303
Validation loss: 2.8282144319685516

Epoch: 6| Step: 12
Training loss: 3.1162802539983403
Validation loss: 2.875177362793053

Epoch: 6| Step: 13
Training loss: 2.115546121634135
Validation loss: 2.882875891063362

Epoch: 54| Step: 0
Training loss: 3.64245402352268
Validation loss: 2.9124935150954507

Epoch: 6| Step: 1
Training loss: 3.3979368345284633
Validation loss: 2.868528631101134

Epoch: 6| Step: 2
Training loss: 2.946302171778509
Validation loss: 2.8377560281975898

Epoch: 6| Step: 3
Training loss: 2.549759617863362
Validation loss: 2.8153415886519664

Epoch: 6| Step: 4
Training loss: 3.138262263253182
Validation loss: 2.7940227635172925

Epoch: 6| Step: 5
Training loss: 3.0342818366696362
Validation loss: 2.7881001584264133

Epoch: 6| Step: 6
Training loss: 3.157600038564105
Validation loss: 2.7867931172134455

Epoch: 6| Step: 7
Training loss: 3.7026220052477834
Validation loss: 2.7864202558698694

Epoch: 6| Step: 8
Training loss: 2.9171383249299137
Validation loss: 2.791957590895196

Epoch: 6| Step: 9
Training loss: 3.2196042306908956
Validation loss: 2.7976896532124913

Epoch: 6| Step: 10
Training loss: 3.2201523179700264
Validation loss: 2.809288703722504

Epoch: 6| Step: 11
Training loss: 3.029814232649057
Validation loss: 2.7914923755992977

Epoch: 6| Step: 12
Training loss: 3.0205196524683076
Validation loss: 2.7889723824825587

Epoch: 6| Step: 13
Training loss: 2.273301687477132
Validation loss: 2.785563198630458

Epoch: 55| Step: 0
Training loss: 3.178431757373327
Validation loss: 2.783068711309898

Epoch: 6| Step: 1
Training loss: 3.247832529194711
Validation loss: 2.781765105573082

Epoch: 6| Step: 2
Training loss: 2.2377818351000855
Validation loss: 2.785263507955039

Epoch: 6| Step: 3
Training loss: 2.862749120541415
Validation loss: 2.7972224208749177

Epoch: 6| Step: 4
Training loss: 3.9375845279400483
Validation loss: 2.837508795455666

Epoch: 6| Step: 5
Training loss: 3.450333100975967
Validation loss: 2.8391671244177807

Epoch: 6| Step: 6
Training loss: 2.6513087369823283
Validation loss: 2.816766384733565

Epoch: 6| Step: 7
Training loss: 2.7354290483770245
Validation loss: 2.79331674574209

Epoch: 6| Step: 8
Training loss: 3.094471394596353
Validation loss: 2.791092384849107

Epoch: 6| Step: 9
Training loss: 3.6623932181665935
Validation loss: 2.786590455888328

Epoch: 6| Step: 10
Training loss: 3.323102573149063
Validation loss: 2.7825579884195464

Epoch: 6| Step: 11
Training loss: 2.184783011165568
Validation loss: 2.7917778382980445

Epoch: 6| Step: 12
Training loss: 3.108436787974229
Validation loss: 2.7902477725493458

Epoch: 6| Step: 13
Training loss: 3.5230834512390605
Validation loss: 2.790701315537635

Epoch: 56| Step: 0
Training loss: 2.708857197103704
Validation loss: 2.79496742890692

Epoch: 6| Step: 1
Training loss: 2.8255174956177482
Validation loss: 2.7973530651167002

Epoch: 6| Step: 2
Training loss: 3.0377569458842597
Validation loss: 2.789186788273549

Epoch: 6| Step: 3
Training loss: 3.261156008481918
Validation loss: 2.779674227892089

Epoch: 6| Step: 4
Training loss: 3.3031201264229066
Validation loss: 2.775452824712414

Epoch: 6| Step: 5
Training loss: 2.7789991893568087
Validation loss: 2.7763906172333948

Epoch: 6| Step: 6
Training loss: 2.7932992592905483
Validation loss: 2.780290850967731

Epoch: 6| Step: 7
Training loss: 3.0467095745857624
Validation loss: 2.784491372613967

Epoch: 6| Step: 8
Training loss: 2.744523751335205
Validation loss: 2.784621225821192

Epoch: 6| Step: 9
Training loss: 3.1266995195507805
Validation loss: 2.7876571194188418

Epoch: 6| Step: 10
Training loss: 3.71000913552036
Validation loss: 2.7881471432410194

Epoch: 6| Step: 11
Training loss: 3.38811994559624
Validation loss: 2.7796603585963036

Epoch: 6| Step: 12
Training loss: 3.06164912645704
Validation loss: 2.7772512380554484

Epoch: 6| Step: 13
Training loss: 3.460469578095975
Validation loss: 2.7788992009315416

Epoch: 57| Step: 0
Training loss: 2.9492376667957063
Validation loss: 2.7733048223141394

Epoch: 6| Step: 1
Training loss: 2.5926892053172614
Validation loss: 2.778318338778956

Epoch: 6| Step: 2
Training loss: 3.121345213880366
Validation loss: 2.77532276330016

Epoch: 6| Step: 3
Training loss: 3.406658743036042
Validation loss: 2.77617687153204

Epoch: 6| Step: 4
Training loss: 3.115946051643534
Validation loss: 2.7739298583209977

Epoch: 6| Step: 5
Training loss: 3.45612367257726
Validation loss: 2.7775759864305303

Epoch: 6| Step: 6
Training loss: 3.5284809970244
Validation loss: 2.772094902592905

Epoch: 6| Step: 7
Training loss: 2.693673428821262
Validation loss: 2.7728949744546516

Epoch: 6| Step: 8
Training loss: 3.0570150030315135
Validation loss: 2.7745793165710633

Epoch: 6| Step: 9
Training loss: 3.2528600579364855
Validation loss: 2.7727987822339117

Epoch: 6| Step: 10
Training loss: 2.8180291821097105
Validation loss: 2.7716293622523276

Epoch: 6| Step: 11
Training loss: 3.0543755959888217
Validation loss: 2.773010654581929

Epoch: 6| Step: 12
Training loss: 2.9052207518857323
Validation loss: 2.7755267433664534

Epoch: 6| Step: 13
Training loss: 3.236188886705628
Validation loss: 2.7741254582697445

Epoch: 58| Step: 0
Training loss: 2.673126641398531
Validation loss: 2.768596106507678

Epoch: 6| Step: 1
Training loss: 3.4107037745950777
Validation loss: 2.7733648207167114

Epoch: 6| Step: 2
Training loss: 2.6485863927887867
Validation loss: 2.770160996567411

Epoch: 6| Step: 3
Training loss: 3.144426009981945
Validation loss: 2.771709435631043

Epoch: 6| Step: 4
Training loss: 3.049695709558322
Validation loss: 2.772837208857031

Epoch: 6| Step: 5
Training loss: 2.54997953518902
Validation loss: 2.776266930680467

Epoch: 6| Step: 6
Training loss: 2.730819221237391
Validation loss: 2.778918641510792

Epoch: 6| Step: 7
Training loss: 3.1890622966491544
Validation loss: 2.781247274358985

Epoch: 6| Step: 8
Training loss: 3.51178664161987
Validation loss: 2.7795360335658468

Epoch: 6| Step: 9
Training loss: 3.0591596174942586
Validation loss: 2.770798649564273

Epoch: 6| Step: 10
Training loss: 3.239515265008282
Validation loss: 2.769010831896469

Epoch: 6| Step: 11
Training loss: 3.617962286672995
Validation loss: 2.7695374084003377

Epoch: 6| Step: 12
Training loss: 3.234177440562131
Validation loss: 2.7688293303445075

Epoch: 6| Step: 13
Training loss: 2.9134520845049185
Validation loss: 2.764191435035665

Epoch: 59| Step: 0
Training loss: 3.586583696372355
Validation loss: 2.7620950071147896

Epoch: 6| Step: 1
Training loss: 3.2519886095098545
Validation loss: 2.7627782550575066

Epoch: 6| Step: 2
Training loss: 2.8408704997822767
Validation loss: 2.7627549826946876

Epoch: 6| Step: 3
Training loss: 2.389948730557286
Validation loss: 2.7623513337597805

Epoch: 6| Step: 4
Training loss: 3.1609667291576793
Validation loss: 2.7617347200353164

Epoch: 6| Step: 5
Training loss: 2.8937020085682787
Validation loss: 2.7617420032467552

Epoch: 6| Step: 6
Training loss: 3.3827734541897136
Validation loss: 2.759690510359462

Epoch: 6| Step: 7
Training loss: 3.324482962197638
Validation loss: 2.7602289440539716

Epoch: 6| Step: 8
Training loss: 2.729956582950304
Validation loss: 2.7622409159887744

Epoch: 6| Step: 9
Training loss: 2.8542070223514675
Validation loss: 2.7669573281919493

Epoch: 6| Step: 10
Training loss: 2.788954788820879
Validation loss: 2.7642328313157813

Epoch: 6| Step: 11
Training loss: 2.853395139642775
Validation loss: 2.767037509903125

Epoch: 6| Step: 12
Training loss: 3.320113160376477
Validation loss: 2.7692035326281323

Epoch: 6| Step: 13
Training loss: 3.8071454077031923
Validation loss: 2.7735802204269517

Epoch: 60| Step: 0
Training loss: 3.379725080290876
Validation loss: 2.785805797486156

Epoch: 6| Step: 1
Training loss: 2.8242165550972627
Validation loss: 2.780986663271801

Epoch: 6| Step: 2
Training loss: 3.281884994825793
Validation loss: 2.7800068747328543

Epoch: 6| Step: 3
Training loss: 2.609880409862525
Validation loss: 2.776669062639616

Epoch: 6| Step: 4
Training loss: 2.1011598335994783
Validation loss: 2.7679338985450332

Epoch: 6| Step: 5
Training loss: 2.727916479717167
Validation loss: 2.7720762437123985

Epoch: 6| Step: 6
Training loss: 3.4914939242827305
Validation loss: 2.7767174697431862

Epoch: 6| Step: 7
Training loss: 3.049397368383257
Validation loss: 2.77070545645022

Epoch: 6| Step: 8
Training loss: 3.3404153613550744
Validation loss: 2.7649813353113957

Epoch: 6| Step: 9
Training loss: 3.506603686875533
Validation loss: 2.7660774883702364

Epoch: 6| Step: 10
Training loss: 3.055329628500654
Validation loss: 2.754225915470686

Epoch: 6| Step: 11
Training loss: 3.0979314732320655
Validation loss: 2.75169858278799

Epoch: 6| Step: 12
Training loss: 2.848413353680054
Validation loss: 2.751742807282702

Epoch: 6| Step: 13
Training loss: 3.5697475128218596
Validation loss: 2.755402425787114

Epoch: 61| Step: 0
Training loss: 2.730983440040267
Validation loss: 2.753985480526831

Epoch: 6| Step: 1
Training loss: 3.1638928026445488
Validation loss: 2.755743031646912

Epoch: 6| Step: 2
Training loss: 2.690760741315436
Validation loss: 2.7567545514407388

Epoch: 6| Step: 3
Training loss: 3.2006901116090196
Validation loss: 2.754262636319158

Epoch: 6| Step: 4
Training loss: 2.5452874975691806
Validation loss: 2.7558802227738335

Epoch: 6| Step: 5
Training loss: 3.167744319317896
Validation loss: 2.753427839531621

Epoch: 6| Step: 6
Training loss: 3.1732741403535285
Validation loss: 2.750845971969316

Epoch: 6| Step: 7
Training loss: 3.8535934571856645
Validation loss: 2.7509245022325484

Epoch: 6| Step: 8
Training loss: 3.1177824977453237
Validation loss: 2.756376309728522

Epoch: 6| Step: 9
Training loss: 3.081805821672994
Validation loss: 2.7479455532147985

Epoch: 6| Step: 10
Training loss: 3.395729547018452
Validation loss: 2.7488523066565596

Epoch: 6| Step: 11
Training loss: 3.0518635919167476
Validation loss: 2.7497462922839757

Epoch: 6| Step: 12
Training loss: 2.7019625242388834
Validation loss: 2.755375073600454

Epoch: 6| Step: 13
Training loss: 2.9712683988201314
Validation loss: 2.783657360822218

Epoch: 62| Step: 0
Training loss: 2.71443333439482
Validation loss: 2.771444672518235

Epoch: 6| Step: 1
Training loss: 2.899169993832236
Validation loss: 2.756755080581565

Epoch: 6| Step: 2
Training loss: 3.590742096348641
Validation loss: 2.7517018454506377

Epoch: 6| Step: 3
Training loss: 2.5781834451235204
Validation loss: 2.7545541415873447

Epoch: 6| Step: 4
Training loss: 2.7819943235711024
Validation loss: 2.7823140513675386

Epoch: 6| Step: 5
Training loss: 2.7025542786799726
Validation loss: 2.769529048782789

Epoch: 6| Step: 6
Training loss: 3.3192865200241695
Validation loss: 2.773437473193707

Epoch: 6| Step: 7
Training loss: 3.0883944617320704
Validation loss: 2.759032481499879

Epoch: 6| Step: 8
Training loss: 3.46000352230885
Validation loss: 2.7585826357255168

Epoch: 6| Step: 9
Training loss: 2.7764434428280986
Validation loss: 2.7495487006896733

Epoch: 6| Step: 10
Training loss: 3.0466195806402587
Validation loss: 2.748682989480603

Epoch: 6| Step: 11
Training loss: 2.4977517509160316
Validation loss: 2.747899320550576

Epoch: 6| Step: 12
Training loss: 3.9613177777188966
Validation loss: 2.74607462504298

Epoch: 6| Step: 13
Training loss: 3.219359849358354
Validation loss: 2.7442953243127355

Epoch: 63| Step: 0
Training loss: 3.052993499828907
Validation loss: 2.7503423412453176

Epoch: 6| Step: 1
Training loss: 2.9597342670859312
Validation loss: 2.7500727076161913

Epoch: 6| Step: 2
Training loss: 3.581956702468551
Validation loss: 2.749816966747696

Epoch: 6| Step: 3
Training loss: 2.475949665864451
Validation loss: 2.752464310827091

Epoch: 6| Step: 4
Training loss: 2.8886758367112795
Validation loss: 2.747962184506221

Epoch: 6| Step: 5
Training loss: 2.670834165702924
Validation loss: 2.753527274405131

Epoch: 6| Step: 6
Training loss: 3.5127337286351517
Validation loss: 2.7467473502553923

Epoch: 6| Step: 7
Training loss: 3.0611918243949017
Validation loss: 2.744466403959793

Epoch: 6| Step: 8
Training loss: 3.5810004927979198
Validation loss: 2.7478088625202526

Epoch: 6| Step: 9
Training loss: 3.0182170895106375
Validation loss: 2.7518201418425576

Epoch: 6| Step: 10
Training loss: 3.2127983103189166
Validation loss: 2.7493888990762367

Epoch: 6| Step: 11
Training loss: 3.3973977789472927
Validation loss: 2.758416367545565

Epoch: 6| Step: 12
Training loss: 2.686381084923555
Validation loss: 2.7614804082492346

Epoch: 6| Step: 13
Training loss: 2.365416314256794
Validation loss: 2.7705921941269525

Epoch: 64| Step: 0
Training loss: 2.4026331285315665
Validation loss: 2.7642189272058837

Epoch: 6| Step: 1
Training loss: 2.8760982571876013
Validation loss: 2.757667106108151

Epoch: 6| Step: 2
Training loss: 3.7432477560024506
Validation loss: 2.7493185698098097

Epoch: 6| Step: 3
Training loss: 3.510476101486299
Validation loss: 2.744921814255397

Epoch: 6| Step: 4
Training loss: 3.569789722992355
Validation loss: 2.7444345066316367

Epoch: 6| Step: 5
Training loss: 2.3466788747137586
Validation loss: 2.746894156491986

Epoch: 6| Step: 6
Training loss: 3.2536184268336754
Validation loss: 2.748691407834058

Epoch: 6| Step: 7
Training loss: 3.322542047858844
Validation loss: 2.7516069229327487

Epoch: 6| Step: 8
Training loss: 3.0298357938581657
Validation loss: 2.7511929304590885

Epoch: 6| Step: 9
Training loss: 2.705833973964298
Validation loss: 2.7602443635875726

Epoch: 6| Step: 10
Training loss: 3.0681172450813268
Validation loss: 2.755068015088352

Epoch: 6| Step: 11
Training loss: 2.727819027516507
Validation loss: 2.7543438828655047

Epoch: 6| Step: 12
Training loss: 3.1676396999849743
Validation loss: 2.7488855852124296

Epoch: 6| Step: 13
Training loss: 3.144932615834891
Validation loss: 2.7445835307729016

Epoch: 65| Step: 0
Training loss: 3.1710859548130355
Validation loss: 2.7426119029757308

Epoch: 6| Step: 1
Training loss: 3.192860154259914
Validation loss: 2.74102851264787

Epoch: 6| Step: 2
Training loss: 3.3126163102369186
Validation loss: 2.7395866360023144

Epoch: 6| Step: 3
Training loss: 3.058780201652529
Validation loss: 2.7389494647169

Epoch: 6| Step: 4
Training loss: 3.009579305556766
Validation loss: 2.736695028060693

Epoch: 6| Step: 5
Training loss: 3.1264519942170157
Validation loss: 2.737172404119893

Epoch: 6| Step: 6
Training loss: 3.111863563763286
Validation loss: 2.746700193004107

Epoch: 6| Step: 7
Training loss: 3.3079609992093375
Validation loss: 2.777484480916199

Epoch: 6| Step: 8
Training loss: 2.7000257773405094
Validation loss: 2.770774362032

Epoch: 6| Step: 9
Training loss: 3.0754361099257697
Validation loss: 2.7373446875380085

Epoch: 6| Step: 10
Training loss: 2.9403289808082462
Validation loss: 2.7375905592690977

Epoch: 6| Step: 11
Training loss: 3.013222483506225
Validation loss: 2.737936594493308

Epoch: 6| Step: 12
Training loss: 2.965024357095804
Validation loss: 2.736805751466177

Epoch: 6| Step: 13
Training loss: 2.912653932883077
Validation loss: 2.731330972167091

Epoch: 66| Step: 0
Training loss: 2.914371422968532
Validation loss: 2.735956974899244

Epoch: 6| Step: 1
Training loss: 3.7653119602119083
Validation loss: 2.7343639020797132

Epoch: 6| Step: 2
Training loss: 3.4380919900407583
Validation loss: 2.734050155540386

Epoch: 6| Step: 3
Training loss: 3.19914601374885
Validation loss: 2.7308052868785215

Epoch: 6| Step: 4
Training loss: 2.747608705683606
Validation loss: 2.723622242154368

Epoch: 6| Step: 5
Training loss: 2.3694370773020026
Validation loss: 2.729775333109638

Epoch: 6| Step: 6
Training loss: 3.3995247340412744
Validation loss: 2.724964840961235

Epoch: 6| Step: 7
Training loss: 2.6674983893177777
Validation loss: 2.7219832556618972

Epoch: 6| Step: 8
Training loss: 2.856092392727928
Validation loss: 2.7280745714622388

Epoch: 6| Step: 9
Training loss: 3.42473019838975
Validation loss: 2.7398714799652377

Epoch: 6| Step: 10
Training loss: 3.1242894700047903
Validation loss: 2.7320822201980124

Epoch: 6| Step: 11
Training loss: 2.944397963950727
Validation loss: 2.73910627668536

Epoch: 6| Step: 12
Training loss: 3.0500226317019425
Validation loss: 2.725435548188902

Epoch: 6| Step: 13
Training loss: 2.0105185474677705
Validation loss: 2.7278058785567643

Epoch: 67| Step: 0
Training loss: 3.5314517343337304
Validation loss: 2.7286390671159952

Epoch: 6| Step: 1
Training loss: 2.4568472643256865
Validation loss: 2.720552095438941

Epoch: 6| Step: 2
Training loss: 3.3097727362759968
Validation loss: 2.724280887402111

Epoch: 6| Step: 3
Training loss: 2.4687403425196783
Validation loss: 2.729438076568551

Epoch: 6| Step: 4
Training loss: 3.3328265440654348
Validation loss: 2.7221467596642612

Epoch: 6| Step: 5
Training loss: 2.3995154129999086
Validation loss: 2.719902304515087

Epoch: 6| Step: 6
Training loss: 2.889188337293374
Validation loss: 2.720774340937379

Epoch: 6| Step: 7
Training loss: 3.1546965449195494
Validation loss: 2.718986569773232

Epoch: 6| Step: 8
Training loss: 3.1566512353258753
Validation loss: 2.7185364270272445

Epoch: 6| Step: 9
Training loss: 3.1698808085660155
Validation loss: 2.717057202383024

Epoch: 6| Step: 10
Training loss: 3.3158762298235422
Validation loss: 2.716856060476087

Epoch: 6| Step: 11
Training loss: 3.010701167160955
Validation loss: 2.715791983948081

Epoch: 6| Step: 12
Training loss: 3.526527149731442
Validation loss: 2.7158618315604754

Epoch: 6| Step: 13
Training loss: 2.229070809938575
Validation loss: 2.7180186367515597

Epoch: 68| Step: 0
Training loss: 2.8977023526512427
Validation loss: 2.7337674573775503

Epoch: 6| Step: 1
Training loss: 3.0088987296428873
Validation loss: 2.764519268056171

Epoch: 6| Step: 2
Training loss: 3.125103758043108
Validation loss: 2.8019290342862555

Epoch: 6| Step: 3
Training loss: 2.98703699075369
Validation loss: 2.809857849036489

Epoch: 6| Step: 4
Training loss: 2.330802862327105
Validation loss: 2.7675443565557214

Epoch: 6| Step: 5
Training loss: 2.6732173470079985
Validation loss: 2.7425887847841435

Epoch: 6| Step: 6
Training loss: 3.8790798244459763
Validation loss: 2.7453065498119433

Epoch: 6| Step: 7
Training loss: 3.2678772674822336
Validation loss: 2.7214320419778906

Epoch: 6| Step: 8
Training loss: 3.0436271376359656
Validation loss: 2.7121405661874762

Epoch: 6| Step: 9
Training loss: 3.2394981904611364
Validation loss: 2.716252029119413

Epoch: 6| Step: 10
Training loss: 3.0243161524049142
Validation loss: 2.716245093954621

Epoch: 6| Step: 11
Training loss: 3.465482255147498
Validation loss: 2.7206087793864793

Epoch: 6| Step: 12
Training loss: 2.8793040690411753
Validation loss: 2.7224689847137973

Epoch: 6| Step: 13
Training loss: 2.1408491922189343
Validation loss: 2.7240781388115507

Epoch: 69| Step: 0
Training loss: 2.4363380988502357
Validation loss: 2.7210640522385434

Epoch: 6| Step: 1
Training loss: 2.210854896107627
Validation loss: 2.72338592821416

Epoch: 6| Step: 2
Training loss: 3.4373533737815722
Validation loss: 2.7225304979701517

Epoch: 6| Step: 3
Training loss: 3.410672597694559
Validation loss: 2.720966855856036

Epoch: 6| Step: 4
Training loss: 3.3854766996880747
Validation loss: 2.7207646979675952

Epoch: 6| Step: 5
Training loss: 3.1421286556096524
Validation loss: 2.7204334260309984

Epoch: 6| Step: 6
Training loss: 3.0995467623736723
Validation loss: 2.717162323442785

Epoch: 6| Step: 7
Training loss: 3.0261305217642906
Validation loss: 2.7189156502214495

Epoch: 6| Step: 8
Training loss: 2.8019984538518545
Validation loss: 2.7147038334382896

Epoch: 6| Step: 9
Training loss: 3.6175523742807183
Validation loss: 2.717459214173843

Epoch: 6| Step: 10
Training loss: 2.7490149380974294
Validation loss: 2.7177706095237903

Epoch: 6| Step: 11
Training loss: 3.049929295955424
Validation loss: 2.718425184890702

Epoch: 6| Step: 12
Training loss: 2.7760602557983574
Validation loss: 2.734410757367187

Epoch: 6| Step: 13
Training loss: 3.3914750259831896
Validation loss: 2.7240213397740582

Epoch: 70| Step: 0
Training loss: 3.717912595693162
Validation loss: 2.7387137469147156

Epoch: 6| Step: 1
Training loss: 3.0705816330536764
Validation loss: 2.7356296118621253

Epoch: 6| Step: 2
Training loss: 2.776466628154543
Validation loss: 2.735722344928735

Epoch: 6| Step: 3
Training loss: 3.0631999558838077
Validation loss: 2.7234354009943726

Epoch: 6| Step: 4
Training loss: 3.142994153145071
Validation loss: 2.7248193333051485

Epoch: 6| Step: 5
Training loss: 2.8003187236582634
Validation loss: 2.7145039762833814

Epoch: 6| Step: 6
Training loss: 2.6797020024833054
Validation loss: 2.7147264997214013

Epoch: 6| Step: 7
Training loss: 3.0940593218057453
Validation loss: 2.715085750431209

Epoch: 6| Step: 8
Training loss: 2.764025985623225
Validation loss: 2.715929311895014

Epoch: 6| Step: 9
Training loss: 3.5671518304806793
Validation loss: 2.719711190377592

Epoch: 6| Step: 10
Training loss: 3.2426773620426994
Validation loss: 2.7214262278305372

Epoch: 6| Step: 11
Training loss: 2.3823677023054266
Validation loss: 2.7152988531911375

Epoch: 6| Step: 12
Training loss: 2.744490219057084
Validation loss: 2.710595504902653

Epoch: 6| Step: 13
Training loss: 3.45431608483541
Validation loss: 2.7135474120498824

Epoch: 71| Step: 0
Training loss: 3.5323359077283203
Validation loss: 2.7091331036246813

Epoch: 6| Step: 1
Training loss: 3.4096735277257597
Validation loss: 2.713593425063828

Epoch: 6| Step: 2
Training loss: 3.0940089261913197
Validation loss: 2.7110136656833106

Epoch: 6| Step: 3
Training loss: 3.101065108151178
Validation loss: 2.71143012059772

Epoch: 6| Step: 4
Training loss: 3.427690832834199
Validation loss: 2.7076817835492233

Epoch: 6| Step: 5
Training loss: 3.2291541970945397
Validation loss: 2.709245830630928

Epoch: 6| Step: 6
Training loss: 2.680129301168861
Validation loss: 2.7043523781343306

Epoch: 6| Step: 7
Training loss: 3.200405548146582
Validation loss: 2.703116822892766

Epoch: 6| Step: 8
Training loss: 1.7846636269825777
Validation loss: 2.7020886357576464

Epoch: 6| Step: 9
Training loss: 2.751641650472228
Validation loss: 2.7039584377567767

Epoch: 6| Step: 10
Training loss: 2.460897778387267
Validation loss: 2.702764148088515

Epoch: 6| Step: 11
Training loss: 3.168377380733805
Validation loss: 2.705089272937791

Epoch: 6| Step: 12
Training loss: 2.9174763418511604
Validation loss: 2.7015803827971077

Epoch: 6| Step: 13
Training loss: 3.569571587210872
Validation loss: 2.7011269013026227

Epoch: 72| Step: 0
Training loss: 3.0125640988950213
Validation loss: 2.707056202239527

Epoch: 6| Step: 1
Training loss: 3.012458047535132
Validation loss: 2.718626205045515

Epoch: 6| Step: 2
Training loss: 3.6335065281269836
Validation loss: 2.7188438811386697

Epoch: 6| Step: 3
Training loss: 3.294288814128712
Validation loss: 2.7225330884175456

Epoch: 6| Step: 4
Training loss: 2.2317523636530328
Validation loss: 2.7267923457732537

Epoch: 6| Step: 5
Training loss: 3.524286205988207
Validation loss: 2.720627644247892

Epoch: 6| Step: 6
Training loss: 2.932792625298934
Validation loss: 2.708066389181949

Epoch: 6| Step: 7
Training loss: 3.0083539995520963
Validation loss: 2.702960007707471

Epoch: 6| Step: 8
Training loss: 2.554219894310913
Validation loss: 2.7011023593528627

Epoch: 6| Step: 9
Training loss: 2.784008329932587
Validation loss: 2.7026129735623172

Epoch: 6| Step: 10
Training loss: 3.037947030786619
Validation loss: 2.7019361406371276

Epoch: 6| Step: 11
Training loss: 3.2104665591855843
Validation loss: 2.701960978632032

Epoch: 6| Step: 12
Training loss: 3.0221455497303373
Validation loss: 2.702660105172654

Epoch: 6| Step: 13
Training loss: 3.120261911011726
Validation loss: 2.699322407954271

Epoch: 73| Step: 0
Training loss: 3.3943444168772476
Validation loss: 2.702652341181651

Epoch: 6| Step: 1
Training loss: 3.045291430428332
Validation loss: 2.701520741665687

Epoch: 6| Step: 2
Training loss: 2.990214122900475
Validation loss: 2.700846846168099

Epoch: 6| Step: 3
Training loss: 2.8287147202190237
Validation loss: 2.70351490322094

Epoch: 6| Step: 4
Training loss: 3.179709094674828
Validation loss: 2.7009657971446157

Epoch: 6| Step: 5
Training loss: 3.1788636436054047
Validation loss: 2.7047224671711083

Epoch: 6| Step: 6
Training loss: 2.6955932470972668
Validation loss: 2.700110492131769

Epoch: 6| Step: 7
Training loss: 2.860702790029202
Validation loss: 2.695512510407253

Epoch: 6| Step: 8
Training loss: 3.1777508810842057
Validation loss: 2.6984189658245725

Epoch: 6| Step: 9
Training loss: 3.3107437660385006
Validation loss: 2.706295653173662

Epoch: 6| Step: 10
Training loss: 2.9085425082151932
Validation loss: 2.70415648948243

Epoch: 6| Step: 11
Training loss: 2.7082718377589954
Validation loss: 2.721347053582517

Epoch: 6| Step: 12
Training loss: 3.096134692413968
Validation loss: 2.7260054411136654

Epoch: 6| Step: 13
Training loss: 3.184567916761595
Validation loss: 2.7276035085324053

Epoch: 74| Step: 0
Training loss: 3.2260765467133456
Validation loss: 2.704231443099697

Epoch: 6| Step: 1
Training loss: 3.0400367097143963
Validation loss: 2.6980111723268014

Epoch: 6| Step: 2
Training loss: 2.5535932991547017
Validation loss: 2.6977028311628954

Epoch: 6| Step: 3
Training loss: 3.044225861560112
Validation loss: 2.699613941823648

Epoch: 6| Step: 4
Training loss: 3.020721082684563
Validation loss: 2.7083374474607003

Epoch: 6| Step: 5
Training loss: 3.387021025969412
Validation loss: 2.7166880934843083

Epoch: 6| Step: 6
Training loss: 2.9506347490604936
Validation loss: 2.726676638825393

Epoch: 6| Step: 7
Training loss: 3.069300050249554
Validation loss: 2.7115828523259924

Epoch: 6| Step: 8
Training loss: 2.6961530618657044
Validation loss: 2.702033317588092

Epoch: 6| Step: 9
Training loss: 3.0059783495582093
Validation loss: 2.7071144207120073

Epoch: 6| Step: 10
Training loss: 3.0479114823591704
Validation loss: 2.7375783159800107

Epoch: 6| Step: 11
Training loss: 2.856419270714624
Validation loss: 2.746511925535244

Epoch: 6| Step: 12
Training loss: 3.4604268612253097
Validation loss: 2.729208175567709

Epoch: 6| Step: 13
Training loss: 3.476247023080856
Validation loss: 2.7068727920394453

Epoch: 75| Step: 0
Training loss: 2.7114603819065706
Validation loss: 2.6984265795373905

Epoch: 6| Step: 1
Training loss: 2.780617374093318
Validation loss: 2.6954543181173456

Epoch: 6| Step: 2
Training loss: 2.95581707032466
Validation loss: 2.693175734524931

Epoch: 6| Step: 3
Training loss: 3.1380776470101166
Validation loss: 2.6973298809719672

Epoch: 6| Step: 4
Training loss: 3.0659888499754575
Validation loss: 2.698177329963815

Epoch: 6| Step: 5
Training loss: 3.5042857769390783
Validation loss: 2.699487257900482

Epoch: 6| Step: 6
Training loss: 2.704393298777276
Validation loss: 2.6980260276571895

Epoch: 6| Step: 7
Training loss: 2.9342841543611886
Validation loss: 2.7002685798027457

Epoch: 6| Step: 8
Training loss: 3.271791759113413
Validation loss: 2.70031067311516

Epoch: 6| Step: 9
Training loss: 2.7497768311546276
Validation loss: 2.7054721880354937

Epoch: 6| Step: 10
Training loss: 3.673408350469868
Validation loss: 2.7090925034556217

Epoch: 6| Step: 11
Training loss: 2.5416417563629987
Validation loss: 2.7113658470516895

Epoch: 6| Step: 12
Training loss: 3.2877522302909634
Validation loss: 2.7141271611455213

Epoch: 6| Step: 13
Training loss: 2.9146129098572664
Validation loss: 2.712848852566539

Epoch: 76| Step: 0
Training loss: 3.3783315533666403
Validation loss: 2.692730958016481

Epoch: 6| Step: 1
Training loss: 3.7600938371352517
Validation loss: 2.690125587240786

Epoch: 6| Step: 2
Training loss: 3.5565843153491383
Validation loss: 2.6909070131408575

Epoch: 6| Step: 3
Training loss: 2.9050828784669327
Validation loss: 2.693569747634279

Epoch: 6| Step: 4
Training loss: 3.5547294865738075
Validation loss: 2.6945345904081495

Epoch: 6| Step: 5
Training loss: 2.8151636014457977
Validation loss: 2.6906982797591468

Epoch: 6| Step: 6
Training loss: 3.07330843911946
Validation loss: 2.690970318692465

Epoch: 6| Step: 7
Training loss: 2.8960645478152425
Validation loss: 2.690644790218188

Epoch: 6| Step: 8
Training loss: 2.219453512063705
Validation loss: 2.692772282326815

Epoch: 6| Step: 9
Training loss: 2.769370436202972
Validation loss: 2.694632083754607

Epoch: 6| Step: 10
Training loss: 2.306886096267244
Validation loss: 2.6941045968878554

Epoch: 6| Step: 11
Training loss: 3.0486326185513906
Validation loss: 2.6993566190872196

Epoch: 6| Step: 12
Training loss: 2.9206870208822777
Validation loss: 2.7044993187262274

Epoch: 6| Step: 13
Training loss: 2.5317953016873216
Validation loss: 2.7179602953084268

Epoch: 77| Step: 0
Training loss: 3.0005529212041533
Validation loss: 2.736240038046406

Epoch: 6| Step: 1
Training loss: 2.873583237238464
Validation loss: 2.7373480693922043

Epoch: 6| Step: 2
Training loss: 2.8100674600071898
Validation loss: 2.742111242857375

Epoch: 6| Step: 3
Training loss: 3.1197040696283462
Validation loss: 2.7227874958212266

Epoch: 6| Step: 4
Training loss: 2.6493022935901944
Validation loss: 2.7072236617266197

Epoch: 6| Step: 5
Training loss: 3.1297389909428905
Validation loss: 2.708415214935222

Epoch: 6| Step: 6
Training loss: 2.8805440439182033
Validation loss: 2.6996018339844876

Epoch: 6| Step: 7
Training loss: 3.101082176086567
Validation loss: 2.6948796454227564

Epoch: 6| Step: 8
Training loss: 3.1875469727888484
Validation loss: 2.6917452087138742

Epoch: 6| Step: 9
Training loss: 3.2865490948718428
Validation loss: 2.6900748862270363

Epoch: 6| Step: 10
Training loss: 3.160391630217315
Validation loss: 2.6916897522611207

Epoch: 6| Step: 11
Training loss: 2.7842918649029675
Validation loss: 2.6927291724279163

Epoch: 6| Step: 12
Training loss: 2.7830989563839426
Validation loss: 2.689811902150751

Epoch: 6| Step: 13
Training loss: 3.9127164494418594
Validation loss: 2.692578978817384

Epoch: 78| Step: 0
Training loss: 2.468275290130222
Validation loss: 2.688382977874968

Epoch: 6| Step: 1
Training loss: 2.715346562868529
Validation loss: 2.689736626296467

Epoch: 6| Step: 2
Training loss: 2.7914228949703146
Validation loss: 2.689156799270339

Epoch: 6| Step: 3
Training loss: 3.2902545716835307
Validation loss: 2.68955401477714

Epoch: 6| Step: 4
Training loss: 3.2607683635985127
Validation loss: 2.687790633882227

Epoch: 6| Step: 5
Training loss: 3.5839002885231297
Validation loss: 2.6889403523987907

Epoch: 6| Step: 6
Training loss: 3.378076493358744
Validation loss: 2.691422080973883

Epoch: 6| Step: 7
Training loss: 3.2140109535130335
Validation loss: 2.6884687327557484

Epoch: 6| Step: 8
Training loss: 3.066900089612958
Validation loss: 2.6913178939290927

Epoch: 6| Step: 9
Training loss: 2.347054758311613
Validation loss: 2.687878362908011

Epoch: 6| Step: 10
Training loss: 3.0329522141472625
Validation loss: 2.690202436498755

Epoch: 6| Step: 11
Training loss: 3.365453570152041
Validation loss: 2.6985019896661235

Epoch: 6| Step: 12
Training loss: 2.8415287271470877
Validation loss: 2.692841577941308

Epoch: 6| Step: 13
Training loss: 2.569789752152844
Validation loss: 2.6946941982099935

Epoch: 79| Step: 0
Training loss: 3.2655242466327943
Validation loss: 2.6958580650311825

Epoch: 6| Step: 1
Training loss: 3.3991767167035305
Validation loss: 2.6992735816426427

Epoch: 6| Step: 2
Training loss: 2.74559474442986
Validation loss: 2.6966112923644263

Epoch: 6| Step: 3
Training loss: 2.479024439560053
Validation loss: 2.6958614523319926

Epoch: 6| Step: 4
Training loss: 3.0397085567108584
Validation loss: 2.687579873747001

Epoch: 6| Step: 5
Training loss: 3.244875168478564
Validation loss: 2.694783889607897

Epoch: 6| Step: 6
Training loss: 2.8004048838114723
Validation loss: 2.695236860809776

Epoch: 6| Step: 7
Training loss: 2.973143689247397
Validation loss: 2.693171915489511

Epoch: 6| Step: 8
Training loss: 3.381510636020321
Validation loss: 2.6901659228446597

Epoch: 6| Step: 9
Training loss: 2.6834489319663213
Validation loss: 2.6871053964497977

Epoch: 6| Step: 10
Training loss: 3.4081382067599537
Validation loss: 2.694148005453541

Epoch: 6| Step: 11
Training loss: 2.748425813425623
Validation loss: 2.692051251551437

Epoch: 6| Step: 12
Training loss: 2.910991942981301
Validation loss: 2.6850352048762924

Epoch: 6| Step: 13
Training loss: 3.0441011762810293
Validation loss: 2.683818026270758

Epoch: 80| Step: 0
Training loss: 3.232944927941782
Validation loss: 2.681472447410222

Epoch: 6| Step: 1
Training loss: 3.3551894972109735
Validation loss: 2.6816455330845717

Epoch: 6| Step: 2
Training loss: 3.2648530622661225
Validation loss: 2.6805192640765427

Epoch: 6| Step: 3
Training loss: 2.5572196706878416
Validation loss: 2.680018470769689

Epoch: 6| Step: 4
Training loss: 2.858748904195892
Validation loss: 2.6790478517934533

Epoch: 6| Step: 5
Training loss: 3.001311492353518
Validation loss: 2.678480128105881

Epoch: 6| Step: 6
Training loss: 3.2891602127892017
Validation loss: 2.67561500942495

Epoch: 6| Step: 7
Training loss: 2.264944461032115
Validation loss: 2.67821880584128

Epoch: 6| Step: 8
Training loss: 3.5542975243243857
Validation loss: 2.679772130674421

Epoch: 6| Step: 9
Training loss: 2.3992257578035376
Validation loss: 2.6830445751491188

Epoch: 6| Step: 10
Training loss: 2.973043128364477
Validation loss: 2.6876026733962903

Epoch: 6| Step: 11
Training loss: 2.7956156532682277
Validation loss: 2.689906146614912

Epoch: 6| Step: 12
Training loss: 3.3484865670073565
Validation loss: 2.688444808554844

Epoch: 6| Step: 13
Training loss: 3.040502839413161
Validation loss: 2.679161408313211

Epoch: 81| Step: 0
Training loss: 2.7759831310826035
Validation loss: 2.677670512383243

Epoch: 6| Step: 1
Training loss: 2.712042943181243
Validation loss: 2.672493278345857

Epoch: 6| Step: 2
Training loss: 2.68373287456647
Validation loss: 2.676339800629384

Epoch: 6| Step: 3
Training loss: 3.1089768658032195
Validation loss: 2.674887483960103

Epoch: 6| Step: 4
Training loss: 3.1163064194279846
Validation loss: 2.676579649510232

Epoch: 6| Step: 5
Training loss: 2.8596651524147974
Validation loss: 2.673606845245204

Epoch: 6| Step: 6
Training loss: 2.4011767522471614
Validation loss: 2.6761898060904414

Epoch: 6| Step: 7
Training loss: 3.1480508192969925
Validation loss: 2.6737742011275096

Epoch: 6| Step: 8
Training loss: 2.7351024422995653
Validation loss: 2.6725475100829246

Epoch: 6| Step: 9
Training loss: 3.016903621015443
Validation loss: 2.6728027111010264

Epoch: 6| Step: 10
Training loss: 3.119502610883126
Validation loss: 2.6730581054628053

Epoch: 6| Step: 11
Training loss: 3.5261437961469975
Validation loss: 2.672883503611704

Epoch: 6| Step: 12
Training loss: 3.2980844891553978
Validation loss: 2.6751895723130072

Epoch: 6| Step: 13
Training loss: 3.6865606889674205
Validation loss: 2.6717988565693296

Epoch: 82| Step: 0
Training loss: 2.5370154947086636
Validation loss: 2.6824018300260235

Epoch: 6| Step: 1
Training loss: 3.4606002057706244
Validation loss: 2.6798429448534575

Epoch: 6| Step: 2
Training loss: 3.222613192183944
Validation loss: 2.699830596490639

Epoch: 6| Step: 3
Training loss: 2.969530183771349
Validation loss: 2.684617434281962

Epoch: 6| Step: 4
Training loss: 2.8333864955028547
Validation loss: 2.679752734248359

Epoch: 6| Step: 5
Training loss: 2.966439080527602
Validation loss: 2.685743968245695

Epoch: 6| Step: 6
Training loss: 3.363532753644428
Validation loss: 2.672476045018131

Epoch: 6| Step: 7
Training loss: 2.5122867968234455
Validation loss: 2.679505796624202

Epoch: 6| Step: 8
Training loss: 2.730995749504835
Validation loss: 2.678611372587846

Epoch: 6| Step: 9
Training loss: 3.020047596436389
Validation loss: 2.671077781805418

Epoch: 6| Step: 10
Training loss: 3.080684623922935
Validation loss: 2.669464749371378

Epoch: 6| Step: 11
Training loss: 3.097260304337087
Validation loss: 2.6712422269577294

Epoch: 6| Step: 12
Training loss: 2.8120754345343792
Validation loss: 2.6700217447397456

Epoch: 6| Step: 13
Training loss: 3.52806122876794
Validation loss: 2.6704437715332063

Epoch: 83| Step: 0
Training loss: 2.5874836612498844
Validation loss: 2.6715069867404093

Epoch: 6| Step: 1
Training loss: 3.3876266230604672
Validation loss: 2.6675763719146097

Epoch: 6| Step: 2
Training loss: 3.2236246769342207
Validation loss: 2.668713655623219

Epoch: 6| Step: 3
Training loss: 2.4803280287346983
Validation loss: 2.670035615134809

Epoch: 6| Step: 4
Training loss: 3.09560931812722
Validation loss: 2.668460193458742

Epoch: 6| Step: 5
Training loss: 3.2270139512315206
Validation loss: 2.669485844502044

Epoch: 6| Step: 6
Training loss: 3.25980716813702
Validation loss: 2.6669956364552294

Epoch: 6| Step: 7
Training loss: 2.642691260916587
Validation loss: 2.667921327436639

Epoch: 6| Step: 8
Training loss: 3.1272936223987347
Validation loss: 2.666090209499417

Epoch: 6| Step: 9
Training loss: 3.158410267828085
Validation loss: 2.6663616323850277

Epoch: 6| Step: 10
Training loss: 3.3000643521594477
Validation loss: 2.6664988352147176

Epoch: 6| Step: 11
Training loss: 2.8642260149424055
Validation loss: 2.6657768249841394

Epoch: 6| Step: 12
Training loss: 2.926969605178898
Validation loss: 2.6635506595074108

Epoch: 6| Step: 13
Training loss: 2.0605391226527745
Validation loss: 2.666245060581201

Epoch: 84| Step: 0
Training loss: 3.0829139286762413
Validation loss: 2.6657769259611825

Epoch: 6| Step: 1
Training loss: 3.758670574093732
Validation loss: 2.6680701937110776

Epoch: 6| Step: 2
Training loss: 2.234168623349866
Validation loss: 2.6722988897508144

Epoch: 6| Step: 3
Training loss: 2.7417033493540792
Validation loss: 2.6679085318867046

Epoch: 6| Step: 4
Training loss: 2.946177550352851
Validation loss: 2.66990497746787

Epoch: 6| Step: 5
Training loss: 3.4100743094930714
Validation loss: 2.6647973172345103

Epoch: 6| Step: 6
Training loss: 2.9024393674315077
Validation loss: 2.66725922609974

Epoch: 6| Step: 7
Training loss: 2.5609125011590166
Validation loss: 2.66912885662978

Epoch: 6| Step: 8
Training loss: 2.7139149785509535
Validation loss: 2.671587897602118

Epoch: 6| Step: 9
Training loss: 3.0359174836697007
Validation loss: 2.665342632567828

Epoch: 6| Step: 10
Training loss: 3.1941279894959203
Validation loss: 2.666666054597395

Epoch: 6| Step: 11
Training loss: 2.8554717558337464
Validation loss: 2.6718648581584294

Epoch: 6| Step: 12
Training loss: 3.109816630069408
Validation loss: 2.6727358128160494

Epoch: 6| Step: 13
Training loss: 3.1501024259838686
Validation loss: 2.6656147259327874

Epoch: 85| Step: 0
Training loss: 2.973726618748226
Validation loss: 2.6671402790071492

Epoch: 6| Step: 1
Training loss: 3.481936435380011
Validation loss: 2.666312024609605

Epoch: 6| Step: 2
Training loss: 3.1585715037167983
Validation loss: 2.6669705814434677

Epoch: 6| Step: 3
Training loss: 3.051929995142658
Validation loss: 2.674462096949263

Epoch: 6| Step: 4
Training loss: 2.815299611654388
Validation loss: 2.677868147999195

Epoch: 6| Step: 5
Training loss: 2.6032816387551945
Validation loss: 2.6881601181586143

Epoch: 6| Step: 6
Training loss: 3.150994939956791
Validation loss: 2.6863264023975626

Epoch: 6| Step: 7
Training loss: 2.3814973797796757
Validation loss: 2.692482685102715

Epoch: 6| Step: 8
Training loss: 3.30572551179961
Validation loss: 2.6885622915109266

Epoch: 6| Step: 9
Training loss: 2.78663619475002
Validation loss: 2.6727197790781854

Epoch: 6| Step: 10
Training loss: 3.4690392176021474
Validation loss: 2.663613117632867

Epoch: 6| Step: 11
Training loss: 2.355073759701648
Validation loss: 2.6599597878538854

Epoch: 6| Step: 12
Training loss: 2.9465145015984366
Validation loss: 2.6634035610000146

Epoch: 6| Step: 13
Training loss: 3.4011983947315843
Validation loss: 2.6627385368604575

Epoch: 86| Step: 0
Training loss: 3.6457102872883813
Validation loss: 2.664892836918828

Epoch: 6| Step: 1
Training loss: 2.858140689448928
Validation loss: 2.669864220541352

Epoch: 6| Step: 2
Training loss: 2.970914994910225
Validation loss: 2.674241186004371

Epoch: 6| Step: 3
Training loss: 3.05811572084592
Validation loss: 2.6728051790139338

Epoch: 6| Step: 4
Training loss: 3.1404030185271465
Validation loss: 2.666763406454953

Epoch: 6| Step: 5
Training loss: 3.627235118152111
Validation loss: 2.6663059306593224

Epoch: 6| Step: 6
Training loss: 2.554383239359456
Validation loss: 2.662886315207704

Epoch: 6| Step: 7
Training loss: 3.112829235389222
Validation loss: 2.6569004505052676

Epoch: 6| Step: 8
Training loss: 2.964672621461163
Validation loss: 2.653180159416653

Epoch: 6| Step: 9
Training loss: 2.7309245109838503
Validation loss: 2.654819691687003

Epoch: 6| Step: 10
Training loss: 2.6822337517766646
Validation loss: 2.674584938780134

Epoch: 6| Step: 11
Training loss: 2.738328179625268
Validation loss: 2.678652794613433

Epoch: 6| Step: 12
Training loss: 3.045694758389175
Validation loss: 2.728396776245129

Epoch: 6| Step: 13
Training loss: 2.5667633319172993
Validation loss: 2.775618336513439

Epoch: 87| Step: 0
Training loss: 3.1933247322279934
Validation loss: 2.8270103421287756

Epoch: 6| Step: 1
Training loss: 3.080237268994189
Validation loss: 2.7668173692101075

Epoch: 6| Step: 2
Training loss: 3.032014101604592
Validation loss: 2.704302692757383

Epoch: 6| Step: 3
Training loss: 2.6938537188253107
Validation loss: 2.685303276998772

Epoch: 6| Step: 4
Training loss: 2.686730563001073
Validation loss: 2.6674313743407145

Epoch: 6| Step: 5
Training loss: 2.9617777012276356
Validation loss: 2.66776913463494

Epoch: 6| Step: 6
Training loss: 3.1310244663663003
Validation loss: 2.6672123445543114

Epoch: 6| Step: 7
Training loss: 2.5940918295024478
Validation loss: 2.658637123778289

Epoch: 6| Step: 8
Training loss: 3.457696296818197
Validation loss: 2.6590979956056713

Epoch: 6| Step: 9
Training loss: 2.7551851806437027
Validation loss: 2.661564680694765

Epoch: 6| Step: 10
Training loss: 2.578938951027857
Validation loss: 2.6605460145645257

Epoch: 6| Step: 11
Training loss: 3.4803683248260717
Validation loss: 2.662124036320735

Epoch: 6| Step: 12
Training loss: 3.3857555669713286
Validation loss: 2.6632684078612088

Epoch: 6| Step: 13
Training loss: 3.1541683773168834
Validation loss: 2.6629315592840674

Epoch: 88| Step: 0
Training loss: 3.252888496296167
Validation loss: 2.6617756457284627

Epoch: 6| Step: 1
Training loss: 2.719476186298427
Validation loss: 2.661779781412984

Epoch: 6| Step: 2
Training loss: 2.7641118107219995
Validation loss: 2.658341701711832

Epoch: 6| Step: 3
Training loss: 2.747929747470574
Validation loss: 2.6582138445751675

Epoch: 6| Step: 4
Training loss: 2.7615378831830513
Validation loss: 2.6572571912131644

Epoch: 6| Step: 5
Training loss: 2.7482264608497506
Validation loss: 2.6516804255092117

Epoch: 6| Step: 6
Training loss: 3.591589236623379
Validation loss: 2.655451661020342

Epoch: 6| Step: 7
Training loss: 2.667336876412139
Validation loss: 2.65630858210146

Epoch: 6| Step: 8
Training loss: 2.9743748432759762
Validation loss: 2.65378550424635

Epoch: 6| Step: 9
Training loss: 3.158995538972251
Validation loss: 2.6628912771136815

Epoch: 6| Step: 10
Training loss: 3.4719236135298304
Validation loss: 2.66432901050831

Epoch: 6| Step: 11
Training loss: 3.2830150398330527
Validation loss: 2.670610133379673

Epoch: 6| Step: 12
Training loss: 3.1998265100179832
Validation loss: 2.677378086701629

Epoch: 6| Step: 13
Training loss: 1.7841143416040455
Validation loss: 2.691130724704706

Epoch: 89| Step: 0
Training loss: 3.134605902765037
Validation loss: 2.677993389581258

Epoch: 6| Step: 1
Training loss: 2.9239952839762466
Validation loss: 2.678899912305614

Epoch: 6| Step: 2
Training loss: 3.0051662149017666
Validation loss: 2.686613511411314

Epoch: 6| Step: 3
Training loss: 3.1781301972863414
Validation loss: 2.6769082904477037

Epoch: 6| Step: 4
Training loss: 2.569011880932542
Validation loss: 2.6583568925173946

Epoch: 6| Step: 5
Training loss: 2.741448979494536
Validation loss: 2.6484611380223964

Epoch: 6| Step: 6
Training loss: 3.1451570065944834
Validation loss: 2.652490609392762

Epoch: 6| Step: 7
Training loss: 3.224244696122432
Validation loss: 2.6512671952371876

Epoch: 6| Step: 8
Training loss: 3.189491248384756
Validation loss: 2.6535072435785

Epoch: 6| Step: 9
Training loss: 2.8893888562542918
Validation loss: 2.6535304896002665

Epoch: 6| Step: 10
Training loss: 2.5069299969267127
Validation loss: 2.6537037235818275

Epoch: 6| Step: 11
Training loss: 3.3428145196314274
Validation loss: 2.6539027556726498

Epoch: 6| Step: 12
Training loss: 3.0434953774983797
Validation loss: 2.6549918933384133

Epoch: 6| Step: 13
Training loss: 2.9201168543805407
Validation loss: 2.6549524312050696

Epoch: 90| Step: 0
Training loss: 3.0751977934453314
Validation loss: 2.6539027894822613

Epoch: 6| Step: 1
Training loss: 3.3230896588839496
Validation loss: 2.6536443912938896

Epoch: 6| Step: 2
Training loss: 2.902147083627452
Validation loss: 2.6517300498446432

Epoch: 6| Step: 3
Training loss: 3.3502499159781673
Validation loss: 2.6523543579386244

Epoch: 6| Step: 4
Training loss: 2.896430541738862
Validation loss: 2.6519140575411475

Epoch: 6| Step: 5
Training loss: 2.725283872184782
Validation loss: 2.6522407845818576

Epoch: 6| Step: 6
Training loss: 2.903162474949866
Validation loss: 2.6534326831570536

Epoch: 6| Step: 7
Training loss: 3.1690303279717114
Validation loss: 2.661236130363706

Epoch: 6| Step: 8
Training loss: 2.180897694640004
Validation loss: 2.671196035306004

Epoch: 6| Step: 9
Training loss: 3.310482922501758
Validation loss: 2.683945999973068

Epoch: 6| Step: 10
Training loss: 3.1162104784452027
Validation loss: 2.6567956642651667

Epoch: 6| Step: 11
Training loss: 2.7780898925485333
Validation loss: 2.650932032367895

Epoch: 6| Step: 12
Training loss: 3.171265642235069
Validation loss: 2.6499147923477646

Epoch: 6| Step: 13
Training loss: 2.930611345223124
Validation loss: 2.650288399140993

Epoch: 91| Step: 0
Training loss: 3.3376027580758216
Validation loss: 2.648321370552813

Epoch: 6| Step: 1
Training loss: 3.093325807408791
Validation loss: 2.647897108434398

Epoch: 6| Step: 2
Training loss: 2.807618036684654
Validation loss: 2.6495718436557274

Epoch: 6| Step: 3
Training loss: 3.8354846197542733
Validation loss: 2.650620767956215

Epoch: 6| Step: 4
Training loss: 1.9023605439935043
Validation loss: 2.6477834833133778

Epoch: 6| Step: 5
Training loss: 2.706025612494922
Validation loss: 2.6451425798066035

Epoch: 6| Step: 6
Training loss: 3.348713266157679
Validation loss: 2.649335887849283

Epoch: 6| Step: 7
Training loss: 3.4087599160162427
Validation loss: 2.647165875800637

Epoch: 6| Step: 8
Training loss: 2.4049680193005982
Validation loss: 2.6519593360729576

Epoch: 6| Step: 9
Training loss: 2.1575803108341005
Validation loss: 2.6700251830605093

Epoch: 6| Step: 10
Training loss: 2.9701525135890736
Validation loss: 2.683105254245817

Epoch: 6| Step: 11
Training loss: 3.43734158237593
Validation loss: 2.7021997307278394

Epoch: 6| Step: 12
Training loss: 3.068258981986689
Validation loss: 2.699287578102413

Epoch: 6| Step: 13
Training loss: 2.866503724930687
Validation loss: 2.7140963769998927

Epoch: 92| Step: 0
Training loss: 3.1813856834150402
Validation loss: 2.7049826970380155

Epoch: 6| Step: 1
Training loss: 3.3782499701350956
Validation loss: 2.682540380884258

Epoch: 6| Step: 2
Training loss: 2.823310927745395
Validation loss: 2.6477466528833262

Epoch: 6| Step: 3
Training loss: 3.0148085047195607
Validation loss: 2.6386832913471427

Epoch: 6| Step: 4
Training loss: 3.2411665078681278
Validation loss: 2.6408024501526275

Epoch: 6| Step: 5
Training loss: 2.5250533749821584
Validation loss: 2.6451081530530853

Epoch: 6| Step: 6
Training loss: 3.265323460725081
Validation loss: 2.6466084519651756

Epoch: 6| Step: 7
Training loss: 2.6958815706429187
Validation loss: 2.6472277026909223

Epoch: 6| Step: 8
Training loss: 2.9064540996460977
Validation loss: 2.651671092020148

Epoch: 6| Step: 9
Training loss: 2.8350822062742744
Validation loss: 2.6505350410950275

Epoch: 6| Step: 10
Training loss: 3.2543043829529434
Validation loss: 2.6469054726942733

Epoch: 6| Step: 11
Training loss: 3.017003984367109
Validation loss: 2.6436118819898704

Epoch: 6| Step: 12
Training loss: 2.9246698568150054
Validation loss: 2.6438613731221072

Epoch: 6| Step: 13
Training loss: 2.941413869252665
Validation loss: 2.6397844415909004

Epoch: 93| Step: 0
Training loss: 3.1984433083232253
Validation loss: 2.640601620950179

Epoch: 6| Step: 1
Training loss: 3.339635438724776
Validation loss: 2.6400386685791095

Epoch: 6| Step: 2
Training loss: 2.6318782427896212
Validation loss: 2.6422384921934166

Epoch: 6| Step: 3
Training loss: 2.681592703305653
Validation loss: 2.647433337747637

Epoch: 6| Step: 4
Training loss: 3.0986742076399016
Validation loss: 2.647579746200519

Epoch: 6| Step: 5
Training loss: 2.9128621674342448
Validation loss: 2.6522352595234917

Epoch: 6| Step: 6
Training loss: 2.6905003145505177
Validation loss: 2.6603384144250217

Epoch: 6| Step: 7
Training loss: 3.3433532479461032
Validation loss: 2.6655927297807107

Epoch: 6| Step: 8
Training loss: 3.413745856713847
Validation loss: 2.656124929032747

Epoch: 6| Step: 9
Training loss: 3.0998467376723813
Validation loss: 2.653272108296186

Epoch: 6| Step: 10
Training loss: 3.0026903804545055
Validation loss: 2.6488162434265448

Epoch: 6| Step: 11
Training loss: 2.4902675013115316
Validation loss: 2.645709383613288

Epoch: 6| Step: 12
Training loss: 2.9099438890638423
Validation loss: 2.647014342388799

Epoch: 6| Step: 13
Training loss: 2.5047168104107107
Validation loss: 2.6467899036715474

Epoch: 94| Step: 0
Training loss: 3.13379606184946
Validation loss: 2.660755119875193

Epoch: 6| Step: 1
Training loss: 3.0211655708103784
Validation loss: 2.679445160395127

Epoch: 6| Step: 2
Training loss: 3.4386192580356143
Validation loss: 2.672978166069911

Epoch: 6| Step: 3
Training loss: 2.4871298433099365
Validation loss: 2.662659322672579

Epoch: 6| Step: 4
Training loss: 2.676427253650974
Validation loss: 2.6613127012359112

Epoch: 6| Step: 5
Training loss: 2.8530690850986598
Validation loss: 2.6587975645750195

Epoch: 6| Step: 6
Training loss: 3.2343832559526273
Validation loss: 2.654410679098886

Epoch: 6| Step: 7
Training loss: 3.230615762412129
Validation loss: 2.652007235467411

Epoch: 6| Step: 8
Training loss: 2.611877064152961
Validation loss: 2.6521174162578194

Epoch: 6| Step: 9
Training loss: 3.350619523567459
Validation loss: 2.639049672005293

Epoch: 6| Step: 10
Training loss: 2.489259728078902
Validation loss: 2.633267218508916

Epoch: 6| Step: 11
Training loss: 2.6417240361222674
Validation loss: 2.633764673729432

Epoch: 6| Step: 12
Training loss: 2.9912208210741054
Validation loss: 2.6367293751030445

Epoch: 6| Step: 13
Training loss: 3.561641790517053
Validation loss: 2.6343688113849164

Epoch: 95| Step: 0
Training loss: 3.3341152386718207
Validation loss: 2.633778274662904

Epoch: 6| Step: 1
Training loss: 2.892710000791929
Validation loss: 2.629058213775513

Epoch: 6| Step: 2
Training loss: 3.341945838840913
Validation loss: 2.636321946415378

Epoch: 6| Step: 3
Training loss: 2.8596346377702946
Validation loss: 2.63676685819563

Epoch: 6| Step: 4
Training loss: 3.126986215715369
Validation loss: 2.6364103369476344

Epoch: 6| Step: 5
Training loss: 2.889255508569436
Validation loss: 2.6318830060006086

Epoch: 6| Step: 6
Training loss: 2.7800635046532274
Validation loss: 2.6275730433463838

Epoch: 6| Step: 7
Training loss: 3.452235733072361
Validation loss: 2.6303791748887138

Epoch: 6| Step: 8
Training loss: 3.157459291752967
Validation loss: 2.6535874188378274

Epoch: 6| Step: 9
Training loss: 2.596037717542274
Validation loss: 2.6812754398378895

Epoch: 6| Step: 10
Training loss: 2.1617029871226325
Validation loss: 2.6958146240900787

Epoch: 6| Step: 11
Training loss: 2.7810536861786246
Validation loss: 2.7224142680574976

Epoch: 6| Step: 12
Training loss: 3.1952095294953553
Validation loss: 2.7028452192416474

Epoch: 6| Step: 13
Training loss: 2.962263067243222
Validation loss: 2.7003893875669838

Epoch: 96| Step: 0
Training loss: 3.3254640355807363
Validation loss: 2.7195181133439887

Epoch: 6| Step: 1
Training loss: 3.1097566763331397
Validation loss: 2.7073436061376985

Epoch: 6| Step: 2
Training loss: 3.3374828895387414
Validation loss: 2.681773985190075

Epoch: 6| Step: 3
Training loss: 2.352154527323865
Validation loss: 2.6456894157580653

Epoch: 6| Step: 4
Training loss: 2.9652576986839594
Validation loss: 2.6315307359861366

Epoch: 6| Step: 5
Training loss: 3.128038531317311
Validation loss: 2.6270630518544387

Epoch: 6| Step: 6
Training loss: 3.530053130012069
Validation loss: 2.6296916898147216

Epoch: 6| Step: 7
Training loss: 2.728618382325969
Validation loss: 2.629375482259918

Epoch: 6| Step: 8
Training loss: 2.378923488109753
Validation loss: 2.625478260480752

Epoch: 6| Step: 9
Training loss: 3.0438591532159793
Validation loss: 2.625407234710826

Epoch: 6| Step: 10
Training loss: 3.3120917302572814
Validation loss: 2.6259918634067922

Epoch: 6| Step: 11
Training loss: 2.570598551593023
Validation loss: 2.6257271899624213

Epoch: 6| Step: 12
Training loss: 2.4858078573338616
Validation loss: 2.625122955185014

Epoch: 6| Step: 13
Training loss: 3.3021813667899593
Validation loss: 2.62682143195117

Epoch: 97| Step: 0
Training loss: 3.420897879942147
Validation loss: 2.639622308062439

Epoch: 6| Step: 1
Training loss: 3.509678673449913
Validation loss: 2.6476863660210586

Epoch: 6| Step: 2
Training loss: 2.531414262127775
Validation loss: 2.642382875524212

Epoch: 6| Step: 3
Training loss: 2.9824698393736417
Validation loss: 2.645181996391784

Epoch: 6| Step: 4
Training loss: 2.987896344696447
Validation loss: 2.6497713554158326

Epoch: 6| Step: 5
Training loss: 2.726702230201358
Validation loss: 2.6657081212406806

Epoch: 6| Step: 6
Training loss: 2.8363931253096264
Validation loss: 2.641022634472732

Epoch: 6| Step: 7
Training loss: 2.9759054585175697
Validation loss: 2.632600824174543

Epoch: 6| Step: 8
Training loss: 2.9254057252330936
Validation loss: 2.6327360574253076

Epoch: 6| Step: 9
Training loss: 3.36622156153132
Validation loss: 2.6245938224646634

Epoch: 6| Step: 10
Training loss: 1.9844574197788996
Validation loss: 2.623639538924996

Epoch: 6| Step: 11
Training loss: 2.9110781035198077
Validation loss: 2.6251927074086128

Epoch: 6| Step: 12
Training loss: 2.5849475636873063
Validation loss: 2.624506634954597

Epoch: 6| Step: 13
Training loss: 3.879746514131563
Validation loss: 2.6271349286719277

Epoch: 98| Step: 0
Training loss: 3.2548892584507128
Validation loss: 2.629776442791239

Epoch: 6| Step: 1
Training loss: 2.6128456653633987
Validation loss: 2.629694150417218

Epoch: 6| Step: 2
Training loss: 2.9865653902434808
Validation loss: 2.6294928637687756

Epoch: 6| Step: 3
Training loss: 3.001443833364014
Validation loss: 2.6233298589064726

Epoch: 6| Step: 4
Training loss: 3.7194161980407685
Validation loss: 2.623704417695026

Epoch: 6| Step: 5
Training loss: 2.1938837907210855
Validation loss: 2.6250394494939804

Epoch: 6| Step: 6
Training loss: 2.6888706349400433
Validation loss: 2.6232897807329727

Epoch: 6| Step: 7
Training loss: 2.5600049036694292
Validation loss: 2.6372876422638236

Epoch: 6| Step: 8
Training loss: 3.124162790684921
Validation loss: 2.6451316609112547

Epoch: 6| Step: 9
Training loss: 3.3968555495504544
Validation loss: 2.6690801080634823

Epoch: 6| Step: 10
Training loss: 2.548094849322729
Validation loss: 2.6838472043075723

Epoch: 6| Step: 11
Training loss: 3.103394551013102
Validation loss: 2.692227391783442

Epoch: 6| Step: 12
Training loss: 3.4042124122213604
Validation loss: 2.665116425434322

Epoch: 6| Step: 13
Training loss: 2.764307861478791
Validation loss: 2.6222951384798256

Epoch: 99| Step: 0
Training loss: 2.5900795945710584
Validation loss: 2.6213740098469267

Epoch: 6| Step: 1
Training loss: 3.173113501277915
Validation loss: 2.628850387547518

Epoch: 6| Step: 2
Training loss: 3.7088547815037467
Validation loss: 2.6450464811253034

Epoch: 6| Step: 3
Training loss: 2.663422001336279
Validation loss: 2.651970978943803

Epoch: 6| Step: 4
Training loss: 2.011113284948777
Validation loss: 2.6574641300675785

Epoch: 6| Step: 5
Training loss: 3.3959120914866845
Validation loss: 2.655434841324748

Epoch: 6| Step: 6
Training loss: 3.1796125173514533
Validation loss: 2.6467847595123426

Epoch: 6| Step: 7
Training loss: 2.7629510053942736
Validation loss: 2.6409384938282834

Epoch: 6| Step: 8
Training loss: 2.8143094494035217
Validation loss: 2.632090624919066

Epoch: 6| Step: 9
Training loss: 2.218743015332041
Validation loss: 2.626844452507345

Epoch: 6| Step: 10
Training loss: 3.2655344681305736
Validation loss: 2.624921826840797

Epoch: 6| Step: 11
Training loss: 3.1140405358412253
Validation loss: 2.6244480052711157

Epoch: 6| Step: 12
Training loss: 3.629495398388573
Validation loss: 2.634925109346354

Epoch: 6| Step: 13
Training loss: 2.7604547653927938
Validation loss: 2.641979493665308

Epoch: 100| Step: 0
Training loss: 2.7437637015936898
Validation loss: 2.6519372972274637

Epoch: 6| Step: 1
Training loss: 3.068038913982344
Validation loss: 2.6785838038075145

Epoch: 6| Step: 2
Training loss: 3.447554431953076
Validation loss: 2.7084340795390123

Epoch: 6| Step: 3
Training loss: 2.7792104036091434
Validation loss: 2.6812235828164077

Epoch: 6| Step: 4
Training loss: 2.8795663809181855
Validation loss: 2.6906043512669364

Epoch: 6| Step: 5
Training loss: 2.9991819537946967
Validation loss: 2.683665400463238

Epoch: 6| Step: 6
Training loss: 3.1152614676035855
Validation loss: 2.679875143194897

Epoch: 6| Step: 7
Training loss: 2.859876411542015
Validation loss: 2.645416543456601

Epoch: 6| Step: 8
Training loss: 2.7780666349478462
Validation loss: 2.632845047597753

Epoch: 6| Step: 9
Training loss: 3.4094707416129912
Validation loss: 2.6224115386732763

Epoch: 6| Step: 10
Training loss: 3.109655319689851
Validation loss: 2.620865030571597

Epoch: 6| Step: 11
Training loss: 2.554742188407855
Validation loss: 2.620134151724981

Epoch: 6| Step: 12
Training loss: 2.6711756811661265
Validation loss: 2.6186213501369857

Epoch: 6| Step: 13
Training loss: 3.412964249216605
Validation loss: 2.6215256621406957

Epoch: 101| Step: 0
Training loss: 3.023187040457768
Validation loss: 2.619991703812497

Epoch: 6| Step: 1
Training loss: 2.7291591925676424
Validation loss: 2.621631643962309

Epoch: 6| Step: 2
Training loss: 2.792062892598952
Validation loss: 2.620734467612599

Epoch: 6| Step: 3
Training loss: 2.6286893984728965
Validation loss: 2.625796450662929

Epoch: 6| Step: 4
Training loss: 3.0779550573229466
Validation loss: 2.624619670764499

Epoch: 6| Step: 5
Training loss: 2.5176358922896336
Validation loss: 2.619135781844397

Epoch: 6| Step: 6
Training loss: 2.8072543923210036
Validation loss: 2.619262577952549

Epoch: 6| Step: 7
Training loss: 3.0063917098876605
Validation loss: 2.6179744051118625

Epoch: 6| Step: 8
Training loss: 2.6472460562117957
Validation loss: 2.626245264816133

Epoch: 6| Step: 9
Training loss: 2.3313600734056754
Validation loss: 2.640486348849281

Epoch: 6| Step: 10
Training loss: 3.0417490560442833
Validation loss: 2.6587594355600275

Epoch: 6| Step: 11
Training loss: 4.058991545787502
Validation loss: 2.675143275364287

Epoch: 6| Step: 12
Training loss: 3.3194748483823413
Validation loss: 2.712214942812205

Epoch: 6| Step: 13
Training loss: 3.421452047607084
Validation loss: 2.695482206062372

Epoch: 102| Step: 0
Training loss: 2.3664143624832574
Validation loss: 2.657322831388236

Epoch: 6| Step: 1
Training loss: 3.099209986280778
Validation loss: 2.62324783290493

Epoch: 6| Step: 2
Training loss: 3.44901469438165
Validation loss: 2.612484100532067

Epoch: 6| Step: 3
Training loss: 2.745491406728968
Validation loss: 2.61343383098376

Epoch: 6| Step: 4
Training loss: 3.026347807446418
Validation loss: 2.6211251833620137

Epoch: 6| Step: 5
Training loss: 3.276731740849296
Validation loss: 2.625739126845767

Epoch: 6| Step: 6
Training loss: 2.359959713058577
Validation loss: 2.6233369175504078

Epoch: 6| Step: 7
Training loss: 3.096167958496709
Validation loss: 2.6214518154777506

Epoch: 6| Step: 8
Training loss: 2.9323949078577196
Validation loss: 2.6200797294212275

Epoch: 6| Step: 9
Training loss: 3.1572764021352295
Validation loss: 2.620250895450579

Epoch: 6| Step: 10
Training loss: 2.524844317782886
Validation loss: 2.6192393742851263

Epoch: 6| Step: 11
Training loss: 2.4224029949910486
Validation loss: 2.619025802215132

Epoch: 6| Step: 12
Training loss: 3.5860010611026722
Validation loss: 2.6179397924583765

Epoch: 6| Step: 13
Training loss: 3.343047736746518
Validation loss: 2.6192154118562803

Epoch: 103| Step: 0
Training loss: 3.107420647391335
Validation loss: 2.618454174002772

Epoch: 6| Step: 1
Training loss: 3.138786878775546
Validation loss: 2.6159215925122816

Epoch: 6| Step: 2
Training loss: 3.065594724919792
Validation loss: 2.615436986401797

Epoch: 6| Step: 3
Training loss: 3.1105094642023015
Validation loss: 2.6184954677628727

Epoch: 6| Step: 4
Training loss: 2.4748594764350935
Validation loss: 2.613437630189559

Epoch: 6| Step: 5
Training loss: 2.806682334170554
Validation loss: 2.615565664335547

Epoch: 6| Step: 6
Training loss: 3.3299176040398994
Validation loss: 2.6138627541930064

Epoch: 6| Step: 7
Training loss: 2.881117738679435
Validation loss: 2.6123903941494415

Epoch: 6| Step: 8
Training loss: 2.391356412411253
Validation loss: 2.617445531500244

Epoch: 6| Step: 9
Training loss: 3.00931153037382
Validation loss: 2.625137096014626

Epoch: 6| Step: 10
Training loss: 2.254130069719984
Validation loss: 2.6228765384824957

Epoch: 6| Step: 11
Training loss: 3.040726468470107
Validation loss: 2.6315319469180602

Epoch: 6| Step: 12
Training loss: 3.446032805629271
Validation loss: 2.6490576843111806

Epoch: 6| Step: 13
Training loss: 3.390232186482111
Validation loss: 2.6492075631685643

Epoch: 104| Step: 0
Training loss: 3.3076101234885447
Validation loss: 2.6459054979852654

Epoch: 6| Step: 1
Training loss: 3.0453844385863964
Validation loss: 2.6350149331365618

Epoch: 6| Step: 2
Training loss: 2.5212978113773086
Validation loss: 2.627994208674576

Epoch: 6| Step: 3
Training loss: 2.5624590614584246
Validation loss: 2.634614990733059

Epoch: 6| Step: 4
Training loss: 2.8241511293285706
Validation loss: 2.643850004345529

Epoch: 6| Step: 5
Training loss: 3.1152389669832927
Validation loss: 2.6448176889818273

Epoch: 6| Step: 6
Training loss: 2.405757308655512
Validation loss: 2.639255204076758

Epoch: 6| Step: 7
Training loss: 3.1038010827852713
Validation loss: 2.627765164016979

Epoch: 6| Step: 8
Training loss: 3.2666320708123178
Validation loss: 2.6201835937225417

Epoch: 6| Step: 9
Training loss: 2.498774323414231
Validation loss: 2.6094667250199426

Epoch: 6| Step: 10
Training loss: 3.08187297226068
Validation loss: 2.60847720904204

Epoch: 6| Step: 11
Training loss: 2.8158759306972456
Validation loss: 2.606463913848918

Epoch: 6| Step: 12
Training loss: 3.5806902223260977
Validation loss: 2.6052012859652836

Epoch: 6| Step: 13
Training loss: 3.160522137975203
Validation loss: 2.6047535316659376

Epoch: 105| Step: 0
Training loss: 2.5298585246037963
Validation loss: 2.6067473004710147

Epoch: 6| Step: 1
Training loss: 3.8894311996045796
Validation loss: 2.6064992877166744

Epoch: 6| Step: 2
Training loss: 2.3547208240684836
Validation loss: 2.6088110073736073

Epoch: 6| Step: 3
Training loss: 2.487411466777001
Validation loss: 2.60640743662729

Epoch: 6| Step: 4
Training loss: 3.1531066349579766
Validation loss: 2.6094665756892828

Epoch: 6| Step: 5
Training loss: 2.801271276022966
Validation loss: 2.6085726127125253

Epoch: 6| Step: 6
Training loss: 2.7860599030943987
Validation loss: 2.609262197865081

Epoch: 6| Step: 7
Training loss: 3.5377909079051917
Validation loss: 2.6082723575895135

Epoch: 6| Step: 8
Training loss: 2.571155166472005
Validation loss: 2.613343527346868

Epoch: 6| Step: 9
Training loss: 2.8761486578391158
Validation loss: 2.61653346443822

Epoch: 6| Step: 10
Training loss: 2.4261484160031532
Validation loss: 2.6186562083194858

Epoch: 6| Step: 11
Training loss: 3.1360078340938573
Validation loss: 2.631565298472502

Epoch: 6| Step: 12
Training loss: 2.9607886928718656
Validation loss: 2.6261386989612583

Epoch: 6| Step: 13
Training loss: 3.707997910549394
Validation loss: 2.622929643870612

Epoch: 106| Step: 0
Training loss: 2.8642077020527066
Validation loss: 2.6207248546804074

Epoch: 6| Step: 1
Training loss: 3.3599214331205967
Validation loss: 2.6197822600151994

Epoch: 6| Step: 2
Training loss: 3.2593282196988977
Validation loss: 2.611710827603147

Epoch: 6| Step: 3
Training loss: 2.5245906686894
Validation loss: 2.6115069444583314

Epoch: 6| Step: 4
Training loss: 2.8035203635760513
Validation loss: 2.6017395686515132

Epoch: 6| Step: 5
Training loss: 2.662058146173445
Validation loss: 2.6047204558861554

Epoch: 6| Step: 6
Training loss: 2.4381506613852895
Validation loss: 2.604425474698862

Epoch: 6| Step: 7
Training loss: 2.838039155395604
Validation loss: 2.6044832046261415

Epoch: 6| Step: 8
Training loss: 3.8908587159580064
Validation loss: 2.602713241740428

Epoch: 6| Step: 9
Training loss: 2.577136873405042
Validation loss: 2.5998727640330426

Epoch: 6| Step: 10
Training loss: 3.312913401016803
Validation loss: 2.5996004186450246

Epoch: 6| Step: 11
Training loss: 3.205519660324143
Validation loss: 2.5993839390304454

Epoch: 6| Step: 12
Training loss: 2.7853605775932664
Validation loss: 2.597690144053373

Epoch: 6| Step: 13
Training loss: 1.9795874566600167
Validation loss: 2.60246090322856

Epoch: 107| Step: 0
Training loss: 2.2089884763860024
Validation loss: 2.6068380843661174

Epoch: 6| Step: 1
Training loss: 3.104313089557109
Validation loss: 2.6034211152668547

Epoch: 6| Step: 2
Training loss: 3.5013182745980376
Validation loss: 2.6171276239345453

Epoch: 6| Step: 3
Training loss: 2.8873579378397225
Validation loss: 2.6343560231666476

Epoch: 6| Step: 4
Training loss: 2.993790876710757
Validation loss: 2.633706851700804

Epoch: 6| Step: 5
Training loss: 3.204172251629933
Validation loss: 2.619568110763645

Epoch: 6| Step: 6
Training loss: 2.673420598452108
Validation loss: 2.6099986563517894

Epoch: 6| Step: 7
Training loss: 3.161160416787491
Validation loss: 2.6133925327797476

Epoch: 6| Step: 8
Training loss: 3.0467857934657383
Validation loss: 2.608937345235578

Epoch: 6| Step: 9
Training loss: 3.095700352423837
Validation loss: 2.603883077295482

Epoch: 6| Step: 10
Training loss: 2.5997999481118996
Validation loss: 2.603396123940023

Epoch: 6| Step: 11
Training loss: 2.7555042148835422
Validation loss: 2.5994271048321598

Epoch: 6| Step: 12
Training loss: 2.697453364551585
Validation loss: 2.5978602589934527

Epoch: 6| Step: 13
Training loss: 3.2126393506889652
Validation loss: 2.598164570958363

Epoch: 108| Step: 0
Training loss: 2.300968596468364
Validation loss: 2.596306601517446

Epoch: 6| Step: 1
Training loss: 3.138512199627313
Validation loss: 2.597840359535339

Epoch: 6| Step: 2
Training loss: 2.8176935351835786
Validation loss: 2.5976615259902007

Epoch: 6| Step: 3
Training loss: 2.626218059042344
Validation loss: 2.600031215726445

Epoch: 6| Step: 4
Training loss: 3.3351749736861693
Validation loss: 2.6029938033316284

Epoch: 6| Step: 5
Training loss: 2.375014857195511
Validation loss: 2.6024692192880403

Epoch: 6| Step: 6
Training loss: 2.9896385551075477
Validation loss: 2.6012663722752127

Epoch: 6| Step: 7
Training loss: 2.8136612084443535
Validation loss: 2.59737312796541

Epoch: 6| Step: 8
Training loss: 2.9635116137616033
Validation loss: 2.5987414434502902

Epoch: 6| Step: 9
Training loss: 3.0016316109544254
Validation loss: 2.595466076714385

Epoch: 6| Step: 10
Training loss: 3.572036694114998
Validation loss: 2.59455372544339

Epoch: 6| Step: 11
Training loss: 2.997603730991099
Validation loss: 2.596304958452884

Epoch: 6| Step: 12
Training loss: 2.7243286425712987
Validation loss: 2.5921978655952063

Epoch: 6| Step: 13
Training loss: 3.4941645067570533
Validation loss: 2.5978333855607363

Epoch: 109| Step: 0
Training loss: 3.0240897330236263
Validation loss: 2.59830423434066

Epoch: 6| Step: 1
Training loss: 2.4262042329491695
Validation loss: 2.5987716536409544

Epoch: 6| Step: 2
Training loss: 2.156410985272136
Validation loss: 2.607532196580777

Epoch: 6| Step: 3
Training loss: 2.714827942287611
Validation loss: 2.6148491409616637

Epoch: 6| Step: 4
Training loss: 2.5673326652101363
Validation loss: 2.6117929641649833

Epoch: 6| Step: 5
Training loss: 3.157672523744651
Validation loss: 2.6318677334987317

Epoch: 6| Step: 6
Training loss: 3.2051008875734204
Validation loss: 2.6595000948738616

Epoch: 6| Step: 7
Training loss: 2.787665436629433
Validation loss: 2.672994428439329

Epoch: 6| Step: 8
Training loss: 2.882168002566736
Validation loss: 2.680968645018614

Epoch: 6| Step: 9
Training loss: 3.166249515429496
Validation loss: 2.625975363650222

Epoch: 6| Step: 10
Training loss: 3.5884094361561
Validation loss: 2.598559833580308

Epoch: 6| Step: 11
Training loss: 3.4516029283013134
Validation loss: 2.595579701638541

Epoch: 6| Step: 12
Training loss: 2.7839785275398548
Validation loss: 2.6017258435865487

Epoch: 6| Step: 13
Training loss: 3.208495462127563
Validation loss: 2.600936406837924

Epoch: 110| Step: 0
Training loss: 2.483376740283215
Validation loss: 2.606468717602102

Epoch: 6| Step: 1
Training loss: 2.9803655564028517
Validation loss: 2.6072732547923088

Epoch: 6| Step: 2
Training loss: 3.2870784764869088
Validation loss: 2.610182487562007

Epoch: 6| Step: 3
Training loss: 2.599858456206716
Validation loss: 2.607944176554039

Epoch: 6| Step: 4
Training loss: 2.6910001451144256
Validation loss: 2.607020783370409

Epoch: 6| Step: 5
Training loss: 3.510113681354248
Validation loss: 2.606231418922187

Epoch: 6| Step: 6
Training loss: 3.6523269081747385
Validation loss: 2.6101261428579874

Epoch: 6| Step: 7
Training loss: 3.015889842999074
Validation loss: 2.608961710610422

Epoch: 6| Step: 8
Training loss: 3.047648326840989
Validation loss: 2.6083094947803076

Epoch: 6| Step: 9
Training loss: 2.3949103747583123
Validation loss: 2.6008661169496237

Epoch: 6| Step: 10
Training loss: 2.9162205127806433
Validation loss: 2.6050045586761574

Epoch: 6| Step: 11
Training loss: 2.5226823840259893
Validation loss: 2.6047185484502307

Epoch: 6| Step: 12
Training loss: 3.223635918801518
Validation loss: 2.614888256336936

Epoch: 6| Step: 13
Training loss: 2.7756901578721904
Validation loss: 2.612676453532659

Epoch: 111| Step: 0
Training loss: 2.7193122370111156
Validation loss: 2.6457942145526205

Epoch: 6| Step: 1
Training loss: 3.022107682052204
Validation loss: 2.6326349134690696

Epoch: 6| Step: 2
Training loss: 2.99037294670959
Validation loss: 2.618731020757503

Epoch: 6| Step: 3
Training loss: 3.1636507496362216
Validation loss: 2.6235028102479174

Epoch: 6| Step: 4
Training loss: 2.1941379649652295
Validation loss: 2.6297724556469415

Epoch: 6| Step: 5
Training loss: 2.851272191986056
Validation loss: 2.6323394637689064

Epoch: 6| Step: 6
Training loss: 3.376281212525077
Validation loss: 2.6322372497969293

Epoch: 6| Step: 7
Training loss: 3.089478906438767
Validation loss: 2.6381956982587202

Epoch: 6| Step: 8
Training loss: 3.0991410572880915
Validation loss: 2.6469624553146187

Epoch: 6| Step: 9
Training loss: 2.5575357127749245
Validation loss: 2.659990852527432

Epoch: 6| Step: 10
Training loss: 3.2907465521958046
Validation loss: 2.6874670039538784

Epoch: 6| Step: 11
Training loss: 3.173482403045425
Validation loss: 2.685264111381501

Epoch: 6| Step: 12
Training loss: 3.115088958694608
Validation loss: 2.666618383903653

Epoch: 6| Step: 13
Training loss: 2.0420579211009424
Validation loss: 2.6111367457916286

Epoch: 112| Step: 0
Training loss: 2.9994317152285443
Validation loss: 2.5962566603820636

Epoch: 6| Step: 1
Training loss: 2.387430487614439
Validation loss: 2.589380202041138

Epoch: 6| Step: 2
Training loss: 2.2510225303739135
Validation loss: 2.591131982237106

Epoch: 6| Step: 3
Training loss: 2.4836417981612176
Validation loss: 2.5884904856184066

Epoch: 6| Step: 4
Training loss: 3.38471913512144
Validation loss: 2.5906634804339133

Epoch: 6| Step: 5
Training loss: 2.872954594668587
Validation loss: 2.59144353831619

Epoch: 6| Step: 6
Training loss: 2.8389725011103133
Validation loss: 2.592362272936396

Epoch: 6| Step: 7
Training loss: 2.741552730461584
Validation loss: 2.593624283429491

Epoch: 6| Step: 8
Training loss: 2.855873006235848
Validation loss: 2.59324896557237

Epoch: 6| Step: 9
Training loss: 3.486889671599774
Validation loss: 2.591206536664372

Epoch: 6| Step: 10
Training loss: 3.2065917072800625
Validation loss: 2.590398430572244

Epoch: 6| Step: 11
Training loss: 3.180551772321277
Validation loss: 2.5895324954552468

Epoch: 6| Step: 12
Training loss: 3.2669026918844994
Validation loss: 2.5853685878989854

Epoch: 6| Step: 13
Training loss: 3.1598072212905985
Validation loss: 2.591895883684457

Epoch: 113| Step: 0
Training loss: 3.0670036365747424
Validation loss: 2.5979184792056036

Epoch: 6| Step: 1
Training loss: 3.1281008785205717
Validation loss: 2.611074749633706

Epoch: 6| Step: 2
Training loss: 2.6860767410518225
Validation loss: 2.6262820033894063

Epoch: 6| Step: 3
Training loss: 2.0077224889387306
Validation loss: 2.635376551809719

Epoch: 6| Step: 4
Training loss: 3.0006485873699464
Validation loss: 2.646040080813895

Epoch: 6| Step: 5
Training loss: 3.028797061694655
Validation loss: 2.6435117932449868

Epoch: 6| Step: 6
Training loss: 2.833463404044694
Validation loss: 2.647068344582058

Epoch: 6| Step: 7
Training loss: 3.3961628635026577
Validation loss: 2.6616418209864863

Epoch: 6| Step: 8
Training loss: 3.3611851273330777
Validation loss: 2.6531566600639445

Epoch: 6| Step: 9
Training loss: 2.7465159280239764
Validation loss: 2.63496513605311

Epoch: 6| Step: 10
Training loss: 3.2078744799632073
Validation loss: 2.6249762757181947

Epoch: 6| Step: 11
Training loss: 2.8975939075698713
Validation loss: 2.609592113583417

Epoch: 6| Step: 12
Training loss: 2.658159355122744
Validation loss: 2.5917893239217076

Epoch: 6| Step: 13
Training loss: 2.878335759070397
Validation loss: 2.597873131142941

Epoch: 114| Step: 0
Training loss: 3.2212656800995334
Validation loss: 2.594399100293261

Epoch: 6| Step: 1
Training loss: 3.0231767882082634
Validation loss: 2.5926684721604807

Epoch: 6| Step: 2
Training loss: 3.323752526335744
Validation loss: 2.5906348510508974

Epoch: 6| Step: 3
Training loss: 1.9951318860737925
Validation loss: 2.5858576621342126

Epoch: 6| Step: 4
Training loss: 3.2566173382878607
Validation loss: 2.582708758280385

Epoch: 6| Step: 5
Training loss: 3.468766221017112
Validation loss: 2.5845599856282444

Epoch: 6| Step: 6
Training loss: 2.9172352554507035
Validation loss: 2.586268152874754

Epoch: 6| Step: 7
Training loss: 3.2401939053850817
Validation loss: 2.5854287978865034

Epoch: 6| Step: 8
Training loss: 2.8008406671369204
Validation loss: 2.584710522822463

Epoch: 6| Step: 9
Training loss: 2.8032011806381036
Validation loss: 2.5846166020124413

Epoch: 6| Step: 10
Training loss: 2.9236330669320654
Validation loss: 2.5850544719225304

Epoch: 6| Step: 11
Training loss: 2.538428969941253
Validation loss: 2.5867893714469172

Epoch: 6| Step: 12
Training loss: 2.2700511973653077
Validation loss: 2.5896400934952677

Epoch: 6| Step: 13
Training loss: 3.227037445654943
Validation loss: 2.591388215697813

Epoch: 115| Step: 0
Training loss: 2.9380151824455014
Validation loss: 2.595320480040147

Epoch: 6| Step: 1
Training loss: 2.650571250523472
Validation loss: 2.601381568981685

Epoch: 6| Step: 2
Training loss: 3.1377287458341714
Validation loss: 2.611055456534339

Epoch: 6| Step: 3
Training loss: 3.291481270377681
Validation loss: 2.605375517477581

Epoch: 6| Step: 4
Training loss: 2.585285577107054
Validation loss: 2.607420267452801

Epoch: 6| Step: 5
Training loss: 3.2976403093890365
Validation loss: 2.6062590025165493

Epoch: 6| Step: 6
Training loss: 2.925261630885494
Validation loss: 2.6162973030241217

Epoch: 6| Step: 7
Training loss: 3.570891552468681
Validation loss: 2.6121208613704847

Epoch: 6| Step: 8
Training loss: 2.372795487263376
Validation loss: 2.6193480442121047

Epoch: 6| Step: 9
Training loss: 2.9071194568467518
Validation loss: 2.613206735760748

Epoch: 6| Step: 10
Training loss: 2.310129239153736
Validation loss: 2.613582441242344

Epoch: 6| Step: 11
Training loss: 3.0136794697733205
Validation loss: 2.6198034420583425

Epoch: 6| Step: 12
Training loss: 2.840502047422021
Validation loss: 2.6210018919620217

Epoch: 6| Step: 13
Training loss: 2.8405119517779465
Validation loss: 2.614773683115273

Epoch: 116| Step: 0
Training loss: 2.8860556288636414
Validation loss: 2.6041672990039344

Epoch: 6| Step: 1
Training loss: 2.7169867750175225
Validation loss: 2.591654248486974

Epoch: 6| Step: 2
Training loss: 2.938936409889556
Validation loss: 2.582273660574915

Epoch: 6| Step: 3
Training loss: 2.7098511379783283
Validation loss: 2.5800054340475436

Epoch: 6| Step: 4
Training loss: 2.7447636776003184
Validation loss: 2.5749657777685924

Epoch: 6| Step: 5
Training loss: 2.7509451889074503
Validation loss: 2.57746438530455

Epoch: 6| Step: 6
Training loss: 2.6312122405688663
Validation loss: 2.579527166419046

Epoch: 6| Step: 7
Training loss: 3.248294823152245
Validation loss: 2.582081653925291

Epoch: 6| Step: 8
Training loss: 3.1182097859648747
Validation loss: 2.5855118011055462

Epoch: 6| Step: 9
Training loss: 3.5304956221143446
Validation loss: 2.5878740844074137

Epoch: 6| Step: 10
Training loss: 3.0193499551412266
Validation loss: 2.5893868562229216

Epoch: 6| Step: 11
Training loss: 3.2918031559584673
Validation loss: 2.5927699748466995

Epoch: 6| Step: 12
Training loss: 2.5824118375547065
Validation loss: 2.5960679167330443

Epoch: 6| Step: 13
Training loss: 2.395457152535818
Validation loss: 2.6034846752077323

Epoch: 117| Step: 0
Training loss: 3.5871938860614
Validation loss: 2.6069410611351804

Epoch: 6| Step: 1
Training loss: 2.826042799780103
Validation loss: 2.604103976243701

Epoch: 6| Step: 2
Training loss: 2.99917209645598
Validation loss: 2.605682186702384

Epoch: 6| Step: 3
Training loss: 2.569622005020922
Validation loss: 2.6000104612498127

Epoch: 6| Step: 4
Training loss: 2.759702040580324
Validation loss: 2.5981168994953268

Epoch: 6| Step: 5
Training loss: 3.5658730048706495
Validation loss: 2.5980363731620937

Epoch: 6| Step: 6
Training loss: 2.541743814100098
Validation loss: 2.600465422441655

Epoch: 6| Step: 7
Training loss: 3.06584311981865
Validation loss: 2.5962223792954138

Epoch: 6| Step: 8
Training loss: 2.445382601674633
Validation loss: 2.598991067499242

Epoch: 6| Step: 9
Training loss: 3.0666404294536345
Validation loss: 2.5929568298985535

Epoch: 6| Step: 10
Training loss: 3.0800141864301276
Validation loss: 2.5885418878515876

Epoch: 6| Step: 11
Training loss: 2.283685090009573
Validation loss: 2.589178712130074

Epoch: 6| Step: 12
Training loss: 3.0319703809353316
Validation loss: 2.593892452965155

Epoch: 6| Step: 13
Training loss: 2.645292952815128
Validation loss: 2.5993688414820504

Epoch: 118| Step: 0
Training loss: 2.7859780060994686
Validation loss: 2.5973780422977066

Epoch: 6| Step: 1
Training loss: 2.0812024726825125
Validation loss: 2.6016798435461967

Epoch: 6| Step: 2
Training loss: 3.2605466644078644
Validation loss: 2.6145034645143634

Epoch: 6| Step: 3
Training loss: 2.714264425036469
Validation loss: 2.626889163808166

Epoch: 6| Step: 4
Training loss: 2.810779469125968
Validation loss: 2.6314332653420216

Epoch: 6| Step: 5
Training loss: 2.8956123834932486
Validation loss: 2.625868669685697

Epoch: 6| Step: 6
Training loss: 3.1432293015137365
Validation loss: 2.6225524621597573

Epoch: 6| Step: 7
Training loss: 2.174397382892384
Validation loss: 2.6038631953134184

Epoch: 6| Step: 8
Training loss: 3.241538844657102
Validation loss: 2.5937634549395483

Epoch: 6| Step: 9
Training loss: 3.244613879350549
Validation loss: 2.590342666003988

Epoch: 6| Step: 10
Training loss: 3.1249766539655286
Validation loss: 2.5739638889413956

Epoch: 6| Step: 11
Training loss: 2.6327299110748084
Validation loss: 2.56979995366333

Epoch: 6| Step: 12
Training loss: 3.2835043293015453
Validation loss: 2.5672395810754365

Epoch: 6| Step: 13
Training loss: 3.4084981796082956
Validation loss: 2.5709734805907143

Epoch: 119| Step: 0
Training loss: 2.3587706341267998
Validation loss: 2.5714284388924167

Epoch: 6| Step: 1
Training loss: 2.9542418290562975
Validation loss: 2.5688309675920804

Epoch: 6| Step: 2
Training loss: 2.5633863451386643
Validation loss: 2.5686527492173123

Epoch: 6| Step: 3
Training loss: 3.345706545532402
Validation loss: 2.5660713474124623

Epoch: 6| Step: 4
Training loss: 2.958796791702641
Validation loss: 2.5748819536995016

Epoch: 6| Step: 5
Training loss: 2.9629158919180556
Validation loss: 2.5706997050592015

Epoch: 6| Step: 6
Training loss: 3.2600572934411067
Validation loss: 2.5662989834733176

Epoch: 6| Step: 7
Training loss: 2.972173383396682
Validation loss: 2.5684883283999786

Epoch: 6| Step: 8
Training loss: 2.9939888494534936
Validation loss: 2.5756302064861214

Epoch: 6| Step: 9
Training loss: 3.27757056887008
Validation loss: 2.5847473846002065

Epoch: 6| Step: 10
Training loss: 3.2296483982858404
Validation loss: 2.597376115651568

Epoch: 6| Step: 11
Training loss: 2.830818032159816
Validation loss: 2.609252932727168

Epoch: 6| Step: 12
Training loss: 2.796375421841268
Validation loss: 2.6127358055941117

Epoch: 6| Step: 13
Training loss: 1.354667360712672
Validation loss: 2.6068819862418224

Epoch: 120| Step: 0
Training loss: 2.9774428139679223
Validation loss: 2.608519033220482

Epoch: 6| Step: 1
Training loss: 2.8255782489246157
Validation loss: 2.6037421776783702

Epoch: 6| Step: 2
Training loss: 3.0918672015059196
Validation loss: 2.606954719407722

Epoch: 6| Step: 3
Training loss: 3.445647415871501
Validation loss: 2.5984888297362074

Epoch: 6| Step: 4
Training loss: 3.190061848677651
Validation loss: 2.59973087937345

Epoch: 6| Step: 5
Training loss: 2.7873026106530436
Validation loss: 2.5816351468973346

Epoch: 6| Step: 6
Training loss: 3.2527149304765874
Validation loss: 2.579378615663885

Epoch: 6| Step: 7
Training loss: 2.813057907718093
Validation loss: 2.575698380743972

Epoch: 6| Step: 8
Training loss: 2.0257451511378224
Validation loss: 2.5666581299022826

Epoch: 6| Step: 9
Training loss: 2.915418375918047
Validation loss: 2.565718982291116

Epoch: 6| Step: 10
Training loss: 3.2093001225993967
Validation loss: 2.562638027696647

Epoch: 6| Step: 11
Training loss: 2.4017132683847078
Validation loss: 2.5649152688786527

Epoch: 6| Step: 12
Training loss: 2.4433213192105314
Validation loss: 2.56490477807318

Epoch: 6| Step: 13
Training loss: 3.4849546489200254
Validation loss: 2.563031529390301

Epoch: 121| Step: 0
Training loss: 2.938753063698441
Validation loss: 2.5598840744630937

Epoch: 6| Step: 1
Training loss: 2.4751870941962415
Validation loss: 2.564699545059495

Epoch: 6| Step: 2
Training loss: 2.960240103288281
Validation loss: 2.5772958336336913

Epoch: 6| Step: 3
Training loss: 2.968112274740271
Validation loss: 2.5906631360638293

Epoch: 6| Step: 4
Training loss: 2.8416961966702075
Validation loss: 2.618448401420613

Epoch: 6| Step: 5
Training loss: 2.822196014496208
Validation loss: 2.629247222779703

Epoch: 6| Step: 6
Training loss: 2.8875884731990045
Validation loss: 2.5849338268203415

Epoch: 6| Step: 7
Training loss: 3.4816363738333744
Validation loss: 2.576301466274158

Epoch: 6| Step: 8
Training loss: 3.039526269040218
Validation loss: 2.5668097090072206

Epoch: 6| Step: 9
Training loss: 3.0720284595363325
Validation loss: 2.5620600324929113

Epoch: 6| Step: 10
Training loss: 3.125967257532621
Validation loss: 2.562246734805034

Epoch: 6| Step: 11
Training loss: 3.2866497840473534
Validation loss: 2.5616843703560748

Epoch: 6| Step: 12
Training loss: 2.5113226072411288
Validation loss: 2.5634708021248644

Epoch: 6| Step: 13
Training loss: 1.6299631911492183
Validation loss: 2.5599534261476458

Epoch: 122| Step: 0
Training loss: 2.8116026400467007
Validation loss: 2.5622611666112634

Epoch: 6| Step: 1
Training loss: 3.0648248372891005
Validation loss: 2.564404942817504

Epoch: 6| Step: 2
Training loss: 2.9029473027601687
Validation loss: 2.563123039499327

Epoch: 6| Step: 3
Training loss: 2.716480140679444
Validation loss: 2.561002628485024

Epoch: 6| Step: 4
Training loss: 3.336427317624134
Validation loss: 2.5677786760896053

Epoch: 6| Step: 5
Training loss: 2.5680471716437285
Validation loss: 2.5625634364397913

Epoch: 6| Step: 6
Training loss: 2.697264387501979
Validation loss: 2.561237435350075

Epoch: 6| Step: 7
Training loss: 2.7692532635247944
Validation loss: 2.5667001421082096

Epoch: 6| Step: 8
Training loss: 2.72761895554089
Validation loss: 2.5767694175351687

Epoch: 6| Step: 9
Training loss: 2.605810414664753
Validation loss: 2.592367385403988

Epoch: 6| Step: 10
Training loss: 3.6159760854487284
Validation loss: 2.6046592666532113

Epoch: 6| Step: 11
Training loss: 3.2245623505997325
Validation loss: 2.5915426337029865

Epoch: 6| Step: 12
Training loss: 3.138991201378096
Validation loss: 2.583851349173533

Epoch: 6| Step: 13
Training loss: 1.9983922933874279
Validation loss: 2.5703079548247714

Epoch: 123| Step: 0
Training loss: 2.6781044780074006
Validation loss: 2.56990463901238

Epoch: 6| Step: 1
Training loss: 3.055635973324874
Validation loss: 2.5641805368988577

Epoch: 6| Step: 2
Training loss: 2.7588875812055083
Validation loss: 2.559937864718868

Epoch: 6| Step: 3
Training loss: 3.268439727120097
Validation loss: 2.5612415692219033

Epoch: 6| Step: 4
Training loss: 2.910402346452687
Validation loss: 2.5590680117825864

Epoch: 6| Step: 5
Training loss: 2.912096930514993
Validation loss: 2.562092572348726

Epoch: 6| Step: 6
Training loss: 3.370778587346269
Validation loss: 2.561367531002997

Epoch: 6| Step: 7
Training loss: 2.6815628296083167
Validation loss: 2.5608603911758347

Epoch: 6| Step: 8
Training loss: 2.3795470829373753
Validation loss: 2.5605997933148092

Epoch: 6| Step: 9
Training loss: 3.1445579385513396
Validation loss: 2.5622377098821247

Epoch: 6| Step: 10
Training loss: 3.423398031671449
Validation loss: 2.569590517792123

Epoch: 6| Step: 11
Training loss: 2.54670845844603
Validation loss: 2.5700750933572847

Epoch: 6| Step: 12
Training loss: 2.703095364270348
Validation loss: 2.5733618565130048

Epoch: 6| Step: 13
Training loss: 2.589700686270561
Validation loss: 2.576707691898171

Epoch: 124| Step: 0
Training loss: 2.9365635454631267
Validation loss: 2.5758054339979455

Epoch: 6| Step: 1
Training loss: 2.721024186906912
Validation loss: 2.5778657904091165

Epoch: 6| Step: 2
Training loss: 3.0707243432036293
Validation loss: 2.57505636698103

Epoch: 6| Step: 3
Training loss: 3.1232397080769974
Validation loss: 2.570739692640208

Epoch: 6| Step: 4
Training loss: 2.9348655412538505
Validation loss: 2.580800426014204

Epoch: 6| Step: 5
Training loss: 2.9493862483478424
Validation loss: 2.575074076062432

Epoch: 6| Step: 6
Training loss: 2.996670783029119
Validation loss: 2.586377240709466

Epoch: 6| Step: 7
Training loss: 2.497939977677622
Validation loss: 2.5766401771366354

Epoch: 6| Step: 8
Training loss: 3.2136898820640822
Validation loss: 2.5838218952075773

Epoch: 6| Step: 9
Training loss: 2.5055019870096253
Validation loss: 2.573430478383251

Epoch: 6| Step: 10
Training loss: 3.2330820936404865
Validation loss: 2.5818347471084637

Epoch: 6| Step: 11
Training loss: 3.026407995499716
Validation loss: 2.570057084993061

Epoch: 6| Step: 12
Training loss: 2.6601031013814573
Validation loss: 2.5724379454618695

Epoch: 6| Step: 13
Training loss: 2.6281875149325744
Validation loss: 2.5734630781862404

Epoch: 125| Step: 0
Training loss: 3.301675636963563
Validation loss: 2.5710707624871185

Epoch: 6| Step: 1
Training loss: 3.110200551916955
Validation loss: 2.5832870735951428

Epoch: 6| Step: 2
Training loss: 2.8829325829283556
Validation loss: 2.583721084815925

Epoch: 6| Step: 3
Training loss: 2.9304815004783764
Validation loss: 2.5961997784339728

Epoch: 6| Step: 4
Training loss: 2.9699470114556745
Validation loss: 2.5897838911221154

Epoch: 6| Step: 5
Training loss: 3.2196236322927816
Validation loss: 2.5891924165746394

Epoch: 6| Step: 6
Training loss: 3.0208288960040597
Validation loss: 2.57983918588913

Epoch: 6| Step: 7
Training loss: 2.9861821799483064
Validation loss: 2.5893127028604854

Epoch: 6| Step: 8
Training loss: 2.462234591205498
Validation loss: 2.5856087521546494

Epoch: 6| Step: 9
Training loss: 2.401771737826336
Validation loss: 2.583201817536587

Epoch: 6| Step: 10
Training loss: 2.968405934523487
Validation loss: 2.5903991500625203

Epoch: 6| Step: 11
Training loss: 2.8276595264767224
Validation loss: 2.574398310806425

Epoch: 6| Step: 12
Training loss: 2.8621860715144276
Validation loss: 2.5699643095189355

Epoch: 6| Step: 13
Training loss: 2.312225222372031
Validation loss: 2.572942429154043

Epoch: 126| Step: 0
Training loss: 3.0837618727623624
Validation loss: 2.5680001829799797

Epoch: 6| Step: 1
Training loss: 2.787451954927922
Validation loss: 2.566355347407552

Epoch: 6| Step: 2
Training loss: 2.9592086858048012
Validation loss: 2.5667437097434065

Epoch: 6| Step: 3
Training loss: 2.8796725243247843
Validation loss: 2.5637919392854287

Epoch: 6| Step: 4
Training loss: 2.0935955844702856
Validation loss: 2.5635862151727253

Epoch: 6| Step: 5
Training loss: 2.7780130816509363
Validation loss: 2.5680974008148105

Epoch: 6| Step: 6
Training loss: 3.2216007978083585
Validation loss: 2.5740629839908062

Epoch: 6| Step: 7
Training loss: 2.6433236141274694
Validation loss: 2.5827424018220646

Epoch: 6| Step: 8
Training loss: 3.2849414224496885
Validation loss: 2.5945178260765593

Epoch: 6| Step: 9
Training loss: 2.3691191896379324
Validation loss: 2.6084870872587818

Epoch: 6| Step: 10
Training loss: 3.3117271817390894
Validation loss: 2.63574903782763

Epoch: 6| Step: 11
Training loss: 2.9355764381204335
Validation loss: 2.607777011466455

Epoch: 6| Step: 12
Training loss: 2.3970444202850776
Validation loss: 2.5875110335290903

Epoch: 6| Step: 13
Training loss: 4.143371362202185
Validation loss: 2.569349301775519

Epoch: 127| Step: 0
Training loss: 2.8179998241178135
Validation loss: 2.554090479477126

Epoch: 6| Step: 1
Training loss: 2.7637759994464037
Validation loss: 2.5522892456830157

Epoch: 6| Step: 2
Training loss: 3.0054146857241686
Validation loss: 2.55631174991312

Epoch: 6| Step: 3
Training loss: 2.501304190914624
Validation loss: 2.5617369209178023

Epoch: 6| Step: 4
Training loss: 3.5515949588472195
Validation loss: 2.562076444559175

Epoch: 6| Step: 5
Training loss: 2.6810534140627666
Validation loss: 2.5656421744087656

Epoch: 6| Step: 6
Training loss: 3.3429229283875452
Validation loss: 2.56545928967104

Epoch: 6| Step: 7
Training loss: 3.030969036491613
Validation loss: 2.5647222475817157

Epoch: 6| Step: 8
Training loss: 2.624720058954558
Validation loss: 2.560797594304103

Epoch: 6| Step: 9
Training loss: 3.368224513129968
Validation loss: 2.5607606460627697

Epoch: 6| Step: 10
Training loss: 2.8414503587598334
Validation loss: 2.557280416112822

Epoch: 6| Step: 11
Training loss: 3.188818864426462
Validation loss: 2.5530001077100346

Epoch: 6| Step: 12
Training loss: 2.267669807308919
Validation loss: 2.5517880966924777

Epoch: 6| Step: 13
Training loss: 2.426586171149585
Validation loss: 2.558330704663392

Epoch: 128| Step: 0
Training loss: 2.8585459023073505
Validation loss: 2.5807811479797103

Epoch: 6| Step: 1
Training loss: 3.0233804071442467
Validation loss: 2.6086811275172197

Epoch: 6| Step: 2
Training loss: 3.0023980093347915
Validation loss: 2.629735667375339

Epoch: 6| Step: 3
Training loss: 2.656752864136484
Validation loss: 2.643921438857957

Epoch: 6| Step: 4
Training loss: 2.8422086122472128
Validation loss: 2.6802785290929783

Epoch: 6| Step: 5
Training loss: 2.665141046738658
Validation loss: 2.701615972123831

Epoch: 6| Step: 6
Training loss: 3.2185043685667725
Validation loss: 2.710728383495802

Epoch: 6| Step: 7
Training loss: 3.1524441879135874
Validation loss: 2.6569550651581584

Epoch: 6| Step: 8
Training loss: 3.3105517722124547
Validation loss: 2.6105421861463984

Epoch: 6| Step: 9
Training loss: 2.6220563096111196
Validation loss: 2.59079730630805

Epoch: 6| Step: 10
Training loss: 3.032861969203868
Validation loss: 2.5761630302186

Epoch: 6| Step: 11
Training loss: 2.6111133746775383
Validation loss: 2.566458684897838

Epoch: 6| Step: 12
Training loss: 3.0572803157008637
Validation loss: 2.559815497057836

Epoch: 6| Step: 13
Training loss: 2.6552440758134335
Validation loss: 2.5579031975458366

Epoch: 129| Step: 0
Training loss: 2.8915413718511713
Validation loss: 2.5612418174541878

Epoch: 6| Step: 1
Training loss: 2.456769240923822
Validation loss: 2.5553043319871236

Epoch: 6| Step: 2
Training loss: 2.715010779203089
Validation loss: 2.5556163134879037

Epoch: 6| Step: 3
Training loss: 3.5212549863759013
Validation loss: 2.5611044392274813

Epoch: 6| Step: 4
Training loss: 2.817420723856713
Validation loss: 2.556719964408241

Epoch: 6| Step: 5
Training loss: 2.6429843632628445
Validation loss: 2.5568691167132243

Epoch: 6| Step: 6
Training loss: 3.278863965757778
Validation loss: 2.5571655204898764

Epoch: 6| Step: 7
Training loss: 3.4188057011001662
Validation loss: 2.5571713592304257

Epoch: 6| Step: 8
Training loss: 2.847497336475979
Validation loss: 2.558196665531257

Epoch: 6| Step: 9
Training loss: 2.8434682853248843
Validation loss: 2.567244912085999

Epoch: 6| Step: 10
Training loss: 2.472361759529319
Validation loss: 2.5755884444575874

Epoch: 6| Step: 11
Training loss: 2.928563749323224
Validation loss: 2.5914424451712077

Epoch: 6| Step: 12
Training loss: 2.7606173076526783
Validation loss: 2.603121648654155

Epoch: 6| Step: 13
Training loss: 2.8637638283857325
Validation loss: 2.639659863705994

Epoch: 130| Step: 0
Training loss: 2.9195108079692256
Validation loss: 2.676114592998716

Epoch: 6| Step: 1
Training loss: 3.017210074389187
Validation loss: 2.6753703997844207

Epoch: 6| Step: 2
Training loss: 3.205925289613819
Validation loss: 2.6509371375330666

Epoch: 6| Step: 3
Training loss: 2.8447274006070686
Validation loss: 2.662772345749986

Epoch: 6| Step: 4
Training loss: 3.108188268499668
Validation loss: 2.646268249945115

Epoch: 6| Step: 5
Training loss: 2.8238231334359845
Validation loss: 2.622444557510978

Epoch: 6| Step: 6
Training loss: 2.6419885489412738
Validation loss: 2.596453182587661

Epoch: 6| Step: 7
Training loss: 2.675987068669617
Validation loss: 2.6002979486082025

Epoch: 6| Step: 8
Training loss: 3.418349588158056
Validation loss: 2.5895850422131304

Epoch: 6| Step: 9
Training loss: 3.6047624452073057
Validation loss: 2.576144254860224

Epoch: 6| Step: 10
Training loss: 2.88708146930432
Validation loss: 2.566829279739936

Epoch: 6| Step: 11
Training loss: 1.7184646369552026
Validation loss: 2.5586840421627053

Epoch: 6| Step: 12
Training loss: 2.3121740781660276
Validation loss: 2.5580601334655526

Epoch: 6| Step: 13
Training loss: 3.219601712917195
Validation loss: 2.5535649057188436

Epoch: 131| Step: 0
Training loss: 2.978892138087804
Validation loss: 2.5548237532234017

Epoch: 6| Step: 1
Training loss: 3.087659292706518
Validation loss: 2.5545488038724855

Epoch: 6| Step: 2
Training loss: 2.3244327222278502
Validation loss: 2.5547249756040893

Epoch: 6| Step: 3
Training loss: 2.9235014443104443
Validation loss: 2.5555870737994852

Epoch: 6| Step: 4
Training loss: 2.806640540051973
Validation loss: 2.561418546729537

Epoch: 6| Step: 5
Training loss: 2.6878819748648235
Validation loss: 2.5618578838890214

Epoch: 6| Step: 6
Training loss: 3.346375619940757
Validation loss: 2.5574039045050228

Epoch: 6| Step: 7
Training loss: 3.022367381680088
Validation loss: 2.5684915652771916

Epoch: 6| Step: 8
Training loss: 2.430923294828147
Validation loss: 2.5765471630987804

Epoch: 6| Step: 9
Training loss: 2.658337838419223
Validation loss: 2.5732818307185323

Epoch: 6| Step: 10
Training loss: 3.206639143917538
Validation loss: 2.58854607616607

Epoch: 6| Step: 11
Training loss: 2.309198652046163
Validation loss: 2.5931535092517146

Epoch: 6| Step: 12
Training loss: 3.523714109673057
Validation loss: 2.635489778981104

Epoch: 6| Step: 13
Training loss: 3.0900653513691942
Validation loss: 2.6435421774344414

Epoch: 132| Step: 0
Training loss: 3.069598010456871
Validation loss: 2.63071887506281

Epoch: 6| Step: 1
Training loss: 3.08056373614215
Validation loss: 2.6514031660778703

Epoch: 6| Step: 2
Training loss: 2.8207501946222435
Validation loss: 2.6454877423409338

Epoch: 6| Step: 3
Training loss: 2.323398374780909
Validation loss: 2.6459806338438416

Epoch: 6| Step: 4
Training loss: 3.259624608431257
Validation loss: 2.6153177604954543

Epoch: 6| Step: 5
Training loss: 3.145520243106453
Validation loss: 2.6088651360750608

Epoch: 6| Step: 6
Training loss: 2.0607825555753148
Validation loss: 2.5975480069357917

Epoch: 6| Step: 7
Training loss: 3.3662045630651134
Validation loss: 2.5701102259376154

Epoch: 6| Step: 8
Training loss: 2.5273690318238966
Validation loss: 2.5778851628419717

Epoch: 6| Step: 9
Training loss: 2.343956900047393
Validation loss: 2.569458426456236

Epoch: 6| Step: 10
Training loss: 2.9497771486063873
Validation loss: 2.5653568373038653

Epoch: 6| Step: 11
Training loss: 3.392325682353664
Validation loss: 2.5718039416931298

Epoch: 6| Step: 12
Training loss: 2.9871389960996195
Validation loss: 2.565148173499674

Epoch: 6| Step: 13
Training loss: 2.853737532011542
Validation loss: 2.5613011663003853

Epoch: 133| Step: 0
Training loss: 2.6966483081653245
Validation loss: 2.5631652946823626

Epoch: 6| Step: 1
Training loss: 3.054028061813406
Validation loss: 2.5548449620772398

Epoch: 6| Step: 2
Training loss: 2.262983163067212
Validation loss: 2.554932943425438

Epoch: 6| Step: 3
Training loss: 3.353177195175658
Validation loss: 2.5665972008938125

Epoch: 6| Step: 4
Training loss: 3.167601163072128
Validation loss: 2.5687550451799357

Epoch: 6| Step: 5
Training loss: 2.4757883685109876
Validation loss: 2.5703904120502816

Epoch: 6| Step: 6
Training loss: 2.337749072181894
Validation loss: 2.5743202631259074

Epoch: 6| Step: 7
Training loss: 2.6930329786874307
Validation loss: 2.581640481447913

Epoch: 6| Step: 8
Training loss: 2.6500967224031733
Validation loss: 2.59656207651983

Epoch: 6| Step: 9
Training loss: 3.4340189560915206
Validation loss: 2.5898946195547374

Epoch: 6| Step: 10
Training loss: 2.9526925552460868
Validation loss: 2.594442773926628

Epoch: 6| Step: 11
Training loss: 2.270174916792103
Validation loss: 2.5924533341191

Epoch: 6| Step: 12
Training loss: 3.6262570536458405
Validation loss: 2.6219021555641118

Epoch: 6| Step: 13
Training loss: 3.408515946424668
Validation loss: 2.6242738628659166

Epoch: 134| Step: 0
Training loss: 3.1978382676710906
Validation loss: 2.5987262198433916

Epoch: 6| Step: 1
Training loss: 3.4833800943938122
Validation loss: 2.587760550104558

Epoch: 6| Step: 2
Training loss: 2.648905034840992
Validation loss: 2.589176075394936

Epoch: 6| Step: 3
Training loss: 2.8172901475499783
Validation loss: 2.5701230350805275

Epoch: 6| Step: 4
Training loss: 2.95812516532235
Validation loss: 2.5674100056615936

Epoch: 6| Step: 5
Training loss: 3.370875204523332
Validation loss: 2.567904016709919

Epoch: 6| Step: 6
Training loss: 2.8704386476260306
Validation loss: 2.558354214249736

Epoch: 6| Step: 7
Training loss: 2.505385796387258
Validation loss: 2.5503039162249603

Epoch: 6| Step: 8
Training loss: 3.0852998871546924
Validation loss: 2.5501926459535884

Epoch: 6| Step: 9
Training loss: 3.0852612490837235
Validation loss: 2.5496573400324345

Epoch: 6| Step: 10
Training loss: 2.3602335801346888
Validation loss: 2.5482123692640464

Epoch: 6| Step: 11
Training loss: 3.0376531868442327
Validation loss: 2.5483493700891504

Epoch: 6| Step: 12
Training loss: 2.2731165708564416
Validation loss: 2.547114265074665

Epoch: 6| Step: 13
Training loss: 2.502725260196841
Validation loss: 2.5522246438223717

Epoch: 135| Step: 0
Training loss: 2.383113454355064
Validation loss: 2.5544054554864077

Epoch: 6| Step: 1
Training loss: 2.3168286200615547
Validation loss: 2.5622752851694384

Epoch: 6| Step: 2
Training loss: 2.7457118847335904
Validation loss: 2.563115828033198

Epoch: 6| Step: 3
Training loss: 2.5589648727444825
Validation loss: 2.5639026403618472

Epoch: 6| Step: 4
Training loss: 2.6776237882320495
Validation loss: 2.5768711435629084

Epoch: 6| Step: 5
Training loss: 3.2922807112698207
Validation loss: 2.5947797070346823

Epoch: 6| Step: 6
Training loss: 3.5742718468562926
Validation loss: 2.6109078934826653

Epoch: 6| Step: 7
Training loss: 2.6453604588495825
Validation loss: 2.616994435280776

Epoch: 6| Step: 8
Training loss: 3.1130133577005688
Validation loss: 2.616962430162906

Epoch: 6| Step: 9
Training loss: 2.823213643761363
Validation loss: 2.624401630814247

Epoch: 6| Step: 10
Training loss: 2.8533267899316406
Validation loss: 2.652109367041055

Epoch: 6| Step: 11
Training loss: 3.1762406696060936
Validation loss: 2.6207447828649197

Epoch: 6| Step: 12
Training loss: 3.018282179192731
Validation loss: 2.577833862372906

Epoch: 6| Step: 13
Training loss: 3.1605945561402247
Validation loss: 2.5567658538783573

Epoch: 136| Step: 0
Training loss: 2.7732849938813713
Validation loss: 2.549332957174134

Epoch: 6| Step: 1
Training loss: 2.9266967156097903
Validation loss: 2.547376777405779

Epoch: 6| Step: 2
Training loss: 2.9286858639306814
Validation loss: 2.544387850126273

Epoch: 6| Step: 3
Training loss: 3.2515674625855633
Validation loss: 2.5422016930917732

Epoch: 6| Step: 4
Training loss: 2.9869131110330827
Validation loss: 2.543460223883694

Epoch: 6| Step: 5
Training loss: 3.153653729421284
Validation loss: 2.5461828983877512

Epoch: 6| Step: 6
Training loss: 2.5947759047164403
Validation loss: 2.5455540353610693

Epoch: 6| Step: 7
Training loss: 2.955000347518255
Validation loss: 2.5471515265076845

Epoch: 6| Step: 8
Training loss: 2.6903984054159156
Validation loss: 2.5705816912977073

Epoch: 6| Step: 9
Training loss: 2.86483959554512
Validation loss: 2.634312252170837

Epoch: 6| Step: 10
Training loss: 2.67054653046194
Validation loss: 2.6241873143821643

Epoch: 6| Step: 11
Training loss: 2.7775358624550863
Validation loss: 2.6254606873034687

Epoch: 6| Step: 12
Training loss: 3.322010997094883
Validation loss: 2.5927771354741465

Epoch: 6| Step: 13
Training loss: 2.530340902709226
Validation loss: 2.5606725645990562

Epoch: 137| Step: 0
Training loss: 3.020845785882649
Validation loss: 2.563866537797333

Epoch: 6| Step: 1
Training loss: 3.299892256162724
Validation loss: 2.5590969852973138

Epoch: 6| Step: 2
Training loss: 2.6268089056311044
Validation loss: 2.5492244990752573

Epoch: 6| Step: 3
Training loss: 3.1014351998828324
Validation loss: 2.5489085469099364

Epoch: 6| Step: 4
Training loss: 2.412615197154029
Validation loss: 2.5429182618925976

Epoch: 6| Step: 5
Training loss: 3.420608495152846
Validation loss: 2.5547216389980902

Epoch: 6| Step: 6
Training loss: 3.3815188147678414
Validation loss: 2.5476309286555154

Epoch: 6| Step: 7
Training loss: 2.5756728098856003
Validation loss: 2.553746235977878

Epoch: 6| Step: 8
Training loss: 2.6921852435048854
Validation loss: 2.553080269171205

Epoch: 6| Step: 9
Training loss: 3.035072040739802
Validation loss: 2.553503882155144

Epoch: 6| Step: 10
Training loss: 2.717132876671387
Validation loss: 2.549142823990196

Epoch: 6| Step: 11
Training loss: 2.766215374536396
Validation loss: 2.557627916686502

Epoch: 6| Step: 12
Training loss: 2.73398923060006
Validation loss: 2.5670387806035295

Epoch: 6| Step: 13
Training loss: 2.121232001925686
Validation loss: 2.5732869913056926

Epoch: 138| Step: 0
Training loss: 2.163328852048836
Validation loss: 2.576225066444994

Epoch: 6| Step: 1
Training loss: 2.4757011191153437
Validation loss: 2.5995447893448906

Epoch: 6| Step: 2
Training loss: 2.9367027012334987
Validation loss: 2.6066786646382596

Epoch: 6| Step: 3
Training loss: 3.1559251674777915
Validation loss: 2.6447288446755746

Epoch: 6| Step: 4
Training loss: 2.7305914287812882
Validation loss: 2.6426297872387803

Epoch: 6| Step: 5
Training loss: 3.0020601828055553
Validation loss: 2.6206460286759112

Epoch: 6| Step: 6
Training loss: 2.8436342991358226
Validation loss: 2.635821557029391

Epoch: 6| Step: 7
Training loss: 3.403958170811988
Validation loss: 2.679312724361929

Epoch: 6| Step: 8
Training loss: 3.237370527469617
Validation loss: 2.658175184462842

Epoch: 6| Step: 9
Training loss: 2.82498618603595
Validation loss: 2.651145753308565

Epoch: 6| Step: 10
Training loss: 2.3328983605355806
Validation loss: 2.6182948397970045

Epoch: 6| Step: 11
Training loss: 2.99432440167002
Validation loss: 2.597183741919711

Epoch: 6| Step: 12
Training loss: 2.973858102867588
Validation loss: 2.5738442459273787

Epoch: 6| Step: 13
Training loss: 3.2624100186739016
Validation loss: 2.5676703506519574

Epoch: 139| Step: 0
Training loss: 2.809763785374502
Validation loss: 2.5530976386622464

Epoch: 6| Step: 1
Training loss: 2.622211428348862
Validation loss: 2.5609726354464937

Epoch: 6| Step: 2
Training loss: 2.9538040591413313
Validation loss: 2.564689468201928

Epoch: 6| Step: 3
Training loss: 3.0373860027758077
Validation loss: 2.5736831908876217

Epoch: 6| Step: 4
Training loss: 2.5782864606756215
Validation loss: 2.5685210652874395

Epoch: 6| Step: 5
Training loss: 3.090570530734469
Validation loss: 2.587661656632569

Epoch: 6| Step: 6
Training loss: 3.2350231755884282
Validation loss: 2.5796256959515738

Epoch: 6| Step: 7
Training loss: 3.0372393712130883
Validation loss: 2.565531458458483

Epoch: 6| Step: 8
Training loss: 2.709670416578277
Validation loss: 2.5635826410943645

Epoch: 6| Step: 9
Training loss: 2.631884765172057
Validation loss: 2.5544075781320825

Epoch: 6| Step: 10
Training loss: 2.806447786357564
Validation loss: 2.5501971234370386

Epoch: 6| Step: 11
Training loss: 2.862192902062711
Validation loss: 2.5527500968357515

Epoch: 6| Step: 12
Training loss: 2.684158554499141
Validation loss: 2.54722277327052

Epoch: 6| Step: 13
Training loss: 3.423258880454393
Validation loss: 2.5457155794723154

Epoch: 140| Step: 0
Training loss: 2.8160624512499006
Validation loss: 2.5443006049356396

Epoch: 6| Step: 1
Training loss: 2.681905023553013
Validation loss: 2.5415590997450668

Epoch: 6| Step: 2
Training loss: 3.1674233753838816
Validation loss: 2.547435915901097

Epoch: 6| Step: 3
Training loss: 2.439613013300078
Validation loss: 2.5408106992695205

Epoch: 6| Step: 4
Training loss: 2.574078059657137
Validation loss: 2.5440482583204913

Epoch: 6| Step: 5
Training loss: 2.821632731399418
Validation loss: 2.5530643746478607

Epoch: 6| Step: 6
Training loss: 2.7934327493728133
Validation loss: 2.5579607096129666

Epoch: 6| Step: 7
Training loss: 3.2893273616170107
Validation loss: 2.569895157162811

Epoch: 6| Step: 8
Training loss: 2.861619245802414
Validation loss: 2.5797715831506296

Epoch: 6| Step: 9
Training loss: 3.501461268965631
Validation loss: 2.6066724676646684

Epoch: 6| Step: 10
Training loss: 2.444296921507435
Validation loss: 2.6166435419642378

Epoch: 6| Step: 11
Training loss: 2.894797453177316
Validation loss: 2.642652359168465

Epoch: 6| Step: 12
Training loss: 3.1871399021568556
Validation loss: 2.636222120614986

Epoch: 6| Step: 13
Training loss: 2.539455723757515
Validation loss: 2.610426702310608

Epoch: 141| Step: 0
Training loss: 3.4371038035171915
Validation loss: 2.5706943208790665

Epoch: 6| Step: 1
Training loss: 2.8564862109785762
Validation loss: 2.5727172776961003

Epoch: 6| Step: 2
Training loss: 2.3012766280490773
Validation loss: 2.5595735396217085

Epoch: 6| Step: 3
Training loss: 2.8648514130892706
Validation loss: 2.552220288423913

Epoch: 6| Step: 4
Training loss: 2.309872552237583
Validation loss: 2.5594861304610275

Epoch: 6| Step: 5
Training loss: 3.5998266178340863
Validation loss: 2.5513129850724936

Epoch: 6| Step: 6
Training loss: 2.7443024828544544
Validation loss: 2.574014891059032

Epoch: 6| Step: 7
Training loss: 2.8824780277893667
Validation loss: 2.588869189301238

Epoch: 6| Step: 8
Training loss: 2.9085120145311203
Validation loss: 2.6115030236614114

Epoch: 6| Step: 9
Training loss: 2.547720552280451
Validation loss: 2.6119740857969185

Epoch: 6| Step: 10
Training loss: 1.8748858735001745
Validation loss: 2.6036069420242627

Epoch: 6| Step: 11
Training loss: 2.9184703880848146
Validation loss: 2.5862733400855147

Epoch: 6| Step: 12
Training loss: 3.501128832114017
Validation loss: 2.5665824968093975

Epoch: 6| Step: 13
Training loss: 2.8374473398842506
Validation loss: 2.5575072979518456

Epoch: 142| Step: 0
Training loss: 2.7179325672623937
Validation loss: 2.5797831632600747

Epoch: 6| Step: 1
Training loss: 3.1478772291990462
Validation loss: 2.5771559926806806

Epoch: 6| Step: 2
Training loss: 3.22559865082266
Validation loss: 2.5990243917692095

Epoch: 6| Step: 3
Training loss: 2.935690789365699
Validation loss: 2.614499760989901

Epoch: 6| Step: 4
Training loss: 2.627148339488001
Validation loss: 2.637686890760967

Epoch: 6| Step: 5
Training loss: 3.229216068669276
Validation loss: 2.6411966325377603

Epoch: 6| Step: 6
Training loss: 2.8584618282815457
Validation loss: 2.603599221374996

Epoch: 6| Step: 7
Training loss: 2.6209068174830166
Validation loss: 2.5885608515822143

Epoch: 6| Step: 8
Training loss: 2.3819783736303375
Validation loss: 2.569450295894412

Epoch: 6| Step: 9
Training loss: 3.2460502685866413
Validation loss: 2.547710806742613

Epoch: 6| Step: 10
Training loss: 2.6020456043090974
Validation loss: 2.544447863117761

Epoch: 6| Step: 11
Training loss: 2.45041443569802
Validation loss: 2.557104784366159

Epoch: 6| Step: 12
Training loss: 2.7736842086023947
Validation loss: 2.5544869407313398

Epoch: 6| Step: 13
Training loss: 3.429336981794672
Validation loss: 2.561196142308721

Epoch: 143| Step: 0
Training loss: 2.732731090661353
Validation loss: 2.5619120770020283

Epoch: 6| Step: 1
Training loss: 2.2087894424517756
Validation loss: 2.557528515625899

Epoch: 6| Step: 2
Training loss: 3.3128368278411164
Validation loss: 2.5550889776647208

Epoch: 6| Step: 3
Training loss: 3.2834407214371035
Validation loss: 2.5515643042598133

Epoch: 6| Step: 4
Training loss: 2.926348357505076
Validation loss: 2.5440170808601663

Epoch: 6| Step: 5
Training loss: 3.256864633962781
Validation loss: 2.5464809547488945

Epoch: 6| Step: 6
Training loss: 2.477716604208452
Validation loss: 2.536204267212112

Epoch: 6| Step: 7
Training loss: 2.9253928483120974
Validation loss: 2.532348979639626

Epoch: 6| Step: 8
Training loss: 2.989679545450459
Validation loss: 2.541656900269781

Epoch: 6| Step: 9
Training loss: 3.0725993019489075
Validation loss: 2.538539906526992

Epoch: 6| Step: 10
Training loss: 2.899004693071265
Validation loss: 2.5431354296004747

Epoch: 6| Step: 11
Training loss: 2.7300041796753574
Validation loss: 2.5554227964662135

Epoch: 6| Step: 12
Training loss: 2.7681855670489584
Validation loss: 2.5757188065923193

Epoch: 6| Step: 13
Training loss: 1.984175724626758
Validation loss: 2.6258174904637652

Epoch: 144| Step: 0
Training loss: 3.687543060568563
Validation loss: 2.729388850665676

Epoch: 6| Step: 1
Training loss: 3.0355213392472455
Validation loss: 2.806876639054822

Epoch: 6| Step: 2
Training loss: 2.7193725574704253
Validation loss: 2.8288707838738523

Epoch: 6| Step: 3
Training loss: 2.5086240792141394
Validation loss: 2.8351298601750132

Epoch: 6| Step: 4
Training loss: 2.919447599442174
Validation loss: 2.7096169060783053

Epoch: 6| Step: 5
Training loss: 2.524645631303464
Validation loss: 2.5934223116804875

Epoch: 6| Step: 6
Training loss: 3.5416195286624483
Validation loss: 2.535579784872951

Epoch: 6| Step: 7
Training loss: 2.914781088092879
Validation loss: 2.54226354559922

Epoch: 6| Step: 8
Training loss: 2.7670343978116887
Validation loss: 2.5715904675629324

Epoch: 6| Step: 9
Training loss: 2.741022715750323
Validation loss: 2.5832126478756714

Epoch: 6| Step: 10
Training loss: 2.966435865646705
Validation loss: 2.580248199876507

Epoch: 6| Step: 11
Training loss: 3.24170683089792
Validation loss: 2.585190389017519

Epoch: 6| Step: 12
Training loss: 2.6469428872294154
Validation loss: 2.565393095774612

Epoch: 6| Step: 13
Training loss: 2.9152135953299347
Validation loss: 2.5499044932078268

Epoch: 145| Step: 0
Training loss: 2.5868047544974524
Validation loss: 2.534925722261828

Epoch: 6| Step: 1
Training loss: 2.7735628341508525
Validation loss: 2.5307013989334126

Epoch: 6| Step: 2
Training loss: 2.501289702581253
Validation loss: 2.5332062855221986

Epoch: 6| Step: 3
Training loss: 2.472466291269186
Validation loss: 2.5384787176939536

Epoch: 6| Step: 4
Training loss: 2.675891734717183
Validation loss: 2.546869902659467

Epoch: 6| Step: 5
Training loss: 3.2065573561734673
Validation loss: 2.566027752376359

Epoch: 6| Step: 6
Training loss: 3.166285809820044
Validation loss: 2.6005995690163775

Epoch: 6| Step: 7
Training loss: 3.0745142173072346
Validation loss: 2.629825640144922

Epoch: 6| Step: 8
Training loss: 2.968985779082898
Validation loss: 2.6866507441581877

Epoch: 6| Step: 9
Training loss: 3.146374653774414
Validation loss: 2.644378378015457

Epoch: 6| Step: 10
Training loss: 3.281333994925674
Validation loss: 2.617717057908766

Epoch: 6| Step: 11
Training loss: 2.6284785156533004
Validation loss: 2.560783370490636

Epoch: 6| Step: 12
Training loss: 2.9305283624031215
Validation loss: 2.544877072476977

Epoch: 6| Step: 13
Training loss: 2.6447815994926485
Validation loss: 2.527638951566836

Epoch: 146| Step: 0
Training loss: 3.1311185828249806
Validation loss: 2.5322558552774366

Epoch: 6| Step: 1
Training loss: 3.1798155662746326
Validation loss: 2.532930977409655

Epoch: 6| Step: 2
Training loss: 2.6868221403939874
Validation loss: 2.533505058000372

Epoch: 6| Step: 3
Training loss: 2.5856529609435284
Validation loss: 2.541689985771129

Epoch: 6| Step: 4
Training loss: 2.4738222961501677
Validation loss: 2.540270397798174

Epoch: 6| Step: 5
Training loss: 3.171385177600184
Validation loss: 2.544007022850746

Epoch: 6| Step: 6
Training loss: 2.9558803077179374
Validation loss: 2.548842987833177

Epoch: 6| Step: 7
Training loss: 2.5250237265501316
Validation loss: 2.5442446507079386

Epoch: 6| Step: 8
Training loss: 3.1439607280384787
Validation loss: 2.5530801707658433

Epoch: 6| Step: 9
Training loss: 2.6776063361187252
Validation loss: 2.564860175678821

Epoch: 6| Step: 10
Training loss: 3.27423129779047
Validation loss: 2.572137554674687

Epoch: 6| Step: 11
Training loss: 2.290694660621149
Validation loss: 2.5667372185921886

Epoch: 6| Step: 12
Training loss: 3.222340183364292
Validation loss: 2.5744762336385456

Epoch: 6| Step: 13
Training loss: 2.5947859200610877
Validation loss: 2.5860856789542743

Epoch: 147| Step: 0
Training loss: 2.5470112021132114
Validation loss: 2.5885558412806335

Epoch: 6| Step: 1
Training loss: 3.277608831186015
Validation loss: 2.602476650721695

Epoch: 6| Step: 2
Training loss: 2.912042075901179
Validation loss: 2.613682709965182

Epoch: 6| Step: 3
Training loss: 2.7672774556044044
Validation loss: 2.6064680192683443

Epoch: 6| Step: 4
Training loss: 2.6599925882910243
Validation loss: 2.6148066768274743

Epoch: 6| Step: 5
Training loss: 3.187969696743292
Validation loss: 2.6180908045020543

Epoch: 6| Step: 6
Training loss: 2.92603026935933
Validation loss: 2.585750941773078

Epoch: 6| Step: 7
Training loss: 2.7600769601679236
Validation loss: 2.6001724805960005

Epoch: 6| Step: 8
Training loss: 3.1913706895394895
Validation loss: 2.5974847320449332

Epoch: 6| Step: 9
Training loss: 2.8088269302704725
Validation loss: 2.578720261710886

Epoch: 6| Step: 10
Training loss: 3.1086056778327333
Validation loss: 2.5801599351463165

Epoch: 6| Step: 11
Training loss: 2.843813381955926
Validation loss: 2.5725014238455155

Epoch: 6| Step: 12
Training loss: 2.480807255753206
Validation loss: 2.5647647123139468

Epoch: 6| Step: 13
Training loss: 2.386417850687732
Validation loss: 2.5628675711917945

Epoch: 148| Step: 0
Training loss: 3.0607341424240992
Validation loss: 2.568126700710923

Epoch: 6| Step: 1
Training loss: 3.118615456777019
Validation loss: 2.5506165847402094

Epoch: 6| Step: 2
Training loss: 3.1430672785870506
Validation loss: 2.5603621143760207

Epoch: 6| Step: 3
Training loss: 3.0849709844229403
Validation loss: 2.5629593772320276

Epoch: 6| Step: 4
Training loss: 3.3627376316436672
Validation loss: 2.563229880844127

Epoch: 6| Step: 5
Training loss: 3.1173129331357967
Validation loss: 2.563297701813519

Epoch: 6| Step: 6
Training loss: 2.420752579025507
Validation loss: 2.5604419522337842

Epoch: 6| Step: 7
Training loss: 2.0187070481776956
Validation loss: 2.566397926965246

Epoch: 6| Step: 8
Training loss: 2.6174782662641602
Validation loss: 2.5680229371847942

Epoch: 6| Step: 9
Training loss: 2.620777093943962
Validation loss: 2.562591164940889

Epoch: 6| Step: 10
Training loss: 2.478627592402959
Validation loss: 2.5721727756963437

Epoch: 6| Step: 11
Training loss: 2.5214370971313245
Validation loss: 2.571931753520581

Epoch: 6| Step: 12
Training loss: 3.1635582039285377
Validation loss: 2.5758931661964133

Epoch: 6| Step: 13
Training loss: 3.187605014641889
Validation loss: 2.5921016426482284

Epoch: 149| Step: 0
Training loss: 2.3271712839507477
Validation loss: 2.591069811178149

Epoch: 6| Step: 1
Training loss: 3.027163395585342
Validation loss: 2.5973293269271527

Epoch: 6| Step: 2
Training loss: 3.4287002289511643
Validation loss: 2.593119351254255

Epoch: 6| Step: 3
Training loss: 2.574060553869188
Validation loss: 2.5971235073315926

Epoch: 6| Step: 4
Training loss: 2.81623151980524
Validation loss: 2.6216466905556586

Epoch: 6| Step: 5
Training loss: 2.4579938449394567
Validation loss: 2.62806638388641

Epoch: 6| Step: 6
Training loss: 3.08752122632348
Validation loss: 2.6257363510809912

Epoch: 6| Step: 7
Training loss: 2.7820861930960064
Validation loss: 2.632120062750933

Epoch: 6| Step: 8
Training loss: 2.644235884654826
Validation loss: 2.6021167229205617

Epoch: 6| Step: 9
Training loss: 2.872806873579521
Validation loss: 2.6058060927530025

Epoch: 6| Step: 10
Training loss: 2.932170497272156
Validation loss: 2.587300247520026

Epoch: 6| Step: 11
Training loss: 2.8542369267709833
Validation loss: 2.5735789003040606

Epoch: 6| Step: 12
Training loss: 3.2898525276873225
Validation loss: 2.5564730639994173

Epoch: 6| Step: 13
Training loss: 2.356342918931606
Validation loss: 2.5450586067183987

Epoch: 150| Step: 0
Training loss: 2.9701024237545703
Validation loss: 2.539966425757366

Epoch: 6| Step: 1
Training loss: 2.0037629966766493
Validation loss: 2.5484518241463414

Epoch: 6| Step: 2
Training loss: 3.1110813691973087
Validation loss: 2.543623756460131

Epoch: 6| Step: 3
Training loss: 3.0306612996519435
Validation loss: 2.5418662206890996

Epoch: 6| Step: 4
Training loss: 2.8822222676600275
Validation loss: 2.546615736364096

Epoch: 6| Step: 5
Training loss: 2.480134620089129
Validation loss: 2.5617642810889865

Epoch: 6| Step: 6
Training loss: 2.8869029232837664
Validation loss: 2.5879503572844995

Epoch: 6| Step: 7
Training loss: 3.201293570606657
Validation loss: 2.6036567047568093

Epoch: 6| Step: 8
Training loss: 3.1878844384627816
Validation loss: 2.6016364525135782

Epoch: 6| Step: 9
Training loss: 2.8390302791667072
Validation loss: 2.6121652054103603

Epoch: 6| Step: 10
Training loss: 2.7840893428706077
Validation loss: 2.6113791258026944

Epoch: 6| Step: 11
Training loss: 2.9545549432562135
Validation loss: 2.609076608818691

Epoch: 6| Step: 12
Training loss: 2.847692251304921
Validation loss: 2.618381733832151

Epoch: 6| Step: 13
Training loss: 2.3939794803909575
Validation loss: 2.613183381197616

Epoch: 151| Step: 0
Training loss: 2.5173008235567114
Validation loss: 2.627183211387828

Epoch: 6| Step: 1
Training loss: 2.070527148365638
Validation loss: 2.654190500442511

Epoch: 6| Step: 2
Training loss: 2.9600867506150883
Validation loss: 2.6680365711030336

Epoch: 6| Step: 3
Training loss: 3.428751963449014
Validation loss: 2.6587975356487035

Epoch: 6| Step: 4
Training loss: 2.5190265475301894
Validation loss: 2.597113660913529

Epoch: 6| Step: 5
Training loss: 3.0847530361351962
Validation loss: 2.567213585936701

Epoch: 6| Step: 6
Training loss: 2.3872471300995333
Validation loss: 2.5457584851108517

Epoch: 6| Step: 7
Training loss: 2.7038444487731947
Validation loss: 2.5373250337941036

Epoch: 6| Step: 8
Training loss: 2.8672257506602135
Validation loss: 2.5399418052787364

Epoch: 6| Step: 9
Training loss: 2.8135904529404137
Validation loss: 2.532754658232167

Epoch: 6| Step: 10
Training loss: 3.4543755799830174
Validation loss: 2.5311013839848417

Epoch: 6| Step: 11
Training loss: 2.4686920545513726
Validation loss: 2.538518638199551

Epoch: 6| Step: 12
Training loss: 3.25418042038776
Validation loss: 2.545192913697158

Epoch: 6| Step: 13
Training loss: 3.184050844294534
Validation loss: 2.5447850382162636

Epoch: 152| Step: 0
Training loss: 3.143948897938954
Validation loss: 2.55616933783271

Epoch: 6| Step: 1
Training loss: 2.3673454206812137
Validation loss: 2.59564840280587

Epoch: 6| Step: 2
Training loss: 2.875896314139329
Validation loss: 2.610781922975535

Epoch: 6| Step: 3
Training loss: 2.8623291764241556
Validation loss: 2.6453893100138575

Epoch: 6| Step: 4
Training loss: 2.9578398351116544
Validation loss: 2.607959818686889

Epoch: 6| Step: 5
Training loss: 3.0952637947329102
Validation loss: 2.586570316077855

Epoch: 6| Step: 6
Training loss: 2.873540424870382
Validation loss: 2.558852485300238

Epoch: 6| Step: 7
Training loss: 3.102937100686682
Validation loss: 2.530549163397252

Epoch: 6| Step: 8
Training loss: 2.5593994735646883
Validation loss: 2.5237733315295543

Epoch: 6| Step: 9
Training loss: 2.942613088141053
Validation loss: 2.524518053570714

Epoch: 6| Step: 10
Training loss: 3.2264410185401133
Validation loss: 2.5217235823426383

Epoch: 6| Step: 11
Training loss: 2.8913233557803015
Validation loss: 2.533402470026864

Epoch: 6| Step: 12
Training loss: 2.949059165022172
Validation loss: 2.532522224401881

Epoch: 6| Step: 13
Training loss: 2.265019618743073
Validation loss: 2.5351045601576074

Epoch: 153| Step: 0
Training loss: 2.113204418767107
Validation loss: 2.5282961758458447

Epoch: 6| Step: 1
Training loss: 2.7056569495796383
Validation loss: 2.52798950954998

Epoch: 6| Step: 2
Training loss: 2.499714453602319
Validation loss: 2.525697417039157

Epoch: 6| Step: 3
Training loss: 3.416603103294542
Validation loss: 2.524172433925178

Epoch: 6| Step: 4
Training loss: 2.8933605549963
Validation loss: 2.5242379487125826

Epoch: 6| Step: 5
Training loss: 2.982725796206216
Validation loss: 2.52672064210403

Epoch: 6| Step: 6
Training loss: 3.1716165672216903
Validation loss: 2.555372382366369

Epoch: 6| Step: 7
Training loss: 2.766913851837236
Validation loss: 2.5852216242662878

Epoch: 6| Step: 8
Training loss: 2.639482871906011
Validation loss: 2.5982713576632777

Epoch: 6| Step: 9
Training loss: 2.8444524882454516
Validation loss: 2.626209084101289

Epoch: 6| Step: 10
Training loss: 3.428570054826007
Validation loss: 2.634627496481097

Epoch: 6| Step: 11
Training loss: 2.945346821956852
Validation loss: 2.6450504219842386

Epoch: 6| Step: 12
Training loss: 2.4093972963323185
Validation loss: 2.661109370850622

Epoch: 6| Step: 13
Training loss: 2.6097499555172456
Validation loss: 2.674703172368133

Epoch: 154| Step: 0
Training loss: 2.8023493379356923
Validation loss: 2.669815040815004

Epoch: 6| Step: 1
Training loss: 2.0434996752009496
Validation loss: 2.6334642068822096

Epoch: 6| Step: 2
Training loss: 2.291360580348188
Validation loss: 2.5802011969361742

Epoch: 6| Step: 3
Training loss: 2.969887284731323
Validation loss: 2.5746420852778056

Epoch: 6| Step: 4
Training loss: 2.5855901663510594
Validation loss: 2.554018351770034

Epoch: 6| Step: 5
Training loss: 3.198950899530185
Validation loss: 2.5547232064508347

Epoch: 6| Step: 6
Training loss: 2.6864287437021317
Validation loss: 2.5346190185783777

Epoch: 6| Step: 7
Training loss: 2.9842687458076878
Validation loss: 2.544742215900142

Epoch: 6| Step: 8
Training loss: 3.0336401256756504
Validation loss: 2.542453066930251

Epoch: 6| Step: 9
Training loss: 3.0415126465423663
Validation loss: 2.537558071317205

Epoch: 6| Step: 10
Training loss: 2.6712754675615527
Validation loss: 2.536117758931251

Epoch: 6| Step: 11
Training loss: 3.174391927086271
Validation loss: 2.532656956286544

Epoch: 6| Step: 12
Training loss: 3.033868347047511
Validation loss: 2.5360670843959072

Epoch: 6| Step: 13
Training loss: 2.842585734044887
Validation loss: 2.531522602739616

Epoch: 155| Step: 0
Training loss: 3.5022515820253157
Validation loss: 2.5283916513721687

Epoch: 6| Step: 1
Training loss: 2.323445988263118
Validation loss: 2.5411763262066716

Epoch: 6| Step: 2
Training loss: 2.439592490326994
Validation loss: 2.548099178571417

Epoch: 6| Step: 3
Training loss: 2.649484253124776
Validation loss: 2.545964225958311

Epoch: 6| Step: 4
Training loss: 3.5419757633338533
Validation loss: 2.5569560959819793

Epoch: 6| Step: 5
Training loss: 2.500360081490139
Validation loss: 2.562832257299689

Epoch: 6| Step: 6
Training loss: 2.6683219798710462
Validation loss: 2.5847083417472185

Epoch: 6| Step: 7
Training loss: 2.583348479277808
Validation loss: 2.5768283162296743

Epoch: 6| Step: 8
Training loss: 2.3867066628107905
Validation loss: 2.5851925072112802

Epoch: 6| Step: 9
Training loss: 2.546092468991796
Validation loss: 2.593148706536528

Epoch: 6| Step: 10
Training loss: 3.034597377308991
Validation loss: 2.6056786979132194

Epoch: 6| Step: 11
Training loss: 3.260481584936564
Validation loss: 2.583461491015484

Epoch: 6| Step: 12
Training loss: 2.9472966884545895
Validation loss: 2.5526844581574015

Epoch: 6| Step: 13
Training loss: 2.6647590330732913
Validation loss: 2.5310037661020823

Epoch: 156| Step: 0
Training loss: 3.0931565457283012
Validation loss: 2.5211196393764927

Epoch: 6| Step: 1
Training loss: 2.1011731095460213
Validation loss: 2.520170112512385

Epoch: 6| Step: 2
Training loss: 2.975463664362974
Validation loss: 2.518141585113777

Epoch: 6| Step: 3
Training loss: 2.6083521865634616
Validation loss: 2.5211956337054935

Epoch: 6| Step: 4
Training loss: 2.761229475781762
Validation loss: 2.5293431383485907

Epoch: 6| Step: 5
Training loss: 2.0292245009351015
Validation loss: 2.544340244166394

Epoch: 6| Step: 6
Training loss: 3.4386400586395864
Validation loss: 2.541276935840404

Epoch: 6| Step: 7
Training loss: 2.6735525832162286
Validation loss: 2.563487686187783

Epoch: 6| Step: 8
Training loss: 2.7472123842627867
Validation loss: 2.5761822622056307

Epoch: 6| Step: 9
Training loss: 3.102277313035948
Validation loss: 2.573947712031445

Epoch: 6| Step: 10
Training loss: 2.944583873526516
Validation loss: 2.5626899494768165

Epoch: 6| Step: 11
Training loss: 2.791772887832886
Validation loss: 2.5536920422437484

Epoch: 6| Step: 12
Training loss: 3.0973936260637385
Validation loss: 2.535759548206593

Epoch: 6| Step: 13
Training loss: 2.8170000315413306
Validation loss: 2.5368101447865676

Epoch: 157| Step: 0
Training loss: 2.4955662511745635
Validation loss: 2.539580190936367

Epoch: 6| Step: 1
Training loss: 2.180171570982077
Validation loss: 2.563212665027949

Epoch: 6| Step: 2
Training loss: 2.9882116770904315
Validation loss: 2.550248649115488

Epoch: 6| Step: 3
Training loss: 2.669609045916336
Validation loss: 2.569730939545424

Epoch: 6| Step: 4
Training loss: 2.9497432015065286
Validation loss: 2.564254714204019

Epoch: 6| Step: 5
Training loss: 2.5972944194077083
Validation loss: 2.5795210443493657

Epoch: 6| Step: 6
Training loss: 2.5558262891229755
Validation loss: 2.5736270123404377

Epoch: 6| Step: 7
Training loss: 3.0152543388622033
Validation loss: 2.5962449276256976

Epoch: 6| Step: 8
Training loss: 2.8815948478555238
Validation loss: 2.6138895628667465

Epoch: 6| Step: 9
Training loss: 2.775694710316307
Validation loss: 2.6127341797298183

Epoch: 6| Step: 10
Training loss: 2.9685533960393435
Validation loss: 2.6169282366345126

Epoch: 6| Step: 11
Training loss: 3.3360501344055935
Validation loss: 2.6274783910504755

Epoch: 6| Step: 12
Training loss: 2.757125120437688
Validation loss: 2.5896848690082095

Epoch: 6| Step: 13
Training loss: 3.165338404976248
Validation loss: 2.562476646503006

Epoch: 158| Step: 0
Training loss: 2.451742280649391
Validation loss: 2.5343575229889086

Epoch: 6| Step: 1
Training loss: 2.76233783781061
Validation loss: 2.512928955874126

Epoch: 6| Step: 2
Training loss: 2.4084093387670427
Validation loss: 2.5028261658583784

Epoch: 6| Step: 3
Training loss: 3.0517764061933566
Validation loss: 2.507172976393423

Epoch: 6| Step: 4
Training loss: 2.375474380499539
Validation loss: 2.503506829135688

Epoch: 6| Step: 5
Training loss: 2.8810684179982626
Validation loss: 2.5077386691296795

Epoch: 6| Step: 6
Training loss: 3.1182519916450686
Validation loss: 2.507780756529211

Epoch: 6| Step: 7
Training loss: 2.679916772404124
Validation loss: 2.5239413620743014

Epoch: 6| Step: 8
Training loss: 3.441279882044252
Validation loss: 2.53703436764742

Epoch: 6| Step: 9
Training loss: 2.82146584553439
Validation loss: 2.558785203754596

Epoch: 6| Step: 10
Training loss: 2.8821828924806296
Validation loss: 2.6199296099382927

Epoch: 6| Step: 11
Training loss: 2.892884067632121
Validation loss: 2.6606484706852966

Epoch: 6| Step: 12
Training loss: 2.7661578855764923
Validation loss: 2.6843545406109635

Epoch: 6| Step: 13
Training loss: 3.4508900033448686
Validation loss: 2.6346584278101965

Epoch: 159| Step: 0
Training loss: 2.745963341775968
Validation loss: 2.5522434806342256

Epoch: 6| Step: 1
Training loss: 2.93047987331475
Validation loss: 2.5235900487379452

Epoch: 6| Step: 2
Training loss: 2.396120822630417
Validation loss: 2.5118051892120143

Epoch: 6| Step: 3
Training loss: 3.339477518982944
Validation loss: 2.5162221324320453

Epoch: 6| Step: 4
Training loss: 2.9501974136764284
Validation loss: 2.5205554820896414

Epoch: 6| Step: 5
Training loss: 3.1352512827162555
Validation loss: 2.5260290489139594

Epoch: 6| Step: 6
Training loss: 2.591637175986084
Validation loss: 2.525454054597079

Epoch: 6| Step: 7
Training loss: 3.2316977804914857
Validation loss: 2.5322865883356105

Epoch: 6| Step: 8
Training loss: 2.9049658450615423
Validation loss: 2.5295558208856934

Epoch: 6| Step: 9
Training loss: 2.7704522198224852
Validation loss: 2.5253348299195246

Epoch: 6| Step: 10
Training loss: 2.4139458588009823
Validation loss: 2.5352258084137613

Epoch: 6| Step: 11
Training loss: 2.3378362689156758
Validation loss: 2.546243570833639

Epoch: 6| Step: 12
Training loss: 2.9526360323945995
Validation loss: 2.5533762191912452

Epoch: 6| Step: 13
Training loss: 2.9560643660024906
Validation loss: 2.6091226474523563

Epoch: 160| Step: 0
Training loss: 3.24186730699599
Validation loss: 2.6691512107106443

Epoch: 6| Step: 1
Training loss: 3.2988642616619006
Validation loss: 2.7161506312452226

Epoch: 6| Step: 2
Training loss: 3.431178435810942
Validation loss: 2.780088730924111

Epoch: 6| Step: 3
Training loss: 2.551473199481213
Validation loss: 2.7477704385543165

Epoch: 6| Step: 4
Training loss: 3.103376112935692
Validation loss: 2.71855392757986

Epoch: 6| Step: 5
Training loss: 2.5235134621161515
Validation loss: 2.6454356421680645

Epoch: 6| Step: 6
Training loss: 3.1461500467360337
Validation loss: 2.619035596597536

Epoch: 6| Step: 7
Training loss: 2.07922104921742
Validation loss: 2.5687834693167995

Epoch: 6| Step: 8
Training loss: 2.474381988122394
Validation loss: 2.5517259988419716

Epoch: 6| Step: 9
Training loss: 2.577325685454558
Validation loss: 2.5451164785373304

Epoch: 6| Step: 10
Training loss: 2.712830248298851
Validation loss: 2.539344176009886

Epoch: 6| Step: 11
Training loss: 3.272764150334671
Validation loss: 2.5387754751679004

Epoch: 6| Step: 12
Training loss: 2.5957237914491906
Validation loss: 2.538331997448563

Epoch: 6| Step: 13
Training loss: 3.04619446025648
Validation loss: 2.5415329564302276

Epoch: 161| Step: 0
Training loss: 2.2478653000085265
Validation loss: 2.5295478519221692

Epoch: 6| Step: 1
Training loss: 3.4284387630953717
Validation loss: 2.5277678332365507

Epoch: 6| Step: 2
Training loss: 2.5476016078822314
Validation loss: 2.5239400720980414

Epoch: 6| Step: 3
Training loss: 3.465091735153952
Validation loss: 2.526581301620364

Epoch: 6| Step: 4
Training loss: 2.552099848064524
Validation loss: 2.540944772725217

Epoch: 6| Step: 5
Training loss: 3.034287651211231
Validation loss: 2.5635794750207865

Epoch: 6| Step: 6
Training loss: 3.0961925998090467
Validation loss: 2.5871044609408367

Epoch: 6| Step: 7
Training loss: 3.172290793540873
Validation loss: 2.604926024607635

Epoch: 6| Step: 8
Training loss: 3.1398056251961957
Validation loss: 2.6084166160617115

Epoch: 6| Step: 9
Training loss: 2.8504552912528975
Validation loss: 2.5669729440255553

Epoch: 6| Step: 10
Training loss: 2.2695204296280895
Validation loss: 2.574689106064479

Epoch: 6| Step: 11
Training loss: 2.708989039542893
Validation loss: 2.563568955748248

Epoch: 6| Step: 12
Training loss: 2.3796249331328867
Validation loss: 2.548235072795822

Epoch: 6| Step: 13
Training loss: 2.1772344314731673
Validation loss: 2.5425922393627634

Epoch: 162| Step: 0
Training loss: 3.461484430983676
Validation loss: 2.5484135822894403

Epoch: 6| Step: 1
Training loss: 2.3973524391500676
Validation loss: 2.5264268502583387

Epoch: 6| Step: 2
Training loss: 3.0238445313568776
Validation loss: 2.5217374520836557

Epoch: 6| Step: 3
Training loss: 2.61029767381478
Validation loss: 2.531253789880919

Epoch: 6| Step: 4
Training loss: 2.785407912345906
Validation loss: 2.522672857811812

Epoch: 6| Step: 5
Training loss: 2.8973340507163527
Validation loss: 2.55084190553449

Epoch: 6| Step: 6
Training loss: 2.779315833149721
Validation loss: 2.571495364712216

Epoch: 6| Step: 7
Training loss: 2.8443886176068123
Validation loss: 2.5564305166901766

Epoch: 6| Step: 8
Training loss: 2.203119047982042
Validation loss: 2.548248627211892

Epoch: 6| Step: 9
Training loss: 2.7030375030998113
Validation loss: 2.5497739112159077

Epoch: 6| Step: 10
Training loss: 2.875020731975606
Validation loss: 2.548965079654848

Epoch: 6| Step: 11
Training loss: 2.5340204030805986
Validation loss: 2.556369172428383

Epoch: 6| Step: 12
Training loss: 2.921871572890286
Validation loss: 2.569590664950583

Epoch: 6| Step: 13
Training loss: 3.4050251569672842
Validation loss: 2.571871295336631

Epoch: 163| Step: 0
Training loss: 2.669631283621527
Validation loss: 2.557394297114513

Epoch: 6| Step: 1
Training loss: 2.432078273868793
Validation loss: 2.557002597810967

Epoch: 6| Step: 2
Training loss: 3.3650566846769263
Validation loss: 2.5564619769777206

Epoch: 6| Step: 3
Training loss: 2.884629088149166
Validation loss: 2.5425050298585568

Epoch: 6| Step: 4
Training loss: 2.768271693814819
Validation loss: 2.530424418150653

Epoch: 6| Step: 5
Training loss: 2.8642000439004764
Validation loss: 2.5266283848105706

Epoch: 6| Step: 6
Training loss: 3.1580966797054675
Validation loss: 2.5313606030419775

Epoch: 6| Step: 7
Training loss: 2.2162669081884743
Validation loss: 2.5200182214632565

Epoch: 6| Step: 8
Training loss: 2.4343301751805226
Validation loss: 2.524343408440137

Epoch: 6| Step: 9
Training loss: 3.1296303586271375
Validation loss: 2.5348459070221097

Epoch: 6| Step: 10
Training loss: 2.768700737439591
Validation loss: 2.5427526775971114

Epoch: 6| Step: 11
Training loss: 2.8373318861847725
Validation loss: 2.5630493760684483

Epoch: 6| Step: 12
Training loss: 3.007066510321572
Validation loss: 2.582322960777681

Epoch: 6| Step: 13
Training loss: 2.305412876611634
Validation loss: 2.601020776048743

Epoch: 164| Step: 0
Training loss: 3.0594532661440876
Validation loss: 2.6665420259552

Epoch: 6| Step: 1
Training loss: 2.6421686660212647
Validation loss: 2.649094995868875

Epoch: 6| Step: 2
Training loss: 2.4538656683781253
Validation loss: 2.6322179043594804

Epoch: 6| Step: 3
Training loss: 3.067702098552972
Validation loss: 2.648200605743623

Epoch: 6| Step: 4
Training loss: 2.5018601173188837
Validation loss: 2.6577260606163584

Epoch: 6| Step: 5
Training loss: 2.936527497035355
Validation loss: 2.630177003975837

Epoch: 6| Step: 6
Training loss: 2.7785008591380636
Validation loss: 2.5761100902632292

Epoch: 6| Step: 7
Training loss: 3.154738262461511
Validation loss: 2.5482682348605423

Epoch: 6| Step: 8
Training loss: 3.0289297760725495
Validation loss: 2.530758344978868

Epoch: 6| Step: 9
Training loss: 2.894709160777345
Validation loss: 2.5252419636335537

Epoch: 6| Step: 10
Training loss: 2.975062996333577
Validation loss: 2.5153085434032825

Epoch: 6| Step: 11
Training loss: 2.2403330294796118
Validation loss: 2.5130023353521116

Epoch: 6| Step: 12
Training loss: 2.846386703672869
Validation loss: 2.5066708998116916

Epoch: 6| Step: 13
Training loss: 2.7447040888925525
Validation loss: 2.499918936368843

Epoch: 165| Step: 0
Training loss: 2.6791086711707197
Validation loss: 2.5036235144999615

Epoch: 6| Step: 1
Training loss: 2.851740750528971
Validation loss: 2.503395582781873

Epoch: 6| Step: 2
Training loss: 2.738108326108624
Validation loss: 2.5056781346624537

Epoch: 6| Step: 3
Training loss: 2.8962762800332436
Validation loss: 2.5117352960569406

Epoch: 6| Step: 4
Training loss: 3.2398267125071976
Validation loss: 2.509832058236356

Epoch: 6| Step: 5
Training loss: 3.2361775410991664
Validation loss: 2.519139237149127

Epoch: 6| Step: 6
Training loss: 3.024134671366188
Validation loss: 2.53734441870565

Epoch: 6| Step: 7
Training loss: 2.625666034307917
Validation loss: 2.5490097519923416

Epoch: 6| Step: 8
Training loss: 2.860406408178091
Validation loss: 2.5850773586498033

Epoch: 6| Step: 9
Training loss: 2.299332530154896
Validation loss: 2.641849548686449

Epoch: 6| Step: 10
Training loss: 2.088715835374066
Validation loss: 2.687529754283179

Epoch: 6| Step: 11
Training loss: 2.7428141255638483
Validation loss: 2.721830030967667

Epoch: 6| Step: 12
Training loss: 3.1405864352615156
Validation loss: 2.727619327734235

Epoch: 6| Step: 13
Training loss: 2.512588469053246
Validation loss: 2.7130799073740905

Epoch: 166| Step: 0
Training loss: 3.138457959807414
Validation loss: 2.667392775740774

Epoch: 6| Step: 1
Training loss: 2.6120184568655613
Validation loss: 2.623190220796465

Epoch: 6| Step: 2
Training loss: 2.9490206822458815
Validation loss: 2.57961706674273

Epoch: 6| Step: 3
Training loss: 2.8041375346226927
Validation loss: 2.564686507411532

Epoch: 6| Step: 4
Training loss: 2.6488721822774335
Validation loss: 2.5411754192592397

Epoch: 6| Step: 5
Training loss: 2.6117404107266213
Validation loss: 2.549678842225281

Epoch: 6| Step: 6
Training loss: 2.905278853723943
Validation loss: 2.567867493189031

Epoch: 6| Step: 7
Training loss: 3.209238758556899
Validation loss: 2.568801088910173

Epoch: 6| Step: 8
Training loss: 1.932496963932865
Validation loss: 2.5918869511194487

Epoch: 6| Step: 9
Training loss: 2.800887825399945
Validation loss: 2.6004889927632

Epoch: 6| Step: 10
Training loss: 2.590663498246158
Validation loss: 2.619923553901455

Epoch: 6| Step: 11
Training loss: 2.3105715365798734
Validation loss: 2.6306981785092916

Epoch: 6| Step: 12
Training loss: 3.593079877654009
Validation loss: 2.644842255956863

Epoch: 6| Step: 13
Training loss: 2.484509254522777
Validation loss: 2.641115109500041

Epoch: 167| Step: 0
Training loss: 2.213931694824148
Validation loss: 2.625192452528186

Epoch: 6| Step: 1
Training loss: 3.1765017284578954
Validation loss: 2.585457039706135

Epoch: 6| Step: 2
Training loss: 2.573905034261507
Validation loss: 2.5479724119449547

Epoch: 6| Step: 3
Training loss: 2.798452177706788
Validation loss: 2.536121465724166

Epoch: 6| Step: 4
Training loss: 2.6391217168078303
Validation loss: 2.5250740379120007

Epoch: 6| Step: 5
Training loss: 2.674579612284426
Validation loss: 2.528619144209674

Epoch: 6| Step: 6
Training loss: 2.613821296029651
Validation loss: 2.5381016551271367

Epoch: 6| Step: 7
Training loss: 2.5388223857317636
Validation loss: 2.5408291363909408

Epoch: 6| Step: 8
Training loss: 3.1763624196760625
Validation loss: 2.5346444978895395

Epoch: 6| Step: 9
Training loss: 2.4410068032600836
Validation loss: 2.536128583115281

Epoch: 6| Step: 10
Training loss: 3.080669455165904
Validation loss: 2.557312240870363

Epoch: 6| Step: 11
Training loss: 3.0919171693670195
Validation loss: 2.557095669111147

Epoch: 6| Step: 12
Training loss: 3.0819789558103112
Validation loss: 2.558330021247779

Epoch: 6| Step: 13
Training loss: 2.7381787682264935
Validation loss: 2.5613196160704708

Epoch: 168| Step: 0
Training loss: 2.6438995463323094
Validation loss: 2.595460414993632

Epoch: 6| Step: 1
Training loss: 2.6377699727377952
Validation loss: 2.591969891931913

Epoch: 6| Step: 2
Training loss: 2.8752809470192635
Validation loss: 2.616694452392842

Epoch: 6| Step: 3
Training loss: 2.4240614343040634
Validation loss: 2.658571382980747

Epoch: 6| Step: 4
Training loss: 3.355058318539453
Validation loss: 2.7196921966184866

Epoch: 6| Step: 5
Training loss: 2.358078657312144
Validation loss: 2.729913812333315

Epoch: 6| Step: 6
Training loss: 2.6909336068175387
Validation loss: 2.7570074673183815

Epoch: 6| Step: 7
Training loss: 2.7229433715569282
Validation loss: 2.726105197249257

Epoch: 6| Step: 8
Training loss: 3.144648010739866
Validation loss: 2.7184974591780247

Epoch: 6| Step: 9
Training loss: 3.141505179736542
Validation loss: 2.6839587219312224

Epoch: 6| Step: 10
Training loss: 2.470429054710025
Validation loss: 2.632395706007851

Epoch: 6| Step: 11
Training loss: 2.6858332588778904
Validation loss: 2.6195506280996343

Epoch: 6| Step: 12
Training loss: 3.227280654604428
Validation loss: 2.5914909457402704

Epoch: 6| Step: 13
Training loss: 2.91219975966374
Validation loss: 2.5613431632810477

Epoch: 169| Step: 0
Training loss: 3.21360441586621
Validation loss: 2.5525296739868515

Epoch: 6| Step: 1
Training loss: 2.618160237839896
Validation loss: 2.543697815139814

Epoch: 6| Step: 2
Training loss: 2.962665949169293
Validation loss: 2.544848739951599

Epoch: 6| Step: 3
Training loss: 2.6162817455248493
Validation loss: 2.5352457286276233

Epoch: 6| Step: 4
Training loss: 2.5340182390768464
Validation loss: 2.529097225627093

Epoch: 6| Step: 5
Training loss: 2.6779613217843345
Validation loss: 2.5249109330251938

Epoch: 6| Step: 6
Training loss: 2.6223632648848594
Validation loss: 2.531676339184714

Epoch: 6| Step: 7
Training loss: 2.780241365452089
Validation loss: 2.5388578750533233

Epoch: 6| Step: 8
Training loss: 2.7659411923107275
Validation loss: 2.571501789020751

Epoch: 6| Step: 9
Training loss: 3.0132272309497194
Validation loss: 2.58198833847237

Epoch: 6| Step: 10
Training loss: 2.5713741811419357
Validation loss: 2.6138671343807065

Epoch: 6| Step: 11
Training loss: 3.088958111756539
Validation loss: 2.6597593526184156

Epoch: 6| Step: 12
Training loss: 2.893961862013572
Validation loss: 2.652698843029897

Epoch: 6| Step: 13
Training loss: 2.9524291495301975
Validation loss: 2.6171159436026907

Epoch: 170| Step: 0
Training loss: 3.179130486665358
Validation loss: 2.5859226362322123

Epoch: 6| Step: 1
Training loss: 3.0717394281781165
Validation loss: 2.5652172329593883

Epoch: 6| Step: 2
Training loss: 2.5821529480941043
Validation loss: 2.5505188986046825

Epoch: 6| Step: 3
Training loss: 2.7702574645383273
Validation loss: 2.551018607612964

Epoch: 6| Step: 4
Training loss: 2.919794821127908
Validation loss: 2.547575861675725

Epoch: 6| Step: 5
Training loss: 2.4233789511912205
Validation loss: 2.549583920516723

Epoch: 6| Step: 6
Training loss: 2.699486284481505
Validation loss: 2.5452912413683557

Epoch: 6| Step: 7
Training loss: 2.1904539599287696
Validation loss: 2.553998985006314

Epoch: 6| Step: 8
Training loss: 2.458231767614544
Validation loss: 2.5555203041762162

Epoch: 6| Step: 9
Training loss: 2.784501050842383
Validation loss: 2.553363196015406

Epoch: 6| Step: 10
Training loss: 2.7184543668120855
Validation loss: 2.5543935074172093

Epoch: 6| Step: 11
Training loss: 3.017325440725044
Validation loss: 2.558958245648916

Epoch: 6| Step: 12
Training loss: 2.732491329420177
Validation loss: 2.5682885668544393

Epoch: 6| Step: 13
Training loss: 3.340898099750281
Validation loss: 2.5688174379484177

Epoch: 171| Step: 0
Training loss: 2.352179259469133
Validation loss: 2.5845180316302754

Epoch: 6| Step: 1
Training loss: 3.1103118558591905
Validation loss: 2.6041269160692666

Epoch: 6| Step: 2
Training loss: 2.299752023016961
Validation loss: 2.6349144857242894

Epoch: 6| Step: 3
Training loss: 3.2270157244015203
Validation loss: 2.639319030715796

Epoch: 6| Step: 4
Training loss: 3.0487894939196547
Validation loss: 2.6367901361024244

Epoch: 6| Step: 5
Training loss: 3.2960234351297197
Validation loss: 2.5950589179156607

Epoch: 6| Step: 6
Training loss: 2.4730095151478326
Validation loss: 2.5592178706975877

Epoch: 6| Step: 7
Training loss: 2.571092666908576
Validation loss: 2.5256681304145556

Epoch: 6| Step: 8
Training loss: 2.374124265135705
Validation loss: 2.51644830588332

Epoch: 6| Step: 9
Training loss: 3.0469138118521615
Validation loss: 2.518021618153974

Epoch: 6| Step: 10
Training loss: 2.709636628961666
Validation loss: 2.5189680885232306

Epoch: 6| Step: 11
Training loss: 3.579376534884114
Validation loss: 2.5066425414700984

Epoch: 6| Step: 12
Training loss: 2.007261920649824
Validation loss: 2.527022673484616

Epoch: 6| Step: 13
Training loss: 2.0786758495875906
Validation loss: 2.509311142752071

Epoch: 172| Step: 0
Training loss: 2.073703967797026
Validation loss: 2.528806111522918

Epoch: 6| Step: 1
Training loss: 3.482549488512892
Validation loss: 2.5268544283208794

Epoch: 6| Step: 2
Training loss: 3.082545789887464
Validation loss: 2.5293940084055886

Epoch: 6| Step: 3
Training loss: 2.9666547910759795
Validation loss: 2.541068495051219

Epoch: 6| Step: 4
Training loss: 3.027398247997369
Validation loss: 2.56115826891577

Epoch: 6| Step: 5
Training loss: 2.6620037816376914
Validation loss: 2.5691597039573466

Epoch: 6| Step: 6
Training loss: 2.7371828322246117
Validation loss: 2.602508489209895

Epoch: 6| Step: 7
Training loss: 2.586641613389958
Validation loss: 2.6023028314776946

Epoch: 6| Step: 8
Training loss: 3.0825335694006535
Validation loss: 2.645806225621739

Epoch: 6| Step: 9
Training loss: 2.6588242566814153
Validation loss: 2.680453262305638

Epoch: 6| Step: 10
Training loss: 2.0374732126920696
Validation loss: 2.668052490776621

Epoch: 6| Step: 11
Training loss: 2.9438045294179904
Validation loss: 2.648234607977219

Epoch: 6| Step: 12
Training loss: 1.8067328682110078
Validation loss: 2.5977356413679185

Epoch: 6| Step: 13
Training loss: 3.339909424610136
Validation loss: 2.554349194195115

Epoch: 173| Step: 0
Training loss: 2.6109649017558016
Validation loss: 2.5377880760753975

Epoch: 6| Step: 1
Training loss: 2.8608241343681375
Validation loss: 2.527233631540845

Epoch: 6| Step: 2
Training loss: 2.578424424787987
Validation loss: 2.5225286355381105

Epoch: 6| Step: 3
Training loss: 3.3809098670225834
Validation loss: 2.522154544609111

Epoch: 6| Step: 4
Training loss: 2.8860890033239484
Validation loss: 2.5167435824250517

Epoch: 6| Step: 5
Training loss: 3.143692568184242
Validation loss: 2.5079059851110377

Epoch: 6| Step: 6
Training loss: 2.0303855817317435
Validation loss: 2.50745472173439

Epoch: 6| Step: 7
Training loss: 2.825386702815524
Validation loss: 2.511787448441717

Epoch: 6| Step: 8
Training loss: 3.047818864221029
Validation loss: 2.5182586236213633

Epoch: 6| Step: 9
Training loss: 2.4840811309710844
Validation loss: 2.5289691476594474

Epoch: 6| Step: 10
Training loss: 2.6653346271381353
Validation loss: 2.540395056661923

Epoch: 6| Step: 11
Training loss: 3.1588743271568287
Validation loss: 2.551876304990423

Epoch: 6| Step: 12
Training loss: 2.778653078984422
Validation loss: 2.5695766983280857

Epoch: 6| Step: 13
Training loss: 0.917810434528088
Validation loss: 2.6228023105311684

Epoch: 174| Step: 0
Training loss: 3.275342582664213
Validation loss: 2.6581115993816264

Epoch: 6| Step: 1
Training loss: 2.988513733041989
Validation loss: 2.6924532997664676

Epoch: 6| Step: 2
Training loss: 2.822003900872663
Validation loss: 2.7064837258787664

Epoch: 6| Step: 3
Training loss: 2.3706112516825706
Validation loss: 2.676757391093938

Epoch: 6| Step: 4
Training loss: 2.553949371935391
Validation loss: 2.64175276202733

Epoch: 6| Step: 5
Training loss: 2.570579538126513
Validation loss: 2.6426317745076338

Epoch: 6| Step: 6
Training loss: 2.779931773988309
Validation loss: 2.6207004881310767

Epoch: 6| Step: 7
Training loss: 2.4298786443854414
Validation loss: 2.5995059174565447

Epoch: 6| Step: 8
Training loss: 2.33372591894033
Validation loss: 2.592975400469829

Epoch: 6| Step: 9
Training loss: 3.1868656499605437
Validation loss: 2.573032779239923

Epoch: 6| Step: 10
Training loss: 3.0985754123760874
Validation loss: 2.559063674041929

Epoch: 6| Step: 11
Training loss: 3.042450337941096
Validation loss: 2.5559808154844843

Epoch: 6| Step: 12
Training loss: 2.453926295721113
Validation loss: 2.547481619384482

Epoch: 6| Step: 13
Training loss: 2.340235198174722
Validation loss: 2.540945028993946

Epoch: 175| Step: 0
Training loss: 3.236354645900688
Validation loss: 2.5393548350065194

Epoch: 6| Step: 1
Training loss: 2.419027709789613
Validation loss: 2.542286479734466

Epoch: 6| Step: 2
Training loss: 2.6882554700170176
Validation loss: 2.5421638170663634

Epoch: 6| Step: 3
Training loss: 2.6848401946633857
Validation loss: 2.540970642115928

Epoch: 6| Step: 4
Training loss: 2.920230504696765
Validation loss: 2.54023562658679

Epoch: 6| Step: 5
Training loss: 2.9985922053404033
Validation loss: 2.5486280149702654

Epoch: 6| Step: 6
Training loss: 2.831895538235395
Validation loss: 2.5474320997766124

Epoch: 6| Step: 7
Training loss: 2.198367562228771
Validation loss: 2.552308550087141

Epoch: 6| Step: 8
Training loss: 2.8011183276502347
Validation loss: 2.544763653844854

Epoch: 6| Step: 9
Training loss: 2.923475021211229
Validation loss: 2.55704961712695

Epoch: 6| Step: 10
Training loss: 2.8879847660455433
Validation loss: 2.5533786097616002

Epoch: 6| Step: 11
Training loss: 2.838112409606171
Validation loss: 2.573823438658473

Epoch: 6| Step: 12
Training loss: 1.7852698358839523
Validation loss: 2.606568021708214

Epoch: 6| Step: 13
Training loss: 3.098322408272817
Validation loss: 2.6375896758010433

Epoch: 176| Step: 0
Training loss: 2.614491272378297
Validation loss: 2.6670006099407875

Epoch: 6| Step: 1
Training loss: 2.953681691494188
Validation loss: 2.7382309294483926

Epoch: 6| Step: 2
Training loss: 2.71565298191136
Validation loss: 2.7601057147188026

Epoch: 6| Step: 3
Training loss: 2.6820454802387017
Validation loss: 2.738716317374622

Epoch: 6| Step: 4
Training loss: 2.829449591069493
Validation loss: 2.731955730935004

Epoch: 6| Step: 5
Training loss: 2.735999883423072
Validation loss: 2.6909795482657946

Epoch: 6| Step: 6
Training loss: 2.7653568805966056
Validation loss: 2.6572618529751972

Epoch: 6| Step: 7
Training loss: 3.0111810226426186
Validation loss: 2.6316698648137873

Epoch: 6| Step: 8
Training loss: 2.0816478268840046
Validation loss: 2.606508838037706

Epoch: 6| Step: 9
Training loss: 2.849863711662161
Validation loss: 2.574800060485385

Epoch: 6| Step: 10
Training loss: 2.7222068995954958
Validation loss: 2.5676167353676784

Epoch: 6| Step: 11
Training loss: 2.9011027377062266
Validation loss: 2.5567991669959675

Epoch: 6| Step: 12
Training loss: 3.1189259817740393
Validation loss: 2.5618897228320607

Epoch: 6| Step: 13
Training loss: 2.337797107276168
Validation loss: 2.5466826256973167

Epoch: 177| Step: 0
Training loss: 2.8752250583297587
Validation loss: 2.5461600265342508

Epoch: 6| Step: 1
Training loss: 3.1228570838691887
Validation loss: 2.5343773362285127

Epoch: 6| Step: 2
Training loss: 3.036167521261481
Validation loss: 2.5280031877283164

Epoch: 6| Step: 3
Training loss: 2.5383546752266266
Validation loss: 2.5180146236804157

Epoch: 6| Step: 4
Training loss: 2.686799423812434
Validation loss: 2.5036731459358554

Epoch: 6| Step: 5
Training loss: 2.756475454092801
Validation loss: 2.5078949000940334

Epoch: 6| Step: 6
Training loss: 2.574786990345861
Validation loss: 2.517567487344623

Epoch: 6| Step: 7
Training loss: 3.00564505028021
Validation loss: 2.5267047045312587

Epoch: 6| Step: 8
Training loss: 2.2086197529393172
Validation loss: 2.5393122684126026

Epoch: 6| Step: 9
Training loss: 2.5677145957225602
Validation loss: 2.572974946463534

Epoch: 6| Step: 10
Training loss: 2.649221748658589
Validation loss: 2.5791401703710846

Epoch: 6| Step: 11
Training loss: 3.3529584773968586
Validation loss: 2.5999652354595835

Epoch: 6| Step: 12
Training loss: 2.1948890141819053
Validation loss: 2.578041235892059

Epoch: 6| Step: 13
Training loss: 2.9582263945114278
Validation loss: 2.5893451665663014

Epoch: 178| Step: 0
Training loss: 2.7834394602234926
Validation loss: 2.583706302559562

Epoch: 6| Step: 1
Training loss: 2.8490015522934877
Validation loss: 2.5722052543971317

Epoch: 6| Step: 2
Training loss: 2.4478892439800983
Validation loss: 2.571348777648916

Epoch: 6| Step: 3
Training loss: 2.745687571367687
Validation loss: 2.5590247732958624

Epoch: 6| Step: 4
Training loss: 3.0054557782164175
Validation loss: 2.5863006458751574

Epoch: 6| Step: 5
Training loss: 2.2989701038422825
Validation loss: 2.606197506105026

Epoch: 6| Step: 6
Training loss: 2.8322275659327754
Validation loss: 2.6290826179275655

Epoch: 6| Step: 7
Training loss: 2.599650278779907
Validation loss: 2.6409680242682883

Epoch: 6| Step: 8
Training loss: 2.167823580443698
Validation loss: 2.628323460514851

Epoch: 6| Step: 9
Training loss: 2.451338001716048
Validation loss: 2.613472565359354

Epoch: 6| Step: 10
Training loss: 3.3327265346079598
Validation loss: 2.628986023861808

Epoch: 6| Step: 11
Training loss: 2.8012931494259927
Validation loss: 2.607741646083153

Epoch: 6| Step: 12
Training loss: 2.762197493478871
Validation loss: 2.5765530026929686

Epoch: 6| Step: 13
Training loss: 3.464471463713936
Validation loss: 2.5382022957331345

Epoch: 179| Step: 0
Training loss: 2.884615367987217
Validation loss: 2.5267578689521706

Epoch: 6| Step: 1
Training loss: 2.6357736659846838
Validation loss: 2.5249824118816417

Epoch: 6| Step: 2
Training loss: 2.219168180359417
Validation loss: 2.5274931204859947

Epoch: 6| Step: 3
Training loss: 3.1954906759040997
Validation loss: 2.535099563534958

Epoch: 6| Step: 4
Training loss: 2.9876124213226696
Validation loss: 2.5443385483992347

Epoch: 6| Step: 5
Training loss: 3.009526227754055
Validation loss: 2.565085718465332

Epoch: 6| Step: 6
Training loss: 2.608972118592777
Validation loss: 2.5672263051783193

Epoch: 6| Step: 7
Training loss: 2.8983251339089176
Validation loss: 2.587432059648955

Epoch: 6| Step: 8
Training loss: 2.8808153465915214
Validation loss: 2.6011771048703016

Epoch: 6| Step: 9
Training loss: 2.556645660745136
Validation loss: 2.627317094456786

Epoch: 6| Step: 10
Training loss: 3.072825716041271
Validation loss: 2.6610762373604104

Epoch: 6| Step: 11
Training loss: 2.2998957071293202
Validation loss: 2.6517681610208794

Epoch: 6| Step: 12
Training loss: 2.445014521081783
Validation loss: 2.645017419774721

Epoch: 6| Step: 13
Training loss: 2.5245728197480646
Validation loss: 2.5935442205728347

Epoch: 180| Step: 0
Training loss: 2.6301331965727264
Validation loss: 2.565049877417815

Epoch: 6| Step: 1
Training loss: 3.0483360504366317
Validation loss: 2.5366748927006206

Epoch: 6| Step: 2
Training loss: 2.028093555835609
Validation loss: 2.5230509916209973

Epoch: 6| Step: 3
Training loss: 3.0707022926670096
Validation loss: 2.5151512470839825

Epoch: 6| Step: 4
Training loss: 3.0487148891928118
Validation loss: 2.5149405900043686

Epoch: 6| Step: 5
Training loss: 2.5971838959049376
Validation loss: 2.513504461420705

Epoch: 6| Step: 6
Training loss: 2.7388090095796365
Validation loss: 2.5243450150671043

Epoch: 6| Step: 7
Training loss: 3.2163857971534404
Validation loss: 2.5240066817504143

Epoch: 6| Step: 8
Training loss: 2.790386494763966
Validation loss: 2.5147064749621713

Epoch: 6| Step: 9
Training loss: 2.7752685520028657
Validation loss: 2.5224435282972832

Epoch: 6| Step: 10
Training loss: 2.1599026025782995
Validation loss: 2.542619756137539

Epoch: 6| Step: 11
Training loss: 2.523256183168815
Validation loss: 2.554033000711031

Epoch: 6| Step: 12
Training loss: 3.0142472830965255
Validation loss: 2.551838531372192

Epoch: 6| Step: 13
Training loss: 3.072503548131994
Validation loss: 2.5634092333067944

Epoch: 181| Step: 0
Training loss: 3.2813780260087
Validation loss: 2.557543277778676

Epoch: 6| Step: 1
Training loss: 2.971311086910173
Validation loss: 2.5448595934867715

Epoch: 6| Step: 2
Training loss: 2.6813542379111004
Validation loss: 2.5621861751623065

Epoch: 6| Step: 3
Training loss: 2.6416551736126377
Validation loss: 2.559865319913024

Epoch: 6| Step: 4
Training loss: 2.5464230001759716
Validation loss: 2.5827343140713896

Epoch: 6| Step: 5
Training loss: 3.059145433114422
Validation loss: 2.5884274845257083

Epoch: 6| Step: 6
Training loss: 2.7000040548788635
Validation loss: 2.5943986823081957

Epoch: 6| Step: 7
Training loss: 2.568112530467995
Validation loss: 2.6184774502251256

Epoch: 6| Step: 8
Training loss: 2.1953622398307546
Validation loss: 2.6337886955410053

Epoch: 6| Step: 9
Training loss: 3.0486323057310263
Validation loss: 2.6419998621705405

Epoch: 6| Step: 10
Training loss: 2.971663962331052
Validation loss: 2.627721343722658

Epoch: 6| Step: 11
Training loss: 2.5800496633318493
Validation loss: 2.6153690971520027

Epoch: 6| Step: 12
Training loss: 1.8297539650876307
Validation loss: 2.601721460694639

Epoch: 6| Step: 13
Training loss: 2.9811450995777324
Validation loss: 2.5842130094786255

Epoch: 182| Step: 0
Training loss: 2.6473575516976853
Validation loss: 2.550781061052219

Epoch: 6| Step: 1
Training loss: 2.553787399518546
Validation loss: 2.5505193981615655

Epoch: 6| Step: 2
Training loss: 2.7778163674111234
Validation loss: 2.5498785953145306

Epoch: 6| Step: 3
Training loss: 2.420305198623943
Validation loss: 2.548332263999936

Epoch: 6| Step: 4
Training loss: 2.273122759134333
Validation loss: 2.5666176801938874

Epoch: 6| Step: 5
Training loss: 2.961840650363718
Validation loss: 2.5717330933140294

Epoch: 6| Step: 6
Training loss: 3.010629894972471
Validation loss: 2.585412791870299

Epoch: 6| Step: 7
Training loss: 2.7441850217438386
Validation loss: 2.565787610735358

Epoch: 6| Step: 8
Training loss: 3.0284297447274553
Validation loss: 2.578359629624501

Epoch: 6| Step: 9
Training loss: 2.597943879458883
Validation loss: 2.586606001651055

Epoch: 6| Step: 10
Training loss: 2.6250707525981545
Validation loss: 2.570175647505334

Epoch: 6| Step: 11
Training loss: 2.689801140280703
Validation loss: 2.570961368207452

Epoch: 6| Step: 12
Training loss: 2.9493273986609534
Validation loss: 2.582438238111571

Epoch: 6| Step: 13
Training loss: 2.7848674094725383
Validation loss: 2.5708570489789913

Epoch: 183| Step: 0
Training loss: 2.5268759906322455
Validation loss: 2.56192289027017

Epoch: 6| Step: 1
Training loss: 2.4802831385094066
Validation loss: 2.519699015035655

Epoch: 6| Step: 2
Training loss: 3.019985544789058
Validation loss: 2.506547034765489

Epoch: 6| Step: 3
Training loss: 2.681379579200585
Validation loss: 2.492809878218614

Epoch: 6| Step: 4
Training loss: 2.5012076322140473
Validation loss: 2.4980032401804815

Epoch: 6| Step: 5
Training loss: 2.903223410130267
Validation loss: 2.4937039537003174

Epoch: 6| Step: 6
Training loss: 3.2190997479980386
Validation loss: 2.4953548756380988

Epoch: 6| Step: 7
Training loss: 2.8823777778169077
Validation loss: 2.4954047567996622

Epoch: 6| Step: 8
Training loss: 2.6237963687167047
Validation loss: 2.494646573275269

Epoch: 6| Step: 9
Training loss: 3.1974084970178205
Validation loss: 2.5138486566132205

Epoch: 6| Step: 10
Training loss: 2.7771214048766963
Validation loss: 2.5307729178550464

Epoch: 6| Step: 11
Training loss: 2.6096985210943804
Validation loss: 2.572969363784199

Epoch: 6| Step: 12
Training loss: 2.304004425720097
Validation loss: 2.587336974308677

Epoch: 6| Step: 13
Training loss: 2.2967012300737264
Validation loss: 2.64689271308367

Epoch: 184| Step: 0
Training loss: 2.720974680649939
Validation loss: 2.673590900153155

Epoch: 6| Step: 1
Training loss: 2.8513606587919296
Validation loss: 2.687854778723185

Epoch: 6| Step: 2
Training loss: 2.9029923095601258
Validation loss: 2.7536991499695374

Epoch: 6| Step: 3
Training loss: 2.4024096472161256
Validation loss: 2.78311080598162

Epoch: 6| Step: 4
Training loss: 3.013055368729439
Validation loss: 2.7427785945865812

Epoch: 6| Step: 5
Training loss: 2.941932094223367
Validation loss: 2.689323143632984

Epoch: 6| Step: 6
Training loss: 2.6858149724134086
Validation loss: 2.6554718151657166

Epoch: 6| Step: 7
Training loss: 2.605502058328135
Validation loss: 2.6148612235838318

Epoch: 6| Step: 8
Training loss: 2.626872348607078
Validation loss: 2.6057582600349853

Epoch: 6| Step: 9
Training loss: 2.6651673473040565
Validation loss: 2.591385552521337

Epoch: 6| Step: 10
Training loss: 2.488398718344293
Validation loss: 2.563273673486686

Epoch: 6| Step: 11
Training loss: 2.584578142404353
Validation loss: 2.553720003599511

Epoch: 6| Step: 12
Training loss: 2.6699101769415
Validation loss: 2.543759891284881

Epoch: 6| Step: 13
Training loss: 3.2836778650394587
Validation loss: 2.547360318939656

Epoch: 185| Step: 0
Training loss: 2.373947211375232
Validation loss: 2.551024301641062

Epoch: 6| Step: 1
Training loss: 2.7664264444445243
Validation loss: 2.54273845820129

Epoch: 6| Step: 2
Training loss: 3.05480457286445
Validation loss: 2.533591308422581

Epoch: 6| Step: 3
Training loss: 3.1212291091384814
Validation loss: 2.5529969234917886

Epoch: 6| Step: 4
Training loss: 3.114540142325467
Validation loss: 2.546534621403926

Epoch: 6| Step: 5
Training loss: 2.5683337540309528
Validation loss: 2.55291715908539

Epoch: 6| Step: 6
Training loss: 2.953148897266074
Validation loss: 2.5517674280513556

Epoch: 6| Step: 7
Training loss: 2.5287016297040408
Validation loss: 2.5634429621293844

Epoch: 6| Step: 8
Training loss: 2.6431964339811826
Validation loss: 2.5587861645741694

Epoch: 6| Step: 9
Training loss: 3.0383849185394545
Validation loss: 2.5892162924924196

Epoch: 6| Step: 10
Training loss: 2.8116025552485935
Validation loss: 2.5981296115105237

Epoch: 6| Step: 11
Training loss: 2.643741371375177
Validation loss: 2.6065018488978597

Epoch: 6| Step: 12
Training loss: 2.0320582029087024
Validation loss: 2.601298978516444

Epoch: 6| Step: 13
Training loss: 2.2566311923703672
Validation loss: 2.6264416788217377

Epoch: 186| Step: 0
Training loss: 2.7105123312915396
Validation loss: 2.6262719939459664

Epoch: 6| Step: 1
Training loss: 2.3337044647792626
Validation loss: 2.6401440519259882

Epoch: 6| Step: 2
Training loss: 2.4524018989564347
Validation loss: 2.6418942520329507

Epoch: 6| Step: 3
Training loss: 2.4862991654956246
Validation loss: 2.658312407668495

Epoch: 6| Step: 4
Training loss: 3.048856589693356
Validation loss: 2.666796678852607

Epoch: 6| Step: 5
Training loss: 2.7495645698531073
Validation loss: 2.7369405825445057

Epoch: 6| Step: 6
Training loss: 2.3588826253101773
Validation loss: 2.7525525808247058

Epoch: 6| Step: 7
Training loss: 2.3430483975916996
Validation loss: 2.745627779552836

Epoch: 6| Step: 8
Training loss: 3.1928353629218216
Validation loss: 2.7032710931010366

Epoch: 6| Step: 9
Training loss: 3.2657859069023
Validation loss: 2.6519460381582727

Epoch: 6| Step: 10
Training loss: 2.5124943367813586
Validation loss: 2.5725778575260665

Epoch: 6| Step: 11
Training loss: 3.1473732183614924
Validation loss: 2.5485520047292174

Epoch: 6| Step: 12
Training loss: 2.974800449378588
Validation loss: 2.5258393711031957

Epoch: 6| Step: 13
Training loss: 2.3967457125931695
Validation loss: 2.5048630750479353

Epoch: 187| Step: 0
Training loss: 2.4655748060022273
Validation loss: 2.4920097774009693

Epoch: 6| Step: 1
Training loss: 2.9699102443400602
Validation loss: 2.4958571337068514

Epoch: 6| Step: 2
Training loss: 2.7719639261769125
Validation loss: 2.494816397551781

Epoch: 6| Step: 3
Training loss: 2.209710633333887
Validation loss: 2.4994683274590157

Epoch: 6| Step: 4
Training loss: 2.8920568270765425
Validation loss: 2.4950820233578876

Epoch: 6| Step: 5
Training loss: 3.1123347165754023
Validation loss: 2.516441176635905

Epoch: 6| Step: 6
Training loss: 2.7570528275468855
Validation loss: 2.520215075536242

Epoch: 6| Step: 7
Training loss: 3.0666898754181497
Validation loss: 2.5259279179606637

Epoch: 6| Step: 8
Training loss: 2.442182298533928
Validation loss: 2.567345918089732

Epoch: 6| Step: 9
Training loss: 2.365842934652018
Validation loss: 2.608788242382998

Epoch: 6| Step: 10
Training loss: 2.1301420492167438
Validation loss: 2.6493647160422773

Epoch: 6| Step: 11
Training loss: 2.7485524615977903
Validation loss: 2.7057590154708286

Epoch: 6| Step: 12
Training loss: 3.3357745450173257
Validation loss: 2.7480675805382

Epoch: 6| Step: 13
Training loss: 2.9624737702186326
Validation loss: 2.7651917280584377

Epoch: 188| Step: 0
Training loss: 2.414547769604416
Validation loss: 2.6859815466441486

Epoch: 6| Step: 1
Training loss: 3.2115982749425958
Validation loss: 2.642996853659276

Epoch: 6| Step: 2
Training loss: 3.0519923347386886
Validation loss: 2.6122922112979006

Epoch: 6| Step: 3
Training loss: 2.8419532549327156
Validation loss: 2.575783294954906

Epoch: 6| Step: 4
Training loss: 2.0581010087622196
Validation loss: 2.564265551585193

Epoch: 6| Step: 5
Training loss: 3.145611348856791
Validation loss: 2.534581627015629

Epoch: 6| Step: 6
Training loss: 2.853467832526704
Validation loss: 2.509352588753981

Epoch: 6| Step: 7
Training loss: 2.624018076758806
Validation loss: 2.5137773343741334

Epoch: 6| Step: 8
Training loss: 2.503197722979955
Validation loss: 2.5090082856176603

Epoch: 6| Step: 9
Training loss: 2.2414749555139557
Validation loss: 2.514033393995001

Epoch: 6| Step: 10
Training loss: 2.3836522358058456
Validation loss: 2.5095953285572534

Epoch: 6| Step: 11
Training loss: 2.6889924629307242
Validation loss: 2.5178403827318747

Epoch: 6| Step: 12
Training loss: 2.8899759749631584
Validation loss: 2.5289225317878175

Epoch: 6| Step: 13
Training loss: 2.519189524578945
Validation loss: 2.534451765741841

Epoch: 189| Step: 0
Training loss: 2.9335957005236524
Validation loss: 2.546784811601672

Epoch: 6| Step: 1
Training loss: 2.6617525439500587
Validation loss: 2.5540751222217892

Epoch: 6| Step: 2
Training loss: 2.5553891212981203
Validation loss: 2.573254780305489

Epoch: 6| Step: 3
Training loss: 3.2322894020248842
Validation loss: 2.581719197557504

Epoch: 6| Step: 4
Training loss: 2.357348651902382
Validation loss: 2.5861604284221484

Epoch: 6| Step: 5
Training loss: 2.8563558346028297
Validation loss: 2.5832948946466514

Epoch: 6| Step: 6
Training loss: 2.796562475719616
Validation loss: 2.578016453978388

Epoch: 6| Step: 7
Training loss: 2.7385573309190048
Validation loss: 2.576128242905172

Epoch: 6| Step: 8
Training loss: 2.763486908562953
Validation loss: 2.5588059068818865

Epoch: 6| Step: 9
Training loss: 2.4871129717290823
Validation loss: 2.5513473500915134

Epoch: 6| Step: 10
Training loss: 2.9040269450469283
Validation loss: 2.55418441267921

Epoch: 6| Step: 11
Training loss: 2.4443587615669315
Validation loss: 2.5561919907507304

Epoch: 6| Step: 12
Training loss: 2.4629157940079933
Validation loss: 2.5722312414477964

Epoch: 6| Step: 13
Training loss: 2.9057122830323614
Validation loss: 2.582050127510186

Epoch: 190| Step: 0
Training loss: 3.0301008110775736
Validation loss: 2.5935846941493303

Epoch: 6| Step: 1
Training loss: 2.7413652279454266
Validation loss: 2.5915285212603005

Epoch: 6| Step: 2
Training loss: 2.741345833400449
Validation loss: 2.6108051311096876

Epoch: 6| Step: 3
Training loss: 2.9254764657880745
Validation loss: 2.6142646161578105

Epoch: 6| Step: 4
Training loss: 2.612254946226201
Validation loss: 2.6294388740343924

Epoch: 6| Step: 5
Training loss: 2.960905291299093
Validation loss: 2.6243446360176708

Epoch: 6| Step: 6
Training loss: 2.86693370225916
Validation loss: 2.6313289282961447

Epoch: 6| Step: 7
Training loss: 3.1859994984235445
Validation loss: 2.6065771321405946

Epoch: 6| Step: 8
Training loss: 2.579160077934498
Validation loss: 2.5994952743315607

Epoch: 6| Step: 9
Training loss: 2.2680389172681585
Validation loss: 2.56776556921226

Epoch: 6| Step: 10
Training loss: 2.673513523539179
Validation loss: 2.5549759932876523

Epoch: 6| Step: 11
Training loss: 2.2390689229507057
Validation loss: 2.5629115900877544

Epoch: 6| Step: 12
Training loss: 2.6605391037821464
Validation loss: 2.562351062407146

Epoch: 6| Step: 13
Training loss: 2.1294980407763155
Validation loss: 2.5664102786507907

Epoch: 191| Step: 0
Training loss: 2.294545971541023
Validation loss: 2.584418070728207

Epoch: 6| Step: 1
Training loss: 2.563684887368413
Validation loss: 2.584498968800445

Epoch: 6| Step: 2
Training loss: 2.7442679922065403
Validation loss: 2.601120389659176

Epoch: 6| Step: 3
Training loss: 1.9136882805417939
Validation loss: 2.5910113598999143

Epoch: 6| Step: 4
Training loss: 2.735009517618248
Validation loss: 2.5905449085355277

Epoch: 6| Step: 5
Training loss: 2.940945978108878
Validation loss: 2.58454552954933

Epoch: 6| Step: 6
Training loss: 2.827602527894544
Validation loss: 2.5822254018740636

Epoch: 6| Step: 7
Training loss: 2.549482450135675
Validation loss: 2.589232265095129

Epoch: 6| Step: 8
Training loss: 2.103417807795591
Validation loss: 2.582135093958482

Epoch: 6| Step: 9
Training loss: 2.8012412317318356
Validation loss: 2.61171188085369

Epoch: 6| Step: 10
Training loss: 3.261092695812051
Validation loss: 2.6240210839337275

Epoch: 6| Step: 11
Training loss: 2.6365806712977675
Validation loss: 2.6462461385139235

Epoch: 6| Step: 12
Training loss: 3.0815545355238667
Validation loss: 2.6752713851726297

Epoch: 6| Step: 13
Training loss: 3.2227644098800265
Validation loss: 2.68249498395798

Epoch: 192| Step: 0
Training loss: 2.7170992695992786
Validation loss: 2.6634257937270105

Epoch: 6| Step: 1
Training loss: 2.368173928780994
Validation loss: 2.6191020811422185

Epoch: 6| Step: 2
Training loss: 2.9088751309196335
Validation loss: 2.586162297007252

Epoch: 6| Step: 3
Training loss: 2.1263345006156253
Validation loss: 2.5695986414253373

Epoch: 6| Step: 4
Training loss: 2.743003093577277
Validation loss: 2.5575609908462074

Epoch: 6| Step: 5
Training loss: 2.158687927201873
Validation loss: 2.5686649353635005

Epoch: 6| Step: 6
Training loss: 3.519978857843889
Validation loss: 2.556240662704814

Epoch: 6| Step: 7
Training loss: 2.809955972211198
Validation loss: 2.580170545752923

Epoch: 6| Step: 8
Training loss: 2.016839068376124
Validation loss: 2.590762967825961

Epoch: 6| Step: 9
Training loss: 2.9968957735202855
Validation loss: 2.634505558039994

Epoch: 6| Step: 10
Training loss: 2.7525443531035068
Validation loss: 2.618732470601225

Epoch: 6| Step: 11
Training loss: 2.5453143808862566
Validation loss: 2.6218232593522663

Epoch: 6| Step: 12
Training loss: 2.724483276511882
Validation loss: 2.609068117301673

Epoch: 6| Step: 13
Training loss: 3.1951850548583316
Validation loss: 2.612244932104408

Epoch: 193| Step: 0
Training loss: 2.223853460931777
Validation loss: 2.602757994273673

Epoch: 6| Step: 1
Training loss: 2.8568863174524757
Validation loss: 2.5822479046445093

Epoch: 6| Step: 2
Training loss: 2.928097550335751
Validation loss: 2.570923876993231

Epoch: 6| Step: 3
Training loss: 2.9501343777325952
Validation loss: 2.5550995769995137

Epoch: 6| Step: 4
Training loss: 2.3834773902660937
Validation loss: 2.5420004976609873

Epoch: 6| Step: 5
Training loss: 2.6478647158428923
Validation loss: 2.534615523004455

Epoch: 6| Step: 6
Training loss: 2.7006794886884595
Validation loss: 2.525329324654181

Epoch: 6| Step: 7
Training loss: 2.632602762533279
Validation loss: 2.533672221556799

Epoch: 6| Step: 8
Training loss: 2.8986822883491494
Validation loss: 2.534107639523775

Epoch: 6| Step: 9
Training loss: 2.427500829411688
Validation loss: 2.538307688855302

Epoch: 6| Step: 10
Training loss: 3.2089995315946083
Validation loss: 2.548457641606469

Epoch: 6| Step: 11
Training loss: 3.113333018409773
Validation loss: 2.5693894420776076

Epoch: 6| Step: 12
Training loss: 1.874101232650349
Validation loss: 2.5805630936186468

Epoch: 6| Step: 13
Training loss: 2.7290283245714906
Validation loss: 2.599066775433106

Epoch: 194| Step: 0
Training loss: 3.1833680242542233
Validation loss: 2.6460127869367747

Epoch: 6| Step: 1
Training loss: 2.6856429315207637
Validation loss: 2.6804339827104635

Epoch: 6| Step: 2
Training loss: 2.4413308582109328
Validation loss: 2.7134666625393393

Epoch: 6| Step: 3
Training loss: 2.762284842695456
Validation loss: 2.7384310817652535

Epoch: 6| Step: 4
Training loss: 2.777058561252267
Validation loss: 2.7076692232344337

Epoch: 6| Step: 5
Training loss: 2.9680505832155837
Validation loss: 2.6674490429539754

Epoch: 6| Step: 6
Training loss: 2.6186753328371606
Validation loss: 2.599750848180185

Epoch: 6| Step: 7
Training loss: 3.019169597015377
Validation loss: 2.5738143607001307

Epoch: 6| Step: 8
Training loss: 2.328277992495603
Validation loss: 2.542957904524699

Epoch: 6| Step: 9
Training loss: 2.319865276765819
Validation loss: 2.5339294303703235

Epoch: 6| Step: 10
Training loss: 2.8450388241014446
Validation loss: 2.5043131497194002

Epoch: 6| Step: 11
Training loss: 2.6738221507705813
Validation loss: 2.516850043726682

Epoch: 6| Step: 12
Training loss: 2.40456936095541
Validation loss: 2.505547128334307

Epoch: 6| Step: 13
Training loss: 2.9197288423861423
Validation loss: 2.5152143488307948

Epoch: 195| Step: 0
Training loss: 2.574900141881549
Validation loss: 2.522694801383017

Epoch: 6| Step: 1
Training loss: 2.8784702752483446
Validation loss: 2.5229842124490767

Epoch: 6| Step: 2
Training loss: 2.3890647034918713
Validation loss: 2.528990176980393

Epoch: 6| Step: 3
Training loss: 2.563440010900127
Validation loss: 2.5449831134089167

Epoch: 6| Step: 4
Training loss: 3.1605947070096696
Validation loss: 2.5505368122311927

Epoch: 6| Step: 5
Training loss: 3.2886977186002015
Validation loss: 2.568763586126697

Epoch: 6| Step: 6
Training loss: 2.3356794642181344
Validation loss: 2.5872402956098854

Epoch: 6| Step: 7
Training loss: 2.5827445518015986
Validation loss: 2.6098058957724817

Epoch: 6| Step: 8
Training loss: 2.3941000819371654
Validation loss: 2.616000223759939

Epoch: 6| Step: 9
Training loss: 2.858930209225672
Validation loss: 2.629740082541029

Epoch: 6| Step: 10
Training loss: 2.479633340802986
Validation loss: 2.644616685817969

Epoch: 6| Step: 11
Training loss: 2.485064908567275
Validation loss: 2.6351531113930204

Epoch: 6| Step: 12
Training loss: 2.729615346897178
Validation loss: 2.6210803835180663

Epoch: 6| Step: 13
Training loss: 2.2743356510206265
Validation loss: 2.607626023472973

Epoch: 196| Step: 0
Training loss: 2.5947456746802704
Validation loss: 2.580893483443113

Epoch: 6| Step: 1
Training loss: 2.5708536894336023
Validation loss: 2.572209362668912

Epoch: 6| Step: 2
Training loss: 2.3599646633541513
Validation loss: 2.5618689565650308

Epoch: 6| Step: 3
Training loss: 2.7062849857456377
Validation loss: 2.5393068691693252

Epoch: 6| Step: 4
Training loss: 2.7601530608982867
Validation loss: 2.5237943472600937

Epoch: 6| Step: 5
Training loss: 2.590927242598763
Validation loss: 2.524524470488416

Epoch: 6| Step: 6
Training loss: 2.957282475189261
Validation loss: 2.527100487262884

Epoch: 6| Step: 7
Training loss: 2.1042678607238416
Validation loss: 2.546954597312906

Epoch: 6| Step: 8
Training loss: 2.9739472522072634
Validation loss: 2.554916644010839

Epoch: 6| Step: 9
Training loss: 2.3861033243988055
Validation loss: 2.562992198743868

Epoch: 6| Step: 10
Training loss: 2.3652809447185614
Validation loss: 2.569368412149673

Epoch: 6| Step: 11
Training loss: 2.721339779075055
Validation loss: 2.5756238840469523

Epoch: 6| Step: 12
Training loss: 3.3334019335999274
Validation loss: 2.5899174021393643

Epoch: 6| Step: 13
Training loss: 2.7990806023814194
Validation loss: 2.59495903309207

Epoch: 197| Step: 0
Training loss: 2.61119673861342
Validation loss: 2.6342396067503713

Epoch: 6| Step: 1
Training loss: 2.9302147962976037
Validation loss: 2.6521464317077146

Epoch: 6| Step: 2
Training loss: 2.299589667827906
Validation loss: 2.708350287700685

Epoch: 6| Step: 3
Training loss: 2.0986664397899175
Validation loss: 2.712050343770235

Epoch: 6| Step: 4
Training loss: 3.0070474815971213
Validation loss: 2.7557101549964207

Epoch: 6| Step: 5
Training loss: 2.542305621103362
Validation loss: 2.7566163482827175

Epoch: 6| Step: 6
Training loss: 2.9647075234781703
Validation loss: 2.7461585270304214

Epoch: 6| Step: 7
Training loss: 2.5088839039707507
Validation loss: 2.6809775293991613

Epoch: 6| Step: 8
Training loss: 3.1741470693108638
Validation loss: 2.654868631610831

Epoch: 6| Step: 9
Training loss: 3.0001250876733474
Validation loss: 2.598586281202383

Epoch: 6| Step: 10
Training loss: 2.7959657181969817
Validation loss: 2.5385595124142086

Epoch: 6| Step: 11
Training loss: 2.4744577218354085
Validation loss: 2.5085267363568926

Epoch: 6| Step: 12
Training loss: 2.0082443307278712
Validation loss: 2.5138798268231004

Epoch: 6| Step: 13
Training loss: 3.03036973894271
Validation loss: 2.5067035322690057

Epoch: 198| Step: 0
Training loss: 1.9044166879375863
Validation loss: 2.5102325723927

Epoch: 6| Step: 1
Training loss: 3.144069320205709
Validation loss: 2.4995401246603386

Epoch: 6| Step: 2
Training loss: 2.486617126209992
Validation loss: 2.50564774232839

Epoch: 6| Step: 3
Training loss: 2.812694288536634
Validation loss: 2.509966246212869

Epoch: 6| Step: 4
Training loss: 3.096260670415228
Validation loss: 2.5198676061986323

Epoch: 6| Step: 5
Training loss: 2.6223809028107015
Validation loss: 2.537551974278482

Epoch: 6| Step: 6
Training loss: 2.953676848343176
Validation loss: 2.5495492391203403

Epoch: 6| Step: 7
Training loss: 2.960667580251446
Validation loss: 2.568332121019898

Epoch: 6| Step: 8
Training loss: 2.5744328735395934
Validation loss: 2.591805938441004

Epoch: 6| Step: 9
Training loss: 2.733896093664159
Validation loss: 2.597324983993775

Epoch: 6| Step: 10
Training loss: 2.468891574325192
Validation loss: 2.6222176189073987

Epoch: 6| Step: 11
Training loss: 2.62527509791873
Validation loss: 2.6475256333989776

Epoch: 6| Step: 12
Training loss: 2.347922717822541
Validation loss: 2.6386421002580445

Epoch: 6| Step: 13
Training loss: 2.662711598042831
Validation loss: 2.640867337323016

Epoch: 199| Step: 0
Training loss: 2.5875994824437125
Validation loss: 2.6367433700718594

Epoch: 6| Step: 1
Training loss: 2.4408737700570544
Validation loss: 2.613548981840374

Epoch: 6| Step: 2
Training loss: 2.7138254574933542
Validation loss: 2.5927347112860017

Epoch: 6| Step: 3
Training loss: 2.2837477296380513
Validation loss: 2.560317364757245

Epoch: 6| Step: 4
Training loss: 2.7041384169910887
Validation loss: 2.55326042093787

Epoch: 6| Step: 5
Training loss: 2.510921749310091
Validation loss: 2.5552528390280536

Epoch: 6| Step: 6
Training loss: 3.152155874106337
Validation loss: 2.5431376443138394

Epoch: 6| Step: 7
Training loss: 2.6468272307317795
Validation loss: 2.5339860812979302

Epoch: 6| Step: 8
Training loss: 2.7881873544930373
Validation loss: 2.5425071977303806

Epoch: 6| Step: 9
Training loss: 2.625884588240324
Validation loss: 2.5439740989923365

Epoch: 6| Step: 10
Training loss: 2.3440072490658164
Validation loss: 2.558030962300145

Epoch: 6| Step: 11
Training loss: 2.669487226445285
Validation loss: 2.5479001694017236

Epoch: 6| Step: 12
Training loss: 3.101925614862742
Validation loss: 2.5751038520930227

Epoch: 6| Step: 13
Training loss: 2.218313899634588
Validation loss: 2.5825026549729766

Epoch: 200| Step: 0
Training loss: 2.8621280944970096
Validation loss: 2.5898436846677635

Epoch: 6| Step: 1
Training loss: 2.4946497888114756
Validation loss: 2.5915416909633464

Epoch: 6| Step: 2
Training loss: 2.807395456597688
Validation loss: 2.5912773542107663

Epoch: 6| Step: 3
Training loss: 2.2066458846704995
Validation loss: 2.587162669523584

Epoch: 6| Step: 4
Training loss: 2.408664532319549
Validation loss: 2.5830168909006037

Epoch: 6| Step: 5
Training loss: 2.4356139295413044
Validation loss: 2.6031531936554018

Epoch: 6| Step: 6
Training loss: 2.112257506769083
Validation loss: 2.6028274859911535

Epoch: 6| Step: 7
Training loss: 2.536898867806621
Validation loss: 2.6122441666172347

Epoch: 6| Step: 8
Training loss: 3.051741718707564
Validation loss: 2.6153222117642043

Epoch: 6| Step: 9
Training loss: 3.1921645796182156
Validation loss: 2.598342179987656

Epoch: 6| Step: 10
Training loss: 3.002696256171065
Validation loss: 2.607483547037933

Epoch: 6| Step: 11
Training loss: 2.3772544199707584
Validation loss: 2.6098294632678702

Epoch: 6| Step: 12
Training loss: 2.592371102994019
Validation loss: 2.6046495934083174

Epoch: 6| Step: 13
Training loss: 2.2597684736571826
Validation loss: 2.6228428990402866

Epoch: 201| Step: 0
Training loss: 2.322522379394719
Validation loss: 2.5973824759472253

Epoch: 6| Step: 1
Training loss: 3.1535834199424064
Validation loss: 2.6068873379677893

Epoch: 6| Step: 2
Training loss: 2.095426542974765
Validation loss: 2.598648344451013

Epoch: 6| Step: 3
Training loss: 2.2760343107778254
Validation loss: 2.600341857383754

Epoch: 6| Step: 4
Training loss: 2.8098529650953843
Validation loss: 2.6145224948798043

Epoch: 6| Step: 5
Training loss: 2.6944637123109394
Validation loss: 2.619712050582712

Epoch: 6| Step: 6
Training loss: 2.861935995584504
Validation loss: 2.6021852209609855

Epoch: 6| Step: 7
Training loss: 2.6771263584187484
Validation loss: 2.600924578883386

Epoch: 6| Step: 8
Training loss: 3.0937464550267726
Validation loss: 2.5965494762968393

Epoch: 6| Step: 9
Training loss: 2.5778900039384935
Validation loss: 2.581377864881532

Epoch: 6| Step: 10
Training loss: 2.022375115121378
Validation loss: 2.5848644005240433

Epoch: 6| Step: 11
Training loss: 2.2754476253590092
Validation loss: 2.572359974837753

Epoch: 6| Step: 12
Training loss: 2.735716136645751
Validation loss: 2.5804205167961123

Epoch: 6| Step: 13
Training loss: 2.8487501515835785
Validation loss: 2.5775303427978433

Epoch: 202| Step: 0
Training loss: 2.669193640112221
Validation loss: 2.586444609340408

Epoch: 6| Step: 1
Training loss: 3.053642855313171
Validation loss: 2.598262923580496

Epoch: 6| Step: 2
Training loss: 2.4389685095223954
Validation loss: 2.606166807522909

Epoch: 6| Step: 3
Training loss: 2.6841140531420526
Validation loss: 2.601650003143358

Epoch: 6| Step: 4
Training loss: 2.3740407110642665
Validation loss: 2.6038458434981675

Epoch: 6| Step: 5
Training loss: 2.532382476278919
Validation loss: 2.6076207863234524

Epoch: 6| Step: 6
Training loss: 2.7093028656223868
Validation loss: 2.5865571537702037

Epoch: 6| Step: 7
Training loss: 2.759817286262307
Validation loss: 2.6088789886677426

Epoch: 6| Step: 8
Training loss: 2.403495202488453
Validation loss: 2.586500608606792

Epoch: 6| Step: 9
Training loss: 2.5311985717070127
Validation loss: 2.5977997775892954

Epoch: 6| Step: 10
Training loss: 2.7374257534880058
Validation loss: 2.582387375550941

Epoch: 6| Step: 11
Training loss: 2.1735006053108474
Validation loss: 2.595517127454114

Epoch: 6| Step: 12
Training loss: 2.859025110402002
Validation loss: 2.5988576093009192

Epoch: 6| Step: 13
Training loss: 2.0501135910942008
Validation loss: 2.589528525546838

Epoch: 203| Step: 0
Training loss: 2.7293601125246063
Validation loss: 2.585491557727779

Epoch: 6| Step: 1
Training loss: 2.0349697386345094
Validation loss: 2.572598726688207

Epoch: 6| Step: 2
Training loss: 2.2422883014416826
Validation loss: 2.584818964277176

Epoch: 6| Step: 3
Training loss: 2.351265112236653
Validation loss: 2.5711178525747664

Epoch: 6| Step: 4
Training loss: 2.770277689431603
Validation loss: 2.5790532399704107

Epoch: 6| Step: 5
Training loss: 2.307605822483122
Validation loss: 2.5629093819588578

Epoch: 6| Step: 6
Training loss: 2.61020496440553
Validation loss: 2.564221535936643

Epoch: 6| Step: 7
Training loss: 2.965867098381799
Validation loss: 2.573269004920985

Epoch: 6| Step: 8
Training loss: 3.344420749021327
Validation loss: 2.567966789549019

Epoch: 6| Step: 9
Training loss: 2.6414959616715947
Validation loss: 2.5591780456825752

Epoch: 6| Step: 10
Training loss: 1.935162148988347
Validation loss: 2.5579043661609355

Epoch: 6| Step: 11
Training loss: 2.7209070352461335
Validation loss: 2.547786823464702

Epoch: 6| Step: 12
Training loss: 2.436517957784419
Validation loss: 2.566196010182646

Epoch: 6| Step: 13
Training loss: 3.1450023606235398
Validation loss: 2.567135054183715

Epoch: 204| Step: 0
Training loss: 2.3763315583931126
Validation loss: 2.6098105401340255

Epoch: 6| Step: 1
Training loss: 2.3011597611835817
Validation loss: 2.605882828494122

Epoch: 6| Step: 2
Training loss: 2.4831515004539177
Validation loss: 2.605025550884358

Epoch: 6| Step: 3
Training loss: 2.6470601599197505
Validation loss: 2.6008503789261312

Epoch: 6| Step: 4
Training loss: 2.9878510209085944
Validation loss: 2.5767016467038237

Epoch: 6| Step: 5
Training loss: 1.9935297016182454
Validation loss: 2.563352073510146

Epoch: 6| Step: 6
Training loss: 3.013425034447086
Validation loss: 2.5561454511076014

Epoch: 6| Step: 7
Training loss: 2.418913476431851
Validation loss: 2.5345230078944665

Epoch: 6| Step: 8
Training loss: 2.306800416842986
Validation loss: 2.5358165060233424

Epoch: 6| Step: 9
Training loss: 2.425794911614861
Validation loss: 2.531451145506821

Epoch: 6| Step: 10
Training loss: 2.17508356218846
Validation loss: 2.5580232153367923

Epoch: 6| Step: 11
Training loss: 3.168772114633291
Validation loss: 2.561003201074159

Epoch: 6| Step: 12
Training loss: 3.0853366701486666
Validation loss: 2.549201740495776

Epoch: 6| Step: 13
Training loss: 2.737645574731448
Validation loss: 2.5609250695029884

Epoch: 205| Step: 0
Training loss: 2.7088536765233755
Validation loss: 2.585988941083105

Epoch: 6| Step: 1
Training loss: 2.869922964942967
Validation loss: 2.59375286633397

Epoch: 6| Step: 2
Training loss: 1.9691298587612964
Validation loss: 2.6057701477068447

Epoch: 6| Step: 3
Training loss: 2.930622572130079
Validation loss: 2.6206125831559786

Epoch: 6| Step: 4
Training loss: 2.799335441744214
Validation loss: 2.6220968915803247

Epoch: 6| Step: 5
Training loss: 2.687450585909047
Validation loss: 2.667600289144928

Epoch: 6| Step: 6
Training loss: 2.703537396851902
Validation loss: 2.7115202539784597

Epoch: 6| Step: 7
Training loss: 2.390444380974277
Validation loss: 2.7586801832505907

Epoch: 6| Step: 8
Training loss: 2.282231368001466
Validation loss: 2.781960094725714

Epoch: 6| Step: 9
Training loss: 2.5908678886568857
Validation loss: 2.7874769570658064

Epoch: 6| Step: 10
Training loss: 2.4912147656526837
Validation loss: 2.737848480635144

Epoch: 6| Step: 11
Training loss: 2.642170470739493
Validation loss: 2.638971434163743

Epoch: 6| Step: 12
Training loss: 2.725594509962782
Validation loss: 2.5884501552311914

Epoch: 6| Step: 13
Training loss: 2.788439085285643
Validation loss: 2.545126710449877

Epoch: 206| Step: 0
Training loss: 2.569782979388965
Validation loss: 2.516097361565411

Epoch: 6| Step: 1
Training loss: 2.4562076710555343
Validation loss: 2.500680462717217

Epoch: 6| Step: 2
Training loss: 2.5588039632156208
Validation loss: 2.50068932638372

Epoch: 6| Step: 3
Training loss: 2.9680766094839304
Validation loss: 2.4935081948825637

Epoch: 6| Step: 4
Training loss: 2.169767935689177
Validation loss: 2.4932568002593185

Epoch: 6| Step: 5
Training loss: 2.724504803800837
Validation loss: 2.4905432500989346

Epoch: 6| Step: 6
Training loss: 3.0637948549085117
Validation loss: 2.4943112925986113

Epoch: 6| Step: 7
Training loss: 2.4789817377781938
Validation loss: 2.504915411450246

Epoch: 6| Step: 8
Training loss: 2.5485209195852163
Validation loss: 2.5149866526161917

Epoch: 6| Step: 9
Training loss: 2.787887624979777
Validation loss: 2.5120597680194168

Epoch: 6| Step: 10
Training loss: 3.0085760559338333
Validation loss: 2.522088668726875

Epoch: 6| Step: 11
Training loss: 2.7497939986319175
Validation loss: 2.547721844303526

Epoch: 6| Step: 12
Training loss: 2.6956304832524784
Validation loss: 2.530094712059774

Epoch: 6| Step: 13
Training loss: 2.1510473317463488
Validation loss: 2.567579715516636

Epoch: 207| Step: 0
Training loss: 2.35545255487799
Validation loss: 2.5805042801685327

Epoch: 6| Step: 1
Training loss: 2.9774661957609885
Validation loss: 2.5863939098190447

Epoch: 6| Step: 2
Training loss: 2.122482828490909
Validation loss: 2.577714922109411

Epoch: 6| Step: 3
Training loss: 2.3558766279188137
Validation loss: 2.572627362466704

Epoch: 6| Step: 4
Training loss: 3.2154396589451624
Validation loss: 2.5524620821490074

Epoch: 6| Step: 5
Training loss: 2.417141133352565
Validation loss: 2.53744696147422

Epoch: 6| Step: 6
Training loss: 2.212176188248577
Validation loss: 2.527856676878519

Epoch: 6| Step: 7
Training loss: 2.659456359838005
Validation loss: 2.510827436112024

Epoch: 6| Step: 8
Training loss: 3.079599714648938
Validation loss: 2.5073038394904685

Epoch: 6| Step: 9
Training loss: 2.515927788181819
Validation loss: 2.5085025022504133

Epoch: 6| Step: 10
Training loss: 2.452186939661889
Validation loss: 2.4965773862437244

Epoch: 6| Step: 11
Training loss: 2.6377916653888946
Validation loss: 2.4941358382266414

Epoch: 6| Step: 12
Training loss: 2.665470769071829
Validation loss: 2.504292613387646

Epoch: 6| Step: 13
Training loss: 2.788211297258366
Validation loss: 2.5139757244222354

Epoch: 208| Step: 0
Training loss: 2.8251903334783726
Validation loss: 2.5114916075801976

Epoch: 6| Step: 1
Training loss: 2.6523321541938625
Validation loss: 2.5390235775471903

Epoch: 6| Step: 2
Training loss: 2.8831654567761906
Validation loss: 2.563675153517953

Epoch: 6| Step: 3
Training loss: 2.426721756051304
Validation loss: 2.588841942786913

Epoch: 6| Step: 4
Training loss: 2.7692579987401724
Validation loss: 2.635544083457035

Epoch: 6| Step: 5
Training loss: 2.7408230856772207
Validation loss: 2.666323653843386

Epoch: 6| Step: 6
Training loss: 2.203251828269845
Validation loss: 2.6534081106948992

Epoch: 6| Step: 7
Training loss: 2.6645383885231553
Validation loss: 2.6513340047819325

Epoch: 6| Step: 8
Training loss: 2.4202683564821723
Validation loss: 2.6194446530995914

Epoch: 6| Step: 9
Training loss: 3.0299749150512523
Validation loss: 2.5684242198239295

Epoch: 6| Step: 10
Training loss: 2.2419299466216787
Validation loss: 2.5325169716365052

Epoch: 6| Step: 11
Training loss: 2.3785151518747476
Validation loss: 2.522138160419763

Epoch: 6| Step: 12
Training loss: 2.5437556161279566
Validation loss: 2.5014500565750644

Epoch: 6| Step: 13
Training loss: 2.4483897191724733
Validation loss: 2.5034740551665298

Epoch: 209| Step: 0
Training loss: 2.1948554489748364
Validation loss: 2.5014979837785263

Epoch: 6| Step: 1
Training loss: 2.3663924994184105
Validation loss: 2.513758140987236

Epoch: 6| Step: 2
Training loss: 2.407616066516582
Validation loss: 2.5168298577199084

Epoch: 6| Step: 3
Training loss: 2.401770149541127
Validation loss: 2.537216767158103

Epoch: 6| Step: 4
Training loss: 2.8798596318794103
Validation loss: 2.5436741106304424

Epoch: 6| Step: 5
Training loss: 2.8208270250829335
Validation loss: 2.5753202692575834

Epoch: 6| Step: 6
Training loss: 2.750513722379787
Validation loss: 2.578051555901256

Epoch: 6| Step: 7
Training loss: 2.5618458354822664
Validation loss: 2.5772002768348385

Epoch: 6| Step: 8
Training loss: 2.601915948359101
Validation loss: 2.570556750703037

Epoch: 6| Step: 9
Training loss: 2.1841865512835907
Validation loss: 2.558135592112494

Epoch: 6| Step: 10
Training loss: 2.5976375263657916
Validation loss: 2.556942115490564

Epoch: 6| Step: 11
Training loss: 3.1287803672203824
Validation loss: 2.5475191375929107

Epoch: 6| Step: 12
Training loss: 2.662228845391007
Validation loss: 2.538829704069128

Epoch: 6| Step: 13
Training loss: 2.083464453067838
Validation loss: 2.545276623699943

Epoch: 210| Step: 0
Training loss: 2.5943595445761183
Validation loss: 2.541392164437605

Epoch: 6| Step: 1
Training loss: 3.2955620488058326
Validation loss: 2.53986672108521

Epoch: 6| Step: 2
Training loss: 2.1014137640864177
Validation loss: 2.5300523828209043

Epoch: 6| Step: 3
Training loss: 3.353656959110405
Validation loss: 2.5498438344770333

Epoch: 6| Step: 4
Training loss: 1.9870715705180535
Validation loss: 2.539521586246017

Epoch: 6| Step: 5
Training loss: 2.8518492672052087
Validation loss: 2.5419757224090485

Epoch: 6| Step: 6
Training loss: 2.088823472288304
Validation loss: 2.5490732304828043

Epoch: 6| Step: 7
Training loss: 3.0097537427267884
Validation loss: 2.563291302949568

Epoch: 6| Step: 8
Training loss: 2.0581123614393775
Validation loss: 2.600922337479939

Epoch: 6| Step: 9
Training loss: 2.4478042143836474
Validation loss: 2.618883784448492

Epoch: 6| Step: 10
Training loss: 2.504765546109856
Validation loss: 2.6521744077255756

Epoch: 6| Step: 11
Training loss: 2.2932809750361263
Validation loss: 2.6688059847709438

Epoch: 6| Step: 12
Training loss: 2.7068849554343433
Validation loss: 2.654463147817995

Epoch: 6| Step: 13
Training loss: 1.7835446351382394
Validation loss: 2.5973811296662035

Epoch: 211| Step: 0
Training loss: 2.7297531740163334
Validation loss: 2.5780523056864

Epoch: 6| Step: 1
Training loss: 3.050520843059498
Validation loss: 2.557846850822418

Epoch: 6| Step: 2
Training loss: 2.2572301621823856
Validation loss: 2.5398785315826204

Epoch: 6| Step: 3
Training loss: 2.7210981379387893
Validation loss: 2.528637014267438

Epoch: 6| Step: 4
Training loss: 2.3207180298174266
Validation loss: 2.5315135027157285

Epoch: 6| Step: 5
Training loss: 2.943217455727527
Validation loss: 2.5094105648082285

Epoch: 6| Step: 6
Training loss: 2.069757811895475
Validation loss: 2.519064392859081

Epoch: 6| Step: 7
Training loss: 2.662923172109297
Validation loss: 2.516748526869733

Epoch: 6| Step: 8
Training loss: 2.5947546794087253
Validation loss: 2.5322154381616033

Epoch: 6| Step: 9
Training loss: 2.1497371557273226
Validation loss: 2.548856841762319

Epoch: 6| Step: 10
Training loss: 2.2861892321703703
Validation loss: 2.5479760391105666

Epoch: 6| Step: 11
Training loss: 2.408472595236324
Validation loss: 2.5721532904717375

Epoch: 6| Step: 12
Training loss: 2.950238305504343
Validation loss: 2.5930360893121422

Epoch: 6| Step: 13
Training loss: 2.0541320746283795
Validation loss: 2.6112482210852055

Epoch: 212| Step: 0
Training loss: 2.6900574691476193
Validation loss: 2.641477803066829

Epoch: 6| Step: 1
Training loss: 2.7533058756582207
Validation loss: 2.656407601918718

Epoch: 6| Step: 2
Training loss: 3.1429522797193044
Validation loss: 2.6543604036919417

Epoch: 6| Step: 3
Training loss: 2.6876882442816368
Validation loss: 2.6251104373622014

Epoch: 6| Step: 4
Training loss: 2.9708931665873464
Validation loss: 2.595524515578992

Epoch: 6| Step: 5
Training loss: 1.6569614681674336
Validation loss: 2.547619330701091

Epoch: 6| Step: 6
Training loss: 2.621842074272735
Validation loss: 2.5318620600854604

Epoch: 6| Step: 7
Training loss: 2.1049506234654967
Validation loss: 2.5166515104862497

Epoch: 6| Step: 8
Training loss: 2.86570763921191
Validation loss: 2.532006416444927

Epoch: 6| Step: 9
Training loss: 2.5537652733822664
Validation loss: 2.519426007054921

Epoch: 6| Step: 10
Training loss: 2.1967749017997376
Validation loss: 2.53930373239351

Epoch: 6| Step: 11
Training loss: 2.723470339027219
Validation loss: 2.5327895817423194

Epoch: 6| Step: 12
Training loss: 2.279658977704004
Validation loss: 2.546084052366024

Epoch: 6| Step: 13
Training loss: 2.4983610502931857
Validation loss: 2.5646668373607344

Epoch: 213| Step: 0
Training loss: 2.5329514424774766
Validation loss: 2.5746036001416845

Epoch: 6| Step: 1
Training loss: 2.2721926502499414
Validation loss: 2.5923627120171364

Epoch: 6| Step: 2
Training loss: 2.4513593989523508
Validation loss: 2.578157691089524

Epoch: 6| Step: 3
Training loss: 1.9085982195770232
Validation loss: 2.5776758493197383

Epoch: 6| Step: 4
Training loss: 2.2569624940851436
Validation loss: 2.593688770396291

Epoch: 6| Step: 5
Training loss: 2.844767964693996
Validation loss: 2.5751856739242527

Epoch: 6| Step: 6
Training loss: 2.5816631660741423
Validation loss: 2.5538499822886966

Epoch: 6| Step: 7
Training loss: 2.721102431242657
Validation loss: 2.5555159925154056

Epoch: 6| Step: 8
Training loss: 2.831979727440813
Validation loss: 2.5616830403408204

Epoch: 6| Step: 9
Training loss: 2.4634631563113873
Validation loss: 2.5568989633755064

Epoch: 6| Step: 10
Training loss: 2.5294782301054
Validation loss: 2.5405458903959106

Epoch: 6| Step: 11
Training loss: 3.008924402587383
Validation loss: 2.5404681751141354

Epoch: 6| Step: 12
Training loss: 2.0206209706939724
Validation loss: 2.52641677397124

Epoch: 6| Step: 13
Training loss: 2.722169238718874
Validation loss: 2.518968998377676

Epoch: 214| Step: 0
Training loss: 2.6675931294709536
Validation loss: 2.537113504735538

Epoch: 6| Step: 1
Training loss: 2.085685571894664
Validation loss: 2.5377381359773024

Epoch: 6| Step: 2
Training loss: 2.156840367974599
Validation loss: 2.5552377496136462

Epoch: 6| Step: 3
Training loss: 2.241838275150264
Validation loss: 2.553287218300689

Epoch: 6| Step: 4
Training loss: 2.8029023761440732
Validation loss: 2.5556209600275923

Epoch: 6| Step: 5
Training loss: 2.601925661325513
Validation loss: 2.5587894277511953

Epoch: 6| Step: 6
Training loss: 1.7154557997574962
Validation loss: 2.565586473291783

Epoch: 6| Step: 7
Training loss: 2.7286833900643166
Validation loss: 2.5588386634476956

Epoch: 6| Step: 8
Training loss: 2.8246831868186555
Validation loss: 2.5522334982361303

Epoch: 6| Step: 9
Training loss: 2.531283719815429
Validation loss: 2.5614745906942167

Epoch: 6| Step: 10
Training loss: 2.5238624427539325
Validation loss: 2.54180224652298

Epoch: 6| Step: 11
Training loss: 2.537345047151779
Validation loss: 2.559739671799683

Epoch: 6| Step: 12
Training loss: 2.9862479678786187
Validation loss: 2.5618992263051186

Epoch: 6| Step: 13
Training loss: 2.5612953890217773
Validation loss: 2.543568842605197

Epoch: 215| Step: 0
Training loss: 2.364513939554834
Validation loss: 2.5339582542615577

Epoch: 6| Step: 1
Training loss: 2.841602562622255
Validation loss: 2.506922170791786

Epoch: 6| Step: 2
Training loss: 2.0503691922341427
Validation loss: 2.5187147576057316

Epoch: 6| Step: 3
Training loss: 2.508459085077201
Validation loss: 2.517694622536039

Epoch: 6| Step: 4
Training loss: 2.628829433458182
Validation loss: 2.5204298902876396

Epoch: 6| Step: 5
Training loss: 2.5157130445154054
Validation loss: 2.509133991382852

Epoch: 6| Step: 6
Training loss: 2.622169512642813
Validation loss: 2.5200387303565903

Epoch: 6| Step: 7
Training loss: 2.0204772504409845
Validation loss: 2.517998006891745

Epoch: 6| Step: 8
Training loss: 2.2957191932768874
Validation loss: 2.532692526940008

Epoch: 6| Step: 9
Training loss: 2.207424432621063
Validation loss: 2.530221440199106

Epoch: 6| Step: 10
Training loss: 2.5832787989941233
Validation loss: 2.531745714236498

Epoch: 6| Step: 11
Training loss: 3.0531107938312982
Validation loss: 2.544309490452321

Epoch: 6| Step: 12
Training loss: 2.3698027110977757
Validation loss: 2.549268445321794

Epoch: 6| Step: 13
Training loss: 3.0468610714325064
Validation loss: 2.5779061392037974

Epoch: 216| Step: 0
Training loss: 3.0700512646299662
Validation loss: 2.572946480949496

Epoch: 6| Step: 1
Training loss: 3.1232235246026416
Validation loss: 2.5693571343221877

Epoch: 6| Step: 2
Training loss: 2.2752041064916106
Validation loss: 2.540150372836753

Epoch: 6| Step: 3
Training loss: 2.5014446852685452
Validation loss: 2.546479531220136

Epoch: 6| Step: 4
Training loss: 2.649395164706377
Validation loss: 2.5209448381328174

Epoch: 6| Step: 5
Training loss: 2.4092256056882686
Validation loss: 2.515663820799142

Epoch: 6| Step: 6
Training loss: 2.594158645978571
Validation loss: 2.4927852866611975

Epoch: 6| Step: 7
Training loss: 2.0549666646587936
Validation loss: 2.5020568195492308

Epoch: 6| Step: 8
Training loss: 2.706695844120304
Validation loss: 2.4839165914032035

Epoch: 6| Step: 9
Training loss: 2.3124093733891367
Validation loss: 2.505551397062482

Epoch: 6| Step: 10
Training loss: 2.3847888192463382
Validation loss: 2.5043727431308414

Epoch: 6| Step: 11
Training loss: 1.863816670198183
Validation loss: 2.535011788834509

Epoch: 6| Step: 12
Training loss: 2.4980808521194
Validation loss: 2.5474067946609393

Epoch: 6| Step: 13
Training loss: 2.310662544818393
Validation loss: 2.582166192421245

Epoch: 217| Step: 0
Training loss: 2.607282976315614
Validation loss: 2.604792019156285

Epoch: 6| Step: 1
Training loss: 2.6438985543865807
Validation loss: 2.5845013454623103

Epoch: 6| Step: 2
Training loss: 2.5281175610936213
Validation loss: 2.557757336959831

Epoch: 6| Step: 3
Training loss: 3.0579353101236264
Validation loss: 2.5165650584438257

Epoch: 6| Step: 4
Training loss: 1.9883853308035853
Validation loss: 2.4825368045083334

Epoch: 6| Step: 5
Training loss: 2.789687655613321
Validation loss: 2.4786772072022325

Epoch: 6| Step: 6
Training loss: 2.12326562451132
Validation loss: 2.469040928940763

Epoch: 6| Step: 7
Training loss: 2.994873594186207
Validation loss: 2.48187729738289

Epoch: 6| Step: 8
Training loss: 2.915111363215603
Validation loss: 2.4903500578051085

Epoch: 6| Step: 9
Training loss: 1.9287195905660324
Validation loss: 2.4941992352472617

Epoch: 6| Step: 10
Training loss: 1.5432394442139348
Validation loss: 2.5049859687324276

Epoch: 6| Step: 11
Training loss: 2.41562589618227
Validation loss: 2.52304915148582

Epoch: 6| Step: 12
Training loss: 2.4849451718335844
Validation loss: 2.543588113411808

Epoch: 6| Step: 13
Training loss: 3.082703878400307
Validation loss: 2.5638849771061882

Epoch: 218| Step: 0
Training loss: 2.831565660812353
Validation loss: 2.5524379709004203

Epoch: 6| Step: 1
Training loss: 2.221643951463964
Validation loss: 2.532267733668384

Epoch: 6| Step: 2
Training loss: 1.866982165422546
Validation loss: 2.517603445829903

Epoch: 6| Step: 3
Training loss: 2.806990928795606
Validation loss: 2.5039355055041055

Epoch: 6| Step: 4
Training loss: 2.918253076634566
Validation loss: 2.4918361131542732

Epoch: 6| Step: 5
Training loss: 2.9727682125145436
Validation loss: 2.493617035067385

Epoch: 6| Step: 6
Training loss: 2.8612777965923653
Validation loss: 2.490000567590384

Epoch: 6| Step: 7
Training loss: 2.51303014144096
Validation loss: 2.498286610710794

Epoch: 6| Step: 8
Training loss: 2.4325264293963826
Validation loss: 2.499190798923275

Epoch: 6| Step: 9
Training loss: 2.2358274207485453
Validation loss: 2.511451229908279

Epoch: 6| Step: 10
Training loss: 2.2310939787696196
Validation loss: 2.5371295608247606

Epoch: 6| Step: 11
Training loss: 2.1523893874188382
Validation loss: 2.518615117552247

Epoch: 6| Step: 12
Training loss: 1.9981071932908747
Validation loss: 2.5348450099460234

Epoch: 6| Step: 13
Training loss: 2.53252717751986
Validation loss: 2.552847107107223

Epoch: 219| Step: 0
Training loss: 1.958534500936203
Validation loss: 2.5506079558885757

Epoch: 6| Step: 1
Training loss: 2.3591759199820896
Validation loss: 2.570411582224192

Epoch: 6| Step: 2
Training loss: 2.2808749792078404
Validation loss: 2.591595714436558

Epoch: 6| Step: 3
Training loss: 2.8775722772318613
Validation loss: 2.619234330663286

Epoch: 6| Step: 4
Training loss: 2.7019364935967105
Validation loss: 2.6175045462379427

Epoch: 6| Step: 5
Training loss: 2.2220319732714193
Validation loss: 2.581724829833019

Epoch: 6| Step: 6
Training loss: 2.431331360541672
Validation loss: 2.536756599837908

Epoch: 6| Step: 7
Training loss: 2.2500827562159924
Validation loss: 2.5260000878580375

Epoch: 6| Step: 8
Training loss: 2.600946393532325
Validation loss: 2.5069972947475256

Epoch: 6| Step: 9
Training loss: 2.2742004163154435
Validation loss: 2.5039668001400157

Epoch: 6| Step: 10
Training loss: 2.8074832678658876
Validation loss: 2.4800491527174615

Epoch: 6| Step: 11
Training loss: 2.5477705241160726
Validation loss: 2.4762602451135693

Epoch: 6| Step: 12
Training loss: 2.6947661357466974
Validation loss: 2.485754310581706

Epoch: 6| Step: 13
Training loss: 2.9015865852864122
Validation loss: 2.4891906931861554

Epoch: 220| Step: 0
Training loss: 2.057251465481097
Validation loss: 2.486190274080585

Epoch: 6| Step: 1
Training loss: 3.1602120789451984
Validation loss: 2.492571133839894

Epoch: 6| Step: 2
Training loss: 2.270907117945642
Validation loss: 2.509008026086929

Epoch: 6| Step: 3
Training loss: 1.8995777363606499
Validation loss: 2.5179905704844088

Epoch: 6| Step: 4
Training loss: 2.5847519291801273
Validation loss: 2.537926822483328

Epoch: 6| Step: 5
Training loss: 2.488009499363075
Validation loss: 2.542352629886744

Epoch: 6| Step: 6
Training loss: 2.467782712314387
Validation loss: 2.5788359197879593

Epoch: 6| Step: 7
Training loss: 2.7152555962903446
Validation loss: 2.5782519108226993

Epoch: 6| Step: 8
Training loss: 2.6649783174015615
Validation loss: 2.5594355670218625

Epoch: 6| Step: 9
Training loss: 2.7359725209189123
Validation loss: 2.537704519098845

Epoch: 6| Step: 10
Training loss: 2.6705770630465637
Validation loss: 2.5301659492274156

Epoch: 6| Step: 11
Training loss: 1.8822920463771329
Validation loss: 2.485066311568971

Epoch: 6| Step: 12
Training loss: 2.1958751025440635
Validation loss: 2.474369886758907

Epoch: 6| Step: 13
Training loss: 2.753081156179117
Validation loss: 2.5014544757752906

Epoch: 221| Step: 0
Training loss: 2.4652927189286147
Validation loss: 2.4983733556014145

Epoch: 6| Step: 1
Training loss: 2.1633492406408172
Validation loss: 2.50366376139998

Epoch: 6| Step: 2
Training loss: 2.4414576166471287
Validation loss: 2.5239132881821496

Epoch: 6| Step: 3
Training loss: 2.572242174787517
Validation loss: 2.5356858567094513

Epoch: 6| Step: 4
Training loss: 2.2003682521913155
Validation loss: 2.5382737245072136

Epoch: 6| Step: 5
Training loss: 2.7276584641449313
Validation loss: 2.540291908802999

Epoch: 6| Step: 6
Training loss: 2.6190267448501703
Validation loss: 2.534482855532678

Epoch: 6| Step: 7
Training loss: 2.27574632999594
Validation loss: 2.547227837195502

Epoch: 6| Step: 8
Training loss: 3.082582915119862
Validation loss: 2.5478093280364646

Epoch: 6| Step: 9
Training loss: 2.003321512137693
Validation loss: 2.58029514433499

Epoch: 6| Step: 10
Training loss: 2.1511345597745835
Validation loss: 2.5564587980742437

Epoch: 6| Step: 11
Training loss: 2.4878508047282324
Validation loss: 2.556155574685397

Epoch: 6| Step: 12
Training loss: 2.2654753536920316
Validation loss: 2.5419029060153417

Epoch: 6| Step: 13
Training loss: 3.0560838088581828
Validation loss: 2.544128383416707

Epoch: 222| Step: 0
Training loss: 1.9438269891241506
Validation loss: 2.5198320808732797

Epoch: 6| Step: 1
Training loss: 1.8928007107160174
Validation loss: 2.4941856944310627

Epoch: 6| Step: 2
Training loss: 2.8275147512035947
Validation loss: 2.495145744643698

Epoch: 6| Step: 3
Training loss: 2.903786876771091
Validation loss: 2.4822865130202687

Epoch: 6| Step: 4
Training loss: 2.142703196127344
Validation loss: 2.470478493792201

Epoch: 6| Step: 5
Training loss: 2.5878360843309287
Validation loss: 2.453245684741457

Epoch: 6| Step: 6
Training loss: 2.7930404547176635
Validation loss: 2.4640018727301825

Epoch: 6| Step: 7
Training loss: 2.6478841648062956
Validation loss: 2.4809360386003814

Epoch: 6| Step: 8
Training loss: 2.554524547734476
Validation loss: 2.4986445054178934

Epoch: 6| Step: 9
Training loss: 2.2651563488553106
Validation loss: 2.5405828662287644

Epoch: 6| Step: 10
Training loss: 2.117342221845968
Validation loss: 2.542876940047586

Epoch: 6| Step: 11
Training loss: 2.622642093878192
Validation loss: 2.542739455835122

Epoch: 6| Step: 12
Training loss: 2.7861567729209815
Validation loss: 2.5788520541053996

Epoch: 6| Step: 13
Training loss: 2.075529729488234
Validation loss: 2.597363284467674

Epoch: 223| Step: 0
Training loss: 2.6738966047658828
Validation loss: 2.6198417055182928

Epoch: 6| Step: 1
Training loss: 2.654867912210817
Validation loss: 2.6166652422226315

Epoch: 6| Step: 2
Training loss: 2.5272851668913066
Validation loss: 2.5681163702671532

Epoch: 6| Step: 3
Training loss: 2.5947901467086973
Validation loss: 2.554943019630594

Epoch: 6| Step: 4
Training loss: 2.056297222859038
Validation loss: 2.5192571370233763

Epoch: 6| Step: 5
Training loss: 2.5455648410730816
Validation loss: 2.5390466671584906

Epoch: 6| Step: 6
Training loss: 2.308537361502015
Validation loss: 2.5127634710582654

Epoch: 6| Step: 7
Training loss: 2.403012760949194
Validation loss: 2.4890794007594437

Epoch: 6| Step: 8
Training loss: 2.1841160349221163
Validation loss: 2.4871383821333626

Epoch: 6| Step: 9
Training loss: 2.240985082744364
Validation loss: 2.4652608844787385

Epoch: 6| Step: 10
Training loss: 2.615440309263819
Validation loss: 2.4771928886490606

Epoch: 6| Step: 11
Training loss: 2.141319440705556
Validation loss: 2.48692380180683

Epoch: 6| Step: 12
Training loss: 2.9721666451682
Validation loss: 2.4856489973835867

Epoch: 6| Step: 13
Training loss: 2.7964482328144453
Validation loss: 2.4994169703893445

Epoch: 224| Step: 0
Training loss: 2.452835940685089
Validation loss: 2.5214194241313734

Epoch: 6| Step: 1
Training loss: 2.846297412154088
Validation loss: 2.5003362070659576

Epoch: 6| Step: 2
Training loss: 2.609818837685779
Validation loss: 2.503440706278077

Epoch: 6| Step: 3
Training loss: 2.5415351917052553
Validation loss: 2.505129914080464

Epoch: 6| Step: 4
Training loss: 2.6079031625099303
Validation loss: 2.5002680470731953

Epoch: 6| Step: 5
Training loss: 2.658556665906785
Validation loss: 2.508754566185876

Epoch: 6| Step: 6
Training loss: 1.808727547823231
Validation loss: 2.5006938730244253

Epoch: 6| Step: 7
Training loss: 2.670159129140595
Validation loss: 2.5248687179211418

Epoch: 6| Step: 8
Training loss: 2.455958970861023
Validation loss: 2.547754858088309

Epoch: 6| Step: 9
Training loss: 2.4938723808987246
Validation loss: 2.5375292095138025

Epoch: 6| Step: 10
Training loss: 2.1551087164838116
Validation loss: 2.531336000136909

Epoch: 6| Step: 11
Training loss: 2.491270560310379
Validation loss: 2.526589521430664

Epoch: 6| Step: 12
Training loss: 2.096938594757683
Validation loss: 2.529072902776937

Epoch: 6| Step: 13
Training loss: 2.1179970182518506
Validation loss: 2.5321670910653085

Epoch: 225| Step: 0
Training loss: 2.697959948650366
Validation loss: 2.549532741385231

Epoch: 6| Step: 1
Training loss: 2.712660887556966
Validation loss: 2.548853098171351

Epoch: 6| Step: 2
Training loss: 2.2781639650463577
Validation loss: 2.5830580256698417

Epoch: 6| Step: 3
Training loss: 2.12632889428009
Validation loss: 2.5646183173237103

Epoch: 6| Step: 4
Training loss: 2.4615340221346655
Validation loss: 2.5766756102200015

Epoch: 6| Step: 5
Training loss: 1.982774584733102
Validation loss: 2.5666351598359465

Epoch: 6| Step: 6
Training loss: 2.865709968729901
Validation loss: 2.5308552237546853

Epoch: 6| Step: 7
Training loss: 2.7630618874642527
Validation loss: 2.5110196833622243

Epoch: 6| Step: 8
Training loss: 2.3782459965125513
Validation loss: 2.507047137533541

Epoch: 6| Step: 9
Training loss: 2.25955418130803
Validation loss: 2.480043359824654

Epoch: 6| Step: 10
Training loss: 3.1733539309220515
Validation loss: 2.4651788968927764

Epoch: 6| Step: 11
Training loss: 2.205106561036478
Validation loss: 2.4660489108910943

Epoch: 6| Step: 12
Training loss: 1.9663298127114353
Validation loss: 2.472779628781577

Epoch: 6| Step: 13
Training loss: 1.9054229067659862
Validation loss: 2.4670466357642846

Epoch: 226| Step: 0
Training loss: 2.1502746495321032
Validation loss: 2.463796901083631

Epoch: 6| Step: 1
Training loss: 2.381672470783327
Validation loss: 2.47775949644338

Epoch: 6| Step: 2
Training loss: 2.972840392415862
Validation loss: 2.4912133105437277

Epoch: 6| Step: 3
Training loss: 2.1426228576831043
Validation loss: 2.4777937579644034

Epoch: 6| Step: 4
Training loss: 2.304261352451499
Validation loss: 2.511752809588869

Epoch: 6| Step: 5
Training loss: 2.306870076833891
Validation loss: 2.519356122822173

Epoch: 6| Step: 6
Training loss: 2.1301404822501953
Validation loss: 2.5264739972095427

Epoch: 6| Step: 7
Training loss: 3.2054494471832284
Validation loss: 2.548148033275847

Epoch: 6| Step: 8
Training loss: 2.4925534927306043
Validation loss: 2.553729239322756

Epoch: 6| Step: 9
Training loss: 2.510709236370948
Validation loss: 2.5675678417334202

Epoch: 6| Step: 10
Training loss: 1.9397198665543347
Validation loss: 2.5348967971128564

Epoch: 6| Step: 11
Training loss: 2.5034620155788354
Validation loss: 2.533726773679098

Epoch: 6| Step: 12
Training loss: 2.666496887365442
Validation loss: 2.521161711852781

Epoch: 6| Step: 13
Training loss: 2.0617640945287694
Validation loss: 2.508190310704933

Epoch: 227| Step: 0
Training loss: 2.787840503371958
Validation loss: 2.4964028649341716

Epoch: 6| Step: 1
Training loss: 2.6761368341230147
Validation loss: 2.504776366583772

Epoch: 6| Step: 2
Training loss: 2.2916886299699177
Validation loss: 2.505280247782765

Epoch: 6| Step: 3
Training loss: 2.28723988539352
Validation loss: 2.5132113442799637

Epoch: 6| Step: 4
Training loss: 2.0084232336581964
Validation loss: 2.5377041826954607

Epoch: 6| Step: 5
Training loss: 2.658435505863678
Validation loss: 2.5550129258470005

Epoch: 6| Step: 6
Training loss: 2.55226529050139
Validation loss: 2.558829598451966

Epoch: 6| Step: 7
Training loss: 2.4641357952820564
Validation loss: 2.5753333884545557

Epoch: 6| Step: 8
Training loss: 1.703659183827353
Validation loss: 2.5615734663284577

Epoch: 6| Step: 9
Training loss: 2.6278292531497773
Validation loss: 2.5656086623539593

Epoch: 6| Step: 10
Training loss: 2.7952781679402374
Validation loss: 2.5459726671467617

Epoch: 6| Step: 11
Training loss: 1.8414403382206208
Validation loss: 2.5003301658828443

Epoch: 6| Step: 12
Training loss: 2.587196619796668
Validation loss: 2.4943430240252193

Epoch: 6| Step: 13
Training loss: 2.6033522489530507
Validation loss: 2.4881524970141062

Epoch: 228| Step: 0
Training loss: 2.5684147933956925
Validation loss: 2.4775736499077365

Epoch: 6| Step: 1
Training loss: 2.606704533229566
Validation loss: 2.4664949985816302

Epoch: 6| Step: 2
Training loss: 1.8811574285803156
Validation loss: 2.458135523553824

Epoch: 6| Step: 3
Training loss: 1.6770654839302301
Validation loss: 2.4649408106599306

Epoch: 6| Step: 4
Training loss: 2.6445476582185763
Validation loss: 2.4735557963543355

Epoch: 6| Step: 5
Training loss: 1.9815993232716655
Validation loss: 2.4751340660111976

Epoch: 6| Step: 6
Training loss: 2.8862429834596934
Validation loss: 2.4761882030853455

Epoch: 6| Step: 7
Training loss: 2.6780376193058752
Validation loss: 2.5109717806702987

Epoch: 6| Step: 8
Training loss: 2.611020968168548
Validation loss: 2.5448352852914833

Epoch: 6| Step: 9
Training loss: 2.1020128412843526
Validation loss: 2.542810495028351

Epoch: 6| Step: 10
Training loss: 2.7494453391000473
Validation loss: 2.572076945839893

Epoch: 6| Step: 11
Training loss: 2.734769258686077
Validation loss: 2.5637401368193884

Epoch: 6| Step: 12
Training loss: 2.3116122423332657
Validation loss: 2.5262445799444944

Epoch: 6| Step: 13
Training loss: 2.1062091947955244
Validation loss: 2.5176307703712686

Epoch: 229| Step: 0
Training loss: 2.4700669264896224
Validation loss: 2.5280923617958218

Epoch: 6| Step: 1
Training loss: 2.596322404111733
Validation loss: 2.508333008212577

Epoch: 6| Step: 2
Training loss: 2.204183013316968
Validation loss: 2.4995083643379115

Epoch: 6| Step: 3
Training loss: 2.1787317292962407
Validation loss: 2.5070216906562046

Epoch: 6| Step: 4
Training loss: 1.9199771349260688
Validation loss: 2.4993433838625103

Epoch: 6| Step: 5
Training loss: 2.3923512129324336
Validation loss: 2.5076682506383867

Epoch: 6| Step: 6
Training loss: 2.3013299828450084
Validation loss: 2.492973623091901

Epoch: 6| Step: 7
Training loss: 2.3223804031638555
Validation loss: 2.5169497465253876

Epoch: 6| Step: 8
Training loss: 2.616075330682055
Validation loss: 2.500574720627932

Epoch: 6| Step: 9
Training loss: 2.387369370007519
Validation loss: 2.4947060923945923

Epoch: 6| Step: 10
Training loss: 2.667895828523945
Validation loss: 2.527069256939821

Epoch: 6| Step: 11
Training loss: 2.7346501675161834
Validation loss: 2.518327290250347

Epoch: 6| Step: 12
Training loss: 2.4019951792342242
Validation loss: 2.51368499672629

Epoch: 6| Step: 13
Training loss: 2.935095269445722
Validation loss: 2.5264714239014583

Epoch: 230| Step: 0
Training loss: 2.354710698915248
Validation loss: 2.5488377858011333

Epoch: 6| Step: 1
Training loss: 2.4905941452738074
Validation loss: 2.5250960245781586

Epoch: 6| Step: 2
Training loss: 2.188213667937634
Validation loss: 2.533246311378095

Epoch: 6| Step: 3
Training loss: 2.30958837780329
Validation loss: 2.5474962183624887

Epoch: 6| Step: 4
Training loss: 2.0500545122295635
Validation loss: 2.5371177961369873

Epoch: 6| Step: 5
Training loss: 2.527956857264851
Validation loss: 2.538678162469547

Epoch: 6| Step: 6
Training loss: 2.1186036726123283
Validation loss: 2.5535102432995105

Epoch: 6| Step: 7
Training loss: 2.1835930948819455
Validation loss: 2.5863060451453417

Epoch: 6| Step: 8
Training loss: 2.851761317180745
Validation loss: 2.6025988585105955

Epoch: 6| Step: 9
Training loss: 2.8409138044838382
Validation loss: 2.5813496191515224

Epoch: 6| Step: 10
Training loss: 2.9389187247819604
Validation loss: 2.5760806025209466

Epoch: 6| Step: 11
Training loss: 2.6536100845000385
Validation loss: 2.5225486123193077

Epoch: 6| Step: 12
Training loss: 1.845856320113891
Validation loss: 2.507739697555002

Epoch: 6| Step: 13
Training loss: 2.1591270160850042
Validation loss: 2.471713129902036

Epoch: 231| Step: 0
Training loss: 2.5643738199073702
Validation loss: 2.469130926312064

Epoch: 6| Step: 1
Training loss: 2.349562799082475
Validation loss: 2.4521295032327335

Epoch: 6| Step: 2
Training loss: 2.424547652695329
Validation loss: 2.4331231736868553

Epoch: 6| Step: 3
Training loss: 2.4376112105602235
Validation loss: 2.4434920074368365

Epoch: 6| Step: 4
Training loss: 2.434728758820645
Validation loss: 2.4462050514892084

Epoch: 6| Step: 5
Training loss: 1.6650706358122658
Validation loss: 2.4791854012507804

Epoch: 6| Step: 6
Training loss: 2.121852788120695
Validation loss: 2.4891174995460714

Epoch: 6| Step: 7
Training loss: 2.5009988696657453
Validation loss: 2.5035745036434736

Epoch: 6| Step: 8
Training loss: 2.4501875280117473
Validation loss: 2.5250842789545453

Epoch: 6| Step: 9
Training loss: 1.6311599180407346
Validation loss: 2.541589516555276

Epoch: 6| Step: 10
Training loss: 2.980821661097583
Validation loss: 2.5646103253591055

Epoch: 6| Step: 11
Training loss: 2.6615303064656444
Validation loss: 2.5858525881017793

Epoch: 6| Step: 12
Training loss: 2.412219186360488
Validation loss: 2.643945927863977

Epoch: 6| Step: 13
Training loss: 3.0240323371167404
Validation loss: 2.6851751312082093

Epoch: 232| Step: 0
Training loss: 2.2007642502241573
Validation loss: 2.699956152425847

Epoch: 6| Step: 1
Training loss: 2.353706269832937
Validation loss: 2.6928191901319827

Epoch: 6| Step: 2
Training loss: 2.511826389788706
Validation loss: 2.6655109151200076

Epoch: 6| Step: 3
Training loss: 2.7971818638398416
Validation loss: 2.5910360204923437

Epoch: 6| Step: 4
Training loss: 2.7188378681584746
Validation loss: 2.5106259330568816

Epoch: 6| Step: 5
Training loss: 2.464369158388393
Validation loss: 2.4776017760077287

Epoch: 6| Step: 6
Training loss: 2.7942386754517994
Validation loss: 2.4424260072055968

Epoch: 6| Step: 7
Training loss: 2.4163244816351375
Validation loss: 2.4244601231973473

Epoch: 6| Step: 8
Training loss: 2.1821939693848327
Validation loss: 2.4398500889361223

Epoch: 6| Step: 9
Training loss: 2.957256998896026
Validation loss: 2.435795890086393

Epoch: 6| Step: 10
Training loss: 2.4484118238124024
Validation loss: 2.430923409779048

Epoch: 6| Step: 11
Training loss: 2.1675714902076777
Validation loss: 2.4441460884229045

Epoch: 6| Step: 12
Training loss: 2.4265338019094402
Validation loss: 2.4714121506642703

Epoch: 6| Step: 13
Training loss: 2.029439383267622
Validation loss: 2.500279644738497

Epoch: 233| Step: 0
Training loss: 2.984831290788921
Validation loss: 2.575649535018059

Epoch: 6| Step: 1
Training loss: 2.7364919260840948
Validation loss: 2.664165871683335

Epoch: 6| Step: 2
Training loss: 2.3552687324383927
Validation loss: 2.7331336785002134

Epoch: 6| Step: 3
Training loss: 2.119760449028873
Validation loss: 2.731336141528689

Epoch: 6| Step: 4
Training loss: 2.9075081675735386
Validation loss: 2.7438492831492045

Epoch: 6| Step: 5
Training loss: 2.3430426992643927
Validation loss: 2.687970155846306

Epoch: 6| Step: 6
Training loss: 2.1033626065078668
Validation loss: 2.6054901025253243

Epoch: 6| Step: 7
Training loss: 2.3833603526186655
Validation loss: 2.555079783980426

Epoch: 6| Step: 8
Training loss: 1.9030895611950813
Validation loss: 2.5098610965609627

Epoch: 6| Step: 9
Training loss: 2.5059888632329765
Validation loss: 2.4831534124841053

Epoch: 6| Step: 10
Training loss: 2.4881920431725675
Validation loss: 2.4529033069802133

Epoch: 6| Step: 11
Training loss: 2.5143417023178065
Validation loss: 2.459234887506478

Epoch: 6| Step: 12
Training loss: 1.9682622638418683
Validation loss: 2.44894075949562

Epoch: 6| Step: 13
Training loss: 3.3519558620141634
Validation loss: 2.4421840694337447

Epoch: 234| Step: 0
Training loss: 2.5650827371441207
Validation loss: 2.446674921286672

Epoch: 6| Step: 1
Training loss: 2.3453292612268526
Validation loss: 2.4524205167312894

Epoch: 6| Step: 2
Training loss: 2.7896715028222316
Validation loss: 2.4426890300160573

Epoch: 6| Step: 3
Training loss: 2.786979517220523
Validation loss: 2.4525464793567116

Epoch: 6| Step: 4
Training loss: 2.1430523329346807
Validation loss: 2.454567924778668

Epoch: 6| Step: 5
Training loss: 2.5279507269282564
Validation loss: 2.4721512382378865

Epoch: 6| Step: 6
Training loss: 2.0757343050034756
Validation loss: 2.5203444161772013

Epoch: 6| Step: 7
Training loss: 1.9812766690068808
Validation loss: 2.5289034239486936

Epoch: 6| Step: 8
Training loss: 2.2385362409972953
Validation loss: 2.5591845950748913

Epoch: 6| Step: 9
Training loss: 2.596313680309546
Validation loss: 2.5714439646813076

Epoch: 6| Step: 10
Training loss: 2.386433835669107
Validation loss: 2.5781815757273954

Epoch: 6| Step: 11
Training loss: 2.6115659549804855
Validation loss: 2.5584680795198627

Epoch: 6| Step: 12
Training loss: 2.8324994561783217
Validation loss: 2.540979043898201

Epoch: 6| Step: 13
Training loss: 1.6762174025401995
Validation loss: 2.5283649985180485

Epoch: 235| Step: 0
Training loss: 2.3947098682488406
Validation loss: 2.522232155369747

Epoch: 6| Step: 1
Training loss: 2.5185896185840995
Validation loss: 2.525667639137743

Epoch: 6| Step: 2
Training loss: 2.1634402706046396
Validation loss: 2.5320041099831463

Epoch: 6| Step: 3
Training loss: 2.1249833947823182
Validation loss: 2.5314108968218183

Epoch: 6| Step: 4
Training loss: 2.3051164648128557
Validation loss: 2.5226154284290954

Epoch: 6| Step: 5
Training loss: 1.677442318739018
Validation loss: 2.522415765505363

Epoch: 6| Step: 6
Training loss: 2.2271599219070515
Validation loss: 2.5284722584180206

Epoch: 6| Step: 7
Training loss: 2.3766266121326916
Validation loss: 2.5123984591677195

Epoch: 6| Step: 8
Training loss: 2.249513467531744
Validation loss: 2.531530622197161

Epoch: 6| Step: 9
Training loss: 2.414402811204754
Validation loss: 2.514587300416896

Epoch: 6| Step: 10
Training loss: 2.389432223086557
Validation loss: 2.520071410973921

Epoch: 6| Step: 11
Training loss: 2.417921420174904
Validation loss: 2.4951949878416944

Epoch: 6| Step: 12
Training loss: 2.9765032264234454
Validation loss: 2.4792556371017413

Epoch: 6| Step: 13
Training loss: 3.459186050506541
Validation loss: 2.468715072972523

Epoch: 236| Step: 0
Training loss: 2.2478666788458517
Validation loss: 2.4805775050192302

Epoch: 6| Step: 1
Training loss: 2.72648047730987
Validation loss: 2.4751424918905705

Epoch: 6| Step: 2
Training loss: 2.736726632462153
Validation loss: 2.482344369887073

Epoch: 6| Step: 3
Training loss: 2.3396585993040966
Validation loss: 2.4978749893410273

Epoch: 6| Step: 4
Training loss: 2.5461031440404716
Validation loss: 2.496819968569872

Epoch: 6| Step: 5
Training loss: 1.7090611031882834
Validation loss: 2.501435050503415

Epoch: 6| Step: 6
Training loss: 2.506750529624645
Validation loss: 2.4999864957301154

Epoch: 6| Step: 7
Training loss: 1.8723429609181008
Validation loss: 2.515793816281524

Epoch: 6| Step: 8
Training loss: 2.62920279339506
Validation loss: 2.5267765658741923

Epoch: 6| Step: 9
Training loss: 2.0531492095402473
Validation loss: 2.51673736060076

Epoch: 6| Step: 10
Training loss: 2.1839662619699167
Validation loss: 2.5154252642745205

Epoch: 6| Step: 11
Training loss: 2.6710033221807925
Validation loss: 2.499551624164748

Epoch: 6| Step: 12
Training loss: 2.3271412659221222
Validation loss: 2.5113267671315813

Epoch: 6| Step: 13
Training loss: 2.5949248445244937
Validation loss: 2.5113003111316936

Epoch: 237| Step: 0
Training loss: 1.8435345540006658
Validation loss: 2.5137515466686255

Epoch: 6| Step: 1
Training loss: 2.1438045972983883
Validation loss: 2.5125665923078744

Epoch: 6| Step: 2
Training loss: 2.1854465110445322
Validation loss: 2.511253250899007

Epoch: 6| Step: 3
Training loss: 3.1843846374305986
Validation loss: 2.5305761536452827

Epoch: 6| Step: 4
Training loss: 2.7129421242974567
Validation loss: 2.569845054907847

Epoch: 6| Step: 5
Training loss: 2.4413011696136215
Validation loss: 2.5638457475450225

Epoch: 6| Step: 6
Training loss: 2.522842667804586
Validation loss: 2.5306943908800403

Epoch: 6| Step: 7
Training loss: 1.7153077073602758
Validation loss: 2.517083843286074

Epoch: 6| Step: 8
Training loss: 2.1024966521355535
Validation loss: 2.4978380935803313

Epoch: 6| Step: 9
Training loss: 2.6540965607475497
Validation loss: 2.49855500679179

Epoch: 6| Step: 10
Training loss: 2.680285506626802
Validation loss: 2.4848077239439905

Epoch: 6| Step: 11
Training loss: 2.1056952133542426
Validation loss: 2.4915572997616264

Epoch: 6| Step: 12
Training loss: 1.928749752378417
Validation loss: 2.473169687643229

Epoch: 6| Step: 13
Training loss: 2.6875444452913255
Validation loss: 2.486806068952949

Epoch: 238| Step: 0
Training loss: 3.312572838324329
Validation loss: 2.4825023637009447

Epoch: 6| Step: 1
Training loss: 2.7699370308890296
Validation loss: 2.4956925518247903

Epoch: 6| Step: 2
Training loss: 1.9731990256332816
Validation loss: 2.511494677016168

Epoch: 6| Step: 3
Training loss: 2.572712528506342
Validation loss: 2.5370378113853005

Epoch: 6| Step: 4
Training loss: 2.6031069824767554
Validation loss: 2.534868856689305

Epoch: 6| Step: 5
Training loss: 2.289077498351035
Validation loss: 2.5297497945185263

Epoch: 6| Step: 6
Training loss: 2.4031147533739
Validation loss: 2.515834048851294

Epoch: 6| Step: 7
Training loss: 2.0593551009610382
Validation loss: 2.507369136582696

Epoch: 6| Step: 8
Training loss: 1.8599039815914546
Validation loss: 2.5054122196802813

Epoch: 6| Step: 9
Training loss: 1.8814023383931286
Validation loss: 2.4943976664796916

Epoch: 6| Step: 10
Training loss: 2.271449632452759
Validation loss: 2.4963624629752337

Epoch: 6| Step: 11
Training loss: 2.0436336099222885
Validation loss: 2.488132044700261

Epoch: 6| Step: 12
Training loss: 2.216669638591103
Validation loss: 2.496265565235801

Epoch: 6| Step: 13
Training loss: 2.5891325881854916
Validation loss: 2.501526654598921

Epoch: 239| Step: 0
Training loss: 1.931208825521206
Validation loss: 2.4697250812363087

Epoch: 6| Step: 1
Training loss: 2.325248836204107
Validation loss: 2.4755502080324168

Epoch: 6| Step: 2
Training loss: 1.981388999322996
Validation loss: 2.5005347100499478

Epoch: 6| Step: 3
Training loss: 2.5087806045193646
Validation loss: 2.4828688826902465

Epoch: 6| Step: 4
Training loss: 2.0926260137499133
Validation loss: 2.4698783338610806

Epoch: 6| Step: 5
Training loss: 2.5352247137808583
Validation loss: 2.482259520295778

Epoch: 6| Step: 6
Training loss: 2.601804338275026
Validation loss: 2.482647907992125

Epoch: 6| Step: 7
Training loss: 2.9276340459794037
Validation loss: 2.4977063640120507

Epoch: 6| Step: 8
Training loss: 1.7590939068561484
Validation loss: 2.5147402800018166

Epoch: 6| Step: 9
Training loss: 2.3282551569046457
Validation loss: 2.55020325558617

Epoch: 6| Step: 10
Training loss: 2.7509269019246343
Validation loss: 2.5478190560918863

Epoch: 6| Step: 11
Training loss: 2.4963207828150034
Validation loss: 2.558549153818283

Epoch: 6| Step: 12
Training loss: 1.9714147910333466
Validation loss: 2.5652887579748964

Epoch: 6| Step: 13
Training loss: 2.364845250169866
Validation loss: 2.5356160263047554

Epoch: 240| Step: 0
Training loss: 1.8647343949088053
Validation loss: 2.542646867799509

Epoch: 6| Step: 1
Training loss: 2.1359297221334477
Validation loss: 2.5592650015740253

Epoch: 6| Step: 2
Training loss: 2.4950751433590734
Validation loss: 2.540526471384774

Epoch: 6| Step: 3
Training loss: 2.462536779603435
Validation loss: 2.5167938010905826

Epoch: 6| Step: 4
Training loss: 2.4895591149422405
Validation loss: 2.505613209927897

Epoch: 6| Step: 5
Training loss: 2.330334325552378
Validation loss: 2.5055906849818865

Epoch: 6| Step: 6
Training loss: 1.8598509748296579
Validation loss: 2.4917902244557557

Epoch: 6| Step: 7
Training loss: 2.202716113084323
Validation loss: 2.497776689755196

Epoch: 6| Step: 8
Training loss: 2.7975855090016073
Validation loss: 2.482956489387761

Epoch: 6| Step: 9
Training loss: 2.212131784262598
Validation loss: 2.5034801543010476

Epoch: 6| Step: 10
Training loss: 3.074183695301251
Validation loss: 2.5536915874789248

Epoch: 6| Step: 11
Training loss: 2.582093854136566
Validation loss: 2.566446979737864

Epoch: 6| Step: 12
Training loss: 2.1381204251237915
Validation loss: 2.5751071722449463

Epoch: 6| Step: 13
Training loss: 2.0810062254226445
Validation loss: 2.5547995287962113

Epoch: 241| Step: 0
Training loss: 2.713902415911375
Validation loss: 2.540683046306058

Epoch: 6| Step: 1
Training loss: 2.443577354947417
Validation loss: 2.525137034843868

Epoch: 6| Step: 2
Training loss: 2.417149122903826
Validation loss: 2.505771140792681

Epoch: 6| Step: 3
Training loss: 2.2388821472663865
Validation loss: 2.494084917161472

Epoch: 6| Step: 4
Training loss: 2.807545770151461
Validation loss: 2.4817982459410777

Epoch: 6| Step: 5
Training loss: 2.4192985366094697
Validation loss: 2.529828017416962

Epoch: 6| Step: 6
Training loss: 2.0538473405947233
Validation loss: 2.5186131952906226

Epoch: 6| Step: 7
Training loss: 1.7312482537766887
Validation loss: 2.506792941440323

Epoch: 6| Step: 8
Training loss: 2.306552145582876
Validation loss: 2.4996296608327198

Epoch: 6| Step: 9
Training loss: 2.3424866386692047
Validation loss: 2.5073327332775524

Epoch: 6| Step: 10
Training loss: 2.259476203815099
Validation loss: 2.5036126214610315

Epoch: 6| Step: 11
Training loss: 2.4475025448966115
Validation loss: 2.5122865876330165

Epoch: 6| Step: 12
Training loss: 2.1496809256899945
Validation loss: 2.5189674046055783

Epoch: 6| Step: 13
Training loss: 2.0757277579803772
Validation loss: 2.5603683633599403

Epoch: 242| Step: 0
Training loss: 2.072122955444601
Validation loss: 2.5693967945795304

Epoch: 6| Step: 1
Training loss: 2.5250005929776242
Validation loss: 2.6194622989333816

Epoch: 6| Step: 2
Training loss: 2.4966584762248756
Validation loss: 2.6089244913179375

Epoch: 6| Step: 3
Training loss: 2.212574059922535
Validation loss: 2.587022353121137

Epoch: 6| Step: 4
Training loss: 2.5419239997877634
Validation loss: 2.549800073594638

Epoch: 6| Step: 5
Training loss: 2.3115715018635132
Validation loss: 2.5206938681027893

Epoch: 6| Step: 6
Training loss: 2.607198755669099
Validation loss: 2.4972305216620097

Epoch: 6| Step: 7
Training loss: 1.9917654151324766
Validation loss: 2.482114502704451

Epoch: 6| Step: 8
Training loss: 2.191038158598079
Validation loss: 2.459832743839682

Epoch: 6| Step: 9
Training loss: 2.0337117463156007
Validation loss: 2.471756568150883

Epoch: 6| Step: 10
Training loss: 2.697396973347403
Validation loss: 2.486208956426423

Epoch: 6| Step: 11
Training loss: 2.412083972380156
Validation loss: 2.4889109777930667

Epoch: 6| Step: 12
Training loss: 2.2546273438272877
Validation loss: 2.5116240421143825

Epoch: 6| Step: 13
Training loss: 2.5078493870194105
Validation loss: 2.530267249958262

Epoch: 243| Step: 0
Training loss: 2.8594933990813214
Validation loss: 2.5231043661340813

Epoch: 6| Step: 1
Training loss: 2.359371261088459
Validation loss: 2.5164769306576575

Epoch: 6| Step: 2
Training loss: 2.011788554045316
Validation loss: 2.548907919806177

Epoch: 6| Step: 3
Training loss: 1.8412798482491686
Validation loss: 2.576871197285654

Epoch: 6| Step: 4
Training loss: 1.7147946709146307
Validation loss: 2.6078944882604747

Epoch: 6| Step: 5
Training loss: 2.497434444082614
Validation loss: 2.6229708789013952

Epoch: 6| Step: 6
Training loss: 2.38223549782595
Validation loss: 2.592063279263533

Epoch: 6| Step: 7
Training loss: 2.6264745113197008
Validation loss: 2.536222770166018

Epoch: 6| Step: 8
Training loss: 2.6702444890414254
Validation loss: 2.4543763456923733

Epoch: 6| Step: 9
Training loss: 2.486752026689117
Validation loss: 2.4538766255398405

Epoch: 6| Step: 10
Training loss: 2.821198131539134
Validation loss: 2.445182285473848

Epoch: 6| Step: 11
Training loss: 2.3682987638881587
Validation loss: 2.4237051239789897

Epoch: 6| Step: 12
Training loss: 2.12603981158786
Validation loss: 2.4294192485209822

Epoch: 6| Step: 13
Training loss: 1.378815818177077
Validation loss: 2.427448506306806

Epoch: 244| Step: 0
Training loss: 1.8297318138014138
Validation loss: 2.4360277406258093

Epoch: 6| Step: 1
Training loss: 2.4331820462719786
Validation loss: 2.4442655803066455

Epoch: 6| Step: 2
Training loss: 2.5529200421433393
Validation loss: 2.4803201672416417

Epoch: 6| Step: 3
Training loss: 2.098169928084744
Validation loss: 2.514481282654616

Epoch: 6| Step: 4
Training loss: 2.169456617467997
Validation loss: 2.574976092182873

Epoch: 6| Step: 5
Training loss: 2.5465072647191835
Validation loss: 2.601474021267568

Epoch: 6| Step: 6
Training loss: 2.3088915740898965
Validation loss: 2.6472359643089582

Epoch: 6| Step: 7
Training loss: 2.018110649976987
Validation loss: 2.657144995801899

Epoch: 6| Step: 8
Training loss: 1.9238068090506917
Validation loss: 2.615801071494239

Epoch: 6| Step: 9
Training loss: 1.8289803354281349
Validation loss: 2.6132274138811518

Epoch: 6| Step: 10
Training loss: 2.916979600376676
Validation loss: 2.5789481103539664

Epoch: 6| Step: 11
Training loss: 2.7719198023326657
Validation loss: 2.5363419601192394

Epoch: 6| Step: 12
Training loss: 2.4557205367248502
Validation loss: 2.5159183230044917

Epoch: 6| Step: 13
Training loss: 2.6479524151309537
Validation loss: 2.4828657592801244

Epoch: 245| Step: 0
Training loss: 1.482930494463551
Validation loss: 2.4800617700956145

Epoch: 6| Step: 1
Training loss: 1.9292314121704845
Validation loss: 2.462216028897222

Epoch: 6| Step: 2
Training loss: 2.136825196231664
Validation loss: 2.484305672514429

Epoch: 6| Step: 3
Training loss: 2.618357746909693
Validation loss: 2.4925583164838283

Epoch: 6| Step: 4
Training loss: 2.7493083257410422
Validation loss: 2.494008817834125

Epoch: 6| Step: 5
Training loss: 2.204212542551026
Validation loss: 2.5239184897832616

Epoch: 6| Step: 6
Training loss: 2.668617806298562
Validation loss: 2.5600241078326698

Epoch: 6| Step: 7
Training loss: 2.108254707388167
Validation loss: 2.6183862533240214

Epoch: 6| Step: 8
Training loss: 1.759106579321651
Validation loss: 2.6526941244443067

Epoch: 6| Step: 9
Training loss: 2.1213684466173506
Validation loss: 2.6434415924162122

Epoch: 6| Step: 10
Training loss: 2.892477565668489
Validation loss: 2.6813556500692433

Epoch: 6| Step: 11
Training loss: 2.7792792034860723
Validation loss: 2.6426444538006955

Epoch: 6| Step: 12
Training loss: 2.2003764870756752
Validation loss: 2.5504095948140706

Epoch: 6| Step: 13
Training loss: 2.399806026726299
Validation loss: 2.4954489229810943

Epoch: 246| Step: 0
Training loss: 2.072235251014439
Validation loss: 2.4955429862982768

Epoch: 6| Step: 1
Training loss: 2.368509760528289
Validation loss: 2.46712515192915

Epoch: 6| Step: 2
Training loss: 2.457827392067388
Validation loss: 2.443855674407352

Epoch: 6| Step: 3
Training loss: 3.0367400800398943
Validation loss: 2.4725027392610994

Epoch: 6| Step: 4
Training loss: 2.564205997410458
Validation loss: 2.455351847725613

Epoch: 6| Step: 5
Training loss: 2.0395852073008807
Validation loss: 2.460030592569684

Epoch: 6| Step: 6
Training loss: 2.4000895523212
Validation loss: 2.4627150957649504

Epoch: 6| Step: 7
Training loss: 1.5962967066253333
Validation loss: 2.497530766814067

Epoch: 6| Step: 8
Training loss: 2.0488507003195005
Validation loss: 2.5078219415911627

Epoch: 6| Step: 9
Training loss: 2.5412482141281134
Validation loss: 2.5473403742036744

Epoch: 6| Step: 10
Training loss: 2.214933740042424
Validation loss: 2.5999342049476577

Epoch: 6| Step: 11
Training loss: 2.243427850660271
Validation loss: 2.5996540616419344

Epoch: 6| Step: 12
Training loss: 1.9609828502988647
Validation loss: 2.573953338404527

Epoch: 6| Step: 13
Training loss: 2.4809550612107167
Validation loss: 2.576589430954813

Epoch: 247| Step: 0
Training loss: 2.290954016648192
Validation loss: 2.5725600704726026

Epoch: 6| Step: 1
Training loss: 1.8057737838063965
Validation loss: 2.5097324945481536

Epoch: 6| Step: 2
Training loss: 2.5879418479600447
Validation loss: 2.4824054908820097

Epoch: 6| Step: 3
Training loss: 2.0464613401860836
Validation loss: 2.473244560826542

Epoch: 6| Step: 4
Training loss: 2.20036987749988
Validation loss: 2.463433421202186

Epoch: 6| Step: 5
Training loss: 2.122292869894315
Validation loss: 2.4603818579651895

Epoch: 6| Step: 6
Training loss: 2.0044725001012385
Validation loss: 2.447869277387178

Epoch: 6| Step: 7
Training loss: 2.050017296322684
Validation loss: 2.4607814350635864

Epoch: 6| Step: 8
Training loss: 2.6526042377724828
Validation loss: 2.4835193997771583

Epoch: 6| Step: 9
Training loss: 2.6044524582763793
Validation loss: 2.4919147031622266

Epoch: 6| Step: 10
Training loss: 2.413087024325686
Validation loss: 2.5387475511765665

Epoch: 6| Step: 11
Training loss: 2.1081025983681587
Validation loss: 2.5614815375542737

Epoch: 6| Step: 12
Training loss: 2.739944453546551
Validation loss: 2.6063871784945882

Epoch: 6| Step: 13
Training loss: 2.1993585952012564
Validation loss: 2.632332183354531

Epoch: 248| Step: 0
Training loss: 2.081472812215707
Validation loss: 2.62690181563894

Epoch: 6| Step: 1
Training loss: 2.3918336293849407
Validation loss: 2.593890213391891

Epoch: 6| Step: 2
Training loss: 2.052014835460195
Validation loss: 2.5659220106563074

Epoch: 6| Step: 3
Training loss: 2.036648311355382
Validation loss: 2.532582535774022

Epoch: 6| Step: 4
Training loss: 2.3757757626501186
Validation loss: 2.483064755505614

Epoch: 6| Step: 5
Training loss: 2.0151875339069476
Validation loss: 2.462528733262358

Epoch: 6| Step: 6
Training loss: 2.7033392319652143
Validation loss: 2.448243948780816

Epoch: 6| Step: 7
Training loss: 1.671728680348783
Validation loss: 2.4647384778906627

Epoch: 6| Step: 8
Training loss: 2.6644229589123967
Validation loss: 2.481090937038053

Epoch: 6| Step: 9
Training loss: 2.724088579398516
Validation loss: 2.5088592717331113

Epoch: 6| Step: 10
Training loss: 2.550495686691756
Validation loss: 2.5339951299509886

Epoch: 6| Step: 11
Training loss: 2.1764087148917115
Validation loss: 2.5573737950791

Epoch: 6| Step: 12
Training loss: 2.2218175824307425
Validation loss: 2.5599013967873674

Epoch: 6| Step: 13
Training loss: 2.075333635095921
Validation loss: 2.6182196163799354

Epoch: 249| Step: 0
Training loss: 2.2831433943480803
Validation loss: 2.6326982345510515

Epoch: 6| Step: 1
Training loss: 2.3625127882838406
Validation loss: 2.610625363083273

Epoch: 6| Step: 2
Training loss: 2.243716154135449
Validation loss: 2.575751427695813

Epoch: 6| Step: 3
Training loss: 1.963977903548673
Validation loss: 2.550425573229447

Epoch: 6| Step: 4
Training loss: 2.2696801036665355
Validation loss: 2.501761679193852

Epoch: 6| Step: 5
Training loss: 1.6313799546899952
Validation loss: 2.4971353700301693

Epoch: 6| Step: 6
Training loss: 2.437362080120008
Validation loss: 2.4815759320914847

Epoch: 6| Step: 7
Training loss: 2.5626909138342517
Validation loss: 2.482809630156081

Epoch: 6| Step: 8
Training loss: 1.6155161306271908
Validation loss: 2.4855914232027194

Epoch: 6| Step: 9
Training loss: 2.5378927969750786
Validation loss: 2.5081815471381828

Epoch: 6| Step: 10
Training loss: 1.8354864337433308
Validation loss: 2.5426657891776943

Epoch: 6| Step: 11
Training loss: 2.889047388065111
Validation loss: 2.554352584480335

Epoch: 6| Step: 12
Training loss: 2.374859655148664
Validation loss: 2.5507859746950188

Epoch: 6| Step: 13
Training loss: 2.537236234739774
Validation loss: 2.5677440447550532

Epoch: 250| Step: 0
Training loss: 2.1867149034079914
Validation loss: 2.583657129962886

Epoch: 6| Step: 1
Training loss: 1.851267086880046
Validation loss: 2.583562799246496

Epoch: 6| Step: 2
Training loss: 2.355761660050185
Validation loss: 2.585150841148629

Epoch: 6| Step: 3
Training loss: 2.6638612195715923
Validation loss: 2.594856454182344

Epoch: 6| Step: 4
Training loss: 2.2941967147187743
Validation loss: 2.5225854505260226

Epoch: 6| Step: 5
Training loss: 2.3622126409568196
Validation loss: 2.471894799818979

Epoch: 6| Step: 6
Training loss: 2.299256420183359
Validation loss: 2.4773985659812774

Epoch: 6| Step: 7
Training loss: 2.5441184074688667
Validation loss: 2.4669955707034776

Epoch: 6| Step: 8
Training loss: 1.7513677837617128
Validation loss: 2.476624896641941

Epoch: 6| Step: 9
Training loss: 2.220586634443276
Validation loss: 2.470623857143501

Epoch: 6| Step: 10
Training loss: 1.7593614323636633
Validation loss: 2.501512009216799

Epoch: 6| Step: 11
Training loss: 2.3021540796332616
Validation loss: 2.5433721530971742

Epoch: 6| Step: 12
Training loss: 2.832517469037454
Validation loss: 2.5560927936148

Epoch: 6| Step: 13
Training loss: 2.0643946874859505
Validation loss: 2.529996949952415

Epoch: 251| Step: 0
Training loss: 2.2431561972679916
Validation loss: 2.5487046350104774

Epoch: 6| Step: 1
Training loss: 2.387931153677205
Validation loss: 2.5275456455551204

Epoch: 6| Step: 2
Training loss: 2.347169746349051
Validation loss: 2.509088068332201

Epoch: 6| Step: 3
Training loss: 2.2215879316560563
Validation loss: 2.5222963463934587

Epoch: 6| Step: 4
Training loss: 2.2620295968181106
Validation loss: 2.534653740410704

Epoch: 6| Step: 5
Training loss: 1.8172476183720483
Validation loss: 2.516292263658409

Epoch: 6| Step: 6
Training loss: 2.1527133631212925
Validation loss: 2.5186107264266377

Epoch: 6| Step: 7
Training loss: 2.7450554351211975
Validation loss: 2.5026982036561045

Epoch: 6| Step: 8
Training loss: 2.090421165485292
Validation loss: 2.4850594306633655

Epoch: 6| Step: 9
Training loss: 2.253198998620955
Validation loss: 2.4615351052745496

Epoch: 6| Step: 10
Training loss: 2.015863448831775
Validation loss: 2.471434843968855

Epoch: 6| Step: 11
Training loss: 1.866871316227377
Validation loss: 2.4934093560857744

Epoch: 6| Step: 12
Training loss: 2.6661753400533676
Validation loss: 2.5118949383201223

Epoch: 6| Step: 13
Training loss: 2.1815361469219683
Validation loss: 2.527052731139276

Epoch: 252| Step: 0
Training loss: 2.1845968327555982
Validation loss: 2.5331498590321555

Epoch: 6| Step: 1
Training loss: 2.2996201491779833
Validation loss: 2.571370324772261

Epoch: 6| Step: 2
Training loss: 2.177463723372117
Validation loss: 2.572964675838688

Epoch: 6| Step: 3
Training loss: 1.9717349478774768
Validation loss: 2.581100567440601

Epoch: 6| Step: 4
Training loss: 2.2483917422539474
Validation loss: 2.600299904638322

Epoch: 6| Step: 5
Training loss: 1.7193886697351257
Validation loss: 2.5786582159204694

Epoch: 6| Step: 6
Training loss: 2.7207508836047425
Validation loss: 2.573571818746798

Epoch: 6| Step: 7
Training loss: 2.6825558627978747
Validation loss: 2.5559609219680963

Epoch: 6| Step: 8
Training loss: 2.47907656551301
Validation loss: 2.542313604530246

Epoch: 6| Step: 9
Training loss: 1.9341381809296065
Validation loss: 2.5274780580604763

Epoch: 6| Step: 10
Training loss: 1.5704976442423206
Validation loss: 2.496415218917965

Epoch: 6| Step: 11
Training loss: 2.5368892817954
Validation loss: 2.5060245075635295

Epoch: 6| Step: 12
Training loss: 1.9721086100716723
Validation loss: 2.5191417874171256

Epoch: 6| Step: 13
Training loss: 2.5713416361115513
Validation loss: 2.535104011045339

Epoch: 253| Step: 0
Training loss: 2.1803861202600907
Validation loss: 2.5021091116782657

Epoch: 6| Step: 1
Training loss: 1.7995594704168958
Validation loss: 2.5250824037513886

Epoch: 6| Step: 2
Training loss: 2.1108266850771034
Validation loss: 2.5821565262533515

Epoch: 6| Step: 3
Training loss: 2.207032006187647
Validation loss: 2.572839655493138

Epoch: 6| Step: 4
Training loss: 2.1806175954730733
Validation loss: 2.5411122428652417

Epoch: 6| Step: 5
Training loss: 2.4821948195974715
Validation loss: 2.530751156769919

Epoch: 6| Step: 6
Training loss: 2.270962551068536
Validation loss: 2.5006856706120524

Epoch: 6| Step: 7
Training loss: 2.506876167595724
Validation loss: 2.5001078274761452

Epoch: 6| Step: 8
Training loss: 2.315389529056536
Validation loss: 2.487607848616799

Epoch: 6| Step: 9
Training loss: 2.1071438893276393
Validation loss: 2.497573612334658

Epoch: 6| Step: 10
Training loss: 2.2093426778929914
Validation loss: 2.4901269909593178

Epoch: 6| Step: 11
Training loss: 2.3080302162241955
Validation loss: 2.4956607589731417

Epoch: 6| Step: 12
Training loss: 2.3057261050261206
Validation loss: 2.536026226619501

Epoch: 6| Step: 13
Training loss: 2.4577048732233835
Validation loss: 2.585720129332063

Epoch: 254| Step: 0
Training loss: 2.7365895921708434
Validation loss: 2.6139470033544887

Epoch: 6| Step: 1
Training loss: 1.9091696970646537
Validation loss: 2.6273272375008143

Epoch: 6| Step: 2
Training loss: 2.2063378249024366
Validation loss: 2.5938266634591804

Epoch: 6| Step: 3
Training loss: 1.714126193481021
Validation loss: 2.5690525653691823

Epoch: 6| Step: 4
Training loss: 2.3551604162440136
Validation loss: 2.5001851420911816

Epoch: 6| Step: 5
Training loss: 2.6812789239634918
Validation loss: 2.4582766214722036

Epoch: 6| Step: 6
Training loss: 2.227591186609299
Validation loss: 2.4318638120239933

Epoch: 6| Step: 7
Training loss: 2.2591861123552412
Validation loss: 2.4229095239503757

Epoch: 6| Step: 8
Training loss: 2.658383757811574
Validation loss: 2.4187649778259694

Epoch: 6| Step: 9
Training loss: 2.6989988908231872
Validation loss: 2.4289372698476734

Epoch: 6| Step: 10
Training loss: 2.114636224796174
Validation loss: 2.427641723597715

Epoch: 6| Step: 11
Training loss: 1.6255373433146647
Validation loss: 2.4455211898549853

Epoch: 6| Step: 12
Training loss: 2.229005992006828
Validation loss: 2.4944707935719763

Epoch: 6| Step: 13
Training loss: 2.21958821541481
Validation loss: 2.567865911795899

Epoch: 255| Step: 0
Training loss: 1.9622818795252468
Validation loss: 2.648041981936343

Epoch: 6| Step: 1
Training loss: 1.743747030276159
Validation loss: 2.736724371136167

Epoch: 6| Step: 2
Training loss: 2.2421181697959414
Validation loss: 2.732071563372509

Epoch: 6| Step: 3
Training loss: 1.9091321075832657
Validation loss: 2.6953447437185725

Epoch: 6| Step: 4
Training loss: 1.8396668561707348
Validation loss: 2.6617984005819233

Epoch: 6| Step: 5
Training loss: 2.016562546913741
Validation loss: 2.6102776305149367

Epoch: 6| Step: 6
Training loss: 1.6369317036843216
Validation loss: 2.5697440763034716

Epoch: 6| Step: 7
Training loss: 2.8741574918829644
Validation loss: 2.5043605287211683

Epoch: 6| Step: 8
Training loss: 2.4153461685232718
Validation loss: 2.469335799877489

Epoch: 6| Step: 9
Training loss: 1.955160804242653
Validation loss: 2.4557522672709515

Epoch: 6| Step: 10
Training loss: 2.749794952377513
Validation loss: 2.4234484517581314

Epoch: 6| Step: 11
Training loss: 2.7929167629285367
Validation loss: 2.422905919586187

Epoch: 6| Step: 12
Training loss: 2.2953158945327288
Validation loss: 2.4181709165938385

Epoch: 6| Step: 13
Training loss: 2.998979394875642
Validation loss: 2.4461263721274054

Epoch: 256| Step: 0
Training loss: 1.9878675708719484
Validation loss: 2.46463934036799

Epoch: 6| Step: 1
Training loss: 1.8181597377780168
Validation loss: 2.5056177783285416

Epoch: 6| Step: 2
Training loss: 2.233029046846471
Validation loss: 2.5702291974411655

Epoch: 6| Step: 3
Training loss: 2.715105617709894
Validation loss: 2.6057441301338358

Epoch: 6| Step: 4
Training loss: 2.5268201329805877
Validation loss: 2.5834633129286666

Epoch: 6| Step: 5
Training loss: 1.9568673862831838
Validation loss: 2.5608543576254053

Epoch: 6| Step: 6
Training loss: 1.9406942677690213
Validation loss: 2.524355430697281

Epoch: 6| Step: 7
Training loss: 2.2006298030680598
Validation loss: 2.50830040053162

Epoch: 6| Step: 8
Training loss: 2.113371729015613
Validation loss: 2.4845344222463104

Epoch: 6| Step: 9
Training loss: 2.115546797824189
Validation loss: 2.477496035032865

Epoch: 6| Step: 10
Training loss: 2.1151204170956075
Validation loss: 2.4927102126232663

Epoch: 6| Step: 11
Training loss: 2.1484790035053676
Validation loss: 2.4646667309774903

Epoch: 6| Step: 12
Training loss: 2.750084875704363
Validation loss: 2.463385280014393

Epoch: 6| Step: 13
Training loss: 2.345377751001181
Validation loss: 2.5026805637628557

Epoch: 257| Step: 0
Training loss: 1.474054618718952
Validation loss: 2.508386782773508

Epoch: 6| Step: 1
Training loss: 1.8608856475806304
Validation loss: 2.524811523284468

Epoch: 6| Step: 2
Training loss: 1.926871650685466
Validation loss: 2.543968768091689

Epoch: 6| Step: 3
Training loss: 2.456770599561471
Validation loss: 2.5558310967728777

Epoch: 6| Step: 4
Training loss: 2.205175216875426
Validation loss: 2.5808734899180363

Epoch: 6| Step: 5
Training loss: 2.7280302715132176
Validation loss: 2.5604221254189756

Epoch: 6| Step: 6
Training loss: 2.242219718675042
Validation loss: 2.567739032273221

Epoch: 6| Step: 7
Training loss: 2.409745686832434
Validation loss: 2.5781327760541233

Epoch: 6| Step: 8
Training loss: 1.4022225245196511
Validation loss: 2.5604584007039586

Epoch: 6| Step: 9
Training loss: 1.856999779524043
Validation loss: 2.535890276621222

Epoch: 6| Step: 10
Training loss: 2.1944886966326433
Validation loss: 2.5037503374005805

Epoch: 6| Step: 11
Training loss: 2.542793513997525
Validation loss: 2.525942251018622

Epoch: 6| Step: 12
Training loss: 2.786154548033426
Validation loss: 2.5409580401471246

Epoch: 6| Step: 13
Training loss: 2.228322829015145
Validation loss: 2.5104804749349894

Epoch: 258| Step: 0
Training loss: 2.5165486979677474
Validation loss: 2.5180332002264176

Epoch: 6| Step: 1
Training loss: 2.738632288483329
Validation loss: 2.5273946400128

Epoch: 6| Step: 2
Training loss: 1.7390110498376712
Validation loss: 2.5445448886663837

Epoch: 6| Step: 3
Training loss: 1.9791725024756341
Validation loss: 2.560226201961211

Epoch: 6| Step: 4
Training loss: 1.5981622841207674
Validation loss: 2.579297473504841

Epoch: 6| Step: 5
Training loss: 2.8108630184804255
Validation loss: 2.5938136812871293

Epoch: 6| Step: 6
Training loss: 1.6317581349972676
Validation loss: 2.6017099427584673

Epoch: 6| Step: 7
Training loss: 2.399794502202535
Validation loss: 2.5902622028191113

Epoch: 6| Step: 8
Training loss: 2.1880283262661315
Validation loss: 2.5521124176182974

Epoch: 6| Step: 9
Training loss: 1.9680042368137685
Validation loss: 2.5627166642443777

Epoch: 6| Step: 10
Training loss: 2.105843533651115
Validation loss: 2.5357761213961263

Epoch: 6| Step: 11
Training loss: 1.7823061572551717
Validation loss: 2.5225895725342267

Epoch: 6| Step: 12
Training loss: 2.2715268840403833
Validation loss: 2.4959198316956104

Epoch: 6| Step: 13
Training loss: 2.7938953916535914
Validation loss: 2.459521028807645

Epoch: 259| Step: 0
Training loss: 2.0999232141897863
Validation loss: 2.47506828516364

Epoch: 6| Step: 1
Training loss: 2.414400046246062
Validation loss: 2.477852281017812

Epoch: 6| Step: 2
Training loss: 2.119471370358776
Validation loss: 2.4868735582791155

Epoch: 6| Step: 3
Training loss: 2.2630280442263806
Validation loss: 2.5587666154817694

Epoch: 6| Step: 4
Training loss: 2.134034418102024
Validation loss: 2.574327636897606

Epoch: 6| Step: 5
Training loss: 2.7229280486643646
Validation loss: 2.60173158922346

Epoch: 6| Step: 6
Training loss: 1.965901448469998
Validation loss: 2.6140727105184705

Epoch: 6| Step: 7
Training loss: 1.8736671160688518
Validation loss: 2.604244425607394

Epoch: 6| Step: 8
Training loss: 2.2455834381223916
Validation loss: 2.5609000869181693

Epoch: 6| Step: 9
Training loss: 2.2225311726807337
Validation loss: 2.541018690048273

Epoch: 6| Step: 10
Training loss: 2.080592246836274
Validation loss: 2.498477185896162

Epoch: 6| Step: 11
Training loss: 2.004067933101835
Validation loss: 2.5092502485392143

Epoch: 6| Step: 12
Training loss: 2.3668454366871936
Validation loss: 2.4773503019007244

Epoch: 6| Step: 13
Training loss: 2.2238940930226874
Validation loss: 2.4731346478484553

Epoch: 260| Step: 0
Training loss: 2.525290172257747
Validation loss: 2.4857141950110786

Epoch: 6| Step: 1
Training loss: 1.7340442238946396
Validation loss: 2.4739407101032076

Epoch: 6| Step: 2
Training loss: 1.5359625409744246
Validation loss: 2.4846851885048142

Epoch: 6| Step: 3
Training loss: 2.647214443955453
Validation loss: 2.482456212621036

Epoch: 6| Step: 4
Training loss: 1.8879323022189753
Validation loss: 2.4967208034369857

Epoch: 6| Step: 5
Training loss: 1.6918124444597882
Validation loss: 2.5134373266109598

Epoch: 6| Step: 6
Training loss: 1.884340165102523
Validation loss: 2.5031422791829363

Epoch: 6| Step: 7
Training loss: 2.6733512146590366
Validation loss: 2.5236950012142314

Epoch: 6| Step: 8
Training loss: 2.166622259222903
Validation loss: 2.5652021701785035

Epoch: 6| Step: 9
Training loss: 2.1822423694174335
Validation loss: 2.6079752508553495

Epoch: 6| Step: 10
Training loss: 2.4900211497255045
Validation loss: 2.6222022480716936

Epoch: 6| Step: 11
Training loss: 2.0535683720725872
Validation loss: 2.6370880347203007

Epoch: 6| Step: 12
Training loss: 2.5113309617233455
Validation loss: 2.567000883057196

Epoch: 6| Step: 13
Training loss: 2.385024547970395
Validation loss: 2.5207199498990756

Epoch: 261| Step: 0
Training loss: 1.7388360327601546
Validation loss: 2.4901151900348983

Epoch: 6| Step: 1
Training loss: 1.5571146665623596
Validation loss: 2.4970391429269707

Epoch: 6| Step: 2
Training loss: 2.1145798506183477
Validation loss: 2.483797295774549

Epoch: 6| Step: 3
Training loss: 2.2424414088867604
Validation loss: 2.500845257600268

Epoch: 6| Step: 4
Training loss: 2.4995730989270712
Validation loss: 2.4958657114919616

Epoch: 6| Step: 5
Training loss: 2.1581905312839575
Validation loss: 2.5090784294551907

Epoch: 6| Step: 6
Training loss: 2.0448796687830426
Validation loss: 2.5212806335999596

Epoch: 6| Step: 7
Training loss: 1.4812192599812921
Validation loss: 2.560561353431455

Epoch: 6| Step: 8
Training loss: 2.297394778028644
Validation loss: 2.5904121236156246

Epoch: 6| Step: 9
Training loss: 2.4000038226415072
Validation loss: 2.6202757514601878

Epoch: 6| Step: 10
Training loss: 2.7263304166201827
Validation loss: 2.6161893667416374

Epoch: 6| Step: 11
Training loss: 2.7223358184658624
Validation loss: 2.6464904022238978

Epoch: 6| Step: 12
Training loss: 2.243243351001296
Validation loss: 2.634394324380968

Epoch: 6| Step: 13
Training loss: 1.620055525734727
Validation loss: 2.6118214892260014

Epoch: 262| Step: 0
Training loss: 2.4369103134112984
Validation loss: 2.555014209165576

Epoch: 6| Step: 1
Training loss: 2.2975226287225525
Validation loss: 2.504296246491049

Epoch: 6| Step: 2
Training loss: 2.1610679427114587
Validation loss: 2.4304821291222383

Epoch: 6| Step: 3
Training loss: 2.040347808658576
Validation loss: 2.419066514435062

Epoch: 6| Step: 4
Training loss: 1.7695560411480817
Validation loss: 2.4493247927687523

Epoch: 6| Step: 5
Training loss: 2.0037363437656035
Validation loss: 2.465300565948686

Epoch: 6| Step: 6
Training loss: 2.19767313929366
Validation loss: 2.4853588882036286

Epoch: 6| Step: 7
Training loss: 2.2740903356184474
Validation loss: 2.499338183428017

Epoch: 6| Step: 8
Training loss: 2.4050476240807956
Validation loss: 2.5364853408857004

Epoch: 6| Step: 9
Training loss: 1.5859247216522614
Validation loss: 2.5276177324956444

Epoch: 6| Step: 10
Training loss: 1.915611418882832
Validation loss: 2.5609310177968867

Epoch: 6| Step: 11
Training loss: 2.488329062009988
Validation loss: 2.5611731682995083

Epoch: 6| Step: 12
Training loss: 2.1732421523939514
Validation loss: 2.5650189512315067

Epoch: 6| Step: 13
Training loss: 2.514093631909628
Validation loss: 2.6123122774139818

Epoch: 263| Step: 0
Training loss: 2.567851549427073
Validation loss: 2.6316486409268176

Epoch: 6| Step: 1
Training loss: 2.00345396771444
Validation loss: 2.640119306745039

Epoch: 6| Step: 2
Training loss: 1.974399755503239
Validation loss: 2.604322212414052

Epoch: 6| Step: 3
Training loss: 2.3642866533892484
Validation loss: 2.5523252086691075

Epoch: 6| Step: 4
Training loss: 1.799938807506981
Validation loss: 2.5043157928859023

Epoch: 6| Step: 5
Training loss: 2.0961358440436464
Validation loss: 2.4776802939622016

Epoch: 6| Step: 6
Training loss: 2.5550831712895437
Validation loss: 2.4614763734095746

Epoch: 6| Step: 7
Training loss: 2.30168561534922
Validation loss: 2.4660442390405573

Epoch: 6| Step: 8
Training loss: 2.060386152462572
Validation loss: 2.482195579746999

Epoch: 6| Step: 9
Training loss: 2.4478560311673783
Validation loss: 2.469477263797282

Epoch: 6| Step: 10
Training loss: 1.7848384248710352
Validation loss: 2.487273064692093

Epoch: 6| Step: 11
Training loss: 1.6954883536971237
Validation loss: 2.52615545278941

Epoch: 6| Step: 12
Training loss: 2.3189218380328738
Validation loss: 2.533196125891656

Epoch: 6| Step: 13
Training loss: 1.9848079059003632
Validation loss: 2.585075823486119

Epoch: 264| Step: 0
Training loss: 2.32624382465082
Validation loss: 2.6057024601546486

Epoch: 6| Step: 1
Training loss: 2.040519573765567
Validation loss: 2.5822316475889893

Epoch: 6| Step: 2
Training loss: 1.8305361896095735
Validation loss: 2.595993283674153

Epoch: 6| Step: 3
Training loss: 2.865602143341064
Validation loss: 2.5944100311222784

Epoch: 6| Step: 4
Training loss: 2.227139582219526
Validation loss: 2.581941488345648

Epoch: 6| Step: 5
Training loss: 1.8364483710971022
Validation loss: 2.5761713226996203

Epoch: 6| Step: 6
Training loss: 2.2185996635976655
Validation loss: 2.597597335035072

Epoch: 6| Step: 7
Training loss: 2.4721767930941905
Validation loss: 2.5917846398483966

Epoch: 6| Step: 8
Training loss: 1.7289914268338469
Validation loss: 2.5862611724764926

Epoch: 6| Step: 9
Training loss: 2.261368218700912
Validation loss: 2.5634927774864793

Epoch: 6| Step: 10
Training loss: 2.0824492931260443
Validation loss: 2.5391555827127226

Epoch: 6| Step: 11
Training loss: 1.7190804597311375
Validation loss: 2.536070206979334

Epoch: 6| Step: 12
Training loss: 1.9807052922488069
Validation loss: 2.5307120619158137

Epoch: 6| Step: 13
Training loss: 1.9461051214705969
Validation loss: 2.5431960124548594

Epoch: 265| Step: 0
Training loss: 2.1530842415947893
Validation loss: 2.5338767502955566

Epoch: 6| Step: 1
Training loss: 2.6185062559037418
Validation loss: 2.5098890212064884

Epoch: 6| Step: 2
Training loss: 2.3986479328301114
Validation loss: 2.497440831530938

Epoch: 6| Step: 3
Training loss: 1.953673079838055
Validation loss: 2.518102577516934

Epoch: 6| Step: 4
Training loss: 2.4647646255005067
Validation loss: 2.5415087172882234

Epoch: 6| Step: 5
Training loss: 2.5839136968910084
Validation loss: 2.5305894511145257

Epoch: 6| Step: 6
Training loss: 1.8670359274661703
Validation loss: 2.542450075202954

Epoch: 6| Step: 7
Training loss: 1.972670632489339
Validation loss: 2.586949108106907

Epoch: 6| Step: 8
Training loss: 1.9523683837215802
Validation loss: 2.5892752882539782

Epoch: 6| Step: 9
Training loss: 1.370162734717694
Validation loss: 2.605519683468455

Epoch: 6| Step: 10
Training loss: 2.2756207132862243
Validation loss: 2.621149837425085

Epoch: 6| Step: 11
Training loss: 1.765086809352322
Validation loss: 2.6278686026131104

Epoch: 6| Step: 12
Training loss: 1.6818487412959089
Validation loss: 2.6032226827015936

Epoch: 6| Step: 13
Training loss: 2.24016753864444
Validation loss: 2.6016986169188274

Epoch: 266| Step: 0
Training loss: 1.765111595386561
Validation loss: 2.5390675059885255

Epoch: 6| Step: 1
Training loss: 2.1343273330660533
Validation loss: 2.5434839838064423

Epoch: 6| Step: 2
Training loss: 2.0994022426898873
Validation loss: 2.529755923535639

Epoch: 6| Step: 3
Training loss: 2.4087248126516023
Validation loss: 2.5061919737863945

Epoch: 6| Step: 4
Training loss: 2.6956743522670648
Validation loss: 2.5125616314709704

Epoch: 6| Step: 5
Training loss: 1.9717682000934853
Validation loss: 2.5047178441708935

Epoch: 6| Step: 6
Training loss: 2.413584146357668
Validation loss: 2.550672736894762

Epoch: 6| Step: 7
Training loss: 2.193196318655283
Validation loss: 2.544612068185123

Epoch: 6| Step: 8
Training loss: 1.7530279530474262
Validation loss: 2.558960573900319

Epoch: 6| Step: 9
Training loss: 2.2293191542714474
Validation loss: 2.5914950323418973

Epoch: 6| Step: 10
Training loss: 2.3182367872497003
Validation loss: 2.6185522922460334

Epoch: 6| Step: 11
Training loss: 1.948501913784811
Validation loss: 2.621439363250497

Epoch: 6| Step: 12
Training loss: 1.8104999951792171
Validation loss: 2.5820459008582706

Epoch: 6| Step: 13
Training loss: 2.0367554222700583
Validation loss: 2.5675415893147275

Epoch: 267| Step: 0
Training loss: 2.0015119559631116
Validation loss: 2.5539342115802715

Epoch: 6| Step: 1
Training loss: 2.0549578470700713
Validation loss: 2.5750438452091173

Epoch: 6| Step: 2
Training loss: 2.0366597836134126
Validation loss: 2.555829534011811

Epoch: 6| Step: 3
Training loss: 1.4854886344749652
Validation loss: 2.5492329993608744

Epoch: 6| Step: 4
Training loss: 2.1667262460390924
Validation loss: 2.567022247465147

Epoch: 6| Step: 5
Training loss: 2.061321384172404
Validation loss: 2.556388663638798

Epoch: 6| Step: 6
Training loss: 2.35687770425565
Validation loss: 2.5540294694747514

Epoch: 6| Step: 7
Training loss: 2.1881638745687613
Validation loss: 2.5300727455277165

Epoch: 6| Step: 8
Training loss: 2.4486335408128355
Validation loss: 2.5064533046336033

Epoch: 6| Step: 9
Training loss: 2.888240015892775
Validation loss: 2.519895981537959

Epoch: 6| Step: 10
Training loss: 1.936697024415508
Validation loss: 2.5157298435199125

Epoch: 6| Step: 11
Training loss: 2.136083979352334
Validation loss: 2.5118393058043043

Epoch: 6| Step: 12
Training loss: 1.1633842591740782
Validation loss: 2.515697840224141

Epoch: 6| Step: 13
Training loss: 1.8756794652050806
Validation loss: 2.506731820888207

Epoch: 268| Step: 0
Training loss: 2.277986465239737
Validation loss: 2.5141830617434873

Epoch: 6| Step: 1
Training loss: 2.3057344806392472
Validation loss: 2.526646574355388

Epoch: 6| Step: 2
Training loss: 1.7206896847428417
Validation loss: 2.502889227014268

Epoch: 6| Step: 3
Training loss: 1.9572715383336872
Validation loss: 2.5018777522376134

Epoch: 6| Step: 4
Training loss: 2.288116155303557
Validation loss: 2.4929782784120427

Epoch: 6| Step: 5
Training loss: 1.9874065401187517
Validation loss: 2.4947935547043234

Epoch: 6| Step: 6
Training loss: 1.852371232348981
Validation loss: 2.5021886207927237

Epoch: 6| Step: 7
Training loss: 2.294860683193499
Validation loss: 2.4986354493016565

Epoch: 6| Step: 8
Training loss: 2.4254642592741615
Validation loss: 2.518202461820234

Epoch: 6| Step: 9
Training loss: 1.968684725209125
Validation loss: 2.5454956281300807

Epoch: 6| Step: 10
Training loss: 1.9881387895611355
Validation loss: 2.578893741413891

Epoch: 6| Step: 11
Training loss: 1.8825499165516744
Validation loss: 2.6018167110574235

Epoch: 6| Step: 12
Training loss: 2.25721357909084
Validation loss: 2.5973491088968172

Epoch: 6| Step: 13
Training loss: 2.086090882337718
Validation loss: 2.6075709989596247

Epoch: 269| Step: 0
Training loss: 1.9951547702231436
Validation loss: 2.6699321951357895

Epoch: 6| Step: 1
Training loss: 1.9698534703826176
Validation loss: 2.7201644410939245

Epoch: 6| Step: 2
Training loss: 1.9451708148389866
Validation loss: 2.659805073013476

Epoch: 6| Step: 3
Training loss: 2.198726727751231
Validation loss: 2.60927958636702

Epoch: 6| Step: 4
Training loss: 2.120147325327018
Validation loss: 2.512032743131831

Epoch: 6| Step: 5
Training loss: 2.111242527245531
Validation loss: 2.476575988109634

Epoch: 6| Step: 6
Training loss: 2.051697386515009
Validation loss: 2.4446336562128277

Epoch: 6| Step: 7
Training loss: 2.509156434456258
Validation loss: 2.4499665219311426

Epoch: 6| Step: 8
Training loss: 2.5617946491358006
Validation loss: 2.4239498093769445

Epoch: 6| Step: 9
Training loss: 1.6065258249438594
Validation loss: 2.429583262344958

Epoch: 6| Step: 10
Training loss: 2.710828883388966
Validation loss: 2.4378434505352136

Epoch: 6| Step: 11
Training loss: 1.6063741465287171
Validation loss: 2.451794011068262

Epoch: 6| Step: 12
Training loss: 2.2712653096280873
Validation loss: 2.4920633234763163

Epoch: 6| Step: 13
Training loss: 2.352171353319825
Validation loss: 2.516993512244946

Epoch: 270| Step: 0
Training loss: 1.8089937958197118
Validation loss: 2.5997941479152153

Epoch: 6| Step: 1
Training loss: 2.211311874774685
Validation loss: 2.6634448249016995

Epoch: 6| Step: 2
Training loss: 2.7576134801705017
Validation loss: 2.713936473480642

Epoch: 6| Step: 3
Training loss: 1.7284850037012238
Validation loss: 2.69277547548416

Epoch: 6| Step: 4
Training loss: 2.411413819881974
Validation loss: 2.6443950799601397

Epoch: 6| Step: 5
Training loss: 1.7515159580332453
Validation loss: 2.589894240932145

Epoch: 6| Step: 6
Training loss: 1.7195202575359967
Validation loss: 2.5372002781501415

Epoch: 6| Step: 7
Training loss: 1.9224378800494246
Validation loss: 2.501089874731098

Epoch: 6| Step: 8
Training loss: 1.8215331867638804
Validation loss: 2.4711678579502205

Epoch: 6| Step: 9
Training loss: 2.621123494236736
Validation loss: 2.4772465454316044

Epoch: 6| Step: 10
Training loss: 2.0468993440301513
Validation loss: 2.4646900231056987

Epoch: 6| Step: 11
Training loss: 1.8928907705029299
Validation loss: 2.471752386263427

Epoch: 6| Step: 12
Training loss: 2.536418018895377
Validation loss: 2.476152507156086

Epoch: 6| Step: 13
Training loss: 2.1635040774605616
Validation loss: 2.4848480780296622

Epoch: 271| Step: 0
Training loss: 2.012002691581852
Validation loss: 2.531988972130262

Epoch: 6| Step: 1
Training loss: 1.8923284249783274
Validation loss: 2.598477876601449

Epoch: 6| Step: 2
Training loss: 2.4008249335344534
Validation loss: 2.631622725283454

Epoch: 6| Step: 3
Training loss: 2.094439378805918
Validation loss: 2.6659465696861795

Epoch: 6| Step: 4
Training loss: 2.3676771406632775
Validation loss: 2.6749090567382923

Epoch: 6| Step: 5
Training loss: 1.9734987178437828
Validation loss: 2.630724879936883

Epoch: 6| Step: 6
Training loss: 1.220594721749182
Validation loss: 2.594513878617796

Epoch: 6| Step: 7
Training loss: 1.7248494898053248
Validation loss: 2.5399402246667413

Epoch: 6| Step: 8
Training loss: 2.2163864226289745
Validation loss: 2.5062020884255425

Epoch: 6| Step: 9
Training loss: 2.488784236164744
Validation loss: 2.489514137844555

Epoch: 6| Step: 10
Training loss: 2.125673972566462
Validation loss: 2.486926332537588

Epoch: 6| Step: 11
Training loss: 2.226358076381973
Validation loss: 2.502378031074468

Epoch: 6| Step: 12
Training loss: 2.2007589418298283
Validation loss: 2.5170756993763117

Epoch: 6| Step: 13
Training loss: 2.352698473123624
Validation loss: 2.5008731230009533

Epoch: 272| Step: 0
Training loss: 2.2655702781645806
Validation loss: 2.5345365334813326

Epoch: 6| Step: 1
Training loss: 2.1535332191726977
Validation loss: 2.5728237963508773

Epoch: 6| Step: 2
Training loss: 2.0307861972369072
Validation loss: 2.585391125781707

Epoch: 6| Step: 3
Training loss: 2.336925591051014
Validation loss: 2.6198047856239066

Epoch: 6| Step: 4
Training loss: 2.2907059013787276
Validation loss: 2.60644105557365

Epoch: 6| Step: 5
Training loss: 2.1654984430322046
Validation loss: 2.6050219017891965

Epoch: 6| Step: 6
Training loss: 1.7710714142766162
Validation loss: 2.5667732178564617

Epoch: 6| Step: 7
Training loss: 2.191858690308303
Validation loss: 2.5480487926235393

Epoch: 6| Step: 8
Training loss: 1.94367366530488
Validation loss: 2.536031582302973

Epoch: 6| Step: 9
Training loss: 1.805032540236734
Validation loss: 2.5099205776533515

Epoch: 6| Step: 10
Training loss: 1.5593769142276734
Validation loss: 2.5243846360738385

Epoch: 6| Step: 11
Training loss: 2.056294208271686
Validation loss: 2.508130889769794

Epoch: 6| Step: 12
Training loss: 2.3184453471053934
Validation loss: 2.511465499359427

Epoch: 6| Step: 13
Training loss: 1.7477102285821928
Validation loss: 2.539427416556332

Epoch: 273| Step: 0
Training loss: 2.0107584318567358
Validation loss: 2.5611253157955587

Epoch: 6| Step: 1
Training loss: 2.1890066135632464
Validation loss: 2.574827722922661

Epoch: 6| Step: 2
Training loss: 1.8508973033326648
Validation loss: 2.618095748489988

Epoch: 6| Step: 3
Training loss: 2.2072857465270075
Validation loss: 2.668052426398605

Epoch: 6| Step: 4
Training loss: 1.7679348580369025
Validation loss: 2.6848701856249155

Epoch: 6| Step: 5
Training loss: 2.1412649938233224
Validation loss: 2.6650008207712115

Epoch: 6| Step: 6
Training loss: 2.119344478242283
Validation loss: 2.6079758642475084

Epoch: 6| Step: 7
Training loss: 1.727477094661271
Validation loss: 2.5691409612386176

Epoch: 6| Step: 8
Training loss: 2.389451580411927
Validation loss: 2.531302342797211

Epoch: 6| Step: 9
Training loss: 2.21926325919318
Validation loss: 2.5295538446094037

Epoch: 6| Step: 10
Training loss: 2.253772963048791
Validation loss: 2.5156057717937403

Epoch: 6| Step: 11
Training loss: 1.868593524518491
Validation loss: 2.5164681511241485

Epoch: 6| Step: 12
Training loss: 1.8178227633625406
Validation loss: 2.49536144049277

Epoch: 6| Step: 13
Training loss: 2.4992854050729667
Validation loss: 2.5113011584303457

Epoch: 274| Step: 0
Training loss: 1.9969723553871601
Validation loss: 2.491228425523751

Epoch: 6| Step: 1
Training loss: 1.849112132664945
Validation loss: 2.531188855736053

Epoch: 6| Step: 2
Training loss: 2.065208967964226
Validation loss: 2.5118615471193686

Epoch: 6| Step: 3
Training loss: 2.2246835376411105
Validation loss: 2.5374347077439956

Epoch: 6| Step: 4
Training loss: 2.309388206351257
Validation loss: 2.5499578364692894

Epoch: 6| Step: 5
Training loss: 1.8068652863902808
Validation loss: 2.5599779853527957

Epoch: 6| Step: 6
Training loss: 1.850603394438606
Validation loss: 2.537839244563904

Epoch: 6| Step: 7
Training loss: 2.1188807174284117
Validation loss: 2.5417673701914967

Epoch: 6| Step: 8
Training loss: 2.265015303031644
Validation loss: 2.534137135141959

Epoch: 6| Step: 9
Training loss: 1.908050999585612
Validation loss: 2.562761673071075

Epoch: 6| Step: 10
Training loss: 1.8058695039293864
Validation loss: 2.618139477260207

Epoch: 6| Step: 11
Training loss: 2.430176517056474
Validation loss: 2.638820439587759

Epoch: 6| Step: 12
Training loss: 2.364792017753664
Validation loss: 2.647431788388052

Epoch: 6| Step: 13
Training loss: 2.053903872668841
Validation loss: 2.6056517545829343

Epoch: 275| Step: 0
Training loss: 1.9979772471716124
Validation loss: 2.558658742122268

Epoch: 6| Step: 1
Training loss: 1.7999547025491052
Validation loss: 2.5514113994236687

Epoch: 6| Step: 2
Training loss: 1.7265895651512717
Validation loss: 2.521833328407196

Epoch: 6| Step: 3
Training loss: 2.209641471019776
Validation loss: 2.5004271275696577

Epoch: 6| Step: 4
Training loss: 2.207775105391196
Validation loss: 2.4799586956277517

Epoch: 6| Step: 5
Training loss: 1.8957378517112773
Validation loss: 2.499993435020441

Epoch: 6| Step: 6
Training loss: 2.2209102161642957
Validation loss: 2.4913243265356515

Epoch: 6| Step: 7
Training loss: 1.8998934339453124
Validation loss: 2.510030158534645

Epoch: 6| Step: 8
Training loss: 2.0660368908360893
Validation loss: 2.5183915991281793

Epoch: 6| Step: 9
Training loss: 2.2821411064579586
Validation loss: 2.560157763897174

Epoch: 6| Step: 10
Training loss: 2.0060552484695204
Validation loss: 2.577076564192376

Epoch: 6| Step: 11
Training loss: 2.052195963858805
Validation loss: 2.6156615935510787

Epoch: 6| Step: 12
Training loss: 2.591409385479148
Validation loss: 2.6465458768377768

Epoch: 6| Step: 13
Training loss: 1.490602700248595
Validation loss: 2.6685706315965585

Epoch: 276| Step: 0
Training loss: 2.0031382258271693
Validation loss: 2.644542668195961

Epoch: 6| Step: 1
Training loss: 1.6628366889477504
Validation loss: 2.6514283198514

Epoch: 6| Step: 2
Training loss: 2.253649401120091
Validation loss: 2.614542527209853

Epoch: 6| Step: 3
Training loss: 1.562160455050312
Validation loss: 2.6277521314679437

Epoch: 6| Step: 4
Training loss: 2.1291470172769187
Validation loss: 2.6141921226554996

Epoch: 6| Step: 5
Training loss: 2.1101385924396006
Validation loss: 2.5774729511014596

Epoch: 6| Step: 6
Training loss: 1.8605214919930295
Validation loss: 2.5361137529201634

Epoch: 6| Step: 7
Training loss: 2.1268732005113673
Validation loss: 2.526374073609719

Epoch: 6| Step: 8
Training loss: 2.1580814931435244
Validation loss: 2.5291694061977514

Epoch: 6| Step: 9
Training loss: 2.3013747377586617
Validation loss: 2.515702620618115

Epoch: 6| Step: 10
Training loss: 2.1729743425633723
Validation loss: 2.4742377656509595

Epoch: 6| Step: 11
Training loss: 1.8376731946637688
Validation loss: 2.501924745973624

Epoch: 6| Step: 12
Training loss: 1.788345326433499
Validation loss: 2.486670794076828

Epoch: 6| Step: 13
Training loss: 2.2762185616498187
Validation loss: 2.4908413217217658

Epoch: 277| Step: 0
Training loss: 2.2686284644831733
Validation loss: 2.526626303764881

Epoch: 6| Step: 1
Training loss: 2.3699789678871706
Validation loss: 2.519464465044177

Epoch: 6| Step: 2
Training loss: 1.5945517075612656
Validation loss: 2.540844216530996

Epoch: 6| Step: 3
Training loss: 1.806394224117766
Validation loss: 2.584525549397178

Epoch: 6| Step: 4
Training loss: 1.97298986050088
Validation loss: 2.609514446534842

Epoch: 6| Step: 5
Training loss: 1.8028896343454779
Validation loss: 2.6072564143576193

Epoch: 6| Step: 6
Training loss: 2.1897191371839804
Validation loss: 2.6099190113265136

Epoch: 6| Step: 7
Training loss: 1.7639229596803194
Validation loss: 2.5749365855619173

Epoch: 6| Step: 8
Training loss: 1.9741476634141382
Validation loss: 2.5533999440721797

Epoch: 6| Step: 9
Training loss: 2.2696881921182297
Validation loss: 2.528924306825653

Epoch: 6| Step: 10
Training loss: 1.6655276300479818
Validation loss: 2.514418275683745

Epoch: 6| Step: 11
Training loss: 2.5592099910916684
Validation loss: 2.521894969902543

Epoch: 6| Step: 12
Training loss: 1.977123135754614
Validation loss: 2.5069373761529463

Epoch: 6| Step: 13
Training loss: 1.8096666881673469
Validation loss: 2.538097495687437

Epoch: 278| Step: 0
Training loss: 2.527560146683948
Validation loss: 2.576136189186169

Epoch: 6| Step: 1
Training loss: 1.9215219064774551
Validation loss: 2.601595895785609

Epoch: 6| Step: 2
Training loss: 1.8993746481289777
Validation loss: 2.630411144435121

Epoch: 6| Step: 3
Training loss: 1.6880363742199684
Validation loss: 2.6365223917887453

Epoch: 6| Step: 4
Training loss: 1.7326316663463692
Validation loss: 2.636534662903768

Epoch: 6| Step: 5
Training loss: 1.7096272507351709
Validation loss: 2.6119582954506684

Epoch: 6| Step: 6
Training loss: 2.041393482330373
Validation loss: 2.564095641372145

Epoch: 6| Step: 7
Training loss: 2.1794036352247175
Validation loss: 2.5593503628479177

Epoch: 6| Step: 8
Training loss: 1.8671426807594862
Validation loss: 2.550510622229529

Epoch: 6| Step: 9
Training loss: 2.0462032701007007
Validation loss: 2.5118157987084198

Epoch: 6| Step: 10
Training loss: 2.369477426563481
Validation loss: 2.512705486663391

Epoch: 6| Step: 11
Training loss: 2.1846516184369555
Validation loss: 2.5158913507730194

Epoch: 6| Step: 12
Training loss: 1.9420632799094388
Validation loss: 2.5398206605289864

Epoch: 6| Step: 13
Training loss: 1.8829676140802445
Validation loss: 2.5492594197068272

Epoch: 279| Step: 0
Training loss: 1.5899408484198394
Validation loss: 2.5499484493506754

Epoch: 6| Step: 1
Training loss: 1.899237005223705
Validation loss: 2.5743746738838786

Epoch: 6| Step: 2
Training loss: 2.442848402181363
Validation loss: 2.553518109370733

Epoch: 6| Step: 3
Training loss: 1.9847256808661984
Validation loss: 2.548488407631629

Epoch: 6| Step: 4
Training loss: 1.2948485018510743
Validation loss: 2.508856132653511

Epoch: 6| Step: 5
Training loss: 2.025860723605587
Validation loss: 2.5033518266478816

Epoch: 6| Step: 6
Training loss: 2.0085917938353464
Validation loss: 2.5135283892569036

Epoch: 6| Step: 7
Training loss: 2.0553100571074836
Validation loss: 2.4930499036379836

Epoch: 6| Step: 8
Training loss: 2.6823203273587612
Validation loss: 2.50581686400271

Epoch: 6| Step: 9
Training loss: 1.6397031828310435
Validation loss: 2.515684736130214

Epoch: 6| Step: 10
Training loss: 2.000084279191967
Validation loss: 2.520650822632617

Epoch: 6| Step: 11
Training loss: 2.1627703503206988
Validation loss: 2.5328531570239807

Epoch: 6| Step: 12
Training loss: 1.9001706849779472
Validation loss: 2.559036213869209

Epoch: 6| Step: 13
Training loss: 2.2444402031601385
Validation loss: 2.618793306534233

Epoch: 280| Step: 0
Training loss: 2.091499371569797
Validation loss: 2.6206871196433603

Epoch: 6| Step: 1
Training loss: 2.0461228714159962
Validation loss: 2.5911445751651936

Epoch: 6| Step: 2
Training loss: 1.805057240051423
Validation loss: 2.5518534861752515

Epoch: 6| Step: 3
Training loss: 1.8533222833253695
Validation loss: 2.5027856381429436

Epoch: 6| Step: 4
Training loss: 2.328010505062666
Validation loss: 2.4915846619744406

Epoch: 6| Step: 5
Training loss: 2.1301807753094684
Validation loss: 2.4733670095446296

Epoch: 6| Step: 6
Training loss: 1.9769065467037192
Validation loss: 2.4979374083294035

Epoch: 6| Step: 7
Training loss: 1.7403930180740326
Validation loss: 2.4980844378135716

Epoch: 6| Step: 8
Training loss: 1.8894237138258405
Validation loss: 2.524241963414674

Epoch: 6| Step: 9
Training loss: 2.184215368460233
Validation loss: 2.5646132382556557

Epoch: 6| Step: 10
Training loss: 2.1706362697705277
Validation loss: 2.579737091944284

Epoch: 6| Step: 11
Training loss: 1.367873058098446
Validation loss: 2.602448987634332

Epoch: 6| Step: 12
Training loss: 2.1705299438787224
Validation loss: 2.6273277136716158

Epoch: 6| Step: 13
Training loss: 2.254538197904246
Validation loss: 2.645071286340487

Epoch: 281| Step: 0
Training loss: 2.2679622827451498
Validation loss: 2.611063525289117

Epoch: 6| Step: 1
Training loss: 1.6982897795139131
Validation loss: 2.5814918129690225

Epoch: 6| Step: 2
Training loss: 1.5726537758456693
Validation loss: 2.564864255734666

Epoch: 6| Step: 3
Training loss: 1.578531496175393
Validation loss: 2.5433309621048172

Epoch: 6| Step: 4
Training loss: 2.316195962505084
Validation loss: 2.5386119296976126

Epoch: 6| Step: 5
Training loss: 2.007082439050468
Validation loss: 2.5543236264018807

Epoch: 6| Step: 6
Training loss: 2.3026264867511173
Validation loss: 2.552410108997337

Epoch: 6| Step: 7
Training loss: 2.389454474019257
Validation loss: 2.5673206484878675

Epoch: 6| Step: 8
Training loss: 1.359510042344968
Validation loss: 2.5787892708623885

Epoch: 6| Step: 9
Training loss: 2.336393688144919
Validation loss: 2.5775764923459676

Epoch: 6| Step: 10
Training loss: 1.6786902017516607
Validation loss: 2.603340401447328

Epoch: 6| Step: 11
Training loss: 1.8323753700706171
Validation loss: 2.63893391049603

Epoch: 6| Step: 12
Training loss: 2.106269528442771
Validation loss: 2.6307408392702434

Epoch: 6| Step: 13
Training loss: 1.9202259711565082
Validation loss: 2.62454363278452

Epoch: 282| Step: 0
Training loss: 1.2527822049427586
Validation loss: 2.6162645466247643

Epoch: 6| Step: 1
Training loss: 1.8881432504539
Validation loss: 2.6050114819607426

Epoch: 6| Step: 2
Training loss: 1.9696486102572164
Validation loss: 2.557529198253299

Epoch: 6| Step: 3
Training loss: 1.7403205482048847
Validation loss: 2.5501904695359157

Epoch: 6| Step: 4
Training loss: 2.600236342765504
Validation loss: 2.5465723206769275

Epoch: 6| Step: 5
Training loss: 2.2604496216605736
Validation loss: 2.5387344085270658

Epoch: 6| Step: 6
Training loss: 1.880105252667626
Validation loss: 2.525622768109235

Epoch: 6| Step: 7
Training loss: 1.7329241208448676
Validation loss: 2.5307466296870342

Epoch: 6| Step: 8
Training loss: 2.0894470408734915
Validation loss: 2.5354897578834725

Epoch: 6| Step: 9
Training loss: 2.0897525945730173
Validation loss: 2.5176816897192276

Epoch: 6| Step: 10
Training loss: 1.548167911777221
Validation loss: 2.5173259536802024

Epoch: 6| Step: 11
Training loss: 1.7395663536598425
Validation loss: 2.5177120874864243

Epoch: 6| Step: 12
Training loss: 2.5706458527776306
Validation loss: 2.562291360680574

Epoch: 6| Step: 13
Training loss: 1.3651811100906681
Validation loss: 2.584036521660448

Epoch: 283| Step: 0
Training loss: 2.233815690042233
Validation loss: 2.625522249054137

Epoch: 6| Step: 1
Training loss: 1.8739641507199634
Validation loss: 2.641530750919206

Epoch: 6| Step: 2
Training loss: 2.06997171152292
Validation loss: 2.624118873859863

Epoch: 6| Step: 3
Training loss: 2.0479314276421023
Validation loss: 2.5991887509896894

Epoch: 6| Step: 4
Training loss: 1.699837407583219
Validation loss: 2.5205289734419596

Epoch: 6| Step: 5
Training loss: 2.359159346065754
Validation loss: 2.4955714943966387

Epoch: 6| Step: 6
Training loss: 1.9063107840430653
Validation loss: 2.506480443887395

Epoch: 6| Step: 7
Training loss: 1.917902927861912
Validation loss: 2.477255549863025

Epoch: 6| Step: 8
Training loss: 2.290434546574054
Validation loss: 2.513831747135305

Epoch: 6| Step: 9
Training loss: 1.8671061605828616
Validation loss: 2.5191529969643267

Epoch: 6| Step: 10
Training loss: 1.7841513578757993
Validation loss: 2.522203344854156

Epoch: 6| Step: 11
Training loss: 1.3716034553133878
Validation loss: 2.557484698785253

Epoch: 6| Step: 12
Training loss: 2.043202140707808
Validation loss: 2.5900417396909203

Epoch: 6| Step: 13
Training loss: 2.1523929320322313
Validation loss: 2.632661284616841

Epoch: 284| Step: 0
Training loss: 1.779909533012627
Validation loss: 2.6232206893753243

Epoch: 6| Step: 1
Training loss: 1.8123899623748645
Validation loss: 2.6258373526621184

Epoch: 6| Step: 2
Training loss: 2.018389676182033
Validation loss: 2.5934036419972184

Epoch: 6| Step: 3
Training loss: 1.826485836355293
Validation loss: 2.591622078812103

Epoch: 6| Step: 4
Training loss: 2.2107000324521384
Validation loss: 2.593142363537998

Epoch: 6| Step: 5
Training loss: 2.111067481454556
Validation loss: 2.5495460460673054

Epoch: 6| Step: 6
Training loss: 2.007713820114257
Validation loss: 2.59071899466794

Epoch: 6| Step: 7
Training loss: 2.110924723690287
Validation loss: 2.576436651084348

Epoch: 6| Step: 8
Training loss: 1.9218628425523754
Validation loss: 2.5777204577131867

Epoch: 6| Step: 9
Training loss: 2.349696740407388
Validation loss: 2.6030674093851673

Epoch: 6| Step: 10
Training loss: 1.8139816016428152
Validation loss: 2.5865177744812886

Epoch: 6| Step: 11
Training loss: 1.9033241956973599
Validation loss: 2.6053482364548377

Epoch: 6| Step: 12
Training loss: 1.6366312008114359
Validation loss: 2.6049956553149762

Epoch: 6| Step: 13
Training loss: 1.7945644616394727
Validation loss: 2.5822614900040373

Epoch: 285| Step: 0
Training loss: 1.8707190916981484
Validation loss: 2.559425316187209

Epoch: 6| Step: 1
Training loss: 2.1178386292260654
Validation loss: 2.523603286511457

Epoch: 6| Step: 2
Training loss: 2.6077914429689297
Validation loss: 2.5098191604915154

Epoch: 6| Step: 3
Training loss: 1.7832431684261818
Validation loss: 2.4967330588151864

Epoch: 6| Step: 4
Training loss: 1.679038414738908
Validation loss: 2.4876897524221535

Epoch: 6| Step: 5
Training loss: 1.9275373456728726
Validation loss: 2.485434820707142

Epoch: 6| Step: 6
Training loss: 1.4951882273853982
Validation loss: 2.487480817978389

Epoch: 6| Step: 7
Training loss: 2.1602556919711158
Validation loss: 2.4895931275797607

Epoch: 6| Step: 8
Training loss: 2.142529162783766
Validation loss: 2.5020575936444414

Epoch: 6| Step: 9
Training loss: 1.876563818785802
Validation loss: 2.5223487560780584

Epoch: 6| Step: 10
Training loss: 2.070376758657836
Validation loss: 2.568702004446398

Epoch: 6| Step: 11
Training loss: 1.8178823072654753
Validation loss: 2.607382790183181

Epoch: 6| Step: 12
Training loss: 1.4689024176546082
Validation loss: 2.618707069340528

Epoch: 6| Step: 13
Training loss: 1.8338967526825254
Validation loss: 2.599998945594113

Epoch: 286| Step: 0
Training loss: 2.3485030743142485
Validation loss: 2.587585616987693

Epoch: 6| Step: 1
Training loss: 1.891989853708752
Validation loss: 2.569368672567824

Epoch: 6| Step: 2
Training loss: 1.8836038279886773
Validation loss: 2.5687687308407976

Epoch: 6| Step: 3
Training loss: 2.1176984670108667
Validation loss: 2.5727515879899396

Epoch: 6| Step: 4
Training loss: 1.536001346537874
Validation loss: 2.573573030054078

Epoch: 6| Step: 5
Training loss: 2.521560112298111
Validation loss: 2.5769512707878937

Epoch: 6| Step: 6
Training loss: 1.856918507428692
Validation loss: 2.5656768830753354

Epoch: 6| Step: 7
Training loss: 1.6876359107776153
Validation loss: 2.584126881183118

Epoch: 6| Step: 8
Training loss: 2.0185518527737716
Validation loss: 2.5657226478168487

Epoch: 6| Step: 9
Training loss: 1.7919402985505226
Validation loss: 2.55936915122156

Epoch: 6| Step: 10
Training loss: 1.698086767120766
Validation loss: 2.534141000624715

Epoch: 6| Step: 11
Training loss: 1.9615989268665583
Validation loss: 2.5363526797436955

Epoch: 6| Step: 12
Training loss: 1.8964487970159831
Validation loss: 2.5391208224859225

Epoch: 6| Step: 13
Training loss: 0.7442174356221909
Validation loss: 2.5683073542237254

Epoch: 287| Step: 0
Training loss: 1.5233820978507808
Validation loss: 2.5437999758225773

Epoch: 6| Step: 1
Training loss: 2.0593063597752144
Validation loss: 2.5444631011524774

Epoch: 6| Step: 2
Training loss: 1.642466501623049
Validation loss: 2.5757248919150997

Epoch: 6| Step: 3
Training loss: 1.9618437599205583
Validation loss: 2.5729208508569132

Epoch: 6| Step: 4
Training loss: 1.5654684479615393
Validation loss: 2.584206112812826

Epoch: 6| Step: 5
Training loss: 1.6969683598641085
Validation loss: 2.6237141955891605

Epoch: 6| Step: 6
Training loss: 2.201545744507966
Validation loss: 2.6360649350159533

Epoch: 6| Step: 7
Training loss: 2.1100174667213976
Validation loss: 2.622660839387114

Epoch: 6| Step: 8
Training loss: 1.772799204765238
Validation loss: 2.5872347194354393

Epoch: 6| Step: 9
Training loss: 2.194972544782981
Validation loss: 2.5539698833922593

Epoch: 6| Step: 10
Training loss: 2.2620313886223578
Validation loss: 2.522141234178639

Epoch: 6| Step: 11
Training loss: 1.9732090543691165
Validation loss: 2.4944737277373026

Epoch: 6| Step: 12
Training loss: 1.979025711929583
Validation loss: 2.5060531613789503

Epoch: 6| Step: 13
Training loss: 1.284942794743622
Validation loss: 2.525964430065997

Epoch: 288| Step: 0
Training loss: 1.8643372300478604
Validation loss: 2.538718742278796

Epoch: 6| Step: 1
Training loss: 1.6429611285690888
Validation loss: 2.596986583986104

Epoch: 6| Step: 2
Training loss: 1.0893236785723073
Validation loss: 2.598559851338426

Epoch: 6| Step: 3
Training loss: 1.9990710843086643
Validation loss: 2.605887143392089

Epoch: 6| Step: 4
Training loss: 1.9070064732162157
Validation loss: 2.5808185426858117

Epoch: 6| Step: 5
Training loss: 2.4354799165064067
Validation loss: 2.5786718331159757

Epoch: 6| Step: 6
Training loss: 1.7595970758974442
Validation loss: 2.5797519039009345

Epoch: 6| Step: 7
Training loss: 1.8534920211591444
Validation loss: 2.5980095355946786

Epoch: 6| Step: 8
Training loss: 2.289528444538755
Validation loss: 2.587207256043564

Epoch: 6| Step: 9
Training loss: 2.415288027692322
Validation loss: 2.6083874571784924

Epoch: 6| Step: 10
Training loss: 2.239647360189579
Validation loss: 2.580848616000442

Epoch: 6| Step: 11
Training loss: 1.3189157173929582
Validation loss: 2.570079363137048

Epoch: 6| Step: 12
Training loss: 1.294672555066071
Validation loss: 2.5808368022707753

Epoch: 6| Step: 13
Training loss: 2.3007101621153923
Validation loss: 2.558296845308734

Epoch: 289| Step: 0
Training loss: 1.9170589736599106
Validation loss: 2.533088954943158

Epoch: 6| Step: 1
Training loss: 2.0727797292082557
Validation loss: 2.5342131063259825

Epoch: 6| Step: 2
Training loss: 1.8728575864419104
Validation loss: 2.492120036795165

Epoch: 6| Step: 3
Training loss: 2.0739165407418514
Validation loss: 2.502611759769229

Epoch: 6| Step: 4
Training loss: 2.004433962100735
Validation loss: 2.499363286963919

Epoch: 6| Step: 5
Training loss: 1.557829475884263
Validation loss: 2.532464860455455

Epoch: 6| Step: 6
Training loss: 1.8355392998187752
Validation loss: 2.5638501971851535

Epoch: 6| Step: 7
Training loss: 1.9359467340700187
Validation loss: 2.5634639716632677

Epoch: 6| Step: 8
Training loss: 1.9875186439455423
Validation loss: 2.56319275062612

Epoch: 6| Step: 9
Training loss: 2.131952692347949
Validation loss: 2.567376238088318

Epoch: 6| Step: 10
Training loss: 1.9199458418598814
Validation loss: 2.5754512123527373

Epoch: 6| Step: 11
Training loss: 1.561499924092042
Validation loss: 2.587915907721016

Epoch: 6| Step: 12
Training loss: 1.8592815856548597
Validation loss: 2.569780260900874

Epoch: 6| Step: 13
Training loss: 1.8559767499486888
Validation loss: 2.573336809368401

Epoch: 290| Step: 0
Training loss: 1.603520680279029
Validation loss: 2.5793811033907263

Epoch: 6| Step: 1
Training loss: 2.5005062544358694
Validation loss: 2.617535817025761

Epoch: 6| Step: 2
Training loss: 2.2462347102507243
Validation loss: 2.6302155200458412

Epoch: 6| Step: 3
Training loss: 2.2008944643778032
Validation loss: 2.5905710738090457

Epoch: 6| Step: 4
Training loss: 1.3843947157306224
Validation loss: 2.5814470979393676

Epoch: 6| Step: 5
Training loss: 2.006058576251586
Validation loss: 2.57597321237819

Epoch: 6| Step: 6
Training loss: 2.327234392263578
Validation loss: 2.5872192428253937

Epoch: 6| Step: 7
Training loss: 1.5255761418377902
Validation loss: 2.5763008468332624

Epoch: 6| Step: 8
Training loss: 1.8150487934205952
Validation loss: 2.5944292217205436

Epoch: 6| Step: 9
Training loss: 1.7841028490313082
Validation loss: 2.6002808209580257

Epoch: 6| Step: 10
Training loss: 1.5901230325422042
Validation loss: 2.582402671651867

Epoch: 6| Step: 11
Training loss: 1.6020626868747652
Validation loss: 2.5454594095251815

Epoch: 6| Step: 12
Training loss: 1.4795211940225836
Validation loss: 2.5535229785922127

Epoch: 6| Step: 13
Training loss: 1.992339483709332
Validation loss: 2.5327009718727966

Epoch: 291| Step: 0
Training loss: 2.021326562001169
Validation loss: 2.50380425543571

Epoch: 6| Step: 1
Training loss: 1.6581236120420213
Validation loss: 2.572861709263524

Epoch: 6| Step: 2
Training loss: 1.6622913229629972
Validation loss: 2.607836763069316

Epoch: 6| Step: 3
Training loss: 2.053121688120129
Validation loss: 2.6340337572838206

Epoch: 6| Step: 4
Training loss: 1.1979174185487904
Validation loss: 2.620851804757948

Epoch: 6| Step: 5
Training loss: 1.9671925030342456
Validation loss: 2.636837245476813

Epoch: 6| Step: 6
Training loss: 1.974562405745473
Validation loss: 2.617805967444424

Epoch: 6| Step: 7
Training loss: 2.10418560158044
Validation loss: 2.612390870098824

Epoch: 6| Step: 8
Training loss: 2.5127584106255973
Validation loss: 2.580632409133475

Epoch: 6| Step: 9
Training loss: 2.0037187336120144
Validation loss: 2.559058985667315

Epoch: 6| Step: 10
Training loss: 1.9134947888552816
Validation loss: 2.5254545997168254

Epoch: 6| Step: 11
Training loss: 2.071665426158252
Validation loss: 2.5222253341833896

Epoch: 6| Step: 12
Training loss: 1.5040573242402797
Validation loss: 2.534407489240067

Epoch: 6| Step: 13
Training loss: 1.1981552328753777
Validation loss: 2.5676940413038203

Epoch: 292| Step: 0
Training loss: 1.6823466698440606
Validation loss: 2.561017919173666

Epoch: 6| Step: 1
Training loss: 1.517566656317266
Validation loss: 2.6065652137254967

Epoch: 6| Step: 2
Training loss: 1.6227749483115124
Validation loss: 2.645919291332377

Epoch: 6| Step: 3
Training loss: 1.413914878263272
Validation loss: 2.661985672398773

Epoch: 6| Step: 4
Training loss: 1.996368090744153
Validation loss: 2.707414647010087

Epoch: 6| Step: 5
Training loss: 1.9683075059407016
Validation loss: 2.7017754842086363

Epoch: 6| Step: 6
Training loss: 1.855509739473234
Validation loss: 2.660433506876002

Epoch: 6| Step: 7
Training loss: 1.8443638054647922
Validation loss: 2.6011129681489678

Epoch: 6| Step: 8
Training loss: 1.9003583821053944
Validation loss: 2.562355527649382

Epoch: 6| Step: 9
Training loss: 1.8149973665959194
Validation loss: 2.549125528120852

Epoch: 6| Step: 10
Training loss: 2.5974847952110403
Validation loss: 2.5333538561649767

Epoch: 6| Step: 11
Training loss: 2.121789863687489
Validation loss: 2.5205812286633886

Epoch: 6| Step: 12
Training loss: 2.100721907282894
Validation loss: 2.495718431626067

Epoch: 6| Step: 13
Training loss: 0.8671842695296318
Validation loss: 2.5152778148972934

Epoch: 293| Step: 0
Training loss: 2.254277296283676
Validation loss: 2.5346400758703393

Epoch: 6| Step: 1
Training loss: 1.1077556880700723
Validation loss: 2.5428005139101546

Epoch: 6| Step: 2
Training loss: 2.043465606780841
Validation loss: 2.5359850709786995

Epoch: 6| Step: 3
Training loss: 1.951055605367255
Validation loss: 2.551185147157341

Epoch: 6| Step: 4
Training loss: 1.2304772270758342
Validation loss: 2.5711976117053683

Epoch: 6| Step: 5
Training loss: 2.062553751851952
Validation loss: 2.5895063226576056

Epoch: 6| Step: 6
Training loss: 1.9347441362666002
Validation loss: 2.5850857107969762

Epoch: 6| Step: 7
Training loss: 1.5272727227830267
Validation loss: 2.5690818543718223

Epoch: 6| Step: 8
Training loss: 2.1331894090899923
Validation loss: 2.6010365401458424

Epoch: 6| Step: 9
Training loss: 1.8641860652363897
Validation loss: 2.6150114869733825

Epoch: 6| Step: 10
Training loss: 1.9882609248293461
Validation loss: 2.586776087362913

Epoch: 6| Step: 11
Training loss: 1.9082955813387077
Validation loss: 2.592635656518559

Epoch: 6| Step: 12
Training loss: 1.8263024268174257
Validation loss: 2.58593024905372

Epoch: 6| Step: 13
Training loss: 1.4568268578887358
Validation loss: 2.5228473167845844

Epoch: 294| Step: 0
Training loss: 2.009019778164261
Validation loss: 2.5516982778575583

Epoch: 6| Step: 1
Training loss: 1.3501126224729925
Validation loss: 2.5523048477188532

Epoch: 6| Step: 2
Training loss: 1.6834568047642564
Validation loss: 2.569410151554232

Epoch: 6| Step: 3
Training loss: 1.8948537650338713
Validation loss: 2.584031636521126

Epoch: 6| Step: 4
Training loss: 2.046797889247072
Validation loss: 2.61686330203679

Epoch: 6| Step: 5
Training loss: 1.4544180582620847
Validation loss: 2.619278638446282

Epoch: 6| Step: 6
Training loss: 1.8618089149018247
Validation loss: 2.5994348733774184

Epoch: 6| Step: 7
Training loss: 1.6757859450054422
Validation loss: 2.6147384604071875

Epoch: 6| Step: 8
Training loss: 1.9981601119931307
Validation loss: 2.602631778039439

Epoch: 6| Step: 9
Training loss: 1.7559634507748598
Validation loss: 2.5433204104911105

Epoch: 6| Step: 10
Training loss: 1.4753106679099
Validation loss: 2.563185971932876

Epoch: 6| Step: 11
Training loss: 2.28896917471872
Validation loss: 2.563364753906084

Epoch: 6| Step: 12
Training loss: 2.214903600244043
Validation loss: 2.550100091775024

Epoch: 6| Step: 13
Training loss: 1.739306543985857
Validation loss: 2.539583403081182

Epoch: 295| Step: 0
Training loss: 1.8835913602354188
Validation loss: 2.5458440812401637

Epoch: 6| Step: 1
Training loss: 1.825730475461181
Validation loss: 2.5446164910096276

Epoch: 6| Step: 2
Training loss: 2.246727364773825
Validation loss: 2.5276252775029366

Epoch: 6| Step: 3
Training loss: 2.481782436176942
Validation loss: 2.531108042996327

Epoch: 6| Step: 4
Training loss: 1.6731037366254764
Validation loss: 2.5297058633808454

Epoch: 6| Step: 5
Training loss: 1.644749497816685
Validation loss: 2.5668386265973195

Epoch: 6| Step: 6
Training loss: 1.3419421698962612
Validation loss: 2.5521610367886876

Epoch: 6| Step: 7
Training loss: 1.670943597911226
Validation loss: 2.570443609435626

Epoch: 6| Step: 8
Training loss: 1.8078564321179906
Validation loss: 2.564337373071847

Epoch: 6| Step: 9
Training loss: 1.81911891066665
Validation loss: 2.5817172344007564

Epoch: 6| Step: 10
Training loss: 1.865572434392481
Validation loss: 2.573138798635466

Epoch: 6| Step: 11
Training loss: 1.719813901902684
Validation loss: 2.595257808726443

Epoch: 6| Step: 12
Training loss: 1.123228055188167
Validation loss: 2.628905068089025

Epoch: 6| Step: 13
Training loss: 2.058980539890424
Validation loss: 2.617214006226362

Epoch: 296| Step: 0
Training loss: 1.6791914806315236
Validation loss: 2.59984804526609

Epoch: 6| Step: 1
Training loss: 2.190340541159931
Validation loss: 2.6081761890330037

Epoch: 6| Step: 2
Training loss: 2.04530938529294
Validation loss: 2.598786324555138

Epoch: 6| Step: 3
Training loss: 1.7430155201941535
Validation loss: 2.6118443386931456

Epoch: 6| Step: 4
Training loss: 1.904320287316015
Validation loss: 2.5998372171730817

Epoch: 6| Step: 5
Training loss: 1.5063619010165208
Validation loss: 2.5567656774051124

Epoch: 6| Step: 6
Training loss: 1.3113003198006976
Validation loss: 2.556001063904127

Epoch: 6| Step: 7
Training loss: 1.5628821859248696
Validation loss: 2.511657571204614

Epoch: 6| Step: 8
Training loss: 1.9881340526961124
Validation loss: 2.501696939751349

Epoch: 6| Step: 9
Training loss: 1.938042595472988
Validation loss: 2.535938295961168

Epoch: 6| Step: 10
Training loss: 1.865142724147192
Validation loss: 2.58084512244791

Epoch: 6| Step: 11
Training loss: 2.003612831451459
Validation loss: 2.608181805458336

Epoch: 6| Step: 12
Training loss: 2.02666319374155
Validation loss: 2.660929679361739

Epoch: 6| Step: 13
Training loss: 1.193934575136647
Validation loss: 2.6542550062341315

Epoch: 297| Step: 0
Training loss: 1.9227427562735395
Validation loss: 2.6590188156545933

Epoch: 6| Step: 1
Training loss: 2.1979404345729354
Validation loss: 2.639365844354796

Epoch: 6| Step: 2
Training loss: 1.2504911411525281
Validation loss: 2.634194722407615

Epoch: 6| Step: 3
Training loss: 1.853609844421831
Validation loss: 2.600566284647122

Epoch: 6| Step: 4
Training loss: 1.4608859292786203
Validation loss: 2.6010879842134895

Epoch: 6| Step: 5
Training loss: 1.9548261634438668
Validation loss: 2.5632436100070954

Epoch: 6| Step: 6
Training loss: 1.7785321297519645
Validation loss: 2.564388144770532

Epoch: 6| Step: 7
Training loss: 1.937610130871686
Validation loss: 2.5511036107146206

Epoch: 6| Step: 8
Training loss: 1.9896807888056223
Validation loss: 2.54229991662345

Epoch: 6| Step: 9
Training loss: 1.6735437923978094
Validation loss: 2.528837749217922

Epoch: 6| Step: 10
Training loss: 1.8747489761164577
Validation loss: 2.533671853757274

Epoch: 6| Step: 11
Training loss: 1.6911510953438533
Validation loss: 2.514235737417698

Epoch: 6| Step: 12
Training loss: 1.5743991189996844
Validation loss: 2.542253210397613

Epoch: 6| Step: 13
Training loss: 1.569603299603897
Validation loss: 2.521928084925189

Epoch: 298| Step: 0
Training loss: 2.081517941751523
Validation loss: 2.5333635243666115

Epoch: 6| Step: 1
Training loss: 1.5263994424624994
Validation loss: 2.5704833716128492

Epoch: 6| Step: 2
Training loss: 2.25618614043003
Validation loss: 2.563466789855924

Epoch: 6| Step: 3
Training loss: 1.7772422677715838
Validation loss: 2.567379315602079

Epoch: 6| Step: 4
Training loss: 1.3818659587065711
Validation loss: 2.5450156600685996

Epoch: 6| Step: 5
Training loss: 1.420851622134698
Validation loss: 2.548555806099846

Epoch: 6| Step: 6
Training loss: 1.6451055470842482
Validation loss: 2.532610611756357

Epoch: 6| Step: 7
Training loss: 2.154664935906033
Validation loss: 2.5625110448903885

Epoch: 6| Step: 8
Training loss: 1.7151882373057745
Validation loss: 2.554024840114962

Epoch: 6| Step: 9
Training loss: 1.5547742963169262
Validation loss: 2.582360164389398

Epoch: 6| Step: 10
Training loss: 2.0090423261134234
Validation loss: 2.625497359716573

Epoch: 6| Step: 11
Training loss: 1.8416831506304998
Validation loss: 2.598645538762464

Epoch: 6| Step: 12
Training loss: 1.9311127746617789
Validation loss: 2.606347149629607

Epoch: 6| Step: 13
Training loss: 1.3608493482944235
Validation loss: 2.588882551272475

Epoch: 299| Step: 0
Training loss: 2.2068430592470714
Validation loss: 2.6219690719433286

Epoch: 6| Step: 1
Training loss: 1.7853050253411322
Validation loss: 2.6103597277123853

Epoch: 6| Step: 2
Training loss: 2.084208368277966
Validation loss: 2.6254567853918376

Epoch: 6| Step: 3
Training loss: 1.8976639792613537
Validation loss: 2.6203667612852675

Epoch: 6| Step: 4
Training loss: 1.9684769577332704
Validation loss: 2.609679942801186

Epoch: 6| Step: 5
Training loss: 1.7935780672088426
Validation loss: 2.578045579489325

Epoch: 6| Step: 6
Training loss: 1.3626172653971154
Validation loss: 2.5404489189878494

Epoch: 6| Step: 7
Training loss: 2.01532169396138
Validation loss: 2.5211063336508492

Epoch: 6| Step: 8
Training loss: 1.6540744816663058
Validation loss: 2.5167153579553303

Epoch: 6| Step: 9
Training loss: 1.5391105992890413
Validation loss: 2.525076358826046

Epoch: 6| Step: 10
Training loss: 1.0204837485948712
Validation loss: 2.5049117751510925

Epoch: 6| Step: 11
Training loss: 1.513422279698843
Validation loss: 2.5329824383397637

Epoch: 6| Step: 12
Training loss: 2.1092968961596377
Validation loss: 2.5410010755548553

Epoch: 6| Step: 13
Training loss: 1.6992857470403866
Validation loss: 2.5606510846405137

Epoch: 300| Step: 0
Training loss: 2.116978934174655
Validation loss: 2.5846688038601755

Epoch: 6| Step: 1
Training loss: 2.154439636093072
Validation loss: 2.5923298598698854

Epoch: 6| Step: 2
Training loss: 1.8153112248701733
Validation loss: 2.6076725802572183

Epoch: 6| Step: 3
Training loss: 1.723351716632792
Validation loss: 2.5892131404363496

Epoch: 6| Step: 4
Training loss: 1.3829632693065637
Validation loss: 2.5993758409246857

Epoch: 6| Step: 5
Training loss: 1.4794206356460264
Validation loss: 2.574100086882428

Epoch: 6| Step: 6
Training loss: 1.6040247899848639
Validation loss: 2.558641061703145

Epoch: 6| Step: 7
Training loss: 1.8924031998584103
Validation loss: 2.587232125308784

Epoch: 6| Step: 8
Training loss: 1.9385515866306784
Validation loss: 2.57835308767637

Epoch: 6| Step: 9
Training loss: 1.287073346156162
Validation loss: 2.5851688638658175

Epoch: 6| Step: 10
Training loss: 1.9873541148644478
Validation loss: 2.58834677361773

Epoch: 6| Step: 11
Training loss: 1.8109593914245885
Validation loss: 2.6040604626728765

Epoch: 6| Step: 12
Training loss: 1.6853600107799755
Validation loss: 2.599632985626256

Epoch: 6| Step: 13
Training loss: 1.671011371909437
Validation loss: 2.62587120416427

Testing loss: 2.464690939197914
