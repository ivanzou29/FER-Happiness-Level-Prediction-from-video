Epoch: 1| Step: 0
Training loss: 4.669734954833984
Validation loss: 5.182062943776448

Epoch: 6| Step: 1
Training loss: 6.215950012207031
Validation loss: 5.173277752373808

Epoch: 6| Step: 2
Training loss: 4.9413838386535645
Validation loss: 5.165302548357236

Epoch: 6| Step: 3
Training loss: 5.328126907348633
Validation loss: 5.158093919036209

Epoch: 6| Step: 4
Training loss: 4.969600200653076
Validation loss: 5.15080395565238

Epoch: 6| Step: 5
Training loss: 5.544766426086426
Validation loss: 5.143135788620159

Epoch: 6| Step: 6
Training loss: 3.9132871627807617
Validation loss: 5.1352721183530745

Epoch: 6| Step: 7
Training loss: 3.057648181915283
Validation loss: 5.126663387462657

Epoch: 6| Step: 8
Training loss: 4.371006011962891
Validation loss: 5.1171509117208505

Epoch: 6| Step: 9
Training loss: 5.857718467712402
Validation loss: 5.107131999026063

Epoch: 6| Step: 10
Training loss: 5.71848201751709
Validation loss: 5.095984192304714

Epoch: 6| Step: 11
Training loss: 5.364355087280273
Validation loss: 5.0841226885395665

Epoch: 6| Step: 12
Training loss: 3.978980779647827
Validation loss: 5.07085108500655

Epoch: 6| Step: 13
Training loss: 5.048903465270996
Validation loss: 5.056490057258196

Epoch: 2| Step: 0
Training loss: 4.9485249519348145
Validation loss: 5.0406555514181814

Epoch: 6| Step: 1
Training loss: 4.6217803955078125
Validation loss: 5.024443318766933

Epoch: 6| Step: 2
Training loss: 4.674480438232422
Validation loss: 5.005979984037338

Epoch: 6| Step: 3
Training loss: 3.7883570194244385
Validation loss: 4.985508052251673

Epoch: 6| Step: 4
Training loss: 4.572804927825928
Validation loss: 4.964506041619085

Epoch: 6| Step: 5
Training loss: 4.202878952026367
Validation loss: 4.9409459380693335

Epoch: 6| Step: 6
Training loss: 5.155888557434082
Validation loss: 4.9165949872744985

Epoch: 6| Step: 7
Training loss: 4.474612236022949
Validation loss: 4.889277396663543

Epoch: 6| Step: 8
Training loss: 5.502182483673096
Validation loss: 4.860889337396109

Epoch: 6| Step: 9
Training loss: 5.0612897872924805
Validation loss: 4.828730434499761

Epoch: 6| Step: 10
Training loss: 5.313554763793945
Validation loss: 4.795824040648758

Epoch: 6| Step: 11
Training loss: 3.86032772064209
Validation loss: 4.762440640439269

Epoch: 6| Step: 12
Training loss: 4.3459320068359375
Validation loss: 4.7253135635006815

Epoch: 6| Step: 13
Training loss: 5.399806022644043
Validation loss: 4.6874479888587866

Epoch: 3| Step: 0
Training loss: 4.213965892791748
Validation loss: 4.650536665352442

Epoch: 6| Step: 1
Training loss: 5.152918338775635
Validation loss: 4.608619474595593

Epoch: 6| Step: 2
Training loss: 4.113852500915527
Validation loss: 4.566383192616124

Epoch: 6| Step: 3
Training loss: 3.6154704093933105
Validation loss: 4.523752576561384

Epoch: 6| Step: 4
Training loss: 5.567183017730713
Validation loss: 4.478001815016552

Epoch: 6| Step: 5
Training loss: 4.539269924163818
Validation loss: 4.431355789143552

Epoch: 6| Step: 6
Training loss: 3.438735008239746
Validation loss: 4.384966604171261

Epoch: 6| Step: 7
Training loss: 3.580909013748169
Validation loss: 4.335764331202353

Epoch: 6| Step: 8
Training loss: 4.029451370239258
Validation loss: 4.2882456471843104

Epoch: 6| Step: 9
Training loss: 4.656816005706787
Validation loss: 4.243179049543155

Epoch: 6| Step: 10
Training loss: 3.0187056064605713
Validation loss: 4.197254468035954

Epoch: 6| Step: 11
Training loss: 4.574678421020508
Validation loss: 4.152279720511488

Epoch: 6| Step: 12
Training loss: 4.330198287963867
Validation loss: 4.108751268797024

Epoch: 6| Step: 13
Training loss: 3.0400350093841553
Validation loss: 4.06118115045691

Epoch: 4| Step: 0
Training loss: 4.56665563583374
Validation loss: 4.019986644867928

Epoch: 6| Step: 1
Training loss: 4.058166980743408
Validation loss: 3.9799574088024836

Epoch: 6| Step: 2
Training loss: 4.425754070281982
Validation loss: 3.945470461281397

Epoch: 6| Step: 3
Training loss: 3.8619956970214844
Validation loss: 3.910345503078994

Epoch: 6| Step: 4
Training loss: 4.572906494140625
Validation loss: 3.8730658203042965

Epoch: 6| Step: 5
Training loss: 4.221517562866211
Validation loss: 3.840372557281166

Epoch: 6| Step: 6
Training loss: 1.8917975425720215
Validation loss: 3.8093708715131207

Epoch: 6| Step: 7
Training loss: 4.601955413818359
Validation loss: 3.7818678168840307

Epoch: 6| Step: 8
Training loss: 2.909337043762207
Validation loss: 3.761332442683558

Epoch: 6| Step: 9
Training loss: 3.1963930130004883
Validation loss: 3.7348237883660103

Epoch: 6| Step: 10
Training loss: 4.096867561340332
Validation loss: 3.7202638067224973

Epoch: 6| Step: 11
Training loss: 3.2187304496765137
Validation loss: 3.697965283547678

Epoch: 6| Step: 12
Training loss: 2.544495105743408
Validation loss: 3.6764513959166822

Epoch: 6| Step: 13
Training loss: 3.7042932510375977
Validation loss: 3.661638044541882

Epoch: 5| Step: 0
Training loss: 4.143465042114258
Validation loss: 3.6454253376171155

Epoch: 6| Step: 1
Training loss: 4.3289384841918945
Validation loss: 3.6317362298247633

Epoch: 6| Step: 2
Training loss: 3.1527161598205566
Validation loss: 3.6171361246416645

Epoch: 6| Step: 3
Training loss: 3.4455959796905518
Validation loss: 3.602675994237264

Epoch: 6| Step: 4
Training loss: 3.6426777839660645
Validation loss: 3.58739580903002

Epoch: 6| Step: 5
Training loss: 3.8639516830444336
Validation loss: 3.5711025422619236

Epoch: 6| Step: 6
Training loss: 2.9540390968322754
Validation loss: 3.5615765971522175

Epoch: 6| Step: 7
Training loss: 2.66021990776062
Validation loss: 3.5525340828844296

Epoch: 6| Step: 8
Training loss: 2.9418954849243164
Validation loss: 3.5389546194384174

Epoch: 6| Step: 9
Training loss: 4.23960018157959
Validation loss: 3.5280880133310952

Epoch: 6| Step: 10
Training loss: 4.6058502197265625
Validation loss: 3.5149493320013887

Epoch: 6| Step: 11
Training loss: 3.9442620277404785
Validation loss: 3.5031520628160044

Epoch: 6| Step: 12
Training loss: 2.4470252990722656
Validation loss: 3.493602209193732

Epoch: 6| Step: 13
Training loss: 1.7050039768218994
Validation loss: 3.4813279157043784

Epoch: 6| Step: 0
Training loss: 3.2343175411224365
Validation loss: 3.471574185996927

Epoch: 6| Step: 1
Training loss: 3.7944087982177734
Validation loss: 3.4591354195789625

Epoch: 6| Step: 2
Training loss: 3.548513889312744
Validation loss: 3.4505920307610625

Epoch: 6| Step: 3
Training loss: 3.494645595550537
Validation loss: 3.4387851735597015

Epoch: 6| Step: 4
Training loss: 3.2222437858581543
Validation loss: 3.4266365676797848

Epoch: 6| Step: 5
Training loss: 3.1541056632995605
Validation loss: 3.41601163084789

Epoch: 6| Step: 6
Training loss: 3.576559543609619
Validation loss: 3.4033598079476306

Epoch: 6| Step: 7
Training loss: 4.157553195953369
Validation loss: 3.393842404888522

Epoch: 6| Step: 8
Training loss: 3.0463528633117676
Validation loss: 3.383555942966092

Epoch: 6| Step: 9
Training loss: 2.9053707122802734
Validation loss: 3.3727331571681525

Epoch: 6| Step: 10
Training loss: 3.1844310760498047
Validation loss: 3.3642601043947282

Epoch: 6| Step: 11
Training loss: 2.6515746116638184
Validation loss: 3.3565470018694477

Epoch: 6| Step: 12
Training loss: 3.9869115352630615
Validation loss: 3.352372725804647

Epoch: 6| Step: 13
Training loss: 2.863784074783325
Validation loss: 3.345713105252994

Epoch: 7| Step: 0
Training loss: 1.5620417594909668
Validation loss: 3.348438160393828

Epoch: 6| Step: 1
Training loss: 3.2281315326690674
Validation loss: 3.3441372507361957

Epoch: 6| Step: 2
Training loss: 3.554016590118408
Validation loss: 3.3293659225586922

Epoch: 6| Step: 3
Training loss: 3.2402141094207764
Validation loss: 3.324436395399032

Epoch: 6| Step: 4
Training loss: 3.3272242546081543
Validation loss: 3.3214477262189313

Epoch: 6| Step: 5
Training loss: 3.997426986694336
Validation loss: 3.3185791533480407

Epoch: 6| Step: 6
Training loss: 3.689258575439453
Validation loss: 3.309105809016894

Epoch: 6| Step: 7
Training loss: 3.0597333908081055
Validation loss: 3.3007252267611924

Epoch: 6| Step: 8
Training loss: 2.8922080993652344
Validation loss: 3.29455417202365

Epoch: 6| Step: 9
Training loss: 3.029466152191162
Validation loss: 3.2887436907778502

Epoch: 6| Step: 10
Training loss: 3.64408278465271
Validation loss: 3.2875371184400333

Epoch: 6| Step: 11
Training loss: 3.4943089485168457
Validation loss: 3.2807330059748825

Epoch: 6| Step: 12
Training loss: 3.5954957008361816
Validation loss: 3.276574324536067

Epoch: 6| Step: 13
Training loss: 3.78446364402771
Validation loss: 3.2677326920211955

Epoch: 8| Step: 0
Training loss: 2.9342899322509766
Validation loss: 3.2608267927682526

Epoch: 6| Step: 1
Training loss: 2.5923666954040527
Validation loss: 3.251664894883351

Epoch: 6| Step: 2
Training loss: 2.693614959716797
Validation loss: 3.2423213066593295

Epoch: 6| Step: 3
Training loss: 2.8833541870117188
Validation loss: 3.2376422343715543

Epoch: 6| Step: 4
Training loss: 2.9961276054382324
Validation loss: 3.238109311749858

Epoch: 6| Step: 5
Training loss: 2.9449920654296875
Validation loss: 3.2335814763140935

Epoch: 6| Step: 6
Training loss: 3.2142372131347656
Validation loss: 3.223864645086309

Epoch: 6| Step: 7
Training loss: 3.9720261096954346
Validation loss: 3.212040824274863

Epoch: 6| Step: 8
Training loss: 3.017534017562866
Validation loss: 3.2000388663302184

Epoch: 6| Step: 9
Training loss: 3.855022668838501
Validation loss: 3.1990057422268774

Epoch: 6| Step: 10
Training loss: 3.9612836837768555
Validation loss: 3.195308603266234

Epoch: 6| Step: 11
Training loss: 2.680715560913086
Validation loss: 3.1810035705566406

Epoch: 6| Step: 12
Training loss: 3.7390050888061523
Validation loss: 3.1454898106154574

Epoch: 6| Step: 13
Training loss: 3.564953327178955
Validation loss: 3.131616623170914

Epoch: 9| Step: 0
Training loss: 3.5518343448638916
Validation loss: 3.1259427352618148

Epoch: 6| Step: 1
Training loss: 3.3163347244262695
Validation loss: 3.126773170245591

Epoch: 6| Step: 2
Training loss: 2.978745460510254
Validation loss: 3.114135957533313

Epoch: 6| Step: 3
Training loss: 3.2236292362213135
Validation loss: 3.1094487892684115

Epoch: 6| Step: 4
Training loss: 2.517882823944092
Validation loss: 3.1000181526266117

Epoch: 6| Step: 5
Training loss: 4.0073466300964355
Validation loss: 3.0915981390142955

Epoch: 6| Step: 6
Training loss: 2.113553047180176
Validation loss: 3.079573654359387

Epoch: 6| Step: 7
Training loss: 2.113483428955078
Validation loss: 3.077360576198947

Epoch: 6| Step: 8
Training loss: 3.215060234069824
Validation loss: 3.0724426366949595

Epoch: 6| Step: 9
Training loss: 2.3918185234069824
Validation loss: 3.076177571409492

Epoch: 6| Step: 10
Training loss: 3.6332039833068848
Validation loss: 3.126399468350154

Epoch: 6| Step: 11
Training loss: 3.179159164428711
Validation loss: 3.0625143563875588

Epoch: 6| Step: 12
Training loss: 4.10751485824585
Validation loss: 3.0484704125312065

Epoch: 6| Step: 13
Training loss: 3.6398141384124756
Validation loss: 3.057119213124757

Epoch: 10| Step: 0
Training loss: 2.4026973247528076
Validation loss: 3.0667372621515745

Epoch: 6| Step: 1
Training loss: 3.379364013671875
Validation loss: 3.083915630976359

Epoch: 6| Step: 2
Training loss: 3.6174373626708984
Validation loss: 3.074532795977849

Epoch: 6| Step: 3
Training loss: 3.1112771034240723
Validation loss: 3.0609431625694357

Epoch: 6| Step: 4
Training loss: 3.032517910003662
Validation loss: 3.0412427533057427

Epoch: 6| Step: 5
Training loss: 3.2531373500823975
Validation loss: 3.027915036806496

Epoch: 6| Step: 6
Training loss: 3.3604328632354736
Validation loss: 3.0289775427951606

Epoch: 6| Step: 7
Training loss: 2.6098320484161377
Validation loss: 3.052378293006651

Epoch: 6| Step: 8
Training loss: 2.5336897373199463
Validation loss: 3.0560526206929195

Epoch: 6| Step: 9
Training loss: 2.43981671333313
Validation loss: 3.046322222678892

Epoch: 6| Step: 10
Training loss: 3.5930800437927246
Validation loss: 3.0594421971228813

Epoch: 6| Step: 11
Training loss: 3.306436538696289
Validation loss: 3.0356373530562206

Epoch: 6| Step: 12
Training loss: 3.6962926387786865
Validation loss: 3.0124800615413214

Epoch: 6| Step: 13
Training loss: 2.8489770889282227
Validation loss: 2.998963071453956

Epoch: 11| Step: 0
Training loss: 3.502518653869629
Validation loss: 3.000902678376885

Epoch: 6| Step: 1
Training loss: 4.059641361236572
Validation loss: 3.0080275715038343

Epoch: 6| Step: 2
Training loss: 2.2752389907836914
Validation loss: 3.0067325715095765

Epoch: 6| Step: 3
Training loss: 3.231383800506592
Validation loss: 3.0114838410449285

Epoch: 6| Step: 4
Training loss: 2.9920597076416016
Validation loss: 3.008341714900027

Epoch: 6| Step: 5
Training loss: 2.7463393211364746
Validation loss: 2.9996798474301576

Epoch: 6| Step: 6
Training loss: 2.9679949283599854
Validation loss: 2.98634369655322

Epoch: 6| Step: 7
Training loss: 3.453490734100342
Validation loss: 2.9747689667568413

Epoch: 6| Step: 8
Training loss: 2.4576950073242188
Validation loss: 2.970583572182604

Epoch: 6| Step: 9
Training loss: 2.8809216022491455
Validation loss: 2.967418029744138

Epoch: 6| Step: 10
Training loss: 2.385585069656372
Validation loss: 2.9658102091922554

Epoch: 6| Step: 11
Training loss: 4.244354248046875
Validation loss: 2.9661861952914985

Epoch: 6| Step: 12
Training loss: 2.993040084838867
Validation loss: 2.9695399653527046

Epoch: 6| Step: 13
Training loss: 2.198390007019043
Validation loss: 2.967797140921316

Epoch: 12| Step: 0
Training loss: 3.379054069519043
Validation loss: 2.9606943925221763

Epoch: 6| Step: 1
Training loss: 3.1769847869873047
Validation loss: 2.9534074183433288

Epoch: 6| Step: 2
Training loss: 2.637432813644409
Validation loss: 2.945001704718477

Epoch: 6| Step: 3
Training loss: 3.5746076107025146
Validation loss: 2.939568022246002

Epoch: 6| Step: 4
Training loss: 3.3001999855041504
Validation loss: 2.937476578579154

Epoch: 6| Step: 5
Training loss: 2.418459892272949
Validation loss: 2.9350458396378385

Epoch: 6| Step: 6
Training loss: 2.9607300758361816
Validation loss: 2.9355090202823764

Epoch: 6| Step: 7
Training loss: 3.051938056945801
Validation loss: 2.9375358114960375

Epoch: 6| Step: 8
Training loss: 2.566831111907959
Validation loss: 2.9332603921172438

Epoch: 6| Step: 9
Training loss: 2.8776159286499023
Validation loss: 2.9302888967657603

Epoch: 6| Step: 10
Training loss: 3.038485527038574
Validation loss: 2.9242645309817408

Epoch: 6| Step: 11
Training loss: 3.619306802749634
Validation loss: 2.91900316105094

Epoch: 6| Step: 12
Training loss: 2.362623691558838
Validation loss: 2.9164915187384493

Epoch: 6| Step: 13
Training loss: 3.6843926906585693
Validation loss: 2.9124225006308606

Epoch: 13| Step: 0
Training loss: 2.5786960124969482
Validation loss: 2.912039884956934

Epoch: 6| Step: 1
Training loss: 3.413395404815674
Validation loss: 2.907977565642326

Epoch: 6| Step: 2
Training loss: 2.4175987243652344
Validation loss: 2.9113780683086765

Epoch: 6| Step: 3
Training loss: 1.6989316940307617
Validation loss: 2.9064936535332793

Epoch: 6| Step: 4
Training loss: 2.5776658058166504
Validation loss: 2.902979422641057

Epoch: 6| Step: 5
Training loss: 3.4064528942108154
Validation loss: 2.90289649655742

Epoch: 6| Step: 6
Training loss: 2.698819398880005
Validation loss: 2.8987031803336194

Epoch: 6| Step: 7
Training loss: 3.2097368240356445
Validation loss: 2.8962764329807733

Epoch: 6| Step: 8
Training loss: 3.5864222049713135
Validation loss: 2.8957401885781238

Epoch: 6| Step: 9
Training loss: 2.4538521766662598
Validation loss: 2.8901477654774985

Epoch: 6| Step: 10
Training loss: 3.200904607772827
Validation loss: 2.887252055188661

Epoch: 6| Step: 11
Training loss: 3.908517360687256
Validation loss: 2.8865020018751903

Epoch: 6| Step: 12
Training loss: 3.4906444549560547
Validation loss: 2.8832611678749003

Epoch: 6| Step: 13
Training loss: 3.4916157722473145
Validation loss: 2.880390756873674

Epoch: 14| Step: 0
Training loss: 3.326212167739868
Validation loss: 2.878474650844451

Epoch: 6| Step: 1
Training loss: 2.713676929473877
Validation loss: 2.870849335065452

Epoch: 6| Step: 2
Training loss: 2.396198272705078
Validation loss: 2.8698757592067925

Epoch: 6| Step: 3
Training loss: 3.079880714416504
Validation loss: 2.865937220152988

Epoch: 6| Step: 4
Training loss: 3.549415349960327
Validation loss: 2.86314901485238

Epoch: 6| Step: 5
Training loss: 3.372669219970703
Validation loss: 2.860857455961166

Epoch: 6| Step: 6
Training loss: 3.2365026473999023
Validation loss: 2.8594905407198015

Epoch: 6| Step: 7
Training loss: 1.762001395225525
Validation loss: 2.8579625339918238

Epoch: 6| Step: 8
Training loss: 1.9322619438171387
Validation loss: 2.858801331571353

Epoch: 6| Step: 9
Training loss: 3.245631694793701
Validation loss: 2.852688745785785

Epoch: 6| Step: 10
Training loss: 2.828577995300293
Validation loss: 2.85075407643472

Epoch: 6| Step: 11
Training loss: 3.4586830139160156
Validation loss: 2.8479068868903705

Epoch: 6| Step: 12
Training loss: 3.4742326736450195
Validation loss: 2.8458585995499805

Epoch: 6| Step: 13
Training loss: 3.327105760574341
Validation loss: 2.830976983552338

Epoch: 15| Step: 0
Training loss: 2.374917984008789
Validation loss: 2.8305328430668

Epoch: 6| Step: 1
Training loss: 3.366889715194702
Validation loss: 2.8262579748707433

Epoch: 6| Step: 2
Training loss: 4.126875877380371
Validation loss: 2.82946414204054

Epoch: 6| Step: 3
Training loss: 2.387509822845459
Validation loss: 2.8243668745922785

Epoch: 6| Step: 4
Training loss: 3.09480357170105
Validation loss: 2.8165215112829722

Epoch: 6| Step: 5
Training loss: 3.4268898963928223
Validation loss: 2.8103477442136375

Epoch: 6| Step: 6
Training loss: 3.01458740234375
Validation loss: 2.8080211352276545

Epoch: 6| Step: 7
Training loss: 2.6701178550720215
Validation loss: 2.803860374676284

Epoch: 6| Step: 8
Training loss: 3.075362205505371
Validation loss: 2.804278696736982

Epoch: 6| Step: 9
Training loss: 2.6153934001922607
Validation loss: 2.8022746860340075

Epoch: 6| Step: 10
Training loss: 2.463047504425049
Validation loss: 2.805494172598726

Epoch: 6| Step: 11
Training loss: 2.691200017929077
Validation loss: 2.8050962686538696

Epoch: 6| Step: 12
Training loss: 3.443340301513672
Validation loss: 2.7985900576396654

Epoch: 6| Step: 13
Training loss: 2.0250861644744873
Validation loss: 2.7827154667146745

Epoch: 16| Step: 0
Training loss: 3.2912449836730957
Validation loss: 2.787293916107506

Epoch: 6| Step: 1
Training loss: 2.5514798164367676
Validation loss: 2.7909798801586194

Epoch: 6| Step: 2
Training loss: 2.9133310317993164
Validation loss: 2.7937010488202496

Epoch: 6| Step: 3
Training loss: 3.361697196960449
Validation loss: 2.7858676782218357

Epoch: 6| Step: 4
Training loss: 3.0795085430145264
Validation loss: 2.780940624975389

Epoch: 6| Step: 5
Training loss: 2.2320146560668945
Validation loss: 2.7726888784798245

Epoch: 6| Step: 6
Training loss: 3.7795965671539307
Validation loss: 2.7707069022681123

Epoch: 6| Step: 7
Training loss: 3.310722827911377
Validation loss: 2.7699170317701114

Epoch: 6| Step: 8
Training loss: 2.64506196975708
Validation loss: 2.7702640974393455

Epoch: 6| Step: 9
Training loss: 2.820435047149658
Validation loss: 2.7699634439201763

Epoch: 6| Step: 10
Training loss: 2.479837417602539
Validation loss: 2.7632809326212895

Epoch: 6| Step: 11
Training loss: 2.303089141845703
Validation loss: 2.764616556065057

Epoch: 6| Step: 12
Training loss: 2.992638111114502
Validation loss: 2.762878869169502

Epoch: 6| Step: 13
Training loss: 3.198969602584839
Validation loss: 2.758273575895576

Epoch: 17| Step: 0
Training loss: 2.2731223106384277
Validation loss: 2.7564634764066307

Epoch: 6| Step: 1
Training loss: 3.0769095420837402
Validation loss: 2.752458285259944

Epoch: 6| Step: 2
Training loss: 1.958595633506775
Validation loss: 2.7522365354722544

Epoch: 6| Step: 3
Training loss: 2.844318389892578
Validation loss: 2.751362410924768

Epoch: 6| Step: 4
Training loss: 2.872426986694336
Validation loss: 2.751271119681738

Epoch: 6| Step: 5
Training loss: 3.157480239868164
Validation loss: 2.7609948906847226

Epoch: 6| Step: 6
Training loss: 2.3210806846618652
Validation loss: 2.764164945130707

Epoch: 6| Step: 7
Training loss: 3.3616790771484375
Validation loss: 2.8032146294911704

Epoch: 6| Step: 8
Training loss: 3.1718509197235107
Validation loss: 2.7627755877792195

Epoch: 6| Step: 9
Training loss: 3.560871124267578
Validation loss: 2.7369110225349345

Epoch: 6| Step: 10
Training loss: 3.360762119293213
Validation loss: 2.7425486169835573

Epoch: 6| Step: 11
Training loss: 3.310861110687256
Validation loss: 2.7481450214180896

Epoch: 6| Step: 12
Training loss: 2.8622965812683105
Validation loss: 2.7538786959904495

Epoch: 6| Step: 13
Training loss: 2.1494948863983154
Validation loss: 2.756456587904243

Epoch: 18| Step: 0
Training loss: 1.9699499607086182
Validation loss: 2.7567692033706175

Epoch: 6| Step: 1
Training loss: 2.8331198692321777
Validation loss: 2.7530954832671792

Epoch: 6| Step: 2
Training loss: 3.2213239669799805
Validation loss: 2.7550028601000385

Epoch: 6| Step: 3
Training loss: 3.5143184661865234
Validation loss: 2.7507561432418

Epoch: 6| Step: 4
Training loss: 3.4331881999969482
Validation loss: 2.7458746817804154

Epoch: 6| Step: 5
Training loss: 2.664740800857544
Validation loss: 2.73598510988297

Epoch: 6| Step: 6
Training loss: 3.087501287460327
Validation loss: 2.734274302759478

Epoch: 6| Step: 7
Training loss: 3.108306884765625
Validation loss: 2.7298575293633247

Epoch: 6| Step: 8
Training loss: 2.742798089981079
Validation loss: 2.7345204737878617

Epoch: 6| Step: 9
Training loss: 2.7725961208343506
Validation loss: 2.729070863416118

Epoch: 6| Step: 10
Training loss: 3.6574454307556152
Validation loss: 2.7267126780684277

Epoch: 6| Step: 11
Training loss: 1.410420536994934
Validation loss: 2.7264712907934703

Epoch: 6| Step: 12
Training loss: 3.379481077194214
Validation loss: 2.72842570530471

Epoch: 6| Step: 13
Training loss: 2.4934964179992676
Validation loss: 2.7329233641265542

Epoch: 19| Step: 0
Training loss: 2.7991268634796143
Validation loss: 2.736611989236647

Epoch: 6| Step: 1
Training loss: 2.932847023010254
Validation loss: 2.7368027497363347

Epoch: 6| Step: 2
Training loss: 2.7389304637908936
Validation loss: 2.74117886635565

Epoch: 6| Step: 3
Training loss: 2.7233433723449707
Validation loss: 2.7426565693270777

Epoch: 6| Step: 4
Training loss: 2.807468891143799
Validation loss: 2.736542611993769

Epoch: 6| Step: 5
Training loss: 2.8938236236572266
Validation loss: 2.7334495026578187

Epoch: 6| Step: 6
Training loss: 3.2994754314422607
Validation loss: 2.7267228480308288

Epoch: 6| Step: 7
Training loss: 2.4449567794799805
Validation loss: 2.72895690958987

Epoch: 6| Step: 8
Training loss: 3.4396634101867676
Validation loss: 2.7335717472978818

Epoch: 6| Step: 9
Training loss: 3.086214303970337
Validation loss: 2.7290176396728842

Epoch: 6| Step: 10
Training loss: 2.658592939376831
Validation loss: 2.718438022880144

Epoch: 6| Step: 11
Training loss: 3.2336182594299316
Validation loss: 2.7071216555051905

Epoch: 6| Step: 12
Training loss: 2.576052188873291
Validation loss: 2.7108191597846245

Epoch: 6| Step: 13
Training loss: 2.6781206130981445
Validation loss: 2.7119305954184583

Epoch: 20| Step: 0
Training loss: 2.4893250465393066
Validation loss: 2.7082040284269597

Epoch: 6| Step: 1
Training loss: 2.5099854469299316
Validation loss: 2.70789772208019

Epoch: 6| Step: 2
Training loss: 3.0564308166503906
Validation loss: 2.7060029686138196

Epoch: 6| Step: 3
Training loss: 3.0472910404205322
Validation loss: 2.7028171118869575

Epoch: 6| Step: 4
Training loss: 3.453817844390869
Validation loss: 2.70651936787431

Epoch: 6| Step: 5
Training loss: 3.0815601348876953
Validation loss: 2.706984127721479

Epoch: 6| Step: 6
Training loss: 2.9418725967407227
Validation loss: 2.707758488193635

Epoch: 6| Step: 7
Training loss: 2.9876060485839844
Validation loss: 2.706969097096433

Epoch: 6| Step: 8
Training loss: 2.209308624267578
Validation loss: 2.706218724609703

Epoch: 6| Step: 9
Training loss: 2.5970144271850586
Validation loss: 2.7031557380512194

Epoch: 6| Step: 10
Training loss: 3.4987740516662598
Validation loss: 2.7003635539803454

Epoch: 6| Step: 11
Training loss: 2.7825145721435547
Validation loss: 2.6954877812375306

Epoch: 6| Step: 12
Training loss: 3.013056755065918
Validation loss: 2.702008593466974

Epoch: 6| Step: 13
Training loss: 2.1658859252929688
Validation loss: 2.697009971064906

Epoch: 21| Step: 0
Training loss: 2.597146511077881
Validation loss: 2.6961241973343717

Epoch: 6| Step: 1
Training loss: 3.147169589996338
Validation loss: 2.692081013033467

Epoch: 6| Step: 2
Training loss: 2.665546417236328
Validation loss: 2.6930569602597143

Epoch: 6| Step: 3
Training loss: 3.1641387939453125
Validation loss: 2.6943946474341938

Epoch: 6| Step: 4
Training loss: 3.0312812328338623
Validation loss: 2.6916971155392226

Epoch: 6| Step: 5
Training loss: 3.0097835063934326
Validation loss: 2.6888485570107736

Epoch: 6| Step: 6
Training loss: 2.4742841720581055
Validation loss: 2.690483682899065

Epoch: 6| Step: 7
Training loss: 2.179795265197754
Validation loss: 2.6893656433269544

Epoch: 6| Step: 8
Training loss: 2.069812059402466
Validation loss: 2.6876940111960135

Epoch: 6| Step: 9
Training loss: 2.9123499393463135
Validation loss: 2.68861069474169

Epoch: 6| Step: 10
Training loss: 3.6983802318573
Validation loss: 2.686383165338988

Epoch: 6| Step: 11
Training loss: 2.9739880561828613
Validation loss: 2.68732690042065

Epoch: 6| Step: 12
Training loss: 3.0358638763427734
Validation loss: 2.6833395906673965

Epoch: 6| Step: 13
Training loss: 3.2521519660949707
Validation loss: 2.6848106666277816

Epoch: 22| Step: 0
Training loss: 3.316277503967285
Validation loss: 2.6894898927339943

Epoch: 6| Step: 1
Training loss: 2.898691177368164
Validation loss: 2.7067790877434517

Epoch: 6| Step: 2
Training loss: 2.417635440826416
Validation loss: 2.69738265263137

Epoch: 6| Step: 3
Training loss: 2.19362735748291
Validation loss: 2.692741847807361

Epoch: 6| Step: 4
Training loss: 3.1240057945251465
Validation loss: 2.7000159038010465

Epoch: 6| Step: 5
Training loss: 3.42842698097229
Validation loss: 2.692182628057336

Epoch: 6| Step: 6
Training loss: 3.4388298988342285
Validation loss: 2.678130352368919

Epoch: 6| Step: 7
Training loss: 2.4560599327087402
Validation loss: 2.6781810791261735

Epoch: 6| Step: 8
Training loss: 3.2402138710021973
Validation loss: 2.679935803977392

Epoch: 6| Step: 9
Training loss: 2.7612431049346924
Validation loss: 2.6790402602123957

Epoch: 6| Step: 10
Training loss: 2.939577579498291
Validation loss: 2.6833095729991956

Epoch: 6| Step: 11
Training loss: 2.4754862785339355
Validation loss: 2.678883606387723

Epoch: 6| Step: 12
Training loss: 2.342189073562622
Validation loss: 2.680707916136711

Epoch: 6| Step: 13
Training loss: 3.025632381439209
Validation loss: 2.677875831562986

Epoch: 23| Step: 0
Training loss: 2.6225016117095947
Validation loss: 2.685825845246674

Epoch: 6| Step: 1
Training loss: 3.1183981895446777
Validation loss: 2.6808956053949173

Epoch: 6| Step: 2
Training loss: 2.3632988929748535
Validation loss: 2.6813620162266556

Epoch: 6| Step: 3
Training loss: 2.984920024871826
Validation loss: 2.673134321807533

Epoch: 6| Step: 4
Training loss: 3.0853896141052246
Validation loss: 2.673240259129514

Epoch: 6| Step: 5
Training loss: 2.8014206886291504
Validation loss: 2.672284633882584

Epoch: 6| Step: 6
Training loss: 2.7723398208618164
Validation loss: 2.6734007558514996

Epoch: 6| Step: 7
Training loss: 3.0371222496032715
Validation loss: 2.6729168353542203

Epoch: 6| Step: 8
Training loss: 2.848881721496582
Validation loss: 2.6729196476679977

Epoch: 6| Step: 9
Training loss: 3.2877371311187744
Validation loss: 2.6748462646238265

Epoch: 6| Step: 10
Training loss: 2.690459728240967
Validation loss: 2.6738977996251916

Epoch: 6| Step: 11
Training loss: 2.8578200340270996
Validation loss: 2.6693591763896327

Epoch: 6| Step: 12
Training loss: 2.2599968910217285
Validation loss: 2.670325694545623

Epoch: 6| Step: 13
Training loss: 3.3088037967681885
Validation loss: 2.6697798390542307

Epoch: 24| Step: 0
Training loss: 2.5954525470733643
Validation loss: 2.6889550583336943

Epoch: 6| Step: 1
Training loss: 3.622014045715332
Validation loss: 2.7122174001509145

Epoch: 6| Step: 2
Training loss: 3.3312294483184814
Validation loss: 2.6952531876102572

Epoch: 6| Step: 3
Training loss: 2.8141984939575195
Validation loss: 2.6808749398877545

Epoch: 6| Step: 4
Training loss: 2.3524491786956787
Validation loss: 2.6656539773428314

Epoch: 6| Step: 5
Training loss: 2.4486002922058105
Validation loss: 2.6651596253918064

Epoch: 6| Step: 6
Training loss: 2.834620237350464
Validation loss: 2.6655516111722557

Epoch: 6| Step: 7
Training loss: 2.3889107704162598
Validation loss: 2.6669299756326983

Epoch: 6| Step: 8
Training loss: 3.303617000579834
Validation loss: 2.6656052835526003

Epoch: 6| Step: 9
Training loss: 2.8507239818573
Validation loss: 2.667748994724725

Epoch: 6| Step: 10
Training loss: 2.5244100093841553
Validation loss: 2.6664753383205784

Epoch: 6| Step: 11
Training loss: 2.6100940704345703
Validation loss: 2.6596280246652584

Epoch: 6| Step: 12
Training loss: 3.405874252319336
Validation loss: 2.662425733381702

Epoch: 6| Step: 13
Training loss: 2.7868263721466064
Validation loss: 2.6597550966406382

Epoch: 25| Step: 0
Training loss: 3.058992862701416
Validation loss: 2.657422468226443

Epoch: 6| Step: 1
Training loss: 2.962160587310791
Validation loss: 2.658510010729554

Epoch: 6| Step: 2
Training loss: 2.698212146759033
Validation loss: 2.6577630812121975

Epoch: 6| Step: 3
Training loss: 2.5344274044036865
Validation loss: 2.658433727038804

Epoch: 6| Step: 4
Training loss: 3.7193336486816406
Validation loss: 2.65820566556787

Epoch: 6| Step: 5
Training loss: 3.0446696281433105
Validation loss: 2.6596297602499686

Epoch: 6| Step: 6
Training loss: 2.5584402084350586
Validation loss: 2.656067722587175

Epoch: 6| Step: 7
Training loss: 2.2014150619506836
Validation loss: 2.661937521349999

Epoch: 6| Step: 8
Training loss: 3.822089195251465
Validation loss: 2.6570534552297285

Epoch: 6| Step: 9
Training loss: 2.209047317504883
Validation loss: 2.65506697470142

Epoch: 6| Step: 10
Training loss: 2.4477035999298096
Validation loss: 2.6519388152707006

Epoch: 6| Step: 11
Training loss: 2.8158984184265137
Validation loss: 2.6512243568256335

Epoch: 6| Step: 12
Training loss: 2.687558650970459
Validation loss: 2.652007185002809

Epoch: 6| Step: 13
Training loss: 2.881683826446533
Validation loss: 2.660203949097664

Epoch: 26| Step: 0
Training loss: 2.6894938945770264
Validation loss: 2.6779284195233415

Epoch: 6| Step: 1
Training loss: 2.6721279621124268
Validation loss: 2.7038911645130446

Epoch: 6| Step: 2
Training loss: 3.098275661468506
Validation loss: 2.735832263064641

Epoch: 6| Step: 3
Training loss: 3.5440621376037598
Validation loss: 2.7431440635394027

Epoch: 6| Step: 4
Training loss: 3.136861562728882
Validation loss: 2.673464636648855

Epoch: 6| Step: 5
Training loss: 3.097653388977051
Validation loss: 2.6488373741026847

Epoch: 6| Step: 6
Training loss: 2.079359531402588
Validation loss: 2.654450237110097

Epoch: 6| Step: 7
Training loss: 2.630160331726074
Validation loss: 2.674371173304896

Epoch: 6| Step: 8
Training loss: 2.552963972091675
Validation loss: 2.6958777161054712

Epoch: 6| Step: 9
Training loss: 2.5051939487457275
Validation loss: 2.6970591237468104

Epoch: 6| Step: 10
Training loss: 3.3690946102142334
Validation loss: 2.685734156639345

Epoch: 6| Step: 11
Training loss: 2.832949638366699
Validation loss: 2.6861587980742097

Epoch: 6| Step: 12
Training loss: 2.705098867416382
Validation loss: 2.6753314028504076

Epoch: 6| Step: 13
Training loss: 2.973649501800537
Validation loss: 2.6594968918831117

Epoch: 27| Step: 0
Training loss: 2.990570068359375
Validation loss: 2.6490239276680896

Epoch: 6| Step: 1
Training loss: 1.8183884620666504
Validation loss: 2.6465393907280377

Epoch: 6| Step: 2
Training loss: 3.318131685256958
Validation loss: 2.6446271455416115

Epoch: 6| Step: 3
Training loss: 2.019819498062134
Validation loss: 2.6410794335026897

Epoch: 6| Step: 4
Training loss: 3.256284713745117
Validation loss: 2.646844446018178

Epoch: 6| Step: 5
Training loss: 2.9237208366394043
Validation loss: 2.6644792710581133

Epoch: 6| Step: 6
Training loss: 2.575631618499756
Validation loss: 2.6572228452210784

Epoch: 6| Step: 7
Training loss: 2.1517269611358643
Validation loss: 2.662567333508563

Epoch: 6| Step: 8
Training loss: 3.2757956981658936
Validation loss: 2.650993565077423

Epoch: 6| Step: 9
Training loss: 3.387868881225586
Validation loss: 2.637064713303761

Epoch: 6| Step: 10
Training loss: 2.336181163787842
Validation loss: 2.632957402096

Epoch: 6| Step: 11
Training loss: 3.1112024784088135
Validation loss: 2.631837039865473

Epoch: 6| Step: 12
Training loss: 3.7163891792297363
Validation loss: 2.6274880337458786

Epoch: 6| Step: 13
Training loss: 2.6020476818084717
Validation loss: 2.630951827572238

Epoch: 28| Step: 0
Training loss: 3.594559669494629
Validation loss: 2.6283537726248465

Epoch: 6| Step: 1
Training loss: 2.7641186714172363
Validation loss: 2.6235329745918192

Epoch: 6| Step: 2
Training loss: 2.646334648132324
Validation loss: 2.62378518555754

Epoch: 6| Step: 3
Training loss: 2.320976734161377
Validation loss: 2.625184174506895

Epoch: 6| Step: 4
Training loss: 2.427365303039551
Validation loss: 2.6270423473850375

Epoch: 6| Step: 5
Training loss: 3.5211048126220703
Validation loss: 2.6287171609940065

Epoch: 6| Step: 6
Training loss: 3.0933494567871094
Validation loss: 2.6288336348789993

Epoch: 6| Step: 7
Training loss: 3.2675371170043945
Validation loss: 2.623189046818723

Epoch: 6| Step: 8
Training loss: 3.209099292755127
Validation loss: 2.6233005267317577

Epoch: 6| Step: 9
Training loss: 1.6276981830596924
Validation loss: 2.625965879809472

Epoch: 6| Step: 10
Training loss: 2.511638879776001
Validation loss: 2.6238218610004713

Epoch: 6| Step: 11
Training loss: 2.711618185043335
Validation loss: 2.624582972577823

Epoch: 6| Step: 12
Training loss: 2.7794666290283203
Validation loss: 2.618336098168486

Epoch: 6| Step: 13
Training loss: 2.7720441818237305
Validation loss: 2.6144051654364473

Epoch: 29| Step: 0
Training loss: 1.7876982688903809
Validation loss: 2.6130832395245953

Epoch: 6| Step: 1
Training loss: 2.3348865509033203
Validation loss: 2.613527150564296

Epoch: 6| Step: 2
Training loss: 3.151064872741699
Validation loss: 2.6121383892592562

Epoch: 6| Step: 3
Training loss: 2.97845458984375
Validation loss: 2.6170816575327227

Epoch: 6| Step: 4
Training loss: 2.8821799755096436
Validation loss: 2.6242134468529814

Epoch: 6| Step: 5
Training loss: 2.8338241577148438
Validation loss: 2.630722084353047

Epoch: 6| Step: 6
Training loss: 2.6590776443481445
Validation loss: 2.617311203351585

Epoch: 6| Step: 7
Training loss: 3.4954795837402344
Validation loss: 2.6131749024955173

Epoch: 6| Step: 8
Training loss: 2.775818347930908
Validation loss: 2.6099796064438356

Epoch: 6| Step: 9
Training loss: 3.2419097423553467
Validation loss: 2.6113922211431686

Epoch: 6| Step: 10
Training loss: 2.7093608379364014
Validation loss: 2.611728032430013

Epoch: 6| Step: 11
Training loss: 3.2816038131713867
Validation loss: 2.6115940642613236

Epoch: 6| Step: 12
Training loss: 2.1774508953094482
Validation loss: 2.6123600647013676

Epoch: 6| Step: 13
Training loss: 2.9076220989227295
Validation loss: 2.6124320004575994

Epoch: 30| Step: 0
Training loss: 2.9399309158325195
Validation loss: 2.6081771440403436

Epoch: 6| Step: 1
Training loss: 2.297196865081787
Validation loss: 2.606066455123245

Epoch: 6| Step: 2
Training loss: 2.716977596282959
Validation loss: 2.6053600080551638

Epoch: 6| Step: 3
Training loss: 2.4653210639953613
Validation loss: 2.6190780978049

Epoch: 6| Step: 4
Training loss: 2.874221086502075
Validation loss: 2.6091928251328005

Epoch: 6| Step: 5
Training loss: 3.453685998916626
Validation loss: 2.6178256080996607

Epoch: 6| Step: 6
Training loss: 2.91605281829834
Validation loss: 2.6098595101346254

Epoch: 6| Step: 7
Training loss: 3.615697145462036
Validation loss: 2.609896139432025

Epoch: 6| Step: 8
Training loss: 2.9338269233703613
Validation loss: 2.61189022884574

Epoch: 6| Step: 9
Training loss: 3.075453281402588
Validation loss: 2.608990389813659

Epoch: 6| Step: 10
Training loss: 1.9345293045043945
Validation loss: 2.6060409699716875

Epoch: 6| Step: 11
Training loss: 2.708064556121826
Validation loss: 2.6050135012595885

Epoch: 6| Step: 12
Training loss: 2.2750701904296875
Validation loss: 2.604346006147323

Epoch: 6| Step: 13
Training loss: 2.7761433124542236
Validation loss: 2.6054728595159387

Epoch: 31| Step: 0
Training loss: 2.8853650093078613
Validation loss: 2.6055558009814193

Epoch: 6| Step: 1
Training loss: 2.6049325466156006
Validation loss: 2.6181500829676145

Epoch: 6| Step: 2
Training loss: 2.628934144973755
Validation loss: 2.6166064380317606

Epoch: 6| Step: 3
Training loss: 2.2114646434783936
Validation loss: 2.6099441333483626

Epoch: 6| Step: 4
Training loss: 2.5432188510894775
Validation loss: 2.6172822521578882

Epoch: 6| Step: 5
Training loss: 2.712747573852539
Validation loss: 2.6334124765088482

Epoch: 6| Step: 6
Training loss: 3.4005532264709473
Validation loss: 2.6455219740508706

Epoch: 6| Step: 7
Training loss: 2.5688436031341553
Validation loss: 2.6487848297242196

Epoch: 6| Step: 8
Training loss: 2.408911943435669
Validation loss: 2.647315050965996

Epoch: 6| Step: 9
Training loss: 2.670647382736206
Validation loss: 2.6163167004944174

Epoch: 6| Step: 10
Training loss: 2.2526001930236816
Validation loss: 2.6057177205239572

Epoch: 6| Step: 11
Training loss: 3.536825656890869
Validation loss: 2.604157437560379

Epoch: 6| Step: 12
Training loss: 3.224602699279785
Validation loss: 2.601443097155581

Epoch: 6| Step: 13
Training loss: 3.719182014465332
Validation loss: 2.599144379297892

Epoch: 32| Step: 0
Training loss: 2.4526703357696533
Validation loss: 2.599039634068807

Epoch: 6| Step: 1
Training loss: 2.7511672973632812
Validation loss: 2.6060084066083355

Epoch: 6| Step: 2
Training loss: 3.180640935897827
Validation loss: 2.6236699678564586

Epoch: 6| Step: 3
Training loss: 3.1185405254364014
Validation loss: 2.5990653525116625

Epoch: 6| Step: 4
Training loss: 2.3587357997894287
Validation loss: 2.5940803545777515

Epoch: 6| Step: 5
Training loss: 2.20736026763916
Validation loss: 2.593685201419297

Epoch: 6| Step: 6
Training loss: 3.153569221496582
Validation loss: 2.591810316167852

Epoch: 6| Step: 7
Training loss: 2.8008179664611816
Validation loss: 2.5988793244925876

Epoch: 6| Step: 8
Training loss: 2.3710203170776367
Validation loss: 2.6068129283125683

Epoch: 6| Step: 9
Training loss: 2.691066026687622
Validation loss: 2.605880191249232

Epoch: 6| Step: 10
Training loss: 2.998239040374756
Validation loss: 2.6066172174228135

Epoch: 6| Step: 11
Training loss: 2.478172779083252
Validation loss: 2.599665644348309

Epoch: 6| Step: 12
Training loss: 3.219846248626709
Validation loss: 2.5944821321836082

Epoch: 6| Step: 13
Training loss: 3.4322688579559326
Validation loss: 2.593771711472542

Epoch: 33| Step: 0
Training loss: 2.57468318939209
Validation loss: 2.5985623431462113

Epoch: 6| Step: 1
Training loss: 2.6558799743652344
Validation loss: 2.6181257719634683

Epoch: 6| Step: 2
Training loss: 2.5620265007019043
Validation loss: 2.62959450034685

Epoch: 6| Step: 3
Training loss: 2.0707364082336426
Validation loss: 2.625062075994348

Epoch: 6| Step: 4
Training loss: 2.2828540802001953
Validation loss: 2.6199143137983096

Epoch: 6| Step: 5
Training loss: 2.407228946685791
Validation loss: 2.614399274190267

Epoch: 6| Step: 6
Training loss: 2.511883497238159
Validation loss: 2.600238505230155

Epoch: 6| Step: 7
Training loss: 3.87477707862854
Validation loss: 2.5922218625263502

Epoch: 6| Step: 8
Training loss: 3.0576345920562744
Validation loss: 2.5813636959240003

Epoch: 6| Step: 9
Training loss: 3.4952383041381836
Validation loss: 2.581667325829947

Epoch: 6| Step: 10
Training loss: 2.7309470176696777
Validation loss: 2.581802893710393

Epoch: 6| Step: 11
Training loss: 3.2185726165771484
Validation loss: 2.583463763677946

Epoch: 6| Step: 12
Training loss: 2.8571395874023438
Validation loss: 2.582334159522928

Epoch: 6| Step: 13
Training loss: 2.4965782165527344
Validation loss: 2.5858025512387677

Epoch: 34| Step: 0
Training loss: 2.0478014945983887
Validation loss: 2.5851798519011466

Epoch: 6| Step: 1
Training loss: 2.5880227088928223
Validation loss: 2.5920814929469937

Epoch: 6| Step: 2
Training loss: 2.3444533348083496
Validation loss: 2.6033039246836016

Epoch: 6| Step: 3
Training loss: 3.0326931476593018
Validation loss: 2.615072545184884

Epoch: 6| Step: 4
Training loss: 2.900761604309082
Validation loss: 2.608312327374694

Epoch: 6| Step: 5
Training loss: 3.1085710525512695
Validation loss: 2.5879665061991703

Epoch: 6| Step: 6
Training loss: 2.5533370971679688
Validation loss: 2.5764663603998

Epoch: 6| Step: 7
Training loss: 2.5578625202178955
Validation loss: 2.5754514612177366

Epoch: 6| Step: 8
Training loss: 3.208220958709717
Validation loss: 2.578537097541235

Epoch: 6| Step: 9
Training loss: 2.8613438606262207
Validation loss: 2.5817265920741583

Epoch: 6| Step: 10
Training loss: 2.684277296066284
Validation loss: 2.583450202018984

Epoch: 6| Step: 11
Training loss: 3.2731168270111084
Validation loss: 2.5848793983459473

Epoch: 6| Step: 12
Training loss: 2.5617289543151855
Validation loss: 2.579473721083774

Epoch: 6| Step: 13
Training loss: 3.416391134262085
Validation loss: 2.5772403363258607

Epoch: 35| Step: 0
Training loss: 2.4980151653289795
Validation loss: 2.5783754138536352

Epoch: 6| Step: 1
Training loss: 3.8218653202056885
Validation loss: 2.5852566483200237

Epoch: 6| Step: 2
Training loss: 2.841892719268799
Validation loss: 2.5986139723049697

Epoch: 6| Step: 3
Training loss: 1.937598705291748
Validation loss: 2.600181818008423

Epoch: 6| Step: 4
Training loss: 2.600703239440918
Validation loss: 2.598256869982648

Epoch: 6| Step: 5
Training loss: 3.496791124343872
Validation loss: 2.574127289556688

Epoch: 6| Step: 6
Training loss: 1.9488351345062256
Validation loss: 2.569029890080934

Epoch: 6| Step: 7
Training loss: 3.5477986335754395
Validation loss: 2.5689620433315152

Epoch: 6| Step: 8
Training loss: 2.9555344581604004
Validation loss: 2.5716665996018278

Epoch: 6| Step: 9
Training loss: 2.360135078430176
Validation loss: 2.575773749300229

Epoch: 6| Step: 10
Training loss: 3.1154932975769043
Validation loss: 2.581009941716348

Epoch: 6| Step: 11
Training loss: 2.8940067291259766
Validation loss: 2.5806398853178947

Epoch: 6| Step: 12
Training loss: 2.2089004516601562
Validation loss: 2.5835647788099063

Epoch: 6| Step: 13
Training loss: 2.2645556926727295
Validation loss: 2.575778135689356

Epoch: 36| Step: 0
Training loss: 2.685239791870117
Validation loss: 2.579371057530885

Epoch: 6| Step: 1
Training loss: 2.9621639251708984
Validation loss: 2.575692674165131

Epoch: 6| Step: 2
Training loss: 2.6014652252197266
Validation loss: 2.570319970448812

Epoch: 6| Step: 3
Training loss: 2.5116164684295654
Validation loss: 2.5675191571635585

Epoch: 6| Step: 4
Training loss: 2.7944066524505615
Validation loss: 2.565742190166186

Epoch: 6| Step: 5
Training loss: 2.8250436782836914
Validation loss: 2.572431292585147

Epoch: 6| Step: 6
Training loss: 1.7254345417022705
Validation loss: 2.5902751825189076

Epoch: 6| Step: 7
Training loss: 3.260026454925537
Validation loss: 2.6007877472908265

Epoch: 6| Step: 8
Training loss: 3.0465052127838135
Validation loss: 2.6291726276438725

Epoch: 6| Step: 9
Training loss: 2.953947067260742
Validation loss: 2.626855210591388

Epoch: 6| Step: 10
Training loss: 2.711864948272705
Validation loss: 2.6102083190794914

Epoch: 6| Step: 11
Training loss: 2.73988676071167
Validation loss: 2.581067633885209

Epoch: 6| Step: 12
Training loss: 3.1526315212249756
Validation loss: 2.5597683204117643

Epoch: 6| Step: 13
Training loss: 2.814305543899536
Validation loss: 2.556616437050604

Epoch: 37| Step: 0
Training loss: 2.975834369659424
Validation loss: 2.5600267917879167

Epoch: 6| Step: 1
Training loss: 2.742607593536377
Validation loss: 2.5634853737328642

Epoch: 6| Step: 2
Training loss: 2.584407329559326
Validation loss: 2.569792926952403

Epoch: 6| Step: 3
Training loss: 2.7930307388305664
Validation loss: 2.5718638025304323

Epoch: 6| Step: 4
Training loss: 2.5978927612304688
Validation loss: 2.575511634990733

Epoch: 6| Step: 5
Training loss: 2.244490623474121
Validation loss: 2.573933070705783

Epoch: 6| Step: 6
Training loss: 2.431314468383789
Validation loss: 2.5707956872960573

Epoch: 6| Step: 7
Training loss: 2.6146016120910645
Validation loss: 2.5590128898620605

Epoch: 6| Step: 8
Training loss: 2.6870288848876953
Validation loss: 2.5587206989206295

Epoch: 6| Step: 9
Training loss: 3.568136692047119
Validation loss: 2.564254169823021

Epoch: 6| Step: 10
Training loss: 2.6842870712280273
Validation loss: 2.5558680616399294

Epoch: 6| Step: 11
Training loss: 3.4636740684509277
Validation loss: 2.545465451414867

Epoch: 6| Step: 12
Training loss: 2.522339105606079
Validation loss: 2.549345226698024

Epoch: 6| Step: 13
Training loss: 2.695571184158325
Validation loss: 2.5559412279436664

Epoch: 38| Step: 0
Training loss: 2.5764060020446777
Validation loss: 2.5843019126563944

Epoch: 6| Step: 1
Training loss: 3.214946985244751
Validation loss: 2.612870447097286

Epoch: 6| Step: 2
Training loss: 2.0901613235473633
Validation loss: 2.616475946159773

Epoch: 6| Step: 3
Training loss: 3.34755802154541
Validation loss: 2.6187216620291434

Epoch: 6| Step: 4
Training loss: 3.193838596343994
Validation loss: 2.583983095743323

Epoch: 6| Step: 5
Training loss: 2.9791812896728516
Validation loss: 2.560981822270219

Epoch: 6| Step: 6
Training loss: 1.9980524778366089
Validation loss: 2.5454425055493592

Epoch: 6| Step: 7
Training loss: 2.733168840408325
Validation loss: 2.5427229019903366

Epoch: 6| Step: 8
Training loss: 3.218183994293213
Validation loss: 2.5494365102501324

Epoch: 6| Step: 9
Training loss: 2.0143496990203857
Validation loss: 2.5538563882150958

Epoch: 6| Step: 10
Training loss: 3.8083176612854004
Validation loss: 2.5608460057166313

Epoch: 6| Step: 11
Training loss: 2.0703835487365723
Validation loss: 2.555152552102202

Epoch: 6| Step: 12
Training loss: 2.456179141998291
Validation loss: 2.5517923344847975

Epoch: 6| Step: 13
Training loss: 3.2712173461914062
Validation loss: 2.5424861933595393

Epoch: 39| Step: 0
Training loss: 3.1225264072418213
Validation loss: 2.5473195916862896

Epoch: 6| Step: 1
Training loss: 2.5090413093566895
Validation loss: 2.541248595842751

Epoch: 6| Step: 2
Training loss: 2.8489084243774414
Validation loss: 2.5389691373353362

Epoch: 6| Step: 3
Training loss: 2.87300968170166
Validation loss: 2.542375638920774

Epoch: 6| Step: 4
Training loss: 3.1721115112304688
Validation loss: 2.5489456909959034

Epoch: 6| Step: 5
Training loss: 1.9155317544937134
Validation loss: 2.5600822638439875

Epoch: 6| Step: 6
Training loss: 2.695903778076172
Validation loss: 2.5583434950920845

Epoch: 6| Step: 7
Training loss: 2.8618245124816895
Validation loss: 2.5545859080488964

Epoch: 6| Step: 8
Training loss: 2.674074649810791
Validation loss: 2.553889982161983

Epoch: 6| Step: 9
Training loss: 2.2072975635528564
Validation loss: 2.5508523833367134

Epoch: 6| Step: 10
Training loss: 2.891315460205078
Validation loss: 2.545269461088283

Epoch: 6| Step: 11
Training loss: 2.792327642440796
Validation loss: 2.539283193567748

Epoch: 6| Step: 12
Training loss: 3.3065810203552246
Validation loss: 2.5353267269749797

Epoch: 6| Step: 13
Training loss: 2.1406474113464355
Validation loss: 2.5353579264815136

Epoch: 40| Step: 0
Training loss: 2.9566478729248047
Validation loss: 2.5334100133629254

Epoch: 6| Step: 1
Training loss: 3.643585681915283
Validation loss: 2.5334786509954803

Epoch: 6| Step: 2
Training loss: 3.3978700637817383
Validation loss: 2.5311579858103106

Epoch: 6| Step: 3
Training loss: 2.0489048957824707
Validation loss: 2.530212394652828

Epoch: 6| Step: 4
Training loss: 2.2819631099700928
Validation loss: 2.5328756224724556

Epoch: 6| Step: 5
Training loss: 2.742464780807495
Validation loss: 2.532133056271461

Epoch: 6| Step: 6
Training loss: 3.002131223678589
Validation loss: 2.527881060877154

Epoch: 6| Step: 7
Training loss: 2.224836587905884
Validation loss: 2.527419526089904

Epoch: 6| Step: 8
Training loss: 2.5291500091552734
Validation loss: 2.52908222393323

Epoch: 6| Step: 9
Training loss: 2.4659225940704346
Validation loss: 2.532832143127277

Epoch: 6| Step: 10
Training loss: 3.125684976577759
Validation loss: 2.531884503620927

Epoch: 6| Step: 11
Training loss: 2.7655091285705566
Validation loss: 2.528350632677796

Epoch: 6| Step: 12
Training loss: 2.4902145862579346
Validation loss: 2.530375849816107

Epoch: 6| Step: 13
Training loss: 2.3643760681152344
Validation loss: 2.5323818396496516

Epoch: 41| Step: 0
Training loss: 3.279245138168335
Validation loss: 2.528675889456144

Epoch: 6| Step: 1
Training loss: 2.225379705429077
Validation loss: 2.5270471931785665

Epoch: 6| Step: 2
Training loss: 3.122734308242798
Validation loss: 2.5259438150672504

Epoch: 6| Step: 3
Training loss: 3.0658533573150635
Validation loss: 2.524872156881517

Epoch: 6| Step: 4
Training loss: 2.9350054264068604
Validation loss: 2.5245274856526363

Epoch: 6| Step: 5
Training loss: 2.139498472213745
Validation loss: 2.52497277721282

Epoch: 6| Step: 6
Training loss: 2.915881872177124
Validation loss: 2.525135250501735

Epoch: 6| Step: 7
Training loss: 3.2227818965911865
Validation loss: 2.5307640901175876

Epoch: 6| Step: 8
Training loss: 2.1809492111206055
Validation loss: 2.531625634880476

Epoch: 6| Step: 9
Training loss: 2.756871223449707
Validation loss: 2.5309636977411087

Epoch: 6| Step: 10
Training loss: 2.4469337463378906
Validation loss: 2.53109331797528

Epoch: 6| Step: 11
Training loss: 3.133873224258423
Validation loss: 2.533850767279184

Epoch: 6| Step: 12
Training loss: 2.0621817111968994
Validation loss: 2.533774132369667

Epoch: 6| Step: 13
Training loss: 2.549264669418335
Validation loss: 2.5311888058980307

Epoch: 42| Step: 0
Training loss: 2.4457545280456543
Validation loss: 2.5305912853569112

Epoch: 6| Step: 1
Training loss: 2.781686782836914
Validation loss: 2.527680289360785

Epoch: 6| Step: 2
Training loss: 2.4679341316223145
Validation loss: 2.523025953641502

Epoch: 6| Step: 3
Training loss: 2.6090283393859863
Validation loss: 2.5196527383660756

Epoch: 6| Step: 4
Training loss: 2.2444729804992676
Validation loss: 2.5200353437854397

Epoch: 6| Step: 5
Training loss: 3.0722217559814453
Validation loss: 2.5206163980627574

Epoch: 6| Step: 6
Training loss: 3.3387441635131836
Validation loss: 2.5245683398298038

Epoch: 6| Step: 7
Training loss: 2.220294237136841
Validation loss: 2.5239605775443454

Epoch: 6| Step: 8
Training loss: 2.513518810272217
Validation loss: 2.5260477783859416

Epoch: 6| Step: 9
Training loss: 3.1227290630340576
Validation loss: 2.521628254203386

Epoch: 6| Step: 10
Training loss: 3.1453592777252197
Validation loss: 2.5243547065283662

Epoch: 6| Step: 11
Training loss: 2.16349458694458
Validation loss: 2.5267135456044185

Epoch: 6| Step: 12
Training loss: 3.5300092697143555
Validation loss: 2.5288670844929193

Epoch: 6| Step: 13
Training loss: 2.312953233718872
Validation loss: 2.5288912865423385

Epoch: 43| Step: 0
Training loss: 3.1025390625
Validation loss: 2.519250487768522

Epoch: 6| Step: 1
Training loss: 3.06978702545166
Validation loss: 2.5240975374816568

Epoch: 6| Step: 2
Training loss: 2.850996971130371
Validation loss: 2.523742991109048

Epoch: 6| Step: 3
Training loss: 2.5086669921875
Validation loss: 2.5263535950773504

Epoch: 6| Step: 4
Training loss: 2.311946392059326
Validation loss: 2.522510349109609

Epoch: 6| Step: 5
Training loss: 2.1518208980560303
Validation loss: 2.524957097986693

Epoch: 6| Step: 6
Training loss: 3.0794894695281982
Validation loss: 2.5220563616803897

Epoch: 6| Step: 7
Training loss: 2.4723637104034424
Validation loss: 2.5167264630717616

Epoch: 6| Step: 8
Training loss: 2.493842840194702
Validation loss: 2.5166850243845293

Epoch: 6| Step: 9
Training loss: 2.9180498123168945
Validation loss: 2.5194820665544078

Epoch: 6| Step: 10
Training loss: 3.0927629470825195
Validation loss: 2.516873605789677

Epoch: 6| Step: 11
Training loss: 2.595308542251587
Validation loss: 2.519803093325707

Epoch: 6| Step: 12
Training loss: 2.904789447784424
Validation loss: 2.5209682090308076

Epoch: 6| Step: 13
Training loss: 2.278836488723755
Validation loss: 2.5223877763235443

Epoch: 44| Step: 0
Training loss: 2.7818942070007324
Validation loss: 2.5229026912361063

Epoch: 6| Step: 1
Training loss: 2.7033705711364746
Validation loss: 2.524752309245448

Epoch: 6| Step: 2
Training loss: 3.603947401046753
Validation loss: 2.5284002160513275

Epoch: 6| Step: 3
Training loss: 2.413416624069214
Validation loss: 2.526938476870137

Epoch: 6| Step: 4
Training loss: 2.3129820823669434
Validation loss: 2.5279090301964873

Epoch: 6| Step: 5
Training loss: 3.038353443145752
Validation loss: 2.523424558742072

Epoch: 6| Step: 6
Training loss: 2.3130643367767334
Validation loss: 2.5207479641001713

Epoch: 6| Step: 7
Training loss: 2.2205164432525635
Validation loss: 2.5214729642355316

Epoch: 6| Step: 8
Training loss: 3.329394817352295
Validation loss: 2.5181488401146344

Epoch: 6| Step: 9
Training loss: 2.605170726776123
Validation loss: 2.5180404134975967

Epoch: 6| Step: 10
Training loss: 1.9573662281036377
Validation loss: 2.5144587819294264

Epoch: 6| Step: 11
Training loss: 3.301248073577881
Validation loss: 2.5147364934285483

Epoch: 6| Step: 12
Training loss: 2.5106422901153564
Validation loss: 2.514842971678703

Epoch: 6| Step: 13
Training loss: 2.931460380554199
Validation loss: 2.519838692039572

Epoch: 45| Step: 0
Training loss: 2.577444314956665
Validation loss: 2.517812293062928

Epoch: 6| Step: 1
Training loss: 2.908501625061035
Validation loss: 2.5221354397394324

Epoch: 6| Step: 2
Training loss: 2.315835475921631
Validation loss: 2.5150228879785024

Epoch: 6| Step: 3
Training loss: 2.2186625003814697
Validation loss: 2.515212289748653

Epoch: 6| Step: 4
Training loss: 2.579455852508545
Validation loss: 2.523943821589152

Epoch: 6| Step: 5
Training loss: 2.7972426414489746
Validation loss: 2.531116344595468

Epoch: 6| Step: 6
Training loss: 2.1552791595458984
Validation loss: 2.529508629152852

Epoch: 6| Step: 7
Training loss: 3.663004159927368
Validation loss: 2.5312795408310427

Epoch: 6| Step: 8
Training loss: 3.178783893585205
Validation loss: 2.52529376809315

Epoch: 6| Step: 9
Training loss: 2.4199676513671875
Validation loss: 2.522200561338855

Epoch: 6| Step: 10
Training loss: 2.576408863067627
Validation loss: 2.523318909829663

Epoch: 6| Step: 11
Training loss: 3.034358024597168
Validation loss: 2.5199351977276545

Epoch: 6| Step: 12
Training loss: 3.2322945594787598
Validation loss: 2.515830619360811

Epoch: 6| Step: 13
Training loss: 1.989621639251709
Validation loss: 2.515619949627948

Epoch: 46| Step: 0
Training loss: 2.4648759365081787
Validation loss: 2.5165025931532665

Epoch: 6| Step: 1
Training loss: 3.3122777938842773
Validation loss: 2.5157005915077786

Epoch: 6| Step: 2
Training loss: 2.3540167808532715
Validation loss: 2.512737084460515

Epoch: 6| Step: 3
Training loss: 2.989306926727295
Validation loss: 2.5146497065021145

Epoch: 6| Step: 4
Training loss: 2.171607255935669
Validation loss: 2.514424523999614

Epoch: 6| Step: 5
Training loss: 2.7444558143615723
Validation loss: 2.5106453690477597

Epoch: 6| Step: 6
Training loss: 2.411959648132324
Validation loss: 2.5140250088066183

Epoch: 6| Step: 7
Training loss: 3.051790714263916
Validation loss: 2.5154023913926977

Epoch: 6| Step: 8
Training loss: 3.664273977279663
Validation loss: 2.513271221550562

Epoch: 6| Step: 9
Training loss: 3.3711767196655273
Validation loss: 2.5125475878356607

Epoch: 6| Step: 10
Training loss: 2.6783251762390137
Validation loss: 2.5139466434396724

Epoch: 6| Step: 11
Training loss: 2.0703043937683105
Validation loss: 2.508930954881894

Epoch: 6| Step: 12
Training loss: 2.1095008850097656
Validation loss: 2.5101801554361978

Epoch: 6| Step: 13
Training loss: 2.2359440326690674
Validation loss: 2.5052104791005454

Epoch: 47| Step: 0
Training loss: 2.134946346282959
Validation loss: 2.505956329325194

Epoch: 6| Step: 1
Training loss: 2.69480562210083
Validation loss: 2.5090074795548634

Epoch: 6| Step: 2
Training loss: 3.1635611057281494
Validation loss: 2.5090726293543333

Epoch: 6| Step: 3
Training loss: 2.2045421600341797
Validation loss: 2.507241554157708

Epoch: 6| Step: 4
Training loss: 1.8663394451141357
Validation loss: 2.506970695270005

Epoch: 6| Step: 5
Training loss: 2.7016232013702393
Validation loss: 2.5098669862234466

Epoch: 6| Step: 6
Training loss: 4.3263468742370605
Validation loss: 2.5091024829495336

Epoch: 6| Step: 7
Training loss: 2.387373447418213
Validation loss: 2.5065381168037333

Epoch: 6| Step: 8
Training loss: 2.9028429985046387
Validation loss: 2.5056586675746466

Epoch: 6| Step: 9
Training loss: 2.6016902923583984
Validation loss: 2.5035846361549954

Epoch: 6| Step: 10
Training loss: 2.696038246154785
Validation loss: 2.5036085844039917

Epoch: 6| Step: 11
Training loss: 3.0433297157287598
Validation loss: 2.505172460309921

Epoch: 6| Step: 12
Training loss: 3.087740898132324
Validation loss: 2.5055121247486403

Epoch: 6| Step: 13
Training loss: 1.4313123226165771
Validation loss: 2.505246752051897

Epoch: 48| Step: 0
Training loss: 3.0373666286468506
Validation loss: 2.501198422524237

Epoch: 6| Step: 1
Training loss: 2.7133960723876953
Validation loss: 2.498470280760078

Epoch: 6| Step: 2
Training loss: 2.73507022857666
Validation loss: 2.495720991524317

Epoch: 6| Step: 3
Training loss: 3.1206183433532715
Validation loss: 2.4960154461604294

Epoch: 6| Step: 4
Training loss: 2.2803144454956055
Validation loss: 2.491743818406136

Epoch: 6| Step: 5
Training loss: 2.718899726867676
Validation loss: 2.4954661233450777

Epoch: 6| Step: 6
Training loss: 2.3190438747406006
Validation loss: 2.4958957164518294

Epoch: 6| Step: 7
Training loss: 3.0158514976501465
Validation loss: 2.4963926833163024

Epoch: 6| Step: 8
Training loss: 3.204134941101074
Validation loss: 2.4979747597889235

Epoch: 6| Step: 9
Training loss: 2.2805073261260986
Validation loss: 2.4951047692247617

Epoch: 6| Step: 10
Training loss: 2.980192184448242
Validation loss: 2.4964875123834096

Epoch: 6| Step: 11
Training loss: 2.2830581665039062
Validation loss: 2.4995940551962903

Epoch: 6| Step: 12
Training loss: 1.998450756072998
Validation loss: 2.5118225671911754

Epoch: 6| Step: 13
Training loss: 3.233543872833252
Validation loss: 2.5242837398282942

Epoch: 49| Step: 0
Training loss: 2.7545993328094482
Validation loss: 2.531826442287814

Epoch: 6| Step: 1
Training loss: 2.1122491359710693
Validation loss: 2.5234202877167733

Epoch: 6| Step: 2
Training loss: 2.655862331390381
Validation loss: 2.509219108089324

Epoch: 6| Step: 3
Training loss: 2.7046329975128174
Validation loss: 2.501802149639335

Epoch: 6| Step: 4
Training loss: 2.2560172080993652
Validation loss: 2.4960685391579904

Epoch: 6| Step: 5
Training loss: 3.07523512840271
Validation loss: 2.4907645076833744

Epoch: 6| Step: 6
Training loss: 2.758061408996582
Validation loss: 2.488232699773645

Epoch: 6| Step: 7
Training loss: 2.273649215698242
Validation loss: 2.489805368966954

Epoch: 6| Step: 8
Training loss: 2.5702157020568848
Validation loss: 2.4949544245196926

Epoch: 6| Step: 9
Training loss: 2.8469719886779785
Validation loss: 2.493822246469477

Epoch: 6| Step: 10
Training loss: 3.019212007522583
Validation loss: 2.4986796173998105

Epoch: 6| Step: 11
Training loss: 3.3541369438171387
Validation loss: 2.502097873277562

Epoch: 6| Step: 12
Training loss: 3.0088438987731934
Validation loss: 2.507873258283061

Epoch: 6| Step: 13
Training loss: 2.2461187839508057
Validation loss: 2.51114994992492

Epoch: 50| Step: 0
Training loss: 2.9331085681915283
Validation loss: 2.5223308583741546

Epoch: 6| Step: 1
Training loss: 2.109928846359253
Validation loss: 2.499547658428069

Epoch: 6| Step: 2
Training loss: 3.138174057006836
Validation loss: 2.5011634826660156

Epoch: 6| Step: 3
Training loss: 4.2283477783203125
Validation loss: 2.503599225833852

Epoch: 6| Step: 4
Training loss: 1.9961869716644287
Validation loss: 2.5002641959856917

Epoch: 6| Step: 5
Training loss: 2.9265623092651367
Validation loss: 2.5113522596256708

Epoch: 6| Step: 6
Training loss: 2.7050082683563232
Validation loss: 2.513054434971143

Epoch: 6| Step: 7
Training loss: 3.2138521671295166
Validation loss: 2.5145484350060903

Epoch: 6| Step: 8
Training loss: 3.19948148727417
Validation loss: 2.493685996660622

Epoch: 6| Step: 9
Training loss: 2.822021961212158
Validation loss: 2.486560462623514

Epoch: 6| Step: 10
Training loss: 1.86008620262146
Validation loss: 2.4838229225527857

Epoch: 6| Step: 11
Training loss: 1.9033095836639404
Validation loss: 2.4852371292729534

Epoch: 6| Step: 12
Training loss: 2.595688819885254
Validation loss: 2.4828111458850164

Epoch: 6| Step: 13
Training loss: 1.6789671182632446
Validation loss: 2.487757564872824

Epoch: 51| Step: 0
Training loss: 2.834834098815918
Validation loss: 2.4971148301196355

Epoch: 6| Step: 1
Training loss: 2.6840410232543945
Validation loss: 2.509408184277114

Epoch: 6| Step: 2
Training loss: 3.62660551071167
Validation loss: 2.5235728320255073

Epoch: 6| Step: 3
Training loss: 2.556192398071289
Validation loss: 2.5305487135405182

Epoch: 6| Step: 4
Training loss: 2.441641330718994
Validation loss: 2.53377172511111

Epoch: 6| Step: 5
Training loss: 2.2971718311309814
Validation loss: 2.5470981059535855

Epoch: 6| Step: 6
Training loss: 2.5672128200531006
Validation loss: 2.5480758887465282

Epoch: 6| Step: 7
Training loss: 2.345302104949951
Validation loss: 2.5342890421549478

Epoch: 6| Step: 8
Training loss: 2.52371883392334
Validation loss: 2.5028675448509956

Epoch: 6| Step: 9
Training loss: 2.5786075592041016
Validation loss: 2.49064306546283

Epoch: 6| Step: 10
Training loss: 2.7431235313415527
Validation loss: 2.4892191861265447

Epoch: 6| Step: 11
Training loss: 2.222989559173584
Validation loss: 2.4855947404779415

Epoch: 6| Step: 12
Training loss: 3.6798105239868164
Validation loss: 2.4899265458506923

Epoch: 6| Step: 13
Training loss: 2.6540451049804688
Validation loss: 2.48797159682038

Epoch: 52| Step: 0
Training loss: 2.379725456237793
Validation loss: 2.4895367135283766

Epoch: 6| Step: 1
Training loss: 2.786026954650879
Validation loss: 2.492875019709269

Epoch: 6| Step: 2
Training loss: 2.418386459350586
Validation loss: 2.5020087149835404

Epoch: 6| Step: 3
Training loss: 2.6589252948760986
Validation loss: 2.51579818161585

Epoch: 6| Step: 4
Training loss: 1.7699217796325684
Validation loss: 2.532330011808744

Epoch: 6| Step: 5
Training loss: 1.9054646492004395
Validation loss: 2.5510409801237044

Epoch: 6| Step: 6
Training loss: 2.828115463256836
Validation loss: 2.5150732122441775

Epoch: 6| Step: 7
Training loss: 2.9796998500823975
Validation loss: 2.4939050238619567

Epoch: 6| Step: 8
Training loss: 2.645151376724243
Validation loss: 2.4806850853786675

Epoch: 6| Step: 9
Training loss: 3.3641669750213623
Validation loss: 2.4814005564617854

Epoch: 6| Step: 10
Training loss: 2.850562334060669
Validation loss: 2.4817315301587506

Epoch: 6| Step: 11
Training loss: 2.3422133922576904
Validation loss: 2.4845597743988037

Epoch: 6| Step: 12
Training loss: 3.242490768432617
Validation loss: 2.4821925419633106

Epoch: 6| Step: 13
Training loss: 4.101762771606445
Validation loss: 2.482741214895761

Epoch: 53| Step: 0
Training loss: 3.360598564147949
Validation loss: 2.4814329711339806

Epoch: 6| Step: 1
Training loss: 2.7176499366760254
Validation loss: 2.481769554076656

Epoch: 6| Step: 2
Training loss: 2.9788382053375244
Validation loss: 2.4814604507979525

Epoch: 6| Step: 3
Training loss: 3.1550912857055664
Validation loss: 2.4787534103598645

Epoch: 6| Step: 4
Training loss: 3.111104965209961
Validation loss: 2.475555391721828

Epoch: 6| Step: 5
Training loss: 2.052212953567505
Validation loss: 2.4820289970726095

Epoch: 6| Step: 6
Training loss: 3.013667583465576
Validation loss: 2.4843036846448014

Epoch: 6| Step: 7
Training loss: 2.2974634170532227
Validation loss: 2.4928374598103185

Epoch: 6| Step: 8
Training loss: 2.238171339035034
Validation loss: 2.4923008180433706

Epoch: 6| Step: 9
Training loss: 2.2633891105651855
Validation loss: 2.4923149462669127

Epoch: 6| Step: 10
Training loss: 2.756171226501465
Validation loss: 2.496171861566523

Epoch: 6| Step: 11
Training loss: 2.197834014892578
Validation loss: 2.493936686105626

Epoch: 6| Step: 12
Training loss: 2.8652095794677734
Validation loss: 2.485270187418948

Epoch: 6| Step: 13
Training loss: 2.525536060333252
Validation loss: 2.4780693413108907

Epoch: 54| Step: 0
Training loss: 2.805091619491577
Validation loss: 2.469302874739452

Epoch: 6| Step: 1
Training loss: 2.2374730110168457
Validation loss: 2.470094729495305

Epoch: 6| Step: 2
Training loss: 2.308629035949707
Validation loss: 2.468461134100473

Epoch: 6| Step: 3
Training loss: 1.8012524843215942
Validation loss: 2.4741432384778093

Epoch: 6| Step: 4
Training loss: 2.5615508556365967
Validation loss: 2.483749105084327

Epoch: 6| Step: 5
Training loss: 2.141803741455078
Validation loss: 2.525775629986999

Epoch: 6| Step: 6
Training loss: 3.095032215118408
Validation loss: 2.557295483927573

Epoch: 6| Step: 7
Training loss: 3.2418036460876465
Validation loss: 2.571427760585662

Epoch: 6| Step: 8
Training loss: 4.110077857971191
Validation loss: 2.5283009185585925

Epoch: 6| Step: 9
Training loss: 3.2177014350891113
Validation loss: 2.47913860249263

Epoch: 6| Step: 10
Training loss: 2.3667848110198975
Validation loss: 2.4715623701772382

Epoch: 6| Step: 11
Training loss: 1.7956795692443848
Validation loss: 2.4688285217490247

Epoch: 6| Step: 12
Training loss: 3.041062593460083
Validation loss: 2.4732979677056752

Epoch: 6| Step: 13
Training loss: 3.383549690246582
Validation loss: 2.480947600897922

Epoch: 55| Step: 0
Training loss: 2.4784340858459473
Validation loss: 2.483187371684659

Epoch: 6| Step: 1
Training loss: 2.796034336090088
Validation loss: 2.4870950124597035

Epoch: 6| Step: 2
Training loss: 3.1959736347198486
Validation loss: 2.4880748615469983

Epoch: 6| Step: 3
Training loss: 2.164909601211548
Validation loss: 2.4861930801022436

Epoch: 6| Step: 4
Training loss: 2.7789885997772217
Validation loss: 2.48097030321757

Epoch: 6| Step: 5
Training loss: 3.330845594406128
Validation loss: 2.4717966048948226

Epoch: 6| Step: 6
Training loss: 2.3775453567504883
Validation loss: 2.469271395796089

Epoch: 6| Step: 7
Training loss: 3.08542537689209
Validation loss: 2.4709141562061925

Epoch: 6| Step: 8
Training loss: 2.797788381576538
Validation loss: 2.4920815908780662

Epoch: 6| Step: 9
Training loss: 2.993412971496582
Validation loss: 2.5193415713566605

Epoch: 6| Step: 10
Training loss: 2.215026617050171
Validation loss: 2.5469838367995394

Epoch: 6| Step: 11
Training loss: 2.415785789489746
Validation loss: 2.5645350922820387

Epoch: 6| Step: 12
Training loss: 2.6399636268615723
Validation loss: 2.5796666247870332

Epoch: 6| Step: 13
Training loss: 2.258650302886963
Validation loss: 2.569403576594527

Epoch: 56| Step: 0
Training loss: 2.478926181793213
Validation loss: 2.5659268671466458

Epoch: 6| Step: 1
Training loss: 3.0245938301086426
Validation loss: 2.542707690628626

Epoch: 6| Step: 2
Training loss: 2.5671048164367676
Validation loss: 2.510832158468103

Epoch: 6| Step: 3
Training loss: 3.445852518081665
Validation loss: 2.468936394619685

Epoch: 6| Step: 4
Training loss: 2.30830979347229
Validation loss: 2.4620908280854583

Epoch: 6| Step: 5
Training loss: 1.9673659801483154
Validation loss: 2.4633873483186126

Epoch: 6| Step: 6
Training loss: 2.722024440765381
Validation loss: 2.468716431689519

Epoch: 6| Step: 7
Training loss: 2.672269105911255
Validation loss: 2.4907430705203804

Epoch: 6| Step: 8
Training loss: 2.446617603302002
Validation loss: 2.5188342038021294

Epoch: 6| Step: 9
Training loss: 3.231580972671509
Validation loss: 2.564358877879317

Epoch: 6| Step: 10
Training loss: 2.760047435760498
Validation loss: 2.5204076049148396

Epoch: 6| Step: 11
Training loss: 2.989884853363037
Validation loss: 2.4993660167981218

Epoch: 6| Step: 12
Training loss: 2.8959641456604004
Validation loss: 2.4849216809836765

Epoch: 6| Step: 13
Training loss: 2.4386374950408936
Validation loss: 2.4804549729952248

Epoch: 57| Step: 0
Training loss: 2.674177885055542
Validation loss: 2.4873159598278742

Epoch: 6| Step: 1
Training loss: 2.441330909729004
Validation loss: 2.4915289378935292

Epoch: 6| Step: 2
Training loss: 3.5384774208068848
Validation loss: 2.5026563752082085

Epoch: 6| Step: 3
Training loss: 2.1962809562683105
Validation loss: 2.4632331376434653

Epoch: 6| Step: 4
Training loss: 2.0222387313842773
Validation loss: 2.457486352612895

Epoch: 6| Step: 5
Training loss: 1.8600480556488037
Validation loss: 2.4676871838108188

Epoch: 6| Step: 6
Training loss: 2.759019613265991
Validation loss: 2.4700408161327405

Epoch: 6| Step: 7
Training loss: 2.3326196670532227
Validation loss: 2.480909014260897

Epoch: 6| Step: 8
Training loss: 2.7515664100646973
Validation loss: 2.4893559153361986

Epoch: 6| Step: 9
Training loss: 3.3051376342773438
Validation loss: 2.5112733917851604

Epoch: 6| Step: 10
Training loss: 3.1751046180725098
Validation loss: 2.503297000802973

Epoch: 6| Step: 11
Training loss: 2.4955508708953857
Validation loss: 2.5019851448715373

Epoch: 6| Step: 12
Training loss: 3.1581339836120605
Validation loss: 2.4997890867212766

Epoch: 6| Step: 13
Training loss: 2.76888370513916
Validation loss: 2.49631844541078

Epoch: 58| Step: 0
Training loss: 2.8753318786621094
Validation loss: 2.4801904104089223

Epoch: 6| Step: 1
Training loss: 2.7470452785491943
Validation loss: 2.473359497644568

Epoch: 6| Step: 2
Training loss: 3.1758968830108643
Validation loss: 2.4675796108861126

Epoch: 6| Step: 3
Training loss: 3.3954861164093018
Validation loss: 2.4633304918965986

Epoch: 6| Step: 4
Training loss: 2.492558479309082
Validation loss: 2.4631764042762017

Epoch: 6| Step: 5
Training loss: 2.414262056350708
Validation loss: 2.462446412732524

Epoch: 6| Step: 6
Training loss: 2.2005462646484375
Validation loss: 2.4652427883558374

Epoch: 6| Step: 7
Training loss: 1.79633367061615
Validation loss: 2.4698741974369174

Epoch: 6| Step: 8
Training loss: 3.1248300075531006
Validation loss: 2.4766215919166483

Epoch: 6| Step: 9
Training loss: 2.3521780967712402
Validation loss: 2.473768126580023

Epoch: 6| Step: 10
Training loss: 2.898097515106201
Validation loss: 2.4761233586137013

Epoch: 6| Step: 11
Training loss: 2.3333778381347656
Validation loss: 2.488774509840114

Epoch: 6| Step: 12
Training loss: 3.0753612518310547
Validation loss: 2.5025319284008396

Epoch: 6| Step: 13
Training loss: 2.6558096408843994
Validation loss: 2.4899489648880495

Epoch: 59| Step: 0
Training loss: 3.0507631301879883
Validation loss: 2.48331771614731

Epoch: 6| Step: 1
Training loss: 3.2987923622131348
Validation loss: 2.5127369332057174

Epoch: 6| Step: 2
Training loss: 2.4787681102752686
Validation loss: 2.4944642833484116

Epoch: 6| Step: 3
Training loss: 2.3639259338378906
Validation loss: 2.4652230688320693

Epoch: 6| Step: 4
Training loss: 3.4548428058624268
Validation loss: 2.45851977409855

Epoch: 6| Step: 5
Training loss: 2.429927349090576
Validation loss: 2.4581736339035856

Epoch: 6| Step: 6
Training loss: 2.3286585807800293
Validation loss: 2.451883690331572

Epoch: 6| Step: 7
Training loss: 2.680696725845337
Validation loss: 2.452186774182063

Epoch: 6| Step: 8
Training loss: 1.9953378438949585
Validation loss: 2.4559287101991716

Epoch: 6| Step: 9
Training loss: 3.074488878250122
Validation loss: 2.463992388017716

Epoch: 6| Step: 10
Training loss: 2.446967601776123
Validation loss: 2.469937345033051

Epoch: 6| Step: 11
Training loss: 2.5413711071014404
Validation loss: 2.491115024012904

Epoch: 6| Step: 12
Training loss: 2.509498357772827
Validation loss: 2.5201246533342587

Epoch: 6| Step: 13
Training loss: 2.7903330326080322
Validation loss: 2.5476106315530758

Epoch: 60| Step: 0
Training loss: 2.6935741901397705
Validation loss: 2.5259745300457044

Epoch: 6| Step: 1
Training loss: 2.4573888778686523
Validation loss: 2.502399698380501

Epoch: 6| Step: 2
Training loss: 2.6745693683624268
Validation loss: 2.49761874188659

Epoch: 6| Step: 3
Training loss: 3.147914409637451
Validation loss: 2.4794421401075137

Epoch: 6| Step: 4
Training loss: 2.928328037261963
Validation loss: 2.4678200034685034

Epoch: 6| Step: 5
Training loss: 3.3338623046875
Validation loss: 2.4615923614912134

Epoch: 6| Step: 6
Training loss: 2.2346601486206055
Validation loss: 2.4563782779119347

Epoch: 6| Step: 7
Training loss: 2.6458380222320557
Validation loss: 2.4464098971377135

Epoch: 6| Step: 8
Training loss: 2.953890085220337
Validation loss: 2.442995591830182

Epoch: 6| Step: 9
Training loss: 2.061351776123047
Validation loss: 2.4396746389327513

Epoch: 6| Step: 10
Training loss: 2.8388869762420654
Validation loss: 2.438905813360727

Epoch: 6| Step: 11
Training loss: 2.235471487045288
Validation loss: 2.438575716428859

Epoch: 6| Step: 12
Training loss: 2.1676015853881836
Validation loss: 2.4428833018067064

Epoch: 6| Step: 13
Training loss: 3.255770444869995
Validation loss: 2.4469070408933904

Epoch: 61| Step: 0
Training loss: 1.9120197296142578
Validation loss: 2.4476868811474053

Epoch: 6| Step: 1
Training loss: 3.0574355125427246
Validation loss: 2.457634174695579

Epoch: 6| Step: 2
Training loss: 3.352383613586426
Validation loss: 2.4533193701057026

Epoch: 6| Step: 3
Training loss: 2.542165756225586
Validation loss: 2.4478522782684653

Epoch: 6| Step: 4
Training loss: 2.5889906883239746
Validation loss: 2.455042831359371

Epoch: 6| Step: 5
Training loss: 2.8573567867279053
Validation loss: 2.4553125827543196

Epoch: 6| Step: 6
Training loss: 2.4474902153015137
Validation loss: 2.454530321141725

Epoch: 6| Step: 7
Training loss: 2.199974536895752
Validation loss: 2.448226482637467

Epoch: 6| Step: 8
Training loss: 2.7731473445892334
Validation loss: 2.4525871174309843

Epoch: 6| Step: 9
Training loss: 2.4559686183929443
Validation loss: 2.463702658171295

Epoch: 6| Step: 10
Training loss: 2.394585132598877
Validation loss: 2.4682950409509803

Epoch: 6| Step: 11
Training loss: 3.009978771209717
Validation loss: 2.4573184802968013

Epoch: 6| Step: 12
Training loss: 2.9407448768615723
Validation loss: 2.451127685526366

Epoch: 6| Step: 13
Training loss: 3.0259904861450195
Validation loss: 2.4501347554627286

Epoch: 62| Step: 0
Training loss: 3.0057315826416016
Validation loss: 2.4456309938943512

Epoch: 6| Step: 1
Training loss: 2.0959930419921875
Validation loss: 2.435752830197734

Epoch: 6| Step: 2
Training loss: 2.047274112701416
Validation loss: 2.429170459829351

Epoch: 6| Step: 3
Training loss: 2.9607105255126953
Validation loss: 2.43462924931639

Epoch: 6| Step: 4
Training loss: 2.459883213043213
Validation loss: 2.433077981395106

Epoch: 6| Step: 5
Training loss: 2.707695484161377
Validation loss: 2.4419176963067826

Epoch: 6| Step: 6
Training loss: 2.787189245223999
Validation loss: 2.4466324672904065

Epoch: 6| Step: 7
Training loss: 2.5428764820098877
Validation loss: 2.4456561996090795

Epoch: 6| Step: 8
Training loss: 2.6657602787017822
Validation loss: 2.4446073911523305

Epoch: 6| Step: 9
Training loss: 3.1217904090881348
Validation loss: 2.4492017581898677

Epoch: 6| Step: 10
Training loss: 2.4492805004119873
Validation loss: 2.4400968654181368

Epoch: 6| Step: 11
Training loss: 2.429988384246826
Validation loss: 2.434467295164703

Epoch: 6| Step: 12
Training loss: 3.3952152729034424
Validation loss: 2.431530532016549

Epoch: 6| Step: 13
Training loss: 2.8749160766601562
Validation loss: 2.4335219296075965

Epoch: 63| Step: 0
Training loss: 2.559931755065918
Validation loss: 2.434380703074958

Epoch: 6| Step: 1
Training loss: 2.4803833961486816
Validation loss: 2.4353845504022416

Epoch: 6| Step: 2
Training loss: 2.9061145782470703
Validation loss: 2.4338074397015315

Epoch: 6| Step: 3
Training loss: 2.8183155059814453
Validation loss: 2.433880344513924

Epoch: 6| Step: 4
Training loss: 2.3536038398742676
Validation loss: 2.4388338647862917

Epoch: 6| Step: 5
Training loss: 2.4693403244018555
Validation loss: 2.448298572212137

Epoch: 6| Step: 6
Training loss: 2.100850820541382
Validation loss: 2.4551033678875176

Epoch: 6| Step: 7
Training loss: 2.054790496826172
Validation loss: 2.463761926979147

Epoch: 6| Step: 8
Training loss: 2.8837404251098633
Validation loss: 2.4750141687290643

Epoch: 6| Step: 9
Training loss: 3.280109405517578
Validation loss: 2.488870604063875

Epoch: 6| Step: 10
Training loss: 3.4148521423339844
Validation loss: 2.4860812233340357

Epoch: 6| Step: 11
Training loss: 2.317093849182129
Validation loss: 2.478359681303783

Epoch: 6| Step: 12
Training loss: 3.3959670066833496
Validation loss: 2.4767608693850938

Epoch: 6| Step: 13
Training loss: 2.200467109680176
Validation loss: 2.464103426984561

Epoch: 64| Step: 0
Training loss: 2.7205634117126465
Validation loss: 2.446310540681244

Epoch: 6| Step: 1
Training loss: 3.158660411834717
Validation loss: 2.438045988800705

Epoch: 6| Step: 2
Training loss: 2.6895387172698975
Validation loss: 2.4285978963298183

Epoch: 6| Step: 3
Training loss: 2.812299966812134
Validation loss: 2.431004754958614

Epoch: 6| Step: 4
Training loss: 2.783318042755127
Validation loss: 2.4293362658510924

Epoch: 6| Step: 5
Training loss: 2.7486209869384766
Validation loss: 2.428084111982776

Epoch: 6| Step: 6
Training loss: 2.9245128631591797
Validation loss: 2.4242396149584042

Epoch: 6| Step: 7
Training loss: 2.520278215408325
Validation loss: 2.422414759153961

Epoch: 6| Step: 8
Training loss: 1.7305177450180054
Validation loss: 2.423702193844703

Epoch: 6| Step: 9
Training loss: 2.099236488342285
Validation loss: 2.4243767697324037

Epoch: 6| Step: 10
Training loss: 2.650134325027466
Validation loss: 2.427962754362373

Epoch: 6| Step: 11
Training loss: 2.893044948577881
Validation loss: 2.4272243207500828

Epoch: 6| Step: 12
Training loss: 2.447021722793579
Validation loss: 2.4248083253060617

Epoch: 6| Step: 13
Training loss: 3.421251058578491
Validation loss: 2.429824303555232

Epoch: 65| Step: 0
Training loss: 2.345966339111328
Validation loss: 2.433110649867724

Epoch: 6| Step: 1
Training loss: 2.9015355110168457
Validation loss: 2.4323118284184444

Epoch: 6| Step: 2
Training loss: 2.4438295364379883
Validation loss: 2.4333400469954296

Epoch: 6| Step: 3
Training loss: 2.939094066619873
Validation loss: 2.4456638238763295

Epoch: 6| Step: 4
Training loss: 2.820958137512207
Validation loss: 2.4609447063938266

Epoch: 6| Step: 5
Training loss: 1.9521175622940063
Validation loss: 2.4456047447778846

Epoch: 6| Step: 6
Training loss: 2.215912342071533
Validation loss: 2.4430957225061234

Epoch: 6| Step: 7
Training loss: 2.701044797897339
Validation loss: 2.449356145756219

Epoch: 6| Step: 8
Training loss: 2.3109514713287354
Validation loss: 2.456644255627868

Epoch: 6| Step: 9
Training loss: 2.901472330093384
Validation loss: 2.4581354689854447

Epoch: 6| Step: 10
Training loss: 3.1297590732574463
Validation loss: 2.4578211153707197

Epoch: 6| Step: 11
Training loss: 2.4002599716186523
Validation loss: 2.4645588167252077

Epoch: 6| Step: 12
Training loss: 3.4994194507598877
Validation loss: 2.469719740652269

Epoch: 6| Step: 13
Training loss: 2.7440719604492188
Validation loss: 2.464133520280161

Epoch: 66| Step: 0
Training loss: 2.6377878189086914
Validation loss: 2.4734487610478557

Epoch: 6| Step: 1
Training loss: 3.036287784576416
Validation loss: 2.459935285711801

Epoch: 6| Step: 2
Training loss: 2.907590866088867
Validation loss: 2.4608974969515236

Epoch: 6| Step: 3
Training loss: 2.447723388671875
Validation loss: 2.4558438383122927

Epoch: 6| Step: 4
Training loss: 2.4351792335510254
Validation loss: 2.4565406999280377

Epoch: 6| Step: 5
Training loss: 3.205805540084839
Validation loss: 2.4552832213781213

Epoch: 6| Step: 6
Training loss: 2.792567014694214
Validation loss: 2.4581987268181256

Epoch: 6| Step: 7
Training loss: 2.5993449687957764
Validation loss: 2.4665950498273297

Epoch: 6| Step: 8
Training loss: 2.2832844257354736
Validation loss: 2.464202937259469

Epoch: 6| Step: 9
Training loss: 3.2396528720855713
Validation loss: 2.457962525788174

Epoch: 6| Step: 10
Training loss: 2.597229480743408
Validation loss: 2.4518302307333997

Epoch: 6| Step: 11
Training loss: 2.0303499698638916
Validation loss: 2.445866425832113

Epoch: 6| Step: 12
Training loss: 2.2145280838012695
Validation loss: 2.4405484635342836

Epoch: 6| Step: 13
Training loss: 3.0192174911499023
Validation loss: 2.4336296307143344

Epoch: 67| Step: 0
Training loss: 3.1764004230499268
Validation loss: 2.426363145151446

Epoch: 6| Step: 1
Training loss: 2.686361789703369
Validation loss: 2.4289431084868727

Epoch: 6| Step: 2
Training loss: 2.4942147731781006
Validation loss: 2.4242144887165358

Epoch: 6| Step: 3
Training loss: 2.0873687267303467
Validation loss: 2.424382166195941

Epoch: 6| Step: 4
Training loss: 3.091970443725586
Validation loss: 2.4258933990232405

Epoch: 6| Step: 5
Training loss: 2.061152696609497
Validation loss: 2.421308550783383

Epoch: 6| Step: 6
Training loss: 2.618342876434326
Validation loss: 2.4212504907320906

Epoch: 6| Step: 7
Training loss: 2.6370134353637695
Validation loss: 2.4256477458502657

Epoch: 6| Step: 8
Training loss: 2.8166019916534424
Validation loss: 2.422036132504863

Epoch: 6| Step: 9
Training loss: 2.5802338123321533
Validation loss: 2.429811982698338

Epoch: 6| Step: 10
Training loss: 2.748474597930908
Validation loss: 2.4266823081560034

Epoch: 6| Step: 11
Training loss: 2.3196654319763184
Validation loss: 2.4285491179394465

Epoch: 6| Step: 12
Training loss: 3.096102714538574
Validation loss: 2.4446540314664125

Epoch: 6| Step: 13
Training loss: 2.7325453758239746
Validation loss: 2.4676474345627653

Epoch: 68| Step: 0
Training loss: 2.1867077350616455
Validation loss: 2.4896097003772693

Epoch: 6| Step: 1
Training loss: 2.4970545768737793
Validation loss: 2.506105189682335

Epoch: 6| Step: 2
Training loss: 2.6523146629333496
Validation loss: 2.511089112168999

Epoch: 6| Step: 3
Training loss: 3.130664587020874
Validation loss: 2.5223784805625997

Epoch: 6| Step: 4
Training loss: 1.9286236763000488
Validation loss: 2.5190663209525486

Epoch: 6| Step: 5
Training loss: 2.015505313873291
Validation loss: 2.504768153672577

Epoch: 6| Step: 6
Training loss: 2.916522741317749
Validation loss: 2.50732385599485

Epoch: 6| Step: 7
Training loss: 2.8462114334106445
Validation loss: 2.4984939098358154

Epoch: 6| Step: 8
Training loss: 2.9607748985290527
Validation loss: 2.4926575332559566

Epoch: 6| Step: 9
Training loss: 3.2725040912628174
Validation loss: 2.4851552107000865

Epoch: 6| Step: 10
Training loss: 2.6482467651367188
Validation loss: 2.4801769564228673

Epoch: 6| Step: 11
Training loss: 3.3567142486572266
Validation loss: 2.4789188010718233

Epoch: 6| Step: 12
Training loss: 2.112976312637329
Validation loss: 2.4791091206253215

Epoch: 6| Step: 13
Training loss: 3.466017723083496
Validation loss: 2.481629576734317

Epoch: 69| Step: 0
Training loss: 3.373443126678467
Validation loss: 2.482410600108485

Epoch: 6| Step: 1
Training loss: 2.6516239643096924
Validation loss: 2.479331165231684

Epoch: 6| Step: 2
Training loss: 2.5777299404144287
Validation loss: 2.4831010141680316

Epoch: 6| Step: 3
Training loss: 2.5654029846191406
Validation loss: 2.492315717922744

Epoch: 6| Step: 4
Training loss: 3.127718925476074
Validation loss: 2.496547645138156

Epoch: 6| Step: 5
Training loss: 3.039801836013794
Validation loss: 2.4995726718697497

Epoch: 6| Step: 6
Training loss: 2.9215424060821533
Validation loss: 2.49023957919049

Epoch: 6| Step: 7
Training loss: 2.186521053314209
Validation loss: 2.4875580033948346

Epoch: 6| Step: 8
Training loss: 2.600989580154419
Validation loss: 2.4838596915686004

Epoch: 6| Step: 9
Training loss: 2.449760913848877
Validation loss: 2.488614736064788

Epoch: 6| Step: 10
Training loss: 2.26509952545166
Validation loss: 2.485122690918625

Epoch: 6| Step: 11
Training loss: 2.3637402057647705
Validation loss: 2.4905332339707242

Epoch: 6| Step: 12
Training loss: 3.005319595336914
Validation loss: 2.4893883402629564

Epoch: 6| Step: 13
Training loss: 2.1628289222717285
Validation loss: 2.4890188658109276

Epoch: 70| Step: 0
Training loss: 2.8751466274261475
Validation loss: 2.494350614086274

Epoch: 6| Step: 1
Training loss: 2.49395751953125
Validation loss: 2.4941778695711525

Epoch: 6| Step: 2
Training loss: 2.8560688495635986
Validation loss: 2.489067949274535

Epoch: 6| Step: 3
Training loss: 3.2586371898651123
Validation loss: 2.485597348982288

Epoch: 6| Step: 4
Training loss: 2.524050235748291
Validation loss: 2.479211402195756

Epoch: 6| Step: 5
Training loss: 3.3114075660705566
Validation loss: 2.4801862009109987

Epoch: 6| Step: 6
Training loss: 2.1404380798339844
Validation loss: 2.4735593975231214

Epoch: 6| Step: 7
Training loss: 2.5359439849853516
Validation loss: 2.471298799719862

Epoch: 6| Step: 8
Training loss: 2.385037660598755
Validation loss: 2.4709705845002206

Epoch: 6| Step: 9
Training loss: 2.556424617767334
Validation loss: 2.474578885621922

Epoch: 6| Step: 10
Training loss: 2.9280710220336914
Validation loss: 2.4800853908702893

Epoch: 6| Step: 11
Training loss: 2.917079448699951
Validation loss: 2.478301130315309

Epoch: 6| Step: 12
Training loss: 2.5901288986206055
Validation loss: 2.479893310095674

Epoch: 6| Step: 13
Training loss: 1.695631742477417
Validation loss: 2.4776092575442408

Epoch: 71| Step: 0
Training loss: 2.375932216644287
Validation loss: 2.4876240889231362

Epoch: 6| Step: 1
Training loss: 3.6680195331573486
Validation loss: 2.4877300723906486

Epoch: 6| Step: 2
Training loss: 2.39731502532959
Validation loss: 2.4903406122679352

Epoch: 6| Step: 3
Training loss: 2.2078676223754883
Validation loss: 2.4889914143470024

Epoch: 6| Step: 4
Training loss: 2.682593822479248
Validation loss: 2.4882424441717004

Epoch: 6| Step: 5
Training loss: 2.7412381172180176
Validation loss: 2.490769237600347

Epoch: 6| Step: 6
Training loss: 2.470982313156128
Validation loss: 2.489639664209017

Epoch: 6| Step: 7
Training loss: 2.0186960697174072
Validation loss: 2.4929689463748725

Epoch: 6| Step: 8
Training loss: 3.0815110206604004
Validation loss: 2.4977292732525895

Epoch: 6| Step: 9
Training loss: 2.745296001434326
Validation loss: 2.502662181854248

Epoch: 6| Step: 10
Training loss: 2.700941562652588
Validation loss: 2.517905717254967

Epoch: 6| Step: 11
Training loss: 3.016707420349121
Validation loss: 2.542252617497598

Epoch: 6| Step: 12
Training loss: 2.7850308418273926
Validation loss: 2.5564879089273433

Epoch: 6| Step: 13
Training loss: 2.6657776832580566
Validation loss: 2.5461687810959353

Epoch: 72| Step: 0
Training loss: 2.6159186363220215
Validation loss: 2.534336336197392

Epoch: 6| Step: 1
Training loss: 1.8103268146514893
Validation loss: 2.503370267088695

Epoch: 6| Step: 2
Training loss: 2.9261550903320312
Validation loss: 2.4620998085186048

Epoch: 6| Step: 3
Training loss: 2.5129785537719727
Validation loss: 2.4526920036603044

Epoch: 6| Step: 4
Training loss: 2.348115921020508
Validation loss: 2.447599708393056

Epoch: 6| Step: 5
Training loss: 2.91256046295166
Validation loss: 2.460703255027853

Epoch: 6| Step: 6
Training loss: 2.713311195373535
Validation loss: 2.4474315002400386

Epoch: 6| Step: 7
Training loss: 2.7589762210845947
Validation loss: 2.4324727827502834

Epoch: 6| Step: 8
Training loss: 2.6203043460845947
Validation loss: 2.4216813541227773

Epoch: 6| Step: 9
Training loss: 3.063563585281372
Validation loss: 2.4297605586308304

Epoch: 6| Step: 10
Training loss: 2.216918468475342
Validation loss: 2.4414197860225553

Epoch: 6| Step: 11
Training loss: 3.6798696517944336
Validation loss: 2.446651004975842

Epoch: 6| Step: 12
Training loss: 2.768907070159912
Validation loss: 2.4374283975170505

Epoch: 6| Step: 13
Training loss: 2.380747079849243
Validation loss: 2.42023995871185

Epoch: 73| Step: 0
Training loss: 2.393599510192871
Validation loss: 2.416102624708606

Epoch: 6| Step: 1
Training loss: 2.7254090309143066
Validation loss: 2.4106139803445465

Epoch: 6| Step: 2
Training loss: 2.6715140342712402
Validation loss: 2.409015732426797

Epoch: 6| Step: 3
Training loss: 2.3969788551330566
Validation loss: 2.414033597515475

Epoch: 6| Step: 4
Training loss: 2.4138331413269043
Validation loss: 2.415213482354277

Epoch: 6| Step: 5
Training loss: 2.3071274757385254
Validation loss: 2.424717354518111

Epoch: 6| Step: 6
Training loss: 2.969841718673706
Validation loss: 2.4275350263041835

Epoch: 6| Step: 7
Training loss: 2.6539714336395264
Validation loss: 2.426447335109916

Epoch: 6| Step: 8
Training loss: 2.484671115875244
Validation loss: 2.4326192255943053

Epoch: 6| Step: 9
Training loss: 2.388333320617676
Validation loss: 2.4176013969605967

Epoch: 6| Step: 10
Training loss: 3.2445931434631348
Validation loss: 2.4131373897675545

Epoch: 6| Step: 11
Training loss: 2.989227771759033
Validation loss: 2.4096996348391295

Epoch: 6| Step: 12
Training loss: 2.798495054244995
Validation loss: 2.404295556006893

Epoch: 6| Step: 13
Training loss: 2.5759522914886475
Validation loss: 2.399586293005174

Epoch: 74| Step: 0
Training loss: 3.29679536819458
Validation loss: 2.4040609200795493

Epoch: 6| Step: 1
Training loss: 2.3963570594787598
Validation loss: 2.4051689460713375

Epoch: 6| Step: 2
Training loss: 2.158029556274414
Validation loss: 2.3993897745686192

Epoch: 6| Step: 3
Training loss: 2.7861738204956055
Validation loss: 2.401522551813433

Epoch: 6| Step: 4
Training loss: 2.2930960655212402
Validation loss: 2.397085943529683

Epoch: 6| Step: 5
Training loss: 2.8879876136779785
Validation loss: 2.4035337355829056

Epoch: 6| Step: 6
Training loss: 1.9905872344970703
Validation loss: 2.397439605446272

Epoch: 6| Step: 7
Training loss: 2.8311290740966797
Validation loss: 2.3965150233237975

Epoch: 6| Step: 8
Training loss: 2.5807042121887207
Validation loss: 2.4069037027256464

Epoch: 6| Step: 9
Training loss: 2.744534730911255
Validation loss: 2.4065545797348022

Epoch: 6| Step: 10
Training loss: 2.7320852279663086
Validation loss: 2.394791864579724

Epoch: 6| Step: 11
Training loss: 3.1386361122131348
Validation loss: 2.410099030822836

Epoch: 6| Step: 12
Training loss: 2.6315760612487793
Validation loss: 2.4192516521740983

Epoch: 6| Step: 13
Training loss: 2.3721938133239746
Validation loss: 2.4402249602861303

Epoch: 75| Step: 0
Training loss: 2.6368606090545654
Validation loss: 2.422522775588497

Epoch: 6| Step: 1
Training loss: 3.1083993911743164
Validation loss: 2.443316146891604

Epoch: 6| Step: 2
Training loss: 2.381356716156006
Validation loss: 2.4340775961517007

Epoch: 6| Step: 3
Training loss: 3.086792469024658
Validation loss: 2.4648616672844015

Epoch: 6| Step: 4
Training loss: 2.595632553100586
Validation loss: 2.4589221426235732

Epoch: 6| Step: 5
Training loss: 2.4525654315948486
Validation loss: 2.4547452247270973

Epoch: 6| Step: 6
Training loss: 2.493140459060669
Validation loss: 2.4388764955664195

Epoch: 6| Step: 7
Training loss: 2.1263132095336914
Validation loss: 2.44897372235534

Epoch: 6| Step: 8
Training loss: 2.7448573112487793
Validation loss: 2.4378276640369045

Epoch: 6| Step: 9
Training loss: 2.8535215854644775
Validation loss: 2.435732267236197

Epoch: 6| Step: 10
Training loss: 3.346113920211792
Validation loss: 2.413714624220325

Epoch: 6| Step: 11
Training loss: 2.3680596351623535
Validation loss: 2.4096741061056814

Epoch: 6| Step: 12
Training loss: 2.4518821239471436
Validation loss: 2.412620347033265

Epoch: 6| Step: 13
Training loss: 2.0374720096588135
Validation loss: 2.407798180016138

Epoch: 76| Step: 0
Training loss: 2.530276298522949
Validation loss: 2.4082895863440728

Epoch: 6| Step: 1
Training loss: 3.0930256843566895
Validation loss: 2.4019000427697295

Epoch: 6| Step: 2
Training loss: 3.2057301998138428
Validation loss: 2.4022017294360745

Epoch: 6| Step: 3
Training loss: 2.627168655395508
Validation loss: 2.39689604954053

Epoch: 6| Step: 4
Training loss: 2.5069680213928223
Validation loss: 2.3953986219180528

Epoch: 6| Step: 5
Training loss: 2.5451440811157227
Validation loss: 2.3950654845083914

Epoch: 6| Step: 6
Training loss: 2.3197481632232666
Validation loss: 2.3992384556801087

Epoch: 6| Step: 7
Training loss: 2.8975887298583984
Validation loss: 2.3970768297872236

Epoch: 6| Step: 8
Training loss: 2.2000911235809326
Validation loss: 2.3975384132836455

Epoch: 6| Step: 9
Training loss: 2.5895907878875732
Validation loss: 2.397467872147919

Epoch: 6| Step: 10
Training loss: 2.0346155166625977
Validation loss: 2.396530501304134

Epoch: 6| Step: 11
Training loss: 2.749610185623169
Validation loss: 2.4052457629993396

Epoch: 6| Step: 12
Training loss: 2.8566763401031494
Validation loss: 2.406578166510469

Epoch: 6| Step: 13
Training loss: 2.7772741317749023
Validation loss: 2.4078607379749255

Epoch: 77| Step: 0
Training loss: 2.5607552528381348
Validation loss: 2.4123890451205674

Epoch: 6| Step: 1
Training loss: 2.6965932846069336
Validation loss: 2.4173718652417584

Epoch: 6| Step: 2
Training loss: 2.8075666427612305
Validation loss: 2.4280375562688357

Epoch: 6| Step: 3
Training loss: 2.6803526878356934
Validation loss: 2.4523066705273044

Epoch: 6| Step: 4
Training loss: 1.9132301807403564
Validation loss: 2.438759316680252

Epoch: 6| Step: 5
Training loss: 3.0548343658447266
Validation loss: 2.4412531160539195

Epoch: 6| Step: 6
Training loss: 2.5218238830566406
Validation loss: 2.432628285500311

Epoch: 6| Step: 7
Training loss: 3.0400075912475586
Validation loss: 2.412347719233523

Epoch: 6| Step: 8
Training loss: 2.9844555854797363
Validation loss: 2.405359519425259

Epoch: 6| Step: 9
Training loss: 2.6305441856384277
Validation loss: 2.397088691752444

Epoch: 6| Step: 10
Training loss: 2.746170997619629
Validation loss: 2.394362288136636

Epoch: 6| Step: 11
Training loss: 1.812965989112854
Validation loss: 2.393360996759066

Epoch: 6| Step: 12
Training loss: 2.9389657974243164
Validation loss: 2.3951606827397502

Epoch: 6| Step: 13
Training loss: 2.2900278568267822
Validation loss: 2.395471260111819

Epoch: 78| Step: 0
Training loss: 3.024050712585449
Validation loss: 2.398767138040194

Epoch: 6| Step: 1
Training loss: 2.425278663635254
Validation loss: 2.401202658171295

Epoch: 6| Step: 2
Training loss: 1.9919679164886475
Validation loss: 2.4080807649961082

Epoch: 6| Step: 3
Training loss: 2.7663307189941406
Validation loss: 2.416768612400178

Epoch: 6| Step: 4
Training loss: 2.982774019241333
Validation loss: 2.426354706928294

Epoch: 6| Step: 5
Training loss: 2.911503314971924
Validation loss: 2.425002703102686

Epoch: 6| Step: 6
Training loss: 3.067453145980835
Validation loss: 2.4230283537218646

Epoch: 6| Step: 7
Training loss: 3.205264091491699
Validation loss: 2.4311165835267756

Epoch: 6| Step: 8
Training loss: 2.468151092529297
Validation loss: 2.429936250050863

Epoch: 6| Step: 9
Training loss: 2.700967788696289
Validation loss: 2.427678600434334

Epoch: 6| Step: 10
Training loss: 1.9664082527160645
Validation loss: 2.4163927467920447

Epoch: 6| Step: 11
Training loss: 2.142885208129883
Validation loss: 2.40731627966768

Epoch: 6| Step: 12
Training loss: 2.343477487564087
Validation loss: 2.40132418499198

Epoch: 6| Step: 13
Training loss: 2.806405544281006
Validation loss: 2.3970217217681227

Epoch: 79| Step: 0
Training loss: 2.4676499366760254
Validation loss: 2.387172855356688

Epoch: 6| Step: 1
Training loss: 2.6405587196350098
Validation loss: 2.383158145412322

Epoch: 6| Step: 2
Training loss: 3.1840286254882812
Validation loss: 2.385120314936484

Epoch: 6| Step: 3
Training loss: 3.056178569793701
Validation loss: 2.383844506356024

Epoch: 6| Step: 4
Training loss: 2.0465521812438965
Validation loss: 2.382725854073801

Epoch: 6| Step: 5
Training loss: 2.653303384780884
Validation loss: 2.390728409572314

Epoch: 6| Step: 6
Training loss: 2.923736572265625
Validation loss: 2.3895910196406867

Epoch: 6| Step: 7
Training loss: 2.4907453060150146
Validation loss: 2.396524731830884

Epoch: 6| Step: 8
Training loss: 2.2637181282043457
Validation loss: 2.399422845532817

Epoch: 6| Step: 9
Training loss: 2.5504002571105957
Validation loss: 2.40181734741375

Epoch: 6| Step: 10
Training loss: 2.4328384399414062
Validation loss: 2.4076743689916467

Epoch: 6| Step: 11
Training loss: 2.366805076599121
Validation loss: 2.410226232262068

Epoch: 6| Step: 12
Training loss: 2.4676356315612793
Validation loss: 2.425676735498572

Epoch: 6| Step: 13
Training loss: 3.6409997940063477
Validation loss: 2.439870067822036

Epoch: 80| Step: 0
Training loss: 3.2724037170410156
Validation loss: 2.4572758110620643

Epoch: 6| Step: 1
Training loss: 2.268986225128174
Validation loss: 2.4719861681743334

Epoch: 6| Step: 2
Training loss: 2.493842601776123
Validation loss: 2.474450793317569

Epoch: 6| Step: 3
Training loss: 2.1278326511383057
Validation loss: 2.469949819708383

Epoch: 6| Step: 4
Training loss: 2.620543956756592
Validation loss: 2.472832756657754

Epoch: 6| Step: 5
Training loss: 2.5087203979492188
Validation loss: 2.4469673351574968

Epoch: 6| Step: 6
Training loss: 3.257974624633789
Validation loss: 2.427198762534767

Epoch: 6| Step: 7
Training loss: 2.3478105068206787
Validation loss: 2.416686834827546

Epoch: 6| Step: 8
Training loss: 2.7863588333129883
Validation loss: 2.409766443314091

Epoch: 6| Step: 9
Training loss: 2.3036956787109375
Validation loss: 2.395529936718684

Epoch: 6| Step: 10
Training loss: 2.2643301486968994
Validation loss: 2.3917920204900924

Epoch: 6| Step: 11
Training loss: 2.5474700927734375
Validation loss: 2.3890193662335797

Epoch: 6| Step: 12
Training loss: 3.439915418624878
Validation loss: 2.387071717169977

Epoch: 6| Step: 13
Training loss: 2.7516446113586426
Validation loss: 2.39275856940977

Epoch: 81| Step: 0
Training loss: 3.4258103370666504
Validation loss: 2.3902430585635606

Epoch: 6| Step: 1
Training loss: 2.1496410369873047
Validation loss: 2.3863106953200472

Epoch: 6| Step: 2
Training loss: 2.774087429046631
Validation loss: 2.383883273729714

Epoch: 6| Step: 3
Training loss: 2.5874977111816406
Validation loss: 2.3769005678033315

Epoch: 6| Step: 4
Training loss: 2.995227336883545
Validation loss: 2.3786238778022026

Epoch: 6| Step: 5
Training loss: 2.568793773651123
Validation loss: 2.3753030274503972

Epoch: 6| Step: 6
Training loss: 2.203731060028076
Validation loss: 2.381071772626651

Epoch: 6| Step: 7
Training loss: 2.841383695602417
Validation loss: 2.3752456890639437

Epoch: 6| Step: 8
Training loss: 1.6808147430419922
Validation loss: 2.3737472975125877

Epoch: 6| Step: 9
Training loss: 2.568683624267578
Validation loss: 2.3784600432201097

Epoch: 6| Step: 10
Training loss: 2.382059097290039
Validation loss: 2.3831471256030503

Epoch: 6| Step: 11
Training loss: 2.8605360984802246
Validation loss: 2.3865996253105903

Epoch: 6| Step: 12
Training loss: 2.848397731781006
Validation loss: 2.3944537126889793

Epoch: 6| Step: 13
Training loss: 3.024989128112793
Validation loss: 2.4020162115814867

Epoch: 82| Step: 0
Training loss: 2.561978340148926
Validation loss: 2.427731285813034

Epoch: 6| Step: 1
Training loss: 2.802656650543213
Validation loss: 2.4291589798465854

Epoch: 6| Step: 2
Training loss: 2.629594087600708
Validation loss: 2.4386065416438605

Epoch: 6| Step: 3
Training loss: 3.1434717178344727
Validation loss: 2.4426356566849576

Epoch: 6| Step: 4
Training loss: 1.9585928916931152
Validation loss: 2.43238728661691

Epoch: 6| Step: 5
Training loss: 2.0912582874298096
Validation loss: 2.430745606781334

Epoch: 6| Step: 6
Training loss: 2.940969944000244
Validation loss: 2.4273809668838338

Epoch: 6| Step: 7
Training loss: 2.3955602645874023
Validation loss: 2.41884252589236

Epoch: 6| Step: 8
Training loss: 2.5983893871307373
Validation loss: 2.410556882940313

Epoch: 6| Step: 9
Training loss: 2.7458157539367676
Validation loss: 2.404841979344686

Epoch: 6| Step: 10
Training loss: 3.070570468902588
Validation loss: 2.383865725609564

Epoch: 6| Step: 11
Training loss: 3.378479242324829
Validation loss: 2.376083912387971

Epoch: 6| Step: 12
Training loss: 2.250742197036743
Validation loss: 2.365276277706187

Epoch: 6| Step: 13
Training loss: 1.7877320051193237
Validation loss: 2.361011148780905

Epoch: 83| Step: 0
Training loss: 2.208932399749756
Validation loss: 2.357006014034312

Epoch: 6| Step: 1
Training loss: 2.288978338241577
Validation loss: 2.359499482698338

Epoch: 6| Step: 2
Training loss: 3.650520086288452
Validation loss: 2.359972330831712

Epoch: 6| Step: 3
Training loss: 2.580570936203003
Validation loss: 2.3639558617786696

Epoch: 6| Step: 4
Training loss: 2.6985228061676025
Validation loss: 2.365699101519841

Epoch: 6| Step: 5
Training loss: 2.4600746631622314
Validation loss: 2.362156250143564

Epoch: 6| Step: 6
Training loss: 3.6979193687438965
Validation loss: 2.3634246703117125

Epoch: 6| Step: 7
Training loss: 1.6618123054504395
Validation loss: 2.365719526044784

Epoch: 6| Step: 8
Training loss: 2.9910452365875244
Validation loss: 2.371367149455573

Epoch: 6| Step: 9
Training loss: 1.989059329032898
Validation loss: 2.3690914774453766

Epoch: 6| Step: 10
Training loss: 2.6709072589874268
Validation loss: 2.3772537195554344

Epoch: 6| Step: 11
Training loss: 2.1663715839385986
Validation loss: 2.378115728337278

Epoch: 6| Step: 12
Training loss: 2.4352307319641113
Validation loss: 2.3760274430756927

Epoch: 6| Step: 13
Training loss: 3.65010929107666
Validation loss: 2.369834312828638

Epoch: 84| Step: 0
Training loss: 2.63571834564209
Validation loss: 2.3757375594108336

Epoch: 6| Step: 1
Training loss: 2.9266610145568848
Validation loss: 2.375654325690321

Epoch: 6| Step: 2
Training loss: 2.6243271827697754
Validation loss: 2.37296163523069

Epoch: 6| Step: 3
Training loss: 3.201711893081665
Validation loss: 2.3645081904626664

Epoch: 6| Step: 4
Training loss: 2.8535988330841064
Validation loss: 2.3655769568617626

Epoch: 6| Step: 5
Training loss: 2.3917388916015625
Validation loss: 2.369734828190137

Epoch: 6| Step: 6
Training loss: 1.834090232849121
Validation loss: 2.366405556278844

Epoch: 6| Step: 7
Training loss: 3.042051315307617
Validation loss: 2.364890306226669

Epoch: 6| Step: 8
Training loss: 2.2497899532318115
Validation loss: 2.37159393166983

Epoch: 6| Step: 9
Training loss: 2.3174452781677246
Validation loss: 2.367260189466579

Epoch: 6| Step: 10
Training loss: 2.5479094982147217
Validation loss: 2.3657368485645582

Epoch: 6| Step: 11
Training loss: 2.30342960357666
Validation loss: 2.362579914831346

Epoch: 6| Step: 12
Training loss: 2.8650388717651367
Validation loss: 2.357940807137438

Epoch: 6| Step: 13
Training loss: 2.887146472930908
Validation loss: 2.363595731796757

Epoch: 85| Step: 0
Training loss: 2.680077314376831
Validation loss: 2.365061693294074

Epoch: 6| Step: 1
Training loss: 2.3921167850494385
Validation loss: 2.3653706030179094

Epoch: 6| Step: 2
Training loss: 2.255540370941162
Validation loss: 2.377168660522789

Epoch: 6| Step: 3
Training loss: 1.7801668643951416
Validation loss: 2.3747562439210954

Epoch: 6| Step: 4
Training loss: 2.527296543121338
Validation loss: 2.3729913003983034

Epoch: 6| Step: 5
Training loss: 1.8774588108062744
Validation loss: 2.3724551623867405

Epoch: 6| Step: 6
Training loss: 2.8800623416900635
Validation loss: 2.375488112049718

Epoch: 6| Step: 7
Training loss: 3.086243152618408
Validation loss: 2.3806171083963044

Epoch: 6| Step: 8
Training loss: 2.5614328384399414
Validation loss: 2.3871632647770706

Epoch: 6| Step: 9
Training loss: 2.10073184967041
Validation loss: 2.4030425343462216

Epoch: 6| Step: 10
Training loss: 2.1821258068084717
Validation loss: 2.431188121918709

Epoch: 6| Step: 11
Training loss: 3.6580986976623535
Validation loss: 2.4315854093079925

Epoch: 6| Step: 12
Training loss: 3.4332122802734375
Validation loss: 2.420683183977681

Epoch: 6| Step: 13
Training loss: 3.7974390983581543
Validation loss: 2.405188775831653

Epoch: 86| Step: 0
Training loss: 2.8668999671936035
Validation loss: 2.385108704208046

Epoch: 6| Step: 1
Training loss: 3.107515811920166
Validation loss: 2.3851790120524745

Epoch: 6| Step: 2
Training loss: 3.1287848949432373
Validation loss: 2.3792521005035727

Epoch: 6| Step: 3
Training loss: 2.5554914474487305
Validation loss: 2.3772727930417625

Epoch: 6| Step: 4
Training loss: 2.4602129459381104
Validation loss: 2.3714800265527542

Epoch: 6| Step: 5
Training loss: 2.015805721282959
Validation loss: 2.3678018995510635

Epoch: 6| Step: 6
Training loss: 2.7532758712768555
Validation loss: 2.36155443550438

Epoch: 6| Step: 7
Training loss: 2.3623366355895996
Validation loss: 2.360204791509977

Epoch: 6| Step: 8
Training loss: 2.6700448989868164
Validation loss: 2.3657540300840973

Epoch: 6| Step: 9
Training loss: 2.0319840908050537
Validation loss: 2.3655579243936846

Epoch: 6| Step: 10
Training loss: 2.4315829277038574
Validation loss: 2.378275917422387

Epoch: 6| Step: 11
Training loss: 2.951673984527588
Validation loss: 2.3711790718058103

Epoch: 6| Step: 12
Training loss: 2.191412925720215
Validation loss: 2.3872094910631896

Epoch: 6| Step: 13
Training loss: 3.1885287761688232
Validation loss: 2.3887986354930426

Epoch: 87| Step: 0
Training loss: 2.028247594833374
Validation loss: 2.3700338666157057

Epoch: 6| Step: 1
Training loss: 3.009443759918213
Validation loss: 2.389931724917504

Epoch: 6| Step: 2
Training loss: 2.508512496948242
Validation loss: 2.374308319501979

Epoch: 6| Step: 3
Training loss: 2.4280261993408203
Validation loss: 2.373676492321876

Epoch: 6| Step: 4
Training loss: 2.512228012084961
Validation loss: 2.3673920118680565

Epoch: 6| Step: 5
Training loss: 2.8827860355377197
Validation loss: 2.364708290305189

Epoch: 6| Step: 6
Training loss: 3.017958641052246
Validation loss: 2.367900912479688

Epoch: 6| Step: 7
Training loss: 2.368288516998291
Validation loss: 2.3713300292209913

Epoch: 6| Step: 8
Training loss: 2.842200994491577
Validation loss: 2.37611400183811

Epoch: 6| Step: 9
Training loss: 2.7724008560180664
Validation loss: 2.384319233637984

Epoch: 6| Step: 10
Training loss: 2.5861291885375977
Validation loss: 2.391667104536487

Epoch: 6| Step: 11
Training loss: 2.2769556045532227
Validation loss: 2.4021807921830045

Epoch: 6| Step: 12
Training loss: 2.6684069633483887
Validation loss: 2.3889502299729215

Epoch: 6| Step: 13
Training loss: 2.5997438430786133
Validation loss: 2.3912336954506497

Epoch: 88| Step: 0
Training loss: 1.5440726280212402
Validation loss: 2.386402996637488

Epoch: 6| Step: 1
Training loss: 3.0603532791137695
Validation loss: 2.3827303327539915

Epoch: 6| Step: 2
Training loss: 2.993943452835083
Validation loss: 2.37700774592738

Epoch: 6| Step: 3
Training loss: 2.2974228858947754
Validation loss: 2.3721105667852584

Epoch: 6| Step: 4
Training loss: 2.8907113075256348
Validation loss: 2.3694524713741836

Epoch: 6| Step: 5
Training loss: 2.783139228820801
Validation loss: 2.374347386821624

Epoch: 6| Step: 6
Training loss: 3.1956748962402344
Validation loss: 2.380026178975259

Epoch: 6| Step: 7
Training loss: 2.5455620288848877
Validation loss: 2.380464989651916

Epoch: 6| Step: 8
Training loss: 2.797783136367798
Validation loss: 2.378118940578994

Epoch: 6| Step: 9
Training loss: 2.910843849182129
Validation loss: 2.381381078432965

Epoch: 6| Step: 10
Training loss: 2.1437699794769287
Validation loss: 2.37340683321799

Epoch: 6| Step: 11
Training loss: 2.2482688426971436
Validation loss: 2.3651822818222867

Epoch: 6| Step: 12
Training loss: 2.3997373580932617
Validation loss: 2.3581427861285467

Epoch: 6| Step: 13
Training loss: 2.469259023666382
Validation loss: 2.3569921139747865

Epoch: 89| Step: 0
Training loss: 2.8886401653289795
Validation loss: 2.358546628746935

Epoch: 6| Step: 1
Training loss: 2.483903408050537
Validation loss: 2.3586745851783344

Epoch: 6| Step: 2
Training loss: 2.0256829261779785
Validation loss: 2.3552606541623353

Epoch: 6| Step: 3
Training loss: 2.382840633392334
Validation loss: 2.354033775227044

Epoch: 6| Step: 4
Training loss: 2.3595263957977295
Validation loss: 2.364563734300675

Epoch: 6| Step: 5
Training loss: 2.1028079986572266
Validation loss: 2.365991125824631

Epoch: 6| Step: 6
Training loss: 3.643312931060791
Validation loss: 2.374598697949481

Epoch: 6| Step: 7
Training loss: 2.795196294784546
Validation loss: 2.373798729271017

Epoch: 6| Step: 8
Training loss: 2.9143576622009277
Validation loss: 2.3758933697977374

Epoch: 6| Step: 9
Training loss: 1.7941036224365234
Validation loss: 2.378478419396185

Epoch: 6| Step: 10
Training loss: 2.9726457595825195
Validation loss: 2.373915926102669

Epoch: 6| Step: 11
Training loss: 2.84018611907959
Validation loss: 2.3890255625529955

Epoch: 6| Step: 12
Training loss: 2.248450756072998
Validation loss: 2.3797232771432526

Epoch: 6| Step: 13
Training loss: 3.0045628547668457
Validation loss: 2.3742221247765327

Epoch: 90| Step: 0
Training loss: 2.700143814086914
Validation loss: 2.347454804246144

Epoch: 6| Step: 1
Training loss: 3.064476490020752
Validation loss: 2.339692920766851

Epoch: 6| Step: 2
Training loss: 3.2856266498565674
Validation loss: 2.3317073557966497

Epoch: 6| Step: 3
Training loss: 2.7273447513580322
Validation loss: 2.3303441757796914

Epoch: 6| Step: 4
Training loss: 2.1340389251708984
Validation loss: 2.3283158322816253

Epoch: 6| Step: 5
Training loss: 2.331608772277832
Validation loss: 2.327965264679283

Epoch: 6| Step: 6
Training loss: 2.9588077068328857
Validation loss: 2.3355327626710296

Epoch: 6| Step: 7
Training loss: 2.6802725791931152
Validation loss: 2.341915792034518

Epoch: 6| Step: 8
Training loss: 2.0795555114746094
Validation loss: 2.3464604346982894

Epoch: 6| Step: 9
Training loss: 2.1974782943725586
Validation loss: 2.341431156281502

Epoch: 6| Step: 10
Training loss: 2.8631796836853027
Validation loss: 2.3339957857644684

Epoch: 6| Step: 11
Training loss: 2.0025651454925537
Validation loss: 2.3356342238764607

Epoch: 6| Step: 12
Training loss: 2.67734432220459
Validation loss: 2.338959114525908

Epoch: 6| Step: 13
Training loss: 2.782698392868042
Validation loss: 2.3373607589352514

Epoch: 91| Step: 0
Training loss: 1.9347529411315918
Validation loss: 2.337607814419654

Epoch: 6| Step: 1
Training loss: 3.1772475242614746
Validation loss: 2.3410740860046877

Epoch: 6| Step: 2
Training loss: 3.2987680435180664
Validation loss: 2.343438479208177

Epoch: 6| Step: 3
Training loss: 2.9342637062072754
Validation loss: 2.354180292416644

Epoch: 6| Step: 4
Training loss: 3.2364768981933594
Validation loss: 2.357673163055092

Epoch: 6| Step: 5
Training loss: 1.6451339721679688
Validation loss: 2.3484281916772165

Epoch: 6| Step: 6
Training loss: 2.3111379146575928
Validation loss: 2.3400109019330753

Epoch: 6| Step: 7
Training loss: 2.41042423248291
Validation loss: 2.3393301938169744

Epoch: 6| Step: 8
Training loss: 2.100921392440796
Validation loss: 2.3280711712375766

Epoch: 6| Step: 9
Training loss: 2.765047788619995
Validation loss: 2.3248503028705554

Epoch: 6| Step: 10
Training loss: 2.8798575401306152
Validation loss: 2.323474181595669

Epoch: 6| Step: 11
Training loss: 2.7518818378448486
Validation loss: 2.3247792233702955

Epoch: 6| Step: 12
Training loss: 2.381049156188965
Validation loss: 2.3245144967109925

Epoch: 6| Step: 13
Training loss: 2.5335676670074463
Validation loss: 2.3211483493927987

Epoch: 92| Step: 0
Training loss: 2.431464672088623
Validation loss: 2.3290694939192904

Epoch: 6| Step: 1
Training loss: 2.6998090744018555
Validation loss: 2.3282286697818386

Epoch: 6| Step: 2
Training loss: 2.5976691246032715
Validation loss: 2.328072727367442

Epoch: 6| Step: 3
Training loss: 2.9134442806243896
Validation loss: 2.323663224456131

Epoch: 6| Step: 4
Training loss: 2.6057772636413574
Validation loss: 2.324709802545527

Epoch: 6| Step: 5
Training loss: 2.703522205352783
Validation loss: 2.3256215562102613

Epoch: 6| Step: 6
Training loss: 1.6638373136520386
Validation loss: 2.3226603923305387

Epoch: 6| Step: 7
Training loss: 3.0707929134368896
Validation loss: 2.327708331487512

Epoch: 6| Step: 8
Training loss: 2.4438602924346924
Validation loss: 2.3238431048649613

Epoch: 6| Step: 9
Training loss: 2.8457112312316895
Validation loss: 2.3292710678551787

Epoch: 6| Step: 10
Training loss: 2.6121444702148438
Validation loss: 2.325982957757929

Epoch: 6| Step: 11
Training loss: 2.873443365097046
Validation loss: 2.3339650541223507

Epoch: 6| Step: 12
Training loss: 2.5618433952331543
Validation loss: 2.340837791401853

Epoch: 6| Step: 13
Training loss: 2.2077136039733887
Validation loss: 2.348350532593266

Epoch: 93| Step: 0
Training loss: 2.9215168952941895
Validation loss: 2.369275480188349

Epoch: 6| Step: 1
Training loss: 3.3877649307250977
Validation loss: 2.380337090902431

Epoch: 6| Step: 2
Training loss: 2.2305383682250977
Validation loss: 2.4022533932039813

Epoch: 6| Step: 3
Training loss: 2.6441445350646973
Validation loss: 2.4150528933412287

Epoch: 6| Step: 4
Training loss: 2.766465187072754
Validation loss: 2.3976964950561523

Epoch: 6| Step: 5
Training loss: 3.1495203971862793
Validation loss: 2.3788585252659296

Epoch: 6| Step: 6
Training loss: 2.301039218902588
Validation loss: 2.3686481547612015

Epoch: 6| Step: 7
Training loss: 2.6982531547546387
Validation loss: 2.3660140986083658

Epoch: 6| Step: 8
Training loss: 2.051158905029297
Validation loss: 2.356233476310648

Epoch: 6| Step: 9
Training loss: 2.4825973510742188
Validation loss: 2.3448772481692735

Epoch: 6| Step: 10
Training loss: 2.8581762313842773
Validation loss: 2.3406372377949376

Epoch: 6| Step: 11
Training loss: 1.799999475479126
Validation loss: 2.3350269345827

Epoch: 6| Step: 12
Training loss: 2.7244768142700195
Validation loss: 2.3339877769511235

Epoch: 6| Step: 13
Training loss: 2.0556631088256836
Validation loss: 2.3337261369151454

Epoch: 94| Step: 0
Training loss: 2.54354190826416
Validation loss: 2.325083117331228

Epoch: 6| Step: 1
Training loss: 2.8695874214172363
Validation loss: 2.3233929423875708

Epoch: 6| Step: 2
Training loss: 2.6823320388793945
Validation loss: 2.3221991574892433

Epoch: 6| Step: 3
Training loss: 2.356937885284424
Validation loss: 2.321880971231768

Epoch: 6| Step: 4
Training loss: 2.691798686981201
Validation loss: 2.3220769923220397

Epoch: 6| Step: 5
Training loss: 2.8623552322387695
Validation loss: 2.322407573781988

Epoch: 6| Step: 6
Training loss: 2.339423894882202
Validation loss: 2.322239980902723

Epoch: 6| Step: 7
Training loss: 3.2533326148986816
Validation loss: 2.3193299501172957

Epoch: 6| Step: 8
Training loss: 2.623164415359497
Validation loss: 2.3205503981600524

Epoch: 6| Step: 9
Training loss: 2.1884400844573975
Validation loss: 2.316755966473651

Epoch: 6| Step: 10
Training loss: 1.9094204902648926
Validation loss: 2.3207040909797914

Epoch: 6| Step: 11
Training loss: 3.2408595085144043
Validation loss: 2.320553848820348

Epoch: 6| Step: 12
Training loss: 2.2037739753723145
Validation loss: 2.326620481347525

Epoch: 6| Step: 13
Training loss: 2.626051425933838
Validation loss: 2.3346235316286803

Epoch: 95| Step: 0
Training loss: 2.7923736572265625
Validation loss: 2.339425251048098

Epoch: 6| Step: 1
Training loss: 1.9642555713653564
Validation loss: 2.343093110669044

Epoch: 6| Step: 2
Training loss: 2.0699334144592285
Validation loss: 2.3538428609089186

Epoch: 6| Step: 3
Training loss: 3.026315689086914
Validation loss: 2.350009749012609

Epoch: 6| Step: 4
Training loss: 2.9987637996673584
Validation loss: 2.343982640133109

Epoch: 6| Step: 5
Training loss: 2.7897748947143555
Validation loss: 2.3464949951376965

Epoch: 6| Step: 6
Training loss: 2.510805606842041
Validation loss: 2.3351416421192948

Epoch: 6| Step: 7
Training loss: 2.6079354286193848
Validation loss: 2.3357545022041566

Epoch: 6| Step: 8
Training loss: 2.596281051635742
Validation loss: 2.337946104746993

Epoch: 6| Step: 9
Training loss: 2.6059648990631104
Validation loss: 2.3400252185842043

Epoch: 6| Step: 10
Training loss: 2.5974249839782715
Validation loss: 2.3372606744048414

Epoch: 6| Step: 11
Training loss: 2.5284085273742676
Validation loss: 2.3434113763993785

Epoch: 6| Step: 12
Training loss: 2.667020797729492
Validation loss: 2.3415238575268815

Epoch: 6| Step: 13
Training loss: 2.283604860305786
Validation loss: 2.3427720480067755

Epoch: 96| Step: 0
Training loss: 2.7027554512023926
Validation loss: 2.36700120792594

Epoch: 6| Step: 1
Training loss: 3.295210361480713
Validation loss: 2.3861907477019937

Epoch: 6| Step: 2
Training loss: 1.8742152452468872
Validation loss: 2.405154840920561

Epoch: 6| Step: 3
Training loss: 2.164816379547119
Validation loss: 2.4293845443315405

Epoch: 6| Step: 4
Training loss: 3.2258455753326416
Validation loss: 2.446292399078287

Epoch: 6| Step: 5
Training loss: 2.458956241607666
Validation loss: 2.43250011885038

Epoch: 6| Step: 6
Training loss: 2.7554640769958496
Validation loss: 2.3957946633779876

Epoch: 6| Step: 7
Training loss: 2.408848762512207
Validation loss: 2.365560548279875

Epoch: 6| Step: 8
Training loss: 2.058008909225464
Validation loss: 2.337737262889903

Epoch: 6| Step: 9
Training loss: 2.850825071334839
Validation loss: 2.310698801471341

Epoch: 6| Step: 10
Training loss: 2.1840596199035645
Validation loss: 2.3055886889016755

Epoch: 6| Step: 11
Training loss: 2.4897842407226562
Validation loss: 2.309524702769454

Epoch: 6| Step: 12
Training loss: 3.468682289123535
Validation loss: 2.314254706905734

Epoch: 6| Step: 13
Training loss: 2.8267838954925537
Validation loss: 2.3173637492682344

Epoch: 97| Step: 0
Training loss: 2.9599533081054688
Validation loss: 2.340289992670859

Epoch: 6| Step: 1
Training loss: 3.0662026405334473
Validation loss: 2.3460240799893617

Epoch: 6| Step: 2
Training loss: 2.8909811973571777
Validation loss: 2.353094313734321

Epoch: 6| Step: 3
Training loss: 2.7677688598632812
Validation loss: 2.34391938999135

Epoch: 6| Step: 4
Training loss: 2.3923816680908203
Validation loss: 2.3201340885572534

Epoch: 6| Step: 5
Training loss: 1.90351402759552
Validation loss: 2.312400705070906

Epoch: 6| Step: 6
Training loss: 2.8255608081817627
Validation loss: 2.306376249559464

Epoch: 6| Step: 7
Training loss: 2.482712984085083
Validation loss: 2.303617297962148

Epoch: 6| Step: 8
Training loss: 2.5069527626037598
Validation loss: 2.3027133634013515

Epoch: 6| Step: 9
Training loss: 2.2650082111358643
Validation loss: 2.30392627562246

Epoch: 6| Step: 10
Training loss: 3.0780625343322754
Validation loss: 2.3155800937324442

Epoch: 6| Step: 11
Training loss: 1.528613567352295
Validation loss: 2.32809559119645

Epoch: 6| Step: 12
Training loss: 2.933171033859253
Validation loss: 2.3412538523315103

Epoch: 6| Step: 13
Training loss: 3.14947772026062
Validation loss: 2.359144961962136

Epoch: 98| Step: 0
Training loss: 2.72627592086792
Validation loss: 2.3579271506237727

Epoch: 6| Step: 1
Training loss: 2.329021692276001
Validation loss: 2.333486669807024

Epoch: 6| Step: 2
Training loss: 2.9670515060424805
Validation loss: 2.3149594594073553

Epoch: 6| Step: 3
Training loss: 2.927375555038452
Validation loss: 2.3157334814789476

Epoch: 6| Step: 4
Training loss: 1.8445732593536377
Validation loss: 2.3196131106345885

Epoch: 6| Step: 5
Training loss: 3.4058947563171387
Validation loss: 2.3282758061603834

Epoch: 6| Step: 6
Training loss: 2.0765347480773926
Validation loss: 2.3367384326073433

Epoch: 6| Step: 7
Training loss: 2.3681442737579346
Validation loss: 2.357891728801112

Epoch: 6| Step: 8
Training loss: 2.28116512298584
Validation loss: 2.3931342453084965

Epoch: 6| Step: 9
Training loss: 2.6328048706054688
Validation loss: 2.405916629299041

Epoch: 6| Step: 10
Training loss: 1.9022396802902222
Validation loss: 2.3952071179625807

Epoch: 6| Step: 11
Training loss: 2.8247172832489014
Validation loss: 2.4172342079941944

Epoch: 6| Step: 12
Training loss: 3.1701643466949463
Validation loss: 2.413985401071528

Epoch: 6| Step: 13
Training loss: 2.9531869888305664
Validation loss: 2.444496085566859

Epoch: 99| Step: 0
Training loss: 2.6811530590057373
Validation loss: 2.4299791320677726

Epoch: 6| Step: 1
Training loss: 2.0945401191711426
Validation loss: 2.447158295621154

Epoch: 6| Step: 2
Training loss: 2.631011962890625
Validation loss: 2.4034906356565413

Epoch: 6| Step: 3
Training loss: 2.2731871604919434
Validation loss: 2.4108431313627507

Epoch: 6| Step: 4
Training loss: 1.9021320343017578
Validation loss: 2.378260986779326

Epoch: 6| Step: 5
Training loss: 2.575363874435425
Validation loss: 2.3411711108299995

Epoch: 6| Step: 6
Training loss: 2.820651054382324
Validation loss: 2.331570666323426

Epoch: 6| Step: 7
Training loss: 1.9910573959350586
Validation loss: 2.3218000576060307

Epoch: 6| Step: 8
Training loss: 2.867722511291504
Validation loss: 2.3222193128319195

Epoch: 6| Step: 9
Training loss: 3.6880507469177246
Validation loss: 2.308828241081648

Epoch: 6| Step: 10
Training loss: 3.077209949493408
Validation loss: 2.30372445044979

Epoch: 6| Step: 11
Training loss: 1.996595859527588
Validation loss: 2.31491659789957

Epoch: 6| Step: 12
Training loss: 2.0297725200653076
Validation loss: 2.3165765013746036

Epoch: 6| Step: 13
Training loss: 3.9625794887542725
Validation loss: 2.309666577205863

Epoch: 100| Step: 0
Training loss: 2.394021511077881
Validation loss: 2.296160492845761

Epoch: 6| Step: 1
Training loss: 2.918227195739746
Validation loss: 2.293632984161377

Epoch: 6| Step: 2
Training loss: 2.3902764320373535
Validation loss: 2.296694117207681

Epoch: 6| Step: 3
Training loss: 2.775038480758667
Validation loss: 2.297161581695721

Epoch: 6| Step: 4
Training loss: 2.742826461791992
Validation loss: 2.2966909203478085

Epoch: 6| Step: 5
Training loss: 2.446770668029785
Validation loss: 2.296083632335868

Epoch: 6| Step: 6
Training loss: 3.0110344886779785
Validation loss: 2.3072798687924623

Epoch: 6| Step: 7
Training loss: 2.25532865524292
Validation loss: 2.2994214796250865

Epoch: 6| Step: 8
Training loss: 2.6752142906188965
Validation loss: 2.302557050540883

Epoch: 6| Step: 9
Training loss: 2.3374788761138916
Validation loss: 2.2981781421169156

Epoch: 6| Step: 10
Training loss: 2.1402413845062256
Validation loss: 2.295401857745263

Epoch: 6| Step: 11
Training loss: 2.3035640716552734
Validation loss: 2.290399597537133

Epoch: 6| Step: 12
Training loss: 2.7573437690734863
Validation loss: 2.290191658081547

Epoch: 6| Step: 13
Training loss: 3.1436269283294678
Validation loss: 2.290989137464954

Epoch: 101| Step: 0
Training loss: 2.5678293704986572
Validation loss: 2.2871162840115127

Epoch: 6| Step: 1
Training loss: 1.935703158378601
Validation loss: 2.2873984754726453

Epoch: 6| Step: 2
Training loss: 2.447399616241455
Validation loss: 2.286121481208391

Epoch: 6| Step: 3
Training loss: 2.138564109802246
Validation loss: 2.2862693878912155

Epoch: 6| Step: 4
Training loss: 2.2507505416870117
Validation loss: 2.2907911885169243

Epoch: 6| Step: 5
Training loss: 2.640178918838501
Validation loss: 2.2891003495903424

Epoch: 6| Step: 6
Training loss: 2.46148419380188
Validation loss: 2.2918933873535483

Epoch: 6| Step: 7
Training loss: 3.237316131591797
Validation loss: 2.28451790348176

Epoch: 6| Step: 8
Training loss: 2.726713180541992
Validation loss: 2.285691617637552

Epoch: 6| Step: 9
Training loss: 2.0483651161193848
Validation loss: 2.2892041847270024

Epoch: 6| Step: 10
Training loss: 2.4787755012512207
Validation loss: 2.293192699391355

Epoch: 6| Step: 11
Training loss: 3.4788873195648193
Validation loss: 2.312532276235601

Epoch: 6| Step: 12
Training loss: 3.1035594940185547
Validation loss: 2.3447052817190848

Epoch: 6| Step: 13
Training loss: 2.6637372970581055
Validation loss: 2.4055121534614154

Epoch: 102| Step: 0
Training loss: 3.1267361640930176
Validation loss: 2.4436466924605833

Epoch: 6| Step: 1
Training loss: 2.434401750564575
Validation loss: 2.4235804721873295

Epoch: 6| Step: 2
Training loss: 2.4707417488098145
Validation loss: 2.4191342989603677

Epoch: 6| Step: 3
Training loss: 2.078192710876465
Validation loss: 2.3687307321897118

Epoch: 6| Step: 4
Training loss: 2.4686384201049805
Validation loss: 2.3401512907397364

Epoch: 6| Step: 5
Training loss: 2.7458291053771973
Validation loss: 2.3172565173077326

Epoch: 6| Step: 6
Training loss: 1.6576931476593018
Validation loss: 2.2995829966760453

Epoch: 6| Step: 7
Training loss: 2.870769500732422
Validation loss: 2.296026319585821

Epoch: 6| Step: 8
Training loss: 2.726461887359619
Validation loss: 2.290135734824724

Epoch: 6| Step: 9
Training loss: 2.847846031188965
Validation loss: 2.3004906754339896

Epoch: 6| Step: 10
Training loss: 2.4438350200653076
Validation loss: 2.2970302181859172

Epoch: 6| Step: 11
Training loss: 3.235145092010498
Validation loss: 2.2970260843153922

Epoch: 6| Step: 12
Training loss: 2.7027454376220703
Validation loss: 2.300825244636946

Epoch: 6| Step: 13
Training loss: 2.0541141033172607
Validation loss: 2.298749828851351

Epoch: 103| Step: 0
Training loss: 2.705707550048828
Validation loss: 2.3140227358828307

Epoch: 6| Step: 1
Training loss: 3.0886590480804443
Validation loss: 2.3393195239446496

Epoch: 6| Step: 2
Training loss: 2.7757718563079834
Validation loss: 2.4122657416969218

Epoch: 6| Step: 3
Training loss: 3.044778347015381
Validation loss: 2.4444979749700075

Epoch: 6| Step: 4
Training loss: 2.435723304748535
Validation loss: 2.435123546149141

Epoch: 6| Step: 5
Training loss: 2.499469041824341
Validation loss: 2.3533765013499925

Epoch: 6| Step: 6
Training loss: 2.9551329612731934
Validation loss: 2.3799301783243814

Epoch: 6| Step: 7
Training loss: 2.910156011581421
Validation loss: 2.338893545571194

Epoch: 6| Step: 8
Training loss: 1.5902111530303955
Validation loss: 2.3149269575713785

Epoch: 6| Step: 9
Training loss: 2.2539126873016357
Validation loss: 2.30342859350225

Epoch: 6| Step: 10
Training loss: 2.548269271850586
Validation loss: 2.2874058831122612

Epoch: 6| Step: 11
Training loss: 2.553529739379883
Validation loss: 2.289259949038106

Epoch: 6| Step: 12
Training loss: 2.4331674575805664
Validation loss: 2.2919396354306127

Epoch: 6| Step: 13
Training loss: 2.0360727310180664
Validation loss: 2.293264167283171

Epoch: 104| Step: 0
Training loss: 2.8120718002319336
Validation loss: 2.2852720470838648

Epoch: 6| Step: 1
Training loss: 3.0746231079101562
Validation loss: 2.282878562968264

Epoch: 6| Step: 2
Training loss: 2.499859571456909
Validation loss: 2.285390782099898

Epoch: 6| Step: 3
Training loss: 2.7999985218048096
Validation loss: 2.292705338488343

Epoch: 6| Step: 4
Training loss: 1.9288275241851807
Validation loss: 2.2941270105300413

Epoch: 6| Step: 5
Training loss: 2.506333112716675
Validation loss: 2.2871613169229157

Epoch: 6| Step: 6
Training loss: 2.144021987915039
Validation loss: 2.2981124988166233

Epoch: 6| Step: 7
Training loss: 2.731989860534668
Validation loss: 2.3165393260217484

Epoch: 6| Step: 8
Training loss: 2.791795253753662
Validation loss: 2.3172006094327537

Epoch: 6| Step: 9
Training loss: 1.9606932401657104
Validation loss: 2.326772880810563

Epoch: 6| Step: 10
Training loss: 3.2480156421661377
Validation loss: 2.3275100672116844

Epoch: 6| Step: 11
Training loss: 2.5878500938415527
Validation loss: 2.3161131258933776

Epoch: 6| Step: 12
Training loss: 2.594433069229126
Validation loss: 2.333888269239856

Epoch: 6| Step: 13
Training loss: 2.187849760055542
Validation loss: 2.330335324810397

Epoch: 105| Step: 0
Training loss: 2.8351919651031494
Validation loss: 2.333421145716021

Epoch: 6| Step: 1
Training loss: 2.6264870166778564
Validation loss: 2.3384637678823164

Epoch: 6| Step: 2
Training loss: 1.947536826133728
Validation loss: 2.3417222140937723

Epoch: 6| Step: 3
Training loss: 2.2835469245910645
Validation loss: 2.3512429204038394

Epoch: 6| Step: 4
Training loss: 3.0283467769622803
Validation loss: 2.311383795994584

Epoch: 6| Step: 5
Training loss: 2.76017427444458
Validation loss: 2.292221596164088

Epoch: 6| Step: 6
Training loss: 2.710453987121582
Validation loss: 2.286406114537229

Epoch: 6| Step: 7
Training loss: 1.9515457153320312
Validation loss: 2.2861991133741153

Epoch: 6| Step: 8
Training loss: 2.407785415649414
Validation loss: 2.2907683413515807

Epoch: 6| Step: 9
Training loss: 2.8224663734436035
Validation loss: 2.285320531937384

Epoch: 6| Step: 10
Training loss: 2.3452630043029785
Validation loss: 2.2859492532668577

Epoch: 6| Step: 11
Training loss: 2.94448184967041
Validation loss: 2.291495197562761

Epoch: 6| Step: 12
Training loss: 2.621488094329834
Validation loss: 2.2909856483500493

Epoch: 6| Step: 13
Training loss: 3.0534892082214355
Validation loss: 2.2948164632243495

Epoch: 106| Step: 0
Training loss: 2.6414554119110107
Validation loss: 2.296961284452869

Epoch: 6| Step: 1
Training loss: 3.0764894485473633
Validation loss: 2.299336257801261

Epoch: 6| Step: 2
Training loss: 3.0058584213256836
Validation loss: 2.2956798614994174

Epoch: 6| Step: 3
Training loss: 2.7694308757781982
Validation loss: 2.291846795748639

Epoch: 6| Step: 4
Training loss: 2.4581868648529053
Validation loss: 2.294439333741383

Epoch: 6| Step: 5
Training loss: 2.4351019859313965
Validation loss: 2.2884448574435328

Epoch: 6| Step: 6
Training loss: 2.2458226680755615
Validation loss: 2.293727021063528

Epoch: 6| Step: 7
Training loss: 2.491689920425415
Validation loss: 2.2929652378123295

Epoch: 6| Step: 8
Training loss: 2.229710102081299
Validation loss: 2.2917596576034382

Epoch: 6| Step: 9
Training loss: 2.930205821990967
Validation loss: 2.2954459677460375

Epoch: 6| Step: 10
Training loss: 2.727200508117676
Validation loss: 2.300424865497056

Epoch: 6| Step: 11
Training loss: 2.0553154945373535
Validation loss: 2.3031193658869755

Epoch: 6| Step: 12
Training loss: 2.205595016479492
Validation loss: 2.3042553778617614

Epoch: 6| Step: 13
Training loss: 2.764803886413574
Validation loss: 2.310430690806399

Epoch: 107| Step: 0
Training loss: 2.499560594558716
Validation loss: 2.304487000229538

Epoch: 6| Step: 1
Training loss: 2.7883901596069336
Validation loss: 2.3112452260909544

Epoch: 6| Step: 2
Training loss: 2.4061670303344727
Validation loss: 2.3229681163705806

Epoch: 6| Step: 3
Training loss: 3.468513250350952
Validation loss: 2.328724609908237

Epoch: 6| Step: 4
Training loss: 2.485708236694336
Validation loss: 2.3354825947874334

Epoch: 6| Step: 5
Training loss: 2.4462947845458984
Validation loss: 2.330908485638198

Epoch: 6| Step: 6
Training loss: 2.57212233543396
Validation loss: 2.3221709907695813

Epoch: 6| Step: 7
Training loss: 2.272073745727539
Validation loss: 2.314387203544699

Epoch: 6| Step: 8
Training loss: 2.6712794303894043
Validation loss: 2.3033551554526053

Epoch: 6| Step: 9
Training loss: 1.6234138011932373
Validation loss: 2.289496447450371

Epoch: 6| Step: 10
Training loss: 2.788024425506592
Validation loss: 2.2823510426346973

Epoch: 6| Step: 11
Training loss: 2.835236072540283
Validation loss: 2.279678157580796

Epoch: 6| Step: 12
Training loss: 2.387162923812866
Validation loss: 2.2757530673857658

Epoch: 6| Step: 13
Training loss: 2.4481353759765625
Validation loss: 2.270615385424706

Epoch: 108| Step: 0
Training loss: 2.2776997089385986
Validation loss: 2.2724683412941555

Epoch: 6| Step: 1
Training loss: 3.454989433288574
Validation loss: 2.275176291824669

Epoch: 6| Step: 2
Training loss: 3.0511229038238525
Validation loss: 2.2818553806633077

Epoch: 6| Step: 3
Training loss: 2.391549587249756
Validation loss: 2.2787446770616757

Epoch: 6| Step: 4
Training loss: 1.9578659534454346
Validation loss: 2.277570119468115

Epoch: 6| Step: 5
Training loss: 1.8611106872558594
Validation loss: 2.28361580961494

Epoch: 6| Step: 6
Training loss: 2.115752696990967
Validation loss: 2.287233588516071

Epoch: 6| Step: 7
Training loss: 2.4910101890563965
Validation loss: 2.287276775606217

Epoch: 6| Step: 8
Training loss: 3.371847629547119
Validation loss: 2.2972124058713197

Epoch: 6| Step: 9
Training loss: 2.259568214416504
Validation loss: 2.3182450750822663

Epoch: 6| Step: 10
Training loss: 3.49159574508667
Validation loss: 2.342853182105608

Epoch: 6| Step: 11
Training loss: 2.357191324234009
Validation loss: 2.356774858249131

Epoch: 6| Step: 12
Training loss: 1.9266960620880127
Validation loss: 2.3771718009825675

Epoch: 6| Step: 13
Training loss: 3.1114182472229004
Validation loss: 2.378351752476026

Epoch: 109| Step: 0
Training loss: 3.520297050476074
Validation loss: 2.3968292154291624

Epoch: 6| Step: 1
Training loss: 2.836787700653076
Validation loss: 2.388443826347269

Epoch: 6| Step: 2
Training loss: 2.4297633171081543
Validation loss: 2.364481344017931

Epoch: 6| Step: 3
Training loss: 2.7875266075134277
Validation loss: 2.3444921585821334

Epoch: 6| Step: 4
Training loss: 3.00879168510437
Validation loss: 2.3093413178638746

Epoch: 6| Step: 5
Training loss: 2.30963397026062
Validation loss: 2.2863459484551543

Epoch: 6| Step: 6
Training loss: 2.665269374847412
Validation loss: 2.2683975106926373

Epoch: 6| Step: 7
Training loss: 2.0016772747039795
Validation loss: 2.262705187643728

Epoch: 6| Step: 8
Training loss: 1.9718677997589111
Validation loss: 2.266966773617652

Epoch: 6| Step: 9
Training loss: 2.7307732105255127
Validation loss: 2.2733590833602415

Epoch: 6| Step: 10
Training loss: 2.2845778465270996
Validation loss: 2.275525995480117

Epoch: 6| Step: 11
Training loss: 2.675119400024414
Validation loss: 2.279036586002637

Epoch: 6| Step: 12
Training loss: 2.310014247894287
Validation loss: 2.2718724973740114

Epoch: 6| Step: 13
Training loss: 2.4330031871795654
Validation loss: 2.2638305233370875

Epoch: 110| Step: 0
Training loss: 2.100545883178711
Validation loss: 2.264145621689417

Epoch: 6| Step: 1
Training loss: 2.364729404449463
Validation loss: 2.26069414231085

Epoch: 6| Step: 2
Training loss: 2.9054927825927734
Validation loss: 2.2680649347202753

Epoch: 6| Step: 3
Training loss: 2.0646204948425293
Validation loss: 2.27239139105684

Epoch: 6| Step: 4
Training loss: 2.9007530212402344
Validation loss: 2.281142753939475

Epoch: 6| Step: 5
Training loss: 1.8839263916015625
Validation loss: 2.2946820207821426

Epoch: 6| Step: 6
Training loss: 2.5677428245544434
Validation loss: 2.311549468707013

Epoch: 6| Step: 7
Training loss: 2.8161427974700928
Validation loss: 2.319862440068235

Epoch: 6| Step: 8
Training loss: 3.361870288848877
Validation loss: 2.326760274107738

Epoch: 6| Step: 9
Training loss: 2.58682918548584
Validation loss: 2.3122096766707716

Epoch: 6| Step: 10
Training loss: 2.9370243549346924
Validation loss: 2.3075092582292456

Epoch: 6| Step: 11
Training loss: 2.2662811279296875
Validation loss: 2.3144619849420365

Epoch: 6| Step: 12
Training loss: 2.8016295433044434
Validation loss: 2.3025277558193413

Epoch: 6| Step: 13
Training loss: 1.8386770486831665
Validation loss: 2.3000128653741654

Epoch: 111| Step: 0
Training loss: 2.5476856231689453
Validation loss: 2.2889952941607405

Epoch: 6| Step: 1
Training loss: 2.459479570388794
Validation loss: 2.2989486520008375

Epoch: 6| Step: 2
Training loss: 2.6268084049224854
Validation loss: 2.2880877064120386

Epoch: 6| Step: 3
Training loss: 2.827381134033203
Validation loss: 2.2699940896803334

Epoch: 6| Step: 4
Training loss: 2.426734685897827
Validation loss: 2.2740321825909358

Epoch: 6| Step: 5
Training loss: 3.2115774154663086
Validation loss: 2.2737807484083277

Epoch: 6| Step: 6
Training loss: 2.621755599975586
Validation loss: 2.2631981385651456

Epoch: 6| Step: 7
Training loss: 2.1775519847869873
Validation loss: 2.262972849671559

Epoch: 6| Step: 8
Training loss: 2.4705660343170166
Validation loss: 2.264472048769715

Epoch: 6| Step: 9
Training loss: 2.9801440238952637
Validation loss: 2.262110847298817

Epoch: 6| Step: 10
Training loss: 2.606442928314209
Validation loss: 2.2613840513331915

Epoch: 6| Step: 11
Training loss: 2.2635905742645264
Validation loss: 2.259678153581517

Epoch: 6| Step: 12
Training loss: 2.456087589263916
Validation loss: 2.2600962859328075

Epoch: 6| Step: 13
Training loss: 1.6497975587844849
Validation loss: 2.262503844435497

Epoch: 112| Step: 0
Training loss: 2.012557029724121
Validation loss: 2.2642492863439743

Epoch: 6| Step: 1
Training loss: 2.636716842651367
Validation loss: 2.2694752344521145

Epoch: 6| Step: 2
Training loss: 2.9090421199798584
Validation loss: 2.275676042802872

Epoch: 6| Step: 3
Training loss: 2.409538745880127
Validation loss: 2.2725299814695954

Epoch: 6| Step: 4
Training loss: 2.2371177673339844
Validation loss: 2.2803540639979865

Epoch: 6| Step: 5
Training loss: 2.5777859687805176
Validation loss: 2.2750040241467056

Epoch: 6| Step: 6
Training loss: 3.0468661785125732
Validation loss: 2.2770168883826143

Epoch: 6| Step: 7
Training loss: 2.7478652000427246
Validation loss: 2.27772706554782

Epoch: 6| Step: 8
Training loss: 2.7874598503112793
Validation loss: 2.2737936076297554

Epoch: 6| Step: 9
Training loss: 2.0623693466186523
Validation loss: 2.275772853564191

Epoch: 6| Step: 10
Training loss: 2.9581727981567383
Validation loss: 2.274888453945037

Epoch: 6| Step: 11
Training loss: 2.010718822479248
Validation loss: 2.2782898487583285

Epoch: 6| Step: 12
Training loss: 2.5249345302581787
Validation loss: 2.2837565714313137

Epoch: 6| Step: 13
Training loss: 2.7180700302124023
Validation loss: 2.3005239681531022

Epoch: 113| Step: 0
Training loss: 2.9659457206726074
Validation loss: 2.3055648547346874

Epoch: 6| Step: 1
Training loss: 2.5256459712982178
Validation loss: 2.2959485579562444

Epoch: 6| Step: 2
Training loss: 3.024811267852783
Validation loss: 2.2901064888123543

Epoch: 6| Step: 3
Training loss: 1.6711950302124023
Validation loss: 2.289702546211981

Epoch: 6| Step: 4
Training loss: 2.4958763122558594
Validation loss: 2.2850322825934297

Epoch: 6| Step: 5
Training loss: 2.4314708709716797
Validation loss: 2.3108774590235885

Epoch: 6| Step: 6
Training loss: 2.9133191108703613
Validation loss: 2.2971244909430064

Epoch: 6| Step: 7
Training loss: 2.80768084526062
Validation loss: 2.2993394097974225

Epoch: 6| Step: 8
Training loss: 2.3768129348754883
Validation loss: 2.308758322910596

Epoch: 6| Step: 9
Training loss: 2.412569999694824
Validation loss: 2.3138205389822684

Epoch: 6| Step: 10
Training loss: 2.4170970916748047
Validation loss: 2.3177531073170323

Epoch: 6| Step: 11
Training loss: 1.980236291885376
Validation loss: 2.303734953685473

Epoch: 6| Step: 12
Training loss: 2.440331220626831
Validation loss: 2.2865806574462564

Epoch: 6| Step: 13
Training loss: 3.618448495864868
Validation loss: 2.2737701682634253

Epoch: 114| Step: 0
Training loss: 2.536397695541382
Validation loss: 2.262040558681693

Epoch: 6| Step: 1
Training loss: 2.8617067337036133
Validation loss: 2.252807919697095

Epoch: 6| Step: 2
Training loss: 2.941819906234741
Validation loss: 2.2597057460456766

Epoch: 6| Step: 3
Training loss: 2.371877431869507
Validation loss: 2.2581928365974018

Epoch: 6| Step: 4
Training loss: 2.6654319763183594
Validation loss: 2.269297594665199

Epoch: 6| Step: 5
Training loss: 2.737138271331787
Validation loss: 2.2723039145110757

Epoch: 6| Step: 6
Training loss: 2.2005491256713867
Validation loss: 2.277015927017376

Epoch: 6| Step: 7
Training loss: 3.611284017562866
Validation loss: 2.2762989382590018

Epoch: 6| Step: 8
Training loss: 2.3384835720062256
Validation loss: 2.2762014686420398

Epoch: 6| Step: 9
Training loss: 2.0896310806274414
Validation loss: 2.2671030208628666

Epoch: 6| Step: 10
Training loss: 2.399374008178711
Validation loss: 2.262835210369479

Epoch: 6| Step: 11
Training loss: 1.9710664749145508
Validation loss: 2.2563113691986247

Epoch: 6| Step: 12
Training loss: 2.830514430999756
Validation loss: 2.251219146995134

Epoch: 6| Step: 13
Training loss: 2.4744555950164795
Validation loss: 2.2502111311881774

Epoch: 115| Step: 0
Training loss: 2.3492305278778076
Validation loss: 2.251753291776103

Epoch: 6| Step: 1
Training loss: 2.6743557453155518
Validation loss: 2.25681366971744

Epoch: 6| Step: 2
Training loss: 3.0486717224121094
Validation loss: 2.266103045914763

Epoch: 6| Step: 3
Training loss: 3.1773858070373535
Validation loss: 2.269157673722954

Epoch: 6| Step: 4
Training loss: 2.959947347640991
Validation loss: 2.2818385580534577

Epoch: 6| Step: 5
Training loss: 1.9078402519226074
Validation loss: 2.293510680557579

Epoch: 6| Step: 6
Training loss: 2.2512805461883545
Validation loss: 2.2967492354813444

Epoch: 6| Step: 7
Training loss: 2.5673046112060547
Validation loss: 2.3000000138436594

Epoch: 6| Step: 8
Training loss: 2.717698335647583
Validation loss: 2.3019353112866803

Epoch: 6| Step: 9
Training loss: 3.0781922340393066
Validation loss: 2.2968214250379995

Epoch: 6| Step: 10
Training loss: 2.1731979846954346
Validation loss: 2.2863114418522006

Epoch: 6| Step: 11
Training loss: 2.117034912109375
Validation loss: 2.2691361570871003

Epoch: 6| Step: 12
Training loss: 2.321774482727051
Validation loss: 2.265497535787603

Epoch: 6| Step: 13
Training loss: 1.9387274980545044
Validation loss: 2.2646256364801878

Epoch: 116| Step: 0
Training loss: 2.1528303623199463
Validation loss: 2.2618442196999826

Epoch: 6| Step: 1
Training loss: 2.808448076248169
Validation loss: 2.2684925986874487

Epoch: 6| Step: 2
Training loss: 2.337662696838379
Validation loss: 2.272305750077771

Epoch: 6| Step: 3
Training loss: 3.0745584964752197
Validation loss: 2.275770661651447

Epoch: 6| Step: 4
Training loss: 2.641317844390869
Validation loss: 2.269293719722379

Epoch: 6| Step: 5
Training loss: 1.9496904611587524
Validation loss: 2.282521827246553

Epoch: 6| Step: 6
Training loss: 2.9443507194519043
Validation loss: 2.275428120807935

Epoch: 6| Step: 7
Training loss: 2.4418375492095947
Validation loss: 2.2808410826549737

Epoch: 6| Step: 8
Training loss: 2.7180750370025635
Validation loss: 2.28503054957236

Epoch: 6| Step: 9
Training loss: 3.2078866958618164
Validation loss: 2.287115499537478

Epoch: 6| Step: 10
Training loss: 2.2239673137664795
Validation loss: 2.2888431395253828

Epoch: 6| Step: 11
Training loss: 2.325409173965454
Validation loss: 2.2758466659053678

Epoch: 6| Step: 12
Training loss: 2.129955768585205
Validation loss: 2.2692884988682245

Epoch: 6| Step: 13
Training loss: 2.410000801086426
Validation loss: 2.2718884816733738

Epoch: 117| Step: 0
Training loss: 2.418375015258789
Validation loss: 2.2920645590751403

Epoch: 6| Step: 1
Training loss: 2.3542532920837402
Validation loss: 2.2840174962115545

Epoch: 6| Step: 2
Training loss: 1.9906389713287354
Validation loss: 2.3006075915469917

Epoch: 6| Step: 3
Training loss: 2.99611759185791
Validation loss: 2.2945081572378836

Epoch: 6| Step: 4
Training loss: 2.742894172668457
Validation loss: 2.2842606434258084

Epoch: 6| Step: 5
Training loss: 2.8779330253601074
Validation loss: 2.264464250174902

Epoch: 6| Step: 6
Training loss: 2.7659380435943604
Validation loss: 2.2508296197460544

Epoch: 6| Step: 7
Training loss: 1.7736552953720093
Validation loss: 2.245833889130623

Epoch: 6| Step: 8
Training loss: 2.807161331176758
Validation loss: 2.2465944956707697

Epoch: 6| Step: 9
Training loss: 2.5843734741210938
Validation loss: 2.2386664395691245

Epoch: 6| Step: 10
Training loss: 2.5215415954589844
Validation loss: 2.2414218302695983

Epoch: 6| Step: 11
Training loss: 2.0002667903900146
Validation loss: 2.2421581770784114

Epoch: 6| Step: 12
Training loss: 3.3432207107543945
Validation loss: 2.2364766418292956

Epoch: 6| Step: 13
Training loss: 2.062678098678589
Validation loss: 2.2376412935154413

Epoch: 118| Step: 0
Training loss: 2.448042392730713
Validation loss: 2.241239930993767

Epoch: 6| Step: 1
Training loss: 3.0445752143859863
Validation loss: 2.238867417458565

Epoch: 6| Step: 2
Training loss: 2.722123861312866
Validation loss: 2.2424814803625948

Epoch: 6| Step: 3
Training loss: 2.192986249923706
Validation loss: 2.2398189011440484

Epoch: 6| Step: 4
Training loss: 1.4336671829223633
Validation loss: 2.247791523574501

Epoch: 6| Step: 5
Training loss: 1.9095919132232666
Validation loss: 2.269857786035025

Epoch: 6| Step: 6
Training loss: 2.8241195678710938
Validation loss: 2.31774301170021

Epoch: 6| Step: 7
Training loss: 2.958193302154541
Validation loss: 2.3403779434901413

Epoch: 6| Step: 8
Training loss: 2.4673678874969482
Validation loss: 2.330782804437863

Epoch: 6| Step: 9
Training loss: 2.9120097160339355
Validation loss: 2.3092512417865056

Epoch: 6| Step: 10
Training loss: 2.7035398483276367
Validation loss: 2.2861616226934616

Epoch: 6| Step: 11
Training loss: 2.3428077697753906
Validation loss: 2.263966247599612

Epoch: 6| Step: 12
Training loss: 3.033241033554077
Validation loss: 2.249221117265763

Epoch: 6| Step: 13
Training loss: 2.497706174850464
Validation loss: 2.2465571716267574

Epoch: 119| Step: 0
Training loss: 2.430253505706787
Validation loss: 2.241938821731075

Epoch: 6| Step: 1
Training loss: 3.6598117351531982
Validation loss: 2.2413798160450433

Epoch: 6| Step: 2
Training loss: 1.6686787605285645
Validation loss: 2.2328579259175125

Epoch: 6| Step: 3
Training loss: 2.440258502960205
Validation loss: 2.238032179494058

Epoch: 6| Step: 4
Training loss: 2.4489026069641113
Validation loss: 2.2352763504110356

Epoch: 6| Step: 5
Training loss: 1.9603545665740967
Validation loss: 2.2411453903362317

Epoch: 6| Step: 6
Training loss: 2.462938070297241
Validation loss: 2.2412790829135525

Epoch: 6| Step: 7
Training loss: 2.818192958831787
Validation loss: 2.2498202170095136

Epoch: 6| Step: 8
Training loss: 2.184652328491211
Validation loss: 2.2456376116762877

Epoch: 6| Step: 9
Training loss: 3.109476327896118
Validation loss: 2.2502110363334737

Epoch: 6| Step: 10
Training loss: 2.6548595428466797
Validation loss: 2.261364939392254

Epoch: 6| Step: 11
Training loss: 2.7934775352478027
Validation loss: 2.2541109028682915

Epoch: 6| Step: 12
Training loss: 2.2334415912628174
Validation loss: 2.267963852933658

Epoch: 6| Step: 13
Training loss: 2.686434507369995
Validation loss: 2.2699810125494517

Epoch: 120| Step: 0
Training loss: 2.926163673400879
Validation loss: 2.284497380256653

Epoch: 6| Step: 1
Training loss: 2.994412422180176
Validation loss: 2.2750769661318873

Epoch: 6| Step: 2
Training loss: 1.937974452972412
Validation loss: 2.271771736042474

Epoch: 6| Step: 3
Training loss: 2.043731212615967
Validation loss: 2.2681054184513707

Epoch: 6| Step: 4
Training loss: 2.196370840072632
Validation loss: 2.2621518873399302

Epoch: 6| Step: 5
Training loss: 2.591212034225464
Validation loss: 2.2604076785425984

Epoch: 6| Step: 6
Training loss: 3.1822152137756348
Validation loss: 2.2582828357655513

Epoch: 6| Step: 7
Training loss: 2.2271008491516113
Validation loss: 2.2510114100671585

Epoch: 6| Step: 8
Training loss: 2.0393214225769043
Validation loss: 2.2482890159853044

Epoch: 6| Step: 9
Training loss: 2.699726104736328
Validation loss: 2.2392614682515464

Epoch: 6| Step: 10
Training loss: 2.6160082817077637
Validation loss: 2.237521101069707

Epoch: 6| Step: 11
Training loss: 2.4377026557922363
Validation loss: 2.2385894739499657

Epoch: 6| Step: 12
Training loss: 3.2186498641967773
Validation loss: 2.249663617021294

Epoch: 6| Step: 13
Training loss: 1.9533907175064087
Validation loss: 2.2429652624232794

Epoch: 121| Step: 0
Training loss: 3.076028823852539
Validation loss: 2.2474620931891987

Epoch: 6| Step: 1
Training loss: 2.074939727783203
Validation loss: 2.2501771091133036

Epoch: 6| Step: 2
Training loss: 2.4388346672058105
Validation loss: 2.255636067800624

Epoch: 6| Step: 3
Training loss: 2.8531317710876465
Validation loss: 2.275693416595459

Epoch: 6| Step: 4
Training loss: 2.5046467781066895
Validation loss: 2.289594337504397

Epoch: 6| Step: 5
Training loss: 2.851928472518921
Validation loss: 2.295926950311148

Epoch: 6| Step: 6
Training loss: 3.2985334396362305
Validation loss: 2.277257357874224

Epoch: 6| Step: 7
Training loss: 2.317610740661621
Validation loss: 2.265326371756933

Epoch: 6| Step: 8
Training loss: 2.4491539001464844
Validation loss: 2.247471752987113

Epoch: 6| Step: 9
Training loss: 2.498307704925537
Validation loss: 2.2377538322120585

Epoch: 6| Step: 10
Training loss: 2.249699354171753
Validation loss: 2.230672901676547

Epoch: 6| Step: 11
Training loss: 2.231354236602783
Validation loss: 2.228894841286444

Epoch: 6| Step: 12
Training loss: 2.3948724269866943
Validation loss: 2.227075487054804

Epoch: 6| Step: 13
Training loss: 1.8251599073410034
Validation loss: 2.2274814344221547

Epoch: 122| Step: 0
Training loss: 3.0732595920562744
Validation loss: 2.224389422324396

Epoch: 6| Step: 1
Training loss: 3.057659149169922
Validation loss: 2.2268549396145727

Epoch: 6| Step: 2
Training loss: 1.9654269218444824
Validation loss: 2.231384055588835

Epoch: 6| Step: 3
Training loss: 3.002326488494873
Validation loss: 2.222733651438067

Epoch: 6| Step: 4
Training loss: 2.311628580093384
Validation loss: 2.225910499531736

Epoch: 6| Step: 5
Training loss: 2.739353656768799
Validation loss: 2.238608166735659

Epoch: 6| Step: 6
Training loss: 2.9971842765808105
Validation loss: 2.241515403152794

Epoch: 6| Step: 7
Training loss: 1.9724268913269043
Validation loss: 2.2363523488403647

Epoch: 6| Step: 8
Training loss: 2.5164260864257812
Validation loss: 2.246137503654726

Epoch: 6| Step: 9
Training loss: 2.829949378967285
Validation loss: 2.2476901854238203

Epoch: 6| Step: 10
Training loss: 2.1863598823547363
Validation loss: 2.233986105970157

Epoch: 6| Step: 11
Training loss: 1.7887003421783447
Validation loss: 2.2242970338431736

Epoch: 6| Step: 12
Training loss: 1.5450077056884766
Validation loss: 2.2362003403325237

Epoch: 6| Step: 13
Training loss: 3.5641069412231445
Validation loss: 2.226387370017267

Epoch: 123| Step: 0
Training loss: 2.4575648307800293
Validation loss: 2.2224786973768667

Epoch: 6| Step: 1
Training loss: 2.6440882682800293
Validation loss: 2.2176333255665277

Epoch: 6| Step: 2
Training loss: 2.533766269683838
Validation loss: 2.225992951341855

Epoch: 6| Step: 3
Training loss: 2.5960841178894043
Validation loss: 2.2279090112255466

Epoch: 6| Step: 4
Training loss: 2.967946767807007
Validation loss: 2.2239745304148686

Epoch: 6| Step: 5
Training loss: 2.0528507232666016
Validation loss: 2.210659626991518

Epoch: 6| Step: 6
Training loss: 2.089298725128174
Validation loss: 2.2136463503683768

Epoch: 6| Step: 7
Training loss: 2.4328644275665283
Validation loss: 2.213868906421046

Epoch: 6| Step: 8
Training loss: 2.574303150177002
Validation loss: 2.1992875350418912

Epoch: 6| Step: 9
Training loss: 2.46795654296875
Validation loss: 2.1997048521554596

Epoch: 6| Step: 10
Training loss: 2.425729751586914
Validation loss: 2.2020402493015414

Epoch: 6| Step: 11
Training loss: 1.8642910718917847
Validation loss: 2.2016052738312752

Epoch: 6| Step: 12
Training loss: 2.32080340385437
Validation loss: 2.199874119092059

Epoch: 6| Step: 13
Training loss: 4.32351016998291
Validation loss: 2.202483595058482

Epoch: 124| Step: 0
Training loss: 2.397850513458252
Validation loss: 2.2084063381277104

Epoch: 6| Step: 1
Training loss: 3.226975917816162
Validation loss: 2.2182227027031685

Epoch: 6| Step: 2
Training loss: 2.179426670074463
Validation loss: 2.218170489034345

Epoch: 6| Step: 3
Training loss: 2.8068857192993164
Validation loss: 2.2256694647573654

Epoch: 6| Step: 4
Training loss: 1.5541523694992065
Validation loss: 2.243047119468771

Epoch: 6| Step: 5
Training loss: 2.823841094970703
Validation loss: 2.252968067763954

Epoch: 6| Step: 6
Training loss: 2.224102020263672
Validation loss: 2.260934332365631

Epoch: 6| Step: 7
Training loss: 2.72641921043396
Validation loss: 2.259512212968642

Epoch: 6| Step: 8
Training loss: 2.676825523376465
Validation loss: 2.2376350536141345

Epoch: 6| Step: 9
Training loss: 2.19632625579834
Validation loss: 2.2381387013261036

Epoch: 6| Step: 10
Training loss: 2.3894147872924805
Validation loss: 2.2297005243198846

Epoch: 6| Step: 11
Training loss: 2.6460213661193848
Validation loss: 2.2222728562611405

Epoch: 6| Step: 12
Training loss: 2.197610855102539
Validation loss: 2.21977335791434

Epoch: 6| Step: 13
Training loss: 2.9758615493774414
Validation loss: 2.2418339611381612

Epoch: 125| Step: 0
Training loss: 2.696345806121826
Validation loss: 2.2526674706448793

Epoch: 6| Step: 1
Training loss: 2.8241426944732666
Validation loss: 2.2519641691638577

Epoch: 6| Step: 2
Training loss: 2.773519992828369
Validation loss: 2.2522357843255483

Epoch: 6| Step: 3
Training loss: 3.057521343231201
Validation loss: 2.2633369174054874

Epoch: 6| Step: 4
Training loss: 2.299567937850952
Validation loss: 2.2716423824269283

Epoch: 6| Step: 5
Training loss: 2.314882755279541
Validation loss: 2.2815841269749466

Epoch: 6| Step: 6
Training loss: 1.7567483186721802
Validation loss: 2.271388899895453

Epoch: 6| Step: 7
Training loss: 2.6197867393493652
Validation loss: 2.2681055658607074

Epoch: 6| Step: 8
Training loss: 2.4093213081359863
Validation loss: 2.2944350242614746

Epoch: 6| Step: 9
Training loss: 2.4017105102539062
Validation loss: 2.3249924003437

Epoch: 6| Step: 10
Training loss: 2.2554407119750977
Validation loss: 2.315815015505719

Epoch: 6| Step: 11
Training loss: 3.029788017272949
Validation loss: 2.3063608907884166

Epoch: 6| Step: 12
Training loss: 2.439091205596924
Validation loss: 2.2961307687144124

Epoch: 6| Step: 13
Training loss: 1.8205899000167847
Validation loss: 2.259215934302217

Testing loss: 2.396398162841797
