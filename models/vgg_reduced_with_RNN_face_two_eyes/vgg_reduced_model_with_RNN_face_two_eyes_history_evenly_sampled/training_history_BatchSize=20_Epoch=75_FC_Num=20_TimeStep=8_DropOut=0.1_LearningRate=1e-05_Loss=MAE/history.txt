Epoch: 1| Step: 0
Training loss: 4.942260265350342
Validation loss: 5.190323604050503

Epoch: 5| Step: 1
Training loss: 5.062088489532471
Validation loss: 5.178830141662269

Epoch: 5| Step: 2
Training loss: 4.2068562507629395
Validation loss: 5.168719025068386

Epoch: 5| Step: 3
Training loss: 4.926969528198242
Validation loss: 5.158236303637104

Epoch: 5| Step: 4
Training loss: 5.156403541564941
Validation loss: 5.146975214763354

Epoch: 5| Step: 5
Training loss: 4.829290390014648
Validation loss: 5.135014221232424

Epoch: 5| Step: 6
Training loss: 5.6625142097473145
Validation loss: 5.12144160527055

Epoch: 5| Step: 7
Training loss: 4.405689239501953
Validation loss: 5.106945027587234

Epoch: 5| Step: 8
Training loss: 4.544294834136963
Validation loss: 5.090881219474218

Epoch: 5| Step: 9
Training loss: 5.099391460418701
Validation loss: 5.072761786881314

Epoch: 5| Step: 10
Training loss: 5.41297721862793
Validation loss: 5.055173796992148

Epoch: 2| Step: 0
Training loss: 4.709818363189697
Validation loss: 5.034157722227035

Epoch: 5| Step: 1
Training loss: 4.728204250335693
Validation loss: 5.012187957763672

Epoch: 5| Step: 2
Training loss: 5.234192848205566
Validation loss: 4.989883156232937

Epoch: 5| Step: 3
Training loss: 4.632363319396973
Validation loss: 4.9637481833017

Epoch: 5| Step: 4
Training loss: 4.520057678222656
Validation loss: 4.936652157896308

Epoch: 5| Step: 5
Training loss: 4.9019060134887695
Validation loss: 4.90739155328402

Epoch: 5| Step: 6
Training loss: 4.281636714935303
Validation loss: 4.876214181223223

Epoch: 5| Step: 7
Training loss: 4.647268772125244
Validation loss: 4.84212084739439

Epoch: 5| Step: 8
Training loss: 4.765389442443848
Validation loss: 4.807021243597871

Epoch: 5| Step: 9
Training loss: 4.223578453063965
Validation loss: 4.770232298040903

Epoch: 5| Step: 10
Training loss: 4.916637420654297
Validation loss: 4.731862293776645

Epoch: 3| Step: 0
Training loss: 4.512658596038818
Validation loss: 4.690304951001239

Epoch: 5| Step: 1
Training loss: 4.793501853942871
Validation loss: 4.648889890281103

Epoch: 5| Step: 2
Training loss: 4.7579450607299805
Validation loss: 4.606748842423962

Epoch: 5| Step: 3
Training loss: 4.152763366699219
Validation loss: 4.561329590376987

Epoch: 5| Step: 4
Training loss: 4.457312107086182
Validation loss: 4.517944079573437

Epoch: 5| Step: 5
Training loss: 4.4584174156188965
Validation loss: 4.471187201879358

Epoch: 5| Step: 6
Training loss: 3.3627681732177734
Validation loss: 4.425226831948885

Epoch: 5| Step: 7
Training loss: 3.7300498485565186
Validation loss: 4.3801950434202785

Epoch: 5| Step: 8
Training loss: 3.8742737770080566
Validation loss: 4.334620293750558

Epoch: 5| Step: 9
Training loss: 4.380168914794922
Validation loss: 4.289667957572527

Epoch: 5| Step: 10
Training loss: 4.35371208190918
Validation loss: 4.243584181672784

Epoch: 4| Step: 0
Training loss: 3.173856258392334
Validation loss: 4.197299957275391

Epoch: 5| Step: 1
Training loss: 4.606793403625488
Validation loss: 4.156110696895148

Epoch: 5| Step: 2
Training loss: 4.234027862548828
Validation loss: 4.115109674392208

Epoch: 5| Step: 3
Training loss: 3.7758469581604004
Validation loss: 4.077405442473709

Epoch: 5| Step: 4
Training loss: 4.491368293762207
Validation loss: 4.040606534609231

Epoch: 5| Step: 5
Training loss: 3.594177722930908
Validation loss: 4.006682390807777

Epoch: 5| Step: 6
Training loss: 3.8326892852783203
Validation loss: 3.9723085075296383

Epoch: 5| Step: 7
Training loss: 4.895559787750244
Validation loss: 3.935912693700483

Epoch: 5| Step: 8
Training loss: 3.917731523513794
Validation loss: 3.8995136804478143

Epoch: 5| Step: 9
Training loss: 3.089247941970825
Validation loss: 3.868429168578117

Epoch: 5| Step: 10
Training loss: 2.591280698776245
Validation loss: 3.838004691626436

Epoch: 5| Step: 0
Training loss: 3.737657070159912
Validation loss: 3.8104942998578473

Epoch: 5| Step: 1
Training loss: 3.645287275314331
Validation loss: 3.7892499328941427

Epoch: 5| Step: 2
Training loss: 3.9348373413085938
Validation loss: 3.765146340093305

Epoch: 5| Step: 3
Training loss: 3.8967254161834717
Validation loss: 3.743511522969892

Epoch: 5| Step: 4
Training loss: 4.040663719177246
Validation loss: 3.7198610510877383

Epoch: 5| Step: 5
Training loss: 3.3697943687438965
Validation loss: 3.699597474067442

Epoch: 5| Step: 6
Training loss: 2.377781391143799
Validation loss: 3.6794532729733374

Epoch: 5| Step: 7
Training loss: 3.4336981773376465
Validation loss: 3.664220222862818

Epoch: 5| Step: 8
Training loss: 3.4747085571289062
Validation loss: 3.645080135714623

Epoch: 5| Step: 9
Training loss: 3.6068115234375
Validation loss: 3.627674313001735

Epoch: 5| Step: 10
Training loss: 4.276857376098633
Validation loss: 3.611170338046166

Epoch: 6| Step: 0
Training loss: 3.442427158355713
Validation loss: 3.5943895411747757

Epoch: 5| Step: 1
Training loss: 3.6529910564422607
Validation loss: 3.5805918068014164

Epoch: 5| Step: 2
Training loss: 2.6778979301452637
Validation loss: 3.56203467358825

Epoch: 5| Step: 3
Training loss: 2.8094382286071777
Validation loss: 3.5514976619392313

Epoch: 5| Step: 4
Training loss: 3.3386073112487793
Validation loss: 3.5392714264572307

Epoch: 5| Step: 5
Training loss: 3.9274239540100098
Validation loss: 3.524455237132247

Epoch: 5| Step: 6
Training loss: 3.6330947875976562
Validation loss: 3.510265688742361

Epoch: 5| Step: 7
Training loss: 3.5465781688690186
Validation loss: 3.4956444489058627

Epoch: 5| Step: 8
Training loss: 4.1828999519348145
Validation loss: 3.4861075570506435

Epoch: 5| Step: 9
Training loss: 3.3972256183624268
Validation loss: 3.4801040849378033

Epoch: 5| Step: 10
Training loss: 3.388653516769409
Validation loss: 3.4662687060653523

Epoch: 7| Step: 0
Training loss: 3.6605026721954346
Validation loss: 3.4526398156278875

Epoch: 5| Step: 1
Training loss: 4.235289573669434
Validation loss: 3.446303895724717

Epoch: 5| Step: 2
Training loss: 3.037628173828125
Validation loss: 3.438194869666971

Epoch: 5| Step: 3
Training loss: 2.7021586894989014
Validation loss: 3.4314326086351947

Epoch: 5| Step: 4
Training loss: 3.348416805267334
Validation loss: 3.421603238710793

Epoch: 5| Step: 5
Training loss: 2.707843542098999
Validation loss: 3.415551818827147

Epoch: 5| Step: 6
Training loss: 3.5247435569763184
Validation loss: 3.411073410382835

Epoch: 5| Step: 7
Training loss: 3.361954927444458
Validation loss: 3.403186516095233

Epoch: 5| Step: 8
Training loss: 3.2198073863983154
Validation loss: 3.3913927590975197

Epoch: 5| Step: 9
Training loss: 3.319683074951172
Validation loss: 3.3818110240403043

Epoch: 5| Step: 10
Training loss: 3.9870712757110596
Validation loss: 3.374836201308876

Epoch: 8| Step: 0
Training loss: 3.529904842376709
Validation loss: 3.3690853041987263

Epoch: 5| Step: 1
Training loss: 3.330425262451172
Validation loss: 3.3613604960903043

Epoch: 5| Step: 2
Training loss: 3.063458204269409
Validation loss: 3.3492584638698126

Epoch: 5| Step: 3
Training loss: 3.4590370655059814
Validation loss: 3.3328390788006526

Epoch: 5| Step: 4
Training loss: 2.91841459274292
Validation loss: 3.313021972615232

Epoch: 5| Step: 5
Training loss: 3.51509165763855
Validation loss: 3.30377866888559

Epoch: 5| Step: 6
Training loss: 3.6731395721435547
Validation loss: 3.2932083017082623

Epoch: 5| Step: 7
Training loss: 2.9100210666656494
Validation loss: 3.285420233203519

Epoch: 5| Step: 8
Training loss: 3.499368190765381
Validation loss: 3.2804008632577877

Epoch: 5| Step: 9
Training loss: 3.4019477367401123
Validation loss: 3.272253497954338

Epoch: 5| Step: 10
Training loss: 2.6919708251953125
Validation loss: 3.266267684198195

Epoch: 9| Step: 0
Training loss: 2.7064757347106934
Validation loss: 3.2623928875051518

Epoch: 5| Step: 1
Training loss: 3.7275638580322266
Validation loss: 3.254923100112587

Epoch: 5| Step: 2
Training loss: 2.8716509342193604
Validation loss: 3.2504596171840543

Epoch: 5| Step: 3
Training loss: 3.588698148727417
Validation loss: 3.247131901402627

Epoch: 5| Step: 4
Training loss: 3.0027995109558105
Validation loss: 3.2418124675750732

Epoch: 5| Step: 5
Training loss: 3.0273616313934326
Validation loss: 3.2321325630270024

Epoch: 5| Step: 6
Training loss: 3.5730621814727783
Validation loss: 3.2228992472412767

Epoch: 5| Step: 7
Training loss: 3.5305702686309814
Validation loss: 3.213608211086642

Epoch: 5| Step: 8
Training loss: 3.0978760719299316
Validation loss: 3.205856038678077

Epoch: 5| Step: 9
Training loss: 3.167583465576172
Validation loss: 3.1988699256732898

Epoch: 5| Step: 10
Training loss: 3.034332513809204
Validation loss: 3.1926952510751705

Epoch: 10| Step: 0
Training loss: 3.7487359046936035
Validation loss: 3.184377183196365

Epoch: 5| Step: 1
Training loss: 2.841625928878784
Validation loss: 3.1769109669552056

Epoch: 5| Step: 2
Training loss: 3.126845121383667
Validation loss: 3.1748166212471585

Epoch: 5| Step: 3
Training loss: 3.1718335151672363
Validation loss: 3.1661562406888573

Epoch: 5| Step: 4
Training loss: 3.2125632762908936
Validation loss: 3.158631060713081

Epoch: 5| Step: 5
Training loss: 2.7187390327453613
Validation loss: 3.1559945588470786

Epoch: 5| Step: 6
Training loss: 3.360713481903076
Validation loss: 3.147873019659391

Epoch: 5| Step: 7
Training loss: 2.7060863971710205
Validation loss: 3.1471949367113012

Epoch: 5| Step: 8
Training loss: 3.259425640106201
Validation loss: 3.1389276801898913

Epoch: 5| Step: 9
Training loss: 3.2574710845947266
Validation loss: 3.136416571114653

Epoch: 5| Step: 10
Training loss: 3.471173048019409
Validation loss: 3.128495042042066

Epoch: 11| Step: 0
Training loss: 2.815138339996338
Validation loss: 3.1247654140636487

Epoch: 5| Step: 1
Training loss: 2.9605441093444824
Validation loss: 3.119098327493155

Epoch: 5| Step: 2
Training loss: 3.367760181427002
Validation loss: 3.115522374388992

Epoch: 5| Step: 3
Training loss: 3.09635591506958
Validation loss: 3.1078695404914116

Epoch: 5| Step: 4
Training loss: 2.8623504638671875
Validation loss: 3.103098177140759

Epoch: 5| Step: 5
Training loss: 3.227414608001709
Validation loss: 3.0972013678601993

Epoch: 5| Step: 6
Training loss: 3.067925214767456
Validation loss: 3.0929008786396315

Epoch: 5| Step: 7
Training loss: 3.2047219276428223
Validation loss: 3.092281764553439

Epoch: 5| Step: 8
Training loss: 2.940819501876831
Validation loss: 3.0874869669637373

Epoch: 5| Step: 9
Training loss: 3.707944393157959
Validation loss: 3.0814025696887763

Epoch: 5| Step: 10
Training loss: 3.1207308769226074
Validation loss: 3.0774906271247455

Epoch: 12| Step: 0
Training loss: 2.43595814704895
Validation loss: 3.0702931342586393

Epoch: 5| Step: 1
Training loss: 3.2476043701171875
Validation loss: 3.064685539532733

Epoch: 5| Step: 2
Training loss: 2.9946036338806152
Validation loss: 3.0605094048284713

Epoch: 5| Step: 3
Training loss: 2.7627012729644775
Validation loss: 3.0566328161506244

Epoch: 5| Step: 4
Training loss: 4.092899799346924
Validation loss: 3.0514385392588954

Epoch: 5| Step: 5
Training loss: 3.3641300201416016
Validation loss: 3.046017882644489

Epoch: 5| Step: 6
Training loss: 2.4753870964050293
Validation loss: 3.041471040377053

Epoch: 5| Step: 7
Training loss: 2.3359456062316895
Validation loss: 3.0406080958663777

Epoch: 5| Step: 8
Training loss: 3.2234463691711426
Validation loss: 3.0330359961396907

Epoch: 5| Step: 9
Training loss: 3.5229687690734863
Validation loss: 3.0291638015418925

Epoch: 5| Step: 10
Training loss: 3.644751787185669
Validation loss: 3.0238079819627988

Epoch: 13| Step: 0
Training loss: 3.3992276191711426
Validation loss: 3.019786616807343

Epoch: 5| Step: 1
Training loss: 2.845900774002075
Validation loss: 3.0165602571220806

Epoch: 5| Step: 2
Training loss: 3.0172574520111084
Validation loss: 3.015880428334718

Epoch: 5| Step: 3
Training loss: 2.852280378341675
Validation loss: 3.0107633477898053

Epoch: 5| Step: 4
Training loss: 3.549091339111328
Validation loss: 3.009418902858611

Epoch: 5| Step: 5
Training loss: 2.9598114490509033
Validation loss: 2.9983394120329168

Epoch: 5| Step: 6
Training loss: 3.3783962726593018
Validation loss: 2.991414567475678

Epoch: 5| Step: 7
Training loss: 2.6485674381256104
Validation loss: 2.98859643167065

Epoch: 5| Step: 8
Training loss: 3.1032772064208984
Validation loss: 2.982833408540295

Epoch: 5| Step: 9
Training loss: 3.26739764213562
Validation loss: 2.9805577314028175

Epoch: 5| Step: 10
Training loss: 2.613267183303833
Validation loss: 2.9758316701458347

Epoch: 14| Step: 0
Training loss: 2.6041524410247803
Validation loss: 2.972599103886594

Epoch: 5| Step: 1
Training loss: 2.679722309112549
Validation loss: 2.9696463718209216

Epoch: 5| Step: 2
Training loss: 2.9269464015960693
Validation loss: 2.963337952090848

Epoch: 5| Step: 3
Training loss: 3.0564608573913574
Validation loss: 2.9606281019026235

Epoch: 5| Step: 4
Training loss: 3.272005558013916
Validation loss: 2.957897427261517

Epoch: 5| Step: 5
Training loss: 2.9109673500061035
Validation loss: 2.948430125431348

Epoch: 5| Step: 6
Training loss: 3.042525053024292
Validation loss: 2.947111770670901

Epoch: 5| Step: 7
Training loss: 3.074082374572754
Validation loss: 2.9424444501117994

Epoch: 5| Step: 8
Training loss: 2.826742649078369
Validation loss: 2.9385220414848736

Epoch: 5| Step: 9
Training loss: 3.3658409118652344
Validation loss: 2.934153826005997

Epoch: 5| Step: 10
Training loss: 3.6682050228118896
Validation loss: 2.9330929120381675

Epoch: 15| Step: 0
Training loss: 2.889800786972046
Validation loss: 2.928468255586522

Epoch: 5| Step: 1
Training loss: 3.624788761138916
Validation loss: 2.9269406974956556

Epoch: 5| Step: 2
Training loss: 3.1511752605438232
Validation loss: 2.924198781290362

Epoch: 5| Step: 3
Training loss: 3.0818302631378174
Validation loss: 2.914846340815226

Epoch: 5| Step: 4
Training loss: 3.2446765899658203
Validation loss: 2.910954862512568

Epoch: 5| Step: 5
Training loss: 2.7355031967163086
Validation loss: 2.906206202763383

Epoch: 5| Step: 6
Training loss: 2.2088582515716553
Validation loss: 2.8999436375915364

Epoch: 5| Step: 7
Training loss: 3.5750815868377686
Validation loss: 2.8957766076569915

Epoch: 5| Step: 8
Training loss: 3.1431846618652344
Validation loss: 2.892784313489032

Epoch: 5| Step: 9
Training loss: 2.7479488849639893
Validation loss: 2.8894453099978867

Epoch: 5| Step: 10
Training loss: 2.5216503143310547
Validation loss: 2.882555677044776

Epoch: 16| Step: 0
Training loss: 2.706967830657959
Validation loss: 2.8772619539691555

Epoch: 5| Step: 1
Training loss: 3.35068941116333
Validation loss: 2.8728405967835458

Epoch: 5| Step: 2
Training loss: 2.801945924758911
Validation loss: 2.8663460413614907

Epoch: 5| Step: 3
Training loss: 3.03975248336792
Validation loss: 2.8648326114941667

Epoch: 5| Step: 4
Training loss: 3.200875759124756
Validation loss: 2.8765691993057088

Epoch: 5| Step: 5
Training loss: 3.707562208175659
Validation loss: 2.8533266385396323

Epoch: 5| Step: 6
Training loss: 2.534099578857422
Validation loss: 2.8501120869831373

Epoch: 5| Step: 7
Training loss: 2.6900343894958496
Validation loss: 2.845696879971412

Epoch: 5| Step: 8
Training loss: 3.0617470741271973
Validation loss: 2.841274743439049

Epoch: 5| Step: 9
Training loss: 2.8003780841827393
Validation loss: 2.8346721254369265

Epoch: 5| Step: 10
Training loss: 2.677342176437378
Validation loss: 2.827881807922035

Epoch: 17| Step: 0
Training loss: 2.486002206802368
Validation loss: 2.826867313795192

Epoch: 5| Step: 1
Training loss: 3.094078540802002
Validation loss: 2.824172824941656

Epoch: 5| Step: 2
Training loss: 3.0325381755828857
Validation loss: 2.8234871766900502

Epoch: 5| Step: 3
Training loss: 2.9848849773406982
Validation loss: 2.815442262157317

Epoch: 5| Step: 4
Training loss: 2.759443759918213
Validation loss: 2.8135071416055

Epoch: 5| Step: 5
Training loss: 2.6227338314056396
Validation loss: 2.80752638078505

Epoch: 5| Step: 6
Training loss: 3.2035489082336426
Validation loss: 2.807177571840184

Epoch: 5| Step: 7
Training loss: 3.0275025367736816
Validation loss: 2.8001281112752934

Epoch: 5| Step: 8
Training loss: 3.487799882888794
Validation loss: 2.794912294674945

Epoch: 5| Step: 9
Training loss: 2.9412474632263184
Validation loss: 2.7893709418594197

Epoch: 5| Step: 10
Training loss: 2.533552408218384
Validation loss: 2.7878693867755193

Epoch: 18| Step: 0
Training loss: 2.733104705810547
Validation loss: 2.788840227229621

Epoch: 5| Step: 1
Training loss: 2.7611544132232666
Validation loss: 2.7859062097405873

Epoch: 5| Step: 2
Training loss: 2.9609408378601074
Validation loss: 2.781401575252574

Epoch: 5| Step: 3
Training loss: 3.2439379692077637
Validation loss: 2.774095622442102

Epoch: 5| Step: 4
Training loss: 2.917667865753174
Validation loss: 2.765290039841847

Epoch: 5| Step: 5
Training loss: 2.2297346591949463
Validation loss: 2.7631715472026537

Epoch: 5| Step: 6
Training loss: 2.7453551292419434
Validation loss: 2.7637029745245494

Epoch: 5| Step: 7
Training loss: 2.7622313499450684
Validation loss: 2.7542043398785334

Epoch: 5| Step: 8
Training loss: 2.574798345565796
Validation loss: 2.751524284321775

Epoch: 5| Step: 9
Training loss: 3.499911069869995
Validation loss: 2.7567484968452045

Epoch: 5| Step: 10
Training loss: 3.615818977355957
Validation loss: 2.760832102068009

Epoch: 19| Step: 0
Training loss: 2.504312038421631
Validation loss: 2.7377723878429783

Epoch: 5| Step: 1
Training loss: 2.223471164703369
Validation loss: 2.74015240259068

Epoch: 5| Step: 2
Training loss: 2.555349111557007
Validation loss: 2.7361402639778714

Epoch: 5| Step: 3
Training loss: 2.4826254844665527
Validation loss: 2.7425512882970993

Epoch: 5| Step: 4
Training loss: 3.371751308441162
Validation loss: 2.735076355677779

Epoch: 5| Step: 5
Training loss: 3.2818291187286377
Validation loss: 2.7359742938831286

Epoch: 5| Step: 6
Training loss: 3.571284770965576
Validation loss: 2.7339822143636723

Epoch: 5| Step: 7
Training loss: 3.0415477752685547
Validation loss: 2.722293584577499

Epoch: 5| Step: 8
Training loss: 2.6666057109832764
Validation loss: 2.7338687860837547

Epoch: 5| Step: 9
Training loss: 3.2646660804748535
Validation loss: 2.745212862568517

Epoch: 5| Step: 10
Training loss: 2.7956864833831787
Validation loss: 2.730063074378557

Epoch: 20| Step: 0
Training loss: 2.840073823928833
Validation loss: 2.705033499707458

Epoch: 5| Step: 1
Training loss: 2.990894079208374
Validation loss: 2.704338471094767

Epoch: 5| Step: 2
Training loss: 2.785480499267578
Validation loss: 2.7067837894603772

Epoch: 5| Step: 3
Training loss: 2.40228533744812
Validation loss: 2.7023317301145164

Epoch: 5| Step: 4
Training loss: 3.021672248840332
Validation loss: 2.700412852789766

Epoch: 5| Step: 5
Training loss: 2.4782261848449707
Validation loss: 2.6979538522740847

Epoch: 5| Step: 6
Training loss: 2.861570358276367
Validation loss: 2.6970573522711314

Epoch: 5| Step: 7
Training loss: 2.7679755687713623
Validation loss: 2.6887744959964546

Epoch: 5| Step: 8
Training loss: 3.0397934913635254
Validation loss: 2.685904159340807

Epoch: 5| Step: 9
Training loss: 2.6281447410583496
Validation loss: 2.6775005068830264

Epoch: 5| Step: 10
Training loss: 3.8519606590270996
Validation loss: 2.6701586554127354

Epoch: 21| Step: 0
Training loss: 3.1607394218444824
Validation loss: 2.670998191320768

Epoch: 5| Step: 1
Training loss: 2.4920997619628906
Validation loss: 2.672222460469892

Epoch: 5| Step: 2
Training loss: 3.4197258949279785
Validation loss: 2.6715079533156527

Epoch: 5| Step: 3
Training loss: 2.967942714691162
Validation loss: 2.667807258585448

Epoch: 5| Step: 4
Training loss: 2.8560688495635986
Validation loss: 2.6605215277723087

Epoch: 5| Step: 5
Training loss: 2.6396472454071045
Validation loss: 2.655414319807483

Epoch: 5| Step: 6
Training loss: 2.937814235687256
Validation loss: 2.653623811660274

Epoch: 5| Step: 7
Training loss: 2.945830821990967
Validation loss: 2.65488088515497

Epoch: 5| Step: 8
Training loss: 2.36104154586792
Validation loss: 2.649429759671611

Epoch: 5| Step: 9
Training loss: 2.870795726776123
Validation loss: 2.6453855704235774

Epoch: 5| Step: 10
Training loss: 2.479829788208008
Validation loss: 2.645478238341629

Epoch: 22| Step: 0
Training loss: 2.912238836288452
Validation loss: 2.644963108083253

Epoch: 5| Step: 1
Training loss: 2.895782470703125
Validation loss: 2.6392048687063236

Epoch: 5| Step: 2
Training loss: 2.3106064796447754
Validation loss: 2.6389032948401665

Epoch: 5| Step: 3
Training loss: 2.864732027053833
Validation loss: 2.636972767050548

Epoch: 5| Step: 4
Training loss: 2.9042725563049316
Validation loss: 2.638722849148576

Epoch: 5| Step: 5
Training loss: 2.936769485473633
Validation loss: 2.6440737119285007

Epoch: 5| Step: 6
Training loss: 2.7875094413757324
Validation loss: 2.632285156557637

Epoch: 5| Step: 7
Training loss: 2.8895328044891357
Validation loss: 2.630426609387962

Epoch: 5| Step: 8
Training loss: 2.504420757293701
Validation loss: 2.6335607908105336

Epoch: 5| Step: 9
Training loss: 2.5173592567443848
Validation loss: 2.625805293360064

Epoch: 5| Step: 10
Training loss: 3.6037142276763916
Validation loss: 2.6199575495976273

Epoch: 23| Step: 0
Training loss: 2.9154045581817627
Validation loss: 2.627613898246519

Epoch: 5| Step: 1
Training loss: 2.657008647918701
Validation loss: 2.628267953472753

Epoch: 5| Step: 2
Training loss: 2.465747833251953
Validation loss: 2.6313417547492572

Epoch: 5| Step: 3
Training loss: 3.2814643383026123
Validation loss: 2.6288299201637186

Epoch: 5| Step: 4
Training loss: 2.5981507301330566
Validation loss: 2.610708472549274

Epoch: 5| Step: 5
Training loss: 2.04154634475708
Validation loss: 2.6132353941599527

Epoch: 5| Step: 6
Training loss: 3.0134756565093994
Validation loss: 2.625828658380816

Epoch: 5| Step: 7
Training loss: 3.7161269187927246
Validation loss: 2.6200931456781205

Epoch: 5| Step: 8
Training loss: 2.698122501373291
Validation loss: 2.6148841047799714

Epoch: 5| Step: 9
Training loss: 2.8567733764648438
Validation loss: 2.604086906679215

Epoch: 5| Step: 10
Training loss: 2.6038577556610107
Validation loss: 2.606147668694937

Epoch: 24| Step: 0
Training loss: 3.0799336433410645
Validation loss: 2.6086520482135076

Epoch: 5| Step: 1
Training loss: 2.841032028198242
Validation loss: 2.606865685473206

Epoch: 5| Step: 2
Training loss: 2.475555896759033
Validation loss: 2.598385167378251

Epoch: 5| Step: 3
Training loss: 2.7061233520507812
Validation loss: 2.5936360564283145

Epoch: 5| Step: 4
Training loss: 2.6448493003845215
Validation loss: 2.594304930779242

Epoch: 5| Step: 5
Training loss: 3.849997043609619
Validation loss: 2.5937870061525734

Epoch: 5| Step: 6
Training loss: 2.569963216781616
Validation loss: 2.59204448423078

Epoch: 5| Step: 7
Training loss: 2.6790270805358887
Validation loss: 2.5893449937143633

Epoch: 5| Step: 8
Training loss: 2.5338234901428223
Validation loss: 2.5891191395380164

Epoch: 5| Step: 9
Training loss: 2.6644420623779297
Validation loss: 2.59514025462571

Epoch: 5| Step: 10
Training loss: 2.716057777404785
Validation loss: 2.6209031305005475

Epoch: 25| Step: 0
Training loss: 3.120161533355713
Validation loss: 2.5942967604565363

Epoch: 5| Step: 1
Training loss: 2.720773696899414
Validation loss: 2.587419463742164

Epoch: 5| Step: 2
Training loss: 2.516310214996338
Validation loss: 2.592442140784315

Epoch: 5| Step: 3
Training loss: 3.0433154106140137
Validation loss: 2.5943351561023342

Epoch: 5| Step: 4
Training loss: 2.9925622940063477
Validation loss: 2.5875193739450104

Epoch: 5| Step: 5
Training loss: 3.04840087890625
Validation loss: 2.5818008504888064

Epoch: 5| Step: 6
Training loss: 2.3965280055999756
Validation loss: 2.583074679938696

Epoch: 5| Step: 7
Training loss: 3.1010608673095703
Validation loss: 2.5801115292374805

Epoch: 5| Step: 8
Training loss: 2.5966415405273438
Validation loss: 2.577567918326265

Epoch: 5| Step: 9
Training loss: 2.9404919147491455
Validation loss: 2.5775512033893215

Epoch: 5| Step: 10
Training loss: 2.048109769821167
Validation loss: 2.5723740695625223

Epoch: 26| Step: 0
Training loss: 2.790346622467041
Validation loss: 2.578938394464472

Epoch: 5| Step: 1
Training loss: 2.7980494499206543
Validation loss: 2.580316492306289

Epoch: 5| Step: 2
Training loss: 3.4939846992492676
Validation loss: 2.5769374703848236

Epoch: 5| Step: 3
Training loss: 2.4927356243133545
Validation loss: 2.566798443435341

Epoch: 5| Step: 4
Training loss: 2.652616024017334
Validation loss: 2.5597652799339703

Epoch: 5| Step: 5
Training loss: 2.4238693714141846
Validation loss: 2.5548626735646236

Epoch: 5| Step: 6
Training loss: 2.9059500694274902
Validation loss: 2.5465540296287945

Epoch: 5| Step: 7
Training loss: 2.8615288734436035
Validation loss: 2.543497100953133

Epoch: 5| Step: 8
Training loss: 2.3269546031951904
Validation loss: 2.543330802712389

Epoch: 5| Step: 9
Training loss: 2.5596747398376465
Validation loss: 2.538075359918738

Epoch: 5| Step: 10
Training loss: 3.155543088912964
Validation loss: 2.543260807632118

Epoch: 27| Step: 0
Training loss: 2.677384376525879
Validation loss: 2.5475792654099

Epoch: 5| Step: 1
Training loss: 3.004448175430298
Validation loss: 2.554282631925357

Epoch: 5| Step: 2
Training loss: 2.5317063331604004
Validation loss: 2.546402100593813

Epoch: 5| Step: 3
Training loss: 2.29775071144104
Validation loss: 2.541603442161314

Epoch: 5| Step: 4
Training loss: 3.083242654800415
Validation loss: 2.5392564265958724

Epoch: 5| Step: 5
Training loss: 2.7442142963409424
Validation loss: 2.5499538401121735

Epoch: 5| Step: 6
Training loss: 3.0553994178771973
Validation loss: 2.5363757533411824

Epoch: 5| Step: 7
Training loss: 2.7958264350891113
Validation loss: 2.523819979800973

Epoch: 5| Step: 8
Training loss: 2.8793938159942627
Validation loss: 2.526669035675705

Epoch: 5| Step: 9
Training loss: 2.2138028144836426
Validation loss: 2.5202649998408493

Epoch: 5| Step: 10
Training loss: 3.035635232925415
Validation loss: 2.5265771137770785

Epoch: 28| Step: 0
Training loss: 3.19047474861145
Validation loss: 2.537100935495028

Epoch: 5| Step: 1
Training loss: 2.5258145332336426
Validation loss: 2.5439150794859855

Epoch: 5| Step: 2
Training loss: 2.9472169876098633
Validation loss: 2.529339539107456

Epoch: 5| Step: 3
Training loss: 2.7993056774139404
Validation loss: 2.536192968327512

Epoch: 5| Step: 4
Training loss: 2.5043082237243652
Validation loss: 2.5387212384131645

Epoch: 5| Step: 5
Training loss: 2.762561798095703
Validation loss: 2.5169853625759

Epoch: 5| Step: 6
Training loss: 2.8690099716186523
Validation loss: 2.5118898883942635

Epoch: 5| Step: 7
Training loss: 2.639094829559326
Validation loss: 2.5208757846586165

Epoch: 5| Step: 8
Training loss: 2.463595151901245
Validation loss: 2.5091075922853205

Epoch: 5| Step: 9
Training loss: 2.4855213165283203
Validation loss: 2.5143007155387633

Epoch: 5| Step: 10
Training loss: 2.9626479148864746
Validation loss: 2.500266880117437

Epoch: 29| Step: 0
Training loss: 3.0188634395599365
Validation loss: 2.5025154980280067

Epoch: 5| Step: 1
Training loss: 2.6723833084106445
Validation loss: 2.5018206488701606

Epoch: 5| Step: 2
Training loss: 1.869183897972107
Validation loss: 2.519855083957795

Epoch: 5| Step: 3
Training loss: 2.6380410194396973
Validation loss: 2.5175167822068736

Epoch: 5| Step: 4
Training loss: 3.170280933380127
Validation loss: 2.513113074405219

Epoch: 5| Step: 5
Training loss: 2.7710628509521484
Validation loss: 2.4984472567035305

Epoch: 5| Step: 6
Training loss: 2.85435152053833
Validation loss: 2.4913437212667158

Epoch: 5| Step: 7
Training loss: 3.2216968536376953
Validation loss: 2.495893855248728

Epoch: 5| Step: 8
Training loss: 2.779757261276245
Validation loss: 2.495916707541353

Epoch: 5| Step: 9
Training loss: 2.093993663787842
Validation loss: 2.4877815323491252

Epoch: 5| Step: 10
Training loss: 2.89581561088562
Validation loss: 2.497035893060828

Epoch: 30| Step: 0
Training loss: 2.7211740016937256
Validation loss: 2.4847856670297603

Epoch: 5| Step: 1
Training loss: 2.4966249465942383
Validation loss: 2.492802781443442

Epoch: 5| Step: 2
Training loss: 3.3415367603302
Validation loss: 2.5091236611848236

Epoch: 5| Step: 3
Training loss: 3.100193977355957
Validation loss: 2.5151094185408724

Epoch: 5| Step: 4
Training loss: 3.2723045349121094
Validation loss: 2.508010741203062

Epoch: 5| Step: 5
Training loss: 2.701690196990967
Validation loss: 2.491482480879753

Epoch: 5| Step: 6
Training loss: 1.9460277557373047
Validation loss: 2.47363539408612

Epoch: 5| Step: 7
Training loss: 2.302325487136841
Validation loss: 2.4681765571717293

Epoch: 5| Step: 8
Training loss: 2.174185037612915
Validation loss: 2.470291958060316

Epoch: 5| Step: 9
Training loss: 3.2309792041778564
Validation loss: 2.468893761275917

Epoch: 5| Step: 10
Training loss: 2.5276424884796143
Validation loss: 2.471597356180991

Epoch: 31| Step: 0
Training loss: 2.4951395988464355
Validation loss: 2.4735024821373726

Epoch: 5| Step: 1
Training loss: 3.5599052906036377
Validation loss: 2.4665104317408737

Epoch: 5| Step: 2
Training loss: 2.453651189804077
Validation loss: 2.4620497329260713

Epoch: 5| Step: 3
Training loss: 2.5975375175476074
Validation loss: 2.464384376361806

Epoch: 5| Step: 4
Training loss: 2.3980183601379395
Validation loss: 2.4631691619914067

Epoch: 5| Step: 5
Training loss: 3.6079113483428955
Validation loss: 2.4656871659781343

Epoch: 5| Step: 6
Training loss: 2.5562634468078613
Validation loss: 2.4680204801661993

Epoch: 5| Step: 7
Training loss: 2.6876718997955322
Validation loss: 2.4637269973754883

Epoch: 5| Step: 8
Training loss: 2.3086774349212646
Validation loss: 2.467834334219656

Epoch: 5| Step: 9
Training loss: 2.243364095687866
Validation loss: 2.471281023435695

Epoch: 5| Step: 10
Training loss: 2.8264715671539307
Validation loss: 2.4686354719182497

Epoch: 32| Step: 0
Training loss: 2.540513515472412
Validation loss: 2.4769163195804884

Epoch: 5| Step: 1
Training loss: 2.7275550365448
Validation loss: 2.4594824929391184

Epoch: 5| Step: 2
Training loss: 2.5841434001922607
Validation loss: 2.459266963825431

Epoch: 5| Step: 3
Training loss: 3.2658133506774902
Validation loss: 2.460252574695054

Epoch: 5| Step: 4
Training loss: 3.185767412185669
Validation loss: 2.464048872711838

Epoch: 5| Step: 5
Training loss: 2.3993728160858154
Validation loss: 2.4635304430479645

Epoch: 5| Step: 6
Training loss: 2.2453551292419434
Validation loss: 2.4547434340241137

Epoch: 5| Step: 7
Training loss: 2.3748176097869873
Validation loss: 2.451658171992148

Epoch: 5| Step: 8
Training loss: 2.6693263053894043
Validation loss: 2.450348013190813

Epoch: 5| Step: 9
Training loss: 3.043795347213745
Validation loss: 2.4502527149774695

Epoch: 5| Step: 10
Training loss: 2.490560293197632
Validation loss: 2.4503338465126614

Epoch: 33| Step: 0
Training loss: 2.26212739944458
Validation loss: 2.44476358736715

Epoch: 5| Step: 1
Training loss: 2.8156166076660156
Validation loss: 2.4478311897605978

Epoch: 5| Step: 2
Training loss: 2.4853012561798096
Validation loss: 2.4490111668904624

Epoch: 5| Step: 3
Training loss: 2.2830522060394287
Validation loss: 2.460611915075651

Epoch: 5| Step: 4
Training loss: 2.6948180198669434
Validation loss: 2.48549832067182

Epoch: 5| Step: 5
Training loss: 2.728334903717041
Validation loss: 2.461363661673761

Epoch: 5| Step: 6
Training loss: 2.971663236618042
Validation loss: 2.4504891390441568

Epoch: 5| Step: 7
Training loss: 2.7459046840667725
Validation loss: 2.4455780213879

Epoch: 5| Step: 8
Training loss: 3.265082597732544
Validation loss: 2.4446354501990863

Epoch: 5| Step: 9
Training loss: 3.0094943046569824
Validation loss: 2.4424091359620452

Epoch: 5| Step: 10
Training loss: 2.221426010131836
Validation loss: 2.4366821755645094

Epoch: 34| Step: 0
Training loss: 2.192033529281616
Validation loss: 2.438530683517456

Epoch: 5| Step: 1
Training loss: 2.939967632293701
Validation loss: 2.434950174823884

Epoch: 5| Step: 2
Training loss: 2.923311710357666
Validation loss: 2.4450903554116525

Epoch: 5| Step: 3
Training loss: 2.697479009628296
Validation loss: 2.441426787325131

Epoch: 5| Step: 4
Training loss: 2.8212063312530518
Validation loss: 2.4447329095614854

Epoch: 5| Step: 5
Training loss: 2.945354461669922
Validation loss: 2.4422789747996996

Epoch: 5| Step: 6
Training loss: 2.1590752601623535
Validation loss: 2.451976858159547

Epoch: 5| Step: 7
Training loss: 2.903320789337158
Validation loss: 2.4489686078922723

Epoch: 5| Step: 8
Training loss: 2.234252691268921
Validation loss: 2.4462864988593647

Epoch: 5| Step: 9
Training loss: 2.866412401199341
Validation loss: 2.4427849733701317

Epoch: 5| Step: 10
Training loss: 2.7819015979766846
Validation loss: 2.4382040654459307

Epoch: 35| Step: 0
Training loss: 2.134239673614502
Validation loss: 2.4367969856467298

Epoch: 5| Step: 1
Training loss: 2.272606372833252
Validation loss: 2.4261761455125708

Epoch: 5| Step: 2
Training loss: 1.950243592262268
Validation loss: 2.4277778312724125

Epoch: 5| Step: 3
Training loss: 2.328533172607422
Validation loss: 2.4321762951471473

Epoch: 5| Step: 4
Training loss: 3.0033040046691895
Validation loss: 2.4345718224843345

Epoch: 5| Step: 5
Training loss: 2.7542648315429688
Validation loss: 2.436578384009741

Epoch: 5| Step: 6
Training loss: 2.273820400238037
Validation loss: 2.453471722141389

Epoch: 5| Step: 7
Training loss: 2.7812514305114746
Validation loss: 2.4455385182493474

Epoch: 5| Step: 8
Training loss: 4.121403694152832
Validation loss: 2.4321843603605866

Epoch: 5| Step: 9
Training loss: 2.988223075866699
Validation loss: 2.4241291399924987

Epoch: 5| Step: 10
Training loss: 2.807610511779785
Validation loss: 2.4209151088550525

Epoch: 36| Step: 0
Training loss: 2.284149408340454
Validation loss: 2.4159048372699368

Epoch: 5| Step: 1
Training loss: 2.9314420223236084
Validation loss: 2.4141720879462456

Epoch: 5| Step: 2
Training loss: 3.2539687156677246
Validation loss: 2.4236663208212903

Epoch: 5| Step: 3
Training loss: 2.4771227836608887
Validation loss: 2.42803926878078

Epoch: 5| Step: 4
Training loss: 2.869380235671997
Validation loss: 2.429894199935339

Epoch: 5| Step: 5
Training loss: 2.8619606494903564
Validation loss: 2.4265903529300483

Epoch: 5| Step: 6
Training loss: 2.848633289337158
Validation loss: 2.418668029128864

Epoch: 5| Step: 7
Training loss: 1.815006971359253
Validation loss: 2.4150914299872612

Epoch: 5| Step: 8
Training loss: 2.5735697746276855
Validation loss: 2.413385179734999

Epoch: 5| Step: 9
Training loss: 2.783965587615967
Validation loss: 2.4079313739653556

Epoch: 5| Step: 10
Training loss: 2.617053985595703
Validation loss: 2.4124782905783704

Epoch: 37| Step: 0
Training loss: 2.6139583587646484
Validation loss: 2.417905822876961

Epoch: 5| Step: 1
Training loss: 1.9968246221542358
Validation loss: 2.414364459694073

Epoch: 5| Step: 2
Training loss: 2.5293397903442383
Validation loss: 2.420049182830318

Epoch: 5| Step: 3
Training loss: 2.3097283840179443
Validation loss: 2.418706568338538

Epoch: 5| Step: 4
Training loss: 2.1715943813323975
Validation loss: 2.4272715917197605

Epoch: 5| Step: 5
Training loss: 3.1573197841644287
Validation loss: 2.4375298125769502

Epoch: 5| Step: 6
Training loss: 3.0017106533050537
Validation loss: 2.4470493626850907

Epoch: 5| Step: 7
Training loss: 2.8205666542053223
Validation loss: 2.4479358760259484

Epoch: 5| Step: 8
Training loss: 3.1767537593841553
Validation loss: 2.4487228931919223

Epoch: 5| Step: 9
Training loss: 2.6265714168548584
Validation loss: 2.4516008464238976

Epoch: 5| Step: 10
Training loss: 2.9755046367645264
Validation loss: 2.4268056782343055

Epoch: 38| Step: 0
Training loss: 2.235473871231079
Validation loss: 2.4145675013142247

Epoch: 5| Step: 1
Training loss: 2.7767727375030518
Validation loss: 2.4118546375664334

Epoch: 5| Step: 2
Training loss: 3.1151528358459473
Validation loss: 2.4073442746234197

Epoch: 5| Step: 3
Training loss: 2.664177417755127
Validation loss: 2.411093547780027

Epoch: 5| Step: 4
Training loss: 2.639932155609131
Validation loss: 2.4070565649258193

Epoch: 5| Step: 5
Training loss: 2.155543804168701
Validation loss: 2.4062507819103938

Epoch: 5| Step: 6
Training loss: 2.2596163749694824
Validation loss: 2.449890044427687

Epoch: 5| Step: 7
Training loss: 2.8745076656341553
Validation loss: 2.553367104581607

Epoch: 5| Step: 8
Training loss: 3.210411787033081
Validation loss: 2.5752954918851136

Epoch: 5| Step: 9
Training loss: 2.6684956550598145
Validation loss: 2.503026975098477

Epoch: 5| Step: 10
Training loss: 3.096303939819336
Validation loss: 2.4621548421921267

Epoch: 39| Step: 0
Training loss: 2.7215218544006348
Validation loss: 2.403886648916429

Epoch: 5| Step: 1
Training loss: 2.5580646991729736
Validation loss: 2.4256798169946157

Epoch: 5| Step: 2
Training loss: 2.314810037612915
Validation loss: 2.4696962846222745

Epoch: 5| Step: 3
Training loss: 2.9292850494384766
Validation loss: 2.539248981783467

Epoch: 5| Step: 4
Training loss: 3.0219192504882812
Validation loss: 2.481929027906028

Epoch: 5| Step: 5
Training loss: 3.249713182449341
Validation loss: 2.4567377054563133

Epoch: 5| Step: 6
Training loss: 2.263587236404419
Validation loss: 2.4246918129664596

Epoch: 5| Step: 7
Training loss: 3.0565733909606934
Validation loss: 2.4155176019155853

Epoch: 5| Step: 8
Training loss: 2.428891181945801
Validation loss: 2.4211650279260453

Epoch: 5| Step: 9
Training loss: 2.839962959289551
Validation loss: 2.4584019363567395

Epoch: 5| Step: 10
Training loss: 2.22556471824646
Validation loss: 2.5285161233717397

Epoch: 40| Step: 0
Training loss: 1.9543235301971436
Validation loss: 2.5439953932198147

Epoch: 5| Step: 1
Training loss: 3.318223237991333
Validation loss: 2.5237741265245663

Epoch: 5| Step: 2
Training loss: 2.582871198654175
Validation loss: 2.490697581280944

Epoch: 5| Step: 3
Training loss: 3.2669386863708496
Validation loss: 2.465406287101007

Epoch: 5| Step: 4
Training loss: 2.7364304065704346
Validation loss: 2.4366549368827575

Epoch: 5| Step: 5
Training loss: 2.9694085121154785
Validation loss: 2.42269048383159

Epoch: 5| Step: 6
Training loss: 2.750420093536377
Validation loss: 2.4193554232197423

Epoch: 5| Step: 7
Training loss: 2.5999741554260254
Validation loss: 2.4235239669840825

Epoch: 5| Step: 8
Training loss: 2.3083174228668213
Validation loss: 2.4297895636609805

Epoch: 5| Step: 9
Training loss: 2.4849822521209717
Validation loss: 2.4316164267960416

Epoch: 5| Step: 10
Training loss: 2.564523458480835
Validation loss: 2.4333090089982554

Epoch: 41| Step: 0
Training loss: 2.0082011222839355
Validation loss: 2.434482712899485

Epoch: 5| Step: 1
Training loss: 2.516298770904541
Validation loss: 2.426392416800222

Epoch: 5| Step: 2
Training loss: 2.876345634460449
Validation loss: 2.4203565428333897

Epoch: 5| Step: 3
Training loss: 2.8951029777526855
Validation loss: 2.422211056114525

Epoch: 5| Step: 4
Training loss: 1.686722993850708
Validation loss: 2.423402560654507

Epoch: 5| Step: 5
Training loss: 2.3784613609313965
Validation loss: 2.4341685284850416

Epoch: 5| Step: 6
Training loss: 3.240253448486328
Validation loss: 2.4401439979512203

Epoch: 5| Step: 7
Training loss: 2.7022414207458496
Validation loss: 2.4429120863637617

Epoch: 5| Step: 8
Training loss: 2.9693551063537598
Validation loss: 2.444552690752091

Epoch: 5| Step: 9
Training loss: 3.17900013923645
Validation loss: 2.442158611871863

Epoch: 5| Step: 10
Training loss: 2.9686119556427
Validation loss: 2.434326917894425

Epoch: 42| Step: 0
Training loss: 3.0621583461761475
Validation loss: 2.4160665440303024

Epoch: 5| Step: 1
Training loss: 2.3838610649108887
Validation loss: 2.4080610685451056

Epoch: 5| Step: 2
Training loss: 3.224557876586914
Validation loss: 2.403277620192497

Epoch: 5| Step: 3
Training loss: 2.395143508911133
Validation loss: 2.3952989526974258

Epoch: 5| Step: 4
Training loss: 2.5204920768737793
Validation loss: 2.38760692586181

Epoch: 5| Step: 5
Training loss: 2.3602893352508545
Validation loss: 2.383681689539263

Epoch: 5| Step: 6
Training loss: 2.6786160469055176
Validation loss: 2.3866961463805167

Epoch: 5| Step: 7
Training loss: 3.0640666484832764
Validation loss: 2.387692815514021

Epoch: 5| Step: 8
Training loss: 2.4154181480407715
Validation loss: 2.3909896266075874

Epoch: 5| Step: 9
Training loss: 2.540653944015503
Validation loss: 2.390473719566099

Epoch: 5| Step: 10
Training loss: 2.4363372325897217
Validation loss: 2.3991945840979136

Epoch: 43| Step: 0
Training loss: 2.636974334716797
Validation loss: 2.4011731275948147

Epoch: 5| Step: 1
Training loss: 2.641521692276001
Validation loss: 2.4020350953584075

Epoch: 5| Step: 2
Training loss: 2.9547905921936035
Validation loss: 2.4002338635024203

Epoch: 5| Step: 3
Training loss: 2.521742820739746
Validation loss: 2.401201637842322

Epoch: 5| Step: 4
Training loss: 2.326368808746338
Validation loss: 2.4078709028100453

Epoch: 5| Step: 5
Training loss: 2.719677448272705
Validation loss: 2.3992134153202014

Epoch: 5| Step: 6
Training loss: 2.3761603832244873
Validation loss: 2.3926801758427776

Epoch: 5| Step: 7
Training loss: 2.4650914669036865
Validation loss: 2.386961216567665

Epoch: 5| Step: 8
Training loss: 2.598499059677124
Validation loss: 2.390283046230193

Epoch: 5| Step: 9
Training loss: 3.1388957500457764
Validation loss: 2.387156737748013

Epoch: 5| Step: 10
Training loss: 2.694634199142456
Validation loss: 2.3899884121392363

Epoch: 44| Step: 0
Training loss: 2.708125591278076
Validation loss: 2.388780291362475

Epoch: 5| Step: 1
Training loss: 2.6804141998291016
Validation loss: 2.380797952734014

Epoch: 5| Step: 2
Training loss: 2.3493993282318115
Validation loss: 2.378972343219224

Epoch: 5| Step: 3
Training loss: 2.26417875289917
Validation loss: 2.3723153503992225

Epoch: 5| Step: 4
Training loss: 3.4145026206970215
Validation loss: 2.369535676894649

Epoch: 5| Step: 5
Training loss: 2.595412492752075
Validation loss: 2.367686910013999

Epoch: 5| Step: 6
Training loss: 3.3568854331970215
Validation loss: 2.3715834361250683

Epoch: 5| Step: 7
Training loss: 2.45349383354187
Validation loss: 2.3706527833015687

Epoch: 5| Step: 8
Training loss: 2.2478091716766357
Validation loss: 2.365564469368227

Epoch: 5| Step: 9
Training loss: 2.504568099975586
Validation loss: 2.3675730036151026

Epoch: 5| Step: 10
Training loss: 2.341541290283203
Validation loss: 2.370999523388442

Epoch: 45| Step: 0
Training loss: 2.501020669937134
Validation loss: 2.376360212602923

Epoch: 5| Step: 1
Training loss: 1.9389104843139648
Validation loss: 2.3832397512210313

Epoch: 5| Step: 2
Training loss: 3.094694137573242
Validation loss: 2.395338084108086

Epoch: 5| Step: 3
Training loss: 2.5005905628204346
Validation loss: 2.4086113642620783

Epoch: 5| Step: 4
Training loss: 2.5585639476776123
Validation loss: 2.4289957797655495

Epoch: 5| Step: 5
Training loss: 2.9561846256256104
Validation loss: 2.457818397911646

Epoch: 5| Step: 6
Training loss: 3.3579819202423096
Validation loss: 2.4425670664797545

Epoch: 5| Step: 7
Training loss: 2.7296695709228516
Validation loss: 2.415042584942233

Epoch: 5| Step: 8
Training loss: 2.765270709991455
Validation loss: 2.3965159436707855

Epoch: 5| Step: 9
Training loss: 2.3616573810577393
Validation loss: 2.3920105477815032

Epoch: 5| Step: 10
Training loss: 2.130390167236328
Validation loss: 2.384510806811753

Epoch: 46| Step: 0
Training loss: 2.8158230781555176
Validation loss: 2.395490277198053

Epoch: 5| Step: 1
Training loss: 2.7030487060546875
Validation loss: 2.3864034196381927

Epoch: 5| Step: 2
Training loss: 2.952183961868286
Validation loss: 2.3848892437514437

Epoch: 5| Step: 3
Training loss: 2.9488327503204346
Validation loss: 2.3620709655105427

Epoch: 5| Step: 4
Training loss: 2.1119742393493652
Validation loss: 2.3690432656195854

Epoch: 5| Step: 5
Training loss: 2.8433682918548584
Validation loss: 2.387377920971122

Epoch: 5| Step: 6
Training loss: 2.399893045425415
Validation loss: 2.408924792402534

Epoch: 5| Step: 7
Training loss: 2.746680736541748
Validation loss: 2.3916389954987394

Epoch: 5| Step: 8
Training loss: 2.362140655517578
Validation loss: 2.3752126488634335

Epoch: 5| Step: 9
Training loss: 2.7902610301971436
Validation loss: 2.3696346334231797

Epoch: 5| Step: 10
Training loss: 2.3432583808898926
Validation loss: 2.3620798203252975

Epoch: 47| Step: 0
Training loss: 2.626500368118286
Validation loss: 2.3550471208428823

Epoch: 5| Step: 1
Training loss: 2.496708631515503
Validation loss: 2.362232792762018

Epoch: 5| Step: 2
Training loss: 2.631909132003784
Validation loss: 2.3636957214724634

Epoch: 5| Step: 3
Training loss: 2.472899913787842
Validation loss: 2.360119814513832

Epoch: 5| Step: 4
Training loss: 2.590420961380005
Validation loss: 2.362649381801646

Epoch: 5| Step: 5
Training loss: 3.1083130836486816
Validation loss: 2.370507668423396

Epoch: 5| Step: 6
Training loss: 2.3529486656188965
Validation loss: 2.3588269397776616

Epoch: 5| Step: 7
Training loss: 2.91499662399292
Validation loss: 2.360088999553393

Epoch: 5| Step: 8
Training loss: 2.715259313583374
Validation loss: 2.360032002131144

Epoch: 5| Step: 9
Training loss: 2.1348776817321777
Validation loss: 2.3676677160365607

Epoch: 5| Step: 10
Training loss: 2.8441295623779297
Validation loss: 2.35826712782665

Epoch: 48| Step: 0
Training loss: 2.7980284690856934
Validation loss: 2.3536646161028134

Epoch: 5| Step: 1
Training loss: 2.6089954376220703
Validation loss: 2.350774311250256

Epoch: 5| Step: 2
Training loss: 2.7476272583007812
Validation loss: 2.347978884173978

Epoch: 5| Step: 3
Training loss: 2.184887409210205
Validation loss: 2.3384185350069435

Epoch: 5| Step: 4
Training loss: 2.2768547534942627
Validation loss: 2.339049054730323

Epoch: 5| Step: 5
Training loss: 2.11976957321167
Validation loss: 2.3430090770926526

Epoch: 5| Step: 6
Training loss: 2.9177703857421875
Validation loss: 2.3486140517778296

Epoch: 5| Step: 7
Training loss: 3.1844985485076904
Validation loss: 2.347901021280596

Epoch: 5| Step: 8
Training loss: 3.2293155193328857
Validation loss: 2.355694358066846

Epoch: 5| Step: 9
Training loss: 2.1144683361053467
Validation loss: 2.3536192294090026

Epoch: 5| Step: 10
Training loss: 2.603243827819824
Validation loss: 2.3451915889657955

Epoch: 49| Step: 0
Training loss: 2.9629154205322266
Validation loss: 2.3455857487135034

Epoch: 5| Step: 1
Training loss: 2.4554076194763184
Validation loss: 2.342644663267238

Epoch: 5| Step: 2
Training loss: 2.253127098083496
Validation loss: 2.3407009788738784

Epoch: 5| Step: 3
Training loss: 2.1306519508361816
Validation loss: 2.34251562241585

Epoch: 5| Step: 4
Training loss: 2.8063628673553467
Validation loss: 2.3421992781341716

Epoch: 5| Step: 5
Training loss: 3.0048489570617676
Validation loss: 2.343546357206119

Epoch: 5| Step: 6
Training loss: 2.6599903106689453
Validation loss: 2.339604131637081

Epoch: 5| Step: 7
Training loss: 2.979917049407959
Validation loss: 2.338991944507886

Epoch: 5| Step: 8
Training loss: 2.152439832687378
Validation loss: 2.335025877080938

Epoch: 5| Step: 9
Training loss: 2.876779556274414
Validation loss: 2.334087300044234

Epoch: 5| Step: 10
Training loss: 2.3015451431274414
Validation loss: 2.3435102303822837

Epoch: 50| Step: 0
Training loss: 2.912635087966919
Validation loss: 2.3468344570488058

Epoch: 5| Step: 1
Training loss: 1.8738362789154053
Validation loss: 2.35769897378901

Epoch: 5| Step: 2
Training loss: 3.365502119064331
Validation loss: 2.3938830693562827

Epoch: 5| Step: 3
Training loss: 2.0161449909210205
Validation loss: 2.41687225526379

Epoch: 5| Step: 4
Training loss: 2.633915424346924
Validation loss: 2.4361989831411712

Epoch: 5| Step: 5
Training loss: 2.5519440174102783
Validation loss: 2.4464818957031413

Epoch: 5| Step: 6
Training loss: 2.9590609073638916
Validation loss: 2.4090602269736667

Epoch: 5| Step: 7
Training loss: 2.3306779861450195
Validation loss: 2.3736119142142673

Epoch: 5| Step: 8
Training loss: 3.3784897327423096
Validation loss: 2.3496269769566034

Epoch: 5| Step: 9
Training loss: 2.277641773223877
Validation loss: 2.333916466723206

Epoch: 5| Step: 10
Training loss: 2.5638108253479004
Validation loss: 2.3576762842875656

Epoch: 51| Step: 0
Training loss: 2.6554675102233887
Validation loss: 2.386248896198888

Epoch: 5| Step: 1
Training loss: 2.6596899032592773
Validation loss: 2.3552230250450874

Epoch: 5| Step: 2
Training loss: 1.9765136241912842
Validation loss: 2.3375775583328737

Epoch: 5| Step: 3
Training loss: 2.3150570392608643
Validation loss: 2.331742916055905

Epoch: 5| Step: 4
Training loss: 3.0781984329223633
Validation loss: 2.335603424297866

Epoch: 5| Step: 5
Training loss: 1.9428446292877197
Validation loss: 2.3271684159514723

Epoch: 5| Step: 6
Training loss: 2.3431975841522217
Validation loss: 2.333022309887794

Epoch: 5| Step: 7
Training loss: 2.90946626663208
Validation loss: 2.347023816518886

Epoch: 5| Step: 8
Training loss: 2.809793710708618
Validation loss: 2.3469414595634706

Epoch: 5| Step: 9
Training loss: 3.296701431274414
Validation loss: 2.3457996165880592

Epoch: 5| Step: 10
Training loss: 2.6362574100494385
Validation loss: 2.346833073964683

Epoch: 52| Step: 0
Training loss: 2.6068644523620605
Validation loss: 2.337656274918587

Epoch: 5| Step: 1
Training loss: 1.9846837520599365
Validation loss: 2.334203048418927

Epoch: 5| Step: 2
Training loss: 2.163520336151123
Validation loss: 2.325400206350511

Epoch: 5| Step: 3
Training loss: 2.598151206970215
Validation loss: 2.3244398934866792

Epoch: 5| Step: 4
Training loss: 2.436397075653076
Validation loss: 2.324980763978856

Epoch: 5| Step: 5
Training loss: 3.290553569793701
Validation loss: 2.3292721086932766

Epoch: 5| Step: 6
Training loss: 2.9320077896118164
Validation loss: 2.3281845123537126

Epoch: 5| Step: 7
Training loss: 2.6261167526245117
Validation loss: 2.32802148531842

Epoch: 5| Step: 8
Training loss: 2.7854669094085693
Validation loss: 2.3249733601847002

Epoch: 5| Step: 9
Training loss: 2.570767879486084
Validation loss: 2.324350321164695

Epoch: 5| Step: 10
Training loss: 2.450303554534912
Validation loss: 2.317054587025796

Epoch: 53| Step: 0
Training loss: 2.2976341247558594
Validation loss: 2.314604587452386

Epoch: 5| Step: 1
Training loss: 2.549595832824707
Validation loss: 2.3167671900923534

Epoch: 5| Step: 2
Training loss: 2.612454652786255
Validation loss: 2.311366045346824

Epoch: 5| Step: 3
Training loss: 1.655016541481018
Validation loss: 2.3006619099647767

Epoch: 5| Step: 4
Training loss: 2.571336030960083
Validation loss: 2.303365445906116

Epoch: 5| Step: 5
Training loss: 2.8421523571014404
Validation loss: 2.306423919175261

Epoch: 5| Step: 6
Training loss: 2.4623520374298096
Validation loss: 2.306275043436276

Epoch: 5| Step: 7
Training loss: 2.4379889965057373
Validation loss: 2.311657198013798

Epoch: 5| Step: 8
Training loss: 2.9993093013763428
Validation loss: 2.318774466873497

Epoch: 5| Step: 9
Training loss: 3.5860068798065186
Validation loss: 2.32948051985874

Epoch: 5| Step: 10
Training loss: 2.377722978591919
Validation loss: 2.3261965320956324

Epoch: 54| Step: 0
Training loss: 2.4965453147888184
Validation loss: 2.3295908794608167

Epoch: 5| Step: 1
Training loss: 3.067007064819336
Validation loss: 2.3296716392681165

Epoch: 5| Step: 2
Training loss: 1.8861478567123413
Validation loss: 2.3225712442910798

Epoch: 5| Step: 3
Training loss: 3.081388473510742
Validation loss: 2.3311375648744646

Epoch: 5| Step: 4
Training loss: 2.982787609100342
Validation loss: 2.326355008668797

Epoch: 5| Step: 5
Training loss: 2.1158597469329834
Validation loss: 2.323010411313785

Epoch: 5| Step: 6
Training loss: 2.89016056060791
Validation loss: 2.325644367484636

Epoch: 5| Step: 7
Training loss: 2.639646053314209
Validation loss: 2.3414309332447667

Epoch: 5| Step: 8
Training loss: 2.1689021587371826
Validation loss: 2.327033245435325

Epoch: 5| Step: 9
Training loss: 2.437669038772583
Validation loss: 2.3243849726133448

Epoch: 5| Step: 10
Training loss: 2.5604639053344727
Validation loss: 2.308711879996843

Epoch: 55| Step: 0
Training loss: 2.338656187057495
Validation loss: 2.3039681219285533

Epoch: 5| Step: 1
Training loss: 2.7796733379364014
Validation loss: 2.302368599881408

Epoch: 5| Step: 2
Training loss: 2.0689902305603027
Validation loss: 2.300140796169158

Epoch: 5| Step: 3
Training loss: 2.582623243331909
Validation loss: 2.3034105352176133

Epoch: 5| Step: 4
Training loss: 2.7502851486206055
Validation loss: 2.302166356835314

Epoch: 5| Step: 5
Training loss: 2.8012022972106934
Validation loss: 2.3224559573717016

Epoch: 5| Step: 6
Training loss: 2.1114134788513184
Validation loss: 2.342499840644098

Epoch: 5| Step: 7
Training loss: 2.63856840133667
Validation loss: 2.372552999886133

Epoch: 5| Step: 8
Training loss: 2.6045639514923096
Validation loss: 2.372010415600192

Epoch: 5| Step: 9
Training loss: 2.894103527069092
Validation loss: 2.3661666224079747

Epoch: 5| Step: 10
Training loss: 2.9275920391082764
Validation loss: 2.3603033096559587

Epoch: 56| Step: 0
Training loss: 2.6104931831359863
Validation loss: 2.336423712392007

Epoch: 5| Step: 1
Training loss: 2.313844680786133
Validation loss: 2.3279948260194514

Epoch: 5| Step: 2
Training loss: 2.4966044425964355
Validation loss: 2.3103509180007444

Epoch: 5| Step: 3
Training loss: 2.5909171104431152
Validation loss: 2.3133563354451168

Epoch: 5| Step: 4
Training loss: 1.9946969747543335
Validation loss: 2.3021263640414

Epoch: 5| Step: 5
Training loss: 2.947329521179199
Validation loss: 2.3029537277836956

Epoch: 5| Step: 6
Training loss: 3.2472100257873535
Validation loss: 2.3046674318211053

Epoch: 5| Step: 7
Training loss: 2.458325147628784
Validation loss: 2.3057716251701437

Epoch: 5| Step: 8
Training loss: 1.941002607345581
Validation loss: 2.2978535441942114

Epoch: 5| Step: 9
Training loss: 2.3268985748291016
Validation loss: 2.2867205232702275

Epoch: 5| Step: 10
Training loss: 3.4480526447296143
Validation loss: 2.2873637035328853

Epoch: 57| Step: 0
Training loss: 2.5831711292266846
Validation loss: 2.278022789186047

Epoch: 5| Step: 1
Training loss: 2.252014636993408
Validation loss: 2.2803422404873754

Epoch: 5| Step: 2
Training loss: 2.14129638671875
Validation loss: 2.276036177912066

Epoch: 5| Step: 3
Training loss: 2.606340169906616
Validation loss: 2.2742658661257837

Epoch: 5| Step: 4
Training loss: 2.8586373329162598
Validation loss: 2.2771118994682067

Epoch: 5| Step: 5
Training loss: 2.2066311836242676
Validation loss: 2.2711072044987834

Epoch: 5| Step: 6
Training loss: 3.207416534423828
Validation loss: 2.279709285305392

Epoch: 5| Step: 7
Training loss: 2.146947145462036
Validation loss: 2.291804761014959

Epoch: 5| Step: 8
Training loss: 2.803452730178833
Validation loss: 2.315289899867068

Epoch: 5| Step: 9
Training loss: 2.7092978954315186
Validation loss: 2.338867961719472

Epoch: 5| Step: 10
Training loss: 2.790520668029785
Validation loss: 2.361515760421753

Epoch: 58| Step: 0
Training loss: 2.821753978729248
Validation loss: 2.34869961584768

Epoch: 5| Step: 1
Training loss: 2.7886252403259277
Validation loss: 2.3455954264569026

Epoch: 5| Step: 2
Training loss: 2.3955445289611816
Validation loss: 2.309410447715431

Epoch: 5| Step: 3
Training loss: 2.2763750553131104
Validation loss: 2.2966526528840423

Epoch: 5| Step: 4
Training loss: 2.3105416297912598
Validation loss: 2.2880501285676034

Epoch: 5| Step: 5
Training loss: 2.569877862930298
Validation loss: 2.2962894670424925

Epoch: 5| Step: 6
Training loss: 2.3543949127197266
Validation loss: 2.287822038896622

Epoch: 5| Step: 7
Training loss: 3.0216920375823975
Validation loss: 2.292212957976967

Epoch: 5| Step: 8
Training loss: 3.0030927658081055
Validation loss: 2.286890237562118

Epoch: 5| Step: 9
Training loss: 2.7127346992492676
Validation loss: 2.289833909721785

Epoch: 5| Step: 10
Training loss: 1.8663263320922852
Validation loss: 2.2893740079736196

Epoch: 59| Step: 0
Training loss: 1.4844505786895752
Validation loss: 2.294851879919729

Epoch: 5| Step: 1
Training loss: 2.7515499591827393
Validation loss: 2.296608906920238

Epoch: 5| Step: 2
Training loss: 2.6515374183654785
Validation loss: 2.2917226796509116

Epoch: 5| Step: 3
Training loss: 2.4219861030578613
Validation loss: 2.2970922480347338

Epoch: 5| Step: 4
Training loss: 2.2841334342956543
Validation loss: 2.308028046802808

Epoch: 5| Step: 5
Training loss: 2.6930909156799316
Validation loss: 2.305559168579758

Epoch: 5| Step: 6
Training loss: 3.0002219676971436
Validation loss: 2.3239211241404214

Epoch: 5| Step: 7
Training loss: 1.984018325805664
Validation loss: 2.339233693256173

Epoch: 5| Step: 8
Training loss: 3.1906681060791016
Validation loss: 2.3711633605341755

Epoch: 5| Step: 9
Training loss: 2.4840524196624756
Validation loss: 2.383797502004972

Epoch: 5| Step: 10
Training loss: 3.4371256828308105
Validation loss: 2.3872899932246052

Epoch: 60| Step: 0
Training loss: 2.5422682762145996
Validation loss: 2.384189660831164

Epoch: 5| Step: 1
Training loss: 2.9590890407562256
Validation loss: 2.3805609057026524

Epoch: 5| Step: 2
Training loss: 2.8336305618286133
Validation loss: 2.335798381477274

Epoch: 5| Step: 3
Training loss: 1.9230802059173584
Validation loss: 2.3097699637054117

Epoch: 5| Step: 4
Training loss: 1.7848031520843506
Validation loss: 2.2969338637526318

Epoch: 5| Step: 5
Training loss: 2.7449307441711426
Validation loss: 2.2897222221538587

Epoch: 5| Step: 6
Training loss: 2.9451162815093994
Validation loss: 2.2788917403067313

Epoch: 5| Step: 7
Training loss: 2.6688003540039062
Validation loss: 2.279139123937135

Epoch: 5| Step: 8
Training loss: 2.7245891094207764
Validation loss: 2.27184493823718

Epoch: 5| Step: 9
Training loss: 2.1689348220825195
Validation loss: 2.267999661866055

Epoch: 5| Step: 10
Training loss: 2.863004684448242
Validation loss: 2.264888435281733

Epoch: 61| Step: 0
Training loss: 2.3160791397094727
Validation loss: 2.259457093413158

Epoch: 5| Step: 1
Training loss: 2.524277925491333
Validation loss: 2.2639274135712655

Epoch: 5| Step: 2
Training loss: 2.5032269954681396
Validation loss: 2.267850334926318

Epoch: 5| Step: 3
Training loss: 2.5696380138397217
Validation loss: 2.2703526532778175

Epoch: 5| Step: 4
Training loss: 2.7043023109436035
Validation loss: 2.2723264719850276

Epoch: 5| Step: 5
Training loss: 2.5532960891723633
Validation loss: 2.2713690470623713

Epoch: 5| Step: 6
Training loss: 2.9630990028381348
Validation loss: 2.2812557464004843

Epoch: 5| Step: 7
Training loss: 2.6558048725128174
Validation loss: 2.3016059014105026

Epoch: 5| Step: 8
Training loss: 2.5505146980285645
Validation loss: 2.3086738842789845

Epoch: 5| Step: 9
Training loss: 2.2777931690216064
Validation loss: 2.314592674214353

Epoch: 5| Step: 10
Training loss: 2.5064921379089355
Validation loss: 2.3277028427329114

Epoch: 62| Step: 0
Training loss: 2.9249215126037598
Validation loss: 2.3274122181759087

Epoch: 5| Step: 1
Training loss: 2.2799766063690186
Validation loss: 2.3058814028257966

Epoch: 5| Step: 2
Training loss: 1.9178078174591064
Validation loss: 2.293834714479344

Epoch: 5| Step: 3
Training loss: 2.489816188812256
Validation loss: 2.2851068717177196

Epoch: 5| Step: 4
Training loss: 2.5989174842834473
Validation loss: 2.280538587160008

Epoch: 5| Step: 5
Training loss: 2.773134231567383
Validation loss: 2.2734656385196153

Epoch: 5| Step: 6
Training loss: 2.933946132659912
Validation loss: 2.2651290457735778

Epoch: 5| Step: 7
Training loss: 2.6108906269073486
Validation loss: 2.2640286978854927

Epoch: 5| Step: 8
Training loss: 2.6274514198303223
Validation loss: 2.2608468083925146

Epoch: 5| Step: 9
Training loss: 2.547489881515503
Validation loss: 2.2600812501804803

Epoch: 5| Step: 10
Training loss: 2.3144567012786865
Validation loss: 2.2645621889381

Epoch: 63| Step: 0
Training loss: 2.455501079559326
Validation loss: 2.268124185582643

Epoch: 5| Step: 1
Training loss: 2.418154001235962
Validation loss: 2.2730693073682886

Epoch: 5| Step: 2
Training loss: 2.5425686836242676
Validation loss: 2.273779446078885

Epoch: 5| Step: 3
Training loss: 2.1125340461730957
Validation loss: 2.2742564703828547

Epoch: 5| Step: 4
Training loss: 2.699288845062256
Validation loss: 2.2760307814485286

Epoch: 5| Step: 5
Training loss: 2.555453300476074
Validation loss: 2.278489153872254

Epoch: 5| Step: 6
Training loss: 2.3946433067321777
Validation loss: 2.2822460384779077

Epoch: 5| Step: 7
Training loss: 2.7924256324768066
Validation loss: 2.2748563994643507

Epoch: 5| Step: 8
Training loss: 2.6311097145080566
Validation loss: 2.2701545966568815

Epoch: 5| Step: 9
Training loss: 3.1668124198913574
Validation loss: 2.2657901356297154

Epoch: 5| Step: 10
Training loss: 2.1211538314819336
Validation loss: 2.265438190070532

Epoch: 64| Step: 0
Training loss: 2.475170373916626
Validation loss: 2.265879995079451

Epoch: 5| Step: 1
Training loss: 3.3731045722961426
Validation loss: 2.26392242985387

Epoch: 5| Step: 2
Training loss: 2.2736926078796387
Validation loss: 2.26134668883457

Epoch: 5| Step: 3
Training loss: 2.8216960430145264
Validation loss: 2.261497128394342

Epoch: 5| Step: 4
Training loss: 2.583247661590576
Validation loss: 2.258795584401777

Epoch: 5| Step: 5
Training loss: 1.8878490924835205
Validation loss: 2.2614983230508785

Epoch: 5| Step: 6
Training loss: 2.6382193565368652
Validation loss: 2.2644235575070946

Epoch: 5| Step: 7
Training loss: 2.4126861095428467
Validation loss: 2.256943056660314

Epoch: 5| Step: 8
Training loss: 2.1067309379577637
Validation loss: 2.2646932345564648

Epoch: 5| Step: 9
Training loss: 2.5906264781951904
Validation loss: 2.2782837293481313

Epoch: 5| Step: 10
Training loss: 2.8850317001342773
Validation loss: 2.277598868134201

Epoch: 65| Step: 0
Training loss: 2.6697661876678467
Validation loss: 2.292215898472776

Epoch: 5| Step: 1
Training loss: 1.8338762521743774
Validation loss: 2.2959876316849903

Epoch: 5| Step: 2
Training loss: 2.9133267402648926
Validation loss: 2.3095549486016713

Epoch: 5| Step: 3
Training loss: 2.2187094688415527
Validation loss: 2.3066211336402485

Epoch: 5| Step: 4
Training loss: 3.1920714378356934
Validation loss: 2.291017340075585

Epoch: 5| Step: 5
Training loss: 2.399466037750244
Validation loss: 2.271415577139906

Epoch: 5| Step: 6
Training loss: 2.688023090362549
Validation loss: 2.262654235286097

Epoch: 5| Step: 7
Training loss: 2.1799514293670654
Validation loss: 2.261049347539102

Epoch: 5| Step: 8
Training loss: 2.5479369163513184
Validation loss: 2.2514283093073035

Epoch: 5| Step: 9
Training loss: 3.030534029006958
Validation loss: 2.25152575841514

Epoch: 5| Step: 10
Training loss: 2.220421075820923
Validation loss: 2.2600278649278867

Epoch: 66| Step: 0
Training loss: 2.449497938156128
Validation loss: 2.2606325764809885

Epoch: 5| Step: 1
Training loss: 2.4153568744659424
Validation loss: 2.2540324208556966

Epoch: 5| Step: 2
Training loss: 2.487220287322998
Validation loss: 2.264334269749221

Epoch: 5| Step: 3
Training loss: 2.330007553100586
Validation loss: 2.251226279043382

Epoch: 5| Step: 4
Training loss: 3.1694295406341553
Validation loss: 2.263175977173672

Epoch: 5| Step: 5
Training loss: 2.3414435386657715
Validation loss: 2.275560721274345

Epoch: 5| Step: 6
Training loss: 2.8498222827911377
Validation loss: 2.2807761879377466

Epoch: 5| Step: 7
Training loss: 2.5215511322021484
Validation loss: 2.282924900772751

Epoch: 5| Step: 8
Training loss: 2.721522808074951
Validation loss: 2.2745305030576644

Epoch: 5| Step: 9
Training loss: 1.703960657119751
Validation loss: 2.268557861287107

Epoch: 5| Step: 10
Training loss: 2.984222173690796
Validation loss: 2.2537215166194464

Epoch: 67| Step: 0
Training loss: 2.357004404067993
Validation loss: 2.238770633615473

Epoch: 5| Step: 1
Training loss: 2.241532802581787
Validation loss: 2.2413479564010457

Epoch: 5| Step: 2
Training loss: 2.239467144012451
Validation loss: 2.2455901817608903

Epoch: 5| Step: 3
Training loss: 2.47989821434021
Validation loss: 2.2391638243070213

Epoch: 5| Step: 4
Training loss: 2.9928297996520996
Validation loss: 2.2380902844090618

Epoch: 5| Step: 5
Training loss: 2.779042959213257
Validation loss: 2.2357855714777464

Epoch: 5| Step: 6
Training loss: 2.581820011138916
Validation loss: 2.2420497145704044

Epoch: 5| Step: 7
Training loss: 2.45648193359375
Validation loss: 2.254940099613641

Epoch: 5| Step: 8
Training loss: 2.5234527587890625
Validation loss: 2.2709930507085656

Epoch: 5| Step: 9
Training loss: 2.182277202606201
Validation loss: 2.2960494538789153

Epoch: 5| Step: 10
Training loss: 3.110215663909912
Validation loss: 2.320998584070513

Epoch: 68| Step: 0
Training loss: 1.9008369445800781
Validation loss: 2.3404868879625873

Epoch: 5| Step: 1
Training loss: 3.140915632247925
Validation loss: 2.3310780909753617

Epoch: 5| Step: 2
Training loss: 1.4298192262649536
Validation loss: 2.30496798792193

Epoch: 5| Step: 3
Training loss: 3.2809150218963623
Validation loss: 2.284243537533668

Epoch: 5| Step: 4
Training loss: 2.602980375289917
Validation loss: 2.254614012215727

Epoch: 5| Step: 5
Training loss: 3.0222878456115723
Validation loss: 2.246059451051938

Epoch: 5| Step: 6
Training loss: 2.591733932495117
Validation loss: 2.2692575531621135

Epoch: 5| Step: 7
Training loss: 2.2218456268310547
Validation loss: 2.2698315997277536

Epoch: 5| Step: 8
Training loss: 2.758098840713501
Validation loss: 2.2450050948768534

Epoch: 5| Step: 9
Training loss: 2.5372090339660645
Validation loss: 2.2356477270844164

Epoch: 5| Step: 10
Training loss: 2.5611765384674072
Validation loss: 2.2341864262857745

Epoch: 69| Step: 0
Training loss: 3.243875503540039
Validation loss: 2.2432562228172057

Epoch: 5| Step: 1
Training loss: 2.0216784477233887
Validation loss: 2.251360527930721

Epoch: 5| Step: 2
Training loss: 2.0712735652923584
Validation loss: 2.2789247317980696

Epoch: 5| Step: 3
Training loss: 2.8602912425994873
Validation loss: 2.3065882934037076

Epoch: 5| Step: 4
Training loss: 2.504237651824951
Validation loss: 2.3156614457407305

Epoch: 5| Step: 5
Training loss: 3.1504905223846436
Validation loss: 2.315495955046787

Epoch: 5| Step: 6
Training loss: 2.378796100616455
Validation loss: 2.304176697167017

Epoch: 5| Step: 7
Training loss: 1.6458103656768799
Validation loss: 2.2926515994533414

Epoch: 5| Step: 8
Training loss: 2.3048744201660156
Validation loss: 2.288252351104572

Epoch: 5| Step: 9
Training loss: 2.9163525104522705
Validation loss: 2.274023582858424

Epoch: 5| Step: 10
Training loss: 2.8366901874542236
Validation loss: 2.2589429270836616

Epoch: 70| Step: 0
Training loss: 2.731208324432373
Validation loss: 2.2511077721913657

Epoch: 5| Step: 1
Training loss: 1.9604727029800415
Validation loss: 2.253028218464185

Epoch: 5| Step: 2
Training loss: 2.622741222381592
Validation loss: 2.2555655484558432

Epoch: 5| Step: 3
Training loss: 2.4775543212890625
Validation loss: 2.2568675087344263

Epoch: 5| Step: 4
Training loss: 2.6638054847717285
Validation loss: 2.2629434600953133

Epoch: 5| Step: 5
Training loss: 2.6166791915893555
Validation loss: 2.257669336052351

Epoch: 5| Step: 6
Training loss: 3.053490400314331
Validation loss: 2.266568406935661

Epoch: 5| Step: 7
Training loss: 2.024385452270508
Validation loss: 2.2601502505681847

Epoch: 5| Step: 8
Training loss: 2.5551013946533203
Validation loss: 2.2736271735160583

Epoch: 5| Step: 9
Training loss: 2.593851327896118
Validation loss: 2.2720795446826565

Epoch: 5| Step: 10
Training loss: 2.4974141120910645
Validation loss: 2.2843520846418155

Epoch: 71| Step: 0
Training loss: 2.345120429992676
Validation loss: 2.2644518677906325

Epoch: 5| Step: 1
Training loss: 2.928231716156006
Validation loss: 2.23566698515287

Epoch: 5| Step: 2
Training loss: 3.0739097595214844
Validation loss: 2.2219015090696272

Epoch: 5| Step: 3
Training loss: 2.0855021476745605
Validation loss: 2.2194239221593386

Epoch: 5| Step: 4
Training loss: 2.1134188175201416
Validation loss: 2.223737580801851

Epoch: 5| Step: 5
Training loss: 2.5149195194244385
Validation loss: 2.2213956796994774

Epoch: 5| Step: 6
Training loss: 1.9485441446304321
Validation loss: 2.22175028247218

Epoch: 5| Step: 7
Training loss: 2.829242467880249
Validation loss: 2.2181155553428074

Epoch: 5| Step: 8
Training loss: 3.2109527587890625
Validation loss: 2.227567522756515

Epoch: 5| Step: 9
Training loss: 2.0521907806396484
Validation loss: 2.2405249534114713

Epoch: 5| Step: 10
Training loss: 2.7721517086029053
Validation loss: 2.255751589293121

Epoch: 72| Step: 0
Training loss: 2.429534912109375
Validation loss: 2.2762364982276835

Epoch: 5| Step: 1
Training loss: 3.0470573902130127
Validation loss: 2.2790252982929187

Epoch: 5| Step: 2
Training loss: 2.384328603744507
Validation loss: 2.251102065527311

Epoch: 5| Step: 3
Training loss: 2.1468682289123535
Validation loss: 2.225210148801086

Epoch: 5| Step: 4
Training loss: 2.5163426399230957
Validation loss: 2.219163034551887

Epoch: 5| Step: 5
Training loss: 2.2893147468566895
Validation loss: 2.222348907942413

Epoch: 5| Step: 6
Training loss: 2.5796027183532715
Validation loss: 2.220467475152785

Epoch: 5| Step: 7
Training loss: 3.3744444847106934
Validation loss: 2.2210544424672283

Epoch: 5| Step: 8
Training loss: 2.029172420501709
Validation loss: 2.2211050961607244

Epoch: 5| Step: 9
Training loss: 2.1204020977020264
Validation loss: 2.2179901010246685

Epoch: 5| Step: 10
Training loss: 3.2909626960754395
Validation loss: 2.221724030792072

Epoch: 73| Step: 0
Training loss: 1.681093454360962
Validation loss: 2.227257295321393

Epoch: 5| Step: 1
Training loss: 2.3975329399108887
Validation loss: 2.2375220765349684

Epoch: 5| Step: 2
Training loss: 2.734902858734131
Validation loss: 2.2449927150562243

Epoch: 5| Step: 3
Training loss: 3.0252952575683594
Validation loss: 2.2450052153679634

Epoch: 5| Step: 4
Training loss: 2.542983293533325
Validation loss: 2.2513828123769453

Epoch: 5| Step: 5
Training loss: 2.599961757659912
Validation loss: 2.2565480509111957

Epoch: 5| Step: 6
Training loss: 2.557098865509033
Validation loss: 2.258612063623244

Epoch: 5| Step: 7
Training loss: 2.9538118839263916
Validation loss: 2.2531063402852705

Epoch: 5| Step: 8
Training loss: 2.6628339290618896
Validation loss: 2.2395695255648707

Epoch: 5| Step: 9
Training loss: 2.1677536964416504
Validation loss: 2.23344761325467

Epoch: 5| Step: 10
Training loss: 2.364006996154785
Validation loss: 2.2290879180354457

Epoch: 74| Step: 0
Training loss: 2.253755807876587
Validation loss: 2.2322291379333823

Epoch: 5| Step: 1
Training loss: 1.9959275722503662
Validation loss: 2.2330475622607815

Epoch: 5| Step: 2
Training loss: 2.6865391731262207
Validation loss: 2.2367210080546718

Epoch: 5| Step: 3
Training loss: 2.1819398403167725
Validation loss: 2.2412638587336384

Epoch: 5| Step: 4
Training loss: 2.080091953277588
Validation loss: 2.245110962980537

Epoch: 5| Step: 5
Training loss: 2.9969329833984375
Validation loss: 2.237335252505477

Epoch: 5| Step: 6
Training loss: 2.742614269256592
Validation loss: 2.236480647517789

Epoch: 5| Step: 7
Training loss: 2.0891942977905273
Validation loss: 2.240848995024158

Epoch: 5| Step: 8
Training loss: 3.0788536071777344
Validation loss: 2.2454756921337498

Epoch: 5| Step: 9
Training loss: 3.0082385540008545
Validation loss: 2.2563379964520855

Epoch: 5| Step: 10
Training loss: 2.545804977416992
Validation loss: 2.2529964805931173

Epoch: 75| Step: 0
Training loss: 2.064378023147583
Validation loss: 2.256759887100548

Epoch: 5| Step: 1
Training loss: 2.53120756149292
Validation loss: 2.2373093930623864

Epoch: 5| Step: 2
Training loss: 2.583122491836548
Validation loss: 2.2246150688458513

Epoch: 5| Step: 3
Training loss: 2.620856761932373
Validation loss: 2.214799181107552

Epoch: 5| Step: 4
Training loss: 2.4247703552246094
Validation loss: 2.207399848968752

Epoch: 5| Step: 5
Training loss: 2.112776279449463
Validation loss: 2.2065862814585366

Epoch: 5| Step: 6
Training loss: 2.3676769733428955
Validation loss: 2.2056215014508975

Epoch: 5| Step: 7
Training loss: 2.533717632293701
Validation loss: 2.2071574041920323

Epoch: 5| Step: 8
Training loss: 2.104743480682373
Validation loss: 2.2075722012468564

Epoch: 5| Step: 9
Training loss: 3.1086666584014893
Validation loss: 2.2132174430354947

Epoch: 5| Step: 10
Training loss: 3.4132003784179688
Validation loss: 2.2141149326037337

Testing loss: 2.455344001452128
