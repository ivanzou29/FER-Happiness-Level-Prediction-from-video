Epoch: 1| Step: 0
Training loss: 4.5733795166015625
Validation loss: 5.130389644253638

Epoch: 5| Step: 1
Training loss: 4.732638359069824
Validation loss: 5.125142333328083

Epoch: 5| Step: 2
Training loss: 5.228409290313721
Validation loss: 5.120290658807241

Epoch: 5| Step: 3
Training loss: 4.984059810638428
Validation loss: 5.115539837909001

Epoch: 5| Step: 4
Training loss: 4.7404890060424805
Validation loss: 5.11120581370528

Epoch: 5| Step: 5
Training loss: 5.574642181396484
Validation loss: 5.106698277176068

Epoch: 5| Step: 6
Training loss: 5.409628868103027
Validation loss: 5.1023633403162805

Epoch: 5| Step: 7
Training loss: 5.099206924438477
Validation loss: 5.098181637384558

Epoch: 5| Step: 8
Training loss: 4.517175674438477
Validation loss: 5.0934407223937335

Epoch: 5| Step: 9
Training loss: 3.955565929412842
Validation loss: 5.088729971198625

Epoch: 5| Step: 10
Training loss: 5.162172317504883
Validation loss: 5.084023783283849

Epoch: 2| Step: 0
Training loss: 4.187063694000244
Validation loss: 5.078984465650333

Epoch: 5| Step: 1
Training loss: 4.565517425537109
Validation loss: 5.073640284999724

Epoch: 5| Step: 2
Training loss: 4.011595726013184
Validation loss: 5.068540280865085

Epoch: 5| Step: 3
Training loss: 5.8834428787231445
Validation loss: 5.0628761988814155

Epoch: 5| Step: 4
Training loss: 5.02591609954834
Validation loss: 5.057007410193003

Epoch: 5| Step: 5
Training loss: 5.630830764770508
Validation loss: 5.05082651363906

Epoch: 5| Step: 6
Training loss: 5.723326683044434
Validation loss: 5.044631916989562

Epoch: 5| Step: 7
Training loss: 4.37477970123291
Validation loss: 5.0381932104787515

Epoch: 5| Step: 8
Training loss: 4.944544315338135
Validation loss: 5.031323991796022

Epoch: 5| Step: 9
Training loss: 4.102690696716309
Validation loss: 5.0243579597883326

Epoch: 5| Step: 10
Training loss: 4.864693641662598
Validation loss: 5.016315203841015

Epoch: 3| Step: 0
Training loss: 4.3054656982421875
Validation loss: 5.008536077314807

Epoch: 5| Step: 1
Training loss: 5.704423427581787
Validation loss: 5.000403896454842

Epoch: 5| Step: 2
Training loss: 4.641517639160156
Validation loss: 4.991903684472525

Epoch: 5| Step: 3
Training loss: 4.285808563232422
Validation loss: 4.982142268970448

Epoch: 5| Step: 4
Training loss: 4.832088470458984
Validation loss: 4.972844592986569

Epoch: 5| Step: 5
Training loss: 5.552834510803223
Validation loss: 4.963375245371172

Epoch: 5| Step: 6
Training loss: 5.236598491668701
Validation loss: 4.952503527364423

Epoch: 5| Step: 7
Training loss: 4.22141170501709
Validation loss: 4.9416871019589

Epoch: 5| Step: 8
Training loss: 4.373240947723389
Validation loss: 4.9305039375059065

Epoch: 5| Step: 9
Training loss: 4.88456916809082
Validation loss: 4.917738304343275

Epoch: 5| Step: 10
Training loss: 4.177309989929199
Validation loss: 4.90576994803644

Epoch: 4| Step: 0
Training loss: 4.51937198638916
Validation loss: 4.892506712226457

Epoch: 5| Step: 1
Training loss: 5.4244537353515625
Validation loss: 4.878321901444466

Epoch: 5| Step: 2
Training loss: 5.135433197021484
Validation loss: 4.864219762945688

Epoch: 5| Step: 3
Training loss: 4.372490882873535
Validation loss: 4.8489248521866335

Epoch: 5| Step: 4
Training loss: 4.951422691345215
Validation loss: 4.833541567607592

Epoch: 5| Step: 5
Training loss: 3.3248791694641113
Validation loss: 4.817111384484075

Epoch: 5| Step: 6
Training loss: 6.4406328201293945
Validation loss: 4.799564484627016

Epoch: 5| Step: 7
Training loss: 3.9469082355499268
Validation loss: 4.781937055690314

Epoch: 5| Step: 8
Training loss: 4.4299445152282715
Validation loss: 4.762859554700954

Epoch: 5| Step: 9
Training loss: 3.9498772621154785
Validation loss: 4.744857593249249

Epoch: 5| Step: 10
Training loss: 4.064083099365234
Validation loss: 4.725956439971924

Epoch: 5| Step: 0
Training loss: 5.328727722167969
Validation loss: 4.706278672782323

Epoch: 5| Step: 1
Training loss: 4.736297607421875
Validation loss: 4.685884665417415

Epoch: 5| Step: 2
Training loss: 3.934462070465088
Validation loss: 4.666671055619434

Epoch: 5| Step: 3
Training loss: 4.9942450523376465
Validation loss: 4.645563033319289

Epoch: 5| Step: 4
Training loss: 4.729183197021484
Validation loss: 4.624689635410104

Epoch: 5| Step: 5
Training loss: 3.9769821166992188
Validation loss: 4.601959115715437

Epoch: 5| Step: 6
Training loss: 3.50077748298645
Validation loss: 4.581022729155838

Epoch: 5| Step: 7
Training loss: 4.075370788574219
Validation loss: 4.559033883515225

Epoch: 5| Step: 8
Training loss: 5.015698432922363
Validation loss: 4.536941969266501

Epoch: 5| Step: 9
Training loss: 3.9613356590270996
Validation loss: 4.514796292910012

Epoch: 5| Step: 10
Training loss: 3.9604406356811523
Validation loss: 4.4940375769010155

Epoch: 6| Step: 0
Training loss: 5.0175395011901855
Validation loss: 4.472259916285033

Epoch: 5| Step: 1
Training loss: 5.401458740234375
Validation loss: 4.44855519007611

Epoch: 5| Step: 2
Training loss: 3.724658966064453
Validation loss: 4.426622231801351

Epoch: 5| Step: 3
Training loss: 3.5623252391815186
Validation loss: 4.407719424975816

Epoch: 5| Step: 4
Training loss: 4.415383338928223
Validation loss: 4.385941836141771

Epoch: 5| Step: 5
Training loss: 4.130131721496582
Validation loss: 4.367779216458721

Epoch: 5| Step: 6
Training loss: 4.360857963562012
Validation loss: 4.349112213298839

Epoch: 5| Step: 7
Training loss: 3.742136001586914
Validation loss: 4.330661389135545

Epoch: 5| Step: 8
Training loss: 3.27229380607605
Validation loss: 4.314115262800647

Epoch: 5| Step: 9
Training loss: 4.2548441886901855
Validation loss: 4.2959179416779545

Epoch: 5| Step: 10
Training loss: 3.9734060764312744
Validation loss: 4.2819975268456245

Epoch: 7| Step: 0
Training loss: 3.9930355548858643
Validation loss: 4.266460100809733

Epoch: 5| Step: 1
Training loss: 3.4866271018981934
Validation loss: 4.251104739404494

Epoch: 5| Step: 2
Training loss: 3.5788536071777344
Validation loss: 4.2367516409966255

Epoch: 5| Step: 3
Training loss: 5.2086405754089355
Validation loss: 4.222791969135243

Epoch: 5| Step: 4
Training loss: 4.0641679763793945
Validation loss: 4.209597900349607

Epoch: 5| Step: 5
Training loss: 4.333733558654785
Validation loss: 4.196966099482711

Epoch: 5| Step: 6
Training loss: 3.0266194343566895
Validation loss: 4.183186233684581

Epoch: 5| Step: 7
Training loss: 3.714975357055664
Validation loss: 4.172437132045787

Epoch: 5| Step: 8
Training loss: 3.7835822105407715
Validation loss: 4.160488851608768

Epoch: 5| Step: 9
Training loss: 4.533899307250977
Validation loss: 4.148708107650921

Epoch: 5| Step: 10
Training loss: 4.542932510375977
Validation loss: 4.137393379724154

Epoch: 8| Step: 0
Training loss: 3.9511542320251465
Validation loss: 4.125204342667774

Epoch: 5| Step: 1
Training loss: 4.289240837097168
Validation loss: 4.11473221932688

Epoch: 5| Step: 2
Training loss: 4.0900163650512695
Validation loss: 4.102920211771483

Epoch: 5| Step: 3
Training loss: 3.8459420204162598
Validation loss: 4.092647742199642

Epoch: 5| Step: 4
Training loss: 4.420140266418457
Validation loss: 4.08005323461307

Epoch: 5| Step: 5
Training loss: 4.271268844604492
Validation loss: 4.0687806375565065

Epoch: 5| Step: 6
Training loss: 4.1247663497924805
Validation loss: 4.057559603004045

Epoch: 5| Step: 7
Training loss: 2.7861485481262207
Validation loss: 4.046017582698535

Epoch: 5| Step: 8
Training loss: 4.479928016662598
Validation loss: 4.03531015047463

Epoch: 5| Step: 9
Training loss: 3.2054824829101562
Validation loss: 4.0232128635529545

Epoch: 5| Step: 10
Training loss: 3.4230966567993164
Validation loss: 4.013148615437169

Epoch: 9| Step: 0
Training loss: 3.3347363471984863
Validation loss: 4.00220097777664

Epoch: 5| Step: 1
Training loss: 4.380741119384766
Validation loss: 3.992026423895231

Epoch: 5| Step: 2
Training loss: 3.4550185203552246
Validation loss: 3.981062771171652

Epoch: 5| Step: 3
Training loss: 2.9589335918426514
Validation loss: 3.9695675911441928

Epoch: 5| Step: 4
Training loss: 4.104686737060547
Validation loss: 3.9605781852558093

Epoch: 5| Step: 5
Training loss: 3.906651020050049
Validation loss: 3.9479897816975913

Epoch: 5| Step: 6
Training loss: 3.786952257156372
Validation loss: 3.9370986056584183

Epoch: 5| Step: 7
Training loss: 4.164264678955078
Validation loss: 3.924406836109777

Epoch: 5| Step: 8
Training loss: 3.3565585613250732
Validation loss: 3.914570170064126

Epoch: 5| Step: 9
Training loss: 4.365074157714844
Validation loss: 3.904389673663724

Epoch: 5| Step: 10
Training loss: 4.068173885345459
Validation loss: 3.8932460354220484

Epoch: 10| Step: 0
Training loss: 2.7121524810791016
Validation loss: 3.884249020648259

Epoch: 5| Step: 1
Training loss: 4.488651752471924
Validation loss: 3.873015021765104

Epoch: 5| Step: 2
Training loss: 4.7073163986206055
Validation loss: 3.8634519602662776

Epoch: 5| Step: 3
Training loss: 4.689667701721191
Validation loss: 3.853442161313949

Epoch: 5| Step: 4
Training loss: 4.494192600250244
Validation loss: 3.8432408404606644

Epoch: 5| Step: 5
Training loss: 3.960479736328125
Validation loss: 3.8328317724248415

Epoch: 5| Step: 6
Training loss: 4.418549537658691
Validation loss: 3.8230459485002743

Epoch: 5| Step: 7
Training loss: 2.45082426071167
Validation loss: 3.812726313068021

Epoch: 5| Step: 8
Training loss: 3.437594175338745
Validation loss: 3.8041483151015414

Epoch: 5| Step: 9
Training loss: 2.157357692718506
Validation loss: 3.7952927081815657

Epoch: 5| Step: 10
Training loss: 3.2423815727233887
Validation loss: 3.7893836677715345

Epoch: 11| Step: 0
Training loss: 4.2998857498168945
Validation loss: 3.778684175142678

Epoch: 5| Step: 1
Training loss: 4.163638591766357
Validation loss: 3.76972851445598

Epoch: 5| Step: 2
Training loss: 2.674107074737549
Validation loss: 3.7609002154360534

Epoch: 5| Step: 3
Training loss: 3.882026195526123
Validation loss: 3.7541281946243776

Epoch: 5| Step: 4
Training loss: 3.3660640716552734
Validation loss: 3.743609530951387

Epoch: 5| Step: 5
Training loss: 4.165740013122559
Validation loss: 3.7362201752201205

Epoch: 5| Step: 6
Training loss: 3.2026190757751465
Validation loss: 3.72470183526316

Epoch: 5| Step: 7
Training loss: 3.3722431659698486
Validation loss: 3.7160443823824645

Epoch: 5| Step: 8
Training loss: 3.8105456829071045
Validation loss: 3.7043784613250406

Epoch: 5| Step: 9
Training loss: 3.703669786453247
Validation loss: 3.6955067060327016

Epoch: 5| Step: 10
Training loss: 3.188230276107788
Validation loss: 3.682624029856856

Epoch: 12| Step: 0
Training loss: 4.372649192810059
Validation loss: 3.6717792736586703

Epoch: 5| Step: 1
Training loss: 2.820369005203247
Validation loss: 3.6597632387632966

Epoch: 5| Step: 2
Training loss: 3.9022421836853027
Validation loss: 3.6495035515036633

Epoch: 5| Step: 3
Training loss: 3.764941453933716
Validation loss: 3.6402477448986423

Epoch: 5| Step: 4
Training loss: 4.702426910400391
Validation loss: 3.6306648382576565

Epoch: 5| Step: 5
Training loss: 2.8532395362854004
Validation loss: 3.6236019211430706

Epoch: 5| Step: 6
Training loss: 2.542633056640625
Validation loss: 3.616231185133739

Epoch: 5| Step: 7
Training loss: 3.070707321166992
Validation loss: 3.6056102014357045

Epoch: 5| Step: 8
Training loss: 2.8934438228607178
Validation loss: 3.5995413154684086

Epoch: 5| Step: 9
Training loss: 4.028842926025391
Validation loss: 3.5900757620411534

Epoch: 5| Step: 10
Training loss: 3.983694553375244
Validation loss: 3.5813171453373407

Epoch: 13| Step: 0
Training loss: 3.86686635017395
Validation loss: 3.574611635618312

Epoch: 5| Step: 1
Training loss: 4.41652774810791
Validation loss: 3.5663909271199215

Epoch: 5| Step: 2
Training loss: 2.9982006549835205
Validation loss: 3.559283479567497

Epoch: 5| Step: 3
Training loss: 3.2879233360290527
Validation loss: 3.551470971876575

Epoch: 5| Step: 4
Training loss: 3.500263214111328
Validation loss: 3.5470376783801663

Epoch: 5| Step: 5
Training loss: 2.611072063446045
Validation loss: 3.537126633428758

Epoch: 5| Step: 6
Training loss: 3.8976662158966064
Validation loss: 3.529457789595409

Epoch: 5| Step: 7
Training loss: 3.2097086906433105
Validation loss: 3.5195475291180354

Epoch: 5| Step: 8
Training loss: 3.7795581817626953
Validation loss: 3.516273590826219

Epoch: 5| Step: 9
Training loss: 3.6331253051757812
Validation loss: 3.5111744275657077

Epoch: 5| Step: 10
Training loss: 2.79974102973938
Validation loss: 3.5029364503839964

Epoch: 14| Step: 0
Training loss: 3.338545560836792
Validation loss: 3.4913500226953977

Epoch: 5| Step: 1
Training loss: 4.3072686195373535
Validation loss: 3.4826812026321248

Epoch: 5| Step: 2
Training loss: 2.5242373943328857
Validation loss: 3.4724235919214066

Epoch: 5| Step: 3
Training loss: 4.052272796630859
Validation loss: 3.464964464146604

Epoch: 5| Step: 4
Training loss: 3.6721954345703125
Validation loss: 3.458514239198418

Epoch: 5| Step: 5
Training loss: 3.751345157623291
Validation loss: 3.4484603507544405

Epoch: 5| Step: 6
Training loss: 2.7848219871520996
Validation loss: 3.4418348445687243

Epoch: 5| Step: 7
Training loss: 3.5129847526550293
Validation loss: 3.4405065557008148

Epoch: 5| Step: 8
Training loss: 3.777920961380005
Validation loss: 3.432807186598419

Epoch: 5| Step: 9
Training loss: 3.0332860946655273
Validation loss: 3.4292229683168474

Epoch: 5| Step: 10
Training loss: 2.4236326217651367
Validation loss: 3.420586339889034

Epoch: 15| Step: 0
Training loss: 3.351386547088623
Validation loss: 3.4136238764691096

Epoch: 5| Step: 1
Training loss: 3.542095899581909
Validation loss: 3.40773521443849

Epoch: 5| Step: 2
Training loss: 2.6540677547454834
Validation loss: 3.4025163727421917

Epoch: 5| Step: 3
Training loss: 3.287585496902466
Validation loss: 3.3989584907408683

Epoch: 5| Step: 4
Training loss: 3.5087356567382812
Validation loss: 3.3935563666846162

Epoch: 5| Step: 5
Training loss: 4.561380863189697
Validation loss: 3.380927360186013

Epoch: 5| Step: 6
Training loss: 4.187126636505127
Validation loss: 3.3815806604200795

Epoch: 5| Step: 7
Training loss: 2.7872166633605957
Validation loss: 3.375804344813029

Epoch: 5| Step: 8
Training loss: 2.5513150691986084
Validation loss: 3.372967166285361

Epoch: 5| Step: 9
Training loss: 3.277714252471924
Validation loss: 3.3692491259626163

Epoch: 5| Step: 10
Training loss: 2.9054219722747803
Validation loss: 3.3643936803264003

Epoch: 16| Step: 0
Training loss: 3.6270413398742676
Validation loss: 3.3594808219581522

Epoch: 5| Step: 1
Training loss: 2.9556326866149902
Validation loss: 3.354581968758696

Epoch: 5| Step: 2
Training loss: 3.516810655593872
Validation loss: 3.347778720240439

Epoch: 5| Step: 3
Training loss: 2.8739194869995117
Validation loss: 3.345280372968284

Epoch: 5| Step: 4
Training loss: 3.1483559608459473
Validation loss: 3.340574651636103

Epoch: 5| Step: 5
Training loss: 3.5543484687805176
Validation loss: 3.3427291582989436

Epoch: 5| Step: 6
Training loss: 3.2934799194335938
Validation loss: 3.3302740691810526

Epoch: 5| Step: 7
Training loss: 3.0618221759796143
Validation loss: 3.3218793074289956

Epoch: 5| Step: 8
Training loss: 3.8843460083007812
Validation loss: 3.3176722167640604

Epoch: 5| Step: 9
Training loss: 2.4035420417785645
Validation loss: 3.3162681466789654

Epoch: 5| Step: 10
Training loss: 3.9849350452423096
Validation loss: 3.312665613748694

Epoch: 17| Step: 0
Training loss: 3.0407166481018066
Validation loss: 3.309728814709571

Epoch: 5| Step: 1
Training loss: 2.7313456535339355
Validation loss: 3.3069268067677817

Epoch: 5| Step: 2
Training loss: 2.7390246391296387
Validation loss: 3.3031161549270793

Epoch: 5| Step: 3
Training loss: 3.197352886199951
Validation loss: 3.2995129144319923

Epoch: 5| Step: 4
Training loss: 3.930372714996338
Validation loss: 3.296272426523188

Epoch: 5| Step: 5
Training loss: 3.1327621936798096
Validation loss: 3.297161166385938

Epoch: 5| Step: 6
Training loss: 2.6927268505096436
Validation loss: 3.2920326186764624

Epoch: 5| Step: 7
Training loss: 4.2974443435668945
Validation loss: 3.286983851463564

Epoch: 5| Step: 8
Training loss: 3.741075038909912
Validation loss: 3.2850994961236113

Epoch: 5| Step: 9
Training loss: 3.6207568645477295
Validation loss: 3.2808805870753464

Epoch: 5| Step: 10
Training loss: 2.615490674972534
Validation loss: 3.2817956401455786

Epoch: 18| Step: 0
Training loss: 2.8166961669921875
Validation loss: 3.2803604782268567

Epoch: 5| Step: 1
Training loss: 2.0856988430023193
Validation loss: 3.2698359361258884

Epoch: 5| Step: 2
Training loss: 2.934121608734131
Validation loss: 3.2650543335945375

Epoch: 5| Step: 3
Training loss: 3.856266736984253
Validation loss: 3.2607293692968224

Epoch: 5| Step: 4
Training loss: 3.271791934967041
Validation loss: 3.2572326711429063

Epoch: 5| Step: 5
Training loss: 3.6578288078308105
Validation loss: 3.2572473197854976

Epoch: 5| Step: 6
Training loss: 3.3033556938171387
Validation loss: 3.2542310991594867

Epoch: 5| Step: 7
Training loss: 3.3458237648010254
Validation loss: 3.247641917197935

Epoch: 5| Step: 8
Training loss: 3.306835174560547
Validation loss: 3.246533924533475

Epoch: 5| Step: 9
Training loss: 3.3943092823028564
Validation loss: 3.2461358834338445

Epoch: 5| Step: 10
Training loss: 3.6706326007843018
Validation loss: 3.2435983509145756

Epoch: 19| Step: 0
Training loss: 3.5639572143554688
Validation loss: 3.2395264256385063

Epoch: 5| Step: 1
Training loss: 3.105712413787842
Validation loss: 3.2319441072402464

Epoch: 5| Step: 2
Training loss: 2.8084280490875244
Validation loss: 3.2288965948166384

Epoch: 5| Step: 3
Training loss: 3.600437641143799
Validation loss: 3.2297953764597573

Epoch: 5| Step: 4
Training loss: 3.8734638690948486
Validation loss: 3.223916684427569

Epoch: 5| Step: 5
Training loss: 3.2997727394104004
Validation loss: 3.2214861480138635

Epoch: 5| Step: 6
Training loss: 3.298372983932495
Validation loss: 3.2207821774226364

Epoch: 5| Step: 7
Training loss: 3.119062900543213
Validation loss: 3.220744025322699

Epoch: 5| Step: 8
Training loss: 3.6267712116241455
Validation loss: 3.2165057992422454

Epoch: 5| Step: 9
Training loss: 2.2746317386627197
Validation loss: 3.2138842818557576

Epoch: 5| Step: 10
Training loss: 2.6218886375427246
Validation loss: 3.2160296491397324

Epoch: 20| Step: 0
Training loss: 3.529282808303833
Validation loss: 3.2124638762525333

Epoch: 5| Step: 1
Training loss: 2.5293312072753906
Validation loss: 3.210159501721782

Epoch: 5| Step: 2
Training loss: 2.83990478515625
Validation loss: 3.203190113908501

Epoch: 5| Step: 3
Training loss: 4.484190464019775
Validation loss: 3.2038180879367295

Epoch: 5| Step: 4
Training loss: 2.706944227218628
Validation loss: 3.1975586004154657

Epoch: 5| Step: 5
Training loss: 2.9843897819519043
Validation loss: 3.197709891103929

Epoch: 5| Step: 6
Training loss: 4.5026373863220215
Validation loss: 3.1930025008416947

Epoch: 5| Step: 7
Training loss: 2.7253520488739014
Validation loss: 3.185327547852711

Epoch: 5| Step: 8
Training loss: 3.000356674194336
Validation loss: 3.1840712306320027

Epoch: 5| Step: 9
Training loss: 3.069380283355713
Validation loss: 3.1768120283721597

Epoch: 5| Step: 10
Training loss: 2.6309351921081543
Validation loss: 3.1770107541033017

Epoch: 21| Step: 0
Training loss: 3.389613389968872
Validation loss: 3.1738299708212576

Epoch: 5| Step: 1
Training loss: 2.5768933296203613
Validation loss: 3.1782890468515377

Epoch: 5| Step: 2
Training loss: 3.0900440216064453
Validation loss: 3.173588962965114

Epoch: 5| Step: 3
Training loss: 2.3381454944610596
Validation loss: 3.1703424505008164

Epoch: 5| Step: 4
Training loss: 3.3617560863494873
Validation loss: 3.168911841607863

Epoch: 5| Step: 5
Training loss: 3.553868055343628
Validation loss: 3.1675604287014214

Epoch: 5| Step: 6
Training loss: 4.543712615966797
Validation loss: 3.166678326104277

Epoch: 5| Step: 7
Training loss: 4.365679740905762
Validation loss: 3.163070781256563

Epoch: 5| Step: 8
Training loss: 2.405965566635132
Validation loss: 3.1546885300708074

Epoch: 5| Step: 9
Training loss: 2.7395808696746826
Validation loss: 3.1553486111343547

Epoch: 5| Step: 10
Training loss: 2.3777897357940674
Validation loss: 3.1609967267641457

Epoch: 22| Step: 0
Training loss: 3.430206775665283
Validation loss: 3.1621077188881497

Epoch: 5| Step: 1
Training loss: 3.5936102867126465
Validation loss: 3.153489820418819

Epoch: 5| Step: 2
Training loss: 3.5893330574035645
Validation loss: 3.150793134525258

Epoch: 5| Step: 3
Training loss: 3.4487805366516113
Validation loss: 3.1426485302627727

Epoch: 5| Step: 4
Training loss: 3.1855664253234863
Validation loss: 3.145511163178311

Epoch: 5| Step: 5
Training loss: 2.5351438522338867
Validation loss: 3.138283847480692

Epoch: 5| Step: 6
Training loss: 3.051093578338623
Validation loss: 3.1413976633420555

Epoch: 5| Step: 7
Training loss: 2.5900959968566895
Validation loss: 3.1402739863241873

Epoch: 5| Step: 8
Training loss: 2.644085645675659
Validation loss: 3.1357288411868516

Epoch: 5| Step: 9
Training loss: 3.515838623046875
Validation loss: 3.133627632612823

Epoch: 5| Step: 10
Training loss: 3.0805928707122803
Validation loss: 3.1319871743520102

Epoch: 23| Step: 0
Training loss: 3.4027061462402344
Validation loss: 3.1279159258770686

Epoch: 5| Step: 1
Training loss: 2.9669294357299805
Validation loss: 3.1264963714025353

Epoch: 5| Step: 2
Training loss: 3.39673113822937
Validation loss: 3.126339068976782

Epoch: 5| Step: 3
Training loss: 3.836357593536377
Validation loss: 3.1241552086286646

Epoch: 5| Step: 4
Training loss: 2.9643750190734863
Validation loss: 3.122315452944848

Epoch: 5| Step: 5
Training loss: 3.239016056060791
Validation loss: 3.119447595329695

Epoch: 5| Step: 6
Training loss: 2.57962703704834
Validation loss: 3.11647016515014

Epoch: 5| Step: 7
Training loss: 3.0234618186950684
Validation loss: 3.1102772323034142

Epoch: 5| Step: 8
Training loss: 2.5961246490478516
Validation loss: 3.1135794398605183

Epoch: 5| Step: 9
Training loss: 3.2599596977233887
Validation loss: 3.1082443473159627

Epoch: 5| Step: 10
Training loss: 3.25657057762146
Validation loss: 3.106073728171728

Epoch: 24| Step: 0
Training loss: 3.1098430156707764
Validation loss: 3.1076362440663

Epoch: 5| Step: 1
Training loss: 3.6894447803497314
Validation loss: 3.1039820076316915

Epoch: 5| Step: 2
Training loss: 2.9784114360809326
Validation loss: 3.104005954598868

Epoch: 5| Step: 3
Training loss: 3.1866486072540283
Validation loss: 3.1018305850285355

Epoch: 5| Step: 4
Training loss: 3.278669834136963
Validation loss: 3.100519267461633

Epoch: 5| Step: 5
Training loss: 3.354538679122925
Validation loss: 3.094809414238058

Epoch: 5| Step: 6
Training loss: 3.4564201831817627
Validation loss: 3.098796752191359

Epoch: 5| Step: 7
Training loss: 2.3972010612487793
Validation loss: 3.09773713286205

Epoch: 5| Step: 8
Training loss: 2.9607486724853516
Validation loss: 3.095914343351959

Epoch: 5| Step: 9
Training loss: 3.062293767929077
Validation loss: 3.0913177459470687

Epoch: 5| Step: 10
Training loss: 2.778010368347168
Validation loss: 3.0886073317579044

Epoch: 25| Step: 0
Training loss: 2.981982469558716
Validation loss: 3.0935417041983655

Epoch: 5| Step: 1
Training loss: 2.1923105716705322
Validation loss: 3.0907487715444257

Epoch: 5| Step: 2
Training loss: 2.9654974937438965
Validation loss: 3.088979459577991

Epoch: 5| Step: 3
Training loss: 4.2490553855896
Validation loss: 3.0867169236624115

Epoch: 5| Step: 4
Training loss: 3.194844961166382
Validation loss: 3.0829589033639557

Epoch: 5| Step: 5
Training loss: 2.6754097938537598
Validation loss: 3.0830583931297384

Epoch: 5| Step: 6
Training loss: 2.0932624340057373
Validation loss: 3.0852412664762108

Epoch: 5| Step: 7
Training loss: 3.595811367034912
Validation loss: 3.093121551698254

Epoch: 5| Step: 8
Training loss: 3.6165401935577393
Validation loss: 3.0772020124620005

Epoch: 5| Step: 9
Training loss: 3.4725048542022705
Validation loss: 3.0752473697867444

Epoch: 5| Step: 10
Training loss: 3.1612720489501953
Validation loss: 3.0781543229215886

Epoch: 26| Step: 0
Training loss: 3.1316745281219482
Validation loss: 3.0849846306667534

Epoch: 5| Step: 1
Training loss: 4.04876708984375
Validation loss: 3.082119967347832

Epoch: 5| Step: 2
Training loss: 2.832838773727417
Validation loss: 3.081833606125206

Epoch: 5| Step: 3
Training loss: 2.895972728729248
Validation loss: 3.0719781332118536

Epoch: 5| Step: 4
Training loss: 2.5728964805603027
Validation loss: 3.066337805922313

Epoch: 5| Step: 5
Training loss: 3.0567140579223633
Validation loss: 3.0714240227976153

Epoch: 5| Step: 6
Training loss: 3.4810702800750732
Validation loss: 3.068201188118227

Epoch: 5| Step: 7
Training loss: 3.216576337814331
Validation loss: 3.069110398651451

Epoch: 5| Step: 8
Training loss: 2.5411019325256348
Validation loss: 3.0626078677433792

Epoch: 5| Step: 9
Training loss: 2.721261978149414
Validation loss: 3.0663878892057683

Epoch: 5| Step: 10
Training loss: 3.7725255489349365
Validation loss: 3.0598560123033423

Epoch: 27| Step: 0
Training loss: 4.0752339363098145
Validation loss: 3.0529393201233237

Epoch: 5| Step: 1
Training loss: 3.5162549018859863
Validation loss: 3.0566906134287515

Epoch: 5| Step: 2
Training loss: 4.093858242034912
Validation loss: 3.0565485415920133

Epoch: 5| Step: 3
Training loss: 1.9421484470367432
Validation loss: 3.0531103816083682

Epoch: 5| Step: 4
Training loss: 3.1202263832092285
Validation loss: 3.0498450263853996

Epoch: 5| Step: 5
Training loss: 3.533533811569214
Validation loss: 3.0491715451722503

Epoch: 5| Step: 6
Training loss: 2.8076119422912598
Validation loss: 3.0468949092331754

Epoch: 5| Step: 7
Training loss: 2.8375725746154785
Validation loss: 3.0447963078816733

Epoch: 5| Step: 8
Training loss: 2.5063488483428955
Validation loss: 3.0433309770399526

Epoch: 5| Step: 9
Training loss: 2.6518442630767822
Validation loss: 3.0404121132307154

Epoch: 5| Step: 10
Training loss: 2.8344507217407227
Validation loss: 3.0394867415069253

Epoch: 28| Step: 0
Training loss: 2.9333178997039795
Validation loss: 3.041926412172215

Epoch: 5| Step: 1
Training loss: 3.1949923038482666
Validation loss: 3.0422467031786518

Epoch: 5| Step: 2
Training loss: 3.1192970275878906
Validation loss: 3.0411215905220277

Epoch: 5| Step: 3
Training loss: 2.610156774520874
Validation loss: 3.0367563770663355

Epoch: 5| Step: 4
Training loss: 3.034888505935669
Validation loss: 3.0359314026371127

Epoch: 5| Step: 5
Training loss: 2.6477866172790527
Validation loss: 3.032795290793142

Epoch: 5| Step: 6
Training loss: 2.9314517974853516
Validation loss: 3.0333906348033617

Epoch: 5| Step: 7
Training loss: 3.954029083251953
Validation loss: 3.029464057696763

Epoch: 5| Step: 8
Training loss: 3.127108097076416
Validation loss: 3.024296896432036

Epoch: 5| Step: 9
Training loss: 3.7791531085968018
Validation loss: 3.0244264089933006

Epoch: 5| Step: 10
Training loss: 2.400400400161743
Validation loss: 3.0265162965302825

Epoch: 29| Step: 0
Training loss: 3.657092332839966
Validation loss: 3.035380337827949

Epoch: 5| Step: 1
Training loss: 2.5874922275543213
Validation loss: 3.040880900557323

Epoch: 5| Step: 2
Training loss: 2.5325255393981934
Validation loss: 3.026824669171405

Epoch: 5| Step: 3
Training loss: 3.0611701011657715
Validation loss: 3.024383880758798

Epoch: 5| Step: 4
Training loss: 4.109976291656494
Validation loss: 3.0221700642698552

Epoch: 5| Step: 5
Training loss: 2.8304238319396973
Validation loss: 3.021486787385838

Epoch: 5| Step: 6
Training loss: 3.0717177391052246
Validation loss: 3.0197041009062078

Epoch: 5| Step: 7
Training loss: 3.4148478507995605
Validation loss: 3.018989837297829

Epoch: 5| Step: 8
Training loss: 3.4907119274139404
Validation loss: 3.0203334798095045

Epoch: 5| Step: 9
Training loss: 2.9115023612976074
Validation loss: 3.01242874258308

Epoch: 5| Step: 10
Training loss: 1.975842833518982
Validation loss: 3.007274281594061

Epoch: 30| Step: 0
Training loss: 3.714141368865967
Validation loss: 3.0081588939953874

Epoch: 5| Step: 1
Training loss: 2.9494640827178955
Validation loss: 3.005245808632143

Epoch: 5| Step: 2
Training loss: 2.7626593112945557
Validation loss: 3.0185739558230162

Epoch: 5| Step: 3
Training loss: 2.9822216033935547
Validation loss: 3.0305183420899096

Epoch: 5| Step: 4
Training loss: 2.304877519607544
Validation loss: 3.0211717185153755

Epoch: 5| Step: 5
Training loss: 4.130269527435303
Validation loss: 3.0168689399637203

Epoch: 5| Step: 6
Training loss: 2.687213182449341
Validation loss: 3.011455023160545

Epoch: 5| Step: 7
Training loss: 2.6558194160461426
Validation loss: 3.0013025140249603

Epoch: 5| Step: 8
Training loss: 2.9227123260498047
Validation loss: 2.995956725971673

Epoch: 5| Step: 9
Training loss: 2.9767746925354004
Validation loss: 2.994661374758649

Epoch: 5| Step: 10
Training loss: 3.6168861389160156
Validation loss: 2.995088774670837

Epoch: 31| Step: 0
Training loss: 2.0314440727233887
Validation loss: 2.999232663903185

Epoch: 5| Step: 1
Training loss: 3.4344773292541504
Validation loss: 3.0020958762015066

Epoch: 5| Step: 2
Training loss: 3.199575901031494
Validation loss: 3.0051296129021594

Epoch: 5| Step: 3
Training loss: 3.595423936843872
Validation loss: 2.995879896225468

Epoch: 5| Step: 4
Training loss: 2.6527724266052246
Validation loss: 2.9926337836891093

Epoch: 5| Step: 5
Training loss: 2.537437915802002
Validation loss: 2.9931392438950075

Epoch: 5| Step: 6
Training loss: 3.698514223098755
Validation loss: 2.997884617056898

Epoch: 5| Step: 7
Training loss: 2.9917924404144287
Validation loss: 2.998635676599318

Epoch: 5| Step: 8
Training loss: 3.6049094200134277
Validation loss: 2.9997547800822923

Epoch: 5| Step: 9
Training loss: 3.3769783973693848
Validation loss: 2.9862090797834497

Epoch: 5| Step: 10
Training loss: 2.3669941425323486
Validation loss: 2.9815385931281635

Epoch: 32| Step: 0
Training loss: 2.224853038787842
Validation loss: 2.981002992199313

Epoch: 5| Step: 1
Training loss: 3.149279832839966
Validation loss: 2.9780305970099663

Epoch: 5| Step: 2
Training loss: 3.3202528953552246
Validation loss: 2.9793859604866273

Epoch: 5| Step: 3
Training loss: 2.8726325035095215
Validation loss: 2.9826602371790076

Epoch: 5| Step: 4
Training loss: 2.7331383228302
Validation loss: 2.987527606307819

Epoch: 5| Step: 5
Training loss: 3.7715282440185547
Validation loss: 2.985178852594027

Epoch: 5| Step: 6
Training loss: 3.061846971511841
Validation loss: 2.979323087200042

Epoch: 5| Step: 7
Training loss: 3.1777846813201904
Validation loss: 2.983207333472467

Epoch: 5| Step: 8
Training loss: 2.7427566051483154
Validation loss: 2.976276674578267

Epoch: 5| Step: 9
Training loss: 3.356832981109619
Validation loss: 2.976691366523825

Epoch: 5| Step: 10
Training loss: 3.011934995651245
Validation loss: 2.970494988144085

Epoch: 33| Step: 0
Training loss: 3.1270737648010254
Validation loss: 2.9644232872993714

Epoch: 5| Step: 1
Training loss: 2.71930193901062
Validation loss: 2.9620911152132097

Epoch: 5| Step: 2
Training loss: 2.6756463050842285
Validation loss: 2.9604395025519916

Epoch: 5| Step: 3
Training loss: 3.651242733001709
Validation loss: 2.95962715918018

Epoch: 5| Step: 4
Training loss: 3.341309070587158
Validation loss: 2.9603387976205475

Epoch: 5| Step: 5
Training loss: 3.763287305831909
Validation loss: 2.9593435846349245

Epoch: 5| Step: 6
Training loss: 3.445308208465576
Validation loss: 2.958926013720933

Epoch: 5| Step: 7
Training loss: 2.825343608856201
Validation loss: 2.955183982849121

Epoch: 5| Step: 8
Training loss: 3.006911039352417
Validation loss: 2.949756919696767

Epoch: 5| Step: 9
Training loss: 2.16465425491333
Validation loss: 2.948622683043121

Epoch: 5| Step: 10
Training loss: 2.5253608226776123
Validation loss: 2.9482487940019175

Epoch: 34| Step: 0
Training loss: 3.572827100753784
Validation loss: 2.948170751653692

Epoch: 5| Step: 1
Training loss: 3.4411911964416504
Validation loss: 2.944574071514991

Epoch: 5| Step: 2
Training loss: 2.2532150745391846
Validation loss: 2.9418438890928864

Epoch: 5| Step: 3
Training loss: 2.981440305709839
Validation loss: 2.9418255718805457

Epoch: 5| Step: 4
Training loss: 3.9561030864715576
Validation loss: 2.944921603766821

Epoch: 5| Step: 5
Training loss: 2.214656352996826
Validation loss: 2.945893221004035

Epoch: 5| Step: 6
Training loss: 3.428551435470581
Validation loss: 2.944567306067354

Epoch: 5| Step: 7
Training loss: 2.92162823677063
Validation loss: 2.9398951940639044

Epoch: 5| Step: 8
Training loss: 2.1816213130950928
Validation loss: 2.936900031182074

Epoch: 5| Step: 9
Training loss: 3.394313097000122
Validation loss: 2.938080551803753

Epoch: 5| Step: 10
Training loss: 2.839298963546753
Validation loss: 2.946769311863889

Epoch: 35| Step: 0
Training loss: 2.9367964267730713
Validation loss: 2.939726002754704

Epoch: 5| Step: 1
Training loss: 2.7308335304260254
Validation loss: 2.9422986840689056

Epoch: 5| Step: 2
Training loss: 2.0236587524414062
Validation loss: 2.941451877676031

Epoch: 5| Step: 3
Training loss: 3.75476336479187
Validation loss: 2.9459994992902203

Epoch: 5| Step: 4
Training loss: 2.8244271278381348
Validation loss: 2.936006320420132

Epoch: 5| Step: 5
Training loss: 3.707770586013794
Validation loss: 2.929330828369305

Epoch: 5| Step: 6
Training loss: 2.9056029319763184
Validation loss: 2.933521757843674

Epoch: 5| Step: 7
Training loss: 2.9307451248168945
Validation loss: 2.9312235514322915

Epoch: 5| Step: 8
Training loss: 3.0363831520080566
Validation loss: 2.93515266910676

Epoch: 5| Step: 9
Training loss: 2.707540988922119
Validation loss: 2.9280948280006327

Epoch: 5| Step: 10
Training loss: 3.6480908393859863
Validation loss: 2.9245439498655257

Epoch: 36| Step: 0
Training loss: 2.6662793159484863
Validation loss: 2.923157663755519

Epoch: 5| Step: 1
Training loss: 3.1213066577911377
Validation loss: 2.9228775603796846

Epoch: 5| Step: 2
Training loss: 3.666536808013916
Validation loss: 2.926134988825808

Epoch: 5| Step: 3
Training loss: 2.732327699661255
Validation loss: 2.926479426763391

Epoch: 5| Step: 4
Training loss: 2.9554481506347656
Validation loss: 2.929362645713232

Epoch: 5| Step: 5
Training loss: 2.4319262504577637
Validation loss: 2.9307098363035466

Epoch: 5| Step: 6
Training loss: 3.581380844116211
Validation loss: 2.933849557753532

Epoch: 5| Step: 7
Training loss: 3.14021635055542
Validation loss: 2.9260195480879916

Epoch: 5| Step: 8
Training loss: 3.339893341064453
Validation loss: 2.921884321397351

Epoch: 5| Step: 9
Training loss: 3.0104820728302
Validation loss: 2.921433964083272

Epoch: 5| Step: 10
Training loss: 2.230642318725586
Validation loss: 2.9218390551946496

Epoch: 37| Step: 0
Training loss: 3.087940216064453
Validation loss: 2.9328723107614825

Epoch: 5| Step: 1
Training loss: 2.8410847187042236
Validation loss: 2.939837742877263

Epoch: 5| Step: 2
Training loss: 2.7138888835906982
Validation loss: 2.9438233939550256

Epoch: 5| Step: 3
Training loss: 2.7108123302459717
Validation loss: 2.93808687374156

Epoch: 5| Step: 4
Training loss: 2.838386058807373
Validation loss: 2.930646845089492

Epoch: 5| Step: 5
Training loss: 3.2998909950256348
Validation loss: 2.9211538171255462

Epoch: 5| Step: 6
Training loss: 3.066704273223877
Validation loss: 2.9204184573183776

Epoch: 5| Step: 7
Training loss: 3.3642189502716064
Validation loss: 2.920649008084369

Epoch: 5| Step: 8
Training loss: 3.269458293914795
Validation loss: 2.9256799323584444

Epoch: 5| Step: 9
Training loss: 2.9734551906585693
Validation loss: 2.9324550808116956

Epoch: 5| Step: 10
Training loss: 2.8755736351013184
Validation loss: 2.944263355706328

Epoch: 38| Step: 0
Training loss: 3.380033016204834
Validation loss: 2.957676000492547

Epoch: 5| Step: 1
Training loss: 2.5561041831970215
Validation loss: 2.925696201221917

Epoch: 5| Step: 2
Training loss: 3.2930736541748047
Validation loss: 2.9141925227257515

Epoch: 5| Step: 3
Training loss: 2.734618902206421
Validation loss: 2.9053806848423456

Epoch: 5| Step: 4
Training loss: 2.6817026138305664
Validation loss: 2.9083979591246574

Epoch: 5| Step: 5
Training loss: 3.4481284618377686
Validation loss: 2.9065144267133487

Epoch: 5| Step: 6
Training loss: 3.273174285888672
Validation loss: 2.9047589891700336

Epoch: 5| Step: 7
Training loss: 3.1629316806793213
Validation loss: 2.9089526130307104

Epoch: 5| Step: 8
Training loss: 2.5754177570343018
Validation loss: 2.9127632597441315

Epoch: 5| Step: 9
Training loss: 3.2663040161132812
Validation loss: 2.9049813901224444

Epoch: 5| Step: 10
Training loss: 2.5595452785491943
Validation loss: 2.9056425556059806

Epoch: 39| Step: 0
Training loss: 2.414379119873047
Validation loss: 2.9035785070029636

Epoch: 5| Step: 1
Training loss: 3.196218490600586
Validation loss: 2.9066016033131588

Epoch: 5| Step: 2
Training loss: 3.159747362136841
Validation loss: 2.9025277706884567

Epoch: 5| Step: 3
Training loss: 2.6883769035339355
Validation loss: 2.903296737260716

Epoch: 5| Step: 4
Training loss: 3.681560516357422
Validation loss: 2.899117677442489

Epoch: 5| Step: 5
Training loss: 3.5421791076660156
Validation loss: 2.894892907911731

Epoch: 5| Step: 6
Training loss: 3.059765100479126
Validation loss: 2.8947031318500476

Epoch: 5| Step: 7
Training loss: 2.9649150371551514
Validation loss: 2.89908355282199

Epoch: 5| Step: 8
Training loss: 2.3874123096466064
Validation loss: 2.8980648927791144

Epoch: 5| Step: 9
Training loss: 2.7005362510681152
Validation loss: 2.8903220802225094

Epoch: 5| Step: 10
Training loss: 2.9933931827545166
Validation loss: 2.8936670211053666

Epoch: 40| Step: 0
Training loss: 3.423841953277588
Validation loss: 2.890692162257369

Epoch: 5| Step: 1
Training loss: 3.630138397216797
Validation loss: 2.8897774347694973

Epoch: 5| Step: 2
Training loss: 3.498516798019409
Validation loss: 2.88345689927378

Epoch: 5| Step: 3
Training loss: 3.1837573051452637
Validation loss: 2.8849763049874255

Epoch: 5| Step: 4
Training loss: 2.5668911933898926
Validation loss: 2.8836110381669897

Epoch: 5| Step: 5
Training loss: 2.3984174728393555
Validation loss: 2.8869693151084324

Epoch: 5| Step: 6
Training loss: 2.9058289527893066
Validation loss: 2.8829394284115044

Epoch: 5| Step: 7
Training loss: 3.274543046951294
Validation loss: 2.8860472171537337

Epoch: 5| Step: 8
Training loss: 3.342087507247925
Validation loss: 2.8874795488131944

Epoch: 5| Step: 9
Training loss: 2.1704297065734863
Validation loss: 2.8820454894855456

Epoch: 5| Step: 10
Training loss: 2.1398067474365234
Validation loss: 2.8847700677892214

Epoch: 41| Step: 0
Training loss: 3.2705752849578857
Validation loss: 2.885069900943387

Epoch: 5| Step: 1
Training loss: 2.1481051445007324
Validation loss: 2.885065511990619

Epoch: 5| Step: 2
Training loss: 3.6762421131134033
Validation loss: 2.8778342226500153

Epoch: 5| Step: 3
Training loss: 2.5200161933898926
Validation loss: 2.8779149850209556

Epoch: 5| Step: 4
Training loss: 4.07232141494751
Validation loss: 2.8828382543338242

Epoch: 5| Step: 5
Training loss: 3.5164783000946045
Validation loss: 2.882785802246422

Epoch: 5| Step: 6
Training loss: 2.773228168487549
Validation loss: 2.8801256072136665

Epoch: 5| Step: 7
Training loss: 2.1328141689300537
Validation loss: 2.879488188733337

Epoch: 5| Step: 8
Training loss: 3.139596700668335
Validation loss: 2.8760923621475056

Epoch: 5| Step: 9
Training loss: 2.4482502937316895
Validation loss: 2.8730300216264624

Epoch: 5| Step: 10
Training loss: 2.9469337463378906
Validation loss: 2.8676311662120204

Epoch: 42| Step: 0
Training loss: 3.098742961883545
Validation loss: 2.8692253456320813

Epoch: 5| Step: 1
Training loss: 3.015906810760498
Validation loss: 2.871057776994603

Epoch: 5| Step: 2
Training loss: 3.440185546875
Validation loss: 2.872503977949901

Epoch: 5| Step: 3
Training loss: 1.9097141027450562
Validation loss: 2.8694942356437765

Epoch: 5| Step: 4
Training loss: 3.480452060699463
Validation loss: 2.8697145626109135

Epoch: 5| Step: 5
Training loss: 2.832645893096924
Validation loss: 2.870671528641896

Epoch: 5| Step: 6
Training loss: 3.7869210243225098
Validation loss: 2.865367453585389

Epoch: 5| Step: 7
Training loss: 3.2886719703674316
Validation loss: 2.8658790024377967

Epoch: 5| Step: 8
Training loss: 2.487931489944458
Validation loss: 2.8608162915834816

Epoch: 5| Step: 9
Training loss: 2.7915706634521484
Validation loss: 2.86239283059233

Epoch: 5| Step: 10
Training loss: 2.2900586128234863
Validation loss: 2.8604829465189288

Epoch: 43| Step: 0
Training loss: 2.5521490573883057
Validation loss: 2.8678435484568277

Epoch: 5| Step: 1
Training loss: 3.566788911819458
Validation loss: 2.861795130596366

Epoch: 5| Step: 2
Training loss: 3.1757328510284424
Validation loss: 2.863117500018048

Epoch: 5| Step: 3
Training loss: 2.7002665996551514
Validation loss: 2.8689644464882473

Epoch: 5| Step: 4
Training loss: 3.0748698711395264
Validation loss: 2.8618288373434417

Epoch: 5| Step: 5
Training loss: 2.295846939086914
Validation loss: 2.8615912801475933

Epoch: 5| Step: 6
Training loss: 2.805051326751709
Validation loss: 2.8593540448014454

Epoch: 5| Step: 7
Training loss: 2.4520959854125977
Validation loss: 2.855456067669776

Epoch: 5| Step: 8
Training loss: 3.815622329711914
Validation loss: 2.8657867908477783

Epoch: 5| Step: 9
Training loss: 2.9195640087127686
Validation loss: 2.8648061111409175

Epoch: 5| Step: 10
Training loss: 3.2349486351013184
Validation loss: 2.8741358890328357

Epoch: 44| Step: 0
Training loss: 3.395547389984131
Validation loss: 2.8634535497234714

Epoch: 5| Step: 1
Training loss: 3.070436954498291
Validation loss: 2.861948331197103

Epoch: 5| Step: 2
Training loss: 3.1199328899383545
Validation loss: 2.8574169425554174

Epoch: 5| Step: 3
Training loss: 3.265026807785034
Validation loss: 2.850303888320923

Epoch: 5| Step: 4
Training loss: 2.91011381149292
Validation loss: 2.846224246486541

Epoch: 5| Step: 5
Training loss: 2.759186267852783
Validation loss: 2.8472921271477976

Epoch: 5| Step: 6
Training loss: 3.0238819122314453
Validation loss: 2.8427734862091723

Epoch: 5| Step: 7
Training loss: 3.026535749435425
Validation loss: 2.84734704033021

Epoch: 5| Step: 8
Training loss: 3.4074318408966064
Validation loss: 2.850237338773666

Epoch: 5| Step: 9
Training loss: 1.800851583480835
Validation loss: 2.8508550120938208

Epoch: 5| Step: 10
Training loss: 2.628419876098633
Validation loss: 2.845282434135355

Epoch: 45| Step: 0
Training loss: 3.036503314971924
Validation loss: 2.8445302107000865

Epoch: 5| Step: 1
Training loss: 2.8026797771453857
Validation loss: 2.84397784356148

Epoch: 5| Step: 2
Training loss: 2.7870025634765625
Validation loss: 2.84682495363297

Epoch: 5| Step: 3
Training loss: 3.1613354682922363
Validation loss: 2.844966483372514

Epoch: 5| Step: 4
Training loss: 3.171480655670166
Validation loss: 2.8523039407627557

Epoch: 5| Step: 5
Training loss: 3.6522960662841797
Validation loss: 2.8643246543022896

Epoch: 5| Step: 6
Training loss: 3.0910816192626953
Validation loss: 2.8576377335415093

Epoch: 5| Step: 7
Training loss: 2.9591612815856934
Validation loss: 2.8437710115986485

Epoch: 5| Step: 8
Training loss: 2.292827606201172
Validation loss: 2.834157802725351

Epoch: 5| Step: 9
Training loss: 2.530498743057251
Validation loss: 2.8333374531038347

Epoch: 5| Step: 10
Training loss: 2.8637237548828125
Validation loss: 2.834867746599259

Epoch: 46| Step: 0
Training loss: 3.454169511795044
Validation loss: 2.8363761004581245

Epoch: 5| Step: 1
Training loss: 2.9429593086242676
Validation loss: 2.8393550713857016

Epoch: 5| Step: 2
Training loss: 2.5933587551116943
Validation loss: 2.849245330338837

Epoch: 5| Step: 3
Training loss: 2.9549362659454346
Validation loss: 2.8537019683468725

Epoch: 5| Step: 4
Training loss: 3.4093384742736816
Validation loss: 2.859267601402857

Epoch: 5| Step: 5
Training loss: 2.9456934928894043
Validation loss: 2.8539671154432398

Epoch: 5| Step: 6
Training loss: 2.029550552368164
Validation loss: 2.8486960677690405

Epoch: 5| Step: 7
Training loss: 2.9915013313293457
Validation loss: 2.8474718883473384

Epoch: 5| Step: 8
Training loss: 3.5036091804504395
Validation loss: 2.8378526421003443

Epoch: 5| Step: 9
Training loss: 2.9090943336486816
Validation loss: 2.832479279528382

Epoch: 5| Step: 10
Training loss: 2.5814387798309326
Validation loss: 2.829491420458722

Epoch: 47| Step: 0
Training loss: 3.7760887145996094
Validation loss: 2.8299412752992366

Epoch: 5| Step: 1
Training loss: 2.8990108966827393
Validation loss: 2.829907153242378

Epoch: 5| Step: 2
Training loss: 3.3804945945739746
Validation loss: 2.828915193516721

Epoch: 5| Step: 3
Training loss: 3.048938274383545
Validation loss: 2.829896503879178

Epoch: 5| Step: 4
Training loss: 2.908341884613037
Validation loss: 2.823947488620717

Epoch: 5| Step: 5
Training loss: 2.1508593559265137
Validation loss: 2.8274220856287147

Epoch: 5| Step: 6
Training loss: 2.9104678630828857
Validation loss: 2.826017000341928

Epoch: 5| Step: 7
Training loss: 2.9335238933563232
Validation loss: 2.828895914939142

Epoch: 5| Step: 8
Training loss: 2.305069923400879
Validation loss: 2.8211763622940227

Epoch: 5| Step: 9
Training loss: 2.935473680496216
Validation loss: 2.8230425491127917

Epoch: 5| Step: 10
Training loss: 3.037493944168091
Validation loss: 2.825122361542076

Epoch: 48| Step: 0
Training loss: 2.4126791954040527
Validation loss: 2.8170857070594706

Epoch: 5| Step: 1
Training loss: 2.7539494037628174
Validation loss: 2.8208049087114233

Epoch: 5| Step: 2
Training loss: 3.5722784996032715
Validation loss: 2.819876019672681

Epoch: 5| Step: 3
Training loss: 3.8978800773620605
Validation loss: 2.819058700274396

Epoch: 5| Step: 4
Training loss: 2.6941866874694824
Validation loss: 2.8199105211483535

Epoch: 5| Step: 5
Training loss: 2.352369785308838
Validation loss: 2.814992371425834

Epoch: 5| Step: 6
Training loss: 3.278301954269409
Validation loss: 2.8128914422886346

Epoch: 5| Step: 7
Training loss: 2.7169783115386963
Validation loss: 2.813913555555446

Epoch: 5| Step: 8
Training loss: 2.7426745891571045
Validation loss: 2.8118872386153027

Epoch: 5| Step: 9
Training loss: 3.0889246463775635
Validation loss: 2.807972010745797

Epoch: 5| Step: 10
Training loss: 2.592024564743042
Validation loss: 2.814676164298929

Epoch: 49| Step: 0
Training loss: 2.7217071056365967
Validation loss: 2.812600766458819

Epoch: 5| Step: 1
Training loss: 3.616185426712036
Validation loss: 2.8159959726436163

Epoch: 5| Step: 2
Training loss: 2.7184786796569824
Validation loss: 2.8121775350263043

Epoch: 5| Step: 3
Training loss: 2.727792263031006
Validation loss: 2.8086036353982906

Epoch: 5| Step: 4
Training loss: 3.377896785736084
Validation loss: 2.804459143710393

Epoch: 5| Step: 5
Training loss: 2.7594399452209473
Validation loss: 2.8046121469108005

Epoch: 5| Step: 6
Training loss: 3.3980813026428223
Validation loss: 2.7999144907920592

Epoch: 5| Step: 7
Training loss: 2.7250208854675293
Validation loss: 2.8033576934568343

Epoch: 5| Step: 8
Training loss: 2.4002327919006348
Validation loss: 2.804080904171031

Epoch: 5| Step: 9
Training loss: 2.983872890472412
Validation loss: 2.8087160869311263

Epoch: 5| Step: 10
Training loss: 2.6147546768188477
Validation loss: 2.815285103295439

Epoch: 50| Step: 0
Training loss: 2.8940470218658447
Validation loss: 2.7996192721910376

Epoch: 5| Step: 1
Training loss: 2.5273032188415527
Validation loss: 2.8000532760415027

Epoch: 5| Step: 2
Training loss: 2.9137444496154785
Validation loss: 2.7998263323178856

Epoch: 5| Step: 3
Training loss: 3.162153959274292
Validation loss: 2.7999472336102555

Epoch: 5| Step: 4
Training loss: 2.676334857940674
Validation loss: 2.7994751520054315

Epoch: 5| Step: 5
Training loss: 2.6766440868377686
Validation loss: 2.7922043236353065

Epoch: 5| Step: 6
Training loss: 3.47157621383667
Validation loss: 2.7904631886430966

Epoch: 5| Step: 7
Training loss: 2.977393627166748
Validation loss: 2.792404936205956

Epoch: 5| Step: 8
Training loss: 3.225715160369873
Validation loss: 2.7931605385195826

Epoch: 5| Step: 9
Training loss: 2.9144785404205322
Validation loss: 2.790542853775845

Epoch: 5| Step: 10
Training loss: 2.532688617706299
Validation loss: 2.7868152382553264

Epoch: 51| Step: 0
Training loss: 1.996606469154358
Validation loss: 2.79125641751033

Epoch: 5| Step: 1
Training loss: 2.937142848968506
Validation loss: 2.7874979408838416

Epoch: 5| Step: 2
Training loss: 3.0605661869049072
Validation loss: 2.7933108319518385

Epoch: 5| Step: 3
Training loss: 3.1940417289733887
Validation loss: 2.796765337708176

Epoch: 5| Step: 4
Training loss: 3.0478785037994385
Validation loss: 2.797439157321889

Epoch: 5| Step: 5
Training loss: 2.465832471847534
Validation loss: 2.8021851483211724

Epoch: 5| Step: 6
Training loss: 2.5217127799987793
Validation loss: 2.8058784495117846

Epoch: 5| Step: 7
Training loss: 3.1136951446533203
Validation loss: 2.8055391644918792

Epoch: 5| Step: 8
Training loss: 3.433350086212158
Validation loss: 2.7989204493902062

Epoch: 5| Step: 9
Training loss: 3.2421374320983887
Validation loss: 2.7913640340169272

Epoch: 5| Step: 10
Training loss: 3.023259401321411
Validation loss: 2.7913311296893704

Epoch: 52| Step: 0
Training loss: 2.9812262058258057
Validation loss: 2.7895024591876614

Epoch: 5| Step: 1
Training loss: 2.861389636993408
Validation loss: 2.7878390358340357

Epoch: 5| Step: 2
Training loss: 3.4563052654266357
Validation loss: 2.7851936945351223

Epoch: 5| Step: 3
Training loss: 2.667816162109375
Validation loss: 2.7868249365078506

Epoch: 5| Step: 4
Training loss: 2.776461124420166
Validation loss: 2.7905211089759745

Epoch: 5| Step: 5
Training loss: 2.5662293434143066
Validation loss: 2.786952559665967

Epoch: 5| Step: 6
Training loss: 2.6899333000183105
Validation loss: 2.785399229295792

Epoch: 5| Step: 7
Training loss: 2.2663865089416504
Validation loss: 2.7821479817872405

Epoch: 5| Step: 8
Training loss: 2.739581823348999
Validation loss: 2.7873262179795133

Epoch: 5| Step: 9
Training loss: 3.2823486328125
Validation loss: 2.7837203728255404

Epoch: 5| Step: 10
Training loss: 3.7624239921569824
Validation loss: 2.785935596753192

Epoch: 53| Step: 0
Training loss: 2.489778995513916
Validation loss: 2.7859627226347565

Epoch: 5| Step: 1
Training loss: 2.8273825645446777
Validation loss: 2.7890476898480485

Epoch: 5| Step: 2
Training loss: 2.7110636234283447
Validation loss: 2.796814985172723

Epoch: 5| Step: 3
Training loss: 3.262986660003662
Validation loss: 2.7956846119255148

Epoch: 5| Step: 4
Training loss: 3.465679883956909
Validation loss: 2.7933825164712887

Epoch: 5| Step: 5
Training loss: 3.261566162109375
Validation loss: 2.7827738792665544

Epoch: 5| Step: 6
Training loss: 2.5661895275115967
Validation loss: 2.777688108464723

Epoch: 5| Step: 7
Training loss: 2.133161783218384
Validation loss: 2.776656619964107

Epoch: 5| Step: 8
Training loss: 3.0056138038635254
Validation loss: 2.7798571586608887

Epoch: 5| Step: 9
Training loss: 3.4605541229248047
Validation loss: 2.781321692210372

Epoch: 5| Step: 10
Training loss: 2.611011266708374
Validation loss: 2.776975590695617

Epoch: 54| Step: 0
Training loss: 3.4494850635528564
Validation loss: 2.779237434428225

Epoch: 5| Step: 1
Training loss: 2.973412036895752
Validation loss: 2.776699942927207

Epoch: 5| Step: 2
Training loss: 3.2223801612854004
Validation loss: 2.779817012048537

Epoch: 5| Step: 3
Training loss: 3.32397198677063
Validation loss: 2.775731550749912

Epoch: 5| Step: 4
Training loss: 2.4410972595214844
Validation loss: 2.7757712641069965

Epoch: 5| Step: 5
Training loss: 2.7580199241638184
Validation loss: 2.774456726607456

Epoch: 5| Step: 6
Training loss: 3.0161685943603516
Validation loss: 2.774132497849003

Epoch: 5| Step: 7
Training loss: 2.77417254447937
Validation loss: 2.777116419166647

Epoch: 5| Step: 8
Training loss: 2.0686097145080566
Validation loss: 2.774269498804564

Epoch: 5| Step: 9
Training loss: 2.7922680377960205
Validation loss: 2.7782230992471018

Epoch: 5| Step: 10
Training loss: 3.012796640396118
Validation loss: 2.773038823117492

Epoch: 55| Step: 0
Training loss: 3.553333282470703
Validation loss: 2.774960128209924

Epoch: 5| Step: 1
Training loss: 2.1969265937805176
Validation loss: 2.779854961620864

Epoch: 5| Step: 2
Training loss: 2.7449228763580322
Validation loss: 2.7790480326580744

Epoch: 5| Step: 3
Training loss: 2.7180838584899902
Validation loss: 2.7742933739898024

Epoch: 5| Step: 4
Training loss: 2.8073859214782715
Validation loss: 2.7705410706099642

Epoch: 5| Step: 5
Training loss: 3.6208081245422363
Validation loss: 2.7704513790786907

Epoch: 5| Step: 6
Training loss: 2.6392593383789062
Validation loss: 2.7738063617419173

Epoch: 5| Step: 7
Training loss: 2.859034299850464
Validation loss: 2.7736544583433416

Epoch: 5| Step: 8
Training loss: 3.126706600189209
Validation loss: 2.7664354744777886

Epoch: 5| Step: 9
Training loss: 2.887552261352539
Validation loss: 2.7715138696855113

Epoch: 5| Step: 10
Training loss: 2.4967782497406006
Validation loss: 2.7708843190182924

Epoch: 56| Step: 0
Training loss: 3.4040122032165527
Validation loss: 2.7765477293281147

Epoch: 5| Step: 1
Training loss: 2.665684223175049
Validation loss: 2.770834384425994

Epoch: 5| Step: 2
Training loss: 3.320748805999756
Validation loss: 2.773965862489516

Epoch: 5| Step: 3
Training loss: 3.2658615112304688
Validation loss: 2.7705904360740417

Epoch: 5| Step: 4
Training loss: 2.088003158569336
Validation loss: 2.7716871307742212

Epoch: 5| Step: 5
Training loss: 2.9218363761901855
Validation loss: 2.7740304444425847

Epoch: 5| Step: 6
Training loss: 3.1474697589874268
Validation loss: 2.768245297093545

Epoch: 5| Step: 7
Training loss: 3.2579917907714844
Validation loss: 2.766554776058402

Epoch: 5| Step: 8
Training loss: 2.2736964225769043
Validation loss: 2.772254979738625

Epoch: 5| Step: 9
Training loss: 2.8143322467803955
Validation loss: 2.7763602605430027

Epoch: 5| Step: 10
Training loss: 2.4379239082336426
Validation loss: 2.7746483177267094

Epoch: 57| Step: 0
Training loss: 2.008450746536255
Validation loss: 2.7846341415118148

Epoch: 5| Step: 1
Training loss: 2.9843478202819824
Validation loss: 2.798181579959008

Epoch: 5| Step: 2
Training loss: 3.0792932510375977
Validation loss: 2.8010651526912564

Epoch: 5| Step: 3
Training loss: 3.0069174766540527
Validation loss: 2.7922450111758326

Epoch: 5| Step: 4
Training loss: 3.1956589221954346
Validation loss: 2.7774054209391275

Epoch: 5| Step: 5
Training loss: 3.1466126441955566
Validation loss: 2.765863646743118

Epoch: 5| Step: 6
Training loss: 3.398362398147583
Validation loss: 2.7836692076857372

Epoch: 5| Step: 7
Training loss: 2.85148549079895
Validation loss: 2.7683390058496946

Epoch: 5| Step: 8
Training loss: 2.717839002609253
Validation loss: 2.7647130643167803

Epoch: 5| Step: 9
Training loss: 2.352369785308838
Validation loss: 2.7630323748434744

Epoch: 5| Step: 10
Training loss: 3.0697221755981445
Validation loss: 2.7637921071821645

Epoch: 58| Step: 0
Training loss: 2.9039196968078613
Validation loss: 2.761784125399846

Epoch: 5| Step: 1
Training loss: 2.943366527557373
Validation loss: 2.761061542777605

Epoch: 5| Step: 2
Training loss: 2.6434836387634277
Validation loss: 2.7606097062428794

Epoch: 5| Step: 3
Training loss: 3.090806484222412
Validation loss: 2.765902655099028

Epoch: 5| Step: 4
Training loss: 2.6192684173583984
Validation loss: 2.7658647696177163

Epoch: 5| Step: 5
Training loss: 2.6890175342559814
Validation loss: 2.7665050363027923

Epoch: 5| Step: 6
Training loss: 2.400952100753784
Validation loss: 2.764982520893056

Epoch: 5| Step: 7
Training loss: 2.7905466556549072
Validation loss: 2.764211652099445

Epoch: 5| Step: 8
Training loss: 3.5801405906677246
Validation loss: 2.7673064367745512

Epoch: 5| Step: 9
Training loss: 3.272190809249878
Validation loss: 2.762408318058137

Epoch: 5| Step: 10
Training loss: 2.797347068786621
Validation loss: 2.7598384734122985

Epoch: 59| Step: 0
Training loss: 2.3588268756866455
Validation loss: 2.752223789051015

Epoch: 5| Step: 1
Training loss: 4.183108806610107
Validation loss: 2.757180267764676

Epoch: 5| Step: 2
Training loss: 2.4561145305633545
Validation loss: 2.7568610919419156

Epoch: 5| Step: 3
Training loss: 2.8986713886260986
Validation loss: 2.757207578228366

Epoch: 5| Step: 4
Training loss: 3.3214282989501953
Validation loss: 2.756537211838589

Epoch: 5| Step: 5
Training loss: 3.83611798286438
Validation loss: 2.753921316516015

Epoch: 5| Step: 6
Training loss: 2.3661983013153076
Validation loss: 2.750977195719237

Epoch: 5| Step: 7
Training loss: 2.732199192047119
Validation loss: 2.751336272044848

Epoch: 5| Step: 8
Training loss: 2.474238872528076
Validation loss: 2.751001722069197

Epoch: 5| Step: 9
Training loss: 2.2710869312286377
Validation loss: 2.7518271605173745

Epoch: 5| Step: 10
Training loss: 2.7111661434173584
Validation loss: 2.746617527418239

Epoch: 60| Step: 0
Training loss: 2.4021103382110596
Validation loss: 2.7488761319909045

Epoch: 5| Step: 1
Training loss: 2.625469923019409
Validation loss: 2.7523645149764193

Epoch: 5| Step: 2
Training loss: 2.93342924118042
Validation loss: 2.7590297242646575

Epoch: 5| Step: 3
Training loss: 3.3346047401428223
Validation loss: 2.756897372584189

Epoch: 5| Step: 4
Training loss: 3.033968925476074
Validation loss: 2.7519148472816712

Epoch: 5| Step: 5
Training loss: 2.441615581512451
Validation loss: 2.7429253491022254

Epoch: 5| Step: 6
Training loss: 3.70786714553833
Validation loss: 2.746907598228865

Epoch: 5| Step: 7
Training loss: 2.276573419570923
Validation loss: 2.7437101974282214

Epoch: 5| Step: 8
Training loss: 3.1160311698913574
Validation loss: 2.7470037296254146

Epoch: 5| Step: 9
Training loss: 3.757615566253662
Validation loss: 2.7408208718863865

Epoch: 5| Step: 10
Training loss: 1.7918696403503418
Validation loss: 2.7469453991100354

Epoch: 61| Step: 0
Training loss: 2.789572238922119
Validation loss: 2.739619311466012

Epoch: 5| Step: 1
Training loss: 3.244266986846924
Validation loss: 2.7388112852650304

Epoch: 5| Step: 2
Training loss: 2.4749209880828857
Validation loss: 2.7438470625108287

Epoch: 5| Step: 3
Training loss: 2.8130393028259277
Validation loss: 2.7375082969665527

Epoch: 5| Step: 4
Training loss: 3.1341793537139893
Validation loss: 2.7419070197689916

Epoch: 5| Step: 5
Training loss: 2.089514970779419
Validation loss: 2.732113225485689

Epoch: 5| Step: 6
Training loss: 2.0807766914367676
Validation loss: 2.7354696642967964

Epoch: 5| Step: 7
Training loss: 3.9775795936584473
Validation loss: 2.7348217579626266

Epoch: 5| Step: 8
Training loss: 2.62780499458313
Validation loss: 2.7364706659829743

Epoch: 5| Step: 9
Training loss: 3.0428435802459717
Validation loss: 2.7349407134517545

Epoch: 5| Step: 10
Training loss: 3.2708678245544434
Validation loss: 2.7354173506459882

Epoch: 62| Step: 0
Training loss: 2.9947986602783203
Validation loss: 2.739852007999215

Epoch: 5| Step: 1
Training loss: 2.6438846588134766
Validation loss: 2.7339447544467066

Epoch: 5| Step: 2
Training loss: 2.99143385887146
Validation loss: 2.7350232088437645

Epoch: 5| Step: 3
Training loss: 3.0483744144439697
Validation loss: 2.7325911188638337

Epoch: 5| Step: 4
Training loss: 2.7895054817199707
Validation loss: 2.733206449016448

Epoch: 5| Step: 5
Training loss: 2.5583598613739014
Validation loss: 2.737405784668461

Epoch: 5| Step: 6
Training loss: 3.301440477371216
Validation loss: 2.7360649442160003

Epoch: 5| Step: 7
Training loss: 2.5278613567352295
Validation loss: 2.7323049704233804

Epoch: 5| Step: 8
Training loss: 3.1220593452453613
Validation loss: 2.7306422046435777

Epoch: 5| Step: 9
Training loss: 2.7535367012023926
Validation loss: 2.72761042400073

Epoch: 5| Step: 10
Training loss: 2.6534345149993896
Validation loss: 2.7335514304458455

Epoch: 63| Step: 0
Training loss: 3.4360153675079346
Validation loss: 2.7390914450409594

Epoch: 5| Step: 1
Training loss: 3.3111166954040527
Validation loss: 2.73866626011428

Epoch: 5| Step: 2
Training loss: 3.0101828575134277
Validation loss: 2.737038594420238

Epoch: 5| Step: 3
Training loss: 2.326110363006592
Validation loss: 2.7257959432499383

Epoch: 5| Step: 4
Training loss: 2.2436718940734863
Validation loss: 2.7254064313827024

Epoch: 5| Step: 5
Training loss: 2.5890703201293945
Validation loss: 2.7214182012824604

Epoch: 5| Step: 6
Training loss: 3.1614606380462646
Validation loss: 2.7221070438302974

Epoch: 5| Step: 7
Training loss: 2.339698314666748
Validation loss: 2.7261226125942764

Epoch: 5| Step: 8
Training loss: 3.557054042816162
Validation loss: 2.7357679951575493

Epoch: 5| Step: 9
Training loss: 2.447221040725708
Validation loss: 2.7312367013705674

Epoch: 5| Step: 10
Training loss: 3.050445556640625
Validation loss: 2.7382311820983887

Epoch: 64| Step: 0
Training loss: 2.5963242053985596
Validation loss: 2.7328635338814027

Epoch: 5| Step: 1
Training loss: 3.2024929523468018
Validation loss: 2.730302015940348

Epoch: 5| Step: 2
Training loss: 3.161966323852539
Validation loss: 2.728838220719368

Epoch: 5| Step: 3
Training loss: 3.2385096549987793
Validation loss: 2.728422457172025

Epoch: 5| Step: 4
Training loss: 2.2679667472839355
Validation loss: 2.7203906120792514

Epoch: 5| Step: 5
Training loss: 2.9053311347961426
Validation loss: 2.718017575561359

Epoch: 5| Step: 6
Training loss: 2.7391676902770996
Validation loss: 2.716977132264004

Epoch: 5| Step: 7
Training loss: 2.7613461017608643
Validation loss: 2.718903003200408

Epoch: 5| Step: 8
Training loss: 2.8578505516052246
Validation loss: 2.7228604875585085

Epoch: 5| Step: 9
Training loss: 2.3989529609680176
Validation loss: 2.714353023036834

Epoch: 5| Step: 10
Training loss: 3.202634334564209
Validation loss: 2.7152961710447907

Epoch: 65| Step: 0
Training loss: 3.3163223266601562
Validation loss: 2.7167789987338486

Epoch: 5| Step: 1
Training loss: 2.7514069080352783
Validation loss: 2.714741145410845

Epoch: 5| Step: 2
Training loss: 2.580453634262085
Validation loss: 2.714394910361177

Epoch: 5| Step: 3
Training loss: 2.6112303733825684
Validation loss: 2.7110057979501705

Epoch: 5| Step: 4
Training loss: 2.5510497093200684
Validation loss: 2.711532210790983

Epoch: 5| Step: 5
Training loss: 2.9976632595062256
Validation loss: 2.716896136601766

Epoch: 5| Step: 6
Training loss: 2.8457999229431152
Validation loss: 2.712504017737604

Epoch: 5| Step: 7
Training loss: 2.886915922164917
Validation loss: 2.7087345918019614

Epoch: 5| Step: 8
Training loss: 2.5227103233337402
Validation loss: 2.7153026570555983

Epoch: 5| Step: 9
Training loss: 3.5104897022247314
Validation loss: 2.723184344589069

Epoch: 5| Step: 10
Training loss: 2.6299238204956055
Validation loss: 2.721530111887122

Epoch: 66| Step: 0
Training loss: 2.365496873855591
Validation loss: 2.720347512152887

Epoch: 5| Step: 1
Training loss: 3.4330945014953613
Validation loss: 2.7160253781144337

Epoch: 5| Step: 2
Training loss: 2.4029858112335205
Validation loss: 2.7114120068088656

Epoch: 5| Step: 3
Training loss: 3.1136906147003174
Validation loss: 2.7118375506452335

Epoch: 5| Step: 4
Training loss: 3.1126058101654053
Validation loss: 2.7230660992283977

Epoch: 5| Step: 5
Training loss: 2.8002350330352783
Validation loss: 2.724472274062454

Epoch: 5| Step: 6
Training loss: 2.2727866172790527
Validation loss: 2.7198702007211666

Epoch: 5| Step: 7
Training loss: 3.012235164642334
Validation loss: 2.7162248088467504

Epoch: 5| Step: 8
Training loss: 2.6996381282806396
Validation loss: 2.7082942813955326

Epoch: 5| Step: 9
Training loss: 2.9487392902374268
Validation loss: 2.7047230556447017

Epoch: 5| Step: 10
Training loss: 3.190267562866211
Validation loss: 2.7052830675596833

Epoch: 67| Step: 0
Training loss: 3.076244831085205
Validation loss: 2.706203499147969

Epoch: 5| Step: 1
Training loss: 2.8164432048797607
Validation loss: 2.7079173954584266

Epoch: 5| Step: 2
Training loss: 3.0490617752075195
Validation loss: 2.70905779510416

Epoch: 5| Step: 3
Training loss: 3.2750275135040283
Validation loss: 2.7065902833015687

Epoch: 5| Step: 4
Training loss: 2.7314722537994385
Validation loss: 2.702736346952377

Epoch: 5| Step: 5
Training loss: 2.158386707305908
Validation loss: 2.701090730646605

Epoch: 5| Step: 6
Training loss: 3.067768096923828
Validation loss: 2.6993113384451917

Epoch: 5| Step: 7
Training loss: 2.453423023223877
Validation loss: 2.7014811987517984

Epoch: 5| Step: 8
Training loss: 2.590646505355835
Validation loss: 2.7029778752275693

Epoch: 5| Step: 9
Training loss: 2.906684398651123
Validation loss: 2.7046141701359905

Epoch: 5| Step: 10
Training loss: 3.0325927734375
Validation loss: 2.71597191338898

Epoch: 68| Step: 0
Training loss: 3.2698612213134766
Validation loss: 2.70932101690641

Epoch: 5| Step: 1
Training loss: 3.0637688636779785
Validation loss: 2.704713762447398

Epoch: 5| Step: 2
Training loss: 2.6900200843811035
Validation loss: 2.7058409901075464

Epoch: 5| Step: 3
Training loss: 2.939476490020752
Validation loss: 2.7034664718053674

Epoch: 5| Step: 4
Training loss: 2.850310802459717
Validation loss: 2.7123341252726894

Epoch: 5| Step: 5
Training loss: 2.742682695388794
Validation loss: 2.7101246772273893

Epoch: 5| Step: 6
Training loss: 2.7154300212860107
Validation loss: 2.7129963136488393

Epoch: 5| Step: 7
Training loss: 2.8274292945861816
Validation loss: 2.710729886126775

Epoch: 5| Step: 8
Training loss: 2.8874030113220215
Validation loss: 2.7023766374075286

Epoch: 5| Step: 9
Training loss: 2.7607810497283936
Validation loss: 2.6969404579490743

Epoch: 5| Step: 10
Training loss: 2.3209357261657715
Validation loss: 2.702176893911054

Epoch: 69| Step: 0
Training loss: 3.4023261070251465
Validation loss: 2.696357168177123

Epoch: 5| Step: 1
Training loss: 2.0775630474090576
Validation loss: 2.694505445418819

Epoch: 5| Step: 2
Training loss: 3.8119235038757324
Validation loss: 2.698926674422397

Epoch: 5| Step: 3
Training loss: 3.096245527267456
Validation loss: 2.696508966466432

Epoch: 5| Step: 4
Training loss: 3.545527219772339
Validation loss: 2.698802432706279

Epoch: 5| Step: 5
Training loss: 2.0568957328796387
Validation loss: 2.702830401800012

Epoch: 5| Step: 6
Training loss: 2.7425382137298584
Validation loss: 2.698473330466978

Epoch: 5| Step: 7
Training loss: 2.7413814067840576
Validation loss: 2.6985167508484214

Epoch: 5| Step: 8
Training loss: 2.322892189025879
Validation loss: 2.6886846019375708

Epoch: 5| Step: 9
Training loss: 2.844217300415039
Validation loss: 2.6939079300049813

Epoch: 5| Step: 10
Training loss: 2.3340814113616943
Validation loss: 2.6904107370684223

Epoch: 70| Step: 0
Training loss: 2.5635263919830322
Validation loss: 2.691227397611064

Epoch: 5| Step: 1
Training loss: 2.2100799083709717
Validation loss: 2.6945525266790904

Epoch: 5| Step: 2
Training loss: 3.736865520477295
Validation loss: 2.6944172100354264

Epoch: 5| Step: 3
Training loss: 2.9283463954925537
Validation loss: 2.696549892425537

Epoch: 5| Step: 4
Training loss: 2.2857069969177246
Validation loss: 2.7007105401767197

Epoch: 5| Step: 5
Training loss: 3.168999433517456
Validation loss: 2.7031722145695842

Epoch: 5| Step: 6
Training loss: 2.983948230743408
Validation loss: 2.693609901653823

Epoch: 5| Step: 7
Training loss: 2.5341975688934326
Validation loss: 2.688953681658673

Epoch: 5| Step: 8
Training loss: 3.1340878009796143
Validation loss: 2.6885943233325915

Epoch: 5| Step: 9
Training loss: 3.003904342651367
Validation loss: 2.6885421545274797

Epoch: 5| Step: 10
Training loss: 2.404378652572632
Validation loss: 2.6907446717703216

Epoch: 71| Step: 0
Training loss: 2.4922585487365723
Validation loss: 2.6954515236680225

Epoch: 5| Step: 1
Training loss: 2.9113993644714355
Validation loss: 2.6861686655270156

Epoch: 5| Step: 2
Training loss: 2.917264461517334
Validation loss: 2.687517648102135

Epoch: 5| Step: 3
Training loss: 2.7713232040405273
Validation loss: 2.684210536300495

Epoch: 5| Step: 4
Training loss: 2.735715389251709
Validation loss: 2.6829771226452244

Epoch: 5| Step: 5
Training loss: 2.9910199642181396
Validation loss: 2.691154208234561

Epoch: 5| Step: 6
Training loss: 2.151581287384033
Validation loss: 2.6905284184281544

Epoch: 5| Step: 7
Training loss: 3.367037296295166
Validation loss: 2.6912616119589856

Epoch: 5| Step: 8
Training loss: 2.9541828632354736
Validation loss: 2.683547571141233

Epoch: 5| Step: 9
Training loss: 2.882124662399292
Validation loss: 2.683048120108984

Epoch: 5| Step: 10
Training loss: 2.901858329772949
Validation loss: 2.685988172408073

Epoch: 72| Step: 0
Training loss: 2.4275548458099365
Validation loss: 2.6857303778330484

Epoch: 5| Step: 1
Training loss: 3.007599353790283
Validation loss: 2.6875437459638043

Epoch: 5| Step: 2
Training loss: 2.260394334793091
Validation loss: 2.6865957706205306

Epoch: 5| Step: 3
Training loss: 2.9351260662078857
Validation loss: 2.685002624347646

Epoch: 5| Step: 4
Training loss: 1.4797947406768799
Validation loss: 2.6760323227092786

Epoch: 5| Step: 5
Training loss: 3.7398247718811035
Validation loss: 2.6839674595863587

Epoch: 5| Step: 6
Training loss: 2.7485756874084473
Validation loss: 2.6836347938865743

Epoch: 5| Step: 7
Training loss: 3.9487833976745605
Validation loss: 2.690475453612625

Epoch: 5| Step: 8
Training loss: 2.5485455989837646
Validation loss: 2.6839417437071442

Epoch: 5| Step: 9
Training loss: 3.174022674560547
Validation loss: 2.689858798057802

Epoch: 5| Step: 10
Training loss: 2.5663163661956787
Validation loss: 2.6825460567269275

Epoch: 73| Step: 0
Training loss: 2.997298002243042
Validation loss: 2.6912389724485335

Epoch: 5| Step: 1
Training loss: 2.2516775131225586
Validation loss: 2.6891437653572328

Epoch: 5| Step: 2
Training loss: 2.563387393951416
Validation loss: 2.691409441732591

Epoch: 5| Step: 3
Training loss: 3.4464797973632812
Validation loss: 2.7002570244573776

Epoch: 5| Step: 4
Training loss: 2.227175235748291
Validation loss: 2.6983680468733593

Epoch: 5| Step: 5
Training loss: 2.858351230621338
Validation loss: 2.6991895296240367

Epoch: 5| Step: 6
Training loss: 3.0589728355407715
Validation loss: 2.6888699711010022

Epoch: 5| Step: 7
Training loss: 2.591696262359619
Validation loss: 2.685608699757566

Epoch: 5| Step: 8
Training loss: 3.031318187713623
Validation loss: 2.6765820954435613

Epoch: 5| Step: 9
Training loss: 3.2201850414276123
Validation loss: 2.6725603816329793

Epoch: 5| Step: 10
Training loss: 2.58542537689209
Validation loss: 2.674286050181235

Epoch: 74| Step: 0
Training loss: 3.0412204265594482
Validation loss: 2.678736425215198

Epoch: 5| Step: 1
Training loss: 3.3134963512420654
Validation loss: 2.671202490406652

Epoch: 5| Step: 2
Training loss: 2.910008192062378
Validation loss: 2.664245415759343

Epoch: 5| Step: 3
Training loss: 2.974815607070923
Validation loss: 2.6622433188141033

Epoch: 5| Step: 4
Training loss: 2.6307101249694824
Validation loss: 2.668713992641818

Epoch: 5| Step: 5
Training loss: 1.582687497138977
Validation loss: 2.673723946335495

Epoch: 5| Step: 6
Training loss: 2.433922529220581
Validation loss: 2.6748174211030364

Epoch: 5| Step: 7
Training loss: 3.2691216468811035
Validation loss: 2.6807963822477605

Epoch: 5| Step: 8
Training loss: 3.4118850231170654
Validation loss: 2.6870581078272995

Epoch: 5| Step: 9
Training loss: 3.1061062812805176
Validation loss: 2.673742507093696

Epoch: 5| Step: 10
Training loss: 2.161237955093384
Validation loss: 2.6727833363317672

Epoch: 75| Step: 0
Training loss: 2.835134983062744
Validation loss: 2.6773416944729385

Epoch: 5| Step: 1
Training loss: 3.7273335456848145
Validation loss: 2.6893808508432038

Epoch: 5| Step: 2
Training loss: 2.824002742767334
Validation loss: 2.67351427642248

Epoch: 5| Step: 3
Training loss: 3.3654894828796387
Validation loss: 2.6677580341216056

Epoch: 5| Step: 4
Training loss: 2.779705047607422
Validation loss: 2.6602547476368565

Epoch: 5| Step: 5
Training loss: 2.1856601238250732
Validation loss: 2.6531923381231164

Epoch: 5| Step: 6
Training loss: 2.663118839263916
Validation loss: 2.6511774191292385

Epoch: 5| Step: 7
Training loss: 2.1700308322906494
Validation loss: 2.655713886343023

Epoch: 5| Step: 8
Training loss: 2.580286741256714
Validation loss: 2.653787036095896

Epoch: 5| Step: 9
Training loss: 3.2989583015441895
Validation loss: 2.6576038406741236

Epoch: 5| Step: 10
Training loss: 2.2325971126556396
Validation loss: 2.6611109728454263

Epoch: 76| Step: 0
Training loss: 3.258622646331787
Validation loss: 2.650340126406762

Epoch: 5| Step: 1
Training loss: 2.45369291305542
Validation loss: 2.6594175087508334

Epoch: 5| Step: 2
Training loss: 2.8705644607543945
Validation loss: 2.6623039912152033

Epoch: 5| Step: 3
Training loss: 3.2152819633483887
Validation loss: 2.6655833234069166

Epoch: 5| Step: 4
Training loss: 2.096254587173462
Validation loss: 2.6629907443959224

Epoch: 5| Step: 5
Training loss: 2.5188405513763428
Validation loss: 2.6597329672946723

Epoch: 5| Step: 6
Training loss: 2.9000816345214844
Validation loss: 2.6556734756756852

Epoch: 5| Step: 7
Training loss: 2.575655937194824
Validation loss: 2.6640851420740925

Epoch: 5| Step: 8
Training loss: 2.918731689453125
Validation loss: 2.6650436180894093

Epoch: 5| Step: 9
Training loss: 2.6441802978515625
Validation loss: 2.6779397021057787

Epoch: 5| Step: 10
Training loss: 3.2816455364227295
Validation loss: 2.681855529867193

Epoch: 77| Step: 0
Training loss: 2.68037748336792
Validation loss: 2.6931366151379

Epoch: 5| Step: 1
Training loss: 3.299748182296753
Validation loss: 2.6887275121545278

Epoch: 5| Step: 2
Training loss: 2.4494080543518066
Validation loss: 2.6707144142479025

Epoch: 5| Step: 3
Training loss: 2.6546530723571777
Validation loss: 2.6588991867598666

Epoch: 5| Step: 4
Training loss: 2.477813720703125
Validation loss: 2.6515950695160897

Epoch: 5| Step: 5
Training loss: 2.7254161834716797
Validation loss: 2.6490044862993303

Epoch: 5| Step: 6
Training loss: 2.54725980758667
Validation loss: 2.6535563827842794

Epoch: 5| Step: 7
Training loss: 2.92106294631958
Validation loss: 2.650071269722395

Epoch: 5| Step: 8
Training loss: 2.9428796768188477
Validation loss: 2.653906209494478

Epoch: 5| Step: 9
Training loss: 2.847710371017456
Validation loss: 2.6537071607446157

Epoch: 5| Step: 10
Training loss: 3.2323150634765625
Validation loss: 2.650439654627154

Epoch: 78| Step: 0
Training loss: 3.2576611042022705
Validation loss: 2.6572942426127772

Epoch: 5| Step: 1
Training loss: 2.259260892868042
Validation loss: 2.6506121235509075

Epoch: 5| Step: 2
Training loss: 2.495518922805786
Validation loss: 2.645080480524289

Epoch: 5| Step: 3
Training loss: 2.9890403747558594
Validation loss: 2.6449594856590353

Epoch: 5| Step: 4
Training loss: 3.1577839851379395
Validation loss: 2.64778890661014

Epoch: 5| Step: 5
Training loss: 2.9842417240142822
Validation loss: 2.6424093118277927

Epoch: 5| Step: 6
Training loss: 2.778454303741455
Validation loss: 2.64973404330592

Epoch: 5| Step: 7
Training loss: 3.191437244415283
Validation loss: 2.6463195585435435

Epoch: 5| Step: 8
Training loss: 2.7585020065307617
Validation loss: 2.646367101259129

Epoch: 5| Step: 9
Training loss: 2.230117082595825
Validation loss: 2.650905406603249

Epoch: 5| Step: 10
Training loss: 2.4954850673675537
Validation loss: 2.6496767459377164

Epoch: 79| Step: 0
Training loss: 2.5551180839538574
Validation loss: 2.6645710775929112

Epoch: 5| Step: 1
Training loss: 2.430668830871582
Validation loss: 2.6756348840651976

Epoch: 5| Step: 2
Training loss: 3.156381607055664
Validation loss: 2.678834899779289

Epoch: 5| Step: 3
Training loss: 2.6863722801208496
Validation loss: 2.676921252281435

Epoch: 5| Step: 4
Training loss: 3.2386157512664795
Validation loss: 2.688351510673441

Epoch: 5| Step: 5
Training loss: 2.5944933891296387
Validation loss: 2.6769291072763424

Epoch: 5| Step: 6
Training loss: 3.2422852516174316
Validation loss: 2.6785828221228813

Epoch: 5| Step: 7
Training loss: 2.800910711288452
Validation loss: 2.672776522174958

Epoch: 5| Step: 8
Training loss: 2.440340518951416
Validation loss: 2.6686333456347064

Epoch: 5| Step: 9
Training loss: 2.5907208919525146
Validation loss: 2.649076302846273

Epoch: 5| Step: 10
Training loss: 2.8668878078460693
Validation loss: 2.6443497519339285

Epoch: 80| Step: 0
Training loss: 2.3127059936523438
Validation loss: 2.642323070956815

Epoch: 5| Step: 1
Training loss: 2.762789011001587
Validation loss: 2.649850276208693

Epoch: 5| Step: 2
Training loss: 2.360365390777588
Validation loss: 2.6574329073711107

Epoch: 5| Step: 3
Training loss: 2.290663242340088
Validation loss: 2.6633814534833355

Epoch: 5| Step: 4
Training loss: 3.2582383155822754
Validation loss: 2.657810334236391

Epoch: 5| Step: 5
Training loss: 2.778625011444092
Validation loss: 2.6572503735942226

Epoch: 5| Step: 6
Training loss: 3.4723899364471436
Validation loss: 2.6520884139563448

Epoch: 5| Step: 7
Training loss: 3.0535173416137695
Validation loss: 2.6485061055870465

Epoch: 5| Step: 8
Training loss: 1.6439632177352905
Validation loss: 2.641013232610559

Epoch: 5| Step: 9
Training loss: 3.7246861457824707
Validation loss: 2.638487431310838

Epoch: 5| Step: 10
Training loss: 2.8731391429901123
Validation loss: 2.6403648635392547

Epoch: 81| Step: 0
Training loss: 2.8078064918518066
Validation loss: 2.639495631699921

Epoch: 5| Step: 1
Training loss: 2.8538103103637695
Validation loss: 2.640147711641045

Epoch: 5| Step: 2
Training loss: 2.7451329231262207
Validation loss: 2.642803051138437

Epoch: 5| Step: 3
Training loss: 2.53645658493042
Validation loss: 2.6394536315753894

Epoch: 5| Step: 4
Training loss: 3.7499260902404785
Validation loss: 2.6426414930692284

Epoch: 5| Step: 5
Training loss: 2.8566126823425293
Validation loss: 2.6485295193169707

Epoch: 5| Step: 6
Training loss: 3.009575366973877
Validation loss: 2.6484707145280737

Epoch: 5| Step: 7
Training loss: 2.3822216987609863
Validation loss: 2.6519311012760287

Epoch: 5| Step: 8
Training loss: 2.8372697830200195
Validation loss: 2.6460913201814056

Epoch: 5| Step: 9
Training loss: 2.5766005516052246
Validation loss: 2.653380883637295

Epoch: 5| Step: 10
Training loss: 1.9897799491882324
Validation loss: 2.6455195206467823

Epoch: 82| Step: 0
Training loss: 2.5702927112579346
Validation loss: 2.657102464347757

Epoch: 5| Step: 1
Training loss: 2.964693784713745
Validation loss: 2.6616640706216135

Epoch: 5| Step: 2
Training loss: 2.3816866874694824
Validation loss: 2.6664062571781937

Epoch: 5| Step: 3
Training loss: 2.8089611530303955
Validation loss: 2.6580235906826553

Epoch: 5| Step: 4
Training loss: 2.6738789081573486
Validation loss: 2.6538806602519047

Epoch: 5| Step: 5
Training loss: 2.9930214881896973
Validation loss: 2.6537816293777956

Epoch: 5| Step: 6
Training loss: 2.5512688159942627
Validation loss: 2.6412673586158344

Epoch: 5| Step: 7
Training loss: 3.034193277359009
Validation loss: 2.6351446631134197

Epoch: 5| Step: 8
Training loss: 2.5024192333221436
Validation loss: 2.6317769609471804

Epoch: 5| Step: 9
Training loss: 3.4355010986328125
Validation loss: 2.635111265285041

Epoch: 5| Step: 10
Training loss: 2.5535666942596436
Validation loss: 2.63474549529373

Epoch: 83| Step: 0
Training loss: 2.5836029052734375
Validation loss: 2.6397618452707925

Epoch: 5| Step: 1
Training loss: 2.5825693607330322
Validation loss: 2.6410299731839086

Epoch: 5| Step: 2
Training loss: 2.416645050048828
Validation loss: 2.631417730803131

Epoch: 5| Step: 3
Training loss: 3.4652717113494873
Validation loss: 2.6385557677156184

Epoch: 5| Step: 4
Training loss: 3.0086159706115723
Validation loss: 2.6451852834352882

Epoch: 5| Step: 5
Training loss: 2.4927542209625244
Validation loss: 2.64729820271974

Epoch: 5| Step: 6
Training loss: 3.1728217601776123
Validation loss: 2.654901260970741

Epoch: 5| Step: 7
Training loss: 2.4533753395080566
Validation loss: 2.659190616300029

Epoch: 5| Step: 8
Training loss: 2.683642864227295
Validation loss: 2.649725447418869

Epoch: 5| Step: 9
Training loss: 2.2051384449005127
Validation loss: 2.6449250123834096

Epoch: 5| Step: 10
Training loss: 3.5628719329833984
Validation loss: 2.6370850686104066

Epoch: 84| Step: 0
Training loss: 2.548724412918091
Validation loss: 2.630692312794347

Epoch: 5| Step: 1
Training loss: 2.6020309925079346
Validation loss: 2.630564702454434

Epoch: 5| Step: 2
Training loss: 2.8280491828918457
Validation loss: 2.6349129061545096

Epoch: 5| Step: 3
Training loss: 2.161132335662842
Validation loss: 2.6357537546465473

Epoch: 5| Step: 4
Training loss: 2.6681365966796875
Validation loss: 2.645773215960431

Epoch: 5| Step: 5
Training loss: 3.335395336151123
Validation loss: 2.647093362705682

Epoch: 5| Step: 6
Training loss: 3.5446391105651855
Validation loss: 2.63287434270305

Epoch: 5| Step: 7
Training loss: 3.0642638206481934
Validation loss: 2.6251493500125025

Epoch: 5| Step: 8
Training loss: 2.358243465423584
Validation loss: 2.633168725557225

Epoch: 5| Step: 9
Training loss: 2.498495578765869
Validation loss: 2.6208944730861212

Epoch: 5| Step: 10
Training loss: 2.9576163291931152
Validation loss: 2.623731602904617

Epoch: 85| Step: 0
Training loss: 3.1077613830566406
Validation loss: 2.6242881000682874

Epoch: 5| Step: 1
Training loss: 3.154829263687134
Validation loss: 2.6371269584983907

Epoch: 5| Step: 2
Training loss: 2.4159114360809326
Validation loss: 2.6334926107878327

Epoch: 5| Step: 3
Training loss: 2.290590524673462
Validation loss: 2.6332770470649964

Epoch: 5| Step: 4
Training loss: 2.5505518913269043
Validation loss: 2.6300704351035495

Epoch: 5| Step: 5
Training loss: 2.3081839084625244
Validation loss: 2.6240148621220745

Epoch: 5| Step: 6
Training loss: 2.7604148387908936
Validation loss: 2.6284315175907587

Epoch: 5| Step: 7
Training loss: 2.7412753105163574
Validation loss: 2.640710178241935

Epoch: 5| Step: 8
Training loss: 3.2071692943573
Validation loss: 2.648711258365262

Epoch: 5| Step: 9
Training loss: 2.9159157276153564
Validation loss: 2.6642479588908534

Epoch: 5| Step: 10
Training loss: 3.0076911449432373
Validation loss: 2.676940564186342

Epoch: 86| Step: 0
Training loss: 2.6121277809143066
Validation loss: 2.688511786922332

Epoch: 5| Step: 1
Training loss: 3.3116517066955566
Validation loss: 2.6960729527217087

Epoch: 5| Step: 2
Training loss: 2.7305359840393066
Validation loss: 2.6662358930034022

Epoch: 5| Step: 3
Training loss: 3.5895016193389893
Validation loss: 2.642409486155356

Epoch: 5| Step: 4
Training loss: 2.6449766159057617
Validation loss: 2.6259241334853636

Epoch: 5| Step: 5
Training loss: 2.633488178253174
Validation loss: 2.6262429760348414

Epoch: 5| Step: 6
Training loss: 2.622844696044922
Validation loss: 2.6323422334527455

Epoch: 5| Step: 7
Training loss: 2.7535576820373535
Validation loss: 2.6349866287682646

Epoch: 5| Step: 8
Training loss: 2.5944504737854004
Validation loss: 2.6382849626643683

Epoch: 5| Step: 9
Training loss: 2.686168670654297
Validation loss: 2.636596618160125

Epoch: 5| Step: 10
Training loss: 2.2312843799591064
Validation loss: 2.6239898384258313

Epoch: 87| Step: 0
Training loss: 2.197263717651367
Validation loss: 2.6209971597117763

Epoch: 5| Step: 1
Training loss: 2.9129438400268555
Validation loss: 2.624047786958756

Epoch: 5| Step: 2
Training loss: 2.224595069885254
Validation loss: 2.623137210005073

Epoch: 5| Step: 3
Training loss: 3.7056899070739746
Validation loss: 2.6233059180680143

Epoch: 5| Step: 4
Training loss: 3.5241103172302246
Validation loss: 2.62058400723242

Epoch: 5| Step: 5
Training loss: 2.9331493377685547
Validation loss: 2.615679576832761

Epoch: 5| Step: 6
Training loss: 2.6544671058654785
Validation loss: 2.6168531935702086

Epoch: 5| Step: 7
Training loss: 2.2401819229125977
Validation loss: 2.626818774848856

Epoch: 5| Step: 8
Training loss: 2.556952953338623
Validation loss: 2.6197943661802556

Epoch: 5| Step: 9
Training loss: 2.6330320835113525
Validation loss: 2.6245715541224324

Epoch: 5| Step: 10
Training loss: 2.729743480682373
Validation loss: 2.632627489746258

Epoch: 88| Step: 0
Training loss: 3.521907329559326
Validation loss: 2.6459065842372116

Epoch: 5| Step: 1
Training loss: 2.5102462768554688
Validation loss: 2.64972274790528

Epoch: 5| Step: 2
Training loss: 2.856618881225586
Validation loss: 2.650682977450791

Epoch: 5| Step: 3
Training loss: 2.4121506214141846
Validation loss: 2.653230990132978

Epoch: 5| Step: 4
Training loss: 3.0845279693603516
Validation loss: 2.6510226829077608

Epoch: 5| Step: 5
Training loss: 3.133270263671875
Validation loss: 2.6354454281509563

Epoch: 5| Step: 6
Training loss: 2.6382458209991455
Validation loss: 2.6280167589905443

Epoch: 5| Step: 7
Training loss: 2.9145820140838623
Validation loss: 2.6394053325858167

Epoch: 5| Step: 8
Training loss: 2.6455137729644775
Validation loss: 2.638255460287935

Epoch: 5| Step: 9
Training loss: 2.332005023956299
Validation loss: 2.639841684731104

Epoch: 5| Step: 10
Training loss: 2.2951204776763916
Validation loss: 2.641731390389063

Epoch: 89| Step: 0
Training loss: 2.536534547805786
Validation loss: 2.6509967516827326

Epoch: 5| Step: 1
Training loss: 2.4206724166870117
Validation loss: 2.6544720639464674

Epoch: 5| Step: 2
Training loss: 3.6095573902130127
Validation loss: 2.6617793113954606

Epoch: 5| Step: 3
Training loss: 2.491921901702881
Validation loss: 2.6602635588697208

Epoch: 5| Step: 4
Training loss: 3.4565587043762207
Validation loss: 2.6519147990852274

Epoch: 5| Step: 5
Training loss: 2.6840972900390625
Validation loss: 2.6371055802991314

Epoch: 5| Step: 6
Training loss: 2.8595385551452637
Validation loss: 2.6247156794353197

Epoch: 5| Step: 7
Training loss: 2.4692060947418213
Validation loss: 2.6186534743155203

Epoch: 5| Step: 8
Training loss: 2.416395664215088
Validation loss: 2.6145578199817288

Epoch: 5| Step: 9
Training loss: 2.3480424880981445
Validation loss: 2.6130697214475243

Epoch: 5| Step: 10
Training loss: 3.394033432006836
Validation loss: 2.6160926613756406

Epoch: 90| Step: 0
Training loss: 2.7578952312469482
Validation loss: 2.623588882466798

Epoch: 5| Step: 1
Training loss: 2.227283477783203
Validation loss: 2.6224772135416665

Epoch: 5| Step: 2
Training loss: 2.245391845703125
Validation loss: 2.622393992639357

Epoch: 5| Step: 3
Training loss: 3.1598870754241943
Validation loss: 2.6212528546651206

Epoch: 5| Step: 4
Training loss: 3.1130902767181396
Validation loss: 2.6244307615423716

Epoch: 5| Step: 5
Training loss: 2.6447536945343018
Validation loss: 2.6217026941237913

Epoch: 5| Step: 6
Training loss: 2.396672248840332
Validation loss: 2.619735512682187

Epoch: 5| Step: 7
Training loss: 3.4126243591308594
Validation loss: 2.6223758574455016

Epoch: 5| Step: 8
Training loss: 2.577004909515381
Validation loss: 2.6230783257433163

Epoch: 5| Step: 9
Training loss: 2.7631003856658936
Validation loss: 2.628017287100515

Epoch: 5| Step: 10
Training loss: 3.1702933311462402
Validation loss: 2.632256543764504

Epoch: 91| Step: 0
Training loss: 3.010500431060791
Validation loss: 2.6232042440804104

Epoch: 5| Step: 1
Training loss: 2.332594871520996
Validation loss: 2.6324897261076075

Epoch: 5| Step: 2
Training loss: 2.701854944229126
Validation loss: 2.63636367295378

Epoch: 5| Step: 3
Training loss: 3.1875758171081543
Validation loss: 2.6416188491288053

Epoch: 5| Step: 4
Training loss: 2.4727606773376465
Validation loss: 2.64076970213203

Epoch: 5| Step: 5
Training loss: 2.5074257850646973
Validation loss: 2.656129603744835

Epoch: 5| Step: 6
Training loss: 2.6981163024902344
Validation loss: 2.6455016059260212

Epoch: 5| Step: 7
Training loss: 2.879437208175659
Validation loss: 2.654192691208214

Epoch: 5| Step: 8
Training loss: 3.037461519241333
Validation loss: 2.668096250103366

Epoch: 5| Step: 9
Training loss: 2.7519421577453613
Validation loss: 2.653347171762938

Epoch: 5| Step: 10
Training loss: 2.93001651763916
Validation loss: 2.614194690540273

Epoch: 92| Step: 0
Training loss: 3.409510374069214
Validation loss: 2.605805878998131

Epoch: 5| Step: 1
Training loss: 2.121574878692627
Validation loss: 2.6061326560153755

Epoch: 5| Step: 2
Training loss: 2.765972137451172
Validation loss: 2.6102519445521857

Epoch: 5| Step: 3
Training loss: 3.445695400238037
Validation loss: 2.610738695308726

Epoch: 5| Step: 4
Training loss: 3.0049970149993896
Validation loss: 2.6180867789894022

Epoch: 5| Step: 5
Training loss: 1.994629144668579
Validation loss: 2.6210254135952202

Epoch: 5| Step: 6
Training loss: 2.587717294692993
Validation loss: 2.6210466559215257

Epoch: 5| Step: 7
Training loss: 2.778224229812622
Validation loss: 2.6154460804436797

Epoch: 5| Step: 8
Training loss: 3.0286571979522705
Validation loss: 2.6184995430772022

Epoch: 5| Step: 9
Training loss: 2.459810733795166
Validation loss: 2.610113036247992

Epoch: 5| Step: 10
Training loss: 2.738417863845825
Validation loss: 2.603156384601388

Epoch: 93| Step: 0
Training loss: 3.4719767570495605
Validation loss: 2.605743836331111

Epoch: 5| Step: 1
Training loss: 1.6964269876480103
Validation loss: 2.602692529719363

Epoch: 5| Step: 2
Training loss: 2.8914132118225098
Validation loss: 2.6032992280939573

Epoch: 5| Step: 3
Training loss: 2.9952893257141113
Validation loss: 2.6074545844908683

Epoch: 5| Step: 4
Training loss: 2.084940195083618
Validation loss: 2.61164677527643

Epoch: 5| Step: 5
Training loss: 2.8841021060943604
Validation loss: 2.613478014546056

Epoch: 5| Step: 6
Training loss: 2.970629930496216
Validation loss: 2.6172235422236945

Epoch: 5| Step: 7
Training loss: 2.860372543334961
Validation loss: 2.6272138318707867

Epoch: 5| Step: 8
Training loss: 2.6373331546783447
Validation loss: 2.611794143594721

Epoch: 5| Step: 9
Training loss: 2.8868484497070312
Validation loss: 2.6019243066028883

Epoch: 5| Step: 10
Training loss: 2.91916823387146
Validation loss: 2.604792789746356

Epoch: 94| Step: 0
Training loss: 2.253988742828369
Validation loss: 2.595769336146693

Epoch: 5| Step: 1
Training loss: 2.467669725418091
Validation loss: 2.5995138947681715

Epoch: 5| Step: 2
Training loss: 3.3783302307128906
Validation loss: 2.6018596413314983

Epoch: 5| Step: 3
Training loss: 3.2086246013641357
Validation loss: 2.6054636765551824

Epoch: 5| Step: 4
Training loss: 2.1966755390167236
Validation loss: 2.605209988932456

Epoch: 5| Step: 5
Training loss: 2.951939344406128
Validation loss: 2.60770744662131

Epoch: 5| Step: 6
Training loss: 2.1206016540527344
Validation loss: 2.6038020759500484

Epoch: 5| Step: 7
Training loss: 2.748706340789795
Validation loss: 2.6030594200216313

Epoch: 5| Step: 8
Training loss: 2.8740406036376953
Validation loss: 2.60710007913651

Epoch: 5| Step: 9
Training loss: 3.0775692462921143
Validation loss: 2.6023610125305834

Epoch: 5| Step: 10
Training loss: 3.0608701705932617
Validation loss: 2.6026845721788305

Epoch: 95| Step: 0
Training loss: 2.4605603218078613
Validation loss: 2.601125440289897

Epoch: 5| Step: 1
Training loss: 2.553071975708008
Validation loss: 2.60324949859291

Epoch: 5| Step: 2
Training loss: 2.66031813621521
Validation loss: 2.6172348350606938

Epoch: 5| Step: 3
Training loss: 3.7330799102783203
Validation loss: 2.624701743484825

Epoch: 5| Step: 4
Training loss: 3.0467875003814697
Validation loss: 2.635165911848827

Epoch: 5| Step: 5
Training loss: 2.4737629890441895
Validation loss: 2.6364370417851273

Epoch: 5| Step: 6
Training loss: 2.4973433017730713
Validation loss: 2.635524660028437

Epoch: 5| Step: 7
Training loss: 3.370018482208252
Validation loss: 2.6243893920734362

Epoch: 5| Step: 8
Training loss: 2.8100790977478027
Validation loss: 2.6158322057416363

Epoch: 5| Step: 9
Training loss: 2.8368258476257324
Validation loss: 2.602690860789309

Epoch: 5| Step: 10
Training loss: 1.7536728382110596
Validation loss: 2.5937936305999756

Epoch: 96| Step: 0
Training loss: 2.528853178024292
Validation loss: 2.5932338929945424

Epoch: 5| Step: 1
Training loss: 3.193108320236206
Validation loss: 2.592976870075349

Epoch: 5| Step: 2
Training loss: 3.5731301307678223
Validation loss: 2.5939529941928003

Epoch: 5| Step: 3
Training loss: 2.6108903884887695
Validation loss: 2.592878786466455

Epoch: 5| Step: 4
Training loss: 2.336718797683716
Validation loss: 2.592799466143372

Epoch: 5| Step: 5
Training loss: 2.574611186981201
Validation loss: 2.587806104331888

Epoch: 5| Step: 6
Training loss: 2.515465497970581
Validation loss: 2.592242956161499

Epoch: 5| Step: 7
Training loss: 2.5836939811706543
Validation loss: 2.594077184636106

Epoch: 5| Step: 8
Training loss: 2.7324862480163574
Validation loss: 2.5944744720253894

Epoch: 5| Step: 9
Training loss: 2.8859734535217285
Validation loss: 2.5993249800897416

Epoch: 5| Step: 10
Training loss: 2.7508907318115234
Validation loss: 2.6003966972392094

Epoch: 97| Step: 0
Training loss: 2.874194383621216
Validation loss: 2.5916667984377955

Epoch: 5| Step: 1
Training loss: 3.5313353538513184
Validation loss: 2.592087555957097

Epoch: 5| Step: 2
Training loss: 2.6107540130615234
Validation loss: 2.591188712786603

Epoch: 5| Step: 3
Training loss: 2.644106149673462
Validation loss: 2.5977108606728176

Epoch: 5| Step: 4
Training loss: 2.839974880218506
Validation loss: 2.600645967709121

Epoch: 5| Step: 5
Training loss: 3.218655824661255
Validation loss: 2.6098174459190777

Epoch: 5| Step: 6
Training loss: 2.3134264945983887
Validation loss: 2.6184578198258595

Epoch: 5| Step: 7
Training loss: 2.243040084838867
Validation loss: 2.6253523108779744

Epoch: 5| Step: 8
Training loss: 2.5722696781158447
Validation loss: 2.6210379241615214

Epoch: 5| Step: 9
Training loss: 2.8439624309539795
Validation loss: 2.606695634062572

Epoch: 5| Step: 10
Training loss: 2.4734110832214355
Validation loss: 2.596789301082652

Epoch: 98| Step: 0
Training loss: 2.969198226928711
Validation loss: 2.594555865051926

Epoch: 5| Step: 1
Training loss: 2.59678316116333
Validation loss: 2.589526258489137

Epoch: 5| Step: 2
Training loss: 2.170077323913574
Validation loss: 2.5865792587239254

Epoch: 5| Step: 3
Training loss: 2.7609703540802
Validation loss: 2.589718508464034

Epoch: 5| Step: 4
Training loss: 2.4614367485046387
Validation loss: 2.597725050423735

Epoch: 5| Step: 5
Training loss: 2.3913826942443848
Validation loss: 2.611718454668599

Epoch: 5| Step: 6
Training loss: 2.736173629760742
Validation loss: 2.6025852490496892

Epoch: 5| Step: 7
Training loss: 2.79217791557312
Validation loss: 2.6050657815830682

Epoch: 5| Step: 8
Training loss: 3.242602586746216
Validation loss: 2.601518146453365

Epoch: 5| Step: 9
Training loss: 3.4149742126464844
Validation loss: 2.5996653290205103

Epoch: 5| Step: 10
Training loss: 2.628516674041748
Validation loss: 2.6107193962220223

Epoch: 99| Step: 0
Training loss: 2.6781930923461914
Validation loss: 2.6196287626861245

Epoch: 5| Step: 1
Training loss: 2.0039703845977783
Validation loss: 2.6310300365571053

Epoch: 5| Step: 2
Training loss: 3.6449074745178223
Validation loss: 2.6297205827569448

Epoch: 5| Step: 3
Training loss: 2.610970973968506
Validation loss: 2.624903742985059

Epoch: 5| Step: 4
Training loss: 3.0856127738952637
Validation loss: 2.6046938921815608

Epoch: 5| Step: 5
Training loss: 3.056191921234131
Validation loss: 2.5992688389234644

Epoch: 5| Step: 6
Training loss: 3.1167616844177246
Validation loss: 2.597511755522861

Epoch: 5| Step: 7
Training loss: 3.5037028789520264
Validation loss: 2.5901049567807104

Epoch: 5| Step: 8
Training loss: 2.3578319549560547
Validation loss: 2.5880780963487524

Epoch: 5| Step: 9
Training loss: 1.7489084005355835
Validation loss: 2.5846904118855796

Epoch: 5| Step: 10
Training loss: 2.3455312252044678
Validation loss: 2.5886177888480564

Epoch: 100| Step: 0
Training loss: 3.210963487625122
Validation loss: 2.5861677456927556

Epoch: 5| Step: 1
Training loss: 2.9437739849090576
Validation loss: 2.5832997137500393

Epoch: 5| Step: 2
Training loss: 2.7592716217041016
Validation loss: 2.585195243999522

Epoch: 5| Step: 3
Training loss: 3.807814359664917
Validation loss: 2.592420977930869

Epoch: 5| Step: 4
Training loss: 2.682595729827881
Validation loss: 2.5914083373162056

Epoch: 5| Step: 5
Training loss: 2.2850635051727295
Validation loss: 2.591638445854187

Epoch: 5| Step: 6
Training loss: 2.2895760536193848
Validation loss: 2.5854023220718547

Epoch: 5| Step: 7
Training loss: 3.615294933319092
Validation loss: 2.582165887278895

Epoch: 5| Step: 8
Training loss: 2.0169358253479004
Validation loss: 2.5826591958281813

Epoch: 5| Step: 9
Training loss: 2.228970527648926
Validation loss: 2.5845359602282123

Epoch: 5| Step: 10
Training loss: 2.1862618923187256
Validation loss: 2.5829077330968713

Epoch: 101| Step: 0
Training loss: 2.8526418209075928
Validation loss: 2.585856278737386

Epoch: 5| Step: 1
Training loss: 3.121152877807617
Validation loss: 2.5941881031118412

Epoch: 5| Step: 2
Training loss: 2.939724922180176
Validation loss: 2.595324203532229

Epoch: 5| Step: 3
Training loss: 2.6159186363220215
Validation loss: 2.6006823098787697

Epoch: 5| Step: 4
Training loss: 3.616142749786377
Validation loss: 2.600155620164769

Epoch: 5| Step: 5
Training loss: 2.474271535873413
Validation loss: 2.5971141399875766

Epoch: 5| Step: 6
Training loss: 2.198793888092041
Validation loss: 2.5909069122806674

Epoch: 5| Step: 7
Training loss: 2.504427433013916
Validation loss: 2.587513231462048

Epoch: 5| Step: 8
Training loss: 2.4308431148529053
Validation loss: 2.5830029005645425

Epoch: 5| Step: 9
Training loss: 2.5521068572998047
Validation loss: 2.5866562063976

Epoch: 5| Step: 10
Training loss: 2.7711100578308105
Validation loss: 2.5882423231678624

Epoch: 102| Step: 0
Training loss: 2.7182140350341797
Validation loss: 2.5940754772514425

Epoch: 5| Step: 1
Training loss: 2.878950834274292
Validation loss: 2.591895664891889

Epoch: 5| Step: 2
Training loss: 2.080057144165039
Validation loss: 2.592864454433482

Epoch: 5| Step: 3
Training loss: 2.8050620555877686
Validation loss: 2.5893716837770198

Epoch: 5| Step: 4
Training loss: 2.74603533744812
Validation loss: 2.599008083343506

Epoch: 5| Step: 5
Training loss: 3.0115580558776855
Validation loss: 2.593649584759948

Epoch: 5| Step: 6
Training loss: 2.880394458770752
Validation loss: 2.590363907557662

Epoch: 5| Step: 7
Training loss: 1.8526170253753662
Validation loss: 2.597202234370734

Epoch: 5| Step: 8
Training loss: 3.2957139015197754
Validation loss: 2.6015778382619223

Epoch: 5| Step: 9
Training loss: 3.057013988494873
Validation loss: 2.6122347360016196

Epoch: 5| Step: 10
Training loss: 2.6353840827941895
Validation loss: 2.6103140846375497

Epoch: 103| Step: 0
Training loss: 3.5120208263397217
Validation loss: 2.612195461027084

Epoch: 5| Step: 1
Training loss: 3.4362270832061768
Validation loss: 2.606923754497241

Epoch: 5| Step: 2
Training loss: 2.5941712856292725
Validation loss: 2.6076950180915093

Epoch: 5| Step: 3
Training loss: 2.4185290336608887
Validation loss: 2.599590973187518

Epoch: 5| Step: 4
Training loss: 3.089259624481201
Validation loss: 2.59329213634614

Epoch: 5| Step: 5
Training loss: 2.37886381149292
Validation loss: 2.5987223245764293

Epoch: 5| Step: 6
Training loss: 2.1927685737609863
Validation loss: 2.5882511933644614

Epoch: 5| Step: 7
Training loss: 3.124641180038452
Validation loss: 2.592343197073988

Epoch: 5| Step: 8
Training loss: 2.3662729263305664
Validation loss: 2.58532811749366

Epoch: 5| Step: 9
Training loss: 2.5591843128204346
Validation loss: 2.5819524308686614

Epoch: 5| Step: 10
Training loss: 2.2906758785247803
Validation loss: 2.570873068224999

Epoch: 104| Step: 0
Training loss: 2.7415831089019775
Validation loss: 2.5744391205490276

Epoch: 5| Step: 1
Training loss: 2.3801751136779785
Validation loss: 2.5827314904941026

Epoch: 5| Step: 2
Training loss: 2.467996835708618
Validation loss: 2.586525358179564

Epoch: 5| Step: 3
Training loss: 2.786344528198242
Validation loss: 2.58562946063216

Epoch: 5| Step: 4
Training loss: 2.7330236434936523
Validation loss: 2.5783162732278146

Epoch: 5| Step: 5
Training loss: 2.7546212673187256
Validation loss: 2.5837185177751767

Epoch: 5| Step: 6
Training loss: 2.552058219909668
Validation loss: 2.5811323811930995

Epoch: 5| Step: 7
Training loss: 3.0754647254943848
Validation loss: 2.5841712951660156

Epoch: 5| Step: 8
Training loss: 2.8516571521759033
Validation loss: 2.5927771829789683

Epoch: 5| Step: 9
Training loss: 2.8821418285369873
Validation loss: 2.5909998621991885

Epoch: 5| Step: 10
Training loss: 2.69183611869812
Validation loss: 2.602878180883264

Epoch: 105| Step: 0
Training loss: 2.2226245403289795
Validation loss: 2.6171006079643004

Epoch: 5| Step: 1
Training loss: 2.9756555557250977
Validation loss: 2.616825424214845

Epoch: 5| Step: 2
Training loss: 2.2904934883117676
Validation loss: 2.608697268270677

Epoch: 5| Step: 3
Training loss: 1.8571783304214478
Validation loss: 2.599043489784323

Epoch: 5| Step: 4
Training loss: 2.8866448402404785
Validation loss: 2.5997309043843257

Epoch: 5| Step: 5
Training loss: 3.3534674644470215
Validation loss: 2.5969776594510643

Epoch: 5| Step: 6
Training loss: 2.3448991775512695
Validation loss: 2.5937394249823784

Epoch: 5| Step: 7
Training loss: 3.065110683441162
Validation loss: 2.6059368630891204

Epoch: 5| Step: 8
Training loss: 2.6663012504577637
Validation loss: 2.59202245743044

Epoch: 5| Step: 9
Training loss: 2.934328079223633
Validation loss: 2.579407048481767

Epoch: 5| Step: 10
Training loss: 3.3521535396575928
Validation loss: 2.57212253796157

Epoch: 106| Step: 0
Training loss: 2.8626809120178223
Validation loss: 2.569562981205602

Epoch: 5| Step: 1
Training loss: 2.6985793113708496
Validation loss: 2.569493232234832

Epoch: 5| Step: 2
Training loss: 2.0555200576782227
Validation loss: 2.5657606509424027

Epoch: 5| Step: 3
Training loss: 2.6164028644561768
Validation loss: 2.570866843705536

Epoch: 5| Step: 4
Training loss: 2.7792747020721436
Validation loss: 2.567843416685699

Epoch: 5| Step: 5
Training loss: 2.0233540534973145
Validation loss: 2.5778817899765505

Epoch: 5| Step: 6
Training loss: 2.980591058731079
Validation loss: 2.57360755243609

Epoch: 5| Step: 7
Training loss: 2.8020732402801514
Validation loss: 2.590500739312941

Epoch: 5| Step: 8
Training loss: 2.9693970680236816
Validation loss: 2.610651708418323

Epoch: 5| Step: 9
Training loss: 2.6183063983917236
Validation loss: 2.6247424925527265

Epoch: 5| Step: 10
Training loss: 3.7231154441833496
Validation loss: 2.6110751064874793

Epoch: 107| Step: 0
Training loss: 3.007401943206787
Validation loss: 2.5836070891349547

Epoch: 5| Step: 1
Training loss: 2.9062399864196777
Validation loss: 2.570488094001688

Epoch: 5| Step: 2
Training loss: 2.7410311698913574
Validation loss: 2.565473520627586

Epoch: 5| Step: 3
Training loss: 2.1859545707702637
Validation loss: 2.571362454404113

Epoch: 5| Step: 4
Training loss: 2.6034538745880127
Validation loss: 2.5744425686456824

Epoch: 5| Step: 5
Training loss: 2.163529396057129
Validation loss: 2.571493569240775

Epoch: 5| Step: 6
Training loss: 2.9308085441589355
Validation loss: 2.5776425535960863

Epoch: 5| Step: 7
Training loss: 3.3030447959899902
Validation loss: 2.5805058171672206

Epoch: 5| Step: 8
Training loss: 2.691258192062378
Validation loss: 2.5863436755313667

Epoch: 5| Step: 9
Training loss: 2.970614194869995
Validation loss: 2.5798477254888064

Epoch: 5| Step: 10
Training loss: 2.2781848907470703
Validation loss: 2.578615385998962

Epoch: 108| Step: 0
Training loss: 2.2093873023986816
Validation loss: 2.5814288559780327

Epoch: 5| Step: 1
Training loss: 3.822305202484131
Validation loss: 2.593031885803387

Epoch: 5| Step: 2
Training loss: 2.3874619007110596
Validation loss: 2.5916740894317627

Epoch: 5| Step: 3
Training loss: 2.6694836616516113
Validation loss: 2.5964656465797016

Epoch: 5| Step: 4
Training loss: 2.9590628147125244
Validation loss: 2.585457550582065

Epoch: 5| Step: 5
Training loss: 2.4790568351745605
Validation loss: 2.5917763992022445

Epoch: 5| Step: 6
Training loss: 3.0180253982543945
Validation loss: 2.579116711052515

Epoch: 5| Step: 7
Training loss: 2.807077407836914
Validation loss: 2.5753746468533754

Epoch: 5| Step: 8
Training loss: 2.1954827308654785
Validation loss: 2.5773271847796697

Epoch: 5| Step: 9
Training loss: 2.4270005226135254
Validation loss: 2.5666822592417398

Epoch: 5| Step: 10
Training loss: 2.9615907669067383
Validation loss: 2.5691982494887484

Epoch: 109| Step: 0
Training loss: 2.8546690940856934
Validation loss: 2.5721102324865197

Epoch: 5| Step: 1
Training loss: 2.3997185230255127
Validation loss: 2.5709434914332565

Epoch: 5| Step: 2
Training loss: 2.9995007514953613
Validation loss: 2.569828866630472

Epoch: 5| Step: 3
Training loss: 2.853996753692627
Validation loss: 2.5659005154845533

Epoch: 5| Step: 4
Training loss: 3.187361001968384
Validation loss: 2.5707641083707093

Epoch: 5| Step: 5
Training loss: 1.7460622787475586
Validation loss: 2.572187944125104

Epoch: 5| Step: 6
Training loss: 2.774822473526001
Validation loss: 2.5841731256054294

Epoch: 5| Step: 7
Training loss: 2.5126793384552
Validation loss: 2.58420652984291

Epoch: 5| Step: 8
Training loss: 2.838632822036743
Validation loss: 2.590514193298996

Epoch: 5| Step: 9
Training loss: 2.936087131500244
Validation loss: 2.583857177406229

Epoch: 5| Step: 10
Training loss: 2.8002219200134277
Validation loss: 2.5686052204460226

Epoch: 110| Step: 0
Training loss: 2.8451755046844482
Validation loss: 2.562366816305345

Epoch: 5| Step: 1
Training loss: 1.820235013961792
Validation loss: 2.5618309487578688

Epoch: 5| Step: 2
Training loss: 3.077298402786255
Validation loss: 2.5542408753466863

Epoch: 5| Step: 3
Training loss: 3.1044020652770996
Validation loss: 2.5622419439336306

Epoch: 5| Step: 4
Training loss: 2.4149396419525146
Validation loss: 2.5626823697038876

Epoch: 5| Step: 5
Training loss: 3.1565423011779785
Validation loss: 2.5626926729756017

Epoch: 5| Step: 6
Training loss: 2.7346739768981934
Validation loss: 2.560856903752973

Epoch: 5| Step: 7
Training loss: 2.31931471824646
Validation loss: 2.5617612177325833

Epoch: 5| Step: 8
Training loss: 2.7255375385284424
Validation loss: 2.560140912250806

Epoch: 5| Step: 9
Training loss: 3.370079755783081
Validation loss: 2.557223525098575

Epoch: 5| Step: 10
Training loss: 2.185863733291626
Validation loss: 2.559100766335764

Epoch: 111| Step: 0
Training loss: 3.131819486618042
Validation loss: 2.5562605063120523

Epoch: 5| Step: 1
Training loss: 2.704926013946533
Validation loss: 2.560557093671573

Epoch: 5| Step: 2
Training loss: 3.083784818649292
Validation loss: 2.5662194887797036

Epoch: 5| Step: 3
Training loss: 2.5423622131347656
Validation loss: 2.565948858056017

Epoch: 5| Step: 4
Training loss: 3.083624839782715
Validation loss: 2.5690608742416545

Epoch: 5| Step: 5
Training loss: 2.4909884929656982
Validation loss: 2.5683227841572096

Epoch: 5| Step: 6
Training loss: 2.7170896530151367
Validation loss: 2.5642577858381372

Epoch: 5| Step: 7
Training loss: 2.512112855911255
Validation loss: 2.564265827978811

Epoch: 5| Step: 8
Training loss: 2.2324671745300293
Validation loss: 2.5554175325619277

Epoch: 5| Step: 9
Training loss: 2.7606918811798096
Validation loss: 2.5523127740429294

Epoch: 5| Step: 10
Training loss: 2.45274019241333
Validation loss: 2.550301949183146

Epoch: 112| Step: 0
Training loss: 3.3784523010253906
Validation loss: 2.554408211861887

Epoch: 5| Step: 1
Training loss: 2.9102041721343994
Validation loss: 2.5678532379929737

Epoch: 5| Step: 2
Training loss: 2.8961567878723145
Validation loss: 2.5663296048359205

Epoch: 5| Step: 3
Training loss: 3.0810182094573975
Validation loss: 2.567521510585662

Epoch: 5| Step: 4
Training loss: 3.4578423500061035
Validation loss: 2.5669620601079797

Epoch: 5| Step: 5
Training loss: 2.0322318077087402
Validation loss: 2.5636575529652257

Epoch: 5| Step: 6
Training loss: 2.1034979820251465
Validation loss: 2.5595810797906693

Epoch: 5| Step: 7
Training loss: 2.4264492988586426
Validation loss: 2.5558087005410144

Epoch: 5| Step: 8
Training loss: 2.5323822498321533
Validation loss: 2.561588853918096

Epoch: 5| Step: 9
Training loss: 2.1067490577697754
Validation loss: 2.567199250703217

Epoch: 5| Step: 10
Training loss: 2.9007883071899414
Validation loss: 2.5933961765740507

Epoch: 113| Step: 0
Training loss: 2.990166425704956
Validation loss: 2.610539795250021

Epoch: 5| Step: 1
Training loss: 2.435131549835205
Validation loss: 2.6246234114452074

Epoch: 5| Step: 2
Training loss: 3.0306448936462402
Validation loss: 2.6153943231028896

Epoch: 5| Step: 3
Training loss: 2.6781508922576904
Validation loss: 2.5973918002138854

Epoch: 5| Step: 4
Training loss: 3.0501201152801514
Validation loss: 2.580659120313583

Epoch: 5| Step: 5
Training loss: 2.6792211532592773
Validation loss: 2.5667231211098294

Epoch: 5| Step: 6
Training loss: 2.020883321762085
Validation loss: 2.5545916813676075

Epoch: 5| Step: 7
Training loss: 3.095533847808838
Validation loss: 2.5456614161050446

Epoch: 5| Step: 8
Training loss: 2.028477191925049
Validation loss: 2.5443565281488563

Epoch: 5| Step: 9
Training loss: 2.7892730236053467
Validation loss: 2.5456545891300326

Epoch: 5| Step: 10
Training loss: 3.0720882415771484
Validation loss: 2.5538595620022027

Epoch: 114| Step: 0
Training loss: 3.032902479171753
Validation loss: 2.5618816550059984

Epoch: 5| Step: 1
Training loss: 2.9247992038726807
Validation loss: 2.5633891551725325

Epoch: 5| Step: 2
Training loss: 1.9797284603118896
Validation loss: 2.583224050460323

Epoch: 5| Step: 3
Training loss: 3.2017250061035156
Validation loss: 2.583504012835923

Epoch: 5| Step: 4
Training loss: 2.5051822662353516
Validation loss: 2.593810760846702

Epoch: 5| Step: 5
Training loss: 2.366196870803833
Validation loss: 2.5821983301511375

Epoch: 5| Step: 6
Training loss: 2.3298144340515137
Validation loss: 2.5778753706203994

Epoch: 5| Step: 7
Training loss: 2.4191269874572754
Validation loss: 2.575822409763131

Epoch: 5| Step: 8
Training loss: 3.09169602394104
Validation loss: 2.5703342422362296

Epoch: 5| Step: 9
Training loss: 2.959820032119751
Validation loss: 2.54969875274166

Epoch: 5| Step: 10
Training loss: 3.024695873260498
Validation loss: 2.548906482676024

Epoch: 115| Step: 0
Training loss: 2.2225890159606934
Validation loss: 2.5421316598051336

Epoch: 5| Step: 1
Training loss: 2.7683181762695312
Validation loss: 2.548919995625814

Epoch: 5| Step: 2
Training loss: 2.76164174079895
Validation loss: 2.54488222060665

Epoch: 5| Step: 3
Training loss: 3.231571912765503
Validation loss: 2.554224039918633

Epoch: 5| Step: 4
Training loss: 1.9835503101348877
Validation loss: 2.559350072696645

Epoch: 5| Step: 5
Training loss: 2.6455624103546143
Validation loss: 2.556233080484534

Epoch: 5| Step: 6
Training loss: 2.707357883453369
Validation loss: 2.5667945672107

Epoch: 5| Step: 7
Training loss: 2.683589220046997
Validation loss: 2.562368646744759

Epoch: 5| Step: 8
Training loss: 3.406686782836914
Validation loss: 2.5576708444985012

Epoch: 5| Step: 9
Training loss: 2.652083396911621
Validation loss: 2.5500681682299544

Epoch: 5| Step: 10
Training loss: 2.8575894832611084
Validation loss: 2.5416640568805

Epoch: 116| Step: 0
Training loss: 2.963287591934204
Validation loss: 2.5412912189319568

Epoch: 5| Step: 1
Training loss: 2.815904378890991
Validation loss: 2.53938679669493

Epoch: 5| Step: 2
Training loss: 2.2131187915802
Validation loss: 2.556134534138505

Epoch: 5| Step: 3
Training loss: 2.9989800453186035
Validation loss: 2.564125273817329

Epoch: 5| Step: 4
Training loss: 2.342426061630249
Validation loss: 2.573992162622431

Epoch: 5| Step: 5
Training loss: 2.400266170501709
Validation loss: 2.575712262943227

Epoch: 5| Step: 6
Training loss: 3.4508941173553467
Validation loss: 2.5693669729335333

Epoch: 5| Step: 7
Training loss: 2.1737592220306396
Validation loss: 2.5678317803208546

Epoch: 5| Step: 8
Training loss: 2.6945111751556396
Validation loss: 2.562073210234283

Epoch: 5| Step: 9
Training loss: 3.1137237548828125
Validation loss: 2.5485471281954037

Epoch: 5| Step: 10
Training loss: 2.761629819869995
Validation loss: 2.5416457806864092

Epoch: 117| Step: 0
Training loss: 2.3033108711242676
Validation loss: 2.5376887885473107

Epoch: 5| Step: 1
Training loss: 2.4687659740448
Validation loss: 2.532826013462518

Epoch: 5| Step: 2
Training loss: 2.3696372509002686
Validation loss: 2.5338412459178636

Epoch: 5| Step: 3
Training loss: 3.2525200843811035
Validation loss: 2.5304449681312806

Epoch: 5| Step: 4
Training loss: 2.8314390182495117
Validation loss: 2.5279138600954445

Epoch: 5| Step: 5
Training loss: 3.427993059158325
Validation loss: 2.5359220556033555

Epoch: 5| Step: 6
Training loss: 3.357189178466797
Validation loss: 2.533939915318643

Epoch: 5| Step: 7
Training loss: 1.9937798976898193
Validation loss: 2.5451304451111825

Epoch: 5| Step: 8
Training loss: 2.3049614429473877
Validation loss: 2.536083929000362

Epoch: 5| Step: 9
Training loss: 2.5298354625701904
Validation loss: 2.5385143961957706

Epoch: 5| Step: 10
Training loss: 2.9719862937927246
Validation loss: 2.5406231264914236

Epoch: 118| Step: 0
Training loss: 2.8344664573669434
Validation loss: 2.538344890840592

Epoch: 5| Step: 1
Training loss: 2.7770323753356934
Validation loss: 2.534517962445495

Epoch: 5| Step: 2
Training loss: 2.7069172859191895
Validation loss: 2.537729227414695

Epoch: 5| Step: 3
Training loss: 2.0836966037750244
Validation loss: 2.537084533322242

Epoch: 5| Step: 4
Training loss: 3.0347862243652344
Validation loss: 2.532165550416516

Epoch: 5| Step: 5
Training loss: 2.7031736373901367
Validation loss: 2.5393812451311337

Epoch: 5| Step: 6
Training loss: 3.0152339935302734
Validation loss: 2.539800661866383

Epoch: 5| Step: 7
Training loss: 2.8565568923950195
Validation loss: 2.54531168424955

Epoch: 5| Step: 8
Training loss: 2.268691301345825
Validation loss: 2.5527029063111994

Epoch: 5| Step: 9
Training loss: 2.951721668243408
Validation loss: 2.5524192164021153

Epoch: 5| Step: 10
Training loss: 2.2592296600341797
Validation loss: 2.5568814393012755

Epoch: 119| Step: 0
Training loss: 2.2681972980499268
Validation loss: 2.5698799471701346

Epoch: 5| Step: 1
Training loss: 2.355555772781372
Validation loss: 2.57627607417363

Epoch: 5| Step: 2
Training loss: 2.466393232345581
Validation loss: 2.592770404713128

Epoch: 5| Step: 3
Training loss: 3.045358180999756
Validation loss: 2.6103572076366794

Epoch: 5| Step: 4
Training loss: 3.123140335083008
Validation loss: 2.6182677412545807

Epoch: 5| Step: 5
Training loss: 2.6161646842956543
Validation loss: 2.600063911048315

Epoch: 5| Step: 6
Training loss: 2.6291775703430176
Validation loss: 2.5795995394388833

Epoch: 5| Step: 7
Training loss: 2.8563742637634277
Validation loss: 2.5626489680300475

Epoch: 5| Step: 8
Training loss: 2.7496602535247803
Validation loss: 2.552986478292814

Epoch: 5| Step: 9
Training loss: 2.8222553730010986
Validation loss: 2.541954501982658

Epoch: 5| Step: 10
Training loss: 2.8199350833892822
Validation loss: 2.551018281649518

Epoch: 120| Step: 0
Training loss: 2.715716600418091
Validation loss: 2.5482750759329846

Epoch: 5| Step: 1
Training loss: 3.0695548057556152
Validation loss: 2.5363997797812186

Epoch: 5| Step: 2
Training loss: 3.0076611042022705
Validation loss: 2.525124975430068

Epoch: 5| Step: 3
Training loss: 2.6387550830841064
Validation loss: 2.519442827470841

Epoch: 5| Step: 4
Training loss: 2.3615355491638184
Validation loss: 2.523752366342852

Epoch: 5| Step: 5
Training loss: 2.253962278366089
Validation loss: 2.5216988107209564

Epoch: 5| Step: 6
Training loss: 3.018956184387207
Validation loss: 2.523785627016457

Epoch: 5| Step: 7
Training loss: 2.671020030975342
Validation loss: 2.520523323807665

Epoch: 5| Step: 8
Training loss: 3.2094759941101074
Validation loss: 2.5216770454119612

Epoch: 5| Step: 9
Training loss: 2.1585686206817627
Validation loss: 2.5227973512423936

Epoch: 5| Step: 10
Training loss: 2.5682873725891113
Validation loss: 2.5240796253245366

Epoch: 121| Step: 0
Training loss: 2.344788074493408
Validation loss: 2.520969908724549

Epoch: 5| Step: 1
Training loss: 3.719409227371216
Validation loss: 2.5305982366684945

Epoch: 5| Step: 2
Training loss: 3.030484676361084
Validation loss: 2.533170579582132

Epoch: 5| Step: 3
Training loss: 2.2637548446655273
Validation loss: 2.529462152911771

Epoch: 5| Step: 4
Training loss: 2.57794451713562
Validation loss: 2.528481198895362

Epoch: 5| Step: 5
Training loss: 2.3874640464782715
Validation loss: 2.537044781510548

Epoch: 5| Step: 6
Training loss: 2.5129008293151855
Validation loss: 2.543068557657221

Epoch: 5| Step: 7
Training loss: 3.4840521812438965
Validation loss: 2.5464741106956237

Epoch: 5| Step: 8
Training loss: 2.298689365386963
Validation loss: 2.5474923169741066

Epoch: 5| Step: 9
Training loss: 2.991976499557495
Validation loss: 2.567085399422594

Epoch: 5| Step: 10
Training loss: 1.9843780994415283
Validation loss: 2.5645039850665676

Epoch: 122| Step: 0
Training loss: 3.409367084503174
Validation loss: 2.5541045435013308

Epoch: 5| Step: 1
Training loss: 3.1013753414154053
Validation loss: 2.5603053031429166

Epoch: 5| Step: 2
Training loss: 2.92531156539917
Validation loss: 2.55418134761113

Epoch: 5| Step: 3
Training loss: 2.3700599670410156
Validation loss: 2.5501145726890972

Epoch: 5| Step: 4
Training loss: 1.7675321102142334
Validation loss: 2.54907557272142

Epoch: 5| Step: 5
Training loss: 2.457361936569214
Validation loss: 2.54401736105642

Epoch: 5| Step: 6
Training loss: 2.5073869228363037
Validation loss: 2.544098469518846

Epoch: 5| Step: 7
Training loss: 2.2556872367858887
Validation loss: 2.5429921868026897

Epoch: 5| Step: 8
Training loss: 2.7668540477752686
Validation loss: 2.549201939695625

Epoch: 5| Step: 9
Training loss: 2.5482664108276367
Validation loss: 2.551381403400052

Epoch: 5| Step: 10
Training loss: 3.5971460342407227
Validation loss: 2.5470080144943728

Epoch: 123| Step: 0
Training loss: 2.6768996715545654
Validation loss: 2.5473423824515393

Epoch: 5| Step: 1
Training loss: 2.5109193325042725
Validation loss: 2.548328886749924

Epoch: 5| Step: 2
Training loss: 2.4924728870391846
Validation loss: 2.5583430156912854

Epoch: 5| Step: 3
Training loss: 2.4326579570770264
Validation loss: 2.5552660060185257

Epoch: 5| Step: 4
Training loss: 1.9362198114395142
Validation loss: 2.547148355873682

Epoch: 5| Step: 5
Training loss: 3.580547332763672
Validation loss: 2.5523671873154177

Epoch: 5| Step: 6
Training loss: 3.0564987659454346
Validation loss: 2.5416773596117572

Epoch: 5| Step: 7
Training loss: 2.776456356048584
Validation loss: 2.5531890059030182

Epoch: 5| Step: 8
Training loss: 2.2443432807922363
Validation loss: 2.552739374099239

Epoch: 5| Step: 9
Training loss: 2.770272731781006
Validation loss: 2.5637796463504916

Epoch: 5| Step: 10
Training loss: 3.0179738998413086
Validation loss: 2.5551745250660884

Epoch: 124| Step: 0
Training loss: 2.5899360179901123
Validation loss: 2.5613400423398582

Epoch: 5| Step: 1
Training loss: 2.506178617477417
Validation loss: 2.561364096979941

Epoch: 5| Step: 2
Training loss: 2.6551897525787354
Validation loss: 2.5583376910096858

Epoch: 5| Step: 3
Training loss: 2.0225918292999268
Validation loss: 2.5542638583849837

Epoch: 5| Step: 4
Training loss: 2.049546003341675
Validation loss: 2.549692896104628

Epoch: 5| Step: 5
Training loss: 3.5741195678710938
Validation loss: 2.5512254725220385

Epoch: 5| Step: 6
Training loss: 2.6035544872283936
Validation loss: 2.550984956884897

Epoch: 5| Step: 7
Training loss: 3.1252522468566895
Validation loss: 2.558418240598453

Epoch: 5| Step: 8
Training loss: 3.0078606605529785
Validation loss: 2.568985685225456

Epoch: 5| Step: 9
Training loss: 3.0934014320373535
Validation loss: 2.5569190927731094

Epoch: 5| Step: 10
Training loss: 2.0636284351348877
Validation loss: 2.5609502664176365

Epoch: 125| Step: 0
Training loss: 2.16797137260437
Validation loss: 2.559951069534466

Epoch: 5| Step: 1
Training loss: 2.8567416667938232
Validation loss: 2.557835453300066

Epoch: 5| Step: 2
Training loss: 3.166107177734375
Validation loss: 2.5574997778861754

Epoch: 5| Step: 3
Training loss: 3.0212512016296387
Validation loss: 2.549370586231191

Epoch: 5| Step: 4
Training loss: 2.134667158126831
Validation loss: 2.549070204457929

Epoch: 5| Step: 5
Training loss: 2.3760180473327637
Validation loss: 2.5423200489372335

Epoch: 5| Step: 6
Training loss: 2.9516024589538574
Validation loss: 2.551167457334457

Epoch: 5| Step: 7
Training loss: 2.968416690826416
Validation loss: 2.540599015451247

Epoch: 5| Step: 8
Training loss: 2.5558018684387207
Validation loss: 2.5411964949741157

Epoch: 5| Step: 9
Training loss: 2.4277710914611816
Validation loss: 2.532259064335977

Epoch: 5| Step: 10
Training loss: 2.8505444526672363
Validation loss: 2.5361120982836654

Epoch: 126| Step: 0
Training loss: 2.4301087856292725
Validation loss: 2.5450428096196984

Epoch: 5| Step: 1
Training loss: 2.567627429962158
Validation loss: 2.546072998354512

Epoch: 5| Step: 2
Training loss: 2.9291813373565674
Validation loss: 2.5512903813392884

Epoch: 5| Step: 3
Training loss: 3.222153902053833
Validation loss: 2.5482738812764487

Epoch: 5| Step: 4
Training loss: 1.9522327184677124
Validation loss: 2.547543720532489

Epoch: 5| Step: 5
Training loss: 2.8149726390838623
Validation loss: 2.5526092360096593

Epoch: 5| Step: 6
Training loss: 2.369973659515381
Validation loss: 2.552618013915195

Epoch: 5| Step: 7
Training loss: 3.465574264526367
Validation loss: 2.545548654371692

Epoch: 5| Step: 8
Training loss: 2.9640440940856934
Validation loss: 2.5477855513172765

Epoch: 5| Step: 9
Training loss: 2.018529176712036
Validation loss: 2.531420212919994

Epoch: 5| Step: 10
Training loss: 2.8187899589538574
Validation loss: 2.538864715124971

Epoch: 127| Step: 0
Training loss: 3.123624086380005
Validation loss: 2.543774030541861

Epoch: 5| Step: 1
Training loss: 3.1278882026672363
Validation loss: 2.543652613957723

Epoch: 5| Step: 2
Training loss: 2.012707233428955
Validation loss: 2.5351287754633094

Epoch: 5| Step: 3
Training loss: 2.882855176925659
Validation loss: 2.539719817458942

Epoch: 5| Step: 4
Training loss: 2.898512840270996
Validation loss: 2.53328751748608

Epoch: 5| Step: 5
Training loss: 2.8806188106536865
Validation loss: 2.5250912148465394

Epoch: 5| Step: 6
Training loss: 2.698103904724121
Validation loss: 2.5302740579010337

Epoch: 5| Step: 7
Training loss: 2.6688640117645264
Validation loss: 2.5190776035349858

Epoch: 5| Step: 8
Training loss: 2.1492481231689453
Validation loss: 2.52211179015457

Epoch: 5| Step: 9
Training loss: 2.9319217205047607
Validation loss: 2.523423514058513

Epoch: 5| Step: 10
Training loss: 2.119584560394287
Validation loss: 2.5335917113929667

Epoch: 128| Step: 0
Training loss: 2.6239013671875
Validation loss: 2.5373886913381596

Epoch: 5| Step: 1
Training loss: 3.4120922088623047
Validation loss: 2.535542259934128

Epoch: 5| Step: 2
Training loss: 2.4739556312561035
Validation loss: 2.540110444509855

Epoch: 5| Step: 3
Training loss: 2.7363662719726562
Validation loss: 2.5437483800354825

Epoch: 5| Step: 4
Training loss: 2.415691375732422
Validation loss: 2.550853234465404

Epoch: 5| Step: 5
Training loss: 2.2856810092926025
Validation loss: 2.545439580435394

Epoch: 5| Step: 6
Training loss: 3.0038139820098877
Validation loss: 2.5483615295861357

Epoch: 5| Step: 7
Training loss: 2.7870662212371826
Validation loss: 2.553200452558456

Epoch: 5| Step: 8
Training loss: 2.7199699878692627
Validation loss: 2.555486020221505

Epoch: 5| Step: 9
Training loss: 2.8428406715393066
Validation loss: 2.560505990059145

Epoch: 5| Step: 10
Training loss: 2.1384007930755615
Validation loss: 2.561875976541991

Epoch: 129| Step: 0
Training loss: 3.135664701461792
Validation loss: 2.5550172816040697

Epoch: 5| Step: 1
Training loss: 2.7355666160583496
Validation loss: 2.5419438705649426

Epoch: 5| Step: 2
Training loss: 2.610677719116211
Validation loss: 2.5253895533982145

Epoch: 5| Step: 3
Training loss: 2.8684186935424805
Validation loss: 2.519427245663058

Epoch: 5| Step: 4
Training loss: 2.4436371326446533
Validation loss: 2.5062017312613865

Epoch: 5| Step: 5
Training loss: 2.5416016578674316
Validation loss: 2.518460596761396

Epoch: 5| Step: 6
Training loss: 2.7376301288604736
Validation loss: 2.5161754931173017

Epoch: 5| Step: 7
Training loss: 2.3136844635009766
Validation loss: 2.5134876389657297

Epoch: 5| Step: 8
Training loss: 2.6539034843444824
Validation loss: 2.510910754562706

Epoch: 5| Step: 9
Training loss: 2.9080259799957275
Validation loss: 2.510617358710176

Epoch: 5| Step: 10
Training loss: 2.6051061153411865
Validation loss: 2.5056972324207263

Epoch: 130| Step: 0
Training loss: 2.5664784908294678
Validation loss: 2.5204033646532285

Epoch: 5| Step: 1
Training loss: 2.6580934524536133
Validation loss: 2.532635542654222

Epoch: 5| Step: 2
Training loss: 2.085432291030884
Validation loss: 2.5489788875784924

Epoch: 5| Step: 3
Training loss: 2.799248456954956
Validation loss: 2.5662125297771987

Epoch: 5| Step: 4
Training loss: 3.1981425285339355
Validation loss: 2.5584445820059827

Epoch: 5| Step: 5
Training loss: 2.806302547454834
Validation loss: 2.5652284109464256

Epoch: 5| Step: 6
Training loss: 2.201712131500244
Validation loss: 2.5462318607555923

Epoch: 5| Step: 7
Training loss: 2.5869898796081543
Validation loss: 2.533419744942778

Epoch: 5| Step: 8
Training loss: 2.1300277709960938
Validation loss: 2.524957669678555

Epoch: 5| Step: 9
Training loss: 3.5158119201660156
Validation loss: 2.5234759828095794

Epoch: 5| Step: 10
Training loss: 2.9321560859680176
Validation loss: 2.530699130027525

Epoch: 131| Step: 0
Training loss: 3.104006767272949
Validation loss: 2.53090492756136

Epoch: 5| Step: 1
Training loss: 2.690492630004883
Validation loss: 2.5332933151593773

Epoch: 5| Step: 2
Training loss: 2.5987637042999268
Validation loss: 2.5284185717182774

Epoch: 5| Step: 3
Training loss: 2.7203400135040283
Validation loss: 2.54023148680246

Epoch: 5| Step: 4
Training loss: 2.6711554527282715
Validation loss: 2.5344858938647854

Epoch: 5| Step: 5
Training loss: 3.0776333808898926
Validation loss: 2.5248894717103694

Epoch: 5| Step: 6
Training loss: 1.717914342880249
Validation loss: 2.5281912947213776

Epoch: 5| Step: 7
Training loss: 2.9321672916412354
Validation loss: 2.529547596490511

Epoch: 5| Step: 8
Training loss: 2.457279682159424
Validation loss: 2.5282923995807605

Epoch: 5| Step: 9
Training loss: 2.8908705711364746
Validation loss: 2.5292734792155604

Epoch: 5| Step: 10
Training loss: 2.579042434692383
Validation loss: 2.528791176375522

Epoch: 132| Step: 0
Training loss: 3.04789137840271
Validation loss: 2.5355176054021364

Epoch: 5| Step: 1
Training loss: 2.7029285430908203
Validation loss: 2.5408813543217157

Epoch: 5| Step: 2
Training loss: 2.5243544578552246
Validation loss: 2.5418673523010744

Epoch: 5| Step: 3
Training loss: 3.0040321350097656
Validation loss: 2.5380665615040767

Epoch: 5| Step: 4
Training loss: 2.271235942840576
Validation loss: 2.528183029543969

Epoch: 5| Step: 5
Training loss: 3.494616985321045
Validation loss: 2.5242721342271373

Epoch: 5| Step: 6
Training loss: 1.8881498575210571
Validation loss: 2.524285137012441

Epoch: 5| Step: 7
Training loss: 3.7620575428009033
Validation loss: 2.525248490354066

Epoch: 5| Step: 8
Training loss: 1.971377968788147
Validation loss: 2.543295124525665

Epoch: 5| Step: 9
Training loss: 2.2849631309509277
Validation loss: 2.5355127601213354

Epoch: 5| Step: 10
Training loss: 2.4073939323425293
Validation loss: 2.52600008954284

Epoch: 133| Step: 0
Training loss: 2.7947933673858643
Validation loss: 2.5205272884779077

Epoch: 5| Step: 1
Training loss: 2.5479934215545654
Validation loss: 2.5123868501314552

Epoch: 5| Step: 2
Training loss: 2.543311595916748
Validation loss: 2.5208182104172243

Epoch: 5| Step: 3
Training loss: 2.994692802429199
Validation loss: 2.5251868617150093

Epoch: 5| Step: 4
Training loss: 3.1920924186706543
Validation loss: 2.5131193002065024

Epoch: 5| Step: 5
Training loss: 2.447857141494751
Validation loss: 2.5200948856210195

Epoch: 5| Step: 6
Training loss: 2.0134475231170654
Validation loss: 2.520109699618432

Epoch: 5| Step: 7
Training loss: 2.9582910537719727
Validation loss: 2.522091737357519

Epoch: 5| Step: 8
Training loss: 2.375467300415039
Validation loss: 2.5225348703322874

Epoch: 5| Step: 9
Training loss: 2.6908907890319824
Validation loss: 2.5283694292909358

Epoch: 5| Step: 10
Training loss: 2.791822910308838
Validation loss: 2.538589923612533

Epoch: 134| Step: 0
Training loss: 2.37099027633667
Validation loss: 2.5343959613512923

Epoch: 5| Step: 1
Training loss: 2.7990264892578125
Validation loss: 2.5481571997365644

Epoch: 5| Step: 2
Training loss: 2.6073756217956543
Validation loss: 2.5585267133610223

Epoch: 5| Step: 3
Training loss: 2.604097843170166
Validation loss: 2.56341714243735

Epoch: 5| Step: 4
Training loss: 2.9812874794006348
Validation loss: 2.547433599348991

Epoch: 5| Step: 5
Training loss: 2.7545981407165527
Validation loss: 2.528504725425474

Epoch: 5| Step: 6
Training loss: 3.1632606983184814
Validation loss: 2.515562606114213

Epoch: 5| Step: 7
Training loss: 1.9558734893798828
Validation loss: 2.5198127197962936

Epoch: 5| Step: 8
Training loss: 2.9724984169006348
Validation loss: 2.5323865721302647

Epoch: 5| Step: 9
Training loss: 2.1726531982421875
Validation loss: 2.5469886128620436

Epoch: 5| Step: 10
Training loss: 3.0373616218566895
Validation loss: 2.5522468064420964

Epoch: 135| Step: 0
Training loss: 2.5577950477600098
Validation loss: 2.5499104504944174

Epoch: 5| Step: 1
Training loss: 2.576726198196411
Validation loss: 2.5534799483514603

Epoch: 5| Step: 2
Training loss: 2.748387575149536
Validation loss: 2.541631083334646

Epoch: 5| Step: 3
Training loss: 3.0093884468078613
Validation loss: 2.52510090028086

Epoch: 5| Step: 4
Training loss: 2.171888828277588
Validation loss: 2.516935069073913

Epoch: 5| Step: 5
Training loss: 2.941098928451538
Validation loss: 2.5107011154133785

Epoch: 5| Step: 6
Training loss: 2.598921537399292
Validation loss: 2.5069239575375795

Epoch: 5| Step: 7
Training loss: 2.571805000305176
Validation loss: 2.508483825191375

Epoch: 5| Step: 8
Training loss: 2.587013006210327
Validation loss: 2.515181964443576

Epoch: 5| Step: 9
Training loss: 2.5464539527893066
Validation loss: 2.516635129528661

Epoch: 5| Step: 10
Training loss: 2.8806746006011963
Validation loss: 2.5203867522619103

Epoch: 136| Step: 0
Training loss: 2.184596300125122
Validation loss: 2.5310832851676532

Epoch: 5| Step: 1
Training loss: 3.5548501014709473
Validation loss: 2.537630063231273

Epoch: 5| Step: 2
Training loss: 2.7428030967712402
Validation loss: 2.55021079381307

Epoch: 5| Step: 3
Training loss: 2.950385332107544
Validation loss: 2.540209303620041

Epoch: 5| Step: 4
Training loss: 2.478114366531372
Validation loss: 2.5495946766227804

Epoch: 5| Step: 5
Training loss: 2.546762228012085
Validation loss: 2.546236381735853

Epoch: 5| Step: 6
Training loss: 3.895397186279297
Validation loss: 2.552086655811597

Epoch: 5| Step: 7
Training loss: 2.4158778190612793
Validation loss: 2.5414961358552337

Epoch: 5| Step: 8
Training loss: 1.49403977394104
Validation loss: 2.5348286538995723

Epoch: 5| Step: 9
Training loss: 2.7507026195526123
Validation loss: 2.5394979651256273

Epoch: 5| Step: 10
Training loss: 2.0910489559173584
Validation loss: 2.5404484477094424

Epoch: 137| Step: 0
Training loss: 2.7721266746520996
Validation loss: 2.531101167842906

Epoch: 5| Step: 1
Training loss: 2.2878165245056152
Validation loss: 2.5212609024458033

Epoch: 5| Step: 2
Training loss: 2.9814419746398926
Validation loss: 2.530046364312531

Epoch: 5| Step: 3
Training loss: 3.230902910232544
Validation loss: 2.519622920661844

Epoch: 5| Step: 4
Training loss: 1.6577224731445312
Validation loss: 2.5186952724251697

Epoch: 5| Step: 5
Training loss: 2.581261157989502
Validation loss: 2.5204100685734905

Epoch: 5| Step: 6
Training loss: 2.6777865886688232
Validation loss: 2.5350143319817

Epoch: 5| Step: 7
Training loss: 3.4275383949279785
Validation loss: 2.542396091645764

Epoch: 5| Step: 8
Training loss: 2.1650948524475098
Validation loss: 2.5326229833787486

Epoch: 5| Step: 9
Training loss: 3.351222276687622
Validation loss: 2.517307171257593

Epoch: 5| Step: 10
Training loss: 1.9788378477096558
Validation loss: 2.510953859616351

Epoch: 138| Step: 0
Training loss: 2.43308687210083
Validation loss: 2.4981776360542542

Epoch: 5| Step: 1
Training loss: 2.1680097579956055
Validation loss: 2.4930133204306326

Epoch: 5| Step: 2
Training loss: 3.004945755004883
Validation loss: 2.501264541379867

Epoch: 5| Step: 3
Training loss: 2.92726469039917
Validation loss: 2.5070586742893344

Epoch: 5| Step: 4
Training loss: 3.1504745483398438
Validation loss: 2.5272517127375447

Epoch: 5| Step: 5
Training loss: 2.688563823699951
Validation loss: 2.5296635320109706

Epoch: 5| Step: 6
Training loss: 2.3822524547576904
Validation loss: 2.537054584872338

Epoch: 5| Step: 7
Training loss: 1.9916740655899048
Validation loss: 2.5395405805239113

Epoch: 5| Step: 8
Training loss: 2.124525308609009
Validation loss: 2.5388459954210507

Epoch: 5| Step: 9
Training loss: 3.4016880989074707
Validation loss: 2.5331045068720335

Epoch: 5| Step: 10
Training loss: 3.1703686714172363
Validation loss: 2.5287331509333786

Epoch: 139| Step: 0
Training loss: 2.448429584503174
Validation loss: 2.525644789459885

Epoch: 5| Step: 1
Training loss: 2.5782833099365234
Validation loss: 2.515629473552909

Epoch: 5| Step: 2
Training loss: 3.0914931297302246
Validation loss: 2.5164098175623084

Epoch: 5| Step: 3
Training loss: 1.981781244277954
Validation loss: 2.512262946815901

Epoch: 5| Step: 4
Training loss: 3.1313178539276123
Validation loss: 2.508909379282305

Epoch: 5| Step: 5
Training loss: 2.9913597106933594
Validation loss: 2.5117172964157595

Epoch: 5| Step: 6
Training loss: 2.4500489234924316
Validation loss: 2.522110208388298

Epoch: 5| Step: 7
Training loss: 2.8248417377471924
Validation loss: 2.507424069989112

Epoch: 5| Step: 8
Training loss: 2.5494096279144287
Validation loss: 2.5132758578946515

Epoch: 5| Step: 9
Training loss: 2.2239608764648438
Validation loss: 2.509332213350522

Epoch: 5| Step: 10
Training loss: 3.0394392013549805
Validation loss: 2.5117702945586173

Epoch: 140| Step: 0
Training loss: 2.5782885551452637
Validation loss: 2.5163545967430196

Epoch: 5| Step: 1
Training loss: 2.663480520248413
Validation loss: 2.523447628944151

Epoch: 5| Step: 2
Training loss: 2.7097060680389404
Validation loss: 2.525295954878612

Epoch: 5| Step: 3
Training loss: 2.8438401222229004
Validation loss: 2.5198279606398715

Epoch: 5| Step: 4
Training loss: 2.2498230934143066
Validation loss: 2.519181159234816

Epoch: 5| Step: 5
Training loss: 2.2621512413024902
Validation loss: 2.5228950156960437

Epoch: 5| Step: 6
Training loss: 2.529520034790039
Validation loss: 2.5132986755781275

Epoch: 5| Step: 7
Training loss: 2.8934242725372314
Validation loss: 2.521401620680286

Epoch: 5| Step: 8
Training loss: 3.1567227840423584
Validation loss: 2.5181766633064515

Epoch: 5| Step: 9
Training loss: 2.7184510231018066
Validation loss: 2.527351002539358

Epoch: 5| Step: 10
Training loss: 2.5828018188476562
Validation loss: 2.5117303453465945

Epoch: 141| Step: 0
Training loss: 3.060303211212158
Validation loss: 2.5120239744904223

Epoch: 5| Step: 1
Training loss: 2.954576015472412
Validation loss: 2.508698394221644

Epoch: 5| Step: 2
Training loss: 2.8420681953430176
Validation loss: 2.5017176879349576

Epoch: 5| Step: 3
Training loss: 2.8355178833007812
Validation loss: 2.508740245655019

Epoch: 5| Step: 4
Training loss: 2.863194227218628
Validation loss: 2.5067806500260548

Epoch: 5| Step: 5
Training loss: 1.9425303936004639
Validation loss: 2.5001836105059554

Epoch: 5| Step: 6
Training loss: 2.408694267272949
Validation loss: 2.493534803390503

Epoch: 5| Step: 7
Training loss: 2.344240188598633
Validation loss: 2.4903165268641647

Epoch: 5| Step: 8
Training loss: 2.842198133468628
Validation loss: 2.4911032620296685

Epoch: 5| Step: 9
Training loss: 2.4643454551696777
Validation loss: 2.5035791115094255

Epoch: 5| Step: 10
Training loss: 2.6028783321380615
Validation loss: 2.4969511724287465

Epoch: 142| Step: 0
Training loss: 2.8402059078216553
Validation loss: 2.501640368533391

Epoch: 5| Step: 1
Training loss: 2.1232571601867676
Validation loss: 2.5068611893602597

Epoch: 5| Step: 2
Training loss: 2.383061170578003
Validation loss: 2.506518230643324

Epoch: 5| Step: 3
Training loss: 2.6440680027008057
Validation loss: 2.5094847730410996

Epoch: 5| Step: 4
Training loss: 2.816986560821533
Validation loss: 2.509943746751355

Epoch: 5| Step: 5
Training loss: 3.1447644233703613
Validation loss: 2.50751252840924

Epoch: 5| Step: 6
Training loss: 2.3174469470977783
Validation loss: 2.504451508163124

Epoch: 5| Step: 7
Training loss: 2.722929000854492
Validation loss: 2.4995850645085818

Epoch: 5| Step: 8
Training loss: 3.1655986309051514
Validation loss: 2.499977260507563

Epoch: 5| Step: 9
Training loss: 2.799633026123047
Validation loss: 2.4866530869596746

Epoch: 5| Step: 10
Training loss: 2.077828884124756
Validation loss: 2.4920474278029574

Epoch: 143| Step: 0
Training loss: 2.5733513832092285
Validation loss: 2.500794013341268

Epoch: 5| Step: 1
Training loss: 3.4179446697235107
Validation loss: 2.490757324362314

Epoch: 5| Step: 2
Training loss: 2.885261058807373
Validation loss: 2.4973566916681107

Epoch: 5| Step: 3
Training loss: 2.2398898601531982
Validation loss: 2.4961253827618015

Epoch: 5| Step: 4
Training loss: 2.4507908821105957
Validation loss: 2.5034726717138804

Epoch: 5| Step: 5
Training loss: 3.0214571952819824
Validation loss: 2.4974572812357256

Epoch: 5| Step: 6
Training loss: 2.409693717956543
Validation loss: 2.5026315489122943

Epoch: 5| Step: 7
Training loss: 3.136000394821167
Validation loss: 2.4989700317382812

Epoch: 5| Step: 8
Training loss: 3.0942485332489014
Validation loss: 2.5042721353551394

Epoch: 5| Step: 9
Training loss: 1.9377219676971436
Validation loss: 2.503816763559977

Epoch: 5| Step: 10
Training loss: 1.79567551612854
Validation loss: 2.5083305579359814

Epoch: 144| Step: 0
Training loss: 2.176217555999756
Validation loss: 2.4986289008971183

Epoch: 5| Step: 1
Training loss: 2.6965556144714355
Validation loss: 2.4940994465222923

Epoch: 5| Step: 2
Training loss: 2.1001625061035156
Validation loss: 2.498816587591684

Epoch: 5| Step: 3
Training loss: 2.3941738605499268
Validation loss: 2.491951178478938

Epoch: 5| Step: 4
Training loss: 2.6143832206726074
Validation loss: 2.500322905919885

Epoch: 5| Step: 5
Training loss: 2.9774646759033203
Validation loss: 2.502617300197642

Epoch: 5| Step: 6
Training loss: 2.849165439605713
Validation loss: 2.5028890153413177

Epoch: 5| Step: 7
Training loss: 2.7189671993255615
Validation loss: 2.5018283782466764

Epoch: 5| Step: 8
Training loss: 3.3277347087860107
Validation loss: 2.4912313325430757

Epoch: 5| Step: 9
Training loss: 2.7911620140075684
Validation loss: 2.481738413533857

Epoch: 5| Step: 10
Training loss: 2.418633222579956
Validation loss: 2.480049648592549

Epoch: 145| Step: 0
Training loss: 2.3845839500427246
Validation loss: 2.4791109485010945

Epoch: 5| Step: 1
Training loss: 2.4730277061462402
Validation loss: 2.486042727706253

Epoch: 5| Step: 2
Training loss: 2.698268413543701
Validation loss: 2.494978491977979

Epoch: 5| Step: 3
Training loss: 2.8758130073547363
Validation loss: 2.5135631484370076

Epoch: 5| Step: 4
Training loss: 2.8012325763702393
Validation loss: 2.513086641988447

Epoch: 5| Step: 5
Training loss: 2.0282273292541504
Validation loss: 2.5033371679244505

Epoch: 5| Step: 6
Training loss: 3.0991039276123047
Validation loss: 2.4998127260515766

Epoch: 5| Step: 7
Training loss: 2.9023261070251465
Validation loss: 2.4934956155797487

Epoch: 5| Step: 8
Training loss: 2.5795421600341797
Validation loss: 2.500964210879418

Epoch: 5| Step: 9
Training loss: 3.0058791637420654
Validation loss: 2.5209406755303823

Epoch: 5| Step: 10
Training loss: 2.247351884841919
Validation loss: 2.552402078464467

Epoch: 146| Step: 0
Training loss: 2.573481798171997
Validation loss: 2.575445170043617

Epoch: 5| Step: 1
Training loss: 2.8840458393096924
Validation loss: 2.535341716581775

Epoch: 5| Step: 2
Training loss: 2.6937975883483887
Validation loss: 2.5085039523340042

Epoch: 5| Step: 3
Training loss: 2.2059197425842285
Validation loss: 2.5079911011521534

Epoch: 5| Step: 4
Training loss: 2.6839098930358887
Validation loss: 2.4933951465032433

Epoch: 5| Step: 5
Training loss: 2.9235758781433105
Validation loss: 2.4884255727132163

Epoch: 5| Step: 6
Training loss: 3.1784229278564453
Validation loss: 2.48803997296159

Epoch: 5| Step: 7
Training loss: 2.3012046813964844
Validation loss: 2.4963444612359487

Epoch: 5| Step: 8
Training loss: 2.4485323429107666
Validation loss: 2.507873688974688

Epoch: 5| Step: 9
Training loss: 2.8035566806793213
Validation loss: 2.5102739898107385

Epoch: 5| Step: 10
Training loss: 2.479736804962158
Validation loss: 2.515692582694433

Epoch: 147| Step: 0
Training loss: 3.391721248626709
Validation loss: 2.5088057210368495

Epoch: 5| Step: 1
Training loss: 2.415616273880005
Validation loss: 2.499211375431348

Epoch: 5| Step: 2
Training loss: 2.773097515106201
Validation loss: 2.497544724454162

Epoch: 5| Step: 3
Training loss: 2.8025310039520264
Validation loss: 2.4823662055436

Epoch: 5| Step: 4
Training loss: 2.1514291763305664
Validation loss: 2.4825681486437396

Epoch: 5| Step: 5
Training loss: 2.88840651512146
Validation loss: 2.4836581548055015

Epoch: 5| Step: 6
Training loss: 2.56632924079895
Validation loss: 2.484318141014345

Epoch: 5| Step: 7
Training loss: 2.23801326751709
Validation loss: 2.4878076430289977

Epoch: 5| Step: 8
Training loss: 2.7454230785369873
Validation loss: 2.482217017040458

Epoch: 5| Step: 9
Training loss: 2.6936511993408203
Validation loss: 2.4877022402260893

Epoch: 5| Step: 10
Training loss: 2.3391318321228027
Validation loss: 2.493107602160464

Epoch: 148| Step: 0
Training loss: 2.738854169845581
Validation loss: 2.4964328837651077

Epoch: 5| Step: 1
Training loss: 2.6548056602478027
Validation loss: 2.495636373437861

Epoch: 5| Step: 2
Training loss: 2.3552708625793457
Validation loss: 2.506808311708512

Epoch: 5| Step: 3
Training loss: 2.857213258743286
Validation loss: 2.5062032104820333

Epoch: 5| Step: 4
Training loss: 2.730072021484375
Validation loss: 2.500897910005303

Epoch: 5| Step: 5
Training loss: 1.9272537231445312
Validation loss: 2.5190916420311056

Epoch: 5| Step: 6
Training loss: 2.7063686847686768
Validation loss: 2.5421943536368747

Epoch: 5| Step: 7
Training loss: 2.494494915008545
Validation loss: 2.5523520541447464

Epoch: 5| Step: 8
Training loss: 2.530574321746826
Validation loss: 2.544533601371191

Epoch: 5| Step: 9
Training loss: 3.5687530040740967
Validation loss: 2.537734417505162

Epoch: 5| Step: 10
Training loss: 2.7487430572509766
Validation loss: 2.520717751595282

Epoch: 149| Step: 0
Training loss: 3.458984851837158
Validation loss: 2.515374029836347

Epoch: 5| Step: 1
Training loss: 3.651761531829834
Validation loss: 2.500732942294049

Epoch: 5| Step: 2
Training loss: 2.4481801986694336
Validation loss: 2.489703416824341

Epoch: 5| Step: 3
Training loss: 1.8079382181167603
Validation loss: 2.474796618184736

Epoch: 5| Step: 4
Training loss: 2.1894850730895996
Validation loss: 2.4798869099668277

Epoch: 5| Step: 5
Training loss: 2.312887191772461
Validation loss: 2.47563063457448

Epoch: 5| Step: 6
Training loss: 2.7154245376586914
Validation loss: 2.480864942714732

Epoch: 5| Step: 7
Training loss: 2.586942434310913
Validation loss: 2.4757436372900523

Epoch: 5| Step: 8
Training loss: 2.6283164024353027
Validation loss: 2.480161654051914

Epoch: 5| Step: 9
Training loss: 3.154794454574585
Validation loss: 2.4781279281903337

Epoch: 5| Step: 10
Training loss: 2.1286818981170654
Validation loss: 2.478458842923564

Epoch: 150| Step: 0
Training loss: 2.671207904815674
Validation loss: 2.4888645346446703

Epoch: 5| Step: 1
Training loss: 2.806100368499756
Validation loss: 2.484087990176293

Epoch: 5| Step: 2
Training loss: 2.254364490509033
Validation loss: 2.4909102416807607

Epoch: 5| Step: 3
Training loss: 3.464693069458008
Validation loss: 2.4893974437508533

Epoch: 5| Step: 4
Training loss: 2.9299874305725098
Validation loss: 2.4976138581511793

Epoch: 5| Step: 5
Training loss: 3.008841037750244
Validation loss: 2.494385414226081

Epoch: 5| Step: 6
Training loss: 2.4868011474609375
Validation loss: 2.4882601666194137

Epoch: 5| Step: 7
Training loss: 2.54620623588562
Validation loss: 2.493019344986126

Epoch: 5| Step: 8
Training loss: 2.106593370437622
Validation loss: 2.4900743833152195

Epoch: 5| Step: 9
Training loss: 2.6845004558563232
Validation loss: 2.494006456867341

Epoch: 5| Step: 10
Training loss: 2.1442244052886963
Validation loss: 2.4854540542889665

Epoch: 151| Step: 0
Training loss: 2.402750253677368
Validation loss: 2.491172262417373

Epoch: 5| Step: 1
Training loss: 3.331465244293213
Validation loss: 2.4950816503135105

Epoch: 5| Step: 2
Training loss: 2.5704123973846436
Validation loss: 2.495560038474298

Epoch: 5| Step: 3
Training loss: 2.912588596343994
Validation loss: 2.49896312785405

Epoch: 5| Step: 4
Training loss: 2.9198150634765625
Validation loss: 2.501260385718397

Epoch: 5| Step: 5
Training loss: 2.6102821826934814
Validation loss: 2.5054498077720724

Epoch: 5| Step: 6
Training loss: 2.5801923274993896
Validation loss: 2.5011808538949616

Epoch: 5| Step: 7
Training loss: 2.270108699798584
Validation loss: 2.501846965923104

Epoch: 5| Step: 8
Training loss: 2.2825722694396973
Validation loss: 2.49957489070072

Epoch: 5| Step: 9
Training loss: 2.3966739177703857
Validation loss: 2.497788759969896

Epoch: 5| Step: 10
Training loss: 2.7984607219696045
Validation loss: 2.4910645792561192

Epoch: 152| Step: 0
Training loss: 3.4461731910705566
Validation loss: 2.494972417431493

Epoch: 5| Step: 1
Training loss: 1.6456878185272217
Validation loss: 2.496361706846504

Epoch: 5| Step: 2
Training loss: 3.9964263439178467
Validation loss: 2.4872804277686664

Epoch: 5| Step: 3
Training loss: 2.7100729942321777
Validation loss: 2.4875692116316928

Epoch: 5| Step: 4
Training loss: 2.759918689727783
Validation loss: 2.4821141073780675

Epoch: 5| Step: 5
Training loss: 2.4392940998077393
Validation loss: 2.490489172679122

Epoch: 5| Step: 6
Training loss: 2.8446855545043945
Validation loss: 2.4944866523947766

Epoch: 5| Step: 7
Training loss: 2.2175958156585693
Validation loss: 2.4949839525325324

Epoch: 5| Step: 8
Training loss: 2.495593547821045
Validation loss: 2.5036124516558904

Epoch: 5| Step: 9
Training loss: 2.3332157135009766
Validation loss: 2.5081953079469743

Epoch: 5| Step: 10
Training loss: 1.8761531114578247
Validation loss: 2.50588551644356

Epoch: 153| Step: 0
Training loss: 2.055940628051758
Validation loss: 2.5161625441684516

Epoch: 5| Step: 1
Training loss: 2.7513880729675293
Validation loss: 2.5264381926546813

Epoch: 5| Step: 2
Training loss: 2.3910768032073975
Validation loss: 2.5289484224011822

Epoch: 5| Step: 3
Training loss: 2.909331798553467
Validation loss: 2.528227516399917

Epoch: 5| Step: 4
Training loss: 3.0081300735473633
Validation loss: 2.520847858921174

Epoch: 5| Step: 5
Training loss: 2.901273250579834
Validation loss: 2.501884557867563

Epoch: 5| Step: 6
Training loss: 2.5473458766937256
Validation loss: 2.488099818588585

Epoch: 5| Step: 7
Training loss: 2.7082085609436035
Validation loss: 2.489179717597141

Epoch: 5| Step: 8
Training loss: 2.3037638664245605
Validation loss: 2.4732133393646567

Epoch: 5| Step: 9
Training loss: 2.9475598335266113
Validation loss: 2.4762629873009137

Epoch: 5| Step: 10
Training loss: 2.3707661628723145
Validation loss: 2.470248373605872

Epoch: 154| Step: 0
Training loss: 2.7369449138641357
Validation loss: 2.467992357028428

Epoch: 5| Step: 1
Training loss: 1.8865940570831299
Validation loss: 2.4740748251638105

Epoch: 5| Step: 2
Training loss: 2.900430202484131
Validation loss: 2.479800344795309

Epoch: 5| Step: 3
Training loss: 2.5866129398345947
Validation loss: 2.4756647694495415

Epoch: 5| Step: 4
Training loss: 3.087158679962158
Validation loss: 2.4856322452586186

Epoch: 5| Step: 5
Training loss: 2.3946163654327393
Validation loss: 2.4768209188215193

Epoch: 5| Step: 6
Training loss: 2.290926456451416
Validation loss: 2.4765500125064643

Epoch: 5| Step: 7
Training loss: 3.048992395401001
Validation loss: 2.4776415504435056

Epoch: 5| Step: 8
Training loss: 2.4827375411987305
Validation loss: 2.474057569298693

Epoch: 5| Step: 9
Training loss: 2.8156352043151855
Validation loss: 2.47955911133879

Epoch: 5| Step: 10
Training loss: 2.747981309890747
Validation loss: 2.4864242794693157

Epoch: 155| Step: 0
Training loss: 2.7870399951934814
Validation loss: 2.479364169541226

Epoch: 5| Step: 1
Training loss: 2.6485185623168945
Validation loss: 2.4886261519565376

Epoch: 5| Step: 2
Training loss: 3.2576823234558105
Validation loss: 2.4815967518796205

Epoch: 5| Step: 3
Training loss: 2.5449001789093018
Validation loss: 2.4948851229042135

Epoch: 5| Step: 4
Training loss: 2.5948948860168457
Validation loss: 2.491591786825529

Epoch: 5| Step: 5
Training loss: 2.6386754512786865
Validation loss: 2.513810044975691

Epoch: 5| Step: 6
Training loss: 2.688659191131592
Validation loss: 2.510591609503633

Epoch: 5| Step: 7
Training loss: 2.6998398303985596
Validation loss: 2.5096662839253745

Epoch: 5| Step: 8
Training loss: 2.724407434463501
Validation loss: 2.4999676032732894

Epoch: 5| Step: 9
Training loss: 2.110337018966675
Validation loss: 2.5044153736483667

Epoch: 5| Step: 10
Training loss: 2.2399632930755615
Validation loss: 2.500676126890285

Epoch: 156| Step: 0
Training loss: 2.853231430053711
Validation loss: 2.4822620858428297

Epoch: 5| Step: 1
Training loss: 2.643054485321045
Validation loss: 2.465820002299483

Epoch: 5| Step: 2
Training loss: 2.631830930709839
Validation loss: 2.4588023001147854

Epoch: 5| Step: 3
Training loss: 3.044412136077881
Validation loss: 2.4587620612113708

Epoch: 5| Step: 4
Training loss: 2.3789031505584717
Validation loss: 2.464737376859111

Epoch: 5| Step: 5
Training loss: 2.42836856842041
Validation loss: 2.4623937017174176

Epoch: 5| Step: 6
Training loss: 2.33809232711792
Validation loss: 2.48233280386976

Epoch: 5| Step: 7
Training loss: 2.8014392852783203
Validation loss: 2.4909597930087837

Epoch: 5| Step: 8
Training loss: 2.1734886169433594
Validation loss: 2.501645116395848

Epoch: 5| Step: 9
Training loss: 3.1999850273132324
Validation loss: 2.5145647782151417

Epoch: 5| Step: 10
Training loss: 2.440675973892212
Validation loss: 2.5105391561344104

Epoch: 157| Step: 0
Training loss: 3.13447904586792
Validation loss: 2.504649216128934

Epoch: 5| Step: 1
Training loss: 2.537052631378174
Validation loss: 2.496762598714521

Epoch: 5| Step: 2
Training loss: 2.782167673110962
Validation loss: 2.492177168528239

Epoch: 5| Step: 3
Training loss: 2.5571227073669434
Validation loss: 2.49388914210822

Epoch: 5| Step: 4
Training loss: 2.5551047325134277
Validation loss: 2.5174764151214273

Epoch: 5| Step: 5
Training loss: 2.8236794471740723
Validation loss: 2.5102982110874628

Epoch: 5| Step: 6
Training loss: 1.9922332763671875
Validation loss: 2.505481107260591

Epoch: 5| Step: 7
Training loss: 3.044565200805664
Validation loss: 2.5188464938953357

Epoch: 5| Step: 8
Training loss: 2.7937216758728027
Validation loss: 2.505725286340201

Epoch: 5| Step: 9
Training loss: 2.664074420928955
Validation loss: 2.5045675769928963

Epoch: 5| Step: 10
Training loss: 2.0771756172180176
Validation loss: 2.490162211079751

Epoch: 158| Step: 0
Training loss: 2.5552141666412354
Validation loss: 2.4894879941017396

Epoch: 5| Step: 1
Training loss: 2.7163853645324707
Validation loss: 2.489299912606516

Epoch: 5| Step: 2
Training loss: 2.672192096710205
Validation loss: 2.496893855833238

Epoch: 5| Step: 3
Training loss: 2.8249497413635254
Validation loss: 2.5042623858298025

Epoch: 5| Step: 4
Training loss: 2.016352653503418
Validation loss: 2.5061512634318364

Epoch: 5| Step: 5
Training loss: 2.720238447189331
Validation loss: 2.5002722073626775

Epoch: 5| Step: 6
Training loss: 2.5640783309936523
Validation loss: 2.495202338823708

Epoch: 5| Step: 7
Training loss: 3.24702787399292
Validation loss: 2.4907680044892015

Epoch: 5| Step: 8
Training loss: 3.023024082183838
Validation loss: 2.4842107167807956

Epoch: 5| Step: 9
Training loss: 2.202423095703125
Validation loss: 2.4792409814814085

Epoch: 5| Step: 10
Training loss: 2.3456649780273438
Validation loss: 2.469270667722148

Epoch: 159| Step: 0
Training loss: 2.381880283355713
Validation loss: 2.4810953858078166

Epoch: 5| Step: 1
Training loss: 3.603663921356201
Validation loss: 2.476511480987713

Epoch: 5| Step: 2
Training loss: 3.0242903232574463
Validation loss: 2.4772153208332677

Epoch: 5| Step: 3
Training loss: 2.040764570236206
Validation loss: 2.472514319163497

Epoch: 5| Step: 4
Training loss: 2.2979729175567627
Validation loss: 2.4696613178458264

Epoch: 5| Step: 5
Training loss: 2.461451530456543
Validation loss: 2.466966300882319

Epoch: 5| Step: 6
Training loss: 2.8983945846557617
Validation loss: 2.4698050714308217

Epoch: 5| Step: 7
Training loss: 2.459714412689209
Validation loss: 2.4668760722683323

Epoch: 5| Step: 8
Training loss: 2.5428478717803955
Validation loss: 2.463097833818005

Epoch: 5| Step: 9
Training loss: 2.424381971359253
Validation loss: 2.484506212255006

Epoch: 5| Step: 10
Training loss: 2.7195870876312256
Validation loss: 2.4773942680769068

Epoch: 160| Step: 0
Training loss: 2.8183937072753906
Validation loss: 2.4772417160772506

Epoch: 5| Step: 1
Training loss: 2.643280506134033
Validation loss: 2.4857592787793887

Epoch: 5| Step: 2
Training loss: 3.257939577102661
Validation loss: 2.4882534421900266

Epoch: 5| Step: 3
Training loss: 2.314873456954956
Validation loss: 2.4881779275914675

Epoch: 5| Step: 4
Training loss: 2.3966801166534424
Validation loss: 2.496823239070113

Epoch: 5| Step: 5
Training loss: 3.143177032470703
Validation loss: 2.4940270762289725

Epoch: 5| Step: 6
Training loss: 1.9563297033309937
Validation loss: 2.4875839833290345

Epoch: 5| Step: 7
Training loss: 1.882306456565857
Validation loss: 2.477971339738497

Epoch: 5| Step: 8
Training loss: 1.9688880443572998
Validation loss: 2.479259693494407

Epoch: 5| Step: 9
Training loss: 3.2997562885284424
Validation loss: 2.481229494976741

Epoch: 5| Step: 10
Training loss: 3.213654041290283
Validation loss: 2.4838461209368963

Epoch: 161| Step: 0
Training loss: 2.6126351356506348
Validation loss: 2.4796677071561097

Epoch: 5| Step: 1
Training loss: 2.861968517303467
Validation loss: 2.4931095569364485

Epoch: 5| Step: 2
Training loss: 3.007014751434326
Validation loss: 2.492939800344488

Epoch: 5| Step: 3
Training loss: 2.76236629486084
Validation loss: 2.488203881889261

Epoch: 5| Step: 4
Training loss: 2.9916350841522217
Validation loss: 2.500996979334021

Epoch: 5| Step: 5
Training loss: 1.9720577001571655
Validation loss: 2.48702210252003

Epoch: 5| Step: 6
Training loss: 2.312321901321411
Validation loss: 2.4853290793716267

Epoch: 5| Step: 7
Training loss: 2.5525476932525635
Validation loss: 2.479357034929337

Epoch: 5| Step: 8
Training loss: 2.9687232971191406
Validation loss: 2.4820785548097346

Epoch: 5| Step: 9
Training loss: 2.3879992961883545
Validation loss: 2.488912679815805

Epoch: 5| Step: 10
Training loss: 2.2528555393218994
Validation loss: 2.483322407609673

Epoch: 162| Step: 0
Training loss: 2.7869348526000977
Validation loss: 2.47610475683725

Epoch: 5| Step: 1
Training loss: 2.7324774265289307
Validation loss: 2.472072716682188

Epoch: 5| Step: 2
Training loss: 3.137986660003662
Validation loss: 2.4717287735272477

Epoch: 5| Step: 3
Training loss: 2.580268383026123
Validation loss: 2.4631135130441315

Epoch: 5| Step: 4
Training loss: 2.3656272888183594
Validation loss: 2.4659439697060535

Epoch: 5| Step: 5
Training loss: 2.433932065963745
Validation loss: 2.454881742436399

Epoch: 5| Step: 6
Training loss: 3.215301036834717
Validation loss: 2.460585653140981

Epoch: 5| Step: 7
Training loss: 2.347403049468994
Validation loss: 2.463194900943387

Epoch: 5| Step: 8
Training loss: 1.9013227224349976
Validation loss: 2.4664443872308217

Epoch: 5| Step: 9
Training loss: 2.302525281906128
Validation loss: 2.471606937787866

Epoch: 5| Step: 10
Training loss: 2.998671531677246
Validation loss: 2.483745131441342

Epoch: 163| Step: 0
Training loss: 2.654491662979126
Validation loss: 2.4918664681014193

Epoch: 5| Step: 1
Training loss: 2.856663465499878
Validation loss: 2.5149312250075804

Epoch: 5| Step: 2
Training loss: 3.042865514755249
Validation loss: 2.5146883251846477

Epoch: 5| Step: 3
Training loss: 2.493251323699951
Validation loss: 2.5035809137487925

Epoch: 5| Step: 4
Training loss: 2.6172220706939697
Validation loss: 2.4823603142974195

Epoch: 5| Step: 5
Training loss: 2.9833157062530518
Validation loss: 2.4644257765944286

Epoch: 5| Step: 6
Training loss: 2.3937814235687256
Validation loss: 2.471333190958987

Epoch: 5| Step: 7
Training loss: 1.6731916666030884
Validation loss: 2.4824645621802217

Epoch: 5| Step: 8
Training loss: 3.1459171772003174
Validation loss: 2.485221839720203

Epoch: 5| Step: 9
Training loss: 2.7722506523132324
Validation loss: 2.494346785288985

Epoch: 5| Step: 10
Training loss: 2.3574442863464355
Validation loss: 2.492063150610975

Epoch: 164| Step: 0
Training loss: 2.555814743041992
Validation loss: 2.485611569496893

Epoch: 5| Step: 1
Training loss: 2.5440306663513184
Validation loss: 2.4801806762654293

Epoch: 5| Step: 2
Training loss: 2.986713409423828
Validation loss: 2.472950566199518

Epoch: 5| Step: 3
Training loss: 2.73710298538208
Validation loss: 2.4711121641179568

Epoch: 5| Step: 4
Training loss: 2.842578411102295
Validation loss: 2.458002023799445

Epoch: 5| Step: 5
Training loss: 2.446073532104492
Validation loss: 2.4661886076773367

Epoch: 5| Step: 6
Training loss: 2.6571030616760254
Validation loss: 2.4635838167641753

Epoch: 5| Step: 7
Training loss: 1.9195398092269897
Validation loss: 2.4529652262246735

Epoch: 5| Step: 8
Training loss: 2.5165679454803467
Validation loss: 2.46092039538968

Epoch: 5| Step: 9
Training loss: 2.553318500518799
Validation loss: 2.4630977671633483

Epoch: 5| Step: 10
Training loss: 3.2291409969329834
Validation loss: 2.462925229021298

Epoch: 165| Step: 0
Training loss: 2.991476058959961
Validation loss: 2.4672911449145247

Epoch: 5| Step: 1
Training loss: 3.05244517326355
Validation loss: 2.462045120936568

Epoch: 5| Step: 2
Training loss: 3.113410472869873
Validation loss: 2.460948815909765

Epoch: 5| Step: 3
Training loss: 2.7507340908050537
Validation loss: 2.460202755466584

Epoch: 5| Step: 4
Training loss: 2.562377452850342
Validation loss: 2.4712145995068293

Epoch: 5| Step: 5
Training loss: 2.6093831062316895
Validation loss: 2.472785408778857

Epoch: 5| Step: 6
Training loss: 1.6916751861572266
Validation loss: 2.4772632198949016

Epoch: 5| Step: 7
Training loss: 2.9964194297790527
Validation loss: 2.470286061686854

Epoch: 5| Step: 8
Training loss: 2.2500100135803223
Validation loss: 2.47511641440853

Epoch: 5| Step: 9
Training loss: 2.6008777618408203
Validation loss: 2.4751318911070466

Epoch: 5| Step: 10
Training loss: 2.058610677719116
Validation loss: 2.460954802010649

Epoch: 166| Step: 0
Training loss: 2.1887879371643066
Validation loss: 2.458476266553325

Epoch: 5| Step: 1
Training loss: 1.9592998027801514
Validation loss: 2.4679493519567672

Epoch: 5| Step: 2
Training loss: 2.969027042388916
Validation loss: 2.4665798935838925

Epoch: 5| Step: 3
Training loss: 2.6899330615997314
Validation loss: 2.4777612711793635

Epoch: 5| Step: 4
Training loss: 2.791149139404297
Validation loss: 2.492238942012992

Epoch: 5| Step: 5
Training loss: 2.9367568492889404
Validation loss: 2.502085308874807

Epoch: 5| Step: 6
Training loss: 2.1239166259765625
Validation loss: 2.5167985629009944

Epoch: 5| Step: 7
Training loss: 2.225289821624756
Validation loss: 2.5176450411478677

Epoch: 5| Step: 8
Training loss: 2.484203815460205
Validation loss: 2.4984422499133694

Epoch: 5| Step: 9
Training loss: 3.793602705001831
Validation loss: 2.4875486640519995

Epoch: 5| Step: 10
Training loss: 2.7280125617980957
Validation loss: 2.486684537702991

Epoch: 167| Step: 0
Training loss: 2.862698554992676
Validation loss: 2.483288618826097

Epoch: 5| Step: 1
Training loss: 2.8697638511657715
Validation loss: 2.5033037354869228

Epoch: 5| Step: 2
Training loss: 2.6446993350982666
Validation loss: 2.496868069453906

Epoch: 5| Step: 3
Training loss: 2.6045475006103516
Validation loss: 2.4901402458067863

Epoch: 5| Step: 4
Training loss: 2.3546676635742188
Validation loss: 2.466496059971471

Epoch: 5| Step: 5
Training loss: 2.582401752471924
Validation loss: 2.452026803006408

Epoch: 5| Step: 6
Training loss: 2.331033229827881
Validation loss: 2.4454204497798795

Epoch: 5| Step: 7
Training loss: 2.8238511085510254
Validation loss: 2.4495572659277145

Epoch: 5| Step: 8
Training loss: 2.365710496902466
Validation loss: 2.4702921298242386

Epoch: 5| Step: 9
Training loss: 2.3660531044006348
Validation loss: 2.47217405996015

Epoch: 5| Step: 10
Training loss: 3.2152154445648193
Validation loss: 2.451962483826504

Epoch: 168| Step: 0
Training loss: 2.4842586517333984
Validation loss: 2.4508759257613972

Epoch: 5| Step: 1
Training loss: 2.8549392223358154
Validation loss: 2.4426030215396675

Epoch: 5| Step: 2
Training loss: 2.9993016719818115
Validation loss: 2.439569439939273

Epoch: 5| Step: 3
Training loss: 2.1034064292907715
Validation loss: 2.4358813173027447

Epoch: 5| Step: 4
Training loss: 2.9409751892089844
Validation loss: 2.445037608505577

Epoch: 5| Step: 5
Training loss: 3.266190767288208
Validation loss: 2.453671004182549

Epoch: 5| Step: 6
Training loss: 2.6299490928649902
Validation loss: 2.448854531011274

Epoch: 5| Step: 7
Training loss: 1.8351593017578125
Validation loss: 2.460573411756946

Epoch: 5| Step: 8
Training loss: 2.5232186317443848
Validation loss: 2.4646418684272358

Epoch: 5| Step: 9
Training loss: 3.1374356746673584
Validation loss: 2.4626967394223778

Epoch: 5| Step: 10
Training loss: 1.937354564666748
Validation loss: 2.4652340822322394

Epoch: 169| Step: 0
Training loss: 3.1024601459503174
Validation loss: 2.462798615937592

Epoch: 5| Step: 1
Training loss: 2.9869015216827393
Validation loss: 2.463223457336426

Epoch: 5| Step: 2
Training loss: 1.868622064590454
Validation loss: 2.468139589473765

Epoch: 5| Step: 3
Training loss: 2.574474334716797
Validation loss: 2.469599276460627

Epoch: 5| Step: 4
Training loss: 2.852473020553589
Validation loss: 2.4697716518114974

Epoch: 5| Step: 5
Training loss: 2.763423442840576
Validation loss: 2.4703762454371296

Epoch: 5| Step: 6
Training loss: 2.7531445026397705
Validation loss: 2.4722681199350665

Epoch: 5| Step: 7
Training loss: 2.8951194286346436
Validation loss: 2.470088040956887

Epoch: 5| Step: 8
Training loss: 2.0105462074279785
Validation loss: 2.472290300553845

Epoch: 5| Step: 9
Training loss: 2.1047427654266357
Validation loss: 2.468010705004456

Epoch: 5| Step: 10
Training loss: 2.8416907787323
Validation loss: 2.498719202574863

Epoch: 170| Step: 0
Training loss: 2.26424503326416
Validation loss: 2.5036993744552776

Epoch: 5| Step: 1
Training loss: 2.657475233078003
Validation loss: 2.5102673371632895

Epoch: 5| Step: 2
Training loss: 2.7867231369018555
Validation loss: 2.5100614511838524

Epoch: 5| Step: 3
Training loss: 2.9551665782928467
Validation loss: 2.5077305147724767

Epoch: 5| Step: 4
Training loss: 2.6382527351379395
Validation loss: 2.4946269245557886

Epoch: 5| Step: 5
Training loss: 2.160978317260742
Validation loss: 2.479487713947091

Epoch: 5| Step: 6
Training loss: 3.4813263416290283
Validation loss: 2.4686969531479703

Epoch: 5| Step: 7
Training loss: 2.1886792182922363
Validation loss: 2.4695956835182766

Epoch: 5| Step: 8
Training loss: 2.7995505332946777
Validation loss: 2.4524527185706684

Epoch: 5| Step: 9
Training loss: 2.515547513961792
Validation loss: 2.4526364726404988

Epoch: 5| Step: 10
Training loss: 2.1325809955596924
Validation loss: 2.453645606194773

Epoch: 171| Step: 0
Training loss: 2.6024417877197266
Validation loss: 2.4434797046005086

Epoch: 5| Step: 1
Training loss: 2.5144333839416504
Validation loss: 2.4531822050771406

Epoch: 5| Step: 2
Training loss: 3.044956922531128
Validation loss: 2.4567548459576023

Epoch: 5| Step: 3
Training loss: 2.935884475708008
Validation loss: 2.456555494698145

Epoch: 5| Step: 4
Training loss: 2.6115634441375732
Validation loss: 2.4682810127094226

Epoch: 5| Step: 5
Training loss: 2.42144513130188
Validation loss: 2.4661183895603305

Epoch: 5| Step: 6
Training loss: 2.987666368484497
Validation loss: 2.470921383109144

Epoch: 5| Step: 7
Training loss: 2.2893548011779785
Validation loss: 2.4847607304972987

Epoch: 5| Step: 8
Training loss: 1.7573511600494385
Validation loss: 2.483205462014803

Epoch: 5| Step: 9
Training loss: 2.7335963249206543
Validation loss: 2.5031587590453444

Epoch: 5| Step: 10
Training loss: 2.7870850563049316
Validation loss: 2.501727024714152

Epoch: 172| Step: 0
Training loss: 2.4635157585144043
Validation loss: 2.485770061451902

Epoch: 5| Step: 1
Training loss: 2.660569429397583
Validation loss: 2.492876734784854

Epoch: 5| Step: 2
Training loss: 2.283867597579956
Validation loss: 2.4797663368204588

Epoch: 5| Step: 3
Training loss: 3.389212131500244
Validation loss: 2.479741286205989

Epoch: 5| Step: 4
Training loss: 2.7072949409484863
Validation loss: 2.4801513071983092

Epoch: 5| Step: 5
Training loss: 2.6803901195526123
Validation loss: 2.470614569161528

Epoch: 5| Step: 6
Training loss: 2.9095137119293213
Validation loss: 2.4780158842763593

Epoch: 5| Step: 7
Training loss: 1.6991117000579834
Validation loss: 2.4604544101222867

Epoch: 5| Step: 8
Training loss: 2.466865062713623
Validation loss: 2.4707339091967513

Epoch: 5| Step: 9
Training loss: 2.3015027046203613
Validation loss: 2.4668479914306314

Epoch: 5| Step: 10
Training loss: 2.9378273487091064
Validation loss: 2.469050689410138

Epoch: 173| Step: 0
Training loss: 2.1848831176757812
Validation loss: 2.473063386896605

Epoch: 5| Step: 1
Training loss: 2.9247403144836426
Validation loss: 2.4805911407675794

Epoch: 5| Step: 2
Training loss: 3.1641502380371094
Validation loss: 2.4689390864423526

Epoch: 5| Step: 3
Training loss: 2.258579730987549
Validation loss: 2.4626965368947675

Epoch: 5| Step: 4
Training loss: 2.570753574371338
Validation loss: 2.4724528276792137

Epoch: 5| Step: 5
Training loss: 1.9362798929214478
Validation loss: 2.4860125305832073

Epoch: 5| Step: 6
Training loss: 2.916029930114746
Validation loss: 2.495334397080124

Epoch: 5| Step: 7
Training loss: 2.769075632095337
Validation loss: 2.5071467943088983

Epoch: 5| Step: 8
Training loss: 2.7094712257385254
Validation loss: 2.50178881870803

Epoch: 5| Step: 9
Training loss: 3.1965394020080566
Validation loss: 2.4793522845032396

Epoch: 5| Step: 10
Training loss: 2.123015880584717
Validation loss: 2.4680115048603346

Epoch: 174| Step: 0
Training loss: 2.4962551593780518
Validation loss: 2.4475404062578754

Epoch: 5| Step: 1
Training loss: 2.5974152088165283
Validation loss: 2.4462974712412846

Epoch: 5| Step: 2
Training loss: 2.8165817260742188
Validation loss: 2.454744638935212

Epoch: 5| Step: 3
Training loss: 2.129481315612793
Validation loss: 2.457793579306654

Epoch: 5| Step: 4
Training loss: 3.7681775093078613
Validation loss: 2.4614307342037076

Epoch: 5| Step: 5
Training loss: 2.419340133666992
Validation loss: 2.4616285549697055

Epoch: 5| Step: 6
Training loss: 2.861119031906128
Validation loss: 2.466372364310808

Epoch: 5| Step: 7
Training loss: 2.4109859466552734
Validation loss: 2.4598054014226443

Epoch: 5| Step: 8
Training loss: 2.456753730773926
Validation loss: 2.44460153836076

Epoch: 5| Step: 9
Training loss: 2.357229709625244
Validation loss: 2.4507847934640865

Epoch: 5| Step: 10
Training loss: 2.2362115383148193
Validation loss: 2.4443938039964244

Epoch: 175| Step: 0
Training loss: 2.749316692352295
Validation loss: 2.4675480242698424

Epoch: 5| Step: 1
Training loss: 2.4142329692840576
Validation loss: 2.484307458323817

Epoch: 5| Step: 2
Training loss: 2.6783995628356934
Validation loss: 2.490786208901354

Epoch: 5| Step: 3
Training loss: 3.239492416381836
Validation loss: 2.5003350550128567

Epoch: 5| Step: 4
Training loss: 2.6187453269958496
Validation loss: 2.4942699350336546

Epoch: 5| Step: 5
Training loss: 3.0031113624572754
Validation loss: 2.4853951700272097

Epoch: 5| Step: 6
Training loss: 2.167198896408081
Validation loss: 2.474742720204015

Epoch: 5| Step: 7
Training loss: 2.0546765327453613
Validation loss: 2.461625732401366

Epoch: 5| Step: 8
Training loss: 2.245833396911621
Validation loss: 2.4605500826271633

Epoch: 5| Step: 9
Training loss: 2.646578550338745
Validation loss: 2.4621379285730343

Epoch: 5| Step: 10
Training loss: 2.946500539779663
Validation loss: 2.451280291362475

Epoch: 176| Step: 0
Training loss: 2.3470730781555176
Validation loss: 2.4599658699445826

Epoch: 5| Step: 1
Training loss: 2.6841979026794434
Validation loss: 2.4688275347473803

Epoch: 5| Step: 2
Training loss: 2.6074538230895996
Validation loss: 2.4653748055940032

Epoch: 5| Step: 3
Training loss: 2.4821314811706543
Validation loss: 2.4517945884376444

Epoch: 5| Step: 4
Training loss: 2.39384126663208
Validation loss: 2.4492366057570263

Epoch: 5| Step: 5
Training loss: 2.6801743507385254
Validation loss: 2.4647279990616666

Epoch: 5| Step: 6
Training loss: 2.002077579498291
Validation loss: 2.4683737857367403

Epoch: 5| Step: 7
Training loss: 2.983976364135742
Validation loss: 2.466638684272766

Epoch: 5| Step: 8
Training loss: 3.192965030670166
Validation loss: 2.4769673514109787

Epoch: 5| Step: 9
Training loss: 2.7188994884490967
Validation loss: 2.4661483123738277

Epoch: 5| Step: 10
Training loss: 2.4695351123809814
Validation loss: 2.4720039418948594

Epoch: 177| Step: 0
Training loss: 2.85115647315979
Validation loss: 2.4598068344977593

Epoch: 5| Step: 1
Training loss: 2.577500820159912
Validation loss: 2.454443975161481

Epoch: 5| Step: 2
Training loss: 2.128204822540283
Validation loss: 2.4482822905304613

Epoch: 5| Step: 3
Training loss: 2.509246349334717
Validation loss: 2.4608479853599303

Epoch: 5| Step: 4
Training loss: 3.147864818572998
Validation loss: 2.470439507115272

Epoch: 5| Step: 5
Training loss: 2.761183500289917
Validation loss: 2.4665635478112007

Epoch: 5| Step: 6
Training loss: 2.5590009689331055
Validation loss: 2.4636232058207193

Epoch: 5| Step: 7
Training loss: 1.9274879693984985
Validation loss: 2.466327803109282

Epoch: 5| Step: 8
Training loss: 2.8370933532714844
Validation loss: 2.477401118124685

Epoch: 5| Step: 9
Training loss: 2.6331686973571777
Validation loss: 2.4823037142394693

Epoch: 5| Step: 10
Training loss: 2.5361742973327637
Validation loss: 2.479677966845933

Epoch: 178| Step: 0
Training loss: 3.058131694793701
Validation loss: 2.4693631177307456

Epoch: 5| Step: 1
Training loss: 2.617131471633911
Validation loss: 2.458135897113431

Epoch: 5| Step: 2
Training loss: 2.2468507289886475
Validation loss: 2.4552184561247468

Epoch: 5| Step: 3
Training loss: 2.2969868183135986
Validation loss: 2.450524499339442

Epoch: 5| Step: 4
Training loss: 2.173302173614502
Validation loss: 2.446365366699875

Epoch: 5| Step: 5
Training loss: 2.552581310272217
Validation loss: 2.4482348195968138

Epoch: 5| Step: 6
Training loss: 3.3331916332244873
Validation loss: 2.457918149168773

Epoch: 5| Step: 7
Training loss: 2.113171339035034
Validation loss: 2.450484437327231

Epoch: 5| Step: 8
Training loss: 3.118824005126953
Validation loss: 2.4596437177350445

Epoch: 5| Step: 9
Training loss: 2.838717222213745
Validation loss: 2.458658687530025

Epoch: 5| Step: 10
Training loss: 2.04990816116333
Validation loss: 2.4654558089471634

Epoch: 179| Step: 0
Training loss: 2.4824016094207764
Validation loss: 2.454691989447481

Epoch: 5| Step: 1
Training loss: 2.7283122539520264
Validation loss: 2.4506257631445445

Epoch: 5| Step: 2
Training loss: 2.849419355392456
Validation loss: 2.4521091112526516

Epoch: 5| Step: 3
Training loss: 2.980224370956421
Validation loss: 2.442304462514898

Epoch: 5| Step: 4
Training loss: 2.0331954956054688
Validation loss: 2.4466532225249917

Epoch: 5| Step: 5
Training loss: 2.01518177986145
Validation loss: 2.4414271641803045

Epoch: 5| Step: 6
Training loss: 2.2669713497161865
Validation loss: 2.4513056534592823

Epoch: 5| Step: 7
Training loss: 2.7164857387542725
Validation loss: 2.451757623303321

Epoch: 5| Step: 8
Training loss: 2.8612310886383057
Validation loss: 2.4606949795958815

Epoch: 5| Step: 9
Training loss: 2.948653221130371
Validation loss: 2.46528596262778

Epoch: 5| Step: 10
Training loss: 2.547090530395508
Validation loss: 2.460658622044389

Epoch: 180| Step: 0
Training loss: 2.49576473236084
Validation loss: 2.4587662091819187

Epoch: 5| Step: 1
Training loss: 2.7269599437713623
Validation loss: 2.464007523752028

Epoch: 5| Step: 2
Training loss: 2.4690940380096436
Validation loss: 2.459964644524359

Epoch: 5| Step: 3
Training loss: 2.78969144821167
Validation loss: 2.4603101566273677

Epoch: 5| Step: 4
Training loss: 2.8460934162139893
Validation loss: 2.462949509261757

Epoch: 5| Step: 5
Training loss: 2.660466432571411
Validation loss: 2.450665630320067

Epoch: 5| Step: 6
Training loss: 2.326129913330078
Validation loss: 2.466807537181403

Epoch: 5| Step: 7
Training loss: 2.452810287475586
Validation loss: 2.4735247127471434

Epoch: 5| Step: 8
Training loss: 2.4735145568847656
Validation loss: 2.4662207018944526

Epoch: 5| Step: 9
Training loss: 3.1251842975616455
Validation loss: 2.471633106149653

Epoch: 5| Step: 10
Training loss: 2.0556538105010986
Validation loss: 2.474236601142473

Epoch: 181| Step: 0
Training loss: 2.9308836460113525
Validation loss: 2.4640540102476716

Epoch: 5| Step: 1
Training loss: 2.3870463371276855
Validation loss: 2.4730412088414675

Epoch: 5| Step: 2
Training loss: 3.0255191326141357
Validation loss: 2.4792694096924155

Epoch: 5| Step: 3
Training loss: 2.4005675315856934
Validation loss: 2.485258671545213

Epoch: 5| Step: 4
Training loss: 2.657214641571045
Validation loss: 2.497666274347613

Epoch: 5| Step: 5
Training loss: 2.1901097297668457
Validation loss: 2.482626394558978

Epoch: 5| Step: 6
Training loss: 2.549104690551758
Validation loss: 2.490512841491289

Epoch: 5| Step: 7
Training loss: 2.1440529823303223
Validation loss: 2.4681720387551094

Epoch: 5| Step: 8
Training loss: 3.021914482116699
Validation loss: 2.4541619464915287

Epoch: 5| Step: 9
Training loss: 2.919567584991455
Validation loss: 2.445684209946663

Epoch: 5| Step: 10
Training loss: 2.2105937004089355
Validation loss: 2.424663145055053

Epoch: 182| Step: 0
Training loss: 2.488060474395752
Validation loss: 2.4268437354795394

Epoch: 5| Step: 1
Training loss: 2.673900604248047
Validation loss: 2.42979762887442

Epoch: 5| Step: 2
Training loss: 2.6698505878448486
Validation loss: 2.438649228824082

Epoch: 5| Step: 3
Training loss: 2.7562949657440186
Validation loss: 2.435914477994365

Epoch: 5| Step: 4
Training loss: 2.60990834236145
Validation loss: 2.435618967138311

Epoch: 5| Step: 5
Training loss: 2.042729377746582
Validation loss: 2.435562659335393

Epoch: 5| Step: 6
Training loss: 3.005140781402588
Validation loss: 2.4315253996079966

Epoch: 5| Step: 7
Training loss: 2.5809741020202637
Validation loss: 2.42875946721723

Epoch: 5| Step: 8
Training loss: 2.4985904693603516
Validation loss: 2.4324267141280638

Epoch: 5| Step: 9
Training loss: 2.448103189468384
Validation loss: 2.433843051233599

Epoch: 5| Step: 10
Training loss: 2.7070300579071045
Validation loss: 2.441264078181277

Epoch: 183| Step: 0
Training loss: 2.7387263774871826
Validation loss: 2.4428296345536427

Epoch: 5| Step: 1
Training loss: 2.761894702911377
Validation loss: 2.4473043077735492

Epoch: 5| Step: 2
Training loss: 3.1307826042175293
Validation loss: 2.4378240416126866

Epoch: 5| Step: 3
Training loss: 2.7931387424468994
Validation loss: 2.4447213449785785

Epoch: 5| Step: 4
Training loss: 2.3181138038635254
Validation loss: 2.452449006419028

Epoch: 5| Step: 5
Training loss: 2.436119318008423
Validation loss: 2.4364558112236763

Epoch: 5| Step: 6
Training loss: 2.324061155319214
Validation loss: 2.4390019191208707

Epoch: 5| Step: 7
Training loss: 2.575026750564575
Validation loss: 2.440798464641776

Epoch: 5| Step: 8
Training loss: 1.9161465167999268
Validation loss: 2.4409543980834303

Epoch: 5| Step: 9
Training loss: 2.518339157104492
Validation loss: 2.447025619527345

Epoch: 5| Step: 10
Training loss: 3.0260608196258545
Validation loss: 2.4481889406840005

Epoch: 184| Step: 0
Training loss: 2.477055788040161
Validation loss: 2.449718142068514

Epoch: 5| Step: 1
Training loss: 2.156965732574463
Validation loss: 2.4599063268271824

Epoch: 5| Step: 2
Training loss: 2.6290194988250732
Validation loss: 2.4715735245776433

Epoch: 5| Step: 3
Training loss: 3.0083203315734863
Validation loss: 2.468423217855474

Epoch: 5| Step: 4
Training loss: 2.632403612136841
Validation loss: 2.4614133424656366

Epoch: 5| Step: 5
Training loss: 2.821244955062866
Validation loss: 2.467885119940645

Epoch: 5| Step: 6
Training loss: 3.131253957748413
Validation loss: 2.4783401335439375

Epoch: 5| Step: 7
Training loss: 2.71004056930542
Validation loss: 2.486289785754296

Epoch: 5| Step: 8
Training loss: 2.2183845043182373
Validation loss: 2.469929648983863

Epoch: 5| Step: 9
Training loss: 2.3838675022125244
Validation loss: 2.46375181341684

Epoch: 5| Step: 10
Training loss: 2.269792318344116
Validation loss: 2.463193271749763

Epoch: 185| Step: 0
Training loss: 1.9689048528671265
Validation loss: 2.448551008778234

Epoch: 5| Step: 1
Training loss: 2.4301931858062744
Validation loss: 2.4446830621329685

Epoch: 5| Step: 2
Training loss: 2.635453224182129
Validation loss: 2.4403942913137455

Epoch: 5| Step: 3
Training loss: 2.2121026515960693
Validation loss: 2.4466905773326917

Epoch: 5| Step: 4
Training loss: 3.546168565750122
Validation loss: 2.4504926230317805

Epoch: 5| Step: 5
Training loss: 2.563838481903076
Validation loss: 2.4618672170946674

Epoch: 5| Step: 6
Training loss: 2.313053846359253
Validation loss: 2.4631224037498556

Epoch: 5| Step: 7
Training loss: 2.5059125423431396
Validation loss: 2.465443385544644

Epoch: 5| Step: 8
Training loss: 2.6966538429260254
Validation loss: 2.4774525985922864

Epoch: 5| Step: 9
Training loss: 2.676112651824951
Validation loss: 2.493796443426481

Epoch: 5| Step: 10
Training loss: 2.8496601581573486
Validation loss: 2.470775137665451

Epoch: 186| Step: 0
Training loss: 2.7717108726501465
Validation loss: 2.47733707838161

Epoch: 5| Step: 1
Training loss: 2.350456714630127
Validation loss: 2.4810732795346166

Epoch: 5| Step: 2
Training loss: 2.5455129146575928
Validation loss: 2.467816286189582

Epoch: 5| Step: 3
Training loss: 2.8893518447875977
Validation loss: 2.4617528889768865

Epoch: 5| Step: 4
Training loss: 3.235630512237549
Validation loss: 2.446565079432662

Epoch: 5| Step: 5
Training loss: 1.7148711681365967
Validation loss: 2.445668125665316

Epoch: 5| Step: 6
Training loss: 2.3694100379943848
Validation loss: 2.4343708843313236

Epoch: 5| Step: 7
Training loss: 3.267192840576172
Validation loss: 2.4408976800980104

Epoch: 5| Step: 8
Training loss: 2.1431984901428223
Validation loss: 2.4362213585966375

Epoch: 5| Step: 9
Training loss: 2.629795551300049
Validation loss: 2.46343296317644

Epoch: 5| Step: 10
Training loss: 2.368475914001465
Validation loss: 2.45955716922719

Epoch: 187| Step: 0
Training loss: 2.061223268508911
Validation loss: 2.4559374240136917

Epoch: 5| Step: 1
Training loss: 2.8232223987579346
Validation loss: 2.470345861168318

Epoch: 5| Step: 2
Training loss: 2.325822114944458
Validation loss: 2.474289365994033

Epoch: 5| Step: 3
Training loss: 2.463496685028076
Validation loss: 2.463867125972625

Epoch: 5| Step: 4
Training loss: 2.8403751850128174
Validation loss: 2.457863559005081

Epoch: 5| Step: 5
Training loss: 2.274465799331665
Validation loss: 2.4541814711786087

Epoch: 5| Step: 6
Training loss: 3.0452072620391846
Validation loss: 2.4531114767956477

Epoch: 5| Step: 7
Training loss: 3.5424582958221436
Validation loss: 2.4713590786021244

Epoch: 5| Step: 8
Training loss: 2.661285877227783
Validation loss: 2.476577471661311

Epoch: 5| Step: 9
Training loss: 2.3579413890838623
Validation loss: 2.4625408187989266

Epoch: 5| Step: 10
Training loss: 1.6873422861099243
Validation loss: 2.451098967623967

Epoch: 188| Step: 0
Training loss: 2.297402858734131
Validation loss: 2.446988667211225

Epoch: 5| Step: 1
Training loss: 2.848508596420288
Validation loss: 2.435857565172257

Epoch: 5| Step: 2
Training loss: 1.9177592992782593
Validation loss: 2.447020710155528

Epoch: 5| Step: 3
Training loss: 3.342419385910034
Validation loss: 2.4513766534866823

Epoch: 5| Step: 4
Training loss: 2.7481017112731934
Validation loss: 2.438721925981583

Epoch: 5| Step: 5
Training loss: 2.510017156600952
Validation loss: 2.424992897177255

Epoch: 5| Step: 6
Training loss: 2.472503662109375
Validation loss: 2.4236069238314064

Epoch: 5| Step: 7
Training loss: 2.4545645713806152
Validation loss: 2.4193650650721725

Epoch: 5| Step: 8
Training loss: 2.4675660133361816
Validation loss: 2.4181493123372397

Epoch: 5| Step: 9
Training loss: 3.031618118286133
Validation loss: 2.4265880789808048

Epoch: 5| Step: 10
Training loss: 2.16691517829895
Validation loss: 2.4414049604887604

Epoch: 189| Step: 0
Training loss: 2.706639289855957
Validation loss: 2.4443498849868774

Epoch: 5| Step: 1
Training loss: 2.520167589187622
Validation loss: 2.4587824395907822

Epoch: 5| Step: 2
Training loss: 2.722160816192627
Validation loss: 2.4730111309277114

Epoch: 5| Step: 3
Training loss: 3.051847457885742
Validation loss: 2.4566251283050864

Epoch: 5| Step: 4
Training loss: 2.55311918258667
Validation loss: 2.4601099491119385

Epoch: 5| Step: 5
Training loss: 2.765923500061035
Validation loss: 2.457637725337859

Epoch: 5| Step: 6
Training loss: 2.3822479248046875
Validation loss: 2.455393568161995

Epoch: 5| Step: 7
Training loss: 2.471264362335205
Validation loss: 2.4510796275190128

Epoch: 5| Step: 8
Training loss: 1.9365968704223633
Validation loss: 2.43773373224402

Epoch: 5| Step: 9
Training loss: 2.420562505722046
Validation loss: 2.438422267154981

Epoch: 5| Step: 10
Training loss: 2.812894821166992
Validation loss: 2.4311391333098054

Epoch: 190| Step: 0
Training loss: 2.2070114612579346
Validation loss: 2.416272340282317

Epoch: 5| Step: 1
Training loss: 1.8890435695648193
Validation loss: 2.41543488348684

Epoch: 5| Step: 2
Training loss: 2.339445114135742
Validation loss: 2.4064151881843485

Epoch: 5| Step: 3
Training loss: 2.881901979446411
Validation loss: 2.420870465617026

Epoch: 5| Step: 4
Training loss: 2.279827833175659
Validation loss: 2.4243629132547686

Epoch: 5| Step: 5
Training loss: 2.51847505569458
Validation loss: 2.4229948828297276

Epoch: 5| Step: 6
Training loss: 2.320767641067505
Validation loss: 2.4231114592603458

Epoch: 5| Step: 7
Training loss: 2.537731885910034
Validation loss: 2.426448691275812

Epoch: 5| Step: 8
Training loss: 3.0466346740722656
Validation loss: 2.418051476119667

Epoch: 5| Step: 9
Training loss: 3.1027321815490723
Validation loss: 2.4239602755474787

Epoch: 5| Step: 10
Training loss: 3.3326706886291504
Validation loss: 2.43191102755967

Epoch: 191| Step: 0
Training loss: 2.5534560680389404
Validation loss: 2.4338701309696322

Epoch: 5| Step: 1
Training loss: 1.729100227355957
Validation loss: 2.4271702997146116

Epoch: 5| Step: 2
Training loss: 2.6422348022460938
Validation loss: 2.4413141871011383

Epoch: 5| Step: 3
Training loss: 2.840137004852295
Validation loss: 2.4438208123689056

Epoch: 5| Step: 4
Training loss: 2.5327951908111572
Validation loss: 2.4455044987381145

Epoch: 5| Step: 5
Training loss: 3.322925567626953
Validation loss: 2.4354220744102233

Epoch: 5| Step: 6
Training loss: 2.4999773502349854
Validation loss: 2.455747467215343

Epoch: 5| Step: 7
Training loss: 2.682097911834717
Validation loss: 2.451774570249742

Epoch: 5| Step: 8
Training loss: 1.803131103515625
Validation loss: 2.459107688678208

Epoch: 5| Step: 9
Training loss: 3.0243749618530273
Validation loss: 2.4787743142856065

Epoch: 5| Step: 10
Training loss: 2.6894073486328125
Validation loss: 2.455237022010229

Epoch: 192| Step: 0
Training loss: 3.151665449142456
Validation loss: 2.459904806588286

Epoch: 5| Step: 1
Training loss: 2.1802914142608643
Validation loss: 2.4545890797850904

Epoch: 5| Step: 2
Training loss: 2.4096813201904297
Validation loss: 2.4514726720830446

Epoch: 5| Step: 3
Training loss: 2.2373013496398926
Validation loss: 2.4496588142969276

Epoch: 5| Step: 4
Training loss: 2.6114535331726074
Validation loss: 2.4681354389395764

Epoch: 5| Step: 5
Training loss: 2.602186441421509
Validation loss: 2.458447205123081

Epoch: 5| Step: 6
Training loss: 3.0519261360168457
Validation loss: 2.446873967365552

Epoch: 5| Step: 7
Training loss: 3.3449883460998535
Validation loss: 2.4489377724227084

Epoch: 5| Step: 8
Training loss: 1.8260624408721924
Validation loss: 2.4453255899490847

Epoch: 5| Step: 9
Training loss: 2.657331943511963
Validation loss: 2.463484735899074

Epoch: 5| Step: 10
Training loss: 2.291630744934082
Validation loss: 2.4761620542054534

Epoch: 193| Step: 0
Training loss: 2.2237284183502197
Validation loss: 2.4697625842145694

Epoch: 5| Step: 1
Training loss: 2.5703628063201904
Validation loss: 2.445331455558859

Epoch: 5| Step: 2
Training loss: 2.0287435054779053
Validation loss: 2.4489628166280766

Epoch: 5| Step: 3
Training loss: 2.4760262966156006
Validation loss: 2.439628356246538

Epoch: 5| Step: 4
Training loss: 1.6556888818740845
Validation loss: 2.4295981622511342

Epoch: 5| Step: 5
Training loss: 3.009166717529297
Validation loss: 2.424372139797416

Epoch: 5| Step: 6
Training loss: 2.991124391555786
Validation loss: 2.4191568154160694

Epoch: 5| Step: 7
Training loss: 3.3213417530059814
Validation loss: 2.4104382837972333

Epoch: 5| Step: 8
Training loss: 2.927328586578369
Validation loss: 2.404278814151723

Epoch: 5| Step: 9
Training loss: 2.564711332321167
Validation loss: 2.405446921625445

Epoch: 5| Step: 10
Training loss: 2.4651153087615967
Validation loss: 2.4103440725675194

Epoch: 194| Step: 0
Training loss: 2.287992000579834
Validation loss: 2.4173031340363207

Epoch: 5| Step: 1
Training loss: 2.508639335632324
Validation loss: 2.41489395787639

Epoch: 5| Step: 2
Training loss: 2.0471436977386475
Validation loss: 2.419878534091416

Epoch: 5| Step: 3
Training loss: 3.268230438232422
Validation loss: 2.4180299312837663

Epoch: 5| Step: 4
Training loss: 2.2581496238708496
Validation loss: 2.4400416548534105

Epoch: 5| Step: 5
Training loss: 2.5376129150390625
Validation loss: 2.4381453708935807

Epoch: 5| Step: 6
Training loss: 2.302114486694336
Validation loss: 2.428514765154931

Epoch: 5| Step: 7
Training loss: 2.336730718612671
Validation loss: 2.4342391362754245

Epoch: 5| Step: 8
Training loss: 2.8000829219818115
Validation loss: 2.436811125406655

Epoch: 5| Step: 9
Training loss: 3.231184482574463
Validation loss: 2.4350896163653304

Epoch: 5| Step: 10
Training loss: 2.5961110591888428
Validation loss: 2.4286647253139044

Epoch: 195| Step: 0
Training loss: 2.8721580505371094
Validation loss: 2.428104410889328

Epoch: 5| Step: 1
Training loss: 2.6894350051879883
Validation loss: 2.41352359197473

Epoch: 5| Step: 2
Training loss: 1.9689804315567017
Validation loss: 2.405572323388951

Epoch: 5| Step: 3
Training loss: 2.561945676803589
Validation loss: 2.413881071152226

Epoch: 5| Step: 4
Training loss: 2.690725564956665
Validation loss: 2.41157667867599

Epoch: 5| Step: 5
Training loss: 1.9510667324066162
Validation loss: 2.4007282359625703

Epoch: 5| Step: 6
Training loss: 3.0151162147521973
Validation loss: 2.3994040399469356

Epoch: 5| Step: 7
Training loss: 2.340301990509033
Validation loss: 2.4088753859202066

Epoch: 5| Step: 8
Training loss: 3.2309136390686035
Validation loss: 2.4050226262820664

Epoch: 5| Step: 9
Training loss: 2.321122169494629
Validation loss: 2.4205259558975056

Epoch: 5| Step: 10
Training loss: 2.6112921237945557
Validation loss: 2.428959451695924

Epoch: 196| Step: 0
Training loss: 2.554377794265747
Validation loss: 2.431571565648561

Epoch: 5| Step: 1
Training loss: 2.646044969558716
Validation loss: 2.4465021061640915

Epoch: 5| Step: 2
Training loss: 2.607809543609619
Validation loss: 2.448547842682049

Epoch: 5| Step: 3
Training loss: 2.7534127235412598
Validation loss: 2.4563510238483386

Epoch: 5| Step: 4
Training loss: 2.091498851776123
Validation loss: 2.4703164792829946

Epoch: 5| Step: 5
Training loss: 2.27950119972229
Validation loss: 2.466587374287267

Epoch: 5| Step: 6
Training loss: 2.460458278656006
Validation loss: 2.488820063170566

Epoch: 5| Step: 7
Training loss: 2.3490424156188965
Validation loss: 2.4693231659550823

Epoch: 5| Step: 8
Training loss: 3.048387289047241
Validation loss: 2.4630214347634265

Epoch: 5| Step: 9
Training loss: 3.0384833812713623
Validation loss: 2.4456262973047074

Epoch: 5| Step: 10
Training loss: 2.4998059272766113
Validation loss: 2.433133840560913

Epoch: 197| Step: 0
Training loss: 2.737061023712158
Validation loss: 2.4280829839808966

Epoch: 5| Step: 1
Training loss: 2.4775283336639404
Validation loss: 2.4154092086258756

Epoch: 5| Step: 2
Training loss: 2.378549098968506
Validation loss: 2.4239691970168904

Epoch: 5| Step: 3
Training loss: 2.8801803588867188
Validation loss: 2.4126709738085346

Epoch: 5| Step: 4
Training loss: 3.011294364929199
Validation loss: 2.4208910849786576

Epoch: 5| Step: 5
Training loss: 2.300938367843628
Validation loss: 2.41611304847143

Epoch: 5| Step: 6
Training loss: 2.543401002883911
Validation loss: 2.421164115269979

Epoch: 5| Step: 7
Training loss: 2.133892059326172
Validation loss: 2.418634142926944

Epoch: 5| Step: 8
Training loss: 2.8355822563171387
Validation loss: 2.4227230882131927

Epoch: 5| Step: 9
Training loss: 2.769252300262451
Validation loss: 2.421673850346637

Epoch: 5| Step: 10
Training loss: 2.1291260719299316
Validation loss: 2.422909877633536

Epoch: 198| Step: 0
Training loss: 2.8914794921875
Validation loss: 2.418507754161794

Epoch: 5| Step: 1
Training loss: 2.770336627960205
Validation loss: 2.4149538086306666

Epoch: 5| Step: 2
Training loss: 3.054673671722412
Validation loss: 2.4113203017942366

Epoch: 5| Step: 3
Training loss: 2.767944812774658
Validation loss: 2.414070339613063

Epoch: 5| Step: 4
Training loss: 2.2266321182250977
Validation loss: 2.4183913302677933

Epoch: 5| Step: 5
Training loss: 2.742649555206299
Validation loss: 2.4260612431392876

Epoch: 5| Step: 6
Training loss: 2.184051990509033
Validation loss: 2.434791716196204

Epoch: 5| Step: 7
Training loss: 2.289308786392212
Validation loss: 2.4372309484789447

Epoch: 5| Step: 8
Training loss: 2.1600847244262695
Validation loss: 2.4352805819562686

Epoch: 5| Step: 9
Training loss: 2.5273125171661377
Validation loss: 2.4344661825446674

Epoch: 5| Step: 10
Training loss: 2.6288373470306396
Validation loss: 2.433557464230445

Epoch: 199| Step: 0
Training loss: 2.899501323699951
Validation loss: 2.432334383328756

Epoch: 5| Step: 1
Training loss: 2.9173803329467773
Validation loss: 2.4352951408714376

Epoch: 5| Step: 2
Training loss: 2.7772035598754883
Validation loss: 2.4380752143039497

Epoch: 5| Step: 3
Training loss: 2.6767852306365967
Validation loss: 2.4514050278612363

Epoch: 5| Step: 4
Training loss: 2.7175018787384033
Validation loss: 2.4582415549985823

Epoch: 5| Step: 5
Training loss: 2.3293962478637695
Validation loss: 2.4336495784021195

Epoch: 5| Step: 6
Training loss: 2.562453269958496
Validation loss: 2.4363443569470475

Epoch: 5| Step: 7
Training loss: 1.890761375427246
Validation loss: 2.43039402269548

Epoch: 5| Step: 8
Training loss: 1.7835079431533813
Validation loss: 2.4283876034521286

Epoch: 5| Step: 9
Training loss: 2.880741834640503
Validation loss: 2.435628244953771

Epoch: 5| Step: 10
Training loss: 2.7252767086029053
Validation loss: 2.43326541941653

Epoch: 200| Step: 0
Training loss: 2.557007312774658
Validation loss: 2.4226393622736775

Epoch: 5| Step: 1
Training loss: 2.0119998455047607
Validation loss: 2.4010381365335114

Epoch: 5| Step: 2
Training loss: 2.2052040100097656
Validation loss: 2.405029143056562

Epoch: 5| Step: 3
Training loss: 2.908236026763916
Validation loss: 2.4110215684419036

Epoch: 5| Step: 4
Training loss: 2.5334300994873047
Validation loss: 2.4032884669560257

Epoch: 5| Step: 5
Training loss: 2.2794265747070312
Validation loss: 2.4233982460473174

Epoch: 5| Step: 6
Training loss: 2.2049460411071777
Validation loss: 2.4216624126639417

Epoch: 5| Step: 7
Training loss: 2.873274564743042
Validation loss: 2.404455864301292

Epoch: 5| Step: 8
Training loss: 3.451770782470703
Validation loss: 2.4080620965650006

Epoch: 5| Step: 9
Training loss: 2.6165823936462402
Validation loss: 2.4012542129844747

Epoch: 5| Step: 10
Training loss: 2.5116770267486572
Validation loss: 2.3963997543499036

Epoch: 201| Step: 0
Training loss: 3.277862548828125
Validation loss: 2.398399677327884

Epoch: 5| Step: 1
Training loss: 2.757103681564331
Validation loss: 2.4062332055901967

Epoch: 5| Step: 2
Training loss: 2.862031936645508
Validation loss: 2.4067989844147877

Epoch: 5| Step: 3
Training loss: 2.4669783115386963
Validation loss: 2.4161352034538024

Epoch: 5| Step: 4
Training loss: 2.721200466156006
Validation loss: 2.420641242816884

Epoch: 5| Step: 5
Training loss: 2.8792788982391357
Validation loss: 2.4200773444226993

Epoch: 5| Step: 6
Training loss: 2.3263165950775146
Validation loss: 2.4103272525213097

Epoch: 5| Step: 7
Training loss: 2.505614757537842
Validation loss: 2.4128903688923007

Epoch: 5| Step: 8
Training loss: 1.3526077270507812
Validation loss: 2.412121824038926

Epoch: 5| Step: 9
Training loss: 3.0455174446105957
Validation loss: 2.414168826995357

Epoch: 5| Step: 10
Training loss: 1.8201513290405273
Validation loss: 2.405331039941439

Epoch: 202| Step: 0
Training loss: 2.444174289703369
Validation loss: 2.4184240423223025

Epoch: 5| Step: 1
Training loss: 2.287168025970459
Validation loss: 2.4217094323968373

Epoch: 5| Step: 2
Training loss: 2.6164746284484863
Validation loss: 2.4231073035988757

Epoch: 5| Step: 3
Training loss: 2.88586163520813
Validation loss: 2.423767287244079

Epoch: 5| Step: 4
Training loss: 2.5359787940979004
Validation loss: 2.44728567395159

Epoch: 5| Step: 5
Training loss: 2.2138543128967285
Validation loss: 2.4531610088963665

Epoch: 5| Step: 6
Training loss: 3.073042631149292
Validation loss: 2.448935362600511

Epoch: 5| Step: 7
Training loss: 2.8083391189575195
Validation loss: 2.4411380854986047

Epoch: 5| Step: 8
Training loss: 3.0627481937408447
Validation loss: 2.4328750743660876

Epoch: 5| Step: 9
Training loss: 1.6592899560928345
Validation loss: 2.42670028696778

Epoch: 5| Step: 10
Training loss: 2.5098958015441895
Validation loss: 2.4165030499940277

Epoch: 203| Step: 0
Training loss: 2.98175311088562
Validation loss: 2.427067764343754

Epoch: 5| Step: 1
Training loss: 2.8374314308166504
Validation loss: 2.440492473622804

Epoch: 5| Step: 2
Training loss: 2.244851589202881
Validation loss: 2.4523694181954987

Epoch: 5| Step: 3
Training loss: 1.9921150207519531
Validation loss: 2.464449390288322

Epoch: 5| Step: 4
Training loss: 3.667980670928955
Validation loss: 2.4602365416865193

Epoch: 5| Step: 5
Training loss: 1.9764289855957031
Validation loss: 2.4542687464785833

Epoch: 5| Step: 6
Training loss: 2.5470175743103027
Validation loss: 2.441802296587216

Epoch: 5| Step: 7
Training loss: 2.552412509918213
Validation loss: 2.433063014861076

Epoch: 5| Step: 8
Training loss: 2.4622890949249268
Validation loss: 2.4229480066607074

Epoch: 5| Step: 9
Training loss: 2.131380319595337
Validation loss: 2.4294850492990143

Epoch: 5| Step: 10
Training loss: 2.7912673950195312
Validation loss: 2.423002202023742

Epoch: 204| Step: 0
Training loss: 2.9547841548919678
Validation loss: 2.428715982744771

Epoch: 5| Step: 1
Training loss: 2.666156768798828
Validation loss: 2.4429220307257866

Epoch: 5| Step: 2
Training loss: 2.6079025268554688
Validation loss: 2.447854734236194

Epoch: 5| Step: 3
Training loss: 2.2986319065093994
Validation loss: 2.4410071552440686

Epoch: 5| Step: 4
Training loss: 2.1645476818084717
Validation loss: 2.445696605149136

Epoch: 5| Step: 5
Training loss: 2.9628634452819824
Validation loss: 2.441277914149787

Epoch: 5| Step: 6
Training loss: 2.5089709758758545
Validation loss: 2.4288122384778914

Epoch: 5| Step: 7
Training loss: 2.1943020820617676
Validation loss: 2.4190186685131443

Epoch: 5| Step: 8
Training loss: 3.01704478263855
Validation loss: 2.420939596750403

Epoch: 5| Step: 9
Training loss: 2.0167031288146973
Validation loss: 2.4078467225515716

Epoch: 5| Step: 10
Training loss: 2.7760396003723145
Validation loss: 2.428141665715043

Epoch: 205| Step: 0
Training loss: 2.324352741241455
Validation loss: 2.4330698367088073

Epoch: 5| Step: 1
Training loss: 2.6975526809692383
Validation loss: 2.467312241113314

Epoch: 5| Step: 2
Training loss: 1.9952081441879272
Validation loss: 2.47168549670968

Epoch: 5| Step: 3
Training loss: 2.85640287399292
Validation loss: 2.459427320829002

Epoch: 5| Step: 4
Training loss: 2.6405773162841797
Validation loss: 2.467627784257294

Epoch: 5| Step: 5
Training loss: 2.7556161880493164
Validation loss: 2.455935537174184

Epoch: 5| Step: 6
Training loss: 2.6675610542297363
Validation loss: 2.4407183047263854

Epoch: 5| Step: 7
Training loss: 2.632437229156494
Validation loss: 2.434537708118398

Epoch: 5| Step: 8
Training loss: 2.4569878578186035
Validation loss: 2.419934477857364

Epoch: 5| Step: 9
Training loss: 2.4384303092956543
Validation loss: 2.4165076004561556

Epoch: 5| Step: 10
Training loss: 2.6350791454315186
Validation loss: 2.4182510427249375

Epoch: 206| Step: 0
Training loss: 2.018815040588379
Validation loss: 2.4206744124812465

Epoch: 5| Step: 1
Training loss: 2.8647189140319824
Validation loss: 2.4226593253433064

Epoch: 5| Step: 2
Training loss: 2.511002540588379
Validation loss: 2.4235348111839703

Epoch: 5| Step: 3
Training loss: 2.9623847007751465
Validation loss: 2.4133158806831605

Epoch: 5| Step: 4
Training loss: 2.422135829925537
Validation loss: 2.4034730234453754

Epoch: 5| Step: 5
Training loss: 2.7579917907714844
Validation loss: 2.394898642775833

Epoch: 5| Step: 6
Training loss: 2.736419200897217
Validation loss: 2.398484044177558

Epoch: 5| Step: 7
Training loss: 1.7797520160675049
Validation loss: 2.3947562761204217

Epoch: 5| Step: 8
Training loss: 3.68888783454895
Validation loss: 2.408064019295477

Epoch: 5| Step: 9
Training loss: 2.073747158050537
Validation loss: 2.4051062522395963

Epoch: 5| Step: 10
Training loss: 2.2445504665374756
Validation loss: 2.4115235036419285

Epoch: 207| Step: 0
Training loss: 2.4079983234405518
Validation loss: 2.405242348230013

Epoch: 5| Step: 1
Training loss: 2.8362629413604736
Validation loss: 2.4034278341518935

Epoch: 5| Step: 2
Training loss: 3.1684021949768066
Validation loss: 2.4185773967414774

Epoch: 5| Step: 3
Training loss: 1.7655408382415771
Validation loss: 2.413030542353148

Epoch: 5| Step: 4
Training loss: 2.921091079711914
Validation loss: 2.4185685111630346

Epoch: 5| Step: 5
Training loss: 2.64723801612854
Validation loss: 2.420208531041299

Epoch: 5| Step: 6
Training loss: 2.6029863357543945
Validation loss: 2.4193178581935104

Epoch: 5| Step: 7
Training loss: 1.9801967144012451
Validation loss: 2.4306256642905613

Epoch: 5| Step: 8
Training loss: 2.7546355724334717
Validation loss: 2.428442347434259

Epoch: 5| Step: 9
Training loss: 2.4285473823547363
Validation loss: 2.436793383731637

Epoch: 5| Step: 10
Training loss: 2.4054036140441895
Validation loss: 2.4246560501795944

Epoch: 208| Step: 0
Training loss: 3.041865587234497
Validation loss: 2.425512162587976

Epoch: 5| Step: 1
Training loss: 2.3054399490356445
Validation loss: 2.4123930264544744

Epoch: 5| Step: 2
Training loss: 2.1324474811553955
Validation loss: 2.4246804380929596

Epoch: 5| Step: 3
Training loss: 2.9838719367980957
Validation loss: 2.4336769196294967

Epoch: 5| Step: 4
Training loss: 2.896725654602051
Validation loss: 2.409149282722063

Epoch: 5| Step: 5
Training loss: 2.5812554359436035
Validation loss: 2.402340207048642

Epoch: 5| Step: 6
Training loss: 2.4795711040496826
Validation loss: 2.4020001888275146

Epoch: 5| Step: 7
Training loss: 2.7410778999328613
Validation loss: 2.408152036769416

Epoch: 5| Step: 8
Training loss: 2.3176167011260986
Validation loss: 2.4097994540327337

Epoch: 5| Step: 9
Training loss: 2.3617730140686035
Validation loss: 2.4148948474596907

Epoch: 5| Step: 10
Training loss: 2.1345674991607666
Validation loss: 2.398386811697355

Epoch: 209| Step: 0
Training loss: 2.5710625648498535
Validation loss: 2.4208900159405125

Epoch: 5| Step: 1
Training loss: 1.6630125045776367
Validation loss: 2.4049532439119075

Epoch: 5| Step: 2
Training loss: 2.624002456665039
Validation loss: 2.4040227782341743

Epoch: 5| Step: 3
Training loss: 2.701586961746216
Validation loss: 2.4051699817821546

Epoch: 5| Step: 4
Training loss: 2.346623182296753
Validation loss: 2.404464683225078

Epoch: 5| Step: 5
Training loss: 2.5104427337646484
Validation loss: 2.422510075312789

Epoch: 5| Step: 6
Training loss: 3.3218657970428467
Validation loss: 2.413385719381353

Epoch: 5| Step: 7
Training loss: 2.7236392498016357
Validation loss: 2.4445163793461298

Epoch: 5| Step: 8
Training loss: 2.551866054534912
Validation loss: 2.4371315971497567

Epoch: 5| Step: 9
Training loss: 2.8078484535217285
Validation loss: 2.4324694756538636

Epoch: 5| Step: 10
Training loss: 1.9707672595977783
Validation loss: 2.4261186866350073

Epoch: 210| Step: 0
Training loss: 2.806265354156494
Validation loss: 2.435967468446301

Epoch: 5| Step: 1
Training loss: 3.0223121643066406
Validation loss: 2.4057560582314768

Epoch: 5| Step: 2
Training loss: 1.8428001403808594
Validation loss: 2.3976892220076693

Epoch: 5| Step: 3
Training loss: 3.0592079162597656
Validation loss: 2.3964770378605014

Epoch: 5| Step: 4
Training loss: 1.8629881143569946
Validation loss: 2.398667053509784

Epoch: 5| Step: 5
Training loss: 2.3057730197906494
Validation loss: 2.387210697256109

Epoch: 5| Step: 6
Training loss: 2.2966766357421875
Validation loss: 2.3868745911505913

Epoch: 5| Step: 7
Training loss: 2.7041640281677246
Validation loss: 2.399139896515877

Epoch: 5| Step: 8
Training loss: 2.840294361114502
Validation loss: 2.4074348941926034

Epoch: 5| Step: 9
Training loss: 2.6267409324645996
Validation loss: 2.4399180463565293

Epoch: 5| Step: 10
Training loss: 2.7300500869750977
Validation loss: 2.4272496264467955

Epoch: 211| Step: 0
Training loss: 2.8925414085388184
Validation loss: 2.4380175708442606

Epoch: 5| Step: 1
Training loss: 2.2669625282287598
Validation loss: 2.452631247940884

Epoch: 5| Step: 2
Training loss: 3.111147403717041
Validation loss: 2.437542300070486

Epoch: 5| Step: 3
Training loss: 1.9539791345596313
Validation loss: 2.428647638649069

Epoch: 5| Step: 4
Training loss: 2.284191608428955
Validation loss: 2.4100961441634805

Epoch: 5| Step: 5
Training loss: 2.570152759552002
Validation loss: 2.41144549205739

Epoch: 5| Step: 6
Training loss: 2.274890184402466
Validation loss: 2.4109112575489986

Epoch: 5| Step: 7
Training loss: 2.794132947921753
Validation loss: 2.4191333863043014

Epoch: 5| Step: 8
Training loss: 2.178101062774658
Validation loss: 2.41472287331858

Epoch: 5| Step: 9
Training loss: 2.6414904594421387
Validation loss: 2.431105134307697

Epoch: 5| Step: 10
Training loss: 3.052724599838257
Validation loss: 2.425868118962934

Epoch: 212| Step: 0
Training loss: 3.483203887939453
Validation loss: 2.437271648837674

Epoch: 5| Step: 1
Training loss: 1.6842111349105835
Validation loss: 2.41355546059147

Epoch: 5| Step: 2
Training loss: 2.332751750946045
Validation loss: 2.4089961064759122

Epoch: 5| Step: 3
Training loss: 2.4724135398864746
Validation loss: 2.4038226937734954

Epoch: 5| Step: 4
Training loss: 2.2197773456573486
Validation loss: 2.4010417025576354

Epoch: 5| Step: 5
Training loss: 2.657818555831909
Validation loss: 2.388687587553455

Epoch: 5| Step: 6
Training loss: 2.4039316177368164
Validation loss: 2.395376420790149

Epoch: 5| Step: 7
Training loss: 2.610469341278076
Validation loss: 2.3952734008912118

Epoch: 5| Step: 8
Training loss: 3.0940356254577637
Validation loss: 2.395360290363271

Epoch: 5| Step: 9
Training loss: 1.843888521194458
Validation loss: 2.3862369239971204

Epoch: 5| Step: 10
Training loss: 3.146928548812866
Validation loss: 2.38789596480708

Epoch: 213| Step: 0
Training loss: 2.6566460132598877
Validation loss: 2.400076286767119

Epoch: 5| Step: 1
Training loss: 2.549053430557251
Validation loss: 2.3908376129724647

Epoch: 5| Step: 2
Training loss: 2.6172738075256348
Validation loss: 2.3959960681135937

Epoch: 5| Step: 3
Training loss: 3.125154495239258
Validation loss: 2.397358409820064

Epoch: 5| Step: 4
Training loss: 2.9617247581481934
Validation loss: 2.412447649945495

Epoch: 5| Step: 5
Training loss: 2.6487202644348145
Validation loss: 2.4073705878309024

Epoch: 5| Step: 6
Training loss: 2.3398709297180176
Validation loss: 2.4151041430811726

Epoch: 5| Step: 7
Training loss: 2.450197458267212
Validation loss: 2.4095787079103532

Epoch: 5| Step: 8
Training loss: 2.698747396469116
Validation loss: 2.404444215118244

Epoch: 5| Step: 9
Training loss: 1.6145877838134766
Validation loss: 2.405551105417231

Epoch: 5| Step: 10
Training loss: 1.9418846368789673
Validation loss: 2.410275951508553

Epoch: 214| Step: 0
Training loss: 2.399442195892334
Validation loss: 2.4008861280256704

Epoch: 5| Step: 1
Training loss: 2.342128276824951
Validation loss: 2.416490565064133

Epoch: 5| Step: 2
Training loss: 2.8620777130126953
Validation loss: 2.4256498993083997

Epoch: 5| Step: 3
Training loss: 2.746175765991211
Validation loss: 2.4471014802173903

Epoch: 5| Step: 4
Training loss: 2.186051845550537
Validation loss: 2.4378457069396973

Epoch: 5| Step: 5
Training loss: 2.7303004264831543
Validation loss: 2.4371002720248316

Epoch: 5| Step: 6
Training loss: 3.046923875808716
Validation loss: 2.440878155410931

Epoch: 5| Step: 7
Training loss: 1.9527851343154907
Validation loss: 2.421439750220186

Epoch: 5| Step: 8
Training loss: 2.5174412727355957
Validation loss: 2.4171627695842455

Epoch: 5| Step: 9
Training loss: 2.31777286529541
Validation loss: 2.4191257492188485

Epoch: 5| Step: 10
Training loss: 2.661325454711914
Validation loss: 2.4186958446297595

Epoch: 215| Step: 0
Training loss: 2.7364394664764404
Validation loss: 2.407757620657644

Epoch: 5| Step: 1
Training loss: 2.66165828704834
Validation loss: 2.4065929151350454

Epoch: 5| Step: 2
Training loss: 2.191628932952881
Validation loss: 2.4000710774493474

Epoch: 5| Step: 3
Training loss: 2.598233461380005
Validation loss: 2.3863535696460354

Epoch: 5| Step: 4
Training loss: 2.142714738845825
Validation loss: 2.380125925105105

Epoch: 5| Step: 5
Training loss: 3.082319974899292
Validation loss: 2.3873808332668838

Epoch: 5| Step: 6
Training loss: 2.846644639968872
Validation loss: 2.383950533405427

Epoch: 5| Step: 7
Training loss: 2.3723368644714355
Validation loss: 2.399591499759305

Epoch: 5| Step: 8
Training loss: 2.6426703929901123
Validation loss: 2.4003647860660347

Epoch: 5| Step: 9
Training loss: 1.9483362436294556
Validation loss: 2.4168911287861485

Epoch: 5| Step: 10
Training loss: 2.5942318439483643
Validation loss: 2.4126803849333074

Epoch: 216| Step: 0
Training loss: 2.5105204582214355
Validation loss: 2.4313098076851136

Epoch: 5| Step: 1
Training loss: 2.4561679363250732
Validation loss: 2.428830813336116

Epoch: 5| Step: 2
Training loss: 2.911076068878174
Validation loss: 2.438627707060947

Epoch: 5| Step: 3
Training loss: 1.9271208047866821
Validation loss: 2.432908437585318

Epoch: 5| Step: 4
Training loss: 2.6204001903533936
Validation loss: 2.422039214000907

Epoch: 5| Step: 5
Training loss: 2.45137882232666
Validation loss: 2.415048519770304

Epoch: 5| Step: 6
Training loss: 2.934792995452881
Validation loss: 2.4082098904476372

Epoch: 5| Step: 7
Training loss: 1.9135100841522217
Validation loss: 2.3960242694424045

Epoch: 5| Step: 8
Training loss: 2.2338433265686035
Validation loss: 2.3960524502620903

Epoch: 5| Step: 9
Training loss: 2.97554349899292
Validation loss: 2.4116045275042133

Epoch: 5| Step: 10
Training loss: 2.818004608154297
Validation loss: 2.4128855659115698

Epoch: 217| Step: 0
Training loss: 2.1136152744293213
Validation loss: 2.3973576279096704

Epoch: 5| Step: 1
Training loss: 2.8619906902313232
Validation loss: 2.4020918825621247

Epoch: 5| Step: 2
Training loss: 1.6156461238861084
Validation loss: 2.4076948781167307

Epoch: 5| Step: 3
Training loss: 3.5228569507598877
Validation loss: 2.404942540712254

Epoch: 5| Step: 4
Training loss: 2.53067946434021
Validation loss: 2.4102945840486916

Epoch: 5| Step: 5
Training loss: 2.732179641723633
Validation loss: 2.4017957025958645

Epoch: 5| Step: 6
Training loss: 2.563972234725952
Validation loss: 2.407626190493184

Epoch: 5| Step: 7
Training loss: 2.4037926197052
Validation loss: 2.417534984568114

Epoch: 5| Step: 8
Training loss: 2.3549137115478516
Validation loss: 2.4160797390886533

Epoch: 5| Step: 9
Training loss: 2.8242928981781006
Validation loss: 2.41418650586118

Epoch: 5| Step: 10
Training loss: 2.046546459197998
Validation loss: 2.402350348810996

Epoch: 218| Step: 0
Training loss: 2.343264102935791
Validation loss: 2.4050760012800976

Epoch: 5| Step: 1
Training loss: 2.5144381523132324
Validation loss: 2.402136887273481

Epoch: 5| Step: 2
Training loss: 2.7368099689483643
Validation loss: 2.394350049316242

Epoch: 5| Step: 3
Training loss: 2.4748289585113525
Validation loss: 2.3973006561238277

Epoch: 5| Step: 4
Training loss: 3.2915501594543457
Validation loss: 2.4081111749013266

Epoch: 5| Step: 5
Training loss: 1.6704829931259155
Validation loss: 2.4034633764656643

Epoch: 5| Step: 6
Training loss: 2.621182918548584
Validation loss: 2.407157310875513

Epoch: 5| Step: 7
Training loss: 2.7980151176452637
Validation loss: 2.4141892105020504

Epoch: 5| Step: 8
Training loss: 2.758136034011841
Validation loss: 2.4190859102433726

Epoch: 5| Step: 9
Training loss: 2.44317364692688
Validation loss: 2.4144749513236423

Epoch: 5| Step: 10
Training loss: 1.840993881225586
Validation loss: 2.410723770818403

Epoch: 219| Step: 0
Training loss: 2.3814167976379395
Validation loss: 2.4044583151417394

Epoch: 5| Step: 1
Training loss: 2.348219394683838
Validation loss: 2.405292249494983

Epoch: 5| Step: 2
Training loss: 3.1354761123657227
Validation loss: 2.405831642048333

Epoch: 5| Step: 3
Training loss: 1.9440748691558838
Validation loss: 2.4105391963835685

Epoch: 5| Step: 4
Training loss: 2.4537765979766846
Validation loss: 2.412968968832365

Epoch: 5| Step: 5
Training loss: 2.816171169281006
Validation loss: 2.4025917771042034

Epoch: 5| Step: 6
Training loss: 2.303602457046509
Validation loss: 2.4089668489271596

Epoch: 5| Step: 7
Training loss: 2.711513042449951
Validation loss: 2.403392496929374

Epoch: 5| Step: 8
Training loss: 2.6253063678741455
Validation loss: 2.4095127172367548

Epoch: 5| Step: 9
Training loss: 2.231086015701294
Validation loss: 2.392786648965651

Epoch: 5| Step: 10
Training loss: 2.658149480819702
Validation loss: 2.3900850895912416

Epoch: 220| Step: 0
Training loss: 2.8853328227996826
Validation loss: 2.4044168482544603

Epoch: 5| Step: 1
Training loss: 1.5475938320159912
Validation loss: 2.4072005620566745

Epoch: 5| Step: 2
Training loss: 2.7750988006591797
Validation loss: 2.419422144530922

Epoch: 5| Step: 3
Training loss: 2.898149013519287
Validation loss: 2.41861899693807

Epoch: 5| Step: 4
Training loss: 2.208085298538208
Validation loss: 2.4157684644063315

Epoch: 5| Step: 5
Training loss: 2.1365814208984375
Validation loss: 2.420317190949635

Epoch: 5| Step: 6
Training loss: 3.1122074127197266
Validation loss: 2.4252418343738844

Epoch: 5| Step: 7
Training loss: 2.1310877799987793
Validation loss: 2.401212410260272

Epoch: 5| Step: 8
Training loss: 2.7241408824920654
Validation loss: 2.405437961701424

Epoch: 5| Step: 9
Training loss: 2.3111367225646973
Validation loss: 2.3952923436318674

Epoch: 5| Step: 10
Training loss: 2.9229159355163574
Validation loss: 2.3763245382616596

Epoch: 221| Step: 0
Training loss: 2.4155526161193848
Validation loss: 2.3777163925991265

Epoch: 5| Step: 1
Training loss: 2.8305182456970215
Validation loss: 2.3807040337593324

Epoch: 5| Step: 2
Training loss: 2.9775540828704834
Validation loss: 2.3842917591012935

Epoch: 5| Step: 3
Training loss: 2.7750308513641357
Validation loss: 2.3886566008290937

Epoch: 5| Step: 4
Training loss: 2.374952793121338
Validation loss: 2.391721784427602

Epoch: 5| Step: 5
Training loss: 1.9388198852539062
Validation loss: 2.3905726555855042

Epoch: 5| Step: 6
Training loss: 2.227649211883545
Validation loss: 2.392512729091029

Epoch: 5| Step: 7
Training loss: 2.1174914836883545
Validation loss: 2.399772495351812

Epoch: 5| Step: 8
Training loss: 2.8116564750671387
Validation loss: 2.4079065066511913

Epoch: 5| Step: 9
Training loss: 2.3333420753479004
Validation loss: 2.4026146370877504

Epoch: 5| Step: 10
Training loss: 2.8816776275634766
Validation loss: 2.3960219711385746

Epoch: 222| Step: 0
Training loss: 2.8882596492767334
Validation loss: 2.4008070653484714

Epoch: 5| Step: 1
Training loss: 2.7720725536346436
Validation loss: 2.393139005989157

Epoch: 5| Step: 2
Training loss: 3.081759452819824
Validation loss: 2.392268919175671

Epoch: 5| Step: 3
Training loss: 2.931074619293213
Validation loss: 2.389541200412217

Epoch: 5| Step: 4
Training loss: 1.954311728477478
Validation loss: 2.3873642721483783

Epoch: 5| Step: 5
Training loss: 2.3343665599823
Validation loss: 2.4052308964472946

Epoch: 5| Step: 6
Training loss: 2.44807767868042
Validation loss: 2.399487033967049

Epoch: 5| Step: 7
Training loss: 1.9587066173553467
Validation loss: 2.404106358046173

Epoch: 5| Step: 8
Training loss: 2.4876742362976074
Validation loss: 2.394579533607729

Epoch: 5| Step: 9
Training loss: 2.773977041244507
Validation loss: 2.399252881285965

Epoch: 5| Step: 10
Training loss: 1.8965314626693726
Validation loss: 2.4068911819047827

Epoch: 223| Step: 0
Training loss: 2.866692066192627
Validation loss: 2.4055711377051567

Epoch: 5| Step: 1
Training loss: 2.60728120803833
Validation loss: 2.401204196355676

Epoch: 5| Step: 2
Training loss: 2.663428783416748
Validation loss: 2.3922538629142185

Epoch: 5| Step: 3
Training loss: 1.9090954065322876
Validation loss: 2.3904328653889317

Epoch: 5| Step: 4
Training loss: 2.022658348083496
Validation loss: 2.3949137887647076

Epoch: 5| Step: 5
Training loss: 2.607390880584717
Validation loss: 2.399023481594619

Epoch: 5| Step: 6
Training loss: 2.747204303741455
Validation loss: 2.4044780064654607

Epoch: 5| Step: 7
Training loss: 3.3044209480285645
Validation loss: 2.3931415952661985

Epoch: 5| Step: 8
Training loss: 2.5230793952941895
Validation loss: 2.3919102504689205

Epoch: 5| Step: 9
Training loss: 1.8029060363769531
Validation loss: 2.3850416765418103

Epoch: 5| Step: 10
Training loss: 2.618837356567383
Validation loss: 2.393429917673911

Epoch: 224| Step: 0
Training loss: 2.411597728729248
Validation loss: 2.3912770696865615

Epoch: 5| Step: 1
Training loss: 2.416165590286255
Validation loss: 2.3966057685113724

Epoch: 5| Step: 2
Training loss: 2.3249220848083496
Validation loss: 2.409729589698135

Epoch: 5| Step: 3
Training loss: 2.769321918487549
Validation loss: 2.406116365104593

Epoch: 5| Step: 4
Training loss: 3.0554416179656982
Validation loss: 2.3973621091535016

Epoch: 5| Step: 5
Training loss: 2.388350248336792
Validation loss: 2.393536111359955

Epoch: 5| Step: 6
Training loss: 2.37559175491333
Validation loss: 2.3967449998342865

Epoch: 5| Step: 7
Training loss: 2.1559948921203613
Validation loss: 2.3849613897262083

Epoch: 5| Step: 8
Training loss: 2.188904285430908
Validation loss: 2.3907677640197096

Epoch: 5| Step: 9
Training loss: 2.7221713066101074
Validation loss: 2.394913024799798

Epoch: 5| Step: 10
Training loss: 2.7726197242736816
Validation loss: 2.3926173666472077

Epoch: 225| Step: 0
Training loss: 2.8533225059509277
Validation loss: 2.396453688221593

Epoch: 5| Step: 1
Training loss: 2.5144143104553223
Validation loss: 2.3953817800808976

Epoch: 5| Step: 2
Training loss: 2.6208419799804688
Validation loss: 2.411674173929358

Epoch: 5| Step: 3
Training loss: 2.7364728450775146
Validation loss: 2.404381513595581

Epoch: 5| Step: 4
Training loss: 1.8418490886688232
Validation loss: 2.413958969936576

Epoch: 5| Step: 5
Training loss: 2.2363991737365723
Validation loss: 2.424013550563525

Epoch: 5| Step: 6
Training loss: 2.21018385887146
Validation loss: 2.4324759770465154

Epoch: 5| Step: 7
Training loss: 2.9625580310821533
Validation loss: 2.445323828727968

Epoch: 5| Step: 8
Training loss: 2.636132001876831
Validation loss: 2.447012637251167

Epoch: 5| Step: 9
Training loss: 2.600764751434326
Validation loss: 2.4444734473382272

Epoch: 5| Step: 10
Training loss: 2.3499321937561035
Validation loss: 2.4390001963543635

Epoch: 226| Step: 0
Training loss: 2.155324935913086
Validation loss: 2.4214394784742788

Epoch: 5| Step: 1
Training loss: 2.5509746074676514
Validation loss: 2.408019570894139

Epoch: 5| Step: 2
Training loss: 2.2466206550598145
Validation loss: 2.3901623090108237

Epoch: 5| Step: 3
Training loss: 2.689549446105957
Validation loss: 2.391178823286487

Epoch: 5| Step: 4
Training loss: 2.233490467071533
Validation loss: 2.376935310261224

Epoch: 5| Step: 5
Training loss: 2.346200466156006
Validation loss: 2.375010226362495

Epoch: 5| Step: 6
Training loss: 2.964625358581543
Validation loss: 2.383431044957971

Epoch: 5| Step: 7
Training loss: 2.5910446643829346
Validation loss: 2.390866082201722

Epoch: 5| Step: 8
Training loss: 3.1268582344055176
Validation loss: 2.390836440106874

Epoch: 5| Step: 9
Training loss: 1.9841783046722412
Validation loss: 2.3798515309569654

Epoch: 5| Step: 10
Training loss: 2.6109650135040283
Validation loss: 2.3856619916936403

Epoch: 227| Step: 0
Training loss: 2.3050098419189453
Validation loss: 2.386787796533236

Epoch: 5| Step: 1
Training loss: 2.243786096572876
Validation loss: 2.4086445275173394

Epoch: 5| Step: 2
Training loss: 2.4541096687316895
Validation loss: 2.4025492514333417

Epoch: 5| Step: 3
Training loss: 2.2494192123413086
Validation loss: 2.4204977943051245

Epoch: 5| Step: 4
Training loss: 3.0499768257141113
Validation loss: 2.4025792511560584

Epoch: 5| Step: 5
Training loss: 2.7629904747009277
Validation loss: 2.4044869253712315

Epoch: 5| Step: 6
Training loss: 2.035186290740967
Validation loss: 2.4033699112553752

Epoch: 5| Step: 7
Training loss: 1.978590726852417
Validation loss: 2.4064300419181905

Epoch: 5| Step: 8
Training loss: 3.05788254737854
Validation loss: 2.4011287689208984

Epoch: 5| Step: 9
Training loss: 2.3629672527313232
Validation loss: 2.4161881310965425

Epoch: 5| Step: 10
Training loss: 2.96037220954895
Validation loss: 2.41056231785846

Epoch: 228| Step: 0
Training loss: 2.76615571975708
Validation loss: 2.399562789547828

Epoch: 5| Step: 1
Training loss: 2.4945666790008545
Validation loss: 2.3974745171044463

Epoch: 5| Step: 2
Training loss: 3.164052724838257
Validation loss: 2.391517205904889

Epoch: 5| Step: 3
Training loss: 2.252962112426758
Validation loss: 2.3882317696848223

Epoch: 5| Step: 4
Training loss: 2.6951184272766113
Validation loss: 2.3713937549180883

Epoch: 5| Step: 5
Training loss: 2.963266372680664
Validation loss: 2.3565053888546523

Epoch: 5| Step: 6
Training loss: 2.123467445373535
Validation loss: 2.3722680102112474

Epoch: 5| Step: 7
Training loss: 2.4493463039398193
Validation loss: 2.3638293794406358

Epoch: 5| Step: 8
Training loss: 1.9633769989013672
Validation loss: 2.3553437699553785

Epoch: 5| Step: 9
Training loss: 2.4308297634124756
Validation loss: 2.367488880311289

Epoch: 5| Step: 10
Training loss: 2.2171826362609863
Validation loss: 2.3674481017615205

Epoch: 229| Step: 0
Training loss: 2.3770248889923096
Validation loss: 2.3721644980933076

Epoch: 5| Step: 1
Training loss: 2.8398613929748535
Validation loss: 2.375681654099495

Epoch: 5| Step: 2
Training loss: 3.0252480506896973
Validation loss: 2.3854876423394806

Epoch: 5| Step: 3
Training loss: 2.337831974029541
Validation loss: 2.406208380576103

Epoch: 5| Step: 4
Training loss: 1.8762754201889038
Validation loss: 2.418426993072674

Epoch: 5| Step: 5
Training loss: 2.902078866958618
Validation loss: 2.4058564683442474

Epoch: 5| Step: 6
Training loss: 2.8009819984436035
Validation loss: 2.416610451154811

Epoch: 5| Step: 7
Training loss: 2.650515079498291
Validation loss: 2.4115656063120854

Epoch: 5| Step: 8
Training loss: 2.351531982421875
Validation loss: 2.394654566241849

Epoch: 5| Step: 9
Training loss: 2.219228506088257
Validation loss: 2.3880529378050115

Epoch: 5| Step: 10
Training loss: 2.143887996673584
Validation loss: 2.3747920015806794

Epoch: 230| Step: 0
Training loss: 3.2055537700653076
Validation loss: 2.372009254270984

Epoch: 5| Step: 1
Training loss: 2.2641043663024902
Validation loss: 2.3796134930784985

Epoch: 5| Step: 2
Training loss: 2.27323579788208
Validation loss: 2.362370729446411

Epoch: 5| Step: 3
Training loss: 2.101201295852661
Validation loss: 2.3728396610547136

Epoch: 5| Step: 4
Training loss: 1.8726890087127686
Validation loss: 2.3702013723311888

Epoch: 5| Step: 5
Training loss: 2.7524476051330566
Validation loss: 2.36793057252002

Epoch: 5| Step: 6
Training loss: 2.779421091079712
Validation loss: 2.3694758979223107

Epoch: 5| Step: 7
Training loss: 2.347137928009033
Validation loss: 2.3775792275705645

Epoch: 5| Step: 8
Training loss: 3.1325607299804688
Validation loss: 2.379569492032451

Epoch: 5| Step: 9
Training loss: 2.2772679328918457
Validation loss: 2.3904256359223397

Epoch: 5| Step: 10
Training loss: 2.4908745288848877
Validation loss: 2.3916485976147395

Epoch: 231| Step: 0
Training loss: 2.6251235008239746
Validation loss: 2.413365323056457

Epoch: 5| Step: 1
Training loss: 2.1834797859191895
Validation loss: 2.413976264256303

Epoch: 5| Step: 2
Training loss: 2.3424315452575684
Validation loss: 2.421566269731009

Epoch: 5| Step: 3
Training loss: 2.097053050994873
Validation loss: 2.4165684971758115

Epoch: 5| Step: 4
Training loss: 2.981569766998291
Validation loss: 2.4261343556065715

Epoch: 5| Step: 5
Training loss: 2.3132338523864746
Validation loss: 2.4077112238894225

Epoch: 5| Step: 6
Training loss: 2.6701924800872803
Validation loss: 2.3937922831504577

Epoch: 5| Step: 7
Training loss: 2.0422775745391846
Validation loss: 2.378686064033098

Epoch: 5| Step: 8
Training loss: 2.8603110313415527
Validation loss: 2.3753597954268098

Epoch: 5| Step: 9
Training loss: 2.5386672019958496
Validation loss: 2.369208581985966

Epoch: 5| Step: 10
Training loss: 2.983389377593994
Validation loss: 2.373452535239599

Epoch: 232| Step: 0
Training loss: 2.7895712852478027
Validation loss: 2.3869585529450448

Epoch: 5| Step: 1
Training loss: 2.48809814453125
Validation loss: 2.3802930821654615

Epoch: 5| Step: 2
Training loss: 2.0762107372283936
Validation loss: 2.4007642884408273

Epoch: 5| Step: 3
Training loss: 3.295668840408325
Validation loss: 2.399082822184409

Epoch: 5| Step: 4
Training loss: 2.4298927783966064
Validation loss: 2.397270346200594

Epoch: 5| Step: 5
Training loss: 2.3761937618255615
Validation loss: 2.41614463252406

Epoch: 5| Step: 6
Training loss: 1.7148666381835938
Validation loss: 2.4217264600979385

Epoch: 5| Step: 7
Training loss: 3.222355365753174
Validation loss: 2.419696689933859

Epoch: 5| Step: 8
Training loss: 2.054049491882324
Validation loss: 2.4261800909555085

Epoch: 5| Step: 9
Training loss: 2.8347415924072266
Validation loss: 2.404094744754094

Epoch: 5| Step: 10
Training loss: 2.2996227741241455
Validation loss: 2.3949535482673237

Epoch: 233| Step: 0
Training loss: 2.6240897178649902
Validation loss: 2.370634922417261

Epoch: 5| Step: 1
Training loss: 2.2861387729644775
Validation loss: 2.3822263389505367

Epoch: 5| Step: 2
Training loss: 3.1290907859802246
Validation loss: 2.373106130989649

Epoch: 5| Step: 3
Training loss: 2.681018829345703
Validation loss: 2.3696311186718684

Epoch: 5| Step: 4
Training loss: 2.643732786178589
Validation loss: 2.3761428940680718

Epoch: 5| Step: 5
Training loss: 2.0816683769226074
Validation loss: 2.3723198777885846

Epoch: 5| Step: 6
Training loss: 2.548978328704834
Validation loss: 2.3777707161441928

Epoch: 5| Step: 7
Training loss: 2.6403183937072754
Validation loss: 2.3820225179836316

Epoch: 5| Step: 8
Training loss: 1.9575999975204468
Validation loss: 2.3877330762083813

Epoch: 5| Step: 9
Training loss: 1.9726594686508179
Validation loss: 2.397688868225262

Epoch: 5| Step: 10
Training loss: 2.712097644805908
Validation loss: 2.4026750390247633

Epoch: 234| Step: 0
Training loss: 3.3995070457458496
Validation loss: 2.4092725912729898

Epoch: 5| Step: 1
Training loss: 2.1163992881774902
Validation loss: 2.423998063610446

Epoch: 5| Step: 2
Training loss: 2.6096560955047607
Validation loss: 2.436323450457665

Epoch: 5| Step: 3
Training loss: 2.9577298164367676
Validation loss: 2.4354893315222954

Epoch: 5| Step: 4
Training loss: 2.221658229827881
Validation loss: 2.4265129514919814

Epoch: 5| Step: 5
Training loss: 2.683622121810913
Validation loss: 2.4210998678720124

Epoch: 5| Step: 6
Training loss: 1.7405344247817993
Validation loss: 2.398082329380897

Epoch: 5| Step: 7
Training loss: 2.5900683403015137
Validation loss: 2.380493184571625

Epoch: 5| Step: 8
Training loss: 2.716257333755493
Validation loss: 2.376529275730092

Epoch: 5| Step: 9
Training loss: 1.8909794092178345
Validation loss: 2.3914118915475826

Epoch: 5| Step: 10
Training loss: 2.3371105194091797
Validation loss: 2.368656719884565

Epoch: 235| Step: 0
Training loss: 2.7328832149505615
Validation loss: 2.371193321802283

Epoch: 5| Step: 1
Training loss: 2.6313083171844482
Validation loss: 2.384745144074963

Epoch: 5| Step: 2
Training loss: 2.729931354522705
Validation loss: 2.3931502321714997

Epoch: 5| Step: 3
Training loss: 2.6570544242858887
Validation loss: 2.41374481877973

Epoch: 5| Step: 4
Training loss: 2.530208110809326
Validation loss: 2.3947829277284685

Epoch: 5| Step: 5
Training loss: 2.514068841934204
Validation loss: 2.395580812167096

Epoch: 5| Step: 6
Training loss: 3.4555251598358154
Validation loss: 2.393204650571269

Epoch: 5| Step: 7
Training loss: 2.115199089050293
Validation loss: 2.39091169962319

Epoch: 5| Step: 8
Training loss: 1.4370263814926147
Validation loss: 2.383399248123169

Epoch: 5| Step: 9
Training loss: 2.4108822345733643
Validation loss: 2.385142813446701

Epoch: 5| Step: 10
Training loss: 2.1300740242004395
Validation loss: 2.3817211504905456

Epoch: 236| Step: 0
Training loss: 2.048002004623413
Validation loss: 2.422094806548088

Epoch: 5| Step: 1
Training loss: 1.9713290929794312
Validation loss: 2.4385313833913496

Epoch: 5| Step: 2
Training loss: 2.490220069885254
Validation loss: 2.4531658259771203

Epoch: 5| Step: 3
Training loss: 2.78369402885437
Validation loss: 2.4143793762371106

Epoch: 5| Step: 4
Training loss: 2.671708583831787
Validation loss: 2.3889475714775825

Epoch: 5| Step: 5
Training loss: 2.602039337158203
Validation loss: 2.3745156693202194

Epoch: 5| Step: 6
Training loss: 2.3401858806610107
Validation loss: 2.376753907049856

Epoch: 5| Step: 7
Training loss: 2.5507774353027344
Validation loss: 2.3870429608129684

Epoch: 5| Step: 8
Training loss: 2.8897342681884766
Validation loss: 2.3962869362164567

Epoch: 5| Step: 9
Training loss: 2.5828471183776855
Validation loss: 2.4085792162085093

Epoch: 5| Step: 10
Training loss: 2.5805540084838867
Validation loss: 2.425905268679383

Epoch: 237| Step: 0
Training loss: 2.310883045196533
Validation loss: 2.4158041502839778

Epoch: 5| Step: 1
Training loss: 2.5727479457855225
Validation loss: 2.430204701680009

Epoch: 5| Step: 2
Training loss: 2.6231894493103027
Validation loss: 2.4292331305883264

Epoch: 5| Step: 3
Training loss: 2.346250534057617
Validation loss: 2.429062835631832

Epoch: 5| Step: 4
Training loss: 3.0171239376068115
Validation loss: 2.4291667989505235

Epoch: 5| Step: 5
Training loss: 2.3419079780578613
Validation loss: 2.409624292004493

Epoch: 5| Step: 6
Training loss: 2.7235829830169678
Validation loss: 2.4017897523859495

Epoch: 5| Step: 7
Training loss: 2.7844841480255127
Validation loss: 2.412092927963503

Epoch: 5| Step: 8
Training loss: 3.2908339500427246
Validation loss: 2.4131135658551286

Epoch: 5| Step: 9
Training loss: 1.4835898876190186
Validation loss: 2.4061660984511017

Epoch: 5| Step: 10
Training loss: 1.808353304862976
Validation loss: 2.3929535650437876

Epoch: 238| Step: 0
Training loss: 1.9026191234588623
Validation loss: 2.378490565925516

Epoch: 5| Step: 1
Training loss: 2.618680238723755
Validation loss: 2.3749371267134145

Epoch: 5| Step: 2
Training loss: 2.0126240253448486
Validation loss: 2.377654029477027

Epoch: 5| Step: 3
Training loss: 2.205773115158081
Validation loss: 2.3794725197617725

Epoch: 5| Step: 4
Training loss: 2.8631577491760254
Validation loss: 2.3868090055322133

Epoch: 5| Step: 5
Training loss: 2.0766754150390625
Validation loss: 2.3802550364566106

Epoch: 5| Step: 6
Training loss: 2.588304281234741
Validation loss: 2.3869121766859487

Epoch: 5| Step: 7
Training loss: 2.3828747272491455
Validation loss: 2.3958040360481507

Epoch: 5| Step: 8
Training loss: 2.663172483444214
Validation loss: 2.3765889649750083

Epoch: 5| Step: 9
Training loss: 3.2268168926239014
Validation loss: 2.3874909057412097

Epoch: 5| Step: 10
Training loss: 2.747485876083374
Validation loss: 2.4038830393104145

Epoch: 239| Step: 0
Training loss: 2.518883466720581
Validation loss: 2.4031182642905944

Epoch: 5| Step: 1
Training loss: 2.9014697074890137
Validation loss: 2.412049780609787

Epoch: 5| Step: 2
Training loss: 2.2578415870666504
Validation loss: 2.4084887953214746

Epoch: 5| Step: 3
Training loss: 2.067563533782959
Validation loss: 2.419528471526279

Epoch: 5| Step: 4
Training loss: 2.0065417289733887
Validation loss: 2.4011682336048414

Epoch: 5| Step: 5
Training loss: 2.419334888458252
Validation loss: 2.3875922823464997

Epoch: 5| Step: 6
Training loss: 2.529200315475464
Validation loss: 2.378865945723749

Epoch: 5| Step: 7
Training loss: 2.473407745361328
Validation loss: 2.3793380798832064

Epoch: 5| Step: 8
Training loss: 2.423100233078003
Validation loss: 2.3729487978002077

Epoch: 5| Step: 9
Training loss: 3.268872022628784
Validation loss: 2.3908443425291326

Epoch: 5| Step: 10
Training loss: 2.171860456466675
Validation loss: 2.3970974030033236

Epoch: 240| Step: 0
Training loss: 2.8260138034820557
Validation loss: 2.4193627629228818

Epoch: 5| Step: 1
Training loss: 1.830718994140625
Validation loss: 2.4050956105673187

Epoch: 5| Step: 2
Training loss: 1.9029171466827393
Validation loss: 2.388861834361989

Epoch: 5| Step: 3
Training loss: 2.4521710872650146
Validation loss: 2.37492415981908

Epoch: 5| Step: 4
Training loss: 2.478220224380493
Validation loss: 2.3683091978872977

Epoch: 5| Step: 5
Training loss: 2.000972032546997
Validation loss: 2.3572163607484553

Epoch: 5| Step: 6
Training loss: 2.4998364448547363
Validation loss: 2.378546266145604

Epoch: 5| Step: 7
Training loss: 2.2308425903320312
Validation loss: 2.3813442055897047

Epoch: 5| Step: 8
Training loss: 3.015886068344116
Validation loss: 2.40206927381536

Epoch: 5| Step: 9
Training loss: 3.011967897415161
Validation loss: 2.4291016132600847

Epoch: 5| Step: 10
Training loss: 3.142131805419922
Validation loss: 2.4239083028608754

Epoch: 241| Step: 0
Training loss: 1.6113609075546265
Validation loss: 2.4281736855865805

Epoch: 5| Step: 1
Training loss: 2.8194336891174316
Validation loss: 2.4193940419022755

Epoch: 5| Step: 2
Training loss: 2.2078871726989746
Validation loss: 2.413281351007441

Epoch: 5| Step: 3
Training loss: 2.994094133377075
Validation loss: 2.402567898073504

Epoch: 5| Step: 4
Training loss: 2.420586347579956
Validation loss: 2.412723213113764

Epoch: 5| Step: 5
Training loss: 2.7820885181427
Validation loss: 2.4243481210483018

Epoch: 5| Step: 6
Training loss: 2.4924416542053223
Validation loss: 2.4118688388537337

Epoch: 5| Step: 7
Training loss: 2.067110776901245
Validation loss: 2.4014932288918445

Epoch: 5| Step: 8
Training loss: 1.93174147605896
Validation loss: 2.3779950500816427

Epoch: 5| Step: 9
Training loss: 3.215311050415039
Validation loss: 2.3585610646073536

Epoch: 5| Step: 10
Training loss: 2.788181781768799
Validation loss: 2.3553714752197266

Epoch: 242| Step: 0
Training loss: 2.186659336090088
Validation loss: 2.351763242034502

Epoch: 5| Step: 1
Training loss: 3.2918477058410645
Validation loss: 2.366048400120069

Epoch: 5| Step: 2
Training loss: 2.0343515872955322
Validation loss: 2.360460945354995

Epoch: 5| Step: 3
Training loss: 2.628556728363037
Validation loss: 2.370370413667412

Epoch: 5| Step: 4
Training loss: 2.350442886352539
Validation loss: 2.3672147181726273

Epoch: 5| Step: 5
Training loss: 2.2463302612304688
Validation loss: 2.3617009808940272

Epoch: 5| Step: 6
Training loss: 2.115609645843506
Validation loss: 2.377966529579573

Epoch: 5| Step: 7
Training loss: 2.497870683670044
Validation loss: 2.3668014721203874

Epoch: 5| Step: 8
Training loss: 2.127349853515625
Validation loss: 2.372140604962585

Epoch: 5| Step: 9
Training loss: 2.8370189666748047
Validation loss: 2.3779514374271518

Epoch: 5| Step: 10
Training loss: 2.894367218017578
Validation loss: 2.38465783672948

Epoch: 243| Step: 0
Training loss: 2.717872142791748
Validation loss: 2.3824713025041806

Epoch: 5| Step: 1
Training loss: 2.1274051666259766
Validation loss: 2.3943062520796254

Epoch: 5| Step: 2
Training loss: 2.9732680320739746
Validation loss: 2.396638319056521

Epoch: 5| Step: 3
Training loss: 1.995849609375
Validation loss: 2.408648262741745

Epoch: 5| Step: 4
Training loss: 2.5642077922821045
Validation loss: 2.432710219455022

Epoch: 5| Step: 5
Training loss: 2.446739435195923
Validation loss: 2.42823374912303

Epoch: 5| Step: 6
Training loss: 2.4109857082366943
Validation loss: 2.4320355448671567

Epoch: 5| Step: 7
Training loss: 2.831146240234375
Validation loss: 2.4358847859085246

Epoch: 5| Step: 8
Training loss: 2.704270124435425
Validation loss: 2.415067849620696

Epoch: 5| Step: 9
Training loss: 2.169325351715088
Validation loss: 2.402114640000046

Epoch: 5| Step: 10
Training loss: 2.0766761302948
Validation loss: 2.3989201361133206

Epoch: 244| Step: 0
Training loss: 2.9420480728149414
Validation loss: 2.3867164350325063

Epoch: 5| Step: 1
Training loss: 2.7696545124053955
Validation loss: 2.376077377667991

Epoch: 5| Step: 2
Training loss: 2.07667875289917
Validation loss: 2.383035357280444

Epoch: 5| Step: 3
Training loss: 2.351853847503662
Validation loss: 2.384961830672397

Epoch: 5| Step: 4
Training loss: 2.132728099822998
Validation loss: 2.386466315997544

Epoch: 5| Step: 5
Training loss: 2.4660911560058594
Validation loss: 2.3828633959575365

Epoch: 5| Step: 6
Training loss: 2.5035691261291504
Validation loss: 2.3857479659459924

Epoch: 5| Step: 7
Training loss: 2.1260666847229004
Validation loss: 2.38661055667426

Epoch: 5| Step: 8
Training loss: 2.310492753982544
Validation loss: 2.380839987467694

Epoch: 5| Step: 9
Training loss: 2.690096378326416
Validation loss: 2.3609881708698888

Epoch: 5| Step: 10
Training loss: 3.0819435119628906
Validation loss: 2.3562206017073763

Epoch: 245| Step: 0
Training loss: 2.382298707962036
Validation loss: 2.3652885293447845

Epoch: 5| Step: 1
Training loss: 2.5922012329101562
Validation loss: 2.368427220211234

Epoch: 5| Step: 2
Training loss: 3.0133399963378906
Validation loss: 2.389747476065031

Epoch: 5| Step: 3
Training loss: 1.8817323446273804
Validation loss: 2.4083758169604885

Epoch: 5| Step: 4
Training loss: 3.0814099311828613
Validation loss: 2.410586090498073

Epoch: 5| Step: 5
Training loss: 2.0752110481262207
Validation loss: 2.3947416351687525

Epoch: 5| Step: 6
Training loss: 2.7365031242370605
Validation loss: 2.3995124960458405

Epoch: 5| Step: 7
Training loss: 1.5272517204284668
Validation loss: 2.3900855407919934

Epoch: 5| Step: 8
Training loss: 2.773361921310425
Validation loss: 2.383516893591932

Epoch: 5| Step: 9
Training loss: 2.6921281814575195
Validation loss: 2.3843686888294835

Epoch: 5| Step: 10
Training loss: 2.3402068614959717
Validation loss: 2.390914951601336

Epoch: 246| Step: 0
Training loss: 2.4859490394592285
Validation loss: 2.384338535288329

Epoch: 5| Step: 1
Training loss: 2.233076572418213
Validation loss: 2.377761497292467

Epoch: 5| Step: 2
Training loss: 2.420761823654175
Validation loss: 2.3815566788437548

Epoch: 5| Step: 3
Training loss: 2.704002857208252
Validation loss: 2.3741805015071744

Epoch: 5| Step: 4
Training loss: 1.8155221939086914
Validation loss: 2.366861989421229

Epoch: 5| Step: 5
Training loss: 2.4894015789031982
Validation loss: 2.3581762083115114

Epoch: 5| Step: 6
Training loss: 1.6871942281723022
Validation loss: 2.367370374741093

Epoch: 5| Step: 7
Training loss: 3.0942301750183105
Validation loss: 2.3642754465021114

Epoch: 5| Step: 8
Training loss: 2.2505574226379395
Validation loss: 2.3677014791837303

Epoch: 5| Step: 9
Training loss: 3.3181540966033936
Validation loss: 2.3614005504115934

Epoch: 5| Step: 10
Training loss: 2.506268262863159
Validation loss: 2.3644192449508177

Epoch: 247| Step: 0
Training loss: 2.3295841217041016
Validation loss: 2.3698727776927333

Epoch: 5| Step: 1
Training loss: 2.122037649154663
Validation loss: 2.369846233757593

Epoch: 5| Step: 2
Training loss: 2.8698039054870605
Validation loss: 2.3637742534760506

Epoch: 5| Step: 3
Training loss: 2.8288187980651855
Validation loss: 2.3661410449653544

Epoch: 5| Step: 4
Training loss: 2.3862977027893066
Validation loss: 2.3565538775536323

Epoch: 5| Step: 5
Training loss: 2.749471426010132
Validation loss: 2.3728838966738794

Epoch: 5| Step: 6
Training loss: 2.335897922515869
Validation loss: 2.3813421085316646

Epoch: 5| Step: 7
Training loss: 2.8190531730651855
Validation loss: 2.382124431671635

Epoch: 5| Step: 8
Training loss: 2.509847640991211
Validation loss: 2.394443260726108

Epoch: 5| Step: 9
Training loss: 2.2761950492858887
Validation loss: 2.3934301842925367

Epoch: 5| Step: 10
Training loss: 1.5651421546936035
Validation loss: 2.3888222914870068

Epoch: 248| Step: 0
Training loss: 1.884621262550354
Validation loss: 2.381889812407955

Epoch: 5| Step: 1
Training loss: 2.2977890968322754
Validation loss: 2.3839256378912155

Epoch: 5| Step: 2
Training loss: 2.0532476902008057
Validation loss: 2.3835655950730845

Epoch: 5| Step: 3
Training loss: 3.127572536468506
Validation loss: 2.38696059103935

Epoch: 5| Step: 4
Training loss: 2.1081597805023193
Validation loss: 2.3840084883474533

Epoch: 5| Step: 5
Training loss: 2.6730427742004395
Validation loss: 2.3946363028659614

Epoch: 5| Step: 6
Training loss: 2.658444881439209
Validation loss: 2.379377406130555

Epoch: 5| Step: 7
Training loss: 2.7701210975646973
Validation loss: 2.368556491790279

Epoch: 5| Step: 8
Training loss: 2.3400111198425293
Validation loss: 2.3633686419456237

Epoch: 5| Step: 9
Training loss: 2.7174205780029297
Validation loss: 2.3739970884015484

Epoch: 5| Step: 10
Training loss: 2.168253183364868
Validation loss: 2.3629432826913814

Epoch: 249| Step: 0
Training loss: 2.7679665088653564
Validation loss: 2.3684559278590704

Epoch: 5| Step: 1
Training loss: 2.0003488063812256
Validation loss: 2.383770353050642

Epoch: 5| Step: 2
Training loss: 2.295464277267456
Validation loss: 2.3799245460059053

Epoch: 5| Step: 3
Training loss: 2.5298666954040527
Validation loss: 2.3677805880064606

Epoch: 5| Step: 4
Training loss: 2.4678640365600586
Validation loss: 2.3771265270889446

Epoch: 5| Step: 5
Training loss: 2.13889741897583
Validation loss: 2.378486076990763

Epoch: 5| Step: 6
Training loss: 2.5462334156036377
Validation loss: 2.383918772461594

Epoch: 5| Step: 7
Training loss: 1.9693523645401
Validation loss: 2.3969640372901835

Epoch: 5| Step: 8
Training loss: 2.6469085216522217
Validation loss: 2.3963112241478375

Epoch: 5| Step: 9
Training loss: 2.309272289276123
Validation loss: 2.4008626912229802

Epoch: 5| Step: 10
Training loss: 3.331204891204834
Validation loss: 2.412248073085662

Epoch: 250| Step: 0
Training loss: 2.4889721870422363
Validation loss: 2.398178861987206

Epoch: 5| Step: 1
Training loss: 3.5820388793945312
Validation loss: 2.390376075621574

Epoch: 5| Step: 2
Training loss: 2.044828414916992
Validation loss: 2.37361071443045

Epoch: 5| Step: 3
Training loss: 1.8202701807022095
Validation loss: 2.3496376006833968

Epoch: 5| Step: 4
Training loss: 2.3500423431396484
Validation loss: 2.355459784948698

Epoch: 5| Step: 5
Training loss: 2.8109657764434814
Validation loss: 2.3510278373636226

Epoch: 5| Step: 6
Training loss: 2.134209632873535
Validation loss: 2.330236429809242

Epoch: 5| Step: 7
Training loss: 2.455648899078369
Validation loss: 2.342140874555034

Epoch: 5| Step: 8
Training loss: 3.018620014190674
Validation loss: 2.3486974162440144

Epoch: 5| Step: 9
Training loss: 1.907030463218689
Validation loss: 2.3598330431087042

Epoch: 5| Step: 10
Training loss: 2.1564478874206543
Validation loss: 2.371018466129098

Epoch: 251| Step: 0
Training loss: 1.9313859939575195
Validation loss: 2.3811703215363207

Epoch: 5| Step: 1
Training loss: 2.7439067363739014
Validation loss: 2.3873953229637555

Epoch: 5| Step: 2
Training loss: 2.488147258758545
Validation loss: 2.390201028957162

Epoch: 5| Step: 3
Training loss: 2.61631441116333
Validation loss: 2.3941199702601277

Epoch: 5| Step: 4
Training loss: 2.3621888160705566
Validation loss: 2.4012466604991625

Epoch: 5| Step: 5
Training loss: 2.6597719192504883
Validation loss: 2.4049315708939747

Epoch: 5| Step: 6
Training loss: 2.2704741954803467
Validation loss: 2.394773260239632

Epoch: 5| Step: 7
Training loss: 3.026432752609253
Validation loss: 2.3923512838220082

Epoch: 5| Step: 8
Training loss: 2.6231040954589844
Validation loss: 2.393642322991484

Epoch: 5| Step: 9
Training loss: 2.003635883331299
Validation loss: 2.3953693451419955

Epoch: 5| Step: 10
Training loss: 2.057117462158203
Validation loss: 2.382818688628494

Epoch: 252| Step: 0
Training loss: 2.6188108921051025
Validation loss: 2.374830902263682

Epoch: 5| Step: 1
Training loss: 2.5228166580200195
Validation loss: 2.361174511653121

Epoch: 5| Step: 2
Training loss: 2.993447780609131
Validation loss: 2.3575467909536054

Epoch: 5| Step: 3
Training loss: 2.4562759399414062
Validation loss: 2.344953934351603

Epoch: 5| Step: 4
Training loss: 2.1629765033721924
Validation loss: 2.3547625874960296

Epoch: 5| Step: 5
Training loss: 1.8779661655426025
Validation loss: 2.368916996063725

Epoch: 5| Step: 6
Training loss: 2.6938443183898926
Validation loss: 2.3939401923969226

Epoch: 5| Step: 7
Training loss: 2.497434139251709
Validation loss: 2.415179665370654

Epoch: 5| Step: 8
Training loss: 2.1649351119995117
Validation loss: 2.3952528148569088

Epoch: 5| Step: 9
Training loss: 2.739542245864868
Validation loss: 2.4022892264909643

Epoch: 5| Step: 10
Training loss: 2.1625969409942627
Validation loss: 2.378346194503128

Epoch: 253| Step: 0
Training loss: 2.2578125
Validation loss: 2.377536881354547

Epoch: 5| Step: 1
Training loss: 2.05729079246521
Validation loss: 2.3909440707134944

Epoch: 5| Step: 2
Training loss: 2.1749067306518555
Validation loss: 2.4143486151131253

Epoch: 5| Step: 3
Training loss: 2.7240004539489746
Validation loss: 2.394893705203969

Epoch: 5| Step: 4
Training loss: 2.132542848587036
Validation loss: 2.400263483806323

Epoch: 5| Step: 5
Training loss: 2.2669577598571777
Validation loss: 2.3791484153398903

Epoch: 5| Step: 6
Training loss: 2.8358426094055176
Validation loss: 2.367306455489128

Epoch: 5| Step: 7
Training loss: 2.5405116081237793
Validation loss: 2.359267039965558

Epoch: 5| Step: 8
Training loss: 2.829108953475952
Validation loss: 2.3510470390319824

Epoch: 5| Step: 9
Training loss: 2.6004631519317627
Validation loss: 2.347969526885658

Epoch: 5| Step: 10
Training loss: 2.462985038757324
Validation loss: 2.3509570603729575

Epoch: 254| Step: 0
Training loss: 2.5422024726867676
Validation loss: 2.3516887182830484

Epoch: 5| Step: 1
Training loss: 2.83878231048584
Validation loss: 2.348125239854218

Epoch: 5| Step: 2
Training loss: 2.9113965034484863
Validation loss: 2.3432886831222044

Epoch: 5| Step: 3
Training loss: 2.765174150466919
Validation loss: 2.346036511082803

Epoch: 5| Step: 4
Training loss: 2.7845168113708496
Validation loss: 2.3373960679577244

Epoch: 5| Step: 5
Training loss: 2.1260476112365723
Validation loss: 2.347551835480557

Epoch: 5| Step: 6
Training loss: 1.5607273578643799
Validation loss: 2.3589537092434463

Epoch: 5| Step: 7
Training loss: 1.9135726690292358
Validation loss: 2.392133617913851

Epoch: 5| Step: 8
Training loss: 2.3492543697357178
Validation loss: 2.4043211334495136

Epoch: 5| Step: 9
Training loss: 2.469703435897827
Validation loss: 2.429153826928908

Epoch: 5| Step: 10
Training loss: 2.54937744140625
Validation loss: 2.4482419311359362

Epoch: 255| Step: 0
Training loss: 2.0757663249969482
Validation loss: 2.4451497729106615

Epoch: 5| Step: 1
Training loss: 2.62825345993042
Validation loss: 2.4466192491592897

Epoch: 5| Step: 2
Training loss: 2.5127975940704346
Validation loss: 2.4358154189202095

Epoch: 5| Step: 3
Training loss: 2.110389232635498
Validation loss: 2.426305822146836

Epoch: 5| Step: 4
Training loss: 1.7407732009887695
Validation loss: 2.4156420384683917

Epoch: 5| Step: 5
Training loss: 2.525818109512329
Validation loss: 2.3996771253565305

Epoch: 5| Step: 6
Training loss: 2.960075616836548
Validation loss: 2.393195749610983

Epoch: 5| Step: 7
Training loss: 2.371366500854492
Validation loss: 2.3673967725487164

Epoch: 5| Step: 8
Training loss: 2.6516342163085938
Validation loss: 2.3635121622393207

Epoch: 5| Step: 9
Training loss: 2.409343957901001
Validation loss: 2.351345859548097

Epoch: 5| Step: 10
Training loss: 2.8213346004486084
Validation loss: 2.3334321514252694

Epoch: 256| Step: 0
Training loss: 2.3056282997131348
Validation loss: 2.3432201416261735

Epoch: 5| Step: 1
Training loss: 2.462294578552246
Validation loss: 2.349774001747049

Epoch: 5| Step: 2
Training loss: 3.008211851119995
Validation loss: 2.3546250712487007

Epoch: 5| Step: 3
Training loss: 2.1697306632995605
Validation loss: 2.345801531627614

Epoch: 5| Step: 4
Training loss: 2.3608336448669434
Validation loss: 2.356269621079968

Epoch: 5| Step: 5
Training loss: 2.3668136596679688
Validation loss: 2.3562047327718427

Epoch: 5| Step: 6
Training loss: 2.578028440475464
Validation loss: 2.373224796787385

Epoch: 5| Step: 7
Training loss: 2.495483160018921
Validation loss: 2.36206486404583

Epoch: 5| Step: 8
Training loss: 2.2270050048828125
Validation loss: 2.3774903051314817

Epoch: 5| Step: 9
Training loss: 2.3242413997650146
Validation loss: 2.3859539647256174

Epoch: 5| Step: 10
Training loss: 2.3009579181671143
Validation loss: 2.3965158872706915

Epoch: 257| Step: 0
Training loss: 2.4970641136169434
Validation loss: 2.408339713209419

Epoch: 5| Step: 1
Training loss: 1.6883506774902344
Validation loss: 2.4176063922143753

Epoch: 5| Step: 2
Training loss: 2.135817050933838
Validation loss: 2.4377701820865756

Epoch: 5| Step: 3
Training loss: 2.1972720623016357
Validation loss: 2.440056662405691

Epoch: 5| Step: 4
Training loss: 3.304661512374878
Validation loss: 2.4370475507551626

Epoch: 5| Step: 5
Training loss: 2.5726704597473145
Validation loss: 2.4221966804996615

Epoch: 5| Step: 6
Training loss: 2.6286063194274902
Validation loss: 2.4086270921973774

Epoch: 5| Step: 7
Training loss: 1.9351751804351807
Validation loss: 2.3996178078395065

Epoch: 5| Step: 8
Training loss: 2.2585160732269287
Validation loss: 2.375178260187949

Epoch: 5| Step: 9
Training loss: 2.7022154331207275
Validation loss: 2.3779959165921776

Epoch: 5| Step: 10
Training loss: 2.763254165649414
Validation loss: 2.3672948524516118

Epoch: 258| Step: 0
Training loss: 2.3990378379821777
Validation loss: 2.3585052720962034

Epoch: 5| Step: 1
Training loss: 2.5982882976531982
Validation loss: 2.3505569683608187

Epoch: 5| Step: 2
Training loss: 3.0786221027374268
Validation loss: 2.343802111123198

Epoch: 5| Step: 3
Training loss: 2.2627711296081543
Validation loss: 2.3402725547872563

Epoch: 5| Step: 4
Training loss: 2.6775894165039062
Validation loss: 2.3455339708635883

Epoch: 5| Step: 5
Training loss: 2.529672145843506
Validation loss: 2.3489083679773475

Epoch: 5| Step: 6
Training loss: 2.6884446144104004
Validation loss: 2.351297006812147

Epoch: 5| Step: 7
Training loss: 2.1918060779571533
Validation loss: 2.3548959788455757

Epoch: 5| Step: 8
Training loss: 2.1195175647735596
Validation loss: 2.352184236690562

Epoch: 5| Step: 9
Training loss: 2.65240740776062
Validation loss: 2.3570147765580045

Epoch: 5| Step: 10
Training loss: 1.423635482788086
Validation loss: 2.3718910730013283

Epoch: 259| Step: 0
Training loss: 2.7653801441192627
Validation loss: 2.3661412744111914

Epoch: 5| Step: 1
Training loss: 2.4563846588134766
Validation loss: 2.3690061133394957

Epoch: 5| Step: 2
Training loss: 2.4670634269714355
Validation loss: 2.3648322192571496

Epoch: 5| Step: 3
Training loss: 2.167926549911499
Validation loss: 2.3814658349560154

Epoch: 5| Step: 4
Training loss: 1.7033382654190063
Validation loss: 2.384940537073279

Epoch: 5| Step: 5
Training loss: 2.4539246559143066
Validation loss: 2.3856438436815814

Epoch: 5| Step: 6
Training loss: 2.367004871368408
Validation loss: 2.4080279809172436

Epoch: 5| Step: 7
Training loss: 1.8698813915252686
Validation loss: 2.423868671540291

Epoch: 5| Step: 8
Training loss: 3.7428085803985596
Validation loss: 2.433801304909491

Epoch: 5| Step: 9
Training loss: 2.5369973182678223
Validation loss: 2.4209539249379146

Epoch: 5| Step: 10
Training loss: 2.101816177368164
Validation loss: 2.4069276163654942

Epoch: 260| Step: 0
Training loss: 2.46877121925354
Validation loss: 2.3977771010450137

Epoch: 5| Step: 1
Training loss: 2.2750892639160156
Validation loss: 2.377030864838631

Epoch: 5| Step: 2
Training loss: 2.623335361480713
Validation loss: 2.3564488298149517

Epoch: 5| Step: 3
Training loss: 2.223078489303589
Validation loss: 2.346029730253322

Epoch: 5| Step: 4
Training loss: 2.597461462020874
Validation loss: 2.339531090951735

Epoch: 5| Step: 5
Training loss: 2.6515955924987793
Validation loss: 2.3285968611317296

Epoch: 5| Step: 6
Training loss: 2.2959065437316895
Validation loss: 2.3396103125746532

Epoch: 5| Step: 7
Training loss: 2.3404738903045654
Validation loss: 2.33904089466218

Epoch: 5| Step: 8
Training loss: 2.001756191253662
Validation loss: 2.337074138784921

Epoch: 5| Step: 9
Training loss: 2.7037596702575684
Validation loss: 2.35695493349465

Epoch: 5| Step: 10
Training loss: 2.2938520908355713
Validation loss: 2.3573544230512393

Epoch: 261| Step: 0
Training loss: 2.3178470134735107
Validation loss: 2.3636126210612636

Epoch: 5| Step: 1
Training loss: 2.284799814224243
Validation loss: 2.3622589111328125

Epoch: 5| Step: 2
Training loss: 2.894153356552124
Validation loss: 2.372130011999479

Epoch: 5| Step: 3
Training loss: 2.668944835662842
Validation loss: 2.377081519813948

Epoch: 5| Step: 4
Training loss: 1.6607509851455688
Validation loss: 2.381559992349276

Epoch: 5| Step: 5
Training loss: 2.7255465984344482
Validation loss: 2.386854787026682

Epoch: 5| Step: 6
Training loss: 2.4718456268310547
Validation loss: 2.388537455630559

Epoch: 5| Step: 7
Training loss: 2.2513911724090576
Validation loss: 2.3877881009091615

Epoch: 5| Step: 8
Training loss: 2.0812718868255615
Validation loss: 2.390904095865065

Epoch: 5| Step: 9
Training loss: 2.276445150375366
Validation loss: 2.3905263613629084

Epoch: 5| Step: 10
Training loss: 2.903899669647217
Validation loss: 2.4069869377279796

Epoch: 262| Step: 0
Training loss: 2.824098587036133
Validation loss: 2.3985395405882146

Epoch: 5| Step: 1
Training loss: 2.002546787261963
Validation loss: 2.3913454701823573

Epoch: 5| Step: 2
Training loss: 1.924533486366272
Validation loss: 2.3800846222908265

Epoch: 5| Step: 3
Training loss: 2.4399960041046143
Validation loss: 2.38201783293037

Epoch: 5| Step: 4
Training loss: 2.206918239593506
Validation loss: 2.3690047725554435

Epoch: 5| Step: 5
Training loss: 2.608333110809326
Validation loss: 2.357248308838055

Epoch: 5| Step: 6
Training loss: 2.754455327987671
Validation loss: 2.362515882779193

Epoch: 5| Step: 7
Training loss: 2.361929178237915
Validation loss: 2.364176550219136

Epoch: 5| Step: 8
Training loss: 2.5493507385253906
Validation loss: 2.3635877152924896

Epoch: 5| Step: 9
Training loss: 2.240990400314331
Validation loss: 2.3551991319143646

Epoch: 5| Step: 10
Training loss: 2.443037986755371
Validation loss: 2.36019467794767

Epoch: 263| Step: 0
Training loss: 2.6034700870513916
Validation loss: 2.370383826635217

Epoch: 5| Step: 1
Training loss: 2.2053980827331543
Validation loss: 2.3646954285201205

Epoch: 5| Step: 2
Training loss: 2.04585862159729
Validation loss: 2.3920555730019846

Epoch: 5| Step: 3
Training loss: 2.495504856109619
Validation loss: 2.400678147551834

Epoch: 5| Step: 4
Training loss: 2.653991222381592
Validation loss: 2.4281174470019597

Epoch: 5| Step: 5
Training loss: 2.5299527645111084
Validation loss: 2.4242587320266233

Epoch: 5| Step: 6
Training loss: 2.2104413509368896
Validation loss: 2.4335749738959858

Epoch: 5| Step: 7
Training loss: 2.4959568977355957
Validation loss: 2.4256806347959783

Epoch: 5| Step: 8
Training loss: 1.9192399978637695
Validation loss: 2.4023975608169392

Epoch: 5| Step: 9
Training loss: 2.8653836250305176
Validation loss: 2.388971508190196

Epoch: 5| Step: 10
Training loss: 2.5086090564727783
Validation loss: 2.3707771711452033

Epoch: 264| Step: 0
Training loss: 2.425100088119507
Validation loss: 2.374365545088245

Epoch: 5| Step: 1
Training loss: 2.764483690261841
Validation loss: 2.3687036165627102

Epoch: 5| Step: 2
Training loss: 2.4457390308380127
Validation loss: 2.3627368737292547

Epoch: 5| Step: 3
Training loss: 2.2638654708862305
Validation loss: 2.3712315764478458

Epoch: 5| Step: 4
Training loss: 2.1540367603302
Validation loss: 2.368394982430243

Epoch: 5| Step: 5
Training loss: 2.795032501220703
Validation loss: 2.375518821900891

Epoch: 5| Step: 6
Training loss: 2.010427236557007
Validation loss: 2.3903525234550558

Epoch: 5| Step: 7
Training loss: 2.8747873306274414
Validation loss: 2.405334065037389

Epoch: 5| Step: 8
Training loss: 2.823746919631958
Validation loss: 2.4128432684047247

Epoch: 5| Step: 9
Training loss: 2.106710433959961
Validation loss: 2.434867428195092

Epoch: 5| Step: 10
Training loss: 1.6894861459732056
Validation loss: 2.4137027622551046

Epoch: 265| Step: 0
Training loss: 2.510328769683838
Validation loss: 2.3972445816122074

Epoch: 5| Step: 1
Training loss: 2.2163407802581787
Validation loss: 2.387764407742408

Epoch: 5| Step: 2
Training loss: 2.2323126792907715
Validation loss: 2.387843333264833

Epoch: 5| Step: 3
Training loss: 2.6495203971862793
Validation loss: 2.380514244879446

Epoch: 5| Step: 4
Training loss: 2.7874863147735596
Validation loss: 2.38062467369982

Epoch: 5| Step: 5
Training loss: 2.6750035285949707
Validation loss: 2.376341901799684

Epoch: 5| Step: 6
Training loss: 1.6056188344955444
Validation loss: 2.3774909383507183

Epoch: 5| Step: 7
Training loss: 2.2692835330963135
Validation loss: 2.377288382540467

Epoch: 5| Step: 8
Training loss: 2.421175479888916
Validation loss: 2.3704578133039576

Epoch: 5| Step: 9
Training loss: 2.354207754135132
Validation loss: 2.3554664247779438

Epoch: 5| Step: 10
Training loss: 2.5722413063049316
Validation loss: 2.3668043972343527

Epoch: 266| Step: 0
Training loss: 1.9130299091339111
Validation loss: 2.3649755165141118

Epoch: 5| Step: 1
Training loss: 1.890364408493042
Validation loss: 2.360311556887883

Epoch: 5| Step: 2
Training loss: 2.880218029022217
Validation loss: 2.356452818839781

Epoch: 5| Step: 3
Training loss: 1.9082626104354858
Validation loss: 2.3476758618508615

Epoch: 5| Step: 4
Training loss: 2.2173571586608887
Validation loss: 2.3434789821665776

Epoch: 5| Step: 5
Training loss: 2.648480176925659
Validation loss: 2.337569941756546

Epoch: 5| Step: 6
Training loss: 2.489173412322998
Validation loss: 2.338310703154533

Epoch: 5| Step: 7
Training loss: 2.9193484783172607
Validation loss: 2.3408735875160462

Epoch: 5| Step: 8
Training loss: 3.0927581787109375
Validation loss: 2.3368143035519506

Epoch: 5| Step: 9
Training loss: 2.653926134109497
Validation loss: 2.3443851855493363

Epoch: 5| Step: 10
Training loss: 1.7632049322128296
Validation loss: 2.352120173874722

Epoch: 267| Step: 0
Training loss: 2.8174071311950684
Validation loss: 2.368609571969637

Epoch: 5| Step: 1
Training loss: 3.122699737548828
Validation loss: 2.3871440656723513

Epoch: 5| Step: 2
Training loss: 1.9652776718139648
Validation loss: 2.394628519652992

Epoch: 5| Step: 3
Training loss: 2.0363659858703613
Validation loss: 2.4153288410555933

Epoch: 5| Step: 4
Training loss: 1.6726011037826538
Validation loss: 2.4068334025721394

Epoch: 5| Step: 5
Training loss: 2.2887585163116455
Validation loss: 2.4163152197355866

Epoch: 5| Step: 6
Training loss: 2.769853353500366
Validation loss: 2.4023379100266324

Epoch: 5| Step: 7
Training loss: 2.1285648345947266
Validation loss: 2.400978285779235

Epoch: 5| Step: 8
Training loss: 2.2025146484375
Validation loss: 2.3708375807731383

Epoch: 5| Step: 9
Training loss: 2.6800713539123535
Validation loss: 2.3568187452131704

Epoch: 5| Step: 10
Training loss: 2.7500760555267334
Validation loss: 2.352022765785135

Epoch: 268| Step: 0
Training loss: 3.0962955951690674
Validation loss: 2.33984725962403

Epoch: 5| Step: 1
Training loss: 2.0718235969543457
Validation loss: 2.336125691731771

Epoch: 5| Step: 2
Training loss: 2.540677309036255
Validation loss: 2.3441282254393383

Epoch: 5| Step: 3
Training loss: 2.077073574066162
Validation loss: 2.340972387662498

Epoch: 5| Step: 4
Training loss: 2.318502426147461
Validation loss: 2.3320546868026897

Epoch: 5| Step: 5
Training loss: 1.994546890258789
Validation loss: 2.343563900198988

Epoch: 5| Step: 6
Training loss: 2.6074206829071045
Validation loss: 2.3423840820148425

Epoch: 5| Step: 7
Training loss: 2.7479312419891357
Validation loss: 2.359269739479147

Epoch: 5| Step: 8
Training loss: 2.444171190261841
Validation loss: 2.358564105085147

Epoch: 5| Step: 9
Training loss: 2.1632721424102783
Validation loss: 2.3701370557149253

Epoch: 5| Step: 10
Training loss: 2.2776219844818115
Validation loss: 2.361691480041832

Epoch: 269| Step: 0
Training loss: 2.4011988639831543
Validation loss: 2.3756243644222135

Epoch: 5| Step: 1
Training loss: 1.6885852813720703
Validation loss: 2.387782524990779

Epoch: 5| Step: 2
Training loss: 2.5077109336853027
Validation loss: 2.421067048144597

Epoch: 5| Step: 3
Training loss: 2.8621177673339844
Validation loss: 2.4230319710188013

Epoch: 5| Step: 4
Training loss: 2.9457173347473145
Validation loss: 2.435223194860643

Epoch: 5| Step: 5
Training loss: 2.4845259189605713
Validation loss: 2.4349556276875157

Epoch: 5| Step: 6
Training loss: 2.431610584259033
Validation loss: 2.4068517736209336

Epoch: 5| Step: 7
Training loss: 1.8077831268310547
Validation loss: 2.38670781863633

Epoch: 5| Step: 8
Training loss: 2.2149643898010254
Validation loss: 2.361083061464371

Epoch: 5| Step: 9
Training loss: 2.8574652671813965
Validation loss: 2.349807180384154

Epoch: 5| Step: 10
Training loss: 2.4028987884521484
Validation loss: 2.3675138796529462

Epoch: 270| Step: 0
Training loss: 2.1436190605163574
Validation loss: 2.4010309327033257

Epoch: 5| Step: 1
Training loss: 2.1398017406463623
Validation loss: 2.419096262224259

Epoch: 5| Step: 2
Training loss: 1.9574816226959229
Validation loss: 2.4307042962761334

Epoch: 5| Step: 3
Training loss: 2.422487497329712
Validation loss: 2.451656723535189

Epoch: 5| Step: 4
Training loss: 2.0815489292144775
Validation loss: 2.4696209738331456

Epoch: 5| Step: 5
Training loss: 3.161477565765381
Validation loss: 2.456818619082051

Epoch: 5| Step: 6
Training loss: 2.8690578937530518
Validation loss: 2.441403042885565

Epoch: 5| Step: 7
Training loss: 3.2328639030456543
Validation loss: 2.400345074233188

Epoch: 5| Step: 8
Training loss: 2.499173641204834
Validation loss: 2.3783233088831746

Epoch: 5| Step: 9
Training loss: 2.2920055389404297
Validation loss: 2.346243776300902

Epoch: 5| Step: 10
Training loss: 2.345224142074585
Validation loss: 2.3217735367436565

Epoch: 271| Step: 0
Training loss: 2.7348694801330566
Validation loss: 2.3105741059908302

Epoch: 5| Step: 1
Training loss: 2.364629030227661
Validation loss: 2.315028762304655

Epoch: 5| Step: 2
Training loss: 2.0013585090637207
Validation loss: 2.3405245042616323

Epoch: 5| Step: 3
Training loss: 2.4995815753936768
Validation loss: 2.3442794661368094

Epoch: 5| Step: 4
Training loss: 3.045518159866333
Validation loss: 2.3507654743809856

Epoch: 5| Step: 5
Training loss: 2.304818630218506
Validation loss: 2.3534579969221547

Epoch: 5| Step: 6
Training loss: 1.9878190755844116
Validation loss: 2.3771846704585577

Epoch: 5| Step: 7
Training loss: 2.9572441577911377
Validation loss: 2.353129494574762

Epoch: 5| Step: 8
Training loss: 1.6707130670547485
Validation loss: 2.3411942374321724

Epoch: 5| Step: 9
Training loss: 2.174456834793091
Validation loss: 2.3332431393284954

Epoch: 5| Step: 10
Training loss: 2.7096285820007324
Validation loss: 2.3459569100410707

Epoch: 272| Step: 0
Training loss: 1.8269708156585693
Validation loss: 2.3532404694505917

Epoch: 5| Step: 1
Training loss: 2.1305153369903564
Validation loss: 2.3643579239486368

Epoch: 5| Step: 2
Training loss: 2.4748826026916504
Validation loss: 2.353555717775899

Epoch: 5| Step: 3
Training loss: 1.574360966682434
Validation loss: 2.356974786327731

Epoch: 5| Step: 4
Training loss: 2.4458892345428467
Validation loss: 2.3620760440826416

Epoch: 5| Step: 5
Training loss: 3.100659132003784
Validation loss: 2.353426020632508

Epoch: 5| Step: 6
Training loss: 3.4325969219207764
Validation loss: 2.349323470105407

Epoch: 5| Step: 7
Training loss: 2.246816396713257
Validation loss: 2.3339516398727254

Epoch: 5| Step: 8
Training loss: 2.713294506072998
Validation loss: 2.343737400988097

Epoch: 5| Step: 9
Training loss: 2.2849597930908203
Validation loss: 2.35295783576145

Epoch: 5| Step: 10
Training loss: 1.9579503536224365
Validation loss: 2.368430858017296

Epoch: 273| Step: 0
Training loss: 2.0022010803222656
Validation loss: 2.3721988970233547

Epoch: 5| Step: 1
Training loss: 2.2259202003479004
Validation loss: 2.377518392378284

Epoch: 5| Step: 2
Training loss: 2.0015454292297363
Validation loss: 2.3861592046676146

Epoch: 5| Step: 3
Training loss: 2.1325364112854004
Validation loss: 2.3962766752448132

Epoch: 5| Step: 4
Training loss: 2.498237133026123
Validation loss: 2.3961916636395197

Epoch: 5| Step: 5
Training loss: 2.5592851638793945
Validation loss: 2.39521123004216

Epoch: 5| Step: 6
Training loss: 2.61694073677063
Validation loss: 2.3865177272468485

Epoch: 5| Step: 7
Training loss: 2.7701900005340576
Validation loss: 2.3820657755738948

Epoch: 5| Step: 8
Training loss: 2.940965175628662
Validation loss: 2.3702223224024617

Epoch: 5| Step: 9
Training loss: 2.5828857421875
Validation loss: 2.3709121160609747

Epoch: 5| Step: 10
Training loss: 1.6901849508285522
Validation loss: 2.356025713746266

Epoch: 274| Step: 0
Training loss: 2.692288637161255
Validation loss: 2.360111249390469

Epoch: 5| Step: 1
Training loss: 2.184746265411377
Validation loss: 2.336348669503325

Epoch: 5| Step: 2
Training loss: 2.5085716247558594
Validation loss: 2.3386795572055283

Epoch: 5| Step: 3
Training loss: 2.0181682109832764
Validation loss: 2.321958690561274

Epoch: 5| Step: 4
Training loss: 1.6601861715316772
Validation loss: 2.3147683041070097

Epoch: 5| Step: 5
Training loss: 2.5792133808135986
Validation loss: 2.327743799455704

Epoch: 5| Step: 6
Training loss: 2.441279888153076
Validation loss: 2.3323573809798046

Epoch: 5| Step: 7
Training loss: 2.1747548580169678
Validation loss: 2.340133754155969

Epoch: 5| Step: 8
Training loss: 2.9891304969787598
Validation loss: 2.3708335789301063

Epoch: 5| Step: 9
Training loss: 2.5103647708892822
Validation loss: 2.383625256117954

Epoch: 5| Step: 10
Training loss: 2.441716194152832
Validation loss: 2.379877431418306

Epoch: 275| Step: 0
Training loss: 2.604858875274658
Validation loss: 2.372291698250719

Epoch: 5| Step: 1
Training loss: 2.1034274101257324
Validation loss: 2.368443831320732

Epoch: 5| Step: 2
Training loss: 2.1474194526672363
Validation loss: 2.3639855807827366

Epoch: 5| Step: 3
Training loss: 1.6525952816009521
Validation loss: 2.361104988282727

Epoch: 5| Step: 4
Training loss: 2.862720489501953
Validation loss: 2.363050958161713

Epoch: 5| Step: 5
Training loss: 2.69081974029541
Validation loss: 2.362527114088817

Epoch: 5| Step: 6
Training loss: 2.4080662727355957
Validation loss: 2.3662815427267425

Epoch: 5| Step: 7
Training loss: 2.224905490875244
Validation loss: 2.3767061976976294

Epoch: 5| Step: 8
Training loss: 3.0697083473205566
Validation loss: 2.366112447554065

Epoch: 5| Step: 9
Training loss: 2.0201022624969482
Validation loss: 2.3666344688784693

Epoch: 5| Step: 10
Training loss: 2.2497730255126953
Validation loss: 2.378151778251894

Epoch: 276| Step: 0
Training loss: 2.5131618976593018
Validation loss: 2.395887359496086

Epoch: 5| Step: 1
Training loss: 2.408222198486328
Validation loss: 2.404779362422164

Epoch: 5| Step: 2
Training loss: 2.418621778488159
Validation loss: 2.374069477922173

Epoch: 5| Step: 3
Training loss: 2.2163147926330566
Validation loss: 2.3619058439808507

Epoch: 5| Step: 4
Training loss: 2.3718490600585938
Validation loss: 2.3453945626494703

Epoch: 5| Step: 5
Training loss: 2.7759475708007812
Validation loss: 2.3479779099905365

Epoch: 5| Step: 6
Training loss: 2.3062117099761963
Validation loss: 2.356381909821623

Epoch: 5| Step: 7
Training loss: 2.4891765117645264
Validation loss: 2.368785942754438

Epoch: 5| Step: 8
Training loss: 2.120161294937134
Validation loss: 2.3594219197509108

Epoch: 5| Step: 9
Training loss: 2.600830316543579
Validation loss: 2.3611484227641935

Epoch: 5| Step: 10
Training loss: 1.7373298406600952
Validation loss: 2.3510793844858804

Epoch: 277| Step: 0
Training loss: 2.1755471229553223
Validation loss: 2.3495623245034167

Epoch: 5| Step: 1
Training loss: 2.4986202716827393
Validation loss: 2.350661931499358

Epoch: 5| Step: 2
Training loss: 1.8560352325439453
Validation loss: 2.345482926214895

Epoch: 5| Step: 3
Training loss: 2.2680165767669678
Validation loss: 2.3491721307077715

Epoch: 5| Step: 4
Training loss: 2.5090630054473877
Validation loss: 2.3593917841552408

Epoch: 5| Step: 5
Training loss: 2.3540072441101074
Validation loss: 2.3474427423169537

Epoch: 5| Step: 6
Training loss: 2.9030961990356445
Validation loss: 2.35705417202365

Epoch: 5| Step: 7
Training loss: 2.3808605670928955
Validation loss: 2.35824764415782

Epoch: 5| Step: 8
Training loss: 2.978086233139038
Validation loss: 2.3739334101318033

Epoch: 5| Step: 9
Training loss: 2.038337230682373
Validation loss: 2.3742742205178864

Epoch: 5| Step: 10
Training loss: 1.7040308713912964
Validation loss: 2.3829784816311252

Epoch: 278| Step: 0
Training loss: 2.01440167427063
Validation loss: 2.392082696319908

Epoch: 5| Step: 1
Training loss: 2.339932441711426
Validation loss: 2.3950323853441464

Epoch: 5| Step: 2
Training loss: 2.597994565963745
Validation loss: 2.4199233260205997

Epoch: 5| Step: 3
Training loss: 2.7580618858337402
Validation loss: 2.403665033719873

Epoch: 5| Step: 4
Training loss: 2.672339677810669
Validation loss: 2.419810200250277

Epoch: 5| Step: 5
Training loss: 1.8151519298553467
Validation loss: 2.405379318421887

Epoch: 5| Step: 6
Training loss: 2.517315626144409
Validation loss: 2.3733695604467906

Epoch: 5| Step: 7
Training loss: 2.2331206798553467
Validation loss: 2.3506029498192573

Epoch: 5| Step: 8
Training loss: 2.5283730030059814
Validation loss: 2.3510014190468738

Epoch: 5| Step: 9
Training loss: 2.1806342601776123
Validation loss: 2.3517352714333484

Epoch: 5| Step: 10
Training loss: 2.145638942718506
Validation loss: 2.3390279995497836

Epoch: 279| Step: 0
Training loss: 2.728445529937744
Validation loss: 2.3362139194242415

Epoch: 5| Step: 1
Training loss: 2.382146120071411
Validation loss: 2.329847422979211

Epoch: 5| Step: 2
Training loss: 2.5814871788024902
Validation loss: 2.3313056858637

Epoch: 5| Step: 3
Training loss: 1.7013664245605469
Validation loss: 2.332753800576733

Epoch: 5| Step: 4
Training loss: 2.413773536682129
Validation loss: 2.316964182802426

Epoch: 5| Step: 5
Training loss: 2.506483316421509
Validation loss: 2.3335846829158005

Epoch: 5| Step: 6
Training loss: 1.7836029529571533
Validation loss: 2.3340646554065008

Epoch: 5| Step: 7
Training loss: 3.011385202407837
Validation loss: 2.347723509675713

Epoch: 5| Step: 8
Training loss: 2.195110321044922
Validation loss: 2.356927920413274

Epoch: 5| Step: 9
Training loss: 2.849985122680664
Validation loss: 2.354702539341424

Epoch: 5| Step: 10
Training loss: 1.605189323425293
Validation loss: 2.361801947316816

Epoch: 280| Step: 0
Training loss: 2.795802354812622
Validation loss: 2.3635447281663136

Epoch: 5| Step: 1
Training loss: 2.1199142932891846
Validation loss: 2.3590394860954693

Epoch: 5| Step: 2
Training loss: 2.2558865547180176
Validation loss: 2.350674078028689

Epoch: 5| Step: 3
Training loss: 2.246305465698242
Validation loss: 2.335839153617941

Epoch: 5| Step: 4
Training loss: 2.7465381622314453
Validation loss: 2.326417787100679

Epoch: 5| Step: 5
Training loss: 2.3701095581054688
Validation loss: 2.3359847325150684

Epoch: 5| Step: 6
Training loss: 2.356407642364502
Validation loss: 2.345314512970627

Epoch: 5| Step: 7
Training loss: 2.1649489402770996
Validation loss: 2.337163920043617

Epoch: 5| Step: 8
Training loss: 2.0737104415893555
Validation loss: 2.3448366093379196

Epoch: 5| Step: 9
Training loss: 1.502924919128418
Validation loss: 2.3402994178956553

Epoch: 5| Step: 10
Training loss: 3.2052290439605713
Validation loss: 2.331970109734484

Epoch: 281| Step: 0
Training loss: 2.6303720474243164
Validation loss: 2.3368690244613157

Epoch: 5| Step: 1
Training loss: 2.7552428245544434
Validation loss: 2.3517767370388074

Epoch: 5| Step: 2
Training loss: 2.230167865753174
Validation loss: 2.3592477998425885

Epoch: 5| Step: 3
Training loss: 2.9031567573547363
Validation loss: 2.355887669388966

Epoch: 5| Step: 4
Training loss: 2.2627782821655273
Validation loss: 2.3617210849638908

Epoch: 5| Step: 5
Training loss: 2.182861566543579
Validation loss: 2.357850797714726

Epoch: 5| Step: 6
Training loss: 1.7233062982559204
Validation loss: 2.3720608795842817

Epoch: 5| Step: 7
Training loss: 1.9745972156524658
Validation loss: 2.3699184284415296

Epoch: 5| Step: 8
Training loss: 2.1912636756896973
Validation loss: 2.365555359471229

Epoch: 5| Step: 9
Training loss: 2.3752660751342773
Validation loss: 2.364045435382474

Epoch: 5| Step: 10
Training loss: 2.511800527572632
Validation loss: 2.3684075878512476

Epoch: 282| Step: 0
Training loss: 2.6728007793426514
Validation loss: 2.3698222483358076

Epoch: 5| Step: 1
Training loss: 2.532930374145508
Validation loss: 2.349696204226504

Epoch: 5| Step: 2
Training loss: 1.8395097255706787
Validation loss: 2.348404751029066

Epoch: 5| Step: 3
Training loss: 2.198538303375244
Validation loss: 2.3209271379696426

Epoch: 5| Step: 4
Training loss: 2.1613430976867676
Validation loss: 2.3200290459458546

Epoch: 5| Step: 5
Training loss: 1.9357391595840454
Validation loss: 2.315897500643166

Epoch: 5| Step: 6
Training loss: 2.8232455253601074
Validation loss: 2.3267067632367535

Epoch: 5| Step: 7
Training loss: 2.3486738204956055
Validation loss: 2.32219438399038

Epoch: 5| Step: 8
Training loss: 2.247357130050659
Validation loss: 2.324417773113456

Epoch: 5| Step: 9
Training loss: 2.7009968757629395
Validation loss: 2.326188410482099

Epoch: 5| Step: 10
Training loss: 2.163018226623535
Validation loss: 2.3402704987474667

Epoch: 283| Step: 0
Training loss: 1.657945990562439
Validation loss: 2.3349937649183374

Epoch: 5| Step: 1
Training loss: 2.234976053237915
Validation loss: 2.3427832741891184

Epoch: 5| Step: 2
Training loss: 2.611483097076416
Validation loss: 2.3566419206639773

Epoch: 5| Step: 3
Training loss: 2.318498134613037
Validation loss: 2.3654984658764255

Epoch: 5| Step: 4
Training loss: 2.592710494995117
Validation loss: 2.376504966007766

Epoch: 5| Step: 5
Training loss: 2.52056622505188
Validation loss: 2.3706059866054083

Epoch: 5| Step: 6
Training loss: 2.7020084857940674
Validation loss: 2.367987337932792

Epoch: 5| Step: 7
Training loss: 2.3440632820129395
Validation loss: 2.360595526233796

Epoch: 5| Step: 8
Training loss: 2.4394750595092773
Validation loss: 2.353574469525327

Epoch: 5| Step: 9
Training loss: 2.136873722076416
Validation loss: 2.353038182822607

Epoch: 5| Step: 10
Training loss: 1.9222941398620605
Validation loss: 2.3337888743287776

Epoch: 284| Step: 0
Training loss: 1.8227134943008423
Validation loss: 2.336445471291901

Epoch: 5| Step: 1
Training loss: 1.9710016250610352
Validation loss: 2.3404997189839682

Epoch: 5| Step: 2
Training loss: 2.195089101791382
Validation loss: 2.340538319721017

Epoch: 5| Step: 3
Training loss: 2.6417243480682373
Validation loss: 2.344080002077164

Epoch: 5| Step: 4
Training loss: 2.5703046321868896
Validation loss: 2.3225032975596767

Epoch: 5| Step: 5
Training loss: 2.1459286212921143
Validation loss: 2.3212738472928285

Epoch: 5| Step: 6
Training loss: 2.1667919158935547
Validation loss: 2.320562254997992

Epoch: 5| Step: 7
Training loss: 2.570012092590332
Validation loss: 2.335381841146818

Epoch: 5| Step: 8
Training loss: 3.2160804271698
Validation loss: 2.3375216196942072

Epoch: 5| Step: 9
Training loss: 1.6332824230194092
Validation loss: 2.3514801917537564

Epoch: 5| Step: 10
Training loss: 2.808128833770752
Validation loss: 2.3434223564722205

Epoch: 285| Step: 0
Training loss: 2.7047393321990967
Validation loss: 2.352808433194314

Epoch: 5| Step: 1
Training loss: 2.8685946464538574
Validation loss: 2.3500784186906714

Epoch: 5| Step: 2
Training loss: 3.043400287628174
Validation loss: 2.3450628108875726

Epoch: 5| Step: 3
Training loss: 1.6922807693481445
Validation loss: 2.351233284960511

Epoch: 5| Step: 4
Training loss: 1.614043951034546
Validation loss: 2.34527934751203

Epoch: 5| Step: 5
Training loss: 1.674208402633667
Validation loss: 2.3350982781379455

Epoch: 5| Step: 6
Training loss: 2.5127453804016113
Validation loss: 2.337406563502486

Epoch: 5| Step: 7
Training loss: 2.645298480987549
Validation loss: 2.3317766343393633

Epoch: 5| Step: 8
Training loss: 2.2700257301330566
Validation loss: 2.3345020432626047

Epoch: 5| Step: 9
Training loss: 2.3955676555633545
Validation loss: 2.345230787031112

Epoch: 5| Step: 10
Training loss: 2.1233108043670654
Validation loss: 2.34163168168837

Epoch: 286| Step: 0
Training loss: 2.36881160736084
Validation loss: 2.341432656011274

Epoch: 5| Step: 1
Training loss: 2.1607699394226074
Validation loss: 2.3369689423550843

Epoch: 5| Step: 2
Training loss: 2.4393069744110107
Validation loss: 2.343297641764405

Epoch: 5| Step: 3
Training loss: 2.883500337600708
Validation loss: 2.336377671969834

Epoch: 5| Step: 4
Training loss: 2.2072181701660156
Validation loss: 2.344814685083205

Epoch: 5| Step: 5
Training loss: 2.0506691932678223
Validation loss: 2.3363615235974713

Epoch: 5| Step: 6
Training loss: 2.758436441421509
Validation loss: 2.325042288790467

Epoch: 5| Step: 7
Training loss: 2.0368120670318604
Validation loss: 2.340958849076302

Epoch: 5| Step: 8
Training loss: 2.3572990894317627
Validation loss: 2.330835247552523

Epoch: 5| Step: 9
Training loss: 2.041618824005127
Validation loss: 2.3452471097310386

Epoch: 5| Step: 10
Training loss: 2.163625955581665
Validation loss: 2.350441163586032

Epoch: 287| Step: 0
Training loss: 2.1313576698303223
Validation loss: 2.3612573185274677

Epoch: 5| Step: 1
Training loss: 2.5074427127838135
Validation loss: 2.3679476655939573

Epoch: 5| Step: 2
Training loss: 2.9890074729919434
Validation loss: 2.4043469198288454

Epoch: 5| Step: 3
Training loss: 2.8993048667907715
Validation loss: 2.3971645011696765

Epoch: 5| Step: 4
Training loss: 1.8256657123565674
Validation loss: 2.3937516084281345

Epoch: 5| Step: 5
Training loss: 2.347568988800049
Validation loss: 2.3768852731233

Epoch: 5| Step: 6
Training loss: 1.8677148818969727
Validation loss: 2.363863306660806

Epoch: 5| Step: 7
Training loss: 2.335923433303833
Validation loss: 2.3594815807957805

Epoch: 5| Step: 8
Training loss: 2.0651211738586426
Validation loss: 2.3516099427336004

Epoch: 5| Step: 9
Training loss: 2.3663992881774902
Validation loss: 2.3356095616535475

Epoch: 5| Step: 10
Training loss: 2.1385316848754883
Validation loss: 2.3249407865667857

Epoch: 288| Step: 0
Training loss: 2.5335440635681152
Validation loss: 2.313481641072099

Epoch: 5| Step: 1
Training loss: 2.2046711444854736
Validation loss: 2.309704247341361

Epoch: 5| Step: 2
Training loss: 2.595313310623169
Validation loss: 2.3119862925621772

Epoch: 5| Step: 3
Training loss: 2.3692991733551025
Validation loss: 2.3143725190111386

Epoch: 5| Step: 4
Training loss: 1.4718225002288818
Validation loss: 2.312527894973755

Epoch: 5| Step: 5
Training loss: 2.9559988975524902
Validation loss: 2.320641650948473

Epoch: 5| Step: 6
Training loss: 2.4272780418395996
Validation loss: 2.315000846821775

Epoch: 5| Step: 7
Training loss: 1.8246692419052124
Validation loss: 2.339748203113515

Epoch: 5| Step: 8
Training loss: 2.027266025543213
Validation loss: 2.341501271852883

Epoch: 5| Step: 9
Training loss: 2.3793094158172607
Validation loss: 2.3515287855620026

Epoch: 5| Step: 10
Training loss: 2.8876538276672363
Validation loss: 2.363474463903776

Epoch: 289| Step: 0
Training loss: 2.210771083831787
Validation loss: 2.382020701644241

Epoch: 5| Step: 1
Training loss: 2.5594935417175293
Validation loss: 2.3868577095770065

Epoch: 5| Step: 2
Training loss: 2.4774169921875
Validation loss: 2.392007907231649

Epoch: 5| Step: 3
Training loss: 1.7983688116073608
Validation loss: 2.397170459070513

Epoch: 5| Step: 4
Training loss: 2.2110114097595215
Validation loss: 2.3807663763723066

Epoch: 5| Step: 5
Training loss: 2.6728196144104004
Validation loss: 2.363745427900745

Epoch: 5| Step: 6
Training loss: 2.580289125442505
Validation loss: 2.3422784497660976

Epoch: 5| Step: 7
Training loss: 2.938950777053833
Validation loss: 2.3322881831917712

Epoch: 5| Step: 8
Training loss: 2.054713726043701
Validation loss: 2.336302347080682

Epoch: 5| Step: 9
Training loss: 1.8918373584747314
Validation loss: 2.3326531610181256

Epoch: 5| Step: 10
Training loss: 2.2862939834594727
Validation loss: 2.3339916916303736

Epoch: 290| Step: 0
Training loss: 2.1972098350524902
Validation loss: 2.3245196278377245

Epoch: 5| Step: 1
Training loss: 2.5795207023620605
Validation loss: 2.315883821056735

Epoch: 5| Step: 2
Training loss: 2.693410634994507
Validation loss: 2.319671371931671

Epoch: 5| Step: 3
Training loss: 2.849909543991089
Validation loss: 2.3172950180627967

Epoch: 5| Step: 4
Training loss: 2.3153178691864014
Validation loss: 2.338600151000484

Epoch: 5| Step: 5
Training loss: 2.1444694995880127
Validation loss: 2.3559580669608167

Epoch: 5| Step: 6
Training loss: 2.3588573932647705
Validation loss: 2.379101066179173

Epoch: 5| Step: 7
Training loss: 2.2091450691223145
Validation loss: 2.3980676858655867

Epoch: 5| Step: 8
Training loss: 2.164375066757202
Validation loss: 2.376685309153731

Epoch: 5| Step: 9
Training loss: 1.9266350269317627
Validation loss: 2.350159140043361

Epoch: 5| Step: 10
Training loss: 2.326791286468506
Validation loss: 2.3277475077618837

Epoch: 291| Step: 0
Training loss: 2.1995580196380615
Validation loss: 2.3087623862810034

Epoch: 5| Step: 1
Training loss: 2.5167527198791504
Validation loss: 2.313683958463771

Epoch: 5| Step: 2
Training loss: 2.7584190368652344
Validation loss: 2.308064373590613

Epoch: 5| Step: 3
Training loss: 2.2066917419433594
Validation loss: 2.311479745372649

Epoch: 5| Step: 4
Training loss: 2.5102853775024414
Validation loss: 2.3211382524941557

Epoch: 5| Step: 5
Training loss: 2.2903971672058105
Validation loss: 2.327816040285172

Epoch: 5| Step: 6
Training loss: 2.0463218688964844
Validation loss: 2.319239659975934

Epoch: 5| Step: 7
Training loss: 2.5131194591522217
Validation loss: 2.3315838408726517

Epoch: 5| Step: 8
Training loss: 1.947657823562622
Validation loss: 2.325200255199145

Epoch: 5| Step: 9
Training loss: 2.3360278606414795
Validation loss: 2.33897122516427

Epoch: 5| Step: 10
Training loss: 2.45609712600708
Validation loss: 2.336735979203255

Epoch: 292| Step: 0
Training loss: 1.403652548789978
Validation loss: 2.3378036496459798

Epoch: 5| Step: 1
Training loss: 2.5691702365875244
Validation loss: 2.3623179979221796

Epoch: 5| Step: 2
Training loss: 2.520988702774048
Validation loss: 2.3899658392834406

Epoch: 5| Step: 3
Training loss: 2.943225860595703
Validation loss: 2.4047842974303872

Epoch: 5| Step: 4
Training loss: 2.55418062210083
Validation loss: 2.393185446339269

Epoch: 5| Step: 5
Training loss: 2.21368145942688
Validation loss: 2.367231402345883

Epoch: 5| Step: 6
Training loss: 1.2923997640609741
Validation loss: 2.3578643324554607

Epoch: 5| Step: 7
Training loss: 2.1987991333007812
Validation loss: 2.3234206322700746

Epoch: 5| Step: 8
Training loss: 2.9545376300811768
Validation loss: 2.320599881551599

Epoch: 5| Step: 9
Training loss: 2.3640847206115723
Validation loss: 2.313287114584318

Epoch: 5| Step: 10
Training loss: 2.5674548149108887
Validation loss: 2.3169657773869012

Epoch: 293| Step: 0
Training loss: 2.089207172393799
Validation loss: 2.3311790497072282

Epoch: 5| Step: 1
Training loss: 2.316934108734131
Validation loss: 2.3374876668376308

Epoch: 5| Step: 2
Training loss: 2.3339786529541016
Validation loss: 2.3466137762992614

Epoch: 5| Step: 3
Training loss: 2.703968048095703
Validation loss: 2.3381806663287583

Epoch: 5| Step: 4
Training loss: 2.4042913913726807
Validation loss: 2.337039655254733

Epoch: 5| Step: 5
Training loss: 2.0146055221557617
Validation loss: 2.3362922745366252

Epoch: 5| Step: 6
Training loss: 2.3489601612091064
Validation loss: 2.333368703883181

Epoch: 5| Step: 7
Training loss: 2.604529619216919
Validation loss: 2.324244776079732

Epoch: 5| Step: 8
Training loss: 2.2593512535095215
Validation loss: 2.3387999124424432

Epoch: 5| Step: 9
Training loss: 2.169661045074463
Validation loss: 2.3510537583340883

Epoch: 5| Step: 10
Training loss: 2.33154034614563
Validation loss: 2.3703298363634335

Epoch: 294| Step: 0
Training loss: 2.8778891563415527
Validation loss: 2.370910060021185

Epoch: 5| Step: 1
Training loss: 2.062263011932373
Validation loss: 2.358799507541041

Epoch: 5| Step: 2
Training loss: 2.4551658630371094
Validation loss: 2.327386740715273

Epoch: 5| Step: 3
Training loss: 2.086196184158325
Validation loss: 2.317571432359757

Epoch: 5| Step: 4
Training loss: 2.2742984294891357
Validation loss: 2.316793849391322

Epoch: 5| Step: 5
Training loss: 1.7609180212020874
Validation loss: 2.3155909174232074

Epoch: 5| Step: 6
Training loss: 2.6679930686950684
Validation loss: 2.325294017791748

Epoch: 5| Step: 7
Training loss: 2.79801607131958
Validation loss: 2.320400100882335

Epoch: 5| Step: 8
Training loss: 2.5577762126922607
Validation loss: 2.31741016398194

Epoch: 5| Step: 9
Training loss: 1.9436819553375244
Validation loss: 2.3225655735179944

Epoch: 5| Step: 10
Training loss: 1.9517802000045776
Validation loss: 2.3285681496384325

Epoch: 295| Step: 0
Training loss: 2.706923007965088
Validation loss: 2.3400409913832143

Epoch: 5| Step: 1
Training loss: 1.7483749389648438
Validation loss: 2.3405960862354567

Epoch: 5| Step: 2
Training loss: 2.4271671772003174
Validation loss: 2.351416052028697

Epoch: 5| Step: 3
Training loss: 1.8629982471466064
Validation loss: 2.341818594163464

Epoch: 5| Step: 4
Training loss: 2.724822521209717
Validation loss: 2.3414887202683317

Epoch: 5| Step: 5
Training loss: 2.265444040298462
Validation loss: 2.3388971615863103

Epoch: 5| Step: 6
Training loss: 2.244663953781128
Validation loss: 2.325038040837934

Epoch: 5| Step: 7
Training loss: 2.3973755836486816
Validation loss: 2.3124812572233138

Epoch: 5| Step: 8
Training loss: 2.0442657470703125
Validation loss: 2.3237805366516113

Epoch: 5| Step: 9
Training loss: 2.384899616241455
Validation loss: 2.3199729534887497

Epoch: 5| Step: 10
Training loss: 2.454676389694214
Validation loss: 2.320528530305432

Epoch: 296| Step: 0
Training loss: 2.288726329803467
Validation loss: 2.328079408214938

Epoch: 5| Step: 1
Training loss: 1.6034501791000366
Validation loss: 2.331300204800021

Epoch: 5| Step: 2
Training loss: 2.1644749641418457
Validation loss: 2.3201454019033783

Epoch: 5| Step: 3
Training loss: 2.3995423316955566
Validation loss: 2.3221957760472454

Epoch: 5| Step: 4
Training loss: 1.7337344884872437
Validation loss: 2.315475656140235

Epoch: 5| Step: 5
Training loss: 2.308997869491577
Validation loss: 2.322733986762262

Epoch: 5| Step: 6
Training loss: 2.7637295722961426
Validation loss: 2.327237570157615

Epoch: 5| Step: 7
Training loss: 2.110503673553467
Validation loss: 2.3378050532392276

Epoch: 5| Step: 8
Training loss: 2.516831636428833
Validation loss: 2.32036804896529

Epoch: 5| Step: 9
Training loss: 2.1697402000427246
Validation loss: 2.313438730855142

Epoch: 5| Step: 10
Training loss: 3.186908721923828
Validation loss: 2.31141992281842

Epoch: 297| Step: 0
Training loss: 2.3697524070739746
Validation loss: 2.301586051141062

Epoch: 5| Step: 1
Training loss: 1.9662173986434937
Validation loss: 2.307941516240438

Epoch: 5| Step: 2
Training loss: 2.6472079753875732
Validation loss: 2.3096244847902687

Epoch: 5| Step: 3
Training loss: 1.5110275745391846
Validation loss: 2.3037596261629494

Epoch: 5| Step: 4
Training loss: 2.9540603160858154
Validation loss: 2.301186059110908

Epoch: 5| Step: 5
Training loss: 2.4373228549957275
Validation loss: 2.309564700690649

Epoch: 5| Step: 6
Training loss: 2.0096707344055176
Validation loss: 2.308875532560451

Epoch: 5| Step: 7
Training loss: 2.1671900749206543
Validation loss: 2.3271795549700336

Epoch: 5| Step: 8
Training loss: 2.821871280670166
Validation loss: 2.351433725767238

Epoch: 5| Step: 9
Training loss: 2.2270500659942627
Validation loss: 2.3461646956782185

Epoch: 5| Step: 10
Training loss: 1.9958292245864868
Validation loss: 2.3610852892680834

Epoch: 298| Step: 0
Training loss: 1.7701069116592407
Validation loss: 2.358272942163611

Epoch: 5| Step: 1
Training loss: 2.869208812713623
Validation loss: 2.3515387247967463

Epoch: 5| Step: 2
Training loss: 2.6873843669891357
Validation loss: 2.335785188982564

Epoch: 5| Step: 3
Training loss: 3.2120978832244873
Validation loss: 2.3270521676668556

Epoch: 5| Step: 4
Training loss: 2.3375792503356934
Validation loss: 2.3112775600084694

Epoch: 5| Step: 5
Training loss: 2.3218719959259033
Validation loss: 2.3135605281399143

Epoch: 5| Step: 6
Training loss: 2.0645980834960938
Validation loss: 2.3125038377700315

Epoch: 5| Step: 7
Training loss: 2.284264326095581
Validation loss: 2.3210990813470658

Epoch: 5| Step: 8
Training loss: 1.6286213397979736
Validation loss: 2.3135986071760937

Epoch: 5| Step: 9
Training loss: 1.9841840267181396
Validation loss: 2.30569000013413

Epoch: 5| Step: 10
Training loss: 2.008924722671509
Validation loss: 2.296842039272349

Epoch: 299| Step: 0
Training loss: 1.9543159008026123
Validation loss: 2.30622955547866

Epoch: 5| Step: 1
Training loss: 2.8423664569854736
Validation loss: 2.3111216278486353

Epoch: 5| Step: 2
Training loss: 2.5402939319610596
Validation loss: 2.3133187242733535

Epoch: 5| Step: 3
Training loss: 2.3537187576293945
Validation loss: 2.322813028930336

Epoch: 5| Step: 4
Training loss: 1.6229702234268188
Validation loss: 2.3265665359394525

Epoch: 5| Step: 5
Training loss: 2.452876091003418
Validation loss: 2.328173178498463

Epoch: 5| Step: 6
Training loss: 2.1298365592956543
Validation loss: 2.3358865963515414

Epoch: 5| Step: 7
Training loss: 1.609903335571289
Validation loss: 2.332572370447138

Epoch: 5| Step: 8
Training loss: 2.2061665058135986
Validation loss: 2.3293326721396497

Epoch: 5| Step: 9
Training loss: 2.425269603729248
Validation loss: 2.3263184870443037

Epoch: 5| Step: 10
Training loss: 3.000939130783081
Validation loss: 2.3266315408932265

Epoch: 300| Step: 0
Training loss: 3.404698133468628
Validation loss: 2.3252266363431047

Epoch: 5| Step: 1
Training loss: 2.4017207622528076
Validation loss: 2.330924777574437

Epoch: 5| Step: 2
Training loss: 2.1756820678710938
Validation loss: 2.324858537284277

Epoch: 5| Step: 3
Training loss: 2.2150559425354004
Validation loss: 2.3140430219711794

Epoch: 5| Step: 4
Training loss: 2.419552803039551
Validation loss: 2.324663072504023

Epoch: 5| Step: 5
Training loss: 1.5449764728546143
Validation loss: 2.326847184088922

Epoch: 5| Step: 6
Training loss: 2.38785982131958
Validation loss: 2.334406332303119

Epoch: 5| Step: 7
Training loss: 1.393185019493103
Validation loss: 2.3332703908284507

Epoch: 5| Step: 8
Training loss: 2.2113752365112305
Validation loss: 2.338788932369601

Epoch: 5| Step: 9
Training loss: 2.893418073654175
Validation loss: 2.3333916638487127

Epoch: 5| Step: 10
Training loss: 1.9445167779922485
Validation loss: 2.343726896470593

Epoch: 301| Step: 0
Training loss: 1.7231546640396118
Validation loss: 2.339902098460864

Epoch: 5| Step: 1
Training loss: 3.1138508319854736
Validation loss: 2.330251321997694

Epoch: 5| Step: 2
Training loss: 2.271088123321533
Validation loss: 2.3443606925267044

Epoch: 5| Step: 3
Training loss: 2.1079230308532715
Validation loss: 2.339070571366177

Epoch: 5| Step: 4
Training loss: 2.080627918243408
Validation loss: 2.349027436266663

Epoch: 5| Step: 5
Training loss: 2.4133987426757812
Validation loss: 2.342268543858682

Epoch: 5| Step: 6
Training loss: 2.754923105239868
Validation loss: 2.31266704938745

Epoch: 5| Step: 7
Training loss: 2.309131383895874
Validation loss: 2.3022593477720856

Epoch: 5| Step: 8
Training loss: 1.2283077239990234
Validation loss: 2.2935861438833256

Epoch: 5| Step: 9
Training loss: 2.574741840362549
Validation loss: 2.2883531919089695

Epoch: 5| Step: 10
Training loss: 2.4447152614593506
Validation loss: 2.2870235443115234

Epoch: 302| Step: 0
Training loss: 2.397141218185425
Validation loss: 2.285392668939406

Epoch: 5| Step: 1
Training loss: 2.906754732131958
Validation loss: 2.2820123869885682

Epoch: 5| Step: 2
Training loss: 2.6333022117614746
Validation loss: 2.2980541747103453

Epoch: 5| Step: 3
Training loss: 2.0808606147766113
Validation loss: 2.300596453810251

Epoch: 5| Step: 4
Training loss: 1.7753785848617554
Validation loss: 2.3080914276902393

Epoch: 5| Step: 5
Training loss: 2.223745346069336
Validation loss: 2.31567483563577

Epoch: 5| Step: 6
Training loss: 2.232269763946533
Validation loss: 2.3417691517901678

Epoch: 5| Step: 7
Training loss: 2.6330459117889404
Validation loss: 2.34317769030089

Epoch: 5| Step: 8
Training loss: 2.345048666000366
Validation loss: 2.3452344709827053

Epoch: 5| Step: 9
Training loss: 2.3777575492858887
Validation loss: 2.3408644301916963

Epoch: 5| Step: 10
Training loss: 1.226258635520935
Validation loss: 2.337360720480642

Epoch: 303| Step: 0
Training loss: 2.346048593521118
Validation loss: 2.32785294389212

Epoch: 5| Step: 1
Training loss: 2.4754996299743652
Validation loss: 2.3295806146437124

Epoch: 5| Step: 2
Training loss: 2.27856707572937
Validation loss: 2.3297034155937935

Epoch: 5| Step: 3
Training loss: 2.718064785003662
Validation loss: 2.3221879748887915

Epoch: 5| Step: 4
Training loss: 1.5350499153137207
Validation loss: 2.301731001946234

Epoch: 5| Step: 5
Training loss: 2.8618228435516357
Validation loss: 2.299819992434594

Epoch: 5| Step: 6
Training loss: 1.8242355585098267
Validation loss: 2.305749111278083

Epoch: 5| Step: 7
Training loss: 2.2465009689331055
Validation loss: 2.2996743417555288

Epoch: 5| Step: 8
Training loss: 2.090531587600708
Validation loss: 2.2896026142181887

Epoch: 5| Step: 9
Training loss: 2.4589431285858154
Validation loss: 2.293782434155864

Epoch: 5| Step: 10
Training loss: 1.9941060543060303
Validation loss: 2.308009211735059

Epoch: 304| Step: 0
Training loss: 2.5993683338165283
Validation loss: 2.321508120465022

Epoch: 5| Step: 1
Training loss: 2.2864842414855957
Validation loss: 2.331079190777194

Epoch: 5| Step: 2
Training loss: 1.9237209558486938
Validation loss: 2.3099344827795543

Epoch: 5| Step: 3
Training loss: 2.355369806289673
Validation loss: 2.3357453192434003

Epoch: 5| Step: 4
Training loss: 2.521019220352173
Validation loss: 2.34248714036839

Epoch: 5| Step: 5
Training loss: 2.570652484893799
Validation loss: 2.3401940920019664

Epoch: 5| Step: 6
Training loss: 2.038991928100586
Validation loss: 2.3442839448169996

Epoch: 5| Step: 7
Training loss: 2.043999433517456
Validation loss: 2.326274924380805

Epoch: 5| Step: 8
Training loss: 2.5541634559631348
Validation loss: 2.332544078109085

Epoch: 5| Step: 9
Training loss: 1.9446232318878174
Validation loss: 2.3371856238252375

Epoch: 5| Step: 10
Training loss: 1.978278636932373
Validation loss: 2.334572115252095

Epoch: 305| Step: 0
Training loss: 1.746519684791565
Validation loss: 2.3284965907373736

Epoch: 5| Step: 1
Training loss: 2.1585965156555176
Validation loss: 2.3174470727161696

Epoch: 5| Step: 2
Training loss: 2.4899826049804688
Validation loss: 2.325547355477528

Epoch: 5| Step: 3
Training loss: 2.148181438446045
Validation loss: 2.3255806661421254

Epoch: 5| Step: 4
Training loss: 2.31455659866333
Validation loss: 2.3232834044323174

Epoch: 5| Step: 5
Training loss: 2.8815643787384033
Validation loss: 2.333470143297667

Epoch: 5| Step: 6
Training loss: 2.130308151245117
Validation loss: 2.33432674407959

Epoch: 5| Step: 7
Training loss: 2.789614200592041
Validation loss: 2.3310478297613

Epoch: 5| Step: 8
Training loss: 1.9201853275299072
Validation loss: 2.3337451616923013

Epoch: 5| Step: 9
Training loss: 1.951873540878296
Validation loss: 2.3150528682175504

Epoch: 5| Step: 10
Training loss: 2.4120676517486572
Validation loss: 2.317168638270388

Epoch: 306| Step: 0
Training loss: 2.245647430419922
Validation loss: 2.311033497574509

Epoch: 5| Step: 1
Training loss: 2.6432318687438965
Validation loss: 2.304592608123697

Epoch: 5| Step: 2
Training loss: 2.0087759494781494
Validation loss: 2.306925460856448

Epoch: 5| Step: 3
Training loss: 2.3461616039276123
Validation loss: 2.3113236094033844

Epoch: 5| Step: 4
Training loss: 2.0768988132476807
Validation loss: 2.3101887138940955

Epoch: 5| Step: 5
Training loss: 2.0135316848754883
Validation loss: 2.3160896634542816

Epoch: 5| Step: 6
Training loss: 2.3242027759552
Validation loss: 2.3311204653914257

Epoch: 5| Step: 7
Training loss: 2.243227958679199
Validation loss: 2.3339177382889615

Epoch: 5| Step: 8
Training loss: 1.9647239446640015
Validation loss: 2.3345280206331642

Epoch: 5| Step: 9
Training loss: 2.5392391681671143
Validation loss: 2.337114134142476

Epoch: 5| Step: 10
Training loss: 2.4485530853271484
Validation loss: 2.3219897900858233

Epoch: 307| Step: 0
Training loss: 2.101510524749756
Validation loss: 2.327841588245925

Epoch: 5| Step: 1
Training loss: 2.407705068588257
Validation loss: 2.3256420525171424

Epoch: 5| Step: 2
Training loss: 2.1925511360168457
Validation loss: 2.308620834863314

Epoch: 5| Step: 3
Training loss: 2.5039799213409424
Validation loss: 2.300679765721803

Epoch: 5| Step: 4
Training loss: 1.7921593189239502
Validation loss: 2.3084681674998295

Epoch: 5| Step: 5
Training loss: 2.4164786338806152
Validation loss: 2.3134753216979322

Epoch: 5| Step: 6
Training loss: 2.437417507171631
Validation loss: 2.302219852324455

Epoch: 5| Step: 7
Training loss: 1.5739587545394897
Validation loss: 2.310065825780233

Epoch: 5| Step: 8
Training loss: 2.7401890754699707
Validation loss: 2.313245722042617

Epoch: 5| Step: 9
Training loss: 2.5261030197143555
Validation loss: 2.3107007882928334

Epoch: 5| Step: 10
Training loss: 2.1594719886779785
Validation loss: 2.3147779690322055

Epoch: 308| Step: 0
Training loss: 1.1909973621368408
Validation loss: 2.3029065542323615

Epoch: 5| Step: 1
Training loss: 2.1026222705841064
Validation loss: 2.3241509840052617

Epoch: 5| Step: 2
Training loss: 2.5209317207336426
Validation loss: 2.3275020891620266

Epoch: 5| Step: 3
Training loss: 2.0706114768981934
Validation loss: 2.327632834834437

Epoch: 5| Step: 4
Training loss: 2.1558997631073
Validation loss: 2.3309238495365268

Epoch: 5| Step: 5
Training loss: 1.842354416847229
Validation loss: 2.3218384276154223

Epoch: 5| Step: 6
Training loss: 2.5267865657806396
Validation loss: 2.320524323371149

Epoch: 5| Step: 7
Training loss: 3.061720371246338
Validation loss: 2.322807664512306

Epoch: 5| Step: 8
Training loss: 2.008270740509033
Validation loss: 2.310782891447826

Epoch: 5| Step: 9
Training loss: 2.917024850845337
Validation loss: 2.3188593977241108

Epoch: 5| Step: 10
Training loss: 2.382248640060425
Validation loss: 2.3050254993541266

Epoch: 309| Step: 0
Training loss: 2.567115306854248
Validation loss: 2.2879924107623357

Epoch: 5| Step: 1
Training loss: 2.718371629714966
Validation loss: 2.2876928339722338

Epoch: 5| Step: 2
Training loss: 2.8057518005371094
Validation loss: 2.2803203598145516

Epoch: 5| Step: 3
Training loss: 1.9526907205581665
Validation loss: 2.309910238430064

Epoch: 5| Step: 4
Training loss: 1.9640519618988037
Validation loss: 2.32362203444204

Epoch: 5| Step: 5
Training loss: 2.405371904373169
Validation loss: 2.340412198856313

Epoch: 5| Step: 6
Training loss: 1.537276268005371
Validation loss: 2.321118447088426

Epoch: 5| Step: 7
Training loss: 2.224292039871216
Validation loss: 2.3397847555016957

Epoch: 5| Step: 8
Training loss: 1.9059789180755615
Validation loss: 2.3377022666315876

Epoch: 5| Step: 9
Training loss: 2.8788704872131348
Validation loss: 2.329160838998774

Epoch: 5| Step: 10
Training loss: 1.945604681968689
Validation loss: 2.339273844995806

Epoch: 310| Step: 0
Training loss: 2.746703624725342
Validation loss: 2.334292763022966

Epoch: 5| Step: 1
Training loss: 3.759253740310669
Validation loss: 2.343984168062928

Epoch: 5| Step: 2
Training loss: 2.834500789642334
Validation loss: 2.336885142069991

Epoch: 5| Step: 3
Training loss: 1.3911253213882446
Validation loss: 2.3200626219472578

Epoch: 5| Step: 4
Training loss: 1.840733528137207
Validation loss: 2.29959858873839

Epoch: 5| Step: 5
Training loss: 2.145298719406128
Validation loss: 2.2945791213743147

Epoch: 5| Step: 6
Training loss: 1.733055830001831
Validation loss: 2.2996936152058263

Epoch: 5| Step: 7
Training loss: 1.6713840961456299
Validation loss: 2.302134220318128

Epoch: 5| Step: 8
Training loss: 2.5435075759887695
Validation loss: 2.3130380363874536

Epoch: 5| Step: 9
Training loss: 2.3172268867492676
Validation loss: 2.3126274526760144

Epoch: 5| Step: 10
Training loss: 1.8896809816360474
Validation loss: 2.315846534185512

Epoch: 311| Step: 0
Training loss: 2.6194348335266113
Validation loss: 2.3211677125705186

Epoch: 5| Step: 1
Training loss: 2.7593390941619873
Validation loss: 2.3091380775615735

Epoch: 5| Step: 2
Training loss: 2.054781675338745
Validation loss: 2.3103991785357074

Epoch: 5| Step: 3
Training loss: 2.4480135440826416
Validation loss: 2.3096914586200508

Epoch: 5| Step: 4
Training loss: 2.2387123107910156
Validation loss: 2.313765219462815

Epoch: 5| Step: 5
Training loss: 2.137047290802002
Validation loss: 2.317963256630846

Epoch: 5| Step: 6
Training loss: 2.2651801109313965
Validation loss: 2.3186696601170365

Epoch: 5| Step: 7
Training loss: 1.7476742267608643
Validation loss: 2.3221884440350276

Epoch: 5| Step: 8
Training loss: 2.317054271697998
Validation loss: 2.3454800677555863

Epoch: 5| Step: 9
Training loss: 2.0859694480895996
Validation loss: 2.3338421365266204

Epoch: 5| Step: 10
Training loss: 2.2095136642456055
Validation loss: 2.3181547631499586

Epoch: 312| Step: 0
Training loss: 2.518430471420288
Validation loss: 2.3121327712971675

Epoch: 5| Step: 1
Training loss: 1.7636394500732422
Validation loss: 2.3196034380184707

Epoch: 5| Step: 2
Training loss: 2.798760175704956
Validation loss: 2.319520055606801

Epoch: 5| Step: 3
Training loss: 2.1588134765625
Validation loss: 2.3053414770351943

Epoch: 5| Step: 4
Training loss: 1.938406229019165
Validation loss: 2.3102361591913367

Epoch: 5| Step: 5
Training loss: 2.292933940887451
Validation loss: 2.3142272733872935

Epoch: 5| Step: 6
Training loss: 2.2093615531921387
Validation loss: 2.3318084029741186

Epoch: 5| Step: 7
Training loss: 2.003859043121338
Validation loss: 2.3248387767422583

Epoch: 5| Step: 8
Training loss: 2.4097583293914795
Validation loss: 2.314949607336393

Epoch: 5| Step: 9
Training loss: 2.3034420013427734
Validation loss: 2.321221956642725

Epoch: 5| Step: 10
Training loss: 2.6029582023620605
Validation loss: 2.331847834330733

Epoch: 313| Step: 0
Training loss: 1.8094151020050049
Validation loss: 2.3155246037308888

Epoch: 5| Step: 1
Training loss: 2.525132894515991
Validation loss: 2.3097463359114943

Epoch: 5| Step: 2
Training loss: 2.0850493907928467
Validation loss: 2.303745613303236

Epoch: 5| Step: 3
Training loss: 2.2126846313476562
Validation loss: 2.3074040541084866

Epoch: 5| Step: 4
Training loss: 2.191019296646118
Validation loss: 2.309216396782988

Epoch: 5| Step: 5
Training loss: 2.6354141235351562
Validation loss: 2.3146005599729476

Epoch: 5| Step: 6
Training loss: 2.398709535598755
Validation loss: 2.3151746898569088

Epoch: 5| Step: 7
Training loss: 1.8659954071044922
Validation loss: 2.3267200352043234

Epoch: 5| Step: 8
Training loss: 2.268223285675049
Validation loss: 2.3178008269238215

Epoch: 5| Step: 9
Training loss: 2.331449031829834
Validation loss: 2.321973341767506

Epoch: 5| Step: 10
Training loss: 2.357689142227173
Validation loss: 2.3246528999779814

Epoch: 314| Step: 0
Training loss: 1.4961268901824951
Validation loss: 2.318682283483526

Epoch: 5| Step: 1
Training loss: 2.058509349822998
Validation loss: 2.3092108080464024

Epoch: 5| Step: 2
Training loss: 2.527437686920166
Validation loss: 2.2883821995027605

Epoch: 5| Step: 3
Training loss: 2.6559319496154785
Validation loss: 2.2940582806064236

Epoch: 5| Step: 4
Training loss: 1.910789132118225
Validation loss: 2.281849535562659

Epoch: 5| Step: 5
Training loss: 2.6941258907318115
Validation loss: 2.2819489612374255

Epoch: 5| Step: 6
Training loss: 2.2552855014801025
Validation loss: 2.2899516756816576

Epoch: 5| Step: 7
Training loss: 2.131829261779785
Validation loss: 2.284928896093881

Epoch: 5| Step: 8
Training loss: 1.7870336771011353
Validation loss: 2.2863089820390106

Epoch: 5| Step: 9
Training loss: 2.500684976577759
Validation loss: 2.308312926241147

Epoch: 5| Step: 10
Training loss: 2.70465087890625
Validation loss: 2.319291651889842

Epoch: 315| Step: 0
Training loss: 2.459380626678467
Validation loss: 2.327995470775071

Epoch: 5| Step: 1
Training loss: 1.7809083461761475
Validation loss: 2.336945382497644

Epoch: 5| Step: 2
Training loss: 2.1236677169799805
Validation loss: 2.3343077423751994

Epoch: 5| Step: 3
Training loss: 2.7609498500823975
Validation loss: 2.345179773146106

Epoch: 5| Step: 4
Training loss: 2.315295696258545
Validation loss: 2.3379045455686507

Epoch: 5| Step: 5
Training loss: 1.7213376760482788
Validation loss: 2.3456252210883686

Epoch: 5| Step: 6
Training loss: 2.3445560932159424
Validation loss: 2.332083481614308

Epoch: 5| Step: 7
Training loss: 2.156630277633667
Validation loss: 2.3255201001321115

Epoch: 5| Step: 8
Training loss: 2.4847512245178223
Validation loss: 2.2960193746833393

Epoch: 5| Step: 9
Training loss: 2.620561361312866
Validation loss: 2.2964838781664447

Epoch: 5| Step: 10
Training loss: 1.7049214839935303
Validation loss: 2.290235645027571

Epoch: 316| Step: 0
Training loss: 1.962761640548706
Validation loss: 2.2746067790574926

Epoch: 5| Step: 1
Training loss: 1.8060299158096313
Validation loss: 2.2839349521103727

Epoch: 5| Step: 2
Training loss: 1.596784234046936
Validation loss: 2.2899026127271753

Epoch: 5| Step: 3
Training loss: 2.598663806915283
Validation loss: 2.300436576207479

Epoch: 5| Step: 4
Training loss: 1.7918167114257812
Validation loss: 2.2994617915922597

Epoch: 5| Step: 5
Training loss: 2.247037887573242
Validation loss: 2.3115604795435423

Epoch: 5| Step: 6
Training loss: 2.690768241882324
Validation loss: 2.3179328877438783

Epoch: 5| Step: 7
Training loss: 2.202613353729248
Validation loss: 2.324869704502885

Epoch: 5| Step: 8
Training loss: 3.0553879737854004
Validation loss: 2.3255505997647523

Epoch: 5| Step: 9
Training loss: 1.9052280187606812
Validation loss: 2.32973409980856

Epoch: 5| Step: 10
Training loss: 2.8222551345825195
Validation loss: 2.324324861649544

Epoch: 317| Step: 0
Training loss: 2.631925106048584
Validation loss: 2.3123115185768373

Epoch: 5| Step: 1
Training loss: 1.8422333002090454
Validation loss: 2.3058885707650134

Epoch: 5| Step: 2
Training loss: 1.7189357280731201
Validation loss: 2.300134584467898

Epoch: 5| Step: 3
Training loss: 2.1227810382843018
Validation loss: 2.2870107837902602

Epoch: 5| Step: 4
Training loss: 2.1633076667785645
Validation loss: 2.293221535221223

Epoch: 5| Step: 5
Training loss: 2.231926202774048
Validation loss: 2.299390838992211

Epoch: 5| Step: 6
Training loss: 2.7609341144561768
Validation loss: 2.2966333512336976

Epoch: 5| Step: 7
Training loss: 2.338618755340576
Validation loss: 2.2939537891777615

Epoch: 5| Step: 8
Training loss: 1.6951234340667725
Validation loss: 2.2996822275141233

Epoch: 5| Step: 9
Training loss: 2.709357738494873
Validation loss: 2.2906235418012066

Epoch: 5| Step: 10
Training loss: 2.2348358631134033
Validation loss: 2.298539279609598

Epoch: 318| Step: 0
Training loss: 2.6242122650146484
Validation loss: 2.3088319378514446

Epoch: 5| Step: 1
Training loss: 1.9868444204330444
Validation loss: 2.2995776771217264

Epoch: 5| Step: 2
Training loss: 2.989919424057007
Validation loss: 2.310962446274296

Epoch: 5| Step: 3
Training loss: 2.0962510108947754
Validation loss: 2.315899323391658

Epoch: 5| Step: 4
Training loss: 2.039916753768921
Validation loss: 2.305636155989862

Epoch: 5| Step: 5
Training loss: 1.9182593822479248
Validation loss: 2.3024147710492535

Epoch: 5| Step: 6
Training loss: 2.360166072845459
Validation loss: 2.2894088247770905

Epoch: 5| Step: 7
Training loss: 2.208754539489746
Validation loss: 2.2853507380331717

Epoch: 5| Step: 8
Training loss: 2.288113832473755
Validation loss: 2.293482224146525

Epoch: 5| Step: 9
Training loss: 1.8394428491592407
Validation loss: 2.282976540186072

Epoch: 5| Step: 10
Training loss: 2.0767064094543457
Validation loss: 2.2892359661799606

Epoch: 319| Step: 0
Training loss: 2.3762199878692627
Validation loss: 2.2900731358476865

Epoch: 5| Step: 1
Training loss: 2.3276870250701904
Validation loss: 2.286722001209054

Epoch: 5| Step: 2
Training loss: 1.48858642578125
Validation loss: 2.3036716061253704

Epoch: 5| Step: 3
Training loss: 2.174084424972534
Validation loss: 2.2903182839834564

Epoch: 5| Step: 4
Training loss: 2.4338793754577637
Validation loss: 2.3035774692412345

Epoch: 5| Step: 5
Training loss: 2.3064687252044678
Validation loss: 2.30524448169175

Epoch: 5| Step: 6
Training loss: 2.5269877910614014
Validation loss: 2.3003373889512915

Epoch: 5| Step: 7
Training loss: 2.2793707847595215
Validation loss: 2.306186827280188

Epoch: 5| Step: 8
Training loss: 1.8234455585479736
Validation loss: 2.3046473790240545

Epoch: 5| Step: 9
Training loss: 2.3773183822631836
Validation loss: 2.3028320086899625

Epoch: 5| Step: 10
Training loss: 2.2728822231292725
Validation loss: 2.3037330014731294

Epoch: 320| Step: 0
Training loss: 2.575796604156494
Validation loss: 2.306389239526564

Epoch: 5| Step: 1
Training loss: 2.1248257160186768
Validation loss: 2.3111175055144937

Epoch: 5| Step: 2
Training loss: 2.174708604812622
Validation loss: 2.3010005745836484

Epoch: 5| Step: 3
Training loss: 2.9794626235961914
Validation loss: 2.314188345786064

Epoch: 5| Step: 4
Training loss: 2.052647352218628
Validation loss: 2.321220741477064

Epoch: 5| Step: 5
Training loss: 1.894688606262207
Validation loss: 2.3239079495911956

Epoch: 5| Step: 6
Training loss: 2.3205065727233887
Validation loss: 2.3049106649173203

Epoch: 5| Step: 7
Training loss: 1.8112930059432983
Validation loss: 2.2958204207881803

Epoch: 5| Step: 8
Training loss: 2.2124416828155518
Validation loss: 2.295387657739783

Epoch: 5| Step: 9
Training loss: 1.715370774269104
Validation loss: 2.2890136652095343

Epoch: 5| Step: 10
Training loss: 2.637145519256592
Validation loss: 2.3044834675327426

Epoch: 321| Step: 0
Training loss: 2.2882697582244873
Validation loss: 2.3027737204746535

Epoch: 5| Step: 1
Training loss: 1.6436870098114014
Validation loss: 2.289027275577668

Epoch: 5| Step: 2
Training loss: 2.5246925354003906
Validation loss: 2.2798894297692085

Epoch: 5| Step: 3
Training loss: 2.387603282928467
Validation loss: 2.2857943580996607

Epoch: 5| Step: 4
Training loss: 2.071814775466919
Validation loss: 2.282434727555962

Epoch: 5| Step: 5
Training loss: 1.857057809829712
Validation loss: 2.2696710350692912

Epoch: 5| Step: 6
Training loss: 1.8400352001190186
Validation loss: 2.275591701589605

Epoch: 5| Step: 7
Training loss: 2.5687148571014404
Validation loss: 2.27298209744115

Epoch: 5| Step: 8
Training loss: 2.299560546875
Validation loss: 2.2732944027070077

Epoch: 5| Step: 9
Training loss: 2.826145648956299
Validation loss: 2.2727100464605514

Epoch: 5| Step: 10
Training loss: 2.127481460571289
Validation loss: 2.2665187825438795

Epoch: 322| Step: 0
Training loss: 2.8043060302734375
Validation loss: 2.268652562172182

Epoch: 5| Step: 1
Training loss: 2.2754340171813965
Validation loss: 2.2629109313411098

Epoch: 5| Step: 2
Training loss: 2.072327136993408
Validation loss: 2.2717151052208355

Epoch: 5| Step: 3
Training loss: 1.782189965248108
Validation loss: 2.2953104331929195

Epoch: 5| Step: 4
Training loss: 2.085848569869995
Validation loss: 2.293662950556765

Epoch: 5| Step: 5
Training loss: 2.136462926864624
Validation loss: 2.3107160804092244

Epoch: 5| Step: 6
Training loss: 2.2441537380218506
Validation loss: 2.326534931377698

Epoch: 5| Step: 7
Training loss: 3.0801572799682617
Validation loss: 2.3174864527999715

Epoch: 5| Step: 8
Training loss: 2.0463809967041016
Validation loss: 2.3135542767022246

Epoch: 5| Step: 9
Training loss: 2.1630008220672607
Validation loss: 2.3180990270389024

Epoch: 5| Step: 10
Training loss: 1.6747891902923584
Validation loss: 2.3144050054652716

Epoch: 323| Step: 0
Training loss: 2.280996799468994
Validation loss: 2.319770633533437

Epoch: 5| Step: 1
Training loss: 1.9711660146713257
Validation loss: 2.319536850016604

Epoch: 5| Step: 2
Training loss: 1.5731031894683838
Validation loss: 2.301913756196217

Epoch: 5| Step: 3
Training loss: 2.152690887451172
Validation loss: 2.2981607837061726

Epoch: 5| Step: 4
Training loss: 1.8563261032104492
Validation loss: 2.288610286610101

Epoch: 5| Step: 5
Training loss: 2.4011452198028564
Validation loss: 2.2840339650389967

Epoch: 5| Step: 6
Training loss: 2.1411871910095215
Validation loss: 2.2762378133753294

Epoch: 5| Step: 7
Training loss: 2.280813217163086
Validation loss: 2.269474564060088

Epoch: 5| Step: 8
Training loss: 2.3116891384124756
Validation loss: 2.2685177095474733

Epoch: 5| Step: 9
Training loss: 2.608839511871338
Validation loss: 2.257301443366594

Epoch: 5| Step: 10
Training loss: 2.8384599685668945
Validation loss: 2.261595815740606

Epoch: 324| Step: 0
Training loss: 1.913661241531372
Validation loss: 2.2652477833532516

Epoch: 5| Step: 1
Training loss: 2.27986478805542
Validation loss: 2.27284848818215

Epoch: 5| Step: 2
Training loss: 2.56512451171875
Validation loss: 2.280940332720357

Epoch: 5| Step: 3
Training loss: 2.2623085975646973
Validation loss: 2.283864054628598

Epoch: 5| Step: 4
Training loss: 1.6778274774551392
Validation loss: 2.2793672546263664

Epoch: 5| Step: 5
Training loss: 1.9070323705673218
Validation loss: 2.2897221452446392

Epoch: 5| Step: 6
Training loss: 2.040299654006958
Validation loss: 2.295234244356873

Epoch: 5| Step: 7
Training loss: 1.8478809595108032
Validation loss: 2.311208035356255

Epoch: 5| Step: 8
Training loss: 3.477646589279175
Validation loss: 2.3132594131654307

Epoch: 5| Step: 9
Training loss: 2.2553250789642334
Validation loss: 2.3077236606228735

Epoch: 5| Step: 10
Training loss: 2.0628435611724854
Validation loss: 2.3128737454773276

Epoch: 325| Step: 0
Training loss: 2.543362855911255
Validation loss: 2.3099250614002185

Epoch: 5| Step: 1
Training loss: 1.676794409751892
Validation loss: 2.3193822624862834

Epoch: 5| Step: 2
Training loss: 1.6303993463516235
Validation loss: 2.3111091711187877

Epoch: 5| Step: 3
Training loss: 2.1304614543914795
Validation loss: 2.3041030463351997

Epoch: 5| Step: 4
Training loss: 2.726130723953247
Validation loss: 2.308644320375176

Epoch: 5| Step: 5
Training loss: 1.5414378643035889
Validation loss: 2.2983793904704433

Epoch: 5| Step: 6
Training loss: 2.1336007118225098
Validation loss: 2.2843466471600276

Epoch: 5| Step: 7
Training loss: 2.4511234760284424
Validation loss: 2.2907161148645545

Epoch: 5| Step: 8
Training loss: 2.697312831878662
Validation loss: 2.2833743274852796

Epoch: 5| Step: 9
Training loss: 2.730623722076416
Validation loss: 2.277676369554253

Epoch: 5| Step: 10
Training loss: 2.012568712234497
Validation loss: 2.2766658695795203

Epoch: 326| Step: 0
Training loss: 2.307349681854248
Validation loss: 2.267797913602603

Epoch: 5| Step: 1
Training loss: 2.5392985343933105
Validation loss: 2.2733486237064486

Epoch: 5| Step: 2
Training loss: 1.9301526546478271
Validation loss: 2.278359220873925

Epoch: 5| Step: 3
Training loss: 1.8943235874176025
Validation loss: 2.2702475619572464

Epoch: 5| Step: 4
Training loss: 1.9657323360443115
Validation loss: 2.287538674569899

Epoch: 5| Step: 5
Training loss: 2.1632437705993652
Validation loss: 2.296792959654203

Epoch: 5| Step: 6
Training loss: 1.7714574337005615
Validation loss: 2.295129611927976

Epoch: 5| Step: 7
Training loss: 2.7218856811523438
Validation loss: 2.291822123271163

Epoch: 5| Step: 8
Training loss: 2.272573471069336
Validation loss: 2.279215743464808

Epoch: 5| Step: 9
Training loss: 2.3320226669311523
Validation loss: 2.271358697645126

Epoch: 5| Step: 10
Training loss: 2.3076670169830322
Validation loss: 2.2668755618474816

Epoch: 327| Step: 0
Training loss: 2.760329246520996
Validation loss: 2.2638857646655013

Epoch: 5| Step: 1
Training loss: 2.1003215312957764
Validation loss: 2.264980541762485

Epoch: 5| Step: 2
Training loss: 2.455986499786377
Validation loss: 2.271508732149678

Epoch: 5| Step: 3
Training loss: 2.220463275909424
Validation loss: 2.251917172503728

Epoch: 5| Step: 4
Training loss: 1.8341362476348877
Validation loss: 2.2703054489627963

Epoch: 5| Step: 5
Training loss: 1.7862895727157593
Validation loss: 2.2782506353111676

Epoch: 5| Step: 6
Training loss: 1.5580352544784546
Validation loss: 2.287251792928224

Epoch: 5| Step: 7
Training loss: 2.519127368927002
Validation loss: 2.2894083505035727

Epoch: 5| Step: 8
Training loss: 2.826275587081909
Validation loss: 2.296820343181651

Epoch: 5| Step: 9
Training loss: 1.910220742225647
Validation loss: 2.313518606206422

Epoch: 5| Step: 10
Training loss: 2.367201328277588
Validation loss: 2.319196019121396

Epoch: 328| Step: 0
Training loss: 2.421793222427368
Validation loss: 2.322106630571427

Epoch: 5| Step: 1
Training loss: 1.6386830806732178
Validation loss: 2.30897525049025

Epoch: 5| Step: 2
Training loss: 1.8779722452163696
Validation loss: 2.303146562268657

Epoch: 5| Step: 3
Training loss: 2.525331974029541
Validation loss: 2.2919633503883117

Epoch: 5| Step: 4
Training loss: 2.367960214614868
Validation loss: 2.2972593179313083

Epoch: 5| Step: 5
Training loss: 2.198089122772217
Validation loss: 2.274908652869604

Epoch: 5| Step: 6
Training loss: 1.6597988605499268
Validation loss: 2.27488201151612

Epoch: 5| Step: 7
Training loss: 2.479468822479248
Validation loss: 2.284495266534949

Epoch: 5| Step: 8
Training loss: 1.975612998008728
Validation loss: 2.2698029625800347

Epoch: 5| Step: 9
Training loss: 3.051743745803833
Validation loss: 2.3031841362676313

Epoch: 5| Step: 10
Training loss: 2.0396740436553955
Validation loss: 2.308023783468431

Epoch: 329| Step: 0
Training loss: 1.8485265970230103
Validation loss: 2.3068166650751585

Epoch: 5| Step: 1
Training loss: 2.6529133319854736
Validation loss: 2.3067282348550777

Epoch: 5| Step: 2
Training loss: 2.4221444129943848
Validation loss: 2.3013080550778295

Epoch: 5| Step: 3
Training loss: 1.988922119140625
Validation loss: 2.2857173078803608

Epoch: 5| Step: 4
Training loss: 2.2220797538757324
Validation loss: 2.2855587261979298

Epoch: 5| Step: 5
Training loss: 2.044938325881958
Validation loss: 2.283210533921437

Epoch: 5| Step: 6
Training loss: 2.6018567085266113
Validation loss: 2.2875604526970976

Epoch: 5| Step: 7
Training loss: 2.0614254474639893
Validation loss: 2.2846749931253414

Epoch: 5| Step: 8
Training loss: 2.0915350914001465
Validation loss: 2.2665085843814317

Epoch: 5| Step: 9
Training loss: 1.7125084400177002
Validation loss: 2.273960631380799

Epoch: 5| Step: 10
Training loss: 2.6426374912261963
Validation loss: 2.266663048857002

Epoch: 330| Step: 0
Training loss: 2.1563620567321777
Validation loss: 2.260089556376139

Epoch: 5| Step: 1
Training loss: 2.1869475841522217
Validation loss: 2.255663305200556

Epoch: 5| Step: 2
Training loss: 2.083580732345581
Validation loss: 2.264817459608919

Epoch: 5| Step: 3
Training loss: 1.7833505868911743
Validation loss: 2.274356144730763

Epoch: 5| Step: 4
Training loss: 2.2595157623291016
Validation loss: 2.274095650642149

Epoch: 5| Step: 5
Training loss: 2.417555093765259
Validation loss: 2.270858656975531

Epoch: 5| Step: 6
Training loss: 2.2506418228149414
Validation loss: 2.2998433728371896

Epoch: 5| Step: 7
Training loss: 2.836155414581299
Validation loss: 2.287288773444391

Epoch: 5| Step: 8
Training loss: 1.796241044998169
Validation loss: 2.3041120524047525

Epoch: 5| Step: 9
Training loss: 1.906227469444275
Validation loss: 2.3205671874425744

Epoch: 5| Step: 10
Training loss: 2.567570924758911
Validation loss: 2.313244517131518

Epoch: 331| Step: 0
Training loss: 1.4764480590820312
Validation loss: 2.304359407835109

Epoch: 5| Step: 1
Training loss: 1.5892527103424072
Validation loss: 2.293885797582647

Epoch: 5| Step: 2
Training loss: 2.1653456687927246
Validation loss: 2.2861313102065877

Epoch: 5| Step: 3
Training loss: 2.866302728652954
Validation loss: 2.2653754398386967

Epoch: 5| Step: 4
Training loss: 2.9883873462677
Validation loss: 2.2631517661515104

Epoch: 5| Step: 5
Training loss: 2.6878275871276855
Validation loss: 2.252362129508808

Epoch: 5| Step: 6
Training loss: 2.3277335166931152
Validation loss: 2.247432694640211

Epoch: 5| Step: 7
Training loss: 2.2525250911712646
Validation loss: 2.2556242660809587

Epoch: 5| Step: 8
Training loss: 2.200713634490967
Validation loss: 2.2558488435642694

Epoch: 5| Step: 9
Training loss: 1.9516795873641968
Validation loss: 2.2474404304258284

Epoch: 5| Step: 10
Training loss: 1.6797763109207153
Validation loss: 2.2517736124736007

Epoch: 332| Step: 0
Training loss: 1.9335391521453857
Validation loss: 2.265396846238003

Epoch: 5| Step: 1
Training loss: 2.722012758255005
Validation loss: 2.273704163489803

Epoch: 5| Step: 2
Training loss: 2.615771770477295
Validation loss: 2.282860125264814

Epoch: 5| Step: 3
Training loss: 2.001981019973755
Validation loss: 2.2810876023384834

Epoch: 5| Step: 4
Training loss: 2.3309333324432373
Validation loss: 2.2938727230154057

Epoch: 5| Step: 5
Training loss: 1.8844139575958252
Validation loss: 2.2947364763547013

Epoch: 5| Step: 6
Training loss: 2.0807583332061768
Validation loss: 2.299085868302212

Epoch: 5| Step: 7
Training loss: 2.2160964012145996
Validation loss: 2.2999010509060276

Epoch: 5| Step: 8
Training loss: 2.0047214031219482
Validation loss: 2.293117448847781

Epoch: 5| Step: 9
Training loss: 2.0350098609924316
Validation loss: 2.297297339285574

Epoch: 5| Step: 10
Training loss: 2.3663582801818848
Validation loss: 2.2917959715730403

Epoch: 333| Step: 0
Training loss: 1.6526243686676025
Validation loss: 2.289776712335566

Epoch: 5| Step: 1
Training loss: 2.347855806350708
Validation loss: 2.285439475890129

Epoch: 5| Step: 2
Training loss: 1.5273020267486572
Validation loss: 2.296124642895114

Epoch: 5| Step: 3
Training loss: 2.739567995071411
Validation loss: 2.2939549594797115

Epoch: 5| Step: 4
Training loss: 1.5221514701843262
Validation loss: 2.312962406425066

Epoch: 5| Step: 5
Training loss: 2.2177257537841797
Validation loss: 2.3084385138685986

Epoch: 5| Step: 6
Training loss: 2.634077548980713
Validation loss: 2.2925776717483357

Epoch: 5| Step: 7
Training loss: 2.808772325515747
Validation loss: 2.291657463196785

Epoch: 5| Step: 8
Training loss: 2.070852279663086
Validation loss: 2.2860282287802747

Epoch: 5| Step: 9
Training loss: 2.1168861389160156
Validation loss: 2.2753712464404363

Epoch: 5| Step: 10
Training loss: 2.4872403144836426
Validation loss: 2.2745209150416876

Epoch: 334| Step: 0
Training loss: 2.2145442962646484
Validation loss: 2.2709195639497493

Epoch: 5| Step: 1
Training loss: 2.2343616485595703
Validation loss: 2.2485065370477657

Epoch: 5| Step: 2
Training loss: 2.2171285152435303
Validation loss: 2.2579510147853563

Epoch: 5| Step: 3
Training loss: 1.9249645471572876
Validation loss: 2.2595817581299813

Epoch: 5| Step: 4
Training loss: 2.480431079864502
Validation loss: 2.263900738890453

Epoch: 5| Step: 5
Training loss: 2.3472912311553955
Validation loss: 2.266693092161609

Epoch: 5| Step: 6
Training loss: 2.280733585357666
Validation loss: 2.2582671001393306

Epoch: 5| Step: 7
Training loss: 2.2061679363250732
Validation loss: 2.2627825352453415

Epoch: 5| Step: 8
Training loss: 1.696526288986206
Validation loss: 2.2678135133558706

Epoch: 5| Step: 9
Training loss: 1.9737571477890015
Validation loss: 2.2629819467503536

Epoch: 5| Step: 10
Training loss: 2.461209535598755
Validation loss: 2.279380072829544

Epoch: 335| Step: 0
Training loss: 2.3398985862731934
Validation loss: 2.2767605986646426

Epoch: 5| Step: 1
Training loss: 2.065270185470581
Validation loss: 2.2834897464321506

Epoch: 5| Step: 2
Training loss: 2.1402511596679688
Validation loss: 2.302183989555605

Epoch: 5| Step: 3
Training loss: 1.4530258178710938
Validation loss: 2.287091608970396

Epoch: 5| Step: 4
Training loss: 1.9376388788223267
Validation loss: 2.294632483554143

Epoch: 5| Step: 5
Training loss: 2.194669246673584
Validation loss: 2.2853218304213656

Epoch: 5| Step: 6
Training loss: 3.2746880054473877
Validation loss: 2.291718077915971

Epoch: 5| Step: 7
Training loss: 2.0429511070251465
Validation loss: 2.3020973154293594

Epoch: 5| Step: 8
Training loss: 2.3795485496520996
Validation loss: 2.2805290555441253

Epoch: 5| Step: 9
Training loss: 2.277470827102661
Validation loss: 2.2781008264069915

Epoch: 5| Step: 10
Training loss: 1.738928198814392
Validation loss: 2.2677504042143464

Epoch: 336| Step: 0
Training loss: 2.030378818511963
Validation loss: 2.2589809022923952

Epoch: 5| Step: 1
Training loss: 2.731886863708496
Validation loss: 2.260851485754854

Epoch: 5| Step: 2
Training loss: 2.0207409858703613
Validation loss: 2.255197168678366

Epoch: 5| Step: 3
Training loss: 2.0520293712615967
Validation loss: 2.250427522966939

Epoch: 5| Step: 4
Training loss: 1.8724696636199951
Validation loss: 2.2599651300778953

Epoch: 5| Step: 5
Training loss: 1.9480949640274048
Validation loss: 2.2573343105213617

Epoch: 5| Step: 6
Training loss: 2.8650925159454346
Validation loss: 2.268417304561984

Epoch: 5| Step: 7
Training loss: 1.9750020503997803
Validation loss: 2.2655704123999483

Epoch: 5| Step: 8
Training loss: 2.6796069145202637
Validation loss: 2.2733677612837924

Epoch: 5| Step: 9
Training loss: 1.896959900856018
Validation loss: 2.2888803392328243

Epoch: 5| Step: 10
Training loss: 1.849760890007019
Validation loss: 2.295683830015121

Epoch: 337| Step: 0
Training loss: 2.079216480255127
Validation loss: 2.3085985286261446

Epoch: 5| Step: 1
Training loss: 1.9781659841537476
Validation loss: 2.323179247558758

Epoch: 5| Step: 2
Training loss: 2.1122970581054688
Validation loss: 2.329117428871893

Epoch: 5| Step: 3
Training loss: 2.5938973426818848
Validation loss: 2.324550961935392

Epoch: 5| Step: 4
Training loss: 1.9326423406600952
Validation loss: 2.3341642874543385

Epoch: 5| Step: 5
Training loss: 2.6909661293029785
Validation loss: 2.3137753022614347

Epoch: 5| Step: 6
Training loss: 2.33225679397583
Validation loss: 2.299246975170669

Epoch: 5| Step: 7
Training loss: 1.6704826354980469
Validation loss: 2.284838999471357

Epoch: 5| Step: 8
Training loss: 2.2895171642303467
Validation loss: 2.270151730506651

Epoch: 5| Step: 9
Training loss: 2.3838014602661133
Validation loss: 2.2634683719245334

Epoch: 5| Step: 10
Training loss: 1.9626744985580444
Validation loss: 2.262895855852353

Epoch: 338| Step: 0
Training loss: 2.2135210037231445
Validation loss: 2.249184549495738

Epoch: 5| Step: 1
Training loss: 2.2520196437835693
Validation loss: 2.239182746538552

Epoch: 5| Step: 2
Training loss: 1.920220136642456
Validation loss: 2.248580168652278

Epoch: 5| Step: 3
Training loss: 2.2870585918426514
Validation loss: 2.2516849810077297

Epoch: 5| Step: 4
Training loss: 2.0700843334198
Validation loss: 2.25124038932144

Epoch: 5| Step: 5
Training loss: 1.6764453649520874
Validation loss: 2.2698865962284867

Epoch: 5| Step: 6
Training loss: 2.6023075580596924
Validation loss: 2.2878457269360943

Epoch: 5| Step: 7
Training loss: 2.6746325492858887
Validation loss: 2.2832381110037527

Epoch: 5| Step: 8
Training loss: 1.920811653137207
Validation loss: 2.289068275882352

Epoch: 5| Step: 9
Training loss: 2.607811450958252
Validation loss: 2.281528949737549

Epoch: 5| Step: 10
Training loss: 1.7057265043258667
Validation loss: 2.2652848253967943

Epoch: 339| Step: 0
Training loss: 2.4528450965881348
Validation loss: 2.272795195220619

Epoch: 5| Step: 1
Training loss: 2.139626979827881
Validation loss: 2.278793801543533

Epoch: 5| Step: 2
Training loss: 2.140495538711548
Validation loss: 2.2783611846226517

Epoch: 5| Step: 3
Training loss: 1.615726113319397
Validation loss: 2.294830646566165

Epoch: 5| Step: 4
Training loss: 2.8040080070495605
Validation loss: 2.307882011577647

Epoch: 5| Step: 5
Training loss: 2.839150905609131
Validation loss: 2.3084206658024944

Epoch: 5| Step: 6
Training loss: 2.111609935760498
Validation loss: 2.303777120446646

Epoch: 5| Step: 7
Training loss: 2.046400785446167
Validation loss: 2.318612319166942

Epoch: 5| Step: 8
Training loss: 1.9593979120254517
Validation loss: 2.2968932531213246

Epoch: 5| Step: 9
Training loss: 1.7002588510513306
Validation loss: 2.2916053918100174

Epoch: 5| Step: 10
Training loss: 2.0805201530456543
Validation loss: 2.293237099083521

Epoch: 340| Step: 0
Training loss: 2.955925464630127
Validation loss: 2.2844309294095604

Epoch: 5| Step: 1
Training loss: 2.357138156890869
Validation loss: 2.2751653207245695

Epoch: 5| Step: 2
Training loss: 1.9391216039657593
Validation loss: 2.274686339080975

Epoch: 5| Step: 3
Training loss: 1.9682365655899048
Validation loss: 2.25981145264

Epoch: 5| Step: 4
Training loss: 1.836316466331482
Validation loss: 2.2533847465310046

Epoch: 5| Step: 5
Training loss: 2.5332179069519043
Validation loss: 2.247201697800749

Epoch: 5| Step: 6
Training loss: 1.1594234704971313
Validation loss: 2.2541278639147357

Epoch: 5| Step: 7
Training loss: 2.4600062370300293
Validation loss: 2.262776441471551

Epoch: 5| Step: 8
Training loss: 1.7425636053085327
Validation loss: 2.276752580878555

Epoch: 5| Step: 9
Training loss: 2.2923800945281982
Validation loss: 2.2817557088790403

Epoch: 5| Step: 10
Training loss: 2.697813034057617
Validation loss: 2.2908915935024137

Epoch: 341| Step: 0
Training loss: 2.064362049102783
Validation loss: 2.2833807904233216

Epoch: 5| Step: 1
Training loss: 1.9118705987930298
Validation loss: 2.290981331179219

Epoch: 5| Step: 2
Training loss: 2.445894241333008
Validation loss: 2.2931684217145367

Epoch: 5| Step: 3
Training loss: 2.051149845123291
Validation loss: 2.294609110842469

Epoch: 5| Step: 4
Training loss: 2.832993268966675
Validation loss: 2.2933775096811275

Epoch: 5| Step: 5
Training loss: 1.5322288274765015
Validation loss: 2.3000847985667567

Epoch: 5| Step: 6
Training loss: 2.083350419998169
Validation loss: 2.2763506494542605

Epoch: 5| Step: 7
Training loss: 2.186415195465088
Validation loss: 2.2728633470432733

Epoch: 5| Step: 8
Training loss: 2.139650583267212
Validation loss: 2.2650011431786323

Epoch: 5| Step: 9
Training loss: 2.1423048973083496
Validation loss: 2.2542281227727092

Epoch: 5| Step: 10
Training loss: 2.323575973510742
Validation loss: 2.2548803975505214

Epoch: 342| Step: 0
Training loss: 2.087320327758789
Validation loss: 2.2547824075145106

Epoch: 5| Step: 1
Training loss: 1.701494574546814
Validation loss: 2.255829257349814

Epoch: 5| Step: 2
Training loss: 3.049682140350342
Validation loss: 2.2609689415142102

Epoch: 5| Step: 3
Training loss: 1.7203642129898071
Validation loss: 2.281595512103009

Epoch: 5| Step: 4
Training loss: 2.014251708984375
Validation loss: 2.284223956446494

Epoch: 5| Step: 5
Training loss: 2.25899076461792
Validation loss: 2.2898303308794574

Epoch: 5| Step: 6
Training loss: 2.353250741958618
Validation loss: 2.2933739833934332

Epoch: 5| Step: 7
Training loss: 2.030830144882202
Validation loss: 2.282493732308829

Epoch: 5| Step: 8
Training loss: 2.560680389404297
Validation loss: 2.270114711535874

Epoch: 5| Step: 9
Training loss: 1.7892868518829346
Validation loss: 2.260003423178068

Epoch: 5| Step: 10
Training loss: 2.20117449760437
Validation loss: 2.27712841187754

Epoch: 343| Step: 0
Training loss: 2.2425107955932617
Validation loss: 2.2727206394236577

Epoch: 5| Step: 1
Training loss: 2.4485225677490234
Validation loss: 2.2617848227100987

Epoch: 5| Step: 2
Training loss: 2.0540931224823
Validation loss: 2.2669345794185514

Epoch: 5| Step: 3
Training loss: 1.9223785400390625
Validation loss: 2.2362618036167596

Epoch: 5| Step: 4
Training loss: 1.7770360708236694
Validation loss: 2.2448526326046196

Epoch: 5| Step: 5
Training loss: 2.4363913536071777
Validation loss: 2.2511118791436635

Epoch: 5| Step: 6
Training loss: 2.3904879093170166
Validation loss: 2.251412235280519

Epoch: 5| Step: 7
Training loss: 2.3488025665283203
Validation loss: 2.263162607787758

Epoch: 5| Step: 8
Training loss: 1.9985582828521729
Validation loss: 2.276568939608912

Epoch: 5| Step: 9
Training loss: 2.228318691253662
Validation loss: 2.2754942037725963

Epoch: 5| Step: 10
Training loss: 2.0360209941864014
Validation loss: 2.2591330005276586

Epoch: 344| Step: 0
Training loss: 2.0917792320251465
Validation loss: 2.2748046331508185

Epoch: 5| Step: 1
Training loss: 2.5057294368743896
Validation loss: 2.2650817414765716

Epoch: 5| Step: 2
Training loss: 2.3632216453552246
Validation loss: 2.2785911380603747

Epoch: 5| Step: 3
Training loss: 2.8180949687957764
Validation loss: 2.28535621909685

Epoch: 5| Step: 4
Training loss: 2.1372692584991455
Validation loss: 2.2840640288527294

Epoch: 5| Step: 5
Training loss: 2.6056315898895264
Validation loss: 2.255978358689175

Epoch: 5| Step: 6
Training loss: 1.968988060951233
Validation loss: 2.2501944188148744

Epoch: 5| Step: 7
Training loss: 1.5603177547454834
Validation loss: 2.253143204155789

Epoch: 5| Step: 8
Training loss: 1.7690566778182983
Validation loss: 2.261665162219796

Epoch: 5| Step: 9
Training loss: 1.9713103771209717
Validation loss: 2.2569863770597722

Epoch: 5| Step: 10
Training loss: 1.908489465713501
Validation loss: 2.259633082215504

Epoch: 345| Step: 0
Training loss: 2.0963799953460693
Validation loss: 2.2642085193305888

Epoch: 5| Step: 1
Training loss: 2.1022744178771973
Validation loss: 2.258268328123195

Epoch: 5| Step: 2
Training loss: 1.5458043813705444
Validation loss: 2.2688819554544266

Epoch: 5| Step: 3
Training loss: 2.3069162368774414
Validation loss: 2.2649817851281937

Epoch: 5| Step: 4
Training loss: 2.3132402896881104
Validation loss: 2.2687310249574724

Epoch: 5| Step: 5
Training loss: 2.184474229812622
Validation loss: 2.2712948642751223

Epoch: 5| Step: 6
Training loss: 2.5406041145324707
Validation loss: 2.265344727423883

Epoch: 5| Step: 7
Training loss: 2.055072546005249
Validation loss: 2.262599898922828

Epoch: 5| Step: 8
Training loss: 1.6715857982635498
Validation loss: 2.2682515754494617

Epoch: 5| Step: 9
Training loss: 2.792876720428467
Validation loss: 2.266796763225268

Epoch: 5| Step: 10
Training loss: 2.0618693828582764
Validation loss: 2.2667336963838145

Epoch: 346| Step: 0
Training loss: 1.5170128345489502
Validation loss: 2.2461313304080757

Epoch: 5| Step: 1
Training loss: 2.412259340286255
Validation loss: 2.2693002941787883

Epoch: 5| Step: 2
Training loss: 2.3420445919036865
Validation loss: 2.263495647779075

Epoch: 5| Step: 3
Training loss: 2.2088704109191895
Validation loss: 2.2639938733911

Epoch: 5| Step: 4
Training loss: 2.240927219390869
Validation loss: 2.28019102158085

Epoch: 5| Step: 5
Training loss: 2.2853152751922607
Validation loss: 2.2846768620193645

Epoch: 5| Step: 6
Training loss: 2.0907249450683594
Validation loss: 2.308176140631399

Epoch: 5| Step: 7
Training loss: 2.16298508644104
Validation loss: 2.276704378025506

Epoch: 5| Step: 8
Training loss: 2.313471555709839
Validation loss: 2.2879480238883727

Epoch: 5| Step: 9
Training loss: 2.211073637008667
Validation loss: 2.272705375507314

Epoch: 5| Step: 10
Training loss: 1.8844090700149536
Validation loss: 2.248952691273023

Epoch: 347| Step: 0
Training loss: 2.5013575553894043
Validation loss: 2.232391711204283

Epoch: 5| Step: 1
Training loss: 2.717874526977539
Validation loss: 2.243588537298223

Epoch: 5| Step: 2
Training loss: 2.333200454711914
Validation loss: 2.2320315863496516

Epoch: 5| Step: 3
Training loss: 1.4812638759613037
Validation loss: 2.2400459128041423

Epoch: 5| Step: 4
Training loss: 2.1501376628875732
Validation loss: 2.236154833147603

Epoch: 5| Step: 5
Training loss: 2.138246536254883
Validation loss: 2.239610405378444

Epoch: 5| Step: 6
Training loss: 1.307664155960083
Validation loss: 2.2423843312007126

Epoch: 5| Step: 7
Training loss: 1.7121444940567017
Validation loss: 2.2604409276798205

Epoch: 5| Step: 8
Training loss: 2.6851272583007812
Validation loss: 2.262381742077489

Epoch: 5| Step: 9
Training loss: 2.052581548690796
Validation loss: 2.2767827203196864

Epoch: 5| Step: 10
Training loss: 2.618196487426758
Validation loss: 2.2958913362154396

Epoch: 348| Step: 0
Training loss: 2.109511375427246
Validation loss: 2.291722295104816

Epoch: 5| Step: 1
Training loss: 2.1731350421905518
Validation loss: 2.2836126665915213

Epoch: 5| Step: 2
Training loss: 2.849853992462158
Validation loss: 2.2692844688251452

Epoch: 5| Step: 3
Training loss: 2.023775577545166
Validation loss: 2.263024642903318

Epoch: 5| Step: 4
Training loss: 2.314906358718872
Validation loss: 2.2622082438520206

Epoch: 5| Step: 5
Training loss: 1.756593942642212
Validation loss: 2.258912306959911

Epoch: 5| Step: 6
Training loss: 2.5266332626342773
Validation loss: 2.261486445703814

Epoch: 5| Step: 7
Training loss: 2.0786349773406982
Validation loss: 2.259518366987987

Epoch: 5| Step: 8
Training loss: 1.7165111303329468
Validation loss: 2.2530728617022113

Epoch: 5| Step: 9
Training loss: 2.088906764984131
Validation loss: 2.2476240473408855

Epoch: 5| Step: 10
Training loss: 1.843325138092041
Validation loss: 2.246233396632697

Epoch: 349| Step: 0
Training loss: 2.1594185829162598
Validation loss: 2.247209507931945

Epoch: 5| Step: 1
Training loss: 2.0354671478271484
Validation loss: 2.250142620455834

Epoch: 5| Step: 2
Training loss: 2.3222012519836426
Validation loss: 2.2499922270415933

Epoch: 5| Step: 3
Training loss: 2.2738423347473145
Validation loss: 2.2520105684957197

Epoch: 5| Step: 4
Training loss: 2.0778768062591553
Validation loss: 2.251273593594951

Epoch: 5| Step: 5
Training loss: 2.4619596004486084
Validation loss: 2.2596584596941547

Epoch: 5| Step: 6
Training loss: 2.49983549118042
Validation loss: 2.2572026893656743

Epoch: 5| Step: 7
Training loss: 2.4955387115478516
Validation loss: 2.247913263177359

Epoch: 5| Step: 8
Training loss: 2.1763341426849365
Validation loss: 2.2607521241711033

Epoch: 5| Step: 9
Training loss: 1.3469244241714478
Validation loss: 2.249915840805218

Epoch: 5| Step: 10
Training loss: 1.5475964546203613
Validation loss: 2.2397349521677983

Epoch: 350| Step: 0
Training loss: 2.9410364627838135
Validation loss: 2.245175325742332

Epoch: 5| Step: 1
Training loss: 1.9404048919677734
Validation loss: 2.2493359529843895

Epoch: 5| Step: 2
Training loss: 2.6567280292510986
Validation loss: 2.2492659412404543

Epoch: 5| Step: 3
Training loss: 2.2068722248077393
Validation loss: 2.2457927580802672

Epoch: 5| Step: 4
Training loss: 1.8221534490585327
Validation loss: 2.2595563447603615

Epoch: 5| Step: 5
Training loss: 1.9108355045318604
Validation loss: 2.259163725760675

Epoch: 5| Step: 6
Training loss: 1.900350570678711
Validation loss: 2.2432554229613273

Epoch: 5| Step: 7
Training loss: 1.8866264820098877
Validation loss: 2.240115555383826

Epoch: 5| Step: 8
Training loss: 2.1932568550109863
Validation loss: 2.237554660407446

Epoch: 5| Step: 9
Training loss: 2.16133451461792
Validation loss: 2.2465889838434037

Epoch: 5| Step: 10
Training loss: 1.85780668258667
Validation loss: 2.2513510001602994

Epoch: 351| Step: 0
Training loss: 1.7945359945297241
Validation loss: 2.253393460345525

Epoch: 5| Step: 1
Training loss: 2.3466832637786865
Validation loss: 2.270330916168869

Epoch: 5| Step: 2
Training loss: 1.9822895526885986
Validation loss: 2.25724543294599

Epoch: 5| Step: 3
Training loss: 2.313488245010376
Validation loss: 2.2729638263743412

Epoch: 5| Step: 4
Training loss: 2.1655592918395996
Validation loss: 2.279808992980629

Epoch: 5| Step: 5
Training loss: 2.358778715133667
Validation loss: 2.2623674600355086

Epoch: 5| Step: 6
Training loss: 2.2794692516326904
Validation loss: 2.2521178363471903

Epoch: 5| Step: 7
Training loss: 3.013700008392334
Validation loss: 2.253286643694806

Epoch: 5| Step: 8
Training loss: 1.8493770360946655
Validation loss: 2.2387751558775544

Epoch: 5| Step: 9
Training loss: 1.912070870399475
Validation loss: 2.250953494861562

Epoch: 5| Step: 10
Training loss: 1.4478546380996704
Validation loss: 2.252742916025141

Epoch: 352| Step: 0
Training loss: 1.7878751754760742
Validation loss: 2.2499773297258603

Epoch: 5| Step: 1
Training loss: 2.313612699508667
Validation loss: 2.2486781740701325

Epoch: 5| Step: 2
Training loss: 1.8309361934661865
Validation loss: 2.2565800836009364

Epoch: 5| Step: 3
Training loss: 1.1967586278915405
Validation loss: 2.244270509289157

Epoch: 5| Step: 4
Training loss: 2.2542121410369873
Validation loss: 2.2423383215422272

Epoch: 5| Step: 5
Training loss: 2.0816445350646973
Validation loss: 2.228401727573846

Epoch: 5| Step: 6
Training loss: 2.289487600326538
Validation loss: 2.2233882334924515

Epoch: 5| Step: 7
Training loss: 3.0275747776031494
Validation loss: 2.238810057281166

Epoch: 5| Step: 8
Training loss: 1.8598740100860596
Validation loss: 2.2354100211974113

Epoch: 5| Step: 9
Training loss: 2.3314032554626465
Validation loss: 2.232282809031907

Epoch: 5| Step: 10
Training loss: 2.570841073989868
Validation loss: 2.241774297529651

Epoch: 353| Step: 0
Training loss: 1.7685444355010986
Validation loss: 2.24193327401274

Epoch: 5| Step: 1
Training loss: 2.334977865219116
Validation loss: 2.2373452878767446

Epoch: 5| Step: 2
Training loss: 2.3078079223632812
Validation loss: 2.2361418995805966

Epoch: 5| Step: 3
Training loss: 1.5388864278793335
Validation loss: 2.2607574783345705

Epoch: 5| Step: 4
Training loss: 2.624377727508545
Validation loss: 2.2535933140785462

Epoch: 5| Step: 5
Training loss: 1.756003737449646
Validation loss: 2.245214778889892

Epoch: 5| Step: 6
Training loss: 2.353317975997925
Validation loss: 2.24775589922423

Epoch: 5| Step: 7
Training loss: 2.0205318927764893
Validation loss: 2.254263160049274

Epoch: 5| Step: 8
Training loss: 2.3561489582061768
Validation loss: 2.245628603043095

Epoch: 5| Step: 9
Training loss: 1.9167476892471313
Validation loss: 2.2444917668578444

Epoch: 5| Step: 10
Training loss: 2.4557290077209473
Validation loss: 2.2468082956088486

Epoch: 354| Step: 0
Training loss: 1.7631028890609741
Validation loss: 2.2519664482403825

Epoch: 5| Step: 1
Training loss: 2.8414340019226074
Validation loss: 2.234654700884255

Epoch: 5| Step: 2
Training loss: 1.718111276626587
Validation loss: 2.2291931849654003

Epoch: 5| Step: 3
Training loss: 1.9877288341522217
Validation loss: 2.2309878051921888

Epoch: 5| Step: 4
Training loss: 2.005727767944336
Validation loss: 2.239278090897427

Epoch: 5| Step: 5
Training loss: 2.2732198238372803
Validation loss: 2.2431334423762497

Epoch: 5| Step: 6
Training loss: 1.697697401046753
Validation loss: 2.243065603317753

Epoch: 5| Step: 7
Training loss: 2.1281533241271973
Validation loss: 2.240496035545103

Epoch: 5| Step: 8
Training loss: 2.1791584491729736
Validation loss: 2.2603277570457867

Epoch: 5| Step: 9
Training loss: 2.418865919113159
Validation loss: 2.248323676406696

Epoch: 5| Step: 10
Training loss: 2.4215550422668457
Validation loss: 2.24918306514781

Epoch: 355| Step: 0
Training loss: 2.1339497566223145
Validation loss: 2.2461505218218734

Epoch: 5| Step: 1
Training loss: 1.9934806823730469
Validation loss: 2.2432833230623634

Epoch: 5| Step: 2
Training loss: 2.044219732284546
Validation loss: 2.239992682651807

Epoch: 5| Step: 3
Training loss: 2.0803823471069336
Validation loss: 2.2318961440875964

Epoch: 5| Step: 4
Training loss: 2.507772922515869
Validation loss: 2.243640561257639

Epoch: 5| Step: 5
Training loss: 1.7407608032226562
Validation loss: 2.254733072814121

Epoch: 5| Step: 6
Training loss: 1.7678674459457397
Validation loss: 2.2516499360402427

Epoch: 5| Step: 7
Training loss: 1.559399127960205
Validation loss: 2.2545576095581055

Epoch: 5| Step: 8
Training loss: 2.0208652019500732
Validation loss: 2.2507737195619972

Epoch: 5| Step: 9
Training loss: 3.1144652366638184
Validation loss: 2.2447562038257556

Epoch: 5| Step: 10
Training loss: 2.3759498596191406
Validation loss: 2.2422527420905327

Epoch: 356| Step: 0
Training loss: 2.029080867767334
Validation loss: 2.250503828448634

Epoch: 5| Step: 1
Training loss: 2.4712157249450684
Validation loss: 2.250876292105644

Epoch: 5| Step: 2
Training loss: 2.0003530979156494
Validation loss: 2.2542910268229823

Epoch: 5| Step: 3
Training loss: 2.138615131378174
Validation loss: 2.255322987033475

Epoch: 5| Step: 4
Training loss: 2.4423623085021973
Validation loss: 2.2435510517448507

Epoch: 5| Step: 5
Training loss: 2.279838800430298
Validation loss: 2.2476069517033075

Epoch: 5| Step: 6
Training loss: 1.910508394241333
Validation loss: 2.2545876323535876

Epoch: 5| Step: 7
Training loss: 2.7697384357452393
Validation loss: 2.2492002287218646

Epoch: 5| Step: 8
Training loss: 1.5657187700271606
Validation loss: 2.241212814084945

Epoch: 5| Step: 9
Training loss: 1.3119304180145264
Validation loss: 2.2423272337964786

Epoch: 5| Step: 10
Training loss: 2.4841082096099854
Validation loss: 2.2576251722151235

Epoch: 357| Step: 0
Training loss: 1.9804975986480713
Validation loss: 2.254520890533283

Epoch: 5| Step: 1
Training loss: 2.181300640106201
Validation loss: 2.2582585914160616

Epoch: 5| Step: 2
Training loss: 2.549220561981201
Validation loss: 2.234031408063827

Epoch: 5| Step: 3
Training loss: 2.0038771629333496
Validation loss: 2.242374768821142

Epoch: 5| Step: 4
Training loss: 2.9430313110351562
Validation loss: 2.232275027100758

Epoch: 5| Step: 5
Training loss: 1.7098972797393799
Validation loss: 2.225988675189275

Epoch: 5| Step: 6
Training loss: 1.6144050359725952
Validation loss: 2.22533312279691

Epoch: 5| Step: 7
Training loss: 2.319905996322632
Validation loss: 2.2381304233304915

Epoch: 5| Step: 8
Training loss: 1.9717992544174194
Validation loss: 2.236893512869394

Epoch: 5| Step: 9
Training loss: 1.6876243352890015
Validation loss: 2.250839743562924

Epoch: 5| Step: 10
Training loss: 2.3953490257263184
Validation loss: 2.2491033782241163

Epoch: 358| Step: 0
Training loss: 1.9340264797210693
Validation loss: 2.2624043905606834

Epoch: 5| Step: 1
Training loss: 1.7054201364517212
Validation loss: 2.2494214080995127

Epoch: 5| Step: 2
Training loss: 2.3586812019348145
Validation loss: 2.2647453584978656

Epoch: 5| Step: 3
Training loss: 1.862052321434021
Validation loss: 2.256337478596677

Epoch: 5| Step: 4
Training loss: 2.2251603603363037
Validation loss: 2.2698317727734967

Epoch: 5| Step: 5
Training loss: 2.1942596435546875
Validation loss: 2.249539371459715

Epoch: 5| Step: 6
Training loss: 1.6262664794921875
Validation loss: 2.234809806269984

Epoch: 5| Step: 7
Training loss: 2.8534188270568848
Validation loss: 2.241009553273519

Epoch: 5| Step: 8
Training loss: 2.401207447052002
Validation loss: 2.22337398862326

Epoch: 5| Step: 9
Training loss: 1.8211555480957031
Validation loss: 2.2128108137397358

Epoch: 5| Step: 10
Training loss: 2.2111685276031494
Validation loss: 2.226184609115765

Epoch: 359| Step: 0
Training loss: 2.473876953125
Validation loss: 2.2178069058284966

Epoch: 5| Step: 1
Training loss: 1.8648639917373657
Validation loss: 2.2344450655803887

Epoch: 5| Step: 2
Training loss: 2.1029610633850098
Validation loss: 2.22999575830275

Epoch: 5| Step: 3
Training loss: 1.785997986793518
Validation loss: 2.2248037527966242

Epoch: 5| Step: 4
Training loss: 2.6188254356384277
Validation loss: 2.245401677264962

Epoch: 5| Step: 5
Training loss: 1.3796329498291016
Validation loss: 2.2516875446483655

Epoch: 5| Step: 6
Training loss: 2.514864683151245
Validation loss: 2.257116589494931

Epoch: 5| Step: 7
Training loss: 1.579181432723999
Validation loss: 2.268832045216714

Epoch: 5| Step: 8
Training loss: 2.2160110473632812
Validation loss: 2.288060067802347

Epoch: 5| Step: 9
Training loss: 2.390866279602051
Validation loss: 2.275999689614901

Epoch: 5| Step: 10
Training loss: 2.3794026374816895
Validation loss: 2.2847533636195685

Epoch: 360| Step: 0
Training loss: 1.8410758972167969
Validation loss: 2.2706196487590833

Epoch: 5| Step: 1
Training loss: 2.3829047679901123
Validation loss: 2.2679019281941075

Epoch: 5| Step: 2
Training loss: 1.8618214130401611
Validation loss: 2.2593345770271878

Epoch: 5| Step: 3
Training loss: 2.1533703804016113
Validation loss: 2.256277243296305

Epoch: 5| Step: 4
Training loss: 1.5595051050186157
Validation loss: 2.2488537462808753

Epoch: 5| Step: 5
Training loss: 1.4957195520401
Validation loss: 2.246348060587401

Epoch: 5| Step: 6
Training loss: 2.8416221141815186
Validation loss: 2.233298296569496

Epoch: 5| Step: 7
Training loss: 1.9591861963272095
Validation loss: 2.2204999923706055

Epoch: 5| Step: 8
Training loss: 2.319336414337158
Validation loss: 2.2135783369823168

Epoch: 5| Step: 9
Training loss: 2.22701358795166
Validation loss: 2.234451581073064

Epoch: 5| Step: 10
Training loss: 2.640547037124634
Validation loss: 2.212522996369229

Epoch: 361| Step: 0
Training loss: 1.6492512226104736
Validation loss: 2.229625822395407

Epoch: 5| Step: 1
Training loss: 2.9734272956848145
Validation loss: 2.2188262452361402

Epoch: 5| Step: 2
Training loss: 1.7551323175430298
Validation loss: 2.221054789840534

Epoch: 5| Step: 3
Training loss: 1.7090097665786743
Validation loss: 2.226094735566006

Epoch: 5| Step: 4
Training loss: 2.4099783897399902
Validation loss: 2.2336290549206477

Epoch: 5| Step: 5
Training loss: 2.192380666732788
Validation loss: 2.2453708110317105

Epoch: 5| Step: 6
Training loss: 2.1047465801239014
Validation loss: 2.253213018499395

Epoch: 5| Step: 7
Training loss: 2.1113781929016113
Validation loss: 2.2535517907911733

Epoch: 5| Step: 8
Training loss: 2.1732120513916016
Validation loss: 2.2732901573181152

Epoch: 5| Step: 9
Training loss: 2.2830729484558105
Validation loss: 2.268954916666913

Epoch: 5| Step: 10
Training loss: 1.816759467124939
Validation loss: 2.2709203074055333

Epoch: 362| Step: 0
Training loss: 1.9959385395050049
Validation loss: 2.257162099243492

Epoch: 5| Step: 1
Training loss: 1.8846896886825562
Validation loss: 2.262185145449895

Epoch: 5| Step: 2
Training loss: 2.220834732055664
Validation loss: 2.253276469886944

Epoch: 5| Step: 3
Training loss: 2.3312506675720215
Validation loss: 2.2555522252154607

Epoch: 5| Step: 4
Training loss: 2.1462254524230957
Validation loss: 2.23264499889907

Epoch: 5| Step: 5
Training loss: 2.437539577484131
Validation loss: 2.2289784031529583

Epoch: 5| Step: 6
Training loss: 1.9604713916778564
Validation loss: 2.2280008536513134

Epoch: 5| Step: 7
Training loss: 1.7586790323257446
Validation loss: 2.217903765298987

Epoch: 5| Step: 8
Training loss: 2.3256359100341797
Validation loss: 2.2075416631596063

Epoch: 5| Step: 9
Training loss: 2.140981674194336
Validation loss: 2.206973152775918

Epoch: 5| Step: 10
Training loss: 1.8313485383987427
Validation loss: 2.2041887403816305

Epoch: 363| Step: 0
Training loss: 2.573598623275757
Validation loss: 2.207665494693223

Epoch: 5| Step: 1
Training loss: 1.7720798254013062
Validation loss: 2.233809441648504

Epoch: 5| Step: 2
Training loss: 2.6964175701141357
Validation loss: 2.244159285740186

Epoch: 5| Step: 3
Training loss: 1.8579883575439453
Validation loss: 2.2522382326023553

Epoch: 5| Step: 4
Training loss: 2.8342807292938232
Validation loss: 2.2471382515404814

Epoch: 5| Step: 5
Training loss: 2.0791869163513184
Validation loss: 2.246857812327723

Epoch: 5| Step: 6
Training loss: 2.908799171447754
Validation loss: 2.2571187455167054

Epoch: 5| Step: 7
Training loss: 1.7646621465682983
Validation loss: 2.2633480307876424

Epoch: 5| Step: 8
Training loss: 1.5174229145050049
Validation loss: 2.2521325157534693

Epoch: 5| Step: 9
Training loss: 1.5874038934707642
Validation loss: 2.2487942941727175

Epoch: 5| Step: 10
Training loss: 1.337464690208435
Validation loss: 2.269778308048043

Epoch: 364| Step: 0
Training loss: 2.234365463256836
Validation loss: 2.251948497628653

Epoch: 5| Step: 1
Training loss: 1.7243478298187256
Validation loss: 2.2466030274668047

Epoch: 5| Step: 2
Training loss: 2.077615261077881
Validation loss: 2.246662075801562

Epoch: 5| Step: 3
Training loss: 2.0185751914978027
Validation loss: 2.2645952945114463

Epoch: 5| Step: 4
Training loss: 1.3697757720947266
Validation loss: 2.2549531844354447

Epoch: 5| Step: 5
Training loss: 1.972115159034729
Validation loss: 2.2743358124968824

Epoch: 5| Step: 6
Training loss: 2.8051929473876953
Validation loss: 2.2584147837854203

Epoch: 5| Step: 7
Training loss: 1.9497864246368408
Validation loss: 2.247974339351859

Epoch: 5| Step: 8
Training loss: 2.3860106468200684
Validation loss: 2.2512784645121586

Epoch: 5| Step: 9
Training loss: 2.4360735416412354
Validation loss: 2.233915630207267

Epoch: 5| Step: 10
Training loss: 2.0698437690734863
Validation loss: 2.223484716107768

Epoch: 365| Step: 0
Training loss: 1.6239871978759766
Validation loss: 2.2288542280914965

Epoch: 5| Step: 1
Training loss: 1.8755576610565186
Validation loss: 2.2275305255766837

Epoch: 5| Step: 2
Training loss: 2.3399455547332764
Validation loss: 2.231282545674232

Epoch: 5| Step: 3
Training loss: 1.6390893459320068
Validation loss: 2.231609154773015

Epoch: 5| Step: 4
Training loss: 2.8173956871032715
Validation loss: 2.2276368500084005

Epoch: 5| Step: 5
Training loss: 1.604811429977417
Validation loss: 2.2523765820328907

Epoch: 5| Step: 6
Training loss: 2.589934825897217
Validation loss: 2.2575193617933538

Epoch: 5| Step: 7
Training loss: 3.072322130203247
Validation loss: 2.2473869669821953

Epoch: 5| Step: 8
Training loss: 1.5140506029129028
Validation loss: 2.269153510370562

Epoch: 5| Step: 9
Training loss: 1.549407958984375
Validation loss: 2.261079872808149

Epoch: 5| Step: 10
Training loss: 2.5680036544799805
Validation loss: 2.2498397750239216

Epoch: 366| Step: 0
Training loss: 2.063985586166382
Validation loss: 2.244116214013869

Epoch: 5| Step: 1
Training loss: 2.397331476211548
Validation loss: 2.2204738560543267

Epoch: 5| Step: 2
Training loss: 2.1086812019348145
Validation loss: 2.2191837603046047

Epoch: 5| Step: 3
Training loss: 2.073744297027588
Validation loss: 2.214520941498459

Epoch: 5| Step: 4
Training loss: 2.368731737136841
Validation loss: 2.2100488729374383

Epoch: 5| Step: 5
Training loss: 2.1101737022399902
Validation loss: 2.210055048747729

Epoch: 5| Step: 6
Training loss: 2.2559547424316406
Validation loss: 2.1997080849063013

Epoch: 5| Step: 7
Training loss: 1.4592468738555908
Validation loss: 2.1970218689210954

Epoch: 5| Step: 8
Training loss: 2.1313230991363525
Validation loss: 2.2048186768767652

Epoch: 5| Step: 9
Training loss: 2.2437493801116943
Validation loss: 2.214194505445419

Epoch: 5| Step: 10
Training loss: 1.776875615119934
Validation loss: 2.2206983258647304

Epoch: 367| Step: 0
Training loss: 2.1160168647766113
Validation loss: 2.235586771401026

Epoch: 5| Step: 1
Training loss: 1.6785072088241577
Validation loss: 2.243130950517552

Epoch: 5| Step: 2
Training loss: 2.433411121368408
Validation loss: 2.252171847128099

Epoch: 5| Step: 3
Training loss: 2.1824514865875244
Validation loss: 2.243636320996028

Epoch: 5| Step: 4
Training loss: 1.8864357471466064
Validation loss: 2.2438736654097036

Epoch: 5| Step: 5
Training loss: 1.8828270435333252
Validation loss: 2.2376613437488513

Epoch: 5| Step: 6
Training loss: 2.2849788665771484
Validation loss: 2.240793025621804

Epoch: 5| Step: 7
Training loss: 1.8855259418487549
Validation loss: 2.234271896782742

Epoch: 5| Step: 8
Training loss: 2.208617687225342
Validation loss: 2.2290521667849634

Epoch: 5| Step: 9
Training loss: 1.7830736637115479
Validation loss: 2.230251581438126

Epoch: 5| Step: 10
Training loss: 2.674124002456665
Validation loss: 2.233962725567561

Epoch: 368| Step: 0
Training loss: 2.437328338623047
Validation loss: 2.2421621481577554

Epoch: 5| Step: 1
Training loss: 2.195481777191162
Validation loss: 2.2372501845000894

Epoch: 5| Step: 2
Training loss: 2.0241222381591797
Validation loss: 2.250373899295766

Epoch: 5| Step: 3
Training loss: 1.628872275352478
Validation loss: 2.246654277206749

Epoch: 5| Step: 4
Training loss: 2.1077702045440674
Validation loss: 2.235987232577416

Epoch: 5| Step: 5
Training loss: 1.7652778625488281
Validation loss: 2.2384383857891126

Epoch: 5| Step: 6
Training loss: 2.241891384124756
Validation loss: 2.2182067594220563

Epoch: 5| Step: 7
Training loss: 2.5449626445770264
Validation loss: 2.219663079066943

Epoch: 5| Step: 8
Training loss: 1.7745187282562256
Validation loss: 2.245048722913188

Epoch: 5| Step: 9
Training loss: 1.697077989578247
Validation loss: 2.2385596101002028

Epoch: 5| Step: 10
Training loss: 2.558336019515991
Validation loss: 2.2208215190518286

Epoch: 369| Step: 0
Training loss: 1.388843297958374
Validation loss: 2.2324884194199757

Epoch: 5| Step: 1
Training loss: 2.206136703491211
Validation loss: 2.2381248679212344

Epoch: 5| Step: 2
Training loss: 2.370616912841797
Validation loss: 2.2379949426138275

Epoch: 5| Step: 3
Training loss: 3.1339879035949707
Validation loss: 2.2406820802278418

Epoch: 5| Step: 4
Training loss: 1.8387782573699951
Validation loss: 2.2304822526952273

Epoch: 5| Step: 5
Training loss: 1.9217573404312134
Validation loss: 2.2385257341528453

Epoch: 5| Step: 6
Training loss: 2.12056565284729
Validation loss: 2.218801301012757

Epoch: 5| Step: 7
Training loss: 1.8992106914520264
Validation loss: 2.2329026037646877

Epoch: 5| Step: 8
Training loss: 2.018493175506592
Validation loss: 2.234972015503914

Epoch: 5| Step: 9
Training loss: 2.2186408042907715
Validation loss: 2.243123621068975

Epoch: 5| Step: 10
Training loss: 1.6761770248413086
Validation loss: 2.2293964688495924

Epoch: 370| Step: 0
Training loss: 1.9623531103134155
Validation loss: 2.2432072521537862

Epoch: 5| Step: 1
Training loss: 2.40435528755188
Validation loss: 2.251575939116939

Epoch: 5| Step: 2
Training loss: 2.406526565551758
Validation loss: 2.2483004805862263

Epoch: 5| Step: 3
Training loss: 1.9355745315551758
Validation loss: 2.253280906267064

Epoch: 5| Step: 4
Training loss: 2.3220529556274414
Validation loss: 2.2458669549675396

Epoch: 5| Step: 5
Training loss: 2.2472779750823975
Validation loss: 2.2318593660990396

Epoch: 5| Step: 6
Training loss: 2.3683953285217285
Validation loss: 2.2341420676118586

Epoch: 5| Step: 7
Training loss: 2.172762393951416
Validation loss: 2.238630848546182

Epoch: 5| Step: 8
Training loss: 1.285259485244751
Validation loss: 2.225630401283182

Epoch: 5| Step: 9
Training loss: 1.967892050743103
Validation loss: 2.2262939150615404

Epoch: 5| Step: 10
Training loss: 1.6650539636611938
Validation loss: 2.224783883299879

Epoch: 371| Step: 0
Training loss: 2.046189069747925
Validation loss: 2.226270418013296

Epoch: 5| Step: 1
Training loss: 2.345210552215576
Validation loss: 2.22879127020477

Epoch: 5| Step: 2
Training loss: 2.295170307159424
Validation loss: 2.214833841528944

Epoch: 5| Step: 3
Training loss: 2.0971519947052
Validation loss: 2.2203242727505264

Epoch: 5| Step: 4
Training loss: 1.7337303161621094
Validation loss: 2.2253946770903883

Epoch: 5| Step: 5
Training loss: 2.1614081859588623
Validation loss: 2.2279855935804305

Epoch: 5| Step: 6
Training loss: 2.3301923274993896
Validation loss: 2.239560996332476

Epoch: 5| Step: 7
Training loss: 1.9019763469696045
Validation loss: 2.242676450360206

Epoch: 5| Step: 8
Training loss: 1.6778709888458252
Validation loss: 2.2441037034475677

Epoch: 5| Step: 9
Training loss: 2.137586832046509
Validation loss: 2.242372147498592

Epoch: 5| Step: 10
Training loss: 2.120840072631836
Validation loss: 2.2532979826773367

Epoch: 372| Step: 0
Training loss: 2.8541998863220215
Validation loss: 2.2438943206623034

Epoch: 5| Step: 1
Training loss: 2.1479218006134033
Validation loss: 2.2441664280429965

Epoch: 5| Step: 2
Training loss: 1.9224380254745483
Validation loss: 2.2419595820929414

Epoch: 5| Step: 3
Training loss: 2.0946757793426514
Validation loss: 2.225325387011292

Epoch: 5| Step: 4
Training loss: 1.8671998977661133
Validation loss: 2.2232660401252007

Epoch: 5| Step: 5
Training loss: 2.3059730529785156
Validation loss: 2.2076084793254895

Epoch: 5| Step: 6
Training loss: 2.3392415046691895
Validation loss: 2.211668437527072

Epoch: 5| Step: 7
Training loss: 1.6259256601333618
Validation loss: 2.208042557521533

Epoch: 5| Step: 8
Training loss: 1.994391679763794
Validation loss: 2.2217758599148003

Epoch: 5| Step: 9
Training loss: 1.7746607065200806
Validation loss: 2.210944370556903

Epoch: 5| Step: 10
Training loss: 1.8292441368103027
Validation loss: 2.2081733698486

Epoch: 373| Step: 0
Training loss: 2.4245409965515137
Validation loss: 2.2322124460692048

Epoch: 5| Step: 1
Training loss: 1.6009362936019897
Validation loss: 2.2441350567725395

Epoch: 5| Step: 2
Training loss: 2.3502776622772217
Validation loss: 2.2353643960850214

Epoch: 5| Step: 3
Training loss: 1.700524926185608
Validation loss: 2.2407997218511437

Epoch: 5| Step: 4
Training loss: 2.1201114654541016
Validation loss: 2.2464586688626196

Epoch: 5| Step: 5
Training loss: 2.9637980461120605
Validation loss: 2.259616680042718

Epoch: 5| Step: 6
Training loss: 2.0708096027374268
Validation loss: 2.2321901731593634

Epoch: 5| Step: 7
Training loss: 2.020824432373047
Validation loss: 2.2449322362099924

Epoch: 5| Step: 8
Training loss: 2.0712146759033203
Validation loss: 2.220724441671884

Epoch: 5| Step: 9
Training loss: 1.5480800867080688
Validation loss: 2.2106507696131223

Epoch: 5| Step: 10
Training loss: 1.9233403205871582
Validation loss: 2.2323573276560795

Epoch: 374| Step: 0
Training loss: 1.7357381582260132
Validation loss: 2.213488540341777

Epoch: 5| Step: 1
Training loss: 2.0279593467712402
Validation loss: 2.2198750408746863

Epoch: 5| Step: 2
Training loss: 2.4521899223327637
Validation loss: 2.2039070590849845

Epoch: 5| Step: 3
Training loss: 2.428131103515625
Validation loss: 2.218215902646383

Epoch: 5| Step: 4
Training loss: 1.9816566705703735
Validation loss: 2.220263763140607

Epoch: 5| Step: 5
Training loss: 2.2207534313201904
Validation loss: 2.2179265112005253

Epoch: 5| Step: 6
Training loss: 2.020461320877075
Validation loss: 2.205216400084957

Epoch: 5| Step: 7
Training loss: 2.026243209838867
Validation loss: 2.2155912178818897

Epoch: 5| Step: 8
Training loss: 2.247211456298828
Validation loss: 2.2137552333134476

Epoch: 5| Step: 9
Training loss: 2.028991460800171
Validation loss: 2.218934884635351

Epoch: 5| Step: 10
Training loss: 1.6075009107589722
Validation loss: 2.2296825480717484

Epoch: 375| Step: 0
Training loss: 2.384138822555542
Validation loss: 2.2233360864782847

Epoch: 5| Step: 1
Training loss: 2.56398344039917
Validation loss: 2.2264485000282206

Epoch: 5| Step: 2
Training loss: 1.8169606924057007
Validation loss: 2.2306524374151744

Epoch: 5| Step: 3
Training loss: 2.1538546085357666
Validation loss: 2.2326996608447005

Epoch: 5| Step: 4
Training loss: 2.182281017303467
Validation loss: 2.2378380580614974

Epoch: 5| Step: 5
Training loss: 1.9420688152313232
Validation loss: 2.260435749125737

Epoch: 5| Step: 6
Training loss: 1.8797810077667236
Validation loss: 2.265387778641075

Epoch: 5| Step: 7
Training loss: 2.182995319366455
Validation loss: 2.246096521295527

Epoch: 5| Step: 8
Training loss: 1.6956567764282227
Validation loss: 2.2271135160999913

Epoch: 5| Step: 9
Training loss: 2.263012170791626
Validation loss: 2.2139540308265278

Epoch: 5| Step: 10
Training loss: 1.6989736557006836
Validation loss: 2.2280417719194965

Epoch: 376| Step: 0
Training loss: 1.6172012090682983
Validation loss: 2.246632037624236

Epoch: 5| Step: 1
Training loss: 2.0821447372436523
Validation loss: 2.2529005158332085

Epoch: 5| Step: 2
Training loss: 2.141389846801758
Validation loss: 2.2567474662616687

Epoch: 5| Step: 3
Training loss: 2.269296407699585
Validation loss: 2.2352799318170034

Epoch: 5| Step: 4
Training loss: 2.219668388366699
Validation loss: 2.2193433136068363

Epoch: 5| Step: 5
Training loss: 1.7619918584823608
Validation loss: 2.2107065005968978

Epoch: 5| Step: 6
Training loss: 2.2644472122192383
Validation loss: 2.210233461472296

Epoch: 5| Step: 7
Training loss: 1.9332958459854126
Validation loss: 2.218015919449509

Epoch: 5| Step: 8
Training loss: 2.548074960708618
Validation loss: 2.2443012011948453

Epoch: 5| Step: 9
Training loss: 2.348679780960083
Validation loss: 2.2690887528081096

Epoch: 5| Step: 10
Training loss: 1.8157744407653809
Validation loss: 2.268318248051469

Epoch: 377| Step: 0
Training loss: 2.5424113273620605
Validation loss: 2.285325739332425

Epoch: 5| Step: 1
Training loss: 2.2699387073516846
Validation loss: 2.2580232286965973

Epoch: 5| Step: 2
Training loss: 2.3332855701446533
Validation loss: 2.2335360255292667

Epoch: 5| Step: 3
Training loss: 2.5547003746032715
Validation loss: 2.2116885441605763

Epoch: 5| Step: 4
Training loss: 1.937376618385315
Validation loss: 2.209751996942746

Epoch: 5| Step: 5
Training loss: 1.817766785621643
Validation loss: 2.215836740309192

Epoch: 5| Step: 6
Training loss: 1.8405544757843018
Validation loss: 2.2191654148922173

Epoch: 5| Step: 7
Training loss: 1.8262096643447876
Validation loss: 2.21742953408149

Epoch: 5| Step: 8
Training loss: 2.1495261192321777
Validation loss: 2.2260077973847747

Epoch: 5| Step: 9
Training loss: 1.7011616230010986
Validation loss: 2.231130499993601

Epoch: 5| Step: 10
Training loss: 1.899059772491455
Validation loss: 2.225617770225771

Epoch: 378| Step: 0
Training loss: 2.61352801322937
Validation loss: 2.2330168062640774

Epoch: 5| Step: 1
Training loss: 3.0999577045440674
Validation loss: 2.234855305763983

Epoch: 5| Step: 2
Training loss: 1.8697175979614258
Validation loss: 2.2361326243287776

Epoch: 5| Step: 3
Training loss: 1.9116442203521729
Validation loss: 2.2193847843395766

Epoch: 5| Step: 4
Training loss: 2.1975643634796143
Validation loss: 2.2257870243441675

Epoch: 5| Step: 5
Training loss: 1.1720764636993408
Validation loss: 2.2119823924956785

Epoch: 5| Step: 6
Training loss: 1.800565481185913
Validation loss: 2.2207388954777874

Epoch: 5| Step: 7
Training loss: 2.463069438934326
Validation loss: 2.2176598823198708

Epoch: 5| Step: 8
Training loss: 1.9153931140899658
Validation loss: 2.2229562164634786

Epoch: 5| Step: 9
Training loss: 1.4166309833526611
Validation loss: 2.223551099018384

Epoch: 5| Step: 10
Training loss: 2.189276695251465
Validation loss: 2.222623312345115

Epoch: 379| Step: 0
Training loss: 2.152143716812134
Validation loss: 2.2299642819230274

Epoch: 5| Step: 1
Training loss: 1.4255902767181396
Validation loss: 2.2144609856349167

Epoch: 5| Step: 2
Training loss: 1.9067833423614502
Validation loss: 2.2132825031075427

Epoch: 5| Step: 3
Training loss: 2.6043057441711426
Validation loss: 2.2184589421877297

Epoch: 5| Step: 4
Training loss: 1.9476172924041748
Validation loss: 2.2142315808162896

Epoch: 5| Step: 5
Training loss: 2.123870849609375
Validation loss: 2.2284400206740185

Epoch: 5| Step: 6
Training loss: 1.9171584844589233
Validation loss: 2.218587335719857

Epoch: 5| Step: 7
Training loss: 2.381864547729492
Validation loss: 2.2173363700989754

Epoch: 5| Step: 8
Training loss: 2.294403076171875
Validation loss: 2.2140711545944214

Epoch: 5| Step: 9
Training loss: 2.156130790710449
Validation loss: 2.2110019935074674

Epoch: 5| Step: 10
Training loss: 1.7078120708465576
Validation loss: 2.203481110193396

Epoch: 380| Step: 0
Training loss: 1.884766936302185
Validation loss: 2.207816449544763

Epoch: 5| Step: 1
Training loss: 2.008176326751709
Validation loss: 2.218131924188265

Epoch: 5| Step: 2
Training loss: 2.385544538497925
Validation loss: 2.217193388169812

Epoch: 5| Step: 3
Training loss: 1.5908358097076416
Validation loss: 2.230205858907392

Epoch: 5| Step: 4
Training loss: 2.3046836853027344
Validation loss: 2.2184212925613567

Epoch: 5| Step: 5
Training loss: 1.5358809232711792
Validation loss: 2.2184646565427064

Epoch: 5| Step: 6
Training loss: 2.437922239303589
Validation loss: 2.2289939465061313

Epoch: 5| Step: 7
Training loss: 2.4112067222595215
Validation loss: 2.241702322036989

Epoch: 5| Step: 8
Training loss: 2.2916042804718018
Validation loss: 2.2281671493284163

Epoch: 5| Step: 9
Training loss: 1.8947376012802124
Validation loss: 2.25205373507674

Epoch: 5| Step: 10
Training loss: 1.7645001411437988
Validation loss: 2.2454236681743334

Epoch: 381| Step: 0
Training loss: 1.7611720561981201
Validation loss: 2.246001584555513

Epoch: 5| Step: 1
Training loss: 1.4992835521697998
Validation loss: 2.2348233422925396

Epoch: 5| Step: 2
Training loss: 1.4765276908874512
Validation loss: 2.2146593165654007

Epoch: 5| Step: 3
Training loss: 2.3512802124023438
Validation loss: 2.2450859854298253

Epoch: 5| Step: 4
Training loss: 2.327254295349121
Validation loss: 2.2289013119154077

Epoch: 5| Step: 5
Training loss: 2.3816654682159424
Validation loss: 2.2270938991218485

Epoch: 5| Step: 6
Training loss: 2.3585610389709473
Validation loss: 2.2244280179341636

Epoch: 5| Step: 7
Training loss: 2.081312656402588
Validation loss: 2.226370483316401

Epoch: 5| Step: 8
Training loss: 2.14475154876709
Validation loss: 2.2272241141206477

Epoch: 5| Step: 9
Training loss: 1.9096282720565796
Validation loss: 2.2301486179392827

Epoch: 5| Step: 10
Training loss: 2.2062489986419678
Validation loss: 2.2196445798361175

Epoch: 382| Step: 0
Training loss: 1.8310730457305908
Validation loss: 2.2131317225835656

Epoch: 5| Step: 1
Training loss: 2.071265459060669
Validation loss: 2.2174701203582106

Epoch: 5| Step: 2
Training loss: 1.9969336986541748
Validation loss: 2.212730574351485

Epoch: 5| Step: 3
Training loss: 2.305602550506592
Validation loss: 2.2020583716771935

Epoch: 5| Step: 4
Training loss: 1.9731953144073486
Validation loss: 2.197110673432709

Epoch: 5| Step: 5
Training loss: 2.4755282402038574
Validation loss: 2.2039886033663185

Epoch: 5| Step: 6
Training loss: 1.8736343383789062
Validation loss: 2.219124274869119

Epoch: 5| Step: 7
Training loss: 2.171919345855713
Validation loss: 2.2189810686213995

Epoch: 5| Step: 8
Training loss: 2.1762213706970215
Validation loss: 2.204248138653335

Epoch: 5| Step: 9
Training loss: 1.7117595672607422
Validation loss: 2.203981599500102

Epoch: 5| Step: 10
Training loss: 1.8156778812408447
Validation loss: 2.1927513768596034

Epoch: 383| Step: 0
Training loss: 2.2943735122680664
Validation loss: 2.198457623040804

Epoch: 5| Step: 1
Training loss: 2.2538726329803467
Validation loss: 2.1951452993577525

Epoch: 5| Step: 2
Training loss: 1.654597520828247
Validation loss: 2.1887803564789476

Epoch: 5| Step: 3
Training loss: 2.1215755939483643
Validation loss: 2.189863366465415

Epoch: 5| Step: 4
Training loss: 1.858111023902893
Validation loss: 2.197931671655306

Epoch: 5| Step: 5
Training loss: 1.8250846862792969
Validation loss: 2.1948585510253906

Epoch: 5| Step: 6
Training loss: 2.0698089599609375
Validation loss: 2.1991796775530745

Epoch: 5| Step: 7
Training loss: 1.8461936712265015
Validation loss: 2.194967528825165

Epoch: 5| Step: 8
Training loss: 2.682671308517456
Validation loss: 2.2139077237857285

Epoch: 5| Step: 9
Training loss: 2.1368486881256104
Validation loss: 2.2289200290556876

Epoch: 5| Step: 10
Training loss: 1.6928515434265137
Validation loss: 2.2385494478287233

Epoch: 384| Step: 0
Training loss: 1.5088417530059814
Validation loss: 2.2579131472495293

Epoch: 5| Step: 1
Training loss: 2.0728204250335693
Validation loss: 2.2510320704470397

Epoch: 5| Step: 2
Training loss: 2.4153685569763184
Validation loss: 2.254799207051595

Epoch: 5| Step: 3
Training loss: 2.1895508766174316
Validation loss: 2.2332592984681487

Epoch: 5| Step: 4
Training loss: 2.375690460205078
Validation loss: 2.2300209896538847

Epoch: 5| Step: 5
Training loss: 1.7034084796905518
Validation loss: 2.2144446385804044

Epoch: 5| Step: 6
Training loss: 2.015883207321167
Validation loss: 2.2181877038812123

Epoch: 5| Step: 7
Training loss: 2.2018141746520996
Validation loss: 2.200844480145362

Epoch: 5| Step: 8
Training loss: 2.191066265106201
Validation loss: 2.1989425638670563

Epoch: 5| Step: 9
Training loss: 1.727813720703125
Validation loss: 2.1959838739005466

Epoch: 5| Step: 10
Training loss: 2.08090877532959
Validation loss: 2.187133550643921

Epoch: 385| Step: 0
Training loss: 2.2528433799743652
Validation loss: 2.1974421854942077

Epoch: 5| Step: 1
Training loss: 1.1921708583831787
Validation loss: 2.1980354298827467

Epoch: 5| Step: 2
Training loss: 2.1510791778564453
Validation loss: 2.199413017560077

Epoch: 5| Step: 3
Training loss: 1.749029517173767
Validation loss: 2.1922684972004225

Epoch: 5| Step: 4
Training loss: 2.4864017963409424
Validation loss: 2.200555973155524

Epoch: 5| Step: 5
Training loss: 1.9847434759140015
Validation loss: 2.2058263414649555

Epoch: 5| Step: 6
Training loss: 2.29878830909729
Validation loss: 2.200932768083388

Epoch: 5| Step: 7
Training loss: 2.1024959087371826
Validation loss: 2.2041451674635693

Epoch: 5| Step: 8
Training loss: 2.2290568351745605
Validation loss: 2.210250634019093

Epoch: 5| Step: 9
Training loss: 2.1153693199157715
Validation loss: 2.214731599694939

Epoch: 5| Step: 10
Training loss: 1.89145028591156
Validation loss: 2.2263592353431125

Epoch: 386| Step: 0
Training loss: 2.279395580291748
Validation loss: 2.221656950571204

Epoch: 5| Step: 1
Training loss: 2.179874897003174
Validation loss: 2.2084593901070217

Epoch: 5| Step: 2
Training loss: 2.2327537536621094
Validation loss: 2.224219916969217

Epoch: 5| Step: 3
Training loss: 2.380798816680908
Validation loss: 2.216676381326491

Epoch: 5| Step: 4
Training loss: 2.1269211769104004
Validation loss: 2.2132756376779206

Epoch: 5| Step: 5
Training loss: 1.1238658428192139
Validation loss: 2.225928665489279

Epoch: 5| Step: 6
Training loss: 1.794525146484375
Validation loss: 2.2092014743435766

Epoch: 5| Step: 7
Training loss: 2.396043300628662
Validation loss: 2.2157430982076995

Epoch: 5| Step: 8
Training loss: 2.326700210571289
Validation loss: 2.2165768761788645

Epoch: 5| Step: 9
Training loss: 1.7425403594970703
Validation loss: 2.2087744077046714

Epoch: 5| Step: 10
Training loss: 1.7537775039672852
Validation loss: 2.2002013344918527

Epoch: 387| Step: 0
Training loss: 2.3102316856384277
Validation loss: 2.203337743718137

Epoch: 5| Step: 1
Training loss: 1.2313580513000488
Validation loss: 2.1900718647946595

Epoch: 5| Step: 2
Training loss: 1.7727636098861694
Validation loss: 2.199053002941993

Epoch: 5| Step: 3
Training loss: 2.4311647415161133
Validation loss: 2.199528850534911

Epoch: 5| Step: 4
Training loss: 2.108182907104492
Validation loss: 2.1964154422924085

Epoch: 5| Step: 5
Training loss: 1.4337506294250488
Validation loss: 2.2043786715435725

Epoch: 5| Step: 6
Training loss: 2.310163974761963
Validation loss: 2.195002753247497

Epoch: 5| Step: 7
Training loss: 1.7462100982666016
Validation loss: 2.2077887212076495

Epoch: 5| Step: 8
Training loss: 2.2001614570617676
Validation loss: 2.2016436156406196

Epoch: 5| Step: 9
Training loss: 2.4489994049072266
Validation loss: 2.2051710646639586

Epoch: 5| Step: 10
Training loss: 2.2740018367767334
Validation loss: 2.217485556038477

Epoch: 388| Step: 0
Training loss: 2.0233232975006104
Validation loss: 2.218774866032344

Epoch: 5| Step: 1
Training loss: 1.7429167032241821
Validation loss: 2.2305087902212657

Epoch: 5| Step: 2
Training loss: 2.1403982639312744
Validation loss: 2.243549857088315

Epoch: 5| Step: 3
Training loss: 1.6978492736816406
Validation loss: 2.2492343277059574

Epoch: 5| Step: 4
Training loss: 1.7130177021026611
Validation loss: 2.2503315094978578

Epoch: 5| Step: 5
Training loss: 2.073396682739258
Validation loss: 2.2548630211942937

Epoch: 5| Step: 6
Training loss: 2.5790295600891113
Validation loss: 2.239224967136178

Epoch: 5| Step: 7
Training loss: 1.6110308170318604
Validation loss: 2.229615278141473

Epoch: 5| Step: 8
Training loss: 2.429056167602539
Validation loss: 2.2213498725686023

Epoch: 5| Step: 9
Training loss: 2.0223915576934814
Validation loss: 2.2053757149686097

Epoch: 5| Step: 10
Training loss: 2.2975850105285645
Validation loss: 2.1872621531127603

Epoch: 389| Step: 0
Training loss: 2.632974624633789
Validation loss: 2.176236039848738

Epoch: 5| Step: 1
Training loss: 2.2698397636413574
Validation loss: 2.166476639368201

Epoch: 5| Step: 2
Training loss: 2.184537887573242
Validation loss: 2.173022658594193

Epoch: 5| Step: 3
Training loss: 1.7376511096954346
Validation loss: 2.1665064057996197

Epoch: 5| Step: 4
Training loss: 2.6664061546325684
Validation loss: 2.159015242771436

Epoch: 5| Step: 5
Training loss: 1.9920628070831299
Validation loss: 2.1600027520169496

Epoch: 5| Step: 6
Training loss: 2.0892186164855957
Validation loss: 2.1609020617700394

Epoch: 5| Step: 7
Training loss: 1.5158792734146118
Validation loss: 2.181681130522041

Epoch: 5| Step: 8
Training loss: 1.8584064245224
Validation loss: 2.1888326291115052

Epoch: 5| Step: 9
Training loss: 1.9768110513687134
Validation loss: 2.197268580877653

Epoch: 5| Step: 10
Training loss: 1.432541847229004
Validation loss: 2.202309854568974

Epoch: 390| Step: 0
Training loss: 1.9768447875976562
Validation loss: 2.2024587277443177

Epoch: 5| Step: 1
Training loss: 1.8980979919433594
Validation loss: 2.231962444961712

Epoch: 5| Step: 2
Training loss: 1.6975606679916382
Validation loss: 2.2399161438788138

Epoch: 5| Step: 3
Training loss: 2.8290183544158936
Validation loss: 2.2400121329933085

Epoch: 5| Step: 4
Training loss: 1.9403951168060303
Validation loss: 2.246120286244218

Epoch: 5| Step: 5
Training loss: 2.1632590293884277
Validation loss: 2.2275642041237123

Epoch: 5| Step: 6
Training loss: 1.8477840423583984
Validation loss: 2.21195161983531

Epoch: 5| Step: 7
Training loss: 2.2873518466949463
Validation loss: 2.2095104648220922

Epoch: 5| Step: 8
Training loss: 1.9553251266479492
Validation loss: 2.1866136802140104

Epoch: 5| Step: 9
Training loss: 1.599414348602295
Validation loss: 2.185010443451584

Epoch: 5| Step: 10
Training loss: 2.096113920211792
Validation loss: 2.19634106210483

Epoch: 391| Step: 0
Training loss: 2.0692076683044434
Validation loss: 2.200163182391915

Epoch: 5| Step: 1
Training loss: 1.8001048564910889
Validation loss: 2.2039665816932597

Epoch: 5| Step: 2
Training loss: 2.061553955078125
Validation loss: 2.198555689986034

Epoch: 5| Step: 3
Training loss: 1.7430064678192139
Validation loss: 2.196351658913397

Epoch: 5| Step: 4
Training loss: 1.914743185043335
Validation loss: 2.1980283657709756

Epoch: 5| Step: 5
Training loss: 1.8266029357910156
Validation loss: 2.2144348416277158

Epoch: 5| Step: 6
Training loss: 2.072767496109009
Validation loss: 2.222271878232238

Epoch: 5| Step: 7
Training loss: 2.218170642852783
Validation loss: 2.2245610760104273

Epoch: 5| Step: 8
Training loss: 1.9488983154296875
Validation loss: 2.232780876980033

Epoch: 5| Step: 9
Training loss: 2.261345863342285
Validation loss: 2.209331795733462

Epoch: 5| Step: 10
Training loss: 2.4768383502960205
Validation loss: 2.220980813426356

Epoch: 392| Step: 0
Training loss: 2.437321186065674
Validation loss: 2.216415846219627

Epoch: 5| Step: 1
Training loss: 1.9927597045898438
Validation loss: 2.2033964818523777

Epoch: 5| Step: 2
Training loss: 1.967420220375061
Validation loss: 2.1999035830138833

Epoch: 5| Step: 3
Training loss: 1.7096754312515259
Validation loss: 2.198700620282081

Epoch: 5| Step: 4
Training loss: 1.8455709218978882
Validation loss: 2.207459721513974

Epoch: 5| Step: 5
Training loss: 2.3463997840881348
Validation loss: 2.180170223277102

Epoch: 5| Step: 6
Training loss: 2.1671669483184814
Validation loss: 2.187025923882761

Epoch: 5| Step: 7
Training loss: 1.8995212316513062
Validation loss: 2.191582182402252

Epoch: 5| Step: 8
Training loss: 1.7876085042953491
Validation loss: 2.212323646391592

Epoch: 5| Step: 9
Training loss: 1.7200219631195068
Validation loss: 2.203142523765564

Epoch: 5| Step: 10
Training loss: 2.467707633972168
Validation loss: 2.2130390085199827

Epoch: 393| Step: 0
Training loss: 1.8896446228027344
Validation loss: 2.2306955040142102

Epoch: 5| Step: 1
Training loss: 2.407217264175415
Validation loss: 2.2299650843425463

Epoch: 5| Step: 2
Training loss: 1.4132000207901
Validation loss: 2.2199219260164487

Epoch: 5| Step: 3
Training loss: 2.3658204078674316
Validation loss: 2.2126591692688646

Epoch: 5| Step: 4
Training loss: 2.149656057357788
Validation loss: 2.2232619908548172

Epoch: 5| Step: 5
Training loss: 2.34352970123291
Validation loss: 2.218620659202658

Epoch: 5| Step: 6
Training loss: 2.40989351272583
Validation loss: 2.2199105062792377

Epoch: 5| Step: 7
Training loss: 1.6686127185821533
Validation loss: 2.211427457870976

Epoch: 5| Step: 8
Training loss: 2.0689163208007812
Validation loss: 2.203391400716638

Epoch: 5| Step: 9
Training loss: 1.4341868162155151
Validation loss: 2.223850968063519

Epoch: 5| Step: 10
Training loss: 2.0103273391723633
Validation loss: 2.2173688488621868

Epoch: 394| Step: 0
Training loss: 1.441523790359497
Validation loss: 2.2042454468306674

Epoch: 5| Step: 1
Training loss: 2.5801374912261963
Validation loss: 2.2003146871443717

Epoch: 5| Step: 2
Training loss: 1.7753721475601196
Validation loss: 2.1791713724854174

Epoch: 5| Step: 3
Training loss: 1.9284718036651611
Validation loss: 2.1956870299513622

Epoch: 5| Step: 4
Training loss: 1.9699275493621826
Validation loss: 2.187236216760451

Epoch: 5| Step: 5
Training loss: 2.8797061443328857
Validation loss: 2.178467976149692

Epoch: 5| Step: 6
Training loss: 2.0178301334381104
Validation loss: 2.188008218683222

Epoch: 5| Step: 7
Training loss: 1.8188636302947998
Validation loss: 2.1945608867112028

Epoch: 5| Step: 8
Training loss: 2.181500196456909
Validation loss: 2.183885253885741

Epoch: 5| Step: 9
Training loss: 2.061870574951172
Validation loss: 2.19438688729399

Epoch: 5| Step: 10
Training loss: 1.5390182733535767
Validation loss: 2.211403677540441

Epoch: 395| Step: 0
Training loss: 1.5385706424713135
Validation loss: 2.19766306108044

Epoch: 5| Step: 1
Training loss: 1.990563988685608
Validation loss: 2.205264199164606

Epoch: 5| Step: 2
Training loss: 1.9514405727386475
Validation loss: 2.2171811288402927

Epoch: 5| Step: 3
Training loss: 2.6951332092285156
Validation loss: 2.2179879616665583

Epoch: 5| Step: 4
Training loss: 2.036864995956421
Validation loss: 2.214828516847344

Epoch: 5| Step: 5
Training loss: 2.378194808959961
Validation loss: 2.211217439302834

Epoch: 5| Step: 6
Training loss: 2.642190933227539
Validation loss: 2.2185212950552664

Epoch: 5| Step: 7
Training loss: 1.6982917785644531
Validation loss: 2.209863175628006

Epoch: 5| Step: 8
Training loss: 1.7863353490829468
Validation loss: 2.1864188204529467

Epoch: 5| Step: 9
Training loss: 1.4621661901474
Validation loss: 2.1909188455150974

Epoch: 5| Step: 10
Training loss: 1.915221929550171
Validation loss: 2.199495671897806

Epoch: 396| Step: 0
Training loss: 1.7389872074127197
Validation loss: 2.176230340875605

Epoch: 5| Step: 1
Training loss: 1.8144630193710327
Validation loss: 2.1887672819117063

Epoch: 5| Step: 2
Training loss: 1.3989852666854858
Validation loss: 2.186733703459463

Epoch: 5| Step: 3
Training loss: 2.4787909984588623
Validation loss: 2.190448785340914

Epoch: 5| Step: 4
Training loss: 2.5072104930877686
Validation loss: 2.17377628818635

Epoch: 5| Step: 5
Training loss: 2.4141006469726562
Validation loss: 2.1874904812023206

Epoch: 5| Step: 6
Training loss: 1.797263741493225
Validation loss: 2.191298005401447

Epoch: 5| Step: 7
Training loss: 1.8019046783447266
Validation loss: 2.1925631287277385

Epoch: 5| Step: 8
Training loss: 2.114781379699707
Validation loss: 2.2132598148879183

Epoch: 5| Step: 9
Training loss: 1.9040905237197876
Validation loss: 2.207820329614865

Epoch: 5| Step: 10
Training loss: 2.324718713760376
Validation loss: 2.220961739940028

Epoch: 397| Step: 0
Training loss: 1.6212352514266968
Validation loss: 2.223373520758844

Epoch: 5| Step: 1
Training loss: 1.8955615758895874
Validation loss: 2.207739148088681

Epoch: 5| Step: 2
Training loss: 1.413739800453186
Validation loss: 2.201337411839475

Epoch: 5| Step: 3
Training loss: 1.895350694656372
Validation loss: 2.1847887936458794

Epoch: 5| Step: 4
Training loss: 1.5359458923339844
Validation loss: 2.183833101744293

Epoch: 5| Step: 5
Training loss: 2.5056607723236084
Validation loss: 2.178577712787095

Epoch: 5| Step: 6
Training loss: 2.2385456562042236
Validation loss: 2.1879864931106567

Epoch: 5| Step: 7
Training loss: 1.6797161102294922
Validation loss: 2.1932721368728147

Epoch: 5| Step: 8
Training loss: 2.3904364109039307
Validation loss: 2.2093136387486614

Epoch: 5| Step: 9
Training loss: 2.3552160263061523
Validation loss: 2.2080790035186277

Epoch: 5| Step: 10
Training loss: 2.6843461990356445
Validation loss: 2.206454679530154

Epoch: 398| Step: 0
Training loss: 1.7462530136108398
Validation loss: 2.2105563866194857

Epoch: 5| Step: 1
Training loss: 1.960127592086792
Validation loss: 2.205728451410929

Epoch: 5| Step: 2
Training loss: 1.9451243877410889
Validation loss: 2.197791437948904

Epoch: 5| Step: 3
Training loss: 2.4425604343414307
Validation loss: 2.1872223897646834

Epoch: 5| Step: 4
Training loss: 2.355350971221924
Validation loss: 2.1918073213228615

Epoch: 5| Step: 5
Training loss: 1.6403398513793945
Validation loss: 2.2056258942491267

Epoch: 5| Step: 6
Training loss: 1.6324561834335327
Validation loss: 2.204708581329674

Epoch: 5| Step: 7
Training loss: 2.517240047454834
Validation loss: 2.1971270525327293

Epoch: 5| Step: 8
Training loss: 1.54026460647583
Validation loss: 2.207724722482825

Epoch: 5| Step: 9
Training loss: 2.026080846786499
Validation loss: 2.2011321462610716

Epoch: 5| Step: 10
Training loss: 2.2733047008514404
Validation loss: 2.2128608560049408

Epoch: 399| Step: 0
Training loss: 1.569839358329773
Validation loss: 2.2035520461297806

Epoch: 5| Step: 1
Training loss: 2.6806704998016357
Validation loss: 2.2195822487595263

Epoch: 5| Step: 2
Training loss: 1.6226688623428345
Validation loss: 2.2138244208469184

Epoch: 5| Step: 3
Training loss: 1.8339836597442627
Validation loss: 2.2190075151381956

Epoch: 5| Step: 4
Training loss: 1.629690408706665
Validation loss: 2.2261930563116588

Epoch: 5| Step: 5
Training loss: 2.4987404346466064
Validation loss: 2.2212066240208124

Epoch: 5| Step: 6
Training loss: 2.256460666656494
Validation loss: 2.212074702785861

Epoch: 5| Step: 7
Training loss: 2.1932497024536133
Validation loss: 2.207259028188644

Epoch: 5| Step: 8
Training loss: 2.3764424324035645
Validation loss: 2.1979159411563667

Epoch: 5| Step: 9
Training loss: 1.574526071548462
Validation loss: 2.2007903168278355

Epoch: 5| Step: 10
Training loss: 1.674932599067688
Validation loss: 2.1978138749317457

Epoch: 400| Step: 0
Training loss: 2.207932949066162
Validation loss: 2.1976075608243226

Epoch: 5| Step: 1
Training loss: 1.7092599868774414
Validation loss: 2.207963205152942

Epoch: 5| Step: 2
Training loss: 2.0222439765930176
Validation loss: 2.207957044724495

Epoch: 5| Step: 3
Training loss: 1.9259986877441406
Validation loss: 2.216183662414551

Epoch: 5| Step: 4
Training loss: 1.6232385635375977
Validation loss: 2.2250291814086256

Epoch: 5| Step: 5
Training loss: 1.9746239185333252
Validation loss: 2.2296977248243106

Epoch: 5| Step: 6
Training loss: 2.782355785369873
Validation loss: 2.2466072702920563

Epoch: 5| Step: 7
Training loss: 2.028498411178589
Validation loss: 2.221055389732443

Epoch: 5| Step: 8
Training loss: 2.041651725769043
Validation loss: 2.2157333999551754

Epoch: 5| Step: 9
Training loss: 1.5204079151153564
Validation loss: 2.2120813195423414

Epoch: 5| Step: 10
Training loss: 1.9619587659835815
Validation loss: 2.1934672529979418

Epoch: 401| Step: 0
Training loss: 1.5958402156829834
Validation loss: 2.183679525570203

Epoch: 5| Step: 1
Training loss: 2.133131504058838
Validation loss: 2.19059988503815

Epoch: 5| Step: 2
Training loss: 1.6535139083862305
Validation loss: 2.1765743814488894

Epoch: 5| Step: 3
Training loss: 1.6936872005462646
Validation loss: 2.1910311252840105

Epoch: 5| Step: 4
Training loss: 2.4521267414093018
Validation loss: 2.189542543503546

Epoch: 5| Step: 5
Training loss: 1.9903348684310913
Validation loss: 2.197867085856776

Epoch: 5| Step: 6
Training loss: 1.8572986125946045
Validation loss: 2.1923468138581965

Epoch: 5| Step: 7
Training loss: 2.3345131874084473
Validation loss: 2.198293867931571

Epoch: 5| Step: 8
Training loss: 2.359814167022705
Validation loss: 2.2070904239531486

Epoch: 5| Step: 9
Training loss: 1.6315498352050781
Validation loss: 2.220622735638772

Epoch: 5| Step: 10
Training loss: 2.1389009952545166
Validation loss: 2.2114286961094027

Epoch: 402| Step: 0
Training loss: 2.315412998199463
Validation loss: 2.2172297585395073

Epoch: 5| Step: 1
Training loss: 2.520554542541504
Validation loss: 2.211005840250241

Epoch: 5| Step: 2
Training loss: 1.3221285343170166
Validation loss: 2.213537270022977

Epoch: 5| Step: 3
Training loss: 1.9515043497085571
Validation loss: 2.2344275495057464

Epoch: 5| Step: 4
Training loss: 1.6757190227508545
Validation loss: 2.213014655215766

Epoch: 5| Step: 5
Training loss: 1.6506268978118896
Validation loss: 2.214593764274351

Epoch: 5| Step: 6
Training loss: 1.619262933731079
Validation loss: 2.182046316003287

Epoch: 5| Step: 7
Training loss: 1.639913558959961
Validation loss: 2.1856118197082193

Epoch: 5| Step: 8
Training loss: 2.9839658737182617
Validation loss: 2.19242383844109

Epoch: 5| Step: 9
Training loss: 2.4160194396972656
Validation loss: 2.1804233289534047

Epoch: 5| Step: 10
Training loss: 1.6004563570022583
Validation loss: 2.184086234338822

Epoch: 403| Step: 0
Training loss: 2.2394700050354004
Validation loss: 2.1702886089201896

Epoch: 5| Step: 1
Training loss: 2.5101521015167236
Validation loss: 2.1864086504905456

Epoch: 5| Step: 2
Training loss: 2.442979097366333
Validation loss: 2.1832267468975437

Epoch: 5| Step: 3
Training loss: 1.3072017431259155
Validation loss: 2.1906508835413123

Epoch: 5| Step: 4
Training loss: 1.7124032974243164
Validation loss: 2.1922582118741927

Epoch: 5| Step: 5
Training loss: 2.1039626598358154
Validation loss: 2.205714225769043

Epoch: 5| Step: 6
Training loss: 1.9483121633529663
Validation loss: 2.2108003657351256

Epoch: 5| Step: 7
Training loss: 1.8786580562591553
Validation loss: 2.2036835865307878

Epoch: 5| Step: 8
Training loss: 1.8040908575057983
Validation loss: 2.233054527672388

Epoch: 5| Step: 9
Training loss: 1.661291480064392
Validation loss: 2.2221196595058648

Epoch: 5| Step: 10
Training loss: 2.2142045497894287
Validation loss: 2.2201707465674287

Epoch: 404| Step: 0
Training loss: 2.037539005279541
Validation loss: 2.22350206939123

Epoch: 5| Step: 1
Training loss: 2.062810182571411
Validation loss: 2.212449594210553

Epoch: 5| Step: 2
Training loss: 1.8267494440078735
Validation loss: 2.2014631558490056

Epoch: 5| Step: 3
Training loss: 2.2300236225128174
Validation loss: 2.2013483585849887

Epoch: 5| Step: 4
Training loss: 1.5596697330474854
Validation loss: 2.208435066284672

Epoch: 5| Step: 5
Training loss: 2.009920835494995
Validation loss: 2.1784954814500708

Epoch: 5| Step: 6
Training loss: 2.1321980953216553
Validation loss: 2.1988900746068647

Epoch: 5| Step: 7
Training loss: 2.236454963684082
Validation loss: 2.18538075365046

Epoch: 5| Step: 8
Training loss: 1.6207195520401
Validation loss: 2.1837700105482534

Epoch: 5| Step: 9
Training loss: 1.8860572576522827
Validation loss: 2.1994115203939457

Epoch: 5| Step: 10
Training loss: 2.243959903717041
Validation loss: 2.2077257171753915

Epoch: 405| Step: 0
Training loss: 1.6895053386688232
Validation loss: 2.202232773585986

Epoch: 5| Step: 1
Training loss: 1.4477237462997437
Validation loss: 2.211496804350166

Epoch: 5| Step: 2
Training loss: 1.6940466165542603
Validation loss: 2.209414025788666

Epoch: 5| Step: 3
Training loss: 2.1229248046875
Validation loss: 2.2040962673002675

Epoch: 5| Step: 4
Training loss: 2.0448734760284424
Validation loss: 2.211011589214366

Epoch: 5| Step: 5
Training loss: 1.9756133556365967
Validation loss: 2.2023801278042536

Epoch: 5| Step: 6
Training loss: 2.364621639251709
Validation loss: 2.1968541452961583

Epoch: 5| Step: 7
Training loss: 2.114351511001587
Validation loss: 2.212663883803993

Epoch: 5| Step: 8
Training loss: 2.7531025409698486
Validation loss: 2.202399133354105

Epoch: 5| Step: 9
Training loss: 1.6319968700408936
Validation loss: 2.205831391837007

Epoch: 5| Step: 10
Training loss: 1.8600422143936157
Validation loss: 2.204049998714078

Epoch: 406| Step: 0
Training loss: 2.0911505222320557
Validation loss: 2.195699558463148

Epoch: 5| Step: 1
Training loss: 2.1073474884033203
Validation loss: 2.1901440735786193

Epoch: 5| Step: 2
Training loss: 1.6425930261611938
Validation loss: 2.191640374481037

Epoch: 5| Step: 3
Training loss: 1.8019558191299438
Validation loss: 2.1936778201851794

Epoch: 5| Step: 4
Training loss: 1.8938699960708618
Validation loss: 2.1806574944526917

Epoch: 5| Step: 5
Training loss: 1.668243169784546
Validation loss: 2.1777641465587

Epoch: 5| Step: 6
Training loss: 1.767650842666626
Validation loss: 2.183994641868017

Epoch: 5| Step: 7
Training loss: 2.0753188133239746
Validation loss: 2.181779143630817

Epoch: 5| Step: 8
Training loss: 2.143345355987549
Validation loss: 2.1832518833939747

Epoch: 5| Step: 9
Training loss: 1.8720409870147705
Validation loss: 2.180394131650207

Epoch: 5| Step: 10
Training loss: 2.825840950012207
Validation loss: 2.1916567433264946

Epoch: 407| Step: 0
Training loss: 2.3363261222839355
Validation loss: 2.20505646223663

Epoch: 5| Step: 1
Training loss: 1.7256942987442017
Validation loss: 2.2201330097772742

Epoch: 5| Step: 2
Training loss: 1.6488635540008545
Validation loss: 2.2274335584332867

Epoch: 5| Step: 3
Training loss: 2.0757675170898438
Validation loss: 2.219736050533992

Epoch: 5| Step: 4
Training loss: 2.2256264686584473
Validation loss: 2.229520236292193

Epoch: 5| Step: 5
Training loss: 1.5156184434890747
Validation loss: 2.220206024826214

Epoch: 5| Step: 6
Training loss: 1.8705205917358398
Validation loss: 2.240690218505039

Epoch: 5| Step: 7
Training loss: 1.5575031042099
Validation loss: 2.2305434506426574

Epoch: 5| Step: 8
Training loss: 2.307349443435669
Validation loss: 2.2245357446773077

Epoch: 5| Step: 9
Training loss: 2.5118818283081055
Validation loss: 2.2122420777556715

Epoch: 5| Step: 10
Training loss: 1.8803157806396484
Validation loss: 2.196196720164309

Epoch: 408| Step: 0
Training loss: 2.021005153656006
Validation loss: 2.1965294371369066

Epoch: 5| Step: 1
Training loss: 1.7765852212905884
Validation loss: 2.174477723336989

Epoch: 5| Step: 2
Training loss: 2.3869781494140625
Validation loss: 2.1777161910969722

Epoch: 5| Step: 3
Training loss: 2.448014736175537
Validation loss: 2.1624255052176853

Epoch: 5| Step: 4
Training loss: 2.1265673637390137
Validation loss: 2.147766013299265

Epoch: 5| Step: 5
Training loss: 1.850667953491211
Validation loss: 2.1685350479618197

Epoch: 5| Step: 6
Training loss: 1.9439218044281006
Validation loss: 2.154542310263521

Epoch: 5| Step: 7
Training loss: 1.3064520359039307
Validation loss: 2.168605996716407

Epoch: 5| Step: 8
Training loss: 1.61898934841156
Validation loss: 2.165248073557372

Epoch: 5| Step: 9
Training loss: 2.173142910003662
Validation loss: 2.168456377521638

Epoch: 5| Step: 10
Training loss: 2.163755416870117
Validation loss: 2.1912866459097913

Epoch: 409| Step: 0
Training loss: 1.5971571207046509
Validation loss: 2.2150422501307663

Epoch: 5| Step: 1
Training loss: 1.8535133600234985
Validation loss: 2.2182154629820134

Epoch: 5| Step: 2
Training loss: 2.4610400199890137
Validation loss: 2.226382770845967

Epoch: 5| Step: 3
Training loss: 2.1754136085510254
Validation loss: 2.2420431362685336

Epoch: 5| Step: 4
Training loss: 1.8986839056015015
Validation loss: 2.2264256349173923

Epoch: 5| Step: 5
Training loss: 1.4362480640411377
Validation loss: 2.217716552877939

Epoch: 5| Step: 6
Training loss: 2.1150965690612793
Validation loss: 2.220040095749722

Epoch: 5| Step: 7
Training loss: 1.9785178899765015
Validation loss: 2.1892529136391095

Epoch: 5| Step: 8
Training loss: 2.329481363296509
Validation loss: 2.17896697854483

Epoch: 5| Step: 9
Training loss: 2.0423166751861572
Validation loss: 2.166151354389806

Epoch: 5| Step: 10
Training loss: 1.7350177764892578
Validation loss: 2.1804761553323395

Epoch: 410| Step: 0
Training loss: 1.4328843355178833
Validation loss: 2.195341440939134

Epoch: 5| Step: 1
Training loss: 2.0808980464935303
Validation loss: 2.1710759273139377

Epoch: 5| Step: 2
Training loss: 1.7811933755874634
Validation loss: 2.1707305254474765

Epoch: 5| Step: 3
Training loss: 1.6650817394256592
Validation loss: 2.1668548737802813

Epoch: 5| Step: 4
Training loss: 2.1620876789093018
Validation loss: 2.1641810978612592

Epoch: 5| Step: 5
Training loss: 1.7164275646209717
Validation loss: 2.1751590108358734

Epoch: 5| Step: 6
Training loss: 1.9069998264312744
Validation loss: 2.178883942224646

Epoch: 5| Step: 7
Training loss: 1.7553752660751343
Validation loss: 2.1836108507648593

Epoch: 5| Step: 8
Training loss: 2.439218759536743
Validation loss: 2.204259326381068

Epoch: 5| Step: 9
Training loss: 2.014467716217041
Validation loss: 2.2120120397178074

Epoch: 5| Step: 10
Training loss: 2.68388295173645
Validation loss: 2.213254262042302

Epoch: 411| Step: 0
Training loss: 2.068263530731201
Validation loss: 2.1962623673100627

Epoch: 5| Step: 1
Training loss: 2.3426706790924072
Validation loss: 2.2248478704883206

Epoch: 5| Step: 2
Training loss: 2.053523063659668
Validation loss: 2.2305845470838648

Epoch: 5| Step: 3
Training loss: 2.2564167976379395
Validation loss: 2.2494171050287064

Epoch: 5| Step: 4
Training loss: 1.681941032409668
Validation loss: 2.2564304080060733

Epoch: 5| Step: 5
Training loss: 1.762495756149292
Validation loss: 2.239306237107964

Epoch: 5| Step: 6
Training loss: 1.6380996704101562
Validation loss: 2.2126084899389618

Epoch: 5| Step: 7
Training loss: 2.140441656112671
Validation loss: 2.1955150673466344

Epoch: 5| Step: 8
Training loss: 2.2010087966918945
Validation loss: 2.1827133868330266

Epoch: 5| Step: 9
Training loss: 1.6616712808609009
Validation loss: 2.1776125072151102

Epoch: 5| Step: 10
Training loss: 1.6308916807174683
Validation loss: 2.1809513773969424

Epoch: 412| Step: 0
Training loss: 2.5454890727996826
Validation loss: 2.174518233986311

Epoch: 5| Step: 1
Training loss: 1.836586356163025
Validation loss: 2.1919491624319427

Epoch: 5| Step: 2
Training loss: 1.9257171154022217
Validation loss: 2.1773969806650633

Epoch: 5| Step: 3
Training loss: 1.9107084274291992
Validation loss: 2.1918376581643217

Epoch: 5| Step: 4
Training loss: 1.9851763248443604
Validation loss: 2.1813457037812922

Epoch: 5| Step: 5
Training loss: 2.1069912910461426
Validation loss: 2.1886616740175473

Epoch: 5| Step: 6
Training loss: 1.7687575817108154
Validation loss: 2.185816667413199

Epoch: 5| Step: 7
Training loss: 1.994680404663086
Validation loss: 2.187093539904523

Epoch: 5| Step: 8
Training loss: 1.836517095565796
Validation loss: 2.1983367063665904

Epoch: 5| Step: 9
Training loss: 1.9706332683563232
Validation loss: 2.1869955114139024

Epoch: 5| Step: 10
Training loss: 1.7488315105438232
Validation loss: 2.1885770854129585

Epoch: 413| Step: 0
Training loss: 1.517081618309021
Validation loss: 2.1922344135981735

Epoch: 5| Step: 1
Training loss: 1.7259801626205444
Validation loss: 2.191001284507013

Epoch: 5| Step: 2
Training loss: 1.9836757183074951
Validation loss: 2.1994779673955773

Epoch: 5| Step: 3
Training loss: 1.8490874767303467
Validation loss: 2.2121426110626548

Epoch: 5| Step: 4
Training loss: 1.73996901512146
Validation loss: 2.211713151265216

Epoch: 5| Step: 5
Training loss: 2.266177177429199
Validation loss: 2.2336638140422043

Epoch: 5| Step: 6
Training loss: 1.8175042867660522
Validation loss: 2.2456449641976306

Epoch: 5| Step: 7
Training loss: 2.0810341835021973
Validation loss: 2.233223807427191

Epoch: 5| Step: 8
Training loss: 2.2541370391845703
Validation loss: 2.2180569043723484

Epoch: 5| Step: 9
Training loss: 2.066728353500366
Validation loss: 2.2150500410346576

Epoch: 5| Step: 10
Training loss: 2.26281476020813
Validation loss: 2.189316234280986

Epoch: 414| Step: 0
Training loss: 1.4218239784240723
Validation loss: 2.1637461646910636

Epoch: 5| Step: 1
Training loss: 2.1979527473449707
Validation loss: 2.1717031002044678

Epoch: 5| Step: 2
Training loss: 1.610314965248108
Validation loss: 2.1654946047772645

Epoch: 5| Step: 3
Training loss: 1.8425617218017578
Validation loss: 2.164967800981255

Epoch: 5| Step: 4
Training loss: 1.4883854389190674
Validation loss: 2.1719917430672595

Epoch: 5| Step: 5
Training loss: 2.278897762298584
Validation loss: 2.158701963322137

Epoch: 5| Step: 6
Training loss: 2.302231550216675
Validation loss: 2.1588966000464653

Epoch: 5| Step: 7
Training loss: 2.449066638946533
Validation loss: 2.161068762502363

Epoch: 5| Step: 8
Training loss: 1.5173884630203247
Validation loss: 2.151357138028709

Epoch: 5| Step: 9
Training loss: 2.150453567504883
Validation loss: 2.1859879211712907

Epoch: 5| Step: 10
Training loss: 2.184333562850952
Validation loss: 2.1807057857513428

Epoch: 415| Step: 0
Training loss: 1.8659673929214478
Validation loss: 2.190066809295326

Epoch: 5| Step: 1
Training loss: 1.4502737522125244
Validation loss: 2.1732851228406354

Epoch: 5| Step: 2
Training loss: 2.5401854515075684
Validation loss: 2.188081722105703

Epoch: 5| Step: 3
Training loss: 1.6153579950332642
Validation loss: 2.193495301790135

Epoch: 5| Step: 4
Training loss: 2.1725869178771973
Validation loss: 2.190162379254577

Epoch: 5| Step: 5
Training loss: 1.648903250694275
Validation loss: 2.202903768067719

Epoch: 5| Step: 6
Training loss: 2.912691116333008
Validation loss: 2.20341980841852

Epoch: 5| Step: 7
Training loss: 1.1546885967254639
Validation loss: 2.2118838448678293

Epoch: 5| Step: 8
Training loss: 2.273210048675537
Validation loss: 2.194874499433784

Epoch: 5| Step: 9
Training loss: 2.3406670093536377
Validation loss: 2.1908521472766833

Epoch: 5| Step: 10
Training loss: 1.2890005111694336
Validation loss: 2.184880002852409

Epoch: 416| Step: 0
Training loss: 1.6486084461212158
Validation loss: 2.1917886631463164

Epoch: 5| Step: 1
Training loss: 2.233856201171875
Validation loss: 2.1745612441852527

Epoch: 5| Step: 2
Training loss: 1.2683641910552979
Validation loss: 2.1849154195477887

Epoch: 5| Step: 3
Training loss: 2.427816390991211
Validation loss: 2.1889521998743855

Epoch: 5| Step: 4
Training loss: 2.1566951274871826
Validation loss: 2.184082531159924

Epoch: 5| Step: 5
Training loss: 2.1276395320892334
Validation loss: 2.183778255216537

Epoch: 5| Step: 6
Training loss: 1.2880151271820068
Validation loss: 2.1828088260466054

Epoch: 5| Step: 7
Training loss: 1.9503917694091797
Validation loss: 2.1896725470019924

Epoch: 5| Step: 8
Training loss: 1.6629937887191772
Validation loss: 2.20309680251665

Epoch: 5| Step: 9
Training loss: 1.9641835689544678
Validation loss: 2.2107279480144544

Epoch: 5| Step: 10
Training loss: 2.603935718536377
Validation loss: 2.215807448151291

Epoch: 417| Step: 0
Training loss: 1.5803896188735962
Validation loss: 2.2275555082546767

Epoch: 5| Step: 1
Training loss: 2.499239683151245
Validation loss: 2.208908522000877

Epoch: 5| Step: 2
Training loss: 1.6416038274765015
Validation loss: 2.210020403708181

Epoch: 5| Step: 3
Training loss: 2.261683702468872
Validation loss: 2.221316470894762

Epoch: 5| Step: 4
Training loss: 1.6406818628311157
Validation loss: 2.2010753616209953

Epoch: 5| Step: 5
Training loss: 1.2911946773529053
Validation loss: 2.2014670295100056

Epoch: 5| Step: 6
Training loss: 2.1029958724975586
Validation loss: 2.2012277367294475

Epoch: 5| Step: 7
Training loss: 2.1245510578155518
Validation loss: 2.1999789002121135

Epoch: 5| Step: 8
Training loss: 2.4127540588378906
Validation loss: 2.196696589069982

Epoch: 5| Step: 9
Training loss: 1.5997638702392578
Validation loss: 2.18389392411837

Epoch: 5| Step: 10
Training loss: 2.032183885574341
Validation loss: 2.18814088964975

Epoch: 418| Step: 0
Training loss: 1.391758918762207
Validation loss: 2.1800733663702525

Epoch: 5| Step: 1
Training loss: 2.8528640270233154
Validation loss: 2.1723302013130596

Epoch: 5| Step: 2
Training loss: 1.2461659908294678
Validation loss: 2.1718985572937997

Epoch: 5| Step: 3
Training loss: 1.9223439693450928
Validation loss: 2.164067828527061

Epoch: 5| Step: 4
Training loss: 1.1940345764160156
Validation loss: 2.172244429588318

Epoch: 5| Step: 5
Training loss: 2.367702007293701
Validation loss: 2.1928114634688183

Epoch: 5| Step: 6
Training loss: 2.113180160522461
Validation loss: 2.1979906661536104

Epoch: 5| Step: 7
Training loss: 2.156703472137451
Validation loss: 2.2153260092581473

Epoch: 5| Step: 8
Training loss: 2.1143672466278076
Validation loss: 2.203332334436396

Epoch: 5| Step: 9
Training loss: 1.9842617511749268
Validation loss: 2.2250788763005245

Epoch: 5| Step: 10
Training loss: 1.7342417240142822
Validation loss: 2.213177422041534

Epoch: 419| Step: 0
Training loss: 2.102605104446411
Validation loss: 2.2156706727961057

Epoch: 5| Step: 1
Training loss: 2.0961754322052
Validation loss: 2.204732071968817

Epoch: 5| Step: 2
Training loss: 2.0268101692199707
Validation loss: 2.2090795809222805

Epoch: 5| Step: 3
Training loss: 1.7648744583129883
Validation loss: 2.212214308400308

Epoch: 5| Step: 4
Training loss: 1.009773850440979
Validation loss: 2.21334522257569

Epoch: 5| Step: 5
Training loss: 2.4497151374816895
Validation loss: 2.1866318025896625

Epoch: 5| Step: 6
Training loss: 2.247457981109619
Validation loss: 2.196557793565976

Epoch: 5| Step: 7
Training loss: 2.114332675933838
Validation loss: 2.1995945515171176

Epoch: 5| Step: 8
Training loss: 1.4288591146469116
Validation loss: 2.193800918517574

Epoch: 5| Step: 9
Training loss: 1.9147971868515015
Validation loss: 2.1902806963971866

Epoch: 5| Step: 10
Training loss: 1.8960314989089966
Validation loss: 2.1941588578685636

Epoch: 420| Step: 0
Training loss: 1.5547643899917603
Validation loss: 2.182474128661617

Epoch: 5| Step: 1
Training loss: 2.474517583847046
Validation loss: 2.153481093786096

Epoch: 5| Step: 2
Training loss: 1.724238634109497
Validation loss: 2.1585350856986096

Epoch: 5| Step: 3
Training loss: 2.109145402908325
Validation loss: 2.1690909990700344

Epoch: 5| Step: 4
Training loss: 2.1015055179595947
Validation loss: 2.156029583305441

Epoch: 5| Step: 5
Training loss: 1.3888111114501953
Validation loss: 2.163647215853455

Epoch: 5| Step: 6
Training loss: 1.7883846759796143
Validation loss: 2.180611120757236

Epoch: 5| Step: 7
Training loss: 1.1091492176055908
Validation loss: 2.187689632497808

Epoch: 5| Step: 8
Training loss: 2.2885124683380127
Validation loss: 2.1962350107008413

Epoch: 5| Step: 9
Training loss: 2.707915782928467
Validation loss: 2.213215481850409

Epoch: 5| Step: 10
Training loss: 1.9249097108840942
Validation loss: 2.187330097280523

Epoch: 421| Step: 0
Training loss: 2.194040536880493
Validation loss: 2.1941025872384348

Epoch: 5| Step: 1
Training loss: 1.7952880859375
Validation loss: 2.1765398440822477

Epoch: 5| Step: 2
Training loss: 2.414543867111206
Validation loss: 2.1695361060480916

Epoch: 5| Step: 3
Training loss: 1.8341186046600342
Validation loss: 2.1701337701530865

Epoch: 5| Step: 4
Training loss: 2.2501096725463867
Validation loss: 2.185250013105331

Epoch: 5| Step: 5
Training loss: 1.2517540454864502
Validation loss: 2.1644780687106553

Epoch: 5| Step: 6
Training loss: 2.0889737606048584
Validation loss: 2.1696998278299966

Epoch: 5| Step: 7
Training loss: 1.782507300376892
Validation loss: 2.1607219275607856

Epoch: 5| Step: 8
Training loss: 2.0900607109069824
Validation loss: 2.1843231929245817

Epoch: 5| Step: 9
Training loss: 1.8937422037124634
Validation loss: 2.1774537358232724

Epoch: 5| Step: 10
Training loss: 1.3656456470489502
Validation loss: 2.194304007355885

Epoch: 422| Step: 0
Training loss: 1.879705786705017
Validation loss: 2.196067535749046

Epoch: 5| Step: 1
Training loss: 1.7840248346328735
Validation loss: 2.204921655757453

Epoch: 5| Step: 2
Training loss: 1.963293433189392
Validation loss: 2.2001058747691493

Epoch: 5| Step: 3
Training loss: 1.5340760946273804
Validation loss: 2.193345110903504

Epoch: 5| Step: 4
Training loss: 2.001122236251831
Validation loss: 2.1806246029433383

Epoch: 5| Step: 5
Training loss: 1.6336015462875366
Validation loss: 2.2060898042494252

Epoch: 5| Step: 6
Training loss: 1.9150127172470093
Validation loss: 2.200240014701761

Epoch: 5| Step: 7
Training loss: 2.0583279132843018
Validation loss: 2.231985419027267

Epoch: 5| Step: 8
Training loss: 2.0833542346954346
Validation loss: 2.2181637928050053

Epoch: 5| Step: 9
Training loss: 1.8391422033309937
Validation loss: 2.2212753359989454

Epoch: 5| Step: 10
Training loss: 2.3934199810028076
Validation loss: 2.196478646288636

Epoch: 423| Step: 0
Training loss: 1.9636539220809937
Validation loss: 2.1728477734391407

Epoch: 5| Step: 1
Training loss: 1.6043732166290283
Validation loss: 2.1504971186319985

Epoch: 5| Step: 2
Training loss: 2.0886147022247314
Validation loss: 2.135274810175742

Epoch: 5| Step: 3
Training loss: 2.3517117500305176
Validation loss: 2.1221711379225536

Epoch: 5| Step: 4
Training loss: 2.03159761428833
Validation loss: 2.124204194673928

Epoch: 5| Step: 5
Training loss: 1.3369262218475342
Validation loss: 2.111375254969443

Epoch: 5| Step: 6
Training loss: 1.6378705501556396
Validation loss: 2.1341124708934496

Epoch: 5| Step: 7
Training loss: 2.210460662841797
Validation loss: 2.1325924332423876

Epoch: 5| Step: 8
Training loss: 2.6831860542297363
Validation loss: 2.164317803998147

Epoch: 5| Step: 9
Training loss: 1.349412202835083
Validation loss: 2.1731715548423027

Epoch: 5| Step: 10
Training loss: 1.8592948913574219
Validation loss: 2.1950016944639144

Epoch: 424| Step: 0
Training loss: 1.6684787273406982
Validation loss: 2.216597813431935

Epoch: 5| Step: 1
Training loss: 2.4128260612487793
Validation loss: 2.2359793109278523

Epoch: 5| Step: 2
Training loss: 1.5013935565948486
Validation loss: 2.20699808930838

Epoch: 5| Step: 3
Training loss: 1.6885108947753906
Validation loss: 2.2208639447407057

Epoch: 5| Step: 4
Training loss: 2.0428466796875
Validation loss: 2.1958368234736945

Epoch: 5| Step: 5
Training loss: 1.5804407596588135
Validation loss: 2.16850443040171

Epoch: 5| Step: 6
Training loss: 1.86696457862854
Validation loss: 2.175503476973503

Epoch: 5| Step: 7
Training loss: 1.9236618280410767
Validation loss: 2.1726737791492092

Epoch: 5| Step: 8
Training loss: 2.597869873046875
Validation loss: 2.1837652806312806

Epoch: 5| Step: 9
Training loss: 2.074376344680786
Validation loss: 2.188350885145126

Epoch: 5| Step: 10
Training loss: 1.4891126155853271
Validation loss: 2.1791499327587824

Epoch: 425| Step: 0
Training loss: 1.4038476943969727
Validation loss: 2.1940006017684937

Epoch: 5| Step: 1
Training loss: 2.2885961532592773
Validation loss: 2.2111995809821674

Epoch: 5| Step: 2
Training loss: 2.594299793243408
Validation loss: 2.203278508237613

Epoch: 5| Step: 3
Training loss: 1.6237525939941406
Validation loss: 2.2003593778097503

Epoch: 5| Step: 4
Training loss: 2.0858216285705566
Validation loss: 2.1814005605636106

Epoch: 5| Step: 5
Training loss: 1.929510474205017
Validation loss: 2.177802772932155

Epoch: 5| Step: 6
Training loss: 1.4740968942642212
Validation loss: 2.1636771848124843

Epoch: 5| Step: 7
Training loss: 2.4993724822998047
Validation loss: 2.1732075188749578

Epoch: 5| Step: 8
Training loss: 1.3627970218658447
Validation loss: 2.170007856943274

Epoch: 5| Step: 9
Training loss: 1.810901403427124
Validation loss: 2.161659904705581

Epoch: 5| Step: 10
Training loss: 1.7195416688919067
Validation loss: 2.172176194447343

Epoch: 426| Step: 0
Training loss: 2.0354230403900146
Validation loss: 2.1814887421105498

Epoch: 5| Step: 1
Training loss: 2.145303964614868
Validation loss: 2.192167748687088

Epoch: 5| Step: 2
Training loss: 2.356085777282715
Validation loss: 2.1950258542132635

Epoch: 5| Step: 3
Training loss: 1.570892572402954
Validation loss: 2.203920559216571

Epoch: 5| Step: 4
Training loss: 2.4420711994171143
Validation loss: 2.225431888334213

Epoch: 5| Step: 5
Training loss: 2.666281223297119
Validation loss: 2.2042686490602392

Epoch: 5| Step: 6
Training loss: 1.5290815830230713
Validation loss: 2.1796999028933945

Epoch: 5| Step: 7
Training loss: 1.2841823101043701
Validation loss: 2.1614325046539307

Epoch: 5| Step: 8
Training loss: 1.4096381664276123
Validation loss: 2.1640961452197005

Epoch: 5| Step: 9
Training loss: 1.9561306238174438
Validation loss: 2.1518076850521948

Epoch: 5| Step: 10
Training loss: 1.3939447402954102
Validation loss: 2.1637576036555792

Epoch: 427| Step: 0
Training loss: 2.0509190559387207
Validation loss: 2.1434094957126084

Epoch: 5| Step: 1
Training loss: 1.0215790271759033
Validation loss: 2.1652188941996586

Epoch: 5| Step: 2
Training loss: 2.019951343536377
Validation loss: 2.186001205957064

Epoch: 5| Step: 3
Training loss: 2.054978132247925
Validation loss: 2.2117675837650093

Epoch: 5| Step: 4
Training loss: 2.0915675163269043
Validation loss: 2.2290455756648893

Epoch: 5| Step: 5
Training loss: 1.685624122619629
Validation loss: 2.2246351395883868

Epoch: 5| Step: 6
Training loss: 1.6828054189682007
Validation loss: 2.230968144632155

Epoch: 5| Step: 7
Training loss: 1.190385103225708
Validation loss: 2.2252277469122284

Epoch: 5| Step: 8
Training loss: 2.4602065086364746
Validation loss: 2.2122175590966338

Epoch: 5| Step: 9
Training loss: 2.4394593238830566
Validation loss: 2.197621545483989

Epoch: 5| Step: 10
Training loss: 2.1300182342529297
Validation loss: 2.178346005819177

Epoch: 428| Step: 0
Training loss: 1.732910394668579
Validation loss: 2.180506314000776

Epoch: 5| Step: 1
Training loss: 2.0900399684906006
Validation loss: 2.187894143084044

Epoch: 5| Step: 2
Training loss: 1.7874168157577515
Validation loss: 2.163601275413267

Epoch: 5| Step: 3
Training loss: 2.0559706687927246
Validation loss: 2.1644626279031076

Epoch: 5| Step: 4
Training loss: 1.8304202556610107
Validation loss: 2.1636841630422943

Epoch: 5| Step: 5
Training loss: 1.6959794759750366
Validation loss: 2.170499708062859

Epoch: 5| Step: 6
Training loss: 1.7724263668060303
Validation loss: 2.1656423845598773

Epoch: 5| Step: 7
Training loss: 1.7459781169891357
Validation loss: 2.188805241738596

Epoch: 5| Step: 8
Training loss: 2.55661678314209
Validation loss: 2.1955429789840535

Epoch: 5| Step: 9
Training loss: 1.6638355255126953
Validation loss: 2.188796845815515

Epoch: 5| Step: 10
Training loss: 1.9542523622512817
Validation loss: 2.1824130665871406

Epoch: 429| Step: 0
Training loss: 1.946528434753418
Validation loss: 2.182689546256937

Epoch: 5| Step: 1
Training loss: 1.6195430755615234
Validation loss: 2.1735063073455647

Epoch: 5| Step: 2
Training loss: 1.5810827016830444
Validation loss: 2.182531846466885

Epoch: 5| Step: 3
Training loss: 2.0081615447998047
Validation loss: 2.2003938869763444

Epoch: 5| Step: 4
Training loss: 2.188206672668457
Validation loss: 2.1897098300277547

Epoch: 5| Step: 5
Training loss: 1.603620171546936
Validation loss: 2.1944149053224953

Epoch: 5| Step: 6
Training loss: 2.4350452423095703
Validation loss: 2.2029834434550297

Epoch: 5| Step: 7
Training loss: 1.774190902709961
Validation loss: 2.1896791342766053

Epoch: 5| Step: 8
Training loss: 1.9154008626937866
Validation loss: 2.192289792081361

Epoch: 5| Step: 9
Training loss: 1.7760337591171265
Validation loss: 2.189401411241101

Epoch: 5| Step: 10
Training loss: 1.9021557569503784
Validation loss: 2.182510814359111

Epoch: 430| Step: 0
Training loss: 1.7975479364395142
Validation loss: 2.183222378453901

Epoch: 5| Step: 1
Training loss: 1.9706920385360718
Validation loss: 2.1904226182609476

Epoch: 5| Step: 2
Training loss: 2.6206870079040527
Validation loss: 2.165211167386783

Epoch: 5| Step: 3
Training loss: 1.896039366722107
Validation loss: 2.166722878333061

Epoch: 5| Step: 4
Training loss: 1.5664526224136353
Validation loss: 2.1591397254697737

Epoch: 5| Step: 5
Training loss: 2.0445685386657715
Validation loss: 2.173399067694141

Epoch: 5| Step: 6
Training loss: 1.804443597793579
Validation loss: 2.1846904036819295

Epoch: 5| Step: 7
Training loss: 1.6483285427093506
Validation loss: 2.1859613310906196

Epoch: 5| Step: 8
Training loss: 1.8499183654785156
Validation loss: 2.2080094609209286

Epoch: 5| Step: 9
Training loss: 2.0559656620025635
Validation loss: 2.202819247399607

Epoch: 5| Step: 10
Training loss: 1.364438533782959
Validation loss: 2.202654757807332

Epoch: 431| Step: 0
Training loss: 1.7684940099716187
Validation loss: 2.2135818414790656

Epoch: 5| Step: 1
Training loss: 1.4978752136230469
Validation loss: 2.2159599975873063

Epoch: 5| Step: 2
Training loss: 2.014801263809204
Validation loss: 2.224572277838184

Epoch: 5| Step: 3
Training loss: 2.291576385498047
Validation loss: 2.1880650315233456

Epoch: 5| Step: 4
Training loss: 2.3327879905700684
Validation loss: 2.1828120216246574

Epoch: 5| Step: 5
Training loss: 1.8394101858139038
Validation loss: 2.164763463440762

Epoch: 5| Step: 6
Training loss: 1.5676748752593994
Validation loss: 2.1476548769140757

Epoch: 5| Step: 7
Training loss: 2.156529664993286
Validation loss: 2.152439127686203

Epoch: 5| Step: 8
Training loss: 1.561287522315979
Validation loss: 2.1460818218928512

Epoch: 5| Step: 9
Training loss: 2.168755054473877
Validation loss: 2.1535335099825295

Epoch: 5| Step: 10
Training loss: 1.4066667556762695
Validation loss: 2.157687703768412

Epoch: 432| Step: 0
Training loss: 2.419513702392578
Validation loss: 2.1642083852521834

Epoch: 5| Step: 1
Training loss: 1.809203863143921
Validation loss: 2.177297637026797

Epoch: 5| Step: 2
Training loss: 2.0525238513946533
Validation loss: 2.1939586259985484

Epoch: 5| Step: 3
Training loss: 1.9318809509277344
Validation loss: 2.2037084820449993

Epoch: 5| Step: 4
Training loss: 1.4407323598861694
Validation loss: 2.221928360641644

Epoch: 5| Step: 5
Training loss: 1.9485948085784912
Validation loss: 2.195644506844141

Epoch: 5| Step: 6
Training loss: 1.9360851049423218
Validation loss: 2.1903754844460437

Epoch: 5| Step: 7
Training loss: 1.9122861623764038
Validation loss: 2.1745977119732927

Epoch: 5| Step: 8
Training loss: 1.4545742273330688
Validation loss: 2.157136747913976

Epoch: 5| Step: 9
Training loss: 1.7982028722763062
Validation loss: 2.151610456487184

Epoch: 5| Step: 10
Training loss: 1.8537715673446655
Validation loss: 2.1680138521297003

Epoch: 433| Step: 0
Training loss: 1.8907315731048584
Validation loss: 2.162153333745977

Epoch: 5| Step: 1
Training loss: 2.4350483417510986
Validation loss: 2.153247429478553

Epoch: 5| Step: 2
Training loss: 1.452449083328247
Validation loss: 2.1741755470152824

Epoch: 5| Step: 3
Training loss: 2.118506669998169
Validation loss: 2.179331410315729

Epoch: 5| Step: 4
Training loss: 1.7006183862686157
Validation loss: 2.195229258588565

Epoch: 5| Step: 5
Training loss: 2.0262138843536377
Validation loss: 2.190224616758285

Epoch: 5| Step: 6
Training loss: 1.3491475582122803
Validation loss: 2.1859599800520044

Epoch: 5| Step: 7
Training loss: 1.6143114566802979
Validation loss: 2.1890720346922516

Epoch: 5| Step: 8
Training loss: 1.8413337469100952
Validation loss: 2.195104645144555

Epoch: 5| Step: 9
Training loss: 1.9813724756240845
Validation loss: 2.193044852184993

Epoch: 5| Step: 10
Training loss: 2.0313570499420166
Validation loss: 2.183613488751073

Epoch: 434| Step: 0
Training loss: 1.6670358180999756
Validation loss: 2.1786435880968646

Epoch: 5| Step: 1
Training loss: 2.282212018966675
Validation loss: 2.1663350802595898

Epoch: 5| Step: 2
Training loss: 2.3608667850494385
Validation loss: 2.1745010550304125

Epoch: 5| Step: 3
Training loss: 1.575751543045044
Validation loss: 2.160283678321428

Epoch: 5| Step: 4
Training loss: 2.4351143836975098
Validation loss: 2.1624385182575514

Epoch: 5| Step: 5
Training loss: 1.8804829120635986
Validation loss: 2.1611977008081253

Epoch: 5| Step: 6
Training loss: 0.9426687955856323
Validation loss: 2.1645572185516357

Epoch: 5| Step: 7
Training loss: 2.1632778644561768
Validation loss: 2.1920370799238964

Epoch: 5| Step: 8
Training loss: 1.7923030853271484
Validation loss: 2.2128293539888118

Epoch: 5| Step: 9
Training loss: 1.3015345335006714
Validation loss: 2.20522871453275

Epoch: 5| Step: 10
Training loss: 2.0249550342559814
Validation loss: 2.212490189460016

Epoch: 435| Step: 0
Training loss: 1.743717908859253
Validation loss: 2.203700127140168

Epoch: 5| Step: 1
Training loss: 2.1990597248077393
Validation loss: 2.2047778688451296

Epoch: 5| Step: 2
Training loss: 1.4024591445922852
Validation loss: 2.203008564569617

Epoch: 5| Step: 3
Training loss: 1.5122803449630737
Validation loss: 2.2066331550639164

Epoch: 5| Step: 4
Training loss: 2.5990147590637207
Validation loss: 2.2052852748542704

Epoch: 5| Step: 5
Training loss: 1.4803322553634644
Validation loss: 2.189279079437256

Epoch: 5| Step: 6
Training loss: 1.8611085414886475
Validation loss: 2.1816334442425798

Epoch: 5| Step: 7
Training loss: 2.6882829666137695
Validation loss: 2.1922816884133125

Epoch: 5| Step: 8
Training loss: 1.9121730327606201
Validation loss: 2.1700202880367154

Epoch: 5| Step: 9
Training loss: 1.5750080347061157
Validation loss: 2.1636462006517636

Epoch: 5| Step: 10
Training loss: 1.2737425565719604
Validation loss: 2.142445474542597

Epoch: 436| Step: 0
Training loss: 2.0293350219726562
Validation loss: 2.1638555219096522

Epoch: 5| Step: 1
Training loss: 2.0409340858459473
Validation loss: 2.1321348733799432

Epoch: 5| Step: 2
Training loss: 1.9211139678955078
Validation loss: 2.141469220961294

Epoch: 5| Step: 3
Training loss: 1.9957386255264282
Validation loss: 2.1366110155659337

Epoch: 5| Step: 4
Training loss: 1.280983805656433
Validation loss: 2.1558746343017905

Epoch: 5| Step: 5
Training loss: 1.8300163745880127
Validation loss: 2.163208066776235

Epoch: 5| Step: 6
Training loss: 1.6365821361541748
Validation loss: 2.1718892705055977

Epoch: 5| Step: 7
Training loss: 1.8975111246109009
Validation loss: 2.197355685695525

Epoch: 5| Step: 8
Training loss: 2.340513229370117
Validation loss: 2.202990670357981

Epoch: 5| Step: 9
Training loss: 1.453118085861206
Validation loss: 2.2326523129658034

Epoch: 5| Step: 10
Training loss: 2.0521786212921143
Validation loss: 2.2327790875588693

Epoch: 437| Step: 0
Training loss: 2.2324397563934326
Validation loss: 2.2386774965511855

Epoch: 5| Step: 1
Training loss: 2.2668299674987793
Validation loss: 2.2257143758958384

Epoch: 5| Step: 2
Training loss: 2.0086894035339355
Validation loss: 2.1996657886812763

Epoch: 5| Step: 3
Training loss: 2.247253179550171
Validation loss: 2.173046076169578

Epoch: 5| Step: 4
Training loss: 1.1768630743026733
Validation loss: 2.1629338597738617

Epoch: 5| Step: 5
Training loss: 1.4946458339691162
Validation loss: 2.1433765426758797

Epoch: 5| Step: 6
Training loss: 1.860624074935913
Validation loss: 2.146156580217423

Epoch: 5| Step: 7
Training loss: 1.00606369972229
Validation loss: 2.1184884912224224

Epoch: 5| Step: 8
Training loss: 1.9056857824325562
Validation loss: 2.141752948043167

Epoch: 5| Step: 9
Training loss: 2.2125020027160645
Validation loss: 2.1404731888924875

Epoch: 5| Step: 10
Training loss: 2.0645358562469482
Validation loss: 2.163773185463362

Epoch: 438| Step: 0
Training loss: 1.9541953802108765
Validation loss: 2.1665703865789596

Epoch: 5| Step: 1
Training loss: 1.8415629863739014
Validation loss: 2.172754015973819

Epoch: 5| Step: 2
Training loss: 2.1678874492645264
Validation loss: 2.1928164228316276

Epoch: 5| Step: 3
Training loss: 1.5578563213348389
Validation loss: 2.200299855201475

Epoch: 5| Step: 4
Training loss: 1.84149169921875
Validation loss: 2.2176284072219685

Epoch: 5| Step: 5
Training loss: 2.154853105545044
Validation loss: 2.2304029721085743

Epoch: 5| Step: 6
Training loss: 1.0418133735656738
Validation loss: 2.238366542323943

Epoch: 5| Step: 7
Training loss: 2.1030819416046143
Validation loss: 2.2214278072439213

Epoch: 5| Step: 8
Training loss: 1.73821222782135
Validation loss: 2.199458158144387

Epoch: 5| Step: 9
Training loss: 2.3960375785827637
Validation loss: 2.1764940728423414

Epoch: 5| Step: 10
Training loss: 1.6057133674621582
Validation loss: 2.183764326956964

Epoch: 439| Step: 0
Training loss: 2.8273580074310303
Validation loss: 2.1569310516439457

Epoch: 5| Step: 1
Training loss: 2.1082205772399902
Validation loss: 2.1439474269907963

Epoch: 5| Step: 2
Training loss: 1.5339199304580688
Validation loss: 2.140883638012794

Epoch: 5| Step: 3
Training loss: 1.4669219255447388
Validation loss: 2.123452394239364

Epoch: 5| Step: 4
Training loss: 1.8627147674560547
Validation loss: 2.140382165549904

Epoch: 5| Step: 5
Training loss: 1.7953904867172241
Validation loss: 2.133068556426674

Epoch: 5| Step: 6
Training loss: 2.0259957313537598
Validation loss: 2.1673156343480593

Epoch: 5| Step: 7
Training loss: 2.3174262046813965
Validation loss: 2.195999567226697

Epoch: 5| Step: 8
Training loss: 1.4474527835845947
Validation loss: 2.1966208411801245

Epoch: 5| Step: 9
Training loss: 1.7055127620697021
Validation loss: 2.203673738305287

Epoch: 5| Step: 10
Training loss: 1.4553968906402588
Validation loss: 2.2217328625340618

Epoch: 440| Step: 0
Training loss: 1.667028784751892
Validation loss: 2.1974602104515157

Epoch: 5| Step: 1
Training loss: 1.5589730739593506
Validation loss: 2.202367377537553

Epoch: 5| Step: 2
Training loss: 2.1061558723449707
Validation loss: 2.1954360726059123

Epoch: 5| Step: 3
Training loss: 1.8885444402694702
Validation loss: 2.203002195204458

Epoch: 5| Step: 4
Training loss: 2.24238920211792
Validation loss: 2.1912536249365857

Epoch: 5| Step: 5
Training loss: 1.5246708393096924
Validation loss: 2.1796064966468403

Epoch: 5| Step: 6
Training loss: 1.4704506397247314
Validation loss: 2.191389735027026

Epoch: 5| Step: 7
Training loss: 2.0981361865997314
Validation loss: 2.183090176633609

Epoch: 5| Step: 8
Training loss: 1.8995662927627563
Validation loss: 2.1915199833531536

Epoch: 5| Step: 9
Training loss: 1.769150972366333
Validation loss: 2.1888209235283638

Epoch: 5| Step: 10
Training loss: 2.0273444652557373
Validation loss: 2.181274001316358

Epoch: 441| Step: 0
Training loss: 2.1257166862487793
Validation loss: 2.1743955560909805

Epoch: 5| Step: 1
Training loss: 1.9253135919570923
Validation loss: 2.144528845305084

Epoch: 5| Step: 2
Training loss: 2.3265228271484375
Validation loss: 2.1587407537685928

Epoch: 5| Step: 3
Training loss: 1.7531553506851196
Validation loss: 2.1509198219545427

Epoch: 5| Step: 4
Training loss: 1.9672672748565674
Validation loss: 2.1358259108758744

Epoch: 5| Step: 5
Training loss: 2.107445240020752
Validation loss: 2.141552884091613

Epoch: 5| Step: 6
Training loss: 1.7327969074249268
Validation loss: 2.1523992553833993

Epoch: 5| Step: 7
Training loss: 1.6288425922393799
Validation loss: 2.1452226074793006

Epoch: 5| Step: 8
Training loss: 1.677032470703125
Validation loss: 2.1367930507147186

Epoch: 5| Step: 9
Training loss: 1.291013479232788
Validation loss: 2.145222984334474

Epoch: 5| Step: 10
Training loss: 1.7035421133041382
Validation loss: 2.1619735789555374

Epoch: 442| Step: 0
Training loss: 1.2872421741485596
Validation loss: 2.1953398181546118

Epoch: 5| Step: 1
Training loss: 1.705082654953003
Validation loss: 2.2005600660077986

Epoch: 5| Step: 2
Training loss: 2.107114315032959
Validation loss: 2.201394142643098

Epoch: 5| Step: 3
Training loss: 1.4206626415252686
Validation loss: 2.205251693725586

Epoch: 5| Step: 4
Training loss: 2.0398144721984863
Validation loss: 2.178751044375922

Epoch: 5| Step: 5
Training loss: 1.683664321899414
Validation loss: 2.1784141089326594

Epoch: 5| Step: 6
Training loss: 1.750414252281189
Validation loss: 2.1664042549748577

Epoch: 5| Step: 7
Training loss: 1.6361472606658936
Validation loss: 2.176521252560359

Epoch: 5| Step: 8
Training loss: 2.172715425491333
Validation loss: 2.183422480860064

Epoch: 5| Step: 9
Training loss: 2.011669874191284
Validation loss: 2.1950953006744385

Epoch: 5| Step: 10
Training loss: 2.3789138793945312
Validation loss: 2.161192520972221

Epoch: 443| Step: 0
Training loss: 1.3652580976486206
Validation loss: 2.1826058344174455

Epoch: 5| Step: 1
Training loss: 2.003368616104126
Validation loss: 2.1949222805679485

Epoch: 5| Step: 2
Training loss: 1.8897892236709595
Validation loss: 2.171202198151619

Epoch: 5| Step: 3
Training loss: 2.4899609088897705
Validation loss: 2.1694835988424157

Epoch: 5| Step: 4
Training loss: 1.5299129486083984
Validation loss: 2.169756991888887

Epoch: 5| Step: 5
Training loss: 1.9010217189788818
Validation loss: 2.153277125409854

Epoch: 5| Step: 6
Training loss: 1.9742136001586914
Validation loss: 2.149527612552848

Epoch: 5| Step: 7
Training loss: 1.998089075088501
Validation loss: 2.1662913163503013

Epoch: 5| Step: 8
Training loss: 1.356569528579712
Validation loss: 2.1619675133817937

Epoch: 5| Step: 9
Training loss: 1.3921339511871338
Validation loss: 2.1522655256332888

Epoch: 5| Step: 10
Training loss: 2.244001626968384
Validation loss: 2.164271923803514

Epoch: 444| Step: 0
Training loss: 1.6814247369766235
Validation loss: 2.180751851809922

Epoch: 5| Step: 1
Training loss: 1.6176307201385498
Validation loss: 2.1898283740525604

Epoch: 5| Step: 2
Training loss: 2.072571277618408
Validation loss: 2.197453671886075

Epoch: 5| Step: 3
Training loss: 1.7337783575057983
Validation loss: 2.192296774156632

Epoch: 5| Step: 4
Training loss: 2.0276637077331543
Validation loss: 2.220809039249215

Epoch: 5| Step: 5
Training loss: 2.452444553375244
Validation loss: 2.1973629651531095

Epoch: 5| Step: 6
Training loss: 1.624285340309143
Validation loss: 2.2007376968219714

Epoch: 5| Step: 7
Training loss: 2.314120054244995
Validation loss: 2.192378523529217

Epoch: 5| Step: 8
Training loss: 1.5098986625671387
Validation loss: 2.169451052142728

Epoch: 5| Step: 9
Training loss: 1.7496201992034912
Validation loss: 2.197802851277013

Epoch: 5| Step: 10
Training loss: 1.311236023902893
Validation loss: 2.1748876366564023

Epoch: 445| Step: 0
Training loss: 2.4747366905212402
Validation loss: 2.152132152229227

Epoch: 5| Step: 1
Training loss: 2.0000219345092773
Validation loss: 2.1667998426704

Epoch: 5| Step: 2
Training loss: 1.5508344173431396
Validation loss: 2.1685845672443347

Epoch: 5| Step: 3
Training loss: 1.8698749542236328
Validation loss: 2.169652428678287

Epoch: 5| Step: 4
Training loss: 1.6152894496917725
Validation loss: 2.1737223466237388

Epoch: 5| Step: 5
Training loss: 1.8847182989120483
Validation loss: 2.16142415231274

Epoch: 5| Step: 6
Training loss: 1.618829369544983
Validation loss: 2.178993464798056

Epoch: 5| Step: 7
Training loss: 1.040724754333496
Validation loss: 2.1699278431553997

Epoch: 5| Step: 8
Training loss: 2.3270087242126465
Validation loss: 2.1965067181535947

Epoch: 5| Step: 9
Training loss: 1.3523364067077637
Validation loss: 2.206125638818228

Epoch: 5| Step: 10
Training loss: 2.3578622341156006
Validation loss: 2.1932585700865714

Epoch: 446| Step: 0
Training loss: 1.9663794040679932
Validation loss: 2.197588192519321

Epoch: 5| Step: 1
Training loss: 1.6270256042480469
Validation loss: 2.1904054610959944

Epoch: 5| Step: 2
Training loss: 1.46942937374115
Validation loss: 2.2063083494863203

Epoch: 5| Step: 3
Training loss: 2.036868095397949
Validation loss: 2.1916137267184514

Epoch: 5| Step: 4
Training loss: 1.2283170223236084
Validation loss: 2.1916679771997596

Epoch: 5| Step: 5
Training loss: 2.103501081466675
Validation loss: 2.1747428306969265

Epoch: 5| Step: 6
Training loss: 2.096050977706909
Validation loss: 2.1701456551910727

Epoch: 5| Step: 7
Training loss: 1.7721145153045654
Validation loss: 2.162140228415048

Epoch: 5| Step: 8
Training loss: 1.7680256366729736
Validation loss: 2.173783127979566

Epoch: 5| Step: 9
Training loss: 2.224827289581299
Validation loss: 2.1731063063426683

Epoch: 5| Step: 10
Training loss: 1.6044981479644775
Validation loss: 2.161406998993248

Epoch: 447| Step: 0
Training loss: 2.6586382389068604
Validation loss: 2.156311550448018

Epoch: 5| Step: 1
Training loss: 1.2460973262786865
Validation loss: 2.172906733328296

Epoch: 5| Step: 2
Training loss: 1.682673454284668
Validation loss: 2.1598728523459485

Epoch: 5| Step: 3
Training loss: 1.0974880456924438
Validation loss: 2.182336163777177

Epoch: 5| Step: 4
Training loss: 1.9967550039291382
Validation loss: 2.165970809998051

Epoch: 5| Step: 5
Training loss: 1.564210295677185
Validation loss: 2.1978896792216966

Epoch: 5| Step: 6
Training loss: 1.746480941772461
Validation loss: 2.20448411151927

Epoch: 5| Step: 7
Training loss: 2.070915937423706
Validation loss: 2.201507431204601

Epoch: 5| Step: 8
Training loss: 1.547755479812622
Validation loss: 2.2103269612917336

Epoch: 5| Step: 9
Training loss: 1.9611717462539673
Validation loss: 2.202643873871014

Epoch: 5| Step: 10
Training loss: 2.498295307159424
Validation loss: 2.195414249615003

Epoch: 448| Step: 0
Training loss: 1.824448585510254
Validation loss: 2.1904046266309676

Epoch: 5| Step: 1
Training loss: 1.6102783679962158
Validation loss: 2.1936053358098513

Epoch: 5| Step: 2
Training loss: 1.9634792804718018
Validation loss: 2.1856081229384228

Epoch: 5| Step: 3
Training loss: 1.580284833908081
Validation loss: 2.171341925538996

Epoch: 5| Step: 4
Training loss: 2.3564770221710205
Validation loss: 2.163288700965143

Epoch: 5| Step: 5
Training loss: 1.779863953590393
Validation loss: 2.185425253324611

Epoch: 5| Step: 6
Training loss: 2.1768691539764404
Validation loss: 2.1594844941169984

Epoch: 5| Step: 7
Training loss: 2.1437573432922363
Validation loss: 2.157522355356524

Epoch: 5| Step: 8
Training loss: 1.726766586303711
Validation loss: 2.1624242105791645

Epoch: 5| Step: 9
Training loss: 1.0062612295150757
Validation loss: 2.153402240045609

Epoch: 5| Step: 10
Training loss: 1.7566089630126953
Validation loss: 2.1698711149154173

Epoch: 449| Step: 0
Training loss: 1.2311033010482788
Validation loss: 2.1869436028183147

Epoch: 5| Step: 1
Training loss: 1.909531831741333
Validation loss: 2.198263247807821

Epoch: 5| Step: 2
Training loss: 1.7317453622817993
Validation loss: 2.1964274529487855

Epoch: 5| Step: 3
Training loss: 1.7157856225967407
Validation loss: 2.218894133003809

Epoch: 5| Step: 4
Training loss: 1.4086252450942993
Validation loss: 2.2041112248615553

Epoch: 5| Step: 5
Training loss: 2.1567139625549316
Validation loss: 2.2083990804610716

Epoch: 5| Step: 6
Training loss: 2.1463005542755127
Validation loss: 2.229476567237608

Epoch: 5| Step: 7
Training loss: 1.738274335861206
Validation loss: 2.2201570669809976

Epoch: 5| Step: 8
Training loss: 2.396496534347534
Validation loss: 2.2050096373404227

Epoch: 5| Step: 9
Training loss: 2.10308575630188
Validation loss: 2.1926645078966693

Epoch: 5| Step: 10
Training loss: 1.3530070781707764
Validation loss: 2.158530112235777

Epoch: 450| Step: 0
Training loss: 1.9359411001205444
Validation loss: 2.146914815389982

Epoch: 5| Step: 1
Training loss: 1.3928232192993164
Validation loss: 2.1555312474568686

Epoch: 5| Step: 2
Training loss: 2.0003597736358643
Validation loss: 2.128349925882073

Epoch: 5| Step: 3
Training loss: 1.4732609987258911
Validation loss: 2.1391017616436048

Epoch: 5| Step: 4
Training loss: 2.4255423545837402
Validation loss: 2.1657967234170563

Epoch: 5| Step: 5
Training loss: 2.027830123901367
Validation loss: 2.1592336085534867

Epoch: 5| Step: 6
Training loss: 1.763427495956421
Validation loss: 2.1714611284194456

Epoch: 5| Step: 7
Training loss: 1.6221210956573486
Validation loss: 2.1598750070859025

Epoch: 5| Step: 8
Training loss: 1.6560767889022827
Validation loss: 2.1783866574687343

Epoch: 5| Step: 9
Training loss: 2.1718006134033203
Validation loss: 2.1970797584902857

Epoch: 5| Step: 10
Training loss: 1.4130206108093262
Validation loss: 2.1738611011094946

Epoch: 451| Step: 0
Training loss: 1.5939395427703857
Validation loss: 2.1950971900775866

Epoch: 5| Step: 1
Training loss: 1.8866145610809326
Validation loss: 2.18286503899482

Epoch: 5| Step: 2
Training loss: 1.6634509563446045
Validation loss: 2.1852100305659796

Epoch: 5| Step: 3
Training loss: 1.763214111328125
Validation loss: 2.1694560281692015

Epoch: 5| Step: 4
Training loss: 1.9263728857040405
Validation loss: 2.1497900332173994

Epoch: 5| Step: 5
Training loss: 1.8523931503295898
Validation loss: 2.145951094165925

Epoch: 5| Step: 6
Training loss: 1.9979044198989868
Validation loss: 2.1472075882778374

Epoch: 5| Step: 7
Training loss: 1.8887832164764404
Validation loss: 2.1428893202094623

Epoch: 5| Step: 8
Training loss: 1.7003644704818726
Validation loss: 2.152623124020074

Epoch: 5| Step: 9
Training loss: 2.0150675773620605
Validation loss: 2.1609956013259066

Epoch: 5| Step: 10
Training loss: 1.547369360923767
Validation loss: 2.1605723519479074

Epoch: 452| Step: 0
Training loss: 2.105339288711548
Validation loss: 2.1779678842072845

Epoch: 5| Step: 1
Training loss: 1.9561446905136108
Validation loss: 2.1844887733459473

Epoch: 5| Step: 2
Training loss: 2.016101121902466
Validation loss: 2.184152280130694

Epoch: 5| Step: 3
Training loss: 1.0517209768295288
Validation loss: 2.1722597614411385

Epoch: 5| Step: 4
Training loss: 2.393254041671753
Validation loss: 2.1837144795284478

Epoch: 5| Step: 5
Training loss: 2.362611770629883
Validation loss: 2.1786409936925417

Epoch: 5| Step: 6
Training loss: 1.8924680948257446
Validation loss: 2.166855131426165

Epoch: 5| Step: 7
Training loss: 1.2198456525802612
Validation loss: 2.1644845970215334

Epoch: 5| Step: 8
Training loss: 1.2386250495910645
Validation loss: 2.139082912475832

Epoch: 5| Step: 9
Training loss: 1.7895843982696533
Validation loss: 2.140519683079053

Epoch: 5| Step: 10
Training loss: 1.6475239992141724
Validation loss: 2.145190376107411

Epoch: 453| Step: 0
Training loss: 1.588731288909912
Validation loss: 2.146899416882505

Epoch: 5| Step: 1
Training loss: 1.4830738306045532
Validation loss: 2.148665492252637

Epoch: 5| Step: 2
Training loss: 1.4732306003570557
Validation loss: 2.1571787044566166

Epoch: 5| Step: 3
Training loss: 1.665612816810608
Validation loss: 2.1540685469104397

Epoch: 5| Step: 4
Training loss: 2.3277764320373535
Validation loss: 2.1815456856963453

Epoch: 5| Step: 5
Training loss: 1.615459680557251
Validation loss: 2.179497929029567

Epoch: 5| Step: 6
Training loss: 2.0391523838043213
Validation loss: 2.1541644270702074

Epoch: 5| Step: 7
Training loss: 2.273240804672241
Validation loss: 2.1544589188791092

Epoch: 5| Step: 8
Training loss: 1.7504074573516846
Validation loss: 2.1691358384265693

Epoch: 5| Step: 9
Training loss: 2.2964770793914795
Validation loss: 2.151034558973005

Epoch: 5| Step: 10
Training loss: 1.3234965801239014
Validation loss: 2.157698776132317

Epoch: 454| Step: 0
Training loss: 1.597266435623169
Validation loss: 2.1608116754921536

Epoch: 5| Step: 1
Training loss: 1.9702036380767822
Validation loss: 2.139682305756436

Epoch: 5| Step: 2
Training loss: 1.4563060998916626
Validation loss: 2.1399808006901897

Epoch: 5| Step: 3
Training loss: 1.8232685327529907
Validation loss: 2.145756531787175

Epoch: 5| Step: 4
Training loss: 1.3746318817138672
Validation loss: 2.1552865274490847

Epoch: 5| Step: 5
Training loss: 1.8074220418930054
Validation loss: 2.1643898012817546

Epoch: 5| Step: 6
Training loss: 2.290877103805542
Validation loss: 2.1717934095731346

Epoch: 5| Step: 7
Training loss: 2.093031167984009
Validation loss: 2.173445165798228

Epoch: 5| Step: 8
Training loss: 1.5541818141937256
Validation loss: 2.1679807375836115

Epoch: 5| Step: 9
Training loss: 1.8758049011230469
Validation loss: 2.176592078260196

Epoch: 5| Step: 10
Training loss: 1.9845800399780273
Validation loss: 2.1675041208985033

Epoch: 455| Step: 0
Training loss: 1.9102115631103516
Validation loss: 2.1548514981423654

Epoch: 5| Step: 1
Training loss: 2.4031853675842285
Validation loss: 2.179773284542945

Epoch: 5| Step: 2
Training loss: 1.6481475830078125
Validation loss: 2.1639532889089277

Epoch: 5| Step: 3
Training loss: 1.5580356121063232
Validation loss: 2.14303373136828

Epoch: 5| Step: 4
Training loss: 1.3910189867019653
Validation loss: 2.1550886233647666

Epoch: 5| Step: 5
Training loss: 2.1782732009887695
Validation loss: 2.146301789950299

Epoch: 5| Step: 6
Training loss: 1.9921680688858032
Validation loss: 2.148438057591838

Epoch: 5| Step: 7
Training loss: 1.2521599531173706
Validation loss: 2.148864810184766

Epoch: 5| Step: 8
Training loss: 2.145887613296509
Validation loss: 2.1428085193839124

Epoch: 5| Step: 9
Training loss: 1.5820835828781128
Validation loss: 2.1447017064658542

Epoch: 5| Step: 10
Training loss: 1.985926628112793
Validation loss: 2.161945004617014

Epoch: 456| Step: 0
Training loss: 1.4588922262191772
Validation loss: 2.149491469065348

Epoch: 5| Step: 1
Training loss: 1.2394249439239502
Validation loss: 2.155384930231238

Epoch: 5| Step: 2
Training loss: 1.7195926904678345
Validation loss: 2.1708156216529106

Epoch: 5| Step: 3
Training loss: 2.0093326568603516
Validation loss: 2.1880541181051605

Epoch: 5| Step: 4
Training loss: 1.6135810613632202
Validation loss: 2.198538427711815

Epoch: 5| Step: 5
Training loss: 2.136777877807617
Validation loss: 2.196194843579364

Epoch: 5| Step: 6
Training loss: 2.5214626789093018
Validation loss: 2.2086978086861233

Epoch: 5| Step: 7
Training loss: 1.375511884689331
Validation loss: 2.2158242220519693

Epoch: 5| Step: 8
Training loss: 1.7356210947036743
Validation loss: 2.1987352704489105

Epoch: 5| Step: 9
Training loss: 1.8893429040908813
Validation loss: 2.1775112408463673

Epoch: 5| Step: 10
Training loss: 2.1266231536865234
Validation loss: 2.1512142509542485

Epoch: 457| Step: 0
Training loss: 1.7207744121551514
Validation loss: 2.1394983363407913

Epoch: 5| Step: 1
Training loss: 2.0139083862304688
Validation loss: 2.1330998764243176

Epoch: 5| Step: 2
Training loss: 1.5130605697631836
Validation loss: 2.1309262373114146

Epoch: 5| Step: 3
Training loss: 1.681117057800293
Validation loss: 2.1351286800958778

Epoch: 5| Step: 4
Training loss: 2.054109573364258
Validation loss: 2.1191265454856296

Epoch: 5| Step: 5
Training loss: 1.4296443462371826
Validation loss: 2.1392883793000252

Epoch: 5| Step: 6
Training loss: 1.8494536876678467
Validation loss: 2.1368621613389704

Epoch: 5| Step: 7
Training loss: 1.5456618070602417
Validation loss: 2.1565180850285355

Epoch: 5| Step: 8
Training loss: 1.5977970361709595
Validation loss: 2.1698497187706733

Epoch: 5| Step: 9
Training loss: 2.2651116847991943
Validation loss: 2.190480539875646

Epoch: 5| Step: 10
Training loss: 2.1560747623443604
Validation loss: 2.202717160665861

Epoch: 458| Step: 0
Training loss: 0.8559280633926392
Validation loss: 2.2004723087433846

Epoch: 5| Step: 1
Training loss: 1.689406394958496
Validation loss: 2.201073092799033

Epoch: 5| Step: 2
Training loss: 1.609450101852417
Validation loss: 2.197252022322788

Epoch: 5| Step: 3
Training loss: 1.8282772302627563
Validation loss: 2.1867449283599854

Epoch: 5| Step: 4
Training loss: 2.008523941040039
Validation loss: 2.167323236824364

Epoch: 5| Step: 5
Training loss: 1.8285719156265259
Validation loss: 2.15658337454642

Epoch: 5| Step: 6
Training loss: 1.9687942266464233
Validation loss: 2.1466292463323122

Epoch: 5| Step: 7
Training loss: 1.5151654481887817
Validation loss: 2.1318001080584783

Epoch: 5| Step: 8
Training loss: 1.860425591468811
Validation loss: 2.1468265569338234

Epoch: 5| Step: 9
Training loss: 2.5556483268737793
Validation loss: 2.1519769635251773

Epoch: 5| Step: 10
Training loss: 2.0233774185180664
Validation loss: 2.155643659253274

Epoch: 459| Step: 0
Training loss: 1.6522737741470337
Validation loss: 2.1684933400923208

Epoch: 5| Step: 1
Training loss: 2.165482521057129
Validation loss: 2.1839902708607335

Epoch: 5| Step: 2
Training loss: 2.0906200408935547
Validation loss: 2.184115325250933

Epoch: 5| Step: 3
Training loss: 1.614739179611206
Validation loss: 2.1564347897806475

Epoch: 5| Step: 4
Training loss: 1.640249252319336
Validation loss: 2.148226909739997

Epoch: 5| Step: 5
Training loss: 1.8151153326034546
Validation loss: 2.1551722339404527

Epoch: 5| Step: 6
Training loss: 1.545515775680542
Validation loss: 2.1595574707113285

Epoch: 5| Step: 7
Training loss: 1.6718246936798096
Validation loss: 2.172111008756904

Epoch: 5| Step: 8
Training loss: 1.982177495956421
Validation loss: 2.1719592771222516

Epoch: 5| Step: 9
Training loss: 1.6102063655853271
Validation loss: 2.184284556296564

Epoch: 5| Step: 10
Training loss: 2.084010601043701
Validation loss: 2.17997492513349

Epoch: 460| Step: 0
Training loss: 1.9298292398452759
Validation loss: 2.184859134817636

Epoch: 5| Step: 1
Training loss: 2.0477707386016846
Validation loss: 2.1609898485163206

Epoch: 5| Step: 2
Training loss: 2.236485242843628
Validation loss: 2.1772433250181136

Epoch: 5| Step: 3
Training loss: 1.5973873138427734
Validation loss: 2.1747562821193407

Epoch: 5| Step: 4
Training loss: 1.2829781770706177
Validation loss: 2.1675614515940347

Epoch: 5| Step: 5
Training loss: 1.8615436553955078
Validation loss: 2.1523969493886477

Epoch: 5| Step: 6
Training loss: 1.2993906736373901
Validation loss: 2.1357881612675165

Epoch: 5| Step: 7
Training loss: 1.9653682708740234
Validation loss: 2.147157005084458

Epoch: 5| Step: 8
Training loss: 2.3258566856384277
Validation loss: 2.1396670162036853

Epoch: 5| Step: 9
Training loss: 1.748100996017456
Validation loss: 2.1386090555498676

Epoch: 5| Step: 10
Training loss: 1.1950631141662598
Validation loss: 2.1291242209813928

Epoch: 461| Step: 0
Training loss: 2.8028135299682617
Validation loss: 2.1314652953096616

Epoch: 5| Step: 1
Training loss: 1.5338106155395508
Validation loss: 2.13418145461749

Epoch: 5| Step: 2
Training loss: 1.5563271045684814
Validation loss: 2.1599970556074575

Epoch: 5| Step: 3
Training loss: 1.8463414907455444
Validation loss: 2.163568304431054

Epoch: 5| Step: 4
Training loss: 2.1978230476379395
Validation loss: 2.166652603815961

Epoch: 5| Step: 5
Training loss: 1.155920386314392
Validation loss: 2.1842741543246853

Epoch: 5| Step: 6
Training loss: 2.017425537109375
Validation loss: 2.1880945364634194

Epoch: 5| Step: 7
Training loss: 2.1232049465179443
Validation loss: 2.2070852428354244

Epoch: 5| Step: 8
Training loss: 1.050788164138794
Validation loss: 2.201173782348633

Epoch: 5| Step: 9
Training loss: 1.5086908340454102
Validation loss: 2.197635717289422

Epoch: 5| Step: 10
Training loss: 1.7861793041229248
Validation loss: 2.157833089110672

Epoch: 462| Step: 0
Training loss: 1.532314419746399
Validation loss: 2.1602743312876713

Epoch: 5| Step: 1
Training loss: 1.6956679821014404
Validation loss: 2.1429555839107883

Epoch: 5| Step: 2
Training loss: 2.2107136249542236
Validation loss: 2.140906330077879

Epoch: 5| Step: 3
Training loss: 1.3914037942886353
Validation loss: 2.1370832766256025

Epoch: 5| Step: 4
Training loss: 2.3854403495788574
Validation loss: 2.1436834796782462

Epoch: 5| Step: 5
Training loss: 1.6097166538238525
Validation loss: 2.125544512143699

Epoch: 5| Step: 6
Training loss: 2.275063991546631
Validation loss: 2.154932222058696

Epoch: 5| Step: 7
Training loss: 2.0730743408203125
Validation loss: 2.126650192404306

Epoch: 5| Step: 8
Training loss: 1.3834068775177002
Validation loss: 2.137984009199245

Epoch: 5| Step: 9
Training loss: 1.083250641822815
Validation loss: 2.151456768794726

Epoch: 5| Step: 10
Training loss: 1.6734426021575928
Validation loss: 2.1720062866005847

Epoch: 463| Step: 0
Training loss: 1.5922701358795166
Validation loss: 2.1883433365052745

Epoch: 5| Step: 1
Training loss: 1.7437162399291992
Validation loss: 2.1855585088012037

Epoch: 5| Step: 2
Training loss: 1.8331760168075562
Validation loss: 2.211130484457939

Epoch: 5| Step: 3
Training loss: 1.9153391122817993
Validation loss: 2.197098998613255

Epoch: 5| Step: 4
Training loss: 2.1646740436553955
Validation loss: 2.2132019150641655

Epoch: 5| Step: 5
Training loss: 1.3072216510772705
Validation loss: 2.2071763776963755

Epoch: 5| Step: 6
Training loss: 1.736188292503357
Validation loss: 2.1868216658151276

Epoch: 5| Step: 7
Training loss: 2.040879011154175
Validation loss: 2.1736939491764193

Epoch: 5| Step: 8
Training loss: 1.7908055782318115
Validation loss: 2.135080550306587

Epoch: 5| Step: 9
Training loss: 1.786867380142212
Validation loss: 2.1249643295041976

Epoch: 5| Step: 10
Training loss: 1.504549503326416
Validation loss: 2.1046563707372195

Epoch: 464| Step: 0
Training loss: 2.240981340408325
Validation loss: 2.0959696808168964

Epoch: 5| Step: 1
Training loss: 1.6208734512329102
Validation loss: 2.1167730849276305

Epoch: 5| Step: 2
Training loss: 1.4858009815216064
Validation loss: 2.1226168678652857

Epoch: 5| Step: 3
Training loss: 1.7527313232421875
Validation loss: 2.1496566444314937

Epoch: 5| Step: 4
Training loss: 2.0609676837921143
Validation loss: 2.1450518190219836

Epoch: 5| Step: 5
Training loss: 1.7319148778915405
Validation loss: 2.1751850804974957

Epoch: 5| Step: 6
Training loss: 1.53664231300354
Validation loss: 2.1840395953065608

Epoch: 5| Step: 7
Training loss: 1.8217235803604126
Validation loss: 2.2013905868735364

Epoch: 5| Step: 8
Training loss: 1.4023876190185547
Validation loss: 2.219127652465656

Epoch: 5| Step: 9
Training loss: 2.4062390327453613
Validation loss: 2.2181988736634612

Epoch: 5| Step: 10
Training loss: 1.3796679973602295
Validation loss: 2.1776882063957954

Epoch: 465| Step: 0
Training loss: 1.5926120281219482
Validation loss: 2.1622688308838875

Epoch: 5| Step: 1
Training loss: 1.8272759914398193
Validation loss: 2.134620617794734

Epoch: 5| Step: 2
Training loss: 1.7459386587142944
Validation loss: 2.1209505745159682

Epoch: 5| Step: 3
Training loss: 1.8332719802856445
Validation loss: 2.0935643180724113

Epoch: 5| Step: 4
Training loss: 1.8747379779815674
Validation loss: 2.1049863035960863

Epoch: 5| Step: 5
Training loss: 1.5482726097106934
Validation loss: 2.0954997129337762

Epoch: 5| Step: 6
Training loss: 1.3032156229019165
Validation loss: 2.1151868117752897

Epoch: 5| Step: 7
Training loss: 2.0245137214660645
Validation loss: 2.1188172140429096

Epoch: 5| Step: 8
Training loss: 2.0103907585144043
Validation loss: 2.1279634096289195

Epoch: 5| Step: 9
Training loss: 1.9776051044464111
Validation loss: 2.1175757095377934

Epoch: 5| Step: 10
Training loss: 1.5914819240570068
Validation loss: 2.141651168946297

Epoch: 466| Step: 0
Training loss: 1.9097778797149658
Validation loss: 2.1494331411136094

Epoch: 5| Step: 1
Training loss: 0.9165116548538208
Validation loss: 2.171993693997783

Epoch: 5| Step: 2
Training loss: 2.180407762527466
Validation loss: 2.172408573089107

Epoch: 5| Step: 3
Training loss: 2.0743207931518555
Validation loss: 2.189851176354193

Epoch: 5| Step: 4
Training loss: 1.2151738405227661
Validation loss: 2.1602579585967527

Epoch: 5| Step: 5
Training loss: 1.952530860900879
Validation loss: 2.1702812794716126

Epoch: 5| Step: 6
Training loss: 1.6682014465332031
Validation loss: 2.1705697941523727

Epoch: 5| Step: 7
Training loss: 2.2569069862365723
Validation loss: 2.1527636076814387

Epoch: 5| Step: 8
Training loss: 1.056538701057434
Validation loss: 2.146952611143871

Epoch: 5| Step: 9
Training loss: 2.2878406047821045
Validation loss: 2.123889087348856

Epoch: 5| Step: 10
Training loss: 1.7731579542160034
Validation loss: 2.1314752512080695

Epoch: 467| Step: 0
Training loss: 1.771341323852539
Validation loss: 2.119176794123906

Epoch: 5| Step: 1
Training loss: 1.198777198791504
Validation loss: 2.1256953195859025

Epoch: 5| Step: 2
Training loss: 1.5446723699569702
Validation loss: 2.1349080762555523

Epoch: 5| Step: 3
Training loss: 1.6561362743377686
Validation loss: 2.139463340082476

Epoch: 5| Step: 4
Training loss: 2.2231545448303223
Validation loss: 2.160780865658996

Epoch: 5| Step: 5
Training loss: 1.8173065185546875
Validation loss: 2.1599045107441563

Epoch: 5| Step: 6
Training loss: 1.5787291526794434
Validation loss: 2.1614963598148798

Epoch: 5| Step: 7
Training loss: 2.042767286300659
Validation loss: 2.176098072400657

Epoch: 5| Step: 8
Training loss: 1.42574942111969
Validation loss: 2.180937445291909

Epoch: 5| Step: 9
Training loss: 1.7085754871368408
Validation loss: 2.1924316472904657

Epoch: 5| Step: 10
Training loss: 2.50230073928833
Validation loss: 2.175063015312277

Epoch: 468| Step: 0
Training loss: 1.7113707065582275
Validation loss: 2.15853540871733

Epoch: 5| Step: 1
Training loss: 1.7287495136260986
Validation loss: 2.1388040076019945

Epoch: 5| Step: 2
Training loss: 2.091287612915039
Validation loss: 2.13777357275768

Epoch: 5| Step: 3
Training loss: 1.5190633535385132
Validation loss: 2.1346638715395363

Epoch: 5| Step: 4
Training loss: 1.769758939743042
Validation loss: 2.105346618160125

Epoch: 5| Step: 5
Training loss: 1.5199416875839233
Validation loss: 2.132762303916357

Epoch: 5| Step: 6
Training loss: 1.860913872718811
Validation loss: 2.154105732517858

Epoch: 5| Step: 7
Training loss: 1.765625
Validation loss: 2.118561689571668

Epoch: 5| Step: 8
Training loss: 1.3721840381622314
Validation loss: 2.1212180647798764

Epoch: 5| Step: 9
Training loss: 1.5853019952774048
Validation loss: 2.134227962904079

Epoch: 5| Step: 10
Training loss: 2.4590423107147217
Validation loss: 2.1530916780553837

Epoch: 469| Step: 0
Training loss: 1.5335512161254883
Validation loss: 2.1660706471371394

Epoch: 5| Step: 1
Training loss: 1.5384266376495361
Validation loss: 2.186158344309817

Epoch: 5| Step: 2
Training loss: 1.6836179494857788
Validation loss: 2.195864354410479

Epoch: 5| Step: 3
Training loss: 1.752931833267212
Validation loss: 2.1817641642785843

Epoch: 5| Step: 4
Training loss: 1.8634693622589111
Validation loss: 2.1549632856922765

Epoch: 5| Step: 5
Training loss: 1.303221344947815
Validation loss: 2.1550764319717244

Epoch: 5| Step: 6
Training loss: 2.0668435096740723
Validation loss: 2.128380516523956

Epoch: 5| Step: 7
Training loss: 1.7130482196807861
Validation loss: 2.120607247916601

Epoch: 5| Step: 8
Training loss: 1.7185758352279663
Validation loss: 2.1207926632255636

Epoch: 5| Step: 9
Training loss: 2.1148316860198975
Validation loss: 2.1223738449876026

Epoch: 5| Step: 10
Training loss: 1.9714322090148926
Validation loss: 2.1167581978664605

Epoch: 470| Step: 0
Training loss: 1.316541075706482
Validation loss: 2.1333976855842014

Epoch: 5| Step: 1
Training loss: 1.9012054204940796
Validation loss: 2.134594322532736

Epoch: 5| Step: 2
Training loss: 2.1269402503967285
Validation loss: 2.135054778027278

Epoch: 5| Step: 3
Training loss: 1.5184437036514282
Validation loss: 2.154305455505207

Epoch: 5| Step: 4
Training loss: 1.7139564752578735
Validation loss: 2.1667880422325543

Epoch: 5| Step: 5
Training loss: 1.299324631690979
Validation loss: 2.157747648095572

Epoch: 5| Step: 6
Training loss: 1.7050552368164062
Validation loss: 2.1592761547334733

Epoch: 5| Step: 7
Training loss: 2.063417673110962
Validation loss: 2.171561897441905

Epoch: 5| Step: 8
Training loss: 1.6591211557388306
Validation loss: 2.188403553860162

Epoch: 5| Step: 9
Training loss: 1.9494930505752563
Validation loss: 2.1892136502009567

Epoch: 5| Step: 10
Training loss: 1.826494574546814
Validation loss: 2.188602198836624

Epoch: 471| Step: 0
Training loss: 1.6540781259536743
Validation loss: 2.1691330825128863

Epoch: 5| Step: 1
Training loss: 2.1884520053863525
Validation loss: 2.1912516265787105

Epoch: 5| Step: 2
Training loss: 1.1740692853927612
Validation loss: 2.180581154361848

Epoch: 5| Step: 3
Training loss: 1.621185302734375
Validation loss: 2.1668099587963474

Epoch: 5| Step: 4
Training loss: 1.9226839542388916
Validation loss: 2.1473847845549225

Epoch: 5| Step: 5
Training loss: 2.0805106163024902
Validation loss: 2.1339993707595335

Epoch: 5| Step: 6
Training loss: 1.726088523864746
Validation loss: 2.135878755200294

Epoch: 5| Step: 7
Training loss: 1.6547954082489014
Validation loss: 2.132950000865485

Epoch: 5| Step: 8
Training loss: 1.3072783946990967
Validation loss: 2.1230619158796085

Epoch: 5| Step: 9
Training loss: 1.5148788690567017
Validation loss: 2.1105484629190094

Epoch: 5| Step: 10
Training loss: 2.304678201675415
Validation loss: 2.0968797911879835

Epoch: 472| Step: 0
Training loss: 1.3578320741653442
Validation loss: 2.101746819352591

Epoch: 5| Step: 1
Training loss: 1.716124176979065
Validation loss: 2.1082086434928318

Epoch: 5| Step: 2
Training loss: 1.4502722024917603
Validation loss: 2.1173296359277542

Epoch: 5| Step: 3
Training loss: 1.2124695777893066
Validation loss: 2.149892645497476

Epoch: 5| Step: 4
Training loss: 1.74465012550354
Validation loss: 2.168266228450242

Epoch: 5| Step: 5
Training loss: 1.9041706323623657
Validation loss: 2.177640937989758

Epoch: 5| Step: 6
Training loss: 2.1382226943969727
Validation loss: 2.178917351589408

Epoch: 5| Step: 7
Training loss: 1.3806707859039307
Validation loss: 2.188687683433615

Epoch: 5| Step: 8
Training loss: 1.9843361377716064
Validation loss: 2.19738583923668

Epoch: 5| Step: 9
Training loss: 1.6542755365371704
Validation loss: 2.1675591955902758

Epoch: 5| Step: 10
Training loss: 2.639932632446289
Validation loss: 2.164706871073733

Epoch: 473| Step: 0
Training loss: 1.4377095699310303
Validation loss: 2.164452629704629

Epoch: 5| Step: 1
Training loss: 1.5882409811019897
Validation loss: 2.1560093382353425

Epoch: 5| Step: 2
Training loss: 2.601627826690674
Validation loss: 2.146950820440887

Epoch: 5| Step: 3
Training loss: 2.097752094268799
Validation loss: 2.138852673192178

Epoch: 5| Step: 4
Training loss: 1.242266297340393
Validation loss: 2.116535102167437

Epoch: 5| Step: 5
Training loss: 1.69809091091156
Validation loss: 2.1438226674192693

Epoch: 5| Step: 6
Training loss: 1.9351390600204468
Validation loss: 2.120234359977066

Epoch: 5| Step: 7
Training loss: 1.757746696472168
Validation loss: 2.1298636339044057

Epoch: 5| Step: 8
Training loss: 1.4750772714614868
Validation loss: 2.10385581626687

Epoch: 5| Step: 9
Training loss: 1.8514988422393799
Validation loss: 2.1063559850056968

Epoch: 5| Step: 10
Training loss: 1.280735969543457
Validation loss: 2.107281579766222

Epoch: 474| Step: 0
Training loss: 1.336081624031067
Validation loss: 2.122176751013725

Epoch: 5| Step: 1
Training loss: 1.3568600416183472
Validation loss: 2.1208036150983585

Epoch: 5| Step: 2
Training loss: 2.1674931049346924
Validation loss: 2.141243511630643

Epoch: 5| Step: 3
Training loss: 2.0686163902282715
Validation loss: 2.132478501207085

Epoch: 5| Step: 4
Training loss: 1.3487884998321533
Validation loss: 2.124512451951222

Epoch: 5| Step: 5
Training loss: 2.058873414993286
Validation loss: 2.143003781636556

Epoch: 5| Step: 6
Training loss: 1.8657960891723633
Validation loss: 2.1666680459053285

Epoch: 5| Step: 7
Training loss: 1.7753210067749023
Validation loss: 2.1792579722660843

Epoch: 5| Step: 8
Training loss: 1.5801396369934082
Validation loss: 2.1853504462908675

Epoch: 5| Step: 9
Training loss: 1.8075250387191772
Validation loss: 2.1840037607377574

Epoch: 5| Step: 10
Training loss: 1.6834396123886108
Validation loss: 2.1745929512926327

Epoch: 475| Step: 0
Training loss: 1.187839150428772
Validation loss: 2.1485256892378612

Epoch: 5| Step: 1
Training loss: 1.7902498245239258
Validation loss: 2.142510929415303

Epoch: 5| Step: 2
Training loss: 2.3054587841033936
Validation loss: 2.1299903264609714

Epoch: 5| Step: 3
Training loss: 2.0706264972686768
Validation loss: 2.0985956294562227

Epoch: 5| Step: 4
Training loss: 2.074925184249878
Validation loss: 2.1116559825917727

Epoch: 5| Step: 5
Training loss: 2.009490489959717
Validation loss: 2.1013862125335203

Epoch: 5| Step: 6
Training loss: 1.3065658807754517
Validation loss: 2.10528798385333

Epoch: 5| Step: 7
Training loss: 1.4515511989593506
Validation loss: 2.1130168463594172

Epoch: 5| Step: 8
Training loss: 1.8017852306365967
Validation loss: 2.1131324319429297

Epoch: 5| Step: 9
Training loss: 1.6824901103973389
Validation loss: 2.125146673571679

Epoch: 5| Step: 10
Training loss: 1.3634241819381714
Validation loss: 2.151173440358972

Epoch: 476| Step: 0
Training loss: 1.715242624282837
Validation loss: 2.171199437110655

Epoch: 5| Step: 1
Training loss: 1.8724607229232788
Validation loss: 2.177372201796501

Epoch: 5| Step: 2
Training loss: 1.5136483907699585
Validation loss: 2.192626207105575

Epoch: 5| Step: 3
Training loss: 2.54394268989563
Validation loss: 2.1609971574557725

Epoch: 5| Step: 4
Training loss: 1.4178202152252197
Validation loss: 2.163288349746376

Epoch: 5| Step: 5
Training loss: 1.2347400188446045
Validation loss: 2.144266390031384

Epoch: 5| Step: 6
Training loss: 1.994424819946289
Validation loss: 2.1550071393289874

Epoch: 5| Step: 7
Training loss: 1.3730214834213257
Validation loss: 2.1405902370329826

Epoch: 5| Step: 8
Training loss: 1.4957845211029053
Validation loss: 2.1326187220952844

Epoch: 5| Step: 9
Training loss: 1.994814157485962
Validation loss: 2.137365145068015

Epoch: 5| Step: 10
Training loss: 1.8722535371780396
Validation loss: 2.125620404879252

Epoch: 477| Step: 0
Training loss: 2.0563559532165527
Validation loss: 2.1207296591933056

Epoch: 5| Step: 1
Training loss: 1.8007242679595947
Validation loss: 2.1222007992447063

Epoch: 5| Step: 2
Training loss: 2.145879030227661
Validation loss: 2.1181767679029897

Epoch: 5| Step: 3
Training loss: 2.4646382331848145
Validation loss: 2.1092139828589653

Epoch: 5| Step: 4
Training loss: 1.3863000869750977
Validation loss: 2.121633157935194

Epoch: 5| Step: 5
Training loss: 1.3895436525344849
Validation loss: 2.1387464871970554

Epoch: 5| Step: 6
Training loss: 1.7930996417999268
Validation loss: 2.119236405177783

Epoch: 5| Step: 7
Training loss: 1.1019747257232666
Validation loss: 2.121674660713442

Epoch: 5| Step: 8
Training loss: 1.5695613622665405
Validation loss: 2.1286076473933395

Epoch: 5| Step: 9
Training loss: 1.6917724609375
Validation loss: 2.1148465717992475

Epoch: 5| Step: 10
Training loss: 1.440643072128296
Validation loss: 2.123890774224394

Epoch: 478| Step: 0
Training loss: 2.1593470573425293
Validation loss: 2.1440680975555093

Epoch: 5| Step: 1
Training loss: 2.0099639892578125
Validation loss: 2.1411424888077604

Epoch: 5| Step: 2
Training loss: 1.5139669179916382
Validation loss: 2.1472591687274236

Epoch: 5| Step: 3
Training loss: 2.027273416519165
Validation loss: 2.1359086062318537

Epoch: 5| Step: 4
Training loss: 1.4167397022247314
Validation loss: 2.138464512363557

Epoch: 5| Step: 5
Training loss: 1.2766934633255005
Validation loss: 2.1588344035610074

Epoch: 5| Step: 6
Training loss: 1.6915416717529297
Validation loss: 2.1703714196399977

Epoch: 5| Step: 7
Training loss: 1.6755082607269287
Validation loss: 2.1545258568179224

Epoch: 5| Step: 8
Training loss: 1.516982078552246
Validation loss: 2.1506631348722722

Epoch: 5| Step: 9
Training loss: 1.190727949142456
Validation loss: 2.15711570555164

Epoch: 5| Step: 10
Training loss: 2.610898733139038
Validation loss: 2.131904122649982

Epoch: 479| Step: 0
Training loss: 1.7387325763702393
Validation loss: 2.1213234752737065

Epoch: 5| Step: 1
Training loss: 1.8998043537139893
Validation loss: 2.114357594520815

Epoch: 5| Step: 2
Training loss: 1.2601921558380127
Validation loss: 2.092443068822225

Epoch: 5| Step: 3
Training loss: 1.7383962869644165
Validation loss: 2.1070870225147535

Epoch: 5| Step: 4
Training loss: 1.9813849925994873
Validation loss: 2.105076059218376

Epoch: 5| Step: 5
Training loss: 1.6010465621948242
Validation loss: 2.105015636772238

Epoch: 5| Step: 6
Training loss: 2.2888882160186768
Validation loss: 2.116073385361702

Epoch: 5| Step: 7
Training loss: 1.1592036485671997
Validation loss: 2.132422395931777

Epoch: 5| Step: 8
Training loss: 1.8251413106918335
Validation loss: 2.1532760743171937

Epoch: 5| Step: 9
Training loss: 1.4165916442871094
Validation loss: 2.1421960707633727

Epoch: 5| Step: 10
Training loss: 1.9543853998184204
Validation loss: 2.1727840913239347

Epoch: 480| Step: 0
Training loss: 1.8391034603118896
Validation loss: 2.1601365996945288

Epoch: 5| Step: 1
Training loss: 1.4228003025054932
Validation loss: 2.1754274509286367

Epoch: 5| Step: 2
Training loss: 1.6534488201141357
Validation loss: 2.1552348418902327

Epoch: 5| Step: 3
Training loss: 1.6289275884628296
Validation loss: 2.1546610709159606

Epoch: 5| Step: 4
Training loss: 1.4101276397705078
Validation loss: 2.1615759480384087

Epoch: 5| Step: 5
Training loss: 1.8040039539337158
Validation loss: 2.1384205997631116

Epoch: 5| Step: 6
Training loss: 2.403395175933838
Validation loss: 2.1213874342621013

Epoch: 5| Step: 7
Training loss: 1.178004503250122
Validation loss: 2.117799134664638

Epoch: 5| Step: 8
Training loss: 2.195810317993164
Validation loss: 2.1170931375154884

Epoch: 5| Step: 9
Training loss: 1.4055994749069214
Validation loss: 2.1347338538016043

Epoch: 5| Step: 10
Training loss: 1.8122879266738892
Validation loss: 2.0971315842802807

Epoch: 481| Step: 0
Training loss: 1.1628310680389404
Validation loss: 2.111392149361231

Epoch: 5| Step: 1
Training loss: 1.341302514076233
Validation loss: 2.1082602829061527

Epoch: 5| Step: 2
Training loss: 1.8075037002563477
Validation loss: 2.104949735826062

Epoch: 5| Step: 3
Training loss: 2.2562484741210938
Validation loss: 2.114840461361793

Epoch: 5| Step: 4
Training loss: 1.9306799173355103
Validation loss: 2.1527718702952066

Epoch: 5| Step: 5
Training loss: 1.7735049724578857
Validation loss: 2.121754683474059

Epoch: 5| Step: 6
Training loss: 1.9052330255508423
Validation loss: 2.113597692981843

Epoch: 5| Step: 7
Training loss: 1.5460355281829834
Validation loss: 2.1312795787729244

Epoch: 5| Step: 8
Training loss: 1.9138357639312744
Validation loss: 2.112040494077949

Epoch: 5| Step: 9
Training loss: 1.9459049701690674
Validation loss: 2.1300106022947576

Epoch: 5| Step: 10
Training loss: 0.9750348329544067
Validation loss: 2.1307610337452223

Epoch: 482| Step: 0
Training loss: 1.4932489395141602
Validation loss: 2.1250175570928924

Epoch: 5| Step: 1
Training loss: 0.8905175924301147
Validation loss: 2.122972132057272

Epoch: 5| Step: 2
Training loss: 1.8314825296401978
Validation loss: 2.12992492798836

Epoch: 5| Step: 3
Training loss: 1.7697179317474365
Validation loss: 2.105922152919154

Epoch: 5| Step: 4
Training loss: 2.261624813079834
Validation loss: 2.134656911255211

Epoch: 5| Step: 5
Training loss: 1.6158688068389893
Validation loss: 2.1209522485733032

Epoch: 5| Step: 6
Training loss: 1.6502021551132202
Validation loss: 2.1195501601824196

Epoch: 5| Step: 7
Training loss: 1.9143457412719727
Validation loss: 2.1088653354234594

Epoch: 5| Step: 8
Training loss: 1.7558231353759766
Validation loss: 2.112252414867442

Epoch: 5| Step: 9
Training loss: 1.8062279224395752
Validation loss: 2.1122304265217116

Epoch: 5| Step: 10
Training loss: 1.6518534421920776
Validation loss: 2.1173611167938478

Epoch: 483| Step: 0
Training loss: 1.6984279155731201
Validation loss: 2.1072629203078566

Epoch: 5| Step: 1
Training loss: 1.5328361988067627
Validation loss: 2.147268413215555

Epoch: 5| Step: 2
Training loss: 2.353342056274414
Validation loss: 2.170292792781707

Epoch: 5| Step: 3
Training loss: 1.930719017982483
Validation loss: 2.150931905674678

Epoch: 5| Step: 4
Training loss: 1.8374608755111694
Validation loss: 2.18657579857816

Epoch: 5| Step: 5
Training loss: 1.728215217590332
Validation loss: 2.1923712043352026

Epoch: 5| Step: 6
Training loss: 1.6295042037963867
Validation loss: 2.181090416446809

Epoch: 5| Step: 7
Training loss: 1.373232364654541
Validation loss: 2.1627477138273177

Epoch: 5| Step: 8
Training loss: 1.8318296670913696
Validation loss: 2.1401274370890793

Epoch: 5| Step: 9
Training loss: 1.3811719417572021
Validation loss: 2.135737757528982

Epoch: 5| Step: 10
Training loss: 1.2910140752792358
Validation loss: 2.124215646456647

Epoch: 484| Step: 0
Training loss: 1.3045600652694702
Validation loss: 2.1036741092640865

Epoch: 5| Step: 1
Training loss: 1.5024230480194092
Validation loss: 2.1121360666008404

Epoch: 5| Step: 2
Training loss: 1.211790680885315
Validation loss: 2.104053181986655

Epoch: 5| Step: 3
Training loss: 2.1411633491516113
Validation loss: 2.1025672881833968

Epoch: 5| Step: 4
Training loss: 1.834157943725586
Validation loss: 2.0995352947583763

Epoch: 5| Step: 5
Training loss: 1.4479868412017822
Validation loss: 2.0956681595053723

Epoch: 5| Step: 6
Training loss: 2.174238920211792
Validation loss: 2.107746749795893

Epoch: 5| Step: 7
Training loss: 1.3023955821990967
Validation loss: 2.1022447770641697

Epoch: 5| Step: 8
Training loss: 2.0405476093292236
Validation loss: 2.1151292221520537

Epoch: 5| Step: 9
Training loss: 2.0616066455841064
Validation loss: 2.122485799174155

Epoch: 5| Step: 10
Training loss: 1.6101868152618408
Validation loss: 2.1062598779637325

Epoch: 485| Step: 0
Training loss: 1.3195925951004028
Validation loss: 2.106554610754854

Epoch: 5| Step: 1
Training loss: 2.284097194671631
Validation loss: 2.114959688596828

Epoch: 5| Step: 2
Training loss: 1.887255072593689
Validation loss: 2.1223142749519757

Epoch: 5| Step: 3
Training loss: 1.4773616790771484
Validation loss: 2.1168944733117216

Epoch: 5| Step: 4
Training loss: 1.127933144569397
Validation loss: 2.153136166193152

Epoch: 5| Step: 5
Training loss: 1.1891021728515625
Validation loss: 2.136363539644467

Epoch: 5| Step: 6
Training loss: 2.6590259075164795
Validation loss: 2.1300171036874094

Epoch: 5| Step: 7
Training loss: 1.2765384912490845
Validation loss: 2.09575044467885

Epoch: 5| Step: 8
Training loss: 2.250889539718628
Validation loss: 2.1028595021975938

Epoch: 5| Step: 9
Training loss: 1.6890668869018555
Validation loss: 2.1261527076844247

Epoch: 5| Step: 10
Training loss: 1.4710615873336792
Validation loss: 2.1271314518426054

Epoch: 486| Step: 0
Training loss: 1.5898717641830444
Validation loss: 2.130206964349234

Epoch: 5| Step: 1
Training loss: 1.9173370599746704
Validation loss: 2.104786160171673

Epoch: 5| Step: 2
Training loss: 1.4947017431259155
Validation loss: 2.1067400786184494

Epoch: 5| Step: 3
Training loss: 1.5947891473770142
Validation loss: 2.096056276752103

Epoch: 5| Step: 4
Training loss: 1.9181137084960938
Validation loss: 2.1015898181546118

Epoch: 5| Step: 5
Training loss: 1.603381872177124
Validation loss: 2.113025188446045

Epoch: 5| Step: 6
Training loss: 1.2288696765899658
Validation loss: 2.107596905000748

Epoch: 5| Step: 7
Training loss: 1.6287063360214233
Validation loss: 2.115223974309942

Epoch: 5| Step: 8
Training loss: 1.877182960510254
Validation loss: 2.1245140516629784

Epoch: 5| Step: 9
Training loss: 1.9100453853607178
Validation loss: 2.133394528460759

Epoch: 5| Step: 10
Training loss: 1.9898585081100464
Validation loss: 2.1335474573155886

Epoch: 487| Step: 0
Training loss: 1.5970677137374878
Validation loss: 2.1534764715420303

Epoch: 5| Step: 1
Training loss: 1.5833678245544434
Validation loss: 2.1624304274077057

Epoch: 5| Step: 2
Training loss: 1.5815973281860352
Validation loss: 2.1521729500063005

Epoch: 5| Step: 3
Training loss: 1.0896530151367188
Validation loss: 2.14879697368991

Epoch: 5| Step: 4
Training loss: 1.9839494228363037
Validation loss: 2.149496895010753

Epoch: 5| Step: 5
Training loss: 1.583191156387329
Validation loss: 2.136136785630257

Epoch: 5| Step: 6
Training loss: 1.7029720544815063
Validation loss: 2.113028169960104

Epoch: 5| Step: 7
Training loss: 1.5258525609970093
Validation loss: 2.1233610363416773

Epoch: 5| Step: 8
Training loss: 2.1526691913604736
Validation loss: 2.0945350739263717

Epoch: 5| Step: 9
Training loss: 1.633114218711853
Validation loss: 2.0961037861403597

Epoch: 5| Step: 10
Training loss: 2.3327999114990234
Validation loss: 2.0760970372025684

Epoch: 488| Step: 0
Training loss: 2.3078722953796387
Validation loss: 2.070947761176735

Epoch: 5| Step: 1
Training loss: 1.8695350885391235
Validation loss: 2.073877662740728

Epoch: 5| Step: 2
Training loss: 1.2053282260894775
Validation loss: 2.099019632544569

Epoch: 5| Step: 3
Training loss: 1.6531524658203125
Validation loss: 2.079697326947284

Epoch: 5| Step: 4
Training loss: 1.6562961339950562
Validation loss: 2.1043878447624946

Epoch: 5| Step: 5
Training loss: 1.551041841506958
Validation loss: 2.1266690736175864

Epoch: 5| Step: 6
Training loss: 1.6404768228530884
Validation loss: 2.1396624375415105

Epoch: 5| Step: 7
Training loss: 1.4943307638168335
Validation loss: 2.184736277467461

Epoch: 5| Step: 8
Training loss: 2.2608418464660645
Validation loss: 2.180434984545554

Epoch: 5| Step: 9
Training loss: 1.5606001615524292
Validation loss: 2.1687775991296254

Epoch: 5| Step: 10
Training loss: 1.6507093906402588
Validation loss: 2.155605907081276

Epoch: 489| Step: 0
Training loss: 1.8292945623397827
Validation loss: 2.1523211207441104

Epoch: 5| Step: 1
Training loss: 2.1744117736816406
Validation loss: 2.132959160753476

Epoch: 5| Step: 2
Training loss: 1.4558703899383545
Validation loss: 2.139540941484513

Epoch: 5| Step: 3
Training loss: 0.9996713399887085
Validation loss: 2.1381602838475215

Epoch: 5| Step: 4
Training loss: 1.5694185495376587
Validation loss: 2.1300344544072307

Epoch: 5| Step: 5
Training loss: 1.4878395795822144
Validation loss: 2.1049786921470397

Epoch: 5| Step: 6
Training loss: 1.9089057445526123
Validation loss: 2.1052915485956336

Epoch: 5| Step: 7
Training loss: 2.0866668224334717
Validation loss: 2.106895823632517

Epoch: 5| Step: 8
Training loss: 1.0149574279785156
Validation loss: 2.096766261644261

Epoch: 5| Step: 9
Training loss: 1.8402068614959717
Validation loss: 2.1125269371976136

Epoch: 5| Step: 10
Training loss: 2.3043105602264404
Validation loss: 2.126470655523321

Epoch: 490| Step: 0
Training loss: 1.7927519083023071
Validation loss: 2.1293417587075183

Epoch: 5| Step: 1
Training loss: 1.5842732191085815
Validation loss: 2.1171908583692325

Epoch: 5| Step: 2
Training loss: 1.4651333093643188
Validation loss: 2.1296204751537693

Epoch: 5| Step: 3
Training loss: 1.3647587299346924
Validation loss: 2.119210345770723

Epoch: 5| Step: 4
Training loss: 1.127760648727417
Validation loss: 2.107509228491014

Epoch: 5| Step: 5
Training loss: 1.8834302425384521
Validation loss: 2.1310402757378033

Epoch: 5| Step: 6
Training loss: 1.8810174465179443
Validation loss: 2.113203384542978

Epoch: 5| Step: 7
Training loss: 2.1279776096343994
Validation loss: 2.1143660365894275

Epoch: 5| Step: 8
Training loss: 1.8794933557510376
Validation loss: 2.1265647334437214

Epoch: 5| Step: 9
Training loss: 1.6547152996063232
Validation loss: 2.1401069600095033

Epoch: 5| Step: 10
Training loss: 1.7001181840896606
Validation loss: 2.126315091245918

Epoch: 491| Step: 0
Training loss: 2.051835298538208
Validation loss: 2.1356086461774764

Epoch: 5| Step: 1
Training loss: 1.7459232807159424
Validation loss: 2.1251707102662776

Epoch: 5| Step: 2
Training loss: 1.6973406076431274
Validation loss: 2.1271518071492515

Epoch: 5| Step: 3
Training loss: 2.0311708450317383
Validation loss: 2.1429747048244683

Epoch: 5| Step: 4
Training loss: 1.7279574871063232
Validation loss: 2.137302803736861

Epoch: 5| Step: 5
Training loss: 1.3199876546859741
Validation loss: 2.1234011034811697

Epoch: 5| Step: 6
Training loss: 1.5541408061981201
Validation loss: 2.120728423518519

Epoch: 5| Step: 7
Training loss: 1.3484992980957031
Validation loss: 2.126819996423619

Epoch: 5| Step: 8
Training loss: 1.3576555252075195
Validation loss: 2.1328795392026185

Epoch: 5| Step: 9
Training loss: 1.6190645694732666
Validation loss: 2.0878739946631977

Epoch: 5| Step: 10
Training loss: 1.9436607360839844
Validation loss: 2.112020687390399

Epoch: 492| Step: 0
Training loss: 1.617113709449768
Validation loss: 2.094824565354214

Epoch: 5| Step: 1
Training loss: 1.8888657093048096
Validation loss: 2.117023285999093

Epoch: 5| Step: 2
Training loss: 1.5473911762237549
Validation loss: 2.097352554721217

Epoch: 5| Step: 3
Training loss: 1.4190967082977295
Validation loss: 2.077368974685669

Epoch: 5| Step: 4
Training loss: 2.38765287399292
Validation loss: 2.076699306887965

Epoch: 5| Step: 5
Training loss: 1.6479027271270752
Validation loss: 2.089472596363355

Epoch: 5| Step: 6
Training loss: 1.4833297729492188
Validation loss: 2.072189495127688

Epoch: 5| Step: 7
Training loss: 1.7229732275009155
Validation loss: 2.0821365797391502

Epoch: 5| Step: 8
Training loss: 2.0920863151550293
Validation loss: 2.0901894184850875

Epoch: 5| Step: 9
Training loss: 1.1585553884506226
Validation loss: 2.098349755810153

Epoch: 5| Step: 10
Training loss: 1.3011465072631836
Validation loss: 2.1145322425391084

Epoch: 493| Step: 0
Training loss: 1.7761306762695312
Validation loss: 2.121318937629782

Epoch: 5| Step: 1
Training loss: 1.6326621770858765
Validation loss: 2.146731265129582

Epoch: 5| Step: 2
Training loss: 1.04250967502594
Validation loss: 2.1324954930172173

Epoch: 5| Step: 3
Training loss: 1.669516921043396
Validation loss: 2.1281408109972553

Epoch: 5| Step: 4
Training loss: 1.9065641164779663
Validation loss: 2.110520379517668

Epoch: 5| Step: 5
Training loss: 1.9253031015396118
Validation loss: 2.119557390930832

Epoch: 5| Step: 6
Training loss: 1.2120777368545532
Validation loss: 2.1115249151824624

Epoch: 5| Step: 7
Training loss: 1.8323700428009033
Validation loss: 2.1126699409177228

Epoch: 5| Step: 8
Training loss: 1.2887691259384155
Validation loss: 2.0961141778576757

Epoch: 5| Step: 9
Training loss: 2.0899643898010254
Validation loss: 2.089827929773638

Epoch: 5| Step: 10
Training loss: 2.0525543689727783
Validation loss: 2.0873615126455984

Epoch: 494| Step: 0
Training loss: 1.1830464601516724
Validation loss: 2.0988375422775105

Epoch: 5| Step: 1
Training loss: 2.3139121532440186
Validation loss: 2.1031528775409987

Epoch: 5| Step: 2
Training loss: 1.5817146301269531
Validation loss: 2.1045032470457015

Epoch: 5| Step: 3
Training loss: 1.1580266952514648
Validation loss: 2.0919768310362294

Epoch: 5| Step: 4
Training loss: 1.9251658916473389
Validation loss: 2.089288648738656

Epoch: 5| Step: 5
Training loss: 1.8952659368515015
Validation loss: 2.101922245435817

Epoch: 5| Step: 6
Training loss: 1.300490379333496
Validation loss: 2.103414040739818

Epoch: 5| Step: 7
Training loss: 1.7376362085342407
Validation loss: 2.1211336120482414

Epoch: 5| Step: 8
Training loss: 1.4880433082580566
Validation loss: 2.138339372732306

Epoch: 5| Step: 9
Training loss: 2.1272900104522705
Validation loss: 2.132705342385077

Epoch: 5| Step: 10
Training loss: 1.597070574760437
Validation loss: 2.130184254338664

Epoch: 495| Step: 0
Training loss: 1.9147011041641235
Validation loss: 2.1263215926385697

Epoch: 5| Step: 1
Training loss: 1.7214319705963135
Validation loss: 2.1366912511087235

Epoch: 5| Step: 2
Training loss: 1.2643749713897705
Validation loss: 2.144028640562488

Epoch: 5| Step: 3
Training loss: 1.6179507970809937
Validation loss: 2.1424666989234185

Epoch: 5| Step: 4
Training loss: 1.9416875839233398
Validation loss: 2.1715731672061387

Epoch: 5| Step: 5
Training loss: 0.9814833402633667
Validation loss: 2.138567537389776

Epoch: 5| Step: 6
Training loss: 1.7271629571914673
Validation loss: 2.13115365915401

Epoch: 5| Step: 7
Training loss: 2.240713119506836
Validation loss: 2.116000406203731

Epoch: 5| Step: 8
Training loss: 1.2137187719345093
Validation loss: 2.1085070563900854

Epoch: 5| Step: 9
Training loss: 1.7819023132324219
Validation loss: 2.1115522230825117

Epoch: 5| Step: 10
Training loss: 1.808501958847046
Validation loss: 2.0954238906983407

Epoch: 496| Step: 0
Training loss: 1.8551753759384155
Validation loss: 2.0694428746418287

Epoch: 5| Step: 1
Training loss: 2.285271406173706
Validation loss: 2.088400386994885

Epoch: 5| Step: 2
Training loss: 1.4400193691253662
Validation loss: 2.0599682049084733

Epoch: 5| Step: 3
Training loss: 1.0709998607635498
Validation loss: 2.0661997641286542

Epoch: 5| Step: 4
Training loss: 2.3030807971954346
Validation loss: 2.079760325852261

Epoch: 5| Step: 5
Training loss: 1.965807557106018
Validation loss: 2.0583774197486138

Epoch: 5| Step: 6
Training loss: 1.1471750736236572
Validation loss: 2.077236270391813

Epoch: 5| Step: 7
Training loss: 1.8170435428619385
Validation loss: 2.1202118845396143

Epoch: 5| Step: 8
Training loss: 1.62729012966156
Validation loss: 2.1462654016351186

Epoch: 5| Step: 9
Training loss: 1.6666691303253174
Validation loss: 2.1193182776051183

Epoch: 5| Step: 10
Training loss: 0.9124348759651184
Validation loss: 2.1242824626225296

Epoch: 497| Step: 0
Training loss: 1.5624128580093384
Validation loss: 2.1382967067021195

Epoch: 5| Step: 1
Training loss: 1.320762276649475
Validation loss: 2.108883032234766

Epoch: 5| Step: 2
Training loss: 0.9542630314826965
Validation loss: 2.124813219552399

Epoch: 5| Step: 3
Training loss: 1.8304693698883057
Validation loss: 2.097448388735453

Epoch: 5| Step: 4
Training loss: 1.8155295848846436
Validation loss: 2.0939101019213275

Epoch: 5| Step: 5
Training loss: 2.0686593055725098
Validation loss: 2.084435183514831

Epoch: 5| Step: 6
Training loss: 1.9027025699615479
Validation loss: 2.091845181680495

Epoch: 5| Step: 7
Training loss: 1.4950571060180664
Validation loss: 2.107719285513765

Epoch: 5| Step: 8
Training loss: 1.3985216617584229
Validation loss: 2.089404265085856

Epoch: 5| Step: 9
Training loss: 1.7422943115234375
Validation loss: 2.099035116934007

Epoch: 5| Step: 10
Training loss: 1.9980493783950806
Validation loss: 2.1335630801416214

Epoch: 498| Step: 0
Training loss: 1.83157479763031
Validation loss: 2.112709765793175

Epoch: 5| Step: 1
Training loss: 1.7922683954238892
Validation loss: 2.124221210838646

Epoch: 5| Step: 2
Training loss: 1.3670237064361572
Validation loss: 2.1072733504797823

Epoch: 5| Step: 3
Training loss: 1.756286859512329
Validation loss: 2.088974068241735

Epoch: 5| Step: 4
Training loss: 1.3032901287078857
Validation loss: 2.0908888770687963

Epoch: 5| Step: 5
Training loss: 1.2193710803985596
Validation loss: 2.092129994464177

Epoch: 5| Step: 6
Training loss: 1.6603527069091797
Validation loss: 2.105191646083709

Epoch: 5| Step: 7
Training loss: 1.71687912940979
Validation loss: 2.0866320158845637

Epoch: 5| Step: 8
Training loss: 2.1017818450927734
Validation loss: 2.079510675963535

Epoch: 5| Step: 9
Training loss: 1.297189712524414
Validation loss: 2.1042810640027447

Epoch: 5| Step: 10
Training loss: 2.090862512588501
Validation loss: 2.083544845222145

Epoch: 499| Step: 0
Training loss: 2.0563111305236816
Validation loss: 2.116778939001022

Epoch: 5| Step: 1
Training loss: 2.3045268058776855
Validation loss: 2.093380517857049

Epoch: 5| Step: 2
Training loss: 1.3030468225479126
Validation loss: 2.081926476570868

Epoch: 5| Step: 3
Training loss: 2.3667778968811035
Validation loss: 2.085024041514243

Epoch: 5| Step: 4
Training loss: 1.3274366855621338
Validation loss: 2.099717147888676

Epoch: 5| Step: 5
Training loss: 1.432646632194519
Validation loss: 2.0933287938435874

Epoch: 5| Step: 6
Training loss: 0.8972841501235962
Validation loss: 2.087053596332509

Epoch: 5| Step: 7
Training loss: 1.2097527980804443
Validation loss: 2.112428201142178

Epoch: 5| Step: 8
Training loss: 0.8814855813980103
Validation loss: 2.1020228760216826

Epoch: 5| Step: 9
Training loss: 1.9567604064941406
Validation loss: 2.115093702911049

Epoch: 5| Step: 10
Training loss: 2.292473316192627
Validation loss: 2.1016134100575603

Epoch: 500| Step: 0
Training loss: 1.934908151626587
Validation loss: 2.110678260044385

Epoch: 5| Step: 1
Training loss: 1.3117440938949585
Validation loss: 2.102511654617966

Epoch: 5| Step: 2
Training loss: 1.4778295755386353
Validation loss: 2.092744335051506

Epoch: 5| Step: 3
Training loss: 2.408254623413086
Validation loss: 2.0758421215959775

Epoch: 5| Step: 4
Training loss: 1.6185734272003174
Validation loss: 2.097295558580788

Epoch: 5| Step: 5
Training loss: 1.6137208938598633
Validation loss: 2.0721715034977084

Epoch: 5| Step: 6
Training loss: 1.8933290243148804
Validation loss: 2.0997525043385004

Epoch: 5| Step: 7
Training loss: 1.387381672859192
Validation loss: 2.100168566549978

Epoch: 5| Step: 8
Training loss: 2.004228353500366
Validation loss: 2.1197610029610257

Epoch: 5| Step: 9
Training loss: 0.9243149757385254
Validation loss: 2.103621167521323

Epoch: 5| Step: 10
Training loss: 1.3689483404159546
Validation loss: 2.119182220069311

Epoch: 501| Step: 0
Training loss: 1.5795118808746338
Validation loss: 2.1184368030999297

Epoch: 5| Step: 1
Training loss: 1.4386231899261475
Validation loss: 2.107118159212092

Epoch: 5| Step: 2
Training loss: 1.8504846096038818
Validation loss: 2.1067470888937674

Epoch: 5| Step: 3
Training loss: 1.6231921911239624
Validation loss: 2.1218506841249365

Epoch: 5| Step: 4
Training loss: 1.5363839864730835
Validation loss: 2.0962270946912867

Epoch: 5| Step: 5
Training loss: 1.7025314569473267
Validation loss: 2.0767851811583324

Epoch: 5| Step: 6
Training loss: 1.8317654132843018
Validation loss: 2.097444208719397

Epoch: 5| Step: 7
Training loss: 1.6728700399398804
Validation loss: 2.066987245313583

Epoch: 5| Step: 8
Training loss: 1.611604928970337
Validation loss: 2.0850521172246625

Epoch: 5| Step: 9
Training loss: 1.6572672128677368
Validation loss: 2.076382952351724

Epoch: 5| Step: 10
Training loss: 1.5406699180603027
Validation loss: 2.077366844300301

Epoch: 502| Step: 0
Training loss: 2.0295169353485107
Validation loss: 2.0993483502377748

Epoch: 5| Step: 1
Training loss: 1.316615343093872
Validation loss: 2.106996287581741

Epoch: 5| Step: 2
Training loss: 1.5687097311019897
Validation loss: 2.121568674682289

Epoch: 5| Step: 3
Training loss: 2.1588351726531982
Validation loss: 2.122752135799777

Epoch: 5| Step: 4
Training loss: 1.9124746322631836
Validation loss: 2.1035883939394386

Epoch: 5| Step: 5
Training loss: 1.244667649269104
Validation loss: 2.1034049449428434

Epoch: 5| Step: 6
Training loss: 1.2708714008331299
Validation loss: 2.0880882176019813

Epoch: 5| Step: 7
Training loss: 1.8646137714385986
Validation loss: 2.088302925068845

Epoch: 5| Step: 8
Training loss: 1.4920603036880493
Validation loss: 2.061968395786901

Epoch: 5| Step: 9
Training loss: 1.5404925346374512
Validation loss: 2.070390050129224

Epoch: 5| Step: 10
Training loss: 1.5950862169265747
Validation loss: 2.066800791730163

Epoch: 503| Step: 0
Training loss: 1.6963188648223877
Validation loss: 2.0798363865062757

Epoch: 5| Step: 1
Training loss: 1.7385122776031494
Validation loss: 2.078437133501935

Epoch: 5| Step: 2
Training loss: 1.3776243925094604
Validation loss: 2.10044292993443

Epoch: 5| Step: 3
Training loss: 1.1548398733139038
Validation loss: 2.0901877957005657

Epoch: 5| Step: 4
Training loss: 2.2035319805145264
Validation loss: 2.119585132086149

Epoch: 5| Step: 5
Training loss: 1.493448257446289
Validation loss: 2.141265241048669

Epoch: 5| Step: 6
Training loss: 1.4117752313613892
Validation loss: 2.1371158117889077

Epoch: 5| Step: 7
Training loss: 1.5892970561981201
Validation loss: 2.1243257112400507

Epoch: 5| Step: 8
Training loss: 1.6278623342514038
Validation loss: 2.1454414257439236

Epoch: 5| Step: 9
Training loss: 2.1869704723358154
Validation loss: 2.13288031342209

Epoch: 5| Step: 10
Training loss: 1.5031875371932983
Validation loss: 2.109845781839022

Epoch: 504| Step: 0
Training loss: 1.394982933998108
Validation loss: 2.079026504229474

Epoch: 5| Step: 1
Training loss: 1.8425853252410889
Validation loss: 2.0689483278541156

Epoch: 5| Step: 2
Training loss: 1.781942367553711
Validation loss: 2.0805165511305614

Epoch: 5| Step: 3
Training loss: 1.6931121349334717
Validation loss: 2.04308299351764

Epoch: 5| Step: 4
Training loss: 2.3826591968536377
Validation loss: 2.0543278571098083

Epoch: 5| Step: 5
Training loss: 1.1597926616668701
Validation loss: 2.0689226068476194

Epoch: 5| Step: 6
Training loss: 2.0699849128723145
Validation loss: 2.073681903141801

Epoch: 5| Step: 7
Training loss: 1.6796419620513916
Validation loss: 2.0647390273309525

Epoch: 5| Step: 8
Training loss: 1.2215430736541748
Validation loss: 2.0585468892128236

Epoch: 5| Step: 9
Training loss: 1.2966196537017822
Validation loss: 2.078562231474025

Epoch: 5| Step: 10
Training loss: 1.3756601810455322
Validation loss: 2.0696127363430556

Epoch: 505| Step: 0
Training loss: 2.1389050483703613
Validation loss: 2.0964298761019142

Epoch: 5| Step: 1
Training loss: 1.2858619689941406
Validation loss: 2.1115337776881393

Epoch: 5| Step: 2
Training loss: 1.6770236492156982
Validation loss: 2.1329992612202964

Epoch: 5| Step: 3
Training loss: 1.5248417854309082
Validation loss: 2.1085096418216662

Epoch: 5| Step: 4
Training loss: 1.2396742105484009
Validation loss: 2.09541017393912

Epoch: 5| Step: 5
Training loss: 1.7599928379058838
Validation loss: 2.0766820394864647

Epoch: 5| Step: 6
Training loss: 1.226266860961914
Validation loss: 2.0595823923746743

Epoch: 5| Step: 7
Training loss: 2.095913887023926
Validation loss: 2.0375871299415507

Epoch: 5| Step: 8
Training loss: 1.3871443271636963
Validation loss: 2.035362628198439

Epoch: 5| Step: 9
Training loss: 1.6525322198867798
Validation loss: 2.0333353524566977

Epoch: 5| Step: 10
Training loss: 2.097463369369507
Validation loss: 2.0412381502889816

Epoch: 506| Step: 0
Training loss: 1.145148754119873
Validation loss: 2.0357307798119

Epoch: 5| Step: 1
Training loss: 2.456735372543335
Validation loss: 2.027812106634981

Epoch: 5| Step: 2
Training loss: 1.7858221530914307
Validation loss: 2.0351637845398276

Epoch: 5| Step: 3
Training loss: 1.8059934377670288
Validation loss: 2.0398397291860273

Epoch: 5| Step: 4
Training loss: 1.1272430419921875
Validation loss: 2.060831069946289

Epoch: 5| Step: 5
Training loss: 2.0721490383148193
Validation loss: 2.0801316025436565

Epoch: 5| Step: 6
Training loss: 1.3770240545272827
Validation loss: 2.0997028940467426

Epoch: 5| Step: 7
Training loss: 1.372847557067871
Validation loss: 2.1293717635575162

Epoch: 5| Step: 8
Training loss: 1.0737613439559937
Validation loss: 2.1506767401131253

Epoch: 5| Step: 9
Training loss: 2.1871864795684814
Validation loss: 2.1288197091830674

Epoch: 5| Step: 10
Training loss: 1.3561712503433228
Validation loss: 2.107312333199286

Epoch: 507| Step: 0
Training loss: 2.0265088081359863
Validation loss: 2.0852602617714995

Epoch: 5| Step: 1
Training loss: 1.89374577999115
Validation loss: 2.068147874647571

Epoch: 5| Step: 2
Training loss: 1.615368127822876
Validation loss: 2.054271344215639

Epoch: 5| Step: 3
Training loss: 0.9442076683044434
Validation loss: 2.0743362211411998

Epoch: 5| Step: 4
Training loss: 1.0451593399047852
Validation loss: 2.106933534786265

Epoch: 5| Step: 5
Training loss: 1.7338590621948242
Validation loss: 2.0867495318894744

Epoch: 5| Step: 6
Training loss: 2.1936068534851074
Validation loss: 2.0907730005120717

Epoch: 5| Step: 7
Training loss: 1.245754599571228
Validation loss: 2.0775184272437968

Epoch: 5| Step: 8
Training loss: 1.8473098278045654
Validation loss: 2.0694666985542542

Epoch: 5| Step: 9
Training loss: 1.5944963693618774
Validation loss: 2.093959846804219

Epoch: 5| Step: 10
Training loss: 1.671582579612732
Validation loss: 2.086796757995441

Epoch: 508| Step: 0
Training loss: 1.8169978857040405
Validation loss: 2.097571985695952

Epoch: 5| Step: 1
Training loss: 1.764155626296997
Validation loss: 2.086570385963686

Epoch: 5| Step: 2
Training loss: 1.2492668628692627
Validation loss: 2.0725573570497575

Epoch: 5| Step: 3
Training loss: 1.5353533029556274
Validation loss: 2.051836682904151

Epoch: 5| Step: 4
Training loss: 1.3044326305389404
Validation loss: 2.019022987734887

Epoch: 5| Step: 5
Training loss: 2.2091763019561768
Validation loss: 2.0209540974709297

Epoch: 5| Step: 6
Training loss: 1.95758056640625
Validation loss: 2.025201120684224

Epoch: 5| Step: 7
Training loss: 2.223659038543701
Validation loss: 2.026857473516977

Epoch: 5| Step: 8
Training loss: 1.71932053565979
Validation loss: 2.0303452194377942

Epoch: 5| Step: 9
Training loss: 1.2222503423690796
Validation loss: 2.0363497118796072

Epoch: 5| Step: 10
Training loss: 0.8576030135154724
Validation loss: 2.044041052941353

Epoch: 509| Step: 0
Training loss: 1.6934688091278076
Validation loss: 2.086443151197126

Epoch: 5| Step: 1
Training loss: 1.6728349924087524
Validation loss: 2.0939188464995353

Epoch: 5| Step: 2
Training loss: 2.226874828338623
Validation loss: 2.127618065444372

Epoch: 5| Step: 3
Training loss: 1.3884437084197998
Validation loss: 2.137153704961141

Epoch: 5| Step: 4
Training loss: 1.332697868347168
Validation loss: 2.137969955321281

Epoch: 5| Step: 5
Training loss: 1.9292552471160889
Validation loss: 2.136693782703851

Epoch: 5| Step: 6
Training loss: 1.8951904773712158
Validation loss: 2.1282746535475536

Epoch: 5| Step: 7
Training loss: 1.1242024898529053
Validation loss: 2.098935011894472

Epoch: 5| Step: 8
Training loss: 1.2420369386672974
Validation loss: 2.079685300909063

Epoch: 5| Step: 9
Training loss: 1.7742078304290771
Validation loss: 2.0549762146447295

Epoch: 5| Step: 10
Training loss: 1.4615857601165771
Validation loss: 2.034688539402459

Epoch: 510| Step: 0
Training loss: 2.104538679122925
Validation loss: 2.032817086865825

Epoch: 5| Step: 1
Training loss: 1.674389123916626
Validation loss: 2.038025381744549

Epoch: 5| Step: 2
Training loss: 1.316483736038208
Validation loss: 2.025020680119914

Epoch: 5| Step: 3
Training loss: 2.3735764026641846
Validation loss: 2.0443829157019175

Epoch: 5| Step: 4
Training loss: 1.6103641986846924
Validation loss: 2.050355303672052

Epoch: 5| Step: 5
Training loss: 1.7654939889907837
Validation loss: 2.0701421332615677

Epoch: 5| Step: 6
Training loss: 0.779167652130127
Validation loss: 2.0765113548565934

Epoch: 5| Step: 7
Training loss: 1.06940495967865
Validation loss: 2.0732255046085646

Epoch: 5| Step: 8
Training loss: 2.2202329635620117
Validation loss: 2.096266172265494

Epoch: 5| Step: 9
Training loss: 1.056322693824768
Validation loss: 2.1183063855735202

Epoch: 5| Step: 10
Training loss: 1.6729726791381836
Validation loss: 2.1068993845293598

Epoch: 511| Step: 0
Training loss: 2.0723462104797363
Validation loss: 2.1088854471842446

Epoch: 5| Step: 1
Training loss: 1.091447353363037
Validation loss: 2.1179287305442234

Epoch: 5| Step: 2
Training loss: 1.7029025554656982
Validation loss: 2.101925640977839

Epoch: 5| Step: 3
Training loss: 1.4620416164398193
Validation loss: 2.0953704221274263

Epoch: 5| Step: 4
Training loss: 1.4528450965881348
Validation loss: 2.0880692466612785

Epoch: 5| Step: 5
Training loss: 1.7102015018463135
Validation loss: 2.067665092406734

Epoch: 5| Step: 6
Training loss: 1.8060967922210693
Validation loss: 2.051895864548222

Epoch: 5| Step: 7
Training loss: 1.5841310024261475
Validation loss: 2.0711954703894992

Epoch: 5| Step: 8
Training loss: 1.5599143505096436
Validation loss: 2.0620639452370266

Epoch: 5| Step: 9
Training loss: 1.8554127216339111
Validation loss: 2.0395930326113136

Epoch: 5| Step: 10
Training loss: 1.3611387014389038
Validation loss: 2.0572671069893786

Epoch: 512| Step: 0
Training loss: 1.4449243545532227
Validation loss: 2.044965979873493

Epoch: 5| Step: 1
Training loss: 1.8781805038452148
Validation loss: 2.0600470278852727

Epoch: 5| Step: 2
Training loss: 0.982200026512146
Validation loss: 2.068468920646175

Epoch: 5| Step: 3
Training loss: 1.5061454772949219
Validation loss: 2.0817469243080384

Epoch: 5| Step: 4
Training loss: 1.5241105556488037
Validation loss: 2.0848247620367233

Epoch: 5| Step: 5
Training loss: 1.6249635219573975
Validation loss: 2.1302632567703084

Epoch: 5| Step: 6
Training loss: 1.577012538909912
Validation loss: 2.109522783628074

Epoch: 5| Step: 7
Training loss: 2.0853476524353027
Validation loss: 2.1073815745692097

Epoch: 5| Step: 8
Training loss: 1.8570451736450195
Validation loss: 2.1164177489537064

Epoch: 5| Step: 9
Training loss: 0.9275142550468445
Validation loss: 2.0970543712698

Epoch: 5| Step: 10
Training loss: 2.2189948558807373
Validation loss: 2.0872039025829685

Epoch: 513| Step: 0
Training loss: 1.6344192028045654
Validation loss: 2.090057976784245

Epoch: 5| Step: 1
Training loss: 1.766831398010254
Validation loss: 2.081019655350716

Epoch: 5| Step: 2
Training loss: 1.2635852098464966
Validation loss: 2.065816257589607

Epoch: 5| Step: 3
Training loss: 1.4438676834106445
Validation loss: 2.0560042101849794

Epoch: 5| Step: 4
Training loss: 1.542946457862854
Validation loss: 2.0421342170366676

Epoch: 5| Step: 5
Training loss: 1.4613471031188965
Validation loss: 2.0502559549065045

Epoch: 5| Step: 6
Training loss: 1.656170129776001
Validation loss: 2.031346439033426

Epoch: 5| Step: 7
Training loss: 1.5314910411834717
Validation loss: 2.0490514309175554

Epoch: 5| Step: 8
Training loss: 2.1740431785583496
Validation loss: 2.055551346912179

Epoch: 5| Step: 9
Training loss: 1.430506944656372
Validation loss: 2.0758446621638473

Epoch: 5| Step: 10
Training loss: 1.7252745628356934
Validation loss: 2.0810217113905054

Epoch: 514| Step: 0
Training loss: 1.9419904947280884
Validation loss: 2.1097033049470637

Epoch: 5| Step: 1
Training loss: 2.1434996128082275
Validation loss: 2.116239683602446

Epoch: 5| Step: 2
Training loss: 1.7095218896865845
Validation loss: 2.089490011174192

Epoch: 5| Step: 3
Training loss: 1.7352920770645142
Validation loss: 2.0984492250668105

Epoch: 5| Step: 4
Training loss: 2.3483684062957764
Validation loss: 2.0827145704659085

Epoch: 5| Step: 5
Training loss: 1.0771803855895996
Validation loss: 2.071649815446587

Epoch: 5| Step: 6
Training loss: 1.5940632820129395
Validation loss: 2.0422978247365644

Epoch: 5| Step: 7
Training loss: 1.1691601276397705
Validation loss: 2.0419289142854753

Epoch: 5| Step: 8
Training loss: 1.132194995880127
Validation loss: 2.028856764557541

Epoch: 5| Step: 9
Training loss: 1.1305265426635742
Validation loss: 2.0350252838544947

Epoch: 5| Step: 10
Training loss: 1.4443167448043823
Validation loss: 2.0287379321231636

Epoch: 515| Step: 0
Training loss: 1.3147830963134766
Validation loss: 2.0202582600296184

Epoch: 5| Step: 1
Training loss: 1.6256253719329834
Validation loss: 2.02892759923012

Epoch: 5| Step: 2
Training loss: 1.500796914100647
Validation loss: 2.037381115780082

Epoch: 5| Step: 3
Training loss: 1.3776135444641113
Validation loss: 2.046614086115232

Epoch: 5| Step: 4
Training loss: 2.2332446575164795
Validation loss: 2.059446232293242

Epoch: 5| Step: 5
Training loss: 0.9619868993759155
Validation loss: 2.0787515665895198

Epoch: 5| Step: 6
Training loss: 1.603040337562561
Validation loss: 2.081069387415404

Epoch: 5| Step: 7
Training loss: 1.9268518686294556
Validation loss: 2.0736440612423803

Epoch: 5| Step: 8
Training loss: 1.7505995035171509
Validation loss: 2.0816292173119

Epoch: 5| Step: 9
Training loss: 1.1900237798690796
Validation loss: 2.0738018199961674

Epoch: 5| Step: 10
Training loss: 2.2685434818267822
Validation loss: 2.059877767357775

Epoch: 516| Step: 0
Training loss: 1.215772032737732
Validation loss: 2.0639250291291105

Epoch: 5| Step: 1
Training loss: 1.9849331378936768
Validation loss: 2.0708092310095347

Epoch: 5| Step: 2
Training loss: 1.1398816108703613
Validation loss: 2.057980123386588

Epoch: 5| Step: 3
Training loss: 2.086470365524292
Validation loss: 2.0411865865030596

Epoch: 5| Step: 4
Training loss: 1.4000990390777588
Validation loss: 2.071327486345845

Epoch: 5| Step: 5
Training loss: 1.386578917503357
Validation loss: 2.0490304154734456

Epoch: 5| Step: 6
Training loss: 1.2429295778274536
Validation loss: 2.0310207272088654

Epoch: 5| Step: 7
Training loss: 1.9001340866088867
Validation loss: 2.0387205308483494

Epoch: 5| Step: 8
Training loss: 1.525980830192566
Validation loss: 2.031067488014057

Epoch: 5| Step: 9
Training loss: 1.4584991931915283
Validation loss: 2.037059574998835

Epoch: 5| Step: 10
Training loss: 2.1293585300445557
Validation loss: 2.031249789781468

Epoch: 517| Step: 0
Training loss: 1.7999513149261475
Validation loss: 2.0485066675370738

Epoch: 5| Step: 1
Training loss: 1.4931920766830444
Validation loss: 2.0615113012252317

Epoch: 5| Step: 2
Training loss: 0.8240629434585571
Validation loss: 2.0600995568818945

Epoch: 5| Step: 3
Training loss: 1.5470999479293823
Validation loss: 2.0611633228999313

Epoch: 5| Step: 4
Training loss: 1.6183198690414429
Validation loss: 2.062072992324829

Epoch: 5| Step: 5
Training loss: 1.6942462921142578
Validation loss: 2.0734942087563137

Epoch: 5| Step: 6
Training loss: 1.3790557384490967
Validation loss: 2.0799960397904917

Epoch: 5| Step: 7
Training loss: 1.373169183731079
Validation loss: 2.0628831271202333

Epoch: 5| Step: 8
Training loss: 2.00400972366333
Validation loss: 2.0407551052749797

Epoch: 5| Step: 9
Training loss: 2.0838911533355713
Validation loss: 2.062485164211642

Epoch: 5| Step: 10
Training loss: 1.435372233390808
Validation loss: 2.054098868882784

Epoch: 518| Step: 0
Training loss: 1.8779172897338867
Validation loss: 2.065312562450286

Epoch: 5| Step: 1
Training loss: 1.2720649242401123
Validation loss: 2.0391452325287687

Epoch: 5| Step: 2
Training loss: 1.556753158569336
Validation loss: 2.0361488942177064

Epoch: 5| Step: 3
Training loss: 1.132907509803772
Validation loss: 2.0293902812465543

Epoch: 5| Step: 4
Training loss: 1.8960930109024048
Validation loss: 2.042198383679954

Epoch: 5| Step: 5
Training loss: 1.5210676193237305
Validation loss: 2.0414974779211064

Epoch: 5| Step: 6
Training loss: 1.9747486114501953
Validation loss: 2.0343571478320706

Epoch: 5| Step: 7
Training loss: 1.991565465927124
Validation loss: 2.043178689095282

Epoch: 5| Step: 8
Training loss: 1.4935117959976196
Validation loss: 2.0362393625320925

Epoch: 5| Step: 9
Training loss: 1.338728666305542
Validation loss: 2.0425028031872166

Epoch: 5| Step: 10
Training loss: 1.2873687744140625
Validation loss: 2.0496824326053744

Epoch: 519| Step: 0
Training loss: 1.318227767944336
Validation loss: 2.072550876166231

Epoch: 5| Step: 1
Training loss: 0.9615898132324219
Validation loss: 2.0545621687366116

Epoch: 5| Step: 2
Training loss: 1.4166978597640991
Validation loss: 2.0777902013512066

Epoch: 5| Step: 3
Training loss: 2.022709369659424
Validation loss: 2.106753400577012

Epoch: 5| Step: 4
Training loss: 1.4842545986175537
Validation loss: 2.0901993615652925

Epoch: 5| Step: 5
Training loss: 1.6337945461273193
Validation loss: 2.083924151236011

Epoch: 5| Step: 6
Training loss: 2.1767144203186035
Validation loss: 2.0635993275591122

Epoch: 5| Step: 7
Training loss: 1.7252953052520752
Validation loss: 2.0415360812217958

Epoch: 5| Step: 8
Training loss: 1.463224172592163
Validation loss: 2.0442941509267336

Epoch: 5| Step: 9
Training loss: 1.6210672855377197
Validation loss: 2.026749026390814

Epoch: 5| Step: 10
Training loss: 1.3960620164871216
Validation loss: 2.0223614887524675

Epoch: 520| Step: 0
Training loss: 1.758521318435669
Validation loss: 2.023734883595538

Epoch: 5| Step: 1
Training loss: 1.0916519165039062
Validation loss: 2.0470949629301667

Epoch: 5| Step: 2
Training loss: 1.6263891458511353
Validation loss: 2.047321217034453

Epoch: 5| Step: 3
Training loss: 1.331805944442749
Validation loss: 2.049134110891691

Epoch: 5| Step: 4
Training loss: 1.70099675655365
Validation loss: 2.070035344810896

Epoch: 5| Step: 5
Training loss: 1.5098416805267334
Validation loss: 2.0863420194195164

Epoch: 5| Step: 6
Training loss: 1.6064081192016602
Validation loss: 2.0808481990650134

Epoch: 5| Step: 7
Training loss: 1.5308116674423218
Validation loss: 2.0635248384168072

Epoch: 5| Step: 8
Training loss: 1.4682849645614624
Validation loss: 2.0660825083332677

Epoch: 5| Step: 9
Training loss: 1.6241495609283447
Validation loss: 2.048496129692242

Epoch: 5| Step: 10
Training loss: 2.064119338989258
Validation loss: 2.0408197244008384

Epoch: 521| Step: 0
Training loss: 1.9941139221191406
Validation loss: 2.0189658236759964

Epoch: 5| Step: 1
Training loss: 0.7067597508430481
Validation loss: 2.032364963203348

Epoch: 5| Step: 2
Training loss: 1.4654819965362549
Validation loss: 2.016998424324938

Epoch: 5| Step: 3
Training loss: 1.9849001169204712
Validation loss: 2.0244385157862017

Epoch: 5| Step: 4
Training loss: 1.1749098300933838
Validation loss: 2.0202681723461358

Epoch: 5| Step: 5
Training loss: 1.8705962896347046
Validation loss: 2.0367086023412724

Epoch: 5| Step: 6
Training loss: 1.3580472469329834
Validation loss: 2.036098510988297

Epoch: 5| Step: 7
Training loss: 1.623327612876892
Validation loss: 2.0494382560894056

Epoch: 5| Step: 8
Training loss: 1.2766468524932861
Validation loss: 2.068978771086662

Epoch: 5| Step: 9
Training loss: 1.8427207469940186
Validation loss: 2.0758089288588493

Epoch: 5| Step: 10
Training loss: 1.949183702468872
Validation loss: 2.1053793173964306

Epoch: 522| Step: 0
Training loss: 1.7809451818466187
Validation loss: 2.0984776161050283

Epoch: 5| Step: 1
Training loss: 1.1355750560760498
Validation loss: 2.0845977465311685

Epoch: 5| Step: 2
Training loss: 1.6848258972167969
Validation loss: 2.067213776291058

Epoch: 5| Step: 3
Training loss: 1.8427274227142334
Validation loss: 2.0410237081589235

Epoch: 5| Step: 4
Training loss: 1.1979665756225586
Validation loss: 2.030878507962791

Epoch: 5| Step: 5
Training loss: 1.5336462259292603
Validation loss: 2.0187799981845322

Epoch: 5| Step: 6
Training loss: 1.826507568359375
Validation loss: 2.0095757489563315

Epoch: 5| Step: 7
Training loss: 1.3207743167877197
Validation loss: 2.00607757670905

Epoch: 5| Step: 8
Training loss: 1.7957544326782227
Validation loss: 2.0083886167054534

Epoch: 5| Step: 9
Training loss: 1.5977762937545776
Validation loss: 1.998943212211773

Epoch: 5| Step: 10
Training loss: 1.569069266319275
Validation loss: 2.020431980010002

Epoch: 523| Step: 0
Training loss: 1.6394774913787842
Validation loss: 2.0135786815356185

Epoch: 5| Step: 1
Training loss: 1.3251315355300903
Validation loss: 2.0553571421612977

Epoch: 5| Step: 2
Training loss: 1.0395798683166504
Validation loss: 2.0481128102989605

Epoch: 5| Step: 3
Training loss: 1.8065214157104492
Validation loss: 2.083668557546472

Epoch: 5| Step: 4
Training loss: 1.9158174991607666
Validation loss: 2.088197390238444

Epoch: 5| Step: 5
Training loss: 1.1226478815078735
Validation loss: 2.0871848649876092

Epoch: 5| Step: 6
Training loss: 1.581390619277954
Validation loss: 2.0735340605499926

Epoch: 5| Step: 7
Training loss: 1.53743577003479
Validation loss: 2.054094583757462

Epoch: 5| Step: 8
Training loss: 1.1668665409088135
Validation loss: 2.069330417981712

Epoch: 5| Step: 9
Training loss: 1.898101568222046
Validation loss: 2.0624383764882244

Epoch: 5| Step: 10
Training loss: 2.149559736251831
Validation loss: 2.0717076511793238

Epoch: 524| Step: 0
Training loss: 1.6373062133789062
Validation loss: 2.0534188926860852

Epoch: 5| Step: 1
Training loss: 0.8711321949958801
Validation loss: 2.064094202492827

Epoch: 5| Step: 2
Training loss: 1.0388275384902954
Validation loss: 2.054059415735224

Epoch: 5| Step: 3
Training loss: 1.6306488513946533
Validation loss: 2.107651449018909

Epoch: 5| Step: 4
Training loss: 1.4945755004882812
Validation loss: 2.075248784916375

Epoch: 5| Step: 5
Training loss: 2.106234312057495
Validation loss: 2.11678074764949

Epoch: 5| Step: 6
Training loss: 1.4330494403839111
Validation loss: 2.116115541868312

Epoch: 5| Step: 7
Training loss: 1.4049075841903687
Validation loss: 2.1377118941276305

Epoch: 5| Step: 8
Training loss: 0.9468683004379272
Validation loss: 2.124809076709132

Epoch: 5| Step: 9
Training loss: 2.6870665550231934
Validation loss: 2.1242012041871265

Epoch: 5| Step: 10
Training loss: 2.031567096710205
Validation loss: 2.0925828679915397

Epoch: 525| Step: 0
Training loss: 1.4066276550292969
Validation loss: 2.0640149642062444

Epoch: 5| Step: 1
Training loss: 1.684342384338379
Validation loss: 2.054243741496917

Epoch: 5| Step: 2
Training loss: 2.6781234741210938
Validation loss: 2.021568206048781

Epoch: 5| Step: 3
Training loss: 0.8904123306274414
Validation loss: 2.0411807003841607

Epoch: 5| Step: 4
Training loss: 1.2631690502166748
Validation loss: 2.0363954241557787

Epoch: 5| Step: 5
Training loss: 1.1525352001190186
Validation loss: 2.026525297472554

Epoch: 5| Step: 6
Training loss: 1.4663355350494385
Validation loss: 2.0286483713375625

Epoch: 5| Step: 7
Training loss: 1.6349632740020752
Validation loss: 2.0390147662931875

Epoch: 5| Step: 8
Training loss: 1.430634617805481
Validation loss: 2.040658958496586

Epoch: 5| Step: 9
Training loss: 2.229557514190674
Validation loss: 2.0382361796594437

Epoch: 5| Step: 10
Training loss: 1.263713002204895
Validation loss: 2.027005259708692

Epoch: 526| Step: 0
Training loss: 1.6421293020248413
Validation loss: 2.048734498280351

Epoch: 5| Step: 1
Training loss: 2.2167325019836426
Validation loss: 2.071600402555158

Epoch: 5| Step: 2
Training loss: 1.0852562189102173
Validation loss: 2.089265056835708

Epoch: 5| Step: 3
Training loss: 1.6021360158920288
Validation loss: 2.11474871635437

Epoch: 5| Step: 4
Training loss: 1.7292753458023071
Validation loss: 2.1427821087580856

Epoch: 5| Step: 5
Training loss: 1.928272008895874
Validation loss: 2.142161096296003

Epoch: 5| Step: 6
Training loss: 1.6655652523040771
Validation loss: 2.1581950469683577

Epoch: 5| Step: 7
Training loss: 1.5041543245315552
Validation loss: 2.1255244978012575

Epoch: 5| Step: 8
Training loss: 0.9111536741256714
Validation loss: 2.088378688340546

Epoch: 5| Step: 9
Training loss: 1.390500783920288
Validation loss: 2.06612983826668

Epoch: 5| Step: 10
Training loss: 1.4526054859161377
Validation loss: 2.0405796343280422

Epoch: 527| Step: 0
Training loss: 1.840383529663086
Validation loss: 2.0258835028576594

Epoch: 5| Step: 1
Training loss: 1.5452728271484375
Validation loss: 2.0246163991189774

Epoch: 5| Step: 2
Training loss: 2.0778915882110596
Validation loss: 2.0352517533045944

Epoch: 5| Step: 3
Training loss: 1.257430911064148
Validation loss: 2.0117168913605394

Epoch: 5| Step: 4
Training loss: 1.2493318319320679
Validation loss: 2.038467280326351

Epoch: 5| Step: 5
Training loss: 1.6062513589859009
Validation loss: 2.0452116586828746

Epoch: 5| Step: 6
Training loss: 1.2798311710357666
Validation loss: 2.0349579626514065

Epoch: 5| Step: 7
Training loss: 1.377419114112854
Validation loss: 2.080932690251258

Epoch: 5| Step: 8
Training loss: 1.2751621007919312
Validation loss: 2.051114034909074

Epoch: 5| Step: 9
Training loss: 1.5926700830459595
Validation loss: 2.087010375915035

Epoch: 5| Step: 10
Training loss: 1.8704509735107422
Validation loss: 2.114521026611328

Epoch: 528| Step: 0
Training loss: 1.6468703746795654
Validation loss: 2.0810191336498467

Epoch: 5| Step: 1
Training loss: 1.3770153522491455
Validation loss: 2.0542102936775453

Epoch: 5| Step: 2
Training loss: 0.9460710287094116
Validation loss: 2.0382786899484615

Epoch: 5| Step: 3
Training loss: 2.2115745544433594
Validation loss: 2.026394005744688

Epoch: 5| Step: 4
Training loss: 1.3841229677200317
Validation loss: 2.0256420373916626

Epoch: 5| Step: 5
Training loss: 1.7535314559936523
Validation loss: 2.0101460308156986

Epoch: 5| Step: 6
Training loss: 1.674970030784607
Validation loss: 2.010554867406045

Epoch: 5| Step: 7
Training loss: 1.3894743919372559
Validation loss: 2.0306092744232505

Epoch: 5| Step: 8
Training loss: 1.0555882453918457
Validation loss: 2.0177368822918145

Epoch: 5| Step: 9
Training loss: 2.007185220718384
Validation loss: 2.032597582827332

Epoch: 5| Step: 10
Training loss: 1.419817328453064
Validation loss: 2.0465988459125644

Epoch: 529| Step: 0
Training loss: 0.9431096911430359
Validation loss: 2.0413371568085044

Epoch: 5| Step: 1
Training loss: 1.567276120185852
Validation loss: 2.0629134049979587

Epoch: 5| Step: 2
Training loss: 1.934775948524475
Validation loss: 2.063693038878902

Epoch: 5| Step: 3
Training loss: 1.7925338745117188
Validation loss: 2.0582616713739212

Epoch: 5| Step: 4
Training loss: 1.607313871383667
Validation loss: 2.077649031915972

Epoch: 5| Step: 5
Training loss: 1.5283173322677612
Validation loss: 2.0614417983639624

Epoch: 5| Step: 6
Training loss: 1.5913655757904053
Validation loss: 2.042237017744331

Epoch: 5| Step: 7
Training loss: 1.4260581731796265
Validation loss: 2.0456775183318765

Epoch: 5| Step: 8
Training loss: 1.597229242324829
Validation loss: 2.0480055373202086

Epoch: 5| Step: 9
Training loss: 1.153246283531189
Validation loss: 2.0370515456763645

Epoch: 5| Step: 10
Training loss: 1.7730417251586914
Validation loss: 2.0279430189440326

Epoch: 530| Step: 0
Training loss: 1.7507648468017578
Validation loss: 2.048434154961699

Epoch: 5| Step: 1
Training loss: 1.2938461303710938
Validation loss: 2.04096806433893

Epoch: 5| Step: 2
Training loss: 0.8891092538833618
Validation loss: 2.0410473833801928

Epoch: 5| Step: 3
Training loss: 1.8519083261489868
Validation loss: 2.042429739429105

Epoch: 5| Step: 4
Training loss: 1.6115598678588867
Validation loss: 2.0690593565663984

Epoch: 5| Step: 5
Training loss: 2.0239083766937256
Validation loss: 2.073602784064508

Epoch: 5| Step: 6
Training loss: 1.0758970975875854
Validation loss: 2.061850740063575

Epoch: 5| Step: 7
Training loss: 1.7849254608154297
Validation loss: 2.061163333154494

Epoch: 5| Step: 8
Training loss: 1.5705772638320923
Validation loss: 2.075470739795316

Epoch: 5| Step: 9
Training loss: 1.4808458089828491
Validation loss: 2.068030026651198

Epoch: 5| Step: 10
Training loss: 1.3980746269226074
Validation loss: 2.078003809016238

Epoch: 531| Step: 0
Training loss: 1.4462645053863525
Validation loss: 2.109860248463128

Epoch: 5| Step: 1
Training loss: 2.1626198291778564
Validation loss: 2.1138459097954536

Epoch: 5| Step: 2
Training loss: 1.0085411071777344
Validation loss: 2.1003794811105214

Epoch: 5| Step: 3
Training loss: 1.362494707107544
Validation loss: 2.092919680380052

Epoch: 5| Step: 4
Training loss: 1.6586236953735352
Validation loss: 2.0807194837959866

Epoch: 5| Step: 5
Training loss: 1.876979112625122
Validation loss: 2.039786884861608

Epoch: 5| Step: 6
Training loss: 1.4484716653823853
Validation loss: 2.023879313981661

Epoch: 5| Step: 7
Training loss: 0.9113004803657532
Validation loss: 2.0115601426811627

Epoch: 5| Step: 8
Training loss: 1.8201391696929932
Validation loss: 2.0065320307208645

Epoch: 5| Step: 9
Training loss: 1.6696417331695557
Validation loss: 2.0070309972250335

Epoch: 5| Step: 10
Training loss: 1.4870729446411133
Validation loss: 2.026172955830892

Epoch: 532| Step: 0
Training loss: 1.4440505504608154
Validation loss: 2.012943375495172

Epoch: 5| Step: 1
Training loss: 1.1016427278518677
Validation loss: 2.0365522087261243

Epoch: 5| Step: 2
Training loss: 1.6156975030899048
Validation loss: 2.0313922128369732

Epoch: 5| Step: 3
Training loss: 1.359615445137024
Validation loss: 2.041766947315585

Epoch: 5| Step: 4
Training loss: 1.497723937034607
Validation loss: 2.027845072489913

Epoch: 5| Step: 5
Training loss: 1.3263766765594482
Validation loss: 2.0334717509567097

Epoch: 5| Step: 6
Training loss: 2.1284546852111816
Validation loss: 2.037225155420201

Epoch: 5| Step: 7
Training loss: 1.8582420349121094
Validation loss: 2.067717147129838

Epoch: 5| Step: 8
Training loss: 1.6313121318817139
Validation loss: 2.077153380199145

Epoch: 5| Step: 9
Training loss: 1.7189782857894897
Validation loss: 2.066131022668654

Epoch: 5| Step: 10
Training loss: 0.9751113653182983
Validation loss: 2.09113565311637

Epoch: 533| Step: 0
Training loss: 1.397362232208252
Validation loss: 2.0953971519265124

Epoch: 5| Step: 1
Training loss: 2.2255260944366455
Validation loss: 2.0915115699973157

Epoch: 5| Step: 2
Training loss: 1.045472502708435
Validation loss: 2.080524226670624

Epoch: 5| Step: 3
Training loss: 1.518265962600708
Validation loss: 2.09760033699774

Epoch: 5| Step: 4
Training loss: 1.688602089881897
Validation loss: 2.076915071856591

Epoch: 5| Step: 5
Training loss: 1.2417761087417603
Validation loss: 2.058764034701932

Epoch: 5| Step: 6
Training loss: 1.3422346115112305
Validation loss: 2.0538801480365056

Epoch: 5| Step: 7
Training loss: 1.5177425146102905
Validation loss: 2.0376653171354726

Epoch: 5| Step: 8
Training loss: 0.9813228845596313
Validation loss: 2.0157948437557427

Epoch: 5| Step: 9
Training loss: 2.0888075828552246
Validation loss: 2.041119997219373

Epoch: 5| Step: 10
Training loss: 1.5979435443878174
Validation loss: 2.0176283877382994

Epoch: 534| Step: 0
Training loss: 1.4348794221878052
Validation loss: 2.0399830674612396

Epoch: 5| Step: 1
Training loss: 1.418100118637085
Validation loss: 2.045508428286481

Epoch: 5| Step: 2
Training loss: 1.4898138046264648
Validation loss: 2.0369439932607833

Epoch: 5| Step: 3
Training loss: 1.253940463066101
Validation loss: 2.021221827435237

Epoch: 5| Step: 4
Training loss: 1.1237108707427979
Validation loss: 2.021369118844309

Epoch: 5| Step: 5
Training loss: 2.261470079421997
Validation loss: 2.016854665612662

Epoch: 5| Step: 6
Training loss: 1.2898149490356445
Validation loss: 2.023073411756946

Epoch: 5| Step: 7
Training loss: 1.6257225275039673
Validation loss: 2.0070389291291595

Epoch: 5| Step: 8
Training loss: 1.6921405792236328
Validation loss: 2.0132289548074045

Epoch: 5| Step: 9
Training loss: 1.379425048828125
Validation loss: 2.0209994136646228

Epoch: 5| Step: 10
Training loss: 1.748590350151062
Validation loss: 2.0270737319864254

Epoch: 535| Step: 0
Training loss: 1.85483717918396
Validation loss: 2.0304892601505404

Epoch: 5| Step: 1
Training loss: 1.2658154964447021
Validation loss: 2.0316140190247567

Epoch: 5| Step: 2
Training loss: 1.7408123016357422
Validation loss: 2.033389832383843

Epoch: 5| Step: 3
Training loss: 1.3679726123809814
Validation loss: 2.039380560639084

Epoch: 5| Step: 4
Training loss: 1.0061798095703125
Validation loss: 2.0572960992013254

Epoch: 5| Step: 5
Training loss: 1.9712908267974854
Validation loss: 2.067779638433969

Epoch: 5| Step: 6
Training loss: 2.092522382736206
Validation loss: 2.06833650219825

Epoch: 5| Step: 7
Training loss: 1.7138967514038086
Validation loss: 2.0505110845770886

Epoch: 5| Step: 8
Training loss: 2.0420780181884766
Validation loss: 2.0365248828805904

Epoch: 5| Step: 9
Training loss: 0.6328102350234985
Validation loss: 2.039544233711817

Epoch: 5| Step: 10
Training loss: 0.7964189052581787
Validation loss: 2.0075767501708

Epoch: 536| Step: 0
Training loss: 1.407875657081604
Validation loss: 2.0072567668012393

Epoch: 5| Step: 1
Training loss: 1.642300009727478
Validation loss: 1.9984294099192466

Epoch: 5| Step: 2
Training loss: 1.3730459213256836
Validation loss: 2.009285226944954

Epoch: 5| Step: 3
Training loss: 1.741725206375122
Validation loss: 2.0152781419856574

Epoch: 5| Step: 4
Training loss: 1.3795465230941772
Validation loss: 2.027004349616266

Epoch: 5| Step: 5
Training loss: 1.0696685314178467
Validation loss: 2.0542774085075624

Epoch: 5| Step: 6
Training loss: 1.7551448345184326
Validation loss: 2.0426914820107083

Epoch: 5| Step: 7
Training loss: 1.8675460815429688
Validation loss: 2.0366673648998304

Epoch: 5| Step: 8
Training loss: 1.2959924936294556
Validation loss: 2.055019627335251

Epoch: 5| Step: 9
Training loss: 1.3587720394134521
Validation loss: 2.0389683169703328

Epoch: 5| Step: 10
Training loss: 1.5509027242660522
Validation loss: 2.0326237409345564

Epoch: 537| Step: 0
Training loss: 1.4996745586395264
Validation loss: 2.001634467032648

Epoch: 5| Step: 1
Training loss: 1.201836109161377
Validation loss: 2.032150049363413

Epoch: 5| Step: 2
Training loss: 1.0522708892822266
Validation loss: 2.027966432673957

Epoch: 5| Step: 3
Training loss: 1.7438281774520874
Validation loss: 2.0129881007696993

Epoch: 5| Step: 4
Training loss: 1.1110185384750366
Validation loss: 2.0135098400936333

Epoch: 5| Step: 5
Training loss: 1.5558183193206787
Validation loss: 2.0046830331125567

Epoch: 5| Step: 6
Training loss: 1.3120496273040771
Validation loss: 1.992737094561259

Epoch: 5| Step: 7
Training loss: 1.9765723943710327
Validation loss: 1.9872087394037554

Epoch: 5| Step: 8
Training loss: 1.5357232093811035
Validation loss: 1.9942521510585662

Epoch: 5| Step: 9
Training loss: 1.9089794158935547
Validation loss: 1.9857890093198387

Epoch: 5| Step: 10
Training loss: 1.5251834392547607
Validation loss: 1.999991052894182

Epoch: 538| Step: 0
Training loss: 1.5384629964828491
Validation loss: 1.9861346431957778

Epoch: 5| Step: 1
Training loss: 1.643402099609375
Validation loss: 2.011820920052067

Epoch: 5| Step: 2
Training loss: 1.539227843284607
Validation loss: 2.0063896640654533

Epoch: 5| Step: 3
Training loss: 1.523794412612915
Validation loss: 2.0474170484850482

Epoch: 5| Step: 4
Training loss: 1.6798549890518188
Validation loss: 2.0505981265857653

Epoch: 5| Step: 5
Training loss: 1.5567634105682373
Validation loss: 2.0509406238473873

Epoch: 5| Step: 6
Training loss: 1.2625558376312256
Validation loss: 2.0819860478883148

Epoch: 5| Step: 7
Training loss: 1.5988218784332275
Validation loss: 2.0964085773755143

Epoch: 5| Step: 8
Training loss: 1.5816761255264282
Validation loss: 2.0958756964693785

Epoch: 5| Step: 9
Training loss: 1.5587408542633057
Validation loss: 2.073064475931147

Epoch: 5| Step: 10
Training loss: 0.9075903296470642
Validation loss: 2.047242469685052

Epoch: 539| Step: 0
Training loss: 1.6367638111114502
Validation loss: 2.0428149866801437

Epoch: 5| Step: 1
Training loss: 2.0277669429779053
Validation loss: 2.028283930593921

Epoch: 5| Step: 2
Training loss: 1.1486130952835083
Validation loss: 2.017441575245191

Epoch: 5| Step: 3
Training loss: 1.1918041706085205
Validation loss: 2.044478790734404

Epoch: 5| Step: 4
Training loss: 1.6133403778076172
Validation loss: 2.010280834731235

Epoch: 5| Step: 5
Training loss: 1.2775553464889526
Validation loss: 2.0233287170369136

Epoch: 5| Step: 6
Training loss: 1.351226568222046
Validation loss: 2.004216314643942

Epoch: 5| Step: 7
Training loss: 2.222505569458008
Validation loss: 2.0105070644809353

Epoch: 5| Step: 8
Training loss: 1.202675223350525
Validation loss: 1.9891754042717718

Epoch: 5| Step: 9
Training loss: 1.36586594581604
Validation loss: 2.0117220917055683

Epoch: 5| Step: 10
Training loss: 1.2918741703033447
Validation loss: 2.0290683238737044

Epoch: 540| Step: 0
Training loss: 1.068171501159668
Validation loss: 2.036789624921737

Epoch: 5| Step: 1
Training loss: 1.4579845666885376
Validation loss: 2.0504385194470807

Epoch: 5| Step: 2
Training loss: 1.9853944778442383
Validation loss: 2.040694704619787

Epoch: 5| Step: 3
Training loss: 1.560291051864624
Validation loss: 2.0584874076227986

Epoch: 5| Step: 4
Training loss: 0.8491369485855103
Validation loss: 2.037833341988184

Epoch: 5| Step: 5
Training loss: 1.5663131475448608
Validation loss: 2.02589701965291

Epoch: 5| Step: 6
Training loss: 1.4085201025009155
Validation loss: 2.0004929547668784

Epoch: 5| Step: 7
Training loss: 1.4766438007354736
Validation loss: 1.9909730688218148

Epoch: 5| Step: 8
Training loss: 1.507964849472046
Validation loss: 1.9918119240832586

Epoch: 5| Step: 9
Training loss: 1.4519097805023193
Validation loss: 1.978427420380295

Epoch: 5| Step: 10
Training loss: 2.0884671211242676
Validation loss: 2.002874779444869

Epoch: 541| Step: 0
Training loss: 1.2727384567260742
Validation loss: 2.000525248947964

Epoch: 5| Step: 1
Training loss: 1.6639817953109741
Validation loss: 2.010922681900763

Epoch: 5| Step: 2
Training loss: 0.986491322517395
Validation loss: 2.0722868288716962

Epoch: 5| Step: 3
Training loss: 0.7622069120407104
Validation loss: 2.0648333539244947

Epoch: 5| Step: 4
Training loss: 1.217840313911438
Validation loss: 2.0564221310359176

Epoch: 5| Step: 5
Training loss: 1.6627233028411865
Validation loss: 2.0381354298642886

Epoch: 5| Step: 6
Training loss: 1.8700745105743408
Validation loss: 2.015143605970567

Epoch: 5| Step: 7
Training loss: 1.7398078441619873
Validation loss: 2.010728689932054

Epoch: 5| Step: 8
Training loss: 1.6363837718963623
Validation loss: 2.0055389891388598

Epoch: 5| Step: 9
Training loss: 1.7742153406143188
Validation loss: 2.0159594987028386

Epoch: 5| Step: 10
Training loss: 1.7226295471191406
Validation loss: 1.996684274365825

Epoch: 542| Step: 0
Training loss: 1.3444724082946777
Validation loss: 2.0144586819474415

Epoch: 5| Step: 1
Training loss: 1.6325242519378662
Validation loss: 2.0239919744512087

Epoch: 5| Step: 2
Training loss: 1.2620609998703003
Validation loss: 1.9875180516191708

Epoch: 5| Step: 3
Training loss: 1.555800199508667
Validation loss: 2.0301392616764193

Epoch: 5| Step: 4
Training loss: 1.404134750366211
Validation loss: 2.0286860709549277

Epoch: 5| Step: 5
Training loss: 1.2590620517730713
Validation loss: 2.0197804051060833

Epoch: 5| Step: 6
Training loss: 1.707676649093628
Validation loss: 2.018434647590883

Epoch: 5| Step: 7
Training loss: 0.95191490650177
Validation loss: 1.9930294431665891

Epoch: 5| Step: 8
Training loss: 2.025622606277466
Validation loss: 1.9845750652333742

Epoch: 5| Step: 9
Training loss: 1.2785310745239258
Validation loss: 1.992693603679698

Epoch: 5| Step: 10
Training loss: 1.7454451322555542
Validation loss: 1.9888383829465477

Epoch: 543| Step: 0
Training loss: 1.1347039937973022
Validation loss: 2.0091992937108523

Epoch: 5| Step: 1
Training loss: 1.854518175125122
Validation loss: 1.9849788424789265

Epoch: 5| Step: 2
Training loss: 1.3677560091018677
Validation loss: 1.97555786050776

Epoch: 5| Step: 3
Training loss: 1.5517852306365967
Validation loss: 1.9788738501969205

Epoch: 5| Step: 4
Training loss: 1.6102184057235718
Validation loss: 1.9830122558019494

Epoch: 5| Step: 5
Training loss: 1.547607421875
Validation loss: 1.9849997540955902

Epoch: 5| Step: 6
Training loss: 1.3812386989593506
Validation loss: 2.0010549611942743

Epoch: 5| Step: 7
Training loss: 1.0039583444595337
Validation loss: 2.0085163654819613

Epoch: 5| Step: 8
Training loss: 1.9275844097137451
Validation loss: 2.0019532083183207

Epoch: 5| Step: 9
Training loss: 1.14501953125
Validation loss: 2.029766187872938

Epoch: 5| Step: 10
Training loss: 1.6959342956542969
Validation loss: 2.0568326596290833

Epoch: 544| Step: 0
Training loss: 1.9218757152557373
Validation loss: 2.043155616329562

Epoch: 5| Step: 1
Training loss: 1.5406743288040161
Validation loss: 2.042609058400636

Epoch: 5| Step: 2
Training loss: 1.468896508216858
Validation loss: 2.0276849551867415

Epoch: 5| Step: 3
Training loss: 1.9529927968978882
Validation loss: 2.0648897847821637

Epoch: 5| Step: 4
Training loss: 1.1675100326538086
Validation loss: 2.0254368141133297

Epoch: 5| Step: 5
Training loss: 1.03900945186615
Validation loss: 2.0431326102184992

Epoch: 5| Step: 6
Training loss: 1.5666208267211914
Validation loss: 2.0206055910356584

Epoch: 5| Step: 7
Training loss: 1.2252731323242188
Validation loss: 2.0309659319539226

Epoch: 5| Step: 8
Training loss: 1.5224025249481201
Validation loss: 2.032132999871367

Epoch: 5| Step: 9
Training loss: 1.0400675535202026
Validation loss: 2.034095528305218

Epoch: 5| Step: 10
Training loss: 1.675755262374878
Validation loss: 2.021173072117631

Epoch: 545| Step: 0
Training loss: 1.498929738998413
Validation loss: 2.008701391117547

Epoch: 5| Step: 1
Training loss: 1.3250941038131714
Validation loss: 1.9922206389006747

Epoch: 5| Step: 2
Training loss: 1.559093713760376
Validation loss: 1.9910402631246915

Epoch: 5| Step: 3
Training loss: 1.0769097805023193
Validation loss: 1.9922824790400844

Epoch: 5| Step: 4
Training loss: 1.711268663406372
Validation loss: 2.00287756740406

Epoch: 5| Step: 5
Training loss: 1.2097173929214478
Validation loss: 1.981045025651173

Epoch: 5| Step: 6
Training loss: 1.4958940744400024
Validation loss: 2.000431365864251

Epoch: 5| Step: 7
Training loss: 1.438820481300354
Validation loss: 2.016194030802737

Epoch: 5| Step: 8
Training loss: 1.6221132278442383
Validation loss: 2.0469332689880044

Epoch: 5| Step: 9
Training loss: 1.9436753988265991
Validation loss: 2.0657801153839275

Epoch: 5| Step: 10
Training loss: 1.2391871213912964
Validation loss: 2.0812494857336885

Epoch: 546| Step: 0
Training loss: 1.1482503414154053
Validation loss: 2.073034103198718

Epoch: 5| Step: 1
Training loss: 1.6835609674453735
Validation loss: 2.054856196526558

Epoch: 5| Step: 2
Training loss: 1.5937010049819946
Validation loss: 2.050244305723457

Epoch: 5| Step: 3
Training loss: 1.2678028345108032
Validation loss: 2.0280027338253555

Epoch: 5| Step: 4
Training loss: 1.6434831619262695
Validation loss: 2.0193851583747455

Epoch: 5| Step: 5
Training loss: 1.4263426065444946
Validation loss: 2.012657073236281

Epoch: 5| Step: 6
Training loss: 1.8660293817520142
Validation loss: 1.986882987842765

Epoch: 5| Step: 7
Training loss: 1.1383816003799438
Validation loss: 2.0075292818007933

Epoch: 5| Step: 8
Training loss: 1.6859219074249268
Validation loss: 2.000731045199979

Epoch: 5| Step: 9
Training loss: 0.9347860217094421
Validation loss: 2.019498504618163

Epoch: 5| Step: 10
Training loss: 1.7263457775115967
Validation loss: 2.0138970933934695

Epoch: 547| Step: 0
Training loss: 1.588789701461792
Validation loss: 2.006772343830396

Epoch: 5| Step: 1
Training loss: 1.918264627456665
Validation loss: 2.0216668600677163

Epoch: 5| Step: 2
Training loss: 1.541404128074646
Validation loss: 2.0459235355418217

Epoch: 5| Step: 3
Training loss: 1.5277583599090576
Validation loss: 2.0267051394267748

Epoch: 5| Step: 4
Training loss: 1.1336570978164673
Validation loss: 2.025814853688722

Epoch: 5| Step: 5
Training loss: 1.0355250835418701
Validation loss: 2.0118458399208645

Epoch: 5| Step: 6
Training loss: 1.7502031326293945
Validation loss: 2.0053364999832644

Epoch: 5| Step: 7
Training loss: 0.8992346525192261
Validation loss: 2.0057663891905095

Epoch: 5| Step: 8
Training loss: 2.1974716186523438
Validation loss: 2.029330207455543

Epoch: 5| Step: 9
Training loss: 1.11781907081604
Validation loss: 2.0529552775044597

Epoch: 5| Step: 10
Training loss: 1.3294247388839722
Validation loss: 2.030585091601136

Epoch: 548| Step: 0
Training loss: 1.6923322677612305
Validation loss: 2.0101131598154702

Epoch: 5| Step: 1
Training loss: 0.7909604907035828
Validation loss: 2.0523546716218353

Epoch: 5| Step: 2
Training loss: 1.3216631412506104
Validation loss: 2.0289186328969975

Epoch: 5| Step: 3
Training loss: 1.6235545873641968
Validation loss: 2.01544665521191

Epoch: 5| Step: 4
Training loss: 1.6461455821990967
Validation loss: 2.0110683389889297

Epoch: 5| Step: 5
Training loss: 1.4846261739730835
Validation loss: 1.9995569311162478

Epoch: 5| Step: 6
Training loss: 1.096149206161499
Validation loss: 2.0222291408046598

Epoch: 5| Step: 7
Training loss: 0.8218483924865723
Validation loss: 2.0189804441185406

Epoch: 5| Step: 8
Training loss: 1.656243920326233
Validation loss: 2.0304896036783853

Epoch: 5| Step: 9
Training loss: 1.756152868270874
Validation loss: 2.039184252421061

Epoch: 5| Step: 10
Training loss: 2.1301426887512207
Validation loss: 2.021974963526572

Epoch: 549| Step: 0
Training loss: 1.5069959163665771
Validation loss: 2.036426712107915

Epoch: 5| Step: 1
Training loss: 1.339017629623413
Validation loss: 2.0224779344374135

Epoch: 5| Step: 2
Training loss: 1.1634236574172974
Validation loss: 2.0215154181244555

Epoch: 5| Step: 3
Training loss: 1.1234309673309326
Validation loss: 2.02934508169851

Epoch: 5| Step: 4
Training loss: 1.521030306816101
Validation loss: 1.983317131637245

Epoch: 5| Step: 5
Training loss: 1.1220356225967407
Validation loss: 2.037039941357028

Epoch: 5| Step: 6
Training loss: 1.3750613927841187
Validation loss: 1.9865214824676514

Epoch: 5| Step: 7
Training loss: 1.3894363641738892
Validation loss: 2.0078094249130576

Epoch: 5| Step: 8
Training loss: 1.920240044593811
Validation loss: 2.010660227908883

Epoch: 5| Step: 9
Training loss: 1.4996130466461182
Validation loss: 2.0192493238756732

Epoch: 5| Step: 10
Training loss: 2.1136536598205566
Validation loss: 2.049454117334017

Epoch: 550| Step: 0
Training loss: 1.0947673320770264
Validation loss: 2.0414979893674134

Epoch: 5| Step: 1
Training loss: 1.8957754373550415
Validation loss: 2.049311376387073

Epoch: 5| Step: 2
Training loss: 1.0378923416137695
Validation loss: 2.0551011293165145

Epoch: 5| Step: 3
Training loss: 1.2374975681304932
Validation loss: 2.0377374285010883

Epoch: 5| Step: 4
Training loss: 1.3364899158477783
Validation loss: 2.011156746136245

Epoch: 5| Step: 5
Training loss: 1.8281923532485962
Validation loss: 2.006050596955002

Epoch: 5| Step: 6
Training loss: 2.063244581222534
Validation loss: 2.021851437066191

Epoch: 5| Step: 7
Training loss: 0.9014022946357727
Validation loss: 2.018603591508763

Epoch: 5| Step: 8
Training loss: 1.2499582767486572
Validation loss: 2.0148866381696475

Epoch: 5| Step: 9
Training loss: 1.7820497751235962
Validation loss: 2.0238412593000676

Epoch: 5| Step: 10
Training loss: 1.3520853519439697
Validation loss: 2.039493573609219

Testing loss: 2.217800590727064
