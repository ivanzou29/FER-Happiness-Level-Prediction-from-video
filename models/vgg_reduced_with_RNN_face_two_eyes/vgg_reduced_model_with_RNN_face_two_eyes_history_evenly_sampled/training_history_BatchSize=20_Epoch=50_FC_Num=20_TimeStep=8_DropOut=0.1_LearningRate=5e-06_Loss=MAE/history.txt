Epoch: 1| Step: 0
Training loss: 5.073983669281006
Validation loss: 5.234893204063497

Epoch: 5| Step: 1
Training loss: 3.857560634613037
Validation loss: 5.2303598619276475

Epoch: 5| Step: 2
Training loss: 5.052712440490723
Validation loss: 5.225512345631917

Epoch: 5| Step: 3
Training loss: 4.3682966232299805
Validation loss: 5.220428512942407

Epoch: 5| Step: 4
Training loss: 6.142664909362793
Validation loss: 5.215293581767749

Epoch: 5| Step: 5
Training loss: 5.175042152404785
Validation loss: 5.209870464058333

Epoch: 5| Step: 6
Training loss: 5.46437931060791
Validation loss: 5.204723758082236

Epoch: 5| Step: 7
Training loss: 5.286531448364258
Validation loss: 5.199614478695777

Epoch: 5| Step: 8
Training loss: 4.513585567474365
Validation loss: 5.194336352809783

Epoch: 5| Step: 9
Training loss: 4.5605316162109375
Validation loss: 5.188749733791556

Epoch: 5| Step: 10
Training loss: 5.662999629974365
Validation loss: 5.183555136444748

Epoch: 2| Step: 0
Training loss: 4.836143493652344
Validation loss: 5.177344568314091

Epoch: 5| Step: 1
Training loss: 5.068210124969482
Validation loss: 5.171761799884099

Epoch: 5| Step: 2
Training loss: 4.471733093261719
Validation loss: 5.165747545098745

Epoch: 5| Step: 3
Training loss: 4.579056739807129
Validation loss: 5.159493651441348

Epoch: 5| Step: 4
Training loss: 4.448636054992676
Validation loss: 5.152523107426141

Epoch: 5| Step: 5
Training loss: 6.177663803100586
Validation loss: 5.146229282502206

Epoch: 5| Step: 6
Training loss: 4.641153335571289
Validation loss: 5.138376200070945

Epoch: 5| Step: 7
Training loss: 4.737602233886719
Validation loss: 5.1305904593518985

Epoch: 5| Step: 8
Training loss: 5.387967586517334
Validation loss: 5.122035969970047

Epoch: 5| Step: 9
Training loss: 4.613997459411621
Validation loss: 5.113652208799957

Epoch: 5| Step: 10
Training loss: 5.4345269203186035
Validation loss: 5.104514321973247

Epoch: 3| Step: 0
Training loss: 4.60577917098999
Validation loss: 5.094878868390155

Epoch: 5| Step: 1
Training loss: 5.037117004394531
Validation loss: 5.085156343316519

Epoch: 5| Step: 2
Training loss: 4.965913772583008
Validation loss: 5.074756827405704

Epoch: 5| Step: 3
Training loss: 5.089178562164307
Validation loss: 5.063277608604841

Epoch: 5| Step: 4
Training loss: 4.133698463439941
Validation loss: 5.051452047081404

Epoch: 5| Step: 5
Training loss: 5.199283599853516
Validation loss: 5.039541126579366

Epoch: 5| Step: 6
Training loss: 4.727761268615723
Validation loss: 5.026913422410206

Epoch: 5| Step: 7
Training loss: 5.168983459472656
Validation loss: 5.0133539322883856

Epoch: 5| Step: 8
Training loss: 4.526827812194824
Validation loss: 4.9997609456380205

Epoch: 5| Step: 9
Training loss: 4.836704254150391
Validation loss: 4.983761710505331

Epoch: 5| Step: 10
Training loss: 4.855622291564941
Validation loss: 4.969277243460378

Epoch: 4| Step: 0
Training loss: 4.312780857086182
Validation loss: 4.952627438370899

Epoch: 5| Step: 1
Training loss: 5.0783538818359375
Validation loss: 4.935735128259146

Epoch: 5| Step: 2
Training loss: 4.276775360107422
Validation loss: 4.916910679109635

Epoch: 5| Step: 3
Training loss: 5.502279758453369
Validation loss: 4.899763338027462

Epoch: 5| Step: 4
Training loss: 3.212423324584961
Validation loss: 4.880154009788267

Epoch: 5| Step: 5
Training loss: 5.866680145263672
Validation loss: 4.858831133893741

Epoch: 5| Step: 6
Training loss: 4.118437767028809
Validation loss: 4.83807716061992

Epoch: 5| Step: 7
Training loss: 4.431690216064453
Validation loss: 4.8160728434080715

Epoch: 5| Step: 8
Training loss: 4.7636871337890625
Validation loss: 4.793215402992823

Epoch: 5| Step: 9
Training loss: 5.530586242675781
Validation loss: 4.768524928759503

Epoch: 5| Step: 10
Training loss: 3.9118967056274414
Validation loss: 4.746453738981677

Epoch: 5| Step: 0
Training loss: 4.9186906814575195
Validation loss: 4.721887911519697

Epoch: 5| Step: 1
Training loss: 4.007536888122559
Validation loss: 4.696901685448103

Epoch: 5| Step: 2
Training loss: 4.280170440673828
Validation loss: 4.672601320410288

Epoch: 5| Step: 3
Training loss: 4.671064853668213
Validation loss: 4.646405968614804

Epoch: 5| Step: 4
Training loss: 4.489743232727051
Validation loss: 4.619063444035028

Epoch: 5| Step: 5
Training loss: 3.970127820968628
Validation loss: 4.592481233740366

Epoch: 5| Step: 6
Training loss: 4.943177223205566
Validation loss: 4.565718343180995

Epoch: 5| Step: 7
Training loss: 4.621732234954834
Validation loss: 4.5379361388503865

Epoch: 5| Step: 8
Training loss: 3.7573351860046387
Validation loss: 4.509122453710084

Epoch: 5| Step: 9
Training loss: 4.214098930358887
Validation loss: 4.480478558489072

Epoch: 5| Step: 10
Training loss: 4.232584476470947
Validation loss: 4.450944264729817

Epoch: 6| Step: 0
Training loss: 4.403901100158691
Validation loss: 4.421275328564388

Epoch: 5| Step: 1
Training loss: 3.836249589920044
Validation loss: 4.393038585621824

Epoch: 5| Step: 2
Training loss: 3.146914005279541
Validation loss: 4.363791404231902

Epoch: 5| Step: 3
Training loss: 4.794792175292969
Validation loss: 4.33218708345967

Epoch: 5| Step: 4
Training loss: 4.074753761291504
Validation loss: 4.301261132763278

Epoch: 5| Step: 5
Training loss: 3.1335318088531494
Validation loss: 4.270125112225933

Epoch: 5| Step: 6
Training loss: 4.141097545623779
Validation loss: 4.2381422135137745

Epoch: 5| Step: 7
Training loss: 4.426548004150391
Validation loss: 4.2066064855103855

Epoch: 5| Step: 8
Training loss: 4.591042518615723
Validation loss: 4.177674949810069

Epoch: 5| Step: 9
Training loss: 3.7384934425354004
Validation loss: 4.145267973663986

Epoch: 5| Step: 10
Training loss: 4.63876485824585
Validation loss: 4.114225244009367

Epoch: 7| Step: 0
Training loss: 3.8431129455566406
Validation loss: 4.08568307404877

Epoch: 5| Step: 1
Training loss: 2.8102009296417236
Validation loss: 4.053733387301045

Epoch: 5| Step: 2
Training loss: 3.8072597980499268
Validation loss: 4.0246840497498875

Epoch: 5| Step: 3
Training loss: 3.1721014976501465
Validation loss: 3.99538759005967

Epoch: 5| Step: 4
Training loss: 3.4398555755615234
Validation loss: 3.9681821125809864

Epoch: 5| Step: 5
Training loss: 3.7181873321533203
Validation loss: 3.9409386086207565

Epoch: 5| Step: 6
Training loss: 4.5915656089782715
Validation loss: 3.913179418092133

Epoch: 5| Step: 7
Training loss: 4.976568698883057
Validation loss: 3.888912970019925

Epoch: 5| Step: 8
Training loss: 4.035592555999756
Validation loss: 3.864573529971543

Epoch: 5| Step: 9
Training loss: 3.828029155731201
Validation loss: 3.8384882916686354

Epoch: 5| Step: 10
Training loss: 3.3698132038116455
Validation loss: 3.814772172640729

Epoch: 8| Step: 0
Training loss: 4.119826316833496
Validation loss: 3.7917466522544943

Epoch: 5| Step: 1
Training loss: 4.257349491119385
Validation loss: 3.7691544153357066

Epoch: 5| Step: 2
Training loss: 3.8460936546325684
Validation loss: 3.7484962504397155

Epoch: 5| Step: 3
Training loss: 3.829784870147705
Validation loss: 3.725687913997199

Epoch: 5| Step: 4
Training loss: 3.091794013977051
Validation loss: 3.705929402382143

Epoch: 5| Step: 5
Training loss: 4.08833122253418
Validation loss: 3.6857731265406453

Epoch: 5| Step: 6
Training loss: 2.921572208404541
Validation loss: 3.6699915137342227

Epoch: 5| Step: 7
Training loss: 3.1782925128936768
Validation loss: 3.6531392476891957

Epoch: 5| Step: 8
Training loss: 2.8395073413848877
Validation loss: 3.6375650718647945

Epoch: 5| Step: 9
Training loss: 3.808318614959717
Validation loss: 3.6248823519675963

Epoch: 5| Step: 10
Training loss: 3.5993330478668213
Validation loss: 3.607827491657708

Epoch: 9| Step: 0
Training loss: 4.607419490814209
Validation loss: 3.5986385422368206

Epoch: 5| Step: 1
Training loss: 3.0222179889678955
Validation loss: 3.5829160572380148

Epoch: 5| Step: 2
Training loss: 3.3618457317352295
Validation loss: 3.568216536634712

Epoch: 5| Step: 3
Training loss: 4.525325298309326
Validation loss: 3.5560534743852514

Epoch: 5| Step: 4
Training loss: 2.678579092025757
Validation loss: 3.5423416399186656

Epoch: 5| Step: 5
Training loss: 2.840636730194092
Validation loss: 3.5308779747255388

Epoch: 5| Step: 6
Training loss: 3.20524525642395
Validation loss: 3.520411829794607

Epoch: 5| Step: 7
Training loss: 2.6035568714141846
Validation loss: 3.5081960103845082

Epoch: 5| Step: 8
Training loss: 3.556363344192505
Validation loss: 3.4955947476048626

Epoch: 5| Step: 9
Training loss: 4.571145534515381
Validation loss: 3.4860387053540958

Epoch: 5| Step: 10
Training loss: 3.091456174850464
Validation loss: 3.476072465219805

Epoch: 10| Step: 0
Training loss: 4.597931861877441
Validation loss: 3.4645585654884257

Epoch: 5| Step: 1
Training loss: 2.9754931926727295
Validation loss: 3.452464703590639

Epoch: 5| Step: 2
Training loss: 3.8836731910705566
Validation loss: 3.443590420548634

Epoch: 5| Step: 3
Training loss: 2.5302486419677734
Validation loss: 3.4343862713024182

Epoch: 5| Step: 4
Training loss: 3.4888267517089844
Validation loss: 3.4251487050005185

Epoch: 5| Step: 5
Training loss: 3.780341386795044
Validation loss: 3.4162597399885937

Epoch: 5| Step: 6
Training loss: 3.626403331756592
Validation loss: 3.4052435633956746

Epoch: 5| Step: 7
Training loss: 3.14911150932312
Validation loss: 3.394128317474037

Epoch: 5| Step: 8
Training loss: 2.7496979236602783
Validation loss: 3.3851318256829375

Epoch: 5| Step: 9
Training loss: 3.007737636566162
Validation loss: 3.3792600170258553

Epoch: 5| Step: 10
Training loss: 3.214503049850464
Validation loss: 3.368785801754203

Epoch: 11| Step: 0
Training loss: 3.7640480995178223
Validation loss: 3.36174637527876

Epoch: 5| Step: 1
Training loss: 3.584188938140869
Validation loss: 3.35408265103576

Epoch: 5| Step: 2
Training loss: 2.403651475906372
Validation loss: 3.346075891166605

Epoch: 5| Step: 3
Training loss: 3.0944652557373047
Validation loss: 3.3372582748372066

Epoch: 5| Step: 4
Training loss: 2.4080307483673096
Validation loss: 3.3302078247070312

Epoch: 5| Step: 5
Training loss: 3.1948819160461426
Validation loss: 3.3239927445688555

Epoch: 5| Step: 6
Training loss: 3.3254342079162598
Validation loss: 3.315711864861109

Epoch: 5| Step: 7
Training loss: 3.318971633911133
Validation loss: 3.3091790317207255

Epoch: 5| Step: 8
Training loss: 3.241117000579834
Validation loss: 3.3001625563508723

Epoch: 5| Step: 9
Training loss: 4.055231094360352
Validation loss: 3.293198116364018

Epoch: 5| Step: 10
Training loss: 3.8470561504364014
Validation loss: 3.2857292595730034

Epoch: 12| Step: 0
Training loss: 2.9512417316436768
Validation loss: 3.278980826818815

Epoch: 5| Step: 1
Training loss: 3.3968186378479004
Validation loss: 3.2730137250756703

Epoch: 5| Step: 2
Training loss: 2.7551398277282715
Validation loss: 3.26524753468011

Epoch: 5| Step: 3
Training loss: 2.971419334411621
Validation loss: 3.2596151008400867

Epoch: 5| Step: 4
Training loss: 2.399609327316284
Validation loss: 3.2530479918244066

Epoch: 5| Step: 5
Training loss: 4.09869384765625
Validation loss: 3.2478385791983655

Epoch: 5| Step: 6
Training loss: 3.025367259979248
Validation loss: 3.2414193384109007

Epoch: 5| Step: 7
Training loss: 3.2705140113830566
Validation loss: 3.2336814967534875

Epoch: 5| Step: 8
Training loss: 3.3951869010925293
Validation loss: 3.23048000438239

Epoch: 5| Step: 9
Training loss: 3.265561580657959
Validation loss: 3.2252721760862615

Epoch: 5| Step: 10
Training loss: 4.117300033569336
Validation loss: 3.218854752920007

Epoch: 13| Step: 0
Training loss: 3.645251512527466
Validation loss: 3.2136720739385134

Epoch: 5| Step: 1
Training loss: 2.9854910373687744
Validation loss: 3.209516171486147

Epoch: 5| Step: 2
Training loss: 2.84419322013855
Validation loss: 3.205277855678271

Epoch: 5| Step: 3
Training loss: 2.563671112060547
Validation loss: 3.2016592794849026

Epoch: 5| Step: 4
Training loss: 3.2896697521209717
Validation loss: 3.1938245783569994

Epoch: 5| Step: 5
Training loss: 4.36226224899292
Validation loss: 3.189311909419234

Epoch: 5| Step: 6
Training loss: 3.49664306640625
Validation loss: 3.182104951591902

Epoch: 5| Step: 7
Training loss: 2.4505934715270996
Validation loss: 3.1794676370518182

Epoch: 5| Step: 8
Training loss: 3.2738404273986816
Validation loss: 3.1752066227697555

Epoch: 5| Step: 9
Training loss: 2.739166498184204
Validation loss: 3.173078647223852

Epoch: 5| Step: 10
Training loss: 3.4486680030822754
Validation loss: 3.1682300259990077

Epoch: 14| Step: 0
Training loss: 4.095195770263672
Validation loss: 3.1626045370614655

Epoch: 5| Step: 1
Training loss: 2.624601364135742
Validation loss: 3.1575603177470546

Epoch: 5| Step: 2
Training loss: 3.2088851928710938
Validation loss: 3.1524627721437843

Epoch: 5| Step: 3
Training loss: 3.3142249584198
Validation loss: 3.1466986389570337

Epoch: 5| Step: 4
Training loss: 3.7080581188201904
Validation loss: 3.142417992314985

Epoch: 5| Step: 5
Training loss: 2.9294354915618896
Validation loss: 3.138998867363058

Epoch: 5| Step: 6
Training loss: 3.4947097301483154
Validation loss: 3.1373910263020504

Epoch: 5| Step: 7
Training loss: 2.9097845554351807
Validation loss: 3.1337853529120006

Epoch: 5| Step: 8
Training loss: 2.7281494140625
Validation loss: 3.1313809476872927

Epoch: 5| Step: 9
Training loss: 2.6904780864715576
Validation loss: 3.1274955016310497

Epoch: 5| Step: 10
Training loss: 2.9787869453430176
Validation loss: 3.12324514953039

Epoch: 15| Step: 0
Training loss: 3.4761319160461426
Validation loss: 3.1203204047295356

Epoch: 5| Step: 1
Training loss: 3.5328826904296875
Validation loss: 3.116310642611596

Epoch: 5| Step: 2
Training loss: 3.202075242996216
Validation loss: 3.1152316652318484

Epoch: 5| Step: 3
Training loss: 2.3120875358581543
Validation loss: 3.111576046994937

Epoch: 5| Step: 4
Training loss: 3.6006875038146973
Validation loss: 3.1100358604103007

Epoch: 5| Step: 5
Training loss: 2.945150852203369
Validation loss: 3.106992165247599

Epoch: 5| Step: 6
Training loss: 3.0747084617614746
Validation loss: 3.10025054665022

Epoch: 5| Step: 7
Training loss: 4.0053791999816895
Validation loss: 3.096287276155205

Epoch: 5| Step: 8
Training loss: 2.7813684940338135
Validation loss: 3.0942508328345513

Epoch: 5| Step: 9
Training loss: 2.4532241821289062
Validation loss: 3.092903560207736

Epoch: 5| Step: 10
Training loss: 2.994572162628174
Validation loss: 3.0882801137944704

Epoch: 16| Step: 0
Training loss: 3.243434429168701
Validation loss: 3.0869205562017297

Epoch: 5| Step: 1
Training loss: 3.2784945964813232
Validation loss: 3.0835058150752896

Epoch: 5| Step: 2
Training loss: 3.258213758468628
Validation loss: 3.077544773778608

Epoch: 5| Step: 3
Training loss: 2.8319733142852783
Validation loss: 3.075787618596067

Epoch: 5| Step: 4
Training loss: 2.558027505874634
Validation loss: 3.0742175937980734

Epoch: 5| Step: 5
Training loss: 3.2317252159118652
Validation loss: 3.071511104542722

Epoch: 5| Step: 6
Training loss: 3.412290096282959
Validation loss: 3.0682601159618748

Epoch: 5| Step: 7
Training loss: 2.963019609451294
Validation loss: 3.0650548345299176

Epoch: 5| Step: 8
Training loss: 3.8795981407165527
Validation loss: 3.060801044587166

Epoch: 5| Step: 9
Training loss: 2.572775363922119
Validation loss: 3.059467977093112

Epoch: 5| Step: 10
Training loss: 2.9293978214263916
Validation loss: 3.0586137002514255

Epoch: 17| Step: 0
Training loss: 3.5878567695617676
Validation loss: 3.0566619903810563

Epoch: 5| Step: 1
Training loss: 3.3815834522247314
Validation loss: 3.054655090455086

Epoch: 5| Step: 2
Training loss: 3.135343074798584
Validation loss: 3.052307923634847

Epoch: 5| Step: 3
Training loss: 2.5950393676757812
Validation loss: 3.04911405809464

Epoch: 5| Step: 4
Training loss: 2.7348570823669434
Validation loss: 3.0495481157815583

Epoch: 5| Step: 5
Training loss: 3.6008846759796143
Validation loss: 3.046633046160462

Epoch: 5| Step: 6
Training loss: 2.711364984512329
Validation loss: 3.045715803741127

Epoch: 5| Step: 7
Training loss: 3.2152843475341797
Validation loss: 3.0427387427258235

Epoch: 5| Step: 8
Training loss: 3.2806599140167236
Validation loss: 3.0407496626659105

Epoch: 5| Step: 9
Training loss: 2.8096694946289062
Validation loss: 3.0372363239206295

Epoch: 5| Step: 10
Training loss: 2.922513246536255
Validation loss: 3.0321812629699707

Epoch: 18| Step: 0
Training loss: 2.07783842086792
Validation loss: 3.028266132518809

Epoch: 5| Step: 1
Training loss: 3.1595780849456787
Validation loss: 3.0287762508597424

Epoch: 5| Step: 2
Training loss: 3.121140956878662
Validation loss: 3.0255487734271633

Epoch: 5| Step: 3
Training loss: 2.5980186462402344
Validation loss: 3.0221629424761702

Epoch: 5| Step: 4
Training loss: 3.4644782543182373
Validation loss: 3.0195226284765426

Epoch: 5| Step: 5
Training loss: 2.9786789417266846
Validation loss: 3.0172191486563733

Epoch: 5| Step: 6
Training loss: 2.9657387733459473
Validation loss: 3.014801440700408

Epoch: 5| Step: 7
Training loss: 4.273556232452393
Validation loss: 3.0117807311396443

Epoch: 5| Step: 8
Training loss: 3.260612964630127
Validation loss: 3.0115303736861034

Epoch: 5| Step: 9
Training loss: 2.605478286743164
Validation loss: 3.010744138430524

Epoch: 5| Step: 10
Training loss: 3.3262741565704346
Validation loss: 3.0050022960990987

Epoch: 19| Step: 0
Training loss: 2.6668105125427246
Validation loss: 3.0062699189750095

Epoch: 5| Step: 1
Training loss: 3.415083408355713
Validation loss: 3.0047785876899638

Epoch: 5| Step: 2
Training loss: 3.7861855030059814
Validation loss: 3.0056933279960387

Epoch: 5| Step: 3
Training loss: 3.1524851322174072
Validation loss: 3.00031610714492

Epoch: 5| Step: 4
Training loss: 2.6655659675598145
Validation loss: 2.996496905562698

Epoch: 5| Step: 5
Training loss: 3.7158076763153076
Validation loss: 2.9953961474921114

Epoch: 5| Step: 6
Training loss: 2.304917573928833
Validation loss: 2.9946348077507428

Epoch: 5| Step: 7
Training loss: 3.6060562133789062
Validation loss: 2.991044477749896

Epoch: 5| Step: 8
Training loss: 2.568617820739746
Validation loss: 2.988096293582711

Epoch: 5| Step: 9
Training loss: 2.801584482192993
Validation loss: 2.9885368270258748

Epoch: 5| Step: 10
Training loss: 2.953641653060913
Validation loss: 2.991575771762479

Epoch: 20| Step: 0
Training loss: 2.9747440814971924
Validation loss: 2.990707435915547

Epoch: 5| Step: 1
Training loss: 2.069762945175171
Validation loss: 2.9909643409072713

Epoch: 5| Step: 2
Training loss: 2.7046144008636475
Validation loss: 2.984692781202255

Epoch: 5| Step: 3
Training loss: 3.04888653755188
Validation loss: 2.9830357182410454

Epoch: 5| Step: 4
Training loss: 2.4563887119293213
Validation loss: 2.9807955859809794

Epoch: 5| Step: 5
Training loss: 3.2338485717773438
Validation loss: 2.9806959987968527

Epoch: 5| Step: 6
Training loss: 3.4447968006134033
Validation loss: 2.9745748504515617

Epoch: 5| Step: 7
Training loss: 3.9700076580047607
Validation loss: 2.97605074092906

Epoch: 5| Step: 8
Training loss: 3.1695122718811035
Validation loss: 2.9743432562838317

Epoch: 5| Step: 9
Training loss: 2.788602590560913
Validation loss: 2.970752972428517

Epoch: 5| Step: 10
Training loss: 3.7546167373657227
Validation loss: 2.97051453334029

Epoch: 21| Step: 0
Training loss: 2.8838558197021484
Validation loss: 2.968125994487475

Epoch: 5| Step: 1
Training loss: 2.9840731620788574
Validation loss: 2.965146282667755

Epoch: 5| Step: 2
Training loss: 3.2623887062072754
Validation loss: 2.9640666695051294

Epoch: 5| Step: 3
Training loss: 3.312950611114502
Validation loss: 2.962102295250021

Epoch: 5| Step: 4
Training loss: 3.0352370738983154
Validation loss: 2.962500197913057

Epoch: 5| Step: 5
Training loss: 2.909729242324829
Validation loss: 2.960699076293617

Epoch: 5| Step: 6
Training loss: 3.4216854572296143
Validation loss: 2.960884876148675

Epoch: 5| Step: 7
Training loss: 3.006714105606079
Validation loss: 2.9583304620558217

Epoch: 5| Step: 8
Training loss: 2.78509259223938
Validation loss: 2.961150587245982

Epoch: 5| Step: 9
Training loss: 1.767721176147461
Validation loss: 2.955255498168289

Epoch: 5| Step: 10
Training loss: 4.208407402038574
Validation loss: 2.9505273808715162

Epoch: 22| Step: 0
Training loss: 2.6316628456115723
Validation loss: 2.9491986869483866

Epoch: 5| Step: 1
Training loss: 3.0472195148468018
Validation loss: 2.9483923014774116

Epoch: 5| Step: 2
Training loss: 2.90177583694458
Validation loss: 2.9476932607671267

Epoch: 5| Step: 3
Training loss: 3.458901882171631
Validation loss: 2.9468759541870444

Epoch: 5| Step: 4
Training loss: 2.7480101585388184
Validation loss: 2.9461500824138684

Epoch: 5| Step: 5
Training loss: 3.305255889892578
Validation loss: 2.9437681526266117

Epoch: 5| Step: 6
Training loss: 2.690863847732544
Validation loss: 2.9445360322152414

Epoch: 5| Step: 7
Training loss: 3.120985746383667
Validation loss: 2.944731745668637

Epoch: 5| Step: 8
Training loss: 3.3295369148254395
Validation loss: 2.948164014406102

Epoch: 5| Step: 9
Training loss: 2.908566951751709
Validation loss: 2.942035669921547

Epoch: 5| Step: 10
Training loss: 3.1810622215270996
Validation loss: 2.9377053835058726

Epoch: 23| Step: 0
Training loss: 3.0619406700134277
Validation loss: 2.935895806999617

Epoch: 5| Step: 1
Training loss: 2.410597801208496
Validation loss: 2.9363118986929617

Epoch: 5| Step: 2
Training loss: 3.0258142948150635
Validation loss: 2.9340315018930743

Epoch: 5| Step: 3
Training loss: 3.0114052295684814
Validation loss: 2.933949657665786

Epoch: 5| Step: 4
Training loss: 3.2744827270507812
Validation loss: 2.93314956080529

Epoch: 5| Step: 5
Training loss: 2.919329881668091
Validation loss: 2.9312754805370043

Epoch: 5| Step: 6
Training loss: 3.0008928775787354
Validation loss: 2.930078752579228

Epoch: 5| Step: 7
Training loss: 2.983154535293579
Validation loss: 2.9298183456543954

Epoch: 5| Step: 8
Training loss: 2.9494025707244873
Validation loss: 2.929647543097055

Epoch: 5| Step: 9
Training loss: 3.142597198486328
Validation loss: 2.9261360245366252

Epoch: 5| Step: 10
Training loss: 3.4811489582061768
Validation loss: 2.9265191837023665

Epoch: 24| Step: 0
Training loss: 3.2938003540039062
Validation loss: 2.9278365770975747

Epoch: 5| Step: 1
Training loss: 3.1511456966400146
Validation loss: 2.926673491795858

Epoch: 5| Step: 2
Training loss: 2.885327100753784
Validation loss: 2.927017011950093

Epoch: 5| Step: 3
Training loss: 3.6650452613830566
Validation loss: 2.9290703394079722

Epoch: 5| Step: 4
Training loss: 2.6153714656829834
Validation loss: 2.928247418454898

Epoch: 5| Step: 5
Training loss: 3.660442352294922
Validation loss: 2.9221193457162506

Epoch: 5| Step: 6
Training loss: 2.778743028640747
Validation loss: 2.91974062560707

Epoch: 5| Step: 7
Training loss: 2.0434768199920654
Validation loss: 2.9191277821858725

Epoch: 5| Step: 8
Training loss: 3.5443451404571533
Validation loss: 2.917668140062722

Epoch: 5| Step: 9
Training loss: 2.595991849899292
Validation loss: 2.91814745882506

Epoch: 5| Step: 10
Training loss: 2.868981122970581
Validation loss: 2.9184783453582437

Epoch: 25| Step: 0
Training loss: 2.726684331893921
Validation loss: 2.9174766386708906

Epoch: 5| Step: 1
Training loss: 2.7966198921203613
Validation loss: 2.917028078468897

Epoch: 5| Step: 2
Training loss: 3.065464496612549
Validation loss: 2.9152125696982107

Epoch: 5| Step: 3
Training loss: 3.0503313541412354
Validation loss: 2.9156353012208016

Epoch: 5| Step: 4
Training loss: 2.7949414253234863
Validation loss: 2.9148019795776694

Epoch: 5| Step: 5
Training loss: 2.649120807647705
Validation loss: 2.9133488644835768

Epoch: 5| Step: 6
Training loss: 2.9659626483917236
Validation loss: 2.913535212957731

Epoch: 5| Step: 7
Training loss: 2.7153146266937256
Validation loss: 2.913670829547349

Epoch: 5| Step: 8
Training loss: 4.1268839836120605
Validation loss: 2.9116459610641643

Epoch: 5| Step: 9
Training loss: 3.637678623199463
Validation loss: 2.9103524864360852

Epoch: 5| Step: 10
Training loss: 2.4442806243896484
Validation loss: 2.9101083688838507

Epoch: 26| Step: 0
Training loss: 2.6012983322143555
Validation loss: 2.909972006274808

Epoch: 5| Step: 1
Training loss: 3.9321677684783936
Validation loss: 2.9074044765964633

Epoch: 5| Step: 2
Training loss: 2.8890743255615234
Validation loss: 2.907725408513059

Epoch: 5| Step: 3
Training loss: 2.5605359077453613
Validation loss: 2.9056210364064863

Epoch: 5| Step: 4
Training loss: 3.370175838470459
Validation loss: 2.9043970620760353

Epoch: 5| Step: 5
Training loss: 3.2332139015197754
Validation loss: 2.9035112780909382

Epoch: 5| Step: 6
Training loss: 2.5438239574432373
Validation loss: 2.9018508516332155

Epoch: 5| Step: 7
Training loss: 2.630422353744507
Validation loss: 2.902492751357376

Epoch: 5| Step: 8
Training loss: 3.172600507736206
Validation loss: 2.900331663829024

Epoch: 5| Step: 9
Training loss: 3.061913013458252
Validation loss: 2.9001606459258706

Epoch: 5| Step: 10
Training loss: 3.0002458095550537
Validation loss: 2.8993600312099663

Epoch: 27| Step: 0
Training loss: 3.0171806812286377
Validation loss: 2.900675432656401

Epoch: 5| Step: 1
Training loss: 2.848079204559326
Validation loss: 2.899855372726276

Epoch: 5| Step: 2
Training loss: 3.172546148300171
Validation loss: 2.899136584292176

Epoch: 5| Step: 3
Training loss: 3.3111813068389893
Validation loss: 2.8969450842949653

Epoch: 5| Step: 4
Training loss: 2.8421831130981445
Validation loss: 2.896668634107036

Epoch: 5| Step: 5
Training loss: 3.007802963256836
Validation loss: 2.8952037108841764

Epoch: 5| Step: 6
Training loss: 3.39332914352417
Validation loss: 2.893093296276626

Epoch: 5| Step: 7
Training loss: 3.3358612060546875
Validation loss: 2.893323367641818

Epoch: 5| Step: 8
Training loss: 2.313394069671631
Validation loss: 2.8938315786341184

Epoch: 5| Step: 9
Training loss: 3.4289536476135254
Validation loss: 2.8936025327251804

Epoch: 5| Step: 10
Training loss: 2.1405391693115234
Validation loss: 2.891817113404633

Epoch: 28| Step: 0
Training loss: 2.8214571475982666
Validation loss: 2.893312082495741

Epoch: 5| Step: 1
Training loss: 2.9602150917053223
Validation loss: 2.891936030439151

Epoch: 5| Step: 2
Training loss: 3.525926113128662
Validation loss: 2.888760102692471

Epoch: 5| Step: 3
Training loss: 3.190277099609375
Validation loss: 2.8885532604750765

Epoch: 5| Step: 4
Training loss: 2.3821041584014893
Validation loss: 2.8886773868273665

Epoch: 5| Step: 5
Training loss: 2.5497469902038574
Validation loss: 2.890676744522587

Epoch: 5| Step: 6
Training loss: 3.1652629375457764
Validation loss: 2.888573387617706

Epoch: 5| Step: 7
Training loss: 3.1729423999786377
Validation loss: 2.8895700131693194

Epoch: 5| Step: 8
Training loss: 3.1499202251434326
Validation loss: 2.886151352236348

Epoch: 5| Step: 9
Training loss: 3.3265113830566406
Validation loss: 2.885219471428984

Epoch: 5| Step: 10
Training loss: 2.5738658905029297
Validation loss: 2.8857853771537862

Epoch: 29| Step: 0
Training loss: 2.3628082275390625
Validation loss: 2.885520658185405

Epoch: 5| Step: 1
Training loss: 2.4950051307678223
Validation loss: 2.887857514043008

Epoch: 5| Step: 2
Training loss: 2.3797693252563477
Validation loss: 2.8876203183204896

Epoch: 5| Step: 3
Training loss: 3.369450330734253
Validation loss: 2.8867588863577893

Epoch: 5| Step: 4
Training loss: 2.9944007396698
Validation loss: 2.889821549897553

Epoch: 5| Step: 5
Training loss: 3.026210069656372
Validation loss: 2.884361643945017

Epoch: 5| Step: 6
Training loss: 3.218693971633911
Validation loss: 2.8817650695000925

Epoch: 5| Step: 7
Training loss: 2.602804660797119
Validation loss: 2.882536406158119

Epoch: 5| Step: 8
Training loss: 3.6711783409118652
Validation loss: 2.8805459186594975

Epoch: 5| Step: 9
Training loss: 3.4173076152801514
Validation loss: 2.8802824840750745

Epoch: 5| Step: 10
Training loss: 3.344197988510132
Validation loss: 2.879914617025724

Epoch: 30| Step: 0
Training loss: 3.2246100902557373
Validation loss: 2.8794095362386396

Epoch: 5| Step: 1
Training loss: 3.334746837615967
Validation loss: 2.880094135961225

Epoch: 5| Step: 2
Training loss: 2.980748176574707
Validation loss: 2.878094611629363

Epoch: 5| Step: 3
Training loss: 2.7934396266937256
Validation loss: 2.876118039572111

Epoch: 5| Step: 4
Training loss: 2.733517646789551
Validation loss: 2.8782365501567884

Epoch: 5| Step: 5
Training loss: 3.255323886871338
Validation loss: 2.876571073327013

Epoch: 5| Step: 6
Training loss: 2.779287815093994
Validation loss: 2.877077446188978

Epoch: 5| Step: 7
Training loss: 2.9663968086242676
Validation loss: 2.8797302066638903

Epoch: 5| Step: 8
Training loss: 3.1518819332122803
Validation loss: 2.8916072230185232

Epoch: 5| Step: 9
Training loss: 2.941751718521118
Validation loss: 2.8843427370953303

Epoch: 5| Step: 10
Training loss: 2.550548791885376
Validation loss: 2.8752555565167497

Epoch: 31| Step: 0
Training loss: 3.057356357574463
Validation loss: 2.874144846393216

Epoch: 5| Step: 1
Training loss: 2.4709384441375732
Validation loss: 2.8734160366878716

Epoch: 5| Step: 2
Training loss: 3.3557255268096924
Validation loss: 2.8772873288841656

Epoch: 5| Step: 3
Training loss: 3.140420436859131
Validation loss: 2.8786397800650647

Epoch: 5| Step: 4
Training loss: 3.033262014389038
Validation loss: 2.8801131222837713

Epoch: 5| Step: 5
Training loss: 2.4759902954101562
Validation loss: 2.8767580165657947

Epoch: 5| Step: 6
Training loss: 3.0596632957458496
Validation loss: 2.878023175783055

Epoch: 5| Step: 7
Training loss: 3.4398772716522217
Validation loss: 2.8755199140118015

Epoch: 5| Step: 8
Training loss: 3.0814387798309326
Validation loss: 2.8754184938246206

Epoch: 5| Step: 9
Training loss: 3.0365450382232666
Validation loss: 2.873983739524759

Epoch: 5| Step: 10
Training loss: 2.5768749713897705
Validation loss: 2.8745148181915283

Epoch: 32| Step: 0
Training loss: 2.765009641647339
Validation loss: 2.8720018607313915

Epoch: 5| Step: 1
Training loss: 1.8056933879852295
Validation loss: 2.8735347665766233

Epoch: 5| Step: 2
Training loss: 2.850952625274658
Validation loss: 2.8710354656301518

Epoch: 5| Step: 3
Training loss: 3.567333221435547
Validation loss: 2.8712990899239816

Epoch: 5| Step: 4
Training loss: 3.6166412830352783
Validation loss: 2.869161908344556

Epoch: 5| Step: 5
Training loss: 3.2724132537841797
Validation loss: 2.869880930069954

Epoch: 5| Step: 6
Training loss: 2.402600049972534
Validation loss: 2.87041502101447

Epoch: 5| Step: 7
Training loss: 3.8570709228515625
Validation loss: 2.8699081277334564

Epoch: 5| Step: 8
Training loss: 2.136404514312744
Validation loss: 2.8703492815776537

Epoch: 5| Step: 9
Training loss: 2.9183382987976074
Validation loss: 2.8685372132127003

Epoch: 5| Step: 10
Training loss: 3.647581100463867
Validation loss: 2.8659173493744223

Epoch: 33| Step: 0
Training loss: 2.783146381378174
Validation loss: 2.8666362839360393

Epoch: 5| Step: 1
Training loss: 2.902432918548584
Validation loss: 2.866522712092246

Epoch: 5| Step: 2
Training loss: 2.5655083656311035
Validation loss: 2.865976651509603

Epoch: 5| Step: 3
Training loss: 3.6270751953125
Validation loss: 2.862292597370763

Epoch: 5| Step: 4
Training loss: 2.3133251667022705
Validation loss: 2.864232909294867

Epoch: 5| Step: 5
Training loss: 3.234954833984375
Validation loss: 2.863770613106348

Epoch: 5| Step: 6
Training loss: 2.7731258869171143
Validation loss: 2.864187086782148

Epoch: 5| Step: 7
Training loss: 3.763483762741089
Validation loss: 2.863728395072363

Epoch: 5| Step: 8
Training loss: 2.2487361431121826
Validation loss: 2.861862641508861

Epoch: 5| Step: 9
Training loss: 3.495831251144409
Validation loss: 2.861302944921678

Epoch: 5| Step: 10
Training loss: 3.0046560764312744
Validation loss: 2.8605303584888415

Epoch: 34| Step: 0
Training loss: 2.6914992332458496
Validation loss: 2.8609235440531084

Epoch: 5| Step: 1
Training loss: 3.216409206390381
Validation loss: 2.8614698456179712

Epoch: 5| Step: 2
Training loss: 3.2331643104553223
Validation loss: 2.8595589745429253

Epoch: 5| Step: 3
Training loss: 2.2047581672668457
Validation loss: 2.8585335849433817

Epoch: 5| Step: 4
Training loss: 3.108663320541382
Validation loss: 2.8591705470956783

Epoch: 5| Step: 5
Training loss: 2.6337218284606934
Validation loss: 2.857941953084802

Epoch: 5| Step: 6
Training loss: 2.862840175628662
Validation loss: 2.8580584731153262

Epoch: 5| Step: 7
Training loss: 3.413323163986206
Validation loss: 2.8586135115674747

Epoch: 5| Step: 8
Training loss: 3.2607409954071045
Validation loss: 2.8591334717248076

Epoch: 5| Step: 9
Training loss: 2.8856089115142822
Validation loss: 2.85711831431235

Epoch: 5| Step: 10
Training loss: 3.195777177810669
Validation loss: 2.856489919847058

Epoch: 35| Step: 0
Training loss: 2.4092185497283936
Validation loss: 2.8567764579608874

Epoch: 5| Step: 1
Training loss: 2.9396257400512695
Validation loss: 2.856755546344224

Epoch: 5| Step: 2
Training loss: 3.3766582012176514
Validation loss: 2.8557400498338925

Epoch: 5| Step: 3
Training loss: 3.121021270751953
Validation loss: 2.855512334454444

Epoch: 5| Step: 4
Training loss: 3.2383804321289062
Validation loss: 2.8557167437768753

Epoch: 5| Step: 5
Training loss: 2.7365636825561523
Validation loss: 2.8552304134573987

Epoch: 5| Step: 6
Training loss: 2.78428316116333
Validation loss: 2.8545864294934016

Epoch: 5| Step: 7
Training loss: 2.5947818756103516
Validation loss: 2.854560036813059

Epoch: 5| Step: 8
Training loss: 2.6156866550445557
Validation loss: 2.854948628333307

Epoch: 5| Step: 9
Training loss: 3.7860236167907715
Validation loss: 2.8546107866430797

Epoch: 5| Step: 10
Training loss: 3.055565595626831
Validation loss: 2.852903676289384

Epoch: 36| Step: 0
Training loss: 3.0843727588653564
Validation loss: 2.8532493678472375

Epoch: 5| Step: 1
Training loss: 3.5190606117248535
Validation loss: 2.85239351436656

Epoch: 5| Step: 2
Training loss: 3.655707597732544
Validation loss: 2.851418674633067

Epoch: 5| Step: 3
Training loss: 2.3875949382781982
Validation loss: 2.852780426702192

Epoch: 5| Step: 4
Training loss: 3.6708579063415527
Validation loss: 2.851057944759246

Epoch: 5| Step: 5
Training loss: 2.818671703338623
Validation loss: 2.851785008625318

Epoch: 5| Step: 6
Training loss: 3.072190523147583
Validation loss: 2.8522746537321355

Epoch: 5| Step: 7
Training loss: 2.620532512664795
Validation loss: 2.851171091038694

Epoch: 5| Step: 8
Training loss: 2.9755847454071045
Validation loss: 2.8516653327531714

Epoch: 5| Step: 9
Training loss: 2.3898274898529053
Validation loss: 2.849726738468293

Epoch: 5| Step: 10
Training loss: 2.32531476020813
Validation loss: 2.849094929233674

Epoch: 37| Step: 0
Training loss: 3.373413562774658
Validation loss: 2.8496920498468543

Epoch: 5| Step: 1
Training loss: 2.688035249710083
Validation loss: 2.8487920799563007

Epoch: 5| Step: 2
Training loss: 2.673865795135498
Validation loss: 2.8483233785116546

Epoch: 5| Step: 3
Training loss: 2.639436721801758
Validation loss: 2.847330895803308

Epoch: 5| Step: 4
Training loss: 2.875974178314209
Validation loss: 2.84831480826101

Epoch: 5| Step: 5
Training loss: 3.3582382202148438
Validation loss: 2.848348891863259

Epoch: 5| Step: 6
Training loss: 2.887765407562256
Validation loss: 2.8461661954079904

Epoch: 5| Step: 7
Training loss: 3.6034340858459473
Validation loss: 2.84727890517122

Epoch: 5| Step: 8
Training loss: 2.9897549152374268
Validation loss: 2.8461829129085747

Epoch: 5| Step: 9
Training loss: 2.629333019256592
Validation loss: 2.846677928842524

Epoch: 5| Step: 10
Training loss: 2.8503620624542236
Validation loss: 2.8473288218180337

Epoch: 38| Step: 0
Training loss: 2.945554256439209
Validation loss: 2.848402202770274

Epoch: 5| Step: 1
Training loss: 3.6761317253112793
Validation loss: 2.8465113280921854

Epoch: 5| Step: 2
Training loss: 2.4847216606140137
Validation loss: 2.84590979032619

Epoch: 5| Step: 3
Training loss: 2.669703960418701
Validation loss: 2.8455576383939354

Epoch: 5| Step: 4
Training loss: 2.5996413230895996
Validation loss: 2.8433530151203112

Epoch: 5| Step: 5
Training loss: 2.8165440559387207
Validation loss: 2.8426064393853627

Epoch: 5| Step: 6
Training loss: 2.921062707901001
Validation loss: 2.8421584688207155

Epoch: 5| Step: 7
Training loss: 2.8760769367218018
Validation loss: 2.8438846295879734

Epoch: 5| Step: 8
Training loss: 3.251338243484497
Validation loss: 2.8421417359382875

Epoch: 5| Step: 9
Training loss: 3.592723846435547
Validation loss: 2.842934464895597

Epoch: 5| Step: 10
Training loss: 2.6950275897979736
Validation loss: 2.8416795397317536

Epoch: 39| Step: 0
Training loss: 3.2567009925842285
Validation loss: 2.8420485860557965

Epoch: 5| Step: 1
Training loss: 2.8221187591552734
Validation loss: 2.842390747480495

Epoch: 5| Step: 2
Training loss: 3.8899478912353516
Validation loss: 2.840711780773696

Epoch: 5| Step: 3
Training loss: 2.404731273651123
Validation loss: 2.8415827110249507

Epoch: 5| Step: 4
Training loss: 2.9421935081481934
Validation loss: 2.8395574579956713

Epoch: 5| Step: 5
Training loss: 3.0448222160339355
Validation loss: 2.8401409759316394

Epoch: 5| Step: 6
Training loss: 3.186532497406006
Validation loss: 2.8392885013293196

Epoch: 5| Step: 7
Training loss: 2.947462558746338
Validation loss: 2.8380789038955525

Epoch: 5| Step: 8
Training loss: 3.175828456878662
Validation loss: 2.8379085089570735

Epoch: 5| Step: 9
Training loss: 2.257535457611084
Validation loss: 2.840569024444908

Epoch: 5| Step: 10
Training loss: 2.554405450820923
Validation loss: 2.838759199265511

Epoch: 40| Step: 0
Training loss: 2.249966859817505
Validation loss: 2.8393535742195706

Epoch: 5| Step: 1
Training loss: 3.0250773429870605
Validation loss: 2.842987278456329

Epoch: 5| Step: 2
Training loss: 3.320479154586792
Validation loss: 2.838935093213153

Epoch: 5| Step: 3
Training loss: 2.5300164222717285
Validation loss: 2.8398177751930813

Epoch: 5| Step: 4
Training loss: 2.331745147705078
Validation loss: 2.8390432685934086

Epoch: 5| Step: 5
Training loss: 2.7292637825012207
Validation loss: 2.8390212059020996

Epoch: 5| Step: 6
Training loss: 4.060192584991455
Validation loss: 2.843604754376155

Epoch: 5| Step: 7
Training loss: 3.8161118030548096
Validation loss: 2.842458535266179

Epoch: 5| Step: 8
Training loss: 3.216904878616333
Validation loss: 2.8426325833925636

Epoch: 5| Step: 9
Training loss: 2.547187328338623
Validation loss: 2.8392089464331187

Epoch: 5| Step: 10
Training loss: 2.6484012603759766
Validation loss: 2.8359729884773173

Epoch: 41| Step: 0
Training loss: 3.0483598709106445
Validation loss: 2.8353354956514094

Epoch: 5| Step: 1
Training loss: 3.0379531383514404
Validation loss: 2.8338840776874172

Epoch: 5| Step: 2
Training loss: 3.3551063537597656
Validation loss: 2.836779502130324

Epoch: 5| Step: 3
Training loss: 2.4434092044830322
Validation loss: 2.8337771841274795

Epoch: 5| Step: 4
Training loss: 3.2811226844787598
Validation loss: 2.8347471990892963

Epoch: 5| Step: 5
Training loss: 2.3671534061431885
Validation loss: 2.8336018772535425

Epoch: 5| Step: 6
Training loss: 2.825422763824463
Validation loss: 2.834762957788283

Epoch: 5| Step: 7
Training loss: 2.4845478534698486
Validation loss: 2.8325874933632473

Epoch: 5| Step: 8
Training loss: 3.9329349994659424
Validation loss: 2.8346065013639388

Epoch: 5| Step: 9
Training loss: 3.015285015106201
Validation loss: 2.8461191782387356

Epoch: 5| Step: 10
Training loss: 2.6802046298980713
Validation loss: 2.8513040491329726

Epoch: 42| Step: 0
Training loss: 2.531745195388794
Validation loss: 2.8409695907305648

Epoch: 5| Step: 1
Training loss: 2.9840965270996094
Validation loss: 2.8327599007596254

Epoch: 5| Step: 2
Training loss: 3.1047909259796143
Validation loss: 2.8351483370668147

Epoch: 5| Step: 3
Training loss: 3.1357548236846924
Validation loss: 2.835721577367475

Epoch: 5| Step: 4
Training loss: 3.0458943843841553
Validation loss: 2.834419160760859

Epoch: 5| Step: 5
Training loss: 2.7622408866882324
Validation loss: 2.8336852212106027

Epoch: 5| Step: 6
Training loss: 2.947709321975708
Validation loss: 2.833886933583085

Epoch: 5| Step: 7
Training loss: 2.1889071464538574
Validation loss: 2.835595484702818

Epoch: 5| Step: 8
Training loss: 2.7754669189453125
Validation loss: 2.835392003418297

Epoch: 5| Step: 9
Training loss: 3.3652679920196533
Validation loss: 2.83431677920844

Epoch: 5| Step: 10
Training loss: 3.797456979751587
Validation loss: 2.835112661443731

Epoch: 43| Step: 0
Training loss: 1.7356268167495728
Validation loss: 2.8334589132698635

Epoch: 5| Step: 1
Training loss: 2.83522891998291
Validation loss: 2.8346716832089167

Epoch: 5| Step: 2
Training loss: 3.3986709117889404
Validation loss: 2.835711940642326

Epoch: 5| Step: 3
Training loss: 2.4599952697753906
Validation loss: 2.8369743593277468

Epoch: 5| Step: 4
Training loss: 2.7837486267089844
Validation loss: 2.8483237912577968

Epoch: 5| Step: 5
Training loss: 3.9323341846466064
Validation loss: 2.8490992592227076

Epoch: 5| Step: 6
Training loss: 2.970745086669922
Validation loss: 2.8379275132251043

Epoch: 5| Step: 7
Training loss: 3.1623446941375732
Validation loss: 2.834792667819608

Epoch: 5| Step: 8
Training loss: 2.926872730255127
Validation loss: 2.8316946183481524

Epoch: 5| Step: 9
Training loss: 2.726640462875366
Validation loss: 2.829813498322682

Epoch: 5| Step: 10
Training loss: 3.664146900177002
Validation loss: 2.8311139588714926

Epoch: 44| Step: 0
Training loss: 2.1845290660858154
Validation loss: 2.8312841615369244

Epoch: 5| Step: 1
Training loss: 3.1674561500549316
Validation loss: 2.831238454388034

Epoch: 5| Step: 2
Training loss: 3.3325905799865723
Validation loss: 2.8303164999972106

Epoch: 5| Step: 3
Training loss: 3.1193459033966064
Validation loss: 2.8322051058533373

Epoch: 5| Step: 4
Training loss: 3.1856071949005127
Validation loss: 2.8312410590469197

Epoch: 5| Step: 5
Training loss: 3.1352577209472656
Validation loss: 2.831825228147609

Epoch: 5| Step: 6
Training loss: 2.773418426513672
Validation loss: 2.8303048610687256

Epoch: 5| Step: 7
Training loss: 2.7373461723327637
Validation loss: 2.830833755513673

Epoch: 5| Step: 8
Training loss: 2.758692502975464
Validation loss: 2.8308770066948346

Epoch: 5| Step: 9
Training loss: 2.6962738037109375
Validation loss: 2.8319290940479567

Epoch: 5| Step: 10
Training loss: 3.4412384033203125
Validation loss: 2.8314184963062243

Epoch: 45| Step: 0
Training loss: 3.3995137214660645
Validation loss: 2.8299465563989457

Epoch: 5| Step: 1
Training loss: 3.4829413890838623
Validation loss: 2.8304308076058664

Epoch: 5| Step: 2
Training loss: 2.597975730895996
Validation loss: 2.8287431399027505

Epoch: 5| Step: 3
Training loss: 2.086261034011841
Validation loss: 2.8285670126638105

Epoch: 5| Step: 4
Training loss: 2.0451412200927734
Validation loss: 2.827674050484934

Epoch: 5| Step: 5
Training loss: 2.685347318649292
Validation loss: 2.8252372126425467

Epoch: 5| Step: 6
Training loss: 3.3867790699005127
Validation loss: 2.826229538968814

Epoch: 5| Step: 7
Training loss: 2.8604888916015625
Validation loss: 2.8257252516285067

Epoch: 5| Step: 8
Training loss: 2.605271339416504
Validation loss: 2.826083967762609

Epoch: 5| Step: 9
Training loss: 4.226224899291992
Validation loss: 2.8262631790612334

Epoch: 5| Step: 10
Training loss: 3.0920422077178955
Validation loss: 2.8252021881841842

Epoch: 46| Step: 0
Training loss: 3.0679266452789307
Validation loss: 2.8278103208029144

Epoch: 5| Step: 1
Training loss: 3.3813576698303223
Validation loss: 2.824763867162889

Epoch: 5| Step: 2
Training loss: 2.435412883758545
Validation loss: 2.826396434537826

Epoch: 5| Step: 3
Training loss: 2.5546212196350098
Validation loss: 2.8258435008346394

Epoch: 5| Step: 4
Training loss: 2.7570531368255615
Validation loss: 2.825720687066355

Epoch: 5| Step: 5
Training loss: 3.4076716899871826
Validation loss: 2.826272313312818

Epoch: 5| Step: 6
Training loss: 2.7776198387145996
Validation loss: 2.8250132632511917

Epoch: 5| Step: 7
Training loss: 2.651710033416748
Validation loss: 2.8249016731016097

Epoch: 5| Step: 8
Training loss: 3.6005375385284424
Validation loss: 2.825251556211902

Epoch: 5| Step: 9
Training loss: 3.1069281101226807
Validation loss: 2.823382521188387

Epoch: 5| Step: 10
Training loss: 2.624552011489868
Validation loss: 2.8229776684955885

Epoch: 47| Step: 0
Training loss: 3.3405323028564453
Validation loss: 2.8233720666618756

Epoch: 5| Step: 1
Training loss: 3.3205406665802
Validation loss: 2.820977308416879

Epoch: 5| Step: 2
Training loss: 3.162992000579834
Validation loss: 2.8211864707290486

Epoch: 5| Step: 3
Training loss: 2.1542110443115234
Validation loss: 2.820919131719938

Epoch: 5| Step: 4
Training loss: 3.1838455200195312
Validation loss: 2.821413852835214

Epoch: 5| Step: 5
Training loss: 2.9313881397247314
Validation loss: 2.820476024381576

Epoch: 5| Step: 6
Training loss: 2.20906138420105
Validation loss: 2.8210525487058904

Epoch: 5| Step: 7
Training loss: 2.8939669132232666
Validation loss: 2.818838116943195

Epoch: 5| Step: 8
Training loss: 2.566594362258911
Validation loss: 2.820284407625916

Epoch: 5| Step: 9
Training loss: 3.3924193382263184
Validation loss: 2.8203175913903022

Epoch: 5| Step: 10
Training loss: 3.281414747238159
Validation loss: 2.820501394169305

Epoch: 48| Step: 0
Training loss: 2.8619747161865234
Validation loss: 2.819992211557204

Epoch: 5| Step: 1
Training loss: 2.61854887008667
Validation loss: 2.820906792917559

Epoch: 5| Step: 2
Training loss: 2.380157709121704
Validation loss: 2.8207950233131327

Epoch: 5| Step: 3
Training loss: 3.0484981536865234
Validation loss: 2.823419406849851

Epoch: 5| Step: 4
Training loss: 3.237245559692383
Validation loss: 2.826305274040468

Epoch: 5| Step: 5
Training loss: 2.9895718097686768
Validation loss: 2.8258470553223805

Epoch: 5| Step: 6
Training loss: 3.2595622539520264
Validation loss: 2.823622739443215

Epoch: 5| Step: 7
Training loss: 3.5986790657043457
Validation loss: 2.8243393462191344

Epoch: 5| Step: 8
Training loss: 2.9397389888763428
Validation loss: 2.8199168866680515

Epoch: 5| Step: 9
Training loss: 2.2282936573028564
Validation loss: 2.8201985282282673

Epoch: 5| Step: 10
Training loss: 3.236910820007324
Validation loss: 2.815970359310027

Epoch: 49| Step: 0
Training loss: 2.841165542602539
Validation loss: 2.815027818884901

Epoch: 5| Step: 1
Training loss: 2.290738344192505
Validation loss: 2.815171657070037

Epoch: 5| Step: 2
Training loss: 3.039843797683716
Validation loss: 2.815412588016961

Epoch: 5| Step: 3
Training loss: 2.7814667224884033
Validation loss: 2.813836269481208

Epoch: 5| Step: 4
Training loss: 3.5591723918914795
Validation loss: 2.815118169271818

Epoch: 5| Step: 5
Training loss: 3.0142264366149902
Validation loss: 2.8135258690003426

Epoch: 5| Step: 6
Training loss: 3.358248472213745
Validation loss: 2.8151539935860583

Epoch: 5| Step: 7
Training loss: 2.993025541305542
Validation loss: 2.813978574609244

Epoch: 5| Step: 8
Training loss: 3.434460163116455
Validation loss: 2.8142049774046867

Epoch: 5| Step: 9
Training loss: 2.380794048309326
Validation loss: 2.815559123152046

Epoch: 5| Step: 10
Training loss: 2.6167993545532227
Validation loss: 2.814449425666563

Epoch: 50| Step: 0
Training loss: 2.9350998401641846
Validation loss: 2.814472036976968

Epoch: 5| Step: 1
Training loss: 3.1234049797058105
Validation loss: 2.812782367070516

Epoch: 5| Step: 2
Training loss: 3.7040436267852783
Validation loss: 2.813870794029646

Epoch: 5| Step: 3
Training loss: 2.0741360187530518
Validation loss: 2.814569632212321

Epoch: 5| Step: 4
Training loss: 3.0520517826080322
Validation loss: 2.8139004912427676

Epoch: 5| Step: 5
Training loss: 2.920008897781372
Validation loss: 2.8133762703146985

Epoch: 5| Step: 6
Training loss: 2.3945460319519043
Validation loss: 2.81826522017038

Epoch: 5| Step: 7
Training loss: 3.285205125808716
Validation loss: 2.8166108618500414

Epoch: 5| Step: 8
Training loss: 2.4135680198669434
Validation loss: 2.819631204810194

Epoch: 5| Step: 9
Training loss: 2.9232430458068848
Validation loss: 2.8246478214058826

Epoch: 5| Step: 10
Training loss: 3.584488868713379
Validation loss: 2.821441840100032

Testing loss: 2.888253000047472
