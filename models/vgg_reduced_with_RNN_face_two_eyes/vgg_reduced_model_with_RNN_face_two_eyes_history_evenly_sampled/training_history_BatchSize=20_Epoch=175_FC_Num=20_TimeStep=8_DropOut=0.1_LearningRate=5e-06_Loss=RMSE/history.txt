Epoch: 1| Step: 0
Training loss: 5.151794358029237
Validation loss: 5.752702089710131

Epoch: 5| Step: 1
Training loss: 4.602930769024091
Validation loss: 5.747273530366951

Epoch: 5| Step: 2
Training loss: 6.633420954497786
Validation loss: 5.742312340561378

Epoch: 5| Step: 3
Training loss: 5.332053786010068
Validation loss: 5.737253046302994

Epoch: 5| Step: 4
Training loss: 5.287700077537052
Validation loss: 5.732268838631509

Epoch: 5| Step: 5
Training loss: 7.137153031822857
Validation loss: 5.727773208377367

Epoch: 5| Step: 6
Training loss: 6.317405079112289
Validation loss: 5.722739512914266

Epoch: 5| Step: 7
Training loss: 6.547274993840621
Validation loss: 5.7179474994065975

Epoch: 5| Step: 8
Training loss: 5.054131643871575
Validation loss: 5.713486687439097

Epoch: 5| Step: 9
Training loss: 5.288929789693989
Validation loss: 5.708152020207171

Epoch: 5| Step: 10
Training loss: 5.450282189299299
Validation loss: 5.703166950390137

Epoch: 2| Step: 0
Training loss: 6.071624496247894
Validation loss: 5.69787028690998

Epoch: 5| Step: 1
Training loss: 5.361514540247299
Validation loss: 5.692242238849493

Epoch: 5| Step: 2
Training loss: 4.95101315697278
Validation loss: 5.686911185444241

Epoch: 5| Step: 3
Training loss: 5.062218175508175
Validation loss: 5.6807863316448435

Epoch: 5| Step: 4
Training loss: 5.494446638462788
Validation loss: 5.67491357920137

Epoch: 5| Step: 5
Training loss: 6.277502659683545
Validation loss: 5.668246048524596

Epoch: 5| Step: 6
Training loss: 6.043008519382711
Validation loss: 5.66109105147938

Epoch: 5| Step: 7
Training loss: 6.968798992172937
Validation loss: 5.65359096814397

Epoch: 5| Step: 8
Training loss: 5.620899995031969
Validation loss: 5.646235647792464

Epoch: 5| Step: 9
Training loss: 4.66749740200042
Validation loss: 5.637665955833157

Epoch: 5| Step: 10
Training loss: 5.8674244839165075
Validation loss: 5.629465392124202

Epoch: 3| Step: 0
Training loss: 4.892294699250691
Validation loss: 5.620650701232234

Epoch: 5| Step: 1
Training loss: 6.096179340978499
Validation loss: 5.61097483735309

Epoch: 5| Step: 2
Training loss: 5.849669044457772
Validation loss: 5.601451956269658

Epoch: 5| Step: 3
Training loss: 6.176205586109851
Validation loss: 5.5912036087399235

Epoch: 5| Step: 4
Training loss: 5.914975134957709
Validation loss: 5.580388850971383

Epoch: 5| Step: 5
Training loss: 4.740418457681839
Validation loss: 5.569228708274248

Epoch: 5| Step: 6
Training loss: 5.569476606614922
Validation loss: 5.558300620032571

Epoch: 5| Step: 7
Training loss: 6.601756365034345
Validation loss: 5.5460278046775064

Epoch: 5| Step: 8
Training loss: 5.3280328200076905
Validation loss: 5.532841012320375

Epoch: 5| Step: 9
Training loss: 5.495532562300996
Validation loss: 5.51979258644144

Epoch: 5| Step: 10
Training loss: 4.522044756378084
Validation loss: 5.506456176790812

Epoch: 4| Step: 0
Training loss: 4.956414607466611
Validation loss: 5.492848494706639

Epoch: 5| Step: 1
Training loss: 5.685974922696476
Validation loss: 5.47848377848424

Epoch: 5| Step: 2
Training loss: 6.112043417511759
Validation loss: 5.464607307129692

Epoch: 5| Step: 3
Training loss: 5.50771865223681
Validation loss: 5.44881921300934

Epoch: 5| Step: 4
Training loss: 4.966887502859759
Validation loss: 5.433707687891184

Epoch: 5| Step: 5
Training loss: 5.853213557333604
Validation loss: 5.417932714859432

Epoch: 5| Step: 6
Training loss: 5.239559873777418
Validation loss: 5.401129707806052

Epoch: 5| Step: 7
Training loss: 5.197800670035349
Validation loss: 5.385586797208324

Epoch: 5| Step: 8
Training loss: 5.297018673729023
Validation loss: 5.36918826552408

Epoch: 5| Step: 9
Training loss: 5.265700885893743
Validation loss: 5.353206231246263

Epoch: 5| Step: 10
Training loss: 5.945508194257938
Validation loss: 5.336434959601962

Epoch: 5| Step: 0
Training loss: 5.114681556312704
Validation loss: 5.319830445659334

Epoch: 5| Step: 1
Training loss: 5.497213871731979
Validation loss: 5.301511048701057

Epoch: 5| Step: 2
Training loss: 5.669057603458279
Validation loss: 5.28507625258963

Epoch: 5| Step: 3
Training loss: 5.441139493977334
Validation loss: 5.269097610447219

Epoch: 5| Step: 4
Training loss: 5.232180918420725
Validation loss: 5.250547856088633

Epoch: 5| Step: 5
Training loss: 5.549227535343426
Validation loss: 5.234134932675643

Epoch: 5| Step: 6
Training loss: 5.188670933947441
Validation loss: 5.216483144720731

Epoch: 5| Step: 7
Training loss: 5.145405225152852
Validation loss: 5.197506850736962

Epoch: 5| Step: 8
Training loss: 5.404189229705854
Validation loss: 5.182311583606598

Epoch: 5| Step: 9
Training loss: 4.426126653487218
Validation loss: 5.1639607806879155

Epoch: 5| Step: 10
Training loss: 5.437330221397579
Validation loss: 5.145966476518775

Epoch: 6| Step: 0
Training loss: 4.533203335375372
Validation loss: 5.126882630003703

Epoch: 5| Step: 1
Training loss: 4.869580508735294
Validation loss: 5.108075185833822

Epoch: 5| Step: 2
Training loss: 4.699208602830899
Validation loss: 5.0908025833947015

Epoch: 5| Step: 3
Training loss: 5.111629257106718
Validation loss: 5.07085820625389

Epoch: 5| Step: 4
Training loss: 5.2679736958095384
Validation loss: 5.050666076292604

Epoch: 5| Step: 5
Training loss: 5.126599504173921
Validation loss: 5.031202188288976

Epoch: 5| Step: 6
Training loss: 5.252167208994336
Validation loss: 5.009877841743861

Epoch: 5| Step: 7
Training loss: 5.752247246830744
Validation loss: 4.989738484379128

Epoch: 5| Step: 8
Training loss: 5.217196113279989
Validation loss: 4.969220514322584

Epoch: 5| Step: 9
Training loss: 5.021273750626961
Validation loss: 4.9494441695146385

Epoch: 5| Step: 10
Training loss: 5.073886452264058
Validation loss: 4.928323817425245

Epoch: 7| Step: 0
Training loss: 4.958180443893605
Validation loss: 4.909624571437176

Epoch: 5| Step: 1
Training loss: 5.208470986136693
Validation loss: 4.891232361583079

Epoch: 5| Step: 2
Training loss: 4.683824649620081
Validation loss: 4.871377611440399

Epoch: 5| Step: 3
Training loss: 5.4714036879067915
Validation loss: 4.852610469291712

Epoch: 5| Step: 4
Training loss: 4.918665635816577
Validation loss: 4.832839252450435

Epoch: 5| Step: 5
Training loss: 5.302990469184323
Validation loss: 4.810897234238908

Epoch: 5| Step: 6
Training loss: 4.502557028028564
Validation loss: 4.7896882148122835

Epoch: 5| Step: 7
Training loss: 4.973062239477778
Validation loss: 4.7652502016444656

Epoch: 5| Step: 8
Training loss: 4.449764442638588
Validation loss: 4.741530094198018

Epoch: 5| Step: 9
Training loss: 4.760920168948703
Validation loss: 4.718289873409535

Epoch: 5| Step: 10
Training loss: 4.349708915705416
Validation loss: 4.691170969154972

Epoch: 8| Step: 0
Training loss: 5.133634411458203
Validation loss: 4.667691240622801

Epoch: 5| Step: 1
Training loss: 4.218068611784392
Validation loss: 4.648358561189462

Epoch: 5| Step: 2
Training loss: 4.906780238564828
Validation loss: 4.635421383855212

Epoch: 5| Step: 3
Training loss: 4.679895972701489
Validation loss: 4.621392845262226

Epoch: 5| Step: 4
Training loss: 3.873673365752907
Validation loss: 4.605576979573639

Epoch: 5| Step: 5
Training loss: 4.413608547937698
Validation loss: 4.5922069099456895

Epoch: 5| Step: 6
Training loss: 4.923205192893944
Validation loss: 4.577633580028046

Epoch: 5| Step: 7
Training loss: 5.1918989167329
Validation loss: 4.562928223921236

Epoch: 5| Step: 8
Training loss: 5.315934092277433
Validation loss: 4.546620236545453

Epoch: 5| Step: 9
Training loss: 4.047773460306532
Validation loss: 4.532154615016635

Epoch: 5| Step: 10
Training loss: 4.573491691057167
Validation loss: 4.515162574323918

Epoch: 9| Step: 0
Training loss: 4.922475045578273
Validation loss: 4.5006749707708575

Epoch: 5| Step: 1
Training loss: 5.132571140693739
Validation loss: 4.487622560949238

Epoch: 5| Step: 2
Training loss: 4.4360080413745475
Validation loss: 4.472694197846293

Epoch: 5| Step: 3
Training loss: 4.96930888169761
Validation loss: 4.461226424634408

Epoch: 5| Step: 4
Training loss: 4.204614538426566
Validation loss: 4.450629902044198

Epoch: 5| Step: 5
Training loss: 4.539914391000375
Validation loss: 4.436465468465214

Epoch: 5| Step: 6
Training loss: 3.4285224899704825
Validation loss: 4.4255775132735

Epoch: 5| Step: 7
Training loss: 4.333031472671767
Validation loss: 4.413103233715796

Epoch: 5| Step: 8
Training loss: 4.897892923215071
Validation loss: 4.39925131072738

Epoch: 5| Step: 9
Training loss: 4.9063215311266415
Validation loss: 4.387686856798228

Epoch: 5| Step: 10
Training loss: 3.863510942718345
Validation loss: 4.374822131876006

Epoch: 10| Step: 0
Training loss: 4.288112069530087
Validation loss: 4.364334186657064

Epoch: 5| Step: 1
Training loss: 5.109999685567409
Validation loss: 4.351907589866575

Epoch: 5| Step: 2
Training loss: 3.909262144318348
Validation loss: 4.3399334490082335

Epoch: 5| Step: 3
Training loss: 4.609554998471713
Validation loss: 4.328323776095132

Epoch: 5| Step: 4
Training loss: 3.6263364761703127
Validation loss: 4.316159401125564

Epoch: 5| Step: 5
Training loss: 4.43601191109932
Validation loss: 4.3064262940450355

Epoch: 5| Step: 6
Training loss: 4.808877944295309
Validation loss: 4.292858880893748

Epoch: 5| Step: 7
Training loss: 4.566857125610271
Validation loss: 4.28236744040768

Epoch: 5| Step: 8
Training loss: 5.540056534902158
Validation loss: 4.268635820095821

Epoch: 5| Step: 9
Training loss: 3.777495987673534
Validation loss: 4.255578281183368

Epoch: 5| Step: 10
Training loss: 3.391106356015697
Validation loss: 4.245248465611205

Epoch: 11| Step: 0
Training loss: 4.070199097208633
Validation loss: 4.231905723624286

Epoch: 5| Step: 1
Training loss: 4.164606627793051
Validation loss: 4.221136040501418

Epoch: 5| Step: 2
Training loss: 4.946213963984438
Validation loss: 4.206189761714551

Epoch: 5| Step: 3
Training loss: 4.185296461025766
Validation loss: 4.198987233103504

Epoch: 5| Step: 4
Training loss: 4.1063715761438715
Validation loss: 4.186678126662824

Epoch: 5| Step: 5
Training loss: 5.073662026209587
Validation loss: 4.174853807021372

Epoch: 5| Step: 6
Training loss: 4.420362881224683
Validation loss: 4.1619450542244865

Epoch: 5| Step: 7
Training loss: 3.4124436370331064
Validation loss: 4.152398439816874

Epoch: 5| Step: 8
Training loss: 3.762226771575807
Validation loss: 4.143955705662853

Epoch: 5| Step: 9
Training loss: 4.227355318577083
Validation loss: 4.131495550064443

Epoch: 5| Step: 10
Training loss: 4.8169287578374105
Validation loss: 4.120935741716359

Epoch: 12| Step: 0
Training loss: 4.79543101293862
Validation loss: 4.1108763093827

Epoch: 5| Step: 1
Training loss: 3.397724366179557
Validation loss: 4.103076694924799

Epoch: 5| Step: 2
Training loss: 4.409338335497148
Validation loss: 4.0902616719429075

Epoch: 5| Step: 3
Training loss: 4.423847095709876
Validation loss: 4.082695372274771

Epoch: 5| Step: 4
Training loss: 4.807027901149695
Validation loss: 4.072647375784363

Epoch: 5| Step: 5
Training loss: 4.201760676864465
Validation loss: 4.067678969832408

Epoch: 5| Step: 6
Training loss: 4.106455879333907
Validation loss: 4.058490573774474

Epoch: 5| Step: 7
Training loss: 4.799986386279827
Validation loss: 4.050961597812293

Epoch: 5| Step: 8
Training loss: 3.4024816544239305
Validation loss: 4.045049105550402

Epoch: 5| Step: 9
Training loss: 3.830747865812338
Validation loss: 4.038745377918232

Epoch: 5| Step: 10
Training loss: 3.794444244059577
Validation loss: 4.03118890841796

Epoch: 13| Step: 0
Training loss: 3.794229975445266
Validation loss: 4.0266123234858275

Epoch: 5| Step: 1
Training loss: 4.615747424073041
Validation loss: 4.019657646408317

Epoch: 5| Step: 2
Training loss: 4.4210268966384705
Validation loss: 4.016150045243146

Epoch: 5| Step: 3
Training loss: 4.477208595186243
Validation loss: 4.009418081425319

Epoch: 5| Step: 4
Training loss: 3.683221695072632
Validation loss: 4.001830956092553

Epoch: 5| Step: 5
Training loss: 4.37599345235666
Validation loss: 3.993868869145665

Epoch: 5| Step: 6
Training loss: 3.225681877499562
Validation loss: 3.979064243422082

Epoch: 5| Step: 7
Training loss: 4.505039148700402
Validation loss: 3.9644712353846243

Epoch: 5| Step: 8
Training loss: 4.377081675516306
Validation loss: 3.954475992668333

Epoch: 5| Step: 9
Training loss: 4.194847379506615
Validation loss: 3.9477351111712076

Epoch: 5| Step: 10
Training loss: 3.5376341507887243
Validation loss: 3.945993858104392

Epoch: 14| Step: 0
Training loss: 3.585972605016076
Validation loss: 3.9404409935977056

Epoch: 5| Step: 1
Training loss: 4.172455365106224
Validation loss: 3.9366309839087625

Epoch: 5| Step: 2
Training loss: 3.028402032767498
Validation loss: 3.9280367785362413

Epoch: 5| Step: 3
Training loss: 4.713160760427942
Validation loss: 3.9220689464868355

Epoch: 5| Step: 4
Training loss: 4.790846027369173
Validation loss: 3.9238291180947913

Epoch: 5| Step: 5
Training loss: 3.2993763478835123
Validation loss: 3.9151423221121386

Epoch: 5| Step: 6
Training loss: 4.3375384150406235
Validation loss: 3.9077619183741645

Epoch: 5| Step: 7
Training loss: 4.33224742683679
Validation loss: 3.899555633603866

Epoch: 5| Step: 8
Training loss: 4.439425843033748
Validation loss: 3.894797778374564

Epoch: 5| Step: 9
Training loss: 4.1153486224204165
Validation loss: 3.8901862163782908

Epoch: 5| Step: 10
Training loss: 3.5070757867539224
Validation loss: 3.8832620538046747

Epoch: 15| Step: 0
Training loss: 4.457763611705614
Validation loss: 3.879702347659658

Epoch: 5| Step: 1
Training loss: 4.093285221185734
Validation loss: 3.8777812102849007

Epoch: 5| Step: 2
Training loss: 4.6529072276970735
Validation loss: 3.8645951341884963

Epoch: 5| Step: 3
Training loss: 3.3698895227451913
Validation loss: 3.845986016779124

Epoch: 5| Step: 4
Training loss: 4.348555287703028
Validation loss: 3.833491789354792

Epoch: 5| Step: 5
Training loss: 3.7714077562938484
Validation loss: 3.822382628972977

Epoch: 5| Step: 6
Training loss: 3.329727288612135
Validation loss: 3.8146041666226798

Epoch: 5| Step: 7
Training loss: 4.990566892052719
Validation loss: 3.8145727463716206

Epoch: 5| Step: 8
Training loss: 3.2816401658377403
Validation loss: 3.809258632212843

Epoch: 5| Step: 9
Training loss: 4.095569235487407
Validation loss: 3.8048542861512873

Epoch: 5| Step: 10
Training loss: 3.04702116786814
Validation loss: 3.800255520373483

Epoch: 16| Step: 0
Training loss: 4.003461532085902
Validation loss: 3.798597725440226

Epoch: 5| Step: 1
Training loss: 4.4079893750791355
Validation loss: 3.7947565222923725

Epoch: 5| Step: 2
Training loss: 3.245578692873698
Validation loss: 3.79238232972972

Epoch: 5| Step: 3
Training loss: 3.429880610353914
Validation loss: 3.7876047885645203

Epoch: 5| Step: 4
Training loss: 3.4039616728887543
Validation loss: 3.781943388928078

Epoch: 5| Step: 5
Training loss: 4.317526941971911
Validation loss: 3.78014357388413

Epoch: 5| Step: 6
Training loss: 3.3279509163042906
Validation loss: 3.776346516027357

Epoch: 5| Step: 7
Training loss: 4.179008870871449
Validation loss: 3.772153131298679

Epoch: 5| Step: 8
Training loss: 3.8975290833979184
Validation loss: 3.7685276983088603

Epoch: 5| Step: 9
Training loss: 4.252411326583319
Validation loss: 3.7652133939146615

Epoch: 5| Step: 10
Training loss: 4.844713865792928
Validation loss: 3.7572439880510986

Epoch: 17| Step: 0
Training loss: 3.968501285959857
Validation loss: 3.7539102055060116

Epoch: 5| Step: 1
Training loss: 3.768121042482035
Validation loss: 3.753081848525434

Epoch: 5| Step: 2
Training loss: 3.986332670486752
Validation loss: 3.7482892047835663

Epoch: 5| Step: 3
Training loss: 3.631167985052323
Validation loss: 3.7453938487691065

Epoch: 5| Step: 4
Training loss: 3.9214738739478014
Validation loss: 3.740917636284898

Epoch: 5| Step: 5
Training loss: 4.156447556468486
Validation loss: 3.7382968775348977

Epoch: 5| Step: 6
Training loss: 3.793025824670353
Validation loss: 3.7369110205254734

Epoch: 5| Step: 7
Training loss: 4.400573753748779
Validation loss: 3.731028039290415

Epoch: 5| Step: 8
Training loss: 2.860992474447071
Validation loss: 3.7274867637244493

Epoch: 5| Step: 9
Training loss: 3.992059097166037
Validation loss: 3.725390010864231

Epoch: 5| Step: 10
Training loss: 4.49265049414312
Validation loss: 3.7212068351512735

Epoch: 18| Step: 0
Training loss: 4.202261343220876
Validation loss: 3.718329199262107

Epoch: 5| Step: 1
Training loss: 4.249257191089448
Validation loss: 3.7149582770549707

Epoch: 5| Step: 2
Training loss: 4.021931131085335
Validation loss: 3.710694047749639

Epoch: 5| Step: 3
Training loss: 3.718417369167055
Validation loss: 3.709700013297438

Epoch: 5| Step: 4
Training loss: 3.8223046723302523
Validation loss: 3.704474954277591

Epoch: 5| Step: 5
Training loss: 3.903250435248309
Validation loss: 3.700042399712531

Epoch: 5| Step: 6
Training loss: 4.179893303198425
Validation loss: 3.699309677550395

Epoch: 5| Step: 7
Training loss: 3.1933332436335267
Validation loss: 3.6959441291525734

Epoch: 5| Step: 8
Training loss: 3.8964678541708033
Validation loss: 3.6939034749162087

Epoch: 5| Step: 9
Training loss: 3.716153560738214
Validation loss: 3.6906276597321352

Epoch: 5| Step: 10
Training loss: 3.7384687514203834
Validation loss: 3.6878905231186767

Epoch: 19| Step: 0
Training loss: 3.615020300463901
Validation loss: 3.68446706743291

Epoch: 5| Step: 1
Training loss: 3.0460986591073547
Validation loss: 3.6807163927522937

Epoch: 5| Step: 2
Training loss: 4.623790892218832
Validation loss: 3.6789584949880214

Epoch: 5| Step: 3
Training loss: 4.011620331831962
Validation loss: 3.676608024962295

Epoch: 5| Step: 4
Training loss: 3.1376839146910167
Validation loss: 3.672753604246427

Epoch: 5| Step: 5
Training loss: 4.503331117062385
Validation loss: 3.671815593922273

Epoch: 5| Step: 6
Training loss: 3.7111681414757
Validation loss: 3.6666315996240186

Epoch: 5| Step: 7
Training loss: 4.261584929297918
Validation loss: 3.6632758516898782

Epoch: 5| Step: 8
Training loss: 3.726285720239373
Validation loss: 3.661783136790255

Epoch: 5| Step: 9
Training loss: 3.7010295105782913
Validation loss: 3.659787452748794

Epoch: 5| Step: 10
Training loss: 3.803889823497342
Validation loss: 3.655406159320848

Epoch: 20| Step: 0
Training loss: 4.564261527522933
Validation loss: 3.6517995036985145

Epoch: 5| Step: 1
Training loss: 4.290976731233042
Validation loss: 3.651998564805918

Epoch: 5| Step: 2
Training loss: 3.0380076168685566
Validation loss: 3.647934926999544

Epoch: 5| Step: 3
Training loss: 3.592124505007121
Validation loss: 3.645892422573736

Epoch: 5| Step: 4
Training loss: 4.031201739355016
Validation loss: 3.641084704932561

Epoch: 5| Step: 5
Training loss: 3.8141065870813295
Validation loss: 3.6393194285727946

Epoch: 5| Step: 6
Training loss: 3.410572773773144
Validation loss: 3.635029410253013

Epoch: 5| Step: 7
Training loss: 3.5385647522662977
Validation loss: 3.632565444941558

Epoch: 5| Step: 8
Training loss: 4.635419706993678
Validation loss: 3.62993811646564

Epoch: 5| Step: 9
Training loss: 3.401079645962251
Validation loss: 3.628185866587455

Epoch: 5| Step: 10
Training loss: 3.443764682745398
Validation loss: 3.6252489566709873

Epoch: 21| Step: 0
Training loss: 3.8753314953186133
Validation loss: 3.6221997991279244

Epoch: 5| Step: 1
Training loss: 3.7515184507123456
Validation loss: 3.6184712004980497

Epoch: 5| Step: 2
Training loss: 3.933248495275367
Validation loss: 3.616376242033094

Epoch: 5| Step: 3
Training loss: 4.129712274241098
Validation loss: 3.6123347345129746

Epoch: 5| Step: 4
Training loss: 4.176453781568186
Validation loss: 3.6090193915424567

Epoch: 5| Step: 5
Training loss: 3.378825809645817
Validation loss: 3.607470674084383

Epoch: 5| Step: 6
Training loss: 3.89521426961827
Validation loss: 3.6027128104169823

Epoch: 5| Step: 7
Training loss: 4.146243332313234
Validation loss: 3.6028704332692976

Epoch: 5| Step: 8
Training loss: 4.04152417013654
Validation loss: 3.600682598206638

Epoch: 5| Step: 9
Training loss: 3.497158259287522
Validation loss: 3.5969691143490254

Epoch: 5| Step: 10
Training loss: 2.6293370884364915
Validation loss: 3.596995254062578

Epoch: 22| Step: 0
Training loss: 3.0577282222932585
Validation loss: 3.595919110948784

Epoch: 5| Step: 1
Training loss: 4.302791780356393
Validation loss: 3.596757985508994

Epoch: 5| Step: 2
Training loss: 4.430152074817055
Validation loss: 3.586010579300113

Epoch: 5| Step: 3
Training loss: 3.800965166493823
Validation loss: 3.5826877251831064

Epoch: 5| Step: 4
Training loss: 3.3409683208134
Validation loss: 3.581688278425378

Epoch: 5| Step: 5
Training loss: 4.7969471680620694
Validation loss: 3.580463543508461

Epoch: 5| Step: 6
Training loss: 3.0044882896272576
Validation loss: 3.57558651642213

Epoch: 5| Step: 7
Training loss: 3.7289619318562903
Validation loss: 3.5740690434312827

Epoch: 5| Step: 8
Training loss: 3.619243655356851
Validation loss: 3.5685289507893305

Epoch: 5| Step: 9
Training loss: 3.545896420363995
Validation loss: 3.5641517170768653

Epoch: 5| Step: 10
Training loss: 3.483298781252492
Validation loss: 3.564213800896011

Epoch: 23| Step: 0
Training loss: 3.8214683734364208
Validation loss: 3.5599635618316907

Epoch: 5| Step: 1
Training loss: 3.732839611876348
Validation loss: 3.56139572550127

Epoch: 5| Step: 2
Training loss: 4.006328107099242
Validation loss: 3.5643793922582776

Epoch: 5| Step: 3
Training loss: 4.155591869592236
Validation loss: 3.5525601556890463

Epoch: 5| Step: 4
Training loss: 3.8182969344319186
Validation loss: 3.5514843124427062

Epoch: 5| Step: 5
Training loss: 3.7265751676524084
Validation loss: 3.5488433067316745

Epoch: 5| Step: 6
Training loss: 3.7990422597905917
Validation loss: 3.547275565587582

Epoch: 5| Step: 7
Training loss: 3.7553083359748487
Validation loss: 3.5504631009061334

Epoch: 5| Step: 8
Training loss: 3.6975258777427302
Validation loss: 3.5433694605390706

Epoch: 5| Step: 9
Training loss: 3.745198545604237
Validation loss: 3.5398986780423614

Epoch: 5| Step: 10
Training loss: 2.7467465662522907
Validation loss: 3.538148888802177

Epoch: 24| Step: 0
Training loss: 4.251166688438672
Validation loss: 3.53559794680926

Epoch: 5| Step: 1
Training loss: 4.018967955093977
Validation loss: 3.532945515374361

Epoch: 5| Step: 2
Training loss: 3.579817592300008
Validation loss: 3.5290858688158506

Epoch: 5| Step: 3
Training loss: 4.30258897422279
Validation loss: 3.524262734936381

Epoch: 5| Step: 4
Training loss: 3.680279791395831
Validation loss: 3.5208810005861615

Epoch: 5| Step: 5
Training loss: 3.9472403773236957
Validation loss: 3.5223300143647336

Epoch: 5| Step: 6
Training loss: 3.261451792499746
Validation loss: 3.519379630898685

Epoch: 5| Step: 7
Training loss: 3.4880396982523685
Validation loss: 3.516040847229795

Epoch: 5| Step: 8
Training loss: 3.2648172794171737
Validation loss: 3.5139361650494947

Epoch: 5| Step: 9
Training loss: 3.226353082026191
Validation loss: 3.5108267979456285

Epoch: 5| Step: 10
Training loss: 3.827352640515802
Validation loss: 3.508864561022908

Epoch: 25| Step: 0
Training loss: 3.130012916562665
Validation loss: 3.5016926570657825

Epoch: 5| Step: 1
Training loss: 3.0966062365638565
Validation loss: 3.5032846768301917

Epoch: 5| Step: 2
Training loss: 3.891330639683406
Validation loss: 3.5002811248666066

Epoch: 5| Step: 3
Training loss: 4.257915754553626
Validation loss: 3.501221565214619

Epoch: 5| Step: 4
Training loss: 4.196179177894238
Validation loss: 3.4966592827747935

Epoch: 5| Step: 5
Training loss: 2.8768579864827615
Validation loss: 3.495072224148737

Epoch: 5| Step: 6
Training loss: 2.9073579378592185
Validation loss: 3.4886742607833825

Epoch: 5| Step: 7
Training loss: 4.415635954349912
Validation loss: 3.492265878297784

Epoch: 5| Step: 8
Training loss: 4.161252331399307
Validation loss: 3.4889860496380005

Epoch: 5| Step: 9
Training loss: 3.63039063151476
Validation loss: 3.486660321611302

Epoch: 5| Step: 10
Training loss: 3.760537917840818
Validation loss: 3.4893003204191957

Epoch: 26| Step: 0
Training loss: 3.2846595125527576
Validation loss: 3.4881580339610982

Epoch: 5| Step: 1
Training loss: 4.496387727275545
Validation loss: 3.4901031699567118

Epoch: 5| Step: 2
Training loss: 3.642047260453314
Validation loss: 3.478049454722087

Epoch: 5| Step: 3
Training loss: 3.592508118048875
Validation loss: 3.4744934702021806

Epoch: 5| Step: 4
Training loss: 3.4169275757948894
Validation loss: 3.473294046721573

Epoch: 5| Step: 5
Training loss: 3.858671178232054
Validation loss: 3.4728725494301678

Epoch: 5| Step: 6
Training loss: 3.2190652341083914
Validation loss: 3.4727403783809847

Epoch: 5| Step: 7
Training loss: 4.282356954435849
Validation loss: 3.4669792594810214

Epoch: 5| Step: 8
Training loss: 3.7488120422622484
Validation loss: 3.4625877565012413

Epoch: 5| Step: 9
Training loss: 2.999780011058493
Validation loss: 3.4624086562163585

Epoch: 5| Step: 10
Training loss: 3.791347923435422
Validation loss: 3.4596035953738706

Epoch: 27| Step: 0
Training loss: 3.6277284548413253
Validation loss: 3.459324601387066

Epoch: 5| Step: 1
Training loss: 4.135183306947307
Validation loss: 3.457288434224361

Epoch: 5| Step: 2
Training loss: 3.6070389226807476
Validation loss: 3.4549787678627206

Epoch: 5| Step: 3
Training loss: 4.256682135649205
Validation loss: 3.4523043994042917

Epoch: 5| Step: 4
Training loss: 3.040026357436108
Validation loss: 3.451214632140542

Epoch: 5| Step: 5
Training loss: 4.17547041018881
Validation loss: 3.44704211556053

Epoch: 5| Step: 6
Training loss: 3.8923877568069734
Validation loss: 3.445246062071719

Epoch: 5| Step: 7
Training loss: 3.3096146883090185
Validation loss: 3.4435852005393683

Epoch: 5| Step: 8
Training loss: 3.4606660689097017
Validation loss: 3.4420954499877134

Epoch: 5| Step: 9
Training loss: 2.979230671086166
Validation loss: 3.4400712853362405

Epoch: 5| Step: 10
Training loss: 3.60977580169475
Validation loss: 3.4395217543464636

Epoch: 28| Step: 0
Training loss: 3.6414120850662592
Validation loss: 3.439675985748655

Epoch: 5| Step: 1
Training loss: 3.7518245073282763
Validation loss: 3.434793621423501

Epoch: 5| Step: 2
Training loss: 3.251447208675802
Validation loss: 3.4377659475716458

Epoch: 5| Step: 3
Training loss: 4.678482537376736
Validation loss: 3.4416895866350914

Epoch: 5| Step: 4
Training loss: 3.2961206522311866
Validation loss: 3.4374894053425478

Epoch: 5| Step: 5
Training loss: 3.3023159454597457
Validation loss: 3.426579757293913

Epoch: 5| Step: 6
Training loss: 3.7140640098302304
Validation loss: 3.42659236531578

Epoch: 5| Step: 7
Training loss: 3.0241846546329447
Validation loss: 3.42769164358005

Epoch: 5| Step: 8
Training loss: 4.244688417392045
Validation loss: 3.4208934029891025

Epoch: 5| Step: 9
Training loss: 3.9827559229535128
Validation loss: 3.420173510060135

Epoch: 5| Step: 10
Training loss: 2.7287292615283305
Validation loss: 3.4180916746568735

Epoch: 29| Step: 0
Training loss: 4.197174511502337
Validation loss: 3.4173552906900846

Epoch: 5| Step: 1
Training loss: 3.9401365868376965
Validation loss: 3.415574238048346

Epoch: 5| Step: 2
Training loss: 3.9243593895886173
Validation loss: 3.4127741854998774

Epoch: 5| Step: 3
Training loss: 2.961678203445087
Validation loss: 3.410737509788039

Epoch: 5| Step: 4
Training loss: 3.5441066340470195
Validation loss: 3.409421266587919

Epoch: 5| Step: 5
Training loss: 4.351993998256921
Validation loss: 3.407258762602987

Epoch: 5| Step: 6
Training loss: 4.165166025138467
Validation loss: 3.4058620762212395

Epoch: 5| Step: 7
Training loss: 3.808798447023206
Validation loss: 3.407498442011543

Epoch: 5| Step: 8
Training loss: 2.891490085131635
Validation loss: 3.40319473148605

Epoch: 5| Step: 9
Training loss: 2.595024622982271
Validation loss: 3.4037460858582667

Epoch: 5| Step: 10
Training loss: 2.9813032869259133
Validation loss: 3.408883717226619

Epoch: 30| Step: 0
Training loss: 3.9020908033167427
Validation loss: 3.4102625465983145

Epoch: 5| Step: 1
Training loss: 3.081418981038856
Validation loss: 3.395529876070761

Epoch: 5| Step: 2
Training loss: 3.9933186998136336
Validation loss: 3.393472397494775

Epoch: 5| Step: 3
Training loss: 3.3665295022147403
Validation loss: 3.3920502286866507

Epoch: 5| Step: 4
Training loss: 4.232854028035487
Validation loss: 3.3907460232268836

Epoch: 5| Step: 5
Training loss: 3.680030369425973
Validation loss: 3.389920612099806

Epoch: 5| Step: 6
Training loss: 2.8052707586320147
Validation loss: 3.3897460929483296

Epoch: 5| Step: 7
Training loss: 3.567948842353319
Validation loss: 3.3874437047537396

Epoch: 5| Step: 8
Training loss: 3.914668662518539
Validation loss: 3.3886183968038552

Epoch: 5| Step: 9
Training loss: 3.6279943529734884
Validation loss: 3.3836616178527943

Epoch: 5| Step: 10
Training loss: 3.348553211315118
Validation loss: 3.3837766222870207

Epoch: 31| Step: 0
Training loss: 4.448367927524423
Validation loss: 3.380190688740272

Epoch: 5| Step: 1
Training loss: 3.76120634936647
Validation loss: 3.3793456806205255

Epoch: 5| Step: 2
Training loss: 3.785505564094901
Validation loss: 3.3743465935033625

Epoch: 5| Step: 3
Training loss: 3.9211532110952785
Validation loss: 3.37361590779212

Epoch: 5| Step: 4
Training loss: 3.1981399077156913
Validation loss: 3.3727810552441433

Epoch: 5| Step: 5
Training loss: 3.1034570860098243
Validation loss: 3.3714989802522517

Epoch: 5| Step: 6
Training loss: 2.558658791217674
Validation loss: 3.3711474453611556

Epoch: 5| Step: 7
Training loss: 3.844233908857303
Validation loss: 3.3740717691182804

Epoch: 5| Step: 8
Training loss: 3.3733420361593813
Validation loss: 3.368730737531128

Epoch: 5| Step: 9
Training loss: 3.664259264772712
Validation loss: 3.366650917977271

Epoch: 5| Step: 10
Training loss: 3.65203810448212
Validation loss: 3.365326524296462

Epoch: 32| Step: 0
Training loss: 3.9632041810864913
Validation loss: 3.361266549678838

Epoch: 5| Step: 1
Training loss: 3.438888685452057
Validation loss: 3.3597333956812503

Epoch: 5| Step: 2
Training loss: 3.922964970471429
Validation loss: 3.358773425517613

Epoch: 5| Step: 3
Training loss: 3.1846626967874587
Validation loss: 3.358351060478585

Epoch: 5| Step: 4
Training loss: 3.159522295950899
Validation loss: 3.358399124516856

Epoch: 5| Step: 5
Training loss: 3.3537434060127533
Validation loss: 3.3560791789769304

Epoch: 5| Step: 6
Training loss: 3.5584590815198474
Validation loss: 3.352795802206476

Epoch: 5| Step: 7
Training loss: 4.50476965854123
Validation loss: 3.35211011793464

Epoch: 5| Step: 8
Training loss: 3.521432648763891
Validation loss: 3.351464414271599

Epoch: 5| Step: 9
Training loss: 3.235945315791352
Validation loss: 3.3537688317777152

Epoch: 5| Step: 10
Training loss: 3.384805493084231
Validation loss: 3.353671406068041

Epoch: 33| Step: 0
Training loss: 3.1425424672172944
Validation loss: 3.3532681161881412

Epoch: 5| Step: 1
Training loss: 3.754512106822712
Validation loss: 3.3465805593201408

Epoch: 5| Step: 2
Training loss: 4.238554408680134
Validation loss: 3.3431497379502755

Epoch: 5| Step: 3
Training loss: 4.016661513920139
Validation loss: 3.346541171975279

Epoch: 5| Step: 4
Training loss: 3.6576304641786592
Validation loss: 3.3493634589082864

Epoch: 5| Step: 5
Training loss: 2.8886339083247017
Validation loss: 3.346122481951312

Epoch: 5| Step: 6
Training loss: 3.3374333121391464
Validation loss: 3.343448542907176

Epoch: 5| Step: 7
Training loss: 3.0560415247547588
Validation loss: 3.3438871967152486

Epoch: 5| Step: 8
Training loss: 4.16631114714553
Validation loss: 3.3430745689765415

Epoch: 5| Step: 9
Training loss: 3.650715347632362
Validation loss: 3.3378506128372187

Epoch: 5| Step: 10
Training loss: 3.1066000359338437
Validation loss: 3.3377368548147635

Epoch: 34| Step: 0
Training loss: 3.829018500238788
Validation loss: 3.334414351946588

Epoch: 5| Step: 1
Training loss: 3.850631756162854
Validation loss: 3.332798526273998

Epoch: 5| Step: 2
Training loss: 3.869049425508965
Validation loss: 3.329112961053937

Epoch: 5| Step: 3
Training loss: 3.9323920163451205
Validation loss: 3.331379616811155

Epoch: 5| Step: 4
Training loss: 3.7899793007318108
Validation loss: 3.3312603031528507

Epoch: 5| Step: 5
Training loss: 3.5616767333594583
Validation loss: 3.3278978951907834

Epoch: 5| Step: 6
Training loss: 2.742739977704163
Validation loss: 3.326692355920256

Epoch: 5| Step: 7
Training loss: 3.3826448958461546
Validation loss: 3.3262655858577546

Epoch: 5| Step: 8
Training loss: 3.6411272611141206
Validation loss: 3.324198431877856

Epoch: 5| Step: 9
Training loss: 3.174009309732188
Validation loss: 3.324107681327047

Epoch: 5| Step: 10
Training loss: 3.226626933565175
Validation loss: 3.3226712913206775

Epoch: 35| Step: 0
Training loss: 3.975244569752063
Validation loss: 3.3215762670821016

Epoch: 5| Step: 1
Training loss: 3.278820337202071
Validation loss: 3.3211704608337764

Epoch: 5| Step: 2
Training loss: 3.6714351309420317
Validation loss: 3.3187628120681953

Epoch: 5| Step: 3
Training loss: 3.8906210780602724
Validation loss: 3.3182800349537986

Epoch: 5| Step: 4
Training loss: 3.5889794572150344
Validation loss: 3.316442641926246

Epoch: 5| Step: 5
Training loss: 3.274031919711765
Validation loss: 3.3172484200317016

Epoch: 5| Step: 6
Training loss: 3.4284060784613257
Validation loss: 3.3166937181747818

Epoch: 5| Step: 7
Training loss: 3.7775423141725057
Validation loss: 3.315899425525672

Epoch: 5| Step: 8
Training loss: 3.2292885706051746
Validation loss: 3.3127640703863253

Epoch: 5| Step: 9
Training loss: 3.7597739955263965
Validation loss: 3.3133629371216187

Epoch: 5| Step: 10
Training loss: 3.0905748507883115
Validation loss: 3.3131067483019945

Epoch: 36| Step: 0
Training loss: 3.3509179409160303
Validation loss: 3.31292692448901

Epoch: 5| Step: 1
Training loss: 3.580923526922079
Validation loss: 3.312240050183487

Epoch: 5| Step: 2
Training loss: 3.219782839495282
Validation loss: 3.309291306342101

Epoch: 5| Step: 3
Training loss: 3.057067412297295
Validation loss: 3.3055302638585187

Epoch: 5| Step: 4
Training loss: 4.368033393732214
Validation loss: 3.3066181396540135

Epoch: 5| Step: 5
Training loss: 3.5048508407482273
Validation loss: 3.308092624194527

Epoch: 5| Step: 6
Training loss: 3.538288764499224
Validation loss: 3.3078024074102417

Epoch: 5| Step: 7
Training loss: 2.9708670044890626
Validation loss: 3.3026973841418883

Epoch: 5| Step: 8
Training loss: 3.6929378178162335
Validation loss: 3.3041903314949628

Epoch: 5| Step: 9
Training loss: 4.004605026675881
Validation loss: 3.30296111746204

Epoch: 5| Step: 10
Training loss: 3.5401076232584976
Validation loss: 3.3025216100003623

Epoch: 37| Step: 0
Training loss: 2.942848044710738
Validation loss: 3.3012256532611612

Epoch: 5| Step: 1
Training loss: 3.8661752936677853
Validation loss: 3.2996037701822876

Epoch: 5| Step: 2
Training loss: 3.689466437037591
Validation loss: 3.3001436741385755

Epoch: 5| Step: 3
Training loss: 2.785854514229105
Validation loss: 3.2975602539329802

Epoch: 5| Step: 4
Training loss: 3.482269745914723
Validation loss: 3.2948218245467293

Epoch: 5| Step: 5
Training loss: 4.228971404781079
Validation loss: 3.2961262327629477

Epoch: 5| Step: 6
Training loss: 4.091317655410137
Validation loss: 3.295547039834882

Epoch: 5| Step: 7
Training loss: 3.4030674056406793
Validation loss: 3.2957313745741903

Epoch: 5| Step: 8
Training loss: 3.569284637541745
Validation loss: 3.294596433017676

Epoch: 5| Step: 9
Training loss: 3.7847664615639234
Validation loss: 3.292335880446794

Epoch: 5| Step: 10
Training loss: 2.5738337088446315
Validation loss: 3.290505488053253

Epoch: 38| Step: 0
Training loss: 3.827314143038106
Validation loss: 3.2965086847313905

Epoch: 5| Step: 1
Training loss: 3.1504053067020727
Validation loss: 3.2904212208197396

Epoch: 5| Step: 2
Training loss: 4.354277005539128
Validation loss: 3.2897957692343165

Epoch: 5| Step: 3
Training loss: 3.7738633320315853
Validation loss: 3.2872039514392872

Epoch: 5| Step: 4
Training loss: 3.5439613238908767
Validation loss: 3.2872152909457792

Epoch: 5| Step: 5
Training loss: 2.9528831100297595
Validation loss: 3.287545504551992

Epoch: 5| Step: 6
Training loss: 3.2711787112335573
Validation loss: 3.2886161381478685

Epoch: 5| Step: 7
Training loss: 3.749025726913862
Validation loss: 3.2876506843721103

Epoch: 5| Step: 8
Training loss: 3.8264728328468682
Validation loss: 3.285598294182634

Epoch: 5| Step: 9
Training loss: 3.0459371052471016
Validation loss: 3.2843608542229865

Epoch: 5| Step: 10
Training loss: 3.0271337817810915
Validation loss: 3.2865360455522996

Epoch: 39| Step: 0
Training loss: 3.4801908953695184
Validation loss: 3.295914012682235

Epoch: 5| Step: 1
Training loss: 2.69124918397713
Validation loss: 3.2888517970170374

Epoch: 5| Step: 2
Training loss: 2.9713699826291293
Validation loss: 3.2856745065604507

Epoch: 5| Step: 3
Training loss: 4.389707421913219
Validation loss: 3.2819996764069335

Epoch: 5| Step: 4
Training loss: 4.237143874606021
Validation loss: 3.2801397583137137

Epoch: 5| Step: 5
Training loss: 4.1923792865915175
Validation loss: 3.280660837528666

Epoch: 5| Step: 6
Training loss: 3.222854663636318
Validation loss: 3.2805463982873095

Epoch: 5| Step: 7
Training loss: 2.792189952334804
Validation loss: 3.2799570500292763

Epoch: 5| Step: 8
Training loss: 3.9616597436938834
Validation loss: 3.2793428854762916

Epoch: 5| Step: 9
Training loss: 2.777798171498352
Validation loss: 3.277887008369038

Epoch: 5| Step: 10
Training loss: 3.509643756361865
Validation loss: 3.276080143515726

Epoch: 40| Step: 0
Training loss: 3.8039467343071838
Validation loss: 3.273935609660687

Epoch: 5| Step: 1
Training loss: 3.655451760820213
Validation loss: 3.273322648451023

Epoch: 5| Step: 2
Training loss: 3.9581690034719825
Validation loss: 3.2776656864824

Epoch: 5| Step: 3
Training loss: 3.2483055392531615
Validation loss: 3.2776682973127444

Epoch: 5| Step: 4
Training loss: 3.2962666171670936
Validation loss: 3.2736432543902185

Epoch: 5| Step: 5
Training loss: 3.032126545753876
Validation loss: 3.2691626550069843

Epoch: 5| Step: 6
Training loss: 3.218008011413806
Validation loss: 3.2691133620977695

Epoch: 5| Step: 7
Training loss: 3.5011206603887666
Validation loss: 3.2678579264305068

Epoch: 5| Step: 8
Training loss: 3.803643618025908
Validation loss: 3.2661344658044174

Epoch: 5| Step: 9
Training loss: 3.686828940156048
Validation loss: 3.2659297863098407

Epoch: 5| Step: 10
Training loss: 3.3376290457133715
Validation loss: 3.26255292486886

Epoch: 41| Step: 0
Training loss: 3.7835043500207552
Validation loss: 3.2623662439421737

Epoch: 5| Step: 1
Training loss: 3.2767876208913447
Validation loss: 3.2589147865060535

Epoch: 5| Step: 2
Training loss: 3.572765083915906
Validation loss: 3.262074873112369

Epoch: 5| Step: 3
Training loss: 3.609900630312416
Validation loss: 3.261233711001857

Epoch: 5| Step: 4
Training loss: 3.506424865170079
Validation loss: 3.261119925646307

Epoch: 5| Step: 5
Training loss: 3.7793714412459862
Validation loss: 3.2585598663378614

Epoch: 5| Step: 6
Training loss: 4.311182235401991
Validation loss: 3.254294334154003

Epoch: 5| Step: 7
Training loss: 2.8817275572109966
Validation loss: 3.2560823192483688

Epoch: 5| Step: 8
Training loss: 3.4471889930398874
Validation loss: 3.2575353063490313

Epoch: 5| Step: 9
Training loss: 3.1046539197314265
Validation loss: 3.253902373699188

Epoch: 5| Step: 10
Training loss: 3.0242880874131264
Validation loss: 3.2536775955050317

Epoch: 42| Step: 0
Training loss: 3.909795510098467
Validation loss: 3.2499151597414753

Epoch: 5| Step: 1
Training loss: 3.1205336124203367
Validation loss: 3.249516890583268

Epoch: 5| Step: 2
Training loss: 2.796602715392678
Validation loss: 3.252311436751743

Epoch: 5| Step: 3
Training loss: 3.7262939100420023
Validation loss: 3.2524946229084115

Epoch: 5| Step: 4
Training loss: 4.145327794420287
Validation loss: 3.258416508072335

Epoch: 5| Step: 5
Training loss: 3.8760583724280684
Validation loss: 3.2431594888074917

Epoch: 5| Step: 6
Training loss: 3.59834261465591
Validation loss: 3.2445663010185513

Epoch: 5| Step: 7
Training loss: 3.653169426431702
Validation loss: 3.242834770192423

Epoch: 5| Step: 8
Training loss: 3.0597581072174016
Validation loss: 3.2467852501649634

Epoch: 5| Step: 9
Training loss: 3.225105307582237
Validation loss: 3.244314918197931

Epoch: 5| Step: 10
Training loss: 3.06370629667366
Validation loss: 3.245682139574774

Epoch: 43| Step: 0
Training loss: 4.177670913934787
Validation loss: 3.2439872884894685

Epoch: 5| Step: 1
Training loss: 3.7312877455037015
Validation loss: 3.2436608491567465

Epoch: 5| Step: 2
Training loss: 3.4374707307436436
Validation loss: 3.2387740759180415

Epoch: 5| Step: 3
Training loss: 3.4164261306822796
Validation loss: 3.2391368008369064

Epoch: 5| Step: 4
Training loss: 2.0815045404432793
Validation loss: 3.238270380392859

Epoch: 5| Step: 5
Training loss: 3.6170204733727127
Validation loss: 3.2430850598691854

Epoch: 5| Step: 6
Training loss: 2.459273874998174
Validation loss: 3.245929251098491

Epoch: 5| Step: 7
Training loss: 3.2854963165155735
Validation loss: 3.259090418168415

Epoch: 5| Step: 8
Training loss: 3.926618040870744
Validation loss: 3.243496599932976

Epoch: 5| Step: 9
Training loss: 4.013027909866949
Validation loss: 3.2373718166659224

Epoch: 5| Step: 10
Training loss: 3.7279370090254633
Validation loss: 3.234281122724663

Epoch: 44| Step: 0
Training loss: 3.2794691793718243
Validation loss: 3.235721961774626

Epoch: 5| Step: 1
Training loss: 3.395869826294322
Validation loss: 3.2425270437489684

Epoch: 5| Step: 2
Training loss: 3.167436171613426
Validation loss: 3.2411855241288476

Epoch: 5| Step: 3
Training loss: 3.6221962971399893
Validation loss: 3.239459195485621

Epoch: 5| Step: 4
Training loss: 3.6831811732512802
Validation loss: 3.2354068862740486

Epoch: 5| Step: 5
Training loss: 3.6923121718232785
Validation loss: 3.231740574481349

Epoch: 5| Step: 6
Training loss: 3.554256874242573
Validation loss: 3.234039918626218

Epoch: 5| Step: 7
Training loss: 2.3520520483278453
Validation loss: 3.2364580721683947

Epoch: 5| Step: 8
Training loss: 3.1885263623120914
Validation loss: 3.239972140327752

Epoch: 5| Step: 9
Training loss: 4.317073000681468
Validation loss: 3.233763116279842

Epoch: 5| Step: 10
Training loss: 3.848412887612248
Validation loss: 3.2345285021057077

Epoch: 45| Step: 0
Training loss: 3.812001305154615
Validation loss: 3.2308715723118313

Epoch: 5| Step: 1
Training loss: 3.9600732827389806
Validation loss: 3.22835671822444

Epoch: 5| Step: 2
Training loss: 4.006596847492875
Validation loss: 3.2283043230288273

Epoch: 5| Step: 3
Training loss: 3.1036383842835087
Validation loss: 3.227819966287898

Epoch: 5| Step: 4
Training loss: 2.4371541095730063
Validation loss: 3.2280685706563577

Epoch: 5| Step: 5
Training loss: 3.5081130410905836
Validation loss: 3.2268938119281123

Epoch: 5| Step: 6
Training loss: 3.417015492070072
Validation loss: 3.225632311955694

Epoch: 5| Step: 7
Training loss: 3.172607788226821
Validation loss: 3.2247773169824527

Epoch: 5| Step: 8
Training loss: 3.4947328444115144
Validation loss: 3.2251265472769712

Epoch: 5| Step: 9
Training loss: 4.004129662212081
Validation loss: 3.222815926263712

Epoch: 5| Step: 10
Training loss: 2.9553156402400176
Validation loss: 3.223160462373383

Epoch: 46| Step: 0
Training loss: 2.67760571282686
Validation loss: 3.2228836149404314

Epoch: 5| Step: 1
Training loss: 3.8248826601068986
Validation loss: 3.2227240876049272

Epoch: 5| Step: 2
Training loss: 2.685765793633986
Validation loss: 3.2234277040873343

Epoch: 5| Step: 3
Training loss: 2.4753691388365975
Validation loss: 3.2225003239760612

Epoch: 5| Step: 4
Training loss: 2.8377195701846207
Validation loss: 3.2270142769483052

Epoch: 5| Step: 5
Training loss: 4.085356749478289
Validation loss: 3.22738433035583

Epoch: 5| Step: 6
Training loss: 3.625846763895163
Validation loss: 3.2246807498411125

Epoch: 5| Step: 7
Training loss: 3.544511721924868
Validation loss: 3.2191688877513744

Epoch: 5| Step: 8
Training loss: 3.494976935140008
Validation loss: 3.2185084961912005

Epoch: 5| Step: 9
Training loss: 3.9370523834115496
Validation loss: 3.2175556264315404

Epoch: 5| Step: 10
Training loss: 4.569417230021951
Validation loss: 3.217533809296415

Epoch: 47| Step: 0
Training loss: 3.5369811685161667
Validation loss: 3.217269486879213

Epoch: 5| Step: 1
Training loss: 3.220248419851966
Validation loss: 3.2154420986542536

Epoch: 5| Step: 2
Training loss: 3.591740319956466
Validation loss: 3.215591065697632

Epoch: 5| Step: 3
Training loss: 3.3642824745104773
Validation loss: 3.217285061028394

Epoch: 5| Step: 4
Training loss: 3.1911272839845064
Validation loss: 3.219762749325992

Epoch: 5| Step: 5
Training loss: 3.1362158347222997
Validation loss: 3.2178538566647275

Epoch: 5| Step: 6
Training loss: 3.9739166030925914
Validation loss: 3.2167922654120664

Epoch: 5| Step: 7
Training loss: 3.15294360725068
Validation loss: 3.2179932828312894

Epoch: 5| Step: 8
Training loss: 3.020944124141339
Validation loss: 3.2139586243667257

Epoch: 5| Step: 9
Training loss: 3.680909166603496
Validation loss: 3.2144279864536145

Epoch: 5| Step: 10
Training loss: 4.231289010030084
Validation loss: 3.2123949454681737

Epoch: 48| Step: 0
Training loss: 4.134432094926532
Validation loss: 3.213698070700373

Epoch: 5| Step: 1
Training loss: 3.9776757261539157
Validation loss: 3.2147417192963674

Epoch: 5| Step: 2
Training loss: 3.2051679841531904
Validation loss: 3.2108769465116684

Epoch: 5| Step: 3
Training loss: 3.4524947061574074
Validation loss: 3.2117332520569106

Epoch: 5| Step: 4
Training loss: 3.270049825399562
Validation loss: 3.2120848622924214

Epoch: 5| Step: 5
Training loss: 3.6850287998683777
Validation loss: 3.214975992909664

Epoch: 5| Step: 6
Training loss: 3.6992098557426734
Validation loss: 3.21586665638627

Epoch: 5| Step: 7
Training loss: 3.6027980844720657
Validation loss: 3.2152915938405444

Epoch: 5| Step: 8
Training loss: 3.2847390652727215
Validation loss: 3.2155141537505663

Epoch: 5| Step: 9
Training loss: 2.668625847030263
Validation loss: 3.214647797404896

Epoch: 5| Step: 10
Training loss: 2.8529198329397816
Validation loss: 3.2123489106223553

Epoch: 49| Step: 0
Training loss: 2.8036100820526917
Validation loss: 3.211208567494878

Epoch: 5| Step: 1
Training loss: 3.634928425500054
Validation loss: 3.2114744808007973

Epoch: 5| Step: 2
Training loss: 3.8026766936752714
Validation loss: 3.2083801651791335

Epoch: 5| Step: 3
Training loss: 3.5456220791766184
Validation loss: 3.2099980538227224

Epoch: 5| Step: 4
Training loss: 2.8207160470790944
Validation loss: 3.210716608625903

Epoch: 5| Step: 5
Training loss: 3.697795138802284
Validation loss: 3.2102190800885837

Epoch: 5| Step: 6
Training loss: 3.7085243490221336
Validation loss: 3.2096959371347444

Epoch: 5| Step: 7
Training loss: 4.201615867403492
Validation loss: 3.2075307780111206

Epoch: 5| Step: 8
Training loss: 2.9397324540245355
Validation loss: 3.2070613401676877

Epoch: 5| Step: 9
Training loss: 3.5317782116698355
Validation loss: 3.206766071487359

Epoch: 5| Step: 10
Training loss: 3.1131553480855203
Validation loss: 3.2085453251603226

Epoch: 50| Step: 0
Training loss: 3.250771357625089
Validation loss: 3.2072068996259797

Epoch: 5| Step: 1
Training loss: 3.8250064525674485
Validation loss: 3.2080925439728514

Epoch: 5| Step: 2
Training loss: 3.3983662214148604
Validation loss: 3.204305256581171

Epoch: 5| Step: 3
Training loss: 3.682175105227099
Validation loss: 3.211039166165486

Epoch: 5| Step: 4
Training loss: 3.414529240389029
Validation loss: 3.223908285113369

Epoch: 5| Step: 5
Training loss: 3.4861246001517507
Validation loss: 3.2155522870625837

Epoch: 5| Step: 6
Training loss: 3.6475785937349103
Validation loss: 3.2062481620620353

Epoch: 5| Step: 7
Training loss: 3.807359199951275
Validation loss: 3.203645446898848

Epoch: 5| Step: 8
Training loss: 3.4296861096772524
Validation loss: 3.203672035100227

Epoch: 5| Step: 9
Training loss: 2.8930479050700617
Validation loss: 3.2035404843259108

Epoch: 5| Step: 10
Training loss: 3.13904771056045
Validation loss: 3.2032960571426448

Epoch: 51| Step: 0
Training loss: 3.244238220988324
Validation loss: 3.204493628678033

Epoch: 5| Step: 1
Training loss: 4.041848142554431
Validation loss: 3.2030730612700986

Epoch: 5| Step: 2
Training loss: 3.106999702475699
Validation loss: 3.2041159532850685

Epoch: 5| Step: 3
Training loss: 3.6931385960750696
Validation loss: 3.2066481060645318

Epoch: 5| Step: 4
Training loss: 3.2869924523360057
Validation loss: 3.20509766732459

Epoch: 5| Step: 5
Training loss: 3.726956328688619
Validation loss: 3.202784417566641

Epoch: 5| Step: 6
Training loss: 3.9904927278850804
Validation loss: 3.2024016108957034

Epoch: 5| Step: 7
Training loss: 3.2828282511577
Validation loss: 3.20183939411742

Epoch: 5| Step: 8
Training loss: 3.110754732504371
Validation loss: 3.203430263680737

Epoch: 5| Step: 9
Training loss: 2.8316427872047374
Validation loss: 3.202258815946501

Epoch: 5| Step: 10
Training loss: 3.5885338121096613
Validation loss: 3.2025898115890845

Epoch: 52| Step: 0
Training loss: 4.000051021250532
Validation loss: 3.19975008924402

Epoch: 5| Step: 1
Training loss: 3.513897823344161
Validation loss: 3.1979391125226018

Epoch: 5| Step: 2
Training loss: 3.3830432416704648
Validation loss: 3.197490754497419

Epoch: 5| Step: 3
Training loss: 3.1953739822553806
Validation loss: 3.1987424436773124

Epoch: 5| Step: 4
Training loss: 3.6684286623441387
Validation loss: 3.2007724753783133

Epoch: 5| Step: 5
Training loss: 3.022169532347743
Validation loss: 3.199601717935654

Epoch: 5| Step: 6
Training loss: 3.5690579203028583
Validation loss: 3.1992037770515673

Epoch: 5| Step: 7
Training loss: 3.354075949885467
Validation loss: 3.1985559257796137

Epoch: 5| Step: 8
Training loss: 3.2544063627996667
Validation loss: 3.199315817239843

Epoch: 5| Step: 9
Training loss: 3.4258376218013757
Validation loss: 3.1990609796024407

Epoch: 5| Step: 10
Training loss: 3.586999274741643
Validation loss: 3.1976512657044847

Epoch: 53| Step: 0
Training loss: 4.051912567279908
Validation loss: 3.196930710109023

Epoch: 5| Step: 1
Training loss: 2.6060150809038296
Validation loss: 3.196169913102919

Epoch: 5| Step: 2
Training loss: 3.9347802108786665
Validation loss: 3.1963259654278704

Epoch: 5| Step: 3
Training loss: 3.8129544847094388
Validation loss: 3.197133576482592

Epoch: 5| Step: 4
Training loss: 3.0978103349228445
Validation loss: 3.1959199648640437

Epoch: 5| Step: 5
Training loss: 3.247825775603851
Validation loss: 3.1966038506019454

Epoch: 5| Step: 6
Training loss: 2.451279741930623
Validation loss: 3.1969582891704507

Epoch: 5| Step: 7
Training loss: 3.502636053041817
Validation loss: 3.194586210298926

Epoch: 5| Step: 8
Training loss: 3.619878241878164
Validation loss: 3.194740032117669

Epoch: 5| Step: 9
Training loss: 3.3126476902696176
Validation loss: 3.1962385607021235

Epoch: 5| Step: 10
Training loss: 4.019737186476231
Validation loss: 3.1938148324510367

Epoch: 54| Step: 0
Training loss: 3.6592831542284103
Validation loss: 3.193508874417349

Epoch: 5| Step: 1
Training loss: 2.4009740879260515
Validation loss: 3.193233622962257

Epoch: 5| Step: 2
Training loss: 3.481854677676821
Validation loss: 3.19134677187848

Epoch: 5| Step: 3
Training loss: 3.6298353896636537
Validation loss: 3.1937554056067956

Epoch: 5| Step: 4
Training loss: 3.819176752747323
Validation loss: 3.1919350409857596

Epoch: 5| Step: 5
Training loss: 3.7916459862001846
Validation loss: 3.1898789187634073

Epoch: 5| Step: 6
Training loss: 2.703767468611624
Validation loss: 3.189212756331047

Epoch: 5| Step: 7
Training loss: 3.1610605575133484
Validation loss: 3.1885205508464507

Epoch: 5| Step: 8
Training loss: 3.7891563797165047
Validation loss: 3.1915314940833204

Epoch: 5| Step: 9
Training loss: 3.53961514164353
Validation loss: 3.188550304345357

Epoch: 5| Step: 10
Training loss: 3.689298546755175
Validation loss: 3.188644123415528

Epoch: 55| Step: 0
Training loss: 3.5692067510393732
Validation loss: 3.1839652773688067

Epoch: 5| Step: 1
Training loss: 3.311042464979122
Validation loss: 3.1871243568587917

Epoch: 5| Step: 2
Training loss: 3.0294512888292426
Validation loss: 3.187409999862863

Epoch: 5| Step: 3
Training loss: 3.205728951812332
Validation loss: 3.1877214007824666

Epoch: 5| Step: 4
Training loss: 3.3378377679218953
Validation loss: 3.1857865843809656

Epoch: 5| Step: 5
Training loss: 3.722525851516677
Validation loss: 3.1843555019493044

Epoch: 5| Step: 6
Training loss: 3.5857321819625234
Validation loss: 3.1839843502330485

Epoch: 5| Step: 7
Training loss: 2.833509009655747
Validation loss: 3.184036942532908

Epoch: 5| Step: 8
Training loss: 3.4302547046636622
Validation loss: 3.184954275519478

Epoch: 5| Step: 9
Training loss: 4.022005348494135
Validation loss: 3.1810831429238533

Epoch: 5| Step: 10
Training loss: 3.7391163880688967
Validation loss: 3.182341876099691

Epoch: 56| Step: 0
Training loss: 3.979968697506286
Validation loss: 3.1827619776478286

Epoch: 5| Step: 1
Training loss: 2.781610872666419
Validation loss: 3.181129375562436

Epoch: 5| Step: 2
Training loss: 3.327201894336848
Validation loss: 3.1809983883259285

Epoch: 5| Step: 3
Training loss: 3.500354340191429
Validation loss: 3.1795166869525726

Epoch: 5| Step: 4
Training loss: 3.4579869905031826
Validation loss: 3.1807786675168406

Epoch: 5| Step: 5
Training loss: 3.8045924995358456
Validation loss: 3.1807855610472893

Epoch: 5| Step: 6
Training loss: 2.4917805019474035
Validation loss: 3.181584962571358

Epoch: 5| Step: 7
Training loss: 3.5379477928540632
Validation loss: 3.1775803286016537

Epoch: 5| Step: 8
Training loss: 3.5319056619593434
Validation loss: 3.179457989467371

Epoch: 5| Step: 9
Training loss: 3.4366950739942306
Validation loss: 3.178718726698643

Epoch: 5| Step: 10
Training loss: 3.7914975865711176
Validation loss: 3.178258673157438

Epoch: 57| Step: 0
Training loss: 3.292284476975151
Validation loss: 3.176460304813753

Epoch: 5| Step: 1
Training loss: 3.655788164232934
Validation loss: 3.178806202653396

Epoch: 5| Step: 2
Training loss: 3.8409221140049237
Validation loss: 3.1766663394511987

Epoch: 5| Step: 3
Training loss: 3.2683908531448465
Validation loss: 3.17776287254733

Epoch: 5| Step: 4
Training loss: 3.265728524497303
Validation loss: 3.1748219904673474

Epoch: 5| Step: 5
Training loss: 3.267354260954442
Validation loss: 3.1769288707177448

Epoch: 5| Step: 6
Training loss: 3.3113300488632786
Validation loss: 3.1749162152104993

Epoch: 5| Step: 7
Training loss: 3.602489161901961
Validation loss: 3.1772530486019757

Epoch: 5| Step: 8
Training loss: 3.549322955621021
Validation loss: 3.1732494642175997

Epoch: 5| Step: 9
Training loss: 3.657189142623985
Validation loss: 3.178177815127925

Epoch: 5| Step: 10
Training loss: 2.958518617943738
Validation loss: 3.176622598540373

Epoch: 58| Step: 0
Training loss: 3.5351851151273217
Validation loss: 3.1769876423665004

Epoch: 5| Step: 1
Training loss: 4.00252786868494
Validation loss: 3.175940201075366

Epoch: 5| Step: 2
Training loss: 3.0909971069105193
Validation loss: 3.176336377695675

Epoch: 5| Step: 3
Training loss: 3.8848704481678475
Validation loss: 3.173479013380544

Epoch: 5| Step: 4
Training loss: 2.9450311096309894
Validation loss: 3.17339336093758

Epoch: 5| Step: 5
Training loss: 3.289791216733187
Validation loss: 3.1744348265370963

Epoch: 5| Step: 6
Training loss: 3.383791176270985
Validation loss: 3.172233919690894

Epoch: 5| Step: 7
Training loss: 3.274952103359204
Validation loss: 3.1709536067812962

Epoch: 5| Step: 8
Training loss: 3.7992678037250003
Validation loss: 3.1733344370868584

Epoch: 5| Step: 9
Training loss: 2.8696348467082675
Validation loss: 3.171831171999985

Epoch: 5| Step: 10
Training loss: 3.515485294533189
Validation loss: 3.1716570906380057

Epoch: 59| Step: 0
Training loss: 3.279375830785269
Validation loss: 3.1694587197963

Epoch: 5| Step: 1
Training loss: 3.854184880943905
Validation loss: 3.169987655560749

Epoch: 5| Step: 2
Training loss: 3.3801618591468015
Validation loss: 3.1702662393567675

Epoch: 5| Step: 3
Training loss: 3.13460879304921
Validation loss: 3.170324458497535

Epoch: 5| Step: 4
Training loss: 3.520486953821702
Validation loss: 3.1668656604549574

Epoch: 5| Step: 5
Training loss: 3.1435560526849318
Validation loss: 3.1708968544755933

Epoch: 5| Step: 6
Training loss: 3.1723845875866967
Validation loss: 3.170448770202623

Epoch: 5| Step: 7
Training loss: 3.300096718497873
Validation loss: 3.173670591623904

Epoch: 5| Step: 8
Training loss: 4.026994455103044
Validation loss: 3.171582995619391

Epoch: 5| Step: 9
Training loss: 3.7081150605045843
Validation loss: 3.1725564585609165

Epoch: 5| Step: 10
Training loss: 3.0105815873075836
Validation loss: 3.1787034515282127

Epoch: 60| Step: 0
Training loss: 3.679832245071462
Validation loss: 3.1834755250545124

Epoch: 5| Step: 1
Training loss: 4.0224091335960726
Validation loss: 3.168539003477996

Epoch: 5| Step: 2
Training loss: 2.8275731006620153
Validation loss: 3.165481773696183

Epoch: 5| Step: 3
Training loss: 2.7138903803210117
Validation loss: 3.1659486088203628

Epoch: 5| Step: 4
Training loss: 3.695759719981389
Validation loss: 3.1683565155366384

Epoch: 5| Step: 5
Training loss: 3.58437724026092
Validation loss: 3.1761307833483445

Epoch: 5| Step: 6
Training loss: 3.1847514849952105
Validation loss: 3.1722175723918906

Epoch: 5| Step: 7
Training loss: 3.7638298599350337
Validation loss: 3.1739698897916737

Epoch: 5| Step: 8
Training loss: 2.5465074519706192
Validation loss: 3.1701247569545226

Epoch: 5| Step: 9
Training loss: 3.40034042224931
Validation loss: 3.170183706498963

Epoch: 5| Step: 10
Training loss: 4.064306239086583
Validation loss: 3.169443848106376

Epoch: 61| Step: 0
Training loss: 3.5298052507663087
Validation loss: 3.1721794418360028

Epoch: 5| Step: 1
Training loss: 3.492095058506289
Validation loss: 3.17466557073484

Epoch: 5| Step: 2
Training loss: 2.75417860050665
Validation loss: 3.176245980520169

Epoch: 5| Step: 3
Training loss: 3.7227763970151164
Validation loss: 3.172218679562814

Epoch: 5| Step: 4
Training loss: 2.9327469376891186
Validation loss: 3.1679770835217687

Epoch: 5| Step: 5
Training loss: 3.7248284165976373
Validation loss: 3.1675673862349534

Epoch: 5| Step: 6
Training loss: 2.9480096018310036
Validation loss: 3.16608440009204

Epoch: 5| Step: 7
Training loss: 4.250745147007707
Validation loss: 3.166752487556792

Epoch: 5| Step: 8
Training loss: 3.5727020881359937
Validation loss: 3.1651433352744993

Epoch: 5| Step: 9
Training loss: 3.2861393422576284
Validation loss: 3.1641655945019274

Epoch: 5| Step: 10
Training loss: 3.2179171771764854
Validation loss: 3.161608747124899

Epoch: 62| Step: 0
Training loss: 3.8164035012304582
Validation loss: 3.163410224358255

Epoch: 5| Step: 1
Training loss: 3.024213981969569
Validation loss: 3.163898842469615

Epoch: 5| Step: 2
Training loss: 3.7854454788234015
Validation loss: 3.1622188534747506

Epoch: 5| Step: 3
Training loss: 3.864952350831034
Validation loss: 3.161443420224695

Epoch: 5| Step: 4
Training loss: 2.4692687443277346
Validation loss: 3.1606843676092105

Epoch: 5| Step: 5
Training loss: 3.8109295221286676
Validation loss: 3.1642389250071323

Epoch: 5| Step: 6
Training loss: 3.0106482675202457
Validation loss: 3.162340963413864

Epoch: 5| Step: 7
Training loss: 3.40808392073056
Validation loss: 3.165393275933291

Epoch: 5| Step: 8
Training loss: 3.3418672198634334
Validation loss: 3.164505187411835

Epoch: 5| Step: 9
Training loss: 4.052395505411014
Validation loss: 3.1632050055531242

Epoch: 5| Step: 10
Training loss: 2.5409256422924744
Validation loss: 3.159655789748186

Epoch: 63| Step: 0
Training loss: 3.524044415968013
Validation loss: 3.1619449077574675

Epoch: 5| Step: 1
Training loss: 2.734681379319888
Validation loss: 3.159635217469353

Epoch: 5| Step: 2
Training loss: 3.0604968623765485
Validation loss: 3.16102985914653

Epoch: 5| Step: 3
Training loss: 3.608155940557702
Validation loss: 3.158859915303257

Epoch: 5| Step: 4
Training loss: 3.1389090181978716
Validation loss: 3.1612888808463744

Epoch: 5| Step: 5
Training loss: 3.1957403143749628
Validation loss: 3.161471047748962

Epoch: 5| Step: 6
Training loss: 3.478419941395272
Validation loss: 3.16150645798383

Epoch: 5| Step: 7
Training loss: 3.4612327432529453
Validation loss: 3.158877893183656

Epoch: 5| Step: 8
Training loss: 4.103645536898244
Validation loss: 3.1577704751449653

Epoch: 5| Step: 9
Training loss: 3.7595071441180696
Validation loss: 3.156444097265132

Epoch: 5| Step: 10
Training loss: 3.358640084720148
Validation loss: 3.1573332888381973

Epoch: 64| Step: 0
Training loss: 2.8329770107231957
Validation loss: 3.1580384315942673

Epoch: 5| Step: 1
Training loss: 2.80987315953923
Validation loss: 3.1554093225651534

Epoch: 5| Step: 2
Training loss: 4.072093727636946
Validation loss: 3.156936262248762

Epoch: 5| Step: 3
Training loss: 3.863129183685649
Validation loss: 3.156320817011391

Epoch: 5| Step: 4
Training loss: 2.483979103645482
Validation loss: 3.1566839123950303

Epoch: 5| Step: 5
Training loss: 3.020733553236034
Validation loss: 3.156618946125047

Epoch: 5| Step: 6
Training loss: 3.3988373619824777
Validation loss: 3.1573457784421297

Epoch: 5| Step: 7
Training loss: 3.5864281412198666
Validation loss: 3.1551865465736544

Epoch: 5| Step: 8
Training loss: 3.7967256744282687
Validation loss: 3.1546011116111914

Epoch: 5| Step: 9
Training loss: 3.262347461159897
Validation loss: 3.1584461165938054

Epoch: 5| Step: 10
Training loss: 4.147163497214914
Validation loss: 3.157108037146902

Epoch: 65| Step: 0
Training loss: 2.9162461840575586
Validation loss: 3.1560603194136823

Epoch: 5| Step: 1
Training loss: 3.5646602037451007
Validation loss: 3.1571836850059976

Epoch: 5| Step: 2
Training loss: 3.3912327656798356
Validation loss: 3.154118038283853

Epoch: 5| Step: 3
Training loss: 3.5968655557119034
Validation loss: 3.1556873094087723

Epoch: 5| Step: 4
Training loss: 3.113091016674679
Validation loss: 3.1557570163528617

Epoch: 5| Step: 5
Training loss: 3.9716709231600493
Validation loss: 3.152471372220291

Epoch: 5| Step: 6
Training loss: 3.075952838183956
Validation loss: 3.153793950245148

Epoch: 5| Step: 7
Training loss: 3.270545574253856
Validation loss: 3.1498869479626697

Epoch: 5| Step: 8
Training loss: 3.63847988602967
Validation loss: 3.151606624314171

Epoch: 5| Step: 9
Training loss: 3.3569295809635107
Validation loss: 3.1549359322047996

Epoch: 5| Step: 10
Training loss: 3.5946349008196132
Validation loss: 3.1548501403735387

Epoch: 66| Step: 0
Training loss: 3.2301507906364098
Validation loss: 3.149975703950319

Epoch: 5| Step: 1
Training loss: 3.3654525783509275
Validation loss: 3.1523510521549776

Epoch: 5| Step: 2
Training loss: 3.5265481078970145
Validation loss: 3.153149236172112

Epoch: 5| Step: 3
Training loss: 3.782190883634646
Validation loss: 3.160299602338681

Epoch: 5| Step: 4
Training loss: 3.3365099234894324
Validation loss: 3.1537920725030624

Epoch: 5| Step: 5
Training loss: 2.632804078221647
Validation loss: 3.155954508563017

Epoch: 5| Step: 6
Training loss: 3.3496671710574994
Validation loss: 3.15572302500669

Epoch: 5| Step: 7
Training loss: 3.639633371103442
Validation loss: 3.1584413423013027

Epoch: 5| Step: 8
Training loss: 3.193953917799742
Validation loss: 3.157271265554903

Epoch: 5| Step: 9
Training loss: 3.678003140280681
Validation loss: 3.154909310317488

Epoch: 5| Step: 10
Training loss: 3.7062665916444604
Validation loss: 3.153165226215323

Epoch: 67| Step: 0
Training loss: 2.6920456701148536
Validation loss: 3.154875269208113

Epoch: 5| Step: 1
Training loss: 4.07342468891829
Validation loss: 3.1534652616941936

Epoch: 5| Step: 2
Training loss: 3.526178955530791
Validation loss: 3.157394747411193

Epoch: 5| Step: 3
Training loss: 4.101341604914796
Validation loss: 3.1563999729676664

Epoch: 5| Step: 4
Training loss: 3.4285562861199006
Validation loss: 3.151915006835476

Epoch: 5| Step: 5
Training loss: 3.529508448192787
Validation loss: 3.158762207077785

Epoch: 5| Step: 6
Training loss: 2.868734747819102
Validation loss: 3.156943418166335

Epoch: 5| Step: 7
Training loss: 2.936632068731882
Validation loss: 3.1465517959576506

Epoch: 5| Step: 8
Training loss: 3.583404776873787
Validation loss: 3.1453324242187546

Epoch: 5| Step: 9
Training loss: 3.1399804208230115
Validation loss: 3.144786979066566

Epoch: 5| Step: 10
Training loss: 3.3181689714632
Validation loss: 3.1464183165407

Epoch: 68| Step: 0
Training loss: 3.1166766902606002
Validation loss: 3.145366415376745

Epoch: 5| Step: 1
Training loss: 3.2939703561807385
Validation loss: 3.1505804337395675

Epoch: 5| Step: 2
Training loss: 4.023241708676667
Validation loss: 3.1471780403306187

Epoch: 5| Step: 3
Training loss: 3.801315411221597
Validation loss: 3.1521287440100614

Epoch: 5| Step: 4
Training loss: 2.9180998051434637
Validation loss: 3.1477477234288127

Epoch: 5| Step: 5
Training loss: 3.694918782912135
Validation loss: 3.147013182147512

Epoch: 5| Step: 6
Training loss: 3.251686538904087
Validation loss: 3.1515069682919084

Epoch: 5| Step: 7
Training loss: 3.361407423663321
Validation loss: 3.1536860977558345

Epoch: 5| Step: 8
Training loss: 4.180356665548562
Validation loss: 3.149570230483563

Epoch: 5| Step: 9
Training loss: 2.8633212181726138
Validation loss: 3.1452233083588066

Epoch: 5| Step: 10
Training loss: 2.4858454545181967
Validation loss: 3.142884235028256

Epoch: 69| Step: 0
Training loss: 3.4017455388640756
Validation loss: 3.1459402370291745

Epoch: 5| Step: 1
Training loss: 3.0447234553395206
Validation loss: 3.146642334124239

Epoch: 5| Step: 2
Training loss: 3.3233413345204887
Validation loss: 3.1443748366431636

Epoch: 5| Step: 3
Training loss: 4.297891836361234
Validation loss: 3.1440442958070074

Epoch: 5| Step: 4
Training loss: 3.070198503469769
Validation loss: 3.1435117695022323

Epoch: 5| Step: 5
Training loss: 3.499085851906356
Validation loss: 3.1447670187511028

Epoch: 5| Step: 6
Training loss: 3.8925592600991687
Validation loss: 3.145756496791442

Epoch: 5| Step: 7
Training loss: 3.1141232221916275
Validation loss: 3.146103850915817

Epoch: 5| Step: 8
Training loss: 4.041577262807212
Validation loss: 3.14267604599379

Epoch: 5| Step: 9
Training loss: 2.491320324645439
Validation loss: 3.144895494608298

Epoch: 5| Step: 10
Training loss: 2.767591908487201
Validation loss: 3.143705446329644

Epoch: 70| Step: 0
Training loss: 2.945309747750289
Validation loss: 3.141190364263679

Epoch: 5| Step: 1
Training loss: 3.4068232062767336
Validation loss: 3.1444210122082548

Epoch: 5| Step: 2
Training loss: 3.5812136716481344
Validation loss: 3.1403739697045108

Epoch: 5| Step: 3
Training loss: 4.092326608385767
Validation loss: 3.142149993585666

Epoch: 5| Step: 4
Training loss: 2.6714894869906494
Validation loss: 3.141890503748649

Epoch: 5| Step: 5
Training loss: 3.5709445652650227
Validation loss: 3.1406351937328716

Epoch: 5| Step: 6
Training loss: 3.628979044698433
Validation loss: 3.142870237639877

Epoch: 5| Step: 7
Training loss: 2.879462386391521
Validation loss: 3.14134681784725

Epoch: 5| Step: 8
Training loss: 3.9271851112405205
Validation loss: 3.1390806182457847

Epoch: 5| Step: 9
Training loss: 3.341403886795546
Validation loss: 3.1404585765908704

Epoch: 5| Step: 10
Training loss: 3.047367936387347
Validation loss: 3.141638174281683

Epoch: 71| Step: 0
Training loss: 3.2058195364284754
Validation loss: 3.137587022655139

Epoch: 5| Step: 1
Training loss: 3.5428773643206624
Validation loss: 3.1385269466973735

Epoch: 5| Step: 2
Training loss: 3.006727146659711
Validation loss: 3.138645296490742

Epoch: 5| Step: 3
Training loss: 3.8362990945040605
Validation loss: 3.1402597489962383

Epoch: 5| Step: 4
Training loss: 2.8078464580301676
Validation loss: 3.1390266822594293

Epoch: 5| Step: 5
Training loss: 2.832092705421567
Validation loss: 3.1372328460449714

Epoch: 5| Step: 6
Training loss: 3.645246069703856
Validation loss: 3.138807902149071

Epoch: 5| Step: 7
Training loss: 3.8046401253948643
Validation loss: 3.1363048370020157

Epoch: 5| Step: 8
Training loss: 3.5798008088686664
Validation loss: 3.135860655472705

Epoch: 5| Step: 9
Training loss: 3.766406346218042
Validation loss: 3.134441458054041

Epoch: 5| Step: 10
Training loss: 3.120282235951522
Validation loss: 3.1354688523484535

Epoch: 72| Step: 0
Training loss: 3.2137947827798143
Validation loss: 3.1384199753653323

Epoch: 5| Step: 1
Training loss: 3.4187345682245693
Validation loss: 3.1376929773823634

Epoch: 5| Step: 2
Training loss: 3.451521142838747
Validation loss: 3.1416538206166247

Epoch: 5| Step: 3
Training loss: 3.348965863841812
Validation loss: 3.14000912548145

Epoch: 5| Step: 4
Training loss: 3.2673595147844594
Validation loss: 3.144345684279258

Epoch: 5| Step: 5
Training loss: 3.1355519482058436
Validation loss: 3.1420211174461

Epoch: 5| Step: 6
Training loss: 2.985202854234971
Validation loss: 3.14508984592131

Epoch: 5| Step: 7
Training loss: 4.055750948119698
Validation loss: 3.140112141023469

Epoch: 5| Step: 8
Training loss: 3.4790070243955324
Validation loss: 3.1327347308873668

Epoch: 5| Step: 9
Training loss: 3.5422195601390163
Validation loss: 3.132172612139977

Epoch: 5| Step: 10
Training loss: 3.3735387959186656
Validation loss: 3.134784787850098

Epoch: 73| Step: 0
Training loss: 3.2605940472956405
Validation loss: 3.1372765159197926

Epoch: 5| Step: 1
Training loss: 3.4055090982138894
Validation loss: 3.137458997627742

Epoch: 5| Step: 2
Training loss: 3.4476975816038125
Validation loss: 3.1364680936509615

Epoch: 5| Step: 3
Training loss: 3.0922282165653225
Validation loss: 3.134841360182238

Epoch: 5| Step: 4
Training loss: 3.660953463406831
Validation loss: 3.1321221749659265

Epoch: 5| Step: 5
Training loss: 3.445697927216987
Validation loss: 3.1330400213015546

Epoch: 5| Step: 6
Training loss: 3.3072772328619995
Validation loss: 3.1315844171500253

Epoch: 5| Step: 7
Training loss: 3.176372627854592
Validation loss: 3.1315995013765034

Epoch: 5| Step: 8
Training loss: 3.9433218891389408
Validation loss: 3.1350970214504668

Epoch: 5| Step: 9
Training loss: 2.7089235591869
Validation loss: 3.133683245745617

Epoch: 5| Step: 10
Training loss: 3.828471016329623
Validation loss: 3.1349552103728904

Epoch: 74| Step: 0
Training loss: 3.5501297456913705
Validation loss: 3.1317242836025176

Epoch: 5| Step: 1
Training loss: 3.724973199735149
Validation loss: 3.1348692282831734

Epoch: 5| Step: 2
Training loss: 3.2965028381011425
Validation loss: 3.134612020284699

Epoch: 5| Step: 3
Training loss: 3.8899075869294215
Validation loss: 3.1363775151740216

Epoch: 5| Step: 4
Training loss: 2.8815950133323414
Validation loss: 3.1303813630497275

Epoch: 5| Step: 5
Training loss: 4.1427866925041945
Validation loss: 3.129177848057831

Epoch: 5| Step: 6
Training loss: 3.0617431951132454
Validation loss: 3.1306256722819237

Epoch: 5| Step: 7
Training loss: 3.190607388827957
Validation loss: 3.1274141039736527

Epoch: 5| Step: 8
Training loss: 3.5499415648043264
Validation loss: 3.127837311038788

Epoch: 5| Step: 9
Training loss: 2.7109304642379883
Validation loss: 3.128049498758568

Epoch: 5| Step: 10
Training loss: 2.9378395695936024
Validation loss: 3.126011951631139

Epoch: 75| Step: 0
Training loss: 3.5907758264428873
Validation loss: 3.121905064598447

Epoch: 5| Step: 1
Training loss: 3.395911248996294
Validation loss: 3.123624389758631

Epoch: 5| Step: 2
Training loss: 3.816018154125096
Validation loss: 3.1177809962907066

Epoch: 5| Step: 3
Training loss: 3.526889370434891
Validation loss: 3.1214071691385064

Epoch: 5| Step: 4
Training loss: 3.5327620518290996
Validation loss: 3.115125694440343

Epoch: 5| Step: 5
Training loss: 3.551052238438921
Validation loss: 3.118044819383122

Epoch: 5| Step: 6
Training loss: 3.184139649563499
Validation loss: 3.1121697754867657

Epoch: 5| Step: 7
Training loss: 2.8261791300334487
Validation loss: 3.112331093925815

Epoch: 5| Step: 8
Training loss: 3.4322491856880455
Validation loss: 3.1133668978103306

Epoch: 5| Step: 9
Training loss: 2.2753845476716053
Validation loss: 3.111296723349732

Epoch: 5| Step: 10
Training loss: 3.83934140339254
Validation loss: 3.109877702123016

Epoch: 76| Step: 0
Training loss: 4.130098371096219
Validation loss: 3.10821209364576

Epoch: 5| Step: 1
Training loss: 3.1108963661405853
Validation loss: 3.1070576656325657

Epoch: 5| Step: 2
Training loss: 3.3404217850027846
Validation loss: 3.1066557099914354

Epoch: 5| Step: 3
Training loss: 2.269835459925833
Validation loss: 3.107252990101993

Epoch: 5| Step: 4
Training loss: 3.4770320960936822
Validation loss: 3.109805870368937

Epoch: 5| Step: 5
Training loss: 3.9460727676743064
Validation loss: 3.1074241569648184

Epoch: 5| Step: 6
Training loss: 3.314915909657158
Validation loss: 3.1055236204798193

Epoch: 5| Step: 7
Training loss: 3.1991348348751143
Validation loss: 3.106801927005544

Epoch: 5| Step: 8
Training loss: 3.318909543902622
Validation loss: 3.106037931675776

Epoch: 5| Step: 9
Training loss: 3.0411363600992596
Validation loss: 3.1067369144591472

Epoch: 5| Step: 10
Training loss: 3.6227849572611426
Validation loss: 3.1076125626075166

Epoch: 77| Step: 0
Training loss: 3.115245242682846
Validation loss: 3.106947584300366

Epoch: 5| Step: 1
Training loss: 3.211053776549997
Validation loss: 3.1060541485671407

Epoch: 5| Step: 2
Training loss: 3.21478679323786
Validation loss: 3.1086968115035924

Epoch: 5| Step: 3
Training loss: 3.650769682950994
Validation loss: 3.1065695029116562

Epoch: 5| Step: 4
Training loss: 3.1110018207639136
Validation loss: 3.1068429905082957

Epoch: 5| Step: 5
Training loss: 3.4557536205048422
Validation loss: 3.107338422906876

Epoch: 5| Step: 6
Training loss: 2.897186585163774
Validation loss: 3.1030709666719214

Epoch: 5| Step: 7
Training loss: 3.3192822103257007
Validation loss: 3.1021265374754856

Epoch: 5| Step: 8
Training loss: 3.616980000882259
Validation loss: 3.103640241156543

Epoch: 5| Step: 9
Training loss: 4.139850356857462
Validation loss: 3.10557052394972

Epoch: 5| Step: 10
Training loss: 3.127657713843281
Validation loss: 3.1039868622265963

Epoch: 78| Step: 0
Training loss: 3.7820634203454517
Validation loss: 3.1035957271105

Epoch: 5| Step: 1
Training loss: 3.3255844807141344
Validation loss: 3.104569314787358

Epoch: 5| Step: 2
Training loss: 3.375966392901229
Validation loss: 3.100203117242184

Epoch: 5| Step: 3
Training loss: 2.9022535512880943
Validation loss: 3.1010858895859794

Epoch: 5| Step: 4
Training loss: 3.347191866310113
Validation loss: 3.1007565712059533

Epoch: 5| Step: 5
Training loss: 3.7461633765280626
Validation loss: 3.103096620561506

Epoch: 5| Step: 6
Training loss: 3.6242468479035166
Validation loss: 3.100344950113829

Epoch: 5| Step: 7
Training loss: 3.4213104479087013
Validation loss: 3.1002012566566215

Epoch: 5| Step: 8
Training loss: 3.205997128395513
Validation loss: 3.100863523155555

Epoch: 5| Step: 9
Training loss: 2.9531550330194065
Validation loss: 3.1005274870665387

Epoch: 5| Step: 10
Training loss: 3.2245867501382994
Validation loss: 3.098239427654991

Epoch: 79| Step: 0
Training loss: 3.618303757002982
Validation loss: 3.0982963193385804

Epoch: 5| Step: 1
Training loss: 3.26271007343825
Validation loss: 3.0997995871504798

Epoch: 5| Step: 2
Training loss: 2.899612887623327
Validation loss: 3.102197018214692

Epoch: 5| Step: 3
Training loss: 2.6717300821902046
Validation loss: 3.097241475479094

Epoch: 5| Step: 4
Training loss: 3.4315936585253572
Validation loss: 3.09998468761784

Epoch: 5| Step: 5
Training loss: 3.9133142909724485
Validation loss: 3.0994590850368167

Epoch: 5| Step: 6
Training loss: 3.3875753865880083
Validation loss: 3.0980154344235977

Epoch: 5| Step: 7
Training loss: 3.9089963490217077
Validation loss: 3.0982568454449804

Epoch: 5| Step: 8
Training loss: 3.0660070463175466
Validation loss: 3.0983341809048603

Epoch: 5| Step: 9
Training loss: 3.0004179981216197
Validation loss: 3.100840106184445

Epoch: 5| Step: 10
Training loss: 3.665096698229536
Validation loss: 3.10169154796279

Epoch: 80| Step: 0
Training loss: 3.338541127094259
Validation loss: 3.0964951221747836

Epoch: 5| Step: 1
Training loss: 3.2419099620009795
Validation loss: 3.0986404886042025

Epoch: 5| Step: 2
Training loss: 4.221804946781292
Validation loss: 3.0967896247038356

Epoch: 5| Step: 3
Training loss: 3.0748792857224716
Validation loss: 3.096575672473742

Epoch: 5| Step: 4
Training loss: 3.2314556417937057
Validation loss: 3.0975578104287007

Epoch: 5| Step: 5
Training loss: 3.2351241418995
Validation loss: 3.096305939040321

Epoch: 5| Step: 6
Training loss: 2.8147004738202996
Validation loss: 3.0951377562781928

Epoch: 5| Step: 7
Training loss: 3.56729285426715
Validation loss: 3.0951723930965453

Epoch: 5| Step: 8
Training loss: 3.056743271539268
Validation loss: 3.0966995860605735

Epoch: 5| Step: 9
Training loss: 3.775819141364355
Validation loss: 3.095525363724954

Epoch: 5| Step: 10
Training loss: 3.185206167593885
Validation loss: 3.094052810906239

Epoch: 81| Step: 0
Training loss: 3.1682991203642805
Validation loss: 3.0947244136555114

Epoch: 5| Step: 1
Training loss: 3.761613030299858
Validation loss: 3.0970274029814986

Epoch: 5| Step: 2
Training loss: 3.3624920245788608
Validation loss: 3.1028802048613517

Epoch: 5| Step: 3
Training loss: 3.017198537512987
Validation loss: 3.1001060312234188

Epoch: 5| Step: 4
Training loss: 3.832845090096934
Validation loss: 3.1084652527923375

Epoch: 5| Step: 5
Training loss: 2.5344747088629083
Validation loss: 3.1085402098344312

Epoch: 5| Step: 6
Training loss: 3.560407191145453
Validation loss: 3.1016006423986604

Epoch: 5| Step: 7
Training loss: 3.1536142655842028
Validation loss: 3.099609647110976

Epoch: 5| Step: 8
Training loss: 2.9459660055526067
Validation loss: 3.0950882769216

Epoch: 5| Step: 9
Training loss: 3.9813390796702524
Validation loss: 3.093377990995242

Epoch: 5| Step: 10
Training loss: 3.3814333599811137
Validation loss: 3.090188075861448

Epoch: 82| Step: 0
Training loss: 3.0352096651107385
Validation loss: 3.091116828629295

Epoch: 5| Step: 1
Training loss: 3.772122424463984
Validation loss: 3.092522624729844

Epoch: 5| Step: 2
Training loss: 3.0077414764341865
Validation loss: 3.0920298030384674

Epoch: 5| Step: 3
Training loss: 3.91801037295625
Validation loss: 3.09110645169201

Epoch: 5| Step: 4
Training loss: 3.3898306061049626
Validation loss: 3.0920350231265146

Epoch: 5| Step: 5
Training loss: 3.4368418670405783
Validation loss: 3.0926281537919045

Epoch: 5| Step: 6
Training loss: 3.0076319256368227
Validation loss: 3.0921522978419884

Epoch: 5| Step: 7
Training loss: 3.047086268216269
Validation loss: 3.0902401763802536

Epoch: 5| Step: 8
Training loss: 3.2026133058799826
Validation loss: 3.0894574088105164

Epoch: 5| Step: 9
Training loss: 3.6824889968738765
Validation loss: 3.090311553710275

Epoch: 5| Step: 10
Training loss: 3.2675436853758884
Validation loss: 3.089374376789406

Epoch: 83| Step: 0
Training loss: 4.1067993446897235
Validation loss: 3.089952885035286

Epoch: 5| Step: 1
Training loss: 3.227382010882046
Validation loss: 3.0929808478300425

Epoch: 5| Step: 2
Training loss: 2.5829158773809233
Validation loss: 3.092071323056697

Epoch: 5| Step: 3
Training loss: 2.7387687912979257
Validation loss: 3.092740436632794

Epoch: 5| Step: 4
Training loss: 3.718994517261539
Validation loss: 3.094873727460387

Epoch: 5| Step: 5
Training loss: 3.3710107185331424
Validation loss: 3.0926861641454906

Epoch: 5| Step: 6
Training loss: 3.0641272756371776
Validation loss: 3.091483696329213

Epoch: 5| Step: 7
Training loss: 3.305501923183885
Validation loss: 3.0883669524776365

Epoch: 5| Step: 8
Training loss: 3.231275612233403
Validation loss: 3.0864488553149134

Epoch: 5| Step: 9
Training loss: 3.728736866880864
Validation loss: 3.087595182328936

Epoch: 5| Step: 10
Training loss: 3.5524805616884545
Validation loss: 3.0856056210414122

Epoch: 84| Step: 0
Training loss: 2.9568093542900575
Validation loss: 3.083600562858824

Epoch: 5| Step: 1
Training loss: 2.8240181626122154
Validation loss: 3.0866937863518804

Epoch: 5| Step: 2
Training loss: 3.4549170629591486
Validation loss: 3.088134601564966

Epoch: 5| Step: 3
Training loss: 3.745661196432736
Validation loss: 3.093999972519416

Epoch: 5| Step: 4
Training loss: 2.975767334785085
Validation loss: 3.1024245015895175

Epoch: 5| Step: 5
Training loss: 3.6850170245870753
Validation loss: 3.1162454338759784

Epoch: 5| Step: 6
Training loss: 3.833104596708026
Validation loss: 3.0971388020565844

Epoch: 5| Step: 7
Training loss: 2.759176894752427
Validation loss: 3.0841713597662443

Epoch: 5| Step: 8
Training loss: 3.345836238139322
Validation loss: 3.084936120878402

Epoch: 5| Step: 9
Training loss: 3.6085132709653984
Validation loss: 3.0884218993544996

Epoch: 5| Step: 10
Training loss: 3.541802362572607
Validation loss: 3.0915977223124913

Epoch: 85| Step: 0
Training loss: 3.2417286008068382
Validation loss: 3.091661474393091

Epoch: 5| Step: 1
Training loss: 2.734576059851292
Validation loss: 3.087729451086075

Epoch: 5| Step: 2
Training loss: 3.1881992844596776
Validation loss: 3.0854603770440505

Epoch: 5| Step: 3
Training loss: 3.6934404530696163
Validation loss: 3.0837738522832616

Epoch: 5| Step: 4
Training loss: 3.126063204145277
Validation loss: 3.0857666566473485

Epoch: 5| Step: 5
Training loss: 2.9560524291781927
Validation loss: 3.0820956898811414

Epoch: 5| Step: 6
Training loss: 3.6641988830561374
Validation loss: 3.0822319041242263

Epoch: 5| Step: 7
Training loss: 2.9136677901667305
Validation loss: 3.082999897903485

Epoch: 5| Step: 8
Training loss: 3.602420067625086
Validation loss: 3.0835881553342315

Epoch: 5| Step: 9
Training loss: 3.842786962928866
Validation loss: 3.0907302152548186

Epoch: 5| Step: 10
Training loss: 3.801839463586642
Validation loss: 3.0915779832966224

Epoch: 86| Step: 0
Training loss: 3.5196393638881602
Validation loss: 3.087658489819741

Epoch: 5| Step: 1
Training loss: 3.8380827023340776
Validation loss: 3.085220381941975

Epoch: 5| Step: 2
Training loss: 3.552389957621593
Validation loss: 3.0838660589518803

Epoch: 5| Step: 3
Training loss: 3.3101386524675322
Validation loss: 3.083996819169042

Epoch: 5| Step: 4
Training loss: 3.3336842987944015
Validation loss: 3.083654332655776

Epoch: 5| Step: 5
Training loss: 3.3597658861433164
Validation loss: 3.08354161087586

Epoch: 5| Step: 6
Training loss: 3.1188674262497873
Validation loss: 3.083209317702923

Epoch: 5| Step: 7
Training loss: 2.808358258175443
Validation loss: 3.0835355516641916

Epoch: 5| Step: 8
Training loss: 2.879823535970153
Validation loss: 3.0813540519423586

Epoch: 5| Step: 9
Training loss: 3.6198578240731925
Validation loss: 3.082529549952693

Epoch: 5| Step: 10
Training loss: 3.42408256216422
Validation loss: 3.082442117969675

Epoch: 87| Step: 0
Training loss: 3.776963255218988
Validation loss: 3.0800997022406897

Epoch: 5| Step: 1
Training loss: 3.425064760138853
Validation loss: 3.0795898008782214

Epoch: 5| Step: 2
Training loss: 3.316081863552414
Validation loss: 3.0794903142679813

Epoch: 5| Step: 3
Training loss: 3.6682041730475654
Validation loss: 3.07925776644192

Epoch: 5| Step: 4
Training loss: 3.0896465175870356
Validation loss: 3.079091038497348

Epoch: 5| Step: 5
Training loss: 3.8058343369095824
Validation loss: 3.080971206858377

Epoch: 5| Step: 6
Training loss: 3.3425487606626216
Validation loss: 3.0849733860398727

Epoch: 5| Step: 7
Training loss: 2.922713541888259
Validation loss: 3.083729302529195

Epoch: 5| Step: 8
Training loss: 3.261874733124675
Validation loss: 3.0790757836252145

Epoch: 5| Step: 9
Training loss: 3.1897368716596053
Validation loss: 3.0798374407922497

Epoch: 5| Step: 10
Training loss: 2.791486696354047
Validation loss: 3.078423578391569

Epoch: 88| Step: 0
Training loss: 2.72532630156688
Validation loss: 3.0776135344682722

Epoch: 5| Step: 1
Training loss: 4.231808493422168
Validation loss: 3.0810755889252786

Epoch: 5| Step: 2
Training loss: 3.7650076332369524
Validation loss: 3.0829130937857427

Epoch: 5| Step: 3
Training loss: 3.460222088516208
Validation loss: 3.0786550800529655

Epoch: 5| Step: 4
Training loss: 2.9911294764760594
Validation loss: 3.0783124406169327

Epoch: 5| Step: 5
Training loss: 3.4082828720075624
Validation loss: 3.0767814886147167

Epoch: 5| Step: 6
Training loss: 3.027547876182658
Validation loss: 3.0774916846917875

Epoch: 5| Step: 7
Training loss: 3.3307804027172803
Validation loss: 3.077711293359443

Epoch: 5| Step: 8
Training loss: 3.203356032064507
Validation loss: 3.078725475264077

Epoch: 5| Step: 9
Training loss: 3.6048584790433402
Validation loss: 3.0759242591873344

Epoch: 5| Step: 10
Training loss: 2.613196036598824
Validation loss: 3.078618824284142

Epoch: 89| Step: 0
Training loss: 3.3983603282365786
Validation loss: 3.0796100321290507

Epoch: 5| Step: 1
Training loss: 3.20265127260996
Validation loss: 3.076776769244248

Epoch: 5| Step: 2
Training loss: 3.291655254746626
Validation loss: 3.0758906558151358

Epoch: 5| Step: 3
Training loss: 3.9592077928988614
Validation loss: 3.074861105199671

Epoch: 5| Step: 4
Training loss: 3.8751198534734614
Validation loss: 3.07473804743068

Epoch: 5| Step: 5
Training loss: 2.4598863082293176
Validation loss: 3.0744277256177615

Epoch: 5| Step: 6
Training loss: 4.217626803605576
Validation loss: 3.077726293443487

Epoch: 5| Step: 7
Training loss: 2.9039180793346797
Validation loss: 3.075767122469542

Epoch: 5| Step: 8
Training loss: 2.5747008733243493
Validation loss: 3.0755842712755546

Epoch: 5| Step: 9
Training loss: 2.7737589045446565
Validation loss: 3.075816513399023

Epoch: 5| Step: 10
Training loss: 3.6555721600151236
Validation loss: 3.0748451323302692

Epoch: 90| Step: 0
Training loss: 4.049161169521141
Validation loss: 3.073478280052918

Epoch: 5| Step: 1
Training loss: 3.4150401795286993
Validation loss: 3.0707696560083475

Epoch: 5| Step: 2
Training loss: 2.913992300543107
Validation loss: 3.069012735824081

Epoch: 5| Step: 3
Training loss: 3.310677800923231
Validation loss: 3.0733916899763334

Epoch: 5| Step: 4
Training loss: 3.5822934852381767
Validation loss: 3.0741401257130048

Epoch: 5| Step: 5
Training loss: 3.3210523072867093
Validation loss: 3.072352776671603

Epoch: 5| Step: 6
Training loss: 3.5131004933383196
Validation loss: 3.0709582768562638

Epoch: 5| Step: 7
Training loss: 2.980291318799165
Validation loss: 3.074237849955952

Epoch: 5| Step: 8
Training loss: 3.5373591688180595
Validation loss: 3.0692769512538884

Epoch: 5| Step: 9
Training loss: 2.9729828222800525
Validation loss: 3.0708338004181863

Epoch: 5| Step: 10
Training loss: 2.911477258901667
Validation loss: 3.0702874739642856

Epoch: 91| Step: 0
Training loss: 3.182200645397898
Validation loss: 3.0725873397684453

Epoch: 5| Step: 1
Training loss: 3.73240935494695
Validation loss: 3.072928355872418

Epoch: 5| Step: 2
Training loss: 3.3481932023610756
Validation loss: 3.0762314482358755

Epoch: 5| Step: 3
Training loss: 3.19826306052349
Validation loss: 3.07875015126158

Epoch: 5| Step: 4
Training loss: 3.1366363552573433
Validation loss: 3.0875151682791606

Epoch: 5| Step: 5
Training loss: 3.145022222443442
Validation loss: 3.0711577462012105

Epoch: 5| Step: 6
Training loss: 4.056175355856309
Validation loss: 3.0698145059887945

Epoch: 5| Step: 7
Training loss: 3.147410184928616
Validation loss: 3.0712430344875483

Epoch: 5| Step: 8
Training loss: 3.1897280516746465
Validation loss: 3.0694056661149616

Epoch: 5| Step: 9
Training loss: 3.375339490981955
Validation loss: 3.0678053209499625

Epoch: 5| Step: 10
Training loss: 3.0712631345785546
Validation loss: 3.070212026396254

Epoch: 92| Step: 0
Training loss: 3.8569249086515236
Validation loss: 3.0693147890803285

Epoch: 5| Step: 1
Training loss: 2.6695608189312527
Validation loss: 3.06758021109358

Epoch: 5| Step: 2
Training loss: 3.059451863430912
Validation loss: 3.067160846973303

Epoch: 5| Step: 3
Training loss: 3.1425301765686404
Validation loss: 3.072087589057791

Epoch: 5| Step: 4
Training loss: 3.772162749305891
Validation loss: 3.0688329999667396

Epoch: 5| Step: 5
Training loss: 3.2464439304197716
Validation loss: 3.0666344706043254

Epoch: 5| Step: 6
Training loss: 2.8172752531732383
Validation loss: 3.065665751180896

Epoch: 5| Step: 7
Training loss: 3.724431034133286
Validation loss: 3.0644182480474296

Epoch: 5| Step: 8
Training loss: 3.38535021594439
Validation loss: 3.0667731437705514

Epoch: 5| Step: 9
Training loss: 3.4476014576146814
Validation loss: 3.066498288346854

Epoch: 5| Step: 10
Training loss: 3.360187237154768
Validation loss: 3.0648684355806477

Epoch: 93| Step: 0
Training loss: 2.987586086421494
Validation loss: 3.0659532011536186

Epoch: 5| Step: 1
Training loss: 3.9160780904073476
Validation loss: 3.064199255383582

Epoch: 5| Step: 2
Training loss: 3.6033312908052717
Validation loss: 3.0632562814773863

Epoch: 5| Step: 3
Training loss: 3.543631932143604
Validation loss: 3.065430259534008

Epoch: 5| Step: 4
Training loss: 2.8962458218415557
Validation loss: 3.0642910504706227

Epoch: 5| Step: 5
Training loss: 3.187665000085642
Validation loss: 3.066310735870965

Epoch: 5| Step: 6
Training loss: 3.58819761504767
Validation loss: 3.065239600709117

Epoch: 5| Step: 7
Training loss: 3.3788416156209733
Validation loss: 3.063750650583184

Epoch: 5| Step: 8
Training loss: 2.8304080073224496
Validation loss: 3.063886392685008

Epoch: 5| Step: 9
Training loss: 3.43140939922474
Validation loss: 3.06586618615249

Epoch: 5| Step: 10
Training loss: 3.103183582133256
Validation loss: 3.0652097224756516

Epoch: 94| Step: 0
Training loss: 2.912768856622402
Validation loss: 3.0643035035022352

Epoch: 5| Step: 1
Training loss: 3.561211336193104
Validation loss: 3.0665512954625713

Epoch: 5| Step: 2
Training loss: 3.179789923440597
Validation loss: 3.06450960491071

Epoch: 5| Step: 3
Training loss: 3.486800645280599
Validation loss: 3.066201373037682

Epoch: 5| Step: 4
Training loss: 3.0476063950877714
Validation loss: 3.0652058751844735

Epoch: 5| Step: 5
Training loss: 3.381180649361723
Validation loss: 3.064102314544061

Epoch: 5| Step: 6
Training loss: 3.962648883513556
Validation loss: 3.064803612571153

Epoch: 5| Step: 7
Training loss: 2.927791867191097
Validation loss: 3.064425213430724

Epoch: 5| Step: 8
Training loss: 3.4619210871314485
Validation loss: 3.0645283429205192

Epoch: 5| Step: 9
Training loss: 3.111817134113068
Validation loss: 3.06111275328984

Epoch: 5| Step: 10
Training loss: 3.456704334383645
Validation loss: 3.0634544413837297

Epoch: 95| Step: 0
Training loss: 2.967711256906594
Validation loss: 3.0625442667430773

Epoch: 5| Step: 1
Training loss: 2.7901225493120267
Validation loss: 3.066224258589237

Epoch: 5| Step: 2
Training loss: 3.650294613379218
Validation loss: 3.063801244350497

Epoch: 5| Step: 3
Training loss: 2.9057196676743224
Validation loss: 3.066222297120555

Epoch: 5| Step: 4
Training loss: 3.5330579062542
Validation loss: 3.062944110062962

Epoch: 5| Step: 5
Training loss: 3.4535208772917727
Validation loss: 3.060581606764127

Epoch: 5| Step: 6
Training loss: 3.4729323733286765
Validation loss: 3.0608343684904016

Epoch: 5| Step: 7
Training loss: 3.4843982644437745
Validation loss: 3.057878053176613

Epoch: 5| Step: 8
Training loss: 3.8717246210361727
Validation loss: 3.0584363272293693

Epoch: 5| Step: 9
Training loss: 3.261066960980566
Validation loss: 3.0590810603776544

Epoch: 5| Step: 10
Training loss: 3.001351052282636
Validation loss: 3.058365278090317

Epoch: 96| Step: 0
Training loss: 3.911638617223341
Validation loss: 3.0550234677813597

Epoch: 5| Step: 1
Training loss: 3.443460325599389
Validation loss: 3.058246064788644

Epoch: 5| Step: 2
Training loss: 3.112056630126806
Validation loss: 3.058420138655428

Epoch: 5| Step: 3
Training loss: 3.4657861918051336
Validation loss: 3.0570530840340804

Epoch: 5| Step: 4
Training loss: 3.3338353414808064
Validation loss: 3.05764482081087

Epoch: 5| Step: 5
Training loss: 3.6787439906349575
Validation loss: 3.0618725565658926

Epoch: 5| Step: 6
Training loss: 2.590141728032496
Validation loss: 3.060658791890636

Epoch: 5| Step: 7
Training loss: 3.548464649924688
Validation loss: 3.063551499795189

Epoch: 5| Step: 8
Training loss: 3.4954503325091855
Validation loss: 3.0611833743626273

Epoch: 5| Step: 9
Training loss: 2.811539973547889
Validation loss: 3.0582724249618565

Epoch: 5| Step: 10
Training loss: 2.907313982719481
Validation loss: 3.0573457560532673

Epoch: 97| Step: 0
Training loss: 3.4274246988852024
Validation loss: 3.054846817023429

Epoch: 5| Step: 1
Training loss: 3.419585136771622
Validation loss: 3.0561980869287986

Epoch: 5| Step: 2
Training loss: 3.002320187129028
Validation loss: 3.0566986331142

Epoch: 5| Step: 3
Training loss: 3.600799148657443
Validation loss: 3.056446844554981

Epoch: 5| Step: 4
Training loss: 3.4743594615277957
Validation loss: 3.0571775328973003

Epoch: 5| Step: 5
Training loss: 3.5934789140708174
Validation loss: 3.0551850278522434

Epoch: 5| Step: 6
Training loss: 2.5030683761078505
Validation loss: 3.05489010287541

Epoch: 5| Step: 7
Training loss: 3.103331553796353
Validation loss: 3.058821090153128

Epoch: 5| Step: 8
Training loss: 3.438535638338013
Validation loss: 3.0549498905547186

Epoch: 5| Step: 9
Training loss: 3.309451733961223
Validation loss: 3.0560596427501676

Epoch: 5| Step: 10
Training loss: 3.5897141060648896
Validation loss: 3.0546386301930775

Epoch: 98| Step: 0
Training loss: 3.113120731824895
Validation loss: 3.0537057845435416

Epoch: 5| Step: 1
Training loss: 3.3187854082478028
Validation loss: 3.054679377746232

Epoch: 5| Step: 2
Training loss: 3.9865235762502427
Validation loss: 3.058570737784524

Epoch: 5| Step: 3
Training loss: 2.985567184313282
Validation loss: 3.065241293499205

Epoch: 5| Step: 4
Training loss: 2.90191491143318
Validation loss: 3.073703336611832

Epoch: 5| Step: 5
Training loss: 2.916632043542173
Validation loss: 3.0834987272309573

Epoch: 5| Step: 6
Training loss: 3.565123278183724
Validation loss: 3.115678564552468

Epoch: 5| Step: 7
Training loss: 3.602344353600714
Validation loss: 3.109611160512097

Epoch: 5| Step: 8
Training loss: 3.5019005656087856
Validation loss: 3.0577794321613068

Epoch: 5| Step: 9
Training loss: 3.4226236438917805
Validation loss: 3.0518193172565646

Epoch: 5| Step: 10
Training loss: 3.1352486972025915
Validation loss: 3.052826429167732

Epoch: 99| Step: 0
Training loss: 3.5069252710269407
Validation loss: 3.0665475994989344

Epoch: 5| Step: 1
Training loss: 2.3560748735910413
Validation loss: 3.072282363112423

Epoch: 5| Step: 2
Training loss: 3.0675154119600285
Validation loss: 3.081835146372519

Epoch: 5| Step: 3
Training loss: 3.6356721513197976
Validation loss: 3.080757339383811

Epoch: 5| Step: 4
Training loss: 3.7256478840688763
Validation loss: 3.062143697263564

Epoch: 5| Step: 5
Training loss: 3.215719184941964
Validation loss: 3.0555709024331663

Epoch: 5| Step: 6
Training loss: 3.256615288393254
Validation loss: 3.0553168527681893

Epoch: 5| Step: 7
Training loss: 3.5051823804479327
Validation loss: 3.0545084864950485

Epoch: 5| Step: 8
Training loss: 3.587127687494093
Validation loss: 3.061775984156391

Epoch: 5| Step: 9
Training loss: 3.4867916194439146
Validation loss: 3.065436868024416

Epoch: 5| Step: 10
Training loss: 3.182741690041362
Validation loss: 3.0662712072134664

Epoch: 100| Step: 0
Training loss: 3.981530105103343
Validation loss: 3.0680435481935207

Epoch: 5| Step: 1
Training loss: 3.471639992960482
Validation loss: 3.060370693848414

Epoch: 5| Step: 2
Training loss: 3.146481344078304
Validation loss: 3.062617904271935

Epoch: 5| Step: 3
Training loss: 2.6480855792354663
Validation loss: 3.0551847391979026

Epoch: 5| Step: 4
Training loss: 4.220545633847323
Validation loss: 3.054095932275808

Epoch: 5| Step: 5
Training loss: 2.913316892087214
Validation loss: 3.0520641076129436

Epoch: 5| Step: 6
Training loss: 2.735434539418884
Validation loss: 3.056320497932926

Epoch: 5| Step: 7
Training loss: 3.3724717454454862
Validation loss: 3.054411980891767

Epoch: 5| Step: 8
Training loss: 2.638203611126747
Validation loss: 3.053746218815477

Epoch: 5| Step: 9
Training loss: 3.6609565893921854
Validation loss: 3.0563833208664

Epoch: 5| Step: 10
Training loss: 3.4179444753602284
Validation loss: 3.0508293681770704

Epoch: 101| Step: 0
Training loss: 3.23049797589183
Validation loss: 3.0520094150315256

Epoch: 5| Step: 1
Training loss: 3.5963280759947343
Validation loss: 3.052959929567846

Epoch: 5| Step: 2
Training loss: 2.734625842986413
Validation loss: 3.052380668965125

Epoch: 5| Step: 3
Training loss: 3.7356196288615418
Validation loss: 3.05430465467331

Epoch: 5| Step: 4
Training loss: 3.4110458629413585
Validation loss: 3.0520448789715293

Epoch: 5| Step: 5
Training loss: 3.215844778366923
Validation loss: 3.05222464759326

Epoch: 5| Step: 6
Training loss: 3.3300699631040005
Validation loss: 3.049016050798651

Epoch: 5| Step: 7
Training loss: 3.7212855566528122
Validation loss: 3.0486503004180054

Epoch: 5| Step: 8
Training loss: 3.072044136614435
Validation loss: 3.0524176638784883

Epoch: 5| Step: 9
Training loss: 3.442490440471732
Validation loss: 3.0516374539437883

Epoch: 5| Step: 10
Training loss: 2.851483571253551
Validation loss: 3.0552597951210116

Epoch: 102| Step: 0
Training loss: 3.5638881455068256
Validation loss: 3.0513905079698413

Epoch: 5| Step: 1
Training loss: 3.569126725229788
Validation loss: 3.0488055999325914

Epoch: 5| Step: 2
Training loss: 3.6046169345200756
Validation loss: 3.0513499122560024

Epoch: 5| Step: 3
Training loss: 3.1734771440547496
Validation loss: 3.0507427285254356

Epoch: 5| Step: 4
Training loss: 3.4911190164909427
Validation loss: 3.0508552193463268

Epoch: 5| Step: 5
Training loss: 2.9368364923960013
Validation loss: 3.0489280285799905

Epoch: 5| Step: 6
Training loss: 3.672311310513874
Validation loss: 3.051592831561992

Epoch: 5| Step: 7
Training loss: 3.4825623591440755
Validation loss: 3.049195565837766

Epoch: 5| Step: 8
Training loss: 2.9307582678648547
Validation loss: 3.0518689445491023

Epoch: 5| Step: 9
Training loss: 2.8551965419373184
Validation loss: 3.057967450036538

Epoch: 5| Step: 10
Training loss: 3.0314041570417625
Validation loss: 3.0594042763824953

Epoch: 103| Step: 0
Training loss: 2.9917361563968483
Validation loss: 3.0752728110849046

Epoch: 5| Step: 1
Training loss: 3.6679375497874314
Validation loss: 3.0571184697113494

Epoch: 5| Step: 2
Training loss: 3.221754283105024
Validation loss: 3.049382244080376

Epoch: 5| Step: 3
Training loss: 3.2362713990106267
Validation loss: 3.048400905732161

Epoch: 5| Step: 4
Training loss: 3.244758781319529
Validation loss: 3.049967571336965

Epoch: 5| Step: 5
Training loss: 3.1962557941573717
Validation loss: 3.0507302453490603

Epoch: 5| Step: 6
Training loss: 3.029330088017073
Validation loss: 3.0494339673725657

Epoch: 5| Step: 7
Training loss: 3.612283038847673
Validation loss: 3.047531823648405

Epoch: 5| Step: 8
Training loss: 3.3272082001805408
Validation loss: 3.04775551062266

Epoch: 5| Step: 9
Training loss: 3.7063215277783104
Validation loss: 3.0468009693627267

Epoch: 5| Step: 10
Training loss: 3.138335195072518
Validation loss: 3.0502638026451714

Epoch: 104| Step: 0
Training loss: 3.03759573326424
Validation loss: 3.047390096039173

Epoch: 5| Step: 1
Training loss: 3.1390708000411363
Validation loss: 3.047833161875598

Epoch: 5| Step: 2
Training loss: 3.606304100860506
Validation loss: 3.0490331797148182

Epoch: 5| Step: 3
Training loss: 3.3801900728944285
Validation loss: 3.0458199996008846

Epoch: 5| Step: 4
Training loss: 3.0318252175010185
Validation loss: 3.0492924130868233

Epoch: 5| Step: 5
Training loss: 2.962173566257268
Validation loss: 3.049843554533311

Epoch: 5| Step: 6
Training loss: 3.5305719315370596
Validation loss: 3.0450528140158597

Epoch: 5| Step: 7
Training loss: 3.438688454224559
Validation loss: 3.043760151250374

Epoch: 5| Step: 8
Training loss: 4.0137174951786925
Validation loss: 3.043849728606732

Epoch: 5| Step: 9
Training loss: 3.1190022704815465
Validation loss: 3.0445068462137224

Epoch: 5| Step: 10
Training loss: 3.001300370994405
Validation loss: 3.039608445417657

Epoch: 105| Step: 0
Training loss: 3.5598529551708964
Validation loss: 3.0407858163253123

Epoch: 5| Step: 1
Training loss: 3.48292148534231
Validation loss: 3.0416144719002336

Epoch: 5| Step: 2
Training loss: 2.8692380136849582
Validation loss: 3.043439103990979

Epoch: 5| Step: 3
Training loss: 3.4817512795073506
Validation loss: 3.0394482807328873

Epoch: 5| Step: 4
Training loss: 2.763897372370682
Validation loss: 3.0378428394102004

Epoch: 5| Step: 5
Training loss: 3.2493305984107796
Validation loss: 3.0411664562982588

Epoch: 5| Step: 6
Training loss: 3.0611703282709577
Validation loss: 3.041490653948196

Epoch: 5| Step: 7
Training loss: 3.072221235474774
Validation loss: 3.0432759179080415

Epoch: 5| Step: 8
Training loss: 3.688182056517688
Validation loss: 3.045204955648811

Epoch: 5| Step: 9
Training loss: 3.5725148292911775
Validation loss: 3.0408073612838544

Epoch: 5| Step: 10
Training loss: 3.493881736278028
Validation loss: 3.0436730930604634

Epoch: 106| Step: 0
Training loss: 3.4410741085019714
Validation loss: 3.040845589614841

Epoch: 5| Step: 1
Training loss: 3.591489794300677
Validation loss: 3.0434578731736526

Epoch: 5| Step: 2
Training loss: 2.525899624845556
Validation loss: 3.0410677536120128

Epoch: 5| Step: 3
Training loss: 3.3673140995450836
Validation loss: 3.0436238661493054

Epoch: 5| Step: 4
Training loss: 3.2962211936875296
Validation loss: 3.0462914988542216

Epoch: 5| Step: 5
Training loss: 3.5650903753994267
Validation loss: 3.0412391742027247

Epoch: 5| Step: 6
Training loss: 3.6754885809363835
Validation loss: 3.0398038904654365

Epoch: 5| Step: 7
Training loss: 3.2139177808137926
Validation loss: 3.0398268507797295

Epoch: 5| Step: 8
Training loss: 3.1700825253884855
Validation loss: 3.0375332399952635

Epoch: 5| Step: 9
Training loss: 3.336766160160579
Validation loss: 3.0388517402898465

Epoch: 5| Step: 10
Training loss: 3.009780992670452
Validation loss: 3.03825998174452

Epoch: 107| Step: 0
Training loss: 2.7719856007905217
Validation loss: 3.0366054157283267

Epoch: 5| Step: 1
Training loss: 3.173619283994413
Validation loss: 3.03651482682865

Epoch: 5| Step: 2
Training loss: 3.6326780889112995
Validation loss: 3.039530695380071

Epoch: 5| Step: 3
Training loss: 3.095396586262432
Validation loss: 3.0393122670492465

Epoch: 5| Step: 4
Training loss: 3.420629126478146
Validation loss: 3.03680608795545

Epoch: 5| Step: 5
Training loss: 2.9054577475675654
Validation loss: 3.0361330928331425

Epoch: 5| Step: 6
Training loss: 3.264755060141904
Validation loss: 3.038023369929556

Epoch: 5| Step: 7
Training loss: 3.7565101063781645
Validation loss: 3.0375785229727708

Epoch: 5| Step: 8
Training loss: 3.434302212444526
Validation loss: 3.03624135015365

Epoch: 5| Step: 9
Training loss: 3.6415940988207907
Validation loss: 3.0349412488956795

Epoch: 5| Step: 10
Training loss: 3.1504511676606657
Validation loss: 3.035513223139108

Epoch: 108| Step: 0
Training loss: 3.358221663392474
Validation loss: 3.0374494004779384

Epoch: 5| Step: 1
Training loss: 3.9295392169619077
Validation loss: 3.036145797301333

Epoch: 5| Step: 2
Training loss: 3.38101042570387
Validation loss: 3.032163474955908

Epoch: 5| Step: 3
Training loss: 3.2675217955956137
Validation loss: 3.037051873991077

Epoch: 5| Step: 4
Training loss: 2.8012622542583494
Validation loss: 3.0358559590653384

Epoch: 5| Step: 5
Training loss: 3.338044762888942
Validation loss: 3.0362783010773438

Epoch: 5| Step: 6
Training loss: 2.686126357934603
Validation loss: 3.036484920923047

Epoch: 5| Step: 7
Training loss: 2.7240224992380258
Validation loss: 3.035515421500198

Epoch: 5| Step: 8
Training loss: 4.040982585051011
Validation loss: 3.0435376421721907

Epoch: 5| Step: 9
Training loss: 3.6812583988009693
Validation loss: 3.0397658581891807

Epoch: 5| Step: 10
Training loss: 2.680362182740247
Validation loss: 3.0378336037363205

Epoch: 109| Step: 0
Training loss: 3.3036263568096973
Validation loss: 3.0354009365408112

Epoch: 5| Step: 1
Training loss: 2.409901313344049
Validation loss: 3.0388309213273814

Epoch: 5| Step: 2
Training loss: 3.3130332949341583
Validation loss: 3.037570616603751

Epoch: 5| Step: 3
Training loss: 2.972207234741959
Validation loss: 3.0334434949940126

Epoch: 5| Step: 4
Training loss: 3.55669666562453
Validation loss: 3.0328140139682316

Epoch: 5| Step: 5
Training loss: 3.5803929766420195
Validation loss: 3.0330838862743605

Epoch: 5| Step: 6
Training loss: 2.829606653382447
Validation loss: 3.0340140430727525

Epoch: 5| Step: 7
Training loss: 3.791795637571267
Validation loss: 3.0310494115826483

Epoch: 5| Step: 8
Training loss: 3.1238025659944446
Validation loss: 3.0312736010481056

Epoch: 5| Step: 9
Training loss: 3.936793914943396
Validation loss: 3.033550196980462

Epoch: 5| Step: 10
Training loss: 3.21023366226211
Validation loss: 3.0318710693941617

Epoch: 110| Step: 0
Training loss: 3.620522331574572
Validation loss: 3.0317676906840454

Epoch: 5| Step: 1
Training loss: 2.950217132336142
Validation loss: 3.0310742219754903

Epoch: 5| Step: 2
Training loss: 3.107745026114412
Validation loss: 3.03041107337975

Epoch: 5| Step: 3
Training loss: 3.1594809434222175
Validation loss: 3.026452340348208

Epoch: 5| Step: 4
Training loss: 2.9015869139597896
Validation loss: 3.026718885363314

Epoch: 5| Step: 5
Training loss: 3.3279840143993566
Validation loss: 3.0269242885320238

Epoch: 5| Step: 6
Training loss: 3.554057239369925
Validation loss: 3.0293945496475865

Epoch: 5| Step: 7
Training loss: 2.576832950386815
Validation loss: 3.027670115312593

Epoch: 5| Step: 8
Training loss: 3.553477188142334
Validation loss: 3.0277772002608305

Epoch: 5| Step: 9
Training loss: 3.4186832400538654
Validation loss: 3.028133642147771

Epoch: 5| Step: 10
Training loss: 4.005696769996349
Validation loss: 3.028069094411232

Epoch: 111| Step: 0
Training loss: 2.887596399588929
Validation loss: 3.0282743408116044

Epoch: 5| Step: 1
Training loss: 3.293260952801504
Validation loss: 3.027638372665514

Epoch: 5| Step: 2
Training loss: 3.450718520157633
Validation loss: 3.0283129593116658

Epoch: 5| Step: 3
Training loss: 3.108348427770814
Validation loss: 3.029245880978383

Epoch: 5| Step: 4
Training loss: 2.691414931328978
Validation loss: 3.029154303526436

Epoch: 5| Step: 5
Training loss: 3.7264199539528247
Validation loss: 3.0277618460342524

Epoch: 5| Step: 6
Training loss: 3.6959373800661997
Validation loss: 3.026867664597916

Epoch: 5| Step: 7
Training loss: 3.7338838773057876
Validation loss: 3.0279669413902366

Epoch: 5| Step: 8
Training loss: 3.0972958676221674
Validation loss: 3.0276381203352

Epoch: 5| Step: 9
Training loss: 3.3214999599959247
Validation loss: 3.0277342092462574

Epoch: 5| Step: 10
Training loss: 3.02809025574269
Validation loss: 3.0258646484659266

Epoch: 112| Step: 0
Training loss: 3.0325932623476604
Validation loss: 3.0284645874844096

Epoch: 5| Step: 1
Training loss: 3.317182146841609
Validation loss: 3.0297256415624503

Epoch: 5| Step: 2
Training loss: 3.67502228606856
Validation loss: 3.029423238406425

Epoch: 5| Step: 3
Training loss: 2.8039724984663743
Validation loss: 3.0270369319135675

Epoch: 5| Step: 4
Training loss: 3.30656621390728
Validation loss: 3.029904583598545

Epoch: 5| Step: 5
Training loss: 3.6450631917700784
Validation loss: 3.030724831256567

Epoch: 5| Step: 6
Training loss: 3.4170157711657563
Validation loss: 3.034354826016935

Epoch: 5| Step: 7
Training loss: 3.5782810493656743
Validation loss: 3.026575855326438

Epoch: 5| Step: 8
Training loss: 3.263332894948346
Validation loss: 3.0229437568182127

Epoch: 5| Step: 9
Training loss: 2.5582251829302223
Validation loss: 3.0256796084706927

Epoch: 5| Step: 10
Training loss: 3.5091984990642753
Validation loss: 3.0226718307967686

Epoch: 113| Step: 0
Training loss: 2.6068045924868715
Validation loss: 3.026791242289326

Epoch: 5| Step: 1
Training loss: 3.1686530826351538
Validation loss: 3.02338173501564

Epoch: 5| Step: 2
Training loss: 3.666729897618564
Validation loss: 3.0273127508412236

Epoch: 5| Step: 3
Training loss: 3.341451122026344
Validation loss: 3.027071766989006

Epoch: 5| Step: 4
Training loss: 3.353641603177578
Validation loss: 3.025629436378848

Epoch: 5| Step: 5
Training loss: 3.5373940819293996
Validation loss: 3.0258967672524473

Epoch: 5| Step: 6
Training loss: 3.564910742242881
Validation loss: 3.023088427470714

Epoch: 5| Step: 7
Training loss: 3.1461323139184927
Validation loss: 3.022179377448898

Epoch: 5| Step: 8
Training loss: 3.130007889222754
Validation loss: 3.0224167580168517

Epoch: 5| Step: 9
Training loss: 3.6171910592838183
Validation loss: 3.022089328272969

Epoch: 5| Step: 10
Training loss: 2.9810232144193756
Validation loss: 3.022535898476236

Epoch: 114| Step: 0
Training loss: 2.536194105439548
Validation loss: 3.0228226088800922

Epoch: 5| Step: 1
Training loss: 2.8843662447812
Validation loss: 3.025130073058026

Epoch: 5| Step: 2
Training loss: 3.737139456719501
Validation loss: 3.0240927068926977

Epoch: 5| Step: 3
Training loss: 3.1818105747082424
Validation loss: 3.0232232139152835

Epoch: 5| Step: 4
Training loss: 3.226646440721073
Validation loss: 3.0248025844493256

Epoch: 5| Step: 5
Training loss: 3.747309164388594
Validation loss: 3.021544597145505

Epoch: 5| Step: 6
Training loss: 3.654363422613593
Validation loss: 3.021639418841044

Epoch: 5| Step: 7
Training loss: 4.079477137179293
Validation loss: 3.0210988206364022

Epoch: 5| Step: 8
Training loss: 2.864537316155007
Validation loss: 3.0203622152888068

Epoch: 5| Step: 9
Training loss: 2.8657442457042657
Validation loss: 3.022036957124254

Epoch: 5| Step: 10
Training loss: 3.0471339971551386
Validation loss: 3.020756746763276

Epoch: 115| Step: 0
Training loss: 2.831307659446243
Validation loss: 3.0223779759631033

Epoch: 5| Step: 1
Training loss: 3.1503490012458744
Validation loss: 3.024336194793105

Epoch: 5| Step: 2
Training loss: 4.124057315269033
Validation loss: 3.024011487341302

Epoch: 5| Step: 3
Training loss: 3.2937429294112173
Validation loss: 3.022605786474147

Epoch: 5| Step: 4
Training loss: 2.9322558728885437
Validation loss: 3.0240027028234655

Epoch: 5| Step: 5
Training loss: 2.7968195904405717
Validation loss: 3.0234897561631824

Epoch: 5| Step: 6
Training loss: 3.7111546503077686
Validation loss: 3.024087713707213

Epoch: 5| Step: 7
Training loss: 3.1588630057659635
Validation loss: 3.0218810870173582

Epoch: 5| Step: 8
Training loss: 3.2475391755006027
Validation loss: 3.020327177206708

Epoch: 5| Step: 9
Training loss: 3.488919566020286
Validation loss: 3.017749495179562

Epoch: 5| Step: 10
Training loss: 3.202096615831818
Validation loss: 3.017961845793439

Epoch: 116| Step: 0
Training loss: 3.1298835742491273
Validation loss: 3.018119516061718

Epoch: 5| Step: 1
Training loss: 3.475496072831979
Validation loss: 3.0173545730435465

Epoch: 5| Step: 2
Training loss: 3.2741873162339243
Validation loss: 3.0175089641986763

Epoch: 5| Step: 3
Training loss: 3.62544576600703
Validation loss: 3.0167763142524042

Epoch: 5| Step: 4
Training loss: 3.493410446781571
Validation loss: 3.0179894361578903

Epoch: 5| Step: 5
Training loss: 3.441197989805513
Validation loss: 3.0172695075503664

Epoch: 5| Step: 6
Training loss: 2.739216817457277
Validation loss: 3.017820441216569

Epoch: 5| Step: 7
Training loss: 3.1528607290804236
Validation loss: 3.0156478247633367

Epoch: 5| Step: 8
Training loss: 3.0200337020307186
Validation loss: 3.0188066846173904

Epoch: 5| Step: 9
Training loss: 3.4539280298595134
Validation loss: 3.0168179929971815

Epoch: 5| Step: 10
Training loss: 3.251303778074915
Validation loss: 3.0166507077263787

Epoch: 117| Step: 0
Training loss: 3.149093824561846
Validation loss: 3.018116533758774

Epoch: 5| Step: 1
Training loss: 3.5823187759466633
Validation loss: 3.01492988965429

Epoch: 5| Step: 2
Training loss: 3.0206565191328174
Validation loss: 3.0175620443163416

Epoch: 5| Step: 3
Training loss: 3.308543883829499
Validation loss: 3.019400662048035

Epoch: 5| Step: 4
Training loss: 3.210933044876015
Validation loss: 3.0203133384103706

Epoch: 5| Step: 5
Training loss: 2.546206427507061
Validation loss: 3.018487504193211

Epoch: 5| Step: 6
Training loss: 3.346050576219398
Validation loss: 3.021241288578649

Epoch: 5| Step: 7
Training loss: 3.0713699499980422
Validation loss: 3.022158158611772

Epoch: 5| Step: 8
Training loss: 3.5490702418956404
Validation loss: 3.0276267315793355

Epoch: 5| Step: 9
Training loss: 3.720752209116854
Validation loss: 3.0231792473945234

Epoch: 5| Step: 10
Training loss: 3.5047926105956875
Validation loss: 3.0238598766490323

Epoch: 118| Step: 0
Training loss: 3.1177389092204137
Validation loss: 3.0175865764999354

Epoch: 5| Step: 1
Training loss: 3.803394889188535
Validation loss: 3.017026723072539

Epoch: 5| Step: 2
Training loss: 3.6915488563724
Validation loss: 3.0134966454702896

Epoch: 5| Step: 3
Training loss: 2.916621416739997
Validation loss: 3.019963388634652

Epoch: 5| Step: 4
Training loss: 2.385302533968878
Validation loss: 3.0144235193072126

Epoch: 5| Step: 5
Training loss: 3.0757664973472245
Validation loss: 3.011027841274692

Epoch: 5| Step: 6
Training loss: 3.453860657638465
Validation loss: 3.0138247263374556

Epoch: 5| Step: 7
Training loss: 3.0271192898138626
Validation loss: 3.0126167461961644

Epoch: 5| Step: 8
Training loss: 3.3508075139409903
Validation loss: 3.0180982916160137

Epoch: 5| Step: 9
Training loss: 3.4533079625330605
Validation loss: 3.012719680087404

Epoch: 5| Step: 10
Training loss: 3.6334503598279673
Validation loss: 3.011453128996818

Epoch: 119| Step: 0
Training loss: 2.78537375950393
Validation loss: 3.0165475782285527

Epoch: 5| Step: 1
Training loss: 3.3465484602317783
Validation loss: 3.021232497703281

Epoch: 5| Step: 2
Training loss: 3.4550121553375575
Validation loss: 3.01686837196151

Epoch: 5| Step: 3
Training loss: 2.679528946259087
Validation loss: 3.017760622181055

Epoch: 5| Step: 4
Training loss: 3.637196379374673
Validation loss: 3.010621556782544

Epoch: 5| Step: 5
Training loss: 3.4750132334066115
Validation loss: 3.0108823680380628

Epoch: 5| Step: 6
Training loss: 3.643421588839732
Validation loss: 3.0090580198594195

Epoch: 5| Step: 7
Training loss: 3.0946447446485768
Validation loss: 3.0121681990242553

Epoch: 5| Step: 8
Training loss: 3.0581718533854287
Validation loss: 3.009513264395618

Epoch: 5| Step: 9
Training loss: 3.1170917391110224
Validation loss: 3.010630445060578

Epoch: 5| Step: 10
Training loss: 3.753659306718974
Validation loss: 3.010340670954069

Epoch: 120| Step: 0
Training loss: 3.448154929112254
Validation loss: 3.011969121376204

Epoch: 5| Step: 1
Training loss: 3.2387055969139036
Validation loss: 3.010251468440925

Epoch: 5| Step: 2
Training loss: 3.647386942857214
Validation loss: 3.010424444511668

Epoch: 5| Step: 3
Training loss: 3.7331902448163152
Validation loss: 3.0108232813644134

Epoch: 5| Step: 4
Training loss: 3.5883968122873595
Validation loss: 3.011101578202417

Epoch: 5| Step: 5
Training loss: 2.841355541868637
Validation loss: 3.013447194436128

Epoch: 5| Step: 6
Training loss: 2.532324574637354
Validation loss: 3.010915656465831

Epoch: 5| Step: 7
Training loss: 2.412109078472907
Validation loss: 3.01231051062527

Epoch: 5| Step: 8
Training loss: 3.1587831510699496
Validation loss: 3.007569462695471

Epoch: 5| Step: 9
Training loss: 3.3588120099651504
Validation loss: 3.0126783360820513

Epoch: 5| Step: 10
Training loss: 3.877158271493057
Validation loss: 3.0068051984074127

Epoch: 121| Step: 0
Training loss: 3.466142791509786
Validation loss: 3.0080291810632986

Epoch: 5| Step: 1
Training loss: 3.5267467310373752
Validation loss: 3.0077100919867292

Epoch: 5| Step: 2
Training loss: 3.1703082946177905
Validation loss: 3.0071445609335914

Epoch: 5| Step: 3
Training loss: 3.4540475847051133
Validation loss: 3.0054472874859544

Epoch: 5| Step: 4
Training loss: 2.865141010908562
Validation loss: 3.007598827599537

Epoch: 5| Step: 5
Training loss: 2.8127402308969716
Validation loss: 3.00547655029414

Epoch: 5| Step: 6
Training loss: 3.43513185250817
Validation loss: 3.0070276360097132

Epoch: 5| Step: 7
Training loss: 3.6094785733245547
Validation loss: 3.0042771020711716

Epoch: 5| Step: 8
Training loss: 3.7239270758039504
Validation loss: 3.0068817799675602

Epoch: 5| Step: 9
Training loss: 2.670358774175973
Validation loss: 3.004353901668515

Epoch: 5| Step: 10
Training loss: 3.116524303129149
Validation loss: 3.005752921613956

Epoch: 122| Step: 0
Training loss: 2.882600440519396
Validation loss: 3.0061178482662245

Epoch: 5| Step: 1
Training loss: 3.129840916012489
Validation loss: 3.006941191338629

Epoch: 5| Step: 2
Training loss: 3.1391267001857917
Validation loss: 3.0073216234171674

Epoch: 5| Step: 3
Training loss: 3.2088234432123985
Validation loss: 3.0043864261981605

Epoch: 5| Step: 4
Training loss: 3.078227549747169
Validation loss: 3.008865104502231

Epoch: 5| Step: 5
Training loss: 4.223688244759077
Validation loss: 3.0086664524713562

Epoch: 5| Step: 6
Training loss: 2.8750210636860007
Validation loss: 3.0118568933190693

Epoch: 5| Step: 7
Training loss: 3.4013084474453485
Validation loss: 3.011076199675618

Epoch: 5| Step: 8
Training loss: 3.417612007052514
Validation loss: 3.0141404046984457

Epoch: 5| Step: 9
Training loss: 2.9404546609284887
Validation loss: 3.0116263058944632

Epoch: 5| Step: 10
Training loss: 3.5573102392975002
Validation loss: 3.0038428860030444

Epoch: 123| Step: 0
Training loss: 2.995828589451995
Validation loss: 3.0032535073514546

Epoch: 5| Step: 1
Training loss: 3.499716066015157
Validation loss: 3.003038187362043

Epoch: 5| Step: 2
Training loss: 2.7382539102928143
Validation loss: 3.005345141794254

Epoch: 5| Step: 3
Training loss: 3.4042178750515237
Validation loss: 3.00551099894001

Epoch: 5| Step: 4
Training loss: 3.255659897064871
Validation loss: 3.0042832264163843

Epoch: 5| Step: 5
Training loss: 3.489252892786204
Validation loss: 3.0026814720881134

Epoch: 5| Step: 6
Training loss: 3.362573564710277
Validation loss: 3.003527302382867

Epoch: 5| Step: 7
Training loss: 3.5872550322470573
Validation loss: 3.0002635537533315

Epoch: 5| Step: 8
Training loss: 3.1471686823765945
Validation loss: 3.0012569460487546

Epoch: 5| Step: 9
Training loss: 3.6025173551629823
Validation loss: 3.0003245974530577

Epoch: 5| Step: 10
Training loss: 2.7362720992937253
Validation loss: 3.0028307456353955

Epoch: 124| Step: 0
Training loss: 2.8214815628014507
Validation loss: 2.9995703799764817

Epoch: 5| Step: 1
Training loss: 2.8851023111432563
Validation loss: 3.0015672004956158

Epoch: 5| Step: 2
Training loss: 3.8912468225629744
Validation loss: 2.9998834016489413

Epoch: 5| Step: 3
Training loss: 3.9406173718081403
Validation loss: 3.0013600038892045

Epoch: 5| Step: 4
Training loss: 2.9013441785312826
Validation loss: 3.000954558163675

Epoch: 5| Step: 5
Training loss: 2.6880085486151226
Validation loss: 3.0012818224915754

Epoch: 5| Step: 6
Training loss: 3.998675365461008
Validation loss: 3.000053906041879

Epoch: 5| Step: 7
Training loss: 2.886482528498848
Validation loss: 2.9988952075680375

Epoch: 5| Step: 8
Training loss: 2.9119112393821416
Validation loss: 3.0002362951242265

Epoch: 5| Step: 9
Training loss: 3.5073867233593257
Validation loss: 2.998185649969638

Epoch: 5| Step: 10
Training loss: 3.182085412433407
Validation loss: 2.9969029488755643

Epoch: 125| Step: 0
Training loss: 3.8097596873191453
Validation loss: 2.99957172949896

Epoch: 5| Step: 1
Training loss: 2.9103815388362952
Validation loss: 3.00339978884101

Epoch: 5| Step: 2
Training loss: 3.5664701591857324
Validation loss: 3.0091527698572507

Epoch: 5| Step: 3
Training loss: 3.315567180046701
Validation loss: 2.998005093492518

Epoch: 5| Step: 4
Training loss: 3.1095999631539692
Validation loss: 2.996755985822973

Epoch: 5| Step: 5
Training loss: 3.0492450592759113
Validation loss: 2.9975060946338874

Epoch: 5| Step: 6
Training loss: 3.883524470612072
Validation loss: 2.9988717620395846

Epoch: 5| Step: 7
Training loss: 3.365746988761692
Validation loss: 2.998198438279653

Epoch: 5| Step: 8
Training loss: 2.544004542856539
Validation loss: 3.000655719576857

Epoch: 5| Step: 9
Training loss: 3.084830942823412
Validation loss: 3.0012483306862494

Epoch: 5| Step: 10
Training loss: 3.1165879516725106
Validation loss: 2.9996011889362078

Epoch: 126| Step: 0
Training loss: 3.77568956860132
Validation loss: 3.000867625874424

Epoch: 5| Step: 1
Training loss: 3.275313465754109
Validation loss: 2.996925436334562

Epoch: 5| Step: 2
Training loss: 3.186830487715668
Validation loss: 2.997810300831259

Epoch: 5| Step: 3
Training loss: 2.954540902247623
Validation loss: 2.99542464420166

Epoch: 5| Step: 4
Training loss: 3.2289895450048283
Validation loss: 2.9972771658636677

Epoch: 5| Step: 5
Training loss: 3.380457950695571
Validation loss: 3.0014249329874807

Epoch: 5| Step: 6
Training loss: 3.7096749496986763
Validation loss: 3.0006225445892976

Epoch: 5| Step: 7
Training loss: 2.6504952417808414
Validation loss: 3.0058640283156532

Epoch: 5| Step: 8
Training loss: 3.2538883717058367
Validation loss: 3.0084728456317427

Epoch: 5| Step: 9
Training loss: 3.3907742093915227
Validation loss: 3.0118209706392105

Epoch: 5| Step: 10
Training loss: 2.9992596984436837
Validation loss: 3.0073303236766527

Epoch: 127| Step: 0
Training loss: 3.8140213229258957
Validation loss: 3.0097547776363203

Epoch: 5| Step: 1
Training loss: 3.372481077238686
Validation loss: 3.006959982016419

Epoch: 5| Step: 2
Training loss: 3.285061901792476
Validation loss: 2.9987154743499027

Epoch: 5| Step: 3
Training loss: 3.2796643013245004
Validation loss: 2.9990339210572166

Epoch: 5| Step: 4
Training loss: 3.5988644239407988
Validation loss: 2.9977520430189584

Epoch: 5| Step: 5
Training loss: 3.4312908621823355
Validation loss: 2.9965461602981533

Epoch: 5| Step: 6
Training loss: 2.168924426888974
Validation loss: 2.9965836469020943

Epoch: 5| Step: 7
Training loss: 3.4456028545629094
Validation loss: 2.995645247376482

Epoch: 5| Step: 8
Training loss: 2.544158516587682
Validation loss: 2.997594739089404

Epoch: 5| Step: 9
Training loss: 3.6270396315242355
Validation loss: 2.997988161302615

Epoch: 5| Step: 10
Training loss: 3.0508547101230947
Validation loss: 2.9991273157618585

Epoch: 128| Step: 0
Training loss: 3.2292055845479073
Validation loss: 2.9965686812335512

Epoch: 5| Step: 1
Training loss: 3.2512923385520933
Validation loss: 2.999033507323266

Epoch: 5| Step: 2
Training loss: 3.471740807962325
Validation loss: 2.994832566219649

Epoch: 5| Step: 3
Training loss: 3.054468015312549
Validation loss: 2.994186727766895

Epoch: 5| Step: 4
Training loss: 3.4140285603737066
Validation loss: 2.9980825890436757

Epoch: 5| Step: 5
Training loss: 3.0764800192886077
Validation loss: 2.995878509295421

Epoch: 5| Step: 6
Training loss: 2.9651314617173576
Validation loss: 2.9923765455366444

Epoch: 5| Step: 7
Training loss: 3.2678962365699866
Validation loss: 2.993640611182781

Epoch: 5| Step: 8
Training loss: 2.87290463591434
Validation loss: 2.9956510393517046

Epoch: 5| Step: 9
Training loss: 3.5419697052205565
Validation loss: 3.0030409174368917

Epoch: 5| Step: 10
Training loss: 3.7529658986592223
Validation loss: 3.004512648689143

Epoch: 129| Step: 0
Training loss: 3.9035502144891865
Validation loss: 3.010277412589641

Epoch: 5| Step: 1
Training loss: 2.923780014060168
Validation loss: 3.008740974081893

Epoch: 5| Step: 2
Training loss: 3.3071594372045054
Validation loss: 3.0132790711846322

Epoch: 5| Step: 3
Training loss: 3.3739622427970817
Validation loss: 2.9976389850748055

Epoch: 5| Step: 4
Training loss: 2.7712009922179983
Validation loss: 2.9974369496597695

Epoch: 5| Step: 5
Training loss: 2.9427577911991967
Validation loss: 2.9939848695423477

Epoch: 5| Step: 6
Training loss: 3.314532681950691
Validation loss: 2.9940895373904692

Epoch: 5| Step: 7
Training loss: 3.4510520823596234
Validation loss: 2.9921926149607145

Epoch: 5| Step: 8
Training loss: 3.4312512562789426
Validation loss: 2.993790554734717

Epoch: 5| Step: 9
Training loss: 3.172705480535996
Validation loss: 2.992825561990116

Epoch: 5| Step: 10
Training loss: 3.1744616254781377
Validation loss: 2.9920743945890895

Epoch: 130| Step: 0
Training loss: 3.0244779152022088
Validation loss: 2.9898134148533235

Epoch: 5| Step: 1
Training loss: 3.132663637653236
Validation loss: 2.990993531748531

Epoch: 5| Step: 2
Training loss: 3.715860478388368
Validation loss: 2.9905959061665492

Epoch: 5| Step: 3
Training loss: 3.0157292007074363
Validation loss: 2.991542804434603

Epoch: 5| Step: 4
Training loss: 3.213392372723359
Validation loss: 2.9916616011027193

Epoch: 5| Step: 5
Training loss: 2.974134521253653
Validation loss: 2.9925621258928925

Epoch: 5| Step: 6
Training loss: 3.5631822970015214
Validation loss: 2.9929932392705765

Epoch: 5| Step: 7
Training loss: 3.2133417711371393
Validation loss: 2.98881989793981

Epoch: 5| Step: 8
Training loss: 3.0520529544780963
Validation loss: 2.9874415586850414

Epoch: 5| Step: 9
Training loss: 3.4019140241502224
Validation loss: 2.987687293894073

Epoch: 5| Step: 10
Training loss: 3.523441424653094
Validation loss: 2.9894641559335713

Epoch: 131| Step: 0
Training loss: 3.018632407099595
Validation loss: 2.988589293299439

Epoch: 5| Step: 1
Training loss: 2.9236906397723215
Validation loss: 2.9888284393366966

Epoch: 5| Step: 2
Training loss: 2.650625489749157
Validation loss: 2.9869553283523484

Epoch: 5| Step: 3
Training loss: 3.5532961627192177
Validation loss: 2.985476807093729

Epoch: 5| Step: 4
Training loss: 3.4906499494653067
Validation loss: 2.9880010602320195

Epoch: 5| Step: 5
Training loss: 3.1918387709414553
Validation loss: 2.989049050752354

Epoch: 5| Step: 6
Training loss: 3.494318301362277
Validation loss: 2.9874776415031783

Epoch: 5| Step: 7
Training loss: 3.8690517671444073
Validation loss: 2.9866412161018854

Epoch: 5| Step: 8
Training loss: 2.7923574779071227
Validation loss: 2.9869720630268217

Epoch: 5| Step: 9
Training loss: 2.742871321488246
Validation loss: 2.9890055678933876

Epoch: 5| Step: 10
Training loss: 3.9217608309842014
Validation loss: 2.9903168103120734

Epoch: 132| Step: 0
Training loss: 3.109205691841517
Validation loss: 2.9973932343930683

Epoch: 5| Step: 1
Training loss: 3.2932079585788787
Validation loss: 2.9967425360630626

Epoch: 5| Step: 2
Training loss: 3.311586505960912
Validation loss: 2.9890063483913223

Epoch: 5| Step: 3
Training loss: 4.035498930421323
Validation loss: 2.9864274402018913

Epoch: 5| Step: 4
Training loss: 2.765823788152784
Validation loss: 2.985232162627864

Epoch: 5| Step: 5
Training loss: 3.0274147862129435
Validation loss: 2.9850258169385353

Epoch: 5| Step: 6
Training loss: 2.677367693769229
Validation loss: 2.9827119548518954

Epoch: 5| Step: 7
Training loss: 3.3184047828338206
Validation loss: 2.9875437561639493

Epoch: 5| Step: 8
Training loss: 3.835905677057408
Validation loss: 2.983138789780987

Epoch: 5| Step: 9
Training loss: 2.8888517972407133
Validation loss: 2.9853226803597304

Epoch: 5| Step: 10
Training loss: 3.3274069714457064
Validation loss: 2.982934989316409

Epoch: 133| Step: 0
Training loss: 3.555258769987049
Validation loss: 2.990429508979654

Epoch: 5| Step: 1
Training loss: 3.382915539306523
Validation loss: 2.9847678473734423

Epoch: 5| Step: 2
Training loss: 3.0656815176604058
Validation loss: 2.9850500282199426

Epoch: 5| Step: 3
Training loss: 2.810332162169599
Validation loss: 2.9847922608712887

Epoch: 5| Step: 4
Training loss: 3.361465158722557
Validation loss: 2.9845741212846213

Epoch: 5| Step: 5
Training loss: 3.9586694005886294
Validation loss: 2.9833414600688077

Epoch: 5| Step: 6
Training loss: 3.1862846002088125
Validation loss: 2.981283916620043

Epoch: 5| Step: 7
Training loss: 3.036818433361565
Validation loss: 2.981370336483725

Epoch: 5| Step: 8
Training loss: 3.3319005907028023
Validation loss: 2.9823805579732685

Epoch: 5| Step: 9
Training loss: 2.967156233379235
Validation loss: 2.988871924772574

Epoch: 5| Step: 10
Training loss: 3.015326766847046
Validation loss: 2.9846187527013748

Epoch: 134| Step: 0
Training loss: 3.261833654880987
Validation loss: 2.9856707510962357

Epoch: 5| Step: 1
Training loss: 3.899091096262451
Validation loss: 2.9857913372058102

Epoch: 5| Step: 2
Training loss: 3.736635681032947
Validation loss: 2.989231040983639

Epoch: 5| Step: 3
Training loss: 2.873973331409977
Validation loss: 2.983684672776243

Epoch: 5| Step: 4
Training loss: 3.0685402606214387
Validation loss: 2.9842563531045676

Epoch: 5| Step: 5
Training loss: 3.541293823962061
Validation loss: 2.978474076477354

Epoch: 5| Step: 6
Training loss: 2.9479696495947243
Validation loss: 2.982998185527739

Epoch: 5| Step: 7
Training loss: 2.5678565631868073
Validation loss: 2.979368190258487

Epoch: 5| Step: 8
Training loss: 3.606910293398496
Validation loss: 2.981754242569258

Epoch: 5| Step: 9
Training loss: 2.870948092340503
Validation loss: 2.980698949937523

Epoch: 5| Step: 10
Training loss: 3.1788889939089886
Validation loss: 2.9795671565712287

Epoch: 135| Step: 0
Training loss: 3.034432539703708
Validation loss: 2.9766099300690785

Epoch: 5| Step: 1
Training loss: 3.315494263684438
Validation loss: 2.9806959697575746

Epoch: 5| Step: 2
Training loss: 3.667827566921453
Validation loss: 2.9835851923799463

Epoch: 5| Step: 3
Training loss: 3.0761447481442814
Validation loss: 2.979725851847205

Epoch: 5| Step: 4
Training loss: 3.3186195994475476
Validation loss: 2.9847066289451267

Epoch: 5| Step: 5
Training loss: 3.48368192203116
Validation loss: 2.983082025676374

Epoch: 5| Step: 6
Training loss: 3.5356148269558214
Validation loss: 2.9828052142904014

Epoch: 5| Step: 7
Training loss: 2.2484343697722955
Validation loss: 2.9762278704542733

Epoch: 5| Step: 8
Training loss: 3.1227691316947723
Validation loss: 2.975472933373155

Epoch: 5| Step: 9
Training loss: 3.6363253764827403
Validation loss: 2.9756435665737877

Epoch: 5| Step: 10
Training loss: 3.086925956705573
Validation loss: 2.9742057715602925

Epoch: 136| Step: 0
Training loss: 3.099569838427354
Validation loss: 2.9736230428931805

Epoch: 5| Step: 1
Training loss: 3.708837424888086
Validation loss: 2.973769193963211

Epoch: 5| Step: 2
Training loss: 3.0504614434049473
Validation loss: 2.974780771297694

Epoch: 5| Step: 3
Training loss: 2.924282285880111
Validation loss: 2.9741758321583625

Epoch: 5| Step: 4
Training loss: 2.850399919525839
Validation loss: 2.9724334128335426

Epoch: 5| Step: 5
Training loss: 3.0608137509780415
Validation loss: 2.9753025101050232

Epoch: 5| Step: 6
Training loss: 3.4069621890214568
Validation loss: 2.9740495754866907

Epoch: 5| Step: 7
Training loss: 3.6123533964933756
Validation loss: 2.9732190382669033

Epoch: 5| Step: 8
Training loss: 3.6194362694612274
Validation loss: 2.973318203309519

Epoch: 5| Step: 9
Training loss: 3.450749197066795
Validation loss: 2.9735445796821045

Epoch: 5| Step: 10
Training loss: 2.7478631126925137
Validation loss: 2.9733202795233895

Epoch: 137| Step: 0
Training loss: 2.8561055820941452
Validation loss: 2.9761399971098803

Epoch: 5| Step: 1
Training loss: 3.14208070031935
Validation loss: 2.977054077239831

Epoch: 5| Step: 2
Training loss: 2.8072474280972446
Validation loss: 2.9759582900202846

Epoch: 5| Step: 3
Training loss: 2.6606126749417682
Validation loss: 2.975491523002032

Epoch: 5| Step: 4
Training loss: 3.2570183607081105
Validation loss: 2.97154615032086

Epoch: 5| Step: 5
Training loss: 3.7037690322907104
Validation loss: 2.9718682087847323

Epoch: 5| Step: 6
Training loss: 3.932005181729229
Validation loss: 2.9705677816476492

Epoch: 5| Step: 7
Training loss: 3.5291305528134362
Validation loss: 2.9688068308893065

Epoch: 5| Step: 8
Training loss: 3.3646888047133685
Validation loss: 2.969931287470951

Epoch: 5| Step: 9
Training loss: 3.1261750110294466
Validation loss: 2.970265340367294

Epoch: 5| Step: 10
Training loss: 3.1105741555946893
Validation loss: 2.972688321031986

Epoch: 138| Step: 0
Training loss: 2.5284987202890608
Validation loss: 2.96904060396511

Epoch: 5| Step: 1
Training loss: 3.517209115760571
Validation loss: 2.9721589632930794

Epoch: 5| Step: 2
Training loss: 3.3959318899506923
Validation loss: 2.9685686678900853

Epoch: 5| Step: 3
Training loss: 2.8375224578909757
Validation loss: 2.969342753846334

Epoch: 5| Step: 4
Training loss: 3.194530437989014
Validation loss: 2.978525165103486

Epoch: 5| Step: 5
Training loss: 3.517863192701774
Validation loss: 2.977852015329309

Epoch: 5| Step: 6
Training loss: 3.1831747891022375
Validation loss: 2.978660077176766

Epoch: 5| Step: 7
Training loss: 2.688046155924979
Validation loss: 2.9712446593658792

Epoch: 5| Step: 8
Training loss: 3.599052431649436
Validation loss: 2.977889541838553

Epoch: 5| Step: 9
Training loss: 3.8319513621737724
Validation loss: 2.967623317975395

Epoch: 5| Step: 10
Training loss: 3.179999108944174
Validation loss: 2.9602383850950535

Epoch: 139| Step: 0
Training loss: 3.2087683114456995
Validation loss: 2.961843132778922

Epoch: 5| Step: 1
Training loss: 3.1171793925626865
Validation loss: 2.9619264292399388

Epoch: 5| Step: 2
Training loss: 3.185771847656361
Validation loss: 2.962323677233303

Epoch: 5| Step: 3
Training loss: 3.434047005066735
Validation loss: 2.963479784259177

Epoch: 5| Step: 4
Training loss: 2.9227949519972998
Validation loss: 2.9596668707302043

Epoch: 5| Step: 5
Training loss: 3.1593671457134533
Validation loss: 2.9588000235482266

Epoch: 5| Step: 6
Training loss: 3.8437179936262713
Validation loss: 2.9580006935973957

Epoch: 5| Step: 7
Training loss: 3.2726604112865942
Validation loss: 2.9595222758839905

Epoch: 5| Step: 8
Training loss: 3.3750356036533504
Validation loss: 2.9619911780784656

Epoch: 5| Step: 9
Training loss: 3.0275948106581922
Validation loss: 2.963619207302083

Epoch: 5| Step: 10
Training loss: 2.939524663010297
Validation loss: 2.9625791602191542

Epoch: 140| Step: 0
Training loss: 3.1100665526306654
Validation loss: 2.961796008081606

Epoch: 5| Step: 1
Training loss: 3.3652714989065204
Validation loss: 2.968590990869623

Epoch: 5| Step: 2
Training loss: 2.9534572838231745
Validation loss: 2.967306010214192

Epoch: 5| Step: 3
Training loss: 3.217849901879799
Validation loss: 2.9762571156273596

Epoch: 5| Step: 4
Training loss: 2.8808184915001567
Validation loss: 2.9624122606982333

Epoch: 5| Step: 5
Training loss: 3.541901853643707
Validation loss: 2.959078300807752

Epoch: 5| Step: 6
Training loss: 3.1327243706919146
Validation loss: 2.956588955873121

Epoch: 5| Step: 7
Training loss: 3.052169347251918
Validation loss: 2.952013895224909

Epoch: 5| Step: 8
Training loss: 3.2767560429638483
Validation loss: 2.953055117964656

Epoch: 5| Step: 9
Training loss: 3.3538410826438088
Validation loss: 2.953735777147369

Epoch: 5| Step: 10
Training loss: 3.678164156670489
Validation loss: 2.9545891300825238

Epoch: 141| Step: 0
Training loss: 3.807945031891317
Validation loss: 2.9531236622404693

Epoch: 5| Step: 1
Training loss: 3.4507519607389137
Validation loss: 2.94885316487219

Epoch: 5| Step: 2
Training loss: 3.14609230103991
Validation loss: 2.952842293028422

Epoch: 5| Step: 3
Training loss: 3.476660017724657
Validation loss: 2.95173096371655

Epoch: 5| Step: 4
Training loss: 3.35814711730478
Validation loss: 2.9529651156478836

Epoch: 5| Step: 5
Training loss: 3.1423367063208096
Validation loss: 2.953405641779711

Epoch: 5| Step: 6
Training loss: 3.7582700454785325
Validation loss: 2.9500171033093356

Epoch: 5| Step: 7
Training loss: 2.7311913839723885
Validation loss: 2.9519014251686415

Epoch: 5| Step: 8
Training loss: 3.0508897202827816
Validation loss: 2.949338415247565

Epoch: 5| Step: 9
Training loss: 2.724209882646837
Validation loss: 2.949484458927385

Epoch: 5| Step: 10
Training loss: 2.5372389598053338
Validation loss: 2.9502649546654545

Epoch: 142| Step: 0
Training loss: 3.262320713071681
Validation loss: 2.952937207705166

Epoch: 5| Step: 1
Training loss: 3.174146919085572
Validation loss: 2.9504958750163697

Epoch: 5| Step: 2
Training loss: 2.7245148673125335
Validation loss: 2.9571461378820283

Epoch: 5| Step: 3
Training loss: 3.8846260609592638
Validation loss: 2.9555891193089177

Epoch: 5| Step: 4
Training loss: 3.3169760062977516
Validation loss: 2.959743238887809

Epoch: 5| Step: 5
Training loss: 2.428619248055645
Validation loss: 2.9589641620036713

Epoch: 5| Step: 6
Training loss: 3.2862635502875057
Validation loss: 2.9600154280724693

Epoch: 5| Step: 7
Training loss: 3.3220078392418606
Validation loss: 2.95586320967864

Epoch: 5| Step: 8
Training loss: 3.172293048237966
Validation loss: 2.9640525747863617

Epoch: 5| Step: 9
Training loss: 3.4626135631901347
Validation loss: 2.968472961037998

Epoch: 5| Step: 10
Training loss: 3.2892956141409715
Validation loss: 2.959209158818983

Epoch: 143| Step: 0
Training loss: 3.818828770500945
Validation loss: 2.9496322301783215

Epoch: 5| Step: 1
Training loss: 3.100576710124065
Validation loss: 2.9492549988273047

Epoch: 5| Step: 2
Training loss: 3.248486386473027
Validation loss: 2.947056374806525

Epoch: 5| Step: 3
Training loss: 2.8953301154896196
Validation loss: 2.9498421954076046

Epoch: 5| Step: 4
Training loss: 3.243939250504225
Validation loss: 2.9482178695962684

Epoch: 5| Step: 5
Training loss: 2.7743522747266622
Validation loss: 2.9474977788264733

Epoch: 5| Step: 6
Training loss: 3.3875045832641675
Validation loss: 2.947973943820833

Epoch: 5| Step: 7
Training loss: 3.4735566249639653
Validation loss: 2.948545035813676

Epoch: 5| Step: 8
Training loss: 2.9681015109467985
Validation loss: 2.9482245825612017

Epoch: 5| Step: 9
Training loss: 3.0304578552286277
Validation loss: 2.944382956800491

Epoch: 5| Step: 10
Training loss: 3.4587642140815036
Validation loss: 2.944219309815667

Epoch: 144| Step: 0
Training loss: 3.291061844770024
Validation loss: 2.9439414201498626

Epoch: 5| Step: 1
Training loss: 3.4754938776354427
Validation loss: 2.9453321469146903

Epoch: 5| Step: 2
Training loss: 3.300246408684089
Validation loss: 2.9434912819463763

Epoch: 5| Step: 3
Training loss: 3.3788324425193954
Validation loss: 2.9471545081896404

Epoch: 5| Step: 4
Training loss: 3.5321209938951887
Validation loss: 2.945195339972745

Epoch: 5| Step: 5
Training loss: 3.3496015454081234
Validation loss: 2.945334021772905

Epoch: 5| Step: 6
Training loss: 3.1697997271213514
Validation loss: 2.943661298256489

Epoch: 5| Step: 7
Training loss: 2.8876053167515865
Validation loss: 2.9469023117121957

Epoch: 5| Step: 8
Training loss: 2.599649453373671
Validation loss: 2.945221509017837

Epoch: 5| Step: 9
Training loss: 3.5068817603087408
Validation loss: 2.9534543803167694

Epoch: 5| Step: 10
Training loss: 2.7827839425285386
Validation loss: 2.955046274062207

Epoch: 145| Step: 0
Training loss: 2.921263605297499
Validation loss: 2.9480625923645722

Epoch: 5| Step: 1
Training loss: 3.5790787804100983
Validation loss: 2.947630761251336

Epoch: 5| Step: 2
Training loss: 3.2697265274998504
Validation loss: 2.9511317501374124

Epoch: 5| Step: 3
Training loss: 3.359382097103695
Validation loss: 2.945186708593547

Epoch: 5| Step: 4
Training loss: 3.7843138837092476
Validation loss: 2.945332298365677

Epoch: 5| Step: 5
Training loss: 2.1191306118355024
Validation loss: 2.944177614280052

Epoch: 5| Step: 6
Training loss: 3.354757426740859
Validation loss: 2.940022497578661

Epoch: 5| Step: 7
Training loss: 3.0681817424016358
Validation loss: 2.939846912199086

Epoch: 5| Step: 8
Training loss: 2.811915612437277
Validation loss: 2.949052281833634

Epoch: 5| Step: 9
Training loss: 3.4787648286822104
Validation loss: 2.952388095277637

Epoch: 5| Step: 10
Training loss: 3.430941758615728
Validation loss: 2.949677677110569

Epoch: 146| Step: 0
Training loss: 2.278717516543601
Validation loss: 2.9398883770291238

Epoch: 5| Step: 1
Training loss: 2.9239582652024136
Validation loss: 2.939894784623034

Epoch: 5| Step: 2
Training loss: 2.6612989125341535
Validation loss: 2.9417930498722114

Epoch: 5| Step: 3
Training loss: 3.226810177956018
Validation loss: 2.9414161719330116

Epoch: 5| Step: 4
Training loss: 3.0652655745632447
Validation loss: 2.9436050574780643

Epoch: 5| Step: 5
Training loss: 3.948210424332722
Validation loss: 2.946897747981279

Epoch: 5| Step: 6
Training loss: 3.545212410614765
Validation loss: 2.947505836350573

Epoch: 5| Step: 7
Training loss: 3.4021337994026757
Validation loss: 2.944470675627572

Epoch: 5| Step: 8
Training loss: 3.7869752778524868
Validation loss: 2.944168490554612

Epoch: 5| Step: 9
Training loss: 3.5951819179384077
Validation loss: 2.9447973832384

Epoch: 5| Step: 10
Training loss: 2.4761527411411715
Validation loss: 2.943273840661962

Epoch: 147| Step: 0
Training loss: 2.4081229314886774
Validation loss: 2.9406186412140856

Epoch: 5| Step: 1
Training loss: 3.5732117615369012
Validation loss: 2.938641755866993

Epoch: 5| Step: 2
Training loss: 3.091028114311935
Validation loss: 2.9387702822226003

Epoch: 5| Step: 3
Training loss: 3.489798528763846
Validation loss: 2.9385541875793586

Epoch: 5| Step: 4
Training loss: 3.1178634025499656
Validation loss: 2.9411991943516655

Epoch: 5| Step: 5
Training loss: 2.7744803174012116
Validation loss: 2.942983335291399

Epoch: 5| Step: 6
Training loss: 3.129832536647687
Validation loss: 2.9416240289091635

Epoch: 5| Step: 7
Training loss: 3.170194735156419
Validation loss: 2.946621795286294

Epoch: 5| Step: 8
Training loss: 3.734081560042027
Validation loss: 2.948100299798125

Epoch: 5| Step: 9
Training loss: 3.1645606884994777
Validation loss: 2.943205154097456

Epoch: 5| Step: 10
Training loss: 3.634564246041877
Validation loss: 2.9415402098309413

Epoch: 148| Step: 0
Training loss: 3.4644579753267575
Validation loss: 2.942307524192667

Epoch: 5| Step: 1
Training loss: 3.157505050256455
Validation loss: 2.936751513576128

Epoch: 5| Step: 2
Training loss: 2.92545560239211
Validation loss: 2.937161997154331

Epoch: 5| Step: 3
Training loss: 3.3270895336637167
Validation loss: 2.9368239711202127

Epoch: 5| Step: 4
Training loss: 3.342432778708943
Validation loss: 2.940239631748632

Epoch: 5| Step: 5
Training loss: 3.2797560424330308
Validation loss: 2.939713224034924

Epoch: 5| Step: 6
Training loss: 3.2936368108479206
Validation loss: 2.944770279780737

Epoch: 5| Step: 7
Training loss: 3.0888543745288315
Validation loss: 2.9404405159711584

Epoch: 5| Step: 8
Training loss: 3.2993811171529708
Validation loss: 2.938619050966403

Epoch: 5| Step: 9
Training loss: 3.435290788449865
Validation loss: 2.9338645370406518

Epoch: 5| Step: 10
Training loss: 2.7153014311826627
Validation loss: 2.9342976134508127

Epoch: 149| Step: 0
Training loss: 2.760652457669185
Validation loss: 2.9360899969950496

Epoch: 5| Step: 1
Training loss: 2.597297356845282
Validation loss: 2.9352582119695585

Epoch: 5| Step: 2
Training loss: 3.59075896143537
Validation loss: 2.9446546530867064

Epoch: 5| Step: 3
Training loss: 3.929246032064315
Validation loss: 2.955925499873073

Epoch: 5| Step: 4
Training loss: 3.3615123957607276
Validation loss: 2.9713947115462838

Epoch: 5| Step: 5
Training loss: 3.1625796764122422
Validation loss: 2.957223340516726

Epoch: 5| Step: 6
Training loss: 2.267337230993456
Validation loss: 2.944701310354425

Epoch: 5| Step: 7
Training loss: 3.101395071588862
Validation loss: 2.933578063617917

Epoch: 5| Step: 8
Training loss: 3.9283052899267767
Validation loss: 2.93517688464242

Epoch: 5| Step: 9
Training loss: 3.3261945256678853
Validation loss: 2.9325602882015986

Epoch: 5| Step: 10
Training loss: 2.9482145304992105
Validation loss: 2.93453961054087

Epoch: 150| Step: 0
Training loss: 3.5360296529847015
Validation loss: 2.9341852410452725

Epoch: 5| Step: 1
Training loss: 3.3450019845543237
Validation loss: 2.9340300608510756

Epoch: 5| Step: 2
Training loss: 3.3211035650014487
Validation loss: 2.9329371677959255

Epoch: 5| Step: 3
Training loss: 3.5709739422943723
Validation loss: 2.933574830202827

Epoch: 5| Step: 4
Training loss: 3.2685707349471613
Validation loss: 2.9333947119928725

Epoch: 5| Step: 5
Training loss: 3.21266384078033
Validation loss: 2.932977856237914

Epoch: 5| Step: 6
Training loss: 2.4484183480512423
Validation loss: 2.9314684449505752

Epoch: 5| Step: 7
Training loss: 2.9803130782883698
Validation loss: 2.9337882524220795

Epoch: 5| Step: 8
Training loss: 2.8005303732054645
Validation loss: 2.9317059211733527

Epoch: 5| Step: 9
Training loss: 3.58567686110253
Validation loss: 2.932434285475617

Epoch: 5| Step: 10
Training loss: 3.139688380626556
Validation loss: 2.9320459467071154

Epoch: 151| Step: 0
Training loss: 3.763949832837336
Validation loss: 2.933651788884406

Epoch: 5| Step: 1
Training loss: 3.3955148340810344
Validation loss: 2.9326060775021827

Epoch: 5| Step: 2
Training loss: 3.30234828973029
Validation loss: 2.935599926319136

Epoch: 5| Step: 3
Training loss: 4.152829935744989
Validation loss: 2.938614419410348

Epoch: 5| Step: 4
Training loss: 3.5315512469593164
Validation loss: 2.939030460005672

Epoch: 5| Step: 5
Training loss: 2.435249463409374
Validation loss: 2.9428759586043682

Epoch: 5| Step: 6
Training loss: 2.789886011098937
Validation loss: 2.9373785402683725

Epoch: 5| Step: 7
Training loss: 2.022821516738519
Validation loss: 2.9310915199483842

Epoch: 5| Step: 8
Training loss: 3.1225810034501764
Validation loss: 2.9397825197776397

Epoch: 5| Step: 9
Training loss: 3.7195834980856333
Validation loss: 2.9311160927675037

Epoch: 5| Step: 10
Training loss: 2.3088684434977846
Validation loss: 2.9316926784189588

Epoch: 152| Step: 0
Training loss: 2.7579088923653092
Validation loss: 2.9296381219237113

Epoch: 5| Step: 1
Training loss: 3.3112062050849045
Validation loss: 2.9332887497456857

Epoch: 5| Step: 2
Training loss: 3.359037728345607
Validation loss: 2.934706763901006

Epoch: 5| Step: 3
Training loss: 3.312529365841237
Validation loss: 2.934241107575677

Epoch: 5| Step: 4
Training loss: 2.7903729093174947
Validation loss: 2.9338812250195936

Epoch: 5| Step: 5
Training loss: 2.78883561779614
Validation loss: 2.9314080120691615

Epoch: 5| Step: 6
Training loss: 3.339411550297193
Validation loss: 2.9304072921498303

Epoch: 5| Step: 7
Training loss: 3.2034760073493738
Validation loss: 2.9293339822972055

Epoch: 5| Step: 8
Training loss: 4.015874357682204
Validation loss: 2.9251628287707696

Epoch: 5| Step: 9
Training loss: 3.1464670987072263
Validation loss: 2.927886129945678

Epoch: 5| Step: 10
Training loss: 3.120950898492833
Validation loss: 2.927470192196203

Epoch: 153| Step: 0
Training loss: 3.5240611943226194
Validation loss: 2.927200214036329

Epoch: 5| Step: 1
Training loss: 3.2005473860820497
Validation loss: 2.9257872381107566

Epoch: 5| Step: 2
Training loss: 3.4242222369257003
Validation loss: 2.927459288601324

Epoch: 5| Step: 3
Training loss: 3.2869721427644576
Validation loss: 2.927108628492844

Epoch: 5| Step: 4
Training loss: 2.42189252293308
Validation loss: 2.92854120089493

Epoch: 5| Step: 5
Training loss: 3.2212690847391787
Validation loss: 2.928242301826112

Epoch: 5| Step: 6
Training loss: 2.733241429373314
Validation loss: 2.926565523356642

Epoch: 5| Step: 7
Training loss: 3.230705944426547
Validation loss: 2.930281174097707

Epoch: 5| Step: 8
Training loss: 3.228928259795993
Validation loss: 2.928177474733199

Epoch: 5| Step: 9
Training loss: 3.8774428512326518
Validation loss: 2.9291907936070767

Epoch: 5| Step: 10
Training loss: 2.874384440991117
Validation loss: 2.9268316175943023

Epoch: 154| Step: 0
Training loss: 3.7775954564049044
Validation loss: 2.9273109112549736

Epoch: 5| Step: 1
Training loss: 3.4686392001764865
Validation loss: 2.928051948815886

Epoch: 5| Step: 2
Training loss: 3.2170515301258935
Validation loss: 2.932534486111004

Epoch: 5| Step: 3
Training loss: 3.2046747691898063
Validation loss: 2.9380542351836936

Epoch: 5| Step: 4
Training loss: 2.6701683259974747
Validation loss: 2.9360067062413107

Epoch: 5| Step: 5
Training loss: 2.994912443075258
Validation loss: 2.935670057944051

Epoch: 5| Step: 6
Training loss: 3.5224185662911136
Validation loss: 2.9337521585329767

Epoch: 5| Step: 7
Training loss: 2.7846297399099784
Validation loss: 2.932169040663011

Epoch: 5| Step: 8
Training loss: 2.914621744364048
Validation loss: 2.9278327059428806

Epoch: 5| Step: 9
Training loss: 3.1041516467932206
Validation loss: 2.924442476031775

Epoch: 5| Step: 10
Training loss: 3.502759799075862
Validation loss: 2.923361418105271

Epoch: 155| Step: 0
Training loss: 2.793288590050865
Validation loss: 2.9243067379537013

Epoch: 5| Step: 1
Training loss: 3.714349402940114
Validation loss: 2.9237566676497813

Epoch: 5| Step: 2
Training loss: 3.482068859613609
Validation loss: 2.920247806098108

Epoch: 5| Step: 3
Training loss: 2.6740540659081486
Validation loss: 2.9226145808272457

Epoch: 5| Step: 4
Training loss: 3.2584659643732667
Validation loss: 2.923276954361001

Epoch: 5| Step: 5
Training loss: 3.245359482330989
Validation loss: 2.9228443263947885

Epoch: 5| Step: 6
Training loss: 3.450216043314452
Validation loss: 2.9228868463694693

Epoch: 5| Step: 7
Training loss: 3.303664750360708
Validation loss: 2.921555620152122

Epoch: 5| Step: 8
Training loss: 2.7872300740059326
Validation loss: 2.9226440519605124

Epoch: 5| Step: 9
Training loss: 3.2443874019532
Validation loss: 2.922417476759874

Epoch: 5| Step: 10
Training loss: 3.142632141976715
Validation loss: 2.921580766321861

Epoch: 156| Step: 0
Training loss: 2.9722125289933228
Validation loss: 2.9205804509944735

Epoch: 5| Step: 1
Training loss: 2.6594609319517897
Validation loss: 2.9216583436601553

Epoch: 5| Step: 2
Training loss: 3.1046496192683084
Validation loss: 2.921758689230244

Epoch: 5| Step: 3
Training loss: 3.5076841742952802
Validation loss: 2.9232041162998117

Epoch: 5| Step: 4
Training loss: 3.245671985094406
Validation loss: 2.92598255035123

Epoch: 5| Step: 5
Training loss: 3.339641435529826
Validation loss: 2.924144011044651

Epoch: 5| Step: 6
Training loss: 3.3078616794972
Validation loss: 2.9271701021412593

Epoch: 5| Step: 7
Training loss: 3.4173362975130637
Validation loss: 2.935194621991399

Epoch: 5| Step: 8
Training loss: 2.8693337372256047
Validation loss: 2.9264253459135627

Epoch: 5| Step: 9
Training loss: 3.6352774840257047
Validation loss: 2.922977584512675

Epoch: 5| Step: 10
Training loss: 3.0446615933695567
Validation loss: 2.923099633419625

Epoch: 157| Step: 0
Training loss: 3.271501719870065
Validation loss: 2.9195962016733485

Epoch: 5| Step: 1
Training loss: 3.371556114412067
Validation loss: 2.9172376070949744

Epoch: 5| Step: 2
Training loss: 3.330322829398113
Validation loss: 2.9184328881251442

Epoch: 5| Step: 3
Training loss: 2.9152503980134665
Validation loss: 2.922057538233632

Epoch: 5| Step: 4
Training loss: 3.3552140837585256
Validation loss: 2.9177566448815377

Epoch: 5| Step: 5
Training loss: 3.44327102348719
Validation loss: 2.924285373522366

Epoch: 5| Step: 6
Training loss: 2.7805763028751502
Validation loss: 2.9182535018211224

Epoch: 5| Step: 7
Training loss: 2.77725696025721
Validation loss: 2.9203635212887913

Epoch: 5| Step: 8
Training loss: 3.0777940911121973
Validation loss: 2.923461427235142

Epoch: 5| Step: 9
Training loss: 3.4000572816847945
Validation loss: 2.922176526050001

Epoch: 5| Step: 10
Training loss: 3.4801099187657702
Validation loss: 2.9191273945869427

Epoch: 158| Step: 0
Training loss: 3.0395774110906757
Validation loss: 2.921617866113563

Epoch: 5| Step: 1
Training loss: 2.363565929070313
Validation loss: 2.918397755961877

Epoch: 5| Step: 2
Training loss: 3.5006920266609205
Validation loss: 2.918402401154899

Epoch: 5| Step: 3
Training loss: 3.2717688775545812
Validation loss: 2.9186235795070097

Epoch: 5| Step: 4
Training loss: 4.106517886360776
Validation loss: 2.918940596152189

Epoch: 5| Step: 5
Training loss: 3.1851388002151086
Validation loss: 2.9179332414873227

Epoch: 5| Step: 6
Training loss: 3.4013849915644427
Validation loss: 2.9195354299641507

Epoch: 5| Step: 7
Training loss: 2.92697107138249
Validation loss: 2.9158487049016433

Epoch: 5| Step: 8
Training loss: 2.954456170607052
Validation loss: 2.9170032576551788

Epoch: 5| Step: 9
Training loss: 3.4853470477082693
Validation loss: 2.9160962497755354

Epoch: 5| Step: 10
Training loss: 2.560892577879961
Validation loss: 2.9145894680269273

Epoch: 159| Step: 0
Training loss: 3.1654649428548973
Validation loss: 2.9137992428762303

Epoch: 5| Step: 1
Training loss: 3.059596651209244
Validation loss: 2.915391399436068

Epoch: 5| Step: 2
Training loss: 3.102486960286073
Validation loss: 2.9148432491705307

Epoch: 5| Step: 3
Training loss: 3.0051316241033494
Validation loss: 2.9147694791386867

Epoch: 5| Step: 4
Training loss: 3.1693174076132222
Validation loss: 2.9140953144153774

Epoch: 5| Step: 5
Training loss: 3.7655411706987802
Validation loss: 2.9154592666463874

Epoch: 5| Step: 6
Training loss: 2.5769738604012193
Validation loss: 2.916974073169276

Epoch: 5| Step: 7
Training loss: 3.035742665005914
Validation loss: 2.9145873719657502

Epoch: 5| Step: 8
Training loss: 3.534153917381523
Validation loss: 2.915825747783177

Epoch: 5| Step: 9
Training loss: 3.236646508790197
Validation loss: 2.9151617269406924

Epoch: 5| Step: 10
Training loss: 3.463565973564653
Validation loss: 2.9231690563887667

Epoch: 160| Step: 0
Training loss: 2.6250935492421883
Validation loss: 2.9167107685698475

Epoch: 5| Step: 1
Training loss: 2.836032666167535
Validation loss: 2.9186072566528116

Epoch: 5| Step: 2
Training loss: 3.617354387095743
Validation loss: 2.92211260314001

Epoch: 5| Step: 3
Training loss: 2.997368294031195
Validation loss: 2.9193044439550793

Epoch: 5| Step: 4
Training loss: 3.0074690981931824
Validation loss: 2.915267408874627

Epoch: 5| Step: 5
Training loss: 3.319898440404774
Validation loss: 2.9160777509700315

Epoch: 5| Step: 6
Training loss: 3.450901748456835
Validation loss: 2.917215583643636

Epoch: 5| Step: 7
Training loss: 3.347560244666973
Validation loss: 2.9142683871874864

Epoch: 5| Step: 8
Training loss: 3.47653232518506
Validation loss: 2.915665037617107

Epoch: 5| Step: 9
Training loss: 3.0742006022633825
Validation loss: 2.918032309475019

Epoch: 5| Step: 10
Training loss: 3.3256915871861983
Validation loss: 2.911684869709957

Epoch: 161| Step: 0
Training loss: 3.063805438146715
Validation loss: 2.91162680149273

Epoch: 5| Step: 1
Training loss: 2.9641807327458687
Validation loss: 2.911698384837516

Epoch: 5| Step: 2
Training loss: 3.545092433052588
Validation loss: 2.9117103406104423

Epoch: 5| Step: 3
Training loss: 3.254912551666195
Validation loss: 2.9108362379486725

Epoch: 5| Step: 4
Training loss: 3.168481825215539
Validation loss: 2.9130839503624237

Epoch: 5| Step: 5
Training loss: 2.8383301449046776
Validation loss: 2.909972821616075

Epoch: 5| Step: 6
Training loss: 3.2583764043304395
Validation loss: 2.9096173834945684

Epoch: 5| Step: 7
Training loss: 2.885940797945378
Validation loss: 2.913222626958618

Epoch: 5| Step: 8
Training loss: 3.3678218659979255
Validation loss: 2.908806808673279

Epoch: 5| Step: 9
Training loss: 3.3836453229751924
Validation loss: 2.9101098669638885

Epoch: 5| Step: 10
Training loss: 3.395705253822452
Validation loss: 2.9086203063829754

Epoch: 162| Step: 0
Training loss: 2.770305745847572
Validation loss: 2.9127651661984366

Epoch: 5| Step: 1
Training loss: 3.6666661753798646
Validation loss: 2.912947436573985

Epoch: 5| Step: 2
Training loss: 3.5801913362657674
Validation loss: 2.9102922234789292

Epoch: 5| Step: 3
Training loss: 3.427886837777382
Validation loss: 2.9104092012533487

Epoch: 5| Step: 4
Training loss: 2.8554629053142135
Validation loss: 2.9114048626548015

Epoch: 5| Step: 5
Training loss: 3.375454059715956
Validation loss: 2.9153747885242103

Epoch: 5| Step: 6
Training loss: 2.700519783708938
Validation loss: 2.9097901323150475

Epoch: 5| Step: 7
Training loss: 2.2289634207885465
Validation loss: 2.9157917272010057

Epoch: 5| Step: 8
Training loss: 3.2484750838167473
Validation loss: 2.916596060805061

Epoch: 5| Step: 9
Training loss: 3.7675976156993256
Validation loss: 2.9141668591167362

Epoch: 5| Step: 10
Training loss: 3.1606025522108903
Validation loss: 2.9172617016728375

Epoch: 163| Step: 0
Training loss: 2.497585274860539
Validation loss: 2.9120576106636618

Epoch: 5| Step: 1
Training loss: 3.3201681666699145
Validation loss: 2.9270949182655905

Epoch: 5| Step: 2
Training loss: 3.2552534339323596
Validation loss: 2.9143572560945157

Epoch: 5| Step: 3
Training loss: 3.403977642313133
Validation loss: 2.911924769306139

Epoch: 5| Step: 4
Training loss: 3.443954373091779
Validation loss: 2.907912087026621

Epoch: 5| Step: 5
Training loss: 3.2358289021643327
Validation loss: 2.907439345876208

Epoch: 5| Step: 6
Training loss: 3.2352713849294106
Validation loss: 2.9057025179835647

Epoch: 5| Step: 7
Training loss: 2.9498886863267826
Validation loss: 2.9072458777465875

Epoch: 5| Step: 8
Training loss: 2.6963346892644395
Validation loss: 2.90662254091948

Epoch: 5| Step: 9
Training loss: 3.522667371402798
Validation loss: 2.907794774278349

Epoch: 5| Step: 10
Training loss: 3.4476267682199557
Validation loss: 2.9038556031672496

Epoch: 164| Step: 0
Training loss: 2.9649407291760244
Validation loss: 2.90497559670166

Epoch: 5| Step: 1
Training loss: 3.134405097550691
Validation loss: 2.907816589602626

Epoch: 5| Step: 2
Training loss: 2.858560081214848
Validation loss: 2.904444976953446

Epoch: 5| Step: 3
Training loss: 3.387276538643275
Validation loss: 2.909995202938471

Epoch: 5| Step: 4
Training loss: 3.341997346823351
Validation loss: 2.9045387052246814

Epoch: 5| Step: 5
Training loss: 3.523489196804088
Validation loss: 2.9039793394218174

Epoch: 5| Step: 6
Training loss: 2.9769125104355347
Validation loss: 2.9050350642303604

Epoch: 5| Step: 7
Training loss: 3.418801516854336
Validation loss: 2.9103212133488903

Epoch: 5| Step: 8
Training loss: 3.0496622492654373
Validation loss: 2.904496791346576

Epoch: 5| Step: 9
Training loss: 3.3214597627314917
Validation loss: 2.9072110989230207

Epoch: 5| Step: 10
Training loss: 3.0396370234376553
Validation loss: 2.912595347949636

Epoch: 165| Step: 0
Training loss: 2.6340251359949516
Validation loss: 2.9126841825268284

Epoch: 5| Step: 1
Training loss: 3.4083606585189954
Validation loss: 2.9122490724915315

Epoch: 5| Step: 2
Training loss: 3.701573300295556
Validation loss: 2.917233279048652

Epoch: 5| Step: 3
Training loss: 3.474903868299222
Validation loss: 2.9167014780618663

Epoch: 5| Step: 4
Training loss: 3.6129568583269625
Validation loss: 2.9156624842320062

Epoch: 5| Step: 5
Training loss: 3.3138976117687493
Validation loss: 2.910201770762031

Epoch: 5| Step: 6
Training loss: 2.931605166653486
Validation loss: 2.915415574343132

Epoch: 5| Step: 7
Training loss: 3.061227650932704
Validation loss: 2.9071633126346934

Epoch: 5| Step: 8
Training loss: 2.459802953380211
Validation loss: 2.9096946463083913

Epoch: 5| Step: 9
Training loss: 3.059176919231174
Validation loss: 2.9078400675189293

Epoch: 5| Step: 10
Training loss: 3.2355412393935588
Validation loss: 2.911532014973334

Epoch: 166| Step: 0
Training loss: 3.4855898804765273
Validation loss: 2.901476940597229

Epoch: 5| Step: 1
Training loss: 3.374943768068154
Validation loss: 2.902705023770473

Epoch: 5| Step: 2
Training loss: 3.038950626304852
Validation loss: 2.901091031600278

Epoch: 5| Step: 3
Training loss: 3.057014847050215
Validation loss: 2.8999629562524016

Epoch: 5| Step: 4
Training loss: 3.292990470624539
Validation loss: 2.900607985186095

Epoch: 5| Step: 5
Training loss: 3.531928613323641
Validation loss: 2.905005790395877

Epoch: 5| Step: 6
Training loss: 3.192924371891182
Validation loss: 2.901018500762566

Epoch: 5| Step: 7
Training loss: 2.534607438459839
Validation loss: 2.905381068277168

Epoch: 5| Step: 8
Training loss: 3.2767892216076757
Validation loss: 2.9098444743365266

Epoch: 5| Step: 9
Training loss: 2.7246441145018734
Validation loss: 2.9092577629497196

Epoch: 5| Step: 10
Training loss: 3.5801102240872096
Validation loss: 2.9230318348500024

Epoch: 167| Step: 0
Training loss: 3.241168861771188
Validation loss: 2.9111992625727816

Epoch: 5| Step: 1
Training loss: 2.7734916574267747
Validation loss: 2.9113705209609537

Epoch: 5| Step: 2
Training loss: 3.073780382401026
Validation loss: 2.9164181358757753

Epoch: 5| Step: 3
Training loss: 3.092360984249604
Validation loss: 2.9103995470961417

Epoch: 5| Step: 4
Training loss: 2.901093697666306
Validation loss: 2.9066599824538213

Epoch: 5| Step: 5
Training loss: 3.3397703642339587
Validation loss: 2.9043020352954123

Epoch: 5| Step: 6
Training loss: 3.7083148884403836
Validation loss: 2.9083900330717927

Epoch: 5| Step: 7
Training loss: 2.9123746263754375
Validation loss: 2.9028924147851196

Epoch: 5| Step: 8
Training loss: 3.9776901115285552
Validation loss: 2.903418673839438

Epoch: 5| Step: 9
Training loss: 3.074165547357695
Validation loss: 2.901274641561957

Epoch: 5| Step: 10
Training loss: 2.7172735304810822
Validation loss: 2.90458723196129

Epoch: 168| Step: 0
Training loss: 3.199849160930865
Validation loss: 2.904785963348945

Epoch: 5| Step: 1
Training loss: 3.4557476872070274
Validation loss: 2.9052227761689355

Epoch: 5| Step: 2
Training loss: 2.9035004766144255
Validation loss: 2.903900887222452

Epoch: 5| Step: 3
Training loss: 3.326170584767439
Validation loss: 2.9051979728666977

Epoch: 5| Step: 4
Training loss: 3.853576876215883
Validation loss: 2.9051645549619107

Epoch: 5| Step: 5
Training loss: 2.7174036485142836
Validation loss: 2.9060853789553964

Epoch: 5| Step: 6
Training loss: 3.182710227765151
Validation loss: 2.902939120674349

Epoch: 5| Step: 7
Training loss: 2.888019108864923
Validation loss: 2.9038974088839877

Epoch: 5| Step: 8
Training loss: 3.0838514013051976
Validation loss: 2.9052951482201355

Epoch: 5| Step: 9
Training loss: 2.6746533320745223
Validation loss: 2.9028791130025513

Epoch: 5| Step: 10
Training loss: 3.6428477824114904
Validation loss: 2.905494306769947

Epoch: 169| Step: 0
Training loss: 3.3017167971979253
Validation loss: 2.9043400893221767

Epoch: 5| Step: 1
Training loss: 2.962114004750025
Validation loss: 2.90230103505759

Epoch: 5| Step: 2
Training loss: 3.584747981493303
Validation loss: 2.90188323850394

Epoch: 5| Step: 3
Training loss: 3.381765155012936
Validation loss: 2.9031399429321554

Epoch: 5| Step: 4
Training loss: 3.0415697125872883
Validation loss: 2.903724606140431

Epoch: 5| Step: 5
Training loss: 3.5081350607280046
Validation loss: 2.902275035502223

Epoch: 5| Step: 6
Training loss: 3.2022004072387658
Validation loss: 2.8979165722686617

Epoch: 5| Step: 7
Training loss: 3.031110622701795
Validation loss: 2.8993142504618294

Epoch: 5| Step: 8
Training loss: 2.968052189781967
Validation loss: 2.8988813679486043

Epoch: 5| Step: 9
Training loss: 2.9566088920318654
Validation loss: 2.9000538246738277

Epoch: 5| Step: 10
Training loss: 2.985971712707908
Validation loss: 2.9008055203650547

Epoch: 170| Step: 0
Training loss: 3.1964543547812014
Validation loss: 2.899842565419392

Epoch: 5| Step: 1
Training loss: 2.94231782645834
Validation loss: 2.89800241031398

Epoch: 5| Step: 2
Training loss: 2.966133490523641
Validation loss: 2.904433657685278

Epoch: 5| Step: 3
Training loss: 3.4925020831463005
Validation loss: 2.909590821973527

Epoch: 5| Step: 4
Training loss: 3.3897410000686463
Validation loss: 2.9011229614902105

Epoch: 5| Step: 5
Training loss: 3.4223835885066833
Validation loss: 2.8982357123731903

Epoch: 5| Step: 6
Training loss: 3.0925719204852817
Validation loss: 2.8989808570788873

Epoch: 5| Step: 7
Training loss: 2.5738725212321993
Validation loss: 2.8974187133069953

Epoch: 5| Step: 8
Training loss: 3.741913022863935
Validation loss: 2.8974001925812733

Epoch: 5| Step: 9
Training loss: 3.2679992513854197
Validation loss: 2.896903097090767

Epoch: 5| Step: 10
Training loss: 2.6602004351426336
Validation loss: 2.896037293678473

Epoch: 171| Step: 0
Training loss: 3.8803559482154566
Validation loss: 2.8959516541081647

Epoch: 5| Step: 1
Training loss: 2.6439267796060406
Validation loss: 2.8966176324019477

Epoch: 5| Step: 2
Training loss: 3.653223333675072
Validation loss: 2.894186028676716

Epoch: 5| Step: 3
Training loss: 2.6435970758168836
Validation loss: 2.895095659235839

Epoch: 5| Step: 4
Training loss: 3.686969266295214
Validation loss: 2.8946465531599315

Epoch: 5| Step: 5
Training loss: 3.37215345928116
Validation loss: 2.892583669576413

Epoch: 5| Step: 6
Training loss: 2.6423608615879024
Validation loss: 2.897310749577173

Epoch: 5| Step: 7
Training loss: 3.1537415762662935
Validation loss: 2.89492819176157

Epoch: 5| Step: 8
Training loss: 3.4980336523950957
Validation loss: 2.892557084582972

Epoch: 5| Step: 9
Training loss: 2.3133110479917613
Validation loss: 2.893903609145827

Epoch: 5| Step: 10
Training loss: 3.034125311308701
Validation loss: 2.8951037350898825

Epoch: 172| Step: 0
Training loss: 3.1688154526069616
Validation loss: 2.893270072685864

Epoch: 5| Step: 1
Training loss: 3.2301493144289566
Validation loss: 2.896632651598237

Epoch: 5| Step: 2
Training loss: 3.430984147687029
Validation loss: 2.89184375934756

Epoch: 5| Step: 3
Training loss: 3.329446306447895
Validation loss: 2.896067483187676

Epoch: 5| Step: 4
Training loss: 3.4461008843672607
Validation loss: 2.8980572360974812

Epoch: 5| Step: 5
Training loss: 2.844235221631938
Validation loss: 2.9018448191972985

Epoch: 5| Step: 6
Training loss: 3.3598799924763343
Validation loss: 2.8950125722661553

Epoch: 5| Step: 7
Training loss: 2.201688365709027
Validation loss: 2.8941450942662508

Epoch: 5| Step: 8
Training loss: 3.095964198129732
Validation loss: 2.889521859754651

Epoch: 5| Step: 9
Training loss: 3.4622669293013626
Validation loss: 2.8884870086226506

Epoch: 5| Step: 10
Training loss: 3.2064953448025206
Validation loss: 2.8905126016011353

Epoch: 173| Step: 0
Training loss: 2.9082024691486836
Validation loss: 2.8885737161881258

Epoch: 5| Step: 1
Training loss: 2.927969222673097
Validation loss: 2.887427312757058

Epoch: 5| Step: 2
Training loss: 2.6312528342913586
Validation loss: 2.888143990500099

Epoch: 5| Step: 3
Training loss: 3.2162534049676217
Validation loss: 2.889311786003844

Epoch: 5| Step: 4
Training loss: 3.379447972966849
Validation loss: 2.8895923050250834

Epoch: 5| Step: 5
Training loss: 3.355092712576711
Validation loss: 2.88799722033581

Epoch: 5| Step: 6
Training loss: 3.157228072803536
Validation loss: 2.8899260088485637

Epoch: 5| Step: 7
Training loss: 3.8039491160185492
Validation loss: 2.8899202498182155

Epoch: 5| Step: 8
Training loss: 3.0933920913355464
Validation loss: 2.885682464531841

Epoch: 5| Step: 9
Training loss: 3.192363992182211
Validation loss: 2.8877862109518793

Epoch: 5| Step: 10
Training loss: 3.1860505342660486
Validation loss: 2.884657577850791

Epoch: 174| Step: 0
Training loss: 3.331281284664895
Validation loss: 2.888903408557015

Epoch: 5| Step: 1
Training loss: 2.9177100540550103
Validation loss: 2.8893531695288623

Epoch: 5| Step: 2
Training loss: 2.6162794673042096
Validation loss: 2.8963862720669056

Epoch: 5| Step: 3
Training loss: 3.245674776473865
Validation loss: 2.8956959490360967

Epoch: 5| Step: 4
Training loss: 3.1957598608557616
Validation loss: 2.900007349895347

Epoch: 5| Step: 5
Training loss: 3.0106210254265204
Validation loss: 2.8966822878506777

Epoch: 5| Step: 6
Training loss: 4.103491687296315
Validation loss: 2.9017034227921883

Epoch: 5| Step: 7
Training loss: 3.4196036826383076
Validation loss: 2.8939878467834976

Epoch: 5| Step: 8
Training loss: 3.669832611216504
Validation loss: 2.892443759718289

Epoch: 5| Step: 9
Training loss: 2.6720812980025075
Validation loss: 2.889183428623399

Epoch: 5| Step: 10
Training loss: 2.1753204241217703
Validation loss: 2.8870700890632395

Epoch: 175| Step: 0
Training loss: 3.2407380690387027
Validation loss: 2.8893693435552286

Epoch: 5| Step: 1
Training loss: 3.538943122382997
Validation loss: 2.8948861095127585

Epoch: 5| Step: 2
Training loss: 3.0875289483199775
Validation loss: 2.893780591975727

Epoch: 5| Step: 3
Training loss: 3.380955422027162
Validation loss: 2.8905059585958726

Epoch: 5| Step: 4
Training loss: 3.318599627117954
Validation loss: 2.8967673394203652

Epoch: 5| Step: 5
Training loss: 2.8944678254585496
Validation loss: 2.8963713259432198

Epoch: 5| Step: 6
Training loss: 2.5648841931410575
Validation loss: 2.895461148766536

Epoch: 5| Step: 7
Training loss: 3.1611619252115553
Validation loss: 2.8872012308348953

Epoch: 5| Step: 8
Training loss: 3.220666259406581
Validation loss: 2.8898865257280564

Epoch: 5| Step: 9
Training loss: 3.0854797796422284
Validation loss: 2.884059190571188

Epoch: 5| Step: 10
Training loss: 3.355118721056716
Validation loss: 2.8833285954488814

Testing loss: 3.082836446160478
