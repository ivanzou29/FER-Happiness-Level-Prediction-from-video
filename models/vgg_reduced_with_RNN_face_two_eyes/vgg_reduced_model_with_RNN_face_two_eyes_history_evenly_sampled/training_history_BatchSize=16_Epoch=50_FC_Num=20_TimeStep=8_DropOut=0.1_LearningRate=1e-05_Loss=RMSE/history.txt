Epoch: 1| Step: 0
Training loss: 5.799225775246654
Validation loss: 5.798681665478073

Epoch: 6| Step: 1
Training loss: 5.90524428751384
Validation loss: 5.792513326519215

Epoch: 6| Step: 2
Training loss: 6.098251167126792
Validation loss: 5.786181252739195

Epoch: 6| Step: 3
Training loss: 5.575217977462031
Validation loss: 5.779795686852272

Epoch: 6| Step: 4
Training loss: 6.774306438460544
Validation loss: 5.773517179871091

Epoch: 6| Step: 5
Training loss: 5.798954428777744
Validation loss: 5.766360263388876

Epoch: 6| Step: 6
Training loss: 5.9147087761974015
Validation loss: 5.759271011071197

Epoch: 6| Step: 7
Training loss: 4.011423488251971
Validation loss: 5.751696911809794

Epoch: 6| Step: 8
Training loss: 6.307158069996492
Validation loss: 5.7437853228267

Epoch: 6| Step: 9
Training loss: 5.805203359690622
Validation loss: 5.735215028000865

Epoch: 6| Step: 10
Training loss: 5.641543664910846
Validation loss: 5.726006621449972

Epoch: 6| Step: 11
Training loss: 4.9488580176350725
Validation loss: 5.71539716891138

Epoch: 6| Step: 12
Training loss: 5.870272418431837
Validation loss: 5.704665463501912

Epoch: 6| Step: 13
Training loss: 6.374454250536864
Validation loss: 5.692313887573763

Epoch: 2| Step: 0
Training loss: 5.774133539635615
Validation loss: 5.679834558058236

Epoch: 6| Step: 1
Training loss: 4.566946293050042
Validation loss: 5.6659397235636355

Epoch: 6| Step: 2
Training loss: 5.83172708830922
Validation loss: 5.65009567473035

Epoch: 6| Step: 3
Training loss: 6.919685103467668
Validation loss: 5.634856055625218

Epoch: 6| Step: 4
Training loss: 6.334599251299212
Validation loss: 5.616881603004947

Epoch: 6| Step: 5
Training loss: 5.279948960259864
Validation loss: 5.5984744402342175

Epoch: 6| Step: 6
Training loss: 4.741475336184663
Validation loss: 5.579319308883843

Epoch: 6| Step: 7
Training loss: 5.126680052251583
Validation loss: 5.558664616170869

Epoch: 6| Step: 8
Training loss: 5.243075208928857
Validation loss: 5.537724669083576

Epoch: 6| Step: 9
Training loss: 5.240646749871011
Validation loss: 5.514141249568351

Epoch: 6| Step: 10
Training loss: 5.584921236225606
Validation loss: 5.490990184584848

Epoch: 6| Step: 11
Training loss: 5.424511007605281
Validation loss: 5.466090481904606

Epoch: 6| Step: 12
Training loss: 5.869934495498677
Validation loss: 5.439580692530303

Epoch: 6| Step: 13
Training loss: 6.372332444919538
Validation loss: 5.412548433829956

Epoch: 3| Step: 0
Training loss: 5.343090529768493
Validation loss: 5.383821241544742

Epoch: 6| Step: 1
Training loss: 4.437108841969992
Validation loss: 5.356116707962891

Epoch: 6| Step: 2
Training loss: 6.104943270532969
Validation loss: 5.327078213431925

Epoch: 6| Step: 3
Training loss: 6.3642091864846755
Validation loss: 5.298475235707434

Epoch: 6| Step: 4
Training loss: 5.662703231297062
Validation loss: 5.268608596837521

Epoch: 6| Step: 5
Training loss: 4.8455897621262025
Validation loss: 5.2395384117146016

Epoch: 6| Step: 6
Training loss: 5.224179852379212
Validation loss: 5.20957325341959

Epoch: 6| Step: 7
Training loss: 4.449292270230471
Validation loss: 5.179685682575673

Epoch: 6| Step: 8
Training loss: 5.239506725360476
Validation loss: 5.148369366679561

Epoch: 6| Step: 9
Training loss: 4.8624689488535
Validation loss: 5.119348100213148

Epoch: 6| Step: 10
Training loss: 5.482756547052591
Validation loss: 5.087867781452186

Epoch: 6| Step: 11
Training loss: 6.432517484544045
Validation loss: 5.055897328422322

Epoch: 6| Step: 12
Training loss: 3.995171254943052
Validation loss: 5.022787796267131

Epoch: 6| Step: 13
Training loss: 3.7773928555252425
Validation loss: 4.9927699246639206

Epoch: 4| Step: 0
Training loss: 5.469656732866389
Validation loss: 4.964126897258989

Epoch: 6| Step: 1
Training loss: 5.573824381360874
Validation loss: 4.936630189023626

Epoch: 6| Step: 2
Training loss: 3.4399850359302895
Validation loss: 4.906846562423159

Epoch: 6| Step: 3
Training loss: 5.653937778698622
Validation loss: 4.87941686574898

Epoch: 6| Step: 4
Training loss: 5.685741781591351
Validation loss: 4.850262893133253

Epoch: 6| Step: 5
Training loss: 4.799178076945405
Validation loss: 4.8172832956260905

Epoch: 6| Step: 6
Training loss: 4.50408792253393
Validation loss: 4.784783232303144

Epoch: 6| Step: 7
Training loss: 5.12408587979511
Validation loss: 4.754449997542459

Epoch: 6| Step: 8
Training loss: 5.5250571545712805
Validation loss: 4.726389372422878

Epoch: 6| Step: 9
Training loss: 4.477213707338165
Validation loss: 4.7020551463360585

Epoch: 6| Step: 10
Training loss: 3.695442568403301
Validation loss: 4.678614830487366

Epoch: 6| Step: 11
Training loss: 5.20452055673372
Validation loss: 4.655678706811026

Epoch: 6| Step: 12
Training loss: 3.729795576942035
Validation loss: 4.633450567778271

Epoch: 6| Step: 13
Training loss: 4.101354161375393
Validation loss: 4.608807276904725

Epoch: 5| Step: 0
Training loss: 4.299923235185857
Validation loss: 4.58486529763401

Epoch: 6| Step: 1
Training loss: 4.994326615254929
Validation loss: 4.560806789581803

Epoch: 6| Step: 2
Training loss: 3.567017752459652
Validation loss: 4.539074152839259

Epoch: 6| Step: 3
Training loss: 4.705988117039273
Validation loss: 4.5184697542615595

Epoch: 6| Step: 4
Training loss: 5.965075575165133
Validation loss: 4.498314401643687

Epoch: 6| Step: 5
Training loss: 5.097810402362715
Validation loss: 4.4776396651367

Epoch: 6| Step: 6
Training loss: 4.987331171452836
Validation loss: 4.456276729873888

Epoch: 6| Step: 7
Training loss: 3.7194333770893713
Validation loss: 4.432625156112545

Epoch: 6| Step: 8
Training loss: 3.641770473254816
Validation loss: 4.412037908027954

Epoch: 6| Step: 9
Training loss: 5.117913533895399
Validation loss: 4.389097750752804

Epoch: 6| Step: 10
Training loss: 4.192794413502346
Validation loss: 4.369816234916101

Epoch: 6| Step: 11
Training loss: 5.1743858673280165
Validation loss: 4.35139042791047

Epoch: 6| Step: 12
Training loss: 4.165141296920842
Validation loss: 4.332472949282299

Epoch: 6| Step: 13
Training loss: 1.970707540819043
Validation loss: 4.312987322779744

Epoch: 6| Step: 0
Training loss: 4.592850369963518
Validation loss: 4.297214062868749

Epoch: 6| Step: 1
Training loss: 4.019568025144574
Validation loss: 4.282465639485551

Epoch: 6| Step: 2
Training loss: 4.863330666164602
Validation loss: 4.264770778072475

Epoch: 6| Step: 3
Training loss: 4.909868400348449
Validation loss: 4.250910321872725

Epoch: 6| Step: 4
Training loss: 4.567259096203704
Validation loss: 4.232213848037106

Epoch: 6| Step: 5
Training loss: 4.348921297871247
Validation loss: 4.216215355932594

Epoch: 6| Step: 6
Training loss: 4.554371111237211
Validation loss: 4.201493419536836

Epoch: 6| Step: 7
Training loss: 4.114214118455674
Validation loss: 4.188068080149216

Epoch: 6| Step: 8
Training loss: 4.072209419576155
Validation loss: 4.174995479737261

Epoch: 6| Step: 9
Training loss: 3.6855770204864786
Validation loss: 4.161518612372606

Epoch: 6| Step: 10
Training loss: 4.624095106526164
Validation loss: 4.153469517876198

Epoch: 6| Step: 11
Training loss: 4.15102109182022
Validation loss: 4.142348230145685

Epoch: 6| Step: 12
Training loss: 3.3658614590036313
Validation loss: 4.133415147988513

Epoch: 6| Step: 13
Training loss: 4.748833964931735
Validation loss: 4.120149044061321

Epoch: 7| Step: 0
Training loss: 4.393490762239162
Validation loss: 4.10801035232087

Epoch: 6| Step: 1
Training loss: 3.6193360112783974
Validation loss: 4.094913722121059

Epoch: 6| Step: 2
Training loss: 4.305247746338024
Validation loss: 4.08598493595846

Epoch: 6| Step: 3
Training loss: 3.862536907328347
Validation loss: 4.076054534464529

Epoch: 6| Step: 4
Training loss: 4.375687463426506
Validation loss: 4.067789373664194

Epoch: 6| Step: 5
Training loss: 3.6153749740521977
Validation loss: 4.0574159423737495

Epoch: 6| Step: 6
Training loss: 4.506316520210522
Validation loss: 4.048442699572004

Epoch: 6| Step: 7
Training loss: 4.1812538135551085
Validation loss: 4.039291216999649

Epoch: 6| Step: 8
Training loss: 4.802676789635456
Validation loss: 4.030614151713677

Epoch: 6| Step: 9
Training loss: 5.15230450965914
Validation loss: 4.022700657462001

Epoch: 6| Step: 10
Training loss: 3.7744980737335347
Validation loss: 4.013286278698577

Epoch: 6| Step: 11
Training loss: 4.130485124521283
Validation loss: 4.006292252183959

Epoch: 6| Step: 12
Training loss: 4.08402500652313
Validation loss: 3.9992793610751396

Epoch: 6| Step: 13
Training loss: 3.012362756412432
Validation loss: 3.9934136864114276

Epoch: 8| Step: 0
Training loss: 3.837271091455657
Validation loss: 3.983786741355036

Epoch: 6| Step: 1
Training loss: 4.68370757231115
Validation loss: 3.97741151583253

Epoch: 6| Step: 2
Training loss: 4.684262798204909
Validation loss: 3.965078826179919

Epoch: 6| Step: 3
Training loss: 3.8535277515806405
Validation loss: 3.9603323098228986

Epoch: 6| Step: 4
Training loss: 3.1761544959592487
Validation loss: 3.9533499435205623

Epoch: 6| Step: 5
Training loss: 4.0908073740171975
Validation loss: 3.94765082135871

Epoch: 6| Step: 6
Training loss: 4.024395223164773
Validation loss: 3.937677801635992

Epoch: 6| Step: 7
Training loss: 3.4444324294943773
Validation loss: 3.932410486755905

Epoch: 6| Step: 8
Training loss: 4.312212063672203
Validation loss: 3.927051369867813

Epoch: 6| Step: 9
Training loss: 4.158409074133043
Validation loss: 3.9225787276723154

Epoch: 6| Step: 10
Training loss: 3.8186229878232707
Validation loss: 3.916933189824369

Epoch: 6| Step: 11
Training loss: 4.3427311642379784
Validation loss: 3.908633896446757

Epoch: 6| Step: 12
Training loss: 4.520392307034542
Validation loss: 3.9028974740083027

Epoch: 6| Step: 13
Training loss: 4.17750403869178
Validation loss: 3.896339516983964

Epoch: 9| Step: 0
Training loss: 3.135529745265904
Validation loss: 3.8941786426402794

Epoch: 6| Step: 1
Training loss: 3.6531204784877653
Validation loss: 3.894128699045442

Epoch: 6| Step: 2
Training loss: 4.67727909938669
Validation loss: 3.8821717357886563

Epoch: 6| Step: 3
Training loss: 2.739444763005472
Validation loss: 3.870336061897489

Epoch: 6| Step: 4
Training loss: 5.1042744320243
Validation loss: 3.869852773771063

Epoch: 6| Step: 5
Training loss: 3.6596113876233978
Validation loss: 3.8612446020593056

Epoch: 6| Step: 6
Training loss: 4.673647133000491
Validation loss: 3.8531578989845587

Epoch: 6| Step: 7
Training loss: 3.201952165950433
Validation loss: 3.8420730762542794

Epoch: 6| Step: 8
Training loss: 4.277631358053238
Validation loss: 3.8455366465472047

Epoch: 6| Step: 9
Training loss: 3.3918662897423055
Validation loss: 3.8373588413395887

Epoch: 6| Step: 10
Training loss: 4.466411699068523
Validation loss: 3.8278474467289847

Epoch: 6| Step: 11
Training loss: 4.054408539747534
Validation loss: 3.8287312907941207

Epoch: 6| Step: 12
Training loss: 4.074757321860489
Validation loss: 3.810423973173957

Epoch: 6| Step: 13
Training loss: 4.648898472088219
Validation loss: 3.808666804359495

Epoch: 10| Step: 0
Training loss: 3.6491220228262558
Validation loss: 3.800120559468162

Epoch: 6| Step: 1
Training loss: 3.1834698799233823
Validation loss: 3.791571213743291

Epoch: 6| Step: 2
Training loss: 4.197168376607233
Validation loss: 3.7894466183879074

Epoch: 6| Step: 3
Training loss: 3.281346928209366
Validation loss: 3.7850842346440694

Epoch: 6| Step: 4
Training loss: 4.049730390828915
Validation loss: 3.780021794122798

Epoch: 6| Step: 5
Training loss: 4.062387787663004
Validation loss: 3.771974137558105

Epoch: 6| Step: 6
Training loss: 3.278936533302941
Validation loss: 3.763691309639413

Epoch: 6| Step: 7
Training loss: 3.638597963721956
Validation loss: 3.7625088221567466

Epoch: 6| Step: 8
Training loss: 4.223728435514369
Validation loss: 3.7553110338902385

Epoch: 6| Step: 9
Training loss: 3.943306652848398
Validation loss: 3.752370659952578

Epoch: 6| Step: 10
Training loss: 3.782130115322385
Validation loss: 3.747071608321567

Epoch: 6| Step: 11
Training loss: 4.193872641576595
Validation loss: 3.737947512333753

Epoch: 6| Step: 12
Training loss: 4.813409892677111
Validation loss: 3.7334924095039943

Epoch: 6| Step: 13
Training loss: 4.851192933287292
Validation loss: 3.7273977422884372

Epoch: 11| Step: 0
Training loss: 4.066125982851841
Validation loss: 3.730005752960205

Epoch: 6| Step: 1
Training loss: 4.629866230888099
Validation loss: 3.717120156657913

Epoch: 6| Step: 2
Training loss: 4.387554792187029
Validation loss: 3.716921978773122

Epoch: 6| Step: 3
Training loss: 3.056144971544571
Validation loss: 3.709910633992209

Epoch: 6| Step: 4
Training loss: 3.7863367088265436
Validation loss: 3.705158246420195

Epoch: 6| Step: 5
Training loss: 4.155796571248593
Validation loss: 3.6990611561718825

Epoch: 6| Step: 6
Training loss: 4.427088599108388
Validation loss: 3.6993959071754614

Epoch: 6| Step: 7
Training loss: 3.56192467042582
Validation loss: 3.6973143892890508

Epoch: 6| Step: 8
Training loss: 3.9771011077712806
Validation loss: 3.6879217519481573

Epoch: 6| Step: 9
Training loss: 3.8306674533059355
Validation loss: 3.686604489279814

Epoch: 6| Step: 10
Training loss: 3.7429583239425077
Validation loss: 3.6839050322211353

Epoch: 6| Step: 11
Training loss: 3.0763064206687303
Validation loss: 3.6729614144711955

Epoch: 6| Step: 12
Training loss: 3.498185095939622
Validation loss: 3.669343690338021

Epoch: 6| Step: 13
Training loss: 3.7866763437398197
Validation loss: 3.6681685124373336

Epoch: 12| Step: 0
Training loss: 4.22850344614297
Validation loss: 3.663590401127384

Epoch: 6| Step: 1
Training loss: 3.0782864136175982
Validation loss: 3.6596274211504896

Epoch: 6| Step: 2
Training loss: 4.9698805572464115
Validation loss: 3.6533223910205654

Epoch: 6| Step: 3
Training loss: 3.81756030841348
Validation loss: 3.651112278228603

Epoch: 6| Step: 4
Training loss: 4.228333389548869
Validation loss: 3.647200823626659

Epoch: 6| Step: 5
Training loss: 3.1145543806246447
Validation loss: 3.644191819384331

Epoch: 6| Step: 6
Training loss: 3.3738678340114263
Validation loss: 3.6396057287876125

Epoch: 6| Step: 7
Training loss: 3.4856679937875668
Validation loss: 3.6371447339888663

Epoch: 6| Step: 8
Training loss: 3.2826029576746523
Validation loss: 3.6319696160207853

Epoch: 6| Step: 9
Training loss: 3.062742106929999
Validation loss: 3.630307152426908

Epoch: 6| Step: 10
Training loss: 3.0901662704028325
Validation loss: 3.627622630898123

Epoch: 6| Step: 11
Training loss: 5.5491227015040545
Validation loss: 3.6292177005271413

Epoch: 6| Step: 12
Training loss: 3.8379633073985984
Validation loss: 3.620539069269224

Epoch: 6| Step: 13
Training loss: 3.3891300122583425
Validation loss: 3.6157238924362645

Epoch: 13| Step: 0
Training loss: 2.8814344963533185
Validation loss: 3.615440906427606

Epoch: 6| Step: 1
Training loss: 3.4553337110455047
Validation loss: 3.614744782761496

Epoch: 6| Step: 2
Training loss: 4.045161646759383
Validation loss: 3.6108756278608523

Epoch: 6| Step: 3
Training loss: 3.9247080992018284
Validation loss: 3.603390488395869

Epoch: 6| Step: 4
Training loss: 3.7139171323143767
Validation loss: 3.5997587045064883

Epoch: 6| Step: 5
Training loss: 3.156756671990609
Validation loss: 3.594859564273067

Epoch: 6| Step: 6
Training loss: 4.084831481968869
Validation loss: 3.598729535640175

Epoch: 6| Step: 7
Training loss: 3.8464115511316144
Validation loss: 3.5875377790672753

Epoch: 6| Step: 8
Training loss: 3.3961481209793174
Validation loss: 3.5848834659597606

Epoch: 6| Step: 9
Training loss: 4.335522001136526
Validation loss: 3.5802645772498414

Epoch: 6| Step: 10
Training loss: 4.126620350106855
Validation loss: 3.5779774100678705

Epoch: 6| Step: 11
Training loss: 4.338933895679239
Validation loss: 3.5775845801042006

Epoch: 6| Step: 12
Training loss: 3.5830932507188766
Validation loss: 3.57459012168884

Epoch: 6| Step: 13
Training loss: 3.9335036812010196
Validation loss: 3.57576445324431

Epoch: 14| Step: 0
Training loss: 3.4452251674110643
Validation loss: 3.5664547318943596

Epoch: 6| Step: 1
Training loss: 3.6781946219415693
Validation loss: 3.564174295359454

Epoch: 6| Step: 2
Training loss: 4.88469573058252
Validation loss: 3.563421047210147

Epoch: 6| Step: 3
Training loss: 3.420403847971074
Validation loss: 3.5628111695661695

Epoch: 6| Step: 4
Training loss: 4.043424453484342
Validation loss: 3.561612647466512

Epoch: 6| Step: 5
Training loss: 3.854192180377264
Validation loss: 3.5526045935017945

Epoch: 6| Step: 6
Training loss: 3.4053899396654
Validation loss: 3.5483733595491747

Epoch: 6| Step: 7
Training loss: 4.110727993981471
Validation loss: 3.549024140318561

Epoch: 6| Step: 8
Training loss: 4.110430563767702
Validation loss: 3.548145673902006

Epoch: 6| Step: 9
Training loss: 3.9500442985271884
Validation loss: 3.545384424014651

Epoch: 6| Step: 10
Training loss: 2.908159510565334
Validation loss: 3.5394787819623694

Epoch: 6| Step: 11
Training loss: 3.7926707911901185
Validation loss: 3.541238826748865

Epoch: 6| Step: 12
Training loss: 2.74948028508548
Validation loss: 3.537034130013515

Epoch: 6| Step: 13
Training loss: 3.7468306818004273
Validation loss: 3.536220976736964

Epoch: 15| Step: 0
Training loss: 3.6289731318261524
Validation loss: 3.5397384162170407

Epoch: 6| Step: 1
Training loss: 3.9601213265145465
Validation loss: 3.5377968862170603

Epoch: 6| Step: 2
Training loss: 3.9115269532599544
Validation loss: 3.537461470637582

Epoch: 6| Step: 3
Training loss: 3.821339849402158
Validation loss: 3.5281096308459987

Epoch: 6| Step: 4
Training loss: 4.033551172936481
Validation loss: 3.5278670193884145

Epoch: 6| Step: 5
Training loss: 2.8311831973786403
Validation loss: 3.526830275697124

Epoch: 6| Step: 6
Training loss: 3.6421251603416582
Validation loss: 3.527561943262849

Epoch: 6| Step: 7
Training loss: 4.103809838185522
Validation loss: 3.527416290233933

Epoch: 6| Step: 8
Training loss: 3.349570369215311
Validation loss: 3.525324317431949

Epoch: 6| Step: 9
Training loss: 3.224356943528397
Validation loss: 3.5263919153182353

Epoch: 6| Step: 10
Training loss: 4.117144184499969
Validation loss: 3.51994134960833

Epoch: 6| Step: 11
Training loss: 4.024537167683074
Validation loss: 3.5153994324944433

Epoch: 6| Step: 12
Training loss: 3.4566342573078144
Validation loss: 3.514587925361127

Epoch: 6| Step: 13
Training loss: 4.038111089515078
Validation loss: 3.512770302320468

Epoch: 16| Step: 0
Training loss: 3.819987589431495
Validation loss: 3.5137926175207825

Epoch: 6| Step: 1
Training loss: 4.292930984678065
Validation loss: 3.512612450506473

Epoch: 6| Step: 2
Training loss: 3.1000948491506626
Validation loss: 3.5103556202686192

Epoch: 6| Step: 3
Training loss: 4.034770286100149
Validation loss: 3.508940014085232

Epoch: 6| Step: 4
Training loss: 3.949465780710466
Validation loss: 3.5070380630324465

Epoch: 6| Step: 5
Training loss: 3.8966855563665015
Validation loss: 3.506288197390327

Epoch: 6| Step: 6
Training loss: 3.2461124056981214
Validation loss: 3.5048605178843806

Epoch: 6| Step: 7
Training loss: 3.059937942972659
Validation loss: 3.506256105382087

Epoch: 6| Step: 8
Training loss: 4.291816313767187
Validation loss: 3.501842807641139

Epoch: 6| Step: 9
Training loss: 3.2430221770096135
Validation loss: 3.503754235719605

Epoch: 6| Step: 10
Training loss: 3.9465463049895613
Validation loss: 3.500077204284941

Epoch: 6| Step: 11
Training loss: 4.093369327929497
Validation loss: 3.5014068000024694

Epoch: 6| Step: 12
Training loss: 3.1216935021964076
Validation loss: 3.498485070323825

Epoch: 6| Step: 13
Training loss: 3.529313898599646
Validation loss: 3.4997929601183824

Epoch: 17| Step: 0
Training loss: 3.56319313668017
Validation loss: 3.4969480982005092

Epoch: 6| Step: 1
Training loss: 3.151139455912015
Validation loss: 3.496969038634798

Epoch: 6| Step: 2
Training loss: 4.069776151907589
Validation loss: 3.496885374383492

Epoch: 6| Step: 3
Training loss: 3.41263101626678
Validation loss: 3.4985307724181887

Epoch: 6| Step: 4
Training loss: 3.2384991727789347
Validation loss: 3.4918158926884475

Epoch: 6| Step: 5
Training loss: 4.104615679091878
Validation loss: 3.4927230416614963

Epoch: 6| Step: 6
Training loss: 3.3499259598933793
Validation loss: 3.494603962113111

Epoch: 6| Step: 7
Training loss: 3.1350877828035038
Validation loss: 3.4932053266388805

Epoch: 6| Step: 8
Training loss: 3.8009077092271655
Validation loss: 3.4908337785151744

Epoch: 6| Step: 9
Training loss: 4.251776828711954
Validation loss: 3.4916219977218788

Epoch: 6| Step: 10
Training loss: 4.858408350335365
Validation loss: 3.4914497733578234

Epoch: 6| Step: 11
Training loss: 2.672104853508659
Validation loss: 3.487414287093543

Epoch: 6| Step: 12
Training loss: 4.25878268046558
Validation loss: 3.4857880574309115

Epoch: 6| Step: 13
Training loss: 3.178574275816106
Validation loss: 3.4856060245966223

Epoch: 18| Step: 0
Training loss: 4.4197667356362285
Validation loss: 3.4867869668203753

Epoch: 6| Step: 1
Training loss: 3.605924203525674
Validation loss: 3.4853393597503395

Epoch: 6| Step: 2
Training loss: 3.7730171806698527
Validation loss: 3.4853796985385066

Epoch: 6| Step: 3
Training loss: 4.027443441494675
Validation loss: 3.4848692425869143

Epoch: 6| Step: 4
Training loss: 3.86373568524486
Validation loss: 3.48072883668425

Epoch: 6| Step: 5
Training loss: 2.816995715120772
Validation loss: 3.4800427837945533

Epoch: 6| Step: 6
Training loss: 4.023380138395713
Validation loss: 3.480374529942153

Epoch: 6| Step: 7
Training loss: 3.446762091412014
Validation loss: 3.480616504636718

Epoch: 6| Step: 8
Training loss: 3.3779131714416266
Validation loss: 3.477994632373776

Epoch: 6| Step: 9
Training loss: 3.127257790338277
Validation loss: 3.4772040023798967

Epoch: 6| Step: 10
Training loss: 3.331507007640171
Validation loss: 3.476037234991617

Epoch: 6| Step: 11
Training loss: 3.7490324679576705
Validation loss: 3.4748885848559357

Epoch: 6| Step: 12
Training loss: 4.182541601837169
Validation loss: 3.4754330857783433

Epoch: 6| Step: 13
Training loss: 3.7049151894029837
Validation loss: 3.4736564942835213

Epoch: 19| Step: 0
Training loss: 4.083492094314151
Validation loss: 3.472532318597271

Epoch: 6| Step: 1
Training loss: 4.151930550716574
Validation loss: 3.4718429314516346

Epoch: 6| Step: 2
Training loss: 4.049221463196081
Validation loss: 3.470166869738114

Epoch: 6| Step: 3
Training loss: 3.481860018690915
Validation loss: 3.469470266296882

Epoch: 6| Step: 4
Training loss: 3.3120766135214095
Validation loss: 3.4696227511790805

Epoch: 6| Step: 5
Training loss: 2.9259520456656762
Validation loss: 3.4692908754735448

Epoch: 6| Step: 6
Training loss: 3.6688855277768173
Validation loss: 3.467375702106929

Epoch: 6| Step: 7
Training loss: 3.813853039395136
Validation loss: 3.4673646678732584

Epoch: 6| Step: 8
Training loss: 3.7125430839941367
Validation loss: 3.4658940989813156

Epoch: 6| Step: 9
Training loss: 3.9637500175156077
Validation loss: 3.4682302310047817

Epoch: 6| Step: 10
Training loss: 3.2916772737613824
Validation loss: 3.4648864434924795

Epoch: 6| Step: 11
Training loss: 3.9355892813317053
Validation loss: 3.4632612854005695

Epoch: 6| Step: 12
Training loss: 3.3314278560489035
Validation loss: 3.4631602650085247

Epoch: 6| Step: 13
Training loss: 3.625398942765011
Validation loss: 3.461881237747135

Epoch: 20| Step: 0
Training loss: 3.370166001122507
Validation loss: 3.461024325750253

Epoch: 6| Step: 1
Training loss: 3.3428617349297327
Validation loss: 3.460773945723942

Epoch: 6| Step: 2
Training loss: 3.5318289763193165
Validation loss: 3.4594794631538925

Epoch: 6| Step: 3
Training loss: 3.8193355629554278
Validation loss: 3.457522183851315

Epoch: 6| Step: 4
Training loss: 3.8991957788969724
Validation loss: 3.4605035245192477

Epoch: 6| Step: 5
Training loss: 4.15336772820777
Validation loss: 3.458306087223978

Epoch: 6| Step: 6
Training loss: 3.883608945526372
Validation loss: 3.4556628587772424

Epoch: 6| Step: 7
Training loss: 3.117964798234936
Validation loss: 3.455987343384413

Epoch: 6| Step: 8
Training loss: 3.976709868992345
Validation loss: 3.4561095759966367

Epoch: 6| Step: 9
Training loss: 4.05359718789906
Validation loss: 3.456848312477432

Epoch: 6| Step: 10
Training loss: 3.296430657260213
Validation loss: 3.456016786660832

Epoch: 6| Step: 11
Training loss: 4.094142516443008
Validation loss: 3.4541777486816465

Epoch: 6| Step: 12
Training loss: 2.905241268204252
Validation loss: 3.454594190580233

Epoch: 6| Step: 13
Training loss: 3.8068442997237053
Validation loss: 3.454289338922001

Epoch: 21| Step: 0
Training loss: 3.126071288542506
Validation loss: 3.4502739106062026

Epoch: 6| Step: 1
Training loss: 2.786579554883036
Validation loss: 3.4537157384825443

Epoch: 6| Step: 2
Training loss: 3.469821661288231
Validation loss: 3.452663708757534

Epoch: 6| Step: 3
Training loss: 3.512597980693864
Validation loss: 3.450796312916098

Epoch: 6| Step: 4
Training loss: 4.096423957490479
Validation loss: 3.451468232898694

Epoch: 6| Step: 5
Training loss: 3.670181858016118
Validation loss: 3.448703121623773

Epoch: 6| Step: 6
Training loss: 3.398328897779812
Validation loss: 3.449035405533826

Epoch: 6| Step: 7
Training loss: 4.448515209273615
Validation loss: 3.4488883822036924

Epoch: 6| Step: 8
Training loss: 4.081226557946172
Validation loss: 3.448450961958988

Epoch: 6| Step: 9
Training loss: 4.071166434011615
Validation loss: 3.449202289889727

Epoch: 6| Step: 10
Training loss: 3.942690138310821
Validation loss: 3.448552770069116

Epoch: 6| Step: 11
Training loss: 3.2940647387463042
Validation loss: 3.4470016434657835

Epoch: 6| Step: 12
Training loss: 3.7724153070062627
Validation loss: 3.4460574344091977

Epoch: 6| Step: 13
Training loss: 3.0588961825653533
Validation loss: 3.4454590509054466

Epoch: 22| Step: 0
Training loss: 3.1153277439965525
Validation loss: 3.4448313314409598

Epoch: 6| Step: 1
Training loss: 3.4306061020669603
Validation loss: 3.4453405805517767

Epoch: 6| Step: 2
Training loss: 3.067234972111773
Validation loss: 3.4460726820547234

Epoch: 6| Step: 3
Training loss: 3.102040290064209
Validation loss: 3.447331317530271

Epoch: 6| Step: 4
Training loss: 3.9425020688861263
Validation loss: 3.4483082970871335

Epoch: 6| Step: 5
Training loss: 3.7146712302211635
Validation loss: 3.443529500446254

Epoch: 6| Step: 6
Training loss: 4.248338935721649
Validation loss: 3.4405354362562184

Epoch: 6| Step: 7
Training loss: 3.9912179863300246
Validation loss: 3.4422130980932617

Epoch: 6| Step: 8
Training loss: 4.1033924489187905
Validation loss: 3.4411507395570706

Epoch: 6| Step: 9
Training loss: 3.895516380975786
Validation loss: 3.442980481210731

Epoch: 6| Step: 10
Training loss: 3.8877075777720362
Validation loss: 3.440440070422471

Epoch: 6| Step: 11
Training loss: 3.6251675797236054
Validation loss: 3.4391019770642792

Epoch: 6| Step: 12
Training loss: 3.844577483139694
Validation loss: 3.4392031540073855

Epoch: 6| Step: 13
Training loss: 2.3636588307293245
Validation loss: 3.4351265791447556

Epoch: 23| Step: 0
Training loss: 3.902930840823905
Validation loss: 3.4397312727392917

Epoch: 6| Step: 1
Training loss: 3.541351857873234
Validation loss: 3.438115973299508

Epoch: 6| Step: 2
Training loss: 3.720028825668714
Validation loss: 3.43752814287913

Epoch: 6| Step: 3
Training loss: 3.02923170716896
Validation loss: 3.4355732325408694

Epoch: 6| Step: 4
Training loss: 3.0270526573760397
Validation loss: 3.4395259551251853

Epoch: 6| Step: 5
Training loss: 3.5301821284007677
Validation loss: 3.4416179673102563

Epoch: 6| Step: 6
Training loss: 3.424160964551349
Validation loss: 3.436586969111793

Epoch: 6| Step: 7
Training loss: 4.466028838854216
Validation loss: 3.434578736614255

Epoch: 6| Step: 8
Training loss: 4.45405049661721
Validation loss: 3.4317618676696595

Epoch: 6| Step: 9
Training loss: 3.4419165242705096
Validation loss: 3.432292426531223

Epoch: 6| Step: 10
Training loss: 3.369164402090012
Validation loss: 3.4326763387845984

Epoch: 6| Step: 11
Training loss: 3.4760208222234175
Validation loss: 3.4325745616765775

Epoch: 6| Step: 12
Training loss: 3.7483829826661537
Validation loss: 3.4312185013060446

Epoch: 6| Step: 13
Training loss: 3.804710059128449
Validation loss: 3.430709412668869

Epoch: 24| Step: 0
Training loss: 3.4581240548539847
Validation loss: 3.431193455196331

Epoch: 6| Step: 1
Training loss: 3.8859582818384033
Validation loss: 3.4282323055329385

Epoch: 6| Step: 2
Training loss: 3.3951429511692894
Validation loss: 3.4285314015145882

Epoch: 6| Step: 3
Training loss: 2.8010470850731215
Validation loss: 3.4262831770833353

Epoch: 6| Step: 4
Training loss: 4.044344902793161
Validation loss: 3.425879164074849

Epoch: 6| Step: 5
Training loss: 3.5588716467542474
Validation loss: 3.4281021390657385

Epoch: 6| Step: 6
Training loss: 3.30372594818124
Validation loss: 3.428956553508356

Epoch: 6| Step: 7
Training loss: 4.046901393495013
Validation loss: 3.4255132583561627

Epoch: 6| Step: 8
Training loss: 3.600004376302814
Validation loss: 3.426712170631494

Epoch: 6| Step: 9
Training loss: 3.843141833318278
Validation loss: 3.4260719398522883

Epoch: 6| Step: 10
Training loss: 4.450543214024816
Validation loss: 3.4220629101205193

Epoch: 6| Step: 11
Training loss: 3.658720437136675
Validation loss: 3.4224433256529876

Epoch: 6| Step: 12
Training loss: 3.14403504431221
Validation loss: 3.4217255509561526

Epoch: 6| Step: 13
Training loss: 3.5818109309374373
Validation loss: 3.421332230438282

Epoch: 25| Step: 0
Training loss: 3.797916348042826
Validation loss: 3.4209008116162924

Epoch: 6| Step: 1
Training loss: 3.117962810115944
Validation loss: 3.4200508761116413

Epoch: 6| Step: 2
Training loss: 3.110209444113834
Validation loss: 3.4194149746117852

Epoch: 6| Step: 3
Training loss: 2.9030159624891483
Validation loss: 3.4181668739381323

Epoch: 6| Step: 4
Training loss: 3.7274571910219008
Validation loss: 3.419682177966098

Epoch: 6| Step: 5
Training loss: 3.1973825478773574
Validation loss: 3.420885616644023

Epoch: 6| Step: 6
Training loss: 3.748506502929192
Validation loss: 3.4216881719413847

Epoch: 6| Step: 7
Training loss: 3.66369705167141
Validation loss: 3.422235388720038

Epoch: 6| Step: 8
Training loss: 3.5054230229842958
Validation loss: 3.4171858307312366

Epoch: 6| Step: 9
Training loss: 4.667498832257068
Validation loss: 3.41547091099093

Epoch: 6| Step: 10
Training loss: 3.4452875876012583
Validation loss: 3.4155151733818667

Epoch: 6| Step: 11
Training loss: 4.142870484880283
Validation loss: 3.417125191423305

Epoch: 6| Step: 12
Training loss: 3.4918386127193553
Validation loss: 3.41671272209775

Epoch: 6| Step: 13
Training loss: 4.439168482062129
Validation loss: 3.416698802813874

Epoch: 26| Step: 0
Training loss: 3.7002120653157307
Validation loss: 3.415085623819952

Epoch: 6| Step: 1
Training loss: 3.6856917780868006
Validation loss: 3.4136273041084837

Epoch: 6| Step: 2
Training loss: 4.636720806786612
Validation loss: 3.4126854898833145

Epoch: 6| Step: 3
Training loss: 3.723828222318196
Validation loss: 3.4133133167963683

Epoch: 6| Step: 4
Training loss: 3.120907201431778
Validation loss: 3.4107357795164415

Epoch: 6| Step: 5
Training loss: 3.43451227915145
Validation loss: 3.4115680154983

Epoch: 6| Step: 6
Training loss: 3.8313275078903506
Validation loss: 3.4109360086565186

Epoch: 6| Step: 7
Training loss: 3.146261897589369
Validation loss: 3.410580645299581

Epoch: 6| Step: 8
Training loss: 3.151506088122649
Validation loss: 3.414003667495574

Epoch: 6| Step: 9
Training loss: 3.5784722705218153
Validation loss: 3.413514971900098

Epoch: 6| Step: 10
Training loss: 4.738115803093608
Validation loss: 3.409827649135218

Epoch: 6| Step: 11
Training loss: 3.147983717104378
Validation loss: 3.4102356686769695

Epoch: 6| Step: 12
Training loss: 3.43185266090449
Validation loss: 3.4088739556431054

Epoch: 6| Step: 13
Training loss: 2.614196708230138
Validation loss: 3.4058775971519966

Epoch: 27| Step: 0
Training loss: 4.359591352228194
Validation loss: 3.4061813806683814

Epoch: 6| Step: 1
Training loss: 4.451843934085308
Validation loss: 3.404738519950778

Epoch: 6| Step: 2
Training loss: 3.7181899987440468
Validation loss: 3.404980700239411

Epoch: 6| Step: 3
Training loss: 3.2168662475443153
Validation loss: 3.4057854084095602

Epoch: 6| Step: 4
Training loss: 3.5342162510629347
Validation loss: 3.4043800781034768

Epoch: 6| Step: 5
Training loss: 3.346690373533056
Validation loss: 3.4023454770044643

Epoch: 6| Step: 6
Training loss: 2.6672103049538576
Validation loss: 3.4042572201227093

Epoch: 6| Step: 7
Training loss: 4.058800524087866
Validation loss: 3.403990519320353

Epoch: 6| Step: 8
Training loss: 3.8374935187368924
Validation loss: 3.403952838610767

Epoch: 6| Step: 9
Training loss: 4.137171964520411
Validation loss: 3.402490192644612

Epoch: 6| Step: 10
Training loss: 2.6586694805828013
Validation loss: 3.402092539875918

Epoch: 6| Step: 11
Training loss: 2.612658416471558
Validation loss: 3.4020416192302476

Epoch: 6| Step: 12
Training loss: 3.9550928336917854
Validation loss: 3.400165444172569

Epoch: 6| Step: 13
Training loss: 3.5747927679006875
Validation loss: 3.3986587371308197

Epoch: 28| Step: 0
Training loss: 4.494954989911259
Validation loss: 3.4007203096131082

Epoch: 6| Step: 1
Training loss: 3.4217735519351153
Validation loss: 3.3985391724431424

Epoch: 6| Step: 2
Training loss: 3.2418445084011034
Validation loss: 3.3979327830233617

Epoch: 6| Step: 3
Training loss: 3.3746011286379884
Validation loss: 3.398034917201362

Epoch: 6| Step: 4
Training loss: 3.73307107163184
Validation loss: 3.3960147620214274

Epoch: 6| Step: 5
Training loss: 3.740460277936435
Validation loss: 3.3993017734389497

Epoch: 6| Step: 6
Training loss: 3.3698124047200864
Validation loss: 3.396218359131087

Epoch: 6| Step: 7
Training loss: 3.2860752049649666
Validation loss: 3.394555463992108

Epoch: 6| Step: 8
Training loss: 3.5731671897021506
Validation loss: 3.394348634292647

Epoch: 6| Step: 9
Training loss: 3.6057410504144696
Validation loss: 3.394284919342561

Epoch: 6| Step: 10
Training loss: 3.6143076825457023
Validation loss: 3.394537983594583

Epoch: 6| Step: 11
Training loss: 4.147175455024871
Validation loss: 3.3931776183914417

Epoch: 6| Step: 12
Training loss: 3.0505614842619866
Validation loss: 3.3936474139662938

Epoch: 6| Step: 13
Training loss: 4.001432877436761
Validation loss: 3.3914301157229825

Epoch: 29| Step: 0
Training loss: 2.779498288006709
Validation loss: 3.3921223458723597

Epoch: 6| Step: 1
Training loss: 3.681781278397456
Validation loss: 3.392483623680723

Epoch: 6| Step: 2
Training loss: 4.020479229502782
Validation loss: 3.3896830220780454

Epoch: 6| Step: 3
Training loss: 2.740025203059877
Validation loss: 3.3918835964662435

Epoch: 6| Step: 4
Training loss: 4.335267051206124
Validation loss: 3.3893643311367936

Epoch: 6| Step: 5
Training loss: 4.350931721142152
Validation loss: 3.389939796694096

Epoch: 6| Step: 6
Training loss: 3.725789179826498
Validation loss: 3.3870954891012928

Epoch: 6| Step: 7
Training loss: 2.421173584795184
Validation loss: 3.390420454530023

Epoch: 6| Step: 8
Training loss: 3.6687806422239033
Validation loss: 3.3881845331204086

Epoch: 6| Step: 9
Training loss: 3.4987185720958633
Validation loss: 3.388372007022713

Epoch: 6| Step: 10
Training loss: 3.252925729648973
Validation loss: 3.386536616123605

Epoch: 6| Step: 11
Training loss: 4.681583587209909
Validation loss: 3.3883278697456216

Epoch: 6| Step: 12
Training loss: 3.178522069801903
Validation loss: 3.386400671887057

Epoch: 6| Step: 13
Training loss: 3.4764035306439234
Validation loss: 3.3853192977849216

Epoch: 30| Step: 0
Training loss: 4.085646434795984
Validation loss: 3.386846324101206

Epoch: 6| Step: 1
Training loss: 2.7906141052375166
Validation loss: 3.382219084196525

Epoch: 6| Step: 2
Training loss: 3.3067614673540544
Validation loss: 3.385981207917273

Epoch: 6| Step: 3
Training loss: 3.456396702003561
Validation loss: 3.382935177393797

Epoch: 6| Step: 4
Training loss: 3.469869621971616
Validation loss: 3.3821033832565517

Epoch: 6| Step: 5
Training loss: 4.564129682057541
Validation loss: 3.3845096379593316

Epoch: 6| Step: 6
Training loss: 2.7919414631738007
Validation loss: 3.382895937480813

Epoch: 6| Step: 7
Training loss: 3.411024195101863
Validation loss: 3.3817029283933

Epoch: 6| Step: 8
Training loss: 4.3242202937977146
Validation loss: 3.381025539047074

Epoch: 6| Step: 9
Training loss: 4.091764012024953
Validation loss: 3.380271498573134

Epoch: 6| Step: 10
Training loss: 3.3107807808222685
Validation loss: 3.378709226155287

Epoch: 6| Step: 11
Training loss: 3.302443299193003
Validation loss: 3.3798557506337046

Epoch: 6| Step: 12
Training loss: 2.965511764438714
Validation loss: 3.3785791503727025

Epoch: 6| Step: 13
Training loss: 4.477107842000933
Validation loss: 3.380148230002099

Epoch: 31| Step: 0
Training loss: 3.331270978621795
Validation loss: 3.379122622166106

Epoch: 6| Step: 1
Training loss: 3.3149491379001934
Validation loss: 3.37760124851893

Epoch: 6| Step: 2
Training loss: 3.5783243581881092
Validation loss: 3.3782930719579976

Epoch: 6| Step: 3
Training loss: 3.584608841629077
Validation loss: 3.3756100214585003

Epoch: 6| Step: 4
Training loss: 4.74178788891098
Validation loss: 3.3754129677458793

Epoch: 6| Step: 5
Training loss: 3.298051235580589
Validation loss: 3.374816084347085

Epoch: 6| Step: 6
Training loss: 2.848006531740049
Validation loss: 3.3755003247991007

Epoch: 6| Step: 7
Training loss: 3.7345025587442153
Validation loss: 3.3726173628707903

Epoch: 6| Step: 8
Training loss: 2.7597037684371792
Validation loss: 3.3741453722612857

Epoch: 6| Step: 9
Training loss: 4.112449047387505
Validation loss: 3.371366786835104

Epoch: 6| Step: 10
Training loss: 4.226304361918379
Validation loss: 3.371142619444941

Epoch: 6| Step: 11
Training loss: 3.3980418007779103
Validation loss: 3.3698848897796005

Epoch: 6| Step: 12
Training loss: 3.501521461038652
Validation loss: 3.373587111682692

Epoch: 6| Step: 13
Training loss: 3.5347092150882076
Validation loss: 3.3733138608931843

Epoch: 32| Step: 0
Training loss: 3.158246909966275
Validation loss: 3.372999652046726

Epoch: 6| Step: 1
Training loss: 4.007978588328779
Validation loss: 3.3704376572770944

Epoch: 6| Step: 2
Training loss: 3.760441168003448
Validation loss: 3.3687088431778798

Epoch: 6| Step: 3
Training loss: 3.73976824771681
Validation loss: 3.3677889006068993

Epoch: 6| Step: 4
Training loss: 3.262555445642062
Validation loss: 3.3665127170038214

Epoch: 6| Step: 5
Training loss: 3.6955197298361697
Validation loss: 3.3652561837830217

Epoch: 6| Step: 6
Training loss: 2.6957532439404717
Validation loss: 3.3617713281717325

Epoch: 6| Step: 7
Training loss: 3.4403109068428956
Validation loss: 3.361498666597324

Epoch: 6| Step: 8
Training loss: 3.5782691893197964
Validation loss: 3.3598172765919854

Epoch: 6| Step: 9
Training loss: 4.183468828375357
Validation loss: 3.3603979027661524

Epoch: 6| Step: 10
Training loss: 3.3654612211793804
Validation loss: 3.359982193801018

Epoch: 6| Step: 11
Training loss: 3.8608647610193314
Validation loss: 3.3619897669604435

Epoch: 6| Step: 12
Training loss: 3.90530213109145
Validation loss: 3.3708345495622583

Epoch: 6| Step: 13
Training loss: 3.259881330097143
Validation loss: 3.3564286433673463

Epoch: 33| Step: 0
Training loss: 2.9309359319186283
Validation loss: 3.354922889163326

Epoch: 6| Step: 1
Training loss: 3.776953660296399
Validation loss: 3.355392721644858

Epoch: 6| Step: 2
Training loss: 2.934548051340274
Validation loss: 3.3573651226334214

Epoch: 6| Step: 3
Training loss: 4.567859793587372
Validation loss: 3.3641084786560813

Epoch: 6| Step: 4
Training loss: 3.3546769758964667
Validation loss: 3.3554639718240895

Epoch: 6| Step: 5
Training loss: 3.5731982832862337
Validation loss: 3.354812373170544

Epoch: 6| Step: 6
Training loss: 3.952674568659497
Validation loss: 3.356344204200793

Epoch: 6| Step: 7
Training loss: 3.514157679902646
Validation loss: 3.359891805462106

Epoch: 6| Step: 8
Training loss: 3.1068067823037144
Validation loss: 3.361131709102454

Epoch: 6| Step: 9
Training loss: 3.801358060596028
Validation loss: 3.3505867791451323

Epoch: 6| Step: 10
Training loss: 2.8375962295683554
Validation loss: 3.350092566993881

Epoch: 6| Step: 11
Training loss: 3.4635691400265336
Validation loss: 3.3478512756168004

Epoch: 6| Step: 12
Training loss: 3.8303338354051353
Validation loss: 3.35072332638215

Epoch: 6| Step: 13
Training loss: 4.531457093866683
Validation loss: 3.348855652680949

Epoch: 34| Step: 0
Training loss: 3.2054661080677023
Validation loss: 3.3486223317165913

Epoch: 6| Step: 1
Training loss: 3.1529808109763
Validation loss: 3.352965536090127

Epoch: 6| Step: 2
Training loss: 3.691590707196952
Validation loss: 3.346004671647679

Epoch: 6| Step: 3
Training loss: 3.000735669533497
Validation loss: 3.347520689644376

Epoch: 6| Step: 4
Training loss: 3.4535587090207156
Validation loss: 3.355811721827223

Epoch: 6| Step: 5
Training loss: 3.862117642239179
Validation loss: 3.352810200115673

Epoch: 6| Step: 6
Training loss: 3.5356957461268763
Validation loss: 3.3505538752538175

Epoch: 6| Step: 7
Training loss: 3.4986894061097797
Validation loss: 3.347732741988389

Epoch: 6| Step: 8
Training loss: 3.527219514570547
Validation loss: 3.3420492697728124

Epoch: 6| Step: 9
Training loss: 3.9011217558125915
Validation loss: 3.343462416731409

Epoch: 6| Step: 10
Training loss: 2.522362542088605
Validation loss: 3.3442211200660434

Epoch: 6| Step: 11
Training loss: 4.262206332027165
Validation loss: 3.3437879834506146

Epoch: 6| Step: 12
Training loss: 4.4835478654511975
Validation loss: 3.3420244943235375

Epoch: 6| Step: 13
Training loss: 3.5537389810225593
Validation loss: 3.342723147093325

Epoch: 35| Step: 0
Training loss: 3.2429804188539766
Validation loss: 3.3403822298719774

Epoch: 6| Step: 1
Training loss: 3.070681173694755
Validation loss: 3.337541883395629

Epoch: 6| Step: 2
Training loss: 3.3090141236507318
Validation loss: 3.338808041226775

Epoch: 6| Step: 3
Training loss: 3.969065495964369
Validation loss: 3.338231840998882

Epoch: 6| Step: 4
Training loss: 3.1178055917694496
Validation loss: 3.3364790076147997

Epoch: 6| Step: 5
Training loss: 3.753224830030285
Validation loss: 3.339300331321819

Epoch: 6| Step: 6
Training loss: 4.413542860383746
Validation loss: 3.341331684637294

Epoch: 6| Step: 7
Training loss: 2.9662905493921334
Validation loss: 3.3406974944313257

Epoch: 6| Step: 8
Training loss: 3.514435019960034
Validation loss: 3.3391728861831127

Epoch: 6| Step: 9
Training loss: 3.8325586918407146
Validation loss: 3.337370112983692

Epoch: 6| Step: 10
Training loss: 3.359857710822751
Validation loss: 3.3364583569172264

Epoch: 6| Step: 11
Training loss: 3.6496062602001587
Validation loss: 3.332753056090961

Epoch: 6| Step: 12
Training loss: 3.6462028243524687
Validation loss: 3.335526871092139

Epoch: 6| Step: 13
Training loss: 4.095886371899102
Validation loss: 3.3356239913317935

Epoch: 36| Step: 0
Training loss: 4.209322419719627
Validation loss: 3.333662483412684

Epoch: 6| Step: 1
Training loss: 2.292203551316179
Validation loss: 3.3302222351373016

Epoch: 6| Step: 2
Training loss: 3.5634060426959584
Validation loss: 3.331862201664593

Epoch: 6| Step: 3
Training loss: 3.671820717268307
Validation loss: 3.332134330105359

Epoch: 6| Step: 4
Training loss: 3.8990152729730303
Validation loss: 3.3294121957125142

Epoch: 6| Step: 5
Training loss: 3.1172375208921306
Validation loss: 3.3309704932727637

Epoch: 6| Step: 6
Training loss: 3.8021688094612065
Validation loss: 3.3308425708652623

Epoch: 6| Step: 7
Training loss: 3.1695014077752295
Validation loss: 3.3301605850483513

Epoch: 6| Step: 8
Training loss: 2.852587037693537
Validation loss: 3.3282026572331223

Epoch: 6| Step: 9
Training loss: 4.3398903364398755
Validation loss: 3.3293356662746194

Epoch: 6| Step: 10
Training loss: 3.669307249207528
Validation loss: 3.3291319446959755

Epoch: 6| Step: 11
Training loss: 3.4343095712442895
Validation loss: 3.328023514294842

Epoch: 6| Step: 12
Training loss: 3.824114009993136
Validation loss: 3.3295177761602517

Epoch: 6| Step: 13
Training loss: 3.5177721036794427
Validation loss: 3.3328459680780034

Epoch: 37| Step: 0
Training loss: 3.3751193837844258
Validation loss: 3.3368674821525044

Epoch: 6| Step: 1
Training loss: 2.7611746461117894
Validation loss: 3.346409229878768

Epoch: 6| Step: 2
Training loss: 4.053518372963317
Validation loss: 3.337067726171514

Epoch: 6| Step: 3
Training loss: 2.499669720767354
Validation loss: 3.325047621353971

Epoch: 6| Step: 4
Training loss: 3.2184563660246948
Validation loss: 3.3236453157242423

Epoch: 6| Step: 5
Training loss: 3.785769197420479
Validation loss: 3.3346288614281154

Epoch: 6| Step: 6
Training loss: 4.177288985798567
Validation loss: 3.3399243731561294

Epoch: 6| Step: 7
Training loss: 4.2729833385982765
Validation loss: 3.3231104798329634

Epoch: 6| Step: 8
Training loss: 4.150750673721021
Validation loss: 3.3210164660936212

Epoch: 6| Step: 9
Training loss: 3.523302705812702
Validation loss: 3.325512579564623

Epoch: 6| Step: 10
Training loss: 3.5647403298248235
Validation loss: 3.3282469402094983

Epoch: 6| Step: 11
Training loss: 3.2171340886073727
Validation loss: 3.3312360800544796

Epoch: 6| Step: 12
Training loss: 3.437075224554034
Validation loss: 3.3346751647638846

Epoch: 6| Step: 13
Training loss: 3.257448317848962
Validation loss: 3.326450208238521

Epoch: 38| Step: 0
Training loss: 2.343282017080374
Validation loss: 3.32256266313986

Epoch: 6| Step: 1
Training loss: 3.574307866887647
Validation loss: 3.330786406228926

Epoch: 6| Step: 2
Training loss: 3.4307524606992907
Validation loss: 3.333692339566039

Epoch: 6| Step: 3
Training loss: 3.449750952093459
Validation loss: 3.333699988124428

Epoch: 6| Step: 4
Training loss: 2.955456333199862
Validation loss: 3.329021987154348

Epoch: 6| Step: 5
Training loss: 3.998039599674316
Validation loss: 3.3230776610700987

Epoch: 6| Step: 6
Training loss: 3.751450321755782
Validation loss: 3.3210762217853644

Epoch: 6| Step: 7
Training loss: 2.9320098217517336
Validation loss: 3.320906582597548

Epoch: 6| Step: 8
Training loss: 4.162302300051225
Validation loss: 3.318952591404876

Epoch: 6| Step: 9
Training loss: 3.02329965518698
Validation loss: 3.3139298646617994

Epoch: 6| Step: 10
Training loss: 4.166070564862772
Validation loss: 3.314508112299981

Epoch: 6| Step: 11
Training loss: 4.035202572640697
Validation loss: 3.3174455099148936

Epoch: 6| Step: 12
Training loss: 3.805561067216754
Validation loss: 3.314285473539644

Epoch: 6| Step: 13
Training loss: 3.6800022517073003
Validation loss: 3.309564011780931

Epoch: 39| Step: 0
Training loss: 2.7590208351203023
Validation loss: 3.3127379917209

Epoch: 6| Step: 1
Training loss: 3.5408486412640965
Validation loss: 3.3096846025491673

Epoch: 6| Step: 2
Training loss: 3.4574590903156115
Validation loss: 3.31155217410093

Epoch: 6| Step: 3
Training loss: 4.478932976356027
Validation loss: 3.310596929373774

Epoch: 6| Step: 4
Training loss: 4.079109160836531
Validation loss: 3.3093843262432645

Epoch: 6| Step: 5
Training loss: 3.9431813744496513
Validation loss: 3.311402350863269

Epoch: 6| Step: 6
Training loss: 3.8328177202067106
Validation loss: 3.308014183327294

Epoch: 6| Step: 7
Training loss: 3.2603047669599716
Validation loss: 3.3088622872810967

Epoch: 6| Step: 8
Training loss: 2.498783578575502
Validation loss: 3.3095690948060277

Epoch: 6| Step: 9
Training loss: 4.292696387942284
Validation loss: 3.307549178905367

Epoch: 6| Step: 10
Training loss: 2.471190200259659
Validation loss: 3.308042767519329

Epoch: 6| Step: 11
Training loss: 3.3677505057884383
Validation loss: 3.308432178896457

Epoch: 6| Step: 12
Training loss: 3.5359465837888733
Validation loss: 3.311548105162031

Epoch: 6| Step: 13
Training loss: 3.4167938829013993
Validation loss: 3.310670653616839

Epoch: 40| Step: 0
Training loss: 4.246231203214486
Validation loss: 3.308389657813162

Epoch: 6| Step: 1
Training loss: 3.1188573356306457
Validation loss: 3.30329298400458

Epoch: 6| Step: 2
Training loss: 2.8373028119508326
Validation loss: 3.305751381336992

Epoch: 6| Step: 3
Training loss: 2.264478406490266
Validation loss: 3.31059085207998

Epoch: 6| Step: 4
Training loss: 4.117453868725669
Validation loss: 3.3066998589899352

Epoch: 6| Step: 5
Training loss: 3.957978296252206
Validation loss: 3.3131620473389964

Epoch: 6| Step: 6
Training loss: 4.099641942462352
Validation loss: 3.3055095811308175

Epoch: 6| Step: 7
Training loss: 3.463434218649758
Validation loss: 3.3056661455720993

Epoch: 6| Step: 8
Training loss: 3.7337622997795243
Validation loss: 3.303620497943751

Epoch: 6| Step: 9
Training loss: 3.632570057644291
Validation loss: 3.305147739651799

Epoch: 6| Step: 10
Training loss: 3.704724960105581
Validation loss: 3.3044983506110754

Epoch: 6| Step: 11
Training loss: 3.3551262535296678
Validation loss: 3.301898365087815

Epoch: 6| Step: 12
Training loss: 3.3989246238527873
Validation loss: 3.3025550778335404

Epoch: 6| Step: 13
Training loss: 2.839438723051246
Validation loss: 3.299688485060648

Epoch: 41| Step: 0
Training loss: 4.129475333298446
Validation loss: 3.2982123296269905

Epoch: 6| Step: 1
Training loss: 3.181954889952385
Validation loss: 3.299683518116952

Epoch: 6| Step: 2
Training loss: 4.331605468959599
Validation loss: 3.3012855606166442

Epoch: 6| Step: 3
Training loss: 3.6567578085358736
Validation loss: 3.2996626425760853

Epoch: 6| Step: 4
Training loss: 3.619234696311819
Validation loss: 3.299755062983171

Epoch: 6| Step: 5
Training loss: 2.162592750280194
Validation loss: 3.303490245298434

Epoch: 6| Step: 6
Training loss: 2.871726785016848
Validation loss: 3.302172249350957

Epoch: 6| Step: 7
Training loss: 3.5826020196842006
Validation loss: 3.3025178311273593

Epoch: 6| Step: 8
Training loss: 3.1156662979373353
Validation loss: 3.2991282400148245

Epoch: 6| Step: 9
Training loss: 4.265020194861126
Validation loss: 3.300391690913117

Epoch: 6| Step: 10
Training loss: 3.2596415775528644
Validation loss: 3.3006594818988004

Epoch: 6| Step: 11
Training loss: 3.5657053130162706
Validation loss: 3.3023154121306253

Epoch: 6| Step: 12
Training loss: 3.9782459465394076
Validation loss: 3.3026387699961397

Epoch: 6| Step: 13
Training loss: 2.799508501239234
Validation loss: 3.2983758967670997

Epoch: 42| Step: 0
Training loss: 3.3339666400743884
Validation loss: 3.302915514387598

Epoch: 6| Step: 1
Training loss: 4.2284962290259545
Validation loss: 3.308580294049475

Epoch: 6| Step: 2
Training loss: 3.5569409280826045
Validation loss: 3.3097875599054487

Epoch: 6| Step: 3
Training loss: 3.4518032392384406
Validation loss: 3.294878205422

Epoch: 6| Step: 4
Training loss: 2.624704980166372
Validation loss: 3.291534212956655

Epoch: 6| Step: 5
Training loss: 3.8903470227314414
Validation loss: 3.2918388962356913

Epoch: 6| Step: 6
Training loss: 4.3306507218949015
Validation loss: 3.2945110751765663

Epoch: 6| Step: 7
Training loss: 3.382653917643703
Validation loss: 3.2944032242252947

Epoch: 6| Step: 8
Training loss: 3.146677438695972
Validation loss: 3.2900774650007922

Epoch: 6| Step: 9
Training loss: 2.9491862516317897
Validation loss: 3.2893714166362313

Epoch: 6| Step: 10
Training loss: 3.207719141311872
Validation loss: 3.290394534213606

Epoch: 6| Step: 11
Training loss: 3.4626496430709213
Validation loss: 3.2879581212223394

Epoch: 6| Step: 12
Training loss: 3.934651994839646
Validation loss: 3.289317599070835

Epoch: 6| Step: 13
Training loss: 3.5668100084633902
Validation loss: 3.294794887247435

Epoch: 43| Step: 0
Training loss: 3.457118836063852
Validation loss: 3.2920334283118367

Epoch: 6| Step: 1
Training loss: 3.1629507113055744
Validation loss: 3.2982610259764353

Epoch: 6| Step: 2
Training loss: 3.4926631868066824
Validation loss: 3.295053885472401

Epoch: 6| Step: 3
Training loss: 3.2704965859485577
Validation loss: 3.293492046407144

Epoch: 6| Step: 4
Training loss: 3.496837549631201
Validation loss: 3.2882603790684506

Epoch: 6| Step: 5
Training loss: 2.566620653739114
Validation loss: 3.2871820911936163

Epoch: 6| Step: 6
Training loss: 3.1985682383896026
Validation loss: 3.2830815599798386

Epoch: 6| Step: 7
Training loss: 3.00104822283665
Validation loss: 3.2844767497236855

Epoch: 6| Step: 8
Training loss: 4.448909651658825
Validation loss: 3.2849035670808435

Epoch: 6| Step: 9
Training loss: 3.6699703389977874
Validation loss: 3.2818004984310325

Epoch: 6| Step: 10
Training loss: 4.204303335205944
Validation loss: 3.2839131319699675

Epoch: 6| Step: 11
Training loss: 3.6100959883421306
Validation loss: 3.2841388297023304

Epoch: 6| Step: 12
Training loss: 4.135067762490794
Validation loss: 3.2816980683980295

Epoch: 6| Step: 13
Training loss: 2.894993136435692
Validation loss: 3.281508950105532

Epoch: 44| Step: 0
Training loss: 2.477857185121531
Validation loss: 3.279539538491308

Epoch: 6| Step: 1
Training loss: 3.6236393446671435
Validation loss: 3.2815618207661434

Epoch: 6| Step: 2
Training loss: 3.7641066659859574
Validation loss: 3.281377310365742

Epoch: 6| Step: 3
Training loss: 3.221457222493035
Validation loss: 3.2796966751307113

Epoch: 6| Step: 4
Training loss: 3.9868632606420826
Validation loss: 3.2789774801610694

Epoch: 6| Step: 5
Training loss: 3.591794219853559
Validation loss: 3.279291107130251

Epoch: 6| Step: 6
Training loss: 3.6114612181396817
Validation loss: 3.27670074604234

Epoch: 6| Step: 7
Training loss: 2.8999184169474788
Validation loss: 3.276772702740836

Epoch: 6| Step: 8
Training loss: 4.086323998808977
Validation loss: 3.2724946062228804

Epoch: 6| Step: 9
Training loss: 3.368764981323222
Validation loss: 3.274486838269627

Epoch: 6| Step: 10
Training loss: 4.301333136493689
Validation loss: 3.2745847511258424

Epoch: 6| Step: 11
Training loss: 2.8290177932994145
Validation loss: 3.273250553252357

Epoch: 6| Step: 12
Training loss: 3.5951437196401708
Validation loss: 3.2728672860859556

Epoch: 6| Step: 13
Training loss: 3.3401933810507054
Validation loss: 3.2687148964714443

Epoch: 45| Step: 0
Training loss: 3.494443160681665
Validation loss: 3.2701886896908254

Epoch: 6| Step: 1
Training loss: 3.9643472595543314
Validation loss: 3.272105781801584

Epoch: 6| Step: 2
Training loss: 3.8238515239205806
Validation loss: 3.2717284485314955

Epoch: 6| Step: 3
Training loss: 3.771883247575063
Validation loss: 3.270668661030871

Epoch: 6| Step: 4
Training loss: 3.650405385746307
Validation loss: 3.2693734569719486

Epoch: 6| Step: 5
Training loss: 3.3419347095880574
Validation loss: 3.2674527296315485

Epoch: 6| Step: 6
Training loss: 2.699826118380316
Validation loss: 3.2681386326763886

Epoch: 6| Step: 7
Training loss: 3.497278517826397
Validation loss: 3.2682906588185308

Epoch: 6| Step: 8
Training loss: 3.2771077485982745
Validation loss: 3.269331288883872

Epoch: 6| Step: 9
Training loss: 2.9544400309714267
Validation loss: 3.2671736357941805

Epoch: 6| Step: 10
Training loss: 3.5732199018418873
Validation loss: 3.2676018298830165

Epoch: 6| Step: 11
Training loss: 3.989250760206435
Validation loss: 3.2691983197176215

Epoch: 6| Step: 12
Training loss: 3.1212326228979914
Validation loss: 3.265867700481493

Epoch: 6| Step: 13
Training loss: 3.8089460474080528
Validation loss: 3.2671546217081318

Epoch: 46| Step: 0
Training loss: 4.762713634275042
Validation loss: 3.2658303674070868

Epoch: 6| Step: 1
Training loss: 3.232176249872785
Validation loss: 3.269547669020346

Epoch: 6| Step: 2
Training loss: 3.8055645756177596
Validation loss: 3.2669365748347348

Epoch: 6| Step: 3
Training loss: 4.005989120963794
Validation loss: 3.2714673215507015

Epoch: 6| Step: 4
Training loss: 3.402772300525504
Validation loss: 3.267259120916784

Epoch: 6| Step: 5
Training loss: 2.9022537155870216
Validation loss: 3.263118745602871

Epoch: 6| Step: 6
Training loss: 4.130542153156642
Validation loss: 3.2610562192068593

Epoch: 6| Step: 7
Training loss: 3.3530213353325555
Validation loss: 3.262165637734263

Epoch: 6| Step: 8
Training loss: 3.346030197591008
Validation loss: 3.262457879768599

Epoch: 6| Step: 9
Training loss: 3.2370037508598988
Validation loss: 3.2623291749149486

Epoch: 6| Step: 10
Training loss: 2.703731049970794
Validation loss: 3.259470732468552

Epoch: 6| Step: 11
Training loss: 3.575409104207681
Validation loss: 3.260279313704145

Epoch: 6| Step: 12
Training loss: 2.7910314283197186
Validation loss: 3.255992759778778

Epoch: 6| Step: 13
Training loss: 3.0093278510816015
Validation loss: 3.2572218954053738

Epoch: 47| Step: 0
Training loss: 2.8929087921860286
Validation loss: 3.2569650066213596

Epoch: 6| Step: 1
Training loss: 2.7289156228032034
Validation loss: 3.259286288186576

Epoch: 6| Step: 2
Training loss: 3.5270572854417317
Validation loss: 3.261337303359265

Epoch: 6| Step: 3
Training loss: 3.8841975176920793
Validation loss: 3.257712153453355

Epoch: 6| Step: 4
Training loss: 3.6790723023170218
Validation loss: 3.2571006774921205

Epoch: 6| Step: 5
Training loss: 2.921638519998757
Validation loss: 3.2547939005548288

Epoch: 6| Step: 6
Training loss: 3.199099807484454
Validation loss: 3.255366311585772

Epoch: 6| Step: 7
Training loss: 4.382014727276525
Validation loss: 3.2553280807947713

Epoch: 6| Step: 8
Training loss: 4.0505408691182785
Validation loss: 3.254788109741863

Epoch: 6| Step: 9
Training loss: 3.2835158018217285
Validation loss: 3.253991989126688

Epoch: 6| Step: 10
Training loss: 3.5615956011762986
Validation loss: 3.253240161257878

Epoch: 6| Step: 11
Training loss: 3.7428297793761947
Validation loss: 3.2514886057898953

Epoch: 6| Step: 12
Training loss: 3.7428780637299917
Validation loss: 3.2514133164856527

Epoch: 6| Step: 13
Training loss: 2.3568315754574494
Validation loss: 3.2530814613854515

Epoch: 48| Step: 0
Training loss: 3.291234402501881
Validation loss: 3.255578822687503

Epoch: 6| Step: 1
Training loss: 3.8657448283614024
Validation loss: 3.258258702363633

Epoch: 6| Step: 2
Training loss: 3.4800434644769074
Validation loss: 3.2601095054439235

Epoch: 6| Step: 3
Training loss: 3.331961985468535
Validation loss: 3.258931624019768

Epoch: 6| Step: 4
Training loss: 3.8330012191424183
Validation loss: 3.2582493022939483

Epoch: 6| Step: 5
Training loss: 4.175751103434211
Validation loss: 3.2538864351210997

Epoch: 6| Step: 6
Training loss: 2.7192121091087635
Validation loss: 3.2492780995896275

Epoch: 6| Step: 7
Training loss: 3.905144618991627
Validation loss: 3.248050865631783

Epoch: 6| Step: 8
Training loss: 2.804064583207401
Validation loss: 3.2498461763439805

Epoch: 6| Step: 9
Training loss: 3.344522547381956
Validation loss: 3.2492019661131897

Epoch: 6| Step: 10
Training loss: 2.7941977191234493
Validation loss: 3.2483122950034304

Epoch: 6| Step: 11
Training loss: 4.408767089464526
Validation loss: 3.2472179485926045

Epoch: 6| Step: 12
Training loss: 2.872550750363782
Validation loss: 3.249278243185396

Epoch: 6| Step: 13
Training loss: 3.5258775200475916
Validation loss: 3.248592081215457

Epoch: 49| Step: 0
Training loss: 3.907815604225826
Validation loss: 3.2488788046457606

Epoch: 6| Step: 1
Training loss: 3.8348491546526873
Validation loss: 3.2460802608415205

Epoch: 6| Step: 2
Training loss: 3.235356573532189
Validation loss: 3.2482477754362504

Epoch: 6| Step: 3
Training loss: 3.6569309741612943
Validation loss: 3.251501495367292

Epoch: 6| Step: 4
Training loss: 4.010509513011417
Validation loss: 3.271232166562907

Epoch: 6| Step: 5
Training loss: 3.100771555713619
Validation loss: 3.2484717771391667

Epoch: 6| Step: 6
Training loss: 3.8073633328992984
Validation loss: 3.2458796187866334

Epoch: 6| Step: 7
Training loss: 2.95677742315896
Validation loss: 3.2423778760228474

Epoch: 6| Step: 8
Training loss: 2.944614641400898
Validation loss: 3.243333675062976

Epoch: 6| Step: 9
Training loss: 3.643966516569129
Validation loss: 3.242755422754287

Epoch: 6| Step: 10
Training loss: 3.7426850499824074
Validation loss: 3.2415134718188603

Epoch: 6| Step: 11
Training loss: 3.8608160996349197
Validation loss: 3.2409702562612215

Epoch: 6| Step: 12
Training loss: 2.7230327679710973
Validation loss: 3.2420919013579157

Epoch: 6| Step: 13
Training loss: 2.6457091374922452
Validation loss: 3.2419634800322856

Epoch: 50| Step: 0
Training loss: 3.476155940939995
Validation loss: 3.2390437398720175

Epoch: 6| Step: 1
Training loss: 3.509316714474519
Validation loss: 3.2390692412800712

Epoch: 6| Step: 2
Training loss: 3.690494549906311
Validation loss: 3.234289458973985

Epoch: 6| Step: 3
Training loss: 3.4773398226851
Validation loss: 3.235746291423959

Epoch: 6| Step: 4
Training loss: 3.8774605599124743
Validation loss: 3.2374922291386095

Epoch: 6| Step: 5
Training loss: 3.3584371987713006
Validation loss: 3.235429327710573

Epoch: 6| Step: 6
Training loss: 2.487065232204069
Validation loss: 3.237920519473406

Epoch: 6| Step: 7
Training loss: 3.3467533491948105
Validation loss: 3.2365657502235203

Epoch: 6| Step: 8
Training loss: 3.831484943299078
Validation loss: 3.2421490046873003

Epoch: 6| Step: 9
Training loss: 3.3732747507348573
Validation loss: 3.238090227768116

Epoch: 6| Step: 10
Training loss: 4.317467302773984
Validation loss: 3.246456002972387

Epoch: 6| Step: 11
Training loss: 2.98995529855848
Validation loss: 3.2375490525144004

Epoch: 6| Step: 12
Training loss: 3.330236204092561
Validation loss: 3.2394367605989154

Epoch: 6| Step: 13
Training loss: 3.173930737523918
Validation loss: 3.2472020908915344

Testing loss: 3.41420395337682
