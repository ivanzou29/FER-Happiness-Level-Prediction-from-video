Epoch: 1| Step: 0
Training loss: 4.1763345835300205
Validation loss: 5.768581923942677

Epoch: 5| Step: 1
Training loss: 6.376836175707857
Validation loss: 5.763442097496766

Epoch: 5| Step: 2
Training loss: 6.241716923360686
Validation loss: 5.758503591885979

Epoch: 5| Step: 3
Training loss: 6.237819857604717
Validation loss: 5.753798490566904

Epoch: 5| Step: 4
Training loss: 5.884681354151011
Validation loss: 5.749266514803102

Epoch: 5| Step: 5
Training loss: 5.917612277836457
Validation loss: 5.744610772368504

Epoch: 5| Step: 6
Training loss: 5.50009345928895
Validation loss: 5.7404005933370374

Epoch: 5| Step: 7
Training loss: 5.851585316836356
Validation loss: 5.736087866594377

Epoch: 5| Step: 8
Training loss: 5.907546128243453
Validation loss: 5.73168234922162

Epoch: 5| Step: 9
Training loss: 6.267902217294587
Validation loss: 5.727227488432924

Epoch: 5| Step: 10
Training loss: 4.662131876385791
Validation loss: 5.722644964454311

Epoch: 2| Step: 0
Training loss: 5.897547855611561
Validation loss: 5.7178814230242265

Epoch: 5| Step: 1
Training loss: 5.0404915609274905
Validation loss: 5.713299691407566

Epoch: 5| Step: 2
Training loss: 4.844515438512336
Validation loss: 5.708095711161349

Epoch: 5| Step: 3
Training loss: 6.562792090318872
Validation loss: 5.703146382492782

Epoch: 5| Step: 4
Training loss: 5.045429412441782
Validation loss: 5.697294779859539

Epoch: 5| Step: 5
Training loss: 6.360254925111284
Validation loss: 5.691664314200469

Epoch: 5| Step: 6
Training loss: 4.813687661004303
Validation loss: 5.685740441547931

Epoch: 5| Step: 7
Training loss: 6.2397187164682775
Validation loss: 5.679790942232717

Epoch: 5| Step: 8
Training loss: 6.2617473827714045
Validation loss: 5.672902392647126

Epoch: 5| Step: 9
Training loss: 5.618223728743003
Validation loss: 5.666258186780036

Epoch: 5| Step: 10
Training loss: 5.976936198998973
Validation loss: 5.658803849716022

Epoch: 3| Step: 0
Training loss: 5.0736868376182525
Validation loss: 5.650771923005911

Epoch: 5| Step: 1
Training loss: 3.6086090728441054
Validation loss: 5.643208442701913

Epoch: 5| Step: 2
Training loss: 5.07745976712446
Validation loss: 5.63483495812691

Epoch: 5| Step: 3
Training loss: 6.218347277612455
Validation loss: 5.626271706393996

Epoch: 5| Step: 4
Training loss: 5.673114735702369
Validation loss: 5.617154113897598

Epoch: 5| Step: 5
Training loss: 7.314128726951955
Validation loss: 5.6072492568024686

Epoch: 5| Step: 6
Training loss: 6.53197157674797
Validation loss: 5.5976407059794155

Epoch: 5| Step: 7
Training loss: 6.057908354505852
Validation loss: 5.58668038783404

Epoch: 5| Step: 8
Training loss: 5.4286433910676815
Validation loss: 5.575140142773959

Epoch: 5| Step: 9
Training loss: 5.185911371958887
Validation loss: 5.564160069658204

Epoch: 5| Step: 10
Training loss: 4.971237999218409
Validation loss: 5.55272645239796

Epoch: 4| Step: 0
Training loss: 6.097965288853529
Validation loss: 5.5407319404357365

Epoch: 5| Step: 1
Training loss: 5.477061729151546
Validation loss: 5.527106175537944

Epoch: 5| Step: 2
Training loss: 6.13942623327921
Validation loss: 5.514690617610388

Epoch: 5| Step: 3
Training loss: 4.738034486438204
Validation loss: 5.500955638477719

Epoch: 5| Step: 4
Training loss: 4.99029151600113
Validation loss: 5.487083781168757

Epoch: 5| Step: 5
Training loss: 4.6819339512301585
Validation loss: 5.472230041780381

Epoch: 5| Step: 6
Training loss: 6.624150635595964
Validation loss: 5.45714555729966

Epoch: 5| Step: 7
Training loss: 5.231000581216606
Validation loss: 5.4417650701797164

Epoch: 5| Step: 8
Training loss: 5.73438630895513
Validation loss: 5.425970228566221

Epoch: 5| Step: 9
Training loss: 5.366556855178039
Validation loss: 5.408608428548428

Epoch: 5| Step: 10
Training loss: 5.1964053273793045
Validation loss: 5.392041807216662

Epoch: 5| Step: 0
Training loss: 5.856784257976592
Validation loss: 5.374998147501033

Epoch: 5| Step: 1
Training loss: 5.375013307067013
Validation loss: 5.3559293370798775

Epoch: 5| Step: 2
Training loss: 5.438443332268518
Validation loss: 5.337774063578145

Epoch: 5| Step: 3
Training loss: 5.670613130119562
Validation loss: 5.318189105593249

Epoch: 5| Step: 4
Training loss: 5.403994756869717
Validation loss: 5.299550771994182

Epoch: 5| Step: 5
Training loss: 5.801780085512077
Validation loss: 5.279379856073768

Epoch: 5| Step: 6
Training loss: 5.285081726135246
Validation loss: 5.258912147070782

Epoch: 5| Step: 7
Training loss: 4.311118969030746
Validation loss: 5.240182297983049

Epoch: 5| Step: 8
Training loss: 5.296329976626596
Validation loss: 5.219713779954386

Epoch: 5| Step: 9
Training loss: 4.884551057675022
Validation loss: 5.198381551821601

Epoch: 5| Step: 10
Training loss: 5.124609955622537
Validation loss: 5.178958378549077

Epoch: 6| Step: 0
Training loss: 4.192654071085527
Validation loss: 5.158393572900658

Epoch: 5| Step: 1
Training loss: 5.193086121289995
Validation loss: 5.1383595593185545

Epoch: 5| Step: 2
Training loss: 4.256828656401493
Validation loss: 5.118915113994193

Epoch: 5| Step: 3
Training loss: 5.242697405284233
Validation loss: 5.098326454586108

Epoch: 5| Step: 4
Training loss: 5.04704128499281
Validation loss: 5.078168735110726

Epoch: 5| Step: 5
Training loss: 4.626212914685924
Validation loss: 5.0590540152760415

Epoch: 5| Step: 6
Training loss: 5.920794305352858
Validation loss: 5.039148032945912

Epoch: 5| Step: 7
Training loss: 4.906214622807366
Validation loss: 5.019597105533747

Epoch: 5| Step: 8
Training loss: 6.488801552926528
Validation loss: 4.998797181769692

Epoch: 5| Step: 9
Training loss: 4.3877575834038245
Validation loss: 4.978375600338521

Epoch: 5| Step: 10
Training loss: 5.587792148675697
Validation loss: 4.958689919390434

Epoch: 7| Step: 0
Training loss: 5.049691468435631
Validation loss: 4.938620744776302

Epoch: 5| Step: 1
Training loss: 4.790963074263366
Validation loss: 4.9205083832366885

Epoch: 5| Step: 2
Training loss: 5.632362294822804
Validation loss: 4.8993899456390455

Epoch: 5| Step: 3
Training loss: 4.976198958648037
Validation loss: 4.878877686238831

Epoch: 5| Step: 4
Training loss: 4.986824988097543
Validation loss: 4.859827045989175

Epoch: 5| Step: 5
Training loss: 4.70672834379365
Validation loss: 4.8393830735935675

Epoch: 5| Step: 6
Training loss: 4.81862755606281
Validation loss: 4.819555630595794

Epoch: 5| Step: 7
Training loss: 5.327188448663903
Validation loss: 4.797753059713527

Epoch: 5| Step: 8
Training loss: 5.046463799037896
Validation loss: 4.778192474282204

Epoch: 5| Step: 9
Training loss: 4.30597978915137
Validation loss: 4.759037099665684

Epoch: 5| Step: 10
Training loss: 4.2029845487250235
Validation loss: 4.739635355367647

Epoch: 8| Step: 0
Training loss: 4.810461033478419
Validation loss: 4.719198389120653

Epoch: 5| Step: 1
Training loss: 4.947270251428946
Validation loss: 4.700384308797453

Epoch: 5| Step: 2
Training loss: 4.868834288899517
Validation loss: 4.679840193320652

Epoch: 5| Step: 3
Training loss: 4.128605047552003
Validation loss: 4.6634470949537015

Epoch: 5| Step: 4
Training loss: 4.1786158819011545
Validation loss: 4.6443978723284856

Epoch: 5| Step: 5
Training loss: 5.084086419692371
Validation loss: 4.625793827911684

Epoch: 5| Step: 6
Training loss: 5.197495356159053
Validation loss: 4.609172417117101

Epoch: 5| Step: 7
Training loss: 5.533238112921061
Validation loss: 4.5923133463647785

Epoch: 5| Step: 8
Training loss: 4.280759017524028
Validation loss: 4.576499432256689

Epoch: 5| Step: 9
Training loss: 4.064966480074696
Validation loss: 4.559584210294816

Epoch: 5| Step: 10
Training loss: 4.570802632973199
Validation loss: 4.5435783643028955

Epoch: 9| Step: 0
Training loss: 4.994756237722475
Validation loss: 4.527189308663747

Epoch: 5| Step: 1
Training loss: 4.802774882911725
Validation loss: 4.515051952593672

Epoch: 5| Step: 2
Training loss: 4.514329348210134
Validation loss: 4.503310295156506

Epoch: 5| Step: 3
Training loss: 4.112859952531297
Validation loss: 4.489591263267576

Epoch: 5| Step: 4
Training loss: 3.6704507865854303
Validation loss: 4.4768806654703415

Epoch: 5| Step: 5
Training loss: 4.701963363602087
Validation loss: 4.465069621275653

Epoch: 5| Step: 6
Training loss: 5.151865997028919
Validation loss: 4.454872906021747

Epoch: 5| Step: 7
Training loss: 3.914132062404246
Validation loss: 4.444824591054928

Epoch: 5| Step: 8
Training loss: 5.273311992140715
Validation loss: 4.433427662801566

Epoch: 5| Step: 9
Training loss: 4.242217624058559
Validation loss: 4.423244847233604

Epoch: 5| Step: 10
Training loss: 4.649809203796847
Validation loss: 4.413930403286166

Epoch: 10| Step: 0
Training loss: 3.913905827780652
Validation loss: 4.405273112772932

Epoch: 5| Step: 1
Training loss: 4.197140883078292
Validation loss: 4.396568783079233

Epoch: 5| Step: 2
Training loss: 3.3624965625163945
Validation loss: 4.389249035204074

Epoch: 5| Step: 3
Training loss: 4.520639980886776
Validation loss: 4.381516926142331

Epoch: 5| Step: 4
Training loss: 4.498161364153023
Validation loss: 4.372995829898817

Epoch: 5| Step: 5
Training loss: 4.672935952248689
Validation loss: 4.365353298776517

Epoch: 5| Step: 6
Training loss: 5.065063957571228
Validation loss: 4.357607209567483

Epoch: 5| Step: 7
Training loss: 5.006967648849061
Validation loss: 4.349009708511025

Epoch: 5| Step: 8
Training loss: 4.47270294564871
Validation loss: 4.338735381147589

Epoch: 5| Step: 9
Training loss: 5.2080265819498175
Validation loss: 4.326066452182965

Epoch: 5| Step: 10
Training loss: 3.9242164947485056
Validation loss: 4.315943732384996

Epoch: 11| Step: 0
Training loss: 3.6502518971933795
Validation loss: 4.308686581890468

Epoch: 5| Step: 1
Training loss: 4.594584901675142
Validation loss: 4.303090746759162

Epoch: 5| Step: 2
Training loss: 5.014534424671528
Validation loss: 4.297506537988174

Epoch: 5| Step: 3
Training loss: 4.320209412267503
Validation loss: 4.293051009651719

Epoch: 5| Step: 4
Training loss: 3.639034333044303
Validation loss: 4.284923819409194

Epoch: 5| Step: 5
Training loss: 4.751636825426787
Validation loss: 4.279888063695357

Epoch: 5| Step: 6
Training loss: 3.443775621377721
Validation loss: 4.27291739953134

Epoch: 5| Step: 7
Training loss: 4.362183899890609
Validation loss: 4.266202679347773

Epoch: 5| Step: 8
Training loss: 4.901833848917919
Validation loss: 4.260772131037052

Epoch: 5| Step: 9
Training loss: 4.447716356303852
Validation loss: 4.253508502782315

Epoch: 5| Step: 10
Training loss: 5.0466497506816035
Validation loss: 4.24611100072402

Epoch: 12| Step: 0
Training loss: 4.8044592330176465
Validation loss: 4.239154968284926

Epoch: 5| Step: 1
Training loss: 4.099377208022256
Validation loss: 4.231903642133827

Epoch: 5| Step: 2
Training loss: 3.230143114350287
Validation loss: 4.224619317372186

Epoch: 5| Step: 3
Training loss: 4.5408820544871755
Validation loss: 4.219027373911917

Epoch: 5| Step: 4
Training loss: 4.610611468493449
Validation loss: 4.214089553744159

Epoch: 5| Step: 5
Training loss: 4.177660869649052
Validation loss: 4.207979384557673

Epoch: 5| Step: 6
Training loss: 3.7884009973469306
Validation loss: 4.203347440506633

Epoch: 5| Step: 7
Training loss: 4.562080468524634
Validation loss: 4.199760410547853

Epoch: 5| Step: 8
Training loss: 3.5125917361623533
Validation loss: 4.191846839152396

Epoch: 5| Step: 9
Training loss: 5.372307746326548
Validation loss: 4.186399045430704

Epoch: 5| Step: 10
Training loss: 4.6538259865917375
Validation loss: 4.181749978186795

Epoch: 13| Step: 0
Training loss: 3.5677342026415366
Validation loss: 4.175982775282502

Epoch: 5| Step: 1
Training loss: 4.319972323223042
Validation loss: 4.1715916811664275

Epoch: 5| Step: 2
Training loss: 4.581740686386033
Validation loss: 4.166544644609706

Epoch: 5| Step: 3
Training loss: 4.532689148816606
Validation loss: 4.16097002302319

Epoch: 5| Step: 4
Training loss: 4.916197393404081
Validation loss: 4.157148978410428

Epoch: 5| Step: 5
Training loss: 4.364210065784072
Validation loss: 4.151437787924835

Epoch: 5| Step: 6
Training loss: 3.827517340562884
Validation loss: 4.147847749434604

Epoch: 5| Step: 7
Training loss: 4.6149068450618405
Validation loss: 4.142373167456383

Epoch: 5| Step: 8
Training loss: 4.177798976461137
Validation loss: 4.140452773013784

Epoch: 5| Step: 9
Training loss: 4.142003474110206
Validation loss: 4.134077906472937

Epoch: 5| Step: 10
Training loss: 3.910288805624975
Validation loss: 4.128546015039193

Epoch: 14| Step: 0
Training loss: 4.383393872982797
Validation loss: 4.125165267920043

Epoch: 5| Step: 1
Training loss: 4.271631057795242
Validation loss: 4.120882093815312

Epoch: 5| Step: 2
Training loss: 4.199866183737728
Validation loss: 4.116337365891926

Epoch: 5| Step: 3
Training loss: 4.029518406113202
Validation loss: 4.112984929408288

Epoch: 5| Step: 4
Training loss: 4.634315800047545
Validation loss: 4.110225099681311

Epoch: 5| Step: 5
Training loss: 4.5758730196107456
Validation loss: 4.104479849254265

Epoch: 5| Step: 6
Training loss: 3.485643369815404
Validation loss: 4.100988204291561

Epoch: 5| Step: 7
Training loss: 4.402955033952296
Validation loss: 4.0974357850122445

Epoch: 5| Step: 8
Training loss: 4.667144523859508
Validation loss: 4.094784806631443

Epoch: 5| Step: 9
Training loss: 4.4066148972079375
Validation loss: 4.089087521375793

Epoch: 5| Step: 10
Training loss: 3.302432181205604
Validation loss: 4.085074401170695

Epoch: 15| Step: 0
Training loss: 4.58066111028478
Validation loss: 4.08376690084409

Epoch: 5| Step: 1
Training loss: 3.7417845698233045
Validation loss: 4.078587986469379

Epoch: 5| Step: 2
Training loss: 4.156866501137169
Validation loss: 4.075871499177344

Epoch: 5| Step: 3
Training loss: 4.715657616686404
Validation loss: 4.0714737696398835

Epoch: 5| Step: 4
Training loss: 4.751093688336566
Validation loss: 4.068686734017607

Epoch: 5| Step: 5
Training loss: 4.559887490808628
Validation loss: 4.064564232045949

Epoch: 5| Step: 6
Training loss: 4.090588462672243
Validation loss: 4.060713658764276

Epoch: 5| Step: 7
Training loss: 3.426472401684688
Validation loss: 4.055808049113607

Epoch: 5| Step: 8
Training loss: 4.218318210686734
Validation loss: 4.052883190828284

Epoch: 5| Step: 9
Training loss: 3.8742835090026495
Validation loss: 4.04928057079122

Epoch: 5| Step: 10
Training loss: 3.960744397875573
Validation loss: 4.043336701914978

Epoch: 16| Step: 0
Training loss: 3.839425235887238
Validation loss: 4.04195570898

Epoch: 5| Step: 1
Training loss: 4.173937798336813
Validation loss: 4.037086199284779

Epoch: 5| Step: 2
Training loss: 3.1920627026243316
Validation loss: 4.033543675639002

Epoch: 5| Step: 3
Training loss: 3.6844669087912214
Validation loss: 4.02934070221517

Epoch: 5| Step: 4
Training loss: 4.712840643189687
Validation loss: 4.0254871958883065

Epoch: 5| Step: 5
Training loss: 4.008462061305287
Validation loss: 4.021313091570619

Epoch: 5| Step: 6
Training loss: 4.929388795922593
Validation loss: 4.014758634295482

Epoch: 5| Step: 7
Training loss: 4.629773743541021
Validation loss: 4.011060399954379

Epoch: 5| Step: 8
Training loss: 3.9305364400865366
Validation loss: 4.005805097267744

Epoch: 5| Step: 9
Training loss: 4.052718608779574
Validation loss: 4.001724202264524

Epoch: 5| Step: 10
Training loss: 4.44986238588295
Validation loss: 3.9974617788055262

Epoch: 17| Step: 0
Training loss: 4.7391657495114865
Validation loss: 3.9924530852186213

Epoch: 5| Step: 1
Training loss: 3.96760254139104
Validation loss: 3.9885606727623646

Epoch: 5| Step: 2
Training loss: 3.3935374044074282
Validation loss: 3.9820601827795548

Epoch: 5| Step: 3
Training loss: 4.133197845781526
Validation loss: 3.976823280487328

Epoch: 5| Step: 4
Training loss: 3.9730084018421605
Validation loss: 3.9735931863945253

Epoch: 5| Step: 5
Training loss: 3.8081564001694908
Validation loss: 3.9689777823405414

Epoch: 5| Step: 6
Training loss: 4.662746326801992
Validation loss: 3.965127197233568

Epoch: 5| Step: 7
Training loss: 3.7842767124658354
Validation loss: 3.962182389973315

Epoch: 5| Step: 8
Training loss: 3.789908466089313
Validation loss: 3.9597928908121403

Epoch: 5| Step: 9
Training loss: 3.881002760428371
Validation loss: 3.955029943474775

Epoch: 5| Step: 10
Training loss: 5.098759533984751
Validation loss: 3.9510184236181973

Epoch: 18| Step: 0
Training loss: 4.117959690246864
Validation loss: 3.9476411672302136

Epoch: 5| Step: 1
Training loss: 4.102407604527678
Validation loss: 3.945292122405588

Epoch: 5| Step: 2
Training loss: 3.397276932310578
Validation loss: 3.941610652665462

Epoch: 5| Step: 3
Training loss: 4.170278636670541
Validation loss: 3.937646963694457

Epoch: 5| Step: 4
Training loss: 3.1041961941605463
Validation loss: 3.933419996276367

Epoch: 5| Step: 5
Training loss: 3.2140883975545727
Validation loss: 3.930423576709204

Epoch: 5| Step: 6
Training loss: 4.739915885017992
Validation loss: 3.927097895764358

Epoch: 5| Step: 7
Training loss: 4.651347607001354
Validation loss: 3.9218835775440657

Epoch: 5| Step: 8
Training loss: 4.966712773938975
Validation loss: 3.920868129278758

Epoch: 5| Step: 9
Training loss: 4.039679887761041
Validation loss: 3.9139220352714132

Epoch: 5| Step: 10
Training loss: 4.012849434821577
Validation loss: 3.909285022012965

Epoch: 19| Step: 0
Training loss: 4.326840647376902
Validation loss: 3.9018794736382056

Epoch: 5| Step: 1
Training loss: 3.367835033490384
Validation loss: 3.8981465308281953

Epoch: 5| Step: 2
Training loss: 4.438249981324679
Validation loss: 3.8916808200276756

Epoch: 5| Step: 3
Training loss: 3.6710105365382706
Validation loss: 3.886021068110877

Epoch: 5| Step: 4
Training loss: 3.50826472912278
Validation loss: 3.8812270872038757

Epoch: 5| Step: 5
Training loss: 4.801542217138559
Validation loss: 3.873917988617971

Epoch: 5| Step: 6
Training loss: 4.587141824403024
Validation loss: 3.869206677691862

Epoch: 5| Step: 7
Training loss: 4.637286594138511
Validation loss: 3.8640462581055206

Epoch: 5| Step: 8
Training loss: 4.129336534092613
Validation loss: 3.8575503080437845

Epoch: 5| Step: 9
Training loss: 3.4945057933484804
Validation loss: 3.851972214750653

Epoch: 5| Step: 10
Training loss: 2.8353299417530007
Validation loss: 3.8468139479386565

Epoch: 20| Step: 0
Training loss: 3.673343316172508
Validation loss: 3.8389788146188426

Epoch: 5| Step: 1
Training loss: 3.2302795133320785
Validation loss: 3.8346127135760075

Epoch: 5| Step: 2
Training loss: 3.373086316132681
Validation loss: 3.8294896579549103

Epoch: 5| Step: 3
Training loss: 4.276123095661308
Validation loss: 3.826177755157417

Epoch: 5| Step: 4
Training loss: 3.9896193752536613
Validation loss: 3.81953185955011

Epoch: 5| Step: 5
Training loss: 3.786780230426609
Validation loss: 3.8142733673247187

Epoch: 5| Step: 6
Training loss: 4.869615368703295
Validation loss: 3.8089708993111353

Epoch: 5| Step: 7
Training loss: 4.396965037862986
Validation loss: 3.801916287616019

Epoch: 5| Step: 8
Training loss: 4.473807720569792
Validation loss: 3.7952442043806336

Epoch: 5| Step: 9
Training loss: 3.7153982236041587
Validation loss: 3.78929362140316

Epoch: 5| Step: 10
Training loss: 3.691661490845048
Validation loss: 3.785778757811222

Epoch: 21| Step: 0
Training loss: 4.190803704942451
Validation loss: 3.779134504531393

Epoch: 5| Step: 1
Training loss: 4.041283710597539
Validation loss: 3.7742192924223805

Epoch: 5| Step: 2
Training loss: 4.011683804695048
Validation loss: 3.7664549191351813

Epoch: 5| Step: 3
Training loss: 4.7343204104861245
Validation loss: 3.7612239537064682

Epoch: 5| Step: 4
Training loss: 3.1818069779830456
Validation loss: 3.757142310160775

Epoch: 5| Step: 5
Training loss: 3.726193583719457
Validation loss: 3.75169049924829

Epoch: 5| Step: 6
Training loss: 4.604581143924638
Validation loss: 3.745614670002198

Epoch: 5| Step: 7
Training loss: 3.8183904700220452
Validation loss: 3.7405336390350774

Epoch: 5| Step: 8
Training loss: 4.37069097577407
Validation loss: 3.733986846265723

Epoch: 5| Step: 9
Training loss: 2.7233123207760213
Validation loss: 3.730126892104869

Epoch: 5| Step: 10
Training loss: 3.309653732765793
Validation loss: 3.724910107722929

Epoch: 22| Step: 0
Training loss: 3.5577899514992812
Validation loss: 3.7214672308801884

Epoch: 5| Step: 1
Training loss: 3.342323355390275
Validation loss: 3.7171542255430796

Epoch: 5| Step: 2
Training loss: 4.370050518869958
Validation loss: 3.7122479141579303

Epoch: 5| Step: 3
Training loss: 4.831579854939099
Validation loss: 3.7080552574241628

Epoch: 5| Step: 4
Training loss: 4.093250506264092
Validation loss: 3.703361548328127

Epoch: 5| Step: 5
Training loss: 2.9509267547421483
Validation loss: 3.6996551605183727

Epoch: 5| Step: 6
Training loss: 4.52997944875607
Validation loss: 3.6978894637252764

Epoch: 5| Step: 7
Training loss: 3.322896225885324
Validation loss: 3.6918451700536075

Epoch: 5| Step: 8
Training loss: 3.6226978226399393
Validation loss: 3.6876734850414143

Epoch: 5| Step: 9
Training loss: 4.0579063854145385
Validation loss: 3.682792098478697

Epoch: 5| Step: 10
Training loss: 3.62297593533144
Validation loss: 3.6789191247847888

Epoch: 23| Step: 0
Training loss: 4.216774937341615
Validation loss: 3.675010528951182

Epoch: 5| Step: 1
Training loss: 4.423739953246596
Validation loss: 3.669785724192054

Epoch: 5| Step: 2
Training loss: 3.892032720979087
Validation loss: 3.667536336415412

Epoch: 5| Step: 3
Training loss: 3.637466304662314
Validation loss: 3.663262931555334

Epoch: 5| Step: 4
Training loss: 3.5904273553938326
Validation loss: 3.6563958818269726

Epoch: 5| Step: 5
Training loss: 3.874678690725189
Validation loss: 3.6527796310327982

Epoch: 5| Step: 6
Training loss: 3.26394873129092
Validation loss: 3.6477445978377916

Epoch: 5| Step: 7
Training loss: 3.7947354037756003
Validation loss: 3.642872044688011

Epoch: 5| Step: 8
Training loss: 4.2077046796638005
Validation loss: 3.6379704549392797

Epoch: 5| Step: 9
Training loss: 3.332860881384503
Validation loss: 3.636995301357829

Epoch: 5| Step: 10
Training loss: 3.918511517582631
Validation loss: 3.6314565014901516

Epoch: 24| Step: 0
Training loss: 3.664801354326699
Validation loss: 3.6272356680233484

Epoch: 5| Step: 1
Training loss: 3.6029815195304744
Validation loss: 3.6208248840170763

Epoch: 5| Step: 2
Training loss: 2.8691022336714145
Validation loss: 3.618100044678653

Epoch: 5| Step: 3
Training loss: 4.077273926773892
Validation loss: 3.612484748672735

Epoch: 5| Step: 4
Training loss: 3.261011835118318
Validation loss: 3.6084350418897784

Epoch: 5| Step: 5
Training loss: 3.054497520217226
Validation loss: 3.6051625991805

Epoch: 5| Step: 6
Training loss: 4.068260686137993
Validation loss: 3.60048578527109

Epoch: 5| Step: 7
Training loss: 4.33009574449505
Validation loss: 3.594916050277177

Epoch: 5| Step: 8
Training loss: 3.9123659397350505
Validation loss: 3.5898458709865855

Epoch: 5| Step: 9
Training loss: 3.9831682359858958
Validation loss: 3.586178292457456

Epoch: 5| Step: 10
Training loss: 4.764909534216017
Validation loss: 3.5818932170370568

Epoch: 25| Step: 0
Training loss: 4.100980939052946
Validation loss: 3.577631831355255

Epoch: 5| Step: 1
Training loss: 3.866415050694672
Validation loss: 3.5729297465614724

Epoch: 5| Step: 2
Training loss: 4.018276660149831
Validation loss: 3.569057078459647

Epoch: 5| Step: 3
Training loss: 3.650565660095963
Validation loss: 3.563554708053126

Epoch: 5| Step: 4
Training loss: 3.610852224085013
Validation loss: 3.5607200253165883

Epoch: 5| Step: 5
Training loss: 3.4996949471640475
Validation loss: 3.5535452126009304

Epoch: 5| Step: 6
Training loss: 3.7246703136401886
Validation loss: 3.5550001509725413

Epoch: 5| Step: 7
Training loss: 3.79397409396258
Validation loss: 3.546280439238393

Epoch: 5| Step: 8
Training loss: 3.9300580617871987
Validation loss: 3.540423776080711

Epoch: 5| Step: 9
Training loss: 4.109095806892281
Validation loss: 3.538629393939531

Epoch: 5| Step: 10
Training loss: 2.7268404668649353
Validation loss: 3.531980808612988

Epoch: 26| Step: 0
Training loss: 3.7514763786856538
Validation loss: 3.529843840922776

Epoch: 5| Step: 1
Training loss: 3.995611047909844
Validation loss: 3.525590895633346

Epoch: 5| Step: 2
Training loss: 3.615055914482035
Validation loss: 3.520886636267298

Epoch: 5| Step: 3
Training loss: 4.2886320082228
Validation loss: 3.5169913575695166

Epoch: 5| Step: 4
Training loss: 4.0486726634408665
Validation loss: 3.509883343623398

Epoch: 5| Step: 5
Training loss: 3.4508680329692756
Validation loss: 3.506656538389057

Epoch: 5| Step: 6
Training loss: 4.243459493275426
Validation loss: 3.5059993792150994

Epoch: 5| Step: 7
Training loss: 4.011894898229324
Validation loss: 3.5013104752698068

Epoch: 5| Step: 8
Training loss: 2.5939536876441296
Validation loss: 3.4930446208177437

Epoch: 5| Step: 9
Training loss: 3.4096469564389964
Validation loss: 3.488690875626847

Epoch: 5| Step: 10
Training loss: 3.0854089984545228
Validation loss: 3.4874261194387337

Epoch: 27| Step: 0
Training loss: 3.8347501762415463
Validation loss: 3.484037693729288

Epoch: 5| Step: 1
Training loss: 2.979964267337267
Validation loss: 3.4828778101876594

Epoch: 5| Step: 2
Training loss: 3.6049365211855458
Validation loss: 3.479121007405402

Epoch: 5| Step: 3
Training loss: 3.872263896090921
Validation loss: 3.4747439273806524

Epoch: 5| Step: 4
Training loss: 3.7757778452647335
Validation loss: 3.473333988071147

Epoch: 5| Step: 5
Training loss: 4.023302153745965
Validation loss: 3.4678014352362885

Epoch: 5| Step: 6
Training loss: 4.101290448566873
Validation loss: 3.4660544527126764

Epoch: 5| Step: 7
Training loss: 2.7946391625773854
Validation loss: 3.4626378933849566

Epoch: 5| Step: 8
Training loss: 3.8571731525825887
Validation loss: 3.4604258625658337

Epoch: 5| Step: 9
Training loss: 3.8859774241986837
Validation loss: 3.457225391296095

Epoch: 5| Step: 10
Training loss: 3.583155265346258
Validation loss: 3.4536812280060207

Epoch: 28| Step: 0
Training loss: 3.993575420354738
Validation loss: 3.4508269178147106

Epoch: 5| Step: 1
Training loss: 3.1468189708036536
Validation loss: 3.446276057144678

Epoch: 5| Step: 2
Training loss: 3.164234297998009
Validation loss: 3.443718085598854

Epoch: 5| Step: 3
Training loss: 3.3205103916211822
Validation loss: 3.4401230083063643

Epoch: 5| Step: 4
Training loss: 4.103620437961159
Validation loss: 3.4377914737693276

Epoch: 5| Step: 5
Training loss: 3.7696024675510147
Validation loss: 3.436662132196775

Epoch: 5| Step: 6
Training loss: 2.8932905124829795
Validation loss: 3.4319051904993243

Epoch: 5| Step: 7
Training loss: 3.571411497892713
Validation loss: 3.4293644642915915

Epoch: 5| Step: 8
Training loss: 3.09022783865326
Validation loss: 3.428258765673936

Epoch: 5| Step: 9
Training loss: 4.764399736828861
Validation loss: 3.425992915217828

Epoch: 5| Step: 10
Training loss: 4.030559391925744
Validation loss: 3.4200866254366105

Epoch: 29| Step: 0
Training loss: 3.7979930597275033
Validation loss: 3.4152455489554616

Epoch: 5| Step: 1
Training loss: 3.111033241871782
Validation loss: 3.4149354414853117

Epoch: 5| Step: 2
Training loss: 4.036851643094466
Validation loss: 3.4138187576653247

Epoch: 5| Step: 3
Training loss: 3.367865191101712
Validation loss: 3.4078845967504896

Epoch: 5| Step: 4
Training loss: 4.129615744387008
Validation loss: 3.4038103286726717

Epoch: 5| Step: 5
Training loss: 3.3323496479707178
Validation loss: 3.4004295092306682

Epoch: 5| Step: 6
Training loss: 3.1984357050232353
Validation loss: 3.3962812376817273

Epoch: 5| Step: 7
Training loss: 3.617773811823457
Validation loss: 3.3960480830021758

Epoch: 5| Step: 8
Training loss: 3.7944697544140586
Validation loss: 3.3914381737916366

Epoch: 5| Step: 9
Training loss: 3.747624598614583
Validation loss: 3.3910757035288444

Epoch: 5| Step: 10
Training loss: 3.657400357811452
Validation loss: 3.3879169068161787

Epoch: 30| Step: 0
Training loss: 4.214011915424521
Validation loss: 3.3856296812426896

Epoch: 5| Step: 1
Training loss: 3.3066622558174656
Validation loss: 3.38303415270976

Epoch: 5| Step: 2
Training loss: 4.2089981963955205
Validation loss: 3.3805808568601354

Epoch: 5| Step: 3
Training loss: 3.3803264830424307
Validation loss: 3.378078084024177

Epoch: 5| Step: 4
Training loss: 3.1318357852451633
Validation loss: 3.3786982711126883

Epoch: 5| Step: 5
Training loss: 4.324539848060247
Validation loss: 3.375178271241349

Epoch: 5| Step: 6
Training loss: 3.088936500121397
Validation loss: 3.369222972090019

Epoch: 5| Step: 7
Training loss: 3.5165707820698873
Validation loss: 3.366850435311291

Epoch: 5| Step: 8
Training loss: 3.4064745347798384
Validation loss: 3.3647967890919435

Epoch: 5| Step: 9
Training loss: 3.181904088136321
Validation loss: 3.3634824169198754

Epoch: 5| Step: 10
Training loss: 3.6157417456556344
Validation loss: 3.3633449897558836

Epoch: 31| Step: 0
Training loss: 4.045039051371942
Validation loss: 3.3587063107871105

Epoch: 5| Step: 1
Training loss: 3.4910710745585845
Validation loss: 3.356223640789815

Epoch: 5| Step: 2
Training loss: 3.376101420076864
Validation loss: 3.3532261361306035

Epoch: 5| Step: 3
Training loss: 3.3641814158143646
Validation loss: 3.3541919985251347

Epoch: 5| Step: 4
Training loss: 3.114157214832194
Validation loss: 3.3506164248123476

Epoch: 5| Step: 5
Training loss: 4.041506472424657
Validation loss: 3.3483209963121414

Epoch: 5| Step: 6
Training loss: 4.001629259177475
Validation loss: 3.3472835028702796

Epoch: 5| Step: 7
Training loss: 4.243835466336087
Validation loss: 3.340693439504065

Epoch: 5| Step: 8
Training loss: 2.5278706539357954
Validation loss: 3.3419187229206706

Epoch: 5| Step: 9
Training loss: 3.3706023210568565
Validation loss: 3.3396727827087638

Epoch: 5| Step: 10
Training loss: 3.5052672669820875
Validation loss: 3.336754114716427

Epoch: 32| Step: 0
Training loss: 3.246864273303233
Validation loss: 3.3347514136840397

Epoch: 5| Step: 1
Training loss: 3.8561418712919213
Validation loss: 3.3392066346440092

Epoch: 5| Step: 2
Training loss: 3.446895590311702
Validation loss: 3.3358866900087802

Epoch: 5| Step: 3
Training loss: 4.097221707848698
Validation loss: 3.327001762346938

Epoch: 5| Step: 4
Training loss: 2.878351165798709
Validation loss: 3.3264985636591167

Epoch: 5| Step: 5
Training loss: 3.6977146720341154
Validation loss: 3.3379031563519197

Epoch: 5| Step: 6
Training loss: 3.2933578170864983
Validation loss: 3.335373599142348

Epoch: 5| Step: 7
Training loss: 4.353176947487066
Validation loss: 3.327221036819557

Epoch: 5| Step: 8
Training loss: 3.372275630423953
Validation loss: 3.317337614789606

Epoch: 5| Step: 9
Training loss: 3.2627822695404816
Validation loss: 3.315377936876881

Epoch: 5| Step: 10
Training loss: 3.513350229771597
Validation loss: 3.3205678464506465

Epoch: 33| Step: 0
Training loss: 4.301704494739102
Validation loss: 3.3229776745174306

Epoch: 5| Step: 1
Training loss: 3.461469140133025
Validation loss: 3.31480788888495

Epoch: 5| Step: 2
Training loss: 3.2653402542013916
Validation loss: 3.3093510289562387

Epoch: 5| Step: 3
Training loss: 3.2419220229695744
Validation loss: 3.31297617527624

Epoch: 5| Step: 4
Training loss: 4.193285006399811
Validation loss: 3.312354284491836

Epoch: 5| Step: 5
Training loss: 3.4255384926816617
Validation loss: 3.308373517573779

Epoch: 5| Step: 6
Training loss: 3.1985266452697387
Validation loss: 3.3050265280229962

Epoch: 5| Step: 7
Training loss: 3.7554631175440782
Validation loss: 3.300512653317074

Epoch: 5| Step: 8
Training loss: 3.968870386415389
Validation loss: 3.299935919983791

Epoch: 5| Step: 9
Training loss: 2.7592173340144273
Validation loss: 3.297882880908832

Epoch: 5| Step: 10
Training loss: 3.0975391033866346
Validation loss: 3.297167117869826

Epoch: 34| Step: 0
Training loss: 2.8448821109421547
Validation loss: 3.300129839597936

Epoch: 5| Step: 1
Training loss: 3.79681132698829
Validation loss: 3.301182424300473

Epoch: 5| Step: 2
Training loss: 2.9877225465762085
Validation loss: 3.2915736136336253

Epoch: 5| Step: 3
Training loss: 4.096062625793682
Validation loss: 3.2884995387907376

Epoch: 5| Step: 4
Training loss: 3.727488404735028
Validation loss: 3.287499129290048

Epoch: 5| Step: 5
Training loss: 3.1515145611651296
Validation loss: 3.2888232619520177

Epoch: 5| Step: 6
Training loss: 4.181142735495281
Validation loss: 3.28553053206345

Epoch: 5| Step: 7
Training loss: 4.319343113230248
Validation loss: 3.279142149044365

Epoch: 5| Step: 8
Training loss: 2.574670222377577
Validation loss: 3.279825537158832

Epoch: 5| Step: 9
Training loss: 2.998365274725331
Validation loss: 3.284406524469758

Epoch: 5| Step: 10
Training loss: 3.7077597413808636
Validation loss: 3.2896344952612857

Epoch: 35| Step: 0
Training loss: 3.3670138781187604
Validation loss: 3.288956412817923

Epoch: 5| Step: 1
Training loss: 3.5944904393891304
Validation loss: 3.2779369780228373

Epoch: 5| Step: 2
Training loss: 2.9814347567779076
Validation loss: 3.276445378232952

Epoch: 5| Step: 3
Training loss: 4.497616878600257
Validation loss: 3.2745135903217824

Epoch: 5| Step: 4
Training loss: 3.5986998594500434
Validation loss: 3.2726461597573264

Epoch: 5| Step: 5
Training loss: 3.6674344097115266
Validation loss: 3.271891121456779

Epoch: 5| Step: 6
Training loss: 2.8531356025824697
Validation loss: 3.270449235219638

Epoch: 5| Step: 7
Training loss: 3.7069839136861824
Validation loss: 3.271756389086123

Epoch: 5| Step: 8
Training loss: 3.5654034745509984
Validation loss: 3.265808332693918

Epoch: 5| Step: 9
Training loss: 3.410154292399925
Validation loss: 3.2647029836851678

Epoch: 5| Step: 10
Training loss: 3.1638207614058564
Validation loss: 3.2690108497890367

Epoch: 36| Step: 0
Training loss: 3.0698535372312583
Validation loss: 3.2655886509552285

Epoch: 5| Step: 1
Training loss: 3.467991926507231
Validation loss: 3.2634461970093986

Epoch: 5| Step: 2
Training loss: 3.709814797274673
Validation loss: 3.2618831615435764

Epoch: 5| Step: 3
Training loss: 4.295040890517889
Validation loss: 3.257581495911167

Epoch: 5| Step: 4
Training loss: 3.6654140037696643
Validation loss: 3.2551844242653543

Epoch: 5| Step: 5
Training loss: 3.4491547419828916
Validation loss: 3.2566060024489922

Epoch: 5| Step: 6
Training loss: 2.83679119113215
Validation loss: 3.2571446977232306

Epoch: 5| Step: 7
Training loss: 3.7608743038660544
Validation loss: 3.2561171777091853

Epoch: 5| Step: 8
Training loss: 3.0911607792832303
Validation loss: 3.2529840361412563

Epoch: 5| Step: 9
Training loss: 3.2212461403589363
Validation loss: 3.2505249044443634

Epoch: 5| Step: 10
Training loss: 3.8379802043060383
Validation loss: 3.249221550767126

Epoch: 37| Step: 0
Training loss: 3.5493697077031086
Validation loss: 3.246878438235551

Epoch: 5| Step: 1
Training loss: 3.334556418777431
Validation loss: 3.2474953455702447

Epoch: 5| Step: 2
Training loss: 3.234552498337591
Validation loss: 3.245893226460704

Epoch: 5| Step: 3
Training loss: 3.1838191602044947
Validation loss: 3.25000797015176

Epoch: 5| Step: 4
Training loss: 2.917102853765743
Validation loss: 3.244414775152898

Epoch: 5| Step: 5
Training loss: 3.5496805665198403
Validation loss: 3.2437535690125805

Epoch: 5| Step: 6
Training loss: 3.388390714650811
Validation loss: 3.2427663326678156

Epoch: 5| Step: 7
Training loss: 3.8097103731703026
Validation loss: 3.2433640702627735

Epoch: 5| Step: 8
Training loss: 4.4188798121872095
Validation loss: 3.241253914750958

Epoch: 5| Step: 9
Training loss: 3.648731293377128
Validation loss: 3.242554441350416

Epoch: 5| Step: 10
Training loss: 3.145619231426635
Validation loss: 3.238945979448437

Epoch: 38| Step: 0
Training loss: 3.639688919943566
Validation loss: 3.240891489669175

Epoch: 5| Step: 1
Training loss: 3.9854105482571276
Validation loss: 3.2383350544138985

Epoch: 5| Step: 2
Training loss: 3.6418189190798156
Validation loss: 3.2364012835022606

Epoch: 5| Step: 3
Training loss: 2.527487513419832
Validation loss: 3.2329255856669095

Epoch: 5| Step: 4
Training loss: 2.8284930416491596
Validation loss: 3.2387021077008

Epoch: 5| Step: 5
Training loss: 3.6218724406301623
Validation loss: 3.24605837006094

Epoch: 5| Step: 6
Training loss: 4.083041563444276
Validation loss: 3.2450174801437814

Epoch: 5| Step: 7
Training loss: 3.1578440653767803
Validation loss: 3.2362711344296007

Epoch: 5| Step: 8
Training loss: 3.7142312941913684
Validation loss: 3.2315713339740286

Epoch: 5| Step: 9
Training loss: 3.6138526258539656
Validation loss: 3.2281368972877855

Epoch: 5| Step: 10
Training loss: 3.2675279247488724
Validation loss: 3.234885565976827

Epoch: 39| Step: 0
Training loss: 3.463813224223721
Validation loss: 3.2412740200135315

Epoch: 5| Step: 1
Training loss: 3.086754026913783
Validation loss: 3.2490832563774097

Epoch: 5| Step: 2
Training loss: 2.9197657514699755
Validation loss: 3.2432041820281885

Epoch: 5| Step: 3
Training loss: 3.3952234262648773
Validation loss: 3.2428208611303617

Epoch: 5| Step: 4
Training loss: 3.529003407659099
Validation loss: 3.234225354827954

Epoch: 5| Step: 5
Training loss: 3.6887767327224497
Validation loss: 3.224320520439114

Epoch: 5| Step: 6
Training loss: 3.560476431094838
Validation loss: 3.221229976529886

Epoch: 5| Step: 7
Training loss: 3.7057463948681937
Validation loss: 3.227538504899969

Epoch: 5| Step: 8
Training loss: 4.208693435420262
Validation loss: 3.231195556470123

Epoch: 5| Step: 9
Training loss: 3.6641107812234113
Validation loss: 3.2293366836317827

Epoch: 5| Step: 10
Training loss: 2.7833663946080294
Validation loss: 3.223599659344354

Epoch: 40| Step: 0
Training loss: 3.839765514923369
Validation loss: 3.2206537701896547

Epoch: 5| Step: 1
Training loss: 3.6865160647691178
Validation loss: 3.2192645714457355

Epoch: 5| Step: 2
Training loss: 3.3250620900717074
Validation loss: 3.219860112863634

Epoch: 5| Step: 3
Training loss: 3.6407431390937757
Validation loss: 3.2422844969256364

Epoch: 5| Step: 4
Training loss: 3.4930178617276826
Validation loss: 3.2169915969606637

Epoch: 5| Step: 5
Training loss: 3.91011405563835
Validation loss: 3.2141785655219537

Epoch: 5| Step: 6
Training loss: 3.047496086787777
Validation loss: 3.2170550444149626

Epoch: 5| Step: 7
Training loss: 3.503953744147529
Validation loss: 3.2236669339367046

Epoch: 5| Step: 8
Training loss: 3.3803116714520254
Validation loss: 3.2271099679382496

Epoch: 5| Step: 9
Training loss: 3.005486557553009
Validation loss: 3.2250122137491055

Epoch: 5| Step: 10
Training loss: 3.323425556945146
Validation loss: 3.2246026522732167

Epoch: 41| Step: 0
Training loss: 4.114344387922776
Validation loss: 3.221396394031835

Epoch: 5| Step: 1
Training loss: 3.2229509808407486
Validation loss: 3.2173487329758017

Epoch: 5| Step: 2
Training loss: 3.0915747807944323
Validation loss: 3.2118846579295512

Epoch: 5| Step: 3
Training loss: 4.0303996763985666
Validation loss: 3.211965674692269

Epoch: 5| Step: 4
Training loss: 3.390294493990374
Validation loss: 3.209854020221501

Epoch: 5| Step: 5
Training loss: 4.019534097119983
Validation loss: 3.2132458440561105

Epoch: 5| Step: 6
Training loss: 4.027746526370357
Validation loss: 3.2127956595400997

Epoch: 5| Step: 7
Training loss: 2.9356677245583622
Validation loss: 3.2109056784626846

Epoch: 5| Step: 8
Training loss: 2.7056501644424418
Validation loss: 3.209566513520363

Epoch: 5| Step: 9
Training loss: 2.873424927858746
Validation loss: 3.208413507562228

Epoch: 5| Step: 10
Training loss: 3.3632618264447114
Validation loss: 3.2088947393596596

Epoch: 42| Step: 0
Training loss: 3.2968959717286923
Validation loss: 3.205622520374562

Epoch: 5| Step: 1
Training loss: 3.5733688261157783
Validation loss: 3.205392664203808

Epoch: 5| Step: 2
Training loss: 3.7825562293795407
Validation loss: 3.2056633704523443

Epoch: 5| Step: 3
Training loss: 3.7371092167819686
Validation loss: 3.199058977772419

Epoch: 5| Step: 4
Training loss: 3.5524504948172666
Validation loss: 3.198327382886554

Epoch: 5| Step: 5
Training loss: 3.5695252333097955
Validation loss: 3.1978871168223884

Epoch: 5| Step: 6
Training loss: 3.1871589029351193
Validation loss: 3.1959780166894407

Epoch: 5| Step: 7
Training loss: 3.1698036383332675
Validation loss: 3.194923184406189

Epoch: 5| Step: 8
Training loss: 2.5768649634499585
Validation loss: 3.1960250958893504

Epoch: 5| Step: 9
Training loss: 3.508180866567987
Validation loss: 3.1949707413312183

Epoch: 5| Step: 10
Training loss: 3.9679556224325694
Validation loss: 3.19291348356879

Epoch: 43| Step: 0
Training loss: 2.495302651038944
Validation loss: 3.192602767340633

Epoch: 5| Step: 1
Training loss: 3.8115703512437586
Validation loss: 3.1903645084203673

Epoch: 5| Step: 2
Training loss: 4.067389963791732
Validation loss: 3.191242111727984

Epoch: 5| Step: 3
Training loss: 4.150452205425511
Validation loss: 3.188596710115794

Epoch: 5| Step: 4
Training loss: 3.433535700145668
Validation loss: 3.1903027608741

Epoch: 5| Step: 5
Training loss: 2.5440577740256933
Validation loss: 3.1886036390042682

Epoch: 5| Step: 6
Training loss: 3.219587346758998
Validation loss: 3.18839661970467

Epoch: 5| Step: 7
Training loss: 3.1735859282589103
Validation loss: 3.1851514391522326

Epoch: 5| Step: 8
Training loss: 3.4016324163566383
Validation loss: 3.1859160317439943

Epoch: 5| Step: 9
Training loss: 4.258916141369626
Validation loss: 3.1824987071689357

Epoch: 5| Step: 10
Training loss: 2.706450428929998
Validation loss: 3.1866718151707234

Epoch: 44| Step: 0
Training loss: 3.281057152303527
Validation loss: 3.1811229896829616

Epoch: 5| Step: 1
Training loss: 3.393973529683228
Validation loss: 3.183182319323849

Epoch: 5| Step: 2
Training loss: 3.9664626851780866
Validation loss: 3.182551067055258

Epoch: 5| Step: 3
Training loss: 3.69434755400632
Validation loss: 3.17980936157591

Epoch: 5| Step: 4
Training loss: 3.610189502846071
Validation loss: 3.1795787874832344

Epoch: 5| Step: 5
Training loss: 3.0707544683287105
Validation loss: 3.1809899776995225

Epoch: 5| Step: 6
Training loss: 3.238777444738655
Validation loss: 3.1780504621007526

Epoch: 5| Step: 7
Training loss: 3.3316216524514015
Validation loss: 3.181057777869427

Epoch: 5| Step: 8
Training loss: 3.6881088788640657
Validation loss: 3.178735353484987

Epoch: 5| Step: 9
Training loss: 2.8292689249232095
Validation loss: 3.178428818216061

Epoch: 5| Step: 10
Training loss: 3.6207360808053526
Validation loss: 3.1787820251257366

Epoch: 45| Step: 0
Training loss: 3.365892059299941
Validation loss: 3.176937730271243

Epoch: 5| Step: 1
Training loss: 3.9390290939445847
Validation loss: 3.1762544698929487

Epoch: 5| Step: 2
Training loss: 3.127699487119259
Validation loss: 3.1734841738126742

Epoch: 5| Step: 3
Training loss: 3.509857329378961
Validation loss: 3.173106580576962

Epoch: 5| Step: 4
Training loss: 3.448936995234144
Validation loss: 3.171802165299807

Epoch: 5| Step: 5
Training loss: 3.0996453728415334
Validation loss: 3.17204371590152

Epoch: 5| Step: 6
Training loss: 3.207191528329677
Validation loss: 3.169109869452737

Epoch: 5| Step: 7
Training loss: 3.2331177852659994
Validation loss: 3.1704089890142932

Epoch: 5| Step: 8
Training loss: 3.0081517412180787
Validation loss: 3.1683492373235054

Epoch: 5| Step: 9
Training loss: 3.457609001201262
Validation loss: 3.169008442105667

Epoch: 5| Step: 10
Training loss: 4.3139867016724835
Validation loss: 3.1676135587750984

Epoch: 46| Step: 0
Training loss: 3.0588709290314346
Validation loss: 3.1691931704424245

Epoch: 5| Step: 1
Training loss: 3.750554615969239
Validation loss: 3.166857723102816

Epoch: 5| Step: 2
Training loss: 3.525014317260236
Validation loss: 3.1653238848684904

Epoch: 5| Step: 3
Training loss: 3.16082598140179
Validation loss: 3.167147258845677

Epoch: 5| Step: 4
Training loss: 4.085489573096458
Validation loss: 3.164304832618755

Epoch: 5| Step: 5
Training loss: 3.2745589563546686
Validation loss: 3.160611167958446

Epoch: 5| Step: 6
Training loss: 3.081421766464993
Validation loss: 3.1610877877500583

Epoch: 5| Step: 7
Training loss: 3.3512156202522765
Validation loss: 3.1581990395086135

Epoch: 5| Step: 8
Training loss: 3.381792368375494
Validation loss: 3.1571233875701963

Epoch: 5| Step: 9
Training loss: 3.5844752835626696
Validation loss: 3.155838936251064

Epoch: 5| Step: 10
Training loss: 3.2749470073110802
Validation loss: 3.154657859646545

Epoch: 47| Step: 0
Training loss: 3.846242453214713
Validation loss: 3.154629218391379

Epoch: 5| Step: 1
Training loss: 3.821499817493459
Validation loss: 3.151505745653767

Epoch: 5| Step: 2
Training loss: 3.4839798912843247
Validation loss: 3.1529598243758006

Epoch: 5| Step: 3
Training loss: 3.7866448623629427
Validation loss: 3.150650525442529

Epoch: 5| Step: 4
Training loss: 2.953035545003431
Validation loss: 3.1488903821930068

Epoch: 5| Step: 5
Training loss: 3.3359194895774062
Validation loss: 3.1428350889113745

Epoch: 5| Step: 6
Training loss: 3.062192628966933
Validation loss: 3.1449093786406914

Epoch: 5| Step: 7
Training loss: 3.813161323598197
Validation loss: 3.144285037919243

Epoch: 5| Step: 8
Training loss: 3.4178048230779337
Validation loss: 3.145801757271554

Epoch: 5| Step: 9
Training loss: 2.828204833532009
Validation loss: 3.142809617461357

Epoch: 5| Step: 10
Training loss: 2.909463234125838
Validation loss: 3.1433313306947093

Epoch: 48| Step: 0
Training loss: 2.949053990896597
Validation loss: 3.1442129347132606

Epoch: 5| Step: 1
Training loss: 2.612374871282667
Validation loss: 3.1498559811756124

Epoch: 5| Step: 2
Training loss: 3.404876852175274
Validation loss: 3.153367196074925

Epoch: 5| Step: 3
Training loss: 3.504258562320172
Validation loss: 3.143025344960996

Epoch: 5| Step: 4
Training loss: 3.658834212532703
Validation loss: 3.140159954115495

Epoch: 5| Step: 5
Training loss: 3.214824319551321
Validation loss: 3.133402190786021

Epoch: 5| Step: 6
Training loss: 3.779309744406383
Validation loss: 3.127363398235489

Epoch: 5| Step: 7
Training loss: 3.246263410080043
Validation loss: 3.133208843383761

Epoch: 5| Step: 8
Training loss: 3.357509361134742
Validation loss: 3.1322966332894144

Epoch: 5| Step: 9
Training loss: 3.496641864112866
Validation loss: 3.126598913859456

Epoch: 5| Step: 10
Training loss: 4.091175463702906
Validation loss: 3.126484408016806

Epoch: 49| Step: 0
Training loss: 3.139609708888273
Validation loss: 3.122498263563325

Epoch: 5| Step: 1
Training loss: 4.025154651016481
Validation loss: 3.1205447565794593

Epoch: 5| Step: 2
Training loss: 3.3378900535766043
Validation loss: 3.1277242783652457

Epoch: 5| Step: 3
Training loss: 3.25371471267189
Validation loss: 3.124501453952892

Epoch: 5| Step: 4
Training loss: 2.996392624332678
Validation loss: 3.1234038216312623

Epoch: 5| Step: 5
Training loss: 3.7150015010291617
Validation loss: 3.1308105084999474

Epoch: 5| Step: 6
Training loss: 3.533111216803158
Validation loss: 3.1235241216607665

Epoch: 5| Step: 7
Training loss: 3.1104636275435666
Validation loss: 3.1201499415370244

Epoch: 5| Step: 8
Training loss: 3.508815834289392
Validation loss: 3.1181164884691266

Epoch: 5| Step: 9
Training loss: 3.259201375811759
Validation loss: 3.112869303581865

Epoch: 5| Step: 10
Training loss: 3.2752744486887506
Validation loss: 3.1140387329184462

Epoch: 50| Step: 0
Training loss: 3.3990124446307757
Validation loss: 3.112447813937237

Epoch: 5| Step: 1
Training loss: 3.94576135480434
Validation loss: 3.1119948907242883

Epoch: 5| Step: 2
Training loss: 3.24723125775939
Validation loss: 3.1135442530577024

Epoch: 5| Step: 3
Training loss: 3.093880390540604
Validation loss: 3.114393147713038

Epoch: 5| Step: 4
Training loss: 3.4931860398648173
Validation loss: 3.1108268340807306

Epoch: 5| Step: 5
Training loss: 3.3436641503837556
Validation loss: 3.1091015681545024

Epoch: 5| Step: 6
Training loss: 3.7926536924216596
Validation loss: 3.1097290436077567

Epoch: 5| Step: 7
Training loss: 2.622163784414025
Validation loss: 3.107786457438912

Epoch: 5| Step: 8
Training loss: 3.2247976136096783
Validation loss: 3.1109110793056285

Epoch: 5| Step: 9
Training loss: 3.441512938630726
Validation loss: 3.1172529064603873

Epoch: 5| Step: 10
Training loss: 3.4557837007881873
Validation loss: 3.1147987460516147

Epoch: 51| Step: 0
Training loss: 3.5521500805860278
Validation loss: 3.1103546442891146

Epoch: 5| Step: 1
Training loss: 3.312117356566188
Validation loss: 3.1055691734355526

Epoch: 5| Step: 2
Training loss: 3.449224556284043
Validation loss: 3.103645042754128

Epoch: 5| Step: 3
Training loss: 3.444101272086478
Validation loss: 3.1035574977167815

Epoch: 5| Step: 4
Training loss: 3.180615488863828
Validation loss: 3.1028080309926165

Epoch: 5| Step: 5
Training loss: 2.98166249618395
Validation loss: 3.1034147039046682

Epoch: 5| Step: 6
Training loss: 3.6566440989360967
Validation loss: 3.104535387274712

Epoch: 5| Step: 7
Training loss: 3.396117933708033
Validation loss: 3.102012262155747

Epoch: 5| Step: 8
Training loss: 3.35099065566119
Validation loss: 3.101376958882695

Epoch: 5| Step: 9
Training loss: 3.37831419239415
Validation loss: 3.10206561529393

Epoch: 5| Step: 10
Training loss: 3.4094424904525265
Validation loss: 3.0992351427312697

Epoch: 52| Step: 0
Training loss: 3.1753126035573347
Validation loss: 3.0960745482573473

Epoch: 5| Step: 1
Training loss: 3.8539451054304585
Validation loss: 3.1006327469928827

Epoch: 5| Step: 2
Training loss: 2.935415786587809
Validation loss: 3.0989141667728437

Epoch: 5| Step: 3
Training loss: 3.8983686360792142
Validation loss: 3.101778931599766

Epoch: 5| Step: 4
Training loss: 3.0390690899068975
Validation loss: 3.099302182036854

Epoch: 5| Step: 5
Training loss: 3.8650447573420577
Validation loss: 3.101283859292478

Epoch: 5| Step: 6
Training loss: 3.0622891723309844
Validation loss: 3.0991194984647277

Epoch: 5| Step: 7
Training loss: 3.5710140014903793
Validation loss: 3.1007966945346452

Epoch: 5| Step: 8
Training loss: 2.663525658714657
Validation loss: 3.0940256336771212

Epoch: 5| Step: 9
Training loss: 3.48570082547986
Validation loss: 3.0948008102078854

Epoch: 5| Step: 10
Training loss: 3.256067334577817
Validation loss: 3.092863689906963

Epoch: 53| Step: 0
Training loss: 3.589328068833744
Validation loss: 3.0908121939602733

Epoch: 5| Step: 1
Training loss: 2.8840061600787315
Validation loss: 3.0924541286369416

Epoch: 5| Step: 2
Training loss: 2.943459168016315
Validation loss: 3.0908912219120586

Epoch: 5| Step: 3
Training loss: 3.629372688924672
Validation loss: 3.0919120892053535

Epoch: 5| Step: 4
Training loss: 3.295747537054823
Validation loss: 3.090532292022251

Epoch: 5| Step: 5
Training loss: 4.009573209505931
Validation loss: 3.093297203276055

Epoch: 5| Step: 6
Training loss: 2.9477004835751446
Validation loss: 3.092048254882642

Epoch: 5| Step: 7
Training loss: 3.4835067146141285
Validation loss: 3.090684754643294

Epoch: 5| Step: 8
Training loss: 2.9518437911368123
Validation loss: 3.090661174284963

Epoch: 5| Step: 9
Training loss: 3.4467037099572977
Validation loss: 3.0923711149029818

Epoch: 5| Step: 10
Training loss: 3.6794686221974824
Validation loss: 3.0946155347059574

Epoch: 54| Step: 0
Training loss: 3.884863329119507
Validation loss: 3.091038886296312

Epoch: 5| Step: 1
Training loss: 3.2953575945138662
Validation loss: 3.0921990799671626

Epoch: 5| Step: 2
Training loss: 3.5969783711762795
Validation loss: 3.08856617238002

Epoch: 5| Step: 3
Training loss: 3.633433299191393
Validation loss: 3.0909819423151665

Epoch: 5| Step: 4
Training loss: 3.737764488226325
Validation loss: 3.0943770151829764

Epoch: 5| Step: 5
Training loss: 2.756842856106267
Validation loss: 3.097863743877941

Epoch: 5| Step: 6
Training loss: 3.196545798914144
Validation loss: 3.0948781036337283

Epoch: 5| Step: 7
Training loss: 3.8346835260228422
Validation loss: 3.0887424384577624

Epoch: 5| Step: 8
Training loss: 2.828323525895255
Validation loss: 3.087956204520681

Epoch: 5| Step: 9
Training loss: 3.152390641592845
Validation loss: 3.086432804532031

Epoch: 5| Step: 10
Training loss: 2.67884889164681
Validation loss: 3.0894192666859848

Epoch: 55| Step: 0
Training loss: 3.0662830886890515
Validation loss: 3.084477722483487

Epoch: 5| Step: 1
Training loss: 3.8523564942086654
Validation loss: 3.0867849241219094

Epoch: 5| Step: 2
Training loss: 3.0829569268943633
Validation loss: 3.0801418807984926

Epoch: 5| Step: 3
Training loss: 2.8798319804665296
Validation loss: 3.0829067040386247

Epoch: 5| Step: 4
Training loss: 3.8335277812125756
Validation loss: 3.0831163297305255

Epoch: 5| Step: 5
Training loss: 3.775318632510048
Validation loss: 3.0832350719950323

Epoch: 5| Step: 6
Training loss: 3.112931714126014
Validation loss: 3.0798715837724355

Epoch: 5| Step: 7
Training loss: 3.416901758681248
Validation loss: 3.077908750851844

Epoch: 5| Step: 8
Training loss: 3.5880140886572383
Validation loss: 3.0801959273697976

Epoch: 5| Step: 9
Training loss: 3.348226385185541
Validation loss: 3.0786724737436946

Epoch: 5| Step: 10
Training loss: 2.627113490545433
Validation loss: 3.081386622322617

Epoch: 56| Step: 0
Training loss: 3.2580919031583915
Validation loss: 3.085286986247429

Epoch: 5| Step: 1
Training loss: 3.540538488477581
Validation loss: 3.085536634069326

Epoch: 5| Step: 2
Training loss: 4.123012641970627
Validation loss: 3.093503938719361

Epoch: 5| Step: 3
Training loss: 3.682410655961084
Validation loss: 3.084874215156359

Epoch: 5| Step: 4
Training loss: 2.984919792899626
Validation loss: 3.0784916788177896

Epoch: 5| Step: 5
Training loss: 3.641801242975097
Validation loss: 3.078666972025354

Epoch: 5| Step: 6
Training loss: 3.256068066806385
Validation loss: 3.077338286859905

Epoch: 5| Step: 7
Training loss: 3.2993750471724637
Validation loss: 3.0759523981244286

Epoch: 5| Step: 8
Training loss: 2.4812810093553885
Validation loss: 3.077430369794973

Epoch: 5| Step: 9
Training loss: 2.969072183894947
Validation loss: 3.077811116510293

Epoch: 5| Step: 10
Training loss: 3.3706422151974382
Validation loss: 3.077477728087838

Epoch: 57| Step: 0
Training loss: 3.2076892619144046
Validation loss: 3.076675810977353

Epoch: 5| Step: 1
Training loss: 3.1058086856989577
Validation loss: 3.0773339915439175

Epoch: 5| Step: 2
Training loss: 3.2370202493349485
Validation loss: 3.0831404450758395

Epoch: 5| Step: 3
Training loss: 3.431528904876076
Validation loss: 3.0776943623682227

Epoch: 5| Step: 4
Training loss: 3.6440522266501887
Validation loss: 3.0735399623897903

Epoch: 5| Step: 5
Training loss: 3.551796611650536
Validation loss: 3.0756620868014615

Epoch: 5| Step: 6
Training loss: 3.4953574316268576
Validation loss: 3.074160585466783

Epoch: 5| Step: 7
Training loss: 2.9260907283231012
Validation loss: 3.0714883584553343

Epoch: 5| Step: 8
Training loss: 3.688962872528014
Validation loss: 3.074838117181218

Epoch: 5| Step: 9
Training loss: 3.322931239814651
Validation loss: 3.075846682833572

Epoch: 5| Step: 10
Training loss: 3.1404733194190504
Validation loss: 3.073825773590509

Epoch: 58| Step: 0
Training loss: 3.7570734070467
Validation loss: 3.0760397995453554

Epoch: 5| Step: 1
Training loss: 3.1156721136420247
Validation loss: 3.0822925396302785

Epoch: 5| Step: 2
Training loss: 2.8788143231273975
Validation loss: 3.0842315390448727

Epoch: 5| Step: 3
Training loss: 3.0843617725958294
Validation loss: 3.0883797691311905

Epoch: 5| Step: 4
Training loss: 3.843605100800346
Validation loss: 3.085910036965108

Epoch: 5| Step: 5
Training loss: 3.630269659866155
Validation loss: 3.074412475958182

Epoch: 5| Step: 6
Training loss: 3.0458832520561665
Validation loss: 3.067683920622218

Epoch: 5| Step: 7
Training loss: 3.182204990902688
Validation loss: 3.0682342600498655

Epoch: 5| Step: 8
Training loss: 2.944708886257636
Validation loss: 3.068190931843414

Epoch: 5| Step: 9
Training loss: 3.7554180423558123
Validation loss: 3.0678463565705174

Epoch: 5| Step: 10
Training loss: 3.4037704542248015
Validation loss: 3.070185538271541

Epoch: 59| Step: 0
Training loss: 3.391448733914536
Validation loss: 3.0692726388095863

Epoch: 5| Step: 1
Training loss: 3.249256489143135
Validation loss: 3.0676532020812166

Epoch: 5| Step: 2
Training loss: 3.6366230330281124
Validation loss: 3.0677117223163957

Epoch: 5| Step: 3
Training loss: 2.741729785072823
Validation loss: 3.067281992189171

Epoch: 5| Step: 4
Training loss: 2.787511228530233
Validation loss: 3.066265188285002

Epoch: 5| Step: 5
Training loss: 3.5628081071363313
Validation loss: 3.0680707901278756

Epoch: 5| Step: 6
Training loss: 3.5129264816987433
Validation loss: 3.0670798944415534

Epoch: 5| Step: 7
Training loss: 3.6894598456463403
Validation loss: 3.0674285758324813

Epoch: 5| Step: 8
Training loss: 3.009605606449468
Validation loss: 3.06695021180774

Epoch: 5| Step: 9
Training loss: 3.7084780604091665
Validation loss: 3.06567176041512

Epoch: 5| Step: 10
Training loss: 3.321947408839756
Validation loss: 3.0655940743078207

Epoch: 60| Step: 0
Training loss: 3.733270585577306
Validation loss: 3.0662459751241173

Epoch: 5| Step: 1
Training loss: 4.042862128726941
Validation loss: 3.0699763849489923

Epoch: 5| Step: 2
Training loss: 3.4765168262010304
Validation loss: 3.070140538329921

Epoch: 5| Step: 3
Training loss: 3.1051048209515697
Validation loss: 3.0672003190310235

Epoch: 5| Step: 4
Training loss: 3.427395760963491
Validation loss: 3.0702873086374676

Epoch: 5| Step: 5
Training loss: 3.094201565549192
Validation loss: 3.064238307116662

Epoch: 5| Step: 6
Training loss: 2.8519857014194643
Validation loss: 3.0641488397026655

Epoch: 5| Step: 7
Training loss: 2.5799105847559316
Validation loss: 3.066814790891767

Epoch: 5| Step: 8
Training loss: 3.4018575362528702
Validation loss: 3.0646263577682458

Epoch: 5| Step: 9
Training loss: 3.1885594122084515
Validation loss: 3.0616835325556724

Epoch: 5| Step: 10
Training loss: 3.618914264119807
Validation loss: 3.0585135371575505

Epoch: 61| Step: 0
Training loss: 2.8163061878137587
Validation loss: 3.0591719028604865

Epoch: 5| Step: 1
Training loss: 3.492982778092288
Validation loss: 3.0588778500558615

Epoch: 5| Step: 2
Training loss: 3.7039698671141017
Validation loss: 3.058464244836988

Epoch: 5| Step: 3
Training loss: 3.0104635866374014
Validation loss: 3.0601808507479733

Epoch: 5| Step: 4
Training loss: 3.9032101208802095
Validation loss: 3.0555079344254445

Epoch: 5| Step: 5
Training loss: 3.215892819891285
Validation loss: 3.055226097045363

Epoch: 5| Step: 6
Training loss: 3.110728367089598
Validation loss: 3.0533340250720116

Epoch: 5| Step: 7
Training loss: 3.804564926397604
Validation loss: 3.0524705568895

Epoch: 5| Step: 8
Training loss: 3.0525639560257276
Validation loss: 3.050103748654289

Epoch: 5| Step: 9
Training loss: 3.319307206498929
Validation loss: 3.0524460799810913

Epoch: 5| Step: 10
Training loss: 2.986413868383605
Validation loss: 3.0570161485713454

Epoch: 62| Step: 0
Training loss: 3.012263979708164
Validation loss: 3.053331811832612

Epoch: 5| Step: 1
Training loss: 3.4359531043142
Validation loss: 3.053296108432252

Epoch: 5| Step: 2
Training loss: 3.9116659232096755
Validation loss: 3.052513018115368

Epoch: 5| Step: 3
Training loss: 2.914296485977141
Validation loss: 3.0578534233723524

Epoch: 5| Step: 4
Training loss: 3.8492214059636667
Validation loss: 3.0553393852108415

Epoch: 5| Step: 5
Training loss: 2.4124796100604704
Validation loss: 3.0542076054263125

Epoch: 5| Step: 6
Training loss: 3.5294044195360534
Validation loss: 3.050935979730758

Epoch: 5| Step: 7
Training loss: 3.2405563479649504
Validation loss: 3.046254980771522

Epoch: 5| Step: 8
Training loss: 3.0806510358605266
Validation loss: 3.0439245671170068

Epoch: 5| Step: 9
Training loss: 3.2237761430098177
Validation loss: 3.0464575225668797

Epoch: 5| Step: 10
Training loss: 3.71548344091412
Validation loss: 3.0465802904442745

Epoch: 63| Step: 0
Training loss: 3.393297820764165
Validation loss: 3.0430936080450453

Epoch: 5| Step: 1
Training loss: 3.084494260513326
Validation loss: 3.046574420264401

Epoch: 5| Step: 2
Training loss: 2.9557373763767227
Validation loss: 3.0448589999772997

Epoch: 5| Step: 3
Training loss: 3.7300318277345954
Validation loss: 3.0435763702357357

Epoch: 5| Step: 4
Training loss: 3.410171910760145
Validation loss: 3.041312664186476

Epoch: 5| Step: 5
Training loss: 3.7247983327462046
Validation loss: 3.0418598188452877

Epoch: 5| Step: 6
Training loss: 3.453192386573822
Validation loss: 3.0431609254386163

Epoch: 5| Step: 7
Training loss: 3.626326745689625
Validation loss: 3.0373539565291203

Epoch: 5| Step: 8
Training loss: 3.0316045494769233
Validation loss: 3.03633672606897

Epoch: 5| Step: 9
Training loss: 3.0146672600744586
Validation loss: 3.0347624458722295

Epoch: 5| Step: 10
Training loss: 2.9275135163109995
Validation loss: 3.0366045630401928

Epoch: 64| Step: 0
Training loss: 3.3902275450191888
Validation loss: 3.0335508291120807

Epoch: 5| Step: 1
Training loss: 2.9891761387282423
Validation loss: 3.0351475720673426

Epoch: 5| Step: 2
Training loss: 3.0039121233382926
Validation loss: 3.0325052486893966

Epoch: 5| Step: 3
Training loss: 3.604316634804809
Validation loss: 3.0352575782734323

Epoch: 5| Step: 4
Training loss: 3.1128261716979186
Validation loss: 3.0348914774187064

Epoch: 5| Step: 5
Training loss: 3.731191003994378
Validation loss: 3.035407000623205

Epoch: 5| Step: 6
Training loss: 3.1499760278667606
Validation loss: 3.030557761243794

Epoch: 5| Step: 7
Training loss: 3.7336073848637437
Validation loss: 3.032071451262841

Epoch: 5| Step: 8
Training loss: 3.2958260987431873
Validation loss: 3.0324053831647837

Epoch: 5| Step: 9
Training loss: 3.254795058401125
Validation loss: 3.0324275769150177

Epoch: 5| Step: 10
Training loss: 3.002878715268614
Validation loss: 3.036386003577169

Epoch: 65| Step: 0
Training loss: 3.6234386633262066
Validation loss: 3.0450762323136904

Epoch: 5| Step: 1
Training loss: 3.6591676987226873
Validation loss: 3.064309798183003

Epoch: 5| Step: 2
Training loss: 3.181386133065449
Validation loss: 3.0497746849519634

Epoch: 5| Step: 3
Training loss: 3.314981646594856
Validation loss: 3.049586527647143

Epoch: 5| Step: 4
Training loss: 3.230965554207532
Validation loss: 3.03590976888472

Epoch: 5| Step: 5
Training loss: 2.9536695836017675
Validation loss: 3.028356402630847

Epoch: 5| Step: 6
Training loss: 3.268060533446184
Validation loss: 3.0307909481863664

Epoch: 5| Step: 7
Training loss: 3.194491031325452
Validation loss: 3.030163689446006

Epoch: 5| Step: 8
Training loss: 2.5744626938307476
Validation loss: 3.0252756357105675

Epoch: 5| Step: 9
Training loss: 3.665067295013495
Validation loss: 3.02750918356786

Epoch: 5| Step: 10
Training loss: 3.652488795373586
Validation loss: 3.027855094624193

Epoch: 66| Step: 0
Training loss: 3.2052459393909887
Validation loss: 3.0269706008647588

Epoch: 5| Step: 1
Training loss: 2.4010846071409926
Validation loss: 3.0267685540714795

Epoch: 5| Step: 2
Training loss: 3.661499167911446
Validation loss: 3.025154815898077

Epoch: 5| Step: 3
Training loss: 3.085074233981219
Validation loss: 3.026742831743562

Epoch: 5| Step: 4
Training loss: 3.3668260845046305
Validation loss: 3.024751004431229

Epoch: 5| Step: 5
Training loss: 3.560342771337342
Validation loss: 3.021763992514575

Epoch: 5| Step: 6
Training loss: 2.46348241582889
Validation loss: 3.023189261349915

Epoch: 5| Step: 7
Training loss: 3.5992633489748203
Validation loss: 3.022783630184177

Epoch: 5| Step: 8
Training loss: 3.784211441399031
Validation loss: 3.0234687593487033

Epoch: 5| Step: 9
Training loss: 3.4803786003862234
Validation loss: 3.0205854326197916

Epoch: 5| Step: 10
Training loss: 3.447324135259474
Validation loss: 3.022115449036695

Epoch: 67| Step: 0
Training loss: 4.400606261014218
Validation loss: 3.026784164891356

Epoch: 5| Step: 1
Training loss: 3.3182130885758814
Validation loss: 3.024170826706932

Epoch: 5| Step: 2
Training loss: 3.2945526766425153
Validation loss: 3.024013732213027

Epoch: 5| Step: 3
Training loss: 3.3136295336134296
Validation loss: 3.025069979918668

Epoch: 5| Step: 4
Training loss: 3.1725900529926876
Validation loss: 3.022632946845372

Epoch: 5| Step: 5
Training loss: 2.766245368302058
Validation loss: 3.020737940067441

Epoch: 5| Step: 6
Training loss: 2.730275945446037
Validation loss: 3.017713101493721

Epoch: 5| Step: 7
Training loss: 2.57456743255099
Validation loss: 3.0260329145878537

Epoch: 5| Step: 8
Training loss: 3.5394448585358993
Validation loss: 3.019431970830438

Epoch: 5| Step: 9
Training loss: 3.558237838952687
Validation loss: 3.0191329351397953

Epoch: 5| Step: 10
Training loss: 3.2002483569566307
Validation loss: 3.0200874219580665

Epoch: 68| Step: 0
Training loss: 3.6249229159873986
Validation loss: 3.017766913701534

Epoch: 5| Step: 1
Training loss: 3.0084936386327708
Validation loss: 3.013498901577802

Epoch: 5| Step: 2
Training loss: 3.1239729147114232
Validation loss: 3.0151166845065167

Epoch: 5| Step: 3
Training loss: 3.329579496668279
Validation loss: 3.0131114592593162

Epoch: 5| Step: 4
Training loss: 3.4435737357057112
Validation loss: 3.009968669189882

Epoch: 5| Step: 5
Training loss: 3.431418848660333
Validation loss: 3.0121705310230547

Epoch: 5| Step: 6
Training loss: 3.329354932010954
Validation loss: 3.0137503287325904

Epoch: 5| Step: 7
Training loss: 3.379384336661494
Validation loss: 3.011264714929777

Epoch: 5| Step: 8
Training loss: 2.9561680852981205
Validation loss: 3.0149105372691216

Epoch: 5| Step: 9
Training loss: 2.943743300379684
Validation loss: 3.0118160652105153

Epoch: 5| Step: 10
Training loss: 3.6187908005596747
Validation loss: 3.0125859290811303

Epoch: 69| Step: 0
Training loss: 3.4726091516860254
Validation loss: 3.0112330036728028

Epoch: 5| Step: 1
Training loss: 2.8421477111078115
Validation loss: 3.010112461088737

Epoch: 5| Step: 2
Training loss: 3.0635204561327876
Validation loss: 3.0080218447496616

Epoch: 5| Step: 3
Training loss: 3.4408119199392453
Validation loss: 3.008450532258005

Epoch: 5| Step: 4
Training loss: 3.520677657137374
Validation loss: 3.0064214214149314

Epoch: 5| Step: 5
Training loss: 3.7509665197323905
Validation loss: 3.0069889419381637

Epoch: 5| Step: 6
Training loss: 2.553544935151885
Validation loss: 3.0056831202484027

Epoch: 5| Step: 7
Training loss: 3.3263013257894616
Validation loss: 3.007024728813687

Epoch: 5| Step: 8
Training loss: 3.354470722957164
Validation loss: 3.0104763943236694

Epoch: 5| Step: 9
Training loss: 3.69074171432457
Validation loss: 3.0132864423423555

Epoch: 5| Step: 10
Training loss: 2.9382310322915544
Validation loss: 3.0053243082429293

Epoch: 70| Step: 0
Training loss: 3.682112168285538
Validation loss: 3.0020111360409714

Epoch: 5| Step: 1
Training loss: 3.088220915239984
Validation loss: 3.004366404318224

Epoch: 5| Step: 2
Training loss: 3.384178115035056
Validation loss: 3.005061374927722

Epoch: 5| Step: 3
Training loss: 3.2257617021348555
Validation loss: 3.008212312085438

Epoch: 5| Step: 4
Training loss: 3.433972994156647
Validation loss: 3.009395497844472

Epoch: 5| Step: 5
Training loss: 3.2319016882230294
Validation loss: 3.0062550994254686

Epoch: 5| Step: 6
Training loss: 3.225857341272654
Validation loss: 3.0044594924697705

Epoch: 5| Step: 7
Training loss: 3.0583483523243453
Validation loss: 3.00254462109558

Epoch: 5| Step: 8
Training loss: 3.4429782563474953
Validation loss: 2.999238061026567

Epoch: 5| Step: 9
Training loss: 3.1753447398060213
Validation loss: 3.001922736434187

Epoch: 5| Step: 10
Training loss: 3.2281989503645474
Validation loss: 3.0020030352289564

Epoch: 71| Step: 0
Training loss: 3.4899063340436443
Validation loss: 3.007338657352515

Epoch: 5| Step: 1
Training loss: 3.079752380523765
Validation loss: 3.0080487541378065

Epoch: 5| Step: 2
Training loss: 2.804786786630497
Validation loss: 3.0128254184632945

Epoch: 5| Step: 3
Training loss: 3.267403880123289
Validation loss: 3.016253264437628

Epoch: 5| Step: 4
Training loss: 3.5159761380632513
Validation loss: 3.0080807904331603

Epoch: 5| Step: 5
Training loss: 3.078815518300429
Validation loss: 3.003169322056262

Epoch: 5| Step: 6
Training loss: 3.840734399862303
Validation loss: 2.9994136056041483

Epoch: 5| Step: 7
Training loss: 3.185592080362114
Validation loss: 2.997631279533235

Epoch: 5| Step: 8
Training loss: 2.925124050020411
Validation loss: 2.9988640784727703

Epoch: 5| Step: 9
Training loss: 3.0525400559955034
Validation loss: 2.9960117799755768

Epoch: 5| Step: 10
Training loss: 3.777264472894817
Validation loss: 2.9972946195376515

Epoch: 72| Step: 0
Training loss: 3.028282522035248
Validation loss: 2.9962181904762395

Epoch: 5| Step: 1
Training loss: 3.195205201676843
Validation loss: 2.9941003199231853

Epoch: 5| Step: 2
Training loss: 3.730812320566268
Validation loss: 2.994896975141957

Epoch: 5| Step: 3
Training loss: 3.199099807484454
Validation loss: 2.9934239574102683

Epoch: 5| Step: 4
Training loss: 3.4122337488959475
Validation loss: 2.9927532233468033

Epoch: 5| Step: 5
Training loss: 3.1424808617542443
Validation loss: 2.9915673357486225

Epoch: 5| Step: 6
Training loss: 3.0763050256401443
Validation loss: 2.9906136765755735

Epoch: 5| Step: 7
Training loss: 3.425732532881226
Validation loss: 2.9934261481425

Epoch: 5| Step: 8
Training loss: 3.061357557557569
Validation loss: 2.994818396464616

Epoch: 5| Step: 9
Training loss: 3.3427684448454538
Validation loss: 2.997236705382892

Epoch: 5| Step: 10
Training loss: 3.38790967652893
Validation loss: 2.9984409937012386

Epoch: 73| Step: 0
Training loss: 3.5586953174823632
Validation loss: 2.9977168809158075

Epoch: 5| Step: 1
Training loss: 2.828331112595696
Validation loss: 3.022663289194251

Epoch: 5| Step: 2
Training loss: 3.676396998398234
Validation loss: 3.0205498895846477

Epoch: 5| Step: 3
Training loss: 2.6498340986611306
Validation loss: 2.995328215498996

Epoch: 5| Step: 4
Training loss: 3.6167846191673223
Validation loss: 2.990019165207013

Epoch: 5| Step: 5
Training loss: 3.4617699855421207
Validation loss: 2.987873367996916

Epoch: 5| Step: 6
Training loss: 2.9347388093785214
Validation loss: 2.987728602746748

Epoch: 5| Step: 7
Training loss: 3.645743508821856
Validation loss: 2.9918668910344963

Epoch: 5| Step: 8
Training loss: 2.791655374380778
Validation loss: 2.991650075389732

Epoch: 5| Step: 9
Training loss: 3.323455974059417
Validation loss: 2.9895676108680727

Epoch: 5| Step: 10
Training loss: 3.3550676987663994
Validation loss: 2.9911758356351927

Epoch: 74| Step: 0
Training loss: 3.9793657715733706
Validation loss: 2.9899435364791516

Epoch: 5| Step: 1
Training loss: 3.166725526229212
Validation loss: 2.988201365755998

Epoch: 5| Step: 2
Training loss: 3.4145581477044984
Validation loss: 2.9874527161897637

Epoch: 5| Step: 3
Training loss: 3.6400127632839583
Validation loss: 2.9885223731064032

Epoch: 5| Step: 4
Training loss: 2.996431135257382
Validation loss: 2.98735701876615

Epoch: 5| Step: 5
Training loss: 2.7059960085324146
Validation loss: 2.9880566824597676

Epoch: 5| Step: 6
Training loss: 3.599509624355467
Validation loss: 2.98793484672443

Epoch: 5| Step: 7
Training loss: 3.2567991880891407
Validation loss: 2.986951781083684

Epoch: 5| Step: 8
Training loss: 3.3901057395085523
Validation loss: 2.9879445695363076

Epoch: 5| Step: 9
Training loss: 2.8605562698812164
Validation loss: 2.9891796276106417

Epoch: 5| Step: 10
Training loss: 2.672115649712915
Validation loss: 2.9869129325085497

Epoch: 75| Step: 0
Training loss: 3.4540549014377286
Validation loss: 2.986542433348283

Epoch: 5| Step: 1
Training loss: 2.5898724722672006
Validation loss: 2.9869719428684514

Epoch: 5| Step: 2
Training loss: 3.708744469186267
Validation loss: 2.987403621827503

Epoch: 5| Step: 3
Training loss: 2.8131352025211256
Validation loss: 2.989983725250221

Epoch: 5| Step: 4
Training loss: 2.9315085486154513
Validation loss: 2.9871227429696177

Epoch: 5| Step: 5
Training loss: 3.4512177460519733
Validation loss: 2.9910015029547163

Epoch: 5| Step: 6
Training loss: 3.8359040610415605
Validation loss: 2.991685517886658

Epoch: 5| Step: 7
Training loss: 3.1381636506606276
Validation loss: 2.9856159911676157

Epoch: 5| Step: 8
Training loss: 3.3623825449797025
Validation loss: 2.9826509125441665

Epoch: 5| Step: 9
Training loss: 3.062001401834896
Validation loss: 2.9834195607902094

Epoch: 5| Step: 10
Training loss: 3.414590685597748
Validation loss: 2.984016415383292

Epoch: 76| Step: 0
Training loss: 4.140165944113811
Validation loss: 2.9869204983345683

Epoch: 5| Step: 1
Training loss: 2.882168002566736
Validation loss: 2.988375223531889

Epoch: 5| Step: 2
Training loss: 4.19055201205897
Validation loss: 2.987329528231384

Epoch: 5| Step: 3
Training loss: 3.0229152652273648
Validation loss: 2.9862341085103057

Epoch: 5| Step: 4
Training loss: 2.778944538700984
Validation loss: 2.9828311573709922

Epoch: 5| Step: 5
Training loss: 3.173544308223429
Validation loss: 2.9829649310443265

Epoch: 5| Step: 6
Training loss: 3.476438232944113
Validation loss: 2.978812508959644

Epoch: 5| Step: 7
Training loss: 2.875575298301822
Validation loss: 2.9815446407367583

Epoch: 5| Step: 8
Training loss: 3.011053068658105
Validation loss: 2.9801971479953817

Epoch: 5| Step: 9
Training loss: 2.9886893997207085
Validation loss: 2.9804941689496194

Epoch: 5| Step: 10
Training loss: 3.062767951298063
Validation loss: 2.9805692100117205

Epoch: 77| Step: 0
Training loss: 3.340645034772783
Validation loss: 2.9810912609588245

Epoch: 5| Step: 1
Training loss: 3.4886559160230797
Validation loss: 2.9809550510857568

Epoch: 5| Step: 2
Training loss: 3.3981885796949154
Validation loss: 2.980889295125699

Epoch: 5| Step: 3
Training loss: 2.8873543046136705
Validation loss: 2.9825518686989656

Epoch: 5| Step: 4
Training loss: 3.4994629039103597
Validation loss: 2.980319280264224

Epoch: 5| Step: 5
Training loss: 3.2883168007199326
Validation loss: 2.9893410431464047

Epoch: 5| Step: 6
Training loss: 3.611328389078546
Validation loss: 2.9801698598072104

Epoch: 5| Step: 7
Training loss: 3.190991004627523
Validation loss: 2.979112016374663

Epoch: 5| Step: 8
Training loss: 2.8127357384114426
Validation loss: 2.9803625827709497

Epoch: 5| Step: 9
Training loss: 3.039933499060619
Validation loss: 2.9797683387635283

Epoch: 5| Step: 10
Training loss: 3.240632127627091
Validation loss: 2.99158209077522

Epoch: 78| Step: 0
Training loss: 3.549482555019285
Validation loss: 2.9864317512371454

Epoch: 5| Step: 1
Training loss: 3.373890588466362
Validation loss: 2.985273791421391

Epoch: 5| Step: 2
Training loss: 3.0896903481002034
Validation loss: 2.9803819341198334

Epoch: 5| Step: 3
Training loss: 3.058851910800363
Validation loss: 2.9764471333435645

Epoch: 5| Step: 4
Training loss: 3.5257417371899606
Validation loss: 2.9760667748065264

Epoch: 5| Step: 5
Training loss: 2.9823121935668406
Validation loss: 2.9777139405642346

Epoch: 5| Step: 6
Training loss: 3.333091504543662
Validation loss: 2.97484619347626

Epoch: 5| Step: 7
Training loss: 3.00245724815151
Validation loss: 2.974844405297789

Epoch: 5| Step: 8
Training loss: 3.751660170231034
Validation loss: 2.97317439869142

Epoch: 5| Step: 9
Training loss: 3.1228586107947853
Validation loss: 2.9740282477238438

Epoch: 5| Step: 10
Training loss: 2.9161068697001995
Validation loss: 2.973169038896663

Epoch: 79| Step: 0
Training loss: 3.1117985927060547
Validation loss: 2.973378089598931

Epoch: 5| Step: 1
Training loss: 3.1829544267954324
Validation loss: 2.97315722679235

Epoch: 5| Step: 2
Training loss: 3.8177457896949982
Validation loss: 2.9732735160758477

Epoch: 5| Step: 3
Training loss: 3.324088357414398
Validation loss: 2.9727470014662822

Epoch: 5| Step: 4
Training loss: 3.259468663918912
Validation loss: 2.974080440217741

Epoch: 5| Step: 5
Training loss: 3.0416401030194855
Validation loss: 2.9743804198223893

Epoch: 5| Step: 6
Training loss: 3.5323643909296245
Validation loss: 2.972117668345677

Epoch: 5| Step: 7
Training loss: 2.956098885736642
Validation loss: 2.973538780857414

Epoch: 5| Step: 8
Training loss: 3.1312605136230367
Validation loss: 2.9727544670895267

Epoch: 5| Step: 9
Training loss: 2.9058223943027635
Validation loss: 2.971247277151741

Epoch: 5| Step: 10
Training loss: 3.5100168213617833
Validation loss: 2.971498403033739

Epoch: 80| Step: 0
Training loss: 3.142385264679104
Validation loss: 2.9727481475704565

Epoch: 5| Step: 1
Training loss: 3.568310867255477
Validation loss: 2.971071393742128

Epoch: 5| Step: 2
Training loss: 3.5879330204269175
Validation loss: 2.972948243342507

Epoch: 5| Step: 3
Training loss: 2.9780311465610456
Validation loss: 2.9699870513057003

Epoch: 5| Step: 4
Training loss: 2.9566058277406344
Validation loss: 2.9708333001045237

Epoch: 5| Step: 5
Training loss: 3.4682339121109194
Validation loss: 2.9756691732022076

Epoch: 5| Step: 6
Training loss: 3.301782796923735
Validation loss: 2.9853720141804674

Epoch: 5| Step: 7
Training loss: 3.236879714988903
Validation loss: 2.981891785496285

Epoch: 5| Step: 8
Training loss: 2.9782649100423635
Validation loss: 2.9808816555099025

Epoch: 5| Step: 9
Training loss: 3.5031493867540857
Validation loss: 2.9756061943888

Epoch: 5| Step: 10
Training loss: 3.0251344950388126
Validation loss: 2.969962650764578

Epoch: 81| Step: 0
Training loss: 3.154357645022194
Validation loss: 2.968602174317864

Epoch: 5| Step: 1
Training loss: 3.9389672346144504
Validation loss: 2.9698527819702423

Epoch: 5| Step: 2
Training loss: 2.8574669313561523
Validation loss: 2.968133427355009

Epoch: 5| Step: 3
Training loss: 3.8359812561150015
Validation loss: 2.9683978214575615

Epoch: 5| Step: 4
Training loss: 3.4225071710660497
Validation loss: 2.969198218783286

Epoch: 5| Step: 5
Training loss: 2.71004029303857
Validation loss: 2.9679756894808293

Epoch: 5| Step: 6
Training loss: 3.5838135390142543
Validation loss: 2.967693489302582

Epoch: 5| Step: 7
Training loss: 3.371298844517918
Validation loss: 2.966767387079141

Epoch: 5| Step: 8
Training loss: 2.2219542884897385
Validation loss: 2.9690468398492547

Epoch: 5| Step: 9
Training loss: 2.6994045872622396
Validation loss: 2.9693274030929513

Epoch: 5| Step: 10
Training loss: 3.6458987566209617
Validation loss: 2.967665191184656

Epoch: 82| Step: 0
Training loss: 3.353268915875996
Validation loss: 2.9650705503074577

Epoch: 5| Step: 1
Training loss: 3.4507570735264985
Validation loss: 2.9670213970032675

Epoch: 5| Step: 2
Training loss: 3.8565641352532034
Validation loss: 2.96538437637012

Epoch: 5| Step: 3
Training loss: 2.958550207937283
Validation loss: 2.9656718281739387

Epoch: 5| Step: 4
Training loss: 2.89682332047307
Validation loss: 2.964673264820033

Epoch: 5| Step: 5
Training loss: 2.9272447498563428
Validation loss: 2.9659022430607638

Epoch: 5| Step: 6
Training loss: 2.919780612960471
Validation loss: 2.9643488835534852

Epoch: 5| Step: 7
Training loss: 3.355123411089031
Validation loss: 2.9653209335940716

Epoch: 5| Step: 8
Training loss: 3.1455296418250613
Validation loss: 2.9683254039777083

Epoch: 5| Step: 9
Training loss: 3.4268805415825128
Validation loss: 2.974481323339545

Epoch: 5| Step: 10
Training loss: 3.369403437439773
Validation loss: 2.9760311850653727

Epoch: 83| Step: 0
Training loss: 3.318924342172099
Validation loss: 2.976285175287673

Epoch: 5| Step: 1
Training loss: 3.3117620257884024
Validation loss: 2.9698781433082617

Epoch: 5| Step: 2
Training loss: 3.532970043315586
Validation loss: 2.9777490297930322

Epoch: 5| Step: 3
Training loss: 3.0537752706486914
Validation loss: 2.967488509734033

Epoch: 5| Step: 4
Training loss: 2.303220637702502
Validation loss: 2.968357934629141

Epoch: 5| Step: 5
Training loss: 3.1197300534965287
Validation loss: 2.9642300750840693

Epoch: 5| Step: 6
Training loss: 3.330226897107502
Validation loss: 2.9628991009752967

Epoch: 5| Step: 7
Training loss: 3.969602238020906
Validation loss: 2.965455152229266

Epoch: 5| Step: 8
Training loss: 3.2495708182196172
Validation loss: 2.9640871909031237

Epoch: 5| Step: 9
Training loss: 3.477265499059879
Validation loss: 2.965686684375218

Epoch: 5| Step: 10
Training loss: 2.7509253418920365
Validation loss: 2.9645881205945233

Epoch: 84| Step: 0
Training loss: 3.4546893274655246
Validation loss: 2.965745271680611

Epoch: 5| Step: 1
Training loss: 2.7502200298717048
Validation loss: 2.9647988572119077

Epoch: 5| Step: 2
Training loss: 3.3619013313642347
Validation loss: 2.963988601844773

Epoch: 5| Step: 3
Training loss: 3.415739926204751
Validation loss: 2.964366321817252

Epoch: 5| Step: 4
Training loss: 3.6675804184493974
Validation loss: 2.9623066241730602

Epoch: 5| Step: 5
Training loss: 2.819173820757906
Validation loss: 2.9610660403970845

Epoch: 5| Step: 6
Training loss: 3.6474447267879393
Validation loss: 2.9624631918974353

Epoch: 5| Step: 7
Training loss: 3.0255625745499115
Validation loss: 2.9610729250954853

Epoch: 5| Step: 8
Training loss: 2.6708596960741464
Validation loss: 2.961558133073977

Epoch: 5| Step: 9
Training loss: 3.8728349851818797
Validation loss: 2.9609514275571587

Epoch: 5| Step: 10
Training loss: 2.7377462476645937
Validation loss: 2.9607062995611817

Epoch: 85| Step: 0
Training loss: 3.398600817735226
Validation loss: 2.959899733469846

Epoch: 5| Step: 1
Training loss: 3.3659937749522917
Validation loss: 2.961379800848095

Epoch: 5| Step: 2
Training loss: 2.8639879382428255
Validation loss: 2.9591158609394657

Epoch: 5| Step: 3
Training loss: 3.755842997356063
Validation loss: 2.958716918939769

Epoch: 5| Step: 4
Training loss: 3.3879661154915994
Validation loss: 2.9592620683566535

Epoch: 5| Step: 5
Training loss: 2.8325873309120855
Validation loss: 2.959950797110783

Epoch: 5| Step: 6
Training loss: 2.5760095413576263
Validation loss: 2.9608153076829358

Epoch: 5| Step: 7
Training loss: 3.079803628730333
Validation loss: 2.958620673308084

Epoch: 5| Step: 8
Training loss: 3.138218199457652
Validation loss: 2.9592361863425576

Epoch: 5| Step: 9
Training loss: 3.1299673655213267
Validation loss: 2.958815271226778

Epoch: 5| Step: 10
Training loss: 4.072353444421781
Validation loss: 2.957479533682215

Epoch: 86| Step: 0
Training loss: 3.56860283917318
Validation loss: 2.9566413833817724

Epoch: 5| Step: 1
Training loss: 3.7228919291870737
Validation loss: 2.9569469122405767

Epoch: 5| Step: 2
Training loss: 2.59242968678192
Validation loss: 2.957745557510194

Epoch: 5| Step: 3
Training loss: 3.1635871435938516
Validation loss: 2.954932867916926

Epoch: 5| Step: 4
Training loss: 3.3013528362811484
Validation loss: 2.956217145118271

Epoch: 5| Step: 5
Training loss: 3.10259823356976
Validation loss: 2.954164355851439

Epoch: 5| Step: 6
Training loss: 2.759867046028734
Validation loss: 2.9569465628439637

Epoch: 5| Step: 7
Training loss: 3.691319055889844
Validation loss: 2.957400621360919

Epoch: 5| Step: 8
Training loss: 3.438633957142129
Validation loss: 2.960103269977241

Epoch: 5| Step: 9
Training loss: 2.8646097262929495
Validation loss: 2.9600206150827018

Epoch: 5| Step: 10
Training loss: 3.2897883178418175
Validation loss: 2.961206439365892

Epoch: 87| Step: 0
Training loss: 3.3877925732380825
Validation loss: 2.961488654330326

Epoch: 5| Step: 1
Training loss: 2.6665966700268235
Validation loss: 2.962753317051988

Epoch: 5| Step: 2
Training loss: 3.36956320945819
Validation loss: 2.9561024344715086

Epoch: 5| Step: 3
Training loss: 2.419902859937147
Validation loss: 2.9539673157340673

Epoch: 5| Step: 4
Training loss: 2.9668145546502513
Validation loss: 2.9547018431557577

Epoch: 5| Step: 5
Training loss: 3.315377335282543
Validation loss: 2.952496187952393

Epoch: 5| Step: 6
Training loss: 3.8079213649260093
Validation loss: 2.9517199412946384

Epoch: 5| Step: 7
Training loss: 3.978787442389798
Validation loss: 2.9504620413222065

Epoch: 5| Step: 8
Training loss: 3.355157804459019
Validation loss: 2.949394524968747

Epoch: 5| Step: 9
Training loss: 2.7582859573060454
Validation loss: 2.950007816886244

Epoch: 5| Step: 10
Training loss: 3.306202642610018
Validation loss: 2.9499139672761516

Epoch: 88| Step: 0
Training loss: 3.2384436627603326
Validation loss: 2.949269425738364

Epoch: 5| Step: 1
Training loss: 3.570293668534514
Validation loss: 2.949634211814753

Epoch: 5| Step: 2
Training loss: 3.4976758051894987
Validation loss: 2.949008074480925

Epoch: 5| Step: 3
Training loss: 2.966840591761517
Validation loss: 2.949910962078735

Epoch: 5| Step: 4
Training loss: 3.309266581573984
Validation loss: 2.9514959117024624

Epoch: 5| Step: 5
Training loss: 2.943662793594915
Validation loss: 2.950978256861378

Epoch: 5| Step: 6
Training loss: 3.452552299131016
Validation loss: 2.95176672398787

Epoch: 5| Step: 7
Training loss: 3.4966883659841055
Validation loss: 2.9489270446373714

Epoch: 5| Step: 8
Training loss: 3.382559328538671
Validation loss: 2.9492375398844217

Epoch: 5| Step: 9
Training loss: 2.704459682238129
Validation loss: 2.948880642011233

Epoch: 5| Step: 10
Training loss: 2.9000900780730072
Validation loss: 2.950588757325643

Epoch: 89| Step: 0
Training loss: 2.587174687230001
Validation loss: 2.95136588956078

Epoch: 5| Step: 1
Training loss: 3.70383842452829
Validation loss: 2.9529676749769047

Epoch: 5| Step: 2
Training loss: 2.9580635879109347
Validation loss: 2.9524169739821007

Epoch: 5| Step: 3
Training loss: 3.2080454181110163
Validation loss: 2.952612874209699

Epoch: 5| Step: 4
Training loss: 2.936468227262001
Validation loss: 2.955352268833435

Epoch: 5| Step: 5
Training loss: 3.848509532209429
Validation loss: 2.9539923309278384

Epoch: 5| Step: 6
Training loss: 3.1154504970094465
Validation loss: 2.9535867825142414

Epoch: 5| Step: 7
Training loss: 2.942622810853951
Validation loss: 2.9513435500875134

Epoch: 5| Step: 8
Training loss: 2.8402702084797733
Validation loss: 2.951688449302334

Epoch: 5| Step: 9
Training loss: 3.8778953810101133
Validation loss: 2.9483742707523435

Epoch: 5| Step: 10
Training loss: 3.408728861223905
Validation loss: 2.9495265879081978

Epoch: 90| Step: 0
Training loss: 3.4137918116196033
Validation loss: 2.950806608305081

Epoch: 5| Step: 1
Training loss: 3.222521156022592
Validation loss: 2.9527874938366434

Epoch: 5| Step: 2
Training loss: 2.922059242029193
Validation loss: 2.947590485989815

Epoch: 5| Step: 3
Training loss: 3.4698202870468458
Validation loss: 2.951719690291091

Epoch: 5| Step: 4
Training loss: 3.306538237210594
Validation loss: 2.949687506905702

Epoch: 5| Step: 5
Training loss: 2.4693554485901648
Validation loss: 2.9550344268207596

Epoch: 5| Step: 6
Training loss: 3.325889445492393
Validation loss: 2.955352038957355

Epoch: 5| Step: 7
Training loss: 3.3813371855095102
Validation loss: 2.9651037893304433

Epoch: 5| Step: 8
Training loss: 3.106538638668059
Validation loss: 2.9607529342003462

Epoch: 5| Step: 9
Training loss: 4.032783867055584
Validation loss: 2.962913517691794

Epoch: 5| Step: 10
Training loss: 2.5841355052530193
Validation loss: 2.9662363409002337

Epoch: 91| Step: 0
Training loss: 2.8370466769240683
Validation loss: 2.9542482419652027

Epoch: 5| Step: 1
Training loss: 3.0165302716466718
Validation loss: 2.9494513915583513

Epoch: 5| Step: 2
Training loss: 3.3987989211551355
Validation loss: 2.946963643881419

Epoch: 5| Step: 3
Training loss: 2.919382756197799
Validation loss: 2.948111527932003

Epoch: 5| Step: 4
Training loss: 3.0057253246892053
Validation loss: 2.9464835560574434

Epoch: 5| Step: 5
Training loss: 3.7006349843526247
Validation loss: 2.9492852650963455

Epoch: 5| Step: 6
Training loss: 3.3495494425669676
Validation loss: 2.953537306634724

Epoch: 5| Step: 7
Training loss: 3.730868556782493
Validation loss: 2.9477963882676868

Epoch: 5| Step: 8
Training loss: 2.4672449087140085
Validation loss: 2.9451922080976582

Epoch: 5| Step: 9
Training loss: 3.3208532992488293
Validation loss: 2.9459891672560325

Epoch: 5| Step: 10
Training loss: 3.7092458623760316
Validation loss: 2.945788183636609

Epoch: 92| Step: 0
Training loss: 3.1841941594968004
Validation loss: 2.9433074024856714

Epoch: 5| Step: 1
Training loss: 3.363653678521432
Validation loss: 2.9445372944971204

Epoch: 5| Step: 2
Training loss: 3.321353955463516
Validation loss: 2.942782890354685

Epoch: 5| Step: 3
Training loss: 3.439574292034525
Validation loss: 2.9415962286334465

Epoch: 5| Step: 4
Training loss: 2.8660941468965238
Validation loss: 2.942605053810508

Epoch: 5| Step: 5
Training loss: 3.523494610038133
Validation loss: 2.94309540748455

Epoch: 5| Step: 6
Training loss: 2.9986917504222226
Validation loss: 2.945108484478063

Epoch: 5| Step: 7
Training loss: 3.08198498980056
Validation loss: 2.946480280250138

Epoch: 5| Step: 8
Training loss: 3.2538448479069326
Validation loss: 2.9430300181842317

Epoch: 5| Step: 9
Training loss: 3.416255569537215
Validation loss: 2.9438009858878678

Epoch: 5| Step: 10
Training loss: 3.010398486301387
Validation loss: 2.947142390878733

Epoch: 93| Step: 0
Training loss: 2.4512435598643827
Validation loss: 2.9511170673765323

Epoch: 5| Step: 1
Training loss: 3.5992222793591604
Validation loss: 2.9569729183301776

Epoch: 5| Step: 2
Training loss: 3.1971662968497454
Validation loss: 2.956074862285279

Epoch: 5| Step: 3
Training loss: 3.342197521278513
Validation loss: 2.94290538799241

Epoch: 5| Step: 4
Training loss: 2.82948565550473
Validation loss: 2.93790326375537

Epoch: 5| Step: 5
Training loss: 3.9463063414076682
Validation loss: 2.9385723581961525

Epoch: 5| Step: 6
Training loss: 3.1629190521639963
Validation loss: 2.940862969592945

Epoch: 5| Step: 7
Training loss: 3.696995164557987
Validation loss: 2.943140021583885

Epoch: 5| Step: 8
Training loss: 2.5390450344952185
Validation loss: 2.9508669870752744

Epoch: 5| Step: 9
Training loss: 3.0872974344746207
Validation loss: 2.9535654528100226

Epoch: 5| Step: 10
Training loss: 3.4620739726378758
Validation loss: 2.95031033971478

Epoch: 94| Step: 0
Training loss: 3.151058346202411
Validation loss: 2.949910513645313

Epoch: 5| Step: 1
Training loss: 3.041927448398196
Validation loss: 2.9499429970822315

Epoch: 5| Step: 2
Training loss: 3.3733123515787087
Validation loss: 2.9443520637366762

Epoch: 5| Step: 3
Training loss: 3.3341459873139447
Validation loss: 2.947453771692409

Epoch: 5| Step: 4
Training loss: 3.5486273784890834
Validation loss: 2.9445084490842666

Epoch: 5| Step: 5
Training loss: 3.15797211150695
Validation loss: 2.944715647269026

Epoch: 5| Step: 6
Training loss: 2.845499527559323
Validation loss: 2.9452490008882046

Epoch: 5| Step: 7
Training loss: 3.206453110952096
Validation loss: 2.944401660873303

Epoch: 5| Step: 8
Training loss: 2.877174715933723
Validation loss: 2.947062942534715

Epoch: 5| Step: 9
Training loss: 4.064405023967535
Validation loss: 2.947119467886967

Epoch: 5| Step: 10
Training loss: 2.707295898888218
Validation loss: 2.948732718334248

Epoch: 95| Step: 0
Training loss: 3.2121545568788923
Validation loss: 2.9498394334789273

Epoch: 5| Step: 1
Training loss: 3.0459922098522294
Validation loss: 2.9509909343954623

Epoch: 5| Step: 2
Training loss: 3.2957359624304883
Validation loss: 2.946117089398494

Epoch: 5| Step: 3
Training loss: 2.072627892499718
Validation loss: 2.946203412212025

Epoch: 5| Step: 4
Training loss: 3.051741874958384
Validation loss: 2.9399018723753154

Epoch: 5| Step: 5
Training loss: 2.908730217670077
Validation loss: 2.9451190972790773

Epoch: 5| Step: 6
Training loss: 3.7094983331861915
Validation loss: 2.945444420442322

Epoch: 5| Step: 7
Training loss: 3.327771235186967
Validation loss: 2.94058497459858

Epoch: 5| Step: 8
Training loss: 4.021347777245415
Validation loss: 2.9345090794897026

Epoch: 5| Step: 9
Training loss: 3.1114654414927245
Validation loss: 2.933155123642642

Epoch: 5| Step: 10
Training loss: 3.4569857319566926
Validation loss: 2.9343143277980857

Epoch: 96| Step: 0
Training loss: 3.3812221109928857
Validation loss: 2.934245642938575

Epoch: 5| Step: 1
Training loss: 3.2180472782756446
Validation loss: 2.935043613527453

Epoch: 5| Step: 2
Training loss: 3.349117071602866
Validation loss: 2.9354468977124495

Epoch: 5| Step: 3
Training loss: 3.967545694570004
Validation loss: 2.9383021899853037

Epoch: 5| Step: 4
Training loss: 2.9315667800701286
Validation loss: 2.936987162524629

Epoch: 5| Step: 5
Training loss: 3.081587185313516
Validation loss: 2.9361808640845446

Epoch: 5| Step: 6
Training loss: 2.6889632921022173
Validation loss: 2.9358711465569725

Epoch: 5| Step: 7
Training loss: 3.2127892568070484
Validation loss: 2.9341111560972557

Epoch: 5| Step: 8
Training loss: 3.091840212356175
Validation loss: 2.933243725359802

Epoch: 5| Step: 9
Training loss: 3.44406139814385
Validation loss: 2.93311029473743

Epoch: 5| Step: 10
Training loss: 2.984255803309254
Validation loss: 2.9322064156608105

Epoch: 97| Step: 0
Training loss: 3.3005602158796408
Validation loss: 2.9294178802135438

Epoch: 5| Step: 1
Training loss: 3.470945745863444
Validation loss: 2.932760397714398

Epoch: 5| Step: 2
Training loss: 3.2252377799447
Validation loss: 2.932516156566562

Epoch: 5| Step: 3
Training loss: 3.969450881225502
Validation loss: 2.9305894318984107

Epoch: 5| Step: 4
Training loss: 2.872486010485017
Validation loss: 2.9323788706069767

Epoch: 5| Step: 5
Training loss: 2.900733716818252
Validation loss: 2.9320869815144017

Epoch: 5| Step: 6
Training loss: 3.9252304981365076
Validation loss: 2.933809472502975

Epoch: 5| Step: 7
Training loss: 2.4410718520988635
Validation loss: 2.9336027999993295

Epoch: 5| Step: 8
Training loss: 3.2704034186645825
Validation loss: 2.933494601041983

Epoch: 5| Step: 9
Training loss: 2.4740275697891203
Validation loss: 2.9375811347238057

Epoch: 5| Step: 10
Training loss: 3.1991637508150172
Validation loss: 2.933823655547568

Epoch: 98| Step: 0
Training loss: 3.185599864002112
Validation loss: 2.9307416915651436

Epoch: 5| Step: 1
Training loss: 3.073886334722139
Validation loss: 2.936796723368627

Epoch: 5| Step: 2
Training loss: 3.4189072372290745
Validation loss: 2.9292200025326864

Epoch: 5| Step: 3
Training loss: 2.7181898395017514
Validation loss: 2.930296494933756

Epoch: 5| Step: 4
Training loss: 3.323441482921773
Validation loss: 2.925738303303053

Epoch: 5| Step: 5
Training loss: 3.1428051114419837
Validation loss: 2.92738122569741

Epoch: 5| Step: 6
Training loss: 3.4002475872773084
Validation loss: 2.9257461605111583

Epoch: 5| Step: 7
Training loss: 3.087895875331558
Validation loss: 2.9238619231851852

Epoch: 5| Step: 8
Training loss: 3.9538193646984623
Validation loss: 2.9266353301264276

Epoch: 5| Step: 9
Training loss: 2.948812898916678
Validation loss: 2.9260635181765937

Epoch: 5| Step: 10
Training loss: 3.011228370572988
Validation loss: 2.925482380912328

Epoch: 99| Step: 0
Training loss: 3.313998189443348
Validation loss: 2.9260883119510717

Epoch: 5| Step: 1
Training loss: 2.776349840837913
Validation loss: 2.929071619852521

Epoch: 5| Step: 2
Training loss: 3.4997640257714497
Validation loss: 2.929529033572708

Epoch: 5| Step: 3
Training loss: 3.0897306284108548
Validation loss: 2.9252770446154077

Epoch: 5| Step: 4
Training loss: 3.5803405032911098
Validation loss: 2.927091425449252

Epoch: 5| Step: 5
Training loss: 3.574015693941759
Validation loss: 2.9243492506914035

Epoch: 5| Step: 6
Training loss: 2.5197607128128663
Validation loss: 2.9248951443947018

Epoch: 5| Step: 7
Training loss: 3.3443868155458736
Validation loss: 2.9245895052121957

Epoch: 5| Step: 8
Training loss: 3.1878474924997606
Validation loss: 2.9236681326779586

Epoch: 5| Step: 9
Training loss: 3.59038432537268
Validation loss: 2.922081582539835

Epoch: 5| Step: 10
Training loss: 2.618812898959347
Validation loss: 2.9237079224515803

Epoch: 100| Step: 0
Training loss: 3.2196405160343966
Validation loss: 2.9230597371372564

Epoch: 5| Step: 1
Training loss: 3.3949723039488964
Validation loss: 2.921949907577266

Epoch: 5| Step: 2
Training loss: 2.961078892052026
Validation loss: 2.9224737875489826

Epoch: 5| Step: 3
Training loss: 3.2969632249932674
Validation loss: 2.9224213971108868

Epoch: 5| Step: 4
Training loss: 2.991855533202627
Validation loss: 2.9213027433194707

Epoch: 5| Step: 5
Training loss: 3.1948237336776533
Validation loss: 2.9236786382900446

Epoch: 5| Step: 6
Training loss: 2.7557924993823644
Validation loss: 2.922028448096098

Epoch: 5| Step: 7
Training loss: 3.458434015363463
Validation loss: 2.921041033917977

Epoch: 5| Step: 8
Training loss: 2.8982555404263968
Validation loss: 2.9240546855823344

Epoch: 5| Step: 9
Training loss: 3.4569407650587536
Validation loss: 2.9240419272094833

Epoch: 5| Step: 10
Training loss: 3.7021484375
Validation loss: 2.9229596581310617

Epoch: 101| Step: 0
Training loss: 2.8404453065478563
Validation loss: 2.9285991201899133

Epoch: 5| Step: 1
Training loss: 3.3928810032744106
Validation loss: 2.9232311118904453

Epoch: 5| Step: 2
Training loss: 2.71254091363806
Validation loss: 2.925731625492

Epoch: 5| Step: 3
Training loss: 3.453960334925585
Validation loss: 2.9248570913443483

Epoch: 5| Step: 4
Training loss: 3.408709137087265
Validation loss: 2.9206279054017057

Epoch: 5| Step: 5
Training loss: 2.958644975894166
Validation loss: 2.921694801928465

Epoch: 5| Step: 6
Training loss: 3.3721350766659337
Validation loss: 2.9224455384270422

Epoch: 5| Step: 7
Training loss: 2.8931115255579773
Validation loss: 2.920372189165199

Epoch: 5| Step: 8
Training loss: 3.2634759429797726
Validation loss: 2.9192108235654057

Epoch: 5| Step: 9
Training loss: 3.6494586177287514
Validation loss: 2.919291413664688

Epoch: 5| Step: 10
Training loss: 3.2595766262990113
Validation loss: 2.9190059234781964

Epoch: 102| Step: 0
Training loss: 2.680930869577508
Validation loss: 2.9185926193237988

Epoch: 5| Step: 1
Training loss: 3.3763682099896495
Validation loss: 2.918686927092314

Epoch: 5| Step: 2
Training loss: 3.2913311815518163
Validation loss: 2.9209094507216977

Epoch: 5| Step: 3
Training loss: 3.3357470991843488
Validation loss: 2.9206835563906983

Epoch: 5| Step: 4
Training loss: 3.6338716009085474
Validation loss: 2.922298891770638

Epoch: 5| Step: 5
Training loss: 3.306847986613141
Validation loss: 2.920636869178963

Epoch: 5| Step: 6
Training loss: 3.1758329004871158
Validation loss: 2.9247168574383497

Epoch: 5| Step: 7
Training loss: 3.4856050655129436
Validation loss: 2.9230347413872284

Epoch: 5| Step: 8
Training loss: 2.9504726548510707
Validation loss: 2.9230034832432557

Epoch: 5| Step: 9
Training loss: 3.2843874509159807
Validation loss: 2.9209848429556273

Epoch: 5| Step: 10
Training loss: 2.595327885517263
Validation loss: 2.917302329295821

Epoch: 103| Step: 0
Training loss: 4.101797565808681
Validation loss: 2.9184052385138677

Epoch: 5| Step: 1
Training loss: 3.450854076871881
Validation loss: 2.917544673721722

Epoch: 5| Step: 2
Training loss: 2.6499165143951537
Validation loss: 2.917941034490174

Epoch: 5| Step: 3
Training loss: 3.6691520821510144
Validation loss: 2.9179892223729578

Epoch: 5| Step: 4
Training loss: 3.1610097215956126
Validation loss: 2.916995054354316

Epoch: 5| Step: 5
Training loss: 3.370223586139182
Validation loss: 2.9181388854470893

Epoch: 5| Step: 6
Training loss: 2.6890325390544736
Validation loss: 2.916562974788866

Epoch: 5| Step: 7
Training loss: 3.1801505536602055
Validation loss: 2.915640302044484

Epoch: 5| Step: 8
Training loss: 2.361462711509098
Validation loss: 2.9173836882940196

Epoch: 5| Step: 9
Training loss: 3.4969177298027456
Validation loss: 2.9161596109434726

Epoch: 5| Step: 10
Training loss: 2.778866292876961
Validation loss: 2.914125793661724

Epoch: 104| Step: 0
Training loss: 3.5202442255692725
Validation loss: 2.9151723405962637

Epoch: 5| Step: 1
Training loss: 2.9219985364613925
Validation loss: 2.9163175669882113

Epoch: 5| Step: 2
Training loss: 2.7991894570600455
Validation loss: 2.91448292938879

Epoch: 5| Step: 3
Training loss: 3.897663658870614
Validation loss: 2.914076404383855

Epoch: 5| Step: 4
Training loss: 3.1756854541402073
Validation loss: 2.9138687044275753

Epoch: 5| Step: 5
Training loss: 3.18293480167615
Validation loss: 2.913784412466541

Epoch: 5| Step: 6
Training loss: 3.217672815905888
Validation loss: 2.916598171244358

Epoch: 5| Step: 7
Training loss: 3.135103296649739
Validation loss: 2.9187524217094585

Epoch: 5| Step: 8
Training loss: 3.235518396222986
Validation loss: 2.917281372290145

Epoch: 5| Step: 9
Training loss: 2.8737617811680813
Validation loss: 2.9228978573615496

Epoch: 5| Step: 10
Training loss: 3.212432735941218
Validation loss: 2.925878277965505

Epoch: 105| Step: 0
Training loss: 3.830009276973953
Validation loss: 2.9258958053226936

Epoch: 5| Step: 1
Training loss: 3.07498845664238
Validation loss: 2.9264389686088994

Epoch: 5| Step: 2
Training loss: 2.763064044658841
Validation loss: 2.929134666211942

Epoch: 5| Step: 3
Training loss: 3.1651516017191397
Validation loss: 2.9213457280193804

Epoch: 5| Step: 4
Training loss: 3.290584112567233
Validation loss: 2.918183220453267

Epoch: 5| Step: 5
Training loss: 3.5096135942396254
Validation loss: 2.9117655668572464

Epoch: 5| Step: 6
Training loss: 2.6497394433673693
Validation loss: 2.9113517860753504

Epoch: 5| Step: 7
Training loss: 3.019165490662903
Validation loss: 2.9114640755891825

Epoch: 5| Step: 8
Training loss: 3.1945714860799863
Validation loss: 2.9089179819913578

Epoch: 5| Step: 9
Training loss: 2.746635893569084
Validation loss: 2.9109123323082535

Epoch: 5| Step: 10
Training loss: 3.9018693698620632
Validation loss: 2.9104938640214995

Epoch: 106| Step: 0
Training loss: 3.2848775520902698
Validation loss: 2.911071276713792

Epoch: 5| Step: 1
Training loss: 3.3451416827247304
Validation loss: 2.908990247128652

Epoch: 5| Step: 2
Training loss: 3.3907616934931517
Validation loss: 2.9106334664166433

Epoch: 5| Step: 3
Training loss: 2.6435095927997163
Validation loss: 2.9114574037818555

Epoch: 5| Step: 4
Training loss: 2.6307005972410122
Validation loss: 2.9163438325343494

Epoch: 5| Step: 5
Training loss: 3.353736439157454
Validation loss: 2.9140565616949976

Epoch: 5| Step: 6
Training loss: 3.3178607101221806
Validation loss: 2.9131763341055086

Epoch: 5| Step: 7
Training loss: 2.811987257948938
Validation loss: 2.9131373632337705

Epoch: 5| Step: 8
Training loss: 3.3604826764416673
Validation loss: 2.9121373907427617

Epoch: 5| Step: 9
Training loss: 3.2285407331336136
Validation loss: 2.913221598676542

Epoch: 5| Step: 10
Training loss: 3.8277200290019073
Validation loss: 2.9126698410944125

Epoch: 107| Step: 0
Training loss: 3.4661528341030134
Validation loss: 2.908973695725017

Epoch: 5| Step: 1
Training loss: 3.440875805991239
Validation loss: 2.9089897879807127

Epoch: 5| Step: 2
Training loss: 3.2197153069829048
Validation loss: 2.911154542927394

Epoch: 5| Step: 3
Training loss: 2.773239601489216
Validation loss: 2.9091915822450045

Epoch: 5| Step: 4
Training loss: 3.140801116408365
Validation loss: 2.910012862962167

Epoch: 5| Step: 5
Training loss: 3.393510425745522
Validation loss: 2.9127905405191856

Epoch: 5| Step: 6
Training loss: 4.138438673231683
Validation loss: 2.9084381976199105

Epoch: 5| Step: 7
Training loss: 3.2994757784991893
Validation loss: 2.909875501166904

Epoch: 5| Step: 8
Training loss: 2.441801530500681
Validation loss: 2.9090129039184083

Epoch: 5| Step: 9
Training loss: 2.66840927486143
Validation loss: 2.9087494859148935

Epoch: 5| Step: 10
Training loss: 2.86397245424759
Validation loss: 2.9088453863242405

Epoch: 108| Step: 0
Training loss: 3.6716472149260233
Validation loss: 2.911291644481515

Epoch: 5| Step: 1
Training loss: 3.6001527224041188
Validation loss: 2.9113398076962786

Epoch: 5| Step: 2
Training loss: 3.458690594217106
Validation loss: 2.911642124514403

Epoch: 5| Step: 3
Training loss: 2.779763070720165
Validation loss: 2.916029650185721

Epoch: 5| Step: 4
Training loss: 3.109839169921937
Validation loss: 2.9124931366

Epoch: 5| Step: 5
Training loss: 2.9114631739230967
Validation loss: 2.9096701983137208

Epoch: 5| Step: 6
Training loss: 3.220592378894928
Validation loss: 2.9067318980232772

Epoch: 5| Step: 7
Training loss: 3.2534827131882302
Validation loss: 2.9078453414280916

Epoch: 5| Step: 8
Training loss: 2.8849133948908254
Validation loss: 2.9089349858182665

Epoch: 5| Step: 9
Training loss: 3.218826737461322
Validation loss: 2.9078223784297883

Epoch: 5| Step: 10
Training loss: 2.970381760128371
Validation loss: 2.906069437346342

Epoch: 109| Step: 0
Training loss: 2.562136554530234
Validation loss: 2.9066438305538114

Epoch: 5| Step: 1
Training loss: 3.5277048055021814
Validation loss: 2.9035511724109377

Epoch: 5| Step: 2
Training loss: 3.0489471431866115
Validation loss: 2.9054865827348655

Epoch: 5| Step: 3
Training loss: 3.6431985689759325
Validation loss: 2.9064141115906366

Epoch: 5| Step: 4
Training loss: 3.069835519018986
Validation loss: 2.9094319923045524

Epoch: 5| Step: 5
Training loss: 3.0358364369155497
Validation loss: 2.9108571664958114

Epoch: 5| Step: 6
Training loss: 3.4967517766300946
Validation loss: 2.9080661564104013

Epoch: 5| Step: 7
Training loss: 3.1155707963917467
Validation loss: 2.9168274274080472

Epoch: 5| Step: 8
Training loss: 3.0710366052838984
Validation loss: 2.9243368333083333

Epoch: 5| Step: 9
Training loss: 3.4684932029451856
Validation loss: 2.9230177248599576

Epoch: 5| Step: 10
Training loss: 2.989254303126003
Validation loss: 2.910718675778174

Epoch: 110| Step: 0
Training loss: 3.9039800533504274
Validation loss: 2.9041121840561805

Epoch: 5| Step: 1
Training loss: 3.2719548402388594
Validation loss: 2.9056130835028107

Epoch: 5| Step: 2
Training loss: 3.0606104412671273
Validation loss: 2.902807267133063

Epoch: 5| Step: 3
Training loss: 3.3106862986865044
Validation loss: 2.902389636196148

Epoch: 5| Step: 4
Training loss: 3.3166043746951597
Validation loss: 2.903021670813522

Epoch: 5| Step: 5
Training loss: 3.01600605034664
Validation loss: 2.9020137850762624

Epoch: 5| Step: 6
Training loss: 2.290112355570192
Validation loss: 2.9010058779121786

Epoch: 5| Step: 7
Training loss: 3.0707755867968882
Validation loss: 2.8995763249967412

Epoch: 5| Step: 8
Training loss: 2.828777090525314
Validation loss: 2.901891118780829

Epoch: 5| Step: 9
Training loss: 3.1662013230646386
Validation loss: 2.9020761277517364

Epoch: 5| Step: 10
Training loss: 3.7292947729401873
Validation loss: 2.9019089482700284

Epoch: 111| Step: 0
Training loss: 3.104436431700878
Validation loss: 2.900746699670294

Epoch: 5| Step: 1
Training loss: 3.665172807228623
Validation loss: 2.8997048040690876

Epoch: 5| Step: 2
Training loss: 2.616031858460206
Validation loss: 2.898014174896193

Epoch: 5| Step: 3
Training loss: 3.353246732494765
Validation loss: 2.898976497354398

Epoch: 5| Step: 4
Training loss: 2.77723154949282
Validation loss: 2.896991616422984

Epoch: 5| Step: 5
Training loss: 3.600464229321821
Validation loss: 2.8987421476508266

Epoch: 5| Step: 6
Training loss: 3.0982383767923203
Validation loss: 2.896144582565094

Epoch: 5| Step: 7
Training loss: 2.9050431565773938
Validation loss: 2.8979082945908585

Epoch: 5| Step: 8
Training loss: 3.33691363380704
Validation loss: 2.8996798315597823

Epoch: 5| Step: 9
Training loss: 3.5599728371087536
Validation loss: 2.8992171850146167

Epoch: 5| Step: 10
Training loss: 2.892755826222048
Validation loss: 2.899549623749734

Epoch: 112| Step: 0
Training loss: 3.632653148806824
Validation loss: 2.910098983774909

Epoch: 5| Step: 1
Training loss: 3.266060540025374
Validation loss: 2.9066475322776975

Epoch: 5| Step: 2
Training loss: 3.430501437221505
Validation loss: 2.9065530887757913

Epoch: 5| Step: 3
Training loss: 3.2017814982081565
Validation loss: 2.9117132954282643

Epoch: 5| Step: 4
Training loss: 2.7188786443331896
Validation loss: 2.9122008618125395

Epoch: 5| Step: 5
Training loss: 3.4921537734756325
Validation loss: 2.9004725069887414

Epoch: 5| Step: 6
Training loss: 2.9570957514431493
Validation loss: 2.8991678574421416

Epoch: 5| Step: 7
Training loss: 3.410080741754248
Validation loss: 2.898290977780158

Epoch: 5| Step: 8
Training loss: 2.7546203985929236
Validation loss: 2.8978737363354754

Epoch: 5| Step: 9
Training loss: 3.042194076867971
Validation loss: 2.8949868597007686

Epoch: 5| Step: 10
Training loss: 3.0638592875866313
Validation loss: 2.894909106049784

Epoch: 113| Step: 0
Training loss: 3.225920015151156
Validation loss: 2.8959964757294037

Epoch: 5| Step: 1
Training loss: 2.258788218087823
Validation loss: 2.895395585056659

Epoch: 5| Step: 2
Training loss: 3.51153747294389
Validation loss: 2.8960574138563864

Epoch: 5| Step: 3
Training loss: 3.4273940914605534
Validation loss: 2.894363325601772

Epoch: 5| Step: 4
Training loss: 3.773352580566203
Validation loss: 2.895610332128401

Epoch: 5| Step: 5
Training loss: 2.560431599295402
Validation loss: 2.896354274911769

Epoch: 5| Step: 6
Training loss: 2.890171819680939
Validation loss: 2.895959326558056

Epoch: 5| Step: 7
Training loss: 3.152861334038464
Validation loss: 2.8996593183293995

Epoch: 5| Step: 8
Training loss: 3.2358862253471017
Validation loss: 2.9034522460491834

Epoch: 5| Step: 9
Training loss: 3.5777479747718237
Validation loss: 2.9048357824100015

Epoch: 5| Step: 10
Training loss: 3.2276158864722286
Validation loss: 2.908506477402265

Epoch: 114| Step: 0
Training loss: 3.384847332936178
Validation loss: 2.9135753507352486

Epoch: 5| Step: 1
Training loss: 2.9931960833829616
Validation loss: 2.9225691463853005

Epoch: 5| Step: 2
Training loss: 3.1770017186089063
Validation loss: 2.932905747716114

Epoch: 5| Step: 3
Training loss: 2.662672021171192
Validation loss: 2.9114152637053334

Epoch: 5| Step: 4
Training loss: 3.2542558827953294
Validation loss: 2.8935840878147845

Epoch: 5| Step: 5
Training loss: 3.266640245239945
Validation loss: 2.891348483810259

Epoch: 5| Step: 6
Training loss: 3.04774736484817
Validation loss: 2.8921611399169045

Epoch: 5| Step: 7
Training loss: 2.9421807190284643
Validation loss: 2.891997086473868

Epoch: 5| Step: 8
Training loss: 3.503783497100765
Validation loss: 2.89844013401172

Epoch: 5| Step: 9
Training loss: 3.7518090017380232
Validation loss: 2.8992375917267026

Epoch: 5| Step: 10
Training loss: 3.0508626812215605
Validation loss: 2.899849296659693

Epoch: 115| Step: 0
Training loss: 3.3893860693709845
Validation loss: 2.899585192939286

Epoch: 5| Step: 1
Training loss: 2.7749049642974386
Validation loss: 2.8985799074437146

Epoch: 5| Step: 2
Training loss: 3.440177152419168
Validation loss: 2.896190134127134

Epoch: 5| Step: 3
Training loss: 3.7167703183578977
Validation loss: 2.8950796394021223

Epoch: 5| Step: 4
Training loss: 2.9779568507627645
Validation loss: 2.8937902679118666

Epoch: 5| Step: 5
Training loss: 3.464966643862335
Validation loss: 2.8956335132634217

Epoch: 5| Step: 6
Training loss: 2.8841592594357652
Validation loss: 2.8959662845947256

Epoch: 5| Step: 7
Training loss: 3.3704856067639324
Validation loss: 2.8957620433272186

Epoch: 5| Step: 8
Training loss: 3.2289891019833963
Validation loss: 2.894427008405058

Epoch: 5| Step: 9
Training loss: 2.5339413687013104
Validation loss: 2.892431609971376

Epoch: 5| Step: 10
Training loss: 3.160481552903012
Validation loss: 2.8938981158216475

Epoch: 116| Step: 0
Training loss: 2.5778530092972183
Validation loss: 2.890903435322939

Epoch: 5| Step: 1
Training loss: 3.0956567610388475
Validation loss: 2.8924680395600584

Epoch: 5| Step: 2
Training loss: 3.282927892473451
Validation loss: 2.8898721740637896

Epoch: 5| Step: 3
Training loss: 2.893052355253326
Validation loss: 2.8932671548549465

Epoch: 5| Step: 4
Training loss: 3.1160286874295284
Validation loss: 2.8908199520603834

Epoch: 5| Step: 5
Training loss: 2.887496822735248
Validation loss: 2.8915223471253753

Epoch: 5| Step: 6
Training loss: 3.3210502971641285
Validation loss: 2.890963784685236

Epoch: 5| Step: 7
Training loss: 2.9599179246194307
Validation loss: 2.889797575842657

Epoch: 5| Step: 8
Training loss: 3.99320024458571
Validation loss: 2.89322667086567

Epoch: 5| Step: 9
Training loss: 2.9353253045539414
Validation loss: 2.8906380779188914

Epoch: 5| Step: 10
Training loss: 3.8569323265304445
Validation loss: 2.8921855444548163

Epoch: 117| Step: 0
Training loss: 4.125963503122824
Validation loss: 2.8915535395242324

Epoch: 5| Step: 1
Training loss: 3.244594921109167
Validation loss: 2.8918114105148436

Epoch: 5| Step: 2
Training loss: 2.680138019025399
Validation loss: 2.891255471767681

Epoch: 5| Step: 3
Training loss: 3.0497696648845625
Validation loss: 2.893312586025756

Epoch: 5| Step: 4
Training loss: 3.7158739524709197
Validation loss: 2.8896417516976967

Epoch: 5| Step: 5
Training loss: 2.925287059815535
Validation loss: 2.8908387801015576

Epoch: 5| Step: 6
Training loss: 2.980688564449044
Validation loss: 2.8914894698202427

Epoch: 5| Step: 7
Training loss: 3.173876502035153
Validation loss: 2.8891239045686214

Epoch: 5| Step: 8
Training loss: 2.6499841725578532
Validation loss: 2.8865190074123444

Epoch: 5| Step: 9
Training loss: 2.953676848343176
Validation loss: 2.886647761244944

Epoch: 5| Step: 10
Training loss: 3.286812418116861
Validation loss: 2.8869868315029863

Epoch: 118| Step: 0
Training loss: 3.4738226563335455
Validation loss: 2.8854885913459443

Epoch: 5| Step: 1
Training loss: 3.239018888865386
Validation loss: 2.8877370805119553

Epoch: 5| Step: 2
Training loss: 3.135270750044791
Validation loss: 2.8875445473937877

Epoch: 5| Step: 3
Training loss: 3.1789690935397066
Validation loss: 2.8866554202353503

Epoch: 5| Step: 4
Training loss: 3.575408837476148
Validation loss: 2.8872252013689073

Epoch: 5| Step: 5
Training loss: 3.0815294676780973
Validation loss: 2.8857244624532963

Epoch: 5| Step: 6
Training loss: 2.7718541743411134
Validation loss: 2.885878412292608

Epoch: 5| Step: 7
Training loss: 3.0358003107271943
Validation loss: 2.887065975968816

Epoch: 5| Step: 8
Training loss: 2.959240912971747
Validation loss: 2.8864389659989906

Epoch: 5| Step: 9
Training loss: 3.2086727573800102
Validation loss: 2.8868656952790364

Epoch: 5| Step: 10
Training loss: 3.3383207362129825
Validation loss: 2.8892910394506894

Epoch: 119| Step: 0
Training loss: 3.457955136742258
Validation loss: 2.885622136202967

Epoch: 5| Step: 1
Training loss: 2.997628546242032
Validation loss: 2.888587254247548

Epoch: 5| Step: 2
Training loss: 2.9931341123093733
Validation loss: 2.8865430910760663

Epoch: 5| Step: 3
Training loss: 3.2684859743580352
Validation loss: 2.8866940239374896

Epoch: 5| Step: 4
Training loss: 3.4362628444460714
Validation loss: 2.888266644173011

Epoch: 5| Step: 5
Training loss: 3.151376417469827
Validation loss: 2.88530155383327

Epoch: 5| Step: 6
Training loss: 2.642156123195524
Validation loss: 2.884925859774371

Epoch: 5| Step: 7
Training loss: 3.1366837857056598
Validation loss: 2.887665925028351

Epoch: 5| Step: 8
Training loss: 2.4968213855014563
Validation loss: 2.886910661519222

Epoch: 5| Step: 9
Training loss: 3.756824641140087
Validation loss: 2.891209271423155

Epoch: 5| Step: 10
Training loss: 3.5204873601607716
Validation loss: 2.8921960642611224

Epoch: 120| Step: 0
Training loss: 2.673550086267646
Validation loss: 2.887915906965253

Epoch: 5| Step: 1
Training loss: 4.182259312081356
Validation loss: 2.8842808417498107

Epoch: 5| Step: 2
Training loss: 3.090713706445481
Validation loss: 2.8851935489677407

Epoch: 5| Step: 3
Training loss: 3.4456817359896172
Validation loss: 2.8839483248140936

Epoch: 5| Step: 4
Training loss: 2.7828147858187817
Validation loss: 2.8821384537762422

Epoch: 5| Step: 5
Training loss: 2.9774141469984623
Validation loss: 2.8836083122844083

Epoch: 5| Step: 6
Training loss: 2.660178297850537
Validation loss: 2.88180336245916

Epoch: 5| Step: 7
Training loss: 2.7009838642879824
Validation loss: 2.8826304781583687

Epoch: 5| Step: 8
Training loss: 3.2507873461757155
Validation loss: 2.8840322443262814

Epoch: 5| Step: 9
Training loss: 3.6435112379310945
Validation loss: 2.882417285523869

Epoch: 5| Step: 10
Training loss: 3.2305084558189407
Validation loss: 2.883393763157224

Epoch: 121| Step: 0
Training loss: 2.886427682699855
Validation loss: 2.882110108178285

Epoch: 5| Step: 1
Training loss: 3.568337192476892
Validation loss: 2.8812848094606043

Epoch: 5| Step: 2
Training loss: 2.9677035444941144
Validation loss: 2.882916663575388

Epoch: 5| Step: 3
Training loss: 2.9054137636804147
Validation loss: 2.880507985955245

Epoch: 5| Step: 4
Training loss: 3.2976868701011175
Validation loss: 2.879479086950561

Epoch: 5| Step: 5
Training loss: 3.2388152819892597
Validation loss: 2.8784713137181415

Epoch: 5| Step: 6
Training loss: 2.903544161032919
Validation loss: 2.8787647127424516

Epoch: 5| Step: 7
Training loss: 3.545860649628244
Validation loss: 2.880489175828002

Epoch: 5| Step: 8
Training loss: 2.935848989568568
Validation loss: 2.8785052347807207

Epoch: 5| Step: 9
Training loss: 3.7513689721272505
Validation loss: 2.8787535730190092

Epoch: 5| Step: 10
Training loss: 2.7427653603155386
Validation loss: 2.877021788452928

Epoch: 122| Step: 0
Training loss: 2.7759339178668365
Validation loss: 2.878156470989081

Epoch: 5| Step: 1
Training loss: 3.3652859516143367
Validation loss: 2.8784065662801015

Epoch: 5| Step: 2
Training loss: 3.036710873675308
Validation loss: 2.878108768805504

Epoch: 5| Step: 3
Training loss: 3.370727943561574
Validation loss: 2.8795048195820425

Epoch: 5| Step: 4
Training loss: 2.84710964404171
Validation loss: 2.880647292773277

Epoch: 5| Step: 5
Training loss: 3.747211309488888
Validation loss: 2.8803222600488154

Epoch: 5| Step: 6
Training loss: 3.3258981911313814
Validation loss: 2.8864626391125032

Epoch: 5| Step: 7
Training loss: 3.210679686654053
Validation loss: 2.887974415539638

Epoch: 5| Step: 8
Training loss: 2.998176974477672
Validation loss: 2.884592163185992

Epoch: 5| Step: 9
Training loss: 3.230887186426288
Validation loss: 2.8778323631173977

Epoch: 5| Step: 10
Training loss: 2.8925871916531607
Validation loss: 2.8771320870995365

Epoch: 123| Step: 0
Training loss: 3.4207006381492904
Validation loss: 2.8745282879850342

Epoch: 5| Step: 1
Training loss: 3.233790837853215
Validation loss: 2.877850601779496

Epoch: 5| Step: 2
Training loss: 3.163458872542686
Validation loss: 2.8772025176268907

Epoch: 5| Step: 3
Training loss: 2.628886842018349
Validation loss: 2.8756702367692863

Epoch: 5| Step: 4
Training loss: 3.58463345088921
Validation loss: 2.878568525657073

Epoch: 5| Step: 5
Training loss: 2.7259913504862823
Validation loss: 2.876271979902429

Epoch: 5| Step: 6
Training loss: 3.1162681658016798
Validation loss: 2.8778824804098884

Epoch: 5| Step: 7
Training loss: 3.12966296395384
Validation loss: 2.875706621945034

Epoch: 5| Step: 8
Training loss: 3.8381002199049816
Validation loss: 2.8768839002867335

Epoch: 5| Step: 9
Training loss: 2.9586012992027233
Validation loss: 2.8736573758528268

Epoch: 5| Step: 10
Training loss: 2.897971061746345
Validation loss: 2.8738924294427184

Epoch: 124| Step: 0
Training loss: 3.1627140138608296
Validation loss: 2.875773476967572

Epoch: 5| Step: 1
Training loss: 2.9766365102142434
Validation loss: 2.8741008427877843

Epoch: 5| Step: 2
Training loss: 3.4217348113585153
Validation loss: 2.8765914225469054

Epoch: 5| Step: 3
Training loss: 2.913947627280925
Validation loss: 2.874502801548346

Epoch: 5| Step: 4
Training loss: 3.314228974171414
Validation loss: 2.876200474820758

Epoch: 5| Step: 5
Training loss: 2.528165468474389
Validation loss: 2.8779997065689344

Epoch: 5| Step: 6
Training loss: 3.486912919265832
Validation loss: 2.8752428463190234

Epoch: 5| Step: 7
Training loss: 3.3292182953371823
Validation loss: 2.878454015933101

Epoch: 5| Step: 8
Training loss: 3.4226636282661285
Validation loss: 2.8817165614946845

Epoch: 5| Step: 9
Training loss: 3.573938711066745
Validation loss: 2.878132147018161

Epoch: 5| Step: 10
Training loss: 2.429569155641275
Validation loss: 2.878382007508843

Epoch: 125| Step: 0
Training loss: 3.4670412820977514
Validation loss: 2.8752368920359226

Epoch: 5| Step: 1
Training loss: 3.4712508525579473
Validation loss: 2.871885511150623

Epoch: 5| Step: 2
Training loss: 2.837050878800697
Validation loss: 2.8739758103314674

Epoch: 5| Step: 3
Training loss: 2.6540211021314586
Validation loss: 2.871755121514595

Epoch: 5| Step: 4
Training loss: 3.455960865585079
Validation loss: 2.874740041328683

Epoch: 5| Step: 5
Training loss: 3.4906250874272593
Validation loss: 2.873331283867629

Epoch: 5| Step: 6
Training loss: 2.699506156404233
Validation loss: 2.8708491775025706

Epoch: 5| Step: 7
Training loss: 2.942215725788168
Validation loss: 2.871036456475882

Epoch: 5| Step: 8
Training loss: 3.153107239868838
Validation loss: 2.8739743447441013

Epoch: 5| Step: 9
Training loss: 3.1223226140430382
Validation loss: 2.8729016447507014

Epoch: 5| Step: 10
Training loss: 3.4595627648484397
Validation loss: 2.870244046677437

Epoch: 126| Step: 0
Training loss: 2.623738576165383
Validation loss: 2.874573440973398

Epoch: 5| Step: 1
Training loss: 3.8246419202954733
Validation loss: 2.873091584600573

Epoch: 5| Step: 2
Training loss: 3.243217139310861
Validation loss: 2.8687755014779057

Epoch: 5| Step: 3
Training loss: 2.625982191619571
Validation loss: 2.8686580431516533

Epoch: 5| Step: 4
Training loss: 3.0560608725352028
Validation loss: 2.870303340621288

Epoch: 5| Step: 5
Training loss: 3.164032660449573
Validation loss: 2.8724547002782446

Epoch: 5| Step: 6
Training loss: 2.8094997934157036
Validation loss: 2.8708891671182752

Epoch: 5| Step: 7
Training loss: 3.1098535830753358
Validation loss: 2.872080045510366

Epoch: 5| Step: 8
Training loss: 3.8669382959083785
Validation loss: 2.8697507303099155

Epoch: 5| Step: 9
Training loss: 3.013975334588006
Validation loss: 2.8691372796512042

Epoch: 5| Step: 10
Training loss: 3.3559577061621795
Validation loss: 2.8698955232945997

Epoch: 127| Step: 0
Training loss: 2.8114996932611462
Validation loss: 2.8703944236508234

Epoch: 5| Step: 1
Training loss: 3.01881895756595
Validation loss: 2.8734512402021517

Epoch: 5| Step: 2
Training loss: 4.0098671805058395
Validation loss: 2.87417620519481

Epoch: 5| Step: 3
Training loss: 3.58797594694753
Validation loss: 2.8738499214122237

Epoch: 5| Step: 4
Training loss: 3.3936370268787788
Validation loss: 2.8731292534114727

Epoch: 5| Step: 5
Training loss: 2.495826862137885
Validation loss: 2.8701231765211457

Epoch: 5| Step: 6
Training loss: 2.8488507480055216
Validation loss: 2.868516614214214

Epoch: 5| Step: 7
Training loss: 3.1501420851860558
Validation loss: 2.8663214142473032

Epoch: 5| Step: 8
Training loss: 3.0727818001499894
Validation loss: 2.8694519612546157

Epoch: 5| Step: 9
Training loss: 3.0807957560075896
Validation loss: 2.8687841643707617

Epoch: 5| Step: 10
Training loss: 3.1146128641385
Validation loss: 2.867973079414376

Epoch: 128| Step: 0
Training loss: 2.756545686323478
Validation loss: 2.8729734701886946

Epoch: 5| Step: 1
Training loss: 3.7705337377297656
Validation loss: 2.8707002907173296

Epoch: 5| Step: 2
Training loss: 3.2170713917853533
Validation loss: 2.867962443940474

Epoch: 5| Step: 3
Training loss: 3.3772209771682826
Validation loss: 2.870685233186503

Epoch: 5| Step: 4
Training loss: 2.432131111896084
Validation loss: 2.8669576616203787

Epoch: 5| Step: 5
Training loss: 3.2423736886486143
Validation loss: 2.8710584618104233

Epoch: 5| Step: 6
Training loss: 2.9559472539942244
Validation loss: 2.8674528103084875

Epoch: 5| Step: 7
Training loss: 3.309188915348566
Validation loss: 2.8669447314234384

Epoch: 5| Step: 8
Training loss: 3.248017807014398
Validation loss: 2.866674920528326

Epoch: 5| Step: 9
Training loss: 3.452815529605069
Validation loss: 2.867586326126141

Epoch: 5| Step: 10
Training loss: 2.812570867705249
Validation loss: 2.8705647209771277

Epoch: 129| Step: 0
Training loss: 3.0122516323923847
Validation loss: 2.866677276088984

Epoch: 5| Step: 1
Training loss: 3.3887837416243545
Validation loss: 2.8632947625996357

Epoch: 5| Step: 2
Training loss: 3.0007541026600877
Validation loss: 2.866742148935428

Epoch: 5| Step: 3
Training loss: 2.4914374583105827
Validation loss: 2.8646076231940003

Epoch: 5| Step: 4
Training loss: 3.4187567451033924
Validation loss: 2.8687276138138906

Epoch: 5| Step: 5
Training loss: 3.3890076044964785
Validation loss: 2.8617291455174403

Epoch: 5| Step: 6
Training loss: 3.713426770987128
Validation loss: 2.8645410087494048

Epoch: 5| Step: 7
Training loss: 3.6553421849750007
Validation loss: 2.8610085417774

Epoch: 5| Step: 8
Training loss: 2.9978117909664737
Validation loss: 2.863415580778846

Epoch: 5| Step: 9
Training loss: 2.9622954221499955
Validation loss: 2.8612988376515007

Epoch: 5| Step: 10
Training loss: 2.3707993150180053
Validation loss: 2.8627309844727544

Epoch: 130| Step: 0
Training loss: 2.870016505762148
Validation loss: 2.8623102531015556

Epoch: 5| Step: 1
Training loss: 2.6508952302091098
Validation loss: 2.861733880903809

Epoch: 5| Step: 2
Training loss: 3.398905824861056
Validation loss: 2.864002280869936

Epoch: 5| Step: 3
Training loss: 3.8573996241446857
Validation loss: 2.8663157616276385

Epoch: 5| Step: 4
Training loss: 3.3387919236453496
Validation loss: 2.86276179207957

Epoch: 5| Step: 5
Training loss: 3.3018671360099128
Validation loss: 2.863394891912648

Epoch: 5| Step: 6
Training loss: 1.7865678477478328
Validation loss: 2.8672583625662518

Epoch: 5| Step: 7
Training loss: 3.5168534908718225
Validation loss: 2.8766214685688487

Epoch: 5| Step: 8
Training loss: 3.236286575151958
Validation loss: 2.876122653623441

Epoch: 5| Step: 9
Training loss: 3.5182296937405155
Validation loss: 2.886137444104881

Epoch: 5| Step: 10
Training loss: 2.745275166517681
Validation loss: 2.8876580183606992

Epoch: 131| Step: 0
Training loss: 2.785594247670071
Validation loss: 2.886820908612547

Epoch: 5| Step: 1
Training loss: 3.4878530890997372
Validation loss: 2.8768103278214214

Epoch: 5| Step: 2
Training loss: 3.7277726421772477
Validation loss: 2.8693720414724377

Epoch: 5| Step: 3
Training loss: 2.5149978898572316
Validation loss: 2.8627904205941417

Epoch: 5| Step: 4
Training loss: 2.7296590191076437
Validation loss: 2.864405751620369

Epoch: 5| Step: 5
Training loss: 3.431230966761874
Validation loss: 2.860972053009712

Epoch: 5| Step: 6
Training loss: 2.7446187861876448
Validation loss: 2.8622129242709557

Epoch: 5| Step: 7
Training loss: 3.3528009007402875
Validation loss: 2.8643029528614647

Epoch: 5| Step: 8
Training loss: 3.626578809314428
Validation loss: 2.867766039032892

Epoch: 5| Step: 9
Training loss: 3.138179149301058
Validation loss: 2.870053915698114

Epoch: 5| Step: 10
Training loss: 2.9122420037076555
Validation loss: 2.873842254164017

Epoch: 132| Step: 0
Training loss: 2.915478564282211
Validation loss: 2.8765114818813053

Epoch: 5| Step: 1
Training loss: 3.609561667631415
Validation loss: 2.867818626077746

Epoch: 5| Step: 2
Training loss: 2.081874018416664
Validation loss: 2.86221273438577

Epoch: 5| Step: 3
Training loss: 2.3252592947150412
Validation loss: 2.862324090927847

Epoch: 5| Step: 4
Training loss: 2.8807790971336096
Validation loss: 2.8643356410060408

Epoch: 5| Step: 5
Training loss: 3.8881647995060185
Validation loss: 2.8617104009788736

Epoch: 5| Step: 6
Training loss: 3.960178520725502
Validation loss: 2.8604204541812326

Epoch: 5| Step: 7
Training loss: 3.285750436287794
Validation loss: 2.8605990829960106

Epoch: 5| Step: 8
Training loss: 3.122882888811466
Validation loss: 2.8622166091158867

Epoch: 5| Step: 9
Training loss: 3.046638205692346
Validation loss: 2.867466317554835

Epoch: 5| Step: 10
Training loss: 3.233899657476853
Validation loss: 2.867434324911119

Epoch: 133| Step: 0
Training loss: 2.7373525919483748
Validation loss: 2.871515284428166

Epoch: 5| Step: 1
Training loss: 2.8035155161453233
Validation loss: 2.868773487221991

Epoch: 5| Step: 2
Training loss: 2.9540313460146805
Validation loss: 2.871835307056829

Epoch: 5| Step: 3
Training loss: 3.515701903455753
Validation loss: 2.8817418533587085

Epoch: 5| Step: 4
Training loss: 3.215744244706547
Validation loss: 2.8669707670218925

Epoch: 5| Step: 5
Training loss: 3.045158333005246
Validation loss: 2.8588254496761323

Epoch: 5| Step: 6
Training loss: 3.403589872305396
Validation loss: 2.859405623209847

Epoch: 5| Step: 7
Training loss: 3.26448207001123
Validation loss: 2.8607268643065042

Epoch: 5| Step: 8
Training loss: 3.752334503855007
Validation loss: 2.863750624159122

Epoch: 5| Step: 9
Training loss: 2.8459214524067673
Validation loss: 2.8588379341483834

Epoch: 5| Step: 10
Training loss: 3.1281757240108057
Validation loss: 2.860893846248476

Epoch: 134| Step: 0
Training loss: 3.329640647812748
Validation loss: 2.8599168656397884

Epoch: 5| Step: 1
Training loss: 3.3025728137690744
Validation loss: 2.8616139753906467

Epoch: 5| Step: 2
Training loss: 3.1671290478349077
Validation loss: 2.8631481208031313

Epoch: 5| Step: 3
Training loss: 2.4461900397872594
Validation loss: 2.8574848774405104

Epoch: 5| Step: 4
Training loss: 2.8029523917546504
Validation loss: 2.8573025215674304

Epoch: 5| Step: 5
Training loss: 2.6934452388982866
Validation loss: 2.8562834970479227

Epoch: 5| Step: 6
Training loss: 3.3320658817258
Validation loss: 2.8564015611597444

Epoch: 5| Step: 7
Training loss: 2.957493855461129
Validation loss: 2.8533229857891484

Epoch: 5| Step: 8
Training loss: 3.314207392739604
Validation loss: 2.8561844100416764

Epoch: 5| Step: 9
Training loss: 3.6346383705390455
Validation loss: 2.8577999638981892

Epoch: 5| Step: 10
Training loss: 3.6276301346301496
Validation loss: 2.8594008014836634

Epoch: 135| Step: 0
Training loss: 3.0813922098703705
Validation loss: 2.8586115892488015

Epoch: 5| Step: 1
Training loss: 3.62600141702194
Validation loss: 2.858116452563886

Epoch: 5| Step: 2
Training loss: 2.8438259575728844
Validation loss: 2.8566832370497393

Epoch: 5| Step: 3
Training loss: 3.2411175168726465
Validation loss: 2.854705516864906

Epoch: 5| Step: 4
Training loss: 3.149964825872797
Validation loss: 2.853971469408887

Epoch: 5| Step: 5
Training loss: 3.652104562689355
Validation loss: 2.8532308007194747

Epoch: 5| Step: 6
Training loss: 3.198699722759521
Validation loss: 2.851969630898357

Epoch: 5| Step: 7
Training loss: 2.935213375880991
Validation loss: 2.849944223485285

Epoch: 5| Step: 8
Training loss: 2.5391008110090465
Validation loss: 2.851261291913128

Epoch: 5| Step: 9
Training loss: 3.3090148441630785
Validation loss: 2.8504984737260584

Epoch: 5| Step: 10
Training loss: 2.954979692573285
Validation loss: 2.850531584582402

Epoch: 136| Step: 0
Training loss: 3.634507569300313
Validation loss: 2.849389393983265

Epoch: 5| Step: 1
Training loss: 3.615583356586161
Validation loss: 2.850547421285561

Epoch: 5| Step: 2
Training loss: 2.9565597017099776
Validation loss: 2.85138438308083

Epoch: 5| Step: 3
Training loss: 3.6599471481342776
Validation loss: 2.8526399369088558

Epoch: 5| Step: 4
Training loss: 2.4555114023871725
Validation loss: 2.8525305228273616

Epoch: 5| Step: 5
Training loss: 3.0890461004243486
Validation loss: 2.857945602750333

Epoch: 5| Step: 6
Training loss: 3.016793770685393
Validation loss: 2.8544079231230857

Epoch: 5| Step: 7
Training loss: 2.8928047828039785
Validation loss: 2.8563376085765593

Epoch: 5| Step: 8
Training loss: 3.2468705883124653
Validation loss: 2.8524249062991824

Epoch: 5| Step: 9
Training loss: 3.141955497140006
Validation loss: 2.8501181533549986

Epoch: 5| Step: 10
Training loss: 2.7140448183703687
Validation loss: 2.8464072964009706

Epoch: 137| Step: 0
Training loss: 3.1510180932206198
Validation loss: 2.8483895533435946

Epoch: 5| Step: 1
Training loss: 3.3589555345404647
Validation loss: 2.8492389521330286

Epoch: 5| Step: 2
Training loss: 3.0471181919171917
Validation loss: 2.8470793099848577

Epoch: 5| Step: 3
Training loss: 3.2296847184256436
Validation loss: 2.8493519997501418

Epoch: 5| Step: 4
Training loss: 3.0125401980935282
Validation loss: 2.84882187771961

Epoch: 5| Step: 5
Training loss: 3.446824345428311
Validation loss: 2.85044786147038

Epoch: 5| Step: 6
Training loss: 2.6697492564614955
Validation loss: 2.8491199604510222

Epoch: 5| Step: 7
Training loss: 3.1455335832148292
Validation loss: 2.8487672972136346

Epoch: 5| Step: 8
Training loss: 3.6015243693751575
Validation loss: 2.8476106674998163

Epoch: 5| Step: 9
Training loss: 3.25279482467735
Validation loss: 2.844212629299473

Epoch: 5| Step: 10
Training loss: 2.4891081054494224
Validation loss: 2.8469372953333627

Epoch: 138| Step: 0
Training loss: 3.837117745810629
Validation loss: 2.846142104996626

Epoch: 5| Step: 1
Training loss: 2.5190188811027303
Validation loss: 2.8456818091685188

Epoch: 5| Step: 2
Training loss: 3.2276630141194795
Validation loss: 2.8493675505995397

Epoch: 5| Step: 3
Training loss: 3.1462890261266994
Validation loss: 2.847790107015657

Epoch: 5| Step: 4
Training loss: 3.2546722865928044
Validation loss: 2.8460316087916366

Epoch: 5| Step: 5
Training loss: 3.648534083262218
Validation loss: 2.8495435138295195

Epoch: 5| Step: 6
Training loss: 2.7281781413177844
Validation loss: 2.8495869557250955

Epoch: 5| Step: 7
Training loss: 2.4546828456278478
Validation loss: 2.8511393670416205

Epoch: 5| Step: 8
Training loss: 3.043530785658248
Validation loss: 2.851529687009136

Epoch: 5| Step: 9
Training loss: 3.574043978394372
Validation loss: 2.845864763733277

Epoch: 5| Step: 10
Training loss: 2.8492206310938575
Validation loss: 2.8484887387002447

Epoch: 139| Step: 0
Training loss: 3.9938151704966103
Validation loss: 2.846141871704356

Epoch: 5| Step: 1
Training loss: 3.359051356139646
Validation loss: 2.849110166101655

Epoch: 5| Step: 2
Training loss: 2.750786668793255
Validation loss: 2.8506460342379247

Epoch: 5| Step: 3
Training loss: 2.868509014039009
Validation loss: 2.8458719253235487

Epoch: 5| Step: 4
Training loss: 3.39045834461361
Validation loss: 2.8464674219192765

Epoch: 5| Step: 5
Training loss: 2.612553197145708
Validation loss: 2.845373527509979

Epoch: 5| Step: 6
Training loss: 3.1236548008022904
Validation loss: 2.8530033082879704

Epoch: 5| Step: 7
Training loss: 3.279961033101172
Validation loss: 2.8516728628044063

Epoch: 5| Step: 8
Training loss: 3.3169567428588187
Validation loss: 2.857756141794888

Epoch: 5| Step: 9
Training loss: 2.9999930063801945
Validation loss: 2.8473170429657593

Epoch: 5| Step: 10
Training loss: 2.59849839864582
Validation loss: 2.842764071289119

Epoch: 140| Step: 0
Training loss: 3.5471531427027005
Validation loss: 2.8425825269960603

Epoch: 5| Step: 1
Training loss: 3.4626972899710213
Validation loss: 2.844426453828425

Epoch: 5| Step: 2
Training loss: 3.2636099261026676
Validation loss: 2.846408690619829

Epoch: 5| Step: 3
Training loss: 3.3013460477400294
Validation loss: 2.8491034553557513

Epoch: 5| Step: 4
Training loss: 3.0409381638536876
Validation loss: 2.8533189615147982

Epoch: 5| Step: 5
Training loss: 3.1867363706916616
Validation loss: 2.853262754953602

Epoch: 5| Step: 6
Training loss: 3.05987638859624
Validation loss: 2.8543828713631525

Epoch: 5| Step: 7
Training loss: 3.261566268189189
Validation loss: 2.8531331540750373

Epoch: 5| Step: 8
Training loss: 2.9521550598978816
Validation loss: 2.8489309051147793

Epoch: 5| Step: 9
Training loss: 2.681543447090961
Validation loss: 2.846570938625943

Epoch: 5| Step: 10
Training loss: 2.862181739938777
Validation loss: 2.843805905071712

Epoch: 141| Step: 0
Training loss: 3.531195581067479
Validation loss: 2.842110915247764

Epoch: 5| Step: 1
Training loss: 3.126983928349997
Validation loss: 2.841105743895652

Epoch: 5| Step: 2
Training loss: 3.3711255758292737
Validation loss: 2.8427668632997505

Epoch: 5| Step: 3
Training loss: 3.3391649415256306
Validation loss: 2.840898097265904

Epoch: 5| Step: 4
Training loss: 3.380855002750278
Validation loss: 2.8423834051064074

Epoch: 5| Step: 5
Training loss: 2.6327907663234997
Validation loss: 2.8469962678603005

Epoch: 5| Step: 6
Training loss: 3.118700773962948
Validation loss: 2.8495047424107773

Epoch: 5| Step: 7
Training loss: 3.5077392298601255
Validation loss: 2.849707573304276

Epoch: 5| Step: 8
Training loss: 3.130745450789112
Validation loss: 2.8494031488050946

Epoch: 5| Step: 9
Training loss: 2.5990935285999535
Validation loss: 2.8509878071962533

Epoch: 5| Step: 10
Training loss: 2.6368054637072262
Validation loss: 2.8525736163679785

Epoch: 142| Step: 0
Training loss: 3.29198624874316
Validation loss: 2.8557787633585394

Epoch: 5| Step: 1
Training loss: 2.62615868563548
Validation loss: 2.847312899457112

Epoch: 5| Step: 2
Training loss: 2.6933365365125788
Validation loss: 2.840559795269379

Epoch: 5| Step: 3
Training loss: 2.7730108228404173
Validation loss: 2.8404353929340243

Epoch: 5| Step: 4
Training loss: 2.893466521975664
Validation loss: 2.840103293953426

Epoch: 5| Step: 5
Training loss: 3.480730417264586
Validation loss: 2.837754450853467

Epoch: 5| Step: 6
Training loss: 3.038925363932736
Validation loss: 2.8381301510839827

Epoch: 5| Step: 7
Training loss: 3.547209870919279
Validation loss: 2.839542035545776

Epoch: 5| Step: 8
Training loss: 3.52548232870687
Validation loss: 2.839996218698316

Epoch: 5| Step: 9
Training loss: 3.3725558720422093
Validation loss: 2.8397480940552784

Epoch: 5| Step: 10
Training loss: 3.1843515442048917
Validation loss: 2.8409066628812107

Epoch: 143| Step: 0
Training loss: 2.9805301844913537
Validation loss: 2.8369886614742996

Epoch: 5| Step: 1
Training loss: 2.4019331418340055
Validation loss: 2.8382425310729387

Epoch: 5| Step: 2
Training loss: 3.8372549370168456
Validation loss: 2.83817306493066

Epoch: 5| Step: 3
Training loss: 3.2776751708729215
Validation loss: 2.837976731191847

Epoch: 5| Step: 4
Training loss: 2.8229911109333035
Validation loss: 2.8390442259472852

Epoch: 5| Step: 5
Training loss: 3.2966988322119475
Validation loss: 2.839562732081703

Epoch: 5| Step: 6
Training loss: 3.036361788768341
Validation loss: 2.836889959650214

Epoch: 5| Step: 7
Training loss: 3.3167363554056464
Validation loss: 2.838903696696784

Epoch: 5| Step: 8
Training loss: 3.5550667026018976
Validation loss: 2.837213947470014

Epoch: 5| Step: 9
Training loss: 2.7152886115397603
Validation loss: 2.84271953311827

Epoch: 5| Step: 10
Training loss: 3.0502515032523565
Validation loss: 2.847018494125757

Epoch: 144| Step: 0
Training loss: 3.4329551476144027
Validation loss: 2.839363309030292

Epoch: 5| Step: 1
Training loss: 2.475854140581256
Validation loss: 2.8377876019977575

Epoch: 5| Step: 2
Training loss: 3.6364111355366946
Validation loss: 2.8358545031587004

Epoch: 5| Step: 3
Training loss: 3.332714802257468
Validation loss: 2.8352133936314363

Epoch: 5| Step: 4
Training loss: 3.509822414068253
Validation loss: 2.835867827329781

Epoch: 5| Step: 5
Training loss: 3.4518312818420345
Validation loss: 2.834102801796995

Epoch: 5| Step: 6
Training loss: 2.9941957273346156
Validation loss: 2.835791531839741

Epoch: 5| Step: 7
Training loss: 2.459335726238992
Validation loss: 2.8338188217505826

Epoch: 5| Step: 8
Training loss: 2.839980257261184
Validation loss: 2.8372363822891207

Epoch: 5| Step: 9
Training loss: 2.9474094525148566
Validation loss: 2.8342573865597016

Epoch: 5| Step: 10
Training loss: 3.22935737949095
Validation loss: 2.8367740259852385

Epoch: 145| Step: 0
Training loss: 2.8704577513580554
Validation loss: 2.8383671568714526

Epoch: 5| Step: 1
Training loss: 3.1144262335886737
Validation loss: 2.8376979332942307

Epoch: 5| Step: 2
Training loss: 2.8371323939758724
Validation loss: 2.8313264893650603

Epoch: 5| Step: 3
Training loss: 3.1609259989402423
Validation loss: 2.835646355369153

Epoch: 5| Step: 4
Training loss: 3.1741452666068937
Validation loss: 2.8309279965382492

Epoch: 5| Step: 5
Training loss: 3.286605533420768
Validation loss: 2.832572299757996

Epoch: 5| Step: 6
Training loss: 3.061710800935394
Validation loss: 2.832729082139696

Epoch: 5| Step: 7
Training loss: 2.6766523516483183
Validation loss: 2.8307451325698647

Epoch: 5| Step: 8
Training loss: 2.924947011092713
Validation loss: 2.8321186033814354

Epoch: 5| Step: 9
Training loss: 3.555263732484488
Validation loss: 2.833257803251016

Epoch: 5| Step: 10
Training loss: 3.8117443649141256
Validation loss: 2.832661624803765

Epoch: 146| Step: 0
Training loss: 3.282565334625714
Validation loss: 2.8319647455663546

Epoch: 5| Step: 1
Training loss: 3.373624026648665
Validation loss: 2.8304720204444465

Epoch: 5| Step: 2
Training loss: 2.6255132082663395
Validation loss: 2.831969036455719

Epoch: 5| Step: 3
Training loss: 3.632096677417726
Validation loss: 2.8314424188198446

Epoch: 5| Step: 4
Training loss: 3.641555732649399
Validation loss: 2.8366822574717663

Epoch: 5| Step: 5
Training loss: 3.296680462779102
Validation loss: 2.8389102563641946

Epoch: 5| Step: 6
Training loss: 3.060617140576221
Validation loss: 2.8331299684084263

Epoch: 5| Step: 7
Training loss: 2.7146016184458626
Validation loss: 2.837599698833616

Epoch: 5| Step: 8
Training loss: 2.574966808216278
Validation loss: 2.844864081751939

Epoch: 5| Step: 9
Training loss: 3.1905369969709687
Validation loss: 2.846361665978807

Epoch: 5| Step: 10
Training loss: 2.847392338165116
Validation loss: 2.8435626404911734

Epoch: 147| Step: 0
Training loss: 3.199133940563528
Validation loss: 2.8567622985332455

Epoch: 5| Step: 1
Training loss: 3.0878952576459557
Validation loss: 2.85181804146349

Epoch: 5| Step: 2
Training loss: 3.6105718568678227
Validation loss: 2.846354293962093

Epoch: 5| Step: 3
Training loss: 3.158374184886942
Validation loss: 2.844239644534348

Epoch: 5| Step: 4
Training loss: 3.139695974319365
Validation loss: 2.8317185009921637

Epoch: 5| Step: 5
Training loss: 2.8296497934357903
Validation loss: 2.829127430752879

Epoch: 5| Step: 6
Training loss: 2.7425683781350534
Validation loss: 2.828840111957628

Epoch: 5| Step: 7
Training loss: 2.605635927890656
Validation loss: 2.8254185709058364

Epoch: 5| Step: 8
Training loss: 3.639578869530674
Validation loss: 2.830148084228696

Epoch: 5| Step: 9
Training loss: 2.216484632642307
Validation loss: 2.83002957618663

Epoch: 5| Step: 10
Training loss: 4.021513069424705
Validation loss: 2.82889155032592

Epoch: 148| Step: 0
Training loss: 3.111979405018732
Validation loss: 2.832740503309409

Epoch: 5| Step: 1
Training loss: 2.633162659131984
Validation loss: 2.831990475415882

Epoch: 5| Step: 2
Training loss: 3.591715361109437
Validation loss: 2.8338220360033577

Epoch: 5| Step: 3
Training loss: 3.021499683067637
Validation loss: 2.8370125936010435

Epoch: 5| Step: 4
Training loss: 2.8758568523472916
Validation loss: 2.83059110047328

Epoch: 5| Step: 5
Training loss: 3.002637022069719
Validation loss: 2.827468160350976

Epoch: 5| Step: 6
Training loss: 3.1203687300794622
Validation loss: 2.828895354698042

Epoch: 5| Step: 7
Training loss: 3.3931300318834
Validation loss: 2.828907605140257

Epoch: 5| Step: 8
Training loss: 3.7752415863947744
Validation loss: 2.828139721660951

Epoch: 5| Step: 9
Training loss: 3.075092041374899
Validation loss: 2.827269482811208

Epoch: 5| Step: 10
Training loss: 2.6628929099002776
Validation loss: 2.826522268759969

Epoch: 149| Step: 0
Training loss: 3.369670474640809
Validation loss: 2.82600316618192

Epoch: 5| Step: 1
Training loss: 3.0199626500933725
Validation loss: 2.8281270051345238

Epoch: 5| Step: 2
Training loss: 2.811344672373404
Validation loss: 2.825699682668053

Epoch: 5| Step: 3
Training loss: 2.9843673306511405
Validation loss: 2.8258368731845747

Epoch: 5| Step: 4
Training loss: 2.543170317412245
Validation loss: 2.8255880096163724

Epoch: 5| Step: 5
Training loss: 3.225758893523809
Validation loss: 2.827469714419349

Epoch: 5| Step: 6
Training loss: 2.9492236004720045
Validation loss: 2.8326533845036415

Epoch: 5| Step: 7
Training loss: 3.2211235701915193
Validation loss: 2.8339727182168994

Epoch: 5| Step: 8
Training loss: 3.207511466311314
Validation loss: 2.8388768429002886

Epoch: 5| Step: 9
Training loss: 3.75816042235185
Validation loss: 2.8442330187409492

Epoch: 5| Step: 10
Training loss: 3.2329747214162388
Validation loss: 2.8487744474575756

Epoch: 150| Step: 0
Training loss: 3.092028206167333
Validation loss: 2.852512324485783

Epoch: 5| Step: 1
Training loss: 3.9455936142887564
Validation loss: 2.843795617337307

Epoch: 5| Step: 2
Training loss: 2.8960401795060573
Validation loss: 2.8341458702461124

Epoch: 5| Step: 3
Training loss: 2.274820857278379
Validation loss: 2.8283241005635995

Epoch: 5| Step: 4
Training loss: 3.0981632698039503
Validation loss: 2.8259422460170276

Epoch: 5| Step: 5
Training loss: 3.3985275782781845
Validation loss: 2.823494334024861

Epoch: 5| Step: 6
Training loss: 2.6870514251365054
Validation loss: 2.823586573828062

Epoch: 5| Step: 7
Training loss: 3.46990315282929
Validation loss: 2.823047299051599

Epoch: 5| Step: 8
Training loss: 2.860785798113943
Validation loss: 2.8221542330170797

Epoch: 5| Step: 9
Training loss: 3.067953742184613
Validation loss: 2.8215295854244613

Epoch: 5| Step: 10
Training loss: 3.451041581307105
Validation loss: 2.8223932452478433

Testing loss: 3.042929208781793
