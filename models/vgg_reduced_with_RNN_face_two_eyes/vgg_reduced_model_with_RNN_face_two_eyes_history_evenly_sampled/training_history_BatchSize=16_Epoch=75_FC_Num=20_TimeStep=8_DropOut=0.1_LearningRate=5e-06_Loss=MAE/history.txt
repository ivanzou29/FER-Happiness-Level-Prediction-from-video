Epoch: 1| Step: 0
Training loss: 4.535182476043701
Validation loss: 5.216000613345895

Epoch: 6| Step: 1
Training loss: 4.6998395919799805
Validation loss: 5.211113652875347

Epoch: 6| Step: 2
Training loss: 4.307522773742676
Validation loss: 5.206901170874155

Epoch: 6| Step: 3
Training loss: 4.866340637207031
Validation loss: 5.2026588480959655

Epoch: 6| Step: 4
Training loss: 5.862009048461914
Validation loss: 5.199091003787133

Epoch: 6| Step: 5
Training loss: 5.596181869506836
Validation loss: 5.195388717036093

Epoch: 6| Step: 6
Training loss: 6.198447227478027
Validation loss: 5.192455553239392

Epoch: 6| Step: 7
Training loss: 5.094727039337158
Validation loss: 5.189135674507387

Epoch: 6| Step: 8
Training loss: 4.1270246505737305
Validation loss: 5.186075041371007

Epoch: 6| Step: 9
Training loss: 4.398447036743164
Validation loss: 5.182609788833126

Epoch: 6| Step: 10
Training loss: 4.79248046875
Validation loss: 5.179351150348622

Epoch: 6| Step: 11
Training loss: 5.273385047912598
Validation loss: 5.175826529020904

Epoch: 6| Step: 12
Training loss: 5.27410888671875
Validation loss: 5.171841785471926

Epoch: 6| Step: 13
Training loss: 4.649035930633545
Validation loss: 5.167756301100536

Epoch: 2| Step: 0
Training loss: 5.730320453643799
Validation loss: 5.16357240369243

Epoch: 6| Step: 1
Training loss: 4.265326976776123
Validation loss: 5.159357163213914

Epoch: 6| Step: 2
Training loss: 4.269687652587891
Validation loss: 5.15467216122535

Epoch: 6| Step: 3
Training loss: 4.985270977020264
Validation loss: 5.150054075384653

Epoch: 6| Step: 4
Training loss: 4.308506011962891
Validation loss: 5.145174390526228

Epoch: 6| Step: 5
Training loss: 4.647858619689941
Validation loss: 5.139482344350507

Epoch: 6| Step: 6
Training loss: 4.614147186279297
Validation loss: 5.1342106737116335

Epoch: 6| Step: 7
Training loss: 3.27134370803833
Validation loss: 5.1278322845376945

Epoch: 6| Step: 8
Training loss: 5.760931015014648
Validation loss: 5.122289657592773

Epoch: 6| Step: 9
Training loss: 5.847024917602539
Validation loss: 5.115588049734792

Epoch: 6| Step: 10
Training loss: 4.314627170562744
Validation loss: 5.10870018313008

Epoch: 6| Step: 11
Training loss: 4.605953216552734
Validation loss: 5.10144845900997

Epoch: 6| Step: 12
Training loss: 7.215586185455322
Validation loss: 5.094131708145142

Epoch: 6| Step: 13
Training loss: 5.243718147277832
Validation loss: 5.085763264727849

Epoch: 3| Step: 0
Training loss: 3.8281383514404297
Validation loss: 5.078021551973077

Epoch: 6| Step: 1
Training loss: 4.891627311706543
Validation loss: 5.069161650955036

Epoch: 6| Step: 2
Training loss: 4.1329474449157715
Validation loss: 5.059665982441236

Epoch: 6| Step: 3
Training loss: 3.9639687538146973
Validation loss: 5.050253606611682

Epoch: 6| Step: 4
Training loss: 5.04910135269165
Validation loss: 5.040081654825518

Epoch: 6| Step: 5
Training loss: 4.453897476196289
Validation loss: 5.0294491449991865

Epoch: 6| Step: 6
Training loss: 3.939316987991333
Validation loss: 5.018189137981784

Epoch: 6| Step: 7
Training loss: 5.035341739654541
Validation loss: 5.007051703750446

Epoch: 6| Step: 8
Training loss: 5.378322601318359
Validation loss: 4.994568737604284

Epoch: 6| Step: 9
Training loss: 6.745011329650879
Validation loss: 4.982180585143387

Epoch: 6| Step: 10
Training loss: 6.082218170166016
Validation loss: 4.967970601973995

Epoch: 6| Step: 11
Training loss: 4.229464054107666
Validation loss: 4.9542118503201396

Epoch: 6| Step: 12
Training loss: 5.277386665344238
Validation loss: 4.940087928566881

Epoch: 6| Step: 13
Training loss: 3.7762935161590576
Validation loss: 4.924148374988187

Epoch: 4| Step: 0
Training loss: 3.7381930351257324
Validation loss: 4.908316596861808

Epoch: 6| Step: 1
Training loss: 5.40217399597168
Validation loss: 4.892121340638848

Epoch: 6| Step: 2
Training loss: 5.567844867706299
Validation loss: 4.874588448514221

Epoch: 6| Step: 3
Training loss: 4.450080871582031
Validation loss: 4.856776099051198

Epoch: 6| Step: 4
Training loss: 4.095499515533447
Validation loss: 4.838617945230135

Epoch: 6| Step: 5
Training loss: 4.755481719970703
Validation loss: 4.81906472995717

Epoch: 6| Step: 6
Training loss: 4.58902645111084
Validation loss: 4.799943749622632

Epoch: 6| Step: 7
Training loss: 4.8258585929870605
Validation loss: 4.779806434467274

Epoch: 6| Step: 8
Training loss: 4.157552719116211
Validation loss: 4.758731706168062

Epoch: 6| Step: 9
Training loss: 3.474518060684204
Validation loss: 4.7387019434282855

Epoch: 6| Step: 10
Training loss: 4.842937469482422
Validation loss: 4.717666964377126

Epoch: 6| Step: 11
Training loss: 4.7843146324157715
Validation loss: 4.695802268161569

Epoch: 6| Step: 12
Training loss: 4.930331230163574
Validation loss: 4.674612093997258

Epoch: 6| Step: 13
Training loss: 4.393513202667236
Validation loss: 4.652831077575684

Epoch: 5| Step: 0
Training loss: 4.867064952850342
Validation loss: 4.629830683431318

Epoch: 6| Step: 1
Training loss: 3.959909439086914
Validation loss: 4.607948928750972

Epoch: 6| Step: 2
Training loss: 4.3569536209106445
Validation loss: 4.586038210058725

Epoch: 6| Step: 3
Training loss: 4.606771469116211
Validation loss: 4.564794181495585

Epoch: 6| Step: 4
Training loss: 4.511346340179443
Validation loss: 4.540660653063046

Epoch: 6| Step: 5
Training loss: 4.921939849853516
Validation loss: 4.519802354997204

Epoch: 6| Step: 6
Training loss: 3.867016315460205
Validation loss: 4.497741314672655

Epoch: 6| Step: 7
Training loss: 3.593447685241699
Validation loss: 4.4775921247338735

Epoch: 6| Step: 8
Training loss: 5.0701823234558105
Validation loss: 4.454714123920728

Epoch: 6| Step: 9
Training loss: 3.811807632446289
Validation loss: 4.433573502366261

Epoch: 6| Step: 10
Training loss: 3.2027969360351562
Validation loss: 4.412255928080569

Epoch: 6| Step: 11
Training loss: 4.255836486816406
Validation loss: 4.392160236194569

Epoch: 6| Step: 12
Training loss: 4.546091556549072
Validation loss: 4.372659524281819

Epoch: 6| Step: 13
Training loss: 4.483959674835205
Validation loss: 4.352605045482677

Epoch: 6| Step: 0
Training loss: 5.066701889038086
Validation loss: 4.333368409064509

Epoch: 6| Step: 1
Training loss: 3.7627615928649902
Validation loss: 4.314212296598701

Epoch: 6| Step: 2
Training loss: 4.368772029876709
Validation loss: 4.295342676101193

Epoch: 6| Step: 3
Training loss: 3.0050137042999268
Validation loss: 4.278437386276901

Epoch: 6| Step: 4
Training loss: 3.4145898818969727
Validation loss: 4.259470424344463

Epoch: 6| Step: 5
Training loss: 4.359189510345459
Validation loss: 4.2424625837674705

Epoch: 6| Step: 6
Training loss: 3.243788242340088
Validation loss: 4.224508267576977

Epoch: 6| Step: 7
Training loss: 2.607189178466797
Validation loss: 4.208861709922872

Epoch: 6| Step: 8
Training loss: 5.455080986022949
Validation loss: 4.191312897589899

Epoch: 6| Step: 9
Training loss: 2.992886543273926
Validation loss: 4.175913313383697

Epoch: 6| Step: 10
Training loss: 4.827157497406006
Validation loss: 4.15931039215416

Epoch: 6| Step: 11
Training loss: 4.370038032531738
Validation loss: 4.142955318573983

Epoch: 6| Step: 12
Training loss: 4.341841220855713
Validation loss: 4.129092134455199

Epoch: 6| Step: 13
Training loss: 5.16269588470459
Validation loss: 4.111898042822397

Epoch: 7| Step: 0
Training loss: 4.664936542510986
Validation loss: 4.098424647444038

Epoch: 6| Step: 1
Training loss: 3.2552871704101562
Validation loss: 4.083062238590692

Epoch: 6| Step: 2
Training loss: 3.6294007301330566
Validation loss: 4.068969941908313

Epoch: 6| Step: 3
Training loss: 3.9739151000976562
Validation loss: 4.052880194879347

Epoch: 6| Step: 4
Training loss: 4.42020320892334
Validation loss: 4.0384330185510775

Epoch: 6| Step: 5
Training loss: 3.225801706314087
Validation loss: 4.0243194795423936

Epoch: 6| Step: 6
Training loss: 3.846188545227051
Validation loss: 4.010171182693973

Epoch: 6| Step: 7
Training loss: 3.650749444961548
Validation loss: 3.995471267290013

Epoch: 6| Step: 8
Training loss: 3.155153274536133
Validation loss: 3.9804349227618148

Epoch: 6| Step: 9
Training loss: 4.339359283447266
Validation loss: 3.966622024454096

Epoch: 6| Step: 10
Training loss: 4.864668846130371
Validation loss: 3.9499500772004486

Epoch: 6| Step: 11
Training loss: 4.198611736297607
Validation loss: 3.9324051846740065

Epoch: 6| Step: 12
Training loss: 2.9889347553253174
Validation loss: 3.9172271195278374

Epoch: 6| Step: 13
Training loss: 3.6483068466186523
Validation loss: 3.903132072059057

Epoch: 8| Step: 0
Training loss: 4.543059349060059
Validation loss: 3.8920775023839806

Epoch: 6| Step: 1
Training loss: 3.6258621215820312
Validation loss: 3.8811236196948635

Epoch: 6| Step: 2
Training loss: 3.28202223777771
Validation loss: 3.8723390333114134

Epoch: 6| Step: 3
Training loss: 3.462007522583008
Validation loss: 3.859186828777354

Epoch: 6| Step: 4
Training loss: 4.3120036125183105
Validation loss: 3.8468226361018356

Epoch: 6| Step: 5
Training loss: 3.8221192359924316
Validation loss: 3.834133809612643

Epoch: 6| Step: 6
Training loss: 3.2124383449554443
Validation loss: 3.8240437225628923

Epoch: 6| Step: 7
Training loss: 4.387659072875977
Validation loss: 3.812052562672605

Epoch: 6| Step: 8
Training loss: 3.7632484436035156
Validation loss: 3.8031762953727477

Epoch: 6| Step: 9
Training loss: 3.608264446258545
Validation loss: 3.7924106454336517

Epoch: 6| Step: 10
Training loss: 3.7053065299987793
Validation loss: 3.784507833501344

Epoch: 6| Step: 11
Training loss: 2.6316447257995605
Validation loss: 3.775953902993151

Epoch: 6| Step: 12
Training loss: 3.416651725769043
Validation loss: 3.7676071966848066

Epoch: 6| Step: 13
Training loss: 4.34459114074707
Validation loss: 3.757476688713156

Epoch: 9| Step: 0
Training loss: 3.2751479148864746
Validation loss: 3.749385041575278

Epoch: 6| Step: 1
Training loss: 3.065721273422241
Validation loss: 3.7397911676796536

Epoch: 6| Step: 2
Training loss: 3.634887218475342
Validation loss: 3.7320862713680474

Epoch: 6| Step: 3
Training loss: 3.3488564491271973
Validation loss: 3.719909457750218

Epoch: 6| Step: 4
Training loss: 4.807251930236816
Validation loss: 3.7134254363275345

Epoch: 6| Step: 5
Training loss: 3.722773313522339
Validation loss: 3.7028756654390724

Epoch: 6| Step: 6
Training loss: 3.966707706451416
Validation loss: 3.6943495811954623

Epoch: 6| Step: 7
Training loss: 3.1409735679626465
Validation loss: 3.686322599328974

Epoch: 6| Step: 8
Training loss: 3.1911420822143555
Validation loss: 3.6788395732961674

Epoch: 6| Step: 9
Training loss: 3.6418509483337402
Validation loss: 3.672398428763113

Epoch: 6| Step: 10
Training loss: 3.667964220046997
Validation loss: 3.6639884518038843

Epoch: 6| Step: 11
Training loss: 3.7446160316467285
Validation loss: 3.6570229299606813

Epoch: 6| Step: 12
Training loss: 3.4493422508239746
Validation loss: 3.6493269089729554

Epoch: 6| Step: 13
Training loss: 3.7993757724761963
Validation loss: 3.6424138597262803

Epoch: 10| Step: 0
Training loss: 4.072864532470703
Validation loss: 3.6342818224301903

Epoch: 6| Step: 1
Training loss: 4.341146469116211
Validation loss: 3.6257637239271596

Epoch: 6| Step: 2
Training loss: 4.434379577636719
Validation loss: 3.6174097855885825

Epoch: 6| Step: 3
Training loss: 3.1218504905700684
Validation loss: 3.6137555183902865

Epoch: 6| Step: 4
Training loss: 3.749110221862793
Validation loss: 3.6063761659847793

Epoch: 6| Step: 5
Training loss: 3.0038881301879883
Validation loss: 3.598625744542768

Epoch: 6| Step: 6
Training loss: 3.0843698978424072
Validation loss: 3.590859866911365

Epoch: 6| Step: 7
Training loss: 3.85467529296875
Validation loss: 3.584789978560581

Epoch: 6| Step: 8
Training loss: 3.065743923187256
Validation loss: 3.579172549709197

Epoch: 6| Step: 9
Training loss: 4.071358680725098
Validation loss: 3.57099885325278

Epoch: 6| Step: 10
Training loss: 4.320256233215332
Validation loss: 3.5646305596956642

Epoch: 6| Step: 11
Training loss: 2.0449633598327637
Validation loss: 3.557804681921518

Epoch: 6| Step: 12
Training loss: 3.0782902240753174
Validation loss: 3.5512065528541483

Epoch: 6| Step: 13
Training loss: 2.452028512954712
Validation loss: 3.54536348260859

Epoch: 11| Step: 0
Training loss: 4.693447589874268
Validation loss: 3.5389774563491985

Epoch: 6| Step: 1
Training loss: 3.847057819366455
Validation loss: 3.533059604706303

Epoch: 6| Step: 2
Training loss: 1.997509241104126
Validation loss: 3.524593912145143

Epoch: 6| Step: 3
Training loss: 3.361647129058838
Validation loss: 3.5200977017802577

Epoch: 6| Step: 4
Training loss: 3.8725571632385254
Validation loss: 3.512751753612231

Epoch: 6| Step: 5
Training loss: 3.6528825759887695
Validation loss: 3.5075161380152546

Epoch: 6| Step: 6
Training loss: 3.436497926712036
Validation loss: 3.5018346899299213

Epoch: 6| Step: 7
Training loss: 3.5231056213378906
Validation loss: 3.492911566970169

Epoch: 6| Step: 8
Training loss: 2.9909327030181885
Validation loss: 3.4882055867102837

Epoch: 6| Step: 9
Training loss: 4.677478790283203
Validation loss: 3.48146883133919

Epoch: 6| Step: 10
Training loss: 2.8284835815429688
Validation loss: 3.4754065980193434

Epoch: 6| Step: 11
Training loss: 2.952202796936035
Validation loss: 3.469176576983544

Epoch: 6| Step: 12
Training loss: 3.1353096961975098
Validation loss: 3.4634685336902575

Epoch: 6| Step: 13
Training loss: 2.8292055130004883
Validation loss: 3.4589229783704205

Epoch: 12| Step: 0
Training loss: 3.156301498413086
Validation loss: 3.4534492133766093

Epoch: 6| Step: 1
Training loss: 3.4929208755493164
Validation loss: 3.449900124662666

Epoch: 6| Step: 2
Training loss: 2.6122853755950928
Validation loss: 3.4451547873917447

Epoch: 6| Step: 3
Training loss: 3.7179737091064453
Validation loss: 3.441072963899182

Epoch: 6| Step: 4
Training loss: 4.569957733154297
Validation loss: 3.4370716464134956

Epoch: 6| Step: 5
Training loss: 4.16220760345459
Validation loss: 3.4319843323000017

Epoch: 6| Step: 6
Training loss: 3.5785694122314453
Validation loss: 3.425366242726644

Epoch: 6| Step: 7
Training loss: 3.3471860885620117
Validation loss: 3.418236958083286

Epoch: 6| Step: 8
Training loss: 3.2075791358947754
Validation loss: 3.4174765566343903

Epoch: 6| Step: 9
Training loss: 3.080075979232788
Validation loss: 3.4125098746309996

Epoch: 6| Step: 10
Training loss: 3.3499226570129395
Validation loss: 3.4106326205756075

Epoch: 6| Step: 11
Training loss: 3.08465576171875
Validation loss: 3.4098780642273607

Epoch: 6| Step: 12
Training loss: 2.8011295795440674
Validation loss: 3.4103249042264876

Epoch: 6| Step: 13
Training loss: 2.7672622203826904
Validation loss: 3.399979691351614

Epoch: 13| Step: 0
Training loss: 4.252439498901367
Validation loss: 3.3982855555831746

Epoch: 6| Step: 1
Training loss: 3.5836679935455322
Validation loss: 3.4005388905925136

Epoch: 6| Step: 2
Training loss: 3.4397082328796387
Validation loss: 3.402091754380093

Epoch: 6| Step: 3
Training loss: 2.3001184463500977
Validation loss: 3.401432637245424

Epoch: 6| Step: 4
Training loss: 3.788804531097412
Validation loss: 3.3972968337356404

Epoch: 6| Step: 5
Training loss: 2.3777525424957275
Validation loss: 3.3941946952573714

Epoch: 6| Step: 6
Training loss: 4.20211124420166
Validation loss: 3.396178348090059

Epoch: 6| Step: 7
Training loss: 2.666558265686035
Validation loss: 3.3908645004354496

Epoch: 6| Step: 8
Training loss: 3.674865245819092
Validation loss: 3.3860050811562488

Epoch: 6| Step: 9
Training loss: 3.8109936714172363
Validation loss: 3.3827053910942486

Epoch: 6| Step: 10
Training loss: 2.369525909423828
Validation loss: 3.3788172532153387

Epoch: 6| Step: 11
Training loss: 3.5829014778137207
Validation loss: 3.374732671245452

Epoch: 6| Step: 12
Training loss: 3.4580142498016357
Validation loss: 3.371895238917361

Epoch: 6| Step: 13
Training loss: 3.1916942596435547
Validation loss: 3.37028847202178

Epoch: 14| Step: 0
Training loss: 2.1867265701293945
Validation loss: 3.3663965143183225

Epoch: 6| Step: 1
Training loss: 3.2376163005828857
Validation loss: 3.3620863114633868

Epoch: 6| Step: 2
Training loss: 3.2148756980895996
Validation loss: 3.35949041510141

Epoch: 6| Step: 3
Training loss: 3.409313917160034
Validation loss: 3.357634280317573

Epoch: 6| Step: 4
Training loss: 4.377076625823975
Validation loss: 3.3556503736844627

Epoch: 6| Step: 5
Training loss: 3.5487771034240723
Validation loss: 3.3528906324858307

Epoch: 6| Step: 6
Training loss: 3.7242050170898438
Validation loss: 3.350173447721748

Epoch: 6| Step: 7
Training loss: 3.2142839431762695
Validation loss: 3.348046459177489

Epoch: 6| Step: 8
Training loss: 2.9266231060028076
Validation loss: 3.3459327784917687

Epoch: 6| Step: 9
Training loss: 3.2621617317199707
Validation loss: 3.3413931169817523

Epoch: 6| Step: 10
Training loss: 2.9981131553649902
Validation loss: 3.3395412070776826

Epoch: 6| Step: 11
Training loss: 3.470630645751953
Validation loss: 3.336103254748929

Epoch: 6| Step: 12
Training loss: 3.942180871963501
Validation loss: 3.3338504427222797

Epoch: 6| Step: 13
Training loss: 2.432309865951538
Validation loss: 3.3322073695480183

Epoch: 15| Step: 0
Training loss: 4.065679550170898
Validation loss: 3.330111398491808

Epoch: 6| Step: 1
Training loss: 2.733238697052002
Validation loss: 3.328293305571361

Epoch: 6| Step: 2
Training loss: 3.5013418197631836
Validation loss: 3.3269531393563874

Epoch: 6| Step: 3
Training loss: 3.2862095832824707
Validation loss: 3.324637556588778

Epoch: 6| Step: 4
Training loss: 3.337535858154297
Validation loss: 3.324360211690267

Epoch: 6| Step: 5
Training loss: 2.8342576026916504
Validation loss: 3.323710790244482

Epoch: 6| Step: 6
Training loss: 4.236549377441406
Validation loss: 3.318925439670522

Epoch: 6| Step: 7
Training loss: 3.2913694381713867
Validation loss: 3.316567769614599

Epoch: 6| Step: 8
Training loss: 4.219203948974609
Validation loss: 3.3123826878045195

Epoch: 6| Step: 9
Training loss: 2.5104105472564697
Validation loss: 3.311594696455104

Epoch: 6| Step: 10
Training loss: 2.472273349761963
Validation loss: 3.3111180413153862

Epoch: 6| Step: 11
Training loss: 3.3919363021850586
Validation loss: 3.309016489213513

Epoch: 6| Step: 12
Training loss: 2.495497703552246
Validation loss: 3.3076324821800314

Epoch: 6| Step: 13
Training loss: 3.8444197177886963
Validation loss: 3.3054664929707847

Epoch: 16| Step: 0
Training loss: 4.188900470733643
Validation loss: 3.3049811368347495

Epoch: 6| Step: 1
Training loss: 2.7422103881835938
Validation loss: 3.3013333069380892

Epoch: 6| Step: 2
Training loss: 3.0008044242858887
Validation loss: 3.298649667411722

Epoch: 6| Step: 3
Training loss: 5.076181411743164
Validation loss: 3.2939417387849543

Epoch: 6| Step: 4
Training loss: 3.120382070541382
Validation loss: 3.292607392034223

Epoch: 6| Step: 5
Training loss: 2.7754483222961426
Validation loss: 3.2904214602644726

Epoch: 6| Step: 6
Training loss: 2.9214491844177246
Validation loss: 3.287888316697972

Epoch: 6| Step: 7
Training loss: 2.9504847526550293
Validation loss: 3.287751818215975

Epoch: 6| Step: 8
Training loss: 2.64119029045105
Validation loss: 3.2847673175155476

Epoch: 6| Step: 9
Training loss: 3.6113131046295166
Validation loss: 3.2836711868163078

Epoch: 6| Step: 10
Training loss: 2.941596508026123
Validation loss: 3.281256757756715

Epoch: 6| Step: 11
Training loss: 3.3121328353881836
Validation loss: 3.2738491694132485

Epoch: 6| Step: 12
Training loss: 2.678231716156006
Validation loss: 3.270214847339097

Epoch: 6| Step: 13
Training loss: 4.039207458496094
Validation loss: 3.2676599564090854

Epoch: 17| Step: 0
Training loss: 3.9025356769561768
Validation loss: 3.2656420097556165

Epoch: 6| Step: 1
Training loss: 1.9721055030822754
Validation loss: 3.26273145726932

Epoch: 6| Step: 2
Training loss: 2.8130593299865723
Validation loss: 3.261379522662009

Epoch: 6| Step: 3
Training loss: 4.1536407470703125
Validation loss: 3.2618705252165436

Epoch: 6| Step: 4
Training loss: 3.636378288269043
Validation loss: 3.2596317260496077

Epoch: 6| Step: 5
Training loss: 2.030242443084717
Validation loss: 3.2574427896930325

Epoch: 6| Step: 6
Training loss: 3.210097312927246
Validation loss: 3.25428149777074

Epoch: 6| Step: 7
Training loss: 2.4345650672912598
Validation loss: 3.2553012063426356

Epoch: 6| Step: 8
Training loss: 3.1387674808502197
Validation loss: 3.2553077974627094

Epoch: 6| Step: 9
Training loss: 3.582648515701294
Validation loss: 3.252930707828973

Epoch: 6| Step: 10
Training loss: 3.2528347969055176
Validation loss: 3.250002861022949

Epoch: 6| Step: 11
Training loss: 4.259018421173096
Validation loss: 3.2487691602399273

Epoch: 6| Step: 12
Training loss: 3.678535223007202
Validation loss: 3.245720224995767

Epoch: 6| Step: 13
Training loss: 3.2311227321624756
Validation loss: 3.2441637028930006

Epoch: 18| Step: 0
Training loss: 2.5165791511535645
Validation loss: 3.243808982192829

Epoch: 6| Step: 1
Training loss: 2.8540546894073486
Validation loss: 3.2410981911484913

Epoch: 6| Step: 2
Training loss: 2.418572187423706
Validation loss: 3.2412602081093738

Epoch: 6| Step: 3
Training loss: 3.299156665802002
Validation loss: 3.2391459531681512

Epoch: 6| Step: 4
Training loss: 3.562145471572876
Validation loss: 3.2363105640616467

Epoch: 6| Step: 5
Training loss: 3.4022622108459473
Validation loss: 3.236137479864141

Epoch: 6| Step: 6
Training loss: 2.7966394424438477
Validation loss: 3.234045813160558

Epoch: 6| Step: 7
Training loss: 3.626688003540039
Validation loss: 3.2335423654125584

Epoch: 6| Step: 8
Training loss: 3.4164772033691406
Validation loss: 3.231273494740968

Epoch: 6| Step: 9
Training loss: 2.9228670597076416
Validation loss: 3.2296876958621445

Epoch: 6| Step: 10
Training loss: 3.216085195541382
Validation loss: 3.228418950111635

Epoch: 6| Step: 11
Training loss: 3.347146511077881
Validation loss: 3.2320306352389756

Epoch: 6| Step: 12
Training loss: 4.223654270172119
Validation loss: 3.2352413874800487

Epoch: 6| Step: 13
Training loss: 3.6886401176452637
Validation loss: 3.225128816020104

Epoch: 19| Step: 0
Training loss: 3.538655996322632
Validation loss: 3.223289458982406

Epoch: 6| Step: 1
Training loss: 3.44527530670166
Validation loss: 3.222195589414207

Epoch: 6| Step: 2
Training loss: 3.7888739109039307
Validation loss: 3.22154059461368

Epoch: 6| Step: 3
Training loss: 3.8483104705810547
Validation loss: 3.2203450766942834

Epoch: 6| Step: 4
Training loss: 2.175856828689575
Validation loss: 3.219281176085113

Epoch: 6| Step: 5
Training loss: 3.5823593139648438
Validation loss: 3.2188844757695354

Epoch: 6| Step: 6
Training loss: 3.4100799560546875
Validation loss: 3.217706141933318

Epoch: 6| Step: 7
Training loss: 2.334090232849121
Validation loss: 3.2167928500842025

Epoch: 6| Step: 8
Training loss: 4.040764808654785
Validation loss: 3.2164213836833997

Epoch: 6| Step: 9
Training loss: 3.379878044128418
Validation loss: 3.2148874241818666

Epoch: 6| Step: 10
Training loss: 3.6448287963867188
Validation loss: 3.2148718013558337

Epoch: 6| Step: 11
Training loss: 2.5580148696899414
Validation loss: 3.213567723510086

Epoch: 6| Step: 12
Training loss: 2.0296027660369873
Validation loss: 3.210959183272495

Epoch: 6| Step: 13
Training loss: 3.1438779830932617
Validation loss: 3.2090438437718216

Epoch: 20| Step: 0
Training loss: 3.392758846282959
Validation loss: 3.209680857196931

Epoch: 6| Step: 1
Training loss: 2.410274028778076
Validation loss: 3.2087526141956286

Epoch: 6| Step: 2
Training loss: 3.2566468715667725
Validation loss: 3.2103323551916305

Epoch: 6| Step: 3
Training loss: 3.1690564155578613
Validation loss: 3.207288470319522

Epoch: 6| Step: 4
Training loss: 3.032651901245117
Validation loss: 3.209214328437723

Epoch: 6| Step: 5
Training loss: 2.7632510662078857
Validation loss: 3.210742278765607

Epoch: 6| Step: 6
Training loss: 2.9662208557128906
Validation loss: 3.2110098920842653

Epoch: 6| Step: 7
Training loss: 2.9668428897857666
Validation loss: 3.2057267055716565

Epoch: 6| Step: 8
Training loss: 3.7134850025177
Validation loss: 3.2038861833592898

Epoch: 6| Step: 9
Training loss: 4.286069393157959
Validation loss: 3.2010815220494426

Epoch: 6| Step: 10
Training loss: 3.443638563156128
Validation loss: 3.2020883124361754

Epoch: 6| Step: 11
Training loss: 3.1083240509033203
Validation loss: 3.199593613224645

Epoch: 6| Step: 12
Training loss: 2.920381546020508
Validation loss: 3.1999071336561635

Epoch: 6| Step: 13
Training loss: 3.5524632930755615
Validation loss: 3.1993582017960085

Epoch: 21| Step: 0
Training loss: 2.8394742012023926
Validation loss: 3.199756758187407

Epoch: 6| Step: 1
Training loss: 2.841222047805786
Validation loss: 3.1999085257130284

Epoch: 6| Step: 2
Training loss: 3.644284725189209
Validation loss: 3.1995751114301783

Epoch: 6| Step: 3
Training loss: 3.801640033721924
Validation loss: 3.198262027514878

Epoch: 6| Step: 4
Training loss: 2.8832390308380127
Validation loss: 3.1973681834436234

Epoch: 6| Step: 5
Training loss: 2.6403870582580566
Validation loss: 3.1962736780925463

Epoch: 6| Step: 6
Training loss: 3.6717569828033447
Validation loss: 3.1949045350474696

Epoch: 6| Step: 7
Training loss: 2.418792963027954
Validation loss: 3.194677342650711

Epoch: 6| Step: 8
Training loss: 3.4800572395324707
Validation loss: 3.193334074430568

Epoch: 6| Step: 9
Training loss: 3.628246784210205
Validation loss: 3.1938096451502975

Epoch: 6| Step: 10
Training loss: 2.451340436935425
Validation loss: 3.1918018351319017

Epoch: 6| Step: 11
Training loss: 3.8220887184143066
Validation loss: 3.192269271419894

Epoch: 6| Step: 12
Training loss: 3.3017916679382324
Validation loss: 3.1922007247965825

Epoch: 6| Step: 13
Training loss: 3.4003965854644775
Validation loss: 3.188377626480595

Epoch: 22| Step: 0
Training loss: 4.988759994506836
Validation loss: 3.1891066848590808

Epoch: 6| Step: 1
Training loss: 2.3904707431793213
Validation loss: 3.1879260898918234

Epoch: 6| Step: 2
Training loss: 3.0987675189971924
Validation loss: 3.186238496534286

Epoch: 6| Step: 3
Training loss: 3.7531330585479736
Validation loss: 3.18843666456079

Epoch: 6| Step: 4
Training loss: 3.590869426727295
Validation loss: 3.1855636489006782

Epoch: 6| Step: 5
Training loss: 2.796694278717041
Validation loss: 3.185844791832791

Epoch: 6| Step: 6
Training loss: 2.451718807220459
Validation loss: 3.1858009779325096

Epoch: 6| Step: 7
Training loss: 2.907726764678955
Validation loss: 3.1853558965908584

Epoch: 6| Step: 8
Training loss: 4.048100471496582
Validation loss: 3.1821219203292683

Epoch: 6| Step: 9
Training loss: 2.966571807861328
Validation loss: 3.183028636440154

Epoch: 6| Step: 10
Training loss: 2.9422647953033447
Validation loss: 3.1811497160183486

Epoch: 6| Step: 11
Training loss: 3.4731316566467285
Validation loss: 3.180654146338022

Epoch: 6| Step: 12
Training loss: 2.366191864013672
Validation loss: 3.1828729619262037

Epoch: 6| Step: 13
Training loss: 2.6230225563049316
Validation loss: 3.179816310123731

Epoch: 23| Step: 0
Training loss: 3.0766513347625732
Validation loss: 3.1806237031054754

Epoch: 6| Step: 1
Training loss: 3.048309326171875
Validation loss: 3.1785666019685808

Epoch: 6| Step: 2
Training loss: 3.2638111114501953
Validation loss: 3.1811496109090824

Epoch: 6| Step: 3
Training loss: 3.192469835281372
Validation loss: 3.176792388321251

Epoch: 6| Step: 4
Training loss: 2.067363739013672
Validation loss: 3.177897858363326

Epoch: 6| Step: 5
Training loss: 3.1199464797973633
Validation loss: 3.175937537224062

Epoch: 6| Step: 6
Training loss: 3.2912707328796387
Validation loss: 3.1767978847667737

Epoch: 6| Step: 7
Training loss: 3.2877731323242188
Validation loss: 3.1757127956677507

Epoch: 6| Step: 8
Training loss: 2.1546950340270996
Validation loss: 3.1764266208935807

Epoch: 6| Step: 9
Training loss: 3.47175931930542
Validation loss: 3.176128413087578

Epoch: 6| Step: 10
Training loss: 3.6033551692962646
Validation loss: 3.177504024197978

Epoch: 6| Step: 11
Training loss: 4.391063690185547
Validation loss: 3.17747490636764

Epoch: 6| Step: 12
Training loss: 3.328110933303833
Validation loss: 3.176516702098231

Epoch: 6| Step: 13
Training loss: 3.3966331481933594
Validation loss: 3.1754325205279934

Epoch: 24| Step: 0
Training loss: 2.761431932449341
Validation loss: 3.1740731628992225

Epoch: 6| Step: 1
Training loss: 4.096986293792725
Validation loss: 3.174954265676519

Epoch: 6| Step: 2
Training loss: 3.370224952697754
Validation loss: 3.175079104720905

Epoch: 6| Step: 3
Training loss: 3.221435308456421
Validation loss: 3.174706320608816

Epoch: 6| Step: 4
Training loss: 3.2996251583099365
Validation loss: 3.174364879567136

Epoch: 6| Step: 5
Training loss: 3.2058329582214355
Validation loss: 3.173537920880061

Epoch: 6| Step: 6
Training loss: 2.5794081687927246
Validation loss: 3.1739771981393137

Epoch: 6| Step: 7
Training loss: 3.0500407218933105
Validation loss: 3.173300086811025

Epoch: 6| Step: 8
Training loss: 2.6780357360839844
Validation loss: 3.1728260337665515

Epoch: 6| Step: 9
Training loss: 3.1733224391937256
Validation loss: 3.1711710191542104

Epoch: 6| Step: 10
Training loss: 2.979166030883789
Validation loss: 3.171003577529743

Epoch: 6| Step: 11
Training loss: 2.8727951049804688
Validation loss: 3.168476771282893

Epoch: 6| Step: 12
Training loss: 4.1263885498046875
Validation loss: 3.169061686403008

Epoch: 6| Step: 13
Training loss: 3.065263032913208
Validation loss: 3.1700920648472284

Epoch: 25| Step: 0
Training loss: 3.26419734954834
Validation loss: 3.1689331839161534

Epoch: 6| Step: 1
Training loss: 2.9283204078674316
Validation loss: 3.1686541726512294

Epoch: 6| Step: 2
Training loss: 3.416811943054199
Validation loss: 3.168709449870612

Epoch: 6| Step: 3
Training loss: 2.1628873348236084
Validation loss: 3.167263589879518

Epoch: 6| Step: 4
Training loss: 3.6218855381011963
Validation loss: 3.1644510812656854

Epoch: 6| Step: 5
Training loss: 3.6642515659332275
Validation loss: 3.1657476937899025

Epoch: 6| Step: 6
Training loss: 3.2233662605285645
Validation loss: 3.1640365303203626

Epoch: 6| Step: 7
Training loss: 3.699198007583618
Validation loss: 3.1664352724629063

Epoch: 6| Step: 8
Training loss: 2.8767952919006348
Validation loss: 3.166338059210008

Epoch: 6| Step: 9
Training loss: 3.5100760459899902
Validation loss: 3.165183126285512

Epoch: 6| Step: 10
Training loss: 3.179745674133301
Validation loss: 3.1635244225942962

Epoch: 6| Step: 11
Training loss: 3.1236085891723633
Validation loss: 3.163245003710511

Epoch: 6| Step: 12
Training loss: 2.7932381629943848
Validation loss: 3.162340715367307

Epoch: 6| Step: 13
Training loss: 2.8590447902679443
Validation loss: 3.1609235040603147

Epoch: 26| Step: 0
Training loss: 3.1246962547302246
Validation loss: 3.16143960337485

Epoch: 6| Step: 1
Training loss: 3.1033875942230225
Validation loss: 3.163156981109291

Epoch: 6| Step: 2
Training loss: 3.0505316257476807
Validation loss: 3.1616721255804903

Epoch: 6| Step: 3
Training loss: 2.9474220275878906
Validation loss: 3.161693078215404

Epoch: 6| Step: 4
Training loss: 3.803027629852295
Validation loss: 3.1603523274903655

Epoch: 6| Step: 5
Training loss: 3.6376054286956787
Validation loss: 3.158832606448922

Epoch: 6| Step: 6
Training loss: 2.040945529937744
Validation loss: 3.160362410288985

Epoch: 6| Step: 7
Training loss: 2.868788242340088
Validation loss: 3.1608940478294127

Epoch: 6| Step: 8
Training loss: 3.5646862983703613
Validation loss: 3.1643268985133015

Epoch: 6| Step: 9
Training loss: 2.7509663105010986
Validation loss: 3.1638382455354095

Epoch: 6| Step: 10
Training loss: 3.9956471920013428
Validation loss: 3.1612208530467045

Epoch: 6| Step: 11
Training loss: 3.160806894302368
Validation loss: 3.1575802346711517

Epoch: 6| Step: 12
Training loss: 3.20536470413208
Validation loss: 3.1575155360724336

Epoch: 6| Step: 13
Training loss: 3.149576425552368
Validation loss: 3.154945755517611

Epoch: 27| Step: 0
Training loss: 2.60366153717041
Validation loss: 3.1518639338913785

Epoch: 6| Step: 1
Training loss: 2.5301108360290527
Validation loss: 3.1578028432784544

Epoch: 6| Step: 2
Training loss: 3.5794286727905273
Validation loss: 3.1536585412999636

Epoch: 6| Step: 3
Training loss: 4.746893882751465
Validation loss: 3.1523887931659655

Epoch: 6| Step: 4
Training loss: 5.257058143615723
Validation loss: 3.153046049097533

Epoch: 6| Step: 5
Training loss: 3.536865234375
Validation loss: 3.1532723083291003

Epoch: 6| Step: 6
Training loss: 2.2915821075439453
Validation loss: 3.1515694536188597

Epoch: 6| Step: 7
Training loss: 2.2018868923187256
Validation loss: 3.152774126298966

Epoch: 6| Step: 8
Training loss: 2.262167453765869
Validation loss: 3.1526648870078464

Epoch: 6| Step: 9
Training loss: 4.033874988555908
Validation loss: 3.1516126945454586

Epoch: 6| Step: 10
Training loss: 2.4447736740112305
Validation loss: 3.1530242299520843

Epoch: 6| Step: 11
Training loss: 2.767890453338623
Validation loss: 3.1539802243632655

Epoch: 6| Step: 12
Training loss: 2.9563634395599365
Validation loss: 3.1543005922789216

Epoch: 6| Step: 13
Training loss: 3.146725654602051
Validation loss: 3.153397188391737

Epoch: 28| Step: 0
Training loss: 2.2089200019836426
Validation loss: 3.1503371269472185

Epoch: 6| Step: 1
Training loss: 2.775568962097168
Validation loss: 3.151984086600683

Epoch: 6| Step: 2
Training loss: 3.183286666870117
Validation loss: 3.1524342106234644

Epoch: 6| Step: 3
Training loss: 3.216527223587036
Validation loss: 3.1546185760087866

Epoch: 6| Step: 4
Training loss: 3.140254497528076
Validation loss: 3.1534781058629355

Epoch: 6| Step: 5
Training loss: 3.2959017753601074
Validation loss: 3.1558905519464964

Epoch: 6| Step: 6
Training loss: 3.6623151302337646
Validation loss: 3.154166985583562

Epoch: 6| Step: 7
Training loss: 3.0351712703704834
Validation loss: 3.153441834193404

Epoch: 6| Step: 8
Training loss: 3.065046548843384
Validation loss: 3.1572476740806334

Epoch: 6| Step: 9
Training loss: 3.5502936840057373
Validation loss: 3.155897601958244

Epoch: 6| Step: 10
Training loss: 3.3803181648254395
Validation loss: 3.1523333852009108

Epoch: 6| Step: 11
Training loss: 3.1326348781585693
Validation loss: 3.150861704221336

Epoch: 6| Step: 12
Training loss: 3.3367843627929688
Validation loss: 3.147885504589286

Epoch: 6| Step: 13
Training loss: 3.4464292526245117
Validation loss: 3.147990924055858

Epoch: 29| Step: 0
Training loss: 3.1474175453186035
Validation loss: 3.1515565226154942

Epoch: 6| Step: 1
Training loss: 2.8888630867004395
Validation loss: 3.15494187929297

Epoch: 6| Step: 2
Training loss: 2.5054383277893066
Validation loss: 3.1632814817531134

Epoch: 6| Step: 3
Training loss: 3.8612453937530518
Validation loss: 3.17951452091176

Epoch: 6| Step: 4
Training loss: 3.3322503566741943
Validation loss: 3.1717153697885494

Epoch: 6| Step: 5
Training loss: 2.3848893642425537
Validation loss: 3.1568977704612156

Epoch: 6| Step: 6
Training loss: 4.918129920959473
Validation loss: 3.1505195709966842

Epoch: 6| Step: 7
Training loss: 3.459848165512085
Validation loss: 3.1476765191683205

Epoch: 6| Step: 8
Training loss: 3.0156164169311523
Validation loss: 3.1469544005650345

Epoch: 6| Step: 9
Training loss: 2.073791027069092
Validation loss: 3.1469763325106714

Epoch: 6| Step: 10
Training loss: 2.937042236328125
Validation loss: 3.1489793151937504

Epoch: 6| Step: 11
Training loss: 2.429027557373047
Validation loss: 3.1538639991514144

Epoch: 6| Step: 12
Training loss: 4.021274089813232
Validation loss: 3.161965403505551

Epoch: 6| Step: 13
Training loss: 3.4666290283203125
Validation loss: 3.1622435533872215

Epoch: 30| Step: 0
Training loss: 3.320909023284912
Validation loss: 3.1502015821395384

Epoch: 6| Step: 1
Training loss: 3.31611967086792
Validation loss: 3.1448532586456626

Epoch: 6| Step: 2
Training loss: 2.06081485748291
Validation loss: 3.1474962952316448

Epoch: 6| Step: 3
Training loss: 2.9968156814575195
Validation loss: 3.1498674782373572

Epoch: 6| Step: 4
Training loss: 3.693538188934326
Validation loss: 3.1611513783854823

Epoch: 6| Step: 5
Training loss: 2.2607274055480957
Validation loss: 3.1611272801635084

Epoch: 6| Step: 6
Training loss: 2.8128366470336914
Validation loss: 3.1683278801620647

Epoch: 6| Step: 7
Training loss: 2.7316274642944336
Validation loss: 3.1582266258937057

Epoch: 6| Step: 8
Training loss: 4.00615119934082
Validation loss: 3.1600042209830335

Epoch: 6| Step: 9
Training loss: 3.122786521911621
Validation loss: 3.1540070144079064

Epoch: 6| Step: 10
Training loss: 2.790266990661621
Validation loss: 3.1487194543243735

Epoch: 6| Step: 11
Training loss: 3.2254996299743652
Validation loss: 3.145456180777601

Epoch: 6| Step: 12
Training loss: 4.405400276184082
Validation loss: 3.1438344576025523

Epoch: 6| Step: 13
Training loss: 3.843428373336792
Validation loss: 3.1430351836707002

Epoch: 31| Step: 0
Training loss: 3.6879379749298096
Validation loss: 3.1422796403208086

Epoch: 6| Step: 1
Training loss: 3.283433198928833
Validation loss: 3.1434287460901404

Epoch: 6| Step: 2
Training loss: 2.174476146697998
Validation loss: 3.1421821322492374

Epoch: 6| Step: 3
Training loss: 3.4265542030334473
Validation loss: 3.1427837007789203

Epoch: 6| Step: 4
Training loss: 3.157478094100952
Validation loss: 3.1413125530365975

Epoch: 6| Step: 5
Training loss: 2.1361632347106934
Validation loss: 3.1419401245732463

Epoch: 6| Step: 6
Training loss: 3.3377790451049805
Validation loss: 3.1404222826803885

Epoch: 6| Step: 7
Training loss: 3.1267778873443604
Validation loss: 3.1411924900547152

Epoch: 6| Step: 8
Training loss: 1.9036701917648315
Validation loss: 3.141613555210893

Epoch: 6| Step: 9
Training loss: 4.055948257446289
Validation loss: 3.1413331877800728

Epoch: 6| Step: 10
Training loss: 3.8159117698669434
Validation loss: 3.140695156589631

Epoch: 6| Step: 11
Training loss: 3.105556011199951
Validation loss: 3.139462281298894

Epoch: 6| Step: 12
Training loss: 3.442063093185425
Validation loss: 3.1377886546555387

Epoch: 6| Step: 13
Training loss: 3.8865437507629395
Validation loss: 3.137554250737672

Epoch: 32| Step: 0
Training loss: 3.038064956665039
Validation loss: 3.1372578451710362

Epoch: 6| Step: 1
Training loss: 3.5827512741088867
Validation loss: 3.138133671975905

Epoch: 6| Step: 2
Training loss: 2.272854804992676
Validation loss: 3.1368340164102535

Epoch: 6| Step: 3
Training loss: 3.0858888626098633
Validation loss: 3.137002980837258

Epoch: 6| Step: 4
Training loss: 3.62048602104187
Validation loss: 3.135686415497975

Epoch: 6| Step: 5
Training loss: 2.395894765853882
Validation loss: 3.134985593057448

Epoch: 6| Step: 6
Training loss: 3.2810096740722656
Validation loss: 3.1350520041681107

Epoch: 6| Step: 7
Training loss: 2.5248939990997314
Validation loss: 3.133314614654869

Epoch: 6| Step: 8
Training loss: 3.01531982421875
Validation loss: 3.1339846862259733

Epoch: 6| Step: 9
Training loss: 3.395514488220215
Validation loss: 3.1332879015194472

Epoch: 6| Step: 10
Training loss: 3.4798765182495117
Validation loss: 3.13286691839977

Epoch: 6| Step: 11
Training loss: 3.967014789581299
Validation loss: 3.1327070318242556

Epoch: 6| Step: 12
Training loss: 3.508284568786621
Validation loss: 3.1328238543643745

Epoch: 6| Step: 13
Training loss: 2.8829023838043213
Validation loss: 3.1315219940677768

Epoch: 33| Step: 0
Training loss: 2.5100762844085693
Validation loss: 3.1307652304249425

Epoch: 6| Step: 1
Training loss: 3.453585624694824
Validation loss: 3.1300302474729476

Epoch: 6| Step: 2
Training loss: 3.749100685119629
Validation loss: 3.1294756653488323

Epoch: 6| Step: 3
Training loss: 3.7379093170166016
Validation loss: 3.130945377452399

Epoch: 6| Step: 4
Training loss: 3.107374668121338
Validation loss: 3.130352976501629

Epoch: 6| Step: 5
Training loss: 3.0283303260803223
Validation loss: 3.129992356864355

Epoch: 6| Step: 6
Training loss: 2.857048988342285
Validation loss: 3.127955085487776

Epoch: 6| Step: 7
Training loss: 3.3201022148132324
Validation loss: 3.128639136591265

Epoch: 6| Step: 8
Training loss: 2.835683822631836
Validation loss: 3.128271682288057

Epoch: 6| Step: 9
Training loss: 3.1889491081237793
Validation loss: 3.1272716265852734

Epoch: 6| Step: 10
Training loss: 3.2976467609405518
Validation loss: 3.128952572422643

Epoch: 6| Step: 11
Training loss: 2.829606533050537
Validation loss: 3.1252898862285

Epoch: 6| Step: 12
Training loss: 2.6841025352478027
Validation loss: 3.1246389471074587

Epoch: 6| Step: 13
Training loss: 3.801295280456543
Validation loss: 3.126033421485655

Epoch: 34| Step: 0
Training loss: 2.2356526851654053
Validation loss: 3.1253394619111092

Epoch: 6| Step: 1
Training loss: 3.3504998683929443
Validation loss: 3.1230677891803045

Epoch: 6| Step: 2
Training loss: 3.2712652683258057
Validation loss: 3.122968191741615

Epoch: 6| Step: 3
Training loss: 2.748528003692627
Validation loss: 3.1208921991368777

Epoch: 6| Step: 4
Training loss: 4.750183582305908
Validation loss: 3.1191116994427097

Epoch: 6| Step: 5
Training loss: 3.13240122795105
Validation loss: 3.120328149487895

Epoch: 6| Step: 6
Training loss: 2.8234996795654297
Validation loss: 3.122196594874064

Epoch: 6| Step: 7
Training loss: 3.0014567375183105
Validation loss: 3.1145033913273967

Epoch: 6| Step: 8
Training loss: 3.1821789741516113
Validation loss: 3.1110832050282466

Epoch: 6| Step: 9
Training loss: 1.84468412399292
Validation loss: 3.1183176476468324

Epoch: 6| Step: 10
Training loss: 3.702544927597046
Validation loss: 3.114921772351829

Epoch: 6| Step: 11
Training loss: 4.400364875793457
Validation loss: 3.1146630471752537

Epoch: 6| Step: 12
Training loss: 2.6039364337921143
Validation loss: 3.112141809155864

Epoch: 6| Step: 13
Training loss: 2.8395915031433105
Validation loss: 3.1096338995041384

Epoch: 35| Step: 0
Training loss: 3.37501859664917
Validation loss: 3.111085461032006

Epoch: 6| Step: 1
Training loss: 3.758362293243408
Validation loss: 3.110323464998635

Epoch: 6| Step: 2
Training loss: 3.1894214153289795
Validation loss: 3.1071037323244157

Epoch: 6| Step: 3
Training loss: 3.7170212268829346
Validation loss: 3.108026122534147

Epoch: 6| Step: 4
Training loss: 2.3333492279052734
Validation loss: 3.104919813012564

Epoch: 6| Step: 5
Training loss: 3.2206180095672607
Validation loss: 3.1104770398909047

Epoch: 6| Step: 6
Training loss: 2.0678834915161133
Validation loss: 3.1100555337885374

Epoch: 6| Step: 7
Training loss: 2.9502837657928467
Validation loss: 3.1100965366568616

Epoch: 6| Step: 8
Training loss: 3.456068515777588
Validation loss: 3.1104333785272416

Epoch: 6| Step: 9
Training loss: 3.0079658031463623
Validation loss: 3.111116922029885

Epoch: 6| Step: 10
Training loss: 3.711529493331909
Validation loss: 3.107559334847235

Epoch: 6| Step: 11
Training loss: 3.2688357830047607
Validation loss: 3.103488932373703

Epoch: 6| Step: 12
Training loss: 3.0011415481567383
Validation loss: 3.101736501980853

Epoch: 6| Step: 13
Training loss: 2.5513105392456055
Validation loss: 3.100819733835036

Epoch: 36| Step: 0
Training loss: 3.3250012397766113
Validation loss: 3.099717791362475

Epoch: 6| Step: 1
Training loss: 3.341914653778076
Validation loss: 3.0988062299707884

Epoch: 6| Step: 2
Training loss: 3.538163423538208
Validation loss: 3.097401890703427

Epoch: 6| Step: 3
Training loss: 3.140164613723755
Validation loss: 3.100140287030128

Epoch: 6| Step: 4
Training loss: 2.8489527702331543
Validation loss: 3.0973233586998394

Epoch: 6| Step: 5
Training loss: 2.77830171585083
Validation loss: 3.09942199337867

Epoch: 6| Step: 6
Training loss: 3.880044460296631
Validation loss: 3.095286556469497

Epoch: 6| Step: 7
Training loss: 4.091012954711914
Validation loss: 3.0959490345370386

Epoch: 6| Step: 8
Training loss: 2.794973850250244
Validation loss: 3.0925757269705496

Epoch: 6| Step: 9
Training loss: 3.517970561981201
Validation loss: 3.0989009411104265

Epoch: 6| Step: 10
Training loss: 2.5341198444366455
Validation loss: 3.1027322251309633

Epoch: 6| Step: 11
Training loss: 2.944993019104004
Validation loss: 3.1058754151867283

Epoch: 6| Step: 12
Training loss: 2.5266032218933105
Validation loss: 3.095823141836351

Epoch: 6| Step: 13
Training loss: 2.1128695011138916
Validation loss: 3.0933649360492663

Epoch: 37| Step: 0
Training loss: 3.183234691619873
Validation loss: 3.0908122062683105

Epoch: 6| Step: 1
Training loss: 2.7817163467407227
Validation loss: 3.0921191746188748

Epoch: 6| Step: 2
Training loss: 3.3397021293640137
Validation loss: 3.092593054617605

Epoch: 6| Step: 3
Training loss: 3.1651906967163086
Validation loss: 3.0930964254563853

Epoch: 6| Step: 4
Training loss: 3.075423240661621
Validation loss: 3.089496889422017

Epoch: 6| Step: 5
Training loss: 2.6258976459503174
Validation loss: 3.0932926465106267

Epoch: 6| Step: 6
Training loss: 2.6555442810058594
Validation loss: 3.092080746927569

Epoch: 6| Step: 7
Training loss: 3.8240439891815186
Validation loss: 3.092829822212137

Epoch: 6| Step: 8
Training loss: 3.3579041957855225
Validation loss: 3.092812661201723

Epoch: 6| Step: 9
Training loss: 2.935832977294922
Validation loss: 3.0933714835874495

Epoch: 6| Step: 10
Training loss: 2.9886231422424316
Validation loss: 3.108626127243042

Epoch: 6| Step: 11
Training loss: 3.168001174926758
Validation loss: 3.107904044530725

Epoch: 6| Step: 12
Training loss: 3.309027671813965
Validation loss: 3.0962950670590965

Epoch: 6| Step: 13
Training loss: 3.5132405757904053
Validation loss: 3.0963166400950444

Epoch: 38| Step: 0
Training loss: 3.3565759658813477
Validation loss: 3.0907461130490868

Epoch: 6| Step: 1
Training loss: 3.0605878829956055
Validation loss: 3.089647154654226

Epoch: 6| Step: 2
Training loss: 2.900649070739746
Validation loss: 3.090402503167429

Epoch: 6| Step: 3
Training loss: 2.995471239089966
Validation loss: 3.0888378466329267

Epoch: 6| Step: 4
Training loss: 2.840888500213623
Validation loss: 3.0891503287899877

Epoch: 6| Step: 5
Training loss: 2.94122576713562
Validation loss: 3.0909611999347644

Epoch: 6| Step: 6
Training loss: 2.9418869018554688
Validation loss: 3.0887550794950096

Epoch: 6| Step: 7
Training loss: 3.659576654434204
Validation loss: 3.0898968147975143

Epoch: 6| Step: 8
Training loss: 2.6041691303253174
Validation loss: 3.0868050257364907

Epoch: 6| Step: 9
Training loss: 3.750509262084961
Validation loss: 3.08757964000907

Epoch: 6| Step: 10
Training loss: 2.43105411529541
Validation loss: 3.0851129588260444

Epoch: 6| Step: 11
Training loss: 3.6387078762054443
Validation loss: 3.082772618980818

Epoch: 6| Step: 12
Training loss: 2.8781633377075195
Validation loss: 3.0811849691534556

Epoch: 6| Step: 13
Training loss: 4.196016788482666
Validation loss: 3.085856048009729

Epoch: 39| Step: 0
Training loss: 3.4853382110595703
Validation loss: 3.0853459091596704

Epoch: 6| Step: 1
Training loss: 2.8229963779449463
Validation loss: 3.084011029171687

Epoch: 6| Step: 2
Training loss: 2.6492953300476074
Validation loss: 3.088893054634012

Epoch: 6| Step: 3
Training loss: 3.268040657043457
Validation loss: 3.0882886942996772

Epoch: 6| Step: 4
Training loss: 3.56837797164917
Validation loss: 3.0868749746712307

Epoch: 6| Step: 5
Training loss: 3.8848228454589844
Validation loss: 3.0848814364402526

Epoch: 6| Step: 6
Training loss: 3.859900951385498
Validation loss: 3.084754438810451

Epoch: 6| Step: 7
Training loss: 3.203094482421875
Validation loss: 3.087696700967768

Epoch: 6| Step: 8
Training loss: 3.1153316497802734
Validation loss: 3.0847389749301377

Epoch: 6| Step: 9
Training loss: 2.9571380615234375
Validation loss: 3.0977609798472416

Epoch: 6| Step: 10
Training loss: 2.681817054748535
Validation loss: 3.0820809513010006

Epoch: 6| Step: 11
Training loss: 2.1318130493164062
Validation loss: 3.0771907068067983

Epoch: 6| Step: 12
Training loss: 2.9267258644104004
Validation loss: 3.0753995090402584

Epoch: 6| Step: 13
Training loss: 2.919184446334839
Validation loss: 3.068144590623917

Epoch: 40| Step: 0
Training loss: 2.6669180393218994
Validation loss: 3.0659837568959882

Epoch: 6| Step: 1
Training loss: 2.636874198913574
Validation loss: 3.0667548974355063

Epoch: 6| Step: 2
Training loss: 3.387192964553833
Validation loss: 3.0665732045327463

Epoch: 6| Step: 3
Training loss: 3.5735907554626465
Validation loss: 3.0680781154222387

Epoch: 6| Step: 4
Training loss: 2.7677719593048096
Validation loss: 3.067851886954359

Epoch: 6| Step: 5
Training loss: 3.2883822917938232
Validation loss: 3.0677859347353698

Epoch: 6| Step: 6
Training loss: 2.9079320430755615
Validation loss: 3.06676697474654

Epoch: 6| Step: 7
Training loss: 3.144840717315674
Validation loss: 3.0684172825146745

Epoch: 6| Step: 8
Training loss: 2.9532010555267334
Validation loss: 3.0634318628618793

Epoch: 6| Step: 9
Training loss: 3.2751922607421875
Validation loss: 3.0659619531323834

Epoch: 6| Step: 10
Training loss: 3.8494744300842285
Validation loss: 3.0625384853732203

Epoch: 6| Step: 11
Training loss: 3.454185724258423
Validation loss: 3.0585975288062968

Epoch: 6| Step: 12
Training loss: 2.2089805603027344
Validation loss: 3.058546676430651

Epoch: 6| Step: 13
Training loss: 3.6786999702453613
Validation loss: 3.058681503418953

Epoch: 41| Step: 0
Training loss: 3.0897650718688965
Validation loss: 3.056271937585646

Epoch: 6| Step: 1
Training loss: 2.5419058799743652
Validation loss: 3.057800446787188

Epoch: 6| Step: 2
Training loss: 2.5712673664093018
Validation loss: 3.0581299207543813

Epoch: 6| Step: 3
Training loss: 3.7419588565826416
Validation loss: 3.0561654336990847

Epoch: 6| Step: 4
Training loss: 2.4049878120422363
Validation loss: 3.057159992956346

Epoch: 6| Step: 5
Training loss: 2.855116844177246
Validation loss: 3.0598288851399578

Epoch: 6| Step: 6
Training loss: 3.154357433319092
Validation loss: 3.0573648355340444

Epoch: 6| Step: 7
Training loss: 3.210886001586914
Validation loss: 3.0579908996499996

Epoch: 6| Step: 8
Training loss: 2.8858957290649414
Validation loss: 3.0660388879878546

Epoch: 6| Step: 9
Training loss: 3.750450611114502
Validation loss: 3.0817706969476517

Epoch: 6| Step: 10
Training loss: 3.796290874481201
Validation loss: 3.0648997522169545

Epoch: 6| Step: 11
Training loss: 3.459419012069702
Validation loss: 3.0617366349825295

Epoch: 6| Step: 12
Training loss: 1.6955312490463257
Validation loss: 3.0526502875871557

Epoch: 6| Step: 13
Training loss: 5.268459796905518
Validation loss: 3.0552128361117457

Epoch: 42| Step: 0
Training loss: 4.59145975112915
Validation loss: 3.0504342791854695

Epoch: 6| Step: 1
Training loss: 3.2999305725097656
Validation loss: 3.049087673105219

Epoch: 6| Step: 2
Training loss: 3.181933879852295
Validation loss: 3.05041100389214

Epoch: 6| Step: 3
Training loss: 2.3152499198913574
Validation loss: 3.0492909364802863

Epoch: 6| Step: 4
Training loss: 3.037478446960449
Validation loss: 3.051817094126055

Epoch: 6| Step: 5
Training loss: 2.2187631130218506
Validation loss: 3.053749725382815

Epoch: 6| Step: 6
Training loss: 4.27517032623291
Validation loss: 3.0498119631121234

Epoch: 6| Step: 7
Training loss: 3.0264477729797363
Validation loss: 3.0508100422479774

Epoch: 6| Step: 8
Training loss: 2.6086366176605225
Validation loss: 3.052924063897902

Epoch: 6| Step: 9
Training loss: 3.23399019241333
Validation loss: 3.0500896259020736

Epoch: 6| Step: 10
Training loss: 2.108855724334717
Validation loss: 3.0475039353934665

Epoch: 6| Step: 11
Training loss: 3.824862241744995
Validation loss: 3.0498185106503066

Epoch: 6| Step: 12
Training loss: 2.774420738220215
Validation loss: 3.0490588629117577

Epoch: 6| Step: 13
Training loss: 2.7820918560028076
Validation loss: 3.0475073322173087

Epoch: 43| Step: 0
Training loss: 3.6118080615997314
Validation loss: 3.0477664509127216

Epoch: 6| Step: 1
Training loss: 2.3956995010375977
Validation loss: 3.0468311514905704

Epoch: 6| Step: 2
Training loss: 2.9015676975250244
Validation loss: 3.0486482240820445

Epoch: 6| Step: 3
Training loss: 2.806790828704834
Validation loss: 3.0471128263781146

Epoch: 6| Step: 4
Training loss: 4.321858882904053
Validation loss: 3.0470051483441423

Epoch: 6| Step: 5
Training loss: 3.996474504470825
Validation loss: 3.0479715485726633

Epoch: 6| Step: 6
Training loss: 3.0434587001800537
Validation loss: 3.047662168420771

Epoch: 6| Step: 7
Training loss: 2.6273279190063477
Validation loss: 3.050461417885237

Epoch: 6| Step: 8
Training loss: 2.7031638622283936
Validation loss: 3.0506179512188

Epoch: 6| Step: 9
Training loss: 2.234908103942871
Validation loss: 3.0501863982087825

Epoch: 6| Step: 10
Training loss: 2.6184186935424805
Validation loss: 3.0480622271055817

Epoch: 6| Step: 11
Training loss: 3.2754569053649902
Validation loss: 3.048053954237251

Epoch: 6| Step: 12
Training loss: 2.9384422302246094
Validation loss: 3.04402684139949

Epoch: 6| Step: 13
Training loss: 4.453290939331055
Validation loss: 3.0426632614545923

Epoch: 44| Step: 0
Training loss: 3.0347347259521484
Validation loss: 3.0429363148186797

Epoch: 6| Step: 1
Training loss: 4.3159966468811035
Validation loss: 3.041372376103555

Epoch: 6| Step: 2
Training loss: 2.595883846282959
Validation loss: 3.042014650119248

Epoch: 6| Step: 3
Training loss: 3.0501859188079834
Validation loss: 3.0397942707102787

Epoch: 6| Step: 4
Training loss: 2.955002784729004
Validation loss: 3.0434561211575746

Epoch: 6| Step: 5
Training loss: 2.9029197692871094
Validation loss: 3.05000643063617

Epoch: 6| Step: 6
Training loss: 3.22802472114563
Validation loss: 3.0487387564874466

Epoch: 6| Step: 7
Training loss: 2.534419536590576
Validation loss: 3.047824892946469

Epoch: 6| Step: 8
Training loss: 3.3687450885772705
Validation loss: 3.0460030340379283

Epoch: 6| Step: 9
Training loss: 3.488790512084961
Validation loss: 3.0490651822859243

Epoch: 6| Step: 10
Training loss: 2.7039408683776855
Validation loss: 3.0456648462562153

Epoch: 6| Step: 11
Training loss: 3.288498878479004
Validation loss: 3.045748587577574

Epoch: 6| Step: 12
Training loss: 2.733431339263916
Validation loss: 3.0517821286314275

Epoch: 6| Step: 13
Training loss: 3.193777084350586
Validation loss: 3.0511030048452397

Epoch: 45| Step: 0
Training loss: 2.9694008827209473
Validation loss: 3.041629557968468

Epoch: 6| Step: 1
Training loss: 2.3853230476379395
Validation loss: 3.0372962490204842

Epoch: 6| Step: 2
Training loss: 1.6682202816009521
Validation loss: 3.0379822920727473

Epoch: 6| Step: 3
Training loss: 3.7209677696228027
Validation loss: 3.042013268316946

Epoch: 6| Step: 4
Training loss: 3.262784242630005
Validation loss: 3.041539128108691

Epoch: 6| Step: 5
Training loss: 3.789473056793213
Validation loss: 3.040806888252176

Epoch: 6| Step: 6
Training loss: 2.9932870864868164
Validation loss: 3.0419334211657123

Epoch: 6| Step: 7
Training loss: 2.5702314376831055
Validation loss: 3.0470122163013746

Epoch: 6| Step: 8
Training loss: 3.6322989463806152
Validation loss: 3.046895647561678

Epoch: 6| Step: 9
Training loss: 3.1034345626831055
Validation loss: 3.04913596184023

Epoch: 6| Step: 10
Training loss: 2.0972368717193604
Validation loss: 3.0502780278523765

Epoch: 6| Step: 11
Training loss: 4.575778007507324
Validation loss: 3.052772437372515

Epoch: 6| Step: 12
Training loss: 3.5284018516540527
Validation loss: 3.053096273893951

Epoch: 6| Step: 13
Training loss: 2.819992780685425
Validation loss: 3.051618053067115

Epoch: 46| Step: 0
Training loss: 2.8146867752075195
Validation loss: 3.046340593727686

Epoch: 6| Step: 1
Training loss: 2.0190811157226562
Validation loss: 3.0410786213413363

Epoch: 6| Step: 2
Training loss: 3.3880295753479004
Validation loss: 3.0454830533714703

Epoch: 6| Step: 3
Training loss: 2.6970715522766113
Validation loss: 3.03644996817394

Epoch: 6| Step: 4
Training loss: 2.6018834114074707
Validation loss: 3.033276904013849

Epoch: 6| Step: 5
Training loss: 3.590757369995117
Validation loss: 3.033208580427272

Epoch: 6| Step: 6
Training loss: 2.582408905029297
Validation loss: 3.0315486513158327

Epoch: 6| Step: 7
Training loss: 3.6612167358398438
Validation loss: 3.031927736856604

Epoch: 6| Step: 8
Training loss: 3.1748924255371094
Validation loss: 3.0324538343696186

Epoch: 6| Step: 9
Training loss: 2.719925880432129
Validation loss: 3.0299429150037867

Epoch: 6| Step: 10
Training loss: 2.9176418781280518
Validation loss: 3.030032152770668

Epoch: 6| Step: 11
Training loss: 3.521791458129883
Validation loss: 3.032378137752574

Epoch: 6| Step: 12
Training loss: 3.5093047618865967
Validation loss: 3.034948120835007

Epoch: 6| Step: 13
Training loss: 4.656252861022949
Validation loss: 3.0358433056903142

Epoch: 47| Step: 0
Training loss: 3.3948683738708496
Validation loss: 3.0367418873694634

Epoch: 6| Step: 1
Training loss: 2.872180461883545
Validation loss: 3.039822063138408

Epoch: 6| Step: 2
Training loss: 3.5079548358917236
Validation loss: 3.044679977560556

Epoch: 6| Step: 3
Training loss: 3.1902012825012207
Validation loss: 3.040056779820432

Epoch: 6| Step: 4
Training loss: 2.9133172035217285
Validation loss: 3.048209257023309

Epoch: 6| Step: 5
Training loss: 3.4539122581481934
Validation loss: 3.0433287748726467

Epoch: 6| Step: 6
Training loss: 3.375232219696045
Validation loss: 3.034398522428287

Epoch: 6| Step: 7
Training loss: 2.48947811126709
Validation loss: 3.0275670892448834

Epoch: 6| Step: 8
Training loss: 2.6605470180511475
Validation loss: 3.0265317655378774

Epoch: 6| Step: 9
Training loss: 2.4256486892700195
Validation loss: 3.0278132884733138

Epoch: 6| Step: 10
Training loss: 3.4487833976745605
Validation loss: 3.0290487017682803

Epoch: 6| Step: 11
Training loss: 3.2530601024627686
Validation loss: 3.030669537923669

Epoch: 6| Step: 12
Training loss: 2.920644760131836
Validation loss: 3.0297060294817855

Epoch: 6| Step: 13
Training loss: 3.430710792541504
Validation loss: 3.0326333045959473

Epoch: 48| Step: 0
Training loss: 3.205709934234619
Validation loss: 3.030403393571095

Epoch: 6| Step: 1
Training loss: 3.1479718685150146
Validation loss: 3.0325881076115433

Epoch: 6| Step: 2
Training loss: 3.4944536685943604
Validation loss: 3.0309057927900747

Epoch: 6| Step: 3
Training loss: 3.8367209434509277
Validation loss: 3.0296394542981218

Epoch: 6| Step: 4
Training loss: 3.058800458908081
Validation loss: 3.0298090724534887

Epoch: 6| Step: 5
Training loss: 2.551985740661621
Validation loss: 3.0285590258977746

Epoch: 6| Step: 6
Training loss: 2.924454689025879
Validation loss: 3.028802805049445

Epoch: 6| Step: 7
Training loss: 2.2730965614318848
Validation loss: 3.0290555774524646

Epoch: 6| Step: 8
Training loss: 3.2361764907836914
Validation loss: 3.0283104758108816

Epoch: 6| Step: 9
Training loss: 2.9618358612060547
Validation loss: 3.028525247368761

Epoch: 6| Step: 10
Training loss: 3.131222724914551
Validation loss: 3.0285706084261657

Epoch: 6| Step: 11
Training loss: 2.910917282104492
Validation loss: 3.0273834223388345

Epoch: 6| Step: 12
Training loss: 3.912935733795166
Validation loss: 3.0270962510057675

Epoch: 6| Step: 13
Training loss: 2.0623137950897217
Validation loss: 3.0277132347065914

Epoch: 49| Step: 0
Training loss: 2.3373382091522217
Validation loss: 3.02477684328633

Epoch: 6| Step: 1
Training loss: 3.074497699737549
Validation loss: 3.0242949506287933

Epoch: 6| Step: 2
Training loss: 3.4323861598968506
Validation loss: 3.025156331318681

Epoch: 6| Step: 3
Training loss: 4.17420768737793
Validation loss: 3.025735614120319

Epoch: 6| Step: 4
Training loss: 2.2709035873413086
Validation loss: 3.026205711467292

Epoch: 6| Step: 5
Training loss: 3.8225386142730713
Validation loss: 3.0239989603719404

Epoch: 6| Step: 6
Training loss: 3.5467894077301025
Validation loss: 3.025456802819365

Epoch: 6| Step: 7
Training loss: 2.448726177215576
Validation loss: 3.0264061650922223

Epoch: 6| Step: 8
Training loss: 2.6198596954345703
Validation loss: 3.0269034754845405

Epoch: 6| Step: 9
Training loss: 2.842824697494507
Validation loss: 3.0280585212092244

Epoch: 6| Step: 10
Training loss: 2.768612861633301
Validation loss: 3.0234935001660417

Epoch: 6| Step: 11
Training loss: 3.3092284202575684
Validation loss: 3.0231677896233013

Epoch: 6| Step: 12
Training loss: 3.418160915374756
Validation loss: 3.0200177751561648

Epoch: 6| Step: 13
Training loss: 2.9429099559783936
Validation loss: 3.0226714354689403

Epoch: 50| Step: 0
Training loss: 3.0546748638153076
Validation loss: 3.021364983691964

Epoch: 6| Step: 1
Training loss: 2.603694200515747
Validation loss: 3.021301079821843

Epoch: 6| Step: 2
Training loss: 2.8595504760742188
Validation loss: 3.020725598899267

Epoch: 6| Step: 3
Training loss: 3.6047401428222656
Validation loss: 3.0183406542706233

Epoch: 6| Step: 4
Training loss: 3.1705102920532227
Validation loss: 3.020786957074237

Epoch: 6| Step: 5
Training loss: 1.8575184345245361
Validation loss: 3.0180463585802304

Epoch: 6| Step: 6
Training loss: 2.2641263008117676
Validation loss: 3.018651875116492

Epoch: 6| Step: 7
Training loss: 2.732271194458008
Validation loss: 3.0168042003467517

Epoch: 6| Step: 8
Training loss: 3.6466217041015625
Validation loss: 3.0197536842797392

Epoch: 6| Step: 9
Training loss: 3.702692747116089
Validation loss: 3.017644895020352

Epoch: 6| Step: 10
Training loss: 3.517129421234131
Validation loss: 3.019511689421951

Epoch: 6| Step: 11
Training loss: 2.6457104682922363
Validation loss: 3.0202024649548274

Epoch: 6| Step: 12
Training loss: 3.0639190673828125
Validation loss: 3.0202354026097122

Epoch: 6| Step: 13
Training loss: 5.223909378051758
Validation loss: 3.017943541208903

Epoch: 51| Step: 0
Training loss: 2.648242473602295
Validation loss: 3.01841478706688

Epoch: 6| Step: 1
Training loss: 3.8200550079345703
Validation loss: 3.0165811072113695

Epoch: 6| Step: 2
Training loss: 3.0133278369903564
Validation loss: 3.0158807205897507

Epoch: 6| Step: 3
Training loss: 3.516663074493408
Validation loss: 3.0152104131637083

Epoch: 6| Step: 4
Training loss: 3.557377815246582
Validation loss: 3.0135113423870457

Epoch: 6| Step: 5
Training loss: 4.303854942321777
Validation loss: 3.0143522190791305

Epoch: 6| Step: 6
Training loss: 3.5039942264556885
Validation loss: 3.0148306738945747

Epoch: 6| Step: 7
Training loss: 1.8692797422409058
Validation loss: 3.013094050909883

Epoch: 6| Step: 8
Training loss: 2.4496634006500244
Validation loss: 3.013668191048407

Epoch: 6| Step: 9
Training loss: 3.025667190551758
Validation loss: 3.0131448725218415

Epoch: 6| Step: 10
Training loss: 3.227447986602783
Validation loss: 3.012415765434183

Epoch: 6| Step: 11
Training loss: 2.4747042655944824
Validation loss: 3.013829254334973

Epoch: 6| Step: 12
Training loss: 2.782351493835449
Validation loss: 3.0125609854216218

Epoch: 6| Step: 13
Training loss: 2.631088972091675
Validation loss: 3.0127268401525353

Epoch: 52| Step: 0
Training loss: 3.266407012939453
Validation loss: 3.011500068890151

Epoch: 6| Step: 1
Training loss: 3.1487669944763184
Validation loss: 3.0104725181415515

Epoch: 6| Step: 2
Training loss: 3.2245140075683594
Validation loss: 3.009492363981021

Epoch: 6| Step: 3
Training loss: 2.5416417121887207
Validation loss: 3.0094058872551046

Epoch: 6| Step: 4
Training loss: 3.226445198059082
Validation loss: 3.0099121165531937

Epoch: 6| Step: 5
Training loss: 2.680413007736206
Validation loss: 3.0102681011281986

Epoch: 6| Step: 6
Training loss: 2.5833725929260254
Validation loss: 3.01205079273511

Epoch: 6| Step: 7
Training loss: 3.481175422668457
Validation loss: 3.0100342381385063

Epoch: 6| Step: 8
Training loss: 3.5447463989257812
Validation loss: 3.0119218800657537

Epoch: 6| Step: 9
Training loss: 2.921196699142456
Validation loss: 3.011696856508973

Epoch: 6| Step: 10
Training loss: 2.8690879344940186
Validation loss: 3.011206485891855

Epoch: 6| Step: 11
Training loss: 3.3786253929138184
Validation loss: 3.010817817462388

Epoch: 6| Step: 12
Training loss: 2.9390013217926025
Validation loss: 3.0092635975089124

Epoch: 6| Step: 13
Training loss: 3.208407163619995
Validation loss: 3.009255060585596

Epoch: 53| Step: 0
Training loss: 3.2238526344299316
Validation loss: 3.0080480806289183

Epoch: 6| Step: 1
Training loss: 2.74530291557312
Validation loss: 3.0080573353716122

Epoch: 6| Step: 2
Training loss: 3.698122501373291
Validation loss: 3.0096074714455554

Epoch: 6| Step: 3
Training loss: 2.700641632080078
Validation loss: 3.008276277972806

Epoch: 6| Step: 4
Training loss: 3.01857328414917
Validation loss: 3.008935853999148

Epoch: 6| Step: 5
Training loss: 3.077954053878784
Validation loss: 3.0060654609434065

Epoch: 6| Step: 6
Training loss: 3.8084449768066406
Validation loss: 3.007489183897613

Epoch: 6| Step: 7
Training loss: 2.8962738513946533
Validation loss: 3.007788037741056

Epoch: 6| Step: 8
Training loss: 3.712432861328125
Validation loss: 3.0102507504083778

Epoch: 6| Step: 9
Training loss: 3.092902183532715
Validation loss: 3.011782935870591

Epoch: 6| Step: 10
Training loss: 2.1856961250305176
Validation loss: 3.0109566719301286

Epoch: 6| Step: 11
Training loss: 2.247148036956787
Validation loss: 3.0119798824351323

Epoch: 6| Step: 12
Training loss: 3.310525894165039
Validation loss: 3.0125633208982405

Epoch: 6| Step: 13
Training loss: 3.282546043395996
Validation loss: 3.0208923509044032

Epoch: 54| Step: 0
Training loss: 3.4401328563690186
Validation loss: 3.017046433623119

Epoch: 6| Step: 1
Training loss: 3.1599717140197754
Validation loss: 3.0089159627114572

Epoch: 6| Step: 2
Training loss: 3.056656837463379
Validation loss: 3.0059753489750687

Epoch: 6| Step: 3
Training loss: 3.67939829826355
Validation loss: 3.0051169779992875

Epoch: 6| Step: 4
Training loss: 2.4534127712249756
Validation loss: 3.004409283720037

Epoch: 6| Step: 5
Training loss: 3.0123708248138428
Validation loss: 3.0033796346315773

Epoch: 6| Step: 6
Training loss: 2.3098177909851074
Validation loss: 3.0039252901589997

Epoch: 6| Step: 7
Training loss: 2.992208480834961
Validation loss: 3.0009244001039894

Epoch: 6| Step: 8
Training loss: 3.4104740619659424
Validation loss: 3.00202698861399

Epoch: 6| Step: 9
Training loss: 3.602414846420288
Validation loss: 3.0013876063849336

Epoch: 6| Step: 10
Training loss: 2.8324837684631348
Validation loss: 3.002478286784182

Epoch: 6| Step: 11
Training loss: 2.7977375984191895
Validation loss: 3.000933039572931

Epoch: 6| Step: 12
Training loss: 2.866425037384033
Validation loss: 3.004449713614679

Epoch: 6| Step: 13
Training loss: 3.474229574203491
Validation loss: 3.003743040946222

Epoch: 55| Step: 0
Training loss: 2.48618745803833
Validation loss: 3.0049137479515484

Epoch: 6| Step: 1
Training loss: 4.5145463943481445
Validation loss: 3.002919599574099

Epoch: 6| Step: 2
Training loss: 3.072673797607422
Validation loss: 3.0096522377383326

Epoch: 6| Step: 3
Training loss: 3.2183573246002197
Validation loss: 3.0152420510527906

Epoch: 6| Step: 4
Training loss: 3.373495578765869
Validation loss: 3.009274016144455

Epoch: 6| Step: 5
Training loss: 2.8694632053375244
Validation loss: 3.012475505951912

Epoch: 6| Step: 6
Training loss: 2.489508628845215
Validation loss: 3.0268972714742026

Epoch: 6| Step: 7
Training loss: 3.113577127456665
Validation loss: 3.0166696040861067

Epoch: 6| Step: 8
Training loss: 3.5735254287719727
Validation loss: 3.015330740200576

Epoch: 6| Step: 9
Training loss: 2.8020739555358887
Validation loss: 3.006858669301515

Epoch: 6| Step: 10
Training loss: 2.5712027549743652
Validation loss: 3.0062054408493863

Epoch: 6| Step: 11
Training loss: 2.467769145965576
Validation loss: 2.997569602022889

Epoch: 6| Step: 12
Training loss: 3.074889898300171
Validation loss: 3.0008734374917965

Epoch: 6| Step: 13
Training loss: 3.359114170074463
Validation loss: 2.9980709193855204

Epoch: 56| Step: 0
Training loss: 2.8953020572662354
Validation loss: 2.9984350640286683

Epoch: 6| Step: 1
Training loss: 3.176055431365967
Validation loss: 2.998887454309771

Epoch: 6| Step: 2
Training loss: 3.619203567504883
Validation loss: 2.998170773188273

Epoch: 6| Step: 3
Training loss: 2.0833306312561035
Validation loss: 2.9994533549072924

Epoch: 6| Step: 4
Training loss: 3.795820713043213
Validation loss: 2.997640399522679

Epoch: 6| Step: 5
Training loss: 3.882446527481079
Validation loss: 2.9976550738016763

Epoch: 6| Step: 6
Training loss: 3.2655301094055176
Validation loss: 2.9968918933663318

Epoch: 6| Step: 7
Training loss: 2.9108593463897705
Validation loss: 2.9965803828290714

Epoch: 6| Step: 8
Training loss: 3.2943153381347656
Validation loss: 2.9975686560394945

Epoch: 6| Step: 9
Training loss: 2.955101728439331
Validation loss: 2.997983637676444

Epoch: 6| Step: 10
Training loss: 2.0221898555755615
Validation loss: 2.997883730037238

Epoch: 6| Step: 11
Training loss: 2.6169581413269043
Validation loss: 2.996957604603101

Epoch: 6| Step: 12
Training loss: 2.9492647647857666
Validation loss: 2.9966217446070846

Epoch: 6| Step: 13
Training loss: 3.7130703926086426
Validation loss: 2.9946864471640637

Epoch: 57| Step: 0
Training loss: 3.4441068172454834
Validation loss: 2.9967521852062595

Epoch: 6| Step: 1
Training loss: 2.451639175415039
Validation loss: 2.9964339989487843

Epoch: 6| Step: 2
Training loss: 2.581204414367676
Validation loss: 2.997392782600977

Epoch: 6| Step: 3
Training loss: 3.5578055381774902
Validation loss: 2.9960661139539493

Epoch: 6| Step: 4
Training loss: 3.760227680206299
Validation loss: 2.995820196725989

Epoch: 6| Step: 5
Training loss: 3.4462928771972656
Validation loss: 2.999061499872515

Epoch: 6| Step: 6
Training loss: 2.780494451522827
Validation loss: 2.9982421244344404

Epoch: 6| Step: 7
Training loss: 1.997345209121704
Validation loss: 3.0002250568841093

Epoch: 6| Step: 8
Training loss: 2.5091607570648193
Validation loss: 2.9997591049440446

Epoch: 6| Step: 9
Training loss: 4.099334716796875
Validation loss: 2.999535575989754

Epoch: 6| Step: 10
Training loss: 2.7438907623291016
Validation loss: 2.9941647052764893

Epoch: 6| Step: 11
Training loss: 3.9178662300109863
Validation loss: 2.9977504925061296

Epoch: 6| Step: 12
Training loss: 3.0982351303100586
Validation loss: 2.9915999956028436

Epoch: 6| Step: 13
Training loss: 1.9933793544769287
Validation loss: 2.992161730284332

Epoch: 58| Step: 0
Training loss: 2.895906925201416
Validation loss: 2.9920417519025904

Epoch: 6| Step: 1
Training loss: 2.899864435195923
Validation loss: 2.992233589131345

Epoch: 6| Step: 2
Training loss: 3.5805373191833496
Validation loss: 2.993571037887245

Epoch: 6| Step: 3
Training loss: 3.3937947750091553
Validation loss: 2.998326329774754

Epoch: 6| Step: 4
Training loss: 3.0705063343048096
Validation loss: 2.9953974549488356

Epoch: 6| Step: 5
Training loss: 3.456923007965088
Validation loss: 2.994738245523104

Epoch: 6| Step: 6
Training loss: 3.184898614883423
Validation loss: 2.99592573155639

Epoch: 6| Step: 7
Training loss: 2.3025600910186768
Validation loss: 2.9922124775507117

Epoch: 6| Step: 8
Training loss: 2.074092388153076
Validation loss: 2.993756595478263

Epoch: 6| Step: 9
Training loss: 3.041515588760376
Validation loss: 2.9952665093124553

Epoch: 6| Step: 10
Training loss: 2.71482515335083
Validation loss: 2.9948029159217753

Epoch: 6| Step: 11
Training loss: 3.4670143127441406
Validation loss: 2.9974045753479004

Epoch: 6| Step: 12
Training loss: 3.49241304397583
Validation loss: 2.9998644859560075

Epoch: 6| Step: 13
Training loss: 3.1819522380828857
Validation loss: 2.992349660524758

Epoch: 59| Step: 0
Training loss: 3.6126534938812256
Validation loss: 2.9966284690364713

Epoch: 6| Step: 1
Training loss: 3.9324898719787598
Validation loss: 3.007583684818719

Epoch: 6| Step: 2
Training loss: 3.0677638053894043
Validation loss: 3.025043418330531

Epoch: 6| Step: 3
Training loss: 3.5368571281433105
Validation loss: 3.0242512097922702

Epoch: 6| Step: 4
Training loss: 2.745689868927002
Validation loss: 3.014722470314272

Epoch: 6| Step: 5
Training loss: 3.5091919898986816
Validation loss: 2.9959914838114092

Epoch: 6| Step: 6
Training loss: 2.437941551208496
Validation loss: 2.9889893608708538

Epoch: 6| Step: 7
Training loss: 2.4035043716430664
Validation loss: 2.989823461860739

Epoch: 6| Step: 8
Training loss: 2.65972900390625
Validation loss: 2.9895451504697084

Epoch: 6| Step: 9
Training loss: 3.950108289718628
Validation loss: 2.9862617061984156

Epoch: 6| Step: 10
Training loss: 2.6083121299743652
Validation loss: 2.9856929702143513

Epoch: 6| Step: 11
Training loss: 2.8822529315948486
Validation loss: 2.986973777894051

Epoch: 6| Step: 12
Training loss: 3.125731945037842
Validation loss: 2.989269741119877

Epoch: 6| Step: 13
Training loss: 1.7535141706466675
Validation loss: 2.988598241600939

Epoch: 60| Step: 0
Training loss: 2.5426042079925537
Validation loss: 2.987041542606969

Epoch: 6| Step: 1
Training loss: 3.191706895828247
Validation loss: 2.9862188087996615

Epoch: 6| Step: 2
Training loss: 2.7234349250793457
Validation loss: 2.9888500193113923

Epoch: 6| Step: 3
Training loss: 2.808002233505249
Validation loss: 2.9882277929654686

Epoch: 6| Step: 4
Training loss: 3.4262917041778564
Validation loss: 2.987402941590996

Epoch: 6| Step: 5
Training loss: 2.7534046173095703
Validation loss: 2.9892821311950684

Epoch: 6| Step: 6
Training loss: 3.5177719593048096
Validation loss: 2.9884636325220906

Epoch: 6| Step: 7
Training loss: 2.8057706356048584
Validation loss: 2.9859889117620324

Epoch: 6| Step: 8
Training loss: 3.2010397911071777
Validation loss: 2.989464465007987

Epoch: 6| Step: 9
Training loss: 3.337660789489746
Validation loss: 2.9890748736678914

Epoch: 6| Step: 10
Training loss: 2.7381410598754883
Validation loss: 3.000347311778735

Epoch: 6| Step: 11
Training loss: 3.4456188678741455
Validation loss: 3.000122449731314

Epoch: 6| Step: 12
Training loss: 3.037708044052124
Validation loss: 3.0055897569143646

Epoch: 6| Step: 13
Training loss: 3.4005696773529053
Validation loss: 3.00353064075593

Epoch: 61| Step: 0
Training loss: 3.029364585876465
Validation loss: 2.9986693320735807

Epoch: 6| Step: 1
Training loss: 3.304333448410034
Validation loss: 2.998800144400648

Epoch: 6| Step: 2
Training loss: 4.1495680809021
Validation loss: 3.0073931832467355

Epoch: 6| Step: 3
Training loss: 3.0615615844726562
Validation loss: 3.00791577113572

Epoch: 6| Step: 4
Training loss: 2.3889222145080566
Validation loss: 3.014852367421632

Epoch: 6| Step: 5
Training loss: 1.90279221534729
Validation loss: 3.019234800851473

Epoch: 6| Step: 6
Training loss: 2.625216245651245
Validation loss: 3.0199754879038823

Epoch: 6| Step: 7
Training loss: 3.0957882404327393
Validation loss: 3.028381896275346

Epoch: 6| Step: 8
Training loss: 3.272502899169922
Validation loss: 3.0403779245192006

Epoch: 6| Step: 9
Training loss: 3.6514062881469727
Validation loss: 3.0393529040839082

Epoch: 6| Step: 10
Training loss: 3.3316774368286133
Validation loss: 3.0435385652767715

Epoch: 6| Step: 11
Training loss: 2.6534194946289062
Validation loss: 3.0374180424597954

Epoch: 6| Step: 12
Training loss: 3.535836935043335
Validation loss: 3.046996767802905

Epoch: 6| Step: 13
Training loss: 3.1297194957733154
Validation loss: 3.040768687443067

Epoch: 62| Step: 0
Training loss: 2.043259382247925
Validation loss: 3.0347893802068566

Epoch: 6| Step: 1
Training loss: 3.6593070030212402
Validation loss: 3.029783600120134

Epoch: 6| Step: 2
Training loss: 2.7820839881896973
Validation loss: 3.028286603189284

Epoch: 6| Step: 3
Training loss: 4.029119491577148
Validation loss: 3.0251461587926394

Epoch: 6| Step: 4
Training loss: 3.1393940448760986
Validation loss: 3.0222680696877102

Epoch: 6| Step: 5
Training loss: 3.8131680488586426
Validation loss: 3.016918125972953

Epoch: 6| Step: 6
Training loss: 2.2644293308258057
Validation loss: 3.015490513975902

Epoch: 6| Step: 7
Training loss: 2.0867621898651123
Validation loss: 3.015508997824884

Epoch: 6| Step: 8
Training loss: 3.2080719470977783
Validation loss: 3.0149652265733287

Epoch: 6| Step: 9
Training loss: 3.1007657051086426
Validation loss: 3.0150247825089322

Epoch: 6| Step: 10
Training loss: 3.318905830383301
Validation loss: 3.0101483970560055

Epoch: 6| Step: 11
Training loss: 3.5995006561279297
Validation loss: 2.9986855727370068

Epoch: 6| Step: 12
Training loss: 2.487298011779785
Validation loss: 2.998945341315321

Epoch: 6| Step: 13
Training loss: 3.6988630294799805
Validation loss: 2.984589486993769

Epoch: 63| Step: 0
Training loss: 3.338858127593994
Validation loss: 2.980856931337746

Epoch: 6| Step: 1
Training loss: 2.495131015777588
Validation loss: 2.984449076396163

Epoch: 6| Step: 2
Training loss: 2.448549509048462
Validation loss: 2.988345533288935

Epoch: 6| Step: 3
Training loss: 3.953930616378784
Validation loss: 2.9735614407447075

Epoch: 6| Step: 4
Training loss: 2.939894199371338
Validation loss: 2.974565516236008

Epoch: 6| Step: 5
Training loss: 2.8007211685180664
Validation loss: 2.9788238797136533

Epoch: 6| Step: 6
Training loss: 3.594236135482788
Validation loss: 2.979487047400526

Epoch: 6| Step: 7
Training loss: 3.1450116634368896
Validation loss: 2.9854497935182307

Epoch: 6| Step: 8
Training loss: 2.358316421508789
Validation loss: 2.996754628355785

Epoch: 6| Step: 9
Training loss: 3.6877217292785645
Validation loss: 2.9966336219541487

Epoch: 6| Step: 10
Training loss: 3.332828998565674
Validation loss: 2.9921180048296527

Epoch: 6| Step: 11
Training loss: 2.9202213287353516
Validation loss: 2.987379656043104

Epoch: 6| Step: 12
Training loss: 3.3549094200134277
Validation loss: 2.9808846391657347

Epoch: 6| Step: 13
Training loss: 1.6561630964279175
Validation loss: 2.9788314603990123

Epoch: 64| Step: 0
Training loss: 3.112264394760132
Validation loss: 2.9751499596462456

Epoch: 6| Step: 1
Training loss: 3.6863584518432617
Validation loss: 2.974778293281473

Epoch: 6| Step: 2
Training loss: 3.320077419281006
Validation loss: 2.971219385823896

Epoch: 6| Step: 3
Training loss: 2.9672465324401855
Validation loss: 2.9733736027953444

Epoch: 6| Step: 4
Training loss: 3.578638792037964
Validation loss: 2.9711028734842935

Epoch: 6| Step: 5
Training loss: 1.985579013824463
Validation loss: 2.968932318431075

Epoch: 6| Step: 6
Training loss: 3.139404773712158
Validation loss: 2.9697005466748307

Epoch: 6| Step: 7
Training loss: 2.43540620803833
Validation loss: 2.9737753586102555

Epoch: 6| Step: 8
Training loss: 3.1265556812286377
Validation loss: 2.9744643011400775

Epoch: 6| Step: 9
Training loss: 2.126246690750122
Validation loss: 2.9709316479262484

Epoch: 6| Step: 10
Training loss: 2.822314977645874
Validation loss: 2.9710458196619505

Epoch: 6| Step: 11
Training loss: 2.727044105529785
Validation loss: 2.9737280825132966

Epoch: 6| Step: 12
Training loss: 4.071556091308594
Validation loss: 2.974888014537032

Epoch: 6| Step: 13
Training loss: 3.6936938762664795
Validation loss: 2.9721409787413893

Epoch: 65| Step: 0
Training loss: 3.133746862411499
Validation loss: 2.9688463903242543

Epoch: 6| Step: 1
Training loss: 3.8914144039154053
Validation loss: 2.9728866366929907

Epoch: 6| Step: 2
Training loss: 2.672133684158325
Validation loss: 2.9717926389427594

Epoch: 6| Step: 3
Training loss: 2.5478146076202393
Validation loss: 2.9701958856275006

Epoch: 6| Step: 4
Training loss: 2.257293224334717
Validation loss: 2.9709934521746892

Epoch: 6| Step: 5
Training loss: 2.5124940872192383
Validation loss: 2.9727305032873668

Epoch: 6| Step: 6
Training loss: 2.8919453620910645
Validation loss: 2.971283494785268

Epoch: 6| Step: 7
Training loss: 3.660825729370117
Validation loss: 2.972045462618592

Epoch: 6| Step: 8
Training loss: 2.5357019901275635
Validation loss: 2.966643315489574

Epoch: 6| Step: 9
Training loss: 3.1730597019195557
Validation loss: 2.9649281655588458

Epoch: 6| Step: 10
Training loss: 3.4646778106689453
Validation loss: 2.9631387367043445

Epoch: 6| Step: 11
Training loss: 3.7066988945007324
Validation loss: 2.96234901233386

Epoch: 6| Step: 12
Training loss: 2.5950927734375
Validation loss: 2.963356251357704

Epoch: 6| Step: 13
Training loss: 3.6996943950653076
Validation loss: 2.961764920142389

Epoch: 66| Step: 0
Training loss: 3.2270736694335938
Validation loss: 2.969451504368936

Epoch: 6| Step: 1
Training loss: 2.3767385482788086
Validation loss: 2.963532419614894

Epoch: 6| Step: 2
Training loss: 2.769325017929077
Validation loss: 2.9574931026786886

Epoch: 6| Step: 3
Training loss: 3.853107452392578
Validation loss: 2.9589629070733183

Epoch: 6| Step: 4
Training loss: 2.8981375694274902
Validation loss: 2.9589119803520942

Epoch: 6| Step: 5
Training loss: 2.190243721008301
Validation loss: 2.954609114636657

Epoch: 6| Step: 6
Training loss: 3.201864719390869
Validation loss: 2.9544125526182112

Epoch: 6| Step: 7
Training loss: 2.744198799133301
Validation loss: 2.95552477528972

Epoch: 6| Step: 8
Training loss: 3.5737757682800293
Validation loss: 2.958593912022088

Epoch: 6| Step: 9
Training loss: 3.119776725769043
Validation loss: 2.9565913600306355

Epoch: 6| Step: 10
Training loss: 3.3188529014587402
Validation loss: 2.9549042588921

Epoch: 6| Step: 11
Training loss: 3.6811470985412598
Validation loss: 2.954613665098785

Epoch: 6| Step: 12
Training loss: 3.353806972503662
Validation loss: 2.9570842199428107

Epoch: 6| Step: 13
Training loss: 1.409071683883667
Validation loss: 2.9569938003375964

Epoch: 67| Step: 0
Training loss: 2.129275321960449
Validation loss: 2.954264276771135

Epoch: 6| Step: 1
Training loss: 3.7542519569396973
Validation loss: 2.9554065196744856

Epoch: 6| Step: 2
Training loss: 3.459623336791992
Validation loss: 2.961839291357225

Epoch: 6| Step: 3
Training loss: 2.4151241779327393
Validation loss: 2.9622238374525502

Epoch: 6| Step: 4
Training loss: 3.104158878326416
Validation loss: 2.964250736339118

Epoch: 6| Step: 5
Training loss: 2.928774833679199
Validation loss: 2.9648572373133835

Epoch: 6| Step: 6
Training loss: 3.2824742794036865
Validation loss: 2.964667873997842

Epoch: 6| Step: 7
Training loss: 2.490354299545288
Validation loss: 2.961898342255623

Epoch: 6| Step: 8
Training loss: 2.9362332820892334
Validation loss: 2.969003890150337

Epoch: 6| Step: 9
Training loss: 3.611173629760742
Validation loss: 2.968426122460314

Epoch: 6| Step: 10
Training loss: 2.9033868312835693
Validation loss: 2.9816393442051385

Epoch: 6| Step: 11
Training loss: 2.85006046295166
Validation loss: 2.9870767619020198

Epoch: 6| Step: 12
Training loss: 3.8339831829071045
Validation loss: 2.985982561624178

Epoch: 6| Step: 13
Training loss: 2.4828500747680664
Validation loss: 2.9870049184368503

Epoch: 68| Step: 0
Training loss: 3.6484053134918213
Validation loss: 2.972207289870067

Epoch: 6| Step: 1
Training loss: 3.4330177307128906
Validation loss: 2.9636996946027203

Epoch: 6| Step: 2
Training loss: 2.794992208480835
Validation loss: 2.959095078129922

Epoch: 6| Step: 3
Training loss: 3.161360740661621
Validation loss: 2.9562068498262795

Epoch: 6| Step: 4
Training loss: 3.47615385055542
Validation loss: 2.9548187666041876

Epoch: 6| Step: 5
Training loss: 2.243317127227783
Validation loss: 2.953031139989053

Epoch: 6| Step: 6
Training loss: 2.834594249725342
Validation loss: 2.9532296657562256

Epoch: 6| Step: 7
Training loss: 3.187523603439331
Validation loss: 2.9548071994576404

Epoch: 6| Step: 8
Training loss: 2.4458346366882324
Validation loss: 2.9546172977775655

Epoch: 6| Step: 9
Training loss: 3.2413597106933594
Validation loss: 2.9568481573494534

Epoch: 6| Step: 10
Training loss: 2.9188389778137207
Validation loss: 2.9593002180899344

Epoch: 6| Step: 11
Training loss: 3.090956211090088
Validation loss: 2.963205014505694

Epoch: 6| Step: 12
Training loss: 3.5023763179779053
Validation loss: 2.9564509622512327

Epoch: 6| Step: 13
Training loss: 1.7651846408843994
Validation loss: 2.957067253769085

Epoch: 69| Step: 0
Training loss: 3.2626776695251465
Validation loss: 2.958138155680831

Epoch: 6| Step: 1
Training loss: 4.2976531982421875
Validation loss: 2.9611297576658187

Epoch: 6| Step: 2
Training loss: 3.483487606048584
Validation loss: 2.963746240062098

Epoch: 6| Step: 3
Training loss: 2.6137537956237793
Validation loss: 2.9643468215901363

Epoch: 6| Step: 4
Training loss: 3.0339059829711914
Validation loss: 2.964547828961444

Epoch: 6| Step: 5
Training loss: 2.803933620452881
Validation loss: 2.958353796312886

Epoch: 6| Step: 6
Training loss: 2.9893150329589844
Validation loss: 2.9607775134425007

Epoch: 6| Step: 7
Training loss: 2.590756893157959
Validation loss: 2.9634585918918734

Epoch: 6| Step: 8
Training loss: 3.3062331676483154
Validation loss: 2.962129767223071

Epoch: 6| Step: 9
Training loss: 3.177960157394409
Validation loss: 2.959216728005358

Epoch: 6| Step: 10
Training loss: 3.384730339050293
Validation loss: 2.962136871071272

Epoch: 6| Step: 11
Training loss: 2.3456673622131348
Validation loss: 2.9574158909500285

Epoch: 6| Step: 12
Training loss: 2.418454647064209
Validation loss: 2.9566441197549143

Epoch: 6| Step: 13
Training loss: 2.2436952590942383
Validation loss: 2.9587067737374255

Epoch: 70| Step: 0
Training loss: 3.1401267051696777
Validation loss: 2.956886463267829

Epoch: 6| Step: 1
Training loss: 2.5881710052490234
Validation loss: 2.9592114417783675

Epoch: 6| Step: 2
Training loss: 3.9410758018493652
Validation loss: 2.969821658185733

Epoch: 6| Step: 3
Training loss: 3.189894199371338
Validation loss: 2.966920345060287

Epoch: 6| Step: 4
Training loss: 3.286501884460449
Validation loss: 2.969080901915027

Epoch: 6| Step: 5
Training loss: 2.2844231128692627
Validation loss: 2.97263769436908

Epoch: 6| Step: 6
Training loss: 2.88663387298584
Validation loss: 2.962314026330107

Epoch: 6| Step: 7
Training loss: 3.2740650177001953
Validation loss: 2.9634324965938443

Epoch: 6| Step: 8
Training loss: 2.353654384613037
Validation loss: 2.96521258354187

Epoch: 6| Step: 9
Training loss: 3.123015880584717
Validation loss: 2.96438870891448

Epoch: 6| Step: 10
Training loss: 2.898592472076416
Validation loss: 2.9662513758546565

Epoch: 6| Step: 11
Training loss: 2.971330165863037
Validation loss: 2.9773864874275784

Epoch: 6| Step: 12
Training loss: 3.2135424613952637
Validation loss: 2.9739414594506703

Epoch: 6| Step: 13
Training loss: 3.1127259731292725
Validation loss: 2.977673440851191

Epoch: 71| Step: 0
Training loss: 2.4236996173858643
Validation loss: 2.9872741237763436

Epoch: 6| Step: 1
Training loss: 3.545768976211548
Validation loss: 2.9857142535589074

Epoch: 6| Step: 2
Training loss: 3.071187734603882
Validation loss: 2.9729692859034382

Epoch: 6| Step: 3
Training loss: 2.7034718990325928
Validation loss: 2.9608333623537453

Epoch: 6| Step: 4
Training loss: 3.2779786586761475
Validation loss: 2.9596535364786782

Epoch: 6| Step: 5
Training loss: 3.191159963607788
Validation loss: 2.9609913543988298

Epoch: 6| Step: 6
Training loss: 2.8815340995788574
Validation loss: 2.954415113695206

Epoch: 6| Step: 7
Training loss: 3.5413296222686768
Validation loss: 2.9565651493687786

Epoch: 6| Step: 8
Training loss: 2.409471035003662
Validation loss: 2.9570852992355183

Epoch: 6| Step: 9
Training loss: 2.824618339538574
Validation loss: 2.961227801538283

Epoch: 6| Step: 10
Training loss: 3.3632519245147705
Validation loss: 2.9679018630776355

Epoch: 6| Step: 11
Training loss: 3.5216007232666016
Validation loss: 2.9662349300999797

Epoch: 6| Step: 12
Training loss: 2.91383957862854
Validation loss: 2.965167309648247

Epoch: 6| Step: 13
Training loss: 2.2370784282684326
Validation loss: 2.9634889505242787

Epoch: 72| Step: 0
Training loss: 3.9908454418182373
Validation loss: 2.9677772060517342

Epoch: 6| Step: 1
Training loss: 3.6481854915618896
Validation loss: 2.9674817823594615

Epoch: 6| Step: 2
Training loss: 3.5628867149353027
Validation loss: 2.9643804821916806

Epoch: 6| Step: 3
Training loss: 2.711982488632202
Validation loss: 2.965275546555878

Epoch: 6| Step: 4
Training loss: 3.3177504539489746
Validation loss: 2.958511603775845

Epoch: 6| Step: 5
Training loss: 2.356005907058716
Validation loss: 2.9584491996354956

Epoch: 6| Step: 6
Training loss: 2.513688564300537
Validation loss: 2.9595824928693872

Epoch: 6| Step: 7
Training loss: 2.9746487140655518
Validation loss: 2.9612104713275866

Epoch: 6| Step: 8
Training loss: 2.3183608055114746
Validation loss: 2.956482087412188

Epoch: 6| Step: 9
Training loss: 2.4528167247772217
Validation loss: 2.9578987167727564

Epoch: 6| Step: 10
Training loss: 3.545210599899292
Validation loss: 2.959720770517985

Epoch: 6| Step: 11
Training loss: 3.6990673542022705
Validation loss: 2.953671416928691

Epoch: 6| Step: 12
Training loss: 2.460481643676758
Validation loss: 2.9534586168104604

Epoch: 6| Step: 13
Training loss: 2.4607114791870117
Validation loss: 2.9528232415517173

Epoch: 73| Step: 0
Training loss: 3.00441312789917
Validation loss: 2.9532426659778883

Epoch: 6| Step: 1
Training loss: 3.3231892585754395
Validation loss: 2.951367070597987

Epoch: 6| Step: 2
Training loss: 2.7130613327026367
Validation loss: 2.9467335798407115

Epoch: 6| Step: 3
Training loss: 4.184394359588623
Validation loss: 2.948645076444072

Epoch: 6| Step: 4
Training loss: 3.083066940307617
Validation loss: 2.948962955064671

Epoch: 6| Step: 5
Training loss: 2.7487504482269287
Validation loss: 2.946446769980974

Epoch: 6| Step: 6
Training loss: 3.308957576751709
Validation loss: 2.950697363063853

Epoch: 6| Step: 7
Training loss: 3.43636155128479
Validation loss: 2.9490223905091644

Epoch: 6| Step: 8
Training loss: 2.1551053524017334
Validation loss: 2.9511129881746028

Epoch: 6| Step: 9
Training loss: 3.063117027282715
Validation loss: 2.956812350980697

Epoch: 6| Step: 10
Training loss: 2.554002523422241
Validation loss: 2.956869897022042

Epoch: 6| Step: 11
Training loss: 2.6215686798095703
Validation loss: 2.9537218309217885

Epoch: 6| Step: 12
Training loss: 2.9991915225982666
Validation loss: 2.9535575759026313

Epoch: 6| Step: 13
Training loss: 2.9472367763519287
Validation loss: 2.9573183674966135

Epoch: 74| Step: 0
Training loss: 3.5088977813720703
Validation loss: 2.953103996092273

Epoch: 6| Step: 1
Training loss: 3.5174500942230225
Validation loss: 2.948859973620343

Epoch: 6| Step: 2
Training loss: 3.7095038890838623
Validation loss: 2.9430703040092223

Epoch: 6| Step: 3
Training loss: 2.8004117012023926
Validation loss: 2.9434921100575435

Epoch: 6| Step: 4
Training loss: 3.2702136039733887
Validation loss: 2.9419699125392462

Epoch: 6| Step: 5
Training loss: 1.8469380140304565
Validation loss: 2.9436256936801377

Epoch: 6| Step: 6
Training loss: 3.025603771209717
Validation loss: 2.9425031574823524

Epoch: 6| Step: 7
Training loss: 2.4952335357666016
Validation loss: 2.944763514303392

Epoch: 6| Step: 8
Training loss: 2.64375376701355
Validation loss: 2.946550679463212

Epoch: 6| Step: 9
Training loss: 3.6862404346466064
Validation loss: 2.946207813037339

Epoch: 6| Step: 10
Training loss: 2.9444048404693604
Validation loss: 2.9454399001213813

Epoch: 6| Step: 11
Training loss: 3.5820717811584473
Validation loss: 2.95166100225141

Epoch: 6| Step: 12
Training loss: 2.490856647491455
Validation loss: 2.947415223685644

Epoch: 6| Step: 13
Training loss: 2.266451120376587
Validation loss: 2.946592192496023

Epoch: 75| Step: 0
Training loss: 3.4574995040893555
Validation loss: 2.9497926260835383

Epoch: 6| Step: 1
Training loss: 2.820960521697998
Validation loss: 2.943874630876767

Epoch: 6| Step: 2
Training loss: 2.7332377433776855
Validation loss: 2.942245688489688

Epoch: 6| Step: 3
Training loss: 2.5056843757629395
Validation loss: 2.9437537782935688

Epoch: 6| Step: 4
Training loss: 2.136051654815674
Validation loss: 2.9427408684966383

Epoch: 6| Step: 5
Training loss: 3.3590898513793945
Validation loss: 2.9427278298203663

Epoch: 6| Step: 6
Training loss: 2.6737918853759766
Validation loss: 2.9422037396379697

Epoch: 6| Step: 7
Training loss: 3.3083066940307617
Validation loss: 2.9400936531764206

Epoch: 6| Step: 8
Training loss: 3.6216559410095215
Validation loss: 2.942706192693403

Epoch: 6| Step: 9
Training loss: 2.995086669921875
Validation loss: 2.940287438772058

Epoch: 6| Step: 10
Training loss: 2.2556214332580566
Validation loss: 2.9413340501887824

Epoch: 6| Step: 11
Training loss: 3.894376277923584
Validation loss: 2.9391487695837535

Epoch: 6| Step: 12
Training loss: 3.1839146614074707
Validation loss: 2.9389046981770504

Epoch: 6| Step: 13
Training loss: 3.2018895149230957
Validation loss: 2.9432985192985943

Testing loss: 2.954535738627116
