Epoch: 1| Step: 0
Training loss: 5.992963479539137
Validation loss: 5.750188830655946

Epoch: 6| Step: 1
Training loss: 5.913888341639772
Validation loss: 5.745411278218846

Epoch: 6| Step: 2
Training loss: 6.314124172242734
Validation loss: 5.741020310254058

Epoch: 6| Step: 3
Training loss: 6.673820408522756
Validation loss: 5.736785070162402

Epoch: 6| Step: 4
Training loss: 6.40622796775937
Validation loss: 5.732545021337244

Epoch: 6| Step: 5
Training loss: 5.6871290819555185
Validation loss: 5.7283051762816495

Epoch: 6| Step: 6
Training loss: 4.517304104989294
Validation loss: 5.724044263347126

Epoch: 6| Step: 7
Training loss: 5.796411706553892
Validation loss: 5.719767538639697

Epoch: 6| Step: 8
Training loss: 5.619634145863022
Validation loss: 5.71541455826614

Epoch: 6| Step: 9
Training loss: 5.299602875136521
Validation loss: 5.71081372611689

Epoch: 6| Step: 10
Training loss: 4.673206560607552
Validation loss: 5.706670054263272

Epoch: 6| Step: 11
Training loss: 4.897912978421468
Validation loss: 5.701716808294736

Epoch: 6| Step: 12
Training loss: 6.611614019390897
Validation loss: 5.697038799488889

Epoch: 6| Step: 13
Training loss: 5.6890142751492165
Validation loss: 5.691955779060562

Epoch: 2| Step: 0
Training loss: 4.778699805624474
Validation loss: 5.686506438576256

Epoch: 6| Step: 1
Training loss: 6.361594672704727
Validation loss: 5.681365624550598

Epoch: 6| Step: 2
Training loss: 5.357200604082129
Validation loss: 5.6754911299023565

Epoch: 6| Step: 3
Training loss: 5.932275019067767
Validation loss: 5.669173362430982

Epoch: 6| Step: 4
Training loss: 5.632058017691973
Validation loss: 5.662801529461367

Epoch: 6| Step: 5
Training loss: 7.0728662083604545
Validation loss: 5.656130709512265

Epoch: 6| Step: 6
Training loss: 5.4883677845713565
Validation loss: 5.648771912177956

Epoch: 6| Step: 7
Training loss: 5.774474756704744
Validation loss: 5.6422394381757

Epoch: 6| Step: 8
Training loss: 5.785456596166204
Validation loss: 5.633809398528196

Epoch: 6| Step: 9
Training loss: 5.839396277797916
Validation loss: 5.625338527104667

Epoch: 6| Step: 10
Training loss: 5.742794663903439
Validation loss: 5.616720025387347

Epoch: 6| Step: 11
Training loss: 4.84453748638931
Validation loss: 5.606919034484841

Epoch: 6| Step: 12
Training loss: 5.271715756257208
Validation loss: 5.59797961812493

Epoch: 6| Step: 13
Training loss: 4.977425732444138
Validation loss: 5.588373436860586

Epoch: 3| Step: 0
Training loss: 6.875050492534752
Validation loss: 5.576538518461252

Epoch: 6| Step: 1
Training loss: 5.829910945572049
Validation loss: 5.565752358694151

Epoch: 6| Step: 2
Training loss: 5.970621025461883
Validation loss: 5.554363845384953

Epoch: 6| Step: 3
Training loss: 4.178024503059903
Validation loss: 5.541668654663607

Epoch: 6| Step: 4
Training loss: 5.630581947184931
Validation loss: 5.529067587645374

Epoch: 6| Step: 5
Training loss: 5.414682328054446
Validation loss: 5.514332644966648

Epoch: 6| Step: 6
Training loss: 6.727049629392412
Validation loss: 5.500105550131675

Epoch: 6| Step: 7
Training loss: 5.0842147229798655
Validation loss: 5.485905367879354

Epoch: 6| Step: 8
Training loss: 5.41793178553991
Validation loss: 5.469504790597266

Epoch: 6| Step: 9
Training loss: 5.877820251125498
Validation loss: 5.453960653317925

Epoch: 6| Step: 10
Training loss: 4.97935802565514
Validation loss: 5.436922973672992

Epoch: 6| Step: 11
Training loss: 5.056717949751582
Validation loss: 5.4191058735150595

Epoch: 6| Step: 12
Training loss: 4.933928731266771
Validation loss: 5.40206237135647

Epoch: 6| Step: 13
Training loss: 4.4417738414284935
Validation loss: 5.382050290036678

Epoch: 4| Step: 0
Training loss: 5.862441254994519
Validation loss: 5.364113025337657

Epoch: 6| Step: 1
Training loss: 5.696708183754841
Validation loss: 5.345369728816699

Epoch: 6| Step: 2
Training loss: 4.754157605888342
Validation loss: 5.324282747474992

Epoch: 6| Step: 3
Training loss: 5.711790759509658
Validation loss: 5.303897275235522

Epoch: 6| Step: 4
Training loss: 6.027258940994395
Validation loss: 5.283373644621862

Epoch: 6| Step: 5
Training loss: 4.814204124836297
Validation loss: 5.261864662103787

Epoch: 6| Step: 6
Training loss: 5.436061274168428
Validation loss: 5.240692372930704

Epoch: 6| Step: 7
Training loss: 5.0157234919019205
Validation loss: 5.217825862966945

Epoch: 6| Step: 8
Training loss: 4.836242961942512
Validation loss: 5.19585492219022

Epoch: 6| Step: 9
Training loss: 4.348153057657628
Validation loss: 5.176210539295254

Epoch: 6| Step: 10
Training loss: 5.830481168019906
Validation loss: 5.154683646516108

Epoch: 6| Step: 11
Training loss: 4.914327593083175
Validation loss: 5.134600523342683

Epoch: 6| Step: 12
Training loss: 5.69384244305701
Validation loss: 5.111354426768493

Epoch: 6| Step: 13
Training loss: 4.316083883960527
Validation loss: 5.090582563313443

Epoch: 5| Step: 0
Training loss: 5.458880603329427
Validation loss: 5.0707272171132765

Epoch: 6| Step: 1
Training loss: 5.262132340950923
Validation loss: 5.048693330724775

Epoch: 6| Step: 2
Training loss: 5.087876566979139
Validation loss: 5.0274394749120805

Epoch: 6| Step: 3
Training loss: 4.93256566200692
Validation loss: 5.005949332543661

Epoch: 6| Step: 4
Training loss: 4.426571996741269
Validation loss: 4.987072603266124

Epoch: 6| Step: 5
Training loss: 5.347928917274764
Validation loss: 4.965163051867864

Epoch: 6| Step: 6
Training loss: 5.104798860389045
Validation loss: 4.945642086533189

Epoch: 6| Step: 7
Training loss: 4.846842117247217
Validation loss: 4.925167646938736

Epoch: 6| Step: 8
Training loss: 5.395518152563621
Validation loss: 4.905547370288

Epoch: 6| Step: 9
Training loss: 4.697015082325556
Validation loss: 4.885911550141104

Epoch: 6| Step: 10
Training loss: 5.487768965192688
Validation loss: 4.865374247758295

Epoch: 6| Step: 11
Training loss: 4.442078927800098
Validation loss: 4.848340027369519

Epoch: 6| Step: 12
Training loss: 4.811727090175838
Validation loss: 4.828076128299637

Epoch: 6| Step: 13
Training loss: 4.324006362289279
Validation loss: 4.808562572030267

Epoch: 6| Step: 0
Training loss: 5.060215187171245
Validation loss: 4.790694200761268

Epoch: 6| Step: 1
Training loss: 3.8384873253932454
Validation loss: 4.771243647575774

Epoch: 6| Step: 2
Training loss: 3.9076677114820515
Validation loss: 4.754943794292773

Epoch: 6| Step: 3
Training loss: 4.06978177584535
Validation loss: 4.736246182242743

Epoch: 6| Step: 4
Training loss: 5.575685111744747
Validation loss: 4.717226163375144

Epoch: 6| Step: 5
Training loss: 4.73150809829988
Validation loss: 4.69867534590007

Epoch: 6| Step: 6
Training loss: 5.30198472486531
Validation loss: 4.681292436139235

Epoch: 6| Step: 7
Training loss: 4.540107646119692
Validation loss: 4.6658020837390435

Epoch: 6| Step: 8
Training loss: 5.491619314048425
Validation loss: 4.64547508635711

Epoch: 6| Step: 9
Training loss: 4.4149443429136666
Validation loss: 4.62849536084753

Epoch: 6| Step: 10
Training loss: 4.5649645693888345
Validation loss: 4.608762213907289

Epoch: 6| Step: 11
Training loss: 4.575726294061312
Validation loss: 4.589568094612888

Epoch: 6| Step: 12
Training loss: 5.89861534810521
Validation loss: 4.574702738345959

Epoch: 6| Step: 13
Training loss: 3.510210266988181
Validation loss: 4.55495032441832

Epoch: 7| Step: 0
Training loss: 4.267656338671145
Validation loss: 4.537671354425585

Epoch: 6| Step: 1
Training loss: 4.3928907528254975
Validation loss: 4.519615497368117

Epoch: 6| Step: 2
Training loss: 5.617140641103229
Validation loss: 4.503154999959387

Epoch: 6| Step: 3
Training loss: 5.401806543303306
Validation loss: 4.485573946954843

Epoch: 6| Step: 4
Training loss: 5.50541160687006
Validation loss: 4.470194393773456

Epoch: 6| Step: 5
Training loss: 4.009353668560509
Validation loss: 4.452111073469145

Epoch: 6| Step: 6
Training loss: 4.556208204540811
Validation loss: 4.433362287404761

Epoch: 6| Step: 7
Training loss: 4.253143942830703
Validation loss: 4.416188761943892

Epoch: 6| Step: 8
Training loss: 3.9738465272999886
Validation loss: 4.398140211824401

Epoch: 6| Step: 9
Training loss: 3.8339081347090445
Validation loss: 4.380790326568216

Epoch: 6| Step: 10
Training loss: 4.625658143100929
Validation loss: 4.3662915401588736

Epoch: 6| Step: 11
Training loss: 3.64272526093585
Validation loss: 4.347284752806236

Epoch: 6| Step: 12
Training loss: 3.9213504516459663
Validation loss: 4.330702348984866

Epoch: 6| Step: 13
Training loss: 5.337895091529873
Validation loss: 4.314860022303521

Epoch: 8| Step: 0
Training loss: 4.505967316246105
Validation loss: 4.300773493706413

Epoch: 6| Step: 1
Training loss: 4.925749498063801
Validation loss: 4.286701317164874

Epoch: 6| Step: 2
Training loss: 3.981743994805962
Validation loss: 4.270222002401321

Epoch: 6| Step: 3
Training loss: 4.765479313859238
Validation loss: 4.253672386662558

Epoch: 6| Step: 4
Training loss: 3.734412923325027
Validation loss: 4.239277634558485

Epoch: 6| Step: 5
Training loss: 3.6429192513693014
Validation loss: 4.228682439314333

Epoch: 6| Step: 6
Training loss: 3.7530838048549686
Validation loss: 4.216883266339363

Epoch: 6| Step: 7
Training loss: 5.548815750382189
Validation loss: 4.2023584835161145

Epoch: 6| Step: 8
Training loss: 4.2524214185734905
Validation loss: 4.194100763527965

Epoch: 6| Step: 9
Training loss: 4.851175633730125
Validation loss: 4.178578879462316

Epoch: 6| Step: 10
Training loss: 4.773263681496728
Validation loss: 4.166128180173305

Epoch: 6| Step: 11
Training loss: 3.9464716351063793
Validation loss: 4.154091746441021

Epoch: 6| Step: 12
Training loss: 3.387949648360232
Validation loss: 4.140250210585516

Epoch: 6| Step: 13
Training loss: 4.027806667063504
Validation loss: 4.128143122363432

Epoch: 9| Step: 0
Training loss: 4.597322696587928
Validation loss: 4.120657419001179

Epoch: 6| Step: 1
Training loss: 4.0782056778567854
Validation loss: 4.105759736189771

Epoch: 6| Step: 2
Training loss: 3.5674020603265304
Validation loss: 4.096782576523571

Epoch: 6| Step: 3
Training loss: 3.7326638359399293
Validation loss: 4.08823340263429

Epoch: 6| Step: 4
Training loss: 4.642881724533569
Validation loss: 4.076751286512988

Epoch: 6| Step: 5
Training loss: 2.7404059467180435
Validation loss: 4.068978295404129

Epoch: 6| Step: 6
Training loss: 4.400150487233674
Validation loss: 4.05970260630833

Epoch: 6| Step: 7
Training loss: 3.6214832479133454
Validation loss: 4.051007256231351

Epoch: 6| Step: 8
Training loss: 4.5123076083521365
Validation loss: 4.044537268967755

Epoch: 6| Step: 9
Training loss: 5.042401010717103
Validation loss: 4.038438304110231

Epoch: 6| Step: 10
Training loss: 4.310348858798543
Validation loss: 4.03145387271853

Epoch: 6| Step: 11
Training loss: 3.855683943937458
Validation loss: 4.022761023990405

Epoch: 6| Step: 12
Training loss: 4.960058131338761
Validation loss: 4.016159358509105

Epoch: 6| Step: 13
Training loss: 4.130804428564827
Validation loss: 4.009095707486822

Epoch: 10| Step: 0
Training loss: 5.354500469484521
Validation loss: 4.002101115629841

Epoch: 6| Step: 1
Training loss: 3.8498781556504476
Validation loss: 3.995898520493238

Epoch: 6| Step: 2
Training loss: 4.673519801847087
Validation loss: 3.987942159525635

Epoch: 6| Step: 3
Training loss: 3.260970161102607
Validation loss: 3.9806149864326184

Epoch: 6| Step: 4
Training loss: 3.1374064032587463
Validation loss: 3.973612243361848

Epoch: 6| Step: 5
Training loss: 3.8368664644142974
Validation loss: 3.969117333405573

Epoch: 6| Step: 6
Training loss: 3.3736756163428994
Validation loss: 3.9609392811786837

Epoch: 6| Step: 7
Training loss: 4.294806853138068
Validation loss: 3.9554860122956423

Epoch: 6| Step: 8
Training loss: 3.8045198062857946
Validation loss: 3.951524608907253

Epoch: 6| Step: 9
Training loss: 4.4778328735731465
Validation loss: 3.9429925937562693

Epoch: 6| Step: 10
Training loss: 3.6921453149866053
Validation loss: 3.9382276030426313

Epoch: 6| Step: 11
Training loss: 4.843940189688483
Validation loss: 3.9335577704349554

Epoch: 6| Step: 12
Training loss: 3.9730669707638713
Validation loss: 3.9258520479225703

Epoch: 6| Step: 13
Training loss: 4.6418568424369475
Validation loss: 3.9199024772232556

Epoch: 11| Step: 0
Training loss: 3.2525914937432425
Validation loss: 3.910507964734515

Epoch: 6| Step: 1
Training loss: 3.6232956135133763
Validation loss: 3.9041922529705544

Epoch: 6| Step: 2
Training loss: 3.7867576904057603
Validation loss: 3.896264638951983

Epoch: 6| Step: 3
Training loss: 4.814936825980544
Validation loss: 3.8895664546756388

Epoch: 6| Step: 4
Training loss: 4.768396590950042
Validation loss: 3.8817838075872615

Epoch: 6| Step: 5
Training loss: 4.192094246889576
Validation loss: 3.874650598731666

Epoch: 6| Step: 6
Training loss: 3.1259814437832865
Validation loss: 3.863618414096135

Epoch: 6| Step: 7
Training loss: 2.959418317242127
Validation loss: 3.856594994029377

Epoch: 6| Step: 8
Training loss: 3.9101430795544925
Validation loss: 3.849207539498597

Epoch: 6| Step: 9
Training loss: 4.804367526184914
Validation loss: 3.845387162584185

Epoch: 6| Step: 10
Training loss: 4.564116936097505
Validation loss: 3.839605610767784

Epoch: 6| Step: 11
Training loss: 4.36170815000727
Validation loss: 3.8327808561605234

Epoch: 6| Step: 12
Training loss: 4.4311774975611815
Validation loss: 3.823778162971606

Epoch: 6| Step: 13
Training loss: 2.0045929860456386
Validation loss: 3.8186566049613164

Epoch: 12| Step: 0
Training loss: 3.700682917281654
Validation loss: 3.8125868931468254

Epoch: 6| Step: 1
Training loss: 3.9181068829634653
Validation loss: 3.8077632851606635

Epoch: 6| Step: 2
Training loss: 4.13088453929983
Validation loss: 3.7997761741957774

Epoch: 6| Step: 3
Training loss: 3.8311647141191183
Validation loss: 3.797403492994095

Epoch: 6| Step: 4
Training loss: 3.214230225099224
Validation loss: 3.7894504204346426

Epoch: 6| Step: 5
Training loss: 3.957172357391206
Validation loss: 3.7873838528371775

Epoch: 6| Step: 6
Training loss: 4.447537527370966
Validation loss: 3.7809476895133063

Epoch: 6| Step: 7
Training loss: 4.3981575749762865
Validation loss: 3.778077885485898

Epoch: 6| Step: 8
Training loss: 4.11798145955874
Validation loss: 3.7742918574225337

Epoch: 6| Step: 9
Training loss: 4.196521662923094
Validation loss: 3.7703724014411746

Epoch: 6| Step: 10
Training loss: 3.114904959072224
Validation loss: 3.7664787704257545

Epoch: 6| Step: 11
Training loss: 4.467016350642148
Validation loss: 3.7618878569051883

Epoch: 6| Step: 12
Training loss: 3.6293904255597824
Validation loss: 3.75861982163117

Epoch: 6| Step: 13
Training loss: 4.077691884627507
Validation loss: 3.7566387874638347

Epoch: 13| Step: 0
Training loss: 4.525902480021746
Validation loss: 3.7516484551178086

Epoch: 6| Step: 1
Training loss: 3.4769672286798974
Validation loss: 3.744880126298998

Epoch: 6| Step: 2
Training loss: 3.7209461042708845
Validation loss: 3.742879602101156

Epoch: 6| Step: 3
Training loss: 4.103454734644619
Validation loss: 3.739430866646173

Epoch: 6| Step: 4
Training loss: 3.192659577852564
Validation loss: 3.7381198110254896

Epoch: 6| Step: 5
Training loss: 3.221961632053189
Validation loss: 3.73194904693454

Epoch: 6| Step: 6
Training loss: 3.708885637508811
Validation loss: 3.7260123697462104

Epoch: 6| Step: 7
Training loss: 3.3488038276085486
Validation loss: 3.719462675165787

Epoch: 6| Step: 8
Training loss: 4.578098127787495
Validation loss: 3.7155092767515656

Epoch: 6| Step: 9
Training loss: 3.493171570310984
Validation loss: 3.7109292901233815

Epoch: 6| Step: 10
Training loss: 5.291193522929843
Validation loss: 3.7028727620547164

Epoch: 6| Step: 11
Training loss: 4.040724864177035
Validation loss: 3.7016683073859675

Epoch: 6| Step: 12
Training loss: 3.550820194110555
Validation loss: 3.6933450260897582

Epoch: 6| Step: 13
Training loss: 3.784582891825742
Validation loss: 3.694744074106814

Epoch: 14| Step: 0
Training loss: 4.559605764781053
Validation loss: 3.6830583786494575

Epoch: 6| Step: 1
Training loss: 3.7894523498704236
Validation loss: 3.677020226504421

Epoch: 6| Step: 2
Training loss: 4.142000480928122
Validation loss: 3.6746745764843407

Epoch: 6| Step: 3
Training loss: 3.832033614256088
Validation loss: 3.674692123762057

Epoch: 6| Step: 4
Training loss: 3.018148680637695
Validation loss: 3.670486374035589

Epoch: 6| Step: 5
Training loss: 2.8080332572141318
Validation loss: 3.6619319415461056

Epoch: 6| Step: 6
Training loss: 3.589562937449235
Validation loss: 3.6561519727808345

Epoch: 6| Step: 7
Training loss: 4.044911501073129
Validation loss: 3.6518000639113817

Epoch: 6| Step: 8
Training loss: 4.510410135571315
Validation loss: 3.640762548318601

Epoch: 6| Step: 9
Training loss: 4.049332627305702
Validation loss: 3.6383568496563803

Epoch: 6| Step: 10
Training loss: 3.9698078818162315
Validation loss: 3.6296776071261907

Epoch: 6| Step: 11
Training loss: 2.938373679239115
Validation loss: 3.628143724595634

Epoch: 6| Step: 12
Training loss: 4.3896285585965344
Validation loss: 3.623714186446114

Epoch: 6| Step: 13
Training loss: 3.5555680410510297
Validation loss: 3.618514014128037

Epoch: 15| Step: 0
Training loss: 3.2655671767084664
Validation loss: 3.6172269581011545

Epoch: 6| Step: 1
Training loss: 3.7827797309625306
Validation loss: 3.6114055346816833

Epoch: 6| Step: 2
Training loss: 4.262418219265648
Validation loss: 3.6083747277856086

Epoch: 6| Step: 3
Training loss: 3.2671588416646475
Validation loss: 3.6063867806591916

Epoch: 6| Step: 4
Training loss: 3.048856276895972
Validation loss: 3.6058273847216786

Epoch: 6| Step: 5
Training loss: 4.691667255697445
Validation loss: 3.603689685798115

Epoch: 6| Step: 6
Training loss: 3.8227796954460445
Validation loss: 3.5956768710851263

Epoch: 6| Step: 7
Training loss: 4.1056569035440775
Validation loss: 3.5945326899337493

Epoch: 6| Step: 8
Training loss: 3.6183580519014775
Validation loss: 3.593974102464304

Epoch: 6| Step: 9
Training loss: 3.573972733165729
Validation loss: 3.590193254539523

Epoch: 6| Step: 10
Training loss: 3.999732485408741
Validation loss: 3.588051958453885

Epoch: 6| Step: 11
Training loss: 4.055503101677379
Validation loss: 3.5824870970218097

Epoch: 6| Step: 12
Training loss: 3.5076890681582586
Validation loss: 3.5783549613403527

Epoch: 6| Step: 13
Training loss: 3.8304921830464402
Validation loss: 3.5750022394810212

Epoch: 16| Step: 0
Training loss: 4.748812276015648
Validation loss: 3.571440512172819

Epoch: 6| Step: 1
Training loss: 3.1354126449677455
Validation loss: 3.564968584419846

Epoch: 6| Step: 2
Training loss: 3.338375871006098
Validation loss: 3.563882751905443

Epoch: 6| Step: 3
Training loss: 3.976886728555116
Validation loss: 3.567479906463415

Epoch: 6| Step: 4
Training loss: 3.3348903039738165
Validation loss: 3.5630862464821034

Epoch: 6| Step: 5
Training loss: 3.3620696859586636
Validation loss: 3.5579672832316005

Epoch: 6| Step: 6
Training loss: 3.9392642957967
Validation loss: 3.551880580470882

Epoch: 6| Step: 7
Training loss: 4.229874925861016
Validation loss: 3.5522907588535535

Epoch: 6| Step: 8
Training loss: 3.361597931410867
Validation loss: 3.5504562399034523

Epoch: 6| Step: 9
Training loss: 4.473431249381657
Validation loss: 3.551018639271233

Epoch: 6| Step: 10
Training loss: 3.2049123847876153
Validation loss: 3.5450972159766008

Epoch: 6| Step: 11
Training loss: 3.909611346741305
Validation loss: 3.540936599755614

Epoch: 6| Step: 12
Training loss: 3.9628065165190343
Validation loss: 3.5349409637137352

Epoch: 6| Step: 13
Training loss: 2.694493708427815
Validation loss: 3.531351866810514

Epoch: 17| Step: 0
Training loss: 3.7341612431467572
Validation loss: 3.5321760343679136

Epoch: 6| Step: 1
Training loss: 3.5492685450949177
Validation loss: 3.5273483098819085

Epoch: 6| Step: 2
Training loss: 3.450196418146582
Validation loss: 3.5199595677360023

Epoch: 6| Step: 3
Training loss: 4.5287664513285195
Validation loss: 3.513371488363945

Epoch: 6| Step: 4
Training loss: 3.530179832135581
Validation loss: 3.5146623751523727

Epoch: 6| Step: 5
Training loss: 2.6583391837251993
Validation loss: 3.5122846573365134

Epoch: 6| Step: 6
Training loss: 3.2972028668706894
Validation loss: 3.510322245036401

Epoch: 6| Step: 7
Training loss: 3.848726849785239
Validation loss: 3.5092304312055824

Epoch: 6| Step: 8
Training loss: 4.027465936858882
Validation loss: 3.5088705922717325

Epoch: 6| Step: 9
Training loss: 4.154529875268328
Validation loss: 3.5002858913871515

Epoch: 6| Step: 10
Training loss: 3.50573750658658
Validation loss: 3.491048760766731

Epoch: 6| Step: 11
Training loss: 4.188621712373323
Validation loss: 3.484137230979921

Epoch: 6| Step: 12
Training loss: 2.660910164854504
Validation loss: 3.4819891002781973

Epoch: 6| Step: 13
Training loss: 4.8428751493843425
Validation loss: 3.4765693490270975

Epoch: 18| Step: 0
Training loss: 3.3290451282251006
Validation loss: 3.4723752334406406

Epoch: 6| Step: 1
Training loss: 4.550107665412512
Validation loss: 3.4627615940336884

Epoch: 6| Step: 2
Training loss: 3.161065233773326
Validation loss: 3.459359903353857

Epoch: 6| Step: 3
Training loss: 3.0548070703700123
Validation loss: 3.454080682813913

Epoch: 6| Step: 4
Training loss: 2.521408729984605
Validation loss: 3.4522204873989675

Epoch: 6| Step: 5
Training loss: 3.234157389078952
Validation loss: 3.4456969674413624

Epoch: 6| Step: 6
Training loss: 4.3866952706962925
Validation loss: 3.441759798912805

Epoch: 6| Step: 7
Training loss: 4.730058874364679
Validation loss: 3.4338134133891036

Epoch: 6| Step: 8
Training loss: 3.68330403196898
Validation loss: 3.432470448301044

Epoch: 6| Step: 9
Training loss: 3.14651726031271
Validation loss: 3.427664437118224

Epoch: 6| Step: 10
Training loss: 3.885603394849432
Validation loss: 3.429888265657719

Epoch: 6| Step: 11
Training loss: 3.334488922718506
Validation loss: 3.4189799531447798

Epoch: 6| Step: 12
Training loss: 3.2297194141127004
Validation loss: 3.4184095502890073

Epoch: 6| Step: 13
Training loss: 4.628393217218408
Validation loss: 3.4195898883255125

Epoch: 19| Step: 0
Training loss: 3.3590930909149597
Validation loss: 3.4188118529820484

Epoch: 6| Step: 1
Training loss: 3.9163922288127355
Validation loss: 3.416648514041855

Epoch: 6| Step: 2
Training loss: 3.687593103300283
Validation loss: 3.410789512232781

Epoch: 6| Step: 3
Training loss: 3.2950718002716286
Validation loss: 3.409110466884522

Epoch: 6| Step: 4
Training loss: 3.8060589772163693
Validation loss: 3.4042044687355557

Epoch: 6| Step: 5
Training loss: 3.942156263810553
Validation loss: 3.401053070851765

Epoch: 6| Step: 6
Training loss: 3.682280127234321
Validation loss: 3.3976682145639363

Epoch: 6| Step: 7
Training loss: 4.472487800457833
Validation loss: 3.39599086492463

Epoch: 6| Step: 8
Training loss: 3.292180628830484
Validation loss: 3.390394967898733

Epoch: 6| Step: 9
Training loss: 3.0605509258309183
Validation loss: 3.3882384517130752

Epoch: 6| Step: 10
Training loss: 2.7750916611937964
Validation loss: 3.3856559291501336

Epoch: 6| Step: 11
Training loss: 4.151824200945488
Validation loss: 3.3849982041684252

Epoch: 6| Step: 12
Training loss: 2.8781666109637065
Validation loss: 3.3853080809085614

Epoch: 6| Step: 13
Training loss: 4.292066734456414
Validation loss: 3.380216857534352

Epoch: 20| Step: 0
Training loss: 3.61079068514754
Validation loss: 3.379227215413969

Epoch: 6| Step: 1
Training loss: 3.1053383853828125
Validation loss: 3.377915847470536

Epoch: 6| Step: 2
Training loss: 3.8357705509192432
Validation loss: 3.3744466366709784

Epoch: 6| Step: 3
Training loss: 3.9127087717144216
Validation loss: 3.3707730642384575

Epoch: 6| Step: 4
Training loss: 3.1626695368862583
Validation loss: 3.3656315152609495

Epoch: 6| Step: 5
Training loss: 4.75574166467523
Validation loss: 3.3623435394571026

Epoch: 6| Step: 6
Training loss: 3.7306537043073833
Validation loss: 3.360800347001326

Epoch: 6| Step: 7
Training loss: 4.111498845921006
Validation loss: 3.3557291625209142

Epoch: 6| Step: 8
Training loss: 3.115236517926379
Validation loss: 3.3498426149706613

Epoch: 6| Step: 9
Training loss: 3.366517179462582
Validation loss: 3.3454033857358367

Epoch: 6| Step: 10
Training loss: 3.236393248156637
Validation loss: 3.342836852000005

Epoch: 6| Step: 11
Training loss: 2.672218523752143
Validation loss: 3.339955684674162

Epoch: 6| Step: 12
Training loss: 3.604735724594112
Validation loss: 3.341640841865274

Epoch: 6| Step: 13
Training loss: 3.5957795093054603
Validation loss: 3.337921040865974

Epoch: 21| Step: 0
Training loss: 3.1412131294973853
Validation loss: 3.3386184237925582

Epoch: 6| Step: 1
Training loss: 3.9245869656114096
Validation loss: 3.3346943742823205

Epoch: 6| Step: 2
Training loss: 3.5429236631037604
Validation loss: 3.330750612824559

Epoch: 6| Step: 3
Training loss: 3.4482668019866307
Validation loss: 3.325190410640818

Epoch: 6| Step: 4
Training loss: 3.5095161769660956
Validation loss: 3.324201276083102

Epoch: 6| Step: 5
Training loss: 3.906194091396776
Validation loss: 3.332792697153044

Epoch: 6| Step: 6
Training loss: 3.22280539427608
Validation loss: 3.3129957806713652

Epoch: 6| Step: 7
Training loss: 3.5697614048318074
Validation loss: 3.3108578041928496

Epoch: 6| Step: 8
Training loss: 3.5534494109336148
Validation loss: 3.3085668519915115

Epoch: 6| Step: 9
Training loss: 3.2829730641436243
Validation loss: 3.310994803675944

Epoch: 6| Step: 10
Training loss: 3.5514782849861306
Validation loss: 3.310265170871144

Epoch: 6| Step: 11
Training loss: 3.820916562992138
Validation loss: 3.30022763019989

Epoch: 6| Step: 12
Training loss: 3.8434306686617323
Validation loss: 3.3024917701377134

Epoch: 6| Step: 13
Training loss: 3.2407638181641794
Validation loss: 3.2979029273950675

Epoch: 22| Step: 0
Training loss: 2.856129122457167
Validation loss: 3.29801860197791

Epoch: 6| Step: 1
Training loss: 2.7669202282390573
Validation loss: 3.3015416363088153

Epoch: 6| Step: 2
Training loss: 3.824401040647038
Validation loss: 3.2961279524203775

Epoch: 6| Step: 3
Training loss: 3.6124663882688335
Validation loss: 3.294439210211825

Epoch: 6| Step: 4
Training loss: 3.750212599767783
Validation loss: 3.289551248457395

Epoch: 6| Step: 5
Training loss: 3.421163127829013
Validation loss: 3.282807392601091

Epoch: 6| Step: 6
Training loss: 3.698121888103146
Validation loss: 3.2767242128059646

Epoch: 6| Step: 7
Training loss: 3.6462220484277186
Validation loss: 3.272439152685011

Epoch: 6| Step: 8
Training loss: 3.50881882401969
Validation loss: 3.268285808097738

Epoch: 6| Step: 9
Training loss: 3.2062768827207413
Validation loss: 3.2609098055548587

Epoch: 6| Step: 10
Training loss: 4.107307407091967
Validation loss: 3.2564172439119856

Epoch: 6| Step: 11
Training loss: 3.394362398256592
Validation loss: 3.25636875632872

Epoch: 6| Step: 12
Training loss: 3.9413864089874737
Validation loss: 3.2551362191692883

Epoch: 6| Step: 13
Training loss: 3.0140659868171737
Validation loss: 3.2499707223032557

Epoch: 23| Step: 0
Training loss: 2.3920706572797856
Validation loss: 3.2486807557034028

Epoch: 6| Step: 1
Training loss: 2.95091156534168
Validation loss: 3.247432232336396

Epoch: 6| Step: 2
Training loss: 3.8650590684332404
Validation loss: 3.2457367312101897

Epoch: 6| Step: 3
Training loss: 3.671719162251562
Validation loss: 3.249110552141974

Epoch: 6| Step: 4
Training loss: 3.6587427233176273
Validation loss: 3.2542101643973034

Epoch: 6| Step: 5
Training loss: 3.497918054710296
Validation loss: 3.248684223151203

Epoch: 6| Step: 6
Training loss: 3.5135992698950087
Validation loss: 3.2375701313893304

Epoch: 6| Step: 7
Training loss: 3.5007749789419536
Validation loss: 3.231645469610183

Epoch: 6| Step: 8
Training loss: 3.857668232837178
Validation loss: 3.226610423262063

Epoch: 6| Step: 9
Training loss: 3.295292189613722
Validation loss: 3.2249407921879487

Epoch: 6| Step: 10
Training loss: 3.6702811170383636
Validation loss: 3.2290806568664627

Epoch: 6| Step: 11
Training loss: 3.33626124220405
Validation loss: 3.2227265687332665

Epoch: 6| Step: 12
Training loss: 3.2455691431250044
Validation loss: 3.2225019532496586

Epoch: 6| Step: 13
Training loss: 4.4369693492546896
Validation loss: 3.219962366727886

Epoch: 24| Step: 0
Training loss: 3.3206588743963783
Validation loss: 3.217296926654716

Epoch: 6| Step: 1
Training loss: 2.9286316456734602
Validation loss: 3.215936278581106

Epoch: 6| Step: 2
Training loss: 4.260849735599737
Validation loss: 3.214701278050069

Epoch: 6| Step: 3
Training loss: 4.0948568696845955
Validation loss: 3.2103233739140338

Epoch: 6| Step: 4
Training loss: 3.5141215860938257
Validation loss: 3.2106490027918477

Epoch: 6| Step: 5
Training loss: 3.4732848071651956
Validation loss: 3.2063557272822316

Epoch: 6| Step: 6
Training loss: 3.3404354887432817
Validation loss: 3.208078246143273

Epoch: 6| Step: 7
Training loss: 3.881281406932799
Validation loss: 3.206611881567967

Epoch: 6| Step: 8
Training loss: 2.97191250654073
Validation loss: 3.204069586657916

Epoch: 6| Step: 9
Training loss: 3.0587586885803564
Validation loss: 3.2018248978191792

Epoch: 6| Step: 10
Training loss: 3.204311244234361
Validation loss: 3.2002123804525433

Epoch: 6| Step: 11
Training loss: 3.230469340424674
Validation loss: 3.1996990603919246

Epoch: 6| Step: 12
Training loss: 3.274822952493497
Validation loss: 3.1968259152042804

Epoch: 6| Step: 13
Training loss: 3.783751613892588
Validation loss: 3.1951085054177892

Epoch: 25| Step: 0
Training loss: 3.43016629363679
Validation loss: 3.1954906999721464

Epoch: 6| Step: 1
Training loss: 3.6814723778283844
Validation loss: 3.1916451056451565

Epoch: 6| Step: 2
Training loss: 2.786007530372011
Validation loss: 3.1930944725182773

Epoch: 6| Step: 3
Training loss: 3.682939975039128
Validation loss: 3.1893229233330116

Epoch: 6| Step: 4
Training loss: 4.275742824332294
Validation loss: 3.1887674564396313

Epoch: 6| Step: 5
Training loss: 3.456639499342963
Validation loss: 3.187083051975474

Epoch: 6| Step: 6
Training loss: 2.996821468062118
Validation loss: 3.185637415452195

Epoch: 6| Step: 7
Training loss: 4.297864987162344
Validation loss: 3.185090238477952

Epoch: 6| Step: 8
Training loss: 3.0174494941233
Validation loss: 3.1829599697461397

Epoch: 6| Step: 9
Training loss: 2.9143128479300833
Validation loss: 3.181978330349406

Epoch: 6| Step: 10
Training loss: 3.4949990375391953
Validation loss: 3.1779115648669336

Epoch: 6| Step: 11
Training loss: 3.0046884140989247
Validation loss: 3.1773756974305054

Epoch: 6| Step: 12
Training loss: 3.13470143285132
Validation loss: 3.177211864715225

Epoch: 6| Step: 13
Training loss: 3.832785249310739
Validation loss: 3.1722499662754147

Epoch: 26| Step: 0
Training loss: 3.470953439112841
Validation loss: 3.1727804801693162

Epoch: 6| Step: 1
Training loss: 3.239037290880781
Validation loss: 3.17114034474065

Epoch: 6| Step: 2
Training loss: 3.017660768235223
Validation loss: 3.1687981216955547

Epoch: 6| Step: 3
Training loss: 3.5192754485287434
Validation loss: 3.1729378824089824

Epoch: 6| Step: 4
Training loss: 3.8950328446498212
Validation loss: 3.1771854722449087

Epoch: 6| Step: 5
Training loss: 2.8214656765310426
Validation loss: 3.170088610029335

Epoch: 6| Step: 6
Training loss: 3.4986969020639966
Validation loss: 3.160285007973913

Epoch: 6| Step: 7
Training loss: 3.483355454248402
Validation loss: 3.158603946647753

Epoch: 6| Step: 8
Training loss: 3.612550337813621
Validation loss: 3.151512412808492

Epoch: 6| Step: 9
Training loss: 3.388528061159395
Validation loss: 3.1505828113824395

Epoch: 6| Step: 10
Training loss: 3.7200881730161517
Validation loss: 3.1454450776125884

Epoch: 6| Step: 11
Training loss: 3.0360943339974864
Validation loss: 3.1449427809325146

Epoch: 6| Step: 12
Training loss: 3.444035369071155
Validation loss: 3.144351727408112

Epoch: 6| Step: 13
Training loss: 3.780569976946061
Validation loss: 3.1453235172096528

Epoch: 27| Step: 0
Training loss: 3.137413090569826
Validation loss: 3.1449875232747653

Epoch: 6| Step: 1
Training loss: 2.7452253159567563
Validation loss: 3.1468269350746745

Epoch: 6| Step: 2
Training loss: 2.8238039675043503
Validation loss: 3.1429565816081833

Epoch: 6| Step: 3
Training loss: 3.559437824394805
Validation loss: 3.1372911053680763

Epoch: 6| Step: 4
Training loss: 3.5022707793483705
Validation loss: 3.134607859064067

Epoch: 6| Step: 5
Training loss: 3.7967310748666936
Validation loss: 3.1320903777334506

Epoch: 6| Step: 6
Training loss: 3.203176209575403
Validation loss: 3.1293743027679866

Epoch: 6| Step: 7
Training loss: 3.753147838564332
Validation loss: 3.131907046248422

Epoch: 6| Step: 8
Training loss: 3.9043636802923265
Validation loss: 3.127484059098782

Epoch: 6| Step: 9
Training loss: 3.396263391765297
Validation loss: 3.129027369990885

Epoch: 6| Step: 10
Training loss: 3.4014776553084967
Validation loss: 3.128014435921995

Epoch: 6| Step: 11
Training loss: 3.6897822930433377
Validation loss: 3.1237149867777507

Epoch: 6| Step: 12
Training loss: 3.1149205734389134
Validation loss: 3.121722792188487

Epoch: 6| Step: 13
Training loss: 3.505285359519273
Validation loss: 3.120901687915984

Epoch: 28| Step: 0
Training loss: 3.466851617085406
Validation loss: 3.115366450245703

Epoch: 6| Step: 1
Training loss: 3.242885872873861
Validation loss: 3.110886991344263

Epoch: 6| Step: 2
Training loss: 3.8217932828836685
Validation loss: 3.1092518949922647

Epoch: 6| Step: 3
Training loss: 3.060242112498515
Validation loss: 3.108104310746084

Epoch: 6| Step: 4
Training loss: 3.7348249475599276
Validation loss: 3.100841280178875

Epoch: 6| Step: 5
Training loss: 3.239454031732208
Validation loss: 3.100969914205696

Epoch: 6| Step: 6
Training loss: 4.155257027545447
Validation loss: 3.098615626826777

Epoch: 6| Step: 7
Training loss: 3.055355223436685
Validation loss: 3.0963372675154592

Epoch: 6| Step: 8
Training loss: 2.9064258809347243
Validation loss: 3.095123642355172

Epoch: 6| Step: 9
Training loss: 3.146126402957101
Validation loss: 3.0915078202082538

Epoch: 6| Step: 10
Training loss: 3.009694489090807
Validation loss: 3.0911257856763057

Epoch: 6| Step: 11
Training loss: 3.541009161259958
Validation loss: 3.089207154192482

Epoch: 6| Step: 12
Training loss: 3.433068488069298
Validation loss: 3.0872744776089402

Epoch: 6| Step: 13
Training loss: 3.1479550884198613
Validation loss: 3.089403246272385

Epoch: 29| Step: 0
Training loss: 3.1699797882976055
Validation loss: 3.0857260869813983

Epoch: 6| Step: 1
Training loss: 3.602949756552565
Validation loss: 3.082793529144376

Epoch: 6| Step: 2
Training loss: 2.9162985069796137
Validation loss: 3.0800375087053813

Epoch: 6| Step: 3
Training loss: 4.023866263941063
Validation loss: 3.0772935206423635

Epoch: 6| Step: 4
Training loss: 3.1033464581314116
Validation loss: 3.0773240129918973

Epoch: 6| Step: 5
Training loss: 3.243246250323027
Validation loss: 3.077313242983932

Epoch: 6| Step: 6
Training loss: 3.6478080124779644
Validation loss: 3.080198990224587

Epoch: 6| Step: 7
Training loss: 3.0961237576513105
Validation loss: 3.078634790065311

Epoch: 6| Step: 8
Training loss: 3.5476447123071306
Validation loss: 3.073351026189638

Epoch: 6| Step: 9
Training loss: 3.364248599633612
Validation loss: 3.073707139904728

Epoch: 6| Step: 10
Training loss: 3.009959537069381
Validation loss: 3.072045238997253

Epoch: 6| Step: 11
Training loss: 2.908383150594017
Validation loss: 3.071836935028297

Epoch: 6| Step: 12
Training loss: 3.485131972672392
Validation loss: 3.0675770896747463

Epoch: 6| Step: 13
Training loss: 3.925577186860551
Validation loss: 3.0662785069981986

Epoch: 30| Step: 0
Training loss: 2.6315294529627256
Validation loss: 3.064214909769411

Epoch: 6| Step: 1
Training loss: 3.447964640088665
Validation loss: 3.0655022530088334

Epoch: 6| Step: 2
Training loss: 3.4076076216855045
Validation loss: 3.0664529107523175

Epoch: 6| Step: 3
Training loss: 3.664077335807518
Validation loss: 3.063489913421001

Epoch: 6| Step: 4
Training loss: 3.5351125472091476
Validation loss: 3.061397106952104

Epoch: 6| Step: 5
Training loss: 3.353226397599716
Validation loss: 3.060517227378235

Epoch: 6| Step: 6
Training loss: 3.5622111420893057
Validation loss: 3.0584843400592194

Epoch: 6| Step: 7
Training loss: 3.7681602712509434
Validation loss: 3.059342236976981

Epoch: 6| Step: 8
Training loss: 3.5209340338818143
Validation loss: 3.055656365688986

Epoch: 6| Step: 9
Training loss: 2.77756951081159
Validation loss: 3.055225165644069

Epoch: 6| Step: 10
Training loss: 3.7004812597762307
Validation loss: 3.055257870245922

Epoch: 6| Step: 11
Training loss: 2.758257692189219
Validation loss: 3.0525549866076886

Epoch: 6| Step: 12
Training loss: 3.1541673190789363
Validation loss: 3.0565824144902516

Epoch: 6| Step: 13
Training loss: 3.2183517654130815
Validation loss: 3.0597817330260497

Epoch: 31| Step: 0
Training loss: 3.7012581928424027
Validation loss: 3.0520737269280223

Epoch: 6| Step: 1
Training loss: 4.0873355844076995
Validation loss: 3.0501699161924933

Epoch: 6| Step: 2
Training loss: 2.610051963844261
Validation loss: 3.0482911753620687

Epoch: 6| Step: 3
Training loss: 3.362708562459375
Validation loss: 3.047577962460177

Epoch: 6| Step: 4
Training loss: 2.814031734859677
Validation loss: 3.047635898285079

Epoch: 6| Step: 5
Training loss: 2.5102082689667142
Validation loss: 3.0471946613831515

Epoch: 6| Step: 6
Training loss: 3.789955647392737
Validation loss: 3.053293259564528

Epoch: 6| Step: 7
Training loss: 3.304676678146066
Validation loss: 3.0487703875742795

Epoch: 6| Step: 8
Training loss: 3.8929674075447966
Validation loss: 3.041848429397229

Epoch: 6| Step: 9
Training loss: 3.8718709309874453
Validation loss: 3.042901320515136

Epoch: 6| Step: 10
Training loss: 2.649331991103507
Validation loss: 3.0391424535351543

Epoch: 6| Step: 11
Training loss: 3.1282722126012006
Validation loss: 3.039023577754606

Epoch: 6| Step: 12
Training loss: 3.536189178127129
Validation loss: 3.040452693544246

Epoch: 6| Step: 13
Training loss: 2.526082073294874
Validation loss: 3.0411869372564837

Epoch: 32| Step: 0
Training loss: 3.278775253751287
Validation loss: 3.0420645165501337

Epoch: 6| Step: 1
Training loss: 4.225019755119773
Validation loss: 3.041047938673861

Epoch: 6| Step: 2
Training loss: 3.1372142889629084
Validation loss: 3.0403739945741926

Epoch: 6| Step: 3
Training loss: 3.2703867969922027
Validation loss: 3.03878942133132

Epoch: 6| Step: 4
Training loss: 3.645304672422479
Validation loss: 3.039297553110182

Epoch: 6| Step: 5
Training loss: 3.3663348824458157
Validation loss: 3.0378755893695506

Epoch: 6| Step: 6
Training loss: 3.487716919637177
Validation loss: 3.0357010079397924

Epoch: 6| Step: 7
Training loss: 3.35438003019379
Validation loss: 3.0330389697996223

Epoch: 6| Step: 8
Training loss: 3.293545311606399
Validation loss: 3.0332774756759684

Epoch: 6| Step: 9
Training loss: 2.193558939468655
Validation loss: 3.0321441539321774

Epoch: 6| Step: 10
Training loss: 2.2411947677793607
Validation loss: 3.0334899866851

Epoch: 6| Step: 11
Training loss: 3.9288253900259424
Validation loss: 3.032268231788753

Epoch: 6| Step: 12
Training loss: 3.7469085666403306
Validation loss: 3.0324744510831474

Epoch: 6| Step: 13
Training loss: 2.2417515985596563
Validation loss: 3.0320253183049846

Epoch: 33| Step: 0
Training loss: 3.374805727418238
Validation loss: 3.030244638347921

Epoch: 6| Step: 1
Training loss: 2.936303889469044
Validation loss: 3.025082151185112

Epoch: 6| Step: 2
Training loss: 3.5575520469949047
Validation loss: 3.027663669942871

Epoch: 6| Step: 3
Training loss: 3.3040254258847006
Validation loss: 3.028802306121172

Epoch: 6| Step: 4
Training loss: 3.0653162871765267
Validation loss: 3.0238711829426417

Epoch: 6| Step: 5
Training loss: 2.1718537034561765
Validation loss: 3.0239873379096465

Epoch: 6| Step: 6
Training loss: 2.817232685287418
Validation loss: 3.0226120229573263

Epoch: 6| Step: 7
Training loss: 2.69455715044226
Validation loss: 3.026848990731282

Epoch: 6| Step: 8
Training loss: 3.9070665650429808
Validation loss: 3.0207291146286104

Epoch: 6| Step: 9
Training loss: 3.5581059713037417
Validation loss: 3.020801678252285

Epoch: 6| Step: 10
Training loss: 3.594921949279446
Validation loss: 3.019278572949981

Epoch: 6| Step: 11
Training loss: 4.170247992956043
Validation loss: 3.0169057352147908

Epoch: 6| Step: 12
Training loss: 3.6819812404604315
Validation loss: 3.0143345235156698

Epoch: 6| Step: 13
Training loss: 2.728623013304801
Validation loss: 3.014995148937029

Epoch: 34| Step: 0
Training loss: 3.8139648124939987
Validation loss: 3.0141893510558178

Epoch: 6| Step: 1
Training loss: 2.9339048421311595
Validation loss: 3.010731899684854

Epoch: 6| Step: 2
Training loss: 3.1011821215703312
Validation loss: 3.011500456474644

Epoch: 6| Step: 3
Training loss: 3.999456607148754
Validation loss: 3.015830196485332

Epoch: 6| Step: 4
Training loss: 3.5474522326790603
Validation loss: 3.01754479792576

Epoch: 6| Step: 5
Training loss: 3.027038165020427
Validation loss: 3.0116406851400384

Epoch: 6| Step: 6
Training loss: 2.433260238107001
Validation loss: 3.0100472202943545

Epoch: 6| Step: 7
Training loss: 3.240723060882621
Validation loss: 3.0113154481599254

Epoch: 6| Step: 8
Training loss: 3.785164060476333
Validation loss: 3.005158960319251

Epoch: 6| Step: 9
Training loss: 3.5442423860229066
Validation loss: 3.0086842857129916

Epoch: 6| Step: 10
Training loss: 2.8423493677385423
Validation loss: 3.008406314050401

Epoch: 6| Step: 11
Training loss: 3.534656468254274
Validation loss: 3.0052395249559725

Epoch: 6| Step: 12
Training loss: 2.5443225075749516
Validation loss: 3.008592958359384

Epoch: 6| Step: 13
Training loss: 3.5659307724870266
Validation loss: 3.0081936604720974

Epoch: 35| Step: 0
Training loss: 3.521099930701323
Validation loss: 3.0055285924530595

Epoch: 6| Step: 1
Training loss: 2.850041733821013
Validation loss: 2.999562592219958

Epoch: 6| Step: 2
Training loss: 3.469375553945402
Validation loss: 2.9987090334289634

Epoch: 6| Step: 3
Training loss: 3.5093789458146505
Validation loss: 2.9929792535316353

Epoch: 6| Step: 4
Training loss: 2.933315787118395
Validation loss: 2.9953572758975975

Epoch: 6| Step: 5
Training loss: 2.910449204004735
Validation loss: 2.9979465457276424

Epoch: 6| Step: 6
Training loss: 3.495860785708813
Validation loss: 2.993827711911244

Epoch: 6| Step: 7
Training loss: 3.0855258329055264
Validation loss: 2.989840998305445

Epoch: 6| Step: 8
Training loss: 3.7396576997097655
Validation loss: 2.998852182070362

Epoch: 6| Step: 9
Training loss: 3.3160587124199576
Validation loss: 2.9903679898086604

Epoch: 6| Step: 10
Training loss: 3.1417788383500205
Validation loss: 2.987145765779385

Epoch: 6| Step: 11
Training loss: 3.514291468005283
Validation loss: 2.988225588198692

Epoch: 6| Step: 12
Training loss: 3.417826726960052
Validation loss: 2.9945525511114126

Epoch: 6| Step: 13
Training loss: 2.701546003866053
Validation loss: 2.988643472063725

Epoch: 36| Step: 0
Training loss: 3.4504911985264357
Validation loss: 2.9849408599043032

Epoch: 6| Step: 1
Training loss: 3.5169272490464527
Validation loss: 2.9814955204576306

Epoch: 6| Step: 2
Training loss: 2.7517429377126534
Validation loss: 2.9783958340229946

Epoch: 6| Step: 3
Training loss: 2.9605245579050656
Validation loss: 2.9730092658415517

Epoch: 6| Step: 4
Training loss: 3.6572753251088304
Validation loss: 2.9747636853713315

Epoch: 6| Step: 5
Training loss: 3.073275235910246
Validation loss: 2.970835617088254

Epoch: 6| Step: 6
Training loss: 2.9381133717475403
Validation loss: 2.9798941371955285

Epoch: 6| Step: 7
Training loss: 3.8091300704111624
Validation loss: 2.972157881653106

Epoch: 6| Step: 8
Training loss: 3.3145178640738457
Validation loss: 2.972285408951024

Epoch: 6| Step: 9
Training loss: 2.494818276493711
Validation loss: 2.971302469273362

Epoch: 6| Step: 10
Training loss: 2.9494227862988494
Validation loss: 2.9761870996951214

Epoch: 6| Step: 11
Training loss: 3.2140516044495073
Validation loss: 2.9795778023688397

Epoch: 6| Step: 12
Training loss: 3.4527198243096215
Validation loss: 2.987366286917141

Epoch: 6| Step: 13
Training loss: 4.406756432831384
Validation loss: 2.9749759709983814

Epoch: 37| Step: 0
Training loss: 3.025800703022124
Validation loss: 2.9702570804739232

Epoch: 6| Step: 1
Training loss: 2.7311585609615427
Validation loss: 2.9715447026603434

Epoch: 6| Step: 2
Training loss: 3.442024998026036
Validation loss: 2.966693149670589

Epoch: 6| Step: 3
Training loss: 3.068529072129496
Validation loss: 2.971285311577234

Epoch: 6| Step: 4
Training loss: 3.254555370708992
Validation loss: 2.977493556944103

Epoch: 6| Step: 5
Training loss: 3.2913937676856535
Validation loss: 2.9736208255017766

Epoch: 6| Step: 6
Training loss: 3.799960166320826
Validation loss: 2.967334129463144

Epoch: 6| Step: 7
Training loss: 3.814071456479844
Validation loss: 2.9642428490218684

Epoch: 6| Step: 8
Training loss: 3.377188361619529
Validation loss: 2.96565185266392

Epoch: 6| Step: 9
Training loss: 3.6721748391956477
Validation loss: 2.961048421660646

Epoch: 6| Step: 10
Training loss: 3.059948851214003
Validation loss: 2.962444332727014

Epoch: 6| Step: 11
Training loss: 2.994192542256182
Validation loss: 2.9590365417402387

Epoch: 6| Step: 12
Training loss: 2.8535074368358737
Validation loss: 2.9606375004811314

Epoch: 6| Step: 13
Training loss: 3.070045051865428
Validation loss: 2.9584165339286344

Epoch: 38| Step: 0
Training loss: 3.2379161964867453
Validation loss: 2.9667479503824996

Epoch: 6| Step: 1
Training loss: 3.449284553980169
Validation loss: 2.9601372454962656

Epoch: 6| Step: 2
Training loss: 3.1813555566928677
Validation loss: 2.9623196764150426

Epoch: 6| Step: 3
Training loss: 2.0146601533757136
Validation loss: 2.962261225600922

Epoch: 6| Step: 4
Training loss: 3.848998789215492
Validation loss: 2.9599873224428714

Epoch: 6| Step: 5
Training loss: 3.2840613537538736
Validation loss: 2.9549791807091563

Epoch: 6| Step: 6
Training loss: 3.282629395234857
Validation loss: 2.9586402864386114

Epoch: 6| Step: 7
Training loss: 2.7501159990294366
Validation loss: 2.9531113515255156

Epoch: 6| Step: 8
Training loss: 3.386444186264491
Validation loss: 2.9471075374569775

Epoch: 6| Step: 9
Training loss: 3.6187506114056585
Validation loss: 2.950383387062649

Epoch: 6| Step: 10
Training loss: 2.6604558521114265
Validation loss: 2.9494480625497084

Epoch: 6| Step: 11
Training loss: 3.542276905817815
Validation loss: 2.946187175157285

Epoch: 6| Step: 12
Training loss: 3.6903574588972377
Validation loss: 2.9475412582316354

Epoch: 6| Step: 13
Training loss: 3.2554116310215115
Validation loss: 2.9450802696661484

Epoch: 39| Step: 0
Training loss: 3.417456434819136
Validation loss: 2.9461529613190436

Epoch: 6| Step: 1
Training loss: 3.2581040505782703
Validation loss: 2.944085580734433

Epoch: 6| Step: 2
Training loss: 3.5747519507085017
Validation loss: 2.947243584988149

Epoch: 6| Step: 3
Training loss: 3.0699298028034168
Validation loss: 2.945018875641267

Epoch: 6| Step: 4
Training loss: 2.568182529409468
Validation loss: 2.9463728752566736

Epoch: 6| Step: 5
Training loss: 2.5850256842217134
Validation loss: 2.957986762547041

Epoch: 6| Step: 6
Training loss: 3.4467450751185535
Validation loss: 2.95783392229187

Epoch: 6| Step: 7
Training loss: 3.0372519309389183
Validation loss: 2.9563603515675

Epoch: 6| Step: 8
Training loss: 3.8819127105222573
Validation loss: 2.9532230133269963

Epoch: 6| Step: 9
Training loss: 3.7409618815560486
Validation loss: 2.9504186075664425

Epoch: 6| Step: 10
Training loss: 2.8414307243713277
Validation loss: 2.953657744725631

Epoch: 6| Step: 11
Training loss: 3.7579338070012267
Validation loss: 2.9570569293721434

Epoch: 6| Step: 12
Training loss: 2.97845655038753
Validation loss: 2.9519324563410576

Epoch: 6| Step: 13
Training loss: 2.811389110307078
Validation loss: 2.952995174601551

Epoch: 40| Step: 0
Training loss: 3.525198688724213
Validation loss: 2.9548202504175527

Epoch: 6| Step: 1
Training loss: 3.5614882253794695
Validation loss: 2.947758368206033

Epoch: 6| Step: 2
Training loss: 3.0732238788380597
Validation loss: 2.942352068337248

Epoch: 6| Step: 3
Training loss: 3.645976181864822
Validation loss: 2.943539870234794

Epoch: 6| Step: 4
Training loss: 2.8727026343523687
Validation loss: 2.9472882041418806

Epoch: 6| Step: 5
Training loss: 3.8408086423990007
Validation loss: 2.9547649534494487

Epoch: 6| Step: 6
Training loss: 3.2670598870361953
Validation loss: 2.9476905236547517

Epoch: 6| Step: 7
Training loss: 3.077513348374598
Validation loss: 2.9439811780016014

Epoch: 6| Step: 8
Training loss: 2.788381113971935
Validation loss: 2.945265981237688

Epoch: 6| Step: 9
Training loss: 3.4923871215841515
Validation loss: 2.9443378138632705

Epoch: 6| Step: 10
Training loss: 2.7681721310318625
Validation loss: 2.947076759943161

Epoch: 6| Step: 11
Training loss: 3.3962878213685266
Validation loss: 2.9438341001803603

Epoch: 6| Step: 12
Training loss: 2.940087497732632
Validation loss: 2.9418367617366195

Epoch: 6| Step: 13
Training loss: 2.899864811870378
Validation loss: 2.9399222827043086

Epoch: 41| Step: 0
Training loss: 2.6070681671372893
Validation loss: 2.937661946932999

Epoch: 6| Step: 1
Training loss: 2.917821673627742
Validation loss: 2.937655266555293

Epoch: 6| Step: 2
Training loss: 3.078822023120016
Validation loss: 2.9401105418186506

Epoch: 6| Step: 3
Training loss: 3.8897968927623148
Validation loss: 2.939635468223978

Epoch: 6| Step: 4
Training loss: 3.069079124686098
Validation loss: 2.9435736066946214

Epoch: 6| Step: 5
Training loss: 3.17980956796941
Validation loss: 2.9450688280228374

Epoch: 6| Step: 6
Training loss: 3.456873175676244
Validation loss: 2.9346274733387325

Epoch: 6| Step: 7
Training loss: 3.105236423846957
Validation loss: 2.9380805795207476

Epoch: 6| Step: 8
Training loss: 2.2176868954314117
Validation loss: 2.9344936880433172

Epoch: 6| Step: 9
Training loss: 3.995798049680815
Validation loss: 2.9338358968991125

Epoch: 6| Step: 10
Training loss: 2.412984465345515
Validation loss: 2.9352140518991776

Epoch: 6| Step: 11
Training loss: 3.763926142609475
Validation loss: 2.929803502127708

Epoch: 6| Step: 12
Training loss: 3.8844443869742307
Validation loss: 2.929926576546627

Epoch: 6| Step: 13
Training loss: 3.1207895524570537
Validation loss: 2.926620612065101

Epoch: 42| Step: 0
Training loss: 2.9405790384168826
Validation loss: 2.92714504690271

Epoch: 6| Step: 1
Training loss: 3.9844079109777417
Validation loss: 2.9314584456217165

Epoch: 6| Step: 2
Training loss: 3.4892099816550943
Validation loss: 2.929442221160213

Epoch: 6| Step: 3
Training loss: 3.0843469311210945
Validation loss: 2.930436274616141

Epoch: 6| Step: 4
Training loss: 3.016215370380978
Validation loss: 2.922644644923891

Epoch: 6| Step: 5
Training loss: 2.8356576996957426
Validation loss: 2.928284480777262

Epoch: 6| Step: 6
Training loss: 3.829656053442776
Validation loss: 2.9304857748404594

Epoch: 6| Step: 7
Training loss: 2.7859266587932727
Validation loss: 2.924337370260755

Epoch: 6| Step: 8
Training loss: 3.2628958217159774
Validation loss: 2.9231629068070295

Epoch: 6| Step: 9
Training loss: 3.6853936855418366
Validation loss: 2.9247753450742406

Epoch: 6| Step: 10
Training loss: 2.887872158359394
Validation loss: 2.9209449792252475

Epoch: 6| Step: 11
Training loss: 2.4685326009710473
Validation loss: 2.9197247103238797

Epoch: 6| Step: 12
Training loss: 3.0940792024186847
Validation loss: 2.921009722843452

Epoch: 6| Step: 13
Training loss: 3.7523995669532315
Validation loss: 2.9167589890829855

Epoch: 43| Step: 0
Training loss: 3.572404177790787
Validation loss: 2.920556982450269

Epoch: 6| Step: 1
Training loss: 3.2160861649428663
Validation loss: 2.9163171872309315

Epoch: 6| Step: 2
Training loss: 2.7035177309369507
Validation loss: 2.918228986728097

Epoch: 6| Step: 3
Training loss: 3.4895562621627576
Validation loss: 2.9164792740446646

Epoch: 6| Step: 4
Training loss: 3.2584880613254947
Validation loss: 2.9162696503712615

Epoch: 6| Step: 5
Training loss: 3.2348417231003346
Validation loss: 2.91544198694984

Epoch: 6| Step: 6
Training loss: 2.8568080365318167
Validation loss: 2.9177700211772066

Epoch: 6| Step: 7
Training loss: 3.1824393396821935
Validation loss: 2.9147592123131085

Epoch: 6| Step: 8
Training loss: 2.6491718005714295
Validation loss: 2.9151240199656656

Epoch: 6| Step: 9
Training loss: 4.099184578545393
Validation loss: 2.9210853599818813

Epoch: 6| Step: 10
Training loss: 3.079100633325264
Validation loss: 2.9344946839731567

Epoch: 6| Step: 11
Training loss: 3.3299936412487092
Validation loss: 2.9306362273641127

Epoch: 6| Step: 12
Training loss: 3.388305573907172
Validation loss: 2.9354324308141364

Epoch: 6| Step: 13
Training loss: 2.5726183719667324
Validation loss: 2.9171759294119526

Epoch: 44| Step: 0
Training loss: 3.316338959675109
Validation loss: 2.9134150285596405

Epoch: 6| Step: 1
Training loss: 3.131363150556649
Validation loss: 2.9149935864961414

Epoch: 6| Step: 2
Training loss: 2.751141224660214
Validation loss: 2.916840324564445

Epoch: 6| Step: 3
Training loss: 2.9616092936365352
Validation loss: 2.9213515409358424

Epoch: 6| Step: 4
Training loss: 3.3466105836624673
Validation loss: 2.9216475491175875

Epoch: 6| Step: 5
Training loss: 3.071630452260478
Validation loss: 2.916605382413171

Epoch: 6| Step: 6
Training loss: 2.7671962089552307
Validation loss: 2.913520447404233

Epoch: 6| Step: 7
Training loss: 3.8150403673828595
Validation loss: 2.914370807210149

Epoch: 6| Step: 8
Training loss: 3.284101137599514
Validation loss: 2.913631713629642

Epoch: 6| Step: 9
Training loss: 2.6974236665094913
Validation loss: 2.915290615736161

Epoch: 6| Step: 10
Training loss: 3.4626201732727586
Validation loss: 2.9177363931726856

Epoch: 6| Step: 11
Training loss: 3.5395017102945063
Validation loss: 2.9221306794756794

Epoch: 6| Step: 12
Training loss: 3.3114962226561597
Validation loss: 2.9267147548730517

Epoch: 6| Step: 13
Training loss: 3.745726502747662
Validation loss: 2.9271295781986253

Epoch: 45| Step: 0
Training loss: 2.8163500395309558
Validation loss: 2.9265236507595462

Epoch: 6| Step: 1
Training loss: 3.8881151307567436
Validation loss: 2.9177243390821888

Epoch: 6| Step: 2
Training loss: 2.7805949950705386
Validation loss: 2.9132827242894765

Epoch: 6| Step: 3
Training loss: 3.0619976643778277
Validation loss: 2.9114328288221234

Epoch: 6| Step: 4
Training loss: 3.664220355116768
Validation loss: 2.911212998345805

Epoch: 6| Step: 5
Training loss: 3.0630858503235974
Validation loss: 2.9120842694117908

Epoch: 6| Step: 6
Training loss: 2.833331126791899
Validation loss: 2.9132825500527444

Epoch: 6| Step: 7
Training loss: 2.597813927016686
Validation loss: 2.911546703647538

Epoch: 6| Step: 8
Training loss: 3.638722196713225
Validation loss: 2.910337724496712

Epoch: 6| Step: 9
Training loss: 2.9070033255847743
Validation loss: 2.9051781551336893

Epoch: 6| Step: 10
Training loss: 3.4105446715539496
Validation loss: 2.907824792347914

Epoch: 6| Step: 11
Training loss: 3.566644098679871
Validation loss: 2.9048349210485274

Epoch: 6| Step: 12
Training loss: 3.7813091431082957
Validation loss: 2.9105940431194037

Epoch: 6| Step: 13
Training loss: 2.3906133314857696
Validation loss: 2.907629775159536

Epoch: 46| Step: 0
Training loss: 3.2832130009890133
Validation loss: 2.9051508400084023

Epoch: 6| Step: 1
Training loss: 3.1440872163202034
Validation loss: 2.90423356133048

Epoch: 6| Step: 2
Training loss: 3.558098466493813
Validation loss: 2.903890112305118

Epoch: 6| Step: 3
Training loss: 3.0552375473843707
Validation loss: 2.9072077030272574

Epoch: 6| Step: 4
Training loss: 3.3745316074443745
Validation loss: 2.903660570141561

Epoch: 6| Step: 5
Training loss: 3.238648176399846
Validation loss: 2.8981431814337086

Epoch: 6| Step: 6
Training loss: 3.414581189592273
Validation loss: 2.9003920356960022

Epoch: 6| Step: 7
Training loss: 2.9320436489088024
Validation loss: 2.9004875327398256

Epoch: 6| Step: 8
Training loss: 3.170476144597129
Validation loss: 2.8992888360100912

Epoch: 6| Step: 9
Training loss: 3.4822585174020384
Validation loss: 2.8997510936171977

Epoch: 6| Step: 10
Training loss: 3.2139382553009197
Validation loss: 2.904843142803984

Epoch: 6| Step: 11
Training loss: 2.6525290063535816
Validation loss: 2.904538684041498

Epoch: 6| Step: 12
Training loss: 3.16400282061773
Validation loss: 2.8976273048477874

Epoch: 6| Step: 13
Training loss: 3.217517653908126
Validation loss: 2.8988267072108282

Epoch: 47| Step: 0
Training loss: 3.0146185425813647
Validation loss: 2.9000094600306787

Epoch: 6| Step: 1
Training loss: 3.392948180963513
Validation loss: 2.899900081039057

Epoch: 6| Step: 2
Training loss: 2.9703506170292315
Validation loss: 2.9059421121729043

Epoch: 6| Step: 3
Training loss: 3.5429558296346553
Validation loss: 2.91532822118807

Epoch: 6| Step: 4
Training loss: 3.2418609822405755
Validation loss: 2.902270213448598

Epoch: 6| Step: 5
Training loss: 3.4625880867119823
Validation loss: 2.9047822257155316

Epoch: 6| Step: 6
Training loss: 3.4003477143149743
Validation loss: 2.9002042762795757

Epoch: 6| Step: 7
Training loss: 3.6435901534809
Validation loss: 2.8979485866749375

Epoch: 6| Step: 8
Training loss: 2.638663381567104
Validation loss: 2.896555705052353

Epoch: 6| Step: 9
Training loss: 2.821731083813036
Validation loss: 2.892783189262224

Epoch: 6| Step: 10
Training loss: 3.684245338132065
Validation loss: 2.8932832042176755

Epoch: 6| Step: 11
Training loss: 2.8442431011895857
Validation loss: 2.8935730547579497

Epoch: 6| Step: 12
Training loss: 2.813896341199966
Validation loss: 2.893674269715839

Epoch: 6| Step: 13
Training loss: 3.1954997784264263
Validation loss: 2.8914925375097456

Epoch: 48| Step: 0
Training loss: 3.815653263021733
Validation loss: 2.891382933860264

Epoch: 6| Step: 1
Training loss: 3.311865691866431
Validation loss: 2.8923461011829597

Epoch: 6| Step: 2
Training loss: 3.2018651950439585
Validation loss: 2.891899378281404

Epoch: 6| Step: 3
Training loss: 3.375032071561665
Validation loss: 2.8941465788706724

Epoch: 6| Step: 4
Training loss: 2.798674617159332
Validation loss: 2.8921768576968017

Epoch: 6| Step: 5
Training loss: 3.5543244899637476
Validation loss: 2.890536418733764

Epoch: 6| Step: 6
Training loss: 3.0957239192420696
Validation loss: 2.8908011700115868

Epoch: 6| Step: 7
Training loss: 3.253989778433456
Validation loss: 2.8890315405633116

Epoch: 6| Step: 8
Training loss: 2.5166270469763687
Validation loss: 2.887483274236226

Epoch: 6| Step: 9
Training loss: 3.3409426303517633
Validation loss: 2.8872441940310685

Epoch: 6| Step: 10
Training loss: 3.2702319489322
Validation loss: 2.891651146808578

Epoch: 6| Step: 11
Training loss: 3.0492297341190198
Validation loss: 2.8905434111100554

Epoch: 6| Step: 12
Training loss: 2.6953619468686734
Validation loss: 2.889647587580661

Epoch: 6| Step: 13
Training loss: 3.508626388911035
Validation loss: 2.8923712176685834

Epoch: 49| Step: 0
Training loss: 2.999795747797409
Validation loss: 2.888872247888056

Epoch: 6| Step: 1
Training loss: 3.70110926109636
Validation loss: 2.885506291187923

Epoch: 6| Step: 2
Training loss: 2.6175168869217087
Validation loss: 2.8861889041047553

Epoch: 6| Step: 3
Training loss: 3.1215575521706582
Validation loss: 2.8868188492244027

Epoch: 6| Step: 4
Training loss: 3.150377305458514
Validation loss: 2.884801415575698

Epoch: 6| Step: 5
Training loss: 3.638583417176586
Validation loss: 2.8874755259933034

Epoch: 6| Step: 6
Training loss: 3.262885153533064
Validation loss: 2.8856309706248875

Epoch: 6| Step: 7
Training loss: 2.4740013573904176
Validation loss: 2.887634980945677

Epoch: 6| Step: 8
Training loss: 3.442326988687434
Validation loss: 2.8859088875166847

Epoch: 6| Step: 9
Training loss: 3.6037445409166455
Validation loss: 2.886692997306653

Epoch: 6| Step: 10
Training loss: 3.0899730708359274
Validation loss: 2.8889887406044625

Epoch: 6| Step: 11
Training loss: 3.5884696314668
Validation loss: 2.8855809488185993

Epoch: 6| Step: 12
Training loss: 3.1420558118422157
Validation loss: 2.884705426798879

Epoch: 6| Step: 13
Training loss: 2.2377474216501305
Validation loss: 2.88617577316046

Epoch: 50| Step: 0
Training loss: 2.844828306893603
Validation loss: 2.8868114428745613

Epoch: 6| Step: 1
Training loss: 2.3627955418364013
Validation loss: 2.8913665751472846

Epoch: 6| Step: 2
Training loss: 3.5760753374804533
Validation loss: 2.8942510697236807

Epoch: 6| Step: 3
Training loss: 3.032964162753795
Validation loss: 2.9036176458964533

Epoch: 6| Step: 4
Training loss: 2.834655976589617
Validation loss: 2.9017652950584876

Epoch: 6| Step: 5
Training loss: 3.176371426894115
Validation loss: 2.9026639145082402

Epoch: 6| Step: 6
Training loss: 2.91205288316056
Validation loss: 2.909943675863492

Epoch: 6| Step: 7
Training loss: 3.2152680757805094
Validation loss: 2.9133342750249125

Epoch: 6| Step: 8
Training loss: 3.235405209617856
Validation loss: 2.9205865006798897

Epoch: 6| Step: 9
Training loss: 3.7042660786033323
Validation loss: 2.9239364300259223

Epoch: 6| Step: 10
Training loss: 3.0149217487258175
Validation loss: 2.9066464438990405

Epoch: 6| Step: 11
Training loss: 3.730107634476881
Validation loss: 2.8923431265796116

Epoch: 6| Step: 12
Training loss: 3.5356794275764596
Validation loss: 2.8803421437732553

Epoch: 6| Step: 13
Training loss: 3.576364942221525
Validation loss: 2.8796692232602203

Epoch: 51| Step: 0
Training loss: 3.1873852578248707
Validation loss: 2.882236959832995

Epoch: 6| Step: 1
Training loss: 2.7656524139597347
Validation loss: 2.8860655580990455

Epoch: 6| Step: 2
Training loss: 3.796116380296303
Validation loss: 2.8946098932614426

Epoch: 6| Step: 3
Training loss: 2.836231395110654
Validation loss: 2.8939627788769466

Epoch: 6| Step: 4
Training loss: 3.7043951890194795
Validation loss: 2.8956558717319094

Epoch: 6| Step: 5
Training loss: 2.7938660360727305
Validation loss: 2.888024912519609

Epoch: 6| Step: 6
Training loss: 2.9251255171490778
Validation loss: 2.8853389850515083

Epoch: 6| Step: 7
Training loss: 2.7902921642613836
Validation loss: 2.8862371637866877

Epoch: 6| Step: 8
Training loss: 3.8662209275808666
Validation loss: 2.8796241368205386

Epoch: 6| Step: 9
Training loss: 3.079699428308806
Validation loss: 2.8837285327623072

Epoch: 6| Step: 10
Training loss: 3.440100223944246
Validation loss: 2.880817553545309

Epoch: 6| Step: 11
Training loss: 3.8311825122458827
Validation loss: 2.888298633289057

Epoch: 6| Step: 12
Training loss: 2.555909777247372
Validation loss: 2.8862721331653853

Epoch: 6| Step: 13
Training loss: 2.4291533346012044
Validation loss: 2.9060882327508986

Epoch: 52| Step: 0
Training loss: 3.139543793211394
Validation loss: 2.9126947136736434

Epoch: 6| Step: 1
Training loss: 3.5842025648842792
Validation loss: 2.913985030121481

Epoch: 6| Step: 2
Training loss: 2.9308815925912186
Validation loss: 2.9018672128524177

Epoch: 6| Step: 3
Training loss: 3.288718162507208
Validation loss: 2.9016037195454087

Epoch: 6| Step: 4
Training loss: 2.3767340503501333
Validation loss: 2.905246523888171

Epoch: 6| Step: 5
Training loss: 3.504237062621798
Validation loss: 2.8915800291267977

Epoch: 6| Step: 6
Training loss: 3.2402514456678118
Validation loss: 2.8970437649974072

Epoch: 6| Step: 7
Training loss: 3.302827929632979
Validation loss: 2.885603904905455

Epoch: 6| Step: 8
Training loss: 3.390448921659322
Validation loss: 2.8794004764903915

Epoch: 6| Step: 9
Training loss: 3.216282760032219
Validation loss: 2.879412763133246

Epoch: 6| Step: 10
Training loss: 2.853423047244809
Validation loss: 2.882873114776688

Epoch: 6| Step: 11
Training loss: 3.435690108583252
Validation loss: 2.8842310809590694

Epoch: 6| Step: 12
Training loss: 2.895598221343604
Validation loss: 2.8789817680048846

Epoch: 6| Step: 13
Training loss: 3.5919220629267747
Validation loss: 2.8823948670567456

Epoch: 53| Step: 0
Training loss: 2.8896835856154883
Validation loss: 2.8771679761968656

Epoch: 6| Step: 1
Training loss: 2.659506563009651
Validation loss: 2.875415804034845

Epoch: 6| Step: 2
Training loss: 4.212936351600475
Validation loss: 2.8791874605056016

Epoch: 6| Step: 3
Training loss: 2.656377452709733
Validation loss: 2.8777237589962583

Epoch: 6| Step: 4
Training loss: 2.850948403481972
Validation loss: 2.8784074711760623

Epoch: 6| Step: 5
Training loss: 3.6043919105192623
Validation loss: 2.8810399728894116

Epoch: 6| Step: 6
Training loss: 3.328320851182399
Validation loss: 2.8855575278957764

Epoch: 6| Step: 7
Training loss: 3.120600082447726
Validation loss: 2.8877707835404602

Epoch: 6| Step: 8
Training loss: 2.7803005355195074
Validation loss: 2.8933435482451406

Epoch: 6| Step: 9
Training loss: 3.4273281454440183
Validation loss: 2.8989003647191036

Epoch: 6| Step: 10
Training loss: 2.663592076088742
Validation loss: 2.900851871002929

Epoch: 6| Step: 11
Training loss: 3.101016364070718
Validation loss: 2.896280546455907

Epoch: 6| Step: 12
Training loss: 3.17704989723163
Validation loss: 2.897954285518875

Epoch: 6| Step: 13
Training loss: 4.169583838025591
Validation loss: 2.8960439470116066

Epoch: 54| Step: 0
Training loss: 3.8284685253231023
Validation loss: 2.882613432114584

Epoch: 6| Step: 1
Training loss: 3.218530443721651
Validation loss: 2.876450902385165

Epoch: 6| Step: 2
Training loss: 3.3341205303188066
Validation loss: 2.8734990241649427

Epoch: 6| Step: 3
Training loss: 2.5549192177679645
Validation loss: 2.8720196215847396

Epoch: 6| Step: 4
Training loss: 3.5344218634644546
Validation loss: 2.870103292565523

Epoch: 6| Step: 5
Training loss: 3.005673289348369
Validation loss: 2.8743075615438407

Epoch: 6| Step: 6
Training loss: 3.4338012216008913
Validation loss: 2.8763601234417524

Epoch: 6| Step: 7
Training loss: 2.977128262956065
Validation loss: 2.8742533459241275

Epoch: 6| Step: 8
Training loss: 3.119838266337771
Validation loss: 2.8757045617294383

Epoch: 6| Step: 9
Training loss: 3.149799213368003
Validation loss: 2.874292426582969

Epoch: 6| Step: 10
Training loss: 3.497475667436662
Validation loss: 2.872569372402785

Epoch: 6| Step: 11
Training loss: 2.8956347793094497
Validation loss: 2.8730999239625117

Epoch: 6| Step: 12
Training loss: 2.234291555273681
Validation loss: 2.871808163094566

Epoch: 6| Step: 13
Training loss: 3.72340691314185
Validation loss: 2.8712610790476387

Epoch: 55| Step: 0
Training loss: 2.666412659309613
Validation loss: 2.870661187947269

Epoch: 6| Step: 1
Training loss: 3.210187764127985
Validation loss: 2.8725569190502864

Epoch: 6| Step: 2
Training loss: 3.290838563949847
Validation loss: 2.8747277115281

Epoch: 6| Step: 3
Training loss: 3.0677507502284707
Validation loss: 2.8724800353151316

Epoch: 6| Step: 4
Training loss: 3.2647607563220475
Validation loss: 2.875677686077323

Epoch: 6| Step: 5
Training loss: 3.025216458985747
Validation loss: 2.8688418549597228

Epoch: 6| Step: 6
Training loss: 3.5975722179891623
Validation loss: 2.86993298929739

Epoch: 6| Step: 7
Training loss: 3.6107539725780655
Validation loss: 2.869705915058554

Epoch: 6| Step: 8
Training loss: 2.955592502117675
Validation loss: 2.8685914387587697

Epoch: 6| Step: 9
Training loss: 2.994431891461233
Validation loss: 2.8693466745260774

Epoch: 6| Step: 10
Training loss: 3.1699757268800637
Validation loss: 2.875760581060129

Epoch: 6| Step: 11
Training loss: 2.7245413823001416
Validation loss: 2.8799555979018208

Epoch: 6| Step: 12
Training loss: 3.781851350240374
Validation loss: 2.8825307075229434

Epoch: 6| Step: 13
Training loss: 2.901006418741115
Validation loss: 2.8772195431577767

Epoch: 56| Step: 0
Training loss: 3.555607871491938
Validation loss: 2.8798406038688054

Epoch: 6| Step: 1
Training loss: 2.6189106748539115
Validation loss: 2.874242879074475

Epoch: 6| Step: 2
Training loss: 3.491261062795756
Validation loss: 2.8749598036172377

Epoch: 6| Step: 3
Training loss: 3.4860675618228143
Validation loss: 2.874761597395743

Epoch: 6| Step: 4
Training loss: 3.118490840563856
Validation loss: 2.879744473772525

Epoch: 6| Step: 5
Training loss: 3.26816660705916
Validation loss: 2.875982190783396

Epoch: 6| Step: 6
Training loss: 3.2643659436930874
Validation loss: 2.8727499524410183

Epoch: 6| Step: 7
Training loss: 3.2281466606129836
Validation loss: 2.870501956495646

Epoch: 6| Step: 8
Training loss: 3.396377254681188
Validation loss: 2.870111938052396

Epoch: 6| Step: 9
Training loss: 3.364758104129359
Validation loss: 2.868991998040855

Epoch: 6| Step: 10
Training loss: 2.8361848245179093
Validation loss: 2.867775584619517

Epoch: 6| Step: 11
Training loss: 2.9130428872426575
Validation loss: 2.8645728923051714

Epoch: 6| Step: 12
Training loss: 2.5847268396666907
Validation loss: 2.866260426185547

Epoch: 6| Step: 13
Training loss: 3.3029092102877744
Validation loss: 2.865403071526016

Epoch: 57| Step: 0
Training loss: 2.7104145172212264
Validation loss: 2.8640822905190073

Epoch: 6| Step: 1
Training loss: 2.4676564365875535
Validation loss: 2.8652386956976024

Epoch: 6| Step: 2
Training loss: 2.9156610844414295
Validation loss: 2.863557758524151

Epoch: 6| Step: 3
Training loss: 3.627362237965754
Validation loss: 2.8666589878014723

Epoch: 6| Step: 4
Training loss: 3.353859992055941
Validation loss: 2.8655569411385633

Epoch: 6| Step: 5
Training loss: 3.0050689471010568
Validation loss: 2.86709148841608

Epoch: 6| Step: 6
Training loss: 3.6571279922464246
Validation loss: 2.8639265791306707

Epoch: 6| Step: 7
Training loss: 3.6375891343564604
Validation loss: 2.860929378097152

Epoch: 6| Step: 8
Training loss: 2.6670514564256016
Validation loss: 2.8628709440882507

Epoch: 6| Step: 9
Training loss: 3.2451276202153245
Validation loss: 2.8610674070596556

Epoch: 6| Step: 10
Training loss: 3.253794142679744
Validation loss: 2.8611016204811444

Epoch: 6| Step: 11
Training loss: 3.203682306700467
Validation loss: 2.8611982595608496

Epoch: 6| Step: 12
Training loss: 3.4574237837703747
Validation loss: 2.8602870771066504

Epoch: 6| Step: 13
Training loss: 2.825169489004432
Validation loss: 2.8641834323706266

Epoch: 58| Step: 0
Training loss: 3.4083684930332514
Validation loss: 2.8639789923027315

Epoch: 6| Step: 1
Training loss: 3.1539107614881345
Validation loss: 2.863991593950147

Epoch: 6| Step: 2
Training loss: 2.7914751660914474
Validation loss: 2.859363484383256

Epoch: 6| Step: 3
Training loss: 2.683442357219824
Validation loss: 2.8609291773737344

Epoch: 6| Step: 4
Training loss: 2.7884103562896687
Validation loss: 2.8604956455508126

Epoch: 6| Step: 5
Training loss: 3.1162207306528975
Validation loss: 2.860852200696955

Epoch: 6| Step: 6
Training loss: 2.9243667503936823
Validation loss: 2.8604427043000182

Epoch: 6| Step: 7
Training loss: 3.0538207090219887
Validation loss: 2.8598455934703217

Epoch: 6| Step: 8
Training loss: 3.939202440160062
Validation loss: 2.861414870704469

Epoch: 6| Step: 9
Training loss: 3.388347511268096
Validation loss: 2.8601531891786647

Epoch: 6| Step: 10
Training loss: 2.510924407981825
Validation loss: 2.863102737487302

Epoch: 6| Step: 11
Training loss: 3.5801156848991265
Validation loss: 2.8599039672549678

Epoch: 6| Step: 12
Training loss: 3.314113727697024
Validation loss: 2.8617944189837448

Epoch: 6| Step: 13
Training loss: 3.6665861959007886
Validation loss: 2.8654622777618477

Epoch: 59| Step: 0
Training loss: 2.5463844248102085
Validation loss: 2.861218381912995

Epoch: 6| Step: 1
Training loss: 3.3919438904134145
Validation loss: 2.8599711540339925

Epoch: 6| Step: 2
Training loss: 3.3634325230480195
Validation loss: 2.857179994019493

Epoch: 6| Step: 3
Training loss: 3.342031161881544
Validation loss: 2.8627700003407117

Epoch: 6| Step: 4
Training loss: 2.696109023779088
Validation loss: 2.859485901783749

Epoch: 6| Step: 5
Training loss: 3.2921613651463986
Validation loss: 2.8606046805940237

Epoch: 6| Step: 6
Training loss: 2.4028794102376514
Validation loss: 2.8611006805426786

Epoch: 6| Step: 7
Training loss: 3.16740515948559
Validation loss: 2.8621006623095693

Epoch: 6| Step: 8
Training loss: 3.5886262939986544
Validation loss: 2.862953301892612

Epoch: 6| Step: 9
Training loss: 3.0194071242073117
Validation loss: 2.8587282586793363

Epoch: 6| Step: 10
Training loss: 3.239423561858276
Validation loss: 2.8559345051640204

Epoch: 6| Step: 11
Training loss: 3.379696439395251
Validation loss: 2.8617216778169228

Epoch: 6| Step: 12
Training loss: 3.7572364920821903
Validation loss: 2.856063434073196

Epoch: 6| Step: 13
Training loss: 2.641229323357215
Validation loss: 2.8568648167506834

Epoch: 60| Step: 0
Training loss: 2.887164379613192
Validation loss: 2.8589505860652342

Epoch: 6| Step: 1
Training loss: 3.074983649481746
Validation loss: 2.8552925153451225

Epoch: 6| Step: 2
Training loss: 3.0611567762891525
Validation loss: 2.858395208729868

Epoch: 6| Step: 3
Training loss: 3.5344329262598113
Validation loss: 2.857966323887901

Epoch: 6| Step: 4
Training loss: 3.1320821238891763
Validation loss: 2.8568568679110293

Epoch: 6| Step: 5
Training loss: 3.0453874135479366
Validation loss: 2.8537490945856763

Epoch: 6| Step: 6
Training loss: 3.081833053424089
Validation loss: 2.8598928948026083

Epoch: 6| Step: 7
Training loss: 2.9899324928751625
Validation loss: 2.8572656292694063

Epoch: 6| Step: 8
Training loss: 3.298796468958902
Validation loss: 2.8589939989020965

Epoch: 6| Step: 9
Training loss: 3.7631447882734683
Validation loss: 2.8581570876422786

Epoch: 6| Step: 10
Training loss: 3.2661989428635225
Validation loss: 2.8573973296633954

Epoch: 6| Step: 11
Training loss: 2.5461920074016233
Validation loss: 2.8612672921324283

Epoch: 6| Step: 12
Training loss: 3.300816787438133
Validation loss: 2.856414985141654

Epoch: 6| Step: 13
Training loss: 3.220363027591762
Validation loss: 2.854174982580818

Epoch: 61| Step: 0
Training loss: 2.6720080426203587
Validation loss: 2.8558171434867967

Epoch: 6| Step: 1
Training loss: 2.5188583540032057
Validation loss: 2.855742041691083

Epoch: 6| Step: 2
Training loss: 3.1339742356770732
Validation loss: 2.8609293315006457

Epoch: 6| Step: 3
Training loss: 3.2759880380936104
Validation loss: 2.864465557522419

Epoch: 6| Step: 4
Training loss: 2.979932424303942
Validation loss: 2.8749376952779886

Epoch: 6| Step: 5
Training loss: 2.994017835514251
Validation loss: 2.874025378500225

Epoch: 6| Step: 6
Training loss: 3.041850010471597
Validation loss: 2.876568577236136

Epoch: 6| Step: 7
Training loss: 3.1602313925128382
Validation loss: 2.8757214846942096

Epoch: 6| Step: 8
Training loss: 3.6051235509009594
Validation loss: 2.87194119703331

Epoch: 6| Step: 9
Training loss: 3.5508234170522917
Validation loss: 2.8716753301070277

Epoch: 6| Step: 10
Training loss: 3.217587159109267
Validation loss: 2.8586005386950686

Epoch: 6| Step: 11
Training loss: 3.3931230053673596
Validation loss: 2.8531688571487446

Epoch: 6| Step: 12
Training loss: 3.5246842371420475
Validation loss: 2.856335608885305

Epoch: 6| Step: 13
Training loss: 3.085269285842341
Validation loss: 2.8560770544255245

Epoch: 62| Step: 0
Training loss: 2.7866467183447075
Validation loss: 2.8571626624433195

Epoch: 6| Step: 1
Training loss: 3.219921454425318
Validation loss: 2.850265249658039

Epoch: 6| Step: 2
Training loss: 3.409570038388959
Validation loss: 2.8561854171210075

Epoch: 6| Step: 3
Training loss: 2.6476093449043985
Validation loss: 2.8578395750027563

Epoch: 6| Step: 4
Training loss: 3.464902238663962
Validation loss: 2.8581221779085517

Epoch: 6| Step: 5
Training loss: 2.9013546969396233
Validation loss: 2.8579306870263648

Epoch: 6| Step: 6
Training loss: 4.245625432358541
Validation loss: 2.8675272191753765

Epoch: 6| Step: 7
Training loss: 3.368266983649683
Validation loss: 2.872609272030847

Epoch: 6| Step: 8
Training loss: 3.0599815757047204
Validation loss: 2.8759358591825235

Epoch: 6| Step: 9
Training loss: 2.7307135781912693
Validation loss: 2.89163308562226

Epoch: 6| Step: 10
Training loss: 3.5271665205424103
Validation loss: 2.8935625195802595

Epoch: 6| Step: 11
Training loss: 2.8990491031568695
Validation loss: 2.891815245585829

Epoch: 6| Step: 12
Training loss: 2.8257962750369487
Validation loss: 2.8892988121054524

Epoch: 6| Step: 13
Training loss: 2.884134294544428
Validation loss: 2.8733843329325452

Epoch: 63| Step: 0
Training loss: 3.2407096711945105
Validation loss: 2.8657777511488627

Epoch: 6| Step: 1
Training loss: 3.5516054311121983
Validation loss: 2.8643408777693

Epoch: 6| Step: 2
Training loss: 2.431337832553481
Validation loss: 2.8565919178643573

Epoch: 6| Step: 3
Training loss: 2.719161693051328
Validation loss: 2.8542417266822686

Epoch: 6| Step: 4
Training loss: 3.7649203705694116
Validation loss: 2.852449678667368

Epoch: 6| Step: 5
Training loss: 2.8368375836829802
Validation loss: 2.8519907172588352

Epoch: 6| Step: 6
Training loss: 3.181769811584605
Validation loss: 2.8519518667456563

Epoch: 6| Step: 7
Training loss: 2.559647344647536
Validation loss: 2.848858202650611

Epoch: 6| Step: 8
Training loss: 3.196368129368835
Validation loss: 2.852415375849966

Epoch: 6| Step: 9
Training loss: 3.36981947984179
Validation loss: 2.8506362289441123

Epoch: 6| Step: 10
Training loss: 2.9819132452970574
Validation loss: 2.849856887545953

Epoch: 6| Step: 11
Training loss: 3.7871808915372145
Validation loss: 2.8541187317980685

Epoch: 6| Step: 12
Training loss: 2.563259012346154
Validation loss: 2.8568672127050125

Epoch: 6| Step: 13
Training loss: 4.024174120978991
Validation loss: 2.861105376647795

Epoch: 64| Step: 0
Training loss: 2.918858240640521
Validation loss: 2.857037038572152

Epoch: 6| Step: 1
Training loss: 3.670281506793631
Validation loss: 2.851051958011663

Epoch: 6| Step: 2
Training loss: 3.3712895094522763
Validation loss: 2.8488492559942995

Epoch: 6| Step: 3
Training loss: 3.243071874395496
Validation loss: 2.8481934441053105

Epoch: 6| Step: 4
Training loss: 3.0490426984470265
Validation loss: 2.852440510498567

Epoch: 6| Step: 5
Training loss: 3.1474953275832203
Validation loss: 2.853925445209934

Epoch: 6| Step: 6
Training loss: 2.7389248732325897
Validation loss: 2.851190948891211

Epoch: 6| Step: 7
Training loss: 3.749713378125163
Validation loss: 2.8499021336681856

Epoch: 6| Step: 8
Training loss: 3.137643490127994
Validation loss: 2.849962082909087

Epoch: 6| Step: 9
Training loss: 2.804097828201961
Validation loss: 2.8480692041789433

Epoch: 6| Step: 10
Training loss: 3.0607191863786216
Validation loss: 2.848831639764118

Epoch: 6| Step: 11
Training loss: 2.9535640006763537
Validation loss: 2.848995332604558

Epoch: 6| Step: 12
Training loss: 3.5657117319883906
Validation loss: 2.8479839810265055

Epoch: 6| Step: 13
Training loss: 1.983142139398019
Validation loss: 2.84502873185743

Epoch: 65| Step: 0
Training loss: 3.6646063102159436
Validation loss: 2.8509590934343754

Epoch: 6| Step: 1
Training loss: 2.9094298000071137
Validation loss: 2.8516545484123816

Epoch: 6| Step: 2
Training loss: 3.090561427744103
Validation loss: 2.8483248925387445

Epoch: 6| Step: 3
Training loss: 3.1366708640199876
Validation loss: 2.852401986072252

Epoch: 6| Step: 4
Training loss: 3.240222307749531
Validation loss: 2.847879137487044

Epoch: 6| Step: 5
Training loss: 2.856985959785953
Validation loss: 2.8459238071287656

Epoch: 6| Step: 6
Training loss: 3.196239682010471
Validation loss: 2.847140762947283

Epoch: 6| Step: 7
Training loss: 3.0655819702239424
Validation loss: 2.8450984541154143

Epoch: 6| Step: 8
Training loss: 3.1461253420141375
Validation loss: 2.844629980271468

Epoch: 6| Step: 9
Training loss: 3.4780341644627244
Validation loss: 2.845753512644905

Epoch: 6| Step: 10
Training loss: 2.2522835269938857
Validation loss: 2.8457784863235944

Epoch: 6| Step: 11
Training loss: 3.183330276913865
Validation loss: 2.844441701737529

Epoch: 6| Step: 12
Training loss: 3.290668448861421
Validation loss: 2.846509461653507

Epoch: 6| Step: 13
Training loss: 3.7077297762497423
Validation loss: 2.8467860989253553

Epoch: 66| Step: 0
Training loss: 2.7849685156256476
Validation loss: 2.855950027352404

Epoch: 6| Step: 1
Training loss: 3.3286971912213232
Validation loss: 2.8503017405770654

Epoch: 6| Step: 2
Training loss: 3.566366272751364
Validation loss: 2.856096916649704

Epoch: 6| Step: 3
Training loss: 3.4919957869986065
Validation loss: 2.8557820956294453

Epoch: 6| Step: 4
Training loss: 2.952337573797787
Validation loss: 2.8468963371184963

Epoch: 6| Step: 5
Training loss: 3.564589841128097
Validation loss: 2.844380054365421

Epoch: 6| Step: 6
Training loss: 3.02101278539362
Validation loss: 2.8430026791021548

Epoch: 6| Step: 7
Training loss: 3.3113792970786498
Validation loss: 2.843270244334376

Epoch: 6| Step: 8
Training loss: 3.1729997416537348
Validation loss: 2.843537079364104

Epoch: 6| Step: 9
Training loss: 2.3847484291200254
Validation loss: 2.840944052771022

Epoch: 6| Step: 10
Training loss: 3.04077022005757
Validation loss: 2.842621905986219

Epoch: 6| Step: 11
Training loss: 2.596009339008667
Validation loss: 2.842390230930467

Epoch: 6| Step: 12
Training loss: 3.2293185454716977
Validation loss: 2.8448408888379384

Epoch: 6| Step: 13
Training loss: 3.6976483887976332
Validation loss: 2.8450618333828506

Epoch: 67| Step: 0
Training loss: 2.9242925587215347
Validation loss: 2.844341685752281

Epoch: 6| Step: 1
Training loss: 3.857748824158386
Validation loss: 2.839733015943365

Epoch: 6| Step: 2
Training loss: 2.986443406967971
Validation loss: 2.8449661285075565

Epoch: 6| Step: 3
Training loss: 3.0664984622381097
Validation loss: 2.841665683936584

Epoch: 6| Step: 4
Training loss: 3.9803871692986212
Validation loss: 2.844435312550904

Epoch: 6| Step: 5
Training loss: 3.014393925774482
Validation loss: 2.8402663480377575

Epoch: 6| Step: 6
Training loss: 3.3893286692389393
Validation loss: 2.841074576031837

Epoch: 6| Step: 7
Training loss: 2.67365424271399
Validation loss: 2.839307392329745

Epoch: 6| Step: 8
Training loss: 3.5966857860388157
Validation loss: 2.8430705213757426

Epoch: 6| Step: 9
Training loss: 2.682988127623518
Validation loss: 2.8385403867464474

Epoch: 6| Step: 10
Training loss: 2.620674747910999
Validation loss: 2.842743650569848

Epoch: 6| Step: 11
Training loss: 2.7810619162066317
Validation loss: 2.838238676002224

Epoch: 6| Step: 12
Training loss: 3.275776976226195
Validation loss: 2.842826703292186

Epoch: 6| Step: 13
Training loss: 2.625103358095836
Validation loss: 2.8448284754102002

Epoch: 68| Step: 0
Training loss: 3.220228725863273
Validation loss: 2.8414373070763888

Epoch: 6| Step: 1
Training loss: 3.306213171020066
Validation loss: 2.847259062108425

Epoch: 6| Step: 2
Training loss: 2.6763394184310227
Validation loss: 2.8432274678328504

Epoch: 6| Step: 3
Training loss: 2.473801285962395
Validation loss: 2.8435991858682783

Epoch: 6| Step: 4
Training loss: 3.417667676472035
Validation loss: 2.839083114934665

Epoch: 6| Step: 5
Training loss: 2.3520582316579373
Validation loss: 2.838227417865083

Epoch: 6| Step: 6
Training loss: 3.414880859620199
Validation loss: 2.837759574960154

Epoch: 6| Step: 7
Training loss: 3.0296691232943354
Validation loss: 2.841122464188902

Epoch: 6| Step: 8
Training loss: 3.02951771111355
Validation loss: 2.8412217724014828

Epoch: 6| Step: 9
Training loss: 3.1856118387957415
Validation loss: 2.8409702707006788

Epoch: 6| Step: 10
Training loss: 3.0806552150403133
Validation loss: 2.8435460030652853

Epoch: 6| Step: 11
Training loss: 3.6868592044940103
Validation loss: 2.8472311138978332

Epoch: 6| Step: 12
Training loss: 3.7366420615954605
Validation loss: 2.847674102166831

Epoch: 6| Step: 13
Training loss: 3.1019443690060275
Validation loss: 2.8473070596387284

Epoch: 69| Step: 0
Training loss: 2.927665317731261
Validation loss: 2.850838318379913

Epoch: 6| Step: 1
Training loss: 2.502124741778313
Validation loss: 2.848243939807659

Epoch: 6| Step: 2
Training loss: 2.2494543261583266
Validation loss: 2.849840637699629

Epoch: 6| Step: 3
Training loss: 3.2502953321812043
Validation loss: 2.8499413989262927

Epoch: 6| Step: 4
Training loss: 2.80780298298288
Validation loss: 2.846466476247777

Epoch: 6| Step: 5
Training loss: 3.107290518122448
Validation loss: 2.8545144263494917

Epoch: 6| Step: 6
Training loss: 4.0077130340666525
Validation loss: 2.8467601290760958

Epoch: 6| Step: 7
Training loss: 3.6303224623192802
Validation loss: 2.8460239503728255

Epoch: 6| Step: 8
Training loss: 3.2943976617857613
Validation loss: 2.8416658327931845

Epoch: 6| Step: 9
Training loss: 2.962022567456992
Validation loss: 2.8374815941660376

Epoch: 6| Step: 10
Training loss: 3.2717537202555236
Validation loss: 2.8367473219288004

Epoch: 6| Step: 11
Training loss: 3.636238828597967
Validation loss: 2.835853648869186

Epoch: 6| Step: 12
Training loss: 2.7228437274327324
Validation loss: 2.8370538698101617

Epoch: 6| Step: 13
Training loss: 3.300413285009572
Validation loss: 2.8377579750329134

Epoch: 70| Step: 0
Training loss: 3.3564596611473196
Validation loss: 2.8340369936613587

Epoch: 6| Step: 1
Training loss: 3.29318594979864
Validation loss: 2.833357708323647

Epoch: 6| Step: 2
Training loss: 3.340288884353061
Validation loss: 2.8353212679680304

Epoch: 6| Step: 3
Training loss: 3.216026561342695
Validation loss: 2.834757181691784

Epoch: 6| Step: 4
Training loss: 4.2139695951852225
Validation loss: 2.832334017073313

Epoch: 6| Step: 5
Training loss: 2.959426051246324
Validation loss: 2.8336422973148356

Epoch: 6| Step: 6
Training loss: 3.217409317647532
Validation loss: 2.8353211377661154

Epoch: 6| Step: 7
Training loss: 2.6053212365709415
Validation loss: 2.833570755114104

Epoch: 6| Step: 8
Training loss: 3.565186140382599
Validation loss: 2.83169665709779

Epoch: 6| Step: 9
Training loss: 2.933914268650503
Validation loss: 2.8339742370570233

Epoch: 6| Step: 10
Training loss: 2.582654730564252
Validation loss: 2.832176237033589

Epoch: 6| Step: 11
Training loss: 2.699616200048347
Validation loss: 2.833398503948038

Epoch: 6| Step: 12
Training loss: 2.4744607087409536
Validation loss: 2.832304162895025

Epoch: 6| Step: 13
Training loss: 3.089975076963781
Validation loss: 2.833720004089082

Epoch: 71| Step: 0
Training loss: 3.2524544177720704
Validation loss: 2.838452482708753

Epoch: 6| Step: 1
Training loss: 3.367638931636964
Validation loss: 2.8336331017696805

Epoch: 6| Step: 2
Training loss: 3.2894204277947594
Validation loss: 2.8316297437319276

Epoch: 6| Step: 3
Training loss: 3.1469106450567024
Validation loss: 2.8399925537681914

Epoch: 6| Step: 4
Training loss: 3.2404203815658823
Validation loss: 2.838919072699478

Epoch: 6| Step: 5
Training loss: 2.615335839990482
Validation loss: 2.8353613328026186

Epoch: 6| Step: 6
Training loss: 3.1901425646073456
Validation loss: 2.8366198350391842

Epoch: 6| Step: 7
Training loss: 3.286312158460337
Validation loss: 2.8329078172622544

Epoch: 6| Step: 8
Training loss: 2.808706140723255
Validation loss: 2.834032780079467

Epoch: 6| Step: 9
Training loss: 2.2737252489182502
Validation loss: 2.8336864715233263

Epoch: 6| Step: 10
Training loss: 2.4562705701592744
Validation loss: 2.8360362033339683

Epoch: 6| Step: 11
Training loss: 3.7405881390711366
Validation loss: 2.8326709855022156

Epoch: 6| Step: 12
Training loss: 3.460851526161273
Validation loss: 2.8298730365089115

Epoch: 6| Step: 13
Training loss: 3.7075739022192775
Validation loss: 2.8285878129724975

Epoch: 72| Step: 0
Training loss: 2.9345431766112267
Validation loss: 2.827472481638163

Epoch: 6| Step: 1
Training loss: 3.1540847754251704
Validation loss: 2.8263826615994607

Epoch: 6| Step: 2
Training loss: 3.307896996717636
Validation loss: 2.8308019356542524

Epoch: 6| Step: 3
Training loss: 2.869667581320651
Validation loss: 2.832830996803914

Epoch: 6| Step: 4
Training loss: 3.3561567638098495
Validation loss: 2.8362966208565714

Epoch: 6| Step: 5
Training loss: 3.017481099269429
Validation loss: 2.837382146012204

Epoch: 6| Step: 6
Training loss: 2.6403587252200142
Validation loss: 2.8394313953586017

Epoch: 6| Step: 7
Training loss: 3.450465770737942
Validation loss: 2.838426811436208

Epoch: 6| Step: 8
Training loss: 2.7593211081265414
Validation loss: 2.8394160266446162

Epoch: 6| Step: 9
Training loss: 2.9802297193837006
Validation loss: 2.8409019703855054

Epoch: 6| Step: 10
Training loss: 3.7986973286448236
Validation loss: 2.8420764497599986

Epoch: 6| Step: 11
Training loss: 3.171003250067473
Validation loss: 2.8346925409287373

Epoch: 6| Step: 12
Training loss: 3.3332342768891756
Validation loss: 2.826122210448697

Epoch: 6| Step: 13
Training loss: 2.9166552588830106
Validation loss: 2.823701052461162

Epoch: 73| Step: 0
Training loss: 3.4554534932471803
Validation loss: 2.824677619685595

Epoch: 6| Step: 1
Training loss: 3.8619902240425965
Validation loss: 2.8227436239826535

Epoch: 6| Step: 2
Training loss: 2.4052974252128054
Validation loss: 2.8275382467158217

Epoch: 6| Step: 3
Training loss: 3.3286768496043284
Validation loss: 2.8283064770457855

Epoch: 6| Step: 4
Training loss: 2.711418175201492
Validation loss: 2.824466721271013

Epoch: 6| Step: 5
Training loss: 2.6193765623597254
Validation loss: 2.830108516274625

Epoch: 6| Step: 6
Training loss: 3.0973957813331996
Validation loss: 2.823261678692265

Epoch: 6| Step: 7
Training loss: 2.8927785738278113
Validation loss: 2.8260479959222358

Epoch: 6| Step: 8
Training loss: 3.124382415780998
Validation loss: 2.827547620295404

Epoch: 6| Step: 9
Training loss: 3.1841932609889803
Validation loss: 2.8253371723643954

Epoch: 6| Step: 10
Training loss: 3.48432587045836
Validation loss: 2.8277488961054957

Epoch: 6| Step: 11
Training loss: 3.359887088513332
Validation loss: 2.828378420697659

Epoch: 6| Step: 12
Training loss: 2.7978601691894234
Validation loss: 2.8285681201146775

Epoch: 6| Step: 13
Training loss: 3.378639519367382
Validation loss: 2.8306046676906287

Epoch: 74| Step: 0
Training loss: 3.794190890539771
Validation loss: 2.828783954618876

Epoch: 6| Step: 1
Training loss: 3.5699178197895916
Validation loss: 2.8236989170775137

Epoch: 6| Step: 2
Training loss: 3.161587121258115
Validation loss: 2.824876764476988

Epoch: 6| Step: 3
Training loss: 2.57327489379713
Validation loss: 2.827529720389816

Epoch: 6| Step: 4
Training loss: 3.5183778284808063
Validation loss: 2.8232786998912616

Epoch: 6| Step: 5
Training loss: 3.264801651682549
Validation loss: 2.8240291542201366

Epoch: 6| Step: 6
Training loss: 3.1006019315532365
Validation loss: 2.825281516148916

Epoch: 6| Step: 7
Training loss: 2.4971799203554528
Validation loss: 2.822366420568059

Epoch: 6| Step: 8
Training loss: 3.292170924582665
Validation loss: 2.81921308387113

Epoch: 6| Step: 9
Training loss: 3.823534895603856
Validation loss: 2.8238865178069745

Epoch: 6| Step: 10
Training loss: 2.219361771608858
Validation loss: 2.823762832623555

Epoch: 6| Step: 11
Training loss: 3.1007447978496394
Validation loss: 2.818421596070831

Epoch: 6| Step: 12
Training loss: 2.467972451907935
Validation loss: 2.824386594188441

Epoch: 6| Step: 13
Training loss: 2.7995405228862515
Validation loss: 2.822974583841767

Epoch: 75| Step: 0
Training loss: 2.638098055031584
Validation loss: 2.835727483302614

Epoch: 6| Step: 1
Training loss: 3.6180590244959143
Validation loss: 2.83953172694617

Epoch: 6| Step: 2
Training loss: 3.670747754372794
Validation loss: 2.830798077695696

Epoch: 6| Step: 3
Training loss: 4.230032971481349
Validation loss: 2.831320774123076

Epoch: 6| Step: 4
Training loss: 2.449961377832037
Validation loss: 2.820552240005599

Epoch: 6| Step: 5
Training loss: 2.450548313053006
Validation loss: 2.8184038697001967

Epoch: 6| Step: 6
Training loss: 2.89050276214304
Validation loss: 2.814945565077707

Epoch: 6| Step: 7
Training loss: 3.396081849036328
Validation loss: 2.816659640134564

Epoch: 6| Step: 8
Training loss: 3.232621901854834
Validation loss: 2.8164861926954248

Epoch: 6| Step: 9
Training loss: 2.9656386283665883
Validation loss: 2.814768844318728

Epoch: 6| Step: 10
Training loss: 2.569718869191902
Validation loss: 2.815741792934121

Epoch: 6| Step: 11
Training loss: 2.6397601635680634
Validation loss: 2.8171234858320497

Epoch: 6| Step: 12
Training loss: 3.2731384286391965
Validation loss: 2.8181629735708564

Epoch: 6| Step: 13
Training loss: 3.245542550599808
Validation loss: 2.8159591686101213

Epoch: 76| Step: 0
Training loss: 2.978646577551617
Validation loss: 2.8177831235472195

Epoch: 6| Step: 1
Training loss: 2.8622165589576016
Validation loss: 2.820372679153022

Epoch: 6| Step: 2
Training loss: 3.0507665577631173
Validation loss: 2.81408368714692

Epoch: 6| Step: 3
Training loss: 2.9550545660619063
Validation loss: 2.8149964577389146

Epoch: 6| Step: 4
Training loss: 3.058188069260583
Validation loss: 2.811124364491274

Epoch: 6| Step: 5
Training loss: 3.0109966911670214
Validation loss: 2.815483205635056

Epoch: 6| Step: 6
Training loss: 2.759780052239138
Validation loss: 2.82074084071589

Epoch: 6| Step: 7
Training loss: 2.9370771063092236
Validation loss: 2.8320936794281186

Epoch: 6| Step: 8
Training loss: 3.477407699884824
Validation loss: 2.8327552548313033

Epoch: 6| Step: 9
Training loss: 2.7208798714630644
Validation loss: 2.854236364505398

Epoch: 6| Step: 10
Training loss: 3.5779457547130913
Validation loss: 2.8506735532718053

Epoch: 6| Step: 11
Training loss: 3.5498663433864945
Validation loss: 2.8541372252915074

Epoch: 6| Step: 12
Training loss: 3.343755704215345
Validation loss: 2.8557753610628427

Epoch: 6| Step: 13
Training loss: 3.757103359381556
Validation loss: 2.842443484061613

Epoch: 77| Step: 0
Training loss: 3.7572216433874464
Validation loss: 2.8437638560213006

Epoch: 6| Step: 1
Training loss: 3.437742467478487
Validation loss: 2.828211830450108

Epoch: 6| Step: 2
Training loss: 2.8310615931594802
Validation loss: 2.8160060290823714

Epoch: 6| Step: 3
Training loss: 3.7292423489241453
Validation loss: 2.812788091965061

Epoch: 6| Step: 4
Training loss: 2.795952074587018
Validation loss: 2.8140928017241222

Epoch: 6| Step: 5
Training loss: 2.5097411158214755
Validation loss: 2.812607691809792

Epoch: 6| Step: 6
Training loss: 3.0159722162884437
Validation loss: 2.8183133805168303

Epoch: 6| Step: 7
Training loss: 2.7156981955476085
Validation loss: 2.8244843424253605

Epoch: 6| Step: 8
Training loss: 2.9506176188868904
Validation loss: 2.8215984918676584

Epoch: 6| Step: 9
Training loss: 3.161986322111578
Validation loss: 2.8330735033780226

Epoch: 6| Step: 10
Training loss: 3.5165067796081773
Validation loss: 2.830603018434902

Epoch: 6| Step: 11
Training loss: 3.028971336674951
Validation loss: 2.8234040960648787

Epoch: 6| Step: 12
Training loss: 2.9634612507739777
Validation loss: 2.817050045295729

Epoch: 6| Step: 13
Training loss: 3.352430111286738
Validation loss: 2.822791688708437

Epoch: 78| Step: 0
Training loss: 2.9738350133942615
Validation loss: 2.8267850936192946

Epoch: 6| Step: 1
Training loss: 3.0372792481632707
Validation loss: 2.8484686146231084

Epoch: 6| Step: 2
Training loss: 2.312240998481472
Validation loss: 2.8547068791917356

Epoch: 6| Step: 3
Training loss: 3.4710320191836668
Validation loss: 2.875340253893493

Epoch: 6| Step: 4
Training loss: 2.845945747206879
Validation loss: 2.8888798530604003

Epoch: 6| Step: 5
Training loss: 3.6477323254961074
Validation loss: 2.906415611979579

Epoch: 6| Step: 6
Training loss: 3.2489993682419245
Validation loss: 2.8762765371502406

Epoch: 6| Step: 7
Training loss: 3.459425757500119
Validation loss: 2.8413136767095324

Epoch: 6| Step: 8
Training loss: 2.9776072833690086
Validation loss: 2.8273822582105232

Epoch: 6| Step: 9
Training loss: 3.288767459348922
Validation loss: 2.817003883825061

Epoch: 6| Step: 10
Training loss: 3.100065009143048
Validation loss: 2.812838599857206

Epoch: 6| Step: 11
Training loss: 3.3637978470488603
Validation loss: 2.810935456009006

Epoch: 6| Step: 12
Training loss: 2.6685965429135403
Validation loss: 2.813567048700051

Epoch: 6| Step: 13
Training loss: 3.3729780286202837
Validation loss: 2.8144978964197676

Epoch: 79| Step: 0
Training loss: 2.7190242059043355
Validation loss: 2.8127148508570996

Epoch: 6| Step: 1
Training loss: 3.1804693137243114
Validation loss: 2.8127782230561387

Epoch: 6| Step: 2
Training loss: 3.6364007763699915
Validation loss: 2.8164756877507076

Epoch: 6| Step: 3
Training loss: 2.9093175306698127
Validation loss: 2.8137961934025504

Epoch: 6| Step: 4
Training loss: 3.1039513293511014
Validation loss: 2.8106762331513955

Epoch: 6| Step: 5
Training loss: 2.936038363816745
Validation loss: 2.808885307421793

Epoch: 6| Step: 6
Training loss: 3.4892850074594435
Validation loss: 2.811245083876893

Epoch: 6| Step: 7
Training loss: 2.554777091318952
Validation loss: 2.807940374105764

Epoch: 6| Step: 8
Training loss: 3.4722102321841595
Validation loss: 2.808901272144326

Epoch: 6| Step: 9
Training loss: 3.5518901843287276
Validation loss: 2.811567490556089

Epoch: 6| Step: 10
Training loss: 2.5382518237079315
Validation loss: 2.804939742440677

Epoch: 6| Step: 11
Training loss: 3.1393651760341763
Validation loss: 2.8069948167350063

Epoch: 6| Step: 12
Training loss: 3.0353009399332174
Validation loss: 2.8080623606132686

Epoch: 6| Step: 13
Training loss: 3.3680043656871343
Validation loss: 2.8066241998401877

Epoch: 80| Step: 0
Training loss: 2.777461182248365
Validation loss: 2.8067985946522147

Epoch: 6| Step: 1
Training loss: 2.7613434489347486
Validation loss: 2.8113774254928874

Epoch: 6| Step: 2
Training loss: 3.340565385991344
Validation loss: 2.8146272970488195

Epoch: 6| Step: 3
Training loss: 2.9765262951989424
Validation loss: 2.8197506717202834

Epoch: 6| Step: 4
Training loss: 2.789685091684472
Validation loss: 2.828026447517735

Epoch: 6| Step: 5
Training loss: 3.241059403470373
Validation loss: 2.8276100702905462

Epoch: 6| Step: 6
Training loss: 2.822321548699824
Validation loss: 2.8255074969644633

Epoch: 6| Step: 7
Training loss: 3.139895681847297
Validation loss: 2.834698583992745

Epoch: 6| Step: 8
Training loss: 3.1703281483045456
Validation loss: 2.821631504834539

Epoch: 6| Step: 9
Training loss: 3.7239665140271088
Validation loss: 2.816724190510188

Epoch: 6| Step: 10
Training loss: 3.1554516075218313
Validation loss: 2.8071570039460823

Epoch: 6| Step: 11
Training loss: 3.0991129005844313
Validation loss: 2.808737811071383

Epoch: 6| Step: 12
Training loss: 3.580984247543173
Validation loss: 2.806252000155137

Epoch: 6| Step: 13
Training loss: 2.8436319515333293
Validation loss: 2.803963375677942

Epoch: 81| Step: 0
Training loss: 2.6313317546693162
Validation loss: 2.806996664349141

Epoch: 6| Step: 1
Training loss: 3.4727868311975274
Validation loss: 2.8050914387486996

Epoch: 6| Step: 2
Training loss: 2.7895962073608556
Validation loss: 2.805515620078949

Epoch: 6| Step: 3
Training loss: 2.9333894254638846
Validation loss: 2.809377842859871

Epoch: 6| Step: 4
Training loss: 3.6579978221304925
Validation loss: 2.8072167180935663

Epoch: 6| Step: 5
Training loss: 3.127326404562502
Validation loss: 2.8135339802886383

Epoch: 6| Step: 6
Training loss: 2.554075861981892
Validation loss: 2.8152989132162527

Epoch: 6| Step: 7
Training loss: 3.503012995158666
Validation loss: 2.8118156575851345

Epoch: 6| Step: 8
Training loss: 2.7070505380975454
Validation loss: 2.8068176657158523

Epoch: 6| Step: 9
Training loss: 3.45600225792034
Validation loss: 2.8029534170452104

Epoch: 6| Step: 10
Training loss: 2.7851103662507284
Validation loss: 2.8011080103516677

Epoch: 6| Step: 11
Training loss: 3.073085008740771
Validation loss: 2.8018480924857347

Epoch: 6| Step: 12
Training loss: 3.3432967689875306
Validation loss: 2.8013511225897676

Epoch: 6| Step: 13
Training loss: 3.5637022967776915
Validation loss: 2.800436139968127

Epoch: 82| Step: 0
Training loss: 3.212469696020736
Validation loss: 2.799638504946348

Epoch: 6| Step: 1
Training loss: 3.1149928271362604
Validation loss: 2.8000105125183024

Epoch: 6| Step: 2
Training loss: 3.2336382187971986
Validation loss: 2.7986892876318246

Epoch: 6| Step: 3
Training loss: 2.956527122751198
Validation loss: 2.7977196394286086

Epoch: 6| Step: 4
Training loss: 2.775950064707445
Validation loss: 2.807876197912828

Epoch: 6| Step: 5
Training loss: 3.1256679583982088
Validation loss: 2.8028105349370995

Epoch: 6| Step: 6
Training loss: 3.37827029555353
Validation loss: 2.8034136568942807

Epoch: 6| Step: 7
Training loss: 3.44832280620322
Validation loss: 2.808705615893163

Epoch: 6| Step: 8
Training loss: 2.7859271722710193
Validation loss: 2.8059270613065355

Epoch: 6| Step: 9
Training loss: 2.570408688864342
Validation loss: 2.808674415252524

Epoch: 6| Step: 10
Training loss: 3.4584378759063905
Validation loss: 2.80614188462629

Epoch: 6| Step: 11
Training loss: 3.141567411465374
Validation loss: 2.804402954647047

Epoch: 6| Step: 12
Training loss: 2.8625887128251493
Validation loss: 2.806428634220393

Epoch: 6| Step: 13
Training loss: 3.590514609131431
Validation loss: 2.8005642368569936

Epoch: 83| Step: 0
Training loss: 2.8299143489102225
Validation loss: 2.8011952957131814

Epoch: 6| Step: 1
Training loss: 3.127250166442657
Validation loss: 2.79981295031171

Epoch: 6| Step: 2
Training loss: 2.842246695767637
Validation loss: 2.80082862710844

Epoch: 6| Step: 3
Training loss: 2.0798696207485565
Validation loss: 2.802635119939077

Epoch: 6| Step: 4
Training loss: 2.981482896964626
Validation loss: 2.80215353252069

Epoch: 6| Step: 5
Training loss: 2.8212813723556063
Validation loss: 2.801087351844535

Epoch: 6| Step: 6
Training loss: 3.8250196668331204
Validation loss: 2.801140479557198

Epoch: 6| Step: 7
Training loss: 3.433589028278181
Validation loss: 2.807527893843607

Epoch: 6| Step: 8
Training loss: 3.4334670945070234
Validation loss: 2.7995055946577403

Epoch: 6| Step: 9
Training loss: 2.9911242157074494
Validation loss: 2.801286560242605

Epoch: 6| Step: 10
Training loss: 3.4420309549787227
Validation loss: 2.797991840998061

Epoch: 6| Step: 11
Training loss: 3.3688891153858322
Validation loss: 2.801522857889022

Epoch: 6| Step: 12
Training loss: 3.1549284028213243
Validation loss: 2.8025683936090355

Epoch: 6| Step: 13
Training loss: 2.7778476091720212
Validation loss: 2.8089312080361992

Epoch: 84| Step: 0
Training loss: 2.386180061446439
Validation loss: 2.805203559456857

Epoch: 6| Step: 1
Training loss: 2.3701177910614186
Validation loss: 2.806213295679624

Epoch: 6| Step: 2
Training loss: 3.583089790643676
Validation loss: 2.805978385233523

Epoch: 6| Step: 3
Training loss: 3.1886169870015624
Validation loss: 2.802270840846608

Epoch: 6| Step: 4
Training loss: 3.2390568705103635
Validation loss: 2.803464263265523

Epoch: 6| Step: 5
Training loss: 2.4532717521167293
Validation loss: 2.804844285422495

Epoch: 6| Step: 6
Training loss: 2.823174121185279
Validation loss: 2.8081710296271507

Epoch: 6| Step: 7
Training loss: 3.8358682599004896
Validation loss: 2.8172511570206655

Epoch: 6| Step: 8
Training loss: 3.2570980029495384
Validation loss: 2.826434704324078

Epoch: 6| Step: 9
Training loss: 3.0556261420525774
Validation loss: 2.8151241188442273

Epoch: 6| Step: 10
Training loss: 3.580624036690597
Validation loss: 2.81497707324603

Epoch: 6| Step: 11
Training loss: 3.0116167855226528
Validation loss: 2.8044629568816117

Epoch: 6| Step: 12
Training loss: 2.900215035720277
Validation loss: 2.796896005848249

Epoch: 6| Step: 13
Training loss: 3.787978813700255
Validation loss: 2.794325554277916

Epoch: 85| Step: 0
Training loss: 2.8704308399772125
Validation loss: 2.7924707148957455

Epoch: 6| Step: 1
Training loss: 2.996854722766874
Validation loss: 2.7940156956619226

Epoch: 6| Step: 2
Training loss: 2.8350033232923404
Validation loss: 2.794875011413945

Epoch: 6| Step: 3
Training loss: 3.0848967909898657
Validation loss: 2.795361832106405

Epoch: 6| Step: 4
Training loss: 3.4916874401655096
Validation loss: 2.7950630187032957

Epoch: 6| Step: 5
Training loss: 3.6289409393524985
Validation loss: 2.7930214896781282

Epoch: 6| Step: 6
Training loss: 3.1334101613412786
Validation loss: 2.7918766152771046

Epoch: 6| Step: 7
Training loss: 2.3272492470559234
Validation loss: 2.7925257609081005

Epoch: 6| Step: 8
Training loss: 3.425570230281068
Validation loss: 2.7919642535158307

Epoch: 6| Step: 9
Training loss: 2.5211953042508455
Validation loss: 2.79373115261023

Epoch: 6| Step: 10
Training loss: 3.0984624556759437
Validation loss: 2.798307921506589

Epoch: 6| Step: 11
Training loss: 3.2183514690892396
Validation loss: 2.7998381945887165

Epoch: 6| Step: 12
Training loss: 3.488240103996903
Validation loss: 2.7975355147377057

Epoch: 6| Step: 13
Training loss: 3.203181568669693
Validation loss: 2.7954377637102548

Epoch: 86| Step: 0
Training loss: 3.0673385077686217
Validation loss: 2.794099291198238

Epoch: 6| Step: 1
Training loss: 3.329441723463771
Validation loss: 2.7946534859228964

Epoch: 6| Step: 2
Training loss: 2.5760591495309892
Validation loss: 2.7955098755478534

Epoch: 6| Step: 3
Training loss: 3.5914206211814106
Validation loss: 2.7967431216124763

Epoch: 6| Step: 4
Training loss: 2.714927617156698
Validation loss: 2.7983546259124705

Epoch: 6| Step: 5
Training loss: 3.5552163872942866
Validation loss: 2.8168508823174787

Epoch: 6| Step: 6
Training loss: 2.658868194951566
Validation loss: 2.831476468692461

Epoch: 6| Step: 7
Training loss: 3.02139347188725
Validation loss: 2.837934623775621

Epoch: 6| Step: 8
Training loss: 3.0844806564152423
Validation loss: 2.8335983766467536

Epoch: 6| Step: 9
Training loss: 2.571675133616003
Validation loss: 2.831310569598639

Epoch: 6| Step: 10
Training loss: 3.592507852586886
Validation loss: 2.8052624333034264

Epoch: 6| Step: 11
Training loss: 3.477613243162407
Validation loss: 2.798146719356412

Epoch: 6| Step: 12
Training loss: 2.770943737459675
Validation loss: 2.79232070074171

Epoch: 6| Step: 13
Training loss: 3.421665132958585
Validation loss: 2.789933432634207

Epoch: 87| Step: 0
Training loss: 3.246238145244752
Validation loss: 2.792748025229297

Epoch: 6| Step: 1
Training loss: 3.114508909699279
Validation loss: 2.790991888162976

Epoch: 6| Step: 2
Training loss: 3.7966367544771487
Validation loss: 2.7912441200803646

Epoch: 6| Step: 3
Training loss: 2.9857046949815325
Validation loss: 2.787011796882299

Epoch: 6| Step: 4
Training loss: 2.935700859858548
Validation loss: 2.7899453469304825

Epoch: 6| Step: 5
Training loss: 2.191022489131976
Validation loss: 2.7927875258355246

Epoch: 6| Step: 6
Training loss: 3.1057243961696566
Validation loss: 2.7939515391236527

Epoch: 6| Step: 7
Training loss: 2.5418854499416375
Validation loss: 2.791848191622653

Epoch: 6| Step: 8
Training loss: 3.4304787802674475
Validation loss: 2.79290196713032

Epoch: 6| Step: 9
Training loss: 3.346897818294355
Validation loss: 2.789307231029244

Epoch: 6| Step: 10
Training loss: 3.2263127338823687
Validation loss: 2.793193093722556

Epoch: 6| Step: 11
Training loss: 3.386623711225974
Validation loss: 2.7938550184743893

Epoch: 6| Step: 12
Training loss: 3.0075582025212304
Validation loss: 2.7955509474577385

Epoch: 6| Step: 13
Training loss: 2.7143242428131704
Validation loss: 2.7922494164057463

Epoch: 88| Step: 0
Training loss: 3.493665139356809
Validation loss: 2.794067895338974

Epoch: 6| Step: 1
Training loss: 3.5855248573259733
Validation loss: 2.794763212019492

Epoch: 6| Step: 2
Training loss: 2.404963954726797
Validation loss: 2.7903979413263778

Epoch: 6| Step: 3
Training loss: 3.1233091739248056
Validation loss: 2.794087146883503

Epoch: 6| Step: 4
Training loss: 3.768373111839402
Validation loss: 2.794764760424085

Epoch: 6| Step: 5
Training loss: 3.144269963183727
Validation loss: 2.7931122925175584

Epoch: 6| Step: 6
Training loss: 3.121265163178558
Validation loss: 2.7978082317735193

Epoch: 6| Step: 7
Training loss: 3.080117756958087
Validation loss: 2.808042028983729

Epoch: 6| Step: 8
Training loss: 2.613643968895262
Validation loss: 2.8034524923819166

Epoch: 6| Step: 9
Training loss: 3.740182359298881
Validation loss: 2.809900732101806

Epoch: 6| Step: 10
Training loss: 2.8751054827371525
Validation loss: 2.813722481063606

Epoch: 6| Step: 11
Training loss: 3.0679925982250467
Validation loss: 2.8063808629261415

Epoch: 6| Step: 12
Training loss: 2.236898850822503
Validation loss: 2.800218669787811

Epoch: 6| Step: 13
Training loss: 2.42810605703302
Validation loss: 2.797151586821448

Epoch: 89| Step: 0
Training loss: 3.2244823483933196
Validation loss: 2.8032020485367775

Epoch: 6| Step: 1
Training loss: 3.078602865082002
Validation loss: 2.807623350931173

Epoch: 6| Step: 2
Training loss: 3.2558114838353167
Validation loss: 2.8086302209777503

Epoch: 6| Step: 3
Training loss: 2.8706170549205927
Validation loss: 2.804877247891427

Epoch: 6| Step: 4
Training loss: 2.8469994393211806
Validation loss: 2.7994425438071056

Epoch: 6| Step: 5
Training loss: 3.8437434250690083
Validation loss: 2.794861040517947

Epoch: 6| Step: 6
Training loss: 3.4419091817344074
Validation loss: 2.786850194294981

Epoch: 6| Step: 7
Training loss: 3.0601710592091242
Validation loss: 2.7822996783194833

Epoch: 6| Step: 8
Training loss: 3.334257824169737
Validation loss: 2.7859149039918814

Epoch: 6| Step: 9
Training loss: 2.6433721394073553
Validation loss: 2.7838088833780446

Epoch: 6| Step: 10
Training loss: 2.5439022009302854
Validation loss: 2.7826099819968806

Epoch: 6| Step: 11
Training loss: 3.481790037061772
Validation loss: 2.788590160475012

Epoch: 6| Step: 12
Training loss: 2.5106005040731283
Validation loss: 2.7857180290027235

Epoch: 6| Step: 13
Training loss: 2.9618351765789086
Validation loss: 2.789121894712997

Epoch: 90| Step: 0
Training loss: 2.724479863633378
Validation loss: 2.80379164082438

Epoch: 6| Step: 1
Training loss: 2.9865553316016533
Validation loss: 2.797567483824685

Epoch: 6| Step: 2
Training loss: 2.8103617699315984
Validation loss: 2.814834106553021

Epoch: 6| Step: 3
Training loss: 2.6623450865474374
Validation loss: 2.8201305939879004

Epoch: 6| Step: 4
Training loss: 3.422762820934156
Validation loss: 2.810043295661516

Epoch: 6| Step: 5
Training loss: 2.3328506333746954
Validation loss: 2.8062130645492576

Epoch: 6| Step: 6
Training loss: 3.340622053867679
Validation loss: 2.798321300776987

Epoch: 6| Step: 7
Training loss: 3.348703725736457
Validation loss: 2.7894781123628603

Epoch: 6| Step: 8
Training loss: 2.66744538699073
Validation loss: 2.7869036256116426

Epoch: 6| Step: 9
Training loss: 3.670518989974268
Validation loss: 2.78797561297639

Epoch: 6| Step: 10
Training loss: 3.9058222422039783
Validation loss: 2.7874238098950865

Epoch: 6| Step: 11
Training loss: 2.9802817189740107
Validation loss: 2.7869336837266383

Epoch: 6| Step: 12
Training loss: 3.303351526784468
Validation loss: 2.790308550501171

Epoch: 6| Step: 13
Training loss: 2.671359096043328
Validation loss: 2.7877255682937725

Epoch: 91| Step: 0
Training loss: 3.3323598075848637
Validation loss: 2.787669161157313

Epoch: 6| Step: 1
Training loss: 3.3989509983823387
Validation loss: 2.781771592621667

Epoch: 6| Step: 2
Training loss: 2.3721491116234406
Validation loss: 2.783291955583449

Epoch: 6| Step: 3
Training loss: 3.4625697710740306
Validation loss: 2.783546645260633

Epoch: 6| Step: 4
Training loss: 3.504157730314916
Validation loss: 2.786595727436903

Epoch: 6| Step: 5
Training loss: 2.833822339063873
Validation loss: 2.7862112793507583

Epoch: 6| Step: 6
Training loss: 2.4175725313369405
Validation loss: 2.784487126409528

Epoch: 6| Step: 7
Training loss: 3.047947464998314
Validation loss: 2.7827532545894647

Epoch: 6| Step: 8
Training loss: 3.119838266337771
Validation loss: 2.780958471243286

Epoch: 6| Step: 9
Training loss: 3.253659755350714
Validation loss: 2.783949464282494

Epoch: 6| Step: 10
Training loss: 2.6074345849116725
Validation loss: 2.782791094185689

Epoch: 6| Step: 11
Training loss: 3.396750687023904
Validation loss: 2.7833966318421357

Epoch: 6| Step: 12
Training loss: 3.09273550951641
Validation loss: 2.7849370867919023

Epoch: 6| Step: 13
Training loss: 3.4809397369139226
Validation loss: 2.7889022590387427

Epoch: 92| Step: 0
Training loss: 3.445916708906598
Validation loss: 2.7916568749197452

Epoch: 6| Step: 1
Training loss: 2.9607187960332486
Validation loss: 2.801003423033181

Epoch: 6| Step: 2
Training loss: 2.357151828269896
Validation loss: 2.80171899378295

Epoch: 6| Step: 3
Training loss: 3.5714348629487342
Validation loss: 2.804480705552155

Epoch: 6| Step: 4
Training loss: 2.422350043191629
Validation loss: 2.8037454914839115

Epoch: 6| Step: 5
Training loss: 3.758423436361282
Validation loss: 2.7977711579004176

Epoch: 6| Step: 6
Training loss: 3.2503906895486563
Validation loss: 2.8068911492947577

Epoch: 6| Step: 7
Training loss: 3.2688261705207045
Validation loss: 2.8062732601199842

Epoch: 6| Step: 8
Training loss: 3.0906415022823146
Validation loss: 2.7980813711735397

Epoch: 6| Step: 9
Training loss: 2.8627522852969056
Validation loss: 2.7932521583054934

Epoch: 6| Step: 10
Training loss: 2.4909869803291693
Validation loss: 2.794551343104627

Epoch: 6| Step: 11
Training loss: 3.1722506596644755
Validation loss: 2.7862126227213966

Epoch: 6| Step: 12
Training loss: 2.7721977794268713
Validation loss: 2.7836282582937604

Epoch: 6| Step: 13
Training loss: 3.8809147885056805
Validation loss: 2.7786614655866884

Epoch: 93| Step: 0
Training loss: 2.8201787605171367
Validation loss: 2.786413123647945

Epoch: 6| Step: 1
Training loss: 3.3385334143732512
Validation loss: 2.7779756513143483

Epoch: 6| Step: 2
Training loss: 2.804702121197091
Validation loss: 2.7776238396420045

Epoch: 6| Step: 3
Training loss: 3.051411386587412
Validation loss: 2.7797901857039946

Epoch: 6| Step: 4
Training loss: 3.093979798076542
Validation loss: 2.7748447248020662

Epoch: 6| Step: 5
Training loss: 3.4059366904538733
Validation loss: 2.7747757179628847

Epoch: 6| Step: 6
Training loss: 2.166116889258215
Validation loss: 2.7768117111428388

Epoch: 6| Step: 7
Training loss: 3.387758933443389
Validation loss: 2.775380671143134

Epoch: 6| Step: 8
Training loss: 3.0226267434832113
Validation loss: 2.7754746956097534

Epoch: 6| Step: 9
Training loss: 2.8525587875901373
Validation loss: 2.7757104410821634

Epoch: 6| Step: 10
Training loss: 3.6645137940026298
Validation loss: 2.7745638990891273

Epoch: 6| Step: 11
Training loss: 3.3493817399418595
Validation loss: 2.780417770045944

Epoch: 6| Step: 12
Training loss: 3.152259040838312
Validation loss: 2.781978475365785

Epoch: 6| Step: 13
Training loss: 2.769487776098979
Validation loss: 2.7809850629471815

Epoch: 94| Step: 0
Training loss: 3.191588379088187
Validation loss: 2.785126888832191

Epoch: 6| Step: 1
Training loss: 2.775927991609222
Validation loss: 2.7767065493663763

Epoch: 6| Step: 2
Training loss: 2.9934292997794887
Validation loss: 2.7888638064933455

Epoch: 6| Step: 3
Training loss: 3.7526664155151406
Validation loss: 2.7828155486054986

Epoch: 6| Step: 4
Training loss: 2.4993338651102834
Validation loss: 2.7775606040419483

Epoch: 6| Step: 5
Training loss: 3.091076244587557
Validation loss: 2.781275051437808

Epoch: 6| Step: 6
Training loss: 3.3373900206086495
Validation loss: 2.783070425580816

Epoch: 6| Step: 7
Training loss: 3.135019186347524
Validation loss: 2.784971827682308

Epoch: 6| Step: 8
Training loss: 2.619199156196053
Validation loss: 2.7860972285022374

Epoch: 6| Step: 9
Training loss: 2.7947829110009246
Validation loss: 2.7887926075368656

Epoch: 6| Step: 10
Training loss: 3.256214948527757
Validation loss: 2.7873943742020004

Epoch: 6| Step: 11
Training loss: 3.208380727706875
Validation loss: 2.7817940902782996

Epoch: 6| Step: 12
Training loss: 3.0998418152350906
Validation loss: 2.7822910013815902

Epoch: 6| Step: 13
Training loss: 3.4007860509241326
Validation loss: 2.777400561599232

Epoch: 95| Step: 0
Training loss: 2.862103270644848
Validation loss: 2.7765570167616946

Epoch: 6| Step: 1
Training loss: 2.833066553758041
Validation loss: 2.7799790656168484

Epoch: 6| Step: 2
Training loss: 3.376444754606271
Validation loss: 2.7800247444975024

Epoch: 6| Step: 3
Training loss: 3.224784453529959
Validation loss: 2.7784214086951016

Epoch: 6| Step: 4
Training loss: 3.4163933311233845
Validation loss: 2.7791726416356193

Epoch: 6| Step: 5
Training loss: 3.5240839261594954
Validation loss: 2.7821629330072817

Epoch: 6| Step: 6
Training loss: 2.457496683888803
Validation loss: 2.7735270759413293

Epoch: 6| Step: 7
Training loss: 2.7693875683099183
Validation loss: 2.7750871539506687

Epoch: 6| Step: 8
Training loss: 2.7681621401050793
Validation loss: 2.775853544286707

Epoch: 6| Step: 9
Training loss: 3.2092720408950535
Validation loss: 2.7748829346227675

Epoch: 6| Step: 10
Training loss: 2.6478441862265405
Validation loss: 2.777267397545013

Epoch: 6| Step: 11
Training loss: 3.243955419720918
Validation loss: 2.775294011223891

Epoch: 6| Step: 12
Training loss: 3.5872571590521494
Validation loss: 2.774588430640913

Epoch: 6| Step: 13
Training loss: 2.983987353648369
Validation loss: 2.7709608996221093

Epoch: 96| Step: 0
Training loss: 3.044499493385106
Validation loss: 2.7746018355870605

Epoch: 6| Step: 1
Training loss: 3.4231705673385986
Validation loss: 2.7717355213439543

Epoch: 6| Step: 2
Training loss: 2.6773299364635808
Validation loss: 2.772416125270235

Epoch: 6| Step: 3
Training loss: 3.6547752079544797
Validation loss: 2.7714380604702646

Epoch: 6| Step: 4
Training loss: 3.2549279338869184
Validation loss: 2.7733550500118085

Epoch: 6| Step: 5
Training loss: 3.042238747782748
Validation loss: 2.777760241736841

Epoch: 6| Step: 6
Training loss: 3.068046685014063
Validation loss: 2.7766730973665443

Epoch: 6| Step: 7
Training loss: 2.627045697137496
Validation loss: 2.775028887081664

Epoch: 6| Step: 8
Training loss: 3.801766592270879
Validation loss: 2.7757905306516255

Epoch: 6| Step: 9
Training loss: 2.9043241293063846
Validation loss: 2.7758531674781204

Epoch: 6| Step: 10
Training loss: 2.4879183661815447
Validation loss: 2.7731053917405344

Epoch: 6| Step: 11
Training loss: 3.539400535085866
Validation loss: 2.7749212871157383

Epoch: 6| Step: 12
Training loss: 2.4476972657488996
Validation loss: 2.7738178792471926

Epoch: 6| Step: 13
Training loss: 2.5785575734993924
Validation loss: 2.775080884999808

Epoch: 97| Step: 0
Training loss: 3.3129551412882843
Validation loss: 2.7759110624093544

Epoch: 6| Step: 1
Training loss: 2.871625329456452
Validation loss: 2.7754505912442404

Epoch: 6| Step: 2
Training loss: 3.539572167486519
Validation loss: 2.7734506895891813

Epoch: 6| Step: 3
Training loss: 3.1826826605627336
Validation loss: 2.776445891562282

Epoch: 6| Step: 4
Training loss: 3.6843167805945387
Validation loss: 2.77285454420997

Epoch: 6| Step: 5
Training loss: 2.8071450859873557
Validation loss: 2.7692771228179605

Epoch: 6| Step: 6
Training loss: 3.1139194116865045
Validation loss: 2.770415246252603

Epoch: 6| Step: 7
Training loss: 2.8399285431052395
Validation loss: 2.7740935609636472

Epoch: 6| Step: 8
Training loss: 2.6323172898750626
Validation loss: 2.773893395054951

Epoch: 6| Step: 9
Training loss: 3.3115718188923715
Validation loss: 2.7716619557292104

Epoch: 6| Step: 10
Training loss: 3.364747617192824
Validation loss: 2.770245360995769

Epoch: 6| Step: 11
Training loss: 2.8782297320368397
Validation loss: 2.768153190100745

Epoch: 6| Step: 12
Training loss: 2.145998482382772
Validation loss: 2.770263298354771

Epoch: 6| Step: 13
Training loss: 3.2937811486293254
Validation loss: 2.770525769904969

Epoch: 98| Step: 0
Training loss: 3.354437459751891
Validation loss: 2.775998119565322

Epoch: 6| Step: 1
Training loss: 2.8475204456322096
Validation loss: 2.7709211896398527

Epoch: 6| Step: 2
Training loss: 3.5657387450360916
Validation loss: 2.7656228698310694

Epoch: 6| Step: 3
Training loss: 3.4100645212462624
Validation loss: 2.7668101466138277

Epoch: 6| Step: 4
Training loss: 2.743416448317485
Validation loss: 2.7652669083500125

Epoch: 6| Step: 5
Training loss: 2.6238395305622473
Validation loss: 2.7657318381957663

Epoch: 6| Step: 6
Training loss: 2.8245356422859063
Validation loss: 2.7646884870178927

Epoch: 6| Step: 7
Training loss: 2.4846755511745378
Validation loss: 2.7705975867946697

Epoch: 6| Step: 8
Training loss: 3.5966075648653932
Validation loss: 2.768594164745106

Epoch: 6| Step: 9
Training loss: 3.291938738302747
Validation loss: 2.7731916310252256

Epoch: 6| Step: 10
Training loss: 2.850385198160604
Validation loss: 2.7712593081173007

Epoch: 6| Step: 11
Training loss: 3.039582901750464
Validation loss: 2.7800115104806458

Epoch: 6| Step: 12
Training loss: 3.202568638562582
Validation loss: 2.784120102638633

Epoch: 6| Step: 13
Training loss: 3.038559585185416
Validation loss: 2.777950900504127

Epoch: 99| Step: 0
Training loss: 2.956320512184726
Validation loss: 2.785028325349569

Epoch: 6| Step: 1
Training loss: 2.9242038523615306
Validation loss: 2.781681353182631

Epoch: 6| Step: 2
Training loss: 3.5035113023826328
Validation loss: 2.7818199017192162

Epoch: 6| Step: 3
Training loss: 3.35583465677189
Validation loss: 2.7657938695294972

Epoch: 6| Step: 4
Training loss: 3.083950513638124
Validation loss: 2.764340147601227

Epoch: 6| Step: 5
Training loss: 3.222965184055937
Validation loss: 2.7662271731980717

Epoch: 6| Step: 6
Training loss: 2.7909813699295274
Validation loss: 2.766739748708466

Epoch: 6| Step: 7
Training loss: 2.2334118881454392
Validation loss: 2.771420752333236

Epoch: 6| Step: 8
Training loss: 2.643079350677821
Validation loss: 2.763826260250748

Epoch: 6| Step: 9
Training loss: 3.537874068577041
Validation loss: 2.76857763887376

Epoch: 6| Step: 10
Training loss: 3.510936679678712
Validation loss: 2.762764710157904

Epoch: 6| Step: 11
Training loss: 2.6136957817711757
Validation loss: 2.7698382795188317

Epoch: 6| Step: 12
Training loss: 3.130619337336102
Validation loss: 2.768716091273457

Epoch: 6| Step: 13
Training loss: 3.4833038462679085
Validation loss: 2.76555599114731

Epoch: 100| Step: 0
Training loss: 2.834558409084512
Validation loss: 2.765080023718329

Epoch: 6| Step: 1
Training loss: 2.941100166677376
Validation loss: 2.768358742099961

Epoch: 6| Step: 2
Training loss: 3.46287768125401
Validation loss: 2.769475765463056

Epoch: 6| Step: 3
Training loss: 2.701554917368443
Validation loss: 2.77049904773767

Epoch: 6| Step: 4
Training loss: 2.6708598746073515
Validation loss: 2.776943669209228

Epoch: 6| Step: 5
Training loss: 3.1034418749103816
Validation loss: 2.771431848941887

Epoch: 6| Step: 6
Training loss: 2.4862820964906773
Validation loss: 2.7701923635326753

Epoch: 6| Step: 7
Training loss: 2.604293993062424
Validation loss: 2.7686283801245146

Epoch: 6| Step: 8
Training loss: 3.9895562684790336
Validation loss: 2.780408450107317

Epoch: 6| Step: 9
Training loss: 2.8047894217585987
Validation loss: 2.7691593249910476

Epoch: 6| Step: 10
Training loss: 3.4478448743155123
Validation loss: 2.779308797074408

Epoch: 6| Step: 11
Training loss: 3.5321886283645236
Validation loss: 2.785232468114593

Epoch: 6| Step: 12
Training loss: 2.9172215251848725
Validation loss: 2.7924888803833876

Epoch: 6| Step: 13
Training loss: 3.2401242964650243
Validation loss: 2.7784803813146546

Epoch: 101| Step: 0
Training loss: 3.003818942265835
Validation loss: 2.778757748241074

Epoch: 6| Step: 1
Training loss: 2.277468224815698
Validation loss: 2.7684424576723172

Epoch: 6| Step: 2
Training loss: 2.846725248884964
Validation loss: 2.7635472240170795

Epoch: 6| Step: 3
Training loss: 3.1577740002021266
Validation loss: 2.7636657118778403

Epoch: 6| Step: 4
Training loss: 3.4241814352165596
Validation loss: 2.7640313456541885

Epoch: 6| Step: 5
Training loss: 3.209843135815669
Validation loss: 2.7613936361094558

Epoch: 6| Step: 6
Training loss: 3.4195353552637
Validation loss: 2.759847387646975

Epoch: 6| Step: 7
Training loss: 2.424711768727877
Validation loss: 2.7627812707999038

Epoch: 6| Step: 8
Training loss: 3.2652083865812136
Validation loss: 2.7620762881064267

Epoch: 6| Step: 9
Training loss: 3.1294603178668865
Validation loss: 2.760821704708959

Epoch: 6| Step: 10
Training loss: 3.8180386693963513
Validation loss: 2.7593842544449716

Epoch: 6| Step: 11
Training loss: 2.4726672420890154
Validation loss: 2.7666302464585297

Epoch: 6| Step: 12
Training loss: 3.1763468071042658
Validation loss: 2.76262299091214

Epoch: 6| Step: 13
Training loss: 3.001910554960036
Validation loss: 2.7652017065398917

Epoch: 102| Step: 0
Training loss: 2.799041079760446
Validation loss: 2.7654118804268983

Epoch: 6| Step: 1
Training loss: 3.326678467642341
Validation loss: 2.7720226634692087

Epoch: 6| Step: 2
Training loss: 3.5933803202353203
Validation loss: 2.7752930172831385

Epoch: 6| Step: 3
Training loss: 2.7214449099267313
Validation loss: 2.763510147859412

Epoch: 6| Step: 4
Training loss: 3.0289725960782428
Validation loss: 2.78549476012332

Epoch: 6| Step: 5
Training loss: 3.0588310217873484
Validation loss: 2.783794173625409

Epoch: 6| Step: 6
Training loss: 3.7273927159672096
Validation loss: 2.782678672025515

Epoch: 6| Step: 7
Training loss: 3.4109892466836085
Validation loss: 2.802969430187549

Epoch: 6| Step: 8
Training loss: 2.4543951354574167
Validation loss: 2.789826980926231

Epoch: 6| Step: 9
Training loss: 3.0229987089739234
Validation loss: 2.7859729726329756

Epoch: 6| Step: 10
Training loss: 2.430078800006939
Validation loss: 2.7792055349935434

Epoch: 6| Step: 11
Training loss: 3.0296056947882763
Validation loss: 2.76223384941299

Epoch: 6| Step: 12
Training loss: 3.0682117370790767
Validation loss: 2.7654747069016077

Epoch: 6| Step: 13
Training loss: 3.0483873575330587
Validation loss: 2.758966405716626

Epoch: 103| Step: 0
Training loss: 2.2112662674136763
Validation loss: 2.756043267372269

Epoch: 6| Step: 1
Training loss: 2.8180254594994283
Validation loss: 2.7554766692578574

Epoch: 6| Step: 2
Training loss: 3.536038283438594
Validation loss: 2.759252997079099

Epoch: 6| Step: 3
Training loss: 3.214290752104187
Validation loss: 2.7558795092767063

Epoch: 6| Step: 4
Training loss: 2.161502687543001
Validation loss: 2.7558436044115426

Epoch: 6| Step: 5
Training loss: 3.035668996264713
Validation loss: 2.7542452993665627

Epoch: 6| Step: 6
Training loss: 3.5826226498145677
Validation loss: 2.7531677275183055

Epoch: 6| Step: 7
Training loss: 3.3232902548040824
Validation loss: 2.7532916128226543

Epoch: 6| Step: 8
Training loss: 3.076658722635458
Validation loss: 2.7532516694133884

Epoch: 6| Step: 9
Training loss: 2.5284142327572963
Validation loss: 2.756142350234523

Epoch: 6| Step: 10
Training loss: 3.211613122255839
Validation loss: 2.7559716660879254

Epoch: 6| Step: 11
Training loss: 3.2166533817418816
Validation loss: 2.7603993918926446

Epoch: 6| Step: 12
Training loss: 3.22696858730105
Validation loss: 2.7715233248935323

Epoch: 6| Step: 13
Training loss: 3.742247897558662
Validation loss: 2.762545769454807

Epoch: 104| Step: 0
Training loss: 2.9814653042954857
Validation loss: 2.761260063124714

Epoch: 6| Step: 1
Training loss: 2.590322044705655
Validation loss: 2.762463035219255

Epoch: 6| Step: 2
Training loss: 3.271036000057455
Validation loss: 2.769654395041427

Epoch: 6| Step: 3
Training loss: 3.084373985839182
Validation loss: 2.772797549784681

Epoch: 6| Step: 4
Training loss: 3.000329953168628
Validation loss: 2.7632738087111517

Epoch: 6| Step: 5
Training loss: 3.4682575597983827
Validation loss: 2.7595705549318117

Epoch: 6| Step: 6
Training loss: 3.3974944812317207
Validation loss: 2.7526866415290976

Epoch: 6| Step: 7
Training loss: 3.3138715675528756
Validation loss: 2.756899966491969

Epoch: 6| Step: 8
Training loss: 2.9459334713014114
Validation loss: 2.7538431847364437

Epoch: 6| Step: 9
Training loss: 3.4053010231084415
Validation loss: 2.751065201729005

Epoch: 6| Step: 10
Training loss: 2.6836153387675563
Validation loss: 2.748330958722375

Epoch: 6| Step: 11
Training loss: 2.715171739264379
Validation loss: 2.7508005000712132

Epoch: 6| Step: 12
Training loss: 3.3083937042903298
Validation loss: 2.753539415123874

Epoch: 6| Step: 13
Training loss: 2.3865162565299833
Validation loss: 2.7511690680852894

Epoch: 105| Step: 0
Training loss: 2.9405704440529883
Validation loss: 2.754059211126905

Epoch: 6| Step: 1
Training loss: 2.928253555325656
Validation loss: 2.7498872534347814

Epoch: 6| Step: 2
Training loss: 3.325130207695982
Validation loss: 2.7532321807523985

Epoch: 6| Step: 3
Training loss: 3.0024543894686966
Validation loss: 2.753432560064585

Epoch: 6| Step: 4
Training loss: 2.9043246218517376
Validation loss: 2.7534272604045347

Epoch: 6| Step: 5
Training loss: 3.314936191871083
Validation loss: 2.751608843142159

Epoch: 6| Step: 6
Training loss: 2.9626279650385596
Validation loss: 2.7520159746053032

Epoch: 6| Step: 7
Training loss: 3.148845485255612
Validation loss: 2.7583181266364254

Epoch: 6| Step: 8
Training loss: 3.5032513366840403
Validation loss: 2.757850519124079

Epoch: 6| Step: 9
Training loss: 2.39870538364919
Validation loss: 2.7644337208339542

Epoch: 6| Step: 10
Training loss: 3.1308005857510723
Validation loss: 2.7562010954318104

Epoch: 6| Step: 11
Training loss: 2.836315791853609
Validation loss: 2.767240565609751

Epoch: 6| Step: 12
Training loss: 2.8032670103098116
Validation loss: 2.761669066299106

Epoch: 6| Step: 13
Training loss: 3.8952555236444275
Validation loss: 2.753887681062819

Epoch: 106| Step: 0
Training loss: 3.420362861300875
Validation loss: 2.7568018370726786

Epoch: 6| Step: 1
Training loss: 3.422041379463257
Validation loss: 2.7489356258595508

Epoch: 6| Step: 2
Training loss: 3.153507362977688
Validation loss: 2.747801852127146

Epoch: 6| Step: 3
Training loss: 3.640705418824115
Validation loss: 2.749567784699502

Epoch: 6| Step: 4
Training loss: 2.776639996736752
Validation loss: 2.7478670945540027

Epoch: 6| Step: 5
Training loss: 3.067666347628688
Validation loss: 2.7490362639570467

Epoch: 6| Step: 6
Training loss: 2.4132234664623318
Validation loss: 2.746775917682431

Epoch: 6| Step: 7
Training loss: 2.393346795369207
Validation loss: 2.7528543863334427

Epoch: 6| Step: 8
Training loss: 2.603461961128765
Validation loss: 2.7509510655423774

Epoch: 6| Step: 9
Training loss: 2.8538740430383105
Validation loss: 2.7454072294284266

Epoch: 6| Step: 10
Training loss: 3.7187035822175263
Validation loss: 2.7516407327704453

Epoch: 6| Step: 11
Training loss: 2.766005840049862
Validation loss: 2.7498344416298313

Epoch: 6| Step: 12
Training loss: 2.7554276396515944
Validation loss: 2.7491856494459523

Epoch: 6| Step: 13
Training loss: 3.8855711196322495
Validation loss: 2.7479762800229786

Epoch: 107| Step: 0
Training loss: 3.094180915183964
Validation loss: 2.752075605273005

Epoch: 6| Step: 1
Training loss: 2.786186124155872
Validation loss: 2.753530574004541

Epoch: 6| Step: 2
Training loss: 2.8155492571297223
Validation loss: 2.755077296060179

Epoch: 6| Step: 3
Training loss: 2.4899392824545057
Validation loss: 2.760049892088729

Epoch: 6| Step: 4
Training loss: 2.8891429504119452
Validation loss: 2.7691566763246094

Epoch: 6| Step: 5
Training loss: 3.1730287454855706
Validation loss: 2.793382666101269

Epoch: 6| Step: 6
Training loss: 3.4967869588151
Validation loss: 2.8292074734057406

Epoch: 6| Step: 7
Training loss: 3.4422947129683967
Validation loss: 2.8180936801917635

Epoch: 6| Step: 8
Training loss: 3.172607637928643
Validation loss: 2.8542814513867114

Epoch: 6| Step: 9
Training loss: 3.8856496596171297
Validation loss: 2.833314253750669

Epoch: 6| Step: 10
Training loss: 2.3987940420746265
Validation loss: 2.798104545788249

Epoch: 6| Step: 11
Training loss: 3.199118588175646
Validation loss: 2.776336978050863

Epoch: 6| Step: 12
Training loss: 3.217310907814018
Validation loss: 2.746793034849672

Epoch: 6| Step: 13
Training loss: 2.224728655610605
Validation loss: 2.7465140639925196

Epoch: 108| Step: 0
Training loss: 2.4434210436362322
Validation loss: 2.7466719738670746

Epoch: 6| Step: 1
Training loss: 3.120694971688717
Validation loss: 2.7484609859749627

Epoch: 6| Step: 2
Training loss: 3.463104052133479
Validation loss: 2.7560726249052663

Epoch: 6| Step: 3
Training loss: 3.3042814397581033
Validation loss: 2.757269657763294

Epoch: 6| Step: 4
Training loss: 3.1509740564748605
Validation loss: 2.760132910426418

Epoch: 6| Step: 5
Training loss: 3.1160657197928865
Validation loss: 2.7623166517659303

Epoch: 6| Step: 6
Training loss: 3.5091397975187983
Validation loss: 2.7547266268611184

Epoch: 6| Step: 7
Training loss: 3.1264077639667858
Validation loss: 2.751541388112145

Epoch: 6| Step: 8
Training loss: 2.539704790306448
Validation loss: 2.752904882856455

Epoch: 6| Step: 9
Training loss: 3.23308327353523
Validation loss: 2.7497961848811068

Epoch: 6| Step: 10
Training loss: 3.072344779554861
Validation loss: 2.75410593984922

Epoch: 6| Step: 11
Training loss: 2.2480470871117406
Validation loss: 2.761944276884262

Epoch: 6| Step: 12
Training loss: 2.707553917655288
Validation loss: 2.7618994295397212

Epoch: 6| Step: 13
Training loss: 4.171422583805273
Validation loss: 2.765709378583465

Epoch: 109| Step: 0
Training loss: 3.6765254014360877
Validation loss: 2.7675056234681796

Epoch: 6| Step: 1
Training loss: 3.0323811416415967
Validation loss: 2.77073513328548

Epoch: 6| Step: 2
Training loss: 3.5700083797153463
Validation loss: 2.7785070484045424

Epoch: 6| Step: 3
Training loss: 2.9541746827210935
Validation loss: 2.7853531177565247

Epoch: 6| Step: 4
Training loss: 3.0169278033566704
Validation loss: 2.7777989891910457

Epoch: 6| Step: 5
Training loss: 2.864302261897261
Validation loss: 2.793255131968724

Epoch: 6| Step: 6
Training loss: 2.8347812954407887
Validation loss: 2.782882668872385

Epoch: 6| Step: 7
Training loss: 3.6694608503333166
Validation loss: 2.7928290912416647

Epoch: 6| Step: 8
Training loss: 3.1764226174316366
Validation loss: 2.7812213875493743

Epoch: 6| Step: 9
Training loss: 2.875695517624042
Validation loss: 2.759054699987141

Epoch: 6| Step: 10
Training loss: 2.727387661390542
Validation loss: 2.749181696537036

Epoch: 6| Step: 11
Training loss: 2.6161499699818034
Validation loss: 2.747013827411984

Epoch: 6| Step: 12
Training loss: 2.741757611869819
Validation loss: 2.7443015860526523

Epoch: 6| Step: 13
Training loss: 2.849997229323797
Validation loss: 2.742839703769041

Epoch: 110| Step: 0
Training loss: 2.6029496260937215
Validation loss: 2.7420822042470827

Epoch: 6| Step: 1
Training loss: 3.0067051025550326
Validation loss: 2.7460293168665006

Epoch: 6| Step: 2
Training loss: 3.179616266525877
Validation loss: 2.744358970501545

Epoch: 6| Step: 3
Training loss: 2.732348404960705
Validation loss: 2.744689557188842

Epoch: 6| Step: 4
Training loss: 2.658379363216551
Validation loss: 2.7479951361270594

Epoch: 6| Step: 5
Training loss: 3.2149101982804766
Validation loss: 2.7481525840233996

Epoch: 6| Step: 6
Training loss: 2.7849619237190555
Validation loss: 2.7438910638730323

Epoch: 6| Step: 7
Training loss: 3.3595694552187005
Validation loss: 2.739185933427322

Epoch: 6| Step: 8
Training loss: 2.2643692219529123
Validation loss: 2.741793298201577

Epoch: 6| Step: 9
Training loss: 3.6392134520890256
Validation loss: 2.7405285613943837

Epoch: 6| Step: 10
Training loss: 3.6186346533119904
Validation loss: 2.741854540609157

Epoch: 6| Step: 11
Training loss: 3.033544556805619
Validation loss: 2.742167383921912

Epoch: 6| Step: 12
Training loss: 3.211738430845349
Validation loss: 2.7443701316930493

Epoch: 6| Step: 13
Training loss: 3.4977097511246975
Validation loss: 2.743872973732988

Epoch: 111| Step: 0
Training loss: 2.7798611891690896
Validation loss: 2.745231450439205

Epoch: 6| Step: 1
Training loss: 2.2784875317036315
Validation loss: 2.7542625022853677

Epoch: 6| Step: 2
Training loss: 3.0714478856490164
Validation loss: 2.7597827424171673

Epoch: 6| Step: 3
Training loss: 3.6127100477564147
Validation loss: 2.7770127468035852

Epoch: 6| Step: 4
Training loss: 3.021500787770549
Validation loss: 2.757955298377865

Epoch: 6| Step: 5
Training loss: 2.667510097952895
Validation loss: 2.756438945944042

Epoch: 6| Step: 6
Training loss: 3.440917379791439
Validation loss: 2.761645812438217

Epoch: 6| Step: 7
Training loss: 2.9967304532988956
Validation loss: 2.7586790811009396

Epoch: 6| Step: 8
Training loss: 3.354767802769373
Validation loss: 2.7633996428007856

Epoch: 6| Step: 9
Training loss: 2.9958979854761214
Validation loss: 2.756694853659962

Epoch: 6| Step: 10
Training loss: 2.743568181506913
Validation loss: 2.752753973502549

Epoch: 6| Step: 11
Training loss: 2.772592077213963
Validation loss: 2.745817234562821

Epoch: 6| Step: 12
Training loss: 3.4271433785385383
Validation loss: 2.755259843089653

Epoch: 6| Step: 13
Training loss: 3.7259211278195923
Validation loss: 2.744506649905873

Epoch: 112| Step: 0
Training loss: 2.879146239838042
Validation loss: 2.743059221996223

Epoch: 6| Step: 1
Training loss: 2.951874644876944
Validation loss: 2.7430657473083575

Epoch: 6| Step: 2
Training loss: 2.6656416075212617
Validation loss: 2.7436421285150097

Epoch: 6| Step: 3
Training loss: 2.8136872222960587
Validation loss: 2.7438377017278937

Epoch: 6| Step: 4
Training loss: 2.795885816859395
Validation loss: 2.7440402380469893

Epoch: 6| Step: 5
Training loss: 3.0018988004396574
Validation loss: 2.7388307706007646

Epoch: 6| Step: 6
Training loss: 3.660602294059468
Validation loss: 2.7427056048098146

Epoch: 6| Step: 7
Training loss: 3.4149537483534904
Validation loss: 2.7392948378814443

Epoch: 6| Step: 8
Training loss: 3.294310526049573
Validation loss: 2.7380504745256613

Epoch: 6| Step: 9
Training loss: 2.9427731847228107
Validation loss: 2.738411379032812

Epoch: 6| Step: 10
Training loss: 3.1708215927996104
Validation loss: 2.7341158967671584

Epoch: 6| Step: 11
Training loss: 2.6578352741609055
Validation loss: 2.7336688117435917

Epoch: 6| Step: 12
Training loss: 3.4701439058657195
Validation loss: 2.7349168100625763

Epoch: 6| Step: 13
Training loss: 2.7853524458640173
Validation loss: 2.7374641981006493

Epoch: 113| Step: 0
Training loss: 2.9613146378180204
Validation loss: 2.7367092312576333

Epoch: 6| Step: 1
Training loss: 2.0378849531800025
Validation loss: 2.7392422729587214

Epoch: 6| Step: 2
Training loss: 3.3495144221691073
Validation loss: 2.742122096262873

Epoch: 6| Step: 3
Training loss: 3.245989599289981
Validation loss: 2.737175900452227

Epoch: 6| Step: 4
Training loss: 3.056589144434688
Validation loss: 2.7376129508427156

Epoch: 6| Step: 5
Training loss: 3.2432709503708645
Validation loss: 2.7351683635001556

Epoch: 6| Step: 6
Training loss: 3.1430090211113155
Validation loss: 2.736874956003407

Epoch: 6| Step: 7
Training loss: 2.9934098657737667
Validation loss: 2.741572075852886

Epoch: 6| Step: 8
Training loss: 3.5002675635381677
Validation loss: 2.736749284025859

Epoch: 6| Step: 9
Training loss: 2.8270617430576324
Validation loss: 2.7362389146779478

Epoch: 6| Step: 10
Training loss: 2.509010290338389
Validation loss: 2.7399221034826495

Epoch: 6| Step: 11
Training loss: 3.090008563674862
Validation loss: 2.7361814798599817

Epoch: 6| Step: 12
Training loss: 3.515255107494214
Validation loss: 2.7443062410113193

Epoch: 6| Step: 13
Training loss: 2.9125080616065837
Validation loss: 2.7390581399039498

Epoch: 114| Step: 0
Training loss: 2.744706868569494
Validation loss: 2.739586109160127

Epoch: 6| Step: 1
Training loss: 3.261195925538068
Validation loss: 2.7433244818358475

Epoch: 6| Step: 2
Training loss: 2.6051402192259467
Validation loss: 2.73680113339674

Epoch: 6| Step: 3
Training loss: 2.774005068878185
Validation loss: 2.74031593362121

Epoch: 6| Step: 4
Training loss: 3.509708291563576
Validation loss: 2.7396524001776723

Epoch: 6| Step: 5
Training loss: 3.226120445136213
Validation loss: 2.737491896879511

Epoch: 6| Step: 6
Training loss: 2.2302519631130755
Validation loss: 2.739404669165659

Epoch: 6| Step: 7
Training loss: 3.3945521802882492
Validation loss: 2.7377212998356755

Epoch: 6| Step: 8
Training loss: 3.3043108786387565
Validation loss: 2.735506033483538

Epoch: 6| Step: 9
Training loss: 2.76409473217101
Validation loss: 2.7318430119873622

Epoch: 6| Step: 10
Training loss: 3.5609440668304138
Validation loss: 2.7362480309074177

Epoch: 6| Step: 11
Training loss: 3.0646709610275025
Validation loss: 2.733436814016832

Epoch: 6| Step: 12
Training loss: 2.7819555866308017
Validation loss: 2.732642018087922

Epoch: 6| Step: 13
Training loss: 3.4121598238346214
Validation loss: 2.7315134064633466

Epoch: 115| Step: 0
Training loss: 3.5704181413443057
Validation loss: 2.729694747152109

Epoch: 6| Step: 1
Training loss: 2.499924086371838
Validation loss: 2.7334581638747175

Epoch: 6| Step: 2
Training loss: 2.721758088186143
Validation loss: 2.733086963593176

Epoch: 6| Step: 3
Training loss: 3.204371363364519
Validation loss: 2.7314563087125507

Epoch: 6| Step: 4
Training loss: 2.6090222879834384
Validation loss: 2.730021169115301

Epoch: 6| Step: 5
Training loss: 2.8381940623005892
Validation loss: 2.7310849048696295

Epoch: 6| Step: 6
Training loss: 3.339621160574173
Validation loss: 2.733477881676525

Epoch: 6| Step: 7
Training loss: 3.1229476292665557
Validation loss: 2.7360507191222063

Epoch: 6| Step: 8
Training loss: 3.314537573274136
Validation loss: 2.7314854358851264

Epoch: 6| Step: 9
Training loss: 3.6638295439171134
Validation loss: 2.7367227205731037

Epoch: 6| Step: 10
Training loss: 3.0711193626110167
Validation loss: 2.7332009697125765

Epoch: 6| Step: 11
Training loss: 2.806315000329257
Validation loss: 2.7378978100630578

Epoch: 6| Step: 12
Training loss: 3.0336599306898657
Validation loss: 2.7310204349160516

Epoch: 6| Step: 13
Training loss: 2.3621252337920584
Validation loss: 2.7310744394007025

Epoch: 116| Step: 0
Training loss: 3.0337991908690296
Validation loss: 2.7319950501421393

Epoch: 6| Step: 1
Training loss: 3.0179941625115205
Validation loss: 2.7378050289522204

Epoch: 6| Step: 2
Training loss: 2.659751917377523
Validation loss: 2.738043538395718

Epoch: 6| Step: 3
Training loss: 2.9644406814907174
Validation loss: 2.733834272556966

Epoch: 6| Step: 4
Training loss: 3.7812344889677343
Validation loss: 2.737055228978646

Epoch: 6| Step: 5
Training loss: 3.365258463077603
Validation loss: 2.7419806704697596

Epoch: 6| Step: 6
Training loss: 2.676170331970937
Validation loss: 2.7520315584620683

Epoch: 6| Step: 7
Training loss: 3.313081798203436
Validation loss: 2.7446932980030705

Epoch: 6| Step: 8
Training loss: 3.1871744625431946
Validation loss: 2.7482774854939573

Epoch: 6| Step: 9
Training loss: 3.254502625326462
Validation loss: 2.7410077717071744

Epoch: 6| Step: 10
Training loss: 3.231632562712807
Validation loss: 2.7336020356599096

Epoch: 6| Step: 11
Training loss: 2.046328755647583
Validation loss: 2.7285838071088113

Epoch: 6| Step: 12
Training loss: 2.9308116332910212
Validation loss: 2.726762699320805

Epoch: 6| Step: 13
Training loss: 2.894444596902164
Validation loss: 2.7294522527200313

Epoch: 117| Step: 0
Training loss: 3.463757195136569
Validation loss: 2.730657132167828

Epoch: 6| Step: 1
Training loss: 3.2719388093892734
Validation loss: 2.729895875614295

Epoch: 6| Step: 2
Training loss: 2.6459306313554074
Validation loss: 2.7290936616590713

Epoch: 6| Step: 3
Training loss: 3.269167206435427
Validation loss: 2.726933629494808

Epoch: 6| Step: 4
Training loss: 3.4527515882660076
Validation loss: 2.72994812091039

Epoch: 6| Step: 5
Training loss: 2.8028803451753195
Validation loss: 2.7290063181719497

Epoch: 6| Step: 6
Training loss: 2.2084868635633725
Validation loss: 2.7318270943087275

Epoch: 6| Step: 7
Training loss: 2.832804985899094
Validation loss: 2.7275440966521267

Epoch: 6| Step: 8
Training loss: 2.5242711629948538
Validation loss: 2.7300328875602684

Epoch: 6| Step: 9
Training loss: 3.2644248107580567
Validation loss: 2.726449562782746

Epoch: 6| Step: 10
Training loss: 3.5451455626309194
Validation loss: 2.727021268749412

Epoch: 6| Step: 11
Training loss: 2.723052380503866
Validation loss: 2.727129630568331

Epoch: 6| Step: 12
Training loss: 3.317818025525283
Validation loss: 2.7278624409071908

Epoch: 6| Step: 13
Training loss: 3.2682659658764086
Validation loss: 2.725367407722575

Epoch: 118| Step: 0
Training loss: 2.978224242919475
Validation loss: 2.727714372597536

Epoch: 6| Step: 1
Training loss: 2.9283095717908973
Validation loss: 2.734914305397392

Epoch: 6| Step: 2
Training loss: 2.589753714675073
Validation loss: 2.7328434362066263

Epoch: 6| Step: 3
Training loss: 2.787886000110007
Validation loss: 2.739060380584088

Epoch: 6| Step: 4
Training loss: 2.996047595289051
Validation loss: 2.738658965403524

Epoch: 6| Step: 5
Training loss: 3.017256695562866
Validation loss: 2.7421051948862716

Epoch: 6| Step: 6
Training loss: 2.5611632046903163
Validation loss: 2.741217476564068

Epoch: 6| Step: 7
Training loss: 3.417201643828611
Validation loss: 2.7457800459763546

Epoch: 6| Step: 8
Training loss: 2.9935586442098043
Validation loss: 2.7321446373764635

Epoch: 6| Step: 9
Training loss: 3.141718280344652
Validation loss: 2.7414335589803143

Epoch: 6| Step: 10
Training loss: 3.5038646070372415
Validation loss: 2.731581247206165

Epoch: 6| Step: 11
Training loss: 2.8732773969063192
Validation loss: 2.7309039617872615

Epoch: 6| Step: 12
Training loss: 3.65454074651414
Validation loss: 2.730829557194367

Epoch: 6| Step: 13
Training loss: 3.024538928747049
Validation loss: 2.732807512926706

Epoch: 119| Step: 0
Training loss: 3.1912015478069677
Validation loss: 2.732958867058302

Epoch: 6| Step: 1
Training loss: 3.0657088926387477
Validation loss: 2.725875369714808

Epoch: 6| Step: 2
Training loss: 3.332032967284141
Validation loss: 2.732065155369635

Epoch: 6| Step: 3
Training loss: 3.1627230599486045
Validation loss: 2.730697122555346

Epoch: 6| Step: 4
Training loss: 3.393818559884932
Validation loss: 2.732665800203137

Epoch: 6| Step: 5
Training loss: 2.779345428192816
Validation loss: 2.7440582364619495

Epoch: 6| Step: 6
Training loss: 3.31212541873473
Validation loss: 2.7387976226033803

Epoch: 6| Step: 7
Training loss: 2.6365722615557634
Validation loss: 2.742336334947083

Epoch: 6| Step: 8
Training loss: 2.7939829445484254
Validation loss: 2.7378580278524316

Epoch: 6| Step: 9
Training loss: 2.7543138134805707
Validation loss: 2.734240344316655

Epoch: 6| Step: 10
Training loss: 3.334030857220277
Validation loss: 2.735859663860672

Epoch: 6| Step: 11
Training loss: 3.0124073948219436
Validation loss: 2.7278135841123716

Epoch: 6| Step: 12
Training loss: 3.1364996846662714
Validation loss: 2.727991318989816

Epoch: 6| Step: 13
Training loss: 2.066759393006434
Validation loss: 2.7259245208170433

Epoch: 120| Step: 0
Training loss: 3.1289227088752503
Validation loss: 2.7237518705384876

Epoch: 6| Step: 1
Training loss: 3.03853651658124
Validation loss: 2.7277947708270682

Epoch: 6| Step: 2
Training loss: 3.097275391841235
Validation loss: 2.7218539433434628

Epoch: 6| Step: 3
Training loss: 3.201571501853728
Validation loss: 2.7226161791707426

Epoch: 6| Step: 4
Training loss: 3.023708282094607
Validation loss: 2.718939072471684

Epoch: 6| Step: 5
Training loss: 3.250388782428723
Validation loss: 2.7238672951390015

Epoch: 6| Step: 6
Training loss: 3.202158265652804
Validation loss: 2.726346276120166

Epoch: 6| Step: 7
Training loss: 2.4716718742159696
Validation loss: 2.7241009557807176

Epoch: 6| Step: 8
Training loss: 2.9621173853000617
Validation loss: 2.721336834222294

Epoch: 6| Step: 9
Training loss: 2.6870990720258305
Validation loss: 2.7242208337216063

Epoch: 6| Step: 10
Training loss: 3.782898346574052
Validation loss: 2.7219977173957473

Epoch: 6| Step: 11
Training loss: 3.268557167565163
Validation loss: 2.7299482974574896

Epoch: 6| Step: 12
Training loss: 2.1877182987825194
Validation loss: 2.7309353891346

Epoch: 6| Step: 13
Training loss: 3.0130355865372294
Validation loss: 2.737207982581725

Epoch: 121| Step: 0
Training loss: 3.0455126724493065
Validation loss: 2.7344041420223064

Epoch: 6| Step: 1
Training loss: 2.6594058867654526
Validation loss: 2.7373491665505947

Epoch: 6| Step: 2
Training loss: 3.35058237963415
Validation loss: 2.7424362738685177

Epoch: 6| Step: 3
Training loss: 3.207703384052371
Validation loss: 2.741219139384222

Epoch: 6| Step: 4
Training loss: 2.3401917977265208
Validation loss: 2.7299020436051045

Epoch: 6| Step: 5
Training loss: 2.596934649979361
Validation loss: 2.7376426099610183

Epoch: 6| Step: 6
Training loss: 2.613648529929089
Validation loss: 2.7294775165753027

Epoch: 6| Step: 7
Training loss: 3.5745984152007977
Validation loss: 2.729123790046894

Epoch: 6| Step: 8
Training loss: 3.70131809881833
Validation loss: 2.724067721241705

Epoch: 6| Step: 9
Training loss: 3.507533956568622
Validation loss: 2.7241150552451745

Epoch: 6| Step: 10
Training loss: 2.722340810446079
Validation loss: 2.7253276683642818

Epoch: 6| Step: 11
Training loss: 2.553685823101889
Validation loss: 2.722987942560242

Epoch: 6| Step: 12
Training loss: 3.555743988991134
Validation loss: 2.716877434946412

Epoch: 6| Step: 13
Training loss: 2.3631968081182206
Validation loss: 2.7181812578336775

Epoch: 122| Step: 0
Training loss: 2.719071643262878
Validation loss: 2.714241140960151

Epoch: 6| Step: 1
Training loss: 3.254783924156001
Validation loss: 2.7151886402301226

Epoch: 6| Step: 2
Training loss: 3.351090973805647
Validation loss: 2.7122108065249964

Epoch: 6| Step: 3
Training loss: 2.9460294544019097
Validation loss: 2.714259143350481

Epoch: 6| Step: 4
Training loss: 3.4060828491635684
Validation loss: 2.713398440698742

Epoch: 6| Step: 5
Training loss: 3.141429589295605
Validation loss: 2.7133895245307134

Epoch: 6| Step: 6
Training loss: 3.435458600166364
Validation loss: 2.719300651490905

Epoch: 6| Step: 7
Training loss: 3.0053028287966983
Validation loss: 2.7154526262696024

Epoch: 6| Step: 8
Training loss: 2.3868662886898857
Validation loss: 2.714842931287407

Epoch: 6| Step: 9
Training loss: 2.727460041260433
Validation loss: 2.7171188287223806

Epoch: 6| Step: 10
Training loss: 2.957841769646432
Validation loss: 2.714227953613984

Epoch: 6| Step: 11
Training loss: 3.058290196113675
Validation loss: 2.7138837206236315

Epoch: 6| Step: 12
Training loss: 2.86479498803777
Validation loss: 2.7188188249237886

Epoch: 6| Step: 13
Training loss: 3.164955145109744
Validation loss: 2.7142108719290348

Epoch: 123| Step: 0
Training loss: 3.274403140592805
Validation loss: 2.721234729891749

Epoch: 6| Step: 1
Training loss: 3.5612078548574004
Validation loss: 2.7243743116446058

Epoch: 6| Step: 2
Training loss: 2.4801277947570397
Validation loss: 2.7280509419677847

Epoch: 6| Step: 3
Training loss: 3.432431038249192
Validation loss: 2.7391099558651915

Epoch: 6| Step: 4
Training loss: 3.101698711488688
Validation loss: 2.733582646994783

Epoch: 6| Step: 5
Training loss: 2.839439730652649
Validation loss: 2.74798935019398

Epoch: 6| Step: 6
Training loss: 2.9736910208280745
Validation loss: 2.730199549034788

Epoch: 6| Step: 7
Training loss: 3.513637133305176
Validation loss: 2.72387058078514

Epoch: 6| Step: 8
Training loss: 3.255510500298488
Validation loss: 2.715338590621597

Epoch: 6| Step: 9
Training loss: 3.0335362258239527
Validation loss: 2.7152057034894854

Epoch: 6| Step: 10
Training loss: 2.482210379894531
Validation loss: 2.7131049372168765

Epoch: 6| Step: 11
Training loss: 2.760566093191161
Validation loss: 2.712052371390084

Epoch: 6| Step: 12
Training loss: 2.598319750496053
Validation loss: 2.713547571713669

Epoch: 6| Step: 13
Training loss: 3.1513683979893865
Validation loss: 2.7099088442059096

Epoch: 124| Step: 0
Training loss: 3.344852444027158
Validation loss: 2.711625012978263

Epoch: 6| Step: 1
Training loss: 3.5088248034726446
Validation loss: 2.7101449957322905

Epoch: 6| Step: 2
Training loss: 3.2236530773654923
Validation loss: 2.7115900310472925

Epoch: 6| Step: 3
Training loss: 3.0323169836055235
Validation loss: 2.713466409337142

Epoch: 6| Step: 4
Training loss: 2.7212809040240513
Validation loss: 2.715188424011728

Epoch: 6| Step: 5
Training loss: 2.944321847758576
Validation loss: 2.7204174020131586

Epoch: 6| Step: 6
Training loss: 2.6474245548034916
Validation loss: 2.718377651374096

Epoch: 6| Step: 7
Training loss: 3.3501092921406475
Validation loss: 2.7206681476622587

Epoch: 6| Step: 8
Training loss: 3.1053308612272588
Validation loss: 2.714800997196995

Epoch: 6| Step: 9
Training loss: 2.4696537729610566
Validation loss: 2.731157712409017

Epoch: 6| Step: 10
Training loss: 2.373397989553203
Validation loss: 2.7416653176396713

Epoch: 6| Step: 11
Training loss: 3.5321814734819172
Validation loss: 2.7528380574609668

Epoch: 6| Step: 12
Training loss: 2.6564390227436383
Validation loss: 2.7548620325557374

Epoch: 6| Step: 13
Training loss: 3.4978144497654236
Validation loss: 2.7534330833263208

Epoch: 125| Step: 0
Training loss: 2.754398989052522
Validation loss: 2.728547421856896

Epoch: 6| Step: 1
Training loss: 3.464992102852061
Validation loss: 2.7144796752202627

Epoch: 6| Step: 2
Training loss: 3.170744746236848
Validation loss: 2.7170907401546684

Epoch: 6| Step: 3
Training loss: 3.1440124462842283
Validation loss: 2.7101775463553297

Epoch: 6| Step: 4
Training loss: 2.521622988601402
Validation loss: 2.711184277256893

Epoch: 6| Step: 5
Training loss: 3.2731028820526653
Validation loss: 2.710232759778463

Epoch: 6| Step: 6
Training loss: 3.4846623734143103
Validation loss: 2.7095355710842597

Epoch: 6| Step: 7
Training loss: 2.8534110152582417
Validation loss: 2.711095739298967

Epoch: 6| Step: 8
Training loss: 2.509902416019287
Validation loss: 2.713087057566414

Epoch: 6| Step: 9
Training loss: 2.140087422162822
Validation loss: 2.7137028606103484

Epoch: 6| Step: 10
Training loss: 3.1398729021627356
Validation loss: 2.7103433222937467

Epoch: 6| Step: 11
Training loss: 3.4607137431195327
Validation loss: 2.7136196414761056

Epoch: 6| Step: 12
Training loss: 2.9913752875291064
Validation loss: 2.7100914927109176

Epoch: 6| Step: 13
Training loss: 3.3423222140590774
Validation loss: 2.7094006658917333

Epoch: 126| Step: 0
Training loss: 3.413415074884639
Validation loss: 2.7077313094028197

Epoch: 6| Step: 1
Training loss: 3.6110264026455177
Validation loss: 2.710021430155864

Epoch: 6| Step: 2
Training loss: 3.2565498375085933
Validation loss: 2.709110339442977

Epoch: 6| Step: 3
Training loss: 2.4366078822728836
Validation loss: 2.707748388411884

Epoch: 6| Step: 4
Training loss: 2.4158746035225147
Validation loss: 2.708086871220076

Epoch: 6| Step: 5
Training loss: 2.5706190488798826
Validation loss: 2.708236903389949

Epoch: 6| Step: 6
Training loss: 2.9769187573875673
Validation loss: 2.707826801447349

Epoch: 6| Step: 7
Training loss: 2.8047435191731
Validation loss: 2.705824058888701

Epoch: 6| Step: 8
Training loss: 3.23011979013822
Validation loss: 2.706596612955992

Epoch: 6| Step: 9
Training loss: 3.443246927226607
Validation loss: 2.7065068683050892

Epoch: 6| Step: 10
Training loss: 2.753898285117028
Validation loss: 2.706249008324414

Epoch: 6| Step: 11
Training loss: 3.221909833066734
Validation loss: 2.705978896672892

Epoch: 6| Step: 12
Training loss: 3.3175633437225907
Validation loss: 2.7108104307575087

Epoch: 6| Step: 13
Training loss: 2.3497883640521673
Validation loss: 2.7107405920087024

Epoch: 127| Step: 0
Training loss: 3.069155875594508
Validation loss: 2.7257416983479263

Epoch: 6| Step: 1
Training loss: 2.6647568857691137
Validation loss: 2.7280111571237073

Epoch: 6| Step: 2
Training loss: 3.1109749976158625
Validation loss: 2.7465515534636658

Epoch: 6| Step: 3
Training loss: 3.584059412531912
Validation loss: 2.770106744409082

Epoch: 6| Step: 4
Training loss: 2.579367968006869
Validation loss: 2.7436337376509567

Epoch: 6| Step: 5
Training loss: 3.4284496115433285
Validation loss: 2.7407119212420974

Epoch: 6| Step: 6
Training loss: 3.071042660773698
Validation loss: 2.7256946912158

Epoch: 6| Step: 7
Training loss: 3.338805634075423
Validation loss: 2.712186076575698

Epoch: 6| Step: 8
Training loss: 3.239510849185751
Validation loss: 2.7136710929288186

Epoch: 6| Step: 9
Training loss: 3.0785906289437244
Validation loss: 2.7058591134685246

Epoch: 6| Step: 10
Training loss: 2.75069990788078
Validation loss: 2.7059916618916047

Epoch: 6| Step: 11
Training loss: 2.9919401619379333
Validation loss: 2.706752244281558

Epoch: 6| Step: 12
Training loss: 2.4997575642337493
Validation loss: 2.70724638874318

Epoch: 6| Step: 13
Training loss: 2.6406631918408148
Validation loss: 2.7075460199888415

Epoch: 128| Step: 0
Training loss: 3.1422955828743047
Validation loss: 2.7065941194972143

Epoch: 6| Step: 1
Training loss: 2.73895351195255
Validation loss: 2.7055065999882904

Epoch: 6| Step: 2
Training loss: 3.4315981050830486
Validation loss: 2.705220399678401

Epoch: 6| Step: 3
Training loss: 2.9201880496364025
Validation loss: 2.712622351316202

Epoch: 6| Step: 4
Training loss: 2.6193295950425597
Validation loss: 2.7174813555919295

Epoch: 6| Step: 5
Training loss: 2.2130606334324723
Validation loss: 2.7217364685288095

Epoch: 6| Step: 6
Training loss: 3.227276960802415
Validation loss: 2.731977543729406

Epoch: 6| Step: 7
Training loss: 3.024742455986762
Validation loss: 2.7295126881536635

Epoch: 6| Step: 8
Training loss: 3.18411029767443
Validation loss: 2.719511000799382

Epoch: 6| Step: 9
Training loss: 3.1534946614370405
Validation loss: 2.726213280457399

Epoch: 6| Step: 10
Training loss: 2.9474222332480497
Validation loss: 2.720266502664227

Epoch: 6| Step: 11
Training loss: 3.4241655600174576
Validation loss: 2.7184525542677944

Epoch: 6| Step: 12
Training loss: 3.2649176164547136
Validation loss: 2.7165280678993837

Epoch: 6| Step: 13
Training loss: 2.871874063551857
Validation loss: 2.7169077620230406

Epoch: 129| Step: 0
Training loss: 2.6556715391502275
Validation loss: 2.723593310447351

Epoch: 6| Step: 1
Training loss: 2.76061108942135
Validation loss: 2.7222622240699277

Epoch: 6| Step: 2
Training loss: 2.9213295493763742
Validation loss: 2.7237585945819998

Epoch: 6| Step: 3
Training loss: 3.053514025920651
Validation loss: 2.717240148751522

Epoch: 6| Step: 4
Training loss: 3.3970565621038475
Validation loss: 2.7164660761424995

Epoch: 6| Step: 5
Training loss: 3.185161106460533
Validation loss: 2.716480849425235

Epoch: 6| Step: 6
Training loss: 3.3932924808773572
Validation loss: 2.7137703436169947

Epoch: 6| Step: 7
Training loss: 3.329997650695522
Validation loss: 2.7145805990925465

Epoch: 6| Step: 8
Training loss: 2.5734736242578777
Validation loss: 2.706170693565763

Epoch: 6| Step: 9
Training loss: 2.7596376771417552
Validation loss: 2.702752464126513

Epoch: 6| Step: 10
Training loss: 3.1581605473127135
Validation loss: 2.704351123023859

Epoch: 6| Step: 11
Training loss: 2.889033688885884
Validation loss: 2.7044337799049236

Epoch: 6| Step: 12
Training loss: 3.2410463094207045
Validation loss: 2.7050809889904435

Epoch: 6| Step: 13
Training loss: 2.910634169282533
Validation loss: 2.701896223647012

Epoch: 130| Step: 0
Training loss: 2.7693299730170624
Validation loss: 2.7040841362202284

Epoch: 6| Step: 1
Training loss: 2.9164876792120356
Validation loss: 2.701018766230798

Epoch: 6| Step: 2
Training loss: 2.538594739815956
Validation loss: 2.7003327424819474

Epoch: 6| Step: 3
Training loss: 2.1006533560049183
Validation loss: 2.7048161233875243

Epoch: 6| Step: 4
Training loss: 3.055640498820538
Validation loss: 2.703706452959108

Epoch: 6| Step: 5
Training loss: 3.16448399126449
Validation loss: 2.7069356815907066

Epoch: 6| Step: 6
Training loss: 3.304326030901559
Validation loss: 2.704717729869121

Epoch: 6| Step: 7
Training loss: 3.646899272769279
Validation loss: 2.713017095049177

Epoch: 6| Step: 8
Training loss: 3.3860315947931583
Validation loss: 2.7167788129913997

Epoch: 6| Step: 9
Training loss: 2.965892822263525
Validation loss: 2.727563907022018

Epoch: 6| Step: 10
Training loss: 3.2352564988014643
Validation loss: 2.714560240659118

Epoch: 6| Step: 11
Training loss: 3.34211134643254
Validation loss: 2.72628119854856

Epoch: 6| Step: 12
Training loss: 2.8613857849352455
Validation loss: 2.7118417536133697

Epoch: 6| Step: 13
Training loss: 2.8130089193420362
Validation loss: 2.7025104018196706

Epoch: 131| Step: 0
Training loss: 3.420035368530137
Validation loss: 2.697768307336854

Epoch: 6| Step: 1
Training loss: 3.598344337360565
Validation loss: 2.6975525552390853

Epoch: 6| Step: 2
Training loss: 3.0721706368421335
Validation loss: 2.7001832167620736

Epoch: 6| Step: 3
Training loss: 2.731193566339443
Validation loss: 2.702469728717001

Epoch: 6| Step: 4
Training loss: 2.25119717855297
Validation loss: 2.6975031808383556

Epoch: 6| Step: 5
Training loss: 2.875506149187247
Validation loss: 2.6993837468341195

Epoch: 6| Step: 6
Training loss: 3.080023939857087
Validation loss: 2.705350986554217

Epoch: 6| Step: 7
Training loss: 2.6186652267682584
Validation loss: 2.7025409811846646

Epoch: 6| Step: 8
Training loss: 3.036752798852803
Validation loss: 2.699796384716834

Epoch: 6| Step: 9
Training loss: 3.2827432776755514
Validation loss: 2.697796092488874

Epoch: 6| Step: 10
Training loss: 3.4468744245098115
Validation loss: 2.700789161790688

Epoch: 6| Step: 11
Training loss: 3.1099302476622697
Validation loss: 2.699065633017816

Epoch: 6| Step: 12
Training loss: 2.80469523564284
Validation loss: 2.6993269733259644

Epoch: 6| Step: 13
Training loss: 2.749654401390728
Validation loss: 2.698541672811076

Epoch: 132| Step: 0
Training loss: 3.3378186248817387
Validation loss: 2.7101994199727635

Epoch: 6| Step: 1
Training loss: 3.3328385621673497
Validation loss: 2.7168874191405363

Epoch: 6| Step: 2
Training loss: 3.0689928941492157
Validation loss: 2.722283719952871

Epoch: 6| Step: 3
Training loss: 2.3719356242638323
Validation loss: 2.7377245454447796

Epoch: 6| Step: 4
Training loss: 2.929002198494255
Validation loss: 2.7498384840323324

Epoch: 6| Step: 5
Training loss: 2.398903866634205
Validation loss: 2.7579968319474717

Epoch: 6| Step: 6
Training loss: 2.7419788248592587
Validation loss: 2.764088148915129

Epoch: 6| Step: 7
Training loss: 3.3188473329800674
Validation loss: 2.742451977597404

Epoch: 6| Step: 8
Training loss: 3.0276225300066884
Validation loss: 2.7176229035749864

Epoch: 6| Step: 9
Training loss: 3.0874524997038004
Validation loss: 2.7088376010411808

Epoch: 6| Step: 10
Training loss: 2.5354065852303056
Validation loss: 2.6984563738963434

Epoch: 6| Step: 11
Training loss: 3.0694647242210333
Validation loss: 2.6924011267219035

Epoch: 6| Step: 12
Training loss: 3.5773081284311736
Validation loss: 2.6921343160732985

Epoch: 6| Step: 13
Training loss: 3.5671230903521725
Validation loss: 2.6845584404880416

Epoch: 133| Step: 0
Training loss: 2.5947438369767464
Validation loss: 2.6913649747269557

Epoch: 6| Step: 1
Training loss: 2.985132410892201
Validation loss: 2.6899103991630864

Epoch: 6| Step: 2
Training loss: 3.0425218050699607
Validation loss: 2.688436188199899

Epoch: 6| Step: 3
Training loss: 2.8842055513776503
Validation loss: 2.69018622669313

Epoch: 6| Step: 4
Training loss: 3.5572261925290123
Validation loss: 2.682484881312364

Epoch: 6| Step: 5
Training loss: 3.0275935506817757
Validation loss: 2.6837134475404785

Epoch: 6| Step: 6
Training loss: 2.7167672128929805
Validation loss: 2.6825369576490736

Epoch: 6| Step: 7
Training loss: 3.1715839421570475
Validation loss: 2.6779397984846645

Epoch: 6| Step: 8
Training loss: 2.95759542870719
Validation loss: 2.6759467061583613

Epoch: 6| Step: 9
Training loss: 3.4105038460269546
Validation loss: 2.6790051755896767

Epoch: 6| Step: 10
Training loss: 3.040395410069676
Validation loss: 2.6783095907356866

Epoch: 6| Step: 11
Training loss: 3.027831519424747
Validation loss: 2.6774482298014397

Epoch: 6| Step: 12
Training loss: 2.768684548321241
Validation loss: 2.6800418187684993

Epoch: 6| Step: 13
Training loss: 2.8299878134313445
Validation loss: 2.6826126309613376

Epoch: 134| Step: 0
Training loss: 3.4986245313623177
Validation loss: 2.686449200807196

Epoch: 6| Step: 1
Training loss: 3.842325334221326
Validation loss: 2.690093002690867

Epoch: 6| Step: 2
Training loss: 3.141683675246064
Validation loss: 2.686698729259814

Epoch: 6| Step: 3
Training loss: 3.253730833310021
Validation loss: 2.677671174914011

Epoch: 6| Step: 4
Training loss: 2.870782661452175
Validation loss: 2.681184959029107

Epoch: 6| Step: 5
Training loss: 2.7784296372932764
Validation loss: 2.6764247019126817

Epoch: 6| Step: 6
Training loss: 1.9192149043291173
Validation loss: 2.675675078051294

Epoch: 6| Step: 7
Training loss: 2.7635764600909893
Validation loss: 2.680127270441788

Epoch: 6| Step: 8
Training loss: 3.154412971934678
Validation loss: 2.6704470413098447

Epoch: 6| Step: 9
Training loss: 2.504156472116074
Validation loss: 2.6786996367164573

Epoch: 6| Step: 10
Training loss: 3.1309336976518356
Validation loss: 2.6782692689689025

Epoch: 6| Step: 11
Training loss: 3.057052906251158
Validation loss: 2.6770645880869823

Epoch: 6| Step: 12
Training loss: 3.1639173686333137
Validation loss: 2.6781014387071402

Epoch: 6| Step: 13
Training loss: 2.1524043412169562
Validation loss: 2.6804596444924997

Epoch: 135| Step: 0
Training loss: 3.0681268809117146
Validation loss: 2.6836120726166515

Epoch: 6| Step: 1
Training loss: 2.8168478525638205
Validation loss: 2.6809037788729393

Epoch: 6| Step: 2
Training loss: 2.537291299289692
Validation loss: 2.6818483876233836

Epoch: 6| Step: 3
Training loss: 3.2583405503553253
Validation loss: 2.6868001508834176

Epoch: 6| Step: 4
Training loss: 2.292299657156691
Validation loss: 2.688251728866177

Epoch: 6| Step: 5
Training loss: 2.7237828467438114
Validation loss: 2.680456267377383

Epoch: 6| Step: 6
Training loss: 3.102466979853933
Validation loss: 2.681314164625978

Epoch: 6| Step: 7
Training loss: 3.2154512260200843
Validation loss: 2.6856145824798197

Epoch: 6| Step: 8
Training loss: 2.4236481113275303
Validation loss: 2.6952619802606983

Epoch: 6| Step: 9
Training loss: 2.5728187284993083
Validation loss: 2.6885634815234534

Epoch: 6| Step: 10
Training loss: 3.225220481965163
Validation loss: 2.6864790879215397

Epoch: 6| Step: 11
Training loss: 3.941666714518401
Validation loss: 2.6796871661138146

Epoch: 6| Step: 12
Training loss: 3.5757958440001505
Validation loss: 2.6871094769308566

Epoch: 6| Step: 13
Training loss: 2.6711529207774642
Validation loss: 2.694645458333954

Epoch: 136| Step: 0
Training loss: 3.3124015361618793
Validation loss: 2.6814305000790903

Epoch: 6| Step: 1
Training loss: 2.6882287745078166
Validation loss: 2.6837237557173794

Epoch: 6| Step: 2
Training loss: 3.0597870935909035
Validation loss: 2.6920297618619484

Epoch: 6| Step: 3
Training loss: 3.42662158085395
Validation loss: 2.686046832280925

Epoch: 6| Step: 4
Training loss: 2.7719423374052017
Validation loss: 2.686426404728523

Epoch: 6| Step: 5
Training loss: 3.586641130415569
Validation loss: 2.6919540770969266

Epoch: 6| Step: 6
Training loss: 2.42517377093145
Validation loss: 2.684693648635439

Epoch: 6| Step: 7
Training loss: 2.439137520085415
Validation loss: 2.683661663421673

Epoch: 6| Step: 8
Training loss: 3.200030362462005
Validation loss: 2.683259172114737

Epoch: 6| Step: 9
Training loss: 3.0777262318040197
Validation loss: 2.675063168279457

Epoch: 6| Step: 10
Training loss: 3.3835511843695425
Validation loss: 2.6741951707796225

Epoch: 6| Step: 11
Training loss: 2.6830139866541485
Validation loss: 2.668010333413431

Epoch: 6| Step: 12
Training loss: 2.3185577436261027
Validation loss: 2.6734900216776953

Epoch: 6| Step: 13
Training loss: 3.486876816941407
Validation loss: 2.674592810127054

Epoch: 137| Step: 0
Training loss: 2.8109504669721583
Validation loss: 2.6752343979705073

Epoch: 6| Step: 1
Training loss: 3.1345773040201017
Validation loss: 2.6747708763874667

Epoch: 6| Step: 2
Training loss: 3.0548606101544378
Validation loss: 2.6725497480117455

Epoch: 6| Step: 3
Training loss: 3.4137462757583354
Validation loss: 2.6743669645811643

Epoch: 6| Step: 4
Training loss: 3.303303602401122
Validation loss: 2.67721272762315

Epoch: 6| Step: 5
Training loss: 2.7220342683674104
Validation loss: 2.6738962624864677

Epoch: 6| Step: 6
Training loss: 2.375994524278336
Validation loss: 2.674756477997143

Epoch: 6| Step: 7
Training loss: 2.937920885167339
Validation loss: 2.6726652774625417

Epoch: 6| Step: 8
Training loss: 2.830769351134728
Validation loss: 2.6821273544708273

Epoch: 6| Step: 9
Training loss: 2.8487263828585805
Validation loss: 2.671769390550881

Epoch: 6| Step: 10
Training loss: 3.035957220919527
Validation loss: 2.6808831618313773

Epoch: 6| Step: 11
Training loss: 2.924465724045704
Validation loss: 2.676165840133895

Epoch: 6| Step: 12
Training loss: 3.2635031199357796
Validation loss: 2.6720974267156152

Epoch: 6| Step: 13
Training loss: 3.29886469529944
Validation loss: 2.6705719800664576

Epoch: 138| Step: 0
Training loss: 3.183756256636548
Validation loss: 2.671890363329437

Epoch: 6| Step: 1
Training loss: 3.313949555698584
Validation loss: 2.668980192523076

Epoch: 6| Step: 2
Training loss: 2.848382718495348
Validation loss: 2.677992772123274

Epoch: 6| Step: 3
Training loss: 2.901405809287287
Validation loss: 2.667917426126475

Epoch: 6| Step: 4
Training loss: 2.695313207653893
Validation loss: 2.6721762680595194

Epoch: 6| Step: 5
Training loss: 2.4400441512819144
Validation loss: 2.6715923697878146

Epoch: 6| Step: 6
Training loss: 3.083337079295039
Validation loss: 2.6718860916956197

Epoch: 6| Step: 7
Training loss: 3.156251661847876
Validation loss: 2.6782899396335464

Epoch: 6| Step: 8
Training loss: 3.2867490193519395
Validation loss: 2.6802460744745087

Epoch: 6| Step: 9
Training loss: 2.831626115957276
Validation loss: 2.677514496184166

Epoch: 6| Step: 10
Training loss: 2.968027930537001
Validation loss: 2.689228425443422

Epoch: 6| Step: 11
Training loss: 2.868583484878346
Validation loss: 2.6840197710175526

Epoch: 6| Step: 12
Training loss: 2.673046725154807
Validation loss: 2.6812452996677427

Epoch: 6| Step: 13
Training loss: 3.8814241625153403
Validation loss: 2.672255949390654

Epoch: 139| Step: 0
Training loss: 3.0020538293331565
Validation loss: 2.671273509759418

Epoch: 6| Step: 1
Training loss: 2.9670549874348326
Validation loss: 2.665022045508291

Epoch: 6| Step: 2
Training loss: 2.6380514210279893
Validation loss: 2.66587683173543

Epoch: 6| Step: 3
Training loss: 3.288229938885273
Validation loss: 2.669964571566408

Epoch: 6| Step: 4
Training loss: 2.7661580579589677
Validation loss: 2.673537668612372

Epoch: 6| Step: 5
Training loss: 3.0426500028621417
Validation loss: 2.668546259050761

Epoch: 6| Step: 6
Training loss: 3.0687136770301326
Validation loss: 2.667862935950339

Epoch: 6| Step: 7
Training loss: 3.2794197427566556
Validation loss: 2.6665354720139836

Epoch: 6| Step: 8
Training loss: 2.839948187879291
Validation loss: 2.667120612894649

Epoch: 6| Step: 9
Training loss: 2.6590833026566747
Validation loss: 2.6714270901797117

Epoch: 6| Step: 10
Training loss: 3.100851520367782
Validation loss: 2.6720478669026266

Epoch: 6| Step: 11
Training loss: 2.872898660722775
Validation loss: 2.6710050047173066

Epoch: 6| Step: 12
Training loss: 3.431529460706591
Validation loss: 2.6858050302057146

Epoch: 6| Step: 13
Training loss: 2.8508691232132053
Validation loss: 2.6764020024459754

Epoch: 140| Step: 0
Training loss: 2.877153336550119
Validation loss: 2.6799647078044573

Epoch: 6| Step: 1
Training loss: 3.304864973348447
Validation loss: 2.675045062155079

Epoch: 6| Step: 2
Training loss: 3.1350604052405173
Validation loss: 2.678519148855993

Epoch: 6| Step: 3
Training loss: 2.752267769450469
Validation loss: 2.668890163230557

Epoch: 6| Step: 4
Training loss: 3.316221054531729
Validation loss: 2.667302758225528

Epoch: 6| Step: 5
Training loss: 2.4431702611541
Validation loss: 2.674180051729526

Epoch: 6| Step: 6
Training loss: 3.322879149285944
Validation loss: 2.6871795072093785

Epoch: 6| Step: 7
Training loss: 3.1790344917415756
Validation loss: 2.6943955630738654

Epoch: 6| Step: 8
Training loss: 3.369628587851836
Validation loss: 2.705143940099296

Epoch: 6| Step: 9
Training loss: 2.9731051974452036
Validation loss: 2.6890731780136607

Epoch: 6| Step: 10
Training loss: 2.419887588664494
Validation loss: 2.683013146762712

Epoch: 6| Step: 11
Training loss: 2.556654613156443
Validation loss: 2.669965710337004

Epoch: 6| Step: 12
Training loss: 3.2214840138364504
Validation loss: 2.6720349807785313

Epoch: 6| Step: 13
Training loss: 2.6754626898932803
Validation loss: 2.6714080937987146

Epoch: 141| Step: 0
Training loss: 2.9920979379342563
Validation loss: 2.673639802353073

Epoch: 6| Step: 1
Training loss: 3.246689504220631
Validation loss: 2.6666227812642465

Epoch: 6| Step: 2
Training loss: 3.262519783749283
Validation loss: 2.6698260460061194

Epoch: 6| Step: 3
Training loss: 2.7086418171796756
Validation loss: 2.659023569776903

Epoch: 6| Step: 4
Training loss: 3.1610786591264333
Validation loss: 2.6626619357433583

Epoch: 6| Step: 5
Training loss: 3.190581085470775
Validation loss: 2.6611654549393857

Epoch: 6| Step: 6
Training loss: 3.0310041190244954
Validation loss: 2.667770074461429

Epoch: 6| Step: 7
Training loss: 3.2843245860839287
Validation loss: 2.671160008526289

Epoch: 6| Step: 8
Training loss: 2.6229170755068396
Validation loss: 2.6769992165086496

Epoch: 6| Step: 9
Training loss: 2.935978109699104
Validation loss: 2.681654581565207

Epoch: 6| Step: 10
Training loss: 2.5154951547793254
Validation loss: 2.676920899326848

Epoch: 6| Step: 11
Training loss: 2.9340036565527723
Validation loss: 2.6797248347186415

Epoch: 6| Step: 12
Training loss: 2.7958882898272446
Validation loss: 2.6726881084224434

Epoch: 6| Step: 13
Training loss: 3.190049143206383
Validation loss: 2.667911664476696

Epoch: 142| Step: 0
Training loss: 3.0364189516177857
Validation loss: 2.666934439907303

Epoch: 6| Step: 1
Training loss: 2.7853331864105715
Validation loss: 2.6603630520035595

Epoch: 6| Step: 2
Training loss: 3.22823336660324
Validation loss: 2.66141510857641

Epoch: 6| Step: 3
Training loss: 2.1401618400768645
Validation loss: 2.6594706718871413

Epoch: 6| Step: 4
Training loss: 3.3869202233811677
Validation loss: 2.6615097348852594

Epoch: 6| Step: 5
Training loss: 2.2414558094033024
Validation loss: 2.660343322300517

Epoch: 6| Step: 6
Training loss: 2.5609552332768617
Validation loss: 2.6580826268642905

Epoch: 6| Step: 7
Training loss: 3.2257059729216913
Validation loss: 2.6622949532721707

Epoch: 6| Step: 8
Training loss: 2.9260703581918306
Validation loss: 2.6574971310917403

Epoch: 6| Step: 9
Training loss: 3.227674241921401
Validation loss: 2.656551843874003

Epoch: 6| Step: 10
Training loss: 3.1591058784364723
Validation loss: 2.655957844234399

Epoch: 6| Step: 11
Training loss: 3.1263095400698937
Validation loss: 2.6597356704267257

Epoch: 6| Step: 12
Training loss: 3.4483197640222243
Validation loss: 2.6595551940186404

Epoch: 6| Step: 13
Training loss: 3.1661296355647948
Validation loss: 2.65525702411489

Epoch: 143| Step: 0
Training loss: 3.354331555469882
Validation loss: 2.6599398537262378

Epoch: 6| Step: 1
Training loss: 2.7187692926533513
Validation loss: 2.6606466524851156

Epoch: 6| Step: 2
Training loss: 3.4277986438953527
Validation loss: 2.662032695107062

Epoch: 6| Step: 3
Training loss: 3.1973552563127545
Validation loss: 2.6576725470035387

Epoch: 6| Step: 4
Training loss: 3.1133440458888075
Validation loss: 2.6583461995571622

Epoch: 6| Step: 5
Training loss: 3.3833352757590847
Validation loss: 2.668226878393382

Epoch: 6| Step: 6
Training loss: 2.280978251954339
Validation loss: 2.669567650660283

Epoch: 6| Step: 7
Training loss: 3.0454082381973477
Validation loss: 2.6708905053535084

Epoch: 6| Step: 8
Training loss: 2.7268956371630733
Validation loss: 2.6784655845500764

Epoch: 6| Step: 9
Training loss: 2.1854585113252827
Validation loss: 2.670852066168109

Epoch: 6| Step: 10
Training loss: 2.71958998058082
Validation loss: 2.6741994214692015

Epoch: 6| Step: 11
Training loss: 2.917198314350436
Validation loss: 2.680060450723558

Epoch: 6| Step: 12
Training loss: 3.2922865046608525
Validation loss: 2.681466624060412

Epoch: 6| Step: 13
Training loss: 3.1915876320663954
Validation loss: 2.6937335068442105

Epoch: 144| Step: 0
Training loss: 3.499813074842411
Validation loss: 2.6967940743316006

Epoch: 6| Step: 1
Training loss: 3.1355174271286765
Validation loss: 2.68109811060568

Epoch: 6| Step: 2
Training loss: 3.246101535461858
Validation loss: 2.6874840753326263

Epoch: 6| Step: 3
Training loss: 2.766671365327943
Validation loss: 2.682209425964776

Epoch: 6| Step: 4
Training loss: 2.4424237137656313
Validation loss: 2.666511964412401

Epoch: 6| Step: 5
Training loss: 3.063056272472401
Validation loss: 2.6617743011962003

Epoch: 6| Step: 6
Training loss: 2.6830545963813495
Validation loss: 2.660735337195903

Epoch: 6| Step: 7
Training loss: 2.9350959192878046
Validation loss: 2.664566795352126

Epoch: 6| Step: 8
Training loss: 3.146683803231512
Validation loss: 2.6652842682692137

Epoch: 6| Step: 9
Training loss: 3.3362958300212946
Validation loss: 2.6686076578422693

Epoch: 6| Step: 10
Training loss: 2.368813941112696
Validation loss: 2.667958422269257

Epoch: 6| Step: 11
Training loss: 2.7934762773682613
Validation loss: 2.6705756672679097

Epoch: 6| Step: 12
Training loss: 3.2677816907880954
Validation loss: 2.671852091089133

Epoch: 6| Step: 13
Training loss: 3.102604227459335
Validation loss: 2.682290923877824

Epoch: 145| Step: 0
Training loss: 2.325546167683485
Validation loss: 2.6918166641073493

Epoch: 6| Step: 1
Training loss: 3.1496749225785066
Validation loss: 2.6813433211482387

Epoch: 6| Step: 2
Training loss: 3.132930001887772
Validation loss: 2.682466567243367

Epoch: 6| Step: 3
Training loss: 2.7375676290440913
Validation loss: 2.6941113540083266

Epoch: 6| Step: 4
Training loss: 3.6518405506468423
Validation loss: 2.685005970049198

Epoch: 6| Step: 5
Training loss: 2.719420777805497
Validation loss: 2.6824696646741435

Epoch: 6| Step: 6
Training loss: 2.6680346993244517
Validation loss: 2.6713292969610993

Epoch: 6| Step: 7
Training loss: 2.8642067031644465
Validation loss: 2.662111953942233

Epoch: 6| Step: 8
Training loss: 2.821701595347828
Validation loss: 2.6622428854244053

Epoch: 6| Step: 9
Training loss: 2.903633170107383
Validation loss: 2.666715145311336

Epoch: 6| Step: 10
Training loss: 2.984827296949481
Validation loss: 2.664339994098332

Epoch: 6| Step: 11
Training loss: 2.8934780578044985
Validation loss: 2.665332866959933

Epoch: 6| Step: 12
Training loss: 3.3179647605086977
Validation loss: 2.6704448985793934

Epoch: 6| Step: 13
Training loss: 3.684288954437814
Validation loss: 2.6754912020771973

Epoch: 146| Step: 0
Training loss: 3.047841236765591
Validation loss: 2.665534478676845

Epoch: 6| Step: 1
Training loss: 2.7893587697706765
Validation loss: 2.668877827635193

Epoch: 6| Step: 2
Training loss: 3.084306271298442
Validation loss: 2.6648636216242587

Epoch: 6| Step: 3
Training loss: 3.6808429693767106
Validation loss: 2.66148015784268

Epoch: 6| Step: 4
Training loss: 2.835004837058918
Validation loss: 2.6576198030589215

Epoch: 6| Step: 5
Training loss: 2.3202892777536372
Validation loss: 2.6605233810108504

Epoch: 6| Step: 6
Training loss: 2.6309463724479953
Validation loss: 2.665903875121464

Epoch: 6| Step: 7
Training loss: 2.5499973932888693
Validation loss: 2.6598080956306394

Epoch: 6| Step: 8
Training loss: 2.977092065035324
Validation loss: 2.667556069922479

Epoch: 6| Step: 9
Training loss: 3.30972605744303
Validation loss: 2.6579356800292295

Epoch: 6| Step: 10
Training loss: 3.367629303237433
Validation loss: 2.6611826565076515

Epoch: 6| Step: 11
Training loss: 2.651214404121227
Validation loss: 2.662081306933161

Epoch: 6| Step: 12
Training loss: 3.325183266773336
Validation loss: 2.6631797372309105

Epoch: 6| Step: 13
Training loss: 2.911315932684033
Validation loss: 2.6634443301621817

Epoch: 147| Step: 0
Training loss: 3.284193480726685
Validation loss: 2.673734541587822

Epoch: 6| Step: 1
Training loss: 2.761490139273838
Validation loss: 2.670007326980117

Epoch: 6| Step: 2
Training loss: 3.055458537401432
Validation loss: 2.667228124972968

Epoch: 6| Step: 3
Training loss: 3.3791131281501827
Validation loss: 2.6796480475672912

Epoch: 6| Step: 4
Training loss: 2.2834761744275913
Validation loss: 2.665608308203178

Epoch: 6| Step: 5
Training loss: 2.2818312231131217
Validation loss: 2.673395565297146

Epoch: 6| Step: 6
Training loss: 3.6972535017795165
Validation loss: 2.6655513534217605

Epoch: 6| Step: 7
Training loss: 2.635827576539222
Validation loss: 2.663674104640224

Epoch: 6| Step: 8
Training loss: 3.2596831222708116
Validation loss: 2.6525214609616707

Epoch: 6| Step: 9
Training loss: 3.1286724636637335
Validation loss: 2.659604265612926

Epoch: 6| Step: 10
Training loss: 2.9049356421270165
Validation loss: 2.6520456993598875

Epoch: 6| Step: 11
Training loss: 3.2180440184034658
Validation loss: 2.653446512735871

Epoch: 6| Step: 12
Training loss: 2.4251991347517596
Validation loss: 2.6551166797365107

Epoch: 6| Step: 13
Training loss: 3.180286997673833
Validation loss: 2.6520974154508865

Epoch: 148| Step: 0
Training loss: 2.8750378150111593
Validation loss: 2.656535873134216

Epoch: 6| Step: 1
Training loss: 2.5391295438864883
Validation loss: 2.6527180381398923

Epoch: 6| Step: 2
Training loss: 3.1722873363355504
Validation loss: 2.6497979817129678

Epoch: 6| Step: 3
Training loss: 2.690487465350563
Validation loss: 2.6487922359498834

Epoch: 6| Step: 4
Training loss: 3.0948395014793566
Validation loss: 2.6542676889208665

Epoch: 6| Step: 5
Training loss: 2.823997140634402
Validation loss: 2.655963522743856

Epoch: 6| Step: 6
Training loss: 2.6232903680671895
Validation loss: 2.6510099588055636

Epoch: 6| Step: 7
Training loss: 2.882169160673909
Validation loss: 2.656519066093514

Epoch: 6| Step: 8
Training loss: 3.156884006992648
Validation loss: 2.664137163235554

Epoch: 6| Step: 9
Training loss: 3.3484442728163684
Validation loss: 2.6623668350995637

Epoch: 6| Step: 10
Training loss: 3.4509922535670357
Validation loss: 2.666472758336663

Epoch: 6| Step: 11
Training loss: 2.696092487203368
Validation loss: 2.66864039713861

Epoch: 6| Step: 12
Training loss: 3.051364193365282
Validation loss: 2.666256850679731

Epoch: 6| Step: 13
Training loss: 3.442957897441839
Validation loss: 2.660455417523489

Epoch: 149| Step: 0
Training loss: 3.391380542305309
Validation loss: 2.6604680340353206

Epoch: 6| Step: 1
Training loss: 2.9940648178188765
Validation loss: 2.670764954689437

Epoch: 6| Step: 2
Training loss: 3.023589532070659
Validation loss: 2.670594553415993

Epoch: 6| Step: 3
Training loss: 2.2462821549718264
Validation loss: 2.6715834234897438

Epoch: 6| Step: 4
Training loss: 3.0270343843945082
Validation loss: 2.6636518037267125

Epoch: 6| Step: 5
Training loss: 2.9591948280151086
Validation loss: 2.67811041588076

Epoch: 6| Step: 6
Training loss: 2.9339932551914276
Validation loss: 2.665329862631229

Epoch: 6| Step: 7
Training loss: 2.4942148028808897
Validation loss: 2.6661043157395192

Epoch: 6| Step: 8
Training loss: 3.0832138210194713
Validation loss: 2.665138943028504

Epoch: 6| Step: 9
Training loss: 3.831746782015907
Validation loss: 2.6706816282162835

Epoch: 6| Step: 10
Training loss: 2.6347740405084745
Validation loss: 2.6601990898142196

Epoch: 6| Step: 11
Training loss: 3.0819407402643977
Validation loss: 2.6576495966963507

Epoch: 6| Step: 12
Training loss: 2.785264022475471
Validation loss: 2.659788557472876

Epoch: 6| Step: 13
Training loss: 2.9469510890809754
Validation loss: 2.663014382179221

Epoch: 150| Step: 0
Training loss: 3.287465049644896
Validation loss: 2.6464216114289707

Epoch: 6| Step: 1
Training loss: 3.0773001403120324
Validation loss: 2.65124926213708

Epoch: 6| Step: 2
Training loss: 2.555844479505349
Validation loss: 2.650099563585703

Epoch: 6| Step: 3
Training loss: 3.1279915795468995
Validation loss: 2.6569330793301047

Epoch: 6| Step: 4
Training loss: 2.6656568125070845
Validation loss: 2.644941511676215

Epoch: 6| Step: 5
Training loss: 2.671666187358519
Validation loss: 2.6505597001593126

Epoch: 6| Step: 6
Training loss: 2.774404953401537
Validation loss: 2.6489562857685938

Epoch: 6| Step: 7
Training loss: 3.684808427652452
Validation loss: 2.6542251773900905

Epoch: 6| Step: 8
Training loss: 3.3942567562888204
Validation loss: 2.6585380259628475

Epoch: 6| Step: 9
Training loss: 3.0221338739135084
Validation loss: 2.6563250092562813

Epoch: 6| Step: 10
Training loss: 2.5902149975770534
Validation loss: 2.6567102871908883

Epoch: 6| Step: 11
Training loss: 3.0285405900315667
Validation loss: 2.657343064921669

Epoch: 6| Step: 12
Training loss: 2.951689194504081
Validation loss: 2.654056175393059

Epoch: 6| Step: 13
Training loss: 2.3663383950208297
Validation loss: 2.653428876483753

Epoch: 151| Step: 0
Training loss: 3.077852653421986
Validation loss: 2.651111161792431

Epoch: 6| Step: 1
Training loss: 3.2744038687210844
Validation loss: 2.6582307537370826

Epoch: 6| Step: 2
Training loss: 2.793079037923016
Validation loss: 2.6540630470320394

Epoch: 6| Step: 3
Training loss: 2.2803637729697326
Validation loss: 2.648114907510114

Epoch: 6| Step: 4
Training loss: 3.664857562577227
Validation loss: 2.6462304829199046

Epoch: 6| Step: 5
Training loss: 2.8402873326404863
Validation loss: 2.6474916530463877

Epoch: 6| Step: 6
Training loss: 2.455095216726504
Validation loss: 2.6434047451329414

Epoch: 6| Step: 7
Training loss: 3.3002623020310113
Validation loss: 2.645791613891235

Epoch: 6| Step: 8
Training loss: 3.0532041884961427
Validation loss: 2.644172415209561

Epoch: 6| Step: 9
Training loss: 3.2289675415335695
Validation loss: 2.6554786657639347

Epoch: 6| Step: 10
Training loss: 2.8185114723663696
Validation loss: 2.6522827383059435

Epoch: 6| Step: 11
Training loss: 2.5398060810225687
Validation loss: 2.6530162210037505

Epoch: 6| Step: 12
Training loss: 3.0682611577214907
Validation loss: 2.6581193324055974

Epoch: 6| Step: 13
Training loss: 3.0814576672876175
Validation loss: 2.6567461992003816

Epoch: 152| Step: 0
Training loss: 2.898174263652895
Validation loss: 2.6668775994826097

Epoch: 6| Step: 1
Training loss: 2.9372108804174206
Validation loss: 2.6819693827632674

Epoch: 6| Step: 2
Training loss: 3.1498582535595294
Validation loss: 2.680276385613896

Epoch: 6| Step: 3
Training loss: 2.572538206448821
Validation loss: 2.6847489211181883

Epoch: 6| Step: 4
Training loss: 3.5844323151187387
Validation loss: 2.6587575495364955

Epoch: 6| Step: 5
Training loss: 2.7056858523111074
Validation loss: 2.6496946687145213

Epoch: 6| Step: 6
Training loss: 2.5250883105858546
Validation loss: 2.640924812311355

Epoch: 6| Step: 7
Training loss: 2.972386752731296
Validation loss: 2.6456694962018905

Epoch: 6| Step: 8
Training loss: 3.180077681162449
Validation loss: 2.64438687926807

Epoch: 6| Step: 9
Training loss: 3.363720447604674
Validation loss: 2.6508086659972507

Epoch: 6| Step: 10
Training loss: 3.3146794185142507
Validation loss: 2.650320465150481

Epoch: 6| Step: 11
Training loss: 3.289327216652063
Validation loss: 2.6519678391244836

Epoch: 6| Step: 12
Training loss: 2.7458283254050015
Validation loss: 2.6508091021667286

Epoch: 6| Step: 13
Training loss: 2.1170041613711335
Validation loss: 2.64919105607459

Epoch: 153| Step: 0
Training loss: 3.298365251625399
Validation loss: 2.6490111396925804

Epoch: 6| Step: 1
Training loss: 2.762961878074173
Validation loss: 2.647848980744662

Epoch: 6| Step: 2
Training loss: 3.245050623047748
Validation loss: 2.645952886881325

Epoch: 6| Step: 3
Training loss: 2.790106740844367
Validation loss: 2.644968127954551

Epoch: 6| Step: 4
Training loss: 3.2722926356956417
Validation loss: 2.6456071813345963

Epoch: 6| Step: 5
Training loss: 2.6734181013802534
Validation loss: 2.6434849940437872

Epoch: 6| Step: 6
Training loss: 2.7822886895540266
Validation loss: 2.646785556659114

Epoch: 6| Step: 7
Training loss: 3.207622961361865
Validation loss: 2.64484053836003

Epoch: 6| Step: 8
Training loss: 2.62740833068117
Validation loss: 2.64835879218925

Epoch: 6| Step: 9
Training loss: 3.2823667533193026
Validation loss: 2.6609290704688853

Epoch: 6| Step: 10
Training loss: 2.51890208350758
Validation loss: 2.6646924033041257

Epoch: 6| Step: 11
Training loss: 3.351442419359641
Validation loss: 2.667300578368247

Epoch: 6| Step: 12
Training loss: 3.077564788805733
Validation loss: 2.6659745807110857

Epoch: 6| Step: 13
Training loss: 2.4912134257999137
Validation loss: 2.6699302267467613

Epoch: 154| Step: 0
Training loss: 2.3114127618928353
Validation loss: 2.663774254815892

Epoch: 6| Step: 1
Training loss: 3.27244694910842
Validation loss: 2.6693265272923705

Epoch: 6| Step: 2
Training loss: 3.6557250338854077
Validation loss: 2.6766605818281173

Epoch: 6| Step: 3
Training loss: 3.1045425665344513
Validation loss: 2.6647410368405873

Epoch: 6| Step: 4
Training loss: 3.5941981823962936
Validation loss: 2.6650053708673167

Epoch: 6| Step: 5
Training loss: 2.28829557831753
Validation loss: 2.6687498633621534

Epoch: 6| Step: 6
Training loss: 2.414621430415476
Validation loss: 2.6507412735658145

Epoch: 6| Step: 7
Training loss: 3.334550412827564
Validation loss: 2.655709413246473

Epoch: 6| Step: 8
Training loss: 2.9108128978129493
Validation loss: 2.6489340854781322

Epoch: 6| Step: 9
Training loss: 3.2918028662466243
Validation loss: 2.6514891413955235

Epoch: 6| Step: 10
Training loss: 3.0042721211781696
Validation loss: 2.6617088911929425

Epoch: 6| Step: 11
Training loss: 2.91337663285168
Validation loss: 2.66242866430178

Epoch: 6| Step: 12
Training loss: 2.1263654473217826
Validation loss: 2.6666168908759875

Epoch: 6| Step: 13
Training loss: 2.931922487335012
Validation loss: 2.654361520182358

Epoch: 155| Step: 0
Training loss: 2.741208676132395
Validation loss: 2.654741159576012

Epoch: 6| Step: 1
Training loss: 3.0791882842410154
Validation loss: 2.654495520733087

Epoch: 6| Step: 2
Training loss: 3.056078503873613
Validation loss: 2.6474850103070984

Epoch: 6| Step: 3
Training loss: 3.1840316752099427
Validation loss: 2.6504106802791454

Epoch: 6| Step: 4
Training loss: 2.8863819220038103
Validation loss: 2.6501286775502555

Epoch: 6| Step: 5
Training loss: 3.1222028802594632
Validation loss: 2.653621889194117

Epoch: 6| Step: 6
Training loss: 2.67813091833825
Validation loss: 2.647073528866367

Epoch: 6| Step: 7
Training loss: 3.3987905033976906
Validation loss: 2.650574308817797

Epoch: 6| Step: 8
Training loss: 2.640005366291025
Validation loss: 2.6469119541732327

Epoch: 6| Step: 9
Training loss: 3.0779762813058276
Validation loss: 2.649104297789178

Epoch: 6| Step: 10
Training loss: 3.057667091276724
Validation loss: 2.651430618148927

Epoch: 6| Step: 11
Training loss: 2.6600121278414637
Validation loss: 2.6503116579186474

Epoch: 6| Step: 12
Training loss: 3.1922967758557723
Validation loss: 2.6540680775936876

Epoch: 6| Step: 13
Training loss: 2.673296277113611
Validation loss: 2.6564550041988335

Epoch: 156| Step: 0
Training loss: 3.0429223660617613
Validation loss: 2.652264349077877

Epoch: 6| Step: 1
Training loss: 3.081350427813165
Validation loss: 2.6538703880847945

Epoch: 6| Step: 2
Training loss: 3.087600298653964
Validation loss: 2.6501354268443893

Epoch: 6| Step: 3
Training loss: 3.542969019173777
Validation loss: 2.6504956538211304

Epoch: 6| Step: 4
Training loss: 2.329073719042167
Validation loss: 2.657138667604161

Epoch: 6| Step: 5
Training loss: 3.778173535006051
Validation loss: 2.6592835478387347

Epoch: 6| Step: 6
Training loss: 1.8708511227085505
Validation loss: 2.654941577760276

Epoch: 6| Step: 7
Training loss: 2.894419885467323
Validation loss: 2.65977332183188

Epoch: 6| Step: 8
Training loss: 2.6627750809816764
Validation loss: 2.6742817966584127

Epoch: 6| Step: 9
Training loss: 2.4384917173575427
Validation loss: 2.6786679104306206

Epoch: 6| Step: 10
Training loss: 2.5945743951193774
Validation loss: 2.6951527176468537

Epoch: 6| Step: 11
Training loss: 3.4442092616962885
Validation loss: 2.7124487395943846

Epoch: 6| Step: 12
Training loss: 3.26788689795593
Validation loss: 2.699610424383264

Epoch: 6| Step: 13
Training loss: 3.3062027868350397
Validation loss: 2.699615248517396

Epoch: 157| Step: 0
Training loss: 2.470220972593825
Validation loss: 2.6946697460882607

Epoch: 6| Step: 1
Training loss: 2.934304954984682
Validation loss: 2.698442584035123

Epoch: 6| Step: 2
Training loss: 3.147044742252835
Validation loss: 2.6947097682221512

Epoch: 6| Step: 3
Training loss: 2.9634538491126046
Validation loss: 2.703042249985528

Epoch: 6| Step: 4
Training loss: 2.507642888783412
Validation loss: 2.696684801543751

Epoch: 6| Step: 5
Training loss: 2.3800639325057933
Validation loss: 2.709481519548295

Epoch: 6| Step: 6
Training loss: 3.757656926921926
Validation loss: 2.6969854341159456

Epoch: 6| Step: 7
Training loss: 3.677489577952229
Validation loss: 2.700603150208728

Epoch: 6| Step: 8
Training loss: 2.215553667779133
Validation loss: 2.6891138411455437

Epoch: 6| Step: 9
Training loss: 2.9304911007253827
Validation loss: 2.689595326420203

Epoch: 6| Step: 10
Training loss: 3.464397827491656
Validation loss: 2.6806670386451055

Epoch: 6| Step: 11
Training loss: 3.4391927539331166
Validation loss: 2.6741867930475665

Epoch: 6| Step: 12
Training loss: 2.7640299534754895
Validation loss: 2.662877098495763

Epoch: 6| Step: 13
Training loss: 2.7001565499308593
Validation loss: 2.640912968335568

Epoch: 158| Step: 0
Training loss: 3.7376079530977524
Validation loss: 2.633086163437277

Epoch: 6| Step: 1
Training loss: 2.4178306034786474
Validation loss: 2.629918364618595

Epoch: 6| Step: 2
Training loss: 3.534576199822762
Validation loss: 2.6352335989382407

Epoch: 6| Step: 3
Training loss: 2.825460538206153
Validation loss: 2.6385299547173537

Epoch: 6| Step: 4
Training loss: 2.639775788583049
Validation loss: 2.6377201343624104

Epoch: 6| Step: 5
Training loss: 2.867280631150958
Validation loss: 2.6340446180432147

Epoch: 6| Step: 6
Training loss: 2.5291978971343174
Validation loss: 2.633315025656402

Epoch: 6| Step: 7
Training loss: 3.1968228004944583
Validation loss: 2.640439659934998

Epoch: 6| Step: 8
Training loss: 2.6190913776771523
Validation loss: 2.652637655877697

Epoch: 6| Step: 9
Training loss: 3.0721551156221523
Validation loss: 2.650724500385929

Epoch: 6| Step: 10
Training loss: 2.9815225600560273
Validation loss: 2.66326157633763

Epoch: 6| Step: 11
Training loss: 2.563799644819075
Validation loss: 2.6542988791286115

Epoch: 6| Step: 12
Training loss: 2.845449086764881
Validation loss: 2.6702994903330297

Epoch: 6| Step: 13
Training loss: 3.844704114147381
Validation loss: 2.6717659918964394

Epoch: 159| Step: 0
Training loss: 2.668757354225907
Validation loss: 2.6644073735593556

Epoch: 6| Step: 1
Training loss: 2.6853852934345075
Validation loss: 2.6488862021309454

Epoch: 6| Step: 2
Training loss: 2.829349484574038
Validation loss: 2.639079875399857

Epoch: 6| Step: 3
Training loss: 3.250885476016316
Validation loss: 2.6383009249273237

Epoch: 6| Step: 4
Training loss: 2.7606844982034087
Validation loss: 2.632289068728168

Epoch: 6| Step: 5
Training loss: 2.673309119757809
Validation loss: 2.636529211890944

Epoch: 6| Step: 6
Training loss: 2.6036498714099534
Validation loss: 2.6356222469820056

Epoch: 6| Step: 7
Training loss: 2.726888030548053
Validation loss: 2.6349499787093613

Epoch: 6| Step: 8
Training loss: 2.9201380825054213
Validation loss: 2.634948001700398

Epoch: 6| Step: 9
Training loss: 4.060358275216624
Validation loss: 2.6298696486093425

Epoch: 6| Step: 10
Training loss: 3.233262465051007
Validation loss: 2.6373376861395417

Epoch: 6| Step: 11
Training loss: 2.685387956945715
Validation loss: 2.631121314554679

Epoch: 6| Step: 12
Training loss: 2.730172377234013
Validation loss: 2.639622009899434

Epoch: 6| Step: 13
Training loss: 3.695340759298328
Validation loss: 2.6355497777408687

Epoch: 160| Step: 0
Training loss: 3.1089842277610216
Validation loss: 2.642006923332141

Epoch: 6| Step: 1
Training loss: 2.9809937820855996
Validation loss: 2.6528784904703766

Epoch: 6| Step: 2
Training loss: 2.436930663301535
Validation loss: 2.6475408378484313

Epoch: 6| Step: 3
Training loss: 2.797767198499023
Validation loss: 2.6637735589940075

Epoch: 6| Step: 4
Training loss: 2.7085035319524464
Validation loss: 2.6397021902541766

Epoch: 6| Step: 5
Training loss: 3.1058955828916996
Validation loss: 2.659745598273902

Epoch: 6| Step: 6
Training loss: 3.560994147887506
Validation loss: 2.647807856238545

Epoch: 6| Step: 7
Training loss: 3.4105361429739665
Validation loss: 2.6591557706946816

Epoch: 6| Step: 8
Training loss: 3.174915829241165
Validation loss: 2.6666295219790275

Epoch: 6| Step: 9
Training loss: 3.4907052736947435
Validation loss: 2.6486238561727697

Epoch: 6| Step: 10
Training loss: 2.641623765213994
Validation loss: 2.6455124271323975

Epoch: 6| Step: 11
Training loss: 2.1189901975339276
Validation loss: 2.634352947017217

Epoch: 6| Step: 12
Training loss: 2.8809994007283426
Validation loss: 2.6316172592254183

Epoch: 6| Step: 13
Training loss: 2.650806189210895
Validation loss: 2.6386478675252993

Epoch: 161| Step: 0
Training loss: 2.625783076877293
Validation loss: 2.62683293249504

Epoch: 6| Step: 1
Training loss: 3.3011527851181564
Validation loss: 2.639793863722748

Epoch: 6| Step: 2
Training loss: 2.5118638822827273
Validation loss: 2.6283011395934364

Epoch: 6| Step: 3
Training loss: 2.9765737137871118
Validation loss: 2.628759048261672

Epoch: 6| Step: 4
Training loss: 3.364098213739755
Validation loss: 2.6255154696867486

Epoch: 6| Step: 5
Training loss: 2.2999168546823925
Validation loss: 2.6309571280482573

Epoch: 6| Step: 6
Training loss: 2.854567525145488
Validation loss: 2.6268719338372635

Epoch: 6| Step: 7
Training loss: 2.3356478202099025
Validation loss: 2.628074703789021

Epoch: 6| Step: 8
Training loss: 3.0491598316611928
Validation loss: 2.635216216311527

Epoch: 6| Step: 9
Training loss: 3.313576577338559
Validation loss: 2.635479214054245

Epoch: 6| Step: 10
Training loss: 2.4892727539763424
Validation loss: 2.631796696059652

Epoch: 6| Step: 11
Training loss: 3.0505342859787103
Validation loss: 2.652510002208378

Epoch: 6| Step: 12
Training loss: 3.4778005388657305
Validation loss: 2.6505113335508277

Epoch: 6| Step: 13
Training loss: 3.837945540717161
Validation loss: 2.651554597567325

Epoch: 162| Step: 0
Training loss: 3.2941967539945636
Validation loss: 2.6595310502074483

Epoch: 6| Step: 1
Training loss: 3.0063414307964007
Validation loss: 2.652608962799958

Epoch: 6| Step: 2
Training loss: 2.9400038092452303
Validation loss: 2.6505294341363372

Epoch: 6| Step: 3
Training loss: 2.235369907635513
Validation loss: 2.6378994826044373

Epoch: 6| Step: 4
Training loss: 2.6904426255927567
Validation loss: 2.634618665008171

Epoch: 6| Step: 5
Training loss: 2.1442630787757775
Validation loss: 2.637799300537625

Epoch: 6| Step: 6
Training loss: 3.3903764906139715
Validation loss: 2.6355353756729287

Epoch: 6| Step: 7
Training loss: 3.151383377757063
Validation loss: 2.63562212928664

Epoch: 6| Step: 8
Training loss: 3.0734406277786577
Validation loss: 2.6299515943167835

Epoch: 6| Step: 9
Training loss: 2.963179330961345
Validation loss: 2.6320580933164046

Epoch: 6| Step: 10
Training loss: 3.5981452932575695
Validation loss: 2.636027861106807

Epoch: 6| Step: 11
Training loss: 3.035306909619437
Validation loss: 2.623764162238236

Epoch: 6| Step: 12
Training loss: 2.9579106060187557
Validation loss: 2.6247900680140805

Epoch: 6| Step: 13
Training loss: 2.1659993342207486
Validation loss: 2.622568411596049

Epoch: 163| Step: 0
Training loss: 3.3451302790111375
Validation loss: 2.6278222397423803

Epoch: 6| Step: 1
Training loss: 2.8452742966292517
Validation loss: 2.6284899796870134

Epoch: 6| Step: 2
Training loss: 3.117415417439212
Validation loss: 2.6249674225175905

Epoch: 6| Step: 3
Training loss: 2.8512865743001314
Validation loss: 2.6280985044764744

Epoch: 6| Step: 4
Training loss: 2.8324885137313305
Validation loss: 2.629581852374291

Epoch: 6| Step: 5
Training loss: 2.9873773142630373
Validation loss: 2.6340607850069855

Epoch: 6| Step: 6
Training loss: 2.8870822951159485
Validation loss: 2.629507765933606

Epoch: 6| Step: 7
Training loss: 2.798945507668025
Validation loss: 2.632774090084304

Epoch: 6| Step: 8
Training loss: 2.4585725592471848
Validation loss: 2.636151216075251

Epoch: 6| Step: 9
Training loss: 3.03240724476778
Validation loss: 2.63245086995539

Epoch: 6| Step: 10
Training loss: 3.168982328366247
Validation loss: 2.634805237203142

Epoch: 6| Step: 11
Training loss: 2.717958356986004
Validation loss: 2.622291254343506

Epoch: 6| Step: 12
Training loss: 3.325389041942828
Validation loss: 2.6269289430901344

Epoch: 6| Step: 13
Training loss: 2.9891546032799257
Validation loss: 2.621806794963828

Epoch: 164| Step: 0
Training loss: 2.191567916482661
Validation loss: 2.621271048476923

Epoch: 6| Step: 1
Training loss: 2.5222505311128827
Validation loss: 2.6200753478780876

Epoch: 6| Step: 2
Training loss: 2.8874289499764507
Validation loss: 2.6195481109935277

Epoch: 6| Step: 3
Training loss: 3.078627492098942
Validation loss: 2.621702350563729

Epoch: 6| Step: 4
Training loss: 3.093787607291943
Validation loss: 2.6275947723729707

Epoch: 6| Step: 5
Training loss: 3.172822857624462
Validation loss: 2.6264933368440007

Epoch: 6| Step: 6
Training loss: 2.4315204146365774
Validation loss: 2.633317805115024

Epoch: 6| Step: 7
Training loss: 3.1769771037034644
Validation loss: 2.63848959926706

Epoch: 6| Step: 8
Training loss: 3.662613767347664
Validation loss: 2.6412151871510927

Epoch: 6| Step: 9
Training loss: 3.2278897786000265
Validation loss: 2.63718713365543

Epoch: 6| Step: 10
Training loss: 3.139501569999962
Validation loss: 2.655875240481169

Epoch: 6| Step: 11
Training loss: 2.714364032762731
Validation loss: 2.6519580551993727

Epoch: 6| Step: 12
Training loss: 2.9789648098795958
Validation loss: 2.664218844953146

Epoch: 6| Step: 13
Training loss: 2.70505873470036
Validation loss: 2.677685848205151

Epoch: 165| Step: 0
Training loss: 2.814091804178131
Validation loss: 2.6689368712219315

Epoch: 6| Step: 1
Training loss: 3.1872067784095597
Validation loss: 2.6644409746125004

Epoch: 6| Step: 2
Training loss: 2.1753911159992265
Validation loss: 2.6565596909683813

Epoch: 6| Step: 3
Training loss: 2.6433658257596404
Validation loss: 2.635647608751659

Epoch: 6| Step: 4
Training loss: 3.6825620272320765
Validation loss: 2.6245835594576445

Epoch: 6| Step: 5
Training loss: 3.0555140945241828
Validation loss: 2.6251762534102787

Epoch: 6| Step: 6
Training loss: 2.601816159274163
Validation loss: 2.6228247994509886

Epoch: 6| Step: 7
Training loss: 2.9943008330222427
Validation loss: 2.619499564723375

Epoch: 6| Step: 8
Training loss: 2.751098933424914
Validation loss: 2.622791042540207

Epoch: 6| Step: 9
Training loss: 3.135924204221783
Validation loss: 2.624851739254363

Epoch: 6| Step: 10
Training loss: 3.395192528548006
Validation loss: 2.6223304082859853

Epoch: 6| Step: 11
Training loss: 3.076603702329327
Validation loss: 2.624279356918975

Epoch: 6| Step: 12
Training loss: 2.818579397515507
Validation loss: 2.6225454199776843

Epoch: 6| Step: 13
Training loss: 2.6979716134582232
Validation loss: 2.6284447562511835

Epoch: 166| Step: 0
Training loss: 2.784836845755386
Validation loss: 2.6216795038966465

Epoch: 6| Step: 1
Training loss: 2.7835189479527638
Validation loss: 2.625166037602165

Epoch: 6| Step: 2
Training loss: 2.6355552988693742
Validation loss: 2.631099727678026

Epoch: 6| Step: 3
Training loss: 2.3911339710439625
Validation loss: 2.6298773184553053

Epoch: 6| Step: 4
Training loss: 3.1409089069243445
Validation loss: 2.641514820866429

Epoch: 6| Step: 5
Training loss: 2.992890676238367
Validation loss: 2.6362205705011537

Epoch: 6| Step: 6
Training loss: 2.792190976986591
Validation loss: 2.643896376565034

Epoch: 6| Step: 7
Training loss: 3.4015324673183267
Validation loss: 2.633874757218917

Epoch: 6| Step: 8
Training loss: 2.6328146733577826
Validation loss: 2.6246334939279605

Epoch: 6| Step: 9
Training loss: 3.2143121143044064
Validation loss: 2.621176276197552

Epoch: 6| Step: 10
Training loss: 3.3257389021998507
Validation loss: 2.618799105766372

Epoch: 6| Step: 11
Training loss: 3.0091094948651174
Validation loss: 2.619701158782759

Epoch: 6| Step: 12
Training loss: 2.970202923659399
Validation loss: 2.6198958979198137

Epoch: 6| Step: 13
Training loss: 3.523859172211082
Validation loss: 2.6195681225074465

Epoch: 167| Step: 0
Training loss: 2.065343341871276
Validation loss: 2.6236112723149283

Epoch: 6| Step: 1
Training loss: 2.522999066982029
Validation loss: 2.6260393978634524

Epoch: 6| Step: 2
Training loss: 2.6267205004169725
Validation loss: 2.62665124846604

Epoch: 6| Step: 3
Training loss: 2.9252295183951853
Validation loss: 2.6301461495807943

Epoch: 6| Step: 4
Training loss: 3.1851992812161014
Validation loss: 2.632837673643962

Epoch: 6| Step: 5
Training loss: 2.8386547007788576
Validation loss: 2.62624409732621

Epoch: 6| Step: 6
Training loss: 3.6696401734619086
Validation loss: 2.6340342264025907

Epoch: 6| Step: 7
Training loss: 3.4447376697246797
Validation loss: 2.62425508882611

Epoch: 6| Step: 8
Training loss: 2.706761114120039
Validation loss: 2.6223460863187156

Epoch: 6| Step: 9
Training loss: 2.3413880717577724
Validation loss: 2.6268916241080156

Epoch: 6| Step: 10
Training loss: 3.157555640569302
Validation loss: 2.6222309991455486

Epoch: 6| Step: 11
Training loss: 3.0379465599056026
Validation loss: 2.624380684185925

Epoch: 6| Step: 12
Training loss: 3.454885732966641
Validation loss: 2.6314900686132865

Epoch: 6| Step: 13
Training loss: 3.1911281805399527
Validation loss: 2.643529554815267

Epoch: 168| Step: 0
Training loss: 3.6823903258981203
Validation loss: 2.6463715988666694

Epoch: 6| Step: 1
Training loss: 3.1094774392280704
Validation loss: 2.6438160063260017

Epoch: 6| Step: 2
Training loss: 2.952845807476566
Validation loss: 2.6436938119250435

Epoch: 6| Step: 3
Training loss: 3.199959432821626
Validation loss: 2.637911546141602

Epoch: 6| Step: 4
Training loss: 2.6633378550746123
Validation loss: 2.643104219941257

Epoch: 6| Step: 5
Training loss: 3.4530233653029523
Validation loss: 2.64040224742906

Epoch: 6| Step: 6
Training loss: 2.4833156798415845
Validation loss: 2.637025336242844

Epoch: 6| Step: 7
Training loss: 2.769655297518363
Validation loss: 2.640899015848442

Epoch: 6| Step: 8
Training loss: 2.5039786151301886
Validation loss: 2.6429028235888095

Epoch: 6| Step: 9
Training loss: 2.7222803805965787
Validation loss: 2.6518117096272484

Epoch: 6| Step: 10
Training loss: 2.7239214941467043
Validation loss: 2.646072803835626

Epoch: 6| Step: 11
Training loss: 3.120518942982199
Validation loss: 2.6636151840494473

Epoch: 6| Step: 12
Training loss: 2.6370800533707244
Validation loss: 2.652595500943528

Epoch: 6| Step: 13
Training loss: 3.1465268075971853
Validation loss: 2.6411683655237943

Epoch: 169| Step: 0
Training loss: 2.91572061363522
Validation loss: 2.629561215116747

Epoch: 6| Step: 1
Training loss: 3.131252290340355
Validation loss: 2.6254569279542768

Epoch: 6| Step: 2
Training loss: 3.056870560940187
Validation loss: 2.620469676007464

Epoch: 6| Step: 3
Training loss: 2.6925133364603044
Validation loss: 2.6124045774038303

Epoch: 6| Step: 4
Training loss: 2.9365435727402462
Validation loss: 2.6148421133284128

Epoch: 6| Step: 5
Training loss: 2.570819932190658
Validation loss: 2.6143836537691847

Epoch: 6| Step: 6
Training loss: 2.5468250105930954
Validation loss: 2.6114372193630344

Epoch: 6| Step: 7
Training loss: 3.068027723662089
Validation loss: 2.6142022112032843

Epoch: 6| Step: 8
Training loss: 3.3555443503197644
Validation loss: 2.6099373374413113

Epoch: 6| Step: 9
Training loss: 2.844944797241772
Validation loss: 2.6155342190484365

Epoch: 6| Step: 10
Training loss: 3.036820474603447
Validation loss: 2.6113044964175254

Epoch: 6| Step: 11
Training loss: 3.2677856306459954
Validation loss: 2.6134612336005216

Epoch: 6| Step: 12
Training loss: 3.0779967305523597
Validation loss: 2.610437890110484

Epoch: 6| Step: 13
Training loss: 2.674115139789847
Validation loss: 2.617125423835767

Epoch: 170| Step: 0
Training loss: 2.857251155026949
Validation loss: 2.622153981184777

Epoch: 6| Step: 1
Training loss: 3.1222267052047723
Validation loss: 2.621491087574565

Epoch: 6| Step: 2
Training loss: 2.386900350151882
Validation loss: 2.6180229400044848

Epoch: 6| Step: 3
Training loss: 3.4550149155997287
Validation loss: 2.619428676813433

Epoch: 6| Step: 4
Training loss: 3.5954417351776304
Validation loss: 2.6269741526091974

Epoch: 6| Step: 5
Training loss: 2.750631780011455
Validation loss: 2.616411271599036

Epoch: 6| Step: 6
Training loss: 2.1618169157723175
Validation loss: 2.6306337694576682

Epoch: 6| Step: 7
Training loss: 3.024133882979968
Validation loss: 2.626238143705229

Epoch: 6| Step: 8
Training loss: 2.0604583576588587
Validation loss: 2.6211572325229247

Epoch: 6| Step: 9
Training loss: 3.5378027688660776
Validation loss: 2.6326928466801727

Epoch: 6| Step: 10
Training loss: 3.1670421745785267
Validation loss: 2.621550610700087

Epoch: 6| Step: 11
Training loss: 3.408480272802025
Validation loss: 2.635793203192775

Epoch: 6| Step: 12
Training loss: 2.5950857193153527
Validation loss: 2.615206700799017

Epoch: 6| Step: 13
Training loss: 2.3786537775572865
Validation loss: 2.6235905646409963

Epoch: 171| Step: 0
Training loss: 3.3599586157293757
Validation loss: 2.619464517621874

Epoch: 6| Step: 1
Training loss: 2.884410549618414
Validation loss: 2.6165724213855976

Epoch: 6| Step: 2
Training loss: 2.6306027157656016
Validation loss: 2.6081684312887643

Epoch: 6| Step: 3
Training loss: 2.6940932017617825
Validation loss: 2.6128413825614354

Epoch: 6| Step: 4
Training loss: 2.7546084543572444
Validation loss: 2.611604477540972

Epoch: 6| Step: 5
Training loss: 3.2006206864169817
Validation loss: 2.612623639190471

Epoch: 6| Step: 6
Training loss: 2.6380923613892784
Validation loss: 2.607292789245636

Epoch: 6| Step: 7
Training loss: 3.6493493845870844
Validation loss: 2.612917450555071

Epoch: 6| Step: 8
Training loss: 3.158039454440172
Validation loss: 2.6128399294487963

Epoch: 6| Step: 9
Training loss: 2.8350440265123193
Validation loss: 2.6096916318558874

Epoch: 6| Step: 10
Training loss: 2.904688918352935
Validation loss: 2.6102095167162283

Epoch: 6| Step: 11
Training loss: 2.4407446369150123
Validation loss: 2.611462733548915

Epoch: 6| Step: 12
Training loss: 2.589893645529447
Validation loss: 2.611836517737331

Epoch: 6| Step: 13
Training loss: 3.6347639195572974
Validation loss: 2.6098477536665476

Epoch: 172| Step: 0
Training loss: 3.464326254336386
Validation loss: 2.6103053167064005

Epoch: 6| Step: 1
Training loss: 2.717699571456227
Validation loss: 2.6183838506315245

Epoch: 6| Step: 2
Training loss: 2.470502979479817
Validation loss: 2.6177044111434418

Epoch: 6| Step: 3
Training loss: 3.0696846900079713
Validation loss: 2.6237219918873524

Epoch: 6| Step: 4
Training loss: 2.451644645175365
Validation loss: 2.6284768429574563

Epoch: 6| Step: 5
Training loss: 3.086177613779535
Validation loss: 2.6226171214889824

Epoch: 6| Step: 6
Training loss: 3.5117000116817922
Validation loss: 2.6268510069072493

Epoch: 6| Step: 7
Training loss: 3.6664506819719422
Validation loss: 2.6245021494457017

Epoch: 6| Step: 8
Training loss: 3.434030620049634
Validation loss: 2.6317100978665544

Epoch: 6| Step: 9
Training loss: 2.692672719418639
Validation loss: 2.6289753635631246

Epoch: 6| Step: 10
Training loss: 2.294869721814312
Validation loss: 2.614068725900981

Epoch: 6| Step: 11
Training loss: 2.156273440910855
Validation loss: 2.615414179103933

Epoch: 6| Step: 12
Training loss: 2.340892321163758
Validation loss: 2.6191639939808535

Epoch: 6| Step: 13
Training loss: 3.559862465505575
Validation loss: 2.6149316309048714

Epoch: 173| Step: 0
Training loss: 3.09777893362232
Validation loss: 2.615662897099368

Epoch: 6| Step: 1
Training loss: 2.5973299438205095
Validation loss: 2.6202865723849955

Epoch: 6| Step: 2
Training loss: 3.189747336016907
Validation loss: 2.6112023632686463

Epoch: 6| Step: 3
Training loss: 2.509365373452844
Validation loss: 2.606520868835157

Epoch: 6| Step: 4
Training loss: 2.8777083204013447
Validation loss: 2.6099146520162853

Epoch: 6| Step: 5
Training loss: 3.4326292729605883
Validation loss: 2.609004050754607

Epoch: 6| Step: 6
Training loss: 3.0470652985444455
Validation loss: 2.6097914980027075

Epoch: 6| Step: 7
Training loss: 3.2227084808740853
Validation loss: 2.608783919508371

Epoch: 6| Step: 8
Training loss: 3.41610663561582
Validation loss: 2.6094620495908223

Epoch: 6| Step: 9
Training loss: 2.8423149763966746
Validation loss: 2.608316791629663

Epoch: 6| Step: 10
Training loss: 2.659956377001561
Validation loss: 2.606795661836467

Epoch: 6| Step: 11
Training loss: 2.698481015913102
Validation loss: 2.606958691297437

Epoch: 6| Step: 12
Training loss: 2.983338980074463
Validation loss: 2.613042355658733

Epoch: 6| Step: 13
Training loss: 2.01679237331233
Validation loss: 2.613248673580912

Epoch: 174| Step: 0
Training loss: 3.2516454785971742
Validation loss: 2.611464442666502

Epoch: 6| Step: 1
Training loss: 2.2539574470192716
Validation loss: 2.6133243029893367

Epoch: 6| Step: 2
Training loss: 3.244227344472343
Validation loss: 2.622618923043632

Epoch: 6| Step: 3
Training loss: 1.8085864995889362
Validation loss: 2.623449155548087

Epoch: 6| Step: 4
Training loss: 3.098915181006454
Validation loss: 2.629057614078191

Epoch: 6| Step: 5
Training loss: 2.8108013533593716
Validation loss: 2.6183004903272344

Epoch: 6| Step: 6
Training loss: 3.2427401519759957
Validation loss: 2.633598044182629

Epoch: 6| Step: 7
Training loss: 2.622333989302781
Validation loss: 2.6291739440222326

Epoch: 6| Step: 8
Training loss: 3.25817854400608
Validation loss: 2.626895298450784

Epoch: 6| Step: 9
Training loss: 2.9917227680468006
Validation loss: 2.625316109597284

Epoch: 6| Step: 10
Training loss: 3.3587146198665163
Validation loss: 2.6297221498447163

Epoch: 6| Step: 11
Training loss: 3.1322036113398863
Validation loss: 2.6268415246879284

Epoch: 6| Step: 12
Training loss: 2.853281668198247
Validation loss: 2.6245994789692224

Epoch: 6| Step: 13
Training loss: 2.94981481326475
Validation loss: 2.631738449909904

Epoch: 175| Step: 0
Training loss: 3.3188401491956623
Validation loss: 2.622450229404723

Epoch: 6| Step: 1
Training loss: 2.861915335436573
Validation loss: 2.6222672435467786

Epoch: 6| Step: 2
Training loss: 2.949177035611448
Validation loss: 2.6217637081927454

Epoch: 6| Step: 3
Training loss: 3.282928909205984
Validation loss: 2.6136125102963628

Epoch: 6| Step: 4
Training loss: 3.2139084337219566
Validation loss: 2.6146529356382735

Epoch: 6| Step: 5
Training loss: 3.1196904662228118
Validation loss: 2.61406924665739

Epoch: 6| Step: 6
Training loss: 2.233055952506324
Validation loss: 2.6151156927548582

Epoch: 6| Step: 7
Training loss: 2.302571815919812
Validation loss: 2.61465680758978

Epoch: 6| Step: 8
Training loss: 2.725142232000258
Validation loss: 2.612394124216403

Epoch: 6| Step: 9
Training loss: 2.690172153338817
Validation loss: 2.6215994050227387

Epoch: 6| Step: 10
Training loss: 3.2634115063893154
Validation loss: 2.6133712752312483

Epoch: 6| Step: 11
Training loss: 3.5405761984738735
Validation loss: 2.6182846568664764

Epoch: 6| Step: 12
Training loss: 2.524970566228653
Validation loss: 2.614251075508042

Epoch: 6| Step: 13
Training loss: 2.8366676420515677
Validation loss: 2.6180577571937937

Epoch: 176| Step: 0
Training loss: 3.0208808281332784
Validation loss: 2.619303624068293

Epoch: 6| Step: 1
Training loss: 2.7787287567740657
Validation loss: 2.616009280764416

Epoch: 6| Step: 2
Training loss: 3.3881950988442253
Validation loss: 2.6250211165009016

Epoch: 6| Step: 3
Training loss: 2.8527690686327474
Validation loss: 2.6345798698146248

Epoch: 6| Step: 4
Training loss: 2.8698335749525277
Validation loss: 2.641487521963602

Epoch: 6| Step: 5
Training loss: 3.022713507974903
Validation loss: 2.655909757399878

Epoch: 6| Step: 6
Training loss: 2.796732637842023
Validation loss: 2.6573910341712845

Epoch: 6| Step: 7
Training loss: 3.0668344769658575
Validation loss: 2.680089967156092

Epoch: 6| Step: 8
Training loss: 2.1758522556299815
Validation loss: 2.6853107006824195

Epoch: 6| Step: 9
Training loss: 3.2846316396111406
Validation loss: 2.6911144861958456

Epoch: 6| Step: 10
Training loss: 3.022514892490952
Validation loss: 2.689384974622465

Epoch: 6| Step: 11
Training loss: 2.974290195706183
Validation loss: 2.6772334552813617

Epoch: 6| Step: 12
Training loss: 2.551972325823699
Validation loss: 2.683592427862656

Epoch: 6| Step: 13
Training loss: 3.6470335519772843
Validation loss: 2.659560807975191

Epoch: 177| Step: 0
Training loss: 3.269191418924462
Validation loss: 2.647631563080698

Epoch: 6| Step: 1
Training loss: 2.759958788246191
Validation loss: 2.6451029101567807

Epoch: 6| Step: 2
Training loss: 3.6380068815815303
Validation loss: 2.6296685206531105

Epoch: 6| Step: 3
Training loss: 2.7150769908800467
Validation loss: 2.622149831886321

Epoch: 6| Step: 4
Training loss: 2.252958789467165
Validation loss: 2.610730236879876

Epoch: 6| Step: 5
Training loss: 3.523073706274643
Validation loss: 2.607971546907327

Epoch: 6| Step: 6
Training loss: 2.7148960904352033
Validation loss: 2.6051100651749644

Epoch: 6| Step: 7
Training loss: 3.5692477652413226
Validation loss: 2.604382073794449

Epoch: 6| Step: 8
Training loss: 2.4513601770301516
Validation loss: 2.6029727548499566

Epoch: 6| Step: 9
Training loss: 2.7809501229113414
Validation loss: 2.6014104604892005

Epoch: 6| Step: 10
Training loss: 2.843579968410096
Validation loss: 2.601924812008939

Epoch: 6| Step: 11
Training loss: 2.4275357939323476
Validation loss: 2.597276581509812

Epoch: 6| Step: 12
Training loss: 3.1955745375058706
Validation loss: 2.6040194096102804

Epoch: 6| Step: 13
Training loss: 2.4946440544870616
Validation loss: 2.6078132080402754

Epoch: 178| Step: 0
Training loss: 3.03629645847978
Validation loss: 2.605872591158597

Epoch: 6| Step: 1
Training loss: 3.420089604280296
Validation loss: 2.6168961802550803

Epoch: 6| Step: 2
Training loss: 3.3609802669001474
Validation loss: 2.6374670500476594

Epoch: 6| Step: 3
Training loss: 2.558022192094471
Validation loss: 2.6332850199725293

Epoch: 6| Step: 4
Training loss: 2.419898229303362
Validation loss: 2.649033195140361

Epoch: 6| Step: 5
Training loss: 2.6651351424944267
Validation loss: 2.6592299768754146

Epoch: 6| Step: 6
Training loss: 3.117164554368086
Validation loss: 2.666172318885435

Epoch: 6| Step: 7
Training loss: 2.7377908351856544
Validation loss: 2.6673719033735637

Epoch: 6| Step: 8
Training loss: 2.901489953698964
Validation loss: 2.6549619173112284

Epoch: 6| Step: 9
Training loss: 2.8978478173734814
Validation loss: 2.6561371617053298

Epoch: 6| Step: 10
Training loss: 3.051590151644431
Validation loss: 2.6355009080512355

Epoch: 6| Step: 11
Training loss: 2.8700020511633157
Validation loss: 2.6249862725230497

Epoch: 6| Step: 12
Training loss: 3.2231397601298766
Validation loss: 2.612290251489481

Epoch: 6| Step: 13
Training loss: 2.6403271208015284
Validation loss: 2.6161018364175046

Epoch: 179| Step: 0
Training loss: 2.874804946253555
Validation loss: 2.613973325695567

Epoch: 6| Step: 1
Training loss: 2.9117101425072334
Validation loss: 2.615376696797113

Epoch: 6| Step: 2
Training loss: 2.8627362949175534
Validation loss: 2.6113867321508186

Epoch: 6| Step: 3
Training loss: 2.5385436481587584
Validation loss: 2.608385983893384

Epoch: 6| Step: 4
Training loss: 2.682661891435629
Validation loss: 2.6070259174892714

Epoch: 6| Step: 5
Training loss: 2.823406603949705
Validation loss: 2.607449434202424

Epoch: 6| Step: 6
Training loss: 2.386285970505678
Validation loss: 2.6190398624184383

Epoch: 6| Step: 7
Training loss: 3.2505416418769615
Validation loss: 2.6208266910812017

Epoch: 6| Step: 8
Training loss: 2.9732872271990147
Validation loss: 2.6312143879675323

Epoch: 6| Step: 9
Training loss: 3.0215001565117916
Validation loss: 2.6370146637235243

Epoch: 6| Step: 10
Training loss: 3.224899935094053
Validation loss: 2.6323818827020924

Epoch: 6| Step: 11
Training loss: 3.4776438199434847
Validation loss: 2.629579391666713

Epoch: 6| Step: 12
Training loss: 2.841804257937145
Validation loss: 2.619899681883591

Epoch: 6| Step: 13
Training loss: 3.3602566294077176
Validation loss: 2.6267734636781155

Epoch: 180| Step: 0
Training loss: 2.0675529082054367
Validation loss: 2.6337047871263373

Epoch: 6| Step: 1
Training loss: 3.45653741617588
Validation loss: 2.638703982105643

Epoch: 6| Step: 2
Training loss: 3.243746389633257
Validation loss: 2.6456498671964246

Epoch: 6| Step: 3
Training loss: 2.991469015607197
Validation loss: 2.6293049586017903

Epoch: 6| Step: 4
Training loss: 3.273526647988052
Validation loss: 2.634595629670692

Epoch: 6| Step: 5
Training loss: 2.6912864802360175
Validation loss: 2.649381971005578

Epoch: 6| Step: 6
Training loss: 2.894378699273744
Validation loss: 2.6508454403447317

Epoch: 6| Step: 7
Training loss: 3.1623970829196315
Validation loss: 2.6465326330913626

Epoch: 6| Step: 8
Training loss: 2.77519080391023
Validation loss: 2.6417621528782425

Epoch: 6| Step: 9
Training loss: 3.173864933680785
Validation loss: 2.6359773430424225

Epoch: 6| Step: 10
Training loss: 2.7044004397058603
Validation loss: 2.632680889715695

Epoch: 6| Step: 11
Training loss: 2.879215798370526
Validation loss: 2.616544672176558

Epoch: 6| Step: 12
Training loss: 2.6743971314643358
Validation loss: 2.603304634080478

Epoch: 6| Step: 13
Training loss: 2.8706540971307453
Validation loss: 2.600390933339905

Epoch: 181| Step: 0
Training loss: 2.282317760834297
Validation loss: 2.597877527435135

Epoch: 6| Step: 1
Training loss: 2.4287931998156416
Validation loss: 2.598823566721032

Epoch: 6| Step: 2
Training loss: 2.484609244957479
Validation loss: 2.6020765086560322

Epoch: 6| Step: 3
Training loss: 3.899325894515695
Validation loss: 2.600615668861104

Epoch: 6| Step: 4
Training loss: 2.6439015302226503
Validation loss: 2.6002889058933834

Epoch: 6| Step: 5
Training loss: 3.697741494484732
Validation loss: 2.6024570121468273

Epoch: 6| Step: 6
Training loss: 3.062995714822898
Validation loss: 2.600654932269737

Epoch: 6| Step: 7
Training loss: 3.147524414937389
Validation loss: 2.600396098294058

Epoch: 6| Step: 8
Training loss: 2.2301076406322076
Validation loss: 2.598263427771287

Epoch: 6| Step: 9
Training loss: 3.1778415129641937
Validation loss: 2.5985512948713403

Epoch: 6| Step: 10
Training loss: 2.663336870368579
Validation loss: 2.5956670588125497

Epoch: 6| Step: 11
Training loss: 3.0606433144804903
Validation loss: 2.6011786798097734

Epoch: 6| Step: 12
Training loss: 2.8912319886355324
Validation loss: 2.59602461804892

Epoch: 6| Step: 13
Training loss: 3.055374731628084
Validation loss: 2.6031691299844204

Epoch: 182| Step: 0
Training loss: 3.1824447336964434
Validation loss: 2.6083305694881003

Epoch: 6| Step: 1
Training loss: 2.8111197581637763
Validation loss: 2.610724688782728

Epoch: 6| Step: 2
Training loss: 2.660070387116947
Validation loss: 2.615802778757294

Epoch: 6| Step: 3
Training loss: 2.504452745427062
Validation loss: 2.615774030533383

Epoch: 6| Step: 4
Training loss: 2.873447164713219
Validation loss: 2.6119259616510284

Epoch: 6| Step: 5
Training loss: 3.127170876826384
Validation loss: 2.6095392662897554

Epoch: 6| Step: 6
Training loss: 3.1063779255796162
Validation loss: 2.60499375004881

Epoch: 6| Step: 7
Training loss: 2.9116133555914487
Validation loss: 2.614353334705524

Epoch: 6| Step: 8
Training loss: 2.902965371267343
Validation loss: 2.626400395792285

Epoch: 6| Step: 9
Training loss: 2.967943583936804
Validation loss: 2.627015474440086

Epoch: 6| Step: 10
Training loss: 2.428248528243555
Validation loss: 2.6199214765083116

Epoch: 6| Step: 11
Training loss: 3.2867263870023584
Validation loss: 2.6305029799175985

Epoch: 6| Step: 12
Training loss: 3.1054392687279866
Validation loss: 2.62984806413122

Epoch: 6| Step: 13
Training loss: 3.069589466641
Validation loss: 2.6360624054756507

Epoch: 183| Step: 0
Training loss: 3.159341336909557
Validation loss: 2.64620169808603

Epoch: 6| Step: 1
Training loss: 2.7319035287247586
Validation loss: 2.6370971617187693

Epoch: 6| Step: 2
Training loss: 2.8193292568168595
Validation loss: 2.6534685786583383

Epoch: 6| Step: 3
Training loss: 3.330423626917303
Validation loss: 2.653180741100293

Epoch: 6| Step: 4
Training loss: 3.3490581270164252
Validation loss: 2.648013524661775

Epoch: 6| Step: 5
Training loss: 2.6395272224642583
Validation loss: 2.6538842260086524

Epoch: 6| Step: 6
Training loss: 2.8235526031355143
Validation loss: 2.62394832555163

Epoch: 6| Step: 7
Training loss: 2.8802386116151673
Validation loss: 2.6242410135811043

Epoch: 6| Step: 8
Training loss: 2.8489469891775023
Validation loss: 2.6254779372767416

Epoch: 6| Step: 9
Training loss: 2.6272355505709024
Validation loss: 2.633320627406433

Epoch: 6| Step: 10
Training loss: 2.9070638522027155
Validation loss: 2.6119142315566526

Epoch: 6| Step: 11
Training loss: 2.757110160461523
Validation loss: 2.6220424845937016

Epoch: 6| Step: 12
Training loss: 3.20600634982027
Validation loss: 2.627612699099286

Epoch: 6| Step: 13
Training loss: 2.8456677687941725
Validation loss: 2.6228478389577994

Epoch: 184| Step: 0
Training loss: 2.524298270132077
Validation loss: 2.6256779050759356

Epoch: 6| Step: 1
Training loss: 3.0757420024543056
Validation loss: 2.6197350396671597

Epoch: 6| Step: 2
Training loss: 3.1453468165489338
Validation loss: 2.6122539324502316

Epoch: 6| Step: 3
Training loss: 2.2970657788408624
Validation loss: 2.6107249303461413

Epoch: 6| Step: 4
Training loss: 3.0459508814918435
Validation loss: 2.601054223142443

Epoch: 6| Step: 5
Training loss: 3.528819370108165
Validation loss: 2.5989882523166785

Epoch: 6| Step: 6
Training loss: 2.9769075449002087
Validation loss: 2.6028786671443207

Epoch: 6| Step: 7
Training loss: 3.186801010981663
Validation loss: 2.60729935444884

Epoch: 6| Step: 8
Training loss: 3.148327392470202
Validation loss: 2.6212473305442208

Epoch: 6| Step: 9
Training loss: 2.399407305647792
Validation loss: 2.6081199435129196

Epoch: 6| Step: 10
Training loss: 2.6363937516719655
Validation loss: 2.6261611651673435

Epoch: 6| Step: 11
Training loss: 2.7492915888311082
Validation loss: 2.628683347013008

Epoch: 6| Step: 12
Training loss: 2.9708127535142417
Validation loss: 2.645363909841797

Epoch: 6| Step: 13
Training loss: 3.4009894950724653
Validation loss: 2.631152655402819

Epoch: 185| Step: 0
Training loss: 2.517695930985972
Validation loss: 2.6073548202676817

Epoch: 6| Step: 1
Training loss: 3.059576702385204
Validation loss: 2.597074053751636

Epoch: 6| Step: 2
Training loss: 2.5882987222447356
Validation loss: 2.5948828387781573

Epoch: 6| Step: 3
Training loss: 3.2224801680115176
Validation loss: 2.5896072553171336

Epoch: 6| Step: 4
Training loss: 2.270267124339542
Validation loss: 2.596636357550798

Epoch: 6| Step: 5
Training loss: 3.0965831384251112
Validation loss: 2.5952200362925564

Epoch: 6| Step: 6
Training loss: 2.6526747034984455
Validation loss: 2.6008711789416985

Epoch: 6| Step: 7
Training loss: 2.9449844784805252
Validation loss: 2.593405659078786

Epoch: 6| Step: 8
Training loss: 2.6436203440082684
Validation loss: 2.596011061262789

Epoch: 6| Step: 9
Training loss: 3.7071185890577336
Validation loss: 2.611364096622504

Epoch: 6| Step: 10
Training loss: 2.4045185944426604
Validation loss: 2.6055004053194106

Epoch: 6| Step: 11
Training loss: 3.6007979568289192
Validation loss: 2.6013100360638592

Epoch: 6| Step: 12
Training loss: 3.1948561214234172
Validation loss: 2.6017355799259034

Epoch: 6| Step: 13
Training loss: 3.1043372054052507
Validation loss: 2.60013334596527

Epoch: 186| Step: 0
Training loss: 2.540388400801876
Validation loss: 2.592728028122733

Epoch: 6| Step: 1
Training loss: 2.4385613307189913
Validation loss: 2.5921242930876813

Epoch: 6| Step: 2
Training loss: 2.8384057435322725
Validation loss: 2.5943427151796805

Epoch: 6| Step: 3
Training loss: 3.233552247596976
Validation loss: 2.5901026536577945

Epoch: 6| Step: 4
Training loss: 3.235643073759688
Validation loss: 2.5888724110938464

Epoch: 6| Step: 5
Training loss: 2.747422571037079
Validation loss: 2.593918220766971

Epoch: 6| Step: 6
Training loss: 3.1089649025846096
Validation loss: 2.586970878083107

Epoch: 6| Step: 7
Training loss: 3.187898498757278
Validation loss: 2.5867913297632894

Epoch: 6| Step: 8
Training loss: 3.0156289530515705
Validation loss: 2.5852599086981667

Epoch: 6| Step: 9
Training loss: 3.155121252084687
Validation loss: 2.5869759192017825

Epoch: 6| Step: 10
Training loss: 2.7730140040333264
Validation loss: 2.58910887190228

Epoch: 6| Step: 11
Training loss: 2.8543324851621703
Validation loss: 2.593763014119157

Epoch: 6| Step: 12
Training loss: 2.7618862247001554
Validation loss: 2.5953847490390385

Epoch: 6| Step: 13
Training loss: 3.0984904643969755
Validation loss: 2.59236765167034

Epoch: 187| Step: 0
Training loss: 2.8371996212240385
Validation loss: 2.603385891596989

Epoch: 6| Step: 1
Training loss: 2.4036137395157864
Validation loss: 2.608871421193263

Epoch: 6| Step: 2
Training loss: 3.1320486302796327
Validation loss: 2.6049241852287066

Epoch: 6| Step: 3
Training loss: 3.2238104585537695
Validation loss: 2.620216987970621

Epoch: 6| Step: 4
Training loss: 2.8893343956908257
Validation loss: 2.6004049336050934

Epoch: 6| Step: 5
Training loss: 2.655295705473931
Validation loss: 2.6081107264135386

Epoch: 6| Step: 6
Training loss: 2.510015642945683
Validation loss: 2.6003842402775463

Epoch: 6| Step: 7
Training loss: 3.053957956910292
Validation loss: 2.5983129563928666

Epoch: 6| Step: 8
Training loss: 2.9982970490591776
Validation loss: 2.598955998826664

Epoch: 6| Step: 9
Training loss: 3.5819536406617685
Validation loss: 2.6094170495080693

Epoch: 6| Step: 10
Training loss: 2.8424495196661956
Validation loss: 2.607769597103542

Epoch: 6| Step: 11
Training loss: 2.156162536616352
Validation loss: 2.59678361304762

Epoch: 6| Step: 12
Training loss: 3.099937339887771
Validation loss: 2.59515639247886

Epoch: 6| Step: 13
Training loss: 3.5689964623533905
Validation loss: 2.5908348998041335

Epoch: 188| Step: 0
Training loss: 1.9124650166621782
Validation loss: 2.603602422478497

Epoch: 6| Step: 1
Training loss: 2.9928841439767724
Validation loss: 2.601624119768013

Epoch: 6| Step: 2
Training loss: 3.3195325945256458
Validation loss: 2.6092431350291014

Epoch: 6| Step: 3
Training loss: 3.4147504379659823
Validation loss: 2.6036539596046366

Epoch: 6| Step: 4
Training loss: 2.649455547183739
Validation loss: 2.599095642367537

Epoch: 6| Step: 5
Training loss: 3.1910040052120423
Validation loss: 2.6155939380129776

Epoch: 6| Step: 6
Training loss: 2.99129048340403
Validation loss: 2.619585377030739

Epoch: 6| Step: 7
Training loss: 2.987993533177253
Validation loss: 2.610929089590693

Epoch: 6| Step: 8
Training loss: 2.6771049844977055
Validation loss: 2.6110401397737872

Epoch: 6| Step: 9
Training loss: 2.4981717100111824
Validation loss: 2.640754949414945

Epoch: 6| Step: 10
Training loss: 3.3370985382593568
Validation loss: 2.6409930512542577

Epoch: 6| Step: 11
Training loss: 3.0406168515134424
Validation loss: 2.644158210387053

Epoch: 6| Step: 12
Training loss: 2.789347145237227
Validation loss: 2.6257644825352062

Epoch: 6| Step: 13
Training loss: 2.808458943109519
Validation loss: 2.6382039454043285

Epoch: 189| Step: 0
Training loss: 2.7288600564973606
Validation loss: 2.6093194764181122

Epoch: 6| Step: 1
Training loss: 2.8547783263508464
Validation loss: 2.593853450905828

Epoch: 6| Step: 2
Training loss: 3.4386311837306147
Validation loss: 2.5964977339784263

Epoch: 6| Step: 3
Training loss: 2.7399103431233827
Validation loss: 2.58148841463013

Epoch: 6| Step: 4
Training loss: 3.0443909520495063
Validation loss: 2.58289900716747

Epoch: 6| Step: 5
Training loss: 2.682218729650918
Validation loss: 2.580414106744023

Epoch: 6| Step: 6
Training loss: 2.6313248684849007
Validation loss: 2.582999824830882

Epoch: 6| Step: 7
Training loss: 3.2061985063786502
Validation loss: 2.5787491953566115

Epoch: 6| Step: 8
Training loss: 2.6948892896910266
Validation loss: 2.5767960718956915

Epoch: 6| Step: 9
Training loss: 3.15836557927106
Validation loss: 2.5788872003236154

Epoch: 6| Step: 10
Training loss: 3.2086761753816657
Validation loss: 2.5795340557177457

Epoch: 6| Step: 11
Training loss: 2.8124615136798186
Validation loss: 2.5813853908004147

Epoch: 6| Step: 12
Training loss: 2.960795134893758
Validation loss: 2.576038298450769

Epoch: 6| Step: 13
Training loss: 2.6443659901223158
Validation loss: 2.5783715292757257

Epoch: 190| Step: 0
Training loss: 2.8544308802324174
Validation loss: 2.585218610633585

Epoch: 6| Step: 1
Training loss: 2.9836629447494727
Validation loss: 2.5735846350661435

Epoch: 6| Step: 2
Training loss: 3.0956404333656047
Validation loss: 2.585804529045662

Epoch: 6| Step: 3
Training loss: 2.8973612059428553
Validation loss: 2.5869134163657015

Epoch: 6| Step: 4
Training loss: 2.9913784756072195
Validation loss: 2.5871711130383526

Epoch: 6| Step: 5
Training loss: 2.777038643304016
Validation loss: 2.594452685816129

Epoch: 6| Step: 6
Training loss: 3.051055231625318
Validation loss: 2.5933657293697494

Epoch: 6| Step: 7
Training loss: 2.9058424140854657
Validation loss: 2.6003503773966186

Epoch: 6| Step: 8
Training loss: 2.5505242912004706
Validation loss: 2.596265841557733

Epoch: 6| Step: 9
Training loss: 2.8279332891578695
Validation loss: 2.603423956182277

Epoch: 6| Step: 10
Training loss: 2.9508348091967114
Validation loss: 2.601693742279612

Epoch: 6| Step: 11
Training loss: 3.5586468120014887
Validation loss: 2.607375645086537

Epoch: 6| Step: 12
Training loss: 2.692667849523529
Validation loss: 2.610760011793798

Epoch: 6| Step: 13
Training loss: 2.4730639852228053
Validation loss: 2.609826571369254

Epoch: 191| Step: 0
Training loss: 3.061916685021123
Validation loss: 2.618888531158617

Epoch: 6| Step: 1
Training loss: 2.547248017312103
Validation loss: 2.6120979564167537

Epoch: 6| Step: 2
Training loss: 3.404442543857045
Validation loss: 2.614984943716183

Epoch: 6| Step: 3
Training loss: 2.9799911496331815
Validation loss: 2.6059221591249533

Epoch: 6| Step: 4
Training loss: 2.5982111058616
Validation loss: 2.599480578818372

Epoch: 6| Step: 5
Training loss: 3.198467758028132
Validation loss: 2.592355095340238

Epoch: 6| Step: 6
Training loss: 2.4351401031418978
Validation loss: 2.5926285933934508

Epoch: 6| Step: 7
Training loss: 2.753625733718452
Validation loss: 2.5935856816152545

Epoch: 6| Step: 8
Training loss: 2.044252069148224
Validation loss: 2.5841698702934575

Epoch: 6| Step: 9
Training loss: 2.649324341775847
Validation loss: 2.5796788420191867

Epoch: 6| Step: 10
Training loss: 3.192140977906074
Validation loss: 2.592030148366027

Epoch: 6| Step: 11
Training loss: 3.4110042046504527
Validation loss: 2.58502014045996

Epoch: 6| Step: 12
Training loss: 3.324498739677485
Validation loss: 2.5809476433841945

Epoch: 6| Step: 13
Training loss: 2.9665414726615564
Validation loss: 2.6007654787960117

Epoch: 192| Step: 0
Training loss: 2.727635563209652
Validation loss: 2.596097782785812

Epoch: 6| Step: 1
Training loss: 2.9212050052257803
Validation loss: 2.595357133833789

Epoch: 6| Step: 2
Training loss: 3.3668708386846036
Validation loss: 2.594408188240303

Epoch: 6| Step: 3
Training loss: 2.5671045755470177
Validation loss: 2.610183438301542

Epoch: 6| Step: 4
Training loss: 2.944080044332029
Validation loss: 2.607122813851058

Epoch: 6| Step: 5
Training loss: 3.132133886035798
Validation loss: 2.5938658942295523

Epoch: 6| Step: 6
Training loss: 3.567020693407492
Validation loss: 2.5844668479414565

Epoch: 6| Step: 7
Training loss: 2.4424263493845557
Validation loss: 2.5914673786548197

Epoch: 6| Step: 8
Training loss: 2.769375946037873
Validation loss: 2.586910725789395

Epoch: 6| Step: 9
Training loss: 2.8803097992741895
Validation loss: 2.587491527081996

Epoch: 6| Step: 10
Training loss: 2.7025362817973697
Validation loss: 2.5862893387934767

Epoch: 6| Step: 11
Training loss: 2.8391068668709307
Validation loss: 2.5788383364626366

Epoch: 6| Step: 12
Training loss: 3.1925375531287346
Validation loss: 2.591648722861067

Epoch: 6| Step: 13
Training loss: 2.4418345327468325
Validation loss: 2.57675021281345

Epoch: 193| Step: 0
Training loss: 3.640631286877619
Validation loss: 2.5878056127384492

Epoch: 6| Step: 1
Training loss: 2.1963342209952796
Validation loss: 2.589264432778326

Epoch: 6| Step: 2
Training loss: 2.8905484576014615
Validation loss: 2.5844465616605765

Epoch: 6| Step: 3
Training loss: 2.5587151651475786
Validation loss: 2.5897177190712823

Epoch: 6| Step: 4
Training loss: 3.071919804321019
Validation loss: 2.5907564408703334

Epoch: 6| Step: 5
Training loss: 3.0031394426234725
Validation loss: 2.59179827957331

Epoch: 6| Step: 6
Training loss: 2.8207070029823345
Validation loss: 2.586521839205718

Epoch: 6| Step: 7
Training loss: 3.112285229730124
Validation loss: 2.590575344938286

Epoch: 6| Step: 8
Training loss: 3.1580137857784902
Validation loss: 2.5850134502443463

Epoch: 6| Step: 9
Training loss: 3.1299292788574973
Validation loss: 2.586068660397703

Epoch: 6| Step: 10
Training loss: 2.8714152668615567
Validation loss: 2.5924460410750814

Epoch: 6| Step: 11
Training loss: 2.981571018681413
Validation loss: 2.589813100091215

Epoch: 6| Step: 12
Training loss: 2.1869219424913293
Validation loss: 2.594157894919198

Epoch: 6| Step: 13
Training loss: 2.833248660748437
Validation loss: 2.59597054058663

Epoch: 194| Step: 0
Training loss: 3.5678208085125678
Validation loss: 2.5938395526606577

Epoch: 6| Step: 1
Training loss: 2.4537653967927655
Validation loss: 2.593748639972843

Epoch: 6| Step: 2
Training loss: 2.723089941612036
Validation loss: 2.5891041329762956

Epoch: 6| Step: 3
Training loss: 3.0109935238609236
Validation loss: 2.5886139152207575

Epoch: 6| Step: 4
Training loss: 2.5306772596635323
Validation loss: 2.585667682496795

Epoch: 6| Step: 5
Training loss: 2.394301635287364
Validation loss: 2.58947402828618

Epoch: 6| Step: 6
Training loss: 3.3036568118811127
Validation loss: 2.5844192660403307

Epoch: 6| Step: 7
Training loss: 2.4116184738957473
Validation loss: 2.5786355893649824

Epoch: 6| Step: 8
Training loss: 3.188566291329327
Validation loss: 2.579890305377249

Epoch: 6| Step: 9
Training loss: 3.111194480808313
Validation loss: 2.5823515324050264

Epoch: 6| Step: 10
Training loss: 2.8439820582686357
Validation loss: 2.5734157764836314

Epoch: 6| Step: 11
Training loss: 2.81493357171774
Validation loss: 2.5703698361417553

Epoch: 6| Step: 12
Training loss: 2.959819975353066
Validation loss: 2.5731865512695515

Epoch: 6| Step: 13
Training loss: 3.6139912995327124
Validation loss: 2.573872527208348

Epoch: 195| Step: 0
Training loss: 3.0097405929564176
Validation loss: 2.579880331576912

Epoch: 6| Step: 1
Training loss: 3.030258173755064
Validation loss: 2.586789773813661

Epoch: 6| Step: 2
Training loss: 2.2033013888691833
Validation loss: 2.5913937844186803

Epoch: 6| Step: 3
Training loss: 2.909782313958215
Validation loss: 2.595159744271871

Epoch: 6| Step: 4
Training loss: 2.5517809837973986
Validation loss: 2.6371800994453274

Epoch: 6| Step: 5
Training loss: 2.5164222164885133
Validation loss: 2.6591024189001393

Epoch: 6| Step: 6
Training loss: 3.3407736392804486
Validation loss: 2.6494358194702756

Epoch: 6| Step: 7
Training loss: 3.324243278726704
Validation loss: 2.634589490577682

Epoch: 6| Step: 8
Training loss: 3.2788143745877
Validation loss: 2.629195162534185

Epoch: 6| Step: 9
Training loss: 2.3220235250827237
Validation loss: 2.6179433163188732

Epoch: 6| Step: 10
Training loss: 3.2735892831942044
Validation loss: 2.602857942267017

Epoch: 6| Step: 11
Training loss: 2.993364784766497
Validation loss: 2.6013151538593315

Epoch: 6| Step: 12
Training loss: 3.4225374042258756
Validation loss: 2.5955841186060336

Epoch: 6| Step: 13
Training loss: 2.2500749151685704
Validation loss: 2.5924294356025896

Epoch: 196| Step: 0
Training loss: 2.723265482579846
Validation loss: 2.5895704973677676

Epoch: 6| Step: 1
Training loss: 3.381955079974284
Validation loss: 2.589337087558338

Epoch: 6| Step: 2
Training loss: 3.2152038595016488
Validation loss: 2.582651245410686

Epoch: 6| Step: 3
Training loss: 2.805930624546745
Validation loss: 2.579912585060372

Epoch: 6| Step: 4
Training loss: 3.4013729352790225
Validation loss: 2.5766004084844645

Epoch: 6| Step: 5
Training loss: 2.9120163675623756
Validation loss: 2.5732061053837088

Epoch: 6| Step: 6
Training loss: 3.178184360186102
Validation loss: 2.574380212686765

Epoch: 6| Step: 7
Training loss: 2.532365812039712
Validation loss: 2.570620990095021

Epoch: 6| Step: 8
Training loss: 3.0030759301280177
Validation loss: 2.5713113848059135

Epoch: 6| Step: 9
Training loss: 2.877921734485957
Validation loss: 2.5729499872195705

Epoch: 6| Step: 10
Training loss: 1.9291143763179268
Validation loss: 2.575065796972524

Epoch: 6| Step: 11
Training loss: 2.077577676617741
Validation loss: 2.5819725881473854

Epoch: 6| Step: 12
Training loss: 3.5194114808630803
Validation loss: 2.5978879936397665

Epoch: 6| Step: 13
Training loss: 3.085371907227426
Validation loss: 2.617092768901992

Epoch: 197| Step: 0
Training loss: 3.0686493462800217
Validation loss: 2.649301101425004

Epoch: 6| Step: 1
Training loss: 3.5202836429583173
Validation loss: 2.6480107983857653

Epoch: 6| Step: 2
Training loss: 2.8609603072569367
Validation loss: 2.6330361020433672

Epoch: 6| Step: 3
Training loss: 2.5416760887429954
Validation loss: 2.6182514876539393

Epoch: 6| Step: 4
Training loss: 3.0980878531680256
Validation loss: 2.596915977412089

Epoch: 6| Step: 5
Training loss: 2.3489101317564005
Validation loss: 2.591500414854323

Epoch: 6| Step: 6
Training loss: 2.220632050382511
Validation loss: 2.5884243914297898

Epoch: 6| Step: 7
Training loss: 3.0432663112194795
Validation loss: 2.5725324294922673

Epoch: 6| Step: 8
Training loss: 3.3565451834956215
Validation loss: 2.5703065155674767

Epoch: 6| Step: 9
Training loss: 3.1410007536704136
Validation loss: 2.5732206879317516

Epoch: 6| Step: 10
Training loss: 3.271900626503928
Validation loss: 2.5650761438445118

Epoch: 6| Step: 11
Training loss: 2.4736304992833635
Validation loss: 2.5668961856496226

Epoch: 6| Step: 12
Training loss: 3.0942696799559863
Validation loss: 2.5773497598293504

Epoch: 6| Step: 13
Training loss: 2.4409191896970093
Validation loss: 2.5727589488196334

Epoch: 198| Step: 0
Training loss: 2.6967460910934644
Validation loss: 2.5706248530738804

Epoch: 6| Step: 1
Training loss: 2.3649855844328513
Validation loss: 2.5770800897128527

Epoch: 6| Step: 2
Training loss: 3.188430351167804
Validation loss: 2.5762218502307688

Epoch: 6| Step: 3
Training loss: 3.738673334078573
Validation loss: 2.573979961171451

Epoch: 6| Step: 4
Training loss: 2.5991145350136815
Validation loss: 2.5736587714297188

Epoch: 6| Step: 5
Training loss: 2.9664461532533113
Validation loss: 2.5799874428299376

Epoch: 6| Step: 6
Training loss: 2.9983226537452428
Validation loss: 2.5825871260840256

Epoch: 6| Step: 7
Training loss: 2.644892387580698
Validation loss: 2.594337672564917

Epoch: 6| Step: 8
Training loss: 2.9180213688570626
Validation loss: 2.589599216725866

Epoch: 6| Step: 9
Training loss: 3.0288778245176036
Validation loss: 2.602069930767841

Epoch: 6| Step: 10
Training loss: 2.6489778490706453
Validation loss: 2.588109756822916

Epoch: 6| Step: 11
Training loss: 3.0644356974488516
Validation loss: 2.5734357701699024

Epoch: 6| Step: 12
Training loss: 2.7591632420472423
Validation loss: 2.568964336105833

Epoch: 6| Step: 13
Training loss: 3.0968827848981366
Validation loss: 2.5787316506942908

Epoch: 199| Step: 0
Training loss: 3.2230447800827937
Validation loss: 2.571910668624928

Epoch: 6| Step: 1
Training loss: 3.284119287004047
Validation loss: 2.580035627134547

Epoch: 6| Step: 2
Training loss: 2.6757247584707327
Validation loss: 2.5684686215886505

Epoch: 6| Step: 3
Training loss: 2.769031388082489
Validation loss: 2.578651348142109

Epoch: 6| Step: 4
Training loss: 2.892662855886795
Validation loss: 2.5740885150683988

Epoch: 6| Step: 5
Training loss: 2.8383649205234525
Validation loss: 2.5806081850757376

Epoch: 6| Step: 6
Training loss: 2.9665548139195503
Validation loss: 2.5749930620921377

Epoch: 6| Step: 7
Training loss: 3.1517268337058906
Validation loss: 2.5753695532519987

Epoch: 6| Step: 8
Training loss: 2.7779142971399673
Validation loss: 2.5847050845127306

Epoch: 6| Step: 9
Training loss: 3.1616384003507982
Validation loss: 2.5822737628316914

Epoch: 6| Step: 10
Training loss: 2.6574949152154086
Validation loss: 2.5846632955360844

Epoch: 6| Step: 11
Training loss: 2.475743107067036
Validation loss: 2.5828328165447685

Epoch: 6| Step: 12
Training loss: 3.17837624846119
Validation loss: 2.585469949809543

Epoch: 6| Step: 13
Training loss: 2.3934165264146556
Validation loss: 2.583232275950774

Epoch: 200| Step: 0
Training loss: 3.1834550511389463
Validation loss: 2.587605446697046

Epoch: 6| Step: 1
Training loss: 2.9166065391519016
Validation loss: 2.59316796776319

Epoch: 6| Step: 2
Training loss: 2.696208771667632
Validation loss: 2.5909386323444905

Epoch: 6| Step: 3
Training loss: 2.7930706725830365
Validation loss: 2.591798441791587

Epoch: 6| Step: 4
Training loss: 2.730089589699511
Validation loss: 2.5990591044248683

Epoch: 6| Step: 5
Training loss: 2.9239263014787995
Validation loss: 2.595563514257601

Epoch: 6| Step: 6
Training loss: 3.320048961278379
Validation loss: 2.602744887234176

Epoch: 6| Step: 7
Training loss: 2.716928419909128
Validation loss: 2.598091235500523

Epoch: 6| Step: 8
Training loss: 2.3807100620030384
Validation loss: 2.5990686199437327

Epoch: 6| Step: 9
Training loss: 3.274679526453934
Validation loss: 2.6044613132938235

Epoch: 6| Step: 10
Training loss: 2.6321465530118155
Validation loss: 2.601388342259146

Epoch: 6| Step: 11
Training loss: 3.4667370428375626
Validation loss: 2.582544973266304

Epoch: 6| Step: 12
Training loss: 2.4735036545929474
Validation loss: 2.5705290233551263

Epoch: 6| Step: 13
Training loss: 3.347572067430822
Validation loss: 2.564255164096215

Testing loss: 2.8037180843606904
