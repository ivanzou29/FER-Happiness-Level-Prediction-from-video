Epoch: 1| Step: 0
Training loss: 3.3080878257751465
Validation loss: 5.1400101518118255

Epoch: 6| Step: 1
Training loss: 4.674994945526123
Validation loss: 5.129825468986265

Epoch: 6| Step: 2
Training loss: 4.86955451965332
Validation loss: 5.120455593191167

Epoch: 6| Step: 3
Training loss: 3.936689853668213
Validation loss: 5.111006357336557

Epoch: 6| Step: 4
Training loss: 5.724353790283203
Validation loss: 5.102808567785448

Epoch: 6| Step: 5
Training loss: 5.849216461181641
Validation loss: 5.094591335583758

Epoch: 6| Step: 6
Training loss: 4.374980449676514
Validation loss: 5.085943222045898

Epoch: 6| Step: 7
Training loss: 5.974822521209717
Validation loss: 5.076735450375464

Epoch: 6| Step: 8
Training loss: 4.640221118927002
Validation loss: 5.067620697841849

Epoch: 6| Step: 9
Training loss: 6.350931644439697
Validation loss: 5.057881683431646

Epoch: 6| Step: 10
Training loss: 5.109086036682129
Validation loss: 5.047225372765654

Epoch: 6| Step: 11
Training loss: 3.9109787940979004
Validation loss: 5.035941093198715

Epoch: 6| Step: 12
Training loss: 5.101757526397705
Validation loss: 5.023877064387004

Epoch: 6| Step: 13
Training loss: 4.0887861251831055
Validation loss: 5.0110384264299945

Epoch: 2| Step: 0
Training loss: 4.2568039894104
Validation loss: 4.997013481714392

Epoch: 6| Step: 1
Training loss: 3.940673828125
Validation loss: 4.982371232842886

Epoch: 6| Step: 2
Training loss: 4.95352840423584
Validation loss: 4.965783001274191

Epoch: 6| Step: 3
Training loss: 5.019400119781494
Validation loss: 4.94984116092805

Epoch: 6| Step: 4
Training loss: 3.828453779220581
Validation loss: 4.9316060722515145

Epoch: 6| Step: 5
Training loss: 3.820220470428467
Validation loss: 4.9115347810970835

Epoch: 6| Step: 6
Training loss: 6.592185020446777
Validation loss: 4.89068745028588

Epoch: 6| Step: 7
Training loss: 4.471853256225586
Validation loss: 4.867852790381319

Epoch: 6| Step: 8
Training loss: 4.2140583992004395
Validation loss: 4.844346056702316

Epoch: 6| Step: 9
Training loss: 5.788249969482422
Validation loss: 4.818697837091261

Epoch: 6| Step: 10
Training loss: 4.191466331481934
Validation loss: 4.790906080635645

Epoch: 6| Step: 11
Training loss: 5.156546592712402
Validation loss: 4.761764628912813

Epoch: 6| Step: 12
Training loss: 5.056595802307129
Validation loss: 4.732965469360352

Epoch: 6| Step: 13
Training loss: 3.470872402191162
Validation loss: 4.70157415123396

Epoch: 3| Step: 0
Training loss: 4.579925537109375
Validation loss: 4.670564713016633

Epoch: 6| Step: 1
Training loss: 4.563350677490234
Validation loss: 4.639395498460339

Epoch: 6| Step: 2
Training loss: 5.6744384765625
Validation loss: 4.606910028765278

Epoch: 6| Step: 3
Training loss: 5.160696983337402
Validation loss: 4.573362888828401

Epoch: 6| Step: 4
Training loss: 4.0510640144348145
Validation loss: 4.5409697409599055

Epoch: 6| Step: 5
Training loss: 4.540216445922852
Validation loss: 4.5059846498632945

Epoch: 6| Step: 6
Training loss: 4.404338836669922
Validation loss: 4.472019605739142

Epoch: 6| Step: 7
Training loss: 5.071013927459717
Validation loss: 4.438696486975557

Epoch: 6| Step: 8
Training loss: 3.235106945037842
Validation loss: 4.403318241078367

Epoch: 6| Step: 9
Training loss: 3.144657611846924
Validation loss: 4.368087953136813

Epoch: 6| Step: 10
Training loss: 2.8937578201293945
Validation loss: 4.33055748990787

Epoch: 6| Step: 11
Training loss: 4.025979995727539
Validation loss: 4.293952259966122

Epoch: 6| Step: 12
Training loss: 3.9551093578338623
Validation loss: 4.253866934007214

Epoch: 6| Step: 13
Training loss: 4.301273345947266
Validation loss: 4.214464385022399

Epoch: 4| Step: 0
Training loss: 3.3274009227752686
Validation loss: 4.177035618853825

Epoch: 6| Step: 1
Training loss: 4.431507587432861
Validation loss: 4.14112518166983

Epoch: 6| Step: 2
Training loss: 3.759761333465576
Validation loss: 4.1020352814787175

Epoch: 6| Step: 3
Training loss: 3.904202938079834
Validation loss: 4.06549338627887

Epoch: 6| Step: 4
Training loss: 4.723604202270508
Validation loss: 4.02880863476825

Epoch: 6| Step: 5
Training loss: 3.485896110534668
Validation loss: 3.9927427794343684

Epoch: 6| Step: 6
Training loss: 5.036121845245361
Validation loss: 3.9589753894395727

Epoch: 6| Step: 7
Training loss: 2.5827019214630127
Validation loss: 3.9268067472724506

Epoch: 6| Step: 8
Training loss: 4.00905179977417
Validation loss: 3.8972664340849845

Epoch: 6| Step: 9
Training loss: 2.7254574298858643
Validation loss: 3.865374098541916

Epoch: 6| Step: 10
Training loss: 3.6524486541748047
Validation loss: 3.8376400752734114

Epoch: 6| Step: 11
Training loss: 3.315855026245117
Validation loss: 3.8126388493404595

Epoch: 6| Step: 12
Training loss: 4.243767261505127
Validation loss: 3.7846914850255495

Epoch: 6| Step: 13
Training loss: 4.4512410163879395
Validation loss: 3.761938951348746

Epoch: 5| Step: 0
Training loss: 2.4424729347229004
Validation loss: 3.7397153967170307

Epoch: 6| Step: 1
Training loss: 4.5855512619018555
Validation loss: 3.7148909620059434

Epoch: 6| Step: 2
Training loss: 4.91025447845459
Validation loss: 3.6949485501935406

Epoch: 6| Step: 3
Training loss: 4.004176616668701
Validation loss: 3.6733618397866525

Epoch: 6| Step: 4
Training loss: 4.056509494781494
Validation loss: 3.658568782191123

Epoch: 6| Step: 5
Training loss: 3.75992751121521
Validation loss: 3.6451162856112242

Epoch: 6| Step: 6
Training loss: 3.7311313152313232
Validation loss: 3.63104086537515

Epoch: 6| Step: 7
Training loss: 1.926425576210022
Validation loss: 3.618340225629909

Epoch: 6| Step: 8
Training loss: 2.4150705337524414
Validation loss: 3.606511941520117

Epoch: 6| Step: 9
Training loss: 3.550081729888916
Validation loss: 3.5954651396761657

Epoch: 6| Step: 10
Training loss: 2.748443603515625
Validation loss: 3.587333345925936

Epoch: 6| Step: 11
Training loss: 3.9337849617004395
Validation loss: 3.5769769812142975

Epoch: 6| Step: 12
Training loss: 4.027491569519043
Validation loss: 3.568656313803888

Epoch: 6| Step: 13
Training loss: 3.7061924934387207
Validation loss: 3.560804236319757

Epoch: 6| Step: 0
Training loss: 4.5027008056640625
Validation loss: 3.551554023578603

Epoch: 6| Step: 1
Training loss: 3.9071927070617676
Validation loss: 3.5456495233761367

Epoch: 6| Step: 2
Training loss: 3.6340606212615967
Validation loss: 3.53431672434653

Epoch: 6| Step: 3
Training loss: 3.3917081356048584
Validation loss: 3.522615694230603

Epoch: 6| Step: 4
Training loss: 2.833951950073242
Validation loss: 3.5168902002355105

Epoch: 6| Step: 5
Training loss: 3.322141647338867
Validation loss: 3.5119018221414215

Epoch: 6| Step: 6
Training loss: 3.931987762451172
Validation loss: 3.5014488671415593

Epoch: 6| Step: 7
Training loss: 2.8343148231506348
Validation loss: 3.4934797927897465

Epoch: 6| Step: 8
Training loss: 3.3301753997802734
Validation loss: 3.486781930410734

Epoch: 6| Step: 9
Training loss: 3.2314116954803467
Validation loss: 3.4800228534206266

Epoch: 6| Step: 10
Training loss: 2.7605249881744385
Validation loss: 3.4758539815102854

Epoch: 6| Step: 11
Training loss: 2.963489532470703
Validation loss: 3.4652299880981445

Epoch: 6| Step: 12
Training loss: 3.7483434677124023
Validation loss: 3.454918853698238

Epoch: 6| Step: 13
Training loss: 3.910614490509033
Validation loss: 3.4483914888033302

Epoch: 7| Step: 0
Training loss: 3.9544124603271484
Validation loss: 3.441705229461834

Epoch: 6| Step: 1
Training loss: 3.879460334777832
Validation loss: 3.4356016036002868

Epoch: 6| Step: 2
Training loss: 3.9414820671081543
Validation loss: 3.427259019626084

Epoch: 6| Step: 3
Training loss: 2.5470755100250244
Validation loss: 3.418733953147806

Epoch: 6| Step: 4
Training loss: 4.286869049072266
Validation loss: 3.4083080035383984

Epoch: 6| Step: 5
Training loss: 3.4672391414642334
Validation loss: 3.4017018425849175

Epoch: 6| Step: 6
Training loss: 2.4691953659057617
Validation loss: 3.3949640848303355

Epoch: 6| Step: 7
Training loss: 2.248403310775757
Validation loss: 3.387108228539908

Epoch: 6| Step: 8
Training loss: 3.3754422664642334
Validation loss: 3.381352522039926

Epoch: 6| Step: 9
Training loss: 3.4341773986816406
Validation loss: 3.379949426138273

Epoch: 6| Step: 10
Training loss: 2.8684725761413574
Validation loss: 3.370123653001683

Epoch: 6| Step: 11
Training loss: 2.448619842529297
Validation loss: 3.3627220148681314

Epoch: 6| Step: 12
Training loss: 3.975454092025757
Validation loss: 3.35590354088814

Epoch: 6| Step: 13
Training loss: 4.394261360168457
Validation loss: 3.34575165471723

Epoch: 8| Step: 0
Training loss: 2.9997634887695312
Validation loss: 3.338121432130055

Epoch: 6| Step: 1
Training loss: 3.8860316276550293
Validation loss: 3.336652071245255

Epoch: 6| Step: 2
Training loss: 2.7602758407592773
Validation loss: 3.33111814273301

Epoch: 6| Step: 3
Training loss: 2.801840305328369
Validation loss: 3.3320007067854687

Epoch: 6| Step: 4
Training loss: 3.8488881587982178
Validation loss: 3.320598607422203

Epoch: 6| Step: 5
Training loss: 3.3826894760131836
Validation loss: 3.307039160882273

Epoch: 6| Step: 6
Training loss: 3.1585633754730225
Validation loss: 3.3030461572831675

Epoch: 6| Step: 7
Training loss: 3.521087884902954
Validation loss: 3.3041295825794177

Epoch: 6| Step: 8
Training loss: 3.854729175567627
Validation loss: 3.2964117757735716

Epoch: 6| Step: 9
Training loss: 3.461651086807251
Validation loss: 3.2887973323945077

Epoch: 6| Step: 10
Training loss: 2.8482534885406494
Validation loss: 3.280932200852261

Epoch: 6| Step: 11
Training loss: 2.9266579151153564
Validation loss: 3.307088654528382

Epoch: 6| Step: 12
Training loss: 3.220315933227539
Validation loss: 3.2973302359222085

Epoch: 6| Step: 13
Training loss: 3.0784058570861816
Validation loss: 3.2662789565260693

Epoch: 9| Step: 0
Training loss: 3.225470542907715
Validation loss: 3.264955097629178

Epoch: 6| Step: 1
Training loss: 4.8961286544799805
Validation loss: 3.271995998197986

Epoch: 6| Step: 2
Training loss: 3.741115093231201
Validation loss: 3.2785994878379245

Epoch: 6| Step: 3
Training loss: 2.788034439086914
Validation loss: 3.2810214745101107

Epoch: 6| Step: 4
Training loss: 3.6962966918945312
Validation loss: 3.26820723472103

Epoch: 6| Step: 5
Training loss: 3.068223476409912
Validation loss: 3.252653609039963

Epoch: 6| Step: 6
Training loss: 4.037393093109131
Validation loss: 3.240518295636741

Epoch: 6| Step: 7
Training loss: 2.7732856273651123
Validation loss: 3.2288087696157475

Epoch: 6| Step: 8
Training loss: 2.4717109203338623
Validation loss: 3.2281929421168503

Epoch: 6| Step: 9
Training loss: 2.634226083755493
Validation loss: 3.232745985830984

Epoch: 6| Step: 10
Training loss: 3.034611701965332
Validation loss: 3.2372731367746987

Epoch: 6| Step: 11
Training loss: 3.1844301223754883
Validation loss: 3.223203464220929

Epoch: 6| Step: 12
Training loss: 3.1578903198242188
Validation loss: 3.21006505720077

Epoch: 6| Step: 13
Training loss: 1.9503865242004395
Validation loss: 3.2016905994825464

Epoch: 10| Step: 0
Training loss: 3.8358325958251953
Validation loss: 3.1969213331899335

Epoch: 6| Step: 1
Training loss: 2.5060863494873047
Validation loss: 3.194409470404348

Epoch: 6| Step: 2
Training loss: 2.3907480239868164
Validation loss: 3.19692632203461

Epoch: 6| Step: 3
Training loss: 2.5227479934692383
Validation loss: 3.1926466829033306

Epoch: 6| Step: 4
Training loss: 3.6624810695648193
Validation loss: 3.18668697726342

Epoch: 6| Step: 5
Training loss: 4.43765926361084
Validation loss: 3.1818366101993028

Epoch: 6| Step: 6
Training loss: 2.62094783782959
Validation loss: 3.172489986624769

Epoch: 6| Step: 7
Training loss: 3.3447208404541016
Validation loss: 3.1684421518797516

Epoch: 6| Step: 8
Training loss: 2.5135672092437744
Validation loss: 3.1634815021227767

Epoch: 6| Step: 9
Training loss: 2.9356276988983154
Validation loss: 3.1651975313822427

Epoch: 6| Step: 10
Training loss: 4.472377777099609
Validation loss: 3.1731837026534544

Epoch: 6| Step: 11
Training loss: 2.5238356590270996
Validation loss: 3.1505746661975818

Epoch: 6| Step: 12
Training loss: 3.5884032249450684
Validation loss: 3.147304409293718

Epoch: 6| Step: 13
Training loss: 3.1582577228546143
Validation loss: 3.147811110301684

Epoch: 11| Step: 0
Training loss: 3.6731314659118652
Validation loss: 3.1449231383621052

Epoch: 6| Step: 1
Training loss: 4.477099418640137
Validation loss: 3.1422695857222362

Epoch: 6| Step: 2
Training loss: 2.729081153869629
Validation loss: 3.1389851723947833

Epoch: 6| Step: 3
Training loss: 2.9365291595458984
Validation loss: 3.134762746031566

Epoch: 6| Step: 4
Training loss: 2.744443893432617
Validation loss: 3.1282570797909974

Epoch: 6| Step: 5
Training loss: 3.004885196685791
Validation loss: 3.1201903102218465

Epoch: 6| Step: 6
Training loss: 2.437769889831543
Validation loss: 3.113541749215895

Epoch: 6| Step: 7
Training loss: 2.8417038917541504
Validation loss: 3.10699119875508

Epoch: 6| Step: 8
Training loss: 3.10784912109375
Validation loss: 3.106714569112306

Epoch: 6| Step: 9
Training loss: 3.033123016357422
Validation loss: 3.1095101218069754

Epoch: 6| Step: 10
Training loss: 3.205028772354126
Validation loss: 3.101648840852963

Epoch: 6| Step: 11
Training loss: 3.224759101867676
Validation loss: 3.098666706392842

Epoch: 6| Step: 12
Training loss: 3.1253106594085693
Validation loss: 3.0954311201649327

Epoch: 6| Step: 13
Training loss: 3.5877790451049805
Validation loss: 3.0911485482287664

Epoch: 12| Step: 0
Training loss: 2.9659910202026367
Validation loss: 3.0858321523153656

Epoch: 6| Step: 1
Training loss: 3.6570138931274414
Validation loss: 3.089208597777992

Epoch: 6| Step: 2
Training loss: 2.8635287284851074
Validation loss: 3.086122671763102

Epoch: 6| Step: 3
Training loss: 3.781439781188965
Validation loss: 3.082362498006513

Epoch: 6| Step: 4
Training loss: 2.3053975105285645
Validation loss: 3.077077732291273

Epoch: 6| Step: 5
Training loss: 2.972963809967041
Validation loss: 3.0746055418445217

Epoch: 6| Step: 6
Training loss: 3.329554557800293
Validation loss: 3.074721567092403

Epoch: 6| Step: 7
Training loss: 3.6829113960266113
Validation loss: 3.070475942345076

Epoch: 6| Step: 8
Training loss: 2.2789828777313232
Validation loss: 3.0689732028592016

Epoch: 6| Step: 9
Training loss: 2.5138306617736816
Validation loss: 3.0670147839412896

Epoch: 6| Step: 10
Training loss: 2.879289150238037
Validation loss: 3.062596377506051

Epoch: 6| Step: 11
Training loss: 3.61722731590271
Validation loss: 3.0560775623526624

Epoch: 6| Step: 12
Training loss: 3.6024606227874756
Validation loss: 3.0506970369687645

Epoch: 6| Step: 13
Training loss: 3.0399179458618164
Validation loss: 3.0464268627987114

Epoch: 13| Step: 0
Training loss: 3.5408034324645996
Validation loss: 3.041583030454574

Epoch: 6| Step: 1
Training loss: 3.79298734664917
Validation loss: 3.0370226085826917

Epoch: 6| Step: 2
Training loss: 3.8808751106262207
Validation loss: 3.028139006706976

Epoch: 6| Step: 3
Training loss: 2.8889732360839844
Validation loss: 3.020784278069773

Epoch: 6| Step: 4
Training loss: 3.5364935398101807
Validation loss: 3.020100744821692

Epoch: 6| Step: 5
Training loss: 2.7448012828826904
Validation loss: 3.014181472921884

Epoch: 6| Step: 6
Training loss: 2.7244038581848145
Validation loss: 3.0089672509060112

Epoch: 6| Step: 7
Training loss: 2.521038055419922
Validation loss: 3.0086974764382965

Epoch: 6| Step: 8
Training loss: 2.3770008087158203
Validation loss: 3.0026570673911803

Epoch: 6| Step: 9
Training loss: 3.1947968006134033
Validation loss: 2.9941531637663483

Epoch: 6| Step: 10
Training loss: 2.5194859504699707
Validation loss: 2.9904439346764677

Epoch: 6| Step: 11
Training loss: 3.4984817504882812
Validation loss: 2.9860664388184905

Epoch: 6| Step: 12
Training loss: 3.1101279258728027
Validation loss: 2.9856467759737404

Epoch: 6| Step: 13
Training loss: 2.352550745010376
Validation loss: 2.981661201805197

Epoch: 14| Step: 0
Training loss: 2.5939836502075195
Validation loss: 2.979867086615614

Epoch: 6| Step: 1
Training loss: 3.817192316055298
Validation loss: 2.976319969341319

Epoch: 6| Step: 2
Training loss: 3.460989475250244
Validation loss: 2.9796447420632965

Epoch: 6| Step: 3
Training loss: 3.381899356842041
Validation loss: 2.980832279369395

Epoch: 6| Step: 4
Training loss: 3.3079357147216797
Validation loss: 2.978427953617547

Epoch: 6| Step: 5
Training loss: 3.404607057571411
Validation loss: 2.980155978151547

Epoch: 6| Step: 6
Training loss: 2.3638689517974854
Validation loss: 2.9759084793829147

Epoch: 6| Step: 7
Training loss: 1.7969393730163574
Validation loss: 2.968880463671941

Epoch: 6| Step: 8
Training loss: 2.3324332237243652
Validation loss: 2.9648689890420563

Epoch: 6| Step: 9
Training loss: 3.2869105339050293
Validation loss: 2.9591628787338093

Epoch: 6| Step: 10
Training loss: 3.5805306434631348
Validation loss: 2.9548561803756224

Epoch: 6| Step: 11
Training loss: 3.864124298095703
Validation loss: 2.9572438988634335

Epoch: 6| Step: 12
Training loss: 2.143096446990967
Validation loss: 2.9566160299444713

Epoch: 6| Step: 13
Training loss: 3.461859703063965
Validation loss: 2.9634651317391345

Epoch: 15| Step: 0
Training loss: 2.722700595855713
Validation loss: 2.9603926827830653

Epoch: 6| Step: 1
Training loss: 1.8152101039886475
Validation loss: 2.9518747252802693

Epoch: 6| Step: 2
Training loss: 4.1591949462890625
Validation loss: 2.947707550500029

Epoch: 6| Step: 3
Training loss: 3.372732400894165
Validation loss: 2.9455612039053314

Epoch: 6| Step: 4
Training loss: 3.542935609817505
Validation loss: 2.9444507809095484

Epoch: 6| Step: 5
Training loss: 2.1026923656463623
Validation loss: 2.944078850489791

Epoch: 6| Step: 6
Training loss: 2.9342191219329834
Validation loss: 2.947469493394257

Epoch: 6| Step: 7
Training loss: 3.8783655166625977
Validation loss: 2.9487064679463706

Epoch: 6| Step: 8
Training loss: 2.0639290809631348
Validation loss: 2.935698140052057

Epoch: 6| Step: 9
Training loss: 3.5559864044189453
Validation loss: 2.9330045484727427

Epoch: 6| Step: 10
Training loss: 3.3047752380371094
Validation loss: 2.9305243415217244

Epoch: 6| Step: 11
Training loss: 3.4713029861450195
Validation loss: 2.9311084593496015

Epoch: 6| Step: 12
Training loss: 2.676036834716797
Validation loss: 2.9258191893177647

Epoch: 6| Step: 13
Training loss: 2.549899101257324
Validation loss: 2.923444289033131

Epoch: 16| Step: 0
Training loss: 2.237814426422119
Validation loss: 2.9224731819604033

Epoch: 6| Step: 1
Training loss: 3.801088333129883
Validation loss: 2.9205314087611374

Epoch: 6| Step: 2
Training loss: 2.1637215614318848
Validation loss: 2.922120342972458

Epoch: 6| Step: 3
Training loss: 3.257101535797119
Validation loss: 2.9216621255361908

Epoch: 6| Step: 4
Training loss: 2.0573158264160156
Validation loss: 2.9217551472366496

Epoch: 6| Step: 5
Training loss: 3.2409815788269043
Validation loss: 2.9155974080485683

Epoch: 6| Step: 6
Training loss: 3.151481866836548
Validation loss: 2.9124038296361126

Epoch: 6| Step: 7
Training loss: 3.4638185501098633
Validation loss: 2.909220782659387

Epoch: 6| Step: 8
Training loss: 2.651728391647339
Validation loss: 2.909792900085449

Epoch: 6| Step: 9
Training loss: 2.89943790435791
Validation loss: 2.9070619229347474

Epoch: 6| Step: 10
Training loss: 3.9853103160858154
Validation loss: 2.9096447267839984

Epoch: 6| Step: 11
Training loss: 2.7089054584503174
Validation loss: 2.9065828656637542

Epoch: 6| Step: 12
Training loss: 4.0173773765563965
Validation loss: 2.9033423367366997

Epoch: 6| Step: 13
Training loss: 1.9953416585922241
Validation loss: 2.9009495294222267

Epoch: 17| Step: 0
Training loss: 3.6547350883483887
Validation loss: 2.9005380061364945

Epoch: 6| Step: 1
Training loss: 2.022517442703247
Validation loss: 2.896671679712111

Epoch: 6| Step: 2
Training loss: 2.301513671875
Validation loss: 2.896313544242613

Epoch: 6| Step: 3
Training loss: 2.2578699588775635
Validation loss: 2.897176586171632

Epoch: 6| Step: 4
Training loss: 3.0684895515441895
Validation loss: 2.891038748525804

Epoch: 6| Step: 5
Training loss: 2.7617383003234863
Validation loss: 2.8915771258774625

Epoch: 6| Step: 6
Training loss: 4.197817802429199
Validation loss: 2.886627471575173

Epoch: 6| Step: 7
Training loss: 3.606933832168579
Validation loss: 2.8858887944170224

Epoch: 6| Step: 8
Training loss: 3.4306368827819824
Validation loss: 2.885246246091781

Epoch: 6| Step: 9
Training loss: 3.358591079711914
Validation loss: 2.885160223130257

Epoch: 6| Step: 10
Training loss: 2.546212911605835
Validation loss: 2.885416733321323

Epoch: 6| Step: 11
Training loss: 3.832848072052002
Validation loss: 2.884375923423357

Epoch: 6| Step: 12
Training loss: 2.6779661178588867
Validation loss: 2.8748716180042555

Epoch: 6| Step: 13
Training loss: 1.3532856702804565
Validation loss: 2.8741149799798125

Epoch: 18| Step: 0
Training loss: 3.1330654621124268
Validation loss: 2.870552791062222

Epoch: 6| Step: 1
Training loss: 2.2147107124328613
Validation loss: 2.873804638462682

Epoch: 6| Step: 2
Training loss: 2.5405006408691406
Validation loss: 2.8764459010093444

Epoch: 6| Step: 3
Training loss: 2.539501905441284
Validation loss: 2.8799042112083844

Epoch: 6| Step: 4
Training loss: 2.9200987815856934
Validation loss: 2.871548996176771

Epoch: 6| Step: 5
Training loss: 2.9695451259613037
Validation loss: 2.861709815199657

Epoch: 6| Step: 6
Training loss: 3.038099765777588
Validation loss: 2.858165458966327

Epoch: 6| Step: 7
Training loss: 3.7357964515686035
Validation loss: 2.8541338418119695

Epoch: 6| Step: 8
Training loss: 4.031518459320068
Validation loss: 2.8602346604870212

Epoch: 6| Step: 9
Training loss: 2.657170295715332
Validation loss: 2.8560769224679596

Epoch: 6| Step: 10
Training loss: 2.8731884956359863
Validation loss: 2.854913798711633

Epoch: 6| Step: 11
Training loss: 2.63869309425354
Validation loss: 2.8524019871988604

Epoch: 6| Step: 12
Training loss: 2.407278537750244
Validation loss: 2.8473479619590183

Epoch: 6| Step: 13
Training loss: 4.402285099029541
Validation loss: 2.8449320382969354

Epoch: 19| Step: 0
Training loss: 2.637877941131592
Validation loss: 2.843213906852148

Epoch: 6| Step: 1
Training loss: 2.2612743377685547
Validation loss: 2.8395857708428496

Epoch: 6| Step: 2
Training loss: 2.7885518074035645
Validation loss: 2.850732659780851

Epoch: 6| Step: 3
Training loss: 3.4627790451049805
Validation loss: 2.8617574386699225

Epoch: 6| Step: 4
Training loss: 2.392888069152832
Validation loss: 2.8901411871756277

Epoch: 6| Step: 5
Training loss: 2.97938871383667
Validation loss: 2.86256819130272

Epoch: 6| Step: 6
Training loss: 2.8888673782348633
Validation loss: 2.8305838723336496

Epoch: 6| Step: 7
Training loss: 3.2347054481506348
Validation loss: 2.828025528179702

Epoch: 6| Step: 8
Training loss: 3.815878391265869
Validation loss: 2.8241237132780013

Epoch: 6| Step: 9
Training loss: 3.657309055328369
Validation loss: 2.8479044668136106

Epoch: 6| Step: 10
Training loss: 2.8201184272766113
Validation loss: 2.845780154710175

Epoch: 6| Step: 11
Training loss: 2.3247017860412598
Validation loss: 2.8335508992595058

Epoch: 6| Step: 12
Training loss: 3.0884711742401123
Validation loss: 2.8258294059384252

Epoch: 6| Step: 13
Training loss: 3.0701792240142822
Validation loss: 2.824114522626323

Epoch: 20| Step: 0
Training loss: 2.8804707527160645
Validation loss: 2.8228956935226277

Epoch: 6| Step: 1
Training loss: 2.4435198307037354
Validation loss: 2.8273731354744203

Epoch: 6| Step: 2
Training loss: 3.5163395404815674
Validation loss: 2.8285585629042758

Epoch: 6| Step: 3
Training loss: 2.509932279586792
Validation loss: 2.827396403076828

Epoch: 6| Step: 4
Training loss: 3.963945150375366
Validation loss: 2.8290855961461223

Epoch: 6| Step: 5
Training loss: 3.139763832092285
Validation loss: 2.8304246317955757

Epoch: 6| Step: 6
Training loss: 2.4547438621520996
Validation loss: 2.8308131387156825

Epoch: 6| Step: 7
Training loss: 2.9497504234313965
Validation loss: 2.8165384800203386

Epoch: 6| Step: 8
Training loss: 2.040618419647217
Validation loss: 2.8138405969066005

Epoch: 6| Step: 9
Training loss: 2.5728507041931152
Validation loss: 2.8092877608473583

Epoch: 6| Step: 10
Training loss: 3.283064842224121
Validation loss: 2.8133258178669918

Epoch: 6| Step: 11
Training loss: 2.348679780960083
Validation loss: 2.8136853992298083

Epoch: 6| Step: 12
Training loss: 3.3940253257751465
Validation loss: 2.8152350251392653

Epoch: 6| Step: 13
Training loss: 4.121718883514404
Validation loss: 2.8075895796539965

Epoch: 21| Step: 0
Training loss: 3.5013461112976074
Validation loss: 2.8045208402859267

Epoch: 6| Step: 1
Training loss: 2.6439223289489746
Validation loss: 2.806112525283649

Epoch: 6| Step: 2
Training loss: 2.8014469146728516
Validation loss: 2.8025855223337808

Epoch: 6| Step: 3
Training loss: 3.7663934230804443
Validation loss: 2.802996148345291

Epoch: 6| Step: 4
Training loss: 2.5517120361328125
Validation loss: 2.8010696698260564

Epoch: 6| Step: 5
Training loss: 3.1980161666870117
Validation loss: 2.7969399062536096

Epoch: 6| Step: 6
Training loss: 2.705866575241089
Validation loss: 2.7981563486078733

Epoch: 6| Step: 7
Training loss: 3.3211565017700195
Validation loss: 2.8025362414698445

Epoch: 6| Step: 8
Training loss: 3.5044829845428467
Validation loss: 2.806714842396398

Epoch: 6| Step: 9
Training loss: 2.4820590019226074
Validation loss: 2.8100747600678475

Epoch: 6| Step: 10
Training loss: 3.0999245643615723
Validation loss: 2.8112748771585445

Epoch: 6| Step: 11
Training loss: 2.4143002033233643
Validation loss: 2.794304924626504

Epoch: 6| Step: 12
Training loss: 2.3086276054382324
Validation loss: 2.8086010102302796

Epoch: 6| Step: 13
Training loss: 2.4521753787994385
Validation loss: 2.8189499147476687

Epoch: 22| Step: 0
Training loss: 2.966034412384033
Validation loss: 2.827336959941413

Epoch: 6| Step: 1
Training loss: 2.591125249862671
Validation loss: 2.823076917279151

Epoch: 6| Step: 2
Training loss: 2.6009440422058105
Validation loss: 2.8246705147527877

Epoch: 6| Step: 3
Training loss: 2.4074530601501465
Validation loss: 2.808309085907475

Epoch: 6| Step: 4
Training loss: 2.93465518951416
Validation loss: 2.7908554871877036

Epoch: 6| Step: 5
Training loss: 1.9717344045639038
Validation loss: 2.789427213771369

Epoch: 6| Step: 6
Training loss: 2.8907597064971924
Validation loss: 2.7913037423164613

Epoch: 6| Step: 7
Training loss: 3.4729061126708984
Validation loss: 2.8063594346405356

Epoch: 6| Step: 8
Training loss: 3.5372092723846436
Validation loss: 2.8178380612404115

Epoch: 6| Step: 9
Training loss: 3.352710723876953
Validation loss: 2.795726599231843

Epoch: 6| Step: 10
Training loss: 2.7541189193725586
Validation loss: 2.780435428824476

Epoch: 6| Step: 11
Training loss: 3.6326546669006348
Validation loss: 2.7791043558428363

Epoch: 6| Step: 12
Training loss: 2.5398454666137695
Validation loss: 2.779084244082051

Epoch: 6| Step: 13
Training loss: 3.449838399887085
Validation loss: 2.787441756135674

Epoch: 23| Step: 0
Training loss: 4.4169769287109375
Validation loss: 2.7998524276159142

Epoch: 6| Step: 1
Training loss: 2.8755860328674316
Validation loss: 2.788158696184876

Epoch: 6| Step: 2
Training loss: 3.1376242637634277
Validation loss: 2.783443235581921

Epoch: 6| Step: 3
Training loss: 2.356996536254883
Validation loss: 2.775528205338345

Epoch: 6| Step: 4
Training loss: 2.92612361907959
Validation loss: 2.773852591873497

Epoch: 6| Step: 5
Training loss: 3.1214065551757812
Validation loss: 2.7721073858199583

Epoch: 6| Step: 6
Training loss: 3.3435096740722656
Validation loss: 2.7690492753059632

Epoch: 6| Step: 7
Training loss: 2.423797607421875
Validation loss: 2.7721006844633367

Epoch: 6| Step: 8
Training loss: 2.080927848815918
Validation loss: 2.77085635482624

Epoch: 6| Step: 9
Training loss: 2.7135629653930664
Validation loss: 2.7753480557472474

Epoch: 6| Step: 10
Training loss: 2.747889518737793
Validation loss: 2.764016568019826

Epoch: 6| Step: 11
Training loss: 3.8435206413269043
Validation loss: 2.7645406133385113

Epoch: 6| Step: 12
Training loss: 2.656149387359619
Validation loss: 2.756096283594767

Epoch: 6| Step: 13
Training loss: 1.5061284303665161
Validation loss: 2.757306614229756

Epoch: 24| Step: 0
Training loss: 3.1945981979370117
Validation loss: 2.794470553757042

Epoch: 6| Step: 1
Training loss: 2.8901944160461426
Validation loss: 2.8143944714659

Epoch: 6| Step: 2
Training loss: 3.1750049591064453
Validation loss: 2.7975127466263308

Epoch: 6| Step: 3
Training loss: 2.528189182281494
Validation loss: 2.777261551990304

Epoch: 6| Step: 4
Training loss: 2.8277478218078613
Validation loss: 2.7742284446634273

Epoch: 6| Step: 5
Training loss: 3.1739869117736816
Validation loss: 2.7771458420702206

Epoch: 6| Step: 6
Training loss: 2.5582032203674316
Validation loss: 2.7731405765779558

Epoch: 6| Step: 7
Training loss: 3.4985203742980957
Validation loss: 2.7681675136730237

Epoch: 6| Step: 8
Training loss: 2.7698991298675537
Validation loss: 2.757508885475897

Epoch: 6| Step: 9
Training loss: 2.150895595550537
Validation loss: 2.7472307476946103

Epoch: 6| Step: 10
Training loss: 3.9513678550720215
Validation loss: 2.7461869024461314

Epoch: 6| Step: 11
Training loss: 2.4501736164093018
Validation loss: 2.743025005504649

Epoch: 6| Step: 12
Training loss: 3.0021402835845947
Validation loss: 2.7399176397631244

Epoch: 6| Step: 13
Training loss: 2.247016429901123
Validation loss: 2.736541255827873

Epoch: 25| Step: 0
Training loss: 1.6914782524108887
Validation loss: 2.7431244311794156

Epoch: 6| Step: 1
Training loss: 2.7274510860443115
Validation loss: 2.7457789887664137

Epoch: 6| Step: 2
Training loss: 2.856384515762329
Validation loss: 2.749602661337904

Epoch: 6| Step: 3
Training loss: 2.775114059448242
Validation loss: 2.7559737261905464

Epoch: 6| Step: 4
Training loss: 2.6118688583374023
Validation loss: 2.75170684629871

Epoch: 6| Step: 5
Training loss: 3.263239860534668
Validation loss: 2.7563888231913247

Epoch: 6| Step: 6
Training loss: 2.9036781787872314
Validation loss: 2.749323842346027

Epoch: 6| Step: 7
Training loss: 4.020572185516357
Validation loss: 2.738667985444428

Epoch: 6| Step: 8
Training loss: 3.4766123294830322
Validation loss: 2.7350164100687993

Epoch: 6| Step: 9
Training loss: 3.0519580841064453
Validation loss: 2.7322984510852444

Epoch: 6| Step: 10
Training loss: 3.0967493057250977
Validation loss: 2.731591434888942

Epoch: 6| Step: 11
Training loss: 2.4263179302215576
Validation loss: 2.724927650984897

Epoch: 6| Step: 12
Training loss: 2.856931686401367
Validation loss: 2.723207414791148

Epoch: 6| Step: 13
Training loss: 2.233647346496582
Validation loss: 2.72910116821207

Epoch: 26| Step: 0
Training loss: 3.172776699066162
Validation loss: 2.7337739980348976

Epoch: 6| Step: 1
Training loss: 2.5579166412353516
Validation loss: 2.744494563789778

Epoch: 6| Step: 2
Training loss: 3.330284833908081
Validation loss: 2.7532025896092898

Epoch: 6| Step: 3
Training loss: 3.4627773761749268
Validation loss: 2.7401592244384108

Epoch: 6| Step: 4
Training loss: 2.620962619781494
Validation loss: 2.7427793625862367

Epoch: 6| Step: 5
Training loss: 2.2720413208007812
Validation loss: 2.727076163855932

Epoch: 6| Step: 6
Training loss: 2.363779306411743
Validation loss: 2.723236294202907

Epoch: 6| Step: 7
Training loss: 3.2085490226745605
Validation loss: 2.715788084973571

Epoch: 6| Step: 8
Training loss: 3.331298351287842
Validation loss: 2.7172951698303223

Epoch: 6| Step: 9
Training loss: 2.825247287750244
Validation loss: 2.7171700334036224

Epoch: 6| Step: 10
Training loss: 2.147892475128174
Validation loss: 2.7171980821958153

Epoch: 6| Step: 11
Training loss: 2.602428913116455
Validation loss: 2.718654642822922

Epoch: 6| Step: 12
Training loss: 3.5315799713134766
Validation loss: 2.7192255809742916

Epoch: 6| Step: 13
Training loss: 2.662466049194336
Validation loss: 2.7204159587942143

Epoch: 27| Step: 0
Training loss: 2.181567668914795
Validation loss: 2.719739660140007

Epoch: 6| Step: 1
Training loss: 3.235936164855957
Validation loss: 2.7266746720960064

Epoch: 6| Step: 2
Training loss: 2.847569465637207
Validation loss: 2.719748071444932

Epoch: 6| Step: 3
Training loss: 2.870680809020996
Validation loss: 2.7181916134331816

Epoch: 6| Step: 4
Training loss: 2.1459269523620605
Validation loss: 2.7159260216579644

Epoch: 6| Step: 5
Training loss: 2.9586822986602783
Validation loss: 2.712348658551452

Epoch: 6| Step: 6
Training loss: 3.2388782501220703
Validation loss: 2.717826238242529

Epoch: 6| Step: 7
Training loss: 2.9675850868225098
Validation loss: 2.7135275615158903

Epoch: 6| Step: 8
Training loss: 2.8548011779785156
Validation loss: 2.710246988522109

Epoch: 6| Step: 9
Training loss: 3.390329360961914
Validation loss: 2.707826242651991

Epoch: 6| Step: 10
Training loss: 3.2684853076934814
Validation loss: 2.708444139008881

Epoch: 6| Step: 11
Training loss: 2.8005685806274414
Validation loss: 2.7054890509574645

Epoch: 6| Step: 12
Training loss: 3.12581205368042
Validation loss: 2.7061453634692776

Epoch: 6| Step: 13
Training loss: 1.6187691688537598
Validation loss: 2.707490154491958

Epoch: 28| Step: 0
Training loss: 2.4704396724700928
Validation loss: 2.7111649179971344

Epoch: 6| Step: 1
Training loss: 3.1043550968170166
Validation loss: 2.705929738219066

Epoch: 6| Step: 2
Training loss: 2.763667106628418
Validation loss: 2.701161635819302

Epoch: 6| Step: 3
Training loss: 2.859837770462036
Validation loss: 2.6978962062507548

Epoch: 6| Step: 4
Training loss: 3.5473570823669434
Validation loss: 2.6974717109434065

Epoch: 6| Step: 5
Training loss: 2.9475865364074707
Validation loss: 2.694352288399973

Epoch: 6| Step: 6
Training loss: 3.153120517730713
Validation loss: 2.6998759597860356

Epoch: 6| Step: 7
Training loss: 2.5396366119384766
Validation loss: 2.6984227831645677

Epoch: 6| Step: 8
Training loss: 3.618988513946533
Validation loss: 2.705415141197943

Epoch: 6| Step: 9
Training loss: 2.5143637657165527
Validation loss: 2.701184038192995

Epoch: 6| Step: 10
Training loss: 2.9313693046569824
Validation loss: 2.699876898078508

Epoch: 6| Step: 11
Training loss: 2.325282573699951
Validation loss: 2.698938403078305

Epoch: 6| Step: 12
Training loss: 2.0914764404296875
Validation loss: 2.701521458164338

Epoch: 6| Step: 13
Training loss: 3.3494696617126465
Validation loss: 2.701581016663582

Epoch: 29| Step: 0
Training loss: 2.3830602169036865
Validation loss: 2.699080890224826

Epoch: 6| Step: 1
Training loss: 2.093531370162964
Validation loss: 2.7099899066391813

Epoch: 6| Step: 2
Training loss: 3.1353726387023926
Validation loss: 2.724622816167852

Epoch: 6| Step: 3
Training loss: 2.341607093811035
Validation loss: 2.7143134942618747

Epoch: 6| Step: 4
Training loss: 3.3106908798217773
Validation loss: 2.720628894785399

Epoch: 6| Step: 5
Training loss: 2.795166254043579
Validation loss: 2.7224583933430333

Epoch: 6| Step: 6
Training loss: 2.2294042110443115
Validation loss: 2.7184966841051654

Epoch: 6| Step: 7
Training loss: 3.099738597869873
Validation loss: 2.714101775999992

Epoch: 6| Step: 8
Training loss: 2.998453378677368
Validation loss: 2.7072246484859015

Epoch: 6| Step: 9
Training loss: 2.85390043258667
Validation loss: 2.7057296588856685

Epoch: 6| Step: 10
Training loss: 3.3345513343811035
Validation loss: 2.703109182337279

Epoch: 6| Step: 11
Training loss: 3.4252259731292725
Validation loss: 2.7026234775461178

Epoch: 6| Step: 12
Training loss: 2.8850555419921875
Validation loss: 2.702928025235412

Epoch: 6| Step: 13
Training loss: 3.27640438079834
Validation loss: 2.702501466197352

Epoch: 30| Step: 0
Training loss: 2.2384560108184814
Validation loss: 2.6970834770510272

Epoch: 6| Step: 1
Training loss: 2.962460994720459
Validation loss: 2.689484329633815

Epoch: 6| Step: 2
Training loss: 2.240485906600952
Validation loss: 2.6984174969375774

Epoch: 6| Step: 3
Training loss: 2.793130397796631
Validation loss: 2.705426013597878

Epoch: 6| Step: 4
Training loss: 3.6217362880706787
Validation loss: 2.7224700117623932

Epoch: 6| Step: 5
Training loss: 2.958704948425293
Validation loss: 2.7521254375416744

Epoch: 6| Step: 6
Training loss: 3.7037038803100586
Validation loss: 2.750626587098645

Epoch: 6| Step: 7
Training loss: 3.2691686153411865
Validation loss: 2.7187385533445623

Epoch: 6| Step: 8
Training loss: 2.6071531772613525
Validation loss: 2.700340922160815

Epoch: 6| Step: 9
Training loss: 2.7975075244903564
Validation loss: 2.687534337402672

Epoch: 6| Step: 10
Training loss: 2.266171455383301
Validation loss: 2.6865028027565248

Epoch: 6| Step: 11
Training loss: 3.230118751525879
Validation loss: 2.6920038807776665

Epoch: 6| Step: 12
Training loss: 2.588742971420288
Validation loss: 2.70423246711813

Epoch: 6| Step: 13
Training loss: 2.555760622024536
Validation loss: 2.718731411041752

Epoch: 31| Step: 0
Training loss: 2.9212934970855713
Validation loss: 2.7234715671949488

Epoch: 6| Step: 1
Training loss: 3.177931308746338
Validation loss: 2.7351473249414915

Epoch: 6| Step: 2
Training loss: 3.098029851913452
Validation loss: 2.7131432461482223

Epoch: 6| Step: 3
Training loss: 2.4540505409240723
Validation loss: 2.693019243978685

Epoch: 6| Step: 4
Training loss: 2.7668910026550293
Validation loss: 2.6873253263453

Epoch: 6| Step: 5
Training loss: 2.735888719558716
Validation loss: 2.6768097851866033

Epoch: 6| Step: 6
Training loss: 3.5780229568481445
Validation loss: 2.6861815452575684

Epoch: 6| Step: 7
Training loss: 2.576779842376709
Validation loss: 2.6938442055897047

Epoch: 6| Step: 8
Training loss: 3.116281509399414
Validation loss: 2.71052550244075

Epoch: 6| Step: 9
Training loss: 2.1847991943359375
Validation loss: 2.7060314096430296

Epoch: 6| Step: 10
Training loss: 3.277369976043701
Validation loss: 2.6911028790217575

Epoch: 6| Step: 11
Training loss: 2.573939800262451
Validation loss: 2.683621547555411

Epoch: 6| Step: 12
Training loss: 2.4370501041412354
Validation loss: 2.672159210328133

Epoch: 6| Step: 13
Training loss: 2.9845147132873535
Validation loss: 2.6733207856455157

Epoch: 32| Step: 0
Training loss: 3.3672773838043213
Validation loss: 2.679087923419091

Epoch: 6| Step: 1
Training loss: 3.1298251152038574
Validation loss: 2.6869110599640877

Epoch: 6| Step: 2
Training loss: 3.449308395385742
Validation loss: 2.706025308178317

Epoch: 6| Step: 3
Training loss: 3.411478281021118
Validation loss: 2.699284735546317

Epoch: 6| Step: 4
Training loss: 2.8685340881347656
Validation loss: 2.683563878459315

Epoch: 6| Step: 5
Training loss: 2.4604594707489014
Validation loss: 2.679574438320693

Epoch: 6| Step: 6
Training loss: 2.594456434249878
Validation loss: 2.69087173861842

Epoch: 6| Step: 7
Training loss: 2.70461368560791
Validation loss: 2.686017564547959

Epoch: 6| Step: 8
Training loss: 3.2461767196655273
Validation loss: 2.7006795252523115

Epoch: 6| Step: 9
Training loss: 2.483588218688965
Validation loss: 2.689657898359401

Epoch: 6| Step: 10
Training loss: 2.3556883335113525
Validation loss: 2.684391480620189

Epoch: 6| Step: 11
Training loss: 2.2186715602874756
Validation loss: 2.688400814610143

Epoch: 6| Step: 12
Training loss: 2.4979727268218994
Validation loss: 2.6838044710056757

Epoch: 6| Step: 13
Training loss: 3.1126813888549805
Validation loss: 2.706702829689108

Epoch: 33| Step: 0
Training loss: 2.5440168380737305
Validation loss: 2.6773767240585817

Epoch: 6| Step: 1
Training loss: 2.9673378467559814
Validation loss: 2.66985983105116

Epoch: 6| Step: 2
Training loss: 2.7174060344696045
Validation loss: 2.665162617160428

Epoch: 6| Step: 3
Training loss: 2.745678186416626
Validation loss: 2.674393000141267

Epoch: 6| Step: 4
Training loss: 2.4202394485473633
Validation loss: 2.670558134714762

Epoch: 6| Step: 5
Training loss: 2.803544044494629
Validation loss: 2.683619835043466

Epoch: 6| Step: 6
Training loss: 2.643026351928711
Validation loss: 2.6765993282359135

Epoch: 6| Step: 7
Training loss: 3.235623836517334
Validation loss: 2.67628546684019

Epoch: 6| Step: 8
Training loss: 3.757632255554199
Validation loss: 2.6706483517923663

Epoch: 6| Step: 9
Training loss: 3.2832093238830566
Validation loss: 2.6672107993915515

Epoch: 6| Step: 10
Training loss: 2.8286378383636475
Validation loss: 2.6630529075540523

Epoch: 6| Step: 11
Training loss: 3.052882671356201
Validation loss: 2.66166522682354

Epoch: 6| Step: 12
Training loss: 2.093069076538086
Validation loss: 2.663232018870692

Epoch: 6| Step: 13
Training loss: 2.3348608016967773
Validation loss: 2.659125017863448

Epoch: 34| Step: 0
Training loss: 2.9248900413513184
Validation loss: 2.657624552326818

Epoch: 6| Step: 1
Training loss: 2.61326265335083
Validation loss: 2.6576694775653142

Epoch: 6| Step: 2
Training loss: 2.2992444038391113
Validation loss: 2.6624324321746826

Epoch: 6| Step: 3
Training loss: 3.581350088119507
Validation loss: 2.6724088422713743

Epoch: 6| Step: 4
Training loss: 2.716254711151123
Validation loss: 2.672304927661855

Epoch: 6| Step: 5
Training loss: 2.876002788543701
Validation loss: 2.6624166068210395

Epoch: 6| Step: 6
Training loss: 2.973869800567627
Validation loss: 2.6654238880321546

Epoch: 6| Step: 7
Training loss: 2.3333687782287598
Validation loss: 2.662837638649889

Epoch: 6| Step: 8
Training loss: 2.553255558013916
Validation loss: 2.652758723946028

Epoch: 6| Step: 9
Training loss: 3.070328712463379
Validation loss: 2.6522742368841685

Epoch: 6| Step: 10
Training loss: 3.5864944458007812
Validation loss: 2.6527767873579458

Epoch: 6| Step: 11
Training loss: 2.33823299407959
Validation loss: 2.6552454912534325

Epoch: 6| Step: 12
Training loss: 2.9375436305999756
Validation loss: 2.654848111573086

Epoch: 6| Step: 13
Training loss: 2.6165101528167725
Validation loss: 2.654920147311303

Epoch: 35| Step: 0
Training loss: 2.8239946365356445
Validation loss: 2.657307399216519

Epoch: 6| Step: 1
Training loss: 2.612189292907715
Validation loss: 2.652299378507881

Epoch: 6| Step: 2
Training loss: 1.818974256515503
Validation loss: 2.654761709192748

Epoch: 6| Step: 3
Training loss: 3.110734224319458
Validation loss: 2.6550866506432973

Epoch: 6| Step: 4
Training loss: 3.539348840713501
Validation loss: 2.650784674511161

Epoch: 6| Step: 5
Training loss: 2.395554542541504
Validation loss: 2.6526429422440065

Epoch: 6| Step: 6
Training loss: 2.9986467361450195
Validation loss: 2.6535767906455585

Epoch: 6| Step: 7
Training loss: 2.397721767425537
Validation loss: 2.6529181234298216

Epoch: 6| Step: 8
Training loss: 3.5464529991149902
Validation loss: 2.652356847640007

Epoch: 6| Step: 9
Training loss: 3.144526720046997
Validation loss: 2.6477990611906974

Epoch: 6| Step: 10
Training loss: 2.531811237335205
Validation loss: 2.644951812682613

Epoch: 6| Step: 11
Training loss: 2.246440887451172
Validation loss: 2.646321996565788

Epoch: 6| Step: 12
Training loss: 3.0956883430480957
Validation loss: 2.6451407273610434

Epoch: 6| Step: 13
Training loss: 3.4452033042907715
Validation loss: 2.6424909586547525

Epoch: 36| Step: 0
Training loss: 2.1115920543670654
Validation loss: 2.642636586261052

Epoch: 6| Step: 1
Training loss: 3.64896821975708
Validation loss: 2.6431770863071566

Epoch: 6| Step: 2
Training loss: 2.829724073410034
Validation loss: 2.6466526780077206

Epoch: 6| Step: 3
Training loss: 2.281324863433838
Validation loss: 2.6508163816185406

Epoch: 6| Step: 4
Training loss: 2.3187007904052734
Validation loss: 2.654681169858543

Epoch: 6| Step: 5
Training loss: 3.4673893451690674
Validation loss: 2.6526657483911

Epoch: 6| Step: 6
Training loss: 3.242173433303833
Validation loss: 2.6486527714678036

Epoch: 6| Step: 7
Training loss: 2.7603695392608643
Validation loss: 2.648801952280024

Epoch: 6| Step: 8
Training loss: 2.68709135055542
Validation loss: 2.6388968165202806

Epoch: 6| Step: 9
Training loss: 2.5831351280212402
Validation loss: 2.6415196336725706

Epoch: 6| Step: 10
Training loss: 2.201373338699341
Validation loss: 2.645212111934539

Epoch: 6| Step: 11
Training loss: 3.5086843967437744
Validation loss: 2.647985117409819

Epoch: 6| Step: 12
Training loss: 3.076608657836914
Validation loss: 2.6421726160151984

Epoch: 6| Step: 13
Training loss: 2.4453046321868896
Validation loss: 2.649980721935149

Epoch: 37| Step: 0
Training loss: 2.263885974884033
Validation loss: 2.6515099258833033

Epoch: 6| Step: 1
Training loss: 3.9967398643493652
Validation loss: 2.6553963691957536

Epoch: 6| Step: 2
Training loss: 2.7329282760620117
Validation loss: 2.6566585750990015

Epoch: 6| Step: 3
Training loss: 1.9440027475357056
Validation loss: 2.659066479693177

Epoch: 6| Step: 4
Training loss: 3.5535387992858887
Validation loss: 2.6703788618887625

Epoch: 6| Step: 5
Training loss: 2.4936888217926025
Validation loss: 2.659684770850725

Epoch: 6| Step: 6
Training loss: 2.616464853286743
Validation loss: 2.6534162131688928

Epoch: 6| Step: 7
Training loss: 3.0887622833251953
Validation loss: 2.647605252522294

Epoch: 6| Step: 8
Training loss: 2.830822229385376
Validation loss: 2.647706365072599

Epoch: 6| Step: 9
Training loss: 3.1368050575256348
Validation loss: 2.6470915784117994

Epoch: 6| Step: 10
Training loss: 2.1538710594177246
Validation loss: 2.647406990810107

Epoch: 6| Step: 11
Training loss: 2.8189899921417236
Validation loss: 2.649258562313613

Epoch: 6| Step: 12
Training loss: 2.8176016807556152
Validation loss: 2.643987606930476

Epoch: 6| Step: 13
Training loss: 2.928757667541504
Validation loss: 2.6430759532477266

Epoch: 38| Step: 0
Training loss: 2.7683186531066895
Validation loss: 2.6350995545746176

Epoch: 6| Step: 1
Training loss: 2.6581363677978516
Validation loss: 2.6330952798166583

Epoch: 6| Step: 2
Training loss: 2.7501778602600098
Validation loss: 2.6358706694777294

Epoch: 6| Step: 3
Training loss: 3.245776891708374
Validation loss: 2.6358177187622234

Epoch: 6| Step: 4
Training loss: 3.3182966709136963
Validation loss: 2.6339568809796403

Epoch: 6| Step: 5
Training loss: 3.422043561935425
Validation loss: 2.6291853638105493

Epoch: 6| Step: 6
Training loss: 2.6415398120880127
Validation loss: 2.621237447184901

Epoch: 6| Step: 7
Training loss: 2.8938651084899902
Validation loss: 2.6282164512142057

Epoch: 6| Step: 8
Training loss: 2.72011661529541
Validation loss: 2.6204313949872087

Epoch: 6| Step: 9
Training loss: 2.845393180847168
Validation loss: 2.627933491942703

Epoch: 6| Step: 10
Training loss: 2.225860595703125
Validation loss: 2.623277794930243

Epoch: 6| Step: 11
Training loss: 3.042559862136841
Validation loss: 2.6268434088717223

Epoch: 6| Step: 12
Training loss: 1.825221300125122
Validation loss: 2.6341778796206237

Epoch: 6| Step: 13
Training loss: 2.8125112056732178
Validation loss: 2.6304907670585056

Epoch: 39| Step: 0
Training loss: 1.98030424118042
Validation loss: 2.6181288073139806

Epoch: 6| Step: 1
Training loss: 3.215714454650879
Validation loss: 2.616634826506338

Epoch: 6| Step: 2
Training loss: 2.6525092124938965
Validation loss: 2.6184918803553425

Epoch: 6| Step: 3
Training loss: 2.3301897048950195
Validation loss: 2.6227709965039323

Epoch: 6| Step: 4
Training loss: 3.1838817596435547
Validation loss: 2.6270305392562703

Epoch: 6| Step: 5
Training loss: 2.7359235286712646
Validation loss: 2.662855455952306

Epoch: 6| Step: 6
Training loss: 2.583143949508667
Validation loss: 2.6273493356602167

Epoch: 6| Step: 7
Training loss: 2.7120413780212402
Validation loss: 2.627617318143127

Epoch: 6| Step: 8
Training loss: 3.7046380043029785
Validation loss: 2.624251893771592

Epoch: 6| Step: 9
Training loss: 3.2077417373657227
Validation loss: 2.6212750865567114

Epoch: 6| Step: 10
Training loss: 2.067615270614624
Validation loss: 2.615721574393652

Epoch: 6| Step: 11
Training loss: 2.897404193878174
Validation loss: 2.6160865752927718

Epoch: 6| Step: 12
Training loss: 3.346747636795044
Validation loss: 2.6103621323903403

Epoch: 6| Step: 13
Training loss: 2.4570295810699463
Validation loss: 2.6091885566711426

Epoch: 40| Step: 0
Training loss: 2.779815673828125
Validation loss: 2.6093003032028035

Epoch: 6| Step: 1
Training loss: 3.503775119781494
Validation loss: 2.61741304397583

Epoch: 6| Step: 2
Training loss: 2.5047385692596436
Validation loss: 2.628776765638782

Epoch: 6| Step: 3
Training loss: 2.860907554626465
Validation loss: 2.6314029539785078

Epoch: 6| Step: 4
Training loss: 3.1268296241760254
Validation loss: 2.6262718451920377

Epoch: 6| Step: 5
Training loss: 2.4374823570251465
Validation loss: 2.6191332288967666

Epoch: 6| Step: 6
Training loss: 2.587031364440918
Validation loss: 2.6145312632283857

Epoch: 6| Step: 7
Training loss: 2.080881357192993
Validation loss: 2.607800196575862

Epoch: 6| Step: 8
Training loss: 2.405949592590332
Validation loss: 2.6058015284999723

Epoch: 6| Step: 9
Training loss: 2.8510513305664062
Validation loss: 2.6045611878877044

Epoch: 6| Step: 10
Training loss: 3.088679075241089
Validation loss: 2.605232725861252

Epoch: 6| Step: 11
Training loss: 3.1458280086517334
Validation loss: 2.598843656560426

Epoch: 6| Step: 12
Training loss: 2.272895336151123
Validation loss: 2.602491594129993

Epoch: 6| Step: 13
Training loss: 3.725480079650879
Validation loss: 2.5996992075315086

Epoch: 41| Step: 0
Training loss: 2.3966987133026123
Validation loss: 2.601982549954486

Epoch: 6| Step: 1
Training loss: 3.3937649726867676
Validation loss: 2.600265295274796

Epoch: 6| Step: 2
Training loss: 2.313326835632324
Validation loss: 2.600501037413074

Epoch: 6| Step: 3
Training loss: 2.8940939903259277
Validation loss: 2.5961593735602593

Epoch: 6| Step: 4
Training loss: 2.8478188514709473
Validation loss: 2.601246469764299

Epoch: 6| Step: 5
Training loss: 3.0955004692077637
Validation loss: 2.6085469568929365

Epoch: 6| Step: 6
Training loss: 2.8949170112609863
Validation loss: 2.6086874418361212

Epoch: 6| Step: 7
Training loss: 2.470284938812256
Validation loss: 2.607030363493068

Epoch: 6| Step: 8
Training loss: 2.9503939151763916
Validation loss: 2.6054802607464533

Epoch: 6| Step: 9
Training loss: 2.4747300148010254
Validation loss: 2.5985362247754167

Epoch: 6| Step: 10
Training loss: 2.3217854499816895
Validation loss: 2.59467815327388

Epoch: 6| Step: 11
Training loss: 3.395331382751465
Validation loss: 2.5924250823195263

Epoch: 6| Step: 12
Training loss: 2.7211594581604004
Validation loss: 2.592956281477405

Epoch: 6| Step: 13
Training loss: 2.7133662700653076
Validation loss: 2.5943979345342165

Epoch: 42| Step: 0
Training loss: 3.2543106079101562
Validation loss: 2.591993296018211

Epoch: 6| Step: 1
Training loss: 2.005782127380371
Validation loss: 2.5948670448795443

Epoch: 6| Step: 2
Training loss: 2.816171646118164
Validation loss: 2.597235142543752

Epoch: 6| Step: 3
Training loss: 2.899590492248535
Validation loss: 2.5957800649827525

Epoch: 6| Step: 4
Training loss: 2.4375948905944824
Validation loss: 2.596579518369449

Epoch: 6| Step: 5
Training loss: 3.1178150177001953
Validation loss: 2.595918598995414

Epoch: 6| Step: 6
Training loss: 2.9050276279449463
Validation loss: 2.587265142830469

Epoch: 6| Step: 7
Training loss: 2.8614091873168945
Validation loss: 2.588277929572649

Epoch: 6| Step: 8
Training loss: 2.8244330883026123
Validation loss: 2.5872375683117936

Epoch: 6| Step: 9
Training loss: 2.472531318664551
Validation loss: 2.5911702725195114

Epoch: 6| Step: 10
Training loss: 3.013650894165039
Validation loss: 2.6041891600496028

Epoch: 6| Step: 11
Training loss: 2.689520835876465
Validation loss: 2.6078759854839695

Epoch: 6| Step: 12
Training loss: 2.597890615463257
Validation loss: 2.61438185937943

Epoch: 6| Step: 13
Training loss: 3.10394287109375
Validation loss: 2.5979507200179563

Epoch: 43| Step: 0
Training loss: 2.2847278118133545
Validation loss: 2.5960289252701627

Epoch: 6| Step: 1
Training loss: 2.2435569763183594
Validation loss: 2.5831660173272573

Epoch: 6| Step: 2
Training loss: 2.8584580421447754
Validation loss: 2.5816161247991745

Epoch: 6| Step: 3
Training loss: 3.8277480602264404
Validation loss: 2.5810935292192685

Epoch: 6| Step: 4
Training loss: 2.9597644805908203
Validation loss: 2.5852186218384774

Epoch: 6| Step: 5
Training loss: 2.7599968910217285
Validation loss: 2.582565894690893

Epoch: 6| Step: 6
Training loss: 2.3211510181427
Validation loss: 2.593969678366056

Epoch: 6| Step: 7
Training loss: 2.4288172721862793
Validation loss: 2.6017644302819365

Epoch: 6| Step: 8
Training loss: 1.9861814975738525
Validation loss: 2.59185726411881

Epoch: 6| Step: 9
Training loss: 3.4673585891723633
Validation loss: 2.5953231960214596

Epoch: 6| Step: 10
Training loss: 2.7147068977355957
Validation loss: 2.588339723566527

Epoch: 6| Step: 11
Training loss: 2.628119468688965
Validation loss: 2.574253761640159

Epoch: 6| Step: 12
Training loss: 3.240490436553955
Validation loss: 2.5768183610772573

Epoch: 6| Step: 13
Training loss: 3.299271583557129
Validation loss: 2.5920204321543374

Epoch: 44| Step: 0
Training loss: 3.394880533218384
Validation loss: 2.6170058455518497

Epoch: 6| Step: 1
Training loss: 2.223132610321045
Validation loss: 2.6165410293045865

Epoch: 6| Step: 2
Training loss: 2.4203860759735107
Validation loss: 2.6173227064071165

Epoch: 6| Step: 3
Training loss: 3.056811571121216
Validation loss: 2.6006492748055408

Epoch: 6| Step: 4
Training loss: 2.4956395626068115
Validation loss: 2.589928824414489

Epoch: 6| Step: 5
Training loss: 2.964008331298828
Validation loss: 2.6101244905943513

Epoch: 6| Step: 6
Training loss: 3.1974215507507324
Validation loss: 2.63421784165085

Epoch: 6| Step: 7
Training loss: 2.9310851097106934
Validation loss: 2.5861515255384546

Epoch: 6| Step: 8
Training loss: 2.6211512088775635
Validation loss: 2.5707185319674912

Epoch: 6| Step: 9
Training loss: 2.5086119174957275
Validation loss: 2.564696006877448

Epoch: 6| Step: 10
Training loss: 2.4717280864715576
Validation loss: 2.5644314724911927

Epoch: 6| Step: 11
Training loss: 3.1041951179504395
Validation loss: 2.576051099326021

Epoch: 6| Step: 12
Training loss: 2.9692399501800537
Validation loss: 2.578762026243312

Epoch: 6| Step: 13
Training loss: 2.088405132293701
Validation loss: 2.584983964120188

Epoch: 45| Step: 0
Training loss: 2.0829882621765137
Validation loss: 2.5669621677808863

Epoch: 6| Step: 1
Training loss: 2.649293899536133
Validation loss: 2.555284725722446

Epoch: 6| Step: 2
Training loss: 2.2514021396636963
Validation loss: 2.550269990838984

Epoch: 6| Step: 3
Training loss: 3.031733989715576
Validation loss: 2.549086739940028

Epoch: 6| Step: 4
Training loss: 2.3853938579559326
Validation loss: 2.5476838209295787

Epoch: 6| Step: 5
Training loss: 3.0418684482574463
Validation loss: 2.5583354683332544

Epoch: 6| Step: 6
Training loss: 3.6349949836730957
Validation loss: 2.5636074081543954

Epoch: 6| Step: 7
Training loss: 3.0517923831939697
Validation loss: 2.5585276670353387

Epoch: 6| Step: 8
Training loss: 2.325529098510742
Validation loss: 2.5552939727742183

Epoch: 6| Step: 9
Training loss: 2.7897512912750244
Validation loss: 2.5584654859317246

Epoch: 6| Step: 10
Training loss: 2.4091591835021973
Validation loss: 2.5610376147813696

Epoch: 6| Step: 11
Training loss: 3.2720327377319336
Validation loss: 2.5718653560966573

Epoch: 6| Step: 12
Training loss: 2.4772214889526367
Validation loss: 2.5603495515802854

Epoch: 6| Step: 13
Training loss: 3.220097780227661
Validation loss: 2.5586443716479885

Epoch: 46| Step: 0
Training loss: 2.190171003341675
Validation loss: 2.5504614665944088

Epoch: 6| Step: 1
Training loss: 2.4892032146453857
Validation loss: 2.5397556802277923

Epoch: 6| Step: 2
Training loss: 2.1866040229797363
Validation loss: 2.5379112382088937

Epoch: 6| Step: 3
Training loss: 2.5067834854125977
Validation loss: 2.540872671270883

Epoch: 6| Step: 4
Training loss: 2.9451818466186523
Validation loss: 2.54475845572769

Epoch: 6| Step: 5
Training loss: 2.565565586090088
Validation loss: 2.5509911044951408

Epoch: 6| Step: 6
Training loss: 3.6814956665039062
Validation loss: 2.5627451712085354

Epoch: 6| Step: 7
Training loss: 1.8954017162322998
Validation loss: 2.564053976407615

Epoch: 6| Step: 8
Training loss: 2.709803581237793
Validation loss: 2.580122665692401

Epoch: 6| Step: 9
Training loss: 3.241053342819214
Validation loss: 2.574470522583172

Epoch: 6| Step: 10
Training loss: 2.7630112171173096
Validation loss: 2.58317550792489

Epoch: 6| Step: 11
Training loss: 2.7905845642089844
Validation loss: 2.5500665967182448

Epoch: 6| Step: 12
Training loss: 3.337693691253662
Validation loss: 2.5440591432714976

Epoch: 6| Step: 13
Training loss: 3.1618573665618896
Validation loss: 2.535622009667017

Epoch: 47| Step: 0
Training loss: 2.7269504070281982
Validation loss: 2.5438476839373187

Epoch: 6| Step: 1
Training loss: 2.652099132537842
Validation loss: 2.5439191813110025

Epoch: 6| Step: 2
Training loss: 2.2314090728759766
Validation loss: 2.5529821534310617

Epoch: 6| Step: 3
Training loss: 2.968991279602051
Validation loss: 2.5525627674595004

Epoch: 6| Step: 4
Training loss: 3.118248462677002
Validation loss: 2.564702787706929

Epoch: 6| Step: 5
Training loss: 2.4436135292053223
Validation loss: 2.5787869448302896

Epoch: 6| Step: 6
Training loss: 2.200985908508301
Validation loss: 2.5952037765133764

Epoch: 6| Step: 7
Training loss: 3.385692596435547
Validation loss: 2.5950972085357993

Epoch: 6| Step: 8
Training loss: 3.1357531547546387
Validation loss: 2.5819503773925123

Epoch: 6| Step: 9
Training loss: 2.1483278274536133
Validation loss: 2.5549738355862197

Epoch: 6| Step: 10
Training loss: 2.99753475189209
Validation loss: 2.5376474113874536

Epoch: 6| Step: 11
Training loss: 3.000833749771118
Validation loss: 2.5318002905896915

Epoch: 6| Step: 12
Training loss: 2.62103533744812
Validation loss: 2.5392064253489175

Epoch: 6| Step: 13
Training loss: 2.584956169128418
Validation loss: 2.560151997432914

Epoch: 48| Step: 0
Training loss: 2.439208507537842
Validation loss: 2.5851952004176315

Epoch: 6| Step: 1
Training loss: 2.8991074562072754
Validation loss: 2.623021756449053

Epoch: 6| Step: 2
Training loss: 2.936025619506836
Validation loss: 2.6580796523760726

Epoch: 6| Step: 3
Training loss: 3.124238967895508
Validation loss: 2.676841566639562

Epoch: 6| Step: 4
Training loss: 2.7285757064819336
Validation loss: 2.6482088745281263

Epoch: 6| Step: 5
Training loss: 2.5611135959625244
Validation loss: 2.665999840664607

Epoch: 6| Step: 6
Training loss: 2.370983839035034
Validation loss: 2.6478497366751395

Epoch: 6| Step: 7
Training loss: 3.1537246704101562
Validation loss: 2.5925129152113393

Epoch: 6| Step: 8
Training loss: 2.526113271713257
Validation loss: 2.541231391250446

Epoch: 6| Step: 9
Training loss: 2.4203832149505615
Validation loss: 2.5291632003681634

Epoch: 6| Step: 10
Training loss: 3.430319309234619
Validation loss: 2.5350386814404557

Epoch: 6| Step: 11
Training loss: 2.2835607528686523
Validation loss: 2.5470733719487346

Epoch: 6| Step: 12
Training loss: 3.0972461700439453
Validation loss: 2.564166284376575

Epoch: 6| Step: 13
Training loss: 2.321864128112793
Validation loss: 2.591905850236134

Epoch: 49| Step: 0
Training loss: 2.5237936973571777
Validation loss: 2.6239730132523404

Epoch: 6| Step: 1
Training loss: 2.817532539367676
Validation loss: 2.6242712133674213

Epoch: 6| Step: 2
Training loss: 3.412458896636963
Validation loss: 2.5870992470813055

Epoch: 6| Step: 3
Training loss: 2.8053770065307617
Validation loss: 2.5535121387051

Epoch: 6| Step: 4
Training loss: 2.2048685550689697
Validation loss: 2.531611907866693

Epoch: 6| Step: 5
Training loss: 2.1303188800811768
Validation loss: 2.525468490457022

Epoch: 6| Step: 6
Training loss: 2.2083587646484375
Validation loss: 2.5358525091601956

Epoch: 6| Step: 7
Training loss: 2.7347216606140137
Validation loss: 2.5509420902498308

Epoch: 6| Step: 8
Training loss: 3.2909791469573975
Validation loss: 2.5628493908912904

Epoch: 6| Step: 9
Training loss: 2.9656522274017334
Validation loss: 2.5561934850549184

Epoch: 6| Step: 10
Training loss: 3.4219677448272705
Validation loss: 2.556572280904298

Epoch: 6| Step: 11
Training loss: 2.595968723297119
Validation loss: 2.553010497041928

Epoch: 6| Step: 12
Training loss: 2.886537551879883
Validation loss: 2.544082341655608

Epoch: 6| Step: 13
Training loss: 2.631345272064209
Validation loss: 2.528275884607787

Epoch: 50| Step: 0
Training loss: 2.304934501647949
Validation loss: 2.525539690448392

Epoch: 6| Step: 1
Training loss: 2.2381389141082764
Validation loss: 2.523232816368021

Epoch: 6| Step: 2
Training loss: 3.7494959831237793
Validation loss: 2.520838955397247

Epoch: 6| Step: 3
Training loss: 2.8055121898651123
Validation loss: 2.5281269627232708

Epoch: 6| Step: 4
Training loss: 2.943037509918213
Validation loss: 2.524669436998265

Epoch: 6| Step: 5
Training loss: 3.154123544692993
Validation loss: 2.523205658440949

Epoch: 6| Step: 6
Training loss: 1.7644908428192139
Validation loss: 2.531018753205576

Epoch: 6| Step: 7
Training loss: 3.1000311374664307
Validation loss: 2.5234056544560257

Epoch: 6| Step: 8
Training loss: 2.37199330329895
Validation loss: 2.525925244054487

Epoch: 6| Step: 9
Training loss: 2.4831931591033936
Validation loss: 2.523976097824753

Epoch: 6| Step: 10
Training loss: 2.0710630416870117
Validation loss: 2.5229909445649836

Epoch: 6| Step: 11
Training loss: 3.410933494567871
Validation loss: 2.5282434058445755

Epoch: 6| Step: 12
Training loss: 2.7101447582244873
Validation loss: 2.526097902687647

Epoch: 6| Step: 13
Training loss: 3.0154178142547607
Validation loss: 2.5285564596934984

Epoch: 51| Step: 0
Training loss: 3.080979824066162
Validation loss: 2.5360058507611676

Epoch: 6| Step: 1
Training loss: 1.8090945482254028
Validation loss: 2.540682505535823

Epoch: 6| Step: 2
Training loss: 2.022057294845581
Validation loss: 2.568044618893695

Epoch: 6| Step: 3
Training loss: 1.7810471057891846
Validation loss: 2.571602600877003

Epoch: 6| Step: 4
Training loss: 2.6118736267089844
Validation loss: 2.5937294242202595

Epoch: 6| Step: 5
Training loss: 3.6467678546905518
Validation loss: 2.616335891908215

Epoch: 6| Step: 6
Training loss: 3.50059175491333
Validation loss: 2.5978714266131

Epoch: 6| Step: 7
Training loss: 2.822965145111084
Validation loss: 2.5600286581182994

Epoch: 6| Step: 8
Training loss: 1.6758335828781128
Validation loss: 2.529557622889037

Epoch: 6| Step: 9
Training loss: 2.677446126937866
Validation loss: 2.5128846527427755

Epoch: 6| Step: 10
Training loss: 2.8956031799316406
Validation loss: 2.5173443363558863

Epoch: 6| Step: 11
Training loss: 3.182333469390869
Validation loss: 2.5378307322020173

Epoch: 6| Step: 12
Training loss: 3.3907203674316406
Validation loss: 2.548730860474289

Epoch: 6| Step: 13
Training loss: 3.453465223312378
Validation loss: 2.5700706512697282

Epoch: 52| Step: 0
Training loss: 2.701233386993408
Validation loss: 2.55724428033316

Epoch: 6| Step: 1
Training loss: 2.2376277446746826
Validation loss: 2.5326178073883057

Epoch: 6| Step: 2
Training loss: 2.835124969482422
Validation loss: 2.532792168278848

Epoch: 6| Step: 3
Training loss: 2.4122602939605713
Validation loss: 2.5318602695259997

Epoch: 6| Step: 4
Training loss: 3.0044660568237305
Validation loss: 2.528901038631316

Epoch: 6| Step: 5
Training loss: 2.9972643852233887
Validation loss: 2.5272519050105924

Epoch: 6| Step: 6
Training loss: 2.639617919921875
Validation loss: 2.5218000463260117

Epoch: 6| Step: 7
Training loss: 3.120610475540161
Validation loss: 2.5200070232473393

Epoch: 6| Step: 8
Training loss: 2.2457261085510254
Validation loss: 2.5167725650213097

Epoch: 6| Step: 9
Training loss: 2.7306594848632812
Validation loss: 2.516479161477858

Epoch: 6| Step: 10
Training loss: 2.3245813846588135
Validation loss: 2.509320174494097

Epoch: 6| Step: 11
Training loss: 3.513617515563965
Validation loss: 2.512668248145811

Epoch: 6| Step: 12
Training loss: 2.7698683738708496
Validation loss: 2.5152015634762344

Epoch: 6| Step: 13
Training loss: 2.7179195880889893
Validation loss: 2.5213191432337605

Epoch: 53| Step: 0
Training loss: 2.5393941402435303
Validation loss: 2.533945455346056

Epoch: 6| Step: 1
Training loss: 3.020979166030884
Validation loss: 2.535133187488843

Epoch: 6| Step: 2
Training loss: 1.7824677228927612
Validation loss: 2.529286825528709

Epoch: 6| Step: 3
Training loss: 3.788769245147705
Validation loss: 2.5241254837282243

Epoch: 6| Step: 4
Training loss: 2.6803178787231445
Validation loss: 2.5209975191341933

Epoch: 6| Step: 5
Training loss: 2.436310291290283
Validation loss: 2.513978660747569

Epoch: 6| Step: 6
Training loss: 3.1705827713012695
Validation loss: 2.508596856106994

Epoch: 6| Step: 7
Training loss: 2.347637176513672
Validation loss: 2.5087063030530046

Epoch: 6| Step: 8
Training loss: 2.743326425552368
Validation loss: 2.510794201204854

Epoch: 6| Step: 9
Training loss: 2.479372024536133
Validation loss: 2.5027581363595943

Epoch: 6| Step: 10
Training loss: 2.693387031555176
Validation loss: 2.49965045016299

Epoch: 6| Step: 11
Training loss: 2.5065715312957764
Validation loss: 2.5040237211411998

Epoch: 6| Step: 12
Training loss: 2.8780786991119385
Validation loss: 2.5084887268722698

Epoch: 6| Step: 13
Training loss: 3.145996570587158
Validation loss: 2.508218249967021

Epoch: 54| Step: 0
Training loss: 2.8667569160461426
Validation loss: 2.50997410538376

Epoch: 6| Step: 1
Training loss: 2.4350080490112305
Validation loss: 2.5087990606984785

Epoch: 6| Step: 2
Training loss: 2.7880635261535645
Validation loss: 2.514652018905968

Epoch: 6| Step: 3
Training loss: 2.6195220947265625
Validation loss: 2.518568859305433

Epoch: 6| Step: 4
Training loss: 3.069369316101074
Validation loss: 2.516778222976192

Epoch: 6| Step: 5
Training loss: 3.159641981124878
Validation loss: 2.51929118299997

Epoch: 6| Step: 6
Training loss: 2.6834983825683594
Validation loss: 2.517785972164523

Epoch: 6| Step: 7
Training loss: 1.9617114067077637
Validation loss: 2.518966661986484

Epoch: 6| Step: 8
Training loss: 2.2678732872009277
Validation loss: 2.5171381017213226

Epoch: 6| Step: 9
Training loss: 3.5830254554748535
Validation loss: 2.5113045938553347

Epoch: 6| Step: 10
Training loss: 2.6374902725219727
Validation loss: 2.515313679172147

Epoch: 6| Step: 11
Training loss: 2.129140853881836
Validation loss: 2.5097259116429154

Epoch: 6| Step: 12
Training loss: 2.7634787559509277
Validation loss: 2.503195233242486

Epoch: 6| Step: 13
Training loss: 3.1349825859069824
Validation loss: 2.499658320539741

Epoch: 55| Step: 0
Training loss: 2.486917495727539
Validation loss: 2.5080652595848165

Epoch: 6| Step: 1
Training loss: 2.7911877632141113
Validation loss: 2.507800755962249

Epoch: 6| Step: 2
Training loss: 2.763082504272461
Validation loss: 2.506426526654151

Epoch: 6| Step: 3
Training loss: 2.4229555130004883
Validation loss: 2.508311710050029

Epoch: 6| Step: 4
Training loss: 3.4628043174743652
Validation loss: 2.5073755248900382

Epoch: 6| Step: 5
Training loss: 2.450326919555664
Validation loss: 2.515751943793348

Epoch: 6| Step: 6
Training loss: 2.084717273712158
Validation loss: 2.508409571904008

Epoch: 6| Step: 7
Training loss: 2.813781261444092
Validation loss: 2.520532590086742

Epoch: 6| Step: 8
Training loss: 2.0418622493743896
Validation loss: 2.527664839580495

Epoch: 6| Step: 9
Training loss: 2.5514535903930664
Validation loss: 2.522504550154491

Epoch: 6| Step: 10
Training loss: 3.5066802501678467
Validation loss: 2.5268734424344954

Epoch: 6| Step: 11
Training loss: 2.7562122344970703
Validation loss: 2.513726995837304

Epoch: 6| Step: 12
Training loss: 2.9166502952575684
Validation loss: 2.5205256682570263

Epoch: 6| Step: 13
Training loss: 2.775468349456787
Validation loss: 2.5107544570840816

Epoch: 56| Step: 0
Training loss: 2.5431602001190186
Validation loss: 2.5046047933640017

Epoch: 6| Step: 1
Training loss: 2.4090025424957275
Validation loss: 2.504786432430308

Epoch: 6| Step: 2
Training loss: 3.2865705490112305
Validation loss: 2.5083418866639495

Epoch: 6| Step: 3
Training loss: 3.018659830093384
Validation loss: 2.5094294266034196

Epoch: 6| Step: 4
Training loss: 3.074737310409546
Validation loss: 2.514944709757323

Epoch: 6| Step: 5
Training loss: 2.307002305984497
Validation loss: 2.516382658353416

Epoch: 6| Step: 6
Training loss: 3.2917609214782715
Validation loss: 2.517134713870223

Epoch: 6| Step: 7
Training loss: 2.5163779258728027
Validation loss: 2.5181449228717434

Epoch: 6| Step: 8
Training loss: 2.921957492828369
Validation loss: 2.517257818611719

Epoch: 6| Step: 9
Training loss: 2.430163860321045
Validation loss: 2.528347125617407

Epoch: 6| Step: 10
Training loss: 2.8711562156677246
Validation loss: 2.547400705275997

Epoch: 6| Step: 11
Training loss: 1.4695699214935303
Validation loss: 2.563901996099821

Epoch: 6| Step: 12
Training loss: 2.635188341140747
Validation loss: 2.575671278020387

Epoch: 6| Step: 13
Training loss: 3.1572890281677246
Validation loss: 2.583119789759318

Epoch: 57| Step: 0
Training loss: 2.3734779357910156
Validation loss: 2.5772008870237615

Epoch: 6| Step: 1
Training loss: 2.722294807434082
Validation loss: 2.5930405867997037

Epoch: 6| Step: 2
Training loss: 2.6746304035186768
Validation loss: 2.548678546823481

Epoch: 6| Step: 3
Training loss: 3.1950278282165527
Validation loss: 2.538178079871721

Epoch: 6| Step: 4
Training loss: 3.326021432876587
Validation loss: 2.5214508784714567

Epoch: 6| Step: 5
Training loss: 2.158910036087036
Validation loss: 2.5086132480252172

Epoch: 6| Step: 6
Training loss: 2.885802745819092
Validation loss: 2.498702423546904

Epoch: 6| Step: 7
Training loss: 2.8153090476989746
Validation loss: 2.4917576236109578

Epoch: 6| Step: 8
Training loss: 1.9010826349258423
Validation loss: 2.4967867251365417

Epoch: 6| Step: 9
Training loss: 2.9918816089630127
Validation loss: 2.4888559464485414

Epoch: 6| Step: 10
Training loss: 3.33827543258667
Validation loss: 2.4913797070903163

Epoch: 6| Step: 11
Training loss: 1.800241231918335
Validation loss: 2.4926040249486126

Epoch: 6| Step: 12
Training loss: 3.1542935371398926
Validation loss: 2.4882338200846026

Epoch: 6| Step: 13
Training loss: 2.5958516597747803
Validation loss: 2.493847167620095

Epoch: 58| Step: 0
Training loss: 2.724226474761963
Validation loss: 2.4860782366926952

Epoch: 6| Step: 1
Training loss: 2.598816156387329
Validation loss: 2.4880992802240516

Epoch: 6| Step: 2
Training loss: 2.2067551612854004
Validation loss: 2.491066473786549

Epoch: 6| Step: 3
Training loss: 2.8193209171295166
Validation loss: 2.494007225959532

Epoch: 6| Step: 4
Training loss: 2.3820416927337646
Validation loss: 2.492562823398139

Epoch: 6| Step: 5
Training loss: 3.469357490539551
Validation loss: 2.495764422160323

Epoch: 6| Step: 6
Training loss: 3.0449295043945312
Validation loss: 2.4956225067056637

Epoch: 6| Step: 7
Training loss: 3.329195499420166
Validation loss: 2.5083682690897295

Epoch: 6| Step: 8
Training loss: 2.594778060913086
Validation loss: 2.5000877662371566

Epoch: 6| Step: 9
Training loss: 2.8470842838287354
Validation loss: 2.4988901948416107

Epoch: 6| Step: 10
Training loss: 2.3376355171203613
Validation loss: 2.493511938279675

Epoch: 6| Step: 11
Training loss: 2.4022340774536133
Validation loss: 2.4898392872143815

Epoch: 6| Step: 12
Training loss: 2.480360507965088
Validation loss: 2.4828927081118346

Epoch: 6| Step: 13
Training loss: 2.3456926345825195
Validation loss: 2.4881958269303843

Epoch: 59| Step: 0
Training loss: 2.3354718685150146
Validation loss: 2.484354431911181

Epoch: 6| Step: 1
Training loss: 2.4887547492980957
Validation loss: 2.484512657247564

Epoch: 6| Step: 2
Training loss: 2.110483407974243
Validation loss: 2.479498629928917

Epoch: 6| Step: 3
Training loss: 2.7862589359283447
Validation loss: 2.4831082667073896

Epoch: 6| Step: 4
Training loss: 1.9839794635772705
Validation loss: 2.4826325908783944

Epoch: 6| Step: 5
Training loss: 2.6072440147399902
Validation loss: 2.482094318636002

Epoch: 6| Step: 6
Training loss: 3.4324936866760254
Validation loss: 2.4817167610250492

Epoch: 6| Step: 7
Training loss: 2.5031960010528564
Validation loss: 2.4834429999833465

Epoch: 6| Step: 8
Training loss: 3.0337350368499756
Validation loss: 2.4875976911155124

Epoch: 6| Step: 9
Training loss: 2.580824375152588
Validation loss: 2.488723295991139

Epoch: 6| Step: 10
Training loss: 3.508601188659668
Validation loss: 2.483112863315049

Epoch: 6| Step: 11
Training loss: 3.7260379791259766
Validation loss: 2.496778380486273

Epoch: 6| Step: 12
Training loss: 2.311645984649658
Validation loss: 2.4998640860280683

Epoch: 6| Step: 13
Training loss: 2.1126880645751953
Validation loss: 2.5019190875432824

Epoch: 60| Step: 0
Training loss: 2.6285653114318848
Validation loss: 2.493698243171938

Epoch: 6| Step: 1
Training loss: 2.660428524017334
Validation loss: 2.492154780254569

Epoch: 6| Step: 2
Training loss: 2.91978120803833
Validation loss: 2.49093319267355

Epoch: 6| Step: 3
Training loss: 2.9163293838500977
Validation loss: 2.4844887282258723

Epoch: 6| Step: 4
Training loss: 2.038876533508301
Validation loss: 2.483809899258357

Epoch: 6| Step: 5
Training loss: 2.739901304244995
Validation loss: 2.4788019554589384

Epoch: 6| Step: 6
Training loss: 3.0517184734344482
Validation loss: 2.4748434533355055

Epoch: 6| Step: 7
Training loss: 3.1569199562072754
Validation loss: 2.477751995927544

Epoch: 6| Step: 8
Training loss: 2.788740873336792
Validation loss: 2.4805453669640327

Epoch: 6| Step: 9
Training loss: 2.5095973014831543
Validation loss: 2.478605257567539

Epoch: 6| Step: 10
Training loss: 2.841667652130127
Validation loss: 2.483533728507257

Epoch: 6| Step: 11
Training loss: 2.053219795227051
Validation loss: 2.4819987614949546

Epoch: 6| Step: 12
Training loss: 2.3840861320495605
Validation loss: 2.481401845973025

Epoch: 6| Step: 13
Training loss: 3.0425987243652344
Validation loss: 2.48350259565538

Epoch: 61| Step: 0
Training loss: 3.091611385345459
Validation loss: 2.4938064826432096

Epoch: 6| Step: 1
Training loss: 2.7494077682495117
Validation loss: 2.4948886722646733

Epoch: 6| Step: 2
Training loss: 2.370187759399414
Validation loss: 2.500132650457403

Epoch: 6| Step: 3
Training loss: 2.7752673625946045
Validation loss: 2.4976864553266958

Epoch: 6| Step: 4
Training loss: 3.0947043895721436
Validation loss: 2.5005637035574964

Epoch: 6| Step: 5
Training loss: 2.9016542434692383
Validation loss: 2.4936380014624646

Epoch: 6| Step: 6
Training loss: 2.185215473175049
Validation loss: 2.4865179625890588

Epoch: 6| Step: 7
Training loss: 1.8753767013549805
Validation loss: 2.475768248240153

Epoch: 6| Step: 8
Training loss: 2.918281078338623
Validation loss: 2.4729302672929663

Epoch: 6| Step: 9
Training loss: 2.3921380043029785
Validation loss: 2.4743745044995378

Epoch: 6| Step: 10
Training loss: 3.4528534412384033
Validation loss: 2.497138500213623

Epoch: 6| Step: 11
Training loss: 2.510096549987793
Validation loss: 2.4994930503188924

Epoch: 6| Step: 12
Training loss: 2.275266170501709
Validation loss: 2.5022574765707857

Epoch: 6| Step: 13
Training loss: 3.440535306930542
Validation loss: 2.4974098179929998

Epoch: 62| Step: 0
Training loss: 2.3946290016174316
Validation loss: 2.496234301597841

Epoch: 6| Step: 1
Training loss: 2.4411184787750244
Validation loss: 2.4880958628910843

Epoch: 6| Step: 2
Training loss: 3.1017909049987793
Validation loss: 2.4837782946966027

Epoch: 6| Step: 3
Training loss: 2.8287343978881836
Validation loss: 2.4814966314582416

Epoch: 6| Step: 4
Training loss: 3.4663267135620117
Validation loss: 2.4781560846554336

Epoch: 6| Step: 5
Training loss: 1.5579822063446045
Validation loss: 2.4832107841327624

Epoch: 6| Step: 6
Training loss: 2.559077262878418
Validation loss: 2.4799409579205256

Epoch: 6| Step: 7
Training loss: 2.479872226715088
Validation loss: 2.4789641928929154

Epoch: 6| Step: 8
Training loss: 2.0404727458953857
Validation loss: 2.498685944464899

Epoch: 6| Step: 9
Training loss: 2.6413064002990723
Validation loss: 2.5096848857018257

Epoch: 6| Step: 10
Training loss: 3.226201057434082
Validation loss: 2.51501638402221

Epoch: 6| Step: 11
Training loss: 3.3358592987060547
Validation loss: 2.5176076632674023

Epoch: 6| Step: 12
Training loss: 2.671013593673706
Validation loss: 2.523286801512523

Epoch: 6| Step: 13
Training loss: 3.2090883255004883
Validation loss: 2.516698870607602

Epoch: 63| Step: 0
Training loss: 3.134815216064453
Validation loss: 2.5188130999124176

Epoch: 6| Step: 1
Training loss: 3.3166675567626953
Validation loss: 2.520897521767565

Epoch: 6| Step: 2
Training loss: 2.6031298637390137
Validation loss: 2.513013844848961

Epoch: 6| Step: 3
Training loss: 2.8034253120422363
Validation loss: 2.5139404112292874

Epoch: 6| Step: 4
Training loss: 2.7596840858459473
Validation loss: 2.513615974815943

Epoch: 6| Step: 5
Training loss: 2.5886857509613037
Validation loss: 2.515325669319399

Epoch: 6| Step: 6
Training loss: 2.6539859771728516
Validation loss: 2.5152441634926745

Epoch: 6| Step: 7
Training loss: 2.4361886978149414
Validation loss: 2.5111054912690194

Epoch: 6| Step: 8
Training loss: 2.513686180114746
Validation loss: 2.508920987447103

Epoch: 6| Step: 9
Training loss: 2.567065715789795
Validation loss: 2.508032980785575

Epoch: 6| Step: 10
Training loss: 2.2389142513275146
Validation loss: 2.5079979563272126

Epoch: 6| Step: 11
Training loss: 2.8836612701416016
Validation loss: 2.5032760481680594

Epoch: 6| Step: 12
Training loss: 3.1025919914245605
Validation loss: 2.50338182398068

Epoch: 6| Step: 13
Training loss: 1.92396080493927
Validation loss: 2.5016564707602225

Epoch: 64| Step: 0
Training loss: 2.9524221420288086
Validation loss: 2.506370121432889

Epoch: 6| Step: 1
Training loss: 2.102055549621582
Validation loss: 2.5025704035194973

Epoch: 6| Step: 2
Training loss: 2.5466248989105225
Validation loss: 2.5095189514980523

Epoch: 6| Step: 3
Training loss: 2.748319387435913
Validation loss: 2.5187483244044806

Epoch: 6| Step: 4
Training loss: 3.026648998260498
Validation loss: 2.540235427118117

Epoch: 6| Step: 5
Training loss: 2.477351427078247
Validation loss: 2.546964996604509

Epoch: 6| Step: 6
Training loss: 3.0404160022735596
Validation loss: 2.5339983047977572

Epoch: 6| Step: 7
Training loss: 3.3542094230651855
Validation loss: 2.5142387420900407

Epoch: 6| Step: 8
Training loss: 2.2069473266601562
Validation loss: 2.511781169522193

Epoch: 6| Step: 9
Training loss: 3.1295905113220215
Validation loss: 2.4993712709796045

Epoch: 6| Step: 10
Training loss: 2.548546314239502
Validation loss: 2.4942597317439255

Epoch: 6| Step: 11
Training loss: 3.0697460174560547
Validation loss: 2.497816306288524

Epoch: 6| Step: 12
Training loss: 2.181053876876831
Validation loss: 2.4971476062651603

Epoch: 6| Step: 13
Training loss: 2.5073487758636475
Validation loss: 2.5011561403992357

Epoch: 65| Step: 0
Training loss: 3.391692638397217
Validation loss: 2.5017725549718386

Epoch: 6| Step: 1
Training loss: 3.5662829875946045
Validation loss: 2.500288813344894

Epoch: 6| Step: 2
Training loss: 2.6938095092773438
Validation loss: 2.4983249351542485

Epoch: 6| Step: 3
Training loss: 2.6404170989990234
Validation loss: 2.4939104023800103

Epoch: 6| Step: 4
Training loss: 2.208399772644043
Validation loss: 2.4928525699082242

Epoch: 6| Step: 5
Training loss: 2.7803921699523926
Validation loss: 2.491488190107448

Epoch: 6| Step: 6
Training loss: 2.939685344696045
Validation loss: 2.492166265364616

Epoch: 6| Step: 7
Training loss: 1.930246353149414
Validation loss: 2.498167268691524

Epoch: 6| Step: 8
Training loss: 2.5613222122192383
Validation loss: 2.4946161521378385

Epoch: 6| Step: 9
Training loss: 2.9996352195739746
Validation loss: 2.499315215695289

Epoch: 6| Step: 10
Training loss: 2.6240878105163574
Validation loss: 2.5038398645257436

Epoch: 6| Step: 11
Training loss: 2.758612871170044
Validation loss: 2.509533497595018

Epoch: 6| Step: 12
Training loss: 2.5262105464935303
Validation loss: 2.5196681279008106

Epoch: 6| Step: 13
Training loss: 1.9121949672698975
Validation loss: 2.5122885883495374

Epoch: 66| Step: 0
Training loss: 3.0581743717193604
Validation loss: 2.5144058273684595

Epoch: 6| Step: 1
Training loss: 2.6457772254943848
Validation loss: 2.5138458051989154

Epoch: 6| Step: 2
Training loss: 2.771393299102783
Validation loss: 2.5074318121838313

Epoch: 6| Step: 3
Training loss: 3.131470203399658
Validation loss: 2.5132119476154284

Epoch: 6| Step: 4
Training loss: 2.3988358974456787
Validation loss: 2.500779785135741

Epoch: 6| Step: 5
Training loss: 2.2119638919830322
Validation loss: 2.4945327902352936

Epoch: 6| Step: 6
Training loss: 2.2768173217773438
Validation loss: 2.4962114493052163

Epoch: 6| Step: 7
Training loss: 2.8235790729522705
Validation loss: 2.4959596203219507

Epoch: 6| Step: 8
Training loss: 2.6029281616210938
Validation loss: 2.4915572981680594

Epoch: 6| Step: 9
Training loss: 3.281404972076416
Validation loss: 2.500433998723184

Epoch: 6| Step: 10
Training loss: 1.9014945030212402
Validation loss: 2.5084533742679063

Epoch: 6| Step: 11
Training loss: 2.652472496032715
Validation loss: 2.511626135918402

Epoch: 6| Step: 12
Training loss: 3.6991047859191895
Validation loss: 2.520907220020089

Epoch: 6| Step: 13
Training loss: 1.8973543643951416
Validation loss: 2.517429990153159

Epoch: 67| Step: 0
Training loss: 3.1228599548339844
Validation loss: 2.5117785161541355

Epoch: 6| Step: 1
Training loss: 3.041105270385742
Validation loss: 2.500307639439901

Epoch: 6| Step: 2
Training loss: 2.8701348304748535
Validation loss: 2.496016130652479

Epoch: 6| Step: 3
Training loss: 2.8388466835021973
Validation loss: 2.490144419413741

Epoch: 6| Step: 4
Training loss: 2.9441516399383545
Validation loss: 2.4907905081267

Epoch: 6| Step: 5
Training loss: 2.2329750061035156
Validation loss: 2.492484151676137

Epoch: 6| Step: 6
Training loss: 2.6554970741271973
Validation loss: 2.495105092243482

Epoch: 6| Step: 7
Training loss: 2.2845711708068848
Validation loss: 2.492639200661772

Epoch: 6| Step: 8
Training loss: 2.494603157043457
Validation loss: 2.4941975121857016

Epoch: 6| Step: 9
Training loss: 3.1490726470947266
Validation loss: 2.4888639501346055

Epoch: 6| Step: 10
Training loss: 2.4186248779296875
Validation loss: 2.4931676823605775

Epoch: 6| Step: 11
Training loss: 2.166935443878174
Validation loss: 2.4911159123143842

Epoch: 6| Step: 12
Training loss: 2.3557662963867188
Validation loss: 2.485210939120221

Epoch: 6| Step: 13
Training loss: 3.226297378540039
Validation loss: 2.4855425768001105

Epoch: 68| Step: 0
Training loss: 2.7996950149536133
Validation loss: 2.4834752236643145

Epoch: 6| Step: 1
Training loss: 3.7039780616760254
Validation loss: 2.478410756716164

Epoch: 6| Step: 2
Training loss: 2.7194061279296875
Validation loss: 2.471552638597386

Epoch: 6| Step: 3
Training loss: 2.7051897048950195
Validation loss: 2.4657015185202322

Epoch: 6| Step: 4
Training loss: 3.132096290588379
Validation loss: 2.465342983122795

Epoch: 6| Step: 5
Training loss: 3.006500244140625
Validation loss: 2.4606258125715357

Epoch: 6| Step: 6
Training loss: 2.3890600204467773
Validation loss: 2.4656594004682315

Epoch: 6| Step: 7
Training loss: 2.743161678314209
Validation loss: 2.465603243920111

Epoch: 6| Step: 8
Training loss: 2.1165409088134766
Validation loss: 2.476625821923697

Epoch: 6| Step: 9
Training loss: 2.230577230453491
Validation loss: 2.4883464510722826

Epoch: 6| Step: 10
Training loss: 2.58611798286438
Validation loss: 2.5036714948633665

Epoch: 6| Step: 11
Training loss: 2.5189504623413086
Validation loss: 2.5331166482740834

Epoch: 6| Step: 12
Training loss: 2.5811867713928223
Validation loss: 2.5456744291449107

Epoch: 6| Step: 13
Training loss: 2.0519747734069824
Validation loss: 2.5166713909436296

Epoch: 69| Step: 0
Training loss: 2.281783103942871
Validation loss: 2.5301745168624388

Epoch: 6| Step: 1
Training loss: 1.9636766910552979
Validation loss: 2.5171105400208504

Epoch: 6| Step: 2
Training loss: 3.0251195430755615
Validation loss: 2.5166233201180734

Epoch: 6| Step: 3
Training loss: 1.5021226406097412
Validation loss: 2.4953740771098802

Epoch: 6| Step: 4
Training loss: 2.201192855834961
Validation loss: 2.470193442477975

Epoch: 6| Step: 5
Training loss: 3.432769775390625
Validation loss: 2.4663652425171225

Epoch: 6| Step: 6
Training loss: 2.35642147064209
Validation loss: 2.460295533621183

Epoch: 6| Step: 7
Training loss: 2.5469095706939697
Validation loss: 2.4584469897772676

Epoch: 6| Step: 8
Training loss: 3.508166790008545
Validation loss: 2.448681694205089

Epoch: 6| Step: 9
Training loss: 3.5536415576934814
Validation loss: 2.451852321624756

Epoch: 6| Step: 10
Training loss: 2.2034525871276855
Validation loss: 2.4509871441830873

Epoch: 6| Step: 11
Training loss: 2.979841947555542
Validation loss: 2.481046474108132

Epoch: 6| Step: 12
Training loss: 2.9650588035583496
Validation loss: 2.4686505153614986

Epoch: 6| Step: 13
Training loss: 3.238617420196533
Validation loss: 2.4656941659988894

Epoch: 70| Step: 0
Training loss: 1.9824817180633545
Validation loss: 2.4745668083108883

Epoch: 6| Step: 1
Training loss: 2.095974922180176
Validation loss: 2.4854552412545807

Epoch: 6| Step: 2
Training loss: 3.1013972759246826
Validation loss: 2.4866322471249487

Epoch: 6| Step: 3
Training loss: 3.209188938140869
Validation loss: 2.474209749570457

Epoch: 6| Step: 4
Training loss: 2.432682752609253
Validation loss: 2.461749827989968

Epoch: 6| Step: 5
Training loss: 2.93681001663208
Validation loss: 2.460178772608439

Epoch: 6| Step: 6
Training loss: 2.7237110137939453
Validation loss: 2.458091248748123

Epoch: 6| Step: 7
Training loss: 3.031059503555298
Validation loss: 2.4548875824097665

Epoch: 6| Step: 8
Training loss: 3.4625349044799805
Validation loss: 2.4502788000209357

Epoch: 6| Step: 9
Training loss: 2.720888614654541
Validation loss: 2.4463158884356098

Epoch: 6| Step: 10
Training loss: 1.9004817008972168
Validation loss: 2.454804648635208

Epoch: 6| Step: 11
Training loss: 2.3435349464416504
Validation loss: 2.4459753933773247

Epoch: 6| Step: 12
Training loss: 2.9715514183044434
Validation loss: 2.454558208424558

Epoch: 6| Step: 13
Training loss: 2.3433191776275635
Validation loss: 2.4525421998834096

Epoch: 71| Step: 0
Training loss: 3.283964157104492
Validation loss: 2.4532550227257515

Epoch: 6| Step: 1
Training loss: 2.2562360763549805
Validation loss: 2.4560194553867465

Epoch: 6| Step: 2
Training loss: 2.475362539291382
Validation loss: 2.4625523885091147

Epoch: 6| Step: 3
Training loss: 2.764346122741699
Validation loss: 2.4761506049863753

Epoch: 6| Step: 4
Training loss: 3.3760151863098145
Validation loss: 2.4779282410939536

Epoch: 6| Step: 5
Training loss: 3.4021553993225098
Validation loss: 2.484971971922023

Epoch: 6| Step: 6
Training loss: 2.744107961654663
Validation loss: 2.4801908334096274

Epoch: 6| Step: 7
Training loss: 2.78786563873291
Validation loss: 2.4773052738558863

Epoch: 6| Step: 8
Training loss: 2.338491916656494
Validation loss: 2.4679012375493206

Epoch: 6| Step: 9
Training loss: 1.7544989585876465
Validation loss: 2.4549614460237565

Epoch: 6| Step: 10
Training loss: 3.1077404022216797
Validation loss: 2.4552420621277182

Epoch: 6| Step: 11
Training loss: 2.046985149383545
Validation loss: 2.4489534798488823

Epoch: 6| Step: 12
Training loss: 2.378037452697754
Validation loss: 2.446699978202902

Epoch: 6| Step: 13
Training loss: 2.603011131286621
Validation loss: 2.433030266915598

Epoch: 72| Step: 0
Training loss: 2.5352771282196045
Validation loss: 2.426880000739969

Epoch: 6| Step: 1
Training loss: 2.931246757507324
Validation loss: 2.4212711293210267

Epoch: 6| Step: 2
Training loss: 2.4310693740844727
Validation loss: 2.4210931947154384

Epoch: 6| Step: 3
Training loss: 3.426931619644165
Validation loss: 2.4221448847042617

Epoch: 6| Step: 4
Training loss: 3.0926425457000732
Validation loss: 2.4323584571961434

Epoch: 6| Step: 5
Training loss: 3.0358409881591797
Validation loss: 2.437226023725284

Epoch: 6| Step: 6
Training loss: 2.546933174133301
Validation loss: 2.437700548479634

Epoch: 6| Step: 7
Training loss: 1.891701102256775
Validation loss: 2.4420452989557737

Epoch: 6| Step: 8
Training loss: 2.3876125812530518
Validation loss: 2.429525820157861

Epoch: 6| Step: 9
Training loss: 1.9076409339904785
Validation loss: 2.440656054404474

Epoch: 6| Step: 10
Training loss: 2.328795909881592
Validation loss: 2.4364711264128327

Epoch: 6| Step: 11
Training loss: 2.5720577239990234
Validation loss: 2.4216358277105514

Epoch: 6| Step: 12
Training loss: 3.568429946899414
Validation loss: 2.416567023082446

Epoch: 6| Step: 13
Training loss: 2.3837475776672363
Validation loss: 2.4188462226621565

Epoch: 73| Step: 0
Training loss: 2.6190600395202637
Validation loss: 2.42652218316191

Epoch: 6| Step: 1
Training loss: 1.996390700340271
Validation loss: 2.4266334528564126

Epoch: 6| Step: 2
Training loss: 3.3158721923828125
Validation loss: 2.4324258758175756

Epoch: 6| Step: 3
Training loss: 1.8971832990646362
Validation loss: 2.429837149958457

Epoch: 6| Step: 4
Training loss: 3.1972217559814453
Validation loss: 2.424904877139676

Epoch: 6| Step: 5
Training loss: 3.126838207244873
Validation loss: 2.4249869597855436

Epoch: 6| Step: 6
Training loss: 3.1949596405029297
Validation loss: 2.423503739859468

Epoch: 6| Step: 7
Training loss: 2.637208938598633
Validation loss: 2.4205433450719362

Epoch: 6| Step: 8
Training loss: 2.4204561710357666
Validation loss: 2.4180330050888883

Epoch: 6| Step: 9
Training loss: 1.9338855743408203
Validation loss: 2.4162898294387327

Epoch: 6| Step: 10
Training loss: 2.6192145347595215
Validation loss: 2.41881884554381

Epoch: 6| Step: 11
Training loss: 2.5055155754089355
Validation loss: 2.4203095807824084

Epoch: 6| Step: 12
Training loss: 2.891974925994873
Validation loss: 2.435873821217527

Epoch: 6| Step: 13
Training loss: 3.050994634628296
Validation loss: 2.4313067287527104

Epoch: 74| Step: 0
Training loss: 2.207888603210449
Validation loss: 2.430569279578424

Epoch: 6| Step: 1
Training loss: 2.2987585067749023
Validation loss: 2.4296833263930453

Epoch: 6| Step: 2
Training loss: 2.7234272956848145
Validation loss: 2.4352944922703568

Epoch: 6| Step: 3
Training loss: 3.0566534996032715
Validation loss: 2.4389117084523684

Epoch: 6| Step: 4
Training loss: 2.9244604110717773
Validation loss: 2.4507447314518753

Epoch: 6| Step: 5
Training loss: 2.7153267860412598
Validation loss: 2.444153606250722

Epoch: 6| Step: 6
Training loss: 2.6597957611083984
Validation loss: 2.4485355987343738

Epoch: 6| Step: 7
Training loss: 2.2440273761749268
Validation loss: 2.453706115804693

Epoch: 6| Step: 8
Training loss: 2.1903436183929443
Validation loss: 2.459646640285369

Epoch: 6| Step: 9
Training loss: 3.2499403953552246
Validation loss: 2.4526629524846233

Epoch: 6| Step: 10
Training loss: 2.566333770751953
Validation loss: 2.4514029308031966

Epoch: 6| Step: 11
Training loss: 2.6885170936584473
Validation loss: 2.439246227664332

Epoch: 6| Step: 12
Training loss: 2.5969576835632324
Validation loss: 2.4347401229284142

Epoch: 6| Step: 13
Training loss: 3.288031578063965
Validation loss: 2.4235551895633822

Epoch: 75| Step: 0
Training loss: 2.468871831893921
Validation loss: 2.415093755209318

Epoch: 6| Step: 1
Training loss: 3.047952175140381
Validation loss: 2.409787006275628

Epoch: 6| Step: 2
Training loss: 3.2325117588043213
Validation loss: 2.4105148776885

Epoch: 6| Step: 3
Training loss: 2.519454002380371
Validation loss: 2.413160765042869

Epoch: 6| Step: 4
Training loss: 2.8458008766174316
Validation loss: 2.424987219995068

Epoch: 6| Step: 5
Training loss: 2.5283868312835693
Validation loss: 2.4382960450264717

Epoch: 6| Step: 6
Training loss: 2.91715931892395
Validation loss: 2.461737081568728

Epoch: 6| Step: 7
Training loss: 1.6880042552947998
Validation loss: 2.4298295051820817

Epoch: 6| Step: 8
Training loss: 3.1274023056030273
Validation loss: 2.4082746031463786

Epoch: 6| Step: 9
Training loss: 2.9528489112854004
Validation loss: 2.4036674191874843

Epoch: 6| Step: 10
Training loss: 3.0102667808532715
Validation loss: 2.4126490854447886

Epoch: 6| Step: 11
Training loss: 2.4673571586608887
Validation loss: 2.4152550569144626

Epoch: 6| Step: 12
Training loss: 1.8016324043273926
Validation loss: 2.4571364669389624

Epoch: 6| Step: 13
Training loss: 2.440911293029785
Validation loss: 2.5038253133014967

Epoch: 76| Step: 0
Training loss: 2.649235725402832
Validation loss: 2.52824394933639

Epoch: 6| Step: 1
Training loss: 1.9792159795761108
Validation loss: 2.5159650002756426

Epoch: 6| Step: 2
Training loss: 2.566237211227417
Validation loss: 2.4834775719591367

Epoch: 6| Step: 3
Training loss: 2.014864444732666
Validation loss: 2.4357628950508694

Epoch: 6| Step: 4
Training loss: 2.7132885456085205
Validation loss: 2.4079679622445056

Epoch: 6| Step: 5
Training loss: 2.5792250633239746
Validation loss: 2.3917554963019585

Epoch: 6| Step: 6
Training loss: 3.193965435028076
Validation loss: 2.395877586897983

Epoch: 6| Step: 7
Training loss: 3.799013137817383
Validation loss: 2.4274532205315045

Epoch: 6| Step: 8
Training loss: 2.7080469131469727
Validation loss: 2.4325036002743627

Epoch: 6| Step: 9
Training loss: 2.6938633918762207
Validation loss: 2.4429530020683043

Epoch: 6| Step: 10
Training loss: 2.8044729232788086
Validation loss: 2.4535270608881468

Epoch: 6| Step: 11
Training loss: 2.6787362098693848
Validation loss: 2.4745790830222507

Epoch: 6| Step: 12
Training loss: 2.564548969268799
Validation loss: 2.5003523442053024

Epoch: 6| Step: 13
Training loss: 2.3248162269592285
Validation loss: 2.487978159740407

Epoch: 77| Step: 0
Training loss: 2.3948779106140137
Validation loss: 2.5105461074459936

Epoch: 6| Step: 1
Training loss: 2.273808002471924
Validation loss: 2.4858787982694563

Epoch: 6| Step: 2
Training loss: 2.1820147037506104
Validation loss: 2.450974549016645

Epoch: 6| Step: 3
Training loss: 2.9697351455688477
Validation loss: 2.4748341063017487

Epoch: 6| Step: 4
Training loss: 2.5871388912200928
Validation loss: 2.4413899298637145

Epoch: 6| Step: 5
Training loss: 2.2414968013763428
Validation loss: 2.4491748502177577

Epoch: 6| Step: 6
Training loss: 2.8879408836364746
Validation loss: 2.4552003593855005

Epoch: 6| Step: 7
Training loss: 2.439091205596924
Validation loss: 2.4493294018571095

Epoch: 6| Step: 8
Training loss: 2.3919572830200195
Validation loss: 2.4421062315663984

Epoch: 6| Step: 9
Training loss: 3.3963606357574463
Validation loss: 2.430460819634058

Epoch: 6| Step: 10
Training loss: 2.447122573852539
Validation loss: 2.4086729608556277

Epoch: 6| Step: 11
Training loss: 3.0504164695739746
Validation loss: 2.3984136607057307

Epoch: 6| Step: 12
Training loss: 2.8719005584716797
Validation loss: 2.392631612798219

Epoch: 6| Step: 13
Training loss: 3.2995169162750244
Validation loss: 2.3833387769678587

Epoch: 78| Step: 0
Training loss: 2.4342565536499023
Validation loss: 2.380957052271853

Epoch: 6| Step: 1
Training loss: 2.9890758991241455
Validation loss: 2.3783342658832507

Epoch: 6| Step: 2
Training loss: 2.6546666622161865
Validation loss: 2.3764003117879233

Epoch: 6| Step: 3
Training loss: 2.8897500038146973
Validation loss: 2.3831512005098405

Epoch: 6| Step: 4
Training loss: 2.7301692962646484
Validation loss: 2.3841549324732956

Epoch: 6| Step: 5
Training loss: 2.3225700855255127
Validation loss: 2.3816731745196926

Epoch: 6| Step: 6
Training loss: 3.3642587661743164
Validation loss: 2.39567300837527

Epoch: 6| Step: 7
Training loss: 2.5776429176330566
Validation loss: 2.3797244384724605

Epoch: 6| Step: 8
Training loss: 2.2184624671936035
Validation loss: 2.3747365141427643

Epoch: 6| Step: 9
Training loss: 2.276759147644043
Validation loss: 2.370477807137274

Epoch: 6| Step: 10
Training loss: 2.8621997833251953
Validation loss: 2.3684452887504333

Epoch: 6| Step: 11
Training loss: 2.614192485809326
Validation loss: 2.369580143241472

Epoch: 6| Step: 12
Training loss: 2.617647409439087
Validation loss: 2.373862231931379

Epoch: 6| Step: 13
Training loss: 2.2790472507476807
Validation loss: 2.3730653460307787

Epoch: 79| Step: 0
Training loss: 2.0552315711975098
Validation loss: 2.375617052919121

Epoch: 6| Step: 1
Training loss: 2.6901731491088867
Validation loss: 2.395414339598789

Epoch: 6| Step: 2
Training loss: 2.660541534423828
Validation loss: 2.412642640452231

Epoch: 6| Step: 3
Training loss: 2.976280450820923
Validation loss: 2.4323170851635676

Epoch: 6| Step: 4
Training loss: 2.0287389755249023
Validation loss: 2.451279483815675

Epoch: 6| Step: 5
Training loss: 3.364231586456299
Validation loss: 2.485666867225401

Epoch: 6| Step: 6
Training loss: 2.820033073425293
Validation loss: 2.4623986469802035

Epoch: 6| Step: 7
Training loss: 2.253932476043701
Validation loss: 2.442709720262917

Epoch: 6| Step: 8
Training loss: 2.80891752243042
Validation loss: 2.4412582792261595

Epoch: 6| Step: 9
Training loss: 2.9774680137634277
Validation loss: 2.416803139512257

Epoch: 6| Step: 10
Training loss: 2.501826524734497
Validation loss: 2.3923268446358303

Epoch: 6| Step: 11
Training loss: 2.9454798698425293
Validation loss: 2.3773960221198296

Epoch: 6| Step: 12
Training loss: 2.335376501083374
Validation loss: 2.3792224853269515

Epoch: 6| Step: 13
Training loss: 2.6489932537078857
Validation loss: 2.384798331927228

Epoch: 80| Step: 0
Training loss: 2.468510627746582
Validation loss: 2.392221978915635

Epoch: 6| Step: 1
Training loss: 2.438826560974121
Validation loss: 2.3969427590729087

Epoch: 6| Step: 2
Training loss: 3.1128463745117188
Validation loss: 2.3844836296573764

Epoch: 6| Step: 3
Training loss: 2.4659502506256104
Validation loss: 2.3975890298043527

Epoch: 6| Step: 4
Training loss: 2.9176077842712402
Validation loss: 2.3836819535942486

Epoch: 6| Step: 5
Training loss: 2.414414405822754
Validation loss: 2.3956386222634265

Epoch: 6| Step: 6
Training loss: 1.9992138147354126
Validation loss: 2.3742308693547405

Epoch: 6| Step: 7
Training loss: 3.0384364128112793
Validation loss: 2.386005373411281

Epoch: 6| Step: 8
Training loss: 2.939365863800049
Validation loss: 2.379050072803292

Epoch: 6| Step: 9
Training loss: 2.1281144618988037
Validation loss: 2.3893972340450493

Epoch: 6| Step: 10
Training loss: 2.546504259109497
Validation loss: 2.398532800776984

Epoch: 6| Step: 11
Training loss: 2.941622734069824
Validation loss: 2.4022815073690107

Epoch: 6| Step: 12
Training loss: 3.3012518882751465
Validation loss: 2.3987654050191245

Epoch: 6| Step: 13
Training loss: 1.7507266998291016
Validation loss: 2.392748955757387

Epoch: 81| Step: 0
Training loss: 3.088158130645752
Validation loss: 2.3895814059883036

Epoch: 6| Step: 1
Training loss: 2.072981357574463
Validation loss: 2.3853236731662544

Epoch: 6| Step: 2
Training loss: 2.607757568359375
Validation loss: 2.395563446065431

Epoch: 6| Step: 3
Training loss: 3.709615468978882
Validation loss: 2.415541797555903

Epoch: 6| Step: 4
Training loss: 2.6950438022613525
Validation loss: 2.4258945834252144

Epoch: 6| Step: 5
Training loss: 2.5989370346069336
Validation loss: 2.4420921212883404

Epoch: 6| Step: 6
Training loss: 2.720529317855835
Validation loss: 2.4512680243420344

Epoch: 6| Step: 7
Training loss: 2.6893105506896973
Validation loss: 2.4793699736236245

Epoch: 6| Step: 8
Training loss: 2.303591251373291
Validation loss: 2.440115349267119

Epoch: 6| Step: 9
Training loss: 2.688394784927368
Validation loss: 2.41203833395435

Epoch: 6| Step: 10
Training loss: 1.9989197254180908
Validation loss: 2.3813844368021977

Epoch: 6| Step: 11
Training loss: 2.9787304401397705
Validation loss: 2.367826651501399

Epoch: 6| Step: 12
Training loss: 1.9662160873413086
Validation loss: 2.3710246855212795

Epoch: 6| Step: 13
Training loss: 2.4636056423187256
Validation loss: 2.3750015253661783

Epoch: 82| Step: 0
Training loss: 2.904191493988037
Validation loss: 2.3967032035191855

Epoch: 6| Step: 1
Training loss: 2.016091823577881
Validation loss: 2.4086346728827364

Epoch: 6| Step: 2
Training loss: 2.984341621398926
Validation loss: 2.4314918543702815

Epoch: 6| Step: 3
Training loss: 2.872182846069336
Validation loss: 2.4696677320746967

Epoch: 6| Step: 4
Training loss: 2.551273822784424
Validation loss: 2.5030103293798303

Epoch: 6| Step: 5
Training loss: 2.3271992206573486
Validation loss: 2.4763649099616596

Epoch: 6| Step: 6
Training loss: 3.1460089683532715
Validation loss: 2.426174630400955

Epoch: 6| Step: 7
Training loss: 2.657221794128418
Validation loss: 2.3936089905359412

Epoch: 6| Step: 8
Training loss: 2.1353237628936768
Validation loss: 2.3838015371753323

Epoch: 6| Step: 9
Training loss: 2.0650765895843506
Validation loss: 2.3772296777335544

Epoch: 6| Step: 10
Training loss: 3.5440993309020996
Validation loss: 2.367435973177674

Epoch: 6| Step: 11
Training loss: 1.8615670204162598
Validation loss: 2.3745766275672504

Epoch: 6| Step: 12
Training loss: 2.8588528633117676
Validation loss: 2.3820167664558656

Epoch: 6| Step: 13
Training loss: 3.4053454399108887
Validation loss: 2.387921271785613

Epoch: 83| Step: 0
Training loss: 2.7343709468841553
Validation loss: 2.3839771824498333

Epoch: 6| Step: 1
Training loss: 2.8057491779327393
Validation loss: 2.3817229655481156

Epoch: 6| Step: 2
Training loss: 2.8602426052093506
Validation loss: 2.3732684837874545

Epoch: 6| Step: 3
Training loss: 1.8034288883209229
Validation loss: 2.3742853005727134

Epoch: 6| Step: 4
Training loss: 2.242713689804077
Validation loss: 2.364112123366325

Epoch: 6| Step: 5
Training loss: 3.314744234085083
Validation loss: 2.358034595366447

Epoch: 6| Step: 6
Training loss: 2.502596378326416
Validation loss: 2.3641517521232687

Epoch: 6| Step: 7
Training loss: 2.846513271331787
Validation loss: 2.36131013337002

Epoch: 6| Step: 8
Training loss: 2.1330032348632812
Validation loss: 2.360333340142363

Epoch: 6| Step: 9
Training loss: 2.6614012718200684
Validation loss: 2.366558685097643

Epoch: 6| Step: 10
Training loss: 2.2943286895751953
Validation loss: 2.3670858106305523

Epoch: 6| Step: 11
Training loss: 2.8954391479492188
Validation loss: 2.3598385549360708

Epoch: 6| Step: 12
Training loss: 2.8374505043029785
Validation loss: 2.3721004480956704

Epoch: 6| Step: 13
Training loss: 2.707317352294922
Validation loss: 2.370434122700845

Epoch: 84| Step: 0
Training loss: 2.3166589736938477
Validation loss: 2.3699064024033083

Epoch: 6| Step: 1
Training loss: 2.6104226112365723
Validation loss: 2.3743760547330304

Epoch: 6| Step: 2
Training loss: 2.220515727996826
Validation loss: 2.386995597552228

Epoch: 6| Step: 3
Training loss: 3.0671257972717285
Validation loss: 2.3880605671995427

Epoch: 6| Step: 4
Training loss: 2.5512640476226807
Validation loss: 2.3832060034557054

Epoch: 6| Step: 5
Training loss: 2.7469735145568848
Validation loss: 2.388518205253027

Epoch: 6| Step: 6
Training loss: 1.8040997982025146
Validation loss: 2.393659645511258

Epoch: 6| Step: 7
Training loss: 2.365551471710205
Validation loss: 2.389391453035416

Epoch: 6| Step: 8
Training loss: 2.4197025299072266
Validation loss: 2.3938687283505677

Epoch: 6| Step: 9
Training loss: 1.8136932849884033
Validation loss: 2.401603211638748

Epoch: 6| Step: 10
Training loss: 3.5434508323669434
Validation loss: 2.3954067768589145

Epoch: 6| Step: 11
Training loss: 3.5474305152893066
Validation loss: 2.391865073993642

Epoch: 6| Step: 12
Training loss: 3.0907797813415527
Validation loss: 2.39539090535974

Epoch: 6| Step: 13
Training loss: 2.345733404159546
Validation loss: 2.386333591194563

Epoch: 85| Step: 0
Training loss: 2.431507110595703
Validation loss: 2.3707545085619857

Epoch: 6| Step: 1
Training loss: 2.438361883163452
Validation loss: 2.3671201121422554

Epoch: 6| Step: 2
Training loss: 2.877675771713257
Validation loss: 2.3714423461626937

Epoch: 6| Step: 3
Training loss: 2.908259391784668
Validation loss: 2.3812353098264305

Epoch: 6| Step: 4
Training loss: 2.6885762214660645
Validation loss: 2.3930931950128205

Epoch: 6| Step: 5
Training loss: 3.12552547454834
Validation loss: 2.4054651209103164

Epoch: 6| Step: 6
Training loss: 2.572317361831665
Validation loss: 2.400550834594234

Epoch: 6| Step: 7
Training loss: 2.199993371963501
Validation loss: 2.3873861118029525

Epoch: 6| Step: 8
Training loss: 2.38449764251709
Validation loss: 2.3662029158684517

Epoch: 6| Step: 9
Training loss: 2.9614734649658203
Validation loss: 2.3573716660981536

Epoch: 6| Step: 10
Training loss: 2.233212471008301
Validation loss: 2.354839822297455

Epoch: 6| Step: 11
Training loss: 2.5324137210845947
Validation loss: 2.3509976222950923

Epoch: 6| Step: 12
Training loss: 2.188692808151245
Validation loss: 2.3749270567329983

Epoch: 6| Step: 13
Training loss: 3.1494784355163574
Validation loss: 2.3870914213119017

Epoch: 86| Step: 0
Training loss: 2.7943735122680664
Validation loss: 2.3980922878429456

Epoch: 6| Step: 1
Training loss: 2.444237232208252
Validation loss: 2.399738896277643

Epoch: 6| Step: 2
Training loss: 3.149242401123047
Validation loss: 2.4243376537035872

Epoch: 6| Step: 3
Training loss: 2.7233529090881348
Validation loss: 2.429811280260804

Epoch: 6| Step: 4
Training loss: 2.4640450477600098
Validation loss: 2.4196968616977816

Epoch: 6| Step: 5
Training loss: 2.2468795776367188
Validation loss: 2.438758634751843

Epoch: 6| Step: 6
Training loss: 2.885861873626709
Validation loss: 2.4261080987991823

Epoch: 6| Step: 7
Training loss: 2.2394487857818604
Validation loss: 2.4064973374848724

Epoch: 6| Step: 8
Training loss: 2.5192606449127197
Validation loss: 2.395481817183956

Epoch: 6| Step: 9
Training loss: 2.9449217319488525
Validation loss: 2.3837629697656118

Epoch: 6| Step: 10
Training loss: 2.698519229888916
Validation loss: 2.3607976308432956

Epoch: 6| Step: 11
Training loss: 2.9324374198913574
Validation loss: 2.3555293877919516

Epoch: 6| Step: 12
Training loss: 2.1053359508514404
Validation loss: 2.3456431576000747

Epoch: 6| Step: 13
Training loss: 2.1140780448913574
Validation loss: 2.353101671382945

Epoch: 87| Step: 0
Training loss: 2.6627197265625
Validation loss: 2.3520122728040143

Epoch: 6| Step: 1
Training loss: 2.4458506107330322
Validation loss: 2.3458025891293763

Epoch: 6| Step: 2
Training loss: 2.0419273376464844
Validation loss: 2.346271368765062

Epoch: 6| Step: 3
Training loss: 3.1856677532196045
Validation loss: 2.342372094431231

Epoch: 6| Step: 4
Training loss: 2.717686176300049
Validation loss: 2.3584518381344375

Epoch: 6| Step: 5
Training loss: 2.849066972732544
Validation loss: 2.3569717535408596

Epoch: 6| Step: 6
Training loss: 2.877796173095703
Validation loss: 2.380574971116999

Epoch: 6| Step: 7
Training loss: 2.5061182975769043
Validation loss: 2.3832953206954466

Epoch: 6| Step: 8
Training loss: 2.535769462585449
Validation loss: 2.3806816326674594

Epoch: 6| Step: 9
Training loss: 2.455873966217041
Validation loss: 2.4041366320784374

Epoch: 6| Step: 10
Training loss: 2.3274717330932617
Validation loss: 2.399376553873862

Epoch: 6| Step: 11
Training loss: 2.973639488220215
Validation loss: 2.395737845410583

Epoch: 6| Step: 12
Training loss: 2.734619379043579
Validation loss: 2.367824089142584

Epoch: 6| Step: 13
Training loss: 1.8781496286392212
Validation loss: 2.3680728148388606

Epoch: 88| Step: 0
Training loss: 2.0274293422698975
Validation loss: 2.381097657706148

Epoch: 6| Step: 1
Training loss: 2.2854790687561035
Validation loss: 2.382629794459189

Epoch: 6| Step: 2
Training loss: 2.3804938793182373
Validation loss: 2.3959678578120407

Epoch: 6| Step: 3
Training loss: 2.6045608520507812
Validation loss: 2.4243409249090377

Epoch: 6| Step: 4
Training loss: 2.538161277770996
Validation loss: 2.4427553761389946

Epoch: 6| Step: 5
Training loss: 2.7670187950134277
Validation loss: 2.4061313367659047

Epoch: 6| Step: 6
Training loss: 1.9537956714630127
Validation loss: 2.3644602273100164

Epoch: 6| Step: 7
Training loss: 2.8406267166137695
Validation loss: 2.3524156385852444

Epoch: 6| Step: 8
Training loss: 3.0281314849853516
Validation loss: 2.3474780000666136

Epoch: 6| Step: 9
Training loss: 2.7586307525634766
Validation loss: 2.3556119318931334

Epoch: 6| Step: 10
Training loss: 2.6253538131713867
Validation loss: 2.3656038955975602

Epoch: 6| Step: 11
Training loss: 3.532536506652832
Validation loss: 2.3789849050583376

Epoch: 6| Step: 12
Training loss: 2.3621253967285156
Validation loss: 2.3677844847402265

Epoch: 6| Step: 13
Training loss: 3.037524700164795
Validation loss: 2.3577224695554344

Epoch: 89| Step: 0
Training loss: 2.3385097980499268
Validation loss: 2.3444375299638316

Epoch: 6| Step: 1
Training loss: 2.4573378562927246
Validation loss: 2.3370684885209605

Epoch: 6| Step: 2
Training loss: 3.5521955490112305
Validation loss: 2.328702842035601

Epoch: 6| Step: 3
Training loss: 2.202986001968384
Validation loss: 2.332266548628448

Epoch: 6| Step: 4
Training loss: 2.6057193279266357
Validation loss: 2.3300764355608212

Epoch: 6| Step: 5
Training loss: 2.632847309112549
Validation loss: 2.3281188088078655

Epoch: 6| Step: 6
Training loss: 2.2838125228881836
Validation loss: 2.331458632664014

Epoch: 6| Step: 7
Training loss: 2.837484359741211
Validation loss: 2.330854815821494

Epoch: 6| Step: 8
Training loss: 2.706804037094116
Validation loss: 2.3361421182591426

Epoch: 6| Step: 9
Training loss: 2.536923408508301
Validation loss: 2.3302675267701507

Epoch: 6| Step: 10
Training loss: 2.4336998462677
Validation loss: 2.3417534828186035

Epoch: 6| Step: 11
Training loss: 2.9867701530456543
Validation loss: 2.3512350589998308

Epoch: 6| Step: 12
Training loss: 2.5900673866271973
Validation loss: 2.3741704520358833

Epoch: 6| Step: 13
Training loss: 2.0249319076538086
Validation loss: 2.386905436874718

Epoch: 90| Step: 0
Training loss: 2.9971749782562256
Validation loss: 2.3864379570048344

Epoch: 6| Step: 1
Training loss: 3.3688018321990967
Validation loss: 2.388966214272284

Epoch: 6| Step: 2
Training loss: 2.6945888996124268
Validation loss: 2.3773620948996594

Epoch: 6| Step: 3
Training loss: 2.4315409660339355
Validation loss: 2.369940527023808

Epoch: 6| Step: 4
Training loss: 2.210853338241577
Validation loss: 2.365836433185044

Epoch: 6| Step: 5
Training loss: 2.3072662353515625
Validation loss: 2.3684860942184285

Epoch: 6| Step: 6
Training loss: 1.9747155904769897
Validation loss: 2.3747183251124557

Epoch: 6| Step: 7
Training loss: 2.794123649597168
Validation loss: 2.373016116439655

Epoch: 6| Step: 8
Training loss: 2.837862014770508
Validation loss: 2.3730620620071248

Epoch: 6| Step: 9
Training loss: 2.335251808166504
Validation loss: 2.374299651832991

Epoch: 6| Step: 10
Training loss: 3.0283212661743164
Validation loss: 2.3887746359712336

Epoch: 6| Step: 11
Training loss: 2.4234580993652344
Validation loss: 2.4087832922576577

Epoch: 6| Step: 12
Training loss: 2.6005728244781494
Validation loss: 2.411559827866093

Epoch: 6| Step: 13
Training loss: 2.2414751052856445
Validation loss: 2.3940914856490267

Epoch: 91| Step: 0
Training loss: 2.5242059230804443
Validation loss: 2.3831906780119865

Epoch: 6| Step: 1
Training loss: 2.079827308654785
Validation loss: 2.3844590481891426

Epoch: 6| Step: 2
Training loss: 2.7273974418640137
Validation loss: 2.3808188438415527

Epoch: 6| Step: 3
Training loss: 3.7546768188476562
Validation loss: 2.395777751040715

Epoch: 6| Step: 4
Training loss: 2.760138750076294
Validation loss: 2.399123014942292

Epoch: 6| Step: 5
Training loss: 1.7935552597045898
Validation loss: 2.410754765233686

Epoch: 6| Step: 6
Training loss: 3.1772284507751465
Validation loss: 2.4195551167252245

Epoch: 6| Step: 7
Training loss: 2.939488410949707
Validation loss: 2.4295977046412807

Epoch: 6| Step: 8
Training loss: 1.8777482509613037
Validation loss: 2.45412847047211

Epoch: 6| Step: 9
Training loss: 2.502326726913452
Validation loss: 2.4584925661804857

Epoch: 6| Step: 10
Training loss: 2.6863808631896973
Validation loss: 2.4368123828723864

Epoch: 6| Step: 11
Training loss: 2.272225856781006
Validation loss: 2.442336449059107

Epoch: 6| Step: 12
Training loss: 2.4331068992614746
Validation loss: 2.4171220871710006

Epoch: 6| Step: 13
Training loss: 2.881089210510254
Validation loss: 2.4123584839605514

Epoch: 92| Step: 0
Training loss: 2.540106773376465
Validation loss: 2.405868166236467

Epoch: 6| Step: 1
Training loss: 2.3606467247009277
Validation loss: 2.3866718917764644

Epoch: 6| Step: 2
Training loss: 3.050105571746826
Validation loss: 2.376362023815032

Epoch: 6| Step: 3
Training loss: 2.374105215072632
Validation loss: 2.3546627426660187

Epoch: 6| Step: 4
Training loss: 2.9018986225128174
Validation loss: 2.3478004522221063

Epoch: 6| Step: 5
Training loss: 2.0666463375091553
Validation loss: 2.343604726176108

Epoch: 6| Step: 6
Training loss: 2.738657236099243
Validation loss: 2.3343670175921534

Epoch: 6| Step: 7
Training loss: 2.554309844970703
Validation loss: 2.335825571449854

Epoch: 6| Step: 8
Training loss: 2.6723272800445557
Validation loss: 2.329512688421434

Epoch: 6| Step: 9
Training loss: 2.4565236568450928
Validation loss: 2.3303144003755305

Epoch: 6| Step: 10
Training loss: 2.804990768432617
Validation loss: 2.3312584661668345

Epoch: 6| Step: 11
Training loss: 2.9624578952789307
Validation loss: 2.3264449552823137

Epoch: 6| Step: 12
Training loss: 2.3790640830993652
Validation loss: 2.3406158211410686

Epoch: 6| Step: 13
Training loss: 2.058952808380127
Validation loss: 2.3363118863874868

Epoch: 93| Step: 0
Training loss: 2.3558759689331055
Validation loss: 2.345241613285516

Epoch: 6| Step: 1
Training loss: 3.038789749145508
Validation loss: 2.34755693199814

Epoch: 6| Step: 2
Training loss: 2.5506839752197266
Validation loss: 2.3413096935518327

Epoch: 6| Step: 3
Training loss: 2.563253402709961
Validation loss: 2.3520984982931488

Epoch: 6| Step: 4
Training loss: 3.018467426300049
Validation loss: 2.3498929418543333

Epoch: 6| Step: 5
Training loss: 2.404766321182251
Validation loss: 2.3545523612729964

Epoch: 6| Step: 6
Training loss: 2.1553122997283936
Validation loss: 2.352834545156007

Epoch: 6| Step: 7
Training loss: 2.581331491470337
Validation loss: 2.348379450459634

Epoch: 6| Step: 8
Training loss: 2.8116209506988525
Validation loss: 2.3594624252729517

Epoch: 6| Step: 9
Training loss: 2.6919732093811035
Validation loss: 2.352171532569393

Epoch: 6| Step: 10
Training loss: 2.4198381900787354
Validation loss: 2.35468497455761

Epoch: 6| Step: 11
Training loss: 2.3042726516723633
Validation loss: 2.36890999988843

Epoch: 6| Step: 12
Training loss: 2.832119941711426
Validation loss: 2.4086561741367465

Epoch: 6| Step: 13
Training loss: 2.283104419708252
Validation loss: 2.4291041820280013

Epoch: 94| Step: 0
Training loss: 3.7926535606384277
Validation loss: 2.3911694608708864

Epoch: 6| Step: 1
Training loss: 2.026296615600586
Validation loss: 2.3720766036741194

Epoch: 6| Step: 2
Training loss: 2.4779112339019775
Validation loss: 2.34914198998482

Epoch: 6| Step: 3
Training loss: 2.6425843238830566
Validation loss: 2.3248067594343618

Epoch: 6| Step: 4
Training loss: 3.050743341445923
Validation loss: 2.309262679469201

Epoch: 6| Step: 5
Training loss: 2.7138233184814453
Validation loss: 2.3097320730968187

Epoch: 6| Step: 6
Training loss: 3.1694276332855225
Validation loss: 2.314928129155149

Epoch: 6| Step: 7
Training loss: 1.3616607189178467
Validation loss: 2.3174093410532963

Epoch: 6| Step: 8
Training loss: 2.9285714626312256
Validation loss: 2.3362591522996143

Epoch: 6| Step: 9
Training loss: 2.4070065021514893
Validation loss: 2.3374780595943494

Epoch: 6| Step: 10
Training loss: 2.894395351409912
Validation loss: 2.3467529281493156

Epoch: 6| Step: 11
Training loss: 2.506178379058838
Validation loss: 2.345606232202181

Epoch: 6| Step: 12
Training loss: 2.2925548553466797
Validation loss: 2.3346450405736126

Epoch: 6| Step: 13
Training loss: 1.7295293807983398
Validation loss: 2.339052547690689

Epoch: 95| Step: 0
Training loss: 3.0286033153533936
Validation loss: 2.343970949931811

Epoch: 6| Step: 1
Training loss: 2.56781005859375
Validation loss: 2.336116261379693

Epoch: 6| Step: 2
Training loss: 2.5541365146636963
Validation loss: 2.3303090474938832

Epoch: 6| Step: 3
Training loss: 2.399543046951294
Validation loss: 2.334059223051994

Epoch: 6| Step: 4
Training loss: 2.2342615127563477
Validation loss: 2.3482941350629254

Epoch: 6| Step: 5
Training loss: 2.2521719932556152
Validation loss: 2.367353872586322

Epoch: 6| Step: 6
Training loss: 2.391284465789795
Validation loss: 2.3904799671583277

Epoch: 6| Step: 7
Training loss: 2.419100522994995
Validation loss: 2.429871313033565

Epoch: 6| Step: 8
Training loss: 2.3669910430908203
Validation loss: 2.4553723335266113

Epoch: 6| Step: 9
Training loss: 2.5565125942230225
Validation loss: 2.4912022621400896

Epoch: 6| Step: 10
Training loss: 2.956463575363159
Validation loss: 2.480324201686408

Epoch: 6| Step: 11
Training loss: 2.5102648735046387
Validation loss: 2.3916124887363885

Epoch: 6| Step: 12
Training loss: 3.3471155166625977
Validation loss: 2.3366349409985285

Epoch: 6| Step: 13
Training loss: 2.993476390838623
Validation loss: 2.3217923051567486

Epoch: 96| Step: 0
Training loss: 2.692927360534668
Validation loss: 2.3131009071103987

Epoch: 6| Step: 1
Training loss: 2.2084200382232666
Validation loss: 2.3125867715445896

Epoch: 6| Step: 2
Training loss: 3.3390073776245117
Validation loss: 2.316669128274405

Epoch: 6| Step: 3
Training loss: 2.49662709236145
Validation loss: 2.319687766413535

Epoch: 6| Step: 4
Training loss: 2.309583902359009
Validation loss: 2.345256269619029

Epoch: 6| Step: 5
Training loss: 2.5855960845947266
Validation loss: 2.3607882556094917

Epoch: 6| Step: 6
Training loss: 1.558532953262329
Validation loss: 2.3498529080421693

Epoch: 6| Step: 7
Training loss: 3.052379608154297
Validation loss: 2.3521026693364626

Epoch: 6| Step: 8
Training loss: 2.775425434112549
Validation loss: 2.340890489598756

Epoch: 6| Step: 9
Training loss: 2.568286895751953
Validation loss: 2.34704521138181

Epoch: 6| Step: 10
Training loss: 2.2500829696655273
Validation loss: 2.3261176052913872

Epoch: 6| Step: 11
Training loss: 2.428985595703125
Validation loss: 2.3172850890826155

Epoch: 6| Step: 12
Training loss: 3.4977540969848633
Validation loss: 2.309531227234871

Epoch: 6| Step: 13
Training loss: 2.465420961380005
Validation loss: 2.3082706774434736

Epoch: 97| Step: 0
Training loss: 2.62613844871521
Validation loss: 2.3004138879878546

Epoch: 6| Step: 1
Training loss: 2.843691349029541
Validation loss: 2.2981971899668374

Epoch: 6| Step: 2
Training loss: 2.8239641189575195
Validation loss: 2.31131850904034

Epoch: 6| Step: 3
Training loss: 2.237231731414795
Validation loss: 2.316297028654365

Epoch: 6| Step: 4
Training loss: 2.3765740394592285
Validation loss: 2.331199456286687

Epoch: 6| Step: 5
Training loss: 1.8949744701385498
Validation loss: 2.337455012465036

Epoch: 6| Step: 6
Training loss: 2.6732335090637207
Validation loss: 2.3397544455784622

Epoch: 6| Step: 7
Training loss: 3.20572566986084
Validation loss: 2.354022902827109

Epoch: 6| Step: 8
Training loss: 2.637993335723877
Validation loss: 2.3611726786500666

Epoch: 6| Step: 9
Training loss: 2.533827781677246
Validation loss: 2.410526596089845

Epoch: 6| Step: 10
Training loss: 2.655904531478882
Validation loss: 2.438771455518661

Epoch: 6| Step: 11
Training loss: 2.3662784099578857
Validation loss: 2.4491180296867125

Epoch: 6| Step: 12
Training loss: 2.7301084995269775
Validation loss: 2.42681876818339

Epoch: 6| Step: 13
Training loss: 2.413405418395996
Validation loss: 2.4164406945628505

Epoch: 98| Step: 0
Training loss: 2.4918906688690186
Validation loss: 2.4150379473163235

Epoch: 6| Step: 1
Training loss: 1.6821779012680054
Validation loss: 2.3905398153489634

Epoch: 6| Step: 2
Training loss: 2.3644402027130127
Validation loss: 2.394308420919603

Epoch: 6| Step: 3
Training loss: 2.829458713531494
Validation loss: 2.3886324820979947

Epoch: 6| Step: 4
Training loss: 2.349925994873047
Validation loss: 2.4115635579632175

Epoch: 6| Step: 5
Training loss: 2.402348041534424
Validation loss: 2.4214604593092397

Epoch: 6| Step: 6
Training loss: 2.2844648361206055
Validation loss: 2.4278301987596738

Epoch: 6| Step: 7
Training loss: 3.1337904930114746
Validation loss: 2.4800193873784875

Epoch: 6| Step: 8
Training loss: 2.8445191383361816
Validation loss: 2.5032905635013374

Epoch: 6| Step: 9
Training loss: 3.0472559928894043
Validation loss: 2.467128417825186

Epoch: 6| Step: 10
Training loss: 3.329249620437622
Validation loss: 2.4110316922587733

Epoch: 6| Step: 11
Training loss: 2.5323023796081543
Validation loss: 2.33632763226827

Epoch: 6| Step: 12
Training loss: 2.5098187923431396
Validation loss: 2.303681924778928

Epoch: 6| Step: 13
Training loss: 2.18792986869812
Validation loss: 2.2967358404590237

Epoch: 99| Step: 0
Training loss: 2.5447580814361572
Validation loss: 2.302501504139234

Epoch: 6| Step: 1
Training loss: 2.6417765617370605
Validation loss: 2.2976682852673274

Epoch: 6| Step: 2
Training loss: 2.928520679473877
Validation loss: 2.2979868740163822

Epoch: 6| Step: 3
Training loss: 2.108720541000366
Validation loss: 2.3002327052495812

Epoch: 6| Step: 4
Training loss: 2.8059134483337402
Validation loss: 2.304958374269547

Epoch: 6| Step: 5
Training loss: 2.2664244174957275
Validation loss: 2.3033673788911555

Epoch: 6| Step: 6
Training loss: 3.0502467155456543
Validation loss: 2.309178061382745

Epoch: 6| Step: 7
Training loss: 2.894456386566162
Validation loss: 2.310413251640976

Epoch: 6| Step: 8
Training loss: 3.0201563835144043
Validation loss: 2.3109178491818008

Epoch: 6| Step: 9
Training loss: 2.267702579498291
Validation loss: 2.3137484519712386

Epoch: 6| Step: 10
Training loss: 2.4126839637756348
Validation loss: 2.3175640003655547

Epoch: 6| Step: 11
Training loss: 2.2926011085510254
Validation loss: 2.3084611097971597

Epoch: 6| Step: 12
Training loss: 2.359499454498291
Validation loss: 2.305488674871383

Epoch: 6| Step: 13
Training loss: 2.745985507965088
Validation loss: 2.3044878154672603

Epoch: 100| Step: 0
Training loss: 2.1453752517700195
Validation loss: 2.30059600645496

Epoch: 6| Step: 1
Training loss: 2.901813507080078
Validation loss: 2.30450027988803

Epoch: 6| Step: 2
Training loss: 2.4170665740966797
Validation loss: 2.302813596622918

Epoch: 6| Step: 3
Training loss: 2.6602649688720703
Validation loss: 2.300267864299077

Epoch: 6| Step: 4
Training loss: 3.0954642295837402
Validation loss: 2.2979414283588366

Epoch: 6| Step: 5
Training loss: 2.83184814453125
Validation loss: 2.2946744682968303

Epoch: 6| Step: 6
Training loss: 2.8983001708984375
Validation loss: 2.2970561353109216

Epoch: 6| Step: 7
Training loss: 2.5726115703582764
Validation loss: 2.3043286620929675

Epoch: 6| Step: 8
Training loss: 2.546494483947754
Validation loss: 2.311965907773664

Epoch: 6| Step: 9
Training loss: 2.5927534103393555
Validation loss: 2.3009878435442523

Epoch: 6| Step: 10
Training loss: 1.9564093351364136
Validation loss: 2.308427993969251

Epoch: 6| Step: 11
Training loss: 2.2167282104492188
Validation loss: 2.310978986883676

Epoch: 6| Step: 12
Training loss: 2.5457210540771484
Validation loss: 2.3109148061403664

Epoch: 6| Step: 13
Training loss: 2.5804529190063477
Validation loss: 2.328549092815768

Epoch: 101| Step: 0
Training loss: 2.2209620475769043
Validation loss: 2.3311848922442366

Epoch: 6| Step: 1
Training loss: 2.4480857849121094
Validation loss: 2.341024203967023

Epoch: 6| Step: 2
Training loss: 3.1366236209869385
Validation loss: 2.365320800453104

Epoch: 6| Step: 3
Training loss: 2.164477825164795
Validation loss: 2.3593875720936763

Epoch: 6| Step: 4
Training loss: 2.395475387573242
Validation loss: 2.382587376461234

Epoch: 6| Step: 5
Training loss: 3.038414478302002
Validation loss: 2.3785906889105357

Epoch: 6| Step: 6
Training loss: 2.388930320739746
Validation loss: 2.3807045182874127

Epoch: 6| Step: 7
Training loss: 2.8455049991607666
Validation loss: 2.3822674738463534

Epoch: 6| Step: 8
Training loss: 2.985135555267334
Validation loss: 2.3982120585697952

Epoch: 6| Step: 9
Training loss: 2.27848744392395
Validation loss: 2.3533171787056872

Epoch: 6| Step: 10
Training loss: 2.845309257507324
Validation loss: 2.35500604362898

Epoch: 6| Step: 11
Training loss: 2.4202938079833984
Validation loss: 2.3445575109092136

Epoch: 6| Step: 12
Training loss: 2.401379108428955
Validation loss: 2.347940114236647

Epoch: 6| Step: 13
Training loss: 2.053273916244507
Validation loss: 2.339187568233859

Epoch: 102| Step: 0
Training loss: 3.391524314880371
Validation loss: 2.329054986276934

Epoch: 6| Step: 1
Training loss: 2.4071266651153564
Validation loss: 2.3226341803868613

Epoch: 6| Step: 2
Training loss: 2.503837823867798
Validation loss: 2.319080606583626

Epoch: 6| Step: 3
Training loss: 2.1586179733276367
Validation loss: 2.319618648098361

Epoch: 6| Step: 4
Training loss: 2.8907079696655273
Validation loss: 2.3334102835706485

Epoch: 6| Step: 5
Training loss: 2.480435609817505
Validation loss: 2.3186273215919413

Epoch: 6| Step: 6
Training loss: 2.9784739017486572
Validation loss: 2.3219914256885485

Epoch: 6| Step: 7
Training loss: 2.2150068283081055
Validation loss: 2.3136014707626833

Epoch: 6| Step: 8
Training loss: 2.7652177810668945
Validation loss: 2.318863122693954

Epoch: 6| Step: 9
Training loss: 2.089277744293213
Validation loss: 2.312118730237407

Epoch: 6| Step: 10
Training loss: 2.59401273727417
Validation loss: 2.3113673502399075

Epoch: 6| Step: 11
Training loss: 2.6118621826171875
Validation loss: 2.317727727274741

Epoch: 6| Step: 12
Training loss: 2.6323556900024414
Validation loss: 2.3210750420888266

Epoch: 6| Step: 13
Training loss: 1.8918020725250244
Validation loss: 2.3124496706070437

Epoch: 103| Step: 0
Training loss: 2.8517074584960938
Validation loss: 2.3110376237541117

Epoch: 6| Step: 1
Training loss: 2.1183626651763916
Validation loss: 2.3278266896483717

Epoch: 6| Step: 2
Training loss: 2.488729953765869
Validation loss: 2.329751435146537

Epoch: 6| Step: 3
Training loss: 3.030042886734009
Validation loss: 2.3490559542050926

Epoch: 6| Step: 4
Training loss: 3.2225379943847656
Validation loss: 2.336822868675314

Epoch: 6| Step: 5
Training loss: 2.482433795928955
Validation loss: 2.352871766654394

Epoch: 6| Step: 6
Training loss: 2.6636276245117188
Validation loss: 2.3498498547461724

Epoch: 6| Step: 7
Training loss: 2.3122482299804688
Validation loss: 2.331231294139739

Epoch: 6| Step: 8
Training loss: 2.6616837978363037
Validation loss: 2.3397207849769184

Epoch: 6| Step: 9
Training loss: 2.33708119392395
Validation loss: 2.3210926619909142

Epoch: 6| Step: 10
Training loss: 3.0207109451293945
Validation loss: 2.3332770434758996

Epoch: 6| Step: 11
Training loss: 2.5067331790924072
Validation loss: 2.3457304431546118

Epoch: 6| Step: 12
Training loss: 1.9136039018630981
Validation loss: 2.3346077921569988

Epoch: 6| Step: 13
Training loss: 2.1844863891601562
Validation loss: 2.3153336740309194

Epoch: 104| Step: 0
Training loss: 2.5985798835754395
Validation loss: 2.3111900129625873

Epoch: 6| Step: 1
Training loss: 2.098506212234497
Validation loss: 2.306305931460473

Epoch: 6| Step: 2
Training loss: 2.676055908203125
Validation loss: 2.3198976926906134

Epoch: 6| Step: 3
Training loss: 2.2553627490997314
Validation loss: 2.343603693028932

Epoch: 6| Step: 4
Training loss: 2.7722105979919434
Validation loss: 2.338791944647348

Epoch: 6| Step: 5
Training loss: 3.001232385635376
Validation loss: 2.3531573716030327

Epoch: 6| Step: 6
Training loss: 3.195401191711426
Validation loss: 2.3599344325321976

Epoch: 6| Step: 7
Training loss: 2.4820802211761475
Validation loss: 2.341705440193094

Epoch: 6| Step: 8
Training loss: 2.75974702835083
Validation loss: 2.3400734983464724

Epoch: 6| Step: 9
Training loss: 2.282315969467163
Validation loss: 2.3285446730993127

Epoch: 6| Step: 10
Training loss: 2.1596407890319824
Validation loss: 2.324798014856154

Epoch: 6| Step: 11
Training loss: 2.2231061458587646
Validation loss: 2.318639647576117

Epoch: 6| Step: 12
Training loss: 2.3883233070373535
Validation loss: 2.323576888730449

Epoch: 6| Step: 13
Training loss: 3.125635862350464
Validation loss: 2.3319028474951304

Epoch: 105| Step: 0
Training loss: 2.5588831901550293
Validation loss: 2.3294020416916057

Epoch: 6| Step: 1
Training loss: 2.9138693809509277
Validation loss: 2.363060212904407

Epoch: 6| Step: 2
Training loss: 2.2578701972961426
Validation loss: 2.323356220799108

Epoch: 6| Step: 3
Training loss: 2.4137017726898193
Validation loss: 2.3361626030296407

Epoch: 6| Step: 4
Training loss: 2.204875946044922
Validation loss: 2.341679734568442

Epoch: 6| Step: 5
Training loss: 1.8296033143997192
Validation loss: 2.3352076904748076

Epoch: 6| Step: 6
Training loss: 2.8111469745635986
Validation loss: 2.3616142862586567

Epoch: 6| Step: 7
Training loss: 2.4297080039978027
Validation loss: 2.358340435130622

Epoch: 6| Step: 8
Training loss: 2.764893054962158
Validation loss: 2.3873209953308105

Epoch: 6| Step: 9
Training loss: 2.5603227615356445
Validation loss: 2.395401035585711

Epoch: 6| Step: 10
Training loss: 2.7604315280914307
Validation loss: 2.4109200585273003

Epoch: 6| Step: 11
Training loss: 2.694709062576294
Validation loss: 2.424201729477093

Epoch: 6| Step: 12
Training loss: 2.6390509605407715
Validation loss: 2.4207645257314048

Epoch: 6| Step: 13
Training loss: 3.066175937652588
Validation loss: 2.4102249555690314

Epoch: 106| Step: 0
Training loss: 2.1755707263946533
Validation loss: 2.3826651137362242

Epoch: 6| Step: 1
Training loss: 2.355396270751953
Validation loss: 2.3918632896997596

Epoch: 6| Step: 2
Training loss: 2.5714011192321777
Validation loss: 2.371483738704394

Epoch: 6| Step: 3
Training loss: 2.9046273231506348
Validation loss: 2.366759152822597

Epoch: 6| Step: 4
Training loss: 1.9077985286712646
Validation loss: 2.332302111451344

Epoch: 6| Step: 5
Training loss: 3.0491251945495605
Validation loss: 2.33457596840397

Epoch: 6| Step: 6
Training loss: 2.6543936729431152
Validation loss: 2.3305926399846233

Epoch: 6| Step: 7
Training loss: 3.2230820655822754
Validation loss: 2.27762867558387

Epoch: 6| Step: 8
Training loss: 2.3427021503448486
Validation loss: 2.2763138586475002

Epoch: 6| Step: 9
Training loss: 2.2921838760375977
Validation loss: 2.2786534370914584

Epoch: 6| Step: 10
Training loss: 2.6192991733551025
Validation loss: 2.281554438734567

Epoch: 6| Step: 11
Training loss: 2.3923139572143555
Validation loss: 2.2951085849474837

Epoch: 6| Step: 12
Training loss: 2.4282400608062744
Validation loss: 2.3004867876729658

Epoch: 6| Step: 13
Training loss: 2.8198211193084717
Validation loss: 2.2890382325777443

Epoch: 107| Step: 0
Training loss: 2.027543544769287
Validation loss: 2.310223166660596

Epoch: 6| Step: 1
Training loss: 2.757472276687622
Validation loss: 2.3144525456172165

Epoch: 6| Step: 2
Training loss: 2.8658061027526855
Validation loss: 2.3085652320615706

Epoch: 6| Step: 3
Training loss: 2.19039249420166
Validation loss: 2.2990140479098082

Epoch: 6| Step: 4
Training loss: 2.9532055854797363
Validation loss: 2.288095607552477

Epoch: 6| Step: 5
Training loss: 1.9278489351272583
Validation loss: 2.2805420942203973

Epoch: 6| Step: 6
Training loss: 3.007176399230957
Validation loss: 2.27187160266343

Epoch: 6| Step: 7
Training loss: 2.927217721939087
Validation loss: 2.263588333642611

Epoch: 6| Step: 8
Training loss: 2.7899155616760254
Validation loss: 2.2736350900383404

Epoch: 6| Step: 9
Training loss: 2.609046220779419
Validation loss: 2.261818790948519

Epoch: 6| Step: 10
Training loss: 3.172995090484619
Validation loss: 2.267195083761728

Epoch: 6| Step: 11
Training loss: 2.276416063308716
Validation loss: 2.2630305469677015

Epoch: 6| Step: 12
Training loss: 1.7273638248443604
Validation loss: 2.2713564083140385

Epoch: 6| Step: 13
Training loss: 2.6793136596679688
Validation loss: 2.267386608226325

Epoch: 108| Step: 0
Training loss: 2.4483730792999268
Validation loss: 2.272963995574623

Epoch: 6| Step: 1
Training loss: 2.4564127922058105
Validation loss: 2.2745427470053396

Epoch: 6| Step: 2
Training loss: 2.9786791801452637
Validation loss: 2.2728627061331146

Epoch: 6| Step: 3
Training loss: 2.21416974067688
Validation loss: 2.278294560729816

Epoch: 6| Step: 4
Training loss: 2.9040591716766357
Validation loss: 2.289843664374403

Epoch: 6| Step: 5
Training loss: 2.9491376876831055
Validation loss: 2.2811244713362826

Epoch: 6| Step: 6
Training loss: 2.4790029525756836
Validation loss: 2.2839186819650794

Epoch: 6| Step: 7
Training loss: 2.839261054992676
Validation loss: 2.28962968754512

Epoch: 6| Step: 8
Training loss: 2.0337207317352295
Validation loss: 2.289337588894752

Epoch: 6| Step: 9
Training loss: 2.0551137924194336
Validation loss: 2.2959168495670443

Epoch: 6| Step: 10
Training loss: 3.1360199451446533
Validation loss: 2.3038314978281655

Epoch: 6| Step: 11
Training loss: 2.1066927909851074
Validation loss: 2.3036709549606487

Epoch: 6| Step: 12
Training loss: 2.1235780715942383
Validation loss: 2.324370450870965

Epoch: 6| Step: 13
Training loss: 3.2204301357269287
Validation loss: 2.307957754340223

Epoch: 109| Step: 0
Training loss: 3.5529825687408447
Validation loss: 2.309454430815994

Epoch: 6| Step: 1
Training loss: 2.8279225826263428
Validation loss: 2.3047882792770222

Epoch: 6| Step: 2
Training loss: 2.102285385131836
Validation loss: 2.296751763231011

Epoch: 6| Step: 3
Training loss: 1.956318736076355
Validation loss: 2.304091315115652

Epoch: 6| Step: 4
Training loss: 2.857621669769287
Validation loss: 2.293823060169015

Epoch: 6| Step: 5
Training loss: 2.513882637023926
Validation loss: 2.3010822573015766

Epoch: 6| Step: 6
Training loss: 2.656111240386963
Validation loss: 2.3092068882398706

Epoch: 6| Step: 7
Training loss: 2.4600143432617188
Validation loss: 2.305418001708164

Epoch: 6| Step: 8
Training loss: 2.3083064556121826
Validation loss: 2.3077285648674093

Epoch: 6| Step: 9
Training loss: 1.9965356588363647
Validation loss: 2.325538173798592

Epoch: 6| Step: 10
Training loss: 2.3137145042419434
Validation loss: 2.3301995800387476

Epoch: 6| Step: 11
Training loss: 2.5054502487182617
Validation loss: 2.3698116451181392

Epoch: 6| Step: 12
Training loss: 2.329525947570801
Validation loss: 2.40496067846975

Epoch: 6| Step: 13
Training loss: 3.334993362426758
Validation loss: 2.4221673652689946

Epoch: 110| Step: 0
Training loss: 1.9429113864898682
Validation loss: 2.4922086500352427

Epoch: 6| Step: 1
Training loss: 2.8125641345977783
Validation loss: 2.481713641074396

Epoch: 6| Step: 2
Training loss: 3.2777585983276367
Validation loss: 2.460540384374639

Epoch: 6| Step: 3
Training loss: 2.711479663848877
Validation loss: 2.4106428059198524

Epoch: 6| Step: 4
Training loss: 1.945542812347412
Validation loss: 2.352692428455558

Epoch: 6| Step: 5
Training loss: 1.8191442489624023
Validation loss: 2.301590727221581

Epoch: 6| Step: 6
Training loss: 2.6395046710968018
Validation loss: 2.290057151548324

Epoch: 6| Step: 7
Training loss: 2.8577229976654053
Validation loss: 2.278220545861029

Epoch: 6| Step: 8
Training loss: 3.0247933864593506
Validation loss: 2.2741242506170787

Epoch: 6| Step: 9
Training loss: 2.710838794708252
Validation loss: 2.280327322662518

Epoch: 6| Step: 10
Training loss: 2.6020326614379883
Validation loss: 2.258056725225141

Epoch: 6| Step: 11
Training loss: 1.8449703454971313
Validation loss: 2.262070648131832

Epoch: 6| Step: 12
Training loss: 2.6806275844573975
Validation loss: 2.251896506996565

Epoch: 6| Step: 13
Training loss: 3.0548272132873535
Validation loss: 2.252361656517111

Epoch: 111| Step: 0
Training loss: 2.159576892852783
Validation loss: 2.248180308649617

Epoch: 6| Step: 1
Training loss: 3.0063889026641846
Validation loss: 2.254044889121927

Epoch: 6| Step: 2
Training loss: 2.8130710124969482
Validation loss: 2.247169167764725

Epoch: 6| Step: 3
Training loss: 2.3894548416137695
Validation loss: 2.25228613679127

Epoch: 6| Step: 4
Training loss: 2.569141149520874
Validation loss: 2.252125201686736

Epoch: 6| Step: 5
Training loss: 2.1850197315216064
Validation loss: 2.253176079001478

Epoch: 6| Step: 6
Training loss: 1.8877925872802734
Validation loss: 2.2469220520347677

Epoch: 6| Step: 7
Training loss: 2.59027099609375
Validation loss: 2.2485411782418527

Epoch: 6| Step: 8
Training loss: 3.0573673248291016
Validation loss: 2.248116029206143

Epoch: 6| Step: 9
Training loss: 2.5768589973449707
Validation loss: 2.246247019819034

Epoch: 6| Step: 10
Training loss: 2.703317880630493
Validation loss: 2.2585565095306723

Epoch: 6| Step: 11
Training loss: 2.867677927017212
Validation loss: 2.267970367144513

Epoch: 6| Step: 12
Training loss: 2.726027488708496
Validation loss: 2.2642816625615603

Epoch: 6| Step: 13
Training loss: 1.6804062128067017
Validation loss: 2.283367113400531

Epoch: 112| Step: 0
Training loss: 2.253350257873535
Validation loss: 2.3021572507837766

Epoch: 6| Step: 1
Training loss: 2.489711046218872
Validation loss: 2.3258211561428603

Epoch: 6| Step: 2
Training loss: 3.437429189682007
Validation loss: 2.353864187835365

Epoch: 6| Step: 3
Training loss: 2.211829423904419
Validation loss: 2.356287343527681

Epoch: 6| Step: 4
Training loss: 2.1561214923858643
Validation loss: 2.3449442386627197

Epoch: 6| Step: 5
Training loss: 2.7115087509155273
Validation loss: 2.3591961373565016

Epoch: 6| Step: 6
Training loss: 2.968484401702881
Validation loss: 2.3421163533323552

Epoch: 6| Step: 7
Training loss: 1.9489483833312988
Validation loss: 2.336602169980285

Epoch: 6| Step: 8
Training loss: 2.4917328357696533
Validation loss: 2.314961761556646

Epoch: 6| Step: 9
Training loss: 1.9217473268508911
Validation loss: 2.322225593751477

Epoch: 6| Step: 10
Training loss: 2.3399147987365723
Validation loss: 2.3338738077430317

Epoch: 6| Step: 11
Training loss: 2.930849075317383
Validation loss: 2.3412179177807224

Epoch: 6| Step: 12
Training loss: 2.320692300796509
Validation loss: 2.3692305062406804

Epoch: 6| Step: 13
Training loss: 3.780484914779663
Validation loss: 2.409781676466747

Epoch: 113| Step: 0
Training loss: 1.5225021839141846
Validation loss: 2.4607871809313373

Epoch: 6| Step: 1
Training loss: 2.3242738246917725
Validation loss: 2.407995072744226

Epoch: 6| Step: 2
Training loss: 2.1781485080718994
Validation loss: 2.393732995115301

Epoch: 6| Step: 3
Training loss: 2.517430305480957
Validation loss: 2.366146338883267

Epoch: 6| Step: 4
Training loss: 2.04779052734375
Validation loss: 2.327596382428241

Epoch: 6| Step: 5
Training loss: 2.4959287643432617
Validation loss: 2.318467096615863

Epoch: 6| Step: 6
Training loss: 2.6420767307281494
Validation loss: 2.3075371173120316

Epoch: 6| Step: 7
Training loss: 2.452944755554199
Validation loss: 2.3147318106825634

Epoch: 6| Step: 8
Training loss: 2.7825019359588623
Validation loss: 2.301378260376633

Epoch: 6| Step: 9
Training loss: 3.1793079376220703
Validation loss: 2.319812697748984

Epoch: 6| Step: 10
Training loss: 2.1794567108154297
Validation loss: 2.3088683979485625

Epoch: 6| Step: 11
Training loss: 2.92618989944458
Validation loss: 2.3183356408149964

Epoch: 6| Step: 12
Training loss: 3.067643880844116
Validation loss: 2.3345923039220993

Epoch: 6| Step: 13
Training loss: 3.7101681232452393
Validation loss: 2.321202608846849

Epoch: 114| Step: 0
Training loss: 2.5566389560699463
Validation loss: 2.2925140947423954

Epoch: 6| Step: 1
Training loss: 2.508017063140869
Validation loss: 2.2973396265378563

Epoch: 6| Step: 2
Training loss: 2.434450626373291
Validation loss: 2.284904223616405

Epoch: 6| Step: 3
Training loss: 2.069888114929199
Validation loss: 2.2838234157972437

Epoch: 6| Step: 4
Training loss: 3.059548854827881
Validation loss: 2.290595298172325

Epoch: 6| Step: 5
Training loss: 2.2626352310180664
Validation loss: 2.2879851569411573

Epoch: 6| Step: 6
Training loss: 2.3900585174560547
Validation loss: 2.3013062220747753

Epoch: 6| Step: 7
Training loss: 1.8462276458740234
Validation loss: 2.299109638378184

Epoch: 6| Step: 8
Training loss: 2.397441864013672
Validation loss: 2.2843387921651206

Epoch: 6| Step: 9
Training loss: 2.856994152069092
Validation loss: 2.2890755771308817

Epoch: 6| Step: 10
Training loss: 3.1596808433532715
Validation loss: 2.28654900673897

Epoch: 6| Step: 11
Training loss: 3.0448827743530273
Validation loss: 2.2803023502390873

Epoch: 6| Step: 12
Training loss: 2.0854849815368652
Validation loss: 2.2778499075161514

Epoch: 6| Step: 13
Training loss: 2.764556407928467
Validation loss: 2.282741436394312

Epoch: 115| Step: 0
Training loss: 2.7172324657440186
Validation loss: 2.280367978157536

Epoch: 6| Step: 1
Training loss: 2.5868258476257324
Validation loss: 2.273055779036655

Epoch: 6| Step: 2
Training loss: 2.184767723083496
Validation loss: 2.2790955933191444

Epoch: 6| Step: 3
Training loss: 2.5468549728393555
Validation loss: 2.2861823317825154

Epoch: 6| Step: 4
Training loss: 2.480210542678833
Validation loss: 2.30646058564545

Epoch: 6| Step: 5
Training loss: 2.50357723236084
Validation loss: 2.3398538097258537

Epoch: 6| Step: 6
Training loss: 2.0425844192504883
Validation loss: 2.3636627671539143

Epoch: 6| Step: 7
Training loss: 2.775847911834717
Validation loss: 2.3661439828975226

Epoch: 6| Step: 8
Training loss: 1.7278375625610352
Validation loss: 2.361218980563584

Epoch: 6| Step: 9
Training loss: 3.1214284896850586
Validation loss: 2.3466460012620494

Epoch: 6| Step: 10
Training loss: 2.9736557006835938
Validation loss: 2.3171546613016436

Epoch: 6| Step: 11
Training loss: 1.8944013118743896
Validation loss: 2.3173286017551216

Epoch: 6| Step: 12
Training loss: 2.965062141418457
Validation loss: 2.306610847032198

Epoch: 6| Step: 13
Training loss: 2.5958914756774902
Validation loss: 2.300684211074665

Epoch: 116| Step: 0
Training loss: 2.810002088546753
Validation loss: 2.311435543080812

Epoch: 6| Step: 1
Training loss: 2.390885829925537
Validation loss: 2.323071156778643

Epoch: 6| Step: 2
Training loss: 2.427888870239258
Validation loss: 2.310620753995834

Epoch: 6| Step: 3
Training loss: 1.8760828971862793
Validation loss: 2.3265655425287064

Epoch: 6| Step: 4
Training loss: 2.2997989654541016
Validation loss: 2.3243558406829834

Epoch: 6| Step: 5
Training loss: 2.5645639896392822
Validation loss: 2.3266685983186126

Epoch: 6| Step: 6
Training loss: 2.9723448753356934
Validation loss: 2.3373096271227767

Epoch: 6| Step: 7
Training loss: 2.553253650665283
Validation loss: 2.334583072252171

Epoch: 6| Step: 8
Training loss: 2.1907854080200195
Validation loss: 2.325879837877007

Epoch: 6| Step: 9
Training loss: 2.7245852947235107
Validation loss: 2.342646619325043

Epoch: 6| Step: 10
Training loss: 2.811126470565796
Validation loss: 2.3410831651379986

Epoch: 6| Step: 11
Training loss: 2.063455104827881
Validation loss: 2.317479915516351

Epoch: 6| Step: 12
Training loss: 2.615466833114624
Validation loss: 2.309030367482093

Epoch: 6| Step: 13
Training loss: 2.9529786109924316
Validation loss: 2.297723800905289

Epoch: 117| Step: 0
Training loss: 1.5027389526367188
Validation loss: 2.2952133686311784

Epoch: 6| Step: 1
Training loss: 2.219182014465332
Validation loss: 2.286570531065746

Epoch: 6| Step: 2
Training loss: 2.825463056564331
Validation loss: 2.3032200208274265

Epoch: 6| Step: 3
Training loss: 1.8138628005981445
Validation loss: 2.322195896538355

Epoch: 6| Step: 4
Training loss: 2.2496337890625
Validation loss: 2.322454889615377

Epoch: 6| Step: 5
Training loss: 3.808523416519165
Validation loss: 2.353092283330938

Epoch: 6| Step: 6
Training loss: 2.445481777191162
Validation loss: 2.339858970334453

Epoch: 6| Step: 7
Training loss: 2.590433120727539
Validation loss: 2.345424993063814

Epoch: 6| Step: 8
Training loss: 2.6448612213134766
Validation loss: 2.349156497627176

Epoch: 6| Step: 9
Training loss: 2.9724087715148926
Validation loss: 2.360901017342844

Epoch: 6| Step: 10
Training loss: 1.916818618774414
Validation loss: 2.30883208141532

Epoch: 6| Step: 11
Training loss: 1.8264878988265991
Validation loss: 2.2862494748125792

Epoch: 6| Step: 12
Training loss: 3.41709041595459
Validation loss: 2.277650720329695

Epoch: 6| Step: 13
Training loss: 2.92669677734375
Validation loss: 2.2727087133674213

Epoch: 118| Step: 0
Training loss: 2.019326686859131
Validation loss: 2.2662395379876576

Epoch: 6| Step: 1
Training loss: 2.1416215896606445
Validation loss: 2.2596799481299614

Epoch: 6| Step: 2
Training loss: 2.2525718212127686
Validation loss: 2.2376430931911675

Epoch: 6| Step: 3
Training loss: 3.2974538803100586
Validation loss: 2.236319354785386

Epoch: 6| Step: 4
Training loss: 2.816544532775879
Validation loss: 2.2432576353831957

Epoch: 6| Step: 5
Training loss: 2.954714775085449
Validation loss: 2.267736150372413

Epoch: 6| Step: 6
Training loss: 2.0235981941223145
Validation loss: 2.2822445002935265

Epoch: 6| Step: 7
Training loss: 2.985018014907837
Validation loss: 2.2775241149369108

Epoch: 6| Step: 8
Training loss: 2.518467426300049
Validation loss: 2.330487565327716

Epoch: 6| Step: 9
Training loss: 1.9073138236999512
Validation loss: 2.35264818386365

Epoch: 6| Step: 10
Training loss: 2.1913676261901855
Validation loss: 2.363524592050942

Epoch: 6| Step: 11
Training loss: 3.0364830493927
Validation loss: 2.4026725189660185

Epoch: 6| Step: 12
Training loss: 3.0512986183166504
Validation loss: 2.3351355060454337

Epoch: 6| Step: 13
Training loss: 1.7693049907684326
Validation loss: 2.3036484769595567

Epoch: 119| Step: 0
Training loss: 2.9716897010803223
Validation loss: 2.333963071146319

Epoch: 6| Step: 1
Training loss: 2.4827990531921387
Validation loss: 2.334844840470181

Epoch: 6| Step: 2
Training loss: 2.224626064300537
Validation loss: 2.3498595196713685

Epoch: 6| Step: 3
Training loss: 2.1049561500549316
Validation loss: 2.375924312940208

Epoch: 6| Step: 4
Training loss: 1.8245925903320312
Validation loss: 2.367973268672984

Epoch: 6| Step: 5
Training loss: 1.8298343420028687
Validation loss: 2.3982070056341027

Epoch: 6| Step: 6
Training loss: 2.791574001312256
Validation loss: 2.416547426613428

Epoch: 6| Step: 7
Training loss: 2.2581634521484375
Validation loss: 2.4091039216646584

Epoch: 6| Step: 8
Training loss: 3.243194103240967
Validation loss: 2.3925759253963346

Epoch: 6| Step: 9
Training loss: 3.6644115447998047
Validation loss: 2.3299618126243673

Epoch: 6| Step: 10
Training loss: 2.0709493160247803
Validation loss: 2.3011241625714045

Epoch: 6| Step: 11
Training loss: 2.3720593452453613
Validation loss: 2.2756931320313485

Epoch: 6| Step: 12
Training loss: 2.810204267501831
Validation loss: 2.241879932342037

Epoch: 6| Step: 13
Training loss: 2.4796528816223145
Validation loss: 2.2317954865835046

Epoch: 120| Step: 0
Training loss: 2.664926528930664
Validation loss: 2.2320289919453282

Epoch: 6| Step: 1
Training loss: 2.3904151916503906
Validation loss: 2.2304656569675734

Epoch: 6| Step: 2
Training loss: 2.8701157569885254
Validation loss: 2.236535164617723

Epoch: 6| Step: 3
Training loss: 3.034778594970703
Validation loss: 2.2324301747865576

Epoch: 6| Step: 4
Training loss: 2.155651092529297
Validation loss: 2.2209726456672914

Epoch: 6| Step: 5
Training loss: 2.351618766784668
Validation loss: 2.2156051179414153

Epoch: 6| Step: 6
Training loss: 2.096470355987549
Validation loss: 2.2181084309854815

Epoch: 6| Step: 7
Training loss: 2.018688678741455
Validation loss: 2.2181615829467773

Epoch: 6| Step: 8
Training loss: 2.317929983139038
Validation loss: 2.215252714772378

Epoch: 6| Step: 9
Training loss: 2.826350212097168
Validation loss: 2.2180245435366066

Epoch: 6| Step: 10
Training loss: 2.076953411102295
Validation loss: 2.2159216493688603

Epoch: 6| Step: 11
Training loss: 2.9234395027160645
Validation loss: 2.2140709302758657

Epoch: 6| Step: 12
Training loss: 3.1405649185180664
Validation loss: 2.217531188841789

Epoch: 6| Step: 13
Training loss: 2.530501365661621
Validation loss: 2.2157727890117194

Epoch: 121| Step: 0
Training loss: 2.6874330043792725
Validation loss: 2.2287388386264926

Epoch: 6| Step: 1
Training loss: 2.860166549682617
Validation loss: 2.2267651968104865

Epoch: 6| Step: 2
Training loss: 2.6790473461151123
Validation loss: 2.2198384320864113

Epoch: 6| Step: 3
Training loss: 2.008890151977539
Validation loss: 2.219908747621762

Epoch: 6| Step: 4
Training loss: 2.9904963970184326
Validation loss: 2.246665955871664

Epoch: 6| Step: 5
Training loss: 2.568093776702881
Validation loss: 2.253973866021761

Epoch: 6| Step: 6
Training loss: 2.904355525970459
Validation loss: 2.289736683650683

Epoch: 6| Step: 7
Training loss: 2.4421801567077637
Validation loss: 2.3026445834867415

Epoch: 6| Step: 8
Training loss: 2.2886109352111816
Validation loss: 2.3439936150786695

Epoch: 6| Step: 9
Training loss: 1.817087173461914
Validation loss: 2.318468224617743

Epoch: 6| Step: 10
Training loss: 2.2485690116882324
Validation loss: 2.291282820445235

Epoch: 6| Step: 11
Training loss: 3.1085076332092285
Validation loss: 2.27635468206098

Epoch: 6| Step: 12
Training loss: 2.493706464767456
Validation loss: 2.2681874998154177

Epoch: 6| Step: 13
Training loss: 2.1634528636932373
Validation loss: 2.2673324743906655

Epoch: 122| Step: 0
Training loss: 2.4150469303131104
Validation loss: 2.2668287138785086

Epoch: 6| Step: 1
Training loss: 2.707029342651367
Validation loss: 2.2636071148739068

Epoch: 6| Step: 2
Training loss: 2.2537269592285156
Validation loss: 2.2724694000777377

Epoch: 6| Step: 3
Training loss: 2.6610238552093506
Validation loss: 2.2609683903314735

Epoch: 6| Step: 4
Training loss: 2.556056499481201
Validation loss: 2.273211112586401

Epoch: 6| Step: 5
Training loss: 2.6940598487854004
Validation loss: 2.293393550380584

Epoch: 6| Step: 6
Training loss: 2.410051107406616
Validation loss: 2.2750168115861955

Epoch: 6| Step: 7
Training loss: 2.614534378051758
Validation loss: 2.291849515771353

Epoch: 6| Step: 8
Training loss: 2.7318592071533203
Validation loss: 2.2972640170845935

Epoch: 6| Step: 9
Training loss: 2.5034141540527344
Validation loss: 2.291553125586561

Epoch: 6| Step: 10
Training loss: 2.1010093688964844
Validation loss: 2.317074955150645

Epoch: 6| Step: 11
Training loss: 1.9204497337341309
Validation loss: 2.287802550100511

Epoch: 6| Step: 12
Training loss: 2.8036746978759766
Validation loss: 2.2831531570803736

Epoch: 6| Step: 13
Training loss: 2.4331562519073486
Validation loss: 2.286898059229697

Epoch: 123| Step: 0
Training loss: 2.397486925125122
Validation loss: 2.2998199616709063

Epoch: 6| Step: 1
Training loss: 2.125356674194336
Validation loss: 2.323676029841105

Epoch: 6| Step: 2
Training loss: 2.3022210597991943
Validation loss: 2.328457660572503

Epoch: 6| Step: 3
Training loss: 2.5717339515686035
Validation loss: 2.329913405961888

Epoch: 6| Step: 4
Training loss: 1.903501033782959
Validation loss: 2.309726607414984

Epoch: 6| Step: 5
Training loss: 2.6830101013183594
Validation loss: 2.301056319667447

Epoch: 6| Step: 6
Training loss: 1.9311014413833618
Validation loss: 2.2957479171855475

Epoch: 6| Step: 7
Training loss: 2.6093196868896484
Validation loss: 2.277844822534951

Epoch: 6| Step: 8
Training loss: 2.8306901454925537
Validation loss: 2.279362484972964

Epoch: 6| Step: 9
Training loss: 2.6698174476623535
Validation loss: 2.2731518309603453

Epoch: 6| Step: 10
Training loss: 2.658505439758301
Validation loss: 2.281411829815116

Epoch: 6| Step: 11
Training loss: 3.2166378498077393
Validation loss: 2.2637367556172032

Epoch: 6| Step: 12
Training loss: 2.5758771896362305
Validation loss: 2.247274065530428

Epoch: 6| Step: 13
Training loss: 2.7456119060516357
Validation loss: 2.2294089627522293

Epoch: 124| Step: 0
Training loss: 2.3064889907836914
Validation loss: 2.248580153270434

Epoch: 6| Step: 1
Training loss: 2.3370652198791504
Validation loss: 2.2816393093396257

Epoch: 6| Step: 2
Training loss: 2.7047770023345947
Validation loss: 2.3385404438100834

Epoch: 6| Step: 3
Training loss: 1.8762742280960083
Validation loss: 2.3815571261990454

Epoch: 6| Step: 4
Training loss: 3.9424431324005127
Validation loss: 2.4292693291940997

Epoch: 6| Step: 5
Training loss: 2.0501484870910645
Validation loss: 2.41785845961622

Epoch: 6| Step: 6
Training loss: 2.7236227989196777
Validation loss: 2.395833953734367

Epoch: 6| Step: 7
Training loss: 2.5701828002929688
Validation loss: 2.3072152804302912

Epoch: 6| Step: 8
Training loss: 1.805849552154541
Validation loss: 2.28418372267036

Epoch: 6| Step: 9
Training loss: 2.14793062210083
Validation loss: 2.2479480428080403

Epoch: 6| Step: 10
Training loss: 2.479973793029785
Validation loss: 2.2376075303682716

Epoch: 6| Step: 11
Training loss: 3.0938501358032227
Validation loss: 2.246658441840961

Epoch: 6| Step: 12
Training loss: 2.28648042678833
Validation loss: 2.2732186343080256

Epoch: 6| Step: 13
Training loss: 2.718533754348755
Validation loss: 2.2810562220952844

Epoch: 125| Step: 0
Training loss: 2.6159653663635254
Validation loss: 2.268501556047829

Epoch: 6| Step: 1
Training loss: 2.5809452533721924
Validation loss: 2.2504327374119915

Epoch: 6| Step: 2
Training loss: 2.654672622680664
Validation loss: 2.236844249950942

Epoch: 6| Step: 3
Training loss: 2.5434083938598633
Validation loss: 2.227787907405566

Epoch: 6| Step: 4
Training loss: 1.9759297370910645
Validation loss: 2.2262157265857985

Epoch: 6| Step: 5
Training loss: 2.3713607788085938
Validation loss: 2.2319838616155807

Epoch: 6| Step: 6
Training loss: 1.8277851343154907
Validation loss: 2.250868663992933

Epoch: 6| Step: 7
Training loss: 2.4546148777008057
Validation loss: 2.2636064765273884

Epoch: 6| Step: 8
Training loss: 2.8267390727996826
Validation loss: 2.2702497359245055

Epoch: 6| Step: 9
Training loss: 2.09689998626709
Validation loss: 2.2808613661796815

Epoch: 6| Step: 10
Training loss: 3.0529427528381348
Validation loss: 2.2852693219338693

Epoch: 6| Step: 11
Training loss: 1.862497329711914
Validation loss: 2.2882879562275384

Epoch: 6| Step: 12
Training loss: 3.127946376800537
Validation loss: 2.307643034124887

Epoch: 6| Step: 13
Training loss: 2.769321918487549
Validation loss: 2.3301178716844126

Epoch: 126| Step: 0
Training loss: 3.33007550239563
Validation loss: 2.346651631016885

Epoch: 6| Step: 1
Training loss: 2.4097938537597656
Validation loss: 2.3116835035303587

Epoch: 6| Step: 2
Training loss: 2.745640754699707
Validation loss: 2.3275918294024724

Epoch: 6| Step: 3
Training loss: 2.179558277130127
Validation loss: 2.316165348534943

Epoch: 6| Step: 4
Training loss: 3.118274211883545
Validation loss: 2.3034094636158278

Epoch: 6| Step: 5
Training loss: 2.455611228942871
Validation loss: 2.300433346020278

Epoch: 6| Step: 6
Training loss: 1.5914055109024048
Validation loss: 2.2864041097702517

Epoch: 6| Step: 7
Training loss: 2.3271751403808594
Validation loss: 2.2695968458729405

Epoch: 6| Step: 8
Training loss: 2.266629457473755
Validation loss: 2.2553879778872252

Epoch: 6| Step: 9
Training loss: 2.550952196121216
Validation loss: 2.2526051293137255

Epoch: 6| Step: 10
Training loss: 2.719759702682495
Validation loss: 2.242811010729882

Epoch: 6| Step: 11
Training loss: 1.8483054637908936
Validation loss: 2.247561349663683

Epoch: 6| Step: 12
Training loss: 2.7024104595184326
Validation loss: 2.262845987914711

Epoch: 6| Step: 13
Training loss: 2.249359130859375
Validation loss: 2.2723779114343787

Epoch: 127| Step: 0
Training loss: 2.83681058883667
Validation loss: 2.2669191181018786

Epoch: 6| Step: 1
Training loss: 2.643596649169922
Validation loss: 2.2668489768940914

Epoch: 6| Step: 2
Training loss: 2.3027379512786865
Validation loss: 2.264824862121254

Epoch: 6| Step: 3
Training loss: 2.120741128921509
Validation loss: 2.2483921743208364

Epoch: 6| Step: 4
Training loss: 2.8232421875
Validation loss: 2.250690362786734

Epoch: 6| Step: 5
Training loss: 3.133892774581909
Validation loss: 2.2447503253977787

Epoch: 6| Step: 6
Training loss: 2.446902275085449
Validation loss: 2.2295405787806355

Epoch: 6| Step: 7
Training loss: 2.4487409591674805
Validation loss: 2.2393950621287027

Epoch: 6| Step: 8
Training loss: 2.5467071533203125
Validation loss: 2.2554080204297136

Epoch: 6| Step: 9
Training loss: 1.5156564712524414
Validation loss: 2.2512019424028296

Epoch: 6| Step: 10
Training loss: 2.5417885780334473
Validation loss: 2.2606254085417716

Epoch: 6| Step: 11
Training loss: 2.6170029640197754
Validation loss: 2.2770690533422653

Epoch: 6| Step: 12
Training loss: 1.7968533039093018
Validation loss: 2.258512645639399

Epoch: 6| Step: 13
Training loss: 2.727358341217041
Validation loss: 2.2829086396002

Epoch: 128| Step: 0
Training loss: 2.6613657474517822
Validation loss: 2.3098414597972745

Epoch: 6| Step: 1
Training loss: 2.046602964401245
Validation loss: 2.335093493102699

Epoch: 6| Step: 2
Training loss: 1.861316442489624
Validation loss: 2.3500258397030573

Epoch: 6| Step: 3
Training loss: 3.0192184448242188
Validation loss: 2.3460485473755868

Epoch: 6| Step: 4
Training loss: 1.695371389389038
Validation loss: 2.3436506435435307

Epoch: 6| Step: 5
Training loss: 2.3557956218719482
Validation loss: 2.314054891627322

Epoch: 6| Step: 6
Training loss: 2.712977886199951
Validation loss: 2.3130793110016854

Epoch: 6| Step: 7
Training loss: 2.2243576049804688
Validation loss: 2.311375799999442

Epoch: 6| Step: 8
Training loss: 2.968411445617676
Validation loss: 2.311924008912938

Epoch: 6| Step: 9
Training loss: 2.966648817062378
Validation loss: 2.289615583676164

Epoch: 6| Step: 10
Training loss: 3.21474552154541
Validation loss: 2.2818104579884517

Epoch: 6| Step: 11
Training loss: 2.697810649871826
Validation loss: 2.261785045746834

Epoch: 6| Step: 12
Training loss: 2.162457227706909
Validation loss: 2.2318388774830806

Epoch: 6| Step: 13
Training loss: 1.8378865718841553
Validation loss: 2.220544071607692

Epoch: 129| Step: 0
Training loss: 2.2631869316101074
Validation loss: 2.21408966536163

Epoch: 6| Step: 1
Training loss: 2.2717628479003906
Validation loss: 2.2469935237720446

Epoch: 6| Step: 2
Training loss: 2.509901285171509
Validation loss: 2.2744595325121315

Epoch: 6| Step: 3
Training loss: 2.7039389610290527
Validation loss: 2.295327550621443

Epoch: 6| Step: 4
Training loss: 2.979452133178711
Validation loss: 2.3220831348050024

Epoch: 6| Step: 5
Training loss: 3.400200366973877
Validation loss: 2.3191856825223534

Epoch: 6| Step: 6
Training loss: 2.5712742805480957
Validation loss: 2.302190888312555

Epoch: 6| Step: 7
Training loss: 2.0216712951660156
Validation loss: 2.263712398467525

Epoch: 6| Step: 8
Training loss: 2.1576027870178223
Validation loss: 2.247001350566905

Epoch: 6| Step: 9
Training loss: 2.1124343872070312
Validation loss: 2.2421254752784647

Epoch: 6| Step: 10
Training loss: 1.720411777496338
Validation loss: 2.2217001658613964

Epoch: 6| Step: 11
Training loss: 2.698805332183838
Validation loss: 2.219025045312861

Epoch: 6| Step: 12
Training loss: 2.7625362873077393
Validation loss: 2.2270747487263014

Epoch: 6| Step: 13
Training loss: 2.506455659866333
Validation loss: 2.2458535522542973

Epoch: 130| Step: 0
Training loss: 2.3441267013549805
Validation loss: 2.2431004406303487

Epoch: 6| Step: 1
Training loss: 2.1803064346313477
Validation loss: 2.2579719238383795

Epoch: 6| Step: 2
Training loss: 3.1308655738830566
Validation loss: 2.2775279065614105

Epoch: 6| Step: 3
Training loss: 2.782012462615967
Validation loss: 2.255541116960587

Epoch: 6| Step: 4
Training loss: 2.9513967037200928
Validation loss: 2.2668487589846373

Epoch: 6| Step: 5
Training loss: 2.430612564086914
Validation loss: 2.2654180065278084

Epoch: 6| Step: 6
Training loss: 2.0731191635131836
Validation loss: 2.2930028925659838

Epoch: 6| Step: 7
Training loss: 2.4594454765319824
Validation loss: 2.281695081341651

Epoch: 6| Step: 8
Training loss: 2.171095848083496
Validation loss: 2.265366062041252

Epoch: 6| Step: 9
Training loss: 2.494448661804199
Validation loss: 2.260799938632596

Epoch: 6| Step: 10
Training loss: 2.2999203205108643
Validation loss: 2.25626737840714

Epoch: 6| Step: 11
Training loss: 2.2501609325408936
Validation loss: 2.225296502472252

Epoch: 6| Step: 12
Training loss: 2.2376420497894287
Validation loss: 2.237824168256534

Epoch: 6| Step: 13
Training loss: 2.102325916290283
Validation loss: 2.243523366989628

Epoch: 131| Step: 0
Training loss: 2.373182773590088
Validation loss: 2.2474373976389566

Epoch: 6| Step: 1
Training loss: 2.262375831604004
Validation loss: 2.2575385185980026

Epoch: 6| Step: 2
Training loss: 1.949774980545044
Validation loss: 2.2609537352797804

Epoch: 6| Step: 3
Training loss: 2.7288026809692383
Validation loss: 2.259134410530008

Epoch: 6| Step: 4
Training loss: 2.6990511417388916
Validation loss: 2.263178861269387

Epoch: 6| Step: 5
Training loss: 2.4805655479431152
Validation loss: 2.246855915233653

Epoch: 6| Step: 6
Training loss: 2.8091225624084473
Validation loss: 2.2364803514172955

Epoch: 6| Step: 7
Training loss: 2.7459371089935303
Validation loss: 2.2327551662280993

Epoch: 6| Step: 8
Training loss: 2.4896159172058105
Validation loss: 2.2542030426763717

Epoch: 6| Step: 9
Training loss: 2.443570137023926
Validation loss: 2.238282617702279

Epoch: 6| Step: 10
Training loss: 2.567730665206909
Validation loss: 2.2443934461121917

Epoch: 6| Step: 11
Training loss: 2.5772228240966797
Validation loss: 2.237271826754334

Epoch: 6| Step: 12
Training loss: 1.779543399810791
Validation loss: 2.22481539428875

Epoch: 6| Step: 13
Training loss: 2.3672261238098145
Validation loss: 2.227145364207606

Epoch: 132| Step: 0
Training loss: 2.469803810119629
Validation loss: 2.2420914685854347

Epoch: 6| Step: 1
Training loss: 1.6985301971435547
Validation loss: 2.243969650678737

Epoch: 6| Step: 2
Training loss: 1.4322102069854736
Validation loss: 2.271057362197548

Epoch: 6| Step: 3
Training loss: 2.913588523864746
Validation loss: 2.3211493517762873

Epoch: 6| Step: 4
Training loss: 2.8956995010375977
Validation loss: 2.31081574450257

Epoch: 6| Step: 5
Training loss: 2.8253238201141357
Validation loss: 2.316099774452948

Epoch: 6| Step: 6
Training loss: 2.2538890838623047
Validation loss: 2.37897486840525

Epoch: 6| Step: 7
Training loss: 2.964766502380371
Validation loss: 2.4079729997983543

Epoch: 6| Step: 8
Training loss: 2.2137625217437744
Validation loss: 2.359290856187062

Epoch: 6| Step: 9
Training loss: 2.4954118728637695
Validation loss: 2.322638723158067

Epoch: 6| Step: 10
Training loss: 2.5554707050323486
Validation loss: 2.276452479823943

Epoch: 6| Step: 11
Training loss: 1.7439801692962646
Validation loss: 2.237177707815683

Epoch: 6| Step: 12
Training loss: 3.1133413314819336
Validation loss: 2.2193390169451312

Epoch: 6| Step: 13
Training loss: 2.77384090423584
Validation loss: 2.2162599384143786

Epoch: 133| Step: 0
Training loss: 2.2631824016571045
Validation loss: 2.203125153818438

Epoch: 6| Step: 1
Training loss: 2.819474935531616
Validation loss: 2.1903658220844884

Epoch: 6| Step: 2
Training loss: 1.3799396753311157
Validation loss: 2.1958000647124423

Epoch: 6| Step: 3
Training loss: 2.131333827972412
Validation loss: 2.2033003261012416

Epoch: 6| Step: 4
Training loss: 3.0189504623413086
Validation loss: 2.2146383177849556

Epoch: 6| Step: 5
Training loss: 2.1050281524658203
Validation loss: 2.247413222507764

Epoch: 6| Step: 6
Training loss: 2.683948040008545
Validation loss: 2.300696634477185

Epoch: 6| Step: 7
Training loss: 2.2902674674987793
Validation loss: 2.309238769674814

Epoch: 6| Step: 8
Training loss: 2.471404552459717
Validation loss: 2.341131737155299

Epoch: 6| Step: 9
Training loss: 2.7372090816497803
Validation loss: 2.3997172206960697

Epoch: 6| Step: 10
Training loss: 3.4607553482055664
Validation loss: 2.3378446922507337

Epoch: 6| Step: 11
Training loss: 2.6426970958709717
Validation loss: 2.3290738495447303

Epoch: 6| Step: 12
Training loss: 2.5468952655792236
Validation loss: 2.2664429449266

Epoch: 6| Step: 13
Training loss: 2.153629779815674
Validation loss: 2.2330423042338383

Epoch: 134| Step: 0
Training loss: 2.3013620376586914
Validation loss: 2.2436774417918217

Epoch: 6| Step: 1
Training loss: 3.214402198791504
Validation loss: 2.260233571452479

Epoch: 6| Step: 2
Training loss: 2.0832009315490723
Validation loss: 2.2767592912079184

Epoch: 6| Step: 3
Training loss: 3.055028200149536
Validation loss: 2.264705986104986

Epoch: 6| Step: 4
Training loss: 2.362734317779541
Validation loss: 2.253323870320474

Epoch: 6| Step: 5
Training loss: 2.5097081661224365
Validation loss: 2.2361052907923216

Epoch: 6| Step: 6
Training loss: 2.1713569164276123
Validation loss: 2.228508003296391

Epoch: 6| Step: 7
Training loss: 2.198516368865967
Validation loss: 2.2275292258108816

Epoch: 6| Step: 8
Training loss: 2.769463062286377
Validation loss: 2.234180809349142

Epoch: 6| Step: 9
Training loss: 2.593182325363159
Validation loss: 2.2292960125912904

Epoch: 6| Step: 10
Training loss: 2.5857224464416504
Validation loss: 2.27001779566529

Epoch: 6| Step: 11
Training loss: 2.2950234413146973
Validation loss: 2.323622606133902

Epoch: 6| Step: 12
Training loss: 2.1836235523223877
Validation loss: 2.3593403780332176

Epoch: 6| Step: 13
Training loss: 1.7746634483337402
Validation loss: 2.3594155362857285

Epoch: 135| Step: 0
Training loss: 2.845909357070923
Validation loss: 2.376886881807799

Epoch: 6| Step: 1
Training loss: 2.573549747467041
Validation loss: 2.3514820273204515

Epoch: 6| Step: 2
Training loss: 2.8935775756835938
Validation loss: 2.3291980681880826

Epoch: 6| Step: 3
Training loss: 1.4466745853424072
Validation loss: 2.284751048652075

Epoch: 6| Step: 4
Training loss: 3.2746217250823975
Validation loss: 2.274351691686979

Epoch: 6| Step: 5
Training loss: 1.9250810146331787
Validation loss: 2.264074397343461

Epoch: 6| Step: 6
Training loss: 2.692354202270508
Validation loss: 2.264103571573893

Epoch: 6| Step: 7
Training loss: 2.611158609390259
Validation loss: 2.2530428555703934

Epoch: 6| Step: 8
Training loss: 2.3825912475585938
Validation loss: 2.26296353596513

Epoch: 6| Step: 9
Training loss: 2.399995803833008
Validation loss: 2.2575207269319923

Epoch: 6| Step: 10
Training loss: 2.595834255218506
Validation loss: 2.2620359133648615

Epoch: 6| Step: 11
Training loss: 1.6516568660736084
Validation loss: 2.2787329176420807

Epoch: 6| Step: 12
Training loss: 2.825965404510498
Validation loss: 2.24841340895622

Epoch: 6| Step: 13
Training loss: 2.2714130878448486
Validation loss: 2.2401500286594516

Epoch: 136| Step: 0
Training loss: 2.644421100616455
Validation loss: 2.230609652816608

Epoch: 6| Step: 1
Training loss: 2.385500192642212
Validation loss: 2.2436199239505235

Epoch: 6| Step: 2
Training loss: 1.9952682256698608
Validation loss: 2.246113507978378

Epoch: 6| Step: 3
Training loss: 2.2642464637756348
Validation loss: 2.2555725036128873

Epoch: 6| Step: 4
Training loss: 2.484518051147461
Validation loss: 2.257670933200467

Epoch: 6| Step: 5
Training loss: 2.322237968444824
Validation loss: 2.276541156153525

Epoch: 6| Step: 6
Training loss: 2.973616123199463
Validation loss: 2.279113882331438

Epoch: 6| Step: 7
Training loss: 3.5938196182250977
Validation loss: 2.2730655413801952

Epoch: 6| Step: 8
Training loss: 2.8814897537231445
Validation loss: 2.263722350520472

Epoch: 6| Step: 9
Training loss: 1.475023627281189
Validation loss: 2.253783138849402

Epoch: 6| Step: 10
Training loss: 2.2790987491607666
Validation loss: 2.251164374812957

Epoch: 6| Step: 11
Training loss: 2.654566764831543
Validation loss: 2.2427076473030993

Epoch: 6| Step: 12
Training loss: 1.803024411201477
Validation loss: 2.253068179212591

Epoch: 6| Step: 13
Training loss: 2.049949884414673
Validation loss: 2.2400086028601534

Epoch: 137| Step: 0
Training loss: 2.409080982208252
Validation loss: 2.2372033826766478

Epoch: 6| Step: 1
Training loss: 2.406083345413208
Validation loss: 2.2425757518378635

Epoch: 6| Step: 2
Training loss: 2.4922173023223877
Validation loss: 2.2213886373786518

Epoch: 6| Step: 3
Training loss: 2.9722156524658203
Validation loss: 2.286993903498496

Epoch: 6| Step: 4
Training loss: 2.2066831588745117
Validation loss: 2.3183984756469727

Epoch: 6| Step: 5
Training loss: 2.600686550140381
Validation loss: 2.3344135797151955

Epoch: 6| Step: 6
Training loss: 2.455156087875366
Validation loss: 2.3215281835166355

Epoch: 6| Step: 7
Training loss: 1.73940908908844
Validation loss: 2.295196403739273

Epoch: 6| Step: 8
Training loss: 2.325998544692993
Validation loss: 2.224748796032321

Epoch: 6| Step: 9
Training loss: 2.7920968532562256
Validation loss: 2.206608215967814

Epoch: 6| Step: 10
Training loss: 2.3067612648010254
Validation loss: 2.1952250311451573

Epoch: 6| Step: 11
Training loss: 2.8584396839141846
Validation loss: 2.1914108542985815

Epoch: 6| Step: 12
Training loss: 2.3341636657714844
Validation loss: 2.1938202816952943

Epoch: 6| Step: 13
Training loss: 2.466414451599121
Validation loss: 2.1999246638308287

Epoch: 138| Step: 0
Training loss: 2.5045652389526367
Validation loss: 2.215095140600717

Epoch: 6| Step: 1
Training loss: 2.454557418823242
Validation loss: 2.212056759865053

Epoch: 6| Step: 2
Training loss: 3.4358725547790527
Validation loss: 2.202673360865603

Epoch: 6| Step: 3
Training loss: 2.1400532722473145
Validation loss: 2.220858386767808

Epoch: 6| Step: 4
Training loss: 2.0993587970733643
Validation loss: 2.2285139201789774

Epoch: 6| Step: 5
Training loss: 2.246297836303711
Validation loss: 2.209664649860833

Epoch: 6| Step: 6
Training loss: 2.6528565883636475
Validation loss: 2.214668595662681

Epoch: 6| Step: 7
Training loss: 1.9664124250411987
Validation loss: 2.2187663765363794

Epoch: 6| Step: 8
Training loss: 2.8612489700317383
Validation loss: 2.2089568158631683

Epoch: 6| Step: 9
Training loss: 1.7827725410461426
Validation loss: 2.2419053328934537

Epoch: 6| Step: 10
Training loss: 2.1080586910247803
Validation loss: 2.2818244221389934

Epoch: 6| Step: 11
Training loss: 3.2744076251983643
Validation loss: 2.3253313341448383

Epoch: 6| Step: 12
Training loss: 1.9637672901153564
Validation loss: 2.3349519275849864

Epoch: 6| Step: 13
Training loss: 2.178391695022583
Validation loss: 2.319867136657879

Epoch: 139| Step: 0
Training loss: 1.6288573741912842
Validation loss: 2.3365457352771553

Epoch: 6| Step: 1
Training loss: 2.1179161071777344
Validation loss: 2.3115184178916355

Epoch: 6| Step: 2
Training loss: 2.719301462173462
Validation loss: 2.279734303874354

Epoch: 6| Step: 3
Training loss: 2.7593984603881836
Validation loss: 2.2560728878103276

Epoch: 6| Step: 4
Training loss: 2.175814151763916
Validation loss: 2.23347633628435

Epoch: 6| Step: 5
Training loss: 3.0449471473693848
Validation loss: 2.19773341250676

Epoch: 6| Step: 6
Training loss: 1.702932596206665
Validation loss: 2.208800567093716

Epoch: 6| Step: 7
Training loss: 2.136462688446045
Validation loss: 2.1923664128908547

Epoch: 6| Step: 8
Training loss: 2.6375222206115723
Validation loss: 2.1907232833164993

Epoch: 6| Step: 9
Training loss: 2.8831799030303955
Validation loss: 2.1923482418060303

Epoch: 6| Step: 10
Training loss: 1.908814549446106
Validation loss: 2.1818315136817192

Epoch: 6| Step: 11
Training loss: 2.7285103797912598
Validation loss: 2.1854550787197646

Epoch: 6| Step: 12
Training loss: 2.51766300201416
Validation loss: 2.1953045116957797

Epoch: 6| Step: 13
Training loss: 3.477119207382202
Validation loss: 2.201733443044847

Epoch: 140| Step: 0
Training loss: 2.1386876106262207
Validation loss: 2.2191251067705053

Epoch: 6| Step: 1
Training loss: 2.272716999053955
Validation loss: 2.2131477966103503

Epoch: 6| Step: 2
Training loss: 2.9703283309936523
Validation loss: 2.2087055995900142

Epoch: 6| Step: 3
Training loss: 1.6520910263061523
Validation loss: 2.2200030729334843

Epoch: 6| Step: 4
Training loss: 2.387634038925171
Validation loss: 2.2124129597858717

Epoch: 6| Step: 5
Training loss: 2.807220220565796
Validation loss: 2.2600597002172984

Epoch: 6| Step: 6
Training loss: 2.7321152687072754
Validation loss: 2.2339056204724055

Epoch: 6| Step: 7
Training loss: 2.1494803428649902
Validation loss: 2.266343157778504

Epoch: 6| Step: 8
Training loss: 2.9830541610717773
Validation loss: 2.270518466990481

Epoch: 6| Step: 9
Training loss: 2.6478464603424072
Validation loss: 2.2809128569018458

Epoch: 6| Step: 10
Training loss: 1.8780338764190674
Validation loss: 2.250594800518405

Epoch: 6| Step: 11
Training loss: 2.325124740600586
Validation loss: 2.2462900659089446

Epoch: 6| Step: 12
Training loss: 2.0785202980041504
Validation loss: 2.25728085220501

Epoch: 6| Step: 13
Training loss: 2.9118027687072754
Validation loss: 2.2510312423911145

Epoch: 141| Step: 0
Training loss: 1.7740107774734497
Validation loss: 2.2405974864959717

Epoch: 6| Step: 1
Training loss: 1.8799328804016113
Validation loss: 2.2490100219685543

Epoch: 6| Step: 2
Training loss: 2.2905712127685547
Validation loss: 2.2402655488701275

Epoch: 6| Step: 3
Training loss: 2.9737255573272705
Validation loss: 2.242773145757696

Epoch: 6| Step: 4
Training loss: 1.9155863523483276
Validation loss: 2.2082630177979827

Epoch: 6| Step: 5
Training loss: 3.2310726642608643
Validation loss: 2.2229674067548526

Epoch: 6| Step: 6
Training loss: 2.6464385986328125
Validation loss: 2.2234044510831117

Epoch: 6| Step: 7
Training loss: 1.911914348602295
Validation loss: 2.2156717161978445

Epoch: 6| Step: 8
Training loss: 2.5242111682891846
Validation loss: 2.212536432409799

Epoch: 6| Step: 9
Training loss: 2.866623640060425
Validation loss: 2.2249900756343717

Epoch: 6| Step: 10
Training loss: 2.778193235397339
Validation loss: 2.2382862055173485

Epoch: 6| Step: 11
Training loss: 2.107433795928955
Validation loss: 2.216499109422007

Epoch: 6| Step: 12
Training loss: 1.872636079788208
Validation loss: 2.2032467037118892

Epoch: 6| Step: 13
Training loss: 2.9898006916046143
Validation loss: 2.2239029715138097

Epoch: 142| Step: 0
Training loss: 2.2425081729888916
Validation loss: 2.237037589473109

Epoch: 6| Step: 1
Training loss: 1.8790028095245361
Validation loss: 2.2679390266377437

Epoch: 6| Step: 2
Training loss: 2.1206769943237305
Validation loss: 2.317722858921174

Epoch: 6| Step: 3
Training loss: 3.0331437587738037
Validation loss: 2.364124604450759

Epoch: 6| Step: 4
Training loss: 3.8090522289276123
Validation loss: 2.4509735158694688

Epoch: 6| Step: 5
Training loss: 2.2805328369140625
Validation loss: 2.510573151291058

Epoch: 6| Step: 6
Training loss: 2.518218755722046
Validation loss: 2.4610124377794165

Epoch: 6| Step: 7
Training loss: 2.8167030811309814
Validation loss: 2.4050673361747497

Epoch: 6| Step: 8
Training loss: 2.256443977355957
Validation loss: 2.296390784684048

Epoch: 6| Step: 9
Training loss: 2.465954303741455
Validation loss: 2.2149224153129

Epoch: 6| Step: 10
Training loss: 2.0731687545776367
Validation loss: 2.1875908400422786

Epoch: 6| Step: 11
Training loss: 2.1226348876953125
Validation loss: 2.19834989629766

Epoch: 6| Step: 12
Training loss: 2.041530132293701
Validation loss: 2.216791151672281

Epoch: 6| Step: 13
Training loss: 3.295097827911377
Validation loss: 2.273962213147071

Epoch: 143| Step: 0
Training loss: 3.2123818397521973
Validation loss: 2.3048941550716275

Epoch: 6| Step: 1
Training loss: 2.8638358116149902
Validation loss: 2.325375135226916

Epoch: 6| Step: 2
Training loss: 2.421372175216675
Validation loss: 2.295271542764479

Epoch: 6| Step: 3
Training loss: 2.53153657913208
Validation loss: 2.2390421552042805

Epoch: 6| Step: 4
Training loss: 2.37162446975708
Validation loss: 2.1959522898479173

Epoch: 6| Step: 5
Training loss: 1.7442479133605957
Validation loss: 2.178935138128137

Epoch: 6| Step: 6
Training loss: 1.9312596321105957
Validation loss: 2.1658305365552186

Epoch: 6| Step: 7
Training loss: 3.061617374420166
Validation loss: 2.1639258169358775

Epoch: 6| Step: 8
Training loss: 2.139852285385132
Validation loss: 2.1783630514657624

Epoch: 6| Step: 9
Training loss: 2.025930881500244
Validation loss: 2.2175207958426526

Epoch: 6| Step: 10
Training loss: 2.603018283843994
Validation loss: 2.2459611969609417

Epoch: 6| Step: 11
Training loss: 3.0923051834106445
Validation loss: 2.2503774230198195

Epoch: 6| Step: 12
Training loss: 2.8804855346679688
Validation loss: 2.2477845350901284

Epoch: 6| Step: 13
Training loss: 2.2563297748565674
Validation loss: 2.2421021487123225

Epoch: 144| Step: 0
Training loss: 2.187840223312378
Validation loss: 2.219173017368522

Epoch: 6| Step: 1
Training loss: 2.1363742351531982
Validation loss: 2.2028278304684545

Epoch: 6| Step: 2
Training loss: 2.3644723892211914
Validation loss: 2.189924681058494

Epoch: 6| Step: 3
Training loss: 2.4492990970611572
Validation loss: 2.192870432330716

Epoch: 6| Step: 4
Training loss: 1.8188245296478271
Validation loss: 2.204878232812369

Epoch: 6| Step: 5
Training loss: 1.6238667964935303
Validation loss: 2.216738183011291

Epoch: 6| Step: 6
Training loss: 3.3013384342193604
Validation loss: 2.2434513004877235

Epoch: 6| Step: 7
Training loss: 2.5509121417999268
Validation loss: 2.2390707744065153

Epoch: 6| Step: 8
Training loss: 2.4332926273345947
Validation loss: 2.2284995471277544

Epoch: 6| Step: 9
Training loss: 1.9181146621704102
Validation loss: 2.2396199549398115

Epoch: 6| Step: 10
Training loss: 2.7185540199279785
Validation loss: 2.2367232666220715

Epoch: 6| Step: 11
Training loss: 3.0536751747131348
Validation loss: 2.245123824765605

Epoch: 6| Step: 12
Training loss: 2.544543504714966
Validation loss: 2.2585309807972243

Epoch: 6| Step: 13
Training loss: 2.387327194213867
Validation loss: 2.2796259234028478

Epoch: 145| Step: 0
Training loss: 2.678187370300293
Validation loss: 2.334318563502322

Epoch: 6| Step: 1
Training loss: 2.113743782043457
Validation loss: 2.318574264485349

Epoch: 6| Step: 2
Training loss: 2.478921413421631
Validation loss: 2.292907773807485

Epoch: 6| Step: 3
Training loss: 2.1187310218811035
Validation loss: 2.2560323079427085

Epoch: 6| Step: 4
Training loss: 2.2134130001068115
Validation loss: 2.216116505284463

Epoch: 6| Step: 5
Training loss: 2.56465482711792
Validation loss: 2.2116771769779984

Epoch: 6| Step: 6
Training loss: 2.699803590774536
Validation loss: 2.194915360020053

Epoch: 6| Step: 7
Training loss: 2.576749324798584
Validation loss: 2.1828766022959063

Epoch: 6| Step: 8
Training loss: 2.503472328186035
Validation loss: 2.187839347829101

Epoch: 6| Step: 9
Training loss: 2.2561020851135254
Validation loss: 2.184742025149766

Epoch: 6| Step: 10
Training loss: 2.3921141624450684
Validation loss: 2.1826745310137348

Epoch: 6| Step: 11
Training loss: 2.1856632232666016
Validation loss: 2.1945141464151363

Epoch: 6| Step: 12
Training loss: 2.611130475997925
Validation loss: 2.197911713712959

Epoch: 6| Step: 13
Training loss: 2.991546630859375
Validation loss: 2.1956480741500854

Epoch: 146| Step: 0
Training loss: 2.0352206230163574
Validation loss: 2.2098311173018588

Epoch: 6| Step: 1
Training loss: 2.801974058151245
Validation loss: 2.233048815881052

Epoch: 6| Step: 2
Training loss: 2.6195247173309326
Validation loss: 2.2603966523242254

Epoch: 6| Step: 3
Training loss: 2.141012191772461
Validation loss: 2.24521348040591

Epoch: 6| Step: 4
Training loss: 2.7075369358062744
Validation loss: 2.259181063662293

Epoch: 6| Step: 5
Training loss: 2.784971237182617
Validation loss: 2.2429280806613225

Epoch: 6| Step: 6
Training loss: 2.364741325378418
Validation loss: 2.256444195265411

Epoch: 6| Step: 7
Training loss: 1.804527759552002
Validation loss: 2.2773706066992974

Epoch: 6| Step: 8
Training loss: 2.756690263748169
Validation loss: 2.261853900007022

Epoch: 6| Step: 9
Training loss: 2.5013816356658936
Validation loss: 2.2670960836513068

Epoch: 6| Step: 10
Training loss: 2.012877941131592
Validation loss: 2.223241111283661

Epoch: 6| Step: 11
Training loss: 2.364304780960083
Validation loss: 2.220921706127864

Epoch: 6| Step: 12
Training loss: 2.145683765411377
Validation loss: 2.2097078113145727

Epoch: 6| Step: 13
Training loss: 2.4058167934417725
Validation loss: 2.1894013010045534

Epoch: 147| Step: 0
Training loss: 1.972004771232605
Validation loss: 2.19457184883856

Epoch: 6| Step: 1
Training loss: 2.8210983276367188
Validation loss: 2.2076197260169574

Epoch: 6| Step: 2
Training loss: 2.557555675506592
Validation loss: 2.2145096153341313

Epoch: 6| Step: 3
Training loss: 2.250364065170288
Validation loss: 2.264047271461897

Epoch: 6| Step: 4
Training loss: 2.15217924118042
Validation loss: 2.280197035881781

Epoch: 6| Step: 5
Training loss: 2.2444825172424316
Validation loss: 2.230732553748674

Epoch: 6| Step: 6
Training loss: 2.267822742462158
Validation loss: 2.219984767257526

Epoch: 6| Step: 7
Training loss: 2.0304105281829834
Validation loss: 2.2311817215334986

Epoch: 6| Step: 8
Training loss: 2.538987874984741
Validation loss: 2.202428494730303

Epoch: 6| Step: 9
Training loss: 3.3260622024536133
Validation loss: 2.1919812412672144

Epoch: 6| Step: 10
Training loss: 2.4372944831848145
Validation loss: 2.182165595792955

Epoch: 6| Step: 11
Training loss: 2.5539960861206055
Validation loss: 2.188868599553262

Epoch: 6| Step: 12
Training loss: 2.1623711585998535
Validation loss: 2.188048679341552

Epoch: 6| Step: 13
Training loss: 1.9201223850250244
Validation loss: 2.2080102018130723

Epoch: 148| Step: 0
Training loss: 3.082381010055542
Validation loss: 2.1769166223464476

Epoch: 6| Step: 1
Training loss: 2.8132874965667725
Validation loss: 2.1741010501820552

Epoch: 6| Step: 2
Training loss: 2.570964813232422
Validation loss: 2.187820639661563

Epoch: 6| Step: 3
Training loss: 2.580436944961548
Validation loss: 2.1805888093927854

Epoch: 6| Step: 4
Training loss: 1.506786823272705
Validation loss: 2.193518230991979

Epoch: 6| Step: 5
Training loss: 2.4266695976257324
Validation loss: 2.2013940888066448

Epoch: 6| Step: 6
Training loss: 1.7190134525299072
Validation loss: 2.2391933625744236

Epoch: 6| Step: 7
Training loss: 1.9166247844696045
Validation loss: 2.266816544276412

Epoch: 6| Step: 8
Training loss: 2.63569974899292
Validation loss: 2.242316484451294

Epoch: 6| Step: 9
Training loss: 1.7055449485778809
Validation loss: 2.23376952960927

Epoch: 6| Step: 10
Training loss: 2.285755157470703
Validation loss: 2.2049289364968576

Epoch: 6| Step: 11
Training loss: 2.944761276245117
Validation loss: 2.182398478190104

Epoch: 6| Step: 12
Training loss: 2.5533080101013184
Validation loss: 2.1887653002174954

Epoch: 6| Step: 13
Training loss: 2.3028576374053955
Validation loss: 2.153343362192954

Epoch: 149| Step: 0
Training loss: 2.527958393096924
Validation loss: 2.170934651487617

Epoch: 6| Step: 1
Training loss: 2.1931090354919434
Validation loss: 2.181377859525783

Epoch: 6| Step: 2
Training loss: 2.2216835021972656
Validation loss: 2.1832787375296316

Epoch: 6| Step: 3
Training loss: 2.4492931365966797
Validation loss: 2.197500982592183

Epoch: 6| Step: 4
Training loss: 2.803633689880371
Validation loss: 2.220745268688407

Epoch: 6| Step: 5
Training loss: 2.388131618499756
Validation loss: 2.22283015712615

Epoch: 6| Step: 6
Training loss: 2.0293891429901123
Validation loss: 2.2131217166941655

Epoch: 6| Step: 7
Training loss: 2.248737096786499
Validation loss: 2.229255578851187

Epoch: 6| Step: 8
Training loss: 2.307219982147217
Validation loss: 2.239190588715256

Epoch: 6| Step: 9
Training loss: 2.1482505798339844
Validation loss: 2.288928290849091

Epoch: 6| Step: 10
Training loss: 2.1184937953948975
Validation loss: 2.2677532806191394

Epoch: 6| Step: 11
Training loss: 2.621154308319092
Validation loss: 2.241021305002192

Epoch: 6| Step: 12
Training loss: 2.925325870513916
Validation loss: 2.1997601216839207

Epoch: 6| Step: 13
Training loss: 2.625947952270508
Validation loss: 2.181402219239102

Epoch: 150| Step: 0
Training loss: 2.9951071739196777
Validation loss: 2.1940898356899137

Epoch: 6| Step: 1
Training loss: 1.826766014099121
Validation loss: 2.162579813311177

Epoch: 6| Step: 2
Training loss: 2.3741202354431152
Validation loss: 2.17766470806573

Epoch: 6| Step: 3
Training loss: 2.0092475414276123
Validation loss: 2.158235457635695

Epoch: 6| Step: 4
Training loss: 2.534440279006958
Validation loss: 2.1594591243292696

Epoch: 6| Step: 5
Training loss: 2.6059069633483887
Validation loss: 2.1524204566914547

Epoch: 6| Step: 6
Training loss: 2.609924793243408
Validation loss: 2.172624408557851

Epoch: 6| Step: 7
Training loss: 2.2018165588378906
Validation loss: 2.143018468733757

Epoch: 6| Step: 8
Training loss: 2.484041452407837
Validation loss: 2.134188526420183

Epoch: 6| Step: 9
Training loss: 1.895153284072876
Validation loss: 2.156276551626062

Epoch: 6| Step: 10
Training loss: 2.340333938598633
Validation loss: 2.1745351540145053

Epoch: 6| Step: 11
Training loss: 2.285001277923584
Validation loss: 2.1716398654445523

Epoch: 6| Step: 12
Training loss: 2.8184585571289062
Validation loss: 2.2073502002223844

Epoch: 6| Step: 13
Training loss: 2.592745542526245
Validation loss: 2.2199790247025026

Epoch: 151| Step: 0
Training loss: 3.3906829357147217
Validation loss: 2.2194946299317064

Epoch: 6| Step: 1
Training loss: 2.8748440742492676
Validation loss: 2.261776581887276

Epoch: 6| Step: 2
Training loss: 2.3636832237243652
Validation loss: 2.2948436980606406

Epoch: 6| Step: 3
Training loss: 2.3339896202087402
Validation loss: 2.2849076345402706

Epoch: 6| Step: 4
Training loss: 2.684246063232422
Validation loss: 2.271737167912145

Epoch: 6| Step: 5
Training loss: 2.1018989086151123
Validation loss: 2.2515277965094453

Epoch: 6| Step: 6
Training loss: 1.7152962684631348
Validation loss: 2.2426392442436627

Epoch: 6| Step: 7
Training loss: 2.2800660133361816
Validation loss: 2.2371843245721634

Epoch: 6| Step: 8
Training loss: 1.2479207515716553
Validation loss: 2.2407011819142166

Epoch: 6| Step: 9
Training loss: 2.1108922958374023
Validation loss: 2.2412795456506873

Epoch: 6| Step: 10
Training loss: 3.14219069480896
Validation loss: 2.2299187978108725

Epoch: 6| Step: 11
Training loss: 2.834050416946411
Validation loss: 2.207188472952894

Epoch: 6| Step: 12
Training loss: 2.0996527671813965
Validation loss: 2.1967446855319444

Epoch: 6| Step: 13
Training loss: 1.5795629024505615
Validation loss: 2.148495279332643

Epoch: 152| Step: 0
Training loss: 2.232357978820801
Validation loss: 2.134925606430218

Epoch: 6| Step: 1
Training loss: 2.3375563621520996
Validation loss: 2.1261662206342145

Epoch: 6| Step: 2
Training loss: 2.0442991256713867
Validation loss: 2.1300813741581415

Epoch: 6| Step: 3
Training loss: 2.0835859775543213
Validation loss: 2.13342640220478

Epoch: 6| Step: 4
Training loss: 2.0583741664886475
Validation loss: 2.1451640923817954

Epoch: 6| Step: 5
Training loss: 2.435553789138794
Validation loss: 2.1694024250071537

Epoch: 6| Step: 6
Training loss: 2.8399181365966797
Validation loss: 2.1492218253433064

Epoch: 6| Step: 7
Training loss: 1.9239680767059326
Validation loss: 2.1349919457589426

Epoch: 6| Step: 8
Training loss: 2.4051592350006104
Validation loss: 2.122516780771235

Epoch: 6| Step: 9
Training loss: 3.007042407989502
Validation loss: 2.13068070719319

Epoch: 6| Step: 10
Training loss: 2.6676578521728516
Validation loss: 2.1204195791675198

Epoch: 6| Step: 11
Training loss: 2.934783458709717
Validation loss: 2.1404776675726778

Epoch: 6| Step: 12
Training loss: 2.593635082244873
Validation loss: 2.143350257668444

Epoch: 6| Step: 13
Training loss: 1.6210988759994507
Validation loss: 2.1849450834335817

Epoch: 153| Step: 0
Training loss: 2.2188785076141357
Validation loss: 2.17420373424407

Epoch: 6| Step: 1
Training loss: 2.3112998008728027
Validation loss: 2.2118639253800914

Epoch: 6| Step: 2
Training loss: 2.3914551734924316
Validation loss: 2.2159226530341694

Epoch: 6| Step: 3
Training loss: 2.7698397636413574
Validation loss: 2.2227646791806785

Epoch: 6| Step: 4
Training loss: 2.4912216663360596
Validation loss: 2.21115558121794

Epoch: 6| Step: 5
Training loss: 2.144505500793457
Validation loss: 2.1952013059328963

Epoch: 6| Step: 6
Training loss: 2.8086178302764893
Validation loss: 2.212317095007948

Epoch: 6| Step: 7
Training loss: 2.3227744102478027
Validation loss: 2.218009679548202

Epoch: 6| Step: 8
Training loss: 2.3169238567352295
Validation loss: 2.2334360358535603

Epoch: 6| Step: 9
Training loss: 2.348057746887207
Validation loss: 2.2272252728862147

Epoch: 6| Step: 10
Training loss: 2.1338257789611816
Validation loss: 2.2120201485131377

Epoch: 6| Step: 11
Training loss: 2.0863354206085205
Validation loss: 2.208746776785902

Epoch: 6| Step: 12
Training loss: 1.9974181652069092
Validation loss: 2.1943815805578746

Epoch: 6| Step: 13
Training loss: 3.0590295791625977
Validation loss: 2.225133729237382

Epoch: 154| Step: 0
Training loss: 1.9412481784820557
Validation loss: 2.1897982243568666

Epoch: 6| Step: 1
Training loss: 2.378068447113037
Validation loss: 2.173769361229353

Epoch: 6| Step: 2
Training loss: 2.3679261207580566
Validation loss: 2.1770099388655795

Epoch: 6| Step: 3
Training loss: 1.7386833429336548
Validation loss: 2.161035627447149

Epoch: 6| Step: 4
Training loss: 2.7963619232177734
Validation loss: 2.148777425930064

Epoch: 6| Step: 5
Training loss: 3.040931224822998
Validation loss: 2.155126005090693

Epoch: 6| Step: 6
Training loss: 2.3569929599761963
Validation loss: 2.1431284002078477

Epoch: 6| Step: 7
Training loss: 2.1073689460754395
Validation loss: 2.1487189697962936

Epoch: 6| Step: 8
Training loss: 2.422804355621338
Validation loss: 2.1378802714809293

Epoch: 6| Step: 9
Training loss: 2.3317394256591797
Validation loss: 2.1419071971729235

Epoch: 6| Step: 10
Training loss: 2.4703540802001953
Validation loss: 2.150024676835665

Epoch: 6| Step: 11
Training loss: 2.390420436859131
Validation loss: 2.1820925128075386

Epoch: 6| Step: 12
Training loss: 2.3502278327941895
Validation loss: 2.1786197052207044

Epoch: 6| Step: 13
Training loss: 2.0837490558624268
Validation loss: 2.22326575556109

Epoch: 155| Step: 0
Training loss: 2.5916848182678223
Validation loss: 2.238321056929968

Epoch: 6| Step: 1
Training loss: 2.8055882453918457
Validation loss: 2.2088774583672963

Epoch: 6| Step: 2
Training loss: 2.349693536758423
Validation loss: 2.2223099662411596

Epoch: 6| Step: 3
Training loss: 2.340407371520996
Validation loss: 2.2176945055684736

Epoch: 6| Step: 4
Training loss: 2.3153250217437744
Validation loss: 2.1848917904720513

Epoch: 6| Step: 5
Training loss: 2.0275940895080566
Validation loss: 2.1694462376256145

Epoch: 6| Step: 6
Training loss: 3.009031295776367
Validation loss: 2.1757768713017946

Epoch: 6| Step: 7
Training loss: 2.2859182357788086
Validation loss: 2.152834362881158

Epoch: 6| Step: 8
Training loss: 2.7161426544189453
Validation loss: 2.161031369240053

Epoch: 6| Step: 9
Training loss: 2.224733591079712
Validation loss: 2.172132679211196

Epoch: 6| Step: 10
Training loss: 1.6014704704284668
Validation loss: 2.181539294540241

Epoch: 6| Step: 11
Training loss: 2.19107985496521
Validation loss: 2.2094399339409283

Epoch: 6| Step: 12
Training loss: 2.2282891273498535
Validation loss: 2.2064368724823

Epoch: 6| Step: 13
Training loss: 2.0635125637054443
Validation loss: 2.1743551633691274

Epoch: 156| Step: 0
Training loss: 1.8583717346191406
Validation loss: 2.1758012925424883

Epoch: 6| Step: 1
Training loss: 2.7880501747131348
Validation loss: 2.1905080477396646

Epoch: 6| Step: 2
Training loss: 1.6877834796905518
Validation loss: 2.177362270252679

Epoch: 6| Step: 3
Training loss: 2.401264190673828
Validation loss: 2.1845523157427387

Epoch: 6| Step: 4
Training loss: 2.4158482551574707
Validation loss: 2.1698466500928326

Epoch: 6| Step: 5
Training loss: 2.615196704864502
Validation loss: 2.205037240059145

Epoch: 6| Step: 6
Training loss: 3.2588720321655273
Validation loss: 2.187608011307255

Epoch: 6| Step: 7
Training loss: 2.380664825439453
Validation loss: 2.158013184865316

Epoch: 6| Step: 8
Training loss: 2.1569647789001465
Validation loss: 2.1435505010748424

Epoch: 6| Step: 9
Training loss: 2.3776304721832275
Validation loss: 2.133945404842336

Epoch: 6| Step: 10
Training loss: 2.0172572135925293
Validation loss: 2.131761613712516

Epoch: 6| Step: 11
Training loss: 2.3188769817352295
Validation loss: 2.0907076366486086

Epoch: 6| Step: 12
Training loss: 2.0379586219787598
Validation loss: 2.1017887387224423

Epoch: 6| Step: 13
Training loss: 2.059628486633301
Validation loss: 2.1138146667070288

Epoch: 157| Step: 0
Training loss: 2.445448398590088
Validation loss: 2.1312662145142913

Epoch: 6| Step: 1
Training loss: 2.110417366027832
Validation loss: 2.1368398102380897

Epoch: 6| Step: 2
Training loss: 2.383465528488159
Validation loss: 2.1737324268587175

Epoch: 6| Step: 3
Training loss: 1.845991611480713
Validation loss: 2.1596156256173247

Epoch: 6| Step: 4
Training loss: 2.1892683506011963
Validation loss: 2.1908249470495407

Epoch: 6| Step: 5
Training loss: 3.022296905517578
Validation loss: 2.211590789979504

Epoch: 6| Step: 6
Training loss: 2.133382558822632
Validation loss: 2.2416198279268

Epoch: 6| Step: 7
Training loss: 2.175739288330078
Validation loss: 2.239309339113133

Epoch: 6| Step: 8
Training loss: 2.2125744819641113
Validation loss: 2.209705352783203

Epoch: 6| Step: 9
Training loss: 2.190739631652832
Validation loss: 2.1923925684344385

Epoch: 6| Step: 10
Training loss: 2.7838664054870605
Validation loss: 2.1918731133143106

Epoch: 6| Step: 11
Training loss: 2.9061880111694336
Validation loss: 2.1941358261210944

Epoch: 6| Step: 12
Training loss: 2.286770820617676
Validation loss: 2.1817265274704143

Epoch: 6| Step: 13
Training loss: 2.3616762161254883
Validation loss: 2.1614030074047785

Epoch: 158| Step: 0
Training loss: 2.393878698348999
Validation loss: 2.15114249208922

Epoch: 6| Step: 1
Training loss: 1.8993546962738037
Validation loss: 2.1393592101271435

Epoch: 6| Step: 2
Training loss: 2.625692844390869
Validation loss: 2.1151308731366227

Epoch: 6| Step: 3
Training loss: 1.2868280410766602
Validation loss: 2.1045639873832784

Epoch: 6| Step: 4
Training loss: 2.836228370666504
Validation loss: 2.1094954013824463

Epoch: 6| Step: 5
Training loss: 2.6501402854919434
Validation loss: 2.116761512653802

Epoch: 6| Step: 6
Training loss: 2.553128242492676
Validation loss: 2.1343811993957846

Epoch: 6| Step: 7
Training loss: 2.867400646209717
Validation loss: 2.1239229838053384

Epoch: 6| Step: 8
Training loss: 2.0223140716552734
Validation loss: 2.153771823452365

Epoch: 6| Step: 9
Training loss: 1.6630444526672363
Validation loss: 2.163769701475738

Epoch: 6| Step: 10
Training loss: 2.7817723751068115
Validation loss: 2.153742787658527

Epoch: 6| Step: 11
Training loss: 2.793351650238037
Validation loss: 2.179132483338797

Epoch: 6| Step: 12
Training loss: 1.9822431802749634
Validation loss: 2.189008761477727

Epoch: 6| Step: 13
Training loss: 2.534907817840576
Validation loss: 2.1950019405734156

Epoch: 159| Step: 0
Training loss: 2.584583044052124
Validation loss: 2.188536737554817

Epoch: 6| Step: 1
Training loss: 2.169823169708252
Validation loss: 2.173884581494075

Epoch: 6| Step: 2
Training loss: 2.2473039627075195
Validation loss: 2.1678702113448933

Epoch: 6| Step: 3
Training loss: 1.6704542636871338
Validation loss: 2.1594484672751477

Epoch: 6| Step: 4
Training loss: 2.6255922317504883
Validation loss: 2.148270067348275

Epoch: 6| Step: 5
Training loss: 1.6167378425598145
Validation loss: 2.1382944109619304

Epoch: 6| Step: 6
Training loss: 3.067234992980957
Validation loss: 2.143868646314067

Epoch: 6| Step: 7
Training loss: 2.266221046447754
Validation loss: 2.138054847717285

Epoch: 6| Step: 8
Training loss: 2.6601600646972656
Validation loss: 2.1248666240322973

Epoch: 6| Step: 9
Training loss: 1.7702624797821045
Validation loss: 2.136221857481105

Epoch: 6| Step: 10
Training loss: 1.7667938470840454
Validation loss: 2.1345059692218737

Epoch: 6| Step: 11
Training loss: 2.5723953247070312
Validation loss: 2.1293750783448577

Epoch: 6| Step: 12
Training loss: 3.0250625610351562
Validation loss: 2.143043070711115

Epoch: 6| Step: 13
Training loss: 2.462008237838745
Validation loss: 2.129813721103053

Epoch: 160| Step: 0
Training loss: 2.358280658721924
Validation loss: 2.1463576760343326

Epoch: 6| Step: 1
Training loss: 3.1343441009521484
Validation loss: 2.1726615121287685

Epoch: 6| Step: 2
Training loss: 1.5385454893112183
Validation loss: 2.211082740496564

Epoch: 6| Step: 3
Training loss: 1.8383196592330933
Validation loss: 2.233442157827398

Epoch: 6| Step: 4
Training loss: 2.816265821456909
Validation loss: 2.2027768447834957

Epoch: 6| Step: 5
Training loss: 2.1851511001586914
Validation loss: 2.148116703956358

Epoch: 6| Step: 6
Training loss: 2.687436103820801
Validation loss: 2.142697416326051

Epoch: 6| Step: 7
Training loss: 2.7008495330810547
Validation loss: 2.1440543795144684

Epoch: 6| Step: 8
Training loss: 2.4191417694091797
Validation loss: 2.119888808137627

Epoch: 6| Step: 9
Training loss: 2.04349422454834
Validation loss: 2.114654948634486

Epoch: 6| Step: 10
Training loss: 1.8816146850585938
Validation loss: 2.1076565122091644

Epoch: 6| Step: 11
Training loss: 2.1401596069335938
Validation loss: 2.1233722163784887

Epoch: 6| Step: 12
Training loss: 2.276223659515381
Validation loss: 2.1172918991375993

Epoch: 6| Step: 13
Training loss: 2.2470180988311768
Validation loss: 2.1581393980210826

Epoch: 161| Step: 0
Training loss: 1.772152304649353
Validation loss: 2.1898196256288918

Epoch: 6| Step: 1
Training loss: 2.421172618865967
Validation loss: 2.2064863892011743

Epoch: 6| Step: 2
Training loss: 2.3857216835021973
Validation loss: 2.2486321362116004

Epoch: 6| Step: 3
Training loss: 2.7330076694488525
Validation loss: 2.297660404636014

Epoch: 6| Step: 4
Training loss: 1.842184066772461
Validation loss: 2.3013426514082056

Epoch: 6| Step: 5
Training loss: 2.708458423614502
Validation loss: 2.250703551435983

Epoch: 6| Step: 6
Training loss: 2.365630626678467
Validation loss: 2.2124645069081295

Epoch: 6| Step: 7
Training loss: 2.9998114109039307
Validation loss: 2.1515906959451656

Epoch: 6| Step: 8
Training loss: 1.8924212455749512
Validation loss: 2.1272394105952275

Epoch: 6| Step: 9
Training loss: 1.892867088317871
Validation loss: 2.1195916411697224

Epoch: 6| Step: 10
Training loss: 2.8196375370025635
Validation loss: 2.1031887044188795

Epoch: 6| Step: 11
Training loss: 2.342277765274048
Validation loss: 2.0846051323798394

Epoch: 6| Step: 12
Training loss: 2.3234527111053467
Validation loss: 2.0822117661917083

Epoch: 6| Step: 13
Training loss: 1.6603124141693115
Validation loss: 2.0715464520198044

Epoch: 162| Step: 0
Training loss: 2.398615598678589
Validation loss: 2.0930502068611885

Epoch: 6| Step: 1
Training loss: 2.335453987121582
Validation loss: 2.09592677188176

Epoch: 6| Step: 2
Training loss: 1.9991581439971924
Validation loss: 2.104991920532719

Epoch: 6| Step: 3
Training loss: 2.9520444869995117
Validation loss: 2.1208129057320217

Epoch: 6| Step: 4
Training loss: 1.9592071771621704
Validation loss: 2.1261557584167807

Epoch: 6| Step: 5
Training loss: 2.4409186840057373
Validation loss: 2.111873319072108

Epoch: 6| Step: 6
Training loss: 2.5369362831115723
Validation loss: 2.125617132391981

Epoch: 6| Step: 7
Training loss: 1.9467401504516602
Validation loss: 2.114824587298978

Epoch: 6| Step: 8
Training loss: 1.7584943771362305
Validation loss: 2.1159015368389826

Epoch: 6| Step: 9
Training loss: 2.596194267272949
Validation loss: 2.1308864342269076

Epoch: 6| Step: 10
Training loss: 2.8314743041992188
Validation loss: 2.1770013737422165

Epoch: 6| Step: 11
Training loss: 2.532777786254883
Validation loss: 2.174719948922434

Epoch: 6| Step: 12
Training loss: 2.247058391571045
Validation loss: 2.205092239123519

Epoch: 6| Step: 13
Training loss: 1.938344120979309
Validation loss: 2.200609613490361

Epoch: 163| Step: 0
Training loss: 2.2780425548553467
Validation loss: 2.2085321564828195

Epoch: 6| Step: 1
Training loss: 2.8104100227355957
Validation loss: 2.2093005693087013

Epoch: 6| Step: 2
Training loss: 2.35661244392395
Validation loss: 2.2007173338244037

Epoch: 6| Step: 3
Training loss: 1.8536196947097778
Validation loss: 2.2743449890485374

Epoch: 6| Step: 4
Training loss: 1.6471525430679321
Validation loss: 2.361386396551645

Epoch: 6| Step: 5
Training loss: 3.162320852279663
Validation loss: 2.320156389667142

Epoch: 6| Step: 6
Training loss: 2.0573253631591797
Validation loss: 2.2526562649716615

Epoch: 6| Step: 7
Training loss: 2.1872408390045166
Validation loss: 2.203560103652298

Epoch: 6| Step: 8
Training loss: 2.398620128631592
Validation loss: 2.10000668802569

Epoch: 6| Step: 9
Training loss: 2.2026424407958984
Validation loss: 2.100089583345639

Epoch: 6| Step: 10
Training loss: 2.3812255859375
Validation loss: 2.082478247663026

Epoch: 6| Step: 11
Training loss: 1.9285556077957153
Validation loss: 2.0730437027510775

Epoch: 6| Step: 12
Training loss: 2.445338726043701
Validation loss: 2.063293049412389

Epoch: 6| Step: 13
Training loss: 3.542973518371582
Validation loss: 2.0517259643923853

Epoch: 164| Step: 0
Training loss: 2.4457905292510986
Validation loss: 2.038011779067337

Epoch: 6| Step: 1
Training loss: 2.9724085330963135
Validation loss: 2.0457140040654007

Epoch: 6| Step: 2
Training loss: 2.616528034210205
Validation loss: 2.042322531823189

Epoch: 6| Step: 3
Training loss: 2.1272802352905273
Validation loss: 2.0389778332043718

Epoch: 6| Step: 4
Training loss: 2.3952112197875977
Validation loss: 2.0347031649722847

Epoch: 6| Step: 5
Training loss: 2.278977394104004
Validation loss: 2.0445676337006273

Epoch: 6| Step: 6
Training loss: 2.202303409576416
Validation loss: 2.061685217324124

Epoch: 6| Step: 7
Training loss: 2.279709815979004
Validation loss: 2.0530745047394947

Epoch: 6| Step: 8
Training loss: 2.3701462745666504
Validation loss: 2.0704580276243147

Epoch: 6| Step: 9
Training loss: 2.118882894515991
Validation loss: 2.070033477198693

Epoch: 6| Step: 10
Training loss: 1.5809605121612549
Validation loss: 2.0818981534691265

Epoch: 6| Step: 11
Training loss: 2.2203917503356934
Validation loss: 2.0836760920862996

Epoch: 6| Step: 12
Training loss: 2.614215850830078
Validation loss: 2.1256567970398934

Epoch: 6| Step: 13
Training loss: 2.8716044425964355
Validation loss: 2.152020349297472

Epoch: 165| Step: 0
Training loss: 2.5621986389160156
Validation loss: 2.1881377876445813

Epoch: 6| Step: 1
Training loss: 2.381646156311035
Validation loss: 2.2144073132545716

Epoch: 6| Step: 2
Training loss: 3.0490479469299316
Validation loss: 2.250646339949741

Epoch: 6| Step: 3
Training loss: 2.797940254211426
Validation loss: 2.2754500758263374

Epoch: 6| Step: 4
Training loss: 2.130232572555542
Validation loss: 2.2319662929863058

Epoch: 6| Step: 5
Training loss: 2.2719929218292236
Validation loss: 2.259289236478908

Epoch: 6| Step: 6
Training loss: 2.250856399536133
Validation loss: 2.1983090011022424

Epoch: 6| Step: 7
Training loss: 2.0801916122436523
Validation loss: 2.201124123347703

Epoch: 6| Step: 8
Training loss: 1.6560461521148682
Validation loss: 2.2389911990011893

Epoch: 6| Step: 9
Training loss: 2.2962350845336914
Validation loss: 2.2111481158964095

Epoch: 6| Step: 10
Training loss: 2.4217872619628906
Validation loss: 2.184788809027723

Epoch: 6| Step: 11
Training loss: 2.2876944541931152
Validation loss: 2.1401036529130835

Epoch: 6| Step: 12
Training loss: 2.266845226287842
Validation loss: 2.133870037653113

Epoch: 6| Step: 13
Training loss: 2.023984909057617
Validation loss: 2.099456984509704

Epoch: 166| Step: 0
Training loss: 1.9959813356399536
Validation loss: 2.106362376161801

Epoch: 6| Step: 1
Training loss: 2.2627663612365723
Validation loss: 2.1162674119395595

Epoch: 6| Step: 2
Training loss: 2.077641725540161
Validation loss: 2.141183614730835

Epoch: 6| Step: 3
Training loss: 2.533233880996704
Validation loss: 2.118583451035202

Epoch: 6| Step: 4
Training loss: 2.863171339035034
Validation loss: 2.0807361410510157

Epoch: 6| Step: 5
Training loss: 1.8649466037750244
Validation loss: 2.0732054684751775

Epoch: 6| Step: 6
Training loss: 2.5376696586608887
Validation loss: 2.0805987081220074

Epoch: 6| Step: 7
Training loss: 2.3773233890533447
Validation loss: 2.105872247808723

Epoch: 6| Step: 8
Training loss: 2.594383716583252
Validation loss: 2.146919460706813

Epoch: 6| Step: 9
Training loss: 2.5114216804504395
Validation loss: 2.1784578420782603

Epoch: 6| Step: 10
Training loss: 1.8644742965698242
Validation loss: 2.1970858779004825

Epoch: 6| Step: 11
Training loss: 2.696406364440918
Validation loss: 2.2444271502956266

Epoch: 6| Step: 12
Training loss: 2.297436475753784
Validation loss: 2.180546381140268

Epoch: 6| Step: 13
Training loss: 1.9508024454116821
Validation loss: 2.1838328299983853

Epoch: 167| Step: 0
Training loss: 2.063359022140503
Validation loss: 2.142712567442207

Epoch: 6| Step: 1
Training loss: 2.3117318153381348
Validation loss: 2.1530798199356243

Epoch: 6| Step: 2
Training loss: 2.8112196922302246
Validation loss: 2.1109734299362346

Epoch: 6| Step: 3
Training loss: 2.2315726280212402
Validation loss: 2.102509001249908

Epoch: 6| Step: 4
Training loss: 2.1917788982391357
Validation loss: 2.085590902195182

Epoch: 6| Step: 5
Training loss: 2.4841506481170654
Validation loss: 2.0932212952644593

Epoch: 6| Step: 6
Training loss: 1.6743261814117432
Validation loss: 2.092531652860744

Epoch: 6| Step: 7
Training loss: 2.293529987335205
Validation loss: 2.098739893205704

Epoch: 6| Step: 8
Training loss: 2.1908533573150635
Validation loss: 2.1109322706858316

Epoch: 6| Step: 9
Training loss: 2.8481593132019043
Validation loss: 2.1211232011036207

Epoch: 6| Step: 10
Training loss: 2.0436062812805176
Validation loss: 2.1209725244070894

Epoch: 6| Step: 11
Training loss: 2.3049700260162354
Validation loss: 2.0892281481014785

Epoch: 6| Step: 12
Training loss: 2.1214654445648193
Validation loss: 2.1016189949486845

Epoch: 6| Step: 13
Training loss: 2.791717290878296
Validation loss: 2.0813201422332437

Epoch: 168| Step: 0
Training loss: 1.5087063312530518
Validation loss: 2.0954926475401847

Epoch: 6| Step: 1
Training loss: 2.0103564262390137
Validation loss: 2.091379301522368

Epoch: 6| Step: 2
Training loss: 2.938314914703369
Validation loss: 2.1593629352508055

Epoch: 6| Step: 3
Training loss: 2.1860623359680176
Validation loss: 2.188206511159097

Epoch: 6| Step: 4
Training loss: 1.962094783782959
Validation loss: 2.1738136147940033

Epoch: 6| Step: 5
Training loss: 1.9194285869598389
Validation loss: 2.1789114282977198

Epoch: 6| Step: 6
Training loss: 2.9453418254852295
Validation loss: 2.1801241033820697

Epoch: 6| Step: 7
Training loss: 2.7615184783935547
Validation loss: 2.1623792750861055

Epoch: 6| Step: 8
Training loss: 2.794649362564087
Validation loss: 2.1219374723331903

Epoch: 6| Step: 9
Training loss: 2.3778467178344727
Validation loss: 2.112433175886831

Epoch: 6| Step: 10
Training loss: 2.2135300636291504
Validation loss: 2.1143188015107186

Epoch: 6| Step: 11
Training loss: 1.646594762802124
Validation loss: 2.0899377561384633

Epoch: 6| Step: 12
Training loss: 2.3399062156677246
Validation loss: 2.0764781454558014

Epoch: 6| Step: 13
Training loss: 2.609065055847168
Validation loss: 2.076841410770211

Epoch: 169| Step: 0
Training loss: 2.3863368034362793
Validation loss: 2.0646975950528215

Epoch: 6| Step: 1
Training loss: 2.340725898742676
Validation loss: 2.0664477655964513

Epoch: 6| Step: 2
Training loss: 2.1561925411224365
Validation loss: 2.0544222888126167

Epoch: 6| Step: 3
Training loss: 2.6669740676879883
Validation loss: 2.087729743731919

Epoch: 6| Step: 4
Training loss: 1.7651176452636719
Validation loss: 2.099439074916224

Epoch: 6| Step: 5
Training loss: 2.4431698322296143
Validation loss: 2.1412139707996

Epoch: 6| Step: 6
Training loss: 3.189624786376953
Validation loss: 2.142985431096887

Epoch: 6| Step: 7
Training loss: 2.056190252304077
Validation loss: 2.192678395137992

Epoch: 6| Step: 8
Training loss: 1.981755256652832
Validation loss: 2.272213364160189

Epoch: 6| Step: 9
Training loss: 2.8395698070526123
Validation loss: 2.3303042919405046

Epoch: 6| Step: 10
Training loss: 2.2209601402282715
Validation loss: 2.3180458263684343

Epoch: 6| Step: 11
Training loss: 2.3686490058898926
Validation loss: 2.2712922352616505

Epoch: 6| Step: 12
Training loss: 1.5596411228179932
Validation loss: 2.20673615958101

Epoch: 6| Step: 13
Training loss: 2.6543684005737305
Validation loss: 2.134267489115397

Epoch: 170| Step: 0
Training loss: 2.1939706802368164
Validation loss: 2.082195524246462

Epoch: 6| Step: 1
Training loss: 2.4510462284088135
Validation loss: 2.070484262640758

Epoch: 6| Step: 2
Training loss: 3.076608180999756
Validation loss: 2.032069811256983

Epoch: 6| Step: 3
Training loss: 2.3524279594421387
Validation loss: 2.0341060674318703

Epoch: 6| Step: 4
Training loss: 2.743314266204834
Validation loss: 2.0334200051523026

Epoch: 6| Step: 5
Training loss: 1.8913252353668213
Validation loss: 2.030425529326162

Epoch: 6| Step: 6
Training loss: 2.2270660400390625
Validation loss: 2.049742912733427

Epoch: 6| Step: 7
Training loss: 2.270875930786133
Validation loss: 2.048641252261336

Epoch: 6| Step: 8
Training loss: 2.16715931892395
Validation loss: 2.0813302788683163

Epoch: 6| Step: 9
Training loss: 1.9275765419006348
Validation loss: 2.0930982635867212

Epoch: 6| Step: 10
Training loss: 1.9647759199142456
Validation loss: 2.1143709485248854

Epoch: 6| Step: 11
Training loss: 2.557028293609619
Validation loss: 2.1160183645063833

Epoch: 6| Step: 12
Training loss: 2.3476033210754395
Validation loss: 2.152747056817496

Epoch: 6| Step: 13
Training loss: 2.0762836933135986
Validation loss: 2.155850902680428

Epoch: 171| Step: 0
Training loss: 1.7109260559082031
Validation loss: 2.162692070007324

Epoch: 6| Step: 1
Training loss: 2.224663257598877
Validation loss: 2.2427076806304274

Epoch: 6| Step: 2
Training loss: 2.242610454559326
Validation loss: 2.2800268639800367

Epoch: 6| Step: 3
Training loss: 2.21451735496521
Validation loss: 2.2701586907909763

Epoch: 6| Step: 4
Training loss: 2.260554313659668
Validation loss: 2.2583352263255785

Epoch: 6| Step: 5
Training loss: 2.8098442554473877
Validation loss: 2.1952400463883595

Epoch: 6| Step: 6
Training loss: 2.7495510578155518
Validation loss: 2.1818292487052178

Epoch: 6| Step: 7
Training loss: 3.0791399478912354
Validation loss: 2.166001617267568

Epoch: 6| Step: 8
Training loss: 2.0320217609405518
Validation loss: 2.170548910735756

Epoch: 6| Step: 9
Training loss: 2.265216112136841
Validation loss: 2.1567459875537502

Epoch: 6| Step: 10
Training loss: 2.85135817527771
Validation loss: 2.1232520739237466

Epoch: 6| Step: 11
Training loss: 1.7576930522918701
Validation loss: 2.0949788580658617

Epoch: 6| Step: 12
Training loss: 2.011556386947632
Validation loss: 2.054708655162524

Epoch: 6| Step: 13
Training loss: 2.6484804153442383
Validation loss: 2.0396108063318397

Epoch: 172| Step: 0
Training loss: 2.0003671646118164
Validation loss: 2.0474533393818843

Epoch: 6| Step: 1
Training loss: 2.0922107696533203
Validation loss: 2.069523713921988

Epoch: 6| Step: 2
Training loss: 1.84065842628479
Validation loss: 2.066219263179328

Epoch: 6| Step: 3
Training loss: 3.055144786834717
Validation loss: 2.086710214614868

Epoch: 6| Step: 4
Training loss: 2.9029932022094727
Validation loss: 2.085625584407519

Epoch: 6| Step: 5
Training loss: 2.606537342071533
Validation loss: 2.0889745835335023

Epoch: 6| Step: 6
Training loss: 2.665745735168457
Validation loss: 2.0611772485958633

Epoch: 6| Step: 7
Training loss: 2.736527919769287
Validation loss: 2.0719170544737127

Epoch: 6| Step: 8
Training loss: 2.083604574203491
Validation loss: 2.082923389250232

Epoch: 6| Step: 9
Training loss: 2.1008124351501465
Validation loss: 2.1007103330345562

Epoch: 6| Step: 10
Training loss: 2.250455379486084
Validation loss: 2.1181965617723364

Epoch: 6| Step: 11
Training loss: 1.4801268577575684
Validation loss: 2.1505330890737553

Epoch: 6| Step: 12
Training loss: 1.493290901184082
Validation loss: 2.1721590154914447

Epoch: 6| Step: 13
Training loss: 2.3402318954467773
Validation loss: 2.1788256911821264

Epoch: 173| Step: 0
Training loss: 2.3572354316711426
Validation loss: 2.187308199944035

Epoch: 6| Step: 1
Training loss: 2.274831771850586
Validation loss: 2.211992242003

Epoch: 6| Step: 2
Training loss: 2.5972282886505127
Validation loss: 2.196181861303186

Epoch: 6| Step: 3
Training loss: 2.4049172401428223
Validation loss: 2.187698145066538

Epoch: 6| Step: 4
Training loss: 1.792679786682129
Validation loss: 2.1870654167667514

Epoch: 6| Step: 5
Training loss: 1.6024820804595947
Validation loss: 2.179148586847449

Epoch: 6| Step: 6
Training loss: 2.1697020530700684
Validation loss: 2.1633233280592066

Epoch: 6| Step: 7
Training loss: 2.080733299255371
Validation loss: 2.1318252086639404

Epoch: 6| Step: 8
Training loss: 2.7722249031066895
Validation loss: 2.1280703044706777

Epoch: 6| Step: 9
Training loss: 2.3216421604156494
Validation loss: 2.1160921845384824

Epoch: 6| Step: 10
Training loss: 1.4561433792114258
Validation loss: 2.1251984116851643

Epoch: 6| Step: 11
Training loss: 2.7877655029296875
Validation loss: 2.0835703547282884

Epoch: 6| Step: 12
Training loss: 2.2110579013824463
Validation loss: 2.0901802483425347

Epoch: 6| Step: 13
Training loss: 2.575484275817871
Validation loss: 2.097187893365019

Epoch: 174| Step: 0
Training loss: 2.2410895824432373
Validation loss: 2.1028434768799813

Epoch: 6| Step: 1
Training loss: 1.9544789791107178
Validation loss: 2.0741129498327933

Epoch: 6| Step: 2
Training loss: 2.178598403930664
Validation loss: 2.079818474349155

Epoch: 6| Step: 3
Training loss: 3.225489377975464
Validation loss: 2.0963846842447915

Epoch: 6| Step: 4
Training loss: 3.117128372192383
Validation loss: 2.116060544085759

Epoch: 6| Step: 5
Training loss: 1.960081696510315
Validation loss: 2.1371641953786216

Epoch: 6| Step: 6
Training loss: 2.1092147827148438
Validation loss: 2.1778923183359127

Epoch: 6| Step: 7
Training loss: 2.071040391921997
Validation loss: 2.1619026404555126

Epoch: 6| Step: 8
Training loss: 2.119203805923462
Validation loss: 2.166846271484129

Epoch: 6| Step: 9
Training loss: 2.1651523113250732
Validation loss: 2.1333034410271594

Epoch: 6| Step: 10
Training loss: 1.9205788373947144
Validation loss: 2.10797446004806

Epoch: 6| Step: 11
Training loss: 2.430839776992798
Validation loss: 2.1027286155249483

Epoch: 6| Step: 12
Training loss: 1.571136713027954
Validation loss: 2.1426559109841623

Epoch: 6| Step: 13
Training loss: 2.556285858154297
Validation loss: 2.1460586196632794

Epoch: 175| Step: 0
Training loss: 1.241725206375122
Validation loss: 2.2067013914867113

Epoch: 6| Step: 1
Training loss: 3.171811819076538
Validation loss: 2.2225773565230833

Epoch: 6| Step: 2
Training loss: 2.567464590072632
Validation loss: 2.239203409482074

Epoch: 6| Step: 3
Training loss: 2.371243476867676
Validation loss: 2.209133550684939

Epoch: 6| Step: 4
Training loss: 2.3886306285858154
Validation loss: 2.215501352023053

Epoch: 6| Step: 5
Training loss: 2.6226134300231934
Validation loss: 2.1739054956743793

Epoch: 6| Step: 6
Training loss: 2.0419540405273438
Validation loss: 2.0877942551848707

Epoch: 6| Step: 7
Training loss: 2.0092544555664062
Validation loss: 2.0718334631253312

Epoch: 6| Step: 8
Training loss: 2.5064406394958496
Validation loss: 2.059025869574598

Epoch: 6| Step: 9
Training loss: 2.7253456115722656
Validation loss: 2.0777893117679063

Epoch: 6| Step: 10
Training loss: 2.015718936920166
Validation loss: 2.089297371525918

Epoch: 6| Step: 11
Training loss: 1.5937457084655762
Validation loss: 2.0850235646770847

Epoch: 6| Step: 12
Training loss: 2.147702217102051
Validation loss: 2.095349560501755

Epoch: 6| Step: 13
Training loss: 2.283924102783203
Validation loss: 2.097314452612272

Epoch: 176| Step: 0
Training loss: 2.631422996520996
Validation loss: 2.068360479929114

Epoch: 6| Step: 1
Training loss: 2.206378221511841
Validation loss: 2.0931716375453497

Epoch: 6| Step: 2
Training loss: 2.5295584201812744
Validation loss: 2.1385611462336716

Epoch: 6| Step: 3
Training loss: 2.5129427909851074
Validation loss: 2.1931455801892024

Epoch: 6| Step: 4
Training loss: 2.567294120788574
Validation loss: 2.2253627905281643

Epoch: 6| Step: 5
Training loss: 2.164067506790161
Validation loss: 2.240054948355562

Epoch: 6| Step: 6
Training loss: 1.573692798614502
Validation loss: 2.19117300228406

Epoch: 6| Step: 7
Training loss: 1.6908178329467773
Validation loss: 2.1313150467411166

Epoch: 6| Step: 8
Training loss: 2.3344578742980957
Validation loss: 2.1190449396769204

Epoch: 6| Step: 9
Training loss: 2.3303775787353516
Validation loss: 2.1128258077047204

Epoch: 6| Step: 10
Training loss: 2.1994194984436035
Validation loss: 2.087432001226692

Epoch: 6| Step: 11
Training loss: 2.1458027362823486
Validation loss: 2.099850150846666

Epoch: 6| Step: 12
Training loss: 2.1991682052612305
Validation loss: 2.0811319299923476

Epoch: 6| Step: 13
Training loss: 2.204758644104004
Validation loss: 2.0812489012236237

Epoch: 177| Step: 0
Training loss: 1.832876443862915
Validation loss: 2.078200674826099

Epoch: 6| Step: 1
Training loss: 2.8797049522399902
Validation loss: 2.0755082202214066

Epoch: 6| Step: 2
Training loss: 1.5158181190490723
Validation loss: 2.069312569915607

Epoch: 6| Step: 3
Training loss: 2.0709099769592285
Validation loss: 2.0748595089040776

Epoch: 6| Step: 4
Training loss: 2.6623611450195312
Validation loss: 2.0797620101641585

Epoch: 6| Step: 5
Training loss: 1.8422768115997314
Validation loss: 2.08979445375422

Epoch: 6| Step: 6
Training loss: 2.1752967834472656
Validation loss: 2.1144452889760337

Epoch: 6| Step: 7
Training loss: 2.3894834518432617
Validation loss: 2.140176393652475

Epoch: 6| Step: 8
Training loss: 2.402383804321289
Validation loss: 2.14675659261724

Epoch: 6| Step: 9
Training loss: 3.1812186241149902
Validation loss: 2.1253912397610244

Epoch: 6| Step: 10
Training loss: 1.7492575645446777
Validation loss: 2.1035052717372937

Epoch: 6| Step: 11
Training loss: 2.479125499725342
Validation loss: 2.111074548895641

Epoch: 6| Step: 12
Training loss: 2.414891481399536
Validation loss: 2.071338668946297

Epoch: 6| Step: 13
Training loss: 0.9182276129722595
Validation loss: 2.0876838289281374

Epoch: 178| Step: 0
Training loss: 2.615978717803955
Validation loss: 2.091728275822055

Epoch: 6| Step: 1
Training loss: 2.534435987472534
Validation loss: 2.105281783688453

Epoch: 6| Step: 2
Training loss: 2.7109742164611816
Validation loss: 2.1135859233076855

Epoch: 6| Step: 3
Training loss: 2.1652965545654297
Validation loss: 2.124534022423529

Epoch: 6| Step: 4
Training loss: 2.5271992683410645
Validation loss: 2.120825013806743

Epoch: 6| Step: 5
Training loss: 1.9099054336547852
Validation loss: 2.1114823472115303

Epoch: 6| Step: 6
Training loss: 1.7303541898727417
Validation loss: 2.1085448470166934

Epoch: 6| Step: 7
Training loss: 2.2783126831054688
Validation loss: 2.1288604582509687

Epoch: 6| Step: 8
Training loss: 2.1533074378967285
Validation loss: 2.132772050878053

Epoch: 6| Step: 9
Training loss: 1.9524052143096924
Validation loss: 2.135007760858023

Epoch: 6| Step: 10
Training loss: 2.240360975265503
Validation loss: 2.135697387879895

Epoch: 6| Step: 11
Training loss: 2.2570395469665527
Validation loss: 2.1217996369126024

Epoch: 6| Step: 12
Training loss: 1.7342138290405273
Validation loss: 2.1181231314136135

Epoch: 6| Step: 13
Training loss: 1.7680411338806152
Validation loss: 2.1121204719748548

Epoch: 179| Step: 0
Training loss: 2.0568041801452637
Validation loss: 2.091532304722776

Epoch: 6| Step: 1
Training loss: 2.7950077056884766
Validation loss: 2.0754325851317375

Epoch: 6| Step: 2
Training loss: 1.2725666761398315
Validation loss: 2.0814119462044007

Epoch: 6| Step: 3
Training loss: 2.4194188117980957
Validation loss: 2.056954010840385

Epoch: 6| Step: 4
Training loss: 1.8406881093978882
Validation loss: 2.07595677914158

Epoch: 6| Step: 5
Training loss: 1.5112285614013672
Validation loss: 2.126390313589445

Epoch: 6| Step: 6
Training loss: 1.542978286743164
Validation loss: 2.120634126406844

Epoch: 6| Step: 7
Training loss: 1.9951014518737793
Validation loss: 2.1423518221865416

Epoch: 6| Step: 8
Training loss: 2.6349496841430664
Validation loss: 2.1515723659146215

Epoch: 6| Step: 9
Training loss: 2.571211576461792
Validation loss: 2.141100181046353

Epoch: 6| Step: 10
Training loss: 2.160281181335449
Validation loss: 2.158841283090653

Epoch: 6| Step: 11
Training loss: 3.0957837104797363
Validation loss: 2.136073253488028

Epoch: 6| Step: 12
Training loss: 2.5823922157287598
Validation loss: 2.113896180224675

Epoch: 6| Step: 13
Training loss: 2.215527057647705
Validation loss: 2.089154995897765

Epoch: 180| Step: 0
Training loss: 2.256312370300293
Validation loss: 2.0894551430979083

Epoch: 6| Step: 1
Training loss: 1.7941771745681763
Validation loss: 2.0748976738222185

Epoch: 6| Step: 2
Training loss: 2.4621548652648926
Validation loss: 2.114172307393884

Epoch: 6| Step: 3
Training loss: 1.814969778060913
Validation loss: 2.1272345486507622

Epoch: 6| Step: 4
Training loss: 2.903946876525879
Validation loss: 2.1139604686408915

Epoch: 6| Step: 5
Training loss: 2.4400506019592285
Validation loss: 2.0801275468641713

Epoch: 6| Step: 6
Training loss: 1.9332761764526367
Validation loss: 2.0332021149255897

Epoch: 6| Step: 7
Training loss: 1.5741671323776245
Validation loss: 2.0638793694075717

Epoch: 6| Step: 8
Training loss: 2.7317285537719727
Validation loss: 2.061133655168677

Epoch: 6| Step: 9
Training loss: 1.8531837463378906
Validation loss: 2.0759939711580992

Epoch: 6| Step: 10
Training loss: 1.73879075050354
Validation loss: 2.137838012428694

Epoch: 6| Step: 11
Training loss: 2.0303311347961426
Validation loss: 2.1528624821734685

Epoch: 6| Step: 12
Training loss: 2.7568864822387695
Validation loss: 2.1983399711629397

Epoch: 6| Step: 13
Training loss: 3.019237518310547
Validation loss: 2.2034719656872492

Epoch: 181| Step: 0
Training loss: 1.7241880893707275
Validation loss: 2.1914499190545853

Epoch: 6| Step: 1
Training loss: 2.2633185386657715
Validation loss: 2.183419332709364

Epoch: 6| Step: 2
Training loss: 2.1216254234313965
Validation loss: 2.1600426576470815

Epoch: 6| Step: 3
Training loss: 2.6119422912597656
Validation loss: 2.1254977282657417

Epoch: 6| Step: 4
Training loss: 2.6680262088775635
Validation loss: 2.1345958427716325

Epoch: 6| Step: 5
Training loss: 2.293653964996338
Validation loss: 2.1483930310895367

Epoch: 6| Step: 6
Training loss: 2.3257341384887695
Validation loss: 2.121521217848665

Epoch: 6| Step: 7
Training loss: 1.360425591468811
Validation loss: 2.105377971485097

Epoch: 6| Step: 8
Training loss: 1.5694535970687866
Validation loss: 2.0809480118495163

Epoch: 6| Step: 9
Training loss: 2.6109848022460938
Validation loss: 2.0851542552312217

Epoch: 6| Step: 10
Training loss: 2.5344090461730957
Validation loss: 2.0468408907613447

Epoch: 6| Step: 11
Training loss: 2.0255885124206543
Validation loss: 2.0481005740422074

Epoch: 6| Step: 12
Training loss: 2.3326449394226074
Validation loss: 2.0331244263597714

Epoch: 6| Step: 13
Training loss: 1.8527616262435913
Validation loss: 2.031917106720709

Epoch: 182| Step: 0
Training loss: 1.5447415113449097
Validation loss: 2.048206385745797

Epoch: 6| Step: 1
Training loss: 2.1908509731292725
Validation loss: 2.0567684545311877

Epoch: 6| Step: 2
Training loss: 2.305347204208374
Validation loss: 2.0501950248595207

Epoch: 6| Step: 3
Training loss: 2.8109383583068848
Validation loss: 2.0612641790861725

Epoch: 6| Step: 4
Training loss: 2.1086790561676025
Validation loss: 2.0638947589423067

Epoch: 6| Step: 5
Training loss: 2.210737705230713
Validation loss: 2.089450707999609

Epoch: 6| Step: 6
Training loss: 1.8678714036941528
Validation loss: 2.077538885096068

Epoch: 6| Step: 7
Training loss: 2.6717429161071777
Validation loss: 2.1002188574883247

Epoch: 6| Step: 8
Training loss: 2.3755574226379395
Validation loss: 2.0976963325213362

Epoch: 6| Step: 9
Training loss: 2.3996195793151855
Validation loss: 2.1115164654229277

Epoch: 6| Step: 10
Training loss: 1.6143114566802979
Validation loss: 2.1120933178932435

Epoch: 6| Step: 11
Training loss: 2.08504056930542
Validation loss: 2.127666784871009

Epoch: 6| Step: 12
Training loss: 2.2159929275512695
Validation loss: 2.1157059156766502

Epoch: 6| Step: 13
Training loss: 1.6633065938949585
Validation loss: 2.130193546254148

Epoch: 183| Step: 0
Training loss: 1.4504948854446411
Validation loss: 2.1478233106674685

Epoch: 6| Step: 1
Training loss: 2.922046661376953
Validation loss: 2.1970049847838697

Epoch: 6| Step: 2
Training loss: 2.672900915145874
Validation loss: 2.2300433830548356

Epoch: 6| Step: 3
Training loss: 2.3488614559173584
Validation loss: 2.189012171119772

Epoch: 6| Step: 4
Training loss: 1.642228603363037
Validation loss: 2.134156260439145

Epoch: 6| Step: 5
Training loss: 2.166966676712036
Validation loss: 2.04174369124956

Epoch: 6| Step: 6
Training loss: 2.140120267868042
Validation loss: 2.0233726463010235

Epoch: 6| Step: 7
Training loss: 2.3190457820892334
Validation loss: 2.029296564799483

Epoch: 6| Step: 8
Training loss: 3.470242977142334
Validation loss: 2.0390404103904642

Epoch: 6| Step: 9
Training loss: 2.231397867202759
Validation loss: 2.034592149078205

Epoch: 6| Step: 10
Training loss: 2.1769704818725586
Validation loss: 2.0284309233388593

Epoch: 6| Step: 11
Training loss: 2.126244068145752
Validation loss: 2.0122051315922893

Epoch: 6| Step: 12
Training loss: 2.4699535369873047
Validation loss: 2.004469866393715

Epoch: 6| Step: 13
Training loss: 1.0619738101959229
Validation loss: 2.028282380873157

Epoch: 184| Step: 0
Training loss: 2.1906208992004395
Validation loss: 2.039152850386917

Epoch: 6| Step: 1
Training loss: 1.8421717882156372
Validation loss: 2.0912200609842935

Epoch: 6| Step: 2
Training loss: 2.7853198051452637
Validation loss: 2.140037940394494

Epoch: 6| Step: 3
Training loss: 1.9641246795654297
Validation loss: 2.1823390530001734

Epoch: 6| Step: 4
Training loss: 2.654088258743286
Validation loss: 2.1631155398584183

Epoch: 6| Step: 5
Training loss: 2.261841297149658
Validation loss: 2.1663316680539038

Epoch: 6| Step: 6
Training loss: 2.736217498779297
Validation loss: 2.1452632693834204

Epoch: 6| Step: 7
Training loss: 1.822106957435608
Validation loss: 2.1102116338668333

Epoch: 6| Step: 8
Training loss: 2.0576605796813965
Validation loss: 2.077367200646349

Epoch: 6| Step: 9
Training loss: 2.285548210144043
Validation loss: 2.078912329930131

Epoch: 6| Step: 10
Training loss: 1.937370777130127
Validation loss: 2.0445382389971005

Epoch: 6| Step: 11
Training loss: 2.6159842014312744
Validation loss: 2.0469618715265745

Epoch: 6| Step: 12
Training loss: 0.9919953346252441
Validation loss: 2.0552033006504016

Epoch: 6| Step: 13
Training loss: 2.636418342590332
Validation loss: 2.049985276755466

Epoch: 185| Step: 0
Training loss: 2.0479207038879395
Validation loss: 2.0594102233968754

Epoch: 6| Step: 1
Training loss: 1.9813570976257324
Validation loss: 2.0732714001850416

Epoch: 6| Step: 2
Training loss: 2.1271872520446777
Validation loss: 2.099606619086317

Epoch: 6| Step: 3
Training loss: 2.1771156787872314
Validation loss: 2.165648824425154

Epoch: 6| Step: 4
Training loss: 2.3615150451660156
Validation loss: 2.1805073215115454

Epoch: 6| Step: 5
Training loss: 1.6022990942001343
Validation loss: 2.18401688145053

Epoch: 6| Step: 6
Training loss: 2.3175411224365234
Validation loss: 2.182769852299844

Epoch: 6| Step: 7
Training loss: 1.9375288486480713
Validation loss: 2.139834419373543

Epoch: 6| Step: 8
Training loss: 2.6186108589172363
Validation loss: 2.1231491129885436

Epoch: 6| Step: 9
Training loss: 2.6649045944213867
Validation loss: 2.0566808459579304

Epoch: 6| Step: 10
Training loss: 1.24064040184021
Validation loss: 2.0431973703445925

Epoch: 6| Step: 11
Training loss: 3.0812859535217285
Validation loss: 2.0241329875043643

Epoch: 6| Step: 12
Training loss: 1.9825456142425537
Validation loss: 2.015933739241733

Epoch: 6| Step: 13
Training loss: 2.3939781188964844
Validation loss: 1.984787658978534

Epoch: 186| Step: 0
Training loss: 2.194915771484375
Validation loss: 1.9979800601159372

Epoch: 6| Step: 1
Training loss: 3.038865089416504
Validation loss: 1.9907645640834686

Epoch: 6| Step: 2
Training loss: 2.826127052307129
Validation loss: 1.9868729729806223

Epoch: 6| Step: 3
Training loss: 2.4511730670928955
Validation loss: 1.981059625584592

Epoch: 6| Step: 4
Training loss: 1.9053261280059814
Validation loss: 2.0012061057552213

Epoch: 6| Step: 5
Training loss: 2.8064446449279785
Validation loss: 1.998344321404734

Epoch: 6| Step: 6
Training loss: 1.8564311265945435
Validation loss: 2.0307766827203895

Epoch: 6| Step: 7
Training loss: 1.5904779434204102
Validation loss: 2.026904272776778

Epoch: 6| Step: 8
Training loss: 1.5161147117614746
Validation loss: 2.0547770889856483

Epoch: 6| Step: 9
Training loss: 1.6855968236923218
Validation loss: 2.0606376073693715

Epoch: 6| Step: 10
Training loss: 1.8570586442947388
Validation loss: 2.1113141480312554

Epoch: 6| Step: 11
Training loss: 1.7614680528640747
Validation loss: 2.1125060614719184

Epoch: 6| Step: 12
Training loss: 2.9077320098876953
Validation loss: 2.1203681909909813

Epoch: 6| Step: 13
Training loss: 2.4771618843078613
Validation loss: 2.0898751161431752

Epoch: 187| Step: 0
Training loss: 2.129887580871582
Validation loss: 2.1005466894436906

Epoch: 6| Step: 1
Training loss: 2.97676420211792
Validation loss: 2.0798270881816907

Epoch: 6| Step: 2
Training loss: 2.1977784633636475
Validation loss: 2.0449126510209936

Epoch: 6| Step: 3
Training loss: 1.754141926765442
Validation loss: 2.035462438419301

Epoch: 6| Step: 4
Training loss: 1.8914581537246704
Validation loss: 2.0413804964352678

Epoch: 6| Step: 5
Training loss: 2.099132776260376
Validation loss: 2.0305719503792385

Epoch: 6| Step: 6
Training loss: 1.5451200008392334
Validation loss: 2.0196919236131894

Epoch: 6| Step: 7
Training loss: 2.4500157833099365
Validation loss: 2.0300611808735836

Epoch: 6| Step: 8
Training loss: 2.5485637187957764
Validation loss: 2.062264220688933

Epoch: 6| Step: 9
Training loss: 1.6687060594558716
Validation loss: 2.0592806057263444

Epoch: 6| Step: 10
Training loss: 1.3365153074264526
Validation loss: 2.0794087815028366

Epoch: 6| Step: 11
Training loss: 3.030327320098877
Validation loss: 2.0827580011019142

Epoch: 6| Step: 12
Training loss: 1.3299709558486938
Validation loss: 2.0803347620912778

Epoch: 6| Step: 13
Training loss: 3.5724613666534424
Validation loss: 2.0732246829617407

Epoch: 188| Step: 0
Training loss: 2.266078472137451
Validation loss: 2.059993031204388

Epoch: 6| Step: 1
Training loss: 2.328577995300293
Validation loss: 2.041645598667924

Epoch: 6| Step: 2
Training loss: 2.3373680114746094
Validation loss: 2.06059032101785

Epoch: 6| Step: 3
Training loss: 2.7431936264038086
Validation loss: 2.0762459052506315

Epoch: 6| Step: 4
Training loss: 2.1224653720855713
Validation loss: 2.0740659813727103

Epoch: 6| Step: 5
Training loss: 1.4089634418487549
Validation loss: 2.0529770338407127

Epoch: 6| Step: 6
Training loss: 2.682039976119995
Validation loss: 2.0686465719694733

Epoch: 6| Step: 7
Training loss: 2.040708065032959
Validation loss: 2.1025938475003807

Epoch: 6| Step: 8
Training loss: 2.0177178382873535
Validation loss: 2.1179387261790614

Epoch: 6| Step: 9
Training loss: 1.7867859601974487
Validation loss: 2.0858982019526984

Epoch: 6| Step: 10
Training loss: 2.023268699645996
Validation loss: 2.0894347544639342

Epoch: 6| Step: 11
Training loss: 2.293705701828003
Validation loss: 2.05701623424407

Epoch: 6| Step: 12
Training loss: 1.588270664215088
Validation loss: 2.049442142568609

Epoch: 6| Step: 13
Training loss: 2.060419797897339
Validation loss: 2.0407034761162213

Epoch: 189| Step: 0
Training loss: 2.1636879444122314
Validation loss: 2.0434462511411278

Epoch: 6| Step: 1
Training loss: 2.393340587615967
Validation loss: 2.076353605075549

Epoch: 6| Step: 2
Training loss: 2.0755512714385986
Validation loss: 2.0420628978360083

Epoch: 6| Step: 3
Training loss: 1.392181158065796
Validation loss: 2.0278994011622604

Epoch: 6| Step: 4
Training loss: 2.162144184112549
Validation loss: 2.015391222892269

Epoch: 6| Step: 5
Training loss: 1.887611985206604
Validation loss: 2.043347056194018

Epoch: 6| Step: 6
Training loss: 2.4967174530029297
Validation loss: 2.051793658605186

Epoch: 6| Step: 7
Training loss: 2.150352954864502
Validation loss: 2.07402870731969

Epoch: 6| Step: 8
Training loss: 2.513084888458252
Validation loss: 2.0768211964638

Epoch: 6| Step: 9
Training loss: 1.6047875881195068
Validation loss: 2.0703005649710216

Epoch: 6| Step: 10
Training loss: 1.941598653793335
Validation loss: 2.052051972317439

Epoch: 6| Step: 11
Training loss: 2.779411792755127
Validation loss: 2.060488949539841

Epoch: 6| Step: 12
Training loss: 1.776561975479126
Validation loss: 2.0578352328269713

Epoch: 6| Step: 13
Training loss: 2.554287910461426
Validation loss: 2.032921334748627

Epoch: 190| Step: 0
Training loss: 1.318452000617981
Validation loss: 2.0273063439194874

Epoch: 6| Step: 1
Training loss: 1.5675327777862549
Validation loss: 2.024556471455482

Epoch: 6| Step: 2
Training loss: 2.6724905967712402
Validation loss: 2.0050088628645866

Epoch: 6| Step: 3
Training loss: 2.596177577972412
Validation loss: 2.016791820526123

Epoch: 6| Step: 4
Training loss: 2.935722589492798
Validation loss: 2.028885033822829

Epoch: 6| Step: 5
Training loss: 2.3130125999450684
Validation loss: 2.0373239542848323

Epoch: 6| Step: 6
Training loss: 1.8519442081451416
Validation loss: 2.0334358087149997

Epoch: 6| Step: 7
Training loss: 2.134103536605835
Validation loss: 2.029938397868987

Epoch: 6| Step: 8
Training loss: 2.6090917587280273
Validation loss: 2.074625451077697

Epoch: 6| Step: 9
Training loss: 2.126107692718506
Validation loss: 2.1286174533187703

Epoch: 6| Step: 10
Training loss: 2.630255699157715
Validation loss: 2.206672640256984

Epoch: 6| Step: 11
Training loss: 1.9729843139648438
Validation loss: 2.217550416146555

Epoch: 6| Step: 12
Training loss: 1.6562819480895996
Validation loss: 2.2437017989414993

Epoch: 6| Step: 13
Training loss: 1.8517388105392456
Validation loss: 2.2473656464648504

Epoch: 191| Step: 0
Training loss: 2.5940632820129395
Validation loss: 2.195701524775515

Epoch: 6| Step: 1
Training loss: 1.7559560537338257
Validation loss: 2.153052132616761

Epoch: 6| Step: 2
Training loss: 2.3387248516082764
Validation loss: 2.1275739028889644

Epoch: 6| Step: 3
Training loss: 2.5664987564086914
Validation loss: 2.12138956592929

Epoch: 6| Step: 4
Training loss: 1.659165382385254
Validation loss: 2.107204101418936

Epoch: 6| Step: 5
Training loss: 1.4764262437820435
Validation loss: 2.074686033751375

Epoch: 6| Step: 6
Training loss: 2.3161206245422363
Validation loss: 2.0866190207901822

Epoch: 6| Step: 7
Training loss: 2.4767374992370605
Validation loss: 2.054312568838878

Epoch: 6| Step: 8
Training loss: 1.7395023107528687
Validation loss: 2.027965327744843

Epoch: 6| Step: 9
Training loss: 2.071906566619873
Validation loss: 2.037963476232303

Epoch: 6| Step: 10
Training loss: 2.1983847618103027
Validation loss: 2.0048032973402288

Epoch: 6| Step: 11
Training loss: 2.2426860332489014
Validation loss: 2.011958970818468

Epoch: 6| Step: 12
Training loss: 2.5835800170898438
Validation loss: 2.0280426317645657

Epoch: 6| Step: 13
Training loss: 1.272716999053955
Validation loss: 2.055013697634461

Epoch: 192| Step: 0
Training loss: 2.3656222820281982
Validation loss: 2.056034393208001

Epoch: 6| Step: 1
Training loss: 1.79990553855896
Validation loss: 2.0524041447588193

Epoch: 6| Step: 2
Training loss: 1.8556416034698486
Validation loss: 2.0357260011857554

Epoch: 6| Step: 3
Training loss: 2.0354104042053223
Validation loss: 2.0856382821195867

Epoch: 6| Step: 4
Training loss: 2.317108392715454
Validation loss: 2.1197050425314132

Epoch: 6| Step: 5
Training loss: 2.1576452255249023
Validation loss: 2.185035051838044

Epoch: 6| Step: 6
Training loss: 2.6977381706237793
Validation loss: 2.1773503762419506

Epoch: 6| Step: 7
Training loss: 1.6360480785369873
Validation loss: 2.1391267315033944

Epoch: 6| Step: 8
Training loss: 2.5328524112701416
Validation loss: 2.1390895151322886

Epoch: 6| Step: 9
Training loss: 2.237344264984131
Validation loss: 2.167495649348023

Epoch: 6| Step: 10
Training loss: 1.840620756149292
Validation loss: 2.213329254939992

Epoch: 6| Step: 11
Training loss: 2.136587619781494
Validation loss: 2.2595499946225073

Epoch: 6| Step: 12
Training loss: 2.1177685260772705
Validation loss: 2.2657335060898975

Epoch: 6| Step: 13
Training loss: 2.7894716262817383
Validation loss: 2.2744702421208864

Epoch: 193| Step: 0
Training loss: 2.7793469429016113
Validation loss: 2.24904300320533

Epoch: 6| Step: 1
Training loss: 2.6196837425231934
Validation loss: 2.2227409065410657

Epoch: 6| Step: 2
Training loss: 1.8577487468719482
Validation loss: 2.2151926294449837

Epoch: 6| Step: 3
Training loss: 1.5062706470489502
Validation loss: 2.14202695251793

Epoch: 6| Step: 4
Training loss: 2.089710235595703
Validation loss: 2.08111233352333

Epoch: 6| Step: 5
Training loss: 2.077213764190674
Validation loss: 2.0625675109124955

Epoch: 6| Step: 6
Training loss: 1.9357821941375732
Validation loss: 2.0940113349627425

Epoch: 6| Step: 7
Training loss: 1.9475221633911133
Validation loss: 2.1294814553312076

Epoch: 6| Step: 8
Training loss: 1.4533854722976685
Validation loss: 2.1604174798534763

Epoch: 6| Step: 9
Training loss: 3.341803789138794
Validation loss: 2.253030228358443

Epoch: 6| Step: 10
Training loss: 2.373253107070923
Validation loss: 2.2568613175422914

Epoch: 6| Step: 11
Training loss: 2.7231051921844482
Validation loss: 2.23438629540064

Epoch: 6| Step: 12
Training loss: 1.7556582689285278
Validation loss: 2.173087214910856

Epoch: 6| Step: 13
Training loss: 2.3730247020721436
Validation loss: 2.069635025916561

Epoch: 194| Step: 0
Training loss: 1.6518983840942383
Validation loss: 2.0248637225038264

Epoch: 6| Step: 1
Training loss: 3.001307249069214
Validation loss: 2.0822488800171883

Epoch: 6| Step: 2
Training loss: 2.50571346282959
Validation loss: 2.11518516079072

Epoch: 6| Step: 3
Training loss: 2.5968823432922363
Validation loss: 2.132801073853688

Epoch: 6| Step: 4
Training loss: 1.7904136180877686
Validation loss: 2.1320042815259708

Epoch: 6| Step: 5
Training loss: 1.846381664276123
Validation loss: 2.101319048994331

Epoch: 6| Step: 6
Training loss: 2.2579989433288574
Validation loss: 2.0740193167040424

Epoch: 6| Step: 7
Training loss: 2.4238312244415283
Validation loss: 2.0679806124779487

Epoch: 6| Step: 8
Training loss: 1.8076926469802856
Validation loss: 2.0558118974008868

Epoch: 6| Step: 9
Training loss: 2.995788812637329
Validation loss: 2.0485368877328853

Epoch: 6| Step: 10
Training loss: 1.8190672397613525
Validation loss: 2.036139557438512

Epoch: 6| Step: 11
Training loss: 2.131908655166626
Validation loss: 2.012543346292229

Epoch: 6| Step: 12
Training loss: 2.008559226989746
Validation loss: 2.037284061472903

Epoch: 6| Step: 13
Training loss: 1.5629417896270752
Validation loss: 2.056289603633265

Epoch: 195| Step: 0
Training loss: 2.206212043762207
Validation loss: 2.1021816961226927

Epoch: 6| Step: 1
Training loss: 2.0036911964416504
Validation loss: 2.191673081408265

Epoch: 6| Step: 2
Training loss: 2.1310019493103027
Validation loss: 2.2153309519572923

Epoch: 6| Step: 3
Training loss: 1.829276204109192
Validation loss: 2.206238685115691

Epoch: 6| Step: 4
Training loss: 2.279310703277588
Validation loss: 2.1679539026752597

Epoch: 6| Step: 5
Training loss: 1.8826260566711426
Validation loss: 2.1511399515213503

Epoch: 6| Step: 6
Training loss: 2.74288272857666
Validation loss: 2.0754772616970922

Epoch: 6| Step: 7
Training loss: 2.055640935897827
Validation loss: 2.0430482869507163

Epoch: 6| Step: 8
Training loss: 2.361064910888672
Validation loss: 2.011798552287522

Epoch: 6| Step: 9
Training loss: 1.7743558883666992
Validation loss: 2.010533450752176

Epoch: 6| Step: 10
Training loss: 2.1748862266540527
Validation loss: 2.0077388965955345

Epoch: 6| Step: 11
Training loss: 2.9295084476470947
Validation loss: 2.0069650257787397

Epoch: 6| Step: 12
Training loss: 1.841819167137146
Validation loss: 2.0049753688996836

Epoch: 6| Step: 13
Training loss: 2.245675802230835
Validation loss: 1.9980747469009892

Epoch: 196| Step: 0
Training loss: 2.5188424587249756
Validation loss: 2.0252376000086465

Epoch: 6| Step: 1
Training loss: 2.003286361694336
Validation loss: 2.0607777128937426

Epoch: 6| Step: 2
Training loss: 1.8841700553894043
Validation loss: 2.092551503130185

Epoch: 6| Step: 3
Training loss: 2.0498504638671875
Validation loss: 2.114863375181793

Epoch: 6| Step: 4
Training loss: 2.2396085262298584
Validation loss: 2.1124553731692735

Epoch: 6| Step: 5
Training loss: 2.8070712089538574
Validation loss: 2.188697597031952

Epoch: 6| Step: 6
Training loss: 1.429853081703186
Validation loss: 2.18824738840903

Epoch: 6| Step: 7
Training loss: 2.165990114212036
Validation loss: 2.212621053059896

Epoch: 6| Step: 8
Training loss: 2.8033337593078613
Validation loss: 2.1995730784631546

Epoch: 6| Step: 9
Training loss: 2.424938678741455
Validation loss: 2.126151793746538

Epoch: 6| Step: 10
Training loss: 1.903598666191101
Validation loss: 2.094545484870993

Epoch: 6| Step: 11
Training loss: 2.538547992706299
Validation loss: 2.0619467202053277

Epoch: 6| Step: 12
Training loss: 1.6460295915603638
Validation loss: 2.038033098302862

Epoch: 6| Step: 13
Training loss: 1.1209607124328613
Validation loss: 2.0091667893112346

Epoch: 197| Step: 0
Training loss: 2.300379753112793
Validation loss: 1.9842891411114765

Epoch: 6| Step: 1
Training loss: 1.8646090030670166
Validation loss: 2.008688783132902

Epoch: 6| Step: 2
Training loss: 2.2188451290130615
Validation loss: 2.0055695784989225

Epoch: 6| Step: 3
Training loss: 2.7180821895599365
Validation loss: 2.003698641254056

Epoch: 6| Step: 4
Training loss: 1.816901683807373
Validation loss: 2.002581605347254

Epoch: 6| Step: 5
Training loss: 2.686267375946045
Validation loss: 2.01765626476657

Epoch: 6| Step: 6
Training loss: 1.9108996391296387
Validation loss: 2.0177145311909337

Epoch: 6| Step: 7
Training loss: 1.9203970432281494
Validation loss: 2.0305201263837915

Epoch: 6| Step: 8
Training loss: 2.3149805068969727
Validation loss: 2.025561340393559

Epoch: 6| Step: 9
Training loss: 2.0275039672851562
Validation loss: 2.134567206905734

Epoch: 6| Step: 10
Training loss: 2.465787887573242
Validation loss: 2.1610488173782185

Epoch: 6| Step: 11
Training loss: 2.5387425422668457
Validation loss: 2.1939309899524977

Epoch: 6| Step: 12
Training loss: 1.2185821533203125
Validation loss: 2.140799263472198

Epoch: 6| Step: 13
Training loss: 0.9592335820198059
Validation loss: 2.096745824301115

Epoch: 198| Step: 0
Training loss: 2.8777942657470703
Validation loss: 2.0822510232207594

Epoch: 6| Step: 1
Training loss: 2.392685890197754
Validation loss: 2.071210294641474

Epoch: 6| Step: 2
Training loss: 1.1967206001281738
Validation loss: 2.0642057823878464

Epoch: 6| Step: 3
Training loss: 1.946308970451355
Validation loss: 2.0413008595025666

Epoch: 6| Step: 4
Training loss: 1.8076375722885132
Validation loss: 2.018894454484345

Epoch: 6| Step: 5
Training loss: 2.2840609550476074
Validation loss: 2.022905743250283

Epoch: 6| Step: 6
Training loss: 1.6931195259094238
Validation loss: 2.010648009597614

Epoch: 6| Step: 7
Training loss: 2.5944669246673584
Validation loss: 1.995293326275323

Epoch: 6| Step: 8
Training loss: 1.8531875610351562
Validation loss: 2.008352960309675

Epoch: 6| Step: 9
Training loss: 2.075705051422119
Validation loss: 2.0077569446256085

Epoch: 6| Step: 10
Training loss: 2.610042095184326
Validation loss: 2.0289941795410646

Epoch: 6| Step: 11
Training loss: 1.59299898147583
Validation loss: 2.0352525890514417

Epoch: 6| Step: 12
Training loss: 2.124052047729492
Validation loss: 2.0471615099137828

Epoch: 6| Step: 13
Training loss: 2.2118136882781982
Validation loss: 2.061966016728391

Epoch: 199| Step: 0
Training loss: 2.2262136936187744
Validation loss: 2.0595517773782053

Epoch: 6| Step: 1
Training loss: 1.8120548725128174
Validation loss: 2.048463879093047

Epoch: 6| Step: 2
Training loss: 2.690415859222412
Validation loss: 2.036423703034719

Epoch: 6| Step: 3
Training loss: 1.5305211544036865
Validation loss: 2.063080551803753

Epoch: 6| Step: 4
Training loss: 1.9866313934326172
Validation loss: 2.066115794643279

Epoch: 6| Step: 5
Training loss: 2.286444664001465
Validation loss: 2.0799847392625708

Epoch: 6| Step: 6
Training loss: 2.718658685684204
Validation loss: 2.0927669322618874

Epoch: 6| Step: 7
Training loss: 1.3916560411453247
Validation loss: 2.0568241201421267

Epoch: 6| Step: 8
Training loss: 2.1980576515197754
Validation loss: 2.0652073814022924

Epoch: 6| Step: 9
Training loss: 1.9370802640914917
Validation loss: 2.046727285590223

Epoch: 6| Step: 10
Training loss: 1.6897685527801514
Validation loss: 2.0402029765549528

Epoch: 6| Step: 11
Training loss: 2.2348077297210693
Validation loss: 2.0207929572751446

Epoch: 6| Step: 12
Training loss: 1.8303933143615723
Validation loss: 2.0284949528273715

Epoch: 6| Step: 13
Training loss: 2.4710168838500977
Validation loss: 2.048183338616484

Epoch: 200| Step: 0
Training loss: 1.5804964303970337
Validation loss: 2.077175946645839

Epoch: 6| Step: 1
Training loss: 2.144808292388916
Validation loss: 2.0762740770975747

Epoch: 6| Step: 2
Training loss: 2.221062660217285
Validation loss: 2.1401576098575386

Epoch: 6| Step: 3
Training loss: 2.30562686920166
Validation loss: 2.1355225270794285

Epoch: 6| Step: 4
Training loss: 2.3373281955718994
Validation loss: 2.18063675203631

Epoch: 6| Step: 5
Training loss: 2.0117666721343994
Validation loss: 2.1731033696923205

Epoch: 6| Step: 6
Training loss: 2.260744571685791
Validation loss: 2.154678862581971

Epoch: 6| Step: 7
Training loss: 2.4290647506713867
Validation loss: 2.1512224674224854

Epoch: 6| Step: 8
Training loss: 2.224053144454956
Validation loss: 2.1026215284101424

Epoch: 6| Step: 9
Training loss: 1.6326591968536377
Validation loss: 2.083997107321216

Epoch: 6| Step: 10
Training loss: 2.075861930847168
Validation loss: 2.047739412194939

Epoch: 6| Step: 11
Training loss: 1.9969254732131958
Validation loss: 2.0587464596635554

Epoch: 6| Step: 12
Training loss: 1.3531275987625122
Validation loss: 2.061354083399619

Epoch: 6| Step: 13
Training loss: 3.1051809787750244
Validation loss: 2.0255628401233303

Epoch: 201| Step: 0
Training loss: 1.5410370826721191
Validation loss: 2.0323538472575526

Epoch: 6| Step: 1
Training loss: 2.2198548316955566
Validation loss: 2.038197503294996

Epoch: 6| Step: 2
Training loss: 2.4314754009246826
Validation loss: 2.025439621299826

Epoch: 6| Step: 3
Training loss: 2.2218470573425293
Validation loss: 2.0183722049959245

Epoch: 6| Step: 4
Training loss: 2.2387688159942627
Validation loss: 2.0265811668929232

Epoch: 6| Step: 5
Training loss: 1.6457256078720093
Validation loss: 2.065647876390847

Epoch: 6| Step: 6
Training loss: 1.7593543529510498
Validation loss: 2.0758939635369087

Epoch: 6| Step: 7
Training loss: 2.6786375045776367
Validation loss: 2.093122572027227

Epoch: 6| Step: 8
Training loss: 2.033756732940674
Validation loss: 2.055151424100322

Epoch: 6| Step: 9
Training loss: 2.1987009048461914
Validation loss: 2.005198896572154

Epoch: 6| Step: 10
Training loss: 1.6251698732376099
Validation loss: 2.009407501066885

Epoch: 6| Step: 11
Training loss: 2.6755523681640625
Validation loss: 2.007673501968384

Epoch: 6| Step: 12
Training loss: 2.0728557109832764
Validation loss: 2.0112455737206245

Epoch: 6| Step: 13
Training loss: 1.5609583854675293
Validation loss: 2.057789130877423

Epoch: 202| Step: 0
Training loss: 2.6248533725738525
Validation loss: 2.0936017497893302

Epoch: 6| Step: 1
Training loss: 2.2157211303710938
Validation loss: 2.096563405888055

Epoch: 6| Step: 2
Training loss: 2.196943521499634
Validation loss: 2.1159501614109164

Epoch: 6| Step: 3
Training loss: 2.206334114074707
Validation loss: 2.110666956952823

Epoch: 6| Step: 4
Training loss: 2.486750841140747
Validation loss: 2.0927749064660843

Epoch: 6| Step: 5
Training loss: 2.901120185852051
Validation loss: 2.0936298716452812

Epoch: 6| Step: 6
Training loss: 1.9169695377349854
Validation loss: 2.050882549696071

Epoch: 6| Step: 7
Training loss: 2.0243053436279297
Validation loss: 2.0789332210376696

Epoch: 6| Step: 8
Training loss: 1.8801681995391846
Validation loss: 2.0613050076269333

Epoch: 6| Step: 9
Training loss: 1.5087769031524658
Validation loss: 2.068905294582408

Epoch: 6| Step: 10
Training loss: 2.114309310913086
Validation loss: 2.058336962935745

Epoch: 6| Step: 11
Training loss: 1.4746865034103394
Validation loss: 2.0581179959799654

Epoch: 6| Step: 12
Training loss: 1.3876047134399414
Validation loss: 2.071096642043001

Epoch: 6| Step: 13
Training loss: 2.2350270748138428
Validation loss: 2.0834975216978338

Epoch: 203| Step: 0
Training loss: 2.3866794109344482
Validation loss: 2.081940838085708

Epoch: 6| Step: 1
Training loss: 2.792031764984131
Validation loss: 2.1187797323349984

Epoch: 6| Step: 2
Training loss: 2.2023110389709473
Validation loss: 2.134719012885965

Epoch: 6| Step: 3
Training loss: 1.4159413576126099
Validation loss: 2.12037339005419

Epoch: 6| Step: 4
Training loss: 2.72279953956604
Validation loss: 2.0543163835361438

Epoch: 6| Step: 5
Training loss: 1.7777736186981201
Validation loss: 2.0576951349935224

Epoch: 6| Step: 6
Training loss: 1.8642857074737549
Validation loss: 2.0036461173847155

Epoch: 6| Step: 7
Training loss: 2.3395891189575195
Validation loss: 2.015187580098388

Epoch: 6| Step: 8
Training loss: 2.1174254417419434
Validation loss: 2.00203094174785

Epoch: 6| Step: 9
Training loss: 2.12728214263916
Validation loss: 2.018840107866513

Epoch: 6| Step: 10
Training loss: 1.6843763589859009
Validation loss: 2.001166428289106

Epoch: 6| Step: 11
Training loss: 1.6380424499511719
Validation loss: 2.0173491508729997

Epoch: 6| Step: 12
Training loss: 1.8523273468017578
Validation loss: 2.015185077985128

Epoch: 6| Step: 13
Training loss: 1.9187283515930176
Validation loss: 2.0141120700426

Epoch: 204| Step: 0
Training loss: 1.2838236093521118
Validation loss: 2.0596123869701097

Epoch: 6| Step: 1
Training loss: 2.126941204071045
Validation loss: 2.091033286945794

Epoch: 6| Step: 2
Training loss: 2.829045295715332
Validation loss: 2.088297611923628

Epoch: 6| Step: 3
Training loss: 2.1577601432800293
Validation loss: 2.1327156725750176

Epoch: 6| Step: 4
Training loss: 1.8596341609954834
Validation loss: 2.1438089621964322

Epoch: 6| Step: 5
Training loss: 2.099616050720215
Validation loss: 2.124702312613046

Epoch: 6| Step: 6
Training loss: 2.0506298542022705
Validation loss: 2.095194246179314

Epoch: 6| Step: 7
Training loss: 2.0506489276885986
Validation loss: 2.098426970102454

Epoch: 6| Step: 8
Training loss: 1.7714736461639404
Validation loss: 2.114565219930423

Epoch: 6| Step: 9
Training loss: 1.834636926651001
Validation loss: 2.1217668364124913

Epoch: 6| Step: 10
Training loss: 1.8065801858901978
Validation loss: 2.097989561737225

Epoch: 6| Step: 11
Training loss: 2.308939218521118
Validation loss: 2.0862784488226778

Epoch: 6| Step: 12
Training loss: 2.145063638687134
Validation loss: 2.04696475818593

Epoch: 6| Step: 13
Training loss: 1.8705965280532837
Validation loss: 2.059639670515573

Epoch: 205| Step: 0
Training loss: 1.817842721939087
Validation loss: 2.083896529289984

Epoch: 6| Step: 1
Training loss: 1.821866512298584
Validation loss: 2.0834912151418705

Epoch: 6| Step: 2
Training loss: 2.3893260955810547
Validation loss: 2.0897034124661515

Epoch: 6| Step: 3
Training loss: 1.8259227275848389
Validation loss: 2.069274394742904

Epoch: 6| Step: 4
Training loss: 1.5849745273590088
Validation loss: 2.051321659036862

Epoch: 6| Step: 5
Training loss: 2.3238396644592285
Validation loss: 2.018868218186081

Epoch: 6| Step: 6
Training loss: 1.9873987436294556
Validation loss: 2.038521748717113

Epoch: 6| Step: 7
Training loss: 1.8689237833023071
Validation loss: 2.0444940341416227

Epoch: 6| Step: 8
Training loss: 2.2932698726654053
Validation loss: 2.135932781363046

Epoch: 6| Step: 9
Training loss: 2.271118640899658
Validation loss: 2.1862337948173605

Epoch: 6| Step: 10
Training loss: 2.651792526245117
Validation loss: 2.177143491724486

Epoch: 6| Step: 11
Training loss: 1.9445902109146118
Validation loss: 2.172984392412247

Epoch: 6| Step: 12
Training loss: 2.297140121459961
Validation loss: 2.1367969000211327

Epoch: 6| Step: 13
Training loss: 2.438915967941284
Validation loss: 2.0380951204607562

Epoch: 206| Step: 0
Training loss: 2.185633420944214
Validation loss: 2.0306802693233696

Epoch: 6| Step: 1
Training loss: 2.1360692977905273
Validation loss: 2.0092474811820575

Epoch: 6| Step: 2
Training loss: 1.3979809284210205
Validation loss: 2.0289546123114963

Epoch: 6| Step: 3
Training loss: 2.7880520820617676
Validation loss: 2.0145089267402567

Epoch: 6| Step: 4
Training loss: 2.9038197994232178
Validation loss: 2.0303548946175525

Epoch: 6| Step: 5
Training loss: 1.594209909439087
Validation loss: 2.0139961229857577

Epoch: 6| Step: 6
Training loss: 1.9660272598266602
Validation loss: 1.9967787727232902

Epoch: 6| Step: 7
Training loss: 2.028104305267334
Validation loss: 2.0098994444775324

Epoch: 6| Step: 8
Training loss: 1.5988420248031616
Validation loss: 2.0167233200483423

Epoch: 6| Step: 9
Training loss: 0.9972931146621704
Validation loss: 2.0467784789300736

Epoch: 6| Step: 10
Training loss: 1.8346284627914429
Validation loss: 2.0820352364611883

Epoch: 6| Step: 11
Training loss: 2.2333130836486816
Validation loss: 2.1348267139927035

Epoch: 6| Step: 12
Training loss: 2.6687259674072266
Validation loss: 2.122441842991819

Epoch: 6| Step: 13
Training loss: 2.628920793533325
Validation loss: 2.1251403183065434

Epoch: 207| Step: 0
Training loss: 2.148157835006714
Validation loss: 2.0960458965711695

Epoch: 6| Step: 1
Training loss: 2.160543441772461
Validation loss: 2.0777212227544477

Epoch: 6| Step: 2
Training loss: 1.3889766931533813
Validation loss: 2.0519019493492703

Epoch: 6| Step: 3
Training loss: 1.8505369424819946
Validation loss: 2.0298590634458806

Epoch: 6| Step: 4
Training loss: 2.226794719696045
Validation loss: 2.024306853612264

Epoch: 6| Step: 5
Training loss: 2.548293113708496
Validation loss: 2.0241323747942523

Epoch: 6| Step: 6
Training loss: 1.853092908859253
Validation loss: 2.0014216643507763

Epoch: 6| Step: 7
Training loss: 2.1226627826690674
Validation loss: 2.0091087484872467

Epoch: 6| Step: 8
Training loss: 2.2259533405303955
Validation loss: 2.0159175344692764

Epoch: 6| Step: 9
Training loss: 2.1738247871398926
Validation loss: 2.050758615616829

Epoch: 6| Step: 10
Training loss: 2.7092854976654053
Validation loss: 2.0839673421716176

Epoch: 6| Step: 11
Training loss: 1.5347883701324463
Validation loss: 2.0764536755059355

Epoch: 6| Step: 12
Training loss: 2.0035910606384277
Validation loss: 2.0605106328123357

Epoch: 6| Step: 13
Training loss: 1.271746277809143
Validation loss: 2.058518140546737

Epoch: 208| Step: 0
Training loss: 2.6792373657226562
Validation loss: 2.0907824065095637

Epoch: 6| Step: 1
Training loss: 2.0035510063171387
Validation loss: 2.0851385183231805

Epoch: 6| Step: 2
Training loss: 1.7970467805862427
Validation loss: 2.089763761848532

Epoch: 6| Step: 3
Training loss: 1.7324395179748535
Validation loss: 2.1065409721866732

Epoch: 6| Step: 4
Training loss: 1.6690924167633057
Validation loss: 2.1085749249304495

Epoch: 6| Step: 5
Training loss: 2.1201820373535156
Validation loss: 2.105874123111848

Epoch: 6| Step: 6
Training loss: 2.3028035163879395
Validation loss: 2.120196016885901

Epoch: 6| Step: 7
Training loss: 2.443693161010742
Validation loss: 2.099522484246121

Epoch: 6| Step: 8
Training loss: 2.6929755210876465
Validation loss: 2.073770776871712

Epoch: 6| Step: 9
Training loss: 1.7724934816360474
Validation loss: 2.032881156090767

Epoch: 6| Step: 10
Training loss: 2.031163454055786
Validation loss: 2.0138776302337646

Epoch: 6| Step: 11
Training loss: 1.4133503437042236
Validation loss: 2.011666756804271

Epoch: 6| Step: 12
Training loss: 1.5761592388153076
Validation loss: 2.000844160715739

Epoch: 6| Step: 13
Training loss: 2.2000443935394287
Validation loss: 2.0261225008195445

Epoch: 209| Step: 0
Training loss: 1.370223045349121
Validation loss: 2.0177380090118735

Epoch: 6| Step: 1
Training loss: 2.08705997467041
Validation loss: 2.048496780856963

Epoch: 6| Step: 2
Training loss: 2.115842819213867
Validation loss: 2.073708006130752

Epoch: 6| Step: 3
Training loss: 2.5592050552368164
Validation loss: 2.0764222555263068

Epoch: 6| Step: 4
Training loss: 1.6795958280563354
Validation loss: 2.095722641996158

Epoch: 6| Step: 5
Training loss: 2.356616973876953
Validation loss: 2.079920013745626

Epoch: 6| Step: 6
Training loss: 2.303882122039795
Validation loss: 2.086848925518733

Epoch: 6| Step: 7
Training loss: 1.2916464805603027
Validation loss: 2.0960796340819328

Epoch: 6| Step: 8
Training loss: 1.5874247550964355
Validation loss: 2.0547810434013285

Epoch: 6| Step: 9
Training loss: 2.387847900390625
Validation loss: 2.041558265686035

Epoch: 6| Step: 10
Training loss: 1.9128289222717285
Validation loss: 2.0168200077549105

Epoch: 6| Step: 11
Training loss: 2.096012592315674
Validation loss: 2.0487605653783327

Epoch: 6| Step: 12
Training loss: 2.1032583713531494
Validation loss: 2.0252720271387408

Epoch: 6| Step: 13
Training loss: 2.137338638305664
Validation loss: 2.0392948632599204

Epoch: 210| Step: 0
Training loss: 1.987876296043396
Validation loss: 2.0721395566899288

Epoch: 6| Step: 1
Training loss: 1.620532512664795
Validation loss: 2.062897907790317

Epoch: 6| Step: 2
Training loss: 1.3053739070892334
Validation loss: 2.012874525080445

Epoch: 6| Step: 3
Training loss: 2.1380667686462402
Validation loss: 1.9968420049195648

Epoch: 6| Step: 4
Training loss: 2.067263603210449
Validation loss: 2.0253322406481673

Epoch: 6| Step: 5
Training loss: 1.8944761753082275
Validation loss: 2.0665874737565235

Epoch: 6| Step: 6
Training loss: 2.2786760330200195
Validation loss: 2.08953502357647

Epoch: 6| Step: 7
Training loss: 1.90474271774292
Validation loss: 2.1256326488269273

Epoch: 6| Step: 8
Training loss: 1.6725146770477295
Validation loss: 2.1523737625409196

Epoch: 6| Step: 9
Training loss: 2.368992805480957
Validation loss: 2.120377581606629

Epoch: 6| Step: 10
Training loss: 2.2798056602478027
Validation loss: 2.0599693995650097

Epoch: 6| Step: 11
Training loss: 2.7932775020599365
Validation loss: 2.0478750031481505

Epoch: 6| Step: 12
Training loss: 1.975191593170166
Validation loss: 2.0331285410029913

Epoch: 6| Step: 13
Training loss: 1.4476088285446167
Validation loss: 2.0669796236099733

Epoch: 211| Step: 0
Training loss: 1.7904466390609741
Validation loss: 2.0758871057982087

Epoch: 6| Step: 1
Training loss: 2.1596670150756836
Validation loss: 2.0683371456720496

Epoch: 6| Step: 2
Training loss: 2.947904586791992
Validation loss: 2.085283353764524

Epoch: 6| Step: 3
Training loss: 2.0470714569091797
Validation loss: 2.048941009788103

Epoch: 6| Step: 4
Training loss: 1.8753063678741455
Validation loss: 2.0569459648542505

Epoch: 6| Step: 5
Training loss: 1.7945090532302856
Validation loss: 2.0279802353151384

Epoch: 6| Step: 6
Training loss: 1.8221906423568726
Validation loss: 2.0127182006835938

Epoch: 6| Step: 7
Training loss: 1.863357663154602
Validation loss: 2.0404891762682187

Epoch: 6| Step: 8
Training loss: 2.2822248935699463
Validation loss: 2.0626247993079563

Epoch: 6| Step: 9
Training loss: 2.44942045211792
Validation loss: 2.106110885579099

Epoch: 6| Step: 10
Training loss: 1.7574529647827148
Validation loss: 2.1235150496164956

Epoch: 6| Step: 11
Training loss: 1.344456434249878
Validation loss: 2.101255948825549

Epoch: 6| Step: 12
Training loss: 2.246643543243408
Validation loss: 2.091904095424119

Epoch: 6| Step: 13
Training loss: 1.4236202239990234
Validation loss: 2.0543714787370417

Epoch: 212| Step: 0
Training loss: 1.6805458068847656
Validation loss: 2.035842377652404

Epoch: 6| Step: 1
Training loss: 1.9736528396606445
Validation loss: 2.023725845480478

Epoch: 6| Step: 2
Training loss: 1.9141404628753662
Validation loss: 2.0390566010628977

Epoch: 6| Step: 3
Training loss: 1.9677982330322266
Validation loss: 2.0284847879922516

Epoch: 6| Step: 4
Training loss: 2.448578357696533
Validation loss: 2.023736601234764

Epoch: 6| Step: 5
Training loss: 2.1401376724243164
Validation loss: 2.026445073466147

Epoch: 6| Step: 6
Training loss: 1.5468074083328247
Validation loss: 2.019130217131748

Epoch: 6| Step: 7
Training loss: 1.9997334480285645
Validation loss: 2.018915827556323

Epoch: 6| Step: 8
Training loss: 1.7972970008850098
Validation loss: 1.9977452396064677

Epoch: 6| Step: 9
Training loss: 1.413743257522583
Validation loss: 2.015697994539815

Epoch: 6| Step: 10
Training loss: 1.8610312938690186
Validation loss: 2.0322635276343233

Epoch: 6| Step: 11
Training loss: 1.918639898300171
Validation loss: 2.014311348238299

Epoch: 6| Step: 12
Training loss: 2.3552308082580566
Validation loss: 2.0153770805687032

Epoch: 6| Step: 13
Training loss: 2.7344412803649902
Validation loss: 1.980268314320554

Epoch: 213| Step: 0
Training loss: 2.038285493850708
Validation loss: 1.9950291572078582

Epoch: 6| Step: 1
Training loss: 2.120083808898926
Validation loss: 1.9966296995839765

Epoch: 6| Step: 2
Training loss: 2.0444655418395996
Validation loss: 2.0060293610377977

Epoch: 6| Step: 3
Training loss: 1.8045978546142578
Validation loss: 2.0230789530661797

Epoch: 6| Step: 4
Training loss: 1.7275255918502808
Validation loss: 2.0157536588689333

Epoch: 6| Step: 5
Training loss: 1.88356614112854
Validation loss: 2.034052311733205

Epoch: 6| Step: 6
Training loss: 1.5458717346191406
Validation loss: 2.0787566208070323

Epoch: 6| Step: 7
Training loss: 1.8083088397979736
Validation loss: 2.091593257842525

Epoch: 6| Step: 8
Training loss: 1.7967100143432617
Validation loss: 2.070916219424176

Epoch: 6| Step: 9
Training loss: 2.2227602005004883
Validation loss: 2.082772863808499

Epoch: 6| Step: 10
Training loss: 2.028721570968628
Validation loss: 2.0445900206924765

Epoch: 6| Step: 11
Training loss: 1.8653208017349243
Validation loss: 2.0446101939806374

Epoch: 6| Step: 12
Training loss: 2.1742496490478516
Validation loss: 2.01425108345606

Epoch: 6| Step: 13
Training loss: 2.809190511703491
Validation loss: 1.99095751905954

Epoch: 214| Step: 0
Training loss: 1.7803212404251099
Validation loss: 1.9819824593041533

Epoch: 6| Step: 1
Training loss: 1.8428077697753906
Validation loss: 1.9645625570768952

Epoch: 6| Step: 2
Training loss: 1.599453330039978
Validation loss: 1.9826535204405427

Epoch: 6| Step: 3
Training loss: 2.0405848026275635
Validation loss: 1.957765507441695

Epoch: 6| Step: 4
Training loss: 2.4158217906951904
Validation loss: 1.9718004401012132

Epoch: 6| Step: 5
Training loss: 1.5624206066131592
Validation loss: 1.9446664523052912

Epoch: 6| Step: 6
Training loss: 1.5940144062042236
Validation loss: 2.006266799024356

Epoch: 6| Step: 7
Training loss: 2.2172188758850098
Validation loss: 2.019609564094133

Epoch: 6| Step: 8
Training loss: 2.5834097862243652
Validation loss: 2.0899344490420435

Epoch: 6| Step: 9
Training loss: 2.362307071685791
Validation loss: 2.1166755666014967

Epoch: 6| Step: 10
Training loss: 1.6013295650482178
Validation loss: 2.1496495957015664

Epoch: 6| Step: 11
Training loss: 2.3374197483062744
Validation loss: 2.1631973815220658

Epoch: 6| Step: 12
Training loss: 2.0153841972351074
Validation loss: 2.1435465197409354

Epoch: 6| Step: 13
Training loss: 1.6274447441101074
Validation loss: 2.111564361920921

Epoch: 215| Step: 0
Training loss: 1.8066296577453613
Validation loss: 2.047365032216554

Epoch: 6| Step: 1
Training loss: 3.019956588745117
Validation loss: 2.051718875926028

Epoch: 6| Step: 2
Training loss: 2.2316455841064453
Validation loss: 2.0414681998632287

Epoch: 6| Step: 3
Training loss: 2.2793631553649902
Validation loss: 2.0396005671511412

Epoch: 6| Step: 4
Training loss: 2.1003952026367188
Validation loss: 2.0288196007410684

Epoch: 6| Step: 5
Training loss: 2.2499289512634277
Validation loss: 2.01297660796873

Epoch: 6| Step: 6
Training loss: 2.0924453735351562
Validation loss: 1.9963138744395266

Epoch: 6| Step: 7
Training loss: 2.364086151123047
Validation loss: 1.959510959604735

Epoch: 6| Step: 8
Training loss: 1.483656644821167
Validation loss: 1.9407707927047566

Epoch: 6| Step: 9
Training loss: 1.6898140907287598
Validation loss: 1.9400516633064515

Epoch: 6| Step: 10
Training loss: 1.1435574293136597
Validation loss: 1.9595594508673555

Epoch: 6| Step: 11
Training loss: 2.459226131439209
Validation loss: 2.0276474927061345

Epoch: 6| Step: 12
Training loss: 2.28016996383667
Validation loss: 2.0881362486911077

Epoch: 6| Step: 13
Training loss: 2.5927631855010986
Validation loss: 2.1293940403128184

Epoch: 216| Step: 0
Training loss: 2.8353171348571777
Validation loss: 2.105967539612965

Epoch: 6| Step: 1
Training loss: 2.783944845199585
Validation loss: 2.1134991338176112

Epoch: 6| Step: 2
Training loss: 1.8221538066864014
Validation loss: 2.100465518172069

Epoch: 6| Step: 3
Training loss: 1.7503948211669922
Validation loss: 2.0786726820853447

Epoch: 6| Step: 4
Training loss: 1.55729079246521
Validation loss: 2.1184587863183792

Epoch: 6| Step: 5
Training loss: 1.339237928390503
Validation loss: 2.136419939738448

Epoch: 6| Step: 6
Training loss: 1.975172519683838
Validation loss: 2.1460506044408327

Epoch: 6| Step: 7
Training loss: 2.3343400955200195
Validation loss: 2.145003705896357

Epoch: 6| Step: 8
Training loss: 2.6088485717773438
Validation loss: 2.1213146845499673

Epoch: 6| Step: 9
Training loss: 1.9014734029769897
Validation loss: 2.0434668602481967

Epoch: 6| Step: 10
Training loss: 1.948211431503296
Validation loss: 1.9831497310310282

Epoch: 6| Step: 11
Training loss: 2.453428030014038
Validation loss: 1.9439326678552935

Epoch: 6| Step: 12
Training loss: 1.5490436553955078
Validation loss: 1.9625324638940955

Epoch: 6| Step: 13
Training loss: 1.1084365844726562
Validation loss: 2.0002323991508892

Epoch: 217| Step: 0
Training loss: 2.380380630493164
Validation loss: 2.0273976633625646

Epoch: 6| Step: 1
Training loss: 2.037132978439331
Validation loss: 2.0169187643194713

Epoch: 6| Step: 2
Training loss: 1.8539409637451172
Validation loss: 2.026475647444366

Epoch: 6| Step: 3
Training loss: 1.4175240993499756
Validation loss: 2.006908929476174

Epoch: 6| Step: 4
Training loss: 2.2319812774658203
Validation loss: 2.001908258725238

Epoch: 6| Step: 5
Training loss: 1.7111687660217285
Validation loss: 2.026621121232228

Epoch: 6| Step: 6
Training loss: 2.0021777153015137
Validation loss: 2.077586066338324

Epoch: 6| Step: 7
Training loss: 2.101431369781494
Validation loss: 2.1139573179265505

Epoch: 6| Step: 8
Training loss: 1.3020559549331665
Validation loss: 2.130926170656758

Epoch: 6| Step: 9
Training loss: 2.021996021270752
Validation loss: 2.127521768693001

Epoch: 6| Step: 10
Training loss: 1.9754512310028076
Validation loss: 2.14719420607372

Epoch: 6| Step: 11
Training loss: 2.0111751556396484
Validation loss: 2.116777730244462

Epoch: 6| Step: 12
Training loss: 2.935384750366211
Validation loss: 2.084486151254305

Epoch: 6| Step: 13
Training loss: 1.6137837171554565
Validation loss: 2.056046880701537

Epoch: 218| Step: 0
Training loss: 1.2080187797546387
Validation loss: 2.042629700835033

Epoch: 6| Step: 1
Training loss: 1.6359621286392212
Validation loss: 2.022200071683494

Epoch: 6| Step: 2
Training loss: 3.0792508125305176
Validation loss: 2.028086708438012

Epoch: 6| Step: 3
Training loss: 2.1331682205200195
Validation loss: 2.004102135217318

Epoch: 6| Step: 4
Training loss: 1.7457501888275146
Validation loss: 2.0127156857521302

Epoch: 6| Step: 5
Training loss: 0.9155961275100708
Validation loss: 1.9823852803117485

Epoch: 6| Step: 6
Training loss: 2.112684726715088
Validation loss: 1.9900746217337988

Epoch: 6| Step: 7
Training loss: 2.488067626953125
Validation loss: 1.9739831929565759

Epoch: 6| Step: 8
Training loss: 1.801018476486206
Validation loss: 1.9785506879129717

Epoch: 6| Step: 9
Training loss: 1.8942325115203857
Validation loss: 1.9809735282774894

Epoch: 6| Step: 10
Training loss: 2.3968288898468018
Validation loss: 1.972670296187042

Epoch: 6| Step: 11
Training loss: 2.2460060119628906
Validation loss: 1.9881745999859226

Epoch: 6| Step: 12
Training loss: 2.284606456756592
Validation loss: 1.974540360512272

Epoch: 6| Step: 13
Training loss: 1.5960502624511719
Validation loss: 2.009498641055117

Epoch: 219| Step: 0
Training loss: 1.647297978401184
Validation loss: 1.9922087115626181

Epoch: 6| Step: 1
Training loss: 1.993889331817627
Validation loss: 2.0010767752124416

Epoch: 6| Step: 2
Training loss: 2.5327234268188477
Validation loss: 2.0275608698527017

Epoch: 6| Step: 3
Training loss: 1.613669514656067
Validation loss: 2.020543888051023

Epoch: 6| Step: 4
Training loss: 2.0562829971313477
Validation loss: 2.0209872286806823

Epoch: 6| Step: 5
Training loss: 1.9351553916931152
Validation loss: 1.9970530886803903

Epoch: 6| Step: 6
Training loss: 1.6346276998519897
Validation loss: 2.0008267023230113

Epoch: 6| Step: 7
Training loss: 1.6631001234054565
Validation loss: 2.0153236696797032

Epoch: 6| Step: 8
Training loss: 1.7853327989578247
Validation loss: 2.0316996523129043

Epoch: 6| Step: 9
Training loss: 1.9058170318603516
Validation loss: 2.061689105085147

Epoch: 6| Step: 10
Training loss: 2.6286323070526123
Validation loss: 2.1218986870140157

Epoch: 6| Step: 11
Training loss: 2.1952099800109863
Validation loss: 2.1077971791708343

Epoch: 6| Step: 12
Training loss: 1.7243869304656982
Validation loss: 2.0730632005199308

Epoch: 6| Step: 13
Training loss: 2.075009822845459
Validation loss: 2.0811545438663934

Epoch: 220| Step: 0
Training loss: 2.258617877960205
Validation loss: 2.0672209365393526

Epoch: 6| Step: 1
Training loss: 2.0724539756774902
Validation loss: 2.0542923904234365

Epoch: 6| Step: 2
Training loss: 1.5971546173095703
Validation loss: 2.0095745991635066

Epoch: 6| Step: 3
Training loss: 1.632875680923462
Validation loss: 2.029451588148712

Epoch: 6| Step: 4
Training loss: 1.9345593452453613
Validation loss: 2.011494998008974

Epoch: 6| Step: 5
Training loss: 2.2081923484802246
Validation loss: 2.006465345300654

Epoch: 6| Step: 6
Training loss: 1.7539105415344238
Validation loss: 2.0301413574526386

Epoch: 6| Step: 7
Training loss: 1.5180237293243408
Validation loss: 2.0515522315937984

Epoch: 6| Step: 8
Training loss: 1.7803407907485962
Validation loss: 2.0422607198838265

Epoch: 6| Step: 9
Training loss: 1.3859455585479736
Validation loss: 2.0587419027923257

Epoch: 6| Step: 10
Training loss: 2.2907629013061523
Validation loss: 2.032159620715726

Epoch: 6| Step: 11
Training loss: 2.184570789337158
Validation loss: 2.033227925659508

Epoch: 6| Step: 12
Training loss: 2.1422553062438965
Validation loss: 2.0338316912292154

Epoch: 6| Step: 13
Training loss: 2.3269736766815186
Validation loss: 2.0487065853611117

Epoch: 221| Step: 0
Training loss: 1.7554912567138672
Validation loss: 2.003913679430562

Epoch: 6| Step: 1
Training loss: 2.268904685974121
Validation loss: 2.003063440322876

Epoch: 6| Step: 2
Training loss: 2.4897799491882324
Validation loss: 2.0340329985464773

Epoch: 6| Step: 3
Training loss: 1.2201696634292603
Validation loss: 1.9843987572577693

Epoch: 6| Step: 4
Training loss: 1.2474935054779053
Validation loss: 1.9866683739487843

Epoch: 6| Step: 5
Training loss: 2.0634279251098633
Validation loss: 2.017311624301377

Epoch: 6| Step: 6
Training loss: 2.285114049911499
Validation loss: 2.011684747152431

Epoch: 6| Step: 7
Training loss: 1.9311606884002686
Validation loss: 2.0257801189217517

Epoch: 6| Step: 8
Training loss: 2.065664768218994
Validation loss: 2.0287439105331257

Epoch: 6| Step: 9
Training loss: 1.9850002527236938
Validation loss: 2.0533636718667965

Epoch: 6| Step: 10
Training loss: 1.7702312469482422
Validation loss: 2.069508660224176

Epoch: 6| Step: 11
Training loss: 2.085387706756592
Validation loss: 2.089962572179815

Epoch: 6| Step: 12
Training loss: 1.856364130973816
Validation loss: 2.092270484534643

Epoch: 6| Step: 13
Training loss: 1.541562557220459
Validation loss: 2.092669725418091

Epoch: 222| Step: 0
Training loss: 2.0097641944885254
Validation loss: 2.2051717414650867

Epoch: 6| Step: 1
Training loss: 1.9467377662658691
Validation loss: 2.320672027526363

Epoch: 6| Step: 2
Training loss: 1.8541836738586426
Validation loss: 2.3585667046167518

Epoch: 6| Step: 3
Training loss: 2.0996856689453125
Validation loss: 2.3327722087983163

Epoch: 6| Step: 4
Training loss: 2.5960450172424316
Validation loss: 2.2726224058417865

Epoch: 6| Step: 5
Training loss: 2.299877643585205
Validation loss: 2.172818204408051

Epoch: 6| Step: 6
Training loss: 1.9976458549499512
Validation loss: 2.0972004500768517

Epoch: 6| Step: 7
Training loss: 1.8673217296600342
Validation loss: 2.068676383264603

Epoch: 6| Step: 8
Training loss: 1.3248475790023804
Validation loss: 2.0177041997191725

Epoch: 6| Step: 9
Training loss: 1.6237516403198242
Validation loss: 2.045236954125025

Epoch: 6| Step: 10
Training loss: 2.1225292682647705
Validation loss: 2.058273425666235

Epoch: 6| Step: 11
Training loss: 2.06520938873291
Validation loss: 2.0337438955101916

Epoch: 6| Step: 12
Training loss: 2.284191608428955
Validation loss: 2.0024055742448374

Epoch: 6| Step: 13
Training loss: 2.119849920272827
Validation loss: 1.9770737014791018

Epoch: 223| Step: 0
Training loss: 1.431262731552124
Validation loss: 1.976678689320882

Epoch: 6| Step: 1
Training loss: 2.543259620666504
Validation loss: 1.9944066680887693

Epoch: 6| Step: 2
Training loss: 2.195060968399048
Validation loss: 1.972114501460906

Epoch: 6| Step: 3
Training loss: 2.0127060413360596
Validation loss: 1.9808170872349893

Epoch: 6| Step: 4
Training loss: 2.240868330001831
Validation loss: 2.003407193768409

Epoch: 6| Step: 5
Training loss: 1.9085335731506348
Validation loss: 2.0411134599357523

Epoch: 6| Step: 6
Training loss: 2.0982961654663086
Validation loss: 2.042014329664169

Epoch: 6| Step: 7
Training loss: 1.626697063446045
Validation loss: 2.0679620055742163

Epoch: 6| Step: 8
Training loss: 1.646338701248169
Validation loss: 2.0802556583958287

Epoch: 6| Step: 9
Training loss: 1.965552806854248
Validation loss: 2.0716390032922067

Epoch: 6| Step: 10
Training loss: 2.357186794281006
Validation loss: 2.0758712035353466

Epoch: 6| Step: 11
Training loss: 1.4739534854888916
Validation loss: 2.071981801781603

Epoch: 6| Step: 12
Training loss: 1.3722715377807617
Validation loss: 2.0701247415234967

Epoch: 6| Step: 13
Training loss: 2.4839024543762207
Validation loss: 2.070269433400964

Epoch: 224| Step: 0
Training loss: 2.082167625427246
Validation loss: 2.059191188504619

Epoch: 6| Step: 1
Training loss: 1.4845308065414429
Validation loss: 2.0541220967487623

Epoch: 6| Step: 2
Training loss: 2.186128854751587
Validation loss: 2.009175423652895

Epoch: 6| Step: 3
Training loss: 2.0915169715881348
Validation loss: 2.02498609019864

Epoch: 6| Step: 4
Training loss: 0.9678899645805359
Validation loss: 2.0471012515406453

Epoch: 6| Step: 5
Training loss: 2.6942434310913086
Validation loss: 2.0436584975129817

Epoch: 6| Step: 6
Training loss: 1.2230199575424194
Validation loss: 2.036361348244452

Epoch: 6| Step: 7
Training loss: 1.6950099468231201
Validation loss: 2.003796677435598

Epoch: 6| Step: 8
Training loss: 1.973440170288086
Validation loss: 2.0041376288219164

Epoch: 6| Step: 9
Training loss: 1.9149445295333862
Validation loss: 1.98655487901421

Epoch: 6| Step: 10
Training loss: 2.3543357849121094
Validation loss: 2.000146265952818

Epoch: 6| Step: 11
Training loss: 2.1216611862182617
Validation loss: 1.9943015319044872

Epoch: 6| Step: 12
Training loss: 1.8279935121536255
Validation loss: 2.0407301136242446

Epoch: 6| Step: 13
Training loss: 1.6579655408859253
Validation loss: 2.0615652684242494

Epoch: 225| Step: 0
Training loss: 2.0367326736450195
Validation loss: 2.091327490345124

Epoch: 6| Step: 1
Training loss: 1.5419749021530151
Validation loss: 2.065498004677475

Epoch: 6| Step: 2
Training loss: 1.9885437488555908
Validation loss: 2.0492982749016053

Epoch: 6| Step: 3
Training loss: 1.5074292421340942
Validation loss: 2.0599246627540997

Epoch: 6| Step: 4
Training loss: 1.5143494606018066
Validation loss: 2.0785744626034974

Epoch: 6| Step: 5
Training loss: 2.0685248374938965
Validation loss: 2.0871037975434334

Epoch: 6| Step: 6
Training loss: 1.578707218170166
Validation loss: 2.0926374145733413

Epoch: 6| Step: 7
Training loss: 1.5906190872192383
Validation loss: 2.1100027535551336

Epoch: 6| Step: 8
Training loss: 2.300299882888794
Validation loss: 2.12182278274208

Epoch: 6| Step: 9
Training loss: 2.0673036575317383
Validation loss: 2.1174316508795625

Epoch: 6| Step: 10
Training loss: 2.0482687950134277
Validation loss: 2.0631445043830463

Epoch: 6| Step: 11
Training loss: 1.8702898025512695
Validation loss: 2.034012258693736

Epoch: 6| Step: 12
Training loss: 2.434476852416992
Validation loss: 2.0450269535023677

Epoch: 6| Step: 13
Training loss: 2.517298460006714
Validation loss: 2.0314417564740745

Epoch: 226| Step: 0
Training loss: 1.5418109893798828
Validation loss: 2.0229772085784585

Epoch: 6| Step: 1
Training loss: 2.747605800628662
Validation loss: 2.021683774968629

Epoch: 6| Step: 2
Training loss: 2.472602128982544
Validation loss: 2.0283525502809914

Epoch: 6| Step: 3
Training loss: 2.6132802963256836
Validation loss: 2.041400712023499

Epoch: 6| Step: 4
Training loss: 1.8518321514129639
Validation loss: 2.0424784345011555

Epoch: 6| Step: 5
Training loss: 0.7667231559753418
Validation loss: 2.0727224144884335

Epoch: 6| Step: 6
Training loss: 1.5523148775100708
Validation loss: 2.0480169532119588

Epoch: 6| Step: 7
Training loss: 1.8671795129776
Validation loss: 2.091934077201351

Epoch: 6| Step: 8
Training loss: 2.1998178958892822
Validation loss: 2.111114655771563

Epoch: 6| Step: 9
Training loss: 1.9074633121490479
Validation loss: 2.097067545819026

Epoch: 6| Step: 10
Training loss: 1.273008108139038
Validation loss: 2.073403784023818

Epoch: 6| Step: 11
Training loss: 1.322266697883606
Validation loss: 2.1027982081136396

Epoch: 6| Step: 12
Training loss: 2.568392753601074
Validation loss: 2.105090497642435

Epoch: 6| Step: 13
Training loss: 1.8135225772857666
Validation loss: 2.1167895358095885

Epoch: 227| Step: 0
Training loss: 1.5204455852508545
Validation loss: 2.056241450771209

Epoch: 6| Step: 1
Training loss: 2.030135154724121
Validation loss: 2.0036367985510055

Epoch: 6| Step: 2
Training loss: 2.0592598915100098
Validation loss: 2.0217523010828162

Epoch: 6| Step: 3
Training loss: 1.9278055429458618
Validation loss: 1.9983479348562097

Epoch: 6| Step: 4
Training loss: 2.4382340908050537
Validation loss: 2.0090620210093837

Epoch: 6| Step: 5
Training loss: 2.107720136642456
Validation loss: 2.0366786577368297

Epoch: 6| Step: 6
Training loss: 2.2256131172180176
Validation loss: 2.0160792489205637

Epoch: 6| Step: 7
Training loss: 1.7981209754943848
Validation loss: 2.0087798141664073

Epoch: 6| Step: 8
Training loss: 2.1447973251342773
Validation loss: 1.9796006987171788

Epoch: 6| Step: 9
Training loss: 2.0166494846343994
Validation loss: 1.9650687761204217

Epoch: 6| Step: 10
Training loss: 1.9239051342010498
Validation loss: 2.0119157427100727

Epoch: 6| Step: 11
Training loss: 1.6074550151824951
Validation loss: 2.016754288827219

Epoch: 6| Step: 12
Training loss: 1.7328200340270996
Validation loss: 1.9913621999884163

Epoch: 6| Step: 13
Training loss: 1.4848122596740723
Validation loss: 2.0652590567065823

Epoch: 228| Step: 0
Training loss: 3.140763282775879
Validation loss: 2.1173431834866925

Epoch: 6| Step: 1
Training loss: 2.14548921585083
Validation loss: 2.1783823954161776

Epoch: 6| Step: 2
Training loss: 1.9630815982818604
Validation loss: 2.152652702023906

Epoch: 6| Step: 3
Training loss: 2.456773519515991
Validation loss: 2.0613687140967256

Epoch: 6| Step: 4
Training loss: 1.5833852291107178
Validation loss: 2.0142473815589823

Epoch: 6| Step: 5
Training loss: 1.8139081001281738
Validation loss: 2.006369895832513

Epoch: 6| Step: 6
Training loss: 1.5845627784729004
Validation loss: 1.9951101669701197

Epoch: 6| Step: 7
Training loss: 1.7530821561813354
Validation loss: 2.012390803265315

Epoch: 6| Step: 8
Training loss: 1.5546000003814697
Validation loss: 2.0215798629227506

Epoch: 6| Step: 9
Training loss: 1.79368257522583
Validation loss: 2.0617909418639315

Epoch: 6| Step: 10
Training loss: 1.7983049154281616
Validation loss: 2.0676149040140133

Epoch: 6| Step: 11
Training loss: 1.962172508239746
Validation loss: 2.0863278450504428

Epoch: 6| Step: 12
Training loss: 1.7647356986999512
Validation loss: 2.076374443628455

Epoch: 6| Step: 13
Training loss: 1.3737343549728394
Validation loss: 2.0864737597844933

Epoch: 229| Step: 0
Training loss: 1.7429760694503784
Validation loss: 2.1252464376470095

Epoch: 6| Step: 1
Training loss: 1.993636965751648
Validation loss: 2.140986465638684

Epoch: 6| Step: 2
Training loss: 1.9182236194610596
Validation loss: 2.102686526954815

Epoch: 6| Step: 3
Training loss: 1.8435808420181274
Validation loss: 2.125762936889484

Epoch: 6| Step: 4
Training loss: 2.4513466358184814
Validation loss: 2.1076831625353907

Epoch: 6| Step: 5
Training loss: 1.9653041362762451
Validation loss: 2.1001966255967335

Epoch: 6| Step: 6
Training loss: 2.6020541191101074
Validation loss: 2.0948036511739097

Epoch: 6| Step: 7
Training loss: 1.700950026512146
Validation loss: 2.056525471389935

Epoch: 6| Step: 8
Training loss: 0.7259970903396606
Validation loss: 2.0570203617054927

Epoch: 6| Step: 9
Training loss: 1.8257558345794678
Validation loss: 2.097763107668969

Epoch: 6| Step: 10
Training loss: 1.897902250289917
Validation loss: 2.0657787194816013

Epoch: 6| Step: 11
Training loss: 1.627246379852295
Validation loss: 2.0704017723760297

Epoch: 6| Step: 12
Training loss: 2.2219767570495605
Validation loss: 2.0704005469558058

Epoch: 6| Step: 13
Training loss: 1.6946909427642822
Validation loss: 2.0503371800145795

Epoch: 230| Step: 0
Training loss: 2.119248390197754
Validation loss: 2.0398154579183108

Epoch: 6| Step: 1
Training loss: 1.498943567276001
Validation loss: 2.0551156561861754

Epoch: 6| Step: 2
Training loss: 1.2953886985778809
Validation loss: 2.0215891176654446

Epoch: 6| Step: 3
Training loss: 1.6632251739501953
Validation loss: 2.0593181335797874

Epoch: 6| Step: 4
Training loss: 1.409895658493042
Validation loss: 2.045211298491365

Epoch: 6| Step: 5
Training loss: 1.9577453136444092
Validation loss: 2.0908251757262857

Epoch: 6| Step: 6
Training loss: 2.4745163917541504
Validation loss: 2.0730469149927937

Epoch: 6| Step: 7
Training loss: 1.997967004776001
Validation loss: 2.0224111823625464

Epoch: 6| Step: 8
Training loss: 2.1242032051086426
Validation loss: 2.0483058832025014

Epoch: 6| Step: 9
Training loss: 2.54128360748291
Validation loss: 2.033200369086317

Epoch: 6| Step: 10
Training loss: 1.845216989517212
Validation loss: 2.0590831464336765

Epoch: 6| Step: 11
Training loss: 1.9661128520965576
Validation loss: 2.0362093217911257

Epoch: 6| Step: 12
Training loss: 1.5094377994537354
Validation loss: 2.0464591198070075

Epoch: 6| Step: 13
Training loss: 1.7227509021759033
Validation loss: 2.064230513829057

Epoch: 231| Step: 0
Training loss: 1.1295592784881592
Validation loss: 2.022786594206287

Epoch: 6| Step: 1
Training loss: 2.318887710571289
Validation loss: 2.0310987605843493

Epoch: 6| Step: 2
Training loss: 1.8508689403533936
Validation loss: 2.0297934163001274

Epoch: 6| Step: 3
Training loss: 2.020552396774292
Validation loss: 2.0212069839559574

Epoch: 6| Step: 4
Training loss: 1.97195565700531
Validation loss: 2.0279977642079836

Epoch: 6| Step: 5
Training loss: 1.2348637580871582
Validation loss: 2.064157485961914

Epoch: 6| Step: 6
Training loss: 1.8612648248672485
Validation loss: 2.0953167817925893

Epoch: 6| Step: 7
Training loss: 2.155160903930664
Validation loss: 2.0747169294664936

Epoch: 6| Step: 8
Training loss: 2.0837297439575195
Validation loss: 2.065086139145718

Epoch: 6| Step: 9
Training loss: 1.7199500799179077
Validation loss: 2.0887605015949537

Epoch: 6| Step: 10
Training loss: 1.4465014934539795
Validation loss: 2.05163985683072

Epoch: 6| Step: 11
Training loss: 2.0264534950256348
Validation loss: 2.085131024801603

Epoch: 6| Step: 12
Training loss: 2.212407112121582
Validation loss: 2.0442544388514694

Epoch: 6| Step: 13
Training loss: 1.8014140129089355
Validation loss: 2.054736911609609

Epoch: 232| Step: 0
Training loss: 1.9200950860977173
Validation loss: 2.0557659492697766

Epoch: 6| Step: 1
Training loss: 2.0260887145996094
Validation loss: 2.0565807870639268

Epoch: 6| Step: 2
Training loss: 1.7879772186279297
Validation loss: 2.0568937998945995

Epoch: 6| Step: 3
Training loss: 1.851517677307129
Validation loss: 2.074858114283572

Epoch: 6| Step: 4
Training loss: 2.032520294189453
Validation loss: 2.073642474348827

Epoch: 6| Step: 5
Training loss: 1.2779018878936768
Validation loss: 2.098526206067813

Epoch: 6| Step: 6
Training loss: 1.7918486595153809
Validation loss: 2.0489640158991658

Epoch: 6| Step: 7
Training loss: 2.0217390060424805
Validation loss: 2.053113801504976

Epoch: 6| Step: 8
Training loss: 1.279250144958496
Validation loss: 2.007395707150941

Epoch: 6| Step: 9
Training loss: 2.1033401489257812
Validation loss: 1.979642488623178

Epoch: 6| Step: 10
Training loss: 2.041166305541992
Validation loss: 1.9862148197748328

Epoch: 6| Step: 11
Training loss: 1.9233360290527344
Validation loss: 1.9725882571230653

Epoch: 6| Step: 12
Training loss: 1.9874229431152344
Validation loss: 1.9696622792110647

Epoch: 6| Step: 13
Training loss: 1.5016664266586304
Validation loss: 1.9790694059864167

Epoch: 233| Step: 0
Training loss: 1.4525961875915527
Validation loss: 2.017145279915102

Epoch: 6| Step: 1
Training loss: 2.241095542907715
Validation loss: 2.0682373303239063

Epoch: 6| Step: 2
Training loss: 2.217470645904541
Validation loss: 2.0754990013696815

Epoch: 6| Step: 3
Training loss: 1.9402029514312744
Validation loss: 2.043808401271861

Epoch: 6| Step: 4
Training loss: 1.397108793258667
Validation loss: 2.0526940002236316

Epoch: 6| Step: 5
Training loss: 1.6433907747268677
Validation loss: 2.050733963648478

Epoch: 6| Step: 6
Training loss: 2.4209952354431152
Validation loss: 2.081936679860597

Epoch: 6| Step: 7
Training loss: 1.9557058811187744
Validation loss: 2.0456743624902542

Epoch: 6| Step: 8
Training loss: 1.8623895645141602
Validation loss: 2.0155567020498295

Epoch: 6| Step: 9
Training loss: 2.4155685901641846
Validation loss: 2.006862381453155

Epoch: 6| Step: 10
Training loss: 1.4294545650482178
Validation loss: 2.036190894342238

Epoch: 6| Step: 11
Training loss: 1.4259454011917114
Validation loss: 2.021971280856799

Epoch: 6| Step: 12
Training loss: 2.0160772800445557
Validation loss: 2.0318832320551716

Epoch: 6| Step: 13
Training loss: 1.7257589101791382
Validation loss: 2.026207757252519

Epoch: 234| Step: 0
Training loss: 1.5149565935134888
Validation loss: 2.030446019223941

Epoch: 6| Step: 1
Training loss: 2.192565441131592
Validation loss: 2.0269540432960755

Epoch: 6| Step: 2
Training loss: 1.9880902767181396
Validation loss: 2.018893277773293

Epoch: 6| Step: 3
Training loss: 2.226206064224243
Validation loss: 2.0299540963224185

Epoch: 6| Step: 4
Training loss: 1.6785390377044678
Validation loss: 2.0431008031291347

Epoch: 6| Step: 5
Training loss: 1.3722635507583618
Validation loss: 2.0397028282124507

Epoch: 6| Step: 6
Training loss: 2.310588836669922
Validation loss: 2.048494223625429

Epoch: 6| Step: 7
Training loss: 2.218972682952881
Validation loss: 2.0460697694491317

Epoch: 6| Step: 8
Training loss: 1.8559880256652832
Validation loss: 2.0089904082718717

Epoch: 6| Step: 9
Training loss: 1.3974097967147827
Validation loss: 1.989167856913741

Epoch: 6| Step: 10
Training loss: 1.738560438156128
Validation loss: 2.015964044037686

Epoch: 6| Step: 11
Training loss: 2.4552841186523438
Validation loss: 2.0311704579220025

Epoch: 6| Step: 12
Training loss: 1.1133184432983398
Validation loss: 2.03280302786058

Epoch: 6| Step: 13
Training loss: 1.8389906883239746
Validation loss: 2.030148611273817

Epoch: 235| Step: 0
Training loss: 2.1586194038391113
Validation loss: 2.0109708591174056

Epoch: 6| Step: 1
Training loss: 1.9162460565567017
Validation loss: 2.015204116862307

Epoch: 6| Step: 2
Training loss: 2.6544601917266846
Validation loss: 2.0065952167716077

Epoch: 6| Step: 3
Training loss: 1.2772282361984253
Validation loss: 2.0044498892240625

Epoch: 6| Step: 4
Training loss: 1.4837210178375244
Validation loss: 1.9912195513325353

Epoch: 6| Step: 5
Training loss: 2.5249834060668945
Validation loss: 1.9933943492110058

Epoch: 6| Step: 6
Training loss: 1.3464722633361816
Validation loss: 2.0049150169536634

Epoch: 6| Step: 7
Training loss: 1.7498605251312256
Validation loss: 1.992224972735169

Epoch: 6| Step: 8
Training loss: 1.1625359058380127
Validation loss: 1.9963649062700168

Epoch: 6| Step: 9
Training loss: 1.9476908445358276
Validation loss: 1.9985850921241186

Epoch: 6| Step: 10
Training loss: 1.957137107849121
Validation loss: 2.0425714010833413

Epoch: 6| Step: 11
Training loss: 2.127290725708008
Validation loss: 2.0600890574916715

Epoch: 6| Step: 12
Training loss: 1.4841388463974
Validation loss: 2.0878511782615417

Epoch: 6| Step: 13
Training loss: 1.5850601196289062
Validation loss: 2.1206335636877243

Epoch: 236| Step: 0
Training loss: 2.3601417541503906
Validation loss: 2.109032496329277

Epoch: 6| Step: 1
Training loss: 2.3658714294433594
Validation loss: 2.09377263181953

Epoch: 6| Step: 2
Training loss: 1.5022655725479126
Validation loss: 2.079711385952529

Epoch: 6| Step: 3
Training loss: 1.8046046495437622
Validation loss: 2.0549335197735856

Epoch: 6| Step: 4
Training loss: 2.195608615875244
Validation loss: 2.048524228475427

Epoch: 6| Step: 5
Training loss: 2.0655136108398438
Validation loss: 1.9985300802415418

Epoch: 6| Step: 6
Training loss: 2.3501384258270264
Validation loss: 1.9735753882315852

Epoch: 6| Step: 7
Training loss: 1.4496586322784424
Validation loss: 1.9813481133471254

Epoch: 6| Step: 8
Training loss: 1.3132117986679077
Validation loss: 1.9928203923727876

Epoch: 6| Step: 9
Training loss: 2.1789565086364746
Validation loss: 1.9915936505922707

Epoch: 6| Step: 10
Training loss: 1.9590295553207397
Validation loss: 1.9931333629033898

Epoch: 6| Step: 11
Training loss: 1.375514268875122
Validation loss: 1.9985485307631954

Epoch: 6| Step: 12
Training loss: 1.702852725982666
Validation loss: 2.016968716857254

Epoch: 6| Step: 13
Training loss: 1.447501540184021
Validation loss: 2.043470451908727

Epoch: 237| Step: 0
Training loss: 1.6902399063110352
Validation loss: 2.0736162470233057

Epoch: 6| Step: 1
Training loss: 1.230982780456543
Validation loss: 2.1139899261536135

Epoch: 6| Step: 2
Training loss: 1.7849242687225342
Validation loss: 2.2259336274157286

Epoch: 6| Step: 3
Training loss: 2.534789562225342
Validation loss: 2.319866867475612

Epoch: 6| Step: 4
Training loss: 1.9554957151412964
Validation loss: 2.319616961222823

Epoch: 6| Step: 5
Training loss: 1.3437936305999756
Validation loss: 2.314261298025808

Epoch: 6| Step: 6
Training loss: 2.096531867980957
Validation loss: 2.2848968582768596

Epoch: 6| Step: 7
Training loss: 1.6223182678222656
Validation loss: 2.258776628842918

Epoch: 6| Step: 8
Training loss: 1.3199164867401123
Validation loss: 2.194424169037932

Epoch: 6| Step: 9
Training loss: 2.64078950881958
Validation loss: 2.139661837649602

Epoch: 6| Step: 10
Training loss: 1.1030116081237793
Validation loss: 2.0439165971612416

Epoch: 6| Step: 11
Training loss: 2.005162239074707
Validation loss: 2.0338067329058083

Epoch: 6| Step: 12
Training loss: 2.149473190307617
Validation loss: 2.006547943238289

Epoch: 6| Step: 13
Training loss: 3.2697038650512695
Validation loss: 1.984014887963572

Epoch: 238| Step: 0
Training loss: 1.9440420866012573
Validation loss: 1.975509642272867

Epoch: 6| Step: 1
Training loss: 2.3366453647613525
Validation loss: 1.9601374928669264

Epoch: 6| Step: 2
Training loss: 2.4413421154022217
Validation loss: 1.9472798865328553

Epoch: 6| Step: 3
Training loss: 1.7573809623718262
Validation loss: 1.9303133128791727

Epoch: 6| Step: 4
Training loss: 2.48310923576355
Validation loss: 1.9489573945281327

Epoch: 6| Step: 5
Training loss: 2.0591492652893066
Validation loss: 1.9033857237908147

Epoch: 6| Step: 6
Training loss: 2.4433226585388184
Validation loss: 1.9114597753811908

Epoch: 6| Step: 7
Training loss: 2.3098442554473877
Validation loss: 1.919937172243672

Epoch: 6| Step: 8
Training loss: 1.7872097492218018
Validation loss: 1.9363322052904355

Epoch: 6| Step: 9
Training loss: 1.7695817947387695
Validation loss: 1.9924822110001759

Epoch: 6| Step: 10
Training loss: 1.8335292339324951
Validation loss: 2.0314027365817817

Epoch: 6| Step: 11
Training loss: 1.4274672269821167
Validation loss: 2.1202125113497496

Epoch: 6| Step: 12
Training loss: 1.4803316593170166
Validation loss: 2.128140969942975

Epoch: 6| Step: 13
Training loss: 1.8848241567611694
Validation loss: 2.2261395364679317

Epoch: 239| Step: 0
Training loss: 2.4131648540496826
Validation loss: 2.2143514361432803

Epoch: 6| Step: 1
Training loss: 2.722679615020752
Validation loss: 2.1835533906054754

Epoch: 6| Step: 2
Training loss: 1.352628469467163
Validation loss: 2.120111514163274

Epoch: 6| Step: 3
Training loss: 1.3300023078918457
Validation loss: 2.0534070153390207

Epoch: 6| Step: 4
Training loss: 2.0360913276672363
Validation loss: 2.07610930678665

Epoch: 6| Step: 5
Training loss: 2.7898287773132324
Validation loss: 2.086891076898062

Epoch: 6| Step: 6
Training loss: 3.18088698387146
Validation loss: 2.1036568764717347

Epoch: 6| Step: 7
Training loss: 2.2901980876922607
Validation loss: 2.1110364608867194

Epoch: 6| Step: 8
Training loss: 1.3634064197540283
Validation loss: 2.0938266887459704

Epoch: 6| Step: 9
Training loss: 1.9273014068603516
Validation loss: 2.0490959177735033

Epoch: 6| Step: 10
Training loss: 1.942844271659851
Validation loss: 2.0136458117474794

Epoch: 6| Step: 11
Training loss: 2.1375818252563477
Validation loss: 1.9966245594845022

Epoch: 6| Step: 12
Training loss: 1.6560194492340088
Validation loss: 1.9751225030550392

Epoch: 6| Step: 13
Training loss: 0.6851131916046143
Validation loss: 1.9913325899390764

Epoch: 240| Step: 0
Training loss: 1.6892399787902832
Validation loss: 2.025020573728828

Epoch: 6| Step: 1
Training loss: 1.5460584163665771
Validation loss: 2.1145481935111423

Epoch: 6| Step: 2
Training loss: 1.754130482673645
Validation loss: 2.1645818102744316

Epoch: 6| Step: 3
Training loss: 2.4509997367858887
Validation loss: 2.191356925554173

Epoch: 6| Step: 4
Training loss: 3.2124900817871094
Validation loss: 2.169051662568123

Epoch: 6| Step: 5
Training loss: 1.528310775756836
Validation loss: 2.138819068990728

Epoch: 6| Step: 6
Training loss: 1.8668782711029053
Validation loss: 2.119628075630434

Epoch: 6| Step: 7
Training loss: 1.4688271284103394
Validation loss: 2.0995506612203454

Epoch: 6| Step: 8
Training loss: 2.304218292236328
Validation loss: 2.081757656989559

Epoch: 6| Step: 9
Training loss: 1.5419232845306396
Validation loss: 2.0710699673621886

Epoch: 6| Step: 10
Training loss: 1.9380872249603271
Validation loss: 2.055155877144106

Epoch: 6| Step: 11
Training loss: 1.762033224105835
Validation loss: 2.0618386319888535

Epoch: 6| Step: 12
Training loss: 1.722893476486206
Validation loss: 2.0822957331134426

Epoch: 6| Step: 13
Training loss: 2.046128749847412
Validation loss: 2.0680110928832844

Epoch: 241| Step: 0
Training loss: 2.2261061668395996
Validation loss: 2.019621281213658

Epoch: 6| Step: 1
Training loss: 1.2399754524230957
Validation loss: 1.9986635305548226

Epoch: 6| Step: 2
Training loss: 1.968802571296692
Validation loss: 1.9672829681827175

Epoch: 6| Step: 3
Training loss: 2.051846981048584
Validation loss: 2.0079421407432965

Epoch: 6| Step: 4
Training loss: 1.7936737537384033
Validation loss: 2.050000524008146

Epoch: 6| Step: 5
Training loss: 2.46633243560791
Validation loss: 2.102023616913826

Epoch: 6| Step: 6
Training loss: 2.3277175426483154
Validation loss: 2.1440301146558536

Epoch: 6| Step: 7
Training loss: 1.8796911239624023
Validation loss: 2.1992768587604647

Epoch: 6| Step: 8
Training loss: 2.3627514839172363
Validation loss: 2.1580044300325456

Epoch: 6| Step: 9
Training loss: 1.9251160621643066
Validation loss: 2.0811480501646638

Epoch: 6| Step: 10
Training loss: 1.7839720249176025
Validation loss: 2.0552501037556636

Epoch: 6| Step: 11
Training loss: 0.9263321757316589
Validation loss: 2.0220798215558453

Epoch: 6| Step: 12
Training loss: 1.884972333908081
Validation loss: 2.0603838056646366

Epoch: 6| Step: 13
Training loss: 1.9486844539642334
Validation loss: 2.0937299523302304

Epoch: 242| Step: 0
Training loss: 2.4014065265655518
Validation loss: 2.097317090598486

Epoch: 6| Step: 1
Training loss: 1.474295973777771
Validation loss: 2.1197248838281118

Epoch: 6| Step: 2
Training loss: 2.0362191200256348
Validation loss: 2.1389725541555755

Epoch: 6| Step: 3
Training loss: 1.5899592638015747
Validation loss: 2.109609128326498

Epoch: 6| Step: 4
Training loss: 1.8704278469085693
Validation loss: 2.084660791581677

Epoch: 6| Step: 5
Training loss: 1.3589094877243042
Validation loss: 2.07812395147098

Epoch: 6| Step: 6
Training loss: 1.7802467346191406
Validation loss: 2.0724180013902727

Epoch: 6| Step: 7
Training loss: 1.7782988548278809
Validation loss: 2.1000664464889036

Epoch: 6| Step: 8
Training loss: 1.900345802307129
Validation loss: 2.0778834678793467

Epoch: 6| Step: 9
Training loss: 2.156115770339966
Validation loss: 2.094101144421485

Epoch: 6| Step: 10
Training loss: 2.1157784461975098
Validation loss: 2.0803408930378575

Epoch: 6| Step: 11
Training loss: 2.5539767742156982
Validation loss: 1.9836598019446097

Epoch: 6| Step: 12
Training loss: 1.8481371402740479
Validation loss: 1.9780407221086564

Epoch: 6| Step: 13
Training loss: 1.5345698595046997
Validation loss: 1.9548325141270955

Epoch: 243| Step: 0
Training loss: 1.5748341083526611
Validation loss: 1.9634019136428833

Epoch: 6| Step: 1
Training loss: 1.4902470111846924
Validation loss: 1.9461277325948079

Epoch: 6| Step: 2
Training loss: 1.7950340509414673
Validation loss: 1.9526157020240702

Epoch: 6| Step: 3
Training loss: 2.6003007888793945
Validation loss: 1.9637529439823602

Epoch: 6| Step: 4
Training loss: 2.3863284587860107
Validation loss: 2.00163132913651

Epoch: 6| Step: 5
Training loss: 1.9974325895309448
Validation loss: 2.0227235401830366

Epoch: 6| Step: 6
Training loss: 1.4440908432006836
Validation loss: 2.0562117753490323

Epoch: 6| Step: 7
Training loss: 2.854517936706543
Validation loss: 2.1259658951913156

Epoch: 6| Step: 8
Training loss: 2.4342918395996094
Validation loss: 2.153462484318723

Epoch: 6| Step: 9
Training loss: 1.0459210872650146
Validation loss: 2.1671561618005075

Epoch: 6| Step: 10
Training loss: 1.1131258010864258
Validation loss: 2.1396216730917654

Epoch: 6| Step: 11
Training loss: 2.554276466369629
Validation loss: 2.0884025353257374

Epoch: 6| Step: 12
Training loss: 1.3684513568878174
Validation loss: 2.086713634511476

Epoch: 6| Step: 13
Training loss: 1.0742751359939575
Validation loss: 2.069698146594468

Epoch: 244| Step: 0
Training loss: 2.5001485347747803
Validation loss: 2.0167862676805064

Epoch: 6| Step: 1
Training loss: 1.397684097290039
Validation loss: 2.0414363248373872

Epoch: 6| Step: 2
Training loss: 2.3665754795074463
Validation loss: 2.0027443439729753

Epoch: 6| Step: 3
Training loss: 1.381242036819458
Validation loss: 1.9913741439901373

Epoch: 6| Step: 4
Training loss: 1.8644839525222778
Validation loss: 1.986371422326693

Epoch: 6| Step: 5
Training loss: 1.5959731340408325
Validation loss: 1.9705868485153362

Epoch: 6| Step: 6
Training loss: 1.8151328563690186
Validation loss: 1.9724879713468655

Epoch: 6| Step: 7
Training loss: 1.9273113012313843
Validation loss: 1.981285782270534

Epoch: 6| Step: 8
Training loss: 1.6310096979141235
Validation loss: 1.9872671775920416

Epoch: 6| Step: 9
Training loss: 1.6338262557983398
Validation loss: 2.0074868330391507

Epoch: 6| Step: 10
Training loss: 1.598061203956604
Validation loss: 2.051628497339064

Epoch: 6| Step: 11
Training loss: 2.2571303844451904
Validation loss: 2.0624721127171672

Epoch: 6| Step: 12
Training loss: 1.5501999855041504
Validation loss: 2.120809316635132

Epoch: 6| Step: 13
Training loss: 1.399390697479248
Validation loss: 2.149784998227191

Epoch: 245| Step: 0
Training loss: 1.7412440776824951
Validation loss: 2.1432728254666893

Epoch: 6| Step: 1
Training loss: 1.052506923675537
Validation loss: 2.1648223143751903

Epoch: 6| Step: 2
Training loss: 1.9942305088043213
Validation loss: 2.1899010853100846

Epoch: 6| Step: 3
Training loss: 2.0991926193237305
Validation loss: 2.200016435756478

Epoch: 6| Step: 4
Training loss: 2.260911226272583
Validation loss: 2.153232859027001

Epoch: 6| Step: 5
Training loss: 1.7447679042816162
Validation loss: 2.109091717709777

Epoch: 6| Step: 6
Training loss: 1.6559417247772217
Validation loss: 2.0747058109570573

Epoch: 6| Step: 7
Training loss: 2.242845058441162
Validation loss: 2.0478135308911725

Epoch: 6| Step: 8
Training loss: 1.4821789264678955
Validation loss: 2.025203186978576

Epoch: 6| Step: 9
Training loss: 2.267042875289917
Validation loss: 2.0227051678524224

Epoch: 6| Step: 10
Training loss: 1.800386905670166
Validation loss: 1.9929264745404642

Epoch: 6| Step: 11
Training loss: 1.4318464994430542
Validation loss: 2.0061929200285222

Epoch: 6| Step: 12
Training loss: 2.0269861221313477
Validation loss: 1.9882888101762342

Epoch: 6| Step: 13
Training loss: 1.3476568460464478
Validation loss: 2.007091586307813

Epoch: 246| Step: 0
Training loss: 2.282242774963379
Validation loss: 2.026763714769835

Epoch: 6| Step: 1
Training loss: 1.7402223348617554
Validation loss: 2.033449529319681

Epoch: 6| Step: 2
Training loss: 1.895473599433899
Validation loss: 2.0364962418874106

Epoch: 6| Step: 3
Training loss: 1.7392992973327637
Validation loss: 2.0385794537041777

Epoch: 6| Step: 4
Training loss: 1.322843313217163
Validation loss: 2.0273904467141755

Epoch: 6| Step: 5
Training loss: 1.9852533340454102
Validation loss: 2.0323768610595376

Epoch: 6| Step: 6
Training loss: 1.2027174234390259
Validation loss: 2.0466566547270744

Epoch: 6| Step: 7
Training loss: 2.101566791534424
Validation loss: 2.0368905503262758

Epoch: 6| Step: 8
Training loss: 1.7880983352661133
Validation loss: 2.0483913549812893

Epoch: 6| Step: 9
Training loss: 1.6545345783233643
Validation loss: 2.030999977101562

Epoch: 6| Step: 10
Training loss: 1.637495517730713
Validation loss: 2.0256138129900862

Epoch: 6| Step: 11
Training loss: 2.212425947189331
Validation loss: 2.049651648408623

Epoch: 6| Step: 12
Training loss: 1.3985652923583984
Validation loss: 2.0727148517485587

Epoch: 6| Step: 13
Training loss: 2.041109323501587
Validation loss: 2.081720475227602

Epoch: 247| Step: 0
Training loss: 1.8040645122528076
Validation loss: 2.127460305408765

Epoch: 6| Step: 1
Training loss: 2.2610154151916504
Validation loss: 2.151954863661079

Epoch: 6| Step: 2
Training loss: 1.239403486251831
Validation loss: 2.175183073166878

Epoch: 6| Step: 3
Training loss: 3.0735764503479004
Validation loss: 2.119439512170771

Epoch: 6| Step: 4
Training loss: 1.5234884023666382
Validation loss: 2.082728168015839

Epoch: 6| Step: 5
Training loss: 1.9997806549072266
Validation loss: 2.065716681941863

Epoch: 6| Step: 6
Training loss: 2.279928207397461
Validation loss: 2.0397582028501775

Epoch: 6| Step: 7
Training loss: 1.601170301437378
Validation loss: 2.020220443766604

Epoch: 6| Step: 8
Training loss: 1.7989779710769653
Validation loss: 1.9874807480842835

Epoch: 6| Step: 9
Training loss: 1.6172981262207031
Validation loss: 1.9891103031814739

Epoch: 6| Step: 10
Training loss: 1.8383255004882812
Validation loss: 2.001612719669137

Epoch: 6| Step: 11
Training loss: 1.5177159309387207
Validation loss: 1.9955920903913436

Epoch: 6| Step: 12
Training loss: 1.4871485233306885
Validation loss: 2.0400016256558

Epoch: 6| Step: 13
Training loss: 0.861994743347168
Validation loss: 2.0843273234623734

Epoch: 248| Step: 0
Training loss: 1.989356517791748
Validation loss: 2.1124012008790047

Epoch: 6| Step: 1
Training loss: 1.9270401000976562
Validation loss: 2.1445426607644684

Epoch: 6| Step: 2
Training loss: 1.4337579011917114
Validation loss: 2.1651458458233903

Epoch: 6| Step: 3
Training loss: 1.0943024158477783
Validation loss: 2.1380743185679116

Epoch: 6| Step: 4
Training loss: 1.6138389110565186
Validation loss: 2.1335152374800814

Epoch: 6| Step: 5
Training loss: 2.1901326179504395
Validation loss: 2.0907972845979916

Epoch: 6| Step: 6
Training loss: 1.6578214168548584
Validation loss: 2.036347314875613

Epoch: 6| Step: 7
Training loss: 1.7133487462997437
Validation loss: 2.027414298826648

Epoch: 6| Step: 8
Training loss: 1.893483281135559
Validation loss: 2.015885127488003

Epoch: 6| Step: 9
Training loss: 2.160935401916504
Validation loss: 1.9880759998034405

Epoch: 6| Step: 10
Training loss: 1.8741428852081299
Validation loss: 1.9725123041419572

Epoch: 6| Step: 11
Training loss: 1.3845181465148926
Validation loss: 1.9822896731797086

Epoch: 6| Step: 12
Training loss: 2.5978808403015137
Validation loss: 1.9657511416301932

Epoch: 6| Step: 13
Training loss: 1.5719071626663208
Validation loss: 1.9602778675735637

Epoch: 249| Step: 0
Training loss: 1.7009131908416748
Validation loss: 1.9823871312602874

Epoch: 6| Step: 1
Training loss: 2.4675374031066895
Validation loss: 2.0069452126820884

Epoch: 6| Step: 2
Training loss: 1.9618555307388306
Validation loss: 2.0415566621288175

Epoch: 6| Step: 3
Training loss: 1.2496576309204102
Validation loss: 2.0640149680517053

Epoch: 6| Step: 4
Training loss: 1.8553640842437744
Validation loss: 2.1276725992079704

Epoch: 6| Step: 5
Training loss: 1.800224781036377
Validation loss: 2.1490300060600362

Epoch: 6| Step: 6
Training loss: 1.3612403869628906
Validation loss: 2.179554380396361

Epoch: 6| Step: 7
Training loss: 2.160222291946411
Validation loss: 2.165411400538619

Epoch: 6| Step: 8
Training loss: 1.2798867225646973
Validation loss: 2.113501512876121

Epoch: 6| Step: 9
Training loss: 2.1089065074920654
Validation loss: 2.095127251840407

Epoch: 6| Step: 10
Training loss: 1.2197463512420654
Validation loss: 2.055590337322604

Epoch: 6| Step: 11
Training loss: 2.7340757846832275
Validation loss: 2.072128088243546

Epoch: 6| Step: 12
Training loss: 1.4614825248718262
Validation loss: 2.0326479301657727

Epoch: 6| Step: 13
Training loss: 1.8425920009613037
Validation loss: 2.0089131273249143

Epoch: 250| Step: 0
Training loss: 1.8013992309570312
Validation loss: 1.984606606985933

Epoch: 6| Step: 1
Training loss: 1.9122710227966309
Validation loss: 1.9582537733098513

Epoch: 6| Step: 2
Training loss: 1.9135091304779053
Validation loss: 1.9808136775929441

Epoch: 6| Step: 3
Training loss: 1.4554953575134277
Validation loss: 1.9833230228834255

Epoch: 6| Step: 4
Training loss: 2.2482352256774902
Validation loss: 2.0217344837803997

Epoch: 6| Step: 5
Training loss: 1.6152613162994385
Validation loss: 1.9973965280799455

Epoch: 6| Step: 6
Training loss: 1.963752031326294
Validation loss: 2.02279402876413

Epoch: 6| Step: 7
Training loss: 1.5271060466766357
Validation loss: 2.0193150761306926

Epoch: 6| Step: 8
Training loss: 1.7011545896530151
Validation loss: 2.024567860429005

Epoch: 6| Step: 9
Training loss: 2.1573195457458496
Validation loss: 2.041830829394761

Epoch: 6| Step: 10
Training loss: 1.1621079444885254
Validation loss: 2.076456210946524

Epoch: 6| Step: 11
Training loss: 2.0435009002685547
Validation loss: 2.064196135408135

Epoch: 6| Step: 12
Training loss: 2.016838788986206
Validation loss: 2.0737699411248647

Epoch: 6| Step: 13
Training loss: 1.547539234161377
Validation loss: 2.0972069283967376

Epoch: 251| Step: 0
Training loss: 1.6607557535171509
Validation loss: 2.079025089099843

Epoch: 6| Step: 1
Training loss: 1.4803011417388916
Validation loss: 2.103094823898808

Epoch: 6| Step: 2
Training loss: 1.9159924983978271
Validation loss: 2.082221367025888

Epoch: 6| Step: 3
Training loss: 1.7518068552017212
Validation loss: 2.075599475573468

Epoch: 6| Step: 4
Training loss: 1.5720165967941284
Validation loss: 2.09172809508539

Epoch: 6| Step: 5
Training loss: 1.527361273765564
Validation loss: 2.0660661574332946

Epoch: 6| Step: 6
Training loss: 2.108128547668457
Validation loss: 2.041232789716413

Epoch: 6| Step: 7
Training loss: 2.3333544731140137
Validation loss: 2.0026332639878794

Epoch: 6| Step: 8
Training loss: 1.6743358373641968
Validation loss: 2.0254161229697605

Epoch: 6| Step: 9
Training loss: 1.8559470176696777
Validation loss: 2.0042296583934496

Epoch: 6| Step: 10
Training loss: 1.4261387586593628
Validation loss: 1.9950666683976368

Epoch: 6| Step: 11
Training loss: 1.8652350902557373
Validation loss: 2.023087716871692

Epoch: 6| Step: 12
Training loss: 2.158620834350586
Validation loss: 2.0030404444663756

Epoch: 6| Step: 13
Training loss: 1.2265071868896484
Validation loss: 2.00657650732225

Epoch: 252| Step: 0
Training loss: 2.0389697551727295
Validation loss: 2.009230713690481

Epoch: 6| Step: 1
Training loss: 1.316064715385437
Validation loss: 2.006879847536805

Epoch: 6| Step: 2
Training loss: 1.3143985271453857
Validation loss: 2.0354988754436536

Epoch: 6| Step: 3
Training loss: 2.35914945602417
Validation loss: 2.0616543805727394

Epoch: 6| Step: 4
Training loss: 1.6757773160934448
Validation loss: 2.0783450257393623

Epoch: 6| Step: 5
Training loss: 1.9355878829956055
Validation loss: 2.1310093941227084

Epoch: 6| Step: 6
Training loss: 2.126249313354492
Validation loss: 2.114807959525816

Epoch: 6| Step: 7
Training loss: 1.454268455505371
Validation loss: 2.140105275697606

Epoch: 6| Step: 8
Training loss: 2.010704755783081
Validation loss: 2.0833712162510043

Epoch: 6| Step: 9
Training loss: 1.4707958698272705
Validation loss: 2.0619647374717136

Epoch: 6| Step: 10
Training loss: 1.3234131336212158
Validation loss: 2.0471579054350495

Epoch: 6| Step: 11
Training loss: 1.813594937324524
Validation loss: 2.021651294923598

Epoch: 6| Step: 12
Training loss: 2.0400846004486084
Validation loss: 2.009432315826416

Epoch: 6| Step: 13
Training loss: 1.729472041130066
Validation loss: 2.023164854254774

Epoch: 253| Step: 0
Training loss: 1.5786514282226562
Validation loss: 2.020645199283477

Epoch: 6| Step: 1
Training loss: 1.4935710430145264
Validation loss: 2.007926635844733

Epoch: 6| Step: 2
Training loss: 1.654531717300415
Validation loss: 1.9883317332113943

Epoch: 6| Step: 3
Training loss: 1.8898818492889404
Validation loss: 2.037516588805824

Epoch: 6| Step: 4
Training loss: 1.8218064308166504
Validation loss: 2.0248006838624195

Epoch: 6| Step: 5
Training loss: 1.740146279335022
Validation loss: 2.047751611278903

Epoch: 6| Step: 6
Training loss: 2.1796536445617676
Validation loss: 2.0636587732581684

Epoch: 6| Step: 7
Training loss: 1.7237069606781006
Validation loss: 2.0676039777776247

Epoch: 6| Step: 8
Training loss: 2.006143093109131
Validation loss: 2.0711663000045286

Epoch: 6| Step: 9
Training loss: 2.412559986114502
Validation loss: 2.0460946200996317

Epoch: 6| Step: 10
Training loss: 1.272990345954895
Validation loss: 2.0543686266868346

Epoch: 6| Step: 11
Training loss: 1.331754207611084
Validation loss: 2.0169334411621094

Epoch: 6| Step: 12
Training loss: 1.290384292602539
Validation loss: 2.0361208582437165

Epoch: 6| Step: 13
Training loss: 2.227274179458618
Validation loss: 2.011768553846626

Epoch: 254| Step: 0
Training loss: 1.8355058431625366
Validation loss: 2.034599925882073

Epoch: 6| Step: 1
Training loss: 2.148078441619873
Validation loss: 1.9888751096622919

Epoch: 6| Step: 2
Training loss: 1.7549700736999512
Validation loss: 1.991591848352904

Epoch: 6| Step: 3
Training loss: 1.7129862308502197
Validation loss: 1.9823512338822888

Epoch: 6| Step: 4
Training loss: 2.023273468017578
Validation loss: 1.9795093728650002

Epoch: 6| Step: 5
Training loss: 2.0254597663879395
Validation loss: 1.9592432450222712

Epoch: 6| Step: 6
Training loss: 1.8311572074890137
Validation loss: 1.9522491655042093

Epoch: 6| Step: 7
Training loss: 1.4841408729553223
Validation loss: 1.9659169796974427

Epoch: 6| Step: 8
Training loss: 1.2411681413650513
Validation loss: 1.9980782667795818

Epoch: 6| Step: 9
Training loss: 1.5794743299484253
Validation loss: 1.992325528975456

Epoch: 6| Step: 10
Training loss: 1.9296622276306152
Validation loss: 2.056964166702763

Epoch: 6| Step: 11
Training loss: 1.5773324966430664
Validation loss: 2.045163946767007

Epoch: 6| Step: 12
Training loss: 1.550232172012329
Validation loss: 2.0972445895594936

Epoch: 6| Step: 13
Training loss: 1.7542996406555176
Validation loss: 2.1763304382242183

Epoch: 255| Step: 0
Training loss: 2.324916362762451
Validation loss: 2.2067530949910483

Epoch: 6| Step: 1
Training loss: 2.5132031440734863
Validation loss: 2.1654927192195768

Epoch: 6| Step: 2
Training loss: 1.6155433654785156
Validation loss: 2.110528874140914

Epoch: 6| Step: 3
Training loss: 1.7294442653656006
Validation loss: 2.1089085737864175

Epoch: 6| Step: 4
Training loss: 1.654789686203003
Validation loss: 2.0659779810136363

Epoch: 6| Step: 5
Training loss: 1.2517184019088745
Validation loss: 2.055899909747544

Epoch: 6| Step: 6
Training loss: 1.7670868635177612
Validation loss: 2.035606009985811

Epoch: 6| Step: 7
Training loss: 1.5522212982177734
Validation loss: 2.0231639005804576

Epoch: 6| Step: 8
Training loss: 2.3120217323303223
Validation loss: 1.9910699244468444

Epoch: 6| Step: 9
Training loss: 2.2120954990386963
Validation loss: 1.9920507118266115

Epoch: 6| Step: 10
Training loss: 1.458179235458374
Validation loss: 1.9973366824529504

Epoch: 6| Step: 11
Training loss: 1.855225920677185
Validation loss: 1.9882047996726087

Epoch: 6| Step: 12
Training loss: 1.2197450399398804
Validation loss: 2.0470576888771466

Epoch: 6| Step: 13
Training loss: 1.55341637134552
Validation loss: 2.08231653833902

Epoch: 256| Step: 0
Training loss: 1.9311171770095825
Validation loss: 2.1418065255688084

Epoch: 6| Step: 1
Training loss: 1.1312025785446167
Validation loss: 2.1287592457186792

Epoch: 6| Step: 2
Training loss: 1.8148388862609863
Validation loss: 2.1335982212456326

Epoch: 6| Step: 3
Training loss: 1.7223154306411743
Validation loss: 2.1095376706892446

Epoch: 6| Step: 4
Training loss: 1.8059837818145752
Validation loss: 2.099593693210233

Epoch: 6| Step: 5
Training loss: 1.8203635215759277
Validation loss: 2.1037962667403685

Epoch: 6| Step: 6
Training loss: 1.5727171897888184
Validation loss: 2.107921628541844

Epoch: 6| Step: 7
Training loss: 1.0810983180999756
Validation loss: 2.0783411713056665

Epoch: 6| Step: 8
Training loss: 2.206714153289795
Validation loss: 2.0888499034348356

Epoch: 6| Step: 9
Training loss: 1.7133526802062988
Validation loss: 2.0693610688691497

Epoch: 6| Step: 10
Training loss: 2.215329170227051
Validation loss: 2.01302436859377

Epoch: 6| Step: 11
Training loss: 1.7960317134857178
Validation loss: 1.9902126507092548

Epoch: 6| Step: 12
Training loss: 2.523427724838257
Validation loss: 2.0197016821112683

Epoch: 6| Step: 13
Training loss: 1.3407917022705078
Validation loss: 1.9817497935346378

Epoch: 257| Step: 0
Training loss: 1.7320767641067505
Validation loss: 1.9862383257958196

Epoch: 6| Step: 1
Training loss: 2.3593077659606934
Validation loss: 1.9882394177939302

Epoch: 6| Step: 2
Training loss: 1.9075822830200195
Validation loss: 1.962701432166561

Epoch: 6| Step: 3
Training loss: 1.814184546470642
Validation loss: 1.9427397379311182

Epoch: 6| Step: 4
Training loss: 1.8205242156982422
Validation loss: 1.9758774029311312

Epoch: 6| Step: 5
Training loss: 1.8976035118103027
Validation loss: 1.9909210743442658

Epoch: 6| Step: 6
Training loss: 1.8309650421142578
Validation loss: 1.9909482745714084

Epoch: 6| Step: 7
Training loss: 1.680909514427185
Validation loss: 2.0329560977156445

Epoch: 6| Step: 8
Training loss: 1.6694972515106201
Validation loss: 2.080375159940412

Epoch: 6| Step: 9
Training loss: 1.9386464357376099
Validation loss: 2.124475766253728

Epoch: 6| Step: 10
Training loss: 1.1445376873016357
Validation loss: 2.140809323198052

Epoch: 6| Step: 11
Training loss: 1.5477216243743896
Validation loss: 2.1408006042562504

Epoch: 6| Step: 12
Training loss: 1.438812255859375
Validation loss: 2.1507951367285942

Epoch: 6| Step: 13
Training loss: 1.7083477973937988
Validation loss: 2.137010999905166

Epoch: 258| Step: 0
Training loss: 1.5939319133758545
Validation loss: 2.1444225029278825

Epoch: 6| Step: 1
Training loss: 1.6068439483642578
Validation loss: 2.135228460834872

Epoch: 6| Step: 2
Training loss: 2.3702712059020996
Validation loss: 2.1217170735841155

Epoch: 6| Step: 3
Training loss: 1.0663586854934692
Validation loss: 2.0939771231784614

Epoch: 6| Step: 4
Training loss: 1.5454037189483643
Validation loss: 2.068535429175182

Epoch: 6| Step: 5
Training loss: 1.6241319179534912
Validation loss: 2.071960631237235

Epoch: 6| Step: 6
Training loss: 1.7684704065322876
Validation loss: 2.0426969348743396

Epoch: 6| Step: 7
Training loss: 1.5052939653396606
Validation loss: 2.0416452987219698

Epoch: 6| Step: 8
Training loss: 1.9822276830673218
Validation loss: 1.9873968913990965

Epoch: 6| Step: 9
Training loss: 2.046703815460205
Validation loss: 1.9587521104402439

Epoch: 6| Step: 10
Training loss: 2.07951283454895
Validation loss: 1.964253120524909

Epoch: 6| Step: 11
Training loss: 1.6735879182815552
Validation loss: 1.9582884183493994

Epoch: 6| Step: 12
Training loss: 1.9577540159225464
Validation loss: 1.953414083808981

Epoch: 6| Step: 13
Training loss: 1.5759992599487305
Validation loss: 1.9578220818632392

Epoch: 259| Step: 0
Training loss: 1.666830062866211
Validation loss: 1.9577711243783273

Epoch: 6| Step: 1
Training loss: 1.7312593460083008
Validation loss: 1.9780083779365785

Epoch: 6| Step: 2
Training loss: 2.6093716621398926
Validation loss: 1.9809383525643298

Epoch: 6| Step: 3
Training loss: 1.0990270376205444
Validation loss: 1.9821538143260504

Epoch: 6| Step: 4
Training loss: 2.0507164001464844
Validation loss: 1.9963300125573271

Epoch: 6| Step: 5
Training loss: 1.0814974308013916
Validation loss: 1.985500334411539

Epoch: 6| Step: 6
Training loss: 1.8470039367675781
Validation loss: 2.022614179118987

Epoch: 6| Step: 7
Training loss: 1.7633388042449951
Validation loss: 2.0595843984234716

Epoch: 6| Step: 8
Training loss: 1.9484244585037231
Validation loss: 2.0651704457498368

Epoch: 6| Step: 9
Training loss: 1.3379335403442383
Validation loss: 2.0840897483210408

Epoch: 6| Step: 10
Training loss: 2.4584414958953857
Validation loss: 2.0786652667548067

Epoch: 6| Step: 11
Training loss: 1.894992470741272
Validation loss: 2.074455384285219

Epoch: 6| Step: 12
Training loss: 1.3902521133422852
Validation loss: 2.0505234067158034

Epoch: 6| Step: 13
Training loss: 1.1692540645599365
Validation loss: 2.0371128871876705

Epoch: 260| Step: 0
Training loss: 1.6354422569274902
Validation loss: 2.0246570200048466

Epoch: 6| Step: 1
Training loss: 1.9611341953277588
Validation loss: 2.008079541626797

Epoch: 6| Step: 2
Training loss: 1.7082411050796509
Validation loss: 2.0075916218501266

Epoch: 6| Step: 3
Training loss: 2.3421173095703125
Validation loss: 2.018685504954348

Epoch: 6| Step: 4
Training loss: 1.4869951009750366
Validation loss: 1.9897172374110068

Epoch: 6| Step: 5
Training loss: 1.5274262428283691
Validation loss: 1.9949053333651634

Epoch: 6| Step: 6
Training loss: 1.8730309009552002
Validation loss: 2.006543533776396

Epoch: 6| Step: 7
Training loss: 1.9972902536392212
Validation loss: 2.015162683302356

Epoch: 6| Step: 8
Training loss: 1.4818774461746216
Validation loss: 2.0105176907713695

Epoch: 6| Step: 9
Training loss: 1.6019943952560425
Validation loss: 2.0386113300118396

Epoch: 6| Step: 10
Training loss: 1.2825766801834106
Validation loss: 2.054514337611455

Epoch: 6| Step: 11
Training loss: 2.0592360496520996
Validation loss: 2.055275126170087

Epoch: 6| Step: 12
Training loss: 1.2006927728652954
Validation loss: 2.0915963175476238

Epoch: 6| Step: 13
Training loss: 2.041172981262207
Validation loss: 2.11106264463035

Epoch: 261| Step: 0
Training loss: 1.0522888898849487
Validation loss: 2.1182831666802846

Epoch: 6| Step: 1
Training loss: 1.6589829921722412
Validation loss: 2.134274152017409

Epoch: 6| Step: 2
Training loss: 1.7817575931549072
Validation loss: 2.13579527537028

Epoch: 6| Step: 3
Training loss: 2.8543663024902344
Validation loss: 2.106582292946436

Epoch: 6| Step: 4
Training loss: 2.013989210128784
Validation loss: 2.1194658394782775

Epoch: 6| Step: 5
Training loss: 1.582492709159851
Validation loss: 2.067092090524653

Epoch: 6| Step: 6
Training loss: 1.5943418741226196
Validation loss: 2.09061102456944

Epoch: 6| Step: 7
Training loss: 2.0809197425842285
Validation loss: 2.021422340023902

Epoch: 6| Step: 8
Training loss: 1.4242138862609863
Validation loss: 1.9916548395669589

Epoch: 6| Step: 9
Training loss: 1.79201078414917
Validation loss: 1.9982944739762174

Epoch: 6| Step: 10
Training loss: 1.6674696207046509
Validation loss: 2.0028129393054592

Epoch: 6| Step: 11
Training loss: 1.2663938999176025
Validation loss: 1.9758854104626564

Epoch: 6| Step: 12
Training loss: 2.02254056930542
Validation loss: 1.9682057801113333

Epoch: 6| Step: 13
Training loss: 0.9210835695266724
Validation loss: 1.952632273397138

Epoch: 262| Step: 0
Training loss: 2.1759495735168457
Validation loss: 1.9633637077064925

Epoch: 6| Step: 1
Training loss: 1.9346697330474854
Validation loss: 1.9752841726426156

Epoch: 6| Step: 2
Training loss: 2.4027926921844482
Validation loss: 1.9966553436812533

Epoch: 6| Step: 3
Training loss: 1.6592986583709717
Validation loss: 2.0349345284123577

Epoch: 6| Step: 4
Training loss: 1.5938246250152588
Validation loss: 2.043250537687732

Epoch: 6| Step: 5
Training loss: 2.055449962615967
Validation loss: 2.0675179112342095

Epoch: 6| Step: 6
Training loss: 1.1000878810882568
Validation loss: 2.067395649930482

Epoch: 6| Step: 7
Training loss: 1.6320279836654663
Validation loss: 2.10173301799323

Epoch: 6| Step: 8
Training loss: 1.0085246562957764
Validation loss: 2.0686323322275633

Epoch: 6| Step: 9
Training loss: 1.849700689315796
Validation loss: 2.0698329428190827

Epoch: 6| Step: 10
Training loss: 1.5265740156173706
Validation loss: 2.063025120765932

Epoch: 6| Step: 11
Training loss: 1.9529736042022705
Validation loss: 2.0746553610729914

Epoch: 6| Step: 12
Training loss: 1.6115806102752686
Validation loss: 2.0679121607093403

Epoch: 6| Step: 13
Training loss: 1.9064233303070068
Validation loss: 2.0363363014754428

Epoch: 263| Step: 0
Training loss: 1.5747038125991821
Validation loss: 2.002805591911398

Epoch: 6| Step: 1
Training loss: 1.8386890888214111
Validation loss: 1.9826142723842333

Epoch: 6| Step: 2
Training loss: 1.7928850650787354
Validation loss: 1.961204218608077

Epoch: 6| Step: 3
Training loss: 1.5639004707336426
Validation loss: 1.9594804625357352

Epoch: 6| Step: 4
Training loss: 1.213897466659546
Validation loss: 1.940963932262954

Epoch: 6| Step: 5
Training loss: 2.3180201053619385
Validation loss: 1.958427906036377

Epoch: 6| Step: 6
Training loss: 1.9543617963790894
Validation loss: 1.9765139600282073

Epoch: 6| Step: 7
Training loss: 2.066002607345581
Validation loss: 1.9783331014776742

Epoch: 6| Step: 8
Training loss: 1.8299593925476074
Validation loss: 1.9764595288102345

Epoch: 6| Step: 9
Training loss: 1.9660110473632812
Validation loss: 2.031819288448621

Epoch: 6| Step: 10
Training loss: 1.5110995769500732
Validation loss: 2.069663632300592

Epoch: 6| Step: 11
Training loss: 1.276894450187683
Validation loss: 2.111355053481235

Epoch: 6| Step: 12
Training loss: 1.13943612575531
Validation loss: 2.0876621174555954

Epoch: 6| Step: 13
Training loss: 2.288530111312866
Validation loss: 2.082199819626347

Epoch: 264| Step: 0
Training loss: 1.6364681720733643
Validation loss: 2.0630343408994776

Epoch: 6| Step: 1
Training loss: 1.6028130054473877
Validation loss: 2.0703701062869

Epoch: 6| Step: 2
Training loss: 1.4149028062820435
Validation loss: 2.078721563021342

Epoch: 6| Step: 3
Training loss: 1.962170124053955
Validation loss: 2.044081452072308

Epoch: 6| Step: 4
Training loss: 2.0968399047851562
Validation loss: 2.0325971239356586

Epoch: 6| Step: 5
Training loss: 1.7144650220870972
Validation loss: 2.0339329601615987

Epoch: 6| Step: 6
Training loss: 1.5231040716171265
Validation loss: 2.065548235370267

Epoch: 6| Step: 7
Training loss: 1.6105738878250122
Validation loss: 2.076722929554601

Epoch: 6| Step: 8
Training loss: 1.8740235567092896
Validation loss: 2.0668148327899236

Epoch: 6| Step: 9
Training loss: 1.229034185409546
Validation loss: 2.0629804518914994

Epoch: 6| Step: 10
Training loss: 1.2368240356445312
Validation loss: 2.0261923241358932

Epoch: 6| Step: 11
Training loss: 2.3722915649414062
Validation loss: 2.0123811793583695

Epoch: 6| Step: 12
Training loss: 1.9454940557479858
Validation loss: 1.9896596747059976

Epoch: 6| Step: 13
Training loss: 1.475090742111206
Validation loss: 1.9874209896210702

Epoch: 265| Step: 0
Training loss: 1.8476954698562622
Validation loss: 1.9678439709448046

Epoch: 6| Step: 1
Training loss: 1.5130093097686768
Validation loss: 1.974926265337134

Epoch: 6| Step: 2
Training loss: 2.1317081451416016
Validation loss: 1.975015717168008

Epoch: 6| Step: 3
Training loss: 1.3557887077331543
Validation loss: 1.9731326744120607

Epoch: 6| Step: 4
Training loss: 0.9639773368835449
Validation loss: 2.0364902711683706

Epoch: 6| Step: 5
Training loss: 2.157466411590576
Validation loss: 2.0888534668953187

Epoch: 6| Step: 6
Training loss: 1.3094570636749268
Validation loss: 2.0637218785542313

Epoch: 6| Step: 7
Training loss: 1.4249948263168335
Validation loss: 2.104584474717417

Epoch: 6| Step: 8
Training loss: 2.0838117599487305
Validation loss: 2.113262822551112

Epoch: 6| Step: 9
Training loss: 1.9095815420150757
Validation loss: 2.095851931520688

Epoch: 6| Step: 10
Training loss: 1.292417049407959
Validation loss: 2.0947173923574467

Epoch: 6| Step: 11
Training loss: 1.6747405529022217
Validation loss: 2.0877125955397084

Epoch: 6| Step: 12
Training loss: 1.681213617324829
Validation loss: 2.090416733936597

Epoch: 6| Step: 13
Training loss: 3.3574538230895996
Validation loss: 2.06626203239605

Epoch: 266| Step: 0
Training loss: 1.1163711547851562
Validation loss: 2.0730749458395024

Epoch: 6| Step: 1
Training loss: 1.296159267425537
Validation loss: 2.05441556438323

Epoch: 6| Step: 2
Training loss: 1.5091168880462646
Validation loss: 2.0430106565516484

Epoch: 6| Step: 3
Training loss: 1.0142035484313965
Validation loss: 2.046534897178732

Epoch: 6| Step: 4
Training loss: 2.214501142501831
Validation loss: 2.0878851298362977

Epoch: 6| Step: 5
Training loss: 1.5413928031921387
Validation loss: 2.1300889920162898

Epoch: 6| Step: 6
Training loss: 2.0670247077941895
Validation loss: 2.1673265118752756

Epoch: 6| Step: 7
Training loss: 2.9520182609558105
Validation loss: 2.173397215463782

Epoch: 6| Step: 8
Training loss: 1.9245392084121704
Validation loss: 2.1893777385834725

Epoch: 6| Step: 9
Training loss: 1.82334303855896
Validation loss: 2.116125705421612

Epoch: 6| Step: 10
Training loss: 1.368593454360962
Validation loss: 2.0503539295606714

Epoch: 6| Step: 11
Training loss: 1.792851448059082
Validation loss: 2.059460373334987

Epoch: 6| Step: 12
Training loss: 1.9170105457305908
Validation loss: 2.027658765034009

Epoch: 6| Step: 13
Training loss: 1.7994287014007568
Validation loss: 2.0504397910128356

Epoch: 267| Step: 0
Training loss: 1.929994821548462
Validation loss: 2.0422323634547572

Epoch: 6| Step: 1
Training loss: 2.0124118328094482
Validation loss: 2.0248241616833593

Epoch: 6| Step: 2
Training loss: 1.6744225025177002
Validation loss: 2.0339548997981574

Epoch: 6| Step: 3
Training loss: 1.8650777339935303
Validation loss: 2.033246474881326

Epoch: 6| Step: 4
Training loss: 1.5380126237869263
Validation loss: 2.0057495050532843

Epoch: 6| Step: 5
Training loss: 2.156688928604126
Validation loss: 2.0208652237410187

Epoch: 6| Step: 6
Training loss: 1.8516526222229004
Validation loss: 2.044466116095102

Epoch: 6| Step: 7
Training loss: 1.6244933605194092
Validation loss: 2.0514779526700258

Epoch: 6| Step: 8
Training loss: 1.6400995254516602
Validation loss: 2.033357197238553

Epoch: 6| Step: 9
Training loss: 1.6365656852722168
Validation loss: 2.0315533325236332

Epoch: 6| Step: 10
Training loss: 1.6847285032272339
Validation loss: 2.028766583370906

Epoch: 6| Step: 11
Training loss: 1.3121755123138428
Validation loss: 2.040103148388606

Epoch: 6| Step: 12
Training loss: 1.3756535053253174
Validation loss: 2.002971826061126

Epoch: 6| Step: 13
Training loss: 1.8088223934173584
Validation loss: 2.044540532173649

Epoch: 268| Step: 0
Training loss: 1.4617259502410889
Validation loss: 2.093236087470926

Epoch: 6| Step: 1
Training loss: 1.5045790672302246
Validation loss: 2.1320545045278405

Epoch: 6| Step: 2
Training loss: 2.0694870948791504
Validation loss: 2.2019923322944233

Epoch: 6| Step: 3
Training loss: 1.6128392219543457
Validation loss: 2.237472603397985

Epoch: 6| Step: 4
Training loss: 1.9086108207702637
Validation loss: 2.211575338917394

Epoch: 6| Step: 5
Training loss: 1.959773302078247
Validation loss: 2.1364508572445122

Epoch: 6| Step: 6
Training loss: 1.6755436658859253
Validation loss: 2.1277875733631912

Epoch: 6| Step: 7
Training loss: 1.214063048362732
Validation loss: 2.1055719185900945

Epoch: 6| Step: 8
Training loss: 1.6836413145065308
Validation loss: 2.0469965319479666

Epoch: 6| Step: 9
Training loss: 1.5864579677581787
Validation loss: 2.007479485645089

Epoch: 6| Step: 10
Training loss: 1.934556484222412
Validation loss: 1.9822364032909434

Epoch: 6| Step: 11
Training loss: 1.9589613676071167
Validation loss: 1.9894740709694483

Epoch: 6| Step: 12
Training loss: 1.5170587301254272
Validation loss: 1.9955044587453206

Epoch: 6| Step: 13
Training loss: 2.239654302597046
Validation loss: 1.970197787848852

Epoch: 269| Step: 0
Training loss: 1.53481125831604
Validation loss: 1.9665861693761681

Epoch: 6| Step: 1
Training loss: 2.163137197494507
Validation loss: 1.9774764173774309

Epoch: 6| Step: 2
Training loss: 1.5593900680541992
Validation loss: 1.97791761736716

Epoch: 6| Step: 3
Training loss: 1.4668792486190796
Validation loss: 2.038630113806776

Epoch: 6| Step: 4
Training loss: 1.6796869039535522
Validation loss: 2.074543786305253

Epoch: 6| Step: 5
Training loss: 1.8205233812332153
Validation loss: 2.086072330833763

Epoch: 6| Step: 6
Training loss: 2.1569528579711914
Validation loss: 2.1067968132675334

Epoch: 6| Step: 7
Training loss: 2.5132102966308594
Validation loss: 2.141935169055898

Epoch: 6| Step: 8
Training loss: 1.7688260078430176
Validation loss: 2.134108021695127

Epoch: 6| Step: 9
Training loss: 1.204937219619751
Validation loss: 2.1226457447134037

Epoch: 6| Step: 10
Training loss: 1.4689970016479492
Validation loss: 2.0835701727098033

Epoch: 6| Step: 11
Training loss: 1.5613247156143188
Validation loss: 2.0177457409520305

Epoch: 6| Step: 12
Training loss: 1.441194772720337
Validation loss: 1.982705335463247

Epoch: 6| Step: 13
Training loss: 1.723228931427002
Validation loss: 1.9774950088993195

Epoch: 270| Step: 0
Training loss: 1.664029598236084
Validation loss: 1.9680383077231787

Epoch: 6| Step: 1
Training loss: 1.6147258281707764
Validation loss: 1.967260076153663

Epoch: 6| Step: 2
Training loss: 1.3380162715911865
Validation loss: 1.9811336583988641

Epoch: 6| Step: 3
Training loss: 2.061997890472412
Validation loss: 1.9708055667979743

Epoch: 6| Step: 4
Training loss: 1.8535081148147583
Validation loss: 1.9979583999162078

Epoch: 6| Step: 5
Training loss: 1.303133249282837
Validation loss: 1.9815698656984555

Epoch: 6| Step: 6
Training loss: 1.7831671237945557
Validation loss: 2.003186515582505

Epoch: 6| Step: 7
Training loss: 1.3576302528381348
Validation loss: 2.0428193192328177

Epoch: 6| Step: 8
Training loss: 1.677178144454956
Validation loss: 2.0716464006772606

Epoch: 6| Step: 9
Training loss: 1.9613502025604248
Validation loss: 2.0684212151394097

Epoch: 6| Step: 10
Training loss: 1.8835171461105347
Validation loss: 2.0644313955819733

Epoch: 6| Step: 11
Training loss: 2.148876667022705
Validation loss: 2.109145715672483

Epoch: 6| Step: 12
Training loss: 1.4880871772766113
Validation loss: 2.053555155313143

Epoch: 6| Step: 13
Training loss: 1.2587718963623047
Validation loss: 2.0471491647023026

Epoch: 271| Step: 0
Training loss: 1.4886419773101807
Validation loss: 2.033304037586335

Epoch: 6| Step: 1
Training loss: 1.2201042175292969
Validation loss: 2.0031589320910874

Epoch: 6| Step: 2
Training loss: 1.380319595336914
Validation loss: 1.9894746529158724

Epoch: 6| Step: 3
Training loss: 1.4941489696502686
Validation loss: 1.9869179456464705

Epoch: 6| Step: 4
Training loss: 2.1636569499969482
Validation loss: 1.9757414761409964

Epoch: 6| Step: 5
Training loss: 0.904861330986023
Validation loss: 1.9887247059934883

Epoch: 6| Step: 6
Training loss: 1.6996158361434937
Validation loss: 1.9952207021815802

Epoch: 6| Step: 7
Training loss: 2.2065134048461914
Validation loss: 1.996481567300776

Epoch: 6| Step: 8
Training loss: 1.3078789710998535
Validation loss: 1.9905583012488581

Epoch: 6| Step: 9
Training loss: 2.0611696243286133
Validation loss: 2.001556514411844

Epoch: 6| Step: 10
Training loss: 1.5515286922454834
Validation loss: 2.003170944029285

Epoch: 6| Step: 11
Training loss: 2.305408000946045
Validation loss: 1.9803082686598583

Epoch: 6| Step: 12
Training loss: 1.6160529851913452
Validation loss: 1.970197787848852

Epoch: 6| Step: 13
Training loss: 1.8627744913101196
Validation loss: 1.9784379646342287

Epoch: 272| Step: 0
Training loss: 2.2002735137939453
Validation loss: 1.975533708449333

Epoch: 6| Step: 1
Training loss: 1.8849948644638062
Validation loss: 1.9790716530174337

Epoch: 6| Step: 2
Training loss: 1.384837031364441
Validation loss: 2.0195949269879248

Epoch: 6| Step: 3
Training loss: 1.3994507789611816
Validation loss: 2.0248989815353067

Epoch: 6| Step: 4
Training loss: 2.198525905609131
Validation loss: 2.040142043944328

Epoch: 6| Step: 5
Training loss: 1.2892587184906006
Validation loss: 2.0231894088047806

Epoch: 6| Step: 6
Training loss: 1.230819582939148
Validation loss: 2.0328279028656664

Epoch: 6| Step: 7
Training loss: 1.7028472423553467
Validation loss: 2.0051644604693175

Epoch: 6| Step: 8
Training loss: 1.4895048141479492
Validation loss: 2.027924786331833

Epoch: 6| Step: 9
Training loss: 1.4140383005142212
Validation loss: 2.026121013907976

Epoch: 6| Step: 10
Training loss: 2.0409491062164307
Validation loss: 2.0146210475634505

Epoch: 6| Step: 11
Training loss: 2.0519700050354004
Validation loss: 1.9877630856729323

Epoch: 6| Step: 12
Training loss: 1.4399197101593018
Validation loss: 1.980544344071419

Epoch: 6| Step: 13
Training loss: 1.1814799308776855
Validation loss: 2.0093460159917034

Epoch: 273| Step: 0
Training loss: 1.8359085321426392
Validation loss: 1.998589643868067

Epoch: 6| Step: 1
Training loss: 1.5403790473937988
Validation loss: 2.0335104824394308

Epoch: 6| Step: 2
Training loss: 1.3430057764053345
Validation loss: 2.0376556957921674

Epoch: 6| Step: 3
Training loss: 2.0878257751464844
Validation loss: 2.029874127398255

Epoch: 6| Step: 4
Training loss: 1.848458170890808
Validation loss: 2.055182146769698

Epoch: 6| Step: 5
Training loss: 1.460132122039795
Validation loss: 2.040435678215437

Epoch: 6| Step: 6
Training loss: 1.4194221496582031
Validation loss: 2.0790748775646253

Epoch: 6| Step: 7
Training loss: 1.2679023742675781
Validation loss: 2.1042172857510146

Epoch: 6| Step: 8
Training loss: 1.6541564464569092
Validation loss: 2.086797014359505

Epoch: 6| Step: 9
Training loss: 1.4789679050445557
Validation loss: 2.0854724940433296

Epoch: 6| Step: 10
Training loss: 2.0783028602600098
Validation loss: 2.0725670424840783

Epoch: 6| Step: 11
Training loss: 1.107928991317749
Validation loss: 2.049843169027759

Epoch: 6| Step: 12
Training loss: 1.8546576499938965
Validation loss: 2.0266801631578835

Epoch: 6| Step: 13
Training loss: 2.6598141193389893
Validation loss: 2.0079867403994323

Epoch: 274| Step: 0
Training loss: 1.521498203277588
Validation loss: 1.9959951523811585

Epoch: 6| Step: 1
Training loss: 1.4232151508331299
Validation loss: 1.986531662684615

Epoch: 6| Step: 2
Training loss: 1.6786035299301147
Validation loss: 2.0049302013971473

Epoch: 6| Step: 3
Training loss: 1.8746837377548218
Validation loss: 2.0109952495944117

Epoch: 6| Step: 4
Training loss: 1.5119237899780273
Validation loss: 2.010023578520744

Epoch: 6| Step: 5
Training loss: 1.3757658004760742
Validation loss: 1.9966312710956862

Epoch: 6| Step: 6
Training loss: 1.4417264461517334
Validation loss: 2.0034748033810685

Epoch: 6| Step: 7
Training loss: 1.734375238418579
Validation loss: 2.0058019007405927

Epoch: 6| Step: 8
Training loss: 1.747929334640503
Validation loss: 2.010985227041347

Epoch: 6| Step: 9
Training loss: 1.2418951988220215
Validation loss: 1.9848096396333428

Epoch: 6| Step: 10
Training loss: 2.5573372840881348
Validation loss: 1.9995410006533387

Epoch: 6| Step: 11
Training loss: 1.538433313369751
Validation loss: 1.9725146216730918

Epoch: 6| Step: 12
Training loss: 1.5478973388671875
Validation loss: 1.9796853962764944

Epoch: 6| Step: 13
Training loss: 1.6725505590438843
Validation loss: 2.009176000472038

Epoch: 275| Step: 0
Training loss: 1.803442120552063
Validation loss: 1.9965056552681872

Epoch: 6| Step: 1
Training loss: 1.9714763164520264
Validation loss: 2.0529022139887654

Epoch: 6| Step: 2
Training loss: 1.7349175214767456
Validation loss: 2.0853097464448664

Epoch: 6| Step: 3
Training loss: 1.462580919265747
Validation loss: 2.102257772158551

Epoch: 6| Step: 4
Training loss: 1.3936119079589844
Validation loss: 2.067308266957601

Epoch: 6| Step: 5
Training loss: 1.7986819744110107
Validation loss: 2.0653546805022867

Epoch: 6| Step: 6
Training loss: 1.5393550395965576
Validation loss: 2.032157292930029

Epoch: 6| Step: 7
Training loss: 2.0479044914245605
Validation loss: 2.017422835032145

Epoch: 6| Step: 8
Training loss: 1.1808853149414062
Validation loss: 2.0318786200656684

Epoch: 6| Step: 9
Training loss: 1.6911728382110596
Validation loss: 2.0306625763575235

Epoch: 6| Step: 10
Training loss: 2.0573337078094482
Validation loss: 2.0174933069495746

Epoch: 6| Step: 11
Training loss: 1.2807984352111816
Validation loss: 2.043435522305068

Epoch: 6| Step: 12
Training loss: 1.4919817447662354
Validation loss: 2.013753710254546

Epoch: 6| Step: 13
Training loss: 2.3407692909240723
Validation loss: 2.003597551776517

Epoch: 276| Step: 0
Training loss: 1.2284331321716309
Validation loss: 1.9905092280398133

Epoch: 6| Step: 1
Training loss: 1.9994670152664185
Validation loss: 1.9946347257142425

Epoch: 6| Step: 2
Training loss: 1.4504581689834595
Validation loss: 1.9858242504058345

Epoch: 6| Step: 3
Training loss: 2.0451085567474365
Validation loss: 1.9908331363431868

Epoch: 6| Step: 4
Training loss: 1.5303009748458862
Validation loss: 1.962608693748392

Epoch: 6| Step: 5
Training loss: 1.3483837842941284
Validation loss: 1.9998791781804894

Epoch: 6| Step: 6
Training loss: 0.7982090711593628
Validation loss: 2.013715943982524

Epoch: 6| Step: 7
Training loss: 1.7208799123764038
Validation loss: 2.0276096277339484

Epoch: 6| Step: 8
Training loss: 1.351163625717163
Validation loss: 2.0613292135218138

Epoch: 6| Step: 9
Training loss: 1.6559717655181885
Validation loss: 2.0550456444422402

Epoch: 6| Step: 10
Training loss: 2.3705906867980957
Validation loss: 2.103006991006995

Epoch: 6| Step: 11
Training loss: 1.2318658828735352
Validation loss: 2.1138555772842897

Epoch: 6| Step: 12
Training loss: 2.4888439178466797
Validation loss: 2.08416276208816

Epoch: 6| Step: 13
Training loss: 1.3993511199951172
Validation loss: 2.093587283165224

Epoch: 277| Step: 0
Training loss: 1.478914737701416
Validation loss: 2.0980763037999473

Epoch: 6| Step: 1
Training loss: 1.376399278640747
Validation loss: 2.075260428972142

Epoch: 6| Step: 2
Training loss: 1.235558032989502
Validation loss: 2.0523388219136063

Epoch: 6| Step: 3
Training loss: 1.6936990022659302
Validation loss: 2.021763277310197

Epoch: 6| Step: 4
Training loss: 1.471051812171936
Validation loss: 2.0093940470808294

Epoch: 6| Step: 5
Training loss: 2.494121789932251
Validation loss: 1.9783779664706158

Epoch: 6| Step: 6
Training loss: 2.1624467372894287
Validation loss: 1.9555181559695993

Epoch: 6| Step: 7
Training loss: 1.2043160200119019
Validation loss: 1.9500942166133592

Epoch: 6| Step: 8
Training loss: 1.8882650136947632
Validation loss: 1.99852801522901

Epoch: 6| Step: 9
Training loss: 1.9030859470367432
Validation loss: 2.002736058286441

Epoch: 6| Step: 10
Training loss: 1.632190465927124
Validation loss: 2.014197490548575

Epoch: 6| Step: 11
Training loss: 1.268578290939331
Validation loss: 2.0369337835619525

Epoch: 6| Step: 12
Training loss: 1.3520817756652832
Validation loss: 2.0722425265978743

Epoch: 6| Step: 13
Training loss: 1.2879748344421387
Validation loss: 2.0731944627659296

Epoch: 278| Step: 0
Training loss: 1.2359271049499512
Validation loss: 2.0848968682750577

Epoch: 6| Step: 1
Training loss: 1.4746944904327393
Validation loss: 2.066214041043353

Epoch: 6| Step: 2
Training loss: 1.806793212890625
Validation loss: 2.0760269062493437

Epoch: 6| Step: 3
Training loss: 2.0948426723480225
Validation loss: 2.0478375419493644

Epoch: 6| Step: 4
Training loss: 1.2385568618774414
Validation loss: 2.060135687551191

Epoch: 6| Step: 5
Training loss: 1.9450992345809937
Validation loss: 2.042948927930606

Epoch: 6| Step: 6
Training loss: 1.703474521636963
Validation loss: 2.048847221559094

Epoch: 6| Step: 7
Training loss: 1.7034327983856201
Validation loss: 2.036572907560615

Epoch: 6| Step: 8
Training loss: 1.2120721340179443
Validation loss: 2.0060343050187632

Epoch: 6| Step: 9
Training loss: 1.5124008655548096
Validation loss: 2.026801195195926

Epoch: 6| Step: 10
Training loss: 1.7941656112670898
Validation loss: 2.0284516503733974

Epoch: 6| Step: 11
Training loss: 1.9973559379577637
Validation loss: 2.0222670596132994

Epoch: 6| Step: 12
Training loss: 1.0036756992340088
Validation loss: 2.020036728151383

Epoch: 6| Step: 13
Training loss: 1.7149912118911743
Validation loss: 2.02440837378143

Epoch: 279| Step: 0
Training loss: 1.1136659383773804
Validation loss: 2.0001429819291636

Epoch: 6| Step: 1
Training loss: 1.5746525526046753
Validation loss: 2.0287788606459096

Epoch: 6| Step: 2
Training loss: 1.6822198629379272
Validation loss: 2.0092643166101105

Epoch: 6| Step: 3
Training loss: 1.1114609241485596
Validation loss: 2.0230295324838288

Epoch: 6| Step: 4
Training loss: 1.5814704895019531
Validation loss: 2.0224101786972373

Epoch: 6| Step: 5
Training loss: 2.0381076335906982
Validation loss: 2.055374945363691

Epoch: 6| Step: 6
Training loss: 1.5176907777786255
Validation loss: 2.0339819333886586

Epoch: 6| Step: 7
Training loss: 1.67547607421875
Validation loss: 2.028470871269062

Epoch: 6| Step: 8
Training loss: 1.3414207696914673
Validation loss: 2.0321787570112493

Epoch: 6| Step: 9
Training loss: 1.7815897464752197
Validation loss: 2.0110854333446873

Epoch: 6| Step: 10
Training loss: 1.8405898809432983
Validation loss: 2.022802778469619

Epoch: 6| Step: 11
Training loss: 1.4831846952438354
Validation loss: 2.0140406572690575

Epoch: 6| Step: 12
Training loss: 1.9477498531341553
Validation loss: 1.9882420980802147

Epoch: 6| Step: 13
Training loss: 1.9329760074615479
Validation loss: 2.009367478791104

Epoch: 280| Step: 0
Training loss: 1.6151293516159058
Validation loss: 1.9869725050464753

Epoch: 6| Step: 1
Training loss: 1.7188364267349243
Validation loss: 1.9943367255631315

Epoch: 6| Step: 2
Training loss: 1.31288480758667
Validation loss: 2.0103257266424035

Epoch: 6| Step: 3
Training loss: 1.4608008861541748
Validation loss: 2.020498709012103

Epoch: 6| Step: 4
Training loss: 1.5167195796966553
Validation loss: 2.039171165035617

Epoch: 6| Step: 5
Training loss: 2.1855921745300293
Validation loss: 2.0547517884162163

Epoch: 6| Step: 6
Training loss: 1.2016469240188599
Validation loss: 2.036731440533874

Epoch: 6| Step: 7
Training loss: 1.2836886644363403
Validation loss: 1.9999184711005098

Epoch: 6| Step: 8
Training loss: 1.5917129516601562
Validation loss: 2.0152467091878257

Epoch: 6| Step: 9
Training loss: 1.6082992553710938
Validation loss: 1.988247936771762

Epoch: 6| Step: 10
Training loss: 0.9005914926528931
Validation loss: 2.0334744427793767

Epoch: 6| Step: 11
Training loss: 2.412184238433838
Validation loss: 2.0088311472246723

Epoch: 6| Step: 12
Training loss: 2.008540153503418
Validation loss: 2.01182157762589

Epoch: 6| Step: 13
Training loss: 1.4818049669265747
Validation loss: 2.0082618741578955

Epoch: 281| Step: 0
Training loss: 1.4844410419464111
Validation loss: 2.0222081907333864

Epoch: 6| Step: 1
Training loss: 1.4661542177200317
Validation loss: 2.0459669713051087

Epoch: 6| Step: 2
Training loss: 1.2490119934082031
Validation loss: 2.0354935148710847

Epoch: 6| Step: 3
Training loss: 2.0179738998413086
Validation loss: 2.040482762039349

Epoch: 6| Step: 4
Training loss: 1.4180117845535278
Validation loss: 2.066896802635603

Epoch: 6| Step: 5
Training loss: 1.8344042301177979
Validation loss: 2.0452300092225433

Epoch: 6| Step: 6
Training loss: 2.0184664726257324
Validation loss: 2.0478228535703433

Epoch: 6| Step: 7
Training loss: 1.8846919536590576
Validation loss: 2.0218226768637217

Epoch: 6| Step: 8
Training loss: 1.818408489227295
Validation loss: 2.006524820481577

Epoch: 6| Step: 9
Training loss: 1.5416061878204346
Validation loss: 2.0027336151369157

Epoch: 6| Step: 10
Training loss: 1.6659655570983887
Validation loss: 2.005036880893092

Epoch: 6| Step: 11
Training loss: 1.2131547927856445
Validation loss: 2.0151354625660884

Epoch: 6| Step: 12
Training loss: 1.2824451923370361
Validation loss: 2.0701831899663454

Epoch: 6| Step: 13
Training loss: 1.212874412536621
Validation loss: 2.0591540900609826

Epoch: 282| Step: 0
Training loss: 0.9857460260391235
Validation loss: 2.123628863724329

Epoch: 6| Step: 1
Training loss: 1.5519042015075684
Validation loss: 2.1230103533755065

Epoch: 6| Step: 2
Training loss: 1.0492491722106934
Validation loss: 2.117707480666458

Epoch: 6| Step: 3
Training loss: 2.1147985458374023
Validation loss: 2.113201165712008

Epoch: 6| Step: 4
Training loss: 2.0466885566711426
Validation loss: 2.0559402281238186

Epoch: 6| Step: 5
Training loss: 2.0562915802001953
Validation loss: 2.054209893749606

Epoch: 6| Step: 6
Training loss: 1.348710060119629
Validation loss: 2.0137568391779417

Epoch: 6| Step: 7
Training loss: 1.328444242477417
Validation loss: 1.9975360580669936

Epoch: 6| Step: 8
Training loss: 2.0383474826812744
Validation loss: 2.0141693238289125

Epoch: 6| Step: 9
Training loss: 1.313455581665039
Validation loss: 2.0335539387118433

Epoch: 6| Step: 10
Training loss: 1.5532939434051514
Validation loss: 2.039552842417071

Epoch: 6| Step: 11
Training loss: 2.1520423889160156
Validation loss: 2.0659864115458664

Epoch: 6| Step: 12
Training loss: 1.887152075767517
Validation loss: 2.045918264696675

Epoch: 6| Step: 13
Training loss: 1.1847904920578003
Validation loss: 2.054277907135666

Epoch: 283| Step: 0
Training loss: 1.490649938583374
Validation loss: 2.0761404896295197

Epoch: 6| Step: 1
Training loss: 1.5133591890335083
Validation loss: 2.056020495712116

Epoch: 6| Step: 2
Training loss: 1.3694871664047241
Validation loss: 2.0497614696461666

Epoch: 6| Step: 3
Training loss: 1.3487331867218018
Validation loss: 2.023626955606604

Epoch: 6| Step: 4
Training loss: 2.289346694946289
Validation loss: 2.0205961273562525

Epoch: 6| Step: 5
Training loss: 1.3415703773498535
Validation loss: 1.9984264002051404

Epoch: 6| Step: 6
Training loss: 1.603729009628296
Validation loss: 2.0050865014394126

Epoch: 6| Step: 7
Training loss: 1.7298941612243652
Validation loss: 2.0096058512246735

Epoch: 6| Step: 8
Training loss: 1.7059919834136963
Validation loss: 2.0164221512374056

Epoch: 6| Step: 9
Training loss: 1.742631196975708
Validation loss: 2.0435577925815376

Epoch: 6| Step: 10
Training loss: 1.987989902496338
Validation loss: 2.096111712917205

Epoch: 6| Step: 11
Training loss: 1.2385070323944092
Validation loss: 2.04849164460295

Epoch: 6| Step: 12
Training loss: 1.2762870788574219
Validation loss: 2.011681082428143

Epoch: 6| Step: 13
Training loss: 2.2133357524871826
Validation loss: 2.0129622720902964

Epoch: 284| Step: 0
Training loss: 1.7490010261535645
Validation loss: 1.98846588852585

Epoch: 6| Step: 1
Training loss: 2.1115095615386963
Validation loss: 1.9618243543050622

Epoch: 6| Step: 2
Training loss: 1.3815786838531494
Validation loss: 1.9939644669973722

Epoch: 6| Step: 3
Training loss: 1.8317816257476807
Validation loss: 2.000780786237409

Epoch: 6| Step: 4
Training loss: 1.7505584955215454
Validation loss: 2.0004804518914994

Epoch: 6| Step: 5
Training loss: 1.1172715425491333
Validation loss: 2.0139096988144742

Epoch: 6| Step: 6
Training loss: 2.0713868141174316
Validation loss: 2.047732077619081

Epoch: 6| Step: 7
Training loss: 1.868452548980713
Validation loss: 2.0615437863975443

Epoch: 6| Step: 8
Training loss: 1.804184913635254
Validation loss: 2.0424385942438597

Epoch: 6| Step: 9
Training loss: 1.1482210159301758
Validation loss: 2.0417491594950357

Epoch: 6| Step: 10
Training loss: 1.3119616508483887
Validation loss: 2.017442403301116

Epoch: 6| Step: 11
Training loss: 1.2520525455474854
Validation loss: 1.9992150760466052

Epoch: 6| Step: 12
Training loss: 1.7470521926879883
Validation loss: 2.0040025659786758

Epoch: 6| Step: 13
Training loss: 1.3825511932373047
Validation loss: 2.0158410328690723

Epoch: 285| Step: 0
Training loss: 1.249650239944458
Validation loss: 2.0427901642296904

Epoch: 6| Step: 1
Training loss: 0.9188914895057678
Validation loss: 2.0545918915861394

Epoch: 6| Step: 2
Training loss: 1.5734244585037231
Validation loss: 2.070154772009901

Epoch: 6| Step: 3
Training loss: 1.7084941864013672
Validation loss: 2.081494737696904

Epoch: 6| Step: 4
Training loss: 1.9489916563034058
Validation loss: 2.086275536526916

Epoch: 6| Step: 5
Training loss: 1.5763256549835205
Validation loss: 2.0972556068051245

Epoch: 6| Step: 6
Training loss: 1.494913935661316
Validation loss: 2.1032747299440446

Epoch: 6| Step: 7
Training loss: 1.5608899593353271
Validation loss: 2.0999087813079997

Epoch: 6| Step: 8
Training loss: 1.5225797891616821
Validation loss: 2.0426276678680093

Epoch: 6| Step: 9
Training loss: 1.8205877542495728
Validation loss: 2.0021084534224642

Epoch: 6| Step: 10
Training loss: 1.842057466506958
Validation loss: 1.9968085750456779

Epoch: 6| Step: 11
Training loss: 1.6100332736968994
Validation loss: 1.9888045774993075

Epoch: 6| Step: 12
Training loss: 1.8671835660934448
Validation loss: 2.0011856658484346

Epoch: 6| Step: 13
Training loss: 1.8439488410949707
Validation loss: 2.004660673038934

Epoch: 286| Step: 0
Training loss: 1.6523873805999756
Validation loss: 2.033853825702462

Epoch: 6| Step: 1
Training loss: 0.9374738335609436
Validation loss: 2.024809632250058

Epoch: 6| Step: 2
Training loss: 1.6171696186065674
Validation loss: 2.0665560845405824

Epoch: 6| Step: 3
Training loss: 1.6913946866989136
Validation loss: 2.120852508852559

Epoch: 6| Step: 4
Training loss: 1.8548505306243896
Validation loss: 2.083640331863075

Epoch: 6| Step: 5
Training loss: 1.3274505138397217
Validation loss: 2.0665271307832453

Epoch: 6| Step: 6
Training loss: 1.508111596107483
Validation loss: 2.0492518947970484

Epoch: 6| Step: 7
Training loss: 1.8118314743041992
Validation loss: 2.0169001522884575

Epoch: 6| Step: 8
Training loss: 2.5085647106170654
Validation loss: 2.0100586337427937

Epoch: 6| Step: 9
Training loss: 1.7609343528747559
Validation loss: 1.9838983320420789

Epoch: 6| Step: 10
Training loss: 1.44608736038208
Validation loss: 1.979911461953194

Epoch: 6| Step: 11
Training loss: 1.3908504247665405
Validation loss: 1.9749541333926621

Epoch: 6| Step: 12
Training loss: 1.6463747024536133
Validation loss: 2.001037242592022

Epoch: 6| Step: 13
Training loss: 0.7256714701652527
Validation loss: 2.016200623204631

Epoch: 287| Step: 0
Training loss: 1.9964195489883423
Validation loss: 2.0247224069410756

Epoch: 6| Step: 1
Training loss: 1.690025806427002
Validation loss: 2.0041754925122826

Epoch: 6| Step: 2
Training loss: 2.1844820976257324
Validation loss: 2.01929654869982

Epoch: 6| Step: 3
Training loss: 0.8895086050033569
Validation loss: 2.041784326235453

Epoch: 6| Step: 4
Training loss: 1.529146671295166
Validation loss: 2.04057228437034

Epoch: 6| Step: 5
Training loss: 1.6430668830871582
Validation loss: 2.055929901779339

Epoch: 6| Step: 6
Training loss: 2.0322017669677734
Validation loss: 2.0415922621245026

Epoch: 6| Step: 7
Training loss: 1.4545842409133911
Validation loss: 2.0455795564959125

Epoch: 6| Step: 8
Training loss: 1.1911932229995728
Validation loss: 2.0288399701477378

Epoch: 6| Step: 9
Training loss: 1.431376338005066
Validation loss: 2.0041025274543354

Epoch: 6| Step: 10
Training loss: 1.2838292121887207
Validation loss: 1.9890933780259983

Epoch: 6| Step: 11
Training loss: 1.737133264541626
Validation loss: 1.994807961166546

Epoch: 6| Step: 12
Training loss: 1.6075661182403564
Validation loss: 2.0273489144540604

Epoch: 6| Step: 13
Training loss: 1.048708200454712
Validation loss: 2.0168000241761566

Epoch: 288| Step: 0
Training loss: 1.3317420482635498
Validation loss: 2.0261571407318115

Epoch: 6| Step: 1
Training loss: 0.8560298681259155
Validation loss: 2.032042311083886

Epoch: 6| Step: 2
Training loss: 1.2382993698120117
Validation loss: 2.057757318660777

Epoch: 6| Step: 3
Training loss: 2.2411365509033203
Validation loss: 2.1012314929757068

Epoch: 6| Step: 4
Training loss: 1.2204015254974365
Validation loss: 2.0894383461244646

Epoch: 6| Step: 5
Training loss: 1.9989908933639526
Validation loss: 2.0997807236127954

Epoch: 6| Step: 6
Training loss: 1.7025091648101807
Validation loss: 2.072743836269584

Epoch: 6| Step: 7
Training loss: 1.867631435394287
Validation loss: 2.077116576574182

Epoch: 6| Step: 8
Training loss: 1.0379575490951538
Validation loss: 2.046938991033903

Epoch: 6| Step: 9
Training loss: 1.503203272819519
Validation loss: 1.9969292238194456

Epoch: 6| Step: 10
Training loss: 2.3880226612091064
Validation loss: 1.9811510424460135

Epoch: 6| Step: 11
Training loss: 1.0042893886566162
Validation loss: 1.972741634615006

Epoch: 6| Step: 12
Training loss: 1.6999902725219727
Validation loss: 1.9781715805812548

Epoch: 6| Step: 13
Training loss: 1.9553906917572021
Validation loss: 1.9817160867875623

Epoch: 289| Step: 0
Training loss: 1.3391045331954956
Validation loss: 1.9481580744507492

Epoch: 6| Step: 1
Training loss: 1.0648658275604248
Validation loss: 1.9823230697262673

Epoch: 6| Step: 2
Training loss: 2.097747564315796
Validation loss: 1.9874416346191077

Epoch: 6| Step: 3
Training loss: 1.454787254333496
Validation loss: 2.0118157120161158

Epoch: 6| Step: 4
Training loss: 1.617527723312378
Validation loss: 2.0322281981027253

Epoch: 6| Step: 5
Training loss: 1.7694817781448364
Validation loss: 2.0425616566852858

Epoch: 6| Step: 6
Training loss: 2.088479518890381
Validation loss: 2.0295241622514624

Epoch: 6| Step: 7
Training loss: 1.6315805912017822
Validation loss: 2.0548185686911307

Epoch: 6| Step: 8
Training loss: 1.797155737876892
Validation loss: 2.054404112600511

Epoch: 6| Step: 9
Training loss: 0.8942572474479675
Validation loss: 2.0536830284262217

Epoch: 6| Step: 10
Training loss: 1.1591272354125977
Validation loss: 2.0493228230425107

Epoch: 6| Step: 11
Training loss: 1.4657154083251953
Validation loss: 2.051060826547684

Epoch: 6| Step: 12
Training loss: 1.780625820159912
Validation loss: 2.03337049868799

Epoch: 6| Step: 13
Training loss: 1.4934306144714355
Validation loss: 2.019741032713203

Epoch: 290| Step: 0
Training loss: 1.6312271356582642
Validation loss: 2.0370433433081514

Epoch: 6| Step: 1
Training loss: 1.5351544618606567
Validation loss: 2.0346070361393753

Epoch: 6| Step: 2
Training loss: 1.269348382949829
Validation loss: 2.0907151032519597

Epoch: 6| Step: 3
Training loss: 1.4026930332183838
Validation loss: 2.0712103818052556

Epoch: 6| Step: 4
Training loss: 1.692926049232483
Validation loss: 2.062499866690687

Epoch: 6| Step: 5
Training loss: 1.9450606107711792
Validation loss: 2.030408887452977

Epoch: 6| Step: 6
Training loss: 1.596754789352417
Validation loss: 1.994914980344875

Epoch: 6| Step: 7
Training loss: 1.54105806350708
Validation loss: 1.956153541482905

Epoch: 6| Step: 8
Training loss: 1.5656797885894775
Validation loss: 1.9716432838029758

Epoch: 6| Step: 9
Training loss: 1.9932037591934204
Validation loss: 1.9573439680119997

Epoch: 6| Step: 10
Training loss: 1.3369908332824707
Validation loss: 1.9588137608702465

Epoch: 6| Step: 11
Training loss: 1.5797441005706787
Validation loss: 1.9955394357763312

Epoch: 6| Step: 12
Training loss: 1.9971920251846313
Validation loss: 2.003033367536401

Epoch: 6| Step: 13
Training loss: 0.9446664452552795
Validation loss: 2.0478180582805345

Epoch: 291| Step: 0
Training loss: 0.6007883548736572
Validation loss: 2.050626693233367

Epoch: 6| Step: 1
Training loss: 2.087390422821045
Validation loss: 2.0676041738961333

Epoch: 6| Step: 2
Training loss: 1.8218486309051514
Validation loss: 2.058756028452227

Epoch: 6| Step: 3
Training loss: 1.426316499710083
Validation loss: 2.0044370953754713

Epoch: 6| Step: 4
Training loss: 1.1172670125961304
Validation loss: 1.9756200031567646

Epoch: 6| Step: 5
Training loss: 1.8060048818588257
Validation loss: 1.9847747228478874

Epoch: 6| Step: 6
Training loss: 1.550676941871643
Validation loss: 1.964864582143804

Epoch: 6| Step: 7
Training loss: 1.6918531656265259
Validation loss: 1.983929814830903

Epoch: 6| Step: 8
Training loss: 1.3090003728866577
Validation loss: 1.9797956623056883

Epoch: 6| Step: 9
Training loss: 2.084880828857422
Validation loss: 1.9893309211218229

Epoch: 6| Step: 10
Training loss: 1.2451298236846924
Validation loss: 2.0055670584401777

Epoch: 6| Step: 11
Training loss: 1.274209976196289
Validation loss: 2.0131376020369993

Epoch: 6| Step: 12
Training loss: 1.5671336650848389
Validation loss: 2.020345277683709

Epoch: 6| Step: 13
Training loss: 2.6495699882507324
Validation loss: 2.026185275405966

Epoch: 292| Step: 0
Training loss: 2.0252180099487305
Validation loss: 2.0724676809003277

Epoch: 6| Step: 1
Training loss: 1.1708135604858398
Validation loss: 2.064653055642241

Epoch: 6| Step: 2
Training loss: 2.0827226638793945
Validation loss: 2.1186835996566282

Epoch: 6| Step: 3
Training loss: 1.4548656940460205
Validation loss: 2.08416639092148

Epoch: 6| Step: 4
Training loss: 1.0816235542297363
Validation loss: 2.057720080498726

Epoch: 6| Step: 5
Training loss: 1.4423545598983765
Validation loss: 2.05705100746565

Epoch: 6| Step: 6
Training loss: 1.7554981708526611
Validation loss: 2.0024533374335176

Epoch: 6| Step: 7
Training loss: 1.8056650161743164
Validation loss: 1.9777140053369666

Epoch: 6| Step: 8
Training loss: 1.32456636428833
Validation loss: 1.9894581123064923

Epoch: 6| Step: 9
Training loss: 1.1955504417419434
Validation loss: 1.976411578475788

Epoch: 6| Step: 10
Training loss: 1.6591476202011108
Validation loss: 1.9436486844093568

Epoch: 6| Step: 11
Training loss: 1.156049132347107
Validation loss: 1.9355465135266703

Epoch: 6| Step: 12
Training loss: 2.2556025981903076
Validation loss: 1.929768596285133

Epoch: 6| Step: 13
Training loss: 2.005842924118042
Validation loss: 1.93313314196884

Epoch: 293| Step: 0
Training loss: 2.241384506225586
Validation loss: 1.9789745448738016

Epoch: 6| Step: 1
Training loss: 1.7720308303833008
Validation loss: 2.0014330520424792

Epoch: 6| Step: 2
Training loss: 1.6337664127349854
Validation loss: 2.0294174494281894

Epoch: 6| Step: 3
Training loss: 1.7119147777557373
Validation loss: 2.0952561414369972

Epoch: 6| Step: 4
Training loss: 2.202531337738037
Validation loss: 2.1145522363724245

Epoch: 6| Step: 5
Training loss: 1.40972900390625
Validation loss: 2.116961891933154

Epoch: 6| Step: 6
Training loss: 1.160550832748413
Validation loss: 2.0713593408625615

Epoch: 6| Step: 7
Training loss: 1.5099408626556396
Validation loss: 2.082794512471845

Epoch: 6| Step: 8
Training loss: 0.9596918821334839
Validation loss: 2.054803507302397

Epoch: 6| Step: 9
Training loss: 1.3319295644760132
Validation loss: 2.0199315778670774

Epoch: 6| Step: 10
Training loss: 0.9588333368301392
Validation loss: 2.0147518650177987

Epoch: 6| Step: 11
Training loss: 1.408707857131958
Validation loss: 2.0029320909130957

Epoch: 6| Step: 12
Training loss: 1.9120616912841797
Validation loss: 1.981364837256811

Epoch: 6| Step: 13
Training loss: 1.4216090440750122
Validation loss: 2.0148351038655927

Epoch: 294| Step: 0
Training loss: 1.5294053554534912
Validation loss: 1.988551744850733

Epoch: 6| Step: 1
Training loss: 1.4879956245422363
Validation loss: 2.002792475044086

Epoch: 6| Step: 2
Training loss: 1.5783743858337402
Validation loss: 2.0448481626408075

Epoch: 6| Step: 3
Training loss: 1.6406588554382324
Validation loss: 2.031628921467771

Epoch: 6| Step: 4
Training loss: 1.712069034576416
Validation loss: 2.0031598883290447

Epoch: 6| Step: 5
Training loss: 1.5070552825927734
Validation loss: 2.0019009292766614

Epoch: 6| Step: 6
Training loss: 1.3055776357650757
Validation loss: 1.9899253601668982

Epoch: 6| Step: 7
Training loss: 1.6367369890213013
Validation loss: 1.9777731203263806

Epoch: 6| Step: 8
Training loss: 1.1367369890213013
Validation loss: 2.00180802037639

Epoch: 6| Step: 9
Training loss: 1.3272995948791504
Validation loss: 2.0067878538562405

Epoch: 6| Step: 10
Training loss: 1.5582278966903687
Validation loss: 2.0540066367836407

Epoch: 6| Step: 11
Training loss: 2.1704888343811035
Validation loss: 2.0737226804097495

Epoch: 6| Step: 12
Training loss: 0.8948372602462769
Validation loss: 2.0936043775209816

Epoch: 6| Step: 13
Training loss: 2.115457773208618
Validation loss: 2.116515903062718

Epoch: 295| Step: 0
Training loss: 1.3825581073760986
Validation loss: 2.1482103152941634

Epoch: 6| Step: 1
Training loss: 0.8851932287216187
Validation loss: 2.103070072589382

Epoch: 6| Step: 2
Training loss: 1.9796435832977295
Validation loss: 2.0571939740129697

Epoch: 6| Step: 3
Training loss: 1.2970086336135864
Validation loss: 2.032088295105965

Epoch: 6| Step: 4
Training loss: 1.4147721529006958
Validation loss: 1.9867961124707294

Epoch: 6| Step: 5
Training loss: 1.6223760843276978
Validation loss: 1.945874032153878

Epoch: 6| Step: 6
Training loss: 1.4215837717056274
Validation loss: 1.9492332871242235

Epoch: 6| Step: 7
Training loss: 2.027289390563965
Validation loss: 1.965505430775304

Epoch: 6| Step: 8
Training loss: 1.8887696266174316
Validation loss: 1.9627588372076712

Epoch: 6| Step: 9
Training loss: 1.915515661239624
Validation loss: 2.0019052118383427

Epoch: 6| Step: 10
Training loss: 0.9896498918533325
Validation loss: 2.013358028986121

Epoch: 6| Step: 11
Training loss: 1.929257869720459
Validation loss: 2.0236797268672655

Epoch: 6| Step: 12
Training loss: 1.329505205154419
Validation loss: 2.046785834015057

Epoch: 6| Step: 13
Training loss: 1.7023484706878662
Validation loss: 2.0525502786841443

Epoch: 296| Step: 0
Training loss: 1.8416671752929688
Validation loss: 2.00797043308135

Epoch: 6| Step: 1
Training loss: 1.6939470767974854
Validation loss: 1.9866508873560096

Epoch: 6| Step: 2
Training loss: 0.7380120754241943
Validation loss: 1.9513003339049637

Epoch: 6| Step: 3
Training loss: 1.5483660697937012
Validation loss: 1.9504017419712518

Epoch: 6| Step: 4
Training loss: 1.6079158782958984
Validation loss: 1.9473054101390224

Epoch: 6| Step: 5
Training loss: 1.5815112590789795
Validation loss: 1.9490827732188727

Epoch: 6| Step: 6
Training loss: 1.1711368560791016
Validation loss: 1.955301805209088

Epoch: 6| Step: 7
Training loss: 1.4985077381134033
Validation loss: 1.987397164426824

Epoch: 6| Step: 8
Training loss: 0.9682753682136536
Validation loss: 2.034417958669765

Epoch: 6| Step: 9
Training loss: 1.7337101697921753
Validation loss: 2.089983037723008

Epoch: 6| Step: 10
Training loss: 1.9197484254837036
Validation loss: 2.160781673205796

Epoch: 6| Step: 11
Training loss: 1.9468715190887451
Validation loss: 2.21351820166393

Epoch: 6| Step: 12
Training loss: 1.841196060180664
Validation loss: 2.215939583316926

Epoch: 6| Step: 13
Training loss: 1.825391173362732
Validation loss: 2.204943823558028

Epoch: 297| Step: 0
Training loss: 1.3217756748199463
Validation loss: 2.148747036533971

Epoch: 6| Step: 1
Training loss: 1.8319337368011475
Validation loss: 2.0958980770521265

Epoch: 6| Step: 2
Training loss: 1.2972161769866943
Validation loss: 2.0622135875045613

Epoch: 6| Step: 3
Training loss: 1.929734468460083
Validation loss: 2.009610443345962

Epoch: 6| Step: 4
Training loss: 1.9605529308319092
Validation loss: 2.0108395596986175

Epoch: 6| Step: 5
Training loss: 1.5931998491287231
Validation loss: 2.005778019146253

Epoch: 6| Step: 6
Training loss: 1.841787576675415
Validation loss: 2.0032416947426332

Epoch: 6| Step: 7
Training loss: 1.1315295696258545
Validation loss: 1.9951981434258081

Epoch: 6| Step: 8
Training loss: 1.1278235912322998
Validation loss: 1.9837756772195139

Epoch: 6| Step: 9
Training loss: 1.6525204181671143
Validation loss: 1.9909020111125002

Epoch: 6| Step: 10
Training loss: 1.7402113676071167
Validation loss: 2.021246229448626

Epoch: 6| Step: 11
Training loss: 1.6168066263198853
Validation loss: 2.051156679789225

Epoch: 6| Step: 12
Training loss: 1.6874386072158813
Validation loss: 2.056444303963774

Epoch: 6| Step: 13
Training loss: 1.1268887519836426
Validation loss: 2.0242561358277515

Epoch: 298| Step: 0
Training loss: 1.2458164691925049
Validation loss: 2.032371562014344

Epoch: 6| Step: 1
Training loss: 1.5558578968048096
Validation loss: 1.9774456485625236

Epoch: 6| Step: 2
Training loss: 1.5327961444854736
Validation loss: 1.9956439900141891

Epoch: 6| Step: 3
Training loss: 1.5291342735290527
Validation loss: 2.002906581406952

Epoch: 6| Step: 4
Training loss: 1.5504766702651978
Validation loss: 2.021928855167922

Epoch: 6| Step: 5
Training loss: 1.7099690437316895
Validation loss: 2.0719224112008208

Epoch: 6| Step: 6
Training loss: 1.4382203817367554
Validation loss: 2.0794699204865323

Epoch: 6| Step: 7
Training loss: 1.8563165664672852
Validation loss: 2.1039698034204464

Epoch: 6| Step: 8
Training loss: 1.6278712749481201
Validation loss: 2.06713524428747

Epoch: 6| Step: 9
Training loss: 1.2454787492752075
Validation loss: 2.0812675670910905

Epoch: 6| Step: 10
Training loss: 1.4032684564590454
Validation loss: 2.0321330985715313

Epoch: 6| Step: 11
Training loss: 1.4132602214813232
Validation loss: 2.0082098040529477

Epoch: 6| Step: 12
Training loss: 1.608705759048462
Validation loss: 1.983982547636955

Epoch: 6| Step: 13
Training loss: 1.7581067085266113
Validation loss: 1.9611801216679234

Epoch: 299| Step: 0
Training loss: 2.0431594848632812
Validation loss: 1.9609492581377748

Epoch: 6| Step: 1
Training loss: 1.9512773752212524
Validation loss: 1.9562873096876248

Epoch: 6| Step: 2
Training loss: 1.513530969619751
Validation loss: 1.9738477096762708

Epoch: 6| Step: 3
Training loss: 1.7012708187103271
Validation loss: 1.9777680545724847

Epoch: 6| Step: 4
Training loss: 1.3781826496124268
Validation loss: 2.0413348931138233

Epoch: 6| Step: 5
Training loss: 1.8748795986175537
Validation loss: 2.047355524955257

Epoch: 6| Step: 6
Training loss: 1.4849188327789307
Validation loss: 2.122153023237823

Epoch: 6| Step: 7
Training loss: 1.3609619140625
Validation loss: 2.1582627578448226

Epoch: 6| Step: 8
Training loss: 1.3492661714553833
Validation loss: 2.17286362442919

Epoch: 6| Step: 9
Training loss: 1.1362308263778687
Validation loss: 2.1374551198815785

Epoch: 6| Step: 10
Training loss: 1.7990278005599976
Validation loss: 2.116603002753309

Epoch: 6| Step: 11
Training loss: 1.300100564956665
Validation loss: 2.0472376833679857

Epoch: 6| Step: 12
Training loss: 1.2784873247146606
Validation loss: 1.9955986417749876

Epoch: 6| Step: 13
Training loss: 0.9767443537712097
Validation loss: 1.9588474458263767

Epoch: 300| Step: 0
Training loss: 2.057542324066162
Validation loss: 1.9342117668480001

Epoch: 6| Step: 1
Training loss: 1.4299542903900146
Validation loss: 1.9415811492550759

Epoch: 6| Step: 2
Training loss: 1.1801459789276123
Validation loss: 1.9388850876080093

Epoch: 6| Step: 3
Training loss: 1.5449984073638916
Validation loss: 1.9495563609625703

Epoch: 6| Step: 4
Training loss: 1.680318832397461
Validation loss: 1.9562488102143811

Epoch: 6| Step: 5
Training loss: 1.3430449962615967
Validation loss: 1.9864573632517168

Epoch: 6| Step: 6
Training loss: 1.2774354219436646
Validation loss: 2.011952714253497

Epoch: 6| Step: 7
Training loss: 1.4758028984069824
Validation loss: 2.0589334759660947

Epoch: 6| Step: 8
Training loss: 2.004434585571289
Validation loss: 2.08294891413822

Epoch: 6| Step: 9
Training loss: 1.1501212120056152
Validation loss: 2.0976607902075655

Epoch: 6| Step: 10
Training loss: 1.952713966369629
Validation loss: 2.1195302522310646

Epoch: 6| Step: 11
Training loss: 1.5619568824768066
Validation loss: 2.1542789500246764

Epoch: 6| Step: 12
Training loss: 1.0002477169036865
Validation loss: 2.109274561687182

Epoch: 6| Step: 13
Training loss: 1.4331766366958618
Validation loss: 2.092801924674742

Epoch: 301| Step: 0
Training loss: 0.6868199110031128
Validation loss: 2.0503734773205173

Epoch: 6| Step: 1
Training loss: 1.339966058731079
Validation loss: 2.0290696146667644

Epoch: 6| Step: 2
Training loss: 1.2751307487487793
Validation loss: 2.036129287494126

Epoch: 6| Step: 3
Training loss: 1.6361513137817383
Validation loss: 2.0200735599763933

Epoch: 6| Step: 4
Training loss: 1.6291182041168213
Validation loss: 2.019963402901926

Epoch: 6| Step: 5
Training loss: 1.3001184463500977
Validation loss: 1.9910186413795716

Epoch: 6| Step: 6
Training loss: 1.3936156034469604
Validation loss: 1.9751468012409825

Epoch: 6| Step: 7
Training loss: 1.5780664682388306
Validation loss: 1.9790044010326426

Epoch: 6| Step: 8
Training loss: 1.7952953577041626
Validation loss: 1.9741400070087884

Epoch: 6| Step: 9
Training loss: 1.916285753250122
Validation loss: 1.97595432625022

Epoch: 6| Step: 10
Training loss: 1.5543532371520996
Validation loss: 1.9698014272156583

Epoch: 6| Step: 11
Training loss: 1.3514875173568726
Validation loss: 2.013834040652039

Epoch: 6| Step: 12
Training loss: 2.3277087211608887
Validation loss: 2.038387087083632

Epoch: 6| Step: 13
Training loss: 0.8444472551345825
Validation loss: 2.076016964450959

Epoch: 302| Step: 0
Training loss: 1.9832041263580322
Validation loss: 2.1226405917957263

Epoch: 6| Step: 1
Training loss: 2.0487465858459473
Validation loss: 2.1450684608951693

Epoch: 6| Step: 2
Training loss: 1.7090363502502441
Validation loss: 2.1360003820029636

Epoch: 6| Step: 3
Training loss: 1.493239402770996
Validation loss: 2.0999102054103727

Epoch: 6| Step: 4
Training loss: 1.8205921649932861
Validation loss: 2.044262163100704

Epoch: 6| Step: 5
Training loss: 1.1872532367706299
Validation loss: 2.0276913014791345

Epoch: 6| Step: 6
Training loss: 1.1591887474060059
Validation loss: 2.001368300889128

Epoch: 6| Step: 7
Training loss: 1.4661998748779297
Validation loss: 1.9940542181332905

Epoch: 6| Step: 8
Training loss: 1.0176646709442139
Validation loss: 1.985466173900071

Epoch: 6| Step: 9
Training loss: 0.8585070371627808
Validation loss: 2.004794724525944

Epoch: 6| Step: 10
Training loss: 1.9866994619369507
Validation loss: 2.012300718215204

Epoch: 6| Step: 11
Training loss: 1.311750888824463
Validation loss: 2.0103392447194746

Epoch: 6| Step: 12
Training loss: 1.37214195728302
Validation loss: 2.0291913222241145

Epoch: 6| Step: 13
Training loss: 1.779120922088623
Validation loss: 2.03834778775451

Epoch: 303| Step: 0
Training loss: 1.7976568937301636
Validation loss: 2.0141637761105775

Epoch: 6| Step: 1
Training loss: 1.860615849494934
Validation loss: 1.9927447290830715

Epoch: 6| Step: 2
Training loss: 2.3159286975860596
Validation loss: 1.9882131161228302

Epoch: 6| Step: 3
Training loss: 1.006615161895752
Validation loss: 1.9593643321785876

Epoch: 6| Step: 4
Training loss: 1.443906545639038
Validation loss: 1.9595489219952655

Epoch: 6| Step: 5
Training loss: 1.8335273265838623
Validation loss: 1.9722372754927604

Epoch: 6| Step: 6
Training loss: 1.4834916591644287
Validation loss: 1.9638678578920261

Epoch: 6| Step: 7
Training loss: 0.8996604681015015
Validation loss: 2.0096757847775697

Epoch: 6| Step: 8
Training loss: 1.9367281198501587
Validation loss: 2.04327630612158

Epoch: 6| Step: 9
Training loss: 1.3590810298919678
Validation loss: 2.0495829505305134

Epoch: 6| Step: 10
Training loss: 1.1227164268493652
Validation loss: 2.08742553957047

Epoch: 6| Step: 11
Training loss: 1.22678804397583
Validation loss: 2.0801726361756683

Epoch: 6| Step: 12
Training loss: 1.1501288414001465
Validation loss: 2.091018607539515

Epoch: 6| Step: 13
Training loss: 0.8971400856971741
Validation loss: 2.06475281459029

Epoch: 304| Step: 0
Training loss: 1.4450500011444092
Validation loss: 2.067047378068329

Epoch: 6| Step: 1
Training loss: 1.0409953594207764
Validation loss: 2.0168743389908985

Epoch: 6| Step: 2
Training loss: 1.8270819187164307
Validation loss: 2.008894657575956

Epoch: 6| Step: 3
Training loss: 1.154378890991211
Validation loss: 1.9744784203908776

Epoch: 6| Step: 4
Training loss: 1.8553391695022583
Validation loss: 1.9731249527264667

Epoch: 6| Step: 5
Training loss: 1.932258129119873
Validation loss: 1.9962621734988304

Epoch: 6| Step: 6
Training loss: 1.3647589683532715
Validation loss: 2.0113948506693684

Epoch: 6| Step: 7
Training loss: 1.351468563079834
Validation loss: 2.0300807491425545

Epoch: 6| Step: 8
Training loss: 1.6214241981506348
Validation loss: 2.0701117028472242

Epoch: 6| Step: 9
Training loss: 1.549239993095398
Validation loss: 2.0679712244259414

Epoch: 6| Step: 10
Training loss: 1.6634480953216553
Validation loss: 2.0595792621694584

Epoch: 6| Step: 11
Training loss: 1.2856152057647705
Validation loss: 2.0243994318028933

Epoch: 6| Step: 12
Training loss: 1.2553969621658325
Validation loss: 2.022436644441338

Epoch: 6| Step: 13
Training loss: 1.1697545051574707
Validation loss: 2.0019752902369343

Epoch: 305| Step: 0
Training loss: 2.077080488204956
Validation loss: 1.9741062066888297

Epoch: 6| Step: 1
Training loss: 1.0299439430236816
Validation loss: 1.9701598369947044

Epoch: 6| Step: 2
Training loss: 1.285020112991333
Validation loss: 1.9806587324347547

Epoch: 6| Step: 3
Training loss: 1.684267282485962
Validation loss: 2.003268358527973

Epoch: 6| Step: 4
Training loss: 1.695337176322937
Validation loss: 2.0297353216396865

Epoch: 6| Step: 5
Training loss: 2.103191614151001
Validation loss: 2.044755415249896

Epoch: 6| Step: 6
Training loss: 1.6639139652252197
Validation loss: 2.0443180966120895

Epoch: 6| Step: 7
Training loss: 1.5450234413146973
Validation loss: 2.0478588945122174

Epoch: 6| Step: 8
Training loss: 1.050431251525879
Validation loss: 2.0634074980212795

Epoch: 6| Step: 9
Training loss: 0.6497266292572021
Validation loss: 2.024842728850662

Epoch: 6| Step: 10
Training loss: 1.1256192922592163
Validation loss: 2.0080200856731785

Epoch: 6| Step: 11
Training loss: 1.6420994997024536
Validation loss: 1.9656680989009079

Epoch: 6| Step: 12
Training loss: 1.51790452003479
Validation loss: 2.0069561171275314

Epoch: 6| Step: 13
Training loss: 1.4068998098373413
Validation loss: 2.0113568203423613

Epoch: 306| Step: 0
Training loss: 1.5938351154327393
Validation loss: 2.015670229029912

Epoch: 6| Step: 1
Training loss: 0.8681516647338867
Validation loss: 2.0072603405162854

Epoch: 6| Step: 2
Training loss: 1.4013882875442505
Validation loss: 2.0222313134900984

Epoch: 6| Step: 3
Training loss: 1.0421364307403564
Validation loss: 2.0175440234522664

Epoch: 6| Step: 4
Training loss: 1.6467515230178833
Validation loss: 2.0421879419716458

Epoch: 6| Step: 5
Training loss: 1.2034502029418945
Validation loss: 2.073103970096957

Epoch: 6| Step: 6
Training loss: 1.038271427154541
Validation loss: 2.0592222008653867

Epoch: 6| Step: 7
Training loss: 1.1611244678497314
Validation loss: 2.0619101191079743

Epoch: 6| Step: 8
Training loss: 1.5323470830917358
Validation loss: 2.0649881260369414

Epoch: 6| Step: 9
Training loss: 1.4967654943466187
Validation loss: 2.0272604009156585

Epoch: 6| Step: 10
Training loss: 1.7185254096984863
Validation loss: 2.028864687488925

Epoch: 6| Step: 11
Training loss: 1.4073094129562378
Validation loss: 2.0179580616694626

Epoch: 6| Step: 12
Training loss: 1.8025944232940674
Validation loss: 2.0030634531410794

Epoch: 6| Step: 13
Training loss: 2.552285671234131
Validation loss: 1.981889973404587

Epoch: 307| Step: 0
Training loss: 1.6932746171951294
Validation loss: 1.9743306739355928

Epoch: 6| Step: 1
Training loss: 1.6285260915756226
Validation loss: 1.944538152346047

Epoch: 6| Step: 2
Training loss: 2.0552291870117188
Validation loss: 1.9519257776198848

Epoch: 6| Step: 3
Training loss: 1.529353141784668
Validation loss: 1.9455262294379614

Epoch: 6| Step: 4
Training loss: 1.6654599905014038
Validation loss: 1.96265229358468

Epoch: 6| Step: 5
Training loss: 1.3585710525512695
Validation loss: 1.9816524687633719

Epoch: 6| Step: 6
Training loss: 1.5357167720794678
Validation loss: 2.014069507198949

Epoch: 6| Step: 7
Training loss: 1.0292282104492188
Validation loss: 2.06616775707532

Epoch: 6| Step: 8
Training loss: 1.0852727890014648
Validation loss: 2.081102745507353

Epoch: 6| Step: 9
Training loss: 1.554470181465149
Validation loss: 2.0869221289952598

Epoch: 6| Step: 10
Training loss: 1.3916739225387573
Validation loss: 2.073517612231675

Epoch: 6| Step: 11
Training loss: 1.2192585468292236
Validation loss: 2.0577596772101616

Epoch: 6| Step: 12
Training loss: 1.0973646640777588
Validation loss: 2.062519537505283

Epoch: 6| Step: 13
Training loss: 1.772270679473877
Validation loss: 2.0318460361931914

Epoch: 308| Step: 0
Training loss: 1.5704710483551025
Validation loss: 2.0305282505609656

Epoch: 6| Step: 1
Training loss: 1.040908932685852
Validation loss: 2.02068079158824

Epoch: 6| Step: 2
Training loss: 1.9294036626815796
Validation loss: 2.0119888974774267

Epoch: 6| Step: 3
Training loss: 1.4129300117492676
Validation loss: 1.9903883780202558

Epoch: 6| Step: 4
Training loss: 1.900087833404541
Validation loss: 1.9641217249695972

Epoch: 6| Step: 5
Training loss: 1.0794264078140259
Validation loss: 2.0156370260382213

Epoch: 6| Step: 6
Training loss: 1.1608600616455078
Validation loss: 2.0071283796782136

Epoch: 6| Step: 7
Training loss: 1.7998061180114746
Validation loss: 2.0293868998045563

Epoch: 6| Step: 8
Training loss: 1.1937474012374878
Validation loss: 2.0146828492482505

Epoch: 6| Step: 9
Training loss: 1.0696568489074707
Validation loss: 2.001210722872006

Epoch: 6| Step: 10
Training loss: 1.738539218902588
Validation loss: 1.9934610859040292

Epoch: 6| Step: 11
Training loss: 1.1290884017944336
Validation loss: 2.023266678215355

Epoch: 6| Step: 12
Training loss: 1.1023836135864258
Validation loss: 2.029552698135376

Epoch: 6| Step: 13
Training loss: 2.360146999359131
Validation loss: 2.015909005236882

Epoch: 309| Step: 0
Training loss: 0.9784782528877258
Validation loss: 2.0475914888484503

Epoch: 6| Step: 1
Training loss: 1.7415504455566406
Validation loss: 2.054833709552724

Epoch: 6| Step: 2
Training loss: 1.4525412321090698
Validation loss: 2.0360380500875492

Epoch: 6| Step: 3
Training loss: 1.3540239334106445
Validation loss: 2.023936676722701

Epoch: 6| Step: 4
Training loss: 1.0085686445236206
Validation loss: 1.9843742949988252

Epoch: 6| Step: 5
Training loss: 0.9461339116096497
Validation loss: 2.0058516763871714

Epoch: 6| Step: 6
Training loss: 2.105600357055664
Validation loss: 2.0043526554620392

Epoch: 6| Step: 7
Training loss: 1.165665864944458
Validation loss: 1.9996968469312113

Epoch: 6| Step: 8
Training loss: 1.972060203552246
Validation loss: 1.9719703582025343

Epoch: 6| Step: 9
Training loss: 1.2753872871398926
Validation loss: 1.9657329897726736

Epoch: 6| Step: 10
Training loss: 1.5919592380523682
Validation loss: 1.9542271450001707

Epoch: 6| Step: 11
Training loss: 1.5313451290130615
Validation loss: 1.972991128121653

Epoch: 6| Step: 12
Training loss: 1.1892588138580322
Validation loss: 1.9823319142864597

Epoch: 6| Step: 13
Training loss: 1.7885377407073975
Validation loss: 2.0031926965200775

Epoch: 310| Step: 0
Training loss: 1.4683494567871094
Validation loss: 2.024498601113596

Epoch: 6| Step: 1
Training loss: 0.9909462332725525
Validation loss: 2.035353869520208

Epoch: 6| Step: 2
Training loss: 0.9934833645820618
Validation loss: 2.0602334353231613

Epoch: 6| Step: 3
Training loss: 1.7852380275726318
Validation loss: 2.085925045833793

Epoch: 6| Step: 4
Training loss: 1.592450737953186
Validation loss: 2.0896911672366563

Epoch: 6| Step: 5
Training loss: 2.235640048980713
Validation loss: 2.0602147938102804

Epoch: 6| Step: 6
Training loss: 1.2823314666748047
Validation loss: 2.0302948054446968

Epoch: 6| Step: 7
Training loss: 1.3752937316894531
Validation loss: 2.0101859556731356

Epoch: 6| Step: 8
Training loss: 1.6079373359680176
Validation loss: 1.978369951248169

Epoch: 6| Step: 9
Training loss: 1.6193571090698242
Validation loss: 1.9771458871902958

Epoch: 6| Step: 10
Training loss: 1.0662273168563843
Validation loss: 1.9425156706122941

Epoch: 6| Step: 11
Training loss: 1.4398865699768066
Validation loss: 1.9421432095189248

Epoch: 6| Step: 12
Training loss: 1.6272592544555664
Validation loss: 1.92197121215123

Epoch: 6| Step: 13
Training loss: 1.3074005842208862
Validation loss: 1.9659932044244581

Epoch: 311| Step: 0
Training loss: 1.236149787902832
Validation loss: 1.9769956809218212

Epoch: 6| Step: 1
Training loss: 1.4219458103179932
Validation loss: 2.00871455413039

Epoch: 6| Step: 2
Training loss: 1.8511357307434082
Validation loss: 2.008088122132004

Epoch: 6| Step: 3
Training loss: 1.0439159870147705
Validation loss: 2.0501206356992006

Epoch: 6| Step: 4
Training loss: 1.4349172115325928
Validation loss: 2.0701769987742105

Epoch: 6| Step: 5
Training loss: 1.4280729293823242
Validation loss: 2.0724868389867965

Epoch: 6| Step: 6
Training loss: 1.1990925073623657
Validation loss: 2.075116052422472

Epoch: 6| Step: 7
Training loss: 1.1889057159423828
Validation loss: 2.047240893046061

Epoch: 6| Step: 8
Training loss: 1.606468915939331
Validation loss: 2.0472339442981187

Epoch: 6| Step: 9
Training loss: 1.448317527770996
Validation loss: 2.0024610616827525

Epoch: 6| Step: 10
Training loss: 1.3506165742874146
Validation loss: 1.9443566183890066

Epoch: 6| Step: 11
Training loss: 1.7899609804153442
Validation loss: 1.9339284140576598

Epoch: 6| Step: 12
Training loss: 1.3299479484558105
Validation loss: 1.936125534836964

Epoch: 6| Step: 13
Training loss: 2.2834227085113525
Validation loss: 1.978472000809126

Epoch: 312| Step: 0
Training loss: 1.4699592590332031
Validation loss: 2.0144404954807733

Epoch: 6| Step: 1
Training loss: 2.290956497192383
Validation loss: 2.0678188031719578

Epoch: 6| Step: 2
Training loss: 2.2262401580810547
Validation loss: 2.011963008552469

Epoch: 6| Step: 3
Training loss: 1.3485060930252075
Validation loss: 1.9885293053042503

Epoch: 6| Step: 4
Training loss: 1.1772935390472412
Validation loss: 1.9803971218806442

Epoch: 6| Step: 5
Training loss: 1.0468201637268066
Validation loss: 1.9973530410438456

Epoch: 6| Step: 6
Training loss: 0.7290942668914795
Validation loss: 2.0183201028454687

Epoch: 6| Step: 7
Training loss: 2.049753427505493
Validation loss: 1.9941821803328812

Epoch: 6| Step: 8
Training loss: 1.1954782009124756
Validation loss: 2.0029605486059703

Epoch: 6| Step: 9
Training loss: 1.261472463607788
Validation loss: 2.016870114111131

Epoch: 6| Step: 10
Training loss: 1.24428391456604
Validation loss: 2.0162445422141784

Epoch: 6| Step: 11
Training loss: 1.8051857948303223
Validation loss: 2.0016171522037958

Epoch: 6| Step: 12
Training loss: 1.036765217781067
Validation loss: 1.9941625287455897

Epoch: 6| Step: 13
Training loss: 1.33091139793396
Validation loss: 1.989316027651551

Epoch: 313| Step: 0
Training loss: 1.0643515586853027
Validation loss: 1.9627560364302767

Epoch: 6| Step: 1
Training loss: 0.666202962398529
Validation loss: 1.9481796987595097

Epoch: 6| Step: 2
Training loss: 1.6837000846862793
Validation loss: 1.9547273715337117

Epoch: 6| Step: 3
Training loss: 1.713747501373291
Validation loss: 1.9584027733854068

Epoch: 6| Step: 4
Training loss: 1.2908341884613037
Validation loss: 1.9603594733822731

Epoch: 6| Step: 5
Training loss: 1.522805094718933
Validation loss: 1.9780601737319783

Epoch: 6| Step: 6
Training loss: 1.4805998802185059
Validation loss: 1.9888324942640079

Epoch: 6| Step: 7
Training loss: 1.1446985006332397
Validation loss: 2.020773108287524

Epoch: 6| Step: 8
Training loss: 1.6522114276885986
Validation loss: 2.000000064091016

Epoch: 6| Step: 9
Training loss: 1.1872811317443848
Validation loss: 2.0092379098297446

Epoch: 6| Step: 10
Training loss: 1.7368942499160767
Validation loss: 1.983234272208265

Epoch: 6| Step: 11
Training loss: 1.6865496635437012
Validation loss: 2.010124025806304

Epoch: 6| Step: 12
Training loss: 1.394248366355896
Validation loss: 2.0144015281431136

Epoch: 6| Step: 13
Training loss: 1.1770045757293701
Validation loss: 2.0152545077826387

Epoch: 314| Step: 0
Training loss: 1.4641369581222534
Validation loss: 2.0138958397731987

Epoch: 6| Step: 1
Training loss: 1.313568115234375
Validation loss: 2.0078363944125432

Epoch: 6| Step: 2
Training loss: 1.9817144870758057
Validation loss: 2.0018536070341706

Epoch: 6| Step: 3
Training loss: 0.9480339288711548
Validation loss: 1.9927800842510757

Epoch: 6| Step: 4
Training loss: 1.2275606393814087
Validation loss: 2.0076793547599547

Epoch: 6| Step: 5
Training loss: 1.368909478187561
Validation loss: 2.0120147171840874

Epoch: 6| Step: 6
Training loss: 1.180748701095581
Validation loss: 1.983723068750033

Epoch: 6| Step: 7
Training loss: 0.7046400308609009
Validation loss: 1.9890066654451433

Epoch: 6| Step: 8
Training loss: 1.134107232093811
Validation loss: 2.00192621702789

Epoch: 6| Step: 9
Training loss: 1.218189001083374
Validation loss: 2.0252229167569067

Epoch: 6| Step: 10
Training loss: 1.896435260772705
Validation loss: 2.0013857938910045

Epoch: 6| Step: 11
Training loss: 1.9090662002563477
Validation loss: 2.020103536626344

Epoch: 6| Step: 12
Training loss: 1.4434890747070312
Validation loss: 2.0182084101502613

Epoch: 6| Step: 13
Training loss: 2.1115074157714844
Validation loss: 1.9754425646156393

Epoch: 315| Step: 0
Training loss: 1.6708521842956543
Validation loss: 1.98839488849845

Epoch: 6| Step: 1
Training loss: 1.1114301681518555
Validation loss: 2.0142116802994923

Epoch: 6| Step: 2
Training loss: 1.1687498092651367
Validation loss: 2.004999173584805

Epoch: 6| Step: 3
Training loss: 0.8725913166999817
Validation loss: 2.0319173182210615

Epoch: 6| Step: 4
Training loss: 1.117530107498169
Validation loss: 2.037033301527782

Epoch: 6| Step: 5
Training loss: 2.264382839202881
Validation loss: 2.0368660406399797

Epoch: 6| Step: 6
Training loss: 1.2214465141296387
Validation loss: 2.026812098359549

Epoch: 6| Step: 7
Training loss: 1.6149319410324097
Validation loss: 2.0275860127582344

Epoch: 6| Step: 8
Training loss: 0.9737692475318909
Validation loss: 1.9977771941051687

Epoch: 6| Step: 9
Training loss: 1.0997169017791748
Validation loss: 2.015956868407547

Epoch: 6| Step: 10
Training loss: 2.283677339553833
Validation loss: 2.016749938329061

Epoch: 6| Step: 11
Training loss: 1.512019395828247
Validation loss: 1.970420898929719

Epoch: 6| Step: 12
Training loss: 1.4775092601776123
Validation loss: 1.9571606189973894

Epoch: 6| Step: 13
Training loss: 0.6018370389938354
Validation loss: 1.9537787591257403

Epoch: 316| Step: 0
Training loss: 1.598848819732666
Validation loss: 1.9526601004344162

Epoch: 6| Step: 1
Training loss: 1.2073020935058594
Validation loss: 1.9540017189518097

Epoch: 6| Step: 2
Training loss: 1.2181661128997803
Validation loss: 1.9652651138203119

Epoch: 6| Step: 3
Training loss: 1.0393562316894531
Validation loss: 1.9935295222907938

Epoch: 6| Step: 4
Training loss: 0.8767757415771484
Validation loss: 2.030805198095178

Epoch: 6| Step: 5
Training loss: 1.916684627532959
Validation loss: 2.0327104919700214

Epoch: 6| Step: 6
Training loss: 1.6655426025390625
Validation loss: 2.0658537880066903

Epoch: 6| Step: 7
Training loss: 1.8324954509735107
Validation loss: 2.0670430942248275

Epoch: 6| Step: 8
Training loss: 1.8955464363098145
Validation loss: 2.057888984680176

Epoch: 6| Step: 9
Training loss: 0.891851544380188
Validation loss: 2.025475553286973

Epoch: 6| Step: 10
Training loss: 1.5398249626159668
Validation loss: 2.0091605404371857

Epoch: 6| Step: 11
Training loss: 1.2284024953842163
Validation loss: 2.00842740971555

Epoch: 6| Step: 12
Training loss: 1.1681147813796997
Validation loss: 1.996122121810913

Epoch: 6| Step: 13
Training loss: 1.6028403043746948
Validation loss: 1.9707601660041398

Epoch: 317| Step: 0
Training loss: 1.2000946998596191
Validation loss: 1.9934039923452562

Epoch: 6| Step: 1
Training loss: 1.9973490238189697
Validation loss: 2.002877066212316

Epoch: 6| Step: 2
Training loss: 1.3575246334075928
Validation loss: 1.985317946762167

Epoch: 6| Step: 3
Training loss: 1.3958953619003296
Validation loss: 1.9763568011663293

Epoch: 6| Step: 4
Training loss: 1.4222412109375
Validation loss: 1.9851196401862687

Epoch: 6| Step: 5
Training loss: 1.148179292678833
Validation loss: 1.975582698340057

Epoch: 6| Step: 6
Training loss: 1.9714794158935547
Validation loss: 1.970679718960998

Epoch: 6| Step: 7
Training loss: 1.2095601558685303
Validation loss: 2.0117718647885066

Epoch: 6| Step: 8
Training loss: 1.1900036334991455
Validation loss: 1.9851126465746152

Epoch: 6| Step: 9
Training loss: 1.4253754615783691
Validation loss: 2.0096886260535127

Epoch: 6| Step: 10
Training loss: 0.8212125897407532
Validation loss: 2.0267387410645843

Epoch: 6| Step: 11
Training loss: 1.6596473455429077
Validation loss: 2.0469093399663127

Epoch: 6| Step: 12
Training loss: 1.485926628112793
Validation loss: 2.056973470154629

Epoch: 6| Step: 13
Training loss: 0.9875192642211914
Validation loss: 2.055194934209188

Epoch: 318| Step: 0
Training loss: 1.1089365482330322
Validation loss: 2.036521630902444

Epoch: 6| Step: 1
Training loss: 1.3689920902252197
Validation loss: 2.0191059292003675

Epoch: 6| Step: 2
Training loss: 1.4866784811019897
Validation loss: 1.9990231952359598

Epoch: 6| Step: 3
Training loss: 1.2588543891906738
Validation loss: 2.026083492463635

Epoch: 6| Step: 4
Training loss: 1.5645915269851685
Validation loss: 2.0057255273224204

Epoch: 6| Step: 5
Training loss: 1.7854456901550293
Validation loss: 2.0105376166682087

Epoch: 6| Step: 6
Training loss: 1.7631351947784424
Validation loss: 1.9706274770921277

Epoch: 6| Step: 7
Training loss: 1.0376752614974976
Validation loss: 1.9683003963962677

Epoch: 6| Step: 8
Training loss: 1.368654489517212
Validation loss: 1.9873532838718866

Epoch: 6| Step: 9
Training loss: 1.3095753192901611
Validation loss: 1.9346426904842418

Epoch: 6| Step: 10
Training loss: 1.2575808763504028
Validation loss: 1.9584441607998264

Epoch: 6| Step: 11
Training loss: 1.477526068687439
Validation loss: 1.9774076272082586

Epoch: 6| Step: 12
Training loss: 1.1291890144348145
Validation loss: 1.9786195690913866

Epoch: 6| Step: 13
Training loss: 1.076814889907837
Validation loss: 1.9582244362882388

Epoch: 319| Step: 0
Training loss: 1.4837110042572021
Validation loss: 1.9974416558460524

Epoch: 6| Step: 1
Training loss: 0.9993085265159607
Validation loss: 2.01578853976342

Epoch: 6| Step: 2
Training loss: 1.195746898651123
Validation loss: 2.014555004335219

Epoch: 6| Step: 3
Training loss: 1.4039154052734375
Validation loss: 1.9823117973983928

Epoch: 6| Step: 4
Training loss: 1.2446656227111816
Validation loss: 1.9823980972331057

Epoch: 6| Step: 5
Training loss: 0.862971305847168
Validation loss: 1.9781273257347844

Epoch: 6| Step: 6
Training loss: 2.2029120922088623
Validation loss: 1.9739190147769066

Epoch: 6| Step: 7
Training loss: 1.4235572814941406
Validation loss: 1.9861889757135862

Epoch: 6| Step: 8
Training loss: 1.620694637298584
Validation loss: 1.976861507661881

Epoch: 6| Step: 9
Training loss: 2.075835704803467
Validation loss: 1.9926251160201205

Epoch: 6| Step: 10
Training loss: 0.9519326686859131
Validation loss: 1.9814394699629916

Epoch: 6| Step: 11
Training loss: 0.8227931261062622
Validation loss: 2.0380057737391484

Epoch: 6| Step: 12
Training loss: 1.7282462120056152
Validation loss: 2.0411009403967086

Epoch: 6| Step: 13
Training loss: 0.8430929183959961
Validation loss: 2.0141278364325084

Epoch: 320| Step: 0
Training loss: 1.1870359182357788
Validation loss: 2.0409433892978135

Epoch: 6| Step: 1
Training loss: 1.453208327293396
Validation loss: 2.0421595586243497

Epoch: 6| Step: 2
Training loss: 1.342101812362671
Validation loss: 2.042590916797679

Epoch: 6| Step: 3
Training loss: 1.5192489624023438
Validation loss: 2.051502896893409

Epoch: 6| Step: 4
Training loss: 0.6783902049064636
Validation loss: 2.0172319437867854

Epoch: 6| Step: 5
Training loss: 1.6757230758666992
Validation loss: 2.005217707285317

Epoch: 6| Step: 6
Training loss: 1.3274502754211426
Validation loss: 1.9685701362548336

Epoch: 6| Step: 7
Training loss: 1.322195053100586
Validation loss: 1.9832010833165978

Epoch: 6| Step: 8
Training loss: 1.0408096313476562
Validation loss: 1.9561203384912142

Epoch: 6| Step: 9
Training loss: 1.4928078651428223
Validation loss: 1.9358626898898874

Epoch: 6| Step: 10
Training loss: 1.5637763738632202
Validation loss: 1.9732519375380648

Epoch: 6| Step: 11
Training loss: 1.111809492111206
Validation loss: 1.9740428565650858

Epoch: 6| Step: 12
Training loss: 1.5307714939117432
Validation loss: 2.0108028778465847

Epoch: 6| Step: 13
Training loss: 2.0010440349578857
Validation loss: 2.0479689336592153

Epoch: 321| Step: 0
Training loss: 1.0864815711975098
Validation loss: 2.0973847758385444

Epoch: 6| Step: 1
Training loss: 0.5216354727745056
Validation loss: 2.0789253865518877

Epoch: 6| Step: 2
Training loss: 1.5564067363739014
Validation loss: 2.089837048643379

Epoch: 6| Step: 3
Training loss: 1.2839934825897217
Validation loss: 2.1122308777224634

Epoch: 6| Step: 4
Training loss: 1.1980376243591309
Validation loss: 2.1162471796876643

Epoch: 6| Step: 5
Training loss: 1.385113000869751
Validation loss: 2.1285568514177875

Epoch: 6| Step: 6
Training loss: 1.6996519565582275
Validation loss: 2.0890226338499334

Epoch: 6| Step: 7
Training loss: 1.535760521888733
Validation loss: 2.017291481776904

Epoch: 6| Step: 8
Training loss: 2.0099847316741943
Validation loss: 1.9959834288525324

Epoch: 6| Step: 9
Training loss: 1.115350604057312
Validation loss: 1.9721366795160438

Epoch: 6| Step: 10
Training loss: 1.480958104133606
Validation loss: 1.9596234957377117

Epoch: 6| Step: 11
Training loss: 1.549607515335083
Validation loss: 1.9746681080069592

Epoch: 6| Step: 12
Training loss: 1.0420745611190796
Validation loss: 1.9767382708928918

Epoch: 6| Step: 13
Training loss: 2.2046854496002197
Validation loss: 1.933189348507953

Epoch: 322| Step: 0
Training loss: 1.5190173387527466
Validation loss: 1.9869241483749882

Epoch: 6| Step: 1
Training loss: 1.5273067951202393
Validation loss: 1.9690637665410196

Epoch: 6| Step: 2
Training loss: 1.6990610361099243
Validation loss: 2.002727113744264

Epoch: 6| Step: 3
Training loss: 1.1728026866912842
Validation loss: 2.006005753753006

Epoch: 6| Step: 4
Training loss: 1.4896671772003174
Validation loss: 2.017311337173626

Epoch: 6| Step: 5
Training loss: 1.6214516162872314
Validation loss: 2.019406069991409

Epoch: 6| Step: 6
Training loss: 1.6113383769989014
Validation loss: 2.0483832923314904

Epoch: 6| Step: 7
Training loss: 1.1714706420898438
Validation loss: 2.036003456320814

Epoch: 6| Step: 8
Training loss: 0.9076294302940369
Validation loss: 2.0315750337416127

Epoch: 6| Step: 9
Training loss: 1.0250439643859863
Validation loss: 2.0258931806010585

Epoch: 6| Step: 10
Training loss: 1.061686396598816
Validation loss: 2.0180614917509017

Epoch: 6| Step: 11
Training loss: 1.1884026527404785
Validation loss: 2.0184321147139355

Epoch: 6| Step: 12
Training loss: 1.5423561334609985
Validation loss: 1.9890980464155956

Epoch: 6| Step: 13
Training loss: 1.4583369493484497
Validation loss: 1.978800453165526

Epoch: 323| Step: 0
Training loss: 1.1358509063720703
Validation loss: 1.9336416362434306

Epoch: 6| Step: 1
Training loss: 1.8592474460601807
Validation loss: 1.958974454992561

Epoch: 6| Step: 2
Training loss: 1.3718806505203247
Validation loss: 1.9496648055250927

Epoch: 6| Step: 3
Training loss: 1.2954407930374146
Validation loss: 1.9663623097122356

Epoch: 6| Step: 4
Training loss: 1.2234879732131958
Validation loss: 1.981666926414736

Epoch: 6| Step: 5
Training loss: 1.6645004749298096
Validation loss: 2.014397149444908

Epoch: 6| Step: 6
Training loss: 1.3853890895843506
Validation loss: 2.0349620362763763

Epoch: 6| Step: 7
Training loss: 1.0871349573135376
Validation loss: 2.0541922507747525

Epoch: 6| Step: 8
Training loss: 0.96210116147995
Validation loss: 2.0919495987635788

Epoch: 6| Step: 9
Training loss: 1.284691572189331
Validation loss: 2.0642483542042394

Epoch: 6| Step: 10
Training loss: 1.1975059509277344
Validation loss: 2.080661924936438

Epoch: 6| Step: 11
Training loss: 2.1663594245910645
Validation loss: 2.0578698458210116

Epoch: 6| Step: 12
Training loss: 1.3857874870300293
Validation loss: 2.0462961222535823

Epoch: 6| Step: 13
Training loss: 0.6934931874275208
Validation loss: 2.042966745233023

Epoch: 324| Step: 0
Training loss: 0.9260597229003906
Validation loss: 2.03914572090231

Epoch: 6| Step: 1
Training loss: 1.4944653511047363
Validation loss: 2.022497832134206

Epoch: 6| Step: 2
Training loss: 1.641204833984375
Validation loss: 2.013599370115547

Epoch: 6| Step: 3
Training loss: 1.0579872131347656
Validation loss: 1.994018131686795

Epoch: 6| Step: 4
Training loss: 1.301905632019043
Validation loss: 2.005776184861378

Epoch: 6| Step: 5
Training loss: 1.3320341110229492
Validation loss: 1.9935541870773479

Epoch: 6| Step: 6
Training loss: 1.2945904731750488
Validation loss: 2.0390206806121336

Epoch: 6| Step: 7
Training loss: 1.984586238861084
Validation loss: 2.0321984393622285

Epoch: 6| Step: 8
Training loss: 1.178046464920044
Validation loss: 2.060591010637181

Epoch: 6| Step: 9
Training loss: 1.4600746631622314
Validation loss: 2.067000704426919

Epoch: 6| Step: 10
Training loss: 1.1424036026000977
Validation loss: 2.0166994884449947

Epoch: 6| Step: 11
Training loss: 1.3976041078567505
Validation loss: 2.0197502054193968

Epoch: 6| Step: 12
Training loss: 1.1631826162338257
Validation loss: 1.9846771570944017

Epoch: 6| Step: 13
Training loss: 1.3283882141113281
Validation loss: 2.0180996130871516

Epoch: 325| Step: 0
Training loss: 1.7596527338027954
Validation loss: 1.999039888381958

Epoch: 6| Step: 1
Training loss: 1.6628867387771606
Validation loss: 2.0163755852689027

Epoch: 6| Step: 2
Training loss: 1.1944442987442017
Validation loss: 2.0090345977455057

Epoch: 6| Step: 3
Training loss: 1.4312822818756104
Validation loss: 1.9931188526973929

Epoch: 6| Step: 4
Training loss: 0.6102635860443115
Validation loss: 1.9705224088443223

Epoch: 6| Step: 5
Training loss: 1.1430779695510864
Validation loss: 1.978789601274716

Epoch: 6| Step: 6
Training loss: 1.4301388263702393
Validation loss: 2.013107092149796

Epoch: 6| Step: 7
Training loss: 1.3623876571655273
Validation loss: 2.0440634066058743

Epoch: 6| Step: 8
Training loss: 1.472853422164917
Validation loss: 2.061191831865618

Epoch: 6| Step: 9
Training loss: 1.437852382659912
Validation loss: 2.0567614224649247

Epoch: 6| Step: 10
Training loss: 1.2042386531829834
Validation loss: 2.067026420306134

Epoch: 6| Step: 11
Training loss: 1.0238351821899414
Validation loss: 2.03513817761534

Epoch: 6| Step: 12
Training loss: 2.008871555328369
Validation loss: 2.0055694054531794

Epoch: 6| Step: 13
Training loss: 1.1357661485671997
Validation loss: 2.0042244131847093

Epoch: 326| Step: 0
Training loss: 1.3338615894317627
Validation loss: 1.9543213485389628

Epoch: 6| Step: 1
Training loss: 0.74211585521698
Validation loss: 2.005977690860789

Epoch: 6| Step: 2
Training loss: 1.5042757987976074
Validation loss: 2.0066443130534184

Epoch: 6| Step: 3
Training loss: 1.1045730113983154
Validation loss: 2.0527864553595103

Epoch: 6| Step: 4
Training loss: 1.1811342239379883
Validation loss: 2.035876758636967

Epoch: 6| Step: 5
Training loss: 1.265974998474121
Validation loss: 2.0545813704049714

Epoch: 6| Step: 6
Training loss: 1.4217524528503418
Validation loss: 2.0456887650233444

Epoch: 6| Step: 7
Training loss: 1.2312663793563843
Validation loss: 2.033263442336872

Epoch: 6| Step: 8
Training loss: 1.6899486780166626
Validation loss: 2.0483155276185725

Epoch: 6| Step: 9
Training loss: 1.6994905471801758
Validation loss: 2.0242253324036956

Epoch: 6| Step: 10
Training loss: 0.9472764134407043
Validation loss: 2.0079375287537933

Epoch: 6| Step: 11
Training loss: 1.6828985214233398
Validation loss: 1.9702849208667714

Epoch: 6| Step: 12
Training loss: 1.8226280212402344
Validation loss: 1.9845116933186848

Epoch: 6| Step: 13
Training loss: 1.282569169998169
Validation loss: 1.9727146561427782

Epoch: 327| Step: 0
Training loss: 0.9825437068939209
Validation loss: 1.973755923650598

Epoch: 6| Step: 1
Training loss: 1.7092474699020386
Validation loss: 1.9603909689893004

Epoch: 6| Step: 2
Training loss: 0.9480249881744385
Validation loss: 1.954442552340928

Epoch: 6| Step: 3
Training loss: 1.4543256759643555
Validation loss: 1.9667315713820919

Epoch: 6| Step: 4
Training loss: 1.5478055477142334
Validation loss: 1.9983066025600638

Epoch: 6| Step: 5
Training loss: 1.559550166130066
Validation loss: 1.983517272498018

Epoch: 6| Step: 6
Training loss: 1.0576727390289307
Validation loss: 1.9896604194436023

Epoch: 6| Step: 7
Training loss: 0.9085721373558044
Validation loss: 1.9546757551931566

Epoch: 6| Step: 8
Training loss: 1.7394747734069824
Validation loss: 1.9454544154546594

Epoch: 6| Step: 9
Training loss: 1.6005091667175293
Validation loss: 1.9353160999154533

Epoch: 6| Step: 10
Training loss: 1.4786735773086548
Validation loss: 1.9476355967983123

Epoch: 6| Step: 11
Training loss: 1.6994894742965698
Validation loss: 1.9408550281678476

Epoch: 6| Step: 12
Training loss: 1.2099547386169434
Validation loss: 2.008615473265289

Epoch: 6| Step: 13
Training loss: 0.5314571857452393
Validation loss: 2.004340789651358

Epoch: 328| Step: 0
Training loss: 0.9395743608474731
Validation loss: 2.008087729894987

Epoch: 6| Step: 1
Training loss: 1.416670799255371
Validation loss: 2.0014631517471804

Epoch: 6| Step: 2
Training loss: 1.5354137420654297
Validation loss: 2.049410785398176

Epoch: 6| Step: 3
Training loss: 1.8095718622207642
Validation loss: 2.0436151437861945

Epoch: 6| Step: 4
Training loss: 1.2570760250091553
Validation loss: 2.0005066433260517

Epoch: 6| Step: 5
Training loss: 1.1349023580551147
Validation loss: 1.984722589933744

Epoch: 6| Step: 6
Training loss: 1.2853100299835205
Validation loss: 1.9473727313421105

Epoch: 6| Step: 7
Training loss: 1.7466363906860352
Validation loss: 1.9310339932800622

Epoch: 6| Step: 8
Training loss: 1.573390007019043
Validation loss: 1.968561218630883

Epoch: 6| Step: 9
Training loss: 1.4706720113754272
Validation loss: 1.971982717514038

Epoch: 6| Step: 10
Training loss: 1.043745994567871
Validation loss: 1.9824944003935783

Epoch: 6| Step: 11
Training loss: 1.1808443069458008
Validation loss: 1.9857778280012068

Epoch: 6| Step: 12
Training loss: 1.4332668781280518
Validation loss: 2.0203419398236018

Epoch: 6| Step: 13
Training loss: 1.0925686359405518
Validation loss: 2.0363409147467664

Epoch: 329| Step: 0
Training loss: 1.022397518157959
Validation loss: 2.061797518883982

Epoch: 6| Step: 1
Training loss: 1.274944543838501
Validation loss: 2.0848076779355287

Epoch: 6| Step: 2
Training loss: 1.278765082359314
Validation loss: 2.0487363851198586

Epoch: 6| Step: 3
Training loss: 1.0165776014328003
Validation loss: 2.009950376326038

Epoch: 6| Step: 4
Training loss: 1.1519625186920166
Validation loss: 1.9665404263363089

Epoch: 6| Step: 5
Training loss: 1.4322996139526367
Validation loss: 1.9515713760929723

Epoch: 6| Step: 6
Training loss: 1.774822473526001
Validation loss: 1.9468298624920588

Epoch: 6| Step: 7
Training loss: 1.177797555923462
Validation loss: 1.9960471801860358

Epoch: 6| Step: 8
Training loss: 1.3401720523834229
Validation loss: 2.0132070895164245

Epoch: 6| Step: 9
Training loss: 1.668900489807129
Validation loss: 2.0244585006467757

Epoch: 6| Step: 10
Training loss: 1.4203789234161377
Validation loss: 1.982835356907178

Epoch: 6| Step: 11
Training loss: 1.3823795318603516
Validation loss: 1.9798601878586637

Epoch: 6| Step: 12
Training loss: 1.5176349878311157
Validation loss: 1.9952344458590272

Epoch: 6| Step: 13
Training loss: 1.5555905103683472
Validation loss: 1.9739775170562088

Epoch: 330| Step: 0
Training loss: 0.6705631613731384
Validation loss: 1.9520070834826397

Epoch: 6| Step: 1
Training loss: 1.812821626663208
Validation loss: 1.9612435038371752

Epoch: 6| Step: 2
Training loss: 1.3661344051361084
Validation loss: 1.9592608380061325

Epoch: 6| Step: 3
Training loss: 1.3818519115447998
Validation loss: 1.9686305907464796

Epoch: 6| Step: 4
Training loss: 1.0331673622131348
Validation loss: 1.988966267596009

Epoch: 6| Step: 5
Training loss: 1.1911070346832275
Validation loss: 2.0163574846841956

Epoch: 6| Step: 6
Training loss: 0.9665957689285278
Validation loss: 2.018502499467583

Epoch: 6| Step: 7
Training loss: 1.6691526174545288
Validation loss: 2.011745601572016

Epoch: 6| Step: 8
Training loss: 1.0918936729431152
Validation loss: 2.0252969752075853

Epoch: 6| Step: 9
Training loss: 1.389695167541504
Validation loss: 2.0237825865386636

Epoch: 6| Step: 10
Training loss: 1.2411843538284302
Validation loss: 1.9964134013780983

Epoch: 6| Step: 11
Training loss: 1.6293134689331055
Validation loss: 2.049109302541261

Epoch: 6| Step: 12
Training loss: 1.4493155479431152
Validation loss: 2.0234489274281326

Epoch: 6| Step: 13
Training loss: 1.211308479309082
Validation loss: 2.039103400322699

Epoch: 331| Step: 0
Training loss: 2.0873053073883057
Validation loss: 2.034384286531838

Epoch: 6| Step: 1
Training loss: 0.654559314250946
Validation loss: 2.025012993043469

Epoch: 6| Step: 2
Training loss: 1.4740042686462402
Validation loss: 2.010361474047425

Epoch: 6| Step: 3
Training loss: 0.7289674282073975
Validation loss: 1.9944889468531455

Epoch: 6| Step: 4
Training loss: 1.2853798866271973
Validation loss: 1.986780971609136

Epoch: 6| Step: 5
Training loss: 1.0668590068817139
Validation loss: 1.961815426426549

Epoch: 6| Step: 6
Training loss: 1.6294467449188232
Validation loss: 1.9907761491755003

Epoch: 6| Step: 7
Training loss: 1.5874857902526855
Validation loss: 2.000127471903319

Epoch: 6| Step: 8
Training loss: 1.6312806606292725
Validation loss: 1.9749947619694534

Epoch: 6| Step: 9
Training loss: 1.118080973625183
Validation loss: 1.9995350299342987

Epoch: 6| Step: 10
Training loss: 1.2870163917541504
Validation loss: 1.9772083759307861

Epoch: 6| Step: 11
Training loss: 1.1813572645187378
Validation loss: 1.9767277215116767

Epoch: 6| Step: 12
Training loss: 0.8151350617408752
Validation loss: 1.9983679786805184

Epoch: 6| Step: 13
Training loss: 1.6387383937835693
Validation loss: 2.0081201907127135

Epoch: 332| Step: 0
Training loss: 2.3769047260284424
Validation loss: 1.9734044639013146

Epoch: 6| Step: 1
Training loss: 0.8069693446159363
Validation loss: 1.9583630061918689

Epoch: 6| Step: 2
Training loss: 1.1691762208938599
Validation loss: 1.9682183547686505

Epoch: 6| Step: 3
Training loss: 1.2683370113372803
Validation loss: 1.9470644458647697

Epoch: 6| Step: 4
Training loss: 0.8841047286987305
Validation loss: 1.9375914847978981

Epoch: 6| Step: 5
Training loss: 1.400975227355957
Validation loss: 1.9605917315329275

Epoch: 6| Step: 6
Training loss: 1.2923253774642944
Validation loss: 2.0015223257003294

Epoch: 6| Step: 7
Training loss: 1.2988911867141724
Validation loss: 2.042094320379278

Epoch: 6| Step: 8
Training loss: 1.4104796648025513
Validation loss: 2.0340172911203034

Epoch: 6| Step: 9
Training loss: 1.0937319993972778
Validation loss: 2.0688489816522084

Epoch: 6| Step: 10
Training loss: 1.1908996105194092
Validation loss: 2.0624840836371146

Epoch: 6| Step: 11
Training loss: 1.8305935859680176
Validation loss: 2.070963203266103

Epoch: 6| Step: 12
Training loss: 1.1911394596099854
Validation loss: 2.0318293276653496

Epoch: 6| Step: 13
Training loss: 0.8510646224021912
Validation loss: 2.0435564159065165

Epoch: 333| Step: 0
Training loss: 1.4675856828689575
Validation loss: 2.00378829433072

Epoch: 6| Step: 1
Training loss: 0.845821738243103
Validation loss: 2.0166073614551174

Epoch: 6| Step: 2
Training loss: 1.3662933111190796
Validation loss: 1.9802010636175833

Epoch: 6| Step: 3
Training loss: 1.3805081844329834
Validation loss: 2.003903330013316

Epoch: 6| Step: 4
Training loss: 0.8126807808876038
Validation loss: 2.0211142250286636

Epoch: 6| Step: 5
Training loss: 1.4925600290298462
Validation loss: 2.0012469548051075

Epoch: 6| Step: 6
Training loss: 1.1194535493850708
Validation loss: 1.9780368189657889

Epoch: 6| Step: 7
Training loss: 1.3563125133514404
Validation loss: 2.0048172602089505

Epoch: 6| Step: 8
Training loss: 1.350426197052002
Validation loss: 1.996842271538191

Epoch: 6| Step: 9
Training loss: 1.3193782567977905
Validation loss: 2.0160527562582367

Epoch: 6| Step: 10
Training loss: 1.7248482704162598
Validation loss: 2.0433014387725503

Epoch: 6| Step: 11
Training loss: 1.927119255065918
Validation loss: 2.009000999953157

Epoch: 6| Step: 12
Training loss: 0.9040582776069641
Validation loss: 2.007564237040858

Epoch: 6| Step: 13
Training loss: 0.7333256602287292
Validation loss: 2.004807177410331

Epoch: 334| Step: 0
Training loss: 1.784151315689087
Validation loss: 2.0237237061223676

Epoch: 6| Step: 1
Training loss: 1.0293720960617065
Validation loss: 2.003087346271802

Epoch: 6| Step: 2
Training loss: 0.5392774343490601
Validation loss: 1.9944267067857968

Epoch: 6| Step: 3
Training loss: 1.1042506694793701
Validation loss: 2.000448255128758

Epoch: 6| Step: 4
Training loss: 1.6877259016036987
Validation loss: 2.023835669281662

Epoch: 6| Step: 5
Training loss: 0.7113270163536072
Validation loss: 2.015723502764138

Epoch: 6| Step: 6
Training loss: 1.218557596206665
Validation loss: 1.9923024844097834

Epoch: 6| Step: 7
Training loss: 1.5371557474136353
Validation loss: 1.9812429540900773

Epoch: 6| Step: 8
Training loss: 1.2955188751220703
Validation loss: 1.9838454005538777

Epoch: 6| Step: 9
Training loss: 1.2846693992614746
Validation loss: 2.001829775430823

Epoch: 6| Step: 10
Training loss: 1.1561524868011475
Validation loss: 2.016745331466839

Epoch: 6| Step: 11
Training loss: 2.197314739227295
Validation loss: 2.0100051074899654

Epoch: 6| Step: 12
Training loss: 0.9886965751647949
Validation loss: 2.000134524478707

Epoch: 6| Step: 13
Training loss: 1.498395323753357
Validation loss: 2.001344450058476

Epoch: 335| Step: 0
Training loss: 1.4482507705688477
Validation loss: 2.056127122653428

Epoch: 6| Step: 1
Training loss: 1.156545877456665
Validation loss: 2.037181438938264

Epoch: 6| Step: 2
Training loss: 1.0793933868408203
Validation loss: 2.0107395982229583

Epoch: 6| Step: 3
Training loss: 0.8805203437805176
Validation loss: 2.0290567259634695

Epoch: 6| Step: 4
Training loss: 1.6793639659881592
Validation loss: 2.032632927740774

Epoch: 6| Step: 5
Training loss: 1.399755597114563
Validation loss: 2.0236064195632935

Epoch: 6| Step: 6
Training loss: 1.7225075960159302
Validation loss: 2.0306843839665896

Epoch: 6| Step: 7
Training loss: 1.5381526947021484
Validation loss: 2.0131080381331907

Epoch: 6| Step: 8
Training loss: 1.1695771217346191
Validation loss: 2.024555757481565

Epoch: 6| Step: 9
Training loss: 1.4559102058410645
Validation loss: 2.0527607522984987

Epoch: 6| Step: 10
Training loss: 0.7662666440010071
Validation loss: 2.029605083568122

Epoch: 6| Step: 11
Training loss: 1.070246696472168
Validation loss: 2.02701445164219

Epoch: 6| Step: 12
Training loss: 1.593101978302002
Validation loss: 1.9877992381331742

Epoch: 6| Step: 13
Training loss: 0.7455297708511353
Validation loss: 1.938432785772508

Epoch: 336| Step: 0
Training loss: 1.1562840938568115
Validation loss: 1.929446820289858

Epoch: 6| Step: 1
Training loss: 1.6093003749847412
Validation loss: 1.9068489202889063

Epoch: 6| Step: 2
Training loss: 1.5565394163131714
Validation loss: 1.9183123188634073

Epoch: 6| Step: 3
Training loss: 1.5248820781707764
Validation loss: 1.9551830291748047

Epoch: 6| Step: 4
Training loss: 1.4116809368133545
Validation loss: 1.97590164215334

Epoch: 6| Step: 5
Training loss: 1.0416823625564575
Validation loss: 2.020726212891199

Epoch: 6| Step: 6
Training loss: 1.3004891872406006
Validation loss: 2.032913064443937

Epoch: 6| Step: 7
Training loss: 0.9789300560951233
Validation loss: 2.0140837366862963

Epoch: 6| Step: 8
Training loss: 1.037787675857544
Validation loss: 2.040291727230113

Epoch: 6| Step: 9
Training loss: 1.8633790016174316
Validation loss: 2.04700880922297

Epoch: 6| Step: 10
Training loss: 1.2921030521392822
Validation loss: 1.9828160065476612

Epoch: 6| Step: 11
Training loss: 1.0095022916793823
Validation loss: 2.0052052518372894

Epoch: 6| Step: 12
Training loss: 0.9019253253936768
Validation loss: 1.9802876608346098

Epoch: 6| Step: 13
Training loss: 1.5036063194274902
Validation loss: 1.9619456311707855

Epoch: 337| Step: 0
Training loss: 1.1581366062164307
Validation loss: 1.9818201629064416

Epoch: 6| Step: 1
Training loss: 1.2955890893936157
Validation loss: 1.9995344377333117

Epoch: 6| Step: 2
Training loss: 1.2174158096313477
Validation loss: 2.036970269295477

Epoch: 6| Step: 3
Training loss: 0.9106218814849854
Validation loss: 2.0791005062800583

Epoch: 6| Step: 4
Training loss: 1.1252872943878174
Validation loss: 2.0607723728302987

Epoch: 6| Step: 5
Training loss: 1.1437528133392334
Validation loss: 2.070426948608891

Epoch: 6| Step: 6
Training loss: 1.208345651626587
Validation loss: 2.051257292429606

Epoch: 6| Step: 7
Training loss: 1.1641201972961426
Validation loss: 2.0325052533098447

Epoch: 6| Step: 8
Training loss: 1.432606816291809
Validation loss: 1.980789005115468

Epoch: 6| Step: 9
Training loss: 2.0710408687591553
Validation loss: 1.9822074110789965

Epoch: 6| Step: 10
Training loss: 1.3698639869689941
Validation loss: 1.9762104352315266

Epoch: 6| Step: 11
Training loss: 1.1521918773651123
Validation loss: 1.9825648364200388

Epoch: 6| Step: 12
Training loss: 1.586745262145996
Validation loss: 1.9778058323808896

Epoch: 6| Step: 13
Training loss: 1.1890645027160645
Validation loss: 1.985697671931277

Epoch: 338| Step: 0
Training loss: 0.7691947817802429
Validation loss: 1.9749955797708163

Epoch: 6| Step: 1
Training loss: 1.0722813606262207
Validation loss: 1.99039081476068

Epoch: 6| Step: 2
Training loss: 0.7223902344703674
Validation loss: 1.9797002782103836

Epoch: 6| Step: 3
Training loss: 1.720664381980896
Validation loss: 1.9726639742492347

Epoch: 6| Step: 4
Training loss: 1.479879379272461
Validation loss: 1.9592757250673027

Epoch: 6| Step: 5
Training loss: 1.1932148933410645
Validation loss: 1.9771347917536253

Epoch: 6| Step: 6
Training loss: 1.2540595531463623
Validation loss: 1.9834485515471427

Epoch: 6| Step: 7
Training loss: 1.8615217208862305
Validation loss: 1.9960871537526448

Epoch: 6| Step: 8
Training loss: 1.41636061668396
Validation loss: 1.984967541951005

Epoch: 6| Step: 9
Training loss: 1.1086924076080322
Validation loss: 2.003454860820565

Epoch: 6| Step: 10
Training loss: 1.0267963409423828
Validation loss: 2.031098791348037

Epoch: 6| Step: 11
Training loss: 1.5027272701263428
Validation loss: 1.9966454634102442

Epoch: 6| Step: 12
Training loss: 1.4051403999328613
Validation loss: 1.991955316194924

Epoch: 6| Step: 13
Training loss: 1.1239018440246582
Validation loss: 1.9625568671893048

Epoch: 339| Step: 0
Training loss: 1.2242271900177002
Validation loss: 1.9487749709877917

Epoch: 6| Step: 1
Training loss: 1.056150197982788
Validation loss: 1.9747416844931982

Epoch: 6| Step: 2
Training loss: 0.7937983274459839
Validation loss: 1.948596469817623

Epoch: 6| Step: 3
Training loss: 1.0690171718597412
Validation loss: 1.9472296263581963

Epoch: 6| Step: 4
Training loss: 1.3845231533050537
Validation loss: 1.950785162628338

Epoch: 6| Step: 5
Training loss: 1.5221208333969116
Validation loss: 1.9603896628143966

Epoch: 6| Step: 6
Training loss: 1.8398356437683105
Validation loss: 1.9925715641308857

Epoch: 6| Step: 7
Training loss: 1.4532437324523926
Validation loss: 2.0143535303813156

Epoch: 6| Step: 8
Training loss: 1.1304625272750854
Validation loss: 2.03096350290442

Epoch: 6| Step: 9
Training loss: 1.0295708179473877
Validation loss: 1.9875507098372265

Epoch: 6| Step: 10
Training loss: 1.5146836042404175
Validation loss: 2.0055998422766246

Epoch: 6| Step: 11
Training loss: 1.1336992979049683
Validation loss: 2.0057572908298944

Epoch: 6| Step: 12
Training loss: 1.136948823928833
Validation loss: 2.031918938441943

Epoch: 6| Step: 13
Training loss: 1.214491367340088
Validation loss: 2.0188104978171726

Epoch: 340| Step: 0
Training loss: 1.1091623306274414
Validation loss: 2.0186421127729517

Epoch: 6| Step: 1
Training loss: 1.2642468214035034
Validation loss: 2.02779120783652

Epoch: 6| Step: 2
Training loss: 0.9206975698471069
Validation loss: 2.0249569621137393

Epoch: 6| Step: 3
Training loss: 1.2688276767730713
Validation loss: 2.003937772525254

Epoch: 6| Step: 4
Training loss: 0.6609491109848022
Validation loss: 1.9994056096640966

Epoch: 6| Step: 5
Training loss: 1.4933462142944336
Validation loss: 1.9869324366251628

Epoch: 6| Step: 6
Training loss: 1.330073595046997
Validation loss: 1.9750763626508816

Epoch: 6| Step: 7
Training loss: 1.513451337814331
Validation loss: 1.9762976349041026

Epoch: 6| Step: 8
Training loss: 1.592602252960205
Validation loss: 1.9494703200555616

Epoch: 6| Step: 9
Training loss: 1.7540134191513062
Validation loss: 1.9518391573300926

Epoch: 6| Step: 10
Training loss: 0.853400707244873
Validation loss: 1.9636784010036017

Epoch: 6| Step: 11
Training loss: 1.2754703760147095
Validation loss: 1.9634973003018288

Epoch: 6| Step: 12
Training loss: 0.49928510189056396
Validation loss: 1.9925281629767468

Epoch: 6| Step: 13
Training loss: 2.1458191871643066
Validation loss: 1.966944448409542

Epoch: 341| Step: 0
Training loss: 0.7382833957672119
Validation loss: 1.9689904220642582

Epoch: 6| Step: 1
Training loss: 0.9754922986030579
Validation loss: 1.9892429805571032

Epoch: 6| Step: 2
Training loss: 1.574220061302185
Validation loss: 1.990389052257743

Epoch: 6| Step: 3
Training loss: 1.5901055335998535
Validation loss: 2.015446338602292

Epoch: 6| Step: 4
Training loss: 1.3783845901489258
Validation loss: 1.9578685914316485

Epoch: 6| Step: 5
Training loss: 1.0525221824645996
Validation loss: 1.930308134325089

Epoch: 6| Step: 6
Training loss: 0.970313310623169
Validation loss: 1.9101525596393052

Epoch: 6| Step: 7
Training loss: 1.1857085227966309
Validation loss: 1.900174472921638

Epoch: 6| Step: 8
Training loss: 1.4801578521728516
Validation loss: 1.8942342535141976

Epoch: 6| Step: 9
Training loss: 0.830142617225647
Validation loss: 1.9285135448619883

Epoch: 6| Step: 10
Training loss: 1.4125021696090698
Validation loss: 1.9255243193718694

Epoch: 6| Step: 11
Training loss: 1.8118393421173096
Validation loss: 1.9641888808178645

Epoch: 6| Step: 12
Training loss: 1.2976866960525513
Validation loss: 1.9679916212635655

Epoch: 6| Step: 13
Training loss: 1.3510360717773438
Validation loss: 2.048832836971488

Epoch: 342| Step: 0
Training loss: 1.0614895820617676
Validation loss: 2.0972007589955486

Epoch: 6| Step: 1
Training loss: 0.9925087690353394
Validation loss: 2.117831200681707

Epoch: 6| Step: 2
Training loss: 1.5678679943084717
Validation loss: 2.1021668667434366

Epoch: 6| Step: 3
Training loss: 1.674127221107483
Validation loss: 2.0779427123326126

Epoch: 6| Step: 4
Training loss: 1.2404319047927856
Validation loss: 2.009691507585587

Epoch: 6| Step: 5
Training loss: 1.7458229064941406
Validation loss: 1.9554816061450588

Epoch: 6| Step: 6
Training loss: 0.9051164388656616
Validation loss: 1.9233309632988387

Epoch: 6| Step: 7
Training loss: 1.5979876518249512
Validation loss: 1.9181137751507502

Epoch: 6| Step: 8
Training loss: 1.1204359531402588
Validation loss: 1.8925284877900155

Epoch: 6| Step: 9
Training loss: 1.0930534601211548
Validation loss: 1.8980352596570087

Epoch: 6| Step: 10
Training loss: 1.3797149658203125
Validation loss: 1.9231991485882831

Epoch: 6| Step: 11
Training loss: 1.2605843544006348
Validation loss: 1.9199538153986777

Epoch: 6| Step: 12
Training loss: 1.0193620920181274
Validation loss: 1.952195131650535

Epoch: 6| Step: 13
Training loss: 1.1355760097503662
Validation loss: 1.9798816993672361

Epoch: 343| Step: 0
Training loss: 1.324278473854065
Validation loss: 2.0080318297109296

Epoch: 6| Step: 1
Training loss: 1.0524077415466309
Validation loss: 2.068425019582113

Epoch: 6| Step: 2
Training loss: 1.5545144081115723
Validation loss: 2.0638760161656204

Epoch: 6| Step: 3
Training loss: 1.0788064002990723
Validation loss: 2.063371750616258

Epoch: 6| Step: 4
Training loss: 1.2975291013717651
Validation loss: 2.0596762575129026

Epoch: 6| Step: 5
Training loss: 1.2085210084915161
Validation loss: 2.0488703353430635

Epoch: 6| Step: 6
Training loss: 0.6527531147003174
Validation loss: 2.0310050941282705

Epoch: 6| Step: 7
Training loss: 1.3308284282684326
Validation loss: 1.9961661741297732

Epoch: 6| Step: 8
Training loss: 1.1736843585968018
Validation loss: 1.9627393471297396

Epoch: 6| Step: 9
Training loss: 1.29402756690979
Validation loss: 1.9462110086153912

Epoch: 6| Step: 10
Training loss: 1.0917370319366455
Validation loss: 1.9239083438791253

Epoch: 6| Step: 11
Training loss: 1.1676502227783203
Validation loss: 1.9265557591633131

Epoch: 6| Step: 12
Training loss: 1.5785765647888184
Validation loss: 1.9341426613510295

Epoch: 6| Step: 13
Training loss: 1.8969331979751587
Validation loss: 1.958576456193001

Epoch: 344| Step: 0
Training loss: 1.4399209022521973
Validation loss: 1.9681817793077039

Epoch: 6| Step: 1
Training loss: 0.9491157531738281
Validation loss: 1.9747870276051183

Epoch: 6| Step: 2
Training loss: 1.1867328882217407
Validation loss: 2.0026933172697663

Epoch: 6| Step: 3
Training loss: 1.1011426448822021
Validation loss: 1.9953955783638904

Epoch: 6| Step: 4
Training loss: 1.2635565996170044
Validation loss: 1.9921237550755984

Epoch: 6| Step: 5
Training loss: 1.3660191297531128
Validation loss: 2.023488336993802

Epoch: 6| Step: 6
Training loss: 1.35906982421875
Validation loss: 2.0459757645924888

Epoch: 6| Step: 7
Training loss: 1.6144328117370605
Validation loss: 2.0281644918585338

Epoch: 6| Step: 8
Training loss: 0.6938352584838867
Validation loss: 2.030029541702681

Epoch: 6| Step: 9
Training loss: 1.2139363288879395
Validation loss: 2.002766923237872

Epoch: 6| Step: 10
Training loss: 1.5898447036743164
Validation loss: 1.9855853126895042

Epoch: 6| Step: 11
Training loss: 1.0959670543670654
Validation loss: 1.9739400033027894

Epoch: 6| Step: 12
Training loss: 1.1987054347991943
Validation loss: 1.9466500718106505

Epoch: 6| Step: 13
Training loss: 0.6845893859863281
Validation loss: 1.9365470870848625

Epoch: 345| Step: 0
Training loss: 1.2447872161865234
Validation loss: 1.9598499626241705

Epoch: 6| Step: 1
Training loss: 1.2667951583862305
Validation loss: 1.977404764903489

Epoch: 6| Step: 2
Training loss: 1.131105661392212
Validation loss: 2.0041332167963826

Epoch: 6| Step: 3
Training loss: 1.1829131841659546
Validation loss: 1.98969909708987

Epoch: 6| Step: 4
Training loss: 0.9588965177536011
Validation loss: 1.9781454763104838

Epoch: 6| Step: 5
Training loss: 0.8695300817489624
Validation loss: 1.9557939652473695

Epoch: 6| Step: 6
Training loss: 1.8269081115722656
Validation loss: 1.984950775741249

Epoch: 6| Step: 7
Training loss: 1.0568082332611084
Validation loss: 2.012649836078767

Epoch: 6| Step: 8
Training loss: 1.1968998908996582
Validation loss: 2.056418313775011

Epoch: 6| Step: 9
Training loss: 1.3777872323989868
Validation loss: 2.037291908776888

Epoch: 6| Step: 10
Training loss: 1.1077580451965332
Validation loss: 2.0562556892312984

Epoch: 6| Step: 11
Training loss: 1.157368540763855
Validation loss: 2.0557397591170443

Epoch: 6| Step: 12
Training loss: 1.960390329360962
Validation loss: 2.0385635911777453

Epoch: 6| Step: 13
Training loss: 1.8526933193206787
Validation loss: 2.0397430594249437

Epoch: 346| Step: 0
Training loss: 1.0558916330337524
Validation loss: 2.0621459150827057

Epoch: 6| Step: 1
Training loss: 1.6573587656021118
Validation loss: 2.0319979575372513

Epoch: 6| Step: 2
Training loss: 1.2877445220947266
Validation loss: 2.0170169568830922

Epoch: 6| Step: 3
Training loss: 0.7241538763046265
Validation loss: 1.9460485468628586

Epoch: 6| Step: 4
Training loss: 1.5817902088165283
Validation loss: 1.9565361789477769

Epoch: 6| Step: 5
Training loss: 1.1250646114349365
Validation loss: 1.940244637509828

Epoch: 6| Step: 6
Training loss: 0.9815132021903992
Validation loss: 1.9293278250643002

Epoch: 6| Step: 7
Training loss: 1.4183850288391113
Validation loss: 1.9558257223457418

Epoch: 6| Step: 8
Training loss: 0.915806770324707
Validation loss: 1.963088648293608

Epoch: 6| Step: 9
Training loss: 1.486417531967163
Validation loss: 1.9908855397214171

Epoch: 6| Step: 10
Training loss: 1.7485466003417969
Validation loss: 1.9798631488635976

Epoch: 6| Step: 11
Training loss: 1.0379691123962402
Validation loss: 1.9931976179922781

Epoch: 6| Step: 12
Training loss: 1.1874299049377441
Validation loss: 2.0031936143034246

Epoch: 6| Step: 13
Training loss: 0.9880902767181396
Validation loss: 1.9944145474382626

Epoch: 347| Step: 0
Training loss: 1.6417896747589111
Validation loss: 1.9581219611629364

Epoch: 6| Step: 1
Training loss: 1.4894800186157227
Validation loss: 1.9523107005703835

Epoch: 6| Step: 2
Training loss: 1.1886053085327148
Validation loss: 1.9203552956222205

Epoch: 6| Step: 3
Training loss: 1.3422209024429321
Validation loss: 1.9345983279648649

Epoch: 6| Step: 4
Training loss: 0.5535949468612671
Validation loss: 1.936058662270987

Epoch: 6| Step: 5
Training loss: 1.3422105312347412
Validation loss: 1.96871857489309

Epoch: 6| Step: 6
Training loss: 0.948482871055603
Validation loss: 2.006550314605877

Epoch: 6| Step: 7
Training loss: 0.8390038013458252
Validation loss: 2.0050686790097143

Epoch: 6| Step: 8
Training loss: 1.5519027709960938
Validation loss: 2.0307518769336004

Epoch: 6| Step: 9
Training loss: 1.220526933670044
Validation loss: 2.0324375616606845

Epoch: 6| Step: 10
Training loss: 1.2980352640151978
Validation loss: 1.988820824571835

Epoch: 6| Step: 11
Training loss: 1.2111139297485352
Validation loss: 1.9913335820680023

Epoch: 6| Step: 12
Training loss: 1.0315837860107422
Validation loss: 1.9449073140339186

Epoch: 6| Step: 13
Training loss: 1.1827419996261597
Validation loss: 1.9445737356780677

Epoch: 348| Step: 0
Training loss: 1.1520750522613525
Validation loss: 1.936379498051059

Epoch: 6| Step: 1
Training loss: 1.214127779006958
Validation loss: 1.9535028242295789

Epoch: 6| Step: 2
Training loss: 1.472656011581421
Validation loss: 1.9592549800872803

Epoch: 6| Step: 3
Training loss: 1.423126459121704
Validation loss: 2.005671537050637

Epoch: 6| Step: 4
Training loss: 1.2529100179672241
Validation loss: 2.0558568559667116

Epoch: 6| Step: 5
Training loss: 1.7935211658477783
Validation loss: 2.0624300279924945

Epoch: 6| Step: 6
Training loss: 0.642421305179596
Validation loss: 2.0409546385529223

Epoch: 6| Step: 7
Training loss: 1.2742769718170166
Validation loss: 2.0290325508322766

Epoch: 6| Step: 8
Training loss: 1.3985636234283447
Validation loss: 1.9486637141114922

Epoch: 6| Step: 9
Training loss: 1.191105842590332
Validation loss: 1.979732910792033

Epoch: 6| Step: 10
Training loss: 1.5197620391845703
Validation loss: 1.9496669615468671

Epoch: 6| Step: 11
Training loss: 1.132432222366333
Validation loss: 1.975973936819261

Epoch: 6| Step: 12
Training loss: 0.7138274908065796
Validation loss: 1.9575285296286307

Epoch: 6| Step: 13
Training loss: 0.9218800067901611
Validation loss: 1.9796916515596452

Epoch: 349| Step: 0
Training loss: 1.3316845893859863
Validation loss: 1.9565514941369333

Epoch: 6| Step: 1
Training loss: 1.4847928285598755
Validation loss: 1.9491324681107716

Epoch: 6| Step: 2
Training loss: 0.8831861615180969
Validation loss: 1.9919061365947928

Epoch: 6| Step: 3
Training loss: 0.8100223541259766
Validation loss: 1.9965939739699006

Epoch: 6| Step: 4
Training loss: 0.7048426270484924
Validation loss: 2.0101566596697737

Epoch: 6| Step: 5
Training loss: 1.4647871255874634
Validation loss: 2.024774497555148

Epoch: 6| Step: 6
Training loss: 1.8970015048980713
Validation loss: 2.0141699250026415

Epoch: 6| Step: 7
Training loss: 1.3930113315582275
Validation loss: 2.000503049101881

Epoch: 6| Step: 8
Training loss: 1.9022564888000488
Validation loss: 1.9978527599765408

Epoch: 6| Step: 9
Training loss: 0.7439546585083008
Validation loss: 1.9645146349424958

Epoch: 6| Step: 10
Training loss: 0.7324031591415405
Validation loss: 1.967523701729313

Epoch: 6| Step: 11
Training loss: 1.2885823249816895
Validation loss: 1.9435274959892355

Epoch: 6| Step: 12
Training loss: 1.4776761531829834
Validation loss: 1.9383053279692126

Epoch: 6| Step: 13
Training loss: 1.3865084648132324
Validation loss: 1.915214257855569

Epoch: 350| Step: 0
Training loss: 0.888785183429718
Validation loss: 1.9419490163044264

Epoch: 6| Step: 1
Training loss: 1.2113455533981323
Validation loss: 1.9799964863766906

Epoch: 6| Step: 2
Training loss: 1.5090240240097046
Validation loss: 1.9755720707678026

Epoch: 6| Step: 3
Training loss: 1.0341796875
Validation loss: 2.004932716328611

Epoch: 6| Step: 4
Training loss: 1.0724291801452637
Validation loss: 2.02645186198655

Epoch: 6| Step: 5
Training loss: 1.4819258451461792
Validation loss: 2.010665729481687

Epoch: 6| Step: 6
Training loss: 1.6556320190429688
Validation loss: 2.027865298332707

Epoch: 6| Step: 7
Training loss: 1.2537899017333984
Validation loss: 1.996835018998833

Epoch: 6| Step: 8
Training loss: 1.008272409439087
Validation loss: 1.9867588499540925

Epoch: 6| Step: 9
Training loss: 1.2107913494110107
Validation loss: 1.963480116218649

Epoch: 6| Step: 10
Training loss: 1.2587684392929077
Validation loss: 1.9475555368649062

Epoch: 6| Step: 11
Training loss: 1.1077147722244263
Validation loss: 1.9336660062113116

Epoch: 6| Step: 12
Training loss: 1.0094693899154663
Validation loss: 1.9257869233367264

Epoch: 6| Step: 13
Training loss: 1.5597306489944458
Validation loss: 1.9531176449150167

Epoch: 351| Step: 0
Training loss: 1.5962047576904297
Validation loss: 1.9859057613598403

Epoch: 6| Step: 1
Training loss: 1.722365379333496
Validation loss: 2.007031093361557

Epoch: 6| Step: 2
Training loss: 1.351264476776123
Validation loss: 2.046647176947645

Epoch: 6| Step: 3
Training loss: 1.0968234539031982
Validation loss: 2.0844858666901946

Epoch: 6| Step: 4
Training loss: 1.3001034259796143
Validation loss: 2.066110669925649

Epoch: 6| Step: 5
Training loss: 0.6922467947006226
Validation loss: 2.02051479201163

Epoch: 6| Step: 6
Training loss: 0.9954904317855835
Validation loss: 1.9785854419072468

Epoch: 6| Step: 7
Training loss: 1.0949996709823608
Validation loss: 1.9560675531305292

Epoch: 6| Step: 8
Training loss: 1.2525404691696167
Validation loss: 1.916935496432807

Epoch: 6| Step: 9
Training loss: 1.1463370323181152
Validation loss: 1.9124700651373914

Epoch: 6| Step: 10
Training loss: 0.9750416278839111
Validation loss: 1.9478720106104368

Epoch: 6| Step: 11
Training loss: 1.25230872631073
Validation loss: 1.9145047613369521

Epoch: 6| Step: 12
Training loss: 0.6965909004211426
Validation loss: 1.9627558159571823

Epoch: 6| Step: 13
Training loss: 2.0595929622650146
Validation loss: 1.9602112731625956

Epoch: 352| Step: 0
Training loss: 1.3848155736923218
Validation loss: 2.0135918971030944

Epoch: 6| Step: 1
Training loss: 1.4183173179626465
Validation loss: 2.054084979077821

Epoch: 6| Step: 2
Training loss: 1.0574424266815186
Validation loss: 2.0528081360683648

Epoch: 6| Step: 3
Training loss: 1.6862208843231201
Validation loss: 2.073931699158043

Epoch: 6| Step: 4
Training loss: 1.113480806350708
Validation loss: 2.0294677313937934

Epoch: 6| Step: 5
Training loss: 1.0277037620544434
Validation loss: 2.008493741353353

Epoch: 6| Step: 6
Training loss: 0.9126778841018677
Validation loss: 1.963368078713776

Epoch: 6| Step: 7
Training loss: 1.5929369926452637
Validation loss: 1.9029631896685528

Epoch: 6| Step: 8
Training loss: 1.2378352880477905
Validation loss: 1.868080154542

Epoch: 6| Step: 9
Training loss: 1.1399624347686768
Validation loss: 1.8874419684051185

Epoch: 6| Step: 10
Training loss: 0.996150016784668
Validation loss: 1.8904208675507577

Epoch: 6| Step: 11
Training loss: 1.1374412775039673
Validation loss: 1.9142856661991408

Epoch: 6| Step: 12
Training loss: 0.9438753128051758
Validation loss: 1.9332646451970583

Epoch: 6| Step: 13
Training loss: 1.148655891418457
Validation loss: 1.9559913809581468

Epoch: 353| Step: 0
Training loss: 1.1420661211013794
Validation loss: 1.9881591566147343

Epoch: 6| Step: 1
Training loss: 1.1918045282363892
Validation loss: 2.0536830297080417

Epoch: 6| Step: 2
Training loss: 1.3344287872314453
Validation loss: 2.077100661493117

Epoch: 6| Step: 3
Training loss: 0.7441465854644775
Validation loss: 2.111827932378297

Epoch: 6| Step: 4
Training loss: 1.3863768577575684
Validation loss: 2.0546116828918457

Epoch: 6| Step: 5
Training loss: 1.1771132946014404
Validation loss: 2.018998848494663

Epoch: 6| Step: 6
Training loss: 1.5639591217041016
Validation loss: 1.970125308600805

Epoch: 6| Step: 7
Training loss: 1.3217220306396484
Validation loss: 1.939111231475748

Epoch: 6| Step: 8
Training loss: 1.616819143295288
Validation loss: 1.9259088654671945

Epoch: 6| Step: 9
Training loss: 0.44454798102378845
Validation loss: 1.9083663417446999

Epoch: 6| Step: 10
Training loss: 0.9790547490119934
Validation loss: 1.939982630873239

Epoch: 6| Step: 11
Training loss: 1.600867509841919
Validation loss: 2.0087919081411054

Epoch: 6| Step: 12
Training loss: 1.6718175411224365
Validation loss: 2.0201139860255743

Epoch: 6| Step: 13
Training loss: 0.9580389857292175
Validation loss: 2.008519526450865

Epoch: 354| Step: 0
Training loss: 1.7560272216796875
Validation loss: 1.9892378622485745

Epoch: 6| Step: 1
Training loss: 0.7594393491744995
Validation loss: 1.9526244196840512

Epoch: 6| Step: 2
Training loss: 1.1188982725143433
Validation loss: 1.9575340363287157

Epoch: 6| Step: 3
Training loss: 1.2025678157806396
Validation loss: 1.9675266358160204

Epoch: 6| Step: 4
Training loss: 1.1030144691467285
Validation loss: 1.954302635244144

Epoch: 6| Step: 5
Training loss: 1.2501509189605713
Validation loss: 1.974015284610051

Epoch: 6| Step: 6
Training loss: 1.3764005899429321
Validation loss: 1.9555138977625037

Epoch: 6| Step: 7
Training loss: 1.7117578983306885
Validation loss: 1.9926294895910448

Epoch: 6| Step: 8
Training loss: 0.44095727801322937
Validation loss: 1.9623767201618483

Epoch: 6| Step: 9
Training loss: 1.4993892908096313
Validation loss: 1.9545339461295836

Epoch: 6| Step: 10
Training loss: 1.2224137783050537
Validation loss: 1.9768355546459075

Epoch: 6| Step: 11
Training loss: 0.647918164730072
Validation loss: 1.9910219818033197

Epoch: 6| Step: 12
Training loss: 1.245530605316162
Validation loss: 1.9857628332671298

Epoch: 6| Step: 13
Training loss: 1.1109695434570312
Validation loss: 1.9815735201681814

Epoch: 355| Step: 0
Training loss: 0.9335581064224243
Validation loss: 1.9501285796524377

Epoch: 6| Step: 1
Training loss: 0.912300169467926
Validation loss: 1.9892464876174927

Epoch: 6| Step: 2
Training loss: 1.9134399890899658
Validation loss: 1.9658219173390379

Epoch: 6| Step: 3
Training loss: 0.709845781326294
Validation loss: 2.000630247977472

Epoch: 6| Step: 4
Training loss: 1.502514123916626
Validation loss: 2.013743386473707

Epoch: 6| Step: 5
Training loss: 1.2138981819152832
Validation loss: 1.9991722363297657

Epoch: 6| Step: 6
Training loss: 1.045793056488037
Validation loss: 1.9893828617629183

Epoch: 6| Step: 7
Training loss: 0.8048120737075806
Validation loss: 1.986933486436003

Epoch: 6| Step: 8
Training loss: 1.108551263809204
Validation loss: 1.9664967072907316

Epoch: 6| Step: 9
Training loss: 1.2783374786376953
Validation loss: 1.9861164093017578

Epoch: 6| Step: 10
Training loss: 1.2060390710830688
Validation loss: 2.0071843875351774

Epoch: 6| Step: 11
Training loss: 1.2990410327911377
Validation loss: 1.9696398768373715

Epoch: 6| Step: 12
Training loss: 1.4510886669158936
Validation loss: 2.00173827268744

Epoch: 6| Step: 13
Training loss: 0.7086584568023682
Validation loss: 2.038929944397301

Epoch: 356| Step: 0
Training loss: 1.2459781169891357
Validation loss: 2.0011224182703162

Epoch: 6| Step: 1
Training loss: 0.6265147924423218
Validation loss: 2.026358204503213

Epoch: 6| Step: 2
Training loss: 1.644531488418579
Validation loss: 2.0194248691681893

Epoch: 6| Step: 3
Training loss: 1.2388808727264404
Validation loss: 1.987614522698105

Epoch: 6| Step: 4
Training loss: 0.9096112251281738
Validation loss: 1.919488242877427

Epoch: 6| Step: 5
Training loss: 1.1906070709228516
Validation loss: 1.9138144408502886

Epoch: 6| Step: 6
Training loss: 1.088313102722168
Validation loss: 1.8841233996934788

Epoch: 6| Step: 7
Training loss: 1.3564321994781494
Validation loss: 1.9023866371441913

Epoch: 6| Step: 8
Training loss: 1.493201494216919
Validation loss: 1.914061495052871

Epoch: 6| Step: 9
Training loss: 0.829816460609436
Validation loss: 1.9486993961436774

Epoch: 6| Step: 10
Training loss: 1.6686652898788452
Validation loss: 1.9812564785762499

Epoch: 6| Step: 11
Training loss: 1.137203574180603
Validation loss: 2.020152547026193

Epoch: 6| Step: 12
Training loss: 1.0647867918014526
Validation loss: 2.0570650895436606

Epoch: 6| Step: 13
Training loss: 1.2200599908828735
Validation loss: 2.0989998438025035

Epoch: 357| Step: 0
Training loss: 1.4437506198883057
Validation loss: 2.0936846835638887

Epoch: 6| Step: 1
Training loss: 1.4601998329162598
Validation loss: 2.053079938375822

Epoch: 6| Step: 2
Training loss: 0.9266506433486938
Validation loss: 2.0328779861491215

Epoch: 6| Step: 3
Training loss: 1.1023166179656982
Validation loss: 1.999323384736174

Epoch: 6| Step: 4
Training loss: 0.9350215792655945
Validation loss: 1.9361913922012493

Epoch: 6| Step: 5
Training loss: 0.7625172138214111
Validation loss: 1.8961855711475495

Epoch: 6| Step: 6
Training loss: 1.3979730606079102
Validation loss: 1.9038285081104567

Epoch: 6| Step: 7
Training loss: 0.8819325566291809
Validation loss: 1.914265828747903

Epoch: 6| Step: 8
Training loss: 1.4563748836517334
Validation loss: 1.930607480387534

Epoch: 6| Step: 9
Training loss: 0.7720984816551208
Validation loss: 1.9481465303769676

Epoch: 6| Step: 10
Training loss: 1.8872830867767334
Validation loss: 1.9730178733025827

Epoch: 6| Step: 11
Training loss: 0.7412024736404419
Validation loss: 2.033833448604871

Epoch: 6| Step: 12
Training loss: 0.7994814515113831
Validation loss: 2.039481242497762

Epoch: 6| Step: 13
Training loss: 2.426652193069458
Validation loss: 2.035941299571786

Epoch: 358| Step: 0
Training loss: 1.5307655334472656
Validation loss: 2.0343083630325975

Epoch: 6| Step: 1
Training loss: 1.6262882947921753
Validation loss: 2.038662028569047

Epoch: 6| Step: 2
Training loss: 1.1225773096084595
Validation loss: 2.021580085959486

Epoch: 6| Step: 3
Training loss: 1.70179283618927
Validation loss: 2.037253979713686

Epoch: 6| Step: 4
Training loss: 1.1517176628112793
Validation loss: 2.0188161378265708

Epoch: 6| Step: 5
Training loss: 1.242109775543213
Validation loss: 1.9675080724941787

Epoch: 6| Step: 6
Training loss: 0.8202334642410278
Validation loss: 1.9587528000595749

Epoch: 6| Step: 7
Training loss: 1.1385395526885986
Validation loss: 1.9741644897768575

Epoch: 6| Step: 8
Training loss: 0.9319218397140503
Validation loss: 1.9587849519586051

Epoch: 6| Step: 9
Training loss: 1.2153092622756958
Validation loss: 2.0231943374039023

Epoch: 6| Step: 10
Training loss: 1.2200113534927368
Validation loss: 2.037001790538911

Epoch: 6| Step: 11
Training loss: 1.200714349746704
Validation loss: 2.0684238608165453

Epoch: 6| Step: 12
Training loss: 1.1598764657974243
Validation loss: 2.031066826594773

Epoch: 6| Step: 13
Training loss: 1.1756157875061035
Validation loss: 1.9857904090676257

Epoch: 359| Step: 0
Training loss: 1.2672405242919922
Validation loss: 1.9732979471965502

Epoch: 6| Step: 1
Training loss: 0.9160306453704834
Validation loss: 1.9988299710776216

Epoch: 6| Step: 2
Training loss: 0.8880084753036499
Validation loss: 1.9681940604281682

Epoch: 6| Step: 3
Training loss: 1.445265769958496
Validation loss: 1.971452001602419

Epoch: 6| Step: 4
Training loss: 1.4899952411651611
Validation loss: 1.9466913951340543

Epoch: 6| Step: 5
Training loss: 1.5415616035461426
Validation loss: 1.9248898721510364

Epoch: 6| Step: 6
Training loss: 1.1341830492019653
Validation loss: 1.9504159522312943

Epoch: 6| Step: 7
Training loss: 1.5523762702941895
Validation loss: 1.953020038143281

Epoch: 6| Step: 8
Training loss: 1.0991936922073364
Validation loss: 1.972138418946215

Epoch: 6| Step: 9
Training loss: 1.066254734992981
Validation loss: 1.977595890721967

Epoch: 6| Step: 10
Training loss: 0.5149911642074585
Validation loss: 1.9594110071018178

Epoch: 6| Step: 11
Training loss: 1.4465688467025757
Validation loss: 1.9172423719077982

Epoch: 6| Step: 12
Training loss: 0.7631348371505737
Validation loss: 1.9514264265696208

Epoch: 6| Step: 13
Training loss: 1.3053736686706543
Validation loss: 1.9575852271049254

Epoch: 360| Step: 0
Training loss: 1.0614655017852783
Validation loss: 2.025779137047388

Epoch: 6| Step: 1
Training loss: 1.0773049592971802
Validation loss: 2.0271107291662567

Epoch: 6| Step: 2
Training loss: 1.0035618543624878
Validation loss: 2.0604866448269097

Epoch: 6| Step: 3
Training loss: 0.9803105592727661
Validation loss: 2.036501266623056

Epoch: 6| Step: 4
Training loss: 1.0780434608459473
Validation loss: 2.0268186125704037

Epoch: 6| Step: 5
Training loss: 1.3346412181854248
Validation loss: 1.9860617422288465

Epoch: 6| Step: 6
Training loss: 1.2505213022232056
Validation loss: 1.982056253699846

Epoch: 6| Step: 7
Training loss: 1.3700671195983887
Validation loss: 1.9863341059736026

Epoch: 6| Step: 8
Training loss: 1.330183982849121
Validation loss: 2.0072283872994046

Epoch: 6| Step: 9
Training loss: 0.9886819124221802
Validation loss: 1.976298644978513

Epoch: 6| Step: 10
Training loss: 1.4789645671844482
Validation loss: 1.9791605177746023

Epoch: 6| Step: 11
Training loss: 0.9999971389770508
Validation loss: 1.9800460646229405

Epoch: 6| Step: 12
Training loss: 1.0013047456741333
Validation loss: 1.9096024420953566

Epoch: 6| Step: 13
Training loss: 1.222946286201477
Validation loss: 1.917270500172851

Epoch: 361| Step: 0
Training loss: 1.2833926677703857
Validation loss: 1.917561197793612

Epoch: 6| Step: 1
Training loss: 1.2018053531646729
Validation loss: 1.9168668408547678

Epoch: 6| Step: 2
Training loss: 1.037111520767212
Validation loss: 1.9135745481778217

Epoch: 6| Step: 3
Training loss: 0.7816736102104187
Validation loss: 1.9597977476735269

Epoch: 6| Step: 4
Training loss: 1.1914979219436646
Validation loss: 1.9634294509887695

Epoch: 6| Step: 5
Training loss: 1.3565516471862793
Validation loss: 2.015062796172275

Epoch: 6| Step: 6
Training loss: 1.3608394861221313
Validation loss: 1.998772144317627

Epoch: 6| Step: 7
Training loss: 1.6739145517349243
Validation loss: 2.009569198854508

Epoch: 6| Step: 8
Training loss: 0.9728584289550781
Validation loss: 2.0283355559072187

Epoch: 6| Step: 9
Training loss: 0.3847612142562866
Validation loss: 2.028217705347205

Epoch: 6| Step: 10
Training loss: 0.8982619047164917
Validation loss: 2.0380102613920807

Epoch: 6| Step: 11
Training loss: 1.2942925691604614
Validation loss: 2.013867223134605

Epoch: 6| Step: 12
Training loss: 1.308384656906128
Validation loss: 2.012961747825787

Epoch: 6| Step: 13
Training loss: 1.0635170936584473
Validation loss: 2.02568006771867

Epoch: 362| Step: 0
Training loss: 1.3440217971801758
Validation loss: 2.035810468017414

Epoch: 6| Step: 1
Training loss: 1.176129937171936
Validation loss: 2.0588164278255996

Epoch: 6| Step: 2
Training loss: 0.9251247048377991
Validation loss: 2.0284870260505268

Epoch: 6| Step: 3
Training loss: 1.1038116216659546
Validation loss: 2.0357853404937254

Epoch: 6| Step: 4
Training loss: 1.0019437074661255
Validation loss: 2.0228912907262004

Epoch: 6| Step: 5
Training loss: 1.4344773292541504
Validation loss: 2.00722836935392

Epoch: 6| Step: 6
Training loss: 1.0516180992126465
Validation loss: 2.0074235918701335

Epoch: 6| Step: 7
Training loss: 1.4286541938781738
Validation loss: 2.027999754874937

Epoch: 6| Step: 8
Training loss: 0.8259930610656738
Validation loss: 2.0113485526013117

Epoch: 6| Step: 9
Training loss: 0.8539401888847351
Validation loss: 1.9814011819901005

Epoch: 6| Step: 10
Training loss: 1.057909607887268
Validation loss: 2.00767949832383

Epoch: 6| Step: 11
Training loss: 0.5827658772468567
Validation loss: 2.0083374131110405

Epoch: 6| Step: 12
Training loss: 1.6813604831695557
Validation loss: 1.9865841070810955

Epoch: 6| Step: 13
Training loss: 1.2662322521209717
Validation loss: 1.9831133542522308

Epoch: 363| Step: 0
Training loss: 1.1018905639648438
Validation loss: 1.9461022576978129

Epoch: 6| Step: 1
Training loss: 1.0015383958816528
Validation loss: 1.9044628348401798

Epoch: 6| Step: 2
Training loss: 1.3546020984649658
Validation loss: 1.870600958024302

Epoch: 6| Step: 3
Training loss: 1.0213689804077148
Validation loss: 1.8760482085648404

Epoch: 6| Step: 4
Training loss: 1.2509264945983887
Validation loss: 1.8780251523499847

Epoch: 6| Step: 5
Training loss: 0.8551626205444336
Validation loss: 1.9002309383884552

Epoch: 6| Step: 6
Training loss: 1.2925753593444824
Validation loss: 1.9393077614486858

Epoch: 6| Step: 7
Training loss: 2.088042736053467
Validation loss: 1.9603175604215233

Epoch: 6| Step: 8
Training loss: 0.7897082567214966
Validation loss: 1.9950514865177933

Epoch: 6| Step: 9
Training loss: 1.3581207990646362
Validation loss: 2.013639111672678

Epoch: 6| Step: 10
Training loss: 1.4094939231872559
Validation loss: 2.1211395532854143

Epoch: 6| Step: 11
Training loss: 1.0630311965942383
Validation loss: 2.1890393713469147

Epoch: 6| Step: 12
Training loss: 1.514181137084961
Validation loss: 2.2496920349777385

Epoch: 6| Step: 13
Training loss: 0.7407182455062866
Validation loss: 2.1213366177774247

Epoch: 364| Step: 0
Training loss: 1.2510877847671509
Validation loss: 2.020962581839613

Epoch: 6| Step: 1
Training loss: 1.0225677490234375
Validation loss: 1.953797794157459

Epoch: 6| Step: 2
Training loss: 1.3567960262298584
Validation loss: 1.955489327830653

Epoch: 6| Step: 3
Training loss: 1.1175222396850586
Validation loss: 1.9036857748544345

Epoch: 6| Step: 4
Training loss: 1.498661756515503
Validation loss: 1.9239381987561461

Epoch: 6| Step: 5
Training loss: 1.3371198177337646
Validation loss: 1.8868897063757784

Epoch: 6| Step: 6
Training loss: 0.8912303447723389
Validation loss: 1.9046894747723815

Epoch: 6| Step: 7
Training loss: 1.538818359375
Validation loss: 1.8834354185288953

Epoch: 6| Step: 8
Training loss: 0.9022960066795349
Validation loss: 1.8880372457606818

Epoch: 6| Step: 9
Training loss: 1.1721436977386475
Validation loss: 1.939664182483509

Epoch: 6| Step: 10
Training loss: 1.0411326885223389
Validation loss: 1.988025378155452

Epoch: 6| Step: 11
Training loss: 0.8751485347747803
Validation loss: 2.0137670117039836

Epoch: 6| Step: 12
Training loss: 1.048196792602539
Validation loss: 2.022943497985922

Epoch: 6| Step: 13
Training loss: 1.6019397974014282
Validation loss: 2.009748892117572

Epoch: 365| Step: 0
Training loss: 1.2881616353988647
Validation loss: 2.0046114152477634

Epoch: 6| Step: 1
Training loss: 1.0312782526016235
Validation loss: 1.9584652044439828

Epoch: 6| Step: 2
Training loss: 1.4795641899108887
Validation loss: 1.9484654780357116

Epoch: 6| Step: 3
Training loss: 0.7581949830055237
Validation loss: 1.9436335307295605

Epoch: 6| Step: 4
Training loss: 1.2722108364105225
Validation loss: 1.9743519470255861

Epoch: 6| Step: 5
Training loss: 1.0508995056152344
Validation loss: 1.9667894135239303

Epoch: 6| Step: 6
Training loss: 0.7678253650665283
Validation loss: 1.968967209580124

Epoch: 6| Step: 7
Training loss: 1.0716285705566406
Validation loss: 1.9759883290977889

Epoch: 6| Step: 8
Training loss: 1.449319839477539
Validation loss: 2.0060677682199786

Epoch: 6| Step: 9
Training loss: 0.7510964870452881
Validation loss: 1.9578561026562926

Epoch: 6| Step: 10
Training loss: 1.3902071714401245
Validation loss: 1.9904225616044895

Epoch: 6| Step: 11
Training loss: 0.8644040822982788
Validation loss: 1.9193975258898992

Epoch: 6| Step: 12
Training loss: 1.8140027523040771
Validation loss: 1.9276404919162873

Epoch: 6| Step: 13
Training loss: 0.8289329409599304
Validation loss: 1.8943387731429069

Epoch: 366| Step: 0
Training loss: 1.4325652122497559
Validation loss: 1.8737090505579466

Epoch: 6| Step: 1
Training loss: 1.2532864809036255
Validation loss: 1.8682965181207145

Epoch: 6| Step: 2
Training loss: 0.9643744230270386
Validation loss: 1.9008117222016858

Epoch: 6| Step: 3
Training loss: 0.7428723573684692
Validation loss: 1.9441601640434676

Epoch: 6| Step: 4
Training loss: 0.8585666418075562
Validation loss: 1.9877212662850656

Epoch: 6| Step: 5
Training loss: 1.1911954879760742
Validation loss: 2.0388208153427287

Epoch: 6| Step: 6
Training loss: 1.6214230060577393
Validation loss: 2.0549803433879728

Epoch: 6| Step: 7
Training loss: 1.0220935344696045
Validation loss: 2.079909045209167

Epoch: 6| Step: 8
Training loss: 1.503455400466919
Validation loss: 2.0278068973172094

Epoch: 6| Step: 9
Training loss: 1.3150984048843384
Validation loss: 2.0219208450727564

Epoch: 6| Step: 10
Training loss: 0.7465193867683411
Validation loss: 1.9698956653635988

Epoch: 6| Step: 11
Training loss: 1.1252752542495728
Validation loss: 1.9176031902272215

Epoch: 6| Step: 12
Training loss: 0.984994649887085
Validation loss: 1.868704935555817

Epoch: 6| Step: 13
Training loss: 0.8148861527442932
Validation loss: 1.8874960189224572

Epoch: 367| Step: 0
Training loss: 1.9748611450195312
Validation loss: 1.8910181317278134

Epoch: 6| Step: 1
Training loss: 1.314988136291504
Validation loss: 1.896537483379405

Epoch: 6| Step: 2
Training loss: 0.8546664714813232
Validation loss: 1.883883927458076

Epoch: 6| Step: 3
Training loss: 0.6770446300506592
Validation loss: 1.8959700304974791

Epoch: 6| Step: 4
Training loss: 0.5149617791175842
Validation loss: 1.9469403541216286

Epoch: 6| Step: 5
Training loss: 0.8689354658126831
Validation loss: 1.9874050014762468

Epoch: 6| Step: 6
Training loss: 1.5491001605987549
Validation loss: 2.0351760874512377

Epoch: 6| Step: 7
Training loss: 1.1634900569915771
Validation loss: 2.04756615366987

Epoch: 6| Step: 8
Training loss: 1.3983964920043945
Validation loss: 2.066422482972504

Epoch: 6| Step: 9
Training loss: 1.3940150737762451
Validation loss: 2.0321313899050475

Epoch: 6| Step: 10
Training loss: 0.9680883288383484
Validation loss: 2.0085873732002835

Epoch: 6| Step: 11
Training loss: 1.0370897054672241
Validation loss: 1.9653060192702918

Epoch: 6| Step: 12
Training loss: 1.1772096157073975
Validation loss: 1.9745042093338505

Epoch: 6| Step: 13
Training loss: 0.8098617196083069
Validation loss: 1.8924093297732774

Epoch: 368| Step: 0
Training loss: 1.1279809474945068
Validation loss: 1.9039009835130425

Epoch: 6| Step: 1
Training loss: 1.1137986183166504
Validation loss: 1.9049683411916096

Epoch: 6| Step: 2
Training loss: 1.0739977359771729
Validation loss: 1.9500496977119035

Epoch: 6| Step: 3
Training loss: 1.3521966934204102
Validation loss: 1.9389114341428202

Epoch: 6| Step: 4
Training loss: 1.215947151184082
Validation loss: 1.9507112169778476

Epoch: 6| Step: 5
Training loss: 1.0769485235214233
Validation loss: 1.919046381468414

Epoch: 6| Step: 6
Training loss: 0.8892374038696289
Validation loss: 1.9253501699816795

Epoch: 6| Step: 7
Training loss: 0.8378345370292664
Validation loss: 1.9666663600552468

Epoch: 6| Step: 8
Training loss: 1.0180734395980835
Validation loss: 2.0014109303874354

Epoch: 6| Step: 9
Training loss: 0.9323685169219971
Validation loss: 2.000555155097797

Epoch: 6| Step: 10
Training loss: 1.2919423580169678
Validation loss: 2.020303431377616

Epoch: 6| Step: 11
Training loss: 1.1179401874542236
Validation loss: 2.016604141522479

Epoch: 6| Step: 12
Training loss: 1.3950318098068237
Validation loss: 2.022286525336645

Epoch: 6| Step: 13
Training loss: 1.177990198135376
Validation loss: 2.0346775388204925

Epoch: 369| Step: 0
Training loss: 1.336674451828003
Validation loss: 2.0161976275905484

Epoch: 6| Step: 1
Training loss: 0.9842443466186523
Validation loss: 2.00667711739899

Epoch: 6| Step: 2
Training loss: 1.475635290145874
Validation loss: 1.932927631562756

Epoch: 6| Step: 3
Training loss: 1.6173975467681885
Validation loss: 1.925421639155316

Epoch: 6| Step: 4
Training loss: 0.547257125377655
Validation loss: 1.8986410530664588

Epoch: 6| Step: 5
Training loss: 0.9699035882949829
Validation loss: 1.9168216669431297

Epoch: 6| Step: 6
Training loss: 1.7917956113815308
Validation loss: 1.8885251155463598

Epoch: 6| Step: 7
Training loss: 1.267214059829712
Validation loss: 1.9034670040171633

Epoch: 6| Step: 8
Training loss: 0.6527023315429688
Validation loss: 1.9469347923032698

Epoch: 6| Step: 9
Training loss: 0.48074042797088623
Validation loss: 1.9770367978721537

Epoch: 6| Step: 10
Training loss: 1.3078560829162598
Validation loss: 2.0022281933856267

Epoch: 6| Step: 11
Training loss: 0.8990062475204468
Validation loss: 2.02271508273258

Epoch: 6| Step: 12
Training loss: 0.8421043753623962
Validation loss: 2.029570430837652

Epoch: 6| Step: 13
Training loss: 1.1665396690368652
Validation loss: 2.0199893007996264

Epoch: 370| Step: 0
Training loss: 1.295174479484558
Validation loss: 1.981127920971122

Epoch: 6| Step: 1
Training loss: 1.0222922563552856
Validation loss: 2.0114717816793792

Epoch: 6| Step: 2
Training loss: 1.093724012374878
Validation loss: 1.986182019274722

Epoch: 6| Step: 3
Training loss: 1.2075762748718262
Validation loss: 1.9704335569053568

Epoch: 6| Step: 4
Training loss: 0.8096950054168701
Validation loss: 1.942499590176408

Epoch: 6| Step: 5
Training loss: 1.5102680921554565
Validation loss: 1.9236719492943055

Epoch: 6| Step: 6
Training loss: 0.5012273788452148
Validation loss: 1.9182319538567656

Epoch: 6| Step: 7
Training loss: 0.987510085105896
Validation loss: 1.9155542773585166

Epoch: 6| Step: 8
Training loss: 1.1283810138702393
Validation loss: 1.9195828758260256

Epoch: 6| Step: 9
Training loss: 1.3781300783157349
Validation loss: 1.9334520396365915

Epoch: 6| Step: 10
Training loss: 0.7778550386428833
Validation loss: 1.9453845498382405

Epoch: 6| Step: 11
Training loss: 1.3218653202056885
Validation loss: 1.9707142332548737

Epoch: 6| Step: 12
Training loss: 1.2084665298461914
Validation loss: 1.9784906692402338

Epoch: 6| Step: 13
Training loss: 0.5835673213005066
Validation loss: 2.0218056683899253

Epoch: 371| Step: 0
Training loss: 1.2590391635894775
Validation loss: 2.0378984456421225

Epoch: 6| Step: 1
Training loss: 0.7376553416252136
Validation loss: 2.0233107523251603

Epoch: 6| Step: 2
Training loss: 1.2508792877197266
Validation loss: 2.0579267983795493

Epoch: 6| Step: 3
Training loss: 0.6535050868988037
Validation loss: 2.0301108539745374

Epoch: 6| Step: 4
Training loss: 1.030620813369751
Validation loss: 1.9953102116943688

Epoch: 6| Step: 5
Training loss: 0.9746878147125244
Validation loss: 1.9969238491468533

Epoch: 6| Step: 6
Training loss: 0.772885262966156
Validation loss: 1.9568032474928005

Epoch: 6| Step: 7
Training loss: 1.204012155532837
Validation loss: 1.967424564464118

Epoch: 6| Step: 8
Training loss: 1.1568806171417236
Validation loss: 1.9420777546462191

Epoch: 6| Step: 9
Training loss: 1.1738083362579346
Validation loss: 1.941380113683721

Epoch: 6| Step: 10
Training loss: 1.7028205394744873
Validation loss: 1.9246140398005003

Epoch: 6| Step: 11
Training loss: 1.4717894792556763
Validation loss: 1.896011511484782

Epoch: 6| Step: 12
Training loss: 0.6029084324836731
Validation loss: 1.9132086512862996

Epoch: 6| Step: 13
Training loss: 1.0890573263168335
Validation loss: 1.9120672659207416

Epoch: 372| Step: 0
Training loss: 0.9457123279571533
Validation loss: 1.9406950089239305

Epoch: 6| Step: 1
Training loss: 0.9010931849479675
Validation loss: 1.98055955671495

Epoch: 6| Step: 2
Training loss: 1.0950191020965576
Validation loss: 1.9878121370910316

Epoch: 6| Step: 3
Training loss: 0.9823131561279297
Validation loss: 2.009258390754782

Epoch: 6| Step: 4
Training loss: 0.8049265742301941
Validation loss: 2.0298493036659817

Epoch: 6| Step: 5
Training loss: 0.9752612113952637
Validation loss: 2.0463738287648847

Epoch: 6| Step: 6
Training loss: 1.240808367729187
Validation loss: 2.024750295505729

Epoch: 6| Step: 7
Training loss: 1.1624975204467773
Validation loss: 2.0570499102274575

Epoch: 6| Step: 8
Training loss: 1.075078010559082
Validation loss: 2.033977770036267

Epoch: 6| Step: 9
Training loss: 0.8634215593338013
Validation loss: 2.0004438200304584

Epoch: 6| Step: 10
Training loss: 1.0018198490142822
Validation loss: 1.9633109659276984

Epoch: 6| Step: 11
Training loss: 0.9312301874160767
Validation loss: 1.955917425053094

Epoch: 6| Step: 12
Training loss: 1.5314257144927979
Validation loss: 1.9094306999637234

Epoch: 6| Step: 13
Training loss: 1.432989239692688
Validation loss: 1.9120061333461473

Epoch: 373| Step: 0
Training loss: 1.1983771324157715
Validation loss: 1.8808807044900873

Epoch: 6| Step: 1
Training loss: 1.5488990545272827
Validation loss: 1.8930182982516546

Epoch: 6| Step: 2
Training loss: 1.0233769416809082
Validation loss: 1.8581116507130284

Epoch: 6| Step: 3
Training loss: 1.399925947189331
Validation loss: 1.899096917080623

Epoch: 6| Step: 4
Training loss: 1.0533859729766846
Validation loss: 1.9484876330180834

Epoch: 6| Step: 5
Training loss: 0.875899612903595
Validation loss: 1.9622054612764748

Epoch: 6| Step: 6
Training loss: 0.8576401472091675
Validation loss: 2.034631598380304

Epoch: 6| Step: 7
Training loss: 0.8779931664466858
Validation loss: 2.0649864750523723

Epoch: 6| Step: 8
Training loss: 0.9372573494911194
Validation loss: 2.028698387966361

Epoch: 6| Step: 9
Training loss: 0.9140293598175049
Validation loss: 2.018702257064081

Epoch: 6| Step: 10
Training loss: 1.1126130819320679
Validation loss: 2.0126642757846462

Epoch: 6| Step: 11
Training loss: 0.6572429537773132
Validation loss: 1.9625969715015863

Epoch: 6| Step: 12
Training loss: 1.0873701572418213
Validation loss: 1.9500994451584355

Epoch: 6| Step: 13
Training loss: 1.8013250827789307
Validation loss: 1.9794633952520226

Epoch: 374| Step: 0
Training loss: 0.7739211320877075
Validation loss: 1.9784618141830608

Epoch: 6| Step: 1
Training loss: 1.0783993005752563
Validation loss: 1.9282168162766324

Epoch: 6| Step: 2
Training loss: 0.71455979347229
Validation loss: 2.011532924508536

Epoch: 6| Step: 3
Training loss: 0.868811309337616
Validation loss: 2.023495048604986

Epoch: 6| Step: 4
Training loss: 1.725301742553711
Validation loss: 1.998047810728832

Epoch: 6| Step: 5
Training loss: 0.81792151927948
Validation loss: 2.035828759593348

Epoch: 6| Step: 6
Training loss: 1.3214850425720215
Validation loss: 1.989313010246523

Epoch: 6| Step: 7
Training loss: 1.297086477279663
Validation loss: 1.9884423337956911

Epoch: 6| Step: 8
Training loss: 1.1360909938812256
Validation loss: 1.9106617845514768

Epoch: 6| Step: 9
Training loss: 0.9645571708679199
Validation loss: 1.9194764360304801

Epoch: 6| Step: 10
Training loss: 1.2838547229766846
Validation loss: 1.9089029271115538

Epoch: 6| Step: 11
Training loss: 0.9089513421058655
Validation loss: 1.9394825158580657

Epoch: 6| Step: 12
Training loss: 1.0955784320831299
Validation loss: 2.003756643623434

Epoch: 6| Step: 13
Training loss: 0.9969215393066406
Validation loss: 2.0184790959922214

Epoch: 375| Step: 0
Training loss: 1.5220119953155518
Validation loss: 2.046796347505303

Epoch: 6| Step: 1
Training loss: 1.5687167644500732
Validation loss: 2.0394885424644715

Epoch: 6| Step: 2
Training loss: 1.0396236181259155
Validation loss: 2.0561934889003797

Epoch: 6| Step: 3
Training loss: 1.0210423469543457
Validation loss: 2.0318564215014057

Epoch: 6| Step: 4
Training loss: 0.8135217428207397
Validation loss: 2.021381643510634

Epoch: 6| Step: 5
Training loss: 1.4455204010009766
Validation loss: 1.981128292699014

Epoch: 6| Step: 6
Training loss: 1.824609398841858
Validation loss: 1.9477391025071502

Epoch: 6| Step: 7
Training loss: 0.9728707075119019
Validation loss: 1.8774452030017812

Epoch: 6| Step: 8
Training loss: 1.1243343353271484
Validation loss: 1.8548314622653428

Epoch: 6| Step: 9
Training loss: 1.251734733581543
Validation loss: 1.8884847446154522

Epoch: 6| Step: 10
Training loss: 0.5229164361953735
Validation loss: 1.8920297097134333

Epoch: 6| Step: 11
Training loss: 1.0270206928253174
Validation loss: 1.9296204390064362

Epoch: 6| Step: 12
Training loss: 0.7679862976074219
Validation loss: 1.950563375667859

Epoch: 6| Step: 13
Training loss: 0.9237252473831177
Validation loss: 1.9624639288071664

Epoch: 376| Step: 0
Training loss: 1.0091307163238525
Validation loss: 2.04263279514928

Epoch: 6| Step: 1
Training loss: 1.0310250520706177
Validation loss: 2.0745519040733256

Epoch: 6| Step: 2
Training loss: 0.9692440629005432
Validation loss: 2.068671170101371

Epoch: 6| Step: 3
Training loss: 0.9938925504684448
Validation loss: 2.0237394943032214

Epoch: 6| Step: 4
Training loss: 0.7132848501205444
Validation loss: 1.9638702472050984

Epoch: 6| Step: 5
Training loss: 1.0018967390060425
Validation loss: 1.9253785981926868

Epoch: 6| Step: 6
Training loss: 1.6003862619400024
Validation loss: 1.9051316835547005

Epoch: 6| Step: 7
Training loss: 1.672330379486084
Validation loss: 1.8817811653178225

Epoch: 6| Step: 8
Training loss: 1.4020469188690186
Validation loss: 1.8903159813214374

Epoch: 6| Step: 9
Training loss: 1.1757795810699463
Validation loss: 1.882703600391265

Epoch: 6| Step: 10
Training loss: 0.8067219257354736
Validation loss: 1.855609546425522

Epoch: 6| Step: 11
Training loss: 1.0857229232788086
Validation loss: 1.8818890228066394

Epoch: 6| Step: 12
Training loss: 1.2539594173431396
Validation loss: 1.9357039236253308

Epoch: 6| Step: 13
Training loss: 0.46907323598861694
Validation loss: 1.9651599968633344

Epoch: 377| Step: 0
Training loss: 1.4105639457702637
Validation loss: 1.9898463577352545

Epoch: 6| Step: 1
Training loss: 0.752943754196167
Validation loss: 1.9856524557195685

Epoch: 6| Step: 2
Training loss: 0.7719061970710754
Validation loss: 1.9941889086077291

Epoch: 6| Step: 3
Training loss: 1.2835936546325684
Validation loss: 1.9792860964293122

Epoch: 6| Step: 4
Training loss: 0.8265233039855957
Validation loss: 1.9650370933676278

Epoch: 6| Step: 5
Training loss: 1.1175717115402222
Validation loss: 1.9455981498123498

Epoch: 6| Step: 6
Training loss: 1.1111838817596436
Validation loss: 1.9282699900288736

Epoch: 6| Step: 7
Training loss: 0.9144737720489502
Validation loss: 1.922814316647027

Epoch: 6| Step: 8
Training loss: 0.9523296356201172
Validation loss: 1.9523138589756464

Epoch: 6| Step: 9
Training loss: 0.9652292728424072
Validation loss: 1.937522703601468

Epoch: 6| Step: 10
Training loss: 1.086342692375183
Validation loss: 1.9479210633103565

Epoch: 6| Step: 11
Training loss: 0.8729025721549988
Validation loss: 1.9981083100841892

Epoch: 6| Step: 12
Training loss: 1.6200931072235107
Validation loss: 2.0318313003868185

Epoch: 6| Step: 13
Training loss: 0.6872876882553101
Validation loss: 2.0159801642100015

Epoch: 378| Step: 0
Training loss: 0.9643680453300476
Validation loss: 2.0104010630679388

Epoch: 6| Step: 1
Training loss: 1.2365760803222656
Validation loss: 1.9970844086780344

Epoch: 6| Step: 2
Training loss: 1.0487480163574219
Validation loss: 1.9910856575094245

Epoch: 6| Step: 3
Training loss: 1.1960116624832153
Validation loss: 2.0142245779755297

Epoch: 6| Step: 4
Training loss: 0.8677870035171509
Validation loss: 1.9876314606717838

Epoch: 6| Step: 5
Training loss: 0.955150842666626
Validation loss: 1.966294252744285

Epoch: 6| Step: 6
Training loss: 1.3738881349563599
Validation loss: 1.9741250661111647

Epoch: 6| Step: 7
Training loss: 1.0492149591445923
Validation loss: 1.9363495611375379

Epoch: 6| Step: 8
Training loss: 0.957524836063385
Validation loss: 1.9043981464960242

Epoch: 6| Step: 9
Training loss: 1.1782232522964478
Validation loss: 1.925651829729798

Epoch: 6| Step: 10
Training loss: 0.7888669967651367
Validation loss: 1.9361866853570426

Epoch: 6| Step: 11
Training loss: 1.2456616163253784
Validation loss: 1.9645796821963402

Epoch: 6| Step: 12
Training loss: 0.5983530879020691
Validation loss: 1.956123523814704

Epoch: 6| Step: 13
Training loss: 0.6016308665275574
Validation loss: 1.9783872583860993

Epoch: 379| Step: 0
Training loss: 0.5714982748031616
Validation loss: 1.993162101314914

Epoch: 6| Step: 1
Training loss: 1.1056329011917114
Validation loss: 1.9819152867922218

Epoch: 6| Step: 2
Training loss: 1.231846809387207
Validation loss: 1.980382348901482

Epoch: 6| Step: 3
Training loss: 0.8501027822494507
Validation loss: 1.9745129551938785

Epoch: 6| Step: 4
Training loss: 0.9144703149795532
Validation loss: 2.0029264509036975

Epoch: 6| Step: 5
Training loss: 0.8768474459648132
Validation loss: 1.9946293036142986

Epoch: 6| Step: 6
Training loss: 1.1985290050506592
Validation loss: 1.9706146229979813

Epoch: 6| Step: 7
Training loss: 1.2839871644973755
Validation loss: 1.965121070543925

Epoch: 6| Step: 8
Training loss: 0.8129088282585144
Validation loss: 1.9290672438119048

Epoch: 6| Step: 9
Training loss: 1.189770221710205
Validation loss: 1.8907054547340638

Epoch: 6| Step: 10
Training loss: 1.2753691673278809
Validation loss: 1.910780660567745

Epoch: 6| Step: 11
Training loss: 1.0286757946014404
Validation loss: 1.9260642579806748

Epoch: 6| Step: 12
Training loss: 1.0556520223617554
Validation loss: 1.891249784859278

Epoch: 6| Step: 13
Training loss: 0.515282392501831
Validation loss: 1.9128765854784238

Epoch: 380| Step: 0
Training loss: 0.610901951789856
Validation loss: 1.9551619586124216

Epoch: 6| Step: 1
Training loss: 1.3173949718475342
Validation loss: 2.0053657459956344

Epoch: 6| Step: 2
Training loss: 0.7775088548660278
Validation loss: 2.063319977893624

Epoch: 6| Step: 3
Training loss: 1.114013433456421
Validation loss: 2.070381667024346

Epoch: 6| Step: 4
Training loss: 1.0478479862213135
Validation loss: 2.0611300186444352

Epoch: 6| Step: 5
Training loss: 1.48828125
Validation loss: 2.062800545846262

Epoch: 6| Step: 6
Training loss: 1.4257292747497559
Validation loss: 1.9810583437642744

Epoch: 6| Step: 7
Training loss: 1.2523843050003052
Validation loss: 1.9420007710815759

Epoch: 6| Step: 8
Training loss: 0.9896706342697144
Validation loss: 1.9107535949317358

Epoch: 6| Step: 9
Training loss: 1.2701137065887451
Validation loss: 1.9014988535193986

Epoch: 6| Step: 10
Training loss: 0.8380380868911743
Validation loss: 1.9003036509278

Epoch: 6| Step: 11
Training loss: 0.9206936359405518
Validation loss: 1.8685382053416262

Epoch: 6| Step: 12
Training loss: 1.3441210985183716
Validation loss: 1.8631262843326857

Epoch: 6| Step: 13
Training loss: 0.5060549378395081
Validation loss: 1.8716146138406569

Epoch: 381| Step: 0
Training loss: 0.7217592000961304
Validation loss: 1.8785853424379904

Epoch: 6| Step: 1
Training loss: 1.2731146812438965
Validation loss: 1.8681412486619846

Epoch: 6| Step: 2
Training loss: 0.9735560417175293
Validation loss: 1.914255856185831

Epoch: 6| Step: 3
Training loss: 1.5176606178283691
Validation loss: 1.955042557049823

Epoch: 6| Step: 4
Training loss: 1.443037986755371
Validation loss: 1.9843479830731627

Epoch: 6| Step: 5
Training loss: 0.8434851765632629
Validation loss: 2.014944630284463

Epoch: 6| Step: 6
Training loss: 0.9262464046478271
Validation loss: 2.0385189056396484

Epoch: 6| Step: 7
Training loss: 1.0822042226791382
Validation loss: 2.021572497583205

Epoch: 6| Step: 8
Training loss: 0.4812052547931671
Validation loss: 1.9952691767805366

Epoch: 6| Step: 9
Training loss: 1.5482852458953857
Validation loss: 1.947920976146575

Epoch: 6| Step: 10
Training loss: 0.7766520977020264
Validation loss: 1.9501901647096038

Epoch: 6| Step: 11
Training loss: 0.7181471586227417
Validation loss: 1.9124669708231443

Epoch: 6| Step: 12
Training loss: 1.1828886270523071
Validation loss: 1.921232723420666

Epoch: 6| Step: 13
Training loss: 0.48297104239463806
Validation loss: 1.9054376668827508

Epoch: 382| Step: 0
Training loss: 0.6397506594657898
Validation loss: 1.9145150966541742

Epoch: 6| Step: 1
Training loss: 1.1752679347991943
Validation loss: 1.935456629722349

Epoch: 6| Step: 2
Training loss: 1.011412262916565
Validation loss: 1.9743871663206367

Epoch: 6| Step: 3
Training loss: 0.6121788024902344
Validation loss: 1.971177803572788

Epoch: 6| Step: 4
Training loss: 1.0126546621322632
Validation loss: 1.9695119088695896

Epoch: 6| Step: 5
Training loss: 1.1701246500015259
Validation loss: 2.0203306905684935

Epoch: 6| Step: 6
Training loss: 1.5229991674423218
Validation loss: 2.081433157767019

Epoch: 6| Step: 7
Training loss: 1.4313170909881592
Validation loss: 2.0701391978930404

Epoch: 6| Step: 8
Training loss: 1.5218677520751953
Validation loss: 2.0491135684392785

Epoch: 6| Step: 9
Training loss: 0.7522187232971191
Validation loss: 1.9971198522916405

Epoch: 6| Step: 10
Training loss: 0.8328232169151306
Validation loss: 1.9575576961681407

Epoch: 6| Step: 11
Training loss: 0.9371758699417114
Validation loss: 1.9191132283979846

Epoch: 6| Step: 12
Training loss: 0.7088271379470825
Validation loss: 1.897052280364498

Epoch: 6| Step: 13
Training loss: 1.672978401184082
Validation loss: 1.9021830353685605

Epoch: 383| Step: 0
Training loss: 1.4282729625701904
Validation loss: 1.87182500157305

Epoch: 6| Step: 1
Training loss: 0.9661868214607239
Validation loss: 1.8875799358531993

Epoch: 6| Step: 2
Training loss: 0.7899487018585205
Validation loss: 1.8670881589253743

Epoch: 6| Step: 3
Training loss: 1.3231759071350098
Validation loss: 1.9070648506123533

Epoch: 6| Step: 4
Training loss: 0.450137734413147
Validation loss: 1.922697086488047

Epoch: 6| Step: 5
Training loss: 0.6251604557037354
Validation loss: 1.9188668445874286

Epoch: 6| Step: 6
Training loss: 1.0395119190216064
Validation loss: 1.9726385031977007

Epoch: 6| Step: 7
Training loss: 1.8951274156570435
Validation loss: 2.021573740948913

Epoch: 6| Step: 8
Training loss: 1.0097612142562866
Validation loss: 2.0463314851125083

Epoch: 6| Step: 9
Training loss: 0.9744631052017212
Validation loss: 2.0625666367110385

Epoch: 6| Step: 10
Training loss: 0.9580086469650269
Validation loss: 2.068757067444504

Epoch: 6| Step: 11
Training loss: 0.6346172094345093
Validation loss: 2.034986058870951

Epoch: 6| Step: 12
Training loss: 1.2050480842590332
Validation loss: 1.9614494116075578

Epoch: 6| Step: 13
Training loss: 1.089332938194275
Validation loss: 1.9170897570989465

Epoch: 384| Step: 0
Training loss: 1.0989718437194824
Validation loss: 1.860186702461653

Epoch: 6| Step: 1
Training loss: 0.9174988865852356
Validation loss: 1.8640984001980032

Epoch: 6| Step: 2
Training loss: 0.863459587097168
Validation loss: 1.8665547563183693

Epoch: 6| Step: 3
Training loss: 0.9130170941352844
Validation loss: 1.8314072970421083

Epoch: 6| Step: 4
Training loss: 0.8862743377685547
Validation loss: 1.8456357294513333

Epoch: 6| Step: 5
Training loss: 1.1656323671340942
Validation loss: 1.8621183056985178

Epoch: 6| Step: 6
Training loss: 0.5826285481452942
Validation loss: 1.8828464810566237

Epoch: 6| Step: 7
Training loss: 1.0514639616012573
Validation loss: 1.9729393425808157

Epoch: 6| Step: 8
Training loss: 0.9419702291488647
Validation loss: 2.0017247187194003

Epoch: 6| Step: 9
Training loss: 1.0681980848312378
Validation loss: 2.046805771448279

Epoch: 6| Step: 10
Training loss: 1.3358150720596313
Validation loss: 1.9930249747409616

Epoch: 6| Step: 11
Training loss: 1.2187668085098267
Validation loss: 2.0001779397328696

Epoch: 6| Step: 12
Training loss: 1.711047649383545
Validation loss: 1.988510367690876

Epoch: 6| Step: 13
Training loss: 0.6600248217582703
Validation loss: 1.958000611233455

Epoch: 385| Step: 0
Training loss: 1.0763651132583618
Validation loss: 1.9725070332968107

Epoch: 6| Step: 1
Training loss: 1.1741491556167603
Validation loss: 1.9591851234436035

Epoch: 6| Step: 2
Training loss: 0.9479893445968628
Validation loss: 1.9107359301659368

Epoch: 6| Step: 3
Training loss: 0.6131708025932312
Validation loss: 1.9145701457095403

Epoch: 6| Step: 4
Training loss: 1.0167618989944458
Validation loss: 1.9090898818867181

Epoch: 6| Step: 5
Training loss: 1.363616704940796
Validation loss: 1.9153334966269873

Epoch: 6| Step: 6
Training loss: 1.2191898822784424
Validation loss: 1.9517930810169508

Epoch: 6| Step: 7
Training loss: 0.9820035696029663
Validation loss: 1.9410076128539218

Epoch: 6| Step: 8
Training loss: 1.113567590713501
Validation loss: 1.9127872695205033

Epoch: 6| Step: 9
Training loss: 0.7364513278007507
Validation loss: 1.8723598603279359

Epoch: 6| Step: 10
Training loss: 0.5124279260635376
Validation loss: 1.8915506947425105

Epoch: 6| Step: 11
Training loss: 1.2878646850585938
Validation loss: 1.8906793414905507

Epoch: 6| Step: 12
Training loss: 1.5167088508605957
Validation loss: 1.9373919181926276

Epoch: 6| Step: 13
Training loss: 1.1218770742416382
Validation loss: 1.9190245853957308

Epoch: 386| Step: 0
Training loss: 0.8715755939483643
Validation loss: 1.9523369778868973

Epoch: 6| Step: 1
Training loss: 1.1590036153793335
Validation loss: 1.980646949942394

Epoch: 6| Step: 2
Training loss: 1.0929498672485352
Validation loss: 2.0242628487207557

Epoch: 6| Step: 3
Training loss: 0.914814829826355
Validation loss: 2.0670619985108734

Epoch: 6| Step: 4
Training loss: 0.7494162321090698
Validation loss: 2.0305522052190637

Epoch: 6| Step: 5
Training loss: 0.9112802147865295
Validation loss: 2.017039756621084

Epoch: 6| Step: 6
Training loss: 0.7999462485313416
Validation loss: 1.9664757456830753

Epoch: 6| Step: 7
Training loss: 1.0815351009368896
Validation loss: 1.9018207006557013

Epoch: 6| Step: 8
Training loss: 0.7379694581031799
Validation loss: 1.9007428102595831

Epoch: 6| Step: 9
Training loss: 1.4679539203643799
Validation loss: 1.859398406039002

Epoch: 6| Step: 10
Training loss: 0.9406789541244507
Validation loss: 1.8758632572748328

Epoch: 6| Step: 11
Training loss: 1.1323180198669434
Validation loss: 1.8712572564360916

Epoch: 6| Step: 12
Training loss: 1.2455110549926758
Validation loss: 1.8763226206584642

Epoch: 6| Step: 13
Training loss: 0.6885123252868652
Validation loss: 1.9186795065479894

Epoch: 387| Step: 0
Training loss: 0.9030119180679321
Validation loss: 1.9329919430517382

Epoch: 6| Step: 1
Training loss: 1.60371994972229
Validation loss: 1.9359214107195537

Epoch: 6| Step: 2
Training loss: 1.252201795578003
Validation loss: 1.9848603471632926

Epoch: 6| Step: 3
Training loss: 1.052138328552246
Validation loss: 1.9878243836023475

Epoch: 6| Step: 4
Training loss: 0.8922251462936401
Validation loss: 2.0012321741350236

Epoch: 6| Step: 5
Training loss: 1.3813252449035645
Validation loss: 1.999798809328387

Epoch: 6| Step: 6
Training loss: 1.1156954765319824
Validation loss: 1.9859736798911967

Epoch: 6| Step: 7
Training loss: 0.40053626894950867
Validation loss: 1.9536234076305101

Epoch: 6| Step: 8
Training loss: 0.7683310508728027
Validation loss: 1.9358215908850394

Epoch: 6| Step: 9
Training loss: 0.7129059433937073
Validation loss: 1.9329717851454211

Epoch: 6| Step: 10
Training loss: 1.168956995010376
Validation loss: 1.907042275192917

Epoch: 6| Step: 11
Training loss: 0.6861633658409119
Validation loss: 1.8972903502884733

Epoch: 6| Step: 12
Training loss: 0.9672102332115173
Validation loss: 1.9150551365267845

Epoch: 6| Step: 13
Training loss: 1.294289469718933
Validation loss: 1.9261951100441717

Epoch: 388| Step: 0
Training loss: 0.736423671245575
Validation loss: 1.9614100571601623

Epoch: 6| Step: 1
Training loss: 0.8703548908233643
Validation loss: 1.9743278923855032

Epoch: 6| Step: 2
Training loss: 0.8278191089630127
Validation loss: 1.957724384082261

Epoch: 6| Step: 3
Training loss: 1.1831061840057373
Validation loss: 1.9836039132969354

Epoch: 6| Step: 4
Training loss: 0.7067258358001709
Validation loss: 1.9713508634157078

Epoch: 6| Step: 5
Training loss: 0.9260225296020508
Validation loss: 1.9478183818119827

Epoch: 6| Step: 6
Training loss: 1.380921721458435
Validation loss: 1.9624478740076865

Epoch: 6| Step: 7
Training loss: 1.0266822576522827
Validation loss: 1.9375148909066313

Epoch: 6| Step: 8
Training loss: 0.7427486181259155
Validation loss: 1.9378458415308306

Epoch: 6| Step: 9
Training loss: 1.2606903314590454
Validation loss: 1.9840386298394972

Epoch: 6| Step: 10
Training loss: 0.7648944854736328
Validation loss: 1.947745374453965

Epoch: 6| Step: 11
Training loss: 0.7379100918769836
Validation loss: 1.9796983606071883

Epoch: 6| Step: 12
Training loss: 1.0590031147003174
Validation loss: 1.9700242165596253

Epoch: 6| Step: 13
Training loss: 1.2009108066558838
Validation loss: 1.9398366289754068

Epoch: 389| Step: 0
Training loss: 0.5796685218811035
Validation loss: 1.9226439729813607

Epoch: 6| Step: 1
Training loss: 1.2307161092758179
Validation loss: 1.8840374433866112

Epoch: 6| Step: 2
Training loss: 0.860468327999115
Validation loss: 1.8545514255441644

Epoch: 6| Step: 3
Training loss: 0.8015422224998474
Validation loss: 1.8134441709005704

Epoch: 6| Step: 4
Training loss: 1.1339679956436157
Validation loss: 1.8228584963788268

Epoch: 6| Step: 5
Training loss: 0.8752166032791138
Validation loss: 1.869886403442711

Epoch: 6| Step: 6
Training loss: 1.0419028997421265
Validation loss: 1.8598528139052852

Epoch: 6| Step: 7
Training loss: 1.3240424394607544
Validation loss: 1.8858795806925783

Epoch: 6| Step: 8
Training loss: 0.9074028730392456
Validation loss: 1.9215647661557762

Epoch: 6| Step: 9
Training loss: 1.0908827781677246
Validation loss: 1.9370203812917073

Epoch: 6| Step: 10
Training loss: 1.198387861251831
Validation loss: 1.996038745808345

Epoch: 6| Step: 11
Training loss: 1.0956162214279175
Validation loss: 1.9789643902932443

Epoch: 6| Step: 12
Training loss: 0.9366815090179443
Validation loss: 1.9635586174585486

Epoch: 6| Step: 13
Training loss: 0.5717888474464417
Validation loss: 1.9496024744485014

Epoch: 390| Step: 0
Training loss: 0.873458206653595
Validation loss: 1.974365856057854

Epoch: 6| Step: 1
Training loss: 1.1984443664550781
Validation loss: 1.926102533135363

Epoch: 6| Step: 2
Training loss: 0.819015383720398
Validation loss: 1.9127411470618298

Epoch: 6| Step: 3
Training loss: 1.112870454788208
Validation loss: 1.9226177341194564

Epoch: 6| Step: 4
Training loss: 0.918182909488678
Validation loss: 1.9409213732647639

Epoch: 6| Step: 5
Training loss: 0.9208786487579346
Validation loss: 1.962274238627444

Epoch: 6| Step: 6
Training loss: 1.047486662864685
Validation loss: 1.9374806316949988

Epoch: 6| Step: 7
Training loss: 0.7136124968528748
Validation loss: 1.9672904027405607

Epoch: 6| Step: 8
Training loss: 0.9521428346633911
Validation loss: 1.9575238932845413

Epoch: 6| Step: 9
Training loss: 0.8512285351753235
Validation loss: 1.9619346049524122

Epoch: 6| Step: 10
Training loss: 1.0255495309829712
Validation loss: 1.968942431993382

Epoch: 6| Step: 11
Training loss: 1.0418893098831177
Validation loss: 1.9743828363316034

Epoch: 6| Step: 12
Training loss: 0.9030144214630127
Validation loss: 1.9792855144828878

Epoch: 6| Step: 13
Training loss: 0.7844892144203186
Validation loss: 1.9619146021463538

Epoch: 391| Step: 0
Training loss: 0.8806288242340088
Validation loss: 1.959536761365911

Epoch: 6| Step: 1
Training loss: 0.7647273540496826
Validation loss: 1.9631926154577604

Epoch: 6| Step: 2
Training loss: 0.8246757984161377
Validation loss: 1.9442222631105812

Epoch: 6| Step: 3
Training loss: 0.7634808421134949
Validation loss: 1.9318092664082844

Epoch: 6| Step: 4
Training loss: 0.7527311444282532
Validation loss: 1.9827978098264305

Epoch: 6| Step: 5
Training loss: 0.756486177444458
Validation loss: 1.9164102205666163

Epoch: 6| Step: 6
Training loss: 1.3306269645690918
Validation loss: 1.9159957503759733

Epoch: 6| Step: 7
Training loss: 1.473496437072754
Validation loss: 1.9006838567795292

Epoch: 6| Step: 8
Training loss: 0.9593788385391235
Validation loss: 1.8591377427501063

Epoch: 6| Step: 9
Training loss: 0.9517275094985962
Validation loss: 1.8807483873059672

Epoch: 6| Step: 10
Training loss: 0.9605268239974976
Validation loss: 1.8615811492807122

Epoch: 6| Step: 11
Training loss: 0.934716522693634
Validation loss: 1.8827485794662147

Epoch: 6| Step: 12
Training loss: 0.780997097492218
Validation loss: 1.8903003405499201

Epoch: 6| Step: 13
Training loss: 1.3784387111663818
Validation loss: 1.9168406084019651

Epoch: 392| Step: 0
Training loss: 0.6947852373123169
Validation loss: 1.9346953604810981

Epoch: 6| Step: 1
Training loss: 1.0637261867523193
Validation loss: 1.9226302216129918

Epoch: 6| Step: 2
Training loss: 0.6080198287963867
Validation loss: 1.9068348997382707

Epoch: 6| Step: 3
Training loss: 0.429585337638855
Validation loss: 1.8956601106992332

Epoch: 6| Step: 4
Training loss: 1.5101808309555054
Validation loss: 1.930099715468704

Epoch: 6| Step: 5
Training loss: 1.160322904586792
Validation loss: 1.9284370124980967

Epoch: 6| Step: 6
Training loss: 0.7072209119796753
Validation loss: 1.9408848183129424

Epoch: 6| Step: 7
Training loss: 0.6630281209945679
Validation loss: 1.953147788201609

Epoch: 6| Step: 8
Training loss: 0.9661537408828735
Validation loss: 1.9500612033310758

Epoch: 6| Step: 9
Training loss: 0.8312046527862549
Validation loss: 1.936226592268995

Epoch: 6| Step: 10
Training loss: 0.920079231262207
Validation loss: 1.91019102322158

Epoch: 6| Step: 11
Training loss: 1.2212656736373901
Validation loss: 1.9397887440137966

Epoch: 6| Step: 12
Training loss: 1.3189605474472046
Validation loss: 1.9423442207356936

Epoch: 6| Step: 13
Training loss: 0.8168003559112549
Validation loss: 1.9167283145330285

Epoch: 393| Step: 0
Training loss: 1.2372972965240479
Validation loss: 1.9338117607178227

Epoch: 6| Step: 1
Training loss: 0.7784520387649536
Validation loss: 1.9372224679557226

Epoch: 6| Step: 2
Training loss: 0.9021449089050293
Validation loss: 1.9596313456053376

Epoch: 6| Step: 3
Training loss: 1.0058643817901611
Validation loss: 1.9755299834794895

Epoch: 6| Step: 4
Training loss: 0.8514938354492188
Validation loss: 1.9624811064812444

Epoch: 6| Step: 5
Training loss: 0.788129985332489
Validation loss: 1.9719559197784753

Epoch: 6| Step: 6
Training loss: 0.7518929839134216
Validation loss: 1.9233311119899954

Epoch: 6| Step: 7
Training loss: 0.6040107011795044
Validation loss: 1.9688306662344164

Epoch: 6| Step: 8
Training loss: 1.2369738817214966
Validation loss: 1.9516655924499675

Epoch: 6| Step: 9
Training loss: 0.7669038772583008
Validation loss: 1.9410008204880582

Epoch: 6| Step: 10
Training loss: 1.1469388008117676
Validation loss: 1.9107435057240147

Epoch: 6| Step: 11
Training loss: 1.1376208066940308
Validation loss: 1.8557139186448948

Epoch: 6| Step: 12
Training loss: 1.2450799942016602
Validation loss: 1.8726301731601838

Epoch: 6| Step: 13
Training loss: 0.722295343875885
Validation loss: 1.88317733938976

Epoch: 394| Step: 0
Training loss: 1.0544157028198242
Validation loss: 1.9109243987708964

Epoch: 6| Step: 1
Training loss: 0.8119012117385864
Validation loss: 1.9249053193676857

Epoch: 6| Step: 2
Training loss: 0.9387212991714478
Validation loss: 1.9345064470844884

Epoch: 6| Step: 3
Training loss: 1.014906883239746
Validation loss: 1.9628760840303154

Epoch: 6| Step: 4
Training loss: 0.6919196844100952
Validation loss: 1.955163069950637

Epoch: 6| Step: 5
Training loss: 1.168801188468933
Validation loss: 1.9873126206859466

Epoch: 6| Step: 6
Training loss: 1.750244379043579
Validation loss: 2.0067209300174507

Epoch: 6| Step: 7
Training loss: 1.3890266418457031
Validation loss: 2.0223761963587936

Epoch: 6| Step: 8
Training loss: 0.7842560410499573
Validation loss: 1.9675966360235726

Epoch: 6| Step: 9
Training loss: 0.6346637010574341
Validation loss: 1.8988645717661867

Epoch: 6| Step: 10
Training loss: 0.8003495931625366
Validation loss: 1.9279604573403635

Epoch: 6| Step: 11
Training loss: 1.3775993585586548
Validation loss: 1.8683400448932443

Epoch: 6| Step: 12
Training loss: 0.872241735458374
Validation loss: 1.879253154159874

Epoch: 6| Step: 13
Training loss: 0.485890656709671
Validation loss: 1.903213680431407

Epoch: 395| Step: 0
Training loss: 1.209303855895996
Validation loss: 1.8942219570118894

Epoch: 6| Step: 1
Training loss: 0.9351977705955505
Validation loss: 1.9306368507364744

Epoch: 6| Step: 2
Training loss: 0.9807558655738831
Validation loss: 1.9747813260683449

Epoch: 6| Step: 3
Training loss: 1.1726791858673096
Validation loss: 1.965335234518974

Epoch: 6| Step: 4
Training loss: 0.5508768558502197
Validation loss: 1.9159012712458128

Epoch: 6| Step: 5
Training loss: 0.9449631571769714
Validation loss: 1.9082252492186844

Epoch: 6| Step: 6
Training loss: 0.7557695508003235
Validation loss: 1.8810920446149764

Epoch: 6| Step: 7
Training loss: 0.5796049237251282
Validation loss: 1.8801132081657328

Epoch: 6| Step: 8
Training loss: 1.02681565284729
Validation loss: 1.8697376302493516

Epoch: 6| Step: 9
Training loss: 1.309169054031372
Validation loss: 1.8691416453289729

Epoch: 6| Step: 10
Training loss: 0.7918734550476074
Validation loss: 1.8644146496249783

Epoch: 6| Step: 11
Training loss: 1.00555419921875
Validation loss: 1.9231807237030358

Epoch: 6| Step: 12
Training loss: 1.046005368232727
Validation loss: 1.9223142605955883

Epoch: 6| Step: 13
Training loss: 0.8923404216766357
Validation loss: 1.9683976801492835

Epoch: 396| Step: 0
Training loss: 0.8633306622505188
Validation loss: 1.9807538217113865

Epoch: 6| Step: 1
Training loss: 0.6896607875823975
Validation loss: 2.0170497407195387

Epoch: 6| Step: 2
Training loss: 1.0647433996200562
Validation loss: 1.9782677901688444

Epoch: 6| Step: 3
Training loss: 1.3171133995056152
Validation loss: 1.9909691015879314

Epoch: 6| Step: 4
Training loss: 1.549006462097168
Validation loss: 1.9581475668056036

Epoch: 6| Step: 5
Training loss: 0.8069308996200562
Validation loss: 1.9439949297135877

Epoch: 6| Step: 6
Training loss: 0.48687031865119934
Validation loss: 1.918583180314751

Epoch: 6| Step: 7
Training loss: 0.8852495551109314
Validation loss: 1.8993194180150186

Epoch: 6| Step: 8
Training loss: 0.8890477418899536
Validation loss: 1.914780932088052

Epoch: 6| Step: 9
Training loss: 0.9003643989562988
Validation loss: 1.9230606607211533

Epoch: 6| Step: 10
Training loss: 0.80931556224823
Validation loss: 1.9512359403794812

Epoch: 6| Step: 11
Training loss: 0.6837447285652161
Validation loss: 1.951437747606667

Epoch: 6| Step: 12
Training loss: 0.9276518821716309
Validation loss: 1.9580861471032585

Epoch: 6| Step: 13
Training loss: 1.1117796897888184
Validation loss: 1.9692418370195615

Epoch: 397| Step: 0
Training loss: 0.6815280318260193
Validation loss: 1.975595945953041

Epoch: 6| Step: 1
Training loss: 0.8364512324333191
Validation loss: 1.9623515285471433

Epoch: 6| Step: 2
Training loss: 1.1120855808258057
Validation loss: 1.9303425063369095

Epoch: 6| Step: 3
Training loss: 0.9100099205970764
Validation loss: 1.880857225387327

Epoch: 6| Step: 4
Training loss: 1.159637451171875
Validation loss: 1.9203008682497087

Epoch: 6| Step: 5
Training loss: 0.9241462349891663
Validation loss: 1.8580563119662705

Epoch: 6| Step: 6
Training loss: 0.6799956560134888
Validation loss: 1.878230192328012

Epoch: 6| Step: 7
Training loss: 0.8189650774002075
Validation loss: 1.9422379360404065

Epoch: 6| Step: 8
Training loss: 1.133603811264038
Validation loss: 1.9670830721496253

Epoch: 6| Step: 9
Training loss: 0.9226723313331604
Validation loss: 1.9782068780673447

Epoch: 6| Step: 10
Training loss: 0.7927647829055786
Validation loss: 1.9928281986585228

Epoch: 6| Step: 11
Training loss: 1.3009775876998901
Validation loss: 1.990701949724587

Epoch: 6| Step: 12
Training loss: 0.912224292755127
Validation loss: 1.9791273942557714

Epoch: 6| Step: 13
Training loss: 0.8749295473098755
Validation loss: 1.9533684266510831

Epoch: 398| Step: 0
Training loss: 1.034726858139038
Validation loss: 1.9510254975288146

Epoch: 6| Step: 1
Training loss: 1.0472897291183472
Validation loss: 1.8951492591570782

Epoch: 6| Step: 2
Training loss: 0.9667559266090393
Validation loss: 1.9055236629260484

Epoch: 6| Step: 3
Training loss: 1.0931692123413086
Validation loss: 1.9087852534427439

Epoch: 6| Step: 4
Training loss: 0.8040601015090942
Validation loss: 1.8867103079313874

Epoch: 6| Step: 5
Training loss: 0.8248343467712402
Validation loss: 1.91637223510332

Epoch: 6| Step: 6
Training loss: 0.6553794145584106
Validation loss: 1.9520228549998293

Epoch: 6| Step: 7
Training loss: 1.8131210803985596
Validation loss: 1.951196688477711

Epoch: 6| Step: 8
Training loss: 0.47049450874328613
Validation loss: 1.9656709714602398

Epoch: 6| Step: 9
Training loss: 1.2908082008361816
Validation loss: 2.0008179346720376

Epoch: 6| Step: 10
Training loss: 0.5332956314086914
Validation loss: 1.9638573303017566

Epoch: 6| Step: 11
Training loss: 0.9393052458763123
Validation loss: 1.9596766425717262

Epoch: 6| Step: 12
Training loss: 0.7363563179969788
Validation loss: 1.9963610595272434

Epoch: 6| Step: 13
Training loss: 0.8289963603019714
Validation loss: 1.9651357858411727

Epoch: 399| Step: 0
Training loss: 0.8282403945922852
Validation loss: 1.9657915843430387

Epoch: 6| Step: 1
Training loss: 0.5356929898262024
Validation loss: 1.9442456486404582

Epoch: 6| Step: 2
Training loss: 1.3781815767288208
Validation loss: 1.9213027608010076

Epoch: 6| Step: 3
Training loss: 0.5392636656761169
Validation loss: 1.936469485682826

Epoch: 6| Step: 4
Training loss: 0.812660813331604
Validation loss: 1.8913845246837986

Epoch: 6| Step: 5
Training loss: 1.480985403060913
Validation loss: 1.9412334529302453

Epoch: 6| Step: 6
Training loss: 1.2376658916473389
Validation loss: 1.9384052048447311

Epoch: 6| Step: 7
Training loss: 0.8795180320739746
Validation loss: 1.9399509173567577

Epoch: 6| Step: 8
Training loss: 0.5346695184707642
Validation loss: 1.9411084216128114

Epoch: 6| Step: 9
Training loss: 0.6807649731636047
Validation loss: 1.9383562457176946

Epoch: 6| Step: 10
Training loss: 1.158125877380371
Validation loss: 1.9980087382819063

Epoch: 6| Step: 11
Training loss: 1.2512497901916504
Validation loss: 2.0187503291714575

Epoch: 6| Step: 12
Training loss: 0.8384969830513
Validation loss: 1.9707428511752878

Epoch: 6| Step: 13
Training loss: 0.5731890201568604
Validation loss: 1.9621980779914445

Epoch: 400| Step: 0
Training loss: 0.7309475541114807
Validation loss: 1.9894423561711465

Epoch: 6| Step: 1
Training loss: 0.8175860643386841
Validation loss: 1.9644314345493112

Epoch: 6| Step: 2
Training loss: 0.9916608333587646
Validation loss: 1.9528554703599663

Epoch: 6| Step: 3
Training loss: 1.37143874168396
Validation loss: 1.9361041566377044

Epoch: 6| Step: 4
Training loss: 0.684824526309967
Validation loss: 1.8810141727488527

Epoch: 6| Step: 5
Training loss: 1.2101771831512451
Validation loss: 1.8836386421675324

Epoch: 6| Step: 6
Training loss: 0.6055634617805481
Validation loss: 1.8897446240148237

Epoch: 6| Step: 7
Training loss: 0.7234082221984863
Validation loss: 1.8632554008114723

Epoch: 6| Step: 8
Training loss: 0.6726983785629272
Validation loss: 1.8926424428980837

Epoch: 6| Step: 9
Training loss: 1.1097831726074219
Validation loss: 1.9061509383622037

Epoch: 6| Step: 10
Training loss: 0.7421351671218872
Validation loss: 1.9606969023263583

Epoch: 6| Step: 11
Training loss: 0.947849690914154
Validation loss: 1.971219370442052

Epoch: 6| Step: 12
Training loss: 1.385941743850708
Validation loss: 1.9864434888285976

Epoch: 6| Step: 13
Training loss: 0.5293629765510559
Validation loss: 1.9272052267546296

Epoch: 401| Step: 0
Training loss: 0.9059960246086121
Validation loss: 1.9150393496277511

Epoch: 6| Step: 1
Training loss: 0.9241743087768555
Validation loss: 1.8862357139587402

Epoch: 6| Step: 2
Training loss: 0.952052891254425
Validation loss: 1.8821418490461124

Epoch: 6| Step: 3
Training loss: 1.3536911010742188
Validation loss: 1.8757519901439708

Epoch: 6| Step: 4
Training loss: 1.0286431312561035
Validation loss: 1.892370448317579

Epoch: 6| Step: 5
Training loss: 0.636153519153595
Validation loss: 1.8540248178666638

Epoch: 6| Step: 6
Training loss: 0.991500735282898
Validation loss: 1.8408259743003434

Epoch: 6| Step: 7
Training loss: 0.48217862844467163
Validation loss: 1.9060854732349355

Epoch: 6| Step: 8
Training loss: 0.6541832685470581
Validation loss: 1.9322161289953417

Epoch: 6| Step: 9
Training loss: 1.222916603088379
Validation loss: 1.9931093159542288

Epoch: 6| Step: 10
Training loss: 1.2093230485916138
Validation loss: 1.9981743122941704

Epoch: 6| Step: 11
Training loss: 1.0098005533218384
Validation loss: 2.0311245277363765

Epoch: 6| Step: 12
Training loss: 0.8684723973274231
Validation loss: 2.025209349970664

Epoch: 6| Step: 13
Training loss: 0.6533524990081787
Validation loss: 1.971400084034089

Epoch: 402| Step: 0
Training loss: 0.8235266208648682
Validation loss: 1.9309854481809883

Epoch: 6| Step: 1
Training loss: 0.8792046308517456
Validation loss: 1.9132824354274298

Epoch: 6| Step: 2
Training loss: 0.4631490409374237
Validation loss: 1.8805458007320281

Epoch: 6| Step: 3
Training loss: 1.1648941040039062
Validation loss: 1.861446924107049

Epoch: 6| Step: 4
Training loss: 1.1429221630096436
Validation loss: 1.8924323410116217

Epoch: 6| Step: 5
Training loss: 0.6722980737686157
Validation loss: 1.8792550615085069

Epoch: 6| Step: 6
Training loss: 0.8768806457519531
Validation loss: 1.8915793613720966

Epoch: 6| Step: 7
Training loss: 0.7170279026031494
Validation loss: 1.8928714106159825

Epoch: 6| Step: 8
Training loss: 1.602508306503296
Validation loss: 1.9157524954888128

Epoch: 6| Step: 9
Training loss: 0.6799774765968323
Validation loss: 1.9139304378981232

Epoch: 6| Step: 10
Training loss: 0.9492650628089905
Validation loss: 1.9278017346576979

Epoch: 6| Step: 11
Training loss: 0.8314974308013916
Validation loss: 1.93287230050692

Epoch: 6| Step: 12
Training loss: 1.0360075235366821
Validation loss: 1.9337074936077159

Epoch: 6| Step: 13
Training loss: 1.028147578239441
Validation loss: 1.9383417816572293

Epoch: 403| Step: 0
Training loss: 1.1294605731964111
Validation loss: 1.9504908438651793

Epoch: 6| Step: 1
Training loss: 1.1404435634613037
Validation loss: 1.9713394872603878

Epoch: 6| Step: 2
Training loss: 0.8108377456665039
Validation loss: 1.9709414102697884

Epoch: 6| Step: 3
Training loss: 1.047052264213562
Validation loss: 1.9797140385514946

Epoch: 6| Step: 4
Training loss: 0.8935039043426514
Validation loss: 1.931212866178123

Epoch: 6| Step: 5
Training loss: 0.7238427400588989
Validation loss: 1.9578177147014166

Epoch: 6| Step: 6
Training loss: 1.0192744731903076
Validation loss: 1.9593641181145944

Epoch: 6| Step: 7
Training loss: 0.9956804513931274
Validation loss: 1.9492040449573147

Epoch: 6| Step: 8
Training loss: 1.1003799438476562
Validation loss: 1.9240640171112553

Epoch: 6| Step: 9
Training loss: 0.5816732048988342
Validation loss: 1.9101413116660169

Epoch: 6| Step: 10
Training loss: 0.8554027080535889
Validation loss: 1.9139805993726176

Epoch: 6| Step: 11
Training loss: 0.692578911781311
Validation loss: 1.8878953162059988

Epoch: 6| Step: 12
Training loss: 0.913003146648407
Validation loss: 1.8809604375593123

Epoch: 6| Step: 13
Training loss: 0.7781042456626892
Validation loss: 1.9060888341678086

Epoch: 404| Step: 0
Training loss: 1.1383724212646484
Validation loss: 1.8987750660988592

Epoch: 6| Step: 1
Training loss: 0.7246989607810974
Validation loss: 1.9020561146479782

Epoch: 6| Step: 2
Training loss: 0.6142197847366333
Validation loss: 1.941074864838713

Epoch: 6| Step: 3
Training loss: 0.609074056148529
Validation loss: 1.955866200949556

Epoch: 6| Step: 4
Training loss: 0.6855165362358093
Validation loss: 1.9655219970210906

Epoch: 6| Step: 5
Training loss: 1.7575188875198364
Validation loss: 1.9557388572282688

Epoch: 6| Step: 6
Training loss: 1.1843777894973755
Validation loss: 1.9598159482402187

Epoch: 6| Step: 7
Training loss: 0.767011284828186
Validation loss: 1.9848905135226507

Epoch: 6| Step: 8
Training loss: 0.5323232412338257
Validation loss: 1.9729279600163943

Epoch: 6| Step: 9
Training loss: 0.5092375874519348
Validation loss: 1.9363808067896033

Epoch: 6| Step: 10
Training loss: 0.592013955116272
Validation loss: 1.9082808186930995

Epoch: 6| Step: 11
Training loss: 1.0351674556732178
Validation loss: 1.9342479667355936

Epoch: 6| Step: 12
Training loss: 0.8071739077568054
Validation loss: 1.9346941530063588

Epoch: 6| Step: 13
Training loss: 1.9304711818695068
Validation loss: 1.8763687815717471

Epoch: 405| Step: 0
Training loss: 0.5049173831939697
Validation loss: 1.8826815902545888

Epoch: 6| Step: 1
Training loss: 0.3703078031539917
Validation loss: 1.8793584736444617

Epoch: 6| Step: 2
Training loss: 0.4593982696533203
Validation loss: 1.8834579567755423

Epoch: 6| Step: 3
Training loss: 0.5540493726730347
Validation loss: 1.9014490407000306

Epoch: 6| Step: 4
Training loss: 1.7334537506103516
Validation loss: 1.9073067544608988

Epoch: 6| Step: 5
Training loss: 1.0673397779464722
Validation loss: 1.943438035185619

Epoch: 6| Step: 6
Training loss: 1.1108574867248535
Validation loss: 1.9208131746579242

Epoch: 6| Step: 7
Training loss: 1.3185722827911377
Validation loss: 1.9010968951768772

Epoch: 6| Step: 8
Training loss: 0.6233401298522949
Validation loss: 1.8789579086406256

Epoch: 6| Step: 9
Training loss: 1.1195651292800903
Validation loss: 1.9263868178090742

Epoch: 6| Step: 10
Training loss: 0.9423718452453613
Validation loss: 1.898944103589622

Epoch: 6| Step: 11
Training loss: 0.6035354733467102
Validation loss: 1.9052300773641115

Epoch: 6| Step: 12
Training loss: 0.7582327127456665
Validation loss: 1.9380847843744422

Epoch: 6| Step: 13
Training loss: 0.8063594698905945
Validation loss: 1.919348955154419

Epoch: 406| Step: 0
Training loss: 0.6919445991516113
Validation loss: 1.9430253172433505

Epoch: 6| Step: 1
Training loss: 0.6427859663963318
Validation loss: 1.9737174536592217

Epoch: 6| Step: 2
Training loss: 0.9310387969017029
Validation loss: 1.9390856694149714

Epoch: 6| Step: 3
Training loss: 0.9509798288345337
Validation loss: 1.918043246833227

Epoch: 6| Step: 4
Training loss: 0.7433904409408569
Validation loss: 1.927273811832551

Epoch: 6| Step: 5
Training loss: 0.8217561841011047
Validation loss: 1.929372569566132

Epoch: 6| Step: 6
Training loss: 0.6653074026107788
Validation loss: 1.9180463385838333

Epoch: 6| Step: 7
Training loss: 1.2739781141281128
Validation loss: 1.9098279860711866

Epoch: 6| Step: 8
Training loss: 0.6656996011734009
Validation loss: 1.8890745703892042

Epoch: 6| Step: 9
Training loss: 1.0693187713623047
Validation loss: 1.8973765142502323

Epoch: 6| Step: 10
Training loss: 1.1796741485595703
Validation loss: 1.825702941545876

Epoch: 6| Step: 11
Training loss: 0.699729859828949
Validation loss: 1.8573218955788562

Epoch: 6| Step: 12
Training loss: 0.9250742793083191
Validation loss: 1.8403954698193459

Epoch: 6| Step: 13
Training loss: 0.558795154094696
Validation loss: 1.856095290312203

Epoch: 407| Step: 0
Training loss: 0.44133827090263367
Validation loss: 1.8695922846435218

Epoch: 6| Step: 1
Training loss: 0.6428852081298828
Validation loss: 1.862761269333542

Epoch: 6| Step: 2
Training loss: 1.1188268661499023
Validation loss: 1.8760502556318879

Epoch: 6| Step: 3
Training loss: 0.7021527886390686
Validation loss: 1.9159400181103778

Epoch: 6| Step: 4
Training loss: 0.7948458194732666
Validation loss: 1.8969446959034089

Epoch: 6| Step: 5
Training loss: 0.8744112253189087
Validation loss: 1.9068830090184365

Epoch: 6| Step: 6
Training loss: 0.8309314250946045
Validation loss: 1.902931426161079

Epoch: 6| Step: 7
Training loss: 0.9752851724624634
Validation loss: 1.9058940179886357

Epoch: 6| Step: 8
Training loss: 0.7850802540779114
Validation loss: 1.9111754432801278

Epoch: 6| Step: 9
Training loss: 1.0971393585205078
Validation loss: 1.9454787892680014

Epoch: 6| Step: 10
Training loss: 0.8111242651939392
Validation loss: 1.9227901863795456

Epoch: 6| Step: 11
Training loss: 0.9316972494125366
Validation loss: 1.9224175407040505

Epoch: 6| Step: 12
Training loss: 1.0721843242645264
Validation loss: 1.9167281607145905

Epoch: 6| Step: 13
Training loss: 1.3664932250976562
Validation loss: 1.8702858968447613

Epoch: 408| Step: 0
Training loss: 0.7657109498977661
Validation loss: 1.8965525332317557

Epoch: 6| Step: 1
Training loss: 1.2674071788787842
Validation loss: 1.883920656737461

Epoch: 6| Step: 2
Training loss: 0.8330488204956055
Validation loss: 1.877700637745601

Epoch: 6| Step: 3
Training loss: 0.8274577260017395
Validation loss: 1.9242803242898756

Epoch: 6| Step: 4
Training loss: 0.9901697635650635
Validation loss: 1.8723587297624158

Epoch: 6| Step: 5
Training loss: 1.0368647575378418
Validation loss: 1.9251848010606663

Epoch: 6| Step: 6
Training loss: 0.5012530088424683
Validation loss: 1.929725452135968

Epoch: 6| Step: 7
Training loss: 0.9867870807647705
Validation loss: 1.9403348379237677

Epoch: 6| Step: 8
Training loss: 0.9464096426963806
Validation loss: 1.9168778722004225

Epoch: 6| Step: 9
Training loss: 0.5764458179473877
Validation loss: 1.9494662169487245

Epoch: 6| Step: 10
Training loss: 1.1748466491699219
Validation loss: 1.930070298974232

Epoch: 6| Step: 11
Training loss: 0.49576982855796814
Validation loss: 1.9454524799059796

Epoch: 6| Step: 12
Training loss: 0.5384629368782043
Validation loss: 1.9465448035988757

Epoch: 6| Step: 13
Training loss: 1.3368734121322632
Validation loss: 1.9538372421777377

Epoch: 409| Step: 0
Training loss: 0.8690518736839294
Validation loss: 1.9363685730964906

Epoch: 6| Step: 1
Training loss: 0.45224660634994507
Validation loss: 1.932778323850324

Epoch: 6| Step: 2
Training loss: 0.9521926641464233
Validation loss: 1.9287107811179212

Epoch: 6| Step: 3
Training loss: 0.7581123113632202
Validation loss: 1.920909845700828

Epoch: 6| Step: 4
Training loss: 0.8979613184928894
Validation loss: 1.9023497143099386

Epoch: 6| Step: 5
Training loss: 0.7881326675415039
Validation loss: 1.922772599804786

Epoch: 6| Step: 6
Training loss: 0.23015955090522766
Validation loss: 1.8782256521204466

Epoch: 6| Step: 7
Training loss: 1.001018762588501
Validation loss: 1.9173293805891467

Epoch: 6| Step: 8
Training loss: 1.2321722507476807
Validation loss: 1.9246265349849578

Epoch: 6| Step: 9
Training loss: 0.9407228827476501
Validation loss: 1.9412971158181467

Epoch: 6| Step: 10
Training loss: 1.2930359840393066
Validation loss: 1.9196484063261299

Epoch: 6| Step: 11
Training loss: 0.7212689518928528
Validation loss: 1.9382279790857786

Epoch: 6| Step: 12
Training loss: 0.6654616594314575
Validation loss: 1.9028217465646806

Epoch: 6| Step: 13
Training loss: 1.0352072715759277
Validation loss: 1.9547888258452057

Epoch: 410| Step: 0
Training loss: 1.032167673110962
Validation loss: 1.9542251568968578

Epoch: 6| Step: 1
Training loss: 1.0035231113433838
Validation loss: 1.9564564279330674

Epoch: 6| Step: 2
Training loss: 0.9171316623687744
Validation loss: 1.9210541068866689

Epoch: 6| Step: 3
Training loss: 0.5326318740844727
Validation loss: 1.919884809883692

Epoch: 6| Step: 4
Training loss: 0.4758407771587372
Validation loss: 1.875865460723959

Epoch: 6| Step: 5
Training loss: 0.7182657718658447
Validation loss: 1.879352113252045

Epoch: 6| Step: 6
Training loss: 0.5894137620925903
Validation loss: 1.8640925627882763

Epoch: 6| Step: 7
Training loss: 1.190624475479126
Validation loss: 1.8444584133804485

Epoch: 6| Step: 8
Training loss: 0.8494241833686829
Validation loss: 1.8524220963960052

Epoch: 6| Step: 9
Training loss: 1.3538753986358643
Validation loss: 1.8354139494639572

Epoch: 6| Step: 10
Training loss: 0.9082090258598328
Validation loss: 1.8355122894369147

Epoch: 6| Step: 11
Training loss: 1.387804627418518
Validation loss: 1.8500298710279568

Epoch: 6| Step: 12
Training loss: 0.6750510334968567
Validation loss: 1.8932377907537645

Epoch: 6| Step: 13
Training loss: 0.43524789810180664
Validation loss: 1.9120664545284805

Epoch: 411| Step: 0
Training loss: 1.2331328392028809
Validation loss: 1.9560861074796287

Epoch: 6| Step: 1
Training loss: 1.2429735660552979
Validation loss: 1.9689328080864363

Epoch: 6| Step: 2
Training loss: 0.910603940486908
Validation loss: 1.9998264620381017

Epoch: 6| Step: 3
Training loss: 0.6960533857345581
Validation loss: 1.951780926796698

Epoch: 6| Step: 4
Training loss: 0.5784741640090942
Validation loss: 1.939055222336964

Epoch: 6| Step: 5
Training loss: 0.4254707098007202
Validation loss: 1.9440739564998175

Epoch: 6| Step: 6
Training loss: 0.6741009950637817
Validation loss: 1.899250853446222

Epoch: 6| Step: 7
Training loss: 0.7029062509536743
Validation loss: 1.8792506853739421

Epoch: 6| Step: 8
Training loss: 0.9651062488555908
Validation loss: 1.8777432262256581

Epoch: 6| Step: 9
Training loss: 1.0087089538574219
Validation loss: 1.84937043856549

Epoch: 6| Step: 10
Training loss: 1.069772481918335
Validation loss: 1.87033478418986

Epoch: 6| Step: 11
Training loss: 0.7464132308959961
Validation loss: 1.8785188185271395

Epoch: 6| Step: 12
Training loss: 1.0177693367004395
Validation loss: 1.886637403118995

Epoch: 6| Step: 13
Training loss: 0.6431244015693665
Validation loss: 1.928236041017758

Epoch: 412| Step: 0
Training loss: 0.7163738012313843
Validation loss: 1.9722473826459659

Epoch: 6| Step: 1
Training loss: 0.6154915690422058
Validation loss: 1.9687093380958802

Epoch: 6| Step: 2
Training loss: 1.1616227626800537
Validation loss: 1.9660507940476941

Epoch: 6| Step: 3
Training loss: 0.85233473777771
Validation loss: 1.9802097543593375

Epoch: 6| Step: 4
Training loss: 1.023665189743042
Validation loss: 1.978912470161274

Epoch: 6| Step: 5
Training loss: 1.2688422203063965
Validation loss: 2.0014307024658367

Epoch: 6| Step: 6
Training loss: 0.6623244285583496
Validation loss: 2.0243565792678506

Epoch: 6| Step: 7
Training loss: 0.7604088187217712
Validation loss: 1.9584742233317385

Epoch: 6| Step: 8
Training loss: 0.31601130962371826
Validation loss: 1.9425097127114572

Epoch: 6| Step: 9
Training loss: 1.1027113199234009
Validation loss: 1.9533263765355593

Epoch: 6| Step: 10
Training loss: 1.0004315376281738
Validation loss: 1.9083720253359886

Epoch: 6| Step: 11
Training loss: 0.6327370405197144
Validation loss: 1.9033176693865048

Epoch: 6| Step: 12
Training loss: 0.8954588174819946
Validation loss: 1.895572244480092

Epoch: 6| Step: 13
Training loss: 0.5733324885368347
Validation loss: 1.8819451280819472

Epoch: 413| Step: 0
Training loss: 1.0493147373199463
Validation loss: 1.8851558123865435

Epoch: 6| Step: 1
Training loss: 1.080090045928955
Validation loss: 1.8837910775215394

Epoch: 6| Step: 2
Training loss: 0.43766868114471436
Validation loss: 1.8506182239901634

Epoch: 6| Step: 3
Training loss: 1.04130220413208
Validation loss: 1.9233529618991319

Epoch: 6| Step: 4
Training loss: 0.6284142136573792
Validation loss: 1.913910952947473

Epoch: 6| Step: 5
Training loss: 0.5597139000892639
Validation loss: 1.9394876777484853

Epoch: 6| Step: 6
Training loss: 0.9339127540588379
Validation loss: 1.9559444765890799

Epoch: 6| Step: 7
Training loss: 1.5087413787841797
Validation loss: 1.9402748051510061

Epoch: 6| Step: 8
Training loss: 0.8942322731018066
Validation loss: 1.9216369518669703

Epoch: 6| Step: 9
Training loss: 0.5311428904533386
Validation loss: 1.9481767903092087

Epoch: 6| Step: 10
Training loss: 0.5434679985046387
Validation loss: 1.889475772457738

Epoch: 6| Step: 11
Training loss: 1.060971736907959
Validation loss: 1.8824792702992756

Epoch: 6| Step: 12
Training loss: 0.5841735601425171
Validation loss: 1.8617935488300938

Epoch: 6| Step: 13
Training loss: 0.7028450965881348
Validation loss: 1.8840657280337425

Epoch: 414| Step: 0
Training loss: 0.7832263708114624
Validation loss: 1.8787145896624493

Epoch: 6| Step: 1
Training loss: 0.8901136517524719
Validation loss: 1.9174973336599206

Epoch: 6| Step: 2
Training loss: 0.9738956093788147
Validation loss: 1.9143877798511135

Epoch: 6| Step: 3
Training loss: 1.0803017616271973
Validation loss: 1.8853562390932472

Epoch: 6| Step: 4
Training loss: 1.0287151336669922
Validation loss: 1.957416936915408

Epoch: 6| Step: 5
Training loss: 0.7297284603118896
Validation loss: 1.9886641733108028

Epoch: 6| Step: 6
Training loss: 0.7764054536819458
Validation loss: 1.9643054623757639

Epoch: 6| Step: 7
Training loss: 0.5094244480133057
Validation loss: 1.94601744990195

Epoch: 6| Step: 8
Training loss: 0.48006105422973633
Validation loss: 1.9800069626941477

Epoch: 6| Step: 9
Training loss: 1.1515755653381348
Validation loss: 1.9407075758903258

Epoch: 6| Step: 10
Training loss: 0.8686240911483765
Validation loss: 1.8904258051226217

Epoch: 6| Step: 11
Training loss: 0.5363186597824097
Validation loss: 1.9149100113940496

Epoch: 6| Step: 12
Training loss: 0.8910788297653198
Validation loss: 1.8887860646811865

Epoch: 6| Step: 13
Training loss: 0.7991209626197815
Validation loss: 1.9073657681865077

Epoch: 415| Step: 0
Training loss: 0.8167527318000793
Validation loss: 1.8661582508394796

Epoch: 6| Step: 1
Training loss: 1.245194673538208
Validation loss: 1.852908927907226

Epoch: 6| Step: 2
Training loss: 0.3724859952926636
Validation loss: 1.8465258113799556

Epoch: 6| Step: 3
Training loss: 0.8228621482849121
Validation loss: 1.89769745385775

Epoch: 6| Step: 4
Training loss: 0.401069700717926
Validation loss: 1.888739837113247

Epoch: 6| Step: 5
Training loss: 1.0735317468643188
Validation loss: 1.8713601737894037

Epoch: 6| Step: 6
Training loss: 0.7896262407302856
Validation loss: 1.8935889556843748

Epoch: 6| Step: 7
Training loss: 0.6315595507621765
Validation loss: 1.8893199966799827

Epoch: 6| Step: 8
Training loss: 0.9358927011489868
Validation loss: 1.8882036644925353

Epoch: 6| Step: 9
Training loss: 1.1601001024246216
Validation loss: 1.9032158787532518

Epoch: 6| Step: 10
Training loss: 1.0831966400146484
Validation loss: 1.9349927325402536

Epoch: 6| Step: 11
Training loss: 0.8061314821243286
Validation loss: 1.9730445223469888

Epoch: 6| Step: 12
Training loss: 0.701405942440033
Validation loss: 1.985505901357179

Epoch: 6| Step: 13
Training loss: 1.2062644958496094
Validation loss: 1.9740674444424209

Epoch: 416| Step: 0
Training loss: 0.838215708732605
Validation loss: 1.9370740216265443

Epoch: 6| Step: 1
Training loss: 1.1646101474761963
Validation loss: 1.901490044850175

Epoch: 6| Step: 2
Training loss: 0.7429888844490051
Validation loss: 1.9341052257886497

Epoch: 6| Step: 3
Training loss: 0.9438570737838745
Validation loss: 1.9400936583037018

Epoch: 6| Step: 4
Training loss: 0.8911294937133789
Validation loss: 1.9371348375915198

Epoch: 6| Step: 5
Training loss: 1.1564840078353882
Validation loss: 1.8880191977306078

Epoch: 6| Step: 6
Training loss: 0.8576757311820984
Validation loss: 1.8552192577751734

Epoch: 6| Step: 7
Training loss: 0.6472092270851135
Validation loss: 1.8333007315153718

Epoch: 6| Step: 8
Training loss: 0.8779551982879639
Validation loss: 1.873268832442581

Epoch: 6| Step: 9
Training loss: 0.8559725284576416
Validation loss: 1.9387876295274304

Epoch: 6| Step: 10
Training loss: 0.7822301983833313
Validation loss: 1.9183506581091112

Epoch: 6| Step: 11
Training loss: 0.9725427627563477
Validation loss: 1.967225798996546

Epoch: 6| Step: 12
Training loss: 0.7942461967468262
Validation loss: 2.0002974002592024

Epoch: 6| Step: 13
Training loss: 0.9223160147666931
Validation loss: 2.0146153011629657

Epoch: 417| Step: 0
Training loss: 0.6663298606872559
Validation loss: 2.0049004836749007

Epoch: 6| Step: 1
Training loss: 1.0687934160232544
Validation loss: 2.000003904424688

Epoch: 6| Step: 2
Training loss: 0.6290106177330017
Validation loss: 1.9653955223739787

Epoch: 6| Step: 3
Training loss: 0.8577742576599121
Validation loss: 1.921641626665669

Epoch: 6| Step: 4
Training loss: 0.44464170932769775
Validation loss: 1.8892247805031397

Epoch: 6| Step: 5
Training loss: 1.1178257465362549
Validation loss: 1.852716503604766

Epoch: 6| Step: 6
Training loss: 0.4450424313545227
Validation loss: 1.8374625386730317

Epoch: 6| Step: 7
Training loss: 0.996028482913971
Validation loss: 1.8378464124536003

Epoch: 6| Step: 8
Training loss: 0.9891454577445984
Validation loss: 1.8267935757995934

Epoch: 6| Step: 9
Training loss: 0.8358293771743774
Validation loss: 1.8242904806649813

Epoch: 6| Step: 10
Training loss: 0.8573625683784485
Validation loss: 1.8607618411382039

Epoch: 6| Step: 11
Training loss: 1.325446605682373
Validation loss: 1.861784481233166

Epoch: 6| Step: 12
Training loss: 0.8640537858009338
Validation loss: 1.8871368156966342

Epoch: 6| Step: 13
Training loss: 0.4576065242290497
Validation loss: 1.9235435006439046

Epoch: 418| Step: 0
Training loss: 0.8102647662162781
Validation loss: 1.933801028036302

Epoch: 6| Step: 1
Training loss: 0.6807489395141602
Validation loss: 1.9434591390753304

Epoch: 6| Step: 2
Training loss: 0.5807287096977234
Validation loss: 1.937599616665994

Epoch: 6| Step: 3
Training loss: 0.7352988123893738
Validation loss: 1.9348900241236533

Epoch: 6| Step: 4
Training loss: 0.3813576102256775
Validation loss: 1.8756241952219317

Epoch: 6| Step: 5
Training loss: 0.7741262912750244
Validation loss: 1.8567412309749152

Epoch: 6| Step: 6
Training loss: 1.3483352661132812
Validation loss: 1.8558582631490563

Epoch: 6| Step: 7
Training loss: 0.6829228401184082
Validation loss: 1.8654271556485085

Epoch: 6| Step: 8
Training loss: 0.9352637529373169
Validation loss: 1.8785493681507726

Epoch: 6| Step: 9
Training loss: 1.0382319688796997
Validation loss: 1.8705452898497223

Epoch: 6| Step: 10
Training loss: 0.5686895847320557
Validation loss: 1.8810904718214465

Epoch: 6| Step: 11
Training loss: 0.9954757690429688
Validation loss: 1.8742503786599765

Epoch: 6| Step: 12
Training loss: 0.992828905582428
Validation loss: 1.9235778508647796

Epoch: 6| Step: 13
Training loss: 0.8912298679351807
Validation loss: 1.9315885420768493

Epoch: 419| Step: 0
Training loss: 0.6527975797653198
Validation loss: 1.9672383300719722

Epoch: 6| Step: 1
Training loss: 0.6045850515365601
Validation loss: 1.9564031657352243

Epoch: 6| Step: 2
Training loss: 0.6675177812576294
Validation loss: 1.965769680597449

Epoch: 6| Step: 3
Training loss: 1.019390344619751
Validation loss: 1.9315938359947615

Epoch: 6| Step: 4
Training loss: 0.9209483861923218
Validation loss: 1.8767757813135784

Epoch: 6| Step: 5
Training loss: 1.0462040901184082
Validation loss: 1.8886200035772016

Epoch: 6| Step: 6
Training loss: 0.4948279559612274
Validation loss: 1.8795542076069822

Epoch: 6| Step: 7
Training loss: 0.8621034026145935
Validation loss: 1.8950349105301725

Epoch: 6| Step: 8
Training loss: 0.8792284727096558
Validation loss: 1.8909198827640985

Epoch: 6| Step: 9
Training loss: 1.0596266984939575
Validation loss: 1.868004528425073

Epoch: 6| Step: 10
Training loss: 0.42274904251098633
Validation loss: 1.8694226318790066

Epoch: 6| Step: 11
Training loss: 0.8785015344619751
Validation loss: 1.8853507452113654

Epoch: 6| Step: 12
Training loss: 0.5367543697357178
Validation loss: 1.8956245030126264

Epoch: 6| Step: 13
Training loss: 1.137555480003357
Validation loss: 1.9159835974375408

Epoch: 420| Step: 0
Training loss: 0.7014719843864441
Validation loss: 1.9245860525356826

Epoch: 6| Step: 1
Training loss: 0.8640683889389038
Validation loss: 1.9470424344462733

Epoch: 6| Step: 2
Training loss: 0.290982723236084
Validation loss: 1.9531537102114769

Epoch: 6| Step: 3
Training loss: 0.7499535083770752
Validation loss: 1.8975040553718485

Epoch: 6| Step: 4
Training loss: 0.7386966943740845
Validation loss: 1.8910630954209195

Epoch: 6| Step: 5
Training loss: 1.1589455604553223
Validation loss: 1.8789474835959814

Epoch: 6| Step: 6
Training loss: 0.8273671865463257
Validation loss: 1.881282861514758

Epoch: 6| Step: 7
Training loss: 0.8453660607337952
Validation loss: 1.843283769264016

Epoch: 6| Step: 8
Training loss: 1.0918166637420654
Validation loss: 1.86150021706858

Epoch: 6| Step: 9
Training loss: 0.9261452555656433
Validation loss: 1.8716098159872077

Epoch: 6| Step: 10
Training loss: 0.4134547710418701
Validation loss: 1.8913943947002452

Epoch: 6| Step: 11
Training loss: 0.5941152572631836
Validation loss: 1.9230811390825497

Epoch: 6| Step: 12
Training loss: 1.0722613334655762
Validation loss: 1.9179321437753656

Epoch: 6| Step: 13
Training loss: 0.7339932322502136
Validation loss: 1.9314744767322336

Epoch: 421| Step: 0
Training loss: 0.962481677532196
Validation loss: 1.9118697386915966

Epoch: 6| Step: 1
Training loss: 0.6991862654685974
Validation loss: 1.8986733895476147

Epoch: 6| Step: 2
Training loss: 0.4594072699546814
Validation loss: 1.9045077485422934

Epoch: 6| Step: 3
Training loss: 0.8799694776535034
Validation loss: 1.8959340587739022

Epoch: 6| Step: 4
Training loss: 0.38979265093803406
Validation loss: 1.8736126961246613

Epoch: 6| Step: 5
Training loss: 0.7064816355705261
Validation loss: 1.8709141515916394

Epoch: 6| Step: 6
Training loss: 0.7179955244064331
Validation loss: 1.892901356502246

Epoch: 6| Step: 7
Training loss: 0.43722695112228394
Validation loss: 1.9245684762154855

Epoch: 6| Step: 8
Training loss: 1.0668766498565674
Validation loss: 1.9381296955129153

Epoch: 6| Step: 9
Training loss: 1.048137903213501
Validation loss: 1.9522686466093986

Epoch: 6| Step: 10
Training loss: 0.9874346256256104
Validation loss: 1.9177197692214802

Epoch: 6| Step: 11
Training loss: 0.8395031690597534
Validation loss: 1.9182128367885467

Epoch: 6| Step: 12
Training loss: 0.542943000793457
Validation loss: 1.9125076019635765

Epoch: 6| Step: 13
Training loss: 1.5290160179138184
Validation loss: 1.934969731556472

Epoch: 422| Step: 0
Training loss: 0.8991057276725769
Validation loss: 1.9365788480286956

Epoch: 6| Step: 1
Training loss: 0.5402644872665405
Validation loss: 1.9306080149066063

Epoch: 6| Step: 2
Training loss: 0.7451080083847046
Validation loss: 1.9383308990027315

Epoch: 6| Step: 3
Training loss: 0.43692851066589355
Validation loss: 1.9228329197052987

Epoch: 6| Step: 4
Training loss: 0.46941471099853516
Validation loss: 1.9341710921256774

Epoch: 6| Step: 5
Training loss: 0.9823668599128723
Validation loss: 1.8406031016380555

Epoch: 6| Step: 6
Training loss: 0.9738028645515442
Validation loss: 1.868138974712741

Epoch: 6| Step: 7
Training loss: 1.3071976900100708
Validation loss: 1.8769657368301063

Epoch: 6| Step: 8
Training loss: 0.8669614791870117
Validation loss: 1.849923728614725

Epoch: 6| Step: 9
Training loss: 0.8586083650588989
Validation loss: 1.8240861815790976

Epoch: 6| Step: 10
Training loss: 0.8295519351959229
Validation loss: 1.8294384043703797

Epoch: 6| Step: 11
Training loss: 0.6378827095031738
Validation loss: 1.8696403054780857

Epoch: 6| Step: 12
Training loss: 0.9417500495910645
Validation loss: 1.890091230792384

Epoch: 6| Step: 13
Training loss: 0.399038702249527
Validation loss: 1.9313487673318515

Epoch: 423| Step: 0
Training loss: 0.6467442512512207
Validation loss: 1.9601459964629142

Epoch: 6| Step: 1
Training loss: 0.8050433993339539
Validation loss: 1.9681063262365197

Epoch: 6| Step: 2
Training loss: 0.6005843877792358
Validation loss: 1.9463246458320207

Epoch: 6| Step: 3
Training loss: 0.616620659828186
Validation loss: 1.9571664102615849

Epoch: 6| Step: 4
Training loss: 1.0839183330535889
Validation loss: 1.9044958724770495

Epoch: 6| Step: 5
Training loss: 0.7722019553184509
Validation loss: 1.8668538626804148

Epoch: 6| Step: 6
Training loss: 1.059559941291809
Validation loss: 1.9155819774955831

Epoch: 6| Step: 7
Training loss: 0.6395885348320007
Validation loss: 1.8919432009420087

Epoch: 6| Step: 8
Training loss: 0.6098389029502869
Validation loss: 1.8499553818856516

Epoch: 6| Step: 9
Training loss: 1.0988928079605103
Validation loss: 1.8695006870454358

Epoch: 6| Step: 10
Training loss: 0.35620367527008057
Validation loss: 1.8396006809767855

Epoch: 6| Step: 11
Training loss: 0.9112817049026489
Validation loss: 1.8690611649585027

Epoch: 6| Step: 12
Training loss: 1.2255463600158691
Validation loss: 1.8983293707652757

Epoch: 6| Step: 13
Training loss: 0.37244436144828796
Validation loss: 1.954753122022075

Epoch: 424| Step: 0
Training loss: 0.6968445777893066
Validation loss: 1.8998700482870943

Epoch: 6| Step: 1
Training loss: 0.5898265242576599
Validation loss: 1.8665773125105007

Epoch: 6| Step: 2
Training loss: 0.6154177188873291
Validation loss: 1.8051993385437997

Epoch: 6| Step: 3
Training loss: 1.0613160133361816
Validation loss: 1.8048842389096496

Epoch: 6| Step: 4
Training loss: 0.9846317768096924
Validation loss: 1.8224680269918134

Epoch: 6| Step: 5
Training loss: 0.8849343061447144
Validation loss: 1.8306560413811797

Epoch: 6| Step: 6
Training loss: 0.671248733997345
Validation loss: 1.866030757145215

Epoch: 6| Step: 7
Training loss: 1.3173446655273438
Validation loss: 1.8637923027879448

Epoch: 6| Step: 8
Training loss: 0.8502151370048523
Validation loss: 1.8837678496555617

Epoch: 6| Step: 9
Training loss: 0.7916563749313354
Validation loss: 1.9641436646061559

Epoch: 6| Step: 10
Training loss: 0.4398263692855835
Validation loss: 1.9558340964778778

Epoch: 6| Step: 11
Training loss: 0.918505072593689
Validation loss: 1.9830590781345163

Epoch: 6| Step: 12
Training loss: 0.6768865585327148
Validation loss: 1.983251651128133

Epoch: 6| Step: 13
Training loss: 0.9256327152252197
Validation loss: 2.0152542283458095

Epoch: 425| Step: 0
Training loss: 0.5504063367843628
Validation loss: 1.9726585726584158

Epoch: 6| Step: 1
Training loss: 0.6643955707550049
Validation loss: 1.9506690937985656

Epoch: 6| Step: 2
Training loss: 0.8008023500442505
Validation loss: 1.9163601783014113

Epoch: 6| Step: 3
Training loss: 1.155809998512268
Validation loss: 1.853156465356068

Epoch: 6| Step: 4
Training loss: 1.2155616283416748
Validation loss: 1.8355693227501326

Epoch: 6| Step: 5
Training loss: 0.7944437861442566
Validation loss: 1.848808241146867

Epoch: 6| Step: 6
Training loss: 1.0585694313049316
Validation loss: 1.8700196114919518

Epoch: 6| Step: 7
Training loss: 0.5248784422874451
Validation loss: 1.8763433887112526

Epoch: 6| Step: 8
Training loss: 0.7715325951576233
Validation loss: 1.9219742128925938

Epoch: 6| Step: 9
Training loss: 0.48353058099746704
Validation loss: 1.8916876828798683

Epoch: 6| Step: 10
Training loss: 1.2879893779754639
Validation loss: 1.9532307322307298

Epoch: 6| Step: 11
Training loss: 0.39435017108917236
Validation loss: 1.9380217470148557

Epoch: 6| Step: 12
Training loss: 0.6276305913925171
Validation loss: 1.9790238359923005

Epoch: 6| Step: 13
Training loss: 0.6857938170433044
Validation loss: 1.9530876746741674

Epoch: 426| Step: 0
Training loss: 0.719642698764801
Validation loss: 1.9318574090157785

Epoch: 6| Step: 1
Training loss: 0.6553354263305664
Validation loss: 1.8986282143541562

Epoch: 6| Step: 2
Training loss: 0.6805226802825928
Validation loss: 1.8733866035297353

Epoch: 6| Step: 3
Training loss: 0.8460266590118408
Validation loss: 1.8751568345613376

Epoch: 6| Step: 4
Training loss: 0.3494563400745392
Validation loss: 1.8675425873007825

Epoch: 6| Step: 5
Training loss: 0.714699387550354
Validation loss: 1.8627811580575921

Epoch: 6| Step: 6
Training loss: 0.9710622429847717
Validation loss: 1.8704778161100162

Epoch: 6| Step: 7
Training loss: 0.8953791856765747
Validation loss: 1.8547349027408067

Epoch: 6| Step: 8
Training loss: 0.6738825440406799
Validation loss: 1.8551170595230595

Epoch: 6| Step: 9
Training loss: 0.8734614849090576
Validation loss: 1.8572259039007208

Epoch: 6| Step: 10
Training loss: 0.8329841494560242
Validation loss: 1.8655451830997263

Epoch: 6| Step: 11
Training loss: 1.1874806880950928
Validation loss: 1.8907165168434061

Epoch: 6| Step: 12
Training loss: 0.7609049677848816
Validation loss: 1.9142432751194123

Epoch: 6| Step: 13
Training loss: 0.507233738899231
Validation loss: 1.9219875950967111

Epoch: 427| Step: 0
Training loss: 0.7142341732978821
Validation loss: 1.9156150330779373

Epoch: 6| Step: 1
Training loss: 0.6424316167831421
Validation loss: 1.9114366782608854

Epoch: 6| Step: 2
Training loss: 0.7643594145774841
Validation loss: 1.9404083221189437

Epoch: 6| Step: 3
Training loss: 1.0158525705337524
Validation loss: 1.9335077424203195

Epoch: 6| Step: 4
Training loss: 0.4292263984680176
Validation loss: 1.9092666442676256

Epoch: 6| Step: 5
Training loss: 1.0917396545410156
Validation loss: 1.8707562056920861

Epoch: 6| Step: 6
Training loss: 0.6594642996788025
Validation loss: 1.8380267312449794

Epoch: 6| Step: 7
Training loss: 0.5192338228225708
Validation loss: 1.8099843455899147

Epoch: 6| Step: 8
Training loss: 0.9408334493637085
Validation loss: 1.8055914384062572

Epoch: 6| Step: 9
Training loss: 0.7579785585403442
Validation loss: 1.7908800263558664

Epoch: 6| Step: 10
Training loss: 0.994482159614563
Validation loss: 1.81618490142207

Epoch: 6| Step: 11
Training loss: 0.7023566961288452
Validation loss: 1.8505566658512238

Epoch: 6| Step: 12
Training loss: 0.7556522488594055
Validation loss: 1.8592365057237688

Epoch: 6| Step: 13
Training loss: 1.0628433227539062
Validation loss: 1.8833893178611674

Epoch: 428| Step: 0
Training loss: 0.6796277761459351
Validation loss: 1.942570763249551

Epoch: 6| Step: 1
Training loss: 0.962877631187439
Validation loss: 2.018357837071983

Epoch: 6| Step: 2
Training loss: 0.9378758668899536
Validation loss: 2.0295784524692

Epoch: 6| Step: 3
Training loss: 1.0480250120162964
Validation loss: 1.9916746847091182

Epoch: 6| Step: 4
Training loss: 0.834927499294281
Validation loss: 1.9382804491186654

Epoch: 6| Step: 5
Training loss: 1.009009599685669
Validation loss: 1.8975678413145003

Epoch: 6| Step: 6
Training loss: 0.8586328029632568
Validation loss: 1.8940314656944686

Epoch: 6| Step: 7
Training loss: 0.8420202732086182
Validation loss: 1.8519846726489324

Epoch: 6| Step: 8
Training loss: 0.4987441599369049
Validation loss: 1.8497623397457985

Epoch: 6| Step: 9
Training loss: 0.5653127431869507
Validation loss: 1.8422939521010204

Epoch: 6| Step: 10
Training loss: 0.6560342311859131
Validation loss: 1.8542430093211513

Epoch: 6| Step: 11
Training loss: 1.0818209648132324
Validation loss: 1.8611337651488602

Epoch: 6| Step: 12
Training loss: 0.6913397908210754
Validation loss: 1.924639699279621

Epoch: 6| Step: 13
Training loss: 0.6194891333580017
Validation loss: 1.9002432438635057

Epoch: 429| Step: 0
Training loss: 1.0048108100891113
Validation loss: 1.909097799690821

Epoch: 6| Step: 1
Training loss: 0.7206436991691589
Validation loss: 1.9333007848390968

Epoch: 6| Step: 2
Training loss: 0.8517967462539673
Validation loss: 1.9247869881250526

Epoch: 6| Step: 3
Training loss: 1.1907511949539185
Validation loss: 1.9284072127393497

Epoch: 6| Step: 4
Training loss: 0.9228626489639282
Validation loss: 1.9170442627322288

Epoch: 6| Step: 5
Training loss: 0.6861943006515503
Validation loss: 1.9589931785419423

Epoch: 6| Step: 6
Training loss: 0.6763587594032288
Validation loss: 1.9023916734162198

Epoch: 6| Step: 7
Training loss: 0.6008813381195068
Validation loss: 1.9182216223850046

Epoch: 6| Step: 8
Training loss: 0.7487256526947021
Validation loss: 1.9122101465861003

Epoch: 6| Step: 9
Training loss: 0.7274287939071655
Validation loss: 1.9171072308735182

Epoch: 6| Step: 10
Training loss: 0.9282914400100708
Validation loss: 1.9078669868489748

Epoch: 6| Step: 11
Training loss: 0.6345824599266052
Validation loss: 1.9773017257772467

Epoch: 6| Step: 12
Training loss: 0.6078578233718872
Validation loss: 1.9480054891237648

Epoch: 6| Step: 13
Training loss: 0.7847896814346313
Validation loss: 1.9391769132306498

Epoch: 430| Step: 0
Training loss: 0.7281210422515869
Validation loss: 1.9391367743092198

Epoch: 6| Step: 1
Training loss: 1.0354936122894287
Validation loss: 1.9173757901755712

Epoch: 6| Step: 2
Training loss: 1.0561918020248413
Validation loss: 1.9472727070572555

Epoch: 6| Step: 3
Training loss: 0.9022607207298279
Validation loss: 1.9140282651429534

Epoch: 6| Step: 4
Training loss: 0.473827987909317
Validation loss: 1.9227883187673425

Epoch: 6| Step: 5
Training loss: 0.7331408858299255
Validation loss: 1.8793494932113155

Epoch: 6| Step: 6
Training loss: 0.664717972278595
Validation loss: 1.9041130004390594

Epoch: 6| Step: 7
Training loss: 0.8191991448402405
Validation loss: 1.9053854839776152

Epoch: 6| Step: 8
Training loss: 0.643071174621582
Validation loss: 1.8851734976614676

Epoch: 6| Step: 9
Training loss: 0.782425582408905
Validation loss: 1.8879202758112261

Epoch: 6| Step: 10
Training loss: 0.575333833694458
Validation loss: 1.9110817627240253

Epoch: 6| Step: 11
Training loss: 0.874701976776123
Validation loss: 1.923474939920569

Epoch: 6| Step: 12
Training loss: 0.7231190204620361
Validation loss: 1.90502655377952

Epoch: 6| Step: 13
Training loss: 0.4331141710281372
Validation loss: 1.9108491110545334

Epoch: 431| Step: 0
Training loss: 0.8602021932601929
Validation loss: 1.9101764258518015

Epoch: 6| Step: 1
Training loss: 1.0926169157028198
Validation loss: 1.890798068815662

Epoch: 6| Step: 2
Training loss: 0.47162142395973206
Validation loss: 1.8914022355951288

Epoch: 6| Step: 3
Training loss: 0.7076367139816284
Validation loss: 1.8833313885555472

Epoch: 6| Step: 4
Training loss: 0.6631340980529785
Validation loss: 1.9206328417665215

Epoch: 6| Step: 5
Training loss: 0.43895769119262695
Validation loss: 1.8873003721237183

Epoch: 6| Step: 6
Training loss: 1.1946238279342651
Validation loss: 1.892517433371595

Epoch: 6| Step: 7
Training loss: 0.9882804155349731
Validation loss: 1.8965367117235739

Epoch: 6| Step: 8
Training loss: 0.6361808776855469
Validation loss: 1.8989132681200582

Epoch: 6| Step: 9
Training loss: 0.5843003988265991
Validation loss: 1.9048572868429205

Epoch: 6| Step: 10
Training loss: 0.9415318965911865
Validation loss: 1.9018023629342355

Epoch: 6| Step: 11
Training loss: 0.36625272035598755
Validation loss: 1.8986509948648431

Epoch: 6| Step: 12
Training loss: 0.5275468230247498
Validation loss: 1.928860511831058

Epoch: 6| Step: 13
Training loss: 1.0887550115585327
Validation loss: 1.9036315718004782

Epoch: 432| Step: 0
Training loss: 0.7278963327407837
Validation loss: 1.9095070759455364

Epoch: 6| Step: 1
Training loss: 0.6513081789016724
Validation loss: 1.9233973141639464

Epoch: 6| Step: 2
Training loss: 0.8719846606254578
Validation loss: 1.9082124335791475

Epoch: 6| Step: 3
Training loss: 0.6374289393424988
Validation loss: 1.9176371302655948

Epoch: 6| Step: 4
Training loss: 0.7778213024139404
Validation loss: 1.8756285700746762

Epoch: 6| Step: 5
Training loss: 1.0315905809402466
Validation loss: 1.8717282408027238

Epoch: 6| Step: 6
Training loss: 0.4954380393028259
Validation loss: 1.882871989280947

Epoch: 6| Step: 7
Training loss: 0.6386713981628418
Validation loss: 1.8680374289071688

Epoch: 6| Step: 8
Training loss: 0.7989102602005005
Validation loss: 1.9145087734345467

Epoch: 6| Step: 9
Training loss: 0.870283842086792
Validation loss: 1.914179950632075

Epoch: 6| Step: 10
Training loss: 0.7586206793785095
Validation loss: 1.9298135183190788

Epoch: 6| Step: 11
Training loss: 0.8002629280090332
Validation loss: 1.8729972095899685

Epoch: 6| Step: 12
Training loss: 0.8865410685539246
Validation loss: 1.860069969648956

Epoch: 6| Step: 13
Training loss: 0.35427820682525635
Validation loss: 1.850208649071314

Epoch: 433| Step: 0
Training loss: 0.5474066734313965
Validation loss: 1.8704887179918186

Epoch: 6| Step: 1
Training loss: 0.8042730093002319
Validation loss: 1.858524235345984

Epoch: 6| Step: 2
Training loss: 0.5801929235458374
Validation loss: 1.8631000941799534

Epoch: 6| Step: 3
Training loss: 1.2725625038146973
Validation loss: 1.8783929924811087

Epoch: 6| Step: 4
Training loss: 0.4108573794364929
Validation loss: 1.885417942077883

Epoch: 6| Step: 5
Training loss: 0.5127209424972534
Validation loss: 1.9073359184367682

Epoch: 6| Step: 6
Training loss: 0.620151162147522
Validation loss: 1.9415978693193006

Epoch: 6| Step: 7
Training loss: 1.1508063077926636
Validation loss: 1.9391310291905557

Epoch: 6| Step: 8
Training loss: 1.1223046779632568
Validation loss: 1.9846036639264835

Epoch: 6| Step: 9
Training loss: 0.5852605700492859
Validation loss: 1.9351121764029227

Epoch: 6| Step: 10
Training loss: 0.866383969783783
Validation loss: 1.9066789291238273

Epoch: 6| Step: 11
Training loss: 0.9419422149658203
Validation loss: 1.8823677929498817

Epoch: 6| Step: 12
Training loss: 0.5615717172622681
Validation loss: 1.8793428380002257

Epoch: 6| Step: 13
Training loss: 1.0293641090393066
Validation loss: 1.8312557999805739

Epoch: 434| Step: 0
Training loss: 0.7792576551437378
Validation loss: 1.8419778116287724

Epoch: 6| Step: 1
Training loss: 1.0016846656799316
Validation loss: 1.8959013569739558

Epoch: 6| Step: 2
Training loss: 0.8299747109413147
Validation loss: 1.868960403626965

Epoch: 6| Step: 3
Training loss: 0.9449505805969238
Validation loss: 1.896906138748251

Epoch: 6| Step: 4
Training loss: 0.4623247981071472
Validation loss: 1.9640139879718903

Epoch: 6| Step: 5
Training loss: 0.6362804174423218
Validation loss: 1.949444196557486

Epoch: 6| Step: 6
Training loss: 0.6362428069114685
Validation loss: 1.9407032792286207

Epoch: 6| Step: 7
Training loss: 0.7024094462394714
Validation loss: 1.8918571831077657

Epoch: 6| Step: 8
Training loss: 0.5244927406311035
Validation loss: 1.894229555642733

Epoch: 6| Step: 9
Training loss: 0.55171799659729
Validation loss: 1.8905396256395566

Epoch: 6| Step: 10
Training loss: 0.7322468757629395
Validation loss: 1.8773383658419374

Epoch: 6| Step: 11
Training loss: 1.0466173887252808
Validation loss: 1.8716938816091067

Epoch: 6| Step: 12
Training loss: 0.8253554701805115
Validation loss: 1.8628275830258605

Epoch: 6| Step: 13
Training loss: 0.4389010965824127
Validation loss: 1.8484839649610623

Epoch: 435| Step: 0
Training loss: 0.7044880986213684
Validation loss: 1.88801376024882

Epoch: 6| Step: 1
Training loss: 0.9865962862968445
Validation loss: 1.8430088053467453

Epoch: 6| Step: 2
Training loss: 0.7780932784080505
Validation loss: 1.8576994390897854

Epoch: 6| Step: 3
Training loss: 0.9659513235092163
Validation loss: 1.883863236314507

Epoch: 6| Step: 4
Training loss: 0.4567820131778717
Validation loss: 1.8820438949010705

Epoch: 6| Step: 5
Training loss: 0.7707154750823975
Validation loss: 1.8849031374018679

Epoch: 6| Step: 6
Training loss: 0.49840378761291504
Validation loss: 1.9021492132576563

Epoch: 6| Step: 7
Training loss: 0.745376467704773
Validation loss: 1.9414546271806121

Epoch: 6| Step: 8
Training loss: 0.41315290331840515
Validation loss: 1.9349773827419485

Epoch: 6| Step: 9
Training loss: 0.9398737549781799
Validation loss: 1.9328313002022364

Epoch: 6| Step: 10
Training loss: 0.6795551776885986
Validation loss: 1.875968139658692

Epoch: 6| Step: 11
Training loss: 0.5111323595046997
Validation loss: 1.8574313502157889

Epoch: 6| Step: 12
Training loss: 0.8034447431564331
Validation loss: 1.8705332445841965

Epoch: 6| Step: 13
Training loss: 0.8977700471878052
Validation loss: 1.835388437394173

Epoch: 436| Step: 0
Training loss: 0.8450835943222046
Validation loss: 1.7953911391637658

Epoch: 6| Step: 1
Training loss: 0.6438333988189697
Validation loss: 1.8223717328040832

Epoch: 6| Step: 2
Training loss: 0.8596912622451782
Validation loss: 1.815026657555693

Epoch: 6| Step: 3
Training loss: 1.026665449142456
Validation loss: 1.882774123581507

Epoch: 6| Step: 4
Training loss: 0.6432364583015442
Validation loss: 1.9041965033418389

Epoch: 6| Step: 5
Training loss: 0.40285277366638184
Validation loss: 1.9414243082846365

Epoch: 6| Step: 6
Training loss: 0.4698549211025238
Validation loss: 1.940748753086213

Epoch: 6| Step: 7
Training loss: 0.9384320974349976
Validation loss: 1.8774499406096756

Epoch: 6| Step: 8
Training loss: 0.47065940499305725
Validation loss: 1.8654371153923772

Epoch: 6| Step: 9
Training loss: 0.8365989923477173
Validation loss: 1.8521263291758876

Epoch: 6| Step: 10
Training loss: 0.6320580244064331
Validation loss: 1.8484912649277718

Epoch: 6| Step: 11
Training loss: 0.7255418300628662
Validation loss: 1.7896564416987921

Epoch: 6| Step: 12
Training loss: 0.9961737394332886
Validation loss: 1.8515658711874357

Epoch: 6| Step: 13
Training loss: 0.7241661548614502
Validation loss: 1.8514765295931088

Epoch: 437| Step: 0
Training loss: 0.6298362612724304
Validation loss: 1.8874679701302641

Epoch: 6| Step: 1
Training loss: 0.8646111488342285
Validation loss: 1.886817152141243

Epoch: 6| Step: 2
Training loss: 0.6965161561965942
Validation loss: 1.9228522149465417

Epoch: 6| Step: 3
Training loss: 0.5791690349578857
Validation loss: 1.9367214941209363

Epoch: 6| Step: 4
Training loss: 0.5894434452056885
Validation loss: 1.9452714561134257

Epoch: 6| Step: 5
Training loss: 0.35437464714050293
Validation loss: 1.8989517073477469

Epoch: 6| Step: 6
Training loss: 1.3311002254486084
Validation loss: 1.8516075354750439

Epoch: 6| Step: 7
Training loss: 0.4255759119987488
Validation loss: 1.82699921823317

Epoch: 6| Step: 8
Training loss: 0.6159942746162415
Validation loss: 1.8229172947586223

Epoch: 6| Step: 9
Training loss: 0.9138217568397522
Validation loss: 1.849880273624133

Epoch: 6| Step: 10
Training loss: 1.0696845054626465
Validation loss: 1.8696438702203895

Epoch: 6| Step: 11
Training loss: 0.6832895278930664
Validation loss: 1.8873209132943103

Epoch: 6| Step: 12
Training loss: 0.7728135585784912
Validation loss: 1.8849831255533362

Epoch: 6| Step: 13
Training loss: 0.6195969581604004
Validation loss: 1.933541896522686

Epoch: 438| Step: 0
Training loss: 0.6903257966041565
Validation loss: 1.9819778524419314

Epoch: 6| Step: 1
Training loss: 0.7514364719390869
Validation loss: 1.9599640766779582

Epoch: 6| Step: 2
Training loss: 0.6803517937660217
Validation loss: 1.944757261583882

Epoch: 6| Step: 3
Training loss: 0.6659091711044312
Validation loss: 1.938909916467564

Epoch: 6| Step: 4
Training loss: 0.5434614419937134
Validation loss: 1.9283003653249433

Epoch: 6| Step: 5
Training loss: 0.7014978528022766
Validation loss: 1.8858780886537285

Epoch: 6| Step: 6
Training loss: 0.6983268857002258
Validation loss: 1.8661289163815078

Epoch: 6| Step: 7
Training loss: 0.5602683424949646
Validation loss: 1.8339412596917921

Epoch: 6| Step: 8
Training loss: 0.45771968364715576
Validation loss: 1.825570596161709

Epoch: 6| Step: 9
Training loss: 0.8853720426559448
Validation loss: 1.8338868182192567

Epoch: 6| Step: 10
Training loss: 0.9076172113418579
Validation loss: 1.872274250112554

Epoch: 6| Step: 11
Training loss: 0.7521378397941589
Validation loss: 1.847988151734875

Epoch: 6| Step: 12
Training loss: 0.8018708229064941
Validation loss: 1.8866440583300847

Epoch: 6| Step: 13
Training loss: 0.9932494759559631
Validation loss: 1.8838869474267448

Epoch: 439| Step: 0
Training loss: 0.46579453349113464
Validation loss: 1.8895946382194437

Epoch: 6| Step: 1
Training loss: 0.7393763661384583
Validation loss: 1.8781210645552604

Epoch: 6| Step: 2
Training loss: 0.6770923733711243
Validation loss: 1.8899391274298392

Epoch: 6| Step: 3
Training loss: 1.070340871810913
Validation loss: 1.863440466183488

Epoch: 6| Step: 4
Training loss: 0.48658108711242676
Validation loss: 1.8916038723402127

Epoch: 6| Step: 5
Training loss: 0.8693956136703491
Validation loss: 1.8552179105820195

Epoch: 6| Step: 6
Training loss: 0.7872551083564758
Validation loss: 1.812920198645643

Epoch: 6| Step: 7
Training loss: 0.6351600885391235
Validation loss: 1.8187083839088358

Epoch: 6| Step: 8
Training loss: 0.7270699739456177
Validation loss: 1.8174401278136878

Epoch: 6| Step: 9
Training loss: 0.7556039094924927
Validation loss: 1.8337598692986272

Epoch: 6| Step: 10
Training loss: 0.8586366772651672
Validation loss: 1.8283656848374235

Epoch: 6| Step: 11
Training loss: 0.9859629273414612
Validation loss: 1.9123131690486785

Epoch: 6| Step: 12
Training loss: 0.2871866822242737
Validation loss: 1.9420356878670313

Epoch: 6| Step: 13
Training loss: 0.6317527294158936
Validation loss: 1.9424490967104513

Epoch: 440| Step: 0
Training loss: 0.4440813958644867
Validation loss: 1.9866772108180548

Epoch: 6| Step: 1
Training loss: 0.3397446870803833
Validation loss: 1.9463286463932326

Epoch: 6| Step: 2
Training loss: 0.6089581251144409
Validation loss: 1.932946705049084

Epoch: 6| Step: 3
Training loss: 0.42196300625801086
Validation loss: 1.9152709258499967

Epoch: 6| Step: 4
Training loss: 0.491437166929245
Validation loss: 1.9089251359303792

Epoch: 6| Step: 5
Training loss: 1.1327259540557861
Validation loss: 1.8592511684663835

Epoch: 6| Step: 6
Training loss: 0.9233923554420471
Validation loss: 1.878922967500584

Epoch: 6| Step: 7
Training loss: 0.7936709523200989
Validation loss: 1.8528321148246847

Epoch: 6| Step: 8
Training loss: 0.6314074397087097
Validation loss: 1.8337155849702897

Epoch: 6| Step: 9
Training loss: 0.9175926446914673
Validation loss: 1.8302672473333215

Epoch: 6| Step: 10
Training loss: 0.9543013572692871
Validation loss: 1.8266271391222555

Epoch: 6| Step: 11
Training loss: 0.7775965929031372
Validation loss: 1.836989664262341

Epoch: 6| Step: 12
Training loss: 0.7430293560028076
Validation loss: 1.8981764188376806

Epoch: 6| Step: 13
Training loss: 1.013183832168579
Validation loss: 1.9094914800377303

Epoch: 441| Step: 0
Training loss: 0.5743569135665894
Validation loss: 1.9310142365835046

Epoch: 6| Step: 1
Training loss: 0.3821948170661926
Validation loss: 1.9439855801161898

Epoch: 6| Step: 2
Training loss: 0.537331223487854
Validation loss: 1.9547366634491952

Epoch: 6| Step: 3
Training loss: 0.7891879081726074
Validation loss: 1.9530509646220873

Epoch: 6| Step: 4
Training loss: 1.1327791213989258
Validation loss: 1.8874194275948308

Epoch: 6| Step: 5
Training loss: 1.0110809803009033
Validation loss: 1.8754099210103352

Epoch: 6| Step: 6
Training loss: 0.5426839590072632
Validation loss: 1.8573636752302929

Epoch: 6| Step: 7
Training loss: 0.832467794418335
Validation loss: 1.8516523068951023

Epoch: 6| Step: 8
Training loss: 0.5934396982192993
Validation loss: 1.8449754420147146

Epoch: 6| Step: 9
Training loss: 0.9874324202537537
Validation loss: 1.8577224631463327

Epoch: 6| Step: 10
Training loss: 0.2847920060157776
Validation loss: 1.888611557663128

Epoch: 6| Step: 11
Training loss: 0.5152989625930786
Validation loss: 1.915798326974274

Epoch: 6| Step: 12
Training loss: 0.8400024771690369
Validation loss: 1.9372167689825899

Epoch: 6| Step: 13
Training loss: 0.8295950889587402
Validation loss: 1.9723429833689043

Epoch: 442| Step: 0
Training loss: 0.8512365818023682
Validation loss: 1.9073752664750623

Epoch: 6| Step: 1
Training loss: 0.9352032542228699
Validation loss: 1.8928528780578284

Epoch: 6| Step: 2
Training loss: 0.7245082855224609
Validation loss: 1.9067303378094909

Epoch: 6| Step: 3
Training loss: 0.35865968465805054
Validation loss: 1.8432443962302258

Epoch: 6| Step: 4
Training loss: 0.7982097864151001
Validation loss: 1.838037657481368

Epoch: 6| Step: 5
Training loss: 0.43313369154930115
Validation loss: 1.8227109575784335

Epoch: 6| Step: 6
Training loss: 0.4594905972480774
Validation loss: 1.8190991314508582

Epoch: 6| Step: 7
Training loss: 0.912709653377533
Validation loss: 1.8245299490549232

Epoch: 6| Step: 8
Training loss: 0.9265184998512268
Validation loss: 1.850517052476124

Epoch: 6| Step: 9
Training loss: 0.600958526134491
Validation loss: 1.8543661166262884

Epoch: 6| Step: 10
Training loss: 0.7116371989250183
Validation loss: 1.9282617312605663

Epoch: 6| Step: 11
Training loss: 1.009598970413208
Validation loss: 1.9379724764054822

Epoch: 6| Step: 12
Training loss: 0.5107879638671875
Validation loss: 1.9053360313497565

Epoch: 6| Step: 13
Training loss: 0.4835304617881775
Validation loss: 1.8769844757613314

Epoch: 443| Step: 0
Training loss: 0.8338213562965393
Validation loss: 1.8133198420206706

Epoch: 6| Step: 1
Training loss: 0.3459390103816986
Validation loss: 1.8257413961554085

Epoch: 6| Step: 2
Training loss: 0.6906709671020508
Validation loss: 1.7670370045528616

Epoch: 6| Step: 3
Training loss: 0.7477104663848877
Validation loss: 1.7985822436630086

Epoch: 6| Step: 4
Training loss: 0.6962876319885254
Validation loss: 1.7921584203679075

Epoch: 6| Step: 5
Training loss: 0.6527815461158752
Validation loss: 1.86253660468645

Epoch: 6| Step: 6
Training loss: 1.0794732570648193
Validation loss: 1.879002030177783

Epoch: 6| Step: 7
Training loss: 0.6865890026092529
Validation loss: 1.9576173956676195

Epoch: 6| Step: 8
Training loss: 0.6298753619194031
Validation loss: 1.9687492629533172

Epoch: 6| Step: 9
Training loss: 1.065232276916504
Validation loss: 1.9709750003712152

Epoch: 6| Step: 10
Training loss: 0.7087153196334839
Validation loss: 1.9203715632038731

Epoch: 6| Step: 11
Training loss: 0.4465601444244385
Validation loss: 1.910064374246905

Epoch: 6| Step: 12
Training loss: 0.8201440572738647
Validation loss: 1.8953677274847542

Epoch: 6| Step: 13
Training loss: 0.38473203778266907
Validation loss: 1.8410270867809173

Epoch: 444| Step: 0
Training loss: 0.6065542697906494
Validation loss: 1.8486064467378842

Epoch: 6| Step: 1
Training loss: 0.9922032356262207
Validation loss: 1.8556153825534287

Epoch: 6| Step: 2
Training loss: 0.6967592239379883
Validation loss: 1.849771281724335

Epoch: 6| Step: 3
Training loss: 0.9669552445411682
Validation loss: 1.876938352020838

Epoch: 6| Step: 4
Training loss: 1.0432929992675781
Validation loss: 1.9142759487193117

Epoch: 6| Step: 5
Training loss: 0.5495401620864868
Validation loss: 1.9493286007194108

Epoch: 6| Step: 6
Training loss: 0.6651679873466492
Validation loss: 1.9393551939277238

Epoch: 6| Step: 7
Training loss: 0.8456312417984009
Validation loss: 1.9166283504937285

Epoch: 6| Step: 8
Training loss: 0.7785269021987915
Validation loss: 1.93607343909561

Epoch: 6| Step: 9
Training loss: 0.5061393976211548
Validation loss: 1.8717679823598554

Epoch: 6| Step: 10
Training loss: 0.31936967372894287
Validation loss: 1.8793065906852804

Epoch: 6| Step: 11
Training loss: 0.5047813653945923
Validation loss: 1.8374580388428063

Epoch: 6| Step: 12
Training loss: 0.68565833568573
Validation loss: 1.8417945241415372

Epoch: 6| Step: 13
Training loss: 0.6086177229881287
Validation loss: 1.8415793680375623

Epoch: 445| Step: 0
Training loss: 0.8785415291786194
Validation loss: 1.823744204736525

Epoch: 6| Step: 1
Training loss: 0.6448197364807129
Validation loss: 1.8375838892434233

Epoch: 6| Step: 2
Training loss: 0.5599898099899292
Validation loss: 1.8300400023819299

Epoch: 6| Step: 3
Training loss: 0.5725808143615723
Validation loss: 1.8475704910934612

Epoch: 6| Step: 4
Training loss: 0.6632047295570374
Validation loss: 1.8505048828740274

Epoch: 6| Step: 5
Training loss: 0.8525716066360474
Validation loss: 1.8948586230636926

Epoch: 6| Step: 6
Training loss: 0.6725874543190002
Validation loss: 1.951890060978551

Epoch: 6| Step: 7
Training loss: 0.48475831747055054
Validation loss: 1.988394078388009

Epoch: 6| Step: 8
Training loss: 0.8726707696914673
Validation loss: 2.0444805955374115

Epoch: 6| Step: 9
Training loss: 0.7404273748397827
Validation loss: 1.989278083206505

Epoch: 6| Step: 10
Training loss: 0.9521243572235107
Validation loss: 1.9645473649424892

Epoch: 6| Step: 11
Training loss: 0.6993231177330017
Validation loss: 1.874090148556617

Epoch: 6| Step: 12
Training loss: 0.6726529002189636
Validation loss: 1.879531389923506

Epoch: 6| Step: 13
Training loss: 0.4381876587867737
Validation loss: 1.8743850133752311

Epoch: 446| Step: 0
Training loss: 0.8610836863517761
Validation loss: 1.8605281883670437

Epoch: 6| Step: 1
Training loss: 0.8258639574050903
Validation loss: 1.8662293828943723

Epoch: 6| Step: 2
Training loss: 0.5903012752532959
Validation loss: 1.8948556056586645

Epoch: 6| Step: 3
Training loss: 0.6532639861106873
Validation loss: 1.9547969102859497

Epoch: 6| Step: 4
Training loss: 0.7076817154884338
Validation loss: 1.9232855317413167

Epoch: 6| Step: 5
Training loss: 1.0433311462402344
Validation loss: 1.9177166979799989

Epoch: 6| Step: 6
Training loss: 0.5957528352737427
Validation loss: 1.9287107554815148

Epoch: 6| Step: 7
Training loss: 0.6863200068473816
Validation loss: 1.900138581952741

Epoch: 6| Step: 8
Training loss: 0.9650812149047852
Validation loss: 1.8440249171308292

Epoch: 6| Step: 9
Training loss: 0.42993658781051636
Validation loss: 1.855537114604827

Epoch: 6| Step: 10
Training loss: 0.21108320355415344
Validation loss: 1.8313288124658729

Epoch: 6| Step: 11
Training loss: 0.8089174032211304
Validation loss: 1.8536893167803365

Epoch: 6| Step: 12
Training loss: 0.6905521154403687
Validation loss: 1.8924303977720198

Epoch: 6| Step: 13
Training loss: 0.7959454655647278
Validation loss: 1.8997640225195116

Epoch: 447| Step: 0
Training loss: 0.5311151742935181
Validation loss: 1.9263523483789096

Epoch: 6| Step: 1
Training loss: 0.8708633780479431
Validation loss: 1.8976117128966956

Epoch: 6| Step: 2
Training loss: 1.0382403135299683
Validation loss: 1.907644203914109

Epoch: 6| Step: 3
Training loss: 0.8907968997955322
Validation loss: 1.8905683153419084

Epoch: 6| Step: 4
Training loss: 0.6297955513000488
Validation loss: 1.887836366571406

Epoch: 6| Step: 5
Training loss: 0.40478187799453735
Validation loss: 1.8630858621289652

Epoch: 6| Step: 6
Training loss: 0.7832423448562622
Validation loss: 1.8772714407213273

Epoch: 6| Step: 7
Training loss: 0.7188770174980164
Validation loss: 1.8545797781277729

Epoch: 6| Step: 8
Training loss: 0.2745453417301178
Validation loss: 1.8663681783983785

Epoch: 6| Step: 9
Training loss: 0.5598076581954956
Validation loss: 1.8639883277236775

Epoch: 6| Step: 10
Training loss: 1.1686198711395264
Validation loss: 1.86383201870867

Epoch: 6| Step: 11
Training loss: 0.6130595207214355
Validation loss: 1.8757661606675835

Epoch: 6| Step: 12
Training loss: 0.4048602879047394
Validation loss: 1.9323757233158234

Epoch: 6| Step: 13
Training loss: 0.30840903520584106
Validation loss: 1.9425880908966064

Epoch: 448| Step: 0
Training loss: 0.6808217763900757
Validation loss: 1.9401256345933484

Epoch: 6| Step: 1
Training loss: 0.44429072737693787
Validation loss: 1.9067745900923205

Epoch: 6| Step: 2
Training loss: 0.8188283443450928
Validation loss: 1.9293218915180494

Epoch: 6| Step: 3
Training loss: 0.3380601108074188
Validation loss: 1.9104189462559198

Epoch: 6| Step: 4
Training loss: 0.7351434230804443
Validation loss: 1.9125503032438216

Epoch: 6| Step: 5
Training loss: 0.6233589053153992
Validation loss: 1.8580543725721297

Epoch: 6| Step: 6
Training loss: 0.9723570346832275
Validation loss: 1.8488780529268327

Epoch: 6| Step: 7
Training loss: 0.44538620114326477
Validation loss: 1.8468344185941963

Epoch: 6| Step: 8
Training loss: 0.49324557185173035
Validation loss: 1.854929098518946

Epoch: 6| Step: 9
Training loss: 0.751530110836029
Validation loss: 1.8494366189484954

Epoch: 6| Step: 10
Training loss: 1.0253206491470337
Validation loss: 1.8367582931313464

Epoch: 6| Step: 11
Training loss: 0.6967850923538208
Validation loss: 1.827644391726422

Epoch: 6| Step: 12
Training loss: 0.5322591066360474
Validation loss: 1.8555322629149242

Epoch: 6| Step: 13
Training loss: 1.2251771688461304
Validation loss: 1.8482421264853528

Epoch: 449| Step: 0
Training loss: 0.7763552665710449
Validation loss: 1.876258482215225

Epoch: 6| Step: 1
Training loss: 0.48250508308410645
Validation loss: 1.8972309097166984

Epoch: 6| Step: 2
Training loss: 0.39121928811073303
Validation loss: 1.9453158532419512

Epoch: 6| Step: 3
Training loss: 0.7400169968605042
Validation loss: 1.9711152225412347

Epoch: 6| Step: 4
Training loss: 0.6521705389022827
Validation loss: 1.9616782306342997

Epoch: 6| Step: 5
Training loss: 0.4983307719230652
Validation loss: 1.9749065547861078

Epoch: 6| Step: 6
Training loss: 0.890117883682251
Validation loss: 1.88511513510058

Epoch: 6| Step: 7
Training loss: 0.6066632866859436
Validation loss: 1.873297704163418

Epoch: 6| Step: 8
Training loss: 0.8746009469032288
Validation loss: 1.8302179869785105

Epoch: 6| Step: 9
Training loss: 0.7107462882995605
Validation loss: 1.8330207896488968

Epoch: 6| Step: 10
Training loss: 0.8733167052268982
Validation loss: 1.8465717095200733

Epoch: 6| Step: 11
Training loss: 0.7098077535629272
Validation loss: 1.840463912615212

Epoch: 6| Step: 12
Training loss: 0.517147421836853
Validation loss: 1.8475930677947177

Epoch: 6| Step: 13
Training loss: 0.6444187164306641
Validation loss: 1.8568517623409149

Epoch: 450| Step: 0
Training loss: 0.5259965062141418
Validation loss: 1.912580600348852

Epoch: 6| Step: 1
Training loss: 0.609316349029541
Validation loss: 1.9454199703790809

Epoch: 6| Step: 2
Training loss: 0.5542423725128174
Validation loss: 1.9961806343447777

Epoch: 6| Step: 3
Training loss: 0.7980141043663025
Validation loss: 1.985656540880921

Epoch: 6| Step: 4
Training loss: 0.6277827620506287
Validation loss: 1.9677868402132423

Epoch: 6| Step: 5
Training loss: 0.42708659172058105
Validation loss: 1.9600208408089095

Epoch: 6| Step: 6
Training loss: 0.672600269317627
Validation loss: 1.9376641447826097

Epoch: 6| Step: 7
Training loss: 0.7890982627868652
Validation loss: 1.882862658910854

Epoch: 6| Step: 8
Training loss: 0.6247450113296509
Validation loss: 1.8509229075524114

Epoch: 6| Step: 9
Training loss: 0.5833882093429565
Validation loss: 1.8261890206285702

Epoch: 6| Step: 10
Training loss: 0.6010102033615112
Validation loss: 1.8309952802555536

Epoch: 6| Step: 11
Training loss: 1.0419403314590454
Validation loss: 1.8199943855244627

Epoch: 6| Step: 12
Training loss: 0.732293963432312
Validation loss: 1.8407622075849963

Epoch: 6| Step: 13
Training loss: 0.43643054366111755
Validation loss: 1.8444204458626368

Epoch: 451| Step: 0
Training loss: 0.5523822903633118
Validation loss: 1.8684050754834247

Epoch: 6| Step: 1
Training loss: 0.4884878695011139
Validation loss: 1.8739507634152648

Epoch: 6| Step: 2
Training loss: 0.6553947925567627
Validation loss: 1.8762312371243712

Epoch: 6| Step: 3
Training loss: 0.8004831671714783
Validation loss: 1.9215178592230684

Epoch: 6| Step: 4
Training loss: 0.7593176960945129
Validation loss: 1.9565807388674827

Epoch: 6| Step: 5
Training loss: 0.5523921847343445
Validation loss: 1.931065264568534

Epoch: 6| Step: 6
Training loss: 0.6956861615180969
Validation loss: 1.917970972676431

Epoch: 6| Step: 7
Training loss: 0.6501448154449463
Validation loss: 1.878976389925967

Epoch: 6| Step: 8
Training loss: 0.558387815952301
Validation loss: 1.8973183452442128

Epoch: 6| Step: 9
Training loss: 0.8135162591934204
Validation loss: 1.8713358768852808

Epoch: 6| Step: 10
Training loss: 0.7727077007293701
Validation loss: 1.8733049823391823

Epoch: 6| Step: 11
Training loss: 0.3862523138523102
Validation loss: 1.8426960309346516

Epoch: 6| Step: 12
Training loss: 0.46907007694244385
Validation loss: 1.8287422528830908

Epoch: 6| Step: 13
Training loss: 0.5925632119178772
Validation loss: 1.8344302792702951

Epoch: 452| Step: 0
Training loss: 0.38929712772369385
Validation loss: 1.8661743658845142

Epoch: 6| Step: 1
Training loss: 0.8372604250907898
Validation loss: 1.8681815388382121

Epoch: 6| Step: 2
Training loss: 0.4910840094089508
Validation loss: 1.9133643463093748

Epoch: 6| Step: 3
Training loss: 0.6074022650718689
Validation loss: 1.8934010920986053

Epoch: 6| Step: 4
Training loss: 0.8806448578834534
Validation loss: 1.9033000315389326

Epoch: 6| Step: 5
Training loss: 0.6488864421844482
Validation loss: 1.9075459177776048

Epoch: 6| Step: 6
Training loss: 0.5648367404937744
Validation loss: 1.8452138157301052

Epoch: 6| Step: 7
Training loss: 0.7301851511001587
Validation loss: 1.844026768079368

Epoch: 6| Step: 8
Training loss: 0.6134371757507324
Validation loss: 1.8394523538568968

Epoch: 6| Step: 9
Training loss: 0.6277903318405151
Validation loss: 1.8130028350378877

Epoch: 6| Step: 10
Training loss: 0.8164575695991516
Validation loss: 1.7860510554364932

Epoch: 6| Step: 11
Training loss: 0.8833407163619995
Validation loss: 1.8360271248766171

Epoch: 6| Step: 12
Training loss: 0.6647821068763733
Validation loss: 1.8509331941604614

Epoch: 6| Step: 13
Training loss: 0.8304154872894287
Validation loss: 1.8945754817737046

Epoch: 453| Step: 0
Training loss: 0.36034977436065674
Validation loss: 1.8953223843728342

Epoch: 6| Step: 1
Training loss: 0.837590217590332
Validation loss: 1.9835663674980082

Epoch: 6| Step: 2
Training loss: 0.8385251760482788
Validation loss: 1.9563699755617368

Epoch: 6| Step: 3
Training loss: 0.39413732290267944
Validation loss: 1.8958825424153318

Epoch: 6| Step: 4
Training loss: 0.6672013401985168
Validation loss: 1.9405984288902693

Epoch: 6| Step: 5
Training loss: 0.9568355083465576
Validation loss: 1.9077025011021604

Epoch: 6| Step: 6
Training loss: 0.8225213289260864
Validation loss: 1.914714700432234

Epoch: 6| Step: 7
Training loss: 0.46881353855133057
Validation loss: 1.890116645443824

Epoch: 6| Step: 8
Training loss: 1.2983002662658691
Validation loss: 1.910072527905946

Epoch: 6| Step: 9
Training loss: 0.765150249004364
Validation loss: 1.9009666058324999

Epoch: 6| Step: 10
Training loss: 0.5695676803588867
Validation loss: 1.898728935949264

Epoch: 6| Step: 11
Training loss: 0.6727202534675598
Validation loss: 1.8739040385010421

Epoch: 6| Step: 12
Training loss: 0.5311199426651001
Validation loss: 1.8803556452515304

Epoch: 6| Step: 13
Training loss: 0.36294782161712646
Validation loss: 1.87587897880103

Epoch: 454| Step: 0
Training loss: 1.1521327495574951
Validation loss: 1.9208832351110314

Epoch: 6| Step: 1
Training loss: 0.7289150953292847
Validation loss: 1.8981638159803165

Epoch: 6| Step: 2
Training loss: 0.5119495391845703
Validation loss: 1.9244387572811497

Epoch: 6| Step: 3
Training loss: 0.8446183800697327
Validation loss: 1.8906511516981228

Epoch: 6| Step: 4
Training loss: 0.7135739326477051
Validation loss: 1.8921755116472962

Epoch: 6| Step: 5
Training loss: 0.7073403596878052
Validation loss: 1.9010714818072576

Epoch: 6| Step: 6
Training loss: 0.9358967542648315
Validation loss: 1.8634218938889042

Epoch: 6| Step: 7
Training loss: 0.7376453876495361
Validation loss: 1.8300241578009822

Epoch: 6| Step: 8
Training loss: 0.5407522320747375
Validation loss: 1.8476775025808683

Epoch: 6| Step: 9
Training loss: 0.3033507764339447
Validation loss: 1.8273879892082625

Epoch: 6| Step: 10
Training loss: 0.4574926495552063
Validation loss: 1.8463105053030036

Epoch: 6| Step: 11
Training loss: 0.518593966960907
Validation loss: 1.8711929987835627

Epoch: 6| Step: 12
Training loss: 0.35999536514282227
Validation loss: 1.8682953497414947

Epoch: 6| Step: 13
Training loss: 0.7427135705947876
Validation loss: 1.9129154054067468

Epoch: 455| Step: 0
Training loss: 0.3530654013156891
Validation loss: 1.922023093828591

Epoch: 6| Step: 1
Training loss: 0.34310364723205566
Validation loss: 1.933209006504346

Epoch: 6| Step: 2
Training loss: 0.9664853811264038
Validation loss: 1.9202510362030358

Epoch: 6| Step: 3
Training loss: 1.014744520187378
Validation loss: 1.896676387838138

Epoch: 6| Step: 4
Training loss: 0.5227580070495605
Validation loss: 1.9089692459311536

Epoch: 6| Step: 5
Training loss: 0.42074671387672424
Validation loss: 1.8903108437856038

Epoch: 6| Step: 6
Training loss: 0.45270299911499023
Validation loss: 1.8843467825202531

Epoch: 6| Step: 7
Training loss: 0.6576831340789795
Validation loss: 1.8552350446742067

Epoch: 6| Step: 8
Training loss: 0.5999329090118408
Validation loss: 1.8660426908923733

Epoch: 6| Step: 9
Training loss: 0.5103311538696289
Validation loss: 1.8579544354510564

Epoch: 6| Step: 10
Training loss: 0.693544864654541
Validation loss: 1.838686857172238

Epoch: 6| Step: 11
Training loss: 0.5385589599609375
Validation loss: 1.8514362278804983

Epoch: 6| Step: 12
Training loss: 1.1775102615356445
Validation loss: 1.8667192484742852

Epoch: 6| Step: 13
Training loss: 0.6204860210418701
Validation loss: 1.8711157486002932

Epoch: 456| Step: 0
Training loss: 0.6216413378715515
Validation loss: 1.8740637302398682

Epoch: 6| Step: 1
Training loss: 0.41810402274131775
Validation loss: 1.900740772165278

Epoch: 6| Step: 2
Training loss: 0.47341012954711914
Validation loss: 1.8279915240503126

Epoch: 6| Step: 3
Training loss: 0.5634554624557495
Validation loss: 1.823148299289006

Epoch: 6| Step: 4
Training loss: 0.5539200901985168
Validation loss: 1.8428686639314056

Epoch: 6| Step: 5
Training loss: 0.7495893239974976
Validation loss: 1.8438258171081543

Epoch: 6| Step: 6
Training loss: 0.6091408729553223
Validation loss: 1.8709173792151994

Epoch: 6| Step: 7
Training loss: 0.3221484422683716
Validation loss: 1.8701293929930656

Epoch: 6| Step: 8
Training loss: 0.515148937702179
Validation loss: 1.8703077505993586

Epoch: 6| Step: 9
Training loss: 0.7843098640441895
Validation loss: 1.8722102667695733

Epoch: 6| Step: 10
Training loss: 0.6790683269500732
Validation loss: 1.8815255882919475

Epoch: 6| Step: 11
Training loss: 0.9400527477264404
Validation loss: 1.8978154274725145

Epoch: 6| Step: 12
Training loss: 0.7418596148490906
Validation loss: 1.894454699690624

Epoch: 6| Step: 13
Training loss: 0.34613731503486633
Validation loss: 1.8876157037673458

Epoch: 457| Step: 0
Training loss: 0.7255743145942688
Validation loss: 1.912163144798689

Epoch: 6| Step: 1
Training loss: 0.4655531048774719
Validation loss: 1.8971930665354575

Epoch: 6| Step: 2
Training loss: 0.615146279335022
Validation loss: 1.920610934175471

Epoch: 6| Step: 3
Training loss: 0.8541155457496643
Validation loss: 1.898626406987508

Epoch: 6| Step: 4
Training loss: 0.6935378313064575
Validation loss: 1.8983423517596336

Epoch: 6| Step: 5
Training loss: 0.40550923347473145
Validation loss: 1.9126885526923723

Epoch: 6| Step: 6
Training loss: 0.6774996519088745
Validation loss: 1.8998106448881087

Epoch: 6| Step: 7
Training loss: 0.5451209545135498
Validation loss: 1.9545705831179054

Epoch: 6| Step: 8
Training loss: 0.409829318523407
Validation loss: 1.8964532267662786

Epoch: 6| Step: 9
Training loss: 0.819320797920227
Validation loss: 1.862053007207891

Epoch: 6| Step: 10
Training loss: 0.6684446334838867
Validation loss: 1.8369388862322735

Epoch: 6| Step: 11
Training loss: 0.5668724775314331
Validation loss: 1.8178646090210124

Epoch: 6| Step: 12
Training loss: 0.5809606313705444
Validation loss: 1.7884127850173621

Epoch: 6| Step: 13
Training loss: 0.36252859234809875
Validation loss: 1.8024516823471233

Epoch: 458| Step: 0
Training loss: 0.5830280780792236
Validation loss: 1.8290691183459373

Epoch: 6| Step: 1
Training loss: 0.6048250198364258
Validation loss: 1.8556067802572762

Epoch: 6| Step: 2
Training loss: 0.53361976146698
Validation loss: 1.929707032378002

Epoch: 6| Step: 3
Training loss: 0.3974398970603943
Validation loss: 1.9290296980129775

Epoch: 6| Step: 4
Training loss: 0.7019954323768616
Validation loss: 1.9900349083767142

Epoch: 6| Step: 5
Training loss: 0.20534789562225342
Validation loss: 1.9435724071277085

Epoch: 6| Step: 6
Training loss: 0.7084099054336548
Validation loss: 1.9459516886741883

Epoch: 6| Step: 7
Training loss: 0.6907470226287842
Validation loss: 1.9070530719654535

Epoch: 6| Step: 8
Training loss: 0.9493563175201416
Validation loss: 1.8815887051243936

Epoch: 6| Step: 9
Training loss: 0.6043208837509155
Validation loss: 1.849894590275262

Epoch: 6| Step: 10
Training loss: 0.44906437397003174
Validation loss: 1.847592120529503

Epoch: 6| Step: 11
Training loss: 0.9337601065635681
Validation loss: 1.8101561889853528

Epoch: 6| Step: 12
Training loss: 0.9038989543914795
Validation loss: 1.8207543280816847

Epoch: 6| Step: 13
Training loss: 0.33936837315559387
Validation loss: 1.8467892190461517

Epoch: 459| Step: 0
Training loss: 0.6956483721733093
Validation loss: 1.8628232030458347

Epoch: 6| Step: 1
Training loss: 0.4763867259025574
Validation loss: 1.9110184254184845

Epoch: 6| Step: 2
Training loss: 0.9696131944656372
Validation loss: 1.9173293703345842

Epoch: 6| Step: 3
Training loss: 0.7308549880981445
Validation loss: 1.9086970565139607

Epoch: 6| Step: 4
Training loss: 0.6713994741439819
Validation loss: 1.8684569379334808

Epoch: 6| Step: 5
Training loss: 0.765385627746582
Validation loss: 1.794299517908404

Epoch: 6| Step: 6
Training loss: 0.6869072914123535
Validation loss: 1.8075370942392657

Epoch: 6| Step: 7
Training loss: 0.45023906230926514
Validation loss: 1.7823777352609942

Epoch: 6| Step: 8
Training loss: 0.4779605269432068
Validation loss: 1.8141425386551888

Epoch: 6| Step: 9
Training loss: 0.4677359461784363
Validation loss: 1.7899443231603152

Epoch: 6| Step: 10
Training loss: 0.4997624456882477
Validation loss: 1.8037019365577287

Epoch: 6| Step: 11
Training loss: 0.6584858894348145
Validation loss: 1.8412119739799089

Epoch: 6| Step: 12
Training loss: 0.4716200530529022
Validation loss: 1.863061349879029

Epoch: 6| Step: 13
Training loss: 0.813673734664917
Validation loss: 1.8666609423134917

Epoch: 460| Step: 0
Training loss: 0.5085312128067017
Validation loss: 1.8915524226362987

Epoch: 6| Step: 1
Training loss: 0.37080511450767517
Validation loss: 1.8979774854516471

Epoch: 6| Step: 2
Training loss: 0.45198431611061096
Validation loss: 1.8722568096653107

Epoch: 6| Step: 3
Training loss: 1.0965017080307007
Validation loss: 1.8939448953956686

Epoch: 6| Step: 4
Training loss: 0.49925753474235535
Validation loss: 1.8552622423377088

Epoch: 6| Step: 5
Training loss: 1.1389563083648682
Validation loss: 1.8810115180989748

Epoch: 6| Step: 6
Training loss: 0.5204356908798218
Validation loss: 1.8542615572611492

Epoch: 6| Step: 7
Training loss: 0.6706494092941284
Validation loss: 1.894821072137484

Epoch: 6| Step: 8
Training loss: 0.3611809313297272
Validation loss: 1.9264807778020059

Epoch: 6| Step: 9
Training loss: 0.4270141124725342
Validation loss: 1.873890874206379

Epoch: 6| Step: 10
Training loss: 0.3579098880290985
Validation loss: 1.8804368998414727

Epoch: 6| Step: 11
Training loss: 0.5258312225341797
Validation loss: 1.8979375464941866

Epoch: 6| Step: 12
Training loss: 0.6082375645637512
Validation loss: 1.8865569547940326

Epoch: 6| Step: 13
Training loss: 0.6938210725784302
Validation loss: 1.8791355138183923

Epoch: 461| Step: 0
Training loss: 0.2693502902984619
Validation loss: 1.8572654031938123

Epoch: 6| Step: 1
Training loss: 0.42936626076698303
Validation loss: 1.8211840224522415

Epoch: 6| Step: 2
Training loss: 0.43780338764190674
Validation loss: 1.793031746341336

Epoch: 6| Step: 3
Training loss: 0.7355529069900513
Validation loss: 1.8132162594026136

Epoch: 6| Step: 4
Training loss: 0.5091455578804016
Validation loss: 1.8096813630032282

Epoch: 6| Step: 5
Training loss: 0.7586010694503784
Validation loss: 1.8405729147695726

Epoch: 6| Step: 6
Training loss: 0.42462357878685
Validation loss: 1.8428008159001668

Epoch: 6| Step: 7
Training loss: 0.5723323822021484
Validation loss: 1.8651279916045487

Epoch: 6| Step: 8
Training loss: 0.6473844051361084
Validation loss: 1.8980298888298772

Epoch: 6| Step: 9
Training loss: 0.8858961462974548
Validation loss: 1.9270845895172448

Epoch: 6| Step: 10
Training loss: 0.5104606747627258
Validation loss: 1.9358687170090214

Epoch: 6| Step: 11
Training loss: 0.507965624332428
Validation loss: 1.928627730697714

Epoch: 6| Step: 12
Training loss: 0.6942133903503418
Validation loss: 1.922321686180689

Epoch: 6| Step: 13
Training loss: 0.7828337550163269
Validation loss: 1.8934304175838348

Epoch: 462| Step: 0
Training loss: 1.1574008464813232
Validation loss: 1.8641144511520222

Epoch: 6| Step: 1
Training loss: 0.453938364982605
Validation loss: 1.868017081291445

Epoch: 6| Step: 2
Training loss: 0.40693399310112
Validation loss: 1.8414001682753205

Epoch: 6| Step: 3
Training loss: 0.4847410321235657
Validation loss: 1.8348753708665089

Epoch: 6| Step: 4
Training loss: 0.8835114240646362
Validation loss: 1.8297388989438292

Epoch: 6| Step: 5
Training loss: 0.5097284317016602
Validation loss: 1.8441922216005222

Epoch: 6| Step: 6
Training loss: 0.6654324531555176
Validation loss: 1.8543744023128221

Epoch: 6| Step: 7
Training loss: 0.5383331775665283
Validation loss: 1.831398658854987

Epoch: 6| Step: 8
Training loss: 0.6343359351158142
Validation loss: 1.8458586995319655

Epoch: 6| Step: 9
Training loss: 0.7419387102127075
Validation loss: 1.8873088026559481

Epoch: 6| Step: 10
Training loss: 0.3359416723251343
Validation loss: 1.926197749312206

Epoch: 6| Step: 11
Training loss: 0.456569641828537
Validation loss: 1.9127638942451888

Epoch: 6| Step: 12
Training loss: 0.7321867942810059
Validation loss: 1.8872530139902586

Epoch: 6| Step: 13
Training loss: 0.17334863543510437
Validation loss: 1.8576858197489092

Epoch: 463| Step: 0
Training loss: 0.7785487174987793
Validation loss: 1.8888038384017123

Epoch: 6| Step: 1
Training loss: 0.5332573652267456
Validation loss: 1.8697025724636611

Epoch: 6| Step: 2
Training loss: 0.442889928817749
Validation loss: 1.8979260357477332

Epoch: 6| Step: 3
Training loss: 0.6246150732040405
Validation loss: 1.8761847429378058

Epoch: 6| Step: 4
Training loss: 0.656216561794281
Validation loss: 1.8597912224390174

Epoch: 6| Step: 5
Training loss: 0.5114057064056396
Validation loss: 1.856090098299006

Epoch: 6| Step: 6
Training loss: 0.3118179142475128
Validation loss: 1.845600958793394

Epoch: 6| Step: 7
Training loss: 0.4518163204193115
Validation loss: 1.859249932791597

Epoch: 6| Step: 8
Training loss: 0.7699763774871826
Validation loss: 1.8710710130712038

Epoch: 6| Step: 9
Training loss: 0.9869967103004456
Validation loss: 1.8626803839078514

Epoch: 6| Step: 10
Training loss: 0.38375329971313477
Validation loss: 1.864071379425705

Epoch: 6| Step: 11
Training loss: 0.466688334941864
Validation loss: 1.8831963052031815

Epoch: 6| Step: 12
Training loss: 0.6627683639526367
Validation loss: 1.8764817894146006

Epoch: 6| Step: 13
Training loss: 0.9538198113441467
Validation loss: 1.8518427918034215

Epoch: 464| Step: 0
Training loss: 0.6602100729942322
Validation loss: 1.8920993420385546

Epoch: 6| Step: 1
Training loss: 0.5809219479560852
Validation loss: 1.859586456770538

Epoch: 6| Step: 2
Training loss: 0.7633057236671448
Validation loss: 1.8742905175814064

Epoch: 6| Step: 3
Training loss: 0.6118865013122559
Validation loss: 1.8818052955853042

Epoch: 6| Step: 4
Training loss: 0.3207206726074219
Validation loss: 1.8445539192486835

Epoch: 6| Step: 5
Training loss: 0.6261137127876282
Validation loss: 1.8770710665692565

Epoch: 6| Step: 6
Training loss: 0.5268905162811279
Validation loss: 1.8898531352320025

Epoch: 6| Step: 7
Training loss: 0.4243803024291992
Validation loss: 1.8987262351538545

Epoch: 6| Step: 8
Training loss: 0.7827272415161133
Validation loss: 1.8828290252275364

Epoch: 6| Step: 9
Training loss: 0.6027730703353882
Validation loss: 1.8671218272178405

Epoch: 6| Step: 10
Training loss: 0.7299184799194336
Validation loss: 1.8690704427739626

Epoch: 6| Step: 11
Training loss: 0.5848238468170166
Validation loss: 1.8456818878009755

Epoch: 6| Step: 12
Training loss: 0.5969395637512207
Validation loss: 1.8638804292166105

Epoch: 6| Step: 13
Training loss: 0.30704572796821594
Validation loss: 1.817948474678942

Epoch: 465| Step: 0
Training loss: 0.5945388078689575
Validation loss: 1.8776872760506087

Epoch: 6| Step: 1
Training loss: 0.7535852789878845
Validation loss: 1.8537099643420147

Epoch: 6| Step: 2
Training loss: 0.3647422790527344
Validation loss: 1.8409739386650823

Epoch: 6| Step: 3
Training loss: 0.22288498282432556
Validation loss: 1.8603477516481954

Epoch: 6| Step: 4
Training loss: 0.5813676714897156
Validation loss: 1.8644746375340286

Epoch: 6| Step: 5
Training loss: 0.7449155449867249
Validation loss: 1.8887748346533826

Epoch: 6| Step: 6
Training loss: 0.3399117588996887
Validation loss: 1.9272428533082366

Epoch: 6| Step: 7
Training loss: 0.6419714689254761
Validation loss: 1.8817897330048263

Epoch: 6| Step: 8
Training loss: 0.6910906434059143
Validation loss: 1.880315129474927

Epoch: 6| Step: 9
Training loss: 0.5745833516120911
Validation loss: 1.8401421295699252

Epoch: 6| Step: 10
Training loss: 0.69547438621521
Validation loss: 1.8453863448994134

Epoch: 6| Step: 11
Training loss: 0.6442885398864746
Validation loss: 1.7954259341762913

Epoch: 6| Step: 12
Training loss: 0.6169236898422241
Validation loss: 1.8035651240297543

Epoch: 6| Step: 13
Training loss: 0.40013861656188965
Validation loss: 1.8153713608300814

Epoch: 466| Step: 0
Training loss: 0.556786060333252
Validation loss: 1.8427620536537581

Epoch: 6| Step: 1
Training loss: 0.4283904731273651
Validation loss: 1.8855234743446432

Epoch: 6| Step: 2
Training loss: 0.7730242013931274
Validation loss: 1.9220416648413545

Epoch: 6| Step: 3
Training loss: 0.755264937877655
Validation loss: 1.9030676734062932

Epoch: 6| Step: 4
Training loss: 0.578765869140625
Validation loss: 1.881132948783136

Epoch: 6| Step: 5
Training loss: 0.42814403772354126
Validation loss: 1.868319667795653

Epoch: 6| Step: 6
Training loss: 0.48675858974456787
Validation loss: 1.8369791200084071

Epoch: 6| Step: 7
Training loss: 0.4815334677696228
Validation loss: 1.8588245273918234

Epoch: 6| Step: 8
Training loss: 0.39974266290664673
Validation loss: 1.8599555274491668

Epoch: 6| Step: 9
Training loss: 0.7119529247283936
Validation loss: 1.9019796861115323

Epoch: 6| Step: 10
Training loss: 0.5765718221664429
Validation loss: 1.8800767954959665

Epoch: 6| Step: 11
Training loss: 0.8833522796630859
Validation loss: 1.8948572053704211

Epoch: 6| Step: 12
Training loss: 0.4053717255592346
Validation loss: 1.8560221951494935

Epoch: 6| Step: 13
Training loss: 0.5403839945793152
Validation loss: 1.891365433251986

Epoch: 467| Step: 0
Training loss: 0.5794367790222168
Validation loss: 1.8942596886747627

Epoch: 6| Step: 1
Training loss: 0.3762592673301697
Validation loss: 1.887947956720988

Epoch: 6| Step: 2
Training loss: 0.47094374895095825
Validation loss: 1.8645101311386272

Epoch: 6| Step: 3
Training loss: 0.44159501791000366
Validation loss: 1.8854596640474053

Epoch: 6| Step: 4
Training loss: 0.6076269745826721
Validation loss: 1.8456599981554094

Epoch: 6| Step: 5
Training loss: 0.5649287104606628
Validation loss: 1.8735524121151175

Epoch: 6| Step: 6
Training loss: 0.8367449045181274
Validation loss: 1.8183106299369567

Epoch: 6| Step: 7
Training loss: 0.6915633678436279
Validation loss: 1.873631843956568

Epoch: 6| Step: 8
Training loss: 0.5403547286987305
Validation loss: 1.9334309716378488

Epoch: 6| Step: 9
Training loss: 0.9145737290382385
Validation loss: 1.9392471416022188

Epoch: 6| Step: 10
Training loss: 0.6206591129302979
Validation loss: 1.890536190361105

Epoch: 6| Step: 11
Training loss: 0.29118582606315613
Validation loss: 1.9098210129686581

Epoch: 6| Step: 12
Training loss: 0.5180763006210327
Validation loss: 1.898493843693887

Epoch: 6| Step: 13
Training loss: 0.31797274947166443
Validation loss: 1.8428809527427918

Epoch: 468| Step: 0
Training loss: 0.44282135367393494
Validation loss: 1.8202615963515414

Epoch: 6| Step: 1
Training loss: 0.8385604023933411
Validation loss: 1.8300176000082364

Epoch: 6| Step: 2
Training loss: 1.0213207006454468
Validation loss: 1.8034737340865596

Epoch: 6| Step: 3
Training loss: 0.9178426265716553
Validation loss: 1.850946359736945

Epoch: 6| Step: 4
Training loss: 0.387417733669281
Validation loss: 1.848667290902907

Epoch: 6| Step: 5
Training loss: 0.3564511239528656
Validation loss: 1.8943533435944588

Epoch: 6| Step: 6
Training loss: 0.43661943078041077
Validation loss: 1.9266451840759606

Epoch: 6| Step: 7
Training loss: 0.8319907784461975
Validation loss: 1.9644856747760568

Epoch: 6| Step: 8
Training loss: 0.4316096305847168
Validation loss: 1.9005993412386986

Epoch: 6| Step: 9
Training loss: 0.5751376152038574
Validation loss: 1.9450545003337245

Epoch: 6| Step: 10
Training loss: 0.36815381050109863
Validation loss: 1.912024841513685

Epoch: 6| Step: 11
Training loss: 0.4343487322330475
Validation loss: 1.9111157630079536

Epoch: 6| Step: 12
Training loss: 0.5163264274597168
Validation loss: 1.8463527694825204

Epoch: 6| Step: 13
Training loss: 0.45459333062171936
Validation loss: 1.84904343851151

Epoch: 469| Step: 0
Training loss: 0.6203408241271973
Validation loss: 1.8207886372843096

Epoch: 6| Step: 1
Training loss: 0.5888466835021973
Validation loss: 1.8443573290301907

Epoch: 6| Step: 2
Training loss: 0.33314239978790283
Validation loss: 1.8010051622185657

Epoch: 6| Step: 3
Training loss: 0.5785844326019287
Validation loss: 1.8426608321487263

Epoch: 6| Step: 4
Training loss: 0.682388961315155
Validation loss: 1.8681185373695948

Epoch: 6| Step: 5
Training loss: 0.6047039031982422
Validation loss: 1.8995956887481034

Epoch: 6| Step: 6
Training loss: 0.623032808303833
Validation loss: 1.926854907825429

Epoch: 6| Step: 7
Training loss: 0.6648091077804565
Validation loss: 1.9167666140423025

Epoch: 6| Step: 8
Training loss: 0.7116690278053284
Validation loss: 1.898724009913783

Epoch: 6| Step: 9
Training loss: 0.31382960081100464
Validation loss: 1.9179446992053781

Epoch: 6| Step: 10
Training loss: 0.5299887657165527
Validation loss: 1.8876084807098552

Epoch: 6| Step: 11
Training loss: 0.4800819754600525
Validation loss: 1.8258322310704056

Epoch: 6| Step: 12
Training loss: 0.5746374726295471
Validation loss: 1.8115133495740994

Epoch: 6| Step: 13
Training loss: 0.7495729327201843
Validation loss: 1.8429866465189124

Epoch: 470| Step: 0
Training loss: 0.5059998631477356
Validation loss: 1.82477371410657

Epoch: 6| Step: 1
Training loss: 0.4134453535079956
Validation loss: 1.861025156513337

Epoch: 6| Step: 2
Training loss: 0.6904808282852173
Validation loss: 1.9150103663885465

Epoch: 6| Step: 3
Training loss: 0.4827011823654175
Validation loss: 1.9742426167252243

Epoch: 6| Step: 4
Training loss: 0.5682946443557739
Validation loss: 1.9919159694384503

Epoch: 6| Step: 5
Training loss: 0.5178494453430176
Validation loss: 1.9179489971489034

Epoch: 6| Step: 6
Training loss: 0.5471361875534058
Validation loss: 1.8658448573081725

Epoch: 6| Step: 7
Training loss: 0.7353971004486084
Validation loss: 1.8452465521392

Epoch: 6| Step: 8
Training loss: 0.4007783830165863
Validation loss: 1.8147956581525906

Epoch: 6| Step: 9
Training loss: 0.5353057384490967
Validation loss: 1.8117649657751924

Epoch: 6| Step: 10
Training loss: 0.6550675630569458
Validation loss: 1.8505665691949988

Epoch: 6| Step: 11
Training loss: 0.530892014503479
Validation loss: 1.835555805954882

Epoch: 6| Step: 12
Training loss: 1.134945034980774
Validation loss: 1.8535850253156436

Epoch: 6| Step: 13
Training loss: 0.17029479146003723
Validation loss: 1.88174811614457

Epoch: 471| Step: 0
Training loss: 0.6276773810386658
Validation loss: 1.8627219687225998

Epoch: 6| Step: 1
Training loss: 0.505011796951294
Validation loss: 1.9065125860193723

Epoch: 6| Step: 2
Training loss: 0.5492477416992188
Validation loss: 1.9240371924574657

Epoch: 6| Step: 3
Training loss: 0.431413859128952
Validation loss: 1.9035638019602785

Epoch: 6| Step: 4
Training loss: 0.9324579834938049
Validation loss: 1.9161880375236593

Epoch: 6| Step: 5
Training loss: 0.4422276020050049
Validation loss: 1.8727798077367968

Epoch: 6| Step: 6
Training loss: 0.8208445310592651
Validation loss: 1.8665570892313474

Epoch: 6| Step: 7
Training loss: 0.7442166209220886
Validation loss: 1.8445117832511984

Epoch: 6| Step: 8
Training loss: 0.5439064502716064
Validation loss: 1.8405942827142694

Epoch: 6| Step: 9
Training loss: 0.4533020257949829
Validation loss: 1.813456496884746

Epoch: 6| Step: 10
Training loss: 0.45327138900756836
Validation loss: 1.8257633300237759

Epoch: 6| Step: 11
Training loss: 0.5748544335365295
Validation loss: 1.8224253218661073

Epoch: 6| Step: 12
Training loss: 0.40946048498153687
Validation loss: 1.8274077138593119

Epoch: 6| Step: 13
Training loss: 0.2551020085811615
Validation loss: 1.8881371264816613

Epoch: 472| Step: 0
Training loss: 0.522754967212677
Validation loss: 1.9074233296096965

Epoch: 6| Step: 1
Training loss: 0.5058227181434631
Validation loss: 1.86776114151042

Epoch: 6| Step: 2
Training loss: 0.6778479814529419
Validation loss: 1.886137347067556

Epoch: 6| Step: 3
Training loss: 0.5200250148773193
Validation loss: 1.8800848043093117

Epoch: 6| Step: 4
Training loss: 0.533427357673645
Validation loss: 1.8854509656147291

Epoch: 6| Step: 5
Training loss: 0.5600379705429077
Validation loss: 1.880044170605239

Epoch: 6| Step: 6
Training loss: 0.47895699739456177
Validation loss: 1.884578897107032

Epoch: 6| Step: 7
Training loss: 0.9178097248077393
Validation loss: 1.8446503441820863

Epoch: 6| Step: 8
Training loss: 0.5080814361572266
Validation loss: 1.8055320798709829

Epoch: 6| Step: 9
Training loss: 0.37485557794570923
Validation loss: 1.829774033638739

Epoch: 6| Step: 10
Training loss: 0.6912649869918823
Validation loss: 1.8387489267574844

Epoch: 6| Step: 11
Training loss: 0.6894628405570984
Validation loss: 1.8486745049876552

Epoch: 6| Step: 12
Training loss: 0.47701823711395264
Validation loss: 1.9404831073617423

Epoch: 6| Step: 13
Training loss: 0.6909525990486145
Validation loss: 1.930409300711847

Epoch: 473| Step: 0
Training loss: 0.7028689980506897
Validation loss: 1.929316270735956

Epoch: 6| Step: 1
Training loss: 0.6995550394058228
Validation loss: 1.8817669524941394

Epoch: 6| Step: 2
Training loss: 0.6377058029174805
Validation loss: 1.874138214254892

Epoch: 6| Step: 3
Training loss: 0.42682772874832153
Validation loss: 1.8494531569942352

Epoch: 6| Step: 4
Training loss: 0.6992490887641907
Validation loss: 1.811441408690586

Epoch: 6| Step: 5
Training loss: 0.44234681129455566
Validation loss: 1.8059428712373138

Epoch: 6| Step: 6
Training loss: 0.5219975113868713
Validation loss: 1.8158798576683126

Epoch: 6| Step: 7
Training loss: 0.3124198913574219
Validation loss: 1.8472627683352398

Epoch: 6| Step: 8
Training loss: 0.5860434174537659
Validation loss: 1.9124525336809055

Epoch: 6| Step: 9
Training loss: 0.3246772885322571
Validation loss: 1.9314374577614568

Epoch: 6| Step: 10
Training loss: 0.36283910274505615
Validation loss: 1.9325110040685183

Epoch: 6| Step: 11
Training loss: 0.6956926584243774
Validation loss: 1.9856840115721508

Epoch: 6| Step: 12
Training loss: 0.7861204743385315
Validation loss: 1.979297040611185

Epoch: 6| Step: 13
Training loss: 0.44920021295547485
Validation loss: 1.9422307629739084

Epoch: 474| Step: 0
Training loss: 0.5329791307449341
Validation loss: 1.8852105448322911

Epoch: 6| Step: 1
Training loss: 0.37048351764678955
Validation loss: 1.8644896873863794

Epoch: 6| Step: 2
Training loss: 0.5509565472602844
Validation loss: 1.8582607379523657

Epoch: 6| Step: 3
Training loss: 0.4503130614757538
Validation loss: 1.8513227355095647

Epoch: 6| Step: 4
Training loss: 0.6989993453025818
Validation loss: 1.869481962214234

Epoch: 6| Step: 5
Training loss: 0.8910173177719116
Validation loss: 1.9228934934062343

Epoch: 6| Step: 6
Training loss: 0.47844159603118896
Validation loss: 1.8961172988337855

Epoch: 6| Step: 7
Training loss: 0.3977459669113159
Validation loss: 1.9313472624747985

Epoch: 6| Step: 8
Training loss: 0.8180075883865356
Validation loss: 1.9012721200143137

Epoch: 6| Step: 9
Training loss: 0.3934859335422516
Validation loss: 1.930062932352866

Epoch: 6| Step: 10
Training loss: 0.5396069288253784
Validation loss: 1.9070097195204867

Epoch: 6| Step: 11
Training loss: 0.3829309344291687
Validation loss: 1.8777984444813063

Epoch: 6| Step: 12
Training loss: 0.612453818321228
Validation loss: 1.8533644624935683

Epoch: 6| Step: 13
Training loss: 0.9264187216758728
Validation loss: 1.8196184737707979

Epoch: 475| Step: 0
Training loss: 0.6231794953346252
Validation loss: 1.8101228103842786

Epoch: 6| Step: 1
Training loss: 0.40320885181427
Validation loss: 1.8426221827025056

Epoch: 6| Step: 2
Training loss: 0.2782360017299652
Validation loss: 1.8006266278605307

Epoch: 6| Step: 3
Training loss: 0.5210254192352295
Validation loss: 1.8685604859423894

Epoch: 6| Step: 4
Training loss: 0.5058560371398926
Validation loss: 1.9015206701012068

Epoch: 6| Step: 5
Training loss: 0.7309359908103943
Validation loss: 1.9313145440111879

Epoch: 6| Step: 6
Training loss: 0.5349533557891846
Validation loss: 1.9669746147688998

Epoch: 6| Step: 7
Training loss: 0.783898115158081
Validation loss: 1.9276925081847816

Epoch: 6| Step: 8
Training loss: 0.882880449295044
Validation loss: 1.9401904049740042

Epoch: 6| Step: 9
Training loss: 0.6326596140861511
Validation loss: 1.8613431786978116

Epoch: 6| Step: 10
Training loss: 0.31823796033859253
Validation loss: 1.8557559546603952

Epoch: 6| Step: 11
Training loss: 0.5547209978103638
Validation loss: 1.852426726330993

Epoch: 6| Step: 12
Training loss: 0.3742128312587738
Validation loss: 1.8728437667251916

Epoch: 6| Step: 13
Training loss: 0.4876922369003296
Validation loss: 1.8070326517986994

Epoch: 476| Step: 0
Training loss: 0.670630156993866
Validation loss: 1.8571549846280007

Epoch: 6| Step: 1
Training loss: 0.7259280681610107
Validation loss: 1.8333466629828177

Epoch: 6| Step: 2
Training loss: 0.2947579026222229
Validation loss: 1.8333681027094524

Epoch: 6| Step: 3
Training loss: 0.4948759078979492
Validation loss: 1.8777527809143066

Epoch: 6| Step: 4
Training loss: 0.37059760093688965
Validation loss: 1.886524292730516

Epoch: 6| Step: 5
Training loss: 0.3792891502380371
Validation loss: 1.8804554477814706

Epoch: 6| Step: 6
Training loss: 0.3530108630657196
Validation loss: 1.8759471472873483

Epoch: 6| Step: 7
Training loss: 0.80108642578125
Validation loss: 1.8809251349459413

Epoch: 6| Step: 8
Training loss: 0.6454241275787354
Validation loss: 1.8841243725951

Epoch: 6| Step: 9
Training loss: 0.3139718770980835
Validation loss: 1.9230819158656622

Epoch: 6| Step: 10
Training loss: 0.6462833285331726
Validation loss: 1.9303610222313994

Epoch: 6| Step: 11
Training loss: 0.5103425979614258
Validation loss: 1.923112330898162

Epoch: 6| Step: 12
Training loss: 0.9918172955513
Validation loss: 1.8986312086864183

Epoch: 6| Step: 13
Training loss: 0.3075771927833557
Validation loss: 1.886582564282161

Epoch: 477| Step: 0
Training loss: 0.4661642909049988
Validation loss: 1.8678136000069239

Epoch: 6| Step: 1
Training loss: 0.5638375282287598
Validation loss: 1.8657171546771962

Epoch: 6| Step: 2
Training loss: 0.6335803270339966
Validation loss: 1.8568659764464184

Epoch: 6| Step: 3
Training loss: 0.5905197858810425
Validation loss: 1.8623783485863799

Epoch: 6| Step: 4
Training loss: 0.4188416302204132
Validation loss: 1.8660191989714099

Epoch: 6| Step: 5
Training loss: 0.45519453287124634
Validation loss: 1.8667914918673936

Epoch: 6| Step: 6
Training loss: 0.2893441915512085
Validation loss: 1.9011271345999934

Epoch: 6| Step: 7
Training loss: 0.5367776155471802
Validation loss: 1.8750797446056078

Epoch: 6| Step: 8
Training loss: 0.48640674352645874
Validation loss: 1.8978400794408654

Epoch: 6| Step: 9
Training loss: 0.6261207461357117
Validation loss: 1.9323304019948488

Epoch: 6| Step: 10
Training loss: 0.5466659665107727
Validation loss: 1.9161252860100038

Epoch: 6| Step: 11
Training loss: 0.7019484043121338
Validation loss: 1.8923190639865013

Epoch: 6| Step: 12
Training loss: 0.42664921283721924
Validation loss: 1.9078689736704673

Epoch: 6| Step: 13
Training loss: 0.4121659994125366
Validation loss: 1.8665396423750027

Epoch: 478| Step: 0
Training loss: 0.22553861141204834
Validation loss: 1.8608087878073416

Epoch: 6| Step: 1
Training loss: 0.6018537282943726
Validation loss: 1.849011662185833

Epoch: 6| Step: 2
Training loss: 0.3568871319293976
Validation loss: 1.8418749455482728

Epoch: 6| Step: 3
Training loss: 0.9159303307533264
Validation loss: 1.821365218008718

Epoch: 6| Step: 4
Training loss: 0.7140284776687622
Validation loss: 1.8493428986559632

Epoch: 6| Step: 5
Training loss: 0.22306367754936218
Validation loss: 1.8553792084417036

Epoch: 6| Step: 6
Training loss: 0.7526581883430481
Validation loss: 1.8297773432987992

Epoch: 6| Step: 7
Training loss: 0.20196221768856049
Validation loss: 1.8478684015171503

Epoch: 6| Step: 8
Training loss: 0.5606545209884644
Validation loss: 1.856669133709323

Epoch: 6| Step: 9
Training loss: 0.5608711838722229
Validation loss: 1.8912721398056194

Epoch: 6| Step: 10
Training loss: 0.3004474639892578
Validation loss: 1.8482663080256472

Epoch: 6| Step: 11
Training loss: 0.45154935121536255
Validation loss: 1.8620308637619019

Epoch: 6| Step: 12
Training loss: 0.7727637887001038
Validation loss: 1.8266433669674782

Epoch: 6| Step: 13
Training loss: 0.3251543641090393
Validation loss: 1.8649768867800314

Epoch: 479| Step: 0
Training loss: 0.8395693898200989
Validation loss: 1.8495263873889882

Epoch: 6| Step: 1
Training loss: 0.6477221250534058
Validation loss: 1.841105527775262

Epoch: 6| Step: 2
Training loss: 0.2726899981498718
Validation loss: 1.8168530105262675

Epoch: 6| Step: 3
Training loss: 0.46213358640670776
Validation loss: 1.824412453559137

Epoch: 6| Step: 4
Training loss: 0.3042556345462799
Validation loss: 1.8170286224734398

Epoch: 6| Step: 5
Training loss: 0.31627267599105835
Validation loss: 1.8276658314530567

Epoch: 6| Step: 6
Training loss: 0.4181468188762665
Validation loss: 1.8509814828954718

Epoch: 6| Step: 7
Training loss: 0.5332012176513672
Validation loss: 1.8911834878306235

Epoch: 6| Step: 8
Training loss: 0.41332218050956726
Validation loss: 1.913247331496208

Epoch: 6| Step: 9
Training loss: 0.2892851233482361
Validation loss: 1.879547926687425

Epoch: 6| Step: 10
Training loss: 0.42270052433013916
Validation loss: 1.858441742517615

Epoch: 6| Step: 11
Training loss: 0.7081131339073181
Validation loss: 1.8651014630512526

Epoch: 6| Step: 12
Training loss: 0.9797066450119019
Validation loss: 1.8629835869676323

Epoch: 6| Step: 13
Training loss: 0.49542298913002014
Validation loss: 1.8615548379959599

Epoch: 480| Step: 0
Training loss: 0.8245171308517456
Validation loss: 1.8480041655161048

Epoch: 6| Step: 1
Training loss: 0.5624517202377319
Validation loss: 1.8777090708414714

Epoch: 6| Step: 2
Training loss: 0.4365188181400299
Validation loss: 1.8809176542425667

Epoch: 6| Step: 3
Training loss: 0.2142234593629837
Validation loss: 1.8634556929270427

Epoch: 6| Step: 4
Training loss: 0.5118300914764404
Validation loss: 1.8641073216674149

Epoch: 6| Step: 5
Training loss: 0.6668046712875366
Validation loss: 1.88537682384573

Epoch: 6| Step: 6
Training loss: 0.37277305126190186
Validation loss: 1.874542244019047

Epoch: 6| Step: 7
Training loss: 0.3344256281852722
Validation loss: 1.8646705714605187

Epoch: 6| Step: 8
Training loss: 0.7565199136734009
Validation loss: 1.8820872806733655

Epoch: 6| Step: 9
Training loss: 0.5970737934112549
Validation loss: 1.8514729007597892

Epoch: 6| Step: 10
Training loss: 0.3836989402770996
Validation loss: 1.8863957146162629

Epoch: 6| Step: 11
Training loss: 0.6260404586791992
Validation loss: 1.8724272122947119

Epoch: 6| Step: 12
Training loss: 0.31632381677627563
Validation loss: 1.8322325701354651

Epoch: 6| Step: 13
Training loss: 0.5898467302322388
Validation loss: 1.8254802303929483

Epoch: 481| Step: 0
Training loss: 0.6086685657501221
Validation loss: 1.8251941716799172

Epoch: 6| Step: 1
Training loss: 0.5054089426994324
Validation loss: 1.8593011338223693

Epoch: 6| Step: 2
Training loss: 0.6401582360267639
Validation loss: 1.8679236622266873

Epoch: 6| Step: 3
Training loss: 0.7124314904212952
Validation loss: 1.880426945224885

Epoch: 6| Step: 4
Training loss: 0.19206403195858002
Validation loss: 1.9121487332928566

Epoch: 6| Step: 5
Training loss: 0.40329986810684204
Validation loss: 1.877247828309254

Epoch: 6| Step: 6
Training loss: 0.7047557830810547
Validation loss: 1.8603000076868201

Epoch: 6| Step: 7
Training loss: 0.5003922581672668
Validation loss: 1.8801823482718518

Epoch: 6| Step: 8
Training loss: 0.7079524993896484
Validation loss: 1.838195575180874

Epoch: 6| Step: 9
Training loss: 0.454348087310791
Validation loss: 1.8291434703334686

Epoch: 6| Step: 10
Training loss: 0.34712499380111694
Validation loss: 1.8563802447370303

Epoch: 6| Step: 11
Training loss: 0.2975476384162903
Validation loss: 1.861568502200547

Epoch: 6| Step: 12
Training loss: 0.3688918650150299
Validation loss: 1.8611034847074939

Epoch: 6| Step: 13
Training loss: 0.3069347143173218
Validation loss: 1.8675170765128186

Epoch: 482| Step: 0
Training loss: 0.4640218913555145
Validation loss: 1.8600836915354575

Epoch: 6| Step: 1
Training loss: 0.3932029604911804
Validation loss: 1.8601518023398615

Epoch: 6| Step: 2
Training loss: 0.46425706148147583
Validation loss: 1.8784907082075715

Epoch: 6| Step: 3
Training loss: 0.39602285623550415
Validation loss: 1.8808924331459949

Epoch: 6| Step: 4
Training loss: 0.8328163623809814
Validation loss: 1.8303964445667882

Epoch: 6| Step: 5
Training loss: 0.579017162322998
Validation loss: 1.8387276280310847

Epoch: 6| Step: 6
Training loss: 0.44226399064064026
Validation loss: 1.8319052803900935

Epoch: 6| Step: 7
Training loss: 0.35792505741119385
Validation loss: 1.830718708294694

Epoch: 6| Step: 8
Training loss: 0.6804057955741882
Validation loss: 1.8452823623534171

Epoch: 6| Step: 9
Training loss: 0.44977349042892456
Validation loss: 1.8443233172098796

Epoch: 6| Step: 10
Training loss: 0.6634721755981445
Validation loss: 1.8364985847985873

Epoch: 6| Step: 11
Training loss: 0.38299548625946045
Validation loss: 1.8333423958029798

Epoch: 6| Step: 12
Training loss: 0.3109057545661926
Validation loss: 1.83006812039242

Epoch: 6| Step: 13
Training loss: 0.46645912528038025
Validation loss: 1.8080965806079168

Epoch: 483| Step: 0
Training loss: 0.33718523383140564
Validation loss: 1.8334833524560417

Epoch: 6| Step: 1
Training loss: 0.5745346546173096
Validation loss: 1.8037301571138444

Epoch: 6| Step: 2
Training loss: 0.7979058027267456
Validation loss: 1.8589411858589417

Epoch: 6| Step: 3
Training loss: 0.527243971824646
Validation loss: 1.8292068537845407

Epoch: 6| Step: 4
Training loss: 0.8031351566314697
Validation loss: 1.8488620122273762

Epoch: 6| Step: 5
Training loss: 0.40181204676628113
Validation loss: 1.8704688625950967

Epoch: 6| Step: 6
Training loss: 0.2350667119026184
Validation loss: 1.8872558891132314

Epoch: 6| Step: 7
Training loss: 0.46651721000671387
Validation loss: 1.9341746196951917

Epoch: 6| Step: 8
Training loss: 0.48433277010917664
Validation loss: 1.9198680103466075

Epoch: 6| Step: 9
Training loss: 0.49944624304771423
Validation loss: 1.928525419645412

Epoch: 6| Step: 10
Training loss: 0.6743628978729248
Validation loss: 1.8634966855408044

Epoch: 6| Step: 11
Training loss: 0.38233113288879395
Validation loss: 1.8617702914822487

Epoch: 6| Step: 12
Training loss: 0.535277247428894
Validation loss: 1.8111176824056974

Epoch: 6| Step: 13
Training loss: 0.4576300084590912
Validation loss: 1.814554981006089

Epoch: 484| Step: 0
Training loss: 0.8535611033439636
Validation loss: 1.7997859178050872

Epoch: 6| Step: 1
Training loss: 0.38887304067611694
Validation loss: 1.8473546838247648

Epoch: 6| Step: 2
Training loss: 0.6240662336349487
Validation loss: 1.867603882666557

Epoch: 6| Step: 3
Training loss: 0.33429959416389465
Validation loss: 1.8948903314528927

Epoch: 6| Step: 4
Training loss: 0.3468840718269348
Validation loss: 1.9333026562967608

Epoch: 6| Step: 5
Training loss: 0.4025794565677643
Validation loss: 1.9129782517751057

Epoch: 6| Step: 6
Training loss: 0.30500978231430054
Validation loss: 1.8948794462347542

Epoch: 6| Step: 7
Training loss: 0.5297671556472778
Validation loss: 1.8537096272232712

Epoch: 6| Step: 8
Training loss: 0.7106605768203735
Validation loss: 1.8605049246100969

Epoch: 6| Step: 9
Training loss: 0.3971654772758484
Validation loss: 1.848447508709405

Epoch: 6| Step: 10
Training loss: 0.6633880138397217
Validation loss: 1.8523375603460497

Epoch: 6| Step: 11
Training loss: 0.25716572999954224
Validation loss: 1.8735469310514388

Epoch: 6| Step: 12
Training loss: 0.7742929458618164
Validation loss: 1.9066794918429466

Epoch: 6| Step: 13
Training loss: 0.5125969648361206
Validation loss: 1.8689800821324831

Epoch: 485| Step: 0
Training loss: 0.6248798370361328
Validation loss: 1.8781086975528347

Epoch: 6| Step: 1
Training loss: 0.5509306192398071
Validation loss: 1.8778048843465827

Epoch: 6| Step: 2
Training loss: 0.44374310970306396
Validation loss: 1.862931630944693

Epoch: 6| Step: 3
Training loss: 0.4368661344051361
Validation loss: 1.8217701117197673

Epoch: 6| Step: 4
Training loss: 0.36276668310165405
Validation loss: 1.832506638701244

Epoch: 6| Step: 5
Training loss: 0.42546185851097107
Validation loss: 1.845844147025898

Epoch: 6| Step: 6
Training loss: 0.35127824544906616
Validation loss: 1.8022715583924325

Epoch: 6| Step: 7
Training loss: 0.3399354815483093
Validation loss: 1.8650989609379922

Epoch: 6| Step: 8
Training loss: 0.4866173267364502
Validation loss: 1.8425915677060363

Epoch: 6| Step: 9
Training loss: 0.356792688369751
Validation loss: 1.8815100962115872

Epoch: 6| Step: 10
Training loss: 0.927747368812561
Validation loss: 1.919750322577774

Epoch: 6| Step: 11
Training loss: 0.2951321303844452
Validation loss: 1.8913347413462978

Epoch: 6| Step: 12
Training loss: 0.48485463857650757
Validation loss: 1.896379150370116

Epoch: 6| Step: 13
Training loss: 0.47870370745658875
Validation loss: 1.9003548288858065

Epoch: 486| Step: 0
Training loss: 0.46718084812164307
Validation loss: 1.8576185600731963

Epoch: 6| Step: 1
Training loss: 0.46440446376800537
Validation loss: 1.868809292393346

Epoch: 6| Step: 2
Training loss: 0.4950238764286041
Validation loss: 1.8323702017466228

Epoch: 6| Step: 3
Training loss: 0.47425639629364014
Validation loss: 1.8111674965068858

Epoch: 6| Step: 4
Training loss: 0.7127954959869385
Validation loss: 1.8516096107421383

Epoch: 6| Step: 5
Training loss: 0.36372023820877075
Validation loss: 1.8655618724002634

Epoch: 6| Step: 6
Training loss: 0.4910048246383667
Validation loss: 1.8609866967765234

Epoch: 6| Step: 7
Training loss: 0.4764268696308136
Validation loss: 1.947429874891876

Epoch: 6| Step: 8
Training loss: 0.7636540532112122
Validation loss: 1.9879497610112673

Epoch: 6| Step: 9
Training loss: 0.3248836100101471
Validation loss: 1.9609862296811995

Epoch: 6| Step: 10
Training loss: 0.49713942408561707
Validation loss: 1.9306955299069803

Epoch: 6| Step: 11
Training loss: 0.39018362760543823
Validation loss: 1.8704479868694017

Epoch: 6| Step: 12
Training loss: 0.4460393786430359
Validation loss: 1.8636389829779183

Epoch: 6| Step: 13
Training loss: 0.9201075434684753
Validation loss: 1.8238755272280784

Epoch: 487| Step: 0
Training loss: 0.7245855927467346
Validation loss: 1.836829968678054

Epoch: 6| Step: 1
Training loss: 0.3574652671813965
Validation loss: 1.8152012645557363

Epoch: 6| Step: 2
Training loss: 0.5126243829727173
Validation loss: 1.8542751522474392

Epoch: 6| Step: 3
Training loss: 0.636669397354126
Validation loss: 1.8620652562828475

Epoch: 6| Step: 4
Training loss: 0.4582117795944214
Validation loss: 1.8969456944414365

Epoch: 6| Step: 5
Training loss: 0.4838334918022156
Validation loss: 1.902289628982544

Epoch: 6| Step: 6
Training loss: 0.2860908806324005
Validation loss: 1.9280159050418484

Epoch: 6| Step: 7
Training loss: 0.29845675826072693
Validation loss: 1.8514339962313253

Epoch: 6| Step: 8
Training loss: 0.589102566242218
Validation loss: 1.8453750866715626

Epoch: 6| Step: 9
Training loss: 0.4835257828235626
Validation loss: 1.7990983916867165

Epoch: 6| Step: 10
Training loss: 0.47695493698120117
Validation loss: 1.7849486797086653

Epoch: 6| Step: 11
Training loss: 0.4511110484600067
Validation loss: 1.7856714674221572

Epoch: 6| Step: 12
Training loss: 0.3219337463378906
Validation loss: 1.794360158263996

Epoch: 6| Step: 13
Training loss: 0.6951753497123718
Validation loss: 1.846711593289529

Epoch: 488| Step: 0
Training loss: 0.44784921407699585
Validation loss: 1.846376129375991

Epoch: 6| Step: 1
Training loss: 0.4258571267127991
Validation loss: 1.870408837513257

Epoch: 6| Step: 2
Training loss: 0.4736776649951935
Validation loss: 1.8564781232546734

Epoch: 6| Step: 3
Training loss: 0.27207767963409424
Validation loss: 1.8669104063382713

Epoch: 6| Step: 4
Training loss: 0.31491345167160034
Validation loss: 1.8553010699569539

Epoch: 6| Step: 5
Training loss: 0.5560659766197205
Validation loss: 1.8200461620925574

Epoch: 6| Step: 6
Training loss: 0.5713731050491333
Validation loss: 1.7901065593124719

Epoch: 6| Step: 7
Training loss: 0.6806996464729309
Validation loss: 1.7594441380552066

Epoch: 6| Step: 8
Training loss: 0.5180916786193848
Validation loss: 1.7829724973247898

Epoch: 6| Step: 9
Training loss: 0.43064969778060913
Validation loss: 1.7373100942181003

Epoch: 6| Step: 10
Training loss: 0.4492730498313904
Validation loss: 1.7967485740620603

Epoch: 6| Step: 11
Training loss: 0.6143245697021484
Validation loss: 1.8107353397594985

Epoch: 6| Step: 12
Training loss: 0.6279725432395935
Validation loss: 1.87587482442138

Epoch: 6| Step: 13
Training loss: 0.8626810312271118
Validation loss: 1.9027123617869552

Epoch: 489| Step: 0
Training loss: 0.45724451541900635
Validation loss: 1.9311152606882074

Epoch: 6| Step: 1
Training loss: 0.6042239665985107
Validation loss: 1.9554553262649044

Epoch: 6| Step: 2
Training loss: 0.4780888855457306
Validation loss: 1.9083833079184256

Epoch: 6| Step: 3
Training loss: 0.7030401229858398
Validation loss: 1.883028289323212

Epoch: 6| Step: 4
Training loss: 0.31048959493637085
Validation loss: 1.8033996961450065

Epoch: 6| Step: 5
Training loss: 0.43920397758483887
Validation loss: 1.7932176231056132

Epoch: 6| Step: 6
Training loss: 0.48877817392349243
Validation loss: 1.795677767005018

Epoch: 6| Step: 7
Training loss: 0.5699213147163391
Validation loss: 1.7792795422256633

Epoch: 6| Step: 8
Training loss: 0.46729928255081177
Validation loss: 1.8230103715773551

Epoch: 6| Step: 9
Training loss: 0.43370479345321655
Validation loss: 1.8966632632799045

Epoch: 6| Step: 10
Training loss: 0.4296254515647888
Validation loss: 1.89915289801936

Epoch: 6| Step: 11
Training loss: 0.48356127738952637
Validation loss: 1.9199530245155416

Epoch: 6| Step: 12
Training loss: 0.5789950489997864
Validation loss: 1.9031782919360745

Epoch: 6| Step: 13
Training loss: 0.5273517966270447
Validation loss: 1.9074869425066057

Epoch: 490| Step: 0
Training loss: 0.5567325353622437
Validation loss: 1.8781864591824111

Epoch: 6| Step: 1
Training loss: 0.3122352957725525
Validation loss: 1.84591055557292

Epoch: 6| Step: 2
Training loss: 0.5721057653427124
Validation loss: 1.7876544972901702

Epoch: 6| Step: 3
Training loss: 0.5716017484664917
Validation loss: 1.7835056884314424

Epoch: 6| Step: 4
Training loss: 0.6282927393913269
Validation loss: 1.7572240906376992

Epoch: 6| Step: 5
Training loss: 0.4603933095932007
Validation loss: 1.7455074146229734

Epoch: 6| Step: 6
Training loss: 0.6344444751739502
Validation loss: 1.7686588251462547

Epoch: 6| Step: 7
Training loss: 0.5800867676734924
Validation loss: 1.805355715495284

Epoch: 6| Step: 8
Training loss: 0.5354443788528442
Validation loss: 1.8309800330028738

Epoch: 6| Step: 9
Training loss: 0.213749498128891
Validation loss: 1.8517327424018615

Epoch: 6| Step: 10
Training loss: 0.29693716764450073
Validation loss: 1.8600845362550469

Epoch: 6| Step: 11
Training loss: 0.320402055978775
Validation loss: 1.8657746020183767

Epoch: 6| Step: 12
Training loss: 0.6465195417404175
Validation loss: 1.8584468172442528

Epoch: 6| Step: 13
Training loss: 0.2803325057029724
Validation loss: 1.8708351953055269

Epoch: 491| Step: 0
Training loss: 0.5378544926643372
Validation loss: 1.873052163790631

Epoch: 6| Step: 1
Training loss: 0.4849010109901428
Validation loss: 1.8465211263266943

Epoch: 6| Step: 2
Training loss: 0.4692284166812897
Validation loss: 1.8581714501944921

Epoch: 6| Step: 3
Training loss: 0.4743746519088745
Validation loss: 1.8201267475722938

Epoch: 6| Step: 4
Training loss: 0.5483624339103699
Validation loss: 1.8237928331539195

Epoch: 6| Step: 5
Training loss: 0.4230528175830841
Validation loss: 1.845480623424694

Epoch: 6| Step: 6
Training loss: 0.5338499546051025
Validation loss: 1.8442405808356501

Epoch: 6| Step: 7
Training loss: 0.3388209939002991
Validation loss: 1.8627895027078607

Epoch: 6| Step: 8
Training loss: 0.43301334977149963
Validation loss: 1.9175406066320275

Epoch: 6| Step: 9
Training loss: 0.39230841398239136
Validation loss: 1.9104648392687562

Epoch: 6| Step: 10
Training loss: 0.6354591846466064
Validation loss: 1.9260935655204199

Epoch: 6| Step: 11
Training loss: 0.30859559774398804
Validation loss: 1.8956724315561273

Epoch: 6| Step: 12
Training loss: 0.38398510217666626
Validation loss: 1.922895541755102

Epoch: 6| Step: 13
Training loss: 0.6667125225067139
Validation loss: 1.8643707306154313

Epoch: 492| Step: 0
Training loss: 0.3486520051956177
Validation loss: 1.8669615996781217

Epoch: 6| Step: 1
Training loss: 0.5442348122596741
Validation loss: 1.8691117122609129

Epoch: 6| Step: 2
Training loss: 0.6875567436218262
Validation loss: 1.8824846026717976

Epoch: 6| Step: 3
Training loss: 0.5607930421829224
Validation loss: 1.8334272523080148

Epoch: 6| Step: 4
Training loss: 0.46196919679641724
Validation loss: 1.8063484981495848

Epoch: 6| Step: 5
Training loss: 0.2737088203430176
Validation loss: 1.7920554196962746

Epoch: 6| Step: 6
Training loss: 0.6106215715408325
Validation loss: 1.8276183400102841

Epoch: 6| Step: 7
Training loss: 0.5495911836624146
Validation loss: 1.8131317861618534

Epoch: 6| Step: 8
Training loss: 0.37261486053466797
Validation loss: 1.8104374011357625

Epoch: 6| Step: 9
Training loss: 0.33410006761550903
Validation loss: 1.7909740068579232

Epoch: 6| Step: 10
Training loss: 0.3091820478439331
Validation loss: 1.8286058954013291

Epoch: 6| Step: 11
Training loss: 0.4022716283798218
Validation loss: 1.8324142656018656

Epoch: 6| Step: 12
Training loss: 0.7943152785301208
Validation loss: 1.9224898276790496

Epoch: 6| Step: 13
Training loss: 0.25164392590522766
Validation loss: 1.9213982884601881

Epoch: 493| Step: 0
Training loss: 0.4147814214229584
Validation loss: 1.9980279014956566

Epoch: 6| Step: 1
Training loss: 0.637933611869812
Validation loss: 1.9476747589726602

Epoch: 6| Step: 2
Training loss: 0.411849707365036
Validation loss: 1.8942918303192302

Epoch: 6| Step: 3
Training loss: 0.33903956413269043
Validation loss: 1.8301393165383288

Epoch: 6| Step: 4
Training loss: 0.241468608379364
Validation loss: 1.8090151638113043

Epoch: 6| Step: 5
Training loss: 0.5222487449645996
Validation loss: 1.8018163173429427

Epoch: 6| Step: 6
Training loss: 0.36141490936279297
Validation loss: 1.7884051184500418

Epoch: 6| Step: 7
Training loss: 0.5100945234298706
Validation loss: 1.8037018801576348

Epoch: 6| Step: 8
Training loss: 0.6166983842849731
Validation loss: 1.7949689562602709

Epoch: 6| Step: 9
Training loss: 0.5898302793502808
Validation loss: 1.8194586077044088

Epoch: 6| Step: 10
Training loss: 0.4768672287464142
Validation loss: 1.8220096019006544

Epoch: 6| Step: 11
Training loss: 0.39184531569480896
Validation loss: 1.869132164985903

Epoch: 6| Step: 12
Training loss: 0.9827426075935364
Validation loss: 1.946297994223974

Epoch: 6| Step: 13
Training loss: 0.46992629766464233
Validation loss: 1.9763746287233086

Epoch: 494| Step: 0
Training loss: 0.6776593923568726
Validation loss: 1.9462407301830988

Epoch: 6| Step: 1
Training loss: 0.6107074618339539
Validation loss: 1.8922301466746996

Epoch: 6| Step: 2
Training loss: 0.5508056282997131
Validation loss: 1.8558697085226736

Epoch: 6| Step: 3
Training loss: 0.2607184946537018
Validation loss: 1.8720851393156155

Epoch: 6| Step: 4
Training loss: 0.8260307908058167
Validation loss: 1.8129659878310336

Epoch: 6| Step: 5
Training loss: 0.38636618852615356
Validation loss: 1.8028387869558027

Epoch: 6| Step: 6
Training loss: 0.41062986850738525
Validation loss: 1.8027247998022264

Epoch: 6| Step: 7
Training loss: 0.6217595338821411
Validation loss: 1.8167336217818721

Epoch: 6| Step: 8
Training loss: 0.3741552233695984
Validation loss: 1.8380137784506685

Epoch: 6| Step: 9
Training loss: 0.2516719400882721
Validation loss: 1.8548171366414716

Epoch: 6| Step: 10
Training loss: 0.49943333864212036
Validation loss: 1.8347222484568113

Epoch: 6| Step: 11
Training loss: 0.39246806502342224
Validation loss: 1.8673351067368702

Epoch: 6| Step: 12
Training loss: 0.3913503885269165
Validation loss: 1.8529836490590086

Epoch: 6| Step: 13
Training loss: 0.4209068715572357
Validation loss: 1.8100121610908098

Epoch: 495| Step: 0
Training loss: 0.4540829360485077
Validation loss: 1.8502014311411048

Epoch: 6| Step: 1
Training loss: 0.400837779045105
Validation loss: 1.8491944946268553

Epoch: 6| Step: 2
Training loss: 0.3923070728778839
Validation loss: 1.840440397621483

Epoch: 6| Step: 3
Training loss: 0.49898797273635864
Validation loss: 1.87301101223115

Epoch: 6| Step: 4
Training loss: 0.931187629699707
Validation loss: 1.8743382653882426

Epoch: 6| Step: 5
Training loss: 0.7319049835205078
Validation loss: 1.8476647830778552

Epoch: 6| Step: 6
Training loss: 0.41013404726982117
Validation loss: 1.860291551518184

Epoch: 6| Step: 7
Training loss: 0.44379112124443054
Validation loss: 1.8572893475973478

Epoch: 6| Step: 8
Training loss: 0.27518197894096375
Validation loss: 1.8532761399463942

Epoch: 6| Step: 9
Training loss: 0.2155434489250183
Validation loss: 1.8702388527572795

Epoch: 6| Step: 10
Training loss: 0.5619904398918152
Validation loss: 1.8400994654624694

Epoch: 6| Step: 11
Training loss: 0.5397002696990967
Validation loss: 1.8291400773550874

Epoch: 6| Step: 12
Training loss: 0.30728086829185486
Validation loss: 1.877867055195634

Epoch: 6| Step: 13
Training loss: 0.44213852286338806
Validation loss: 1.8523317395999868

Epoch: 496| Step: 0
Training loss: 0.626814067363739
Validation loss: 1.8474809687624696

Epoch: 6| Step: 1
Training loss: 0.2832832336425781
Validation loss: 1.881760520319785

Epoch: 6| Step: 2
Training loss: 0.3289136290550232
Validation loss: 1.8613433966072657

Epoch: 6| Step: 3
Training loss: 0.24980869889259338
Validation loss: 1.8468658360101844

Epoch: 6| Step: 4
Training loss: 0.29255732893943787
Validation loss: 1.8267049007518317

Epoch: 6| Step: 5
Training loss: 0.33139926195144653
Validation loss: 1.7903447471639162

Epoch: 6| Step: 6
Training loss: 0.5494248867034912
Validation loss: 1.8593921379376483

Epoch: 6| Step: 7
Training loss: 0.4725778102874756
Validation loss: 1.8548568974259079

Epoch: 6| Step: 8
Training loss: 0.6086817979812622
Validation loss: 1.816492936944449

Epoch: 6| Step: 9
Training loss: 0.8130943775177002
Validation loss: 1.801418666557599

Epoch: 6| Step: 10
Training loss: 0.40349534153938293
Validation loss: 1.8169875708959435

Epoch: 6| Step: 11
Training loss: 0.4962701201438904
Validation loss: 1.7980569306240286

Epoch: 6| Step: 12
Training loss: 0.5938417911529541
Validation loss: 1.8314543885569419

Epoch: 6| Step: 13
Training loss: 0.1916959136724472
Validation loss: 1.8981562558040823

Epoch: 497| Step: 0
Training loss: 0.36086609959602356
Validation loss: 1.9118109877391527

Epoch: 6| Step: 1
Training loss: 0.406488835811615
Validation loss: 1.904671343423987

Epoch: 6| Step: 2
Training loss: 0.45363205671310425
Validation loss: 1.906574974777878

Epoch: 6| Step: 3
Training loss: 0.25667911767959595
Validation loss: 1.887637499840029

Epoch: 6| Step: 4
Training loss: 0.5343062877655029
Validation loss: 1.863292783819219

Epoch: 6| Step: 5
Training loss: 0.4274899959564209
Validation loss: 1.8624769513325026

Epoch: 6| Step: 6
Training loss: 0.47174906730651855
Validation loss: 1.8458544233793854

Epoch: 6| Step: 7
Training loss: 0.6978110074996948
Validation loss: 1.8552197769124021

Epoch: 6| Step: 8
Training loss: 0.6906746625900269
Validation loss: 1.84735801271213

Epoch: 6| Step: 9
Training loss: 0.19664865732192993
Validation loss: 1.8625390683451006

Epoch: 6| Step: 10
Training loss: 0.3287869691848755
Validation loss: 1.8650948142492643

Epoch: 6| Step: 11
Training loss: 0.664565920829773
Validation loss: 1.8709402994443012

Epoch: 6| Step: 12
Training loss: 0.35311201214790344
Validation loss: 1.8157661525152062

Epoch: 6| Step: 13
Training loss: 0.4866335093975067
Validation loss: 1.8224379708690028

Epoch: 498| Step: 0
Training loss: 0.5389927625656128
Validation loss: 1.7925376610089374

Epoch: 6| Step: 1
Training loss: 0.4306460916996002
Validation loss: 1.7376974833908903

Epoch: 6| Step: 2
Training loss: 0.4062691330909729
Validation loss: 1.7614024108456028

Epoch: 6| Step: 3
Training loss: 0.3527514338493347
Validation loss: 1.7614623013363089

Epoch: 6| Step: 4
Training loss: 0.5954321026802063
Validation loss: 1.7954264968954108

Epoch: 6| Step: 5
Training loss: 0.3921469748020172
Validation loss: 1.795214553033152

Epoch: 6| Step: 6
Training loss: 0.5512746572494507
Validation loss: 1.8342981261591758

Epoch: 6| Step: 7
Training loss: 0.41296660900115967
Validation loss: 1.8945189727249967

Epoch: 6| Step: 8
Training loss: 0.586634635925293
Validation loss: 1.9280904762206539

Epoch: 6| Step: 9
Training loss: 0.37360385060310364
Validation loss: 1.9398817605869745

Epoch: 6| Step: 10
Training loss: 0.4218097925186157
Validation loss: 1.91831519398638

Epoch: 6| Step: 11
Training loss: 0.5922685265541077
Validation loss: 1.8712352834722048

Epoch: 6| Step: 12
Training loss: 0.7067036032676697
Validation loss: 1.8423178490772043

Epoch: 6| Step: 13
Training loss: 0.14276328682899475
Validation loss: 1.8257468092826106

Epoch: 499| Step: 0
Training loss: 0.31061044335365295
Validation loss: 1.8126210307562223

Epoch: 6| Step: 1
Training loss: 0.5083405375480652
Validation loss: 1.7502414795660204

Epoch: 6| Step: 2
Training loss: 0.2890745997428894
Validation loss: 1.7694727618207213

Epoch: 6| Step: 3
Training loss: 0.6845179200172424
Validation loss: 1.7086601718779533

Epoch: 6| Step: 4
Training loss: 0.48181065917015076
Validation loss: 1.7843273596097065

Epoch: 6| Step: 5
Training loss: 0.46919968724250793
Validation loss: 1.7789182791145899

Epoch: 6| Step: 6
Training loss: 0.3743211627006531
Validation loss: 1.8437398326012395

Epoch: 6| Step: 7
Training loss: 0.837721049785614
Validation loss: 1.8754636036452426

Epoch: 6| Step: 8
Training loss: 0.36375606060028076
Validation loss: 1.8956615155743015

Epoch: 6| Step: 9
Training loss: 0.3857458233833313
Validation loss: 1.8878347771142119

Epoch: 6| Step: 10
Training loss: 0.3342120349407196
Validation loss: 1.8579375590047529

Epoch: 6| Step: 11
Training loss: 0.26427900791168213
Validation loss: 1.832495706055754

Epoch: 6| Step: 12
Training loss: 0.5838274955749512
Validation loss: 1.7906675364381524

Epoch: 6| Step: 13
Training loss: 0.517996072769165
Validation loss: 1.8022581492700884

Epoch: 500| Step: 0
Training loss: 0.41718941926956177
Validation loss: 1.7992723808493665

Epoch: 6| Step: 1
Training loss: 0.5004967451095581
Validation loss: 1.8018840205284856

Epoch: 6| Step: 2
Training loss: 0.3979511857032776
Validation loss: 1.8573913266581874

Epoch: 6| Step: 3
Training loss: 0.26460057497024536
Validation loss: 1.8547474722708426

Epoch: 6| Step: 4
Training loss: 0.5301259160041809
Validation loss: 1.8564016742091025

Epoch: 6| Step: 5
Training loss: 0.39672863483428955
Validation loss: 1.9073871156220794

Epoch: 6| Step: 6
Training loss: 0.5101151466369629
Validation loss: 1.8648925635122484

Epoch: 6| Step: 7
Training loss: 0.4833804666996002
Validation loss: 1.8338607741940407

Epoch: 6| Step: 8
Training loss: 0.5171788930892944
Validation loss: 1.8465279443289644

Epoch: 6| Step: 9
Training loss: 0.3508899211883545
Validation loss: 1.813370946914919

Epoch: 6| Step: 10
Training loss: 0.6270966529846191
Validation loss: 1.8000531696504163

Epoch: 6| Step: 11
Training loss: 0.5198580026626587
Validation loss: 1.8753198449329664

Epoch: 6| Step: 12
Training loss: 0.3766224980354309
Validation loss: 1.8211496978677728

Epoch: 6| Step: 13
Training loss: 0.610500693321228
Validation loss: 1.8270887726096696

Epoch: 501| Step: 0
Training loss: 0.5566151738166809
Validation loss: 1.8546452701732676

Epoch: 6| Step: 1
Training loss: 0.4368784725666046
Validation loss: 1.8563778323511924

Epoch: 6| Step: 2
Training loss: 0.26072555780410767
Validation loss: 1.8648679243621005

Epoch: 6| Step: 3
Training loss: 0.3811095058917999
Validation loss: 1.8439714754781416

Epoch: 6| Step: 4
Training loss: 0.5152292251586914
Validation loss: 1.8499606796490249

Epoch: 6| Step: 5
Training loss: 0.4509350657463074
Validation loss: 1.852769942693813

Epoch: 6| Step: 6
Training loss: 0.2697567939758301
Validation loss: 1.785363926682421

Epoch: 6| Step: 7
Training loss: 0.3697047531604767
Validation loss: 1.8027403354644775

Epoch: 6| Step: 8
Training loss: 0.4075901508331299
Validation loss: 1.797025748478469

Epoch: 6| Step: 9
Training loss: 0.526026725769043
Validation loss: 1.8113128869764266

Epoch: 6| Step: 10
Training loss: 0.5775585770606995
Validation loss: 1.8168608552666121

Epoch: 6| Step: 11
Training loss: 0.31266358494758606
Validation loss: 1.7826488069308701

Epoch: 6| Step: 12
Training loss: 0.4287780523300171
Validation loss: 1.8112350830467798

Epoch: 6| Step: 13
Training loss: 0.20030206441879272
Validation loss: 1.8286455433855775

Epoch: 502| Step: 0
Training loss: 0.4056321680545807
Validation loss: 1.851478659978477

Epoch: 6| Step: 1
Training loss: 0.2342839539051056
Validation loss: 1.8141279682036369

Epoch: 6| Step: 2
Training loss: 0.5099412202835083
Validation loss: 1.841339026727984

Epoch: 6| Step: 3
Training loss: 0.5585917234420776
Validation loss: 1.8757993252046647

Epoch: 6| Step: 4
Training loss: 0.2178000807762146
Validation loss: 1.881955837690702

Epoch: 6| Step: 5
Training loss: 0.5032384395599365
Validation loss: 1.8587978604019328

Epoch: 6| Step: 6
Training loss: 0.786565899848938
Validation loss: 1.816796419441059

Epoch: 6| Step: 7
Training loss: 0.4136166572570801
Validation loss: 1.8027503798084874

Epoch: 6| Step: 8
Training loss: 0.27958130836486816
Validation loss: 1.7648613888730285

Epoch: 6| Step: 9
Training loss: 0.6019283533096313
Validation loss: 1.7655636559250534

Epoch: 6| Step: 10
Training loss: 0.5118418335914612
Validation loss: 1.733620225742299

Epoch: 6| Step: 11
Training loss: 0.4883996248245239
Validation loss: 1.7416153479647893

Epoch: 6| Step: 12
Training loss: 0.44520819187164307
Validation loss: 1.780666857637385

Epoch: 6| Step: 13
Training loss: 0.6112978458404541
Validation loss: 1.7957646052042644

Epoch: 503| Step: 0
Training loss: 0.3910944163799286
Validation loss: 1.8438303675702823

Epoch: 6| Step: 1
Training loss: 0.3290473222732544
Validation loss: 1.9316537790401007

Epoch: 6| Step: 2
Training loss: 0.5080211758613586
Validation loss: 1.9575886200833064

Epoch: 6| Step: 3
Training loss: 0.6563347578048706
Validation loss: 1.8938866443531488

Epoch: 6| Step: 4
Training loss: 0.2809584438800812
Validation loss: 1.8260565239896056

Epoch: 6| Step: 5
Training loss: 0.5395396947860718
Validation loss: 1.7633344409286336

Epoch: 6| Step: 6
Training loss: 0.5764840841293335
Validation loss: 1.7600987713824037

Epoch: 6| Step: 7
Training loss: 0.5681108236312866
Validation loss: 1.739049598734866

Epoch: 6| Step: 8
Training loss: 0.5134350061416626
Validation loss: 1.7821494404987623

Epoch: 6| Step: 9
Training loss: 0.8003487586975098
Validation loss: 1.778454775451332

Epoch: 6| Step: 10
Training loss: 0.4338259994983673
Validation loss: 1.8054717125431183

Epoch: 6| Step: 11
Training loss: 0.353371798992157
Validation loss: 1.870521935083533

Epoch: 6| Step: 12
Training loss: 0.6892305612564087
Validation loss: 1.8832470409331783

Epoch: 6| Step: 13
Training loss: 0.5003472566604614
Validation loss: 1.8982518199951417

Epoch: 504| Step: 0
Training loss: 0.34538745880126953
Validation loss: 1.9047665621644707

Epoch: 6| Step: 1
Training loss: 0.5092331767082214
Validation loss: 1.9499551224452194

Epoch: 6| Step: 2
Training loss: 0.5036723613739014
Validation loss: 1.9465269888600996

Epoch: 6| Step: 3
Training loss: 0.6267447471618652
Validation loss: 1.8875901865702804

Epoch: 6| Step: 4
Training loss: 0.4295077323913574
Validation loss: 1.8316082736497283

Epoch: 6| Step: 5
Training loss: 0.5912366509437561
Validation loss: 1.808716502240909

Epoch: 6| Step: 6
Training loss: 0.601508617401123
Validation loss: 1.7270761689832133

Epoch: 6| Step: 7
Training loss: 0.5015783309936523
Validation loss: 1.7973635145412978

Epoch: 6| Step: 8
Training loss: 0.7822573781013489
Validation loss: 1.8286805870712444

Epoch: 6| Step: 9
Training loss: 0.563721776008606
Validation loss: 1.8281529808557162

Epoch: 6| Step: 10
Training loss: 0.7611268162727356
Validation loss: 1.8776866466768327

Epoch: 6| Step: 11
Training loss: 0.21908384561538696
Validation loss: 1.8872149887905325

Epoch: 6| Step: 12
Training loss: 0.5007871389389038
Validation loss: 1.918026469087088

Epoch: 6| Step: 13
Training loss: 0.7442602515220642
Validation loss: 1.9361698140380204

Epoch: 505| Step: 0
Training loss: 0.6104844212532043
Validation loss: 1.8833541203570623

Epoch: 6| Step: 1
Training loss: 0.4608498513698578
Validation loss: 1.8140704772805656

Epoch: 6| Step: 2
Training loss: 0.46354013681411743
Validation loss: 1.8179463173753472

Epoch: 6| Step: 3
Training loss: 0.6721467971801758
Validation loss: 1.7785432325896395

Epoch: 6| Step: 4
Training loss: 0.6541897654533386
Validation loss: 1.7535434794682327

Epoch: 6| Step: 5
Training loss: 0.33591943979263306
Validation loss: 1.7846555389383787

Epoch: 6| Step: 6
Training loss: 0.4151853024959564
Validation loss: 1.8138498413947322

Epoch: 6| Step: 7
Training loss: 0.368464857339859
Validation loss: 1.8406065330710462

Epoch: 6| Step: 8
Training loss: 0.7039674520492554
Validation loss: 1.9169198236157816

Epoch: 6| Step: 9
Training loss: 0.5112455487251282
Validation loss: 1.9814325019877443

Epoch: 6| Step: 10
Training loss: 0.4289022386074066
Validation loss: 1.9773765033291233

Epoch: 6| Step: 11
Training loss: 0.4941596984863281
Validation loss: 1.9325475256930116

Epoch: 6| Step: 12
Training loss: 0.471353679895401
Validation loss: 1.9146383411140853

Epoch: 6| Step: 13
Training loss: 0.5582325458526611
Validation loss: 1.8702773765851093

Epoch: 506| Step: 0
Training loss: 0.6107544898986816
Validation loss: 1.821591466985723

Epoch: 6| Step: 1
Training loss: 0.3436165452003479
Validation loss: 1.771049662302899

Epoch: 6| Step: 2
Training loss: 0.27112722396850586
Validation loss: 1.7834032171516008

Epoch: 6| Step: 3
Training loss: 0.43216878175735474
Validation loss: 1.8170726555649952

Epoch: 6| Step: 4
Training loss: 0.7591415643692017
Validation loss: 1.8280687973063479

Epoch: 6| Step: 5
Training loss: 0.3163256049156189
Validation loss: 1.8303234987361456

Epoch: 6| Step: 6
Training loss: 0.49879711866378784
Validation loss: 1.8506762020049556

Epoch: 6| Step: 7
Training loss: 0.5153933167457581
Validation loss: 1.8844977783900436

Epoch: 6| Step: 8
Training loss: 0.35670047998428345
Validation loss: 1.931399844026053

Epoch: 6| Step: 9
Training loss: 0.4684493839740753
Validation loss: 1.9398375262496292

Epoch: 6| Step: 10
Training loss: 0.6028045415878296
Validation loss: 1.9698285325880973

Epoch: 6| Step: 11
Training loss: 0.389102578163147
Validation loss: 1.9839150162153347

Epoch: 6| Step: 12
Training loss: 0.5125868320465088
Validation loss: 1.962799032529195

Epoch: 6| Step: 13
Training loss: 0.6793242692947388
Validation loss: 1.9050263781701364

Epoch: 507| Step: 0
Training loss: 0.5830720663070679
Validation loss: 1.871889470725931

Epoch: 6| Step: 1
Training loss: 0.7197041511535645
Validation loss: 1.8257757104853147

Epoch: 6| Step: 2
Training loss: 0.4448665678501129
Validation loss: 1.8346221203445106

Epoch: 6| Step: 3
Training loss: 0.49950921535491943
Validation loss: 1.7850590649471487

Epoch: 6| Step: 4
Training loss: 0.42109981179237366
Validation loss: 1.7987986162144651

Epoch: 6| Step: 5
Training loss: 0.3706909418106079
Validation loss: 1.7783588542733142

Epoch: 6| Step: 6
Training loss: 0.5595062971115112
Validation loss: 1.7956413607443533

Epoch: 6| Step: 7
Training loss: 0.25944072008132935
Validation loss: 1.7969616279807141

Epoch: 6| Step: 8
Training loss: 0.42239251732826233
Validation loss: 1.8363496975232196

Epoch: 6| Step: 9
Training loss: 0.27361196279525757
Validation loss: 1.8561457933918122

Epoch: 6| Step: 10
Training loss: 0.5033560395240784
Validation loss: 1.857102878632084

Epoch: 6| Step: 11
Training loss: 0.30641233921051025
Validation loss: 1.9153786384931175

Epoch: 6| Step: 12
Training loss: 0.3755893111228943
Validation loss: 1.9136607294441552

Epoch: 6| Step: 13
Training loss: 0.45452138781547546
Validation loss: 1.905573162981259

Epoch: 508| Step: 0
Training loss: 0.5841027498245239
Validation loss: 1.9234662696879397

Epoch: 6| Step: 1
Training loss: 0.3486846685409546
Validation loss: 1.8958197844925748

Epoch: 6| Step: 2
Training loss: 0.37986093759536743
Validation loss: 1.8320646817966173

Epoch: 6| Step: 3
Training loss: 0.22451569139957428
Validation loss: 1.8231916863431212

Epoch: 6| Step: 4
Training loss: 0.47010958194732666
Validation loss: 1.781452481464673

Epoch: 6| Step: 5
Training loss: 0.3109424412250519
Validation loss: 1.782553224153416

Epoch: 6| Step: 6
Training loss: 0.5981854200363159
Validation loss: 1.7621027884944793

Epoch: 6| Step: 7
Training loss: 0.8064996004104614
Validation loss: 1.7578031875753914

Epoch: 6| Step: 8
Training loss: 0.48498570919036865
Validation loss: 1.7624227218730475

Epoch: 6| Step: 9
Training loss: 0.392132431268692
Validation loss: 1.7979316711425781

Epoch: 6| Step: 10
Training loss: 0.5893068313598633
Validation loss: 1.806583789087111

Epoch: 6| Step: 11
Training loss: 0.3450140953063965
Validation loss: 1.8464649582421908

Epoch: 6| Step: 12
Training loss: 0.2946716248989105
Validation loss: 1.874064483950215

Epoch: 6| Step: 13
Training loss: 0.6322872638702393
Validation loss: 1.9216797608201222

Epoch: 509| Step: 0
Training loss: 0.5510359406471252
Validation loss: 1.9021421286367601

Epoch: 6| Step: 1
Training loss: 0.3641550838947296
Validation loss: 1.8678070114504906

Epoch: 6| Step: 2
Training loss: 0.2215123474597931
Validation loss: 1.873625132345384

Epoch: 6| Step: 3
Training loss: 0.46219903230667114
Validation loss: 1.8171203623535812

Epoch: 6| Step: 4
Training loss: 0.2939741611480713
Validation loss: 1.794072671603131

Epoch: 6| Step: 5
Training loss: 0.42937296628952026
Validation loss: 1.7844647643386677

Epoch: 6| Step: 6
Training loss: 0.3056706190109253
Validation loss: 1.77773299524861

Epoch: 6| Step: 7
Training loss: 0.6340843439102173
Validation loss: 1.804631733125256

Epoch: 6| Step: 8
Training loss: 0.28194284439086914
Validation loss: 1.7839202855222969

Epoch: 6| Step: 9
Training loss: 0.6118991374969482
Validation loss: 1.7941165431853263

Epoch: 6| Step: 10
Training loss: 0.360585480928421
Validation loss: 1.8318523822292205

Epoch: 6| Step: 11
Training loss: 0.3975823223590851
Validation loss: 1.8159549069660965

Epoch: 6| Step: 12
Training loss: 0.8904528617858887
Validation loss: 1.8842210859380744

Epoch: 6| Step: 13
Training loss: 0.16446873545646667
Validation loss: 1.8544479236807874

Epoch: 510| Step: 0
Training loss: 0.5130351185798645
Validation loss: 1.8138992363406765

Epoch: 6| Step: 1
Training loss: 0.3233683705329895
Validation loss: 1.809000603614315

Epoch: 6| Step: 2
Training loss: 0.6166143417358398
Validation loss: 1.7663339722541072

Epoch: 6| Step: 3
Training loss: 0.21369709074497223
Validation loss: 1.8540441413079538

Epoch: 6| Step: 4
Training loss: 0.5030103325843811
Validation loss: 1.829176305442728

Epoch: 6| Step: 5
Training loss: 0.38571250438690186
Validation loss: 1.8476512611553233

Epoch: 6| Step: 6
Training loss: 0.4379265308380127
Validation loss: 1.8579292079453826

Epoch: 6| Step: 7
Training loss: 0.6199074387550354
Validation loss: 1.874439775302846

Epoch: 6| Step: 8
Training loss: 0.53473299741745
Validation loss: 1.8766470750172932

Epoch: 6| Step: 9
Training loss: 0.38426297903060913
Validation loss: 1.8463177091331893

Epoch: 6| Step: 10
Training loss: 0.3711875081062317
Validation loss: 1.8252813072614773

Epoch: 6| Step: 11
Training loss: 0.22284850478172302
Validation loss: 1.8068777861133698

Epoch: 6| Step: 12
Training loss: 0.4018678069114685
Validation loss: 1.8192326099641862

Epoch: 6| Step: 13
Training loss: 0.3753594756126404
Validation loss: 1.8237531210786553

Epoch: 511| Step: 0
Training loss: 0.21011166274547577
Validation loss: 1.824173617106612

Epoch: 6| Step: 1
Training loss: 0.39871686697006226
Validation loss: 1.854268871327882

Epoch: 6| Step: 2
Training loss: 0.3796555995941162
Validation loss: 1.8607919754520539

Epoch: 6| Step: 3
Training loss: 0.30144646763801575
Validation loss: 1.8200165802432644

Epoch: 6| Step: 4
Training loss: 0.24091941118240356
Validation loss: 1.8059303914347002

Epoch: 6| Step: 5
Training loss: 0.3812686800956726
Validation loss: 1.7523541271045644

Epoch: 6| Step: 6
Training loss: 0.40124762058258057
Validation loss: 1.752624181009108

Epoch: 6| Step: 7
Training loss: 0.6906072497367859
Validation loss: 1.759075810832362

Epoch: 6| Step: 8
Training loss: 0.2852403521537781
Validation loss: 1.7523399629900533

Epoch: 6| Step: 9
Training loss: 0.22569943964481354
Validation loss: 1.7721170135723647

Epoch: 6| Step: 10
Training loss: 0.5058114528656006
Validation loss: 1.83770969734397

Epoch: 6| Step: 11
Training loss: 0.5018343925476074
Validation loss: 1.8520922160917712

Epoch: 6| Step: 12
Training loss: 0.6538508534431458
Validation loss: 1.892542936468637

Epoch: 6| Step: 13
Training loss: 0.9199153184890747
Validation loss: 1.8761853633388397

Epoch: 512| Step: 0
Training loss: 0.3500557541847229
Validation loss: 1.8751663648954002

Epoch: 6| Step: 1
Training loss: 0.5912734866142273
Validation loss: 1.8752749491763372

Epoch: 6| Step: 2
Training loss: 0.3053891062736511
Validation loss: 1.7971662564944195

Epoch: 6| Step: 3
Training loss: 0.5088531970977783
Validation loss: 1.7766243757740143

Epoch: 6| Step: 4
Training loss: 0.3396976590156555
Validation loss: 1.7482189337412517

Epoch: 6| Step: 5
Training loss: 0.4189973473548889
Validation loss: 1.7920342312064221

Epoch: 6| Step: 6
Training loss: 0.4309720993041992
Validation loss: 1.7837382798553796

Epoch: 6| Step: 7
Training loss: 0.5696460008621216
Validation loss: 1.8009098447779173

Epoch: 6| Step: 8
Training loss: 0.4538213610649109
Validation loss: 1.8232825033126339

Epoch: 6| Step: 9
Training loss: 0.20098066329956055
Validation loss: 1.7780963733632078

Epoch: 6| Step: 10
Training loss: 0.519176185131073
Validation loss: 1.789133346208962

Epoch: 6| Step: 11
Training loss: 0.1312984824180603
Validation loss: 1.8176174035636328

Epoch: 6| Step: 12
Training loss: 0.5085926055908203
Validation loss: 1.8461657557436215

Epoch: 6| Step: 13
Training loss: 0.30231067538261414
Validation loss: 1.9122878761701687

Epoch: 513| Step: 0
Training loss: 0.41456711292266846
Validation loss: 1.9412981156379945

Epoch: 6| Step: 1
Training loss: 0.5948184728622437
Validation loss: 1.9382997751235962

Epoch: 6| Step: 2
Training loss: 0.49927014112472534
Validation loss: 1.8837780337179861

Epoch: 6| Step: 3
Training loss: 0.33903345465660095
Validation loss: 1.8241692255902033

Epoch: 6| Step: 4
Training loss: 0.280769944190979
Validation loss: 1.8010942551397509

Epoch: 6| Step: 5
Training loss: 0.2016642987728119
Validation loss: 1.7656993622420936

Epoch: 6| Step: 6
Training loss: 0.5207376480102539
Validation loss: 1.7721939138186875

Epoch: 6| Step: 7
Training loss: 0.5680352449417114
Validation loss: 1.7993525061556088

Epoch: 6| Step: 8
Training loss: 0.6451526284217834
Validation loss: 1.7963309505934357

Epoch: 6| Step: 9
Training loss: 0.44601404666900635
Validation loss: 1.7921526406400947

Epoch: 6| Step: 10
Training loss: 0.47998079657554626
Validation loss: 1.8185765397164129

Epoch: 6| Step: 11
Training loss: 0.4735257625579834
Validation loss: 1.8522991262456423

Epoch: 6| Step: 12
Training loss: 0.3858642578125
Validation loss: 1.9118091880634267

Epoch: 6| Step: 13
Training loss: 0.4011285901069641
Validation loss: 1.9766798275773243

Epoch: 514| Step: 0
Training loss: 0.625705361366272
Validation loss: 1.974196994176475

Epoch: 6| Step: 1
Training loss: 0.5421559810638428
Validation loss: 1.9029430573986423

Epoch: 6| Step: 2
Training loss: 0.5627611875534058
Validation loss: 1.8072205000026251

Epoch: 6| Step: 3
Training loss: 0.49716657400131226
Validation loss: 1.8179322327336958

Epoch: 6| Step: 4
Training loss: 0.4623003602027893
Validation loss: 1.7355020533325851

Epoch: 6| Step: 5
Training loss: 0.29310232400894165
Validation loss: 1.7478196518395537

Epoch: 6| Step: 6
Training loss: 0.36697670817375183
Validation loss: 1.7611916270307315

Epoch: 6| Step: 7
Training loss: 0.3828083276748657
Validation loss: 1.7525429225737048

Epoch: 6| Step: 8
Training loss: 0.482248991727829
Validation loss: 1.764769684883856

Epoch: 6| Step: 9
Training loss: 0.27179357409477234
Validation loss: 1.8131065932653283

Epoch: 6| Step: 10
Training loss: 0.3066943287849426
Validation loss: 1.8373254127399896

Epoch: 6| Step: 11
Training loss: 0.1714458167552948
Validation loss: 1.8839211720292286

Epoch: 6| Step: 12
Training loss: 0.2284037172794342
Validation loss: 1.8765416273506739

Epoch: 6| Step: 13
Training loss: 0.9074937105178833
Validation loss: 1.9146398882712088

Epoch: 515| Step: 0
Training loss: 0.6123895645141602
Validation loss: 1.943089380059191

Epoch: 6| Step: 1
Training loss: 0.355451762676239
Validation loss: 1.8740108884790891

Epoch: 6| Step: 2
Training loss: 0.5309421420097351
Validation loss: 1.8400013472444268

Epoch: 6| Step: 3
Training loss: 0.40351390838623047
Validation loss: 1.8045922697231334

Epoch: 6| Step: 4
Training loss: 0.4423253536224365
Validation loss: 1.794660505428109

Epoch: 6| Step: 5
Training loss: 0.23321330547332764
Validation loss: 1.7602752498401109

Epoch: 6| Step: 6
Training loss: 0.4837137460708618
Validation loss: 1.7525089286988782

Epoch: 6| Step: 7
Training loss: 0.4176460802555084
Validation loss: 1.7643532958081973

Epoch: 6| Step: 8
Training loss: 0.2738337814807892
Validation loss: 1.782217812794511

Epoch: 6| Step: 9
Training loss: 0.3247861862182617
Validation loss: 1.7855065253473097

Epoch: 6| Step: 10
Training loss: 0.28327733278274536
Validation loss: 1.8123530098187026

Epoch: 6| Step: 11
Training loss: 0.49032434821128845
Validation loss: 1.8161752762333039

Epoch: 6| Step: 12
Training loss: 0.4198612570762634
Validation loss: 1.8911012167571692

Epoch: 6| Step: 13
Training loss: 0.5403334498405457
Validation loss: 1.822342990547098

Epoch: 516| Step: 0
Training loss: 0.32053643465042114
Validation loss: 1.8168829846125778

Epoch: 6| Step: 1
Training loss: 0.477189302444458
Validation loss: 1.796771659645983

Epoch: 6| Step: 2
Training loss: 0.4327668845653534
Validation loss: 1.8000860303960822

Epoch: 6| Step: 3
Training loss: 0.5705475807189941
Validation loss: 1.7979903644131077

Epoch: 6| Step: 4
Training loss: 0.3151546120643616
Validation loss: 1.7980320146006923

Epoch: 6| Step: 5
Training loss: 0.35934683680534363
Validation loss: 1.845248128778191

Epoch: 6| Step: 6
Training loss: 0.524507999420166
Validation loss: 1.8301387756101546

Epoch: 6| Step: 7
Training loss: 0.33267080783843994
Validation loss: 1.80386560322136

Epoch: 6| Step: 8
Training loss: 0.4571729898452759
Validation loss: 1.8488275286971882

Epoch: 6| Step: 9
Training loss: 0.4827342629432678
Validation loss: 1.845846692721049

Epoch: 6| Step: 10
Training loss: 0.5078098773956299
Validation loss: 1.8509510665811517

Epoch: 6| Step: 11
Training loss: 0.35292431712150574
Validation loss: 1.8678297701702322

Epoch: 6| Step: 12
Training loss: 0.44060876965522766
Validation loss: 1.8751566115246023

Epoch: 6| Step: 13
Training loss: 0.32263562083244324
Validation loss: 1.8519640891782698

Epoch: 517| Step: 0
Training loss: 0.2526477575302124
Validation loss: 1.8631393332635202

Epoch: 6| Step: 1
Training loss: 0.26706865429878235
Validation loss: 1.79337780193616

Epoch: 6| Step: 2
Training loss: 0.46503889560699463
Validation loss: 1.8018862573049401

Epoch: 6| Step: 3
Training loss: 0.3189818859100342
Validation loss: 1.7810700785729192

Epoch: 6| Step: 4
Training loss: 0.5403268337249756
Validation loss: 1.7649851332428634

Epoch: 6| Step: 5
Training loss: 0.5631452798843384
Validation loss: 1.805654812884587

Epoch: 6| Step: 6
Training loss: 0.5073509216308594
Validation loss: 1.8197401646644837

Epoch: 6| Step: 7
Training loss: 0.4253637194633484
Validation loss: 1.824247988321448

Epoch: 6| Step: 8
Training loss: 0.3747227191925049
Validation loss: 1.859926450637079

Epoch: 6| Step: 9
Training loss: 0.43113359808921814
Validation loss: 1.8448794349547355

Epoch: 6| Step: 10
Training loss: 0.622689425945282
Validation loss: 1.8404363355328959

Epoch: 6| Step: 11
Training loss: 0.22480206191539764
Validation loss: 1.813301428671806

Epoch: 6| Step: 12
Training loss: 0.3894352912902832
Validation loss: 1.827453838881626

Epoch: 6| Step: 13
Training loss: 0.5416634678840637
Validation loss: 1.8350304941977225

Epoch: 518| Step: 0
Training loss: 0.6440945863723755
Validation loss: 1.8176204350686842

Epoch: 6| Step: 1
Training loss: 0.3335549831390381
Validation loss: 1.8299350571888748

Epoch: 6| Step: 2
Training loss: 0.3929266631603241
Validation loss: 1.8539281288782756

Epoch: 6| Step: 3
Training loss: 0.23310424387454987
Validation loss: 1.8847013442747054

Epoch: 6| Step: 4
Training loss: 0.48760107159614563
Validation loss: 1.910955136822116

Epoch: 6| Step: 5
Training loss: 0.6778501272201538
Validation loss: 1.8887202380805888

Epoch: 6| Step: 6
Training loss: 0.25062882900238037
Validation loss: 1.8364317340235556

Epoch: 6| Step: 7
Training loss: 0.38791388273239136
Validation loss: 1.8042268099323395

Epoch: 6| Step: 8
Training loss: 0.20538079738616943
Validation loss: 1.7788008656553043

Epoch: 6| Step: 9
Training loss: 0.2910463511943817
Validation loss: 1.8324075052815099

Epoch: 6| Step: 10
Training loss: 0.630333662033081
Validation loss: 1.8509349887089064

Epoch: 6| Step: 11
Training loss: 0.49783414602279663
Validation loss: 1.8685272368051673

Epoch: 6| Step: 12
Training loss: 0.4398782253265381
Validation loss: 1.8336177615709202

Epoch: 6| Step: 13
Training loss: 0.4202171862125397
Validation loss: 1.7982671799198273

Epoch: 519| Step: 0
Training loss: 0.30864837765693665
Validation loss: 1.7861808589709702

Epoch: 6| Step: 1
Training loss: 0.4264026880264282
Validation loss: 1.8142022291819255

Epoch: 6| Step: 2
Training loss: 0.3075559437274933
Validation loss: 1.7985319104245914

Epoch: 6| Step: 3
Training loss: 0.5331159830093384
Validation loss: 1.8315458797639417

Epoch: 6| Step: 4
Training loss: 0.334547221660614
Validation loss: 1.8031952765680128

Epoch: 6| Step: 5
Training loss: 0.26527082920074463
Validation loss: 1.8234514703032791

Epoch: 6| Step: 6
Training loss: 0.4006631374359131
Validation loss: 1.8038424189372728

Epoch: 6| Step: 7
Training loss: 0.3606199026107788
Validation loss: 1.8205947593976093

Epoch: 6| Step: 8
Training loss: 0.3855436444282532
Validation loss: 1.8091558000092864

Epoch: 6| Step: 9
Training loss: 0.1858271062374115
Validation loss: 1.8058906409048265

Epoch: 6| Step: 10
Training loss: 0.5254204869270325
Validation loss: 1.8268504796489593

Epoch: 6| Step: 11
Training loss: 0.5178685188293457
Validation loss: 1.8046044598343551

Epoch: 6| Step: 12
Training loss: 0.40119147300720215
Validation loss: 1.7806808538334344

Epoch: 6| Step: 13
Training loss: 0.36792245507240295
Validation loss: 1.8205126434244134

Epoch: 520| Step: 0
Training loss: 0.40042608976364136
Validation loss: 1.8479741234933176

Epoch: 6| Step: 1
Training loss: 0.3188187777996063
Validation loss: 1.8168866416459442

Epoch: 6| Step: 2
Training loss: 0.22523227334022522
Validation loss: 1.8191252690489574

Epoch: 6| Step: 3
Training loss: 0.41992875933647156
Validation loss: 1.8018490332429127

Epoch: 6| Step: 4
Training loss: 0.27718690037727356
Validation loss: 1.776234939534177

Epoch: 6| Step: 5
Training loss: 0.21942228078842163
Validation loss: 1.7815361484404533

Epoch: 6| Step: 6
Training loss: 0.31762465834617615
Validation loss: 1.7707116347487255

Epoch: 6| Step: 7
Training loss: 0.2901575565338135
Validation loss: 1.8024386372617496

Epoch: 6| Step: 8
Training loss: 0.6961501836776733
Validation loss: 1.7601297478522024

Epoch: 6| Step: 9
Training loss: 0.26987993717193604
Validation loss: 1.7412303519505326

Epoch: 6| Step: 10
Training loss: 0.5854758024215698
Validation loss: 1.7563953322748984

Epoch: 6| Step: 11
Training loss: 0.6432275772094727
Validation loss: 1.7507544627753637

Epoch: 6| Step: 12
Training loss: 0.36060428619384766
Validation loss: 1.7799188065272507

Epoch: 6| Step: 13
Training loss: 0.44651758670806885
Validation loss: 1.7986492828656269

Epoch: 521| Step: 0
Training loss: 0.23115378618240356
Validation loss: 1.7507717212041218

Epoch: 6| Step: 1
Training loss: 0.256752610206604
Validation loss: 1.802278918604697

Epoch: 6| Step: 2
Training loss: 0.4955272972583771
Validation loss: 1.8334868287527433

Epoch: 6| Step: 3
Training loss: 0.5957415103912354
Validation loss: 1.8502640839545959

Epoch: 6| Step: 4
Training loss: 0.4384673833847046
Validation loss: 1.8777589926155664

Epoch: 6| Step: 5
Training loss: 0.42557722330093384
Validation loss: 1.8886851597857732

Epoch: 6| Step: 6
Training loss: 0.2733232378959656
Validation loss: 1.8933288589600594

Epoch: 6| Step: 7
Training loss: 0.47130319476127625
Validation loss: 1.824693323463522

Epoch: 6| Step: 8
Training loss: 0.28956669569015503
Validation loss: 1.8496924818203013

Epoch: 6| Step: 9
Training loss: 0.34053394198417664
Validation loss: 1.8706621354626072

Epoch: 6| Step: 10
Training loss: 0.5362281799316406
Validation loss: 1.8618244791543612

Epoch: 6| Step: 11
Training loss: 0.2986210286617279
Validation loss: 1.8946045829403786

Epoch: 6| Step: 12
Training loss: 0.40153956413269043
Validation loss: 1.8751927498848207

Epoch: 6| Step: 13
Training loss: 0.38005995750427246
Validation loss: 1.8955240711089103

Epoch: 522| Step: 0
Training loss: 0.3811452388763428
Validation loss: 1.8314817208115772

Epoch: 6| Step: 1
Training loss: 0.3547138571739197
Validation loss: 1.8334374120158534

Epoch: 6| Step: 2
Training loss: 0.32789236307144165
Validation loss: 1.8298474639974616

Epoch: 6| Step: 3
Training loss: 0.34352827072143555
Validation loss: 1.790748264199944

Epoch: 6| Step: 4
Training loss: 0.48696380853652954
Validation loss: 1.8214575911080966

Epoch: 6| Step: 5
Training loss: 0.31187903881073
Validation loss: 1.8366659418229134

Epoch: 6| Step: 6
Training loss: 0.3777671456336975
Validation loss: 1.8305200633182321

Epoch: 6| Step: 7
Training loss: 0.1284051239490509
Validation loss: 1.8485671768906295

Epoch: 6| Step: 8
Training loss: 0.6384091973304749
Validation loss: 1.8370613192999234

Epoch: 6| Step: 9
Training loss: 0.43919479846954346
Validation loss: 1.819044897633214

Epoch: 6| Step: 10
Training loss: 0.31478792428970337
Validation loss: 1.8478960593541462

Epoch: 6| Step: 11
Training loss: 0.4426805377006531
Validation loss: 1.836146967385405

Epoch: 6| Step: 12
Training loss: 0.5103626251220703
Validation loss: 1.8483410689138597

Epoch: 6| Step: 13
Training loss: 0.4356759488582611
Validation loss: 1.8179404639428662

Epoch: 523| Step: 0
Training loss: 0.4781968593597412
Validation loss: 1.8523216503922657

Epoch: 6| Step: 1
Training loss: 0.3537805676460266
Validation loss: 1.8006194099303214

Epoch: 6| Step: 2
Training loss: 0.23918378353118896
Validation loss: 1.812835616450156

Epoch: 6| Step: 3
Training loss: 0.31566786766052246
Validation loss: 1.7802019234626525

Epoch: 6| Step: 4
Training loss: 0.4365955591201782
Validation loss: 1.8084882972060994

Epoch: 6| Step: 5
Training loss: 0.24646183848381042
Validation loss: 1.8529847104062316

Epoch: 6| Step: 6
Training loss: 0.22226592898368835
Validation loss: 1.8339688752287178

Epoch: 6| Step: 7
Training loss: 0.6488691568374634
Validation loss: 1.8432619289685321

Epoch: 6| Step: 8
Training loss: 0.7368012070655823
Validation loss: 1.8515255758839269

Epoch: 6| Step: 9
Training loss: 0.29834747314453125
Validation loss: 1.8414013898500832

Epoch: 6| Step: 10
Training loss: 0.3630574643611908
Validation loss: 1.816402086647608

Epoch: 6| Step: 11
Training loss: 0.25569114089012146
Validation loss: 1.827048247860324

Epoch: 6| Step: 12
Training loss: 0.3166106939315796
Validation loss: 1.812055564695789

Epoch: 6| Step: 13
Training loss: 0.17120195925235748
Validation loss: 1.7654584043769426

Epoch: 524| Step: 0
Training loss: 0.5389153957366943
Validation loss: 1.7932605897226641

Epoch: 6| Step: 1
Training loss: 0.574604332447052
Validation loss: 1.784100269758573

Epoch: 6| Step: 2
Training loss: 0.25231388211250305
Validation loss: 1.8320264867556992

Epoch: 6| Step: 3
Training loss: 0.3824918270111084
Validation loss: 1.8086373036907566

Epoch: 6| Step: 4
Training loss: 0.509218692779541
Validation loss: 1.8029558043326102

Epoch: 6| Step: 5
Training loss: 0.20448672771453857
Validation loss: 1.836726729587842

Epoch: 6| Step: 6
Training loss: 0.26966285705566406
Validation loss: 1.8553791635779924

Epoch: 6| Step: 7
Training loss: 0.39739346504211426
Validation loss: 1.8286742202697261

Epoch: 6| Step: 8
Training loss: 0.3277266025543213
Validation loss: 1.8386216112362441

Epoch: 6| Step: 9
Training loss: 0.32110345363616943
Validation loss: 1.7814045734302972

Epoch: 6| Step: 10
Training loss: 0.5347132682800293
Validation loss: 1.7952393780472458

Epoch: 6| Step: 11
Training loss: 0.3653607964515686
Validation loss: 1.7611136212143848

Epoch: 6| Step: 12
Training loss: 0.3531333804130554
Validation loss: 1.7726463476816814

Epoch: 6| Step: 13
Training loss: 0.3426036834716797
Validation loss: 1.7963365777846305

Epoch: 525| Step: 0
Training loss: 0.21119363605976105
Validation loss: 1.8273562641553982

Epoch: 6| Step: 1
Training loss: 0.29238951206207275
Validation loss: 1.8642356485448859

Epoch: 6| Step: 2
Training loss: 0.42918461561203003
Validation loss: 1.855907424803703

Epoch: 6| Step: 3
Training loss: 0.45972558856010437
Validation loss: 1.855410373339089

Epoch: 6| Step: 4
Training loss: 0.3632988929748535
Validation loss: 1.8095909690344205

Epoch: 6| Step: 5
Training loss: 0.42182791233062744
Validation loss: 1.8268265416545253

Epoch: 6| Step: 6
Training loss: 0.2758314311504364
Validation loss: 1.7913780366220782

Epoch: 6| Step: 7
Training loss: 0.2811703085899353
Validation loss: 1.7667122758844847

Epoch: 6| Step: 8
Training loss: 0.3791804313659668
Validation loss: 1.7977818545474802

Epoch: 6| Step: 9
Training loss: 0.6052259206771851
Validation loss: 1.780019232021865

Epoch: 6| Step: 10
Training loss: 0.4553946852684021
Validation loss: 1.7750545406854281

Epoch: 6| Step: 11
Training loss: 0.4605857729911804
Validation loss: 1.7811827377606464

Epoch: 6| Step: 12
Training loss: 0.5285576581954956
Validation loss: 1.7973226078094975

Epoch: 6| Step: 13
Training loss: 0.32545149326324463
Validation loss: 1.8158281528821556

Epoch: 526| Step: 0
Training loss: 0.22384408116340637
Validation loss: 1.8421905309923234

Epoch: 6| Step: 1
Training loss: 0.41105541586875916
Validation loss: 1.8433837582988124

Epoch: 6| Step: 2
Training loss: 0.3936740458011627
Validation loss: 1.8397658076337589

Epoch: 6| Step: 3
Training loss: 0.2790400981903076
Validation loss: 1.8606173274337605

Epoch: 6| Step: 4
Training loss: 0.17368021607398987
Validation loss: 1.7715282747822423

Epoch: 6| Step: 5
Training loss: 0.24120208621025085
Validation loss: 1.7443868524284774

Epoch: 6| Step: 6
Training loss: 0.17878508567810059
Validation loss: 1.7539458979842484

Epoch: 6| Step: 7
Training loss: 0.4807780981063843
Validation loss: 1.754045932523666

Epoch: 6| Step: 8
Training loss: 0.5623072385787964
Validation loss: 1.7412493639094855

Epoch: 6| Step: 9
Training loss: 0.5151568651199341
Validation loss: 1.747926854318188

Epoch: 6| Step: 10
Training loss: 0.4388114809989929
Validation loss: 1.7892489612743419

Epoch: 6| Step: 11
Training loss: 0.2223118543624878
Validation loss: 1.812624349389025

Epoch: 6| Step: 12
Training loss: 0.674534022808075
Validation loss: 1.8522996723010976

Epoch: 6| Step: 13
Training loss: 0.510875940322876
Validation loss: 1.885098990573678

Epoch: 527| Step: 0
Training loss: 0.3332955241203308
Validation loss: 1.86476670798435

Epoch: 6| Step: 1
Training loss: 0.3322870135307312
Validation loss: 1.7840379463729037

Epoch: 6| Step: 2
Training loss: 0.3240078091621399
Validation loss: 1.763083464355879

Epoch: 6| Step: 3
Training loss: 0.4509960412979126
Validation loss: 1.7633835904059871

Epoch: 6| Step: 4
Training loss: 0.5220357179641724
Validation loss: 1.7731643658812328

Epoch: 6| Step: 5
Training loss: 0.38853248953819275
Validation loss: 1.7752471226517872

Epoch: 6| Step: 6
Training loss: 0.5238276720046997
Validation loss: 1.8145287177895988

Epoch: 6| Step: 7
Training loss: 0.24699847400188446
Validation loss: 1.8276806967232817

Epoch: 6| Step: 8
Training loss: 0.3943048119544983
Validation loss: 1.827011118653

Epoch: 6| Step: 9
Training loss: 0.3104345500469208
Validation loss: 1.7885653934171122

Epoch: 6| Step: 10
Training loss: 0.4751208424568176
Validation loss: 1.8380361398061116

Epoch: 6| Step: 11
Training loss: 0.2709578275680542
Validation loss: 1.8151887924440446

Epoch: 6| Step: 12
Training loss: 0.3441596031188965
Validation loss: 1.8249178009648477

Epoch: 6| Step: 13
Training loss: 0.4488160312175751
Validation loss: 1.7815441405901344

Epoch: 528| Step: 0
Training loss: 0.5490027666091919
Validation loss: 1.8239152918579757

Epoch: 6| Step: 1
Training loss: 0.19714486598968506
Validation loss: 1.8126830798323437

Epoch: 6| Step: 2
Training loss: 0.38974902033805847
Validation loss: 1.7990048252126223

Epoch: 6| Step: 3
Training loss: 0.3340531587600708
Validation loss: 1.8198352577865764

Epoch: 6| Step: 4
Training loss: 0.4278320372104645
Validation loss: 1.820028639608814

Epoch: 6| Step: 5
Training loss: 0.4512689709663391
Validation loss: 1.859899249128116

Epoch: 6| Step: 6
Training loss: 0.2853884696960449
Validation loss: 1.8821464738538187

Epoch: 6| Step: 7
Training loss: 0.2632569670677185
Validation loss: 1.8166714252964142

Epoch: 6| Step: 8
Training loss: 0.5378718376159668
Validation loss: 1.8447274834878984

Epoch: 6| Step: 9
Training loss: 0.3861740231513977
Validation loss: 1.8293070306060135

Epoch: 6| Step: 10
Training loss: 0.3370392322540283
Validation loss: 1.818189223607381

Epoch: 6| Step: 11
Training loss: 0.5155556201934814
Validation loss: 1.8089210217998875

Epoch: 6| Step: 12
Training loss: 0.23114600777626038
Validation loss: 1.8074540656100038

Epoch: 6| Step: 13
Training loss: 0.2960251569747925
Validation loss: 1.8353249360156316

Epoch: 529| Step: 0
Training loss: 0.3251993656158447
Validation loss: 1.8500047652952132

Epoch: 6| Step: 1
Training loss: 0.3447059094905853
Validation loss: 1.8163012304613668

Epoch: 6| Step: 2
Training loss: 0.4145236909389496
Validation loss: 1.8471250405875586

Epoch: 6| Step: 3
Training loss: 0.3748927116394043
Validation loss: 1.7966354482917375

Epoch: 6| Step: 4
Training loss: 0.2724784016609192
Validation loss: 1.794901224874681

Epoch: 6| Step: 5
Training loss: 0.3134172260761261
Validation loss: 1.812299192592662

Epoch: 6| Step: 6
Training loss: 0.32372158765792847
Validation loss: 1.8203596991877402

Epoch: 6| Step: 7
Training loss: 0.739902913570404
Validation loss: 1.8181547375135525

Epoch: 6| Step: 8
Training loss: 0.4486258625984192
Validation loss: 1.8283448911482287

Epoch: 6| Step: 9
Training loss: 0.36508360505104065
Validation loss: 1.7800871761896278

Epoch: 6| Step: 10
Training loss: 0.19324418902397156
Validation loss: 1.7534989426212926

Epoch: 6| Step: 11
Training loss: 0.17293952405452728
Validation loss: 1.7923936126052693

Epoch: 6| Step: 12
Training loss: 0.4440118074417114
Validation loss: 1.7936824367892357

Epoch: 6| Step: 13
Training loss: 0.3822348117828369
Validation loss: 1.821863176361207

Epoch: 530| Step: 0
Training loss: 0.4657081961631775
Validation loss: 1.8412218837327854

Epoch: 6| Step: 1
Training loss: 0.21929802000522614
Validation loss: 1.8756825039463658

Epoch: 6| Step: 2
Training loss: 0.39751502871513367
Validation loss: 1.9145693958446544

Epoch: 6| Step: 3
Training loss: 0.4054194688796997
Validation loss: 1.9231148304477814

Epoch: 6| Step: 4
Training loss: 0.42965343594551086
Validation loss: 1.9164590668934647

Epoch: 6| Step: 5
Training loss: 0.2722407877445221
Validation loss: 1.9201465383652718

Epoch: 6| Step: 6
Training loss: 0.477899968624115
Validation loss: 1.8903092133101596

Epoch: 6| Step: 7
Training loss: 0.32523271441459656
Validation loss: 1.8346810866427679

Epoch: 6| Step: 8
Training loss: 0.4343961477279663
Validation loss: 1.814618666966756

Epoch: 6| Step: 9
Training loss: 0.44498124718666077
Validation loss: 1.7381350135290494

Epoch: 6| Step: 10
Training loss: 0.30578911304473877
Validation loss: 1.7507145109997

Epoch: 6| Step: 11
Training loss: 0.42309898138046265
Validation loss: 1.7304664170870216

Epoch: 6| Step: 12
Training loss: 0.2439872920513153
Validation loss: 1.758124266901324

Epoch: 6| Step: 13
Training loss: 0.5708639621734619
Validation loss: 1.7470743092157508

Epoch: 531| Step: 0
Training loss: 0.5434191823005676
Validation loss: 1.8034175108837824

Epoch: 6| Step: 1
Training loss: 0.26022571325302124
Validation loss: 1.8093317298478977

Epoch: 6| Step: 2
Training loss: 0.6399279832839966
Validation loss: 1.864673404283421

Epoch: 6| Step: 3
Training loss: 0.29523229598999023
Validation loss: 1.8677258465879707

Epoch: 6| Step: 4
Training loss: 0.17569445073604584
Validation loss: 1.8438185491869528

Epoch: 6| Step: 5
Training loss: 0.3127233386039734
Validation loss: 1.798717669261399

Epoch: 6| Step: 6
Training loss: 0.34510043263435364
Validation loss: 1.7449671081317368

Epoch: 6| Step: 7
Training loss: 0.4711519479751587
Validation loss: 1.7189876264141453

Epoch: 6| Step: 8
Training loss: 0.6214091777801514
Validation loss: 1.7584956205019386

Epoch: 6| Step: 9
Training loss: 0.34036877751350403
Validation loss: 1.7538322287221109

Epoch: 6| Step: 10
Training loss: 0.42658936977386475
Validation loss: 1.7456017232710315

Epoch: 6| Step: 11
Training loss: 0.4225137233734131
Validation loss: 1.755906287059989

Epoch: 6| Step: 12
Training loss: 0.3566707968711853
Validation loss: 1.8020688667092273

Epoch: 6| Step: 13
Training loss: 0.39814066886901855
Validation loss: 1.835123945307988

Epoch: 532| Step: 0
Training loss: 0.5486963987350464
Validation loss: 1.8393480777740479

Epoch: 6| Step: 1
Training loss: 0.18334037065505981
Validation loss: 1.7983555806580411

Epoch: 6| Step: 2
Training loss: 0.3115205764770508
Validation loss: 1.7955389125372774

Epoch: 6| Step: 3
Training loss: 0.4347667396068573
Validation loss: 1.7425898531431794

Epoch: 6| Step: 4
Training loss: 0.2860530614852905
Validation loss: 1.7463941958642775

Epoch: 6| Step: 5
Training loss: 0.22526639699935913
Validation loss: 1.738104284450572

Epoch: 6| Step: 6
Training loss: 0.5737302303314209
Validation loss: 1.7775918053042503

Epoch: 6| Step: 7
Training loss: 0.4773057997226715
Validation loss: 1.8333359482467815

Epoch: 6| Step: 8
Training loss: 0.325626403093338
Validation loss: 1.840905165159574

Epoch: 6| Step: 9
Training loss: 0.29771894216537476
Validation loss: 1.8658066795718284

Epoch: 6| Step: 10
Training loss: 0.2445427030324936
Validation loss: 1.8413573670130905

Epoch: 6| Step: 11
Training loss: 0.46630245447158813
Validation loss: 1.863777450335923

Epoch: 6| Step: 12
Training loss: 0.3425067663192749
Validation loss: 1.8187887360972743

Epoch: 6| Step: 13
Training loss: 0.6572060585021973
Validation loss: 1.8107778154393679

Epoch: 533| Step: 0
Training loss: 0.458652138710022
Validation loss: 1.7929787417893768

Epoch: 6| Step: 1
Training loss: 0.40757957100868225
Validation loss: 1.7713259766178746

Epoch: 6| Step: 2
Training loss: 0.459236204624176
Validation loss: 1.768160557234159

Epoch: 6| Step: 3
Training loss: 0.5542975664138794
Validation loss: 1.7902442409146218

Epoch: 6| Step: 4
Training loss: 0.24201059341430664
Validation loss: 1.8132616704510105

Epoch: 6| Step: 5
Training loss: 0.3210937976837158
Validation loss: 1.7625045314911874

Epoch: 6| Step: 6
Training loss: 0.2931100130081177
Validation loss: 1.8084164152863205

Epoch: 6| Step: 7
Training loss: 0.33174988627433777
Validation loss: 1.7982207088060276

Epoch: 6| Step: 8
Training loss: 0.2020539939403534
Validation loss: 1.8488061710070538

Epoch: 6| Step: 9
Training loss: 0.3860052227973938
Validation loss: 1.8913724742909914

Epoch: 6| Step: 10
Training loss: 0.29654401540756226
Validation loss: 1.8513976861071844

Epoch: 6| Step: 11
Training loss: 0.2936277985572815
Validation loss: 1.8734070395910611

Epoch: 6| Step: 12
Training loss: 0.15507030487060547
Validation loss: 1.8547524944428475

Epoch: 6| Step: 13
Training loss: 0.3443760871887207
Validation loss: 1.8207366953613937

Epoch: 534| Step: 0
Training loss: 0.2172318696975708
Validation loss: 1.8235407324247463

Epoch: 6| Step: 1
Training loss: 0.25265422463417053
Validation loss: 1.8093197807188957

Epoch: 6| Step: 2
Training loss: 0.34653645753860474
Validation loss: 1.77070197110535

Epoch: 6| Step: 3
Training loss: 0.48776012659072876
Validation loss: 1.780599997889611

Epoch: 6| Step: 4
Training loss: 0.3141738176345825
Validation loss: 1.8091675440470378

Epoch: 6| Step: 5
Training loss: 0.4252593219280243
Validation loss: 1.8322568279440685

Epoch: 6| Step: 6
Training loss: 0.24441376328468323
Validation loss: 1.7870028326588292

Epoch: 6| Step: 7
Training loss: 0.18607424199581146
Validation loss: 1.8455611839089343

Epoch: 6| Step: 8
Training loss: 0.15458860993385315
Validation loss: 1.8454031431546776

Epoch: 6| Step: 9
Training loss: 0.39701080322265625
Validation loss: 1.831075942644509

Epoch: 6| Step: 10
Training loss: 0.5417674779891968
Validation loss: 1.8202358240722327

Epoch: 6| Step: 11
Training loss: 0.3658151626586914
Validation loss: 1.8133482292134275

Epoch: 6| Step: 12
Training loss: 0.5313441157341003
Validation loss: 1.8048507705811532

Epoch: 6| Step: 13
Training loss: 0.40131184458732605
Validation loss: 1.7958117492737309

Epoch: 535| Step: 0
Training loss: 0.489715576171875
Validation loss: 1.8136685279107863

Epoch: 6| Step: 1
Training loss: 0.35247159004211426
Validation loss: 1.8067266530888055

Epoch: 6| Step: 2
Training loss: 0.3391784131526947
Validation loss: 1.7695994877046155

Epoch: 6| Step: 3
Training loss: 0.4706718921661377
Validation loss: 1.7825395176487584

Epoch: 6| Step: 4
Training loss: 0.2032586634159088
Validation loss: 1.7947624191161125

Epoch: 6| Step: 5
Training loss: 0.29633525013923645
Validation loss: 1.7819464322059386

Epoch: 6| Step: 6
Training loss: 0.2621660828590393
Validation loss: 1.7982414646815228

Epoch: 6| Step: 7
Training loss: 0.3302111327648163
Validation loss: 1.788562104266177

Epoch: 6| Step: 8
Training loss: 0.4021413326263428
Validation loss: 1.8086031329247259

Epoch: 6| Step: 9
Training loss: 0.37513649463653564
Validation loss: 1.7913805912899714

Epoch: 6| Step: 10
Training loss: 0.4210054874420166
Validation loss: 1.8178205849021993

Epoch: 6| Step: 11
Training loss: 0.4617118239402771
Validation loss: 1.7739020316831526

Epoch: 6| Step: 12
Training loss: 0.17767059803009033
Validation loss: 1.7594155355166363

Epoch: 6| Step: 13
Training loss: 0.3361387252807617
Validation loss: 1.7984154852487708

Epoch: 536| Step: 0
Training loss: 0.2746654748916626
Validation loss: 1.7545015286373835

Epoch: 6| Step: 1
Training loss: 0.5273638963699341
Validation loss: 1.7449681361516316

Epoch: 6| Step: 2
Training loss: 0.4653491973876953
Validation loss: 1.7959297895431519

Epoch: 6| Step: 3
Training loss: 0.22730450332164764
Validation loss: 1.794591066657856

Epoch: 6| Step: 4
Training loss: 0.15606242418289185
Validation loss: 1.843437663970455

Epoch: 6| Step: 5
Training loss: 0.12168246507644653
Validation loss: 1.8471404583223405

Epoch: 6| Step: 6
Training loss: 0.3062897026538849
Validation loss: 1.855275506614357

Epoch: 6| Step: 7
Training loss: 0.5953030586242676
Validation loss: 1.8528964340045888

Epoch: 6| Step: 8
Training loss: 0.3082696795463562
Validation loss: 1.8331437944084086

Epoch: 6| Step: 9
Training loss: 0.3471553325653076
Validation loss: 1.8224087863840082

Epoch: 6| Step: 10
Training loss: 0.40642061829566956
Validation loss: 1.762846480133713

Epoch: 6| Step: 11
Training loss: 0.4785085916519165
Validation loss: 1.752445081228851

Epoch: 6| Step: 12
Training loss: 0.5445713996887207
Validation loss: 1.7344317948946388

Epoch: 6| Step: 13
Training loss: 0.4082595109939575
Validation loss: 1.740336928316342

Epoch: 537| Step: 0
Training loss: 0.4710861146450043
Validation loss: 1.7920831582879508

Epoch: 6| Step: 1
Training loss: 0.3666226267814636
Validation loss: 1.8061613869923416

Epoch: 6| Step: 2
Training loss: 0.5739918947219849
Validation loss: 1.8591860109759915

Epoch: 6| Step: 3
Training loss: 0.39003878831863403
Validation loss: 1.8963616945410287

Epoch: 6| Step: 4
Training loss: 0.40171802043914795
Validation loss: 1.852153088456841

Epoch: 6| Step: 5
Training loss: 0.3435722589492798
Validation loss: 1.8707142132584766

Epoch: 6| Step: 6
Training loss: 0.41271263360977173
Validation loss: 1.821433505704326

Epoch: 6| Step: 7
Training loss: 0.35237574577331543
Validation loss: 1.7996339721064414

Epoch: 6| Step: 8
Training loss: 0.36238807439804077
Validation loss: 1.7733622481746059

Epoch: 6| Step: 9
Training loss: 0.3450310230255127
Validation loss: 1.7542763038348126

Epoch: 6| Step: 10
Training loss: 0.43640631437301636
Validation loss: 1.7459751534205612

Epoch: 6| Step: 11
Training loss: 0.5656188130378723
Validation loss: 1.7384782145100255

Epoch: 6| Step: 12
Training loss: 0.2935009002685547
Validation loss: 1.719227478068362

Epoch: 6| Step: 13
Training loss: 0.4079880118370056
Validation loss: 1.7593417295845606

Epoch: 538| Step: 0
Training loss: 0.6022981405258179
Validation loss: 1.8399327596028645

Epoch: 6| Step: 1
Training loss: 0.3138536810874939
Validation loss: 1.9130848376981673

Epoch: 6| Step: 2
Training loss: 0.3326728343963623
Validation loss: 1.9010185874918455

Epoch: 6| Step: 3
Training loss: 0.5614445209503174
Validation loss: 1.9127557059769988

Epoch: 6| Step: 4
Training loss: 0.4107746481895447
Validation loss: 1.8503142813200593

Epoch: 6| Step: 5
Training loss: 0.44571831822395325
Validation loss: 1.820315868623795

Epoch: 6| Step: 6
Training loss: 0.25984737277030945
Validation loss: 1.782928309132976

Epoch: 6| Step: 7
Training loss: 0.5855119824409485
Validation loss: 1.764065291291924

Epoch: 6| Step: 8
Training loss: 0.4325985908508301
Validation loss: 1.7622660565119919

Epoch: 6| Step: 9
Training loss: 0.4534987509250641
Validation loss: 1.7465940508791196

Epoch: 6| Step: 10
Training loss: 0.31486374139785767
Validation loss: 1.748087203630837

Epoch: 6| Step: 11
Training loss: 0.5187519192695618
Validation loss: 1.7448429574248612

Epoch: 6| Step: 12
Training loss: 0.20415827631950378
Validation loss: 1.7026583187041744

Epoch: 6| Step: 13
Training loss: 0.2179199606180191
Validation loss: 1.7958088203143048

Epoch: 539| Step: 0
Training loss: 0.45672082901000977
Validation loss: 1.8149943992655764

Epoch: 6| Step: 1
Training loss: 0.35346847772598267
Validation loss: 1.8627543705765919

Epoch: 6| Step: 2
Training loss: 0.22007834911346436
Validation loss: 1.9201611344532301

Epoch: 6| Step: 3
Training loss: 0.49247175455093384
Validation loss: 1.8569931343037596

Epoch: 6| Step: 4
Training loss: 0.2731880843639374
Validation loss: 1.8449145081222698

Epoch: 6| Step: 5
Training loss: 0.2303048074245453
Validation loss: 1.7980197975712437

Epoch: 6| Step: 6
Training loss: 0.27660197019577026
Validation loss: 1.7714702788219656

Epoch: 6| Step: 7
Training loss: 0.301997572183609
Validation loss: 1.791485366000924

Epoch: 6| Step: 8
Training loss: 0.24423982203006744
Validation loss: 1.774991459743951

Epoch: 6| Step: 9
Training loss: 0.2548988163471222
Validation loss: 1.8163143845014675

Epoch: 6| Step: 10
Training loss: 0.4900164008140564
Validation loss: 1.80236828455361

Epoch: 6| Step: 11
Training loss: 0.5124587416648865
Validation loss: 1.8352663350361649

Epoch: 6| Step: 12
Training loss: 0.36513686180114746
Validation loss: 1.8850654504632438

Epoch: 6| Step: 13
Training loss: 0.5445154905319214
Validation loss: 1.8548554207689019

Epoch: 540| Step: 0
Training loss: 0.3957224488258362
Validation loss: 1.8879870676225232

Epoch: 6| Step: 1
Training loss: 0.5463230013847351
Validation loss: 1.8748759377387263

Epoch: 6| Step: 2
Training loss: 0.2969011664390564
Validation loss: 1.8796947656139251

Epoch: 6| Step: 3
Training loss: 0.4175931215286255
Validation loss: 1.8562811561810073

Epoch: 6| Step: 4
Training loss: 0.22221311926841736
Validation loss: 1.8539735335175709

Epoch: 6| Step: 5
Training loss: 0.18605361878871918
Validation loss: 1.8601111160811556

Epoch: 6| Step: 6
Training loss: 0.5157527923583984
Validation loss: 1.8591750719213997

Epoch: 6| Step: 7
Training loss: 0.2641882598400116
Validation loss: 1.8834464575654717

Epoch: 6| Step: 8
Training loss: 0.4203697443008423
Validation loss: 1.8620442985206522

Epoch: 6| Step: 9
Training loss: 0.36063143610954285
Validation loss: 1.8541937451208792

Epoch: 6| Step: 10
Training loss: 0.42044514417648315
Validation loss: 1.8230521884015811

Epoch: 6| Step: 11
Training loss: 0.3475058674812317
Validation loss: 1.838468792617962

Epoch: 6| Step: 12
Training loss: 0.3512604832649231
Validation loss: 1.8494302559924383

Epoch: 6| Step: 13
Training loss: 0.4091206192970276
Validation loss: 1.8224777265261578

Epoch: 541| Step: 0
Training loss: 0.5411666035652161
Validation loss: 1.820288178741291

Epoch: 6| Step: 1
Training loss: 0.3553139269351959
Validation loss: 1.8218116439798826

Epoch: 6| Step: 2
Training loss: 0.2665742337703705
Validation loss: 1.8705702443276682

Epoch: 6| Step: 3
Training loss: 0.4278009533882141
Validation loss: 1.832751920146327

Epoch: 6| Step: 4
Training loss: 0.3439641296863556
Validation loss: 1.8327317007126347

Epoch: 6| Step: 5
Training loss: 0.3079380393028259
Validation loss: 1.8244010953493015

Epoch: 6| Step: 6
Training loss: 0.18171274662017822
Validation loss: 1.829403317102822

Epoch: 6| Step: 7
Training loss: 0.3307958245277405
Validation loss: 1.8115200342670563

Epoch: 6| Step: 8
Training loss: 0.28005290031433105
Validation loss: 1.7889656700113767

Epoch: 6| Step: 9
Training loss: 0.16995514929294586
Validation loss: 1.784740226243132

Epoch: 6| Step: 10
Training loss: 0.3747625946998596
Validation loss: 1.8096949003076042

Epoch: 6| Step: 11
Training loss: 0.27139177918434143
Validation loss: 1.8404390952920402

Epoch: 6| Step: 12
Training loss: 0.3396205008029938
Validation loss: 1.7961782460571618

Epoch: 6| Step: 13
Training loss: 0.8014212846755981
Validation loss: 1.8132525246630433

Epoch: 542| Step: 0
Training loss: 0.2923395037651062
Validation loss: 1.8941682307950911

Epoch: 6| Step: 1
Training loss: 0.3144225478172302
Validation loss: 1.8953485745255665

Epoch: 6| Step: 2
Training loss: 0.5255393385887146
Validation loss: 1.9066280293208298

Epoch: 6| Step: 3
Training loss: 0.24325984716415405
Validation loss: 1.9110846570743028

Epoch: 6| Step: 4
Training loss: 0.3719905614852905
Validation loss: 1.9218993392041934

Epoch: 6| Step: 5
Training loss: 0.5857182741165161
Validation loss: 1.8653797680331814

Epoch: 6| Step: 6
Training loss: 0.3608437180519104
Validation loss: 1.8032533007283365

Epoch: 6| Step: 7
Training loss: 0.3176295757293701
Validation loss: 1.778818243293352

Epoch: 6| Step: 8
Training loss: 0.2713712453842163
Validation loss: 1.770436099780503

Epoch: 6| Step: 9
Training loss: 0.30361872911453247
Validation loss: 1.8036636293575328

Epoch: 6| Step: 10
Training loss: 0.2134525179862976
Validation loss: 1.8064715529000888

Epoch: 6| Step: 11
Training loss: 0.403626412153244
Validation loss: 1.8161951188118226

Epoch: 6| Step: 12
Training loss: 0.20446455478668213
Validation loss: 1.8406656519059212

Epoch: 6| Step: 13
Training loss: 0.33973896503448486
Validation loss: 1.8860050811562488

Epoch: 543| Step: 0
Training loss: 0.36433517932891846
Validation loss: 1.8748230523960565

Epoch: 6| Step: 1
Training loss: 0.19841527938842773
Validation loss: 1.891188306193198

Epoch: 6| Step: 2
Training loss: 0.2469104528427124
Validation loss: 1.854250515660932

Epoch: 6| Step: 3
Training loss: 0.23090465366840363
Validation loss: 1.851375702888735

Epoch: 6| Step: 4
Training loss: 0.20843173563480377
Validation loss: 1.8186380901644308

Epoch: 6| Step: 5
Training loss: 0.2520720958709717
Validation loss: 1.795431031975695

Epoch: 6| Step: 6
Training loss: 0.4318287968635559
Validation loss: 1.7862358887990315

Epoch: 6| Step: 7
Training loss: 0.5572493672370911
Validation loss: 1.775405636397741

Epoch: 6| Step: 8
Training loss: 0.39086979627609253
Validation loss: 1.752051858491795

Epoch: 6| Step: 9
Training loss: 0.46515998244285583
Validation loss: 1.7622984417023198

Epoch: 6| Step: 10
Training loss: 0.24527965486049652
Validation loss: 1.8538937863483225

Epoch: 6| Step: 11
Training loss: 0.3945332169532776
Validation loss: 1.8458747402314217

Epoch: 6| Step: 12
Training loss: 0.47151118516921997
Validation loss: 1.8589419549511326

Epoch: 6| Step: 13
Training loss: 0.4207703173160553
Validation loss: 1.8985170779689666

Epoch: 544| Step: 0
Training loss: 0.36902859807014465
Validation loss: 1.9137599237503544

Epoch: 6| Step: 1
Training loss: 0.34349358081817627
Validation loss: 1.906540943730262

Epoch: 6| Step: 2
Training loss: 0.3427310287952423
Validation loss: 1.8879243648180397

Epoch: 6| Step: 3
Training loss: 0.2205246090888977
Validation loss: 1.8746253367393249

Epoch: 6| Step: 4
Training loss: 0.657499372959137
Validation loss: 1.8376861759411391

Epoch: 6| Step: 5
Training loss: 0.33438268303871155
Validation loss: 1.8229698865644393

Epoch: 6| Step: 6
Training loss: 0.3067355155944824
Validation loss: 1.8140547313997823

Epoch: 6| Step: 7
Training loss: 0.2182765007019043
Validation loss: 1.8193384332041587

Epoch: 6| Step: 8
Training loss: 0.3357165455818176
Validation loss: 1.7711106628500006

Epoch: 6| Step: 9
Training loss: 0.4206075072288513
Validation loss: 1.8249259277056622

Epoch: 6| Step: 10
Training loss: 0.432852178812027
Validation loss: 1.7947592043107556

Epoch: 6| Step: 11
Training loss: 0.35384857654571533
Validation loss: 1.7832612401695662

Epoch: 6| Step: 12
Training loss: 0.38054659962654114
Validation loss: 1.7780073740149056

Epoch: 6| Step: 13
Training loss: 0.13777506351470947
Validation loss: 1.7758707064454273

Epoch: 545| Step: 0
Training loss: 0.3142300844192505
Validation loss: 1.796811931876726

Epoch: 6| Step: 1
Training loss: 0.2963724434375763
Validation loss: 1.8147290163142706

Epoch: 6| Step: 2
Training loss: 0.3319174647331238
Validation loss: 1.7782523414140106

Epoch: 6| Step: 3
Training loss: 0.371028333902359
Validation loss: 1.8161520342673025

Epoch: 6| Step: 4
Training loss: 0.349427193403244
Validation loss: 1.8506244997824393

Epoch: 6| Step: 5
Training loss: 0.31592169404029846
Validation loss: 1.881781703682356

Epoch: 6| Step: 6
Training loss: 0.452731728553772
Validation loss: 1.8837852516481954

Epoch: 6| Step: 7
Training loss: 0.16304300725460052
Validation loss: 1.8639649960302538

Epoch: 6| Step: 8
Training loss: 0.2956576347351074
Validation loss: 1.8055652661990094

Epoch: 6| Step: 9
Training loss: 0.3758905231952667
Validation loss: 1.7923907464550388

Epoch: 6| Step: 10
Training loss: 0.4717366099357605
Validation loss: 1.7653710585768505

Epoch: 6| Step: 11
Training loss: 0.506060779094696
Validation loss: 1.7405482005047541

Epoch: 6| Step: 12
Training loss: 0.36553680896759033
Validation loss: 1.7179560379315448

Epoch: 6| Step: 13
Training loss: 0.41686126589775085
Validation loss: 1.7788038984421761

Epoch: 546| Step: 0
Training loss: 0.2809869349002838
Validation loss: 1.7967999853113645

Epoch: 6| Step: 1
Training loss: 0.3728145360946655
Validation loss: 1.863381371703199

Epoch: 6| Step: 2
Training loss: 0.33100026845932007
Validation loss: 1.8860077781061972

Epoch: 6| Step: 3
Training loss: 0.317309707403183
Validation loss: 1.9515793195334814

Epoch: 6| Step: 4
Training loss: 0.512973427772522
Validation loss: 1.973331901334947

Epoch: 6| Step: 5
Training loss: 0.5465472340583801
Validation loss: 1.9625853953822967

Epoch: 6| Step: 6
Training loss: 0.30473923683166504
Validation loss: 1.9420576531399962

Epoch: 6| Step: 7
Training loss: 0.32467275857925415
Validation loss: 1.832289134302447

Epoch: 6| Step: 8
Training loss: 0.4726538062095642
Validation loss: 1.8144890505780455

Epoch: 6| Step: 9
Training loss: 0.2707815170288086
Validation loss: 1.765307617443864

Epoch: 6| Step: 10
Training loss: 0.11803635954856873
Validation loss: 1.7586885652234476

Epoch: 6| Step: 11
Training loss: 0.45792075991630554
Validation loss: 1.7546500493121404

Epoch: 6| Step: 12
Training loss: 0.49283671379089355
Validation loss: 1.720281659915883

Epoch: 6| Step: 13
Training loss: 0.30553627014160156
Validation loss: 1.7865142944038555

Epoch: 547| Step: 0
Training loss: 0.29038646817207336
Validation loss: 1.76994829024038

Epoch: 6| Step: 1
Training loss: 0.2723688781261444
Validation loss: 1.8274799546887797

Epoch: 6| Step: 2
Training loss: 0.3578576445579529
Validation loss: 1.8778739565162248

Epoch: 6| Step: 3
Training loss: 0.6809344291687012
Validation loss: 1.9241109586531115

Epoch: 6| Step: 4
Training loss: 0.535477340221405
Validation loss: 1.9203059519490888

Epoch: 6| Step: 5
Training loss: 0.393815815448761
Validation loss: 1.9135166957814207

Epoch: 6| Step: 6
Training loss: 0.5787575244903564
Validation loss: 1.8656024074041715

Epoch: 6| Step: 7
Training loss: 0.34362125396728516
Validation loss: 1.7969230862074002

Epoch: 6| Step: 8
Training loss: 0.2270680069923401
Validation loss: 1.7697801513056601

Epoch: 6| Step: 9
Training loss: 0.21957843005657196
Validation loss: 1.7793861339169164

Epoch: 6| Step: 10
Training loss: 0.28971433639526367
Validation loss: 1.7629784384081442

Epoch: 6| Step: 11
Training loss: 0.2805866003036499
Validation loss: 1.7261921513465144

Epoch: 6| Step: 12
Training loss: 0.21718904376029968
Validation loss: 1.7116385070226525

Epoch: 6| Step: 13
Training loss: 0.37077006697654724
Validation loss: 1.7633316747603878

Epoch: 548| Step: 0
Training loss: 0.2576194107532501
Validation loss: 1.7890218739868493

Epoch: 6| Step: 1
Training loss: 0.37659311294555664
Validation loss: 1.80623947933156

Epoch: 6| Step: 2
Training loss: 0.29576343297958374
Validation loss: 1.8739090824639926

Epoch: 6| Step: 3
Training loss: 0.4321729242801666
Validation loss: 1.9007186582011562

Epoch: 6| Step: 4
Training loss: 0.4059807062149048
Validation loss: 1.932849484105264

Epoch: 6| Step: 5
Training loss: 0.34884732961654663
Validation loss: 1.916436723483506

Epoch: 6| Step: 6
Training loss: 0.22977294027805328
Validation loss: 1.894033767843759

Epoch: 6| Step: 7
Training loss: 0.5086545944213867
Validation loss: 1.8827754528291765

Epoch: 6| Step: 8
Training loss: 0.5685550570487976
Validation loss: 1.8610263101516231

Epoch: 6| Step: 9
Training loss: 0.1807243674993515
Validation loss: 1.840025632612167

Epoch: 6| Step: 10
Training loss: 0.28521549701690674
Validation loss: 1.781987299201309

Epoch: 6| Step: 11
Training loss: 0.2101770043373108
Validation loss: 1.8243768420270694

Epoch: 6| Step: 12
Training loss: 0.328082412481308
Validation loss: 1.832381049791972

Epoch: 6| Step: 13
Training loss: 0.12204551696777344
Validation loss: 1.8469354696171258

Epoch: 549| Step: 0
Training loss: 0.23292843997478485
Validation loss: 1.8072660905058666

Epoch: 6| Step: 1
Training loss: 0.42326945066452026
Validation loss: 1.8253723959768973

Epoch: 6| Step: 2
Training loss: 0.22104109823703766
Validation loss: 1.8777114063180902

Epoch: 6| Step: 3
Training loss: 0.41937196254730225
Validation loss: 1.8510341721196328

Epoch: 6| Step: 4
Training loss: 0.36357200145721436
Validation loss: 1.817837797185426

Epoch: 6| Step: 5
Training loss: 0.3799338638782501
Validation loss: 1.806976887487596

Epoch: 6| Step: 6
Training loss: 0.3537531793117523
Validation loss: 1.8115100053048903

Epoch: 6| Step: 7
Training loss: 0.3979037404060364
Validation loss: 1.7376989395387712

Epoch: 6| Step: 8
Training loss: 0.2317846417427063
Validation loss: 1.7886150895908315

Epoch: 6| Step: 9
Training loss: 0.295656681060791
Validation loss: 1.8101620853588145

Epoch: 6| Step: 10
Training loss: 0.2642023265361786
Validation loss: 1.807803298837395

Epoch: 6| Step: 11
Training loss: 0.3900333642959595
Validation loss: 1.780517726816157

Epoch: 6| Step: 12
Training loss: 0.30290868878364563
Validation loss: 1.8158784733023694

Epoch: 6| Step: 13
Training loss: 0.2739635407924652
Validation loss: 1.8458701923329344

Epoch: 550| Step: 0
Training loss: 0.2960178256034851
Validation loss: 1.8858368858214347

Epoch: 6| Step: 1
Training loss: 0.20468547940254211
Validation loss: 1.8922191127654044

Epoch: 6| Step: 2
Training loss: 0.5184503197669983
Validation loss: 1.8654172394865303

Epoch: 6| Step: 3
Training loss: 0.3868895471096039
Validation loss: 1.8666181038784724

Epoch: 6| Step: 4
Training loss: 0.33748555183410645
Validation loss: 1.8259351663692023

Epoch: 6| Step: 5
Training loss: 0.3166666626930237
Validation loss: 1.8307932346097884

Epoch: 6| Step: 6
Training loss: 0.3202042281627655
Validation loss: 1.7984056882960822

Epoch: 6| Step: 7
Training loss: 0.3848574757575989
Validation loss: 1.776915927087107

Epoch: 6| Step: 8
Training loss: 0.3051649332046509
Validation loss: 1.811589519182841

Epoch: 6| Step: 9
Training loss: 0.4220457673072815
Validation loss: 1.8295735723228865

Epoch: 6| Step: 10
Training loss: 0.19479599595069885
Validation loss: 1.828685914316485

Epoch: 6| Step: 11
Training loss: 0.5531910061836243
Validation loss: 1.896456464003491

Epoch: 6| Step: 12
Training loss: 0.27206772565841675
Validation loss: 1.9702719360269525

Epoch: 6| Step: 13
Training loss: 0.32012176513671875
Validation loss: 1.9516769352779593

Testing loss: 2.0111234294043645
